2798031
I0514 12:44:19.488538 19863 caffe.cpp:184] Using GPUs 0
I0514 12:44:19.915439 19863 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 500
base_lr: 0.0025
display: 500
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt"
I0514 12:44:19.917582 19863 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt
I0514 12:44:19.919937 19863 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0514 12:44:19.919998 19863 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0514 12:44:19.920373 19863 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0514 12:44:19.920569 19863 layer_factory.hpp:77] Creating layer data_hdf5
I0514 12:44:19.920596 19863 net.cpp:106] Creating Layer data_hdf5
I0514 12:44:19.920624 19863 net.cpp:411] data_hdf5 -> data
I0514 12:44:19.920657 19863 net.cpp:411] data_hdf5 -> label
I0514 12:44:19.920688 19863 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0514 12:44:19.921974 19863 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0514 12:44:19.924265 19863 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0514 12:44:41.378216 19863 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0514 12:44:41.383600 19863 net.cpp:150] Setting up data_hdf5
I0514 12:44:41.383656 19863 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0514 12:44:41.383673 19863 net.cpp:157] Top shape: 100 (100)
I0514 12:44:41.383689 19863 net.cpp:165] Memory required for data: 2540400
I0514 12:44:41.383718 19863 layer_factory.hpp:77] Creating layer conv1
I0514 12:44:41.383754 19863 net.cpp:106] Creating Layer conv1
I0514 12:44:41.383769 19863 net.cpp:454] conv1 <- data
I0514 12:44:41.383791 19863 net.cpp:411] conv1 -> conv1
I0514 12:44:41.754912 19863 net.cpp:150] Setting up conv1
I0514 12:44:41.754966 19863 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:44:41.754988 19863 net.cpp:165] Memory required for data: 30188400
I0514 12:44:41.755022 19863 layer_factory.hpp:77] Creating layer relu1
I0514 12:44:41.755044 19863 net.cpp:106] Creating Layer relu1
I0514 12:44:41.755064 19863 net.cpp:454] relu1 <- conv1
I0514 12:44:41.755101 19863 net.cpp:397] relu1 -> conv1 (in-place)
I0514 12:44:41.755636 19863 net.cpp:150] Setting up relu1
I0514 12:44:41.755659 19863 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:44:41.755673 19863 net.cpp:165] Memory required for data: 57836400
I0514 12:44:41.755686 19863 layer_factory.hpp:77] Creating layer pool1
I0514 12:44:41.755717 19863 net.cpp:106] Creating Layer pool1
I0514 12:44:41.755729 19863 net.cpp:454] pool1 <- conv1
I0514 12:44:41.755746 19863 net.cpp:411] pool1 -> pool1
I0514 12:44:41.755841 19863 net.cpp:150] Setting up pool1
I0514 12:44:41.755861 19863 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0514 12:44:41.755875 19863 net.cpp:165] Memory required for data: 71660400
I0514 12:44:41.755895 19863 layer_factory.hpp:77] Creating layer conv2
I0514 12:44:41.755919 19863 net.cpp:106] Creating Layer conv2
I0514 12:44:41.755939 19863 net.cpp:454] conv2 <- pool1
I0514 12:44:41.755956 19863 net.cpp:411] conv2 -> conv2
I0514 12:44:41.758749 19863 net.cpp:150] Setting up conv2
I0514 12:44:41.758780 19863 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:44:41.758795 19863 net.cpp:165] Memory required for data: 91532400
I0514 12:44:41.758818 19863 layer_factory.hpp:77] Creating layer relu2
I0514 12:44:41.758851 19863 net.cpp:106] Creating Layer relu2
I0514 12:44:41.758864 19863 net.cpp:454] relu2 <- conv2
I0514 12:44:41.758882 19863 net.cpp:397] relu2 -> conv2 (in-place)
I0514 12:44:41.759239 19863 net.cpp:150] Setting up relu2
I0514 12:44:41.759260 19863 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:44:41.759274 19863 net.cpp:165] Memory required for data: 111404400
I0514 12:44:41.759285 19863 layer_factory.hpp:77] Creating layer pool2
I0514 12:44:41.759310 19863 net.cpp:106] Creating Layer pool2
I0514 12:44:41.759325 19863 net.cpp:454] pool2 <- conv2
I0514 12:44:41.759341 19863 net.cpp:411] pool2 -> pool2
I0514 12:44:41.759438 19863 net.cpp:150] Setting up pool2
I0514 12:44:41.759455 19863 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0514 12:44:41.759471 19863 net.cpp:165] Memory required for data: 121340400
I0514 12:44:41.759490 19863 layer_factory.hpp:77] Creating layer conv3
I0514 12:44:41.759510 19863 net.cpp:106] Creating Layer conv3
I0514 12:44:41.759523 19863 net.cpp:454] conv3 <- pool2
I0514 12:44:41.759541 19863 net.cpp:411] conv3 -> conv3
I0514 12:44:41.761509 19863 net.cpp:150] Setting up conv3
I0514 12:44:41.761534 19863 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:44:41.761555 19863 net.cpp:165] Memory required for data: 132182000
I0514 12:44:41.761579 19863 layer_factory.hpp:77] Creating layer relu3
I0514 12:44:41.761600 19863 net.cpp:106] Creating Layer relu3
I0514 12:44:41.761622 19863 net.cpp:454] relu3 <- conv3
I0514 12:44:41.761639 19863 net.cpp:397] relu3 -> conv3 (in-place)
I0514 12:44:41.762131 19863 net.cpp:150] Setting up relu3
I0514 12:44:41.762156 19863 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:44:41.762168 19863 net.cpp:165] Memory required for data: 143023600
I0514 12:44:41.762181 19863 layer_factory.hpp:77] Creating layer pool3
I0514 12:44:41.762200 19863 net.cpp:106] Creating Layer pool3
I0514 12:44:41.762222 19863 net.cpp:454] pool3 <- conv3
I0514 12:44:41.762238 19863 net.cpp:411] pool3 -> pool3
I0514 12:44:41.762321 19863 net.cpp:150] Setting up pool3
I0514 12:44:41.762346 19863 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0514 12:44:41.762358 19863 net.cpp:165] Memory required for data: 148444400
I0514 12:44:41.762372 19863 layer_factory.hpp:77] Creating layer conv4
I0514 12:44:41.762392 19863 net.cpp:106] Creating Layer conv4
I0514 12:44:41.762404 19863 net.cpp:454] conv4 <- pool3
I0514 12:44:41.762423 19863 net.cpp:411] conv4 -> conv4
I0514 12:44:41.765435 19863 net.cpp:150] Setting up conv4
I0514 12:44:41.765467 19863 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:44:41.765483 19863 net.cpp:165] Memory required for data: 152073200
I0514 12:44:41.765502 19863 layer_factory.hpp:77] Creating layer relu4
I0514 12:44:41.765524 19863 net.cpp:106] Creating Layer relu4
I0514 12:44:41.765550 19863 net.cpp:454] relu4 <- conv4
I0514 12:44:41.765566 19863 net.cpp:397] relu4 -> conv4 (in-place)
I0514 12:44:41.766049 19863 net.cpp:150] Setting up relu4
I0514 12:44:41.766073 19863 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:44:41.766086 19863 net.cpp:165] Memory required for data: 155702000
I0514 12:44:41.766098 19863 layer_factory.hpp:77] Creating layer pool4
I0514 12:44:41.766119 19863 net.cpp:106] Creating Layer pool4
I0514 12:44:41.766140 19863 net.cpp:454] pool4 <- conv4
I0514 12:44:41.766156 19863 net.cpp:411] pool4 -> pool4
I0514 12:44:41.766244 19863 net.cpp:150] Setting up pool4
I0514 12:44:41.766268 19863 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0514 12:44:41.766281 19863 net.cpp:165] Memory required for data: 157516400
I0514 12:44:41.766294 19863 layer_factory.hpp:77] Creating layer ip1
I0514 12:44:41.766324 19863 net.cpp:106] Creating Layer ip1
I0514 12:44:41.766337 19863 net.cpp:454] ip1 <- pool4
I0514 12:44:41.766353 19863 net.cpp:411] ip1 -> ip1
I0514 12:44:41.782306 19863 net.cpp:150] Setting up ip1
I0514 12:44:41.782342 19863 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:44:41.782356 19863 net.cpp:165] Memory required for data: 157594800
I0514 12:44:41.782387 19863 layer_factory.hpp:77] Creating layer relu5
I0514 12:44:41.782416 19863 net.cpp:106] Creating Layer relu5
I0514 12:44:41.782431 19863 net.cpp:454] relu5 <- ip1
I0514 12:44:41.782447 19863 net.cpp:397] relu5 -> ip1 (in-place)
I0514 12:44:41.782829 19863 net.cpp:150] Setting up relu5
I0514 12:44:41.782850 19863 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:44:41.782863 19863 net.cpp:165] Memory required for data: 157673200
I0514 12:44:41.782879 19863 layer_factory.hpp:77] Creating layer drop1
I0514 12:44:41.782913 19863 net.cpp:106] Creating Layer drop1
I0514 12:44:41.782928 19863 net.cpp:454] drop1 <- ip1
I0514 12:44:41.782945 19863 net.cpp:397] drop1 -> ip1 (in-place)
I0514 12:44:41.783023 19863 net.cpp:150] Setting up drop1
I0514 12:44:41.783049 19863 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:44:41.783062 19863 net.cpp:165] Memory required for data: 157751600
I0514 12:44:41.783074 19863 layer_factory.hpp:77] Creating layer ip2
I0514 12:44:41.783104 19863 net.cpp:106] Creating Layer ip2
I0514 12:44:41.783118 19863 net.cpp:454] ip2 <- ip1
I0514 12:44:41.783134 19863 net.cpp:411] ip2 -> ip2
I0514 12:44:41.783634 19863 net.cpp:150] Setting up ip2
I0514 12:44:41.783653 19863 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:44:41.783668 19863 net.cpp:165] Memory required for data: 157790800
I0514 12:44:41.783687 19863 layer_factory.hpp:77] Creating layer relu6
I0514 12:44:41.783710 19863 net.cpp:106] Creating Layer relu6
I0514 12:44:41.783723 19863 net.cpp:454] relu6 <- ip2
I0514 12:44:41.783738 19863 net.cpp:397] relu6 -> ip2 (in-place)
I0514 12:44:41.784289 19863 net.cpp:150] Setting up relu6
I0514 12:44:41.784312 19863 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:44:41.784327 19863 net.cpp:165] Memory required for data: 157830000
I0514 12:44:41.784343 19863 layer_factory.hpp:77] Creating layer drop2
I0514 12:44:41.784368 19863 net.cpp:106] Creating Layer drop2
I0514 12:44:41.784380 19863 net.cpp:454] drop2 <- ip2
I0514 12:44:41.784397 19863 net.cpp:397] drop2 -> ip2 (in-place)
I0514 12:44:41.784446 19863 net.cpp:150] Setting up drop2
I0514 12:44:41.784469 19863 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:44:41.784482 19863 net.cpp:165] Memory required for data: 157869200
I0514 12:44:41.784495 19863 layer_factory.hpp:77] Creating layer ip3
I0514 12:44:41.784510 19863 net.cpp:106] Creating Layer ip3
I0514 12:44:41.784525 19863 net.cpp:454] ip3 <- ip2
I0514 12:44:41.784553 19863 net.cpp:411] ip3 -> ip3
I0514 12:44:41.784780 19863 net.cpp:150] Setting up ip3
I0514 12:44:41.784801 19863 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:44:41.784812 19863 net.cpp:165] Memory required for data: 157873600
I0514 12:44:41.784833 19863 layer_factory.hpp:77] Creating layer drop3
I0514 12:44:41.784848 19863 net.cpp:106] Creating Layer drop3
I0514 12:44:41.784868 19863 net.cpp:454] drop3 <- ip3
I0514 12:44:41.784884 19863 net.cpp:397] drop3 -> ip3 (in-place)
I0514 12:44:41.784934 19863 net.cpp:150] Setting up drop3
I0514 12:44:41.784950 19863 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:44:41.784965 19863 net.cpp:165] Memory required for data: 157878000
I0514 12:44:41.784977 19863 layer_factory.hpp:77] Creating layer loss
I0514 12:44:41.785003 19863 net.cpp:106] Creating Layer loss
I0514 12:44:41.785017 19863 net.cpp:454] loss <- ip3
I0514 12:44:41.785032 19863 net.cpp:454] loss <- label
I0514 12:44:41.785045 19863 net.cpp:411] loss -> loss
I0514 12:44:41.785082 19863 layer_factory.hpp:77] Creating layer loss
I0514 12:44:41.785744 19863 net.cpp:150] Setting up loss
I0514 12:44:41.785766 19863 net.cpp:157] Top shape: (1)
I0514 12:44:41.785789 19863 net.cpp:160]     with loss weight 1
I0514 12:44:41.785840 19863 net.cpp:165] Memory required for data: 157878004
I0514 12:44:41.785861 19863 net.cpp:226] loss needs backward computation.
I0514 12:44:41.785876 19863 net.cpp:226] drop3 needs backward computation.
I0514 12:44:41.785889 19863 net.cpp:226] ip3 needs backward computation.
I0514 12:44:41.785904 19863 net.cpp:226] drop2 needs backward computation.
I0514 12:44:41.785915 19863 net.cpp:226] relu6 needs backward computation.
I0514 12:44:41.785928 19863 net.cpp:226] ip2 needs backward computation.
I0514 12:44:41.785943 19863 net.cpp:226] drop1 needs backward computation.
I0514 12:44:41.785962 19863 net.cpp:226] relu5 needs backward computation.
I0514 12:44:41.785975 19863 net.cpp:226] ip1 needs backward computation.
I0514 12:44:41.785989 19863 net.cpp:226] pool4 needs backward computation.
I0514 12:44:41.786002 19863 net.cpp:226] relu4 needs backward computation.
I0514 12:44:41.786015 19863 net.cpp:226] conv4 needs backward computation.
I0514 12:44:41.786026 19863 net.cpp:226] pool3 needs backward computation.
I0514 12:44:41.786039 19863 net.cpp:226] relu3 needs backward computation.
I0514 12:44:41.786062 19863 net.cpp:226] conv3 needs backward computation.
I0514 12:44:41.786083 19863 net.cpp:226] pool2 needs backward computation.
I0514 12:44:41.786097 19863 net.cpp:226] relu2 needs backward computation.
I0514 12:44:41.786109 19863 net.cpp:226] conv2 needs backward computation.
I0514 12:44:41.786128 19863 net.cpp:226] pool1 needs backward computation.
I0514 12:44:41.786140 19863 net.cpp:226] relu1 needs backward computation.
I0514 12:44:41.786152 19863 net.cpp:226] conv1 needs backward computation.
I0514 12:44:41.786166 19863 net.cpp:228] data_hdf5 does not need backward computation.
I0514 12:44:41.786178 19863 net.cpp:270] This network produces output loss
I0514 12:44:41.786213 19863 net.cpp:283] Network initialization done.
I0514 12:44:41.788017 19863 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt
I0514 12:44:41.788097 19863 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0514 12:44:41.788477 19863 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0514 12:44:41.788683 19863 layer_factory.hpp:77] Creating layer data_hdf5
I0514 12:44:41.788705 19863 net.cpp:106] Creating Layer data_hdf5
I0514 12:44:41.788727 19863 net.cpp:411] data_hdf5 -> data
I0514 12:44:41.788746 19863 net.cpp:411] data_hdf5 -> label
I0514 12:44:41.788765 19863 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0514 12:44:41.790189 19863 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0514 12:45:03.294905 19863 net.cpp:150] Setting up data_hdf5
I0514 12:45:03.295078 19863 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0514 12:45:03.295099 19863 net.cpp:157] Top shape: 100 (100)
I0514 12:45:03.295110 19863 net.cpp:165] Memory required for data: 2540400
I0514 12:45:03.295125 19863 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0514 12:45:03.295153 19863 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0514 12:45:03.295171 19863 net.cpp:454] label_data_hdf5_1_split <- label
I0514 12:45:03.295208 19863 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0514 12:45:03.295230 19863 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0514 12:45:03.295312 19863 net.cpp:150] Setting up label_data_hdf5_1_split
I0514 12:45:03.295330 19863 net.cpp:157] Top shape: 100 (100)
I0514 12:45:03.295346 19863 net.cpp:157] Top shape: 100 (100)
I0514 12:45:03.295368 19863 net.cpp:165] Memory required for data: 2541200
I0514 12:45:03.295382 19863 layer_factory.hpp:77] Creating layer conv1
I0514 12:45:03.295405 19863 net.cpp:106] Creating Layer conv1
I0514 12:45:03.295418 19863 net.cpp:454] conv1 <- data
I0514 12:45:03.295434 19863 net.cpp:411] conv1 -> conv1
I0514 12:45:03.297415 19863 net.cpp:150] Setting up conv1
I0514 12:45:03.297441 19863 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:45:03.297462 19863 net.cpp:165] Memory required for data: 30189200
I0514 12:45:03.297487 19863 layer_factory.hpp:77] Creating layer relu1
I0514 12:45:03.297508 19863 net.cpp:106] Creating Layer relu1
I0514 12:45:03.297529 19863 net.cpp:454] relu1 <- conv1
I0514 12:45:03.297546 19863 net.cpp:397] relu1 -> conv1 (in-place)
I0514 12:45:03.298072 19863 net.cpp:150] Setting up relu1
I0514 12:45:03.298095 19863 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:45:03.298108 19863 net.cpp:165] Memory required for data: 57837200
I0514 12:45:03.298120 19863 layer_factory.hpp:77] Creating layer pool1
I0514 12:45:03.298151 19863 net.cpp:106] Creating Layer pool1
I0514 12:45:03.298166 19863 net.cpp:454] pool1 <- conv1
I0514 12:45:03.298182 19863 net.cpp:411] pool1 -> pool1
I0514 12:45:03.298280 19863 net.cpp:150] Setting up pool1
I0514 12:45:03.298297 19863 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0514 12:45:03.298310 19863 net.cpp:165] Memory required for data: 71661200
I0514 12:45:03.298322 19863 layer_factory.hpp:77] Creating layer conv2
I0514 12:45:03.298344 19863 net.cpp:106] Creating Layer conv2
I0514 12:45:03.298363 19863 net.cpp:454] conv2 <- pool1
I0514 12:45:03.298380 19863 net.cpp:411] conv2 -> conv2
I0514 12:45:03.300492 19863 net.cpp:150] Setting up conv2
I0514 12:45:03.300515 19863 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:45:03.300536 19863 net.cpp:165] Memory required for data: 91533200
I0514 12:45:03.300559 19863 layer_factory.hpp:77] Creating layer relu2
I0514 12:45:03.300578 19863 net.cpp:106] Creating Layer relu2
I0514 12:45:03.300601 19863 net.cpp:454] relu2 <- conv2
I0514 12:45:03.300617 19863 net.cpp:397] relu2 -> conv2 (in-place)
I0514 12:45:03.300978 19863 net.cpp:150] Setting up relu2
I0514 12:45:03.300998 19863 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:45:03.301012 19863 net.cpp:165] Memory required for data: 111405200
I0514 12:45:03.301023 19863 layer_factory.hpp:77] Creating layer pool2
I0514 12:45:03.301043 19863 net.cpp:106] Creating Layer pool2
I0514 12:45:03.301064 19863 net.cpp:454] pool2 <- conv2
I0514 12:45:03.301079 19863 net.cpp:411] pool2 -> pool2
I0514 12:45:03.301173 19863 net.cpp:150] Setting up pool2
I0514 12:45:03.301192 19863 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0514 12:45:03.301203 19863 net.cpp:165] Memory required for data: 121341200
I0514 12:45:03.301216 19863 layer_factory.hpp:77] Creating layer conv3
I0514 12:45:03.301241 19863 net.cpp:106] Creating Layer conv3
I0514 12:45:03.301260 19863 net.cpp:454] conv3 <- pool2
I0514 12:45:03.301277 19863 net.cpp:411] conv3 -> conv3
I0514 12:45:03.303328 19863 net.cpp:150] Setting up conv3
I0514 12:45:03.303354 19863 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:45:03.303366 19863 net.cpp:165] Memory required for data: 132182800
I0514 12:45:03.303406 19863 layer_factory.hpp:77] Creating layer relu3
I0514 12:45:03.303431 19863 net.cpp:106] Creating Layer relu3
I0514 12:45:03.303447 19863 net.cpp:454] relu3 <- conv3
I0514 12:45:03.303462 19863 net.cpp:397] relu3 -> conv3 (in-place)
I0514 12:45:03.303972 19863 net.cpp:150] Setting up relu3
I0514 12:45:03.303994 19863 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:45:03.304008 19863 net.cpp:165] Memory required for data: 143024400
I0514 12:45:03.304023 19863 layer_factory.hpp:77] Creating layer pool3
I0514 12:45:03.304047 19863 net.cpp:106] Creating Layer pool3
I0514 12:45:03.304061 19863 net.cpp:454] pool3 <- conv3
I0514 12:45:03.304077 19863 net.cpp:411] pool3 -> pool3
I0514 12:45:03.304163 19863 net.cpp:150] Setting up pool3
I0514 12:45:03.304182 19863 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0514 12:45:03.304193 19863 net.cpp:165] Memory required for data: 148445200
I0514 12:45:03.304208 19863 layer_factory.hpp:77] Creating layer conv4
I0514 12:45:03.304234 19863 net.cpp:106] Creating Layer conv4
I0514 12:45:03.304247 19863 net.cpp:454] conv4 <- pool3
I0514 12:45:03.304270 19863 net.cpp:411] conv4 -> conv4
I0514 12:45:03.306411 19863 net.cpp:150] Setting up conv4
I0514 12:45:03.306438 19863 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:45:03.306452 19863 net.cpp:165] Memory required for data: 152074000
I0514 12:45:03.306470 19863 layer_factory.hpp:77] Creating layer relu4
I0514 12:45:03.306490 19863 net.cpp:106] Creating Layer relu4
I0514 12:45:03.306514 19863 net.cpp:454] relu4 <- conv4
I0514 12:45:03.306529 19863 net.cpp:397] relu4 -> conv4 (in-place)
I0514 12:45:03.307034 19863 net.cpp:150] Setting up relu4
I0514 12:45:03.307057 19863 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:45:03.307070 19863 net.cpp:165] Memory required for data: 155702800
I0514 12:45:03.307083 19863 layer_factory.hpp:77] Creating layer pool4
I0514 12:45:03.307102 19863 net.cpp:106] Creating Layer pool4
I0514 12:45:03.307124 19863 net.cpp:454] pool4 <- conv4
I0514 12:45:03.307142 19863 net.cpp:411] pool4 -> pool4
I0514 12:45:03.307231 19863 net.cpp:150] Setting up pool4
I0514 12:45:03.307255 19863 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0514 12:45:03.307268 19863 net.cpp:165] Memory required for data: 157517200
I0514 12:45:03.307282 19863 layer_factory.hpp:77] Creating layer ip1
I0514 12:45:03.307306 19863 net.cpp:106] Creating Layer ip1
I0514 12:45:03.307318 19863 net.cpp:454] ip1 <- pool4
I0514 12:45:03.307335 19863 net.cpp:411] ip1 -> ip1
I0514 12:45:03.323273 19863 net.cpp:150] Setting up ip1
I0514 12:45:03.323307 19863 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:45:03.323320 19863 net.cpp:165] Memory required for data: 157595600
I0514 12:45:03.323346 19863 layer_factory.hpp:77] Creating layer relu5
I0514 12:45:03.323369 19863 net.cpp:106] Creating Layer relu5
I0514 12:45:03.323396 19863 net.cpp:454] relu5 <- ip1
I0514 12:45:03.323415 19863 net.cpp:397] relu5 -> ip1 (in-place)
I0514 12:45:03.323791 19863 net.cpp:150] Setting up relu5
I0514 12:45:03.323812 19863 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:45:03.323825 19863 net.cpp:165] Memory required for data: 157674000
I0514 12:45:03.323837 19863 layer_factory.hpp:77] Creating layer drop1
I0514 12:45:03.323869 19863 net.cpp:106] Creating Layer drop1
I0514 12:45:03.323884 19863 net.cpp:454] drop1 <- ip1
I0514 12:45:03.323899 19863 net.cpp:397] drop1 -> ip1 (in-place)
I0514 12:45:03.323951 19863 net.cpp:150] Setting up drop1
I0514 12:45:03.323973 19863 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:45:03.323987 19863 net.cpp:165] Memory required for data: 157752400
I0514 12:45:03.324002 19863 layer_factory.hpp:77] Creating layer ip2
I0514 12:45:03.324018 19863 net.cpp:106] Creating Layer ip2
I0514 12:45:03.324033 19863 net.cpp:454] ip2 <- ip1
I0514 12:45:03.324055 19863 net.cpp:411] ip2 -> ip2
I0514 12:45:03.324558 19863 net.cpp:150] Setting up ip2
I0514 12:45:03.324578 19863 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:45:03.324590 19863 net.cpp:165] Memory required for data: 157791600
I0514 12:45:03.324611 19863 layer_factory.hpp:77] Creating layer relu6
I0514 12:45:03.324647 19863 net.cpp:106] Creating Layer relu6
I0514 12:45:03.324661 19863 net.cpp:454] relu6 <- ip2
I0514 12:45:03.324677 19863 net.cpp:397] relu6 -> ip2 (in-place)
I0514 12:45:03.325249 19863 net.cpp:150] Setting up relu6
I0514 12:45:03.325273 19863 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:45:03.325285 19863 net.cpp:165] Memory required for data: 157830800
I0514 12:45:03.325297 19863 layer_factory.hpp:77] Creating layer drop2
I0514 12:45:03.325317 19863 net.cpp:106] Creating Layer drop2
I0514 12:45:03.325338 19863 net.cpp:454] drop2 <- ip2
I0514 12:45:03.325356 19863 net.cpp:397] drop2 -> ip2 (in-place)
I0514 12:45:03.325410 19863 net.cpp:150] Setting up drop2
I0514 12:45:03.325429 19863 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:45:03.325441 19863 net.cpp:165] Memory required for data: 157870000
I0514 12:45:03.325461 19863 layer_factory.hpp:77] Creating layer ip3
I0514 12:45:03.325479 19863 net.cpp:106] Creating Layer ip3
I0514 12:45:03.325495 19863 net.cpp:454] ip3 <- ip2
I0514 12:45:03.325510 19863 net.cpp:411] ip3 -> ip3
I0514 12:45:03.325759 19863 net.cpp:150] Setting up ip3
I0514 12:45:03.325778 19863 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:45:03.325791 19863 net.cpp:165] Memory required for data: 157874400
I0514 12:45:03.325812 19863 layer_factory.hpp:77] Creating layer drop3
I0514 12:45:03.325834 19863 net.cpp:106] Creating Layer drop3
I0514 12:45:03.325847 19863 net.cpp:454] drop3 <- ip3
I0514 12:45:03.325863 19863 net.cpp:397] drop3 -> ip3 (in-place)
I0514 12:45:03.325911 19863 net.cpp:150] Setting up drop3
I0514 12:45:03.325934 19863 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:45:03.325947 19863 net.cpp:165] Memory required for data: 157878800
I0514 12:45:03.325965 19863 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0514 12:45:03.325981 19863 net.cpp:106] Creating Layer ip3_drop3_0_split
I0514 12:45:03.325994 19863 net.cpp:454] ip3_drop3_0_split <- ip3
I0514 12:45:03.326011 19863 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0514 12:45:03.326035 19863 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0514 12:45:03.326115 19863 net.cpp:150] Setting up ip3_drop3_0_split
I0514 12:45:03.326139 19863 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:45:03.326154 19863 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:45:03.326167 19863 net.cpp:165] Memory required for data: 157887600
I0514 12:45:03.326180 19863 layer_factory.hpp:77] Creating layer accuracy
I0514 12:45:03.326205 19863 net.cpp:106] Creating Layer accuracy
I0514 12:45:03.326223 19863 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0514 12:45:03.326238 19863 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0514 12:45:03.326256 19863 net.cpp:411] accuracy -> accuracy
I0514 12:45:03.326282 19863 net.cpp:150] Setting up accuracy
I0514 12:45:03.326299 19863 net.cpp:157] Top shape: (1)
I0514 12:45:03.326311 19863 net.cpp:165] Memory required for data: 157887604
I0514 12:45:03.326331 19863 layer_factory.hpp:77] Creating layer loss
I0514 12:45:03.326349 19863 net.cpp:106] Creating Layer loss
I0514 12:45:03.326364 19863 net.cpp:454] loss <- ip3_drop3_0_split_1
I0514 12:45:03.326376 19863 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0514 12:45:03.326395 19863 net.cpp:411] loss -> loss
I0514 12:45:03.326414 19863 layer_factory.hpp:77] Creating layer loss
I0514 12:45:03.326941 19863 net.cpp:150] Setting up loss
I0514 12:45:03.326961 19863 net.cpp:157] Top shape: (1)
I0514 12:45:03.326973 19863 net.cpp:160]     with loss weight 1
I0514 12:45:03.327000 19863 net.cpp:165] Memory required for data: 157887608
I0514 12:45:03.327020 19863 net.cpp:226] loss needs backward computation.
I0514 12:45:03.327035 19863 net.cpp:228] accuracy does not need backward computation.
I0514 12:45:03.327049 19863 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0514 12:45:03.327062 19863 net.cpp:226] drop3 needs backward computation.
I0514 12:45:03.327075 19863 net.cpp:226] ip3 needs backward computation.
I0514 12:45:03.327090 19863 net.cpp:226] drop2 needs backward computation.
I0514 12:45:03.327117 19863 net.cpp:226] relu6 needs backward computation.
I0514 12:45:03.327131 19863 net.cpp:226] ip2 needs backward computation.
I0514 12:45:03.327147 19863 net.cpp:226] drop1 needs backward computation.
I0514 12:45:03.327160 19863 net.cpp:226] relu5 needs backward computation.
I0514 12:45:03.327172 19863 net.cpp:226] ip1 needs backward computation.
I0514 12:45:03.327184 19863 net.cpp:226] pool4 needs backward computation.
I0514 12:45:03.327196 19863 net.cpp:226] relu4 needs backward computation.
I0514 12:45:03.327211 19863 net.cpp:226] conv4 needs backward computation.
I0514 12:45:03.327231 19863 net.cpp:226] pool3 needs backward computation.
I0514 12:45:03.327245 19863 net.cpp:226] relu3 needs backward computation.
I0514 12:45:03.327258 19863 net.cpp:226] conv3 needs backward computation.
I0514 12:45:03.327271 19863 net.cpp:226] pool2 needs backward computation.
I0514 12:45:03.327283 19863 net.cpp:226] relu2 needs backward computation.
I0514 12:45:03.327296 19863 net.cpp:226] conv2 needs backward computation.
I0514 12:45:03.327308 19863 net.cpp:226] pool1 needs backward computation.
I0514 12:45:03.327324 19863 net.cpp:226] relu1 needs backward computation.
I0514 12:45:03.327342 19863 net.cpp:226] conv1 needs backward computation.
I0514 12:45:03.327358 19863 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0514 12:45:03.327373 19863 net.cpp:228] data_hdf5 does not need backward computation.
I0514 12:45:03.327384 19863 net.cpp:270] This network produces output accuracy
I0514 12:45:03.327396 19863 net.cpp:270] This network produces output loss
I0514 12:45:03.327430 19863 net.cpp:283] Network initialization done.
I0514 12:45:03.327579 19863 solver.cpp:60] Solver scaffolding done.
I0514 12:45:03.328758 19863 caffe.cpp:212] Starting Optimization
I0514 12:45:03.328779 19863 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0514 12:45:03.328795 19863 solver.cpp:289] Learning Rate Policy: fixed
I0514 12:45:03.329903 19863 solver.cpp:341] Iteration 0, Testing net (#0)
I0514 12:45:51.134704 19863 solver.cpp:409]     Test net output #0: accuracy = 0.0657266
I0514 12:45:51.134870 19863 solver.cpp:409]     Test net output #1: loss = 2.39933 (* 1 = 2.39933 loss)
I0514 12:45:51.167737 19863 solver.cpp:237] Iteration 0, loss = 2.39851
I0514 12:45:51.167783 19863 solver.cpp:253]     Train net output #0: loss = 2.39851 (* 1 = 2.39851 loss)
I0514 12:45:51.167804 19863 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0514 12:46:20.171036 19863 solver.cpp:341] Iteration 500, Testing net (#0)
I0514 12:47:07.096305 19863 solver.cpp:409]     Test net output #0: accuracy = 0.539207
I0514 12:47:07.096479 19863 solver.cpp:409]     Test net output #1: loss = 1.72561 (* 1 = 1.72561 loss)
I0514 12:47:07.114276 19863 solver.cpp:237] Iteration 500, loss = 1.95022
I0514 12:47:07.114306 19863 solver.cpp:253]     Train net output #0: loss = 1.95022 (* 1 = 1.95022 loss)
I0514 12:47:07.114325 19863 sgd_solver.cpp:106] Iteration 500, lr = 0.0025
I0514 12:47:36.197938 19863 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_1000.caffemodel
I0514 12:47:36.280213 19863 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_1000.solverstate
I0514 12:47:36.310006 19863 solver.cpp:341] Iteration 1000, Testing net (#0)
I0514 12:48:44.175768 19863 solver.cpp:409]     Test net output #0: accuracy = 0.59732
I0514 12:48:44.175937 19863 solver.cpp:409]     Test net output #1: loss = 1.43492 (* 1 = 1.43492 loss)
I0514 12:49:06.432867 19863 solver.cpp:237] Iteration 1000, loss = 1.87348
I0514 12:49:06.432934 19863 solver.cpp:253]     Train net output #0: loss = 1.87348 (* 1 = 1.87348 loss)
I0514 12:49:06.432962 19863 sgd_solver.cpp:106] Iteration 1000, lr = 0.0025
I0514 12:49:35.483427 19863 solver.cpp:341] Iteration 1500, Testing net (#0)
I0514 12:50:22.116348 19863 solver.cpp:409]     Test net output #0: accuracy = 0.646906
I0514 12:50:22.116516 19863 solver.cpp:409]     Test net output #1: loss = 1.32604 (* 1 = 1.32604 loss)
I0514 12:50:22.134275 19863 solver.cpp:237] Iteration 1500, loss = 1.74335
I0514 12:50:22.134306 19863 solver.cpp:253]     Train net output #0: loss = 1.74335 (* 1 = 1.74335 loss)
I0514 12:50:22.134325 19863 sgd_solver.cpp:106] Iteration 1500, lr = 0.0025
I0514 12:50:51.176569 19863 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_2000.caffemodel
I0514 12:50:51.257606 19863 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_2000.solverstate
I0514 12:50:51.286317 19863 solver.cpp:341] Iteration 2000, Testing net (#0)
I0514 12:51:59.173188 19863 solver.cpp:409]     Test net output #0: accuracy = 0.658793
I0514 12:51:59.173357 19863 solver.cpp:409]     Test net output #1: loss = 1.2463 (* 1 = 1.2463 loss)
I0514 12:52:21.456713 19863 solver.cpp:237] Iteration 2000, loss = 1.82009
I0514 12:52:21.456782 19863 solver.cpp:253]     Train net output #0: loss = 1.82009 (* 1 = 1.82009 loss)
I0514 12:52:21.456812 19863 sgd_solver.cpp:106] Iteration 2000, lr = 0.0025
I0514 12:52:50.512212 19863 solver.cpp:341] Iteration 2500, Testing net (#0)
I0514 12:53:37.469535 19863 solver.cpp:409]     Test net output #0: accuracy = 0.678006
I0514 12:53:37.469704 19863 solver.cpp:409]     Test net output #1: loss = 1.11074 (* 1 = 1.11074 loss)
I0514 12:53:37.487535 19863 solver.cpp:237] Iteration 2500, loss = 1.53788
I0514 12:53:37.487565 19863 solver.cpp:253]     Train net output #0: loss = 1.53788 (* 1 = 1.53788 loss)
I0514 12:53:37.487583 19863 sgd_solver.cpp:106] Iteration 2500, lr = 0.0025
I0514 12:54:06.525904 19863 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_3000.caffemodel
I0514 12:54:06.606617 19863 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_3000.solverstate
I0514 12:54:06.635097 19863 solver.cpp:341] Iteration 3000, Testing net (#0)
aprun: Apid 11199327: Caught signal Terminated, sending to application
*** Aborted at 1463244871 (unix time) try "date -d @1463244871" if you are using GNU date ***
=>> PBS: job killed: walltime 621 exceeded limit 600
PC: @     0x2aaab92fb470 (unknown)
*** SIGTERM (@0x4d94) received by PID 19863 (TID 0x2aaac746f900) from PID 19860; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab92fb470 (unknown)
    @     0x2aaab928ec4d (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11199327: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11199327: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x637300 caffe::caffe_gpu_memcpy()
    @           0x606cf0 caffe::SyncedMemory::to_gpu()
    @           0x605ef9 caffe::SyncedMemory::gpu_data()
    @           0x5f0302 caffe::Blob<>::gpu_data()
    @           0x612c57 caffe::InnerProductLayer<>::Forward_gpu()
aprun: Apid 11199327: Caught signal Terminated, sending to application
    @           0x4a6872 caffe::Net<>::ForwardFromTo()
    @           0x4a6987 caffe::Net<>::ForwardPrefilled()
    @           0x59f48f caffe::Solver<>::Test()
    @           0x59fdde caffe::Solver<>::TestAll()
    @           0x59ff21 caffe::Solver<>::Step()
    @           0x5a0ac5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11199327: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
aprun: Apid 11199327: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03791] [c8-1c0s7n1] [Sat May 14 12:54:33 2016] PE RANK 0 exit signal Terminated
Application 11199327 exit codes: 143
Application 11199327 resources: utime ~529s, stime ~85s, Rss ~5329284, inblocks ~1962796, outblocks ~76530
