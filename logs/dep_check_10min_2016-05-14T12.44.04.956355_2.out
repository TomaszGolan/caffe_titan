2798039
I0514 12:55:15.314841  6268 caffe.cpp:184] Using GPUs 0
I0514 12:55:15.737934  6268 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 500
base_lr: 0.0025
display: 500
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt"
I0514 12:55:15.740223  6268 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt
I0514 12:55:15.743229  6268 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0514 12:55:15.743280  6268 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0514 12:55:15.743625  6268 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0514 12:55:15.743803  6268 layer_factory.hpp:77] Creating layer data_hdf5
I0514 12:55:15.743825  6268 net.cpp:106] Creating Layer data_hdf5
I0514 12:55:15.743842  6268 net.cpp:411] data_hdf5 -> data
I0514 12:55:15.743876  6268 net.cpp:411] data_hdf5 -> label
I0514 12:55:15.743906  6268 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0514 12:55:15.745208  6268 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0514 12:55:15.747544  6268 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0514 12:55:37.234660  6268 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0514 12:55:37.239989  6268 net.cpp:150] Setting up data_hdf5
I0514 12:55:37.240038  6268 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0514 12:55:37.240053  6268 net.cpp:157] Top shape: 100 (100)
I0514 12:55:37.240064  6268 net.cpp:165] Memory required for data: 2540400
I0514 12:55:37.240077  6268 layer_factory.hpp:77] Creating layer conv1
I0514 12:55:37.240113  6268 net.cpp:106] Creating Layer conv1
I0514 12:55:37.240125  6268 net.cpp:454] conv1 <- data
I0514 12:55:37.240146  6268 net.cpp:411] conv1 -> conv1
I0514 12:55:37.604704  6268 net.cpp:150] Setting up conv1
I0514 12:55:37.604748  6268 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:55:37.604758  6268 net.cpp:165] Memory required for data: 30188400
I0514 12:55:37.604789  6268 layer_factory.hpp:77] Creating layer relu1
I0514 12:55:37.604811  6268 net.cpp:106] Creating Layer relu1
I0514 12:55:37.604823  6268 net.cpp:454] relu1 <- conv1
I0514 12:55:37.604836  6268 net.cpp:397] relu1 -> conv1 (in-place)
I0514 12:55:37.605358  6268 net.cpp:150] Setting up relu1
I0514 12:55:37.605376  6268 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:55:37.605386  6268 net.cpp:165] Memory required for data: 57836400
I0514 12:55:37.605396  6268 layer_factory.hpp:77] Creating layer pool1
I0514 12:55:37.605412  6268 net.cpp:106] Creating Layer pool1
I0514 12:55:37.605422  6268 net.cpp:454] pool1 <- conv1
I0514 12:55:37.605437  6268 net.cpp:411] pool1 -> pool1
I0514 12:55:37.605518  6268 net.cpp:150] Setting up pool1
I0514 12:55:37.605533  6268 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0514 12:55:37.605543  6268 net.cpp:165] Memory required for data: 71660400
I0514 12:55:37.605551  6268 layer_factory.hpp:77] Creating layer conv2
I0514 12:55:37.605574  6268 net.cpp:106] Creating Layer conv2
I0514 12:55:37.605584  6268 net.cpp:454] conv2 <- pool1
I0514 12:55:37.605598  6268 net.cpp:411] conv2 -> conv2
I0514 12:55:37.608352  6268 net.cpp:150] Setting up conv2
I0514 12:55:37.608381  6268 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:55:37.608392  6268 net.cpp:165] Memory required for data: 91532400
I0514 12:55:37.608412  6268 layer_factory.hpp:77] Creating layer relu2
I0514 12:55:37.608427  6268 net.cpp:106] Creating Layer relu2
I0514 12:55:37.608436  6268 net.cpp:454] relu2 <- conv2
I0514 12:55:37.608448  6268 net.cpp:397] relu2 -> conv2 (in-place)
I0514 12:55:37.608782  6268 net.cpp:150] Setting up relu2
I0514 12:55:37.608795  6268 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:55:37.608806  6268 net.cpp:165] Memory required for data: 111404400
I0514 12:55:37.608816  6268 layer_factory.hpp:77] Creating layer pool2
I0514 12:55:37.608829  6268 net.cpp:106] Creating Layer pool2
I0514 12:55:37.608839  6268 net.cpp:454] pool2 <- conv2
I0514 12:55:37.608851  6268 net.cpp:411] pool2 -> pool2
I0514 12:55:37.608935  6268 net.cpp:150] Setting up pool2
I0514 12:55:37.608949  6268 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0514 12:55:37.608960  6268 net.cpp:165] Memory required for data: 121340400
I0514 12:55:37.608970  6268 layer_factory.hpp:77] Creating layer conv3
I0514 12:55:37.608989  6268 net.cpp:106] Creating Layer conv3
I0514 12:55:37.608999  6268 net.cpp:454] conv3 <- pool2
I0514 12:55:37.609012  6268 net.cpp:411] conv3 -> conv3
I0514 12:55:37.610952  6268 net.cpp:150] Setting up conv3
I0514 12:55:37.610976  6268 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:55:37.610988  6268 net.cpp:165] Memory required for data: 132182000
I0514 12:55:37.611006  6268 layer_factory.hpp:77] Creating layer relu3
I0514 12:55:37.611022  6268 net.cpp:106] Creating Layer relu3
I0514 12:55:37.611032  6268 net.cpp:454] relu3 <- conv3
I0514 12:55:37.611045  6268 net.cpp:397] relu3 -> conv3 (in-place)
I0514 12:55:37.611520  6268 net.cpp:150] Setting up relu3
I0514 12:55:37.611536  6268 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:55:37.611546  6268 net.cpp:165] Memory required for data: 143023600
I0514 12:55:37.611557  6268 layer_factory.hpp:77] Creating layer pool3
I0514 12:55:37.611569  6268 net.cpp:106] Creating Layer pool3
I0514 12:55:37.611579  6268 net.cpp:454] pool3 <- conv3
I0514 12:55:37.611591  6268 net.cpp:411] pool3 -> pool3
I0514 12:55:37.611660  6268 net.cpp:150] Setting up pool3
I0514 12:55:37.611672  6268 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0514 12:55:37.611682  6268 net.cpp:165] Memory required for data: 148444400
I0514 12:55:37.611692  6268 layer_factory.hpp:77] Creating layer conv4
I0514 12:55:37.611709  6268 net.cpp:106] Creating Layer conv4
I0514 12:55:37.611721  6268 net.cpp:454] conv4 <- pool3
I0514 12:55:37.611733  6268 net.cpp:411] conv4 -> conv4
I0514 12:55:37.614722  6268 net.cpp:150] Setting up conv4
I0514 12:55:37.614750  6268 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:55:37.614761  6268 net.cpp:165] Memory required for data: 152073200
I0514 12:55:37.614778  6268 layer_factory.hpp:77] Creating layer relu4
I0514 12:55:37.614791  6268 net.cpp:106] Creating Layer relu4
I0514 12:55:37.614801  6268 net.cpp:454] relu4 <- conv4
I0514 12:55:37.614814  6268 net.cpp:397] relu4 -> conv4 (in-place)
I0514 12:55:37.615309  6268 net.cpp:150] Setting up relu4
I0514 12:55:37.615326  6268 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:55:37.615336  6268 net.cpp:165] Memory required for data: 155702000
I0514 12:55:37.615347  6268 layer_factory.hpp:77] Creating layer pool4
I0514 12:55:37.615360  6268 net.cpp:106] Creating Layer pool4
I0514 12:55:37.615370  6268 net.cpp:454] pool4 <- conv4
I0514 12:55:37.615383  6268 net.cpp:411] pool4 -> pool4
I0514 12:55:37.615453  6268 net.cpp:150] Setting up pool4
I0514 12:55:37.615466  6268 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0514 12:55:37.615476  6268 net.cpp:165] Memory required for data: 157516400
I0514 12:55:37.615486  6268 layer_factory.hpp:77] Creating layer ip1
I0514 12:55:37.615504  6268 net.cpp:106] Creating Layer ip1
I0514 12:55:37.615514  6268 net.cpp:454] ip1 <- pool4
I0514 12:55:37.615527  6268 net.cpp:411] ip1 -> ip1
I0514 12:55:37.631384  6268 net.cpp:150] Setting up ip1
I0514 12:55:37.631413  6268 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:55:37.631425  6268 net.cpp:165] Memory required for data: 157594800
I0514 12:55:37.631448  6268 layer_factory.hpp:77] Creating layer relu5
I0514 12:55:37.631463  6268 net.cpp:106] Creating Layer relu5
I0514 12:55:37.631472  6268 net.cpp:454] relu5 <- ip1
I0514 12:55:37.631486  6268 net.cpp:397] relu5 -> ip1 (in-place)
I0514 12:55:37.631835  6268 net.cpp:150] Setting up relu5
I0514 12:55:37.631849  6268 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:55:37.631858  6268 net.cpp:165] Memory required for data: 157673200
I0514 12:55:37.631870  6268 layer_factory.hpp:77] Creating layer drop1
I0514 12:55:37.631888  6268 net.cpp:106] Creating Layer drop1
I0514 12:55:37.631898  6268 net.cpp:454] drop1 <- ip1
I0514 12:55:37.631911  6268 net.cpp:397] drop1 -> ip1 (in-place)
I0514 12:55:37.631973  6268 net.cpp:150] Setting up drop1
I0514 12:55:37.631986  6268 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:55:37.631996  6268 net.cpp:165] Memory required for data: 157751600
I0514 12:55:37.632006  6268 layer_factory.hpp:77] Creating layer ip2
I0514 12:55:37.632025  6268 net.cpp:106] Creating Layer ip2
I0514 12:55:37.632035  6268 net.cpp:454] ip2 <- ip1
I0514 12:55:37.632050  6268 net.cpp:411] ip2 -> ip2
I0514 12:55:37.632524  6268 net.cpp:150] Setting up ip2
I0514 12:55:37.632537  6268 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:55:37.632549  6268 net.cpp:165] Memory required for data: 157790800
I0514 12:55:37.632563  6268 layer_factory.hpp:77] Creating layer relu6
I0514 12:55:37.632577  6268 net.cpp:106] Creating Layer relu6
I0514 12:55:37.632587  6268 net.cpp:454] relu6 <- ip2
I0514 12:55:37.632599  6268 net.cpp:397] relu6 -> ip2 (in-place)
I0514 12:55:37.633129  6268 net.cpp:150] Setting up relu6
I0514 12:55:37.633147  6268 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:55:37.633158  6268 net.cpp:165] Memory required for data: 157830000
I0514 12:55:37.633168  6268 layer_factory.hpp:77] Creating layer drop2
I0514 12:55:37.633182  6268 net.cpp:106] Creating Layer drop2
I0514 12:55:37.633191  6268 net.cpp:454] drop2 <- ip2
I0514 12:55:37.633203  6268 net.cpp:397] drop2 -> ip2 (in-place)
I0514 12:55:37.633244  6268 net.cpp:150] Setting up drop2
I0514 12:55:37.633257  6268 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:55:37.633268  6268 net.cpp:165] Memory required for data: 157869200
I0514 12:55:37.633278  6268 layer_factory.hpp:77] Creating layer ip3
I0514 12:55:37.633291  6268 net.cpp:106] Creating Layer ip3
I0514 12:55:37.633301  6268 net.cpp:454] ip3 <- ip2
I0514 12:55:37.633314  6268 net.cpp:411] ip3 -> ip3
I0514 12:55:37.633525  6268 net.cpp:150] Setting up ip3
I0514 12:55:37.633538  6268 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:55:37.633549  6268 net.cpp:165] Memory required for data: 157873600
I0514 12:55:37.633564  6268 layer_factory.hpp:77] Creating layer drop3
I0514 12:55:37.633577  6268 net.cpp:106] Creating Layer drop3
I0514 12:55:37.633587  6268 net.cpp:454] drop3 <- ip3
I0514 12:55:37.633599  6268 net.cpp:397] drop3 -> ip3 (in-place)
I0514 12:55:37.633640  6268 net.cpp:150] Setting up drop3
I0514 12:55:37.633652  6268 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:55:37.633662  6268 net.cpp:165] Memory required for data: 157878000
I0514 12:55:37.633671  6268 layer_factory.hpp:77] Creating layer loss
I0514 12:55:37.633688  6268 net.cpp:106] Creating Layer loss
I0514 12:55:37.633698  6268 net.cpp:454] loss <- ip3
I0514 12:55:37.633710  6268 net.cpp:454] loss <- label
I0514 12:55:37.633723  6268 net.cpp:411] loss -> loss
I0514 12:55:37.633749  6268 layer_factory.hpp:77] Creating layer loss
I0514 12:55:37.634399  6268 net.cpp:150] Setting up loss
I0514 12:55:37.634420  6268 net.cpp:157] Top shape: (1)
I0514 12:55:37.634433  6268 net.cpp:160]     with loss weight 1
I0514 12:55:37.634479  6268 net.cpp:165] Memory required for data: 157878004
I0514 12:55:37.634490  6268 net.cpp:226] loss needs backward computation.
I0514 12:55:37.634506  6268 net.cpp:226] drop3 needs backward computation.
I0514 12:55:37.634518  6268 net.cpp:226] ip3 needs backward computation.
I0514 12:55:37.634528  6268 net.cpp:226] drop2 needs backward computation.
I0514 12:55:37.634539  6268 net.cpp:226] relu6 needs backward computation.
I0514 12:55:37.634549  6268 net.cpp:226] ip2 needs backward computation.
I0514 12:55:37.634559  6268 net.cpp:226] drop1 needs backward computation.
I0514 12:55:37.634569  6268 net.cpp:226] relu5 needs backward computation.
I0514 12:55:37.634578  6268 net.cpp:226] ip1 needs backward computation.
I0514 12:55:37.634588  6268 net.cpp:226] pool4 needs backward computation.
I0514 12:55:37.634599  6268 net.cpp:226] relu4 needs backward computation.
I0514 12:55:37.634608  6268 net.cpp:226] conv4 needs backward computation.
I0514 12:55:37.634619  6268 net.cpp:226] pool3 needs backward computation.
I0514 12:55:37.634629  6268 net.cpp:226] relu3 needs backward computation.
I0514 12:55:37.634649  6268 net.cpp:226] conv3 needs backward computation.
I0514 12:55:37.634660  6268 net.cpp:226] pool2 needs backward computation.
I0514 12:55:37.634670  6268 net.cpp:226] relu2 needs backward computation.
I0514 12:55:37.634680  6268 net.cpp:226] conv2 needs backward computation.
I0514 12:55:37.634692  6268 net.cpp:226] pool1 needs backward computation.
I0514 12:55:37.634702  6268 net.cpp:226] relu1 needs backward computation.
I0514 12:55:37.634712  6268 net.cpp:226] conv1 needs backward computation.
I0514 12:55:37.634724  6268 net.cpp:228] data_hdf5 does not need backward computation.
I0514 12:55:37.634733  6268 net.cpp:270] This network produces output loss
I0514 12:55:37.634757  6268 net.cpp:283] Network initialization done.
I0514 12:55:37.636529  6268 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.prototxt
I0514 12:55:37.636600  6268 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0514 12:55:37.636958  6268 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0514 12:55:37.637145  6268 layer_factory.hpp:77] Creating layer data_hdf5
I0514 12:55:37.637159  6268 net.cpp:106] Creating Layer data_hdf5
I0514 12:55:37.637171  6268 net.cpp:411] data_hdf5 -> data
I0514 12:55:37.637188  6268 net.cpp:411] data_hdf5 -> label
I0514 12:55:37.637204  6268 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0514 12:55:37.638556  6268 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0514 12:55:59.092702  6268 net.cpp:150] Setting up data_hdf5
I0514 12:55:59.092872  6268 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0514 12:55:59.092887  6268 net.cpp:157] Top shape: 100 (100)
I0514 12:55:59.092900  6268 net.cpp:165] Memory required for data: 2540400
I0514 12:55:59.092912  6268 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0514 12:55:59.092941  6268 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0514 12:55:59.092952  6268 net.cpp:454] label_data_hdf5_1_split <- label
I0514 12:55:59.092967  6268 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0514 12:55:59.092988  6268 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0514 12:55:59.093065  6268 net.cpp:150] Setting up label_data_hdf5_1_split
I0514 12:55:59.093080  6268 net.cpp:157] Top shape: 100 (100)
I0514 12:55:59.093091  6268 net.cpp:157] Top shape: 100 (100)
I0514 12:55:59.093101  6268 net.cpp:165] Memory required for data: 2541200
I0514 12:55:59.093111  6268 layer_factory.hpp:77] Creating layer conv1
I0514 12:55:59.093132  6268 net.cpp:106] Creating Layer conv1
I0514 12:55:59.093142  6268 net.cpp:454] conv1 <- data
I0514 12:55:59.093155  6268 net.cpp:411] conv1 -> conv1
I0514 12:55:59.095139  6268 net.cpp:150] Setting up conv1
I0514 12:55:59.095165  6268 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:55:59.095175  6268 net.cpp:165] Memory required for data: 30189200
I0514 12:55:59.095196  6268 layer_factory.hpp:77] Creating layer relu1
I0514 12:55:59.095211  6268 net.cpp:106] Creating Layer relu1
I0514 12:55:59.095221  6268 net.cpp:454] relu1 <- conv1
I0514 12:55:59.095234  6268 net.cpp:397] relu1 -> conv1 (in-place)
I0514 12:55:59.095736  6268 net.cpp:150] Setting up relu1
I0514 12:55:59.095753  6268 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0514 12:55:59.095764  6268 net.cpp:165] Memory required for data: 57837200
I0514 12:55:59.095774  6268 layer_factory.hpp:77] Creating layer pool1
I0514 12:55:59.095789  6268 net.cpp:106] Creating Layer pool1
I0514 12:55:59.095800  6268 net.cpp:454] pool1 <- conv1
I0514 12:55:59.095813  6268 net.cpp:411] pool1 -> pool1
I0514 12:55:59.095888  6268 net.cpp:150] Setting up pool1
I0514 12:55:59.095902  6268 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0514 12:55:59.095911  6268 net.cpp:165] Memory required for data: 71661200
I0514 12:55:59.095921  6268 layer_factory.hpp:77] Creating layer conv2
I0514 12:55:59.095938  6268 net.cpp:106] Creating Layer conv2
I0514 12:55:59.095949  6268 net.cpp:454] conv2 <- pool1
I0514 12:55:59.095963  6268 net.cpp:411] conv2 -> conv2
I0514 12:55:59.097972  6268 net.cpp:150] Setting up conv2
I0514 12:55:59.097995  6268 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:55:59.098007  6268 net.cpp:165] Memory required for data: 91533200
I0514 12:55:59.098026  6268 layer_factory.hpp:77] Creating layer relu2
I0514 12:55:59.098038  6268 net.cpp:106] Creating Layer relu2
I0514 12:55:59.098048  6268 net.cpp:454] relu2 <- conv2
I0514 12:55:59.098062  6268 net.cpp:397] relu2 -> conv2 (in-place)
I0514 12:55:59.098405  6268 net.cpp:150] Setting up relu2
I0514 12:55:59.098418  6268 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0514 12:55:59.098428  6268 net.cpp:165] Memory required for data: 111405200
I0514 12:55:59.098439  6268 layer_factory.hpp:77] Creating layer pool2
I0514 12:55:59.098451  6268 net.cpp:106] Creating Layer pool2
I0514 12:55:59.098461  6268 net.cpp:454] pool2 <- conv2
I0514 12:55:59.098474  6268 net.cpp:411] pool2 -> pool2
I0514 12:55:59.098556  6268 net.cpp:150] Setting up pool2
I0514 12:55:59.098569  6268 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0514 12:55:59.098579  6268 net.cpp:165] Memory required for data: 121341200
I0514 12:55:59.098589  6268 layer_factory.hpp:77] Creating layer conv3
I0514 12:55:59.098609  6268 net.cpp:106] Creating Layer conv3
I0514 12:55:59.098620  6268 net.cpp:454] conv3 <- pool2
I0514 12:55:59.098634  6268 net.cpp:411] conv3 -> conv3
I0514 12:55:59.100656  6268 net.cpp:150] Setting up conv3
I0514 12:55:59.100673  6268 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:55:59.100683  6268 net.cpp:165] Memory required for data: 132182800
I0514 12:55:59.100718  6268 layer_factory.hpp:77] Creating layer relu3
I0514 12:55:59.100731  6268 net.cpp:106] Creating Layer relu3
I0514 12:55:59.100741  6268 net.cpp:454] relu3 <- conv3
I0514 12:55:59.100754  6268 net.cpp:397] relu3 -> conv3 (in-place)
I0514 12:55:59.101232  6268 net.cpp:150] Setting up relu3
I0514 12:55:59.101248  6268 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0514 12:55:59.101258  6268 net.cpp:165] Memory required for data: 143024400
I0514 12:55:59.101267  6268 layer_factory.hpp:77] Creating layer pool3
I0514 12:55:59.101280  6268 net.cpp:106] Creating Layer pool3
I0514 12:55:59.101290  6268 net.cpp:454] pool3 <- conv3
I0514 12:55:59.101302  6268 net.cpp:411] pool3 -> pool3
I0514 12:55:59.101374  6268 net.cpp:150] Setting up pool3
I0514 12:55:59.101388  6268 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0514 12:55:59.101398  6268 net.cpp:165] Memory required for data: 148445200
I0514 12:55:59.101407  6268 layer_factory.hpp:77] Creating layer conv4
I0514 12:55:59.101423  6268 net.cpp:106] Creating Layer conv4
I0514 12:55:59.101434  6268 net.cpp:454] conv4 <- pool3
I0514 12:55:59.101449  6268 net.cpp:411] conv4 -> conv4
I0514 12:55:59.103579  6268 net.cpp:150] Setting up conv4
I0514 12:55:59.103600  6268 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:55:59.103613  6268 net.cpp:165] Memory required for data: 152074000
I0514 12:55:59.103629  6268 layer_factory.hpp:77] Creating layer relu4
I0514 12:55:59.103642  6268 net.cpp:106] Creating Layer relu4
I0514 12:55:59.103652  6268 net.cpp:454] relu4 <- conv4
I0514 12:55:59.103665  6268 net.cpp:397] relu4 -> conv4 (in-place)
I0514 12:55:59.104140  6268 net.cpp:150] Setting up relu4
I0514 12:55:59.104156  6268 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0514 12:55:59.104166  6268 net.cpp:165] Memory required for data: 155702800
I0514 12:55:59.104176  6268 layer_factory.hpp:77] Creating layer pool4
I0514 12:55:59.104189  6268 net.cpp:106] Creating Layer pool4
I0514 12:55:59.104199  6268 net.cpp:454] pool4 <- conv4
I0514 12:55:59.104212  6268 net.cpp:411] pool4 -> pool4
I0514 12:55:59.104285  6268 net.cpp:150] Setting up pool4
I0514 12:55:59.104298  6268 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0514 12:55:59.104308  6268 net.cpp:165] Memory required for data: 157517200
I0514 12:55:59.104318  6268 layer_factory.hpp:77] Creating layer ip1
I0514 12:55:59.104334  6268 net.cpp:106] Creating Layer ip1
I0514 12:55:59.104344  6268 net.cpp:454] ip1 <- pool4
I0514 12:55:59.104358  6268 net.cpp:411] ip1 -> ip1
I0514 12:55:59.120263  6268 net.cpp:150] Setting up ip1
I0514 12:55:59.120292  6268 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:55:59.120304  6268 net.cpp:165] Memory required for data: 157595600
I0514 12:55:59.120326  6268 layer_factory.hpp:77] Creating layer relu5
I0514 12:55:59.120342  6268 net.cpp:106] Creating Layer relu5
I0514 12:55:59.120352  6268 net.cpp:454] relu5 <- ip1
I0514 12:55:59.120365  6268 net.cpp:397] relu5 -> ip1 (in-place)
I0514 12:55:59.120718  6268 net.cpp:150] Setting up relu5
I0514 12:55:59.120731  6268 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:55:59.120741  6268 net.cpp:165] Memory required for data: 157674000
I0514 12:55:59.120753  6268 layer_factory.hpp:77] Creating layer drop1
I0514 12:55:59.120771  6268 net.cpp:106] Creating Layer drop1
I0514 12:55:59.120781  6268 net.cpp:454] drop1 <- ip1
I0514 12:55:59.120795  6268 net.cpp:397] drop1 -> ip1 (in-place)
I0514 12:55:59.120839  6268 net.cpp:150] Setting up drop1
I0514 12:55:59.120852  6268 net.cpp:157] Top shape: 100 196 (19600)
I0514 12:55:59.120862  6268 net.cpp:165] Memory required for data: 157752400
I0514 12:55:59.120872  6268 layer_factory.hpp:77] Creating layer ip2
I0514 12:55:59.120885  6268 net.cpp:106] Creating Layer ip2
I0514 12:55:59.120895  6268 net.cpp:454] ip2 <- ip1
I0514 12:55:59.120909  6268 net.cpp:411] ip2 -> ip2
I0514 12:55:59.121398  6268 net.cpp:150] Setting up ip2
I0514 12:55:59.121412  6268 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:55:59.121422  6268 net.cpp:165] Memory required for data: 157791600
I0514 12:55:59.121438  6268 layer_factory.hpp:77] Creating layer relu6
I0514 12:55:59.121462  6268 net.cpp:106] Creating Layer relu6
I0514 12:55:59.121474  6268 net.cpp:454] relu6 <- ip2
I0514 12:55:59.121485  6268 net.cpp:397] relu6 -> ip2 (in-place)
I0514 12:55:59.122028  6268 net.cpp:150] Setting up relu6
I0514 12:55:59.122051  6268 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:55:59.122059  6268 net.cpp:165] Memory required for data: 157830800
I0514 12:55:59.122071  6268 layer_factory.hpp:77] Creating layer drop2
I0514 12:55:59.122083  6268 net.cpp:106] Creating Layer drop2
I0514 12:55:59.122093  6268 net.cpp:454] drop2 <- ip2
I0514 12:55:59.122107  6268 net.cpp:397] drop2 -> ip2 (in-place)
I0514 12:55:59.122150  6268 net.cpp:150] Setting up drop2
I0514 12:55:59.122164  6268 net.cpp:157] Top shape: 100 98 (9800)
I0514 12:55:59.122174  6268 net.cpp:165] Memory required for data: 157870000
I0514 12:55:59.122184  6268 layer_factory.hpp:77] Creating layer ip3
I0514 12:55:59.122197  6268 net.cpp:106] Creating Layer ip3
I0514 12:55:59.122207  6268 net.cpp:454] ip3 <- ip2
I0514 12:55:59.122221  6268 net.cpp:411] ip3 -> ip3
I0514 12:55:59.122447  6268 net.cpp:150] Setting up ip3
I0514 12:55:59.122459  6268 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:55:59.122469  6268 net.cpp:165] Memory required for data: 157874400
I0514 12:55:59.122485  6268 layer_factory.hpp:77] Creating layer drop3
I0514 12:55:59.122505  6268 net.cpp:106] Creating Layer drop3
I0514 12:55:59.122515  6268 net.cpp:454] drop3 <- ip3
I0514 12:55:59.122529  6268 net.cpp:397] drop3 -> ip3 (in-place)
I0514 12:55:59.122570  6268 net.cpp:150] Setting up drop3
I0514 12:55:59.122583  6268 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:55:59.122592  6268 net.cpp:165] Memory required for data: 157878800
I0514 12:55:59.122602  6268 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0514 12:55:59.122616  6268 net.cpp:106] Creating Layer ip3_drop3_0_split
I0514 12:55:59.122625  6268 net.cpp:454] ip3_drop3_0_split <- ip3
I0514 12:55:59.122638  6268 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0514 12:55:59.122653  6268 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0514 12:55:59.122727  6268 net.cpp:150] Setting up ip3_drop3_0_split
I0514 12:55:59.122740  6268 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:55:59.122752  6268 net.cpp:157] Top shape: 100 11 (1100)
I0514 12:55:59.122762  6268 net.cpp:165] Memory required for data: 157887600
I0514 12:55:59.122772  6268 layer_factory.hpp:77] Creating layer accuracy
I0514 12:55:59.122792  6268 net.cpp:106] Creating Layer accuracy
I0514 12:55:59.122802  6268 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0514 12:55:59.122813  6268 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0514 12:55:59.122828  6268 net.cpp:411] accuracy -> accuracy
I0514 12:55:59.122853  6268 net.cpp:150] Setting up accuracy
I0514 12:55:59.122865  6268 net.cpp:157] Top shape: (1)
I0514 12:55:59.122874  6268 net.cpp:165] Memory required for data: 157887604
I0514 12:55:59.122884  6268 layer_factory.hpp:77] Creating layer loss
I0514 12:55:59.122898  6268 net.cpp:106] Creating Layer loss
I0514 12:55:59.122910  6268 net.cpp:454] loss <- ip3_drop3_0_split_1
I0514 12:55:59.122920  6268 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0514 12:55:59.122934  6268 net.cpp:411] loss -> loss
I0514 12:55:59.122953  6268 layer_factory.hpp:77] Creating layer loss
I0514 12:55:59.123445  6268 net.cpp:150] Setting up loss
I0514 12:55:59.123459  6268 net.cpp:157] Top shape: (1)
I0514 12:55:59.123469  6268 net.cpp:160]     with loss weight 1
I0514 12:55:59.123489  6268 net.cpp:165] Memory required for data: 157887608
I0514 12:55:59.123500  6268 net.cpp:226] loss needs backward computation.
I0514 12:55:59.123512  6268 net.cpp:228] accuracy does not need backward computation.
I0514 12:55:59.123522  6268 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0514 12:55:59.123533  6268 net.cpp:226] drop3 needs backward computation.
I0514 12:55:59.123543  6268 net.cpp:226] ip3 needs backward computation.
I0514 12:55:59.123553  6268 net.cpp:226] drop2 needs backward computation.
I0514 12:55:59.123572  6268 net.cpp:226] relu6 needs backward computation.
I0514 12:55:59.123582  6268 net.cpp:226] ip2 needs backward computation.
I0514 12:55:59.123592  6268 net.cpp:226] drop1 needs backward computation.
I0514 12:55:59.123602  6268 net.cpp:226] relu5 needs backward computation.
I0514 12:55:59.123612  6268 net.cpp:226] ip1 needs backward computation.
I0514 12:55:59.123623  6268 net.cpp:226] pool4 needs backward computation.
I0514 12:55:59.123633  6268 net.cpp:226] relu4 needs backward computation.
I0514 12:55:59.123643  6268 net.cpp:226] conv4 needs backward computation.
I0514 12:55:59.123654  6268 net.cpp:226] pool3 needs backward computation.
I0514 12:55:59.123666  6268 net.cpp:226] relu3 needs backward computation.
I0514 12:55:59.123673  6268 net.cpp:226] conv3 needs backward computation.
I0514 12:55:59.123684  6268 net.cpp:226] pool2 needs backward computation.
I0514 12:55:59.123694  6268 net.cpp:226] relu2 needs backward computation.
I0514 12:55:59.123704  6268 net.cpp:226] conv2 needs backward computation.
I0514 12:55:59.123714  6268 net.cpp:226] pool1 needs backward computation.
I0514 12:55:59.123725  6268 net.cpp:226] relu1 needs backward computation.
I0514 12:55:59.123735  6268 net.cpp:226] conv1 needs backward computation.
I0514 12:55:59.123746  6268 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0514 12:55:59.123759  6268 net.cpp:228] data_hdf5 does not need backward computation.
I0514 12:55:59.123769  6268 net.cpp:270] This network produces output accuracy
I0514 12:55:59.123780  6268 net.cpp:270] This network produces output loss
I0514 12:55:59.123807  6268 net.cpp:283] Network initialization done.
I0514 12:55:59.123939  6268 solver.cpp:60] Solver scaffolding done.
I0514 12:55:59.125090  6268 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_3000.solverstate
I0514 12:55:59.176338  6268 sgd_solver.cpp:318] SGDSolver: restoring history
I0514 12:55:59.182039  6268 caffe.cpp:212] Starting Optimization
I0514 12:55:59.182086  6268 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0514 12:55:59.182096  6268 solver.cpp:289] Learning Rate Policy: fixed
I0514 12:55:59.183341  6268 solver.cpp:341] Iteration 3000, Testing net (#0)
I0514 12:56:47.029919  6268 solver.cpp:409]     Test net output #0: accuracy = 0.695192
I0514 12:56:47.030088  6268 solver.cpp:409]     Test net output #1: loss = 1.02799 (* 1 = 1.02799 loss)
I0514 12:56:47.063036  6268 solver.cpp:237] Iteration 3000, loss = 1.54004
I0514 12:56:47.063072  6268 solver.cpp:253]     Train net output #0: loss = 1.54004 (* 1 = 1.54004 loss)
I0514 12:56:47.063091  6268 sgd_solver.cpp:106] Iteration 3000, lr = 0.0025
I0514 12:57:16.085105  6268 solver.cpp:341] Iteration 3500, Testing net (#0)
I0514 12:58:03.002127  6268 solver.cpp:409]     Test net output #0: accuracy = 0.720173
I0514 12:58:03.002287  6268 solver.cpp:409]     Test net output #1: loss = 0.959959 (* 1 = 0.959959 loss)
I0514 12:58:03.020223  6268 solver.cpp:237] Iteration 3500, loss = 1.53734
I0514 12:58:03.020251  6268 solver.cpp:253]     Train net output #0: loss = 1.53734 (* 1 = 1.53734 loss)
I0514 12:58:03.020265  6268 sgd_solver.cpp:106] Iteration 3500, lr = 0.0025
I0514 12:58:32.101433  6268 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_4000.caffemodel
I0514 12:58:32.181262  6268 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_4000.solverstate
I0514 12:58:32.207695  6268 solver.cpp:341] Iteration 4000, Testing net (#0)
I0514 12:59:40.052371  6268 solver.cpp:409]     Test net output #0: accuracy = 0.745533
I0514 12:59:40.052539  6268 solver.cpp:409]     Test net output #1: loss = 0.854718 (* 1 = 0.854718 loss)
I0514 13:00:02.289352  6268 solver.cpp:237] Iteration 4000, loss = 1.67266
I0514 13:00:02.289409  6268 solver.cpp:253]     Train net output #0: loss = 1.67266 (* 1 = 1.67266 loss)
I0514 13:00:02.289425  6268 sgd_solver.cpp:106] Iteration 4000, lr = 0.0025
I0514 13:00:31.340699  6268 solver.cpp:341] Iteration 4500, Testing net (#0)
I0514 13:01:17.955685  6268 solver.cpp:409]     Test net output #0: accuracy = 0.767934
I0514 13:01:17.955845  6268 solver.cpp:409]     Test net output #1: loss = 0.889802 (* 1 = 0.889802 loss)
I0514 13:01:17.973630  6268 solver.cpp:237] Iteration 4500, loss = 1.52145
I0514 13:01:17.973659  6268 solver.cpp:253]     Train net output #0: loss = 1.52145 (* 1 = 1.52145 loss)
I0514 13:01:17.973672  6268 sgd_solver.cpp:106] Iteration 4500, lr = 0.0025
I0514 13:01:47.017128  6268 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_5000.caffemodel
I0514 13:01:47.101749  6268 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_5000.solverstate
I0514 13:01:47.129950  6268 solver.cpp:341] Iteration 5000, Testing net (#0)
I0514 13:02:54.977138  6268 solver.cpp:409]     Test net output #0: accuracy = 0.775901
I0514 13:02:54.977306  6268 solver.cpp:409]     Test net output #1: loss = 0.802665 (* 1 = 0.802665 loss)
I0514 13:03:17.227522  6268 solver.cpp:237] Iteration 5000, loss = 1.52344
I0514 13:03:17.227581  6268 solver.cpp:253]     Train net output #0: loss = 1.52344 (* 1 = 1.52344 loss)
I0514 13:03:17.227598  6268 sgd_solver.cpp:106] Iteration 5000, lr = 0.0025
I0514 13:03:46.288918  6268 solver.cpp:341] Iteration 5500, Testing net (#0)
I0514 13:04:33.249923  6268 solver.cpp:409]     Test net output #0: accuracy = 0.784881
I0514 13:04:33.250087  6268 solver.cpp:409]     Test net output #1: loss = 0.771324 (* 1 = 0.771324 loss)
I0514 13:04:33.267856  6268 solver.cpp:237] Iteration 5500, loss = 1.26274
I0514 13:04:33.267884  6268 solver.cpp:253]     Train net output #0: loss = 1.26274 (* 1 = 1.26274 loss)
I0514 13:04:33.267899  6268 sgd_solver.cpp:106] Iteration 5500, lr = 0.0025
I0514 13:05:02.336238  6268 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_6000.caffemodel
I0514 13:05:02.420783  6268 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_depend/dep_check_10min_2016-05-14T12.44.04.956355_iter_6000.solverstate
I0514 13:05:02.449002  6268 solver.cpp:341] Iteration 6000, Testing net (#0)
aprun: Apid 11199386: Caught signal Terminated, sending to application
*** Aborted at 1463245509 (unix time) try "date -d @1463245509" if you are using GNU date ***
PC: @     0x2aaab7f0d263 __GI_memcpy
*** SIGTERM (@0x1879) received by PID 6268 (TID 0x2aaac746f900) from PID 6265; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11199386: Caught signal Terminated, sending to application
    @     0x2aaab7f0d263 __GI_memcpy
=>> PBS: job killed: walltime 603 exceeded limit 600
aprun: Apid 11199386: Caught signal Terminated, sending to application
    @     0x2aaab144ca16 H5VM_memcpyvv
    @     0x2aaab12905af H5D__compact_readvv
    @     0x2aaab12a3143 H5D__select_io
aprun: Apid 11199386: Caught signal Terminated, sending to application
    @     0x2aaab12a38cd H5D__select_read
    @     0x2aaab128be3d H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11199386: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x5e364a caffe::hdf5_load_nd_dataset<>()
    @           0x5395de caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x61b493 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11199386: Caught signal Terminated, sending to application
    @           0x4a6872 caffe::Net<>::ForwardFromTo()
    @           0x4a6987 caffe::Net<>::ForwardPrefilled()
    @           0x59f48f caffe::Solver<>::Test()
    @           0x59fdde caffe::Solver<>::TestAll()
aprun: Apid 11199386: Caught signal Terminated, sending to application
    @           0x59ff21 caffe::Solver<>::Step()
    @           0x5a0ac5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11199386: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
aprun: Apid 11199386: Caught signal Terminated, sending to application
