2806286
I0521 05:20:05.414249  7203 caffe.cpp:184] Using GPUs 0
I0521 05:20:05.834326  7203 solver.cpp:48] Initializing solver from parameters: 
test_iter: 217
test_interval: 434
base_lr: 0.0025
display: 21
max_iter: 2173
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 217
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289.prototxt"
I0521 05:20:05.835985  7203 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289.prototxt
I0521 05:20:05.853965  7203 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 05:20:05.854025  7203 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 05:20:05.854369  7203 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 690
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 05:20:05.854547  7203 layer_factory.hpp:77] Creating layer data_hdf5
I0521 05:20:05.854575  7203 net.cpp:106] Creating Layer data_hdf5
I0521 05:20:05.854590  7203 net.cpp:411] data_hdf5 -> data
I0521 05:20:05.854624  7203 net.cpp:411] data_hdf5 -> label
I0521 05:20:05.854655  7203 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 05:20:05.855865  7203 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 05:20:05.858037  7203 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 05:20:27.343511  7203 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 05:20:27.348666  7203 net.cpp:150] Setting up data_hdf5
I0521 05:20:27.348707  7203 net.cpp:157] Top shape: 690 1 127 50 (4381500)
I0521 05:20:27.348721  7203 net.cpp:157] Top shape: 690 (690)
I0521 05:20:27.348733  7203 net.cpp:165] Memory required for data: 17528760
I0521 05:20:27.348747  7203 layer_factory.hpp:77] Creating layer conv1
I0521 05:20:27.348781  7203 net.cpp:106] Creating Layer conv1
I0521 05:20:27.348793  7203 net.cpp:454] conv1 <- data
I0521 05:20:27.348817  7203 net.cpp:411] conv1 -> conv1
I0521 05:20:27.711973  7203 net.cpp:150] Setting up conv1
I0521 05:20:27.712018  7203 net.cpp:157] Top shape: 690 12 120 48 (47692800)
I0521 05:20:27.712029  7203 net.cpp:165] Memory required for data: 208299960
I0521 05:20:27.712059  7203 layer_factory.hpp:77] Creating layer relu1
I0521 05:20:27.712080  7203 net.cpp:106] Creating Layer relu1
I0521 05:20:27.712090  7203 net.cpp:454] relu1 <- conv1
I0521 05:20:27.712105  7203 net.cpp:397] relu1 -> conv1 (in-place)
I0521 05:20:27.712620  7203 net.cpp:150] Setting up relu1
I0521 05:20:27.712636  7203 net.cpp:157] Top shape: 690 12 120 48 (47692800)
I0521 05:20:27.712647  7203 net.cpp:165] Memory required for data: 399071160
I0521 05:20:27.712657  7203 layer_factory.hpp:77] Creating layer pool1
I0521 05:20:27.712673  7203 net.cpp:106] Creating Layer pool1
I0521 05:20:27.712683  7203 net.cpp:454] pool1 <- conv1
I0521 05:20:27.712697  7203 net.cpp:411] pool1 -> pool1
I0521 05:20:27.712779  7203 net.cpp:150] Setting up pool1
I0521 05:20:27.712792  7203 net.cpp:157] Top shape: 690 12 60 48 (23846400)
I0521 05:20:27.712802  7203 net.cpp:165] Memory required for data: 494456760
I0521 05:20:27.712812  7203 layer_factory.hpp:77] Creating layer conv2
I0521 05:20:27.712836  7203 net.cpp:106] Creating Layer conv2
I0521 05:20:27.712846  7203 net.cpp:454] conv2 <- pool1
I0521 05:20:27.712859  7203 net.cpp:411] conv2 -> conv2
I0521 05:20:27.715559  7203 net.cpp:150] Setting up conv2
I0521 05:20:27.715586  7203 net.cpp:157] Top shape: 690 20 54 46 (34279200)
I0521 05:20:27.715597  7203 net.cpp:165] Memory required for data: 631573560
I0521 05:20:27.715616  7203 layer_factory.hpp:77] Creating layer relu2
I0521 05:20:27.715631  7203 net.cpp:106] Creating Layer relu2
I0521 05:20:27.715641  7203 net.cpp:454] relu2 <- conv2
I0521 05:20:27.715653  7203 net.cpp:397] relu2 -> conv2 (in-place)
I0521 05:20:27.715986  7203 net.cpp:150] Setting up relu2
I0521 05:20:27.715999  7203 net.cpp:157] Top shape: 690 20 54 46 (34279200)
I0521 05:20:27.716011  7203 net.cpp:165] Memory required for data: 768690360
I0521 05:20:27.716020  7203 layer_factory.hpp:77] Creating layer pool2
I0521 05:20:27.716033  7203 net.cpp:106] Creating Layer pool2
I0521 05:20:27.716043  7203 net.cpp:454] pool2 <- conv2
I0521 05:20:27.716068  7203 net.cpp:411] pool2 -> pool2
I0521 05:20:27.716137  7203 net.cpp:150] Setting up pool2
I0521 05:20:27.716150  7203 net.cpp:157] Top shape: 690 20 27 46 (17139600)
I0521 05:20:27.716161  7203 net.cpp:165] Memory required for data: 837248760
I0521 05:20:27.716171  7203 layer_factory.hpp:77] Creating layer conv3
I0521 05:20:27.716188  7203 net.cpp:106] Creating Layer conv3
I0521 05:20:27.716199  7203 net.cpp:454] conv3 <- pool2
I0521 05:20:27.716212  7203 net.cpp:411] conv3 -> conv3
I0521 05:20:27.718156  7203 net.cpp:150] Setting up conv3
I0521 05:20:27.718179  7203 net.cpp:157] Top shape: 690 28 22 44 (18701760)
I0521 05:20:27.718192  7203 net.cpp:165] Memory required for data: 912055800
I0521 05:20:27.718211  7203 layer_factory.hpp:77] Creating layer relu3
I0521 05:20:27.718227  7203 net.cpp:106] Creating Layer relu3
I0521 05:20:27.718237  7203 net.cpp:454] relu3 <- conv3
I0521 05:20:27.718250  7203 net.cpp:397] relu3 -> conv3 (in-place)
I0521 05:20:27.718720  7203 net.cpp:150] Setting up relu3
I0521 05:20:27.718737  7203 net.cpp:157] Top shape: 690 28 22 44 (18701760)
I0521 05:20:27.718747  7203 net.cpp:165] Memory required for data: 986862840
I0521 05:20:27.718757  7203 layer_factory.hpp:77] Creating layer pool3
I0521 05:20:27.718770  7203 net.cpp:106] Creating Layer pool3
I0521 05:20:27.718780  7203 net.cpp:454] pool3 <- conv3
I0521 05:20:27.718792  7203 net.cpp:411] pool3 -> pool3
I0521 05:20:27.718860  7203 net.cpp:150] Setting up pool3
I0521 05:20:27.718873  7203 net.cpp:157] Top shape: 690 28 11 44 (9350880)
I0521 05:20:27.718883  7203 net.cpp:165] Memory required for data: 1024266360
I0521 05:20:27.718894  7203 layer_factory.hpp:77] Creating layer conv4
I0521 05:20:27.718910  7203 net.cpp:106] Creating Layer conv4
I0521 05:20:27.718921  7203 net.cpp:454] conv4 <- pool3
I0521 05:20:27.718938  7203 net.cpp:411] conv4 -> conv4
I0521 05:20:27.721746  7203 net.cpp:150] Setting up conv4
I0521 05:20:27.721774  7203 net.cpp:157] Top shape: 690 36 6 42 (6259680)
I0521 05:20:27.721786  7203 net.cpp:165] Memory required for data: 1049305080
I0521 05:20:27.721801  7203 layer_factory.hpp:77] Creating layer relu4
I0521 05:20:27.721815  7203 net.cpp:106] Creating Layer relu4
I0521 05:20:27.721825  7203 net.cpp:454] relu4 <- conv4
I0521 05:20:27.721838  7203 net.cpp:397] relu4 -> conv4 (in-place)
I0521 05:20:27.722316  7203 net.cpp:150] Setting up relu4
I0521 05:20:27.722332  7203 net.cpp:157] Top shape: 690 36 6 42 (6259680)
I0521 05:20:27.722343  7203 net.cpp:165] Memory required for data: 1074343800
I0521 05:20:27.722353  7203 layer_factory.hpp:77] Creating layer pool4
I0521 05:20:27.722367  7203 net.cpp:106] Creating Layer pool4
I0521 05:20:27.722376  7203 net.cpp:454] pool4 <- conv4
I0521 05:20:27.722389  7203 net.cpp:411] pool4 -> pool4
I0521 05:20:27.722458  7203 net.cpp:150] Setting up pool4
I0521 05:20:27.722472  7203 net.cpp:157] Top shape: 690 36 3 42 (3129840)
I0521 05:20:27.722482  7203 net.cpp:165] Memory required for data: 1086863160
I0521 05:20:27.722492  7203 layer_factory.hpp:77] Creating layer ip1
I0521 05:20:27.722512  7203 net.cpp:106] Creating Layer ip1
I0521 05:20:27.722522  7203 net.cpp:454] ip1 <- pool4
I0521 05:20:27.722534  7203 net.cpp:411] ip1 -> ip1
I0521 05:20:27.738031  7203 net.cpp:150] Setting up ip1
I0521 05:20:27.738060  7203 net.cpp:157] Top shape: 690 196 (135240)
I0521 05:20:27.738075  7203 net.cpp:165] Memory required for data: 1087404120
I0521 05:20:27.738096  7203 layer_factory.hpp:77] Creating layer relu5
I0521 05:20:27.738111  7203 net.cpp:106] Creating Layer relu5
I0521 05:20:27.738121  7203 net.cpp:454] relu5 <- ip1
I0521 05:20:27.738135  7203 net.cpp:397] relu5 -> ip1 (in-place)
I0521 05:20:27.738476  7203 net.cpp:150] Setting up relu5
I0521 05:20:27.738489  7203 net.cpp:157] Top shape: 690 196 (135240)
I0521 05:20:27.738500  7203 net.cpp:165] Memory required for data: 1087945080
I0521 05:20:27.738510  7203 layer_factory.hpp:77] Creating layer drop1
I0521 05:20:27.738531  7203 net.cpp:106] Creating Layer drop1
I0521 05:20:27.738541  7203 net.cpp:454] drop1 <- ip1
I0521 05:20:27.738566  7203 net.cpp:397] drop1 -> ip1 (in-place)
I0521 05:20:27.738612  7203 net.cpp:150] Setting up drop1
I0521 05:20:27.738626  7203 net.cpp:157] Top shape: 690 196 (135240)
I0521 05:20:27.738636  7203 net.cpp:165] Memory required for data: 1088486040
I0521 05:20:27.738646  7203 layer_factory.hpp:77] Creating layer ip2
I0521 05:20:27.738664  7203 net.cpp:106] Creating Layer ip2
I0521 05:20:27.738674  7203 net.cpp:454] ip2 <- ip1
I0521 05:20:27.738687  7203 net.cpp:411] ip2 -> ip2
I0521 05:20:27.739151  7203 net.cpp:150] Setting up ip2
I0521 05:20:27.739164  7203 net.cpp:157] Top shape: 690 98 (67620)
I0521 05:20:27.739174  7203 net.cpp:165] Memory required for data: 1088756520
I0521 05:20:27.739189  7203 layer_factory.hpp:77] Creating layer relu6
I0521 05:20:27.739202  7203 net.cpp:106] Creating Layer relu6
I0521 05:20:27.739212  7203 net.cpp:454] relu6 <- ip2
I0521 05:20:27.739223  7203 net.cpp:397] relu6 -> ip2 (in-place)
I0521 05:20:27.739744  7203 net.cpp:150] Setting up relu6
I0521 05:20:27.739760  7203 net.cpp:157] Top shape: 690 98 (67620)
I0521 05:20:27.739771  7203 net.cpp:165] Memory required for data: 1089027000
I0521 05:20:27.739781  7203 layer_factory.hpp:77] Creating layer drop2
I0521 05:20:27.739794  7203 net.cpp:106] Creating Layer drop2
I0521 05:20:27.739804  7203 net.cpp:454] drop2 <- ip2
I0521 05:20:27.739816  7203 net.cpp:397] drop2 -> ip2 (in-place)
I0521 05:20:27.739858  7203 net.cpp:150] Setting up drop2
I0521 05:20:27.739871  7203 net.cpp:157] Top shape: 690 98 (67620)
I0521 05:20:27.739881  7203 net.cpp:165] Memory required for data: 1089297480
I0521 05:20:27.739892  7203 layer_factory.hpp:77] Creating layer ip3
I0521 05:20:27.739905  7203 net.cpp:106] Creating Layer ip3
I0521 05:20:27.739915  7203 net.cpp:454] ip3 <- ip2
I0521 05:20:27.739928  7203 net.cpp:411] ip3 -> ip3
I0521 05:20:27.740139  7203 net.cpp:150] Setting up ip3
I0521 05:20:27.740151  7203 net.cpp:157] Top shape: 690 11 (7590)
I0521 05:20:27.740161  7203 net.cpp:165] Memory required for data: 1089327840
I0521 05:20:27.740176  7203 layer_factory.hpp:77] Creating layer drop3
I0521 05:20:27.740190  7203 net.cpp:106] Creating Layer drop3
I0521 05:20:27.740200  7203 net.cpp:454] drop3 <- ip3
I0521 05:20:27.740211  7203 net.cpp:397] drop3 -> ip3 (in-place)
I0521 05:20:27.740250  7203 net.cpp:150] Setting up drop3
I0521 05:20:27.740262  7203 net.cpp:157] Top shape: 690 11 (7590)
I0521 05:20:27.740273  7203 net.cpp:165] Memory required for data: 1089358200
I0521 05:20:27.740283  7203 layer_factory.hpp:77] Creating layer loss
I0521 05:20:27.740301  7203 net.cpp:106] Creating Layer loss
I0521 05:20:27.740311  7203 net.cpp:454] loss <- ip3
I0521 05:20:27.740322  7203 net.cpp:454] loss <- label
I0521 05:20:27.740335  7203 net.cpp:411] loss -> loss
I0521 05:20:27.740353  7203 layer_factory.hpp:77] Creating layer loss
I0521 05:20:27.741000  7203 net.cpp:150] Setting up loss
I0521 05:20:27.741020  7203 net.cpp:157] Top shape: (1)
I0521 05:20:27.741034  7203 net.cpp:160]     with loss weight 1
I0521 05:20:27.741083  7203 net.cpp:165] Memory required for data: 1089358204
I0521 05:20:27.741094  7203 net.cpp:226] loss needs backward computation.
I0521 05:20:27.741106  7203 net.cpp:226] drop3 needs backward computation.
I0521 05:20:27.741116  7203 net.cpp:226] ip3 needs backward computation.
I0521 05:20:27.741127  7203 net.cpp:226] drop2 needs backward computation.
I0521 05:20:27.741135  7203 net.cpp:226] relu6 needs backward computation.
I0521 05:20:27.741145  7203 net.cpp:226] ip2 needs backward computation.
I0521 05:20:27.741156  7203 net.cpp:226] drop1 needs backward computation.
I0521 05:20:27.741165  7203 net.cpp:226] relu5 needs backward computation.
I0521 05:20:27.741175  7203 net.cpp:226] ip1 needs backward computation.
I0521 05:20:27.741185  7203 net.cpp:226] pool4 needs backward computation.
I0521 05:20:27.741196  7203 net.cpp:226] relu4 needs backward computation.
I0521 05:20:27.741205  7203 net.cpp:226] conv4 needs backward computation.
I0521 05:20:27.741216  7203 net.cpp:226] pool3 needs backward computation.
I0521 05:20:27.741235  7203 net.cpp:226] relu3 needs backward computation.
I0521 05:20:27.741246  7203 net.cpp:226] conv3 needs backward computation.
I0521 05:20:27.741257  7203 net.cpp:226] pool2 needs backward computation.
I0521 05:20:27.741268  7203 net.cpp:226] relu2 needs backward computation.
I0521 05:20:27.741278  7203 net.cpp:226] conv2 needs backward computation.
I0521 05:20:27.741289  7203 net.cpp:226] pool1 needs backward computation.
I0521 05:20:27.741297  7203 net.cpp:226] relu1 needs backward computation.
I0521 05:20:27.741307  7203 net.cpp:226] conv1 needs backward computation.
I0521 05:20:27.741318  7203 net.cpp:228] data_hdf5 does not need backward computation.
I0521 05:20:27.741328  7203 net.cpp:270] This network produces output loss
I0521 05:20:27.741351  7203 net.cpp:283] Network initialization done.
I0521 05:20:27.742959  7203 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289.prototxt
I0521 05:20:27.743031  7203 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 05:20:27.743386  7203 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 690
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 05:20:27.743573  7203 layer_factory.hpp:77] Creating layer data_hdf5
I0521 05:20:27.743589  7203 net.cpp:106] Creating Layer data_hdf5
I0521 05:20:27.743602  7203 net.cpp:411] data_hdf5 -> data
I0521 05:20:27.743618  7203 net.cpp:411] data_hdf5 -> label
I0521 05:20:27.743633  7203 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 05:20:27.744868  7203 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 05:20:49.080727  7203 net.cpp:150] Setting up data_hdf5
I0521 05:20:49.080893  7203 net.cpp:157] Top shape: 690 1 127 50 (4381500)
I0521 05:20:49.080907  7203 net.cpp:157] Top shape: 690 (690)
I0521 05:20:49.080919  7203 net.cpp:165] Memory required for data: 17528760
I0521 05:20:49.080932  7203 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 05:20:49.080960  7203 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 05:20:49.080971  7203 net.cpp:454] label_data_hdf5_1_split <- label
I0521 05:20:49.080986  7203 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 05:20:49.081007  7203 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 05:20:49.081091  7203 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 05:20:49.081105  7203 net.cpp:157] Top shape: 690 (690)
I0521 05:20:49.081117  7203 net.cpp:157] Top shape: 690 (690)
I0521 05:20:49.081126  7203 net.cpp:165] Memory required for data: 17534280
I0521 05:20:49.081136  7203 layer_factory.hpp:77] Creating layer conv1
I0521 05:20:49.081156  7203 net.cpp:106] Creating Layer conv1
I0521 05:20:49.081167  7203 net.cpp:454] conv1 <- data
I0521 05:20:49.081182  7203 net.cpp:411] conv1 -> conv1
I0521 05:20:49.083148  7203 net.cpp:150] Setting up conv1
I0521 05:20:49.083166  7203 net.cpp:157] Top shape: 690 12 120 48 (47692800)
I0521 05:20:49.083176  7203 net.cpp:165] Memory required for data: 208305480
I0521 05:20:49.083197  7203 layer_factory.hpp:77] Creating layer relu1
I0521 05:20:49.083212  7203 net.cpp:106] Creating Layer relu1
I0521 05:20:49.083222  7203 net.cpp:454] relu1 <- conv1
I0521 05:20:49.083236  7203 net.cpp:397] relu1 -> conv1 (in-place)
I0521 05:20:49.083732  7203 net.cpp:150] Setting up relu1
I0521 05:20:49.083748  7203 net.cpp:157] Top shape: 690 12 120 48 (47692800)
I0521 05:20:49.083760  7203 net.cpp:165] Memory required for data: 399076680
I0521 05:20:49.083770  7203 layer_factory.hpp:77] Creating layer pool1
I0521 05:20:49.083786  7203 net.cpp:106] Creating Layer pool1
I0521 05:20:49.083796  7203 net.cpp:454] pool1 <- conv1
I0521 05:20:49.083808  7203 net.cpp:411] pool1 -> pool1
I0521 05:20:49.083884  7203 net.cpp:150] Setting up pool1
I0521 05:20:49.083897  7203 net.cpp:157] Top shape: 690 12 60 48 (23846400)
I0521 05:20:49.083906  7203 net.cpp:165] Memory required for data: 494462280
I0521 05:20:49.083917  7203 layer_factory.hpp:77] Creating layer conv2
I0521 05:20:49.083935  7203 net.cpp:106] Creating Layer conv2
I0521 05:20:49.083945  7203 net.cpp:454] conv2 <- pool1
I0521 05:20:49.083959  7203 net.cpp:411] conv2 -> conv2
I0521 05:20:49.085885  7203 net.cpp:150] Setting up conv2
I0521 05:20:49.085906  7203 net.cpp:157] Top shape: 690 20 54 46 (34279200)
I0521 05:20:49.085919  7203 net.cpp:165] Memory required for data: 631579080
I0521 05:20:49.085937  7203 layer_factory.hpp:77] Creating layer relu2
I0521 05:20:49.085952  7203 net.cpp:106] Creating Layer relu2
I0521 05:20:49.085961  7203 net.cpp:454] relu2 <- conv2
I0521 05:20:49.085973  7203 net.cpp:397] relu2 -> conv2 (in-place)
I0521 05:20:49.086308  7203 net.cpp:150] Setting up relu2
I0521 05:20:49.086323  7203 net.cpp:157] Top shape: 690 20 54 46 (34279200)
I0521 05:20:49.086333  7203 net.cpp:165] Memory required for data: 768695880
I0521 05:20:49.086343  7203 layer_factory.hpp:77] Creating layer pool2
I0521 05:20:49.086356  7203 net.cpp:106] Creating Layer pool2
I0521 05:20:49.086366  7203 net.cpp:454] pool2 <- conv2
I0521 05:20:49.086379  7203 net.cpp:411] pool2 -> pool2
I0521 05:20:49.086449  7203 net.cpp:150] Setting up pool2
I0521 05:20:49.086463  7203 net.cpp:157] Top shape: 690 20 27 46 (17139600)
I0521 05:20:49.086473  7203 net.cpp:165] Memory required for data: 837254280
I0521 05:20:49.086483  7203 layer_factory.hpp:77] Creating layer conv3
I0521 05:20:49.086501  7203 net.cpp:106] Creating Layer conv3
I0521 05:20:49.086511  7203 net.cpp:454] conv3 <- pool2
I0521 05:20:49.086525  7203 net.cpp:411] conv3 -> conv3
I0521 05:20:49.088500  7203 net.cpp:150] Setting up conv3
I0521 05:20:49.088522  7203 net.cpp:157] Top shape: 690 28 22 44 (18701760)
I0521 05:20:49.088533  7203 net.cpp:165] Memory required for data: 912061320
I0521 05:20:49.088565  7203 layer_factory.hpp:77] Creating layer relu3
I0521 05:20:49.088579  7203 net.cpp:106] Creating Layer relu3
I0521 05:20:49.088589  7203 net.cpp:454] relu3 <- conv3
I0521 05:20:49.088603  7203 net.cpp:397] relu3 -> conv3 (in-place)
I0521 05:20:49.089081  7203 net.cpp:150] Setting up relu3
I0521 05:20:49.089097  7203 net.cpp:157] Top shape: 690 28 22 44 (18701760)
I0521 05:20:49.089107  7203 net.cpp:165] Memory required for data: 986868360
I0521 05:20:49.089118  7203 layer_factory.hpp:77] Creating layer pool3
I0521 05:20:49.089130  7203 net.cpp:106] Creating Layer pool3
I0521 05:20:49.089140  7203 net.cpp:454] pool3 <- conv3
I0521 05:20:49.089154  7203 net.cpp:411] pool3 -> pool3
I0521 05:20:49.089226  7203 net.cpp:150] Setting up pool3
I0521 05:20:49.089239  7203 net.cpp:157] Top shape: 690 28 11 44 (9350880)
I0521 05:20:49.089249  7203 net.cpp:165] Memory required for data: 1024271880
I0521 05:20:49.089259  7203 layer_factory.hpp:77] Creating layer conv4
I0521 05:20:49.089277  7203 net.cpp:106] Creating Layer conv4
I0521 05:20:49.089287  7203 net.cpp:454] conv4 <- pool3
I0521 05:20:49.089301  7203 net.cpp:411] conv4 -> conv4
I0521 05:20:49.091353  7203 net.cpp:150] Setting up conv4
I0521 05:20:49.091370  7203 net.cpp:157] Top shape: 690 36 6 42 (6259680)
I0521 05:20:49.091383  7203 net.cpp:165] Memory required for data: 1049310600
I0521 05:20:49.091401  7203 layer_factory.hpp:77] Creating layer relu4
I0521 05:20:49.091414  7203 net.cpp:106] Creating Layer relu4
I0521 05:20:49.091424  7203 net.cpp:454] relu4 <- conv4
I0521 05:20:49.091437  7203 net.cpp:397] relu4 -> conv4 (in-place)
I0521 05:20:49.091907  7203 net.cpp:150] Setting up relu4
I0521 05:20:49.091922  7203 net.cpp:157] Top shape: 690 36 6 42 (6259680)
I0521 05:20:49.091933  7203 net.cpp:165] Memory required for data: 1074349320
I0521 05:20:49.091943  7203 layer_factory.hpp:77] Creating layer pool4
I0521 05:20:49.091955  7203 net.cpp:106] Creating Layer pool4
I0521 05:20:49.091965  7203 net.cpp:454] pool4 <- conv4
I0521 05:20:49.091979  7203 net.cpp:411] pool4 -> pool4
I0521 05:20:49.092051  7203 net.cpp:150] Setting up pool4
I0521 05:20:49.092064  7203 net.cpp:157] Top shape: 690 36 3 42 (3129840)
I0521 05:20:49.092074  7203 net.cpp:165] Memory required for data: 1086868680
I0521 05:20:49.092082  7203 layer_factory.hpp:77] Creating layer ip1
I0521 05:20:49.092097  7203 net.cpp:106] Creating Layer ip1
I0521 05:20:49.092108  7203 net.cpp:454] ip1 <- pool4
I0521 05:20:49.092121  7203 net.cpp:411] ip1 -> ip1
I0521 05:20:49.107607  7203 net.cpp:150] Setting up ip1
I0521 05:20:49.107635  7203 net.cpp:157] Top shape: 690 196 (135240)
I0521 05:20:49.107646  7203 net.cpp:165] Memory required for data: 1087409640
I0521 05:20:49.107669  7203 layer_factory.hpp:77] Creating layer relu5
I0521 05:20:49.107684  7203 net.cpp:106] Creating Layer relu5
I0521 05:20:49.107694  7203 net.cpp:454] relu5 <- ip1
I0521 05:20:49.107708  7203 net.cpp:397] relu5 -> ip1 (in-place)
I0521 05:20:49.108052  7203 net.cpp:150] Setting up relu5
I0521 05:20:49.108067  7203 net.cpp:157] Top shape: 690 196 (135240)
I0521 05:20:49.108077  7203 net.cpp:165] Memory required for data: 1087950600
I0521 05:20:49.108088  7203 layer_factory.hpp:77] Creating layer drop1
I0521 05:20:49.108106  7203 net.cpp:106] Creating Layer drop1
I0521 05:20:49.108116  7203 net.cpp:454] drop1 <- ip1
I0521 05:20:49.108129  7203 net.cpp:397] drop1 -> ip1 (in-place)
I0521 05:20:49.108172  7203 net.cpp:150] Setting up drop1
I0521 05:20:49.108186  7203 net.cpp:157] Top shape: 690 196 (135240)
I0521 05:20:49.108196  7203 net.cpp:165] Memory required for data: 1088491560
I0521 05:20:49.108204  7203 layer_factory.hpp:77] Creating layer ip2
I0521 05:20:49.108222  7203 net.cpp:106] Creating Layer ip2
I0521 05:20:49.108232  7203 net.cpp:454] ip2 <- ip1
I0521 05:20:49.108245  7203 net.cpp:411] ip2 -> ip2
I0521 05:20:49.108726  7203 net.cpp:150] Setting up ip2
I0521 05:20:49.108739  7203 net.cpp:157] Top shape: 690 98 (67620)
I0521 05:20:49.108749  7203 net.cpp:165] Memory required for data: 1088762040
I0521 05:20:49.108777  7203 layer_factory.hpp:77] Creating layer relu6
I0521 05:20:49.108790  7203 net.cpp:106] Creating Layer relu6
I0521 05:20:49.108800  7203 net.cpp:454] relu6 <- ip2
I0521 05:20:49.108814  7203 net.cpp:397] relu6 -> ip2 (in-place)
I0521 05:20:49.109356  7203 net.cpp:150] Setting up relu6
I0521 05:20:49.109377  7203 net.cpp:157] Top shape: 690 98 (67620)
I0521 05:20:49.109388  7203 net.cpp:165] Memory required for data: 1089032520
I0521 05:20:49.109398  7203 layer_factory.hpp:77] Creating layer drop2
I0521 05:20:49.109412  7203 net.cpp:106] Creating Layer drop2
I0521 05:20:49.109422  7203 net.cpp:454] drop2 <- ip2
I0521 05:20:49.109436  7203 net.cpp:397] drop2 -> ip2 (in-place)
I0521 05:20:49.109479  7203 net.cpp:150] Setting up drop2
I0521 05:20:49.109493  7203 net.cpp:157] Top shape: 690 98 (67620)
I0521 05:20:49.109504  7203 net.cpp:165] Memory required for data: 1089303000
I0521 05:20:49.109515  7203 layer_factory.hpp:77] Creating layer ip3
I0521 05:20:49.109530  7203 net.cpp:106] Creating Layer ip3
I0521 05:20:49.109539  7203 net.cpp:454] ip3 <- ip2
I0521 05:20:49.109554  7203 net.cpp:411] ip3 -> ip3
I0521 05:20:49.109776  7203 net.cpp:150] Setting up ip3
I0521 05:20:49.109788  7203 net.cpp:157] Top shape: 690 11 (7590)
I0521 05:20:49.109798  7203 net.cpp:165] Memory required for data: 1089333360
I0521 05:20:49.109813  7203 layer_factory.hpp:77] Creating layer drop3
I0521 05:20:49.109827  7203 net.cpp:106] Creating Layer drop3
I0521 05:20:49.109836  7203 net.cpp:454] drop3 <- ip3
I0521 05:20:49.109849  7203 net.cpp:397] drop3 -> ip3 (in-place)
I0521 05:20:49.109890  7203 net.cpp:150] Setting up drop3
I0521 05:20:49.109902  7203 net.cpp:157] Top shape: 690 11 (7590)
I0521 05:20:49.109912  7203 net.cpp:165] Memory required for data: 1089363720
I0521 05:20:49.109922  7203 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 05:20:49.109935  7203 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 05:20:49.109946  7203 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 05:20:49.109957  7203 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 05:20:49.109973  7203 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 05:20:49.110045  7203 net.cpp:150] Setting up ip3_drop3_0_split
I0521 05:20:49.110059  7203 net.cpp:157] Top shape: 690 11 (7590)
I0521 05:20:49.110071  7203 net.cpp:157] Top shape: 690 11 (7590)
I0521 05:20:49.110081  7203 net.cpp:165] Memory required for data: 1089424440
I0521 05:20:49.110090  7203 layer_factory.hpp:77] Creating layer accuracy
I0521 05:20:49.110112  7203 net.cpp:106] Creating Layer accuracy
I0521 05:20:49.110123  7203 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 05:20:49.110134  7203 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 05:20:49.110148  7203 net.cpp:411] accuracy -> accuracy
I0521 05:20:49.110172  7203 net.cpp:150] Setting up accuracy
I0521 05:20:49.110185  7203 net.cpp:157] Top shape: (1)
I0521 05:20:49.110194  7203 net.cpp:165] Memory required for data: 1089424444
I0521 05:20:49.110205  7203 layer_factory.hpp:77] Creating layer loss
I0521 05:20:49.110219  7203 net.cpp:106] Creating Layer loss
I0521 05:20:49.110229  7203 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 05:20:49.110239  7203 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 05:20:49.110252  7203 net.cpp:411] loss -> loss
I0521 05:20:49.110270  7203 layer_factory.hpp:77] Creating layer loss
I0521 05:20:49.110764  7203 net.cpp:150] Setting up loss
I0521 05:20:49.110779  7203 net.cpp:157] Top shape: (1)
I0521 05:20:49.110787  7203 net.cpp:160]     with loss weight 1
I0521 05:20:49.110806  7203 net.cpp:165] Memory required for data: 1089424448
I0521 05:20:49.110817  7203 net.cpp:226] loss needs backward computation.
I0521 05:20:49.110828  7203 net.cpp:228] accuracy does not need backward computation.
I0521 05:20:49.110839  7203 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 05:20:49.110849  7203 net.cpp:226] drop3 needs backward computation.
I0521 05:20:49.110860  7203 net.cpp:226] ip3 needs backward computation.
I0521 05:20:49.110872  7203 net.cpp:226] drop2 needs backward computation.
I0521 05:20:49.110890  7203 net.cpp:226] relu6 needs backward computation.
I0521 05:20:49.110901  7203 net.cpp:226] ip2 needs backward computation.
I0521 05:20:49.110911  7203 net.cpp:226] drop1 needs backward computation.
I0521 05:20:49.110920  7203 net.cpp:226] relu5 needs backward computation.
I0521 05:20:49.110929  7203 net.cpp:226] ip1 needs backward computation.
I0521 05:20:49.110939  7203 net.cpp:226] pool4 needs backward computation.
I0521 05:20:49.110950  7203 net.cpp:226] relu4 needs backward computation.
I0521 05:20:49.110958  7203 net.cpp:226] conv4 needs backward computation.
I0521 05:20:49.110968  7203 net.cpp:226] pool3 needs backward computation.
I0521 05:20:49.110980  7203 net.cpp:226] relu3 needs backward computation.
I0521 05:20:49.110990  7203 net.cpp:226] conv3 needs backward computation.
I0521 05:20:49.110999  7203 net.cpp:226] pool2 needs backward computation.
I0521 05:20:49.111011  7203 net.cpp:226] relu2 needs backward computation.
I0521 05:20:49.111021  7203 net.cpp:226] conv2 needs backward computation.
I0521 05:20:49.111030  7203 net.cpp:226] pool1 needs backward computation.
I0521 05:20:49.111042  7203 net.cpp:226] relu1 needs backward computation.
I0521 05:20:49.111052  7203 net.cpp:226] conv1 needs backward computation.
I0521 05:20:49.111063  7203 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 05:20:49.111075  7203 net.cpp:228] data_hdf5 does not need backward computation.
I0521 05:20:49.111085  7203 net.cpp:270] This network produces output accuracy
I0521 05:20:49.111096  7203 net.cpp:270] This network produces output loss
I0521 05:20:49.111125  7203 net.cpp:283] Network initialization done.
I0521 05:20:49.111258  7203 solver.cpp:60] Solver scaffolding done.
I0521 05:20:49.112385  7203 caffe.cpp:212] Starting Optimization
I0521 05:20:49.112404  7203 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 05:20:49.112417  7203 solver.cpp:289] Learning Rate Policy: fixed
I0521 05:20:49.113651  7203 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 05:21:35.054960  7203 solver.cpp:409]     Test net output #0: accuracy = 0.130001
I0521 05:21:35.055121  7203 solver.cpp:409]     Test net output #1: loss = 2.39813 (* 1 = 2.39813 loss)
I0521 05:21:35.185200  7203 solver.cpp:237] Iteration 0, loss = 2.39764
I0521 05:21:35.185236  7203 solver.cpp:253]     Train net output #0: loss = 2.39764 (* 1 = 2.39764 loss)
I0521 05:21:35.185255  7203 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0521 05:21:42.982161  7203 solver.cpp:237] Iteration 21, loss = 2.3863
I0521 05:21:42.982197  7203 solver.cpp:253]     Train net output #0: loss = 2.3863 (* 1 = 2.3863 loss)
I0521 05:21:42.982213  7203 sgd_solver.cpp:106] Iteration 21, lr = 0.0025
I0521 05:21:50.777007  7203 solver.cpp:237] Iteration 42, loss = 2.37369
I0521 05:21:50.777041  7203 solver.cpp:253]     Train net output #0: loss = 2.37369 (* 1 = 2.37369 loss)
I0521 05:21:50.777066  7203 sgd_solver.cpp:106] Iteration 42, lr = 0.0025
I0521 05:21:58.573292  7203 solver.cpp:237] Iteration 63, loss = 2.35838
I0521 05:21:58.573324  7203 solver.cpp:253]     Train net output #0: loss = 2.35838 (* 1 = 2.35838 loss)
I0521 05:21:58.573341  7203 sgd_solver.cpp:106] Iteration 63, lr = 0.0025
I0521 05:22:06.370291  7203 solver.cpp:237] Iteration 84, loss = 2.33793
I0521 05:22:06.370434  7203 solver.cpp:253]     Train net output #0: loss = 2.33793 (* 1 = 2.33793 loss)
I0521 05:22:06.370447  7203 sgd_solver.cpp:106] Iteration 84, lr = 0.0025
I0521 05:22:14.166303  7203 solver.cpp:237] Iteration 105, loss = 2.33594
I0521 05:22:14.166344  7203 solver.cpp:253]     Train net output #0: loss = 2.33594 (* 1 = 2.33594 loss)
I0521 05:22:14.166363  7203 sgd_solver.cpp:106] Iteration 105, lr = 0.0025
I0521 05:22:21.959981  7203 solver.cpp:237] Iteration 126, loss = 2.32357
I0521 05:22:21.960013  7203 solver.cpp:253]     Train net output #0: loss = 2.32357 (* 1 = 2.32357 loss)
I0521 05:22:21.960031  7203 sgd_solver.cpp:106] Iteration 126, lr = 0.0025
I0521 05:22:51.875823  7203 solver.cpp:237] Iteration 147, loss = 2.32175
I0521 05:22:51.875994  7203 solver.cpp:253]     Train net output #0: loss = 2.32175 (* 1 = 2.32175 loss)
I0521 05:22:51.876008  7203 sgd_solver.cpp:106] Iteration 147, lr = 0.0025
I0521 05:22:59.673894  7203 solver.cpp:237] Iteration 168, loss = 2.30975
I0521 05:22:59.673928  7203 solver.cpp:253]     Train net output #0: loss = 2.30975 (* 1 = 2.30975 loss)
I0521 05:22:59.673944  7203 sgd_solver.cpp:106] Iteration 168, lr = 0.0025
I0521 05:23:07.465715  7203 solver.cpp:237] Iteration 189, loss = 2.31699
I0521 05:23:07.465750  7203 solver.cpp:253]     Train net output #0: loss = 2.31699 (* 1 = 2.31699 loss)
I0521 05:23:07.465772  7203 sgd_solver.cpp:106] Iteration 189, lr = 0.0025
I0521 05:23:15.258549  7203 solver.cpp:237] Iteration 210, loss = 2.30113
I0521 05:23:15.258581  7203 solver.cpp:253]     Train net output #0: loss = 2.30113 (* 1 = 2.30113 loss)
I0521 05:23:15.258599  7203 sgd_solver.cpp:106] Iteration 210, lr = 0.0025
I0521 05:23:17.484586  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_217.caffemodel
I0521 05:23:17.786217  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_217.solverstate
I0521 05:23:23.121650  7203 solver.cpp:237] Iteration 231, loss = 2.29326
I0521 05:23:23.121803  7203 solver.cpp:253]     Train net output #0: loss = 2.29326 (* 1 = 2.29326 loss)
I0521 05:23:23.121816  7203 sgd_solver.cpp:106] Iteration 231, lr = 0.0025
I0521 05:23:30.916481  7203 solver.cpp:237] Iteration 252, loss = 2.29785
I0521 05:23:30.916527  7203 solver.cpp:253]     Train net output #0: loss = 2.29785 (* 1 = 2.29785 loss)
I0521 05:23:30.916543  7203 sgd_solver.cpp:106] Iteration 252, lr = 0.0025
I0521 05:23:38.715900  7203 solver.cpp:237] Iteration 273, loss = 2.24127
I0521 05:23:38.715934  7203 solver.cpp:253]     Train net output #0: loss = 2.24127 (* 1 = 2.24127 loss)
I0521 05:23:38.715950  7203 sgd_solver.cpp:106] Iteration 273, lr = 0.0025
I0521 05:24:08.602563  7203 solver.cpp:237] Iteration 294, loss = 2.20902
I0521 05:24:08.602717  7203 solver.cpp:253]     Train net output #0: loss = 2.20902 (* 1 = 2.20902 loss)
I0521 05:24:08.602732  7203 sgd_solver.cpp:106] Iteration 294, lr = 0.0025
I0521 05:24:16.403511  7203 solver.cpp:237] Iteration 315, loss = 2.19786
I0521 05:24:16.403548  7203 solver.cpp:253]     Train net output #0: loss = 2.19786 (* 1 = 2.19786 loss)
I0521 05:24:16.403566  7203 sgd_solver.cpp:106] Iteration 315, lr = 0.0025
I0521 05:24:24.197298  7203 solver.cpp:237] Iteration 336, loss = 2.16725
I0521 05:24:24.197331  7203 solver.cpp:253]     Train net output #0: loss = 2.16725 (* 1 = 2.16725 loss)
I0521 05:24:24.197347  7203 sgd_solver.cpp:106] Iteration 336, lr = 0.0025
I0521 05:24:31.999639  7203 solver.cpp:237] Iteration 357, loss = 2.13848
I0521 05:24:31.999672  7203 solver.cpp:253]     Train net output #0: loss = 2.13848 (* 1 = 2.13848 loss)
I0521 05:24:31.999688  7203 sgd_solver.cpp:106] Iteration 357, lr = 0.0025
I0521 05:24:39.798360  7203 solver.cpp:237] Iteration 378, loss = 2.06299
I0521 05:24:39.798512  7203 solver.cpp:253]     Train net output #0: loss = 2.06299 (* 1 = 2.06299 loss)
I0521 05:24:39.798527  7203 sgd_solver.cpp:106] Iteration 378, lr = 0.0025
I0521 05:24:47.598446  7203 solver.cpp:237] Iteration 399, loss = 2.07323
I0521 05:24:47.598480  7203 solver.cpp:253]     Train net output #0: loss = 2.07323 (* 1 = 2.07323 loss)
I0521 05:24:47.598501  7203 sgd_solver.cpp:106] Iteration 399, lr = 0.0025
I0521 05:24:55.396311  7203 solver.cpp:237] Iteration 420, loss = 2.07604
I0521 05:24:55.396343  7203 solver.cpp:253]     Train net output #0: loss = 2.07604 (* 1 = 2.07604 loss)
I0521 05:24:55.396360  7203 sgd_solver.cpp:106] Iteration 420, lr = 0.0025
I0521 05:25:00.226620  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_434.caffemodel
I0521 05:25:00.526937  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_434.solverstate
I0521 05:25:00.552122  7203 solver.cpp:341] Iteration 434, Testing net (#0)
I0521 05:25:45.525593  7203 solver.cpp:409]     Test net output #0: accuracy = 0.508776
I0521 05:25:45.525749  7203 solver.cpp:409]     Test net output #1: loss = 1.80691 (* 1 = 1.80691 loss)
I0521 05:26:10.388331  7203 solver.cpp:237] Iteration 441, loss = 2.02253
I0521 05:26:10.388381  7203 solver.cpp:253]     Train net output #0: loss = 2.02253 (* 1 = 2.02253 loss)
I0521 05:26:10.388397  7203 sgd_solver.cpp:106] Iteration 441, lr = 0.0025
I0521 05:26:18.180059  7203 solver.cpp:237] Iteration 462, loss = 2.01876
I0521 05:26:18.180214  7203 solver.cpp:253]     Train net output #0: loss = 2.01876 (* 1 = 2.01876 loss)
I0521 05:26:18.180230  7203 sgd_solver.cpp:106] Iteration 462, lr = 0.0025
I0521 05:26:25.974716  7203 solver.cpp:237] Iteration 483, loss = 1.98323
I0521 05:26:25.974747  7203 solver.cpp:253]     Train net output #0: loss = 1.98323 (* 1 = 1.98323 loss)
I0521 05:26:25.974766  7203 sgd_solver.cpp:106] Iteration 483, lr = 0.0025
I0521 05:26:33.763953  7203 solver.cpp:237] Iteration 504, loss = 1.98435
I0521 05:26:33.763985  7203 solver.cpp:253]     Train net output #0: loss = 1.98435 (* 1 = 1.98435 loss)
I0521 05:26:33.764003  7203 sgd_solver.cpp:106] Iteration 504, lr = 0.0025
I0521 05:26:41.556396  7203 solver.cpp:237] Iteration 525, loss = 1.94596
I0521 05:26:41.556428  7203 solver.cpp:253]     Train net output #0: loss = 1.94596 (* 1 = 1.94596 loss)
I0521 05:26:41.556442  7203 sgd_solver.cpp:106] Iteration 525, lr = 0.0025
I0521 05:26:49.344758  7203 solver.cpp:237] Iteration 546, loss = 1.98053
I0521 05:26:49.344893  7203 solver.cpp:253]     Train net output #0: loss = 1.98053 (* 1 = 1.98053 loss)
I0521 05:26:49.344907  7203 sgd_solver.cpp:106] Iteration 546, lr = 0.0025
I0521 05:26:57.137585  7203 solver.cpp:237] Iteration 567, loss = 1.90764
I0521 05:26:57.137617  7203 solver.cpp:253]     Train net output #0: loss = 1.90764 (* 1 = 1.90764 loss)
I0521 05:26:57.137635  7203 sgd_solver.cpp:106] Iteration 567, lr = 0.0025
I0521 05:27:27.104210  7203 solver.cpp:237] Iteration 588, loss = 1.88975
I0521 05:27:27.104385  7203 solver.cpp:253]     Train net output #0: loss = 1.88975 (* 1 = 1.88975 loss)
I0521 05:27:27.104400  7203 sgd_solver.cpp:106] Iteration 588, lr = 0.0025
I0521 05:27:34.891669  7203 solver.cpp:237] Iteration 609, loss = 1.90953
I0521 05:27:34.891701  7203 solver.cpp:253]     Train net output #0: loss = 1.90953 (* 1 = 1.90953 loss)
I0521 05:27:34.891718  7203 sgd_solver.cpp:106] Iteration 609, lr = 0.0025
I0521 05:27:42.678573  7203 solver.cpp:237] Iteration 630, loss = 1.87528
I0521 05:27:42.678602  7203 solver.cpp:253]     Train net output #0: loss = 1.87528 (* 1 = 1.87528 loss)
I0521 05:27:42.678625  7203 sgd_solver.cpp:106] Iteration 630, lr = 0.0025
I0521 05:27:50.099249  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_651.caffemodel
I0521 05:27:50.400413  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_651.solverstate
I0521 05:27:50.538341  7203 solver.cpp:237] Iteration 651, loss = 1.8529
I0521 05:27:50.538390  7203 solver.cpp:253]     Train net output #0: loss = 1.8529 (* 1 = 1.8529 loss)
I0521 05:27:50.538406  7203 sgd_solver.cpp:106] Iteration 651, lr = 0.0025
I0521 05:27:58.329671  7203 solver.cpp:237] Iteration 672, loss = 1.86589
I0521 05:27:58.329823  7203 solver.cpp:253]     Train net output #0: loss = 1.86589 (* 1 = 1.86589 loss)
I0521 05:27:58.329838  7203 sgd_solver.cpp:106] Iteration 672, lr = 0.0025
I0521 05:28:06.126040  7203 solver.cpp:237] Iteration 693, loss = 1.8528
I0521 05:28:06.126080  7203 solver.cpp:253]     Train net output #0: loss = 1.8528 (* 1 = 1.8528 loss)
I0521 05:28:06.126101  7203 sgd_solver.cpp:106] Iteration 693, lr = 0.0025
I0521 05:28:13.916761  7203 solver.cpp:237] Iteration 714, loss = 1.81746
I0521 05:28:13.916795  7203 solver.cpp:253]     Train net output #0: loss = 1.81746 (* 1 = 1.81746 loss)
I0521 05:28:13.916811  7203 sgd_solver.cpp:106] Iteration 714, lr = 0.0025
I0521 05:28:43.893343  7203 solver.cpp:237] Iteration 735, loss = 1.87807
I0521 05:28:43.893492  7203 solver.cpp:253]     Train net output #0: loss = 1.87807 (* 1 = 1.87807 loss)
I0521 05:28:43.893507  7203 sgd_solver.cpp:106] Iteration 735, lr = 0.0025
I0521 05:28:51.683774  7203 solver.cpp:237] Iteration 756, loss = 1.82916
I0521 05:28:51.683818  7203 solver.cpp:253]     Train net output #0: loss = 1.82916 (* 1 = 1.82916 loss)
I0521 05:28:51.683836  7203 sgd_solver.cpp:106] Iteration 756, lr = 0.0025
I0521 05:28:59.477272  7203 solver.cpp:237] Iteration 777, loss = 1.91507
I0521 05:28:59.477308  7203 solver.cpp:253]     Train net output #0: loss = 1.91507 (* 1 = 1.91507 loss)
I0521 05:28:59.477320  7203 sgd_solver.cpp:106] Iteration 777, lr = 0.0025
I0521 05:29:07.270076  7203 solver.cpp:237] Iteration 798, loss = 1.86716
I0521 05:29:07.270110  7203 solver.cpp:253]     Train net output #0: loss = 1.86716 (* 1 = 1.86716 loss)
I0521 05:29:07.270123  7203 sgd_solver.cpp:106] Iteration 798, lr = 0.0025
I0521 05:29:15.064502  7203 solver.cpp:237] Iteration 819, loss = 1.81999
I0521 05:29:15.064654  7203 solver.cpp:253]     Train net output #0: loss = 1.81999 (* 1 = 1.81999 loss)
I0521 05:29:15.064669  7203 sgd_solver.cpp:106] Iteration 819, lr = 0.0025
I0521 05:29:22.855741  7203 solver.cpp:237] Iteration 840, loss = 1.90124
I0521 05:29:22.855773  7203 solver.cpp:253]     Train net output #0: loss = 1.90124 (* 1 = 1.90124 loss)
I0521 05:29:22.855792  7203 sgd_solver.cpp:106] Iteration 840, lr = 0.0025
I0521 05:29:30.649772  7203 solver.cpp:237] Iteration 861, loss = 1.79312
I0521 05:29:30.649806  7203 solver.cpp:253]     Train net output #0: loss = 1.79312 (* 1 = 1.79312 loss)
I0521 05:29:30.649821  7203 sgd_solver.cpp:106] Iteration 861, lr = 0.0025
I0521 05:29:32.876109  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_868.caffemodel
I0521 05:29:33.177472  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_868.solverstate
I0521 05:29:33.204571  7203 solver.cpp:341] Iteration 868, Testing net (#0)
I0521 05:30:39.095944  7203 solver.cpp:409]     Test net output #0: accuracy = 0.621185
I0521 05:30:39.096113  7203 solver.cpp:409]     Test net output #1: loss = 1.36902 (* 1 = 1.36902 loss)
I0521 05:31:06.547479  7203 solver.cpp:237] Iteration 882, loss = 1.89731
I0521 05:31:06.547528  7203 solver.cpp:253]     Train net output #0: loss = 1.89731 (* 1 = 1.89731 loss)
I0521 05:31:06.547544  7203 sgd_solver.cpp:106] Iteration 882, lr = 0.0025
I0521 05:31:14.331365  7203 solver.cpp:237] Iteration 903, loss = 1.82823
I0521 05:31:14.331512  7203 solver.cpp:253]     Train net output #0: loss = 1.82823 (* 1 = 1.82823 loss)
I0521 05:31:14.331526  7203 sgd_solver.cpp:106] Iteration 903, lr = 0.0025
I0521 05:31:22.119045  7203 solver.cpp:237] Iteration 924, loss = 1.82665
I0521 05:31:22.119076  7203 solver.cpp:253]     Train net output #0: loss = 1.82665 (* 1 = 1.82665 loss)
I0521 05:31:22.119102  7203 sgd_solver.cpp:106] Iteration 924, lr = 0.0025
I0521 05:31:29.907058  7203 solver.cpp:237] Iteration 945, loss = 1.79883
I0521 05:31:29.907091  7203 solver.cpp:253]     Train net output #0: loss = 1.79883 (* 1 = 1.79883 loss)
I0521 05:31:29.907107  7203 sgd_solver.cpp:106] Iteration 945, lr = 0.0025
I0521 05:31:37.690572  7203 solver.cpp:237] Iteration 966, loss = 1.79571
I0521 05:31:37.690603  7203 solver.cpp:253]     Train net output #0: loss = 1.79571 (* 1 = 1.79571 loss)
I0521 05:31:37.690619  7203 sgd_solver.cpp:106] Iteration 966, lr = 0.0025
I0521 05:31:45.478976  7203 solver.cpp:237] Iteration 987, loss = 1.83338
I0521 05:31:45.479113  7203 solver.cpp:253]     Train net output #0: loss = 1.83338 (* 1 = 1.83338 loss)
I0521 05:31:45.479126  7203 sgd_solver.cpp:106] Iteration 987, lr = 0.0025
I0521 05:31:53.262390  7203 solver.cpp:237] Iteration 1008, loss = 1.77795
I0521 05:31:53.262421  7203 solver.cpp:253]     Train net output #0: loss = 1.77795 (* 1 = 1.77795 loss)
I0521 05:31:53.262439  7203 sgd_solver.cpp:106] Iteration 1008, lr = 0.0025
I0521 05:32:23.209007  7203 solver.cpp:237] Iteration 1029, loss = 1.76395
I0521 05:32:23.209174  7203 solver.cpp:253]     Train net output #0: loss = 1.76395 (* 1 = 1.76395 loss)
I0521 05:32:23.209189  7203 sgd_solver.cpp:106] Iteration 1029, lr = 0.0025
I0521 05:32:31.000272  7203 solver.cpp:237] Iteration 1050, loss = 1.79115
I0521 05:32:31.000306  7203 solver.cpp:253]     Train net output #0: loss = 1.79115 (* 1 = 1.79115 loss)
I0521 05:32:31.000319  7203 sgd_solver.cpp:106] Iteration 1050, lr = 0.0025
I0521 05:32:38.796314  7203 solver.cpp:237] Iteration 1071, loss = 1.81706
I0521 05:32:38.796353  7203 solver.cpp:253]     Train net output #0: loss = 1.81706 (* 1 = 1.81706 loss)
I0521 05:32:38.796372  7203 sgd_solver.cpp:106] Iteration 1071, lr = 0.0025
I0521 05:32:43.618026  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1085.caffemodel
I0521 05:32:43.918023  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1085.solverstate
I0521 05:32:46.652539  7203 solver.cpp:237] Iteration 1092, loss = 1.80741
I0521 05:32:46.652587  7203 solver.cpp:253]     Train net output #0: loss = 1.80741 (* 1 = 1.80741 loss)
I0521 05:32:46.652602  7203 sgd_solver.cpp:106] Iteration 1092, lr = 0.0025
I0521 05:32:54.440201  7203 solver.cpp:237] Iteration 1113, loss = 1.77027
I0521 05:32:54.440353  7203 solver.cpp:253]     Train net output #0: loss = 1.77027 (* 1 = 1.77027 loss)
I0521 05:32:54.440369  7203 sgd_solver.cpp:106] Iteration 1113, lr = 0.0025
I0521 05:33:02.232867  7203 solver.cpp:237] Iteration 1134, loss = 1.75951
I0521 05:33:02.232904  7203 solver.cpp:253]     Train net output #0: loss = 1.75951 (* 1 = 1.75951 loss)
I0521 05:33:02.232926  7203 sgd_solver.cpp:106] Iteration 1134, lr = 0.0025
I0521 05:33:10.021486  7203 solver.cpp:237] Iteration 1155, loss = 1.74803
I0521 05:33:10.021518  7203 solver.cpp:253]     Train net output #0: loss = 1.74803 (* 1 = 1.74803 loss)
I0521 05:33:10.021536  7203 sgd_solver.cpp:106] Iteration 1155, lr = 0.0025
I0521 05:33:39.993116  7203 solver.cpp:237] Iteration 1176, loss = 1.77447
I0521 05:33:39.993285  7203 solver.cpp:253]     Train net output #0: loss = 1.77447 (* 1 = 1.77447 loss)
I0521 05:33:39.993299  7203 sgd_solver.cpp:106] Iteration 1176, lr = 0.0025
I0521 05:33:47.779002  7203 solver.cpp:237] Iteration 1197, loss = 1.73594
I0521 05:33:47.779036  7203 solver.cpp:253]     Train net output #0: loss = 1.73594 (* 1 = 1.73594 loss)
I0521 05:33:47.779052  7203 sgd_solver.cpp:106] Iteration 1197, lr = 0.0025
I0521 05:33:55.565474  7203 solver.cpp:237] Iteration 1218, loss = 1.71859
I0521 05:33:55.565515  7203 solver.cpp:253]     Train net output #0: loss = 1.71859 (* 1 = 1.71859 loss)
I0521 05:33:55.565531  7203 sgd_solver.cpp:106] Iteration 1218, lr = 0.0025
I0521 05:34:03.345435  7203 solver.cpp:237] Iteration 1239, loss = 1.72775
I0521 05:34:03.345468  7203 solver.cpp:253]     Train net output #0: loss = 1.72775 (* 1 = 1.72775 loss)
I0521 05:34:03.345485  7203 sgd_solver.cpp:106] Iteration 1239, lr = 0.0025
I0521 05:34:11.129165  7203 solver.cpp:237] Iteration 1260, loss = 1.76685
I0521 05:34:11.129307  7203 solver.cpp:253]     Train net output #0: loss = 1.76685 (* 1 = 1.76685 loss)
I0521 05:34:11.129319  7203 sgd_solver.cpp:106] Iteration 1260, lr = 0.0025
I0521 05:34:18.911749  7203 solver.cpp:237] Iteration 1281, loss = 1.63794
I0521 05:34:18.911787  7203 solver.cpp:253]     Train net output #0: loss = 1.63794 (* 1 = 1.63794 loss)
I0521 05:34:18.911808  7203 sgd_solver.cpp:106] Iteration 1281, lr = 0.0025
I0521 05:34:26.331506  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1302.caffemodel
I0521 05:34:26.628962  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1302.solverstate
I0521 05:34:26.655145  7203 solver.cpp:341] Iteration 1302, Testing net (#0)
I0521 05:35:11.355010  7203 solver.cpp:409]     Test net output #0: accuracy = 0.655587
I0521 05:35:11.355173  7203 solver.cpp:409]     Test net output #1: loss = 1.28077 (* 1 = 1.28077 loss)
I0521 05:35:11.465361  7203 solver.cpp:237] Iteration 1302, loss = 1.73821
I0521 05:35:11.465390  7203 solver.cpp:253]     Train net output #0: loss = 1.73821 (* 1 = 1.73821 loss)
I0521 05:35:11.465407  7203 sgd_solver.cpp:106] Iteration 1302, lr = 0.0025
I0521 05:35:41.404884  7203 solver.cpp:237] Iteration 1323, loss = 1.72859
I0521 05:35:41.405043  7203 solver.cpp:253]     Train net output #0: loss = 1.72859 (* 1 = 1.72859 loss)
I0521 05:35:41.405063  7203 sgd_solver.cpp:106] Iteration 1323, lr = 0.0025
I0521 05:35:49.201241  7203 solver.cpp:237] Iteration 1344, loss = 1.71567
I0521 05:35:49.201272  7203 solver.cpp:253]     Train net output #0: loss = 1.71567 (* 1 = 1.71567 loss)
I0521 05:35:49.201290  7203 sgd_solver.cpp:106] Iteration 1344, lr = 0.0025
I0521 05:35:56.998795  7203 solver.cpp:237] Iteration 1365, loss = 1.71595
I0521 05:35:56.998826  7203 solver.cpp:253]     Train net output #0: loss = 1.71595 (* 1 = 1.71595 loss)
I0521 05:35:56.998847  7203 sgd_solver.cpp:106] Iteration 1365, lr = 0.0025
I0521 05:36:04.792879  7203 solver.cpp:237] Iteration 1386, loss = 1.69562
I0521 05:36:04.792912  7203 solver.cpp:253]     Train net output #0: loss = 1.69562 (* 1 = 1.69562 loss)
I0521 05:36:04.792927  7203 sgd_solver.cpp:106] Iteration 1386, lr = 0.0025
I0521 05:36:12.584267  7203 solver.cpp:237] Iteration 1407, loss = 1.77023
I0521 05:36:12.584414  7203 solver.cpp:253]     Train net output #0: loss = 1.77023 (* 1 = 1.77023 loss)
I0521 05:36:12.584429  7203 sgd_solver.cpp:106] Iteration 1407, lr = 0.0025
I0521 05:36:20.375310  7203 solver.cpp:237] Iteration 1428, loss = 1.72093
I0521 05:36:20.375346  7203 solver.cpp:253]     Train net output #0: loss = 1.72093 (* 1 = 1.72093 loss)
I0521 05:36:20.375363  7203 sgd_solver.cpp:106] Iteration 1428, lr = 0.0025
I0521 05:36:50.350456  7203 solver.cpp:237] Iteration 1449, loss = 1.77559
I0521 05:36:50.350625  7203 solver.cpp:253]     Train net output #0: loss = 1.77559 (* 1 = 1.77559 loss)
I0521 05:36:50.350639  7203 sgd_solver.cpp:106] Iteration 1449, lr = 0.0025
I0521 05:36:58.146118  7203 solver.cpp:237] Iteration 1470, loss = 1.73267
I0521 05:36:58.146152  7203 solver.cpp:253]     Train net output #0: loss = 1.73267 (* 1 = 1.73267 loss)
I0521 05:36:58.146167  7203 sgd_solver.cpp:106] Iteration 1470, lr = 0.0025
I0521 05:37:05.936476  7203 solver.cpp:237] Iteration 1491, loss = 1.77005
I0521 05:37:05.936511  7203 solver.cpp:253]     Train net output #0: loss = 1.77005 (* 1 = 1.77005 loss)
I0521 05:37:05.936524  7203 sgd_solver.cpp:106] Iteration 1491, lr = 0.0025
I0521 05:37:13.726168  7203 solver.cpp:237] Iteration 1512, loss = 1.76124
I0521 05:37:13.726200  7203 solver.cpp:253]     Train net output #0: loss = 1.76124 (* 1 = 1.76124 loss)
I0521 05:37:13.726212  7203 sgd_solver.cpp:106] Iteration 1512, lr = 0.0025
I0521 05:37:15.953619  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1519.caffemodel
I0521 05:37:16.252725  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1519.solverstate
I0521 05:37:21.587707  7203 solver.cpp:237] Iteration 1533, loss = 1.69896
I0521 05:37:21.587865  7203 solver.cpp:253]     Train net output #0: loss = 1.69896 (* 1 = 1.69896 loss)
I0521 05:37:21.587879  7203 sgd_solver.cpp:106] Iteration 1533, lr = 0.0025
I0521 05:37:29.379963  7203 solver.cpp:237] Iteration 1554, loss = 1.69635
I0521 05:37:29.379997  7203 solver.cpp:253]     Train net output #0: loss = 1.69635 (* 1 = 1.69635 loss)
I0521 05:37:29.380012  7203 sgd_solver.cpp:106] Iteration 1554, lr = 0.0025
I0521 05:37:37.175149  7203 solver.cpp:237] Iteration 1575, loss = 1.77861
I0521 05:37:37.175180  7203 solver.cpp:253]     Train net output #0: loss = 1.77861 (* 1 = 1.77861 loss)
I0521 05:37:37.175194  7203 sgd_solver.cpp:106] Iteration 1575, lr = 0.0025
I0521 05:38:07.167733  7203 solver.cpp:237] Iteration 1596, loss = 1.68149
I0521 05:38:07.167901  7203 solver.cpp:253]     Train net output #0: loss = 1.68149 (* 1 = 1.68149 loss)
I0521 05:38:07.167914  7203 sgd_solver.cpp:106] Iteration 1596, lr = 0.0025
I0521 05:38:14.959116  7203 solver.cpp:237] Iteration 1617, loss = 1.68897
I0521 05:38:14.959148  7203 solver.cpp:253]     Train net output #0: loss = 1.68897 (* 1 = 1.68897 loss)
I0521 05:38:14.959164  7203 sgd_solver.cpp:106] Iteration 1617, lr = 0.0025
I0521 05:38:22.747586  7203 solver.cpp:237] Iteration 1638, loss = 1.70736
I0521 05:38:22.747619  7203 solver.cpp:253]     Train net output #0: loss = 1.70736 (* 1 = 1.70736 loss)
I0521 05:38:22.747634  7203 sgd_solver.cpp:106] Iteration 1638, lr = 0.0025
I0521 05:38:30.540640  7203 solver.cpp:237] Iteration 1659, loss = 1.74481
I0521 05:38:30.540675  7203 solver.cpp:253]     Train net output #0: loss = 1.74481 (* 1 = 1.74481 loss)
I0521 05:38:30.540688  7203 sgd_solver.cpp:106] Iteration 1659, lr = 0.0025
I0521 05:38:38.333928  7203 solver.cpp:237] Iteration 1680, loss = 1.69442
I0521 05:38:38.334067  7203 solver.cpp:253]     Train net output #0: loss = 1.69442 (* 1 = 1.69442 loss)
I0521 05:38:38.334080  7203 sgd_solver.cpp:106] Iteration 1680, lr = 0.0025
I0521 05:38:46.123922  7203 solver.cpp:237] Iteration 1701, loss = 1.64679
I0521 05:38:46.123955  7203 solver.cpp:253]     Train net output #0: loss = 1.64679 (* 1 = 1.64679 loss)
I0521 05:38:46.123970  7203 sgd_solver.cpp:106] Iteration 1701, lr = 0.0025
I0521 05:38:53.917407  7203 solver.cpp:237] Iteration 1722, loss = 1.68513
I0521 05:38:53.917445  7203 solver.cpp:253]     Train net output #0: loss = 1.68513 (* 1 = 1.68513 loss)
I0521 05:38:53.917465  7203 sgd_solver.cpp:106] Iteration 1722, lr = 0.0025
I0521 05:38:58.742310  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1736.caffemodel
I0521 05:38:59.042001  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1736.solverstate
I0521 05:38:59.068394  7203 solver.cpp:341] Iteration 1736, Testing net (#0)
I0521 05:40:05.001051  7203 solver.cpp:409]     Test net output #0: accuracy = 0.663775
I0521 05:40:05.001222  7203 solver.cpp:409]     Test net output #1: loss = 1.1498 (* 1 = 1.1498 loss)
I0521 05:40:29.933814  7203 solver.cpp:237] Iteration 1743, loss = 1.70196
I0521 05:40:29.933863  7203 solver.cpp:253]     Train net output #0: loss = 1.70196 (* 1 = 1.70196 loss)
I0521 05:40:29.933878  7203 sgd_solver.cpp:106] Iteration 1743, lr = 0.0025
I0521 05:40:37.732890  7203 solver.cpp:237] Iteration 1764, loss = 1.6598
I0521 05:40:37.733036  7203 solver.cpp:253]     Train net output #0: loss = 1.6598 (* 1 = 1.6598 loss)
I0521 05:40:37.733058  7203 sgd_solver.cpp:106] Iteration 1764, lr = 0.0025
I0521 05:40:45.532802  7203 solver.cpp:237] Iteration 1785, loss = 1.67659
I0521 05:40:45.532835  7203 solver.cpp:253]     Train net output #0: loss = 1.67659 (* 1 = 1.67659 loss)
I0521 05:40:45.532850  7203 sgd_solver.cpp:106] Iteration 1785, lr = 0.0025
I0521 05:40:53.332890  7203 solver.cpp:237] Iteration 1806, loss = 1.70793
I0521 05:40:53.332923  7203 solver.cpp:253]     Train net output #0: loss = 1.70793 (* 1 = 1.70793 loss)
I0521 05:40:53.332938  7203 sgd_solver.cpp:106] Iteration 1806, lr = 0.0025
I0521 05:41:01.134275  7203 solver.cpp:237] Iteration 1827, loss = 1.74429
I0521 05:41:01.134317  7203 solver.cpp:253]     Train net output #0: loss = 1.74429 (* 1 = 1.74429 loss)
I0521 05:41:01.134333  7203 sgd_solver.cpp:106] Iteration 1827, lr = 0.0025
I0521 05:41:08.931484  7203 solver.cpp:237] Iteration 1848, loss = 1.72315
I0521 05:41:08.931627  7203 solver.cpp:253]     Train net output #0: loss = 1.72315 (* 1 = 1.72315 loss)
I0521 05:41:08.931641  7203 sgd_solver.cpp:106] Iteration 1848, lr = 0.0025
I0521 05:41:16.732841  7203 solver.cpp:237] Iteration 1869, loss = 1.66899
I0521 05:41:16.732872  7203 solver.cpp:253]     Train net output #0: loss = 1.66899 (* 1 = 1.66899 loss)
I0521 05:41:16.732888  7203 sgd_solver.cpp:106] Iteration 1869, lr = 0.0025
I0521 05:41:46.717638  7203 solver.cpp:237] Iteration 1890, loss = 1.70567
I0521 05:41:46.717804  7203 solver.cpp:253]     Train net output #0: loss = 1.70567 (* 1 = 1.70567 loss)
I0521 05:41:46.717819  7203 sgd_solver.cpp:106] Iteration 1890, lr = 0.0025
I0521 05:41:54.512948  7203 solver.cpp:237] Iteration 1911, loss = 1.72081
I0521 05:41:54.512979  7203 solver.cpp:253]     Train net output #0: loss = 1.72081 (* 1 = 1.72081 loss)
I0521 05:41:54.512995  7203 sgd_solver.cpp:106] Iteration 1911, lr = 0.0025
I0521 05:42:02.317360  7203 solver.cpp:237] Iteration 1932, loss = 1.7578
I0521 05:42:02.317394  7203 solver.cpp:253]     Train net output #0: loss = 1.7578 (* 1 = 1.7578 loss)
I0521 05:42:02.317409  7203 sgd_solver.cpp:106] Iteration 1932, lr = 0.0025
I0521 05:42:09.744968  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1953.caffemodel
I0521 05:42:10.045157  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_1953.solverstate
I0521 05:42:10.183462  7203 solver.cpp:237] Iteration 1953, loss = 1.73415
I0521 05:42:10.183511  7203 solver.cpp:253]     Train net output #0: loss = 1.73415 (* 1 = 1.73415 loss)
I0521 05:42:10.183527  7203 sgd_solver.cpp:106] Iteration 1953, lr = 0.0025
I0521 05:42:17.981292  7203 solver.cpp:237] Iteration 1974, loss = 1.67182
I0521 05:42:17.981461  7203 solver.cpp:253]     Train net output #0: loss = 1.67182 (* 1 = 1.67182 loss)
I0521 05:42:17.981474  7203 sgd_solver.cpp:106] Iteration 1974, lr = 0.0025
I0521 05:42:25.782184  7203 solver.cpp:237] Iteration 1995, loss = 1.68174
I0521 05:42:25.782217  7203 solver.cpp:253]     Train net output #0: loss = 1.68174 (* 1 = 1.68174 loss)
I0521 05:42:25.782233  7203 sgd_solver.cpp:106] Iteration 1995, lr = 0.0025
I0521 05:42:33.580219  7203 solver.cpp:237] Iteration 2016, loss = 1.6885
I0521 05:42:33.580252  7203 solver.cpp:253]     Train net output #0: loss = 1.6885 (* 1 = 1.6885 loss)
I0521 05:42:33.580265  7203 sgd_solver.cpp:106] Iteration 2016, lr = 0.0025
I0521 05:43:03.523321  7203 solver.cpp:237] Iteration 2037, loss = 1.71065
I0521 05:43:03.523495  7203 solver.cpp:253]     Train net output #0: loss = 1.71065 (* 1 = 1.71065 loss)
I0521 05:43:03.523510  7203 sgd_solver.cpp:106] Iteration 2037, lr = 0.0025
I0521 05:43:11.324945  7203 solver.cpp:237] Iteration 2058, loss = 1.64911
I0521 05:43:11.324977  7203 solver.cpp:253]     Train net output #0: loss = 1.64911 (* 1 = 1.64911 loss)
I0521 05:43:11.324995  7203 sgd_solver.cpp:106] Iteration 2058, lr = 0.0025
I0521 05:43:19.124107  7203 solver.cpp:237] Iteration 2079, loss = 1.62882
I0521 05:43:19.124140  7203 solver.cpp:253]     Train net output #0: loss = 1.62882 (* 1 = 1.62882 loss)
I0521 05:43:19.124156  7203 sgd_solver.cpp:106] Iteration 2079, lr = 0.0025
I0521 05:43:26.925127  7203 solver.cpp:237] Iteration 2100, loss = 1.68241
I0521 05:43:26.925168  7203 solver.cpp:253]     Train net output #0: loss = 1.68241 (* 1 = 1.68241 loss)
I0521 05:43:26.925184  7203 sgd_solver.cpp:106] Iteration 2100, lr = 0.0025
I0521 05:43:34.720356  7203 solver.cpp:237] Iteration 2121, loss = 1.62036
I0521 05:43:34.720497  7203 solver.cpp:253]     Train net output #0: loss = 1.62036 (* 1 = 1.62036 loss)
I0521 05:43:34.720510  7203 sgd_solver.cpp:106] Iteration 2121, lr = 0.0025
I0521 05:43:42.519325  7203 solver.cpp:237] Iteration 2142, loss = 1.63517
I0521 05:43:42.519356  7203 solver.cpp:253]     Train net output #0: loss = 1.63517 (* 1 = 1.63517 loss)
I0521 05:43:42.519372  7203 sgd_solver.cpp:106] Iteration 2142, lr = 0.0025
I0521 05:43:50.319694  7203 solver.cpp:237] Iteration 2163, loss = 1.71824
I0521 05:43:50.319736  7203 solver.cpp:253]     Train net output #0: loss = 1.71824 (* 1 = 1.71824 loss)
I0521 05:43:50.319752  7203 sgd_solver.cpp:106] Iteration 2163, lr = 0.0025
I0521 05:43:52.550051  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_2170.caffemodel
I0521 05:43:52.849324  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_2170.solverstate
I0521 05:43:52.877715  7203 solver.cpp:341] Iteration 2170, Testing net (#0)
I0521 05:44:37.842249  7203 solver.cpp:409]     Test net output #0: accuracy = 0.675984
I0521 05:44:37.842416  7203 solver.cpp:409]     Test net output #1: loss = 1.09662 (* 1 = 1.09662 loss)
I0521 05:44:38.694109  7203 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_2173.caffemodel
I0521 05:44:38.998016  7203 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289_iter_2173.solverstate
I0521 05:44:39.025928  7203 solver.cpp:326] Optimization Done.
I0521 05:44:39.025954  7203 caffe.cpp:215] Optimization Done.
Application 11236912 resources: utime ~1251s, stime ~225s, Rss ~5333992, inblocks ~3594475, outblocks ~194564
	Command being timed: "aprun -n 1 -N 1 ./build/tools/caffe train --solver=/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_batch_size_test/batch_size_690_2016-05-20T11.20.57.709289.solver"
	User time (seconds): 0.56
	System time (seconds): 0.14
	Percent of CPU this job got: 0%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 24:40.35
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 8660
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 15074
	Voluntary context switches: 2710
	Involuntary context switches: 67
	Swaps: 0
	File system inputs: 0
	File system outputs: 0
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
