2807165
I0522 03:44:09.723786 19252 caffe.cpp:184] Using GPUs 0
I0522 03:44:10.150336 19252 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.004
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271.prototxt"
I0522 03:44:10.152046 19252 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271.prototxt
I0522 03:44:10.167435 19252 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 03:44:10.167495 19252 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 03:44:10.167842 19252 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 03:44:10.168020 19252 layer_factory.hpp:77] Creating layer data_hdf5
I0522 03:44:10.168045 19252 net.cpp:106] Creating Layer data_hdf5
I0522 03:44:10.168058 19252 net.cpp:411] data_hdf5 -> data
I0522 03:44:10.168092 19252 net.cpp:411] data_hdf5 -> label
I0522 03:44:10.168125 19252 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 03:44:10.176183 19252 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 03:44:10.192803 19252 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 03:44:31.869366 19252 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 03:44:31.874619 19252 net.cpp:150] Setting up data_hdf5
I0522 03:44:31.874660 19252 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 03:44:31.874673 19252 net.cpp:157] Top shape: 20 (20)
I0522 03:44:31.874685 19252 net.cpp:165] Memory required for data: 508080
I0522 03:44:31.874697 19252 layer_factory.hpp:77] Creating layer conv1
I0522 03:44:31.874732 19252 net.cpp:106] Creating Layer conv1
I0522 03:44:31.874743 19252 net.cpp:454] conv1 <- data
I0522 03:44:31.874764 19252 net.cpp:411] conv1 -> conv1
I0522 03:44:34.881011 19252 net.cpp:150] Setting up conv1
I0522 03:44:34.881057 19252 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 03:44:34.881068 19252 net.cpp:165] Memory required for data: 6037680
I0522 03:44:34.881098 19252 layer_factory.hpp:77] Creating layer relu1
I0522 03:44:34.881121 19252 net.cpp:106] Creating Layer relu1
I0522 03:44:34.881132 19252 net.cpp:454] relu1 <- conv1
I0522 03:44:34.881146 19252 net.cpp:397] relu1 -> conv1 (in-place)
I0522 03:44:34.881669 19252 net.cpp:150] Setting up relu1
I0522 03:44:34.881685 19252 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 03:44:34.881696 19252 net.cpp:165] Memory required for data: 11567280
I0522 03:44:34.881706 19252 layer_factory.hpp:77] Creating layer pool1
I0522 03:44:34.881723 19252 net.cpp:106] Creating Layer pool1
I0522 03:44:34.881732 19252 net.cpp:454] pool1 <- conv1
I0522 03:44:34.881747 19252 net.cpp:411] pool1 -> pool1
I0522 03:44:34.881827 19252 net.cpp:150] Setting up pool1
I0522 03:44:34.881840 19252 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 03:44:34.881850 19252 net.cpp:165] Memory required for data: 14332080
I0522 03:44:34.881860 19252 layer_factory.hpp:77] Creating layer conv2
I0522 03:44:34.881882 19252 net.cpp:106] Creating Layer conv2
I0522 03:44:34.881893 19252 net.cpp:454] conv2 <- pool1
I0522 03:44:34.881906 19252 net.cpp:411] conv2 -> conv2
I0522 03:44:34.884611 19252 net.cpp:150] Setting up conv2
I0522 03:44:34.884639 19252 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 03:44:34.884649 19252 net.cpp:165] Memory required for data: 18306480
I0522 03:44:34.884668 19252 layer_factory.hpp:77] Creating layer relu2
I0522 03:44:34.884682 19252 net.cpp:106] Creating Layer relu2
I0522 03:44:34.884692 19252 net.cpp:454] relu2 <- conv2
I0522 03:44:34.884706 19252 net.cpp:397] relu2 -> conv2 (in-place)
I0522 03:44:34.885046 19252 net.cpp:150] Setting up relu2
I0522 03:44:34.885059 19252 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 03:44:34.885071 19252 net.cpp:165] Memory required for data: 22280880
I0522 03:44:34.885081 19252 layer_factory.hpp:77] Creating layer pool2
I0522 03:44:34.885092 19252 net.cpp:106] Creating Layer pool2
I0522 03:44:34.885102 19252 net.cpp:454] pool2 <- conv2
I0522 03:44:34.885115 19252 net.cpp:411] pool2 -> pool2
I0522 03:44:34.885196 19252 net.cpp:150] Setting up pool2
I0522 03:44:34.885210 19252 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 03:44:34.885220 19252 net.cpp:165] Memory required for data: 24268080
I0522 03:44:34.885229 19252 layer_factory.hpp:77] Creating layer conv3
I0522 03:44:34.885247 19252 net.cpp:106] Creating Layer conv3
I0522 03:44:34.885258 19252 net.cpp:454] conv3 <- pool2
I0522 03:44:34.885272 19252 net.cpp:411] conv3 -> conv3
I0522 03:44:34.887208 19252 net.cpp:150] Setting up conv3
I0522 03:44:34.887233 19252 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 03:44:34.887244 19252 net.cpp:165] Memory required for data: 26436400
I0522 03:44:34.887262 19252 layer_factory.hpp:77] Creating layer relu3
I0522 03:44:34.887279 19252 net.cpp:106] Creating Layer relu3
I0522 03:44:34.887289 19252 net.cpp:454] relu3 <- conv3
I0522 03:44:34.887300 19252 net.cpp:397] relu3 -> conv3 (in-place)
I0522 03:44:34.887773 19252 net.cpp:150] Setting up relu3
I0522 03:44:34.887789 19252 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 03:44:34.887799 19252 net.cpp:165] Memory required for data: 28604720
I0522 03:44:34.887809 19252 layer_factory.hpp:77] Creating layer pool3
I0522 03:44:34.887822 19252 net.cpp:106] Creating Layer pool3
I0522 03:44:34.887832 19252 net.cpp:454] pool3 <- conv3
I0522 03:44:34.887845 19252 net.cpp:411] pool3 -> pool3
I0522 03:44:34.887912 19252 net.cpp:150] Setting up pool3
I0522 03:44:34.887925 19252 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 03:44:34.887935 19252 net.cpp:165] Memory required for data: 29688880
I0522 03:44:34.887944 19252 layer_factory.hpp:77] Creating layer conv4
I0522 03:44:34.887961 19252 net.cpp:106] Creating Layer conv4
I0522 03:44:34.887972 19252 net.cpp:454] conv4 <- pool3
I0522 03:44:34.887986 19252 net.cpp:411] conv4 -> conv4
I0522 03:44:34.890719 19252 net.cpp:150] Setting up conv4
I0522 03:44:34.890748 19252 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 03:44:34.890758 19252 net.cpp:165] Memory required for data: 30414640
I0522 03:44:34.890774 19252 layer_factory.hpp:77] Creating layer relu4
I0522 03:44:34.890789 19252 net.cpp:106] Creating Layer relu4
I0522 03:44:34.890799 19252 net.cpp:454] relu4 <- conv4
I0522 03:44:34.890811 19252 net.cpp:397] relu4 -> conv4 (in-place)
I0522 03:44:34.891278 19252 net.cpp:150] Setting up relu4
I0522 03:44:34.891294 19252 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 03:44:34.891304 19252 net.cpp:165] Memory required for data: 31140400
I0522 03:44:34.891314 19252 layer_factory.hpp:77] Creating layer pool4
I0522 03:44:34.891327 19252 net.cpp:106] Creating Layer pool4
I0522 03:44:34.891336 19252 net.cpp:454] pool4 <- conv4
I0522 03:44:34.891350 19252 net.cpp:411] pool4 -> pool4
I0522 03:44:34.891417 19252 net.cpp:150] Setting up pool4
I0522 03:44:34.891430 19252 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 03:44:34.891441 19252 net.cpp:165] Memory required for data: 31503280
I0522 03:44:34.891451 19252 layer_factory.hpp:77] Creating layer ip1
I0522 03:44:34.891471 19252 net.cpp:106] Creating Layer ip1
I0522 03:44:34.891482 19252 net.cpp:454] ip1 <- pool4
I0522 03:44:34.891495 19252 net.cpp:411] ip1 -> ip1
I0522 03:44:34.906955 19252 net.cpp:150] Setting up ip1
I0522 03:44:34.906980 19252 net.cpp:157] Top shape: 20 196 (3920)
I0522 03:44:34.906991 19252 net.cpp:165] Memory required for data: 31518960
I0522 03:44:34.907018 19252 layer_factory.hpp:77] Creating layer relu5
I0522 03:44:34.907033 19252 net.cpp:106] Creating Layer relu5
I0522 03:44:34.907043 19252 net.cpp:454] relu5 <- ip1
I0522 03:44:34.907058 19252 net.cpp:397] relu5 -> ip1 (in-place)
I0522 03:44:34.907398 19252 net.cpp:150] Setting up relu5
I0522 03:44:34.907413 19252 net.cpp:157] Top shape: 20 196 (3920)
I0522 03:44:34.907423 19252 net.cpp:165] Memory required for data: 31534640
I0522 03:44:34.907433 19252 layer_factory.hpp:77] Creating layer drop1
I0522 03:44:34.907456 19252 net.cpp:106] Creating Layer drop1
I0522 03:44:34.907466 19252 net.cpp:454] drop1 <- ip1
I0522 03:44:34.907479 19252 net.cpp:397] drop1 -> ip1 (in-place)
I0522 03:44:34.907538 19252 net.cpp:150] Setting up drop1
I0522 03:44:34.907552 19252 net.cpp:157] Top shape: 20 196 (3920)
I0522 03:44:34.907562 19252 net.cpp:165] Memory required for data: 31550320
I0522 03:44:34.907572 19252 layer_factory.hpp:77] Creating layer ip2
I0522 03:44:34.907591 19252 net.cpp:106] Creating Layer ip2
I0522 03:44:34.907601 19252 net.cpp:454] ip2 <- ip1
I0522 03:44:34.907614 19252 net.cpp:411] ip2 -> ip2
I0522 03:44:34.908078 19252 net.cpp:150] Setting up ip2
I0522 03:44:34.908092 19252 net.cpp:157] Top shape: 20 98 (1960)
I0522 03:44:34.908100 19252 net.cpp:165] Memory required for data: 31558160
I0522 03:44:34.908115 19252 layer_factory.hpp:77] Creating layer relu6
I0522 03:44:34.908128 19252 net.cpp:106] Creating Layer relu6
I0522 03:44:34.908138 19252 net.cpp:454] relu6 <- ip2
I0522 03:44:34.908150 19252 net.cpp:397] relu6 -> ip2 (in-place)
I0522 03:44:34.908671 19252 net.cpp:150] Setting up relu6
I0522 03:44:34.908689 19252 net.cpp:157] Top shape: 20 98 (1960)
I0522 03:44:34.908699 19252 net.cpp:165] Memory required for data: 31566000
I0522 03:44:34.908710 19252 layer_factory.hpp:77] Creating layer drop2
I0522 03:44:34.908722 19252 net.cpp:106] Creating Layer drop2
I0522 03:44:34.908732 19252 net.cpp:454] drop2 <- ip2
I0522 03:44:34.908746 19252 net.cpp:397] drop2 -> ip2 (in-place)
I0522 03:44:34.908787 19252 net.cpp:150] Setting up drop2
I0522 03:44:34.908800 19252 net.cpp:157] Top shape: 20 98 (1960)
I0522 03:44:34.908812 19252 net.cpp:165] Memory required for data: 31573840
I0522 03:44:34.908821 19252 layer_factory.hpp:77] Creating layer ip3
I0522 03:44:34.908835 19252 net.cpp:106] Creating Layer ip3
I0522 03:44:34.908845 19252 net.cpp:454] ip3 <- ip2
I0522 03:44:34.908859 19252 net.cpp:411] ip3 -> ip3
I0522 03:44:34.909076 19252 net.cpp:150] Setting up ip3
I0522 03:44:34.909090 19252 net.cpp:157] Top shape: 20 11 (220)
I0522 03:44:34.909099 19252 net.cpp:165] Memory required for data: 31574720
I0522 03:44:34.909114 19252 layer_factory.hpp:77] Creating layer drop3
I0522 03:44:34.909127 19252 net.cpp:106] Creating Layer drop3
I0522 03:44:34.909137 19252 net.cpp:454] drop3 <- ip3
I0522 03:44:34.909148 19252 net.cpp:397] drop3 -> ip3 (in-place)
I0522 03:44:34.909188 19252 net.cpp:150] Setting up drop3
I0522 03:44:34.909201 19252 net.cpp:157] Top shape: 20 11 (220)
I0522 03:44:34.909211 19252 net.cpp:165] Memory required for data: 31575600
I0522 03:44:34.909221 19252 layer_factory.hpp:77] Creating layer loss
I0522 03:44:34.909240 19252 net.cpp:106] Creating Layer loss
I0522 03:44:34.909250 19252 net.cpp:454] loss <- ip3
I0522 03:44:34.909261 19252 net.cpp:454] loss <- label
I0522 03:44:34.909272 19252 net.cpp:411] loss -> loss
I0522 03:44:34.909289 19252 layer_factory.hpp:77] Creating layer loss
I0522 03:44:34.909934 19252 net.cpp:150] Setting up loss
I0522 03:44:34.909955 19252 net.cpp:157] Top shape: (1)
I0522 03:44:34.909967 19252 net.cpp:160]     with loss weight 1
I0522 03:44:34.910010 19252 net.cpp:165] Memory required for data: 31575604
I0522 03:44:34.910020 19252 net.cpp:226] loss needs backward computation.
I0522 03:44:34.910032 19252 net.cpp:226] drop3 needs backward computation.
I0522 03:44:34.910042 19252 net.cpp:226] ip3 needs backward computation.
I0522 03:44:34.910049 19252 net.cpp:226] drop2 needs backward computation.
I0522 03:44:34.910060 19252 net.cpp:226] relu6 needs backward computation.
I0522 03:44:34.910070 19252 net.cpp:226] ip2 needs backward computation.
I0522 03:44:34.910079 19252 net.cpp:226] drop1 needs backward computation.
I0522 03:44:34.910090 19252 net.cpp:226] relu5 needs backward computation.
I0522 03:44:34.910100 19252 net.cpp:226] ip1 needs backward computation.
I0522 03:44:34.910110 19252 net.cpp:226] pool4 needs backward computation.
I0522 03:44:34.910120 19252 net.cpp:226] relu4 needs backward computation.
I0522 03:44:34.910130 19252 net.cpp:226] conv4 needs backward computation.
I0522 03:44:34.910140 19252 net.cpp:226] pool3 needs backward computation.
I0522 03:44:34.910151 19252 net.cpp:226] relu3 needs backward computation.
I0522 03:44:34.910161 19252 net.cpp:226] conv3 needs backward computation.
I0522 03:44:34.910179 19252 net.cpp:226] pool2 needs backward computation.
I0522 03:44:34.910190 19252 net.cpp:226] relu2 needs backward computation.
I0522 03:44:34.910202 19252 net.cpp:226] conv2 needs backward computation.
I0522 03:44:34.910212 19252 net.cpp:226] pool1 needs backward computation.
I0522 03:44:34.910223 19252 net.cpp:226] relu1 needs backward computation.
I0522 03:44:34.910233 19252 net.cpp:226] conv1 needs backward computation.
I0522 03:44:34.910244 19252 net.cpp:228] data_hdf5 does not need backward computation.
I0522 03:44:34.910254 19252 net.cpp:270] This network produces output loss
I0522 03:44:34.910279 19252 net.cpp:283] Network initialization done.
I0522 03:44:34.911988 19252 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271.prototxt
I0522 03:44:34.912060 19252 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 03:44:34.912415 19252 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 03:44:34.912605 19252 layer_factory.hpp:77] Creating layer data_hdf5
I0522 03:44:34.912619 19252 net.cpp:106] Creating Layer data_hdf5
I0522 03:44:34.912631 19252 net.cpp:411] data_hdf5 -> data
I0522 03:44:34.912648 19252 net.cpp:411] data_hdf5 -> label
I0522 03:44:34.912664 19252 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 03:44:34.927651 19252 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 03:44:56.314661 19252 net.cpp:150] Setting up data_hdf5
I0522 03:44:56.314826 19252 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 03:44:56.314841 19252 net.cpp:157] Top shape: 20 (20)
I0522 03:44:56.314851 19252 net.cpp:165] Memory required for data: 508080
I0522 03:44:56.314864 19252 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 03:44:56.314893 19252 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 03:44:56.314904 19252 net.cpp:454] label_data_hdf5_1_split <- label
I0522 03:44:56.314918 19252 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 03:44:56.314940 19252 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 03:44:56.315012 19252 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 03:44:56.315026 19252 net.cpp:157] Top shape: 20 (20)
I0522 03:44:56.315038 19252 net.cpp:157] Top shape: 20 (20)
I0522 03:44:56.315048 19252 net.cpp:165] Memory required for data: 508240
I0522 03:44:56.315058 19252 layer_factory.hpp:77] Creating layer conv1
I0522 03:44:56.315081 19252 net.cpp:106] Creating Layer conv1
I0522 03:44:56.315091 19252 net.cpp:454] conv1 <- data
I0522 03:44:56.315104 19252 net.cpp:411] conv1 -> conv1
I0522 03:44:56.317042 19252 net.cpp:150] Setting up conv1
I0522 03:44:56.317067 19252 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 03:44:56.317078 19252 net.cpp:165] Memory required for data: 6037840
I0522 03:44:56.317100 19252 layer_factory.hpp:77] Creating layer relu1
I0522 03:44:56.317114 19252 net.cpp:106] Creating Layer relu1
I0522 03:44:56.317124 19252 net.cpp:454] relu1 <- conv1
I0522 03:44:56.317137 19252 net.cpp:397] relu1 -> conv1 (in-place)
I0522 03:44:56.317641 19252 net.cpp:150] Setting up relu1
I0522 03:44:56.317657 19252 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 03:44:56.317667 19252 net.cpp:165] Memory required for data: 11567440
I0522 03:44:56.317677 19252 layer_factory.hpp:77] Creating layer pool1
I0522 03:44:56.317694 19252 net.cpp:106] Creating Layer pool1
I0522 03:44:56.317704 19252 net.cpp:454] pool1 <- conv1
I0522 03:44:56.317718 19252 net.cpp:411] pool1 -> pool1
I0522 03:44:56.317791 19252 net.cpp:150] Setting up pool1
I0522 03:44:56.317805 19252 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 03:44:56.317814 19252 net.cpp:165] Memory required for data: 14332240
I0522 03:44:56.317824 19252 layer_factory.hpp:77] Creating layer conv2
I0522 03:44:56.317844 19252 net.cpp:106] Creating Layer conv2
I0522 03:44:56.317855 19252 net.cpp:454] conv2 <- pool1
I0522 03:44:56.317869 19252 net.cpp:411] conv2 -> conv2
I0522 03:44:56.319782 19252 net.cpp:150] Setting up conv2
I0522 03:44:56.319804 19252 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 03:44:56.319818 19252 net.cpp:165] Memory required for data: 18306640
I0522 03:44:56.319834 19252 layer_factory.hpp:77] Creating layer relu2
I0522 03:44:56.319849 19252 net.cpp:106] Creating Layer relu2
I0522 03:44:56.319859 19252 net.cpp:454] relu2 <- conv2
I0522 03:44:56.319871 19252 net.cpp:397] relu2 -> conv2 (in-place)
I0522 03:44:56.320204 19252 net.cpp:150] Setting up relu2
I0522 03:44:56.320217 19252 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 03:44:56.320227 19252 net.cpp:165] Memory required for data: 22281040
I0522 03:44:56.320237 19252 layer_factory.hpp:77] Creating layer pool2
I0522 03:44:56.320250 19252 net.cpp:106] Creating Layer pool2
I0522 03:44:56.320261 19252 net.cpp:454] pool2 <- conv2
I0522 03:44:56.320273 19252 net.cpp:411] pool2 -> pool2
I0522 03:44:56.320344 19252 net.cpp:150] Setting up pool2
I0522 03:44:56.320358 19252 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 03:44:56.320369 19252 net.cpp:165] Memory required for data: 24268240
I0522 03:44:56.320379 19252 layer_factory.hpp:77] Creating layer conv3
I0522 03:44:56.320397 19252 net.cpp:106] Creating Layer conv3
I0522 03:44:56.320408 19252 net.cpp:454] conv3 <- pool2
I0522 03:44:56.320422 19252 net.cpp:411] conv3 -> conv3
I0522 03:44:56.322417 19252 net.cpp:150] Setting up conv3
I0522 03:44:56.322440 19252 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 03:44:56.322450 19252 net.cpp:165] Memory required for data: 26436560
I0522 03:44:56.322470 19252 layer_factory.hpp:77] Creating layer relu3
I0522 03:44:56.322495 19252 net.cpp:106] Creating Layer relu3
I0522 03:44:56.322505 19252 net.cpp:454] relu3 <- conv3
I0522 03:44:56.322518 19252 net.cpp:397] relu3 -> conv3 (in-place)
I0522 03:44:56.322993 19252 net.cpp:150] Setting up relu3
I0522 03:44:56.323009 19252 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 03:44:56.323020 19252 net.cpp:165] Memory required for data: 28604880
I0522 03:44:56.323030 19252 layer_factory.hpp:77] Creating layer pool3
I0522 03:44:56.323042 19252 net.cpp:106] Creating Layer pool3
I0522 03:44:56.323052 19252 net.cpp:454] pool3 <- conv3
I0522 03:44:56.323065 19252 net.cpp:411] pool3 -> pool3
I0522 03:44:56.323137 19252 net.cpp:150] Setting up pool3
I0522 03:44:56.323150 19252 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 03:44:56.323160 19252 net.cpp:165] Memory required for data: 29689040
I0522 03:44:56.323170 19252 layer_factory.hpp:77] Creating layer conv4
I0522 03:44:56.323186 19252 net.cpp:106] Creating Layer conv4
I0522 03:44:56.323197 19252 net.cpp:454] conv4 <- pool3
I0522 03:44:56.323211 19252 net.cpp:411] conv4 -> conv4
I0522 03:44:56.325273 19252 net.cpp:150] Setting up conv4
I0522 03:44:56.325295 19252 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 03:44:56.325309 19252 net.cpp:165] Memory required for data: 30414800
I0522 03:44:56.325323 19252 layer_factory.hpp:77] Creating layer relu4
I0522 03:44:56.325337 19252 net.cpp:106] Creating Layer relu4
I0522 03:44:56.325347 19252 net.cpp:454] relu4 <- conv4
I0522 03:44:56.325361 19252 net.cpp:397] relu4 -> conv4 (in-place)
I0522 03:44:56.325836 19252 net.cpp:150] Setting up relu4
I0522 03:44:56.325853 19252 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 03:44:56.325863 19252 net.cpp:165] Memory required for data: 31140560
I0522 03:44:56.325873 19252 layer_factory.hpp:77] Creating layer pool4
I0522 03:44:56.325886 19252 net.cpp:106] Creating Layer pool4
I0522 03:44:56.325896 19252 net.cpp:454] pool4 <- conv4
I0522 03:44:56.325909 19252 net.cpp:411] pool4 -> pool4
I0522 03:44:56.325981 19252 net.cpp:150] Setting up pool4
I0522 03:44:56.325994 19252 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 03:44:56.326004 19252 net.cpp:165] Memory required for data: 31503440
I0522 03:44:56.326014 19252 layer_factory.hpp:77] Creating layer ip1
I0522 03:44:56.326027 19252 net.cpp:106] Creating Layer ip1
I0522 03:44:56.326038 19252 net.cpp:454] ip1 <- pool4
I0522 03:44:56.326051 19252 net.cpp:411] ip1 -> ip1
I0522 03:44:56.341490 19252 net.cpp:150] Setting up ip1
I0522 03:44:56.341519 19252 net.cpp:157] Top shape: 20 196 (3920)
I0522 03:44:56.341532 19252 net.cpp:165] Memory required for data: 31519120
I0522 03:44:56.341554 19252 layer_factory.hpp:77] Creating layer relu5
I0522 03:44:56.341569 19252 net.cpp:106] Creating Layer relu5
I0522 03:44:56.341579 19252 net.cpp:454] relu5 <- ip1
I0522 03:44:56.341593 19252 net.cpp:397] relu5 -> ip1 (in-place)
I0522 03:44:56.341938 19252 net.cpp:150] Setting up relu5
I0522 03:44:56.341953 19252 net.cpp:157] Top shape: 20 196 (3920)
I0522 03:44:56.341963 19252 net.cpp:165] Memory required for data: 31534800
I0522 03:44:56.341972 19252 layer_factory.hpp:77] Creating layer drop1
I0522 03:44:56.341992 19252 net.cpp:106] Creating Layer drop1
I0522 03:44:56.342002 19252 net.cpp:454] drop1 <- ip1
I0522 03:44:56.342015 19252 net.cpp:397] drop1 -> ip1 (in-place)
I0522 03:44:56.342061 19252 net.cpp:150] Setting up drop1
I0522 03:44:56.342077 19252 net.cpp:157] Top shape: 20 196 (3920)
I0522 03:44:56.342085 19252 net.cpp:165] Memory required for data: 31550480
I0522 03:44:56.342095 19252 layer_factory.hpp:77] Creating layer ip2
I0522 03:44:56.342110 19252 net.cpp:106] Creating Layer ip2
I0522 03:44:56.342120 19252 net.cpp:454] ip2 <- ip1
I0522 03:44:56.342133 19252 net.cpp:411] ip2 -> ip2
I0522 03:44:56.342612 19252 net.cpp:150] Setting up ip2
I0522 03:44:56.342625 19252 net.cpp:157] Top shape: 20 98 (1960)
I0522 03:44:56.342635 19252 net.cpp:165] Memory required for data: 31558320
I0522 03:44:56.342650 19252 layer_factory.hpp:77] Creating layer relu6
I0522 03:44:56.342676 19252 net.cpp:106] Creating Layer relu6
I0522 03:44:56.342686 19252 net.cpp:454] relu6 <- ip2
I0522 03:44:56.342699 19252 net.cpp:397] relu6 -> ip2 (in-place)
I0522 03:44:56.343235 19252 net.cpp:150] Setting up relu6
I0522 03:44:56.343250 19252 net.cpp:157] Top shape: 20 98 (1960)
I0522 03:44:56.343261 19252 net.cpp:165] Memory required for data: 31566160
I0522 03:44:56.343271 19252 layer_factory.hpp:77] Creating layer drop2
I0522 03:44:56.343284 19252 net.cpp:106] Creating Layer drop2
I0522 03:44:56.343294 19252 net.cpp:454] drop2 <- ip2
I0522 03:44:56.343307 19252 net.cpp:397] drop2 -> ip2 (in-place)
I0522 03:44:56.343353 19252 net.cpp:150] Setting up drop2
I0522 03:44:56.343365 19252 net.cpp:157] Top shape: 20 98 (1960)
I0522 03:44:56.343375 19252 net.cpp:165] Memory required for data: 31574000
I0522 03:44:56.343385 19252 layer_factory.hpp:77] Creating layer ip3
I0522 03:44:56.343400 19252 net.cpp:106] Creating Layer ip3
I0522 03:44:56.343410 19252 net.cpp:454] ip3 <- ip2
I0522 03:44:56.343423 19252 net.cpp:411] ip3 -> ip3
I0522 03:44:56.343647 19252 net.cpp:150] Setting up ip3
I0522 03:44:56.343660 19252 net.cpp:157] Top shape: 20 11 (220)
I0522 03:44:56.343669 19252 net.cpp:165] Memory required for data: 31574880
I0522 03:44:56.343684 19252 layer_factory.hpp:77] Creating layer drop3
I0522 03:44:56.343698 19252 net.cpp:106] Creating Layer drop3
I0522 03:44:56.343708 19252 net.cpp:454] drop3 <- ip3
I0522 03:44:56.343720 19252 net.cpp:397] drop3 -> ip3 (in-place)
I0522 03:44:56.343761 19252 net.cpp:150] Setting up drop3
I0522 03:44:56.343775 19252 net.cpp:157] Top shape: 20 11 (220)
I0522 03:44:56.343785 19252 net.cpp:165] Memory required for data: 31575760
I0522 03:44:56.343793 19252 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 03:44:56.343807 19252 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 03:44:56.343816 19252 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 03:44:56.343829 19252 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 03:44:56.343844 19252 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 03:44:56.343917 19252 net.cpp:150] Setting up ip3_drop3_0_split
I0522 03:44:56.343930 19252 net.cpp:157] Top shape: 20 11 (220)
I0522 03:44:56.343942 19252 net.cpp:157] Top shape: 20 11 (220)
I0522 03:44:56.343953 19252 net.cpp:165] Memory required for data: 31577520
I0522 03:44:56.343964 19252 layer_factory.hpp:77] Creating layer accuracy
I0522 03:44:56.343986 19252 net.cpp:106] Creating Layer accuracy
I0522 03:44:56.343996 19252 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 03:44:56.344007 19252 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 03:44:56.344020 19252 net.cpp:411] accuracy -> accuracy
I0522 03:44:56.344043 19252 net.cpp:150] Setting up accuracy
I0522 03:44:56.344055 19252 net.cpp:157] Top shape: (1)
I0522 03:44:56.344065 19252 net.cpp:165] Memory required for data: 31577524
I0522 03:44:56.344075 19252 layer_factory.hpp:77] Creating layer loss
I0522 03:44:56.344089 19252 net.cpp:106] Creating Layer loss
I0522 03:44:56.344099 19252 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 03:44:56.344110 19252 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 03:44:56.344123 19252 net.cpp:411] loss -> loss
I0522 03:44:56.344141 19252 layer_factory.hpp:77] Creating layer loss
I0522 03:44:56.344621 19252 net.cpp:150] Setting up loss
I0522 03:44:56.344635 19252 net.cpp:157] Top shape: (1)
I0522 03:44:56.344645 19252 net.cpp:160]     with loss weight 1
I0522 03:44:56.344663 19252 net.cpp:165] Memory required for data: 31577528
I0522 03:44:56.344673 19252 net.cpp:226] loss needs backward computation.
I0522 03:44:56.344686 19252 net.cpp:228] accuracy does not need backward computation.
I0522 03:44:56.344696 19252 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 03:44:56.344707 19252 net.cpp:226] drop3 needs backward computation.
I0522 03:44:56.344717 19252 net.cpp:226] ip3 needs backward computation.
I0522 03:44:56.344728 19252 net.cpp:226] drop2 needs backward computation.
I0522 03:44:56.344738 19252 net.cpp:226] relu6 needs backward computation.
I0522 03:44:56.344755 19252 net.cpp:226] ip2 needs backward computation.
I0522 03:44:56.344766 19252 net.cpp:226] drop1 needs backward computation.
I0522 03:44:56.344775 19252 net.cpp:226] relu5 needs backward computation.
I0522 03:44:56.344784 19252 net.cpp:226] ip1 needs backward computation.
I0522 03:44:56.344794 19252 net.cpp:226] pool4 needs backward computation.
I0522 03:44:56.344805 19252 net.cpp:226] relu4 needs backward computation.
I0522 03:44:56.344815 19252 net.cpp:226] conv4 needs backward computation.
I0522 03:44:56.344825 19252 net.cpp:226] pool3 needs backward computation.
I0522 03:44:56.344835 19252 net.cpp:226] relu3 needs backward computation.
I0522 03:44:56.344846 19252 net.cpp:226] conv3 needs backward computation.
I0522 03:44:56.344857 19252 net.cpp:226] pool2 needs backward computation.
I0522 03:44:56.344867 19252 net.cpp:226] relu2 needs backward computation.
I0522 03:44:56.344884 19252 net.cpp:226] conv2 needs backward computation.
I0522 03:44:56.344894 19252 net.cpp:226] pool1 needs backward computation.
I0522 03:44:56.344904 19252 net.cpp:226] relu1 needs backward computation.
I0522 03:44:56.344914 19252 net.cpp:226] conv1 needs backward computation.
I0522 03:44:56.344926 19252 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 03:44:56.344938 19252 net.cpp:228] data_hdf5 does not need backward computation.
I0522 03:44:56.344947 19252 net.cpp:270] This network produces output accuracy
I0522 03:44:56.344959 19252 net.cpp:270] This network produces output loss
I0522 03:44:56.344987 19252 net.cpp:283] Network initialization done.
I0522 03:44:56.345119 19252 solver.cpp:60] Solver scaffolding done.
I0522 03:44:56.346246 19252 caffe.cpp:212] Starting Optimization
I0522 03:44:56.346263 19252 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 03:44:56.346276 19252 solver.cpp:289] Learning Rate Policy: fixed
I0522 03:44:56.347506 19252 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 03:45:49.206631 19252 solver.cpp:409]     Test net output #0: accuracy = 0.0322742
I0522 03:45:49.206785 19252 solver.cpp:409]     Test net output #1: loss = 2.39977 (* 1 = 2.39977 loss)
I0522 03:45:49.225898 19252 solver.cpp:237] Iteration 0, loss = 2.39885
I0522 03:45:49.225934 19252 solver.cpp:253]     Train net output #0: loss = 2.39885 (* 1 = 2.39885 loss)
I0522 03:45:49.225952 19252 sgd_solver.cpp:106] Iteration 0, lr = 0.004
I0522 03:46:01.369762 19252 solver.cpp:237] Iteration 750, loss = 2.1114
I0522 03:46:01.369802 19252 solver.cpp:253]     Train net output #0: loss = 2.1114 (* 1 = 2.1114 loss)
I0522 03:46:01.369817 19252 sgd_solver.cpp:106] Iteration 750, lr = 0.004
I0522 03:46:13.542781 19252 solver.cpp:237] Iteration 1500, loss = 1.64771
I0522 03:46:13.542825 19252 solver.cpp:253]     Train net output #0: loss = 1.64771 (* 1 = 1.64771 loss)
I0522 03:46:13.542839 19252 sgd_solver.cpp:106] Iteration 1500, lr = 0.004
I0522 03:46:25.728188 19252 solver.cpp:237] Iteration 2250, loss = 1.48376
I0522 03:46:25.728341 19252 solver.cpp:253]     Train net output #0: loss = 1.48376 (* 1 = 1.48376 loss)
I0522 03:46:25.728358 19252 sgd_solver.cpp:106] Iteration 2250, lr = 0.004
I0522 03:46:37.951503 19252 solver.cpp:237] Iteration 3000, loss = 1.28773
I0522 03:46:37.951539 19252 solver.cpp:253]     Train net output #0: loss = 1.28773 (* 1 = 1.28773 loss)
I0522 03:46:37.951555 19252 sgd_solver.cpp:106] Iteration 3000, lr = 0.004
I0522 03:46:50.087241 19252 solver.cpp:237] Iteration 3750, loss = 1.82871
I0522 03:46:50.087291 19252 solver.cpp:253]     Train net output #0: loss = 1.82871 (* 1 = 1.82871 loss)
I0522 03:46:50.087303 19252 sgd_solver.cpp:106] Iteration 3750, lr = 0.004
I0522 03:47:02.228731 19252 solver.cpp:237] Iteration 4500, loss = 1.3699
I0522 03:47:02.228881 19252 solver.cpp:253]     Train net output #0: loss = 1.3699 (* 1 = 1.3699 loss)
I0522 03:47:02.228895 19252 sgd_solver.cpp:106] Iteration 4500, lr = 0.004
I0522 03:47:36.582491 19252 solver.cpp:237] Iteration 5250, loss = 1.60667
I0522 03:47:36.582656 19252 solver.cpp:253]     Train net output #0: loss = 1.60667 (* 1 = 1.60667 loss)
I0522 03:47:36.582672 19252 sgd_solver.cpp:106] Iteration 5250, lr = 0.004
I0522 03:47:48.687377 19252 solver.cpp:237] Iteration 6000, loss = 1.34655
I0522 03:47:48.687413 19252 solver.cpp:253]     Train net output #0: loss = 1.34655 (* 1 = 1.34655 loss)
I0522 03:47:48.687430 19252 sgd_solver.cpp:106] Iteration 6000, lr = 0.004
I0522 03:48:00.822116 19252 solver.cpp:237] Iteration 6750, loss = 1.80937
I0522 03:48:00.822167 19252 solver.cpp:253]     Train net output #0: loss = 1.80937 (* 1 = 1.80937 loss)
I0522 03:48:00.822181 19252 sgd_solver.cpp:106] Iteration 6750, lr = 0.004
I0522 03:48:12.914641 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_7500.caffemodel
I0522 03:48:12.967186 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_7500.solverstate
I0522 03:48:12.997570 19252 solver.cpp:237] Iteration 7500, loss = 1.0264
I0522 03:48:12.997613 19252 solver.cpp:253]     Train net output #0: loss = 1.0264 (* 1 = 1.0264 loss)
I0522 03:48:12.997629 19252 sgd_solver.cpp:106] Iteration 7500, lr = 0.004
I0522 03:48:25.167193 19252 solver.cpp:237] Iteration 8250, loss = 1.9888
I0522 03:48:25.167240 19252 solver.cpp:253]     Train net output #0: loss = 1.9888 (* 1 = 1.9888 loss)
I0522 03:48:25.167256 19252 sgd_solver.cpp:106] Iteration 8250, lr = 0.004
I0522 03:48:37.310426 19252 solver.cpp:237] Iteration 9000, loss = 1.24174
I0522 03:48:37.310463 19252 solver.cpp:253]     Train net output #0: loss = 1.24174 (* 1 = 1.24174 loss)
I0522 03:48:37.310477 19252 sgd_solver.cpp:106] Iteration 9000, lr = 0.004
I0522 03:48:49.452504 19252 solver.cpp:237] Iteration 9750, loss = 0.693693
I0522 03:48:49.452664 19252 solver.cpp:253]     Train net output #0: loss = 0.693693 (* 1 = 0.693693 loss)
I0522 03:48:49.452679 19252 sgd_solver.cpp:106] Iteration 9750, lr = 0.004
I0522 03:49:23.738020 19252 solver.cpp:237] Iteration 10500, loss = 1.31955
I0522 03:49:23.738185 19252 solver.cpp:253]     Train net output #0: loss = 1.31955 (* 1 = 1.31955 loss)
I0522 03:49:23.738201 19252 sgd_solver.cpp:106] Iteration 10500, lr = 0.004
I0522 03:49:35.888340 19252 solver.cpp:237] Iteration 11250, loss = 1.12756
I0522 03:49:35.888389 19252 solver.cpp:253]     Train net output #0: loss = 1.12756 (* 1 = 1.12756 loss)
I0522 03:49:35.888403 19252 sgd_solver.cpp:106] Iteration 11250, lr = 0.004
I0522 03:49:48.044309 19252 solver.cpp:237] Iteration 12000, loss = 1.19816
I0522 03:49:48.044347 19252 solver.cpp:253]     Train net output #0: loss = 1.19816 (* 1 = 1.19816 loss)
I0522 03:49:48.044361 19252 sgd_solver.cpp:106] Iteration 12000, lr = 0.004
I0522 03:50:00.198747 19252 solver.cpp:237] Iteration 12750, loss = 1.29254
I0522 03:50:00.198909 19252 solver.cpp:253]     Train net output #0: loss = 1.29254 (* 1 = 1.29254 loss)
I0522 03:50:00.198923 19252 sgd_solver.cpp:106] Iteration 12750, lr = 0.004
I0522 03:50:12.363157 19252 solver.cpp:237] Iteration 13500, loss = 1.79824
I0522 03:50:12.363193 19252 solver.cpp:253]     Train net output #0: loss = 1.79824 (* 1 = 1.79824 loss)
I0522 03:50:12.363209 19252 sgd_solver.cpp:106] Iteration 13500, lr = 0.004
I0522 03:50:24.429278 19252 solver.cpp:237] Iteration 14250, loss = 1.32745
I0522 03:50:24.429319 19252 solver.cpp:253]     Train net output #0: loss = 1.32745 (* 1 = 1.32745 loss)
I0522 03:50:24.429339 19252 sgd_solver.cpp:106] Iteration 14250, lr = 0.004
I0522 03:50:36.476678 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_15000.caffemodel
I0522 03:50:36.525437 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_15000.solverstate
I0522 03:50:36.550707 19252 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 03:51:28.508940 19252 solver.cpp:409]     Test net output #0: accuracy = 0.854742
I0522 03:51:28.509093 19252 solver.cpp:409]     Test net output #1: loss = 0.487127 (* 1 = 0.487127 loss)
I0522 03:51:50.739545 19252 solver.cpp:237] Iteration 15000, loss = 1.16699
I0522 03:51:50.739596 19252 solver.cpp:253]     Train net output #0: loss = 1.16699 (* 1 = 1.16699 loss)
I0522 03:51:50.739612 19252 sgd_solver.cpp:106] Iteration 15000, lr = 0.004
I0522 03:52:02.876564 19252 solver.cpp:237] Iteration 15750, loss = 1.0478
I0522 03:52:02.876716 19252 solver.cpp:253]     Train net output #0: loss = 1.0478 (* 1 = 1.0478 loss)
I0522 03:52:02.876730 19252 sgd_solver.cpp:106] Iteration 15750, lr = 0.004
I0522 03:52:15.025884 19252 solver.cpp:237] Iteration 16500, loss = 1.59149
I0522 03:52:15.025929 19252 solver.cpp:253]     Train net output #0: loss = 1.59149 (* 1 = 1.59149 loss)
I0522 03:52:15.025943 19252 sgd_solver.cpp:106] Iteration 16500, lr = 0.004
I0522 03:52:27.117770 19252 solver.cpp:237] Iteration 17250, loss = 1.74485
I0522 03:52:27.117807 19252 solver.cpp:253]     Train net output #0: loss = 1.74485 (* 1 = 1.74485 loss)
I0522 03:52:27.117823 19252 sgd_solver.cpp:106] Iteration 17250, lr = 0.004
I0522 03:52:39.262975 19252 solver.cpp:237] Iteration 18000, loss = 1.33024
I0522 03:52:39.263125 19252 solver.cpp:253]     Train net output #0: loss = 1.33024 (* 1 = 1.33024 loss)
I0522 03:52:39.263141 19252 sgd_solver.cpp:106] Iteration 18000, lr = 0.004
I0522 03:52:51.429865 19252 solver.cpp:237] Iteration 18750, loss = 1.48653
I0522 03:52:51.429901 19252 solver.cpp:253]     Train net output #0: loss = 1.48653 (* 1 = 1.48653 loss)
I0522 03:52:51.429918 19252 sgd_solver.cpp:106] Iteration 18750, lr = 0.004
I0522 03:53:03.580633 19252 solver.cpp:237] Iteration 19500, loss = 1.33299
I0522 03:53:03.580674 19252 solver.cpp:253]     Train net output #0: loss = 1.33299 (* 1 = 1.33299 loss)
I0522 03:53:03.580690 19252 sgd_solver.cpp:106] Iteration 19500, lr = 0.004
I0522 03:54:08.899523 19252 solver.cpp:237] Iteration 20250, loss = 1.71518
I0522 03:54:08.899684 19252 solver.cpp:253]     Train net output #0: loss = 1.71518 (* 1 = 1.71518 loss)
I0522 03:54:08.899699 19252 sgd_solver.cpp:106] Iteration 20250, lr = 0.004
I0522 03:54:21.035835 19252 solver.cpp:237] Iteration 21000, loss = 1.11975
I0522 03:54:21.035871 19252 solver.cpp:253]     Train net output #0: loss = 1.11975 (* 1 = 1.11975 loss)
I0522 03:54:21.035887 19252 sgd_solver.cpp:106] Iteration 21000, lr = 0.004
I0522 03:54:33.179546 19252 solver.cpp:237] Iteration 21750, loss = 0.934596
I0522 03:54:33.179584 19252 solver.cpp:253]     Train net output #0: loss = 0.934596 (* 1 = 0.934596 loss)
I0522 03:54:33.179600 19252 sgd_solver.cpp:106] Iteration 21750, lr = 0.004
I0522 03:54:45.293876 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_22500.caffemodel
I0522 03:54:45.346130 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_22500.solverstate
I0522 03:54:45.379756 19252 solver.cpp:237] Iteration 22500, loss = 1.4336
I0522 03:54:45.379802 19252 solver.cpp:253]     Train net output #0: loss = 1.4336 (* 1 = 1.4336 loss)
I0522 03:54:45.379820 19252 sgd_solver.cpp:106] Iteration 22500, lr = 0.004
I0522 03:54:57.506629 19252 solver.cpp:237] Iteration 23250, loss = 1.34985
I0522 03:54:57.506666 19252 solver.cpp:253]     Train net output #0: loss = 1.34985 (* 1 = 1.34985 loss)
I0522 03:54:57.506683 19252 sgd_solver.cpp:106] Iteration 23250, lr = 0.004
I0522 03:55:09.627670 19252 solver.cpp:237] Iteration 24000, loss = 0.848925
I0522 03:55:09.627712 19252 solver.cpp:253]     Train net output #0: loss = 0.848924 (* 1 = 0.848924 loss)
I0522 03:55:09.627727 19252 sgd_solver.cpp:106] Iteration 24000, lr = 0.004
I0522 03:55:21.741951 19252 solver.cpp:237] Iteration 24750, loss = 1.39439
I0522 03:55:21.742100 19252 solver.cpp:253]     Train net output #0: loss = 1.39439 (* 1 = 1.39439 loss)
I0522 03:55:21.742112 19252 sgd_solver.cpp:106] Iteration 24750, lr = 0.004
I0522 03:55:56.178673 19252 solver.cpp:237] Iteration 25500, loss = 1.2052
I0522 03:55:56.178836 19252 solver.cpp:253]     Train net output #0: loss = 1.2052 (* 1 = 1.2052 loss)
I0522 03:55:56.178850 19252 sgd_solver.cpp:106] Iteration 25500, lr = 0.004
I0522 03:56:08.328164 19252 solver.cpp:237] Iteration 26250, loss = 1.39877
I0522 03:56:08.328200 19252 solver.cpp:253]     Train net output #0: loss = 1.39877 (* 1 = 1.39877 loss)
I0522 03:56:08.328217 19252 sgd_solver.cpp:106] Iteration 26250, lr = 0.004
I0522 03:56:20.467707 19252 solver.cpp:237] Iteration 27000, loss = 1.28535
I0522 03:56:20.467756 19252 solver.cpp:253]     Train net output #0: loss = 1.28535 (* 1 = 1.28535 loss)
I0522 03:56:20.467770 19252 sgd_solver.cpp:106] Iteration 27000, lr = 0.004
I0522 03:56:32.616266 19252 solver.cpp:237] Iteration 27750, loss = 1.13701
I0522 03:56:32.616407 19252 solver.cpp:253]     Train net output #0: loss = 1.13701 (* 1 = 1.13701 loss)
I0522 03:56:32.616421 19252 sgd_solver.cpp:106] Iteration 27750, lr = 0.004
I0522 03:56:44.760781 19252 solver.cpp:237] Iteration 28500, loss = 1.29754
I0522 03:56:44.760825 19252 solver.cpp:253]     Train net output #0: loss = 1.29753 (* 1 = 1.29753 loss)
I0522 03:56:44.760844 19252 sgd_solver.cpp:106] Iteration 28500, lr = 0.004
I0522 03:56:56.893501 19252 solver.cpp:237] Iteration 29250, loss = 0.654132
I0522 03:56:56.893537 19252 solver.cpp:253]     Train net output #0: loss = 0.65413 (* 1 = 0.65413 loss)
I0522 03:56:56.893553 19252 sgd_solver.cpp:106] Iteration 29250, lr = 0.004
I0522 03:57:09.036761 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_30000.caffemodel
I0522 03:57:09.088140 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_30000.solverstate
I0522 03:57:09.116595 19252 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 03:58:21.959277 19252 solver.cpp:409]     Test net output #0: accuracy = 0.867149
I0522 03:58:21.959435 19252 solver.cpp:409]     Test net output #1: loss = 0.447844 (* 1 = 0.447844 loss)
I0522 03:58:44.124218 19252 solver.cpp:237] Iteration 30000, loss = 0.93072
I0522 03:58:44.124270 19252 solver.cpp:253]     Train net output #0: loss = 0.930719 (* 1 = 0.930719 loss)
I0522 03:58:44.124287 19252 sgd_solver.cpp:106] Iteration 30000, lr = 0.004
I0522 03:58:56.265053 19252 solver.cpp:237] Iteration 30750, loss = 0.952572
I0522 03:58:56.265213 19252 solver.cpp:253]     Train net output #0: loss = 0.952571 (* 1 = 0.952571 loss)
I0522 03:58:56.265228 19252 sgd_solver.cpp:106] Iteration 30750, lr = 0.004
I0522 03:59:08.423939 19252 solver.cpp:237] Iteration 31500, loss = 1.0233
I0522 03:59:08.423974 19252 solver.cpp:253]     Train net output #0: loss = 1.0233 (* 1 = 1.0233 loss)
I0522 03:59:08.423986 19252 sgd_solver.cpp:106] Iteration 31500, lr = 0.004
I0522 03:59:20.589911 19252 solver.cpp:237] Iteration 32250, loss = 1.30774
I0522 03:59:20.589954 19252 solver.cpp:253]     Train net output #0: loss = 1.30773 (* 1 = 1.30773 loss)
I0522 03:59:20.589967 19252 sgd_solver.cpp:106] Iteration 32250, lr = 0.004
I0522 03:59:32.760975 19252 solver.cpp:237] Iteration 33000, loss = 1.65718
I0522 03:59:32.761119 19252 solver.cpp:253]     Train net output #0: loss = 1.65718 (* 1 = 1.65718 loss)
I0522 03:59:32.761134 19252 sgd_solver.cpp:106] Iteration 33000, lr = 0.004
I0522 03:59:44.879593 19252 solver.cpp:237] Iteration 33750, loss = 1.34681
I0522 03:59:44.879633 19252 solver.cpp:253]     Train net output #0: loss = 1.34681 (* 1 = 1.34681 loss)
I0522 03:59:44.879649 19252 sgd_solver.cpp:106] Iteration 33750, lr = 0.004
I0522 03:59:57.002616 19252 solver.cpp:237] Iteration 34500, loss = 1.68947
I0522 03:59:57.002652 19252 solver.cpp:253]     Train net output #0: loss = 1.68947 (* 1 = 1.68947 loss)
I0522 03:59:57.002666 19252 sgd_solver.cpp:106] Iteration 34500, lr = 0.004
I0522 04:00:31.450316 19252 solver.cpp:237] Iteration 35250, loss = 0.882836
I0522 04:00:31.450485 19252 solver.cpp:253]     Train net output #0: loss = 0.882835 (* 1 = 0.882835 loss)
I0522 04:00:31.450501 19252 sgd_solver.cpp:106] Iteration 35250, lr = 0.004
I0522 04:00:43.610798 19252 solver.cpp:237] Iteration 36000, loss = 0.935533
I0522 04:00:43.610834 19252 solver.cpp:253]     Train net output #0: loss = 0.935532 (* 1 = 0.935532 loss)
I0522 04:00:43.610851 19252 sgd_solver.cpp:106] Iteration 36000, lr = 0.004
I0522 04:00:55.783849 19252 solver.cpp:237] Iteration 36750, loss = 1.19134
I0522 04:00:55.783895 19252 solver.cpp:253]     Train net output #0: loss = 1.19134 (* 1 = 1.19134 loss)
I0522 04:00:55.783908 19252 sgd_solver.cpp:106] Iteration 36750, lr = 0.004
I0522 04:01:07.933393 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_37500.caffemodel
I0522 04:01:07.985141 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_37500.solverstate
I0522 04:01:08.018661 19252 solver.cpp:237] Iteration 37500, loss = 1.13072
I0522 04:01:08.018712 19252 solver.cpp:253]     Train net output #0: loss = 1.13072 (* 1 = 1.13072 loss)
I0522 04:01:08.018728 19252 sgd_solver.cpp:106] Iteration 37500, lr = 0.004
I0522 04:01:20.145393 19252 solver.cpp:237] Iteration 38250, loss = 1.65205
I0522 04:01:20.145440 19252 solver.cpp:253]     Train net output #0: loss = 1.65205 (* 1 = 1.65205 loss)
I0522 04:01:20.145457 19252 sgd_solver.cpp:106] Iteration 38250, lr = 0.004
I0522 04:01:32.219002 19252 solver.cpp:237] Iteration 39000, loss = 1.20634
I0522 04:01:32.219038 19252 solver.cpp:253]     Train net output #0: loss = 1.20634 (* 1 = 1.20634 loss)
I0522 04:01:32.219053 19252 sgd_solver.cpp:106] Iteration 39000, lr = 0.004
I0522 04:01:44.356364 19252 solver.cpp:237] Iteration 39750, loss = 1.2134
I0522 04:01:44.356519 19252 solver.cpp:253]     Train net output #0: loss = 1.2134 (* 1 = 1.2134 loss)
I0522 04:01:44.356533 19252 sgd_solver.cpp:106] Iteration 39750, lr = 0.004
I0522 04:02:18.735183 19252 solver.cpp:237] Iteration 40500, loss = 0.894312
I0522 04:02:18.735363 19252 solver.cpp:253]     Train net output #0: loss = 0.894311 (* 1 = 0.894311 loss)
I0522 04:02:18.735378 19252 sgd_solver.cpp:106] Iteration 40500, lr = 0.004
I0522 04:02:30.902037 19252 solver.cpp:237] Iteration 41250, loss = 1.02228
I0522 04:02:30.902086 19252 solver.cpp:253]     Train net output #0: loss = 1.02228 (* 1 = 1.02228 loss)
I0522 04:02:30.902101 19252 sgd_solver.cpp:106] Iteration 41250, lr = 0.004
I0522 04:02:43.071415 19252 solver.cpp:237] Iteration 42000, loss = 1.46593
I0522 04:02:43.071450 19252 solver.cpp:253]     Train net output #0: loss = 1.46593 (* 1 = 1.46593 loss)
I0522 04:02:43.071467 19252 sgd_solver.cpp:106] Iteration 42000, lr = 0.004
I0522 04:02:55.238567 19252 solver.cpp:237] Iteration 42750, loss = 1.32572
I0522 04:02:55.238724 19252 solver.cpp:253]     Train net output #0: loss = 1.32572 (* 1 = 1.32572 loss)
I0522 04:02:55.238739 19252 sgd_solver.cpp:106] Iteration 42750, lr = 0.004
I0522 04:03:07.398500 19252 solver.cpp:237] Iteration 43500, loss = 1.24343
I0522 04:03:07.398537 19252 solver.cpp:253]     Train net output #0: loss = 1.24343 (* 1 = 1.24343 loss)
I0522 04:03:07.398550 19252 sgd_solver.cpp:106] Iteration 43500, lr = 0.004
I0522 04:03:19.549006 19252 solver.cpp:237] Iteration 44250, loss = 1.24512
I0522 04:03:19.549057 19252 solver.cpp:253]     Train net output #0: loss = 1.24511 (* 1 = 1.24511 loss)
I0522 04:03:19.549070 19252 sgd_solver.cpp:106] Iteration 44250, lr = 0.004
I0522 04:03:31.667934 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_45000.caffemodel
I0522 04:03:31.716917 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_45000.solverstate
I0522 04:03:31.743296 19252 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 04:04:23.466802 19252 solver.cpp:409]     Test net output #0: accuracy = 0.873487
I0522 04:04:23.466964 19252 solver.cpp:409]     Test net output #1: loss = 0.441909 (* 1 = 0.441909 loss)
I0522 04:04:45.613422 19252 solver.cpp:237] Iteration 45000, loss = 0.990675
I0522 04:04:45.613476 19252 solver.cpp:253]     Train net output #0: loss = 0.990674 (* 1 = 0.990674 loss)
I0522 04:04:45.613492 19252 sgd_solver.cpp:106] Iteration 45000, lr = 0.004
I0522 04:04:57.697937 19252 solver.cpp:237] Iteration 45750, loss = 1.12984
I0522 04:04:57.698091 19252 solver.cpp:253]     Train net output #0: loss = 1.12984 (* 1 = 1.12984 loss)
I0522 04:04:57.698104 19252 sgd_solver.cpp:106] Iteration 45750, lr = 0.004
I0522 04:05:09.817855 19252 solver.cpp:237] Iteration 46500, loss = 1.24154
I0522 04:05:09.817903 19252 solver.cpp:253]     Train net output #0: loss = 1.24154 (* 1 = 1.24154 loss)
I0522 04:05:09.817919 19252 sgd_solver.cpp:106] Iteration 46500, lr = 0.004
I0522 04:05:21.943007 19252 solver.cpp:237] Iteration 47250, loss = 1.14776
I0522 04:05:21.943043 19252 solver.cpp:253]     Train net output #0: loss = 1.14776 (* 1 = 1.14776 loss)
I0522 04:05:21.943060 19252 sgd_solver.cpp:106] Iteration 47250, lr = 0.004
I0522 04:05:34.016688 19252 solver.cpp:237] Iteration 48000, loss = 0.942617
I0522 04:05:34.016844 19252 solver.cpp:253]     Train net output #0: loss = 0.942616 (* 1 = 0.942616 loss)
I0522 04:05:34.016860 19252 sgd_solver.cpp:106] Iteration 48000, lr = 0.004
I0522 04:05:46.109266 19252 solver.cpp:237] Iteration 48750, loss = 1.29694
I0522 04:05:46.109302 19252 solver.cpp:253]     Train net output #0: loss = 1.29693 (* 1 = 1.29693 loss)
I0522 04:05:46.109318 19252 sgd_solver.cpp:106] Iteration 48750, lr = 0.004
I0522 04:05:58.244056 19252 solver.cpp:237] Iteration 49500, loss = 1.40573
I0522 04:05:58.244102 19252 solver.cpp:253]     Train net output #0: loss = 1.40572 (* 1 = 1.40572 loss)
I0522 04:05:58.244118 19252 sgd_solver.cpp:106] Iteration 49500, lr = 0.004
I0522 04:06:32.529191 19252 solver.cpp:237] Iteration 50250, loss = 1.01523
I0522 04:06:32.529369 19252 solver.cpp:253]     Train net output #0: loss = 1.01523 (* 1 = 1.01523 loss)
I0522 04:06:32.529383 19252 sgd_solver.cpp:106] Iteration 50250, lr = 0.004
I0522 04:06:44.664671 19252 solver.cpp:237] Iteration 51000, loss = 0.816644
I0522 04:06:44.664722 19252 solver.cpp:253]     Train net output #0: loss = 0.816644 (* 1 = 0.816644 loss)
I0522 04:06:44.664736 19252 sgd_solver.cpp:106] Iteration 51000, lr = 0.004
I0522 04:06:56.799849 19252 solver.cpp:237] Iteration 51750, loss = 1.03565
I0522 04:06:56.799885 19252 solver.cpp:253]     Train net output #0: loss = 1.03565 (* 1 = 1.03565 loss)
I0522 04:06:56.799897 19252 sgd_solver.cpp:106] Iteration 51750, lr = 0.004
I0522 04:07:08.925654 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_52500.caffemodel
I0522 04:07:08.975249 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_52500.solverstate
I0522 04:07:09.007092 19252 solver.cpp:237] Iteration 52500, loss = 1.33296
I0522 04:07:09.007138 19252 solver.cpp:253]     Train net output #0: loss = 1.33296 (* 1 = 1.33296 loss)
I0522 04:07:09.007154 19252 sgd_solver.cpp:106] Iteration 52500, lr = 0.004
I0522 04:07:21.172153 19252 solver.cpp:237] Iteration 53250, loss = 1.33185
I0522 04:07:21.172189 19252 solver.cpp:253]     Train net output #0: loss = 1.33185 (* 1 = 1.33185 loss)
I0522 04:07:21.172206 19252 sgd_solver.cpp:106] Iteration 53250, lr = 0.004
I0522 04:07:33.319988 19252 solver.cpp:237] Iteration 54000, loss = 1.33197
I0522 04:07:33.320031 19252 solver.cpp:253]     Train net output #0: loss = 1.33197 (* 1 = 1.33197 loss)
I0522 04:07:33.320046 19252 sgd_solver.cpp:106] Iteration 54000, lr = 0.004
I0522 04:07:45.465490 19252 solver.cpp:237] Iteration 54750, loss = 0.767973
I0522 04:07:45.465641 19252 solver.cpp:253]     Train net output #0: loss = 0.767972 (* 1 = 0.767972 loss)
I0522 04:07:45.465656 19252 sgd_solver.cpp:106] Iteration 54750, lr = 0.004
I0522 04:08:19.751765 19252 solver.cpp:237] Iteration 55500, loss = 1.07827
I0522 04:08:19.751934 19252 solver.cpp:253]     Train net output #0: loss = 1.07827 (* 1 = 1.07827 loss)
I0522 04:08:19.751948 19252 sgd_solver.cpp:106] Iteration 55500, lr = 0.004
I0522 04:08:31.902351 19252 solver.cpp:237] Iteration 56250, loss = 1.56699
I0522 04:08:31.902387 19252 solver.cpp:253]     Train net output #0: loss = 1.56699 (* 1 = 1.56699 loss)
I0522 04:08:31.902405 19252 sgd_solver.cpp:106] Iteration 56250, lr = 0.004
I0522 04:08:44.014530 19252 solver.cpp:237] Iteration 57000, loss = 1.67122
I0522 04:08:44.014578 19252 solver.cpp:253]     Train net output #0: loss = 1.67122 (* 1 = 1.67122 loss)
I0522 04:08:44.014591 19252 sgd_solver.cpp:106] Iteration 57000, lr = 0.004
I0522 04:08:56.130650 19252 solver.cpp:237] Iteration 57750, loss = 1.60826
I0522 04:08:56.130794 19252 solver.cpp:253]     Train net output #0: loss = 1.60826 (* 1 = 1.60826 loss)
I0522 04:08:56.130808 19252 sgd_solver.cpp:106] Iteration 57750, lr = 0.004
I0522 04:09:08.242130 19252 solver.cpp:237] Iteration 58500, loss = 0.919351
I0522 04:09:08.242167 19252 solver.cpp:253]     Train net output #0: loss = 0.919349 (* 1 = 0.919349 loss)
I0522 04:09:08.242183 19252 sgd_solver.cpp:106] Iteration 58500, lr = 0.004
I0522 04:09:20.349180 19252 solver.cpp:237] Iteration 59250, loss = 1.03391
I0522 04:09:20.349225 19252 solver.cpp:253]     Train net output #0: loss = 1.03391 (* 1 = 1.03391 loss)
I0522 04:09:20.349239 19252 sgd_solver.cpp:106] Iteration 59250, lr = 0.004
I0522 04:09:32.445027 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_60000.caffemodel
I0522 04:09:32.494174 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_60000.solverstate
I0522 04:09:32.520746 19252 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 04:10:45.307958 19252 solver.cpp:409]     Test net output #0: accuracy = 0.874729
I0522 04:10:45.308130 19252 solver.cpp:409]     Test net output #1: loss = 0.402307 (* 1 = 0.402307 loss)
I0522 04:11:07.540382 19252 solver.cpp:237] Iteration 60000, loss = 1.46345
I0522 04:11:07.540434 19252 solver.cpp:253]     Train net output #0: loss = 1.46345 (* 1 = 1.46345 loss)
I0522 04:11:07.540449 19252 sgd_solver.cpp:106] Iteration 60000, lr = 0.004
I0522 04:11:19.652614 19252 solver.cpp:237] Iteration 60750, loss = 1.30919
I0522 04:11:19.652786 19252 solver.cpp:253]     Train net output #0: loss = 1.30918 (* 1 = 1.30918 loss)
I0522 04:11:19.652801 19252 sgd_solver.cpp:106] Iteration 60750, lr = 0.004
I0522 04:11:31.767976 19252 solver.cpp:237] Iteration 61500, loss = 0.952958
I0522 04:11:31.768012 19252 solver.cpp:253]     Train net output #0: loss = 0.952957 (* 1 = 0.952957 loss)
I0522 04:11:31.768028 19252 sgd_solver.cpp:106] Iteration 61500, lr = 0.004
I0522 04:11:43.884788 19252 solver.cpp:237] Iteration 62250, loss = 0.672303
I0522 04:11:43.884835 19252 solver.cpp:253]     Train net output #0: loss = 0.672302 (* 1 = 0.672302 loss)
I0522 04:11:43.884850 19252 sgd_solver.cpp:106] Iteration 62250, lr = 0.004
I0522 04:11:56.026876 19252 solver.cpp:237] Iteration 63000, loss = 1.15864
I0522 04:11:56.027021 19252 solver.cpp:253]     Train net output #0: loss = 1.15864 (* 1 = 1.15864 loss)
I0522 04:11:56.027035 19252 sgd_solver.cpp:106] Iteration 63000, lr = 0.004
I0522 04:12:08.208997 19252 solver.cpp:237] Iteration 63750, loss = 1.26288
I0522 04:12:08.209041 19252 solver.cpp:253]     Train net output #0: loss = 1.26288 (* 1 = 1.26288 loss)
I0522 04:12:08.209056 19252 sgd_solver.cpp:106] Iteration 63750, lr = 0.004
I0522 04:12:20.413715 19252 solver.cpp:237] Iteration 64500, loss = 1.33108
I0522 04:12:20.413751 19252 solver.cpp:253]     Train net output #0: loss = 1.33108 (* 1 = 1.33108 loss)
I0522 04:12:20.413767 19252 sgd_solver.cpp:106] Iteration 64500, lr = 0.004
I0522 04:12:54.749634 19252 solver.cpp:237] Iteration 65250, loss = 1.03725
I0522 04:12:54.749807 19252 solver.cpp:253]     Train net output #0: loss = 1.03725 (* 1 = 1.03725 loss)
I0522 04:12:54.749821 19252 sgd_solver.cpp:106] Iteration 65250, lr = 0.004
I0522 04:13:06.864647 19252 solver.cpp:237] Iteration 66000, loss = 1.2706
I0522 04:13:06.864683 19252 solver.cpp:253]     Train net output #0: loss = 1.2706 (* 1 = 1.2706 loss)
I0522 04:13:06.864699 19252 sgd_solver.cpp:106] Iteration 66000, lr = 0.004
I0522 04:13:19.017004 19252 solver.cpp:237] Iteration 66750, loss = 1.54969
I0522 04:13:19.017048 19252 solver.cpp:253]     Train net output #0: loss = 1.54969 (* 1 = 1.54969 loss)
I0522 04:13:19.017063 19252 sgd_solver.cpp:106] Iteration 66750, lr = 0.004
I0522 04:13:31.173835 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_67500.caffemodel
I0522 04:13:31.224696 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_67500.solverstate
I0522 04:13:31.257994 19252 solver.cpp:237] Iteration 67500, loss = 1.54497
I0522 04:13:31.258044 19252 solver.cpp:253]     Train net output #0: loss = 1.54497 (* 1 = 1.54497 loss)
I0522 04:13:31.258060 19252 sgd_solver.cpp:106] Iteration 67500, lr = 0.004
I0522 04:13:43.428361 19252 solver.cpp:237] Iteration 68250, loss = 1.19508
I0522 04:13:43.428400 19252 solver.cpp:253]     Train net output #0: loss = 1.19508 (* 1 = 1.19508 loss)
I0522 04:13:43.428413 19252 sgd_solver.cpp:106] Iteration 68250, lr = 0.004
I0522 04:13:55.582710 19252 solver.cpp:237] Iteration 69000, loss = 1.52093
I0522 04:13:55.582746 19252 solver.cpp:253]     Train net output #0: loss = 1.52093 (* 1 = 1.52093 loss)
I0522 04:13:55.582767 19252 sgd_solver.cpp:106] Iteration 69000, lr = 0.004
I0522 04:14:07.708966 19252 solver.cpp:237] Iteration 69750, loss = 1.29975
I0522 04:14:07.709128 19252 solver.cpp:253]     Train net output #0: loss = 1.29975 (* 1 = 1.29975 loss)
I0522 04:14:07.709141 19252 sgd_solver.cpp:106] Iteration 69750, lr = 0.004
I0522 04:14:42.034167 19252 solver.cpp:237] Iteration 70500, loss = 1.29686
I0522 04:14:42.034339 19252 solver.cpp:253]     Train net output #0: loss = 1.29686 (* 1 = 1.29686 loss)
I0522 04:14:42.034354 19252 sgd_solver.cpp:106] Iteration 70500, lr = 0.004
I0522 04:14:54.203227 19252 solver.cpp:237] Iteration 71250, loss = 1.17133
I0522 04:14:54.203263 19252 solver.cpp:253]     Train net output #0: loss = 1.17133 (* 1 = 1.17133 loss)
I0522 04:14:54.203279 19252 sgd_solver.cpp:106] Iteration 71250, lr = 0.004
I0522 04:15:06.370710 19252 solver.cpp:237] Iteration 72000, loss = 1.13197
I0522 04:15:06.370760 19252 solver.cpp:253]     Train net output #0: loss = 1.13197 (* 1 = 1.13197 loss)
I0522 04:15:06.370774 19252 sgd_solver.cpp:106] Iteration 72000, lr = 0.004
I0522 04:15:18.501345 19252 solver.cpp:237] Iteration 72750, loss = 1.22794
I0522 04:15:18.501493 19252 solver.cpp:253]     Train net output #0: loss = 1.22794 (* 1 = 1.22794 loss)
I0522 04:15:18.501508 19252 sgd_solver.cpp:106] Iteration 72750, lr = 0.004
I0522 04:15:30.635069 19252 solver.cpp:237] Iteration 73500, loss = 1.09456
I0522 04:15:30.635119 19252 solver.cpp:253]     Train net output #0: loss = 1.09456 (* 1 = 1.09456 loss)
I0522 04:15:30.635133 19252 sgd_solver.cpp:106] Iteration 73500, lr = 0.004
I0522 04:15:42.773953 19252 solver.cpp:237] Iteration 74250, loss = 1.46258
I0522 04:15:42.773989 19252 solver.cpp:253]     Train net output #0: loss = 1.46258 (* 1 = 1.46258 loss)
I0522 04:15:42.774004 19252 sgd_solver.cpp:106] Iteration 74250, lr = 0.004
I0522 04:15:54.906652 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_75000.caffemodel
I0522 04:15:54.957985 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_75000.solverstate
I0522 04:15:54.987256 19252 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 04:16:46.920696 19252 solver.cpp:409]     Test net output #0: accuracy = 0.881656
I0522 04:16:46.920862 19252 solver.cpp:409]     Test net output #1: loss = 0.392313 (* 1 = 0.392313 loss)
I0522 04:17:07.789939 19252 solver.cpp:237] Iteration 75000, loss = 0.930621
I0522 04:17:07.789993 19252 solver.cpp:253]     Train net output #0: loss = 0.93062 (* 1 = 0.93062 loss)
I0522 04:17:07.790007 19252 sgd_solver.cpp:106] Iteration 75000, lr = 0.004
I0522 04:17:20.002410 19252 solver.cpp:237] Iteration 75750, loss = 0.975119
I0522 04:17:20.002564 19252 solver.cpp:253]     Train net output #0: loss = 0.975118 (* 1 = 0.975118 loss)
I0522 04:17:20.002579 19252 sgd_solver.cpp:106] Iteration 75750, lr = 0.004
I0522 04:17:32.208922 19252 solver.cpp:237] Iteration 76500, loss = 1.48427
I0522 04:17:32.208968 19252 solver.cpp:253]     Train net output #0: loss = 1.48427 (* 1 = 1.48427 loss)
I0522 04:17:32.208983 19252 sgd_solver.cpp:106] Iteration 76500, lr = 0.004
I0522 04:17:44.388804 19252 solver.cpp:237] Iteration 77250, loss = 1.42906
I0522 04:17:44.388841 19252 solver.cpp:253]     Train net output #0: loss = 1.42906 (* 1 = 1.42906 loss)
I0522 04:17:44.388857 19252 sgd_solver.cpp:106] Iteration 77250, lr = 0.004
I0522 04:17:56.551465 19252 solver.cpp:237] Iteration 78000, loss = 1.01044
I0522 04:17:56.551633 19252 solver.cpp:253]     Train net output #0: loss = 1.01044 (* 1 = 1.01044 loss)
I0522 04:17:56.551647 19252 sgd_solver.cpp:106] Iteration 78000, lr = 0.004
I0522 04:18:08.727541 19252 solver.cpp:237] Iteration 78750, loss = 0.983297
I0522 04:18:08.727578 19252 solver.cpp:253]     Train net output #0: loss = 0.983296 (* 1 = 0.983296 loss)
I0522 04:18:08.727593 19252 sgd_solver.cpp:106] Iteration 78750, lr = 0.004
I0522 04:18:20.951323 19252 solver.cpp:237] Iteration 79500, loss = 1.53887
I0522 04:18:20.951366 19252 solver.cpp:253]     Train net output #0: loss = 1.53887 (* 1 = 1.53887 loss)
I0522 04:18:20.951382 19252 sgd_solver.cpp:106] Iteration 79500, lr = 0.004
I0522 04:18:54.026216 19252 solver.cpp:237] Iteration 80250, loss = 1.17538
I0522 04:18:54.026396 19252 solver.cpp:253]     Train net output #0: loss = 1.17538 (* 1 = 1.17538 loss)
I0522 04:18:54.026412 19252 sgd_solver.cpp:106] Iteration 80250, lr = 0.004
I0522 04:19:06.251679 19252 solver.cpp:237] Iteration 81000, loss = 1.03355
I0522 04:19:06.251715 19252 solver.cpp:253]     Train net output #0: loss = 1.03355 (* 1 = 1.03355 loss)
I0522 04:19:06.251731 19252 sgd_solver.cpp:106] Iteration 81000, lr = 0.004
I0522 04:19:18.457054 19252 solver.cpp:237] Iteration 81750, loss = 1.98099
I0522 04:19:18.457101 19252 solver.cpp:253]     Train net output #0: loss = 1.98099 (* 1 = 1.98099 loss)
I0522 04:19:18.457116 19252 sgd_solver.cpp:106] Iteration 81750, lr = 0.004
I0522 04:19:30.668987 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_82500.caffemodel
I0522 04:19:30.722599 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_82500.solverstate
I0522 04:19:30.754060 19252 solver.cpp:237] Iteration 82500, loss = 1.07972
I0522 04:19:30.754106 19252 solver.cpp:253]     Train net output #0: loss = 1.07972 (* 1 = 1.07972 loss)
I0522 04:19:30.754122 19252 sgd_solver.cpp:106] Iteration 82500, lr = 0.004
I0522 04:19:43.005719 19252 solver.cpp:237] Iteration 83250, loss = 1.20009
I0522 04:19:43.005767 19252 solver.cpp:253]     Train net output #0: loss = 1.20009 (* 1 = 1.20009 loss)
I0522 04:19:43.005781 19252 sgd_solver.cpp:106] Iteration 83250, lr = 0.004
I0522 04:19:55.241816 19252 solver.cpp:237] Iteration 84000, loss = 0.689886
I0522 04:19:55.241852 19252 solver.cpp:253]     Train net output #0: loss = 0.689885 (* 1 = 0.689885 loss)
I0522 04:19:55.241869 19252 sgd_solver.cpp:106] Iteration 84000, lr = 0.004
I0522 04:20:07.423599 19252 solver.cpp:237] Iteration 84750, loss = 1.24903
I0522 04:20:07.423768 19252 solver.cpp:253]     Train net output #0: loss = 1.24903 (* 1 = 1.24903 loss)
I0522 04:20:07.423784 19252 sgd_solver.cpp:106] Iteration 84750, lr = 0.004
I0522 04:20:40.496364 19252 solver.cpp:237] Iteration 85500, loss = 0.847522
I0522 04:20:40.496536 19252 solver.cpp:253]     Train net output #0: loss = 0.847521 (* 1 = 0.847521 loss)
I0522 04:20:40.496551 19252 sgd_solver.cpp:106] Iteration 85500, lr = 0.004
I0522 04:20:52.688011 19252 solver.cpp:237] Iteration 86250, loss = 0.999586
I0522 04:20:52.688056 19252 solver.cpp:253]     Train net output #0: loss = 0.999585 (* 1 = 0.999585 loss)
I0522 04:20:52.688071 19252 sgd_solver.cpp:106] Iteration 86250, lr = 0.004
I0522 04:21:04.918882 19252 solver.cpp:237] Iteration 87000, loss = 1.00055
I0522 04:21:04.918918 19252 solver.cpp:253]     Train net output #0: loss = 1.00055 (* 1 = 1.00055 loss)
I0522 04:21:04.918933 19252 sgd_solver.cpp:106] Iteration 87000, lr = 0.004
I0522 04:21:17.136163 19252 solver.cpp:237] Iteration 87750, loss = 1.08178
I0522 04:21:17.136332 19252 solver.cpp:253]     Train net output #0: loss = 1.08178 (* 1 = 1.08178 loss)
I0522 04:21:17.136345 19252 sgd_solver.cpp:106] Iteration 87750, lr = 0.004
I0522 04:21:29.352252 19252 solver.cpp:237] Iteration 88500, loss = 1.33296
I0522 04:21:29.352288 19252 solver.cpp:253]     Train net output #0: loss = 1.33296 (* 1 = 1.33296 loss)
I0522 04:21:29.352304 19252 sgd_solver.cpp:106] Iteration 88500, lr = 0.004
I0522 04:21:41.573248 19252 solver.cpp:237] Iteration 89250, loss = 1.20344
I0522 04:21:41.573292 19252 solver.cpp:253]     Train net output #0: loss = 1.20344 (* 1 = 1.20344 loss)
I0522 04:21:41.573307 19252 sgd_solver.cpp:106] Iteration 89250, lr = 0.004
I0522 04:21:53.809126 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_90000.caffemodel
I0522 04:21:53.859016 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_90000.solverstate
I0522 04:21:53.885833 19252 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 04:23:06.856359 19252 solver.cpp:409]     Test net output #0: accuracy = 0.885916
I0522 04:23:06.856529 19252 solver.cpp:409]     Test net output #1: loss = 0.372327 (* 1 = 0.372327 loss)
I0522 04:23:27.738770 19252 solver.cpp:237] Iteration 90000, loss = 1.22056
I0522 04:23:27.738822 19252 solver.cpp:253]     Train net output #0: loss = 1.22056 (* 1 = 1.22056 loss)
I0522 04:23:27.738838 19252 sgd_solver.cpp:106] Iteration 90000, lr = 0.004
I0522 04:23:39.883857 19252 solver.cpp:237] Iteration 90750, loss = 1.18377
I0522 04:23:39.884016 19252 solver.cpp:253]     Train net output #0: loss = 1.18376 (* 1 = 1.18376 loss)
I0522 04:23:39.884030 19252 sgd_solver.cpp:106] Iteration 90750, lr = 0.004
I0522 04:23:52.025450 19252 solver.cpp:237] Iteration 91500, loss = 1.1841
I0522 04:23:52.025499 19252 solver.cpp:253]     Train net output #0: loss = 1.1841 (* 1 = 1.1841 loss)
I0522 04:23:52.025513 19252 sgd_solver.cpp:106] Iteration 91500, lr = 0.004
I0522 04:24:04.163414 19252 solver.cpp:237] Iteration 92250, loss = 1.21626
I0522 04:24:04.163450 19252 solver.cpp:253]     Train net output #0: loss = 1.21626 (* 1 = 1.21626 loss)
I0522 04:24:04.163463 19252 sgd_solver.cpp:106] Iteration 92250, lr = 0.004
I0522 04:24:16.297157 19252 solver.cpp:237] Iteration 93000, loss = 1.10375
I0522 04:24:16.297324 19252 solver.cpp:253]     Train net output #0: loss = 1.10375 (* 1 = 1.10375 loss)
I0522 04:24:16.297339 19252 sgd_solver.cpp:106] Iteration 93000, lr = 0.004
I0522 04:24:28.472882 19252 solver.cpp:237] Iteration 93750, loss = 1.29003
I0522 04:24:28.472918 19252 solver.cpp:253]     Train net output #0: loss = 1.29003 (* 1 = 1.29003 loss)
I0522 04:24:28.472935 19252 sgd_solver.cpp:106] Iteration 93750, lr = 0.004
I0522 04:24:40.636840 19252 solver.cpp:237] Iteration 94500, loss = 0.857337
I0522 04:24:40.636896 19252 solver.cpp:253]     Train net output #0: loss = 0.857337 (* 1 = 0.857337 loss)
I0522 04:24:40.636910 19252 sgd_solver.cpp:106] Iteration 94500, lr = 0.004
I0522 04:25:13.636292 19252 solver.cpp:237] Iteration 95250, loss = 1.31036
I0522 04:25:13.636466 19252 solver.cpp:253]     Train net output #0: loss = 1.31036 (* 1 = 1.31036 loss)
I0522 04:25:13.636481 19252 sgd_solver.cpp:106] Iteration 95250, lr = 0.004
I0522 04:25:25.697595 19252 solver.cpp:237] Iteration 96000, loss = 1.17989
I0522 04:25:25.697644 19252 solver.cpp:253]     Train net output #0: loss = 1.17989 (* 1 = 1.17989 loss)
I0522 04:25:25.697659 19252 sgd_solver.cpp:106] Iteration 96000, lr = 0.004
I0522 04:25:37.759814 19252 solver.cpp:237] Iteration 96750, loss = 1.11881
I0522 04:25:37.759850 19252 solver.cpp:253]     Train net output #0: loss = 1.11881 (* 1 = 1.11881 loss)
I0522 04:25:37.759866 19252 sgd_solver.cpp:106] Iteration 96750, lr = 0.004
I0522 04:25:49.819319 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_97500.caffemodel
I0522 04:25:49.868379 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_97500.solverstate
I0522 04:25:49.899996 19252 solver.cpp:237] Iteration 97500, loss = 1.13568
I0522 04:25:49.900038 19252 solver.cpp:253]     Train net output #0: loss = 1.13568 (* 1 = 1.13568 loss)
I0522 04:25:49.900056 19252 sgd_solver.cpp:106] Iteration 97500, lr = 0.004
I0522 04:26:02.023205 19252 solver.cpp:237] Iteration 98250, loss = 0.755028
I0522 04:26:02.023242 19252 solver.cpp:253]     Train net output #0: loss = 0.755027 (* 1 = 0.755027 loss)
I0522 04:26:02.023258 19252 sgd_solver.cpp:106] Iteration 98250, lr = 0.004
I0522 04:26:14.130399 19252 solver.cpp:237] Iteration 99000, loss = 0.944161
I0522 04:26:14.130450 19252 solver.cpp:253]     Train net output #0: loss = 0.94416 (* 1 = 0.94416 loss)
I0522 04:26:14.130463 19252 sgd_solver.cpp:106] Iteration 99000, lr = 0.004
I0522 04:26:26.237808 19252 solver.cpp:237] Iteration 99750, loss = 1.46674
I0522 04:26:26.237974 19252 solver.cpp:253]     Train net output #0: loss = 1.46673 (* 1 = 1.46673 loss)
I0522 04:26:26.237989 19252 sgd_solver.cpp:106] Iteration 99750, lr = 0.004
I0522 04:26:59.248391 19252 solver.cpp:237] Iteration 100500, loss = 1.18597
I0522 04:26:59.248566 19252 solver.cpp:253]     Train net output #0: loss = 1.18597 (* 1 = 1.18597 loss)
I0522 04:26:59.248580 19252 sgd_solver.cpp:106] Iteration 100500, lr = 0.004
I0522 04:27:11.359341 19252 solver.cpp:237] Iteration 101250, loss = 1.88275
I0522 04:27:11.359388 19252 solver.cpp:253]     Train net output #0: loss = 1.88275 (* 1 = 1.88275 loss)
I0522 04:27:11.359403 19252 sgd_solver.cpp:106] Iteration 101250, lr = 0.004
I0522 04:27:23.503396 19252 solver.cpp:237] Iteration 102000, loss = 1.11562
I0522 04:27:23.503432 19252 solver.cpp:253]     Train net output #0: loss = 1.11562 (* 1 = 1.11562 loss)
I0522 04:27:23.503448 19252 sgd_solver.cpp:106] Iteration 102000, lr = 0.004
I0522 04:27:35.634237 19252 solver.cpp:237] Iteration 102750, loss = 1.01472
I0522 04:27:35.634393 19252 solver.cpp:253]     Train net output #0: loss = 1.01472 (* 1 = 1.01472 loss)
I0522 04:27:35.634407 19252 sgd_solver.cpp:106] Iteration 102750, lr = 0.004
I0522 04:27:47.762112 19252 solver.cpp:237] Iteration 103500, loss = 1.17554
I0522 04:27:47.762148 19252 solver.cpp:253]     Train net output #0: loss = 1.17553 (* 1 = 1.17553 loss)
I0522 04:27:47.762164 19252 sgd_solver.cpp:106] Iteration 103500, lr = 0.004
I0522 04:27:59.891993 19252 solver.cpp:237] Iteration 104250, loss = 0.835232
I0522 04:27:59.892033 19252 solver.cpp:253]     Train net output #0: loss = 0.835231 (* 1 = 0.835231 loss)
I0522 04:27:59.892047 19252 sgd_solver.cpp:106] Iteration 104250, lr = 0.004
I0522 04:28:11.968842 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_105000.caffemodel
I0522 04:28:12.017935 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_105000.solverstate
I0522 04:28:12.043218 19252 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 04:29:03.780150 19252 solver.cpp:409]     Test net output #0: accuracy = 0.883895
I0522 04:29:03.780320 19252 solver.cpp:409]     Test net output #1: loss = 0.389402 (* 1 = 0.389402 loss)
I0522 04:29:24.695966 19252 solver.cpp:237] Iteration 105000, loss = 0.872799
I0522 04:29:24.696020 19252 solver.cpp:253]     Train net output #0: loss = 0.872798 (* 1 = 0.872798 loss)
I0522 04:29:24.696035 19252 sgd_solver.cpp:106] Iteration 105000, lr = 0.004
I0522 04:29:36.819517 19252 solver.cpp:237] Iteration 105750, loss = 1.10865
I0522 04:29:36.819692 19252 solver.cpp:253]     Train net output #0: loss = 1.10865 (* 1 = 1.10865 loss)
I0522 04:29:36.819706 19252 sgd_solver.cpp:106] Iteration 105750, lr = 0.004
I0522 04:29:48.968046 19252 solver.cpp:237] Iteration 106500, loss = 1.18173
I0522 04:29:48.968081 19252 solver.cpp:253]     Train net output #0: loss = 1.18173 (* 1 = 1.18173 loss)
I0522 04:29:48.968097 19252 sgd_solver.cpp:106] Iteration 106500, lr = 0.004
I0522 04:30:01.107131 19252 solver.cpp:237] Iteration 107250, loss = 0.943798
I0522 04:30:01.107182 19252 solver.cpp:253]     Train net output #0: loss = 0.943797 (* 1 = 0.943797 loss)
I0522 04:30:01.107197 19252 sgd_solver.cpp:106] Iteration 107250, lr = 0.004
I0522 04:30:13.236723 19252 solver.cpp:237] Iteration 108000, loss = 1.76146
I0522 04:30:13.236892 19252 solver.cpp:253]     Train net output #0: loss = 1.76146 (* 1 = 1.76146 loss)
I0522 04:30:13.236907 19252 sgd_solver.cpp:106] Iteration 108000, lr = 0.004
I0522 04:30:25.301331 19252 solver.cpp:237] Iteration 108750, loss = 1.33129
I0522 04:30:25.301378 19252 solver.cpp:253]     Train net output #0: loss = 1.33129 (* 1 = 1.33129 loss)
I0522 04:30:25.301396 19252 sgd_solver.cpp:106] Iteration 108750, lr = 0.004
I0522 04:30:37.368155 19252 solver.cpp:237] Iteration 109500, loss = 0.82491
I0522 04:30:37.368191 19252 solver.cpp:253]     Train net output #0: loss = 0.82491 (* 1 = 0.82491 loss)
I0522 04:30:37.368207 19252 sgd_solver.cpp:106] Iteration 109500, lr = 0.004
I0522 04:31:10.331084 19252 solver.cpp:237] Iteration 110250, loss = 1.58865
I0522 04:31:10.331264 19252 solver.cpp:253]     Train net output #0: loss = 1.58865 (* 1 = 1.58865 loss)
I0522 04:31:10.331277 19252 sgd_solver.cpp:106] Iteration 110250, lr = 0.004
I0522 04:31:22.432884 19252 solver.cpp:237] Iteration 111000, loss = 1.29455
I0522 04:31:22.432931 19252 solver.cpp:253]     Train net output #0: loss = 1.29455 (* 1 = 1.29455 loss)
I0522 04:31:22.432945 19252 sgd_solver.cpp:106] Iteration 111000, lr = 0.004
I0522 04:31:34.532176 19252 solver.cpp:237] Iteration 111750, loss = 1.19802
I0522 04:31:34.532212 19252 solver.cpp:253]     Train net output #0: loss = 1.19802 (* 1 = 1.19802 loss)
I0522 04:31:34.532227 19252 sgd_solver.cpp:106] Iteration 111750, lr = 0.004
I0522 04:31:46.616945 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_112500.caffemodel
I0522 04:31:46.667670 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_112500.solverstate
I0522 04:31:46.699623 19252 solver.cpp:237] Iteration 112500, loss = 1.19616
I0522 04:31:46.699672 19252 solver.cpp:253]     Train net output #0: loss = 1.19616 (* 1 = 1.19616 loss)
I0522 04:31:46.699687 19252 sgd_solver.cpp:106] Iteration 112500, lr = 0.004
I0522 04:31:58.820664 19252 solver.cpp:237] Iteration 113250, loss = 1.1528
I0522 04:31:58.820700 19252 solver.cpp:253]     Train net output #0: loss = 1.1528 (* 1 = 1.1528 loss)
I0522 04:31:58.820716 19252 sgd_solver.cpp:106] Iteration 113250, lr = 0.004
I0522 04:32:10.920472 19252 solver.cpp:237] Iteration 114000, loss = 0.958376
I0522 04:32:10.920522 19252 solver.cpp:253]     Train net output #0: loss = 0.958375 (* 1 = 0.958375 loss)
I0522 04:32:10.920536 19252 sgd_solver.cpp:106] Iteration 114000, lr = 0.004
I0522 04:32:23.019695 19252 solver.cpp:237] Iteration 114750, loss = 1.12324
I0522 04:32:23.019848 19252 solver.cpp:253]     Train net output #0: loss = 1.12324 (* 1 = 1.12324 loss)
I0522 04:32:23.019862 19252 sgd_solver.cpp:106] Iteration 114750, lr = 0.004
I0522 04:32:56.110625 19252 solver.cpp:237] Iteration 115500, loss = 1.45887
I0522 04:32:56.110796 19252 solver.cpp:253]     Train net output #0: loss = 1.45887 (* 1 = 1.45887 loss)
I0522 04:32:56.110810 19252 sgd_solver.cpp:106] Iteration 115500, lr = 0.004
I0522 04:33:08.265899 19252 solver.cpp:237] Iteration 116250, loss = 0.88803
I0522 04:33:08.265936 19252 solver.cpp:253]     Train net output #0: loss = 0.888029 (* 1 = 0.888029 loss)
I0522 04:33:08.265952 19252 sgd_solver.cpp:106] Iteration 116250, lr = 0.004
I0522 04:33:20.427896 19252 solver.cpp:237] Iteration 117000, loss = 1.18419
I0522 04:33:20.427932 19252 solver.cpp:253]     Train net output #0: loss = 1.18419 (* 1 = 1.18419 loss)
I0522 04:33:20.427954 19252 sgd_solver.cpp:106] Iteration 117000, lr = 0.004
I0522 04:33:32.600441 19252 solver.cpp:237] Iteration 117750, loss = 1.58127
I0522 04:33:32.600590 19252 solver.cpp:253]     Train net output #0: loss = 1.58127 (* 1 = 1.58127 loss)
I0522 04:33:32.600605 19252 sgd_solver.cpp:106] Iteration 117750, lr = 0.004
I0522 04:33:44.762373 19252 solver.cpp:237] Iteration 118500, loss = 1.36146
I0522 04:33:44.762420 19252 solver.cpp:253]     Train net output #0: loss = 1.36146 (* 1 = 1.36146 loss)
I0522 04:33:44.762439 19252 sgd_solver.cpp:106] Iteration 118500, lr = 0.004
I0522 04:33:56.922056 19252 solver.cpp:237] Iteration 119250, loss = 1.01258
I0522 04:33:56.922092 19252 solver.cpp:253]     Train net output #0: loss = 1.01258 (* 1 = 1.01258 loss)
I0522 04:33:56.922108 19252 sgd_solver.cpp:106] Iteration 119250, lr = 0.004
I0522 04:34:09.071374 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_120000.caffemodel
I0522 04:34:09.120460 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_120000.solverstate
I0522 04:34:09.145683 19252 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 04:35:22.080165 19252 solver.cpp:409]     Test net output #0: accuracy = 0.890611
I0522 04:35:22.080338 19252 solver.cpp:409]     Test net output #1: loss = 0.3588 (* 1 = 0.3588 loss)
I0522 04:35:43.007201 19252 solver.cpp:237] Iteration 120000, loss = 0.972262
I0522 04:35:43.007256 19252 solver.cpp:253]     Train net output #0: loss = 0.972262 (* 1 = 0.972262 loss)
I0522 04:35:43.007272 19252 sgd_solver.cpp:106] Iteration 120000, lr = 0.004
I0522 04:35:55.091859 19252 solver.cpp:237] Iteration 120750, loss = 0.96598
I0522 04:35:55.092030 19252 solver.cpp:253]     Train net output #0: loss = 0.965979 (* 1 = 0.965979 loss)
I0522 04:35:55.092046 19252 sgd_solver.cpp:106] Iteration 120750, lr = 0.004
I0522 04:36:07.185196 19252 solver.cpp:237] Iteration 121500, loss = 1.34938
I0522 04:36:07.185232 19252 solver.cpp:253]     Train net output #0: loss = 1.34938 (* 1 = 1.34938 loss)
I0522 04:36:07.185247 19252 sgd_solver.cpp:106] Iteration 121500, lr = 0.004
I0522 04:36:19.299190 19252 solver.cpp:237] Iteration 122250, loss = 1.73694
I0522 04:36:19.299242 19252 solver.cpp:253]     Train net output #0: loss = 1.73694 (* 1 = 1.73694 loss)
I0522 04:36:19.299254 19252 sgd_solver.cpp:106] Iteration 122250, lr = 0.004
I0522 04:36:31.474997 19252 solver.cpp:237] Iteration 123000, loss = 0.870882
I0522 04:36:31.475149 19252 solver.cpp:253]     Train net output #0: loss = 0.870882 (* 1 = 0.870882 loss)
I0522 04:36:31.475164 19252 sgd_solver.cpp:106] Iteration 123000, lr = 0.004
I0522 04:36:43.665490 19252 solver.cpp:237] Iteration 123750, loss = 1.12408
I0522 04:36:43.665535 19252 solver.cpp:253]     Train net output #0: loss = 1.12408 (* 1 = 1.12408 loss)
I0522 04:36:43.665551 19252 sgd_solver.cpp:106] Iteration 123750, lr = 0.004
I0522 04:36:55.860041 19252 solver.cpp:237] Iteration 124500, loss = 0.930973
I0522 04:36:55.860076 19252 solver.cpp:253]     Train net output #0: loss = 0.930972 (* 1 = 0.930972 loss)
I0522 04:36:55.860093 19252 sgd_solver.cpp:106] Iteration 124500, lr = 0.004
I0522 04:37:28.983484 19252 solver.cpp:237] Iteration 125250, loss = 1.09428
I0522 04:37:28.983667 19252 solver.cpp:253]     Train net output #0: loss = 1.09428 (* 1 = 1.09428 loss)
I0522 04:37:28.983681 19252 sgd_solver.cpp:106] Iteration 125250, lr = 0.004
I0522 04:37:41.151365 19252 solver.cpp:237] Iteration 126000, loss = 1.22582
I0522 04:37:41.151401 19252 solver.cpp:253]     Train net output #0: loss = 1.22582 (* 1 = 1.22582 loss)
I0522 04:37:41.151417 19252 sgd_solver.cpp:106] Iteration 126000, lr = 0.004
I0522 04:37:53.312686 19252 solver.cpp:237] Iteration 126750, loss = 1.12672
I0522 04:37:53.312723 19252 solver.cpp:253]     Train net output #0: loss = 1.12672 (* 1 = 1.12672 loss)
I0522 04:37:53.312738 19252 sgd_solver.cpp:106] Iteration 126750, lr = 0.004
I0522 04:38:05.475678 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_127500.caffemodel
I0522 04:38:05.524703 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_127500.solverstate
I0522 04:38:05.555317 19252 solver.cpp:237] Iteration 127500, loss = 1.20711
I0522 04:38:05.555361 19252 solver.cpp:253]     Train net output #0: loss = 1.20711 (* 1 = 1.20711 loss)
I0522 04:38:05.555380 19252 sgd_solver.cpp:106] Iteration 127500, lr = 0.004
I0522 04:38:17.729197 19252 solver.cpp:237] Iteration 128250, loss = 1.16002
I0522 04:38:17.729233 19252 solver.cpp:253]     Train net output #0: loss = 1.16002 (* 1 = 1.16002 loss)
I0522 04:38:17.729248 19252 sgd_solver.cpp:106] Iteration 128250, lr = 0.004
I0522 04:38:29.893110 19252 solver.cpp:237] Iteration 129000, loss = 0.633459
I0522 04:38:29.893157 19252 solver.cpp:253]     Train net output #0: loss = 0.633458 (* 1 = 0.633458 loss)
I0522 04:38:29.893173 19252 sgd_solver.cpp:106] Iteration 129000, lr = 0.004
I0522 04:38:42.065501 19252 solver.cpp:237] Iteration 129750, loss = 1.27385
I0522 04:38:42.065672 19252 solver.cpp:253]     Train net output #0: loss = 1.27385 (* 1 = 1.27385 loss)
I0522 04:38:42.065687 19252 sgd_solver.cpp:106] Iteration 129750, lr = 0.004
I0522 04:39:15.120442 19252 solver.cpp:237] Iteration 130500, loss = 1.16042
I0522 04:39:15.120622 19252 solver.cpp:253]     Train net output #0: loss = 1.16042 (* 1 = 1.16042 loss)
I0522 04:39:15.120638 19252 sgd_solver.cpp:106] Iteration 130500, lr = 0.004
I0522 04:39:27.305989 19252 solver.cpp:237] Iteration 131250, loss = 1.86581
I0522 04:39:27.306025 19252 solver.cpp:253]     Train net output #0: loss = 1.86581 (* 1 = 1.86581 loss)
I0522 04:39:27.306041 19252 sgd_solver.cpp:106] Iteration 131250, lr = 0.004
I0522 04:39:39.510089 19252 solver.cpp:237] Iteration 132000, loss = 1.20622
I0522 04:39:39.510138 19252 solver.cpp:253]     Train net output #0: loss = 1.20622 (* 1 = 1.20622 loss)
I0522 04:39:39.510151 19252 sgd_solver.cpp:106] Iteration 132000, lr = 0.004
I0522 04:39:51.768643 19252 solver.cpp:237] Iteration 132750, loss = 1.35617
I0522 04:39:51.768797 19252 solver.cpp:253]     Train net output #0: loss = 1.35617 (* 1 = 1.35617 loss)
I0522 04:39:51.768812 19252 sgd_solver.cpp:106] Iteration 132750, lr = 0.004
I0522 04:40:03.972307 19252 solver.cpp:237] Iteration 133500, loss = 1.13271
I0522 04:40:03.972354 19252 solver.cpp:253]     Train net output #0: loss = 1.13271 (* 1 = 1.13271 loss)
I0522 04:40:03.972370 19252 sgd_solver.cpp:106] Iteration 133500, lr = 0.004
I0522 04:40:16.163866 19252 solver.cpp:237] Iteration 134250, loss = 1.15433
I0522 04:40:16.163902 19252 solver.cpp:253]     Train net output #0: loss = 1.15433 (* 1 = 1.15433 loss)
I0522 04:40:16.163918 19252 sgd_solver.cpp:106] Iteration 134250, lr = 0.004
I0522 04:40:28.330847 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_135000.caffemodel
I0522 04:40:28.379801 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_135000.solverstate
I0522 04:40:28.404665 19252 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 04:41:20.368260 19252 solver.cpp:409]     Test net output #0: accuracy = 0.890797
I0522 04:41:20.368432 19252 solver.cpp:409]     Test net output #1: loss = 0.334218 (* 1 = 0.334218 loss)
I0522 04:41:41.305759 19252 solver.cpp:237] Iteration 135000, loss = 1.42657
I0522 04:41:41.305811 19252 solver.cpp:253]     Train net output #0: loss = 1.42657 (* 1 = 1.42657 loss)
I0522 04:41:41.305829 19252 sgd_solver.cpp:106] Iteration 135000, lr = 0.004
I0522 04:41:53.419347 19252 solver.cpp:237] Iteration 135750, loss = 1.07521
I0522 04:41:53.419507 19252 solver.cpp:253]     Train net output #0: loss = 1.07521 (* 1 = 1.07521 loss)
I0522 04:41:53.419523 19252 sgd_solver.cpp:106] Iteration 135750, lr = 0.004
I0522 04:42:05.526712 19252 solver.cpp:237] Iteration 136500, loss = 0.581361
I0522 04:42:05.526756 19252 solver.cpp:253]     Train net output #0: loss = 0.58136 (* 1 = 0.58136 loss)
I0522 04:42:05.526777 19252 sgd_solver.cpp:106] Iteration 136500, lr = 0.004
I0522 04:42:17.625815 19252 solver.cpp:237] Iteration 137250, loss = 1.05128
I0522 04:42:17.625851 19252 solver.cpp:253]     Train net output #0: loss = 1.05128 (* 1 = 1.05128 loss)
I0522 04:42:17.625869 19252 sgd_solver.cpp:106] Iteration 137250, lr = 0.004
I0522 04:42:29.774186 19252 solver.cpp:237] Iteration 138000, loss = 1.00511
I0522 04:42:29.774366 19252 solver.cpp:253]     Train net output #0: loss = 1.00511 (* 1 = 1.00511 loss)
I0522 04:42:29.774381 19252 sgd_solver.cpp:106] Iteration 138000, lr = 0.004
I0522 04:42:41.941237 19252 solver.cpp:237] Iteration 138750, loss = 0.980341
I0522 04:42:41.941275 19252 solver.cpp:253]     Train net output #0: loss = 0.980339 (* 1 = 0.980339 loss)
I0522 04:42:41.941290 19252 sgd_solver.cpp:106] Iteration 138750, lr = 0.004
I0522 04:42:54.084308 19252 solver.cpp:237] Iteration 139500, loss = 0.892718
I0522 04:42:54.084359 19252 solver.cpp:253]     Train net output #0: loss = 0.892717 (* 1 = 0.892717 loss)
I0522 04:42:54.084374 19252 sgd_solver.cpp:106] Iteration 139500, lr = 0.004
I0522 04:43:27.119097 19252 solver.cpp:237] Iteration 140250, loss = 1.03299
I0522 04:43:27.119274 19252 solver.cpp:253]     Train net output #0: loss = 1.03299 (* 1 = 1.03299 loss)
I0522 04:43:27.119290 19252 sgd_solver.cpp:106] Iteration 140250, lr = 0.004
I0522 04:43:39.247532 19252 solver.cpp:237] Iteration 141000, loss = 1.47708
I0522 04:43:39.247568 19252 solver.cpp:253]     Train net output #0: loss = 1.47708 (* 1 = 1.47708 loss)
I0522 04:43:39.247584 19252 sgd_solver.cpp:106] Iteration 141000, lr = 0.004
I0522 04:43:51.357550 19252 solver.cpp:237] Iteration 141750, loss = 1.17918
I0522 04:43:51.357595 19252 solver.cpp:253]     Train net output #0: loss = 1.17918 (* 1 = 1.17918 loss)
I0522 04:43:51.357610 19252 sgd_solver.cpp:106] Iteration 141750, lr = 0.004
I0522 04:44:03.450929 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_142500.caffemodel
I0522 04:44:03.503676 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_142500.solverstate
I0522 04:44:03.535604 19252 solver.cpp:237] Iteration 142500, loss = 1.98987
I0522 04:44:03.535651 19252 solver.cpp:253]     Train net output #0: loss = 1.98987 (* 1 = 1.98987 loss)
I0522 04:44:03.535668 19252 sgd_solver.cpp:106] Iteration 142500, lr = 0.004
I0522 04:44:15.671669 19252 solver.cpp:237] Iteration 143250, loss = 0.835408
I0522 04:44:15.671718 19252 solver.cpp:253]     Train net output #0: loss = 0.835407 (* 1 = 0.835407 loss)
I0522 04:44:15.671733 19252 sgd_solver.cpp:106] Iteration 143250, lr = 0.004
I0522 04:44:27.826217 19252 solver.cpp:237] Iteration 144000, loss = 1.86306
I0522 04:44:27.826254 19252 solver.cpp:253]     Train net output #0: loss = 1.86306 (* 1 = 1.86306 loss)
I0522 04:44:27.826270 19252 sgd_solver.cpp:106] Iteration 144000, lr = 0.004
I0522 04:44:39.937116 19252 solver.cpp:237] Iteration 144750, loss = 1.11501
I0522 04:44:39.937291 19252 solver.cpp:253]     Train net output #0: loss = 1.11501 (* 1 = 1.11501 loss)
I0522 04:44:39.937306 19252 sgd_solver.cpp:106] Iteration 144750, lr = 0.004
I0522 04:45:12.963006 19252 solver.cpp:237] Iteration 145500, loss = 0.52339
I0522 04:45:12.963186 19252 solver.cpp:253]     Train net output #0: loss = 0.523389 (* 1 = 0.523389 loss)
I0522 04:45:12.963201 19252 sgd_solver.cpp:106] Iteration 145500, lr = 0.004
I0522 04:45:25.088243 19252 solver.cpp:237] Iteration 146250, loss = 1.20995
I0522 04:45:25.088287 19252 solver.cpp:253]     Train net output #0: loss = 1.20995 (* 1 = 1.20995 loss)
I0522 04:45:25.088304 19252 sgd_solver.cpp:106] Iteration 146250, lr = 0.004
I0522 04:45:37.201047 19252 solver.cpp:237] Iteration 147000, loss = 1.25461
I0522 04:45:37.201083 19252 solver.cpp:253]     Train net output #0: loss = 1.2546 (* 1 = 1.2546 loss)
I0522 04:45:37.201100 19252 sgd_solver.cpp:106] Iteration 147000, lr = 0.004
I0522 04:45:49.356463 19252 solver.cpp:237] Iteration 147750, loss = 1.08259
I0522 04:45:49.356642 19252 solver.cpp:253]     Train net output #0: loss = 1.08259 (* 1 = 1.08259 loss)
I0522 04:45:49.356657 19252 sgd_solver.cpp:106] Iteration 147750, lr = 0.004
I0522 04:46:01.498194 19252 solver.cpp:237] Iteration 148500, loss = 1.30196
I0522 04:46:01.498230 19252 solver.cpp:253]     Train net output #0: loss = 1.30196 (* 1 = 1.30196 loss)
I0522 04:46:01.498247 19252 sgd_solver.cpp:106] Iteration 148500, lr = 0.004
I0522 04:46:13.582121 19252 solver.cpp:237] Iteration 149250, loss = 1.44353
I0522 04:46:13.582171 19252 solver.cpp:253]     Train net output #0: loss = 1.44353 (* 1 = 1.44353 loss)
I0522 04:46:13.582186 19252 sgd_solver.cpp:106] Iteration 149250, lr = 0.004
I0522 04:46:25.691344 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_150000.caffemodel
I0522 04:46:25.742146 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_150000.solverstate
I0522 04:46:25.769479 19252 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 04:47:38.759883 19252 solver.cpp:409]     Test net output #0: accuracy = 0.89235
I0522 04:47:38.760063 19252 solver.cpp:409]     Test net output #1: loss = 0.331328 (* 1 = 0.331328 loss)
I0522 04:47:59.681377 19252 solver.cpp:237] Iteration 150000, loss = 1.49067
I0522 04:47:59.681432 19252 solver.cpp:253]     Train net output #0: loss = 1.49067 (* 1 = 1.49067 loss)
I0522 04:47:59.681447 19252 sgd_solver.cpp:106] Iteration 150000, lr = 0.004
I0522 04:48:11.721823 19252 solver.cpp:237] Iteration 150750, loss = 1.40168
I0522 04:48:11.721987 19252 solver.cpp:253]     Train net output #0: loss = 1.40168 (* 1 = 1.40168 loss)
I0522 04:48:11.722002 19252 sgd_solver.cpp:106] Iteration 150750, lr = 0.004
I0522 04:48:23.760282 19252 solver.cpp:237] Iteration 151500, loss = 1.28668
I0522 04:48:23.760329 19252 solver.cpp:253]     Train net output #0: loss = 1.28668 (* 1 = 1.28668 loss)
I0522 04:48:23.760345 19252 sgd_solver.cpp:106] Iteration 151500, lr = 0.004
I0522 04:48:35.855042 19252 solver.cpp:237] Iteration 152250, loss = 1.21289
I0522 04:48:35.855078 19252 solver.cpp:253]     Train net output #0: loss = 1.21289 (* 1 = 1.21289 loss)
I0522 04:48:35.855094 19252 sgd_solver.cpp:106] Iteration 152250, lr = 0.004
I0522 04:48:47.993975 19252 solver.cpp:237] Iteration 153000, loss = 1.10837
I0522 04:48:47.994144 19252 solver.cpp:253]     Train net output #0: loss = 1.10837 (* 1 = 1.10837 loss)
I0522 04:48:47.994158 19252 sgd_solver.cpp:106] Iteration 153000, lr = 0.004
I0522 04:49:00.143919 19252 solver.cpp:237] Iteration 153750, loss = 1.21229
I0522 04:49:00.143955 19252 solver.cpp:253]     Train net output #0: loss = 1.21229 (* 1 = 1.21229 loss)
I0522 04:49:00.143971 19252 sgd_solver.cpp:106] Iteration 153750, lr = 0.004
I0522 04:49:12.282655 19252 solver.cpp:237] Iteration 154500, loss = 1.36554
I0522 04:49:12.282697 19252 solver.cpp:253]     Train net output #0: loss = 1.36554 (* 1 = 1.36554 loss)
I0522 04:49:12.282713 19252 sgd_solver.cpp:106] Iteration 154500, lr = 0.004
I0522 04:49:45.280701 19252 solver.cpp:237] Iteration 155250, loss = 1.03999
I0522 04:49:45.280886 19252 solver.cpp:253]     Train net output #0: loss = 1.03998 (* 1 = 1.03998 loss)
I0522 04:49:45.280900 19252 sgd_solver.cpp:106] Iteration 155250, lr = 0.004
I0522 04:49:57.396131 19252 solver.cpp:237] Iteration 156000, loss = 1.45006
I0522 04:49:57.396167 19252 solver.cpp:253]     Train net output #0: loss = 1.45006 (* 1 = 1.45006 loss)
I0522 04:49:57.396183 19252 sgd_solver.cpp:106] Iteration 156000, lr = 0.004
I0522 04:50:09.511530 19252 solver.cpp:237] Iteration 156750, loss = 1.3556
I0522 04:50:09.511579 19252 solver.cpp:253]     Train net output #0: loss = 1.3556 (* 1 = 1.3556 loss)
I0522 04:50:09.511593 19252 sgd_solver.cpp:106] Iteration 156750, lr = 0.004
I0522 04:50:21.615340 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_157500.caffemodel
I0522 04:50:21.664953 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_157500.solverstate
I0522 04:50:21.695152 19252 solver.cpp:237] Iteration 157500, loss = 1.284
I0522 04:50:21.695197 19252 solver.cpp:253]     Train net output #0: loss = 1.284 (* 1 = 1.284 loss)
I0522 04:50:21.695214 19252 sgd_solver.cpp:106] Iteration 157500, lr = 0.004
I0522 04:50:33.835522 19252 solver.cpp:237] Iteration 158250, loss = 1.7854
I0522 04:50:33.835569 19252 solver.cpp:253]     Train net output #0: loss = 1.7854 (* 1 = 1.7854 loss)
I0522 04:50:33.835583 19252 sgd_solver.cpp:106] Iteration 158250, lr = 0.004
I0522 04:50:45.984375 19252 solver.cpp:237] Iteration 159000, loss = 0.757637
I0522 04:50:45.984411 19252 solver.cpp:253]     Train net output #0: loss = 0.757637 (* 1 = 0.757637 loss)
I0522 04:50:45.984426 19252 sgd_solver.cpp:106] Iteration 159000, lr = 0.004
I0522 04:50:58.112432 19252 solver.cpp:237] Iteration 159750, loss = 1.22137
I0522 04:50:58.112607 19252 solver.cpp:253]     Train net output #0: loss = 1.22137 (* 1 = 1.22137 loss)
I0522 04:50:58.112620 19252 sgd_solver.cpp:106] Iteration 159750, lr = 0.004
I0522 04:51:31.147661 19252 solver.cpp:237] Iteration 160500, loss = 0.939596
I0522 04:51:31.147842 19252 solver.cpp:253]     Train net output #0: loss = 0.939595 (* 1 = 0.939595 loss)
I0522 04:51:31.147857 19252 sgd_solver.cpp:106] Iteration 160500, lr = 0.004
I0522 04:51:43.301854 19252 solver.cpp:237] Iteration 161250, loss = 1.46234
I0522 04:51:43.301903 19252 solver.cpp:253]     Train net output #0: loss = 1.46234 (* 1 = 1.46234 loss)
I0522 04:51:43.301918 19252 sgd_solver.cpp:106] Iteration 161250, lr = 0.004
I0522 04:51:55.463964 19252 solver.cpp:237] Iteration 162000, loss = 1.20309
I0522 04:51:55.464000 19252 solver.cpp:253]     Train net output #0: loss = 1.20309 (* 1 = 1.20309 loss)
I0522 04:51:55.464017 19252 sgd_solver.cpp:106] Iteration 162000, lr = 0.004
I0522 04:52:07.653842 19252 solver.cpp:237] Iteration 162750, loss = 1.16068
I0522 04:52:07.654017 19252 solver.cpp:253]     Train net output #0: loss = 1.16068 (* 1 = 1.16068 loss)
I0522 04:52:07.654032 19252 sgd_solver.cpp:106] Iteration 162750, lr = 0.004
I0522 04:52:19.790531 19252 solver.cpp:237] Iteration 163500, loss = 1.23699
I0522 04:52:19.790567 19252 solver.cpp:253]     Train net output #0: loss = 1.23699 (* 1 = 1.23699 loss)
I0522 04:52:19.790583 19252 sgd_solver.cpp:106] Iteration 163500, lr = 0.004
I0522 04:52:31.945075 19252 solver.cpp:237] Iteration 164250, loss = 1.19625
I0522 04:52:31.945122 19252 solver.cpp:253]     Train net output #0: loss = 1.19625 (* 1 = 1.19625 loss)
I0522 04:52:31.945137 19252 sgd_solver.cpp:106] Iteration 164250, lr = 0.004
I0522 04:52:44.077199 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_165000.caffemodel
I0522 04:52:44.126602 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_165000.solverstate
I0522 04:52:44.153142 19252 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 04:53:35.883271 19252 solver.cpp:409]     Test net output #0: accuracy = 0.893869
I0522 04:53:35.883448 19252 solver.cpp:409]     Test net output #1: loss = 0.327189 (* 1 = 0.327189 loss)
I0522 04:53:56.766654 19252 solver.cpp:237] Iteration 165000, loss = 0.975921
I0522 04:53:56.766705 19252 solver.cpp:253]     Train net output #0: loss = 0.97592 (* 1 = 0.97592 loss)
I0522 04:53:56.766723 19252 sgd_solver.cpp:106] Iteration 165000, lr = 0.004
I0522 04:54:08.912729 19252 solver.cpp:237] Iteration 165750, loss = 1.08465
I0522 04:54:08.912922 19252 solver.cpp:253]     Train net output #0: loss = 1.08465 (* 1 = 1.08465 loss)
I0522 04:54:08.912937 19252 sgd_solver.cpp:106] Iteration 165750, lr = 0.004
I0522 04:54:21.070533 19252 solver.cpp:237] Iteration 166500, loss = 1.14654
I0522 04:54:21.070569 19252 solver.cpp:253]     Train net output #0: loss = 1.14654 (* 1 = 1.14654 loss)
I0522 04:54:21.070585 19252 sgd_solver.cpp:106] Iteration 166500, lr = 0.004
I0522 04:54:33.303549 19252 solver.cpp:237] Iteration 167250, loss = 1.06323
I0522 04:54:33.303583 19252 solver.cpp:253]     Train net output #0: loss = 1.06323 (* 1 = 1.06323 loss)
I0522 04:54:33.303601 19252 sgd_solver.cpp:106] Iteration 167250, lr = 0.004
I0522 04:54:45.555282 19252 solver.cpp:237] Iteration 168000, loss = 0.885144
I0522 04:54:45.555439 19252 solver.cpp:253]     Train net output #0: loss = 0.885143 (* 1 = 0.885143 loss)
I0522 04:54:45.555454 19252 sgd_solver.cpp:106] Iteration 168000, lr = 0.004
I0522 04:54:57.730368 19252 solver.cpp:237] Iteration 168750, loss = 1.29783
I0522 04:54:57.730404 19252 solver.cpp:253]     Train net output #0: loss = 1.29783 (* 1 = 1.29783 loss)
I0522 04:54:57.730420 19252 sgd_solver.cpp:106] Iteration 168750, lr = 0.004
I0522 04:55:09.921448 19252 solver.cpp:237] Iteration 169500, loss = 0.853911
I0522 04:55:09.921492 19252 solver.cpp:253]     Train net output #0: loss = 0.853911 (* 1 = 0.853911 loss)
I0522 04:55:09.921509 19252 sgd_solver.cpp:106] Iteration 169500, lr = 0.004
I0522 04:55:43.003417 19252 solver.cpp:237] Iteration 170250, loss = 0.82666
I0522 04:55:43.003600 19252 solver.cpp:253]     Train net output #0: loss = 0.826659 (* 1 = 0.826659 loss)
I0522 04:55:43.003615 19252 sgd_solver.cpp:106] Iteration 170250, lr = 0.004
I0522 04:55:55.241350 19252 solver.cpp:237] Iteration 171000, loss = 1.23751
I0522 04:55:55.241400 19252 solver.cpp:253]     Train net output #0: loss = 1.23751 (* 1 = 1.23751 loss)
I0522 04:55:55.241415 19252 sgd_solver.cpp:106] Iteration 171000, lr = 0.004
I0522 04:56:07.448294 19252 solver.cpp:237] Iteration 171750, loss = 1.13912
I0522 04:56:07.448330 19252 solver.cpp:253]     Train net output #0: loss = 1.13912 (* 1 = 1.13912 loss)
I0522 04:56:07.448348 19252 sgd_solver.cpp:106] Iteration 171750, lr = 0.004
I0522 04:56:19.617794 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_172500.caffemodel
I0522 04:56:19.667577 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_172500.solverstate
I0522 04:56:19.698585 19252 solver.cpp:237] Iteration 172500, loss = 1.15644
I0522 04:56:19.698632 19252 solver.cpp:253]     Train net output #0: loss = 1.15644 (* 1 = 1.15644 loss)
I0522 04:56:19.698645 19252 sgd_solver.cpp:106] Iteration 172500, lr = 0.004
I0522 04:56:31.893115 19252 solver.cpp:237] Iteration 173250, loss = 1.45482
I0522 04:56:31.893151 19252 solver.cpp:253]     Train net output #0: loss = 1.45482 (* 1 = 1.45482 loss)
I0522 04:56:31.893164 19252 sgd_solver.cpp:106] Iteration 173250, lr = 0.004
I0522 04:56:44.079869 19252 solver.cpp:237] Iteration 174000, loss = 1.45552
I0522 04:56:44.079918 19252 solver.cpp:253]     Train net output #0: loss = 1.45552 (* 1 = 1.45552 loss)
I0522 04:56:44.079933 19252 sgd_solver.cpp:106] Iteration 174000, lr = 0.004
I0522 04:56:56.259049 19252 solver.cpp:237] Iteration 174750, loss = 0.964934
I0522 04:56:56.259213 19252 solver.cpp:253]     Train net output #0: loss = 0.964933 (* 1 = 0.964933 loss)
I0522 04:56:56.259229 19252 sgd_solver.cpp:106] Iteration 174750, lr = 0.004
I0522 04:57:29.307746 19252 solver.cpp:237] Iteration 175500, loss = 1.4857
I0522 04:57:29.307920 19252 solver.cpp:253]     Train net output #0: loss = 1.4857 (* 1 = 1.4857 loss)
I0522 04:57:29.307934 19252 sgd_solver.cpp:106] Iteration 175500, lr = 0.004
I0522 04:57:41.459041 19252 solver.cpp:237] Iteration 176250, loss = 1.23384
I0522 04:57:41.459077 19252 solver.cpp:253]     Train net output #0: loss = 1.23384 (* 1 = 1.23384 loss)
I0522 04:57:41.459095 19252 sgd_solver.cpp:106] Iteration 176250, lr = 0.004
I0522 04:57:53.630549 19252 solver.cpp:237] Iteration 177000, loss = 1.31808
I0522 04:57:53.630599 19252 solver.cpp:253]     Train net output #0: loss = 1.31808 (* 1 = 1.31808 loss)
I0522 04:57:53.630612 19252 sgd_solver.cpp:106] Iteration 177000, lr = 0.004
I0522 04:58:05.800509 19252 solver.cpp:237] Iteration 177750, loss = 0.82356
I0522 04:58:05.800684 19252 solver.cpp:253]     Train net output #0: loss = 0.82356 (* 1 = 0.82356 loss)
I0522 04:58:05.800698 19252 sgd_solver.cpp:106] Iteration 177750, lr = 0.004
I0522 04:58:17.970197 19252 solver.cpp:237] Iteration 178500, loss = 1.45183
I0522 04:58:17.970233 19252 solver.cpp:253]     Train net output #0: loss = 1.45183 (* 1 = 1.45183 loss)
I0522 04:58:17.970248 19252 sgd_solver.cpp:106] Iteration 178500, lr = 0.004
I0522 04:58:30.169366 19252 solver.cpp:237] Iteration 179250, loss = 1.1315
I0522 04:58:30.169412 19252 solver.cpp:253]     Train net output #0: loss = 1.1315 (* 1 = 1.1315 loss)
I0522 04:58:30.169427 19252 sgd_solver.cpp:106] Iteration 179250, lr = 0.004
I0522 04:58:42.398564 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_180000.caffemodel
I0522 04:58:42.448464 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_180000.solverstate
I0522 04:58:42.474004 19252 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 04:59:55.347508 19252 solver.cpp:409]     Test net output #0: accuracy = 0.89347
I0522 04:59:55.347690 19252 solver.cpp:409]     Test net output #1: loss = 0.375754 (* 1 = 0.375754 loss)
I0522 05:00:16.230367 19252 solver.cpp:237] Iteration 180000, loss = 1.09761
I0522 05:00:16.230420 19252 solver.cpp:253]     Train net output #0: loss = 1.09761 (* 1 = 1.09761 loss)
I0522 05:00:16.230437 19252 sgd_solver.cpp:106] Iteration 180000, lr = 0.004
I0522 05:00:28.393189 19252 solver.cpp:237] Iteration 180750, loss = 1.20835
I0522 05:00:28.393362 19252 solver.cpp:253]     Train net output #0: loss = 1.20835 (* 1 = 1.20835 loss)
I0522 05:00:28.393376 19252 sgd_solver.cpp:106] Iteration 180750, lr = 0.004
I0522 05:00:40.511950 19252 solver.cpp:237] Iteration 181500, loss = 0.714817
I0522 05:00:40.511986 19252 solver.cpp:253]     Train net output #0: loss = 0.714817 (* 1 = 0.714817 loss)
I0522 05:00:40.512001 19252 sgd_solver.cpp:106] Iteration 181500, lr = 0.004
I0522 05:00:52.621582 19252 solver.cpp:237] Iteration 182250, loss = 0.985401
I0522 05:00:52.621625 19252 solver.cpp:253]     Train net output #0: loss = 0.985402 (* 1 = 0.985402 loss)
I0522 05:00:52.621640 19252 sgd_solver.cpp:106] Iteration 182250, lr = 0.004
I0522 05:01:04.710758 19252 solver.cpp:237] Iteration 183000, loss = 1.02569
I0522 05:01:04.710914 19252 solver.cpp:253]     Train net output #0: loss = 1.02569 (* 1 = 1.02569 loss)
I0522 05:01:04.710929 19252 sgd_solver.cpp:106] Iteration 183000, lr = 0.004
I0522 05:01:16.823689 19252 solver.cpp:237] Iteration 183750, loss = 1.29677
I0522 05:01:16.823730 19252 solver.cpp:253]     Train net output #0: loss = 1.29677 (* 1 = 1.29677 loss)
I0522 05:01:16.823747 19252 sgd_solver.cpp:106] Iteration 183750, lr = 0.004
I0522 05:01:28.931623 19252 solver.cpp:237] Iteration 184500, loss = 0.81217
I0522 05:01:28.931658 19252 solver.cpp:253]     Train net output #0: loss = 0.81217 (* 1 = 0.81217 loss)
I0522 05:01:28.931675 19252 sgd_solver.cpp:106] Iteration 184500, lr = 0.004
I0522 05:02:01.935816 19252 solver.cpp:237] Iteration 185250, loss = 1.01278
I0522 05:02:01.936000 19252 solver.cpp:253]     Train net output #0: loss = 1.01278 (* 1 = 1.01278 loss)
I0522 05:02:01.936017 19252 sgd_solver.cpp:106] Iteration 185250, lr = 0.004
I0522 05:02:14.048328 19252 solver.cpp:237] Iteration 186000, loss = 1.46766
I0522 05:02:14.048373 19252 solver.cpp:253]     Train net output #0: loss = 1.46766 (* 1 = 1.46766 loss)
I0522 05:02:14.048388 19252 sgd_solver.cpp:106] Iteration 186000, lr = 0.004
I0522 05:02:26.159574 19252 solver.cpp:237] Iteration 186750, loss = 1.20068
I0522 05:02:26.159610 19252 solver.cpp:253]     Train net output #0: loss = 1.20068 (* 1 = 1.20068 loss)
I0522 05:02:26.159627 19252 sgd_solver.cpp:106] Iteration 186750, lr = 0.004
I0522 05:02:38.249701 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_187500.caffemodel
I0522 05:02:38.299978 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_187500.solverstate
I0522 05:02:38.331744 19252 solver.cpp:237] Iteration 187500, loss = 1.25169
I0522 05:02:38.331790 19252 solver.cpp:253]     Train net output #0: loss = 1.25169 (* 1 = 1.25169 loss)
I0522 05:02:38.331809 19252 sgd_solver.cpp:106] Iteration 187500, lr = 0.004
I0522 05:02:50.434716 19252 solver.cpp:237] Iteration 188250, loss = 1.26576
I0522 05:02:50.434753 19252 solver.cpp:253]     Train net output #0: loss = 1.26576 (* 1 = 1.26576 loss)
I0522 05:02:50.434768 19252 sgd_solver.cpp:106] Iteration 188250, lr = 0.004
I0522 05:03:02.539611 19252 solver.cpp:237] Iteration 189000, loss = 1.01281
I0522 05:03:02.539662 19252 solver.cpp:253]     Train net output #0: loss = 1.01281 (* 1 = 1.01281 loss)
I0522 05:03:02.539677 19252 sgd_solver.cpp:106] Iteration 189000, lr = 0.004
I0522 05:03:14.656430 19252 solver.cpp:237] Iteration 189750, loss = 0.856843
I0522 05:03:14.656597 19252 solver.cpp:253]     Train net output #0: loss = 0.856844 (* 1 = 0.856844 loss)
I0522 05:03:14.656612 19252 sgd_solver.cpp:106] Iteration 189750, lr = 0.004
I0522 05:03:47.642375 19252 solver.cpp:237] Iteration 190500, loss = 1.24219
I0522 05:03:47.642557 19252 solver.cpp:253]     Train net output #0: loss = 1.24219 (* 1 = 1.24219 loss)
I0522 05:03:47.642571 19252 sgd_solver.cpp:106] Iteration 190500, lr = 0.004
I0522 05:03:59.785431 19252 solver.cpp:237] Iteration 191250, loss = 1.1874
I0522 05:03:59.785467 19252 solver.cpp:253]     Train net output #0: loss = 1.1874 (* 1 = 1.1874 loss)
I0522 05:03:59.785483 19252 sgd_solver.cpp:106] Iteration 191250, lr = 0.004
I0522 05:04:11.926071 19252 solver.cpp:237] Iteration 192000, loss = 1.84768
I0522 05:04:11.926120 19252 solver.cpp:253]     Train net output #0: loss = 1.84768 (* 1 = 1.84768 loss)
I0522 05:04:11.926134 19252 sgd_solver.cpp:106] Iteration 192000, lr = 0.004
I0522 05:04:24.057761 19252 solver.cpp:237] Iteration 192750, loss = 0.722052
I0522 05:04:24.057935 19252 solver.cpp:253]     Train net output #0: loss = 0.722052 (* 1 = 0.722052 loss)
I0522 05:04:24.057950 19252 sgd_solver.cpp:106] Iteration 192750, lr = 0.004
I0522 05:04:36.161859 19252 solver.cpp:237] Iteration 193500, loss = 1.00846
I0522 05:04:36.161908 19252 solver.cpp:253]     Train net output #0: loss = 1.00846 (* 1 = 1.00846 loss)
I0522 05:04:36.161922 19252 sgd_solver.cpp:106] Iteration 193500, lr = 0.004
I0522 05:04:48.271828 19252 solver.cpp:237] Iteration 194250, loss = 0.813315
I0522 05:04:48.271865 19252 solver.cpp:253]     Train net output #0: loss = 0.813315 (* 1 = 0.813315 loss)
I0522 05:04:48.271881 19252 sgd_solver.cpp:106] Iteration 194250, lr = 0.004
I0522 05:05:00.365176 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_195000.caffemodel
I0522 05:05:00.414357 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_195000.solverstate
I0522 05:05:00.439725 19252 solver.cpp:341] Iteration 195000, Testing net (#0)
I0522 05:05:52.391903 19252 solver.cpp:409]     Test net output #0: accuracy = 0.889717
I0522 05:05:52.392094 19252 solver.cpp:409]     Test net output #1: loss = 0.364368 (* 1 = 0.364368 loss)
I0522 05:06:13.316042 19252 solver.cpp:237] Iteration 195000, loss = 0.619782
I0522 05:06:13.316097 19252 solver.cpp:253]     Train net output #0: loss = 0.619783 (* 1 = 0.619783 loss)
I0522 05:06:13.316112 19252 sgd_solver.cpp:106] Iteration 195000, lr = 0.004
I0522 05:06:25.533994 19252 solver.cpp:237] Iteration 195750, loss = 0.692621
I0522 05:06:25.534178 19252 solver.cpp:253]     Train net output #0: loss = 0.692621 (* 1 = 0.692621 loss)
I0522 05:06:25.534193 19252 sgd_solver.cpp:106] Iteration 195750, lr = 0.004
I0522 05:06:37.722242 19252 solver.cpp:237] Iteration 196500, loss = 1.68603
I0522 05:06:37.722278 19252 solver.cpp:253]     Train net output #0: loss = 1.68603 (* 1 = 1.68603 loss)
I0522 05:06:37.722296 19252 sgd_solver.cpp:106] Iteration 196500, lr = 0.004
I0522 05:06:49.876915 19252 solver.cpp:237] Iteration 197250, loss = 1.12896
I0522 05:06:49.876955 19252 solver.cpp:253]     Train net output #0: loss = 1.12896 (* 1 = 1.12896 loss)
I0522 05:06:49.876972 19252 sgd_solver.cpp:106] Iteration 197250, lr = 0.004
I0522 05:07:02.013973 19252 solver.cpp:237] Iteration 198000, loss = 1.09756
I0522 05:07:02.014137 19252 solver.cpp:253]     Train net output #0: loss = 1.09756 (* 1 = 1.09756 loss)
I0522 05:07:02.014153 19252 sgd_solver.cpp:106] Iteration 198000, lr = 0.004
I0522 05:07:14.209576 19252 solver.cpp:237] Iteration 198750, loss = 1.07458
I0522 05:07:14.209620 19252 solver.cpp:253]     Train net output #0: loss = 1.07458 (* 1 = 1.07458 loss)
I0522 05:07:14.209636 19252 sgd_solver.cpp:106] Iteration 198750, lr = 0.004
I0522 05:07:26.393669 19252 solver.cpp:237] Iteration 199500, loss = 1.27065
I0522 05:07:26.393705 19252 solver.cpp:253]     Train net output #0: loss = 1.27065 (* 1 = 1.27065 loss)
I0522 05:07:26.393721 19252 sgd_solver.cpp:106] Iteration 199500, lr = 0.004
I0522 05:07:59.471393 19252 solver.cpp:237] Iteration 200250, loss = 1.38978
I0522 05:07:59.471578 19252 solver.cpp:253]     Train net output #0: loss = 1.38978 (* 1 = 1.38978 loss)
I0522 05:07:59.471593 19252 sgd_solver.cpp:106] Iteration 200250, lr = 0.004
I0522 05:08:11.651937 19252 solver.cpp:237] Iteration 201000, loss = 0.834818
I0522 05:08:11.651974 19252 solver.cpp:253]     Train net output #0: loss = 0.834818 (* 1 = 0.834818 loss)
I0522 05:08:11.651988 19252 sgd_solver.cpp:106] Iteration 201000, lr = 0.004
I0522 05:08:23.812652 19252 solver.cpp:237] Iteration 201750, loss = 1.03792
I0522 05:08:23.812700 19252 solver.cpp:253]     Train net output #0: loss = 1.03792 (* 1 = 1.03792 loss)
I0522 05:08:23.812714 19252 sgd_solver.cpp:106] Iteration 201750, lr = 0.004
I0522 05:08:35.976982 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_202500.caffemodel
I0522 05:08:36.026175 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_202500.solverstate
I0522 05:08:36.056433 19252 solver.cpp:237] Iteration 202500, loss = 1.24032
I0522 05:08:36.056479 19252 solver.cpp:253]     Train net output #0: loss = 1.24032 (* 1 = 1.24032 loss)
I0522 05:08:36.056493 19252 sgd_solver.cpp:106] Iteration 202500, lr = 0.004
I0522 05:08:48.232048 19252 solver.cpp:237] Iteration 203250, loss = 1.16963
I0522 05:08:48.232096 19252 solver.cpp:253]     Train net output #0: loss = 1.16963 (* 1 = 1.16963 loss)
I0522 05:08:48.232110 19252 sgd_solver.cpp:106] Iteration 203250, lr = 0.004
I0522 05:09:00.384811 19252 solver.cpp:237] Iteration 204000, loss = 1.21434
I0522 05:09:00.384847 19252 solver.cpp:253]     Train net output #0: loss = 1.21434 (* 1 = 1.21434 loss)
I0522 05:09:00.384865 19252 sgd_solver.cpp:106] Iteration 204000, lr = 0.004
I0522 05:09:12.540254 19252 solver.cpp:237] Iteration 204750, loss = 1.00196
I0522 05:09:12.540446 19252 solver.cpp:253]     Train net output #0: loss = 1.00196 (* 1 = 1.00196 loss)
I0522 05:09:12.540460 19252 sgd_solver.cpp:106] Iteration 204750, lr = 0.004
I0522 05:09:45.699594 19252 solver.cpp:237] Iteration 205500, loss = 1.34202
I0522 05:09:45.699781 19252 solver.cpp:253]     Train net output #0: loss = 1.34202 (* 1 = 1.34202 loss)
I0522 05:09:45.699796 19252 sgd_solver.cpp:106] Iteration 205500, lr = 0.004
I0522 05:09:57.931278 19252 solver.cpp:237] Iteration 206250, loss = 1.45544
I0522 05:09:57.931315 19252 solver.cpp:253]     Train net output #0: loss = 1.45544 (* 1 = 1.45544 loss)
I0522 05:09:57.931329 19252 sgd_solver.cpp:106] Iteration 206250, lr = 0.004
I0522 05:10:10.128760 19252 solver.cpp:237] Iteration 207000, loss = 0.938753
I0522 05:10:10.128809 19252 solver.cpp:253]     Train net output #0: loss = 0.938753 (* 1 = 0.938753 loss)
I0522 05:10:10.128824 19252 sgd_solver.cpp:106] Iteration 207000, lr = 0.004
I0522 05:10:22.320672 19252 solver.cpp:237] Iteration 207750, loss = 1.03812
I0522 05:10:22.320839 19252 solver.cpp:253]     Train net output #0: loss = 1.03812 (* 1 = 1.03812 loss)
I0522 05:10:22.320854 19252 sgd_solver.cpp:106] Iteration 207750, lr = 0.004
I0522 05:10:34.508836 19252 solver.cpp:237] Iteration 208500, loss = 0.996511
I0522 05:10:34.508906 19252 solver.cpp:253]     Train net output #0: loss = 0.996511 (* 1 = 0.996511 loss)
I0522 05:10:34.508927 19252 sgd_solver.cpp:106] Iteration 208500, lr = 0.004
I0522 05:10:46.691619 19252 solver.cpp:237] Iteration 209250, loss = 1.17447
I0522 05:10:46.691654 19252 solver.cpp:253]     Train net output #0: loss = 1.17447 (* 1 = 1.17447 loss)
I0522 05:10:46.691671 19252 sgd_solver.cpp:106] Iteration 209250, lr = 0.004
I0522 05:10:58.867982 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_210000.caffemodel
I0522 05:10:58.917374 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_210000.solverstate
I0522 05:10:58.942673 19252 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 05:12:11.803190 19252 solver.cpp:409]     Test net output #0: accuracy = 0.89901
I0522 05:12:11.803375 19252 solver.cpp:409]     Test net output #1: loss = 0.329075 (* 1 = 0.329075 loss)
I0522 05:12:32.707947 19252 solver.cpp:237] Iteration 210000, loss = 1.25275
I0522 05:12:32.707998 19252 solver.cpp:253]     Train net output #0: loss = 1.25275 (* 1 = 1.25275 loss)
I0522 05:12:32.708015 19252 sgd_solver.cpp:106] Iteration 210000, lr = 0.004
I0522 05:12:44.911018 19252 solver.cpp:237] Iteration 210750, loss = 1.50538
I0522 05:12:44.911190 19252 solver.cpp:253]     Train net output #0: loss = 1.50538 (* 1 = 1.50538 loss)
I0522 05:12:44.911203 19252 sgd_solver.cpp:106] Iteration 210750, lr = 0.004
I0522 05:12:57.118091 19252 solver.cpp:237] Iteration 211500, loss = 0.961866
I0522 05:12:57.118140 19252 solver.cpp:253]     Train net output #0: loss = 0.961866 (* 1 = 0.961866 loss)
I0522 05:12:57.118155 19252 sgd_solver.cpp:106] Iteration 211500, lr = 0.004
I0522 05:13:09.346647 19252 solver.cpp:237] Iteration 212250, loss = 1.18951
I0522 05:13:09.346683 19252 solver.cpp:253]     Train net output #0: loss = 1.18951 (* 1 = 1.18951 loss)
I0522 05:13:09.346701 19252 sgd_solver.cpp:106] Iteration 212250, lr = 0.004
I0522 05:13:21.591280 19252 solver.cpp:237] Iteration 213000, loss = 1.01949
I0522 05:13:21.591462 19252 solver.cpp:253]     Train net output #0: loss = 1.01949 (* 1 = 1.01949 loss)
I0522 05:13:21.591477 19252 sgd_solver.cpp:106] Iteration 213000, lr = 0.004
I0522 05:13:33.827455 19252 solver.cpp:237] Iteration 213750, loss = 1.21151
I0522 05:13:33.827489 19252 solver.cpp:253]     Train net output #0: loss = 1.21151 (* 1 = 1.21151 loss)
I0522 05:13:33.827507 19252 sgd_solver.cpp:106] Iteration 213750, lr = 0.004
I0522 05:13:46.068570 19252 solver.cpp:237] Iteration 214500, loss = 0.906386
I0522 05:13:46.068621 19252 solver.cpp:253]     Train net output #0: loss = 0.906386 (* 1 = 0.906386 loss)
I0522 05:13:46.068635 19252 sgd_solver.cpp:106] Iteration 214500, lr = 0.004
I0522 05:14:19.205149 19252 solver.cpp:237] Iteration 215250, loss = 1.06414
I0522 05:14:19.205348 19252 solver.cpp:253]     Train net output #0: loss = 1.06414 (* 1 = 1.06414 loss)
I0522 05:14:19.205363 19252 sgd_solver.cpp:106] Iteration 215250, lr = 0.004
I0522 05:14:31.458657 19252 solver.cpp:237] Iteration 216000, loss = 1.03977
I0522 05:14:31.458694 19252 solver.cpp:253]     Train net output #0: loss = 1.03977 (* 1 = 1.03977 loss)
I0522 05:14:31.458709 19252 sgd_solver.cpp:106] Iteration 216000, lr = 0.004
I0522 05:14:43.659888 19252 solver.cpp:237] Iteration 216750, loss = 0.700734
I0522 05:14:43.659934 19252 solver.cpp:253]     Train net output #0: loss = 0.700734 (* 1 = 0.700734 loss)
I0522 05:14:43.659948 19252 sgd_solver.cpp:106] Iteration 216750, lr = 0.004
I0522 05:14:55.862980 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_217500.caffemodel
I0522 05:14:55.913828 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_217500.solverstate
I0522 05:14:55.945380 19252 solver.cpp:237] Iteration 217500, loss = 0.962463
I0522 05:14:55.945430 19252 solver.cpp:253]     Train net output #0: loss = 0.962463 (* 1 = 0.962463 loss)
I0522 05:14:55.945446 19252 sgd_solver.cpp:106] Iteration 217500, lr = 0.004
I0522 05:15:08.110421 19252 solver.cpp:237] Iteration 218250, loss = 0.490762
I0522 05:15:08.110471 19252 solver.cpp:253]     Train net output #0: loss = 0.490762 (* 1 = 0.490762 loss)
I0522 05:15:08.110486 19252 sgd_solver.cpp:106] Iteration 218250, lr = 0.004
I0522 05:15:20.260126 19252 solver.cpp:237] Iteration 219000, loss = 2.91274
I0522 05:15:20.260162 19252 solver.cpp:253]     Train net output #0: loss = 2.91274 (* 1 = 2.91274 loss)
I0522 05:15:20.260179 19252 sgd_solver.cpp:106] Iteration 219000, lr = 0.004
I0522 05:15:32.419836 19252 solver.cpp:237] Iteration 219750, loss = 1.25924
I0522 05:15:32.420022 19252 solver.cpp:253]     Train net output #0: loss = 1.25924 (* 1 = 1.25924 loss)
I0522 05:15:32.420035 19252 sgd_solver.cpp:106] Iteration 219750, lr = 0.004
I0522 05:16:05.467334 19252 solver.cpp:237] Iteration 220500, loss = 0.828832
I0522 05:16:05.467525 19252 solver.cpp:253]     Train net output #0: loss = 0.828832 (* 1 = 0.828832 loss)
I0522 05:16:05.467540 19252 sgd_solver.cpp:106] Iteration 220500, lr = 0.004
I0522 05:16:17.615509 19252 solver.cpp:237] Iteration 221250, loss = 1.00332
I0522 05:16:17.615561 19252 solver.cpp:253]     Train net output #0: loss = 1.00332 (* 1 = 1.00332 loss)
I0522 05:16:17.615576 19252 sgd_solver.cpp:106] Iteration 221250, lr = 0.004
I0522 05:16:29.766845 19252 solver.cpp:237] Iteration 222000, loss = 1.16048
I0522 05:16:29.766881 19252 solver.cpp:253]     Train net output #0: loss = 1.16048 (* 1 = 1.16048 loss)
I0522 05:16:29.766897 19252 sgd_solver.cpp:106] Iteration 222000, lr = 0.004
I0522 05:16:41.932122 19252 solver.cpp:237] Iteration 222750, loss = 1.44951
I0522 05:16:41.932313 19252 solver.cpp:253]     Train net output #0: loss = 1.44951 (* 1 = 1.44951 loss)
I0522 05:16:41.932328 19252 sgd_solver.cpp:106] Iteration 222750, lr = 0.004
I0522 05:16:54.135912 19252 solver.cpp:237] Iteration 223500, loss = 1.31103
I0522 05:16:54.135947 19252 solver.cpp:253]     Train net output #0: loss = 1.31103 (* 1 = 1.31103 loss)
I0522 05:16:54.135965 19252 sgd_solver.cpp:106] Iteration 223500, lr = 0.004
I0522 05:17:06.362467 19252 solver.cpp:237] Iteration 224250, loss = 1.52324
I0522 05:17:06.362514 19252 solver.cpp:253]     Train net output #0: loss = 1.52324 (* 1 = 1.52324 loss)
I0522 05:17:06.362527 19252 sgd_solver.cpp:106] Iteration 224250, lr = 0.004
I0522 05:17:18.582579 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_225000.caffemodel
I0522 05:17:18.633679 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_225000.solverstate
I0522 05:17:18.664536 19252 solver.cpp:341] Iteration 225000, Testing net (#0)
I0522 05:18:10.361187 19252 solver.cpp:409]     Test net output #0: accuracy = 0.897391
I0522 05:18:10.361371 19252 solver.cpp:409]     Test net output #1: loss = 0.341811 (* 1 = 0.341811 loss)
I0522 05:18:31.274374 19252 solver.cpp:237] Iteration 225000, loss = 1.10223
I0522 05:18:31.274425 19252 solver.cpp:253]     Train net output #0: loss = 1.10223 (* 1 = 1.10223 loss)
I0522 05:18:31.274441 19252 sgd_solver.cpp:106] Iteration 225000, lr = 0.004
I0522 05:18:43.447720 19252 solver.cpp:237] Iteration 225750, loss = 1.03539
I0522 05:18:43.449383 19252 solver.cpp:253]     Train net output #0: loss = 1.03539 (* 1 = 1.03539 loss)
I0522 05:18:43.449396 19252 sgd_solver.cpp:106] Iteration 225750, lr = 0.004
I0522 05:18:55.575304 19252 solver.cpp:237] Iteration 226500, loss = 1.34687
I0522 05:18:55.575340 19252 solver.cpp:253]     Train net output #0: loss = 1.34687 (* 1 = 1.34687 loss)
I0522 05:18:55.575352 19252 sgd_solver.cpp:106] Iteration 226500, lr = 0.004
I0522 05:19:07.752672 19252 solver.cpp:237] Iteration 227250, loss = 1.5806
I0522 05:19:07.752708 19252 solver.cpp:253]     Train net output #0: loss = 1.5806 (* 1 = 1.5806 loss)
I0522 05:19:07.752724 19252 sgd_solver.cpp:106] Iteration 227250, lr = 0.004
I0522 05:19:19.918859 19252 solver.cpp:237] Iteration 228000, loss = 1.35511
I0522 05:19:19.919039 19252 solver.cpp:253]     Train net output #0: loss = 1.35511 (* 1 = 1.35511 loss)
I0522 05:19:19.919054 19252 sgd_solver.cpp:106] Iteration 228000, lr = 0.004
I0522 05:19:32.124892 19252 solver.cpp:237] Iteration 228750, loss = 1.0206
I0522 05:19:32.124927 19252 solver.cpp:253]     Train net output #0: loss = 1.0206 (* 1 = 1.0206 loss)
I0522 05:19:32.124943 19252 sgd_solver.cpp:106] Iteration 228750, lr = 0.004
I0522 05:19:44.330708 19252 solver.cpp:237] Iteration 229500, loss = 1.31048
I0522 05:19:44.330751 19252 solver.cpp:253]     Train net output #0: loss = 1.31048 (* 1 = 1.31048 loss)
I0522 05:19:44.330767 19252 sgd_solver.cpp:106] Iteration 229500, lr = 0.004
I0522 05:20:17.379984 19252 solver.cpp:237] Iteration 230250, loss = 1.67216
I0522 05:20:17.380172 19252 solver.cpp:253]     Train net output #0: loss = 1.67216 (* 1 = 1.67216 loss)
I0522 05:20:17.380187 19252 sgd_solver.cpp:106] Iteration 230250, lr = 0.004
I0522 05:20:29.583326 19252 solver.cpp:237] Iteration 231000, loss = 1.33535
I0522 05:20:29.583375 19252 solver.cpp:253]     Train net output #0: loss = 1.33535 (* 1 = 1.33535 loss)
I0522 05:20:29.583389 19252 sgd_solver.cpp:106] Iteration 231000, lr = 0.004
I0522 05:20:41.790439 19252 solver.cpp:237] Iteration 231750, loss = 2.07802
I0522 05:20:41.790475 19252 solver.cpp:253]     Train net output #0: loss = 2.07802 (* 1 = 2.07802 loss)
I0522 05:20:41.790488 19252 sgd_solver.cpp:106] Iteration 231750, lr = 0.004
I0522 05:20:53.981678 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_232500.caffemodel
I0522 05:20:54.234493 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_232500.solverstate
I0522 05:20:54.454675 19252 solver.cpp:237] Iteration 232500, loss = 0.817105
I0522 05:20:54.454723 19252 solver.cpp:253]     Train net output #0: loss = 0.817106 (* 1 = 0.817106 loss)
I0522 05:20:54.454738 19252 sgd_solver.cpp:106] Iteration 232500, lr = 0.004
I0522 05:21:06.619753 19252 solver.cpp:237] Iteration 233250, loss = 1.1509
I0522 05:21:06.619789 19252 solver.cpp:253]     Train net output #0: loss = 1.1509 (* 1 = 1.1509 loss)
I0522 05:21:06.619806 19252 sgd_solver.cpp:106] Iteration 233250, lr = 0.004
I0522 05:21:18.781860 19252 solver.cpp:237] Iteration 234000, loss = 0.898944
I0522 05:21:18.781906 19252 solver.cpp:253]     Train net output #0: loss = 0.898944 (* 1 = 0.898944 loss)
I0522 05:21:18.781920 19252 sgd_solver.cpp:106] Iteration 234000, lr = 0.004
I0522 05:21:30.937103 19252 solver.cpp:237] Iteration 234750, loss = 0.778293
I0522 05:21:30.937286 19252 solver.cpp:253]     Train net output #0: loss = 0.778293 (* 1 = 0.778293 loss)
I0522 05:21:30.937300 19252 sgd_solver.cpp:106] Iteration 234750, lr = 0.004
I0522 05:22:04.028211 19252 solver.cpp:237] Iteration 235500, loss = 1.05302
I0522 05:22:04.028398 19252 solver.cpp:253]     Train net output #0: loss = 1.05302 (* 1 = 1.05302 loss)
I0522 05:22:04.028414 19252 sgd_solver.cpp:106] Iteration 235500, lr = 0.004
I0522 05:22:16.180739 19252 solver.cpp:237] Iteration 236250, loss = 1.35319
I0522 05:22:16.180776 19252 solver.cpp:253]     Train net output #0: loss = 1.35319 (* 1 = 1.35319 loss)
I0522 05:22:16.180794 19252 sgd_solver.cpp:106] Iteration 236250, lr = 0.004
I0522 05:22:28.296111 19252 solver.cpp:237] Iteration 237000, loss = 1.24321
I0522 05:22:28.296146 19252 solver.cpp:253]     Train net output #0: loss = 1.24321 (* 1 = 1.24321 loss)
I0522 05:22:28.296164 19252 sgd_solver.cpp:106] Iteration 237000, lr = 0.004
I0522 05:22:40.435230 19252 solver.cpp:237] Iteration 237750, loss = 1.13421
I0522 05:22:40.435410 19252 solver.cpp:253]     Train net output #0: loss = 1.13421 (* 1 = 1.13421 loss)
I0522 05:22:40.435425 19252 sgd_solver.cpp:106] Iteration 237750, lr = 0.004
I0522 05:22:52.572321 19252 solver.cpp:237] Iteration 238500, loss = 0.950982
I0522 05:22:52.572360 19252 solver.cpp:253]     Train net output #0: loss = 0.950982 (* 1 = 0.950982 loss)
I0522 05:22:52.572374 19252 sgd_solver.cpp:106] Iteration 238500, lr = 0.004
I0522 05:23:04.711001 19252 solver.cpp:237] Iteration 239250, loss = 1.10985
I0522 05:23:04.711051 19252 solver.cpp:253]     Train net output #0: loss = 1.10985 (* 1 = 1.10985 loss)
I0522 05:23:04.711066 19252 sgd_solver.cpp:106] Iteration 239250, lr = 0.004
I0522 05:23:16.830457 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_240000.caffemodel
I0522 05:23:16.879798 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_240000.solverstate
I0522 05:23:16.905128 19252 solver.cpp:341] Iteration 240000, Testing net (#0)
I0522 05:24:29.692013 19252 solver.cpp:409]     Test net output #0: accuracy = 0.897058
I0522 05:24:29.692199 19252 solver.cpp:409]     Test net output #1: loss = 0.338072 (* 1 = 0.338072 loss)
I0522 05:24:50.635681 19252 solver.cpp:237] Iteration 240000, loss = 1.30376
I0522 05:24:50.635736 19252 solver.cpp:253]     Train net output #0: loss = 1.30376 (* 1 = 1.30376 loss)
I0522 05:24:50.635751 19252 sgd_solver.cpp:106] Iteration 240000, lr = 0.004
I0522 05:25:02.814726 19252 solver.cpp:237] Iteration 240750, loss = 0.971797
I0522 05:25:02.814911 19252 solver.cpp:253]     Train net output #0: loss = 0.971797 (* 1 = 0.971797 loss)
I0522 05:25:02.814926 19252 sgd_solver.cpp:106] Iteration 240750, lr = 0.004
I0522 05:25:14.957175 19252 solver.cpp:237] Iteration 241500, loss = 1.01526
I0522 05:25:14.957211 19252 solver.cpp:253]     Train net output #0: loss = 1.01526 (* 1 = 1.01526 loss)
I0522 05:25:14.957226 19252 sgd_solver.cpp:106] Iteration 241500, lr = 0.004
I0522 05:25:27.091768 19252 solver.cpp:237] Iteration 242250, loss = 1.13765
I0522 05:25:27.091815 19252 solver.cpp:253]     Train net output #0: loss = 1.13765 (* 1 = 1.13765 loss)
I0522 05:25:27.091831 19252 sgd_solver.cpp:106] Iteration 242250, lr = 0.004
I0522 05:25:39.249284 19252 solver.cpp:237] Iteration 243000, loss = 1.38849
I0522 05:25:39.249465 19252 solver.cpp:253]     Train net output #0: loss = 1.38849 (* 1 = 1.38849 loss)
I0522 05:25:39.249481 19252 sgd_solver.cpp:106] Iteration 243000, lr = 0.004
I0522 05:25:51.425779 19252 solver.cpp:237] Iteration 243750, loss = 1.33713
I0522 05:25:51.425823 19252 solver.cpp:253]     Train net output #0: loss = 1.33712 (* 1 = 1.33712 loss)
I0522 05:25:51.425839 19252 sgd_solver.cpp:106] Iteration 243750, lr = 0.004
I0522 05:26:03.577345 19252 solver.cpp:237] Iteration 244500, loss = 0.68455
I0522 05:26:03.577383 19252 solver.cpp:253]     Train net output #0: loss = 0.684549 (* 1 = 0.684549 loss)
I0522 05:26:03.577395 19252 sgd_solver.cpp:106] Iteration 244500, lr = 0.004
I0522 05:26:36.603276 19252 solver.cpp:237] Iteration 245250, loss = 0.96244
I0522 05:26:36.603471 19252 solver.cpp:253]     Train net output #0: loss = 0.96244 (* 1 = 0.96244 loss)
I0522 05:26:36.603487 19252 sgd_solver.cpp:106] Iteration 245250, lr = 0.004
I0522 05:26:48.748514 19252 solver.cpp:237] Iteration 246000, loss = 1.00098
I0522 05:26:48.748559 19252 solver.cpp:253]     Train net output #0: loss = 1.00098 (* 1 = 1.00098 loss)
I0522 05:26:48.748575 19252 sgd_solver.cpp:106] Iteration 246000, lr = 0.004
I0522 05:27:00.906952 19252 solver.cpp:237] Iteration 246750, loss = 0.904198
I0522 05:27:00.906988 19252 solver.cpp:253]     Train net output #0: loss = 0.904198 (* 1 = 0.904198 loss)
I0522 05:27:00.907004 19252 sgd_solver.cpp:106] Iteration 246750, lr = 0.004
I0522 05:27:12.999336 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_247500.caffemodel
I0522 05:27:13.049011 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_247500.solverstate
I0522 05:27:13.079340 19252 solver.cpp:237] Iteration 247500, loss = 1.0469
I0522 05:27:13.079385 19252 solver.cpp:253]     Train net output #0: loss = 1.0469 (* 1 = 1.0469 loss)
I0522 05:27:13.079402 19252 sgd_solver.cpp:106] Iteration 247500, lr = 0.004
I0522 05:27:25.243738 19252 solver.cpp:237] Iteration 248250, loss = 1.26557
I0522 05:27:25.243774 19252 solver.cpp:253]     Train net output #0: loss = 1.26557 (* 1 = 1.26557 loss)
I0522 05:27:25.243793 19252 sgd_solver.cpp:106] Iteration 248250, lr = 0.004
I0522 05:27:37.414199 19252 solver.cpp:237] Iteration 249000, loss = 0.899046
I0522 05:27:37.414245 19252 solver.cpp:253]     Train net output #0: loss = 0.899045 (* 1 = 0.899045 loss)
I0522 05:27:37.414259 19252 sgd_solver.cpp:106] Iteration 249000, lr = 0.004
I0522 05:27:49.583050 19252 solver.cpp:237] Iteration 249750, loss = 0.982912
I0522 05:27:49.583225 19252 solver.cpp:253]     Train net output #0: loss = 0.982912 (* 1 = 0.982912 loss)
I0522 05:27:49.583240 19252 sgd_solver.cpp:106] Iteration 249750, lr = 0.004
I0522 05:28:22.668503 19252 solver.cpp:237] Iteration 250500, loss = 0.963868
I0522 05:28:22.668694 19252 solver.cpp:253]     Train net output #0: loss = 0.963867 (* 1 = 0.963867 loss)
I0522 05:28:22.668709 19252 sgd_solver.cpp:106] Iteration 250500, lr = 0.004
I0522 05:28:34.731225 19252 solver.cpp:237] Iteration 251250, loss = 1.43023
I0522 05:28:34.731261 19252 solver.cpp:253]     Train net output #0: loss = 1.43023 (* 1 = 1.43023 loss)
I0522 05:28:34.731276 19252 sgd_solver.cpp:106] Iteration 251250, lr = 0.004
I0522 05:28:46.799892 19252 solver.cpp:237] Iteration 252000, loss = 1.37226
I0522 05:28:46.799942 19252 solver.cpp:253]     Train net output #0: loss = 1.37225 (* 1 = 1.37225 loss)
I0522 05:28:46.799957 19252 sgd_solver.cpp:106] Iteration 252000, lr = 0.004
I0522 05:28:58.867229 19252 solver.cpp:237] Iteration 252750, loss = 1.09993
I0522 05:28:58.867403 19252 solver.cpp:253]     Train net output #0: loss = 1.09993 (* 1 = 1.09993 loss)
I0522 05:28:58.867416 19252 sgd_solver.cpp:106] Iteration 252750, lr = 0.004
I0522 05:29:10.955742 19252 solver.cpp:237] Iteration 253500, loss = 1.43972
I0522 05:29:10.955791 19252 solver.cpp:253]     Train net output #0: loss = 1.43971 (* 1 = 1.43971 loss)
I0522 05:29:10.955806 19252 sgd_solver.cpp:106] Iteration 253500, lr = 0.004
I0522 05:29:23.143132 19252 solver.cpp:237] Iteration 254250, loss = 0.755208
I0522 05:29:23.143168 19252 solver.cpp:253]     Train net output #0: loss = 0.755207 (* 1 = 0.755207 loss)
I0522 05:29:23.143184 19252 sgd_solver.cpp:106] Iteration 254250, lr = 0.004
I0522 05:29:35.303557 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_255000.caffemodel
I0522 05:29:35.352545 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_255000.solverstate
I0522 05:29:35.378264 19252 solver.cpp:341] Iteration 255000, Testing net (#0)
I0522 05:30:27.361232 19252 solver.cpp:409]     Test net output #0: accuracy = 0.899139
I0522 05:30:27.361423 19252 solver.cpp:409]     Test net output #1: loss = 0.336655 (* 1 = 0.336655 loss)
I0522 05:30:48.284260 19252 solver.cpp:237] Iteration 255000, loss = 0.829788
I0522 05:30:48.284315 19252 solver.cpp:253]     Train net output #0: loss = 0.829788 (* 1 = 0.829788 loss)
I0522 05:30:48.284330 19252 sgd_solver.cpp:106] Iteration 255000, lr = 0.004
I0522 05:31:00.460917 19252 solver.cpp:237] Iteration 255750, loss = 0.951613
I0522 05:31:00.461104 19252 solver.cpp:253]     Train net output #0: loss = 0.951613 (* 1 = 0.951613 loss)
I0522 05:31:00.461120 19252 sgd_solver.cpp:106] Iteration 255750, lr = 0.004
I0522 05:31:12.620110 19252 solver.cpp:237] Iteration 256500, loss = 0.905906
I0522 05:31:12.620146 19252 solver.cpp:253]     Train net output #0: loss = 0.905905 (* 1 = 0.905905 loss)
I0522 05:31:12.620162 19252 sgd_solver.cpp:106] Iteration 256500, lr = 0.004
I0522 05:31:24.776453 19252 solver.cpp:237] Iteration 257250, loss = 1.34741
I0522 05:31:24.776501 19252 solver.cpp:253]     Train net output #0: loss = 1.34741 (* 1 = 1.34741 loss)
I0522 05:31:24.776515 19252 sgd_solver.cpp:106] Iteration 257250, lr = 0.004
I0522 05:31:36.962004 19252 solver.cpp:237] Iteration 258000, loss = 1.47996
I0522 05:31:36.962177 19252 solver.cpp:253]     Train net output #0: loss = 1.47996 (* 1 = 1.47996 loss)
I0522 05:31:36.962193 19252 sgd_solver.cpp:106] Iteration 258000, lr = 0.004
I0522 05:31:49.153568 19252 solver.cpp:237] Iteration 258750, loss = 0.948453
I0522 05:31:49.153620 19252 solver.cpp:253]     Train net output #0: loss = 0.948453 (* 1 = 0.948453 loss)
I0522 05:31:49.153633 19252 sgd_solver.cpp:106] Iteration 258750, lr = 0.004
I0522 05:32:01.382731 19252 solver.cpp:237] Iteration 259500, loss = 1.25356
I0522 05:32:01.382766 19252 solver.cpp:253]     Train net output #0: loss = 1.25356 (* 1 = 1.25356 loss)
I0522 05:32:01.382782 19252 sgd_solver.cpp:106] Iteration 259500, lr = 0.004
I0522 05:32:34.538187 19252 solver.cpp:237] Iteration 260250, loss = 1.46335
I0522 05:32:34.538379 19252 solver.cpp:253]     Train net output #0: loss = 1.46335 (* 1 = 1.46335 loss)
I0522 05:32:34.538394 19252 sgd_solver.cpp:106] Iteration 260250, lr = 0.004
I0522 05:32:46.729369 19252 solver.cpp:237] Iteration 261000, loss = 1.33728
I0522 05:32:46.729405 19252 solver.cpp:253]     Train net output #0: loss = 1.33728 (* 1 = 1.33728 loss)
I0522 05:32:46.729423 19252 sgd_solver.cpp:106] Iteration 261000, lr = 0.004
I0522 05:32:58.951835 19252 solver.cpp:237] Iteration 261750, loss = 1.17135
I0522 05:32:58.951884 19252 solver.cpp:253]     Train net output #0: loss = 1.17135 (* 1 = 1.17135 loss)
I0522 05:32:58.951900 19252 sgd_solver.cpp:106] Iteration 261750, lr = 0.004
I0522 05:33:11.143245 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_262500.caffemodel
I0522 05:33:11.194653 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_262500.solverstate
I0522 05:33:11.228163 19252 solver.cpp:237] Iteration 262500, loss = 1.26978
I0522 05:33:11.228212 19252 solver.cpp:253]     Train net output #0: loss = 1.26978 (* 1 = 1.26978 loss)
I0522 05:33:11.228230 19252 sgd_solver.cpp:106] Iteration 262500, lr = 0.004
I0522 05:33:23.404866 19252 solver.cpp:237] Iteration 263250, loss = 1.39852
I0522 05:33:23.404927 19252 solver.cpp:253]     Train net output #0: loss = 1.39852 (* 1 = 1.39852 loss)
I0522 05:33:23.404940 19252 sgd_solver.cpp:106] Iteration 263250, lr = 0.004
I0522 05:33:35.545845 19252 solver.cpp:237] Iteration 264000, loss = 1.11409
I0522 05:33:35.545881 19252 solver.cpp:253]     Train net output #0: loss = 1.11409 (* 1 = 1.11409 loss)
I0522 05:33:35.545893 19252 sgd_solver.cpp:106] Iteration 264000, lr = 0.004
I0522 05:33:47.726541 19252 solver.cpp:237] Iteration 264750, loss = 1.1204
I0522 05:33:47.726740 19252 solver.cpp:253]     Train net output #0: loss = 1.1204 (* 1 = 1.1204 loss)
I0522 05:33:47.726753 19252 sgd_solver.cpp:106] Iteration 264750, lr = 0.004
I0522 05:34:20.805097 19252 solver.cpp:237] Iteration 265500, loss = 1.24184
I0522 05:34:20.805291 19252 solver.cpp:253]     Train net output #0: loss = 1.24184 (* 1 = 1.24184 loss)
I0522 05:34:20.805305 19252 sgd_solver.cpp:106] Iteration 265500, lr = 0.004
I0522 05:34:32.998988 19252 solver.cpp:237] Iteration 266250, loss = 0.934441
I0522 05:34:32.999024 19252 solver.cpp:253]     Train net output #0: loss = 0.934441 (* 1 = 0.934441 loss)
I0522 05:34:32.999042 19252 sgd_solver.cpp:106] Iteration 266250, lr = 0.004
I0522 05:34:45.187603 19252 solver.cpp:237] Iteration 267000, loss = 1.60638
I0522 05:34:45.187649 19252 solver.cpp:253]     Train net output #0: loss = 1.60638 (* 1 = 1.60638 loss)
I0522 05:34:45.187664 19252 sgd_solver.cpp:106] Iteration 267000, lr = 0.004
I0522 05:34:57.379645 19252 solver.cpp:237] Iteration 267750, loss = 1.07974
I0522 05:34:57.379817 19252 solver.cpp:253]     Train net output #0: loss = 1.07974 (* 1 = 1.07974 loss)
I0522 05:34:57.379832 19252 sgd_solver.cpp:106] Iteration 267750, lr = 0.004
I0522 05:35:09.567669 19252 solver.cpp:237] Iteration 268500, loss = 0.66646
I0522 05:35:09.567716 19252 solver.cpp:253]     Train net output #0: loss = 0.666461 (* 1 = 0.666461 loss)
I0522 05:35:09.567730 19252 sgd_solver.cpp:106] Iteration 268500, lr = 0.004
I0522 05:35:21.761214 19252 solver.cpp:237] Iteration 269250, loss = 0.96376
I0522 05:35:21.761251 19252 solver.cpp:253]     Train net output #0: loss = 0.963761 (* 1 = 0.963761 loss)
I0522 05:35:21.761267 19252 sgd_solver.cpp:106] Iteration 269250, lr = 0.004
I0522 05:35:33.939857 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_270000.caffemodel
I0522 05:35:33.991160 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_270000.solverstate
I0522 05:35:34.018362 19252 solver.cpp:341] Iteration 270000, Testing net (#0)
I0522 05:36:46.910086 19252 solver.cpp:409]     Test net output #0: accuracy = 0.898052
I0522 05:36:46.910290 19252 solver.cpp:409]     Test net output #1: loss = 0.333934 (* 1 = 0.333934 loss)
I0522 05:37:07.785935 19252 solver.cpp:237] Iteration 270000, loss = 1.11974
I0522 05:37:07.785989 19252 solver.cpp:253]     Train net output #0: loss = 1.11974 (* 1 = 1.11974 loss)
I0522 05:37:07.786003 19252 sgd_solver.cpp:106] Iteration 270000, lr = 0.004
I0522 05:37:19.915428 19252 solver.cpp:237] Iteration 270750, loss = 0.845409
I0522 05:37:19.915609 19252 solver.cpp:253]     Train net output #0: loss = 0.845409 (* 1 = 0.845409 loss)
I0522 05:37:19.915624 19252 sgd_solver.cpp:106] Iteration 270750, lr = 0.004
I0522 05:37:32.014361 19252 solver.cpp:237] Iteration 271500, loss = 0.969525
I0522 05:37:32.014410 19252 solver.cpp:253]     Train net output #0: loss = 0.969526 (* 1 = 0.969526 loss)
I0522 05:37:32.014425 19252 sgd_solver.cpp:106] Iteration 271500, lr = 0.004
I0522 05:37:44.116462 19252 solver.cpp:237] Iteration 272250, loss = 1.05566
I0522 05:37:44.116498 19252 solver.cpp:253]     Train net output #0: loss = 1.05566 (* 1 = 1.05566 loss)
I0522 05:37:44.116514 19252 sgd_solver.cpp:106] Iteration 272250, lr = 0.004
I0522 05:37:56.240314 19252 solver.cpp:237] Iteration 273000, loss = 0.967975
I0522 05:37:56.240514 19252 solver.cpp:253]     Train net output #0: loss = 0.967975 (* 1 = 0.967975 loss)
I0522 05:37:56.240530 19252 sgd_solver.cpp:106] Iteration 273000, lr = 0.004
I0522 05:38:08.359410 19252 solver.cpp:237] Iteration 273750, loss = 1.18642
I0522 05:38:08.359446 19252 solver.cpp:253]     Train net output #0: loss = 1.18642 (* 1 = 1.18642 loss)
I0522 05:38:08.359462 19252 sgd_solver.cpp:106] Iteration 273750, lr = 0.004
I0522 05:38:20.482199 19252 solver.cpp:237] Iteration 274500, loss = 1.25707
I0522 05:38:20.482244 19252 solver.cpp:253]     Train net output #0: loss = 1.25707 (* 1 = 1.25707 loss)
I0522 05:38:20.482261 19252 sgd_solver.cpp:106] Iteration 274500, lr = 0.004
I0522 05:38:53.498358 19252 solver.cpp:237] Iteration 275250, loss = 1.30777
I0522 05:38:53.498554 19252 solver.cpp:253]     Train net output #0: loss = 1.30777 (* 1 = 1.30777 loss)
I0522 05:38:53.498569 19252 sgd_solver.cpp:106] Iteration 275250, lr = 0.004
I0522 05:39:05.644274 19252 solver.cpp:237] Iteration 276000, loss = 1.20488
I0522 05:39:05.644310 19252 solver.cpp:253]     Train net output #0: loss = 1.20488 (* 1 = 1.20488 loss)
I0522 05:39:05.644326 19252 sgd_solver.cpp:106] Iteration 276000, lr = 0.004
I0522 05:39:17.816974 19252 solver.cpp:237] Iteration 276750, loss = 1.05558
I0522 05:39:17.817019 19252 solver.cpp:253]     Train net output #0: loss = 1.05558 (* 1 = 1.05558 loss)
I0522 05:39:17.817034 19252 sgd_solver.cpp:106] Iteration 276750, lr = 0.004
I0522 05:39:29.972519 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_277500.caffemodel
I0522 05:39:30.022346 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_277500.solverstate
I0522 05:39:30.053283 19252 solver.cpp:237] Iteration 277500, loss = 1.79227
I0522 05:39:30.053325 19252 solver.cpp:253]     Train net output #0: loss = 1.79227 (* 1 = 1.79227 loss)
I0522 05:39:30.053342 19252 sgd_solver.cpp:106] Iteration 277500, lr = 0.004
I0522 05:39:42.216305 19252 solver.cpp:237] Iteration 278250, loss = 1.26366
I0522 05:39:42.216351 19252 solver.cpp:253]     Train net output #0: loss = 1.26366 (* 1 = 1.26366 loss)
I0522 05:39:42.216367 19252 sgd_solver.cpp:106] Iteration 278250, lr = 0.004
I0522 05:39:54.371773 19252 solver.cpp:237] Iteration 279000, loss = 1.25874
I0522 05:39:54.371809 19252 solver.cpp:253]     Train net output #0: loss = 1.25874 (* 1 = 1.25874 loss)
I0522 05:39:54.371825 19252 sgd_solver.cpp:106] Iteration 279000, lr = 0.004
I0522 05:40:06.512581 19252 solver.cpp:237] Iteration 279750, loss = 1.08992
I0522 05:40:06.512768 19252 solver.cpp:253]     Train net output #0: loss = 1.08992 (* 1 = 1.08992 loss)
I0522 05:40:06.512781 19252 sgd_solver.cpp:106] Iteration 279750, lr = 0.004
I0522 05:40:39.576488 19252 solver.cpp:237] Iteration 280500, loss = 1.53403
I0522 05:40:39.576684 19252 solver.cpp:253]     Train net output #0: loss = 1.53403 (* 1 = 1.53403 loss)
I0522 05:40:39.576699 19252 sgd_solver.cpp:106] Iteration 280500, lr = 0.004
I0522 05:40:51.712540 19252 solver.cpp:237] Iteration 281250, loss = 1.32323
I0522 05:40:51.712586 19252 solver.cpp:253]     Train net output #0: loss = 1.32323 (* 1 = 1.32323 loss)
I0522 05:40:51.712601 19252 sgd_solver.cpp:106] Iteration 281250, lr = 0.004
I0522 05:41:03.844789 19252 solver.cpp:237] Iteration 282000, loss = 1.31129
I0522 05:41:03.844825 19252 solver.cpp:253]     Train net output #0: loss = 1.31129 (* 1 = 1.31129 loss)
I0522 05:41:03.844841 19252 sgd_solver.cpp:106] Iteration 282000, lr = 0.004
I0522 05:41:15.991726 19252 solver.cpp:237] Iteration 282750, loss = 1.22588
I0522 05:41:15.991919 19252 solver.cpp:253]     Train net output #0: loss = 1.22588 (* 1 = 1.22588 loss)
I0522 05:41:15.991935 19252 sgd_solver.cpp:106] Iteration 282750, lr = 0.004
I0522 05:41:28.119143 19252 solver.cpp:237] Iteration 283500, loss = 1.4909
I0522 05:41:28.119179 19252 solver.cpp:253]     Train net output #0: loss = 1.4909 (* 1 = 1.4909 loss)
I0522 05:41:28.119195 19252 sgd_solver.cpp:106] Iteration 283500, lr = 0.004
I0522 05:41:40.238685 19252 solver.cpp:237] Iteration 284250, loss = 1.34393
I0522 05:41:40.238731 19252 solver.cpp:253]     Train net output #0: loss = 1.34393 (* 1 = 1.34393 loss)
I0522 05:41:40.238749 19252 sgd_solver.cpp:106] Iteration 284250, lr = 0.004
I0522 05:41:52.365288 19252 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_285000.caffemodel
I0522 05:41:52.415266 19252 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0040_2016-05-20T15.48.56.158271_iter_285000.solverstate
I0522 05:41:52.440691 19252 solver.cpp:341] Iteration 285000, Testing net (#0)
I0522 05:42:44.089468 19252 solver.cpp:409]     Test net output #0: accuracy = 0.898637
I0522 05:42:44.089658 19252 solver.cpp:409]     Test net output #1: loss = 0.315301 (* 1 = 0.315301 loss)
I0522 05:43:05.005825 19252 solver.cpp:237] Iteration 285000, loss = 1.55665
I0522 05:43:05.005878 19252 solver.cpp:253]     Train net output #0: loss = 1.55665 (* 1 = 1.55665 loss)
I0522 05:43:05.005892 19252 sgd_solver.cpp:106] Iteration 285000, lr = 0.004
I0522 05:43:17.162098 19252 solver.cpp:237] Iteration 285750, loss = 1.0619
I0522 05:43:17.162276 19252 solver.cpp:253]     Train net output #0: loss = 1.0619 (* 1 = 1.0619 loss)
I0522 05:43:17.162292 19252 sgd_solver.cpp:106] Iteration 285750, lr = 0.004
I0522 05:43:29.381731 19252 solver.cpp:237] Iteration 286500, loss = 0.565811
I0522 05:43:29.381778 19252 solver.cpp:253]     Train net output #0: loss = 0.565812 (* 1 = 0.565812 loss)
I0522 05:43:29.381793 19252 sgd_solver.cpp:106] Iteration 286500, lr = 0.004
I0522 05:43:41.578951 19252 solver.cpp:237] Iteration 287250, loss = 0.94793
I0522 05:43:41.578989 19252 solver.cpp:253]     Train net output #0: loss = 0.947931 (* 1 = 0.947931 loss)
I0522 05:43:41.579004 19252 sgd_solver.cpp:106] Iteration 287250, lr = 0.004
I0522 05:43:53.773980 19252 solver.cpp:237] Iteration 288000, loss = 0.921436
I0522 05:43:53.774168 19252 solver.cpp:253]     Train net output #0: loss = 0.921438 (* 1 = 0.921438 loss)
I0522 05:43:53.774183 19252 sgd_solver.cpp:106] Iteration 288000, lr = 0.004
I0522 05:44:05.969812 19252 solver.cpp:237] Iteration 288750, loss = 0.811074
I0522 05:44:05.969849 19252 solver.cpp:253]     Train net output #0: loss = 0.811076 (* 1 = 0.811076 loss)
I0522 05:44:05.969866 19252 sgd_solver.cpp:106] Iteration 288750, lr = 0.004
I0522 05:44:18.121482 19252 solver.cpp:237] Iteration 289500, loss = 0.754267
I0522 05:44:18.121531 19252 solver.cpp:253]     Train net output #0: loss = 0.754269 (* 1 = 0.754269 loss)
I0522 05:44:18.121546 19252 sgd_solver.cpp:106] Iteration 289500, lr = 0.004
aprun: Apid 11245181: Caught signal Terminated, sending to application
*** Aborted at 1463910278 (unix time) try "date -d @1463910278" if you are using GNU date ***
aprun: Apid 11245181: Caught signal Terminated, sending to application
PC: @     0x2aaac5e9dd16 inflate
*** SIGTERM (@0x4b31) received by PID 19252 (TID 0x2aaac746f900) from PID 19249; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @     0x2aaac5e9dd16 inflate
=>> PBS: job killed: walltime 7241 exceeded limit 7200
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11245181: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
aprun: Apid 11245181: Caught signal Terminated, sending to application
