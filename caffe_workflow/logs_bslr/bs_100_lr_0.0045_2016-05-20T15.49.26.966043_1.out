2810968
I0525 20:57:52.640343 29460 caffe.cpp:184] Using GPUs 0
I0525 20:57:53.065806 29460 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.0045
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043.prototxt"
I0525 20:57:53.067509 29460 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043.prototxt
I0525 20:57:53.083164 29460 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 20:57:53.083230 29460 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 20:57:53.083607 29460 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 20:57:53.083811 29460 layer_factory.hpp:77] Creating layer data_hdf5
I0525 20:57:53.083840 29460 net.cpp:106] Creating Layer data_hdf5
I0525 20:57:53.083865 29460 net.cpp:411] data_hdf5 -> data
I0525 20:57:53.083899 29460 net.cpp:411] data_hdf5 -> label
I0525 20:57:53.083941 29460 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 20:57:53.085324 29460 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 20:57:53.087684 29460 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 20:58:14.656121 29460 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 20:58:14.661309 29460 net.cpp:150] Setting up data_hdf5
I0525 20:58:14.661350 29460 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 20:58:14.661367 29460 net.cpp:157] Top shape: 100 (100)
I0525 20:58:14.661384 29460 net.cpp:165] Memory required for data: 2540400
I0525 20:58:14.661414 29460 layer_factory.hpp:77] Creating layer conv1
I0525 20:58:14.661448 29460 net.cpp:106] Creating Layer conv1
I0525 20:58:14.661470 29460 net.cpp:454] conv1 <- data
I0525 20:58:14.661495 29460 net.cpp:411] conv1 -> conv1
I0525 20:58:15.029907 29460 net.cpp:150] Setting up conv1
I0525 20:58:15.029961 29460 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:58:15.029989 29460 net.cpp:165] Memory required for data: 30188400
I0525 20:58:15.030020 29460 layer_factory.hpp:77] Creating layer relu1
I0525 20:58:15.030042 29460 net.cpp:106] Creating Layer relu1
I0525 20:58:15.030062 29460 net.cpp:454] relu1 <- conv1
I0525 20:58:15.030098 29460 net.cpp:397] relu1 -> conv1 (in-place)
I0525 20:58:15.030629 29460 net.cpp:150] Setting up relu1
I0525 20:58:15.030653 29460 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:58:15.030666 29460 net.cpp:165] Memory required for data: 57836400
I0525 20:58:15.030683 29460 layer_factory.hpp:77] Creating layer pool1
I0525 20:58:15.030709 29460 net.cpp:106] Creating Layer pool1
I0525 20:58:15.030724 29460 net.cpp:454] pool1 <- conv1
I0525 20:58:15.030740 29460 net.cpp:411] pool1 -> pool1
I0525 20:58:15.030833 29460 net.cpp:150] Setting up pool1
I0525 20:58:15.030850 29460 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 20:58:15.030865 29460 net.cpp:165] Memory required for data: 71660400
I0525 20:58:15.030886 29460 layer_factory.hpp:77] Creating layer conv2
I0525 20:58:15.030910 29460 net.cpp:106] Creating Layer conv2
I0525 20:58:15.030925 29460 net.cpp:454] conv2 <- pool1
I0525 20:58:15.030939 29460 net.cpp:411] conv2 -> conv2
I0525 20:58:15.033680 29460 net.cpp:150] Setting up conv2
I0525 20:58:15.033715 29460 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:58:15.033728 29460 net.cpp:165] Memory required for data: 91532400
I0525 20:58:15.033756 29460 layer_factory.hpp:77] Creating layer relu2
I0525 20:58:15.033783 29460 net.cpp:106] Creating Layer relu2
I0525 20:58:15.033797 29460 net.cpp:454] relu2 <- conv2
I0525 20:58:15.033813 29460 net.cpp:397] relu2 -> conv2 (in-place)
I0525 20:58:15.034173 29460 net.cpp:150] Setting up relu2
I0525 20:58:15.034193 29460 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:58:15.034206 29460 net.cpp:165] Memory required for data: 111404400
I0525 20:58:15.034219 29460 layer_factory.hpp:77] Creating layer pool2
I0525 20:58:15.034245 29460 net.cpp:106] Creating Layer pool2
I0525 20:58:15.034258 29460 net.cpp:454] pool2 <- conv2
I0525 20:58:15.034274 29460 net.cpp:411] pool2 -> pool2
I0525 20:58:15.034369 29460 net.cpp:150] Setting up pool2
I0525 20:58:15.034387 29460 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 20:58:15.034402 29460 net.cpp:165] Memory required for data: 121340400
I0525 20:58:15.034422 29460 layer_factory.hpp:77] Creating layer conv3
I0525 20:58:15.034443 29460 net.cpp:106] Creating Layer conv3
I0525 20:58:15.034463 29460 net.cpp:454] conv3 <- pool2
I0525 20:58:15.034481 29460 net.cpp:411] conv3 -> conv3
I0525 20:58:15.036424 29460 net.cpp:150] Setting up conv3
I0525 20:58:15.036449 29460 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:58:15.036469 29460 net.cpp:165] Memory required for data: 132182000
I0525 20:58:15.036492 29460 layer_factory.hpp:77] Creating layer relu3
I0525 20:58:15.036514 29460 net.cpp:106] Creating Layer relu3
I0525 20:58:15.036536 29460 net.cpp:454] relu3 <- conv3
I0525 20:58:15.036553 29460 net.cpp:397] relu3 -> conv3 (in-place)
I0525 20:58:15.037046 29460 net.cpp:150] Setting up relu3
I0525 20:58:15.037071 29460 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:58:15.037084 29460 net.cpp:165] Memory required for data: 143023600
I0525 20:58:15.037101 29460 layer_factory.hpp:77] Creating layer pool3
I0525 20:58:15.037117 29460 net.cpp:106] Creating Layer pool3
I0525 20:58:15.037138 29460 net.cpp:454] pool3 <- conv3
I0525 20:58:15.037153 29460 net.cpp:411] pool3 -> pool3
I0525 20:58:15.037235 29460 net.cpp:150] Setting up pool3
I0525 20:58:15.037258 29460 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 20:58:15.037271 29460 net.cpp:165] Memory required for data: 148444400
I0525 20:58:15.037286 29460 layer_factory.hpp:77] Creating layer conv4
I0525 20:58:15.037312 29460 net.cpp:106] Creating Layer conv4
I0525 20:58:15.037327 29460 net.cpp:454] conv4 <- pool3
I0525 20:58:15.037343 29460 net.cpp:411] conv4 -> conv4
I0525 20:58:15.040295 29460 net.cpp:150] Setting up conv4
I0525 20:58:15.040331 29460 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:58:15.040345 29460 net.cpp:165] Memory required for data: 152073200
I0525 20:58:15.040369 29460 layer_factory.hpp:77] Creating layer relu4
I0525 20:58:15.040398 29460 net.cpp:106] Creating Layer relu4
I0525 20:58:15.040412 29460 net.cpp:454] relu4 <- conv4
I0525 20:58:15.040428 29460 net.cpp:397] relu4 -> conv4 (in-place)
I0525 20:58:15.040930 29460 net.cpp:150] Setting up relu4
I0525 20:58:15.040952 29460 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:58:15.040966 29460 net.cpp:165] Memory required for data: 155702000
I0525 20:58:15.040982 29460 layer_factory.hpp:77] Creating layer pool4
I0525 20:58:15.041007 29460 net.cpp:106] Creating Layer pool4
I0525 20:58:15.041020 29460 net.cpp:454] pool4 <- conv4
I0525 20:58:15.041036 29460 net.cpp:411] pool4 -> pool4
I0525 20:58:15.041121 29460 net.cpp:150] Setting up pool4
I0525 20:58:15.041144 29460 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 20:58:15.041157 29460 net.cpp:165] Memory required for data: 157516400
I0525 20:58:15.041172 29460 layer_factory.hpp:77] Creating layer ip1
I0525 20:58:15.041200 29460 net.cpp:106] Creating Layer ip1
I0525 20:58:15.041214 29460 net.cpp:454] ip1 <- pool4
I0525 20:58:15.041230 29460 net.cpp:411] ip1 -> ip1
I0525 20:58:15.056658 29460 net.cpp:150] Setting up ip1
I0525 20:58:15.056686 29460 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:58:15.056709 29460 net.cpp:165] Memory required for data: 157594800
I0525 20:58:15.056735 29460 layer_factory.hpp:77] Creating layer relu5
I0525 20:58:15.056756 29460 net.cpp:106] Creating Layer relu5
I0525 20:58:15.056768 29460 net.cpp:454] relu5 <- ip1
I0525 20:58:15.056807 29460 net.cpp:397] relu5 -> ip1 (in-place)
I0525 20:58:15.057166 29460 net.cpp:150] Setting up relu5
I0525 20:58:15.057186 29460 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:58:15.057199 29460 net.cpp:165] Memory required for data: 157673200
I0525 20:58:15.057214 29460 layer_factory.hpp:77] Creating layer drop1
I0525 20:58:15.057245 29460 net.cpp:106] Creating Layer drop1
I0525 20:58:15.057260 29460 net.cpp:454] drop1 <- ip1
I0525 20:58:15.057276 29460 net.cpp:397] drop1 -> ip1 (in-place)
I0525 20:58:15.057346 29460 net.cpp:150] Setting up drop1
I0525 20:58:15.057373 29460 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:58:15.057385 29460 net.cpp:165] Memory required for data: 157751600
I0525 20:58:15.057400 29460 layer_factory.hpp:77] Creating layer ip2
I0525 20:58:15.057422 29460 net.cpp:106] Creating Layer ip2
I0525 20:58:15.057441 29460 net.cpp:454] ip2 <- ip1
I0525 20:58:15.057457 29460 net.cpp:411] ip2 -> ip2
I0525 20:58:15.057946 29460 net.cpp:150] Setting up ip2
I0525 20:58:15.057966 29460 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:58:15.057979 29460 net.cpp:165] Memory required for data: 157790800
I0525 20:58:15.057999 29460 layer_factory.hpp:77] Creating layer relu6
I0525 20:58:15.058022 29460 net.cpp:106] Creating Layer relu6
I0525 20:58:15.058034 29460 net.cpp:454] relu6 <- ip2
I0525 20:58:15.058049 29460 net.cpp:397] relu6 -> ip2 (in-place)
I0525 20:58:15.058604 29460 net.cpp:150] Setting up relu6
I0525 20:58:15.058627 29460 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:58:15.058640 29460 net.cpp:165] Memory required for data: 157830000
I0525 20:58:15.058656 29460 layer_factory.hpp:77] Creating layer drop2
I0525 20:58:15.058671 29460 net.cpp:106] Creating Layer drop2
I0525 20:58:15.058693 29460 net.cpp:454] drop2 <- ip2
I0525 20:58:15.058709 29460 net.cpp:397] drop2 -> ip2 (in-place)
I0525 20:58:15.058758 29460 net.cpp:150] Setting up drop2
I0525 20:58:15.058781 29460 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:58:15.058794 29460 net.cpp:165] Memory required for data: 157869200
I0525 20:58:15.058807 29460 layer_factory.hpp:77] Creating layer ip3
I0525 20:58:15.058826 29460 net.cpp:106] Creating Layer ip3
I0525 20:58:15.058840 29460 net.cpp:454] ip3 <- ip2
I0525 20:58:15.058861 29460 net.cpp:411] ip3 -> ip3
I0525 20:58:15.059082 29460 net.cpp:150] Setting up ip3
I0525 20:58:15.059103 29460 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:58:15.059114 29460 net.cpp:165] Memory required for data: 157873600
I0525 20:58:15.059135 29460 layer_factory.hpp:77] Creating layer drop3
I0525 20:58:15.059150 29460 net.cpp:106] Creating Layer drop3
I0525 20:58:15.059164 29460 net.cpp:454] drop3 <- ip3
I0525 20:58:15.059185 29460 net.cpp:397] drop3 -> ip3 (in-place)
I0525 20:58:15.059231 29460 net.cpp:150] Setting up drop3
I0525 20:58:15.059247 29460 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:58:15.059262 29460 net.cpp:165] Memory required for data: 157878000
I0525 20:58:15.059286 29460 layer_factory.hpp:77] Creating layer loss
I0525 20:58:15.059308 29460 net.cpp:106] Creating Layer loss
I0525 20:58:15.059324 29460 net.cpp:454] loss <- ip3
I0525 20:58:15.059336 29460 net.cpp:454] loss <- label
I0525 20:58:15.059358 29460 net.cpp:411] loss -> loss
I0525 20:58:15.059376 29460 layer_factory.hpp:77] Creating layer loss
I0525 20:58:15.060044 29460 net.cpp:150] Setting up loss
I0525 20:58:15.060065 29460 net.cpp:157] Top shape: (1)
I0525 20:58:15.060081 29460 net.cpp:160]     with loss weight 1
I0525 20:58:15.060130 29460 net.cpp:165] Memory required for data: 157878004
I0525 20:58:15.060151 29460 net.cpp:226] loss needs backward computation.
I0525 20:58:15.060165 29460 net.cpp:226] drop3 needs backward computation.
I0525 20:58:15.060178 29460 net.cpp:226] ip3 needs backward computation.
I0525 20:58:15.060191 29460 net.cpp:226] drop2 needs backward computation.
I0525 20:58:15.060204 29460 net.cpp:226] relu6 needs backward computation.
I0525 20:58:15.060219 29460 net.cpp:226] ip2 needs backward computation.
I0525 20:58:15.060231 29460 net.cpp:226] drop1 needs backward computation.
I0525 20:58:15.060250 29460 net.cpp:226] relu5 needs backward computation.
I0525 20:58:15.060262 29460 net.cpp:226] ip1 needs backward computation.
I0525 20:58:15.060276 29460 net.cpp:226] pool4 needs backward computation.
I0525 20:58:15.060289 29460 net.cpp:226] relu4 needs backward computation.
I0525 20:58:15.060304 29460 net.cpp:226] conv4 needs backward computation.
I0525 20:58:15.060317 29460 net.cpp:226] pool3 needs backward computation.
I0525 20:58:15.060338 29460 net.cpp:226] relu3 needs backward computation.
I0525 20:58:15.060360 29460 net.cpp:226] conv3 needs backward computation.
I0525 20:58:15.060374 29460 net.cpp:226] pool2 needs backward computation.
I0525 20:58:15.060386 29460 net.cpp:226] relu2 needs backward computation.
I0525 20:58:15.060401 29460 net.cpp:226] conv2 needs backward computation.
I0525 20:58:15.060415 29460 net.cpp:226] pool1 needs backward computation.
I0525 20:58:15.060436 29460 net.cpp:226] relu1 needs backward computation.
I0525 20:58:15.060449 29460 net.cpp:226] conv1 needs backward computation.
I0525 20:58:15.060467 29460 net.cpp:228] data_hdf5 does not need backward computation.
I0525 20:58:15.060479 29460 net.cpp:270] This network produces output loss
I0525 20:58:15.060509 29460 net.cpp:283] Network initialization done.
I0525 20:58:15.062222 29460 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043.prototxt
I0525 20:58:15.062301 29460 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 20:58:15.062681 29460 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 20:58:15.062903 29460 layer_factory.hpp:77] Creating layer data_hdf5
I0525 20:58:15.062924 29460 net.cpp:106] Creating Layer data_hdf5
I0525 20:58:15.062942 29460 net.cpp:411] data_hdf5 -> data
I0525 20:58:15.062963 29460 net.cpp:411] data_hdf5 -> label
I0525 20:58:15.062983 29460 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 20:58:15.064292 29460 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 20:58:36.393110 29460 net.cpp:150] Setting up data_hdf5
I0525 20:58:36.393276 29460 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 20:58:36.393296 29460 net.cpp:157] Top shape: 100 (100)
I0525 20:58:36.393309 29460 net.cpp:165] Memory required for data: 2540400
I0525 20:58:36.393323 29460 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 20:58:36.393352 29460 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 20:58:36.393371 29460 net.cpp:454] label_data_hdf5_1_split <- label
I0525 20:58:36.393409 29460 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 20:58:36.393431 29460 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 20:58:36.393512 29460 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 20:58:36.393534 29460 net.cpp:157] Top shape: 100 (100)
I0525 20:58:36.393549 29460 net.cpp:157] Top shape: 100 (100)
I0525 20:58:36.393573 29460 net.cpp:165] Memory required for data: 2541200
I0525 20:58:36.393585 29460 layer_factory.hpp:77] Creating layer conv1
I0525 20:58:36.393611 29460 net.cpp:106] Creating Layer conv1
I0525 20:58:36.393630 29460 net.cpp:454] conv1 <- data
I0525 20:58:36.393649 29460 net.cpp:411] conv1 -> conv1
I0525 20:58:36.395628 29460 net.cpp:150] Setting up conv1
I0525 20:58:36.395654 29460 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:58:36.395675 29460 net.cpp:165] Memory required for data: 30189200
I0525 20:58:36.395699 29460 layer_factory.hpp:77] Creating layer relu1
I0525 20:58:36.395720 29460 net.cpp:106] Creating Layer relu1
I0525 20:58:36.395743 29460 net.cpp:454] relu1 <- conv1
I0525 20:58:36.395758 29460 net.cpp:397] relu1 -> conv1 (in-place)
I0525 20:58:36.396281 29460 net.cpp:150] Setting up relu1
I0525 20:58:36.396303 29460 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:58:36.396317 29460 net.cpp:165] Memory required for data: 57837200
I0525 20:58:36.396328 29460 layer_factory.hpp:77] Creating layer pool1
I0525 20:58:36.396359 29460 net.cpp:106] Creating Layer pool1
I0525 20:58:36.396373 29460 net.cpp:454] pool1 <- conv1
I0525 20:58:36.396389 29460 net.cpp:411] pool1 -> pool1
I0525 20:58:36.396477 29460 net.cpp:150] Setting up pool1
I0525 20:58:36.396494 29460 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 20:58:36.396509 29460 net.cpp:165] Memory required for data: 71661200
I0525 20:58:36.396528 29460 layer_factory.hpp:77] Creating layer conv2
I0525 20:58:36.396549 29460 net.cpp:106] Creating Layer conv2
I0525 20:58:36.396561 29460 net.cpp:454] conv2 <- pool1
I0525 20:58:36.396579 29460 net.cpp:411] conv2 -> conv2
I0525 20:58:36.398546 29460 net.cpp:150] Setting up conv2
I0525 20:58:36.398571 29460 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:58:36.398591 29460 net.cpp:165] Memory required for data: 91533200
I0525 20:58:36.398613 29460 layer_factory.hpp:77] Creating layer relu2
I0525 20:58:36.398633 29460 net.cpp:106] Creating Layer relu2
I0525 20:58:36.398655 29460 net.cpp:454] relu2 <- conv2
I0525 20:58:36.398671 29460 net.cpp:397] relu2 -> conv2 (in-place)
I0525 20:58:36.399024 29460 net.cpp:150] Setting up relu2
I0525 20:58:36.399042 29460 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:58:36.399055 29460 net.cpp:165] Memory required for data: 111405200
I0525 20:58:36.399067 29460 layer_factory.hpp:77] Creating layer pool2
I0525 20:58:36.399093 29460 net.cpp:106] Creating Layer pool2
I0525 20:58:36.399106 29460 net.cpp:454] pool2 <- conv2
I0525 20:58:36.399122 29460 net.cpp:411] pool2 -> pool2
I0525 20:58:36.399214 29460 net.cpp:150] Setting up pool2
I0525 20:58:36.399231 29460 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 20:58:36.399250 29460 net.cpp:165] Memory required for data: 121341200
I0525 20:58:36.399262 29460 layer_factory.hpp:77] Creating layer conv3
I0525 20:58:36.399288 29460 net.cpp:106] Creating Layer conv3
I0525 20:58:36.399307 29460 net.cpp:454] conv3 <- pool2
I0525 20:58:36.399324 29460 net.cpp:411] conv3 -> conv3
I0525 20:58:36.401342 29460 net.cpp:150] Setting up conv3
I0525 20:58:36.401367 29460 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:58:36.401381 29460 net.cpp:165] Memory required for data: 132182800
I0525 20:58:36.401418 29460 layer_factory.hpp:77] Creating layer relu3
I0525 20:58:36.401445 29460 net.cpp:106] Creating Layer relu3
I0525 20:58:36.401458 29460 net.cpp:454] relu3 <- conv3
I0525 20:58:36.401481 29460 net.cpp:397] relu3 -> conv3 (in-place)
I0525 20:58:36.401980 29460 net.cpp:150] Setting up relu3
I0525 20:58:36.402004 29460 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:58:36.402016 29460 net.cpp:165] Memory required for data: 143024400
I0525 20:58:36.402032 29460 layer_factory.hpp:77] Creating layer pool3
I0525 20:58:36.402048 29460 net.cpp:106] Creating Layer pool3
I0525 20:58:36.402070 29460 net.cpp:454] pool3 <- conv3
I0525 20:58:36.402086 29460 net.cpp:411] pool3 -> pool3
I0525 20:58:36.402173 29460 net.cpp:150] Setting up pool3
I0525 20:58:36.402190 29460 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 20:58:36.402205 29460 net.cpp:165] Memory required for data: 148445200
I0525 20:58:36.402217 29460 layer_factory.hpp:77] Creating layer conv4
I0525 20:58:36.402246 29460 net.cpp:106] Creating Layer conv4
I0525 20:58:36.402266 29460 net.cpp:454] conv4 <- pool3
I0525 20:58:36.402283 29460 net.cpp:411] conv4 -> conv4
I0525 20:58:36.404398 29460 net.cpp:150] Setting up conv4
I0525 20:58:36.404423 29460 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:58:36.404443 29460 net.cpp:165] Memory required for data: 152074000
I0525 20:58:36.404463 29460 layer_factory.hpp:77] Creating layer relu4
I0525 20:58:36.404482 29460 net.cpp:106] Creating Layer relu4
I0525 20:58:36.404495 29460 net.cpp:454] relu4 <- conv4
I0525 20:58:36.404520 29460 net.cpp:397] relu4 -> conv4 (in-place)
I0525 20:58:36.405019 29460 net.cpp:150] Setting up relu4
I0525 20:58:36.405041 29460 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:58:36.405055 29460 net.cpp:165] Memory required for data: 155702800
I0525 20:58:36.405071 29460 layer_factory.hpp:77] Creating layer pool4
I0525 20:58:36.405087 29460 net.cpp:106] Creating Layer pool4
I0525 20:58:36.405109 29460 net.cpp:454] pool4 <- conv4
I0525 20:58:36.405125 29460 net.cpp:411] pool4 -> pool4
I0525 20:58:36.405212 29460 net.cpp:150] Setting up pool4
I0525 20:58:36.405230 29460 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 20:58:36.405244 29460 net.cpp:165] Memory required for data: 157517200
I0525 20:58:36.405256 29460 layer_factory.hpp:77] Creating layer ip1
I0525 20:58:36.405282 29460 net.cpp:106] Creating Layer ip1
I0525 20:58:36.405294 29460 net.cpp:454] ip1 <- pool4
I0525 20:58:36.405316 29460 net.cpp:411] ip1 -> ip1
I0525 20:58:36.420814 29460 net.cpp:150] Setting up ip1
I0525 20:58:36.420847 29460 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:58:36.420869 29460 net.cpp:165] Memory required for data: 157595600
I0525 20:58:36.420897 29460 layer_factory.hpp:77] Creating layer relu5
I0525 20:58:36.420919 29460 net.cpp:106] Creating Layer relu5
I0525 20:58:36.420944 29460 net.cpp:454] relu5 <- ip1
I0525 20:58:36.420961 29460 net.cpp:397] relu5 -> ip1 (in-place)
I0525 20:58:36.421329 29460 net.cpp:150] Setting up relu5
I0525 20:58:36.421350 29460 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:58:36.421361 29460 net.cpp:165] Memory required for data: 157674000
I0525 20:58:36.421377 29460 layer_factory.hpp:77] Creating layer drop1
I0525 20:58:36.421406 29460 net.cpp:106] Creating Layer drop1
I0525 20:58:36.421419 29460 net.cpp:454] drop1 <- ip1
I0525 20:58:36.421435 29460 net.cpp:397] drop1 -> ip1 (in-place)
I0525 20:58:36.421488 29460 net.cpp:150] Setting up drop1
I0525 20:58:36.421511 29460 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:58:36.421524 29460 net.cpp:165] Memory required for data: 157752400
I0525 20:58:36.421536 29460 layer_factory.hpp:77] Creating layer ip2
I0525 20:58:36.421553 29460 net.cpp:106] Creating Layer ip2
I0525 20:58:36.421568 29460 net.cpp:454] ip2 <- ip1
I0525 20:58:36.421592 29460 net.cpp:411] ip2 -> ip2
I0525 20:58:36.422087 29460 net.cpp:150] Setting up ip2
I0525 20:58:36.422106 29460 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:58:36.422119 29460 net.cpp:165] Memory required for data: 157791600
I0525 20:58:36.422140 29460 layer_factory.hpp:77] Creating layer relu6
I0525 20:58:36.422176 29460 net.cpp:106] Creating Layer relu6
I0525 20:58:36.422189 29460 net.cpp:454] relu6 <- ip2
I0525 20:58:36.422205 29460 net.cpp:397] relu6 -> ip2 (in-place)
I0525 20:58:36.422780 29460 net.cpp:150] Setting up relu6
I0525 20:58:36.422802 29460 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:58:36.422816 29460 net.cpp:165] Memory required for data: 157830800
I0525 20:58:36.422828 29460 layer_factory.hpp:77] Creating layer drop2
I0525 20:58:36.422848 29460 net.cpp:106] Creating Layer drop2
I0525 20:58:36.422870 29460 net.cpp:454] drop2 <- ip2
I0525 20:58:36.422888 29460 net.cpp:397] drop2 -> ip2 (in-place)
I0525 20:58:36.422941 29460 net.cpp:150] Setting up drop2
I0525 20:58:36.422960 29460 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:58:36.422981 29460 net.cpp:165] Memory required for data: 157870000
I0525 20:58:36.422993 29460 layer_factory.hpp:77] Creating layer ip3
I0525 20:58:36.423017 29460 net.cpp:106] Creating Layer ip3
I0525 20:58:36.423029 29460 net.cpp:454] ip3 <- ip2
I0525 20:58:36.423048 29460 net.cpp:411] ip3 -> ip3
I0525 20:58:36.423295 29460 net.cpp:150] Setting up ip3
I0525 20:58:36.423315 29460 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:58:36.423326 29460 net.cpp:165] Memory required for data: 157874400
I0525 20:58:36.423347 29460 layer_factory.hpp:77] Creating layer drop3
I0525 20:58:36.423369 29460 net.cpp:106] Creating Layer drop3
I0525 20:58:36.423382 29460 net.cpp:454] drop3 <- ip3
I0525 20:58:36.423398 29460 net.cpp:397] drop3 -> ip3 (in-place)
I0525 20:58:36.423446 29460 net.cpp:150] Setting up drop3
I0525 20:58:36.423468 29460 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:58:36.423481 29460 net.cpp:165] Memory required for data: 157878800
I0525 20:58:36.423493 29460 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 20:58:36.423508 29460 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 20:58:36.423524 29460 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 20:58:36.423547 29460 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 20:58:36.423565 29460 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 20:58:36.423655 29460 net.cpp:150] Setting up ip3_drop3_0_split
I0525 20:58:36.423674 29460 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:58:36.423691 29460 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:58:36.423705 29460 net.cpp:165] Memory required for data: 157887600
I0525 20:58:36.423717 29460 layer_factory.hpp:77] Creating layer accuracy
I0525 20:58:36.423746 29460 net.cpp:106] Creating Layer accuracy
I0525 20:58:36.423760 29460 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 20:58:36.423774 29460 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 20:58:36.423790 29460 net.cpp:411] accuracy -> accuracy
I0525 20:58:36.423825 29460 net.cpp:150] Setting up accuracy
I0525 20:58:36.423840 29460 net.cpp:157] Top shape: (1)
I0525 20:58:36.423857 29460 net.cpp:165] Memory required for data: 157887604
I0525 20:58:36.423869 29460 layer_factory.hpp:77] Creating layer loss
I0525 20:58:36.423885 29460 net.cpp:106] Creating Layer loss
I0525 20:58:36.423899 29460 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 20:58:36.423919 29460 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 20:58:36.423936 29460 net.cpp:411] loss -> loss
I0525 20:58:36.423956 29460 layer_factory.hpp:77] Creating layer loss
I0525 20:58:36.424473 29460 net.cpp:150] Setting up loss
I0525 20:58:36.424492 29460 net.cpp:157] Top shape: (1)
I0525 20:58:36.424504 29460 net.cpp:160]     with loss weight 1
I0525 20:58:36.424528 29460 net.cpp:165] Memory required for data: 157887608
I0525 20:58:36.424541 29460 net.cpp:226] loss needs backward computation.
I0525 20:58:36.424563 29460 net.cpp:228] accuracy does not need backward computation.
I0525 20:58:36.424577 29460 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 20:58:36.424590 29460 net.cpp:226] drop3 needs backward computation.
I0525 20:58:36.424603 29460 net.cpp:226] ip3 needs backward computation.
I0525 20:58:36.424619 29460 net.cpp:226] drop2 needs backward computation.
I0525 20:58:36.424646 29460 net.cpp:226] relu6 needs backward computation.
I0525 20:58:36.424659 29460 net.cpp:226] ip2 needs backward computation.
I0525 20:58:36.424674 29460 net.cpp:226] drop1 needs backward computation.
I0525 20:58:36.424685 29460 net.cpp:226] relu5 needs backward computation.
I0525 20:58:36.424696 29460 net.cpp:226] ip1 needs backward computation.
I0525 20:58:36.424711 29460 net.cpp:226] pool4 needs backward computation.
I0525 20:58:36.424731 29460 net.cpp:226] relu4 needs backward computation.
I0525 20:58:36.424744 29460 net.cpp:226] conv4 needs backward computation.
I0525 20:58:36.424757 29460 net.cpp:226] pool3 needs backward computation.
I0525 20:58:36.424770 29460 net.cpp:226] relu3 needs backward computation.
I0525 20:58:36.424803 29460 net.cpp:226] conv3 needs backward computation.
I0525 20:58:36.424818 29460 net.cpp:226] pool2 needs backward computation.
I0525 20:58:36.424837 29460 net.cpp:226] relu2 needs backward computation.
I0525 20:58:36.424850 29460 net.cpp:226] conv2 needs backward computation.
I0525 20:58:36.424867 29460 net.cpp:226] pool1 needs backward computation.
I0525 20:58:36.424880 29460 net.cpp:226] relu1 needs backward computation.
I0525 20:58:36.424892 29460 net.cpp:226] conv1 needs backward computation.
I0525 20:58:36.424908 29460 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 20:58:36.424922 29460 net.cpp:228] data_hdf5 does not need backward computation.
I0525 20:58:36.424942 29460 net.cpp:270] This network produces output accuracy
I0525 20:58:36.424955 29460 net.cpp:270] This network produces output loss
I0525 20:58:36.424990 29460 net.cpp:283] Network initialization done.
I0525 20:58:36.425143 29460 solver.cpp:60] Solver scaffolding done.
I0525 20:58:36.426301 29460 caffe.cpp:212] Starting Optimization
I0525 20:58:36.426319 29460 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 20:58:36.426336 29460 solver.cpp:289] Learning Rate Policy: fixed
I0525 20:58:36.427439 29460 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 20:59:24.211410 29460 solver.cpp:409]     Test net output #0: accuracy = 0.0697533
I0525 20:59:24.211573 29460 solver.cpp:409]     Test net output #1: loss = 2.39931 (* 1 = 2.39931 loss)
I0525 20:59:24.244565 29460 solver.cpp:237] Iteration 0, loss = 2.39956
I0525 20:59:24.244604 29460 solver.cpp:253]     Train net output #0: loss = 2.39956 (* 1 = 2.39956 loss)
I0525 20:59:24.244626 29460 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0525 20:59:32.972098 29460 solver.cpp:237] Iteration 150, loss = 2.24411
I0525 20:59:32.972137 29460 solver.cpp:253]     Train net output #0: loss = 2.24411 (* 1 = 2.24411 loss)
I0525 20:59:32.972162 29460 sgd_solver.cpp:106] Iteration 150, lr = 0.0045
I0525 20:59:41.696516 29460 solver.cpp:237] Iteration 300, loss = 2.11718
I0525 20:59:41.696570 29460 solver.cpp:253]     Train net output #0: loss = 2.11718 (* 1 = 2.11718 loss)
I0525 20:59:41.696595 29460 sgd_solver.cpp:106] Iteration 300, lr = 0.0045
I0525 20:59:50.422161 29460 solver.cpp:237] Iteration 450, loss = 2.06995
I0525 20:59:50.422197 29460 solver.cpp:253]     Train net output #0: loss = 2.06995 (* 1 = 2.06995 loss)
I0525 20:59:50.422215 29460 sgd_solver.cpp:106] Iteration 450, lr = 0.0045
I0525 20:59:59.152292 29460 solver.cpp:237] Iteration 600, loss = 1.78823
I0525 20:59:59.152446 29460 solver.cpp:253]     Train net output #0: loss = 1.78823 (* 1 = 1.78823 loss)
I0525 20:59:59.152463 29460 sgd_solver.cpp:106] Iteration 600, lr = 0.0045
I0525 21:00:07.875030 29460 solver.cpp:237] Iteration 750, loss = 1.85736
I0525 21:00:07.875083 29460 solver.cpp:253]     Train net output #0: loss = 1.85736 (* 1 = 1.85736 loss)
I0525 21:00:07.875110 29460 sgd_solver.cpp:106] Iteration 750, lr = 0.0045
I0525 21:00:16.593008 29460 solver.cpp:237] Iteration 900, loss = 1.87253
I0525 21:00:16.593044 29460 solver.cpp:253]     Train net output #0: loss = 1.87253 (* 1 = 1.87253 loss)
I0525 21:00:16.593065 29460 sgd_solver.cpp:106] Iteration 900, lr = 0.0045
I0525 21:00:47.425967 29460 solver.cpp:237] Iteration 1050, loss = 1.93328
I0525 21:00:47.426129 29460 solver.cpp:253]     Train net output #0: loss = 1.93328 (* 1 = 1.93328 loss)
I0525 21:00:47.426146 29460 sgd_solver.cpp:106] Iteration 1050, lr = 0.0045
I0525 21:00:56.148213 29460 solver.cpp:237] Iteration 1200, loss = 1.70453
I0525 21:00:56.148250 29460 solver.cpp:253]     Train net output #0: loss = 1.70453 (* 1 = 1.70453 loss)
I0525 21:00:56.148273 29460 sgd_solver.cpp:106] Iteration 1200, lr = 0.0045
I0525 21:01:04.877609 29460 solver.cpp:237] Iteration 1350, loss = 1.68075
I0525 21:01:04.877660 29460 solver.cpp:253]     Train net output #0: loss = 1.68075 (* 1 = 1.68075 loss)
I0525 21:01:04.877686 29460 sgd_solver.cpp:106] Iteration 1350, lr = 0.0045
I0525 21:01:13.549190 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_1500.caffemodel
I0525 21:01:13.631182 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_1500.solverstate
I0525 21:01:13.677878 29460 solver.cpp:237] Iteration 1500, loss = 1.7578
I0525 21:01:13.677933 29460 solver.cpp:253]     Train net output #0: loss = 1.7578 (* 1 = 1.7578 loss)
I0525 21:01:13.677953 29460 sgd_solver.cpp:106] Iteration 1500, lr = 0.0045
I0525 21:01:22.404304 29460 solver.cpp:237] Iteration 1650, loss = 1.83066
I0525 21:01:22.404466 29460 solver.cpp:253]     Train net output #0: loss = 1.83066 (* 1 = 1.83066 loss)
I0525 21:01:22.404485 29460 sgd_solver.cpp:106] Iteration 1650, lr = 0.0045
I0525 21:01:31.127935 29460 solver.cpp:237] Iteration 1800, loss = 1.63955
I0525 21:01:31.127971 29460 solver.cpp:253]     Train net output #0: loss = 1.63955 (* 1 = 1.63955 loss)
I0525 21:01:31.127995 29460 sgd_solver.cpp:106] Iteration 1800, lr = 0.0045
I0525 21:01:39.853205 29460 solver.cpp:237] Iteration 1950, loss = 1.53425
I0525 21:01:39.853241 29460 solver.cpp:253]     Train net output #0: loss = 1.53425 (* 1 = 1.53425 loss)
I0525 21:01:39.853266 29460 sgd_solver.cpp:106] Iteration 1950, lr = 0.0045
I0525 21:02:10.692095 29460 solver.cpp:237] Iteration 2100, loss = 1.48623
I0525 21:02:10.692258 29460 solver.cpp:253]     Train net output #0: loss = 1.48623 (* 1 = 1.48623 loss)
I0525 21:02:10.692276 29460 sgd_solver.cpp:106] Iteration 2100, lr = 0.0045
I0525 21:02:19.419373 29460 solver.cpp:237] Iteration 2250, loss = 1.58052
I0525 21:02:19.419426 29460 solver.cpp:253]     Train net output #0: loss = 1.58052 (* 1 = 1.58052 loss)
I0525 21:02:19.419450 29460 sgd_solver.cpp:106] Iteration 2250, lr = 0.0045
I0525 21:02:28.150301 29460 solver.cpp:237] Iteration 2400, loss = 1.52905
I0525 21:02:28.150338 29460 solver.cpp:253]     Train net output #0: loss = 1.52905 (* 1 = 1.52905 loss)
I0525 21:02:28.150362 29460 sgd_solver.cpp:106] Iteration 2400, lr = 0.0045
I0525 21:02:36.879966 29460 solver.cpp:237] Iteration 2550, loss = 1.35747
I0525 21:02:36.880018 29460 solver.cpp:253]     Train net output #0: loss = 1.35747 (* 1 = 1.35747 loss)
I0525 21:02:36.880044 29460 sgd_solver.cpp:106] Iteration 2550, lr = 0.0045
I0525 21:02:45.619901 29460 solver.cpp:237] Iteration 2700, loss = 1.46043
I0525 21:02:45.620054 29460 solver.cpp:253]     Train net output #0: loss = 1.46043 (* 1 = 1.46043 loss)
I0525 21:02:45.620071 29460 sgd_solver.cpp:106] Iteration 2700, lr = 0.0045
I0525 21:02:54.364630 29460 solver.cpp:237] Iteration 2850, loss = 1.3921
I0525 21:02:54.364668 29460 solver.cpp:253]     Train net output #0: loss = 1.3921 (* 1 = 1.3921 loss)
I0525 21:02:54.364691 29460 sgd_solver.cpp:106] Iteration 2850, lr = 0.0045
I0525 21:03:03.047739 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_3000.caffemodel
I0525 21:03:03.128793 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_3000.solverstate
I0525 21:03:03.155467 29460 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 21:03:50.005695 29460 solver.cpp:409]     Test net output #0: accuracy = 0.772002
I0525 21:03:50.005858 29460 solver.cpp:409]     Test net output #1: loss = 0.787685 (* 1 = 0.787685 loss)
I0525 21:04:12.113137 29460 solver.cpp:237] Iteration 3000, loss = 1.46013
I0525 21:04:12.113198 29460 solver.cpp:253]     Train net output #0: loss = 1.46013 (* 1 = 1.46013 loss)
I0525 21:04:12.113227 29460 sgd_solver.cpp:106] Iteration 3000, lr = 0.0045
I0525 21:04:20.865533 29460 solver.cpp:237] Iteration 3150, loss = 1.38573
I0525 21:04:20.865690 29460 solver.cpp:253]     Train net output #0: loss = 1.38573 (* 1 = 1.38573 loss)
I0525 21:04:20.865708 29460 sgd_solver.cpp:106] Iteration 3150, lr = 0.0045
I0525 21:04:29.608603 29460 solver.cpp:237] Iteration 3300, loss = 1.80408
I0525 21:04:29.608640 29460 solver.cpp:253]     Train net output #0: loss = 1.80408 (* 1 = 1.80408 loss)
I0525 21:04:29.608659 29460 sgd_solver.cpp:106] Iteration 3300, lr = 0.0045
I0525 21:04:38.350391 29460 solver.cpp:237] Iteration 3450, loss = 1.50847
I0525 21:04:38.350428 29460 solver.cpp:253]     Train net output #0: loss = 1.50847 (* 1 = 1.50847 loss)
I0525 21:04:38.350451 29460 sgd_solver.cpp:106] Iteration 3450, lr = 0.0045
I0525 21:04:47.099647 29460 solver.cpp:237] Iteration 3600, loss = 1.33856
I0525 21:04:47.099699 29460 solver.cpp:253]     Train net output #0: loss = 1.33856 (* 1 = 1.33856 loss)
I0525 21:04:47.099725 29460 sgd_solver.cpp:106] Iteration 3600, lr = 0.0045
I0525 21:04:55.846138 29460 solver.cpp:237] Iteration 3750, loss = 1.46484
I0525 21:04:55.846279 29460 solver.cpp:253]     Train net output #0: loss = 1.46484 (* 1 = 1.46484 loss)
I0525 21:04:55.846297 29460 sgd_solver.cpp:106] Iteration 3750, lr = 0.0045
I0525 21:05:04.596374 29460 solver.cpp:237] Iteration 3900, loss = 1.4104
I0525 21:05:04.596415 29460 solver.cpp:253]     Train net output #0: loss = 1.4104 (* 1 = 1.4104 loss)
I0525 21:05:04.596432 29460 sgd_solver.cpp:106] Iteration 3900, lr = 0.0045
I0525 21:05:35.454510 29460 solver.cpp:237] Iteration 4050, loss = 1.52871
I0525 21:05:35.454676 29460 solver.cpp:253]     Train net output #0: loss = 1.52871 (* 1 = 1.52871 loss)
I0525 21:05:35.454694 29460 sgd_solver.cpp:106] Iteration 4050, lr = 0.0045
I0525 21:05:44.202064 29460 solver.cpp:237] Iteration 4200, loss = 1.45882
I0525 21:05:44.202101 29460 solver.cpp:253]     Train net output #0: loss = 1.45882 (* 1 = 1.45882 loss)
I0525 21:05:44.202121 29460 sgd_solver.cpp:106] Iteration 4200, lr = 0.0045
I0525 21:05:52.946363 29460 solver.cpp:237] Iteration 4350, loss = 1.26733
I0525 21:05:52.946400 29460 solver.cpp:253]     Train net output #0: loss = 1.26733 (* 1 = 1.26733 loss)
I0525 21:05:52.946424 29460 sgd_solver.cpp:106] Iteration 4350, lr = 0.0045
I0525 21:06:01.633651 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_4500.caffemodel
I0525 21:06:01.714355 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_4500.solverstate
I0525 21:06:01.760332 29460 solver.cpp:237] Iteration 4500, loss = 1.192
I0525 21:06:01.760386 29460 solver.cpp:253]     Train net output #0: loss = 1.192 (* 1 = 1.192 loss)
I0525 21:06:01.760411 29460 sgd_solver.cpp:106] Iteration 4500, lr = 0.0045
I0525 21:06:10.508010 29460 solver.cpp:237] Iteration 4650, loss = 1.39143
I0525 21:06:10.508165 29460 solver.cpp:253]     Train net output #0: loss = 1.39143 (* 1 = 1.39143 loss)
I0525 21:06:10.508183 29460 sgd_solver.cpp:106] Iteration 4650, lr = 0.0045
I0525 21:06:19.254437 29460 solver.cpp:237] Iteration 4800, loss = 1.53437
I0525 21:06:19.254473 29460 solver.cpp:253]     Train net output #0: loss = 1.53437 (* 1 = 1.53437 loss)
I0525 21:06:19.254497 29460 sgd_solver.cpp:106] Iteration 4800, lr = 0.0045
I0525 21:06:27.990324 29460 solver.cpp:237] Iteration 4950, loss = 1.43474
I0525 21:06:27.990380 29460 solver.cpp:253]     Train net output #0: loss = 1.43474 (* 1 = 1.43474 loss)
I0525 21:06:27.990406 29460 sgd_solver.cpp:106] Iteration 4950, lr = 0.0045
I0525 21:06:58.801141 29460 solver.cpp:237] Iteration 5100, loss = 1.31435
I0525 21:06:58.801306 29460 solver.cpp:253]     Train net output #0: loss = 1.31435 (* 1 = 1.31435 loss)
I0525 21:06:58.801323 29460 sgd_solver.cpp:106] Iteration 5100, lr = 0.0045
I0525 21:07:07.531599 29460 solver.cpp:237] Iteration 5250, loss = 1.48479
I0525 21:07:07.531635 29460 solver.cpp:253]     Train net output #0: loss = 1.48479 (* 1 = 1.48479 loss)
I0525 21:07:07.531661 29460 sgd_solver.cpp:106] Iteration 5250, lr = 0.0045
I0525 21:07:16.268801 29460 solver.cpp:237] Iteration 5400, loss = 1.37393
I0525 21:07:16.268856 29460 solver.cpp:253]     Train net output #0: loss = 1.37393 (* 1 = 1.37393 loss)
I0525 21:07:16.268880 29460 sgd_solver.cpp:106] Iteration 5400, lr = 0.0045
I0525 21:07:25.006176 29460 solver.cpp:237] Iteration 5550, loss = 1.32778
I0525 21:07:25.006214 29460 solver.cpp:253]     Train net output #0: loss = 1.32778 (* 1 = 1.32778 loss)
I0525 21:07:25.006233 29460 sgd_solver.cpp:106] Iteration 5550, lr = 0.0045
I0525 21:07:33.743459 29460 solver.cpp:237] Iteration 5700, loss = 1.50982
I0525 21:07:33.743604 29460 solver.cpp:253]     Train net output #0: loss = 1.50982 (* 1 = 1.50982 loss)
I0525 21:07:33.743620 29460 sgd_solver.cpp:106] Iteration 5700, lr = 0.0045
I0525 21:07:42.479925 29460 solver.cpp:237] Iteration 5850, loss = 1.11523
I0525 21:07:42.479977 29460 solver.cpp:253]     Train net output #0: loss = 1.11523 (* 1 = 1.11523 loss)
I0525 21:07:42.480002 29460 sgd_solver.cpp:106] Iteration 5850, lr = 0.0045
I0525 21:07:51.155930 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_6000.caffemodel
I0525 21:07:51.237685 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_6000.solverstate
I0525 21:07:51.265784 29460 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 21:08:58.930773 29460 solver.cpp:409]     Test net output #0: accuracy = 0.83166
I0525 21:08:58.930946 29460 solver.cpp:409]     Test net output #1: loss = 0.571938 (* 1 = 0.571938 loss)
I0525 21:09:21.130754 29460 solver.cpp:237] Iteration 6000, loss = 1.37512
I0525 21:09:21.130816 29460 solver.cpp:253]     Train net output #0: loss = 1.37512 (* 1 = 1.37512 loss)
I0525 21:09:21.130844 29460 sgd_solver.cpp:106] Iteration 6000, lr = 0.0045
I0525 21:09:29.867486 29460 solver.cpp:237] Iteration 6150, loss = 1.35438
I0525 21:09:29.867650 29460 solver.cpp:253]     Train net output #0: loss = 1.35438 (* 1 = 1.35438 loss)
I0525 21:09:29.867666 29460 sgd_solver.cpp:106] Iteration 6150, lr = 0.0045
I0525 21:09:38.603863 29460 solver.cpp:237] Iteration 6300, loss = 1.3484
I0525 21:09:38.603899 29460 solver.cpp:253]     Train net output #0: loss = 1.3484 (* 1 = 1.3484 loss)
I0525 21:09:38.603924 29460 sgd_solver.cpp:106] Iteration 6300, lr = 0.0045
I0525 21:09:47.337831 29460 solver.cpp:237] Iteration 6450, loss = 1.47454
I0525 21:09:47.337885 29460 solver.cpp:253]     Train net output #0: loss = 1.47454 (* 1 = 1.47454 loss)
I0525 21:09:47.337909 29460 sgd_solver.cpp:106] Iteration 6450, lr = 0.0045
I0525 21:09:56.074623 29460 solver.cpp:237] Iteration 6600, loss = 1.28577
I0525 21:09:56.074659 29460 solver.cpp:253]     Train net output #0: loss = 1.28577 (* 1 = 1.28577 loss)
I0525 21:09:56.074678 29460 sgd_solver.cpp:106] Iteration 6600, lr = 0.0045
I0525 21:10:04.809290 29460 solver.cpp:237] Iteration 6750, loss = 1.36306
I0525 21:10:04.809434 29460 solver.cpp:253]     Train net output #0: loss = 1.36306 (* 1 = 1.36306 loss)
I0525 21:10:04.809451 29460 sgd_solver.cpp:106] Iteration 6750, lr = 0.0045
I0525 21:10:13.545166 29460 solver.cpp:237] Iteration 6900, loss = 1.38751
I0525 21:10:13.545213 29460 solver.cpp:253]     Train net output #0: loss = 1.38751 (* 1 = 1.38751 loss)
I0525 21:10:13.545230 29460 sgd_solver.cpp:106] Iteration 6900, lr = 0.0045
I0525 21:10:44.440167 29460 solver.cpp:237] Iteration 7050, loss = 1.34366
I0525 21:10:44.440331 29460 solver.cpp:253]     Train net output #0: loss = 1.34366 (* 1 = 1.34366 loss)
I0525 21:10:44.440348 29460 sgd_solver.cpp:106] Iteration 7050, lr = 0.0045
I0525 21:10:53.177714 29460 solver.cpp:237] Iteration 7200, loss = 1.08954
I0525 21:10:53.177750 29460 solver.cpp:253]     Train net output #0: loss = 1.08954 (* 1 = 1.08954 loss)
I0525 21:10:53.177773 29460 sgd_solver.cpp:106] Iteration 7200, lr = 0.0045
I0525 21:11:01.917142 29460 solver.cpp:237] Iteration 7350, loss = 1.28609
I0525 21:11:01.917196 29460 solver.cpp:253]     Train net output #0: loss = 1.28609 (* 1 = 1.28609 loss)
I0525 21:11:01.917220 29460 sgd_solver.cpp:106] Iteration 7350, lr = 0.0045
I0525 21:11:10.598479 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_7500.caffemodel
I0525 21:11:10.680054 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_7500.solverstate
I0525 21:11:10.725679 29460 solver.cpp:237] Iteration 7500, loss = 1.32247
I0525 21:11:10.725739 29460 solver.cpp:253]     Train net output #0: loss = 1.32247 (* 1 = 1.32247 loss)
I0525 21:11:10.725756 29460 sgd_solver.cpp:106] Iteration 7500, lr = 0.0045
I0525 21:11:19.457098 29460 solver.cpp:237] Iteration 7650, loss = 1.3607
I0525 21:11:19.457245 29460 solver.cpp:253]     Train net output #0: loss = 1.3607 (* 1 = 1.3607 loss)
I0525 21:11:19.457262 29460 sgd_solver.cpp:106] Iteration 7650, lr = 0.0045
I0525 21:11:28.191062 29460 solver.cpp:237] Iteration 7800, loss = 1.22361
I0525 21:11:28.191117 29460 solver.cpp:253]     Train net output #0: loss = 1.22361 (* 1 = 1.22361 loss)
I0525 21:11:28.191141 29460 sgd_solver.cpp:106] Iteration 7800, lr = 0.0045
I0525 21:11:36.926594 29460 solver.cpp:237] Iteration 7950, loss = 1.40136
I0525 21:11:36.926631 29460 solver.cpp:253]     Train net output #0: loss = 1.40136 (* 1 = 1.40136 loss)
I0525 21:11:36.926650 29460 sgd_solver.cpp:106] Iteration 7950, lr = 0.0045
I0525 21:12:07.861817 29460 solver.cpp:237] Iteration 8100, loss = 1.34978
I0525 21:12:07.861987 29460 solver.cpp:253]     Train net output #0: loss = 1.34978 (* 1 = 1.34978 loss)
I0525 21:12:07.862004 29460 sgd_solver.cpp:106] Iteration 8100, lr = 0.0045
I0525 21:12:16.602046 29460 solver.cpp:237] Iteration 8250, loss = 1.11724
I0525 21:12:16.602099 29460 solver.cpp:253]     Train net output #0: loss = 1.11724 (* 1 = 1.11724 loss)
I0525 21:12:16.602124 29460 sgd_solver.cpp:106] Iteration 8250, lr = 0.0045
I0525 21:12:25.337754 29460 solver.cpp:237] Iteration 8400, loss = 1.15333
I0525 21:12:25.337791 29460 solver.cpp:253]     Train net output #0: loss = 1.15333 (* 1 = 1.15333 loss)
I0525 21:12:25.337815 29460 sgd_solver.cpp:106] Iteration 8400, lr = 0.0045
I0525 21:12:34.074771 29460 solver.cpp:237] Iteration 8550, loss = 1.29648
I0525 21:12:34.074808 29460 solver.cpp:253]     Train net output #0: loss = 1.29648 (* 1 = 1.29648 loss)
I0525 21:12:34.074831 29460 sgd_solver.cpp:106] Iteration 8550, lr = 0.0045
I0525 21:12:42.810343 29460 solver.cpp:237] Iteration 8700, loss = 1.23513
I0525 21:12:42.810504 29460 solver.cpp:253]     Train net output #0: loss = 1.23513 (* 1 = 1.23513 loss)
I0525 21:12:42.810523 29460 sgd_solver.cpp:106] Iteration 8700, lr = 0.0045
I0525 21:12:51.547858 29460 solver.cpp:237] Iteration 8850, loss = 0.976283
I0525 21:12:51.547895 29460 solver.cpp:253]     Train net output #0: loss = 0.976283 (* 1 = 0.976283 loss)
I0525 21:12:51.547914 29460 sgd_solver.cpp:106] Iteration 8850, lr = 0.0045
I0525 21:13:00.222267 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_9000.caffemodel
I0525 21:13:00.301589 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_9000.solverstate
I0525 21:13:00.327061 29460 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 21:13:46.849092 29460 solver.cpp:409]     Test net output #0: accuracy = 0.84474
I0525 21:13:46.849257 29460 solver.cpp:409]     Test net output #1: loss = 0.522473 (* 1 = 0.522473 loss)
I0525 21:14:09.058419 29460 solver.cpp:237] Iteration 9000, loss = 1.22522
I0525 21:14:09.058478 29460 solver.cpp:253]     Train net output #0: loss = 1.22522 (* 1 = 1.22522 loss)
I0525 21:14:09.058497 29460 sgd_solver.cpp:106] Iteration 9000, lr = 0.0045
I0525 21:14:17.784898 29460 solver.cpp:237] Iteration 9150, loss = 1.13961
I0525 21:14:17.785066 29460 solver.cpp:253]     Train net output #0: loss = 1.13961 (* 1 = 1.13961 loss)
I0525 21:14:17.785092 29460 sgd_solver.cpp:106] Iteration 9150, lr = 0.0045
I0525 21:14:26.511109 29460 solver.cpp:237] Iteration 9300, loss = 1.23546
I0525 21:14:26.511147 29460 solver.cpp:253]     Train net output #0: loss = 1.23546 (* 1 = 1.23546 loss)
I0525 21:14:26.511169 29460 sgd_solver.cpp:106] Iteration 9300, lr = 0.0045
I0525 21:14:35.235224 29460 solver.cpp:237] Iteration 9450, loss = 1.37021
I0525 21:14:35.235260 29460 solver.cpp:253]     Train net output #0: loss = 1.37021 (* 1 = 1.37021 loss)
I0525 21:14:35.235285 29460 sgd_solver.cpp:106] Iteration 9450, lr = 0.0045
I0525 21:14:43.958961 29460 solver.cpp:237] Iteration 9600, loss = 1.43969
I0525 21:14:43.959014 29460 solver.cpp:253]     Train net output #0: loss = 1.43969 (* 1 = 1.43969 loss)
I0525 21:14:43.959039 29460 sgd_solver.cpp:106] Iteration 9600, lr = 0.0045
I0525 21:14:52.686542 29460 solver.cpp:237] Iteration 9750, loss = 1.34306
I0525 21:14:52.686688 29460 solver.cpp:253]     Train net output #0: loss = 1.34306 (* 1 = 1.34306 loss)
I0525 21:14:52.686705 29460 sgd_solver.cpp:106] Iteration 9750, lr = 0.0045
I0525 21:15:01.409589 29460 solver.cpp:237] Iteration 9900, loss = 1.1819
I0525 21:15:01.409626 29460 solver.cpp:253]     Train net output #0: loss = 1.1819 (* 1 = 1.1819 loss)
I0525 21:15:01.409643 29460 sgd_solver.cpp:106] Iteration 9900, lr = 0.0045
I0525 21:15:32.315382 29460 solver.cpp:237] Iteration 10050, loss = 1.33421
I0525 21:15:32.315562 29460 solver.cpp:253]     Train net output #0: loss = 1.33421 (* 1 = 1.33421 loss)
I0525 21:15:32.315579 29460 sgd_solver.cpp:106] Iteration 10050, lr = 0.0045
I0525 21:15:41.043748 29460 solver.cpp:237] Iteration 10200, loss = 1.28724
I0525 21:15:41.043786 29460 solver.cpp:253]     Train net output #0: loss = 1.28724 (* 1 = 1.28724 loss)
I0525 21:15:41.043808 29460 sgd_solver.cpp:106] Iteration 10200, lr = 0.0045
I0525 21:15:49.768162 29460 solver.cpp:237] Iteration 10350, loss = 1.06154
I0525 21:15:49.768199 29460 solver.cpp:253]     Train net output #0: loss = 1.06154 (* 1 = 1.06154 loss)
I0525 21:15:49.768223 29460 sgd_solver.cpp:106] Iteration 10350, lr = 0.0045
I0525 21:15:58.436316 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_10500.caffemodel
I0525 21:15:58.515851 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_10500.solverstate
I0525 21:15:58.560094 29460 solver.cpp:237] Iteration 10500, loss = 1.13296
I0525 21:15:58.560148 29460 solver.cpp:253]     Train net output #0: loss = 1.13296 (* 1 = 1.13296 loss)
I0525 21:15:58.560165 29460 sgd_solver.cpp:106] Iteration 10500, lr = 0.0045
I0525 21:16:07.286010 29460 solver.cpp:237] Iteration 10650, loss = 1.21961
I0525 21:16:07.286159 29460 solver.cpp:253]     Train net output #0: loss = 1.21961 (* 1 = 1.21961 loss)
I0525 21:16:07.286176 29460 sgd_solver.cpp:106] Iteration 10650, lr = 0.0045
I0525 21:16:16.009341 29460 solver.cpp:237] Iteration 10800, loss = 1.14364
I0525 21:16:16.009378 29460 solver.cpp:253]     Train net output #0: loss = 1.14364 (* 1 = 1.14364 loss)
I0525 21:16:16.009402 29460 sgd_solver.cpp:106] Iteration 10800, lr = 0.0045
I0525 21:16:24.733182 29460 solver.cpp:237] Iteration 10950, loss = 1.2401
I0525 21:16:24.733235 29460 solver.cpp:253]     Train net output #0: loss = 1.2401 (* 1 = 1.2401 loss)
I0525 21:16:24.733260 29460 sgd_solver.cpp:106] Iteration 10950, lr = 0.0045
I0525 21:16:55.599534 29460 solver.cpp:237] Iteration 11100, loss = 1.19321
I0525 21:16:55.599704 29460 solver.cpp:253]     Train net output #0: loss = 1.19321 (* 1 = 1.19321 loss)
I0525 21:16:55.599721 29460 sgd_solver.cpp:106] Iteration 11100, lr = 0.0045
I0525 21:17:04.320972 29460 solver.cpp:237] Iteration 11250, loss = 1.24974
I0525 21:17:04.321010 29460 solver.cpp:253]     Train net output #0: loss = 1.24974 (* 1 = 1.24974 loss)
I0525 21:17:04.321029 29460 sgd_solver.cpp:106] Iteration 11250, lr = 0.0045
I0525 21:17:13.043718 29460 solver.cpp:237] Iteration 11400, loss = 1.1106
I0525 21:17:13.043771 29460 solver.cpp:253]     Train net output #0: loss = 1.1106 (* 1 = 1.1106 loss)
I0525 21:17:13.043797 29460 sgd_solver.cpp:106] Iteration 11400, lr = 0.0045
I0525 21:17:21.767848 29460 solver.cpp:237] Iteration 11550, loss = 1.21003
I0525 21:17:21.767884 29460 solver.cpp:253]     Train net output #0: loss = 1.21003 (* 1 = 1.21003 loss)
I0525 21:17:21.767904 29460 sgd_solver.cpp:106] Iteration 11550, lr = 0.0045
I0525 21:17:30.491780 29460 solver.cpp:237] Iteration 11700, loss = 1.16652
I0525 21:17:30.491927 29460 solver.cpp:253]     Train net output #0: loss = 1.16652 (* 1 = 1.16652 loss)
I0525 21:17:30.491943 29460 sgd_solver.cpp:106] Iteration 11700, lr = 0.0045
I0525 21:17:39.225626 29460 solver.cpp:237] Iteration 11850, loss = 1.37875
I0525 21:17:39.225679 29460 solver.cpp:253]     Train net output #0: loss = 1.37875 (* 1 = 1.37875 loss)
I0525 21:17:39.225699 29460 sgd_solver.cpp:106] Iteration 11850, lr = 0.0045
I0525 21:17:47.903020 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_12000.caffemodel
I0525 21:17:47.982239 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_12000.solverstate
I0525 21:17:48.008746 29460 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 21:18:55.710438 29460 solver.cpp:409]     Test net output #0: accuracy = 0.854593
I0525 21:18:55.710615 29460 solver.cpp:409]     Test net output #1: loss = 0.466462 (* 1 = 0.466462 loss)
I0525 21:19:17.880688 29460 solver.cpp:237] Iteration 12000, loss = 1.14337
I0525 21:19:17.880751 29460 solver.cpp:253]     Train net output #0: loss = 1.14337 (* 1 = 1.14337 loss)
I0525 21:19:17.880789 29460 sgd_solver.cpp:106] Iteration 12000, lr = 0.0045
I0525 21:19:26.621310 29460 solver.cpp:237] Iteration 12150, loss = 1.15055
I0525 21:19:26.621469 29460 solver.cpp:253]     Train net output #0: loss = 1.15055 (* 1 = 1.15055 loss)
I0525 21:19:26.621485 29460 sgd_solver.cpp:106] Iteration 12150, lr = 0.0045
I0525 21:19:35.358484 29460 solver.cpp:237] Iteration 12300, loss = 1.30078
I0525 21:19:35.358520 29460 solver.cpp:253]     Train net output #0: loss = 1.30078 (* 1 = 1.30078 loss)
I0525 21:19:35.358543 29460 sgd_solver.cpp:106] Iteration 12300, lr = 0.0045
I0525 21:19:44.096513 29460 solver.cpp:237] Iteration 12450, loss = 1.15889
I0525 21:19:44.096566 29460 solver.cpp:253]     Train net output #0: loss = 1.15889 (* 1 = 1.15889 loss)
I0525 21:19:44.096591 29460 sgd_solver.cpp:106] Iteration 12450, lr = 0.0045
I0525 21:19:52.830302 29460 solver.cpp:237] Iteration 12600, loss = 1.0816
I0525 21:19:52.830339 29460 solver.cpp:253]     Train net output #0: loss = 1.0816 (* 1 = 1.0816 loss)
I0525 21:19:52.830358 29460 sgd_solver.cpp:106] Iteration 12600, lr = 0.0045
I0525 21:20:01.562047 29460 solver.cpp:237] Iteration 12750, loss = 1.34096
I0525 21:20:01.562208 29460 solver.cpp:253]     Train net output #0: loss = 1.34096 (* 1 = 1.34096 loss)
I0525 21:20:01.562225 29460 sgd_solver.cpp:106] Iteration 12750, lr = 0.0045
I0525 21:20:10.302711 29460 solver.cpp:237] Iteration 12900, loss = 1.09791
I0525 21:20:10.302765 29460 solver.cpp:253]     Train net output #0: loss = 1.09791 (* 1 = 1.09791 loss)
I0525 21:20:10.302791 29460 sgd_solver.cpp:106] Iteration 12900, lr = 0.0045
I0525 21:20:41.273005 29460 solver.cpp:237] Iteration 13050, loss = 1.02088
I0525 21:20:41.273180 29460 solver.cpp:253]     Train net output #0: loss = 1.02088 (* 1 = 1.02088 loss)
I0525 21:20:41.273198 29460 sgd_solver.cpp:106] Iteration 13050, lr = 0.0045
I0525 21:20:50.006924 29460 solver.cpp:237] Iteration 13200, loss = 1.20748
I0525 21:20:50.006961 29460 solver.cpp:253]     Train net output #0: loss = 1.20748 (* 1 = 1.20748 loss)
I0525 21:20:50.006985 29460 sgd_solver.cpp:106] Iteration 13200, lr = 0.0045
I0525 21:20:58.743065 29460 solver.cpp:237] Iteration 13350, loss = 1.10567
I0525 21:20:58.743119 29460 solver.cpp:253]     Train net output #0: loss = 1.10567 (* 1 = 1.10567 loss)
I0525 21:20:58.743146 29460 sgd_solver.cpp:106] Iteration 13350, lr = 0.0045
I0525 21:21:07.424918 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_13500.caffemodel
I0525 21:21:07.506243 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_13500.solverstate
I0525 21:21:07.552916 29460 solver.cpp:237] Iteration 13500, loss = 1.22874
I0525 21:21:07.552975 29460 solver.cpp:253]     Train net output #0: loss = 1.22874 (* 1 = 1.22874 loss)
I0525 21:21:07.552994 29460 sgd_solver.cpp:106] Iteration 13500, lr = 0.0045
I0525 21:21:16.288915 29460 solver.cpp:237] Iteration 13650, loss = 1.14707
I0525 21:21:16.289077 29460 solver.cpp:253]     Train net output #0: loss = 1.14707 (* 1 = 1.14707 loss)
I0525 21:21:16.289094 29460 sgd_solver.cpp:106] Iteration 13650, lr = 0.0045
I0525 21:21:25.022470 29460 solver.cpp:237] Iteration 13800, loss = 1.37421
I0525 21:21:25.022526 29460 solver.cpp:253]     Train net output #0: loss = 1.37421 (* 1 = 1.37421 loss)
I0525 21:21:25.022552 29460 sgd_solver.cpp:106] Iteration 13800, lr = 0.0045
I0525 21:21:33.753588 29460 solver.cpp:237] Iteration 13950, loss = 1.26827
I0525 21:21:33.753628 29460 solver.cpp:253]     Train net output #0: loss = 1.26827 (* 1 = 1.26827 loss)
I0525 21:21:33.753645 29460 sgd_solver.cpp:106] Iteration 13950, lr = 0.0045
I0525 21:22:04.677880 29460 solver.cpp:237] Iteration 14100, loss = 1.28334
I0525 21:22:04.678061 29460 solver.cpp:253]     Train net output #0: loss = 1.28334 (* 1 = 1.28334 loss)
I0525 21:22:04.678078 29460 sgd_solver.cpp:106] Iteration 14100, lr = 0.0045
I0525 21:22:13.413137 29460 solver.cpp:237] Iteration 14250, loss = 1.32399
I0525 21:22:13.413188 29460 solver.cpp:253]     Train net output #0: loss = 1.32399 (* 1 = 1.32399 loss)
I0525 21:22:13.413213 29460 sgd_solver.cpp:106] Iteration 14250, lr = 0.0045
I0525 21:22:22.144582 29460 solver.cpp:237] Iteration 14400, loss = 1.20164
I0525 21:22:22.144619 29460 solver.cpp:253]     Train net output #0: loss = 1.20164 (* 1 = 1.20164 loss)
I0525 21:22:22.144637 29460 sgd_solver.cpp:106] Iteration 14400, lr = 0.0045
I0525 21:22:30.883365 29460 solver.cpp:237] Iteration 14550, loss = 1.53993
I0525 21:22:30.883402 29460 solver.cpp:253]     Train net output #0: loss = 1.53993 (* 1 = 1.53993 loss)
I0525 21:22:30.883425 29460 sgd_solver.cpp:106] Iteration 14550, lr = 0.0045
I0525 21:22:39.618132 29460 solver.cpp:237] Iteration 14700, loss = 1.16175
I0525 21:22:39.618299 29460 solver.cpp:253]     Train net output #0: loss = 1.16175 (* 1 = 1.16175 loss)
I0525 21:22:39.618316 29460 sgd_solver.cpp:106] Iteration 14700, lr = 0.0045
I0525 21:22:48.356581 29460 solver.cpp:237] Iteration 14850, loss = 1.14142
I0525 21:22:48.356618 29460 solver.cpp:253]     Train net output #0: loss = 1.14142 (* 1 = 1.14142 loss)
I0525 21:22:48.356642 29460 sgd_solver.cpp:106] Iteration 14850, lr = 0.0045
I0525 21:22:57.037724 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_15000.caffemodel
I0525 21:22:57.118175 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_15000.solverstate
I0525 21:22:57.146800 29460 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 21:23:44.039044 29460 solver.cpp:409]     Test net output #0: accuracy = 0.869686
I0525 21:23:44.039213 29460 solver.cpp:409]     Test net output #1: loss = 0.433534 (* 1 = 0.433534 loss)
I0525 21:24:04.973299 29460 solver.cpp:237] Iteration 15000, loss = 1.14159
I0525 21:24:04.973359 29460 solver.cpp:253]     Train net output #0: loss = 1.14159 (* 1 = 1.14159 loss)
I0525 21:24:04.973387 29460 sgd_solver.cpp:106] Iteration 15000, lr = 0.0045
I0525 21:24:13.704251 29460 solver.cpp:237] Iteration 15150, loss = 1.10231
I0525 21:24:13.704288 29460 solver.cpp:253]     Train net output #0: loss = 1.10231 (* 1 = 1.10231 loss)
I0525 21:24:13.704313 29460 sgd_solver.cpp:106] Iteration 15150, lr = 0.0045
I0525 21:24:22.438421 29460 solver.cpp:237] Iteration 15300, loss = 1.34944
I0525 21:24:22.438585 29460 solver.cpp:253]     Train net output #0: loss = 1.34944 (* 1 = 1.34944 loss)
I0525 21:24:22.438602 29460 sgd_solver.cpp:106] Iteration 15300, lr = 0.0045
I0525 21:24:31.172973 29460 solver.cpp:237] Iteration 15450, loss = 1.11237
I0525 21:24:31.173010 29460 solver.cpp:253]     Train net output #0: loss = 1.11237 (* 1 = 1.11237 loss)
I0525 21:24:31.173034 29460 sgd_solver.cpp:106] Iteration 15450, lr = 0.0045
I0525 21:24:39.906502 29460 solver.cpp:237] Iteration 15600, loss = 1.04067
I0525 21:24:39.906538 29460 solver.cpp:253]     Train net output #0: loss = 1.04067 (* 1 = 1.04067 loss)
I0525 21:24:39.906561 29460 sgd_solver.cpp:106] Iteration 15600, lr = 0.0045
I0525 21:24:48.638540 29460 solver.cpp:237] Iteration 15750, loss = 1.14285
I0525 21:24:48.638592 29460 solver.cpp:253]     Train net output #0: loss = 1.14285 (* 1 = 1.14285 loss)
I0525 21:24:48.638617 29460 sgd_solver.cpp:106] Iteration 15750, lr = 0.0045
I0525 21:24:57.373883 29460 solver.cpp:237] Iteration 15900, loss = 1.22478
I0525 21:24:57.374043 29460 solver.cpp:253]     Train net output #0: loss = 1.22478 (* 1 = 1.22478 loss)
I0525 21:24:57.374060 29460 sgd_solver.cpp:106] Iteration 15900, lr = 0.0045
I0525 21:25:27.018784 29460 solver.cpp:237] Iteration 16050, loss = 1.13683
I0525 21:25:27.018841 29460 solver.cpp:253]     Train net output #0: loss = 1.13683 (* 1 = 1.13683 loss)
I0525 21:25:27.018860 29460 sgd_solver.cpp:106] Iteration 16050, lr = 0.0045
I0525 21:25:35.751889 29460 solver.cpp:237] Iteration 16200, loss = 1.00049
I0525 21:25:35.752060 29460 solver.cpp:253]     Train net output #0: loss = 1.00049 (* 1 = 1.00049 loss)
I0525 21:25:35.752079 29460 sgd_solver.cpp:106] Iteration 16200, lr = 0.0045
I0525 21:25:44.484477 29460 solver.cpp:237] Iteration 16350, loss = 1.19634
I0525 21:25:44.484514 29460 solver.cpp:253]     Train net output #0: loss = 1.19634 (* 1 = 1.19634 loss)
I0525 21:25:44.484532 29460 sgd_solver.cpp:106] Iteration 16350, lr = 0.0045
I0525 21:25:53.161669 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_16500.caffemodel
I0525 21:25:53.239728 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_16500.solverstate
I0525 21:25:53.283409 29460 solver.cpp:237] Iteration 16500, loss = 1.17758
I0525 21:25:53.283463 29460 solver.cpp:253]     Train net output #0: loss = 1.17758 (* 1 = 1.17758 loss)
I0525 21:25:53.283488 29460 sgd_solver.cpp:106] Iteration 16500, lr = 0.0045
I0525 21:26:02.015128 29460 solver.cpp:237] Iteration 16650, loss = 1.26526
I0525 21:26:02.015182 29460 solver.cpp:253]     Train net output #0: loss = 1.26526 (* 1 = 1.26526 loss)
I0525 21:26:02.015208 29460 sgd_solver.cpp:106] Iteration 16650, lr = 0.0045
I0525 21:26:10.747766 29460 solver.cpp:237] Iteration 16800, loss = 1.18963
I0525 21:26:10.747920 29460 solver.cpp:253]     Train net output #0: loss = 1.18963 (* 1 = 1.18963 loss)
I0525 21:26:10.747936 29460 sgd_solver.cpp:106] Iteration 16800, lr = 0.0045
I0525 21:26:19.478196 29460 solver.cpp:237] Iteration 16950, loss = 1.38798
I0525 21:26:19.478234 29460 solver.cpp:253]     Train net output #0: loss = 1.38798 (* 1 = 1.38798 loss)
I0525 21:26:19.478256 29460 sgd_solver.cpp:106] Iteration 16950, lr = 0.0045
I0525 21:26:49.072865 29460 solver.cpp:237] Iteration 17100, loss = 1.01601
I0525 21:26:49.073041 29460 solver.cpp:253]     Train net output #0: loss = 1.01601 (* 1 = 1.01601 loss)
I0525 21:26:49.073067 29460 sgd_solver.cpp:106] Iteration 17100, lr = 0.0045
I0525 21:26:57.807327 29460 solver.cpp:237] Iteration 17250, loss = 1.1894
I0525 21:26:57.807363 29460 solver.cpp:253]     Train net output #0: loss = 1.1894 (* 1 = 1.1894 loss)
I0525 21:26:57.807386 29460 sgd_solver.cpp:106] Iteration 17250, lr = 0.0045
I0525 21:27:06.538880 29460 solver.cpp:237] Iteration 17400, loss = 1.32334
I0525 21:27:06.538918 29460 solver.cpp:253]     Train net output #0: loss = 1.32334 (* 1 = 1.32334 loss)
I0525 21:27:06.538941 29460 sgd_solver.cpp:106] Iteration 17400, lr = 0.0045
I0525 21:27:15.275002 29460 solver.cpp:237] Iteration 17550, loss = 1.23917
I0525 21:27:15.275055 29460 solver.cpp:253]     Train net output #0: loss = 1.23917 (* 1 = 1.23917 loss)
I0525 21:27:15.275082 29460 sgd_solver.cpp:106] Iteration 17550, lr = 0.0045
I0525 21:27:24.010543 29460 solver.cpp:237] Iteration 17700, loss = 1.39596
I0525 21:27:24.010694 29460 solver.cpp:253]     Train net output #0: loss = 1.39596 (* 1 = 1.39596 loss)
I0525 21:27:24.010711 29460 sgd_solver.cpp:106] Iteration 17700, lr = 0.0045
I0525 21:27:32.743639 29460 solver.cpp:237] Iteration 17850, loss = 1.43174
I0525 21:27:32.743677 29460 solver.cpp:253]     Train net output #0: loss = 1.43174 (* 1 = 1.43174 loss)
I0525 21:27:32.743693 29460 sgd_solver.cpp:106] Iteration 17850, lr = 0.0045
I0525 21:27:41.422652 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_18000.caffemodel
I0525 21:27:41.501330 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_18000.solverstate
I0525 21:27:41.527107 29460 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 21:28:49.333753 29460 solver.cpp:409]     Test net output #0: accuracy = 0.86894
I0525 21:28:49.333940 29460 solver.cpp:409]     Test net output #1: loss = 0.412634 (* 1 = 0.412634 loss)
I0525 21:29:10.230017 29460 solver.cpp:237] Iteration 18000, loss = 1.23958
I0525 21:29:10.230077 29460 solver.cpp:253]     Train net output #0: loss = 1.23958 (* 1 = 1.23958 loss)
I0525 21:29:10.230098 29460 sgd_solver.cpp:106] Iteration 18000, lr = 0.0045
I0525 21:29:18.952854 29460 solver.cpp:237] Iteration 18150, loss = 1.17458
I0525 21:29:18.952908 29460 solver.cpp:253]     Train net output #0: loss = 1.17458 (* 1 = 1.17458 loss)
I0525 21:29:18.952924 29460 sgd_solver.cpp:106] Iteration 18150, lr = 0.0045
I0525 21:29:27.675375 29460 solver.cpp:237] Iteration 18300, loss = 1.26617
I0525 21:29:27.675530 29460 solver.cpp:253]     Train net output #0: loss = 1.26617 (* 1 = 1.26617 loss)
I0525 21:29:27.675546 29460 sgd_solver.cpp:106] Iteration 18300, lr = 0.0045
I0525 21:29:36.398517 29460 solver.cpp:237] Iteration 18450, loss = 1.24865
I0525 21:29:36.398555 29460 solver.cpp:253]     Train net output #0: loss = 1.24865 (* 1 = 1.24865 loss)
I0525 21:29:36.398578 29460 sgd_solver.cpp:106] Iteration 18450, lr = 0.0045
I0525 21:29:45.121968 29460 solver.cpp:237] Iteration 18600, loss = 1.22886
I0525 21:29:45.122022 29460 solver.cpp:253]     Train net output #0: loss = 1.22886 (* 1 = 1.22886 loss)
I0525 21:29:45.122048 29460 sgd_solver.cpp:106] Iteration 18600, lr = 0.0045
I0525 21:29:53.844194 29460 solver.cpp:237] Iteration 18750, loss = 1.20436
I0525 21:29:53.844233 29460 solver.cpp:253]     Train net output #0: loss = 1.20436 (* 1 = 1.20436 loss)
I0525 21:29:53.844251 29460 sgd_solver.cpp:106] Iteration 18750, lr = 0.0045
I0525 21:30:02.568836 29460 solver.cpp:237] Iteration 18900, loss = 1.21965
I0525 21:30:02.568990 29460 solver.cpp:253]     Train net output #0: loss = 1.21965 (* 1 = 1.21965 loss)
I0525 21:30:02.569007 29460 sgd_solver.cpp:106] Iteration 18900, lr = 0.0045
I0525 21:30:32.200357 29460 solver.cpp:237] Iteration 19050, loss = 1.14787
I0525 21:30:32.200413 29460 solver.cpp:253]     Train net output #0: loss = 1.14787 (* 1 = 1.14787 loss)
I0525 21:30:32.200431 29460 sgd_solver.cpp:106] Iteration 19050, lr = 0.0045
I0525 21:30:40.925614 29460 solver.cpp:237] Iteration 19200, loss = 1.20876
I0525 21:30:40.925772 29460 solver.cpp:253]     Train net output #0: loss = 1.20876 (* 1 = 1.20876 loss)
I0525 21:30:40.925789 29460 sgd_solver.cpp:106] Iteration 19200, lr = 0.0045
I0525 21:30:49.652668 29460 solver.cpp:237] Iteration 19350, loss = 1.35678
I0525 21:30:49.652704 29460 solver.cpp:253]     Train net output #0: loss = 1.35678 (* 1 = 1.35678 loss)
I0525 21:30:49.652727 29460 sgd_solver.cpp:106] Iteration 19350, lr = 0.0045
I0525 21:30:58.320731 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_19500.caffemodel
I0525 21:30:58.399029 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_19500.solverstate
I0525 21:30:58.445540 29460 solver.cpp:237] Iteration 19500, loss = 1.16666
I0525 21:30:58.445600 29460 solver.cpp:253]     Train net output #0: loss = 1.16666 (* 1 = 1.16666 loss)
I0525 21:30:58.445617 29460 sgd_solver.cpp:106] Iteration 19500, lr = 0.0045
I0525 21:31:07.171355 29460 solver.cpp:237] Iteration 19650, loss = 1.20865
I0525 21:31:07.171391 29460 solver.cpp:253]     Train net output #0: loss = 1.20865 (* 1 = 1.20865 loss)
I0525 21:31:07.171416 29460 sgd_solver.cpp:106] Iteration 19650, lr = 0.0045
I0525 21:31:15.894088 29460 solver.cpp:237] Iteration 19800, loss = 1.2504
I0525 21:31:15.894254 29460 solver.cpp:253]     Train net output #0: loss = 1.2504 (* 1 = 1.2504 loss)
I0525 21:31:15.894271 29460 sgd_solver.cpp:106] Iteration 19800, lr = 0.0045
I0525 21:31:24.615237 29460 solver.cpp:237] Iteration 19950, loss = 1.23425
I0525 21:31:24.615293 29460 solver.cpp:253]     Train net output #0: loss = 1.23425 (* 1 = 1.23425 loss)
I0525 21:31:24.615319 29460 sgd_solver.cpp:106] Iteration 19950, lr = 0.0045
I0525 21:31:54.199923 29460 solver.cpp:237] Iteration 20100, loss = 1.19541
I0525 21:31:54.200100 29460 solver.cpp:253]     Train net output #0: loss = 1.19541 (* 1 = 1.19541 loss)
I0525 21:31:54.200119 29460 sgd_solver.cpp:106] Iteration 20100, lr = 0.0045
I0525 21:32:02.931282 29460 solver.cpp:237] Iteration 20250, loss = 1.22392
I0525 21:32:02.931318 29460 solver.cpp:253]     Train net output #0: loss = 1.22392 (* 1 = 1.22392 loss)
I0525 21:32:02.931336 29460 sgd_solver.cpp:106] Iteration 20250, lr = 0.0045
I0525 21:32:11.660677 29460 solver.cpp:237] Iteration 20400, loss = 1.26713
I0525 21:32:11.660732 29460 solver.cpp:253]     Train net output #0: loss = 1.26713 (* 1 = 1.26713 loss)
I0525 21:32:11.660758 29460 sgd_solver.cpp:106] Iteration 20400, lr = 0.0045
I0525 21:32:20.388367 29460 solver.cpp:237] Iteration 20550, loss = 1.04387
I0525 21:32:20.388403 29460 solver.cpp:253]     Train net output #0: loss = 1.04387 (* 1 = 1.04387 loss)
I0525 21:32:20.388427 29460 sgd_solver.cpp:106] Iteration 20550, lr = 0.0045
I0525 21:32:29.114667 29460 solver.cpp:237] Iteration 20700, loss = 1.20406
I0525 21:32:29.114823 29460 solver.cpp:253]     Train net output #0: loss = 1.20406 (* 1 = 1.20406 loss)
I0525 21:32:29.114840 29460 sgd_solver.cpp:106] Iteration 20700, lr = 0.0045
I0525 21:32:37.842247 29460 solver.cpp:237] Iteration 20850, loss = 0.997655
I0525 21:32:37.842301 29460 solver.cpp:253]     Train net output #0: loss = 0.997655 (* 1 = 0.997655 loss)
I0525 21:32:37.842326 29460 sgd_solver.cpp:106] Iteration 20850, lr = 0.0045
I0525 21:32:46.510239 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_21000.caffemodel
I0525 21:32:46.589642 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_21000.solverstate
I0525 21:32:46.616379 29460 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 21:33:33.166523 29460 solver.cpp:409]     Test net output #0: accuracy = 0.876407
I0525 21:33:33.166694 29460 solver.cpp:409]     Test net output #1: loss = 0.424236 (* 1 = 0.424236 loss)
I0525 21:33:54.074671 29460 solver.cpp:237] Iteration 21000, loss = 1.28025
I0525 21:33:54.074733 29460 solver.cpp:253]     Train net output #0: loss = 1.28025 (* 1 = 1.28025 loss)
I0525 21:33:54.074759 29460 sgd_solver.cpp:106] Iteration 21000, lr = 0.0045
I0525 21:34:02.804206 29460 solver.cpp:237] Iteration 21150, loss = 1.12919
I0525 21:34:02.804244 29460 solver.cpp:253]     Train net output #0: loss = 1.12919 (* 1 = 1.12919 loss)
I0525 21:34:02.804266 29460 sgd_solver.cpp:106] Iteration 21150, lr = 0.0045
I0525 21:34:11.535115 29460 solver.cpp:237] Iteration 21300, loss = 1.2253
I0525 21:34:11.535277 29460 solver.cpp:253]     Train net output #0: loss = 1.2253 (* 1 = 1.2253 loss)
I0525 21:34:11.535295 29460 sgd_solver.cpp:106] Iteration 21300, lr = 0.0045
I0525 21:34:20.273756 29460 solver.cpp:237] Iteration 21450, loss = 1.3065
I0525 21:34:20.273808 29460 solver.cpp:253]     Train net output #0: loss = 1.3065 (* 1 = 1.3065 loss)
I0525 21:34:20.273828 29460 sgd_solver.cpp:106] Iteration 21450, lr = 0.0045
I0525 21:34:28.997956 29460 solver.cpp:237] Iteration 21600, loss = 1.19927
I0525 21:34:28.997992 29460 solver.cpp:253]     Train net output #0: loss = 1.19927 (* 1 = 1.19927 loss)
I0525 21:34:28.998014 29460 sgd_solver.cpp:106] Iteration 21600, lr = 0.0045
I0525 21:34:37.730170 29460 solver.cpp:237] Iteration 21750, loss = 1.2432
I0525 21:34:37.730206 29460 solver.cpp:253]     Train net output #0: loss = 1.2432 (* 1 = 1.2432 loss)
I0525 21:34:37.730231 29460 sgd_solver.cpp:106] Iteration 21750, lr = 0.0045
I0525 21:34:46.456344 29460 solver.cpp:237] Iteration 21900, loss = 1.17626
I0525 21:34:46.456517 29460 solver.cpp:253]     Train net output #0: loss = 1.17626 (* 1 = 1.17626 loss)
I0525 21:34:46.456535 29460 sgd_solver.cpp:106] Iteration 21900, lr = 0.0045
I0525 21:35:16.025009 29460 solver.cpp:237] Iteration 22050, loss = 1.17964
I0525 21:35:16.025064 29460 solver.cpp:253]     Train net output #0: loss = 1.17964 (* 1 = 1.17964 loss)
I0525 21:35:16.025089 29460 sgd_solver.cpp:106] Iteration 22050, lr = 0.0045
I0525 21:35:24.752218 29460 solver.cpp:237] Iteration 22200, loss = 1.14464
I0525 21:35:24.752382 29460 solver.cpp:253]     Train net output #0: loss = 1.14464 (* 1 = 1.14464 loss)
I0525 21:35:24.752399 29460 sgd_solver.cpp:106] Iteration 22200, lr = 0.0045
I0525 21:35:33.488382 29460 solver.cpp:237] Iteration 22350, loss = 1.23496
I0525 21:35:33.488431 29460 solver.cpp:253]     Train net output #0: loss = 1.23496 (* 1 = 1.23496 loss)
I0525 21:35:33.488456 29460 sgd_solver.cpp:106] Iteration 22350, lr = 0.0045
I0525 21:35:42.157052 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_22500.caffemodel
I0525 21:35:42.237332 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_22500.solverstate
I0525 21:35:42.283391 29460 solver.cpp:237] Iteration 22500, loss = 1.17927
I0525 21:35:42.283452 29460 solver.cpp:253]     Train net output #0: loss = 1.17927 (* 1 = 1.17927 loss)
I0525 21:35:42.283469 29460 sgd_solver.cpp:106] Iteration 22500, lr = 0.0045
I0525 21:35:51.017289 29460 solver.cpp:237] Iteration 22650, loss = 1.23187
I0525 21:35:51.017328 29460 solver.cpp:253]     Train net output #0: loss = 1.23187 (* 1 = 1.23187 loss)
I0525 21:35:51.017350 29460 sgd_solver.cpp:106] Iteration 22650, lr = 0.0045
I0525 21:35:59.745175 29460 solver.cpp:237] Iteration 22800, loss = 1.16039
I0525 21:35:59.745347 29460 solver.cpp:253]     Train net output #0: loss = 1.16039 (* 1 = 1.16039 loss)
I0525 21:35:59.745371 29460 sgd_solver.cpp:106] Iteration 22800, lr = 0.0045
I0525 21:36:08.475397 29460 solver.cpp:237] Iteration 22950, loss = 1.21383
I0525 21:36:08.475433 29460 solver.cpp:253]     Train net output #0: loss = 1.21383 (* 1 = 1.21383 loss)
I0525 21:36:08.475457 29460 sgd_solver.cpp:106] Iteration 22950, lr = 0.0045
I0525 21:36:38.089350 29460 solver.cpp:237] Iteration 23100, loss = 1.2164
I0525 21:36:38.089535 29460 solver.cpp:253]     Train net output #0: loss = 1.2164 (* 1 = 1.2164 loss)
I0525 21:36:38.089552 29460 sgd_solver.cpp:106] Iteration 23100, lr = 0.0045
I0525 21:36:46.825022 29460 solver.cpp:237] Iteration 23250, loss = 1.19295
I0525 21:36:46.825075 29460 solver.cpp:253]     Train net output #0: loss = 1.19295 (* 1 = 1.19295 loss)
I0525 21:36:46.825103 29460 sgd_solver.cpp:106] Iteration 23250, lr = 0.0045
I0525 21:36:55.559381 29460 solver.cpp:237] Iteration 23400, loss = 1.22677
I0525 21:36:55.559418 29460 solver.cpp:253]     Train net output #0: loss = 1.22677 (* 1 = 1.22677 loss)
I0525 21:36:55.559442 29460 sgd_solver.cpp:106] Iteration 23400, lr = 0.0045
I0525 21:37:04.297909 29460 solver.cpp:237] Iteration 23550, loss = 1.18954
I0525 21:37:04.297945 29460 solver.cpp:253]     Train net output #0: loss = 1.18954 (* 1 = 1.18954 loss)
I0525 21:37:04.297968 29460 sgd_solver.cpp:106] Iteration 23550, lr = 0.0045
I0525 21:37:13.021972 29460 solver.cpp:237] Iteration 23700, loss = 1.39888
I0525 21:37:13.022153 29460 solver.cpp:253]     Train net output #0: loss = 1.39888 (* 1 = 1.39888 loss)
I0525 21:37:13.022171 29460 sgd_solver.cpp:106] Iteration 23700, lr = 0.0045
I0525 21:37:21.752256 29460 solver.cpp:237] Iteration 23850, loss = 0.966891
I0525 21:37:21.752295 29460 solver.cpp:253]     Train net output #0: loss = 0.966891 (* 1 = 0.966891 loss)
I0525 21:37:21.752313 29460 sgd_solver.cpp:106] Iteration 23850, lr = 0.0045
I0525 21:37:30.433914 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_24000.caffemodel
I0525 21:37:30.513319 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_24000.solverstate
I0525 21:37:30.539204 29460 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 21:38:38.331089 29460 solver.cpp:409]     Test net output #0: accuracy = 0.878734
I0525 21:38:38.331266 29460 solver.cpp:409]     Test net output #1: loss = 0.392281 (* 1 = 0.392281 loss)
I0525 21:38:59.233461 29460 solver.cpp:237] Iteration 24000, loss = 1.08487
I0525 21:38:59.233520 29460 solver.cpp:253]     Train net output #0: loss = 1.08487 (* 1 = 1.08487 loss)
I0525 21:38:59.233549 29460 sgd_solver.cpp:106] Iteration 24000, lr = 0.0045
I0525 21:39:07.954481 29460 solver.cpp:237] Iteration 24150, loss = 1.03932
I0525 21:39:07.954519 29460 solver.cpp:253]     Train net output #0: loss = 1.03932 (* 1 = 1.03932 loss)
I0525 21:39:07.954543 29460 sgd_solver.cpp:106] Iteration 24150, lr = 0.0045
I0525 21:39:16.680012 29460 solver.cpp:237] Iteration 24300, loss = 1.13473
I0525 21:39:16.680186 29460 solver.cpp:253]     Train net output #0: loss = 1.13473 (* 1 = 1.13473 loss)
I0525 21:39:16.680205 29460 sgd_solver.cpp:106] Iteration 24300, lr = 0.0045
I0525 21:39:25.401463 29460 solver.cpp:237] Iteration 24450, loss = 1.30303
I0525 21:39:25.401501 29460 solver.cpp:253]     Train net output #0: loss = 1.30303 (* 1 = 1.30303 loss)
I0525 21:39:25.401525 29460 sgd_solver.cpp:106] Iteration 24450, lr = 0.0045
I0525 21:39:34.125661 29460 solver.cpp:237] Iteration 24600, loss = 1.21037
I0525 21:39:34.125697 29460 solver.cpp:253]     Train net output #0: loss = 1.21037 (* 1 = 1.21037 loss)
I0525 21:39:34.125720 29460 sgd_solver.cpp:106] Iteration 24600, lr = 0.0045
I0525 21:39:42.843374 29460 solver.cpp:237] Iteration 24750, loss = 1.32337
I0525 21:39:42.843426 29460 solver.cpp:253]     Train net output #0: loss = 1.32337 (* 1 = 1.32337 loss)
I0525 21:39:42.843451 29460 sgd_solver.cpp:106] Iteration 24750, lr = 0.0045
I0525 21:39:51.566221 29460 solver.cpp:237] Iteration 24900, loss = 1.15905
I0525 21:39:51.566380 29460 solver.cpp:253]     Train net output #0: loss = 1.15905 (* 1 = 1.15905 loss)
I0525 21:39:51.566396 29460 sgd_solver.cpp:106] Iteration 24900, lr = 0.0045
I0525 21:40:21.195771 29460 solver.cpp:237] Iteration 25050, loss = 1.36516
I0525 21:40:21.195827 29460 solver.cpp:253]     Train net output #0: loss = 1.36516 (* 1 = 1.36516 loss)
I0525 21:40:21.195853 29460 sgd_solver.cpp:106] Iteration 25050, lr = 0.0045
I0525 21:40:29.916143 29460 solver.cpp:237] Iteration 25200, loss = 1.14574
I0525 21:40:29.916306 29460 solver.cpp:253]     Train net output #0: loss = 1.14574 (* 1 = 1.14574 loss)
I0525 21:40:29.916322 29460 sgd_solver.cpp:106] Iteration 25200, lr = 0.0045
I0525 21:40:38.636613 29460 solver.cpp:237] Iteration 25350, loss = 1.02419
I0525 21:40:38.636662 29460 solver.cpp:253]     Train net output #0: loss = 1.02419 (* 1 = 1.02419 loss)
I0525 21:40:38.636688 29460 sgd_solver.cpp:106] Iteration 25350, lr = 0.0045
I0525 21:40:47.303920 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_25500.caffemodel
I0525 21:40:47.386312 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_25500.solverstate
I0525 21:40:47.430091 29460 solver.cpp:237] Iteration 25500, loss = 1.05563
I0525 21:40:47.430145 29460 solver.cpp:253]     Train net output #0: loss = 1.05563 (* 1 = 1.05563 loss)
I0525 21:40:47.430171 29460 sgd_solver.cpp:106] Iteration 25500, lr = 0.0045
I0525 21:40:56.150828 29460 solver.cpp:237] Iteration 25650, loss = 1.06064
I0525 21:40:56.150866 29460 solver.cpp:253]     Train net output #0: loss = 1.06064 (* 1 = 1.06064 loss)
I0525 21:40:56.150889 29460 sgd_solver.cpp:106] Iteration 25650, lr = 0.0045
I0525 21:41:04.877187 29460 solver.cpp:237] Iteration 25800, loss = 1.23673
I0525 21:41:04.877369 29460 solver.cpp:253]     Train net output #0: loss = 1.23673 (* 1 = 1.23673 loss)
I0525 21:41:04.877388 29460 sgd_solver.cpp:106] Iteration 25800, lr = 0.0045
I0525 21:41:13.598665 29460 solver.cpp:237] Iteration 25950, loss = 1.23177
I0525 21:41:13.598701 29460 solver.cpp:253]     Train net output #0: loss = 1.23177 (* 1 = 1.23177 loss)
I0525 21:41:13.598721 29460 sgd_solver.cpp:106] Iteration 25950, lr = 0.0045
I0525 21:41:43.201637 29460 solver.cpp:237] Iteration 26100, loss = 1.109
I0525 21:41:43.201817 29460 solver.cpp:253]     Train net output #0: loss = 1.109 (* 1 = 1.109 loss)
I0525 21:41:43.201836 29460 sgd_solver.cpp:106] Iteration 26100, lr = 0.0045
I0525 21:41:51.928000 29460 solver.cpp:237] Iteration 26250, loss = 1.13666
I0525 21:41:51.928052 29460 solver.cpp:253]     Train net output #0: loss = 1.13666 (* 1 = 1.13666 loss)
I0525 21:41:51.928081 29460 sgd_solver.cpp:106] Iteration 26250, lr = 0.0045
I0525 21:42:00.656862 29460 solver.cpp:237] Iteration 26400, loss = 1.23099
I0525 21:42:00.656900 29460 solver.cpp:253]     Train net output #0: loss = 1.23099 (* 1 = 1.23099 loss)
I0525 21:42:00.656919 29460 sgd_solver.cpp:106] Iteration 26400, lr = 0.0045
I0525 21:42:09.378512 29460 solver.cpp:237] Iteration 26550, loss = 1.21724
I0525 21:42:09.378550 29460 solver.cpp:253]     Train net output #0: loss = 1.21724 (* 1 = 1.21724 loss)
I0525 21:42:09.378572 29460 sgd_solver.cpp:106] Iteration 26550, lr = 0.0045
I0525 21:42:18.111994 29460 solver.cpp:237] Iteration 26700, loss = 1.12503
I0525 21:42:18.112164 29460 solver.cpp:253]     Train net output #0: loss = 1.12503 (* 1 = 1.12503 loss)
I0525 21:42:18.112182 29460 sgd_solver.cpp:106] Iteration 26700, lr = 0.0045
I0525 21:42:26.852277 29460 solver.cpp:237] Iteration 26850, loss = 1.19928
I0525 21:42:26.852313 29460 solver.cpp:253]     Train net output #0: loss = 1.19928 (* 1 = 1.19928 loss)
I0525 21:42:26.852337 29460 sgd_solver.cpp:106] Iteration 26850, lr = 0.0045
I0525 21:42:35.531368 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_27000.caffemodel
I0525 21:42:35.610066 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_27000.solverstate
I0525 21:42:35.636165 29460 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 21:43:22.518162 29460 solver.cpp:409]     Test net output #0: accuracy = 0.880687
I0525 21:43:22.518335 29460 solver.cpp:409]     Test net output #1: loss = 0.385488 (* 1 = 0.385488 loss)
I0525 21:43:43.383739 29460 solver.cpp:237] Iteration 27000, loss = 1.14945
I0525 21:43:43.383801 29460 solver.cpp:253]     Train net output #0: loss = 1.14945 (* 1 = 1.14945 loss)
I0525 21:43:43.383821 29460 sgd_solver.cpp:106] Iteration 27000, lr = 0.0045
I0525 21:43:52.147209 29460 solver.cpp:237] Iteration 27150, loss = 1.12074
I0525 21:43:52.147264 29460 solver.cpp:253]     Train net output #0: loss = 1.12074 (* 1 = 1.12074 loss)
I0525 21:43:52.147292 29460 sgd_solver.cpp:106] Iteration 27150, lr = 0.0045
I0525 21:44:00.898241 29460 solver.cpp:237] Iteration 27300, loss = 0.971133
I0525 21:44:00.898414 29460 solver.cpp:253]     Train net output #0: loss = 0.971133 (* 1 = 0.971133 loss)
I0525 21:44:00.898432 29460 sgd_solver.cpp:106] Iteration 27300, lr = 0.0045
I0525 21:44:09.652185 29460 solver.cpp:237] Iteration 27450, loss = 1.02616
I0525 21:44:09.652222 29460 solver.cpp:253]     Train net output #0: loss = 1.02616 (* 1 = 1.02616 loss)
I0525 21:44:09.652241 29460 sgd_solver.cpp:106] Iteration 27450, lr = 0.0045
I0525 21:44:18.409029 29460 solver.cpp:237] Iteration 27600, loss = 1.33198
I0525 21:44:18.409082 29460 solver.cpp:253]     Train net output #0: loss = 1.33198 (* 1 = 1.33198 loss)
I0525 21:44:18.409109 29460 sgd_solver.cpp:106] Iteration 27600, lr = 0.0045
I0525 21:44:27.157091 29460 solver.cpp:237] Iteration 27750, loss = 1.17479
I0525 21:44:27.157129 29460 solver.cpp:253]     Train net output #0: loss = 1.17479 (* 1 = 1.17479 loss)
I0525 21:44:27.157152 29460 sgd_solver.cpp:106] Iteration 27750, lr = 0.0045
I0525 21:44:35.911015 29460 solver.cpp:237] Iteration 27900, loss = 1.11336
I0525 21:44:35.911175 29460 solver.cpp:253]     Train net output #0: loss = 1.11336 (* 1 = 1.11336 loss)
I0525 21:44:35.911191 29460 sgd_solver.cpp:106] Iteration 27900, lr = 0.0045
I0525 21:45:05.563496 29460 solver.cpp:237] Iteration 28050, loss = 1.19172
I0525 21:45:05.563552 29460 solver.cpp:253]     Train net output #0: loss = 1.19172 (* 1 = 1.19172 loss)
I0525 21:45:05.563577 29460 sgd_solver.cpp:106] Iteration 28050, lr = 0.0045
I0525 21:45:14.312978 29460 solver.cpp:237] Iteration 28200, loss = 1.06834
I0525 21:45:14.313153 29460 solver.cpp:253]     Train net output #0: loss = 1.06834 (* 1 = 1.06834 loss)
I0525 21:45:14.313170 29460 sgd_solver.cpp:106] Iteration 28200, lr = 0.0045
I0525 21:45:23.061319 29460 solver.cpp:237] Iteration 28350, loss = 1.01039
I0525 21:45:23.061357 29460 solver.cpp:253]     Train net output #0: loss = 1.01039 (* 1 = 1.01039 loss)
I0525 21:45:23.061380 29460 sgd_solver.cpp:106] Iteration 28350, lr = 0.0045
I0525 21:45:31.751006 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_28500.caffemodel
I0525 21:45:31.832744 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_28500.solverstate
I0525 21:45:31.878229 29460 solver.cpp:237] Iteration 28500, loss = 1.42685
I0525 21:45:31.878289 29460 solver.cpp:253]     Train net output #0: loss = 1.42685 (* 1 = 1.42685 loss)
I0525 21:45:31.878306 29460 sgd_solver.cpp:106] Iteration 28500, lr = 0.0045
I0525 21:45:40.633045 29460 solver.cpp:237] Iteration 28650, loss = 1.30012
I0525 21:45:40.633081 29460 solver.cpp:253]     Train net output #0: loss = 1.30012 (* 1 = 1.30012 loss)
I0525 21:45:40.633107 29460 sgd_solver.cpp:106] Iteration 28650, lr = 0.0045
I0525 21:45:49.384578 29460 solver.cpp:237] Iteration 28800, loss = 1.27974
I0525 21:45:49.384740 29460 solver.cpp:253]     Train net output #0: loss = 1.27974 (* 1 = 1.27974 loss)
I0525 21:45:49.384757 29460 sgd_solver.cpp:106] Iteration 28800, lr = 0.0045
I0525 21:45:58.139331 29460 solver.cpp:237] Iteration 28950, loss = 1.07476
I0525 21:45:58.139386 29460 solver.cpp:253]     Train net output #0: loss = 1.07476 (* 1 = 1.07476 loss)
I0525 21:45:58.139405 29460 sgd_solver.cpp:106] Iteration 28950, lr = 0.0045
I0525 21:46:27.786854 29460 solver.cpp:237] Iteration 29100, loss = 1.24487
I0525 21:46:27.787036 29460 solver.cpp:253]     Train net output #0: loss = 1.24487 (* 1 = 1.24487 loss)
I0525 21:46:27.787055 29460 sgd_solver.cpp:106] Iteration 29100, lr = 0.0045
I0525 21:46:36.537456 29460 solver.cpp:237] Iteration 29250, loss = 1.07376
I0525 21:46:36.537493 29460 solver.cpp:253]     Train net output #0: loss = 1.07376 (* 1 = 1.07376 loss)
I0525 21:46:36.537518 29460 sgd_solver.cpp:106] Iteration 29250, lr = 0.0045
I0525 21:46:45.289875 29460 solver.cpp:237] Iteration 29400, loss = 0.970826
I0525 21:46:45.289911 29460 solver.cpp:253]     Train net output #0: loss = 0.970826 (* 1 = 0.970826 loss)
I0525 21:46:45.289934 29460 sgd_solver.cpp:106] Iteration 29400, lr = 0.0045
I0525 21:46:54.042002 29460 solver.cpp:237] Iteration 29550, loss = 1.32984
I0525 21:46:54.042054 29460 solver.cpp:253]     Train net output #0: loss = 1.32984 (* 1 = 1.32984 loss)
I0525 21:46:54.042079 29460 sgd_solver.cpp:106] Iteration 29550, lr = 0.0045
I0525 21:47:02.793553 29460 solver.cpp:237] Iteration 29700, loss = 1.09291
I0525 21:47:02.793732 29460 solver.cpp:253]     Train net output #0: loss = 1.09291 (* 1 = 1.09291 loss)
I0525 21:47:02.793750 29460 sgd_solver.cpp:106] Iteration 29700, lr = 0.0045
I0525 21:47:11.546180 29460 solver.cpp:237] Iteration 29850, loss = 1.14569
I0525 21:47:11.546232 29460 solver.cpp:253]     Train net output #0: loss = 1.14569 (* 1 = 1.14569 loss)
I0525 21:47:11.546262 29460 sgd_solver.cpp:106] Iteration 29850, lr = 0.0045
I0525 21:47:20.242585 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_30000.caffemodel
I0525 21:47:20.323995 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_30000.solverstate
I0525 21:47:20.351997 29460 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 21:48:28.144896 29460 solver.cpp:409]     Test net output #0: accuracy = 0.884068
I0525 21:48:28.145073 29460 solver.cpp:409]     Test net output #1: loss = 0.374639 (* 1 = 0.374639 loss)
I0525 21:48:49.064303 29460 solver.cpp:237] Iteration 30000, loss = 1.18935
I0525 21:48:49.064363 29460 solver.cpp:253]     Train net output #0: loss = 1.18935 (* 1 = 1.18935 loss)
I0525 21:48:49.064383 29460 sgd_solver.cpp:106] Iteration 30000, lr = 0.0045
I0525 21:48:57.802898 29460 solver.cpp:237] Iteration 30150, loss = 1.14597
I0525 21:48:57.802943 29460 solver.cpp:253]     Train net output #0: loss = 1.14597 (* 1 = 1.14597 loss)
I0525 21:48:57.802960 29460 sgd_solver.cpp:106] Iteration 30150, lr = 0.0045
I0525 21:49:06.541646 29460 solver.cpp:237] Iteration 30300, loss = 1.33743
I0525 21:49:06.541810 29460 solver.cpp:253]     Train net output #0: loss = 1.33743 (* 1 = 1.33743 loss)
I0525 21:49:06.541827 29460 sgd_solver.cpp:106] Iteration 30300, lr = 0.0045
I0525 21:49:15.272555 29460 solver.cpp:237] Iteration 30450, loss = 1.10536
I0525 21:49:15.272591 29460 solver.cpp:253]     Train net output #0: loss = 1.10536 (* 1 = 1.10536 loss)
I0525 21:49:15.272614 29460 sgd_solver.cpp:106] Iteration 30450, lr = 0.0045
I0525 21:49:24.013644 29460 solver.cpp:237] Iteration 30600, loss = 1.10928
I0525 21:49:24.013689 29460 solver.cpp:253]     Train net output #0: loss = 1.10928 (* 1 = 1.10928 loss)
I0525 21:49:24.013717 29460 sgd_solver.cpp:106] Iteration 30600, lr = 0.0045
I0525 21:49:32.746187 29460 solver.cpp:237] Iteration 30750, loss = 0.936543
I0525 21:49:32.746223 29460 solver.cpp:253]     Train net output #0: loss = 0.936543 (* 1 = 0.936543 loss)
I0525 21:49:32.746248 29460 sgd_solver.cpp:106] Iteration 30750, lr = 0.0045
I0525 21:49:41.487270 29460 solver.cpp:237] Iteration 30900, loss = 1.12422
I0525 21:49:41.487442 29460 solver.cpp:253]     Train net output #0: loss = 1.12422 (* 1 = 1.12422 loss)
I0525 21:49:41.487462 29460 sgd_solver.cpp:106] Iteration 30900, lr = 0.0045
I0525 21:50:11.123157 29460 solver.cpp:237] Iteration 31050, loss = 1.17508
I0525 21:50:11.123213 29460 solver.cpp:253]     Train net output #0: loss = 1.17508 (* 1 = 1.17508 loss)
I0525 21:50:11.123229 29460 sgd_solver.cpp:106] Iteration 31050, lr = 0.0045
I0525 21:50:19.850834 29460 solver.cpp:237] Iteration 31200, loss = 0.93385
I0525 21:50:19.850996 29460 solver.cpp:253]     Train net output #0: loss = 0.93385 (* 1 = 0.93385 loss)
I0525 21:50:19.851014 29460 sgd_solver.cpp:106] Iteration 31200, lr = 0.0045
I0525 21:50:28.577579 29460 solver.cpp:237] Iteration 31350, loss = 1.31507
I0525 21:50:28.577616 29460 solver.cpp:253]     Train net output #0: loss = 1.31507 (* 1 = 1.31507 loss)
I0525 21:50:28.577636 29460 sgd_solver.cpp:106] Iteration 31350, lr = 0.0045
I0525 21:50:37.247334 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_31500.caffemodel
I0525 21:50:37.325951 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_31500.solverstate
I0525 21:50:37.369663 29460 solver.cpp:237] Iteration 31500, loss = 1.09693
I0525 21:50:37.369714 29460 solver.cpp:253]     Train net output #0: loss = 1.09693 (* 1 = 1.09693 loss)
I0525 21:50:37.369740 29460 sgd_solver.cpp:106] Iteration 31500, lr = 0.0045
I0525 21:50:46.097826 29460 solver.cpp:237] Iteration 31650, loss = 1.26778
I0525 21:50:46.097862 29460 solver.cpp:253]     Train net output #0: loss = 1.26778 (* 1 = 1.26778 loss)
I0525 21:50:46.097887 29460 sgd_solver.cpp:106] Iteration 31650, lr = 0.0045
I0525 21:50:54.822743 29460 solver.cpp:237] Iteration 31800, loss = 1.28765
I0525 21:50:54.822914 29460 solver.cpp:253]     Train net output #0: loss = 1.28765 (* 1 = 1.28765 loss)
I0525 21:50:54.822931 29460 sgd_solver.cpp:106] Iteration 31800, lr = 0.0045
I0525 21:51:03.551388 29460 solver.cpp:237] Iteration 31950, loss = 1.20476
I0525 21:51:03.551436 29460 solver.cpp:253]     Train net output #0: loss = 1.20476 (* 1 = 1.20476 loss)
I0525 21:51:03.551453 29460 sgd_solver.cpp:106] Iteration 31950, lr = 0.0045
I0525 21:51:33.159512 29460 solver.cpp:237] Iteration 32100, loss = 1.11222
I0525 21:51:33.159695 29460 solver.cpp:253]     Train net output #0: loss = 1.11222 (* 1 = 1.11222 loss)
I0525 21:51:33.159714 29460 sgd_solver.cpp:106] Iteration 32100, lr = 0.0045
I0525 21:51:41.886174 29460 solver.cpp:237] Iteration 32250, loss = 1.12408
I0525 21:51:41.886211 29460 solver.cpp:253]     Train net output #0: loss = 1.12408 (* 1 = 1.12408 loss)
I0525 21:51:41.886234 29460 sgd_solver.cpp:106] Iteration 32250, lr = 0.0045
I0525 21:51:50.615818 29460 solver.cpp:237] Iteration 32400, loss = 1.1026
I0525 21:51:50.615869 29460 solver.cpp:253]     Train net output #0: loss = 1.1026 (* 1 = 1.1026 loss)
I0525 21:51:50.615885 29460 sgd_solver.cpp:106] Iteration 32400, lr = 0.0045
I0525 21:51:59.349788 29460 solver.cpp:237] Iteration 32550, loss = 1.10899
I0525 21:51:59.349825 29460 solver.cpp:253]     Train net output #0: loss = 1.10899 (* 1 = 1.10899 loss)
I0525 21:51:59.349849 29460 sgd_solver.cpp:106] Iteration 32550, lr = 0.0045
I0525 21:52:08.082018 29460 solver.cpp:237] Iteration 32700, loss = 1.24162
I0525 21:52:08.082178 29460 solver.cpp:253]     Train net output #0: loss = 1.24162 (* 1 = 1.24162 loss)
I0525 21:52:08.082195 29460 sgd_solver.cpp:106] Iteration 32700, lr = 0.0045
I0525 21:52:16.812355 29460 solver.cpp:237] Iteration 32850, loss = 1.25164
I0525 21:52:16.812407 29460 solver.cpp:253]     Train net output #0: loss = 1.25164 (* 1 = 1.25164 loss)
I0525 21:52:16.812432 29460 sgd_solver.cpp:106] Iteration 32850, lr = 0.0045
I0525 21:52:25.484138 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_33000.caffemodel
I0525 21:52:25.562346 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_33000.solverstate
I0525 21:52:25.587926 29460 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 21:53:12.146993 29460 solver.cpp:409]     Test net output #0: accuracy = 0.882595
I0525 21:53:12.147178 29460 solver.cpp:409]     Test net output #1: loss = 0.372487 (* 1 = 0.372487 loss)
I0525 21:53:33.001073 29460 solver.cpp:237] Iteration 33000, loss = 1.13749
I0525 21:53:33.001134 29460 solver.cpp:253]     Train net output #0: loss = 1.13749 (* 1 = 1.13749 loss)
I0525 21:53:33.001163 29460 sgd_solver.cpp:106] Iteration 33000, lr = 0.0045
I0525 21:53:41.733641 29460 solver.cpp:237] Iteration 33150, loss = 1.19788
I0525 21:53:41.733678 29460 solver.cpp:253]     Train net output #0: loss = 1.19788 (* 1 = 1.19788 loss)
I0525 21:53:41.733701 29460 sgd_solver.cpp:106] Iteration 33150, lr = 0.0045
I0525 21:53:50.462767 29460 solver.cpp:237] Iteration 33300, loss = 1.21835
I0525 21:53:50.462937 29460 solver.cpp:253]     Train net output #0: loss = 1.21835 (* 1 = 1.21835 loss)
I0525 21:53:50.462954 29460 sgd_solver.cpp:106] Iteration 33300, lr = 0.0045
I0525 21:53:59.192850 29460 solver.cpp:237] Iteration 33450, loss = 1.31429
I0525 21:53:59.192896 29460 solver.cpp:253]     Train net output #0: loss = 1.31429 (* 1 = 1.31429 loss)
I0525 21:53:59.192914 29460 sgd_solver.cpp:106] Iteration 33450, lr = 0.0045
I0525 21:54:07.926935 29460 solver.cpp:237] Iteration 33600, loss = 1.14118
I0525 21:54:07.926971 29460 solver.cpp:253]     Train net output #0: loss = 1.14118 (* 1 = 1.14118 loss)
I0525 21:54:07.926990 29460 sgd_solver.cpp:106] Iteration 33600, lr = 0.0045
I0525 21:54:16.666532 29460 solver.cpp:237] Iteration 33750, loss = 1.0169
I0525 21:54:16.666585 29460 solver.cpp:253]     Train net output #0: loss = 1.0169 (* 1 = 1.0169 loss)
I0525 21:54:16.666604 29460 sgd_solver.cpp:106] Iteration 33750, lr = 0.0045
I0525 21:54:25.393263 29460 solver.cpp:237] Iteration 33900, loss = 0.956256
I0525 21:54:25.393429 29460 solver.cpp:253]     Train net output #0: loss = 0.956256 (* 1 = 0.956256 loss)
I0525 21:54:25.393446 29460 sgd_solver.cpp:106] Iteration 33900, lr = 0.0045
I0525 21:54:54.999348 29460 solver.cpp:237] Iteration 34050, loss = 1.19188
I0525 21:54:54.999404 29460 solver.cpp:253]     Train net output #0: loss = 1.19188 (* 1 = 1.19188 loss)
I0525 21:54:54.999429 29460 sgd_solver.cpp:106] Iteration 34050, lr = 0.0045
I0525 21:55:03.729801 29460 solver.cpp:237] Iteration 34200, loss = 1.07904
I0525 21:55:03.729966 29460 solver.cpp:253]     Train net output #0: loss = 1.07904 (* 1 = 1.07904 loss)
I0525 21:55:03.729982 29460 sgd_solver.cpp:106] Iteration 34200, lr = 0.0045
I0525 21:55:12.470782 29460 solver.cpp:237] Iteration 34350, loss = 1.24769
I0525 21:55:12.470832 29460 solver.cpp:253]     Train net output #0: loss = 1.24769 (* 1 = 1.24769 loss)
I0525 21:55:12.470852 29460 sgd_solver.cpp:106] Iteration 34350, lr = 0.0045
I0525 21:55:21.144299 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_34500.caffemodel
I0525 21:55:21.222625 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_34500.solverstate
I0525 21:55:21.266266 29460 solver.cpp:237] Iteration 34500, loss = 1.08737
I0525 21:55:21.266320 29460 solver.cpp:253]     Train net output #0: loss = 1.08737 (* 1 = 1.08737 loss)
I0525 21:55:21.266345 29460 sgd_solver.cpp:106] Iteration 34500, lr = 0.0045
I0525 21:55:29.997313 29460 solver.cpp:237] Iteration 34650, loss = 1.13251
I0525 21:55:29.997350 29460 solver.cpp:253]     Train net output #0: loss = 1.13251 (* 1 = 1.13251 loss)
I0525 21:55:29.997375 29460 sgd_solver.cpp:106] Iteration 34650, lr = 0.0045
I0525 21:55:38.726485 29460 solver.cpp:237] Iteration 34800, loss = 1.18989
I0525 21:55:38.726662 29460 solver.cpp:253]     Train net output #0: loss = 1.18989 (* 1 = 1.18989 loss)
I0525 21:55:38.726680 29460 sgd_solver.cpp:106] Iteration 34800, lr = 0.0045
I0525 21:55:47.458370 29460 solver.cpp:237] Iteration 34950, loss = 1.17457
I0525 21:55:47.458407 29460 solver.cpp:253]     Train net output #0: loss = 1.17457 (* 1 = 1.17457 loss)
I0525 21:55:47.458426 29460 sgd_solver.cpp:106] Iteration 34950, lr = 0.0045
I0525 21:56:17.069727 29460 solver.cpp:237] Iteration 35100, loss = 1.14236
I0525 21:56:17.069911 29460 solver.cpp:253]     Train net output #0: loss = 1.14236 (* 1 = 1.14236 loss)
I0525 21:56:17.069929 29460 sgd_solver.cpp:106] Iteration 35100, lr = 0.0045
I0525 21:56:25.805774 29460 solver.cpp:237] Iteration 35250, loss = 1.0643
I0525 21:56:25.805826 29460 solver.cpp:253]     Train net output #0: loss = 1.0643 (* 1 = 1.0643 loss)
I0525 21:56:25.805851 29460 sgd_solver.cpp:106] Iteration 35250, lr = 0.0045
I0525 21:56:34.534103 29460 solver.cpp:237] Iteration 35400, loss = 1.13634
I0525 21:56:34.534140 29460 solver.cpp:253]     Train net output #0: loss = 1.13634 (* 1 = 1.13634 loss)
I0525 21:56:34.534158 29460 sgd_solver.cpp:106] Iteration 35400, lr = 0.0045
I0525 21:56:43.267864 29460 solver.cpp:237] Iteration 35550, loss = 1.02469
I0525 21:56:43.267900 29460 solver.cpp:253]     Train net output #0: loss = 1.02469 (* 1 = 1.02469 loss)
I0525 21:56:43.267925 29460 sgd_solver.cpp:106] Iteration 35550, lr = 0.0045
I0525 21:56:51.998929 29460 solver.cpp:237] Iteration 35700, loss = 1.09821
I0525 21:56:51.999117 29460 solver.cpp:253]     Train net output #0: loss = 1.09821 (* 1 = 1.09821 loss)
I0525 21:56:51.999136 29460 sgd_solver.cpp:106] Iteration 35700, lr = 0.0045
I0525 21:57:00.728016 29460 solver.cpp:237] Iteration 35850, loss = 1.16567
I0525 21:57:00.728054 29460 solver.cpp:253]     Train net output #0: loss = 1.16567 (* 1 = 1.16567 loss)
I0525 21:57:00.728073 29460 sgd_solver.cpp:106] Iteration 35850, lr = 0.0045
I0525 21:57:09.397346 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_36000.caffemodel
I0525 21:57:09.479854 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_36000.solverstate
I0525 21:57:09.507685 29460 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 21:58:17.332563 29460 solver.cpp:409]     Test net output #0: accuracy = 0.883894
I0525 21:58:17.332744 29460 solver.cpp:409]     Test net output #1: loss = 0.38027 (* 1 = 0.38027 loss)
I0525 21:58:38.265328 29460 solver.cpp:237] Iteration 36000, loss = 1.32832
I0525 21:58:38.265390 29460 solver.cpp:253]     Train net output #0: loss = 1.32832 (* 1 = 1.32832 loss)
I0525 21:58:38.265409 29460 sgd_solver.cpp:106] Iteration 36000, lr = 0.0045
I0525 21:58:47.006364 29460 solver.cpp:237] Iteration 36150, loss = 1.20394
I0525 21:58:47.006402 29460 solver.cpp:253]     Train net output #0: loss = 1.20394 (* 1 = 1.20394 loss)
I0525 21:58:47.006427 29460 sgd_solver.cpp:106] Iteration 36150, lr = 0.0045
I0525 21:58:55.747794 29460 solver.cpp:237] Iteration 36300, loss = 1.2095
I0525 21:58:55.747972 29460 solver.cpp:253]     Train net output #0: loss = 1.2095 (* 1 = 1.2095 loss)
I0525 21:58:55.747992 29460 sgd_solver.cpp:106] Iteration 36300, lr = 0.0045
I0525 21:59:04.488404 29460 solver.cpp:237] Iteration 36450, loss = 1.29482
I0525 21:59:04.488440 29460 solver.cpp:253]     Train net output #0: loss = 1.29482 (* 1 = 1.29482 loss)
I0525 21:59:04.488458 29460 sgd_solver.cpp:106] Iteration 36450, lr = 0.0045
I0525 21:59:13.231554 29460 solver.cpp:237] Iteration 36600, loss = 1.21893
I0525 21:59:13.231590 29460 solver.cpp:253]     Train net output #0: loss = 1.21893 (* 1 = 1.21893 loss)
I0525 21:59:13.231613 29460 sgd_solver.cpp:106] Iteration 36600, lr = 0.0045
I0525 21:59:21.975522 29460 solver.cpp:237] Iteration 36750, loss = 1.1426
I0525 21:59:21.975574 29460 solver.cpp:253]     Train net output #0: loss = 1.1426 (* 1 = 1.1426 loss)
I0525 21:59:21.975600 29460 sgd_solver.cpp:106] Iteration 36750, lr = 0.0045
I0525 21:59:30.717913 29460 solver.cpp:237] Iteration 36900, loss = 1.11896
I0525 21:59:30.718087 29460 solver.cpp:253]     Train net output #0: loss = 1.11896 (* 1 = 1.11896 loss)
I0525 21:59:30.718103 29460 sgd_solver.cpp:106] Iteration 36900, lr = 0.0045
I0525 22:00:00.370883 29460 solver.cpp:237] Iteration 37050, loss = 1.18232
I0525 22:00:00.370939 29460 solver.cpp:253]     Train net output #0: loss = 1.18232 (* 1 = 1.18232 loss)
I0525 22:00:00.370964 29460 sgd_solver.cpp:106] Iteration 37050, lr = 0.0045
I0525 22:00:09.113554 29460 solver.cpp:237] Iteration 37200, loss = 1.20539
I0525 22:00:09.113745 29460 solver.cpp:253]     Train net output #0: loss = 1.20539 (* 1 = 1.20539 loss)
I0525 22:00:09.113765 29460 sgd_solver.cpp:106] Iteration 37200, lr = 0.0045
I0525 22:00:17.857563 29460 solver.cpp:237] Iteration 37350, loss = 1.19484
I0525 22:00:17.857599 29460 solver.cpp:253]     Train net output #0: loss = 1.19484 (* 1 = 1.19484 loss)
I0525 22:00:17.857623 29460 sgd_solver.cpp:106] Iteration 37350, lr = 0.0045
I0525 22:00:26.541718 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_37500.caffemodel
I0525 22:00:26.622254 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_37500.solverstate
I0525 22:00:26.667903 29460 solver.cpp:237] Iteration 37500, loss = 1.15206
I0525 22:00:26.667958 29460 solver.cpp:253]     Train net output #0: loss = 1.15206 (* 1 = 1.15206 loss)
I0525 22:00:26.667984 29460 sgd_solver.cpp:106] Iteration 37500, lr = 0.0045
I0525 22:00:35.413312 29460 solver.cpp:237] Iteration 37650, loss = 0.946946
I0525 22:00:35.413367 29460 solver.cpp:253]     Train net output #0: loss = 0.946946 (* 1 = 0.946946 loss)
I0525 22:00:35.413393 29460 sgd_solver.cpp:106] Iteration 37650, lr = 0.0045
I0525 22:00:44.154366 29460 solver.cpp:237] Iteration 37800, loss = 1.17643
I0525 22:00:44.154536 29460 solver.cpp:253]     Train net output #0: loss = 1.17643 (* 1 = 1.17643 loss)
I0525 22:00:44.154552 29460 sgd_solver.cpp:106] Iteration 37800, lr = 0.0045
I0525 22:00:52.889863 29460 solver.cpp:237] Iteration 37950, loss = 1.01964
I0525 22:00:52.889899 29460 solver.cpp:253]     Train net output #0: loss = 1.01964 (* 1 = 1.01964 loss)
I0525 22:00:52.889924 29460 sgd_solver.cpp:106] Iteration 37950, lr = 0.0045
I0525 22:01:22.505139 29460 solver.cpp:237] Iteration 38100, loss = 1.20029
I0525 22:01:22.505321 29460 solver.cpp:253]     Train net output #0: loss = 1.20029 (* 1 = 1.20029 loss)
I0525 22:01:22.505347 29460 sgd_solver.cpp:106] Iteration 38100, lr = 0.0045
I0525 22:01:31.247687 29460 solver.cpp:237] Iteration 38250, loss = 1.10482
I0525 22:01:31.247725 29460 solver.cpp:253]     Train net output #0: loss = 1.10482 (* 1 = 1.10482 loss)
I0525 22:01:31.247747 29460 sgd_solver.cpp:106] Iteration 38250, lr = 0.0045
I0525 22:01:39.991770 29460 solver.cpp:237] Iteration 38400, loss = 1.02077
I0525 22:01:39.991806 29460 solver.cpp:253]     Train net output #0: loss = 1.02077 (* 1 = 1.02077 loss)
I0525 22:01:39.991825 29460 sgd_solver.cpp:106] Iteration 38400, lr = 0.0045
I0525 22:01:48.733337 29460 solver.cpp:237] Iteration 38550, loss = 1.44067
I0525 22:01:48.733392 29460 solver.cpp:253]     Train net output #0: loss = 1.44067 (* 1 = 1.44067 loss)
I0525 22:01:48.733420 29460 sgd_solver.cpp:106] Iteration 38550, lr = 0.0045
I0525 22:01:57.470675 29460 solver.cpp:237] Iteration 38700, loss = 1.31723
I0525 22:01:57.470850 29460 solver.cpp:253]     Train net output #0: loss = 1.31723 (* 1 = 1.31723 loss)
I0525 22:01:57.470867 29460 sgd_solver.cpp:106] Iteration 38700, lr = 0.0045
I0525 22:02:06.213986 29460 solver.cpp:237] Iteration 38850, loss = 0.912742
I0525 22:02:06.214025 29460 solver.cpp:253]     Train net output #0: loss = 0.912742 (* 1 = 0.912742 loss)
I0525 22:02:06.214045 29460 sgd_solver.cpp:106] Iteration 38850, lr = 0.0045
I0525 22:02:14.899809 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_39000.caffemodel
I0525 22:02:14.978693 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_39000.solverstate
I0525 22:02:15.004544 29460 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 22:03:01.894407 29460 solver.cpp:409]     Test net output #0: accuracy = 0.887861
I0525 22:03:01.894598 29460 solver.cpp:409]     Test net output #1: loss = 0.360268 (* 1 = 0.360268 loss)
I0525 22:03:22.750563 29460 solver.cpp:237] Iteration 39000, loss = 1.25317
I0525 22:03:22.750622 29460 solver.cpp:253]     Train net output #0: loss = 1.25317 (* 1 = 1.25317 loss)
I0525 22:03:22.750640 29460 sgd_solver.cpp:106] Iteration 39000, lr = 0.0045
I0525 22:03:31.485064 29460 solver.cpp:237] Iteration 39150, loss = 1.16482
I0525 22:03:31.485116 29460 solver.cpp:253]     Train net output #0: loss = 1.16482 (* 1 = 1.16482 loss)
I0525 22:03:31.485143 29460 sgd_solver.cpp:106] Iteration 39150, lr = 0.0045
I0525 22:03:40.222313 29460 solver.cpp:237] Iteration 39300, loss = 1.15199
I0525 22:03:40.222493 29460 solver.cpp:253]     Train net output #0: loss = 1.15199 (* 1 = 1.15199 loss)
I0525 22:03:40.222510 29460 sgd_solver.cpp:106] Iteration 39300, lr = 0.0045
I0525 22:03:48.958941 29460 solver.cpp:237] Iteration 39450, loss = 1.12034
I0525 22:03:48.958979 29460 solver.cpp:253]     Train net output #0: loss = 1.12034 (* 1 = 1.12034 loss)
I0525 22:03:48.958997 29460 sgd_solver.cpp:106] Iteration 39450, lr = 0.0045
I0525 22:03:57.697441 29460 solver.cpp:237] Iteration 39600, loss = 1.29728
I0525 22:03:57.697497 29460 solver.cpp:253]     Train net output #0: loss = 1.29728 (* 1 = 1.29728 loss)
I0525 22:03:57.697516 29460 sgd_solver.cpp:106] Iteration 39600, lr = 0.0045
I0525 22:04:06.433755 29460 solver.cpp:237] Iteration 39750, loss = 1.25629
I0525 22:04:06.433792 29460 solver.cpp:253]     Train net output #0: loss = 1.25629 (* 1 = 1.25629 loss)
I0525 22:04:06.433816 29460 sgd_solver.cpp:106] Iteration 39750, lr = 0.0045
I0525 22:04:15.172322 29460 solver.cpp:237] Iteration 39900, loss = 1.075
I0525 22:04:15.172489 29460 solver.cpp:253]     Train net output #0: loss = 1.075 (* 1 = 1.075 loss)
I0525 22:04:15.172507 29460 sgd_solver.cpp:106] Iteration 39900, lr = 0.0045
I0525 22:04:44.751505 29460 solver.cpp:237] Iteration 40050, loss = 1.1679
I0525 22:04:44.751560 29460 solver.cpp:253]     Train net output #0: loss = 1.1679 (* 1 = 1.1679 loss)
I0525 22:04:44.751577 29460 sgd_solver.cpp:106] Iteration 40050, lr = 0.0045
I0525 22:04:53.486657 29460 solver.cpp:237] Iteration 40200, loss = 1.22315
I0525 22:04:53.486824 29460 solver.cpp:253]     Train net output #0: loss = 1.22315 (* 1 = 1.22315 loss)
I0525 22:04:53.486841 29460 sgd_solver.cpp:106] Iteration 40200, lr = 0.0045
I0525 22:05:02.224189 29460 solver.cpp:237] Iteration 40350, loss = 1.15908
I0525 22:05:02.224225 29460 solver.cpp:253]     Train net output #0: loss = 1.15908 (* 1 = 1.15908 loss)
I0525 22:05:02.224244 29460 sgd_solver.cpp:106] Iteration 40350, lr = 0.0045
I0525 22:05:10.901249 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_40500.caffemodel
I0525 22:05:10.980728 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_40500.solverstate
I0525 22:05:11.024453 29460 solver.cpp:237] Iteration 40500, loss = 1.1105
I0525 22:05:11.024507 29460 solver.cpp:253]     Train net output #0: loss = 1.1105 (* 1 = 1.1105 loss)
I0525 22:05:11.024533 29460 sgd_solver.cpp:106] Iteration 40500, lr = 0.0045
I0525 22:05:19.759269 29460 solver.cpp:237] Iteration 40650, loss = 1.05774
I0525 22:05:19.759307 29460 solver.cpp:253]     Train net output #0: loss = 1.05774 (* 1 = 1.05774 loss)
I0525 22:05:19.759326 29460 sgd_solver.cpp:106] Iteration 40650, lr = 0.0045
I0525 22:05:28.502467 29460 solver.cpp:237] Iteration 40800, loss = 1.30804
I0525 22:05:28.502634 29460 solver.cpp:253]     Train net output #0: loss = 1.30804 (* 1 = 1.30804 loss)
I0525 22:05:28.502650 29460 sgd_solver.cpp:106] Iteration 40800, lr = 0.0045
I0525 22:05:37.240942 29460 solver.cpp:237] Iteration 40950, loss = 1.14314
I0525 22:05:37.240993 29460 solver.cpp:253]     Train net output #0: loss = 1.14314 (* 1 = 1.14314 loss)
I0525 22:05:37.241019 29460 sgd_solver.cpp:106] Iteration 40950, lr = 0.0045
I0525 22:06:06.831295 29460 solver.cpp:237] Iteration 41100, loss = 1.17967
I0525 22:06:06.831491 29460 solver.cpp:253]     Train net output #0: loss = 1.17967 (* 1 = 1.17967 loss)
I0525 22:06:06.831511 29460 sgd_solver.cpp:106] Iteration 41100, lr = 0.0045
I0525 22:06:15.569128 29460 solver.cpp:237] Iteration 41250, loss = 1.40088
I0525 22:06:15.569164 29460 solver.cpp:253]     Train net output #0: loss = 1.40088 (* 1 = 1.40088 loss)
I0525 22:06:15.569182 29460 sgd_solver.cpp:106] Iteration 41250, lr = 0.0045
I0525 22:06:24.306588 29460 solver.cpp:237] Iteration 41400, loss = 1.15922
I0525 22:06:24.306643 29460 solver.cpp:253]     Train net output #0: loss = 1.15922 (* 1 = 1.15922 loss)
I0525 22:06:24.306668 29460 sgd_solver.cpp:106] Iteration 41400, lr = 0.0045
I0525 22:06:33.047014 29460 solver.cpp:237] Iteration 41550, loss = 1.34574
I0525 22:06:33.047050 29460 solver.cpp:253]     Train net output #0: loss = 1.34574 (* 1 = 1.34574 loss)
I0525 22:06:33.047075 29460 sgd_solver.cpp:106] Iteration 41550, lr = 0.0045
I0525 22:06:41.789789 29460 solver.cpp:237] Iteration 41700, loss = 1.11104
I0525 22:06:41.789964 29460 solver.cpp:253]     Train net output #0: loss = 1.11104 (* 1 = 1.11104 loss)
I0525 22:06:41.789981 29460 sgd_solver.cpp:106] Iteration 41700, lr = 0.0045
I0525 22:06:50.528723 29460 solver.cpp:237] Iteration 41850, loss = 1.0859
I0525 22:06:50.528781 29460 solver.cpp:253]     Train net output #0: loss = 1.0859 (* 1 = 1.0859 loss)
I0525 22:06:50.528800 29460 sgd_solver.cpp:106] Iteration 41850, lr = 0.0045
I0525 22:06:59.212160 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_42000.caffemodel
I0525 22:06:59.291120 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_42000.solverstate
I0525 22:06:59.317639 29460 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 22:08:07.103730 29460 solver.cpp:409]     Test net output #0: accuracy = 0.887821
I0525 22:08:07.103915 29460 solver.cpp:409]     Test net output #1: loss = 0.348011 (* 1 = 0.348011 loss)
I0525 22:08:27.974289 29460 solver.cpp:237] Iteration 42000, loss = 1.28891
I0525 22:08:27.974352 29460 solver.cpp:253]     Train net output #0: loss = 1.28891 (* 1 = 1.28891 loss)
I0525 22:08:27.974372 29460 sgd_solver.cpp:106] Iteration 42000, lr = 0.0045
I0525 22:08:36.705760 29460 solver.cpp:237] Iteration 42150, loss = 1.09187
I0525 22:08:36.705796 29460 solver.cpp:253]     Train net output #0: loss = 1.09187 (* 1 = 1.09187 loss)
I0525 22:08:36.705821 29460 sgd_solver.cpp:106] Iteration 42150, lr = 0.0045
I0525 22:08:45.441303 29460 solver.cpp:237] Iteration 42300, loss = 0.948921
I0525 22:08:45.441478 29460 solver.cpp:253]     Train net output #0: loss = 0.948921 (* 1 = 0.948921 loss)
I0525 22:08:45.441495 29460 sgd_solver.cpp:106] Iteration 42300, lr = 0.0045
I0525 22:08:54.177605 29460 solver.cpp:237] Iteration 42450, loss = 1.44748
I0525 22:08:54.177659 29460 solver.cpp:253]     Train net output #0: loss = 1.44748 (* 1 = 1.44748 loss)
I0525 22:08:54.177685 29460 sgd_solver.cpp:106] Iteration 42450, lr = 0.0045
I0525 22:09:02.908175 29460 solver.cpp:237] Iteration 42600, loss = 1.24699
I0525 22:09:02.908211 29460 solver.cpp:253]     Train net output #0: loss = 1.24699 (* 1 = 1.24699 loss)
I0525 22:09:02.908236 29460 sgd_solver.cpp:106] Iteration 42600, lr = 0.0045
I0525 22:09:11.650277 29460 solver.cpp:237] Iteration 42750, loss = 1.14045
I0525 22:09:11.650315 29460 solver.cpp:253]     Train net output #0: loss = 1.14045 (* 1 = 1.14045 loss)
I0525 22:09:11.650337 29460 sgd_solver.cpp:106] Iteration 42750, lr = 0.0045
I0525 22:09:20.386924 29460 solver.cpp:237] Iteration 42900, loss = 1.00027
I0525 22:09:20.387107 29460 solver.cpp:253]     Train net output #0: loss = 1.00027 (* 1 = 1.00027 loss)
I0525 22:09:20.387126 29460 sgd_solver.cpp:106] Iteration 42900, lr = 0.0045
I0525 22:09:50.010207 29460 solver.cpp:237] Iteration 43050, loss = 1.17795
I0525 22:09:50.010262 29460 solver.cpp:253]     Train net output #0: loss = 1.17795 (* 1 = 1.17795 loss)
I0525 22:09:50.010280 29460 sgd_solver.cpp:106] Iteration 43050, lr = 0.0045
I0525 22:09:58.740416 29460 solver.cpp:237] Iteration 43200, loss = 1.28107
I0525 22:09:58.740598 29460 solver.cpp:253]     Train net output #0: loss = 1.28107 (* 1 = 1.28107 loss)
I0525 22:09:58.740615 29460 sgd_solver.cpp:106] Iteration 43200, lr = 0.0045
I0525 22:10:07.478814 29460 solver.cpp:237] Iteration 43350, loss = 1.18877
I0525 22:10:07.478868 29460 solver.cpp:253]     Train net output #0: loss = 1.18877 (* 1 = 1.18877 loss)
I0525 22:10:07.478894 29460 sgd_solver.cpp:106] Iteration 43350, lr = 0.0045
I0525 22:10:16.168758 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_43500.caffemodel
I0525 22:10:16.249493 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_43500.solverstate
I0525 22:10:16.295061 29460 solver.cpp:237] Iteration 43500, loss = 1.26481
I0525 22:10:16.295114 29460 solver.cpp:253]     Train net output #0: loss = 1.26481 (* 1 = 1.26481 loss)
I0525 22:10:16.295141 29460 sgd_solver.cpp:106] Iteration 43500, lr = 0.0045
I0525 22:10:25.048324 29460 solver.cpp:237] Iteration 43650, loss = 1.0879
I0525 22:10:25.048360 29460 solver.cpp:253]     Train net output #0: loss = 1.0879 (* 1 = 1.0879 loss)
I0525 22:10:25.048384 29460 sgd_solver.cpp:106] Iteration 43650, lr = 0.0045
I0525 22:10:33.793202 29460 solver.cpp:237] Iteration 43800, loss = 1.41353
I0525 22:10:33.793390 29460 solver.cpp:253]     Train net output #0: loss = 1.41353 (* 1 = 1.41353 loss)
I0525 22:10:33.793411 29460 sgd_solver.cpp:106] Iteration 43800, lr = 0.0045
I0525 22:10:42.523311 29460 solver.cpp:237] Iteration 43950, loss = 1.35813
I0525 22:10:42.523349 29460 solver.cpp:253]     Train net output #0: loss = 1.35813 (* 1 = 1.35813 loss)
I0525 22:10:42.523371 29460 sgd_solver.cpp:106] Iteration 43950, lr = 0.0045
I0525 22:11:12.166522 29460 solver.cpp:237] Iteration 44100, loss = 1.03124
I0525 22:11:12.166712 29460 solver.cpp:253]     Train net output #0: loss = 1.03124 (* 1 = 1.03124 loss)
I0525 22:11:12.166733 29460 sgd_solver.cpp:106] Iteration 44100, lr = 0.0045
I0525 22:11:20.908357 29460 solver.cpp:237] Iteration 44250, loss = 1.2649
I0525 22:11:20.908393 29460 solver.cpp:253]     Train net output #0: loss = 1.2649 (* 1 = 1.2649 loss)
I0525 22:11:20.908416 29460 sgd_solver.cpp:106] Iteration 44250, lr = 0.0045
I0525 22:11:29.651404 29460 solver.cpp:237] Iteration 44400, loss = 1.10435
I0525 22:11:29.651456 29460 solver.cpp:253]     Train net output #0: loss = 1.10435 (* 1 = 1.10435 loss)
I0525 22:11:29.651480 29460 sgd_solver.cpp:106] Iteration 44400, lr = 0.0045
I0525 22:11:38.391906 29460 solver.cpp:237] Iteration 44550, loss = 1.26692
I0525 22:11:38.391944 29460 solver.cpp:253]     Train net output #0: loss = 1.26692 (* 1 = 1.26692 loss)
I0525 22:11:38.391968 29460 sgd_solver.cpp:106] Iteration 44550, lr = 0.0045
I0525 22:11:47.132094 29460 solver.cpp:237] Iteration 44700, loss = 1.07739
I0525 22:11:47.132277 29460 solver.cpp:253]     Train net output #0: loss = 1.07739 (* 1 = 1.07739 loss)
I0525 22:11:47.132297 29460 sgd_solver.cpp:106] Iteration 44700, lr = 0.0045
I0525 22:11:55.873574 29460 solver.cpp:237] Iteration 44850, loss = 1.21906
I0525 22:11:55.873610 29460 solver.cpp:253]     Train net output #0: loss = 1.21906 (* 1 = 1.21906 loss)
I0525 22:11:55.873628 29460 sgd_solver.cpp:106] Iteration 44850, lr = 0.0045
I0525 22:12:04.566681 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_45000.caffemodel
I0525 22:12:04.648031 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_45000.solverstate
I0525 22:12:04.675535 29460 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 22:12:51.285713 29460 solver.cpp:409]     Test net output #0: accuracy = 0.890422
I0525 22:12:51.285907 29460 solver.cpp:409]     Test net output #1: loss = 0.354647 (* 1 = 0.354647 loss)
I0525 22:13:12.190407 29460 solver.cpp:237] Iteration 45000, loss = 1.25698
I0525 22:13:12.190466 29460 solver.cpp:253]     Train net output #0: loss = 1.25698 (* 1 = 1.25698 loss)
I0525 22:13:12.190486 29460 sgd_solver.cpp:106] Iteration 45000, lr = 0.0045
I0525 22:13:20.943269 29460 solver.cpp:237] Iteration 45150, loss = 1.12737
I0525 22:13:20.943307 29460 solver.cpp:253]     Train net output #0: loss = 1.12737 (* 1 = 1.12737 loss)
I0525 22:13:20.943332 29460 sgd_solver.cpp:106] Iteration 45150, lr = 0.0045
I0525 22:13:29.695281 29460 solver.cpp:237] Iteration 45300, loss = 1.32801
I0525 22:13:29.695467 29460 solver.cpp:253]     Train net output #0: loss = 1.32801 (* 1 = 1.32801 loss)
I0525 22:13:29.695485 29460 sgd_solver.cpp:106] Iteration 45300, lr = 0.0045
I0525 22:13:38.437844 29460 solver.cpp:237] Iteration 45450, loss = 1.08831
I0525 22:13:38.437882 29460 solver.cpp:253]     Train net output #0: loss = 1.08831 (* 1 = 1.08831 loss)
I0525 22:13:38.437902 29460 sgd_solver.cpp:106] Iteration 45450, lr = 0.0045
I0525 22:13:47.182801 29460 solver.cpp:237] Iteration 45600, loss = 1.22675
I0525 22:13:47.182837 29460 solver.cpp:253]     Train net output #0: loss = 1.22675 (* 1 = 1.22675 loss)
I0525 22:13:47.182863 29460 sgd_solver.cpp:106] Iteration 45600, lr = 0.0045
I0525 22:13:55.915400 29460 solver.cpp:237] Iteration 45750, loss = 1.10448
I0525 22:13:55.915455 29460 solver.cpp:253]     Train net output #0: loss = 1.10448 (* 1 = 1.10448 loss)
I0525 22:13:55.915482 29460 sgd_solver.cpp:106] Iteration 45750, lr = 0.0045
I0525 22:14:04.657274 29460 solver.cpp:237] Iteration 45900, loss = 1.17518
I0525 22:14:04.657444 29460 solver.cpp:253]     Train net output #0: loss = 1.17518 (* 1 = 1.17518 loss)
I0525 22:14:04.657461 29460 sgd_solver.cpp:106] Iteration 45900, lr = 0.0045
I0525 22:14:34.292189 29460 solver.cpp:237] Iteration 46050, loss = 1.16056
I0525 22:14:34.292244 29460 solver.cpp:253]     Train net output #0: loss = 1.16056 (* 1 = 1.16056 loss)
I0525 22:14:34.292263 29460 sgd_solver.cpp:106] Iteration 46050, lr = 0.0045
I0525 22:14:43.032040 29460 solver.cpp:237] Iteration 46200, loss = 1.2436
I0525 22:14:43.032224 29460 solver.cpp:253]     Train net output #0: loss = 1.2436 (* 1 = 1.2436 loss)
I0525 22:14:43.032245 29460 sgd_solver.cpp:106] Iteration 46200, lr = 0.0045
I0525 22:14:51.774219 29460 solver.cpp:237] Iteration 46350, loss = 1.39179
I0525 22:14:51.774256 29460 solver.cpp:253]     Train net output #0: loss = 1.39179 (* 1 = 1.39179 loss)
I0525 22:14:51.774281 29460 sgd_solver.cpp:106] Iteration 46350, lr = 0.0045
I0525 22:15:00.455636 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_46500.caffemodel
I0525 22:15:00.535001 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_46500.solverstate
I0525 22:15:00.578783 29460 solver.cpp:237] Iteration 46500, loss = 1.06759
I0525 22:15:00.578838 29460 solver.cpp:253]     Train net output #0: loss = 1.06759 (* 1 = 1.06759 loss)
I0525 22:15:00.578855 29460 sgd_solver.cpp:106] Iteration 46500, lr = 0.0045
I0525 22:15:09.320452 29460 solver.cpp:237] Iteration 46650, loss = 1.25597
I0525 22:15:09.320507 29460 solver.cpp:253]     Train net output #0: loss = 1.25597 (* 1 = 1.25597 loss)
I0525 22:15:09.320528 29460 sgd_solver.cpp:106] Iteration 46650, lr = 0.0045
I0525 22:15:18.061951 29460 solver.cpp:237] Iteration 46800, loss = 1.12854
I0525 22:15:18.062134 29460 solver.cpp:253]     Train net output #0: loss = 1.12854 (* 1 = 1.12854 loss)
I0525 22:15:18.062151 29460 sgd_solver.cpp:106] Iteration 46800, lr = 0.0045
I0525 22:15:26.799530 29460 solver.cpp:237] Iteration 46950, loss = 1.25268
I0525 22:15:26.799569 29460 solver.cpp:253]     Train net output #0: loss = 1.25268 (* 1 = 1.25268 loss)
I0525 22:15:26.799589 29460 sgd_solver.cpp:106] Iteration 46950, lr = 0.0045
I0525 22:15:56.428148 29460 solver.cpp:237] Iteration 47100, loss = 0.968177
I0525 22:15:56.428342 29460 solver.cpp:253]     Train net output #0: loss = 0.968177 (* 1 = 0.968177 loss)
I0525 22:15:56.428361 29460 sgd_solver.cpp:106] Iteration 47100, lr = 0.0045
I0525 22:16:05.167764 29460 solver.cpp:237] Iteration 47250, loss = 1.02116
I0525 22:16:05.167803 29460 solver.cpp:253]     Train net output #0: loss = 1.02116 (* 1 = 1.02116 loss)
I0525 22:16:05.167827 29460 sgd_solver.cpp:106] Iteration 47250, lr = 0.0045
I0525 22:16:13.907017 29460 solver.cpp:237] Iteration 47400, loss = 1.25948
I0525 22:16:13.907057 29460 solver.cpp:253]     Train net output #0: loss = 1.25948 (* 1 = 1.25948 loss)
I0525 22:16:13.907076 29460 sgd_solver.cpp:106] Iteration 47400, lr = 0.0045
I0525 22:16:22.644001 29460 solver.cpp:237] Iteration 47550, loss = 1.16472
I0525 22:16:22.644053 29460 solver.cpp:253]     Train net output #0: loss = 1.16472 (* 1 = 1.16472 loss)
I0525 22:16:22.644073 29460 sgd_solver.cpp:106] Iteration 47550, lr = 0.0045
I0525 22:16:31.377534 29460 solver.cpp:237] Iteration 47700, loss = 1.03144
I0525 22:16:31.377707 29460 solver.cpp:253]     Train net output #0: loss = 1.03144 (* 1 = 1.03144 loss)
I0525 22:16:31.377723 29460 sgd_solver.cpp:106] Iteration 47700, lr = 0.0045
I0525 22:16:40.109799 29460 solver.cpp:237] Iteration 47850, loss = 1.13437
I0525 22:16:40.109838 29460 solver.cpp:253]     Train net output #0: loss = 1.13437 (* 1 = 1.13437 loss)
I0525 22:16:40.109858 29460 sgd_solver.cpp:106] Iteration 47850, lr = 0.0045
I0525 22:16:48.783809 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_48000.caffemodel
I0525 22:16:48.863908 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_48000.solverstate
I0525 22:16:48.890028 29460 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 22:17:56.691071 29460 solver.cpp:409]     Test net output #0: accuracy = 0.893668
I0525 22:17:56.691272 29460 solver.cpp:409]     Test net output #1: loss = 0.340194 (* 1 = 0.340194 loss)
I0525 22:18:17.621096 29460 solver.cpp:237] Iteration 48000, loss = 1.10632
I0525 22:18:17.621155 29460 solver.cpp:253]     Train net output #0: loss = 1.10632 (* 1 = 1.10632 loss)
I0525 22:18:17.621175 29460 sgd_solver.cpp:106] Iteration 48000, lr = 0.0045
I0525 22:18:26.359336 29460 solver.cpp:237] Iteration 48150, loss = 1.3569
I0525 22:18:26.359395 29460 solver.cpp:253]     Train net output #0: loss = 1.3569 (* 1 = 1.3569 loss)
I0525 22:18:26.359421 29460 sgd_solver.cpp:106] Iteration 48150, lr = 0.0045
I0525 22:18:35.109086 29460 solver.cpp:237] Iteration 48300, loss = 1.21276
I0525 22:18:35.109258 29460 solver.cpp:253]     Train net output #0: loss = 1.21276 (* 1 = 1.21276 loss)
I0525 22:18:35.109275 29460 sgd_solver.cpp:106] Iteration 48300, lr = 0.0045
I0525 22:18:43.858628 29460 solver.cpp:237] Iteration 48450, loss = 1.17994
I0525 22:18:43.858666 29460 solver.cpp:253]     Train net output #0: loss = 1.17994 (* 1 = 1.17994 loss)
I0525 22:18:43.858686 29460 sgd_solver.cpp:106] Iteration 48450, lr = 0.0045
I0525 22:18:52.605026 29460 solver.cpp:237] Iteration 48600, loss = 1.29812
I0525 22:18:52.605079 29460 solver.cpp:253]     Train net output #0: loss = 1.29812 (* 1 = 1.29812 loss)
I0525 22:18:52.605099 29460 sgd_solver.cpp:106] Iteration 48600, lr = 0.0045
I0525 22:19:01.346451 29460 solver.cpp:237] Iteration 48750, loss = 1.13761
I0525 22:19:01.346489 29460 solver.cpp:253]     Train net output #0: loss = 1.13761 (* 1 = 1.13761 loss)
I0525 22:19:01.346515 29460 sgd_solver.cpp:106] Iteration 48750, lr = 0.0045
I0525 22:19:10.091810 29460 solver.cpp:237] Iteration 48900, loss = 1.10733
I0525 22:19:10.091994 29460 solver.cpp:253]     Train net output #0: loss = 1.10733 (* 1 = 1.10733 loss)
I0525 22:19:10.092010 29460 sgd_solver.cpp:106] Iteration 48900, lr = 0.0045
I0525 22:19:39.706413 29460 solver.cpp:237] Iteration 49050, loss = 1.13309
I0525 22:19:39.706468 29460 solver.cpp:253]     Train net output #0: loss = 1.13309 (* 1 = 1.13309 loss)
I0525 22:19:39.706490 29460 sgd_solver.cpp:106] Iteration 49050, lr = 0.0045
I0525 22:19:48.458454 29460 solver.cpp:237] Iteration 49200, loss = 1.24862
I0525 22:19:48.458644 29460 solver.cpp:253]     Train net output #0: loss = 1.24862 (* 1 = 1.24862 loss)
I0525 22:19:48.458662 29460 sgd_solver.cpp:106] Iteration 49200, lr = 0.0045
I0525 22:19:57.205288 29460 solver.cpp:237] Iteration 49350, loss = 1.09241
I0525 22:19:57.205325 29460 solver.cpp:253]     Train net output #0: loss = 1.09241 (* 1 = 1.09241 loss)
I0525 22:19:57.205351 29460 sgd_solver.cpp:106] Iteration 49350, lr = 0.0045
I0525 22:20:05.874955 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_49500.caffemodel
I0525 22:20:05.953196 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_49500.solverstate
I0525 22:20:05.999603 29460 solver.cpp:237] Iteration 49500, loss = 1.06126
I0525 22:20:05.999658 29460 solver.cpp:253]     Train net output #0: loss = 1.06126 (* 1 = 1.06126 loss)
I0525 22:20:05.999676 29460 sgd_solver.cpp:106] Iteration 49500, lr = 0.0045
I0525 22:20:14.721195 29460 solver.cpp:237] Iteration 49650, loss = 1.27392
I0525 22:20:14.721247 29460 solver.cpp:253]     Train net output #0: loss = 1.27392 (* 1 = 1.27392 loss)
I0525 22:20:14.721278 29460 sgd_solver.cpp:106] Iteration 49650, lr = 0.0045
I0525 22:20:23.451413 29460 solver.cpp:237] Iteration 49800, loss = 1.06757
I0525 22:20:23.451591 29460 solver.cpp:253]     Train net output #0: loss = 1.06757 (* 1 = 1.06757 loss)
I0525 22:20:23.451607 29460 sgd_solver.cpp:106] Iteration 49800, lr = 0.0045
I0525 22:20:32.178822 29460 solver.cpp:237] Iteration 49950, loss = 1.22759
I0525 22:20:32.178876 29460 solver.cpp:253]     Train net output #0: loss = 1.22759 (* 1 = 1.22759 loss)
I0525 22:20:32.178903 29460 sgd_solver.cpp:106] Iteration 49950, lr = 0.0045
I0525 22:21:01.801944 29460 solver.cpp:237] Iteration 50100, loss = 1.09361
I0525 22:21:01.802134 29460 solver.cpp:253]     Train net output #0: loss = 1.09361 (* 1 = 1.09361 loss)
I0525 22:21:01.802155 29460 sgd_solver.cpp:106] Iteration 50100, lr = 0.0045
I0525 22:21:10.532063 29460 solver.cpp:237] Iteration 50250, loss = 1.06364
I0525 22:21:10.532100 29460 solver.cpp:253]     Train net output #0: loss = 1.06364 (* 1 = 1.06364 loss)
I0525 22:21:10.532126 29460 sgd_solver.cpp:106] Iteration 50250, lr = 0.0045
I0525 22:21:19.263949 29460 solver.cpp:237] Iteration 50400, loss = 1.24013
I0525 22:21:19.263988 29460 solver.cpp:253]     Train net output #0: loss = 1.24013 (* 1 = 1.24013 loss)
I0525 22:21:19.264008 29460 sgd_solver.cpp:106] Iteration 50400, lr = 0.0045
I0525 22:21:27.997335 29460 solver.cpp:237] Iteration 50550, loss = 0.857634
I0525 22:21:27.997390 29460 solver.cpp:253]     Train net output #0: loss = 0.857634 (* 1 = 0.857634 loss)
I0525 22:21:27.997416 29460 sgd_solver.cpp:106] Iteration 50550, lr = 0.0045
I0525 22:21:36.735024 29460 solver.cpp:237] Iteration 50700, loss = 1.11081
I0525 22:21:36.735198 29460 solver.cpp:253]     Train net output #0: loss = 1.11081 (* 1 = 1.11081 loss)
I0525 22:21:36.735216 29460 sgd_solver.cpp:106] Iteration 50700, lr = 0.0045
I0525 22:21:45.472425 29460 solver.cpp:237] Iteration 50850, loss = 1.05907
I0525 22:21:45.472462 29460 solver.cpp:253]     Train net output #0: loss = 1.05907 (* 1 = 1.05907 loss)
I0525 22:21:45.472487 29460 sgd_solver.cpp:106] Iteration 50850, lr = 0.0045
I0525 22:21:54.152709 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_51000.caffemodel
I0525 22:21:54.233302 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_51000.solverstate
I0525 22:21:54.260362 29460 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 22:22:41.162786 29460 solver.cpp:409]     Test net output #0: accuracy = 0.892388
I0525 22:22:41.162986 29460 solver.cpp:409]     Test net output #1: loss = 0.364736 (* 1 = 0.364736 loss)
I0525 22:23:02.080009 29460 solver.cpp:237] Iteration 51000, loss = 1.1032
I0525 22:23:02.080071 29460 solver.cpp:253]     Train net output #0: loss = 1.1032 (* 1 = 1.1032 loss)
I0525 22:23:02.080104 29460 sgd_solver.cpp:106] Iteration 51000, lr = 0.0045
I0525 22:23:10.832476 29460 solver.cpp:237] Iteration 51150, loss = 1.05861
I0525 22:23:10.832515 29460 solver.cpp:253]     Train net output #0: loss = 1.05861 (* 1 = 1.05861 loss)
I0525 22:23:10.832540 29460 sgd_solver.cpp:106] Iteration 51150, lr = 0.0045
I0525 22:23:19.580000 29460 solver.cpp:237] Iteration 51300, loss = 1.07536
I0525 22:23:19.580181 29460 solver.cpp:253]     Train net output #0: loss = 1.07536 (* 1 = 1.07536 loss)
I0525 22:23:19.580199 29460 sgd_solver.cpp:106] Iteration 51300, lr = 0.0045
I0525 22:23:28.335973 29460 solver.cpp:237] Iteration 51450, loss = 1.17865
I0525 22:23:28.336027 29460 solver.cpp:253]     Train net output #0: loss = 1.17865 (* 1 = 1.17865 loss)
I0525 22:23:28.336055 29460 sgd_solver.cpp:106] Iteration 51450, lr = 0.0045
I0525 22:23:37.088768 29460 solver.cpp:237] Iteration 51600, loss = 1.17101
I0525 22:23:37.088810 29460 solver.cpp:253]     Train net output #0: loss = 1.17101 (* 1 = 1.17101 loss)
I0525 22:23:37.088835 29460 sgd_solver.cpp:106] Iteration 51600, lr = 0.0045
I0525 22:23:45.841907 29460 solver.cpp:237] Iteration 51750, loss = 1.18583
I0525 22:23:45.841943 29460 solver.cpp:253]     Train net output #0: loss = 1.18583 (* 1 = 1.18583 loss)
I0525 22:23:45.841970 29460 sgd_solver.cpp:106] Iteration 51750, lr = 0.0045
I0525 22:23:54.590490 29460 solver.cpp:237] Iteration 51900, loss = 1.4176
I0525 22:23:54.590678 29460 solver.cpp:253]     Train net output #0: loss = 1.4176 (* 1 = 1.4176 loss)
I0525 22:23:54.590697 29460 sgd_solver.cpp:106] Iteration 51900, lr = 0.0045
I0525 22:24:24.203276 29460 solver.cpp:237] Iteration 52050, loss = 1.21694
I0525 22:24:24.203332 29460 solver.cpp:253]     Train net output #0: loss = 1.21694 (* 1 = 1.21694 loss)
I0525 22:24:24.203358 29460 sgd_solver.cpp:106] Iteration 52050, lr = 0.0045
I0525 22:24:32.957674 29460 solver.cpp:237] Iteration 52200, loss = 1.0501
I0525 22:24:32.957852 29460 solver.cpp:253]     Train net output #0: loss = 1.0501 (* 1 = 1.0501 loss)
I0525 22:24:32.957870 29460 sgd_solver.cpp:106] Iteration 52200, lr = 0.0045
I0525 22:24:41.705168 29460 solver.cpp:237] Iteration 52350, loss = 1.09773
I0525 22:24:41.705220 29460 solver.cpp:253]     Train net output #0: loss = 1.09773 (* 1 = 1.09773 loss)
I0525 22:24:41.705247 29460 sgd_solver.cpp:106] Iteration 52350, lr = 0.0045
I0525 22:24:50.399015 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_52500.caffemodel
I0525 22:24:50.480237 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_52500.solverstate
I0525 22:24:50.526720 29460 solver.cpp:237] Iteration 52500, loss = 1.09777
I0525 22:24:50.526775 29460 solver.cpp:253]     Train net output #0: loss = 1.09777 (* 1 = 1.09777 loss)
I0525 22:24:50.526793 29460 sgd_solver.cpp:106] Iteration 52500, lr = 0.0045
I0525 22:24:59.275900 29460 solver.cpp:237] Iteration 52650, loss = 1.11775
I0525 22:24:59.275938 29460 solver.cpp:253]     Train net output #0: loss = 1.11775 (* 1 = 1.11775 loss)
I0525 22:24:59.275962 29460 sgd_solver.cpp:106] Iteration 52650, lr = 0.0045
I0525 22:25:08.024330 29460 solver.cpp:237] Iteration 52800, loss = 1.07788
I0525 22:25:08.024541 29460 solver.cpp:253]     Train net output #0: loss = 1.07788 (* 1 = 1.07788 loss)
I0525 22:25:08.024559 29460 sgd_solver.cpp:106] Iteration 52800, lr = 0.0045
I0525 22:25:16.771008 29460 solver.cpp:237] Iteration 52950, loss = 0.952221
I0525 22:25:16.771046 29460 solver.cpp:253]     Train net output #0: loss = 0.952221 (* 1 = 0.952221 loss)
I0525 22:25:16.771071 29460 sgd_solver.cpp:106] Iteration 52950, lr = 0.0045
I0525 22:25:46.373517 29460 solver.cpp:237] Iteration 53100, loss = 1.34073
I0525 22:25:46.373714 29460 solver.cpp:253]     Train net output #0: loss = 1.34073 (* 1 = 1.34073 loss)
I0525 22:25:46.373733 29460 sgd_solver.cpp:106] Iteration 53100, lr = 0.0045
I0525 22:25:55.117880 29460 solver.cpp:237] Iteration 53250, loss = 1.21765
I0525 22:25:55.117918 29460 solver.cpp:253]     Train net output #0: loss = 1.21765 (* 1 = 1.21765 loss)
I0525 22:25:55.117943 29460 sgd_solver.cpp:106] Iteration 53250, lr = 0.0045
I0525 22:26:03.867581 29460 solver.cpp:237] Iteration 53400, loss = 1.17189
I0525 22:26:03.867631 29460 solver.cpp:253]     Train net output #0: loss = 1.17189 (* 1 = 1.17189 loss)
I0525 22:26:03.867648 29460 sgd_solver.cpp:106] Iteration 53400, lr = 0.0045
I0525 22:26:12.619742 29460 solver.cpp:237] Iteration 53550, loss = 1.20835
I0525 22:26:12.619778 29460 solver.cpp:253]     Train net output #0: loss = 1.20835 (* 1 = 1.20835 loss)
I0525 22:26:12.619804 29460 sgd_solver.cpp:106] Iteration 53550, lr = 0.0045
I0525 22:26:21.369437 29460 solver.cpp:237] Iteration 53700, loss = 1.28442
I0525 22:26:21.369621 29460 solver.cpp:253]     Train net output #0: loss = 1.28442 (* 1 = 1.28442 loss)
I0525 22:26:21.369639 29460 sgd_solver.cpp:106] Iteration 53700, lr = 0.0045
I0525 22:26:30.120690 29460 solver.cpp:237] Iteration 53850, loss = 0.989551
I0525 22:26:30.120729 29460 solver.cpp:253]     Train net output #0: loss = 0.989551 (* 1 = 0.989551 loss)
I0525 22:26:30.120750 29460 sgd_solver.cpp:106] Iteration 53850, lr = 0.0045
I0525 22:26:38.812968 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_54000.caffemodel
I0525 22:26:38.893643 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_54000.solverstate
I0525 22:26:38.924687 29460 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 22:27:46.706181 29460 solver.cpp:409]     Test net output #0: accuracy = 0.893969
I0525 22:27:46.706374 29460 solver.cpp:409]     Test net output #1: loss = 0.341738 (* 1 = 0.341738 loss)
I0525 22:28:07.577571 29460 solver.cpp:237] Iteration 54000, loss = 1.13537
I0525 22:28:07.577631 29460 solver.cpp:253]     Train net output #0: loss = 1.13537 (* 1 = 1.13537 loss)
I0525 22:28:07.577651 29460 sgd_solver.cpp:106] Iteration 54000, lr = 0.0045
I0525 22:28:16.312062 29460 solver.cpp:237] Iteration 54150, loss = 1.04669
I0525 22:28:16.312101 29460 solver.cpp:253]     Train net output #0: loss = 1.04669 (* 1 = 1.04669 loss)
I0525 22:28:16.312121 29460 sgd_solver.cpp:106] Iteration 54150, lr = 0.0045
I0525 22:28:25.048764 29460 solver.cpp:237] Iteration 54300, loss = 1.12952
I0525 22:28:25.048957 29460 solver.cpp:253]     Train net output #0: loss = 1.12952 (* 1 = 1.12952 loss)
I0525 22:28:25.048974 29460 sgd_solver.cpp:106] Iteration 54300, lr = 0.0045
I0525 22:28:33.779933 29460 solver.cpp:237] Iteration 54450, loss = 1.07052
I0525 22:28:33.779979 29460 solver.cpp:253]     Train net output #0: loss = 1.07052 (* 1 = 1.07052 loss)
I0525 22:28:33.779997 29460 sgd_solver.cpp:106] Iteration 54450, lr = 0.0045
I0525 22:28:42.514225 29460 solver.cpp:237] Iteration 54600, loss = 1.4366
I0525 22:28:42.514259 29460 solver.cpp:253]     Train net output #0: loss = 1.4366 (* 1 = 1.4366 loss)
I0525 22:28:42.514284 29460 sgd_solver.cpp:106] Iteration 54600, lr = 0.0045
I0525 22:28:51.251091 29460 solver.cpp:237] Iteration 54750, loss = 1.18517
I0525 22:28:51.251128 29460 solver.cpp:253]     Train net output #0: loss = 1.18517 (* 1 = 1.18517 loss)
I0525 22:28:51.251152 29460 sgd_solver.cpp:106] Iteration 54750, lr = 0.0045
I0525 22:28:59.983521 29460 solver.cpp:237] Iteration 54900, loss = 1.10036
I0525 22:28:59.983721 29460 solver.cpp:253]     Train net output #0: loss = 1.10036 (* 1 = 1.10036 loss)
I0525 22:28:59.983739 29460 sgd_solver.cpp:106] Iteration 54900, lr = 0.0045
I0525 22:29:29.553202 29460 solver.cpp:237] Iteration 55050, loss = 1.25487
I0525 22:29:29.553258 29460 solver.cpp:253]     Train net output #0: loss = 1.25487 (* 1 = 1.25487 loss)
I0525 22:29:29.553278 29460 sgd_solver.cpp:106] Iteration 55050, lr = 0.0045
I0525 22:29:38.289774 29460 solver.cpp:237] Iteration 55200, loss = 1.20168
I0525 22:29:38.289954 29460 solver.cpp:253]     Train net output #0: loss = 1.20168 (* 1 = 1.20168 loss)
I0525 22:29:38.289970 29460 sgd_solver.cpp:106] Iteration 55200, lr = 0.0045
I0525 22:29:47.022922 29460 solver.cpp:237] Iteration 55350, loss = 1.06638
I0525 22:29:47.022975 29460 solver.cpp:253]     Train net output #0: loss = 1.06638 (* 1 = 1.06638 loss)
I0525 22:29:47.022992 29460 sgd_solver.cpp:106] Iteration 55350, lr = 0.0045
I0525 22:29:55.699210 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_55500.caffemodel
I0525 22:29:55.777935 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_55500.solverstate
I0525 22:29:55.821709 29460 solver.cpp:237] Iteration 55500, loss = 1.16691
I0525 22:29:55.821763 29460 solver.cpp:253]     Train net output #0: loss = 1.16691 (* 1 = 1.16691 loss)
I0525 22:29:55.821780 29460 sgd_solver.cpp:106] Iteration 55500, lr = 0.0045
I0525 22:30:04.551888 29460 solver.cpp:237] Iteration 55650, loss = 1.17675
I0525 22:30:04.551926 29460 solver.cpp:253]     Train net output #0: loss = 1.17675 (* 1 = 1.17675 loss)
I0525 22:30:04.551951 29460 sgd_solver.cpp:106] Iteration 55650, lr = 0.0045
I0525 22:30:13.288826 29460 solver.cpp:237] Iteration 55800, loss = 1.02439
I0525 22:30:13.289018 29460 solver.cpp:253]     Train net output #0: loss = 1.02439 (* 1 = 1.02439 loss)
I0525 22:30:13.289036 29460 sgd_solver.cpp:106] Iteration 55800, lr = 0.0045
I0525 22:30:22.028314 29460 solver.cpp:237] Iteration 55950, loss = 1.09036
I0525 22:30:22.028352 29460 solver.cpp:253]     Train net output #0: loss = 1.09036 (* 1 = 1.09036 loss)
I0525 22:30:22.028376 29460 sgd_solver.cpp:106] Iteration 55950, lr = 0.0045
I0525 22:30:51.621897 29460 solver.cpp:237] Iteration 56100, loss = 1.27915
I0525 22:30:51.622093 29460 solver.cpp:253]     Train net output #0: loss = 1.27915 (* 1 = 1.27915 loss)
I0525 22:30:51.622110 29460 sgd_solver.cpp:106] Iteration 56100, lr = 0.0045
I0525 22:31:00.353904 29460 solver.cpp:237] Iteration 56250, loss = 1.2024
I0525 22:31:00.353957 29460 solver.cpp:253]     Train net output #0: loss = 1.2024 (* 1 = 1.2024 loss)
I0525 22:31:00.353977 29460 sgd_solver.cpp:106] Iteration 56250, lr = 0.0045
I0525 22:31:09.087263 29460 solver.cpp:237] Iteration 56400, loss = 1.1323
I0525 22:31:09.087301 29460 solver.cpp:253]     Train net output #0: loss = 1.1323 (* 1 = 1.1323 loss)
I0525 22:31:09.087326 29460 sgd_solver.cpp:106] Iteration 56400, lr = 0.0045
I0525 22:31:17.815577 29460 solver.cpp:237] Iteration 56550, loss = 1.26803
I0525 22:31:17.815615 29460 solver.cpp:253]     Train net output #0: loss = 1.26803 (* 1 = 1.26803 loss)
I0525 22:31:17.815634 29460 sgd_solver.cpp:106] Iteration 56550, lr = 0.0045
I0525 22:31:26.548159 29460 solver.cpp:237] Iteration 56700, loss = 1.2454
I0525 22:31:26.548357 29460 solver.cpp:253]     Train net output #0: loss = 1.2454 (* 1 = 1.2454 loss)
I0525 22:31:26.548377 29460 sgd_solver.cpp:106] Iteration 56700, lr = 0.0045
I0525 22:31:35.281988 29460 solver.cpp:237] Iteration 56850, loss = 1.26284
I0525 22:31:35.282026 29460 solver.cpp:253]     Train net output #0: loss = 1.26284 (* 1 = 1.26284 loss)
I0525 22:31:35.282050 29460 sgd_solver.cpp:106] Iteration 56850, lr = 0.0045
I0525 22:31:43.951614 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_57000.caffemodel
I0525 22:31:44.030331 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_57000.solverstate
I0525 22:31:44.056151 29460 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 22:32:30.595405 29460 solver.cpp:409]     Test net output #0: accuracy = 0.894423
I0525 22:32:30.595602 29460 solver.cpp:409]     Test net output #1: loss = 0.33496 (* 1 = 0.33496 loss)
I0525 22:32:51.489001 29460 solver.cpp:237] Iteration 57000, loss = 1.06876
I0525 22:32:51.489058 29460 solver.cpp:253]     Train net output #0: loss = 1.06876 (* 1 = 1.06876 loss)
I0525 22:32:51.489076 29460 sgd_solver.cpp:106] Iteration 57000, lr = 0.0045
I0525 22:33:00.222862 29460 solver.cpp:237] Iteration 57150, loss = 1.04171
I0525 22:33:00.222900 29460 solver.cpp:253]     Train net output #0: loss = 1.04171 (* 1 = 1.04171 loss)
I0525 22:33:00.222920 29460 sgd_solver.cpp:106] Iteration 57150, lr = 0.0045
I0525 22:33:08.961279 29460 solver.cpp:237] Iteration 57300, loss = 1.1298
I0525 22:33:08.961472 29460 solver.cpp:253]     Train net output #0: loss = 1.1298 (* 1 = 1.1298 loss)
I0525 22:33:08.961490 29460 sgd_solver.cpp:106] Iteration 57300, lr = 0.0045
I0525 22:33:17.700350 29460 solver.cpp:237] Iteration 57450, loss = 1.25069
I0525 22:33:17.700387 29460 solver.cpp:253]     Train net output #0: loss = 1.25069 (* 1 = 1.25069 loss)
I0525 22:33:17.700407 29460 sgd_solver.cpp:106] Iteration 57450, lr = 0.0045
I0525 22:33:26.442579 29460 solver.cpp:237] Iteration 57600, loss = 1.14663
I0525 22:33:26.442636 29460 solver.cpp:253]     Train net output #0: loss = 1.14663 (* 1 = 1.14663 loss)
I0525 22:33:26.442663 29460 sgd_solver.cpp:106] Iteration 57600, lr = 0.0045
I0525 22:33:35.181038 29460 solver.cpp:237] Iteration 57750, loss = 1.09428
I0525 22:33:35.181076 29460 solver.cpp:253]     Train net output #0: loss = 1.09428 (* 1 = 1.09428 loss)
I0525 22:33:35.181100 29460 sgd_solver.cpp:106] Iteration 57750, lr = 0.0045
I0525 22:33:43.911597 29460 solver.cpp:237] Iteration 57900, loss = 0.829027
I0525 22:33:43.911775 29460 solver.cpp:253]     Train net output #0: loss = 0.829027 (* 1 = 0.829027 loss)
I0525 22:33:43.911792 29460 sgd_solver.cpp:106] Iteration 57900, lr = 0.0045
I0525 22:34:13.487700 29460 solver.cpp:237] Iteration 58050, loss = 1.02948
I0525 22:34:13.487756 29460 solver.cpp:253]     Train net output #0: loss = 1.02948 (* 1 = 1.02948 loss)
I0525 22:34:13.487774 29460 sgd_solver.cpp:106] Iteration 58050, lr = 0.0045
I0525 22:34:22.222748 29460 solver.cpp:237] Iteration 58200, loss = 1.06858
I0525 22:34:22.222942 29460 solver.cpp:253]     Train net output #0: loss = 1.06858 (* 1 = 1.06858 loss)
I0525 22:34:22.222962 29460 sgd_solver.cpp:106] Iteration 58200, lr = 0.0045
I0525 22:34:30.962502 29460 solver.cpp:237] Iteration 58350, loss = 1.07491
I0525 22:34:30.962540 29460 solver.cpp:253]     Train net output #0: loss = 1.07491 (* 1 = 1.07491 loss)
I0525 22:34:30.962565 29460 sgd_solver.cpp:106] Iteration 58350, lr = 0.0045
I0525 22:34:39.637913 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_58500.caffemodel
I0525 22:34:39.717922 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_58500.solverstate
I0525 22:34:39.762823 29460 solver.cpp:237] Iteration 58500, loss = 1.24675
I0525 22:34:39.762883 29460 solver.cpp:253]     Train net output #0: loss = 1.24675 (* 1 = 1.24675 loss)
I0525 22:34:39.762902 29460 sgd_solver.cpp:106] Iteration 58500, lr = 0.0045
I0525 22:34:48.499393 29460 solver.cpp:237] Iteration 58650, loss = 1.15273
I0525 22:34:48.499447 29460 solver.cpp:253]     Train net output #0: loss = 1.15273 (* 1 = 1.15273 loss)
I0525 22:34:48.499469 29460 sgd_solver.cpp:106] Iteration 58650, lr = 0.0045
I0525 22:34:57.234998 29460 solver.cpp:237] Iteration 58800, loss = 1.44533
I0525 22:34:57.235190 29460 solver.cpp:253]     Train net output #0: loss = 1.44533 (* 1 = 1.44533 loss)
I0525 22:34:57.235208 29460 sgd_solver.cpp:106] Iteration 58800, lr = 0.0045
I0525 22:35:05.969034 29460 solver.cpp:237] Iteration 58950, loss = 0.994994
I0525 22:35:05.969076 29460 solver.cpp:253]     Train net output #0: loss = 0.994994 (* 1 = 0.994994 loss)
I0525 22:35:05.969094 29460 sgd_solver.cpp:106] Iteration 58950, lr = 0.0045
I0525 22:35:35.571687 29460 solver.cpp:237] Iteration 59100, loss = 0.981241
I0525 22:35:35.571887 29460 solver.cpp:253]     Train net output #0: loss = 0.981241 (* 1 = 0.981241 loss)
I0525 22:35:35.571904 29460 sgd_solver.cpp:106] Iteration 59100, lr = 0.0045
I0525 22:35:44.310822 29460 solver.cpp:237] Iteration 59250, loss = 1.09363
I0525 22:35:44.310858 29460 solver.cpp:253]     Train net output #0: loss = 1.09363 (* 1 = 1.09363 loss)
I0525 22:35:44.310884 29460 sgd_solver.cpp:106] Iteration 59250, lr = 0.0045
I0525 22:35:53.051091 29460 solver.cpp:237] Iteration 59400, loss = 1.01981
I0525 22:35:53.051129 29460 solver.cpp:253]     Train net output #0: loss = 1.01981 (* 1 = 1.01981 loss)
I0525 22:35:53.051154 29460 sgd_solver.cpp:106] Iteration 59400, lr = 0.0045
I0525 22:36:01.796464 29460 solver.cpp:237] Iteration 59550, loss = 1.20389
I0525 22:36:01.796519 29460 solver.cpp:253]     Train net output #0: loss = 1.20389 (* 1 = 1.20389 loss)
I0525 22:36:01.796538 29460 sgd_solver.cpp:106] Iteration 59550, lr = 0.0045
I0525 22:36:10.532780 29460 solver.cpp:237] Iteration 59700, loss = 1.25976
I0525 22:36:10.532960 29460 solver.cpp:253]     Train net output #0: loss = 1.25976 (* 1 = 1.25976 loss)
I0525 22:36:10.532977 29460 sgd_solver.cpp:106] Iteration 59700, lr = 0.0045
I0525 22:36:19.259737 29460 solver.cpp:237] Iteration 59850, loss = 1.12099
I0525 22:36:19.259775 29460 solver.cpp:253]     Train net output #0: loss = 1.12099 (* 1 = 1.12099 loss)
I0525 22:36:19.259795 29460 sgd_solver.cpp:106] Iteration 59850, lr = 0.0045
I0525 22:36:27.933547 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_60000.caffemodel
I0525 22:36:28.015775 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_60000.solverstate
I0525 22:36:28.043089 29460 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 22:37:35.775271 29460 solver.cpp:409]     Test net output #0: accuracy = 0.890009
I0525 22:37:35.775466 29460 solver.cpp:409]     Test net output #1: loss = 0.354343 (* 1 = 0.354343 loss)
I0525 22:37:56.662683 29460 solver.cpp:237] Iteration 60000, loss = 1.27699
I0525 22:37:56.662741 29460 solver.cpp:253]     Train net output #0: loss = 1.27699 (* 1 = 1.27699 loss)
I0525 22:37:56.662760 29460 sgd_solver.cpp:106] Iteration 60000, lr = 0.0045
I0525 22:38:05.396908 29460 solver.cpp:237] Iteration 60150, loss = 0.920145
I0525 22:38:05.396961 29460 solver.cpp:253]     Train net output #0: loss = 0.920145 (* 1 = 0.920145 loss)
I0525 22:38:05.396980 29460 sgd_solver.cpp:106] Iteration 60150, lr = 0.0045
I0525 22:38:14.127624 29460 solver.cpp:237] Iteration 60300, loss = 1.11937
I0525 22:38:14.127815 29460 solver.cpp:253]     Train net output #0: loss = 1.11937 (* 1 = 1.11937 loss)
I0525 22:38:14.127832 29460 sgd_solver.cpp:106] Iteration 60300, lr = 0.0045
I0525 22:38:22.858500 29460 solver.cpp:237] Iteration 60450, loss = 1.08173
I0525 22:38:22.858536 29460 solver.cpp:253]     Train net output #0: loss = 1.08173 (* 1 = 1.08173 loss)
I0525 22:38:22.858561 29460 sgd_solver.cpp:106] Iteration 60450, lr = 0.0045
I0525 22:38:31.590714 29460 solver.cpp:237] Iteration 60600, loss = 1.13875
I0525 22:38:31.590770 29460 solver.cpp:253]     Train net output #0: loss = 1.13875 (* 1 = 1.13875 loss)
I0525 22:38:31.590796 29460 sgd_solver.cpp:106] Iteration 60600, lr = 0.0045
I0525 22:38:40.317665 29460 solver.cpp:237] Iteration 60750, loss = 0.988092
I0525 22:38:40.317703 29460 solver.cpp:253]     Train net output #0: loss = 0.988092 (* 1 = 0.988092 loss)
I0525 22:38:40.317728 29460 sgd_solver.cpp:106] Iteration 60750, lr = 0.0045
I0525 22:38:49.049278 29460 solver.cpp:237] Iteration 60900, loss = 1.3022
I0525 22:38:49.049459 29460 solver.cpp:253]     Train net output #0: loss = 1.3022 (* 1 = 1.3022 loss)
I0525 22:38:49.049476 29460 sgd_solver.cpp:106] Iteration 60900, lr = 0.0045
I0525 22:39:18.655866 29460 solver.cpp:237] Iteration 61050, loss = 1.25696
I0525 22:39:18.655922 29460 solver.cpp:253]     Train net output #0: loss = 1.25696 (* 1 = 1.25696 loss)
I0525 22:39:18.655943 29460 sgd_solver.cpp:106] Iteration 61050, lr = 0.0045
I0525 22:39:27.385613 29460 solver.cpp:237] Iteration 61200, loss = 1.10964
I0525 22:39:27.385795 29460 solver.cpp:253]     Train net output #0: loss = 1.10964 (* 1 = 1.10964 loss)
I0525 22:39:27.385813 29460 sgd_solver.cpp:106] Iteration 61200, lr = 0.0045
I0525 22:39:36.120414 29460 solver.cpp:237] Iteration 61350, loss = 1.00467
I0525 22:39:36.120450 29460 solver.cpp:253]     Train net output #0: loss = 1.00467 (* 1 = 1.00467 loss)
I0525 22:39:36.120474 29460 sgd_solver.cpp:106] Iteration 61350, lr = 0.0045
I0525 22:39:44.792348 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_61500.caffemodel
I0525 22:39:44.871662 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_61500.solverstate
I0525 22:39:44.915149 29460 solver.cpp:237] Iteration 61500, loss = 1.03107
I0525 22:39:44.915204 29460 solver.cpp:253]     Train net output #0: loss = 1.03107 (* 1 = 1.03107 loss)
I0525 22:39:44.915221 29460 sgd_solver.cpp:106] Iteration 61500, lr = 0.0045
I0525 22:39:53.643970 29460 solver.cpp:237] Iteration 61650, loss = 1.37312
I0525 22:39:53.644007 29460 solver.cpp:253]     Train net output #0: loss = 1.37312 (* 1 = 1.37312 loss)
I0525 22:39:53.644032 29460 sgd_solver.cpp:106] Iteration 61650, lr = 0.0045
I0525 22:40:02.371057 29460 solver.cpp:237] Iteration 61800, loss = 1.09235
I0525 22:40:02.371237 29460 solver.cpp:253]     Train net output #0: loss = 1.09235 (* 1 = 1.09235 loss)
I0525 22:40:02.371254 29460 sgd_solver.cpp:106] Iteration 61800, lr = 0.0045
I0525 22:40:11.097678 29460 solver.cpp:237] Iteration 61950, loss = 1.15329
I0525 22:40:11.097731 29460 solver.cpp:253]     Train net output #0: loss = 1.15329 (* 1 = 1.15329 loss)
I0525 22:40:11.097757 29460 sgd_solver.cpp:106] Iteration 61950, lr = 0.0045
I0525 22:40:40.693217 29460 solver.cpp:237] Iteration 62100, loss = 1.09661
I0525 22:40:40.693416 29460 solver.cpp:253]     Train net output #0: loss = 1.09661 (* 1 = 1.09661 loss)
I0525 22:40:40.693437 29460 sgd_solver.cpp:106] Iteration 62100, lr = 0.0045
I0525 22:40:49.414392 29460 solver.cpp:237] Iteration 62250, loss = 1.05011
I0525 22:40:49.414432 29460 solver.cpp:253]     Train net output #0: loss = 1.05011 (* 1 = 1.05011 loss)
I0525 22:40:49.414450 29460 sgd_solver.cpp:106] Iteration 62250, lr = 0.0045
I0525 22:40:58.141402 29460 solver.cpp:237] Iteration 62400, loss = 1.22851
I0525 22:40:58.141454 29460 solver.cpp:253]     Train net output #0: loss = 1.22851 (* 1 = 1.22851 loss)
I0525 22:40:58.141481 29460 sgd_solver.cpp:106] Iteration 62400, lr = 0.0045
I0525 22:41:06.870151 29460 solver.cpp:237] Iteration 62550, loss = 1.08287
I0525 22:41:06.870188 29460 solver.cpp:253]     Train net output #0: loss = 1.08287 (* 1 = 1.08287 loss)
I0525 22:41:06.870213 29460 sgd_solver.cpp:106] Iteration 62550, lr = 0.0045
I0525 22:41:15.590921 29460 solver.cpp:237] Iteration 62700, loss = 1.05243
I0525 22:41:15.591114 29460 solver.cpp:253]     Train net output #0: loss = 1.05243 (* 1 = 1.05243 loss)
I0525 22:41:15.591130 29460 sgd_solver.cpp:106] Iteration 62700, lr = 0.0045
I0525 22:41:24.315943 29460 solver.cpp:237] Iteration 62850, loss = 1.01918
I0525 22:41:24.315995 29460 solver.cpp:253]     Train net output #0: loss = 1.01918 (* 1 = 1.01918 loss)
I0525 22:41:24.316014 29460 sgd_solver.cpp:106] Iteration 62850, lr = 0.0045
I0525 22:41:32.979162 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_63000.caffemodel
I0525 22:41:33.058094 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_63000.solverstate
I0525 22:41:33.083765 29460 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 22:42:19.959911 29460 solver.cpp:409]     Test net output #0: accuracy = 0.896322
I0525 22:42:19.960113 29460 solver.cpp:409]     Test net output #1: loss = 0.341051 (* 1 = 0.341051 loss)
I0525 22:42:40.824275 29460 solver.cpp:237] Iteration 63000, loss = 1.02612
I0525 22:42:40.824334 29460 solver.cpp:253]     Train net output #0: loss = 1.02612 (* 1 = 1.02612 loss)
I0525 22:42:40.824352 29460 sgd_solver.cpp:106] Iteration 63000, lr = 0.0045
I0525 22:42:49.559891 29460 solver.cpp:237] Iteration 63150, loss = 1.19577
I0525 22:42:49.559928 29460 solver.cpp:253]     Train net output #0: loss = 1.19577 (* 1 = 1.19577 loss)
I0525 22:42:49.559953 29460 sgd_solver.cpp:106] Iteration 63150, lr = 0.0045
I0525 22:42:58.295526 29460 solver.cpp:237] Iteration 63300, loss = 1.02786
I0525 22:42:58.295711 29460 solver.cpp:253]     Train net output #0: loss = 1.02786 (* 1 = 1.02786 loss)
I0525 22:42:58.295727 29460 sgd_solver.cpp:106] Iteration 63300, lr = 0.0045
I0525 22:43:07.038311 29460 solver.cpp:237] Iteration 63450, loss = 1.16529
I0525 22:43:07.038364 29460 solver.cpp:253]     Train net output #0: loss = 1.16529 (* 1 = 1.16529 loss)
I0525 22:43:07.038395 29460 sgd_solver.cpp:106] Iteration 63450, lr = 0.0045
I0525 22:43:15.777309 29460 solver.cpp:237] Iteration 63600, loss = 1.12019
I0525 22:43:15.777346 29460 solver.cpp:253]     Train net output #0: loss = 1.12019 (* 1 = 1.12019 loss)
I0525 22:43:15.777371 29460 sgd_solver.cpp:106] Iteration 63600, lr = 0.0045
I0525 22:43:24.508888 29460 solver.cpp:237] Iteration 63750, loss = 1.22364
I0525 22:43:24.508925 29460 solver.cpp:253]     Train net output #0: loss = 1.22364 (* 1 = 1.22364 loss)
I0525 22:43:24.508949 29460 sgd_solver.cpp:106] Iteration 63750, lr = 0.0045
I0525 22:43:33.249482 29460 solver.cpp:237] Iteration 63900, loss = 1.00585
I0525 22:43:33.249677 29460 solver.cpp:253]     Train net output #0: loss = 1.00585 (* 1 = 1.00585 loss)
I0525 22:43:33.249698 29460 sgd_solver.cpp:106] Iteration 63900, lr = 0.0045
I0525 22:44:02.843405 29460 solver.cpp:237] Iteration 64050, loss = 1.22272
I0525 22:44:02.843461 29460 solver.cpp:253]     Train net output #0: loss = 1.22272 (* 1 = 1.22272 loss)
I0525 22:44:02.843480 29460 sgd_solver.cpp:106] Iteration 64050, lr = 0.0045
I0525 22:44:11.577402 29460 solver.cpp:237] Iteration 64200, loss = 1.101
I0525 22:44:11.577587 29460 solver.cpp:253]     Train net output #0: loss = 1.101 (* 1 = 1.101 loss)
I0525 22:44:11.577605 29460 sgd_solver.cpp:106] Iteration 64200, lr = 0.0045
I0525 22:44:20.314446 29460 solver.cpp:237] Iteration 64350, loss = 1.26192
I0525 22:44:20.314499 29460 solver.cpp:253]     Train net output #0: loss = 1.26192 (* 1 = 1.26192 loss)
I0525 22:44:20.314517 29460 sgd_solver.cpp:106] Iteration 64350, lr = 0.0045
I0525 22:44:28.998805 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_64500.caffemodel
I0525 22:44:29.077234 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_64500.solverstate
I0525 22:44:29.120452 29460 solver.cpp:237] Iteration 64500, loss = 1.07116
I0525 22:44:29.120507 29460 solver.cpp:253]     Train net output #0: loss = 1.07116 (* 1 = 1.07116 loss)
I0525 22:44:29.120525 29460 sgd_solver.cpp:106] Iteration 64500, lr = 0.0045
I0525 22:44:37.851464 29460 solver.cpp:237] Iteration 64650, loss = 1.18168
I0525 22:44:37.851503 29460 solver.cpp:253]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0525 22:44:37.851523 29460 sgd_solver.cpp:106] Iteration 64650, lr = 0.0045
I0525 22:44:46.589931 29460 solver.cpp:237] Iteration 64800, loss = 1.06271
I0525 22:44:46.590138 29460 solver.cpp:253]     Train net output #0: loss = 1.06271 (* 1 = 1.06271 loss)
I0525 22:44:46.590164 29460 sgd_solver.cpp:106] Iteration 64800, lr = 0.0045
I0525 22:44:55.327033 29460 solver.cpp:237] Iteration 64950, loss = 1.12836
I0525 22:44:55.327074 29460 solver.cpp:253]     Train net output #0: loss = 1.12836 (* 1 = 1.12836 loss)
I0525 22:44:55.327092 29460 sgd_solver.cpp:106] Iteration 64950, lr = 0.0045
I0525 22:45:24.939003 29460 solver.cpp:237] Iteration 65100, loss = 1.01428
I0525 22:45:24.939205 29460 solver.cpp:253]     Train net output #0: loss = 1.01428 (* 1 = 1.01428 loss)
I0525 22:45:24.939224 29460 sgd_solver.cpp:106] Iteration 65100, lr = 0.0045
I0525 22:45:33.675273 29460 solver.cpp:237] Iteration 65250, loss = 1.27357
I0525 22:45:33.675326 29460 solver.cpp:253]     Train net output #0: loss = 1.27357 (* 1 = 1.27357 loss)
I0525 22:45:33.675354 29460 sgd_solver.cpp:106] Iteration 65250, lr = 0.0045
I0525 22:45:42.412262 29460 solver.cpp:237] Iteration 65400, loss = 1.11669
I0525 22:45:42.412299 29460 solver.cpp:253]     Train net output #0: loss = 1.11669 (* 1 = 1.11669 loss)
I0525 22:45:42.412324 29460 sgd_solver.cpp:106] Iteration 65400, lr = 0.0045
I0525 22:45:51.146234 29460 solver.cpp:237] Iteration 65550, loss = 1.04283
I0525 22:45:51.146272 29460 solver.cpp:253]     Train net output #0: loss = 1.04283 (* 1 = 1.04283 loss)
I0525 22:45:51.146296 29460 sgd_solver.cpp:106] Iteration 65550, lr = 0.0045
I0525 22:45:59.887670 29460 solver.cpp:237] Iteration 65700, loss = 1.19482
I0525 22:45:59.887866 29460 solver.cpp:253]     Train net output #0: loss = 1.19482 (* 1 = 1.19482 loss)
I0525 22:45:59.887883 29460 sgd_solver.cpp:106] Iteration 65700, lr = 0.0045
I0525 22:46:08.624105 29460 solver.cpp:237] Iteration 65850, loss = 1.21928
I0525 22:46:08.624141 29460 solver.cpp:253]     Train net output #0: loss = 1.21928 (* 1 = 1.21928 loss)
I0525 22:46:08.624166 29460 sgd_solver.cpp:106] Iteration 65850, lr = 0.0045
I0525 22:46:17.299172 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_66000.caffemodel
I0525 22:46:17.379003 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_66000.solverstate
I0525 22:46:17.405966 29460 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 22:47:25.211033 29460 solver.cpp:409]     Test net output #0: accuracy = 0.897423
I0525 22:47:25.211232 29460 solver.cpp:409]     Test net output #1: loss = 0.358164 (* 1 = 0.358164 loss)
I0525 22:47:46.084395 29460 solver.cpp:237] Iteration 66000, loss = 1.34952
I0525 22:47:46.084460 29460 solver.cpp:253]     Train net output #0: loss = 1.34952 (* 1 = 1.34952 loss)
I0525 22:47:46.084478 29460 sgd_solver.cpp:106] Iteration 66000, lr = 0.0045
I0525 22:47:54.830221 29460 solver.cpp:237] Iteration 66150, loss = 1.01668
I0525 22:47:54.830260 29460 solver.cpp:253]     Train net output #0: loss = 1.01668 (* 1 = 1.01668 loss)
I0525 22:47:54.830286 29460 sgd_solver.cpp:106] Iteration 66150, lr = 0.0045
I0525 22:48:03.575786 29460 solver.cpp:237] Iteration 66300, loss = 1.07484
I0525 22:48:03.575992 29460 solver.cpp:253]     Train net output #0: loss = 1.07484 (* 1 = 1.07484 loss)
I0525 22:48:03.576020 29460 sgd_solver.cpp:106] Iteration 66300, lr = 0.0045
I0525 22:48:12.313700 29460 solver.cpp:237] Iteration 66450, loss = 1.34244
I0525 22:48:12.313737 29460 solver.cpp:253]     Train net output #0: loss = 1.34244 (* 1 = 1.34244 loss)
I0525 22:48:12.313762 29460 sgd_solver.cpp:106] Iteration 66450, lr = 0.0045
I0525 22:48:21.052206 29460 solver.cpp:237] Iteration 66600, loss = 1.217
I0525 22:48:21.052243 29460 solver.cpp:253]     Train net output #0: loss = 1.217 (* 1 = 1.217 loss)
I0525 22:48:21.052263 29460 sgd_solver.cpp:106] Iteration 66600, lr = 0.0045
I0525 22:48:29.792454 29460 solver.cpp:237] Iteration 66750, loss = 1.16294
I0525 22:48:29.792506 29460 solver.cpp:253]     Train net output #0: loss = 1.16294 (* 1 = 1.16294 loss)
I0525 22:48:29.792526 29460 sgd_solver.cpp:106] Iteration 66750, lr = 0.0045
I0525 22:48:38.526583 29460 solver.cpp:237] Iteration 66900, loss = 1.22122
I0525 22:48:38.526769 29460 solver.cpp:253]     Train net output #0: loss = 1.22122 (* 1 = 1.22122 loss)
I0525 22:48:38.526787 29460 sgd_solver.cpp:106] Iteration 66900, lr = 0.0045
I0525 22:49:08.112349 29460 solver.cpp:237] Iteration 67050, loss = 1.10596
I0525 22:49:08.112404 29460 solver.cpp:253]     Train net output #0: loss = 1.10596 (* 1 = 1.10596 loss)
I0525 22:49:08.112422 29460 sgd_solver.cpp:106] Iteration 67050, lr = 0.0045
I0525 22:49:16.847138 29460 solver.cpp:237] Iteration 67200, loss = 1.14141
I0525 22:49:16.847337 29460 solver.cpp:253]     Train net output #0: loss = 1.14141 (* 1 = 1.14141 loss)
I0525 22:49:16.847354 29460 sgd_solver.cpp:106] Iteration 67200, lr = 0.0045
I0525 22:49:25.583508 29460 solver.cpp:237] Iteration 67350, loss = 1.26793
I0525 22:49:25.583546 29460 solver.cpp:253]     Train net output #0: loss = 1.26793 (* 1 = 1.26793 loss)
I0525 22:49:25.583571 29460 sgd_solver.cpp:106] Iteration 67350, lr = 0.0045
I0525 22:49:34.263355 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_67500.caffemodel
I0525 22:49:34.344087 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_67500.solverstate
I0525 22:49:34.389715 29460 solver.cpp:237] Iteration 67500, loss = 1.24711
I0525 22:49:34.389770 29460 solver.cpp:253]     Train net output #0: loss = 1.24711 (* 1 = 1.24711 loss)
I0525 22:49:34.389788 29460 sgd_solver.cpp:106] Iteration 67500, lr = 0.0045
I0525 22:49:43.123708 29460 solver.cpp:237] Iteration 67650, loss = 1.08041
I0525 22:49:43.123761 29460 solver.cpp:253]     Train net output #0: loss = 1.08041 (* 1 = 1.08041 loss)
I0525 22:49:43.123780 29460 sgd_solver.cpp:106] Iteration 67650, lr = 0.0045
I0525 22:49:51.860469 29460 solver.cpp:237] Iteration 67800, loss = 1.14166
I0525 22:49:51.860658 29460 solver.cpp:253]     Train net output #0: loss = 1.14166 (* 1 = 1.14166 loss)
I0525 22:49:51.860676 29460 sgd_solver.cpp:106] Iteration 67800, lr = 0.0045
I0525 22:50:00.595548 29460 solver.cpp:237] Iteration 67950, loss = 1.18224
I0525 22:50:00.595587 29460 solver.cpp:253]     Train net output #0: loss = 1.18224 (* 1 = 1.18224 loss)
I0525 22:50:00.595607 29460 sgd_solver.cpp:106] Iteration 67950, lr = 0.0045
I0525 22:50:30.185829 29460 solver.cpp:237] Iteration 68100, loss = 1.14519
I0525 22:50:30.186033 29460 solver.cpp:253]     Train net output #0: loss = 1.14519 (* 1 = 1.14519 loss)
I0525 22:50:30.186051 29460 sgd_solver.cpp:106] Iteration 68100, lr = 0.0045
I0525 22:50:38.923290 29460 solver.cpp:237] Iteration 68250, loss = 1.04182
I0525 22:50:38.923341 29460 solver.cpp:253]     Train net output #0: loss = 1.04182 (* 1 = 1.04182 loss)
I0525 22:50:38.923368 29460 sgd_solver.cpp:106] Iteration 68250, lr = 0.0045
I0525 22:50:47.671494 29460 solver.cpp:237] Iteration 68400, loss = 1.11262
I0525 22:50:47.671531 29460 solver.cpp:253]     Train net output #0: loss = 1.11262 (* 1 = 1.11262 loss)
I0525 22:50:47.671555 29460 sgd_solver.cpp:106] Iteration 68400, lr = 0.0045
I0525 22:50:56.415609 29460 solver.cpp:237] Iteration 68550, loss = 1.27423
I0525 22:50:56.415664 29460 solver.cpp:253]     Train net output #0: loss = 1.27423 (* 1 = 1.27423 loss)
I0525 22:50:56.415691 29460 sgd_solver.cpp:106] Iteration 68550, lr = 0.0045
I0525 22:51:05.162370 29460 solver.cpp:237] Iteration 68700, loss = 1.09024
I0525 22:51:05.162565 29460 solver.cpp:253]     Train net output #0: loss = 1.09024 (* 1 = 1.09024 loss)
I0525 22:51:05.162582 29460 sgd_solver.cpp:106] Iteration 68700, lr = 0.0045
I0525 22:51:13.904672 29460 solver.cpp:237] Iteration 68850, loss = 0.985456
I0525 22:51:13.904711 29460 solver.cpp:253]     Train net output #0: loss = 0.985456 (* 1 = 0.985456 loss)
I0525 22:51:13.904736 29460 sgd_solver.cpp:106] Iteration 68850, lr = 0.0045
I0525 22:51:22.597355 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_69000.caffemodel
I0525 22:51:22.676265 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_69000.solverstate
I0525 22:51:22.702178 29460 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 22:52:09.245105 29460 solver.cpp:409]     Test net output #0: accuracy = 0.894349
I0525 22:52:09.245312 29460 solver.cpp:409]     Test net output #1: loss = 0.329434 (* 1 = 0.329434 loss)
I0525 22:52:30.138262 29460 solver.cpp:237] Iteration 69000, loss = 1.10252
I0525 22:52:30.138320 29460 solver.cpp:253]     Train net output #0: loss = 1.10252 (* 1 = 1.10252 loss)
I0525 22:52:30.138339 29460 sgd_solver.cpp:106] Iteration 69000, lr = 0.0045
I0525 22:52:38.870451 29460 solver.cpp:237] Iteration 69150, loss = 1.02423
I0525 22:52:38.870506 29460 solver.cpp:253]     Train net output #0: loss = 1.02423 (* 1 = 1.02423 loss)
I0525 22:52:38.870533 29460 sgd_solver.cpp:106] Iteration 69150, lr = 0.0045
I0525 22:52:47.611292 29460 solver.cpp:237] Iteration 69300, loss = 1.03665
I0525 22:52:47.611481 29460 solver.cpp:253]     Train net output #0: loss = 1.03665 (* 1 = 1.03665 loss)
I0525 22:52:47.611498 29460 sgd_solver.cpp:106] Iteration 69300, lr = 0.0045
I0525 22:52:56.344825 29460 solver.cpp:237] Iteration 69450, loss = 1.114
I0525 22:52:56.344861 29460 solver.cpp:253]     Train net output #0: loss = 1.114 (* 1 = 1.114 loss)
I0525 22:52:56.344887 29460 sgd_solver.cpp:106] Iteration 69450, lr = 0.0045
I0525 22:53:05.084844 29460 solver.cpp:237] Iteration 69600, loss = 1.16237
I0525 22:53:05.084897 29460 solver.cpp:253]     Train net output #0: loss = 1.16237 (* 1 = 1.16237 loss)
I0525 22:53:05.084918 29460 sgd_solver.cpp:106] Iteration 69600, lr = 0.0045
I0525 22:53:13.817701 29460 solver.cpp:237] Iteration 69750, loss = 1.1958
I0525 22:53:13.817739 29460 solver.cpp:253]     Train net output #0: loss = 1.1958 (* 1 = 1.1958 loss)
I0525 22:53:13.817764 29460 sgd_solver.cpp:106] Iteration 69750, lr = 0.0045
I0525 22:53:22.546880 29460 solver.cpp:237] Iteration 69900, loss = 1.13087
I0525 22:53:22.547065 29460 solver.cpp:253]     Train net output #0: loss = 1.13087 (* 1 = 1.13087 loss)
I0525 22:53:22.547081 29460 sgd_solver.cpp:106] Iteration 69900, lr = 0.0045
I0525 22:53:52.146458 29460 solver.cpp:237] Iteration 70050, loss = 1.00431
I0525 22:53:52.146514 29460 solver.cpp:253]     Train net output #0: loss = 1.00431 (* 1 = 1.00431 loss)
I0525 22:53:52.146533 29460 sgd_solver.cpp:106] Iteration 70050, lr = 0.0045
I0525 22:54:00.881726 29460 solver.cpp:237] Iteration 70200, loss = 1.11628
I0525 22:54:00.881923 29460 solver.cpp:253]     Train net output #0: loss = 1.11628 (* 1 = 1.11628 loss)
I0525 22:54:00.881940 29460 sgd_solver.cpp:106] Iteration 70200, lr = 0.0045
I0525 22:54:09.618139 29460 solver.cpp:237] Iteration 70350, loss = 1.06561
I0525 22:54:09.618177 29460 solver.cpp:253]     Train net output #0: loss = 1.06561 (* 1 = 1.06561 loss)
I0525 22:54:09.618202 29460 sgd_solver.cpp:106] Iteration 70350, lr = 0.0045
I0525 22:54:18.296735 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_70500.caffemodel
I0525 22:54:18.375268 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_70500.solverstate
I0525 22:54:18.419087 29460 solver.cpp:237] Iteration 70500, loss = 1.14165
I0525 22:54:18.419142 29460 solver.cpp:253]     Train net output #0: loss = 1.14165 (* 1 = 1.14165 loss)
I0525 22:54:18.419159 29460 sgd_solver.cpp:106] Iteration 70500, lr = 0.0045
I0525 22:54:27.150547 29460 solver.cpp:237] Iteration 70650, loss = 1.20601
I0525 22:54:27.150584 29460 solver.cpp:253]     Train net output #0: loss = 1.20601 (* 1 = 1.20601 loss)
I0525 22:54:27.150609 29460 sgd_solver.cpp:106] Iteration 70650, lr = 0.0045
I0525 22:54:35.886958 29460 solver.cpp:237] Iteration 70800, loss = 1.21824
I0525 22:54:35.887147 29460 solver.cpp:253]     Train net output #0: loss = 1.21824 (* 1 = 1.21824 loss)
I0525 22:54:35.887164 29460 sgd_solver.cpp:106] Iteration 70800, lr = 0.0045
I0525 22:54:44.621706 29460 solver.cpp:237] Iteration 70950, loss = 1.11003
I0525 22:54:44.621759 29460 solver.cpp:253]     Train net output #0: loss = 1.11003 (* 1 = 1.11003 loss)
I0525 22:54:44.621780 29460 sgd_solver.cpp:106] Iteration 70950, lr = 0.0045
I0525 22:55:14.279500 29460 solver.cpp:237] Iteration 71100, loss = 1.16151
I0525 22:55:14.279707 29460 solver.cpp:253]     Train net output #0: loss = 1.16151 (* 1 = 1.16151 loss)
I0525 22:55:14.279726 29460 sgd_solver.cpp:106] Iteration 71100, lr = 0.0045
I0525 22:55:23.012759 29460 solver.cpp:237] Iteration 71250, loss = 1.26074
I0525 22:55:23.012801 29460 solver.cpp:253]     Train net output #0: loss = 1.26074 (* 1 = 1.26074 loss)
I0525 22:55:23.012830 29460 sgd_solver.cpp:106] Iteration 71250, lr = 0.0045
I0525 22:55:31.754748 29460 solver.cpp:237] Iteration 71400, loss = 1.26065
I0525 22:55:31.754802 29460 solver.cpp:253]     Train net output #0: loss = 1.26065 (* 1 = 1.26065 loss)
I0525 22:55:31.754830 29460 sgd_solver.cpp:106] Iteration 71400, lr = 0.0045
I0525 22:55:40.494125 29460 solver.cpp:237] Iteration 71550, loss = 1.15727
I0525 22:55:40.494163 29460 solver.cpp:253]     Train net output #0: loss = 1.15727 (* 1 = 1.15727 loss)
I0525 22:55:40.494189 29460 sgd_solver.cpp:106] Iteration 71550, lr = 0.0045
I0525 22:55:49.231833 29460 solver.cpp:237] Iteration 71700, loss = 1.24516
I0525 22:55:49.232022 29460 solver.cpp:253]     Train net output #0: loss = 1.24516 (* 1 = 1.24516 loss)
I0525 22:55:49.232038 29460 sgd_solver.cpp:106] Iteration 71700, lr = 0.0045
I0525 22:55:57.969537 29460 solver.cpp:237] Iteration 71850, loss = 1.09295
I0525 22:55:57.969589 29460 solver.cpp:253]     Train net output #0: loss = 1.09295 (* 1 = 1.09295 loss)
I0525 22:55:57.969619 29460 sgd_solver.cpp:106] Iteration 71850, lr = 0.0045
I0525 22:56:06.650904 29460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_72000.caffemodel
I0525 22:56:06.729835 29460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0045_2016-05-20T15.49.26.966043_iter_72000.solverstate
I0525 22:56:06.756475 29460 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 22:57:14.607084 29460 solver.cpp:409]     Test net output #0: accuracy = 0.894162
I0525 22:57:14.607298 29460 solver.cpp:409]     Test net output #1: loss = 0.325181 (* 1 = 0.325181 loss)
I0525 22:57:35.495023 29460 solver.cpp:237] Iteration 72000, loss = 1.19575
I0525 22:57:35.495085 29460 solver.cpp:253]     Train net output #0: loss = 1.19575 (* 1 = 1.19575 loss)
I0525 22:57:35.495102 29460 sgd_solver.cpp:106] Iteration 72000, lr = 0.0045
I0525 22:57:44.220690 29460 solver.cpp:237] Iteration 72150, loss = 1.08881
I0525 22:57:44.220741 29460 solver.cpp:253]     Train net output #0: loss = 1.08881 (* 1 = 1.08881 loss)
I0525 22:57:44.220768 29460 sgd_solver.cpp:106] Iteration 72150, lr = 0.0045
I0525 22:57:52.943853 29460 solver.cpp:237] Iteration 72300, loss = 1.04097
I0525 22:57:52.944043 29460 solver.cpp:253]     Train net output #0: loss = 1.04097 (* 1 = 1.04097 loss)
I0525 22:57:52.944061 29460 sgd_solver.cpp:106] Iteration 72300, lr = 0.0045
I0525 22:58:01.674396 29460 solver.cpp:237] Iteration 72450, loss = 1.21448
I0525 22:58:01.674449 29460 solver.cpp:253]     Train net output #0: loss = 1.21448 (* 1 = 1.21448 loss)
I0525 22:58:01.674470 29460 sgd_solver.cpp:106] Iteration 72450, lr = 0.0045
I0525 22:58:10.399227 29460 solver.cpp:237] Iteration 72600, loss = 1.27696
I0525 22:58:10.399265 29460 solver.cpp:253]     Train net output #0: loss = 1.27696 (* 1 = 1.27696 loss)
I0525 22:58:10.399289 29460 sgd_solver.cpp:106] Iteration 72600, lr = 0.0045
aprun: Apid 11265866: Caught signal Terminated, sending to application
*** Aborted at 1464231495 (unix time) try "date -d @1464231495" if you are using GNU date ***
aprun: Apid 11265866: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11265866: Caught signal Terminated, sending to application
*** SIGTERM (@0x7311) received by PID 29460 (TID 0x2aaac746f900) from PID 29457; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
=>> PBS: job killed: walltime 7232 exceeded limit 7200
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11265866: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11265866: Caught signal Terminated, sending to application
aprun: Apid 11265866: Caught signal Terminated, sending to application
aprun: Apid 11265866: Caught signal Terminated, sending to application
aprun: Apid 11265866: Caught signal Terminated, sending to application
aprun: Apid 11265866: Caught signal Terminated, sending to application
aprun: Apid 11265866: Caught signal Terminated, sending to application
aprun: Apid 11265866: Caught signal Terminated, sending to application
aprun: Apid 11265866: Caught signal Terminated, sending to application
