2805530
I0520 16:12:41.943511 24275 caffe.cpp:184] Using GPUs 0
I0520 16:12:42.365182 24275 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0025
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607.prototxt"
I0520 16:12:42.367169 24275 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607.prototxt
I0520 16:12:42.378167 24275 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0520 16:12:42.378227 24275 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0520 16:12:42.378576 24275 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0520 16:12:42.378757 24275 layer_factory.hpp:77] Creating layer data_hdf5
I0520 16:12:42.378782 24275 net.cpp:106] Creating Layer data_hdf5
I0520 16:12:42.378796 24275 net.cpp:411] data_hdf5 -> data
I0520 16:12:42.378831 24275 net.cpp:411] data_hdf5 -> label
I0520 16:12:42.378864 24275 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0520 16:12:42.391041 24275 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0520 16:12:42.403092 24275 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0520 16:13:03.962020 24275 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0520 16:13:03.967049 24275 net.cpp:150] Setting up data_hdf5
I0520 16:13:03.967089 24275 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0520 16:13:03.967104 24275 net.cpp:157] Top shape: 10 (10)
I0520 16:13:03.967118 24275 net.cpp:165] Memory required for data: 254040
I0520 16:13:03.967130 24275 layer_factory.hpp:77] Creating layer conv1
I0520 16:13:03.967165 24275 net.cpp:106] Creating Layer conv1
I0520 16:13:03.967176 24275 net.cpp:454] conv1 <- data
I0520 16:13:03.967196 24275 net.cpp:411] conv1 -> conv1
I0520 16:13:05.423094 24275 net.cpp:150] Setting up conv1
I0520 16:13:05.423140 24275 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0520 16:13:05.423151 24275 net.cpp:165] Memory required for data: 3018840
I0520 16:13:05.423179 24275 layer_factory.hpp:77] Creating layer relu1
I0520 16:13:05.423200 24275 net.cpp:106] Creating Layer relu1
I0520 16:13:05.423212 24275 net.cpp:454] relu1 <- conv1
I0520 16:13:05.423225 24275 net.cpp:397] relu1 -> conv1 (in-place)
I0520 16:13:05.423756 24275 net.cpp:150] Setting up relu1
I0520 16:13:05.423774 24275 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0520 16:13:05.423784 24275 net.cpp:165] Memory required for data: 5783640
I0520 16:13:05.423795 24275 layer_factory.hpp:77] Creating layer pool1
I0520 16:13:05.423813 24275 net.cpp:106] Creating Layer pool1
I0520 16:13:05.423823 24275 net.cpp:454] pool1 <- conv1
I0520 16:13:05.423837 24275 net.cpp:411] pool1 -> pool1
I0520 16:13:05.423918 24275 net.cpp:150] Setting up pool1
I0520 16:13:05.423931 24275 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0520 16:13:05.423943 24275 net.cpp:165] Memory required for data: 7166040
I0520 16:13:05.423952 24275 layer_factory.hpp:77] Creating layer conv2
I0520 16:13:05.423974 24275 net.cpp:106] Creating Layer conv2
I0520 16:13:05.423985 24275 net.cpp:454] conv2 <- pool1
I0520 16:13:05.423998 24275 net.cpp:411] conv2 -> conv2
I0520 16:13:05.426728 24275 net.cpp:150] Setting up conv2
I0520 16:13:05.426754 24275 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0520 16:13:05.426765 24275 net.cpp:165] Memory required for data: 9153240
I0520 16:13:05.426784 24275 layer_factory.hpp:77] Creating layer relu2
I0520 16:13:05.426800 24275 net.cpp:106] Creating Layer relu2
I0520 16:13:05.426810 24275 net.cpp:454] relu2 <- conv2
I0520 16:13:05.426822 24275 net.cpp:397] relu2 -> conv2 (in-place)
I0520 16:13:05.427153 24275 net.cpp:150] Setting up relu2
I0520 16:13:05.427167 24275 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0520 16:13:05.427177 24275 net.cpp:165] Memory required for data: 11140440
I0520 16:13:05.427188 24275 layer_factory.hpp:77] Creating layer pool2
I0520 16:13:05.427201 24275 net.cpp:106] Creating Layer pool2
I0520 16:13:05.427211 24275 net.cpp:454] pool2 <- conv2
I0520 16:13:05.427223 24275 net.cpp:411] pool2 -> pool2
I0520 16:13:05.427302 24275 net.cpp:150] Setting up pool2
I0520 16:13:05.427316 24275 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0520 16:13:05.427326 24275 net.cpp:165] Memory required for data: 12134040
I0520 16:13:05.427333 24275 layer_factory.hpp:77] Creating layer conv3
I0520 16:13:05.427352 24275 net.cpp:106] Creating Layer conv3
I0520 16:13:05.427362 24275 net.cpp:454] conv3 <- pool2
I0520 16:13:05.427376 24275 net.cpp:411] conv3 -> conv3
I0520 16:13:05.429482 24275 net.cpp:150] Setting up conv3
I0520 16:13:05.429502 24275 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0520 16:13:05.429512 24275 net.cpp:165] Memory required for data: 13218200
I0520 16:13:05.429532 24275 layer_factory.hpp:77] Creating layer relu3
I0520 16:13:05.429548 24275 net.cpp:106] Creating Layer relu3
I0520 16:13:05.429558 24275 net.cpp:454] relu3 <- conv3
I0520 16:13:05.429570 24275 net.cpp:397] relu3 -> conv3 (in-place)
I0520 16:13:05.430032 24275 net.cpp:150] Setting up relu3
I0520 16:13:05.430049 24275 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0520 16:13:05.430060 24275 net.cpp:165] Memory required for data: 14302360
I0520 16:13:05.430070 24275 layer_factory.hpp:77] Creating layer pool3
I0520 16:13:05.430083 24275 net.cpp:106] Creating Layer pool3
I0520 16:13:05.430094 24275 net.cpp:454] pool3 <- conv3
I0520 16:13:05.430106 24275 net.cpp:411] pool3 -> pool3
I0520 16:13:05.430173 24275 net.cpp:150] Setting up pool3
I0520 16:13:05.430187 24275 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0520 16:13:05.430197 24275 net.cpp:165] Memory required for data: 14844440
I0520 16:13:05.430204 24275 layer_factory.hpp:77] Creating layer conv4
I0520 16:13:05.430222 24275 net.cpp:106] Creating Layer conv4
I0520 16:13:05.430232 24275 net.cpp:454] conv4 <- pool3
I0520 16:13:05.430245 24275 net.cpp:411] conv4 -> conv4
I0520 16:13:05.432982 24275 net.cpp:150] Setting up conv4
I0520 16:13:05.433009 24275 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0520 16:13:05.433022 24275 net.cpp:165] Memory required for data: 15207320
I0520 16:13:05.433037 24275 layer_factory.hpp:77] Creating layer relu4
I0520 16:13:05.433050 24275 net.cpp:106] Creating Layer relu4
I0520 16:13:05.433061 24275 net.cpp:454] relu4 <- conv4
I0520 16:13:05.433074 24275 net.cpp:397] relu4 -> conv4 (in-place)
I0520 16:13:05.433539 24275 net.cpp:150] Setting up relu4
I0520 16:13:05.433557 24275 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0520 16:13:05.433567 24275 net.cpp:165] Memory required for data: 15570200
I0520 16:13:05.433576 24275 layer_factory.hpp:77] Creating layer pool4
I0520 16:13:05.433589 24275 net.cpp:106] Creating Layer pool4
I0520 16:13:05.433599 24275 net.cpp:454] pool4 <- conv4
I0520 16:13:05.433612 24275 net.cpp:411] pool4 -> pool4
I0520 16:13:05.433681 24275 net.cpp:150] Setting up pool4
I0520 16:13:05.433693 24275 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0520 16:13:05.433703 24275 net.cpp:165] Memory required for data: 15751640
I0520 16:13:05.433714 24275 layer_factory.hpp:77] Creating layer ip1
I0520 16:13:05.433734 24275 net.cpp:106] Creating Layer ip1
I0520 16:13:05.433745 24275 net.cpp:454] ip1 <- pool4
I0520 16:13:05.433758 24275 net.cpp:411] ip1 -> ip1
I0520 16:13:05.449195 24275 net.cpp:150] Setting up ip1
I0520 16:13:05.449224 24275 net.cpp:157] Top shape: 10 196 (1960)
I0520 16:13:05.449235 24275 net.cpp:165] Memory required for data: 15759480
I0520 16:13:05.449257 24275 layer_factory.hpp:77] Creating layer relu5
I0520 16:13:05.449271 24275 net.cpp:106] Creating Layer relu5
I0520 16:13:05.449282 24275 net.cpp:454] relu5 <- ip1
I0520 16:13:05.449295 24275 net.cpp:397] relu5 -> ip1 (in-place)
I0520 16:13:05.449640 24275 net.cpp:150] Setting up relu5
I0520 16:13:05.449654 24275 net.cpp:157] Top shape: 10 196 (1960)
I0520 16:13:05.449666 24275 net.cpp:165] Memory required for data: 15767320
I0520 16:13:05.449676 24275 layer_factory.hpp:77] Creating layer drop1
I0520 16:13:05.449697 24275 net.cpp:106] Creating Layer drop1
I0520 16:13:05.449707 24275 net.cpp:454] drop1 <- ip1
I0520 16:13:05.449720 24275 net.cpp:397] drop1 -> ip1 (in-place)
I0520 16:13:05.449779 24275 net.cpp:150] Setting up drop1
I0520 16:13:05.449792 24275 net.cpp:157] Top shape: 10 196 (1960)
I0520 16:13:05.449802 24275 net.cpp:165] Memory required for data: 15775160
I0520 16:13:05.449812 24275 layer_factory.hpp:77] Creating layer ip2
I0520 16:13:05.449831 24275 net.cpp:106] Creating Layer ip2
I0520 16:13:05.449841 24275 net.cpp:454] ip2 <- ip1
I0520 16:13:05.449854 24275 net.cpp:411] ip2 -> ip2
I0520 16:13:05.450320 24275 net.cpp:150] Setting up ip2
I0520 16:13:05.450333 24275 net.cpp:157] Top shape: 10 98 (980)
I0520 16:13:05.450342 24275 net.cpp:165] Memory required for data: 15779080
I0520 16:13:05.450358 24275 layer_factory.hpp:77] Creating layer relu6
I0520 16:13:05.450371 24275 net.cpp:106] Creating Layer relu6
I0520 16:13:05.450381 24275 net.cpp:454] relu6 <- ip2
I0520 16:13:05.450392 24275 net.cpp:397] relu6 -> ip2 (in-place)
I0520 16:13:05.450908 24275 net.cpp:150] Setting up relu6
I0520 16:13:05.450924 24275 net.cpp:157] Top shape: 10 98 (980)
I0520 16:13:05.450934 24275 net.cpp:165] Memory required for data: 15783000
I0520 16:13:05.450944 24275 layer_factory.hpp:77] Creating layer drop2
I0520 16:13:05.450958 24275 net.cpp:106] Creating Layer drop2
I0520 16:13:05.450968 24275 net.cpp:454] drop2 <- ip2
I0520 16:13:05.450979 24275 net.cpp:397] drop2 -> ip2 (in-place)
I0520 16:13:05.451022 24275 net.cpp:150] Setting up drop2
I0520 16:13:05.451035 24275 net.cpp:157] Top shape: 10 98 (980)
I0520 16:13:05.451045 24275 net.cpp:165] Memory required for data: 15786920
I0520 16:13:05.451056 24275 layer_factory.hpp:77] Creating layer ip3
I0520 16:13:05.451068 24275 net.cpp:106] Creating Layer ip3
I0520 16:13:05.451078 24275 net.cpp:454] ip3 <- ip2
I0520 16:13:05.451092 24275 net.cpp:411] ip3 -> ip3
I0520 16:13:05.451302 24275 net.cpp:150] Setting up ip3
I0520 16:13:05.451314 24275 net.cpp:157] Top shape: 10 11 (110)
I0520 16:13:05.451324 24275 net.cpp:165] Memory required for data: 15787360
I0520 16:13:05.451339 24275 layer_factory.hpp:77] Creating layer drop3
I0520 16:13:05.451352 24275 net.cpp:106] Creating Layer drop3
I0520 16:13:05.451361 24275 net.cpp:454] drop3 <- ip3
I0520 16:13:05.451373 24275 net.cpp:397] drop3 -> ip3 (in-place)
I0520 16:13:05.451412 24275 net.cpp:150] Setting up drop3
I0520 16:13:05.451426 24275 net.cpp:157] Top shape: 10 11 (110)
I0520 16:13:05.451436 24275 net.cpp:165] Memory required for data: 15787800
I0520 16:13:05.451445 24275 layer_factory.hpp:77] Creating layer loss
I0520 16:13:05.451464 24275 net.cpp:106] Creating Layer loss
I0520 16:13:05.451474 24275 net.cpp:454] loss <- ip3
I0520 16:13:05.451485 24275 net.cpp:454] loss <- label
I0520 16:13:05.451498 24275 net.cpp:411] loss -> loss
I0520 16:13:05.451515 24275 layer_factory.hpp:77] Creating layer loss
I0520 16:13:05.452167 24275 net.cpp:150] Setting up loss
I0520 16:13:05.452188 24275 net.cpp:157] Top shape: (1)
I0520 16:13:05.452200 24275 net.cpp:160]     with loss weight 1
I0520 16:13:05.452244 24275 net.cpp:165] Memory required for data: 15787804
I0520 16:13:05.452253 24275 net.cpp:226] loss needs backward computation.
I0520 16:13:05.452265 24275 net.cpp:226] drop3 needs backward computation.
I0520 16:13:05.452273 24275 net.cpp:226] ip3 needs backward computation.
I0520 16:13:05.452285 24275 net.cpp:226] drop2 needs backward computation.
I0520 16:13:05.452294 24275 net.cpp:226] relu6 needs backward computation.
I0520 16:13:05.452304 24275 net.cpp:226] ip2 needs backward computation.
I0520 16:13:05.452314 24275 net.cpp:226] drop1 needs backward computation.
I0520 16:13:05.452324 24275 net.cpp:226] relu5 needs backward computation.
I0520 16:13:05.452334 24275 net.cpp:226] ip1 needs backward computation.
I0520 16:13:05.452344 24275 net.cpp:226] pool4 needs backward computation.
I0520 16:13:05.452354 24275 net.cpp:226] relu4 needs backward computation.
I0520 16:13:05.452364 24275 net.cpp:226] conv4 needs backward computation.
I0520 16:13:05.452374 24275 net.cpp:226] pool3 needs backward computation.
I0520 16:13:05.452385 24275 net.cpp:226] relu3 needs backward computation.
I0520 16:13:05.452395 24275 net.cpp:226] conv3 needs backward computation.
I0520 16:13:05.452414 24275 net.cpp:226] pool2 needs backward computation.
I0520 16:13:05.452425 24275 net.cpp:226] relu2 needs backward computation.
I0520 16:13:05.452436 24275 net.cpp:226] conv2 needs backward computation.
I0520 16:13:05.452448 24275 net.cpp:226] pool1 needs backward computation.
I0520 16:13:05.452458 24275 net.cpp:226] relu1 needs backward computation.
I0520 16:13:05.452468 24275 net.cpp:226] conv1 needs backward computation.
I0520 16:13:05.452479 24275 net.cpp:228] data_hdf5 does not need backward computation.
I0520 16:13:05.452489 24275 net.cpp:270] This network produces output loss
I0520 16:13:05.452514 24275 net.cpp:283] Network initialization done.
I0520 16:13:05.454058 24275 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607.prototxt
I0520 16:13:05.454130 24275 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0520 16:13:05.454481 24275 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0520 16:13:05.454673 24275 layer_factory.hpp:77] Creating layer data_hdf5
I0520 16:13:05.454687 24275 net.cpp:106] Creating Layer data_hdf5
I0520 16:13:05.454700 24275 net.cpp:411] data_hdf5 -> data
I0520 16:13:05.454717 24275 net.cpp:411] data_hdf5 -> label
I0520 16:13:05.454733 24275 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0520 16:13:05.456060 24275 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0520 16:13:26.855919 24275 net.cpp:150] Setting up data_hdf5
I0520 16:13:26.856097 24275 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0520 16:13:26.856112 24275 net.cpp:157] Top shape: 10 (10)
I0520 16:13:26.856123 24275 net.cpp:165] Memory required for data: 254040
I0520 16:13:26.856137 24275 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0520 16:13:26.856166 24275 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0520 16:13:26.856178 24275 net.cpp:454] label_data_hdf5_1_split <- label
I0520 16:13:26.856192 24275 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0520 16:13:26.856215 24275 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0520 16:13:26.856287 24275 net.cpp:150] Setting up label_data_hdf5_1_split
I0520 16:13:26.856302 24275 net.cpp:157] Top shape: 10 (10)
I0520 16:13:26.856313 24275 net.cpp:157] Top shape: 10 (10)
I0520 16:13:26.856323 24275 net.cpp:165] Memory required for data: 254120
I0520 16:13:26.856334 24275 layer_factory.hpp:77] Creating layer conv1
I0520 16:13:26.856354 24275 net.cpp:106] Creating Layer conv1
I0520 16:13:26.856365 24275 net.cpp:454] conv1 <- data
I0520 16:13:26.856380 24275 net.cpp:411] conv1 -> conv1
I0520 16:13:26.858319 24275 net.cpp:150] Setting up conv1
I0520 16:13:26.858343 24275 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0520 16:13:26.858355 24275 net.cpp:165] Memory required for data: 3018920
I0520 16:13:26.858376 24275 layer_factory.hpp:77] Creating layer relu1
I0520 16:13:26.858391 24275 net.cpp:106] Creating Layer relu1
I0520 16:13:26.858400 24275 net.cpp:454] relu1 <- conv1
I0520 16:13:26.858413 24275 net.cpp:397] relu1 -> conv1 (in-place)
I0520 16:13:26.858921 24275 net.cpp:150] Setting up relu1
I0520 16:13:26.858937 24275 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0520 16:13:26.858947 24275 net.cpp:165] Memory required for data: 5783720
I0520 16:13:26.858957 24275 layer_factory.hpp:77] Creating layer pool1
I0520 16:13:26.858973 24275 net.cpp:106] Creating Layer pool1
I0520 16:13:26.858983 24275 net.cpp:454] pool1 <- conv1
I0520 16:13:26.858996 24275 net.cpp:411] pool1 -> pool1
I0520 16:13:26.859071 24275 net.cpp:150] Setting up pool1
I0520 16:13:26.859084 24275 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0520 16:13:26.859097 24275 net.cpp:165] Memory required for data: 7166120
I0520 16:13:26.859107 24275 layer_factory.hpp:77] Creating layer conv2
I0520 16:13:26.859125 24275 net.cpp:106] Creating Layer conv2
I0520 16:13:26.859135 24275 net.cpp:454] conv2 <- pool1
I0520 16:13:26.859149 24275 net.cpp:411] conv2 -> conv2
I0520 16:13:26.861078 24275 net.cpp:150] Setting up conv2
I0520 16:13:26.861106 24275 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0520 16:13:26.861116 24275 net.cpp:165] Memory required for data: 9153320
I0520 16:13:26.861136 24275 layer_factory.hpp:77] Creating layer relu2
I0520 16:13:26.861150 24275 net.cpp:106] Creating Layer relu2
I0520 16:13:26.861160 24275 net.cpp:454] relu2 <- conv2
I0520 16:13:26.861172 24275 net.cpp:397] relu2 -> conv2 (in-place)
I0520 16:13:26.861508 24275 net.cpp:150] Setting up relu2
I0520 16:13:26.861523 24275 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0520 16:13:26.861533 24275 net.cpp:165] Memory required for data: 11140520
I0520 16:13:26.861543 24275 layer_factory.hpp:77] Creating layer pool2
I0520 16:13:26.861555 24275 net.cpp:106] Creating Layer pool2
I0520 16:13:26.861565 24275 net.cpp:454] pool2 <- conv2
I0520 16:13:26.861578 24275 net.cpp:411] pool2 -> pool2
I0520 16:13:26.861651 24275 net.cpp:150] Setting up pool2
I0520 16:13:26.861665 24275 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0520 16:13:26.861673 24275 net.cpp:165] Memory required for data: 12134120
I0520 16:13:26.861683 24275 layer_factory.hpp:77] Creating layer conv3
I0520 16:13:26.861701 24275 net.cpp:106] Creating Layer conv3
I0520 16:13:26.861712 24275 net.cpp:454] conv3 <- pool2
I0520 16:13:26.861726 24275 net.cpp:411] conv3 -> conv3
I0520 16:13:26.863732 24275 net.cpp:150] Setting up conv3
I0520 16:13:26.863756 24275 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0520 16:13:26.863768 24275 net.cpp:165] Memory required for data: 13218280
I0520 16:13:26.863786 24275 layer_factory.hpp:77] Creating layer relu3
I0520 16:13:26.863812 24275 net.cpp:106] Creating Layer relu3
I0520 16:13:26.863823 24275 net.cpp:454] relu3 <- conv3
I0520 16:13:26.863837 24275 net.cpp:397] relu3 -> conv3 (in-place)
I0520 16:13:26.864312 24275 net.cpp:150] Setting up relu3
I0520 16:13:26.864328 24275 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0520 16:13:26.864339 24275 net.cpp:165] Memory required for data: 14302440
I0520 16:13:26.864349 24275 layer_factory.hpp:77] Creating layer pool3
I0520 16:13:26.864362 24275 net.cpp:106] Creating Layer pool3
I0520 16:13:26.864372 24275 net.cpp:454] pool3 <- conv3
I0520 16:13:26.864385 24275 net.cpp:411] pool3 -> pool3
I0520 16:13:26.864456 24275 net.cpp:150] Setting up pool3
I0520 16:13:26.864470 24275 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0520 16:13:26.864480 24275 net.cpp:165] Memory required for data: 14844520
I0520 16:13:26.864487 24275 layer_factory.hpp:77] Creating layer conv4
I0520 16:13:26.864505 24275 net.cpp:106] Creating Layer conv4
I0520 16:13:26.864516 24275 net.cpp:454] conv4 <- pool3
I0520 16:13:26.864531 24275 net.cpp:411] conv4 -> conv4
I0520 16:13:26.866583 24275 net.cpp:150] Setting up conv4
I0520 16:13:26.866605 24275 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0520 16:13:26.866618 24275 net.cpp:165] Memory required for data: 15207400
I0520 16:13:26.866632 24275 layer_factory.hpp:77] Creating layer relu4
I0520 16:13:26.866647 24275 net.cpp:106] Creating Layer relu4
I0520 16:13:26.866657 24275 net.cpp:454] relu4 <- conv4
I0520 16:13:26.866668 24275 net.cpp:397] relu4 -> conv4 (in-place)
I0520 16:13:26.867132 24275 net.cpp:150] Setting up relu4
I0520 16:13:26.867149 24275 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0520 16:13:26.867159 24275 net.cpp:165] Memory required for data: 15570280
I0520 16:13:26.867169 24275 layer_factory.hpp:77] Creating layer pool4
I0520 16:13:26.867182 24275 net.cpp:106] Creating Layer pool4
I0520 16:13:26.867192 24275 net.cpp:454] pool4 <- conv4
I0520 16:13:26.867207 24275 net.cpp:411] pool4 -> pool4
I0520 16:13:26.867279 24275 net.cpp:150] Setting up pool4
I0520 16:13:26.867291 24275 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0520 16:13:26.867301 24275 net.cpp:165] Memory required for data: 15751720
I0520 16:13:26.867311 24275 layer_factory.hpp:77] Creating layer ip1
I0520 16:13:26.867326 24275 net.cpp:106] Creating Layer ip1
I0520 16:13:26.867336 24275 net.cpp:454] ip1 <- pool4
I0520 16:13:26.867352 24275 net.cpp:411] ip1 -> ip1
I0520 16:13:26.882838 24275 net.cpp:150] Setting up ip1
I0520 16:13:26.882866 24275 net.cpp:157] Top shape: 10 196 (1960)
I0520 16:13:26.882876 24275 net.cpp:165] Memory required for data: 15759560
I0520 16:13:26.882899 24275 layer_factory.hpp:77] Creating layer relu5
I0520 16:13:26.882913 24275 net.cpp:106] Creating Layer relu5
I0520 16:13:26.882925 24275 net.cpp:454] relu5 <- ip1
I0520 16:13:26.882937 24275 net.cpp:397] relu5 -> ip1 (in-place)
I0520 16:13:26.883283 24275 net.cpp:150] Setting up relu5
I0520 16:13:26.883297 24275 net.cpp:157] Top shape: 10 196 (1960)
I0520 16:13:26.883307 24275 net.cpp:165] Memory required for data: 15767400
I0520 16:13:26.883317 24275 layer_factory.hpp:77] Creating layer drop1
I0520 16:13:26.883335 24275 net.cpp:106] Creating Layer drop1
I0520 16:13:26.883345 24275 net.cpp:454] drop1 <- ip1
I0520 16:13:26.883358 24275 net.cpp:397] drop1 -> ip1 (in-place)
I0520 16:13:26.883404 24275 net.cpp:150] Setting up drop1
I0520 16:13:26.883416 24275 net.cpp:157] Top shape: 10 196 (1960)
I0520 16:13:26.883427 24275 net.cpp:165] Memory required for data: 15775240
I0520 16:13:26.883436 24275 layer_factory.hpp:77] Creating layer ip2
I0520 16:13:26.883450 24275 net.cpp:106] Creating Layer ip2
I0520 16:13:26.883460 24275 net.cpp:454] ip2 <- ip1
I0520 16:13:26.883474 24275 net.cpp:411] ip2 -> ip2
I0520 16:13:26.883957 24275 net.cpp:150] Setting up ip2
I0520 16:13:26.883970 24275 net.cpp:157] Top shape: 10 98 (980)
I0520 16:13:26.883980 24275 net.cpp:165] Memory required for data: 15779160
I0520 16:13:26.883996 24275 layer_factory.hpp:77] Creating layer relu6
I0520 16:13:26.884023 24275 net.cpp:106] Creating Layer relu6
I0520 16:13:26.884034 24275 net.cpp:454] relu6 <- ip2
I0520 16:13:26.884047 24275 net.cpp:397] relu6 -> ip2 (in-place)
I0520 16:13:26.884578 24275 net.cpp:150] Setting up relu6
I0520 16:13:26.884600 24275 net.cpp:157] Top shape: 10 98 (980)
I0520 16:13:26.884610 24275 net.cpp:165] Memory required for data: 15783080
I0520 16:13:26.884619 24275 layer_factory.hpp:77] Creating layer drop2
I0520 16:13:26.884634 24275 net.cpp:106] Creating Layer drop2
I0520 16:13:26.884644 24275 net.cpp:454] drop2 <- ip2
I0520 16:13:26.884656 24275 net.cpp:397] drop2 -> ip2 (in-place)
I0520 16:13:26.884699 24275 net.cpp:150] Setting up drop2
I0520 16:13:26.884712 24275 net.cpp:157] Top shape: 10 98 (980)
I0520 16:13:26.884722 24275 net.cpp:165] Memory required for data: 15787000
I0520 16:13:26.884732 24275 layer_factory.hpp:77] Creating layer ip3
I0520 16:13:26.884747 24275 net.cpp:106] Creating Layer ip3
I0520 16:13:26.884757 24275 net.cpp:454] ip3 <- ip2
I0520 16:13:26.884770 24275 net.cpp:411] ip3 -> ip3
I0520 16:13:26.884989 24275 net.cpp:150] Setting up ip3
I0520 16:13:26.885001 24275 net.cpp:157] Top shape: 10 11 (110)
I0520 16:13:26.885011 24275 net.cpp:165] Memory required for data: 15787440
I0520 16:13:26.885026 24275 layer_factory.hpp:77] Creating layer drop3
I0520 16:13:26.885040 24275 net.cpp:106] Creating Layer drop3
I0520 16:13:26.885049 24275 net.cpp:454] drop3 <- ip3
I0520 16:13:26.885062 24275 net.cpp:397] drop3 -> ip3 (in-place)
I0520 16:13:26.885103 24275 net.cpp:150] Setting up drop3
I0520 16:13:26.885116 24275 net.cpp:157] Top shape: 10 11 (110)
I0520 16:13:26.885126 24275 net.cpp:165] Memory required for data: 15787880
I0520 16:13:26.885136 24275 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0520 16:13:26.885150 24275 net.cpp:106] Creating Layer ip3_drop3_0_split
I0520 16:13:26.885159 24275 net.cpp:454] ip3_drop3_0_split <- ip3
I0520 16:13:26.885172 24275 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0520 16:13:26.885188 24275 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0520 16:13:26.885262 24275 net.cpp:150] Setting up ip3_drop3_0_split
I0520 16:13:26.885274 24275 net.cpp:157] Top shape: 10 11 (110)
I0520 16:13:26.885289 24275 net.cpp:157] Top shape: 10 11 (110)
I0520 16:13:26.885299 24275 net.cpp:165] Memory required for data: 15788760
I0520 16:13:26.885309 24275 layer_factory.hpp:77] Creating layer accuracy
I0520 16:13:26.885330 24275 net.cpp:106] Creating Layer accuracy
I0520 16:13:26.885340 24275 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0520 16:13:26.885351 24275 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0520 16:13:26.885365 24275 net.cpp:411] accuracy -> accuracy
I0520 16:13:26.885390 24275 net.cpp:150] Setting up accuracy
I0520 16:13:26.885401 24275 net.cpp:157] Top shape: (1)
I0520 16:13:26.885411 24275 net.cpp:165] Memory required for data: 15788764
I0520 16:13:26.885421 24275 layer_factory.hpp:77] Creating layer loss
I0520 16:13:26.885434 24275 net.cpp:106] Creating Layer loss
I0520 16:13:26.885470 24275 net.cpp:454] loss <- ip3_drop3_0_split_1
I0520 16:13:26.885483 24275 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0520 16:13:26.885495 24275 net.cpp:411] loss -> loss
I0520 16:13:26.885514 24275 layer_factory.hpp:77] Creating layer loss
I0520 16:13:26.886001 24275 net.cpp:150] Setting up loss
I0520 16:13:26.886015 24275 net.cpp:157] Top shape: (1)
I0520 16:13:26.886025 24275 net.cpp:160]     with loss weight 1
I0520 16:13:26.886044 24275 net.cpp:165] Memory required for data: 15788768
I0520 16:13:26.886054 24275 net.cpp:226] loss needs backward computation.
I0520 16:13:26.886065 24275 net.cpp:228] accuracy does not need backward computation.
I0520 16:13:26.886076 24275 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0520 16:13:26.886087 24275 net.cpp:226] drop3 needs backward computation.
I0520 16:13:26.886096 24275 net.cpp:226] ip3 needs backward computation.
I0520 16:13:26.886106 24275 net.cpp:226] drop2 needs backward computation.
I0520 16:13:26.886116 24275 net.cpp:226] relu6 needs backward computation.
I0520 16:13:26.886133 24275 net.cpp:226] ip2 needs backward computation.
I0520 16:13:26.886144 24275 net.cpp:226] drop1 needs backward computation.
I0520 16:13:26.886154 24275 net.cpp:226] relu5 needs backward computation.
I0520 16:13:26.886163 24275 net.cpp:226] ip1 needs backward computation.
I0520 16:13:26.886173 24275 net.cpp:226] pool4 needs backward computation.
I0520 16:13:26.886184 24275 net.cpp:226] relu4 needs backward computation.
I0520 16:13:26.886194 24275 net.cpp:226] conv4 needs backward computation.
I0520 16:13:26.886204 24275 net.cpp:226] pool3 needs backward computation.
I0520 16:13:26.886215 24275 net.cpp:226] relu3 needs backward computation.
I0520 16:13:26.886225 24275 net.cpp:226] conv3 needs backward computation.
I0520 16:13:26.886235 24275 net.cpp:226] pool2 needs backward computation.
I0520 16:13:26.886245 24275 net.cpp:226] relu2 needs backward computation.
I0520 16:13:26.886255 24275 net.cpp:226] conv2 needs backward computation.
I0520 16:13:26.886266 24275 net.cpp:226] pool1 needs backward computation.
I0520 16:13:26.886276 24275 net.cpp:226] relu1 needs backward computation.
I0520 16:13:26.886286 24275 net.cpp:226] conv1 needs backward computation.
I0520 16:13:26.886298 24275 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0520 16:13:26.886309 24275 net.cpp:228] data_hdf5 does not need backward computation.
I0520 16:13:26.886320 24275 net.cpp:270] This network produces output accuracy
I0520 16:13:26.886332 24275 net.cpp:270] This network produces output loss
I0520 16:13:26.886360 24275 net.cpp:283] Network initialization done.
I0520 16:13:26.886495 24275 solver.cpp:60] Solver scaffolding done.
I0520 16:13:26.887646 24275 caffe.cpp:212] Starting Optimization
I0520 16:13:26.887665 24275 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0520 16:13:26.887679 24275 solver.cpp:289] Learning Rate Policy: fixed
I0520 16:13:26.888741 24275 solver.cpp:341] Iteration 0, Testing net (#0)
I0520 16:14:27.382845 24275 solver.cpp:409]     Test net output #0: accuracy = 0.132638
I0520 16:14:27.383005 24275 solver.cpp:409]     Test net output #1: loss = 2.39872 (* 1 = 2.39872 loss)
I0520 16:14:27.400738 24275 solver.cpp:237] Iteration 0, loss = 2.40071
I0520 16:14:27.400775 24275 solver.cpp:253]     Train net output #0: loss = 2.40071 (* 1 = 2.40071 loss)
I0520 16:14:27.400794 24275 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0520 16:14:44.151562 24275 solver.cpp:237] Iteration 1500, loss = 1.81955
I0520 16:14:44.151621 24275 solver.cpp:253]     Train net output #0: loss = 1.81955 (* 1 = 1.81955 loss)
I0520 16:14:44.151636 24275 sgd_solver.cpp:106] Iteration 1500, lr = 0.0025
I0520 16:15:00.945060 24275 solver.cpp:237] Iteration 3000, loss = 1.97281
I0520 16:15:00.945211 24275 solver.cpp:253]     Train net output #0: loss = 1.97281 (* 1 = 1.97281 loss)
I0520 16:15:00.945226 24275 sgd_solver.cpp:106] Iteration 3000, lr = 0.0025
I0520 16:15:17.727419 24275 solver.cpp:237] Iteration 4500, loss = 1.73718
I0520 16:15:17.727463 24275 solver.cpp:253]     Train net output #0: loss = 1.73718 (* 1 = 1.73718 loss)
I0520 16:15:17.727480 24275 sgd_solver.cpp:106] Iteration 4500, lr = 0.0025
I0520 16:15:34.482729 24275 solver.cpp:237] Iteration 6000, loss = 1.57012
I0520 16:15:34.482874 24275 solver.cpp:253]     Train net output #0: loss = 1.57012 (* 1 = 1.57012 loss)
I0520 16:15:34.482888 24275 sgd_solver.cpp:106] Iteration 6000, lr = 0.0025
I0520 16:15:51.210532 24275 solver.cpp:237] Iteration 7500, loss = 1.04538
I0520 16:15:51.210569 24275 solver.cpp:253]     Train net output #0: loss = 1.04537 (* 1 = 1.04537 loss)
I0520 16:15:51.210582 24275 sgd_solver.cpp:106] Iteration 7500, lr = 0.0025
I0520 16:16:07.958469 24275 solver.cpp:237] Iteration 9000, loss = 1.78581
I0520 16:16:07.958603 24275 solver.cpp:253]     Train net output #0: loss = 1.78581 (* 1 = 1.78581 loss)
I0520 16:16:07.958616 24275 sgd_solver.cpp:106] Iteration 9000, lr = 0.0025
I0520 16:16:46.882665 24275 solver.cpp:237] Iteration 10500, loss = 1.70268
I0520 16:16:46.882825 24275 solver.cpp:253]     Train net output #0: loss = 1.70268 (* 1 = 1.70268 loss)
I0520 16:16:46.882839 24275 sgd_solver.cpp:106] Iteration 10500, lr = 0.0025
I0520 16:17:03.649914 24275 solver.cpp:237] Iteration 12000, loss = 1.07191
I0520 16:17:03.649950 24275 solver.cpp:253]     Train net output #0: loss = 1.07191 (* 1 = 1.07191 loss)
I0520 16:17:03.649966 24275 sgd_solver.cpp:106] Iteration 12000, lr = 0.0025
I0520 16:17:20.439676 24275 solver.cpp:237] Iteration 13500, loss = 1.27539
I0520 16:17:20.439833 24275 solver.cpp:253]     Train net output #0: loss = 1.27538 (* 1 = 1.27538 loss)
I0520 16:17:20.439847 24275 sgd_solver.cpp:106] Iteration 13500, lr = 0.0025
I0520 16:17:37.198295 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_15000.caffemodel
I0520 16:17:37.247898 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_15000.solverstate
I0520 16:17:37.276202 24275 solver.cpp:237] Iteration 15000, loss = 0.973613
I0520 16:17:37.276248 24275 solver.cpp:253]     Train net output #0: loss = 0.973611 (* 1 = 0.973611 loss)
I0520 16:17:37.276264 24275 sgd_solver.cpp:106] Iteration 15000, lr = 0.0025
I0520 16:17:54.018335 24275 solver.cpp:237] Iteration 16500, loss = 1.63307
I0520 16:17:54.018477 24275 solver.cpp:253]     Train net output #0: loss = 1.63307 (* 1 = 1.63307 loss)
I0520 16:17:54.018491 24275 sgd_solver.cpp:106] Iteration 16500, lr = 0.0025
I0520 16:18:10.797082 24275 solver.cpp:237] Iteration 18000, loss = 1.26426
I0520 16:18:10.797127 24275 solver.cpp:253]     Train net output #0: loss = 1.26426 (* 1 = 1.26426 loss)
I0520 16:18:10.797139 24275 sgd_solver.cpp:106] Iteration 18000, lr = 0.0025
I0520 16:18:27.572746 24275 solver.cpp:237] Iteration 19500, loss = 1.566
I0520 16:18:27.572888 24275 solver.cpp:253]     Train net output #0: loss = 1.566 (* 1 = 1.566 loss)
I0520 16:18:27.572902 24275 sgd_solver.cpp:106] Iteration 19500, lr = 0.0025
I0520 16:19:06.475260 24275 solver.cpp:237] Iteration 21000, loss = 1.18413
I0520 16:19:06.475432 24275 solver.cpp:253]     Train net output #0: loss = 1.18413 (* 1 = 1.18413 loss)
I0520 16:19:06.475446 24275 sgd_solver.cpp:106] Iteration 21000, lr = 0.0025
I0520 16:19:23.221547 24275 solver.cpp:237] Iteration 22500, loss = 1.36731
I0520 16:19:23.221595 24275 solver.cpp:253]     Train net output #0: loss = 1.36731 (* 1 = 1.36731 loss)
I0520 16:19:23.221608 24275 sgd_solver.cpp:106] Iteration 22500, lr = 0.0025
I0520 16:19:39.961051 24275 solver.cpp:237] Iteration 24000, loss = 0.97734
I0520 16:19:39.961208 24275 solver.cpp:253]     Train net output #0: loss = 0.97734 (* 1 = 0.97734 loss)
I0520 16:19:39.961222 24275 sgd_solver.cpp:106] Iteration 24000, lr = 0.0025
I0520 16:19:56.744818 24275 solver.cpp:237] Iteration 25500, loss = 1.38685
I0520 16:19:56.744854 24275 solver.cpp:253]     Train net output #0: loss = 1.38685 (* 1 = 1.38685 loss)
I0520 16:19:56.744869 24275 sgd_solver.cpp:106] Iteration 25500, lr = 0.0025
I0520 16:20:13.489692 24275 solver.cpp:237] Iteration 27000, loss = 1.47775
I0520 16:20:13.489845 24275 solver.cpp:253]     Train net output #0: loss = 1.47775 (* 1 = 1.47775 loss)
I0520 16:20:13.489858 24275 sgd_solver.cpp:106] Iteration 27000, lr = 0.0025
I0520 16:20:30.256399 24275 solver.cpp:237] Iteration 28500, loss = 1.74373
I0520 16:20:30.256445 24275 solver.cpp:253]     Train net output #0: loss = 1.74373 (* 1 = 1.74373 loss)
I0520 16:20:30.256460 24275 sgd_solver.cpp:106] Iteration 28500, lr = 0.0025
I0520 16:20:47.022523 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_30000.caffemodel
I0520 16:20:47.068120 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_30000.solverstate
I0520 16:20:47.094180 24275 solver.cpp:341] Iteration 30000, Testing net (#0)
I0520 16:21:46.292702 24275 solver.cpp:409]     Test net output #0: accuracy = 0.855651
I0520 16:21:46.292858 24275 solver.cpp:409]     Test net output #1: loss = 0.479542 (* 1 = 0.479542 loss)
I0520 16:22:08.424705 24275 solver.cpp:237] Iteration 30000, loss = 1.03604
I0520 16:22:08.424759 24275 solver.cpp:253]     Train net output #0: loss = 1.03604 (* 1 = 1.03604 loss)
I0520 16:22:08.424775 24275 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0520 16:22:25.403594 24275 solver.cpp:237] Iteration 31500, loss = 1.25474
I0520 16:22:25.403739 24275 solver.cpp:253]     Train net output #0: loss = 1.25474 (* 1 = 1.25474 loss)
I0520 16:22:25.403753 24275 sgd_solver.cpp:106] Iteration 31500, lr = 0.0025
I0520 16:22:42.382041 24275 solver.cpp:237] Iteration 33000, loss = 1.17298
I0520 16:22:42.382084 24275 solver.cpp:253]     Train net output #0: loss = 1.17298 (* 1 = 1.17298 loss)
I0520 16:22:42.382098 24275 sgd_solver.cpp:106] Iteration 33000, lr = 0.0025
I0520 16:22:59.321338 24275 solver.cpp:237] Iteration 34500, loss = 1.28007
I0520 16:22:59.321497 24275 solver.cpp:253]     Train net output #0: loss = 1.28007 (* 1 = 1.28007 loss)
I0520 16:22:59.321511 24275 sgd_solver.cpp:106] Iteration 34500, lr = 0.0025
I0520 16:23:16.271734 24275 solver.cpp:237] Iteration 36000, loss = 1.24036
I0520 16:23:16.271770 24275 solver.cpp:253]     Train net output #0: loss = 1.24036 (* 1 = 1.24036 loss)
I0520 16:23:16.271785 24275 sgd_solver.cpp:106] Iteration 36000, lr = 0.0025
I0520 16:23:33.249481 24275 solver.cpp:237] Iteration 37500, loss = 1.68905
I0520 16:23:33.249627 24275 solver.cpp:253]     Train net output #0: loss = 1.68905 (* 1 = 1.68905 loss)
I0520 16:23:33.249641 24275 sgd_solver.cpp:106] Iteration 37500, lr = 0.0025
I0520 16:23:50.201769 24275 solver.cpp:237] Iteration 39000, loss = 0.713044
I0520 16:23:50.201819 24275 solver.cpp:253]     Train net output #0: loss = 0.713043 (* 1 = 0.713043 loss)
I0520 16:23:50.201833 24275 sgd_solver.cpp:106] Iteration 39000, lr = 0.0025
I0520 16:24:29.265604 24275 solver.cpp:237] Iteration 40500, loss = 1.97268
I0520 16:24:29.265766 24275 solver.cpp:253]     Train net output #0: loss = 1.97268 (* 1 = 1.97268 loss)
I0520 16:24:29.265780 24275 sgd_solver.cpp:106] Iteration 40500, lr = 0.0025
I0520 16:24:46.201786 24275 solver.cpp:237] Iteration 42000, loss = 1.0709
I0520 16:24:46.201830 24275 solver.cpp:253]     Train net output #0: loss = 1.07089 (* 1 = 1.07089 loss)
I0520 16:24:46.201844 24275 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0520 16:25:03.178974 24275 solver.cpp:237] Iteration 43500, loss = 1.54757
I0520 16:25:03.179142 24275 solver.cpp:253]     Train net output #0: loss = 1.54757 (* 1 = 1.54757 loss)
I0520 16:25:03.179157 24275 sgd_solver.cpp:106] Iteration 43500, lr = 0.0025
I0520 16:25:20.120926 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_45000.caffemodel
I0520 16:25:20.167964 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_45000.solverstate
I0520 16:25:20.199410 24275 solver.cpp:237] Iteration 45000, loss = 0.515768
I0520 16:25:20.199463 24275 solver.cpp:253]     Train net output #0: loss = 0.515767 (* 1 = 0.515767 loss)
I0520 16:25:20.199478 24275 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0520 16:25:37.145586 24275 solver.cpp:237] Iteration 46500, loss = 0.999021
I0520 16:25:37.145743 24275 solver.cpp:253]     Train net output #0: loss = 0.99902 (* 1 = 0.99902 loss)
I0520 16:25:37.145758 24275 sgd_solver.cpp:106] Iteration 46500, lr = 0.0025
I0520 16:25:54.087833 24275 solver.cpp:237] Iteration 48000, loss = 1.34207
I0520 16:25:54.087877 24275 solver.cpp:253]     Train net output #0: loss = 1.34207 (* 1 = 1.34207 loss)
I0520 16:25:54.087893 24275 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0520 16:26:11.037137 24275 solver.cpp:237] Iteration 49500, loss = 1.2232
I0520 16:26:11.037274 24275 solver.cpp:253]     Train net output #0: loss = 1.2232 (* 1 = 1.2232 loss)
I0520 16:26:11.037287 24275 sgd_solver.cpp:106] Iteration 49500, lr = 0.0025
I0520 16:26:50.108268 24275 solver.cpp:237] Iteration 51000, loss = 1.05446
I0520 16:26:50.108431 24275 solver.cpp:253]     Train net output #0: loss = 1.05445 (* 1 = 1.05445 loss)
I0520 16:26:50.108445 24275 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0520 16:27:07.042146 24275 solver.cpp:237] Iteration 52500, loss = 0.31034
I0520 16:27:07.042191 24275 solver.cpp:253]     Train net output #0: loss = 0.310339 (* 1 = 0.310339 loss)
I0520 16:27:07.042207 24275 sgd_solver.cpp:106] Iteration 52500, lr = 0.0025
I0520 16:27:23.835055 24275 solver.cpp:237] Iteration 54000, loss = 1.70796
I0520 16:27:23.835192 24275 solver.cpp:253]     Train net output #0: loss = 1.70796 (* 1 = 1.70796 loss)
I0520 16:27:23.835206 24275 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0520 16:27:40.595998 24275 solver.cpp:237] Iteration 55500, loss = 0.804463
I0520 16:27:40.596047 24275 solver.cpp:253]     Train net output #0: loss = 0.804461 (* 1 = 0.804461 loss)
I0520 16:27:40.596061 24275 sgd_solver.cpp:106] Iteration 55500, lr = 0.0025
I0520 16:27:57.381872 24275 solver.cpp:237] Iteration 57000, loss = 1.23276
I0520 16:27:57.382026 24275 solver.cpp:253]     Train net output #0: loss = 1.23276 (* 1 = 1.23276 loss)
I0520 16:27:57.382040 24275 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0520 16:28:14.192850 24275 solver.cpp:237] Iteration 58500, loss = 1.37767
I0520 16:28:14.192888 24275 solver.cpp:253]     Train net output #0: loss = 1.37767 (* 1 = 1.37767 loss)
I0520 16:28:14.192900 24275 sgd_solver.cpp:106] Iteration 58500, lr = 0.0025
I0520 16:28:30.967720 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_60000.caffemodel
I0520 16:28:31.015530 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_60000.solverstate
I0520 16:28:31.043797 24275 solver.cpp:341] Iteration 60000, Testing net (#0)
I0520 16:29:51.433810 24275 solver.cpp:409]     Test net output #0: accuracy = 0.868612
I0520 16:29:51.434000 24275 solver.cpp:409]     Test net output #1: loss = 0.487744 (* 1 = 0.487744 loss)
I0520 16:30:13.555717 24275 solver.cpp:237] Iteration 60000, loss = 1.27221
I0520 16:30:13.555769 24275 solver.cpp:253]     Train net output #0: loss = 1.27221 (* 1 = 1.27221 loss)
I0520 16:30:13.555784 24275 sgd_solver.cpp:106] Iteration 60000, lr = 0.0025
I0520 16:30:30.608640 24275 solver.cpp:237] Iteration 61500, loss = 1.17467
I0520 16:30:30.608803 24275 solver.cpp:253]     Train net output #0: loss = 1.17467 (* 1 = 1.17467 loss)
I0520 16:30:30.608816 24275 sgd_solver.cpp:106] Iteration 61500, lr = 0.0025
I0520 16:30:47.613715 24275 solver.cpp:237] Iteration 63000, loss = 1.05642
I0520 16:30:47.613751 24275 solver.cpp:253]     Train net output #0: loss = 1.05642 (* 1 = 1.05642 loss)
I0520 16:30:47.613765 24275 sgd_solver.cpp:106] Iteration 63000, lr = 0.0025
I0520 16:31:04.672487 24275 solver.cpp:237] Iteration 64500, loss = 0.959655
I0520 16:31:04.672637 24275 solver.cpp:253]     Train net output #0: loss = 0.959653 (* 1 = 0.959653 loss)
I0520 16:31:04.672651 24275 sgd_solver.cpp:106] Iteration 64500, lr = 0.0025
I0520 16:31:21.684391 24275 solver.cpp:237] Iteration 66000, loss = 1.12646
I0520 16:31:21.684434 24275 solver.cpp:253]     Train net output #0: loss = 1.12645 (* 1 = 1.12645 loss)
I0520 16:31:21.684450 24275 sgd_solver.cpp:106] Iteration 66000, lr = 0.0025
I0520 16:31:38.749544 24275 solver.cpp:237] Iteration 67500, loss = 0.852412
I0520 16:31:38.749683 24275 solver.cpp:253]     Train net output #0: loss = 0.852408 (* 1 = 0.852408 loss)
I0520 16:31:38.749697 24275 sgd_solver.cpp:106] Iteration 67500, lr = 0.0025
I0520 16:31:55.797610 24275 solver.cpp:237] Iteration 69000, loss = 0.84049
I0520 16:31:55.797658 24275 solver.cpp:253]     Train net output #0: loss = 0.840487 (* 1 = 0.840487 loss)
I0520 16:31:55.797673 24275 sgd_solver.cpp:106] Iteration 69000, lr = 0.0025
I0520 16:32:34.965361 24275 solver.cpp:237] Iteration 70500, loss = 1.06992
I0520 16:32:34.965526 24275 solver.cpp:253]     Train net output #0: loss = 1.06992 (* 1 = 1.06992 loss)
I0520 16:32:34.965540 24275 sgd_solver.cpp:106] Iteration 70500, lr = 0.0025
I0520 16:32:52.030894 24275 solver.cpp:237] Iteration 72000, loss = 1.0486
I0520 16:32:52.030928 24275 solver.cpp:253]     Train net output #0: loss = 1.0486 (* 1 = 1.0486 loss)
I0520 16:32:52.030944 24275 sgd_solver.cpp:106] Iteration 72000, lr = 0.0025
I0520 16:33:09.064391 24275 solver.cpp:237] Iteration 73500, loss = 1.27029
I0520 16:33:09.064541 24275 solver.cpp:253]     Train net output #0: loss = 1.27028 (* 1 = 1.27028 loss)
I0520 16:33:09.064555 24275 sgd_solver.cpp:106] Iteration 73500, lr = 0.0025
I0520 16:33:26.087792 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_75000.caffemodel
I0520 16:33:26.135618 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_75000.solverstate
I0520 16:33:26.167196 24275 solver.cpp:237] Iteration 75000, loss = 1.34603
I0520 16:33:26.167240 24275 solver.cpp:253]     Train net output #0: loss = 1.34602 (* 1 = 1.34602 loss)
I0520 16:33:26.167259 24275 sgd_solver.cpp:106] Iteration 75000, lr = 0.0025
I0520 16:33:43.213924 24275 solver.cpp:237] Iteration 76500, loss = 1.85902
I0520 16:33:43.214071 24275 solver.cpp:253]     Train net output #0: loss = 1.85902 (* 1 = 1.85902 loss)
I0520 16:33:43.214084 24275 sgd_solver.cpp:106] Iteration 76500, lr = 0.0025
I0520 16:34:00.256531 24275 solver.cpp:237] Iteration 78000, loss = 0.748961
I0520 16:34:00.256579 24275 solver.cpp:253]     Train net output #0: loss = 0.748958 (* 1 = 0.748958 loss)
I0520 16:34:00.256593 24275 sgd_solver.cpp:106] Iteration 78000, lr = 0.0025
I0520 16:34:17.308240 24275 solver.cpp:237] Iteration 79500, loss = 1.11352
I0520 16:34:17.308395 24275 solver.cpp:253]     Train net output #0: loss = 1.11351 (* 1 = 1.11351 loss)
I0520 16:34:17.308409 24275 sgd_solver.cpp:106] Iteration 79500, lr = 0.0025
I0520 16:34:56.519408 24275 solver.cpp:237] Iteration 81000, loss = 1.48431
I0520 16:34:56.519593 24275 solver.cpp:253]     Train net output #0: loss = 1.48431 (* 1 = 1.48431 loss)
I0520 16:34:56.519606 24275 sgd_solver.cpp:106] Iteration 81000, lr = 0.0025
I0520 16:35:13.544991 24275 solver.cpp:237] Iteration 82500, loss = 0.765082
I0520 16:35:13.545033 24275 solver.cpp:253]     Train net output #0: loss = 0.76508 (* 1 = 0.76508 loss)
I0520 16:35:13.545048 24275 sgd_solver.cpp:106] Iteration 82500, lr = 0.0025
I0520 16:35:30.582388 24275 solver.cpp:237] Iteration 84000, loss = 1.19677
I0520 16:35:30.582540 24275 solver.cpp:253]     Train net output #0: loss = 1.19677 (* 1 = 1.19677 loss)
I0520 16:35:30.582552 24275 sgd_solver.cpp:106] Iteration 84000, lr = 0.0025
I0520 16:35:47.646702 24275 solver.cpp:237] Iteration 85500, loss = 1.85745
I0520 16:35:47.646738 24275 solver.cpp:253]     Train net output #0: loss = 1.85745 (* 1 = 1.85745 loss)
I0520 16:35:47.646751 24275 sgd_solver.cpp:106] Iteration 85500, lr = 0.0025
I0520 16:36:04.679662 24275 solver.cpp:237] Iteration 87000, loss = 1.51994
I0520 16:36:04.679814 24275 solver.cpp:253]     Train net output #0: loss = 1.51993 (* 1 = 1.51993 loss)
I0520 16:36:04.679827 24275 sgd_solver.cpp:106] Iteration 87000, lr = 0.0025
I0520 16:36:21.683920 24275 solver.cpp:237] Iteration 88500, loss = 1.04191
I0520 16:36:21.683965 24275 solver.cpp:253]     Train net output #0: loss = 1.04191 (* 1 = 1.04191 loss)
I0520 16:36:21.683980 24275 sgd_solver.cpp:106] Iteration 88500, lr = 0.0025
I0520 16:36:38.727082 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_90000.caffemodel
I0520 16:36:38.776751 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_90000.solverstate
I0520 16:36:38.803174 24275 solver.cpp:341] Iteration 90000, Testing net (#0)
I0520 16:37:38.140169 24275 solver.cpp:409]     Test net output #0: accuracy = 0.872107
I0520 16:37:38.140341 24275 solver.cpp:409]     Test net output #1: loss = 0.408809 (* 1 = 0.408809 loss)
I0520 16:38:00.282202 24275 solver.cpp:237] Iteration 90000, loss = 0.994239
I0520 16:38:00.282254 24275 solver.cpp:253]     Train net output #0: loss = 0.994235 (* 1 = 0.994235 loss)
I0520 16:38:00.282269 24275 sgd_solver.cpp:106] Iteration 90000, lr = 0.0025
I0520 16:38:17.206912 24275 solver.cpp:237] Iteration 91500, loss = 0.637144
I0520 16:38:17.207067 24275 solver.cpp:253]     Train net output #0: loss = 0.63714 (* 1 = 0.63714 loss)
I0520 16:38:17.207080 24275 sgd_solver.cpp:106] Iteration 91500, lr = 0.0025
I0520 16:38:34.075875 24275 solver.cpp:237] Iteration 93000, loss = 0.876588
I0520 16:38:34.075923 24275 solver.cpp:253]     Train net output #0: loss = 0.876583 (* 1 = 0.876583 loss)
I0520 16:38:34.075938 24275 sgd_solver.cpp:106] Iteration 93000, lr = 0.0025
I0520 16:38:50.955158 24275 solver.cpp:237] Iteration 94500, loss = 2.2924
I0520 16:38:50.955314 24275 solver.cpp:253]     Train net output #0: loss = 2.29239 (* 1 = 2.29239 loss)
I0520 16:38:50.955327 24275 sgd_solver.cpp:106] Iteration 94500, lr = 0.0025
I0520 16:39:07.786280 24275 solver.cpp:237] Iteration 96000, loss = 0.842044
I0520 16:39:07.786317 24275 solver.cpp:253]     Train net output #0: loss = 0.84204 (* 1 = 0.84204 loss)
I0520 16:39:07.786332 24275 sgd_solver.cpp:106] Iteration 96000, lr = 0.0025
I0520 16:39:24.680299 24275 solver.cpp:237] Iteration 97500, loss = 1.37728
I0520 16:39:24.680447 24275 solver.cpp:253]     Train net output #0: loss = 1.37728 (* 1 = 1.37728 loss)
I0520 16:39:24.680461 24275 sgd_solver.cpp:106] Iteration 97500, lr = 0.0025
I0520 16:39:41.505611 24275 solver.cpp:237] Iteration 99000, loss = 0.614334
I0520 16:39:41.505661 24275 solver.cpp:253]     Train net output #0: loss = 0.61433 (* 1 = 0.61433 loss)
I0520 16:39:41.505676 24275 sgd_solver.cpp:106] Iteration 99000, lr = 0.0025
I0520 16:40:20.538431 24275 solver.cpp:237] Iteration 100500, loss = 1.14177
I0520 16:40:20.538610 24275 solver.cpp:253]     Train net output #0: loss = 1.14176 (* 1 = 1.14176 loss)
I0520 16:40:20.538624 24275 sgd_solver.cpp:106] Iteration 100500, lr = 0.0025
I0520 16:40:37.444978 24275 solver.cpp:237] Iteration 102000, loss = 1.1364
I0520 16:40:37.445024 24275 solver.cpp:253]     Train net output #0: loss = 1.1364 (* 1 = 1.1364 loss)
I0520 16:40:37.445039 24275 sgd_solver.cpp:106] Iteration 102000, lr = 0.0025
I0520 16:40:54.264325 24275 solver.cpp:237] Iteration 103500, loss = 0.733711
I0520 16:40:54.264479 24275 solver.cpp:253]     Train net output #0: loss = 0.733706 (* 1 = 0.733706 loss)
I0520 16:40:54.264493 24275 sgd_solver.cpp:106] Iteration 103500, lr = 0.0025
I0520 16:41:11.137931 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_105000.caffemodel
I0520 16:41:11.183292 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_105000.solverstate
I0520 16:41:11.211598 24275 solver.cpp:237] Iteration 105000, loss = 1.39839
I0520 16:41:11.211638 24275 solver.cpp:253]     Train net output #0: loss = 1.39839 (* 1 = 1.39839 loss)
I0520 16:41:11.211652 24275 sgd_solver.cpp:106] Iteration 105000, lr = 0.0025
I0520 16:41:28.070142 24275 solver.cpp:237] Iteration 106500, loss = 0.782703
I0520 16:41:28.070303 24275 solver.cpp:253]     Train net output #0: loss = 0.782698 (* 1 = 0.782698 loss)
I0520 16:41:28.070317 24275 sgd_solver.cpp:106] Iteration 106500, lr = 0.0025
I0520 16:41:45.007848 24275 solver.cpp:237] Iteration 108000, loss = 1.41795
I0520 16:41:45.007891 24275 solver.cpp:253]     Train net output #0: loss = 1.41794 (* 1 = 1.41794 loss)
I0520 16:41:45.007907 24275 sgd_solver.cpp:106] Iteration 108000, lr = 0.0025
I0520 16:42:01.914753 24275 solver.cpp:237] Iteration 109500, loss = 1.42349
I0520 16:42:01.914906 24275 solver.cpp:253]     Train net output #0: loss = 1.42349 (* 1 = 1.42349 loss)
I0520 16:42:01.914919 24275 sgd_solver.cpp:106] Iteration 109500, lr = 0.0025
I0520 16:42:40.956609 24275 solver.cpp:237] Iteration 111000, loss = 1.48461
I0520 16:42:40.956786 24275 solver.cpp:253]     Train net output #0: loss = 1.4846 (* 1 = 1.4846 loss)
I0520 16:42:40.956801 24275 sgd_solver.cpp:106] Iteration 111000, lr = 0.0025
I0520 16:42:57.820276 24275 solver.cpp:237] Iteration 112500, loss = 2.0821
I0520 16:42:57.820324 24275 solver.cpp:253]     Train net output #0: loss = 2.08209 (* 1 = 2.08209 loss)
I0520 16:42:57.820339 24275 sgd_solver.cpp:106] Iteration 112500, lr = 0.0025
I0520 16:43:14.704820 24275 solver.cpp:237] Iteration 114000, loss = 1.76642
I0520 16:43:14.704977 24275 solver.cpp:253]     Train net output #0: loss = 1.76641 (* 1 = 1.76641 loss)
I0520 16:43:14.704991 24275 sgd_solver.cpp:106] Iteration 114000, lr = 0.0025
I0520 16:43:31.553499 24275 solver.cpp:237] Iteration 115500, loss = 1.94082
I0520 16:43:31.553549 24275 solver.cpp:253]     Train net output #0: loss = 1.94081 (* 1 = 1.94081 loss)
I0520 16:43:31.553562 24275 sgd_solver.cpp:106] Iteration 115500, lr = 0.0025
I0520 16:43:48.422516 24275 solver.cpp:237] Iteration 117000, loss = 1.28409
I0520 16:43:48.422674 24275 solver.cpp:253]     Train net output #0: loss = 1.28409 (* 1 = 1.28409 loss)
I0520 16:43:48.422688 24275 sgd_solver.cpp:106] Iteration 117000, lr = 0.0025
I0520 16:44:05.336549 24275 solver.cpp:237] Iteration 118500, loss = 1.00288
I0520 16:44:05.336585 24275 solver.cpp:253]     Train net output #0: loss = 1.00288 (* 1 = 1.00288 loss)
I0520 16:44:05.336601 24275 sgd_solver.cpp:106] Iteration 118500, lr = 0.0025
I0520 16:44:22.192119 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_120000.caffemodel
I0520 16:44:22.237879 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_120000.solverstate
I0520 16:44:22.263200 24275 solver.cpp:341] Iteration 120000, Testing net (#0)
I0520 16:45:42.783893 24275 solver.cpp:409]     Test net output #0: accuracy = 0.876693
I0520 16:45:42.784060 24275 solver.cpp:409]     Test net output #1: loss = 0.394427 (* 1 = 0.394427 loss)
I0520 16:46:04.906468 24275 solver.cpp:237] Iteration 120000, loss = 1.34319
I0520 16:46:04.906519 24275 solver.cpp:253]     Train net output #0: loss = 1.34318 (* 1 = 1.34318 loss)
I0520 16:46:04.906534 24275 sgd_solver.cpp:106] Iteration 120000, lr = 0.0025
I0520 16:46:21.696862 24275 solver.cpp:237] Iteration 121500, loss = 1.09988
I0520 16:46:21.697028 24275 solver.cpp:253]     Train net output #0: loss = 1.09987 (* 1 = 1.09987 loss)
I0520 16:46:21.697041 24275 sgd_solver.cpp:106] Iteration 121500, lr = 0.0025
I0520 16:46:38.470010 24275 solver.cpp:237] Iteration 123000, loss = 1.11282
I0520 16:46:38.470046 24275 solver.cpp:253]     Train net output #0: loss = 1.11282 (* 1 = 1.11282 loss)
I0520 16:46:38.470062 24275 sgd_solver.cpp:106] Iteration 123000, lr = 0.0025
I0520 16:46:55.256824 24275 solver.cpp:237] Iteration 124500, loss = 0.763574
I0520 16:46:55.256973 24275 solver.cpp:253]     Train net output #0: loss = 0.763567 (* 1 = 0.763567 loss)
I0520 16:46:55.256988 24275 sgd_solver.cpp:106] Iteration 124500, lr = 0.0025
I0520 16:47:12.039635 24275 solver.cpp:237] Iteration 126000, loss = 0.315361
I0520 16:47:12.039675 24275 solver.cpp:253]     Train net output #0: loss = 0.315354 (* 1 = 0.315354 loss)
I0520 16:47:12.039690 24275 sgd_solver.cpp:106] Iteration 126000, lr = 0.0025
I0520 16:47:28.804744 24275 solver.cpp:237] Iteration 127500, loss = 0.865267
I0520 16:47:28.804888 24275 solver.cpp:253]     Train net output #0: loss = 0.865261 (* 1 = 0.865261 loss)
I0520 16:47:28.804903 24275 sgd_solver.cpp:106] Iteration 127500, lr = 0.0025
I0520 16:47:45.554132 24275 solver.cpp:237] Iteration 129000, loss = 1.79706
I0520 16:47:45.554180 24275 solver.cpp:253]     Train net output #0: loss = 1.79705 (* 1 = 1.79705 loss)
I0520 16:47:45.554194 24275 sgd_solver.cpp:106] Iteration 129000, lr = 0.0025
I0520 16:48:24.446759 24275 solver.cpp:237] Iteration 130500, loss = 1.54859
I0520 16:48:24.446924 24275 solver.cpp:253]     Train net output #0: loss = 1.54859 (* 1 = 1.54859 loss)
I0520 16:48:24.446938 24275 sgd_solver.cpp:106] Iteration 130500, lr = 0.0025
I0520 16:48:41.230761 24275 solver.cpp:237] Iteration 132000, loss = 0.735263
I0520 16:48:41.230798 24275 solver.cpp:253]     Train net output #0: loss = 0.735258 (* 1 = 0.735258 loss)
I0520 16:48:41.230811 24275 sgd_solver.cpp:106] Iteration 132000, lr = 0.0025
I0520 16:48:58.021669 24275 solver.cpp:237] Iteration 133500, loss = 0.585388
I0520 16:48:58.021836 24275 solver.cpp:253]     Train net output #0: loss = 0.585382 (* 1 = 0.585382 loss)
I0520 16:48:58.021850 24275 sgd_solver.cpp:106] Iteration 133500, lr = 0.0025
I0520 16:49:14.773068 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_135000.caffemodel
I0520 16:49:14.820528 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_135000.solverstate
I0520 16:49:14.850931 24275 solver.cpp:237] Iteration 135000, loss = 2.02814
I0520 16:49:14.850980 24275 solver.cpp:253]     Train net output #0: loss = 2.02813 (* 1 = 2.02813 loss)
I0520 16:49:14.850996 24275 sgd_solver.cpp:106] Iteration 135000, lr = 0.0025
I0520 16:49:31.645136 24275 solver.cpp:237] Iteration 136500, loss = 1.25138
I0520 16:49:31.645288 24275 solver.cpp:253]     Train net output #0: loss = 1.25138 (* 1 = 1.25138 loss)
I0520 16:49:31.645301 24275 sgd_solver.cpp:106] Iteration 136500, lr = 0.0025
I0520 16:49:48.530621 24275 solver.cpp:237] Iteration 138000, loss = 1.66645
I0520 16:49:48.530669 24275 solver.cpp:253]     Train net output #0: loss = 1.66644 (* 1 = 1.66644 loss)
I0520 16:49:48.530683 24275 sgd_solver.cpp:106] Iteration 138000, lr = 0.0025
I0520 16:50:05.460676 24275 solver.cpp:237] Iteration 139500, loss = 1.62484
I0520 16:50:05.460853 24275 solver.cpp:253]     Train net output #0: loss = 1.62483 (* 1 = 1.62483 loss)
I0520 16:50:05.460867 24275 sgd_solver.cpp:106] Iteration 139500, lr = 0.0025
I0520 16:50:44.545562 24275 solver.cpp:237] Iteration 141000, loss = 0.801931
I0520 16:50:44.545735 24275 solver.cpp:253]     Train net output #0: loss = 0.801925 (* 1 = 0.801925 loss)
I0520 16:50:44.545750 24275 sgd_solver.cpp:106] Iteration 141000, lr = 0.0025
I0520 16:51:01.404211 24275 solver.cpp:237] Iteration 142500, loss = 1.2332
I0520 16:51:01.404256 24275 solver.cpp:253]     Train net output #0: loss = 1.23319 (* 1 = 1.23319 loss)
I0520 16:51:01.404271 24275 sgd_solver.cpp:106] Iteration 142500, lr = 0.0025
I0520 16:51:18.305881 24275 solver.cpp:237] Iteration 144000, loss = 1.0255
I0520 16:51:18.306033 24275 solver.cpp:253]     Train net output #0: loss = 1.0255 (* 1 = 1.0255 loss)
I0520 16:51:18.306046 24275 sgd_solver.cpp:106] Iteration 144000, lr = 0.0025
I0520 16:51:35.193999 24275 solver.cpp:237] Iteration 145500, loss = 0.6827
I0520 16:51:35.194036 24275 solver.cpp:253]     Train net output #0: loss = 0.682693 (* 1 = 0.682693 loss)
I0520 16:51:35.194049 24275 sgd_solver.cpp:106] Iteration 145500, lr = 0.0025
I0520 16:51:52.084359 24275 solver.cpp:237] Iteration 147000, loss = 1.28814
I0520 16:51:52.084532 24275 solver.cpp:253]     Train net output #0: loss = 1.28813 (* 1 = 1.28813 loss)
I0520 16:51:52.084545 24275 sgd_solver.cpp:106] Iteration 147000, lr = 0.0025
I0520 16:52:08.941328 24275 solver.cpp:237] Iteration 148500, loss = 0.874983
I0520 16:52:08.941378 24275 solver.cpp:253]     Train net output #0: loss = 0.874977 (* 1 = 0.874977 loss)
I0520 16:52:08.941393 24275 sgd_solver.cpp:106] Iteration 148500, lr = 0.0025
I0520 16:52:25.767948 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_150000.caffemodel
I0520 16:52:25.815233 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_150000.solverstate
I0520 16:52:25.842594 24275 solver.cpp:341] Iteration 150000, Testing net (#0)
I0520 16:53:25.501675 24275 solver.cpp:409]     Test net output #0: accuracy = 0.885362
I0520 16:53:25.501834 24275 solver.cpp:409]     Test net output #1: loss = 0.390103 (* 1 = 0.390103 loss)
I0520 16:53:46.316053 24275 solver.cpp:237] Iteration 150000, loss = 1.43212
I0520 16:53:46.316109 24275 solver.cpp:253]     Train net output #0: loss = 1.43211 (* 1 = 1.43211 loss)
I0520 16:53:46.316126 24275 sgd_solver.cpp:106] Iteration 150000, lr = 0.0025
I0520 16:54:02.955265 24275 solver.cpp:237] Iteration 151500, loss = 0.935184
I0520 16:54:02.955421 24275 solver.cpp:253]     Train net output #0: loss = 0.935177 (* 1 = 0.935177 loss)
I0520 16:54:02.955435 24275 sgd_solver.cpp:106] Iteration 151500, lr = 0.0025
I0520 16:54:19.591954 24275 solver.cpp:237] Iteration 153000, loss = 0.778868
I0520 16:54:19.592001 24275 solver.cpp:253]     Train net output #0: loss = 0.778861 (* 1 = 0.778861 loss)
I0520 16:54:19.592016 24275 sgd_solver.cpp:106] Iteration 153000, lr = 0.0025
I0520 16:54:36.205582 24275 solver.cpp:237] Iteration 154500, loss = 1.278
I0520 16:54:36.217541 24275 solver.cpp:253]     Train net output #0: loss = 1.27799 (* 1 = 1.27799 loss)
I0520 16:54:36.217560 24275 sgd_solver.cpp:106] Iteration 154500, lr = 0.0025
I0520 16:54:52.818034 24275 solver.cpp:237] Iteration 156000, loss = 0.813214
I0520 16:54:52.818071 24275 solver.cpp:253]     Train net output #0: loss = 0.813207 (* 1 = 0.813207 loss)
I0520 16:54:52.818085 24275 sgd_solver.cpp:106] Iteration 156000, lr = 0.0025
I0520 16:55:09.417312 24275 solver.cpp:237] Iteration 157500, loss = 1.19276
I0520 16:55:09.417471 24275 solver.cpp:253]     Train net output #0: loss = 1.19276 (* 1 = 1.19276 loss)
I0520 16:55:09.417484 24275 sgd_solver.cpp:106] Iteration 157500, lr = 0.0025
I0520 16:55:26.041856 24275 solver.cpp:237] Iteration 159000, loss = 1.41451
I0520 16:55:26.041893 24275 solver.cpp:253]     Train net output #0: loss = 1.41451 (* 1 = 1.41451 loss)
I0520 16:55:26.041905 24275 sgd_solver.cpp:106] Iteration 159000, lr = 0.0025
I0520 16:56:03.500469 24275 solver.cpp:237] Iteration 160500, loss = 0.73333
I0520 16:56:03.500658 24275 solver.cpp:253]     Train net output #0: loss = 0.733323 (* 1 = 0.733323 loss)
I0520 16:56:03.500671 24275 sgd_solver.cpp:106] Iteration 160500, lr = 0.0025
I0520 16:56:20.124423 24275 solver.cpp:237] Iteration 162000, loss = 1.19404
I0520 16:56:20.124469 24275 solver.cpp:253]     Train net output #0: loss = 1.19403 (* 1 = 1.19403 loss)
I0520 16:56:20.124482 24275 sgd_solver.cpp:106] Iteration 162000, lr = 0.0025
I0520 16:56:36.741123 24275 solver.cpp:237] Iteration 163500, loss = 1.42407
I0520 16:56:36.741271 24275 solver.cpp:253]     Train net output #0: loss = 1.42407 (* 1 = 1.42407 loss)
I0520 16:56:36.741284 24275 sgd_solver.cpp:106] Iteration 163500, lr = 0.0025
I0520 16:56:53.333843 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_165000.caffemodel
I0520 16:56:53.379920 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_165000.solverstate
I0520 16:56:53.408283 24275 solver.cpp:237] Iteration 165000, loss = 1.13872
I0520 16:56:53.408329 24275 solver.cpp:253]     Train net output #0: loss = 1.13871 (* 1 = 1.13871 loss)
I0520 16:56:53.408342 24275 sgd_solver.cpp:106] Iteration 165000, lr = 0.0025
I0520 16:57:10.041086 24275 solver.cpp:237] Iteration 166500, loss = 0.980968
I0520 16:57:10.041254 24275 solver.cpp:253]     Train net output #0: loss = 0.980961 (* 1 = 0.980961 loss)
I0520 16:57:10.041270 24275 sgd_solver.cpp:106] Iteration 166500, lr = 0.0025
I0520 16:57:26.680435 24275 solver.cpp:237] Iteration 168000, loss = 1.2325
I0520 16:57:26.680471 24275 solver.cpp:253]     Train net output #0: loss = 1.23249 (* 1 = 1.23249 loss)
I0520 16:57:26.680487 24275 sgd_solver.cpp:106] Iteration 168000, lr = 0.0025
I0520 16:57:43.326419 24275 solver.cpp:237] Iteration 169500, loss = 0.795032
I0520 16:57:43.326578 24275 solver.cpp:253]     Train net output #0: loss = 0.795025 (* 1 = 0.795025 loss)
I0520 16:57:43.326591 24275 sgd_solver.cpp:106] Iteration 169500, lr = 0.0025
I0520 16:58:20.792291 24275 solver.cpp:237] Iteration 171000, loss = 1.58776
I0520 16:58:20.792459 24275 solver.cpp:253]     Train net output #0: loss = 1.58775 (* 1 = 1.58775 loss)
I0520 16:58:20.792474 24275 sgd_solver.cpp:106] Iteration 171000, lr = 0.0025
I0520 16:58:37.403162 24275 solver.cpp:237] Iteration 172500, loss = 1.35856
I0520 16:58:37.403208 24275 solver.cpp:253]     Train net output #0: loss = 1.35855 (* 1 = 1.35855 loss)
I0520 16:58:37.403221 24275 sgd_solver.cpp:106] Iteration 172500, lr = 0.0025
I0520 16:58:54.009441 24275 solver.cpp:237] Iteration 174000, loss = 1.51179
I0520 16:58:54.009615 24275 solver.cpp:253]     Train net output #0: loss = 1.51178 (* 1 = 1.51178 loss)
I0520 16:58:54.009629 24275 sgd_solver.cpp:106] Iteration 174000, lr = 0.0025
I0520 16:59:10.649588 24275 solver.cpp:237] Iteration 175500, loss = 1.0454
I0520 16:59:10.649624 24275 solver.cpp:253]     Train net output #0: loss = 1.04539 (* 1 = 1.04539 loss)
I0520 16:59:10.649638 24275 sgd_solver.cpp:106] Iteration 175500, lr = 0.0025
I0520 16:59:27.270902 24275 solver.cpp:237] Iteration 177000, loss = 0.649845
I0520 16:59:27.271059 24275 solver.cpp:253]     Train net output #0: loss = 0.649837 (* 1 = 0.649837 loss)
I0520 16:59:27.271073 24275 sgd_solver.cpp:106] Iteration 177000, lr = 0.0025
I0520 16:59:43.897631 24275 solver.cpp:237] Iteration 178500, loss = 1.35917
I0520 16:59:43.897675 24275 solver.cpp:253]     Train net output #0: loss = 1.35916 (* 1 = 1.35916 loss)
I0520 16:59:43.897689 24275 sgd_solver.cpp:106] Iteration 178500, lr = 0.0025
I0520 17:00:00.522320 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_180000.caffemodel
I0520 17:00:00.567942 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_180000.solverstate
I0520 17:00:00.593217 24275 solver.cpp:341] Iteration 180000, Testing net (#0)
I0520 17:01:21.087721 24275 solver.cpp:409]     Test net output #0: accuracy = 0.886172
I0520 17:01:21.087889 24275 solver.cpp:409]     Test net output #1: loss = 0.36169 (* 1 = 0.36169 loss)
I0520 17:01:41.873978 24275 solver.cpp:237] Iteration 180000, loss = 0.993384
I0520 17:01:41.874032 24275 solver.cpp:253]     Train net output #0: loss = 0.993376 (* 1 = 0.993376 loss)
I0520 17:01:41.874047 24275 sgd_solver.cpp:106] Iteration 180000, lr = 0.0025
I0520 17:01:59.042558 24275 solver.cpp:237] Iteration 181500, loss = 1.00763
I0520 17:01:59.042716 24275 solver.cpp:253]     Train net output #0: loss = 1.00762 (* 1 = 1.00762 loss)
I0520 17:01:59.042728 24275 sgd_solver.cpp:106] Iteration 181500, lr = 0.0025
I0520 17:02:16.237143 24275 solver.cpp:237] Iteration 183000, loss = 0.569587
I0520 17:02:16.237190 24275 solver.cpp:253]     Train net output #0: loss = 0.569579 (* 1 = 0.569579 loss)
I0520 17:02:16.237203 24275 sgd_solver.cpp:106] Iteration 183000, lr = 0.0025
I0520 17:02:33.403970 24275 solver.cpp:237] Iteration 184500, loss = 1.39951
I0520 17:02:33.404134 24275 solver.cpp:253]     Train net output #0: loss = 1.3995 (* 1 = 1.3995 loss)
I0520 17:02:33.404146 24275 sgd_solver.cpp:106] Iteration 184500, lr = 0.0025
I0520 17:02:50.602648 24275 solver.cpp:237] Iteration 186000, loss = 1.04718
I0520 17:02:50.602684 24275 solver.cpp:253]     Train net output #0: loss = 1.04718 (* 1 = 1.04718 loss)
I0520 17:02:50.602699 24275 sgd_solver.cpp:106] Iteration 186000, lr = 0.0025
I0520 17:03:07.799288 24275 solver.cpp:237] Iteration 187500, loss = 1.12379
I0520 17:03:07.799446 24275 solver.cpp:253]     Train net output #0: loss = 1.12378 (* 1 = 1.12378 loss)
I0520 17:03:07.799459 24275 sgd_solver.cpp:106] Iteration 187500, lr = 0.0025
I0520 17:03:25.025110 24275 solver.cpp:237] Iteration 189000, loss = 0.891988
I0520 17:03:25.025159 24275 solver.cpp:253]     Train net output #0: loss = 0.89198 (* 1 = 0.89198 loss)
I0520 17:03:25.025173 24275 sgd_solver.cpp:106] Iteration 189000, lr = 0.0025
I0520 17:04:03.059448 24275 solver.cpp:237] Iteration 190500, loss = 1.25233
I0520 17:04:03.059626 24275 solver.cpp:253]     Train net output #0: loss = 1.25233 (* 1 = 1.25233 loss)
I0520 17:04:03.059640 24275 sgd_solver.cpp:106] Iteration 190500, lr = 0.0025
I0520 17:04:20.216927 24275 solver.cpp:237] Iteration 192000, loss = 1.34809
I0520 17:04:20.216976 24275 solver.cpp:253]     Train net output #0: loss = 1.34808 (* 1 = 1.34808 loss)
I0520 17:04:20.216990 24275 sgd_solver.cpp:106] Iteration 192000, lr = 0.0025
I0520 17:04:37.399484 24275 solver.cpp:237] Iteration 193500, loss = 0.904259
I0520 17:04:37.399655 24275 solver.cpp:253]     Train net output #0: loss = 0.904251 (* 1 = 0.904251 loss)
I0520 17:04:37.399669 24275 sgd_solver.cpp:106] Iteration 193500, lr = 0.0025
I0520 17:04:54.578316 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_195000.caffemodel
I0520 17:04:54.623992 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_195000.solverstate
I0520 17:04:54.654227 24275 solver.cpp:237] Iteration 195000, loss = 0.626608
I0520 17:04:54.654274 24275 solver.cpp:253]     Train net output #0: loss = 0.626601 (* 1 = 0.626601 loss)
I0520 17:04:54.654289 24275 sgd_solver.cpp:106] Iteration 195000, lr = 0.0025
I0520 17:05:11.813274 24275 solver.cpp:237] Iteration 196500, loss = 1.12247
I0520 17:05:11.813447 24275 solver.cpp:253]     Train net output #0: loss = 1.12246 (* 1 = 1.12246 loss)
I0520 17:05:11.813462 24275 sgd_solver.cpp:106] Iteration 196500, lr = 0.0025
I0520 17:05:28.995524 24275 solver.cpp:237] Iteration 198000, loss = 1.03289
I0520 17:05:28.995565 24275 solver.cpp:253]     Train net output #0: loss = 1.03288 (* 1 = 1.03288 loss)
I0520 17:05:28.995581 24275 sgd_solver.cpp:106] Iteration 198000, lr = 0.0025
I0520 17:05:46.189955 24275 solver.cpp:237] Iteration 199500, loss = 1.08571
I0520 17:05:46.190104 24275 solver.cpp:253]     Train net output #0: loss = 1.0857 (* 1 = 1.0857 loss)
I0520 17:05:46.190117 24275 sgd_solver.cpp:106] Iteration 199500, lr = 0.0025
I0520 17:06:24.218197 24275 solver.cpp:237] Iteration 201000, loss = 0.993793
I0520 17:06:24.218369 24275 solver.cpp:253]     Train net output #0: loss = 0.993786 (* 1 = 0.993786 loss)
I0520 17:06:24.218384 24275 sgd_solver.cpp:106] Iteration 201000, lr = 0.0025
I0520 17:06:41.352581 24275 solver.cpp:237] Iteration 202500, loss = 0.418348
I0520 17:06:41.352634 24275 solver.cpp:253]     Train net output #0: loss = 0.418341 (* 1 = 0.418341 loss)
I0520 17:06:41.352648 24275 sgd_solver.cpp:106] Iteration 202500, lr = 0.0025
I0520 17:06:57.932245 24275 solver.cpp:237] Iteration 204000, loss = 1.24974
I0520 17:06:57.932399 24275 solver.cpp:253]     Train net output #0: loss = 1.24973 (* 1 = 1.24973 loss)
I0520 17:06:57.932411 24275 sgd_solver.cpp:106] Iteration 204000, lr = 0.0025
I0520 17:07:14.525924 24275 solver.cpp:237] Iteration 205500, loss = 0.656203
I0520 17:07:14.525972 24275 solver.cpp:253]     Train net output #0: loss = 0.656196 (* 1 = 0.656196 loss)
I0520 17:07:14.525986 24275 sgd_solver.cpp:106] Iteration 205500, lr = 0.0025
I0520 17:07:31.120312 24275 solver.cpp:237] Iteration 207000, loss = 1.21736
I0520 17:07:31.120461 24275 solver.cpp:253]     Train net output #0: loss = 1.21735 (* 1 = 1.21735 loss)
I0520 17:07:31.120474 24275 sgd_solver.cpp:106] Iteration 207000, lr = 0.0025
I0520 17:07:47.709913 24275 solver.cpp:237] Iteration 208500, loss = 1.34787
I0520 17:07:47.709950 24275 solver.cpp:253]     Train net output #0: loss = 1.34786 (* 1 = 1.34786 loss)
I0520 17:07:47.709965 24275 sgd_solver.cpp:106] Iteration 208500, lr = 0.0025
I0520 17:08:04.311677 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_210000.caffemodel
I0520 17:08:04.357303 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_210000.solverstate
I0520 17:08:04.382923 24275 solver.cpp:341] Iteration 210000, Testing net (#0)
I0520 17:09:03.569480 24275 solver.cpp:409]     Test net output #0: accuracy = 0.883394
I0520 17:09:03.569649 24275 solver.cpp:409]     Test net output #1: loss = 0.389908 (* 1 = 0.389908 loss)
I0520 17:09:24.416898 24275 solver.cpp:237] Iteration 210000, loss = 0.898221
I0520 17:09:24.416951 24275 solver.cpp:253]     Train net output #0: loss = 0.898214 (* 1 = 0.898214 loss)
I0520 17:09:24.416967 24275 sgd_solver.cpp:106] Iteration 210000, lr = 0.0025
I0520 17:09:41.301417 24275 solver.cpp:237] Iteration 211500, loss = 0.562588
I0520 17:09:41.301589 24275 solver.cpp:253]     Train net output #0: loss = 0.562581 (* 1 = 0.562581 loss)
I0520 17:09:41.301602 24275 sgd_solver.cpp:106] Iteration 211500, lr = 0.0025
I0520 17:09:58.256127 24275 solver.cpp:237] Iteration 213000, loss = 0.430741
I0520 17:09:58.256165 24275 solver.cpp:253]     Train net output #0: loss = 0.430733 (* 1 = 0.430733 loss)
I0520 17:09:58.256180 24275 sgd_solver.cpp:106] Iteration 213000, lr = 0.0025
I0520 17:10:15.218294 24275 solver.cpp:237] Iteration 214500, loss = 1.19603
I0520 17:10:15.218475 24275 solver.cpp:253]     Train net output #0: loss = 1.19602 (* 1 = 1.19602 loss)
I0520 17:10:15.218488 24275 sgd_solver.cpp:106] Iteration 214500, lr = 0.0025
I0520 17:10:32.189831 24275 solver.cpp:237] Iteration 216000, loss = 1.10059
I0520 17:10:32.189878 24275 solver.cpp:253]     Train net output #0: loss = 1.10058 (* 1 = 1.10058 loss)
I0520 17:10:32.189893 24275 sgd_solver.cpp:106] Iteration 216000, lr = 0.0025
I0520 17:10:49.171358 24275 solver.cpp:237] Iteration 217500, loss = 1.39663
I0520 17:10:49.171511 24275 solver.cpp:253]     Train net output #0: loss = 1.39662 (* 1 = 1.39662 loss)
I0520 17:10:49.171525 24275 sgd_solver.cpp:106] Iteration 217500, lr = 0.0025
I0520 17:11:06.120394 24275 solver.cpp:237] Iteration 219000, loss = 1.54642
I0520 17:11:06.120440 24275 solver.cpp:253]     Train net output #0: loss = 1.54641 (* 1 = 1.54641 loss)
I0520 17:11:06.120453 24275 sgd_solver.cpp:106] Iteration 219000, lr = 0.0025
I0520 17:11:43.911983 24275 solver.cpp:237] Iteration 220500, loss = 1.11042
I0520 17:11:43.912156 24275 solver.cpp:253]     Train net output #0: loss = 1.11041 (* 1 = 1.11041 loss)
I0520 17:11:43.912170 24275 sgd_solver.cpp:106] Iteration 220500, lr = 0.0025
I0520 17:12:00.881461 24275 solver.cpp:237] Iteration 222000, loss = 1.00007
I0520 17:12:00.881499 24275 solver.cpp:253]     Train net output #0: loss = 1.00006 (* 1 = 1.00006 loss)
I0520 17:12:00.881513 24275 sgd_solver.cpp:106] Iteration 222000, lr = 0.0025
I0520 17:12:17.863116 24275 solver.cpp:237] Iteration 223500, loss = 1.38377
I0520 17:12:17.863273 24275 solver.cpp:253]     Train net output #0: loss = 1.38376 (* 1 = 1.38376 loss)
I0520 17:12:17.863287 24275 sgd_solver.cpp:106] Iteration 223500, lr = 0.0025
I0520 17:12:34.808773 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_225000.caffemodel
I0520 17:12:34.856729 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_225000.solverstate
I0520 17:12:34.887712 24275 solver.cpp:237] Iteration 225000, loss = 1.55795
I0520 17:12:34.887763 24275 solver.cpp:253]     Train net output #0: loss = 1.55795 (* 1 = 1.55795 loss)
I0520 17:12:34.887778 24275 sgd_solver.cpp:106] Iteration 225000, lr = 0.0025
I0520 17:12:51.839594 24275 solver.cpp:237] Iteration 226500, loss = 1.64526
I0520 17:12:51.839752 24275 solver.cpp:253]     Train net output #0: loss = 1.64525 (* 1 = 1.64525 loss)
I0520 17:12:51.839766 24275 sgd_solver.cpp:106] Iteration 226500, lr = 0.0025
I0520 17:13:08.786867 24275 solver.cpp:237] Iteration 228000, loss = 0.715961
I0520 17:13:08.786916 24275 solver.cpp:253]     Train net output #0: loss = 0.715955 (* 1 = 0.715955 loss)
I0520 17:13:08.786931 24275 sgd_solver.cpp:106] Iteration 228000, lr = 0.0025
I0520 17:13:25.711848 24275 solver.cpp:237] Iteration 229500, loss = 1.5306
I0520 17:13:25.712004 24275 solver.cpp:253]     Train net output #0: loss = 1.5306 (* 1 = 1.5306 loss)
I0520 17:13:25.712018 24275 sgd_solver.cpp:106] Iteration 229500, lr = 0.0025
I0520 17:14:03.460141 24275 solver.cpp:237] Iteration 231000, loss = 0.789677
I0520 17:14:03.460319 24275 solver.cpp:253]     Train net output #0: loss = 0.789669 (* 1 = 0.789669 loss)
I0520 17:14:03.460336 24275 sgd_solver.cpp:106] Iteration 231000, lr = 0.0025
I0520 17:14:20.421511 24275 solver.cpp:237] Iteration 232500, loss = 0.98139
I0520 17:14:20.421560 24275 solver.cpp:253]     Train net output #0: loss = 0.981384 (* 1 = 0.981384 loss)
I0520 17:14:20.421574 24275 sgd_solver.cpp:106] Iteration 232500, lr = 0.0025
I0520 17:14:37.351817 24275 solver.cpp:237] Iteration 234000, loss = 1.18544
I0520 17:14:37.351975 24275 solver.cpp:253]     Train net output #0: loss = 1.18543 (* 1 = 1.18543 loss)
I0520 17:14:37.351989 24275 sgd_solver.cpp:106] Iteration 234000, lr = 0.0025
I0520 17:14:54.314939 24275 solver.cpp:237] Iteration 235500, loss = 1.03003
I0520 17:14:54.314975 24275 solver.cpp:253]     Train net output #0: loss = 1.03002 (* 1 = 1.03002 loss)
I0520 17:14:54.314988 24275 sgd_solver.cpp:106] Iteration 235500, lr = 0.0025
I0520 17:15:11.287140 24275 solver.cpp:237] Iteration 237000, loss = 1.48112
I0520 17:15:11.287309 24275 solver.cpp:253]     Train net output #0: loss = 1.48112 (* 1 = 1.48112 loss)
I0520 17:15:11.287323 24275 sgd_solver.cpp:106] Iteration 237000, lr = 0.0025
I0520 17:15:28.272588 24275 solver.cpp:237] Iteration 238500, loss = 1.2519
I0520 17:15:28.272627 24275 solver.cpp:253]     Train net output #0: loss = 1.25189 (* 1 = 1.25189 loss)
I0520 17:15:28.272646 24275 sgd_solver.cpp:106] Iteration 238500, lr = 0.0025
I0520 17:15:45.210628 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_240000.caffemodel
I0520 17:15:45.257004 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_240000.solverstate
I0520 17:15:45.282382 24275 solver.cpp:341] Iteration 240000, Testing net (#0)
I0520 17:17:05.432950 24275 solver.cpp:409]     Test net output #0: accuracy = 0.891723
I0520 17:17:05.433121 24275 solver.cpp:409]     Test net output #1: loss = 0.391476 (* 1 = 0.391476 loss)
I0520 17:17:26.239753 24275 solver.cpp:237] Iteration 240000, loss = 1.38379
I0520 17:17:26.239805 24275 solver.cpp:253]     Train net output #0: loss = 1.38379 (* 1 = 1.38379 loss)
I0520 17:17:26.239820 24275 sgd_solver.cpp:106] Iteration 240000, lr = 0.0025
I0520 17:17:43.293437 24275 solver.cpp:237] Iteration 241500, loss = 1.11615
I0520 17:17:43.293603 24275 solver.cpp:253]     Train net output #0: loss = 1.11615 (* 1 = 1.11615 loss)
I0520 17:17:43.293617 24275 sgd_solver.cpp:106] Iteration 241500, lr = 0.0025
I0520 17:18:00.361697 24275 solver.cpp:237] Iteration 243000, loss = 1.94989
I0520 17:18:00.361744 24275 solver.cpp:253]     Train net output #0: loss = 1.94988 (* 1 = 1.94988 loss)
I0520 17:18:00.361758 24275 sgd_solver.cpp:106] Iteration 243000, lr = 0.0025
I0520 17:18:17.380880 24275 solver.cpp:237] Iteration 244500, loss = 1.33484
I0520 17:18:17.381032 24275 solver.cpp:253]     Train net output #0: loss = 1.33484 (* 1 = 1.33484 loss)
I0520 17:18:17.381045 24275 sgd_solver.cpp:106] Iteration 244500, lr = 0.0025
I0520 17:18:34.429918 24275 solver.cpp:237] Iteration 246000, loss = 0.364516
I0520 17:18:34.429965 24275 solver.cpp:253]     Train net output #0: loss = 0.36451 (* 1 = 0.36451 loss)
I0520 17:18:34.429980 24275 sgd_solver.cpp:106] Iteration 246000, lr = 0.0025
I0520 17:18:51.485281 24275 solver.cpp:237] Iteration 247500, loss = 0.960864
I0520 17:18:51.485460 24275 solver.cpp:253]     Train net output #0: loss = 0.960858 (* 1 = 0.960858 loss)
I0520 17:18:51.485474 24275 sgd_solver.cpp:106] Iteration 247500, lr = 0.0025
I0520 17:19:08.532726 24275 solver.cpp:237] Iteration 249000, loss = 0.932133
I0520 17:19:08.532762 24275 solver.cpp:253]     Train net output #0: loss = 0.932127 (* 1 = 0.932127 loss)
I0520 17:19:08.532776 24275 sgd_solver.cpp:106] Iteration 249000, lr = 0.0025
I0520 17:19:46.431351 24275 solver.cpp:237] Iteration 250500, loss = 1.22991
I0520 17:19:46.431525 24275 solver.cpp:253]     Train net output #0: loss = 1.2299 (* 1 = 1.2299 loss)
I0520 17:19:46.431540 24275 sgd_solver.cpp:106] Iteration 250500, lr = 0.0025
I0520 17:20:03.516543 24275 solver.cpp:237] Iteration 252000, loss = 1.40773
I0520 17:20:03.516590 24275 solver.cpp:253]     Train net output #0: loss = 1.40773 (* 1 = 1.40773 loss)
I0520 17:20:03.516605 24275 sgd_solver.cpp:106] Iteration 252000, lr = 0.0025
I0520 17:20:20.571151 24275 solver.cpp:237] Iteration 253500, loss = 0.762685
I0520 17:20:20.571303 24275 solver.cpp:253]     Train net output #0: loss = 0.76268 (* 1 = 0.76268 loss)
I0520 17:20:20.571316 24275 sgd_solver.cpp:106] Iteration 253500, lr = 0.0025
I0520 17:20:37.580889 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_255000.caffemodel
I0520 17:20:37.627573 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_255000.solverstate
I0520 17:20:37.656810 24275 solver.cpp:237] Iteration 255000, loss = 1.46649
I0520 17:20:37.656849 24275 solver.cpp:253]     Train net output #0: loss = 1.46648 (* 1 = 1.46648 loss)
I0520 17:20:37.656862 24275 sgd_solver.cpp:106] Iteration 255000, lr = 0.0025
I0520 17:20:54.683156 24275 solver.cpp:237] Iteration 256500, loss = 1.78677
I0520 17:20:54.683347 24275 solver.cpp:253]     Train net output #0: loss = 1.78676 (* 1 = 1.78676 loss)
I0520 17:20:54.683362 24275 sgd_solver.cpp:106] Iteration 256500, lr = 0.0025
I0520 17:21:11.709648 24275 solver.cpp:237] Iteration 258000, loss = 1.2555
I0520 17:21:11.709684 24275 solver.cpp:253]     Train net output #0: loss = 1.2555 (* 1 = 1.2555 loss)
I0520 17:21:11.709699 24275 sgd_solver.cpp:106] Iteration 258000, lr = 0.0025
I0520 17:21:28.603293 24275 solver.cpp:237] Iteration 259500, loss = 0.99918
I0520 17:21:28.603454 24275 solver.cpp:253]     Train net output #0: loss = 0.999173 (* 1 = 0.999173 loss)
I0520 17:21:28.603468 24275 sgd_solver.cpp:106] Iteration 259500, lr = 0.0025
I0520 17:22:06.331290 24275 solver.cpp:237] Iteration 261000, loss = 1.42617
I0520 17:22:06.331466 24275 solver.cpp:253]     Train net output #0: loss = 1.42616 (* 1 = 1.42616 loss)
I0520 17:22:06.331480 24275 sgd_solver.cpp:106] Iteration 261000, lr = 0.0025
I0520 17:22:23.229925 24275 solver.cpp:237] Iteration 262500, loss = 1.9405
I0520 17:22:23.229961 24275 solver.cpp:253]     Train net output #0: loss = 1.94049 (* 1 = 1.94049 loss)
I0520 17:22:23.229975 24275 sgd_solver.cpp:106] Iteration 262500, lr = 0.0025
I0520 17:22:40.082811 24275 solver.cpp:237] Iteration 264000, loss = 1.65123
I0520 17:22:40.082983 24275 solver.cpp:253]     Train net output #0: loss = 1.65122 (* 1 = 1.65122 loss)
I0520 17:22:40.082998 24275 sgd_solver.cpp:106] Iteration 264000, lr = 0.0025
I0520 17:22:56.924978 24275 solver.cpp:237] Iteration 265500, loss = 1.47855
I0520 17:22:56.925024 24275 solver.cpp:253]     Train net output #0: loss = 1.47854 (* 1 = 1.47854 loss)
I0520 17:22:56.925039 24275 sgd_solver.cpp:106] Iteration 265500, lr = 0.0025
I0520 17:23:13.848562 24275 solver.cpp:237] Iteration 267000, loss = 1.33443
I0520 17:23:13.848713 24275 solver.cpp:253]     Train net output #0: loss = 1.33443 (* 1 = 1.33443 loss)
I0520 17:23:13.848727 24275 sgd_solver.cpp:106] Iteration 267000, lr = 0.0025
I0520 17:23:30.727447 24275 solver.cpp:237] Iteration 268500, loss = 1.22661
I0520 17:23:30.727494 24275 solver.cpp:253]     Train net output #0: loss = 1.22661 (* 1 = 1.22661 loss)
I0520 17:23:30.727509 24275 sgd_solver.cpp:106] Iteration 268500, lr = 0.0025
I0520 17:23:47.543954 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_270000.caffemodel
I0520 17:23:47.590020 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_270000.solverstate
I0520 17:23:47.615572 24275 solver.cpp:341] Iteration 270000, Testing net (#0)
I0520 17:24:46.967370 24275 solver.cpp:409]     Test net output #0: accuracy = 0.884388
I0520 17:24:46.967541 24275 solver.cpp:409]     Test net output #1: loss = 0.365592 (* 1 = 0.365592 loss)
I0520 17:25:07.785789 24275 solver.cpp:237] Iteration 270000, loss = 1.25976
I0520 17:25:07.785840 24275 solver.cpp:253]     Train net output #0: loss = 1.25975 (* 1 = 1.25975 loss)
I0520 17:25:07.785856 24275 sgd_solver.cpp:106] Iteration 270000, lr = 0.0025
I0520 17:25:24.717041 24275 solver.cpp:237] Iteration 271500, loss = 1.75794
I0520 17:25:24.717213 24275 solver.cpp:253]     Train net output #0: loss = 1.75794 (* 1 = 1.75794 loss)
I0520 17:25:24.717226 24275 sgd_solver.cpp:106] Iteration 271500, lr = 0.0025
I0520 17:25:41.679873 24275 solver.cpp:237] Iteration 273000, loss = 0.701385
I0520 17:25:41.679921 24275 solver.cpp:253]     Train net output #0: loss = 0.70138 (* 1 = 0.70138 loss)
I0520 17:25:41.679936 24275 sgd_solver.cpp:106] Iteration 273000, lr = 0.0025
I0520 17:25:58.617099 24275 solver.cpp:237] Iteration 274500, loss = 1.32713
I0520 17:25:58.617267 24275 solver.cpp:253]     Train net output #0: loss = 1.32713 (* 1 = 1.32713 loss)
I0520 17:25:58.617281 24275 sgd_solver.cpp:106] Iteration 274500, lr = 0.0025
I0520 17:26:15.577483 24275 solver.cpp:237] Iteration 276000, loss = 1.32194
I0520 17:26:15.577519 24275 solver.cpp:253]     Train net output #0: loss = 1.32194 (* 1 = 1.32194 loss)
I0520 17:26:15.577534 24275 sgd_solver.cpp:106] Iteration 276000, lr = 0.0025
I0520 17:26:32.553917 24275 solver.cpp:237] Iteration 277500, loss = 1.32777
I0520 17:26:32.554080 24275 solver.cpp:253]     Train net output #0: loss = 1.32776 (* 1 = 1.32776 loss)
I0520 17:26:32.554095 24275 sgd_solver.cpp:106] Iteration 277500, lr = 0.0025
I0520 17:26:49.516368 24275 solver.cpp:237] Iteration 279000, loss = 1.57248
I0520 17:26:49.516415 24275 solver.cpp:253]     Train net output #0: loss = 1.57247 (* 1 = 1.57247 loss)
I0520 17:26:49.516429 24275 sgd_solver.cpp:106] Iteration 279000, lr = 0.0025
I0520 17:27:27.245710 24275 solver.cpp:237] Iteration 280500, loss = 0.999958
I0520 17:27:27.245888 24275 solver.cpp:253]     Train net output #0: loss = 0.999954 (* 1 = 0.999954 loss)
I0520 17:27:27.245903 24275 sgd_solver.cpp:106] Iteration 280500, lr = 0.0025
I0520 17:27:44.185453 24275 solver.cpp:237] Iteration 282000, loss = 0.844247
I0520 17:27:44.185503 24275 solver.cpp:253]     Train net output #0: loss = 0.844244 (* 1 = 0.844244 loss)
I0520 17:27:44.185516 24275 sgd_solver.cpp:106] Iteration 282000, lr = 0.0025
I0520 17:28:01.111090 24275 solver.cpp:237] Iteration 283500, loss = 1.34255
I0520 17:28:01.111259 24275 solver.cpp:253]     Train net output #0: loss = 1.34254 (* 1 = 1.34254 loss)
I0520 17:28:01.111274 24275 sgd_solver.cpp:106] Iteration 283500, lr = 0.0025
I0520 17:28:18.074409 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_285000.caffemodel
I0520 17:28:18.122406 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_285000.solverstate
I0520 17:28:18.153126 24275 solver.cpp:237] Iteration 285000, loss = 1.32077
I0520 17:28:18.153175 24275 solver.cpp:253]     Train net output #0: loss = 1.32077 (* 1 = 1.32077 loss)
I0520 17:28:18.153189 24275 sgd_solver.cpp:106] Iteration 285000, lr = 0.0025
I0520 17:28:35.127243 24275 solver.cpp:237] Iteration 286500, loss = 0.848884
I0520 17:28:35.127416 24275 solver.cpp:253]     Train net output #0: loss = 0.848882 (* 1 = 0.848882 loss)
I0520 17:28:35.127430 24275 sgd_solver.cpp:106] Iteration 286500, lr = 0.0025
I0520 17:28:52.065387 24275 solver.cpp:237] Iteration 288000, loss = 1.74941
I0520 17:28:52.065433 24275 solver.cpp:253]     Train net output #0: loss = 1.74941 (* 1 = 1.74941 loss)
I0520 17:28:52.065450 24275 sgd_solver.cpp:106] Iteration 288000, lr = 0.0025
I0520 17:29:09.001277 24275 solver.cpp:237] Iteration 289500, loss = 1.32423
I0520 17:29:09.001435 24275 solver.cpp:253]     Train net output #0: loss = 1.32423 (* 1 = 1.32423 loss)
I0520 17:29:09.001447 24275 sgd_solver.cpp:106] Iteration 289500, lr = 0.0025
I0520 17:29:46.802573 24275 solver.cpp:237] Iteration 291000, loss = 1.14304
I0520 17:29:46.802844 24275 solver.cpp:253]     Train net output #0: loss = 1.14304 (* 1 = 1.14304 loss)
I0520 17:29:46.802857 24275 sgd_solver.cpp:106] Iteration 291000, lr = 0.0025
I0520 17:30:03.731942 24275 solver.cpp:237] Iteration 292500, loss = 1.58779
I0520 17:30:03.731992 24275 solver.cpp:253]     Train net output #0: loss = 1.58779 (* 1 = 1.58779 loss)
I0520 17:30:03.732007 24275 sgd_solver.cpp:106] Iteration 292500, lr = 0.0025
I0520 17:30:20.514035 24275 solver.cpp:237] Iteration 294000, loss = 1.37266
I0520 17:30:20.514202 24275 solver.cpp:253]     Train net output #0: loss = 1.37266 (* 1 = 1.37266 loss)
I0520 17:30:20.514216 24275 sgd_solver.cpp:106] Iteration 294000, lr = 0.0025
I0520 17:30:37.305702 24275 solver.cpp:237] Iteration 295500, loss = 1.19651
I0520 17:30:37.305747 24275 solver.cpp:253]     Train net output #0: loss = 1.19651 (* 1 = 1.19651 loss)
I0520 17:30:37.305762 24275 sgd_solver.cpp:106] Iteration 295500, lr = 0.0025
I0520 17:30:54.096848 24275 solver.cpp:237] Iteration 297000, loss = 1.77164
I0520 17:30:54.097030 24275 solver.cpp:253]     Train net output #0: loss = 1.77164 (* 1 = 1.77164 loss)
I0520 17:30:54.097044 24275 sgd_solver.cpp:106] Iteration 297000, lr = 0.0025
I0520 17:31:10.875337 24275 solver.cpp:237] Iteration 298500, loss = 0.832261
I0520 17:31:10.875375 24275 solver.cpp:253]     Train net output #0: loss = 0.83226 (* 1 = 0.83226 loss)
I0520 17:31:10.875388 24275 sgd_solver.cpp:106] Iteration 298500, lr = 0.0025
I0520 17:31:27.604861 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_300000.caffemodel
I0520 17:31:27.653491 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_300000.solverstate
I0520 17:31:27.681084 24275 solver.cpp:341] Iteration 300000, Testing net (#0)
I0520 17:32:48.087365 24275 solver.cpp:409]     Test net output #0: accuracy = 0.889541
I0520 17:32:48.087540 24275 solver.cpp:409]     Test net output #1: loss = 0.346073 (* 1 = 0.346073 loss)
I0520 17:33:08.979074 24275 solver.cpp:237] Iteration 300000, loss = 1.55454
I0520 17:33:08.979125 24275 solver.cpp:253]     Train net output #0: loss = 1.55454 (* 1 = 1.55454 loss)
I0520 17:33:08.979140 24275 sgd_solver.cpp:106] Iteration 300000, lr = 0.0025
I0520 17:33:25.613958 24275 solver.cpp:237] Iteration 301500, loss = 1.14645
I0520 17:33:25.614132 24275 solver.cpp:253]     Train net output #0: loss = 1.14645 (* 1 = 1.14645 loss)
I0520 17:33:25.614146 24275 sgd_solver.cpp:106] Iteration 301500, lr = 0.0025
I0520 17:33:42.234943 24275 solver.cpp:237] Iteration 303000, loss = 1.43321
I0520 17:33:42.234978 24275 solver.cpp:253]     Train net output #0: loss = 1.43321 (* 1 = 1.43321 loss)
I0520 17:33:42.234994 24275 sgd_solver.cpp:106] Iteration 303000, lr = 0.0025
I0520 17:33:58.878731 24275 solver.cpp:237] Iteration 304500, loss = 1.09999
I0520 17:33:58.878901 24275 solver.cpp:253]     Train net output #0: loss = 1.09999 (* 1 = 1.09999 loss)
I0520 17:33:58.878916 24275 sgd_solver.cpp:106] Iteration 304500, lr = 0.0025
I0520 17:34:15.511785 24275 solver.cpp:237] Iteration 306000, loss = 1.18057
I0520 17:34:15.511831 24275 solver.cpp:253]     Train net output #0: loss = 1.18058 (* 1 = 1.18058 loss)
I0520 17:34:15.511847 24275 sgd_solver.cpp:106] Iteration 306000, lr = 0.0025
I0520 17:34:32.139686 24275 solver.cpp:237] Iteration 307500, loss = 1.20136
I0520 17:34:32.139842 24275 solver.cpp:253]     Train net output #0: loss = 1.20136 (* 1 = 1.20136 loss)
I0520 17:34:32.139856 24275 sgd_solver.cpp:106] Iteration 307500, lr = 0.0025
I0520 17:34:48.761241 24275 solver.cpp:237] Iteration 309000, loss = 1.25792
I0520 17:34:48.761283 24275 solver.cpp:253]     Train net output #0: loss = 1.25792 (* 1 = 1.25792 loss)
I0520 17:34:48.761297 24275 sgd_solver.cpp:106] Iteration 309000, lr = 0.0025
I0520 17:35:26.249869 24275 solver.cpp:237] Iteration 310500, loss = 0.977131
I0520 17:35:26.250047 24275 solver.cpp:253]     Train net output #0: loss = 0.977133 (* 1 = 0.977133 loss)
I0520 17:35:26.250061 24275 sgd_solver.cpp:106] Iteration 310500, lr = 0.0025
I0520 17:35:42.878444 24275 solver.cpp:237] Iteration 312000, loss = 1.59103
I0520 17:35:42.878480 24275 solver.cpp:253]     Train net output #0: loss = 1.59103 (* 1 = 1.59103 loss)
I0520 17:35:42.878495 24275 sgd_solver.cpp:106] Iteration 312000, lr = 0.0025
I0520 17:35:59.488626 24275 solver.cpp:237] Iteration 313500, loss = 0.616924
I0520 17:35:59.488801 24275 solver.cpp:253]     Train net output #0: loss = 0.616926 (* 1 = 0.616926 loss)
I0520 17:35:59.488814 24275 sgd_solver.cpp:106] Iteration 313500, lr = 0.0025
I0520 17:36:16.089541 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_315000.caffemodel
I0520 17:36:16.135709 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_315000.solverstate
I0520 17:36:16.164676 24275 solver.cpp:237] Iteration 315000, loss = 0.893353
I0520 17:36:16.164722 24275 solver.cpp:253]     Train net output #0: loss = 0.893355 (* 1 = 0.893355 loss)
I0520 17:36:16.164739 24275 sgd_solver.cpp:106] Iteration 315000, lr = 0.0025
I0520 17:36:32.786427 24275 solver.cpp:237] Iteration 316500, loss = 0.947774
I0520 17:36:32.786592 24275 solver.cpp:253]     Train net output #0: loss = 0.947775 (* 1 = 0.947775 loss)
I0520 17:36:32.786607 24275 sgd_solver.cpp:106] Iteration 316500, lr = 0.0025
I0520 17:36:49.386303 24275 solver.cpp:237] Iteration 318000, loss = 0.801219
I0520 17:36:49.386349 24275 solver.cpp:253]     Train net output #0: loss = 0.80122 (* 1 = 0.80122 loss)
I0520 17:36:49.386363 24275 sgd_solver.cpp:106] Iteration 318000, lr = 0.0025
I0520 17:37:05.974318 24275 solver.cpp:237] Iteration 319500, loss = 1.27842
I0520 17:37:05.974474 24275 solver.cpp:253]     Train net output #0: loss = 1.27842 (* 1 = 1.27842 loss)
I0520 17:37:05.974488 24275 sgd_solver.cpp:106] Iteration 319500, lr = 0.0025
I0520 17:37:43.427552 24275 solver.cpp:237] Iteration 321000, loss = 0.697036
I0520 17:37:43.427731 24275 solver.cpp:253]     Train net output #0: loss = 0.697038 (* 1 = 0.697038 loss)
I0520 17:37:43.427747 24275 sgd_solver.cpp:106] Iteration 321000, lr = 0.0025
I0520 17:38:00.023411 24275 solver.cpp:237] Iteration 322500, loss = 1.20234
I0520 17:38:00.023457 24275 solver.cpp:253]     Train net output #0: loss = 1.20234 (* 1 = 1.20234 loss)
I0520 17:38:00.023473 24275 sgd_solver.cpp:106] Iteration 322500, lr = 0.0025
I0520 17:38:16.635701 24275 solver.cpp:237] Iteration 324000, loss = 1.1121
I0520 17:38:16.635856 24275 solver.cpp:253]     Train net output #0: loss = 1.1121 (* 1 = 1.1121 loss)
I0520 17:38:16.635869 24275 sgd_solver.cpp:106] Iteration 324000, lr = 0.0025
I0520 17:38:33.231773 24275 solver.cpp:237] Iteration 325500, loss = 0.688065
I0520 17:38:33.231820 24275 solver.cpp:253]     Train net output #0: loss = 0.688066 (* 1 = 0.688066 loss)
I0520 17:38:33.231834 24275 sgd_solver.cpp:106] Iteration 325500, lr = 0.0025
I0520 17:38:49.877804 24275 solver.cpp:237] Iteration 327000, loss = 1.26311
I0520 17:38:49.877970 24275 solver.cpp:253]     Train net output #0: loss = 1.26312 (* 1 = 1.26312 loss)
I0520 17:38:49.877985 24275 sgd_solver.cpp:106] Iteration 327000, lr = 0.0025
I0520 17:39:06.476424 24275 solver.cpp:237] Iteration 328500, loss = 1.2943
I0520 17:39:06.476460 24275 solver.cpp:253]     Train net output #0: loss = 1.2943 (* 1 = 1.2943 loss)
I0520 17:39:06.476475 24275 sgd_solver.cpp:106] Iteration 328500, lr = 0.0025
I0520 17:39:23.080756 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_330000.caffemodel
I0520 17:39:23.126515 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_330000.solverstate
I0520 17:39:23.152164 24275 solver.cpp:341] Iteration 330000, Testing net (#0)
I0520 17:40:22.036909 24275 solver.cpp:409]     Test net output #0: accuracy = 0.894321
I0520 17:40:22.037106 24275 solver.cpp:409]     Test net output #1: loss = 0.338366 (* 1 = 0.338366 loss)
I0520 17:40:42.892654 24275 solver.cpp:237] Iteration 330000, loss = 0.53279
I0520 17:40:42.892709 24275 solver.cpp:253]     Train net output #0: loss = 0.532791 (* 1 = 0.532791 loss)
I0520 17:40:42.892724 24275 sgd_solver.cpp:106] Iteration 330000, lr = 0.0025
I0520 17:40:59.820653 24275 solver.cpp:237] Iteration 331500, loss = 1.31036
I0520 17:40:59.820830 24275 solver.cpp:253]     Train net output #0: loss = 1.31036 (* 1 = 1.31036 loss)
I0520 17:40:59.820844 24275 sgd_solver.cpp:106] Iteration 331500, lr = 0.0025
I0520 17:41:16.778261 24275 solver.cpp:237] Iteration 333000, loss = 0.964013
I0520 17:41:16.778309 24275 solver.cpp:253]     Train net output #0: loss = 0.964014 (* 1 = 0.964014 loss)
I0520 17:41:16.778323 24275 sgd_solver.cpp:106] Iteration 333000, lr = 0.0025
I0520 17:41:33.724828 24275 solver.cpp:237] Iteration 334500, loss = 1.03256
I0520 17:41:33.724989 24275 solver.cpp:253]     Train net output #0: loss = 1.03256 (* 1 = 1.03256 loss)
I0520 17:41:33.725003 24275 sgd_solver.cpp:106] Iteration 334500, lr = 0.0025
I0520 17:41:50.643404 24275 solver.cpp:237] Iteration 336000, loss = 0.993021
I0520 17:41:50.643452 24275 solver.cpp:253]     Train net output #0: loss = 0.993022 (* 1 = 0.993022 loss)
I0520 17:41:50.643466 24275 sgd_solver.cpp:106] Iteration 336000, lr = 0.0025
I0520 17:42:07.605886 24275 solver.cpp:237] Iteration 337500, loss = 0.94157
I0520 17:42:07.606058 24275 solver.cpp:253]     Train net output #0: loss = 0.941572 (* 1 = 0.941572 loss)
I0520 17:42:07.606072 24275 sgd_solver.cpp:106] Iteration 337500, lr = 0.0025
I0520 17:42:24.564622 24275 solver.cpp:237] Iteration 339000, loss = 1.11671
I0520 17:42:24.564657 24275 solver.cpp:253]     Train net output #0: loss = 1.11672 (* 1 = 1.11672 loss)
I0520 17:42:24.564673 24275 sgd_solver.cpp:106] Iteration 339000, lr = 0.0025
I0520 17:43:02.372115 24275 solver.cpp:237] Iteration 340500, loss = 1.48177
I0520 17:43:02.372293 24275 solver.cpp:253]     Train net output #0: loss = 1.48177 (* 1 = 1.48177 loss)
I0520 17:43:02.372308 24275 sgd_solver.cpp:106] Iteration 340500, lr = 0.0025
I0520 17:43:19.355399 24275 solver.cpp:237] Iteration 342000, loss = 0.96992
I0520 17:43:19.355437 24275 solver.cpp:253]     Train net output #0: loss = 0.969923 (* 1 = 0.969923 loss)
I0520 17:43:19.355450 24275 sgd_solver.cpp:106] Iteration 342000, lr = 0.0025
I0520 17:43:36.305860 24275 solver.cpp:237] Iteration 343500, loss = 1.73834
I0520 17:43:36.306030 24275 solver.cpp:253]     Train net output #0: loss = 1.73834 (* 1 = 1.73834 loss)
I0520 17:43:36.306044 24275 sgd_solver.cpp:106] Iteration 343500, lr = 0.0025
I0520 17:43:53.244554 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_345000.caffemodel
I0520 17:43:53.290920 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_345000.solverstate
I0520 17:43:53.319186 24275 solver.cpp:237] Iteration 345000, loss = 1.18793
I0520 17:43:53.319233 24275 solver.cpp:253]     Train net output #0: loss = 1.18793 (* 1 = 1.18793 loss)
I0520 17:43:53.319248 24275 sgd_solver.cpp:106] Iteration 345000, lr = 0.0025
I0520 17:44:10.265558 24275 solver.cpp:237] Iteration 346500, loss = 1.53462
I0520 17:44:10.265718 24275 solver.cpp:253]     Train net output #0: loss = 1.53462 (* 1 = 1.53462 loss)
I0520 17:44:10.265733 24275 sgd_solver.cpp:106] Iteration 346500, lr = 0.0025
I0520 17:44:27.223062 24275 solver.cpp:237] Iteration 348000, loss = 1.3627
I0520 17:44:27.223105 24275 solver.cpp:253]     Train net output #0: loss = 1.3627 (* 1 = 1.3627 loss)
I0520 17:44:27.223120 24275 sgd_solver.cpp:106] Iteration 348000, lr = 0.0025
I0520 17:44:44.170902 24275 solver.cpp:237] Iteration 349500, loss = 1.36981
I0520 17:44:44.171082 24275 solver.cpp:253]     Train net output #0: loss = 1.36981 (* 1 = 1.36981 loss)
I0520 17:44:44.171095 24275 sgd_solver.cpp:106] Iteration 349500, lr = 0.0025
I0520 17:45:21.959560 24275 solver.cpp:237] Iteration 351000, loss = 1.29435
I0520 17:45:21.959748 24275 solver.cpp:253]     Train net output #0: loss = 1.29435 (* 1 = 1.29435 loss)
I0520 17:45:21.959761 24275 sgd_solver.cpp:106] Iteration 351000, lr = 0.0025
I0520 17:45:38.910943 24275 solver.cpp:237] Iteration 352500, loss = 0.411048
I0520 17:45:38.910992 24275 solver.cpp:253]     Train net output #0: loss = 0.41105 (* 1 = 0.41105 loss)
I0520 17:45:38.911006 24275 sgd_solver.cpp:106] Iteration 352500, lr = 0.0025
I0520 17:45:55.834664 24275 solver.cpp:237] Iteration 354000, loss = 1.11298
I0520 17:45:55.834836 24275 solver.cpp:253]     Train net output #0: loss = 1.11298 (* 1 = 1.11298 loss)
I0520 17:45:55.834851 24275 sgd_solver.cpp:106] Iteration 354000, lr = 0.0025
I0520 17:46:12.804307 24275 solver.cpp:237] Iteration 355500, loss = 1.33961
I0520 17:46:12.804344 24275 solver.cpp:253]     Train net output #0: loss = 1.33962 (* 1 = 1.33962 loss)
I0520 17:46:12.804358 24275 sgd_solver.cpp:106] Iteration 355500, lr = 0.0025
I0520 17:46:29.792330 24275 solver.cpp:237] Iteration 357000, loss = 1.30469
I0520 17:46:29.792502 24275 solver.cpp:253]     Train net output #0: loss = 1.30469 (* 1 = 1.30469 loss)
I0520 17:46:29.792516 24275 sgd_solver.cpp:106] Iteration 357000, lr = 0.0025
I0520 17:46:46.740476 24275 solver.cpp:237] Iteration 358500, loss = 0.975852
I0520 17:46:46.740526 24275 solver.cpp:253]     Train net output #0: loss = 0.975854 (* 1 = 0.975854 loss)
I0520 17:46:46.740541 24275 sgd_solver.cpp:106] Iteration 358500, lr = 0.0025
I0520 17:47:03.683431 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_360000.caffemodel
I0520 17:47:03.729109 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_360000.solverstate
I0520 17:47:03.754766 24275 solver.cpp:341] Iteration 360000, Testing net (#0)
I0520 17:48:24.058346 24275 solver.cpp:409]     Test net output #0: accuracy = 0.893982
I0520 17:48:24.058523 24275 solver.cpp:409]     Test net output #1: loss = 0.359181 (* 1 = 0.359181 loss)
I0520 17:48:44.898330 24275 solver.cpp:237] Iteration 360000, loss = 1.53373
I0520 17:48:44.898383 24275 solver.cpp:253]     Train net output #0: loss = 1.53373 (* 1 = 1.53373 loss)
I0520 17:48:44.898398 24275 sgd_solver.cpp:106] Iteration 360000, lr = 0.0025
I0520 17:49:01.747105 24275 solver.cpp:237] Iteration 361500, loss = 0.860199
I0520 17:49:01.747284 24275 solver.cpp:253]     Train net output #0: loss = 0.860202 (* 1 = 0.860202 loss)
I0520 17:49:01.747298 24275 sgd_solver.cpp:106] Iteration 361500, lr = 0.0025
I0520 17:49:18.601536 24275 solver.cpp:237] Iteration 363000, loss = 0.826067
I0520 17:49:18.601580 24275 solver.cpp:253]     Train net output #0: loss = 0.826071 (* 1 = 0.826071 loss)
I0520 17:49:18.601594 24275 sgd_solver.cpp:106] Iteration 363000, lr = 0.0025
I0520 17:49:35.470856 24275 solver.cpp:237] Iteration 364500, loss = 0.928606
I0520 17:49:35.471026 24275 solver.cpp:253]     Train net output #0: loss = 0.928609 (* 1 = 0.928609 loss)
I0520 17:49:35.471040 24275 sgd_solver.cpp:106] Iteration 364500, lr = 0.0025
I0520 17:49:52.323623 24275 solver.cpp:237] Iteration 366000, loss = 0.944149
I0520 17:49:52.323671 24275 solver.cpp:253]     Train net output #0: loss = 0.944153 (* 1 = 0.944153 loss)
I0520 17:49:52.323685 24275 sgd_solver.cpp:106] Iteration 366000, lr = 0.0025
I0520 17:50:09.178464 24275 solver.cpp:237] Iteration 367500, loss = 0.954371
I0520 17:50:09.178640 24275 solver.cpp:253]     Train net output #0: loss = 0.954374 (* 1 = 0.954374 loss)
I0520 17:50:09.178654 24275 sgd_solver.cpp:106] Iteration 367500, lr = 0.0025
I0520 17:50:26.101482 24275 solver.cpp:237] Iteration 369000, loss = 0.98067
I0520 17:50:26.101519 24275 solver.cpp:253]     Train net output #0: loss = 0.980673 (* 1 = 0.980673 loss)
I0520 17:50:26.101533 24275 sgd_solver.cpp:106] Iteration 369000, lr = 0.0025
I0520 17:51:03.856583 24275 solver.cpp:237] Iteration 370500, loss = 1.53148
I0520 17:51:03.856778 24275 solver.cpp:253]     Train net output #0: loss = 1.53148 (* 1 = 1.53148 loss)
I0520 17:51:03.856792 24275 sgd_solver.cpp:106] Iteration 370500, lr = 0.0025
I0520 17:51:20.782387 24275 solver.cpp:237] Iteration 372000, loss = 1.33903
I0520 17:51:20.782431 24275 solver.cpp:253]     Train net output #0: loss = 1.33903 (* 1 = 1.33903 loss)
I0520 17:51:20.782447 24275 sgd_solver.cpp:106] Iteration 372000, lr = 0.0025
I0520 17:51:37.680403 24275 solver.cpp:237] Iteration 373500, loss = 0.77125
I0520 17:51:37.680567 24275 solver.cpp:253]     Train net output #0: loss = 0.771253 (* 1 = 0.771253 loss)
I0520 17:51:37.680579 24275 sgd_solver.cpp:106] Iteration 373500, lr = 0.0025
I0520 17:51:54.654386 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_375000.caffemodel
I0520 17:51:54.701921 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_375000.solverstate
I0520 17:51:54.732942 24275 solver.cpp:237] Iteration 375000, loss = 1.18499
I0520 17:51:54.732992 24275 solver.cpp:253]     Train net output #0: loss = 1.185 (* 1 = 1.185 loss)
I0520 17:51:54.733007 24275 sgd_solver.cpp:106] Iteration 375000, lr = 0.0025
I0520 17:52:11.780320 24275 solver.cpp:237] Iteration 376500, loss = 1.1596
I0520 17:52:11.780514 24275 solver.cpp:253]     Train net output #0: loss = 1.1596 (* 1 = 1.1596 loss)
I0520 17:52:11.780529 24275 sgd_solver.cpp:106] Iteration 376500, lr = 0.0025
I0520 17:52:28.788136 24275 solver.cpp:237] Iteration 378000, loss = 0.99015
I0520 17:52:28.788172 24275 solver.cpp:253]     Train net output #0: loss = 0.990151 (* 1 = 0.990151 loss)
I0520 17:52:28.788187 24275 sgd_solver.cpp:106] Iteration 378000, lr = 0.0025
I0520 17:52:45.818714 24275 solver.cpp:237] Iteration 379500, loss = 0.947444
I0520 17:52:45.818883 24275 solver.cpp:253]     Train net output #0: loss = 0.947446 (* 1 = 0.947446 loss)
I0520 17:52:45.818897 24275 sgd_solver.cpp:106] Iteration 379500, lr = 0.0025
I0520 17:53:23.731683 24275 solver.cpp:237] Iteration 381000, loss = 0.854072
I0520 17:53:23.731866 24275 solver.cpp:253]     Train net output #0: loss = 0.854074 (* 1 = 0.854074 loss)
I0520 17:53:23.731880 24275 sgd_solver.cpp:106] Iteration 381000, lr = 0.0025
I0520 17:53:40.778650 24275 solver.cpp:237] Iteration 382500, loss = 1.00448
I0520 17:53:40.778687 24275 solver.cpp:253]     Train net output #0: loss = 1.00448 (* 1 = 1.00448 loss)
I0520 17:53:40.778702 24275 sgd_solver.cpp:106] Iteration 382500, lr = 0.0025
I0520 17:53:57.808181 24275 solver.cpp:237] Iteration 384000, loss = 0.966421
I0520 17:53:57.808351 24275 solver.cpp:253]     Train net output #0: loss = 0.966422 (* 1 = 0.966422 loss)
I0520 17:53:57.808364 24275 sgd_solver.cpp:106] Iteration 384000, lr = 0.0025
I0520 17:54:14.882562 24275 solver.cpp:237] Iteration 385500, loss = 1.39654
I0520 17:54:14.882598 24275 solver.cpp:253]     Train net output #0: loss = 1.39654 (* 1 = 1.39654 loss)
I0520 17:54:14.882611 24275 sgd_solver.cpp:106] Iteration 385500, lr = 0.0025
I0520 17:54:31.904537 24275 solver.cpp:237] Iteration 387000, loss = 1.31617
I0520 17:54:31.904692 24275 solver.cpp:253]     Train net output #0: loss = 1.31618 (* 1 = 1.31618 loss)
I0520 17:54:31.904706 24275 sgd_solver.cpp:106] Iteration 387000, lr = 0.0025
I0520 17:54:48.862098 24275 solver.cpp:237] Iteration 388500, loss = 1.00002
I0520 17:54:48.862143 24275 solver.cpp:253]     Train net output #0: loss = 1.00002 (* 1 = 1.00002 loss)
I0520 17:54:48.862156 24275 sgd_solver.cpp:106] Iteration 388500, lr = 0.0025
I0520 17:55:05.828466 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_390000.caffemodel
I0520 17:55:05.874181 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_390000.solverstate
I0520 17:55:05.899158 24275 solver.cpp:341] Iteration 390000, Testing net (#0)
I0520 17:56:05.297890 24275 solver.cpp:409]     Test net output #0: accuracy = 0.895523
I0520 17:56:05.298071 24275 solver.cpp:409]     Test net output #1: loss = 0.335293 (* 1 = 0.335293 loss)
I0520 17:56:26.106245 24275 solver.cpp:237] Iteration 390000, loss = 0.709643
I0520 17:56:26.106298 24275 solver.cpp:253]     Train net output #0: loss = 0.709645 (* 1 = 0.709645 loss)
I0520 17:56:26.106314 24275 sgd_solver.cpp:106] Iteration 390000, lr = 0.0025
I0520 17:56:42.935798 24275 solver.cpp:237] Iteration 391500, loss = 0.693455
I0520 17:56:42.935977 24275 solver.cpp:253]     Train net output #0: loss = 0.693457 (* 1 = 0.693457 loss)
I0520 17:56:42.935992 24275 sgd_solver.cpp:106] Iteration 391500, lr = 0.0025
I0520 17:56:59.775764 24275 solver.cpp:237] Iteration 393000, loss = 1.16862
I0520 17:56:59.775800 24275 solver.cpp:253]     Train net output #0: loss = 1.16862 (* 1 = 1.16862 loss)
I0520 17:56:59.775815 24275 sgd_solver.cpp:106] Iteration 393000, lr = 0.0025
I0520 17:57:16.662636 24275 solver.cpp:237] Iteration 394500, loss = 1.02029
I0520 17:57:16.662820 24275 solver.cpp:253]     Train net output #0: loss = 1.0203 (* 1 = 1.0203 loss)
I0520 17:57:16.662834 24275 sgd_solver.cpp:106] Iteration 394500, lr = 0.0025
I0520 17:57:33.550926 24275 solver.cpp:237] Iteration 396000, loss = 0.763591
I0520 17:57:33.550977 24275 solver.cpp:253]     Train net output #0: loss = 0.763592 (* 1 = 0.763592 loss)
I0520 17:57:33.550992 24275 sgd_solver.cpp:106] Iteration 396000, lr = 0.0025
I0520 17:57:50.355293 24275 solver.cpp:237] Iteration 397500, loss = 1.53761
I0520 17:57:50.355458 24275 solver.cpp:253]     Train net output #0: loss = 1.53761 (* 1 = 1.53761 loss)
I0520 17:57:50.355471 24275 sgd_solver.cpp:106] Iteration 397500, lr = 0.0025
I0520 17:58:07.193307 24275 solver.cpp:237] Iteration 399000, loss = 0.716567
I0520 17:58:07.193358 24275 solver.cpp:253]     Train net output #0: loss = 0.716567 (* 1 = 0.716567 loss)
I0520 17:58:07.193377 24275 sgd_solver.cpp:106] Iteration 399000, lr = 0.0025
I0520 17:58:44.926257 24275 solver.cpp:237] Iteration 400500, loss = 1.10835
I0520 17:58:44.926442 24275 solver.cpp:253]     Train net output #0: loss = 1.10835 (* 1 = 1.10835 loss)
I0520 17:58:44.926456 24275 sgd_solver.cpp:106] Iteration 400500, lr = 0.0025
I0520 17:59:01.812717 24275 solver.cpp:237] Iteration 402000, loss = 1.24685
I0520 17:59:01.812763 24275 solver.cpp:253]     Train net output #0: loss = 1.24685 (* 1 = 1.24685 loss)
I0520 17:59:01.812777 24275 sgd_solver.cpp:106] Iteration 402000, lr = 0.0025
I0520 17:59:18.674818 24275 solver.cpp:237] Iteration 403500, loss = 1.05309
I0520 17:59:18.674998 24275 solver.cpp:253]     Train net output #0: loss = 1.05309 (* 1 = 1.05309 loss)
I0520 17:59:18.675014 24275 sgd_solver.cpp:106] Iteration 403500, lr = 0.0025
I0520 17:59:35.507689 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_405000.caffemodel
I0520 17:59:35.554149 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_405000.solverstate
I0520 17:59:35.582514 24275 solver.cpp:237] Iteration 405000, loss = 1.09044
I0520 17:59:35.582559 24275 solver.cpp:253]     Train net output #0: loss = 1.09044 (* 1 = 1.09044 loss)
I0520 17:59:35.582574 24275 sgd_solver.cpp:106] Iteration 405000, lr = 0.0025
I0520 17:59:52.505566 24275 solver.cpp:237] Iteration 406500, loss = 1.40254
I0520 17:59:52.505758 24275 solver.cpp:253]     Train net output #0: loss = 1.40254 (* 1 = 1.40254 loss)
I0520 17:59:52.505772 24275 sgd_solver.cpp:106] Iteration 406500, lr = 0.0025
I0520 18:00:09.391504 24275 solver.cpp:237] Iteration 408000, loss = 0.961597
I0520 18:00:09.391556 24275 solver.cpp:253]     Train net output #0: loss = 0.961599 (* 1 = 0.961599 loss)
I0520 18:00:09.391569 24275 sgd_solver.cpp:106] Iteration 408000, lr = 0.0025
I0520 18:00:26.278071 24275 solver.cpp:237] Iteration 409500, loss = 0.853619
I0520 18:00:26.278250 24275 solver.cpp:253]     Train net output #0: loss = 0.853622 (* 1 = 0.853622 loss)
I0520 18:00:26.278265 24275 sgd_solver.cpp:106] Iteration 409500, lr = 0.0025
I0520 18:01:03.905656 24275 solver.cpp:237] Iteration 411000, loss = 0.957897
I0520 18:01:03.905859 24275 solver.cpp:253]     Train net output #0: loss = 0.957899 (* 1 = 0.957899 loss)
I0520 18:01:03.905874 24275 sgd_solver.cpp:106] Iteration 411000, lr = 0.0025
I0520 18:01:20.741878 24275 solver.cpp:237] Iteration 412500, loss = 3.22107
I0520 18:01:20.741925 24275 solver.cpp:253]     Train net output #0: loss = 3.22107 (* 1 = 3.22107 loss)
I0520 18:01:20.741940 24275 sgd_solver.cpp:106] Iteration 412500, lr = 0.0025
I0520 18:01:37.566767 24275 solver.cpp:237] Iteration 414000, loss = 0.893736
I0520 18:01:37.566943 24275 solver.cpp:253]     Train net output #0: loss = 0.89374 (* 1 = 0.89374 loss)
I0520 18:01:37.566957 24275 sgd_solver.cpp:106] Iteration 414000, lr = 0.0025
I0520 18:01:54.484297 24275 solver.cpp:237] Iteration 415500, loss = 0.832271
I0520 18:01:54.484344 24275 solver.cpp:253]     Train net output #0: loss = 0.832275 (* 1 = 0.832275 loss)
I0520 18:01:54.484357 24275 sgd_solver.cpp:106] Iteration 415500, lr = 0.0025
I0520 18:02:11.371371 24275 solver.cpp:237] Iteration 417000, loss = 1.65466
I0520 18:02:11.371539 24275 solver.cpp:253]     Train net output #0: loss = 1.65466 (* 1 = 1.65466 loss)
I0520 18:02:11.371553 24275 sgd_solver.cpp:106] Iteration 417000, lr = 0.0025
I0520 18:02:28.247573 24275 solver.cpp:237] Iteration 418500, loss = 1.6404
I0520 18:02:28.247616 24275 solver.cpp:253]     Train net output #0: loss = 1.64041 (* 1 = 1.64041 loss)
I0520 18:02:28.247628 24275 sgd_solver.cpp:106] Iteration 418500, lr = 0.0025
I0520 18:02:45.076114 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_420000.caffemodel
I0520 18:02:45.121629 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_420000.solverstate
I0520 18:02:45.147308 24275 solver.cpp:341] Iteration 420000, Testing net (#0)
I0520 18:04:05.441951 24275 solver.cpp:409]     Test net output #0: accuracy = 0.895473
I0520 18:04:05.442145 24275 solver.cpp:409]     Test net output #1: loss = 0.337339 (* 1 = 0.337339 loss)
I0520 18:04:26.276387 24275 solver.cpp:237] Iteration 420000, loss = 1.64749
I0520 18:04:26.276442 24275 solver.cpp:253]     Train net output #0: loss = 1.6475 (* 1 = 1.6475 loss)
I0520 18:04:26.276456 24275 sgd_solver.cpp:106] Iteration 420000, lr = 0.0025
I0520 18:04:43.484956 24275 solver.cpp:237] Iteration 421500, loss = 1.11056
I0520 18:04:43.485138 24275 solver.cpp:253]     Train net output #0: loss = 1.11056 (* 1 = 1.11056 loss)
I0520 18:04:43.485152 24275 sgd_solver.cpp:106] Iteration 421500, lr = 0.0025
I0520 18:05:00.682322 24275 solver.cpp:237] Iteration 423000, loss = 0.638548
I0520 18:05:00.682359 24275 solver.cpp:253]     Train net output #0: loss = 0.638551 (* 1 = 0.638551 loss)
I0520 18:05:00.682374 24275 sgd_solver.cpp:106] Iteration 423000, lr = 0.0025
I0520 18:05:17.852118 24275 solver.cpp:237] Iteration 424500, loss = 1.61108
I0520 18:05:17.852296 24275 solver.cpp:253]     Train net output #0: loss = 1.61108 (* 1 = 1.61108 loss)
I0520 18:05:17.852310 24275 sgd_solver.cpp:106] Iteration 424500, lr = 0.0025
I0520 18:05:35.061626 24275 solver.cpp:237] Iteration 426000, loss = 0.846193
I0520 18:05:35.061678 24275 solver.cpp:253]     Train net output #0: loss = 0.846194 (* 1 = 0.846194 loss)
I0520 18:05:35.061692 24275 sgd_solver.cpp:106] Iteration 426000, lr = 0.0025
I0520 18:05:52.289566 24275 solver.cpp:237] Iteration 427500, loss = 1.30835
I0520 18:05:52.289753 24275 solver.cpp:253]     Train net output #0: loss = 1.30835 (* 1 = 1.30835 loss)
I0520 18:05:52.289767 24275 sgd_solver.cpp:106] Iteration 427500, lr = 0.0025
I0520 18:06:09.455227 24275 solver.cpp:237] Iteration 429000, loss = 0.793873
I0520 18:06:09.455265 24275 solver.cpp:253]     Train net output #0: loss = 0.793874 (* 1 = 0.793874 loss)
I0520 18:06:09.455279 24275 sgd_solver.cpp:106] Iteration 429000, lr = 0.0025
I0520 18:06:47.111964 24275 solver.cpp:237] Iteration 430500, loss = 0.985013
I0520 18:06:47.112152 24275 solver.cpp:253]     Train net output #0: loss = 0.985015 (* 1 = 0.985015 loss)
I0520 18:06:47.112166 24275 sgd_solver.cpp:106] Iteration 430500, lr = 0.0025
I0520 18:07:03.735261 24275 solver.cpp:237] Iteration 432000, loss = 1.25807
I0520 18:07:03.735298 24275 solver.cpp:253]     Train net output #0: loss = 1.25807 (* 1 = 1.25807 loss)
I0520 18:07:03.735312 24275 sgd_solver.cpp:106] Iteration 432000, lr = 0.0025
I0520 18:07:20.371026 24275 solver.cpp:237] Iteration 433500, loss = 1.18441
I0520 18:07:20.371201 24275 solver.cpp:253]     Train net output #0: loss = 1.18441 (* 1 = 1.18441 loss)
I0520 18:07:20.371214 24275 sgd_solver.cpp:106] Iteration 433500, lr = 0.0025
I0520 18:07:36.985658 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_435000.caffemodel
I0520 18:07:37.033725 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_435000.solverstate
I0520 18:07:37.064177 24275 solver.cpp:237] Iteration 435000, loss = 1.96739
I0520 18:07:37.064226 24275 solver.cpp:253]     Train net output #0: loss = 1.96739 (* 1 = 1.96739 loss)
I0520 18:07:37.064241 24275 sgd_solver.cpp:106] Iteration 435000, lr = 0.0025
I0520 18:07:53.646767 24275 solver.cpp:237] Iteration 436500, loss = 0.954932
I0520 18:07:53.646940 24275 solver.cpp:253]     Train net output #0: loss = 0.954934 (* 1 = 0.954934 loss)
I0520 18:07:53.646955 24275 sgd_solver.cpp:106] Iteration 436500, lr = 0.0025
I0520 18:08:10.277789 24275 solver.cpp:237] Iteration 438000, loss = 1.56908
I0520 18:08:10.277837 24275 solver.cpp:253]     Train net output #0: loss = 1.56908 (* 1 = 1.56908 loss)
I0520 18:08:10.277850 24275 sgd_solver.cpp:106] Iteration 438000, lr = 0.0025
I0520 18:08:26.914415 24275 solver.cpp:237] Iteration 439500, loss = 1.35149
I0520 18:08:26.914587 24275 solver.cpp:253]     Train net output #0: loss = 1.35149 (* 1 = 1.35149 loss)
I0520 18:08:26.914602 24275 sgd_solver.cpp:106] Iteration 439500, lr = 0.0025
I0520 18:09:04.362522 24275 solver.cpp:237] Iteration 441000, loss = 0.947935
I0520 18:09:04.362712 24275 solver.cpp:253]     Train net output #0: loss = 0.947938 (* 1 = 0.947938 loss)
I0520 18:09:04.362726 24275 sgd_solver.cpp:106] Iteration 441000, lr = 0.0025
I0520 18:09:21.011790 24275 solver.cpp:237] Iteration 442500, loss = 1.54965
I0520 18:09:21.011836 24275 solver.cpp:253]     Train net output #0: loss = 1.54965 (* 1 = 1.54965 loss)
I0520 18:09:21.011849 24275 sgd_solver.cpp:106] Iteration 442500, lr = 0.0025
I0520 18:09:37.618594 24275 solver.cpp:237] Iteration 444000, loss = 1.77115
I0520 18:09:37.618782 24275 solver.cpp:253]     Train net output #0: loss = 1.77115 (* 1 = 1.77115 loss)
I0520 18:09:37.618798 24275 sgd_solver.cpp:106] Iteration 444000, lr = 0.0025
I0520 18:09:54.218768 24275 solver.cpp:237] Iteration 445500, loss = 1.69084
I0520 18:09:54.218804 24275 solver.cpp:253]     Train net output #0: loss = 1.69084 (* 1 = 1.69084 loss)
I0520 18:09:54.218819 24275 sgd_solver.cpp:106] Iteration 445500, lr = 0.0025
I0520 18:10:10.875166 24275 solver.cpp:237] Iteration 447000, loss = 0.979359
I0520 18:10:10.875349 24275 solver.cpp:253]     Train net output #0: loss = 0.979361 (* 1 = 0.979361 loss)
I0520 18:10:10.875362 24275 sgd_solver.cpp:106] Iteration 447000, lr = 0.0025
I0520 18:10:27.485255 24275 solver.cpp:237] Iteration 448500, loss = 1.07169
I0520 18:10:27.485302 24275 solver.cpp:253]     Train net output #0: loss = 1.07169 (* 1 = 1.07169 loss)
I0520 18:10:27.485318 24275 sgd_solver.cpp:106] Iteration 448500, lr = 0.0025
I0520 18:10:44.082530 24275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_450000.caffemodel
I0520 18:10:44.130937 24275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0025_2016-05-20T15.48.50.893607_iter_450000.solverstate
I0520 18:10:44.158546 24275 solver.cpp:341] Iteration 450000, Testing net (#0)
I0520 18:11:42.993829 24275 solver.cpp:409]     Test net output #0: accuracy = 0.89351
I0520 18:11:42.994012 24275 solver.cpp:409]     Test net output #1: loss = 0.355755 (* 1 = 0.355755 loss)
I0520 18:12:03.853363 24275 solver.cpp:237] Iteration 450000, loss = 0.804368
I0520 18:12:03.853416 24275 solver.cpp:253]     Train net output #0: loss = 0.804371 (* 1 = 0.804371 loss)
I0520 18:12:03.853431 24275 sgd_solver.cpp:106] Iteration 450000, lr = 0.0025
I0520 18:12:20.845798 24275 solver.cpp:237] Iteration 451500, loss = 1.14536
I0520 18:12:20.845978 24275 solver.cpp:253]     Train net output #0: loss = 1.14537 (* 1 = 1.14537 loss)
I0520 18:12:20.845993 24275 sgd_solver.cpp:106] Iteration 451500, lr = 0.0025
I0520 18:12:37.785756 24275 solver.cpp:237] Iteration 453000, loss = 1.22942
I0520 18:12:37.785801 24275 solver.cpp:253]     Train net output #0: loss = 1.22943 (* 1 = 1.22943 loss)
I0520 18:12:37.785816 24275 sgd_solver.cpp:106] Iteration 453000, lr = 0.0025
aprun: Apid 11233226: Caught signal Terminated, sending to application
*** Aborted at 1463782365 (unix time) try "date -d @1463782365" if you are using GNU date ***
aprun: Apid 11233226: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x5ed0) received by PID 24275 (TID 0x2aaac746f900) from PID 24272; stack trace: ***
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
=>> PBS: job killed: walltime 7214 exceeded limit 7200
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11233226: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11233226: Caught signal Terminated, sending to application
aprun: Apid 11233226: Caught signal Terminated, sending to application
aprun: Apid 11233226: Caught signal Terminated, sending to application
aprun: Apid 11233226: Caught signal Terminated, sending to application
aprun: Apid 11233226: Caught signal Terminated, sending to application
aprun: Apid 11233226: Caught signal Terminated, sending to application
aprun: Apid 11233226: Caught signal Terminated, sending to application
aprun: Apid 11233226: Caught signal Terminated, sending to application
