2810395
I0525 12:54:49.510432 21107 caffe.cpp:184] Using GPUs 0
I0525 12:54:49.936473 21107 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.0005
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990.prototxt"
I0525 12:54:49.938618 21107 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990.prototxt
I0525 12:54:49.959203 21107 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 12:54:49.959260 21107 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 12:54:49.959607 21107 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 12:54:49.959785 21107 layer_factory.hpp:77] Creating layer data_hdf5
I0525 12:54:49.959808 21107 net.cpp:106] Creating Layer data_hdf5
I0525 12:54:49.959823 21107 net.cpp:411] data_hdf5 -> data
I0525 12:54:49.959856 21107 net.cpp:411] data_hdf5 -> label
I0525 12:54:49.959888 21107 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 12:54:49.961612 21107 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 12:54:49.963799 21107 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 12:55:11.556095 21107 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 12:55:11.561305 21107 net.cpp:150] Setting up data_hdf5
I0525 12:55:11.561343 21107 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 12:55:11.561358 21107 net.cpp:157] Top shape: 100 (100)
I0525 12:55:11.561370 21107 net.cpp:165] Memory required for data: 2540400
I0525 12:55:11.561383 21107 layer_factory.hpp:77] Creating layer conv1
I0525 12:55:11.561417 21107 net.cpp:106] Creating Layer conv1
I0525 12:55:11.561429 21107 net.cpp:454] conv1 <- data
I0525 12:55:11.561451 21107 net.cpp:411] conv1 -> conv1
I0525 12:55:11.938366 21107 net.cpp:150] Setting up conv1
I0525 12:55:11.938413 21107 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 12:55:11.938424 21107 net.cpp:165] Memory required for data: 30188400
I0525 12:55:11.938452 21107 layer_factory.hpp:77] Creating layer relu1
I0525 12:55:11.938474 21107 net.cpp:106] Creating Layer relu1
I0525 12:55:11.938485 21107 net.cpp:454] relu1 <- conv1
I0525 12:55:11.938498 21107 net.cpp:397] relu1 -> conv1 (in-place)
I0525 12:55:11.939009 21107 net.cpp:150] Setting up relu1
I0525 12:55:11.939026 21107 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 12:55:11.939038 21107 net.cpp:165] Memory required for data: 57836400
I0525 12:55:11.939048 21107 layer_factory.hpp:77] Creating layer pool1
I0525 12:55:11.939064 21107 net.cpp:106] Creating Layer pool1
I0525 12:55:11.939074 21107 net.cpp:454] pool1 <- conv1
I0525 12:55:11.939087 21107 net.cpp:411] pool1 -> pool1
I0525 12:55:11.939177 21107 net.cpp:150] Setting up pool1
I0525 12:55:11.939191 21107 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 12:55:11.939201 21107 net.cpp:165] Memory required for data: 71660400
I0525 12:55:11.939213 21107 layer_factory.hpp:77] Creating layer conv2
I0525 12:55:11.939234 21107 net.cpp:106] Creating Layer conv2
I0525 12:55:11.939245 21107 net.cpp:454] conv2 <- pool1
I0525 12:55:11.939259 21107 net.cpp:411] conv2 -> conv2
I0525 12:55:11.941973 21107 net.cpp:150] Setting up conv2
I0525 12:55:11.942001 21107 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 12:55:11.942011 21107 net.cpp:165] Memory required for data: 91532400
I0525 12:55:11.942030 21107 layer_factory.hpp:77] Creating layer relu2
I0525 12:55:11.942044 21107 net.cpp:106] Creating Layer relu2
I0525 12:55:11.942054 21107 net.cpp:454] relu2 <- conv2
I0525 12:55:11.942067 21107 net.cpp:397] relu2 -> conv2 (in-place)
I0525 12:55:11.942396 21107 net.cpp:150] Setting up relu2
I0525 12:55:11.942410 21107 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 12:55:11.942421 21107 net.cpp:165] Memory required for data: 111404400
I0525 12:55:11.942431 21107 layer_factory.hpp:77] Creating layer pool2
I0525 12:55:11.942443 21107 net.cpp:106] Creating Layer pool2
I0525 12:55:11.942453 21107 net.cpp:454] pool2 <- conv2
I0525 12:55:11.942466 21107 net.cpp:411] pool2 -> pool2
I0525 12:55:11.942546 21107 net.cpp:150] Setting up pool2
I0525 12:55:11.942560 21107 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 12:55:11.942570 21107 net.cpp:165] Memory required for data: 121340400
I0525 12:55:11.942577 21107 layer_factory.hpp:77] Creating layer conv3
I0525 12:55:11.942596 21107 net.cpp:106] Creating Layer conv3
I0525 12:55:11.942607 21107 net.cpp:454] conv3 <- pool2
I0525 12:55:11.942620 21107 net.cpp:411] conv3 -> conv3
I0525 12:55:11.944535 21107 net.cpp:150] Setting up conv3
I0525 12:55:11.944560 21107 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 12:55:11.944571 21107 net.cpp:165] Memory required for data: 132182000
I0525 12:55:11.944589 21107 layer_factory.hpp:77] Creating layer relu3
I0525 12:55:11.944605 21107 net.cpp:106] Creating Layer relu3
I0525 12:55:11.944615 21107 net.cpp:454] relu3 <- conv3
I0525 12:55:11.944628 21107 net.cpp:397] relu3 -> conv3 (in-place)
I0525 12:55:11.945091 21107 net.cpp:150] Setting up relu3
I0525 12:55:11.945108 21107 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 12:55:11.945118 21107 net.cpp:165] Memory required for data: 143023600
I0525 12:55:11.945128 21107 layer_factory.hpp:77] Creating layer pool3
I0525 12:55:11.945142 21107 net.cpp:106] Creating Layer pool3
I0525 12:55:11.945152 21107 net.cpp:454] pool3 <- conv3
I0525 12:55:11.945163 21107 net.cpp:411] pool3 -> pool3
I0525 12:55:11.945231 21107 net.cpp:150] Setting up pool3
I0525 12:55:11.945245 21107 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 12:55:11.945255 21107 net.cpp:165] Memory required for data: 148444400
I0525 12:55:11.945264 21107 layer_factory.hpp:77] Creating layer conv4
I0525 12:55:11.945281 21107 net.cpp:106] Creating Layer conv4
I0525 12:55:11.945291 21107 net.cpp:454] conv4 <- pool3
I0525 12:55:11.945304 21107 net.cpp:411] conv4 -> conv4
I0525 12:55:11.948242 21107 net.cpp:150] Setting up conv4
I0525 12:55:11.948271 21107 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 12:55:11.948282 21107 net.cpp:165] Memory required for data: 152073200
I0525 12:55:11.948297 21107 layer_factory.hpp:77] Creating layer relu4
I0525 12:55:11.948312 21107 net.cpp:106] Creating Layer relu4
I0525 12:55:11.948323 21107 net.cpp:454] relu4 <- conv4
I0525 12:55:11.948336 21107 net.cpp:397] relu4 -> conv4 (in-place)
I0525 12:55:11.948803 21107 net.cpp:150] Setting up relu4
I0525 12:55:11.948819 21107 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 12:55:11.948830 21107 net.cpp:165] Memory required for data: 155702000
I0525 12:55:11.948840 21107 layer_factory.hpp:77] Creating layer pool4
I0525 12:55:11.948853 21107 net.cpp:106] Creating Layer pool4
I0525 12:55:11.948863 21107 net.cpp:454] pool4 <- conv4
I0525 12:55:11.948876 21107 net.cpp:411] pool4 -> pool4
I0525 12:55:11.948945 21107 net.cpp:150] Setting up pool4
I0525 12:55:11.948958 21107 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 12:55:11.948968 21107 net.cpp:165] Memory required for data: 157516400
I0525 12:55:11.948976 21107 layer_factory.hpp:77] Creating layer ip1
I0525 12:55:11.948997 21107 net.cpp:106] Creating Layer ip1
I0525 12:55:11.949007 21107 net.cpp:454] ip1 <- pool4
I0525 12:55:11.949020 21107 net.cpp:411] ip1 -> ip1
I0525 12:55:11.964406 21107 net.cpp:150] Setting up ip1
I0525 12:55:11.964433 21107 net.cpp:157] Top shape: 100 196 (19600)
I0525 12:55:11.964445 21107 net.cpp:165] Memory required for data: 157594800
I0525 12:55:11.964467 21107 layer_factory.hpp:77] Creating layer relu5
I0525 12:55:11.964481 21107 net.cpp:106] Creating Layer relu5
I0525 12:55:11.964491 21107 net.cpp:454] relu5 <- ip1
I0525 12:55:11.964504 21107 net.cpp:397] relu5 -> ip1 (in-place)
I0525 12:55:11.964846 21107 net.cpp:150] Setting up relu5
I0525 12:55:11.964860 21107 net.cpp:157] Top shape: 100 196 (19600)
I0525 12:55:11.964870 21107 net.cpp:165] Memory required for data: 157673200
I0525 12:55:11.964880 21107 layer_factory.hpp:77] Creating layer drop1
I0525 12:55:11.964901 21107 net.cpp:106] Creating Layer drop1
I0525 12:55:11.964911 21107 net.cpp:454] drop1 <- ip1
I0525 12:55:11.964923 21107 net.cpp:397] drop1 -> ip1 (in-place)
I0525 12:55:11.964982 21107 net.cpp:150] Setting up drop1
I0525 12:55:11.964995 21107 net.cpp:157] Top shape: 100 196 (19600)
I0525 12:55:11.965005 21107 net.cpp:165] Memory required for data: 157751600
I0525 12:55:11.965014 21107 layer_factory.hpp:77] Creating layer ip2
I0525 12:55:11.965034 21107 net.cpp:106] Creating Layer ip2
I0525 12:55:11.965044 21107 net.cpp:454] ip2 <- ip1
I0525 12:55:11.965055 21107 net.cpp:411] ip2 -> ip2
I0525 12:55:11.965522 21107 net.cpp:150] Setting up ip2
I0525 12:55:11.965534 21107 net.cpp:157] Top shape: 100 98 (9800)
I0525 12:55:11.965544 21107 net.cpp:165] Memory required for data: 157790800
I0525 12:55:11.965559 21107 layer_factory.hpp:77] Creating layer relu6
I0525 12:55:11.965572 21107 net.cpp:106] Creating Layer relu6
I0525 12:55:11.965581 21107 net.cpp:454] relu6 <- ip2
I0525 12:55:11.965593 21107 net.cpp:397] relu6 -> ip2 (in-place)
I0525 12:55:11.966114 21107 net.cpp:150] Setting up relu6
I0525 12:55:11.966130 21107 net.cpp:157] Top shape: 100 98 (9800)
I0525 12:55:11.966140 21107 net.cpp:165] Memory required for data: 157830000
I0525 12:55:11.966150 21107 layer_factory.hpp:77] Creating layer drop2
I0525 12:55:11.966162 21107 net.cpp:106] Creating Layer drop2
I0525 12:55:11.966172 21107 net.cpp:454] drop2 <- ip2
I0525 12:55:11.966184 21107 net.cpp:397] drop2 -> ip2 (in-place)
I0525 12:55:11.966226 21107 net.cpp:150] Setting up drop2
I0525 12:55:11.966239 21107 net.cpp:157] Top shape: 100 98 (9800)
I0525 12:55:11.966249 21107 net.cpp:165] Memory required for data: 157869200
I0525 12:55:11.966259 21107 layer_factory.hpp:77] Creating layer ip3
I0525 12:55:11.966272 21107 net.cpp:106] Creating Layer ip3
I0525 12:55:11.966282 21107 net.cpp:454] ip3 <- ip2
I0525 12:55:11.966295 21107 net.cpp:411] ip3 -> ip3
I0525 12:55:11.966505 21107 net.cpp:150] Setting up ip3
I0525 12:55:11.966517 21107 net.cpp:157] Top shape: 100 11 (1100)
I0525 12:55:11.966528 21107 net.cpp:165] Memory required for data: 157873600
I0525 12:55:11.966543 21107 layer_factory.hpp:77] Creating layer drop3
I0525 12:55:11.966555 21107 net.cpp:106] Creating Layer drop3
I0525 12:55:11.966565 21107 net.cpp:454] drop3 <- ip3
I0525 12:55:11.966578 21107 net.cpp:397] drop3 -> ip3 (in-place)
I0525 12:55:11.966616 21107 net.cpp:150] Setting up drop3
I0525 12:55:11.966629 21107 net.cpp:157] Top shape: 100 11 (1100)
I0525 12:55:11.966639 21107 net.cpp:165] Memory required for data: 157878000
I0525 12:55:11.966650 21107 layer_factory.hpp:77] Creating layer loss
I0525 12:55:11.966670 21107 net.cpp:106] Creating Layer loss
I0525 12:55:11.966680 21107 net.cpp:454] loss <- ip3
I0525 12:55:11.966689 21107 net.cpp:454] loss <- label
I0525 12:55:11.966702 21107 net.cpp:411] loss -> loss
I0525 12:55:11.966719 21107 layer_factory.hpp:77] Creating layer loss
I0525 12:55:11.967360 21107 net.cpp:150] Setting up loss
I0525 12:55:11.967381 21107 net.cpp:157] Top shape: (1)
I0525 12:55:11.967394 21107 net.cpp:160]     with loss weight 1
I0525 12:55:11.967437 21107 net.cpp:165] Memory required for data: 157878004
I0525 12:55:11.967447 21107 net.cpp:226] loss needs backward computation.
I0525 12:55:11.967458 21107 net.cpp:226] drop3 needs backward computation.
I0525 12:55:11.967468 21107 net.cpp:226] ip3 needs backward computation.
I0525 12:55:11.967478 21107 net.cpp:226] drop2 needs backward computation.
I0525 12:55:11.967488 21107 net.cpp:226] relu6 needs backward computation.
I0525 12:55:11.967497 21107 net.cpp:226] ip2 needs backward computation.
I0525 12:55:11.967509 21107 net.cpp:226] drop1 needs backward computation.
I0525 12:55:11.967517 21107 net.cpp:226] relu5 needs backward computation.
I0525 12:55:11.967527 21107 net.cpp:226] ip1 needs backward computation.
I0525 12:55:11.967537 21107 net.cpp:226] pool4 needs backward computation.
I0525 12:55:11.967548 21107 net.cpp:226] relu4 needs backward computation.
I0525 12:55:11.967558 21107 net.cpp:226] conv4 needs backward computation.
I0525 12:55:11.967568 21107 net.cpp:226] pool3 needs backward computation.
I0525 12:55:11.967579 21107 net.cpp:226] relu3 needs backward computation.
I0525 12:55:11.967597 21107 net.cpp:226] conv3 needs backward computation.
I0525 12:55:11.967608 21107 net.cpp:226] pool2 needs backward computation.
I0525 12:55:11.967619 21107 net.cpp:226] relu2 needs backward computation.
I0525 12:55:11.967629 21107 net.cpp:226] conv2 needs backward computation.
I0525 12:55:11.967641 21107 net.cpp:226] pool1 needs backward computation.
I0525 12:55:11.967653 21107 net.cpp:226] relu1 needs backward computation.
I0525 12:55:11.967663 21107 net.cpp:226] conv1 needs backward computation.
I0525 12:55:11.967674 21107 net.cpp:228] data_hdf5 does not need backward computation.
I0525 12:55:11.967684 21107 net.cpp:270] This network produces output loss
I0525 12:55:11.967706 21107 net.cpp:283] Network initialization done.
I0525 12:55:11.969434 21107 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990.prototxt
I0525 12:55:11.969504 21107 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 12:55:11.969859 21107 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 12:55:11.970049 21107 layer_factory.hpp:77] Creating layer data_hdf5
I0525 12:55:11.970064 21107 net.cpp:106] Creating Layer data_hdf5
I0525 12:55:11.970077 21107 net.cpp:411] data_hdf5 -> data
I0525 12:55:11.970093 21107 net.cpp:411] data_hdf5 -> label
I0525 12:55:11.970109 21107 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 12:55:11.971505 21107 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 12:55:33.287902 21107 net.cpp:150] Setting up data_hdf5
I0525 12:55:33.288064 21107 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 12:55:33.288079 21107 net.cpp:157] Top shape: 100 (100)
I0525 12:55:33.288091 21107 net.cpp:165] Memory required for data: 2540400
I0525 12:55:33.288105 21107 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 12:55:33.288133 21107 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 12:55:33.288143 21107 net.cpp:454] label_data_hdf5_1_split <- label
I0525 12:55:33.288158 21107 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 12:55:33.288180 21107 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 12:55:33.288254 21107 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 12:55:33.288267 21107 net.cpp:157] Top shape: 100 (100)
I0525 12:55:33.288280 21107 net.cpp:157] Top shape: 100 (100)
I0525 12:55:33.288290 21107 net.cpp:165] Memory required for data: 2541200
I0525 12:55:33.288298 21107 layer_factory.hpp:77] Creating layer conv1
I0525 12:55:33.288318 21107 net.cpp:106] Creating Layer conv1
I0525 12:55:33.288329 21107 net.cpp:454] conv1 <- data
I0525 12:55:33.288343 21107 net.cpp:411] conv1 -> conv1
I0525 12:55:33.290362 21107 net.cpp:150] Setting up conv1
I0525 12:55:33.290381 21107 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 12:55:33.290396 21107 net.cpp:165] Memory required for data: 30189200
I0525 12:55:33.290417 21107 layer_factory.hpp:77] Creating layer relu1
I0525 12:55:33.290431 21107 net.cpp:106] Creating Layer relu1
I0525 12:55:33.290441 21107 net.cpp:454] relu1 <- conv1
I0525 12:55:33.290454 21107 net.cpp:397] relu1 -> conv1 (in-place)
I0525 12:55:33.290951 21107 net.cpp:150] Setting up relu1
I0525 12:55:33.290966 21107 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 12:55:33.290977 21107 net.cpp:165] Memory required for data: 57837200
I0525 12:55:33.290987 21107 layer_factory.hpp:77] Creating layer pool1
I0525 12:55:33.291002 21107 net.cpp:106] Creating Layer pool1
I0525 12:55:33.291013 21107 net.cpp:454] pool1 <- conv1
I0525 12:55:33.291025 21107 net.cpp:411] pool1 -> pool1
I0525 12:55:33.291101 21107 net.cpp:150] Setting up pool1
I0525 12:55:33.291115 21107 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 12:55:33.291133 21107 net.cpp:165] Memory required for data: 71661200
I0525 12:55:33.291144 21107 layer_factory.hpp:77] Creating layer conv2
I0525 12:55:33.291162 21107 net.cpp:106] Creating Layer conv2
I0525 12:55:33.291172 21107 net.cpp:454] conv2 <- pool1
I0525 12:55:33.291187 21107 net.cpp:411] conv2 -> conv2
I0525 12:55:33.293090 21107 net.cpp:150] Setting up conv2
I0525 12:55:33.293107 21107 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 12:55:33.293118 21107 net.cpp:165] Memory required for data: 91533200
I0525 12:55:33.293135 21107 layer_factory.hpp:77] Creating layer relu2
I0525 12:55:33.293149 21107 net.cpp:106] Creating Layer relu2
I0525 12:55:33.293159 21107 net.cpp:454] relu2 <- conv2
I0525 12:55:33.293171 21107 net.cpp:397] relu2 -> conv2 (in-place)
I0525 12:55:33.293506 21107 net.cpp:150] Setting up relu2
I0525 12:55:33.293520 21107 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 12:55:33.293530 21107 net.cpp:165] Memory required for data: 111405200
I0525 12:55:33.293540 21107 layer_factory.hpp:77] Creating layer pool2
I0525 12:55:33.293555 21107 net.cpp:106] Creating Layer pool2
I0525 12:55:33.293563 21107 net.cpp:454] pool2 <- conv2
I0525 12:55:33.293576 21107 net.cpp:411] pool2 -> pool2
I0525 12:55:33.293648 21107 net.cpp:150] Setting up pool2
I0525 12:55:33.293661 21107 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 12:55:33.293671 21107 net.cpp:165] Memory required for data: 121341200
I0525 12:55:33.293679 21107 layer_factory.hpp:77] Creating layer conv3
I0525 12:55:33.293699 21107 net.cpp:106] Creating Layer conv3
I0525 12:55:33.293709 21107 net.cpp:454] conv3 <- pool2
I0525 12:55:33.293723 21107 net.cpp:411] conv3 -> conv3
I0525 12:55:33.295707 21107 net.cpp:150] Setting up conv3
I0525 12:55:33.295730 21107 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 12:55:33.295742 21107 net.cpp:165] Memory required for data: 132182800
I0525 12:55:33.295775 21107 layer_factory.hpp:77] Creating layer relu3
I0525 12:55:33.295789 21107 net.cpp:106] Creating Layer relu3
I0525 12:55:33.295799 21107 net.cpp:454] relu3 <- conv3
I0525 12:55:33.295812 21107 net.cpp:397] relu3 -> conv3 (in-place)
I0525 12:55:33.296283 21107 net.cpp:150] Setting up relu3
I0525 12:55:33.296298 21107 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 12:55:33.296309 21107 net.cpp:165] Memory required for data: 143024400
I0525 12:55:33.296319 21107 layer_factory.hpp:77] Creating layer pool3
I0525 12:55:33.296332 21107 net.cpp:106] Creating Layer pool3
I0525 12:55:33.296342 21107 net.cpp:454] pool3 <- conv3
I0525 12:55:33.296355 21107 net.cpp:411] pool3 -> pool3
I0525 12:55:33.296427 21107 net.cpp:150] Setting up pool3
I0525 12:55:33.296439 21107 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 12:55:33.296449 21107 net.cpp:165] Memory required for data: 148445200
I0525 12:55:33.296459 21107 layer_factory.hpp:77] Creating layer conv4
I0525 12:55:33.296475 21107 net.cpp:106] Creating Layer conv4
I0525 12:55:33.296485 21107 net.cpp:454] conv4 <- pool3
I0525 12:55:33.296499 21107 net.cpp:411] conv4 -> conv4
I0525 12:55:33.298578 21107 net.cpp:150] Setting up conv4
I0525 12:55:33.298599 21107 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 12:55:33.298612 21107 net.cpp:165] Memory required for data: 152074000
I0525 12:55:33.298627 21107 layer_factory.hpp:77] Creating layer relu4
I0525 12:55:33.298640 21107 net.cpp:106] Creating Layer relu4
I0525 12:55:33.298650 21107 net.cpp:454] relu4 <- conv4
I0525 12:55:33.298663 21107 net.cpp:397] relu4 -> conv4 (in-place)
I0525 12:55:33.299140 21107 net.cpp:150] Setting up relu4
I0525 12:55:33.299155 21107 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 12:55:33.299166 21107 net.cpp:165] Memory required for data: 155702800
I0525 12:55:33.299176 21107 layer_factory.hpp:77] Creating layer pool4
I0525 12:55:33.299190 21107 net.cpp:106] Creating Layer pool4
I0525 12:55:33.299199 21107 net.cpp:454] pool4 <- conv4
I0525 12:55:33.299212 21107 net.cpp:411] pool4 -> pool4
I0525 12:55:33.299283 21107 net.cpp:150] Setting up pool4
I0525 12:55:33.299296 21107 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 12:55:33.299306 21107 net.cpp:165] Memory required for data: 157517200
I0525 12:55:33.299316 21107 layer_factory.hpp:77] Creating layer ip1
I0525 12:55:33.299332 21107 net.cpp:106] Creating Layer ip1
I0525 12:55:33.299343 21107 net.cpp:454] ip1 <- pool4
I0525 12:55:33.299357 21107 net.cpp:411] ip1 -> ip1
I0525 12:55:33.314788 21107 net.cpp:150] Setting up ip1
I0525 12:55:33.314815 21107 net.cpp:157] Top shape: 100 196 (19600)
I0525 12:55:33.314826 21107 net.cpp:165] Memory required for data: 157595600
I0525 12:55:33.314849 21107 layer_factory.hpp:77] Creating layer relu5
I0525 12:55:33.314864 21107 net.cpp:106] Creating Layer relu5
I0525 12:55:33.314875 21107 net.cpp:454] relu5 <- ip1
I0525 12:55:33.314888 21107 net.cpp:397] relu5 -> ip1 (in-place)
I0525 12:55:33.315243 21107 net.cpp:150] Setting up relu5
I0525 12:55:33.315258 21107 net.cpp:157] Top shape: 100 196 (19600)
I0525 12:55:33.315268 21107 net.cpp:165] Memory required for data: 157674000
I0525 12:55:33.315277 21107 layer_factory.hpp:77] Creating layer drop1
I0525 12:55:33.315295 21107 net.cpp:106] Creating Layer drop1
I0525 12:55:33.315305 21107 net.cpp:454] drop1 <- ip1
I0525 12:55:33.315318 21107 net.cpp:397] drop1 -> ip1 (in-place)
I0525 12:55:33.315362 21107 net.cpp:150] Setting up drop1
I0525 12:55:33.315376 21107 net.cpp:157] Top shape: 100 196 (19600)
I0525 12:55:33.315385 21107 net.cpp:165] Memory required for data: 157752400
I0525 12:55:33.315397 21107 layer_factory.hpp:77] Creating layer ip2
I0525 12:55:33.315410 21107 net.cpp:106] Creating Layer ip2
I0525 12:55:33.315420 21107 net.cpp:454] ip2 <- ip1
I0525 12:55:33.315434 21107 net.cpp:411] ip2 -> ip2
I0525 12:55:33.315912 21107 net.cpp:150] Setting up ip2
I0525 12:55:33.315927 21107 net.cpp:157] Top shape: 100 98 (9800)
I0525 12:55:33.315937 21107 net.cpp:165] Memory required for data: 157791600
I0525 12:55:33.315953 21107 layer_factory.hpp:77] Creating layer relu6
I0525 12:55:33.315979 21107 net.cpp:106] Creating Layer relu6
I0525 12:55:33.315989 21107 net.cpp:454] relu6 <- ip2
I0525 12:55:33.316001 21107 net.cpp:397] relu6 -> ip2 (in-place)
I0525 12:55:33.316532 21107 net.cpp:150] Setting up relu6
I0525 12:55:33.316548 21107 net.cpp:157] Top shape: 100 98 (9800)
I0525 12:55:33.316556 21107 net.cpp:165] Memory required for data: 157830800
I0525 12:55:33.316566 21107 layer_factory.hpp:77] Creating layer drop2
I0525 12:55:33.316581 21107 net.cpp:106] Creating Layer drop2
I0525 12:55:33.316591 21107 net.cpp:454] drop2 <- ip2
I0525 12:55:33.316603 21107 net.cpp:397] drop2 -> ip2 (in-place)
I0525 12:55:33.316647 21107 net.cpp:150] Setting up drop2
I0525 12:55:33.316659 21107 net.cpp:157] Top shape: 100 98 (9800)
I0525 12:55:33.316669 21107 net.cpp:165] Memory required for data: 157870000
I0525 12:55:33.316679 21107 layer_factory.hpp:77] Creating layer ip3
I0525 12:55:33.316694 21107 net.cpp:106] Creating Layer ip3
I0525 12:55:33.316704 21107 net.cpp:454] ip3 <- ip2
I0525 12:55:33.316717 21107 net.cpp:411] ip3 -> ip3
I0525 12:55:33.316939 21107 net.cpp:150] Setting up ip3
I0525 12:55:33.316952 21107 net.cpp:157] Top shape: 100 11 (1100)
I0525 12:55:33.316962 21107 net.cpp:165] Memory required for data: 157874400
I0525 12:55:33.316977 21107 layer_factory.hpp:77] Creating layer drop3
I0525 12:55:33.316990 21107 net.cpp:106] Creating Layer drop3
I0525 12:55:33.317000 21107 net.cpp:454] drop3 <- ip3
I0525 12:55:33.317013 21107 net.cpp:397] drop3 -> ip3 (in-place)
I0525 12:55:33.317054 21107 net.cpp:150] Setting up drop3
I0525 12:55:33.317067 21107 net.cpp:157] Top shape: 100 11 (1100)
I0525 12:55:33.317077 21107 net.cpp:165] Memory required for data: 157878800
I0525 12:55:33.317087 21107 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 12:55:33.317101 21107 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 12:55:33.317111 21107 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 12:55:33.317122 21107 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 12:55:33.317138 21107 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 12:55:33.317211 21107 net.cpp:150] Setting up ip3_drop3_0_split
I0525 12:55:33.317224 21107 net.cpp:157] Top shape: 100 11 (1100)
I0525 12:55:33.317237 21107 net.cpp:157] Top shape: 100 11 (1100)
I0525 12:55:33.317247 21107 net.cpp:165] Memory required for data: 157887600
I0525 12:55:33.317257 21107 layer_factory.hpp:77] Creating layer accuracy
I0525 12:55:33.317278 21107 net.cpp:106] Creating Layer accuracy
I0525 12:55:33.317288 21107 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 12:55:33.317299 21107 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 12:55:33.317313 21107 net.cpp:411] accuracy -> accuracy
I0525 12:55:33.317337 21107 net.cpp:150] Setting up accuracy
I0525 12:55:33.317348 21107 net.cpp:157] Top shape: (1)
I0525 12:55:33.317358 21107 net.cpp:165] Memory required for data: 157887604
I0525 12:55:33.317368 21107 layer_factory.hpp:77] Creating layer loss
I0525 12:55:33.317383 21107 net.cpp:106] Creating Layer loss
I0525 12:55:33.317392 21107 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 12:55:33.317404 21107 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 12:55:33.317416 21107 net.cpp:411] loss -> loss
I0525 12:55:33.317435 21107 layer_factory.hpp:77] Creating layer loss
I0525 12:55:33.317920 21107 net.cpp:150] Setting up loss
I0525 12:55:33.317934 21107 net.cpp:157] Top shape: (1)
I0525 12:55:33.317945 21107 net.cpp:160]     with loss weight 1
I0525 12:55:33.317962 21107 net.cpp:165] Memory required for data: 157887608
I0525 12:55:33.317972 21107 net.cpp:226] loss needs backward computation.
I0525 12:55:33.317983 21107 net.cpp:228] accuracy does not need backward computation.
I0525 12:55:33.317994 21107 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 12:55:33.318006 21107 net.cpp:226] drop3 needs backward computation.
I0525 12:55:33.318014 21107 net.cpp:226] ip3 needs backward computation.
I0525 12:55:33.318025 21107 net.cpp:226] drop2 needs backward computation.
I0525 12:55:33.318043 21107 net.cpp:226] relu6 needs backward computation.
I0525 12:55:33.318053 21107 net.cpp:226] ip2 needs backward computation.
I0525 12:55:33.318063 21107 net.cpp:226] drop1 needs backward computation.
I0525 12:55:33.318073 21107 net.cpp:226] relu5 needs backward computation.
I0525 12:55:33.318083 21107 net.cpp:226] ip1 needs backward computation.
I0525 12:55:33.318092 21107 net.cpp:226] pool4 needs backward computation.
I0525 12:55:33.318104 21107 net.cpp:226] relu4 needs backward computation.
I0525 12:55:33.318114 21107 net.cpp:226] conv4 needs backward computation.
I0525 12:55:33.318125 21107 net.cpp:226] pool3 needs backward computation.
I0525 12:55:33.318135 21107 net.cpp:226] relu3 needs backward computation.
I0525 12:55:33.318145 21107 net.cpp:226] conv3 needs backward computation.
I0525 12:55:33.318155 21107 net.cpp:226] pool2 needs backward computation.
I0525 12:55:33.318166 21107 net.cpp:226] relu2 needs backward computation.
I0525 12:55:33.318176 21107 net.cpp:226] conv2 needs backward computation.
I0525 12:55:33.318186 21107 net.cpp:226] pool1 needs backward computation.
I0525 12:55:33.318197 21107 net.cpp:226] relu1 needs backward computation.
I0525 12:55:33.318205 21107 net.cpp:226] conv1 needs backward computation.
I0525 12:55:33.318217 21107 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 12:55:33.318229 21107 net.cpp:228] data_hdf5 does not need backward computation.
I0525 12:55:33.318239 21107 net.cpp:270] This network produces output accuracy
I0525 12:55:33.318249 21107 net.cpp:270] This network produces output loss
I0525 12:55:33.318276 21107 net.cpp:283] Network initialization done.
I0525 12:55:33.318409 21107 solver.cpp:60] Solver scaffolding done.
I0525 12:55:33.319555 21107 caffe.cpp:212] Starting Optimization
I0525 12:55:33.319573 21107 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 12:55:33.319587 21107 solver.cpp:289] Learning Rate Policy: fixed
I0525 12:55:33.320649 21107 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 12:56:21.100088 21107 solver.cpp:409]     Test net output #0: accuracy = 0.1078
I0525 12:56:21.100249 21107 solver.cpp:409]     Test net output #1: loss = 2.39686 (* 1 = 2.39686 loss)
I0525 12:56:21.133136 21107 solver.cpp:237] Iteration 0, loss = 2.39792
I0525 12:56:21.133173 21107 solver.cpp:253]     Train net output #0: loss = 2.39792 (* 1 = 2.39792 loss)
I0525 12:56:21.133190 21107 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0525 12:56:29.857051 21107 solver.cpp:237] Iteration 150, loss = 2.34074
I0525 12:56:29.857089 21107 solver.cpp:253]     Train net output #0: loss = 2.34074 (* 1 = 2.34074 loss)
I0525 12:56:29.857103 21107 sgd_solver.cpp:106] Iteration 150, lr = 0.0005
I0525 12:56:38.585491 21107 solver.cpp:237] Iteration 300, loss = 2.32889
I0525 12:56:38.585535 21107 solver.cpp:253]     Train net output #0: loss = 2.32889 (* 1 = 2.32889 loss)
I0525 12:56:38.585552 21107 sgd_solver.cpp:106] Iteration 300, lr = 0.0005
I0525 12:56:47.315158 21107 solver.cpp:237] Iteration 450, loss = 2.33372
I0525 12:56:47.315194 21107 solver.cpp:253]     Train net output #0: loss = 2.33372 (* 1 = 2.33372 loss)
I0525 12:56:47.315210 21107 sgd_solver.cpp:106] Iteration 450, lr = 0.0005
I0525 12:56:56.046174 21107 solver.cpp:237] Iteration 600, loss = 2.29962
I0525 12:56:56.046321 21107 solver.cpp:253]     Train net output #0: loss = 2.29962 (* 1 = 2.29962 loss)
I0525 12:56:56.046337 21107 sgd_solver.cpp:106] Iteration 600, lr = 0.0005
I0525 12:57:04.783963 21107 solver.cpp:237] Iteration 750, loss = 2.32929
I0525 12:57:04.784000 21107 solver.cpp:253]     Train net output #0: loss = 2.32929 (* 1 = 2.32929 loss)
I0525 12:57:04.784021 21107 sgd_solver.cpp:106] Iteration 750, lr = 0.0005
I0525 12:57:13.508852 21107 solver.cpp:237] Iteration 900, loss = 2.3585
I0525 12:57:13.508888 21107 solver.cpp:253]     Train net output #0: loss = 2.3585 (* 1 = 2.3585 loss)
I0525 12:57:13.508903 21107 sgd_solver.cpp:106] Iteration 900, lr = 0.0005
I0525 12:57:44.362294 21107 solver.cpp:237] Iteration 1050, loss = 2.29488
I0525 12:57:44.362465 21107 solver.cpp:253]     Train net output #0: loss = 2.29488 (* 1 = 2.29488 loss)
I0525 12:57:44.362481 21107 sgd_solver.cpp:106] Iteration 1050, lr = 0.0005
I0525 12:57:53.093448 21107 solver.cpp:237] Iteration 1200, loss = 2.31174
I0525 12:57:53.093484 21107 solver.cpp:253]     Train net output #0: loss = 2.31174 (* 1 = 2.31174 loss)
I0525 12:57:53.093507 21107 sgd_solver.cpp:106] Iteration 1200, lr = 0.0005
I0525 12:58:01.820583 21107 solver.cpp:237] Iteration 1350, loss = 2.30575
I0525 12:58:01.820618 21107 solver.cpp:253]     Train net output #0: loss = 2.30575 (* 1 = 2.30575 loss)
I0525 12:58:01.820634 21107 sgd_solver.cpp:106] Iteration 1350, lr = 0.0005
I0525 12:58:10.497048 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_1500.caffemodel
I0525 12:58:10.579800 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_1500.solverstate
I0525 12:58:10.626058 21107 solver.cpp:237] Iteration 1500, loss = 2.21254
I0525 12:58:10.626103 21107 solver.cpp:253]     Train net output #0: loss = 2.21254 (* 1 = 2.21254 loss)
I0525 12:58:10.626121 21107 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0525 12:58:19.360327 21107 solver.cpp:237] Iteration 1650, loss = 2.25435
I0525 12:58:19.360481 21107 solver.cpp:253]     Train net output #0: loss = 2.25435 (* 1 = 2.25435 loss)
I0525 12:58:19.360496 21107 sgd_solver.cpp:106] Iteration 1650, lr = 0.0005
I0525 12:58:28.087757 21107 solver.cpp:237] Iteration 1800, loss = 2.12151
I0525 12:58:28.087791 21107 solver.cpp:253]     Train net output #0: loss = 2.12151 (* 1 = 2.12151 loss)
I0525 12:58:28.087808 21107 sgd_solver.cpp:106] Iteration 1800, lr = 0.0005
I0525 12:58:36.816082 21107 solver.cpp:237] Iteration 1950, loss = 2.10966
I0525 12:58:36.816117 21107 solver.cpp:253]     Train net output #0: loss = 2.10966 (* 1 = 2.10966 loss)
I0525 12:58:36.816133 21107 sgd_solver.cpp:106] Iteration 1950, lr = 0.0005
I0525 12:59:07.707015 21107 solver.cpp:237] Iteration 2100, loss = 1.98749
I0525 12:59:07.707186 21107 solver.cpp:253]     Train net output #0: loss = 1.98749 (* 1 = 1.98749 loss)
I0525 12:59:07.707201 21107 sgd_solver.cpp:106] Iteration 2100, lr = 0.0005
I0525 12:59:16.437463 21107 solver.cpp:237] Iteration 2250, loss = 2.13641
I0525 12:59:16.437497 21107 solver.cpp:253]     Train net output #0: loss = 2.13641 (* 1 = 2.13641 loss)
I0525 12:59:16.437515 21107 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0525 12:59:25.165777 21107 solver.cpp:237] Iteration 2400, loss = 2.07411
I0525 12:59:25.165812 21107 solver.cpp:253]     Train net output #0: loss = 2.07411 (* 1 = 2.07411 loss)
I0525 12:59:25.165828 21107 sgd_solver.cpp:106] Iteration 2400, lr = 0.0005
I0525 12:59:33.891464 21107 solver.cpp:237] Iteration 2550, loss = 1.906
I0525 12:59:33.891502 21107 solver.cpp:253]     Train net output #0: loss = 1.906 (* 1 = 1.906 loss)
I0525 12:59:33.891523 21107 sgd_solver.cpp:106] Iteration 2550, lr = 0.0005
I0525 12:59:42.622081 21107 solver.cpp:237] Iteration 2700, loss = 1.94262
I0525 12:59:42.622238 21107 solver.cpp:253]     Train net output #0: loss = 1.94262 (* 1 = 1.94262 loss)
I0525 12:59:42.622252 21107 sgd_solver.cpp:106] Iteration 2700, lr = 0.0005
I0525 12:59:51.353304 21107 solver.cpp:237] Iteration 2850, loss = 1.91237
I0525 12:59:51.353339 21107 solver.cpp:253]     Train net output #0: loss = 1.91237 (* 1 = 1.91237 loss)
I0525 12:59:51.353356 21107 sgd_solver.cpp:106] Iteration 2850, lr = 0.0005
I0525 13:00:00.023655 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_3000.caffemodel
I0525 13:00:00.103145 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_3000.solverstate
I0525 13:00:00.130065 21107 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 13:00:46.968544 21107 solver.cpp:409]     Test net output #0: accuracy = 0.579467
I0525 13:00:46.968703 21107 solver.cpp:409]     Test net output #1: loss = 1.58117 (* 1 = 1.58117 loss)
I0525 13:01:09.154906 21107 solver.cpp:237] Iteration 3000, loss = 1.88466
I0525 13:01:09.154959 21107 solver.cpp:253]     Train net output #0: loss = 1.88466 (* 1 = 1.88466 loss)
I0525 13:01:09.154974 21107 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0525 13:01:17.898986 21107 solver.cpp:237] Iteration 3150, loss = 2.05875
I0525 13:01:17.899142 21107 solver.cpp:253]     Train net output #0: loss = 2.05875 (* 1 = 2.05875 loss)
I0525 13:01:17.899157 21107 sgd_solver.cpp:106] Iteration 3150, lr = 0.0005
I0525 13:01:26.641350 21107 solver.cpp:237] Iteration 3300, loss = 2.08084
I0525 13:01:26.641384 21107 solver.cpp:253]     Train net output #0: loss = 2.08084 (* 1 = 2.08084 loss)
I0525 13:01:26.641402 21107 sgd_solver.cpp:106] Iteration 3300, lr = 0.0005
I0525 13:01:35.382905 21107 solver.cpp:237] Iteration 3450, loss = 1.98311
I0525 13:01:35.382951 21107 solver.cpp:253]     Train net output #0: loss = 1.98311 (* 1 = 1.98311 loss)
I0525 13:01:35.382967 21107 sgd_solver.cpp:106] Iteration 3450, lr = 0.0005
I0525 13:01:44.130039 21107 solver.cpp:237] Iteration 3600, loss = 1.81392
I0525 13:01:44.130075 21107 solver.cpp:253]     Train net output #0: loss = 1.81392 (* 1 = 1.81392 loss)
I0525 13:01:44.130091 21107 sgd_solver.cpp:106] Iteration 3600, lr = 0.0005
I0525 13:01:52.869069 21107 solver.cpp:237] Iteration 3750, loss = 1.92146
I0525 13:01:52.869207 21107 solver.cpp:253]     Train net output #0: loss = 1.92146 (* 1 = 1.92146 loss)
I0525 13:01:52.869223 21107 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0525 13:02:01.612133 21107 solver.cpp:237] Iteration 3900, loss = 1.99443
I0525 13:02:01.612175 21107 solver.cpp:253]     Train net output #0: loss = 1.99443 (* 1 = 1.99443 loss)
I0525 13:02:01.612191 21107 sgd_solver.cpp:106] Iteration 3900, lr = 0.0005
I0525 13:02:32.541785 21107 solver.cpp:237] Iteration 4050, loss = 1.90236
I0525 13:02:32.541949 21107 solver.cpp:253]     Train net output #0: loss = 1.90236 (* 1 = 1.90236 loss)
I0525 13:02:32.541965 21107 sgd_solver.cpp:106] Iteration 4050, lr = 0.0005
I0525 13:02:41.283318 21107 solver.cpp:237] Iteration 4200, loss = 1.80057
I0525 13:02:41.283354 21107 solver.cpp:253]     Train net output #0: loss = 1.80057 (* 1 = 1.80057 loss)
I0525 13:02:41.283368 21107 sgd_solver.cpp:106] Iteration 4200, lr = 0.0005
I0525 13:02:50.022675 21107 solver.cpp:237] Iteration 4350, loss = 1.83774
I0525 13:02:50.022711 21107 solver.cpp:253]     Train net output #0: loss = 1.83774 (* 1 = 1.83774 loss)
I0525 13:02:50.022732 21107 sgd_solver.cpp:106] Iteration 4350, lr = 0.0005
I0525 13:02:58.706729 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_4500.caffemodel
I0525 13:02:58.787804 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_4500.solverstate
I0525 13:02:58.833271 21107 solver.cpp:237] Iteration 4500, loss = 1.64868
I0525 13:02:58.833319 21107 solver.cpp:253]     Train net output #0: loss = 1.64868 (* 1 = 1.64868 loss)
I0525 13:02:58.833333 21107 sgd_solver.cpp:106] Iteration 4500, lr = 0.0005
I0525 13:03:07.573562 21107 solver.cpp:237] Iteration 4650, loss = 1.73095
I0525 13:03:07.573714 21107 solver.cpp:253]     Train net output #0: loss = 1.73095 (* 1 = 1.73095 loss)
I0525 13:03:07.573729 21107 sgd_solver.cpp:106] Iteration 4650, lr = 0.0005
I0525 13:03:16.312706 21107 solver.cpp:237] Iteration 4800, loss = 1.89006
I0525 13:03:16.312753 21107 solver.cpp:253]     Train net output #0: loss = 1.89006 (* 1 = 1.89006 loss)
I0525 13:03:16.312770 21107 sgd_solver.cpp:106] Iteration 4800, lr = 0.0005
I0525 13:03:25.055173 21107 solver.cpp:237] Iteration 4950, loss = 1.75414
I0525 13:03:25.055207 21107 solver.cpp:253]     Train net output #0: loss = 1.75414 (* 1 = 1.75414 loss)
I0525 13:03:25.055224 21107 sgd_solver.cpp:106] Iteration 4950, lr = 0.0005
I0525 13:03:55.913816 21107 solver.cpp:237] Iteration 5100, loss = 1.6313
I0525 13:03:55.913978 21107 solver.cpp:253]     Train net output #0: loss = 1.6313 (* 1 = 1.6313 loss)
I0525 13:03:55.913993 21107 sgd_solver.cpp:106] Iteration 5100, lr = 0.0005
I0525 13:04:04.658563 21107 solver.cpp:237] Iteration 5250, loss = 1.83324
I0525 13:04:04.658604 21107 solver.cpp:253]     Train net output #0: loss = 1.83324 (* 1 = 1.83324 loss)
I0525 13:04:04.658627 21107 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0525 13:04:13.402390 21107 solver.cpp:237] Iteration 5400, loss = 1.77025
I0525 13:04:13.402426 21107 solver.cpp:253]     Train net output #0: loss = 1.77025 (* 1 = 1.77025 loss)
I0525 13:04:13.402438 21107 sgd_solver.cpp:106] Iteration 5400, lr = 0.0005
I0525 13:04:22.143400 21107 solver.cpp:237] Iteration 5550, loss = 1.80656
I0525 13:04:22.143436 21107 solver.cpp:253]     Train net output #0: loss = 1.80656 (* 1 = 1.80656 loss)
I0525 13:04:22.143452 21107 sgd_solver.cpp:106] Iteration 5550, lr = 0.0005
I0525 13:04:30.884989 21107 solver.cpp:237] Iteration 5700, loss = 1.60307
I0525 13:04:30.885149 21107 solver.cpp:253]     Train net output #0: loss = 1.60307 (* 1 = 1.60307 loss)
I0525 13:04:30.885162 21107 sgd_solver.cpp:106] Iteration 5700, lr = 0.0005
I0525 13:04:39.628073 21107 solver.cpp:237] Iteration 5850, loss = 1.8425
I0525 13:04:39.628108 21107 solver.cpp:253]     Train net output #0: loss = 1.8425 (* 1 = 1.8425 loss)
I0525 13:04:39.628124 21107 sgd_solver.cpp:106] Iteration 5850, lr = 0.0005
I0525 13:04:48.309751 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_6000.caffemodel
I0525 13:04:48.389775 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_6000.solverstate
I0525 13:04:48.417250 21107 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 13:05:56.018625 21107 solver.cpp:409]     Test net output #0: accuracy = 0.64176
I0525 13:05:56.018793 21107 solver.cpp:409]     Test net output #1: loss = 1.25569 (* 1 = 1.25569 loss)
I0525 13:06:18.262928 21107 solver.cpp:237] Iteration 6000, loss = 1.70875
I0525 13:06:18.262980 21107 solver.cpp:253]     Train net output #0: loss = 1.70875 (* 1 = 1.70875 loss)
I0525 13:06:18.262995 21107 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0525 13:06:26.995960 21107 solver.cpp:237] Iteration 6150, loss = 1.86207
I0525 13:06:26.996120 21107 solver.cpp:253]     Train net output #0: loss = 1.86207 (* 1 = 1.86207 loss)
I0525 13:06:26.996134 21107 sgd_solver.cpp:106] Iteration 6150, lr = 0.0005
I0525 13:06:35.737303 21107 solver.cpp:237] Iteration 6300, loss = 1.63588
I0525 13:06:35.737346 21107 solver.cpp:253]     Train net output #0: loss = 1.63588 (* 1 = 1.63588 loss)
I0525 13:06:35.737365 21107 sgd_solver.cpp:106] Iteration 6300, lr = 0.0005
I0525 13:06:44.475605 21107 solver.cpp:237] Iteration 6450, loss = 1.77868
I0525 13:06:44.475641 21107 solver.cpp:253]     Train net output #0: loss = 1.77868 (* 1 = 1.77868 loss)
I0525 13:06:44.475657 21107 sgd_solver.cpp:106] Iteration 6450, lr = 0.0005
I0525 13:06:53.214309 21107 solver.cpp:237] Iteration 6600, loss = 1.71228
I0525 13:06:53.214344 21107 solver.cpp:253]     Train net output #0: loss = 1.71228 (* 1 = 1.71228 loss)
I0525 13:06:53.214360 21107 sgd_solver.cpp:106] Iteration 6600, lr = 0.0005
I0525 13:07:01.951742 21107 solver.cpp:237] Iteration 6750, loss = 1.69532
I0525 13:07:01.951894 21107 solver.cpp:253]     Train net output #0: loss = 1.69532 (* 1 = 1.69532 loss)
I0525 13:07:01.951908 21107 sgd_solver.cpp:106] Iteration 6750, lr = 0.0005
I0525 13:07:10.682143 21107 solver.cpp:237] Iteration 6900, loss = 1.61942
I0525 13:07:10.682178 21107 solver.cpp:253]     Train net output #0: loss = 1.61942 (* 1 = 1.61942 loss)
I0525 13:07:10.682191 21107 sgd_solver.cpp:106] Iteration 6900, lr = 0.0005
I0525 13:07:41.630863 21107 solver.cpp:237] Iteration 7050, loss = 1.81174
I0525 13:07:41.631023 21107 solver.cpp:253]     Train net output #0: loss = 1.81174 (* 1 = 1.81174 loss)
I0525 13:07:41.631038 21107 sgd_solver.cpp:106] Iteration 7050, lr = 0.0005
I0525 13:07:50.363905 21107 solver.cpp:237] Iteration 7200, loss = 1.69194
I0525 13:07:50.363941 21107 solver.cpp:253]     Train net output #0: loss = 1.69194 (* 1 = 1.69194 loss)
I0525 13:07:50.363963 21107 sgd_solver.cpp:106] Iteration 7200, lr = 0.0005
I0525 13:07:59.100452 21107 solver.cpp:237] Iteration 7350, loss = 1.63507
I0525 13:07:59.100487 21107 solver.cpp:253]     Train net output #0: loss = 1.63507 (* 1 = 1.63507 loss)
I0525 13:07:59.100503 21107 sgd_solver.cpp:106] Iteration 7350, lr = 0.0005
I0525 13:08:07.781886 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_7500.caffemodel
I0525 13:08:07.863363 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_7500.solverstate
I0525 13:08:07.908452 21107 solver.cpp:237] Iteration 7500, loss = 1.68769
I0525 13:08:07.908502 21107 solver.cpp:253]     Train net output #0: loss = 1.68769 (* 1 = 1.68769 loss)
I0525 13:08:07.908516 21107 sgd_solver.cpp:106] Iteration 7500, lr = 0.0005
I0525 13:08:16.641453 21107 solver.cpp:237] Iteration 7650, loss = 1.68509
I0525 13:08:16.641603 21107 solver.cpp:253]     Train net output #0: loss = 1.68509 (* 1 = 1.68509 loss)
I0525 13:08:16.641616 21107 sgd_solver.cpp:106] Iteration 7650, lr = 0.0005
I0525 13:08:25.367564 21107 solver.cpp:237] Iteration 7800, loss = 1.53607
I0525 13:08:25.367596 21107 solver.cpp:253]     Train net output #0: loss = 1.53607 (* 1 = 1.53607 loss)
I0525 13:08:25.367616 21107 sgd_solver.cpp:106] Iteration 7800, lr = 0.0005
I0525 13:08:34.095525 21107 solver.cpp:237] Iteration 7950, loss = 1.96508
I0525 13:08:34.095559 21107 solver.cpp:253]     Train net output #0: loss = 1.96508 (* 1 = 1.96508 loss)
I0525 13:08:34.095576 21107 sgd_solver.cpp:106] Iteration 7950, lr = 0.0005
I0525 13:09:05.026857 21107 solver.cpp:237] Iteration 8100, loss = 1.57439
I0525 13:09:05.027022 21107 solver.cpp:253]     Train net output #0: loss = 1.57439 (* 1 = 1.57439 loss)
I0525 13:09:05.027036 21107 sgd_solver.cpp:106] Iteration 8100, lr = 0.0005
I0525 13:09:13.756665 21107 solver.cpp:237] Iteration 8250, loss = 1.69081
I0525 13:09:13.756700 21107 solver.cpp:253]     Train net output #0: loss = 1.69081 (* 1 = 1.69081 loss)
I0525 13:09:13.756717 21107 sgd_solver.cpp:106] Iteration 8250, lr = 0.0005
I0525 13:09:22.489979 21107 solver.cpp:237] Iteration 8400, loss = 1.77916
I0525 13:09:22.490015 21107 solver.cpp:253]     Train net output #0: loss = 1.77916 (* 1 = 1.77916 loss)
I0525 13:09:22.490031 21107 sgd_solver.cpp:106] Iteration 8400, lr = 0.0005
I0525 13:09:31.225198 21107 solver.cpp:237] Iteration 8550, loss = 1.66923
I0525 13:09:31.225240 21107 solver.cpp:253]     Train net output #0: loss = 1.66923 (* 1 = 1.66923 loss)
I0525 13:09:31.225253 21107 sgd_solver.cpp:106] Iteration 8550, lr = 0.0005
I0525 13:09:39.959625 21107 solver.cpp:237] Iteration 8700, loss = 1.8215
I0525 13:09:39.959764 21107 solver.cpp:253]     Train net output #0: loss = 1.8215 (* 1 = 1.8215 loss)
I0525 13:09:39.959776 21107 sgd_solver.cpp:106] Iteration 8700, lr = 0.0005
I0525 13:09:48.692103 21107 solver.cpp:237] Iteration 8850, loss = 1.53036
I0525 13:09:48.692138 21107 solver.cpp:253]     Train net output #0: loss = 1.53036 (* 1 = 1.53036 loss)
I0525 13:09:48.692153 21107 sgd_solver.cpp:106] Iteration 8850, lr = 0.0005
I0525 13:09:57.366083 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_9000.caffemodel
I0525 13:09:57.444260 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_9000.solverstate
I0525 13:09:57.469344 21107 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 13:10:43.960535 21107 solver.cpp:409]     Test net output #0: accuracy = 0.677386
I0525 13:10:43.960698 21107 solver.cpp:409]     Test net output #1: loss = 1.11464 (* 1 = 1.11464 loss)
I0525 13:11:06.130477 21107 solver.cpp:237] Iteration 9000, loss = 1.66991
I0525 13:11:06.130528 21107 solver.cpp:253]     Train net output #0: loss = 1.66991 (* 1 = 1.66991 loss)
I0525 13:11:06.130545 21107 sgd_solver.cpp:106] Iteration 9000, lr = 0.0005
I0525 13:11:14.870398 21107 solver.cpp:237] Iteration 9150, loss = 1.57061
I0525 13:11:14.870558 21107 solver.cpp:253]     Train net output #0: loss = 1.57061 (* 1 = 1.57061 loss)
I0525 13:11:14.870573 21107 sgd_solver.cpp:106] Iteration 9150, lr = 0.0005
I0525 13:11:23.610453 21107 solver.cpp:237] Iteration 9300, loss = 1.79606
I0525 13:11:23.610487 21107 solver.cpp:253]     Train net output #0: loss = 1.79606 (* 1 = 1.79606 loss)
I0525 13:11:23.610505 21107 sgd_solver.cpp:106] Iteration 9300, lr = 0.0005
I0525 13:11:32.349185 21107 solver.cpp:237] Iteration 9450, loss = 1.56515
I0525 13:11:32.349220 21107 solver.cpp:253]     Train net output #0: loss = 1.56515 (* 1 = 1.56515 loss)
I0525 13:11:32.349236 21107 sgd_solver.cpp:106] Iteration 9450, lr = 0.0005
I0525 13:11:41.083202 21107 solver.cpp:237] Iteration 9600, loss = 1.69311
I0525 13:11:41.083250 21107 solver.cpp:253]     Train net output #0: loss = 1.69311 (* 1 = 1.69311 loss)
I0525 13:11:41.083264 21107 sgd_solver.cpp:106] Iteration 9600, lr = 0.0005
I0525 13:11:49.822105 21107 solver.cpp:237] Iteration 9750, loss = 1.61109
I0525 13:11:49.822248 21107 solver.cpp:253]     Train net output #0: loss = 1.61109 (* 1 = 1.61109 loss)
I0525 13:11:49.822262 21107 sgd_solver.cpp:106] Iteration 9750, lr = 0.0005
I0525 13:11:58.565346 21107 solver.cpp:237] Iteration 9900, loss = 1.71574
I0525 13:11:58.565379 21107 solver.cpp:253]     Train net output #0: loss = 1.71574 (* 1 = 1.71574 loss)
I0525 13:11:58.565397 21107 sgd_solver.cpp:106] Iteration 9900, lr = 0.0005
I0525 13:12:29.463599 21107 solver.cpp:237] Iteration 10050, loss = 1.73007
I0525 13:12:29.463771 21107 solver.cpp:253]     Train net output #0: loss = 1.73007 (* 1 = 1.73007 loss)
I0525 13:12:29.463788 21107 sgd_solver.cpp:106] Iteration 10050, lr = 0.0005
I0525 13:12:38.199743 21107 solver.cpp:237] Iteration 10200, loss = 1.61671
I0525 13:12:38.199775 21107 solver.cpp:253]     Train net output #0: loss = 1.61671 (* 1 = 1.61671 loss)
I0525 13:12:38.199792 21107 sgd_solver.cpp:106] Iteration 10200, lr = 0.0005
I0525 13:12:46.939301 21107 solver.cpp:237] Iteration 10350, loss = 1.4789
I0525 13:12:46.939334 21107 solver.cpp:253]     Train net output #0: loss = 1.4789 (* 1 = 1.4789 loss)
I0525 13:12:46.939352 21107 sgd_solver.cpp:106] Iteration 10350, lr = 0.0005
I0525 13:12:55.621361 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_10500.caffemodel
I0525 13:12:55.699785 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_10500.solverstate
I0525 13:12:55.743877 21107 solver.cpp:237] Iteration 10500, loss = 1.4959
I0525 13:12:55.743921 21107 solver.cpp:253]     Train net output #0: loss = 1.4959 (* 1 = 1.4959 loss)
I0525 13:12:55.743938 21107 sgd_solver.cpp:106] Iteration 10500, lr = 0.0005
I0525 13:13:04.488613 21107 solver.cpp:237] Iteration 10650, loss = 1.65742
I0525 13:13:04.488759 21107 solver.cpp:253]     Train net output #0: loss = 1.65742 (* 1 = 1.65742 loss)
I0525 13:13:04.488771 21107 sgd_solver.cpp:106] Iteration 10650, lr = 0.0005
I0525 13:13:13.235333 21107 solver.cpp:237] Iteration 10800, loss = 1.7042
I0525 13:13:13.235366 21107 solver.cpp:253]     Train net output #0: loss = 1.7042 (* 1 = 1.7042 loss)
I0525 13:13:13.235383 21107 sgd_solver.cpp:106] Iteration 10800, lr = 0.0005
I0525 13:13:21.980635 21107 solver.cpp:237] Iteration 10950, loss = 1.59902
I0525 13:13:21.980672 21107 solver.cpp:253]     Train net output #0: loss = 1.59902 (* 1 = 1.59902 loss)
I0525 13:13:21.980690 21107 sgd_solver.cpp:106] Iteration 10950, lr = 0.0005
I0525 13:13:52.895159 21107 solver.cpp:237] Iteration 11100, loss = 1.54961
I0525 13:13:52.895325 21107 solver.cpp:253]     Train net output #0: loss = 1.54961 (* 1 = 1.54961 loss)
I0525 13:13:52.895341 21107 sgd_solver.cpp:106] Iteration 11100, lr = 0.0005
I0525 13:14:01.635591 21107 solver.cpp:237] Iteration 11250, loss = 1.80364
I0525 13:14:01.635624 21107 solver.cpp:253]     Train net output #0: loss = 1.80364 (* 1 = 1.80364 loss)
I0525 13:14:01.635642 21107 sgd_solver.cpp:106] Iteration 11250, lr = 0.0005
I0525 13:14:10.375855 21107 solver.cpp:237] Iteration 11400, loss = 1.61141
I0525 13:14:10.375892 21107 solver.cpp:253]     Train net output #0: loss = 1.61141 (* 1 = 1.61141 loss)
I0525 13:14:10.375910 21107 sgd_solver.cpp:106] Iteration 11400, lr = 0.0005
I0525 13:14:19.113555 21107 solver.cpp:237] Iteration 11550, loss = 1.56428
I0525 13:14:19.113590 21107 solver.cpp:253]     Train net output #0: loss = 1.56428 (* 1 = 1.56428 loss)
I0525 13:14:19.113607 21107 sgd_solver.cpp:106] Iteration 11550, lr = 0.0005
I0525 13:14:27.859109 21107 solver.cpp:237] Iteration 11700, loss = 1.5534
I0525 13:14:27.859252 21107 solver.cpp:253]     Train net output #0: loss = 1.5534 (* 1 = 1.5534 loss)
I0525 13:14:27.859266 21107 sgd_solver.cpp:106] Iteration 11700, lr = 0.0005
I0525 13:14:36.601701 21107 solver.cpp:237] Iteration 11850, loss = 1.76196
I0525 13:14:36.601742 21107 solver.cpp:253]     Train net output #0: loss = 1.76196 (* 1 = 1.76196 loss)
I0525 13:14:36.601761 21107 sgd_solver.cpp:106] Iteration 11850, lr = 0.0005
I0525 13:14:45.284705 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_12000.caffemodel
I0525 13:14:45.362933 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_12000.solverstate
I0525 13:14:45.389219 21107 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 13:15:53.091336 21107 solver.cpp:409]     Test net output #0: accuracy = 0.711686
I0525 13:15:53.091511 21107 solver.cpp:409]     Test net output #1: loss = 1.01456 (* 1 = 1.01456 loss)
I0525 13:16:15.248661 21107 solver.cpp:237] Iteration 12000, loss = 1.43929
I0525 13:16:15.248713 21107 solver.cpp:253]     Train net output #0: loss = 1.43929 (* 1 = 1.43929 loss)
I0525 13:16:15.248728 21107 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0525 13:16:23.979863 21107 solver.cpp:237] Iteration 12150, loss = 1.76284
I0525 13:16:23.980015 21107 solver.cpp:253]     Train net output #0: loss = 1.76284 (* 1 = 1.76284 loss)
I0525 13:16:23.980028 21107 sgd_solver.cpp:106] Iteration 12150, lr = 0.0005
I0525 13:16:32.711783 21107 solver.cpp:237] Iteration 12300, loss = 1.30224
I0525 13:16:32.711819 21107 solver.cpp:253]     Train net output #0: loss = 1.30224 (* 1 = 1.30224 loss)
I0525 13:16:32.711835 21107 sgd_solver.cpp:106] Iteration 12300, lr = 0.0005
I0525 13:16:41.442263 21107 solver.cpp:237] Iteration 12450, loss = 1.56285
I0525 13:16:41.442301 21107 solver.cpp:253]     Train net output #0: loss = 1.56285 (* 1 = 1.56285 loss)
I0525 13:16:41.442320 21107 sgd_solver.cpp:106] Iteration 12450, lr = 0.0005
I0525 13:16:50.170722 21107 solver.cpp:237] Iteration 12600, loss = 1.68877
I0525 13:16:50.170758 21107 solver.cpp:253]     Train net output #0: loss = 1.68877 (* 1 = 1.68877 loss)
I0525 13:16:50.170775 21107 sgd_solver.cpp:106] Iteration 12600, lr = 0.0005
I0525 13:16:58.900645 21107 solver.cpp:237] Iteration 12750, loss = 1.6696
I0525 13:16:58.900794 21107 solver.cpp:253]     Train net output #0: loss = 1.6696 (* 1 = 1.6696 loss)
I0525 13:16:58.900810 21107 sgd_solver.cpp:106] Iteration 12750, lr = 0.0005
I0525 13:17:07.633347 21107 solver.cpp:237] Iteration 12900, loss = 1.39408
I0525 13:17:07.633383 21107 solver.cpp:253]     Train net output #0: loss = 1.39408 (* 1 = 1.39408 loss)
I0525 13:17:07.633404 21107 sgd_solver.cpp:106] Iteration 12900, lr = 0.0005
I0525 13:17:38.507714 21107 solver.cpp:237] Iteration 13050, loss = 1.52131
I0525 13:17:38.507875 21107 solver.cpp:253]     Train net output #0: loss = 1.52131 (* 1 = 1.52131 loss)
I0525 13:17:38.507891 21107 sgd_solver.cpp:106] Iteration 13050, lr = 0.0005
I0525 13:17:47.236953 21107 solver.cpp:237] Iteration 13200, loss = 1.46821
I0525 13:17:47.236986 21107 solver.cpp:253]     Train net output #0: loss = 1.46821 (* 1 = 1.46821 loss)
I0525 13:17:47.237004 21107 sgd_solver.cpp:106] Iteration 13200, lr = 0.0005
I0525 13:17:55.966461 21107 solver.cpp:237] Iteration 13350, loss = 1.52729
I0525 13:17:55.966506 21107 solver.cpp:253]     Train net output #0: loss = 1.52729 (* 1 = 1.52729 loss)
I0525 13:17:55.966522 21107 sgd_solver.cpp:106] Iteration 13350, lr = 0.0005
I0525 13:18:04.643816 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_13500.caffemodel
I0525 13:18:04.724123 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_13500.solverstate
I0525 13:18:04.770516 21107 solver.cpp:237] Iteration 13500, loss = 1.54507
I0525 13:18:04.770562 21107 solver.cpp:253]     Train net output #0: loss = 1.54507 (* 1 = 1.54507 loss)
I0525 13:18:04.770581 21107 sgd_solver.cpp:106] Iteration 13500, lr = 0.0005
I0525 13:18:13.502774 21107 solver.cpp:237] Iteration 13650, loss = 1.41432
I0525 13:18:13.502923 21107 solver.cpp:253]     Train net output #0: loss = 1.41432 (* 1 = 1.41432 loss)
I0525 13:18:13.502938 21107 sgd_solver.cpp:106] Iteration 13650, lr = 0.0005
I0525 13:18:22.235097 21107 solver.cpp:237] Iteration 13800, loss = 1.46751
I0525 13:18:22.235141 21107 solver.cpp:253]     Train net output #0: loss = 1.46751 (* 1 = 1.46751 loss)
I0525 13:18:22.235158 21107 sgd_solver.cpp:106] Iteration 13800, lr = 0.0005
I0525 13:18:30.966485 21107 solver.cpp:237] Iteration 13950, loss = 1.63244
I0525 13:18:30.966518 21107 solver.cpp:253]     Train net output #0: loss = 1.63244 (* 1 = 1.63244 loss)
I0525 13:18:30.966534 21107 sgd_solver.cpp:106] Iteration 13950, lr = 0.0005
I0525 13:19:01.826759 21107 solver.cpp:237] Iteration 14100, loss = 1.49447
I0525 13:19:01.826938 21107 solver.cpp:253]     Train net output #0: loss = 1.49447 (* 1 = 1.49447 loss)
I0525 13:19:01.826954 21107 sgd_solver.cpp:106] Iteration 14100, lr = 0.0005
I0525 13:19:10.559983 21107 solver.cpp:237] Iteration 14250, loss = 1.5208
I0525 13:19:10.560024 21107 solver.cpp:253]     Train net output #0: loss = 1.5208 (* 1 = 1.5208 loss)
I0525 13:19:10.560041 21107 sgd_solver.cpp:106] Iteration 14250, lr = 0.0005
I0525 13:19:19.291132 21107 solver.cpp:237] Iteration 14400, loss = 1.55639
I0525 13:19:19.291167 21107 solver.cpp:253]     Train net output #0: loss = 1.55639 (* 1 = 1.55639 loss)
I0525 13:19:19.291183 21107 sgd_solver.cpp:106] Iteration 14400, lr = 0.0005
I0525 13:19:28.024016 21107 solver.cpp:237] Iteration 14550, loss = 1.66558
I0525 13:19:28.024050 21107 solver.cpp:253]     Train net output #0: loss = 1.66558 (* 1 = 1.66558 loss)
I0525 13:19:28.024067 21107 sgd_solver.cpp:106] Iteration 14550, lr = 0.0005
I0525 13:19:36.755082 21107 solver.cpp:237] Iteration 14700, loss = 1.60208
I0525 13:19:36.755254 21107 solver.cpp:253]     Train net output #0: loss = 1.60208 (* 1 = 1.60208 loss)
I0525 13:19:36.755269 21107 sgd_solver.cpp:106] Iteration 14700, lr = 0.0005
I0525 13:19:45.484923 21107 solver.cpp:237] Iteration 14850, loss = 1.30453
I0525 13:19:45.484957 21107 solver.cpp:253]     Train net output #0: loss = 1.30453 (* 1 = 1.30453 loss)
I0525 13:19:45.484973 21107 sgd_solver.cpp:106] Iteration 14850, lr = 0.0005
I0525 13:19:54.158682 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_15000.caffemodel
I0525 13:19:54.238793 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_15000.solverstate
I0525 13:19:54.294930 21107 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 13:20:41.078773 21107 solver.cpp:409]     Test net output #0: accuracy = 0.752793
I0525 13:20:41.078936 21107 solver.cpp:409]     Test net output #1: loss = 0.899877 (* 1 = 0.899877 loss)
I0525 13:21:01.960811 21107 solver.cpp:237] Iteration 15000, loss = 1.39432
I0525 13:21:01.960862 21107 solver.cpp:253]     Train net output #0: loss = 1.39432 (* 1 = 1.39432 loss)
I0525 13:21:01.960880 21107 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0525 13:21:10.702389 21107 solver.cpp:237] Iteration 15150, loss = 1.61452
I0525 13:21:10.702428 21107 solver.cpp:253]     Train net output #0: loss = 1.61452 (* 1 = 1.61452 loss)
I0525 13:21:10.702447 21107 sgd_solver.cpp:106] Iteration 15150, lr = 0.0005
I0525 13:21:19.441717 21107 solver.cpp:237] Iteration 15300, loss = 1.54237
I0525 13:21:19.441862 21107 solver.cpp:253]     Train net output #0: loss = 1.54237 (* 1 = 1.54237 loss)
I0525 13:21:19.441877 21107 sgd_solver.cpp:106] Iteration 15300, lr = 0.0005
I0525 13:21:28.183802 21107 solver.cpp:237] Iteration 15450, loss = 1.34305
I0525 13:21:28.183835 21107 solver.cpp:253]     Train net output #0: loss = 1.34305 (* 1 = 1.34305 loss)
I0525 13:21:28.183852 21107 sgd_solver.cpp:106] Iteration 15450, lr = 0.0005
I0525 13:21:36.920853 21107 solver.cpp:237] Iteration 15600, loss = 1.51832
I0525 13:21:36.920892 21107 solver.cpp:253]     Train net output #0: loss = 1.51832 (* 1 = 1.51832 loss)
I0525 13:21:36.920909 21107 sgd_solver.cpp:106] Iteration 15600, lr = 0.0005
I0525 13:21:45.666340 21107 solver.cpp:237] Iteration 15750, loss = 1.62615
I0525 13:21:45.666374 21107 solver.cpp:253]     Train net output #0: loss = 1.62615 (* 1 = 1.62615 loss)
I0525 13:21:45.666388 21107 sgd_solver.cpp:106] Iteration 15750, lr = 0.0005
I0525 13:21:54.410706 21107 solver.cpp:237] Iteration 15900, loss = 1.42948
I0525 13:21:54.410859 21107 solver.cpp:253]     Train net output #0: loss = 1.42948 (* 1 = 1.42948 loss)
I0525 13:21:54.410876 21107 sgd_solver.cpp:106] Iteration 15900, lr = 0.0005
I0525 13:22:23.992980 21107 solver.cpp:237] Iteration 16050, loss = 1.40479
I0525 13:22:23.993031 21107 solver.cpp:253]     Train net output #0: loss = 1.40479 (* 1 = 1.40479 loss)
I0525 13:22:23.993046 21107 sgd_solver.cpp:106] Iteration 16050, lr = 0.0005
I0525 13:22:32.735541 21107 solver.cpp:237] Iteration 16200, loss = 1.4863
I0525 13:22:32.735703 21107 solver.cpp:253]     Train net output #0: loss = 1.4863 (* 1 = 1.4863 loss)
I0525 13:22:32.735718 21107 sgd_solver.cpp:106] Iteration 16200, lr = 0.0005
I0525 13:22:41.479174 21107 solver.cpp:237] Iteration 16350, loss = 1.55426
I0525 13:22:41.479209 21107 solver.cpp:253]     Train net output #0: loss = 1.55426 (* 1 = 1.55426 loss)
I0525 13:22:41.479225 21107 sgd_solver.cpp:106] Iteration 16350, lr = 0.0005
I0525 13:22:50.165874 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_16500.caffemodel
I0525 13:22:50.244027 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_16500.solverstate
I0525 13:22:50.287307 21107 solver.cpp:237] Iteration 16500, loss = 1.55428
I0525 13:22:50.287351 21107 solver.cpp:253]     Train net output #0: loss = 1.55428 (* 1 = 1.55428 loss)
I0525 13:22:50.287364 21107 sgd_solver.cpp:106] Iteration 16500, lr = 0.0005
I0525 13:22:59.029682 21107 solver.cpp:237] Iteration 16650, loss = 1.65709
I0525 13:22:59.029717 21107 solver.cpp:253]     Train net output #0: loss = 1.65709 (* 1 = 1.65709 loss)
I0525 13:22:59.029734 21107 sgd_solver.cpp:106] Iteration 16650, lr = 0.0005
I0525 13:23:07.768412 21107 solver.cpp:237] Iteration 16800, loss = 1.462
I0525 13:23:07.768561 21107 solver.cpp:253]     Train net output #0: loss = 1.462 (* 1 = 1.462 loss)
I0525 13:23:07.768576 21107 sgd_solver.cpp:106] Iteration 16800, lr = 0.0005
I0525 13:23:16.505249 21107 solver.cpp:237] Iteration 16950, loss = 1.5036
I0525 13:23:16.505292 21107 solver.cpp:253]     Train net output #0: loss = 1.5036 (* 1 = 1.5036 loss)
I0525 13:23:16.505306 21107 sgd_solver.cpp:106] Iteration 16950, lr = 0.0005
I0525 13:23:46.063629 21107 solver.cpp:237] Iteration 17100, loss = 1.47485
I0525 13:23:46.063809 21107 solver.cpp:253]     Train net output #0: loss = 1.47485 (* 1 = 1.47485 loss)
I0525 13:23:46.063823 21107 sgd_solver.cpp:106] Iteration 17100, lr = 0.0005
I0525 13:23:54.810173 21107 solver.cpp:237] Iteration 17250, loss = 1.65828
I0525 13:23:54.810207 21107 solver.cpp:253]     Train net output #0: loss = 1.65828 (* 1 = 1.65828 loss)
I0525 13:23:54.810225 21107 sgd_solver.cpp:106] Iteration 17250, lr = 0.0005
I0525 13:24:03.550483 21107 solver.cpp:237] Iteration 17400, loss = 1.37087
I0525 13:24:03.550518 21107 solver.cpp:253]     Train net output #0: loss = 1.37087 (* 1 = 1.37087 loss)
I0525 13:24:03.550534 21107 sgd_solver.cpp:106] Iteration 17400, lr = 0.0005
I0525 13:24:12.289907 21107 solver.cpp:237] Iteration 17550, loss = 1.34473
I0525 13:24:12.289942 21107 solver.cpp:253]     Train net output #0: loss = 1.34473 (* 1 = 1.34473 loss)
I0525 13:24:12.289961 21107 sgd_solver.cpp:106] Iteration 17550, lr = 0.0005
I0525 13:24:21.033561 21107 solver.cpp:237] Iteration 17700, loss = 1.60848
I0525 13:24:21.033715 21107 solver.cpp:253]     Train net output #0: loss = 1.60848 (* 1 = 1.60848 loss)
I0525 13:24:21.033730 21107 sgd_solver.cpp:106] Iteration 17700, lr = 0.0005
I0525 13:24:29.773948 21107 solver.cpp:237] Iteration 17850, loss = 1.55569
I0525 13:24:29.773986 21107 solver.cpp:253]     Train net output #0: loss = 1.55569 (* 1 = 1.55569 loss)
I0525 13:24:29.774008 21107 sgd_solver.cpp:106] Iteration 17850, lr = 0.0005
I0525 13:24:38.455432 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_18000.caffemodel
I0525 13:24:38.534477 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_18000.solverstate
I0525 13:24:38.559875 21107 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 13:25:46.258858 21107 solver.cpp:409]     Test net output #0: accuracy = 0.764081
I0525 13:25:46.259030 21107 solver.cpp:409]     Test net output #1: loss = 0.861174 (* 1 = 0.861174 loss)
I0525 13:26:07.138911 21107 solver.cpp:237] Iteration 18000, loss = 1.54045
I0525 13:26:07.138962 21107 solver.cpp:253]     Train net output #0: loss = 1.54045 (* 1 = 1.54045 loss)
I0525 13:26:07.138978 21107 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0525 13:26:15.873252 21107 solver.cpp:237] Iteration 18150, loss = 1.44395
I0525 13:26:15.873294 21107 solver.cpp:253]     Train net output #0: loss = 1.44395 (* 1 = 1.44395 loss)
I0525 13:26:15.873311 21107 sgd_solver.cpp:106] Iteration 18150, lr = 0.0005
I0525 13:26:24.607489 21107 solver.cpp:237] Iteration 18300, loss = 1.61217
I0525 13:26:24.607650 21107 solver.cpp:253]     Train net output #0: loss = 1.61217 (* 1 = 1.61217 loss)
I0525 13:26:24.607663 21107 sgd_solver.cpp:106] Iteration 18300, lr = 0.0005
I0525 13:26:33.341732 21107 solver.cpp:237] Iteration 18450, loss = 1.64193
I0525 13:26:33.341766 21107 solver.cpp:253]     Train net output #0: loss = 1.64193 (* 1 = 1.64193 loss)
I0525 13:26:33.341784 21107 sgd_solver.cpp:106] Iteration 18450, lr = 0.0005
I0525 13:26:42.073812 21107 solver.cpp:237] Iteration 18600, loss = 1.4963
I0525 13:26:42.073854 21107 solver.cpp:253]     Train net output #0: loss = 1.4963 (* 1 = 1.4963 loss)
I0525 13:26:42.073873 21107 sgd_solver.cpp:106] Iteration 18600, lr = 0.0005
I0525 13:26:50.807474 21107 solver.cpp:237] Iteration 18750, loss = 1.65837
I0525 13:26:50.807508 21107 solver.cpp:253]     Train net output #0: loss = 1.65837 (* 1 = 1.65837 loss)
I0525 13:26:50.807525 21107 sgd_solver.cpp:106] Iteration 18750, lr = 0.0005
I0525 13:26:59.544772 21107 solver.cpp:237] Iteration 18900, loss = 1.47821
I0525 13:26:59.544926 21107 solver.cpp:253]     Train net output #0: loss = 1.47821 (* 1 = 1.47821 loss)
I0525 13:26:59.544940 21107 sgd_solver.cpp:106] Iteration 18900, lr = 0.0005
I0525 13:27:29.183799 21107 solver.cpp:237] Iteration 19050, loss = 1.64927
I0525 13:27:29.183847 21107 solver.cpp:253]     Train net output #0: loss = 1.64927 (* 1 = 1.64927 loss)
I0525 13:27:29.183866 21107 sgd_solver.cpp:106] Iteration 19050, lr = 0.0005
I0525 13:27:37.916491 21107 solver.cpp:237] Iteration 19200, loss = 1.45631
I0525 13:27:37.916654 21107 solver.cpp:253]     Train net output #0: loss = 1.45631 (* 1 = 1.45631 loss)
I0525 13:27:37.916667 21107 sgd_solver.cpp:106] Iteration 19200, lr = 0.0005
I0525 13:27:46.655588 21107 solver.cpp:237] Iteration 19350, loss = 1.50298
I0525 13:27:46.655622 21107 solver.cpp:253]     Train net output #0: loss = 1.50298 (* 1 = 1.50298 loss)
I0525 13:27:46.655640 21107 sgd_solver.cpp:106] Iteration 19350, lr = 0.0005
I0525 13:27:55.332788 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_19500.caffemodel
I0525 13:27:55.412001 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_19500.solverstate
I0525 13:27:55.457986 21107 solver.cpp:237] Iteration 19500, loss = 1.50402
I0525 13:27:55.458031 21107 solver.cpp:253]     Train net output #0: loss = 1.50402 (* 1 = 1.50402 loss)
I0525 13:27:55.458051 21107 sgd_solver.cpp:106] Iteration 19500, lr = 0.0005
I0525 13:28:04.192358 21107 solver.cpp:237] Iteration 19650, loss = 1.66437
I0525 13:28:04.192391 21107 solver.cpp:253]     Train net output #0: loss = 1.66437 (* 1 = 1.66437 loss)
I0525 13:28:04.192405 21107 sgd_solver.cpp:106] Iteration 19650, lr = 0.0005
I0525 13:28:12.921414 21107 solver.cpp:237] Iteration 19800, loss = 1.51966
I0525 13:28:12.921577 21107 solver.cpp:253]     Train net output #0: loss = 1.51966 (* 1 = 1.51966 loss)
I0525 13:28:12.921591 21107 sgd_solver.cpp:106] Iteration 19800, lr = 0.0005
I0525 13:28:21.650972 21107 solver.cpp:237] Iteration 19950, loss = 1.40079
I0525 13:28:21.651008 21107 solver.cpp:253]     Train net output #0: loss = 1.40079 (* 1 = 1.40079 loss)
I0525 13:28:21.651027 21107 sgd_solver.cpp:106] Iteration 19950, lr = 0.0005
I0525 13:28:51.245508 21107 solver.cpp:237] Iteration 20100, loss = 1.4431
I0525 13:28:51.245681 21107 solver.cpp:253]     Train net output #0: loss = 1.4431 (* 1 = 1.4431 loss)
I0525 13:28:51.245694 21107 sgd_solver.cpp:106] Iteration 20100, lr = 0.0005
I0525 13:28:59.989218 21107 solver.cpp:237] Iteration 20250, loss = 1.2716
I0525 13:28:59.989251 21107 solver.cpp:253]     Train net output #0: loss = 1.2716 (* 1 = 1.2716 loss)
I0525 13:28:59.989269 21107 sgd_solver.cpp:106] Iteration 20250, lr = 0.0005
I0525 13:29:08.724434 21107 solver.cpp:237] Iteration 20400, loss = 1.44354
I0525 13:29:08.724475 21107 solver.cpp:253]     Train net output #0: loss = 1.44354 (* 1 = 1.44354 loss)
I0525 13:29:08.724490 21107 sgd_solver.cpp:106] Iteration 20400, lr = 0.0005
I0525 13:29:17.455247 21107 solver.cpp:237] Iteration 20550, loss = 1.42584
I0525 13:29:17.455277 21107 solver.cpp:253]     Train net output #0: loss = 1.42584 (* 1 = 1.42584 loss)
I0525 13:29:17.455291 21107 sgd_solver.cpp:106] Iteration 20550, lr = 0.0005
I0525 13:29:26.192265 21107 solver.cpp:237] Iteration 20700, loss = 1.43704
I0525 13:29:26.192411 21107 solver.cpp:253]     Train net output #0: loss = 1.43704 (* 1 = 1.43704 loss)
I0525 13:29:26.192427 21107 sgd_solver.cpp:106] Iteration 20700, lr = 0.0005
I0525 13:29:34.928362 21107 solver.cpp:237] Iteration 20850, loss = 1.3442
I0525 13:29:34.928401 21107 solver.cpp:253]     Train net output #0: loss = 1.3442 (* 1 = 1.3442 loss)
I0525 13:29:34.928419 21107 sgd_solver.cpp:106] Iteration 20850, lr = 0.0005
I0525 13:29:43.608429 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_21000.caffemodel
I0525 13:29:43.688501 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_21000.solverstate
I0525 13:29:43.715172 21107 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 13:30:30.227746 21107 solver.cpp:409]     Test net output #0: accuracy = 0.779907
I0525 13:30:30.227910 21107 solver.cpp:409]     Test net output #1: loss = 0.783315 (* 1 = 0.783315 loss)
I0525 13:30:51.139348 21107 solver.cpp:237] Iteration 21000, loss = 1.66615
I0525 13:30:51.139397 21107 solver.cpp:253]     Train net output #0: loss = 1.66615 (* 1 = 1.66615 loss)
I0525 13:30:51.139412 21107 sgd_solver.cpp:106] Iteration 21000, lr = 0.0005
I0525 13:30:59.884109 21107 solver.cpp:237] Iteration 21150, loss = 1.33961
I0525 13:30:59.884143 21107 solver.cpp:253]     Train net output #0: loss = 1.33961 (* 1 = 1.33961 loss)
I0525 13:30:59.884160 21107 sgd_solver.cpp:106] Iteration 21150, lr = 0.0005
I0525 13:31:08.619050 21107 solver.cpp:237] Iteration 21300, loss = 1.57573
I0525 13:31:08.619210 21107 solver.cpp:253]     Train net output #0: loss = 1.57573 (* 1 = 1.57573 loss)
I0525 13:31:08.619226 21107 sgd_solver.cpp:106] Iteration 21300, lr = 0.0005
I0525 13:31:17.362522 21107 solver.cpp:237] Iteration 21450, loss = 1.60147
I0525 13:31:17.362565 21107 solver.cpp:253]     Train net output #0: loss = 1.60147 (* 1 = 1.60147 loss)
I0525 13:31:17.362583 21107 sgd_solver.cpp:106] Iteration 21450, lr = 0.0005
I0525 13:31:26.109187 21107 solver.cpp:237] Iteration 21600, loss = 1.33912
I0525 13:31:26.109222 21107 solver.cpp:253]     Train net output #0: loss = 1.33912 (* 1 = 1.33912 loss)
I0525 13:31:26.109238 21107 sgd_solver.cpp:106] Iteration 21600, lr = 0.0005
I0525 13:31:34.844516 21107 solver.cpp:237] Iteration 21750, loss = 1.5578
I0525 13:31:34.844560 21107 solver.cpp:253]     Train net output #0: loss = 1.5578 (* 1 = 1.5578 loss)
I0525 13:31:34.844578 21107 sgd_solver.cpp:106] Iteration 21750, lr = 0.0005
I0525 13:31:43.586290 21107 solver.cpp:237] Iteration 21900, loss = 1.57961
I0525 13:31:43.586450 21107 solver.cpp:253]     Train net output #0: loss = 1.57961 (* 1 = 1.57961 loss)
I0525 13:31:43.586464 21107 sgd_solver.cpp:106] Iteration 21900, lr = 0.0005
I0525 13:32:13.186107 21107 solver.cpp:237] Iteration 22050, loss = 1.56072
I0525 13:32:13.186156 21107 solver.cpp:253]     Train net output #0: loss = 1.56072 (* 1 = 1.56072 loss)
I0525 13:32:13.186172 21107 sgd_solver.cpp:106] Iteration 22050, lr = 0.0005
I0525 13:32:21.930438 21107 solver.cpp:237] Iteration 22200, loss = 1.40098
I0525 13:32:21.930611 21107 solver.cpp:253]     Train net output #0: loss = 1.40098 (* 1 = 1.40098 loss)
I0525 13:32:21.930625 21107 sgd_solver.cpp:106] Iteration 22200, lr = 0.0005
I0525 13:32:30.674458 21107 solver.cpp:237] Iteration 22350, loss = 1.54425
I0525 13:32:30.674500 21107 solver.cpp:253]     Train net output #0: loss = 1.54425 (* 1 = 1.54425 loss)
I0525 13:32:30.674520 21107 sgd_solver.cpp:106] Iteration 22350, lr = 0.0005
I0525 13:32:39.361703 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_22500.caffemodel
I0525 13:32:39.442278 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_22500.solverstate
I0525 13:32:39.487848 21107 solver.cpp:237] Iteration 22500, loss = 1.51903
I0525 13:32:39.487896 21107 solver.cpp:253]     Train net output #0: loss = 1.51903 (* 1 = 1.51903 loss)
I0525 13:32:39.487912 21107 sgd_solver.cpp:106] Iteration 22500, lr = 0.0005
I0525 13:32:48.229849 21107 solver.cpp:237] Iteration 22650, loss = 1.41222
I0525 13:32:48.229884 21107 solver.cpp:253]     Train net output #0: loss = 1.41222 (* 1 = 1.41222 loss)
I0525 13:32:48.229898 21107 sgd_solver.cpp:106] Iteration 22650, lr = 0.0005
I0525 13:32:56.971222 21107 solver.cpp:237] Iteration 22800, loss = 1.48823
I0525 13:32:56.971390 21107 solver.cpp:253]     Train net output #0: loss = 1.48823 (* 1 = 1.48823 loss)
I0525 13:32:56.971405 21107 sgd_solver.cpp:106] Iteration 22800, lr = 0.0005
I0525 13:33:05.716212 21107 solver.cpp:237] Iteration 22950, loss = 1.51425
I0525 13:33:05.716245 21107 solver.cpp:253]     Train net output #0: loss = 1.51425 (* 1 = 1.51425 loss)
I0525 13:33:05.716262 21107 sgd_solver.cpp:106] Iteration 22950, lr = 0.0005
I0525 13:33:35.320786 21107 solver.cpp:237] Iteration 23100, loss = 1.46916
I0525 13:33:35.320960 21107 solver.cpp:253]     Train net output #0: loss = 1.46916 (* 1 = 1.46916 loss)
I0525 13:33:35.320976 21107 sgd_solver.cpp:106] Iteration 23100, lr = 0.0005
I0525 13:33:44.064129 21107 solver.cpp:237] Iteration 23250, loss = 1.41105
I0525 13:33:44.064178 21107 solver.cpp:253]     Train net output #0: loss = 1.41105 (* 1 = 1.41105 loss)
I0525 13:33:44.064191 21107 sgd_solver.cpp:106] Iteration 23250, lr = 0.0005
I0525 13:33:52.806870 21107 solver.cpp:237] Iteration 23400, loss = 1.42809
I0525 13:33:52.806906 21107 solver.cpp:253]     Train net output #0: loss = 1.42809 (* 1 = 1.42809 loss)
I0525 13:33:52.806922 21107 sgd_solver.cpp:106] Iteration 23400, lr = 0.0005
I0525 13:34:01.544318 21107 solver.cpp:237] Iteration 23550, loss = 1.35808
I0525 13:34:01.544353 21107 solver.cpp:253]     Train net output #0: loss = 1.35808 (* 1 = 1.35808 loss)
I0525 13:34:01.544366 21107 sgd_solver.cpp:106] Iteration 23550, lr = 0.0005
I0525 13:34:10.284157 21107 solver.cpp:237] Iteration 23700, loss = 1.61546
I0525 13:34:10.284324 21107 solver.cpp:253]     Train net output #0: loss = 1.61546 (* 1 = 1.61546 loss)
I0525 13:34:10.284342 21107 sgd_solver.cpp:106] Iteration 23700, lr = 0.0005
I0525 13:34:19.019407 21107 solver.cpp:237] Iteration 23850, loss = 1.36693
I0525 13:34:19.019441 21107 solver.cpp:253]     Train net output #0: loss = 1.36693 (* 1 = 1.36693 loss)
I0525 13:34:19.019459 21107 sgd_solver.cpp:106] Iteration 23850, lr = 0.0005
I0525 13:34:27.702652 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_24000.caffemodel
I0525 13:34:27.780625 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_24000.solverstate
I0525 13:34:27.806010 21107 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 13:35:35.452100 21107 solver.cpp:409]     Test net output #0: accuracy = 0.780128
I0525 13:35:35.452270 21107 solver.cpp:409]     Test net output #1: loss = 0.718284 (* 1 = 0.718284 loss)
I0525 13:35:56.323734 21107 solver.cpp:237] Iteration 24000, loss = 1.52935
I0525 13:35:56.323786 21107 solver.cpp:253]     Train net output #0: loss = 1.52935 (* 1 = 1.52935 loss)
I0525 13:35:56.323801 21107 sgd_solver.cpp:106] Iteration 24000, lr = 0.0005
I0525 13:36:05.053848 21107 solver.cpp:237] Iteration 24150, loss = 1.21087
I0525 13:36:05.053882 21107 solver.cpp:253]     Train net output #0: loss = 1.21087 (* 1 = 1.21087 loss)
I0525 13:36:05.053900 21107 sgd_solver.cpp:106] Iteration 24150, lr = 0.0005
I0525 13:36:13.779728 21107 solver.cpp:237] Iteration 24300, loss = 1.32993
I0525 13:36:13.779893 21107 solver.cpp:253]     Train net output #0: loss = 1.32993 (* 1 = 1.32993 loss)
I0525 13:36:13.779907 21107 sgd_solver.cpp:106] Iteration 24300, lr = 0.0005
I0525 13:36:22.508625 21107 solver.cpp:237] Iteration 24450, loss = 1.47197
I0525 13:36:22.508659 21107 solver.cpp:253]     Train net output #0: loss = 1.47197 (* 1 = 1.47197 loss)
I0525 13:36:22.508673 21107 sgd_solver.cpp:106] Iteration 24450, lr = 0.0005
I0525 13:36:31.236402 21107 solver.cpp:237] Iteration 24600, loss = 1.72612
I0525 13:36:31.236436 21107 solver.cpp:253]     Train net output #0: loss = 1.72612 (* 1 = 1.72612 loss)
I0525 13:36:31.236452 21107 sgd_solver.cpp:106] Iteration 24600, lr = 0.0005
I0525 13:36:39.959309 21107 solver.cpp:237] Iteration 24750, loss = 1.50878
I0525 13:36:39.959350 21107 solver.cpp:253]     Train net output #0: loss = 1.50878 (* 1 = 1.50878 loss)
I0525 13:36:39.959368 21107 sgd_solver.cpp:106] Iteration 24750, lr = 0.0005
I0525 13:36:48.687027 21107 solver.cpp:237] Iteration 24900, loss = 1.31408
I0525 13:36:48.687186 21107 solver.cpp:253]     Train net output #0: loss = 1.31408 (* 1 = 1.31408 loss)
I0525 13:36:48.687201 21107 sgd_solver.cpp:106] Iteration 24900, lr = 0.0005
I0525 13:37:18.257514 21107 solver.cpp:237] Iteration 25050, loss = 1.37249
I0525 13:37:18.257565 21107 solver.cpp:253]     Train net output #0: loss = 1.37249 (* 1 = 1.37249 loss)
I0525 13:37:18.257580 21107 sgd_solver.cpp:106] Iteration 25050, lr = 0.0005
I0525 13:37:26.991017 21107 solver.cpp:237] Iteration 25200, loss = 1.43735
I0525 13:37:26.991196 21107 solver.cpp:253]     Train net output #0: loss = 1.43735 (* 1 = 1.43735 loss)
I0525 13:37:26.991210 21107 sgd_solver.cpp:106] Iteration 25200, lr = 0.0005
I0525 13:37:35.722476 21107 solver.cpp:237] Iteration 25350, loss = 1.36698
I0525 13:37:35.722510 21107 solver.cpp:253]     Train net output #0: loss = 1.36698 (* 1 = 1.36698 loss)
I0525 13:37:35.722527 21107 sgd_solver.cpp:106] Iteration 25350, lr = 0.0005
I0525 13:37:44.400490 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_25500.caffemodel
I0525 13:37:44.482745 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_25500.solverstate
I0525 13:37:44.525763 21107 solver.cpp:237] Iteration 25500, loss = 1.52265
I0525 13:37:44.525804 21107 solver.cpp:253]     Train net output #0: loss = 1.52265 (* 1 = 1.52265 loss)
I0525 13:37:44.525821 21107 sgd_solver.cpp:106] Iteration 25500, lr = 0.0005
I0525 13:37:53.261625 21107 solver.cpp:237] Iteration 25650, loss = 1.55005
I0525 13:37:53.261669 21107 solver.cpp:253]     Train net output #0: loss = 1.55005 (* 1 = 1.55005 loss)
I0525 13:37:53.261687 21107 sgd_solver.cpp:106] Iteration 25650, lr = 0.0005
I0525 13:38:01.988850 21107 solver.cpp:237] Iteration 25800, loss = 1.54287
I0525 13:38:01.989015 21107 solver.cpp:253]     Train net output #0: loss = 1.54287 (* 1 = 1.54287 loss)
I0525 13:38:01.989028 21107 sgd_solver.cpp:106] Iteration 25800, lr = 0.0005
I0525 13:38:10.721182 21107 solver.cpp:237] Iteration 25950, loss = 1.51413
I0525 13:38:10.721217 21107 solver.cpp:253]     Train net output #0: loss = 1.51413 (* 1 = 1.51413 loss)
I0525 13:38:10.721233 21107 sgd_solver.cpp:106] Iteration 25950, lr = 0.0005
I0525 13:38:40.296766 21107 solver.cpp:237] Iteration 26100, loss = 1.39117
I0525 13:38:40.296942 21107 solver.cpp:253]     Train net output #0: loss = 1.39117 (* 1 = 1.39117 loss)
I0525 13:38:40.296957 21107 sgd_solver.cpp:106] Iteration 26100, lr = 0.0005
I0525 13:38:49.021736 21107 solver.cpp:237] Iteration 26250, loss = 1.35401
I0525 13:38:49.021770 21107 solver.cpp:253]     Train net output #0: loss = 1.35401 (* 1 = 1.35401 loss)
I0525 13:38:49.021787 21107 sgd_solver.cpp:106] Iteration 26250, lr = 0.0005
I0525 13:38:57.751744 21107 solver.cpp:237] Iteration 26400, loss = 1.44761
I0525 13:38:57.751778 21107 solver.cpp:253]     Train net output #0: loss = 1.44761 (* 1 = 1.44761 loss)
I0525 13:38:57.751796 21107 sgd_solver.cpp:106] Iteration 26400, lr = 0.0005
I0525 13:39:06.480414 21107 solver.cpp:237] Iteration 26550, loss = 1.5091
I0525 13:39:06.480460 21107 solver.cpp:253]     Train net output #0: loss = 1.5091 (* 1 = 1.5091 loss)
I0525 13:39:06.480478 21107 sgd_solver.cpp:106] Iteration 26550, lr = 0.0005
I0525 13:39:15.212954 21107 solver.cpp:237] Iteration 26700, loss = 1.75883
I0525 13:39:15.213106 21107 solver.cpp:253]     Train net output #0: loss = 1.75883 (* 1 = 1.75883 loss)
I0525 13:39:15.213121 21107 sgd_solver.cpp:106] Iteration 26700, lr = 0.0005
I0525 13:39:23.939707 21107 solver.cpp:237] Iteration 26850, loss = 1.37574
I0525 13:39:23.939740 21107 solver.cpp:253]     Train net output #0: loss = 1.37574 (* 1 = 1.37574 loss)
I0525 13:39:23.939757 21107 sgd_solver.cpp:106] Iteration 26850, lr = 0.0005
I0525 13:39:32.614610 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_27000.caffemodel
I0525 13:39:32.692543 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_27000.solverstate
I0525 13:39:32.718246 21107 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 13:40:19.520874 21107 solver.cpp:409]     Test net output #0: accuracy = 0.804347
I0525 13:40:19.521049 21107 solver.cpp:409]     Test net output #1: loss = 0.743151 (* 1 = 0.743151 loss)
I0525 13:40:40.347848 21107 solver.cpp:237] Iteration 27000, loss = 1.4925
I0525 13:40:40.347901 21107 solver.cpp:253]     Train net output #0: loss = 1.4925 (* 1 = 1.4925 loss)
I0525 13:40:40.347916 21107 sgd_solver.cpp:106] Iteration 27000, lr = 0.0005
I0525 13:40:49.090076 21107 solver.cpp:237] Iteration 27150, loss = 1.53604
I0525 13:40:49.090116 21107 solver.cpp:253]     Train net output #0: loss = 1.53604 (* 1 = 1.53604 loss)
I0525 13:40:49.090134 21107 sgd_solver.cpp:106] Iteration 27150, lr = 0.0005
I0525 13:40:57.832176 21107 solver.cpp:237] Iteration 27300, loss = 1.36148
I0525 13:40:57.832334 21107 solver.cpp:253]     Train net output #0: loss = 1.36148 (* 1 = 1.36148 loss)
I0525 13:40:57.832347 21107 sgd_solver.cpp:106] Iteration 27300, lr = 0.0005
I0525 13:41:06.575620 21107 solver.cpp:237] Iteration 27450, loss = 1.46583
I0525 13:41:06.575654 21107 solver.cpp:253]     Train net output #0: loss = 1.46583 (* 1 = 1.46583 loss)
I0525 13:41:06.575670 21107 sgd_solver.cpp:106] Iteration 27450, lr = 0.0005
I0525 13:41:15.319000 21107 solver.cpp:237] Iteration 27600, loss = 1.33473
I0525 13:41:15.319041 21107 solver.cpp:253]     Train net output #0: loss = 1.33473 (* 1 = 1.33473 loss)
I0525 13:41:15.319059 21107 sgd_solver.cpp:106] Iteration 27600, lr = 0.0005
I0525 13:41:24.059597 21107 solver.cpp:237] Iteration 27750, loss = 1.41927
I0525 13:41:24.059631 21107 solver.cpp:253]     Train net output #0: loss = 1.41927 (* 1 = 1.41927 loss)
I0525 13:41:24.059644 21107 sgd_solver.cpp:106] Iteration 27750, lr = 0.0005
I0525 13:41:32.801398 21107 solver.cpp:237] Iteration 27900, loss = 1.15127
I0525 13:41:32.801558 21107 solver.cpp:253]     Train net output #0: loss = 1.15127 (* 1 = 1.15127 loss)
I0525 13:41:32.801573 21107 sgd_solver.cpp:106] Iteration 27900, lr = 0.0005
I0525 13:42:02.438279 21107 solver.cpp:237] Iteration 28050, loss = 1.47813
I0525 13:42:02.438328 21107 solver.cpp:253]     Train net output #0: loss = 1.47813 (* 1 = 1.47813 loss)
I0525 13:42:02.438344 21107 sgd_solver.cpp:106] Iteration 28050, lr = 0.0005
I0525 13:42:11.176003 21107 solver.cpp:237] Iteration 28200, loss = 1.47961
I0525 13:42:11.176170 21107 solver.cpp:253]     Train net output #0: loss = 1.47961 (* 1 = 1.47961 loss)
I0525 13:42:11.176184 21107 sgd_solver.cpp:106] Iteration 28200, lr = 0.0005
I0525 13:42:19.916654 21107 solver.cpp:237] Iteration 28350, loss = 1.18195
I0525 13:42:19.916688 21107 solver.cpp:253]     Train net output #0: loss = 1.18195 (* 1 = 1.18195 loss)
I0525 13:42:19.916705 21107 sgd_solver.cpp:106] Iteration 28350, lr = 0.0005
I0525 13:42:28.600908 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_28500.caffemodel
I0525 13:42:28.683923 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_28500.solverstate
I0525 13:42:28.728835 21107 solver.cpp:237] Iteration 28500, loss = 1.45409
I0525 13:42:28.728884 21107 solver.cpp:253]     Train net output #0: loss = 1.45409 (* 1 = 1.45409 loss)
I0525 13:42:28.728899 21107 sgd_solver.cpp:106] Iteration 28500, lr = 0.0005
I0525 13:42:37.468493 21107 solver.cpp:237] Iteration 28650, loss = 1.40756
I0525 13:42:37.468528 21107 solver.cpp:253]     Train net output #0: loss = 1.40756 (* 1 = 1.40756 loss)
I0525 13:42:37.468541 21107 sgd_solver.cpp:106] Iteration 28650, lr = 0.0005
I0525 13:42:46.213451 21107 solver.cpp:237] Iteration 28800, loss = 1.30656
I0525 13:42:46.213608 21107 solver.cpp:253]     Train net output #0: loss = 1.30656 (* 1 = 1.30656 loss)
I0525 13:42:46.213623 21107 sgd_solver.cpp:106] Iteration 28800, lr = 0.0005
I0525 13:42:54.957419 21107 solver.cpp:237] Iteration 28950, loss = 1.50669
I0525 13:42:54.957460 21107 solver.cpp:253]     Train net output #0: loss = 1.50669 (* 1 = 1.50669 loss)
I0525 13:42:54.957481 21107 sgd_solver.cpp:106] Iteration 28950, lr = 0.0005
I0525 13:43:24.580725 21107 solver.cpp:237] Iteration 29100, loss = 1.19299
I0525 13:43:24.580900 21107 solver.cpp:253]     Train net output #0: loss = 1.19299 (* 1 = 1.19299 loss)
I0525 13:43:24.580916 21107 sgd_solver.cpp:106] Iteration 29100, lr = 0.0005
I0525 13:43:33.323598 21107 solver.cpp:237] Iteration 29250, loss = 1.44749
I0525 13:43:33.323628 21107 solver.cpp:253]     Train net output #0: loss = 1.44749 (* 1 = 1.44749 loss)
I0525 13:43:33.323650 21107 sgd_solver.cpp:106] Iteration 29250, lr = 0.0005
I0525 13:43:42.067159 21107 solver.cpp:237] Iteration 29400, loss = 1.52638
I0525 13:43:42.067203 21107 solver.cpp:253]     Train net output #0: loss = 1.52638 (* 1 = 1.52638 loss)
I0525 13:43:42.067220 21107 sgd_solver.cpp:106] Iteration 29400, lr = 0.0005
I0525 13:43:50.807008 21107 solver.cpp:237] Iteration 29550, loss = 1.73164
I0525 13:43:50.807042 21107 solver.cpp:253]     Train net output #0: loss = 1.73164 (* 1 = 1.73164 loss)
I0525 13:43:50.807059 21107 sgd_solver.cpp:106] Iteration 29550, lr = 0.0005
I0525 13:43:59.549907 21107 solver.cpp:237] Iteration 29700, loss = 1.49302
I0525 13:43:59.550071 21107 solver.cpp:253]     Train net output #0: loss = 1.49302 (* 1 = 1.49302 loss)
I0525 13:43:59.550084 21107 sgd_solver.cpp:106] Iteration 29700, lr = 0.0005
I0525 13:44:08.289114 21107 solver.cpp:237] Iteration 29850, loss = 1.387
I0525 13:44:08.289160 21107 solver.cpp:253]     Train net output #0: loss = 1.387 (* 1 = 1.387 loss)
I0525 13:44:08.289175 21107 sgd_solver.cpp:106] Iteration 29850, lr = 0.0005
I0525 13:44:16.978600 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_30000.caffemodel
I0525 13:44:17.059309 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_30000.solverstate
I0525 13:44:17.086688 21107 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 13:45:24.887677 21107 solver.cpp:409]     Test net output #0: accuracy = 0.80822
I0525 13:45:24.887850 21107 solver.cpp:409]     Test net output #1: loss = 0.674457 (* 1 = 0.674457 loss)
I0525 13:45:45.804185 21107 solver.cpp:237] Iteration 30000, loss = 1.36241
I0525 13:45:45.804237 21107 solver.cpp:253]     Train net output #0: loss = 1.36241 (* 1 = 1.36241 loss)
I0525 13:45:45.804253 21107 sgd_solver.cpp:106] Iteration 30000, lr = 0.0005
I0525 13:45:54.544190 21107 solver.cpp:237] Iteration 30150, loss = 1.31387
I0525 13:45:54.544226 21107 solver.cpp:253]     Train net output #0: loss = 1.31387 (* 1 = 1.31387 loss)
I0525 13:45:54.544239 21107 sgd_solver.cpp:106] Iteration 30150, lr = 0.0005
I0525 13:46:03.281179 21107 solver.cpp:237] Iteration 30300, loss = 1.62815
I0525 13:46:03.281338 21107 solver.cpp:253]     Train net output #0: loss = 1.62815 (* 1 = 1.62815 loss)
I0525 13:46:03.281353 21107 sgd_solver.cpp:106] Iteration 30300, lr = 0.0005
I0525 13:46:12.015045 21107 solver.cpp:237] Iteration 30450, loss = 1.38404
I0525 13:46:12.015081 21107 solver.cpp:253]     Train net output #0: loss = 1.38404 (* 1 = 1.38404 loss)
I0525 13:46:12.015099 21107 sgd_solver.cpp:106] Iteration 30450, lr = 0.0005
I0525 13:46:20.750988 21107 solver.cpp:237] Iteration 30600, loss = 1.40322
I0525 13:46:20.751022 21107 solver.cpp:253]     Train net output #0: loss = 1.40322 (* 1 = 1.40322 loss)
I0525 13:46:20.751037 21107 sgd_solver.cpp:106] Iteration 30600, lr = 0.0005
I0525 13:46:29.488123 21107 solver.cpp:237] Iteration 30750, loss = 1.41762
I0525 13:46:29.488158 21107 solver.cpp:253]     Train net output #0: loss = 1.41762 (* 1 = 1.41762 loss)
I0525 13:46:29.488170 21107 sgd_solver.cpp:106] Iteration 30750, lr = 0.0005
I0525 13:46:38.224752 21107 solver.cpp:237] Iteration 30900, loss = 1.40678
I0525 13:46:38.224916 21107 solver.cpp:253]     Train net output #0: loss = 1.40678 (* 1 = 1.40678 loss)
I0525 13:46:38.224931 21107 sgd_solver.cpp:106] Iteration 30900, lr = 0.0005
I0525 13:47:07.873728 21107 solver.cpp:237] Iteration 31050, loss = 1.25949
I0525 13:47:07.873777 21107 solver.cpp:253]     Train net output #0: loss = 1.25949 (* 1 = 1.25949 loss)
I0525 13:47:07.873791 21107 sgd_solver.cpp:106] Iteration 31050, lr = 0.0005
I0525 13:47:16.609386 21107 solver.cpp:237] Iteration 31200, loss = 1.37409
I0525 13:47:16.609545 21107 solver.cpp:253]     Train net output #0: loss = 1.37409 (* 1 = 1.37409 loss)
I0525 13:47:16.609558 21107 sgd_solver.cpp:106] Iteration 31200, lr = 0.0005
I0525 13:47:25.346624 21107 solver.cpp:237] Iteration 31350, loss = 1.48486
I0525 13:47:25.346668 21107 solver.cpp:253]     Train net output #0: loss = 1.48486 (* 1 = 1.48486 loss)
I0525 13:47:25.346688 21107 sgd_solver.cpp:106] Iteration 31350, lr = 0.0005
I0525 13:47:34.026028 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_31500.caffemodel
I0525 13:47:34.104902 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_31500.solverstate
I0525 13:47:34.148236 21107 solver.cpp:237] Iteration 31500, loss = 1.1246
I0525 13:47:34.148283 21107 solver.cpp:253]     Train net output #0: loss = 1.1246 (* 1 = 1.1246 loss)
I0525 13:47:34.148296 21107 sgd_solver.cpp:106] Iteration 31500, lr = 0.0005
I0525 13:47:42.879046 21107 solver.cpp:237] Iteration 31650, loss = 1.3855
I0525 13:47:42.879082 21107 solver.cpp:253]     Train net output #0: loss = 1.3855 (* 1 = 1.3855 loss)
I0525 13:47:42.879097 21107 sgd_solver.cpp:106] Iteration 31650, lr = 0.0005
I0525 13:47:51.607072 21107 solver.cpp:237] Iteration 31800, loss = 1.17436
I0525 13:47:51.607259 21107 solver.cpp:253]     Train net output #0: loss = 1.17436 (* 1 = 1.17436 loss)
I0525 13:47:51.607272 21107 sgd_solver.cpp:106] Iteration 31800, lr = 0.0005
I0525 13:48:00.347728 21107 solver.cpp:237] Iteration 31950, loss = 1.25073
I0525 13:48:00.347762 21107 solver.cpp:253]     Train net output #0: loss = 1.25073 (* 1 = 1.25073 loss)
I0525 13:48:00.347780 21107 sgd_solver.cpp:106] Iteration 31950, lr = 0.0005
I0525 13:48:29.962772 21107 solver.cpp:237] Iteration 32100, loss = 1.22562
I0525 13:48:29.962960 21107 solver.cpp:253]     Train net output #0: loss = 1.22562 (* 1 = 1.22562 loss)
I0525 13:48:29.962976 21107 sgd_solver.cpp:106] Iteration 32100, lr = 0.0005
I0525 13:48:38.696975 21107 solver.cpp:237] Iteration 32250, loss = 1.179
I0525 13:48:38.697010 21107 solver.cpp:253]     Train net output #0: loss = 1.179 (* 1 = 1.179 loss)
I0525 13:48:38.697026 21107 sgd_solver.cpp:106] Iteration 32250, lr = 0.0005
I0525 13:48:47.434428 21107 solver.cpp:237] Iteration 32400, loss = 1.48309
I0525 13:48:47.434473 21107 solver.cpp:253]     Train net output #0: loss = 1.48309 (* 1 = 1.48309 loss)
I0525 13:48:47.434487 21107 sgd_solver.cpp:106] Iteration 32400, lr = 0.0005
I0525 13:48:56.171605 21107 solver.cpp:237] Iteration 32550, loss = 1.27939
I0525 13:48:56.171641 21107 solver.cpp:253]     Train net output #0: loss = 1.27939 (* 1 = 1.27939 loss)
I0525 13:48:56.171655 21107 sgd_solver.cpp:106] Iteration 32550, lr = 0.0005
I0525 13:49:04.911247 21107 solver.cpp:237] Iteration 32700, loss = 1.22129
I0525 13:49:04.911412 21107 solver.cpp:253]     Train net output #0: loss = 1.22129 (* 1 = 1.22129 loss)
I0525 13:49:04.911427 21107 sgd_solver.cpp:106] Iteration 32700, lr = 0.0005
I0525 13:49:13.647480 21107 solver.cpp:237] Iteration 32850, loss = 1.3807
I0525 13:49:13.647512 21107 solver.cpp:253]     Train net output #0: loss = 1.3807 (* 1 = 1.3807 loss)
I0525 13:49:13.647531 21107 sgd_solver.cpp:106] Iteration 32850, lr = 0.0005
I0525 13:49:22.324403 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_33000.caffemodel
I0525 13:49:22.402760 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_33000.solverstate
I0525 13:49:22.428611 21107 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 13:50:08.953915 21107 solver.cpp:409]     Test net output #0: accuracy = 0.818387
I0525 13:50:08.954100 21107 solver.cpp:409]     Test net output #1: loss = 0.665164 (* 1 = 0.665164 loss)
I0525 13:50:29.833748 21107 solver.cpp:237] Iteration 33000, loss = 1.34909
I0525 13:50:29.833802 21107 solver.cpp:253]     Train net output #0: loss = 1.34909 (* 1 = 1.34909 loss)
I0525 13:50:29.833817 21107 sgd_solver.cpp:106] Iteration 33000, lr = 0.0005
I0525 13:50:38.571494 21107 solver.cpp:237] Iteration 33150, loss = 1.37194
I0525 13:50:38.571529 21107 solver.cpp:253]     Train net output #0: loss = 1.37194 (* 1 = 1.37194 loss)
I0525 13:50:38.571545 21107 sgd_solver.cpp:106] Iteration 33150, lr = 0.0005
I0525 13:50:47.308748 21107 solver.cpp:237] Iteration 33300, loss = 1.52869
I0525 13:50:47.308923 21107 solver.cpp:253]     Train net output #0: loss = 1.52869 (* 1 = 1.52869 loss)
I0525 13:50:47.308936 21107 sgd_solver.cpp:106] Iteration 33300, lr = 0.0005
I0525 13:50:56.049451 21107 solver.cpp:237] Iteration 33450, loss = 1.46939
I0525 13:50:56.049485 21107 solver.cpp:253]     Train net output #0: loss = 1.46939 (* 1 = 1.46939 loss)
I0525 13:50:56.049502 21107 sgd_solver.cpp:106] Iteration 33450, lr = 0.0005
I0525 13:51:04.790865 21107 solver.cpp:237] Iteration 33600, loss = 1.3426
I0525 13:51:04.790899 21107 solver.cpp:253]     Train net output #0: loss = 1.3426 (* 1 = 1.3426 loss)
I0525 13:51:04.790915 21107 sgd_solver.cpp:106] Iteration 33600, lr = 0.0005
I0525 13:51:13.531723 21107 solver.cpp:237] Iteration 33750, loss = 1.4294
I0525 13:51:13.531764 21107 solver.cpp:253]     Train net output #0: loss = 1.4294 (* 1 = 1.4294 loss)
I0525 13:51:13.531781 21107 sgd_solver.cpp:106] Iteration 33750, lr = 0.0005
I0525 13:51:22.264876 21107 solver.cpp:237] Iteration 33900, loss = 1.17465
I0525 13:51:22.265034 21107 solver.cpp:253]     Train net output #0: loss = 1.17465 (* 1 = 1.17465 loss)
I0525 13:51:22.265048 21107 sgd_solver.cpp:106] Iteration 33900, lr = 0.0005
I0525 13:51:51.877897 21107 solver.cpp:237] Iteration 34050, loss = 1.46212
I0525 13:51:51.877944 21107 solver.cpp:253]     Train net output #0: loss = 1.46212 (* 1 = 1.46212 loss)
I0525 13:51:51.877964 21107 sgd_solver.cpp:106] Iteration 34050, lr = 0.0005
I0525 13:52:00.616912 21107 solver.cpp:237] Iteration 34200, loss = 1.37069
I0525 13:52:00.617079 21107 solver.cpp:253]     Train net output #0: loss = 1.37069 (* 1 = 1.37069 loss)
I0525 13:52:00.617092 21107 sgd_solver.cpp:106] Iteration 34200, lr = 0.0005
I0525 13:52:09.355082 21107 solver.cpp:237] Iteration 34350, loss = 1.44412
I0525 13:52:09.355126 21107 solver.cpp:253]     Train net output #0: loss = 1.44412 (* 1 = 1.44412 loss)
I0525 13:52:09.355141 21107 sgd_solver.cpp:106] Iteration 34350, lr = 0.0005
I0525 13:52:18.036193 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_34500.caffemodel
I0525 13:52:18.113912 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_34500.solverstate
I0525 13:52:18.156975 21107 solver.cpp:237] Iteration 34500, loss = 1.28524
I0525 13:52:18.157019 21107 solver.cpp:253]     Train net output #0: loss = 1.28524 (* 1 = 1.28524 loss)
I0525 13:52:18.157033 21107 sgd_solver.cpp:106] Iteration 34500, lr = 0.0005
I0525 13:52:26.901720 21107 solver.cpp:237] Iteration 34650, loss = 1.33788
I0525 13:52:26.901759 21107 solver.cpp:253]     Train net output #0: loss = 1.33788 (* 1 = 1.33788 loss)
I0525 13:52:26.901775 21107 sgd_solver.cpp:106] Iteration 34650, lr = 0.0005
I0525 13:52:35.646035 21107 solver.cpp:237] Iteration 34800, loss = 1.49114
I0525 13:52:35.646205 21107 solver.cpp:253]     Train net output #0: loss = 1.49114 (* 1 = 1.49114 loss)
I0525 13:52:35.646219 21107 sgd_solver.cpp:106] Iteration 34800, lr = 0.0005
I0525 13:52:44.385357 21107 solver.cpp:237] Iteration 34950, loss = 1.46921
I0525 13:52:44.385391 21107 solver.cpp:253]     Train net output #0: loss = 1.46921 (* 1 = 1.46921 loss)
I0525 13:52:44.385408 21107 sgd_solver.cpp:106] Iteration 34950, lr = 0.0005
I0525 13:53:13.973677 21107 solver.cpp:237] Iteration 35100, loss = 1.51583
I0525 13:53:13.973855 21107 solver.cpp:253]     Train net output #0: loss = 1.51583 (* 1 = 1.51583 loss)
I0525 13:53:13.973870 21107 sgd_solver.cpp:106] Iteration 35100, lr = 0.0005
I0525 13:53:22.714319 21107 solver.cpp:237] Iteration 35250, loss = 1.16627
I0525 13:53:22.714360 21107 solver.cpp:253]     Train net output #0: loss = 1.16627 (* 1 = 1.16627 loss)
I0525 13:53:22.714380 21107 sgd_solver.cpp:106] Iteration 35250, lr = 0.0005
I0525 13:53:31.453943 21107 solver.cpp:237] Iteration 35400, loss = 1.36978
I0525 13:53:31.453975 21107 solver.cpp:253]     Train net output #0: loss = 1.36978 (* 1 = 1.36978 loss)
I0525 13:53:31.453992 21107 sgd_solver.cpp:106] Iteration 35400, lr = 0.0005
I0525 13:53:40.200598 21107 solver.cpp:237] Iteration 35550, loss = 1.42785
I0525 13:53:40.200636 21107 solver.cpp:253]     Train net output #0: loss = 1.42785 (* 1 = 1.42785 loss)
I0525 13:53:40.200654 21107 sgd_solver.cpp:106] Iteration 35550, lr = 0.0005
I0525 13:53:48.941326 21107 solver.cpp:237] Iteration 35700, loss = 1.33933
I0525 13:53:48.941503 21107 solver.cpp:253]     Train net output #0: loss = 1.33933 (* 1 = 1.33933 loss)
I0525 13:53:48.941516 21107 sgd_solver.cpp:106] Iteration 35700, lr = 0.0005
I0525 13:53:57.686485 21107 solver.cpp:237] Iteration 35850, loss = 1.23983
I0525 13:53:57.686517 21107 solver.cpp:253]     Train net output #0: loss = 1.23983 (* 1 = 1.23983 loss)
I0525 13:53:57.686535 21107 sgd_solver.cpp:106] Iteration 35850, lr = 0.0005
I0525 13:54:06.368716 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_36000.caffemodel
I0525 13:54:06.450273 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_36000.solverstate
I0525 13:54:06.477082 21107 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 13:55:14.198566 21107 solver.cpp:409]     Test net output #0: accuracy = 0.818101
I0525 13:55:14.198747 21107 solver.cpp:409]     Test net output #1: loss = 0.606562 (* 1 = 0.606562 loss)
I0525 13:55:35.101528 21107 solver.cpp:237] Iteration 36000, loss = 1.49951
I0525 13:55:35.101582 21107 solver.cpp:253]     Train net output #0: loss = 1.49951 (* 1 = 1.49951 loss)
I0525 13:55:35.101596 21107 sgd_solver.cpp:106] Iteration 36000, lr = 0.0005
I0525 13:55:43.827489 21107 solver.cpp:237] Iteration 36150, loss = 1.42083
I0525 13:55:43.827524 21107 solver.cpp:253]     Train net output #0: loss = 1.42083 (* 1 = 1.42083 loss)
I0525 13:55:43.827543 21107 sgd_solver.cpp:106] Iteration 36150, lr = 0.0005
I0525 13:55:52.562059 21107 solver.cpp:237] Iteration 36300, loss = 1.36188
I0525 13:55:52.562228 21107 solver.cpp:253]     Train net output #0: loss = 1.36188 (* 1 = 1.36188 loss)
I0525 13:55:52.562242 21107 sgd_solver.cpp:106] Iteration 36300, lr = 0.0005
I0525 13:56:01.293445 21107 solver.cpp:237] Iteration 36450, loss = 1.56646
I0525 13:56:01.293480 21107 solver.cpp:253]     Train net output #0: loss = 1.56646 (* 1 = 1.56646 loss)
I0525 13:56:01.293498 21107 sgd_solver.cpp:106] Iteration 36450, lr = 0.0005
I0525 13:56:10.027710 21107 solver.cpp:237] Iteration 36600, loss = 1.44291
I0525 13:56:10.027755 21107 solver.cpp:253]     Train net output #0: loss = 1.44291 (* 1 = 1.44291 loss)
I0525 13:56:10.027772 21107 sgd_solver.cpp:106] Iteration 36600, lr = 0.0005
I0525 13:56:18.760869 21107 solver.cpp:237] Iteration 36750, loss = 1.52899
I0525 13:56:18.760903 21107 solver.cpp:253]     Train net output #0: loss = 1.52899 (* 1 = 1.52899 loss)
I0525 13:56:18.760920 21107 sgd_solver.cpp:106] Iteration 36750, lr = 0.0005
I0525 13:56:27.492282 21107 solver.cpp:237] Iteration 36900, loss = 1.43881
I0525 13:56:27.492439 21107 solver.cpp:253]     Train net output #0: loss = 1.43881 (* 1 = 1.43881 loss)
I0525 13:56:27.492455 21107 sgd_solver.cpp:106] Iteration 36900, lr = 0.0005
I0525 13:56:57.097487 21107 solver.cpp:237] Iteration 37050, loss = 1.18816
I0525 13:56:57.097537 21107 solver.cpp:253]     Train net output #0: loss = 1.18816 (* 1 = 1.18816 loss)
I0525 13:56:57.097553 21107 sgd_solver.cpp:106] Iteration 37050, lr = 0.0005
I0525 13:57:05.826819 21107 solver.cpp:237] Iteration 37200, loss = 1.21822
I0525 13:57:05.827003 21107 solver.cpp:253]     Train net output #0: loss = 1.21822 (* 1 = 1.21822 loss)
I0525 13:57:05.827018 21107 sgd_solver.cpp:106] Iteration 37200, lr = 0.0005
I0525 13:57:14.556398 21107 solver.cpp:237] Iteration 37350, loss = 1.50684
I0525 13:57:14.556432 21107 solver.cpp:253]     Train net output #0: loss = 1.50684 (* 1 = 1.50684 loss)
I0525 13:57:14.556449 21107 sgd_solver.cpp:106] Iteration 37350, lr = 0.0005
I0525 13:57:23.225312 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_37500.caffemodel
I0525 13:57:23.305755 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_37500.solverstate
I0525 13:57:23.350821 21107 solver.cpp:237] Iteration 37500, loss = 1.38058
I0525 13:57:23.350870 21107 solver.cpp:253]     Train net output #0: loss = 1.38058 (* 1 = 1.38058 loss)
I0525 13:57:23.350884 21107 sgd_solver.cpp:106] Iteration 37500, lr = 0.0005
I0525 13:57:32.086711 21107 solver.cpp:237] Iteration 37650, loss = 1.29133
I0525 13:57:32.086755 21107 solver.cpp:253]     Train net output #0: loss = 1.29133 (* 1 = 1.29133 loss)
I0525 13:57:32.086772 21107 sgd_solver.cpp:106] Iteration 37650, lr = 0.0005
I0525 13:57:40.819908 21107 solver.cpp:237] Iteration 37800, loss = 1.26016
I0525 13:57:40.820072 21107 solver.cpp:253]     Train net output #0: loss = 1.26016 (* 1 = 1.26016 loss)
I0525 13:57:40.820086 21107 sgd_solver.cpp:106] Iteration 37800, lr = 0.0005
I0525 13:57:49.549628 21107 solver.cpp:237] Iteration 37950, loss = 1.49706
I0525 13:57:49.549669 21107 solver.cpp:253]     Train net output #0: loss = 1.49706 (* 1 = 1.49706 loss)
I0525 13:57:49.549690 21107 sgd_solver.cpp:106] Iteration 37950, lr = 0.0005
I0525 13:58:19.137812 21107 solver.cpp:237] Iteration 38100, loss = 1.39678
I0525 13:58:19.137987 21107 solver.cpp:253]     Train net output #0: loss = 1.39678 (* 1 = 1.39678 loss)
I0525 13:58:19.138001 21107 sgd_solver.cpp:106] Iteration 38100, lr = 0.0005
I0525 13:58:27.868521 21107 solver.cpp:237] Iteration 38250, loss = 1.44152
I0525 13:58:27.868556 21107 solver.cpp:253]     Train net output #0: loss = 1.44152 (* 1 = 1.44152 loss)
I0525 13:58:27.868573 21107 sgd_solver.cpp:106] Iteration 38250, lr = 0.0005
I0525 13:58:36.599879 21107 solver.cpp:237] Iteration 38400, loss = 1.32165
I0525 13:58:36.599915 21107 solver.cpp:253]     Train net output #0: loss = 1.32165 (* 1 = 1.32165 loss)
I0525 13:58:36.599928 21107 sgd_solver.cpp:106] Iteration 38400, lr = 0.0005
I0525 13:58:45.330709 21107 solver.cpp:237] Iteration 38550, loss = 1.60742
I0525 13:58:45.330752 21107 solver.cpp:253]     Train net output #0: loss = 1.60742 (* 1 = 1.60742 loss)
I0525 13:58:45.330770 21107 sgd_solver.cpp:106] Iteration 38550, lr = 0.0005
I0525 13:58:54.057700 21107 solver.cpp:237] Iteration 38700, loss = 1.41345
I0525 13:58:54.057858 21107 solver.cpp:253]     Train net output #0: loss = 1.41345 (* 1 = 1.41345 loss)
I0525 13:58:54.057873 21107 sgd_solver.cpp:106] Iteration 38700, lr = 0.0005
I0525 13:59:02.793365 21107 solver.cpp:237] Iteration 38850, loss = 1.10476
I0525 13:59:02.793398 21107 solver.cpp:253]     Train net output #0: loss = 1.10476 (* 1 = 1.10476 loss)
I0525 13:59:02.793416 21107 sgd_solver.cpp:106] Iteration 38850, lr = 0.0005
I0525 13:59:11.468101 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_39000.caffemodel
I0525 13:59:11.547058 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_39000.solverstate
I0525 13:59:11.572288 21107 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 13:59:58.436851 21107 solver.cpp:409]     Test net output #0: accuracy = 0.826033
I0525 13:59:58.437047 21107 solver.cpp:409]     Test net output #1: loss = 0.597632 (* 1 = 0.597632 loss)
I0525 14:00:19.341115 21107 solver.cpp:237] Iteration 39000, loss = 1.38696
I0525 14:00:19.341164 21107 solver.cpp:253]     Train net output #0: loss = 1.38696 (* 1 = 1.38696 loss)
I0525 14:00:19.341179 21107 sgd_solver.cpp:106] Iteration 39000, lr = 0.0005
I0525 14:00:28.086200 21107 solver.cpp:237] Iteration 39150, loss = 1.24471
I0525 14:00:28.086235 21107 solver.cpp:253]     Train net output #0: loss = 1.24471 (* 1 = 1.24471 loss)
I0525 14:00:28.086251 21107 sgd_solver.cpp:106] Iteration 39150, lr = 0.0005
I0525 14:00:36.832705 21107 solver.cpp:237] Iteration 39300, loss = 1.35392
I0525 14:00:36.832871 21107 solver.cpp:253]     Train net output #0: loss = 1.35392 (* 1 = 1.35392 loss)
I0525 14:00:36.832887 21107 sgd_solver.cpp:106] Iteration 39300, lr = 0.0005
I0525 14:00:45.573647 21107 solver.cpp:237] Iteration 39450, loss = 1.31633
I0525 14:00:45.573686 21107 solver.cpp:253]     Train net output #0: loss = 1.31633 (* 1 = 1.31633 loss)
I0525 14:00:45.573706 21107 sgd_solver.cpp:106] Iteration 39450, lr = 0.0005
I0525 14:00:54.316645 21107 solver.cpp:237] Iteration 39600, loss = 1.39996
I0525 14:00:54.316680 21107 solver.cpp:253]     Train net output #0: loss = 1.39996 (* 1 = 1.39996 loss)
I0525 14:00:54.316696 21107 sgd_solver.cpp:106] Iteration 39600, lr = 0.0005
I0525 14:01:03.062228 21107 solver.cpp:237] Iteration 39750, loss = 1.31019
I0525 14:01:03.062263 21107 solver.cpp:253]     Train net output #0: loss = 1.31019 (* 1 = 1.31019 loss)
I0525 14:01:03.062278 21107 sgd_solver.cpp:106] Iteration 39750, lr = 0.0005
I0525 14:01:11.805064 21107 solver.cpp:237] Iteration 39900, loss = 1.54149
I0525 14:01:11.805229 21107 solver.cpp:253]     Train net output #0: loss = 1.54149 (* 1 = 1.54149 loss)
I0525 14:01:11.805243 21107 sgd_solver.cpp:106] Iteration 39900, lr = 0.0005
I0525 14:01:41.397469 21107 solver.cpp:237] Iteration 40050, loss = 1.35617
I0525 14:01:41.397517 21107 solver.cpp:253]     Train net output #0: loss = 1.35617 (* 1 = 1.35617 loss)
I0525 14:01:41.397534 21107 sgd_solver.cpp:106] Iteration 40050, lr = 0.0005
I0525 14:01:50.139322 21107 solver.cpp:237] Iteration 40200, loss = 1.47384
I0525 14:01:50.139498 21107 solver.cpp:253]     Train net output #0: loss = 1.47384 (* 1 = 1.47384 loss)
I0525 14:01:50.139513 21107 sgd_solver.cpp:106] Iteration 40200, lr = 0.0005
I0525 14:01:58.885921 21107 solver.cpp:237] Iteration 40350, loss = 1.19761
I0525 14:01:58.885956 21107 solver.cpp:253]     Train net output #0: loss = 1.19761 (* 1 = 1.19761 loss)
I0525 14:01:58.885972 21107 sgd_solver.cpp:106] Iteration 40350, lr = 0.0005
I0525 14:02:07.570116 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_40500.caffemodel
I0525 14:02:07.648892 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_40500.solverstate
I0525 14:02:07.692178 21107 solver.cpp:237] Iteration 40500, loss = 1.36362
I0525 14:02:07.692225 21107 solver.cpp:253]     Train net output #0: loss = 1.36362 (* 1 = 1.36362 loss)
I0525 14:02:07.692239 21107 sgd_solver.cpp:106] Iteration 40500, lr = 0.0005
I0525 14:02:16.435139 21107 solver.cpp:237] Iteration 40650, loss = 1.26457
I0525 14:02:16.435175 21107 solver.cpp:253]     Train net output #0: loss = 1.26457 (* 1 = 1.26457 loss)
I0525 14:02:16.435190 21107 sgd_solver.cpp:106] Iteration 40650, lr = 0.0005
I0525 14:02:25.176050 21107 solver.cpp:237] Iteration 40800, loss = 1.48322
I0525 14:02:25.176226 21107 solver.cpp:253]     Train net output #0: loss = 1.48322 (* 1 = 1.48322 loss)
I0525 14:02:25.176240 21107 sgd_solver.cpp:106] Iteration 40800, lr = 0.0005
I0525 14:02:33.914556 21107 solver.cpp:237] Iteration 40950, loss = 1.4352
I0525 14:02:33.914589 21107 solver.cpp:253]     Train net output #0: loss = 1.4352 (* 1 = 1.4352 loss)
I0525 14:02:33.914607 21107 sgd_solver.cpp:106] Iteration 40950, lr = 0.0005
I0525 14:03:03.505935 21107 solver.cpp:237] Iteration 41100, loss = 1.20718
I0525 14:03:03.506125 21107 solver.cpp:253]     Train net output #0: loss = 1.20718 (* 1 = 1.20718 loss)
I0525 14:03:03.506141 21107 sgd_solver.cpp:106] Iteration 41100, lr = 0.0005
I0525 14:03:12.250334 21107 solver.cpp:237] Iteration 41250, loss = 1.38988
I0525 14:03:12.250370 21107 solver.cpp:253]     Train net output #0: loss = 1.38988 (* 1 = 1.38988 loss)
I0525 14:03:12.250386 21107 sgd_solver.cpp:106] Iteration 41250, lr = 0.0005
I0525 14:03:20.992259 21107 solver.cpp:237] Iteration 41400, loss = 1.39798
I0525 14:03:20.992307 21107 solver.cpp:253]     Train net output #0: loss = 1.39798 (* 1 = 1.39798 loss)
I0525 14:03:20.992321 21107 sgd_solver.cpp:106] Iteration 41400, lr = 0.0005
I0525 14:03:29.733862 21107 solver.cpp:237] Iteration 41550, loss = 1.33521
I0525 14:03:29.733897 21107 solver.cpp:253]     Train net output #0: loss = 1.33521 (* 1 = 1.33521 loss)
I0525 14:03:29.733913 21107 sgd_solver.cpp:106] Iteration 41550, lr = 0.0005
I0525 14:03:38.476399 21107 solver.cpp:237] Iteration 41700, loss = 1.33911
I0525 14:03:38.476565 21107 solver.cpp:253]     Train net output #0: loss = 1.33911 (* 1 = 1.33911 loss)
I0525 14:03:38.476582 21107 sgd_solver.cpp:106] Iteration 41700, lr = 0.0005
I0525 14:03:47.218996 21107 solver.cpp:237] Iteration 41850, loss = 1.40968
I0525 14:03:47.219040 21107 solver.cpp:253]     Train net output #0: loss = 1.40968 (* 1 = 1.40968 loss)
I0525 14:03:47.219055 21107 sgd_solver.cpp:106] Iteration 41850, lr = 0.0005
I0525 14:03:55.906594 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_42000.caffemodel
I0525 14:03:55.984941 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_42000.solverstate
I0525 14:03:56.009887 21107 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 14:05:03.741176 21107 solver.cpp:409]     Test net output #0: accuracy = 0.830693
I0525 14:05:03.741360 21107 solver.cpp:409]     Test net output #1: loss = 0.599699 (* 1 = 0.599699 loss)
I0525 14:05:24.610043 21107 solver.cpp:237] Iteration 42000, loss = 1.3677
I0525 14:05:24.610095 21107 solver.cpp:253]     Train net output #0: loss = 1.3677 (* 1 = 1.3677 loss)
I0525 14:05:24.610110 21107 sgd_solver.cpp:106] Iteration 42000, lr = 0.0005
I0525 14:05:33.349200 21107 solver.cpp:237] Iteration 42150, loss = 1.21235
I0525 14:05:33.349234 21107 solver.cpp:253]     Train net output #0: loss = 1.21235 (* 1 = 1.21235 loss)
I0525 14:05:33.349252 21107 sgd_solver.cpp:106] Iteration 42150, lr = 0.0005
I0525 14:05:42.075731 21107 solver.cpp:237] Iteration 42300, loss = 1.30059
I0525 14:05:42.075898 21107 solver.cpp:253]     Train net output #0: loss = 1.30059 (* 1 = 1.30059 loss)
I0525 14:05:42.075912 21107 sgd_solver.cpp:106] Iteration 42300, lr = 0.0005
I0525 14:05:50.807678 21107 solver.cpp:237] Iteration 42450, loss = 1.27294
I0525 14:05:50.807718 21107 solver.cpp:253]     Train net output #0: loss = 1.27294 (* 1 = 1.27294 loss)
I0525 14:05:50.807736 21107 sgd_solver.cpp:106] Iteration 42450, lr = 0.0005
I0525 14:05:59.541743 21107 solver.cpp:237] Iteration 42600, loss = 1.3464
I0525 14:05:59.541777 21107 solver.cpp:253]     Train net output #0: loss = 1.3464 (* 1 = 1.3464 loss)
I0525 14:05:59.541790 21107 sgd_solver.cpp:106] Iteration 42600, lr = 0.0005
I0525 14:06:08.276160 21107 solver.cpp:237] Iteration 42750, loss = 1.43811
I0525 14:06:08.276196 21107 solver.cpp:253]     Train net output #0: loss = 1.43811 (* 1 = 1.43811 loss)
I0525 14:06:08.276212 21107 sgd_solver.cpp:106] Iteration 42750, lr = 0.0005
I0525 14:06:17.012881 21107 solver.cpp:237] Iteration 42900, loss = 1.11205
I0525 14:06:17.013056 21107 solver.cpp:253]     Train net output #0: loss = 1.11205 (* 1 = 1.11205 loss)
I0525 14:06:17.013069 21107 sgd_solver.cpp:106] Iteration 42900, lr = 0.0005
I0525 14:06:46.623390 21107 solver.cpp:237] Iteration 43050, loss = 1.38962
I0525 14:06:46.623438 21107 solver.cpp:253]     Train net output #0: loss = 1.38962 (* 1 = 1.38962 loss)
I0525 14:06:46.623456 21107 sgd_solver.cpp:106] Iteration 43050, lr = 0.0005
I0525 14:06:55.360499 21107 solver.cpp:237] Iteration 43200, loss = 1.2273
I0525 14:06:55.360677 21107 solver.cpp:253]     Train net output #0: loss = 1.2273 (* 1 = 1.2273 loss)
I0525 14:06:55.360690 21107 sgd_solver.cpp:106] Iteration 43200, lr = 0.0005
I0525 14:07:04.099400 21107 solver.cpp:237] Iteration 43350, loss = 1.19447
I0525 14:07:04.099444 21107 solver.cpp:253]     Train net output #0: loss = 1.19447 (* 1 = 1.19447 loss)
I0525 14:07:04.099462 21107 sgd_solver.cpp:106] Iteration 43350, lr = 0.0005
I0525 14:07:12.773557 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_43500.caffemodel
I0525 14:07:12.854866 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_43500.solverstate
I0525 14:07:12.900271 21107 solver.cpp:237] Iteration 43500, loss = 1.32658
I0525 14:07:12.900319 21107 solver.cpp:253]     Train net output #0: loss = 1.32658 (* 1 = 1.32658 loss)
I0525 14:07:12.900333 21107 sgd_solver.cpp:106] Iteration 43500, lr = 0.0005
I0525 14:07:21.635045 21107 solver.cpp:237] Iteration 43650, loss = 1.32338
I0525 14:07:21.635079 21107 solver.cpp:253]     Train net output #0: loss = 1.32338 (* 1 = 1.32338 loss)
I0525 14:07:21.635097 21107 sgd_solver.cpp:106] Iteration 43650, lr = 0.0005
I0525 14:07:30.373420 21107 solver.cpp:237] Iteration 43800, loss = 1.35929
I0525 14:07:30.373599 21107 solver.cpp:253]     Train net output #0: loss = 1.35929 (* 1 = 1.35929 loss)
I0525 14:07:30.373612 21107 sgd_solver.cpp:106] Iteration 43800, lr = 0.0005
I0525 14:07:39.106591 21107 solver.cpp:237] Iteration 43950, loss = 1.23072
I0525 14:07:39.106621 21107 solver.cpp:253]     Train net output #0: loss = 1.23072 (* 1 = 1.23072 loss)
I0525 14:07:39.106642 21107 sgd_solver.cpp:106] Iteration 43950, lr = 0.0005
I0525 14:08:08.720473 21107 solver.cpp:237] Iteration 44100, loss = 1.31027
I0525 14:08:08.720657 21107 solver.cpp:253]     Train net output #0: loss = 1.31027 (* 1 = 1.31027 loss)
I0525 14:08:08.720672 21107 sgd_solver.cpp:106] Iteration 44100, lr = 0.0005
I0525 14:08:17.457734 21107 solver.cpp:237] Iteration 44250, loss = 1.39848
I0525 14:08:17.457778 21107 solver.cpp:253]     Train net output #0: loss = 1.39848 (* 1 = 1.39848 loss)
I0525 14:08:17.457793 21107 sgd_solver.cpp:106] Iteration 44250, lr = 0.0005
I0525 14:08:26.190501 21107 solver.cpp:237] Iteration 44400, loss = 1.50314
I0525 14:08:26.190536 21107 solver.cpp:253]     Train net output #0: loss = 1.50314 (* 1 = 1.50314 loss)
I0525 14:08:26.190551 21107 sgd_solver.cpp:106] Iteration 44400, lr = 0.0005
I0525 14:08:34.922312 21107 solver.cpp:237] Iteration 44550, loss = 1.52107
I0525 14:08:34.922345 21107 solver.cpp:253]     Train net output #0: loss = 1.52107 (* 1 = 1.52107 loss)
I0525 14:08:34.922358 21107 sgd_solver.cpp:106] Iteration 44550, lr = 0.0005
I0525 14:08:43.665673 21107 solver.cpp:237] Iteration 44700, loss = 1.32599
I0525 14:08:43.665845 21107 solver.cpp:253]     Train net output #0: loss = 1.32599 (* 1 = 1.32599 loss)
I0525 14:08:43.665859 21107 sgd_solver.cpp:106] Iteration 44700, lr = 0.0005
I0525 14:08:52.399943 21107 solver.cpp:237] Iteration 44850, loss = 1.38859
I0525 14:08:52.399977 21107 solver.cpp:253]     Train net output #0: loss = 1.38859 (* 1 = 1.38859 loss)
I0525 14:08:52.399993 21107 sgd_solver.cpp:106] Iteration 44850, lr = 0.0005
I0525 14:09:01.081713 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_45000.caffemodel
I0525 14:09:01.162153 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_45000.solverstate
I0525 14:09:01.189623 21107 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 14:09:47.726058 21107 solver.cpp:409]     Test net output #0: accuracy = 0.832372
I0525 14:09:47.726253 21107 solver.cpp:409]     Test net output #1: loss = 0.583147 (* 1 = 0.583147 loss)
I0525 14:10:08.600124 21107 solver.cpp:237] Iteration 45000, loss = 1.3455
I0525 14:10:08.600177 21107 solver.cpp:253]     Train net output #0: loss = 1.3455 (* 1 = 1.3455 loss)
I0525 14:10:08.600191 21107 sgd_solver.cpp:106] Iteration 45000, lr = 0.0005
I0525 14:10:17.347950 21107 solver.cpp:237] Iteration 45150, loss = 1.30772
I0525 14:10:17.347985 21107 solver.cpp:253]     Train net output #0: loss = 1.30772 (* 1 = 1.30772 loss)
I0525 14:10:17.348002 21107 sgd_solver.cpp:106] Iteration 45150, lr = 0.0005
I0525 14:10:26.092530 21107 solver.cpp:237] Iteration 45300, loss = 1.2038
I0525 14:10:26.092706 21107 solver.cpp:253]     Train net output #0: loss = 1.2038 (* 1 = 1.2038 loss)
I0525 14:10:26.092720 21107 sgd_solver.cpp:106] Iteration 45300, lr = 0.0005
I0525 14:10:34.827949 21107 solver.cpp:237] Iteration 45450, loss = 1.19321
I0525 14:10:34.827982 21107 solver.cpp:253]     Train net output #0: loss = 1.19321 (* 1 = 1.19321 loss)
I0525 14:10:34.827997 21107 sgd_solver.cpp:106] Iteration 45450, lr = 0.0005
I0525 14:10:43.568538 21107 solver.cpp:237] Iteration 45600, loss = 1.27852
I0525 14:10:43.568573 21107 solver.cpp:253]     Train net output #0: loss = 1.27852 (* 1 = 1.27852 loss)
I0525 14:10:43.568589 21107 sgd_solver.cpp:106] Iteration 45600, lr = 0.0005
I0525 14:10:52.311745 21107 solver.cpp:237] Iteration 45750, loss = 1.21579
I0525 14:10:52.311782 21107 solver.cpp:253]     Train net output #0: loss = 1.21579 (* 1 = 1.21579 loss)
I0525 14:10:52.311805 21107 sgd_solver.cpp:106] Iteration 45750, lr = 0.0005
I0525 14:11:01.052265 21107 solver.cpp:237] Iteration 45900, loss = 1.23797
I0525 14:11:01.052428 21107 solver.cpp:253]     Train net output #0: loss = 1.23797 (* 1 = 1.23797 loss)
I0525 14:11:01.052441 21107 sgd_solver.cpp:106] Iteration 45900, lr = 0.0005
I0525 14:11:30.678395 21107 solver.cpp:237] Iteration 46050, loss = 1.45652
I0525 14:11:30.678444 21107 solver.cpp:253]     Train net output #0: loss = 1.45652 (* 1 = 1.45652 loss)
I0525 14:11:30.678460 21107 sgd_solver.cpp:106] Iteration 46050, lr = 0.0005
I0525 14:11:39.417444 21107 solver.cpp:237] Iteration 46200, loss = 1.23526
I0525 14:11:39.417634 21107 solver.cpp:253]     Train net output #0: loss = 1.23526 (* 1 = 1.23526 loss)
I0525 14:11:39.417647 21107 sgd_solver.cpp:106] Iteration 46200, lr = 0.0005
I0525 14:11:48.158151 21107 solver.cpp:237] Iteration 46350, loss = 1.32175
I0525 14:11:48.158186 21107 solver.cpp:253]     Train net output #0: loss = 1.32175 (* 1 = 1.32175 loss)
I0525 14:11:48.158202 21107 sgd_solver.cpp:106] Iteration 46350, lr = 0.0005
I0525 14:11:56.841656 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_46500.caffemodel
I0525 14:11:56.920069 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_46500.solverstate
I0525 14:11:56.964052 21107 solver.cpp:237] Iteration 46500, loss = 1.28042
I0525 14:11:56.964097 21107 solver.cpp:253]     Train net output #0: loss = 1.28042 (* 1 = 1.28042 loss)
I0525 14:11:56.964114 21107 sgd_solver.cpp:106] Iteration 46500, lr = 0.0005
I0525 14:12:05.699636 21107 solver.cpp:237] Iteration 46650, loss = 1.44653
I0525 14:12:05.699678 21107 solver.cpp:253]     Train net output #0: loss = 1.44653 (* 1 = 1.44653 loss)
I0525 14:12:05.699694 21107 sgd_solver.cpp:106] Iteration 46650, lr = 0.0005
I0525 14:12:14.439539 21107 solver.cpp:237] Iteration 46800, loss = 1.30303
I0525 14:12:14.439716 21107 solver.cpp:253]     Train net output #0: loss = 1.30303 (* 1 = 1.30303 loss)
I0525 14:12:14.439730 21107 sgd_solver.cpp:106] Iteration 46800, lr = 0.0005
I0525 14:12:23.183748 21107 solver.cpp:237] Iteration 46950, loss = 1.28474
I0525 14:12:23.183782 21107 solver.cpp:253]     Train net output #0: loss = 1.28474 (* 1 = 1.28474 loss)
I0525 14:12:23.183799 21107 sgd_solver.cpp:106] Iteration 46950, lr = 0.0005
I0525 14:12:52.748919 21107 solver.cpp:237] Iteration 47100, loss = 1.36678
I0525 14:12:52.749104 21107 solver.cpp:253]     Train net output #0: loss = 1.36678 (* 1 = 1.36678 loss)
I0525 14:12:52.749119 21107 sgd_solver.cpp:106] Iteration 47100, lr = 0.0005
I0525 14:13:01.487200 21107 solver.cpp:237] Iteration 47250, loss = 1.14963
I0525 14:13:01.487234 21107 solver.cpp:253]     Train net output #0: loss = 1.14963 (* 1 = 1.14963 loss)
I0525 14:13:01.487251 21107 sgd_solver.cpp:106] Iteration 47250, lr = 0.0005
I0525 14:13:10.230830 21107 solver.cpp:237] Iteration 47400, loss = 1.30901
I0525 14:13:10.230865 21107 solver.cpp:253]     Train net output #0: loss = 1.30901 (* 1 = 1.30901 loss)
I0525 14:13:10.230880 21107 sgd_solver.cpp:106] Iteration 47400, lr = 0.0005
I0525 14:13:18.975219 21107 solver.cpp:237] Iteration 47550, loss = 1.27269
I0525 14:13:18.975262 21107 solver.cpp:253]     Train net output #0: loss = 1.27269 (* 1 = 1.27269 loss)
I0525 14:13:18.975276 21107 sgd_solver.cpp:106] Iteration 47550, lr = 0.0005
I0525 14:13:27.720908 21107 solver.cpp:237] Iteration 47700, loss = 1.24029
I0525 14:13:27.721076 21107 solver.cpp:253]     Train net output #0: loss = 1.24029 (* 1 = 1.24029 loss)
I0525 14:13:27.721091 21107 sgd_solver.cpp:106] Iteration 47700, lr = 0.0005
I0525 14:13:36.463105 21107 solver.cpp:237] Iteration 47850, loss = 1.41191
I0525 14:13:36.463143 21107 solver.cpp:253]     Train net output #0: loss = 1.41191 (* 1 = 1.41191 loss)
I0525 14:13:36.463161 21107 sgd_solver.cpp:106] Iteration 47850, lr = 0.0005
I0525 14:13:45.147609 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_48000.caffemodel
I0525 14:13:45.226330 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_48000.solverstate
I0525 14:13:45.251608 21107 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 14:14:52.920311 21107 solver.cpp:409]     Test net output #0: accuracy = 0.833654
I0525 14:14:52.920497 21107 solver.cpp:409]     Test net output #1: loss = 0.539736 (* 1 = 0.539736 loss)
I0525 14:15:13.781394 21107 solver.cpp:237] Iteration 48000, loss = 1.27041
I0525 14:15:13.781445 21107 solver.cpp:253]     Train net output #0: loss = 1.27041 (* 1 = 1.27041 loss)
I0525 14:15:13.781460 21107 sgd_solver.cpp:106] Iteration 48000, lr = 0.0005
I0525 14:15:22.511693 21107 solver.cpp:237] Iteration 48150, loss = 1.43147
I0525 14:15:22.511740 21107 solver.cpp:253]     Train net output #0: loss = 1.43147 (* 1 = 1.43147 loss)
I0525 14:15:22.511755 21107 sgd_solver.cpp:106] Iteration 48150, lr = 0.0005
I0525 14:15:31.237455 21107 solver.cpp:237] Iteration 48300, loss = 1.32387
I0525 14:15:31.237624 21107 solver.cpp:253]     Train net output #0: loss = 1.32387 (* 1 = 1.32387 loss)
I0525 14:15:31.237638 21107 sgd_solver.cpp:106] Iteration 48300, lr = 0.0005
I0525 14:15:39.964282 21107 solver.cpp:237] Iteration 48450, loss = 1.37454
I0525 14:15:39.964314 21107 solver.cpp:253]     Train net output #0: loss = 1.37454 (* 1 = 1.37454 loss)
I0525 14:15:39.964332 21107 sgd_solver.cpp:106] Iteration 48450, lr = 0.0005
I0525 14:15:48.695314 21107 solver.cpp:237] Iteration 48600, loss = 1.45596
I0525 14:15:48.695359 21107 solver.cpp:253]     Train net output #0: loss = 1.45596 (* 1 = 1.45596 loss)
I0525 14:15:48.695377 21107 sgd_solver.cpp:106] Iteration 48600, lr = 0.0005
I0525 14:15:57.429136 21107 solver.cpp:237] Iteration 48750, loss = 1.20685
I0525 14:15:57.429172 21107 solver.cpp:253]     Train net output #0: loss = 1.20685 (* 1 = 1.20685 loss)
I0525 14:15:57.429188 21107 sgd_solver.cpp:106] Iteration 48750, lr = 0.0005
I0525 14:16:06.160076 21107 solver.cpp:237] Iteration 48900, loss = 1.50112
I0525 14:16:06.160253 21107 solver.cpp:253]     Train net output #0: loss = 1.50112 (* 1 = 1.50112 loss)
I0525 14:16:06.160267 21107 sgd_solver.cpp:106] Iteration 48900, lr = 0.0005
I0525 14:16:35.741533 21107 solver.cpp:237] Iteration 49050, loss = 1.40613
I0525 14:16:35.741580 21107 solver.cpp:253]     Train net output #0: loss = 1.40613 (* 1 = 1.40613 loss)
I0525 14:16:35.741597 21107 sgd_solver.cpp:106] Iteration 49050, lr = 0.0005
I0525 14:16:44.472487 21107 solver.cpp:237] Iteration 49200, loss = 1.30581
I0525 14:16:44.472659 21107 solver.cpp:253]     Train net output #0: loss = 1.30581 (* 1 = 1.30581 loss)
I0525 14:16:44.472672 21107 sgd_solver.cpp:106] Iteration 49200, lr = 0.0005
I0525 14:16:53.204058 21107 solver.cpp:237] Iteration 49350, loss = 1.46841
I0525 14:16:53.204092 21107 solver.cpp:253]     Train net output #0: loss = 1.46841 (* 1 = 1.46841 loss)
I0525 14:16:53.204109 21107 sgd_solver.cpp:106] Iteration 49350, lr = 0.0005
I0525 14:17:01.880652 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_49500.caffemodel
I0525 14:17:01.959300 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_49500.solverstate
I0525 14:17:02.005247 21107 solver.cpp:237] Iteration 49500, loss = 1.24588
I0525 14:17:02.005297 21107 solver.cpp:253]     Train net output #0: loss = 1.24588 (* 1 = 1.24588 loss)
I0525 14:17:02.005312 21107 sgd_solver.cpp:106] Iteration 49500, lr = 0.0005
I0525 14:17:10.739652 21107 solver.cpp:237] Iteration 49650, loss = 1.29314
I0525 14:17:10.739686 21107 solver.cpp:253]     Train net output #0: loss = 1.29314 (* 1 = 1.29314 loss)
I0525 14:17:10.739702 21107 sgd_solver.cpp:106] Iteration 49650, lr = 0.0005
I0525 14:17:19.471287 21107 solver.cpp:237] Iteration 49800, loss = 1.4764
I0525 14:17:19.471457 21107 solver.cpp:253]     Train net output #0: loss = 1.4764 (* 1 = 1.4764 loss)
I0525 14:17:19.471470 21107 sgd_solver.cpp:106] Iteration 49800, lr = 0.0005
I0525 14:17:28.199718 21107 solver.cpp:237] Iteration 49950, loss = 1.45618
I0525 14:17:28.199760 21107 solver.cpp:253]     Train net output #0: loss = 1.45618 (* 1 = 1.45618 loss)
I0525 14:17:28.199780 21107 sgd_solver.cpp:106] Iteration 49950, lr = 0.0005
I0525 14:17:57.783859 21107 solver.cpp:237] Iteration 50100, loss = 1.15087
I0525 14:17:57.784046 21107 solver.cpp:253]     Train net output #0: loss = 1.15087 (* 1 = 1.15087 loss)
I0525 14:17:57.784060 21107 sgd_solver.cpp:106] Iteration 50100, lr = 0.0005
I0525 14:18:06.512984 21107 solver.cpp:237] Iteration 50250, loss = 1.24462
I0525 14:18:06.513020 21107 solver.cpp:253]     Train net output #0: loss = 1.24462 (* 1 = 1.24462 loss)
I0525 14:18:06.513036 21107 sgd_solver.cpp:106] Iteration 50250, lr = 0.0005
I0525 14:18:15.238404 21107 solver.cpp:237] Iteration 50400, loss = 1.31894
I0525 14:18:15.238445 21107 solver.cpp:253]     Train net output #0: loss = 1.31894 (* 1 = 1.31894 loss)
I0525 14:18:15.238463 21107 sgd_solver.cpp:106] Iteration 50400, lr = 0.0005
I0525 14:18:23.972798 21107 solver.cpp:237] Iteration 50550, loss = 1.36917
I0525 14:18:23.972833 21107 solver.cpp:253]     Train net output #0: loss = 1.36917 (* 1 = 1.36917 loss)
I0525 14:18:23.972849 21107 sgd_solver.cpp:106] Iteration 50550, lr = 0.0005
I0525 14:18:32.708564 21107 solver.cpp:237] Iteration 50700, loss = 1.16238
I0525 14:18:32.708731 21107 solver.cpp:253]     Train net output #0: loss = 1.16238 (* 1 = 1.16238 loss)
I0525 14:18:32.708745 21107 sgd_solver.cpp:106] Iteration 50700, lr = 0.0005
I0525 14:18:41.440714 21107 solver.cpp:237] Iteration 50850, loss = 1.25504
I0525 14:18:41.440760 21107 solver.cpp:253]     Train net output #0: loss = 1.25504 (* 1 = 1.25504 loss)
I0525 14:18:41.440778 21107 sgd_solver.cpp:106] Iteration 50850, lr = 0.0005
I0525 14:18:50.115583 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_51000.caffemodel
I0525 14:18:50.194785 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_51000.solverstate
I0525 14:18:50.220886 21107 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 14:19:37.044009 21107 solver.cpp:409]     Test net output #0: accuracy = 0.838626
I0525 14:19:37.044203 21107 solver.cpp:409]     Test net output #1: loss = 0.56433 (* 1 = 0.56433 loss)
I0525 14:19:57.910105 21107 solver.cpp:237] Iteration 51000, loss = 1.25323
I0525 14:19:57.910159 21107 solver.cpp:253]     Train net output #0: loss = 1.25323 (* 1 = 1.25323 loss)
I0525 14:19:57.910174 21107 sgd_solver.cpp:106] Iteration 51000, lr = 0.0005
I0525 14:20:06.650080 21107 solver.cpp:237] Iteration 51150, loss = 1.31135
I0525 14:20:06.650115 21107 solver.cpp:253]     Train net output #0: loss = 1.31135 (* 1 = 1.31135 loss)
I0525 14:20:06.650132 21107 sgd_solver.cpp:106] Iteration 51150, lr = 0.0005
I0525 14:20:15.392511 21107 solver.cpp:237] Iteration 51300, loss = 1.27192
I0525 14:20:15.392683 21107 solver.cpp:253]     Train net output #0: loss = 1.27192 (* 1 = 1.27192 loss)
I0525 14:20:15.392698 21107 sgd_solver.cpp:106] Iteration 51300, lr = 0.0005
I0525 14:20:24.134582 21107 solver.cpp:237] Iteration 51450, loss = 1.63436
I0525 14:20:24.134626 21107 solver.cpp:253]     Train net output #0: loss = 1.63436 (* 1 = 1.63436 loss)
I0525 14:20:24.134644 21107 sgd_solver.cpp:106] Iteration 51450, lr = 0.0005
I0525 14:20:32.875066 21107 solver.cpp:237] Iteration 51600, loss = 1.38095
I0525 14:20:32.875100 21107 solver.cpp:253]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0525 14:20:32.875123 21107 sgd_solver.cpp:106] Iteration 51600, lr = 0.0005
I0525 14:20:41.622732 21107 solver.cpp:237] Iteration 51750, loss = 1.40205
I0525 14:20:41.622767 21107 solver.cpp:253]     Train net output #0: loss = 1.40205 (* 1 = 1.40205 loss)
I0525 14:20:41.622781 21107 sgd_solver.cpp:106] Iteration 51750, lr = 0.0005
I0525 14:20:50.360270 21107 solver.cpp:237] Iteration 51900, loss = 1.15842
I0525 14:20:50.360447 21107 solver.cpp:253]     Train net output #0: loss = 1.15842 (* 1 = 1.15842 loss)
I0525 14:20:50.360461 21107 sgd_solver.cpp:106] Iteration 51900, lr = 0.0005
I0525 14:21:19.935436 21107 solver.cpp:237] Iteration 52050, loss = 1.36704
I0525 14:21:19.935485 21107 solver.cpp:253]     Train net output #0: loss = 1.36704 (* 1 = 1.36704 loss)
I0525 14:21:19.935500 21107 sgd_solver.cpp:106] Iteration 52050, lr = 0.0005
I0525 14:21:28.674940 21107 solver.cpp:237] Iteration 52200, loss = 1.24302
I0525 14:21:28.675114 21107 solver.cpp:253]     Train net output #0: loss = 1.24302 (* 1 = 1.24302 loss)
I0525 14:21:28.675134 21107 sgd_solver.cpp:106] Iteration 52200, lr = 0.0005
I0525 14:21:37.420003 21107 solver.cpp:237] Iteration 52350, loss = 1.34762
I0525 14:21:37.420047 21107 solver.cpp:253]     Train net output #0: loss = 1.34762 (* 1 = 1.34762 loss)
I0525 14:21:37.420063 21107 sgd_solver.cpp:106] Iteration 52350, lr = 0.0005
I0525 14:21:46.102474 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_52500.caffemodel
I0525 14:21:46.182271 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_52500.solverstate
I0525 14:21:46.226986 21107 solver.cpp:237] Iteration 52500, loss = 1.43096
I0525 14:21:46.227031 21107 solver.cpp:253]     Train net output #0: loss = 1.43096 (* 1 = 1.43096 loss)
I0525 14:21:46.227052 21107 sgd_solver.cpp:106] Iteration 52500, lr = 0.0005
I0525 14:21:54.967741 21107 solver.cpp:237] Iteration 52650, loss = 1.32714
I0525 14:21:54.967775 21107 solver.cpp:253]     Train net output #0: loss = 1.32714 (* 1 = 1.32714 loss)
I0525 14:21:54.967792 21107 sgd_solver.cpp:106] Iteration 52650, lr = 0.0005
I0525 14:22:03.710633 21107 solver.cpp:237] Iteration 52800, loss = 1.27088
I0525 14:22:03.710824 21107 solver.cpp:253]     Train net output #0: loss = 1.27088 (* 1 = 1.27088 loss)
I0525 14:22:03.710839 21107 sgd_solver.cpp:106] Iteration 52800, lr = 0.0005
I0525 14:22:12.456243 21107 solver.cpp:237] Iteration 52950, loss = 1.37211
I0525 14:22:12.456277 21107 solver.cpp:253]     Train net output #0: loss = 1.37211 (* 1 = 1.37211 loss)
I0525 14:22:12.456295 21107 sgd_solver.cpp:106] Iteration 52950, lr = 0.0005
I0525 14:22:42.053521 21107 solver.cpp:237] Iteration 53100, loss = 1.22882
I0525 14:22:42.053722 21107 solver.cpp:253]     Train net output #0: loss = 1.22882 (* 1 = 1.22882 loss)
I0525 14:22:42.053736 21107 sgd_solver.cpp:106] Iteration 53100, lr = 0.0005
I0525 14:22:50.797878 21107 solver.cpp:237] Iteration 53250, loss = 1.2036
I0525 14:22:50.797914 21107 solver.cpp:253]     Train net output #0: loss = 1.2036 (* 1 = 1.2036 loss)
I0525 14:22:50.797935 21107 sgd_solver.cpp:106] Iteration 53250, lr = 0.0005
I0525 14:22:59.538576 21107 solver.cpp:237] Iteration 53400, loss = 1.46034
I0525 14:22:59.538610 21107 solver.cpp:253]     Train net output #0: loss = 1.46034 (* 1 = 1.46034 loss)
I0525 14:22:59.538628 21107 sgd_solver.cpp:106] Iteration 53400, lr = 0.0005
I0525 14:23:08.280396 21107 solver.cpp:237] Iteration 53550, loss = 1.3784
I0525 14:23:08.280431 21107 solver.cpp:253]     Train net output #0: loss = 1.3784 (* 1 = 1.3784 loss)
I0525 14:23:08.280447 21107 sgd_solver.cpp:106] Iteration 53550, lr = 0.0005
I0525 14:23:17.025707 21107 solver.cpp:237] Iteration 53700, loss = 1.30635
I0525 14:23:17.025885 21107 solver.cpp:253]     Train net output #0: loss = 1.30635 (* 1 = 1.30635 loss)
I0525 14:23:17.025899 21107 sgd_solver.cpp:106] Iteration 53700, lr = 0.0005
I0525 14:23:25.768262 21107 solver.cpp:237] Iteration 53850, loss = 1.19889
I0525 14:23:25.768297 21107 solver.cpp:253]     Train net output #0: loss = 1.19889 (* 1 = 1.19889 loss)
I0525 14:23:25.768314 21107 sgd_solver.cpp:106] Iteration 53850, lr = 0.0005
I0525 14:23:34.450750 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_54000.caffemodel
I0525 14:23:34.532444 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_54000.solverstate
I0525 14:23:34.563321 21107 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 14:24:42.277823 21107 solver.cpp:409]     Test net output #0: accuracy = 0.83608
I0525 14:24:42.278013 21107 solver.cpp:409]     Test net output #1: loss = 0.539913 (* 1 = 0.539913 loss)
I0525 14:25:03.162634 21107 solver.cpp:237] Iteration 54000, loss = 1.32416
I0525 14:25:03.162686 21107 solver.cpp:253]     Train net output #0: loss = 1.32416 (* 1 = 1.32416 loss)
I0525 14:25:03.162701 21107 sgd_solver.cpp:106] Iteration 54000, lr = 0.0005
I0525 14:25:11.895588 21107 solver.cpp:237] Iteration 54150, loss = 1.21863
I0525 14:25:11.895622 21107 solver.cpp:253]     Train net output #0: loss = 1.21863 (* 1 = 1.21863 loss)
I0525 14:25:11.895639 21107 sgd_solver.cpp:106] Iteration 54150, lr = 0.0005
I0525 14:25:20.635108 21107 solver.cpp:237] Iteration 54300, loss = 1.36523
I0525 14:25:20.635298 21107 solver.cpp:253]     Train net output #0: loss = 1.36523 (* 1 = 1.36523 loss)
I0525 14:25:20.635311 21107 sgd_solver.cpp:106] Iteration 54300, lr = 0.0005
I0525 14:25:29.364608 21107 solver.cpp:237] Iteration 54450, loss = 1.45246
I0525 14:25:29.364641 21107 solver.cpp:253]     Train net output #0: loss = 1.45246 (* 1 = 1.45246 loss)
I0525 14:25:29.364660 21107 sgd_solver.cpp:106] Iteration 54450, lr = 0.0005
I0525 14:25:38.094573 21107 solver.cpp:237] Iteration 54600, loss = 1.42049
I0525 14:25:38.094607 21107 solver.cpp:253]     Train net output #0: loss = 1.42049 (* 1 = 1.42049 loss)
I0525 14:25:38.094622 21107 sgd_solver.cpp:106] Iteration 54600, lr = 0.0005
I0525 14:25:46.832262 21107 solver.cpp:237] Iteration 54750, loss = 1.46082
I0525 14:25:46.832309 21107 solver.cpp:253]     Train net output #0: loss = 1.46082 (* 1 = 1.46082 loss)
I0525 14:25:46.832322 21107 sgd_solver.cpp:106] Iteration 54750, lr = 0.0005
I0525 14:25:55.570674 21107 solver.cpp:237] Iteration 54900, loss = 1.18023
I0525 14:25:55.570861 21107 solver.cpp:253]     Train net output #0: loss = 1.18023 (* 1 = 1.18023 loss)
I0525 14:25:55.570875 21107 sgd_solver.cpp:106] Iteration 54900, lr = 0.0005
I0525 14:26:25.160689 21107 solver.cpp:237] Iteration 55050, loss = 1.24907
I0525 14:26:25.160738 21107 solver.cpp:253]     Train net output #0: loss = 1.24907 (* 1 = 1.24907 loss)
I0525 14:26:25.160755 21107 sgd_solver.cpp:106] Iteration 55050, lr = 0.0005
I0525 14:26:33.892987 21107 solver.cpp:237] Iteration 55200, loss = 1.31815
I0525 14:26:33.893162 21107 solver.cpp:253]     Train net output #0: loss = 1.31815 (* 1 = 1.31815 loss)
I0525 14:26:33.893175 21107 sgd_solver.cpp:106] Iteration 55200, lr = 0.0005
I0525 14:26:42.626376 21107 solver.cpp:237] Iteration 55350, loss = 1.18168
I0525 14:26:42.626422 21107 solver.cpp:253]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0525 14:26:42.626440 21107 sgd_solver.cpp:106] Iteration 55350, lr = 0.0005
I0525 14:26:51.303181 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_55500.caffemodel
I0525 14:26:51.381983 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_55500.solverstate
I0525 14:26:51.425407 21107 solver.cpp:237] Iteration 55500, loss = 1.40218
I0525 14:26:51.425452 21107 solver.cpp:253]     Train net output #0: loss = 1.40218 (* 1 = 1.40218 loss)
I0525 14:26:51.425470 21107 sgd_solver.cpp:106] Iteration 55500, lr = 0.0005
I0525 14:27:00.163055 21107 solver.cpp:237] Iteration 55650, loss = 1.25263
I0525 14:27:00.163095 21107 solver.cpp:253]     Train net output #0: loss = 1.25263 (* 1 = 1.25263 loss)
I0525 14:27:00.163112 21107 sgd_solver.cpp:106] Iteration 55650, lr = 0.0005
I0525 14:27:08.903125 21107 solver.cpp:237] Iteration 55800, loss = 1.27624
I0525 14:27:08.903300 21107 solver.cpp:253]     Train net output #0: loss = 1.27624 (* 1 = 1.27624 loss)
I0525 14:27:08.903312 21107 sgd_solver.cpp:106] Iteration 55800, lr = 0.0005
I0525 14:27:17.638887 21107 solver.cpp:237] Iteration 55950, loss = 1.4568
I0525 14:27:17.638922 21107 solver.cpp:253]     Train net output #0: loss = 1.4568 (* 1 = 1.4568 loss)
I0525 14:27:17.638936 21107 sgd_solver.cpp:106] Iteration 55950, lr = 0.0005
I0525 14:27:47.192989 21107 solver.cpp:237] Iteration 56100, loss = 1.15047
I0525 14:27:47.193181 21107 solver.cpp:253]     Train net output #0: loss = 1.15047 (* 1 = 1.15047 loss)
I0525 14:27:47.193194 21107 sgd_solver.cpp:106] Iteration 56100, lr = 0.0005
I0525 14:27:55.928990 21107 solver.cpp:237] Iteration 56250, loss = 1.28517
I0525 14:27:55.929024 21107 solver.cpp:253]     Train net output #0: loss = 1.28517 (* 1 = 1.28517 loss)
I0525 14:27:55.929041 21107 sgd_solver.cpp:106] Iteration 56250, lr = 0.0005
I0525 14:28:04.660174 21107 solver.cpp:237] Iteration 56400, loss = 1.2499
I0525 14:28:04.660209 21107 solver.cpp:253]     Train net output #0: loss = 1.2499 (* 1 = 1.2499 loss)
I0525 14:28:04.660225 21107 sgd_solver.cpp:106] Iteration 56400, lr = 0.0005
I0525 14:28:13.394306 21107 solver.cpp:237] Iteration 56550, loss = 1.45806
I0525 14:28:13.394340 21107 solver.cpp:253]     Train net output #0: loss = 1.45806 (* 1 = 1.45806 loss)
I0525 14:28:13.394356 21107 sgd_solver.cpp:106] Iteration 56550, lr = 0.0005
I0525 14:28:22.132369 21107 solver.cpp:237] Iteration 56700, loss = 1.34427
I0525 14:28:22.132550 21107 solver.cpp:253]     Train net output #0: loss = 1.34427 (* 1 = 1.34427 loss)
I0525 14:28:22.132563 21107 sgd_solver.cpp:106] Iteration 56700, lr = 0.0005
I0525 14:28:30.868181 21107 solver.cpp:237] Iteration 56850, loss = 1.26849
I0525 14:28:30.868214 21107 solver.cpp:253]     Train net output #0: loss = 1.26849 (* 1 = 1.26849 loss)
I0525 14:28:30.868232 21107 sgd_solver.cpp:106] Iteration 56850, lr = 0.0005
I0525 14:28:39.544589 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_57000.caffemodel
I0525 14:28:39.623133 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_57000.solverstate
I0525 14:28:39.648473 21107 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 14:29:26.146361 21107 solver.cpp:409]     Test net output #0: accuracy = 0.844146
I0525 14:29:26.146553 21107 solver.cpp:409]     Test net output #1: loss = 0.541284 (* 1 = 0.541284 loss)
I0525 14:29:47.009165 21107 solver.cpp:237] Iteration 57000, loss = 1.23728
I0525 14:29:47.009217 21107 solver.cpp:253]     Train net output #0: loss = 1.23728 (* 1 = 1.23728 loss)
I0525 14:29:47.009232 21107 sgd_solver.cpp:106] Iteration 57000, lr = 0.0005
I0525 14:29:55.749367 21107 solver.cpp:237] Iteration 57150, loss = 1.30823
I0525 14:29:55.749405 21107 solver.cpp:253]     Train net output #0: loss = 1.30823 (* 1 = 1.30823 loss)
I0525 14:29:55.749425 21107 sgd_solver.cpp:106] Iteration 57150, lr = 0.0005
I0525 14:30:04.488647 21107 solver.cpp:237] Iteration 57300, loss = 1.23133
I0525 14:30:04.488823 21107 solver.cpp:253]     Train net output #0: loss = 1.23133 (* 1 = 1.23133 loss)
I0525 14:30:04.488837 21107 sgd_solver.cpp:106] Iteration 57300, lr = 0.0005
I0525 14:30:13.226267 21107 solver.cpp:237] Iteration 57450, loss = 1.31822
I0525 14:30:13.226301 21107 solver.cpp:253]     Train net output #0: loss = 1.31822 (* 1 = 1.31822 loss)
I0525 14:30:13.226317 21107 sgd_solver.cpp:106] Iteration 57450, lr = 0.0005
I0525 14:30:21.964699 21107 solver.cpp:237] Iteration 57600, loss = 1.11104
I0525 14:30:21.964745 21107 solver.cpp:253]     Train net output #0: loss = 1.11104 (* 1 = 1.11104 loss)
I0525 14:30:21.964761 21107 sgd_solver.cpp:106] Iteration 57600, lr = 0.0005
I0525 14:30:30.707201 21107 solver.cpp:237] Iteration 57750, loss = 1.37666
I0525 14:30:30.707237 21107 solver.cpp:253]     Train net output #0: loss = 1.37666 (* 1 = 1.37666 loss)
I0525 14:30:30.707249 21107 sgd_solver.cpp:106] Iteration 57750, lr = 0.0005
I0525 14:30:39.450361 21107 solver.cpp:237] Iteration 57900, loss = 1.21429
I0525 14:30:39.450531 21107 solver.cpp:253]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0525 14:30:39.450546 21107 sgd_solver.cpp:106] Iteration 57900, lr = 0.0005
I0525 14:31:09.038550 21107 solver.cpp:237] Iteration 58050, loss = 1.20844
I0525 14:31:09.038600 21107 solver.cpp:253]     Train net output #0: loss = 1.20844 (* 1 = 1.20844 loss)
I0525 14:31:09.038616 21107 sgd_solver.cpp:106] Iteration 58050, lr = 0.0005
I0525 14:31:17.779521 21107 solver.cpp:237] Iteration 58200, loss = 1.23532
I0525 14:31:17.779705 21107 solver.cpp:253]     Train net output #0: loss = 1.23532 (* 1 = 1.23532 loss)
I0525 14:31:17.779718 21107 sgd_solver.cpp:106] Iteration 58200, lr = 0.0005
I0525 14:31:26.529150 21107 solver.cpp:237] Iteration 58350, loss = 1.08535
I0525 14:31:26.529184 21107 solver.cpp:253]     Train net output #0: loss = 1.08535 (* 1 = 1.08535 loss)
I0525 14:31:26.529201 21107 sgd_solver.cpp:106] Iteration 58350, lr = 0.0005
I0525 14:31:35.210479 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_58500.caffemodel
I0525 14:31:35.289547 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_58500.solverstate
I0525 14:31:35.333794 21107 solver.cpp:237] Iteration 58500, loss = 1.23972
I0525 14:31:35.333843 21107 solver.cpp:253]     Train net output #0: loss = 1.23972 (* 1 = 1.23972 loss)
I0525 14:31:35.333856 21107 sgd_solver.cpp:106] Iteration 58500, lr = 0.0005
I0525 14:31:44.074698 21107 solver.cpp:237] Iteration 58650, loss = 1.22963
I0525 14:31:44.074733 21107 solver.cpp:253]     Train net output #0: loss = 1.22963 (* 1 = 1.22963 loss)
I0525 14:31:44.074749 21107 sgd_solver.cpp:106] Iteration 58650, lr = 0.0005
I0525 14:31:52.813241 21107 solver.cpp:237] Iteration 58800, loss = 1.54123
I0525 14:31:52.813427 21107 solver.cpp:253]     Train net output #0: loss = 1.54123 (* 1 = 1.54123 loss)
I0525 14:31:52.813441 21107 sgd_solver.cpp:106] Iteration 58800, lr = 0.0005
I0525 14:32:01.551919 21107 solver.cpp:237] Iteration 58950, loss = 1.34827
I0525 14:32:01.551966 21107 solver.cpp:253]     Train net output #0: loss = 1.34827 (* 1 = 1.34827 loss)
I0525 14:32:01.551982 21107 sgd_solver.cpp:106] Iteration 58950, lr = 0.0005
I0525 14:32:31.132673 21107 solver.cpp:237] Iteration 59100, loss = 1.1549
I0525 14:32:31.132875 21107 solver.cpp:253]     Train net output #0: loss = 1.1549 (* 1 = 1.1549 loss)
I0525 14:32:31.132890 21107 sgd_solver.cpp:106] Iteration 59100, lr = 0.0005
I0525 14:32:39.873901 21107 solver.cpp:237] Iteration 59250, loss = 1.30541
I0525 14:32:39.873935 21107 solver.cpp:253]     Train net output #0: loss = 1.30541 (* 1 = 1.30541 loss)
I0525 14:32:39.873952 21107 sgd_solver.cpp:106] Iteration 59250, lr = 0.0005
I0525 14:32:48.612932 21107 solver.cpp:237] Iteration 59400, loss = 1.51031
I0525 14:32:48.612967 21107 solver.cpp:253]     Train net output #0: loss = 1.51031 (* 1 = 1.51031 loss)
I0525 14:32:48.612984 21107 sgd_solver.cpp:106] Iteration 59400, lr = 0.0005
I0525 14:32:57.352378 21107 solver.cpp:237] Iteration 59550, loss = 1.45848
I0525 14:32:57.352418 21107 solver.cpp:253]     Train net output #0: loss = 1.45848 (* 1 = 1.45848 loss)
I0525 14:32:57.352439 21107 sgd_solver.cpp:106] Iteration 59550, lr = 0.0005
I0525 14:33:06.088951 21107 solver.cpp:237] Iteration 59700, loss = 1.34195
I0525 14:33:06.089133 21107 solver.cpp:253]     Train net output #0: loss = 1.34195 (* 1 = 1.34195 loss)
I0525 14:33:06.089148 21107 sgd_solver.cpp:106] Iteration 59700, lr = 0.0005
I0525 14:33:14.822708 21107 solver.cpp:237] Iteration 59850, loss = 1.339
I0525 14:33:14.822754 21107 solver.cpp:253]     Train net output #0: loss = 1.339 (* 1 = 1.339 loss)
I0525 14:33:14.822768 21107 sgd_solver.cpp:106] Iteration 59850, lr = 0.0005
I0525 14:33:23.505220 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_60000.caffemodel
I0525 14:33:23.586485 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_60000.solverstate
I0525 14:33:23.613591 21107 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 14:34:31.299810 21107 solver.cpp:409]     Test net output #0: accuracy = 0.846019
I0525 14:34:31.300009 21107 solver.cpp:409]     Test net output #1: loss = 0.559092 (* 1 = 0.559092 loss)
I0525 14:34:52.166144 21107 solver.cpp:237] Iteration 60000, loss = 1.24045
I0525 14:34:52.166195 21107 solver.cpp:253]     Train net output #0: loss = 1.24045 (* 1 = 1.24045 loss)
I0525 14:34:52.166209 21107 sgd_solver.cpp:106] Iteration 60000, lr = 0.0005
I0525 14:35:00.896817 21107 solver.cpp:237] Iteration 60150, loss = 1.25837
I0525 14:35:00.896863 21107 solver.cpp:253]     Train net output #0: loss = 1.25837 (* 1 = 1.25837 loss)
I0525 14:35:00.896880 21107 sgd_solver.cpp:106] Iteration 60150, lr = 0.0005
I0525 14:35:09.628875 21107 solver.cpp:237] Iteration 60300, loss = 1.42832
I0525 14:35:09.629063 21107 solver.cpp:253]     Train net output #0: loss = 1.42832 (* 1 = 1.42832 loss)
I0525 14:35:09.629079 21107 sgd_solver.cpp:106] Iteration 60300, lr = 0.0005
I0525 14:35:18.362943 21107 solver.cpp:237] Iteration 60450, loss = 0.958359
I0525 14:35:18.362978 21107 solver.cpp:253]     Train net output #0: loss = 0.958359 (* 1 = 0.958359 loss)
I0525 14:35:18.362996 21107 sgd_solver.cpp:106] Iteration 60450, lr = 0.0005
I0525 14:35:27.093916 21107 solver.cpp:237] Iteration 60600, loss = 1.01746
I0525 14:35:27.093961 21107 solver.cpp:253]     Train net output #0: loss = 1.01746 (* 1 = 1.01746 loss)
I0525 14:35:27.093977 21107 sgd_solver.cpp:106] Iteration 60600, lr = 0.0005
I0525 14:35:35.824127 21107 solver.cpp:237] Iteration 60750, loss = 1.27952
I0525 14:35:35.824162 21107 solver.cpp:253]     Train net output #0: loss = 1.27952 (* 1 = 1.27952 loss)
I0525 14:35:35.824178 21107 sgd_solver.cpp:106] Iteration 60750, lr = 0.0005
I0525 14:35:44.555459 21107 solver.cpp:237] Iteration 60900, loss = 1.42456
I0525 14:35:44.555637 21107 solver.cpp:253]     Train net output #0: loss = 1.42456 (* 1 = 1.42456 loss)
I0525 14:35:44.555652 21107 sgd_solver.cpp:106] Iteration 60900, lr = 0.0005
I0525 14:36:14.096058 21107 solver.cpp:237] Iteration 61050, loss = 1.30495
I0525 14:36:14.096109 21107 solver.cpp:253]     Train net output #0: loss = 1.30495 (* 1 = 1.30495 loss)
I0525 14:36:14.096124 21107 sgd_solver.cpp:106] Iteration 61050, lr = 0.0005
I0525 14:36:22.829282 21107 solver.cpp:237] Iteration 61200, loss = 1.17935
I0525 14:36:22.829460 21107 solver.cpp:253]     Train net output #0: loss = 1.17935 (* 1 = 1.17935 loss)
I0525 14:36:22.829474 21107 sgd_solver.cpp:106] Iteration 61200, lr = 0.0005
I0525 14:36:31.561944 21107 solver.cpp:237] Iteration 61350, loss = 1.48835
I0525 14:36:31.561978 21107 solver.cpp:253]     Train net output #0: loss = 1.48835 (* 1 = 1.48835 loss)
I0525 14:36:31.561995 21107 sgd_solver.cpp:106] Iteration 61350, lr = 0.0005
I0525 14:36:40.236726 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_61500.caffemodel
I0525 14:36:40.315362 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_61500.solverstate
I0525 14:36:40.358582 21107 solver.cpp:237] Iteration 61500, loss = 1.25507
I0525 14:36:40.358628 21107 solver.cpp:253]     Train net output #0: loss = 1.25507 (* 1 = 1.25507 loss)
I0525 14:36:40.358644 21107 sgd_solver.cpp:106] Iteration 61500, lr = 0.0005
I0525 14:36:49.090634 21107 solver.cpp:237] Iteration 61650, loss = 1.41944
I0525 14:36:49.090668 21107 solver.cpp:253]     Train net output #0: loss = 1.41944 (* 1 = 1.41944 loss)
I0525 14:36:49.090685 21107 sgd_solver.cpp:106] Iteration 61650, lr = 0.0005
I0525 14:36:57.822494 21107 solver.cpp:237] Iteration 61800, loss = 1.23471
I0525 14:36:57.822670 21107 solver.cpp:253]     Train net output #0: loss = 1.23471 (* 1 = 1.23471 loss)
I0525 14:36:57.822685 21107 sgd_solver.cpp:106] Iteration 61800, lr = 0.0005
I0525 14:37:06.553283 21107 solver.cpp:237] Iteration 61950, loss = 1.28763
I0525 14:37:06.553333 21107 solver.cpp:253]     Train net output #0: loss = 1.28763 (* 1 = 1.28763 loss)
I0525 14:37:06.553346 21107 sgd_solver.cpp:106] Iteration 61950, lr = 0.0005
I0525 14:37:36.114076 21107 solver.cpp:237] Iteration 62100, loss = 1.06188
I0525 14:37:36.114270 21107 solver.cpp:253]     Train net output #0: loss = 1.06188 (* 1 = 1.06188 loss)
I0525 14:37:36.114286 21107 sgd_solver.cpp:106] Iteration 62100, lr = 0.0005
I0525 14:37:44.843174 21107 solver.cpp:237] Iteration 62250, loss = 1.25963
I0525 14:37:44.843209 21107 solver.cpp:253]     Train net output #0: loss = 1.25963 (* 1 = 1.25963 loss)
I0525 14:37:44.843225 21107 sgd_solver.cpp:106] Iteration 62250, lr = 0.0005
I0525 14:37:53.575003 21107 solver.cpp:237] Iteration 62400, loss = 1.39098
I0525 14:37:53.575047 21107 solver.cpp:253]     Train net output #0: loss = 1.39098 (* 1 = 1.39098 loss)
I0525 14:37:53.575065 21107 sgd_solver.cpp:106] Iteration 62400, lr = 0.0005
I0525 14:38:02.306551 21107 solver.cpp:237] Iteration 62550, loss = 1.21294
I0525 14:38:02.306586 21107 solver.cpp:253]     Train net output #0: loss = 1.21294 (* 1 = 1.21294 loss)
I0525 14:38:02.306603 21107 sgd_solver.cpp:106] Iteration 62550, lr = 0.0005
I0525 14:38:11.037053 21107 solver.cpp:237] Iteration 62700, loss = 1.21941
I0525 14:38:11.037240 21107 solver.cpp:253]     Train net output #0: loss = 1.21941 (* 1 = 1.21941 loss)
I0525 14:38:11.037253 21107 sgd_solver.cpp:106] Iteration 62700, lr = 0.0005
I0525 14:38:19.769265 21107 solver.cpp:237] Iteration 62850, loss = 1.33433
I0525 14:38:19.769307 21107 solver.cpp:253]     Train net output #0: loss = 1.33433 (* 1 = 1.33433 loss)
I0525 14:38:19.769321 21107 sgd_solver.cpp:106] Iteration 62850, lr = 0.0005
I0525 14:38:28.445545 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_63000.caffemodel
I0525 14:38:28.523568 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_63000.solverstate
I0525 14:38:28.549109 21107 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 14:39:15.384300 21107 solver.cpp:409]     Test net output #0: accuracy = 0.846466
I0525 14:39:15.384503 21107 solver.cpp:409]     Test net output #1: loss = 0.505423 (* 1 = 0.505423 loss)
I0525 14:39:36.213882 21107 solver.cpp:237] Iteration 63000, loss = 1.17341
I0525 14:39:36.213934 21107 solver.cpp:253]     Train net output #0: loss = 1.17341 (* 1 = 1.17341 loss)
I0525 14:39:36.213949 21107 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I0525 14:39:44.956178 21107 solver.cpp:237] Iteration 63150, loss = 1.38744
I0525 14:39:44.956212 21107 solver.cpp:253]     Train net output #0: loss = 1.38744 (* 1 = 1.38744 loss)
I0525 14:39:44.956229 21107 sgd_solver.cpp:106] Iteration 63150, lr = 0.0005
I0525 14:39:53.697124 21107 solver.cpp:237] Iteration 63300, loss = 1.23831
I0525 14:39:53.697304 21107 solver.cpp:253]     Train net output #0: loss = 1.23831 (* 1 = 1.23831 loss)
I0525 14:39:53.697316 21107 sgd_solver.cpp:106] Iteration 63300, lr = 0.0005
I0525 14:40:02.437053 21107 solver.cpp:237] Iteration 63450, loss = 1.27655
I0525 14:40:02.437093 21107 solver.cpp:253]     Train net output #0: loss = 1.27655 (* 1 = 1.27655 loss)
I0525 14:40:02.437110 21107 sgd_solver.cpp:106] Iteration 63450, lr = 0.0005
I0525 14:40:11.177891 21107 solver.cpp:237] Iteration 63600, loss = 1.40405
I0525 14:40:11.177924 21107 solver.cpp:253]     Train net output #0: loss = 1.40405 (* 1 = 1.40405 loss)
I0525 14:40:11.177940 21107 sgd_solver.cpp:106] Iteration 63600, lr = 0.0005
I0525 14:40:19.919476 21107 solver.cpp:237] Iteration 63750, loss = 1.47791
I0525 14:40:19.919517 21107 solver.cpp:253]     Train net output #0: loss = 1.47791 (* 1 = 1.47791 loss)
I0525 14:40:19.919534 21107 sgd_solver.cpp:106] Iteration 63750, lr = 0.0005
I0525 14:40:28.662850 21107 solver.cpp:237] Iteration 63900, loss = 1.20572
I0525 14:40:28.663023 21107 solver.cpp:253]     Train net output #0: loss = 1.20572 (* 1 = 1.20572 loss)
I0525 14:40:28.663038 21107 sgd_solver.cpp:106] Iteration 63900, lr = 0.0005
I0525 14:40:58.250046 21107 solver.cpp:237] Iteration 64050, loss = 1.25371
I0525 14:40:58.250097 21107 solver.cpp:253]     Train net output #0: loss = 1.25371 (* 1 = 1.25371 loss)
I0525 14:40:58.250111 21107 sgd_solver.cpp:106] Iteration 64050, lr = 0.0005
I0525 14:41:06.993242 21107 solver.cpp:237] Iteration 64200, loss = 1.20835
I0525 14:41:06.993432 21107 solver.cpp:253]     Train net output #0: loss = 1.20835 (* 1 = 1.20835 loss)
I0525 14:41:06.993448 21107 sgd_solver.cpp:106] Iteration 64200, lr = 0.0005
I0525 14:41:15.737397 21107 solver.cpp:237] Iteration 64350, loss = 1.28734
I0525 14:41:15.737443 21107 solver.cpp:253]     Train net output #0: loss = 1.28734 (* 1 = 1.28734 loss)
I0525 14:41:15.737460 21107 sgd_solver.cpp:106] Iteration 64350, lr = 0.0005
I0525 14:41:24.418965 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_64500.caffemodel
I0525 14:41:24.497738 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_64500.solverstate
I0525 14:41:24.540613 21107 solver.cpp:237] Iteration 64500, loss = 1.10889
I0525 14:41:24.540659 21107 solver.cpp:253]     Train net output #0: loss = 1.10889 (* 1 = 1.10889 loss)
I0525 14:41:24.540673 21107 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I0525 14:41:33.283824 21107 solver.cpp:237] Iteration 64650, loss = 1.2994
I0525 14:41:33.283860 21107 solver.cpp:253]     Train net output #0: loss = 1.2994 (* 1 = 1.2994 loss)
I0525 14:41:33.283875 21107 sgd_solver.cpp:106] Iteration 64650, lr = 0.0005
I0525 14:41:42.027348 21107 solver.cpp:237] Iteration 64800, loss = 1.39897
I0525 14:41:42.027544 21107 solver.cpp:253]     Train net output #0: loss = 1.39897 (* 1 = 1.39897 loss)
I0525 14:41:42.027559 21107 sgd_solver.cpp:106] Iteration 64800, lr = 0.0005
I0525 14:41:50.769021 21107 solver.cpp:237] Iteration 64950, loss = 1.4332
I0525 14:41:50.769054 21107 solver.cpp:253]     Train net output #0: loss = 1.4332 (* 1 = 1.4332 loss)
I0525 14:41:50.769070 21107 sgd_solver.cpp:106] Iteration 64950, lr = 0.0005
I0525 14:42:20.387464 21107 solver.cpp:237] Iteration 65100, loss = 1.14679
I0525 14:42:20.387661 21107 solver.cpp:253]     Train net output #0: loss = 1.14679 (* 1 = 1.14679 loss)
I0525 14:42:20.387677 21107 sgd_solver.cpp:106] Iteration 65100, lr = 0.0005
I0525 14:42:29.127933 21107 solver.cpp:237] Iteration 65250, loss = 1.0917
I0525 14:42:29.127971 21107 solver.cpp:253]     Train net output #0: loss = 1.0917 (* 1 = 1.0917 loss)
I0525 14:42:29.127991 21107 sgd_solver.cpp:106] Iteration 65250, lr = 0.0005
I0525 14:42:37.869045 21107 solver.cpp:237] Iteration 65400, loss = 1.34794
I0525 14:42:37.869081 21107 solver.cpp:253]     Train net output #0: loss = 1.34794 (* 1 = 1.34794 loss)
I0525 14:42:37.869096 21107 sgd_solver.cpp:106] Iteration 65400, lr = 0.0005
I0525 14:42:46.610486 21107 solver.cpp:237] Iteration 65550, loss = 1.36333
I0525 14:42:46.610520 21107 solver.cpp:253]     Train net output #0: loss = 1.36333 (* 1 = 1.36333 loss)
I0525 14:42:46.610533 21107 sgd_solver.cpp:106] Iteration 65550, lr = 0.0005
I0525 14:42:55.358250 21107 solver.cpp:237] Iteration 65700, loss = 1.20048
I0525 14:42:55.358453 21107 solver.cpp:253]     Train net output #0: loss = 1.20048 (* 1 = 1.20048 loss)
I0525 14:42:55.358466 21107 sgd_solver.cpp:106] Iteration 65700, lr = 0.0005
I0525 14:43:04.098140 21107 solver.cpp:237] Iteration 65850, loss = 1.24614
I0525 14:43:04.098173 21107 solver.cpp:253]     Train net output #0: loss = 1.24614 (* 1 = 1.24614 loss)
I0525 14:43:04.098191 21107 sgd_solver.cpp:106] Iteration 65850, lr = 0.0005
I0525 14:43:12.781903 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_66000.caffemodel
I0525 14:43:12.861884 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_66000.solverstate
I0525 14:43:12.888464 21107 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 14:44:20.635437 21107 solver.cpp:409]     Test net output #0: accuracy = 0.848912
I0525 14:44:20.635633 21107 solver.cpp:409]     Test net output #1: loss = 0.519368 (* 1 = 0.519368 loss)
I0525 14:44:41.523715 21107 solver.cpp:237] Iteration 66000, loss = 1.52157
I0525 14:44:41.523766 21107 solver.cpp:253]     Train net output #0: loss = 1.52157 (* 1 = 1.52157 loss)
I0525 14:44:41.523782 21107 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I0525 14:44:50.256937 21107 solver.cpp:237] Iteration 66150, loss = 1.30324
I0525 14:44:50.256970 21107 solver.cpp:253]     Train net output #0: loss = 1.30324 (* 1 = 1.30324 loss)
I0525 14:44:50.256988 21107 sgd_solver.cpp:106] Iteration 66150, lr = 0.0005
I0525 14:44:58.989825 21107 solver.cpp:237] Iteration 66300, loss = 1.40216
I0525 14:44:58.990020 21107 solver.cpp:253]     Train net output #0: loss = 1.40216 (* 1 = 1.40216 loss)
I0525 14:44:58.990034 21107 sgd_solver.cpp:106] Iteration 66300, lr = 0.0005
I0525 14:45:07.726007 21107 solver.cpp:237] Iteration 66450, loss = 1.5517
I0525 14:45:07.726042 21107 solver.cpp:253]     Train net output #0: loss = 1.5517 (* 1 = 1.5517 loss)
I0525 14:45:07.726058 21107 sgd_solver.cpp:106] Iteration 66450, lr = 0.0005
I0525 14:45:16.465641 21107 solver.cpp:237] Iteration 66600, loss = 1.36878
I0525 14:45:16.465675 21107 solver.cpp:253]     Train net output #0: loss = 1.36878 (* 1 = 1.36878 loss)
I0525 14:45:16.465690 21107 sgd_solver.cpp:106] Iteration 66600, lr = 0.0005
I0525 14:45:25.199978 21107 solver.cpp:237] Iteration 66750, loss = 1.386
I0525 14:45:25.200011 21107 solver.cpp:253]     Train net output #0: loss = 1.386 (* 1 = 1.386 loss)
I0525 14:45:25.200032 21107 sgd_solver.cpp:106] Iteration 66750, lr = 0.0005
I0525 14:45:33.937068 21107 solver.cpp:237] Iteration 66900, loss = 1.2291
I0525 14:45:33.937239 21107 solver.cpp:253]     Train net output #0: loss = 1.2291 (* 1 = 1.2291 loss)
I0525 14:45:33.937252 21107 sgd_solver.cpp:106] Iteration 66900, lr = 0.0005
I0525 14:46:03.531364 21107 solver.cpp:237] Iteration 67050, loss = 1.16251
I0525 14:46:03.531414 21107 solver.cpp:253]     Train net output #0: loss = 1.16251 (* 1 = 1.16251 loss)
I0525 14:46:03.531429 21107 sgd_solver.cpp:106] Iteration 67050, lr = 0.0005
I0525 14:46:12.267370 21107 solver.cpp:237] Iteration 67200, loss = 1.01163
I0525 14:46:12.267563 21107 solver.cpp:253]     Train net output #0: loss = 1.01163 (* 1 = 1.01163 loss)
I0525 14:46:12.267577 21107 sgd_solver.cpp:106] Iteration 67200, lr = 0.0005
I0525 14:46:21.000977 21107 solver.cpp:237] Iteration 67350, loss = 1.31684
I0525 14:46:21.001011 21107 solver.cpp:253]     Train net output #0: loss = 1.31684 (* 1 = 1.31684 loss)
I0525 14:46:21.001026 21107 sgd_solver.cpp:106] Iteration 67350, lr = 0.0005
I0525 14:46:29.671691 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_67500.caffemodel
I0525 14:46:29.752282 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_67500.solverstate
I0525 14:46:29.797612 21107 solver.cpp:237] Iteration 67500, loss = 1.222
I0525 14:46:29.797658 21107 solver.cpp:253]     Train net output #0: loss = 1.222 (* 1 = 1.222 loss)
I0525 14:46:29.797677 21107 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I0525 14:46:38.530586 21107 solver.cpp:237] Iteration 67650, loss = 1.25981
I0525 14:46:38.530627 21107 solver.cpp:253]     Train net output #0: loss = 1.25981 (* 1 = 1.25981 loss)
I0525 14:46:38.530639 21107 sgd_solver.cpp:106] Iteration 67650, lr = 0.0005
I0525 14:46:47.266067 21107 solver.cpp:237] Iteration 67800, loss = 1.2543
I0525 14:46:47.266249 21107 solver.cpp:253]     Train net output #0: loss = 1.2543 (* 1 = 1.2543 loss)
I0525 14:46:47.266263 21107 sgd_solver.cpp:106] Iteration 67800, lr = 0.0005
I0525 14:46:55.998016 21107 solver.cpp:237] Iteration 67950, loss = 1.5015
I0525 14:46:55.998051 21107 solver.cpp:253]     Train net output #0: loss = 1.5015 (* 1 = 1.5015 loss)
I0525 14:46:55.998067 21107 sgd_solver.cpp:106] Iteration 67950, lr = 0.0005
I0525 14:47:25.597158 21107 solver.cpp:237] Iteration 68100, loss = 1.21432
I0525 14:47:25.597357 21107 solver.cpp:253]     Train net output #0: loss = 1.21432 (* 1 = 1.21432 loss)
I0525 14:47:25.597370 21107 sgd_solver.cpp:106] Iteration 68100, lr = 0.0005
I0525 14:47:34.331938 21107 solver.cpp:237] Iteration 68250, loss = 1.44283
I0525 14:47:34.331971 21107 solver.cpp:253]     Train net output #0: loss = 1.44283 (* 1 = 1.44283 loss)
I0525 14:47:34.331986 21107 sgd_solver.cpp:106] Iteration 68250, lr = 0.0005
I0525 14:47:43.063406 21107 solver.cpp:237] Iteration 68400, loss = 1.22991
I0525 14:47:43.063441 21107 solver.cpp:253]     Train net output #0: loss = 1.22991 (* 1 = 1.22991 loss)
I0525 14:47:43.063457 21107 sgd_solver.cpp:106] Iteration 68400, lr = 0.0005
I0525 14:47:51.797006 21107 solver.cpp:237] Iteration 68550, loss = 1.4024
I0525 14:47:51.797050 21107 solver.cpp:253]     Train net output #0: loss = 1.4024 (* 1 = 1.4024 loss)
I0525 14:47:51.797065 21107 sgd_solver.cpp:106] Iteration 68550, lr = 0.0005
I0525 14:48:00.531818 21107 solver.cpp:237] Iteration 68700, loss = 1.45927
I0525 14:48:00.532006 21107 solver.cpp:253]     Train net output #0: loss = 1.45927 (* 1 = 1.45927 loss)
I0525 14:48:00.532019 21107 sgd_solver.cpp:106] Iteration 68700, lr = 0.0005
I0525 14:48:09.265633 21107 solver.cpp:237] Iteration 68850, loss = 1.06222
I0525 14:48:09.265666 21107 solver.cpp:253]     Train net output #0: loss = 1.06222 (* 1 = 1.06222 loss)
I0525 14:48:09.265683 21107 sgd_solver.cpp:106] Iteration 68850, lr = 0.0005
I0525 14:48:17.943343 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_69000.caffemodel
I0525 14:48:18.021729 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_69000.solverstate
I0525 14:48:18.046756 21107 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 14:49:04.546545 21107 solver.cpp:409]     Test net output #0: accuracy = 0.850913
I0525 14:49:04.546736 21107 solver.cpp:409]     Test net output #1: loss = 0.531047 (* 1 = 0.531047 loss)
I0525 14:49:25.373914 21107 solver.cpp:237] Iteration 69000, loss = 1.35035
I0525 14:49:25.373965 21107 solver.cpp:253]     Train net output #0: loss = 1.35035 (* 1 = 1.35035 loss)
I0525 14:49:25.373981 21107 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I0525 14:49:34.109324 21107 solver.cpp:237] Iteration 69150, loss = 1.13223
I0525 14:49:34.109364 21107 solver.cpp:253]     Train net output #0: loss = 1.13223 (* 1 = 1.13223 loss)
I0525 14:49:34.109381 21107 sgd_solver.cpp:106] Iteration 69150, lr = 0.0005
I0525 14:49:42.843531 21107 solver.cpp:237] Iteration 69300, loss = 1.33429
I0525 14:49:42.843713 21107 solver.cpp:253]     Train net output #0: loss = 1.33429 (* 1 = 1.33429 loss)
I0525 14:49:42.843729 21107 sgd_solver.cpp:106] Iteration 69300, lr = 0.0005
I0525 14:49:51.588580 21107 solver.cpp:237] Iteration 69450, loss = 1.32587
I0525 14:49:51.588614 21107 solver.cpp:253]     Train net output #0: loss = 1.32587 (* 1 = 1.32587 loss)
I0525 14:49:51.588631 21107 sgd_solver.cpp:106] Iteration 69450, lr = 0.0005
I0525 14:50:00.339952 21107 solver.cpp:237] Iteration 69600, loss = 1.4402
I0525 14:50:00.339990 21107 solver.cpp:253]     Train net output #0: loss = 1.4402 (* 1 = 1.4402 loss)
I0525 14:50:00.340008 21107 sgd_solver.cpp:106] Iteration 69600, lr = 0.0005
I0525 14:50:09.077780 21107 solver.cpp:237] Iteration 69750, loss = 1.22246
I0525 14:50:09.077816 21107 solver.cpp:253]     Train net output #0: loss = 1.22246 (* 1 = 1.22246 loss)
I0525 14:50:09.077831 21107 sgd_solver.cpp:106] Iteration 69750, lr = 0.0005
I0525 14:50:17.821666 21107 solver.cpp:237] Iteration 69900, loss = 1.31354
I0525 14:50:17.821841 21107 solver.cpp:253]     Train net output #0: loss = 1.31354 (* 1 = 1.31354 loss)
I0525 14:50:17.821856 21107 sgd_solver.cpp:106] Iteration 69900, lr = 0.0005
I0525 14:50:47.400511 21107 solver.cpp:237] Iteration 70050, loss = 1.45284
I0525 14:50:47.400559 21107 solver.cpp:253]     Train net output #0: loss = 1.45284 (* 1 = 1.45284 loss)
I0525 14:50:47.400578 21107 sgd_solver.cpp:106] Iteration 70050, lr = 0.0005
I0525 14:50:56.139364 21107 solver.cpp:237] Iteration 70200, loss = 1.34672
I0525 14:50:56.139554 21107 solver.cpp:253]     Train net output #0: loss = 1.34672 (* 1 = 1.34672 loss)
I0525 14:50:56.139567 21107 sgd_solver.cpp:106] Iteration 70200, lr = 0.0005
I0525 14:51:04.875865 21107 solver.cpp:237] Iteration 70350, loss = 1.10338
I0525 14:51:04.875900 21107 solver.cpp:253]     Train net output #0: loss = 1.10338 (* 1 = 1.10338 loss)
I0525 14:51:04.875917 21107 sgd_solver.cpp:106] Iteration 70350, lr = 0.0005
I0525 14:51:13.559897 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_70500.caffemodel
I0525 14:51:13.647135 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_70500.solverstate
I0525 14:51:13.690207 21107 solver.cpp:237] Iteration 70500, loss = 1.29516
I0525 14:51:13.690253 21107 solver.cpp:253]     Train net output #0: loss = 1.29516 (* 1 = 1.29516 loss)
I0525 14:51:13.690265 21107 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I0525 14:51:22.432602 21107 solver.cpp:237] Iteration 70650, loss = 1.39738
I0525 14:51:22.432637 21107 solver.cpp:253]     Train net output #0: loss = 1.39738 (* 1 = 1.39738 loss)
I0525 14:51:22.432653 21107 sgd_solver.cpp:106] Iteration 70650, lr = 0.0005
I0525 14:51:31.165367 21107 solver.cpp:237] Iteration 70800, loss = 1.18427
I0525 14:51:31.165554 21107 solver.cpp:253]     Train net output #0: loss = 1.18427 (* 1 = 1.18427 loss)
I0525 14:51:31.165567 21107 sgd_solver.cpp:106] Iteration 70800, lr = 0.0005
I0525 14:51:39.900262 21107 solver.cpp:237] Iteration 70950, loss = 1.29661
I0525 14:51:39.900302 21107 solver.cpp:253]     Train net output #0: loss = 1.29661 (* 1 = 1.29661 loss)
I0525 14:51:39.900319 21107 sgd_solver.cpp:106] Iteration 70950, lr = 0.0005
I0525 14:52:09.504565 21107 solver.cpp:237] Iteration 71100, loss = 1.03302
I0525 14:52:09.504765 21107 solver.cpp:253]     Train net output #0: loss = 1.03302 (* 1 = 1.03302 loss)
I0525 14:52:09.504781 21107 sgd_solver.cpp:106] Iteration 71100, lr = 0.0005
I0525 14:52:18.245277 21107 solver.cpp:237] Iteration 71250, loss = 1.40513
I0525 14:52:18.245311 21107 solver.cpp:253]     Train net output #0: loss = 1.40513 (* 1 = 1.40513 loss)
I0525 14:52:18.245328 21107 sgd_solver.cpp:106] Iteration 71250, lr = 0.0005
I0525 14:52:26.981781 21107 solver.cpp:237] Iteration 71400, loss = 1.25969
I0525 14:52:26.981818 21107 solver.cpp:253]     Train net output #0: loss = 1.25969 (* 1 = 1.25969 loss)
I0525 14:52:26.981838 21107 sgd_solver.cpp:106] Iteration 71400, lr = 0.0005
I0525 14:52:35.722473 21107 solver.cpp:237] Iteration 71550, loss = 1.23226
I0525 14:52:35.722507 21107 solver.cpp:253]     Train net output #0: loss = 1.23226 (* 1 = 1.23226 loss)
I0525 14:52:35.722523 21107 sgd_solver.cpp:106] Iteration 71550, lr = 0.0005
I0525 14:52:44.460566 21107 solver.cpp:237] Iteration 71700, loss = 1.34425
I0525 14:52:44.460747 21107 solver.cpp:253]     Train net output #0: loss = 1.34425 (* 1 = 1.34425 loss)
I0525 14:52:44.460760 21107 sgd_solver.cpp:106] Iteration 71700, lr = 0.0005
I0525 14:52:53.201273 21107 solver.cpp:237] Iteration 71850, loss = 1.20169
I0525 14:52:53.201308 21107 solver.cpp:253]     Train net output #0: loss = 1.20169 (* 1 = 1.20169 loss)
I0525 14:52:53.201329 21107 sgd_solver.cpp:106] Iteration 71850, lr = 0.0005
I0525 14:53:01.888170 21107 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_72000.caffemodel
I0525 14:53:01.966668 21107 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0005_2016-05-20T15.49.23.973990_iter_72000.solverstate
I0525 14:53:01.991564 21107 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 14:54:09.700009 21107 solver.cpp:409]     Test net output #0: accuracy = 0.850599
I0525 14:54:09.700222 21107 solver.cpp:409]     Test net output #1: loss = 0.49081 (* 1 = 0.49081 loss)
I0525 14:54:30.566558 21107 solver.cpp:237] Iteration 72000, loss = 1.33256
I0525 14:54:30.566612 21107 solver.cpp:253]     Train net output #0: loss = 1.33256 (* 1 = 1.33256 loss)
I0525 14:54:30.566625 21107 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I0525 14:54:39.298569 21107 solver.cpp:237] Iteration 72150, loss = 1.32457
I0525 14:54:39.298604 21107 solver.cpp:253]     Train net output #0: loss = 1.32457 (* 1 = 1.32457 loss)
I0525 14:54:39.298620 21107 sgd_solver.cpp:106] Iteration 72150, lr = 0.0005
I0525 14:54:48.030926 21107 solver.cpp:237] Iteration 72300, loss = 1.19043
I0525 14:54:48.031116 21107 solver.cpp:253]     Train net output #0: loss = 1.19043 (* 1 = 1.19043 loss)
I0525 14:54:48.031134 21107 sgd_solver.cpp:106] Iteration 72300, lr = 0.0005
I0525 14:54:56.760861 21107 solver.cpp:237] Iteration 72450, loss = 1.36676
I0525 14:54:56.760902 21107 solver.cpp:253]     Train net output #0: loss = 1.36676 (* 1 = 1.36676 loss)
I0525 14:54:56.760920 21107 sgd_solver.cpp:106] Iteration 72450, lr = 0.0005
I0525 14:55:05.492866 21107 solver.cpp:237] Iteration 72600, loss = 1.25852
I0525 14:55:05.492900 21107 solver.cpp:253]     Train net output #0: loss = 1.25852 (* 1 = 1.25852 loss)
I0525 14:55:05.492915 21107 sgd_solver.cpp:106] Iteration 72600, lr = 0.0005
I0525 14:55:14.216478 21107 solver.cpp:237] Iteration 72750, loss = 1.43286
I0525 14:55:14.216513 21107 solver.cpp:253]     Train net output #0: loss = 1.43286 (* 1 = 1.43286 loss)
I0525 14:55:14.216529 21107 sgd_solver.cpp:106] Iteration 72750, lr = 0.0005
aprun: Apid 11264248: Caught signal Terminated, sending to application
*** Aborted at 1464202518 (unix time) try "date -d @1464202518" if you are using GNU date ***
PC: @     0x2aaab9276646 (unknown)
*** SIGTERM (@0x5270) received by PID 21107 (TID 0x2aaac746f900) from PID 21104; stack trace: ***
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab9276646 (unknown)
=>> PBS: job killed: walltime 7238 exceeded limit 7200
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
    @     0x2aaab928a408 (unknown)
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11264248: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
aprun: Apid 11264248: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03794] [c8-1c0s6n2] [Wed May 25 14:55:20 2016] PE RANK 0 exit signal Terminated
Application 11264248 exit codes: 143
Application 11264248 resources: utime ~6238s, stime ~991s, Rss ~5333168, inblocks ~16606063, outblocks ~740503
