2808699
I0523 16:20:18.338781 19131 caffe.cpp:184] Using GPUs 0
I0523 16:20:18.768265 19131 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.003
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928.prototxt"
I0523 16:20:18.769968 19131 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928.prototxt
I0523 16:20:18.789896 19131 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 16:20:18.789954 19131 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 16:20:18.790300 19131 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 16:20:18.790480 19131 layer_factory.hpp:77] Creating layer data_hdf5
I0523 16:20:18.790504 19131 net.cpp:106] Creating Layer data_hdf5
I0523 16:20:18.790518 19131 net.cpp:411] data_hdf5 -> data
I0523 16:20:18.790552 19131 net.cpp:411] data_hdf5 -> label
I0523 16:20:18.790585 19131 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 16:20:18.791875 19131 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 16:20:18.794121 19131 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 16:20:40.309299 19131 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 16:20:40.314499 19131 net.cpp:150] Setting up data_hdf5
I0523 16:20:40.314539 19131 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 16:20:40.314553 19131 net.cpp:157] Top shape: 60 (60)
I0523 16:20:40.314565 19131 net.cpp:165] Memory required for data: 1524240
I0523 16:20:40.314579 19131 layer_factory.hpp:77] Creating layer conv1
I0523 16:20:40.314612 19131 net.cpp:106] Creating Layer conv1
I0523 16:20:40.314623 19131 net.cpp:454] conv1 <- data
I0523 16:20:40.314645 19131 net.cpp:411] conv1 -> conv1
I0523 16:20:40.678630 19131 net.cpp:150] Setting up conv1
I0523 16:20:40.678674 19131 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:20:40.678685 19131 net.cpp:165] Memory required for data: 18113040
I0523 16:20:40.678725 19131 layer_factory.hpp:77] Creating layer relu1
I0523 16:20:40.678746 19131 net.cpp:106] Creating Layer relu1
I0523 16:20:40.678757 19131 net.cpp:454] relu1 <- conv1
I0523 16:20:40.678771 19131 net.cpp:397] relu1 -> conv1 (in-place)
I0523 16:20:40.679283 19131 net.cpp:150] Setting up relu1
I0523 16:20:40.679301 19131 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:20:40.679311 19131 net.cpp:165] Memory required for data: 34701840
I0523 16:20:40.679321 19131 layer_factory.hpp:77] Creating layer pool1
I0523 16:20:40.679337 19131 net.cpp:106] Creating Layer pool1
I0523 16:20:40.679347 19131 net.cpp:454] pool1 <- conv1
I0523 16:20:40.679359 19131 net.cpp:411] pool1 -> pool1
I0523 16:20:40.679438 19131 net.cpp:150] Setting up pool1
I0523 16:20:40.679452 19131 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 16:20:40.679462 19131 net.cpp:165] Memory required for data: 42996240
I0523 16:20:40.679471 19131 layer_factory.hpp:77] Creating layer conv2
I0523 16:20:40.679493 19131 net.cpp:106] Creating Layer conv2
I0523 16:20:40.679504 19131 net.cpp:454] conv2 <- pool1
I0523 16:20:40.679518 19131 net.cpp:411] conv2 -> conv2
I0523 16:20:40.682229 19131 net.cpp:150] Setting up conv2
I0523 16:20:40.682255 19131 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:20:40.682266 19131 net.cpp:165] Memory required for data: 54919440
I0523 16:20:40.682284 19131 layer_factory.hpp:77] Creating layer relu2
I0523 16:20:40.682299 19131 net.cpp:106] Creating Layer relu2
I0523 16:20:40.682309 19131 net.cpp:454] relu2 <- conv2
I0523 16:20:40.682322 19131 net.cpp:397] relu2 -> conv2 (in-place)
I0523 16:20:40.682651 19131 net.cpp:150] Setting up relu2
I0523 16:20:40.682665 19131 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:20:40.682677 19131 net.cpp:165] Memory required for data: 66842640
I0523 16:20:40.682687 19131 layer_factory.hpp:77] Creating layer pool2
I0523 16:20:40.682699 19131 net.cpp:106] Creating Layer pool2
I0523 16:20:40.682719 19131 net.cpp:454] pool2 <- conv2
I0523 16:20:40.682732 19131 net.cpp:411] pool2 -> pool2
I0523 16:20:40.682813 19131 net.cpp:150] Setting up pool2
I0523 16:20:40.682826 19131 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 16:20:40.682838 19131 net.cpp:165] Memory required for data: 72804240
I0523 16:20:40.682848 19131 layer_factory.hpp:77] Creating layer conv3
I0523 16:20:40.682867 19131 net.cpp:106] Creating Layer conv3
I0523 16:20:40.682878 19131 net.cpp:454] conv3 <- pool2
I0523 16:20:40.682893 19131 net.cpp:411] conv3 -> conv3
I0523 16:20:40.684914 19131 net.cpp:150] Setting up conv3
I0523 16:20:40.684933 19131 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:20:40.684944 19131 net.cpp:165] Memory required for data: 79309200
I0523 16:20:40.684962 19131 layer_factory.hpp:77] Creating layer relu3
I0523 16:20:40.684978 19131 net.cpp:106] Creating Layer relu3
I0523 16:20:40.684988 19131 net.cpp:454] relu3 <- conv3
I0523 16:20:40.685001 19131 net.cpp:397] relu3 -> conv3 (in-place)
I0523 16:20:40.685472 19131 net.cpp:150] Setting up relu3
I0523 16:20:40.685489 19131 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:20:40.685499 19131 net.cpp:165] Memory required for data: 85814160
I0523 16:20:40.685509 19131 layer_factory.hpp:77] Creating layer pool3
I0523 16:20:40.685523 19131 net.cpp:106] Creating Layer pool3
I0523 16:20:40.685534 19131 net.cpp:454] pool3 <- conv3
I0523 16:20:40.685545 19131 net.cpp:411] pool3 -> pool3
I0523 16:20:40.685613 19131 net.cpp:150] Setting up pool3
I0523 16:20:40.685627 19131 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 16:20:40.685636 19131 net.cpp:165] Memory required for data: 89066640
I0523 16:20:40.685647 19131 layer_factory.hpp:77] Creating layer conv4
I0523 16:20:40.685663 19131 net.cpp:106] Creating Layer conv4
I0523 16:20:40.685674 19131 net.cpp:454] conv4 <- pool3
I0523 16:20:40.685688 19131 net.cpp:411] conv4 -> conv4
I0523 16:20:40.688462 19131 net.cpp:150] Setting up conv4
I0523 16:20:40.688489 19131 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:20:40.688499 19131 net.cpp:165] Memory required for data: 91243920
I0523 16:20:40.688516 19131 layer_factory.hpp:77] Creating layer relu4
I0523 16:20:40.688531 19131 net.cpp:106] Creating Layer relu4
I0523 16:20:40.688542 19131 net.cpp:454] relu4 <- conv4
I0523 16:20:40.688555 19131 net.cpp:397] relu4 -> conv4 (in-place)
I0523 16:20:40.689030 19131 net.cpp:150] Setting up relu4
I0523 16:20:40.689046 19131 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:20:40.689057 19131 net.cpp:165] Memory required for data: 93421200
I0523 16:20:40.689067 19131 layer_factory.hpp:77] Creating layer pool4
I0523 16:20:40.689080 19131 net.cpp:106] Creating Layer pool4
I0523 16:20:40.689090 19131 net.cpp:454] pool4 <- conv4
I0523 16:20:40.689103 19131 net.cpp:411] pool4 -> pool4
I0523 16:20:40.689172 19131 net.cpp:150] Setting up pool4
I0523 16:20:40.689185 19131 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 16:20:40.689195 19131 net.cpp:165] Memory required for data: 94509840
I0523 16:20:40.689205 19131 layer_factory.hpp:77] Creating layer ip1
I0523 16:20:40.689224 19131 net.cpp:106] Creating Layer ip1
I0523 16:20:40.689234 19131 net.cpp:454] ip1 <- pool4
I0523 16:20:40.689247 19131 net.cpp:411] ip1 -> ip1
I0523 16:20:40.704658 19131 net.cpp:150] Setting up ip1
I0523 16:20:40.704681 19131 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:20:40.704692 19131 net.cpp:165] Memory required for data: 94556880
I0523 16:20:40.704715 19131 layer_factory.hpp:77] Creating layer relu5
I0523 16:20:40.704730 19131 net.cpp:106] Creating Layer relu5
I0523 16:20:40.704740 19131 net.cpp:454] relu5 <- ip1
I0523 16:20:40.704752 19131 net.cpp:397] relu5 -> ip1 (in-place)
I0523 16:20:40.705096 19131 net.cpp:150] Setting up relu5
I0523 16:20:40.705109 19131 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:20:40.705119 19131 net.cpp:165] Memory required for data: 94603920
I0523 16:20:40.705130 19131 layer_factory.hpp:77] Creating layer drop1
I0523 16:20:40.705152 19131 net.cpp:106] Creating Layer drop1
I0523 16:20:40.705162 19131 net.cpp:454] drop1 <- ip1
I0523 16:20:40.705174 19131 net.cpp:397] drop1 -> ip1 (in-place)
I0523 16:20:40.705234 19131 net.cpp:150] Setting up drop1
I0523 16:20:40.705246 19131 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:20:40.705256 19131 net.cpp:165] Memory required for data: 94650960
I0523 16:20:40.705266 19131 layer_factory.hpp:77] Creating layer ip2
I0523 16:20:40.705284 19131 net.cpp:106] Creating Layer ip2
I0523 16:20:40.705294 19131 net.cpp:454] ip2 <- ip1
I0523 16:20:40.705307 19131 net.cpp:411] ip2 -> ip2
I0523 16:20:40.705768 19131 net.cpp:150] Setting up ip2
I0523 16:20:40.705782 19131 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:20:40.705792 19131 net.cpp:165] Memory required for data: 94674480
I0523 16:20:40.705806 19131 layer_factory.hpp:77] Creating layer relu6
I0523 16:20:40.705819 19131 net.cpp:106] Creating Layer relu6
I0523 16:20:40.705829 19131 net.cpp:454] relu6 <- ip2
I0523 16:20:40.705842 19131 net.cpp:397] relu6 -> ip2 (in-place)
I0523 16:20:40.706360 19131 net.cpp:150] Setting up relu6
I0523 16:20:40.706377 19131 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:20:40.706387 19131 net.cpp:165] Memory required for data: 94698000
I0523 16:20:40.706398 19131 layer_factory.hpp:77] Creating layer drop2
I0523 16:20:40.706410 19131 net.cpp:106] Creating Layer drop2
I0523 16:20:40.706419 19131 net.cpp:454] drop2 <- ip2
I0523 16:20:40.706432 19131 net.cpp:397] drop2 -> ip2 (in-place)
I0523 16:20:40.706475 19131 net.cpp:150] Setting up drop2
I0523 16:20:40.706487 19131 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:20:40.706499 19131 net.cpp:165] Memory required for data: 94721520
I0523 16:20:40.706508 19131 layer_factory.hpp:77] Creating layer ip3
I0523 16:20:40.706522 19131 net.cpp:106] Creating Layer ip3
I0523 16:20:40.706532 19131 net.cpp:454] ip3 <- ip2
I0523 16:20:40.706544 19131 net.cpp:411] ip3 -> ip3
I0523 16:20:40.706763 19131 net.cpp:150] Setting up ip3
I0523 16:20:40.706776 19131 net.cpp:157] Top shape: 60 11 (660)
I0523 16:20:40.706786 19131 net.cpp:165] Memory required for data: 94724160
I0523 16:20:40.706801 19131 layer_factory.hpp:77] Creating layer drop3
I0523 16:20:40.706815 19131 net.cpp:106] Creating Layer drop3
I0523 16:20:40.706825 19131 net.cpp:454] drop3 <- ip3
I0523 16:20:40.706836 19131 net.cpp:397] drop3 -> ip3 (in-place)
I0523 16:20:40.706876 19131 net.cpp:150] Setting up drop3
I0523 16:20:40.706888 19131 net.cpp:157] Top shape: 60 11 (660)
I0523 16:20:40.706898 19131 net.cpp:165] Memory required for data: 94726800
I0523 16:20:40.706908 19131 layer_factory.hpp:77] Creating layer loss
I0523 16:20:40.706928 19131 net.cpp:106] Creating Layer loss
I0523 16:20:40.706936 19131 net.cpp:454] loss <- ip3
I0523 16:20:40.706948 19131 net.cpp:454] loss <- label
I0523 16:20:40.706960 19131 net.cpp:411] loss -> loss
I0523 16:20:40.706979 19131 layer_factory.hpp:77] Creating layer loss
I0523 16:20:40.707618 19131 net.cpp:150] Setting up loss
I0523 16:20:40.707639 19131 net.cpp:157] Top shape: (1)
I0523 16:20:40.707653 19131 net.cpp:160]     with loss weight 1
I0523 16:20:40.707695 19131 net.cpp:165] Memory required for data: 94726804
I0523 16:20:40.707705 19131 net.cpp:226] loss needs backward computation.
I0523 16:20:40.707716 19131 net.cpp:226] drop3 needs backward computation.
I0523 16:20:40.707726 19131 net.cpp:226] ip3 needs backward computation.
I0523 16:20:40.707739 19131 net.cpp:226] drop2 needs backward computation.
I0523 16:20:40.707748 19131 net.cpp:226] relu6 needs backward computation.
I0523 16:20:40.707758 19131 net.cpp:226] ip2 needs backward computation.
I0523 16:20:40.707768 19131 net.cpp:226] drop1 needs backward computation.
I0523 16:20:40.707778 19131 net.cpp:226] relu5 needs backward computation.
I0523 16:20:40.707788 19131 net.cpp:226] ip1 needs backward computation.
I0523 16:20:40.707798 19131 net.cpp:226] pool4 needs backward computation.
I0523 16:20:40.707808 19131 net.cpp:226] relu4 needs backward computation.
I0523 16:20:40.707818 19131 net.cpp:226] conv4 needs backward computation.
I0523 16:20:40.707828 19131 net.cpp:226] pool3 needs backward computation.
I0523 16:20:40.707839 19131 net.cpp:226] relu3 needs backward computation.
I0523 16:20:40.707849 19131 net.cpp:226] conv3 needs backward computation.
I0523 16:20:40.707869 19131 net.cpp:226] pool2 needs backward computation.
I0523 16:20:40.707880 19131 net.cpp:226] relu2 needs backward computation.
I0523 16:20:40.707890 19131 net.cpp:226] conv2 needs backward computation.
I0523 16:20:40.707901 19131 net.cpp:226] pool1 needs backward computation.
I0523 16:20:40.707911 19131 net.cpp:226] relu1 needs backward computation.
I0523 16:20:40.707921 19131 net.cpp:226] conv1 needs backward computation.
I0523 16:20:40.707932 19131 net.cpp:228] data_hdf5 does not need backward computation.
I0523 16:20:40.707942 19131 net.cpp:270] This network produces output loss
I0523 16:20:40.707967 19131 net.cpp:283] Network initialization done.
I0523 16:20:40.709694 19131 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928.prototxt
I0523 16:20:40.709765 19131 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 16:20:40.710120 19131 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 16:20:40.710309 19131 layer_factory.hpp:77] Creating layer data_hdf5
I0523 16:20:40.710325 19131 net.cpp:106] Creating Layer data_hdf5
I0523 16:20:40.710338 19131 net.cpp:411] data_hdf5 -> data
I0523 16:20:40.710355 19131 net.cpp:411] data_hdf5 -> label
I0523 16:20:40.710371 19131 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 16:20:40.711781 19131 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 16:21:02.040532 19131 net.cpp:150] Setting up data_hdf5
I0523 16:21:02.040699 19131 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 16:21:02.040712 19131 net.cpp:157] Top shape: 60 (60)
I0523 16:21:02.040724 19131 net.cpp:165] Memory required for data: 1524240
I0523 16:21:02.040738 19131 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 16:21:02.040766 19131 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 16:21:02.040777 19131 net.cpp:454] label_data_hdf5_1_split <- label
I0523 16:21:02.040792 19131 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 16:21:02.040813 19131 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 16:21:02.040885 19131 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 16:21:02.040899 19131 net.cpp:157] Top shape: 60 (60)
I0523 16:21:02.040911 19131 net.cpp:157] Top shape: 60 (60)
I0523 16:21:02.040920 19131 net.cpp:165] Memory required for data: 1524720
I0523 16:21:02.040930 19131 layer_factory.hpp:77] Creating layer conv1
I0523 16:21:02.040952 19131 net.cpp:106] Creating Layer conv1
I0523 16:21:02.040964 19131 net.cpp:454] conv1 <- data
I0523 16:21:02.040978 19131 net.cpp:411] conv1 -> conv1
I0523 16:21:02.042929 19131 net.cpp:150] Setting up conv1
I0523 16:21:02.042953 19131 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:21:02.042965 19131 net.cpp:165] Memory required for data: 18113520
I0523 16:21:02.042986 19131 layer_factory.hpp:77] Creating layer relu1
I0523 16:21:02.043001 19131 net.cpp:106] Creating Layer relu1
I0523 16:21:02.043011 19131 net.cpp:454] relu1 <- conv1
I0523 16:21:02.043025 19131 net.cpp:397] relu1 -> conv1 (in-place)
I0523 16:21:02.043524 19131 net.cpp:150] Setting up relu1
I0523 16:21:02.043540 19131 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 16:21:02.043550 19131 net.cpp:165] Memory required for data: 34702320
I0523 16:21:02.043560 19131 layer_factory.hpp:77] Creating layer pool1
I0523 16:21:02.043576 19131 net.cpp:106] Creating Layer pool1
I0523 16:21:02.043586 19131 net.cpp:454] pool1 <- conv1
I0523 16:21:02.043599 19131 net.cpp:411] pool1 -> pool1
I0523 16:21:02.043674 19131 net.cpp:150] Setting up pool1
I0523 16:21:02.043687 19131 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 16:21:02.043697 19131 net.cpp:165] Memory required for data: 42996720
I0523 16:21:02.043707 19131 layer_factory.hpp:77] Creating layer conv2
I0523 16:21:02.043723 19131 net.cpp:106] Creating Layer conv2
I0523 16:21:02.043735 19131 net.cpp:454] conv2 <- pool1
I0523 16:21:02.043748 19131 net.cpp:411] conv2 -> conv2
I0523 16:21:02.045660 19131 net.cpp:150] Setting up conv2
I0523 16:21:02.045682 19131 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:21:02.045694 19131 net.cpp:165] Memory required for data: 54919920
I0523 16:21:02.045712 19131 layer_factory.hpp:77] Creating layer relu2
I0523 16:21:02.045727 19131 net.cpp:106] Creating Layer relu2
I0523 16:21:02.045737 19131 net.cpp:454] relu2 <- conv2
I0523 16:21:02.045748 19131 net.cpp:397] relu2 -> conv2 (in-place)
I0523 16:21:02.046079 19131 net.cpp:150] Setting up relu2
I0523 16:21:02.046093 19131 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 16:21:02.046103 19131 net.cpp:165] Memory required for data: 66843120
I0523 16:21:02.046114 19131 layer_factory.hpp:77] Creating layer pool2
I0523 16:21:02.046128 19131 net.cpp:106] Creating Layer pool2
I0523 16:21:02.046138 19131 net.cpp:454] pool2 <- conv2
I0523 16:21:02.046150 19131 net.cpp:411] pool2 -> pool2
I0523 16:21:02.046222 19131 net.cpp:150] Setting up pool2
I0523 16:21:02.046236 19131 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 16:21:02.046244 19131 net.cpp:165] Memory required for data: 72804720
I0523 16:21:02.046255 19131 layer_factory.hpp:77] Creating layer conv3
I0523 16:21:02.046274 19131 net.cpp:106] Creating Layer conv3
I0523 16:21:02.046285 19131 net.cpp:454] conv3 <- pool2
I0523 16:21:02.046298 19131 net.cpp:411] conv3 -> conv3
I0523 16:21:02.048275 19131 net.cpp:150] Setting up conv3
I0523 16:21:02.048300 19131 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:21:02.048310 19131 net.cpp:165] Memory required for data: 79309680
I0523 16:21:02.048341 19131 layer_factory.hpp:77] Creating layer relu3
I0523 16:21:02.048354 19131 net.cpp:106] Creating Layer relu3
I0523 16:21:02.048364 19131 net.cpp:454] relu3 <- conv3
I0523 16:21:02.048377 19131 net.cpp:397] relu3 -> conv3 (in-place)
I0523 16:21:02.048848 19131 net.cpp:150] Setting up relu3
I0523 16:21:02.048866 19131 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 16:21:02.048876 19131 net.cpp:165] Memory required for data: 85814640
I0523 16:21:02.048885 19131 layer_factory.hpp:77] Creating layer pool3
I0523 16:21:02.048899 19131 net.cpp:106] Creating Layer pool3
I0523 16:21:02.048909 19131 net.cpp:454] pool3 <- conv3
I0523 16:21:02.048923 19131 net.cpp:411] pool3 -> pool3
I0523 16:21:02.048993 19131 net.cpp:150] Setting up pool3
I0523 16:21:02.049007 19131 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 16:21:02.049016 19131 net.cpp:165] Memory required for data: 89067120
I0523 16:21:02.049026 19131 layer_factory.hpp:77] Creating layer conv4
I0523 16:21:02.049042 19131 net.cpp:106] Creating Layer conv4
I0523 16:21:02.049052 19131 net.cpp:454] conv4 <- pool3
I0523 16:21:02.049067 19131 net.cpp:411] conv4 -> conv4
I0523 16:21:02.051131 19131 net.cpp:150] Setting up conv4
I0523 16:21:02.051153 19131 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:21:02.051167 19131 net.cpp:165] Memory required for data: 91244400
I0523 16:21:02.051182 19131 layer_factory.hpp:77] Creating layer relu4
I0523 16:21:02.051195 19131 net.cpp:106] Creating Layer relu4
I0523 16:21:02.051205 19131 net.cpp:454] relu4 <- conv4
I0523 16:21:02.051218 19131 net.cpp:397] relu4 -> conv4 (in-place)
I0523 16:21:02.051688 19131 net.cpp:150] Setting up relu4
I0523 16:21:02.051704 19131 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 16:21:02.051714 19131 net.cpp:165] Memory required for data: 93421680
I0523 16:21:02.051724 19131 layer_factory.hpp:77] Creating layer pool4
I0523 16:21:02.051738 19131 net.cpp:106] Creating Layer pool4
I0523 16:21:02.051748 19131 net.cpp:454] pool4 <- conv4
I0523 16:21:02.051760 19131 net.cpp:411] pool4 -> pool4
I0523 16:21:02.051831 19131 net.cpp:150] Setting up pool4
I0523 16:21:02.051844 19131 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 16:21:02.051853 19131 net.cpp:165] Memory required for data: 94510320
I0523 16:21:02.051863 19131 layer_factory.hpp:77] Creating layer ip1
I0523 16:21:02.051878 19131 net.cpp:106] Creating Layer ip1
I0523 16:21:02.051889 19131 net.cpp:454] ip1 <- pool4
I0523 16:21:02.051903 19131 net.cpp:411] ip1 -> ip1
I0523 16:21:02.067332 19131 net.cpp:150] Setting up ip1
I0523 16:21:02.067361 19131 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:21:02.067373 19131 net.cpp:165] Memory required for data: 94557360
I0523 16:21:02.067394 19131 layer_factory.hpp:77] Creating layer relu5
I0523 16:21:02.067409 19131 net.cpp:106] Creating Layer relu5
I0523 16:21:02.067420 19131 net.cpp:454] relu5 <- ip1
I0523 16:21:02.067433 19131 net.cpp:397] relu5 -> ip1 (in-place)
I0523 16:21:02.067780 19131 net.cpp:150] Setting up relu5
I0523 16:21:02.067793 19131 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:21:02.067802 19131 net.cpp:165] Memory required for data: 94604400
I0523 16:21:02.067813 19131 layer_factory.hpp:77] Creating layer drop1
I0523 16:21:02.067831 19131 net.cpp:106] Creating Layer drop1
I0523 16:21:02.067842 19131 net.cpp:454] drop1 <- ip1
I0523 16:21:02.067854 19131 net.cpp:397] drop1 -> ip1 (in-place)
I0523 16:21:02.067899 19131 net.cpp:150] Setting up drop1
I0523 16:21:02.067912 19131 net.cpp:157] Top shape: 60 196 (11760)
I0523 16:21:02.067921 19131 net.cpp:165] Memory required for data: 94651440
I0523 16:21:02.067931 19131 layer_factory.hpp:77] Creating layer ip2
I0523 16:21:02.067945 19131 net.cpp:106] Creating Layer ip2
I0523 16:21:02.067955 19131 net.cpp:454] ip2 <- ip1
I0523 16:21:02.067970 19131 net.cpp:411] ip2 -> ip2
I0523 16:21:02.068447 19131 net.cpp:150] Setting up ip2
I0523 16:21:02.068460 19131 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:21:02.068470 19131 net.cpp:165] Memory required for data: 94674960
I0523 16:21:02.068486 19131 layer_factory.hpp:77] Creating layer relu6
I0523 16:21:02.068511 19131 net.cpp:106] Creating Layer relu6
I0523 16:21:02.068521 19131 net.cpp:454] relu6 <- ip2
I0523 16:21:02.068534 19131 net.cpp:397] relu6 -> ip2 (in-place)
I0523 16:21:02.069067 19131 net.cpp:150] Setting up relu6
I0523 16:21:02.069083 19131 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:21:02.069095 19131 net.cpp:165] Memory required for data: 94698480
I0523 16:21:02.069105 19131 layer_factory.hpp:77] Creating layer drop2
I0523 16:21:02.069119 19131 net.cpp:106] Creating Layer drop2
I0523 16:21:02.069129 19131 net.cpp:454] drop2 <- ip2
I0523 16:21:02.069141 19131 net.cpp:397] drop2 -> ip2 (in-place)
I0523 16:21:02.069185 19131 net.cpp:150] Setting up drop2
I0523 16:21:02.069198 19131 net.cpp:157] Top shape: 60 98 (5880)
I0523 16:21:02.069208 19131 net.cpp:165] Memory required for data: 94722000
I0523 16:21:02.069218 19131 layer_factory.hpp:77] Creating layer ip3
I0523 16:21:02.069232 19131 net.cpp:106] Creating Layer ip3
I0523 16:21:02.069242 19131 net.cpp:454] ip3 <- ip2
I0523 16:21:02.069257 19131 net.cpp:411] ip3 -> ip3
I0523 16:21:02.069478 19131 net.cpp:150] Setting up ip3
I0523 16:21:02.069491 19131 net.cpp:157] Top shape: 60 11 (660)
I0523 16:21:02.069501 19131 net.cpp:165] Memory required for data: 94724640
I0523 16:21:02.069516 19131 layer_factory.hpp:77] Creating layer drop3
I0523 16:21:02.069530 19131 net.cpp:106] Creating Layer drop3
I0523 16:21:02.069540 19131 net.cpp:454] drop3 <- ip3
I0523 16:21:02.069552 19131 net.cpp:397] drop3 -> ip3 (in-place)
I0523 16:21:02.069593 19131 net.cpp:150] Setting up drop3
I0523 16:21:02.069607 19131 net.cpp:157] Top shape: 60 11 (660)
I0523 16:21:02.069615 19131 net.cpp:165] Memory required for data: 94727280
I0523 16:21:02.069625 19131 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 16:21:02.069638 19131 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 16:21:02.069648 19131 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 16:21:02.069661 19131 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 16:21:02.069676 19131 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 16:21:02.069749 19131 net.cpp:150] Setting up ip3_drop3_0_split
I0523 16:21:02.069762 19131 net.cpp:157] Top shape: 60 11 (660)
I0523 16:21:02.069774 19131 net.cpp:157] Top shape: 60 11 (660)
I0523 16:21:02.069784 19131 net.cpp:165] Memory required for data: 94732560
I0523 16:21:02.069794 19131 layer_factory.hpp:77] Creating layer accuracy
I0523 16:21:02.069816 19131 net.cpp:106] Creating Layer accuracy
I0523 16:21:02.069826 19131 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 16:21:02.069838 19131 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 16:21:02.069851 19131 net.cpp:411] accuracy -> accuracy
I0523 16:21:02.069875 19131 net.cpp:150] Setting up accuracy
I0523 16:21:02.069887 19131 net.cpp:157] Top shape: (1)
I0523 16:21:02.069897 19131 net.cpp:165] Memory required for data: 94732564
I0523 16:21:02.069908 19131 layer_factory.hpp:77] Creating layer loss
I0523 16:21:02.069922 19131 net.cpp:106] Creating Layer loss
I0523 16:21:02.069932 19131 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 16:21:02.069943 19131 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 16:21:02.069957 19131 net.cpp:411] loss -> loss
I0523 16:21:02.069975 19131 layer_factory.hpp:77] Creating layer loss
I0523 16:21:02.070461 19131 net.cpp:150] Setting up loss
I0523 16:21:02.070475 19131 net.cpp:157] Top shape: (1)
I0523 16:21:02.070485 19131 net.cpp:160]     with loss weight 1
I0523 16:21:02.070503 19131 net.cpp:165] Memory required for data: 94732568
I0523 16:21:02.070514 19131 net.cpp:226] loss needs backward computation.
I0523 16:21:02.070525 19131 net.cpp:228] accuracy does not need backward computation.
I0523 16:21:02.070536 19131 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 16:21:02.070546 19131 net.cpp:226] drop3 needs backward computation.
I0523 16:21:02.070555 19131 net.cpp:226] ip3 needs backward computation.
I0523 16:21:02.070565 19131 net.cpp:226] drop2 needs backward computation.
I0523 16:21:02.070575 19131 net.cpp:226] relu6 needs backward computation.
I0523 16:21:02.070592 19131 net.cpp:226] ip2 needs backward computation.
I0523 16:21:02.070603 19131 net.cpp:226] drop1 needs backward computation.
I0523 16:21:02.070612 19131 net.cpp:226] relu5 needs backward computation.
I0523 16:21:02.070622 19131 net.cpp:226] ip1 needs backward computation.
I0523 16:21:02.070632 19131 net.cpp:226] pool4 needs backward computation.
I0523 16:21:02.070642 19131 net.cpp:226] relu4 needs backward computation.
I0523 16:21:02.070652 19131 net.cpp:226] conv4 needs backward computation.
I0523 16:21:02.070660 19131 net.cpp:226] pool3 needs backward computation.
I0523 16:21:02.070672 19131 net.cpp:226] relu3 needs backward computation.
I0523 16:21:02.070682 19131 net.cpp:226] conv3 needs backward computation.
I0523 16:21:02.070693 19131 net.cpp:226] pool2 needs backward computation.
I0523 16:21:02.070711 19131 net.cpp:226] relu2 needs backward computation.
I0523 16:21:02.070721 19131 net.cpp:226] conv2 needs backward computation.
I0523 16:21:02.070731 19131 net.cpp:226] pool1 needs backward computation.
I0523 16:21:02.070742 19131 net.cpp:226] relu1 needs backward computation.
I0523 16:21:02.070752 19131 net.cpp:226] conv1 needs backward computation.
I0523 16:21:02.070765 19131 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 16:21:02.070776 19131 net.cpp:228] data_hdf5 does not need backward computation.
I0523 16:21:02.070786 19131 net.cpp:270] This network produces output accuracy
I0523 16:21:02.070797 19131 net.cpp:270] This network produces output loss
I0523 16:21:02.070827 19131 net.cpp:283] Network initialization done.
I0523 16:21:02.070958 19131 solver.cpp:60] Solver scaffolding done.
I0523 16:21:02.072088 19131 caffe.cpp:212] Starting Optimization
I0523 16:21:02.072106 19131 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 16:21:02.072119 19131 solver.cpp:289] Learning Rate Policy: fixed
I0523 16:21:02.073331 19131 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 16:21:50.247267 19131 solver.cpp:409]     Test net output #0: accuracy = 0.114287
I0523 16:21:50.247426 19131 solver.cpp:409]     Test net output #1: loss = 2.39766 (* 1 = 2.39766 loss)
I0523 16:21:50.273434 19131 solver.cpp:237] Iteration 0, loss = 2.40239
I0523 16:21:50.273470 19131 solver.cpp:253]     Train net output #0: loss = 2.40239 (* 1 = 2.40239 loss)
I0523 16:21:50.273488 19131 sgd_solver.cpp:106] Iteration 0, lr = 0.003
I0523 16:21:59.388912 19131 solver.cpp:237] Iteration 250, loss = 2.23647
I0523 16:21:59.388948 19131 solver.cpp:253]     Train net output #0: loss = 2.23647 (* 1 = 2.23647 loss)
I0523 16:21:59.388965 19131 sgd_solver.cpp:106] Iteration 250, lr = 0.003
I0523 16:22:08.492468 19131 solver.cpp:237] Iteration 500, loss = 2.03349
I0523 16:22:08.492504 19131 solver.cpp:253]     Train net output #0: loss = 2.03349 (* 1 = 2.03349 loss)
I0523 16:22:08.492521 19131 sgd_solver.cpp:106] Iteration 500, lr = 0.003
I0523 16:22:17.604467 19131 solver.cpp:237] Iteration 750, loss = 1.93654
I0523 16:22:17.604513 19131 solver.cpp:253]     Train net output #0: loss = 1.93654 (* 1 = 1.93654 loss)
I0523 16:22:17.604532 19131 sgd_solver.cpp:106] Iteration 750, lr = 0.003
I0523 16:22:26.698972 19131 solver.cpp:237] Iteration 1000, loss = 1.7221
I0523 16:22:26.699120 19131 solver.cpp:253]     Train net output #0: loss = 1.7221 (* 1 = 1.7221 loss)
I0523 16:22:26.699134 19131 sgd_solver.cpp:106] Iteration 1000, lr = 0.003
I0523 16:22:35.814350 19131 solver.cpp:237] Iteration 1250, loss = 1.85029
I0523 16:22:35.814386 19131 solver.cpp:253]     Train net output #0: loss = 1.85029 (* 1 = 1.85029 loss)
I0523 16:22:35.814401 19131 sgd_solver.cpp:106] Iteration 1250, lr = 0.003
I0523 16:22:44.915422 19131 solver.cpp:237] Iteration 1500, loss = 1.64561
I0523 16:22:44.915465 19131 solver.cpp:253]     Train net output #0: loss = 1.64561 (* 1 = 1.64561 loss)
I0523 16:22:44.915482 19131 sgd_solver.cpp:106] Iteration 1500, lr = 0.003
I0523 16:23:16.096379 19131 solver.cpp:237] Iteration 1750, loss = 1.84866
I0523 16:23:16.096544 19131 solver.cpp:253]     Train net output #0: loss = 1.84866 (* 1 = 1.84866 loss)
I0523 16:23:16.096560 19131 sgd_solver.cpp:106] Iteration 1750, lr = 0.003
I0523 16:23:25.197196 19131 solver.cpp:237] Iteration 2000, loss = 1.39666
I0523 16:23:25.197230 19131 solver.cpp:253]     Train net output #0: loss = 1.39666 (* 1 = 1.39666 loss)
I0523 16:23:25.197247 19131 sgd_solver.cpp:106] Iteration 2000, lr = 0.003
I0523 16:23:34.303530 19131 solver.cpp:237] Iteration 2250, loss = 1.84198
I0523 16:23:34.303578 19131 solver.cpp:253]     Train net output #0: loss = 1.84198 (* 1 = 1.84198 loss)
I0523 16:23:34.303596 19131 sgd_solver.cpp:106] Iteration 2250, lr = 0.003
I0523 16:23:43.379154 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_2500.caffemodel
I0523 16:23:43.444854 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_2500.solverstate
I0523 16:23:43.481565 19131 solver.cpp:237] Iteration 2500, loss = 1.57734
I0523 16:23:43.481605 19131 solver.cpp:253]     Train net output #0: loss = 1.57734 (* 1 = 1.57734 loss)
I0523 16:23:43.481622 19131 sgd_solver.cpp:106] Iteration 2500, lr = 0.003
I0523 16:23:52.587884 19131 solver.cpp:237] Iteration 2750, loss = 1.50404
I0523 16:23:52.588024 19131 solver.cpp:253]     Train net output #0: loss = 1.50404 (* 1 = 1.50404 loss)
I0523 16:23:52.588038 19131 sgd_solver.cpp:106] Iteration 2750, lr = 0.003
I0523 16:24:01.689376 19131 solver.cpp:237] Iteration 3000, loss = 1.30985
I0523 16:24:01.689419 19131 solver.cpp:253]     Train net output #0: loss = 1.30985 (* 1 = 1.30985 loss)
I0523 16:24:01.689435 19131 sgd_solver.cpp:106] Iteration 3000, lr = 0.003
I0523 16:24:10.790895 19131 solver.cpp:237] Iteration 3250, loss = 1.41089
I0523 16:24:10.790931 19131 solver.cpp:253]     Train net output #0: loss = 1.41089 (* 1 = 1.41089 loss)
I0523 16:24:10.790948 19131 sgd_solver.cpp:106] Iteration 3250, lr = 0.003
I0523 16:24:41.994424 19131 solver.cpp:237] Iteration 3500, loss = 1.32221
I0523 16:24:41.994582 19131 solver.cpp:253]     Train net output #0: loss = 1.32221 (* 1 = 1.32221 loss)
I0523 16:24:41.994596 19131 sgd_solver.cpp:106] Iteration 3500, lr = 0.003
I0523 16:24:51.105482 19131 solver.cpp:237] Iteration 3750, loss = 1.50748
I0523 16:24:51.105525 19131 solver.cpp:253]     Train net output #0: loss = 1.50748 (* 1 = 1.50748 loss)
I0523 16:24:51.105542 19131 sgd_solver.cpp:106] Iteration 3750, lr = 0.003
I0523 16:25:00.218837 19131 solver.cpp:237] Iteration 4000, loss = 1.77911
I0523 16:25:00.218871 19131 solver.cpp:253]     Train net output #0: loss = 1.77911 (* 1 = 1.77911 loss)
I0523 16:25:00.218888 19131 sgd_solver.cpp:106] Iteration 4000, lr = 0.003
I0523 16:25:09.328805 19131 solver.cpp:237] Iteration 4250, loss = 1.48085
I0523 16:25:09.328842 19131 solver.cpp:253]     Train net output #0: loss = 1.48085 (* 1 = 1.48085 loss)
I0523 16:25:09.328858 19131 sgd_solver.cpp:106] Iteration 4250, lr = 0.003
I0523 16:25:18.439244 19131 solver.cpp:237] Iteration 4500, loss = 1.74403
I0523 16:25:18.439393 19131 solver.cpp:253]     Train net output #0: loss = 1.74403 (* 1 = 1.74403 loss)
I0523 16:25:18.439407 19131 sgd_solver.cpp:106] Iteration 4500, lr = 0.003
I0523 16:25:27.541980 19131 solver.cpp:237] Iteration 4750, loss = 1.40022
I0523 16:25:27.542016 19131 solver.cpp:253]     Train net output #0: loss = 1.40022 (* 1 = 1.40022 loss)
I0523 16:25:27.542032 19131 sgd_solver.cpp:106] Iteration 4750, lr = 0.003
I0523 16:25:36.622418 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_5000.caffemodel
I0523 16:25:36.686048 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_5000.solverstate
I0523 16:25:36.711552 19131 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 16:26:23.996052 19131 solver.cpp:409]     Test net output #0: accuracy = 0.790096
I0523 16:26:23.996201 19131 solver.cpp:409]     Test net output #1: loss = 0.731202 (* 1 = 0.731202 loss)
I0523 16:26:46.121476 19131 solver.cpp:237] Iteration 5000, loss = 1.49237
I0523 16:26:46.121527 19131 solver.cpp:253]     Train net output #0: loss = 1.49237 (* 1 = 1.49237 loss)
I0523 16:26:46.121546 19131 sgd_solver.cpp:106] Iteration 5000, lr = 0.003
I0523 16:26:55.193876 19131 solver.cpp:237] Iteration 5250, loss = 1.43498
I0523 16:26:55.194028 19131 solver.cpp:253]     Train net output #0: loss = 1.43498 (* 1 = 1.43498 loss)
I0523 16:26:55.194042 19131 sgd_solver.cpp:106] Iteration 5250, lr = 0.003
I0523 16:27:04.267611 19131 solver.cpp:237] Iteration 5500, loss = 1.37324
I0523 16:27:04.267647 19131 solver.cpp:253]     Train net output #0: loss = 1.37324 (* 1 = 1.37324 loss)
I0523 16:27:04.267663 19131 sgd_solver.cpp:106] Iteration 5500, lr = 0.003
I0523 16:27:13.341886 19131 solver.cpp:237] Iteration 5750, loss = 1.25669
I0523 16:27:13.341922 19131 solver.cpp:253]     Train net output #0: loss = 1.25669 (* 1 = 1.25669 loss)
I0523 16:27:13.341938 19131 sgd_solver.cpp:106] Iteration 5750, lr = 0.003
I0523 16:27:22.419744 19131 solver.cpp:237] Iteration 6000, loss = 1.43631
I0523 16:27:22.419791 19131 solver.cpp:253]     Train net output #0: loss = 1.43631 (* 1 = 1.43631 loss)
I0523 16:27:22.419806 19131 sgd_solver.cpp:106] Iteration 6000, lr = 0.003
I0523 16:27:31.488004 19131 solver.cpp:237] Iteration 6250, loss = 1.65399
I0523 16:27:31.488142 19131 solver.cpp:253]     Train net output #0: loss = 1.65399 (* 1 = 1.65399 loss)
I0523 16:27:31.488157 19131 sgd_solver.cpp:106] Iteration 6250, lr = 0.003
I0523 16:27:40.563329 19131 solver.cpp:237] Iteration 6500, loss = 1.56733
I0523 16:27:40.563379 19131 solver.cpp:253]     Train net output #0: loss = 1.56733 (* 1 = 1.56733 loss)
I0523 16:27:40.563395 19131 sgd_solver.cpp:106] Iteration 6500, lr = 0.003
I0523 16:28:11.772967 19131 solver.cpp:237] Iteration 6750, loss = 1.43527
I0523 16:28:11.773126 19131 solver.cpp:253]     Train net output #0: loss = 1.43527 (* 1 = 1.43527 loss)
I0523 16:28:11.773140 19131 sgd_solver.cpp:106] Iteration 6750, lr = 0.003
I0523 16:28:20.839570 19131 solver.cpp:237] Iteration 7000, loss = 1.19226
I0523 16:28:20.839606 19131 solver.cpp:253]     Train net output #0: loss = 1.19226 (* 1 = 1.19226 loss)
I0523 16:28:20.839622 19131 sgd_solver.cpp:106] Iteration 7000, lr = 0.003
I0523 16:28:29.914657 19131 solver.cpp:237] Iteration 7250, loss = 1.38534
I0523 16:28:29.914711 19131 solver.cpp:253]     Train net output #0: loss = 1.38534 (* 1 = 1.38534 loss)
I0523 16:28:29.914726 19131 sgd_solver.cpp:106] Iteration 7250, lr = 0.003
I0523 16:28:38.943799 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_7500.caffemodel
I0523 16:28:39.009618 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_7500.solverstate
I0523 16:28:39.048897 19131 solver.cpp:237] Iteration 7500, loss = 1.34528
I0523 16:28:39.048948 19131 solver.cpp:253]     Train net output #0: loss = 1.34528 (* 1 = 1.34528 loss)
I0523 16:28:39.048964 19131 sgd_solver.cpp:106] Iteration 7500, lr = 0.003
I0523 16:28:48.123590 19131 solver.cpp:237] Iteration 7750, loss = 1.27963
I0523 16:28:48.123754 19131 solver.cpp:253]     Train net output #0: loss = 1.27963 (* 1 = 1.27963 loss)
I0523 16:28:48.123767 19131 sgd_solver.cpp:106] Iteration 7750, lr = 0.003
I0523 16:28:57.204435 19131 solver.cpp:237] Iteration 8000, loss = 1.44513
I0523 16:28:57.204475 19131 solver.cpp:253]     Train net output #0: loss = 1.44513 (* 1 = 1.44513 loss)
I0523 16:28:57.204498 19131 sgd_solver.cpp:106] Iteration 8000, lr = 0.003
I0523 16:29:06.278127 19131 solver.cpp:237] Iteration 8250, loss = 1.41584
I0523 16:29:06.278163 19131 solver.cpp:253]     Train net output #0: loss = 1.41584 (* 1 = 1.41584 loss)
I0523 16:29:06.278180 19131 sgd_solver.cpp:106] Iteration 8250, lr = 0.003
I0523 16:29:37.529388 19131 solver.cpp:237] Iteration 8500, loss = 1.36406
I0523 16:29:37.529549 19131 solver.cpp:253]     Train net output #0: loss = 1.36406 (* 1 = 1.36406 loss)
I0523 16:29:37.529564 19131 sgd_solver.cpp:106] Iteration 8500, lr = 0.003
I0523 16:29:46.600697 19131 solver.cpp:237] Iteration 8750, loss = 1.39167
I0523 16:29:46.600745 19131 solver.cpp:253]     Train net output #0: loss = 1.39167 (* 1 = 1.39167 loss)
I0523 16:29:46.600761 19131 sgd_solver.cpp:106] Iteration 8750, lr = 0.003
I0523 16:29:55.668004 19131 solver.cpp:237] Iteration 9000, loss = 1.28083
I0523 16:29:55.668040 19131 solver.cpp:253]     Train net output #0: loss = 1.28083 (* 1 = 1.28083 loss)
I0523 16:29:55.668056 19131 sgd_solver.cpp:106] Iteration 9000, lr = 0.003
I0523 16:30:04.745290 19131 solver.cpp:237] Iteration 9250, loss = 1.41833
I0523 16:30:04.745326 19131 solver.cpp:253]     Train net output #0: loss = 1.41833 (* 1 = 1.41833 loss)
I0523 16:30:04.745342 19131 sgd_solver.cpp:106] Iteration 9250, lr = 0.003
I0523 16:30:13.818984 19131 solver.cpp:237] Iteration 9500, loss = 1.47625
I0523 16:30:13.819128 19131 solver.cpp:253]     Train net output #0: loss = 1.47625 (* 1 = 1.47625 loss)
I0523 16:30:13.819141 19131 sgd_solver.cpp:106] Iteration 9500, lr = 0.003
I0523 16:30:22.891371 19131 solver.cpp:237] Iteration 9750, loss = 1.15189
I0523 16:30:22.891404 19131 solver.cpp:253]     Train net output #0: loss = 1.15189 (* 1 = 1.15189 loss)
I0523 16:30:22.891422 19131 sgd_solver.cpp:106] Iteration 9750, lr = 0.003
I0523 16:30:31.919462 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_10000.caffemodel
I0523 16:30:31.984264 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_10000.solverstate
I0523 16:30:32.012253 19131 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 16:31:40.176442 19131 solver.cpp:409]     Test net output #0: accuracy = 0.826242
I0523 16:31:40.176599 19131 solver.cpp:409]     Test net output #1: loss = 0.607186 (* 1 = 0.607186 loss)
I0523 16:32:02.342483 19131 solver.cpp:237] Iteration 10000, loss = 1.45626
I0523 16:32:02.342535 19131 solver.cpp:253]     Train net output #0: loss = 1.45626 (* 1 = 1.45626 loss)
I0523 16:32:02.342550 19131 sgd_solver.cpp:106] Iteration 10000, lr = 0.003
I0523 16:32:11.464591 19131 solver.cpp:237] Iteration 10250, loss = 1.11584
I0523 16:32:11.464754 19131 solver.cpp:253]     Train net output #0: loss = 1.11584 (* 1 = 1.11584 loss)
I0523 16:32:11.464767 19131 sgd_solver.cpp:106] Iteration 10250, lr = 0.003
I0523 16:32:20.585155 19131 solver.cpp:237] Iteration 10500, loss = 1.27251
I0523 16:32:20.585197 19131 solver.cpp:253]     Train net output #0: loss = 1.27251 (* 1 = 1.27251 loss)
I0523 16:32:20.585216 19131 sgd_solver.cpp:106] Iteration 10500, lr = 0.003
I0523 16:32:29.708887 19131 solver.cpp:237] Iteration 10750, loss = 1.25378
I0523 16:32:29.708922 19131 solver.cpp:253]     Train net output #0: loss = 1.25378 (* 1 = 1.25378 loss)
I0523 16:32:29.708938 19131 sgd_solver.cpp:106] Iteration 10750, lr = 0.003
I0523 16:32:38.827060 19131 solver.cpp:237] Iteration 11000, loss = 1.4974
I0523 16:32:38.827107 19131 solver.cpp:253]     Train net output #0: loss = 1.4974 (* 1 = 1.4974 loss)
I0523 16:32:38.827122 19131 sgd_solver.cpp:106] Iteration 11000, lr = 0.003
I0523 16:32:47.949292 19131 solver.cpp:237] Iteration 11250, loss = 1.20371
I0523 16:32:47.949435 19131 solver.cpp:253]     Train net output #0: loss = 1.20371 (* 1 = 1.20371 loss)
I0523 16:32:47.949448 19131 sgd_solver.cpp:106] Iteration 11250, lr = 0.003
I0523 16:32:57.078121 19131 solver.cpp:237] Iteration 11500, loss = 1.1269
I0523 16:32:57.078156 19131 solver.cpp:253]     Train net output #0: loss = 1.1269 (* 1 = 1.1269 loss)
I0523 16:32:57.078173 19131 sgd_solver.cpp:106] Iteration 11500, lr = 0.003
I0523 16:33:28.343547 19131 solver.cpp:237] Iteration 11750, loss = 1.45228
I0523 16:33:28.343708 19131 solver.cpp:253]     Train net output #0: loss = 1.45228 (* 1 = 1.45228 loss)
I0523 16:33:28.343724 19131 sgd_solver.cpp:106] Iteration 11750, lr = 0.003
I0523 16:33:37.463709 19131 solver.cpp:237] Iteration 12000, loss = 1.30397
I0523 16:33:37.463750 19131 solver.cpp:253]     Train net output #0: loss = 1.30397 (* 1 = 1.30397 loss)
I0523 16:33:37.463771 19131 sgd_solver.cpp:106] Iteration 12000, lr = 0.003
I0523 16:33:46.573601 19131 solver.cpp:237] Iteration 12250, loss = 1.47398
I0523 16:33:46.573637 19131 solver.cpp:253]     Train net output #0: loss = 1.47398 (* 1 = 1.47398 loss)
I0523 16:33:46.573653 19131 sgd_solver.cpp:106] Iteration 12250, lr = 0.003
I0523 16:33:55.660898 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_12500.caffemodel
I0523 16:33:55.725826 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_12500.solverstate
I0523 16:33:55.764999 19131 solver.cpp:237] Iteration 12500, loss = 1.37775
I0523 16:33:55.765049 19131 solver.cpp:253]     Train net output #0: loss = 1.37775 (* 1 = 1.37775 loss)
I0523 16:33:55.765067 19131 sgd_solver.cpp:106] Iteration 12500, lr = 0.003
I0523 16:34:04.878517 19131 solver.cpp:237] Iteration 12750, loss = 1.20541
I0523 16:34:04.878664 19131 solver.cpp:253]     Train net output #0: loss = 1.20541 (* 1 = 1.20541 loss)
I0523 16:34:04.878679 19131 sgd_solver.cpp:106] Iteration 12750, lr = 0.003
I0523 16:34:13.992563 19131 solver.cpp:237] Iteration 13000, loss = 1.3859
I0523 16:34:13.992599 19131 solver.cpp:253]     Train net output #0: loss = 1.3859 (* 1 = 1.3859 loss)
I0523 16:34:13.992616 19131 sgd_solver.cpp:106] Iteration 13000, lr = 0.003
I0523 16:34:23.116035 19131 solver.cpp:237] Iteration 13250, loss = 1.66866
I0523 16:34:23.116076 19131 solver.cpp:253]     Train net output #0: loss = 1.66866 (* 1 = 1.66866 loss)
I0523 16:34:23.116093 19131 sgd_solver.cpp:106] Iteration 13250, lr = 0.003
I0523 16:34:54.405877 19131 solver.cpp:237] Iteration 13500, loss = 1.4974
I0523 16:34:54.406052 19131 solver.cpp:253]     Train net output #0: loss = 1.4974 (* 1 = 1.4974 loss)
I0523 16:34:54.406069 19131 sgd_solver.cpp:106] Iteration 13500, lr = 0.003
I0523 16:35:03.525293 19131 solver.cpp:237] Iteration 13750, loss = 1.33567
I0523 16:35:03.525329 19131 solver.cpp:253]     Train net output #0: loss = 1.33567 (* 1 = 1.33567 loss)
I0523 16:35:03.525346 19131 sgd_solver.cpp:106] Iteration 13750, lr = 0.003
I0523 16:35:12.647944 19131 solver.cpp:237] Iteration 14000, loss = 1.29393
I0523 16:35:12.647986 19131 solver.cpp:253]     Train net output #0: loss = 1.29393 (* 1 = 1.29393 loss)
I0523 16:35:12.648006 19131 sgd_solver.cpp:106] Iteration 14000, lr = 0.003
I0523 16:35:21.762552 19131 solver.cpp:237] Iteration 14250, loss = 1.37258
I0523 16:35:21.762588 19131 solver.cpp:253]     Train net output #0: loss = 1.37258 (* 1 = 1.37258 loss)
I0523 16:35:21.762604 19131 sgd_solver.cpp:106] Iteration 14250, lr = 0.003
I0523 16:35:30.881604 19131 solver.cpp:237] Iteration 14500, loss = 1.2101
I0523 16:35:30.881747 19131 solver.cpp:253]     Train net output #0: loss = 1.2101 (* 1 = 1.2101 loss)
I0523 16:35:30.881762 19131 sgd_solver.cpp:106] Iteration 14500, lr = 0.003
I0523 16:35:39.998870 19131 solver.cpp:237] Iteration 14750, loss = 1.09471
I0523 16:35:39.998913 19131 solver.cpp:253]     Train net output #0: loss = 1.09471 (* 1 = 1.09471 loss)
I0523 16:35:39.998930 19131 sgd_solver.cpp:106] Iteration 14750, lr = 0.003
I0523 16:35:49.078158 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_15000.caffemodel
I0523 16:35:49.151028 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_15000.solverstate
I0523 16:35:49.176295 19131 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 16:36:36.146663 19131 solver.cpp:409]     Test net output #0: accuracy = 0.842582
I0523 16:36:36.146836 19131 solver.cpp:409]     Test net output #1: loss = 0.535356 (* 1 = 0.535356 loss)
I0523 16:36:58.295306 19131 solver.cpp:237] Iteration 15000, loss = 1.13488
I0523 16:36:58.295357 19131 solver.cpp:253]     Train net output #0: loss = 1.13488 (* 1 = 1.13488 loss)
I0523 16:36:58.295375 19131 sgd_solver.cpp:106] Iteration 15000, lr = 0.003
I0523 16:37:07.321504 19131 solver.cpp:237] Iteration 15250, loss = 0.910664
I0523 16:37:07.321656 19131 solver.cpp:253]     Train net output #0: loss = 0.910664 (* 1 = 0.910664 loss)
I0523 16:37:07.321671 19131 sgd_solver.cpp:106] Iteration 15250, lr = 0.003
I0523 16:37:16.347194 19131 solver.cpp:237] Iteration 15500, loss = 1.24544
I0523 16:37:16.347240 19131 solver.cpp:253]     Train net output #0: loss = 1.24544 (* 1 = 1.24544 loss)
I0523 16:37:16.347257 19131 sgd_solver.cpp:106] Iteration 15500, lr = 0.003
I0523 16:37:25.377902 19131 solver.cpp:237] Iteration 15750, loss = 1.41546
I0523 16:37:25.377938 19131 solver.cpp:253]     Train net output #0: loss = 1.41546 (* 1 = 1.41546 loss)
I0523 16:37:25.377954 19131 sgd_solver.cpp:106] Iteration 15750, lr = 0.003
I0523 16:37:34.407485 19131 solver.cpp:237] Iteration 16000, loss = 1.45799
I0523 16:37:34.407521 19131 solver.cpp:253]     Train net output #0: loss = 1.45799 (* 1 = 1.45799 loss)
I0523 16:37:34.407536 19131 sgd_solver.cpp:106] Iteration 16000, lr = 0.003
I0523 16:37:43.440796 19131 solver.cpp:237] Iteration 16250, loss = 1.47646
I0523 16:37:43.440953 19131 solver.cpp:253]     Train net output #0: loss = 1.47646 (* 1 = 1.47646 loss)
I0523 16:37:43.440966 19131 sgd_solver.cpp:106] Iteration 16250, lr = 0.003
I0523 16:37:52.469009 19131 solver.cpp:237] Iteration 16500, loss = 1.0614
I0523 16:37:52.469044 19131 solver.cpp:253]     Train net output #0: loss = 1.0614 (* 1 = 1.0614 loss)
I0523 16:37:52.469061 19131 sgd_solver.cpp:106] Iteration 16500, lr = 0.003
I0523 16:38:23.678535 19131 solver.cpp:237] Iteration 16750, loss = 1.17087
I0523 16:38:23.678717 19131 solver.cpp:253]     Train net output #0: loss = 1.17087 (* 1 = 1.17087 loss)
I0523 16:38:23.678731 19131 sgd_solver.cpp:106] Iteration 16750, lr = 0.003
I0523 16:38:32.707527 19131 solver.cpp:237] Iteration 17000, loss = 1.29002
I0523 16:38:32.707576 19131 solver.cpp:253]     Train net output #0: loss = 1.29002 (* 1 = 1.29002 loss)
I0523 16:38:32.707592 19131 sgd_solver.cpp:106] Iteration 17000, lr = 0.003
I0523 16:38:41.733098 19131 solver.cpp:237] Iteration 17250, loss = 1.27985
I0523 16:38:41.733134 19131 solver.cpp:253]     Train net output #0: loss = 1.27985 (* 1 = 1.27985 loss)
I0523 16:38:41.733151 19131 sgd_solver.cpp:106] Iteration 17250, lr = 0.003
I0523 16:38:50.726943 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_17500.caffemodel
I0523 16:38:50.790380 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_17500.solverstate
I0523 16:38:50.828222 19131 solver.cpp:237] Iteration 17500, loss = 1.11955
I0523 16:38:50.828265 19131 solver.cpp:253]     Train net output #0: loss = 1.11955 (* 1 = 1.11955 loss)
I0523 16:38:50.828279 19131 sgd_solver.cpp:106] Iteration 17500, lr = 0.003
I0523 16:38:59.858463 19131 solver.cpp:237] Iteration 17750, loss = 1.29506
I0523 16:38:59.858623 19131 solver.cpp:253]     Train net output #0: loss = 1.29506 (* 1 = 1.29506 loss)
I0523 16:38:59.858639 19131 sgd_solver.cpp:106] Iteration 17750, lr = 0.003
I0523 16:39:08.891499 19131 solver.cpp:237] Iteration 18000, loss = 0.976295
I0523 16:39:08.891535 19131 solver.cpp:253]     Train net output #0: loss = 0.976295 (* 1 = 0.976295 loss)
I0523 16:39:08.891548 19131 sgd_solver.cpp:106] Iteration 18000, lr = 0.003
I0523 16:39:17.916398 19131 solver.cpp:237] Iteration 18250, loss = 1.06354
I0523 16:39:17.916434 19131 solver.cpp:253]     Train net output #0: loss = 1.06354 (* 1 = 1.06354 loss)
I0523 16:39:17.916448 19131 sgd_solver.cpp:106] Iteration 18250, lr = 0.003
I0523 16:39:49.081475 19131 solver.cpp:237] Iteration 18500, loss = 1.35229
I0523 16:39:49.081645 19131 solver.cpp:253]     Train net output #0: loss = 1.35229 (* 1 = 1.35229 loss)
I0523 16:39:49.081658 19131 sgd_solver.cpp:106] Iteration 18500, lr = 0.003
I0523 16:39:58.107020 19131 solver.cpp:237] Iteration 18750, loss = 1.23288
I0523 16:39:58.107050 19131 solver.cpp:253]     Train net output #0: loss = 1.23288 (* 1 = 1.23288 loss)
I0523 16:39:58.107065 19131 sgd_solver.cpp:106] Iteration 18750, lr = 0.003
I0523 16:40:07.137709 19131 solver.cpp:237] Iteration 19000, loss = 1.22458
I0523 16:40:07.137744 19131 solver.cpp:253]     Train net output #0: loss = 1.22458 (* 1 = 1.22458 loss)
I0523 16:40:07.137763 19131 sgd_solver.cpp:106] Iteration 19000, lr = 0.003
I0523 16:40:16.167412 19131 solver.cpp:237] Iteration 19250, loss = 1.12693
I0523 16:40:16.167454 19131 solver.cpp:253]     Train net output #0: loss = 1.12693 (* 1 = 1.12693 loss)
I0523 16:40:16.167474 19131 sgd_solver.cpp:106] Iteration 19250, lr = 0.003
I0523 16:40:25.194175 19131 solver.cpp:237] Iteration 19500, loss = 1.05573
I0523 16:40:25.194317 19131 solver.cpp:253]     Train net output #0: loss = 1.05573 (* 1 = 1.05573 loss)
I0523 16:40:25.194334 19131 sgd_solver.cpp:106] Iteration 19500, lr = 0.003
I0523 16:40:34.223048 19131 solver.cpp:237] Iteration 19750, loss = 1.42317
I0523 16:40:34.223093 19131 solver.cpp:253]     Train net output #0: loss = 1.42317 (* 1 = 1.42317 loss)
I0523 16:40:34.223109 19131 sgd_solver.cpp:106] Iteration 19750, lr = 0.003
I0523 16:40:43.220788 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_20000.caffemodel
I0523 16:40:43.283299 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_20000.solverstate
I0523 16:40:43.309620 19131 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 16:41:51.458295 19131 solver.cpp:409]     Test net output #0: accuracy = 0.858368
I0523 16:41:51.458467 19131 solver.cpp:409]     Test net output #1: loss = 0.463205 (* 1 = 0.463205 loss)
I0523 16:42:13.599246 19131 solver.cpp:237] Iteration 20000, loss = 1.23472
I0523 16:42:13.599300 19131 solver.cpp:253]     Train net output #0: loss = 1.23472 (* 1 = 1.23472 loss)
I0523 16:42:13.599314 19131 sgd_solver.cpp:106] Iteration 20000, lr = 0.003
I0523 16:42:22.656836 19131 solver.cpp:237] Iteration 20250, loss = 1.14788
I0523 16:42:22.656998 19131 solver.cpp:253]     Train net output #0: loss = 1.14788 (* 1 = 1.14788 loss)
I0523 16:42:22.657011 19131 sgd_solver.cpp:106] Iteration 20250, lr = 0.003
I0523 16:42:31.733131 19131 solver.cpp:237] Iteration 20500, loss = 1.1918
I0523 16:42:31.733166 19131 solver.cpp:253]     Train net output #0: loss = 1.1918 (* 1 = 1.1918 loss)
I0523 16:42:31.733185 19131 sgd_solver.cpp:106] Iteration 20500, lr = 0.003
I0523 16:42:40.805213 19131 solver.cpp:237] Iteration 20750, loss = 1.0033
I0523 16:42:40.805254 19131 solver.cpp:253]     Train net output #0: loss = 1.0033 (* 1 = 1.0033 loss)
I0523 16:42:40.805271 19131 sgd_solver.cpp:106] Iteration 20750, lr = 0.003
I0523 16:42:49.872593 19131 solver.cpp:237] Iteration 21000, loss = 1.2265
I0523 16:42:49.872629 19131 solver.cpp:253]     Train net output #0: loss = 1.2265 (* 1 = 1.2265 loss)
I0523 16:42:49.872645 19131 sgd_solver.cpp:106] Iteration 21000, lr = 0.003
I0523 16:42:58.928769 19131 solver.cpp:237] Iteration 21250, loss = 1.22635
I0523 16:42:58.928916 19131 solver.cpp:253]     Train net output #0: loss = 1.22635 (* 1 = 1.22635 loss)
I0523 16:42:58.928930 19131 sgd_solver.cpp:106] Iteration 21250, lr = 0.003
I0523 16:43:07.997952 19131 solver.cpp:237] Iteration 21500, loss = 1.02727
I0523 16:43:07.997997 19131 solver.cpp:253]     Train net output #0: loss = 1.02727 (* 1 = 1.02727 loss)
I0523 16:43:07.998014 19131 sgd_solver.cpp:106] Iteration 21500, lr = 0.003
I0523 16:43:39.186743 19131 solver.cpp:237] Iteration 21750, loss = 1.30211
I0523 16:43:39.186910 19131 solver.cpp:253]     Train net output #0: loss = 1.30211 (* 1 = 1.30211 loss)
I0523 16:43:39.186926 19131 sgd_solver.cpp:106] Iteration 21750, lr = 0.003
I0523 16:43:48.264953 19131 solver.cpp:237] Iteration 22000, loss = 1.40777
I0523 16:43:48.264987 19131 solver.cpp:253]     Train net output #0: loss = 1.40777 (* 1 = 1.40777 loss)
I0523 16:43:48.265004 19131 sgd_solver.cpp:106] Iteration 22000, lr = 0.003
I0523 16:43:57.331231 19131 solver.cpp:237] Iteration 22250, loss = 1.22753
I0523 16:43:57.331271 19131 solver.cpp:253]     Train net output #0: loss = 1.22753 (* 1 = 1.22753 loss)
I0523 16:43:57.331291 19131 sgd_solver.cpp:106] Iteration 22250, lr = 0.003
I0523 16:44:06.364845 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_22500.caffemodel
I0523 16:44:06.430676 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_22500.solverstate
I0523 16:44:06.470692 19131 solver.cpp:237] Iteration 22500, loss = 1.3462
I0523 16:44:06.470743 19131 solver.cpp:253]     Train net output #0: loss = 1.3462 (* 1 = 1.3462 loss)
I0523 16:44:06.470764 19131 sgd_solver.cpp:106] Iteration 22500, lr = 0.003
I0523 16:44:15.540361 19131 solver.cpp:237] Iteration 22750, loss = 1.29926
I0523 16:44:15.540513 19131 solver.cpp:253]     Train net output #0: loss = 1.29926 (* 1 = 1.29926 loss)
I0523 16:44:15.540526 19131 sgd_solver.cpp:106] Iteration 22750, lr = 0.003
I0523 16:44:24.615912 19131 solver.cpp:237] Iteration 23000, loss = 1.34834
I0523 16:44:24.615957 19131 solver.cpp:253]     Train net output #0: loss = 1.34834 (* 1 = 1.34834 loss)
I0523 16:44:24.615973 19131 sgd_solver.cpp:106] Iteration 23000, lr = 0.003
I0523 16:44:33.684940 19131 solver.cpp:237] Iteration 23250, loss = 1.22917
I0523 16:44:33.684976 19131 solver.cpp:253]     Train net output #0: loss = 1.22917 (* 1 = 1.22917 loss)
I0523 16:44:33.684993 19131 sgd_solver.cpp:106] Iteration 23250, lr = 0.003
I0523 16:45:04.874354 19131 solver.cpp:237] Iteration 23500, loss = 1.08435
I0523 16:45:04.874537 19131 solver.cpp:253]     Train net output #0: loss = 1.08435 (* 1 = 1.08435 loss)
I0523 16:45:04.874552 19131 sgd_solver.cpp:106] Iteration 23500, lr = 0.003
I0523 16:45:13.925508 19131 solver.cpp:237] Iteration 23750, loss = 1.33105
I0523 16:45:13.925549 19131 solver.cpp:253]     Train net output #0: loss = 1.33105 (* 1 = 1.33105 loss)
I0523 16:45:13.925567 19131 sgd_solver.cpp:106] Iteration 23750, lr = 0.003
I0523 16:45:22.980273 19131 solver.cpp:237] Iteration 24000, loss = 1.22204
I0523 16:45:22.980309 19131 solver.cpp:253]     Train net output #0: loss = 1.22204 (* 1 = 1.22204 loss)
I0523 16:45:22.980325 19131 sgd_solver.cpp:106] Iteration 24000, lr = 0.003
I0523 16:45:32.042423 19131 solver.cpp:237] Iteration 24250, loss = 1.3159
I0523 16:45:32.042459 19131 solver.cpp:253]     Train net output #0: loss = 1.3159 (* 1 = 1.3159 loss)
I0523 16:45:32.042475 19131 sgd_solver.cpp:106] Iteration 24250, lr = 0.003
I0523 16:45:41.099310 19131 solver.cpp:237] Iteration 24500, loss = 1.17449
I0523 16:45:41.099462 19131 solver.cpp:253]     Train net output #0: loss = 1.17449 (* 1 = 1.17449 loss)
I0523 16:45:41.099475 19131 sgd_solver.cpp:106] Iteration 24500, lr = 0.003
I0523 16:45:50.165112 19131 solver.cpp:237] Iteration 24750, loss = 1.34025
I0523 16:45:50.165146 19131 solver.cpp:253]     Train net output #0: loss = 1.34025 (* 1 = 1.34025 loss)
I0523 16:45:50.165163 19131 sgd_solver.cpp:106] Iteration 24750, lr = 0.003
I0523 16:45:59.198261 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_25000.caffemodel
I0523 16:45:59.264044 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_25000.solverstate
I0523 16:45:59.293068 19131 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 16:46:46.632017 19131 solver.cpp:409]     Test net output #0: accuracy = 0.869407
I0523 16:46:46.632182 19131 solver.cpp:409]     Test net output #1: loss = 0.438983 (* 1 = 0.438983 loss)
I0523 16:47:07.529342 19131 solver.cpp:237] Iteration 25000, loss = 0.998728
I0523 16:47:07.529397 19131 solver.cpp:253]     Train net output #0: loss = 0.998728 (* 1 = 0.998728 loss)
I0523 16:47:07.529412 19131 sgd_solver.cpp:106] Iteration 25000, lr = 0.003
I0523 16:47:16.542636 19131 solver.cpp:237] Iteration 25250, loss = 1.13873
I0523 16:47:16.542683 19131 solver.cpp:253]     Train net output #0: loss = 1.13873 (* 1 = 1.13873 loss)
I0523 16:47:16.542706 19131 sgd_solver.cpp:106] Iteration 25250, lr = 0.003
I0523 16:47:25.552911 19131 solver.cpp:237] Iteration 25500, loss = 1.30847
I0523 16:47:25.553062 19131 solver.cpp:253]     Train net output #0: loss = 1.30847 (* 1 = 1.30847 loss)
I0523 16:47:25.553076 19131 sgd_solver.cpp:106] Iteration 25500, lr = 0.003
I0523 16:47:34.567448 19131 solver.cpp:237] Iteration 25750, loss = 1.16487
I0523 16:47:34.567483 19131 solver.cpp:253]     Train net output #0: loss = 1.16487 (* 1 = 1.16487 loss)
I0523 16:47:34.567502 19131 sgd_solver.cpp:106] Iteration 25750, lr = 0.003
I0523 16:47:43.580631 19131 solver.cpp:237] Iteration 26000, loss = 1.29167
I0523 16:47:43.580672 19131 solver.cpp:253]     Train net output #0: loss = 1.29167 (* 1 = 1.29167 loss)
I0523 16:47:43.580693 19131 sgd_solver.cpp:106] Iteration 26000, lr = 0.003
I0523 16:47:52.595801 19131 solver.cpp:237] Iteration 26250, loss = 1.12668
I0523 16:47:52.595839 19131 solver.cpp:253]     Train net output #0: loss = 1.12668 (* 1 = 1.12668 loss)
I0523 16:47:52.595854 19131 sgd_solver.cpp:106] Iteration 26250, lr = 0.003
I0523 16:48:01.599364 19131 solver.cpp:237] Iteration 26500, loss = 1.48912
I0523 16:48:01.599521 19131 solver.cpp:253]     Train net output #0: loss = 1.48912 (* 1 = 1.48912 loss)
I0523 16:48:01.599535 19131 sgd_solver.cpp:106] Iteration 26500, lr = 0.003
I0523 16:48:31.555219 19131 solver.cpp:237] Iteration 26750, loss = 1.01141
I0523 16:48:31.555269 19131 solver.cpp:253]     Train net output #0: loss = 1.01141 (* 1 = 1.01141 loss)
I0523 16:48:31.555284 19131 sgd_solver.cpp:106] Iteration 26750, lr = 0.003
I0523 16:48:40.568898 19131 solver.cpp:237] Iteration 27000, loss = 1.23535
I0523 16:48:40.569052 19131 solver.cpp:253]     Train net output #0: loss = 1.23535 (* 1 = 1.23535 loss)
I0523 16:48:40.569067 19131 sgd_solver.cpp:106] Iteration 27000, lr = 0.003
I0523 16:48:49.576922 19131 solver.cpp:237] Iteration 27250, loss = 1.40856
I0523 16:48:49.576957 19131 solver.cpp:253]     Train net output #0: loss = 1.40856 (* 1 = 1.40856 loss)
I0523 16:48:49.576975 19131 sgd_solver.cpp:106] Iteration 27250, lr = 0.003
I0523 16:48:58.553283 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_27500.caffemodel
I0523 16:48:58.616272 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_27500.solverstate
I0523 16:48:58.654285 19131 solver.cpp:237] Iteration 27500, loss = 1.08921
I0523 16:48:58.654330 19131 solver.cpp:253]     Train net output #0: loss = 1.08921 (* 1 = 1.08921 loss)
I0523 16:48:58.654346 19131 sgd_solver.cpp:106] Iteration 27500, lr = 0.003
I0523 16:49:07.672274 19131 solver.cpp:237] Iteration 27750, loss = 1.43313
I0523 16:49:07.672310 19131 solver.cpp:253]     Train net output #0: loss = 1.43313 (* 1 = 1.43313 loss)
I0523 16:49:07.672323 19131 sgd_solver.cpp:106] Iteration 27750, lr = 0.003
I0523 16:49:16.680961 19131 solver.cpp:237] Iteration 28000, loss = 1.10341
I0523 16:49:16.681112 19131 solver.cpp:253]     Train net output #0: loss = 1.10341 (* 1 = 1.10341 loss)
I0523 16:49:16.681126 19131 sgd_solver.cpp:106] Iteration 28000, lr = 0.003
I0523 16:49:25.692914 19131 solver.cpp:237] Iteration 28250, loss = 1.33098
I0523 16:49:25.692951 19131 solver.cpp:253]     Train net output #0: loss = 1.33098 (* 1 = 1.33098 loss)
I0523 16:49:25.692965 19131 sgd_solver.cpp:106] Iteration 28250, lr = 0.003
I0523 16:49:55.635202 19131 solver.cpp:237] Iteration 28500, loss = 1.14158
I0523 16:49:55.635371 19131 solver.cpp:253]     Train net output #0: loss = 1.14158 (* 1 = 1.14158 loss)
I0523 16:49:55.635385 19131 sgd_solver.cpp:106] Iteration 28500, lr = 0.003
I0523 16:50:04.651216 19131 solver.cpp:237] Iteration 28750, loss = 1.05726
I0523 16:50:04.651250 19131 solver.cpp:253]     Train net output #0: loss = 1.05726 (* 1 = 1.05726 loss)
I0523 16:50:04.651264 19131 sgd_solver.cpp:106] Iteration 28750, lr = 0.003
I0523 16:50:13.657716 19131 solver.cpp:237] Iteration 29000, loss = 1.43106
I0523 16:50:13.657762 19131 solver.cpp:253]     Train net output #0: loss = 1.43106 (* 1 = 1.43106 loss)
I0523 16:50:13.657778 19131 sgd_solver.cpp:106] Iteration 29000, lr = 0.003
I0523 16:50:22.669868 19131 solver.cpp:237] Iteration 29250, loss = 1.11581
I0523 16:50:22.669904 19131 solver.cpp:253]     Train net output #0: loss = 1.11581 (* 1 = 1.11581 loss)
I0523 16:50:22.669920 19131 sgd_solver.cpp:106] Iteration 29250, lr = 0.003
I0523 16:50:31.684017 19131 solver.cpp:237] Iteration 29500, loss = 1.13404
I0523 16:50:31.684165 19131 solver.cpp:253]     Train net output #0: loss = 1.13404 (* 1 = 1.13404 loss)
I0523 16:50:31.684178 19131 sgd_solver.cpp:106] Iteration 29500, lr = 0.003
I0523 16:50:40.699271 19131 solver.cpp:237] Iteration 29750, loss = 1.23531
I0523 16:50:40.699317 19131 solver.cpp:253]     Train net output #0: loss = 1.23531 (* 1 = 1.23531 loss)
I0523 16:50:40.699332 19131 sgd_solver.cpp:106] Iteration 29750, lr = 0.003
I0523 16:50:49.669420 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_30000.caffemodel
I0523 16:50:49.732467 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_30000.solverstate
I0523 16:50:49.759106 19131 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 16:51:57.889258 19131 solver.cpp:409]     Test net output #0: accuracy = 0.87206
I0523 16:51:57.889435 19131 solver.cpp:409]     Test net output #1: loss = 0.40618 (* 1 = 0.40618 loss)
I0523 16:52:18.809666 19131 solver.cpp:237] Iteration 30000, loss = 1.22597
I0523 16:52:18.809720 19131 solver.cpp:253]     Train net output #0: loss = 1.22597 (* 1 = 1.22597 loss)
I0523 16:52:18.809734 19131 sgd_solver.cpp:106] Iteration 30000, lr = 0.003
I0523 16:52:27.923034 19131 solver.cpp:237] Iteration 30250, loss = 1.24563
I0523 16:52:27.923185 19131 solver.cpp:253]     Train net output #0: loss = 1.24563 (* 1 = 1.24563 loss)
I0523 16:52:27.923199 19131 sgd_solver.cpp:106] Iteration 30250, lr = 0.003
I0523 16:52:37.027741 19131 solver.cpp:237] Iteration 30500, loss = 0.984556
I0523 16:52:37.027778 19131 solver.cpp:253]     Train net output #0: loss = 0.984556 (* 1 = 0.984556 loss)
I0523 16:52:37.027794 19131 sgd_solver.cpp:106] Iteration 30500, lr = 0.003
I0523 16:52:46.142742 19131 solver.cpp:237] Iteration 30750, loss = 1.37966
I0523 16:52:46.142781 19131 solver.cpp:253]     Train net output #0: loss = 1.37966 (* 1 = 1.37966 loss)
I0523 16:52:46.142802 19131 sgd_solver.cpp:106] Iteration 30750, lr = 0.003
I0523 16:52:55.252938 19131 solver.cpp:237] Iteration 31000, loss = 1.35948
I0523 16:52:55.252974 19131 solver.cpp:253]     Train net output #0: loss = 1.35948 (* 1 = 1.35948 loss)
I0523 16:52:55.252990 19131 sgd_solver.cpp:106] Iteration 31000, lr = 0.003
I0523 16:53:04.353710 19131 solver.cpp:237] Iteration 31250, loss = 1.20505
I0523 16:53:04.353873 19131 solver.cpp:253]     Train net output #0: loss = 1.20505 (* 1 = 1.20505 loss)
I0523 16:53:04.353886 19131 sgd_solver.cpp:106] Iteration 31250, lr = 0.003
I0523 16:53:13.454469 19131 solver.cpp:237] Iteration 31500, loss = 1.14552
I0523 16:53:13.454504 19131 solver.cpp:253]     Train net output #0: loss = 1.14552 (* 1 = 1.14552 loss)
I0523 16:53:13.454521 19131 sgd_solver.cpp:106] Iteration 31500, lr = 0.003
I0523 16:53:43.498720 19131 solver.cpp:237] Iteration 31750, loss = 1.03326
I0523 16:53:43.498888 19131 solver.cpp:253]     Train net output #0: loss = 1.03326 (* 1 = 1.03326 loss)
I0523 16:53:43.498903 19131 sgd_solver.cpp:106] Iteration 31750, lr = 0.003
I0523 16:53:52.606181 19131 solver.cpp:237] Iteration 32000, loss = 0.974609
I0523 16:53:52.606217 19131 solver.cpp:253]     Train net output #0: loss = 0.974609 (* 1 = 0.974609 loss)
I0523 16:53:52.606233 19131 sgd_solver.cpp:106] Iteration 32000, lr = 0.003
I0523 16:54:01.715814 19131 solver.cpp:237] Iteration 32250, loss = 1.38859
I0523 16:54:01.715852 19131 solver.cpp:253]     Train net output #0: loss = 1.38859 (* 1 = 1.38859 loss)
I0523 16:54:01.715868 19131 sgd_solver.cpp:106] Iteration 32250, lr = 0.003
I0523 16:54:10.784265 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_32500.caffemodel
I0523 16:54:10.847170 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_32500.solverstate
I0523 16:54:10.884883 19131 solver.cpp:237] Iteration 32500, loss = 1.22683
I0523 16:54:10.884929 19131 solver.cpp:253]     Train net output #0: loss = 1.22683 (* 1 = 1.22683 loss)
I0523 16:54:10.884946 19131 sgd_solver.cpp:106] Iteration 32500, lr = 0.003
I0523 16:54:19.984367 19131 solver.cpp:237] Iteration 32750, loss = 1.11805
I0523 16:54:19.984529 19131 solver.cpp:253]     Train net output #0: loss = 1.11805 (* 1 = 1.11805 loss)
I0523 16:54:19.984542 19131 sgd_solver.cpp:106] Iteration 32750, lr = 0.003
I0523 16:54:29.097956 19131 solver.cpp:237] Iteration 33000, loss = 1.28183
I0523 16:54:29.097991 19131 solver.cpp:253]     Train net output #0: loss = 1.28183 (* 1 = 1.28183 loss)
I0523 16:54:29.098008 19131 sgd_solver.cpp:106] Iteration 33000, lr = 0.003
I0523 16:54:38.211122 19131 solver.cpp:237] Iteration 33250, loss = 1.21684
I0523 16:54:38.211158 19131 solver.cpp:253]     Train net output #0: loss = 1.21684 (* 1 = 1.21684 loss)
I0523 16:54:38.211174 19131 sgd_solver.cpp:106] Iteration 33250, lr = 0.003
I0523 16:55:08.206038 19131 solver.cpp:237] Iteration 33500, loss = 1.07143
I0523 16:55:08.206223 19131 solver.cpp:253]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0523 16:55:08.206236 19131 sgd_solver.cpp:106] Iteration 33500, lr = 0.003
I0523 16:55:17.318316 19131 solver.cpp:237] Iteration 33750, loss = 1.32574
I0523 16:55:17.318362 19131 solver.cpp:253]     Train net output #0: loss = 1.32574 (* 1 = 1.32574 loss)
I0523 16:55:17.318382 19131 sgd_solver.cpp:106] Iteration 33750, lr = 0.003
I0523 16:55:26.414351 19131 solver.cpp:237] Iteration 34000, loss = 1.15958
I0523 16:55:26.414387 19131 solver.cpp:253]     Train net output #0: loss = 1.15958 (* 1 = 1.15958 loss)
I0523 16:55:26.414403 19131 sgd_solver.cpp:106] Iteration 34000, lr = 0.003
I0523 16:55:35.517585 19131 solver.cpp:237] Iteration 34250, loss = 0.938834
I0523 16:55:35.517633 19131 solver.cpp:253]     Train net output #0: loss = 0.938834 (* 1 = 0.938834 loss)
I0523 16:55:35.517650 19131 sgd_solver.cpp:106] Iteration 34250, lr = 0.003
I0523 16:55:44.630100 19131 solver.cpp:237] Iteration 34500, loss = 1.41159
I0523 16:55:44.630252 19131 solver.cpp:253]     Train net output #0: loss = 1.41159 (* 1 = 1.41159 loss)
I0523 16:55:44.630265 19131 sgd_solver.cpp:106] Iteration 34500, lr = 0.003
I0523 16:55:53.752547 19131 solver.cpp:237] Iteration 34750, loss = 1.45276
I0523 16:55:53.752581 19131 solver.cpp:253]     Train net output #0: loss = 1.45276 (* 1 = 1.45276 loss)
I0523 16:55:53.752599 19131 sgd_solver.cpp:106] Iteration 34750, lr = 0.003
I0523 16:56:02.820174 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_35000.caffemodel
I0523 16:56:02.893383 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_35000.solverstate
I0523 16:56:02.920065 19131 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 16:56:49.918745 19131 solver.cpp:409]     Test net output #0: accuracy = 0.872387
I0523 16:56:49.918918 19131 solver.cpp:409]     Test net output #1: loss = 0.439103 (* 1 = 0.439103 loss)
I0523 16:57:10.810835 19131 solver.cpp:237] Iteration 35000, loss = 0.993438
I0523 16:57:10.810892 19131 solver.cpp:253]     Train net output #0: loss = 0.993438 (* 1 = 0.993438 loss)
I0523 16:57:10.810909 19131 sgd_solver.cpp:106] Iteration 35000, lr = 0.003
I0523 16:57:19.885179 19131 solver.cpp:237] Iteration 35250, loss = 1.47921
I0523 16:57:19.885224 19131 solver.cpp:253]     Train net output #0: loss = 1.47921 (* 1 = 1.47921 loss)
I0523 16:57:19.885241 19131 sgd_solver.cpp:106] Iteration 35250, lr = 0.003
I0523 16:57:28.963353 19131 solver.cpp:237] Iteration 35500, loss = 1.10052
I0523 16:57:28.963508 19131 solver.cpp:253]     Train net output #0: loss = 1.10052 (* 1 = 1.10052 loss)
I0523 16:57:28.963522 19131 sgd_solver.cpp:106] Iteration 35500, lr = 0.003
I0523 16:57:38.038152 19131 solver.cpp:237] Iteration 35750, loss = 1.12284
I0523 16:57:38.038187 19131 solver.cpp:253]     Train net output #0: loss = 1.12284 (* 1 = 1.12284 loss)
I0523 16:57:38.038205 19131 sgd_solver.cpp:106] Iteration 35750, lr = 0.003
I0523 16:57:47.113318 19131 solver.cpp:237] Iteration 36000, loss = 1.11526
I0523 16:57:47.113361 19131 solver.cpp:253]     Train net output #0: loss = 1.11526 (* 1 = 1.11526 loss)
I0523 16:57:47.113378 19131 sgd_solver.cpp:106] Iteration 36000, lr = 0.003
I0523 16:57:56.190994 19131 solver.cpp:237] Iteration 36250, loss = 1.23973
I0523 16:57:56.191030 19131 solver.cpp:253]     Train net output #0: loss = 1.23973 (* 1 = 1.23973 loss)
I0523 16:57:56.191045 19131 sgd_solver.cpp:106] Iteration 36250, lr = 0.003
I0523 16:58:05.264042 19131 solver.cpp:237] Iteration 36500, loss = 1.12953
I0523 16:58:05.264214 19131 solver.cpp:253]     Train net output #0: loss = 1.12953 (* 1 = 1.12953 loss)
I0523 16:58:05.264228 19131 sgd_solver.cpp:106] Iteration 36500, lr = 0.003
I0523 16:58:35.234535 19131 solver.cpp:237] Iteration 36750, loss = 1.17618
I0523 16:58:35.234585 19131 solver.cpp:253]     Train net output #0: loss = 1.17618 (* 1 = 1.17618 loss)
I0523 16:58:35.234603 19131 sgd_solver.cpp:106] Iteration 36750, lr = 0.003
I0523 16:58:44.311450 19131 solver.cpp:237] Iteration 37000, loss = 1.33163
I0523 16:58:44.311609 19131 solver.cpp:253]     Train net output #0: loss = 1.33163 (* 1 = 1.33163 loss)
I0523 16:58:44.311622 19131 sgd_solver.cpp:106] Iteration 37000, lr = 0.003
I0523 16:58:53.385311 19131 solver.cpp:237] Iteration 37250, loss = 1.0375
I0523 16:58:53.385346 19131 solver.cpp:253]     Train net output #0: loss = 1.0375 (* 1 = 1.0375 loss)
I0523 16:58:53.385365 19131 sgd_solver.cpp:106] Iteration 37250, lr = 0.003
I0523 16:59:02.420220 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_37500.caffemodel
I0523 16:59:02.486716 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_37500.solverstate
I0523 16:59:02.527115 19131 solver.cpp:237] Iteration 37500, loss = 1.27269
I0523 16:59:02.527163 19131 solver.cpp:253]     Train net output #0: loss = 1.27269 (* 1 = 1.27269 loss)
I0523 16:59:02.527184 19131 sgd_solver.cpp:106] Iteration 37500, lr = 0.003
I0523 16:59:11.606729 19131 solver.cpp:237] Iteration 37750, loss = 1.2705
I0523 16:59:11.606763 19131 solver.cpp:253]     Train net output #0: loss = 1.2705 (* 1 = 1.2705 loss)
I0523 16:59:11.606781 19131 sgd_solver.cpp:106] Iteration 37750, lr = 0.003
I0523 16:59:20.674567 19131 solver.cpp:237] Iteration 38000, loss = 1.21153
I0523 16:59:20.674744 19131 solver.cpp:253]     Train net output #0: loss = 1.21153 (* 1 = 1.21153 loss)
I0523 16:59:20.674759 19131 sgd_solver.cpp:106] Iteration 38000, lr = 0.003
I0523 16:59:29.754544 19131 solver.cpp:237] Iteration 38250, loss = 1.26506
I0523 16:59:29.754580 19131 solver.cpp:253]     Train net output #0: loss = 1.26506 (* 1 = 1.26506 loss)
I0523 16:59:29.754598 19131 sgd_solver.cpp:106] Iteration 38250, lr = 0.003
I0523 16:59:59.727891 19131 solver.cpp:237] Iteration 38500, loss = 1.07184
I0523 16:59:59.728066 19131 solver.cpp:253]     Train net output #0: loss = 1.07184 (* 1 = 1.07184 loss)
I0523 16:59:59.728083 19131 sgd_solver.cpp:106] Iteration 38500, lr = 0.003
I0523 17:00:08.803951 19131 solver.cpp:237] Iteration 38750, loss = 1.29315
I0523 17:00:08.804002 19131 solver.cpp:253]     Train net output #0: loss = 1.29315 (* 1 = 1.29315 loss)
I0523 17:00:08.804018 19131 sgd_solver.cpp:106] Iteration 38750, lr = 0.003
I0523 17:00:17.946491 19131 solver.cpp:237] Iteration 39000, loss = 1.22873
I0523 17:00:17.946527 19131 solver.cpp:253]     Train net output #0: loss = 1.22873 (* 1 = 1.22873 loss)
I0523 17:00:17.946543 19131 sgd_solver.cpp:106] Iteration 39000, lr = 0.003
I0523 17:00:27.079066 19131 solver.cpp:237] Iteration 39250, loss = 1.08654
I0523 17:00:27.079102 19131 solver.cpp:253]     Train net output #0: loss = 1.08654 (* 1 = 1.08654 loss)
I0523 17:00:27.079118 19131 sgd_solver.cpp:106] Iteration 39250, lr = 0.003
I0523 17:00:36.205860 19131 solver.cpp:237] Iteration 39500, loss = 1.13051
I0523 17:00:36.206027 19131 solver.cpp:253]     Train net output #0: loss = 1.13051 (* 1 = 1.13051 loss)
I0523 17:00:36.206040 19131 sgd_solver.cpp:106] Iteration 39500, lr = 0.003
I0523 17:00:45.333140 19131 solver.cpp:237] Iteration 39750, loss = 1.0531
I0523 17:00:45.333176 19131 solver.cpp:253]     Train net output #0: loss = 1.0531 (* 1 = 1.0531 loss)
I0523 17:00:45.333192 19131 sgd_solver.cpp:106] Iteration 39750, lr = 0.003
I0523 17:00:54.434959 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_40000.caffemodel
I0523 17:00:54.498478 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_40000.solverstate
I0523 17:00:54.525063 19131 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 17:02:02.712468 19131 solver.cpp:409]     Test net output #0: accuracy = 0.877347
I0523 17:02:02.712679 19131 solver.cpp:409]     Test net output #1: loss = 0.394515 (* 1 = 0.394515 loss)
I0523 17:02:23.623594 19131 solver.cpp:237] Iteration 40000, loss = 1.09474
I0523 17:02:23.623646 19131 solver.cpp:253]     Train net output #0: loss = 1.09474 (* 1 = 1.09474 loss)
I0523 17:02:23.623664 19131 sgd_solver.cpp:106] Iteration 40000, lr = 0.003
I0523 17:02:32.596312 19131 solver.cpp:237] Iteration 40250, loss = 1.02895
I0523 17:02:32.596349 19131 solver.cpp:253]     Train net output #0: loss = 1.02895 (* 1 = 1.02895 loss)
I0523 17:02:32.596364 19131 sgd_solver.cpp:106] Iteration 40250, lr = 0.003
I0523 17:02:41.568559 19131 solver.cpp:237] Iteration 40500, loss = 1.25151
I0523 17:02:41.568727 19131 solver.cpp:253]     Train net output #0: loss = 1.25151 (* 1 = 1.25151 loss)
I0523 17:02:41.568740 19131 sgd_solver.cpp:106] Iteration 40500, lr = 0.003
I0523 17:02:50.547096 19131 solver.cpp:237] Iteration 40750, loss = 1.4241
I0523 17:02:50.547129 19131 solver.cpp:253]     Train net output #0: loss = 1.4241 (* 1 = 1.4241 loss)
I0523 17:02:50.547147 19131 sgd_solver.cpp:106] Iteration 40750, lr = 0.003
I0523 17:02:59.528439 19131 solver.cpp:237] Iteration 41000, loss = 1.15412
I0523 17:02:59.528473 19131 solver.cpp:253]     Train net output #0: loss = 1.15412 (* 1 = 1.15412 loss)
I0523 17:02:59.528491 19131 sgd_solver.cpp:106] Iteration 41000, lr = 0.003
I0523 17:03:08.494876 19131 solver.cpp:237] Iteration 41250, loss = 1.03534
I0523 17:03:08.494915 19131 solver.cpp:253]     Train net output #0: loss = 1.03534 (* 1 = 1.03534 loss)
I0523 17:03:08.494936 19131 sgd_solver.cpp:106] Iteration 41250, lr = 0.003
I0523 17:03:17.466505 19131 solver.cpp:237] Iteration 41500, loss = 1.15269
I0523 17:03:17.466656 19131 solver.cpp:253]     Train net output #0: loss = 1.15269 (* 1 = 1.15269 loss)
I0523 17:03:17.466670 19131 sgd_solver.cpp:106] Iteration 41500, lr = 0.003
I0523 17:03:47.349551 19131 solver.cpp:237] Iteration 41750, loss = 1.09529
I0523 17:03:47.349602 19131 solver.cpp:253]     Train net output #0: loss = 1.09529 (* 1 = 1.09529 loss)
I0523 17:03:47.349618 19131 sgd_solver.cpp:106] Iteration 41750, lr = 0.003
I0523 17:03:56.323526 19131 solver.cpp:237] Iteration 42000, loss = 0.883452
I0523 17:03:56.323696 19131 solver.cpp:253]     Train net output #0: loss = 0.883452 (* 1 = 0.883452 loss)
I0523 17:03:56.323710 19131 sgd_solver.cpp:106] Iteration 42000, lr = 0.003
I0523 17:04:05.293648 19131 solver.cpp:237] Iteration 42250, loss = 1.23746
I0523 17:04:05.293684 19131 solver.cpp:253]     Train net output #0: loss = 1.23746 (* 1 = 1.23746 loss)
I0523 17:04:05.293699 19131 sgd_solver.cpp:106] Iteration 42250, lr = 0.003
I0523 17:04:14.236688 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_42500.caffemodel
I0523 17:04:14.299973 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_42500.solverstate
I0523 17:04:14.338066 19131 solver.cpp:237] Iteration 42500, loss = 1.04153
I0523 17:04:14.338114 19131 solver.cpp:253]     Train net output #0: loss = 1.04153 (* 1 = 1.04153 loss)
I0523 17:04:14.338130 19131 sgd_solver.cpp:106] Iteration 42500, lr = 0.003
I0523 17:04:23.306974 19131 solver.cpp:237] Iteration 42750, loss = 0.974475
I0523 17:04:23.307018 19131 solver.cpp:253]     Train net output #0: loss = 0.974475 (* 1 = 0.974475 loss)
I0523 17:04:23.307034 19131 sgd_solver.cpp:106] Iteration 42750, lr = 0.003
I0523 17:04:32.285220 19131 solver.cpp:237] Iteration 43000, loss = 1.34747
I0523 17:04:32.285389 19131 solver.cpp:253]     Train net output #0: loss = 1.34747 (* 1 = 1.34747 loss)
I0523 17:04:32.285405 19131 sgd_solver.cpp:106] Iteration 43000, lr = 0.003
I0523 17:04:41.256960 19131 solver.cpp:237] Iteration 43250, loss = 1.06909
I0523 17:04:41.256995 19131 solver.cpp:253]     Train net output #0: loss = 1.06909 (* 1 = 1.06909 loss)
I0523 17:04:41.257011 19131 sgd_solver.cpp:106] Iteration 43250, lr = 0.003
I0523 17:05:11.166569 19131 solver.cpp:237] Iteration 43500, loss = 1.41218
I0523 17:05:11.166764 19131 solver.cpp:253]     Train net output #0: loss = 1.41218 (* 1 = 1.41218 loss)
I0523 17:05:11.166779 19131 sgd_solver.cpp:106] Iteration 43500, lr = 0.003
I0523 17:05:20.144340 19131 solver.cpp:237] Iteration 43750, loss = 1.2945
I0523 17:05:20.144376 19131 solver.cpp:253]     Train net output #0: loss = 1.2945 (* 1 = 1.2945 loss)
I0523 17:05:20.144394 19131 sgd_solver.cpp:106] Iteration 43750, lr = 0.003
I0523 17:05:29.118013 19131 solver.cpp:237] Iteration 44000, loss = 1.41595
I0523 17:05:29.118049 19131 solver.cpp:253]     Train net output #0: loss = 1.41595 (* 1 = 1.41595 loss)
I0523 17:05:29.118065 19131 sgd_solver.cpp:106] Iteration 44000, lr = 0.003
I0523 17:05:38.088676 19131 solver.cpp:237] Iteration 44250, loss = 1.15548
I0523 17:05:38.088721 19131 solver.cpp:253]     Train net output #0: loss = 1.15548 (* 1 = 1.15548 loss)
I0523 17:05:38.088739 19131 sgd_solver.cpp:106] Iteration 44250, lr = 0.003
I0523 17:05:47.058886 19131 solver.cpp:237] Iteration 44500, loss = 1.17041
I0523 17:05:47.059037 19131 solver.cpp:253]     Train net output #0: loss = 1.17041 (* 1 = 1.17041 loss)
I0523 17:05:47.059051 19131 sgd_solver.cpp:106] Iteration 44500, lr = 0.003
I0523 17:05:56.030481 19131 solver.cpp:237] Iteration 44750, loss = 1.09213
I0523 17:05:56.030517 19131 solver.cpp:253]     Train net output #0: loss = 1.09213 (* 1 = 1.09213 loss)
I0523 17:05:56.030534 19131 sgd_solver.cpp:106] Iteration 44750, lr = 0.003
I0523 17:06:04.970573 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_45000.caffemodel
I0523 17:06:05.033774 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_45000.solverstate
I0523 17:06:05.060518 19131 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 17:06:52.332413 19131 solver.cpp:409]     Test net output #0: accuracy = 0.878379
I0523 17:06:52.332584 19131 solver.cpp:409]     Test net output #1: loss = 0.380397 (* 1 = 0.380397 loss)
I0523 17:07:13.202502 19131 solver.cpp:237] Iteration 45000, loss = 1.26478
I0523 17:07:13.202555 19131 solver.cpp:253]     Train net output #0: loss = 1.26478 (* 1 = 1.26478 loss)
I0523 17:07:13.202570 19131 sgd_solver.cpp:106] Iteration 45000, lr = 0.003
I0523 17:07:22.206650 19131 solver.cpp:237] Iteration 45250, loss = 1.49156
I0523 17:07:22.206692 19131 solver.cpp:253]     Train net output #0: loss = 1.49156 (* 1 = 1.49156 loss)
I0523 17:07:22.206715 19131 sgd_solver.cpp:106] Iteration 45250, lr = 0.003
I0523 17:07:31.216471 19131 solver.cpp:237] Iteration 45500, loss = 1.28206
I0523 17:07:31.216634 19131 solver.cpp:253]     Train net output #0: loss = 1.28206 (* 1 = 1.28206 loss)
I0523 17:07:31.216648 19131 sgd_solver.cpp:106] Iteration 45500, lr = 0.003
I0523 17:07:40.223320 19131 solver.cpp:237] Iteration 45750, loss = 1.16973
I0523 17:07:40.223368 19131 solver.cpp:253]     Train net output #0: loss = 1.16973 (* 1 = 1.16973 loss)
I0523 17:07:40.223386 19131 sgd_solver.cpp:106] Iteration 45750, lr = 0.003
I0523 17:07:49.239406 19131 solver.cpp:237] Iteration 46000, loss = 1.20713
I0523 17:07:49.239442 19131 solver.cpp:253]     Train net output #0: loss = 1.20713 (* 1 = 1.20713 loss)
I0523 17:07:49.239459 19131 sgd_solver.cpp:106] Iteration 46000, lr = 0.003
I0523 17:07:58.252650 19131 solver.cpp:237] Iteration 46250, loss = 1.13342
I0523 17:07:58.252686 19131 solver.cpp:253]     Train net output #0: loss = 1.13342 (* 1 = 1.13342 loss)
I0523 17:07:58.252702 19131 sgd_solver.cpp:106] Iteration 46250, lr = 0.003
I0523 17:08:07.262747 19131 solver.cpp:237] Iteration 46500, loss = 0.955115
I0523 17:08:07.262928 19131 solver.cpp:253]     Train net output #0: loss = 0.955115 (* 1 = 0.955115 loss)
I0523 17:08:07.262943 19131 sgd_solver.cpp:106] Iteration 46500, lr = 0.003
I0523 17:08:37.177513 19131 solver.cpp:237] Iteration 46750, loss = 1.00206
I0523 17:08:37.177563 19131 solver.cpp:253]     Train net output #0: loss = 1.00206 (* 1 = 1.00206 loss)
I0523 17:08:37.177580 19131 sgd_solver.cpp:106] Iteration 46750, lr = 0.003
I0523 17:08:46.183727 19131 solver.cpp:237] Iteration 47000, loss = 1.63061
I0523 17:08:46.183888 19131 solver.cpp:253]     Train net output #0: loss = 1.63061 (* 1 = 1.63061 loss)
I0523 17:08:46.183902 19131 sgd_solver.cpp:106] Iteration 47000, lr = 0.003
I0523 17:08:55.194943 19131 solver.cpp:237] Iteration 47250, loss = 1.09772
I0523 17:08:55.194984 19131 solver.cpp:253]     Train net output #0: loss = 1.09772 (* 1 = 1.09772 loss)
I0523 17:08:55.195003 19131 sgd_solver.cpp:106] Iteration 47250, lr = 0.003
I0523 17:09:04.167489 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_47500.caffemodel
I0523 17:09:04.232110 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_47500.solverstate
I0523 17:09:04.272280 19131 solver.cpp:237] Iteration 47500, loss = 1.36428
I0523 17:09:04.272330 19131 solver.cpp:253]     Train net output #0: loss = 1.36428 (* 1 = 1.36428 loss)
I0523 17:09:04.272344 19131 sgd_solver.cpp:106] Iteration 47500, lr = 0.003
I0523 17:09:13.279316 19131 solver.cpp:237] Iteration 47750, loss = 1.18565
I0523 17:09:13.279352 19131 solver.cpp:253]     Train net output #0: loss = 1.18565 (* 1 = 1.18565 loss)
I0523 17:09:13.279369 19131 sgd_solver.cpp:106] Iteration 47750, lr = 0.003
I0523 17:09:22.289029 19131 solver.cpp:237] Iteration 48000, loss = 1.61113
I0523 17:09:22.289204 19131 solver.cpp:253]     Train net output #0: loss = 1.61113 (* 1 = 1.61113 loss)
I0523 17:09:22.289219 19131 sgd_solver.cpp:106] Iteration 48000, lr = 0.003
I0523 17:09:31.300750 19131 solver.cpp:237] Iteration 48250, loss = 1.15164
I0523 17:09:31.300784 19131 solver.cpp:253]     Train net output #0: loss = 1.15164 (* 1 = 1.15164 loss)
I0523 17:09:31.300801 19131 sgd_solver.cpp:106] Iteration 48250, lr = 0.003
I0523 17:10:01.175019 19131 solver.cpp:237] Iteration 48500, loss = 1.01247
I0523 17:10:01.175197 19131 solver.cpp:253]     Train net output #0: loss = 1.01247 (* 1 = 1.01247 loss)
I0523 17:10:01.175212 19131 sgd_solver.cpp:106] Iteration 48500, lr = 0.003
I0523 17:10:10.189851 19131 solver.cpp:237] Iteration 48750, loss = 1.3997
I0523 17:10:10.189890 19131 solver.cpp:253]     Train net output #0: loss = 1.3997 (* 1 = 1.3997 loss)
I0523 17:10:10.189910 19131 sgd_solver.cpp:106] Iteration 48750, lr = 0.003
I0523 17:10:19.202251 19131 solver.cpp:237] Iteration 49000, loss = 1.24625
I0523 17:10:19.202286 19131 solver.cpp:253]     Train net output #0: loss = 1.24625 (* 1 = 1.24625 loss)
I0523 17:10:19.202302 19131 sgd_solver.cpp:106] Iteration 49000, lr = 0.003
I0523 17:10:28.213114 19131 solver.cpp:237] Iteration 49250, loss = 1.56261
I0523 17:10:28.213150 19131 solver.cpp:253]     Train net output #0: loss = 1.56261 (* 1 = 1.56261 loss)
I0523 17:10:28.213165 19131 sgd_solver.cpp:106] Iteration 49250, lr = 0.003
I0523 17:10:37.225122 19131 solver.cpp:237] Iteration 49500, loss = 1.03857
I0523 17:10:37.225306 19131 solver.cpp:253]     Train net output #0: loss = 1.03857 (* 1 = 1.03857 loss)
I0523 17:10:37.225320 19131 sgd_solver.cpp:106] Iteration 49500, lr = 0.003
I0523 17:10:46.245674 19131 solver.cpp:237] Iteration 49750, loss = 1.5049
I0523 17:10:46.245708 19131 solver.cpp:253]     Train net output #0: loss = 1.5049 (* 1 = 1.5049 loss)
I0523 17:10:46.245728 19131 sgd_solver.cpp:106] Iteration 49750, lr = 0.003
I0523 17:10:55.221349 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_50000.caffemodel
I0523 17:10:55.286990 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_50000.solverstate
I0523 17:10:55.315666 19131 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 17:12:03.498199 19131 solver.cpp:409]     Test net output #0: accuracy = 0.883106
I0523 17:12:03.498379 19131 solver.cpp:409]     Test net output #1: loss = 0.378635 (* 1 = 0.378635 loss)
I0523 17:12:24.345312 19131 solver.cpp:237] Iteration 50000, loss = 1.17667
I0523 17:12:24.345363 19131 solver.cpp:253]     Train net output #0: loss = 1.17667 (* 1 = 1.17667 loss)
I0523 17:12:24.345379 19131 sgd_solver.cpp:106] Iteration 50000, lr = 0.003
I0523 17:12:33.403563 19131 solver.cpp:237] Iteration 50250, loss = 1.14043
I0523 17:12:33.403599 19131 solver.cpp:253]     Train net output #0: loss = 1.14043 (* 1 = 1.14043 loss)
I0523 17:12:33.403615 19131 sgd_solver.cpp:106] Iteration 50250, lr = 0.003
I0523 17:12:42.489549 19131 solver.cpp:237] Iteration 50500, loss = 1.09845
I0523 17:12:42.489718 19131 solver.cpp:253]     Train net output #0: loss = 1.09845 (* 1 = 1.09845 loss)
I0523 17:12:42.489732 19131 sgd_solver.cpp:106] Iteration 50500, lr = 0.003
I0523 17:12:51.548094 19131 solver.cpp:237] Iteration 50750, loss = 1.43417
I0523 17:12:51.548127 19131 solver.cpp:253]     Train net output #0: loss = 1.43417 (* 1 = 1.43417 loss)
I0523 17:12:51.548146 19131 sgd_solver.cpp:106] Iteration 50750, lr = 0.003
I0523 17:13:00.619927 19131 solver.cpp:237] Iteration 51000, loss = 1.27029
I0523 17:13:00.619962 19131 solver.cpp:253]     Train net output #0: loss = 1.27029 (* 1 = 1.27029 loss)
I0523 17:13:00.619978 19131 sgd_solver.cpp:106] Iteration 51000, lr = 0.003
I0523 17:13:09.699067 19131 solver.cpp:237] Iteration 51250, loss = 1.29072
I0523 17:13:09.699105 19131 solver.cpp:253]     Train net output #0: loss = 1.29072 (* 1 = 1.29072 loss)
I0523 17:13:09.699126 19131 sgd_solver.cpp:106] Iteration 51250, lr = 0.003
I0523 17:13:18.774507 19131 solver.cpp:237] Iteration 51500, loss = 1.14153
I0523 17:13:18.774663 19131 solver.cpp:253]     Train net output #0: loss = 1.14153 (* 1 = 1.14153 loss)
I0523 17:13:18.774677 19131 sgd_solver.cpp:106] Iteration 51500, lr = 0.003
I0523 17:13:48.689347 19131 solver.cpp:237] Iteration 51750, loss = 1.04868
I0523 17:13:48.689398 19131 solver.cpp:253]     Train net output #0: loss = 1.04868 (* 1 = 1.04868 loss)
I0523 17:13:48.689414 19131 sgd_solver.cpp:106] Iteration 51750, lr = 0.003
I0523 17:13:57.764161 19131 solver.cpp:237] Iteration 52000, loss = 1.09469
I0523 17:13:57.764331 19131 solver.cpp:253]     Train net output #0: loss = 1.09469 (* 1 = 1.09469 loss)
I0523 17:13:57.764344 19131 sgd_solver.cpp:106] Iteration 52000, lr = 0.003
I0523 17:14:06.830312 19131 solver.cpp:237] Iteration 52250, loss = 1.31885
I0523 17:14:06.830345 19131 solver.cpp:253]     Train net output #0: loss = 1.31885 (* 1 = 1.31885 loss)
I0523 17:14:06.830363 19131 sgd_solver.cpp:106] Iteration 52250, lr = 0.003
I0523 17:14:15.860280 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_52500.caffemodel
I0523 17:14:15.923481 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_52500.solverstate
I0523 17:14:15.961283 19131 solver.cpp:237] Iteration 52500, loss = 1.04363
I0523 17:14:15.961324 19131 solver.cpp:253]     Train net output #0: loss = 1.04363 (* 1 = 1.04363 loss)
I0523 17:14:15.961341 19131 sgd_solver.cpp:106] Iteration 52500, lr = 0.003
I0523 17:14:25.020624 19131 solver.cpp:237] Iteration 52750, loss = 1.38968
I0523 17:14:25.020663 19131 solver.cpp:253]     Train net output #0: loss = 1.38968 (* 1 = 1.38968 loss)
I0523 17:14:25.020681 19131 sgd_solver.cpp:106] Iteration 52750, lr = 0.003
I0523 17:14:34.090966 19131 solver.cpp:237] Iteration 53000, loss = 0.823743
I0523 17:14:34.091135 19131 solver.cpp:253]     Train net output #0: loss = 0.823743 (* 1 = 0.823743 loss)
I0523 17:14:34.091150 19131 sgd_solver.cpp:106] Iteration 53000, lr = 0.003
I0523 17:14:43.153800 19131 solver.cpp:237] Iteration 53250, loss = 1.14209
I0523 17:14:43.153834 19131 solver.cpp:253]     Train net output #0: loss = 1.14209 (* 1 = 1.14209 loss)
I0523 17:14:43.153852 19131 sgd_solver.cpp:106] Iteration 53250, lr = 0.003
I0523 17:15:13.059691 19131 solver.cpp:237] Iteration 53500, loss = 1.19483
I0523 17:15:13.059867 19131 solver.cpp:253]     Train net output #0: loss = 1.19483 (* 1 = 1.19483 loss)
I0523 17:15:13.059882 19131 sgd_solver.cpp:106] Iteration 53500, lr = 0.003
I0523 17:15:22.141716 19131 solver.cpp:237] Iteration 53750, loss = 1.22867
I0523 17:15:22.141751 19131 solver.cpp:253]     Train net output #0: loss = 1.22867 (* 1 = 1.22867 loss)
I0523 17:15:22.141769 19131 sgd_solver.cpp:106] Iteration 53750, lr = 0.003
I0523 17:15:31.216032 19131 solver.cpp:237] Iteration 54000, loss = 1.25411
I0523 17:15:31.216066 19131 solver.cpp:253]     Train net output #0: loss = 1.25411 (* 1 = 1.25411 loss)
I0523 17:15:31.216083 19131 sgd_solver.cpp:106] Iteration 54000, lr = 0.003
I0523 17:15:40.286020 19131 solver.cpp:237] Iteration 54250, loss = 1.17385
I0523 17:15:40.286059 19131 solver.cpp:253]     Train net output #0: loss = 1.17385 (* 1 = 1.17385 loss)
I0523 17:15:40.286078 19131 sgd_solver.cpp:106] Iteration 54250, lr = 0.003
I0523 17:15:49.355216 19131 solver.cpp:237] Iteration 54500, loss = 1.27487
I0523 17:15:49.355370 19131 solver.cpp:253]     Train net output #0: loss = 1.27487 (* 1 = 1.27487 loss)
I0523 17:15:49.355384 19131 sgd_solver.cpp:106] Iteration 54500, lr = 0.003
I0523 17:15:58.405441 19131 solver.cpp:237] Iteration 54750, loss = 1.40037
I0523 17:15:58.405475 19131 solver.cpp:253]     Train net output #0: loss = 1.40037 (* 1 = 1.40037 loss)
I0523 17:15:58.405493 19131 sgd_solver.cpp:106] Iteration 54750, lr = 0.003
I0523 17:16:07.437465 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_55000.caffemodel
I0523 17:16:07.513908 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_55000.solverstate
I0523 17:16:07.540621 19131 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 17:16:54.525436 19131 solver.cpp:409]     Test net output #0: accuracy = 0.883527
I0523 17:16:54.525614 19131 solver.cpp:409]     Test net output #1: loss = 0.358159 (* 1 = 0.358159 loss)
I0523 17:17:15.347290 19131 solver.cpp:237] Iteration 55000, loss = 1.01195
I0523 17:17:15.347337 19131 solver.cpp:253]     Train net output #0: loss = 1.01195 (* 1 = 1.01195 loss)
I0523 17:17:15.347352 19131 sgd_solver.cpp:106] Iteration 55000, lr = 0.003
I0523 17:17:24.344993 19131 solver.cpp:237] Iteration 55250, loss = 1.09192
I0523 17:17:24.345024 19131 solver.cpp:253]     Train net output #0: loss = 1.09192 (* 1 = 1.09192 loss)
I0523 17:17:24.345038 19131 sgd_solver.cpp:106] Iteration 55250, lr = 0.003
I0523 17:17:33.342283 19131 solver.cpp:237] Iteration 55500, loss = 1.26116
I0523 17:17:33.342453 19131 solver.cpp:253]     Train net output #0: loss = 1.26116 (* 1 = 1.26116 loss)
I0523 17:17:33.342468 19131 sgd_solver.cpp:106] Iteration 55500, lr = 0.003
I0523 17:17:42.339794 19131 solver.cpp:237] Iteration 55750, loss = 1.27932
I0523 17:17:42.339835 19131 solver.cpp:253]     Train net output #0: loss = 1.27932 (* 1 = 1.27932 loss)
I0523 17:17:42.339848 19131 sgd_solver.cpp:106] Iteration 55750, lr = 0.003
I0523 17:17:51.333183 19131 solver.cpp:237] Iteration 56000, loss = 1.25611
I0523 17:17:51.333217 19131 solver.cpp:253]     Train net output #0: loss = 1.25611 (* 1 = 1.25611 loss)
I0523 17:17:51.333235 19131 sgd_solver.cpp:106] Iteration 56000, lr = 0.003
I0523 17:18:00.330713 19131 solver.cpp:237] Iteration 56250, loss = 1.41983
I0523 17:18:00.330749 19131 solver.cpp:253]     Train net output #0: loss = 1.41983 (* 1 = 1.41983 loss)
I0523 17:18:00.330765 19131 sgd_solver.cpp:106] Iteration 56250, lr = 0.003
I0523 17:18:09.325224 19131 solver.cpp:237] Iteration 56500, loss = 1.10102
I0523 17:18:09.325398 19131 solver.cpp:253]     Train net output #0: loss = 1.10102 (* 1 = 1.10102 loss)
I0523 17:18:09.325413 19131 sgd_solver.cpp:106] Iteration 56500, lr = 0.003
I0523 17:18:39.186272 19131 solver.cpp:237] Iteration 56750, loss = 1.44699
I0523 17:18:39.186322 19131 solver.cpp:253]     Train net output #0: loss = 1.44699 (* 1 = 1.44699 loss)
I0523 17:18:39.186341 19131 sgd_solver.cpp:106] Iteration 56750, lr = 0.003
I0523 17:18:48.186043 19131 solver.cpp:237] Iteration 57000, loss = 1.1963
I0523 17:18:48.186208 19131 solver.cpp:253]     Train net output #0: loss = 1.1963 (* 1 = 1.1963 loss)
I0523 17:18:48.186221 19131 sgd_solver.cpp:106] Iteration 57000, lr = 0.003
I0523 17:18:57.186501 19131 solver.cpp:237] Iteration 57250, loss = 1.06568
I0523 17:18:57.186545 19131 solver.cpp:253]     Train net output #0: loss = 1.06568 (* 1 = 1.06568 loss)
I0523 17:18:57.186563 19131 sgd_solver.cpp:106] Iteration 57250, lr = 0.003
I0523 17:19:06.147359 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_57500.caffemodel
I0523 17:19:06.210945 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_57500.solverstate
I0523 17:19:06.248783 19131 solver.cpp:237] Iteration 57500, loss = 1.19598
I0523 17:19:06.248828 19131 solver.cpp:253]     Train net output #0: loss = 1.19598 (* 1 = 1.19598 loss)
I0523 17:19:06.248843 19131 sgd_solver.cpp:106] Iteration 57500, lr = 0.003
I0523 17:19:15.242842 19131 solver.cpp:237] Iteration 57750, loss = 1.02217
I0523 17:19:15.242877 19131 solver.cpp:253]     Train net output #0: loss = 1.02217 (* 1 = 1.02217 loss)
I0523 17:19:15.242892 19131 sgd_solver.cpp:106] Iteration 57750, lr = 0.003
I0523 17:19:24.236140 19131 solver.cpp:237] Iteration 58000, loss = 1.1239
I0523 17:19:24.236310 19131 solver.cpp:253]     Train net output #0: loss = 1.1239 (* 1 = 1.1239 loss)
I0523 17:19:24.236325 19131 sgd_solver.cpp:106] Iteration 58000, lr = 0.003
I0523 17:19:33.228514 19131 solver.cpp:237] Iteration 58250, loss = 1.10949
I0523 17:19:33.228549 19131 solver.cpp:253]     Train net output #0: loss = 1.10949 (* 1 = 1.10949 loss)
I0523 17:19:33.228566 19131 sgd_solver.cpp:106] Iteration 58250, lr = 0.003
I0523 17:20:03.114965 19131 solver.cpp:237] Iteration 58500, loss = 1.25788
I0523 17:20:03.115144 19131 solver.cpp:253]     Train net output #0: loss = 1.25788 (* 1 = 1.25788 loss)
I0523 17:20:03.115159 19131 sgd_solver.cpp:106] Iteration 58500, lr = 0.003
I0523 17:20:12.116144 19131 solver.cpp:237] Iteration 58750, loss = 1.41694
I0523 17:20:12.116194 19131 solver.cpp:253]     Train net output #0: loss = 1.41694 (* 1 = 1.41694 loss)
I0523 17:20:12.116209 19131 sgd_solver.cpp:106] Iteration 58750, lr = 0.003
I0523 17:20:21.110585 19131 solver.cpp:237] Iteration 59000, loss = 1.28763
I0523 17:20:21.110622 19131 solver.cpp:253]     Train net output #0: loss = 1.28763 (* 1 = 1.28763 loss)
I0523 17:20:21.110638 19131 sgd_solver.cpp:106] Iteration 59000, lr = 0.003
I0523 17:20:30.112541 19131 solver.cpp:237] Iteration 59250, loss = 1.21009
I0523 17:20:30.112577 19131 solver.cpp:253]     Train net output #0: loss = 1.21009 (* 1 = 1.21009 loss)
I0523 17:20:30.112593 19131 sgd_solver.cpp:106] Iteration 59250, lr = 0.003
I0523 17:20:39.105911 19131 solver.cpp:237] Iteration 59500, loss = 1.20966
I0523 17:20:39.106092 19131 solver.cpp:253]     Train net output #0: loss = 1.20966 (* 1 = 1.20966 loss)
I0523 17:20:39.106107 19131 sgd_solver.cpp:106] Iteration 59500, lr = 0.003
I0523 17:20:48.104111 19131 solver.cpp:237] Iteration 59750, loss = 0.880786
I0523 17:20:48.104146 19131 solver.cpp:253]     Train net output #0: loss = 0.880786 (* 1 = 0.880786 loss)
I0523 17:20:48.104163 19131 sgd_solver.cpp:106] Iteration 59750, lr = 0.003
I0523 17:20:57.065901 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_60000.caffemodel
I0523 17:20:57.130218 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_60000.solverstate
I0523 17:20:57.156777 19131 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 17:22:05.311403 19131 solver.cpp:409]     Test net output #0: accuracy = 0.883687
I0523 17:22:05.311584 19131 solver.cpp:409]     Test net output #1: loss = 0.370616 (* 1 = 0.370616 loss)
I0523 17:22:26.177956 19131 solver.cpp:237] Iteration 60000, loss = 1.24567
I0523 17:22:26.178009 19131 solver.cpp:253]     Train net output #0: loss = 1.24567 (* 1 = 1.24567 loss)
I0523 17:22:26.178025 19131 sgd_solver.cpp:106] Iteration 60000, lr = 0.003
I0523 17:22:35.319008 19131 solver.cpp:237] Iteration 60250, loss = 1.40328
I0523 17:22:35.319175 19131 solver.cpp:253]     Train net output #0: loss = 1.40328 (* 1 = 1.40328 loss)
I0523 17:22:35.319188 19131 sgd_solver.cpp:106] Iteration 60250, lr = 0.003
I0523 17:22:44.454478 19131 solver.cpp:237] Iteration 60500, loss = 1.40813
I0523 17:22:44.454524 19131 solver.cpp:253]     Train net output #0: loss = 1.40813 (* 1 = 1.40813 loss)
I0523 17:22:44.454541 19131 sgd_solver.cpp:106] Iteration 60500, lr = 0.003
I0523 17:22:53.592883 19131 solver.cpp:237] Iteration 60750, loss = 1.10222
I0523 17:22:53.592917 19131 solver.cpp:253]     Train net output #0: loss = 1.10222 (* 1 = 1.10222 loss)
I0523 17:22:53.592934 19131 sgd_solver.cpp:106] Iteration 60750, lr = 0.003
I0523 17:23:02.725729 19131 solver.cpp:237] Iteration 61000, loss = 1.1725
I0523 17:23:02.725765 19131 solver.cpp:253]     Train net output #0: loss = 1.1725 (* 1 = 1.1725 loss)
I0523 17:23:02.725781 19131 sgd_solver.cpp:106] Iteration 61000, lr = 0.003
I0523 17:23:11.857980 19131 solver.cpp:237] Iteration 61250, loss = 1.14367
I0523 17:23:11.858150 19131 solver.cpp:253]     Train net output #0: loss = 1.14367 (* 1 = 1.14367 loss)
I0523 17:23:11.858163 19131 sgd_solver.cpp:106] Iteration 61250, lr = 0.003
I0523 17:23:20.992961 19131 solver.cpp:237] Iteration 61500, loss = 1.25138
I0523 17:23:20.992996 19131 solver.cpp:253]     Train net output #0: loss = 1.25138 (* 1 = 1.25138 loss)
I0523 17:23:20.993015 19131 sgd_solver.cpp:106] Iteration 61500, lr = 0.003
I0523 17:23:50.978471 19131 solver.cpp:237] Iteration 61750, loss = 0.823599
I0523 17:23:50.978652 19131 solver.cpp:253]     Train net output #0: loss = 0.823599 (* 1 = 0.823599 loss)
I0523 17:23:50.978667 19131 sgd_solver.cpp:106] Iteration 61750, lr = 0.003
I0523 17:24:00.112553 19131 solver.cpp:237] Iteration 62000, loss = 1.17334
I0523 17:24:00.112599 19131 solver.cpp:253]     Train net output #0: loss = 1.17334 (* 1 = 1.17334 loss)
I0523 17:24:00.112615 19131 sgd_solver.cpp:106] Iteration 62000, lr = 0.003
I0523 17:24:09.248394 19131 solver.cpp:237] Iteration 62250, loss = 1.21652
I0523 17:24:09.248430 19131 solver.cpp:253]     Train net output #0: loss = 1.21652 (* 1 = 1.21652 loss)
I0523 17:24:09.248445 19131 sgd_solver.cpp:106] Iteration 62250, lr = 0.003
I0523 17:24:18.350559 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_62500.caffemodel
I0523 17:24:18.416026 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_62500.solverstate
I0523 17:24:18.455775 19131 solver.cpp:237] Iteration 62500, loss = 1.17513
I0523 17:24:18.455823 19131 solver.cpp:253]     Train net output #0: loss = 1.17513 (* 1 = 1.17513 loss)
I0523 17:24:18.455838 19131 sgd_solver.cpp:106] Iteration 62500, lr = 0.003
I0523 17:24:27.588359 19131 solver.cpp:237] Iteration 62750, loss = 1.25532
I0523 17:24:27.588544 19131 solver.cpp:253]     Train net output #0: loss = 1.25532 (* 1 = 1.25532 loss)
I0523 17:24:27.588558 19131 sgd_solver.cpp:106] Iteration 62750, lr = 0.003
I0523 17:24:36.720142 19131 solver.cpp:237] Iteration 63000, loss = 1.53349
I0523 17:24:36.720177 19131 solver.cpp:253]     Train net output #0: loss = 1.53349 (* 1 = 1.53349 loss)
I0523 17:24:36.720196 19131 sgd_solver.cpp:106] Iteration 63000, lr = 0.003
I0523 17:24:45.850875 19131 solver.cpp:237] Iteration 63250, loss = 1.15516
I0523 17:24:45.850921 19131 solver.cpp:253]     Train net output #0: loss = 1.15516 (* 1 = 1.15516 loss)
I0523 17:24:45.850939 19131 sgd_solver.cpp:106] Iteration 63250, lr = 0.003
I0523 17:25:15.837971 19131 solver.cpp:237] Iteration 63500, loss = 1.32855
I0523 17:25:15.838157 19131 solver.cpp:253]     Train net output #0: loss = 1.32855 (* 1 = 1.32855 loss)
I0523 17:25:15.838171 19131 sgd_solver.cpp:106] Iteration 63500, lr = 0.003
I0523 17:25:24.974320 19131 solver.cpp:237] Iteration 63750, loss = 1.47315
I0523 17:25:24.974355 19131 solver.cpp:253]     Train net output #0: loss = 1.47315 (* 1 = 1.47315 loss)
I0523 17:25:24.974372 19131 sgd_solver.cpp:106] Iteration 63750, lr = 0.003
I0523 17:25:34.109540 19131 solver.cpp:237] Iteration 64000, loss = 1.16507
I0523 17:25:34.109586 19131 solver.cpp:253]     Train net output #0: loss = 1.16507 (* 1 = 1.16507 loss)
I0523 17:25:34.109603 19131 sgd_solver.cpp:106] Iteration 64000, lr = 0.003
I0523 17:25:43.245339 19131 solver.cpp:237] Iteration 64250, loss = 1.19926
I0523 17:25:43.245373 19131 solver.cpp:253]     Train net output #0: loss = 1.19926 (* 1 = 1.19926 loss)
I0523 17:25:43.245390 19131 sgd_solver.cpp:106] Iteration 64250, lr = 0.003
I0523 17:25:52.382024 19131 solver.cpp:237] Iteration 64500, loss = 1.13454
I0523 17:25:52.382184 19131 solver.cpp:253]     Train net output #0: loss = 1.13454 (* 1 = 1.13454 loss)
I0523 17:25:52.382196 19131 sgd_solver.cpp:106] Iteration 64500, lr = 0.003
I0523 17:26:01.509241 19131 solver.cpp:237] Iteration 64750, loss = 1.13278
I0523 17:26:01.509287 19131 solver.cpp:253]     Train net output #0: loss = 1.13278 (* 1 = 1.13278 loss)
I0523 17:26:01.509305 19131 sgd_solver.cpp:106] Iteration 64750, lr = 0.003
I0523 17:26:10.612756 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_65000.caffemodel
I0523 17:26:10.675784 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_65000.solverstate
I0523 17:26:10.701977 19131 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 17:26:57.987861 19131 solver.cpp:409]     Test net output #0: accuracy = 0.886573
I0523 17:26:57.988039 19131 solver.cpp:409]     Test net output #1: loss = 0.346465 (* 1 = 0.346465 loss)
I0523 17:27:18.888643 19131 solver.cpp:237] Iteration 65000, loss = 1.0696
I0523 17:27:18.888695 19131 solver.cpp:253]     Train net output #0: loss = 1.0696 (* 1 = 1.0696 loss)
I0523 17:27:18.888710 19131 sgd_solver.cpp:106] Iteration 65000, lr = 0.003
I0523 17:27:28.024047 19131 solver.cpp:237] Iteration 65250, loss = 0.858488
I0523 17:27:28.024220 19131 solver.cpp:253]     Train net output #0: loss = 0.858488 (* 1 = 0.858488 loss)
I0523 17:27:28.024235 19131 sgd_solver.cpp:106] Iteration 65250, lr = 0.003
I0523 17:27:37.148829 19131 solver.cpp:237] Iteration 65500, loss = 1.13181
I0523 17:27:37.148864 19131 solver.cpp:253]     Train net output #0: loss = 1.13181 (* 1 = 1.13181 loss)
I0523 17:27:37.148881 19131 sgd_solver.cpp:106] Iteration 65500, lr = 0.003
I0523 17:27:46.280489 19131 solver.cpp:237] Iteration 65750, loss = 1.07463
I0523 17:27:46.280534 19131 solver.cpp:253]     Train net output #0: loss = 1.07463 (* 1 = 1.07463 loss)
I0523 17:27:46.280550 19131 sgd_solver.cpp:106] Iteration 65750, lr = 0.003
I0523 17:27:55.410949 19131 solver.cpp:237] Iteration 66000, loss = 1.24344
I0523 17:27:55.410985 19131 solver.cpp:253]     Train net output #0: loss = 1.24344 (* 1 = 1.24344 loss)
I0523 17:27:55.411001 19131 sgd_solver.cpp:106] Iteration 66000, lr = 0.003
I0523 17:28:04.545967 19131 solver.cpp:237] Iteration 66250, loss = 1.36675
I0523 17:28:04.546142 19131 solver.cpp:253]     Train net output #0: loss = 1.36675 (* 1 = 1.36675 loss)
I0523 17:28:04.546156 19131 sgd_solver.cpp:106] Iteration 66250, lr = 0.003
I0523 17:28:13.679954 19131 solver.cpp:237] Iteration 66500, loss = 0.850421
I0523 17:28:13.679991 19131 solver.cpp:253]     Train net output #0: loss = 0.850421 (* 1 = 0.850421 loss)
I0523 17:28:13.680006 19131 sgd_solver.cpp:106] Iteration 66500, lr = 0.003
I0523 17:28:43.734107 19131 solver.cpp:237] Iteration 66750, loss = 1.16001
I0523 17:28:43.734287 19131 solver.cpp:253]     Train net output #0: loss = 1.16001 (* 1 = 1.16001 loss)
I0523 17:28:43.734302 19131 sgd_solver.cpp:106] Iteration 66750, lr = 0.003
I0523 17:28:52.864400 19131 solver.cpp:237] Iteration 67000, loss = 1.17122
I0523 17:28:52.864435 19131 solver.cpp:253]     Train net output #0: loss = 1.17122 (* 1 = 1.17122 loss)
I0523 17:28:52.864452 19131 sgd_solver.cpp:106] Iteration 67000, lr = 0.003
I0523 17:29:01.997429 19131 solver.cpp:237] Iteration 67250, loss = 1.1352
I0523 17:29:01.997467 19131 solver.cpp:253]     Train net output #0: loss = 1.1352 (* 1 = 1.1352 loss)
I0523 17:29:01.997486 19131 sgd_solver.cpp:106] Iteration 67250, lr = 0.003
I0523 17:29:11.101475 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_67500.caffemodel
I0523 17:29:11.165083 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_67500.solverstate
I0523 17:29:11.202564 19131 solver.cpp:237] Iteration 67500, loss = 1.29561
I0523 17:29:11.202601 19131 solver.cpp:253]     Train net output #0: loss = 1.29561 (* 1 = 1.29561 loss)
I0523 17:29:11.202620 19131 sgd_solver.cpp:106] Iteration 67500, lr = 0.003
I0523 17:29:20.345832 19131 solver.cpp:237] Iteration 67750, loss = 1.20441
I0523 17:29:20.346010 19131 solver.cpp:253]     Train net output #0: loss = 1.20441 (* 1 = 1.20441 loss)
I0523 17:29:20.346025 19131 sgd_solver.cpp:106] Iteration 67750, lr = 0.003
I0523 17:29:29.476214 19131 solver.cpp:237] Iteration 68000, loss = 1.3801
I0523 17:29:29.476249 19131 solver.cpp:253]     Train net output #0: loss = 1.3801 (* 1 = 1.3801 loss)
I0523 17:29:29.476266 19131 sgd_solver.cpp:106] Iteration 68000, lr = 0.003
I0523 17:29:38.601483 19131 solver.cpp:237] Iteration 68250, loss = 1.11057
I0523 17:29:38.601519 19131 solver.cpp:253]     Train net output #0: loss = 1.11057 (* 1 = 1.11057 loss)
I0523 17:29:38.601536 19131 sgd_solver.cpp:106] Iteration 68250, lr = 0.003
I0523 17:30:08.593567 19131 solver.cpp:237] Iteration 68500, loss = 1.32574
I0523 17:30:08.593751 19131 solver.cpp:253]     Train net output #0: loss = 1.32574 (* 1 = 1.32574 loss)
I0523 17:30:08.593766 19131 sgd_solver.cpp:106] Iteration 68500, lr = 0.003
I0523 17:30:17.717437 19131 solver.cpp:237] Iteration 68750, loss = 1.3262
I0523 17:30:17.717480 19131 solver.cpp:253]     Train net output #0: loss = 1.3262 (* 1 = 1.3262 loss)
I0523 17:30:17.717495 19131 sgd_solver.cpp:106] Iteration 68750, lr = 0.003
I0523 17:30:26.794823 19131 solver.cpp:237] Iteration 69000, loss = 0.981754
I0523 17:30:26.794860 19131 solver.cpp:253]     Train net output #0: loss = 0.981754 (* 1 = 0.981754 loss)
I0523 17:30:26.794877 19131 sgd_solver.cpp:106] Iteration 69000, lr = 0.003
I0523 17:30:35.853190 19131 solver.cpp:237] Iteration 69250, loss = 1.25432
I0523 17:30:35.853238 19131 solver.cpp:253]     Train net output #0: loss = 1.25432 (* 1 = 1.25432 loss)
I0523 17:30:35.853255 19131 sgd_solver.cpp:106] Iteration 69250, lr = 0.003
I0523 17:30:44.918467 19131 solver.cpp:237] Iteration 69500, loss = 0.982213
I0523 17:30:44.918643 19131 solver.cpp:253]     Train net output #0: loss = 0.982213 (* 1 = 0.982213 loss)
I0523 17:30:44.918658 19131 sgd_solver.cpp:106] Iteration 69500, lr = 0.003
I0523 17:30:53.989787 19131 solver.cpp:237] Iteration 69750, loss = 1.21944
I0523 17:30:53.989821 19131 solver.cpp:253]     Train net output #0: loss = 1.21944 (* 1 = 1.21944 loss)
I0523 17:30:53.989840 19131 sgd_solver.cpp:106] Iteration 69750, lr = 0.003
I0523 17:31:03.017238 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_70000.caffemodel
I0523 17:31:03.081099 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_70000.solverstate
I0523 17:31:03.107671 19131 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 17:32:11.336696 19131 solver.cpp:409]     Test net output #0: accuracy = 0.888592
I0523 17:32:11.336884 19131 solver.cpp:409]     Test net output #1: loss = 0.346131 (* 1 = 0.346131 loss)
I0523 17:32:32.207367 19131 solver.cpp:237] Iteration 70000, loss = 1.33749
I0523 17:32:32.207420 19131 solver.cpp:253]     Train net output #0: loss = 1.33749 (* 1 = 1.33749 loss)
I0523 17:32:32.207437 19131 sgd_solver.cpp:106] Iteration 70000, lr = 0.003
I0523 17:32:41.282764 19131 solver.cpp:237] Iteration 70250, loss = 1.22685
I0523 17:32:41.282807 19131 solver.cpp:253]     Train net output #0: loss = 1.22685 (* 1 = 1.22685 loss)
I0523 17:32:41.282825 19131 sgd_solver.cpp:106] Iteration 70250, lr = 0.003
I0523 17:32:50.365543 19131 solver.cpp:237] Iteration 70500, loss = 1.20455
I0523 17:32:50.365725 19131 solver.cpp:253]     Train net output #0: loss = 1.20455 (* 1 = 1.20455 loss)
I0523 17:32:50.365739 19131 sgd_solver.cpp:106] Iteration 70500, lr = 0.003
I0523 17:32:59.434442 19131 solver.cpp:237] Iteration 70750, loss = 1.21076
I0523 17:32:59.434476 19131 solver.cpp:253]     Train net output #0: loss = 1.21076 (* 1 = 1.21076 loss)
I0523 17:32:59.434494 19131 sgd_solver.cpp:106] Iteration 70750, lr = 0.003
I0523 17:33:08.508584 19131 solver.cpp:237] Iteration 71000, loss = 1.14729
I0523 17:33:08.508625 19131 solver.cpp:253]     Train net output #0: loss = 1.14729 (* 1 = 1.14729 loss)
I0523 17:33:08.508643 19131 sgd_solver.cpp:106] Iteration 71000, lr = 0.003
I0523 17:33:17.579402 19131 solver.cpp:237] Iteration 71250, loss = 0.962788
I0523 17:33:17.579438 19131 solver.cpp:253]     Train net output #0: loss = 0.962788 (* 1 = 0.962788 loss)
I0523 17:33:17.579454 19131 sgd_solver.cpp:106] Iteration 71250, lr = 0.003
I0523 17:33:26.658185 19131 solver.cpp:237] Iteration 71500, loss = 0.948818
I0523 17:33:26.658349 19131 solver.cpp:253]     Train net output #0: loss = 0.948818 (* 1 = 0.948818 loss)
I0523 17:33:26.658363 19131 sgd_solver.cpp:106] Iteration 71500, lr = 0.003
I0523 17:33:56.666373 19131 solver.cpp:237] Iteration 71750, loss = 1.08569
I0523 17:33:56.666554 19131 solver.cpp:253]     Train net output #0: loss = 1.08569 (* 1 = 1.08569 loss)
I0523 17:33:56.666569 19131 sgd_solver.cpp:106] Iteration 71750, lr = 0.003
I0523 17:34:05.743629 19131 solver.cpp:237] Iteration 72000, loss = 1.15172
I0523 17:34:05.743665 19131 solver.cpp:253]     Train net output #0: loss = 1.15172 (* 1 = 1.15172 loss)
I0523 17:34:05.743682 19131 sgd_solver.cpp:106] Iteration 72000, lr = 0.003
I0523 17:34:14.823561 19131 solver.cpp:237] Iteration 72250, loss = 1.30136
I0523 17:34:14.823598 19131 solver.cpp:253]     Train net output #0: loss = 1.30136 (* 1 = 1.30136 loss)
I0523 17:34:14.823614 19131 sgd_solver.cpp:106] Iteration 72250, lr = 0.003
I0523 17:34:23.859812 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_72500.caffemodel
I0523 17:34:23.925123 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_72500.solverstate
I0523 17:34:23.964957 19131 solver.cpp:237] Iteration 72500, loss = 1.1632
I0523 17:34:23.965009 19131 solver.cpp:253]     Train net output #0: loss = 1.1632 (* 1 = 1.1632 loss)
I0523 17:34:23.965023 19131 sgd_solver.cpp:106] Iteration 72500, lr = 0.003
I0523 17:34:33.041090 19131 solver.cpp:237] Iteration 72750, loss = 1.19727
I0523 17:34:33.041281 19131 solver.cpp:253]     Train net output #0: loss = 1.19727 (* 1 = 1.19727 loss)
I0523 17:34:33.041295 19131 sgd_solver.cpp:106] Iteration 72750, lr = 0.003
I0523 17:34:42.122480 19131 solver.cpp:237] Iteration 73000, loss = 1.81813
I0523 17:34:42.122515 19131 solver.cpp:253]     Train net output #0: loss = 1.81813 (* 1 = 1.81813 loss)
I0523 17:34:42.122532 19131 sgd_solver.cpp:106] Iteration 73000, lr = 0.003
I0523 17:34:51.204092 19131 solver.cpp:237] Iteration 73250, loss = 1.16603
I0523 17:34:51.204138 19131 solver.cpp:253]     Train net output #0: loss = 1.16603 (* 1 = 1.16603 loss)
I0523 17:34:51.204152 19131 sgd_solver.cpp:106] Iteration 73250, lr = 0.003
I0523 17:35:21.175544 19131 solver.cpp:237] Iteration 73500, loss = 1.05316
I0523 17:35:21.175732 19131 solver.cpp:253]     Train net output #0: loss = 1.05316 (* 1 = 1.05316 loss)
I0523 17:35:21.175747 19131 sgd_solver.cpp:106] Iteration 73500, lr = 0.003
I0523 17:35:30.247442 19131 solver.cpp:237] Iteration 73750, loss = 1.07762
I0523 17:35:30.247478 19131 solver.cpp:253]     Train net output #0: loss = 1.07762 (* 1 = 1.07762 loss)
I0523 17:35:30.247493 19131 sgd_solver.cpp:106] Iteration 73750, lr = 0.003
I0523 17:35:39.324823 19131 solver.cpp:237] Iteration 74000, loss = 1.29009
I0523 17:35:39.324868 19131 solver.cpp:253]     Train net output #0: loss = 1.29009 (* 1 = 1.29009 loss)
I0523 17:35:39.324885 19131 sgd_solver.cpp:106] Iteration 74000, lr = 0.003
I0523 17:35:48.411538 19131 solver.cpp:237] Iteration 74250, loss = 1.31958
I0523 17:35:48.411574 19131 solver.cpp:253]     Train net output #0: loss = 1.31958 (* 1 = 1.31958 loss)
I0523 17:35:48.411590 19131 sgd_solver.cpp:106] Iteration 74250, lr = 0.003
I0523 17:35:57.479020 19131 solver.cpp:237] Iteration 74500, loss = 1.06266
I0523 17:35:57.479183 19131 solver.cpp:253]     Train net output #0: loss = 1.06266 (* 1 = 1.06266 loss)
I0523 17:35:57.479198 19131 sgd_solver.cpp:106] Iteration 74500, lr = 0.003
I0523 17:36:06.563627 19131 solver.cpp:237] Iteration 74750, loss = 1.23254
I0523 17:36:06.563674 19131 solver.cpp:253]     Train net output #0: loss = 1.23254 (* 1 = 1.23254 loss)
I0523 17:36:06.563691 19131 sgd_solver.cpp:106] Iteration 74750, lr = 0.003
I0523 17:36:15.599126 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_75000.caffemodel
I0523 17:36:15.672197 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_75000.solverstate
I0523 17:36:15.700742 19131 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 17:37:02.738467 19131 solver.cpp:409]     Test net output #0: accuracy = 0.890106
I0523 17:37:02.738662 19131 solver.cpp:409]     Test net output #1: loss = 0.35504 (* 1 = 0.35504 loss)
I0523 17:37:23.646837 19131 solver.cpp:237] Iteration 75000, loss = 1.07969
I0523 17:37:23.646890 19131 solver.cpp:253]     Train net output #0: loss = 1.07969 (* 1 = 1.07969 loss)
I0523 17:37:23.646905 19131 sgd_solver.cpp:106] Iteration 75000, lr = 0.003
I0523 17:37:32.599948 19131 solver.cpp:237] Iteration 75250, loss = 1.09061
I0523 17:37:32.599983 19131 solver.cpp:253]     Train net output #0: loss = 1.09061 (* 1 = 1.09061 loss)
I0523 17:37:32.600000 19131 sgd_solver.cpp:106] Iteration 75250, lr = 0.003
I0523 17:37:41.563462 19131 solver.cpp:237] Iteration 75500, loss = 1.16153
I0523 17:37:41.563644 19131 solver.cpp:253]     Train net output #0: loss = 1.16153 (* 1 = 1.16153 loss)
I0523 17:37:41.563658 19131 sgd_solver.cpp:106] Iteration 75500, lr = 0.003
I0523 17:37:50.536104 19131 solver.cpp:237] Iteration 75750, loss = 1.15405
I0523 17:37:50.536140 19131 solver.cpp:253]     Train net output #0: loss = 1.15405 (* 1 = 1.15405 loss)
I0523 17:37:50.536154 19131 sgd_solver.cpp:106] Iteration 75750, lr = 0.003
I0523 17:37:59.506017 19131 solver.cpp:237] Iteration 76000, loss = 1.10254
I0523 17:37:59.506053 19131 solver.cpp:253]     Train net output #0: loss = 1.10254 (* 1 = 1.10254 loss)
I0523 17:37:59.506069 19131 sgd_solver.cpp:106] Iteration 76000, lr = 0.003
I0523 17:38:08.466193 19131 solver.cpp:237] Iteration 76250, loss = 1.20771
I0523 17:38:08.466240 19131 solver.cpp:253]     Train net output #0: loss = 1.20771 (* 1 = 1.20771 loss)
I0523 17:38:08.466258 19131 sgd_solver.cpp:106] Iteration 76250, lr = 0.003
I0523 17:38:17.429052 19131 solver.cpp:237] Iteration 76500, loss = 1.00858
I0523 17:38:17.429217 19131 solver.cpp:253]     Train net output #0: loss = 1.00858 (* 1 = 1.00858 loss)
I0523 17:38:17.429231 19131 sgd_solver.cpp:106] Iteration 76500, lr = 0.003
I0523 17:38:47.288081 19131 solver.cpp:237] Iteration 76750, loss = 0.999075
I0523 17:38:47.288132 19131 solver.cpp:253]     Train net output #0: loss = 0.999075 (* 1 = 0.999075 loss)
I0523 17:38:47.288148 19131 sgd_solver.cpp:106] Iteration 76750, lr = 0.003
I0523 17:38:56.260184 19131 solver.cpp:237] Iteration 77000, loss = 1.27789
I0523 17:38:56.260367 19131 solver.cpp:253]     Train net output #0: loss = 1.27789 (* 1 = 1.27789 loss)
I0523 17:38:56.260381 19131 sgd_solver.cpp:106] Iteration 77000, lr = 0.003
I0523 17:39:05.226271 19131 solver.cpp:237] Iteration 77250, loss = 1.10079
I0523 17:39:05.226308 19131 solver.cpp:253]     Train net output #0: loss = 1.10079 (* 1 = 1.10079 loss)
I0523 17:39:05.226325 19131 sgd_solver.cpp:106] Iteration 77250, lr = 0.003
I0523 17:39:14.164067 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_77500.caffemodel
I0523 17:39:14.227149 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_77500.solverstate
I0523 17:39:14.264840 19131 solver.cpp:237] Iteration 77500, loss = 1.15953
I0523 17:39:14.264885 19131 solver.cpp:253]     Train net output #0: loss = 1.15953 (* 1 = 1.15953 loss)
I0523 17:39:14.264902 19131 sgd_solver.cpp:106] Iteration 77500, lr = 0.003
I0523 17:39:23.231613 19131 solver.cpp:237] Iteration 77750, loss = 1.35699
I0523 17:39:23.231660 19131 solver.cpp:253]     Train net output #0: loss = 1.35699 (* 1 = 1.35699 loss)
I0523 17:39:23.231675 19131 sgd_solver.cpp:106] Iteration 77750, lr = 0.003
I0523 17:39:32.203477 19131 solver.cpp:237] Iteration 78000, loss = 1.23392
I0523 17:39:32.203647 19131 solver.cpp:253]     Train net output #0: loss = 1.23392 (* 1 = 1.23392 loss)
I0523 17:39:32.203660 19131 sgd_solver.cpp:106] Iteration 78000, lr = 0.003
I0523 17:39:41.167776 19131 solver.cpp:237] Iteration 78250, loss = 1.19001
I0523 17:39:41.167812 19131 solver.cpp:253]     Train net output #0: loss = 1.19001 (* 1 = 1.19001 loss)
I0523 17:39:41.167829 19131 sgd_solver.cpp:106] Iteration 78250, lr = 0.003
I0523 17:40:11.002614 19131 solver.cpp:237] Iteration 78500, loss = 1.10881
I0523 17:40:11.002815 19131 solver.cpp:253]     Train net output #0: loss = 1.10881 (* 1 = 1.10881 loss)
I0523 17:40:11.002830 19131 sgd_solver.cpp:106] Iteration 78500, lr = 0.003
I0523 17:40:19.964588 19131 solver.cpp:237] Iteration 78750, loss = 1.14549
I0523 17:40:19.964623 19131 solver.cpp:253]     Train net output #0: loss = 1.14549 (* 1 = 1.14549 loss)
I0523 17:40:19.964640 19131 sgd_solver.cpp:106] Iteration 78750, lr = 0.003
I0523 17:40:28.926651 19131 solver.cpp:237] Iteration 79000, loss = 1.28184
I0523 17:40:28.926686 19131 solver.cpp:253]     Train net output #0: loss = 1.28184 (* 1 = 1.28184 loss)
I0523 17:40:28.926707 19131 sgd_solver.cpp:106] Iteration 79000, lr = 0.003
I0523 17:40:37.889950 19131 solver.cpp:237] Iteration 79250, loss = 1.04507
I0523 17:40:37.889991 19131 solver.cpp:253]     Train net output #0: loss = 1.04507 (* 1 = 1.04507 loss)
I0523 17:40:37.890010 19131 sgd_solver.cpp:106] Iteration 79250, lr = 0.003
I0523 17:40:46.859601 19131 solver.cpp:237] Iteration 79500, loss = 1.23856
I0523 17:40:46.859767 19131 solver.cpp:253]     Train net output #0: loss = 1.23856 (* 1 = 1.23856 loss)
I0523 17:40:46.859781 19131 sgd_solver.cpp:106] Iteration 79500, lr = 0.003
I0523 17:40:55.821984 19131 solver.cpp:237] Iteration 79750, loss = 1.1697
I0523 17:40:55.822019 19131 solver.cpp:253]     Train net output #0: loss = 1.1697 (* 1 = 1.1697 loss)
I0523 17:40:55.822034 19131 sgd_solver.cpp:106] Iteration 79750, lr = 0.003
I0523 17:41:04.748266 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_80000.caffemodel
I0523 17:41:04.811800 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_80000.solverstate
I0523 17:41:04.838390 19131 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 17:42:13.088855 19131 solver.cpp:409]     Test net output #0: accuracy = 0.892179
I0523 17:42:13.089043 19131 solver.cpp:409]     Test net output #1: loss = 0.33145 (* 1 = 0.33145 loss)
I0523 17:42:33.993688 19131 solver.cpp:237] Iteration 80000, loss = 1.0005
I0523 17:42:33.993741 19131 solver.cpp:253]     Train net output #0: loss = 1.0005 (* 1 = 1.0005 loss)
I0523 17:42:33.993755 19131 sgd_solver.cpp:106] Iteration 80000, lr = 0.003
I0523 17:42:43.024111 19131 solver.cpp:237] Iteration 80250, loss = 1.14544
I0523 17:42:43.024149 19131 solver.cpp:253]     Train net output #0: loss = 1.14544 (* 1 = 1.14544 loss)
I0523 17:42:43.024170 19131 sgd_solver.cpp:106] Iteration 80250, lr = 0.003
I0523 17:42:52.056952 19131 solver.cpp:237] Iteration 80500, loss = 1.09378
I0523 17:42:52.057126 19131 solver.cpp:253]     Train net output #0: loss = 1.09378 (* 1 = 1.09378 loss)
I0523 17:42:52.057140 19131 sgd_solver.cpp:106] Iteration 80500, lr = 0.003
I0523 17:43:01.086673 19131 solver.cpp:237] Iteration 80750, loss = 0.988574
I0523 17:43:01.086714 19131 solver.cpp:253]     Train net output #0: loss = 0.988574 (* 1 = 0.988574 loss)
I0523 17:43:01.086729 19131 sgd_solver.cpp:106] Iteration 80750, lr = 0.003
I0523 17:43:10.116613 19131 solver.cpp:237] Iteration 81000, loss = 1.23052
I0523 17:43:10.116654 19131 solver.cpp:253]     Train net output #0: loss = 1.23052 (* 1 = 1.23052 loss)
I0523 17:43:10.116674 19131 sgd_solver.cpp:106] Iteration 81000, lr = 0.003
I0523 17:43:19.154640 19131 solver.cpp:237] Iteration 81250, loss = 1.37549
I0523 17:43:19.154675 19131 solver.cpp:253]     Train net output #0: loss = 1.37549 (* 1 = 1.37549 loss)
I0523 17:43:19.154693 19131 sgd_solver.cpp:106] Iteration 81250, lr = 0.003
I0523 17:43:28.190397 19131 solver.cpp:237] Iteration 81500, loss = 1.02809
I0523 17:43:28.190577 19131 solver.cpp:253]     Train net output #0: loss = 1.02809 (* 1 = 1.02809 loss)
I0523 17:43:28.190590 19131 sgd_solver.cpp:106] Iteration 81500, lr = 0.003
I0523 17:43:58.122114 19131 solver.cpp:237] Iteration 81750, loss = 1.3877
I0523 17:43:58.122162 19131 solver.cpp:253]     Train net output #0: loss = 1.3877 (* 1 = 1.3877 loss)
I0523 17:43:58.122181 19131 sgd_solver.cpp:106] Iteration 81750, lr = 0.003
I0523 17:44:07.151530 19131 solver.cpp:237] Iteration 82000, loss = 0.96531
I0523 17:44:07.151715 19131 solver.cpp:253]     Train net output #0: loss = 0.96531 (* 1 = 0.96531 loss)
I0523 17:44:07.151729 19131 sgd_solver.cpp:106] Iteration 82000, lr = 0.003
I0523 17:44:16.183564 19131 solver.cpp:237] Iteration 82250, loss = 1.45111
I0523 17:44:16.183600 19131 solver.cpp:253]     Train net output #0: loss = 1.45111 (* 1 = 1.45111 loss)
I0523 17:44:16.183616 19131 sgd_solver.cpp:106] Iteration 82250, lr = 0.003
I0523 17:44:25.187068 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_82500.caffemodel
I0523 17:44:25.250044 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_82500.solverstate
I0523 17:44:25.287875 19131 solver.cpp:237] Iteration 82500, loss = 1.22659
I0523 17:44:25.287916 19131 solver.cpp:253]     Train net output #0: loss = 1.22659 (* 1 = 1.22659 loss)
I0523 17:44:25.287935 19131 sgd_solver.cpp:106] Iteration 82500, lr = 0.003
I0523 17:44:34.317451 19131 solver.cpp:237] Iteration 82750, loss = 1.13598
I0523 17:44:34.317487 19131 solver.cpp:253]     Train net output #0: loss = 1.13598 (* 1 = 1.13598 loss)
I0523 17:44:34.317503 19131 sgd_solver.cpp:106] Iteration 82750, lr = 0.003
I0523 17:44:43.347970 19131 solver.cpp:237] Iteration 83000, loss = 0.935278
I0523 17:44:43.348145 19131 solver.cpp:253]     Train net output #0: loss = 0.935278 (* 1 = 0.935278 loss)
I0523 17:44:43.348158 19131 sgd_solver.cpp:106] Iteration 83000, lr = 0.003
I0523 17:44:52.389508 19131 solver.cpp:237] Iteration 83250, loss = 1.23879
I0523 17:44:52.389550 19131 solver.cpp:253]     Train net output #0: loss = 1.23879 (* 1 = 1.23879 loss)
I0523 17:44:52.389570 19131 sgd_solver.cpp:106] Iteration 83250, lr = 0.003
I0523 17:45:22.309438 19131 solver.cpp:237] Iteration 83500, loss = 1.0744
I0523 17:45:22.309629 19131 solver.cpp:253]     Train net output #0: loss = 1.0744 (* 1 = 1.0744 loss)
I0523 17:45:22.309646 19131 sgd_solver.cpp:106] Iteration 83500, lr = 0.003
I0523 17:45:31.340071 19131 solver.cpp:237] Iteration 83750, loss = 1.15205
I0523 17:45:31.340107 19131 solver.cpp:253]     Train net output #0: loss = 1.15205 (* 1 = 1.15205 loss)
I0523 17:45:31.340121 19131 sgd_solver.cpp:106] Iteration 83750, lr = 0.003
I0523 17:45:40.365228 19131 solver.cpp:237] Iteration 84000, loss = 1.15336
I0523 17:45:40.365278 19131 solver.cpp:253]     Train net output #0: loss = 1.15336 (* 1 = 1.15336 loss)
I0523 17:45:40.365294 19131 sgd_solver.cpp:106] Iteration 84000, lr = 0.003
I0523 17:45:49.396823 19131 solver.cpp:237] Iteration 84250, loss = 1.00545
I0523 17:45:49.396859 19131 solver.cpp:253]     Train net output #0: loss = 1.00545 (* 1 = 1.00545 loss)
I0523 17:45:49.396873 19131 sgd_solver.cpp:106] Iteration 84250, lr = 0.003
I0523 17:45:58.432580 19131 solver.cpp:237] Iteration 84500, loss = 1.19563
I0523 17:45:58.432751 19131 solver.cpp:253]     Train net output #0: loss = 1.19563 (* 1 = 1.19563 loss)
I0523 17:45:58.432766 19131 sgd_solver.cpp:106] Iteration 84500, lr = 0.003
I0523 17:46:07.468870 19131 solver.cpp:237] Iteration 84750, loss = 1.06876
I0523 17:46:07.468910 19131 solver.cpp:253]     Train net output #0: loss = 1.06876 (* 1 = 1.06876 loss)
I0523 17:46:07.468929 19131 sgd_solver.cpp:106] Iteration 84750, lr = 0.003
I0523 17:46:16.468863 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_85000.caffemodel
I0523 17:46:16.532258 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_85000.solverstate
I0523 17:46:16.558822 19131 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 17:47:03.948988 19131 solver.cpp:409]     Test net output #0: accuracy = 0.890093
I0523 17:47:03.949187 19131 solver.cpp:409]     Test net output #1: loss = 0.375713 (* 1 = 0.375713 loss)
I0523 17:47:24.858513 19131 solver.cpp:237] Iteration 85000, loss = 1.20359
I0523 17:47:24.858566 19131 solver.cpp:253]     Train net output #0: loss = 1.20359 (* 1 = 1.20359 loss)
I0523 17:47:24.858582 19131 sgd_solver.cpp:106] Iteration 85000, lr = 0.003
I0523 17:47:33.849900 19131 solver.cpp:237] Iteration 85250, loss = 1.26389
I0523 17:47:33.849936 19131 solver.cpp:253]     Train net output #0: loss = 1.26389 (* 1 = 1.26389 loss)
I0523 17:47:33.849953 19131 sgd_solver.cpp:106] Iteration 85250, lr = 0.003
I0523 17:47:42.846818 19131 solver.cpp:237] Iteration 85500, loss = 1.46495
I0523 17:47:42.847007 19131 solver.cpp:253]     Train net output #0: loss = 1.46495 (* 1 = 1.46495 loss)
I0523 17:47:42.847020 19131 sgd_solver.cpp:106] Iteration 85500, lr = 0.003
I0523 17:47:51.836762 19131 solver.cpp:237] Iteration 85750, loss = 1.16819
I0523 17:47:51.836797 19131 solver.cpp:253]     Train net output #0: loss = 1.16819 (* 1 = 1.16819 loss)
I0523 17:47:51.836814 19131 sgd_solver.cpp:106] Iteration 85750, lr = 0.003
I0523 17:48:00.826617 19131 solver.cpp:237] Iteration 86000, loss = 1.23637
I0523 17:48:00.826653 19131 solver.cpp:253]     Train net output #0: loss = 1.23637 (* 1 = 1.23637 loss)
I0523 17:48:00.826668 19131 sgd_solver.cpp:106] Iteration 86000, lr = 0.003
I0523 17:48:09.817706 19131 solver.cpp:237] Iteration 86250, loss = 1.31283
I0523 17:48:09.817744 19131 solver.cpp:253]     Train net output #0: loss = 1.31283 (* 1 = 1.31283 loss)
I0523 17:48:09.817765 19131 sgd_solver.cpp:106] Iteration 86250, lr = 0.003
I0523 17:48:18.813664 19131 solver.cpp:237] Iteration 86500, loss = 1.28545
I0523 17:48:18.813828 19131 solver.cpp:253]     Train net output #0: loss = 1.28545 (* 1 = 1.28545 loss)
I0523 17:48:18.813841 19131 sgd_solver.cpp:106] Iteration 86500, lr = 0.003
I0523 17:48:48.732692 19131 solver.cpp:237] Iteration 86750, loss = 1.0204
I0523 17:48:48.732743 19131 solver.cpp:253]     Train net output #0: loss = 1.0204 (* 1 = 1.0204 loss)
I0523 17:48:48.732759 19131 sgd_solver.cpp:106] Iteration 86750, lr = 0.003
I0523 17:48:57.736467 19131 solver.cpp:237] Iteration 87000, loss = 1.16648
I0523 17:48:57.736652 19131 solver.cpp:253]     Train net output #0: loss = 1.16648 (* 1 = 1.16648 loss)
I0523 17:48:57.736665 19131 sgd_solver.cpp:106] Iteration 87000, lr = 0.003
I0523 17:49:06.734563 19131 solver.cpp:237] Iteration 87250, loss = 1.05067
I0523 17:49:06.734597 19131 solver.cpp:253]     Train net output #0: loss = 1.05067 (* 1 = 1.05067 loss)
I0523 17:49:06.734616 19131 sgd_solver.cpp:106] Iteration 87250, lr = 0.003
I0523 17:49:15.686704 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_87500.caffemodel
I0523 17:49:15.751019 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_87500.solverstate
I0523 17:49:15.791180 19131 solver.cpp:237] Iteration 87500, loss = 1.60571
I0523 17:49:15.791226 19131 solver.cpp:253]     Train net output #0: loss = 1.60571 (* 1 = 1.60571 loss)
I0523 17:49:15.791247 19131 sgd_solver.cpp:106] Iteration 87500, lr = 0.003
I0523 17:49:24.792953 19131 solver.cpp:237] Iteration 87750, loss = 0.942745
I0523 17:49:24.792991 19131 solver.cpp:253]     Train net output #0: loss = 0.942745 (* 1 = 0.942745 loss)
I0523 17:49:24.793014 19131 sgd_solver.cpp:106] Iteration 87750, lr = 0.003
I0523 17:49:33.790334 19131 solver.cpp:237] Iteration 88000, loss = 1.19901
I0523 17:49:33.790518 19131 solver.cpp:253]     Train net output #0: loss = 1.19901 (* 1 = 1.19901 loss)
I0523 17:49:33.790531 19131 sgd_solver.cpp:106] Iteration 88000, lr = 0.003
I0523 17:49:42.780351 19131 solver.cpp:237] Iteration 88250, loss = 1.2255
I0523 17:49:42.780386 19131 solver.cpp:253]     Train net output #0: loss = 1.2255 (* 1 = 1.2255 loss)
I0523 17:49:42.780403 19131 sgd_solver.cpp:106] Iteration 88250, lr = 0.003
I0523 17:50:12.669782 19131 solver.cpp:237] Iteration 88500, loss = 1.09247
I0523 17:50:12.669973 19131 solver.cpp:253]     Train net output #0: loss = 1.09247 (* 1 = 1.09247 loss)
I0523 17:50:12.669988 19131 sgd_solver.cpp:106] Iteration 88500, lr = 0.003
I0523 17:50:21.669392 19131 solver.cpp:237] Iteration 88750, loss = 1.13102
I0523 17:50:21.669427 19131 solver.cpp:253]     Train net output #0: loss = 1.13102 (* 1 = 1.13102 loss)
I0523 17:50:21.669445 19131 sgd_solver.cpp:106] Iteration 88750, lr = 0.003
I0523 17:50:30.664870 19131 solver.cpp:237] Iteration 89000, loss = 1.3737
I0523 17:50:30.664906 19131 solver.cpp:253]     Train net output #0: loss = 1.3737 (* 1 = 1.3737 loss)
I0523 17:50:30.664921 19131 sgd_solver.cpp:106] Iteration 89000, lr = 0.003
I0523 17:50:39.662864 19131 solver.cpp:237] Iteration 89250, loss = 1.32902
I0523 17:50:39.662904 19131 solver.cpp:253]     Train net output #0: loss = 1.32902 (* 1 = 1.32902 loss)
I0523 17:50:39.662919 19131 sgd_solver.cpp:106] Iteration 89250, lr = 0.003
I0523 17:50:48.658987 19131 solver.cpp:237] Iteration 89500, loss = 1.08263
I0523 17:50:48.659152 19131 solver.cpp:253]     Train net output #0: loss = 1.08263 (* 1 = 1.08263 loss)
I0523 17:50:48.659168 19131 sgd_solver.cpp:106] Iteration 89500, lr = 0.003
I0523 17:50:57.650807 19131 solver.cpp:237] Iteration 89750, loss = 0.990183
I0523 17:50:57.650842 19131 solver.cpp:253]     Train net output #0: loss = 0.990183 (* 1 = 0.990183 loss)
I0523 17:50:57.650861 19131 sgd_solver.cpp:106] Iteration 89750, lr = 0.003
I0523 17:51:06.609102 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_90000.caffemodel
I0523 17:51:06.674996 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_90000.solverstate
I0523 17:51:06.707062 19131 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 17:52:14.916988 19131 solver.cpp:409]     Test net output #0: accuracy = 0.89404
I0523 17:52:14.917176 19131 solver.cpp:409]     Test net output #1: loss = 0.330257 (* 1 = 0.330257 loss)
I0523 17:52:35.793449 19131 solver.cpp:237] Iteration 90000, loss = 1.05631
I0523 17:52:35.793503 19131 solver.cpp:253]     Train net output #0: loss = 1.05631 (* 1 = 1.05631 loss)
I0523 17:52:35.793517 19131 sgd_solver.cpp:106] Iteration 90000, lr = 0.003
I0523 17:52:44.882588 19131 solver.cpp:237] Iteration 90250, loss = 1.08853
I0523 17:52:44.882632 19131 solver.cpp:253]     Train net output #0: loss = 1.08853 (* 1 = 1.08853 loss)
I0523 17:52:44.882649 19131 sgd_solver.cpp:106] Iteration 90250, lr = 0.003
I0523 17:52:53.980238 19131 solver.cpp:237] Iteration 90500, loss = 1.35608
I0523 17:52:53.980413 19131 solver.cpp:253]     Train net output #0: loss = 1.35608 (* 1 = 1.35608 loss)
I0523 17:52:53.980427 19131 sgd_solver.cpp:106] Iteration 90500, lr = 0.003
I0523 17:53:03.063222 19131 solver.cpp:237] Iteration 90750, loss = 1.20753
I0523 17:53:03.063257 19131 solver.cpp:253]     Train net output #0: loss = 1.20753 (* 1 = 1.20753 loss)
I0523 17:53:03.063274 19131 sgd_solver.cpp:106] Iteration 90750, lr = 0.003
I0523 17:53:12.156666 19131 solver.cpp:237] Iteration 91000, loss = 1.01561
I0523 17:53:12.156713 19131 solver.cpp:253]     Train net output #0: loss = 1.01561 (* 1 = 1.01561 loss)
I0523 17:53:12.156728 19131 sgd_solver.cpp:106] Iteration 91000, lr = 0.003
I0523 17:53:21.251102 19131 solver.cpp:237] Iteration 91250, loss = 1.38234
I0523 17:53:21.251137 19131 solver.cpp:253]     Train net output #0: loss = 1.38234 (* 1 = 1.38234 loss)
I0523 17:53:21.251153 19131 sgd_solver.cpp:106] Iteration 91250, lr = 0.003
I0523 17:53:30.345839 19131 solver.cpp:237] Iteration 91500, loss = 0.881711
I0523 17:53:30.346030 19131 solver.cpp:253]     Train net output #0: loss = 0.881711 (* 1 = 0.881711 loss)
I0523 17:53:30.346045 19131 sgd_solver.cpp:106] Iteration 91500, lr = 0.003
I0523 17:54:00.309110 19131 solver.cpp:237] Iteration 91750, loss = 1.37795
I0523 17:54:00.309160 19131 solver.cpp:253]     Train net output #0: loss = 1.37795 (* 1 = 1.37795 loss)
I0523 17:54:00.309177 19131 sgd_solver.cpp:106] Iteration 91750, lr = 0.003
I0523 17:54:09.400235 19131 solver.cpp:237] Iteration 92000, loss = 0.963158
I0523 17:54:09.400411 19131 solver.cpp:253]     Train net output #0: loss = 0.963158 (* 1 = 0.963158 loss)
I0523 17:54:09.400425 19131 sgd_solver.cpp:106] Iteration 92000, lr = 0.003
I0523 17:54:18.494997 19131 solver.cpp:237] Iteration 92250, loss = 1.06981
I0523 17:54:18.495033 19131 solver.cpp:253]     Train net output #0: loss = 1.06981 (* 1 = 1.06981 loss)
I0523 17:54:18.495050 19131 sgd_solver.cpp:106] Iteration 92250, lr = 0.003
I0523 17:54:27.548511 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_92500.caffemodel
I0523 17:54:27.612236 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_92500.solverstate
I0523 17:54:27.650243 19131 solver.cpp:237] Iteration 92500, loss = 0.942137
I0523 17:54:27.650285 19131 solver.cpp:253]     Train net output #0: loss = 0.942137 (* 1 = 0.942137 loss)
I0523 17:54:27.650302 19131 sgd_solver.cpp:106] Iteration 92500, lr = 0.003
I0523 17:54:36.740383 19131 solver.cpp:237] Iteration 92750, loss = 1.30424
I0523 17:54:36.740419 19131 solver.cpp:253]     Train net output #0: loss = 1.30424 (* 1 = 1.30424 loss)
I0523 17:54:36.740435 19131 sgd_solver.cpp:106] Iteration 92750, lr = 0.003
I0523 17:54:45.833300 19131 solver.cpp:237] Iteration 93000, loss = 1.09289
I0523 17:54:45.833489 19131 solver.cpp:253]     Train net output #0: loss = 1.09289 (* 1 = 1.09289 loss)
I0523 17:54:45.833504 19131 sgd_solver.cpp:106] Iteration 93000, lr = 0.003
I0523 17:54:54.921305 19131 solver.cpp:237] Iteration 93250, loss = 1.16657
I0523 17:54:54.921340 19131 solver.cpp:253]     Train net output #0: loss = 1.16657 (* 1 = 1.16657 loss)
I0523 17:54:54.921358 19131 sgd_solver.cpp:106] Iteration 93250, lr = 0.003
I0523 17:55:24.911047 19131 solver.cpp:237] Iteration 93500, loss = 0.952064
I0523 17:55:24.911242 19131 solver.cpp:253]     Train net output #0: loss = 0.952064 (* 1 = 0.952064 loss)
I0523 17:55:24.911257 19131 sgd_solver.cpp:106] Iteration 93500, lr = 0.003
I0523 17:55:33.999150 19131 solver.cpp:237] Iteration 93750, loss = 1.28359
I0523 17:55:33.999196 19131 solver.cpp:253]     Train net output #0: loss = 1.28359 (* 1 = 1.28359 loss)
I0523 17:55:33.999214 19131 sgd_solver.cpp:106] Iteration 93750, lr = 0.003
I0523 17:55:43.100725 19131 solver.cpp:237] Iteration 94000, loss = 1.11862
I0523 17:55:43.100761 19131 solver.cpp:253]     Train net output #0: loss = 1.11862 (* 1 = 1.11862 loss)
I0523 17:55:43.100777 19131 sgd_solver.cpp:106] Iteration 94000, lr = 0.003
I0523 17:55:52.197854 19131 solver.cpp:237] Iteration 94250, loss = 1.32525
I0523 17:55:52.197890 19131 solver.cpp:253]     Train net output #0: loss = 1.32525 (* 1 = 1.32525 loss)
I0523 17:55:52.197906 19131 sgd_solver.cpp:106] Iteration 94250, lr = 0.003
I0523 17:56:01.294320 19131 solver.cpp:237] Iteration 94500, loss = 1.27429
I0523 17:56:01.294502 19131 solver.cpp:253]     Train net output #0: loss = 1.27429 (* 1 = 1.27429 loss)
I0523 17:56:01.294517 19131 sgd_solver.cpp:106] Iteration 94500, lr = 0.003
I0523 17:56:10.384308 19131 solver.cpp:237] Iteration 94750, loss = 1.23836
I0523 17:56:10.384343 19131 solver.cpp:253]     Train net output #0: loss = 1.23836 (* 1 = 1.23836 loss)
I0523 17:56:10.384361 19131 sgd_solver.cpp:106] Iteration 94750, lr = 0.003
I0523 17:56:19.434202 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_95000.caffemodel
I0523 17:56:19.508318 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_95000.solverstate
I0523 17:56:19.535162 19131 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 17:57:06.541370 19131 solver.cpp:409]     Test net output #0: accuracy = 0.892345
I0523 17:57:06.541580 19131 solver.cpp:409]     Test net output #1: loss = 0.342827 (* 1 = 0.342827 loss)
I0523 17:57:27.444979 19131 solver.cpp:237] Iteration 95000, loss = 1.29172
I0523 17:57:27.445034 19131 solver.cpp:253]     Train net output #0: loss = 1.29172 (* 1 = 1.29172 loss)
I0523 17:57:27.445050 19131 sgd_solver.cpp:106] Iteration 95000, lr = 0.003
I0523 17:57:36.518046 19131 solver.cpp:237] Iteration 95250, loss = 1.18952
I0523 17:57:36.518082 19131 solver.cpp:253]     Train net output #0: loss = 1.18952 (* 1 = 1.18952 loss)
I0523 17:57:36.518098 19131 sgd_solver.cpp:106] Iteration 95250, lr = 0.003
I0523 17:57:45.579066 19131 solver.cpp:237] Iteration 95500, loss = 1.00747
I0523 17:57:45.579251 19131 solver.cpp:253]     Train net output #0: loss = 1.00747 (* 1 = 1.00747 loss)
I0523 17:57:45.579264 19131 sgd_solver.cpp:106] Iteration 95500, lr = 0.003
I0523 17:57:54.644527 19131 solver.cpp:237] Iteration 95750, loss = 1.07552
I0523 17:57:54.644563 19131 solver.cpp:253]     Train net output #0: loss = 1.07552 (* 1 = 1.07552 loss)
I0523 17:57:54.644579 19131 sgd_solver.cpp:106] Iteration 95750, lr = 0.003
I0523 17:58:03.716217 19131 solver.cpp:237] Iteration 96000, loss = 1.16899
I0523 17:58:03.716264 19131 solver.cpp:253]     Train net output #0: loss = 1.16899 (* 1 = 1.16899 loss)
I0523 17:58:03.716277 19131 sgd_solver.cpp:106] Iteration 96000, lr = 0.003
I0523 17:58:12.779633 19131 solver.cpp:237] Iteration 96250, loss = 1.39556
I0523 17:58:12.779669 19131 solver.cpp:253]     Train net output #0: loss = 1.39556 (* 1 = 1.39556 loss)
I0523 17:58:12.779685 19131 sgd_solver.cpp:106] Iteration 96250, lr = 0.003
I0523 17:58:21.854933 19131 solver.cpp:237] Iteration 96500, loss = 0.88608
I0523 17:58:21.855108 19131 solver.cpp:253]     Train net output #0: loss = 0.88608 (* 1 = 0.88608 loss)
I0523 17:58:21.855121 19131 sgd_solver.cpp:106] Iteration 96500, lr = 0.003
I0523 17:58:51.823580 19131 solver.cpp:237] Iteration 96750, loss = 1.07319
I0523 17:58:51.823632 19131 solver.cpp:253]     Train net output #0: loss = 1.07319 (* 1 = 1.07319 loss)
I0523 17:58:51.823649 19131 sgd_solver.cpp:106] Iteration 96750, lr = 0.003
I0523 17:59:00.898535 19131 solver.cpp:237] Iteration 97000, loss = 0.951302
I0523 17:59:00.898731 19131 solver.cpp:253]     Train net output #0: loss = 0.951302 (* 1 = 0.951302 loss)
I0523 17:59:00.898746 19131 sgd_solver.cpp:106] Iteration 97000, lr = 0.003
I0523 17:59:09.977725 19131 solver.cpp:237] Iteration 97250, loss = 1.20486
I0523 17:59:09.977761 19131 solver.cpp:253]     Train net output #0: loss = 1.20486 (* 1 = 1.20486 loss)
I0523 17:59:09.977776 19131 sgd_solver.cpp:106] Iteration 97250, lr = 0.003
I0523 17:59:19.012609 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_97500.caffemodel
I0523 17:59:19.075991 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_97500.solverstate
I0523 17:59:19.113908 19131 solver.cpp:237] Iteration 97500, loss = 1.52057
I0523 17:59:19.113955 19131 solver.cpp:253]     Train net output #0: loss = 1.52057 (* 1 = 1.52057 loss)
I0523 17:59:19.113970 19131 sgd_solver.cpp:106] Iteration 97500, lr = 0.003
I0523 17:59:28.187465 19131 solver.cpp:237] Iteration 97750, loss = 1.07298
I0523 17:59:28.187502 19131 solver.cpp:253]     Train net output #0: loss = 1.07298 (* 1 = 1.07298 loss)
I0523 17:59:28.187518 19131 sgd_solver.cpp:106] Iteration 97750, lr = 0.003
I0523 17:59:37.269055 19131 solver.cpp:237] Iteration 98000, loss = 1.04289
I0523 17:59:37.269243 19131 solver.cpp:253]     Train net output #0: loss = 1.04289 (* 1 = 1.04289 loss)
I0523 17:59:37.269258 19131 sgd_solver.cpp:106] Iteration 98000, lr = 0.003
I0523 17:59:46.331290 19131 solver.cpp:237] Iteration 98250, loss = 1.14698
I0523 17:59:46.331334 19131 solver.cpp:253]     Train net output #0: loss = 1.14698 (* 1 = 1.14698 loss)
I0523 17:59:46.331351 19131 sgd_solver.cpp:106] Iteration 98250, lr = 0.003
I0523 18:00:16.306403 19131 solver.cpp:237] Iteration 98500, loss = 1.1536
I0523 18:00:16.306603 19131 solver.cpp:253]     Train net output #0: loss = 1.1536 (* 1 = 1.1536 loss)
I0523 18:00:16.306617 19131 sgd_solver.cpp:106] Iteration 98500, lr = 0.003
I0523 18:00:25.388521 19131 solver.cpp:237] Iteration 98750, loss = 1.04465
I0523 18:00:25.388557 19131 solver.cpp:253]     Train net output #0: loss = 1.04465 (* 1 = 1.04465 loss)
I0523 18:00:25.388574 19131 sgd_solver.cpp:106] Iteration 98750, lr = 0.003
I0523 18:00:34.460335 19131 solver.cpp:237] Iteration 99000, loss = 1.18506
I0523 18:00:34.460384 19131 solver.cpp:253]     Train net output #0: loss = 1.18506 (* 1 = 1.18506 loss)
I0523 18:00:34.460399 19131 sgd_solver.cpp:106] Iteration 99000, lr = 0.003
I0523 18:00:43.527125 19131 solver.cpp:237] Iteration 99250, loss = 1.11007
I0523 18:00:43.527161 19131 solver.cpp:253]     Train net output #0: loss = 1.11007 (* 1 = 1.11007 loss)
I0523 18:00:43.527178 19131 sgd_solver.cpp:106] Iteration 99250, lr = 0.003
I0523 18:00:52.595932 19131 solver.cpp:237] Iteration 99500, loss = 0.902488
I0523 18:00:52.596107 19131 solver.cpp:253]     Train net output #0: loss = 0.902488 (* 1 = 0.902488 loss)
I0523 18:00:52.596122 19131 sgd_solver.cpp:106] Iteration 99500, lr = 0.003
I0523 18:01:01.662109 19131 solver.cpp:237] Iteration 99750, loss = 1.28451
I0523 18:01:01.662152 19131 solver.cpp:253]     Train net output #0: loss = 1.28451 (* 1 = 1.28451 loss)
I0523 18:01:01.662169 19131 sgd_solver.cpp:106] Iteration 99750, lr = 0.003
I0523 18:01:10.711838 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_100000.caffemodel
I0523 18:01:10.780467 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_100000.solverstate
I0523 18:01:10.808161 19131 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 18:02:19.040055 19131 solver.cpp:409]     Test net output #0: accuracy = 0.895739
I0523 18:02:19.040247 19131 solver.cpp:409]     Test net output #1: loss = 0.332559 (* 1 = 0.332559 loss)
I0523 18:02:39.939888 19131 solver.cpp:237] Iteration 100000, loss = 1.06862
I0523 18:02:39.939939 19131 solver.cpp:253]     Train net output #0: loss = 1.06862 (* 1 = 1.06862 loss)
I0523 18:02:39.939955 19131 sgd_solver.cpp:106] Iteration 100000, lr = 0.003
I0523 18:02:49.025291 19131 solver.cpp:237] Iteration 100250, loss = 1.19519
I0523 18:02:49.025327 19131 solver.cpp:253]     Train net output #0: loss = 1.19519 (* 1 = 1.19519 loss)
I0523 18:02:49.025343 19131 sgd_solver.cpp:106] Iteration 100250, lr = 0.003
I0523 18:02:58.101856 19131 solver.cpp:237] Iteration 100500, loss = 1.44138
I0523 18:02:58.102037 19131 solver.cpp:253]     Train net output #0: loss = 1.44138 (* 1 = 1.44138 loss)
I0523 18:02:58.102051 19131 sgd_solver.cpp:106] Iteration 100500, lr = 0.003
I0523 18:03:07.180769 19131 solver.cpp:237] Iteration 100750, loss = 1.29562
I0523 18:03:07.180815 19131 solver.cpp:253]     Train net output #0: loss = 1.29562 (* 1 = 1.29562 loss)
I0523 18:03:07.180833 19131 sgd_solver.cpp:106] Iteration 100750, lr = 0.003
I0523 18:03:16.262459 19131 solver.cpp:237] Iteration 101000, loss = 1.05729
I0523 18:03:16.262495 19131 solver.cpp:253]     Train net output #0: loss = 1.05729 (* 1 = 1.05729 loss)
I0523 18:03:16.262511 19131 sgd_solver.cpp:106] Iteration 101000, lr = 0.003
I0523 18:03:25.337182 19131 solver.cpp:237] Iteration 101250, loss = 1.12891
I0523 18:03:25.337218 19131 solver.cpp:253]     Train net output #0: loss = 1.12891 (* 1 = 1.12891 loss)
I0523 18:03:25.337234 19131 sgd_solver.cpp:106] Iteration 101250, lr = 0.003
I0523 18:03:34.413164 19131 solver.cpp:237] Iteration 101500, loss = 1.28127
I0523 18:03:34.413367 19131 solver.cpp:253]     Train net output #0: loss = 1.28127 (* 1 = 1.28127 loss)
I0523 18:03:34.413381 19131 sgd_solver.cpp:106] Iteration 101500, lr = 0.003
I0523 18:04:04.407008 19131 solver.cpp:237] Iteration 101750, loss = 0.879055
I0523 18:04:04.407061 19131 solver.cpp:253]     Train net output #0: loss = 0.879055 (* 1 = 0.879055 loss)
I0523 18:04:04.407078 19131 sgd_solver.cpp:106] Iteration 101750, lr = 0.003
I0523 18:04:13.494830 19131 solver.cpp:237] Iteration 102000, loss = 1.14659
I0523 18:04:13.495012 19131 solver.cpp:253]     Train net output #0: loss = 1.14659 (* 1 = 1.14659 loss)
I0523 18:04:13.495025 19131 sgd_solver.cpp:106] Iteration 102000, lr = 0.003
I0523 18:04:22.576254 19131 solver.cpp:237] Iteration 102250, loss = 1.68552
I0523 18:04:22.576295 19131 solver.cpp:253]     Train net output #0: loss = 1.68552 (* 1 = 1.68552 loss)
I0523 18:04:22.576316 19131 sgd_solver.cpp:106] Iteration 102250, lr = 0.003
I0523 18:04:31.612684 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_102500.caffemodel
I0523 18:04:31.675030 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_102500.solverstate
I0523 18:04:31.711704 19131 solver.cpp:237] Iteration 102500, loss = 1.08622
I0523 18:04:31.711747 19131 solver.cpp:253]     Train net output #0: loss = 1.08622 (* 1 = 1.08622 loss)
I0523 18:04:31.711768 19131 sgd_solver.cpp:106] Iteration 102500, lr = 0.003
I0523 18:04:40.785027 19131 solver.cpp:237] Iteration 102750, loss = 1.20639
I0523 18:04:40.785061 19131 solver.cpp:253]     Train net output #0: loss = 1.20639 (* 1 = 1.20639 loss)
I0523 18:04:40.785079 19131 sgd_solver.cpp:106] Iteration 102750, lr = 0.003
I0523 18:04:49.860189 19131 solver.cpp:237] Iteration 103000, loss = 1.03838
I0523 18:04:49.860383 19131 solver.cpp:253]     Train net output #0: loss = 1.03838 (* 1 = 1.03838 loss)
I0523 18:04:49.860396 19131 sgd_solver.cpp:106] Iteration 103000, lr = 0.003
I0523 18:04:58.933034 19131 solver.cpp:237] Iteration 103250, loss = 1.26769
I0523 18:04:58.933069 19131 solver.cpp:253]     Train net output #0: loss = 1.26769 (* 1 = 1.26769 loss)
I0523 18:04:58.933086 19131 sgd_solver.cpp:106] Iteration 103250, lr = 0.003
I0523 18:05:28.917685 19131 solver.cpp:237] Iteration 103500, loss = 1.06316
I0523 18:05:28.917878 19131 solver.cpp:253]     Train net output #0: loss = 1.06316 (* 1 = 1.06316 loss)
I0523 18:05:28.917892 19131 sgd_solver.cpp:106] Iteration 103500, lr = 0.003
I0523 18:05:37.993938 19131 solver.cpp:237] Iteration 103750, loss = 1.01878
I0523 18:05:37.993980 19131 solver.cpp:253]     Train net output #0: loss = 1.01878 (* 1 = 1.01878 loss)
I0523 18:05:37.994001 19131 sgd_solver.cpp:106] Iteration 103750, lr = 0.003
I0523 18:05:47.074167 19131 solver.cpp:237] Iteration 104000, loss = 1.41151
I0523 18:05:47.074203 19131 solver.cpp:253]     Train net output #0: loss = 1.41151 (* 1 = 1.41151 loss)
I0523 18:05:47.074220 19131 sgd_solver.cpp:106] Iteration 104000, lr = 0.003
I0523 18:05:56.146167 19131 solver.cpp:237] Iteration 104250, loss = 1.17166
I0523 18:05:56.146203 19131 solver.cpp:253]     Train net output #0: loss = 1.17166 (* 1 = 1.17166 loss)
I0523 18:05:56.146219 19131 sgd_solver.cpp:106] Iteration 104250, lr = 0.003
I0523 18:06:05.221668 19131 solver.cpp:237] Iteration 104500, loss = 1.09782
I0523 18:06:05.221873 19131 solver.cpp:253]     Train net output #0: loss = 1.09782 (* 1 = 1.09782 loss)
I0523 18:06:05.221886 19131 sgd_solver.cpp:106] Iteration 104500, lr = 0.003
I0523 18:06:14.300910 19131 solver.cpp:237] Iteration 104750, loss = 1.28779
I0523 18:06:14.300945 19131 solver.cpp:253]     Train net output #0: loss = 1.28779 (* 1 = 1.28779 loss)
I0523 18:06:14.300962 19131 sgd_solver.cpp:106] Iteration 104750, lr = 0.003
I0523 18:06:23.338644 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_105000.caffemodel
I0523 18:06:23.402066 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_105000.solverstate
I0523 18:06:23.428809 19131 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 18:07:10.738801 19131 solver.cpp:409]     Test net output #0: accuracy = 0.895559
I0523 18:07:10.738997 19131 solver.cpp:409]     Test net output #1: loss = 0.324026 (* 1 = 0.324026 loss)
I0523 18:07:31.655658 19131 solver.cpp:237] Iteration 105000, loss = 1.06783
I0523 18:07:31.655709 19131 solver.cpp:253]     Train net output #0: loss = 1.06783 (* 1 = 1.06783 loss)
I0523 18:07:31.655725 19131 sgd_solver.cpp:106] Iteration 105000, lr = 0.003
I0523 18:07:40.624274 19131 solver.cpp:237] Iteration 105250, loss = 1.27578
I0523 18:07:40.624320 19131 solver.cpp:253]     Train net output #0: loss = 1.27578 (* 1 = 1.27578 loss)
I0523 18:07:40.624337 19131 sgd_solver.cpp:106] Iteration 105250, lr = 0.003
I0523 18:07:49.583837 19131 solver.cpp:237] Iteration 105500, loss = 1.19645
I0523 18:07:49.584018 19131 solver.cpp:253]     Train net output #0: loss = 1.19645 (* 1 = 1.19645 loss)
I0523 18:07:49.584033 19131 sgd_solver.cpp:106] Iteration 105500, lr = 0.003
I0523 18:07:58.557221 19131 solver.cpp:237] Iteration 105750, loss = 1.03144
I0523 18:07:58.557256 19131 solver.cpp:253]     Train net output #0: loss = 1.03144 (* 1 = 1.03144 loss)
I0523 18:07:58.557273 19131 sgd_solver.cpp:106] Iteration 105750, lr = 0.003
I0523 18:08:07.521592 19131 solver.cpp:237] Iteration 106000, loss = 1.11193
I0523 18:08:07.521641 19131 solver.cpp:253]     Train net output #0: loss = 1.11193 (* 1 = 1.11193 loss)
I0523 18:08:07.521656 19131 sgd_solver.cpp:106] Iteration 106000, lr = 0.003
I0523 18:08:16.479066 19131 solver.cpp:237] Iteration 106250, loss = 1.08442
I0523 18:08:16.479102 19131 solver.cpp:253]     Train net output #0: loss = 1.08442 (* 1 = 1.08442 loss)
I0523 18:08:16.479120 19131 sgd_solver.cpp:106] Iteration 106250, lr = 0.003
I0523 18:08:25.432904 19131 solver.cpp:237] Iteration 106500, loss = 1.11321
I0523 18:08:25.433081 19131 solver.cpp:253]     Train net output #0: loss = 1.11321 (* 1 = 1.11321 loss)
I0523 18:08:25.433095 19131 sgd_solver.cpp:106] Iteration 106500, lr = 0.003
I0523 18:08:55.299381 19131 solver.cpp:237] Iteration 106750, loss = 1.35373
I0523 18:08:55.299429 19131 solver.cpp:253]     Train net output #0: loss = 1.35373 (* 1 = 1.35373 loss)
I0523 18:08:55.299448 19131 sgd_solver.cpp:106] Iteration 106750, lr = 0.003
I0523 18:09:04.259735 19131 solver.cpp:237] Iteration 107000, loss = 0.963024
I0523 18:09:04.259918 19131 solver.cpp:253]     Train net output #0: loss = 0.963024 (* 1 = 0.963024 loss)
I0523 18:09:04.259932 19131 sgd_solver.cpp:106] Iteration 107000, lr = 0.003
I0523 18:09:13.223662 19131 solver.cpp:237] Iteration 107250, loss = 1.12909
I0523 18:09:13.223697 19131 solver.cpp:253]     Train net output #0: loss = 1.12909 (* 1 = 1.12909 loss)
I0523 18:09:13.223714 19131 sgd_solver.cpp:106] Iteration 107250, lr = 0.003
I0523 18:09:22.149394 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_107500.caffemodel
I0523 18:09:22.212992 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_107500.solverstate
I0523 18:09:22.249658 19131 solver.cpp:237] Iteration 107500, loss = 1.05343
I0523 18:09:22.249704 19131 solver.cpp:253]     Train net output #0: loss = 1.05343 (* 1 = 1.05343 loss)
I0523 18:09:22.249718 19131 sgd_solver.cpp:106] Iteration 107500, lr = 0.003
I0523 18:09:31.211773 19131 solver.cpp:237] Iteration 107750, loss = 1.07635
I0523 18:09:31.211810 19131 solver.cpp:253]     Train net output #0: loss = 1.07635 (* 1 = 1.07635 loss)
I0523 18:09:31.211824 19131 sgd_solver.cpp:106] Iteration 107750, lr = 0.003
I0523 18:09:40.188251 19131 solver.cpp:237] Iteration 108000, loss = 1.01298
I0523 18:09:40.188441 19131 solver.cpp:253]     Train net output #0: loss = 1.01298 (* 1 = 1.01298 loss)
I0523 18:09:40.188453 19131 sgd_solver.cpp:106] Iteration 108000, lr = 0.003
I0523 18:09:49.151327 19131 solver.cpp:237] Iteration 108250, loss = 0.99524
I0523 18:09:49.151370 19131 solver.cpp:253]     Train net output #0: loss = 0.99524 (* 1 = 0.99524 loss)
I0523 18:09:49.151389 19131 sgd_solver.cpp:106] Iteration 108250, lr = 0.003
I0523 18:10:18.994462 19131 solver.cpp:237] Iteration 108500, loss = 0.916173
I0523 18:10:18.994659 19131 solver.cpp:253]     Train net output #0: loss = 0.916173 (* 1 = 0.916173 loss)
I0523 18:10:18.994676 19131 sgd_solver.cpp:106] Iteration 108500, lr = 0.003
I0523 18:10:27.964769 19131 solver.cpp:237] Iteration 108750, loss = 1.38774
I0523 18:10:27.964805 19131 solver.cpp:253]     Train net output #0: loss = 1.38774 (* 1 = 1.38774 loss)
I0523 18:10:27.964823 19131 sgd_solver.cpp:106] Iteration 108750, lr = 0.003
I0523 18:10:36.936255 19131 solver.cpp:237] Iteration 109000, loss = 1.32503
I0523 18:10:36.936302 19131 solver.cpp:253]     Train net output #0: loss = 1.32503 (* 1 = 1.32503 loss)
I0523 18:10:36.936319 19131 sgd_solver.cpp:106] Iteration 109000, lr = 0.003
I0523 18:10:45.905608 19131 solver.cpp:237] Iteration 109250, loss = 1.06791
I0523 18:10:45.905644 19131 solver.cpp:253]     Train net output #0: loss = 1.06791 (* 1 = 1.06791 loss)
I0523 18:10:45.905659 19131 sgd_solver.cpp:106] Iteration 109250, lr = 0.003
I0523 18:10:54.874033 19131 solver.cpp:237] Iteration 109500, loss = 1.05026
I0523 18:10:54.874212 19131 solver.cpp:253]     Train net output #0: loss = 1.05026 (* 1 = 1.05026 loss)
I0523 18:10:54.874225 19131 sgd_solver.cpp:106] Iteration 109500, lr = 0.003
I0523 18:11:03.843621 19131 solver.cpp:237] Iteration 109750, loss = 1.12165
I0523 18:11:03.843668 19131 solver.cpp:253]     Train net output #0: loss = 1.12165 (* 1 = 1.12165 loss)
I0523 18:11:03.843685 19131 sgd_solver.cpp:106] Iteration 109750, lr = 0.003
I0523 18:11:12.778463 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_110000.caffemodel
I0523 18:11:12.847229 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_110000.solverstate
I0523 18:11:12.873504 19131 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 18:12:21.046063 19131 solver.cpp:409]     Test net output #0: accuracy = 0.896972
I0523 18:12:21.046272 19131 solver.cpp:409]     Test net output #1: loss = 0.353936 (* 1 = 0.353936 loss)
I0523 18:12:41.963111 19131 solver.cpp:237] Iteration 110000, loss = 1.08178
I0523 18:12:41.963165 19131 solver.cpp:253]     Train net output #0: loss = 1.08178 (* 1 = 1.08178 loss)
I0523 18:12:41.963178 19131 sgd_solver.cpp:106] Iteration 110000, lr = 0.003
I0523 18:12:50.999732 19131 solver.cpp:237] Iteration 110250, loss = 1.43626
I0523 18:12:50.999768 19131 solver.cpp:253]     Train net output #0: loss = 1.43626 (* 1 = 1.43626 loss)
I0523 18:12:50.999785 19131 sgd_solver.cpp:106] Iteration 110250, lr = 0.003
I0523 18:13:00.028916 19131 solver.cpp:237] Iteration 110500, loss = 0.914331
I0523 18:13:00.029112 19131 solver.cpp:253]     Train net output #0: loss = 0.914331 (* 1 = 0.914331 loss)
I0523 18:13:00.029129 19131 sgd_solver.cpp:106] Iteration 110500, lr = 0.003
I0523 18:13:09.064698 19131 solver.cpp:237] Iteration 110750, loss = 1.18093
I0523 18:13:09.064744 19131 solver.cpp:253]     Train net output #0: loss = 1.18093 (* 1 = 1.18093 loss)
I0523 18:13:09.064761 19131 sgd_solver.cpp:106] Iteration 110750, lr = 0.003
I0523 18:13:18.097975 19131 solver.cpp:237] Iteration 111000, loss = 1.19736
I0523 18:13:18.098011 19131 solver.cpp:253]     Train net output #0: loss = 1.19736 (* 1 = 1.19736 loss)
I0523 18:13:18.098026 19131 sgd_solver.cpp:106] Iteration 111000, lr = 0.003
I0523 18:13:27.137095 19131 solver.cpp:237] Iteration 111250, loss = 1.33621
I0523 18:13:27.137130 19131 solver.cpp:253]     Train net output #0: loss = 1.33621 (* 1 = 1.33621 loss)
I0523 18:13:27.137146 19131 sgd_solver.cpp:106] Iteration 111250, lr = 0.003
I0523 18:13:36.176488 19131 solver.cpp:237] Iteration 111500, loss = 1.12098
I0523 18:13:36.176686 19131 solver.cpp:253]     Train net output #0: loss = 1.12098 (* 1 = 1.12098 loss)
I0523 18:13:36.176700 19131 sgd_solver.cpp:106] Iteration 111500, lr = 0.003
I0523 18:14:06.109019 19131 solver.cpp:237] Iteration 111750, loss = 1.1095
I0523 18:14:06.109068 19131 solver.cpp:253]     Train net output #0: loss = 1.1095 (* 1 = 1.1095 loss)
I0523 18:14:06.109086 19131 sgd_solver.cpp:106] Iteration 111750, lr = 0.003
I0523 18:14:15.138568 19131 solver.cpp:237] Iteration 112000, loss = 1.12876
I0523 18:14:15.138772 19131 solver.cpp:253]     Train net output #0: loss = 1.12876 (* 1 = 1.12876 loss)
I0523 18:14:15.138785 19131 sgd_solver.cpp:106] Iteration 112000, lr = 0.003
I0523 18:14:24.173789 19131 solver.cpp:237] Iteration 112250, loss = 1.198
I0523 18:14:24.173833 19131 solver.cpp:253]     Train net output #0: loss = 1.198 (* 1 = 1.198 loss)
I0523 18:14:24.173851 19131 sgd_solver.cpp:106] Iteration 112250, lr = 0.003
I0523 18:14:33.169915 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_112500.caffemodel
I0523 18:14:33.234712 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_112500.solverstate
I0523 18:14:33.273505 19131 solver.cpp:237] Iteration 112500, loss = 1.18346
I0523 18:14:33.273555 19131 solver.cpp:253]     Train net output #0: loss = 1.18346 (* 1 = 1.18346 loss)
I0523 18:14:33.273571 19131 sgd_solver.cpp:106] Iteration 112500, lr = 0.003
I0523 18:14:42.302947 19131 solver.cpp:237] Iteration 112750, loss = 1.05104
I0523 18:14:42.302981 19131 solver.cpp:253]     Train net output #0: loss = 1.05104 (* 1 = 1.05104 loss)
I0523 18:14:42.302999 19131 sgd_solver.cpp:106] Iteration 112750, lr = 0.003
I0523 18:14:51.335880 19131 solver.cpp:237] Iteration 113000, loss = 1.24421
I0523 18:14:51.336073 19131 solver.cpp:253]     Train net output #0: loss = 1.24421 (* 1 = 1.24421 loss)
I0523 18:14:51.336087 19131 sgd_solver.cpp:106] Iteration 113000, lr = 0.003
I0523 18:15:00.368773 19131 solver.cpp:237] Iteration 113250, loss = 1.19235
I0523 18:15:00.368808 19131 solver.cpp:253]     Train net output #0: loss = 1.19235 (* 1 = 1.19235 loss)
I0523 18:15:00.368825 19131 sgd_solver.cpp:106] Iteration 113250, lr = 0.003
I0523 18:15:30.342384 19131 solver.cpp:237] Iteration 113500, loss = 1.13353
I0523 18:15:30.342584 19131 solver.cpp:253]     Train net output #0: loss = 1.13353 (* 1 = 1.13353 loss)
I0523 18:15:30.342598 19131 sgd_solver.cpp:106] Iteration 113500, lr = 0.003
I0523 18:15:39.377619 19131 solver.cpp:237] Iteration 113750, loss = 0.953586
I0523 18:15:39.377661 19131 solver.cpp:253]     Train net output #0: loss = 0.953586 (* 1 = 0.953586 loss)
I0523 18:15:39.377681 19131 sgd_solver.cpp:106] Iteration 113750, lr = 0.003
I0523 18:15:48.410454 19131 solver.cpp:237] Iteration 114000, loss = 1.2493
I0523 18:15:48.410490 19131 solver.cpp:253]     Train net output #0: loss = 1.2493 (* 1 = 1.2493 loss)
I0523 18:15:48.410506 19131 sgd_solver.cpp:106] Iteration 114000, lr = 0.003
I0523 18:15:57.450655 19131 solver.cpp:237] Iteration 114250, loss = 1.07107
I0523 18:15:57.450690 19131 solver.cpp:253]     Train net output #0: loss = 1.07107 (* 1 = 1.07107 loss)
I0523 18:15:57.450714 19131 sgd_solver.cpp:106] Iteration 114250, lr = 0.003
I0523 18:16:06.489706 19131 solver.cpp:237] Iteration 114500, loss = 1.2111
I0523 18:16:06.489904 19131 solver.cpp:253]     Train net output #0: loss = 1.2111 (* 1 = 1.2111 loss)
I0523 18:16:06.489918 19131 sgd_solver.cpp:106] Iteration 114500, lr = 0.003
I0523 18:16:15.523298 19131 solver.cpp:237] Iteration 114750, loss = 0.929428
I0523 18:16:15.523334 19131 solver.cpp:253]     Train net output #0: loss = 0.929428 (* 1 = 0.929428 loss)
I0523 18:16:15.523350 19131 sgd_solver.cpp:106] Iteration 114750, lr = 0.003
I0523 18:16:24.524900 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_115000.caffemodel
I0523 18:16:24.597112 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_115000.solverstate
I0523 18:16:24.622376 19131 solver.cpp:341] Iteration 115000, Testing net (#0)
I0523 18:17:11.653043 19131 solver.cpp:409]     Test net output #0: accuracy = 0.895718
I0523 18:17:11.653245 19131 solver.cpp:409]     Test net output #1: loss = 0.320071 (* 1 = 0.320071 loss)
I0523 18:17:32.538619 19131 solver.cpp:237] Iteration 115000, loss = 1.23159
I0523 18:17:32.538674 19131 solver.cpp:253]     Train net output #0: loss = 1.23159 (* 1 = 1.23159 loss)
I0523 18:17:32.538691 19131 sgd_solver.cpp:106] Iteration 115000, lr = 0.003
I0523 18:17:41.538645 19131 solver.cpp:237] Iteration 115250, loss = 1.0919
I0523 18:17:41.538686 19131 solver.cpp:253]     Train net output #0: loss = 1.0919 (* 1 = 1.0919 loss)
I0523 18:17:41.538712 19131 sgd_solver.cpp:106] Iteration 115250, lr = 0.003
I0523 18:17:50.528813 19131 solver.cpp:237] Iteration 115500, loss = 1.21737
I0523 18:17:50.528996 19131 solver.cpp:253]     Train net output #0: loss = 1.21737 (* 1 = 1.21737 loss)
I0523 18:17:50.529011 19131 sgd_solver.cpp:106] Iteration 115500, lr = 0.003
I0523 18:17:59.519974 19131 solver.cpp:237] Iteration 115750, loss = 1.21779
I0523 18:17:59.520009 19131 solver.cpp:253]     Train net output #0: loss = 1.21779 (* 1 = 1.21779 loss)
I0523 18:17:59.520026 19131 sgd_solver.cpp:106] Iteration 115750, lr = 0.003
I0523 18:18:08.514317 19131 solver.cpp:237] Iteration 116000, loss = 0.899537
I0523 18:18:08.514364 19131 solver.cpp:253]     Train net output #0: loss = 0.899537 (* 1 = 0.899537 loss)
I0523 18:18:08.514382 19131 sgd_solver.cpp:106] Iteration 116000, lr = 0.003
I0523 18:18:17.515195 19131 solver.cpp:237] Iteration 116250, loss = 0.946135
I0523 18:18:17.515231 19131 solver.cpp:253]     Train net output #0: loss = 0.946135 (* 1 = 0.946135 loss)
I0523 18:18:17.515247 19131 sgd_solver.cpp:106] Iteration 116250, lr = 0.003
I0523 18:18:26.504933 19131 solver.cpp:237] Iteration 116500, loss = 1.07879
I0523 18:18:26.505110 19131 solver.cpp:253]     Train net output #0: loss = 1.07879 (* 1 = 1.07879 loss)
I0523 18:18:26.505125 19131 sgd_solver.cpp:106] Iteration 116500, lr = 0.003
I0523 18:18:56.394536 19131 solver.cpp:237] Iteration 116750, loss = 1.34904
I0523 18:18:56.394584 19131 solver.cpp:253]     Train net output #0: loss = 1.34904 (* 1 = 1.34904 loss)
I0523 18:18:56.394603 19131 sgd_solver.cpp:106] Iteration 116750, lr = 0.003
I0523 18:19:05.392788 19131 solver.cpp:237] Iteration 117000, loss = 1.04155
I0523 18:19:05.392973 19131 solver.cpp:253]     Train net output #0: loss = 1.04155 (* 1 = 1.04155 loss)
I0523 18:19:05.392987 19131 sgd_solver.cpp:106] Iteration 117000, lr = 0.003
I0523 18:19:14.388401 19131 solver.cpp:237] Iteration 117250, loss = 0.921307
I0523 18:19:14.388437 19131 solver.cpp:253]     Train net output #0: loss = 0.921307 (* 1 = 0.921307 loss)
I0523 18:19:14.388453 19131 sgd_solver.cpp:106] Iteration 117250, lr = 0.003
I0523 18:19:23.352200 19131 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_117500.caffemodel
I0523 18:19:23.416160 19131 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0030_2016-05-20T15.49.10.660928_iter_117500.solverstate
I0523 18:19:23.453130 19131 solver.cpp:237] Iteration 117500, loss = 1.08864
I0523 18:19:23.453174 19131 solver.cpp:253]     Train net output #0: loss = 1.08864 (* 1 = 1.08864 loss)
I0523 18:19:23.453192 19131 sgd_solver.cpp:106] Iteration 117500, lr = 0.003
I0523 18:19:32.444861 19131 solver.cpp:237] Iteration 117750, loss = 1.24732
I0523 18:19:32.444896 19131 solver.cpp:253]     Train net output #0: loss = 1.24732 (* 1 = 1.24732 loss)
I0523 18:19:32.444911 19131 sgd_solver.cpp:106] Iteration 117750, lr = 0.003
I0523 18:19:41.440021 19131 solver.cpp:237] Iteration 118000, loss = 1.11209
I0523 18:19:41.440217 19131 solver.cpp:253]     Train net output #0: loss = 1.11209 (* 1 = 1.11209 loss)
I0523 18:19:41.440232 19131 sgd_solver.cpp:106] Iteration 118000, lr = 0.003
I0523 18:19:50.434926 19131 solver.cpp:237] Iteration 118250, loss = 0.856331
I0523 18:19:50.434967 19131 solver.cpp:253]     Train net output #0: loss = 0.856331 (* 1 = 0.856331 loss)
I0523 18:19:50.434988 19131 sgd_solver.cpp:106] Iteration 118250, lr = 0.003
I0523 18:20:20.304930 19131 solver.cpp:237] Iteration 118500, loss = 1.03056
I0523 18:20:20.305135 19131 solver.cpp:253]     Train net output #0: loss = 1.03056 (* 1 = 1.03056 loss)
I0523 18:20:20.305148 19131 sgd_solver.cpp:106] Iteration 118500, lr = 0.003
I0523 18:20:29.302135 19131 solver.cpp:237] Iteration 118750, loss = 1.28095
I0523 18:20:29.302172 19131 solver.cpp:253]     Train net output #0: loss = 1.28095 (* 1 = 1.28095 loss)
I0523 18:20:29.302188 19131 sgd_solver.cpp:106] Iteration 118750, lr = 0.003
aprun: Apid 11256828: Caught signal Terminated, sending to application
*** Aborted at 1464042032 (unix time) try "date -d @1464042032" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x4ab8) received by PID 19131 (TID 0x2aaac746f900) from PID 19128; stack trace: ***
=>> PBS: job killed: walltime 7223 exceeded limit 7200
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11256828: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
aprun: Apid 11256828: Caught signal Terminated, sending to application
