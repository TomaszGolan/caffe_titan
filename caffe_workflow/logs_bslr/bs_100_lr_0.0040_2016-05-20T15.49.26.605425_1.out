2810964
I0525 20:54:54.749835 22368 caffe.cpp:184] Using GPUs 0
I0525 20:54:55.179486 22368 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.004
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425.prototxt"
I0525 20:54:55.181128 22368 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425.prototxt
I0525 20:54:55.198329 22368 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 20:54:55.198395 22368 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 20:54:55.198768 22368 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 20:54:55.198971 22368 layer_factory.hpp:77] Creating layer data_hdf5
I0525 20:54:55.199007 22368 net.cpp:106] Creating Layer data_hdf5
I0525 20:54:55.199025 22368 net.cpp:411] data_hdf5 -> data
I0525 20:54:55.199059 22368 net.cpp:411] data_hdf5 -> label
I0525 20:54:55.199100 22368 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 20:54:55.216652 22368 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 20:54:55.236476 22368 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 20:55:16.782124 22368 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 20:55:16.787220 22368 net.cpp:150] Setting up data_hdf5
I0525 20:55:16.787261 22368 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 20:55:16.787277 22368 net.cpp:157] Top shape: 100 (100)
I0525 20:55:16.787291 22368 net.cpp:165] Memory required for data: 2540400
I0525 20:55:16.787309 22368 layer_factory.hpp:77] Creating layer conv1
I0525 20:55:16.787356 22368 net.cpp:106] Creating Layer conv1
I0525 20:55:16.787370 22368 net.cpp:454] conv1 <- data
I0525 20:55:16.787395 22368 net.cpp:411] conv1 -> conv1
I0525 20:55:20.188161 22368 net.cpp:150] Setting up conv1
I0525 20:55:20.188216 22368 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:55:20.188240 22368 net.cpp:165] Memory required for data: 30188400
I0525 20:55:20.188269 22368 layer_factory.hpp:77] Creating layer relu1
I0525 20:55:20.188292 22368 net.cpp:106] Creating Layer relu1
I0525 20:55:20.188311 22368 net.cpp:454] relu1 <- conv1
I0525 20:55:20.188328 22368 net.cpp:397] relu1 -> conv1 (in-place)
I0525 20:55:20.188887 22368 net.cpp:150] Setting up relu1
I0525 20:55:20.188910 22368 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:55:20.188925 22368 net.cpp:165] Memory required for data: 57836400
I0525 20:55:20.188941 22368 layer_factory.hpp:77] Creating layer pool1
I0525 20:55:20.188967 22368 net.cpp:106] Creating Layer pool1
I0525 20:55:20.188983 22368 net.cpp:454] pool1 <- conv1
I0525 20:55:20.188999 22368 net.cpp:411] pool1 -> pool1
I0525 20:55:20.189092 22368 net.cpp:150] Setting up pool1
I0525 20:55:20.189111 22368 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 20:55:20.189126 22368 net.cpp:165] Memory required for data: 71660400
I0525 20:55:20.189146 22368 layer_factory.hpp:77] Creating layer conv2
I0525 20:55:20.189170 22368 net.cpp:106] Creating Layer conv2
I0525 20:55:20.189190 22368 net.cpp:454] conv2 <- pool1
I0525 20:55:20.189206 22368 net.cpp:411] conv2 -> conv2
I0525 20:55:20.191956 22368 net.cpp:150] Setting up conv2
I0525 20:55:20.191987 22368 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:55:20.192003 22368 net.cpp:165] Memory required for data: 91532400
I0525 20:55:20.192030 22368 layer_factory.hpp:77] Creating layer relu2
I0525 20:55:20.192059 22368 net.cpp:106] Creating Layer relu2
I0525 20:55:20.192073 22368 net.cpp:454] relu2 <- conv2
I0525 20:55:20.192090 22368 net.cpp:397] relu2 -> conv2 (in-place)
I0525 20:55:20.192445 22368 net.cpp:150] Setting up relu2
I0525 20:55:20.192466 22368 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:55:20.192478 22368 net.cpp:165] Memory required for data: 111404400
I0525 20:55:20.192490 22368 layer_factory.hpp:77] Creating layer pool2
I0525 20:55:20.192528 22368 net.cpp:106] Creating Layer pool2
I0525 20:55:20.192541 22368 net.cpp:454] pool2 <- conv2
I0525 20:55:20.192564 22368 net.cpp:411] pool2 -> pool2
I0525 20:55:20.192659 22368 net.cpp:150] Setting up pool2
I0525 20:55:20.192680 22368 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 20:55:20.192699 22368 net.cpp:165] Memory required for data: 121340400
I0525 20:55:20.192713 22368 layer_factory.hpp:77] Creating layer conv3
I0525 20:55:20.192734 22368 net.cpp:106] Creating Layer conv3
I0525 20:55:20.192749 22368 net.cpp:454] conv3 <- pool2
I0525 20:55:20.192764 22368 net.cpp:411] conv3 -> conv3
I0525 20:55:20.194702 22368 net.cpp:150] Setting up conv3
I0525 20:55:20.194727 22368 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:55:20.194748 22368 net.cpp:165] Memory required for data: 132182000
I0525 20:55:20.194771 22368 layer_factory.hpp:77] Creating layer relu3
I0525 20:55:20.194802 22368 net.cpp:106] Creating Layer relu3
I0525 20:55:20.194815 22368 net.cpp:454] relu3 <- conv3
I0525 20:55:20.194831 22368 net.cpp:397] relu3 -> conv3 (in-place)
I0525 20:55:20.195317 22368 net.cpp:150] Setting up relu3
I0525 20:55:20.195340 22368 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:55:20.195353 22368 net.cpp:165] Memory required for data: 143023600
I0525 20:55:20.195369 22368 layer_factory.hpp:77] Creating layer pool3
I0525 20:55:20.195392 22368 net.cpp:106] Creating Layer pool3
I0525 20:55:20.195406 22368 net.cpp:454] pool3 <- conv3
I0525 20:55:20.195422 22368 net.cpp:411] pool3 -> pool3
I0525 20:55:20.195502 22368 net.cpp:150] Setting up pool3
I0525 20:55:20.195521 22368 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 20:55:20.195536 22368 net.cpp:165] Memory required for data: 148444400
I0525 20:55:20.195549 22368 layer_factory.hpp:77] Creating layer conv4
I0525 20:55:20.195574 22368 net.cpp:106] Creating Layer conv4
I0525 20:55:20.195587 22368 net.cpp:454] conv4 <- pool3
I0525 20:55:20.195605 22368 net.cpp:411] conv4 -> conv4
I0525 20:55:20.198585 22368 net.cpp:150] Setting up conv4
I0525 20:55:20.198617 22368 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:55:20.198633 22368 net.cpp:165] Memory required for data: 152073200
I0525 20:55:20.198652 22368 layer_factory.hpp:77] Creating layer relu4
I0525 20:55:20.198685 22368 net.cpp:106] Creating Layer relu4
I0525 20:55:20.198699 22368 net.cpp:454] relu4 <- conv4
I0525 20:55:20.198715 22368 net.cpp:397] relu4 -> conv4 (in-place)
I0525 20:55:20.199203 22368 net.cpp:150] Setting up relu4
I0525 20:55:20.199225 22368 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:55:20.199239 22368 net.cpp:165] Memory required for data: 155702000
I0525 20:55:20.199254 22368 layer_factory.hpp:77] Creating layer pool4
I0525 20:55:20.199277 22368 net.cpp:106] Creating Layer pool4
I0525 20:55:20.199291 22368 net.cpp:454] pool4 <- conv4
I0525 20:55:20.199307 22368 net.cpp:411] pool4 -> pool4
I0525 20:55:20.199390 22368 net.cpp:150] Setting up pool4
I0525 20:55:20.199412 22368 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 20:55:20.199425 22368 net.cpp:165] Memory required for data: 157516400
I0525 20:55:20.199440 22368 layer_factory.hpp:77] Creating layer ip1
I0525 20:55:20.199467 22368 net.cpp:106] Creating Layer ip1
I0525 20:55:20.199481 22368 net.cpp:454] ip1 <- pool4
I0525 20:55:20.199496 22368 net.cpp:411] ip1 -> ip1
I0525 20:55:20.214987 22368 net.cpp:150] Setting up ip1
I0525 20:55:20.215016 22368 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:55:20.215039 22368 net.cpp:165] Memory required for data: 157594800
I0525 20:55:20.215064 22368 layer_factory.hpp:77] Creating layer relu5
I0525 20:55:20.215083 22368 net.cpp:106] Creating Layer relu5
I0525 20:55:20.215107 22368 net.cpp:454] relu5 <- ip1
I0525 20:55:20.215124 22368 net.cpp:397] relu5 -> ip1 (in-place)
I0525 20:55:20.215483 22368 net.cpp:150] Setting up relu5
I0525 20:55:20.215503 22368 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:55:20.215517 22368 net.cpp:165] Memory required for data: 157673200
I0525 20:55:20.215531 22368 layer_factory.hpp:77] Creating layer drop1
I0525 20:55:20.215555 22368 net.cpp:106] Creating Layer drop1
I0525 20:55:20.215569 22368 net.cpp:454] drop1 <- ip1
I0525 20:55:20.215590 22368 net.cpp:397] drop1 -> ip1 (in-place)
I0525 20:55:20.215656 22368 net.cpp:150] Setting up drop1
I0525 20:55:20.215672 22368 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:55:20.215689 22368 net.cpp:165] Memory required for data: 157751600
I0525 20:55:20.215703 22368 layer_factory.hpp:77] Creating layer ip2
I0525 20:55:20.215731 22368 net.cpp:106] Creating Layer ip2
I0525 20:55:20.215744 22368 net.cpp:454] ip2 <- ip1
I0525 20:55:20.215759 22368 net.cpp:411] ip2 -> ip2
I0525 20:55:20.216253 22368 net.cpp:150] Setting up ip2
I0525 20:55:20.216272 22368 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:55:20.216284 22368 net.cpp:165] Memory required for data: 157790800
I0525 20:55:20.216305 22368 layer_factory.hpp:77] Creating layer relu6
I0525 20:55:20.216327 22368 net.cpp:106] Creating Layer relu6
I0525 20:55:20.216341 22368 net.cpp:454] relu6 <- ip2
I0525 20:55:20.216356 22368 net.cpp:397] relu6 -> ip2 (in-place)
I0525 20:55:20.216909 22368 net.cpp:150] Setting up relu6
I0525 20:55:20.216933 22368 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:55:20.216945 22368 net.cpp:165] Memory required for data: 157830000
I0525 20:55:20.216961 22368 layer_factory.hpp:77] Creating layer drop2
I0525 20:55:20.216984 22368 net.cpp:106] Creating Layer drop2
I0525 20:55:20.216997 22368 net.cpp:454] drop2 <- ip2
I0525 20:55:20.217013 22368 net.cpp:397] drop2 -> ip2 (in-place)
I0525 20:55:20.217069 22368 net.cpp:150] Setting up drop2
I0525 20:55:20.217085 22368 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:55:20.217098 22368 net.cpp:165] Memory required for data: 157869200
I0525 20:55:20.217113 22368 layer_factory.hpp:77] Creating layer ip3
I0525 20:55:20.217128 22368 net.cpp:106] Creating Layer ip3
I0525 20:55:20.217144 22368 net.cpp:454] ip3 <- ip2
I0525 20:55:20.217165 22368 net.cpp:411] ip3 -> ip3
I0525 20:55:20.217391 22368 net.cpp:150] Setting up ip3
I0525 20:55:20.217409 22368 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:55:20.217422 22368 net.cpp:165] Memory required for data: 157873600
I0525 20:55:20.217443 22368 layer_factory.hpp:77] Creating layer drop3
I0525 20:55:20.217465 22368 net.cpp:106] Creating Layer drop3
I0525 20:55:20.217478 22368 net.cpp:454] drop3 <- ip3
I0525 20:55:20.217494 22368 net.cpp:397] drop3 -> ip3 (in-place)
I0525 20:55:20.217540 22368 net.cpp:150] Setting up drop3
I0525 20:55:20.217562 22368 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:55:20.217576 22368 net.cpp:165] Memory required for data: 157878000
I0525 20:55:20.217594 22368 layer_factory.hpp:77] Creating layer loss
I0525 20:55:20.217617 22368 net.cpp:106] Creating Layer loss
I0525 20:55:20.217631 22368 net.cpp:454] loss <- ip3
I0525 20:55:20.217651 22368 net.cpp:454] loss <- label
I0525 20:55:20.217667 22368 net.cpp:411] loss -> loss
I0525 20:55:20.217685 22368 layer_factory.hpp:77] Creating layer loss
I0525 20:55:20.218350 22368 net.cpp:150] Setting up loss
I0525 20:55:20.218371 22368 net.cpp:157] Top shape: (1)
I0525 20:55:20.218389 22368 net.cpp:160]     with loss weight 1
I0525 20:55:20.218437 22368 net.cpp:165] Memory required for data: 157878004
I0525 20:55:20.218458 22368 net.cpp:226] loss needs backward computation.
I0525 20:55:20.218472 22368 net.cpp:226] drop3 needs backward computation.
I0525 20:55:20.218485 22368 net.cpp:226] ip3 needs backward computation.
I0525 20:55:20.218498 22368 net.cpp:226] drop2 needs backward computation.
I0525 20:55:20.218510 22368 net.cpp:226] relu6 needs backward computation.
I0525 20:55:20.218524 22368 net.cpp:226] ip2 needs backward computation.
I0525 20:55:20.218544 22368 net.cpp:226] drop1 needs backward computation.
I0525 20:55:20.218556 22368 net.cpp:226] relu5 needs backward computation.
I0525 20:55:20.218569 22368 net.cpp:226] ip1 needs backward computation.
I0525 20:55:20.218585 22368 net.cpp:226] pool4 needs backward computation.
I0525 20:55:20.218598 22368 net.cpp:226] relu4 needs backward computation.
I0525 20:55:20.218611 22368 net.cpp:226] conv4 needs backward computation.
I0525 20:55:20.218623 22368 net.cpp:226] pool3 needs backward computation.
I0525 20:55:20.218646 22368 net.cpp:226] relu3 needs backward computation.
I0525 20:55:20.218667 22368 net.cpp:226] conv3 needs backward computation.
I0525 20:55:20.218682 22368 net.cpp:226] pool2 needs backward computation.
I0525 20:55:20.218695 22368 net.cpp:226] relu2 needs backward computation.
I0525 20:55:20.218708 22368 net.cpp:226] conv2 needs backward computation.
I0525 20:55:20.218721 22368 net.cpp:226] pool1 needs backward computation.
I0525 20:55:20.218736 22368 net.cpp:226] relu1 needs backward computation.
I0525 20:55:20.218756 22368 net.cpp:226] conv1 needs backward computation.
I0525 20:55:20.218770 22368 net.cpp:228] data_hdf5 does not need backward computation.
I0525 20:55:20.218786 22368 net.cpp:270] This network produces output loss
I0525 20:55:20.218814 22368 net.cpp:283] Network initialization done.
I0525 20:55:20.220499 22368 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425.prototxt
I0525 20:55:20.220587 22368 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 20:55:20.220963 22368 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 20:55:20.221184 22368 layer_factory.hpp:77] Creating layer data_hdf5
I0525 20:55:20.221204 22368 net.cpp:106] Creating Layer data_hdf5
I0525 20:55:20.221218 22368 net.cpp:411] data_hdf5 -> data
I0525 20:55:20.221238 22368 net.cpp:411] data_hdf5 -> label
I0525 20:55:20.221259 22368 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 20:55:20.239300 22368 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 20:55:41.644196 22368 net.cpp:150] Setting up data_hdf5
I0525 20:55:41.644362 22368 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 20:55:41.644381 22368 net.cpp:157] Top shape: 100 (100)
I0525 20:55:41.644392 22368 net.cpp:165] Memory required for data: 2540400
I0525 20:55:41.644407 22368 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 20:55:41.644435 22368 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 20:55:41.644454 22368 net.cpp:454] label_data_hdf5_1_split <- label
I0525 20:55:41.644490 22368 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 20:55:41.644520 22368 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 20:55:41.644606 22368 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 20:55:41.644624 22368 net.cpp:157] Top shape: 100 (100)
I0525 20:55:41.644639 22368 net.cpp:157] Top shape: 100 (100)
I0525 20:55:41.644652 22368 net.cpp:165] Memory required for data: 2541200
I0525 20:55:41.644665 22368 layer_factory.hpp:77] Creating layer conv1
I0525 20:55:41.644697 22368 net.cpp:106] Creating Layer conv1
I0525 20:55:41.644711 22368 net.cpp:454] conv1 <- data
I0525 20:55:41.644728 22368 net.cpp:411] conv1 -> conv1
I0525 20:55:41.646680 22368 net.cpp:150] Setting up conv1
I0525 20:55:41.646705 22368 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:55:41.646728 22368 net.cpp:165] Memory required for data: 30189200
I0525 20:55:41.646750 22368 layer_factory.hpp:77] Creating layer relu1
I0525 20:55:41.646771 22368 net.cpp:106] Creating Layer relu1
I0525 20:55:41.646793 22368 net.cpp:454] relu1 <- conv1
I0525 20:55:41.646809 22368 net.cpp:397] relu1 -> conv1 (in-place)
I0525 20:55:41.647392 22368 net.cpp:150] Setting up relu1
I0525 20:55:41.647411 22368 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 20:55:41.647428 22368 net.cpp:165] Memory required for data: 57837200
I0525 20:55:41.647439 22368 layer_factory.hpp:77] Creating layer pool1
I0525 20:55:41.647460 22368 net.cpp:106] Creating Layer pool1
I0525 20:55:41.647480 22368 net.cpp:454] pool1 <- conv1
I0525 20:55:41.647498 22368 net.cpp:411] pool1 -> pool1
I0525 20:55:41.647586 22368 net.cpp:150] Setting up pool1
I0525 20:55:41.647604 22368 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 20:55:41.647617 22368 net.cpp:165] Memory required for data: 71661200
I0525 20:55:41.647629 22368 layer_factory.hpp:77] Creating layer conv2
I0525 20:55:41.647652 22368 net.cpp:106] Creating Layer conv2
I0525 20:55:41.647671 22368 net.cpp:454] conv2 <- pool1
I0525 20:55:41.647688 22368 net.cpp:411] conv2 -> conv2
I0525 20:55:41.649636 22368 net.cpp:150] Setting up conv2
I0525 20:55:41.649660 22368 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:55:41.649680 22368 net.cpp:165] Memory required for data: 91533200
I0525 20:55:41.649703 22368 layer_factory.hpp:77] Creating layer relu2
I0525 20:55:41.649722 22368 net.cpp:106] Creating Layer relu2
I0525 20:55:41.649744 22368 net.cpp:454] relu2 <- conv2
I0525 20:55:41.649760 22368 net.cpp:397] relu2 -> conv2 (in-place)
I0525 20:55:41.650110 22368 net.cpp:150] Setting up relu2
I0525 20:55:41.650130 22368 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 20:55:41.650143 22368 net.cpp:165] Memory required for data: 111405200
I0525 20:55:41.650158 22368 layer_factory.hpp:77] Creating layer pool2
I0525 20:55:41.650180 22368 net.cpp:106] Creating Layer pool2
I0525 20:55:41.650193 22368 net.cpp:454] pool2 <- conv2
I0525 20:55:41.650209 22368 net.cpp:411] pool2 -> pool2
I0525 20:55:41.650302 22368 net.cpp:150] Setting up pool2
I0525 20:55:41.650319 22368 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 20:55:41.650334 22368 net.cpp:165] Memory required for data: 121341200
I0525 20:55:41.650347 22368 layer_factory.hpp:77] Creating layer conv3
I0525 20:55:41.650378 22368 net.cpp:106] Creating Layer conv3
I0525 20:55:41.650391 22368 net.cpp:454] conv3 <- pool2
I0525 20:55:41.650408 22368 net.cpp:411] conv3 -> conv3
I0525 20:55:41.652427 22368 net.cpp:150] Setting up conv3
I0525 20:55:41.652452 22368 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:55:41.652472 22368 net.cpp:165] Memory required for data: 132182800
I0525 20:55:41.652519 22368 layer_factory.hpp:77] Creating layer relu3
I0525 20:55:41.652545 22368 net.cpp:106] Creating Layer relu3
I0525 20:55:41.652560 22368 net.cpp:454] relu3 <- conv3
I0525 20:55:41.652575 22368 net.cpp:397] relu3 -> conv3 (in-place)
I0525 20:55:41.653072 22368 net.cpp:150] Setting up relu3
I0525 20:55:41.653095 22368 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 20:55:41.653108 22368 net.cpp:165] Memory required for data: 143024400
I0525 20:55:41.653125 22368 layer_factory.hpp:77] Creating layer pool3
I0525 20:55:41.653148 22368 net.cpp:106] Creating Layer pool3
I0525 20:55:41.653162 22368 net.cpp:454] pool3 <- conv3
I0525 20:55:41.653178 22368 net.cpp:411] pool3 -> pool3
I0525 20:55:41.653264 22368 net.cpp:150] Setting up pool3
I0525 20:55:41.653281 22368 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 20:55:41.653296 22368 net.cpp:165] Memory required for data: 148445200
I0525 20:55:41.653308 22368 layer_factory.hpp:77] Creating layer conv4
I0525 20:55:41.653329 22368 net.cpp:106] Creating Layer conv4
I0525 20:55:41.653343 22368 net.cpp:454] conv4 <- pool3
I0525 20:55:41.653367 22368 net.cpp:411] conv4 -> conv4
I0525 20:55:41.655478 22368 net.cpp:150] Setting up conv4
I0525 20:55:41.655503 22368 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:55:41.655524 22368 net.cpp:165] Memory required for data: 152074000
I0525 20:55:41.655542 22368 layer_factory.hpp:77] Creating layer relu4
I0525 20:55:41.655562 22368 net.cpp:106] Creating Layer relu4
I0525 20:55:41.655575 22368 net.cpp:454] relu4 <- conv4
I0525 20:55:41.655601 22368 net.cpp:397] relu4 -> conv4 (in-place)
I0525 20:55:41.656090 22368 net.cpp:150] Setting up relu4
I0525 20:55:41.656113 22368 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 20:55:41.656126 22368 net.cpp:165] Memory required for data: 155702800
I0525 20:55:41.656142 22368 layer_factory.hpp:77] Creating layer pool4
I0525 20:55:41.656167 22368 net.cpp:106] Creating Layer pool4
I0525 20:55:41.656179 22368 net.cpp:454] pool4 <- conv4
I0525 20:55:41.656195 22368 net.cpp:411] pool4 -> pool4
I0525 20:55:41.656280 22368 net.cpp:150] Setting up pool4
I0525 20:55:41.656297 22368 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 20:55:41.656312 22368 net.cpp:165] Memory required for data: 157517200
I0525 20:55:41.656324 22368 layer_factory.hpp:77] Creating layer ip1
I0525 20:55:41.656349 22368 net.cpp:106] Creating Layer ip1
I0525 20:55:41.656361 22368 net.cpp:454] ip1 <- pool4
I0525 20:55:41.656384 22368 net.cpp:411] ip1 -> ip1
I0525 20:55:41.671836 22368 net.cpp:150] Setting up ip1
I0525 20:55:41.671869 22368 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:55:41.671890 22368 net.cpp:165] Memory required for data: 157595600
I0525 20:55:41.671916 22368 layer_factory.hpp:77] Creating layer relu5
I0525 20:55:41.671936 22368 net.cpp:106] Creating Layer relu5
I0525 20:55:41.671962 22368 net.cpp:454] relu5 <- ip1
I0525 20:55:41.671978 22368 net.cpp:397] relu5 -> ip1 (in-place)
I0525 20:55:41.672345 22368 net.cpp:150] Setting up relu5
I0525 20:55:41.672365 22368 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:55:41.672379 22368 net.cpp:165] Memory required for data: 157674000
I0525 20:55:41.672390 22368 layer_factory.hpp:77] Creating layer drop1
I0525 20:55:41.672422 22368 net.cpp:106] Creating Layer drop1
I0525 20:55:41.672435 22368 net.cpp:454] drop1 <- ip1
I0525 20:55:41.672451 22368 net.cpp:397] drop1 -> ip1 (in-place)
I0525 20:55:41.672513 22368 net.cpp:150] Setting up drop1
I0525 20:55:41.672530 22368 net.cpp:157] Top shape: 100 196 (19600)
I0525 20:55:41.672550 22368 net.cpp:165] Memory required for data: 157752400
I0525 20:55:41.672564 22368 layer_factory.hpp:77] Creating layer ip2
I0525 20:55:41.672580 22368 net.cpp:106] Creating Layer ip2
I0525 20:55:41.672595 22368 net.cpp:454] ip2 <- ip1
I0525 20:55:41.672619 22368 net.cpp:411] ip2 -> ip2
I0525 20:55:41.673115 22368 net.cpp:150] Setting up ip2
I0525 20:55:41.673133 22368 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:55:41.673146 22368 net.cpp:165] Memory required for data: 157791600
I0525 20:55:41.673167 22368 layer_factory.hpp:77] Creating layer relu6
I0525 20:55:41.673203 22368 net.cpp:106] Creating Layer relu6
I0525 20:55:41.673216 22368 net.cpp:454] relu6 <- ip2
I0525 20:55:41.673233 22368 net.cpp:397] relu6 -> ip2 (in-place)
I0525 20:55:41.673795 22368 net.cpp:150] Setting up relu6
I0525 20:55:41.673817 22368 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:55:41.673830 22368 net.cpp:165] Memory required for data: 157830800
I0525 20:55:41.673843 22368 layer_factory.hpp:77] Creating layer drop2
I0525 20:55:41.673862 22368 net.cpp:106] Creating Layer drop2
I0525 20:55:41.673884 22368 net.cpp:454] drop2 <- ip2
I0525 20:55:41.673900 22368 net.cpp:397] drop2 -> ip2 (in-place)
I0525 20:55:41.673954 22368 net.cpp:150] Setting up drop2
I0525 20:55:41.673974 22368 net.cpp:157] Top shape: 100 98 (9800)
I0525 20:55:41.673993 22368 net.cpp:165] Memory required for data: 157870000
I0525 20:55:41.674006 22368 layer_factory.hpp:77] Creating layer ip3
I0525 20:55:41.674028 22368 net.cpp:106] Creating Layer ip3
I0525 20:55:41.674041 22368 net.cpp:454] ip3 <- ip2
I0525 20:55:41.674060 22368 net.cpp:411] ip3 -> ip3
I0525 20:55:41.674305 22368 net.cpp:150] Setting up ip3
I0525 20:55:41.674324 22368 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:55:41.674336 22368 net.cpp:165] Memory required for data: 157874400
I0525 20:55:41.674357 22368 layer_factory.hpp:77] Creating layer drop3
I0525 20:55:41.674379 22368 net.cpp:106] Creating Layer drop3
I0525 20:55:41.674392 22368 net.cpp:454] drop3 <- ip3
I0525 20:55:41.674408 22368 net.cpp:397] drop3 -> ip3 (in-place)
I0525 20:55:41.674463 22368 net.cpp:150] Setting up drop3
I0525 20:55:41.674479 22368 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:55:41.674491 22368 net.cpp:165] Memory required for data: 157878800
I0525 20:55:41.674507 22368 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 20:55:41.674523 22368 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 20:55:41.674535 22368 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 20:55:41.674561 22368 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 20:55:41.674579 22368 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 20:55:41.674666 22368 net.cpp:150] Setting up ip3_drop3_0_split
I0525 20:55:41.674684 22368 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:55:41.674698 22368 net.cpp:157] Top shape: 100 11 (1100)
I0525 20:55:41.674713 22368 net.cpp:165] Memory required for data: 157887600
I0525 20:55:41.674726 22368 layer_factory.hpp:77] Creating layer accuracy
I0525 20:55:41.674754 22368 net.cpp:106] Creating Layer accuracy
I0525 20:55:41.674772 22368 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 20:55:41.674787 22368 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 20:55:41.674803 22368 net.cpp:411] accuracy -> accuracy
I0525 20:55:41.674836 22368 net.cpp:150] Setting up accuracy
I0525 20:55:41.674852 22368 net.cpp:157] Top shape: (1)
I0525 20:55:41.674865 22368 net.cpp:165] Memory required for data: 157887604
I0525 20:55:41.674876 22368 layer_factory.hpp:77] Creating layer loss
I0525 20:55:41.674892 22368 net.cpp:106] Creating Layer loss
I0525 20:55:41.674907 22368 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 20:55:41.674921 22368 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 20:55:41.674943 22368 net.cpp:411] loss -> loss
I0525 20:55:41.674968 22368 layer_factory.hpp:77] Creating layer loss
I0525 20:55:41.675482 22368 net.cpp:150] Setting up loss
I0525 20:55:41.675503 22368 net.cpp:157] Top shape: (1)
I0525 20:55:41.675515 22368 net.cpp:160]     with loss weight 1
I0525 20:55:41.675539 22368 net.cpp:165] Memory required for data: 157887608
I0525 20:55:41.675560 22368 net.cpp:226] loss needs backward computation.
I0525 20:55:41.675575 22368 net.cpp:228] accuracy does not need backward computation.
I0525 20:55:41.675590 22368 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 20:55:41.675602 22368 net.cpp:226] drop3 needs backward computation.
I0525 20:55:41.675614 22368 net.cpp:226] ip3 needs backward computation.
I0525 20:55:41.675631 22368 net.cpp:226] drop2 needs backward computation.
I0525 20:55:41.675657 22368 net.cpp:226] relu6 needs backward computation.
I0525 20:55:41.675669 22368 net.cpp:226] ip2 needs backward computation.
I0525 20:55:41.675686 22368 net.cpp:226] drop1 needs backward computation.
I0525 20:55:41.675698 22368 net.cpp:226] relu5 needs backward computation.
I0525 20:55:41.675709 22368 net.cpp:226] ip1 needs backward computation.
I0525 20:55:41.675724 22368 net.cpp:226] pool4 needs backward computation.
I0525 20:55:41.675737 22368 net.cpp:226] relu4 needs backward computation.
I0525 20:55:41.675756 22368 net.cpp:226] conv4 needs backward computation.
I0525 20:55:41.675770 22368 net.cpp:226] pool3 needs backward computation.
I0525 20:55:41.675786 22368 net.cpp:226] relu3 needs backward computation.
I0525 20:55:41.675798 22368 net.cpp:226] conv3 needs backward computation.
I0525 20:55:41.675811 22368 net.cpp:226] pool2 needs backward computation.
I0525 20:55:41.675825 22368 net.cpp:226] relu2 needs backward computation.
I0525 20:55:41.675837 22368 net.cpp:226] conv2 needs backward computation.
I0525 20:55:41.675858 22368 net.cpp:226] pool1 needs backward computation.
I0525 20:55:41.675871 22368 net.cpp:226] relu1 needs backward computation.
I0525 20:55:41.675889 22368 net.cpp:226] conv1 needs backward computation.
I0525 20:55:41.675904 22368 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 20:55:41.675916 22368 net.cpp:228] data_hdf5 does not need backward computation.
I0525 20:55:41.675928 22368 net.cpp:270] This network produces output accuracy
I0525 20:55:41.675943 22368 net.cpp:270] This network produces output loss
I0525 20:55:41.675976 22368 net.cpp:283] Network initialization done.
I0525 20:55:41.676110 22368 solver.cpp:60] Solver scaffolding done.
I0525 20:55:41.677280 22368 caffe.cpp:212] Starting Optimization
I0525 20:55:41.677299 22368 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 20:55:41.677315 22368 solver.cpp:289] Learning Rate Policy: fixed
I0525 20:55:41.678387 22368 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 20:56:29.513770 22368 solver.cpp:409]     Test net output #0: accuracy = 0.117813
I0525 20:56:29.513933 22368 solver.cpp:409]     Test net output #1: loss = 2.39666 (* 1 = 2.39666 loss)
I0525 20:56:29.546778 22368 solver.cpp:237] Iteration 0, loss = 2.39543
I0525 20:56:29.546818 22368 solver.cpp:253]     Train net output #0: loss = 2.39543 (* 1 = 2.39543 loss)
I0525 20:56:29.546839 22368 sgd_solver.cpp:106] Iteration 0, lr = 0.004
I0525 20:56:38.267794 22368 solver.cpp:237] Iteration 150, loss = 2.27694
I0525 20:56:38.267832 22368 solver.cpp:253]     Train net output #0: loss = 2.27694 (* 1 = 2.27694 loss)
I0525 20:56:38.267851 22368 sgd_solver.cpp:106] Iteration 150, lr = 0.004
I0525 20:56:46.988914 22368 solver.cpp:237] Iteration 300, loss = 2.10507
I0525 20:56:46.988951 22368 solver.cpp:253]     Train net output #0: loss = 2.10507 (* 1 = 2.10507 loss)
I0525 20:56:46.988970 22368 sgd_solver.cpp:106] Iteration 300, lr = 0.004
I0525 20:56:55.710214 22368 solver.cpp:237] Iteration 450, loss = 1.88901
I0525 20:56:55.710264 22368 solver.cpp:253]     Train net output #0: loss = 1.88901 (* 1 = 1.88901 loss)
I0525 20:56:55.710291 22368 sgd_solver.cpp:106] Iteration 450, lr = 0.004
I0525 20:57:04.436991 22368 solver.cpp:237] Iteration 600, loss = 1.83761
I0525 20:57:04.437144 22368 solver.cpp:253]     Train net output #0: loss = 1.83761 (* 1 = 1.83761 loss)
I0525 20:57:04.437161 22368 sgd_solver.cpp:106] Iteration 600, lr = 0.004
I0525 20:57:13.162739 22368 solver.cpp:237] Iteration 750, loss = 2.03665
I0525 20:57:13.162776 22368 solver.cpp:253]     Train net output #0: loss = 2.03665 (* 1 = 2.03665 loss)
I0525 20:57:13.162801 22368 sgd_solver.cpp:106] Iteration 750, lr = 0.004
I0525 20:57:21.891453 22368 solver.cpp:237] Iteration 900, loss = 1.82682
I0525 20:57:21.891499 22368 solver.cpp:253]     Train net output #0: loss = 1.82682 (* 1 = 1.82682 loss)
I0525 20:57:21.891525 22368 sgd_solver.cpp:106] Iteration 900, lr = 0.004
I0525 20:57:52.803031 22368 solver.cpp:237] Iteration 1050, loss = 1.84437
I0525 20:57:52.803205 22368 solver.cpp:253]     Train net output #0: loss = 1.84437 (* 1 = 1.84437 loss)
I0525 20:57:52.803222 22368 sgd_solver.cpp:106] Iteration 1050, lr = 0.004
I0525 20:58:01.528558 22368 solver.cpp:237] Iteration 1200, loss = 1.62562
I0525 20:58:01.528594 22368 solver.cpp:253]     Train net output #0: loss = 1.62562 (* 1 = 1.62562 loss)
I0525 20:58:01.528616 22368 sgd_solver.cpp:106] Iteration 1200, lr = 0.004
I0525 20:58:10.256808 22368 solver.cpp:237] Iteration 1350, loss = 1.71022
I0525 20:58:10.256856 22368 solver.cpp:253]     Train net output #0: loss = 1.71022 (* 1 = 1.71022 loss)
I0525 20:58:10.256880 22368 sgd_solver.cpp:106] Iteration 1350, lr = 0.004
I0525 20:58:18.925010 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_1500.caffemodel
I0525 20:58:19.007244 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_1500.solverstate
I0525 20:58:19.053931 22368 solver.cpp:237] Iteration 1500, loss = 1.82879
I0525 20:58:19.053987 22368 solver.cpp:253]     Train net output #0: loss = 1.82879 (* 1 = 1.82879 loss)
I0525 20:58:19.054006 22368 sgd_solver.cpp:106] Iteration 1500, lr = 0.004
I0525 20:58:27.778610 22368 solver.cpp:237] Iteration 1650, loss = 1.59964
I0525 20:58:27.778766 22368 solver.cpp:253]     Train net output #0: loss = 1.59964 (* 1 = 1.59964 loss)
I0525 20:58:27.778784 22368 sgd_solver.cpp:106] Iteration 1650, lr = 0.004
I0525 20:58:36.498826 22368 solver.cpp:237] Iteration 1800, loss = 1.72371
I0525 20:58:36.498873 22368 solver.cpp:253]     Train net output #0: loss = 1.72371 (* 1 = 1.72371 loss)
I0525 20:58:36.498890 22368 sgd_solver.cpp:106] Iteration 1800, lr = 0.004
I0525 20:58:45.222560 22368 solver.cpp:237] Iteration 1950, loss = 1.62244
I0525 20:58:45.222597 22368 solver.cpp:253]     Train net output #0: loss = 1.62244 (* 1 = 1.62244 loss)
I0525 20:58:45.222615 22368 sgd_solver.cpp:106] Iteration 1950, lr = 0.004
I0525 20:59:16.139137 22368 solver.cpp:237] Iteration 2100, loss = 1.40424
I0525 20:59:16.139312 22368 solver.cpp:253]     Train net output #0: loss = 1.40424 (* 1 = 1.40424 loss)
I0525 20:59:16.139329 22368 sgd_solver.cpp:106] Iteration 2100, lr = 0.004
I0525 20:59:24.867086 22368 solver.cpp:237] Iteration 2250, loss = 1.42887
I0525 20:59:24.867138 22368 solver.cpp:253]     Train net output #0: loss = 1.42887 (* 1 = 1.42887 loss)
I0525 20:59:24.867166 22368 sgd_solver.cpp:106] Iteration 2250, lr = 0.004
I0525 20:59:33.593816 22368 solver.cpp:237] Iteration 2400, loss = 1.59086
I0525 20:59:33.593853 22368 solver.cpp:253]     Train net output #0: loss = 1.59086 (* 1 = 1.59086 loss)
I0525 20:59:33.593876 22368 sgd_solver.cpp:106] Iteration 2400, lr = 0.004
I0525 20:59:42.320366 22368 solver.cpp:237] Iteration 2550, loss = 1.47422
I0525 20:59:42.320405 22368 solver.cpp:253]     Train net output #0: loss = 1.47422 (* 1 = 1.47422 loss)
I0525 20:59:42.320422 22368 sgd_solver.cpp:106] Iteration 2550, lr = 0.004
I0525 20:59:51.049273 22368 solver.cpp:237] Iteration 2700, loss = 1.3932
I0525 20:59:51.049434 22368 solver.cpp:253]     Train net output #0: loss = 1.3932 (* 1 = 1.3932 loss)
I0525 20:59:51.049453 22368 sgd_solver.cpp:106] Iteration 2700, lr = 0.004
I0525 20:59:59.776273 22368 solver.cpp:237] Iteration 2850, loss = 1.56323
I0525 20:59:59.776309 22368 solver.cpp:253]     Train net output #0: loss = 1.56323 (* 1 = 1.56323 loss)
I0525 20:59:59.776327 22368 sgd_solver.cpp:106] Iteration 2850, lr = 0.004
I0525 21:00:08.443126 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_3000.caffemodel
I0525 21:00:08.523133 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_3000.solverstate
I0525 21:00:08.550041 22368 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 21:00:55.400187 22368 solver.cpp:409]     Test net output #0: accuracy = 0.778762
I0525 21:00:55.400348 22368 solver.cpp:409]     Test net output #1: loss = 0.739544 (* 1 = 0.739544 loss)
I0525 21:01:17.631345 22368 solver.cpp:237] Iteration 3000, loss = 1.41762
I0525 21:01:17.631407 22368 solver.cpp:253]     Train net output #0: loss = 1.41762 (* 1 = 1.41762 loss)
I0525 21:01:17.631427 22368 sgd_solver.cpp:106] Iteration 3000, lr = 0.004
I0525 21:01:26.370240 22368 solver.cpp:237] Iteration 3150, loss = 1.36803
I0525 21:01:26.370383 22368 solver.cpp:253]     Train net output #0: loss = 1.36803 (* 1 = 1.36803 loss)
I0525 21:01:26.370403 22368 sgd_solver.cpp:106] Iteration 3150, lr = 0.004
I0525 21:01:35.110406 22368 solver.cpp:237] Iteration 3300, loss = 1.49455
I0525 21:01:35.110445 22368 solver.cpp:253]     Train net output #0: loss = 1.49455 (* 1 = 1.49455 loss)
I0525 21:01:35.110461 22368 sgd_solver.cpp:106] Iteration 3300, lr = 0.004
I0525 21:01:43.846961 22368 solver.cpp:237] Iteration 3450, loss = 1.65432
I0525 21:01:43.846997 22368 solver.cpp:253]     Train net output #0: loss = 1.65432 (* 1 = 1.65432 loss)
I0525 21:01:43.847021 22368 sgd_solver.cpp:106] Iteration 3450, lr = 0.004
I0525 21:01:52.585465 22368 solver.cpp:237] Iteration 3600, loss = 1.45428
I0525 21:01:52.585515 22368 solver.cpp:253]     Train net output #0: loss = 1.45428 (* 1 = 1.45428 loss)
I0525 21:01:52.585544 22368 sgd_solver.cpp:106] Iteration 3600, lr = 0.004
I0525 21:02:01.323134 22368 solver.cpp:237] Iteration 3750, loss = 1.21865
I0525 21:02:01.323272 22368 solver.cpp:253]     Train net output #0: loss = 1.21865 (* 1 = 1.21865 loss)
I0525 21:02:01.323289 22368 sgd_solver.cpp:106] Iteration 3750, lr = 0.004
I0525 21:02:10.060977 22368 solver.cpp:237] Iteration 3900, loss = 1.16081
I0525 21:02:10.061012 22368 solver.cpp:253]     Train net output #0: loss = 1.16081 (* 1 = 1.16081 loss)
I0525 21:02:10.061031 22368 sgd_solver.cpp:106] Iteration 3900, lr = 0.004
I0525 21:02:41.000874 22368 solver.cpp:237] Iteration 4050, loss = 1.43232
I0525 21:02:41.001039 22368 solver.cpp:253]     Train net output #0: loss = 1.43232 (* 1 = 1.43232 loss)
I0525 21:02:41.001058 22368 sgd_solver.cpp:106] Iteration 4050, lr = 0.004
I0525 21:02:49.739743 22368 solver.cpp:237] Iteration 4200, loss = 1.21164
I0525 21:02:49.739785 22368 solver.cpp:253]     Train net output #0: loss = 1.21164 (* 1 = 1.21164 loss)
I0525 21:02:49.739802 22368 sgd_solver.cpp:106] Iteration 4200, lr = 0.004
I0525 21:02:58.473989 22368 solver.cpp:237] Iteration 4350, loss = 1.26253
I0525 21:02:58.474027 22368 solver.cpp:253]     Train net output #0: loss = 1.26253 (* 1 = 1.26253 loss)
I0525 21:02:58.474045 22368 sgd_solver.cpp:106] Iteration 4350, lr = 0.004
I0525 21:03:07.160015 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_4500.caffemodel
I0525 21:03:07.240751 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_4500.solverstate
I0525 21:03:07.286835 22368 solver.cpp:237] Iteration 4500, loss = 1.11726
I0525 21:03:07.286896 22368 solver.cpp:253]     Train net output #0: loss = 1.11726 (* 1 = 1.11726 loss)
I0525 21:03:07.286914 22368 sgd_solver.cpp:106] Iteration 4500, lr = 0.004
I0525 21:03:16.022896 22368 solver.cpp:237] Iteration 4650, loss = 1.34061
I0525 21:03:16.023061 22368 solver.cpp:253]     Train net output #0: loss = 1.34061 (* 1 = 1.34061 loss)
I0525 21:03:16.023078 22368 sgd_solver.cpp:106] Iteration 4650, lr = 0.004
I0525 21:03:24.760458 22368 solver.cpp:237] Iteration 4800, loss = 1.39925
I0525 21:03:24.760494 22368 solver.cpp:253]     Train net output #0: loss = 1.39925 (* 1 = 1.39925 loss)
I0525 21:03:24.760525 22368 sgd_solver.cpp:106] Iteration 4800, lr = 0.004
I0525 21:03:33.503408 22368 solver.cpp:237] Iteration 4950, loss = 1.49554
I0525 21:03:33.503458 22368 solver.cpp:253]     Train net output #0: loss = 1.49554 (* 1 = 1.49554 loss)
I0525 21:03:33.503485 22368 sgd_solver.cpp:106] Iteration 4950, lr = 0.004
I0525 21:04:04.481323 22368 solver.cpp:237] Iteration 5100, loss = 1.38559
I0525 21:04:04.481487 22368 solver.cpp:253]     Train net output #0: loss = 1.38559 (* 1 = 1.38559 loss)
I0525 21:04:04.481504 22368 sgd_solver.cpp:106] Iteration 5100, lr = 0.004
I0525 21:04:13.220423 22368 solver.cpp:237] Iteration 5250, loss = 1.29433
I0525 21:04:13.220460 22368 solver.cpp:253]     Train net output #0: loss = 1.29433 (* 1 = 1.29433 loss)
I0525 21:04:13.220484 22368 sgd_solver.cpp:106] Iteration 5250, lr = 0.004
I0525 21:04:21.955674 22368 solver.cpp:237] Iteration 5400, loss = 1.30398
I0525 21:04:21.955729 22368 solver.cpp:253]     Train net output #0: loss = 1.30398 (* 1 = 1.30398 loss)
I0525 21:04:21.955756 22368 sgd_solver.cpp:106] Iteration 5400, lr = 0.004
I0525 21:04:30.694016 22368 solver.cpp:237] Iteration 5550, loss = 1.32678
I0525 21:04:30.694052 22368 solver.cpp:253]     Train net output #0: loss = 1.32678 (* 1 = 1.32678 loss)
I0525 21:04:30.694070 22368 sgd_solver.cpp:106] Iteration 5550, lr = 0.004
I0525 21:04:39.435534 22368 solver.cpp:237] Iteration 5700, loss = 1.38206
I0525 21:04:39.435693 22368 solver.cpp:253]     Train net output #0: loss = 1.38206 (* 1 = 1.38206 loss)
I0525 21:04:39.435708 22368 sgd_solver.cpp:106] Iteration 5700, lr = 0.004
I0525 21:04:48.182139 22368 solver.cpp:237] Iteration 5850, loss = 1.26588
I0525 21:04:48.182193 22368 solver.cpp:253]     Train net output #0: loss = 1.26588 (* 1 = 1.26588 loss)
I0525 21:04:48.182220 22368 sgd_solver.cpp:106] Iteration 5850, lr = 0.004
I0525 21:04:56.860844 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_6000.caffemodel
I0525 21:04:56.942044 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_6000.solverstate
I0525 21:04:56.969866 22368 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 21:06:04.605929 22368 solver.cpp:409]     Test net output #0: accuracy = 0.82096
I0525 21:06:04.606101 22368 solver.cpp:409]     Test net output #1: loss = 0.641837 (* 1 = 0.641837 loss)
I0525 21:06:26.864408 22368 solver.cpp:237] Iteration 6000, loss = 1.39667
I0525 21:06:26.864472 22368 solver.cpp:253]     Train net output #0: loss = 1.39667 (* 1 = 1.39667 loss)
I0525 21:06:26.864490 22368 sgd_solver.cpp:106] Iteration 6000, lr = 0.004
I0525 21:06:35.595723 22368 solver.cpp:237] Iteration 6150, loss = 1.291
I0525 21:06:35.595876 22368 solver.cpp:253]     Train net output #0: loss = 1.291 (* 1 = 1.291 loss)
I0525 21:06:35.595893 22368 sgd_solver.cpp:106] Iteration 6150, lr = 0.004
I0525 21:06:44.326867 22368 solver.cpp:237] Iteration 6300, loss = 1.39855
I0525 21:06:44.326905 22368 solver.cpp:253]     Train net output #0: loss = 1.39855 (* 1 = 1.39855 loss)
I0525 21:06:44.326923 22368 sgd_solver.cpp:106] Iteration 6300, lr = 0.004
I0525 21:06:53.060788 22368 solver.cpp:237] Iteration 6450, loss = 1.5283
I0525 21:06:53.060838 22368 solver.cpp:253]     Train net output #0: loss = 1.5283 (* 1 = 1.5283 loss)
I0525 21:06:53.060855 22368 sgd_solver.cpp:106] Iteration 6450, lr = 0.004
I0525 21:07:01.801975 22368 solver.cpp:237] Iteration 6600, loss = 1.35963
I0525 21:07:01.802011 22368 solver.cpp:253]     Train net output #0: loss = 1.35963 (* 1 = 1.35963 loss)
I0525 21:07:01.802034 22368 sgd_solver.cpp:106] Iteration 6600, lr = 0.004
I0525 21:07:10.536396 22368 solver.cpp:237] Iteration 6750, loss = 1.30106
I0525 21:07:10.536550 22368 solver.cpp:253]     Train net output #0: loss = 1.30106 (* 1 = 1.30106 loss)
I0525 21:07:10.536567 22368 sgd_solver.cpp:106] Iteration 6750, lr = 0.004
I0525 21:07:19.269194 22368 solver.cpp:237] Iteration 6900, loss = 1.41903
I0525 21:07:19.269239 22368 solver.cpp:253]     Train net output #0: loss = 1.41903 (* 1 = 1.41903 loss)
I0525 21:07:19.269256 22368 sgd_solver.cpp:106] Iteration 6900, lr = 0.004
I0525 21:07:50.203011 22368 solver.cpp:237] Iteration 7050, loss = 1.33013
I0525 21:07:50.203172 22368 solver.cpp:253]     Train net output #0: loss = 1.33013 (* 1 = 1.33013 loss)
I0525 21:07:50.203191 22368 sgd_solver.cpp:106] Iteration 7050, lr = 0.004
I0525 21:07:58.929529 22368 solver.cpp:237] Iteration 7200, loss = 1.25145
I0525 21:07:58.929566 22368 solver.cpp:253]     Train net output #0: loss = 1.25145 (* 1 = 1.25145 loss)
I0525 21:07:58.929590 22368 sgd_solver.cpp:106] Iteration 7200, lr = 0.004
I0525 21:08:07.662830 22368 solver.cpp:237] Iteration 7350, loss = 1.21078
I0525 21:08:07.662883 22368 solver.cpp:253]     Train net output #0: loss = 1.21078 (* 1 = 1.21078 loss)
I0525 21:08:07.662910 22368 sgd_solver.cpp:106] Iteration 7350, lr = 0.004
I0525 21:08:16.335844 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_7500.caffemodel
I0525 21:08:16.417165 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_7500.solverstate
I0525 21:08:16.463021 22368 solver.cpp:237] Iteration 7500, loss = 1.34345
I0525 21:08:16.463080 22368 solver.cpp:253]     Train net output #0: loss = 1.34345 (* 1 = 1.34345 loss)
I0525 21:08:16.463099 22368 sgd_solver.cpp:106] Iteration 7500, lr = 0.004
I0525 21:08:25.197301 22368 solver.cpp:237] Iteration 7650, loss = 1.38158
I0525 21:08:25.197448 22368 solver.cpp:253]     Train net output #0: loss = 1.38158 (* 1 = 1.38158 loss)
I0525 21:08:25.197465 22368 sgd_solver.cpp:106] Iteration 7650, lr = 0.004
I0525 21:08:33.933630 22368 solver.cpp:237] Iteration 7800, loss = 1.44218
I0525 21:08:33.933686 22368 solver.cpp:253]     Train net output #0: loss = 1.44218 (* 1 = 1.44218 loss)
I0525 21:08:33.933712 22368 sgd_solver.cpp:106] Iteration 7800, lr = 0.004
I0525 21:08:42.672123 22368 solver.cpp:237] Iteration 7950, loss = 1.63233
I0525 21:08:42.672159 22368 solver.cpp:253]     Train net output #0: loss = 1.63233 (* 1 = 1.63233 loss)
I0525 21:08:42.672178 22368 sgd_solver.cpp:106] Iteration 7950, lr = 0.004
I0525 21:09:13.598875 22368 solver.cpp:237] Iteration 8100, loss = 1.31012
I0525 21:09:13.599056 22368 solver.cpp:253]     Train net output #0: loss = 1.31012 (* 1 = 1.31012 loss)
I0525 21:09:13.599071 22368 sgd_solver.cpp:106] Iteration 8100, lr = 0.004
I0525 21:09:22.333123 22368 solver.cpp:237] Iteration 8250, loss = 1.44703
I0525 21:09:22.333178 22368 solver.cpp:253]     Train net output #0: loss = 1.44703 (* 1 = 1.44703 loss)
I0525 21:09:22.333202 22368 sgd_solver.cpp:106] Iteration 8250, lr = 0.004
I0525 21:09:31.070729 22368 solver.cpp:237] Iteration 8400, loss = 1.17632
I0525 21:09:31.070765 22368 solver.cpp:253]     Train net output #0: loss = 1.17632 (* 1 = 1.17632 loss)
I0525 21:09:31.070783 22368 sgd_solver.cpp:106] Iteration 8400, lr = 0.004
I0525 21:09:39.805205 22368 solver.cpp:237] Iteration 8550, loss = 1.44312
I0525 21:09:39.805243 22368 solver.cpp:253]     Train net output #0: loss = 1.44312 (* 1 = 1.44312 loss)
I0525 21:09:39.805260 22368 sgd_solver.cpp:106] Iteration 8550, lr = 0.004
I0525 21:09:48.540978 22368 solver.cpp:237] Iteration 8700, loss = 1.39653
I0525 21:09:48.541138 22368 solver.cpp:253]     Train net output #0: loss = 1.39653 (* 1 = 1.39653 loss)
I0525 21:09:48.541158 22368 sgd_solver.cpp:106] Iteration 8700, lr = 0.004
I0525 21:09:57.270118 22368 solver.cpp:237] Iteration 8850, loss = 0.973745
I0525 21:09:57.270160 22368 solver.cpp:253]     Train net output #0: loss = 0.973745 (* 1 = 0.973745 loss)
I0525 21:09:57.270177 22368 sgd_solver.cpp:106] Iteration 8850, lr = 0.004
I0525 21:10:05.948815 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_9000.caffemodel
I0525 21:10:06.027513 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_9000.solverstate
I0525 21:10:06.053601 22368 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 21:10:52.582835 22368 solver.cpp:409]     Test net output #0: accuracy = 0.838386
I0525 21:10:52.583015 22368 solver.cpp:409]     Test net output #1: loss = 0.529841 (* 1 = 0.529841 loss)
I0525 21:11:14.979032 22368 solver.cpp:237] Iteration 9000, loss = 1.35665
I0525 21:11:14.979094 22368 solver.cpp:253]     Train net output #0: loss = 1.35665 (* 1 = 1.35665 loss)
I0525 21:11:14.979120 22368 sgd_solver.cpp:106] Iteration 9000, lr = 0.004
I0525 21:11:23.715850 22368 solver.cpp:237] Iteration 9150, loss = 1.26617
I0525 21:11:23.716004 22368 solver.cpp:253]     Train net output #0: loss = 1.26617 (* 1 = 1.26617 loss)
I0525 21:11:23.716022 22368 sgd_solver.cpp:106] Iteration 9150, lr = 0.004
I0525 21:11:32.453711 22368 solver.cpp:237] Iteration 9300, loss = 1.46561
I0525 21:11:32.453758 22368 solver.cpp:253]     Train net output #0: loss = 1.46561 (* 1 = 1.46561 loss)
I0525 21:11:32.453783 22368 sgd_solver.cpp:106] Iteration 9300, lr = 0.004
I0525 21:11:41.192426 22368 solver.cpp:237] Iteration 9450, loss = 1.21692
I0525 21:11:41.192463 22368 solver.cpp:253]     Train net output #0: loss = 1.21692 (* 1 = 1.21692 loss)
I0525 21:11:41.192481 22368 sgd_solver.cpp:106] Iteration 9450, lr = 0.004
I0525 21:11:49.933184 22368 solver.cpp:237] Iteration 9600, loss = 1.47502
I0525 21:11:49.933220 22368 solver.cpp:253]     Train net output #0: loss = 1.47502 (* 1 = 1.47502 loss)
I0525 21:11:49.933243 22368 sgd_solver.cpp:106] Iteration 9600, lr = 0.004
I0525 21:11:58.668756 22368 solver.cpp:237] Iteration 9750, loss = 1.28945
I0525 21:11:58.668905 22368 solver.cpp:253]     Train net output #0: loss = 1.28945 (* 1 = 1.28945 loss)
I0525 21:11:58.668925 22368 sgd_solver.cpp:106] Iteration 9750, lr = 0.004
I0525 21:12:07.404916 22368 solver.cpp:237] Iteration 9900, loss = 1.1881
I0525 21:12:07.404950 22368 solver.cpp:253]     Train net output #0: loss = 1.1881 (* 1 = 1.1881 loss)
I0525 21:12:07.404974 22368 sgd_solver.cpp:106] Iteration 9900, lr = 0.004
I0525 21:12:38.257516 22368 solver.cpp:237] Iteration 10050, loss = 1.35326
I0525 21:12:38.257700 22368 solver.cpp:253]     Train net output #0: loss = 1.35326 (* 1 = 1.35326 loss)
I0525 21:12:38.257719 22368 sgd_solver.cpp:106] Iteration 10050, lr = 0.004
I0525 21:12:46.999277 22368 solver.cpp:237] Iteration 10200, loss = 1.27538
I0525 21:12:46.999378 22368 solver.cpp:253]     Train net output #0: loss = 1.27538 (* 1 = 1.27538 loss)
I0525 21:12:46.999397 22368 sgd_solver.cpp:106] Iteration 10200, lr = 0.004
I0525 21:12:55.740649 22368 solver.cpp:237] Iteration 10350, loss = 1.36256
I0525 21:12:55.740686 22368 solver.cpp:253]     Train net output #0: loss = 1.36256 (* 1 = 1.36256 loss)
I0525 21:12:55.740710 22368 sgd_solver.cpp:106] Iteration 10350, lr = 0.004
I0525 21:13:04.427345 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_10500.caffemodel
I0525 21:13:04.505250 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_10500.solverstate
I0525 21:13:04.549489 22368 solver.cpp:237] Iteration 10500, loss = 1.1607
I0525 21:13:04.549543 22368 solver.cpp:253]     Train net output #0: loss = 1.1607 (* 1 = 1.1607 loss)
I0525 21:13:04.549569 22368 sgd_solver.cpp:106] Iteration 10500, lr = 0.004
I0525 21:13:13.287222 22368 solver.cpp:237] Iteration 10650, loss = 1.45903
I0525 21:13:13.287379 22368 solver.cpp:253]     Train net output #0: loss = 1.45903 (* 1 = 1.45903 loss)
I0525 21:13:13.287397 22368 sgd_solver.cpp:106] Iteration 10650, lr = 0.004
I0525 21:13:22.022073 22368 solver.cpp:237] Iteration 10800, loss = 1.21676
I0525 21:13:22.022109 22368 solver.cpp:253]     Train net output #0: loss = 1.21676 (* 1 = 1.21676 loss)
I0525 21:13:22.022132 22368 sgd_solver.cpp:106] Iteration 10800, lr = 0.004
I0525 21:13:30.756515 22368 solver.cpp:237] Iteration 10950, loss = 1.29704
I0525 21:13:30.756551 22368 solver.cpp:253]     Train net output #0: loss = 1.29704 (* 1 = 1.29704 loss)
I0525 21:13:30.756570 22368 sgd_solver.cpp:106] Iteration 10950, lr = 0.004
I0525 21:14:01.691612 22368 solver.cpp:237] Iteration 11100, loss = 1.19883
I0525 21:14:01.691782 22368 solver.cpp:253]     Train net output #0: loss = 1.19883 (* 1 = 1.19883 loss)
I0525 21:14:01.691800 22368 sgd_solver.cpp:106] Iteration 11100, lr = 0.004
I0525 21:14:10.431968 22368 solver.cpp:237] Iteration 11250, loss = 1.14752
I0525 21:14:10.432004 22368 solver.cpp:253]     Train net output #0: loss = 1.14752 (* 1 = 1.14752 loss)
I0525 21:14:10.432024 22368 sgd_solver.cpp:106] Iteration 11250, lr = 0.004
I0525 21:14:19.168764 22368 solver.cpp:237] Iteration 11400, loss = 1.27335
I0525 21:14:19.168800 22368 solver.cpp:253]     Train net output #0: loss = 1.27335 (* 1 = 1.27335 loss)
I0525 21:14:19.168823 22368 sgd_solver.cpp:106] Iteration 11400, lr = 0.004
I0525 21:14:27.903071 22368 solver.cpp:237] Iteration 11550, loss = 1.45432
I0525 21:14:27.903121 22368 solver.cpp:253]     Train net output #0: loss = 1.45432 (* 1 = 1.45432 loss)
I0525 21:14:27.903147 22368 sgd_solver.cpp:106] Iteration 11550, lr = 0.004
I0525 21:14:36.645359 22368 solver.cpp:237] Iteration 11700, loss = 1.34405
I0525 21:14:36.645506 22368 solver.cpp:253]     Train net output #0: loss = 1.34405 (* 1 = 1.34405 loss)
I0525 21:14:36.645522 22368 sgd_solver.cpp:106] Iteration 11700, lr = 0.004
I0525 21:14:45.384193 22368 solver.cpp:237] Iteration 11850, loss = 1.33121
I0525 21:14:45.384230 22368 solver.cpp:253]     Train net output #0: loss = 1.33121 (* 1 = 1.33121 loss)
I0525 21:14:45.384248 22368 sgd_solver.cpp:106] Iteration 11850, lr = 0.004
I0525 21:14:54.063668 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_12000.caffemodel
I0525 21:14:54.141659 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_12000.solverstate
I0525 21:14:54.168324 22368 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 21:16:01.820801 22368 solver.cpp:409]     Test net output #0: accuracy = 0.856646
I0525 21:16:01.820987 22368 solver.cpp:409]     Test net output #1: loss = 0.478272 (* 1 = 0.478272 loss)
I0525 21:16:24.035856 22368 solver.cpp:237] Iteration 12000, loss = 1.29983
I0525 21:16:24.035920 22368 solver.cpp:253]     Train net output #0: loss = 1.29983 (* 1 = 1.29983 loss)
I0525 21:16:24.035948 22368 sgd_solver.cpp:106] Iteration 12000, lr = 0.004
I0525 21:16:32.765295 22368 solver.cpp:237] Iteration 12150, loss = 1.1184
I0525 21:16:32.765453 22368 solver.cpp:253]     Train net output #0: loss = 1.1184 (* 1 = 1.1184 loss)
I0525 21:16:32.765471 22368 sgd_solver.cpp:106] Iteration 12150, lr = 0.004
I0525 21:16:41.490294 22368 solver.cpp:237] Iteration 12300, loss = 1.18131
I0525 21:16:41.490330 22368 solver.cpp:253]     Train net output #0: loss = 1.18131 (* 1 = 1.18131 loss)
I0525 21:16:41.490350 22368 sgd_solver.cpp:106] Iteration 12300, lr = 0.004
I0525 21:16:50.219058 22368 solver.cpp:237] Iteration 12450, loss = 1.17532
I0525 21:16:50.219094 22368 solver.cpp:253]     Train net output #0: loss = 1.17532 (* 1 = 1.17532 loss)
I0525 21:16:50.219118 22368 sgd_solver.cpp:106] Iteration 12450, lr = 0.004
I0525 21:16:58.943750 22368 solver.cpp:237] Iteration 12600, loss = 1.53111
I0525 21:16:58.943794 22368 solver.cpp:253]     Train net output #0: loss = 1.53111 (* 1 = 1.53111 loss)
I0525 21:16:58.943820 22368 sgd_solver.cpp:106] Iteration 12600, lr = 0.004
I0525 21:17:07.673244 22368 solver.cpp:237] Iteration 12750, loss = 1.34441
I0525 21:17:07.673390 22368 solver.cpp:253]     Train net output #0: loss = 1.34441 (* 1 = 1.34441 loss)
I0525 21:17:07.673406 22368 sgd_solver.cpp:106] Iteration 12750, lr = 0.004
I0525 21:17:16.401621 22368 solver.cpp:237] Iteration 12900, loss = 1.13164
I0525 21:17:16.401671 22368 solver.cpp:253]     Train net output #0: loss = 1.13164 (* 1 = 1.13164 loss)
I0525 21:17:16.401698 22368 sgd_solver.cpp:106] Iteration 12900, lr = 0.004
I0525 21:17:47.380266 22368 solver.cpp:237] Iteration 13050, loss = 1.31517
I0525 21:17:47.380439 22368 solver.cpp:253]     Train net output #0: loss = 1.31517 (* 1 = 1.31517 loss)
I0525 21:17:47.380456 22368 sgd_solver.cpp:106] Iteration 13050, lr = 0.004
I0525 21:17:56.111404 22368 solver.cpp:237] Iteration 13200, loss = 1.09047
I0525 21:17:56.111440 22368 solver.cpp:253]     Train net output #0: loss = 1.09047 (* 1 = 1.09047 loss)
I0525 21:17:56.111459 22368 sgd_solver.cpp:106] Iteration 13200, lr = 0.004
I0525 21:18:04.837496 22368 solver.cpp:237] Iteration 13350, loss = 1.01934
I0525 21:18:04.837532 22368 solver.cpp:253]     Train net output #0: loss = 1.01934 (* 1 = 1.01934 loss)
I0525 21:18:04.837554 22368 sgd_solver.cpp:106] Iteration 13350, lr = 0.004
I0525 21:18:13.508139 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_13500.caffemodel
I0525 21:18:13.588309 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_13500.solverstate
I0525 21:18:13.635025 22368 solver.cpp:237] Iteration 13500, loss = 1.40253
I0525 21:18:13.635082 22368 solver.cpp:253]     Train net output #0: loss = 1.40253 (* 1 = 1.40253 loss)
I0525 21:18:13.635102 22368 sgd_solver.cpp:106] Iteration 13500, lr = 0.004
I0525 21:18:22.363440 22368 solver.cpp:237] Iteration 13650, loss = 1.28823
I0525 21:18:22.363595 22368 solver.cpp:253]     Train net output #0: loss = 1.28823 (* 1 = 1.28823 loss)
I0525 21:18:22.363612 22368 sgd_solver.cpp:106] Iteration 13650, lr = 0.004
I0525 21:18:31.092762 22368 solver.cpp:237] Iteration 13800, loss = 1.4579
I0525 21:18:31.092816 22368 solver.cpp:253]     Train net output #0: loss = 1.4579 (* 1 = 1.4579 loss)
I0525 21:18:31.092844 22368 sgd_solver.cpp:106] Iteration 13800, lr = 0.004
I0525 21:18:39.821254 22368 solver.cpp:237] Iteration 13950, loss = 1.35275
I0525 21:18:39.821290 22368 solver.cpp:253]     Train net output #0: loss = 1.35275 (* 1 = 1.35275 loss)
I0525 21:18:39.821313 22368 sgd_solver.cpp:106] Iteration 13950, lr = 0.004
I0525 21:19:10.755427 22368 solver.cpp:237] Iteration 14100, loss = 1.2238
I0525 21:19:10.755609 22368 solver.cpp:253]     Train net output #0: loss = 1.2238 (* 1 = 1.2238 loss)
I0525 21:19:10.755626 22368 sgd_solver.cpp:106] Iteration 14100, lr = 0.004
I0525 21:19:19.489148 22368 solver.cpp:237] Iteration 14250, loss = 1.34434
I0525 21:19:19.489186 22368 solver.cpp:253]     Train net output #0: loss = 1.34434 (* 1 = 1.34434 loss)
I0525 21:19:19.489204 22368 sgd_solver.cpp:106] Iteration 14250, lr = 0.004
I0525 21:19:28.216125 22368 solver.cpp:237] Iteration 14400, loss = 1.2176
I0525 21:19:28.216178 22368 solver.cpp:253]     Train net output #0: loss = 1.2176 (* 1 = 1.2176 loss)
I0525 21:19:28.216204 22368 sgd_solver.cpp:106] Iteration 14400, lr = 0.004
I0525 21:19:36.947585 22368 solver.cpp:237] Iteration 14550, loss = 1.41344
I0525 21:19:36.947623 22368 solver.cpp:253]     Train net output #0: loss = 1.41344 (* 1 = 1.41344 loss)
I0525 21:19:36.947641 22368 sgd_solver.cpp:106] Iteration 14550, lr = 0.004
I0525 21:19:45.673410 22368 solver.cpp:237] Iteration 14700, loss = 1.24704
I0525 21:19:45.673576 22368 solver.cpp:253]     Train net output #0: loss = 1.24704 (* 1 = 1.24704 loss)
I0525 21:19:45.673593 22368 sgd_solver.cpp:106] Iteration 14700, lr = 0.004
I0525 21:19:54.401340 22368 solver.cpp:237] Iteration 14850, loss = 1.32843
I0525 21:19:54.401389 22368 solver.cpp:253]     Train net output #0: loss = 1.32843 (* 1 = 1.32843 loss)
I0525 21:19:54.401414 22368 sgd_solver.cpp:106] Iteration 14850, lr = 0.004
I0525 21:20:03.076494 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_15000.caffemodel
I0525 21:20:03.159718 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_15000.solverstate
I0525 21:20:03.188413 22368 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 21:20:50.007252 22368 solver.cpp:409]     Test net output #0: accuracy = 0.859273
I0525 21:20:50.007416 22368 solver.cpp:409]     Test net output #1: loss = 0.440325 (* 1 = 0.440325 loss)
I0525 21:21:10.918018 22368 solver.cpp:237] Iteration 15000, loss = 1.19831
I0525 21:21:10.918077 22368 solver.cpp:253]     Train net output #0: loss = 1.19831 (* 1 = 1.19831 loss)
I0525 21:21:10.918097 22368 sgd_solver.cpp:106] Iteration 15000, lr = 0.004
I0525 21:21:19.640463 22368 solver.cpp:237] Iteration 15150, loss = 1.14415
I0525 21:21:19.640501 22368 solver.cpp:253]     Train net output #0: loss = 1.14415 (* 1 = 1.14415 loss)
I0525 21:21:19.640522 22368 sgd_solver.cpp:106] Iteration 15150, lr = 0.004
I0525 21:21:28.365288 22368 solver.cpp:237] Iteration 15300, loss = 1.3067
I0525 21:21:28.365458 22368 solver.cpp:253]     Train net output #0: loss = 1.3067 (* 1 = 1.3067 loss)
I0525 21:21:28.365483 22368 sgd_solver.cpp:106] Iteration 15300, lr = 0.004
I0525 21:21:37.107787 22368 solver.cpp:237] Iteration 15450, loss = 1.25024
I0525 21:21:37.107825 22368 solver.cpp:253]     Train net output #0: loss = 1.25024 (* 1 = 1.25024 loss)
I0525 21:21:37.107843 22368 sgd_solver.cpp:106] Iteration 15450, lr = 0.004
I0525 21:21:45.848304 22368 solver.cpp:237] Iteration 15600, loss = 1.195
I0525 21:21:45.848340 22368 solver.cpp:253]     Train net output #0: loss = 1.195 (* 1 = 1.195 loss)
I0525 21:21:45.848363 22368 sgd_solver.cpp:106] Iteration 15600, lr = 0.004
I0525 21:21:54.586068 22368 solver.cpp:237] Iteration 15750, loss = 1.12036
I0525 21:21:54.586122 22368 solver.cpp:253]     Train net output #0: loss = 1.12036 (* 1 = 1.12036 loss)
I0525 21:21:54.586146 22368 sgd_solver.cpp:106] Iteration 15750, lr = 0.004
I0525 21:22:03.326766 22368 solver.cpp:237] Iteration 15900, loss = 1.24289
I0525 21:22:03.326922 22368 solver.cpp:253]     Train net output #0: loss = 1.24289 (* 1 = 1.24289 loss)
I0525 21:22:03.326938 22368 sgd_solver.cpp:106] Iteration 15900, lr = 0.004
I0525 21:22:32.915031 22368 solver.cpp:237] Iteration 16050, loss = 1.20517
I0525 21:22:32.915089 22368 solver.cpp:253]     Train net output #0: loss = 1.20517 (* 1 = 1.20517 loss)
I0525 21:22:32.915107 22368 sgd_solver.cpp:106] Iteration 16050, lr = 0.004
I0525 21:22:41.654072 22368 solver.cpp:237] Iteration 16200, loss = 1.16166
I0525 21:22:41.654240 22368 solver.cpp:253]     Train net output #0: loss = 1.16166 (* 1 = 1.16166 loss)
I0525 21:22:41.654258 22368 sgd_solver.cpp:106] Iteration 16200, lr = 0.004
I0525 21:22:50.392917 22368 solver.cpp:237] Iteration 16350, loss = 1.19118
I0525 21:22:50.392954 22368 solver.cpp:253]     Train net output #0: loss = 1.19118 (* 1 = 1.19118 loss)
I0525 21:22:50.392978 22368 sgd_solver.cpp:106] Iteration 16350, lr = 0.004
I0525 21:22:59.071943 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_16500.caffemodel
I0525 21:22:59.151007 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_16500.solverstate
I0525 21:22:59.195133 22368 solver.cpp:237] Iteration 16500, loss = 1.213
I0525 21:22:59.195186 22368 solver.cpp:253]     Train net output #0: loss = 1.213 (* 1 = 1.213 loss)
I0525 21:22:59.195211 22368 sgd_solver.cpp:106] Iteration 16500, lr = 0.004
I0525 21:23:07.935102 22368 solver.cpp:237] Iteration 16650, loss = 1.3465
I0525 21:23:07.935156 22368 solver.cpp:253]     Train net output #0: loss = 1.3465 (* 1 = 1.3465 loss)
I0525 21:23:07.935184 22368 sgd_solver.cpp:106] Iteration 16650, lr = 0.004
I0525 21:23:16.670631 22368 solver.cpp:237] Iteration 16800, loss = 1.27111
I0525 21:23:16.670784 22368 solver.cpp:253]     Train net output #0: loss = 1.27111 (* 1 = 1.27111 loss)
I0525 21:23:16.670801 22368 sgd_solver.cpp:106] Iteration 16800, lr = 0.004
I0525 21:23:25.408336 22368 solver.cpp:237] Iteration 16950, loss = 1.20055
I0525 21:23:25.408375 22368 solver.cpp:253]     Train net output #0: loss = 1.20055 (* 1 = 1.20055 loss)
I0525 21:23:25.408391 22368 sgd_solver.cpp:106] Iteration 16950, lr = 0.004
I0525 21:23:55.009433 22368 solver.cpp:237] Iteration 17100, loss = 1.07734
I0525 21:23:55.009606 22368 solver.cpp:253]     Train net output #0: loss = 1.07734 (* 1 = 1.07734 loss)
I0525 21:23:55.009624 22368 sgd_solver.cpp:106] Iteration 17100, lr = 0.004
I0525 21:24:03.751437 22368 solver.cpp:237] Iteration 17250, loss = 1.03894
I0525 21:24:03.751490 22368 solver.cpp:253]     Train net output #0: loss = 1.03894 (* 1 = 1.03894 loss)
I0525 21:24:03.751515 22368 sgd_solver.cpp:106] Iteration 17250, lr = 0.004
I0525 21:24:12.489543 22368 solver.cpp:237] Iteration 17400, loss = 1.32188
I0525 21:24:12.489580 22368 solver.cpp:253]     Train net output #0: loss = 1.32188 (* 1 = 1.32188 loss)
I0525 21:24:12.489603 22368 sgd_solver.cpp:106] Iteration 17400, lr = 0.004
I0525 21:24:21.225502 22368 solver.cpp:237] Iteration 17550, loss = 1.07151
I0525 21:24:21.225558 22368 solver.cpp:253]     Train net output #0: loss = 1.07151 (* 1 = 1.07151 loss)
I0525 21:24:21.225584 22368 sgd_solver.cpp:106] Iteration 17550, lr = 0.004
I0525 21:24:29.964753 22368 solver.cpp:237] Iteration 17700, loss = 1.24084
I0525 21:24:29.964905 22368 solver.cpp:253]     Train net output #0: loss = 1.24084 (* 1 = 1.24084 loss)
I0525 21:24:29.964922 22368 sgd_solver.cpp:106] Iteration 17700, lr = 0.004
I0525 21:24:38.706522 22368 solver.cpp:237] Iteration 17850, loss = 1.26687
I0525 21:24:38.706559 22368 solver.cpp:253]     Train net output #0: loss = 1.26687 (* 1 = 1.26687 loss)
I0525 21:24:38.706583 22368 sgd_solver.cpp:106] Iteration 17850, lr = 0.004
I0525 21:24:47.387960 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_18000.caffemodel
I0525 21:24:47.466684 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_18000.solverstate
I0525 21:24:47.491834 22368 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 21:25:55.172660 22368 solver.cpp:409]     Test net output #0: accuracy = 0.865479
I0525 21:25:55.172842 22368 solver.cpp:409]     Test net output #1: loss = 0.416918 (* 1 = 0.416918 loss)
I0525 21:26:16.051442 22368 solver.cpp:237] Iteration 18000, loss = 1.37216
I0525 21:26:16.051502 22368 solver.cpp:253]     Train net output #0: loss = 1.37216 (* 1 = 1.37216 loss)
I0525 21:26:16.051532 22368 sgd_solver.cpp:106] Iteration 18000, lr = 0.004
I0525 21:26:24.787122 22368 solver.cpp:237] Iteration 18150, loss = 1.06709
I0525 21:26:24.787160 22368 solver.cpp:253]     Train net output #0: loss = 1.06709 (* 1 = 1.06709 loss)
I0525 21:26:24.787184 22368 sgd_solver.cpp:106] Iteration 18150, lr = 0.004
I0525 21:26:33.522742 22368 solver.cpp:237] Iteration 18300, loss = 1.16827
I0525 21:26:33.522914 22368 solver.cpp:253]     Train net output #0: loss = 1.16827 (* 1 = 1.16827 loss)
I0525 21:26:33.522933 22368 sgd_solver.cpp:106] Iteration 18300, lr = 0.004
I0525 21:26:42.262718 22368 solver.cpp:237] Iteration 18450, loss = 1.11706
I0525 21:26:42.262754 22368 solver.cpp:253]     Train net output #0: loss = 1.11706 (* 1 = 1.11706 loss)
I0525 21:26:42.262773 22368 sgd_solver.cpp:106] Iteration 18450, lr = 0.004
I0525 21:26:51.001049 22368 solver.cpp:237] Iteration 18600, loss = 1.34597
I0525 21:26:51.001102 22368 solver.cpp:253]     Train net output #0: loss = 1.34597 (* 1 = 1.34597 loss)
I0525 21:26:51.001121 22368 sgd_solver.cpp:106] Iteration 18600, lr = 0.004
I0525 21:26:59.733114 22368 solver.cpp:237] Iteration 18750, loss = 1.37797
I0525 21:26:59.733152 22368 solver.cpp:253]     Train net output #0: loss = 1.37797 (* 1 = 1.37797 loss)
I0525 21:26:59.733171 22368 sgd_solver.cpp:106] Iteration 18750, lr = 0.004
I0525 21:27:08.465718 22368 solver.cpp:237] Iteration 18900, loss = 1.24218
I0525 21:27:08.465869 22368 solver.cpp:253]     Train net output #0: loss = 1.24218 (* 1 = 1.24218 loss)
I0525 21:27:08.465886 22368 sgd_solver.cpp:106] Iteration 18900, lr = 0.004
I0525 21:27:38.087203 22368 solver.cpp:237] Iteration 19050, loss = 1.15567
I0525 21:27:38.087258 22368 solver.cpp:253]     Train net output #0: loss = 1.15567 (* 1 = 1.15567 loss)
I0525 21:27:38.087276 22368 sgd_solver.cpp:106] Iteration 19050, lr = 0.004
I0525 21:27:46.821177 22368 solver.cpp:237] Iteration 19200, loss = 1.32299
I0525 21:27:46.821344 22368 solver.cpp:253]     Train net output #0: loss = 1.32299 (* 1 = 1.32299 loss)
I0525 21:27:46.821363 22368 sgd_solver.cpp:106] Iteration 19200, lr = 0.004
I0525 21:27:55.554229 22368 solver.cpp:237] Iteration 19350, loss = 1.18647
I0525 21:27:55.554265 22368 solver.cpp:253]     Train net output #0: loss = 1.18647 (* 1 = 1.18647 loss)
I0525 21:27:55.554289 22368 sgd_solver.cpp:106] Iteration 19350, lr = 0.004
I0525 21:28:04.229856 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_19500.caffemodel
I0525 21:28:04.311367 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_19500.solverstate
I0525 21:28:04.356557 22368 solver.cpp:237] Iteration 19500, loss = 1.13829
I0525 21:28:04.356611 22368 solver.cpp:253]     Train net output #0: loss = 1.13829 (* 1 = 1.13829 loss)
I0525 21:28:04.356636 22368 sgd_solver.cpp:106] Iteration 19500, lr = 0.004
I0525 21:28:13.091759 22368 solver.cpp:237] Iteration 19650, loss = 1.22905
I0525 21:28:13.091811 22368 solver.cpp:253]     Train net output #0: loss = 1.22905 (* 1 = 1.22905 loss)
I0525 21:28:13.091836 22368 sgd_solver.cpp:106] Iteration 19650, lr = 0.004
I0525 21:28:21.828280 22368 solver.cpp:237] Iteration 19800, loss = 1.17167
I0525 21:28:21.828456 22368 solver.cpp:253]     Train net output #0: loss = 1.17167 (* 1 = 1.17167 loss)
I0525 21:28:21.828472 22368 sgd_solver.cpp:106] Iteration 19800, lr = 0.004
I0525 21:28:30.564805 22368 solver.cpp:237] Iteration 19950, loss = 1.21401
I0525 21:28:30.564842 22368 solver.cpp:253]     Train net output #0: loss = 1.21401 (* 1 = 1.21401 loss)
I0525 21:28:30.564859 22368 sgd_solver.cpp:106] Iteration 19950, lr = 0.004
I0525 21:29:00.125455 22368 solver.cpp:237] Iteration 20100, loss = 1.14833
I0525 21:29:00.125627 22368 solver.cpp:253]     Train net output #0: loss = 1.14833 (* 1 = 1.14833 loss)
I0525 21:29:00.125653 22368 sgd_solver.cpp:106] Iteration 20100, lr = 0.004
I0525 21:29:08.860075 22368 solver.cpp:237] Iteration 20250, loss = 1.2106
I0525 21:29:08.860111 22368 solver.cpp:253]     Train net output #0: loss = 1.2106 (* 1 = 1.2106 loss)
I0525 21:29:08.860133 22368 sgd_solver.cpp:106] Iteration 20250, lr = 0.004
I0525 21:29:17.596369 22368 solver.cpp:237] Iteration 20400, loss = 1.42934
I0525 21:29:17.596406 22368 solver.cpp:253]     Train net output #0: loss = 1.42934 (* 1 = 1.42934 loss)
I0525 21:29:17.596429 22368 sgd_solver.cpp:106] Iteration 20400, lr = 0.004
I0525 21:29:26.340102 22368 solver.cpp:237] Iteration 20550, loss = 1.26548
I0525 21:29:26.340155 22368 solver.cpp:253]     Train net output #0: loss = 1.26548 (* 1 = 1.26548 loss)
I0525 21:29:26.340179 22368 sgd_solver.cpp:106] Iteration 20550, lr = 0.004
I0525 21:29:35.075923 22368 solver.cpp:237] Iteration 20700, loss = 1.23227
I0525 21:29:35.076074 22368 solver.cpp:253]     Train net output #0: loss = 1.23227 (* 1 = 1.23227 loss)
I0525 21:29:35.076092 22368 sgd_solver.cpp:106] Iteration 20700, lr = 0.004
I0525 21:29:43.814164 22368 solver.cpp:237] Iteration 20850, loss = 1.23243
I0525 21:29:43.814200 22368 solver.cpp:253]     Train net output #0: loss = 1.23243 (* 1 = 1.23243 loss)
I0525 21:29:43.814224 22368 sgd_solver.cpp:106] Iteration 20850, lr = 0.004
I0525 21:29:52.489302 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_21000.caffemodel
I0525 21:29:52.569156 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_21000.solverstate
I0525 21:29:52.596479 22368 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 21:30:39.146469 22368 solver.cpp:409]     Test net output #0: accuracy = 0.871346
I0525 21:30:39.146641 22368 solver.cpp:409]     Test net output #1: loss = 0.438571 (* 1 = 0.438571 loss)
I0525 21:31:00.006083 22368 solver.cpp:237] Iteration 21000, loss = 1.21221
I0525 21:31:00.006147 22368 solver.cpp:253]     Train net output #0: loss = 1.21221 (* 1 = 1.21221 loss)
I0525 21:31:00.006168 22368 sgd_solver.cpp:106] Iteration 21000, lr = 0.004
I0525 21:31:08.736286 22368 solver.cpp:237] Iteration 21150, loss = 1.14705
I0525 21:31:08.736340 22368 solver.cpp:253]     Train net output #0: loss = 1.14705 (* 1 = 1.14705 loss)
I0525 21:31:08.736366 22368 sgd_solver.cpp:106] Iteration 21150, lr = 0.004
I0525 21:31:17.467346 22368 solver.cpp:237] Iteration 21300, loss = 1.29723
I0525 21:31:17.467507 22368 solver.cpp:253]     Train net output #0: loss = 1.29723 (* 1 = 1.29723 loss)
I0525 21:31:17.467525 22368 sgd_solver.cpp:106] Iteration 21300, lr = 0.004
I0525 21:31:26.198855 22368 solver.cpp:237] Iteration 21450, loss = 1.38347
I0525 21:31:26.198910 22368 solver.cpp:253]     Train net output #0: loss = 1.38347 (* 1 = 1.38347 loss)
I0525 21:31:26.198937 22368 sgd_solver.cpp:106] Iteration 21450, lr = 0.004
I0525 21:31:34.932725 22368 solver.cpp:237] Iteration 21600, loss = 1.12006
I0525 21:31:34.932762 22368 solver.cpp:253]     Train net output #0: loss = 1.12006 (* 1 = 1.12006 loss)
I0525 21:31:34.932780 22368 sgd_solver.cpp:106] Iteration 21600, lr = 0.004
I0525 21:31:43.666662 22368 solver.cpp:237] Iteration 21750, loss = 1.3018
I0525 21:31:43.666698 22368 solver.cpp:253]     Train net output #0: loss = 1.3018 (* 1 = 1.3018 loss)
I0525 21:31:43.666721 22368 sgd_solver.cpp:106] Iteration 21750, lr = 0.004
I0525 21:31:52.397408 22368 solver.cpp:237] Iteration 21900, loss = 1.30992
I0525 21:31:52.397588 22368 solver.cpp:253]     Train net output #0: loss = 1.30992 (* 1 = 1.30992 loss)
I0525 21:31:52.397604 22368 sgd_solver.cpp:106] Iteration 21900, lr = 0.004
I0525 21:32:22.003010 22368 solver.cpp:237] Iteration 22050, loss = 1.32991
I0525 21:32:22.003067 22368 solver.cpp:253]     Train net output #0: loss = 1.32991 (* 1 = 1.32991 loss)
I0525 21:32:22.003084 22368 sgd_solver.cpp:106] Iteration 22050, lr = 0.004
I0525 21:32:30.738912 22368 solver.cpp:237] Iteration 22200, loss = 1.15308
I0525 21:32:30.739070 22368 solver.cpp:253]     Train net output #0: loss = 1.15308 (* 1 = 1.15308 loss)
I0525 21:32:30.739087 22368 sgd_solver.cpp:106] Iteration 22200, lr = 0.004
I0525 21:32:39.474570 22368 solver.cpp:237] Iteration 22350, loss = 1.14663
I0525 21:32:39.474611 22368 solver.cpp:253]     Train net output #0: loss = 1.14663 (* 1 = 1.14663 loss)
I0525 21:32:39.474627 22368 sgd_solver.cpp:106] Iteration 22350, lr = 0.004
I0525 21:32:48.152653 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_22500.caffemodel
I0525 21:32:48.233659 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_22500.solverstate
I0525 21:32:48.279568 22368 solver.cpp:237] Iteration 22500, loss = 1.08925
I0525 21:32:48.279623 22368 solver.cpp:253]     Train net output #0: loss = 1.08925 (* 1 = 1.08925 loss)
I0525 21:32:48.279650 22368 sgd_solver.cpp:106] Iteration 22500, lr = 0.004
I0525 21:32:57.010381 22368 solver.cpp:237] Iteration 22650, loss = 1.03065
I0525 21:32:57.010417 22368 solver.cpp:253]     Train net output #0: loss = 1.03065 (* 1 = 1.03065 loss)
I0525 21:32:57.010440 22368 sgd_solver.cpp:106] Iteration 22650, lr = 0.004
I0525 21:33:05.742784 22368 solver.cpp:237] Iteration 22800, loss = 1.16069
I0525 21:33:05.742941 22368 solver.cpp:253]     Train net output #0: loss = 1.16069 (* 1 = 1.16069 loss)
I0525 21:33:05.742957 22368 sgd_solver.cpp:106] Iteration 22800, lr = 0.004
I0525 21:33:14.475333 22368 solver.cpp:237] Iteration 22950, loss = 1.23719
I0525 21:33:14.475378 22368 solver.cpp:253]     Train net output #0: loss = 1.23719 (* 1 = 1.23719 loss)
I0525 21:33:14.475402 22368 sgd_solver.cpp:106] Iteration 22950, lr = 0.004
I0525 21:33:44.090806 22368 solver.cpp:237] Iteration 23100, loss = 1.27586
I0525 21:33:44.090977 22368 solver.cpp:253]     Train net output #0: loss = 1.27586 (* 1 = 1.27586 loss)
I0525 21:33:44.090996 22368 sgd_solver.cpp:106] Iteration 23100, lr = 0.004
I0525 21:33:52.827792 22368 solver.cpp:237] Iteration 23250, loss = 1.11224
I0525 21:33:52.827828 22368 solver.cpp:253]     Train net output #0: loss = 1.11224 (* 1 = 1.11224 loss)
I0525 21:33:52.827852 22368 sgd_solver.cpp:106] Iteration 23250, lr = 0.004
I0525 21:34:01.563294 22368 solver.cpp:237] Iteration 23400, loss = 1.21027
I0525 21:34:01.563346 22368 solver.cpp:253]     Train net output #0: loss = 1.21027 (* 1 = 1.21027 loss)
I0525 21:34:01.563372 22368 sgd_solver.cpp:106] Iteration 23400, lr = 0.004
I0525 21:34:10.297066 22368 solver.cpp:237] Iteration 23550, loss = 1.31281
I0525 21:34:10.297102 22368 solver.cpp:253]     Train net output #0: loss = 1.31281 (* 1 = 1.31281 loss)
I0525 21:34:10.297125 22368 sgd_solver.cpp:106] Iteration 23550, lr = 0.004
I0525 21:34:19.030603 22368 solver.cpp:237] Iteration 23700, loss = 1.16316
I0525 21:34:19.030757 22368 solver.cpp:253]     Train net output #0: loss = 1.16316 (* 1 = 1.16316 loss)
I0525 21:34:19.030773 22368 sgd_solver.cpp:106] Iteration 23700, lr = 0.004
I0525 21:34:27.766261 22368 solver.cpp:237] Iteration 23850, loss = 1.11047
I0525 21:34:27.766315 22368 solver.cpp:253]     Train net output #0: loss = 1.11047 (* 1 = 1.11047 loss)
I0525 21:34:27.766338 22368 sgd_solver.cpp:106] Iteration 23850, lr = 0.004
I0525 21:34:36.441396 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_24000.caffemodel
I0525 21:34:36.562695 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_24000.solverstate
I0525 21:34:36.588243 22368 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 21:35:44.342995 22368 solver.cpp:409]     Test net output #0: accuracy = 0.863807
I0525 21:35:44.343181 22368 solver.cpp:409]     Test net output #1: loss = 0.431185 (* 1 = 0.431185 loss)
I0525 21:36:05.284267 22368 solver.cpp:237] Iteration 24000, loss = 1.26219
I0525 21:36:05.284329 22368 solver.cpp:253]     Train net output #0: loss = 1.26219 (* 1 = 1.26219 loss)
I0525 21:36:05.284358 22368 sgd_solver.cpp:106] Iteration 24000, lr = 0.004
I0525 21:36:14.037616 22368 solver.cpp:237] Iteration 24150, loss = 1.05671
I0525 21:36:14.037653 22368 solver.cpp:253]     Train net output #0: loss = 1.05671 (* 1 = 1.05671 loss)
I0525 21:36:14.037677 22368 sgd_solver.cpp:106] Iteration 24150, lr = 0.004
I0525 21:36:22.778551 22368 solver.cpp:237] Iteration 24300, loss = 1.2445
I0525 21:36:22.778722 22368 solver.cpp:253]     Train net output #0: loss = 1.2445 (* 1 = 1.2445 loss)
I0525 21:36:22.778738 22368 sgd_solver.cpp:106] Iteration 24300, lr = 0.004
I0525 21:36:31.523859 22368 solver.cpp:237] Iteration 24450, loss = 1.07425
I0525 21:36:31.523911 22368 solver.cpp:253]     Train net output #0: loss = 1.07425 (* 1 = 1.07425 loss)
I0525 21:36:31.523939 22368 sgd_solver.cpp:106] Iteration 24450, lr = 0.004
I0525 21:36:40.278465 22368 solver.cpp:237] Iteration 24600, loss = 1.24072
I0525 21:36:40.278502 22368 solver.cpp:253]     Train net output #0: loss = 1.24072 (* 1 = 1.24072 loss)
I0525 21:36:40.278520 22368 sgd_solver.cpp:106] Iteration 24600, lr = 0.004
I0525 21:36:49.025164 22368 solver.cpp:237] Iteration 24750, loss = 1.23065
I0525 21:36:49.025200 22368 solver.cpp:253]     Train net output #0: loss = 1.23065 (* 1 = 1.23065 loss)
I0525 21:36:49.025224 22368 sgd_solver.cpp:106] Iteration 24750, lr = 0.004
I0525 21:36:57.774898 22368 solver.cpp:237] Iteration 24900, loss = 1.20827
I0525 21:36:57.775068 22368 solver.cpp:253]     Train net output #0: loss = 1.20827 (* 1 = 1.20827 loss)
I0525 21:36:57.775086 22368 sgd_solver.cpp:106] Iteration 24900, lr = 0.004
I0525 21:37:27.401608 22368 solver.cpp:237] Iteration 25050, loss = 1.16853
I0525 21:37:27.401664 22368 solver.cpp:253]     Train net output #0: loss = 1.16853 (* 1 = 1.16853 loss)
I0525 21:37:27.401689 22368 sgd_solver.cpp:106] Iteration 25050, lr = 0.004
I0525 21:37:36.154428 22368 solver.cpp:237] Iteration 25200, loss = 1.40797
I0525 21:37:36.154598 22368 solver.cpp:253]     Train net output #0: loss = 1.40797 (* 1 = 1.40797 loss)
I0525 21:37:36.154615 22368 sgd_solver.cpp:106] Iteration 25200, lr = 0.004
I0525 21:37:44.914412 22368 solver.cpp:237] Iteration 25350, loss = 1.16546
I0525 21:37:44.914464 22368 solver.cpp:253]     Train net output #0: loss = 1.16546 (* 1 = 1.16546 loss)
I0525 21:37:44.914489 22368 sgd_solver.cpp:106] Iteration 25350, lr = 0.004
I0525 21:37:53.600940 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_25500.caffemodel
I0525 21:37:53.680869 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_25500.solverstate
I0525 21:37:53.724493 22368 solver.cpp:237] Iteration 25500, loss = 0.990774
I0525 21:37:53.724551 22368 solver.cpp:253]     Train net output #0: loss = 0.990774 (* 1 = 0.990774 loss)
I0525 21:37:53.724576 22368 sgd_solver.cpp:106] Iteration 25500, lr = 0.004
I0525 21:38:02.478937 22368 solver.cpp:237] Iteration 25650, loss = 1.33736
I0525 21:38:02.478976 22368 solver.cpp:253]     Train net output #0: loss = 1.33736 (* 1 = 1.33736 loss)
I0525 21:38:02.478992 22368 sgd_solver.cpp:106] Iteration 25650, lr = 0.004
I0525 21:38:11.228550 22368 solver.cpp:237] Iteration 25800, loss = 1.31463
I0525 21:38:11.228736 22368 solver.cpp:253]     Train net output #0: loss = 1.31463 (* 1 = 1.31463 loss)
I0525 21:38:11.228754 22368 sgd_solver.cpp:106] Iteration 25800, lr = 0.004
I0525 21:38:19.984051 22368 solver.cpp:237] Iteration 25950, loss = 1.20618
I0525 21:38:19.984088 22368 solver.cpp:253]     Train net output #0: loss = 1.20618 (* 1 = 1.20618 loss)
I0525 21:38:19.984112 22368 sgd_solver.cpp:106] Iteration 25950, lr = 0.004
I0525 21:38:49.628829 22368 solver.cpp:237] Iteration 26100, loss = 1.13636
I0525 21:38:49.629004 22368 solver.cpp:253]     Train net output #0: loss = 1.13636 (* 1 = 1.13636 loss)
I0525 21:38:49.629022 22368 sgd_solver.cpp:106] Iteration 26100, lr = 0.004
I0525 21:38:58.389602 22368 solver.cpp:237] Iteration 26250, loss = 1.41129
I0525 21:38:58.389655 22368 solver.cpp:253]     Train net output #0: loss = 1.41129 (* 1 = 1.41129 loss)
I0525 21:38:58.389683 22368 sgd_solver.cpp:106] Iteration 26250, lr = 0.004
I0525 21:39:07.152746 22368 solver.cpp:237] Iteration 26400, loss = 1.18612
I0525 21:39:07.152782 22368 solver.cpp:253]     Train net output #0: loss = 1.18612 (* 1 = 1.18612 loss)
I0525 21:39:07.152806 22368 sgd_solver.cpp:106] Iteration 26400, lr = 0.004
I0525 21:39:15.906503 22368 solver.cpp:237] Iteration 26550, loss = 1.11632
I0525 21:39:15.906539 22368 solver.cpp:253]     Train net output #0: loss = 1.11632 (* 1 = 1.11632 loss)
I0525 21:39:15.906564 22368 sgd_solver.cpp:106] Iteration 26550, lr = 0.004
I0525 21:39:24.663760 22368 solver.cpp:237] Iteration 26700, loss = 1.08752
I0525 21:39:24.663933 22368 solver.cpp:253]     Train net output #0: loss = 1.08752 (* 1 = 1.08752 loss)
I0525 21:39:24.663949 22368 sgd_solver.cpp:106] Iteration 26700, lr = 0.004
I0525 21:39:33.401916 22368 solver.cpp:237] Iteration 26850, loss = 0.995797
I0525 21:39:33.401953 22368 solver.cpp:253]     Train net output #0: loss = 0.995797 (* 1 = 0.995797 loss)
I0525 21:39:33.401973 22368 sgd_solver.cpp:106] Iteration 26850, lr = 0.004
I0525 21:39:42.088369 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_27000.caffemodel
I0525 21:39:42.167207 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_27000.solverstate
I0525 21:39:42.195706 22368 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 21:40:29.061205 22368 solver.cpp:409]     Test net output #0: accuracy = 0.873753
I0525 21:40:29.061379 22368 solver.cpp:409]     Test net output #1: loss = 0.422093 (* 1 = 0.422093 loss)
I0525 21:40:49.943476 22368 solver.cpp:237] Iteration 27000, loss = 1.26854
I0525 21:40:49.943539 22368 solver.cpp:253]     Train net output #0: loss = 1.26854 (* 1 = 1.26854 loss)
I0525 21:40:49.943558 22368 sgd_solver.cpp:106] Iteration 27000, lr = 0.004
I0525 21:40:58.695545 22368 solver.cpp:237] Iteration 27150, loss = 1.22804
I0525 21:40:58.695581 22368 solver.cpp:253]     Train net output #0: loss = 1.22804 (* 1 = 1.22804 loss)
I0525 21:40:58.695605 22368 sgd_solver.cpp:106] Iteration 27150, lr = 0.004
I0525 21:41:07.442399 22368 solver.cpp:237] Iteration 27300, loss = 1.19655
I0525 21:41:07.442574 22368 solver.cpp:253]     Train net output #0: loss = 1.19655 (* 1 = 1.19655 loss)
I0525 21:41:07.442592 22368 sgd_solver.cpp:106] Iteration 27300, lr = 0.004
I0525 21:41:16.198431 22368 solver.cpp:237] Iteration 27450, loss = 1.35686
I0525 21:41:16.198472 22368 solver.cpp:253]     Train net output #0: loss = 1.35686 (* 1 = 1.35686 loss)
I0525 21:41:16.198487 22368 sgd_solver.cpp:106] Iteration 27450, lr = 0.004
I0525 21:41:24.944895 22368 solver.cpp:237] Iteration 27600, loss = 1.3197
I0525 21:41:24.944929 22368 solver.cpp:253]     Train net output #0: loss = 1.3197 (* 1 = 1.3197 loss)
I0525 21:41:24.944953 22368 sgd_solver.cpp:106] Iteration 27600, lr = 0.004
I0525 21:41:33.696933 22368 solver.cpp:237] Iteration 27750, loss = 1.12024
I0525 21:41:33.696985 22368 solver.cpp:253]     Train net output #0: loss = 1.12024 (* 1 = 1.12024 loss)
I0525 21:41:33.697010 22368 sgd_solver.cpp:106] Iteration 27750, lr = 0.004
I0525 21:41:42.446159 22368 solver.cpp:237] Iteration 27900, loss = 1.24766
I0525 21:41:42.446328 22368 solver.cpp:253]     Train net output #0: loss = 1.24766 (* 1 = 1.24766 loss)
I0525 21:41:42.446344 22368 sgd_solver.cpp:106] Iteration 27900, lr = 0.004
I0525 21:42:12.095945 22368 solver.cpp:237] Iteration 28050, loss = 1.25364
I0525 21:42:12.096000 22368 solver.cpp:253]     Train net output #0: loss = 1.25364 (* 1 = 1.25364 loss)
I0525 21:42:12.096024 22368 sgd_solver.cpp:106] Iteration 28050, lr = 0.004
I0525 21:42:20.848232 22368 solver.cpp:237] Iteration 28200, loss = 1.33812
I0525 21:42:20.848405 22368 solver.cpp:253]     Train net output #0: loss = 1.33812 (* 1 = 1.33812 loss)
I0525 21:42:20.848423 22368 sgd_solver.cpp:106] Iteration 28200, lr = 0.004
I0525 21:42:29.596808 22368 solver.cpp:237] Iteration 28350, loss = 1.28629
I0525 21:42:29.596845 22368 solver.cpp:253]     Train net output #0: loss = 1.28629 (* 1 = 1.28629 loss)
I0525 21:42:29.596868 22368 sgd_solver.cpp:106] Iteration 28350, lr = 0.004
I0525 21:42:38.293496 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_28500.caffemodel
I0525 21:42:38.379111 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_28500.solverstate
I0525 21:42:38.425535 22368 solver.cpp:237] Iteration 28500, loss = 1.3304
I0525 21:42:38.425591 22368 solver.cpp:253]     Train net output #0: loss = 1.3304 (* 1 = 1.3304 loss)
I0525 21:42:38.425608 22368 sgd_solver.cpp:106] Iteration 28500, lr = 0.004
I0525 21:42:47.179039 22368 solver.cpp:237] Iteration 28650, loss = 1.3092
I0525 21:42:47.179095 22368 solver.cpp:253]     Train net output #0: loss = 1.3092 (* 1 = 1.3092 loss)
I0525 21:42:47.179117 22368 sgd_solver.cpp:106] Iteration 28650, lr = 0.004
I0525 21:42:55.932651 22368 solver.cpp:237] Iteration 28800, loss = 1.47122
I0525 21:42:55.932811 22368 solver.cpp:253]     Train net output #0: loss = 1.47122 (* 1 = 1.47122 loss)
I0525 21:42:55.932827 22368 sgd_solver.cpp:106] Iteration 28800, lr = 0.004
I0525 21:43:04.681427 22368 solver.cpp:237] Iteration 28950, loss = 1.14889
I0525 21:43:04.681465 22368 solver.cpp:253]     Train net output #0: loss = 1.14889 (* 1 = 1.14889 loss)
I0525 21:43:04.681483 22368 sgd_solver.cpp:106] Iteration 28950, lr = 0.004
I0525 21:43:34.305763 22368 solver.cpp:237] Iteration 29100, loss = 1.22692
I0525 21:43:34.305938 22368 solver.cpp:253]     Train net output #0: loss = 1.22692 (* 1 = 1.22692 loss)
I0525 21:43:34.305956 22368 sgd_solver.cpp:106] Iteration 29100, lr = 0.004
I0525 21:43:43.052690 22368 solver.cpp:237] Iteration 29250, loss = 1.2523
I0525 21:43:43.052727 22368 solver.cpp:253]     Train net output #0: loss = 1.2523 (* 1 = 1.2523 loss)
I0525 21:43:43.052745 22368 sgd_solver.cpp:106] Iteration 29250, lr = 0.004
I0525 21:43:51.801797 22368 solver.cpp:237] Iteration 29400, loss = 1.15993
I0525 21:43:51.801839 22368 solver.cpp:253]     Train net output #0: loss = 1.15993 (* 1 = 1.15993 loss)
I0525 21:43:51.801856 22368 sgd_solver.cpp:106] Iteration 29400, lr = 0.004
I0525 21:44:00.551640 22368 solver.cpp:237] Iteration 29550, loss = 1.33976
I0525 21:44:00.551692 22368 solver.cpp:253]     Train net output #0: loss = 1.33976 (* 1 = 1.33976 loss)
I0525 21:44:00.551710 22368 sgd_solver.cpp:106] Iteration 29550, lr = 0.004
I0525 21:44:09.297410 22368 solver.cpp:237] Iteration 29700, loss = 1.14347
I0525 21:44:09.297580 22368 solver.cpp:253]     Train net output #0: loss = 1.14347 (* 1 = 1.14347 loss)
I0525 21:44:09.297597 22368 sgd_solver.cpp:106] Iteration 29700, lr = 0.004
I0525 21:44:18.051146 22368 solver.cpp:237] Iteration 29850, loss = 1.19443
I0525 21:44:18.051182 22368 solver.cpp:253]     Train net output #0: loss = 1.19443 (* 1 = 1.19443 loss)
I0525 21:44:18.051204 22368 sgd_solver.cpp:106] Iteration 29850, lr = 0.004
I0525 21:44:26.742422 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_30000.caffemodel
I0525 21:44:26.823341 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_30000.solverstate
I0525 21:44:26.851299 22368 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 21:45:34.614864 22368 solver.cpp:409]     Test net output #0: accuracy = 0.881287
I0525 21:45:34.615052 22368 solver.cpp:409]     Test net output #1: loss = 0.385622 (* 1 = 0.385622 loss)
I0525 21:45:55.506070 22368 solver.cpp:237] Iteration 30000, loss = 1.27157
I0525 21:45:55.506129 22368 solver.cpp:253]     Train net output #0: loss = 1.27157 (* 1 = 1.27157 loss)
I0525 21:45:55.506150 22368 sgd_solver.cpp:106] Iteration 30000, lr = 0.004
I0525 21:46:04.254914 22368 solver.cpp:237] Iteration 30150, loss = 1.10645
I0525 21:46:04.254964 22368 solver.cpp:253]     Train net output #0: loss = 1.10645 (* 1 = 1.10645 loss)
I0525 21:46:04.254992 22368 sgd_solver.cpp:106] Iteration 30150, lr = 0.004
I0525 21:46:13.009829 22368 solver.cpp:237] Iteration 30300, loss = 1.26064
I0525 21:46:13.009990 22368 solver.cpp:253]     Train net output #0: loss = 1.26064 (* 1 = 1.26064 loss)
I0525 21:46:13.010007 22368 sgd_solver.cpp:106] Iteration 30300, lr = 0.004
I0525 21:46:21.762161 22368 solver.cpp:237] Iteration 30450, loss = 1.23191
I0525 21:46:21.762198 22368 solver.cpp:253]     Train net output #0: loss = 1.23191 (* 1 = 1.23191 loss)
I0525 21:46:21.762222 22368 sgd_solver.cpp:106] Iteration 30450, lr = 0.004
I0525 21:46:30.517282 22368 solver.cpp:237] Iteration 30600, loss = 0.906148
I0525 21:46:30.517330 22368 solver.cpp:253]     Train net output #0: loss = 0.906148 (* 1 = 0.906148 loss)
I0525 21:46:30.517350 22368 sgd_solver.cpp:106] Iteration 30600, lr = 0.004
I0525 21:46:39.266998 22368 solver.cpp:237] Iteration 30750, loss = 1.12747
I0525 21:46:39.267035 22368 solver.cpp:253]     Train net output #0: loss = 1.12747 (* 1 = 1.12747 loss)
I0525 21:46:39.267052 22368 sgd_solver.cpp:106] Iteration 30750, lr = 0.004
I0525 21:46:48.018937 22368 solver.cpp:237] Iteration 30900, loss = 1.12911
I0525 21:46:48.019104 22368 solver.cpp:253]     Train net output #0: loss = 1.12911 (* 1 = 1.12911 loss)
I0525 21:46:48.019119 22368 sgd_solver.cpp:106] Iteration 30900, lr = 0.004
I0525 21:47:17.588474 22368 solver.cpp:237] Iteration 31050, loss = 1.20446
I0525 21:47:17.588538 22368 solver.cpp:253]     Train net output #0: loss = 1.20446 (* 1 = 1.20446 loss)
I0525 21:47:17.588565 22368 sgd_solver.cpp:106] Iteration 31050, lr = 0.004
I0525 21:47:26.342557 22368 solver.cpp:237] Iteration 31200, loss = 1.29987
I0525 21:47:26.342728 22368 solver.cpp:253]     Train net output #0: loss = 1.29987 (* 1 = 1.29987 loss)
I0525 21:47:26.342746 22368 sgd_solver.cpp:106] Iteration 31200, lr = 0.004
I0525 21:47:35.097384 22368 solver.cpp:237] Iteration 31350, loss = 1.23192
I0525 21:47:35.097421 22368 solver.cpp:253]     Train net output #0: loss = 1.23192 (* 1 = 1.23192 loss)
I0525 21:47:35.097445 22368 sgd_solver.cpp:106] Iteration 31350, lr = 0.004
I0525 21:47:43.793064 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_31500.caffemodel
I0525 21:47:43.871351 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_31500.solverstate
I0525 21:47:43.914654 22368 solver.cpp:237] Iteration 31500, loss = 1.22989
I0525 21:47:43.914706 22368 solver.cpp:253]     Train net output #0: loss = 1.22989 (* 1 = 1.22989 loss)
I0525 21:47:43.914731 22368 sgd_solver.cpp:106] Iteration 31500, lr = 0.004
I0525 21:47:52.663125 22368 solver.cpp:237] Iteration 31650, loss = 1.27276
I0525 21:47:52.663163 22368 solver.cpp:253]     Train net output #0: loss = 1.27276 (* 1 = 1.27276 loss)
I0525 21:47:52.663180 22368 sgd_solver.cpp:106] Iteration 31650, lr = 0.004
I0525 21:48:01.415398 22368 solver.cpp:237] Iteration 31800, loss = 1.21344
I0525 21:48:01.415570 22368 solver.cpp:253]     Train net output #0: loss = 1.21344 (* 1 = 1.21344 loss)
I0525 21:48:01.415586 22368 sgd_solver.cpp:106] Iteration 31800, lr = 0.004
I0525 21:48:10.170652 22368 solver.cpp:237] Iteration 31950, loss = 1.28247
I0525 21:48:10.170706 22368 solver.cpp:253]     Train net output #0: loss = 1.28247 (* 1 = 1.28247 loss)
I0525 21:48:10.170730 22368 sgd_solver.cpp:106] Iteration 31950, lr = 0.004
I0525 21:48:39.750422 22368 solver.cpp:237] Iteration 32100, loss = 1.18454
I0525 21:48:39.750604 22368 solver.cpp:253]     Train net output #0: loss = 1.18454 (* 1 = 1.18454 loss)
I0525 21:48:39.750629 22368 sgd_solver.cpp:106] Iteration 32100, lr = 0.004
I0525 21:48:48.503125 22368 solver.cpp:237] Iteration 32250, loss = 1.09089
I0525 21:48:48.503161 22368 solver.cpp:253]     Train net output #0: loss = 1.09089 (* 1 = 1.09089 loss)
I0525 21:48:48.503180 22368 sgd_solver.cpp:106] Iteration 32250, lr = 0.004
I0525 21:48:57.256177 22368 solver.cpp:237] Iteration 32400, loss = 1.44426
I0525 21:48:57.256232 22368 solver.cpp:253]     Train net output #0: loss = 1.44426 (* 1 = 1.44426 loss)
I0525 21:48:57.256258 22368 sgd_solver.cpp:106] Iteration 32400, lr = 0.004
I0525 21:49:06.004415 22368 solver.cpp:237] Iteration 32550, loss = 1.15782
I0525 21:49:06.004451 22368 solver.cpp:253]     Train net output #0: loss = 1.15782 (* 1 = 1.15782 loss)
I0525 21:49:06.004475 22368 sgd_solver.cpp:106] Iteration 32550, lr = 0.004
I0525 21:49:14.752599 22368 solver.cpp:237] Iteration 32700, loss = 1.09158
I0525 21:49:14.752755 22368 solver.cpp:253]     Train net output #0: loss = 1.09158 (* 1 = 1.09158 loss)
I0525 21:49:14.752779 22368 sgd_solver.cpp:106] Iteration 32700, lr = 0.004
I0525 21:49:23.507374 22368 solver.cpp:237] Iteration 32850, loss = 1.19009
I0525 21:49:23.507426 22368 solver.cpp:253]     Train net output #0: loss = 1.19009 (* 1 = 1.19009 loss)
I0525 21:49:23.507450 22368 sgd_solver.cpp:106] Iteration 32850, lr = 0.004
I0525 21:49:32.206820 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_33000.caffemodel
I0525 21:49:32.285277 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_33000.solverstate
I0525 21:49:32.311326 22368 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 21:50:18.874217 22368 solver.cpp:409]     Test net output #0: accuracy = 0.880254
I0525 21:50:18.874402 22368 solver.cpp:409]     Test net output #1: loss = 0.394171 (* 1 = 0.394171 loss)
I0525 21:50:39.747593 22368 solver.cpp:237] Iteration 33000, loss = 1.02181
I0525 21:50:39.747653 22368 solver.cpp:253]     Train net output #0: loss = 1.02181 (* 1 = 1.02181 loss)
I0525 21:50:39.747671 22368 sgd_solver.cpp:106] Iteration 33000, lr = 0.004
I0525 21:50:48.506620 22368 solver.cpp:237] Iteration 33150, loss = 1.10246
I0525 21:50:48.506656 22368 solver.cpp:253]     Train net output #0: loss = 1.10246 (* 1 = 1.10246 loss)
I0525 21:50:48.506680 22368 sgd_solver.cpp:106] Iteration 33150, lr = 0.004
I0525 21:50:57.256958 22368 solver.cpp:237] Iteration 33300, loss = 1.22697
I0525 21:50:57.257143 22368 solver.cpp:253]     Train net output #0: loss = 1.22697 (* 1 = 1.22697 loss)
I0525 21:50:57.257160 22368 sgd_solver.cpp:106] Iteration 33300, lr = 0.004
I0525 21:51:06.007333 22368 solver.cpp:237] Iteration 33450, loss = 1.14684
I0525 21:51:06.007385 22368 solver.cpp:253]     Train net output #0: loss = 1.14684 (* 1 = 1.14684 loss)
I0525 21:51:06.007411 22368 sgd_solver.cpp:106] Iteration 33450, lr = 0.004
I0525 21:51:14.760810 22368 solver.cpp:237] Iteration 33600, loss = 1.26019
I0525 21:51:14.760848 22368 solver.cpp:253]     Train net output #0: loss = 1.26019 (* 1 = 1.26019 loss)
I0525 21:51:14.760867 22368 sgd_solver.cpp:106] Iteration 33600, lr = 0.004
I0525 21:51:23.518630 22368 solver.cpp:237] Iteration 33750, loss = 1.32032
I0525 21:51:23.518669 22368 solver.cpp:253]     Train net output #0: loss = 1.32032 (* 1 = 1.32032 loss)
I0525 21:51:23.518685 22368 sgd_solver.cpp:106] Iteration 33750, lr = 0.004
I0525 21:51:32.275233 22368 solver.cpp:237] Iteration 33900, loss = 1.13913
I0525 21:51:32.275410 22368 solver.cpp:253]     Train net output #0: loss = 1.13913 (* 1 = 1.13913 loss)
I0525 21:51:32.275429 22368 sgd_solver.cpp:106] Iteration 33900, lr = 0.004
I0525 21:52:01.917238 22368 solver.cpp:237] Iteration 34050, loss = 1.12202
I0525 21:52:01.917294 22368 solver.cpp:253]     Train net output #0: loss = 1.12202 (* 1 = 1.12202 loss)
I0525 21:52:01.917318 22368 sgd_solver.cpp:106] Iteration 34050, lr = 0.004
I0525 21:52:10.666988 22368 solver.cpp:237] Iteration 34200, loss = 1.28293
I0525 21:52:10.667162 22368 solver.cpp:253]     Train net output #0: loss = 1.28293 (* 1 = 1.28293 loss)
I0525 21:52:10.667178 22368 sgd_solver.cpp:106] Iteration 34200, lr = 0.004
I0525 21:52:19.418416 22368 solver.cpp:237] Iteration 34350, loss = 1.19672
I0525 21:52:19.418469 22368 solver.cpp:253]     Train net output #0: loss = 1.19672 (* 1 = 1.19672 loss)
I0525 21:52:19.418489 22368 sgd_solver.cpp:106] Iteration 34350, lr = 0.004
I0525 21:52:28.103149 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_34500.caffemodel
I0525 21:52:28.182014 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_34500.solverstate
I0525 21:52:28.225515 22368 solver.cpp:237] Iteration 34500, loss = 1.19823
I0525 21:52:28.225569 22368 solver.cpp:253]     Train net output #0: loss = 1.19823 (* 1 = 1.19823 loss)
I0525 21:52:28.225592 22368 sgd_solver.cpp:106] Iteration 34500, lr = 0.004
I0525 21:52:36.967795 22368 solver.cpp:237] Iteration 34650, loss = 1.28905
I0525 21:52:36.967831 22368 solver.cpp:253]     Train net output #0: loss = 1.28905 (* 1 = 1.28905 loss)
I0525 21:52:36.967854 22368 sgd_solver.cpp:106] Iteration 34650, lr = 0.004
I0525 21:52:45.709085 22368 solver.cpp:237] Iteration 34800, loss = 1.06887
I0525 21:52:45.709265 22368 solver.cpp:253]     Train net output #0: loss = 1.06887 (* 1 = 1.06887 loss)
I0525 21:52:45.709285 22368 sgd_solver.cpp:106] Iteration 34800, lr = 0.004
I0525 21:52:54.443167 22368 solver.cpp:237] Iteration 34950, loss = 1.12139
I0525 21:52:54.443204 22368 solver.cpp:253]     Train net output #0: loss = 1.12139 (* 1 = 1.12139 loss)
I0525 21:52:54.443228 22368 sgd_solver.cpp:106] Iteration 34950, lr = 0.004
I0525 21:53:24.063388 22368 solver.cpp:237] Iteration 35100, loss = 1.05384
I0525 21:53:24.063571 22368 solver.cpp:253]     Train net output #0: loss = 1.05384 (* 1 = 1.05384 loss)
I0525 21:53:24.063588 22368 sgd_solver.cpp:106] Iteration 35100, lr = 0.004
I0525 21:53:32.805089 22368 solver.cpp:237] Iteration 35250, loss = 1.28505
I0525 21:53:32.805142 22368 solver.cpp:253]     Train net output #0: loss = 1.28505 (* 1 = 1.28505 loss)
I0525 21:53:32.805167 22368 sgd_solver.cpp:106] Iteration 35250, lr = 0.004
I0525 21:53:41.545891 22368 solver.cpp:237] Iteration 35400, loss = 1.22644
I0525 21:53:41.545928 22368 solver.cpp:253]     Train net output #0: loss = 1.22644 (* 1 = 1.22644 loss)
I0525 21:53:41.545950 22368 sgd_solver.cpp:106] Iteration 35400, lr = 0.004
I0525 21:53:50.290858 22368 solver.cpp:237] Iteration 35550, loss = 1.18083
I0525 21:53:50.290894 22368 solver.cpp:253]     Train net output #0: loss = 1.18083 (* 1 = 1.18083 loss)
I0525 21:53:50.290912 22368 sgd_solver.cpp:106] Iteration 35550, lr = 0.004
I0525 21:53:59.035003 22368 solver.cpp:237] Iteration 35700, loss = 1.20452
I0525 21:53:59.035192 22368 solver.cpp:253]     Train net output #0: loss = 1.20452 (* 1 = 1.20452 loss)
I0525 21:53:59.035212 22368 sgd_solver.cpp:106] Iteration 35700, lr = 0.004
I0525 21:54:07.773871 22368 solver.cpp:237] Iteration 35850, loss = 1.26305
I0525 21:54:07.773908 22368 solver.cpp:253]     Train net output #0: loss = 1.26305 (* 1 = 1.26305 loss)
I0525 21:54:07.773931 22368 sgd_solver.cpp:106] Iteration 35850, lr = 0.004
I0525 21:54:16.452767 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_36000.caffemodel
I0525 21:54:16.532727 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_36000.solverstate
I0525 21:54:16.559764 22368 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 21:55:24.325346 22368 solver.cpp:409]     Test net output #0: accuracy = 0.879867
I0525 21:55:24.325527 22368 solver.cpp:409]     Test net output #1: loss = 0.39216 (* 1 = 0.39216 loss)
I0525 21:55:45.167696 22368 solver.cpp:237] Iteration 36000, loss = 1.11239
I0525 21:55:45.167758 22368 solver.cpp:253]     Train net output #0: loss = 1.11239 (* 1 = 1.11239 loss)
I0525 21:55:45.167779 22368 sgd_solver.cpp:106] Iteration 36000, lr = 0.004
I0525 21:55:53.900444 22368 solver.cpp:237] Iteration 36150, loss = 1.3262
I0525 21:55:53.900480 22368 solver.cpp:253]     Train net output #0: loss = 1.3262 (* 1 = 1.3262 loss)
I0525 21:55:53.900497 22368 sgd_solver.cpp:106] Iteration 36150, lr = 0.004
I0525 21:56:02.637774 22368 solver.cpp:237] Iteration 36300, loss = 1.15786
I0525 21:56:02.637954 22368 solver.cpp:253]     Train net output #0: loss = 1.15786 (* 1 = 1.15786 loss)
I0525 21:56:02.637972 22368 sgd_solver.cpp:106] Iteration 36300, lr = 0.004
I0525 21:56:11.371778 22368 solver.cpp:237] Iteration 36450, loss = 1.35712
I0525 21:56:11.371815 22368 solver.cpp:253]     Train net output #0: loss = 1.35712 (* 1 = 1.35712 loss)
I0525 21:56:11.371834 22368 sgd_solver.cpp:106] Iteration 36450, lr = 0.004
I0525 21:56:20.101863 22368 solver.cpp:237] Iteration 36600, loss = 1.13739
I0525 21:56:20.101899 22368 solver.cpp:253]     Train net output #0: loss = 1.13739 (* 1 = 1.13739 loss)
I0525 21:56:20.101922 22368 sgd_solver.cpp:106] Iteration 36600, lr = 0.004
I0525 21:56:28.839169 22368 solver.cpp:237] Iteration 36750, loss = 1.29815
I0525 21:56:28.839223 22368 solver.cpp:253]     Train net output #0: loss = 1.29815 (* 1 = 1.29815 loss)
I0525 21:56:28.839251 22368 sgd_solver.cpp:106] Iteration 36750, lr = 0.004
I0525 21:56:37.568898 22368 solver.cpp:237] Iteration 36900, loss = 1.40989
I0525 21:56:37.569072 22368 solver.cpp:253]     Train net output #0: loss = 1.40989 (* 1 = 1.40989 loss)
I0525 21:56:37.569088 22368 sgd_solver.cpp:106] Iteration 36900, lr = 0.004
I0525 21:57:07.163178 22368 solver.cpp:237] Iteration 37050, loss = 1.16163
I0525 21:57:07.163231 22368 solver.cpp:253]     Train net output #0: loss = 1.16163 (* 1 = 1.16163 loss)
I0525 21:57:07.163250 22368 sgd_solver.cpp:106] Iteration 37050, lr = 0.004
I0525 21:57:15.900712 22368 solver.cpp:237] Iteration 37200, loss = 1.1773
I0525 21:57:15.900877 22368 solver.cpp:253]     Train net output #0: loss = 1.1773 (* 1 = 1.1773 loss)
I0525 21:57:15.900893 22368 sgd_solver.cpp:106] Iteration 37200, lr = 0.004
I0525 21:57:24.636420 22368 solver.cpp:237] Iteration 37350, loss = 1.12579
I0525 21:57:24.636466 22368 solver.cpp:253]     Train net output #0: loss = 1.12579 (* 1 = 1.12579 loss)
I0525 21:57:24.636494 22368 sgd_solver.cpp:106] Iteration 37350, lr = 0.004
I0525 21:57:33.314138 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_37500.caffemodel
I0525 21:57:33.394845 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_37500.solverstate
I0525 21:57:33.440467 22368 solver.cpp:237] Iteration 37500, loss = 1.13913
I0525 21:57:33.440533 22368 solver.cpp:253]     Train net output #0: loss = 1.13913 (* 1 = 1.13913 loss)
I0525 21:57:33.440551 22368 sgd_solver.cpp:106] Iteration 37500, lr = 0.004
I0525 21:57:42.176766 22368 solver.cpp:237] Iteration 37650, loss = 1.06047
I0525 21:57:42.176818 22368 solver.cpp:253]     Train net output #0: loss = 1.06047 (* 1 = 1.06047 loss)
I0525 21:57:42.176846 22368 sgd_solver.cpp:106] Iteration 37650, lr = 0.004
I0525 21:57:50.907166 22368 solver.cpp:237] Iteration 37800, loss = 1.15247
I0525 21:57:50.907351 22368 solver.cpp:253]     Train net output #0: loss = 1.15247 (* 1 = 1.15247 loss)
I0525 21:57:50.907367 22368 sgd_solver.cpp:106] Iteration 37800, lr = 0.004
I0525 21:57:59.646956 22368 solver.cpp:237] Iteration 37950, loss = 1.14274
I0525 21:57:59.646993 22368 solver.cpp:253]     Train net output #0: loss = 1.14274 (* 1 = 1.14274 loss)
I0525 21:57:59.647017 22368 sgd_solver.cpp:106] Iteration 37950, lr = 0.004
I0525 21:58:29.207257 22368 solver.cpp:237] Iteration 38100, loss = 1.26299
I0525 21:58:29.207440 22368 solver.cpp:253]     Train net output #0: loss = 1.26299 (* 1 = 1.26299 loss)
I0525 21:58:29.207458 22368 sgd_solver.cpp:106] Iteration 38100, lr = 0.004
I0525 21:58:37.942628 22368 solver.cpp:237] Iteration 38250, loss = 1.12303
I0525 21:58:37.942678 22368 solver.cpp:253]     Train net output #0: loss = 1.12303 (* 1 = 1.12303 loss)
I0525 21:58:37.942697 22368 sgd_solver.cpp:106] Iteration 38250, lr = 0.004
I0525 21:58:46.676499 22368 solver.cpp:237] Iteration 38400, loss = 1.1995
I0525 21:58:46.676540 22368 solver.cpp:253]     Train net output #0: loss = 1.1995 (* 1 = 1.1995 loss)
I0525 21:58:46.676564 22368 sgd_solver.cpp:106] Iteration 38400, lr = 0.004
I0525 21:58:55.410019 22368 solver.cpp:237] Iteration 38550, loss = 1.14253
I0525 21:58:55.410056 22368 solver.cpp:253]     Train net output #0: loss = 1.14253 (* 1 = 1.14253 loss)
I0525 21:58:55.410074 22368 sgd_solver.cpp:106] Iteration 38550, lr = 0.004
I0525 21:59:04.141919 22368 solver.cpp:237] Iteration 38700, loss = 1.25926
I0525 21:59:04.142091 22368 solver.cpp:253]     Train net output #0: loss = 1.25926 (* 1 = 1.25926 loss)
I0525 21:59:04.142108 22368 sgd_solver.cpp:106] Iteration 38700, lr = 0.004
I0525 21:59:12.873733 22368 solver.cpp:237] Iteration 38850, loss = 0.982746
I0525 21:59:12.873772 22368 solver.cpp:253]     Train net output #0: loss = 0.982746 (* 1 = 0.982746 loss)
I0525 21:59:12.873790 22368 sgd_solver.cpp:106] Iteration 38850, lr = 0.004
I0525 21:59:21.546510 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_39000.caffemodel
I0525 21:59:21.625306 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_39000.solverstate
I0525 21:59:21.650862 22368 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 22:00:08.534227 22368 solver.cpp:409]     Test net output #0: accuracy = 0.883275
I0525 22:00:08.534420 22368 solver.cpp:409]     Test net output #1: loss = 0.364901 (* 1 = 0.364901 loss)
I0525 22:00:29.411769 22368 solver.cpp:237] Iteration 39000, loss = 1.21267
I0525 22:00:29.411828 22368 solver.cpp:253]     Train net output #0: loss = 1.21267 (* 1 = 1.21267 loss)
I0525 22:00:29.411846 22368 sgd_solver.cpp:106] Iteration 39000, lr = 0.004
I0525 22:00:38.170326 22368 solver.cpp:237] Iteration 39150, loss = 1.11426
I0525 22:00:38.170377 22368 solver.cpp:253]     Train net output #0: loss = 1.11426 (* 1 = 1.11426 loss)
I0525 22:00:38.170394 22368 sgd_solver.cpp:106] Iteration 39150, lr = 0.004
I0525 22:00:46.928720 22368 solver.cpp:237] Iteration 39300, loss = 1.06834
I0525 22:00:46.928890 22368 solver.cpp:253]     Train net output #0: loss = 1.06834 (* 1 = 1.06834 loss)
I0525 22:00:46.928907 22368 sgd_solver.cpp:106] Iteration 39300, lr = 0.004
I0525 22:00:55.684308 22368 solver.cpp:237] Iteration 39450, loss = 1.1322
I0525 22:00:55.684345 22368 solver.cpp:253]     Train net output #0: loss = 1.1322 (* 1 = 1.1322 loss)
I0525 22:00:55.684362 22368 sgd_solver.cpp:106] Iteration 39450, lr = 0.004
I0525 22:01:04.445407 22368 solver.cpp:237] Iteration 39600, loss = 1.04925
I0525 22:01:04.445461 22368 solver.cpp:253]     Train net output #0: loss = 1.04925 (* 1 = 1.04925 loss)
I0525 22:01:04.445485 22368 sgd_solver.cpp:106] Iteration 39600, lr = 0.004
I0525 22:01:13.205986 22368 solver.cpp:237] Iteration 39750, loss = 1.2113
I0525 22:01:13.206023 22368 solver.cpp:253]     Train net output #0: loss = 1.2113 (* 1 = 1.2113 loss)
I0525 22:01:13.206040 22368 sgd_solver.cpp:106] Iteration 39750, lr = 0.004
I0525 22:01:21.962066 22368 solver.cpp:237] Iteration 39900, loss = 1.43631
I0525 22:01:21.962244 22368 solver.cpp:253]     Train net output #0: loss = 1.43631 (* 1 = 1.43631 loss)
I0525 22:01:21.962261 22368 sgd_solver.cpp:106] Iteration 39900, lr = 0.004
I0525 22:01:51.595340 22368 solver.cpp:237] Iteration 40050, loss = 1.23379
I0525 22:01:51.595397 22368 solver.cpp:253]     Train net output #0: loss = 1.23379 (* 1 = 1.23379 loss)
I0525 22:01:51.595417 22368 sgd_solver.cpp:106] Iteration 40050, lr = 0.004
I0525 22:02:00.349222 22368 solver.cpp:237] Iteration 40200, loss = 1.1871
I0525 22:02:00.349390 22368 solver.cpp:253]     Train net output #0: loss = 1.1871 (* 1 = 1.1871 loss)
I0525 22:02:00.349406 22368 sgd_solver.cpp:106] Iteration 40200, lr = 0.004
I0525 22:02:09.098997 22368 solver.cpp:237] Iteration 40350, loss = 1.04393
I0525 22:02:09.099035 22368 solver.cpp:253]     Train net output #0: loss = 1.04393 (* 1 = 1.04393 loss)
I0525 22:02:09.099052 22368 sgd_solver.cpp:106] Iteration 40350, lr = 0.004
I0525 22:02:17.798387 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_40500.caffemodel
I0525 22:02:17.876955 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_40500.solverstate
I0525 22:02:17.920572 22368 solver.cpp:237] Iteration 40500, loss = 1.11913
I0525 22:02:17.920622 22368 solver.cpp:253]     Train net output #0: loss = 1.11913 (* 1 = 1.11913 loss)
I0525 22:02:17.920650 22368 sgd_solver.cpp:106] Iteration 40500, lr = 0.004
I0525 22:02:26.675802 22368 solver.cpp:237] Iteration 40650, loss = 1.13359
I0525 22:02:26.675838 22368 solver.cpp:253]     Train net output #0: loss = 1.13359 (* 1 = 1.13359 loss)
I0525 22:02:26.675861 22368 sgd_solver.cpp:106] Iteration 40650, lr = 0.004
I0525 22:02:35.425534 22368 solver.cpp:237] Iteration 40800, loss = 1.03267
I0525 22:02:35.425701 22368 solver.cpp:253]     Train net output #0: loss = 1.03267 (* 1 = 1.03267 loss)
I0525 22:02:35.425717 22368 sgd_solver.cpp:106] Iteration 40800, lr = 0.004
I0525 22:02:44.184306 22368 solver.cpp:237] Iteration 40950, loss = 1.33138
I0525 22:02:44.184360 22368 solver.cpp:253]     Train net output #0: loss = 1.33138 (* 1 = 1.33138 loss)
I0525 22:02:44.184383 22368 sgd_solver.cpp:106] Iteration 40950, lr = 0.004
I0525 22:03:13.828104 22368 solver.cpp:237] Iteration 41100, loss = 1.13983
I0525 22:03:13.828292 22368 solver.cpp:253]     Train net output #0: loss = 1.13983 (* 1 = 1.13983 loss)
I0525 22:03:13.828311 22368 sgd_solver.cpp:106] Iteration 41100, lr = 0.004
I0525 22:03:22.582309 22368 solver.cpp:237] Iteration 41250, loss = 1.10038
I0525 22:03:22.582345 22368 solver.cpp:253]     Train net output #0: loss = 1.10038 (* 1 = 1.10038 loss)
I0525 22:03:22.582362 22368 sgd_solver.cpp:106] Iteration 41250, lr = 0.004
I0525 22:03:31.333151 22368 solver.cpp:237] Iteration 41400, loss = 0.947117
I0525 22:03:31.333200 22368 solver.cpp:253]     Train net output #0: loss = 0.947117 (* 1 = 0.947117 loss)
I0525 22:03:31.333220 22368 sgd_solver.cpp:106] Iteration 41400, lr = 0.004
I0525 22:03:40.086138 22368 solver.cpp:237] Iteration 41550, loss = 1.3124
I0525 22:03:40.086175 22368 solver.cpp:253]     Train net output #0: loss = 1.3124 (* 1 = 1.3124 loss)
I0525 22:03:40.086192 22368 sgd_solver.cpp:106] Iteration 41550, lr = 0.004
I0525 22:03:48.839498 22368 solver.cpp:237] Iteration 41700, loss = 1.14248
I0525 22:03:48.839684 22368 solver.cpp:253]     Train net output #0: loss = 1.14248 (* 1 = 1.14248 loss)
I0525 22:03:48.839700 22368 sgd_solver.cpp:106] Iteration 41700, lr = 0.004
I0525 22:03:57.598824 22368 solver.cpp:237] Iteration 41850, loss = 1.05937
I0525 22:03:57.598876 22368 solver.cpp:253]     Train net output #0: loss = 1.05937 (* 1 = 1.05937 loss)
I0525 22:03:57.598901 22368 sgd_solver.cpp:106] Iteration 41850, lr = 0.004
I0525 22:04:06.293398 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_42000.caffemodel
I0525 22:04:06.372678 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_42000.solverstate
I0525 22:04:06.398337 22368 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 22:05:14.132982 22368 solver.cpp:409]     Test net output #0: accuracy = 0.885534
I0525 22:05:14.133164 22368 solver.cpp:409]     Test net output #1: loss = 0.357781 (* 1 = 0.357781 loss)
I0525 22:05:34.990250 22368 solver.cpp:237] Iteration 42000, loss = 1.15227
I0525 22:05:34.990314 22368 solver.cpp:253]     Train net output #0: loss = 1.15227 (* 1 = 1.15227 loss)
I0525 22:05:34.990334 22368 sgd_solver.cpp:106] Iteration 42000, lr = 0.004
I0525 22:05:43.732903 22368 solver.cpp:237] Iteration 42150, loss = 1.03083
I0525 22:05:43.732952 22368 solver.cpp:253]     Train net output #0: loss = 1.03083 (* 1 = 1.03083 loss)
I0525 22:05:43.732976 22368 sgd_solver.cpp:106] Iteration 42150, lr = 0.004
I0525 22:05:52.480960 22368 solver.cpp:237] Iteration 42300, loss = 1.13068
I0525 22:05:52.481129 22368 solver.cpp:253]     Train net output #0: loss = 1.13068 (* 1 = 1.13068 loss)
I0525 22:05:52.481145 22368 sgd_solver.cpp:106] Iteration 42300, lr = 0.004
I0525 22:06:01.216285 22368 solver.cpp:237] Iteration 42450, loss = 1.1367
I0525 22:06:01.216331 22368 solver.cpp:253]     Train net output #0: loss = 1.1367 (* 1 = 1.1367 loss)
I0525 22:06:01.216361 22368 sgd_solver.cpp:106] Iteration 42450, lr = 0.004
I0525 22:06:09.945698 22368 solver.cpp:237] Iteration 42600, loss = 1.27034
I0525 22:06:09.945735 22368 solver.cpp:253]     Train net output #0: loss = 1.27034 (* 1 = 1.27034 loss)
I0525 22:06:09.945754 22368 sgd_solver.cpp:106] Iteration 42600, lr = 0.004
I0525 22:06:18.676729 22368 solver.cpp:237] Iteration 42750, loss = 1.21774
I0525 22:06:18.676765 22368 solver.cpp:253]     Train net output #0: loss = 1.21774 (* 1 = 1.21774 loss)
I0525 22:06:18.676784 22368 sgd_solver.cpp:106] Iteration 42750, lr = 0.004
I0525 22:06:27.412515 22368 solver.cpp:237] Iteration 42900, loss = 1.03225
I0525 22:06:27.412691 22368 solver.cpp:253]     Train net output #0: loss = 1.03225 (* 1 = 1.03225 loss)
I0525 22:06:27.412708 22368 sgd_solver.cpp:106] Iteration 42900, lr = 0.004
I0525 22:06:57.003293 22368 solver.cpp:237] Iteration 43050, loss = 1.34118
I0525 22:06:57.003350 22368 solver.cpp:253]     Train net output #0: loss = 1.34118 (* 1 = 1.34118 loss)
I0525 22:06:57.003374 22368 sgd_solver.cpp:106] Iteration 43050, lr = 0.004
I0525 22:07:05.731273 22368 solver.cpp:237] Iteration 43200, loss = 1.25541
I0525 22:07:05.731456 22368 solver.cpp:253]     Train net output #0: loss = 1.25541 (* 1 = 1.25541 loss)
I0525 22:07:05.731472 22368 sgd_solver.cpp:106] Iteration 43200, lr = 0.004
I0525 22:07:14.466776 22368 solver.cpp:237] Iteration 43350, loss = 1.05511
I0525 22:07:14.466815 22368 solver.cpp:253]     Train net output #0: loss = 1.05511 (* 1 = 1.05511 loss)
I0525 22:07:14.466831 22368 sgd_solver.cpp:106] Iteration 43350, lr = 0.004
I0525 22:07:23.144534 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_43500.caffemodel
I0525 22:07:23.225319 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_43500.solverstate
I0525 22:07:23.270956 22368 solver.cpp:237] Iteration 43500, loss = 1.31665
I0525 22:07:23.271016 22368 solver.cpp:253]     Train net output #0: loss = 1.31665 (* 1 = 1.31665 loss)
I0525 22:07:23.271034 22368 sgd_solver.cpp:106] Iteration 43500, lr = 0.004
I0525 22:07:32.011890 22368 solver.cpp:237] Iteration 43650, loss = 1.21109
I0525 22:07:32.011927 22368 solver.cpp:253]     Train net output #0: loss = 1.21109 (* 1 = 1.21109 loss)
I0525 22:07:32.011945 22368 sgd_solver.cpp:106] Iteration 43650, lr = 0.004
I0525 22:07:40.748306 22368 solver.cpp:237] Iteration 43800, loss = 1.43543
I0525 22:07:40.748478 22368 solver.cpp:253]     Train net output #0: loss = 1.43543 (* 1 = 1.43543 loss)
I0525 22:07:40.748494 22368 sgd_solver.cpp:106] Iteration 43800, lr = 0.004
I0525 22:07:49.484220 22368 solver.cpp:237] Iteration 43950, loss = 1.15658
I0525 22:07:49.484273 22368 solver.cpp:253]     Train net output #0: loss = 1.15658 (* 1 = 1.15658 loss)
I0525 22:07:49.484298 22368 sgd_solver.cpp:106] Iteration 43950, lr = 0.004
I0525 22:08:19.047593 22368 solver.cpp:237] Iteration 44100, loss = 1.02274
I0525 22:08:19.047778 22368 solver.cpp:253]     Train net output #0: loss = 1.02274 (* 1 = 1.02274 loss)
I0525 22:08:19.047796 22368 sgd_solver.cpp:106] Iteration 44100, lr = 0.004
I0525 22:08:27.785435 22368 solver.cpp:237] Iteration 44250, loss = 1.16815
I0525 22:08:27.785470 22368 solver.cpp:253]     Train net output #0: loss = 1.16815 (* 1 = 1.16815 loss)
I0525 22:08:27.785490 22368 sgd_solver.cpp:106] Iteration 44250, lr = 0.004
I0525 22:08:36.523337 22368 solver.cpp:237] Iteration 44400, loss = 1.3128
I0525 22:08:36.523389 22368 solver.cpp:253]     Train net output #0: loss = 1.3128 (* 1 = 1.3128 loss)
I0525 22:08:36.523413 22368 sgd_solver.cpp:106] Iteration 44400, lr = 0.004
I0525 22:08:45.252743 22368 solver.cpp:237] Iteration 44550, loss = 1.26247
I0525 22:08:45.252780 22368 solver.cpp:253]     Train net output #0: loss = 1.26247 (* 1 = 1.26247 loss)
I0525 22:08:45.252799 22368 sgd_solver.cpp:106] Iteration 44550, lr = 0.004
I0525 22:08:53.986939 22368 solver.cpp:237] Iteration 44700, loss = 1.11171
I0525 22:08:53.987104 22368 solver.cpp:253]     Train net output #0: loss = 1.11171 (* 1 = 1.11171 loss)
I0525 22:08:53.987120 22368 sgd_solver.cpp:106] Iteration 44700, lr = 0.004
I0525 22:09:02.719089 22368 solver.cpp:237] Iteration 44850, loss = 1.18079
I0525 22:09:02.719143 22368 solver.cpp:253]     Train net output #0: loss = 1.18079 (* 1 = 1.18079 loss)
I0525 22:09:02.719167 22368 sgd_solver.cpp:106] Iteration 44850, lr = 0.004
I0525 22:09:11.401829 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_45000.caffemodel
I0525 22:09:11.482974 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_45000.solverstate
I0525 22:09:11.511253 22368 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 22:09:58.079298 22368 solver.cpp:409]     Test net output #0: accuracy = 0.884688
I0525 22:09:58.079504 22368 solver.cpp:409]     Test net output #1: loss = 0.381969 (* 1 = 0.381969 loss)
I0525 22:10:18.968914 22368 solver.cpp:237] Iteration 45000, loss = 1.09117
I0525 22:10:18.968974 22368 solver.cpp:253]     Train net output #0: loss = 1.09117 (* 1 = 1.09117 loss)
I0525 22:10:18.968993 22368 sgd_solver.cpp:106] Iteration 45000, lr = 0.004
I0525 22:10:27.710271 22368 solver.cpp:237] Iteration 45150, loss = 1.12257
I0525 22:10:27.710309 22368 solver.cpp:253]     Train net output #0: loss = 1.12257 (* 1 = 1.12257 loss)
I0525 22:10:27.710327 22368 sgd_solver.cpp:106] Iteration 45150, lr = 0.004
I0525 22:10:36.449008 22368 solver.cpp:237] Iteration 45300, loss = 0.998703
I0525 22:10:36.449190 22368 solver.cpp:253]     Train net output #0: loss = 0.998703 (* 1 = 0.998703 loss)
I0525 22:10:36.449210 22368 sgd_solver.cpp:106] Iteration 45300, lr = 0.004
I0525 22:10:45.206584 22368 solver.cpp:237] Iteration 45450, loss = 1.1032
I0525 22:10:45.206621 22368 solver.cpp:253]     Train net output #0: loss = 1.1032 (* 1 = 1.1032 loss)
I0525 22:10:45.206645 22368 sgd_solver.cpp:106] Iteration 45450, lr = 0.004
I0525 22:10:53.964345 22368 solver.cpp:237] Iteration 45600, loss = 1.10531
I0525 22:10:53.964381 22368 solver.cpp:253]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0525 22:10:53.964406 22368 sgd_solver.cpp:106] Iteration 45600, lr = 0.004
I0525 22:11:02.716981 22368 solver.cpp:237] Iteration 45750, loss = 1.15141
I0525 22:11:02.717036 22368 solver.cpp:253]     Train net output #0: loss = 1.15141 (* 1 = 1.15141 loss)
I0525 22:11:02.717061 22368 sgd_solver.cpp:106] Iteration 45750, lr = 0.004
I0525 22:11:11.474531 22368 solver.cpp:237] Iteration 45900, loss = 1.16503
I0525 22:11:11.474701 22368 solver.cpp:253]     Train net output #0: loss = 1.16503 (* 1 = 1.16503 loss)
I0525 22:11:11.474719 22368 sgd_solver.cpp:106] Iteration 45900, lr = 0.004
I0525 22:11:41.091229 22368 solver.cpp:237] Iteration 46050, loss = 1.20698
I0525 22:11:41.091286 22368 solver.cpp:253]     Train net output #0: loss = 1.20698 (* 1 = 1.20698 loss)
I0525 22:11:41.091305 22368 sgd_solver.cpp:106] Iteration 46050, lr = 0.004
I0525 22:11:49.840960 22368 solver.cpp:237] Iteration 46200, loss = 1.01068
I0525 22:11:49.841132 22368 solver.cpp:253]     Train net output #0: loss = 1.01068 (* 1 = 1.01068 loss)
I0525 22:11:49.841150 22368 sgd_solver.cpp:106] Iteration 46200, lr = 0.004
I0525 22:11:58.593269 22368 solver.cpp:237] Iteration 46350, loss = 1.35057
I0525 22:11:58.593322 22368 solver.cpp:253]     Train net output #0: loss = 1.35057 (* 1 = 1.35057 loss)
I0525 22:11:58.593346 22368 sgd_solver.cpp:106] Iteration 46350, lr = 0.004
I0525 22:12:07.290557 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_46500.caffemodel
I0525 22:12:07.369418 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_46500.solverstate
I0525 22:12:07.412758 22368 solver.cpp:237] Iteration 46500, loss = 1.24409
I0525 22:12:07.412811 22368 solver.cpp:253]     Train net output #0: loss = 1.24409 (* 1 = 1.24409 loss)
I0525 22:12:07.412838 22368 sgd_solver.cpp:106] Iteration 46500, lr = 0.004
I0525 22:12:16.169036 22368 solver.cpp:237] Iteration 46650, loss = 1.20061
I0525 22:12:16.169090 22368 solver.cpp:253]     Train net output #0: loss = 1.20061 (* 1 = 1.20061 loss)
I0525 22:12:16.169108 22368 sgd_solver.cpp:106] Iteration 46650, lr = 0.004
I0525 22:12:24.927651 22368 solver.cpp:237] Iteration 46800, loss = 1.16236
I0525 22:12:24.927825 22368 solver.cpp:253]     Train net output #0: loss = 1.16236 (* 1 = 1.16236 loss)
I0525 22:12:24.927841 22368 sgd_solver.cpp:106] Iteration 46800, lr = 0.004
I0525 22:12:33.682943 22368 solver.cpp:237] Iteration 46950, loss = 1.29795
I0525 22:12:33.682978 22368 solver.cpp:253]     Train net output #0: loss = 1.29795 (* 1 = 1.29795 loss)
I0525 22:12:33.682997 22368 sgd_solver.cpp:106] Iteration 46950, lr = 0.004
I0525 22:13:03.292435 22368 solver.cpp:237] Iteration 47100, loss = 1.01612
I0525 22:13:03.292637 22368 solver.cpp:253]     Train net output #0: loss = 1.01612 (* 1 = 1.01612 loss)
I0525 22:13:03.292655 22368 sgd_solver.cpp:106] Iteration 47100, lr = 0.004
I0525 22:13:12.046145 22368 solver.cpp:237] Iteration 47250, loss = 1.19831
I0525 22:13:12.046200 22368 solver.cpp:253]     Train net output #0: loss = 1.19831 (* 1 = 1.19831 loss)
I0525 22:13:12.046226 22368 sgd_solver.cpp:106] Iteration 47250, lr = 0.004
I0525 22:13:20.804886 22368 solver.cpp:237] Iteration 47400, loss = 1.19136
I0525 22:13:20.804922 22368 solver.cpp:253]     Train net output #0: loss = 1.19136 (* 1 = 1.19136 loss)
I0525 22:13:20.804946 22368 sgd_solver.cpp:106] Iteration 47400, lr = 0.004
I0525 22:13:29.563354 22368 solver.cpp:237] Iteration 47550, loss = 1.04494
I0525 22:13:29.563390 22368 solver.cpp:253]     Train net output #0: loss = 1.04494 (* 1 = 1.04494 loss)
I0525 22:13:29.563410 22368 sgd_solver.cpp:106] Iteration 47550, lr = 0.004
I0525 22:13:38.315605 22368 solver.cpp:237] Iteration 47700, loss = 1.22694
I0525 22:13:38.315783 22368 solver.cpp:253]     Train net output #0: loss = 1.22694 (* 1 = 1.22694 loss)
I0525 22:13:38.315799 22368 sgd_solver.cpp:106] Iteration 47700, lr = 0.004
I0525 22:13:47.070354 22368 solver.cpp:237] Iteration 47850, loss = 1.19455
I0525 22:13:47.070392 22368 solver.cpp:253]     Train net output #0: loss = 1.19455 (* 1 = 1.19455 loss)
I0525 22:13:47.070410 22368 sgd_solver.cpp:106] Iteration 47850, lr = 0.004
I0525 22:13:55.768751 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_48000.caffemodel
I0525 22:13:55.847195 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_48000.solverstate
I0525 22:13:55.872587 22368 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 22:15:03.694903 22368 solver.cpp:409]     Test net output #0: accuracy = 0.890182
I0525 22:15:03.695108 22368 solver.cpp:409]     Test net output #1: loss = 0.344408 (* 1 = 0.344408 loss)
I0525 22:15:24.582162 22368 solver.cpp:237] Iteration 48000, loss = 1.17753
I0525 22:15:24.582221 22368 solver.cpp:253]     Train net output #0: loss = 1.17753 (* 1 = 1.17753 loss)
I0525 22:15:24.582247 22368 sgd_solver.cpp:106] Iteration 48000, lr = 0.004
I0525 22:15:33.321590 22368 solver.cpp:237] Iteration 48150, loss = 1.14704
I0525 22:15:33.321629 22368 solver.cpp:253]     Train net output #0: loss = 1.14704 (* 1 = 1.14704 loss)
I0525 22:15:33.321645 22368 sgd_solver.cpp:106] Iteration 48150, lr = 0.004
I0525 22:15:42.063004 22368 solver.cpp:237] Iteration 48300, loss = 1.23734
I0525 22:15:42.063190 22368 solver.cpp:253]     Train net output #0: loss = 1.23734 (* 1 = 1.23734 loss)
I0525 22:15:42.063208 22368 sgd_solver.cpp:106] Iteration 48300, lr = 0.004
I0525 22:15:50.799474 22368 solver.cpp:237] Iteration 48450, loss = 1.34807
I0525 22:15:50.799510 22368 solver.cpp:253]     Train net output #0: loss = 1.34807 (* 1 = 1.34807 loss)
I0525 22:15:50.799528 22368 sgd_solver.cpp:106] Iteration 48450, lr = 0.004
I0525 22:15:59.527194 22368 solver.cpp:237] Iteration 48600, loss = 1.28783
I0525 22:15:59.527230 22368 solver.cpp:253]     Train net output #0: loss = 1.28783 (* 1 = 1.28783 loss)
I0525 22:15:59.527248 22368 sgd_solver.cpp:106] Iteration 48600, lr = 0.004
I0525 22:16:08.261171 22368 solver.cpp:237] Iteration 48750, loss = 1.07086
I0525 22:16:08.261225 22368 solver.cpp:253]     Train net output #0: loss = 1.07086 (* 1 = 1.07086 loss)
I0525 22:16:08.261250 22368 sgd_solver.cpp:106] Iteration 48750, lr = 0.004
I0525 22:16:16.995365 22368 solver.cpp:237] Iteration 48900, loss = 1.19773
I0525 22:16:16.995544 22368 solver.cpp:253]     Train net output #0: loss = 1.19773 (* 1 = 1.19773 loss)
I0525 22:16:16.995561 22368 sgd_solver.cpp:106] Iteration 48900, lr = 0.004
I0525 22:16:46.558122 22368 solver.cpp:237] Iteration 49050, loss = 1.16075
I0525 22:16:46.558179 22368 solver.cpp:253]     Train net output #0: loss = 1.16075 (* 1 = 1.16075 loss)
I0525 22:16:46.558198 22368 sgd_solver.cpp:106] Iteration 49050, lr = 0.004
I0525 22:16:55.293521 22368 solver.cpp:237] Iteration 49200, loss = 1.12602
I0525 22:16:55.293712 22368 solver.cpp:253]     Train net output #0: loss = 1.12602 (* 1 = 1.12602 loss)
I0525 22:16:55.293730 22368 sgd_solver.cpp:106] Iteration 49200, lr = 0.004
I0525 22:17:04.027590 22368 solver.cpp:237] Iteration 49350, loss = 1.21923
I0525 22:17:04.027629 22368 solver.cpp:253]     Train net output #0: loss = 1.21923 (* 1 = 1.21923 loss)
I0525 22:17:04.027645 22368 sgd_solver.cpp:106] Iteration 49350, lr = 0.004
I0525 22:17:12.708931 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_49500.caffemodel
I0525 22:17:12.790266 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_49500.solverstate
I0525 22:17:12.836083 22368 solver.cpp:237] Iteration 49500, loss = 1.2662
I0525 22:17:12.836138 22368 solver.cpp:253]     Train net output #0: loss = 1.2662 (* 1 = 1.2662 loss)
I0525 22:17:12.836158 22368 sgd_solver.cpp:106] Iteration 49500, lr = 0.004
I0525 22:17:21.574491 22368 solver.cpp:237] Iteration 49650, loss = 1.11859
I0525 22:17:21.574542 22368 solver.cpp:253]     Train net output #0: loss = 1.11859 (* 1 = 1.11859 loss)
I0525 22:17:21.574559 22368 sgd_solver.cpp:106] Iteration 49650, lr = 0.004
I0525 22:17:30.310350 22368 solver.cpp:237] Iteration 49800, loss = 1.24227
I0525 22:17:30.310523 22368 solver.cpp:253]     Train net output #0: loss = 1.24227 (* 1 = 1.24227 loss)
I0525 22:17:30.310539 22368 sgd_solver.cpp:106] Iteration 49800, lr = 0.004
I0525 22:17:39.053961 22368 solver.cpp:237] Iteration 49950, loss = 1.11397
I0525 22:17:39.053999 22368 solver.cpp:253]     Train net output #0: loss = 1.11397 (* 1 = 1.11397 loss)
I0525 22:17:39.054016 22368 sgd_solver.cpp:106] Iteration 49950, lr = 0.004
I0525 22:18:08.688848 22368 solver.cpp:237] Iteration 50100, loss = 1.1383
I0525 22:18:08.689039 22368 solver.cpp:253]     Train net output #0: loss = 1.1383 (* 1 = 1.1383 loss)
I0525 22:18:08.689059 22368 sgd_solver.cpp:106] Iteration 50100, lr = 0.004
I0525 22:18:17.425052 22368 solver.cpp:237] Iteration 50250, loss = 1.17238
I0525 22:18:17.425089 22368 solver.cpp:253]     Train net output #0: loss = 1.17238 (* 1 = 1.17238 loss)
I0525 22:18:17.425107 22368 sgd_solver.cpp:106] Iteration 50250, lr = 0.004
I0525 22:18:26.163549 22368 solver.cpp:237] Iteration 50400, loss = 1.11203
I0525 22:18:26.163590 22368 solver.cpp:253]     Train net output #0: loss = 1.11203 (* 1 = 1.11203 loss)
I0525 22:18:26.163606 22368 sgd_solver.cpp:106] Iteration 50400, lr = 0.004
I0525 22:18:34.897650 22368 solver.cpp:237] Iteration 50550, loss = 1.11886
I0525 22:18:34.897698 22368 solver.cpp:253]     Train net output #0: loss = 1.11886 (* 1 = 1.11886 loss)
I0525 22:18:34.897717 22368 sgd_solver.cpp:106] Iteration 50550, lr = 0.004
I0525 22:18:43.633945 22368 solver.cpp:237] Iteration 50700, loss = 1.186
I0525 22:18:43.634124 22368 solver.cpp:253]     Train net output #0: loss = 1.186 (* 1 = 1.186 loss)
I0525 22:18:43.634140 22368 sgd_solver.cpp:106] Iteration 50700, lr = 0.004
I0525 22:18:52.370168 22368 solver.cpp:237] Iteration 50850, loss = 1.1469
I0525 22:18:52.370204 22368 solver.cpp:253]     Train net output #0: loss = 1.1469 (* 1 = 1.1469 loss)
I0525 22:18:52.370223 22368 sgd_solver.cpp:106] Iteration 50850, lr = 0.004
I0525 22:19:01.051899 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_51000.caffemodel
I0525 22:19:01.132079 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_51000.solverstate
I0525 22:19:01.159274 22368 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 22:19:48.046262 22368 solver.cpp:409]     Test net output #0: accuracy = 0.885068
I0525 22:19:48.046463 22368 solver.cpp:409]     Test net output #1: loss = 0.380471 (* 1 = 0.380471 loss)
I0525 22:20:08.901330 22368 solver.cpp:237] Iteration 51000, loss = 1.18572
I0525 22:20:08.901394 22368 solver.cpp:253]     Train net output #0: loss = 1.18572 (* 1 = 1.18572 loss)
I0525 22:20:08.901415 22368 sgd_solver.cpp:106] Iteration 51000, lr = 0.004
I0525 22:20:17.649236 22368 solver.cpp:237] Iteration 51150, loss = 1.08637
I0525 22:20:17.649286 22368 solver.cpp:253]     Train net output #0: loss = 1.08637 (* 1 = 1.08637 loss)
I0525 22:20:17.649304 22368 sgd_solver.cpp:106] Iteration 51150, lr = 0.004
I0525 22:20:26.396297 22368 solver.cpp:237] Iteration 51300, loss = 1.11544
I0525 22:20:26.396474 22368 solver.cpp:253]     Train net output #0: loss = 1.11544 (* 1 = 1.11544 loss)
I0525 22:20:26.396491 22368 sgd_solver.cpp:106] Iteration 51300, lr = 0.004
I0525 22:20:35.144717 22368 solver.cpp:237] Iteration 51450, loss = 1.19554
I0525 22:20:35.144753 22368 solver.cpp:253]     Train net output #0: loss = 1.19554 (* 1 = 1.19554 loss)
I0525 22:20:35.144773 22368 sgd_solver.cpp:106] Iteration 51450, lr = 0.004
I0525 22:20:43.889955 22368 solver.cpp:237] Iteration 51600, loss = 1.24753
I0525 22:20:43.890005 22368 solver.cpp:253]     Train net output #0: loss = 1.24753 (* 1 = 1.24753 loss)
I0525 22:20:43.890031 22368 sgd_solver.cpp:106] Iteration 51600, lr = 0.004
I0525 22:20:52.640072 22368 solver.cpp:237] Iteration 51750, loss = 1.12095
I0525 22:20:52.640110 22368 solver.cpp:253]     Train net output #0: loss = 1.12095 (* 1 = 1.12095 loss)
I0525 22:20:52.640127 22368 sgd_solver.cpp:106] Iteration 51750, lr = 0.004
I0525 22:21:01.388825 22368 solver.cpp:237] Iteration 51900, loss = 1.10811
I0525 22:21:01.389011 22368 solver.cpp:253]     Train net output #0: loss = 1.10811 (* 1 = 1.10811 loss)
I0525 22:21:01.389029 22368 sgd_solver.cpp:106] Iteration 51900, lr = 0.004
I0525 22:21:31.015178 22368 solver.cpp:237] Iteration 52050, loss = 1.081
I0525 22:21:31.015236 22368 solver.cpp:253]     Train net output #0: loss = 1.081 (* 1 = 1.081 loss)
I0525 22:21:31.015255 22368 sgd_solver.cpp:106] Iteration 52050, lr = 0.004
I0525 22:21:39.755136 22368 solver.cpp:237] Iteration 52200, loss = 0.987353
I0525 22:21:39.755313 22368 solver.cpp:253]     Train net output #0: loss = 0.987353 (* 1 = 0.987353 loss)
I0525 22:21:39.755329 22368 sgd_solver.cpp:106] Iteration 52200, lr = 0.004
I0525 22:21:48.497779 22368 solver.cpp:237] Iteration 52350, loss = 1.21574
I0525 22:21:48.497817 22368 solver.cpp:253]     Train net output #0: loss = 1.21574 (* 1 = 1.21574 loss)
I0525 22:21:48.497834 22368 sgd_solver.cpp:106] Iteration 52350, lr = 0.004
I0525 22:21:57.184279 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_52500.caffemodel
I0525 22:21:57.265357 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_52500.solverstate
I0525 22:21:57.310943 22368 solver.cpp:237] Iteration 52500, loss = 1.16768
I0525 22:21:57.310999 22368 solver.cpp:253]     Train net output #0: loss = 1.16768 (* 1 = 1.16768 loss)
I0525 22:21:57.311025 22368 sgd_solver.cpp:106] Iteration 52500, lr = 0.004
I0525 22:22:06.058465 22368 solver.cpp:237] Iteration 52650, loss = 0.919788
I0525 22:22:06.058503 22368 solver.cpp:253]     Train net output #0: loss = 0.919788 (* 1 = 0.919788 loss)
I0525 22:22:06.058521 22368 sgd_solver.cpp:106] Iteration 52650, lr = 0.004
I0525 22:22:14.801643 22368 solver.cpp:237] Iteration 52800, loss = 1.01082
I0525 22:22:14.801831 22368 solver.cpp:253]     Train net output #0: loss = 1.01082 (* 1 = 1.01082 loss)
I0525 22:22:14.801847 22368 sgd_solver.cpp:106] Iteration 52800, lr = 0.004
I0525 22:22:23.542304 22368 solver.cpp:237] Iteration 52950, loss = 1.26377
I0525 22:22:23.542356 22368 solver.cpp:253]     Train net output #0: loss = 1.26377 (* 1 = 1.26377 loss)
I0525 22:22:23.542381 22368 sgd_solver.cpp:106] Iteration 52950, lr = 0.004
I0525 22:22:53.173161 22368 solver.cpp:237] Iteration 53100, loss = 1.08275
I0525 22:22:53.173357 22368 solver.cpp:253]     Train net output #0: loss = 1.08275 (* 1 = 1.08275 loss)
I0525 22:22:53.173373 22368 sgd_solver.cpp:106] Iteration 53100, lr = 0.004
I0525 22:23:01.917424 22368 solver.cpp:237] Iteration 53250, loss = 1.21916
I0525 22:23:01.917460 22368 solver.cpp:253]     Train net output #0: loss = 1.21916 (* 1 = 1.21916 loss)
I0525 22:23:01.917479 22368 sgd_solver.cpp:106] Iteration 53250, lr = 0.004
I0525 22:23:10.666280 22368 solver.cpp:237] Iteration 53400, loss = 1.08804
I0525 22:23:10.666333 22368 solver.cpp:253]     Train net output #0: loss = 1.08804 (* 1 = 1.08804 loss)
I0525 22:23:10.666358 22368 sgd_solver.cpp:106] Iteration 53400, lr = 0.004
I0525 22:23:19.411424 22368 solver.cpp:237] Iteration 53550, loss = 1.1985
I0525 22:23:19.411460 22368 solver.cpp:253]     Train net output #0: loss = 1.1985 (* 1 = 1.1985 loss)
I0525 22:23:19.411478 22368 sgd_solver.cpp:106] Iteration 53550, lr = 0.004
I0525 22:23:28.158550 22368 solver.cpp:237] Iteration 53700, loss = 1.1016
I0525 22:23:28.158722 22368 solver.cpp:253]     Train net output #0: loss = 1.1016 (* 1 = 1.1016 loss)
I0525 22:23:28.158740 22368 sgd_solver.cpp:106] Iteration 53700, lr = 0.004
I0525 22:23:36.905923 22368 solver.cpp:237] Iteration 53850, loss = 0.945079
I0525 22:23:36.905977 22368 solver.cpp:253]     Train net output #0: loss = 0.945079 (* 1 = 0.945079 loss)
I0525 22:23:36.906002 22368 sgd_solver.cpp:106] Iteration 53850, lr = 0.004
I0525 22:23:45.596604 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_54000.caffemodel
I0525 22:23:45.677325 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_54000.solverstate
I0525 22:23:45.705516 22368 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 22:24:53.494034 22368 solver.cpp:409]     Test net output #0: accuracy = 0.890008
I0525 22:24:53.494227 22368 solver.cpp:409]     Test net output #1: loss = 0.346252 (* 1 = 0.346252 loss)
I0525 22:25:14.371191 22368 solver.cpp:237] Iteration 54000, loss = 1.07628
I0525 22:25:14.371254 22368 solver.cpp:253]     Train net output #0: loss = 1.07628 (* 1 = 1.07628 loss)
I0525 22:25:14.371274 22368 sgd_solver.cpp:106] Iteration 54000, lr = 0.004
I0525 22:25:23.126755 22368 solver.cpp:237] Iteration 54150, loss = 0.972187
I0525 22:25:23.126792 22368 solver.cpp:253]     Train net output #0: loss = 0.972187 (* 1 = 0.972187 loss)
I0525 22:25:23.126811 22368 sgd_solver.cpp:106] Iteration 54150, lr = 0.004
I0525 22:25:31.876821 22368 solver.cpp:237] Iteration 54300, loss = 1.10614
I0525 22:25:31.876998 22368 solver.cpp:253]     Train net output #0: loss = 1.10614 (* 1 = 1.10614 loss)
I0525 22:25:31.877014 22368 sgd_solver.cpp:106] Iteration 54300, lr = 0.004
I0525 22:25:40.627207 22368 solver.cpp:237] Iteration 54450, loss = 1.23705
I0525 22:25:40.627257 22368 solver.cpp:253]     Train net output #0: loss = 1.23705 (* 1 = 1.23705 loss)
I0525 22:25:40.627285 22368 sgd_solver.cpp:106] Iteration 54450, lr = 0.004
I0525 22:25:49.376011 22368 solver.cpp:237] Iteration 54600, loss = 1.2445
I0525 22:25:49.376047 22368 solver.cpp:253]     Train net output #0: loss = 1.2445 (* 1 = 1.2445 loss)
I0525 22:25:49.376065 22368 sgd_solver.cpp:106] Iteration 54600, lr = 0.004
I0525 22:25:58.123077 22368 solver.cpp:237] Iteration 54750, loss = 1.22554
I0525 22:25:58.123114 22368 solver.cpp:253]     Train net output #0: loss = 1.22554 (* 1 = 1.22554 loss)
I0525 22:25:58.123131 22368 sgd_solver.cpp:106] Iteration 54750, lr = 0.004
I0525 22:26:06.856488 22368 solver.cpp:237] Iteration 54900, loss = 1.11861
I0525 22:26:06.856690 22368 solver.cpp:253]     Train net output #0: loss = 1.11861 (* 1 = 1.11861 loss)
I0525 22:26:06.856708 22368 sgd_solver.cpp:106] Iteration 54900, lr = 0.004
I0525 22:26:36.471698 22368 solver.cpp:237] Iteration 55050, loss = 1.09537
I0525 22:26:36.471750 22368 solver.cpp:253]     Train net output #0: loss = 1.09537 (* 1 = 1.09537 loss)
I0525 22:26:36.471776 22368 sgd_solver.cpp:106] Iteration 55050, lr = 0.004
I0525 22:26:45.198262 22368 solver.cpp:237] Iteration 55200, loss = 1.14435
I0525 22:26:45.198441 22368 solver.cpp:253]     Train net output #0: loss = 1.14435 (* 1 = 1.14435 loss)
I0525 22:26:45.198457 22368 sgd_solver.cpp:106] Iteration 55200, lr = 0.004
I0525 22:26:53.925398 22368 solver.cpp:237] Iteration 55350, loss = 1.24634
I0525 22:26:53.925451 22368 solver.cpp:253]     Train net output #0: loss = 1.24634 (* 1 = 1.24634 loss)
I0525 22:26:53.925475 22368 sgd_solver.cpp:106] Iteration 55350, lr = 0.004
I0525 22:27:02.592780 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_55500.caffemodel
I0525 22:27:02.672236 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_55500.solverstate
I0525 22:27:02.715667 22368 solver.cpp:237] Iteration 55500, loss = 0.905751
I0525 22:27:02.715723 22368 solver.cpp:253]     Train net output #0: loss = 0.905751 (* 1 = 0.905751 loss)
I0525 22:27:02.715750 22368 sgd_solver.cpp:106] Iteration 55500, lr = 0.004
I0525 22:27:11.440616 22368 solver.cpp:237] Iteration 55650, loss = 1.09878
I0525 22:27:11.440652 22368 solver.cpp:253]     Train net output #0: loss = 1.09878 (* 1 = 1.09878 loss)
I0525 22:27:11.440672 22368 sgd_solver.cpp:106] Iteration 55650, lr = 0.004
I0525 22:27:20.162955 22368 solver.cpp:237] Iteration 55800, loss = 1.07383
I0525 22:27:20.163147 22368 solver.cpp:253]     Train net output #0: loss = 1.07383 (* 1 = 1.07383 loss)
I0525 22:27:20.163166 22368 sgd_solver.cpp:106] Iteration 55800, lr = 0.004
I0525 22:27:28.889259 22368 solver.cpp:237] Iteration 55950, loss = 0.964866
I0525 22:27:28.889297 22368 solver.cpp:253]     Train net output #0: loss = 0.964866 (* 1 = 0.964866 loss)
I0525 22:27:28.889313 22368 sgd_solver.cpp:106] Iteration 55950, lr = 0.004
I0525 22:27:58.493996 22368 solver.cpp:237] Iteration 56100, loss = 1.13346
I0525 22:27:58.494194 22368 solver.cpp:253]     Train net output #0: loss = 1.13346 (* 1 = 1.13346 loss)
I0525 22:27:58.494210 22368 sgd_solver.cpp:106] Iteration 56100, lr = 0.004
I0525 22:28:07.219353 22368 solver.cpp:237] Iteration 56250, loss = 1.07057
I0525 22:28:07.219403 22368 solver.cpp:253]     Train net output #0: loss = 1.07057 (* 1 = 1.07057 loss)
I0525 22:28:07.219434 22368 sgd_solver.cpp:106] Iteration 56250, lr = 0.004
I0525 22:28:15.947125 22368 solver.cpp:237] Iteration 56400, loss = 1.14527
I0525 22:28:15.947163 22368 solver.cpp:253]     Train net output #0: loss = 1.14527 (* 1 = 1.14527 loss)
I0525 22:28:15.947180 22368 sgd_solver.cpp:106] Iteration 56400, lr = 0.004
I0525 22:28:24.676980 22368 solver.cpp:237] Iteration 56550, loss = 1.18426
I0525 22:28:24.677017 22368 solver.cpp:253]     Train net output #0: loss = 1.18426 (* 1 = 1.18426 loss)
I0525 22:28:24.677036 22368 sgd_solver.cpp:106] Iteration 56550, lr = 0.004
I0525 22:28:33.402957 22368 solver.cpp:237] Iteration 56700, loss = 1.18792
I0525 22:28:33.403147 22368 solver.cpp:253]     Train net output #0: loss = 1.18792 (* 1 = 1.18792 loss)
I0525 22:28:33.403164 22368 sgd_solver.cpp:106] Iteration 56700, lr = 0.004
I0525 22:28:42.127180 22368 solver.cpp:237] Iteration 56850, loss = 1.11614
I0525 22:28:42.127216 22368 solver.cpp:253]     Train net output #0: loss = 1.11614 (* 1 = 1.11614 loss)
I0525 22:28:42.127235 22368 sgd_solver.cpp:106] Iteration 56850, lr = 0.004
I0525 22:28:50.794363 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_57000.caffemodel
I0525 22:28:50.872684 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_57000.solverstate
I0525 22:28:50.898205 22368 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 22:29:37.444875 22368 solver.cpp:409]     Test net output #0: accuracy = 0.890935
I0525 22:29:37.445080 22368 solver.cpp:409]     Test net output #1: loss = 0.341703 (* 1 = 0.341703 loss)
I0525 22:29:58.330950 22368 solver.cpp:237] Iteration 57000, loss = 1.20861
I0525 22:29:58.331013 22368 solver.cpp:253]     Train net output #0: loss = 1.20861 (* 1 = 1.20861 loss)
I0525 22:29:58.331033 22368 sgd_solver.cpp:106] Iteration 57000, lr = 0.004
I0525 22:30:07.085280 22368 solver.cpp:237] Iteration 57150, loss = 1.1518
I0525 22:30:07.085317 22368 solver.cpp:253]     Train net output #0: loss = 1.1518 (* 1 = 1.1518 loss)
I0525 22:30:07.085338 22368 sgd_solver.cpp:106] Iteration 57150, lr = 0.004
I0525 22:30:15.834352 22368 solver.cpp:237] Iteration 57300, loss = 1.09454
I0525 22:30:15.834552 22368 solver.cpp:253]     Train net output #0: loss = 1.09454 (* 1 = 1.09454 loss)
I0525 22:30:15.834576 22368 sgd_solver.cpp:106] Iteration 57300, lr = 0.004
I0525 22:30:24.585000 22368 solver.cpp:237] Iteration 57450, loss = 1.01984
I0525 22:30:24.585036 22368 solver.cpp:253]     Train net output #0: loss = 1.01984 (* 1 = 1.01984 loss)
I0525 22:30:24.585065 22368 sgd_solver.cpp:106] Iteration 57450, lr = 0.004
I0525 22:30:33.332590 22368 solver.cpp:237] Iteration 57600, loss = 1.36463
I0525 22:30:33.332626 22368 solver.cpp:253]     Train net output #0: loss = 1.36463 (* 1 = 1.36463 loss)
I0525 22:30:33.332656 22368 sgd_solver.cpp:106] Iteration 57600, lr = 0.004
I0525 22:30:42.089512 22368 solver.cpp:237] Iteration 57750, loss = 1.06951
I0525 22:30:42.089567 22368 solver.cpp:253]     Train net output #0: loss = 1.06951 (* 1 = 1.06951 loss)
I0525 22:30:42.089594 22368 sgd_solver.cpp:106] Iteration 57750, lr = 0.004
I0525 22:30:50.839990 22368 solver.cpp:237] Iteration 57900, loss = 1.02577
I0525 22:30:50.840167 22368 solver.cpp:253]     Train net output #0: loss = 1.02577 (* 1 = 1.02577 loss)
I0525 22:30:50.840183 22368 sgd_solver.cpp:106] Iteration 57900, lr = 0.004
I0525 22:31:20.458159 22368 solver.cpp:237] Iteration 58050, loss = 1.03008
I0525 22:31:20.458215 22368 solver.cpp:253]     Train net output #0: loss = 1.03008 (* 1 = 1.03008 loss)
I0525 22:31:20.458240 22368 sgd_solver.cpp:106] Iteration 58050, lr = 0.004
I0525 22:31:29.208691 22368 solver.cpp:237] Iteration 58200, loss = 1.2651
I0525 22:31:29.208895 22368 solver.cpp:253]     Train net output #0: loss = 1.2651 (* 1 = 1.2651 loss)
I0525 22:31:29.208914 22368 sgd_solver.cpp:106] Iteration 58200, lr = 0.004
I0525 22:31:37.956811 22368 solver.cpp:237] Iteration 58350, loss = 1.05927
I0525 22:31:37.956848 22368 solver.cpp:253]     Train net output #0: loss = 1.05927 (* 1 = 1.05927 loss)
I0525 22:31:37.956879 22368 sgd_solver.cpp:106] Iteration 58350, lr = 0.004
I0525 22:31:46.647788 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_58500.caffemodel
I0525 22:31:46.729638 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_58500.solverstate
I0525 22:31:46.774435 22368 solver.cpp:237] Iteration 58500, loss = 1.37048
I0525 22:31:46.774490 22368 solver.cpp:253]     Train net output #0: loss = 1.37048 (* 1 = 1.37048 loss)
I0525 22:31:46.774508 22368 sgd_solver.cpp:106] Iteration 58500, lr = 0.004
I0525 22:31:55.522701 22368 solver.cpp:237] Iteration 58650, loss = 0.92684
I0525 22:31:55.522754 22368 solver.cpp:253]     Train net output #0: loss = 0.92684 (* 1 = 0.92684 loss)
I0525 22:31:55.522773 22368 sgd_solver.cpp:106] Iteration 58650, lr = 0.004
I0525 22:32:04.271709 22368 solver.cpp:237] Iteration 58800, loss = 1.45847
I0525 22:32:04.271900 22368 solver.cpp:253]     Train net output #0: loss = 1.45847 (* 1 = 1.45847 loss)
I0525 22:32:04.271917 22368 sgd_solver.cpp:106] Iteration 58800, lr = 0.004
I0525 22:32:13.025846 22368 solver.cpp:237] Iteration 58950, loss = 1.29961
I0525 22:32:13.025883 22368 solver.cpp:253]     Train net output #0: loss = 1.29961 (* 1 = 1.29961 loss)
I0525 22:32:13.025912 22368 sgd_solver.cpp:106] Iteration 58950, lr = 0.004
I0525 22:32:42.620245 22368 solver.cpp:237] Iteration 59100, loss = 1.14927
I0525 22:32:42.620445 22368 solver.cpp:253]     Train net output #0: loss = 1.14927 (* 1 = 1.14927 loss)
I0525 22:32:42.620465 22368 sgd_solver.cpp:106] Iteration 59100, lr = 0.004
I0525 22:32:51.357620 22368 solver.cpp:237] Iteration 59250, loss = 1.16456
I0525 22:32:51.357656 22368 solver.cpp:253]     Train net output #0: loss = 1.16456 (* 1 = 1.16456 loss)
I0525 22:32:51.357676 22368 sgd_solver.cpp:106] Iteration 59250, lr = 0.004
I0525 22:33:00.090639 22368 solver.cpp:237] Iteration 59400, loss = 0.905009
I0525 22:33:00.090677 22368 solver.cpp:253]     Train net output #0: loss = 0.905009 (* 1 = 0.905009 loss)
I0525 22:33:00.090698 22368 sgd_solver.cpp:106] Iteration 59400, lr = 0.004
I0525 22:33:08.830435 22368 solver.cpp:237] Iteration 59550, loss = 1.08685
I0525 22:33:08.830489 22368 solver.cpp:253]     Train net output #0: loss = 1.08685 (* 1 = 1.08685 loss)
I0525 22:33:08.830519 22368 sgd_solver.cpp:106] Iteration 59550, lr = 0.004
I0525 22:33:17.565922 22368 solver.cpp:237] Iteration 59700, loss = 1.18836
I0525 22:33:17.566099 22368 solver.cpp:253]     Train net output #0: loss = 1.18836 (* 1 = 1.18836 loss)
I0525 22:33:17.566115 22368 sgd_solver.cpp:106] Iteration 59700, lr = 0.004
I0525 22:33:26.306133 22368 solver.cpp:237] Iteration 59850, loss = 0.996762
I0525 22:33:26.306170 22368 solver.cpp:253]     Train net output #0: loss = 0.996762 (* 1 = 0.996762 loss)
I0525 22:33:26.306197 22368 sgd_solver.cpp:106] Iteration 59850, lr = 0.004
I0525 22:33:34.981966 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_60000.caffemodel
I0525 22:33:35.062700 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_60000.solverstate
I0525 22:33:35.090426 22368 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 22:34:42.876873 22368 solver.cpp:409]     Test net output #0: accuracy = 0.892728
I0525 22:34:42.877079 22368 solver.cpp:409]     Test net output #1: loss = 0.34716 (* 1 = 0.34716 loss)
I0525 22:35:03.796398 22368 solver.cpp:237] Iteration 60000, loss = 1.25743
I0525 22:35:03.796455 22368 solver.cpp:253]     Train net output #0: loss = 1.25743 (* 1 = 1.25743 loss)
I0525 22:35:03.796474 22368 sgd_solver.cpp:106] Iteration 60000, lr = 0.004
I0525 22:35:12.521245 22368 solver.cpp:237] Iteration 60150, loss = 1.09672
I0525 22:35:12.521296 22368 solver.cpp:253]     Train net output #0: loss = 1.09672 (* 1 = 1.09672 loss)
I0525 22:35:12.521313 22368 sgd_solver.cpp:106] Iteration 60150, lr = 0.004
I0525 22:35:21.249004 22368 solver.cpp:237] Iteration 60300, loss = 1.30149
I0525 22:35:21.249186 22368 solver.cpp:253]     Train net output #0: loss = 1.30149 (* 1 = 1.30149 loss)
I0525 22:35:21.249204 22368 sgd_solver.cpp:106] Iteration 60300, lr = 0.004
I0525 22:35:29.971408 22368 solver.cpp:237] Iteration 60450, loss = 1.11624
I0525 22:35:29.971449 22368 solver.cpp:253]     Train net output #0: loss = 1.11624 (* 1 = 1.11624 loss)
I0525 22:35:29.971475 22368 sgd_solver.cpp:106] Iteration 60450, lr = 0.004
I0525 22:35:38.691814 22368 solver.cpp:237] Iteration 60600, loss = 1.13492
I0525 22:35:38.691862 22368 solver.cpp:253]     Train net output #0: loss = 1.13492 (* 1 = 1.13492 loss)
I0525 22:35:38.691892 22368 sgd_solver.cpp:106] Iteration 60600, lr = 0.004
I0525 22:35:47.415976 22368 solver.cpp:237] Iteration 60750, loss = 0.905389
I0525 22:35:47.416013 22368 solver.cpp:253]     Train net output #0: loss = 0.905389 (* 1 = 0.905389 loss)
I0525 22:35:47.416038 22368 sgd_solver.cpp:106] Iteration 60750, lr = 0.004
I0525 22:35:56.139665 22368 solver.cpp:237] Iteration 60900, loss = 1.3626
I0525 22:35:56.139853 22368 solver.cpp:253]     Train net output #0: loss = 1.3626 (* 1 = 1.3626 loss)
I0525 22:35:56.139868 22368 sgd_solver.cpp:106] Iteration 60900, lr = 0.004
I0525 22:36:25.782961 22368 solver.cpp:237] Iteration 61050, loss = 1.09521
I0525 22:36:25.783017 22368 solver.cpp:253]     Train net output #0: loss = 1.09521 (* 1 = 1.09521 loss)
I0525 22:36:25.783043 22368 sgd_solver.cpp:106] Iteration 61050, lr = 0.004
I0525 22:36:34.507598 22368 solver.cpp:237] Iteration 61200, loss = 1.06734
I0525 22:36:34.507786 22368 solver.cpp:253]     Train net output #0: loss = 1.06734 (* 1 = 1.06734 loss)
I0525 22:36:34.507810 22368 sgd_solver.cpp:106] Iteration 61200, lr = 0.004
I0525 22:36:43.226748 22368 solver.cpp:237] Iteration 61350, loss = 1.45917
I0525 22:36:43.226788 22368 solver.cpp:253]     Train net output #0: loss = 1.45917 (* 1 = 1.45917 loss)
I0525 22:36:43.226814 22368 sgd_solver.cpp:106] Iteration 61350, lr = 0.004
I0525 22:36:51.891468 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_61500.caffemodel
I0525 22:36:51.970289 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_61500.solverstate
I0525 22:36:52.014744 22368 solver.cpp:237] Iteration 61500, loss = 1.26047
I0525 22:36:52.014796 22368 solver.cpp:253]     Train net output #0: loss = 1.26047 (* 1 = 1.26047 loss)
I0525 22:36:52.014813 22368 sgd_solver.cpp:106] Iteration 61500, lr = 0.004
I0525 22:37:00.734899 22368 solver.cpp:237] Iteration 61650, loss = 1.02112
I0525 22:37:00.734937 22368 solver.cpp:253]     Train net output #0: loss = 1.02112 (* 1 = 1.02112 loss)
I0525 22:37:00.734966 22368 sgd_solver.cpp:106] Iteration 61650, lr = 0.004
I0525 22:37:09.454632 22368 solver.cpp:237] Iteration 61800, loss = 0.972478
I0525 22:37:09.454815 22368 solver.cpp:253]     Train net output #0: loss = 0.972478 (* 1 = 0.972478 loss)
I0525 22:37:09.454833 22368 sgd_solver.cpp:106] Iteration 61800, lr = 0.004
I0525 22:37:18.177942 22368 solver.cpp:237] Iteration 61950, loss = 1.36454
I0525 22:37:18.177996 22368 solver.cpp:253]     Train net output #0: loss = 1.36454 (* 1 = 1.36454 loss)
I0525 22:37:18.178027 22368 sgd_solver.cpp:106] Iteration 61950, lr = 0.004
I0525 22:37:47.747593 22368 solver.cpp:237] Iteration 62100, loss = 1.2597
I0525 22:37:47.747803 22368 solver.cpp:253]     Train net output #0: loss = 1.2597 (* 1 = 1.2597 loss)
I0525 22:37:47.747824 22368 sgd_solver.cpp:106] Iteration 62100, lr = 0.004
I0525 22:37:56.474370 22368 solver.cpp:237] Iteration 62250, loss = 1.10445
I0525 22:37:56.474406 22368 solver.cpp:253]     Train net output #0: loss = 1.10445 (* 1 = 1.10445 loss)
I0525 22:37:56.474433 22368 sgd_solver.cpp:106] Iteration 62250, lr = 0.004
I0525 22:38:05.200054 22368 solver.cpp:237] Iteration 62400, loss = 1.29113
I0525 22:38:05.200091 22368 solver.cpp:253]     Train net output #0: loss = 1.29113 (* 1 = 1.29113 loss)
I0525 22:38:05.200119 22368 sgd_solver.cpp:106] Iteration 62400, lr = 0.004
I0525 22:38:13.920755 22368 solver.cpp:237] Iteration 62550, loss = 1.13165
I0525 22:38:13.920806 22368 solver.cpp:253]     Train net output #0: loss = 1.13165 (* 1 = 1.13165 loss)
I0525 22:38:13.920835 22368 sgd_solver.cpp:106] Iteration 62550, lr = 0.004
I0525 22:38:22.643703 22368 solver.cpp:237] Iteration 62700, loss = 0.976675
I0525 22:38:22.643903 22368 solver.cpp:253]     Train net output #0: loss = 0.976675 (* 1 = 0.976675 loss)
I0525 22:38:22.643921 22368 sgd_solver.cpp:106] Iteration 62700, lr = 0.004
I0525 22:38:31.367121 22368 solver.cpp:237] Iteration 62850, loss = 1.26694
I0525 22:38:31.367173 22368 solver.cpp:253]     Train net output #0: loss = 1.26694 (* 1 = 1.26694 loss)
I0525 22:38:31.367192 22368 sgd_solver.cpp:106] Iteration 62850, lr = 0.004
I0525 22:38:40.028990 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_63000.caffemodel
I0525 22:38:40.106937 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_63000.solverstate
I0525 22:38:40.131973 22368 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 22:39:27.023660 22368 solver.cpp:409]     Test net output #0: accuracy = 0.893802
I0525 22:39:27.023860 22368 solver.cpp:409]     Test net output #1: loss = 0.327798 (* 1 = 0.327798 loss)
I0525 22:39:47.898254 22368 solver.cpp:237] Iteration 63000, loss = 1.15441
I0525 22:39:47.898316 22368 solver.cpp:253]     Train net output #0: loss = 1.15441 (* 1 = 1.15441 loss)
I0525 22:39:47.898334 22368 sgd_solver.cpp:106] Iteration 63000, lr = 0.004
I0525 22:39:56.637311 22368 solver.cpp:237] Iteration 63150, loss = 0.956762
I0525 22:39:56.637351 22368 solver.cpp:253]     Train net output #0: loss = 0.956762 (* 1 = 0.956762 loss)
I0525 22:39:56.637377 22368 sgd_solver.cpp:106] Iteration 63150, lr = 0.004
I0525 22:40:05.374209 22368 solver.cpp:237] Iteration 63300, loss = 1.22573
I0525 22:40:05.374394 22368 solver.cpp:253]     Train net output #0: loss = 1.22573 (* 1 = 1.22573 loss)
I0525 22:40:05.374411 22368 sgd_solver.cpp:106] Iteration 63300, lr = 0.004
I0525 22:40:14.117180 22368 solver.cpp:237] Iteration 63450, loss = 1.09014
I0525 22:40:14.117233 22368 solver.cpp:253]     Train net output #0: loss = 1.09014 (* 1 = 1.09014 loss)
I0525 22:40:14.117249 22368 sgd_solver.cpp:106] Iteration 63450, lr = 0.004
I0525 22:40:22.859803 22368 solver.cpp:237] Iteration 63600, loss = 1.14782
I0525 22:40:22.859840 22368 solver.cpp:253]     Train net output #0: loss = 1.14782 (* 1 = 1.14782 loss)
I0525 22:40:22.859868 22368 sgd_solver.cpp:106] Iteration 63600, lr = 0.004
I0525 22:40:31.599364 22368 solver.cpp:237] Iteration 63750, loss = 1.58286
I0525 22:40:31.599402 22368 solver.cpp:253]     Train net output #0: loss = 1.58286 (* 1 = 1.58286 loss)
I0525 22:40:31.599428 22368 sgd_solver.cpp:106] Iteration 63750, lr = 0.004
I0525 22:40:40.338996 22368 solver.cpp:237] Iteration 63900, loss = 1.13204
I0525 22:40:40.339191 22368 solver.cpp:253]     Train net output #0: loss = 1.13204 (* 1 = 1.13204 loss)
I0525 22:40:40.339211 22368 sgd_solver.cpp:106] Iteration 63900, lr = 0.004
I0525 22:41:09.924371 22368 solver.cpp:237] Iteration 64050, loss = 1.28333
I0525 22:41:09.924427 22368 solver.cpp:253]     Train net output #0: loss = 1.28333 (* 1 = 1.28333 loss)
I0525 22:41:09.924444 22368 sgd_solver.cpp:106] Iteration 64050, lr = 0.004
I0525 22:41:18.659113 22368 solver.cpp:237] Iteration 64200, loss = 1.03823
I0525 22:41:18.659296 22368 solver.cpp:253]     Train net output #0: loss = 1.03823 (* 1 = 1.03823 loss)
I0525 22:41:18.659313 22368 sgd_solver.cpp:106] Iteration 64200, lr = 0.004
I0525 22:41:27.394995 22368 solver.cpp:237] Iteration 64350, loss = 1.2005
I0525 22:41:27.395050 22368 solver.cpp:253]     Train net output #0: loss = 1.2005 (* 1 = 1.2005 loss)
I0525 22:41:27.395079 22368 sgd_solver.cpp:106] Iteration 64350, lr = 0.004
I0525 22:41:36.081871 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_64500.caffemodel
I0525 22:41:36.159785 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_64500.solverstate
I0525 22:41:36.205960 22368 solver.cpp:237] Iteration 64500, loss = 1.22073
I0525 22:41:36.206019 22368 solver.cpp:253]     Train net output #0: loss = 1.22073 (* 1 = 1.22073 loss)
I0525 22:41:36.206037 22368 sgd_solver.cpp:106] Iteration 64500, lr = 0.004
I0525 22:41:44.947666 22368 solver.cpp:237] Iteration 64650, loss = 1.18933
I0525 22:41:44.947703 22368 solver.cpp:253]     Train net output #0: loss = 1.18933 (* 1 = 1.18933 loss)
I0525 22:41:44.947723 22368 sgd_solver.cpp:106] Iteration 64650, lr = 0.004
I0525 22:41:53.688185 22368 solver.cpp:237] Iteration 64800, loss = 1.06964
I0525 22:41:53.688390 22368 solver.cpp:253]     Train net output #0: loss = 1.06964 (* 1 = 1.06964 loss)
I0525 22:41:53.688416 22368 sgd_solver.cpp:106] Iteration 64800, lr = 0.004
I0525 22:42:02.426096 22368 solver.cpp:237] Iteration 64950, loss = 1.28637
I0525 22:42:02.426133 22368 solver.cpp:253]     Train net output #0: loss = 1.28637 (* 1 = 1.28637 loss)
I0525 22:42:02.426161 22368 sgd_solver.cpp:106] Iteration 64950, lr = 0.004
I0525 22:42:32.020931 22368 solver.cpp:237] Iteration 65100, loss = 0.940479
I0525 22:42:32.021131 22368 solver.cpp:253]     Train net output #0: loss = 0.940479 (* 1 = 0.940479 loss)
I0525 22:42:32.021150 22368 sgd_solver.cpp:106] Iteration 65100, lr = 0.004
I0525 22:42:40.756572 22368 solver.cpp:237] Iteration 65250, loss = 1.14274
I0525 22:42:40.756608 22368 solver.cpp:253]     Train net output #0: loss = 1.14274 (* 1 = 1.14274 loss)
I0525 22:42:40.756628 22368 sgd_solver.cpp:106] Iteration 65250, lr = 0.004
I0525 22:42:49.495520 22368 solver.cpp:237] Iteration 65400, loss = 1.04919
I0525 22:42:49.495563 22368 solver.cpp:253]     Train net output #0: loss = 1.04919 (* 1 = 1.04919 loss)
I0525 22:42:49.495580 22368 sgd_solver.cpp:106] Iteration 65400, lr = 0.004
I0525 22:42:58.237398 22368 solver.cpp:237] Iteration 65550, loss = 1.12346
I0525 22:42:58.237434 22368 solver.cpp:253]     Train net output #0: loss = 1.12346 (* 1 = 1.12346 loss)
I0525 22:42:58.237455 22368 sgd_solver.cpp:106] Iteration 65550, lr = 0.004
I0525 22:43:06.974453 22368 solver.cpp:237] Iteration 65700, loss = 1.12842
I0525 22:43:06.974652 22368 solver.cpp:253]     Train net output #0: loss = 1.12842 (* 1 = 1.12842 loss)
I0525 22:43:06.974673 22368 sgd_solver.cpp:106] Iteration 65700, lr = 0.004
I0525 22:43:15.716862 22368 solver.cpp:237] Iteration 65850, loss = 1.06214
I0525 22:43:15.716900 22368 solver.cpp:253]     Train net output #0: loss = 1.06214 (* 1 = 1.06214 loss)
I0525 22:43:15.716917 22368 sgd_solver.cpp:106] Iteration 65850, lr = 0.004
I0525 22:43:24.400540 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_66000.caffemodel
I0525 22:43:24.480340 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_66000.solverstate
I0525 22:43:24.507279 22368 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 22:44:32.282512 22368 solver.cpp:409]     Test net output #0: accuracy = 0.892896
I0525 22:44:32.282711 22368 solver.cpp:409]     Test net output #1: loss = 0.354532 (* 1 = 0.354532 loss)
I0525 22:44:53.163276 22368 solver.cpp:237] Iteration 66000, loss = 1.0664
I0525 22:44:53.163339 22368 solver.cpp:253]     Train net output #0: loss = 1.0664 (* 1 = 1.0664 loss)
I0525 22:44:53.163359 22368 sgd_solver.cpp:106] Iteration 66000, lr = 0.004
I0525 22:45:01.902078 22368 solver.cpp:237] Iteration 66150, loss = 1.09147
I0525 22:45:01.902117 22368 solver.cpp:253]     Train net output #0: loss = 1.09147 (* 1 = 1.09147 loss)
I0525 22:45:01.902137 22368 sgd_solver.cpp:106] Iteration 66150, lr = 0.004
I0525 22:45:10.643864 22368 solver.cpp:237] Iteration 66300, loss = 1.08095
I0525 22:45:10.644062 22368 solver.cpp:253]     Train net output #0: loss = 1.08095 (* 1 = 1.08095 loss)
I0525 22:45:10.644078 22368 sgd_solver.cpp:106] Iteration 66300, lr = 0.004
I0525 22:45:19.385196 22368 solver.cpp:237] Iteration 66450, loss = 0.91671
I0525 22:45:19.385249 22368 solver.cpp:253]     Train net output #0: loss = 0.91671 (* 1 = 0.91671 loss)
I0525 22:45:19.385270 22368 sgd_solver.cpp:106] Iteration 66450, lr = 0.004
I0525 22:45:28.124672 22368 solver.cpp:237] Iteration 66600, loss = 1.17359
I0525 22:45:28.124714 22368 solver.cpp:253]     Train net output #0: loss = 1.17359 (* 1 = 1.17359 loss)
I0525 22:45:28.124734 22368 sgd_solver.cpp:106] Iteration 66600, lr = 0.004
I0525 22:45:36.866801 22368 solver.cpp:237] Iteration 66750, loss = 1.21613
I0525 22:45:36.866857 22368 solver.cpp:253]     Train net output #0: loss = 1.21613 (* 1 = 1.21613 loss)
I0525 22:45:36.866883 22368 sgd_solver.cpp:106] Iteration 66750, lr = 0.004
I0525 22:45:45.605983 22368 solver.cpp:237] Iteration 66900, loss = 1.01957
I0525 22:45:45.606169 22368 solver.cpp:253]     Train net output #0: loss = 1.01957 (* 1 = 1.01957 loss)
I0525 22:45:45.606185 22368 sgd_solver.cpp:106] Iteration 66900, lr = 0.004
I0525 22:46:15.244184 22368 solver.cpp:237] Iteration 67050, loss = 1.16505
I0525 22:46:15.244240 22368 solver.cpp:253]     Train net output #0: loss = 1.16505 (* 1 = 1.16505 loss)
I0525 22:46:15.244257 22368 sgd_solver.cpp:106] Iteration 67050, lr = 0.004
I0525 22:46:23.983070 22368 solver.cpp:237] Iteration 67200, loss = 1.12537
I0525 22:46:23.983260 22368 solver.cpp:253]     Train net output #0: loss = 1.12537 (* 1 = 1.12537 loss)
I0525 22:46:23.983278 22368 sgd_solver.cpp:106] Iteration 67200, lr = 0.004
I0525 22:46:32.723501 22368 solver.cpp:237] Iteration 67350, loss = 1.12707
I0525 22:46:32.723552 22368 solver.cpp:253]     Train net output #0: loss = 1.12707 (* 1 = 1.12707 loss)
I0525 22:46:32.723569 22368 sgd_solver.cpp:106] Iteration 67350, lr = 0.004
I0525 22:46:41.405119 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_67500.caffemodel
I0525 22:46:41.485718 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_67500.solverstate
I0525 22:46:41.531363 22368 solver.cpp:237] Iteration 67500, loss = 1.02816
I0525 22:46:41.531419 22368 solver.cpp:253]     Train net output #0: loss = 1.02816 (* 1 = 1.02816 loss)
I0525 22:46:41.531435 22368 sgd_solver.cpp:106] Iteration 67500, lr = 0.004
I0525 22:46:50.270021 22368 solver.cpp:237] Iteration 67650, loss = 1.15125
I0525 22:46:50.270058 22368 solver.cpp:253]     Train net output #0: loss = 1.15125 (* 1 = 1.15125 loss)
I0525 22:46:50.270087 22368 sgd_solver.cpp:106] Iteration 67650, lr = 0.004
I0525 22:46:59.009487 22368 solver.cpp:237] Iteration 67800, loss = 1.02683
I0525 22:46:59.009690 22368 solver.cpp:253]     Train net output #0: loss = 1.02683 (* 1 = 1.02683 loss)
I0525 22:46:59.009708 22368 sgd_solver.cpp:106] Iteration 67800, lr = 0.004
I0525 22:47:07.751271 22368 solver.cpp:237] Iteration 67950, loss = 1.06893
I0525 22:47:07.751309 22368 solver.cpp:253]     Train net output #0: loss = 1.06893 (* 1 = 1.06893 loss)
I0525 22:47:07.751337 22368 sgd_solver.cpp:106] Iteration 67950, lr = 0.004
I0525 22:47:37.352021 22368 solver.cpp:237] Iteration 68100, loss = 1.10307
I0525 22:47:37.352224 22368 solver.cpp:253]     Train net output #0: loss = 1.10307 (* 1 = 1.10307 loss)
I0525 22:47:37.352241 22368 sgd_solver.cpp:106] Iteration 68100, lr = 0.004
I0525 22:47:46.091291 22368 solver.cpp:237] Iteration 68250, loss = 1.25319
I0525 22:47:46.091342 22368 solver.cpp:253]     Train net output #0: loss = 1.25319 (* 1 = 1.25319 loss)
I0525 22:47:46.091361 22368 sgd_solver.cpp:106] Iteration 68250, lr = 0.004
I0525 22:47:54.831809 22368 solver.cpp:237] Iteration 68400, loss = 1.0872
I0525 22:47:54.831847 22368 solver.cpp:253]     Train net output #0: loss = 1.0872 (* 1 = 1.0872 loss)
I0525 22:47:54.831876 22368 sgd_solver.cpp:106] Iteration 68400, lr = 0.004
I0525 22:48:03.567641 22368 solver.cpp:237] Iteration 68550, loss = 1.37704
I0525 22:48:03.567678 22368 solver.cpp:253]     Train net output #0: loss = 1.37704 (* 1 = 1.37704 loss)
I0525 22:48:03.567706 22368 sgd_solver.cpp:106] Iteration 68550, lr = 0.004
I0525 22:48:12.308951 22368 solver.cpp:237] Iteration 68700, loss = 1.00796
I0525 22:48:12.309161 22368 solver.cpp:253]     Train net output #0: loss = 1.00796 (* 1 = 1.00796 loss)
I0525 22:48:12.309181 22368 sgd_solver.cpp:106] Iteration 68700, lr = 0.004
I0525 22:48:21.050557 22368 solver.cpp:237] Iteration 68850, loss = 1.11427
I0525 22:48:21.050595 22368 solver.cpp:253]     Train net output #0: loss = 1.11427 (* 1 = 1.11427 loss)
I0525 22:48:21.050622 22368 sgd_solver.cpp:106] Iteration 68850, lr = 0.004
I0525 22:48:29.736865 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_69000.caffemodel
I0525 22:48:29.815062 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_69000.solverstate
I0525 22:48:29.840121 22368 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 22:49:16.404712 22368 solver.cpp:409]     Test net output #0: accuracy = 0.893223
I0525 22:49:16.404913 22368 solver.cpp:409]     Test net output #1: loss = 0.323416 (* 1 = 0.323416 loss)
I0525 22:49:37.286618 22368 solver.cpp:237] Iteration 69000, loss = 0.983092
I0525 22:49:37.286679 22368 solver.cpp:253]     Train net output #0: loss = 0.983092 (* 1 = 0.983092 loss)
I0525 22:49:37.286701 22368 sgd_solver.cpp:106] Iteration 69000, lr = 0.004
I0525 22:49:46.022140 22368 solver.cpp:237] Iteration 69150, loss = 0.945455
I0525 22:49:46.022194 22368 solver.cpp:253]     Train net output #0: loss = 0.945455 (* 1 = 0.945455 loss)
I0525 22:49:46.022212 22368 sgd_solver.cpp:106] Iteration 69150, lr = 0.004
I0525 22:49:54.747573 22368 solver.cpp:237] Iteration 69300, loss = 1.31535
I0525 22:49:54.747762 22368 solver.cpp:253]     Train net output #0: loss = 1.31535 (* 1 = 1.31535 loss)
I0525 22:49:54.747779 22368 sgd_solver.cpp:106] Iteration 69300, lr = 0.004
I0525 22:50:03.488391 22368 solver.cpp:237] Iteration 69450, loss = 1.07033
I0525 22:50:03.488432 22368 solver.cpp:253]     Train net output #0: loss = 1.07033 (* 1 = 1.07033 loss)
I0525 22:50:03.488452 22368 sgd_solver.cpp:106] Iteration 69450, lr = 0.004
I0525 22:50:12.223454 22368 solver.cpp:237] Iteration 69600, loss = 1.25302
I0525 22:50:12.223505 22368 solver.cpp:253]     Train net output #0: loss = 1.25302 (* 1 = 1.25302 loss)
I0525 22:50:12.223523 22368 sgd_solver.cpp:106] Iteration 69600, lr = 0.004
I0525 22:50:20.963073 22368 solver.cpp:237] Iteration 69750, loss = 1.36606
I0525 22:50:20.963110 22368 solver.cpp:253]     Train net output #0: loss = 1.36606 (* 1 = 1.36606 loss)
I0525 22:50:20.963138 22368 sgd_solver.cpp:106] Iteration 69750, lr = 0.004
I0525 22:50:29.702886 22368 solver.cpp:237] Iteration 69900, loss = 1.03345
I0525 22:50:29.703069 22368 solver.cpp:253]     Train net output #0: loss = 1.03345 (* 1 = 1.03345 loss)
I0525 22:50:29.703086 22368 sgd_solver.cpp:106] Iteration 69900, lr = 0.004
I0525 22:50:59.307437 22368 solver.cpp:237] Iteration 70050, loss = 1.10212
I0525 22:50:59.307495 22368 solver.cpp:253]     Train net output #0: loss = 1.10212 (* 1 = 1.10212 loss)
I0525 22:50:59.307514 22368 sgd_solver.cpp:106] Iteration 70050, lr = 0.004
I0525 22:51:08.044421 22368 solver.cpp:237] Iteration 70200, loss = 1.10073
I0525 22:51:08.044628 22368 solver.cpp:253]     Train net output #0: loss = 1.10073 (* 1 = 1.10073 loss)
I0525 22:51:08.044648 22368 sgd_solver.cpp:106] Iteration 70200, lr = 0.004
I0525 22:51:16.782932 22368 solver.cpp:237] Iteration 70350, loss = 1.18884
I0525 22:51:16.782968 22368 solver.cpp:253]     Train net output #0: loss = 1.18884 (* 1 = 1.18884 loss)
I0525 22:51:16.782995 22368 sgd_solver.cpp:106] Iteration 70350, lr = 0.004
I0525 22:51:25.458647 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_70500.caffemodel
I0525 22:51:25.537400 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_70500.solverstate
I0525 22:51:25.580622 22368 solver.cpp:237] Iteration 70500, loss = 1.21356
I0525 22:51:25.580677 22368 solver.cpp:253]     Train net output #0: loss = 1.21356 (* 1 = 1.21356 loss)
I0525 22:51:25.580695 22368 sgd_solver.cpp:106] Iteration 70500, lr = 0.004
I0525 22:51:34.333998 22368 solver.cpp:237] Iteration 70650, loss = 1.31434
I0525 22:51:34.334053 22368 solver.cpp:253]     Train net output #0: loss = 1.31434 (* 1 = 1.31434 loss)
I0525 22:51:34.334079 22368 sgd_solver.cpp:106] Iteration 70650, lr = 0.004
I0525 22:51:43.086566 22368 solver.cpp:237] Iteration 70800, loss = 1.32404
I0525 22:51:43.086766 22368 solver.cpp:253]     Train net output #0: loss = 1.32404 (* 1 = 1.32404 loss)
I0525 22:51:43.086783 22368 sgd_solver.cpp:106] Iteration 70800, lr = 0.004
I0525 22:51:51.840800 22368 solver.cpp:237] Iteration 70950, loss = 1.11949
I0525 22:51:51.840853 22368 solver.cpp:253]     Train net output #0: loss = 1.11949 (* 1 = 1.11949 loss)
I0525 22:51:51.840872 22368 sgd_solver.cpp:106] Iteration 70950, lr = 0.004
I0525 22:52:21.444988 22368 solver.cpp:237] Iteration 71100, loss = 1.13909
I0525 22:52:21.445191 22368 solver.cpp:253]     Train net output #0: loss = 1.13909 (* 1 = 1.13909 loss)
I0525 22:52:21.445211 22368 sgd_solver.cpp:106] Iteration 71100, lr = 0.004
I0525 22:52:30.163487 22368 solver.cpp:237] Iteration 71250, loss = 1.1723
I0525 22:52:30.163524 22368 solver.cpp:253]     Train net output #0: loss = 1.1723 (* 1 = 1.1723 loss)
I0525 22:52:30.163544 22368 sgd_solver.cpp:106] Iteration 71250, lr = 0.004
I0525 22:52:38.887537 22368 solver.cpp:237] Iteration 71400, loss = 1.1539
I0525 22:52:38.887574 22368 solver.cpp:253]     Train net output #0: loss = 1.1539 (* 1 = 1.1539 loss)
I0525 22:52:38.887595 22368 sgd_solver.cpp:106] Iteration 71400, lr = 0.004
I0525 22:52:47.622017 22368 solver.cpp:237] Iteration 71550, loss = 1.52075
I0525 22:52:47.622069 22368 solver.cpp:253]     Train net output #0: loss = 1.52075 (* 1 = 1.52075 loss)
I0525 22:52:47.622098 22368 sgd_solver.cpp:106] Iteration 71550, lr = 0.004
I0525 22:52:56.362121 22368 solver.cpp:237] Iteration 71700, loss = 1.28172
I0525 22:52:56.362319 22368 solver.cpp:253]     Train net output #0: loss = 1.28172 (* 1 = 1.28172 loss)
I0525 22:52:56.362336 22368 sgd_solver.cpp:106] Iteration 71700, lr = 0.004
I0525 22:53:05.097371 22368 solver.cpp:237] Iteration 71850, loss = 1.28731
I0525 22:53:05.097409 22368 solver.cpp:253]     Train net output #0: loss = 1.28731 (* 1 = 1.28731 loss)
I0525 22:53:05.097435 22368 sgd_solver.cpp:106] Iteration 71850, lr = 0.004
I0525 22:53:13.775790 22368 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_72000.caffemodel
I0525 22:53:13.855060 22368 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0040_2016-05-20T15.49.26.605425_iter_72000.solverstate
I0525 22:53:13.880565 22368 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 22:54:21.642601 22368 solver.cpp:409]     Test net output #0: accuracy = 0.893815
I0525 22:54:21.642801 22368 solver.cpp:409]     Test net output #1: loss = 0.332105 (* 1 = 0.332105 loss)
I0525 22:54:42.508906 22368 solver.cpp:237] Iteration 72000, loss = 1.17478
I0525 22:54:42.508965 22368 solver.cpp:253]     Train net output #0: loss = 1.17478 (* 1 = 1.17478 loss)
I0525 22:54:42.508987 22368 sgd_solver.cpp:106] Iteration 72000, lr = 0.004
I0525 22:54:51.253428 22368 solver.cpp:237] Iteration 72150, loss = 1.17814
I0525 22:54:51.253482 22368 solver.cpp:253]     Train net output #0: loss = 1.17814 (* 1 = 1.17814 loss)
I0525 22:54:51.253510 22368 sgd_solver.cpp:106] Iteration 72150, lr = 0.004
I0525 22:54:59.998538 22368 solver.cpp:237] Iteration 72300, loss = 1.17463
I0525 22:54:59.998738 22368 solver.cpp:253]     Train net output #0: loss = 1.17463 (* 1 = 1.17463 loss)
I0525 22:54:59.998754 22368 sgd_solver.cpp:106] Iteration 72300, lr = 0.004
I0525 22:55:08.741076 22368 solver.cpp:237] Iteration 72450, loss = 1.25553
I0525 22:55:08.741114 22368 solver.cpp:253]     Train net output #0: loss = 1.25553 (* 1 = 1.25553 loss)
I0525 22:55:08.741139 22368 sgd_solver.cpp:106] Iteration 72450, lr = 0.004
I0525 22:55:17.487645 22368 solver.cpp:237] Iteration 72600, loss = 1.26148
I0525 22:55:17.487694 22368 solver.cpp:253]     Train net output #0: loss = 1.26148 (* 1 = 1.26148 loss)
I0525 22:55:17.487711 22368 sgd_solver.cpp:106] Iteration 72600, lr = 0.004
aprun: Apid 11265855: Caught signal Terminated, sending to application
*** Aborted at 1464231320 (unix time) try "date -d @1464231320" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11265855: Caught signal Terminated, sending to application
*** SIGTERM (@0x575d) received by PID 22368 (TID 0x2aaac746f900) from PID 22365; stack trace: ***
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
=>> PBS: job killed: walltime 7238 exceeded limit 7200
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11265855: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11265855: Caught signal Terminated, sending to application
aprun: Apid 11265855: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 00841] [c2-1c1s4n1] [Wed May 25 22:55:22 2016] PE RANK 0 exit signal Terminated
Application 11265855 exit codes: 143
Application 11265855 resources: utime ~6238s, stime ~983s, Rss ~5332468, inblocks ~16605764, outblocks ~740500
