2807195
I0522 05:46:02.365137 19460 caffe.cpp:184] Using GPUs 0
I0522 05:46:02.791999 19460 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.005
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305.prototxt"
I0522 05:46:02.794100 19460 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305.prototxt
I0522 05:46:02.810902 19460 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 05:46:02.810962 19460 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 05:46:02.811311 19460 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 05:46:02.811489 19460 layer_factory.hpp:77] Creating layer data_hdf5
I0522 05:46:02.811513 19460 net.cpp:106] Creating Layer data_hdf5
I0522 05:46:02.811528 19460 net.cpp:411] data_hdf5 -> data
I0522 05:46:02.811561 19460 net.cpp:411] data_hdf5 -> label
I0522 05:46:02.811594 19460 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 05:46:02.826170 19460 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 05:46:02.843523 19460 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 05:46:24.406764 19460 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 05:46:24.411957 19460 net.cpp:150] Setting up data_hdf5
I0522 05:46:24.411995 19460 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 05:46:24.412010 19460 net.cpp:157] Top shape: 20 (20)
I0522 05:46:24.412024 19460 net.cpp:165] Memory required for data: 508080
I0522 05:46:24.412036 19460 layer_factory.hpp:77] Creating layer conv1
I0522 05:46:24.412070 19460 net.cpp:106] Creating Layer conv1
I0522 05:46:24.412081 19460 net.cpp:454] conv1 <- data
I0522 05:46:24.412102 19460 net.cpp:411] conv1 -> conv1
I0522 05:46:27.832072 19460 net.cpp:150] Setting up conv1
I0522 05:46:27.832119 19460 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 05:46:27.832130 19460 net.cpp:165] Memory required for data: 6037680
I0522 05:46:27.832160 19460 layer_factory.hpp:77] Creating layer relu1
I0522 05:46:27.832182 19460 net.cpp:106] Creating Layer relu1
I0522 05:46:27.832193 19460 net.cpp:454] relu1 <- conv1
I0522 05:46:27.832206 19460 net.cpp:397] relu1 -> conv1 (in-place)
I0522 05:46:27.832725 19460 net.cpp:150] Setting up relu1
I0522 05:46:27.832741 19460 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 05:46:27.832752 19460 net.cpp:165] Memory required for data: 11567280
I0522 05:46:27.832763 19460 layer_factory.hpp:77] Creating layer pool1
I0522 05:46:27.832780 19460 net.cpp:106] Creating Layer pool1
I0522 05:46:27.832790 19460 net.cpp:454] pool1 <- conv1
I0522 05:46:27.832803 19460 net.cpp:411] pool1 -> pool1
I0522 05:46:27.832893 19460 net.cpp:150] Setting up pool1
I0522 05:46:27.832907 19460 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 05:46:27.832919 19460 net.cpp:165] Memory required for data: 14332080
I0522 05:46:27.832929 19460 layer_factory.hpp:77] Creating layer conv2
I0522 05:46:27.832952 19460 net.cpp:106] Creating Layer conv2
I0522 05:46:27.832962 19460 net.cpp:454] conv2 <- pool1
I0522 05:46:27.832975 19460 net.cpp:411] conv2 -> conv2
I0522 05:46:27.835661 19460 net.cpp:150] Setting up conv2
I0522 05:46:27.835690 19460 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 05:46:27.835700 19460 net.cpp:165] Memory required for data: 18306480
I0522 05:46:27.835719 19460 layer_factory.hpp:77] Creating layer relu2
I0522 05:46:27.835733 19460 net.cpp:106] Creating Layer relu2
I0522 05:46:27.835743 19460 net.cpp:454] relu2 <- conv2
I0522 05:46:27.835757 19460 net.cpp:397] relu2 -> conv2 (in-place)
I0522 05:46:27.836086 19460 net.cpp:150] Setting up relu2
I0522 05:46:27.836099 19460 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 05:46:27.836109 19460 net.cpp:165] Memory required for data: 22280880
I0522 05:46:27.836120 19460 layer_factory.hpp:77] Creating layer pool2
I0522 05:46:27.836133 19460 net.cpp:106] Creating Layer pool2
I0522 05:46:27.836143 19460 net.cpp:454] pool2 <- conv2
I0522 05:46:27.836154 19460 net.cpp:411] pool2 -> pool2
I0522 05:46:27.836236 19460 net.cpp:150] Setting up pool2
I0522 05:46:27.836249 19460 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 05:46:27.836259 19460 net.cpp:165] Memory required for data: 24268080
I0522 05:46:27.836269 19460 layer_factory.hpp:77] Creating layer conv3
I0522 05:46:27.836285 19460 net.cpp:106] Creating Layer conv3
I0522 05:46:27.836295 19460 net.cpp:454] conv3 <- pool2
I0522 05:46:27.836309 19460 net.cpp:411] conv3 -> conv3
I0522 05:46:27.838255 19460 net.cpp:150] Setting up conv3
I0522 05:46:27.838279 19460 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 05:46:27.838291 19460 net.cpp:165] Memory required for data: 26436400
I0522 05:46:27.838310 19460 layer_factory.hpp:77] Creating layer relu3
I0522 05:46:27.838326 19460 net.cpp:106] Creating Layer relu3
I0522 05:46:27.838336 19460 net.cpp:454] relu3 <- conv3
I0522 05:46:27.838349 19460 net.cpp:397] relu3 -> conv3 (in-place)
I0522 05:46:27.838819 19460 net.cpp:150] Setting up relu3
I0522 05:46:27.838836 19460 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 05:46:27.838846 19460 net.cpp:165] Memory required for data: 28604720
I0522 05:46:27.838856 19460 layer_factory.hpp:77] Creating layer pool3
I0522 05:46:27.838870 19460 net.cpp:106] Creating Layer pool3
I0522 05:46:27.838879 19460 net.cpp:454] pool3 <- conv3
I0522 05:46:27.838892 19460 net.cpp:411] pool3 -> pool3
I0522 05:46:27.838960 19460 net.cpp:150] Setting up pool3
I0522 05:46:27.838973 19460 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 05:46:27.838984 19460 net.cpp:165] Memory required for data: 29688880
I0522 05:46:27.838992 19460 layer_factory.hpp:77] Creating layer conv4
I0522 05:46:27.839009 19460 net.cpp:106] Creating Layer conv4
I0522 05:46:27.839018 19460 net.cpp:454] conv4 <- pool3
I0522 05:46:27.839032 19460 net.cpp:411] conv4 -> conv4
I0522 05:46:27.841743 19460 net.cpp:150] Setting up conv4
I0522 05:46:27.841771 19460 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 05:46:27.841784 19460 net.cpp:165] Memory required for data: 30414640
I0522 05:46:27.841800 19460 layer_factory.hpp:77] Creating layer relu4
I0522 05:46:27.841814 19460 net.cpp:106] Creating Layer relu4
I0522 05:46:27.841825 19460 net.cpp:454] relu4 <- conv4
I0522 05:46:27.841838 19460 net.cpp:397] relu4 -> conv4 (in-place)
I0522 05:46:27.842301 19460 net.cpp:150] Setting up relu4
I0522 05:46:27.842317 19460 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 05:46:27.842329 19460 net.cpp:165] Memory required for data: 31140400
I0522 05:46:27.842339 19460 layer_factory.hpp:77] Creating layer pool4
I0522 05:46:27.842351 19460 net.cpp:106] Creating Layer pool4
I0522 05:46:27.842361 19460 net.cpp:454] pool4 <- conv4
I0522 05:46:27.842373 19460 net.cpp:411] pool4 -> pool4
I0522 05:46:27.842442 19460 net.cpp:150] Setting up pool4
I0522 05:46:27.842455 19460 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 05:46:27.842466 19460 net.cpp:165] Memory required for data: 31503280
I0522 05:46:27.842476 19460 layer_factory.hpp:77] Creating layer ip1
I0522 05:46:27.842496 19460 net.cpp:106] Creating Layer ip1
I0522 05:46:27.842506 19460 net.cpp:454] ip1 <- pool4
I0522 05:46:27.842520 19460 net.cpp:411] ip1 -> ip1
I0522 05:46:27.857996 19460 net.cpp:150] Setting up ip1
I0522 05:46:27.858026 19460 net.cpp:157] Top shape: 20 196 (3920)
I0522 05:46:27.858039 19460 net.cpp:165] Memory required for data: 31518960
I0522 05:46:27.858062 19460 layer_factory.hpp:77] Creating layer relu5
I0522 05:46:27.858077 19460 net.cpp:106] Creating Layer relu5
I0522 05:46:27.858086 19460 net.cpp:454] relu5 <- ip1
I0522 05:46:27.858100 19460 net.cpp:397] relu5 -> ip1 (in-place)
I0522 05:46:27.858441 19460 net.cpp:150] Setting up relu5
I0522 05:46:27.858455 19460 net.cpp:157] Top shape: 20 196 (3920)
I0522 05:46:27.858465 19460 net.cpp:165] Memory required for data: 31534640
I0522 05:46:27.858476 19460 layer_factory.hpp:77] Creating layer drop1
I0522 05:46:27.858499 19460 net.cpp:106] Creating Layer drop1
I0522 05:46:27.858508 19460 net.cpp:454] drop1 <- ip1
I0522 05:46:27.858520 19460 net.cpp:397] drop1 -> ip1 (in-place)
I0522 05:46:27.858580 19460 net.cpp:150] Setting up drop1
I0522 05:46:27.858593 19460 net.cpp:157] Top shape: 20 196 (3920)
I0522 05:46:27.858603 19460 net.cpp:165] Memory required for data: 31550320
I0522 05:46:27.858613 19460 layer_factory.hpp:77] Creating layer ip2
I0522 05:46:27.858633 19460 net.cpp:106] Creating Layer ip2
I0522 05:46:27.858642 19460 net.cpp:454] ip2 <- ip1
I0522 05:46:27.858655 19460 net.cpp:411] ip2 -> ip2
I0522 05:46:27.859118 19460 net.cpp:150] Setting up ip2
I0522 05:46:27.859132 19460 net.cpp:157] Top shape: 20 98 (1960)
I0522 05:46:27.859141 19460 net.cpp:165] Memory required for data: 31558160
I0522 05:46:27.859156 19460 layer_factory.hpp:77] Creating layer relu6
I0522 05:46:27.859169 19460 net.cpp:106] Creating Layer relu6
I0522 05:46:27.859179 19460 net.cpp:454] relu6 <- ip2
I0522 05:46:27.859190 19460 net.cpp:397] relu6 -> ip2 (in-place)
I0522 05:46:27.859705 19460 net.cpp:150] Setting up relu6
I0522 05:46:27.859721 19460 net.cpp:157] Top shape: 20 98 (1960)
I0522 05:46:27.859732 19460 net.cpp:165] Memory required for data: 31566000
I0522 05:46:27.859743 19460 layer_factory.hpp:77] Creating layer drop2
I0522 05:46:27.859756 19460 net.cpp:106] Creating Layer drop2
I0522 05:46:27.859766 19460 net.cpp:454] drop2 <- ip2
I0522 05:46:27.859779 19460 net.cpp:397] drop2 -> ip2 (in-place)
I0522 05:46:27.859822 19460 net.cpp:150] Setting up drop2
I0522 05:46:27.859835 19460 net.cpp:157] Top shape: 20 98 (1960)
I0522 05:46:27.859845 19460 net.cpp:165] Memory required for data: 31573840
I0522 05:46:27.859855 19460 layer_factory.hpp:77] Creating layer ip3
I0522 05:46:27.859869 19460 net.cpp:106] Creating Layer ip3
I0522 05:46:27.859879 19460 net.cpp:454] ip3 <- ip2
I0522 05:46:27.859891 19460 net.cpp:411] ip3 -> ip3
I0522 05:46:27.860102 19460 net.cpp:150] Setting up ip3
I0522 05:46:27.860116 19460 net.cpp:157] Top shape: 20 11 (220)
I0522 05:46:27.860126 19460 net.cpp:165] Memory required for data: 31574720
I0522 05:46:27.860141 19460 layer_factory.hpp:77] Creating layer drop3
I0522 05:46:27.860153 19460 net.cpp:106] Creating Layer drop3
I0522 05:46:27.860163 19460 net.cpp:454] drop3 <- ip3
I0522 05:46:27.860175 19460 net.cpp:397] drop3 -> ip3 (in-place)
I0522 05:46:27.860215 19460 net.cpp:150] Setting up drop3
I0522 05:46:27.860229 19460 net.cpp:157] Top shape: 20 11 (220)
I0522 05:46:27.860237 19460 net.cpp:165] Memory required for data: 31575600
I0522 05:46:27.860247 19460 layer_factory.hpp:77] Creating layer loss
I0522 05:46:27.860267 19460 net.cpp:106] Creating Layer loss
I0522 05:46:27.860276 19460 net.cpp:454] loss <- ip3
I0522 05:46:27.860287 19460 net.cpp:454] loss <- label
I0522 05:46:27.860301 19460 net.cpp:411] loss -> loss
I0522 05:46:27.860318 19460 layer_factory.hpp:77] Creating layer loss
I0522 05:46:27.860965 19460 net.cpp:150] Setting up loss
I0522 05:46:27.860985 19460 net.cpp:157] Top shape: (1)
I0522 05:46:27.860999 19460 net.cpp:160]     with loss weight 1
I0522 05:46:27.861040 19460 net.cpp:165] Memory required for data: 31575604
I0522 05:46:27.861052 19460 net.cpp:226] loss needs backward computation.
I0522 05:46:27.861063 19460 net.cpp:226] drop3 needs backward computation.
I0522 05:46:27.861073 19460 net.cpp:226] ip3 needs backward computation.
I0522 05:46:27.861080 19460 net.cpp:226] drop2 needs backward computation.
I0522 05:46:27.861090 19460 net.cpp:226] relu6 needs backward computation.
I0522 05:46:27.861099 19460 net.cpp:226] ip2 needs backward computation.
I0522 05:46:27.861110 19460 net.cpp:226] drop1 needs backward computation.
I0522 05:46:27.861120 19460 net.cpp:226] relu5 needs backward computation.
I0522 05:46:27.861129 19460 net.cpp:226] ip1 needs backward computation.
I0522 05:46:27.861140 19460 net.cpp:226] pool4 needs backward computation.
I0522 05:46:27.861150 19460 net.cpp:226] relu4 needs backward computation.
I0522 05:46:27.861160 19460 net.cpp:226] conv4 needs backward computation.
I0522 05:46:27.861171 19460 net.cpp:226] pool3 needs backward computation.
I0522 05:46:27.861181 19460 net.cpp:226] relu3 needs backward computation.
I0522 05:46:27.861191 19460 net.cpp:226] conv3 needs backward computation.
I0522 05:46:27.861210 19460 net.cpp:226] pool2 needs backward computation.
I0522 05:46:27.861222 19460 net.cpp:226] relu2 needs backward computation.
I0522 05:46:27.861232 19460 net.cpp:226] conv2 needs backward computation.
I0522 05:46:27.861243 19460 net.cpp:226] pool1 needs backward computation.
I0522 05:46:27.861254 19460 net.cpp:226] relu1 needs backward computation.
I0522 05:46:27.861264 19460 net.cpp:226] conv1 needs backward computation.
I0522 05:46:27.861275 19460 net.cpp:228] data_hdf5 does not need backward computation.
I0522 05:46:27.861285 19460 net.cpp:270] This network produces output loss
I0522 05:46:27.861309 19460 net.cpp:283] Network initialization done.
I0522 05:46:27.863140 19460 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305.prototxt
I0522 05:46:27.863211 19460 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 05:46:27.863567 19460 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 05:46:27.863757 19460 layer_factory.hpp:77] Creating layer data_hdf5
I0522 05:46:27.863773 19460 net.cpp:106] Creating Layer data_hdf5
I0522 05:46:27.863785 19460 net.cpp:411] data_hdf5 -> data
I0522 05:46:27.863801 19460 net.cpp:411] data_hdf5 -> label
I0522 05:46:27.863817 19460 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 05:46:27.872771 19460 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 05:46:49.232136 19460 net.cpp:150] Setting up data_hdf5
I0522 05:46:49.232303 19460 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 05:46:49.232317 19460 net.cpp:157] Top shape: 20 (20)
I0522 05:46:49.232331 19460 net.cpp:165] Memory required for data: 508080
I0522 05:46:49.232343 19460 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 05:46:49.232372 19460 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 05:46:49.232383 19460 net.cpp:454] label_data_hdf5_1_split <- label
I0522 05:46:49.232398 19460 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 05:46:49.232419 19460 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 05:46:49.232492 19460 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 05:46:49.232506 19460 net.cpp:157] Top shape: 20 (20)
I0522 05:46:49.232518 19460 net.cpp:157] Top shape: 20 (20)
I0522 05:46:49.232527 19460 net.cpp:165] Memory required for data: 508240
I0522 05:46:49.232537 19460 layer_factory.hpp:77] Creating layer conv1
I0522 05:46:49.232559 19460 net.cpp:106] Creating Layer conv1
I0522 05:46:49.232569 19460 net.cpp:454] conv1 <- data
I0522 05:46:49.232581 19460 net.cpp:411] conv1 -> conv1
I0522 05:46:49.234511 19460 net.cpp:150] Setting up conv1
I0522 05:46:49.234535 19460 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 05:46:49.234546 19460 net.cpp:165] Memory required for data: 6037840
I0522 05:46:49.234567 19460 layer_factory.hpp:77] Creating layer relu1
I0522 05:46:49.234582 19460 net.cpp:106] Creating Layer relu1
I0522 05:46:49.234592 19460 net.cpp:454] relu1 <- conv1
I0522 05:46:49.234606 19460 net.cpp:397] relu1 -> conv1 (in-place)
I0522 05:46:49.235105 19460 net.cpp:150] Setting up relu1
I0522 05:46:49.235121 19460 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 05:46:49.235131 19460 net.cpp:165] Memory required for data: 11567440
I0522 05:46:49.235141 19460 layer_factory.hpp:77] Creating layer pool1
I0522 05:46:49.235157 19460 net.cpp:106] Creating Layer pool1
I0522 05:46:49.235167 19460 net.cpp:454] pool1 <- conv1
I0522 05:46:49.235180 19460 net.cpp:411] pool1 -> pool1
I0522 05:46:49.235255 19460 net.cpp:150] Setting up pool1
I0522 05:46:49.235268 19460 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 05:46:49.235277 19460 net.cpp:165] Memory required for data: 14332240
I0522 05:46:49.235286 19460 layer_factory.hpp:77] Creating layer conv2
I0522 05:46:49.235304 19460 net.cpp:106] Creating Layer conv2
I0522 05:46:49.235314 19460 net.cpp:454] conv2 <- pool1
I0522 05:46:49.235328 19460 net.cpp:411] conv2 -> conv2
I0522 05:46:49.237248 19460 net.cpp:150] Setting up conv2
I0522 05:46:49.237270 19460 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 05:46:49.237283 19460 net.cpp:165] Memory required for data: 18306640
I0522 05:46:49.237300 19460 layer_factory.hpp:77] Creating layer relu2
I0522 05:46:49.237314 19460 net.cpp:106] Creating Layer relu2
I0522 05:46:49.237324 19460 net.cpp:454] relu2 <- conv2
I0522 05:46:49.237336 19460 net.cpp:397] relu2 -> conv2 (in-place)
I0522 05:46:49.237669 19460 net.cpp:150] Setting up relu2
I0522 05:46:49.237684 19460 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 05:46:49.237694 19460 net.cpp:165] Memory required for data: 22281040
I0522 05:46:49.237704 19460 layer_factory.hpp:77] Creating layer pool2
I0522 05:46:49.237716 19460 net.cpp:106] Creating Layer pool2
I0522 05:46:49.237726 19460 net.cpp:454] pool2 <- conv2
I0522 05:46:49.237738 19460 net.cpp:411] pool2 -> pool2
I0522 05:46:49.237810 19460 net.cpp:150] Setting up pool2
I0522 05:46:49.237823 19460 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 05:46:49.237833 19460 net.cpp:165] Memory required for data: 24268240
I0522 05:46:49.237843 19460 layer_factory.hpp:77] Creating layer conv3
I0522 05:46:49.237862 19460 net.cpp:106] Creating Layer conv3
I0522 05:46:49.237874 19460 net.cpp:454] conv3 <- pool2
I0522 05:46:49.237887 19460 net.cpp:411] conv3 -> conv3
I0522 05:46:49.239862 19460 net.cpp:150] Setting up conv3
I0522 05:46:49.239886 19460 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 05:46:49.239897 19460 net.cpp:165] Memory required for data: 26436560
I0522 05:46:49.239915 19460 layer_factory.hpp:77] Creating layer relu3
I0522 05:46:49.239940 19460 net.cpp:106] Creating Layer relu3
I0522 05:46:49.239950 19460 net.cpp:454] relu3 <- conv3
I0522 05:46:49.239964 19460 net.cpp:397] relu3 -> conv3 (in-place)
I0522 05:46:49.240437 19460 net.cpp:150] Setting up relu3
I0522 05:46:49.240453 19460 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 05:46:49.240464 19460 net.cpp:165] Memory required for data: 28604880
I0522 05:46:49.240474 19460 layer_factory.hpp:77] Creating layer pool3
I0522 05:46:49.240488 19460 net.cpp:106] Creating Layer pool3
I0522 05:46:49.240496 19460 net.cpp:454] pool3 <- conv3
I0522 05:46:49.240509 19460 net.cpp:411] pool3 -> pool3
I0522 05:46:49.240581 19460 net.cpp:150] Setting up pool3
I0522 05:46:49.240594 19460 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 05:46:49.240604 19460 net.cpp:165] Memory required for data: 29689040
I0522 05:46:49.240614 19460 layer_factory.hpp:77] Creating layer conv4
I0522 05:46:49.240630 19460 net.cpp:106] Creating Layer conv4
I0522 05:46:49.240640 19460 net.cpp:454] conv4 <- pool3
I0522 05:46:49.240655 19460 net.cpp:411] conv4 -> conv4
I0522 05:46:49.242720 19460 net.cpp:150] Setting up conv4
I0522 05:46:49.242743 19460 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 05:46:49.242751 19460 net.cpp:165] Memory required for data: 30414800
I0522 05:46:49.242766 19460 layer_factory.hpp:77] Creating layer relu4
I0522 05:46:49.242780 19460 net.cpp:106] Creating Layer relu4
I0522 05:46:49.242790 19460 net.cpp:454] relu4 <- conv4
I0522 05:46:49.242804 19460 net.cpp:397] relu4 -> conv4 (in-place)
I0522 05:46:49.243271 19460 net.cpp:150] Setting up relu4
I0522 05:46:49.243288 19460 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 05:46:49.243297 19460 net.cpp:165] Memory required for data: 31140560
I0522 05:46:49.243307 19460 layer_factory.hpp:77] Creating layer pool4
I0522 05:46:49.243320 19460 net.cpp:106] Creating Layer pool4
I0522 05:46:49.243330 19460 net.cpp:454] pool4 <- conv4
I0522 05:46:49.243345 19460 net.cpp:411] pool4 -> pool4
I0522 05:46:49.243417 19460 net.cpp:150] Setting up pool4
I0522 05:46:49.243430 19460 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 05:46:49.243440 19460 net.cpp:165] Memory required for data: 31503440
I0522 05:46:49.243450 19460 layer_factory.hpp:77] Creating layer ip1
I0522 05:46:49.243463 19460 net.cpp:106] Creating Layer ip1
I0522 05:46:49.243474 19460 net.cpp:454] ip1 <- pool4
I0522 05:46:49.243487 19460 net.cpp:411] ip1 -> ip1
I0522 05:46:49.258945 19460 net.cpp:150] Setting up ip1
I0522 05:46:49.258970 19460 net.cpp:157] Top shape: 20 196 (3920)
I0522 05:46:49.258980 19460 net.cpp:165] Memory required for data: 31519120
I0522 05:46:49.259002 19460 layer_factory.hpp:77] Creating layer relu5
I0522 05:46:49.259017 19460 net.cpp:106] Creating Layer relu5
I0522 05:46:49.259027 19460 net.cpp:454] relu5 <- ip1
I0522 05:46:49.259042 19460 net.cpp:397] relu5 -> ip1 (in-place)
I0522 05:46:49.259387 19460 net.cpp:150] Setting up relu5
I0522 05:46:49.259402 19460 net.cpp:157] Top shape: 20 196 (3920)
I0522 05:46:49.259412 19460 net.cpp:165] Memory required for data: 31534800
I0522 05:46:49.259421 19460 layer_factory.hpp:77] Creating layer drop1
I0522 05:46:49.259440 19460 net.cpp:106] Creating Layer drop1
I0522 05:46:49.259450 19460 net.cpp:454] drop1 <- ip1
I0522 05:46:49.259464 19460 net.cpp:397] drop1 -> ip1 (in-place)
I0522 05:46:49.259510 19460 net.cpp:150] Setting up drop1
I0522 05:46:49.259521 19460 net.cpp:157] Top shape: 20 196 (3920)
I0522 05:46:49.259533 19460 net.cpp:165] Memory required for data: 31550480
I0522 05:46:49.259542 19460 layer_factory.hpp:77] Creating layer ip2
I0522 05:46:49.259557 19460 net.cpp:106] Creating Layer ip2
I0522 05:46:49.259567 19460 net.cpp:454] ip2 <- ip1
I0522 05:46:49.259580 19460 net.cpp:411] ip2 -> ip2
I0522 05:46:49.260059 19460 net.cpp:150] Setting up ip2
I0522 05:46:49.260072 19460 net.cpp:157] Top shape: 20 98 (1960)
I0522 05:46:49.260083 19460 net.cpp:165] Memory required for data: 31558320
I0522 05:46:49.260098 19460 layer_factory.hpp:77] Creating layer relu6
I0522 05:46:49.260124 19460 net.cpp:106] Creating Layer relu6
I0522 05:46:49.260134 19460 net.cpp:454] relu6 <- ip2
I0522 05:46:49.260149 19460 net.cpp:397] relu6 -> ip2 (in-place)
I0522 05:46:49.260678 19460 net.cpp:150] Setting up relu6
I0522 05:46:49.260694 19460 net.cpp:157] Top shape: 20 98 (1960)
I0522 05:46:49.260704 19460 net.cpp:165] Memory required for data: 31566160
I0522 05:46:49.260715 19460 layer_factory.hpp:77] Creating layer drop2
I0522 05:46:49.260728 19460 net.cpp:106] Creating Layer drop2
I0522 05:46:49.260738 19460 net.cpp:454] drop2 <- ip2
I0522 05:46:49.260751 19460 net.cpp:397] drop2 -> ip2 (in-place)
I0522 05:46:49.260795 19460 net.cpp:150] Setting up drop2
I0522 05:46:49.260808 19460 net.cpp:157] Top shape: 20 98 (1960)
I0522 05:46:49.260818 19460 net.cpp:165] Memory required for data: 31574000
I0522 05:46:49.260828 19460 layer_factory.hpp:77] Creating layer ip3
I0522 05:46:49.260843 19460 net.cpp:106] Creating Layer ip3
I0522 05:46:49.260853 19460 net.cpp:454] ip3 <- ip2
I0522 05:46:49.260866 19460 net.cpp:411] ip3 -> ip3
I0522 05:46:49.261097 19460 net.cpp:150] Setting up ip3
I0522 05:46:49.261111 19460 net.cpp:157] Top shape: 20 11 (220)
I0522 05:46:49.261121 19460 net.cpp:165] Memory required for data: 31574880
I0522 05:46:49.261137 19460 layer_factory.hpp:77] Creating layer drop3
I0522 05:46:49.261149 19460 net.cpp:106] Creating Layer drop3
I0522 05:46:49.261158 19460 net.cpp:454] drop3 <- ip3
I0522 05:46:49.261171 19460 net.cpp:397] drop3 -> ip3 (in-place)
I0522 05:46:49.261212 19460 net.cpp:150] Setting up drop3
I0522 05:46:49.261225 19460 net.cpp:157] Top shape: 20 11 (220)
I0522 05:46:49.261235 19460 net.cpp:165] Memory required for data: 31575760
I0522 05:46:49.261245 19460 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 05:46:49.261257 19460 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 05:46:49.261267 19460 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 05:46:49.261281 19460 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 05:46:49.261296 19460 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 05:46:49.261369 19460 net.cpp:150] Setting up ip3_drop3_0_split
I0522 05:46:49.261381 19460 net.cpp:157] Top shape: 20 11 (220)
I0522 05:46:49.261394 19460 net.cpp:157] Top shape: 20 11 (220)
I0522 05:46:49.261404 19460 net.cpp:165] Memory required for data: 31577520
I0522 05:46:49.261415 19460 layer_factory.hpp:77] Creating layer accuracy
I0522 05:46:49.261437 19460 net.cpp:106] Creating Layer accuracy
I0522 05:46:49.261448 19460 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 05:46:49.261459 19460 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 05:46:49.261473 19460 net.cpp:411] accuracy -> accuracy
I0522 05:46:49.261497 19460 net.cpp:150] Setting up accuracy
I0522 05:46:49.261510 19460 net.cpp:157] Top shape: (1)
I0522 05:46:49.261520 19460 net.cpp:165] Memory required for data: 31577524
I0522 05:46:49.261529 19460 layer_factory.hpp:77] Creating layer loss
I0522 05:46:49.261543 19460 net.cpp:106] Creating Layer loss
I0522 05:46:49.261554 19460 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 05:46:49.261564 19460 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 05:46:49.261577 19460 net.cpp:411] loss -> loss
I0522 05:46:49.261595 19460 layer_factory.hpp:77] Creating layer loss
I0522 05:46:49.262078 19460 net.cpp:150] Setting up loss
I0522 05:46:49.262091 19460 net.cpp:157] Top shape: (1)
I0522 05:46:49.262101 19460 net.cpp:160]     with loss weight 1
I0522 05:46:49.262120 19460 net.cpp:165] Memory required for data: 31577528
I0522 05:46:49.262130 19460 net.cpp:226] loss needs backward computation.
I0522 05:46:49.262141 19460 net.cpp:228] accuracy does not need backward computation.
I0522 05:46:49.262152 19460 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 05:46:49.262162 19460 net.cpp:226] drop3 needs backward computation.
I0522 05:46:49.262171 19460 net.cpp:226] ip3 needs backward computation.
I0522 05:46:49.262182 19460 net.cpp:226] drop2 needs backward computation.
I0522 05:46:49.262192 19460 net.cpp:226] relu6 needs backward computation.
I0522 05:46:49.262210 19460 net.cpp:226] ip2 needs backward computation.
I0522 05:46:49.262220 19460 net.cpp:226] drop1 needs backward computation.
I0522 05:46:49.262230 19460 net.cpp:226] relu5 needs backward computation.
I0522 05:46:49.262239 19460 net.cpp:226] ip1 needs backward computation.
I0522 05:46:49.262249 19460 net.cpp:226] pool4 needs backward computation.
I0522 05:46:49.262259 19460 net.cpp:226] relu4 needs backward computation.
I0522 05:46:49.262269 19460 net.cpp:226] conv4 needs backward computation.
I0522 05:46:49.262279 19460 net.cpp:226] pool3 needs backward computation.
I0522 05:46:49.262290 19460 net.cpp:226] relu3 needs backward computation.
I0522 05:46:49.262300 19460 net.cpp:226] conv3 needs backward computation.
I0522 05:46:49.262310 19460 net.cpp:226] pool2 needs backward computation.
I0522 05:46:49.262320 19460 net.cpp:226] relu2 needs backward computation.
I0522 05:46:49.262329 19460 net.cpp:226] conv2 needs backward computation.
I0522 05:46:49.262339 19460 net.cpp:226] pool1 needs backward computation.
I0522 05:46:49.262351 19460 net.cpp:226] relu1 needs backward computation.
I0522 05:46:49.262359 19460 net.cpp:226] conv1 needs backward computation.
I0522 05:46:49.262372 19460 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 05:46:49.262382 19460 net.cpp:228] data_hdf5 does not need backward computation.
I0522 05:46:49.262392 19460 net.cpp:270] This network produces output accuracy
I0522 05:46:49.262403 19460 net.cpp:270] This network produces output loss
I0522 05:46:49.262433 19460 net.cpp:283] Network initialization done.
I0522 05:46:49.262567 19460 solver.cpp:60] Solver scaffolding done.
I0522 05:46:49.263695 19460 caffe.cpp:212] Starting Optimization
I0522 05:46:49.263712 19460 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 05:46:49.263726 19460 solver.cpp:289] Learning Rate Policy: fixed
I0522 05:46:49.264947 19460 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 05:47:42.123142 19460 solver.cpp:409]     Test net output #0: accuracy = 0.0823449
I0522 05:47:42.123306 19460 solver.cpp:409]     Test net output #1: loss = 2.39792 (* 1 = 2.39792 loss)
I0522 05:47:42.142331 19460 solver.cpp:237] Iteration 0, loss = 2.39927
I0522 05:47:42.142366 19460 solver.cpp:253]     Train net output #0: loss = 2.39927 (* 1 = 2.39927 loss)
I0522 05:47:42.142385 19460 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0522 05:47:54.295929 19460 solver.cpp:237] Iteration 750, loss = 1.88306
I0522 05:47:54.295979 19460 solver.cpp:253]     Train net output #0: loss = 1.88306 (* 1 = 1.88306 loss)
I0522 05:47:54.295994 19460 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0522 05:48:06.443399 19460 solver.cpp:237] Iteration 1500, loss = 1.99099
I0522 05:48:06.443439 19460 solver.cpp:253]     Train net output #0: loss = 1.99099 (* 1 = 1.99099 loss)
I0522 05:48:06.443451 19460 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0522 05:48:18.552366 19460 solver.cpp:237] Iteration 2250, loss = 1.67421
I0522 05:48:18.552528 19460 solver.cpp:253]     Train net output #0: loss = 1.67421 (* 1 = 1.67421 loss)
I0522 05:48:18.552542 19460 sgd_solver.cpp:106] Iteration 2250, lr = 0.005
I0522 05:48:30.709769 19460 solver.cpp:237] Iteration 3000, loss = 1.39857
I0522 05:48:30.709806 19460 solver.cpp:253]     Train net output #0: loss = 1.39857 (* 1 = 1.39857 loss)
I0522 05:48:30.709823 19460 sgd_solver.cpp:106] Iteration 3000, lr = 0.005
I0522 05:48:42.873760 19460 solver.cpp:237] Iteration 3750, loss = 1.1696
I0522 05:48:42.873796 19460 solver.cpp:253]     Train net output #0: loss = 1.1696 (* 1 = 1.1696 loss)
I0522 05:48:42.873813 19460 sgd_solver.cpp:106] Iteration 3750, lr = 0.005
I0522 05:48:55.033505 19460 solver.cpp:237] Iteration 4500, loss = 1.31084
I0522 05:48:55.033653 19460 solver.cpp:253]     Train net output #0: loss = 1.31084 (* 1 = 1.31084 loss)
I0522 05:48:55.033668 19460 sgd_solver.cpp:106] Iteration 4500, lr = 0.005
I0522 05:49:29.340260 19460 solver.cpp:237] Iteration 5250, loss = 1.54838
I0522 05:49:29.340425 19460 solver.cpp:253]     Train net output #0: loss = 1.54838 (* 1 = 1.54838 loss)
I0522 05:49:29.340438 19460 sgd_solver.cpp:106] Iteration 5250, lr = 0.005
I0522 05:49:41.547871 19460 solver.cpp:237] Iteration 6000, loss = 1.19355
I0522 05:49:41.547915 19460 solver.cpp:253]     Train net output #0: loss = 1.19355 (* 1 = 1.19355 loss)
I0522 05:49:41.547932 19460 sgd_solver.cpp:106] Iteration 6000, lr = 0.005
I0522 05:49:53.755540 19460 solver.cpp:237] Iteration 6750, loss = 2.26482
I0522 05:49:53.755578 19460 solver.cpp:253]     Train net output #0: loss = 2.26482 (* 1 = 2.26482 loss)
I0522 05:49:53.755594 19460 sgd_solver.cpp:106] Iteration 6750, lr = 0.005
I0522 05:50:05.955440 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_7500.caffemodel
I0522 05:50:06.009515 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_7500.solverstate
I0522 05:50:06.039760 19460 solver.cpp:237] Iteration 7500, loss = 1.0525
I0522 05:50:06.039803 19460 solver.cpp:253]     Train net output #0: loss = 1.0525 (* 1 = 1.0525 loss)
I0522 05:50:06.039819 19460 sgd_solver.cpp:106] Iteration 7500, lr = 0.005
I0522 05:50:18.255118 19460 solver.cpp:237] Iteration 8250, loss = 1.41247
I0522 05:50:18.255156 19460 solver.cpp:253]     Train net output #0: loss = 1.41247 (* 1 = 1.41247 loss)
I0522 05:50:18.255168 19460 sgd_solver.cpp:106] Iteration 8250, lr = 0.005
I0522 05:50:30.478646 19460 solver.cpp:237] Iteration 9000, loss = 1.12361
I0522 05:50:30.478700 19460 solver.cpp:253]     Train net output #0: loss = 1.12361 (* 1 = 1.12361 loss)
I0522 05:50:30.478714 19460 sgd_solver.cpp:106] Iteration 9000, lr = 0.005
I0522 05:50:42.698457 19460 solver.cpp:237] Iteration 9750, loss = 1.42151
I0522 05:50:42.698601 19460 solver.cpp:253]     Train net output #0: loss = 1.42151 (* 1 = 1.42151 loss)
I0522 05:50:42.698616 19460 sgd_solver.cpp:106] Iteration 9750, lr = 0.005
I0522 05:51:17.096710 19460 solver.cpp:237] Iteration 10500, loss = 1.07921
I0522 05:51:17.096878 19460 solver.cpp:253]     Train net output #0: loss = 1.07921 (* 1 = 1.07921 loss)
I0522 05:51:17.096892 19460 sgd_solver.cpp:106] Iteration 10500, lr = 0.005
I0522 05:51:29.316488 19460 solver.cpp:237] Iteration 11250, loss = 0.655989
I0522 05:51:29.316525 19460 solver.cpp:253]     Train net output #0: loss = 0.655989 (* 1 = 0.655989 loss)
I0522 05:51:29.316540 19460 sgd_solver.cpp:106] Iteration 11250, lr = 0.005
I0522 05:51:41.528233 19460 solver.cpp:237] Iteration 12000, loss = 1.13572
I0522 05:51:41.528277 19460 solver.cpp:253]     Train net output #0: loss = 1.13572 (* 1 = 1.13572 loss)
I0522 05:51:41.528290 19460 sgd_solver.cpp:106] Iteration 12000, lr = 0.005
I0522 05:51:53.734926 19460 solver.cpp:237] Iteration 12750, loss = 1.44295
I0522 05:51:53.735092 19460 solver.cpp:253]     Train net output #0: loss = 1.44295 (* 1 = 1.44295 loss)
I0522 05:51:53.735107 19460 sgd_solver.cpp:106] Iteration 12750, lr = 0.005
I0522 05:52:05.985065 19460 solver.cpp:237] Iteration 13500, loss = 1.66603
I0522 05:52:05.985116 19460 solver.cpp:253]     Train net output #0: loss = 1.66603 (* 1 = 1.66603 loss)
I0522 05:52:05.985129 19460 sgd_solver.cpp:106] Iteration 13500, lr = 0.005
I0522 05:52:18.155760 19460 solver.cpp:237] Iteration 14250, loss = 1.65787
I0522 05:52:18.155796 19460 solver.cpp:253]     Train net output #0: loss = 1.65787 (* 1 = 1.65787 loss)
I0522 05:52:18.155812 19460 sgd_solver.cpp:106] Iteration 14250, lr = 0.005
I0522 05:52:30.340917 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_15000.caffemodel
I0522 05:52:30.390295 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_15000.solverstate
I0522 05:52:30.415355 19460 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 05:53:22.351961 19460 solver.cpp:409]     Test net output #0: accuracy = 0.850288
I0522 05:53:22.352118 19460 solver.cpp:409]     Test net output #1: loss = 0.529631 (* 1 = 0.529631 loss)
I0522 05:53:44.496592 19460 solver.cpp:237] Iteration 15000, loss = 1.34934
I0522 05:53:44.496642 19460 solver.cpp:253]     Train net output #0: loss = 1.34934 (* 1 = 1.34934 loss)
I0522 05:53:44.496659 19460 sgd_solver.cpp:106] Iteration 15000, lr = 0.005
I0522 05:53:56.694339 19460 solver.cpp:237] Iteration 15750, loss = 0.715927
I0522 05:53:56.694490 19460 solver.cpp:253]     Train net output #0: loss = 0.715927 (* 1 = 0.715927 loss)
I0522 05:53:56.694505 19460 sgd_solver.cpp:106] Iteration 15750, lr = 0.005
I0522 05:54:08.925019 19460 solver.cpp:237] Iteration 16500, loss = 1.19969
I0522 05:54:08.925067 19460 solver.cpp:253]     Train net output #0: loss = 1.19969 (* 1 = 1.19969 loss)
I0522 05:54:08.925083 19460 sgd_solver.cpp:106] Iteration 16500, lr = 0.005
I0522 05:54:21.122858 19460 solver.cpp:237] Iteration 17250, loss = 1.72678
I0522 05:54:21.122894 19460 solver.cpp:253]     Train net output #0: loss = 1.72678 (* 1 = 1.72678 loss)
I0522 05:54:21.122907 19460 sgd_solver.cpp:106] Iteration 17250, lr = 0.005
I0522 05:54:33.307971 19460 solver.cpp:237] Iteration 18000, loss = 1.37189
I0522 05:54:33.308114 19460 solver.cpp:253]     Train net output #0: loss = 1.37189 (* 1 = 1.37189 loss)
I0522 05:54:33.308127 19460 sgd_solver.cpp:106] Iteration 18000, lr = 0.005
I0522 05:54:45.491396 19460 solver.cpp:237] Iteration 18750, loss = 1.20595
I0522 05:54:45.491441 19460 solver.cpp:253]     Train net output #0: loss = 1.20595 (* 1 = 1.20595 loss)
I0522 05:54:45.491457 19460 sgd_solver.cpp:106] Iteration 18750, lr = 0.005
I0522 05:54:57.673995 19460 solver.cpp:237] Iteration 19500, loss = 1.10283
I0522 05:54:57.674031 19460 solver.cpp:253]     Train net output #0: loss = 1.10283 (* 1 = 1.10283 loss)
I0522 05:54:57.674048 19460 sgd_solver.cpp:106] Iteration 19500, lr = 0.005
I0522 05:55:32.067087 19460 solver.cpp:237] Iteration 20250, loss = 1.06003
I0522 05:55:32.067252 19460 solver.cpp:253]     Train net output #0: loss = 1.06002 (* 1 = 1.06002 loss)
I0522 05:55:32.067266 19460 sgd_solver.cpp:106] Iteration 20250, lr = 0.005
I0522 05:55:44.268160 19460 solver.cpp:237] Iteration 21000, loss = 1.5903
I0522 05:55:44.268196 19460 solver.cpp:253]     Train net output #0: loss = 1.5903 (* 1 = 1.5903 loss)
I0522 05:55:44.268209 19460 sgd_solver.cpp:106] Iteration 21000, lr = 0.005
I0522 05:55:56.466330 19460 solver.cpp:237] Iteration 21750, loss = 1.24518
I0522 05:55:56.466378 19460 solver.cpp:253]     Train net output #0: loss = 1.24518 (* 1 = 1.24518 loss)
I0522 05:55:56.466392 19460 sgd_solver.cpp:106] Iteration 21750, lr = 0.005
I0522 05:56:08.666286 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_22500.caffemodel
I0522 05:56:08.718190 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_22500.solverstate
I0522 05:56:08.751837 19460 solver.cpp:237] Iteration 22500, loss = 1.66488
I0522 05:56:08.751886 19460 solver.cpp:253]     Train net output #0: loss = 1.66488 (* 1 = 1.66488 loss)
I0522 05:56:08.751901 19460 sgd_solver.cpp:106] Iteration 22500, lr = 0.005
I0522 05:56:20.950026 19460 solver.cpp:237] Iteration 23250, loss = 1.48783
I0522 05:56:20.950073 19460 solver.cpp:253]     Train net output #0: loss = 1.48783 (* 1 = 1.48783 loss)
I0522 05:56:20.950086 19460 sgd_solver.cpp:106] Iteration 23250, lr = 0.005
I0522 05:56:33.142418 19460 solver.cpp:237] Iteration 24000, loss = 0.786448
I0522 05:56:33.142455 19460 solver.cpp:253]     Train net output #0: loss = 0.786447 (* 1 = 0.786447 loss)
I0522 05:56:33.142472 19460 sgd_solver.cpp:106] Iteration 24000, lr = 0.005
I0522 05:56:45.328982 19460 solver.cpp:237] Iteration 24750, loss = 1.80884
I0522 05:56:45.329146 19460 solver.cpp:253]     Train net output #0: loss = 1.80884 (* 1 = 1.80884 loss)
I0522 05:56:45.329161 19460 sgd_solver.cpp:106] Iteration 24750, lr = 0.005
I0522 05:57:19.679477 19460 solver.cpp:237] Iteration 25500, loss = 1.58569
I0522 05:57:19.679642 19460 solver.cpp:253]     Train net output #0: loss = 1.58569 (* 1 = 1.58569 loss)
I0522 05:57:19.679656 19460 sgd_solver.cpp:106] Iteration 25500, lr = 0.005
I0522 05:57:31.773859 19460 solver.cpp:237] Iteration 26250, loss = 1.69591
I0522 05:57:31.773906 19460 solver.cpp:253]     Train net output #0: loss = 1.69591 (* 1 = 1.69591 loss)
I0522 05:57:31.773922 19460 sgd_solver.cpp:106] Iteration 26250, lr = 0.005
I0522 05:57:43.881340 19460 solver.cpp:237] Iteration 27000, loss = 1.33469
I0522 05:57:43.881376 19460 solver.cpp:253]     Train net output #0: loss = 1.33469 (* 1 = 1.33469 loss)
I0522 05:57:43.881392 19460 sgd_solver.cpp:106] Iteration 27000, lr = 0.005
I0522 05:57:56.027127 19460 solver.cpp:237] Iteration 27750, loss = 1.24186
I0522 05:57:56.027295 19460 solver.cpp:253]     Train net output #0: loss = 1.24186 (* 1 = 1.24186 loss)
I0522 05:57:56.027310 19460 sgd_solver.cpp:106] Iteration 27750, lr = 0.005
I0522 05:58:08.178328 19460 solver.cpp:237] Iteration 28500, loss = 1.38883
I0522 05:58:08.178362 19460 solver.cpp:253]     Train net output #0: loss = 1.38883 (* 1 = 1.38883 loss)
I0522 05:58:08.178380 19460 sgd_solver.cpp:106] Iteration 28500, lr = 0.005
I0522 05:58:20.333465 19460 solver.cpp:237] Iteration 29250, loss = 1.02034
I0522 05:58:20.333505 19460 solver.cpp:253]     Train net output #0: loss = 1.02034 (* 1 = 1.02034 loss)
I0522 05:58:20.333526 19460 sgd_solver.cpp:106] Iteration 29250, lr = 0.005
I0522 05:58:32.473801 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_30000.caffemodel
I0522 05:58:32.525153 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_30000.solverstate
I0522 05:58:32.554100 19460 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 05:59:45.330116 19460 solver.cpp:409]     Test net output #0: accuracy = 0.86454
I0522 05:59:45.330279 19460 solver.cpp:409]     Test net output #1: loss = 0.456477 (* 1 = 0.456477 loss)
I0522 06:00:07.537902 19460 solver.cpp:237] Iteration 30000, loss = 1.31332
I0522 06:00:07.537956 19460 solver.cpp:253]     Train net output #0: loss = 1.31332 (* 1 = 1.31332 loss)
I0522 06:00:07.537971 19460 sgd_solver.cpp:106] Iteration 30000, lr = 0.005
I0522 06:00:19.713526 19460 solver.cpp:237] Iteration 30750, loss = 0.727251
I0522 06:00:19.713681 19460 solver.cpp:253]     Train net output #0: loss = 0.727251 (* 1 = 0.727251 loss)
I0522 06:00:19.713696 19460 sgd_solver.cpp:106] Iteration 30750, lr = 0.005
I0522 06:00:31.927747 19460 solver.cpp:237] Iteration 31500, loss = 1.56278
I0522 06:00:31.927791 19460 solver.cpp:253]     Train net output #0: loss = 1.56278 (* 1 = 1.56278 loss)
I0522 06:00:31.927809 19460 sgd_solver.cpp:106] Iteration 31500, lr = 0.005
I0522 06:00:44.068831 19460 solver.cpp:237] Iteration 32250, loss = 1.40447
I0522 06:00:44.068879 19460 solver.cpp:253]     Train net output #0: loss = 1.40447 (* 1 = 1.40447 loss)
I0522 06:00:44.068894 19460 sgd_solver.cpp:106] Iteration 32250, lr = 0.005
I0522 06:00:56.266407 19460 solver.cpp:237] Iteration 33000, loss = 1.47509
I0522 06:00:56.266562 19460 solver.cpp:253]     Train net output #0: loss = 1.47509 (* 1 = 1.47509 loss)
I0522 06:00:56.266577 19460 sgd_solver.cpp:106] Iteration 33000, lr = 0.005
I0522 06:01:08.418442 19460 solver.cpp:237] Iteration 33750, loss = 1.10241
I0522 06:01:08.418478 19460 solver.cpp:253]     Train net output #0: loss = 1.10241 (* 1 = 1.10241 loss)
I0522 06:01:08.418495 19460 sgd_solver.cpp:106] Iteration 33750, lr = 0.005
I0522 06:01:20.588677 19460 solver.cpp:237] Iteration 34500, loss = 1.06489
I0522 06:01:20.588722 19460 solver.cpp:253]     Train net output #0: loss = 1.06489 (* 1 = 1.06489 loss)
I0522 06:01:20.588737 19460 sgd_solver.cpp:106] Iteration 34500, lr = 0.005
I0522 06:01:54.966275 19460 solver.cpp:237] Iteration 35250, loss = 1.29945
I0522 06:01:54.966439 19460 solver.cpp:253]     Train net output #0: loss = 1.29945 (* 1 = 1.29945 loss)
I0522 06:01:54.966454 19460 sgd_solver.cpp:106] Iteration 35250, lr = 0.005
I0522 06:02:07.102495 19460 solver.cpp:237] Iteration 36000, loss = 1.51235
I0522 06:02:07.102536 19460 solver.cpp:253]     Train net output #0: loss = 1.51235 (* 1 = 1.51235 loss)
I0522 06:02:07.102553 19460 sgd_solver.cpp:106] Iteration 36000, lr = 0.005
I0522 06:02:19.277292 19460 solver.cpp:237] Iteration 36750, loss = 1.1868
I0522 06:02:19.277328 19460 solver.cpp:253]     Train net output #0: loss = 1.1868 (* 1 = 1.1868 loss)
I0522 06:02:19.277344 19460 sgd_solver.cpp:106] Iteration 36750, lr = 0.005
I0522 06:02:31.472371 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_37500.caffemodel
I0522 06:02:31.523836 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_37500.solverstate
I0522 06:02:31.557478 19460 solver.cpp:237] Iteration 37500, loss = 1.04505
I0522 06:02:31.557528 19460 solver.cpp:253]     Train net output #0: loss = 1.04505 (* 1 = 1.04505 loss)
I0522 06:02:31.557541 19460 sgd_solver.cpp:106] Iteration 37500, lr = 0.005
I0522 06:02:43.750277 19460 solver.cpp:237] Iteration 38250, loss = 1.44502
I0522 06:02:43.750314 19460 solver.cpp:253]     Train net output #0: loss = 1.44502 (* 1 = 1.44502 loss)
I0522 06:02:43.750330 19460 sgd_solver.cpp:106] Iteration 38250, lr = 0.005
I0522 06:02:55.940304 19460 solver.cpp:237] Iteration 39000, loss = 1.06348
I0522 06:02:55.940354 19460 solver.cpp:253]     Train net output #0: loss = 1.06348 (* 1 = 1.06348 loss)
I0522 06:02:55.940368 19460 sgd_solver.cpp:106] Iteration 39000, lr = 0.005
I0522 06:03:08.127758 19460 solver.cpp:237] Iteration 39750, loss = 1.2127
I0522 06:03:08.127907 19460 solver.cpp:253]     Train net output #0: loss = 1.2127 (* 1 = 1.2127 loss)
I0522 06:03:08.127920 19460 sgd_solver.cpp:106] Iteration 39750, lr = 0.005
I0522 06:03:42.506878 19460 solver.cpp:237] Iteration 40500, loss = 1.20054
I0522 06:03:42.507058 19460 solver.cpp:253]     Train net output #0: loss = 1.20054 (* 1 = 1.20054 loss)
I0522 06:03:42.507073 19460 sgd_solver.cpp:106] Iteration 40500, lr = 0.005
I0522 06:03:54.720891 19460 solver.cpp:237] Iteration 41250, loss = 1.26197
I0522 06:03:54.720933 19460 solver.cpp:253]     Train net output #0: loss = 1.26197 (* 1 = 1.26197 loss)
I0522 06:03:54.720947 19460 sgd_solver.cpp:106] Iteration 41250, lr = 0.005
I0522 06:04:06.955967 19460 solver.cpp:237] Iteration 42000, loss = 1.16296
I0522 06:04:06.956003 19460 solver.cpp:253]     Train net output #0: loss = 1.16296 (* 1 = 1.16296 loss)
I0522 06:04:06.956019 19460 sgd_solver.cpp:106] Iteration 42000, lr = 0.005
I0522 06:04:19.187875 19460 solver.cpp:237] Iteration 42750, loss = 0.861577
I0522 06:04:19.188024 19460 solver.cpp:253]     Train net output #0: loss = 0.861577 (* 1 = 0.861577 loss)
I0522 06:04:19.188037 19460 sgd_solver.cpp:106] Iteration 42750, lr = 0.005
I0522 06:04:31.304556 19460 solver.cpp:237] Iteration 43500, loss = 1.54093
I0522 06:04:31.304592 19460 solver.cpp:253]     Train net output #0: loss = 1.54093 (* 1 = 1.54093 loss)
I0522 06:04:31.304605 19460 sgd_solver.cpp:106] Iteration 43500, lr = 0.005
I0522 06:04:43.415695 19460 solver.cpp:237] Iteration 44250, loss = 0.848358
I0522 06:04:43.415740 19460 solver.cpp:253]     Train net output #0: loss = 0.848358 (* 1 = 0.848358 loss)
I0522 06:04:43.415755 19460 sgd_solver.cpp:106] Iteration 44250, lr = 0.005
I0522 06:04:55.528412 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_45000.caffemodel
I0522 06:04:55.579160 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_45000.solverstate
I0522 06:04:55.605731 19460 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 06:05:47.303411 19460 solver.cpp:409]     Test net output #0: accuracy = 0.861041
I0522 06:05:47.303576 19460 solver.cpp:409]     Test net output #1: loss = 0.581943 (* 1 = 0.581943 loss)
I0522 06:06:09.466177 19460 solver.cpp:237] Iteration 45000, loss = 1.50387
I0522 06:06:09.466228 19460 solver.cpp:253]     Train net output #0: loss = 1.50387 (* 1 = 1.50387 loss)
I0522 06:06:09.466246 19460 sgd_solver.cpp:106] Iteration 45000, lr = 0.005
I0522 06:06:21.634690 19460 solver.cpp:237] Iteration 45750, loss = 0.704749
I0522 06:06:21.634855 19460 solver.cpp:253]     Train net output #0: loss = 0.704749 (* 1 = 0.704749 loss)
I0522 06:06:21.634870 19460 sgd_solver.cpp:106] Iteration 45750, lr = 0.005
I0522 06:06:33.808177 19460 solver.cpp:237] Iteration 46500, loss = 1.68702
I0522 06:06:33.808213 19460 solver.cpp:253]     Train net output #0: loss = 1.68702 (* 1 = 1.68702 loss)
I0522 06:06:33.808226 19460 sgd_solver.cpp:106] Iteration 46500, lr = 0.005
I0522 06:06:45.979696 19460 solver.cpp:237] Iteration 47250, loss = 1.20184
I0522 06:06:45.979743 19460 solver.cpp:253]     Train net output #0: loss = 1.20184 (* 1 = 1.20184 loss)
I0522 06:06:45.979758 19460 sgd_solver.cpp:106] Iteration 47250, lr = 0.005
I0522 06:06:58.120847 19460 solver.cpp:237] Iteration 48000, loss = 1.04095
I0522 06:06:58.120996 19460 solver.cpp:253]     Train net output #0: loss = 1.04095 (* 1 = 1.04095 loss)
I0522 06:06:58.121011 19460 sgd_solver.cpp:106] Iteration 48000, lr = 0.005
I0522 06:07:10.282992 19460 solver.cpp:237] Iteration 48750, loss = 0.858671
I0522 06:07:10.283043 19460 solver.cpp:253]     Train net output #0: loss = 0.858671 (* 1 = 0.858671 loss)
I0522 06:07:10.283057 19460 sgd_solver.cpp:106] Iteration 48750, lr = 0.005
I0522 06:07:22.427352 19460 solver.cpp:237] Iteration 49500, loss = 1.28281
I0522 06:07:22.427387 19460 solver.cpp:253]     Train net output #0: loss = 1.28281 (* 1 = 1.28281 loss)
I0522 06:07:22.427403 19460 sgd_solver.cpp:106] Iteration 49500, lr = 0.005
I0522 06:07:56.705667 19460 solver.cpp:237] Iteration 50250, loss = 0.863063
I0522 06:07:56.705845 19460 solver.cpp:253]     Train net output #0: loss = 0.863062 (* 1 = 0.863062 loss)
I0522 06:07:56.705860 19460 sgd_solver.cpp:106] Iteration 50250, lr = 0.005
I0522 06:08:08.888785 19460 solver.cpp:237] Iteration 51000, loss = 0.785387
I0522 06:08:08.888821 19460 solver.cpp:253]     Train net output #0: loss = 0.785386 (* 1 = 0.785386 loss)
I0522 06:08:08.888839 19460 sgd_solver.cpp:106] Iteration 51000, lr = 0.005
I0522 06:08:21.079295 19460 solver.cpp:237] Iteration 51750, loss = 1.12488
I0522 06:08:21.079341 19460 solver.cpp:253]     Train net output #0: loss = 1.12488 (* 1 = 1.12488 loss)
I0522 06:08:21.079357 19460 sgd_solver.cpp:106] Iteration 51750, lr = 0.005
I0522 06:08:33.201779 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_52500.caffemodel
I0522 06:08:33.254801 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_52500.solverstate
I0522 06:08:33.286164 19460 solver.cpp:237] Iteration 52500, loss = 1.23995
I0522 06:08:33.286206 19460 solver.cpp:253]     Train net output #0: loss = 1.23995 (* 1 = 1.23995 loss)
I0522 06:08:33.286221 19460 sgd_solver.cpp:106] Iteration 52500, lr = 0.005
I0522 06:08:45.427224 19460 solver.cpp:237] Iteration 53250, loss = 1.40151
I0522 06:08:45.427269 19460 solver.cpp:253]     Train net output #0: loss = 1.40151 (* 1 = 1.40151 loss)
I0522 06:08:45.427285 19460 sgd_solver.cpp:106] Iteration 53250, lr = 0.005
I0522 06:08:57.621096 19460 solver.cpp:237] Iteration 54000, loss = 1.17812
I0522 06:08:57.621132 19460 solver.cpp:253]     Train net output #0: loss = 1.17812 (* 1 = 1.17812 loss)
I0522 06:08:57.621148 19460 sgd_solver.cpp:106] Iteration 54000, lr = 0.005
I0522 06:09:09.827345 19460 solver.cpp:237] Iteration 54750, loss = 1.04124
I0522 06:09:09.827502 19460 solver.cpp:253]     Train net output #0: loss = 1.04123 (* 1 = 1.04123 loss)
I0522 06:09:09.827517 19460 sgd_solver.cpp:106] Iteration 54750, lr = 0.005
I0522 06:09:44.097615 19460 solver.cpp:237] Iteration 55500, loss = 1.86442
I0522 06:09:44.097784 19460 solver.cpp:253]     Train net output #0: loss = 1.86442 (* 1 = 1.86442 loss)
I0522 06:09:44.097798 19460 sgd_solver.cpp:106] Iteration 55500, lr = 0.005
I0522 06:09:56.213971 19460 solver.cpp:237] Iteration 56250, loss = 1.48552
I0522 06:09:56.214007 19460 solver.cpp:253]     Train net output #0: loss = 1.48552 (* 1 = 1.48552 loss)
I0522 06:09:56.214023 19460 sgd_solver.cpp:106] Iteration 56250, lr = 0.005
I0522 06:10:08.377151 19460 solver.cpp:237] Iteration 57000, loss = 1.39609
I0522 06:10:08.377197 19460 solver.cpp:253]     Train net output #0: loss = 1.39609 (* 1 = 1.39609 loss)
I0522 06:10:08.377212 19460 sgd_solver.cpp:106] Iteration 57000, lr = 0.005
I0522 06:10:20.549669 19460 solver.cpp:237] Iteration 57750, loss = 0.868691
I0522 06:10:20.549814 19460 solver.cpp:253]     Train net output #0: loss = 0.868691 (* 1 = 0.868691 loss)
I0522 06:10:20.549830 19460 sgd_solver.cpp:106] Iteration 57750, lr = 0.005
I0522 06:10:32.724964 19460 solver.cpp:237] Iteration 58500, loss = 1.38844
I0522 06:10:32.725013 19460 solver.cpp:253]     Train net output #0: loss = 1.38844 (* 1 = 1.38844 loss)
I0522 06:10:32.725029 19460 sgd_solver.cpp:106] Iteration 58500, lr = 0.005
I0522 06:10:44.862181 19460 solver.cpp:237] Iteration 59250, loss = 0.915567
I0522 06:10:44.862218 19460 solver.cpp:253]     Train net output #0: loss = 0.915567 (* 1 = 0.915567 loss)
I0522 06:10:44.862234 19460 sgd_solver.cpp:106] Iteration 59250, lr = 0.005
I0522 06:10:56.970489 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_60000.caffemodel
I0522 06:10:57.020598 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_60000.solverstate
I0522 06:10:57.047780 19460 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 06:12:09.732549 19460 solver.cpp:409]     Test net output #0: accuracy = 0.875908
I0522 06:12:09.732724 19460 solver.cpp:409]     Test net output #1: loss = 0.386145 (* 1 = 0.386145 loss)
I0522 06:12:31.867091 19460 solver.cpp:237] Iteration 60000, loss = 1.64985
I0522 06:12:31.867143 19460 solver.cpp:253]     Train net output #0: loss = 1.64985 (* 1 = 1.64985 loss)
I0522 06:12:31.867159 19460 sgd_solver.cpp:106] Iteration 60000, lr = 0.005
I0522 06:12:43.988343 19460 solver.cpp:237] Iteration 60750, loss = 0.609291
I0522 06:12:43.988499 19460 solver.cpp:253]     Train net output #0: loss = 0.609291 (* 1 = 0.609291 loss)
I0522 06:12:43.988514 19460 sgd_solver.cpp:106] Iteration 60750, lr = 0.005
I0522 06:12:56.079192 19460 solver.cpp:237] Iteration 61500, loss = 0.828987
I0522 06:12:56.079242 19460 solver.cpp:253]     Train net output #0: loss = 0.828987 (* 1 = 0.828987 loss)
I0522 06:12:56.079257 19460 sgd_solver.cpp:106] Iteration 61500, lr = 0.005
I0522 06:13:08.217386 19460 solver.cpp:237] Iteration 62250, loss = 1.35347
I0522 06:13:08.217422 19460 solver.cpp:253]     Train net output #0: loss = 1.35347 (* 1 = 1.35347 loss)
I0522 06:13:08.217438 19460 sgd_solver.cpp:106] Iteration 62250, lr = 0.005
I0522 06:13:20.375608 19460 solver.cpp:237] Iteration 63000, loss = 0.983794
I0522 06:13:20.375763 19460 solver.cpp:253]     Train net output #0: loss = 0.983794 (* 1 = 0.983794 loss)
I0522 06:13:20.375777 19460 sgd_solver.cpp:106] Iteration 63000, lr = 0.005
I0522 06:13:32.535727 19460 solver.cpp:237] Iteration 63750, loss = 1.38275
I0522 06:13:32.535763 19460 solver.cpp:253]     Train net output #0: loss = 1.38275 (* 1 = 1.38275 loss)
I0522 06:13:32.535778 19460 sgd_solver.cpp:106] Iteration 63750, lr = 0.005
I0522 06:13:44.625478 19460 solver.cpp:237] Iteration 64500, loss = 1.23232
I0522 06:13:44.625525 19460 solver.cpp:253]     Train net output #0: loss = 1.23232 (* 1 = 1.23232 loss)
I0522 06:13:44.625540 19460 sgd_solver.cpp:106] Iteration 64500, lr = 0.005
I0522 06:14:18.973078 19460 solver.cpp:237] Iteration 65250, loss = 0.948211
I0522 06:14:18.973248 19460 solver.cpp:253]     Train net output #0: loss = 0.948211 (* 1 = 0.948211 loss)
I0522 06:14:18.973263 19460 sgd_solver.cpp:106] Iteration 65250, lr = 0.005
I0522 06:14:31.063789 19460 solver.cpp:237] Iteration 66000, loss = 0.940274
I0522 06:14:31.063825 19460 solver.cpp:253]     Train net output #0: loss = 0.940275 (* 1 = 0.940275 loss)
I0522 06:14:31.063841 19460 sgd_solver.cpp:106] Iteration 66000, lr = 0.005
I0522 06:14:43.178380 19460 solver.cpp:237] Iteration 66750, loss = 1.20896
I0522 06:14:43.178427 19460 solver.cpp:253]     Train net output #0: loss = 1.20896 (* 1 = 1.20896 loss)
I0522 06:14:43.178442 19460 sgd_solver.cpp:106] Iteration 66750, lr = 0.005
I0522 06:14:55.266862 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_67500.caffemodel
I0522 06:14:55.318204 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_67500.solverstate
I0522 06:14:55.351358 19460 solver.cpp:237] Iteration 67500, loss = 1.63234
I0522 06:14:55.351404 19460 solver.cpp:253]     Train net output #0: loss = 1.63234 (* 1 = 1.63234 loss)
I0522 06:14:55.351420 19460 sgd_solver.cpp:106] Iteration 67500, lr = 0.005
I0522 06:15:07.490998 19460 solver.cpp:237] Iteration 68250, loss = 1.3866
I0522 06:15:07.491042 19460 solver.cpp:253]     Train net output #0: loss = 1.3866 (* 1 = 1.3866 loss)
I0522 06:15:07.491058 19460 sgd_solver.cpp:106] Iteration 68250, lr = 0.005
I0522 06:15:19.667376 19460 solver.cpp:237] Iteration 69000, loss = 1.16524
I0522 06:15:19.667412 19460 solver.cpp:253]     Train net output #0: loss = 1.16524 (* 1 = 1.16524 loss)
I0522 06:15:19.667424 19460 sgd_solver.cpp:106] Iteration 69000, lr = 0.005
I0522 06:15:31.834605 19460 solver.cpp:237] Iteration 69750, loss = 1.15241
I0522 06:15:31.834789 19460 solver.cpp:253]     Train net output #0: loss = 1.15241 (* 1 = 1.15241 loss)
I0522 06:15:31.834802 19460 sgd_solver.cpp:106] Iteration 69750, lr = 0.005
I0522 06:16:06.192184 19460 solver.cpp:237] Iteration 70500, loss = 1.07282
I0522 06:16:06.192358 19460 solver.cpp:253]     Train net output #0: loss = 1.07282 (* 1 = 1.07282 loss)
I0522 06:16:06.192373 19460 sgd_solver.cpp:106] Iteration 70500, lr = 0.005
I0522 06:16:18.346855 19460 solver.cpp:237] Iteration 71250, loss = 1.42672
I0522 06:16:18.346904 19460 solver.cpp:253]     Train net output #0: loss = 1.42672 (* 1 = 1.42672 loss)
I0522 06:16:18.346920 19460 sgd_solver.cpp:106] Iteration 71250, lr = 0.005
I0522 06:16:30.488090 19460 solver.cpp:237] Iteration 72000, loss = 1.13991
I0522 06:16:30.488126 19460 solver.cpp:253]     Train net output #0: loss = 1.13991 (* 1 = 1.13991 loss)
I0522 06:16:30.488142 19460 sgd_solver.cpp:106] Iteration 72000, lr = 0.005
I0522 06:16:42.644024 19460 solver.cpp:237] Iteration 72750, loss = 1.07453
I0522 06:16:42.644186 19460 solver.cpp:253]     Train net output #0: loss = 1.07453 (* 1 = 1.07453 loss)
I0522 06:16:42.644201 19460 sgd_solver.cpp:106] Iteration 72750, lr = 0.005
I0522 06:16:54.773726 19460 solver.cpp:237] Iteration 73500, loss = 1.52511
I0522 06:16:54.773761 19460 solver.cpp:253]     Train net output #0: loss = 1.52511 (* 1 = 1.52511 loss)
I0522 06:16:54.773778 19460 sgd_solver.cpp:106] Iteration 73500, lr = 0.005
I0522 06:17:06.917414 19460 solver.cpp:237] Iteration 74250, loss = 1.53398
I0522 06:17:06.917461 19460 solver.cpp:253]     Train net output #0: loss = 1.53398 (* 1 = 1.53398 loss)
I0522 06:17:06.917474 19460 sgd_solver.cpp:106] Iteration 74250, lr = 0.005
I0522 06:17:19.005383 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_75000.caffemodel
I0522 06:17:19.056113 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_75000.solverstate
I0522 06:17:19.085444 19460 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 06:18:11.073227 19460 solver.cpp:409]     Test net output #0: accuracy = 0.883148
I0522 06:18:11.073392 19460 solver.cpp:409]     Test net output #1: loss = 0.395731 (* 1 = 0.395731 loss)
I0522 06:18:31.982493 19460 solver.cpp:237] Iteration 75000, loss = 1.24494
I0522 06:18:31.982545 19460 solver.cpp:253]     Train net output #0: loss = 1.24494 (* 1 = 1.24494 loss)
I0522 06:18:31.982560 19460 sgd_solver.cpp:106] Iteration 75000, lr = 0.005
I0522 06:18:44.145907 19460 solver.cpp:237] Iteration 75750, loss = 1.34169
I0522 06:18:44.146067 19460 solver.cpp:253]     Train net output #0: loss = 1.34169 (* 1 = 1.34169 loss)
I0522 06:18:44.146081 19460 sgd_solver.cpp:106] Iteration 75750, lr = 0.005
I0522 06:18:56.311663 19460 solver.cpp:237] Iteration 76500, loss = 1.1492
I0522 06:18:56.311698 19460 solver.cpp:253]     Train net output #0: loss = 1.1492 (* 1 = 1.1492 loss)
I0522 06:18:56.311714 19460 sgd_solver.cpp:106] Iteration 76500, lr = 0.005
I0522 06:19:08.465586 19460 solver.cpp:237] Iteration 77250, loss = 1.2209
I0522 06:19:08.465636 19460 solver.cpp:253]     Train net output #0: loss = 1.2209 (* 1 = 1.2209 loss)
I0522 06:19:08.465651 19460 sgd_solver.cpp:106] Iteration 77250, lr = 0.005
I0522 06:19:20.672982 19460 solver.cpp:237] Iteration 78000, loss = 1.14093
I0522 06:19:20.673132 19460 solver.cpp:253]     Train net output #0: loss = 1.14093 (* 1 = 1.14093 loss)
I0522 06:19:20.673147 19460 sgd_solver.cpp:106] Iteration 78000, lr = 0.005
I0522 06:19:32.805852 19460 solver.cpp:237] Iteration 78750, loss = 1.60395
I0522 06:19:32.805889 19460 solver.cpp:253]     Train net output #0: loss = 1.60395 (* 1 = 1.60395 loss)
I0522 06:19:32.805902 19460 sgd_solver.cpp:106] Iteration 78750, lr = 0.005
I0522 06:19:44.936583 19460 solver.cpp:237] Iteration 79500, loss = 1.47422
I0522 06:19:44.936630 19460 solver.cpp:253]     Train net output #0: loss = 1.47422 (* 1 = 1.47422 loss)
I0522 06:19:44.936645 19460 sgd_solver.cpp:106] Iteration 79500, lr = 0.005
I0522 06:20:17.944983 19460 solver.cpp:237] Iteration 80250, loss = 1.39834
I0522 06:20:17.945163 19460 solver.cpp:253]     Train net output #0: loss = 1.39834 (* 1 = 1.39834 loss)
I0522 06:20:17.945178 19460 sgd_solver.cpp:106] Iteration 80250, lr = 0.005
I0522 06:20:30.117997 19460 solver.cpp:237] Iteration 81000, loss = 1.22184
I0522 06:20:30.118044 19460 solver.cpp:253]     Train net output #0: loss = 1.22184 (* 1 = 1.22184 loss)
I0522 06:20:30.118059 19460 sgd_solver.cpp:106] Iteration 81000, lr = 0.005
I0522 06:20:42.344733 19460 solver.cpp:237] Iteration 81750, loss = 1.48137
I0522 06:20:42.344769 19460 solver.cpp:253]     Train net output #0: loss = 1.48137 (* 1 = 1.48137 loss)
I0522 06:20:42.344785 19460 sgd_solver.cpp:106] Iteration 81750, lr = 0.005
I0522 06:20:54.500953 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_82500.caffemodel
I0522 06:20:54.550252 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_82500.solverstate
I0522 06:20:54.581778 19460 solver.cpp:237] Iteration 82500, loss = 1.39233
I0522 06:20:54.581817 19460 solver.cpp:253]     Train net output #0: loss = 1.39233 (* 1 = 1.39233 loss)
I0522 06:20:54.581836 19460 sgd_solver.cpp:106] Iteration 82500, lr = 0.005
I0522 06:21:06.766947 19460 solver.cpp:237] Iteration 83250, loss = 1.42419
I0522 06:21:06.766981 19460 solver.cpp:253]     Train net output #0: loss = 1.4242 (* 1 = 1.4242 loss)
I0522 06:21:06.766999 19460 sgd_solver.cpp:106] Iteration 83250, lr = 0.005
I0522 06:21:18.962466 19460 solver.cpp:237] Iteration 84000, loss = 1.01806
I0522 06:21:18.962513 19460 solver.cpp:253]     Train net output #0: loss = 1.01806 (* 1 = 1.01806 loss)
I0522 06:21:18.962527 19460 sgd_solver.cpp:106] Iteration 84000, lr = 0.005
I0522 06:21:31.123775 19460 solver.cpp:237] Iteration 84750, loss = 0.838234
I0522 06:21:31.123927 19460 solver.cpp:253]     Train net output #0: loss = 0.838235 (* 1 = 0.838235 loss)
I0522 06:21:31.123942 19460 sgd_solver.cpp:106] Iteration 84750, lr = 0.005
I0522 06:22:04.175528 19460 solver.cpp:237] Iteration 85500, loss = 1.03939
I0522 06:22:04.175695 19460 solver.cpp:253]     Train net output #0: loss = 1.03939 (* 1 = 1.03939 loss)
I0522 06:22:04.175709 19460 sgd_solver.cpp:106] Iteration 85500, lr = 0.005
I0522 06:22:16.348942 19460 solver.cpp:237] Iteration 86250, loss = 0.740676
I0522 06:22:16.348978 19460 solver.cpp:253]     Train net output #0: loss = 0.740677 (* 1 = 0.740677 loss)
I0522 06:22:16.348995 19460 sgd_solver.cpp:106] Iteration 86250, lr = 0.005
I0522 06:22:28.517952 19460 solver.cpp:237] Iteration 87000, loss = 1.45265
I0522 06:22:28.518002 19460 solver.cpp:253]     Train net output #0: loss = 1.45265 (* 1 = 1.45265 loss)
I0522 06:22:28.518015 19460 sgd_solver.cpp:106] Iteration 87000, lr = 0.005
I0522 06:22:40.688340 19460 solver.cpp:237] Iteration 87750, loss = 1.13334
I0522 06:22:40.688490 19460 solver.cpp:253]     Train net output #0: loss = 1.13334 (* 1 = 1.13334 loss)
I0522 06:22:40.688504 19460 sgd_solver.cpp:106] Iteration 87750, lr = 0.005
I0522 06:22:52.850431 19460 solver.cpp:237] Iteration 88500, loss = 1.35805
I0522 06:22:52.850467 19460 solver.cpp:253]     Train net output #0: loss = 1.35805 (* 1 = 1.35805 loss)
I0522 06:22:52.850483 19460 sgd_solver.cpp:106] Iteration 88500, lr = 0.005
I0522 06:23:05.000627 19460 solver.cpp:237] Iteration 89250, loss = 1.15702
I0522 06:23:05.000672 19460 solver.cpp:253]     Train net output #0: loss = 1.15702 (* 1 = 1.15702 loss)
I0522 06:23:05.000689 19460 sgd_solver.cpp:106] Iteration 89250, lr = 0.005
I0522 06:23:17.094455 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_90000.caffemodel
I0522 06:23:17.143601 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_90000.solverstate
I0522 06:23:17.170277 19460 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 06:24:29.949694 19460 solver.cpp:409]     Test net output #0: accuracy = 0.882311
I0522 06:24:29.949867 19460 solver.cpp:409]     Test net output #1: loss = 0.381065 (* 1 = 0.381065 loss)
I0522 06:24:50.828801 19460 solver.cpp:237] Iteration 90000, loss = 1.36295
I0522 06:24:50.828853 19460 solver.cpp:253]     Train net output #0: loss = 1.36295 (* 1 = 1.36295 loss)
I0522 06:24:50.828876 19460 sgd_solver.cpp:106] Iteration 90000, lr = 0.005
I0522 06:25:02.961890 19460 solver.cpp:237] Iteration 90750, loss = 1.29973
I0522 06:25:02.962059 19460 solver.cpp:253]     Train net output #0: loss = 1.29973 (* 1 = 1.29973 loss)
I0522 06:25:02.962072 19460 sgd_solver.cpp:106] Iteration 90750, lr = 0.005
I0522 06:25:15.096974 19460 solver.cpp:237] Iteration 91500, loss = 1.08778
I0522 06:25:15.097010 19460 solver.cpp:253]     Train net output #0: loss = 1.08778 (* 1 = 1.08778 loss)
I0522 06:25:15.097023 19460 sgd_solver.cpp:106] Iteration 91500, lr = 0.005
I0522 06:25:27.246889 19460 solver.cpp:237] Iteration 92250, loss = 1.08761
I0522 06:25:27.246935 19460 solver.cpp:253]     Train net output #0: loss = 1.08761 (* 1 = 1.08761 loss)
I0522 06:25:27.246951 19460 sgd_solver.cpp:106] Iteration 92250, lr = 0.005
I0522 06:25:39.382521 19460 solver.cpp:237] Iteration 93000, loss = 1.13329
I0522 06:25:39.382673 19460 solver.cpp:253]     Train net output #0: loss = 1.13329 (* 1 = 1.13329 loss)
I0522 06:25:39.382686 19460 sgd_solver.cpp:106] Iteration 93000, lr = 0.005
I0522 06:25:51.542927 19460 solver.cpp:237] Iteration 93750, loss = 1.70584
I0522 06:25:51.542974 19460 solver.cpp:253]     Train net output #0: loss = 1.70584 (* 1 = 1.70584 loss)
I0522 06:25:51.542989 19460 sgd_solver.cpp:106] Iteration 93750, lr = 0.005
I0522 06:26:03.715397 19460 solver.cpp:237] Iteration 94500, loss = 1.23901
I0522 06:26:03.715433 19460 solver.cpp:253]     Train net output #0: loss = 1.23902 (* 1 = 1.23902 loss)
I0522 06:26:03.715450 19460 sgd_solver.cpp:106] Iteration 94500, lr = 0.005
I0522 06:26:36.771342 19460 solver.cpp:237] Iteration 95250, loss = 1.34412
I0522 06:26:36.771515 19460 solver.cpp:253]     Train net output #0: loss = 1.34412 (* 1 = 1.34412 loss)
I0522 06:26:36.771530 19460 sgd_solver.cpp:106] Iteration 95250, lr = 0.005
I0522 06:26:48.955224 19460 solver.cpp:237] Iteration 96000, loss = 1.14947
I0522 06:26:48.955266 19460 solver.cpp:253]     Train net output #0: loss = 1.14948 (* 1 = 1.14948 loss)
I0522 06:26:48.955282 19460 sgd_solver.cpp:106] Iteration 96000, lr = 0.005
I0522 06:27:01.065971 19460 solver.cpp:237] Iteration 96750, loss = 1.36314
I0522 06:27:01.066006 19460 solver.cpp:253]     Train net output #0: loss = 1.36314 (* 1 = 1.36314 loss)
I0522 06:27:01.066022 19460 sgd_solver.cpp:106] Iteration 96750, lr = 0.005
I0522 06:27:13.202940 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_97500.caffemodel
I0522 06:27:13.252081 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_97500.solverstate
I0522 06:27:13.283520 19460 solver.cpp:237] Iteration 97500, loss = 1.05019
I0522 06:27:13.283565 19460 solver.cpp:253]     Train net output #0: loss = 1.0502 (* 1 = 1.0502 loss)
I0522 06:27:13.283581 19460 sgd_solver.cpp:106] Iteration 97500, lr = 0.005
I0522 06:27:25.383728 19460 solver.cpp:237] Iteration 98250, loss = 1.25462
I0522 06:27:25.383764 19460 solver.cpp:253]     Train net output #0: loss = 1.25463 (* 1 = 1.25463 loss)
I0522 06:27:25.383777 19460 sgd_solver.cpp:106] Iteration 98250, lr = 0.005
I0522 06:27:37.558715 19460 solver.cpp:237] Iteration 99000, loss = 1.31743
I0522 06:27:37.558764 19460 solver.cpp:253]     Train net output #0: loss = 1.31743 (* 1 = 1.31743 loss)
I0522 06:27:37.558779 19460 sgd_solver.cpp:106] Iteration 99000, lr = 0.005
I0522 06:27:49.745333 19460 solver.cpp:237] Iteration 99750, loss = 0.987417
I0522 06:27:49.745501 19460 solver.cpp:253]     Train net output #0: loss = 0.987419 (* 1 = 0.987419 loss)
I0522 06:27:49.745514 19460 sgd_solver.cpp:106] Iteration 99750, lr = 0.005
I0522 06:28:22.764765 19460 solver.cpp:237] Iteration 100500, loss = 1.50282
I0522 06:28:22.764946 19460 solver.cpp:253]     Train net output #0: loss = 1.50282 (* 1 = 1.50282 loss)
I0522 06:28:22.764962 19460 sgd_solver.cpp:106] Iteration 100500, lr = 0.005
I0522 06:28:34.903467 19460 solver.cpp:237] Iteration 101250, loss = 1.13954
I0522 06:28:34.903503 19460 solver.cpp:253]     Train net output #0: loss = 1.13955 (* 1 = 1.13955 loss)
I0522 06:28:34.903518 19460 sgd_solver.cpp:106] Iteration 101250, lr = 0.005
I0522 06:28:47.028676 19460 solver.cpp:237] Iteration 102000, loss = 1.32828
I0522 06:28:47.028725 19460 solver.cpp:253]     Train net output #0: loss = 1.32828 (* 1 = 1.32828 loss)
I0522 06:28:47.028738 19460 sgd_solver.cpp:106] Iteration 102000, lr = 0.005
I0522 06:28:59.120221 19460 solver.cpp:237] Iteration 102750, loss = 0.973712
I0522 06:28:59.120374 19460 solver.cpp:253]     Train net output #0: loss = 0.973715 (* 1 = 0.973715 loss)
I0522 06:28:59.120388 19460 sgd_solver.cpp:106] Iteration 102750, lr = 0.005
I0522 06:29:11.203917 19460 solver.cpp:237] Iteration 103500, loss = 0.935432
I0522 06:29:11.203965 19460 solver.cpp:253]     Train net output #0: loss = 0.935434 (* 1 = 0.935434 loss)
I0522 06:29:11.203980 19460 sgd_solver.cpp:106] Iteration 103500, lr = 0.005
I0522 06:29:23.285490 19460 solver.cpp:237] Iteration 104250, loss = 0.889686
I0522 06:29:23.285526 19460 solver.cpp:253]     Train net output #0: loss = 0.889688 (* 1 = 0.889688 loss)
I0522 06:29:23.285543 19460 sgd_solver.cpp:106] Iteration 104250, lr = 0.005
I0522 06:29:35.395023 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_105000.caffemodel
I0522 06:29:35.444216 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_105000.solverstate
I0522 06:29:35.469338 19460 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 06:30:27.146291 19460 solver.cpp:409]     Test net output #0: accuracy = 0.883335
I0522 06:30:27.146458 19460 solver.cpp:409]     Test net output #1: loss = 0.377842 (* 1 = 0.377842 loss)
I0522 06:30:48.034375 19460 solver.cpp:237] Iteration 105000, loss = 1.1068
I0522 06:30:48.034428 19460 solver.cpp:253]     Train net output #0: loss = 1.1068 (* 1 = 1.1068 loss)
I0522 06:30:48.034443 19460 sgd_solver.cpp:106] Iteration 105000, lr = 0.005
I0522 06:31:00.257719 19460 solver.cpp:237] Iteration 105750, loss = 1.14267
I0522 06:31:00.257887 19460 solver.cpp:253]     Train net output #0: loss = 1.14267 (* 1 = 1.14267 loss)
I0522 06:31:00.257901 19460 sgd_solver.cpp:106] Iteration 105750, lr = 0.005
I0522 06:31:12.478173 19460 solver.cpp:237] Iteration 106500, loss = 1.0012
I0522 06:31:12.478207 19460 solver.cpp:253]     Train net output #0: loss = 1.00121 (* 1 = 1.00121 loss)
I0522 06:31:12.478221 19460 sgd_solver.cpp:106] Iteration 106500, lr = 0.005
I0522 06:31:24.692700 19460 solver.cpp:237] Iteration 107250, loss = 1.10195
I0522 06:31:24.692741 19460 solver.cpp:253]     Train net output #0: loss = 1.10195 (* 1 = 1.10195 loss)
I0522 06:31:24.692759 19460 sgd_solver.cpp:106] Iteration 107250, lr = 0.005
I0522 06:31:36.884515 19460 solver.cpp:237] Iteration 108000, loss = 0.660675
I0522 06:31:36.884677 19460 solver.cpp:253]     Train net output #0: loss = 0.660677 (* 1 = 0.660677 loss)
I0522 06:31:36.884693 19460 sgd_solver.cpp:106] Iteration 108000, lr = 0.005
I0522 06:31:48.999387 19460 solver.cpp:237] Iteration 108750, loss = 1.18487
I0522 06:31:48.999430 19460 solver.cpp:253]     Train net output #0: loss = 1.18487 (* 1 = 1.18487 loss)
I0522 06:31:48.999445 19460 sgd_solver.cpp:106] Iteration 108750, lr = 0.005
I0522 06:32:01.108095 19460 solver.cpp:237] Iteration 109500, loss = 1.26993
I0522 06:32:01.108130 19460 solver.cpp:253]     Train net output #0: loss = 1.26993 (* 1 = 1.26993 loss)
I0522 06:32:01.108147 19460 sgd_solver.cpp:106] Iteration 109500, lr = 0.005
I0522 06:32:34.114161 19460 solver.cpp:237] Iteration 110250, loss = 1.6526
I0522 06:32:34.114339 19460 solver.cpp:253]     Train net output #0: loss = 1.65261 (* 1 = 1.65261 loss)
I0522 06:32:34.114354 19460 sgd_solver.cpp:106] Iteration 110250, lr = 0.005
I0522 06:32:46.231549 19460 solver.cpp:237] Iteration 111000, loss = 1.25827
I0522 06:32:46.231585 19460 solver.cpp:253]     Train net output #0: loss = 1.25828 (* 1 = 1.25828 loss)
I0522 06:32:46.231601 19460 sgd_solver.cpp:106] Iteration 111000, lr = 0.005
I0522 06:32:58.347224 19460 solver.cpp:237] Iteration 111750, loss = 0.919135
I0522 06:32:58.347275 19460 solver.cpp:253]     Train net output #0: loss = 0.919137 (* 1 = 0.919137 loss)
I0522 06:32:58.347288 19460 sgd_solver.cpp:106] Iteration 111750, lr = 0.005
I0522 06:33:10.443882 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_112500.caffemodel
I0522 06:33:10.494587 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_112500.solverstate
I0522 06:33:10.526533 19460 solver.cpp:237] Iteration 112500, loss = 1.09588
I0522 06:33:10.526584 19460 solver.cpp:253]     Train net output #0: loss = 1.09589 (* 1 = 1.09589 loss)
I0522 06:33:10.526598 19460 sgd_solver.cpp:106] Iteration 112500, lr = 0.005
I0522 06:33:22.668620 19460 solver.cpp:237] Iteration 113250, loss = 1.31926
I0522 06:33:22.668669 19460 solver.cpp:253]     Train net output #0: loss = 1.31926 (* 1 = 1.31926 loss)
I0522 06:33:22.668684 19460 sgd_solver.cpp:106] Iteration 113250, lr = 0.005
I0522 06:33:34.870918 19460 solver.cpp:237] Iteration 114000, loss = 1.21015
I0522 06:33:34.870954 19460 solver.cpp:253]     Train net output #0: loss = 1.21016 (* 1 = 1.21016 loss)
I0522 06:33:34.870967 19460 sgd_solver.cpp:106] Iteration 114000, lr = 0.005
I0522 06:33:47.070672 19460 solver.cpp:237] Iteration 114750, loss = 1.14236
I0522 06:33:47.070842 19460 solver.cpp:253]     Train net output #0: loss = 1.14236 (* 1 = 1.14236 loss)
I0522 06:33:47.070858 19460 sgd_solver.cpp:106] Iteration 114750, lr = 0.005
I0522 06:34:20.165307 19460 solver.cpp:237] Iteration 115500, loss = 1.12865
I0522 06:34:20.165482 19460 solver.cpp:253]     Train net output #0: loss = 1.12866 (* 1 = 1.12866 loss)
I0522 06:34:20.165498 19460 sgd_solver.cpp:106] Iteration 115500, lr = 0.005
I0522 06:34:32.345717 19460 solver.cpp:237] Iteration 116250, loss = 1.18975
I0522 06:34:32.345753 19460 solver.cpp:253]     Train net output #0: loss = 1.18975 (* 1 = 1.18975 loss)
I0522 06:34:32.345770 19460 sgd_solver.cpp:106] Iteration 116250, lr = 0.005
I0522 06:34:44.535557 19460 solver.cpp:237] Iteration 117000, loss = 1.62771
I0522 06:34:44.535598 19460 solver.cpp:253]     Train net output #0: loss = 1.62771 (* 1 = 1.62771 loss)
I0522 06:34:44.535615 19460 sgd_solver.cpp:106] Iteration 117000, lr = 0.005
I0522 06:34:56.695211 19460 solver.cpp:237] Iteration 117750, loss = 1.14867
I0522 06:34:56.695363 19460 solver.cpp:253]     Train net output #0: loss = 1.14867 (* 1 = 1.14867 loss)
I0522 06:34:56.695377 19460 sgd_solver.cpp:106] Iteration 117750, lr = 0.005
I0522 06:35:08.849622 19460 solver.cpp:237] Iteration 118500, loss = 0.980099
I0522 06:35:08.849666 19460 solver.cpp:253]     Train net output #0: loss = 0.9801 (* 1 = 0.9801 loss)
I0522 06:35:08.849681 19460 sgd_solver.cpp:106] Iteration 118500, lr = 0.005
I0522 06:35:21.005216 19460 solver.cpp:237] Iteration 119250, loss = 1.10448
I0522 06:35:21.005252 19460 solver.cpp:253]     Train net output #0: loss = 1.10448 (* 1 = 1.10448 loss)
I0522 06:35:21.005265 19460 sgd_solver.cpp:106] Iteration 119250, lr = 0.005
I0522 06:35:33.186724 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_120000.caffemodel
I0522 06:35:33.240525 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_120000.solverstate
I0522 06:35:33.265504 19460 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 06:36:46.175835 19460 solver.cpp:409]     Test net output #0: accuracy = 0.888564
I0522 06:36:46.176008 19460 solver.cpp:409]     Test net output #1: loss = 0.382564 (* 1 = 0.382564 loss)
I0522 06:37:07.062438 19460 solver.cpp:237] Iteration 120000, loss = 1.08854
I0522 06:37:07.062490 19460 solver.cpp:253]     Train net output #0: loss = 1.08854 (* 1 = 1.08854 loss)
I0522 06:37:07.062505 19460 sgd_solver.cpp:106] Iteration 120000, lr = 0.005
I0522 06:37:19.171792 19460 solver.cpp:237] Iteration 120750, loss = 0.957916
I0522 06:37:19.171952 19460 solver.cpp:253]     Train net output #0: loss = 0.957917 (* 1 = 0.957917 loss)
I0522 06:37:19.171967 19460 sgd_solver.cpp:106] Iteration 120750, lr = 0.005
I0522 06:37:31.283363 19460 solver.cpp:237] Iteration 121500, loss = 2.27552
I0522 06:37:31.283407 19460 solver.cpp:253]     Train net output #0: loss = 2.27552 (* 1 = 2.27552 loss)
I0522 06:37:31.283423 19460 sgd_solver.cpp:106] Iteration 121500, lr = 0.005
I0522 06:37:43.397449 19460 solver.cpp:237] Iteration 122250, loss = 1.81153
I0522 06:37:43.397485 19460 solver.cpp:253]     Train net output #0: loss = 1.81153 (* 1 = 1.81153 loss)
I0522 06:37:43.397502 19460 sgd_solver.cpp:106] Iteration 122250, lr = 0.005
I0522 06:37:55.503059 19460 solver.cpp:237] Iteration 123000, loss = 1.02507
I0522 06:37:55.503224 19460 solver.cpp:253]     Train net output #0: loss = 1.02507 (* 1 = 1.02507 loss)
I0522 06:37:55.503239 19460 sgd_solver.cpp:106] Iteration 123000, lr = 0.005
I0522 06:38:07.612970 19460 solver.cpp:237] Iteration 123750, loss = 1.06953
I0522 06:38:07.613006 19460 solver.cpp:253]     Train net output #0: loss = 1.06953 (* 1 = 1.06953 loss)
I0522 06:38:07.613023 19460 sgd_solver.cpp:106] Iteration 123750, lr = 0.005
I0522 06:38:19.718425 19460 solver.cpp:237] Iteration 124500, loss = 1.08521
I0522 06:38:19.718463 19460 solver.cpp:253]     Train net output #0: loss = 1.08521 (* 1 = 1.08521 loss)
I0522 06:38:19.718482 19460 sgd_solver.cpp:106] Iteration 124500, lr = 0.005
I0522 06:38:52.688375 19460 solver.cpp:237] Iteration 125250, loss = 1.16968
I0522 06:38:52.688552 19460 solver.cpp:253]     Train net output #0: loss = 1.16968 (* 1 = 1.16968 loss)
I0522 06:38:52.688566 19460 sgd_solver.cpp:106] Iteration 125250, lr = 0.005
I0522 06:39:04.796398 19460 solver.cpp:237] Iteration 126000, loss = 0.962242
I0522 06:39:04.796434 19460 solver.cpp:253]     Train net output #0: loss = 0.962242 (* 1 = 0.962242 loss)
I0522 06:39:04.796452 19460 sgd_solver.cpp:106] Iteration 126000, lr = 0.005
I0522 06:39:16.920161 19460 solver.cpp:237] Iteration 126750, loss = 1.33706
I0522 06:39:16.920210 19460 solver.cpp:253]     Train net output #0: loss = 1.33706 (* 1 = 1.33706 loss)
I0522 06:39:16.920224 19460 sgd_solver.cpp:106] Iteration 126750, lr = 0.005
I0522 06:39:29.036095 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_127500.caffemodel
I0522 06:39:29.085404 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_127500.solverstate
I0522 06:39:29.115439 19460 solver.cpp:237] Iteration 127500, loss = 1.69492
I0522 06:39:29.115483 19460 solver.cpp:253]     Train net output #0: loss = 1.69492 (* 1 = 1.69492 loss)
I0522 06:39:29.115497 19460 sgd_solver.cpp:106] Iteration 127500, lr = 0.005
I0522 06:39:41.240381 19460 solver.cpp:237] Iteration 128250, loss = 1.60617
I0522 06:39:41.240428 19460 solver.cpp:253]     Train net output #0: loss = 1.60617 (* 1 = 1.60617 loss)
I0522 06:39:41.240442 19460 sgd_solver.cpp:106] Iteration 128250, lr = 0.005
I0522 06:39:53.377014 19460 solver.cpp:237] Iteration 129000, loss = 1.11856
I0522 06:39:53.377050 19460 solver.cpp:253]     Train net output #0: loss = 1.11856 (* 1 = 1.11856 loss)
I0522 06:39:53.377066 19460 sgd_solver.cpp:106] Iteration 129000, lr = 0.005
I0522 06:40:05.530030 19460 solver.cpp:237] Iteration 129750, loss = 1.3039
I0522 06:40:05.530215 19460 solver.cpp:253]     Train net output #0: loss = 1.3039 (* 1 = 1.3039 loss)
I0522 06:40:05.530230 19460 sgd_solver.cpp:106] Iteration 129750, lr = 0.005
I0522 06:40:38.592622 19460 solver.cpp:237] Iteration 130500, loss = 1.55778
I0522 06:40:38.592803 19460 solver.cpp:253]     Train net output #0: loss = 1.55778 (* 1 = 1.55778 loss)
I0522 06:40:38.592818 19460 sgd_solver.cpp:106] Iteration 130500, lr = 0.005
I0522 06:40:50.751840 19460 solver.cpp:237] Iteration 131250, loss = 1.58839
I0522 06:40:50.751884 19460 solver.cpp:253]     Train net output #0: loss = 1.58839 (* 1 = 1.58839 loss)
I0522 06:40:50.751899 19460 sgd_solver.cpp:106] Iteration 131250, lr = 0.005
I0522 06:41:02.900022 19460 solver.cpp:237] Iteration 132000, loss = 1.22916
I0522 06:41:02.900058 19460 solver.cpp:253]     Train net output #0: loss = 1.22916 (* 1 = 1.22916 loss)
I0522 06:41:02.900071 19460 sgd_solver.cpp:106] Iteration 132000, lr = 0.005
I0522 06:41:15.036064 19460 solver.cpp:237] Iteration 132750, loss = 1.16755
I0522 06:41:15.036227 19460 solver.cpp:253]     Train net output #0: loss = 1.16755 (* 1 = 1.16755 loss)
I0522 06:41:15.036242 19460 sgd_solver.cpp:106] Iteration 132750, lr = 0.005
I0522 06:41:27.173435 19460 solver.cpp:237] Iteration 133500, loss = 0.732816
I0522 06:41:27.173472 19460 solver.cpp:253]     Train net output #0: loss = 0.732816 (* 1 = 0.732816 loss)
I0522 06:41:27.173488 19460 sgd_solver.cpp:106] Iteration 133500, lr = 0.005
I0522 06:41:39.278085 19460 solver.cpp:237] Iteration 134250, loss = 1.5414
I0522 06:41:39.278129 19460 solver.cpp:253]     Train net output #0: loss = 1.5414 (* 1 = 1.5414 loss)
I0522 06:41:39.278151 19460 sgd_solver.cpp:106] Iteration 134250, lr = 0.005
I0522 06:41:51.382062 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_135000.caffemodel
I0522 06:41:51.431121 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_135000.solverstate
I0522 06:41:51.456498 19460 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 06:42:43.467177 19460 solver.cpp:409]     Test net output #0: accuracy = 0.883907
I0522 06:42:43.467351 19460 solver.cpp:409]     Test net output #1: loss = 0.366004 (* 1 = 0.366004 loss)
I0522 06:43:04.334059 19460 solver.cpp:237] Iteration 135000, loss = 1.2322
I0522 06:43:04.334112 19460 solver.cpp:253]     Train net output #0: loss = 1.2322 (* 1 = 1.2322 loss)
I0522 06:43:04.334127 19460 sgd_solver.cpp:106] Iteration 135000, lr = 0.005
I0522 06:43:16.451509 19460 solver.cpp:237] Iteration 135750, loss = 1.17877
I0522 06:43:16.451674 19460 solver.cpp:253]     Train net output #0: loss = 1.17877 (* 1 = 1.17877 loss)
I0522 06:43:16.451689 19460 sgd_solver.cpp:106] Iteration 135750, lr = 0.005
I0522 06:43:28.619839 19460 solver.cpp:237] Iteration 136500, loss = 1.1384
I0522 06:43:28.619887 19460 solver.cpp:253]     Train net output #0: loss = 1.1384 (* 1 = 1.1384 loss)
I0522 06:43:28.619900 19460 sgd_solver.cpp:106] Iteration 136500, lr = 0.005
I0522 06:43:40.803935 19460 solver.cpp:237] Iteration 137250, loss = 0.854569
I0522 06:43:40.803971 19460 solver.cpp:253]     Train net output #0: loss = 0.854569 (* 1 = 0.854569 loss)
I0522 06:43:40.803987 19460 sgd_solver.cpp:106] Iteration 137250, lr = 0.005
I0522 06:43:52.976402 19460 solver.cpp:237] Iteration 138000, loss = 1.32143
I0522 06:43:52.976588 19460 solver.cpp:253]     Train net output #0: loss = 1.32143 (* 1 = 1.32143 loss)
I0522 06:43:52.976604 19460 sgd_solver.cpp:106] Iteration 138000, lr = 0.005
I0522 06:44:05.146514 19460 solver.cpp:237] Iteration 138750, loss = 1.05406
I0522 06:44:05.146550 19460 solver.cpp:253]     Train net output #0: loss = 1.05406 (* 1 = 1.05406 loss)
I0522 06:44:05.146566 19460 sgd_solver.cpp:106] Iteration 138750, lr = 0.005
I0522 06:44:17.295258 19460 solver.cpp:237] Iteration 139500, loss = 1.30401
I0522 06:44:17.295303 19460 solver.cpp:253]     Train net output #0: loss = 1.30401 (* 1 = 1.30401 loss)
I0522 06:44:17.295320 19460 sgd_solver.cpp:106] Iteration 139500, lr = 0.005
I0522 06:44:50.365118 19460 solver.cpp:237] Iteration 140250, loss = 1.0306
I0522 06:44:50.365283 19460 solver.cpp:253]     Train net output #0: loss = 1.0306 (* 1 = 1.0306 loss)
I0522 06:44:50.365298 19460 sgd_solver.cpp:106] Iteration 140250, lr = 0.005
I0522 06:45:02.459590 19460 solver.cpp:237] Iteration 141000, loss = 0.875697
I0522 06:45:02.459638 19460 solver.cpp:253]     Train net output #0: loss = 0.875698 (* 1 = 0.875698 loss)
I0522 06:45:02.459652 19460 sgd_solver.cpp:106] Iteration 141000, lr = 0.005
I0522 06:45:14.555670 19460 solver.cpp:237] Iteration 141750, loss = 1.12237
I0522 06:45:14.555706 19460 solver.cpp:253]     Train net output #0: loss = 1.12237 (* 1 = 1.12237 loss)
I0522 06:45:14.555722 19460 sgd_solver.cpp:106] Iteration 141750, lr = 0.005
I0522 06:45:26.627629 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_142500.caffemodel
I0522 06:45:26.679469 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_142500.solverstate
I0522 06:45:26.711313 19460 solver.cpp:237] Iteration 142500, loss = 1.32743
I0522 06:45:26.711357 19460 solver.cpp:253]     Train net output #0: loss = 1.32743 (* 1 = 1.32743 loss)
I0522 06:45:26.711374 19460 sgd_solver.cpp:106] Iteration 142500, lr = 0.005
I0522 06:45:38.802404 19460 solver.cpp:237] Iteration 143250, loss = 1.15702
I0522 06:45:38.802440 19460 solver.cpp:253]     Train net output #0: loss = 1.15702 (* 1 = 1.15702 loss)
I0522 06:45:38.802453 19460 sgd_solver.cpp:106] Iteration 143250, lr = 0.005
I0522 06:45:50.951642 19460 solver.cpp:237] Iteration 144000, loss = 1.75168
I0522 06:45:50.951689 19460 solver.cpp:253]     Train net output #0: loss = 1.75168 (* 1 = 1.75168 loss)
I0522 06:45:50.951704 19460 sgd_solver.cpp:106] Iteration 144000, lr = 0.005
I0522 06:46:03.097111 19460 solver.cpp:237] Iteration 144750, loss = 0.994158
I0522 06:46:03.097275 19460 solver.cpp:253]     Train net output #0: loss = 0.994159 (* 1 = 0.994159 loss)
I0522 06:46:03.097288 19460 sgd_solver.cpp:106] Iteration 144750, lr = 0.005
I0522 06:46:36.164146 19460 solver.cpp:237] Iteration 145500, loss = 1.25274
I0522 06:46:36.164329 19460 solver.cpp:253]     Train net output #0: loss = 1.25274 (* 1 = 1.25274 loss)
I0522 06:46:36.164343 19460 sgd_solver.cpp:106] Iteration 145500, lr = 0.005
I0522 06:46:48.286201 19460 solver.cpp:237] Iteration 146250, loss = 1.24106
I0522 06:46:48.286250 19460 solver.cpp:253]     Train net output #0: loss = 1.24106 (* 1 = 1.24106 loss)
I0522 06:46:48.286263 19460 sgd_solver.cpp:106] Iteration 146250, lr = 0.005
I0522 06:47:00.400084 19460 solver.cpp:237] Iteration 147000, loss = 0.893344
I0522 06:47:00.400121 19460 solver.cpp:253]     Train net output #0: loss = 0.893345 (* 1 = 0.893345 loss)
I0522 06:47:00.400135 19460 sgd_solver.cpp:106] Iteration 147000, lr = 0.005
I0522 06:47:12.519867 19460 solver.cpp:237] Iteration 147750, loss = 1.07466
I0522 06:47:12.520051 19460 solver.cpp:253]     Train net output #0: loss = 1.07466 (* 1 = 1.07466 loss)
I0522 06:47:12.520066 19460 sgd_solver.cpp:106] Iteration 147750, lr = 0.005
I0522 06:47:24.651502 19460 solver.cpp:237] Iteration 148500, loss = 1.19707
I0522 06:47:24.651540 19460 solver.cpp:253]     Train net output #0: loss = 1.19707 (* 1 = 1.19707 loss)
I0522 06:47:24.651556 19460 sgd_solver.cpp:106] Iteration 148500, lr = 0.005
I0522 06:47:36.778746 19460 solver.cpp:237] Iteration 149250, loss = 1.22965
I0522 06:47:36.778795 19460 solver.cpp:253]     Train net output #0: loss = 1.22965 (* 1 = 1.22965 loss)
I0522 06:47:36.778810 19460 sgd_solver.cpp:106] Iteration 149250, lr = 0.005
I0522 06:47:48.888977 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_150000.caffemodel
I0522 06:47:48.939911 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_150000.solverstate
I0522 06:47:48.966892 19460 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 06:49:01.958647 19460 solver.cpp:409]     Test net output #0: accuracy = 0.890451
I0522 06:49:01.958825 19460 solver.cpp:409]     Test net output #1: loss = 0.353652 (* 1 = 0.353652 loss)
I0522 06:49:22.852618 19460 solver.cpp:237] Iteration 150000, loss = 1.14428
I0522 06:49:22.852672 19460 solver.cpp:253]     Train net output #0: loss = 1.14428 (* 1 = 1.14428 loss)
I0522 06:49:22.852687 19460 sgd_solver.cpp:106] Iteration 150000, lr = 0.005
I0522 06:49:34.932615 19460 solver.cpp:237] Iteration 150750, loss = 1.20622
I0522 06:49:34.932790 19460 solver.cpp:253]     Train net output #0: loss = 1.20622 (* 1 = 1.20622 loss)
I0522 06:49:34.932804 19460 sgd_solver.cpp:106] Iteration 150750, lr = 0.005
I0522 06:49:47.011889 19460 solver.cpp:237] Iteration 151500, loss = 0.902515
I0522 06:49:47.011926 19460 solver.cpp:253]     Train net output #0: loss = 0.902515 (* 1 = 0.902515 loss)
I0522 06:49:47.011943 19460 sgd_solver.cpp:106] Iteration 151500, lr = 0.005
I0522 06:49:59.115741 19460 solver.cpp:237] Iteration 152250, loss = 1.01124
I0522 06:49:59.115783 19460 solver.cpp:253]     Train net output #0: loss = 1.01124 (* 1 = 1.01124 loss)
I0522 06:49:59.115803 19460 sgd_solver.cpp:106] Iteration 152250, lr = 0.005
I0522 06:50:11.209972 19460 solver.cpp:237] Iteration 153000, loss = 0.714333
I0522 06:50:11.210127 19460 solver.cpp:253]     Train net output #0: loss = 0.714333 (* 1 = 0.714333 loss)
I0522 06:50:11.210144 19460 sgd_solver.cpp:106] Iteration 153000, lr = 0.005
I0522 06:50:23.328446 19460 solver.cpp:237] Iteration 153750, loss = 1.2195
I0522 06:50:23.328482 19460 solver.cpp:253]     Train net output #0: loss = 1.2195 (* 1 = 1.2195 loss)
I0522 06:50:23.328496 19460 sgd_solver.cpp:106] Iteration 153750, lr = 0.005
I0522 06:50:35.394985 19460 solver.cpp:237] Iteration 154500, loss = 1.76899
I0522 06:50:35.395032 19460 solver.cpp:253]     Train net output #0: loss = 1.76899 (* 1 = 1.76899 loss)
I0522 06:50:35.395047 19460 sgd_solver.cpp:106] Iteration 154500, lr = 0.005
I0522 06:51:08.399979 19460 solver.cpp:237] Iteration 155250, loss = 1.59573
I0522 06:51:08.400159 19460 solver.cpp:253]     Train net output #0: loss = 1.59573 (* 1 = 1.59573 loss)
I0522 06:51:08.400176 19460 sgd_solver.cpp:106] Iteration 155250, lr = 0.005
I0522 06:51:20.504083 19460 solver.cpp:237] Iteration 156000, loss = 1.32331
I0522 06:51:20.504127 19460 solver.cpp:253]     Train net output #0: loss = 1.32331 (* 1 = 1.32331 loss)
I0522 06:51:20.504145 19460 sgd_solver.cpp:106] Iteration 156000, lr = 0.005
I0522 06:51:32.640040 19460 solver.cpp:237] Iteration 156750, loss = 1.6725
I0522 06:51:32.640076 19460 solver.cpp:253]     Train net output #0: loss = 1.6725 (* 1 = 1.6725 loss)
I0522 06:51:32.640092 19460 sgd_solver.cpp:106] Iteration 156750, lr = 0.005
I0522 06:51:44.758842 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_157500.caffemodel
I0522 06:51:44.808167 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_157500.solverstate
I0522 06:51:44.839612 19460 solver.cpp:237] Iteration 157500, loss = 1.00571
I0522 06:51:44.839655 19460 solver.cpp:253]     Train net output #0: loss = 1.00571 (* 1 = 1.00571 loss)
I0522 06:51:44.839669 19460 sgd_solver.cpp:106] Iteration 157500, lr = 0.005
I0522 06:51:56.991546 19460 solver.cpp:237] Iteration 158250, loss = 1.06994
I0522 06:51:56.991582 19460 solver.cpp:253]     Train net output #0: loss = 1.06994 (* 1 = 1.06994 loss)
I0522 06:51:56.991600 19460 sgd_solver.cpp:106] Iteration 158250, lr = 0.005
I0522 06:52:09.130065 19460 solver.cpp:237] Iteration 159000, loss = 0.889809
I0522 06:52:09.130115 19460 solver.cpp:253]     Train net output #0: loss = 0.889809 (* 1 = 0.889809 loss)
I0522 06:52:09.130131 19460 sgd_solver.cpp:106] Iteration 159000, lr = 0.005
I0522 06:52:21.265769 19460 solver.cpp:237] Iteration 159750, loss = 0.897373
I0522 06:52:21.265934 19460 solver.cpp:253]     Train net output #0: loss = 0.897373 (* 1 = 0.897373 loss)
I0522 06:52:21.265949 19460 sgd_solver.cpp:106] Iteration 159750, lr = 0.005
I0522 06:52:54.241869 19460 solver.cpp:237] Iteration 160500, loss = 1.28888
I0522 06:52:54.242046 19460 solver.cpp:253]     Train net output #0: loss = 1.28888 (* 1 = 1.28888 loss)
I0522 06:52:54.242060 19460 sgd_solver.cpp:106] Iteration 160500, lr = 0.005
I0522 06:53:06.291002 19460 solver.cpp:237] Iteration 161250, loss = 0.996185
I0522 06:53:06.291038 19460 solver.cpp:253]     Train net output #0: loss = 0.996184 (* 1 = 0.996184 loss)
I0522 06:53:06.291055 19460 sgd_solver.cpp:106] Iteration 161250, lr = 0.005
I0522 06:53:18.338533 19460 solver.cpp:237] Iteration 162000, loss = 1.13055
I0522 06:53:18.338569 19460 solver.cpp:253]     Train net output #0: loss = 1.13055 (* 1 = 1.13055 loss)
I0522 06:53:18.338585 19460 sgd_solver.cpp:106] Iteration 162000, lr = 0.005
I0522 06:53:30.386251 19460 solver.cpp:237] Iteration 162750, loss = 1.2944
I0522 06:53:30.386418 19460 solver.cpp:253]     Train net output #0: loss = 1.2944 (* 1 = 1.2944 loss)
I0522 06:53:30.386432 19460 sgd_solver.cpp:106] Iteration 162750, lr = 0.005
I0522 06:53:42.431808 19460 solver.cpp:237] Iteration 163500, loss = 1.41009
I0522 06:53:42.431843 19460 solver.cpp:253]     Train net output #0: loss = 1.41009 (* 1 = 1.41009 loss)
I0522 06:53:42.431860 19460 sgd_solver.cpp:106] Iteration 163500, lr = 0.005
I0522 06:53:54.486419 19460 solver.cpp:237] Iteration 164250, loss = 1.18665
I0522 06:53:54.486459 19460 solver.cpp:253]     Train net output #0: loss = 1.18665 (* 1 = 1.18665 loss)
I0522 06:53:54.486477 19460 sgd_solver.cpp:106] Iteration 164250, lr = 0.005
I0522 06:54:06.517964 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_165000.caffemodel
I0522 06:54:06.566853 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_165000.solverstate
I0522 06:54:06.591886 19460 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 06:54:58.324503 19460 solver.cpp:409]     Test net output #0: accuracy = 0.890649
I0522 06:54:58.324684 19460 solver.cpp:409]     Test net output #1: loss = 0.344808 (* 1 = 0.344808 loss)
I0522 06:55:19.223383 19460 solver.cpp:237] Iteration 165000, loss = 0.675782
I0522 06:55:19.223436 19460 solver.cpp:253]     Train net output #0: loss = 0.675782 (* 1 = 0.675782 loss)
I0522 06:55:19.223451 19460 sgd_solver.cpp:106] Iteration 165000, lr = 0.005
I0522 06:55:31.345798 19460 solver.cpp:237] Iteration 165750, loss = 1.27416
I0522 06:55:31.345984 19460 solver.cpp:253]     Train net output #0: loss = 1.27416 (* 1 = 1.27416 loss)
I0522 06:55:31.345999 19460 sgd_solver.cpp:106] Iteration 165750, lr = 0.005
I0522 06:55:43.515661 19460 solver.cpp:237] Iteration 166500, loss = 1.14982
I0522 06:55:43.515697 19460 solver.cpp:253]     Train net output #0: loss = 1.14982 (* 1 = 1.14982 loss)
I0522 06:55:43.515714 19460 sgd_solver.cpp:106] Iteration 166500, lr = 0.005
I0522 06:55:55.634855 19460 solver.cpp:237] Iteration 167250, loss = 1.1634
I0522 06:55:55.634904 19460 solver.cpp:253]     Train net output #0: loss = 1.1634 (* 1 = 1.1634 loss)
I0522 06:55:55.634919 19460 sgd_solver.cpp:106] Iteration 167250, lr = 0.005
I0522 06:56:07.787080 19460 solver.cpp:237] Iteration 168000, loss = 1.02341
I0522 06:56:07.787242 19460 solver.cpp:253]     Train net output #0: loss = 1.02341 (* 1 = 1.02341 loss)
I0522 06:56:07.787257 19460 sgd_solver.cpp:106] Iteration 168000, lr = 0.005
I0522 06:56:19.933085 19460 solver.cpp:237] Iteration 168750, loss = 1.07559
I0522 06:56:19.933131 19460 solver.cpp:253]     Train net output #0: loss = 1.07559 (* 1 = 1.07559 loss)
I0522 06:56:19.933145 19460 sgd_solver.cpp:106] Iteration 168750, lr = 0.005
I0522 06:56:32.088227 19460 solver.cpp:237] Iteration 169500, loss = 1.35898
I0522 06:56:32.088263 19460 solver.cpp:253]     Train net output #0: loss = 1.35898 (* 1 = 1.35898 loss)
I0522 06:56:32.088279 19460 sgd_solver.cpp:106] Iteration 169500, lr = 0.005
I0522 06:57:05.119539 19460 solver.cpp:237] Iteration 170250, loss = 1.29206
I0522 06:57:05.119719 19460 solver.cpp:253]     Train net output #0: loss = 1.29206 (* 1 = 1.29206 loss)
I0522 06:57:05.119734 19460 sgd_solver.cpp:106] Iteration 170250, lr = 0.005
I0522 06:57:17.242585 19460 solver.cpp:237] Iteration 171000, loss = 1.03338
I0522 06:57:17.242622 19460 solver.cpp:253]     Train net output #0: loss = 1.03338 (* 1 = 1.03338 loss)
I0522 06:57:17.242638 19460 sgd_solver.cpp:106] Iteration 171000, lr = 0.005
I0522 06:57:29.392596 19460 solver.cpp:237] Iteration 171750, loss = 1.43396
I0522 06:57:29.392643 19460 solver.cpp:253]     Train net output #0: loss = 1.43396 (* 1 = 1.43396 loss)
I0522 06:57:29.392658 19460 sgd_solver.cpp:106] Iteration 171750, lr = 0.005
I0522 06:57:41.500530 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_172500.caffemodel
I0522 06:57:41.550397 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_172500.solverstate
I0522 06:57:41.580989 19460 solver.cpp:237] Iteration 172500, loss = 1.28805
I0522 06:57:41.581034 19460 solver.cpp:253]     Train net output #0: loss = 1.28805 (* 1 = 1.28805 loss)
I0522 06:57:41.581049 19460 sgd_solver.cpp:106] Iteration 172500, lr = 0.005
I0522 06:57:53.669762 19460 solver.cpp:237] Iteration 173250, loss = 1.17099
I0522 06:57:53.669809 19460 solver.cpp:253]     Train net output #0: loss = 1.17099 (* 1 = 1.17099 loss)
I0522 06:57:53.669826 19460 sgd_solver.cpp:106] Iteration 173250, lr = 0.005
I0522 06:58:05.760368 19460 solver.cpp:237] Iteration 174000, loss = 1.02316
I0522 06:58:05.760406 19460 solver.cpp:253]     Train net output #0: loss = 1.02316 (* 1 = 1.02316 loss)
I0522 06:58:05.760421 19460 sgd_solver.cpp:106] Iteration 174000, lr = 0.005
I0522 06:58:17.847139 19460 solver.cpp:237] Iteration 174750, loss = 1.50642
I0522 06:58:17.847306 19460 solver.cpp:253]     Train net output #0: loss = 1.50643 (* 1 = 1.50643 loss)
I0522 06:58:17.847321 19460 sgd_solver.cpp:106] Iteration 174750, lr = 0.005
I0522 06:58:50.945430 19460 solver.cpp:237] Iteration 175500, loss = 1.60856
I0522 06:58:50.945621 19460 solver.cpp:253]     Train net output #0: loss = 1.60856 (* 1 = 1.60856 loss)
I0522 06:58:50.945637 19460 sgd_solver.cpp:106] Iteration 175500, lr = 0.005
I0522 06:59:03.080759 19460 solver.cpp:237] Iteration 176250, loss = 1.07779
I0522 06:59:03.080795 19460 solver.cpp:253]     Train net output #0: loss = 1.07779 (* 1 = 1.07779 loss)
I0522 06:59:03.080811 19460 sgd_solver.cpp:106] Iteration 176250, lr = 0.005
I0522 06:59:15.164476 19460 solver.cpp:237] Iteration 177000, loss = 1.4092
I0522 06:59:15.164525 19460 solver.cpp:253]     Train net output #0: loss = 1.4092 (* 1 = 1.4092 loss)
I0522 06:59:15.164538 19460 sgd_solver.cpp:106] Iteration 177000, lr = 0.005
I0522 06:59:27.257308 19460 solver.cpp:237] Iteration 177750, loss = 0.977102
I0522 06:59:27.257483 19460 solver.cpp:253]     Train net output #0: loss = 0.977103 (* 1 = 0.977103 loss)
I0522 06:59:27.257498 19460 sgd_solver.cpp:106] Iteration 177750, lr = 0.005
I0522 06:59:39.343988 19460 solver.cpp:237] Iteration 178500, loss = 1.12548
I0522 06:59:39.344034 19460 solver.cpp:253]     Train net output #0: loss = 1.12548 (* 1 = 1.12548 loss)
I0522 06:59:39.344049 19460 sgd_solver.cpp:106] Iteration 178500, lr = 0.005
I0522 06:59:51.432592 19460 solver.cpp:237] Iteration 179250, loss = 0.847733
I0522 06:59:51.432629 19460 solver.cpp:253]     Train net output #0: loss = 0.847734 (* 1 = 0.847734 loss)
I0522 06:59:51.432646 19460 sgd_solver.cpp:106] Iteration 179250, lr = 0.005
I0522 07:00:03.498770 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_180000.caffemodel
I0522 07:00:03.548022 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_180000.solverstate
I0522 07:00:03.573072 19460 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 07:01:16.399564 19460 solver.cpp:409]     Test net output #0: accuracy = 0.890422
I0522 07:01:16.399744 19460 solver.cpp:409]     Test net output #1: loss = 0.36507 (* 1 = 0.36507 loss)
I0522 07:01:37.242602 19460 solver.cpp:237] Iteration 180000, loss = 1.37623
I0522 07:01:37.242657 19460 solver.cpp:253]     Train net output #0: loss = 1.37623 (* 1 = 1.37623 loss)
I0522 07:01:37.242672 19460 sgd_solver.cpp:106] Iteration 180000, lr = 0.005
I0522 07:01:49.450531 19460 solver.cpp:237] Iteration 180750, loss = 1.03723
I0522 07:01:49.450706 19460 solver.cpp:253]     Train net output #0: loss = 1.03723 (* 1 = 1.03723 loss)
I0522 07:01:49.450721 19460 sgd_solver.cpp:106] Iteration 180750, lr = 0.005
I0522 07:02:01.617218 19460 solver.cpp:237] Iteration 181500, loss = 1.3239
I0522 07:02:01.617254 19460 solver.cpp:253]     Train net output #0: loss = 1.3239 (* 1 = 1.3239 loss)
I0522 07:02:01.617269 19460 sgd_solver.cpp:106] Iteration 181500, lr = 0.005
I0522 07:02:13.758494 19460 solver.cpp:237] Iteration 182250, loss = 1.34263
I0522 07:02:13.758538 19460 solver.cpp:253]     Train net output #0: loss = 1.34263 (* 1 = 1.34263 loss)
I0522 07:02:13.758553 19460 sgd_solver.cpp:106] Iteration 182250, lr = 0.005
I0522 07:02:25.889863 19460 solver.cpp:237] Iteration 183000, loss = 1.06526
I0522 07:02:25.890024 19460 solver.cpp:253]     Train net output #0: loss = 1.06526 (* 1 = 1.06526 loss)
I0522 07:02:25.890039 19460 sgd_solver.cpp:106] Iteration 183000, lr = 0.005
I0522 07:02:38.030750 19460 solver.cpp:237] Iteration 183750, loss = 1.1639
I0522 07:02:38.030793 19460 solver.cpp:253]     Train net output #0: loss = 1.1639 (* 1 = 1.1639 loss)
I0522 07:02:38.030808 19460 sgd_solver.cpp:106] Iteration 183750, lr = 0.005
I0522 07:02:50.176185 19460 solver.cpp:237] Iteration 184500, loss = 1.37865
I0522 07:02:50.176220 19460 solver.cpp:253]     Train net output #0: loss = 1.37865 (* 1 = 1.37865 loss)
I0522 07:02:50.176236 19460 sgd_solver.cpp:106] Iteration 184500, lr = 0.005
I0522 07:03:23.171429 19460 solver.cpp:237] Iteration 185250, loss = 1.37495
I0522 07:03:23.171613 19460 solver.cpp:253]     Train net output #0: loss = 1.37495 (* 1 = 1.37495 loss)
I0522 07:03:23.171627 19460 sgd_solver.cpp:106] Iteration 185250, lr = 0.005
I0522 07:03:35.319577 19460 solver.cpp:237] Iteration 186000, loss = 1.05683
I0522 07:03:35.319612 19460 solver.cpp:253]     Train net output #0: loss = 1.05683 (* 1 = 1.05683 loss)
I0522 07:03:35.319629 19460 sgd_solver.cpp:106] Iteration 186000, lr = 0.005
I0522 07:03:47.469323 19460 solver.cpp:237] Iteration 186750, loss = 1.14322
I0522 07:03:47.469372 19460 solver.cpp:253]     Train net output #0: loss = 1.14323 (* 1 = 1.14323 loss)
I0522 07:03:47.469388 19460 sgd_solver.cpp:106] Iteration 186750, lr = 0.005
I0522 07:03:59.601487 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_187500.caffemodel
I0522 07:03:59.651741 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_187500.solverstate
I0522 07:03:59.683280 19460 solver.cpp:237] Iteration 187500, loss = 1.07084
I0522 07:03:59.683331 19460 solver.cpp:253]     Train net output #0: loss = 1.07084 (* 1 = 1.07084 loss)
I0522 07:03:59.683344 19460 sgd_solver.cpp:106] Iteration 187500, lr = 0.005
I0522 07:04:11.816817 19460 solver.cpp:237] Iteration 188250, loss = 1.17851
I0522 07:04:11.816859 19460 solver.cpp:253]     Train net output #0: loss = 1.17851 (* 1 = 1.17851 loss)
I0522 07:04:11.816880 19460 sgd_solver.cpp:106] Iteration 188250, lr = 0.005
I0522 07:04:24.005452 19460 solver.cpp:237] Iteration 189000, loss = 0.813609
I0522 07:04:24.005488 19460 solver.cpp:253]     Train net output #0: loss = 0.813609 (* 1 = 0.813609 loss)
I0522 07:04:24.005506 19460 sgd_solver.cpp:106] Iteration 189000, lr = 0.005
I0522 07:04:36.206821 19460 solver.cpp:237] Iteration 189750, loss = 1.41812
I0522 07:04:36.206998 19460 solver.cpp:253]     Train net output #0: loss = 1.41812 (* 1 = 1.41812 loss)
I0522 07:04:36.207012 19460 sgd_solver.cpp:106] Iteration 189750, lr = 0.005
I0522 07:05:09.287781 19460 solver.cpp:237] Iteration 190500, loss = 1.0197
I0522 07:05:09.287963 19460 solver.cpp:253]     Train net output #0: loss = 1.0197 (* 1 = 1.0197 loss)
I0522 07:05:09.287978 19460 sgd_solver.cpp:106] Iteration 190500, lr = 0.005
I0522 07:05:21.519124 19460 solver.cpp:237] Iteration 191250, loss = 1.23613
I0522 07:05:21.519160 19460 solver.cpp:253]     Train net output #0: loss = 1.23613 (* 1 = 1.23613 loss)
I0522 07:05:21.519176 19460 sgd_solver.cpp:106] Iteration 191250, lr = 0.005
I0522 07:05:33.736238 19460 solver.cpp:237] Iteration 192000, loss = 1.34362
I0522 07:05:33.736280 19460 solver.cpp:253]     Train net output #0: loss = 1.34362 (* 1 = 1.34362 loss)
I0522 07:05:33.736294 19460 sgd_solver.cpp:106] Iteration 192000, lr = 0.005
I0522 07:05:45.931217 19460 solver.cpp:237] Iteration 192750, loss = 1.13207
I0522 07:05:45.931381 19460 solver.cpp:253]     Train net output #0: loss = 1.13207 (* 1 = 1.13207 loss)
I0522 07:05:45.931396 19460 sgd_solver.cpp:106] Iteration 192750, lr = 0.005
I0522 07:05:58.146798 19460 solver.cpp:237] Iteration 193500, loss = 0.910968
I0522 07:05:58.146848 19460 solver.cpp:253]     Train net output #0: loss = 0.910968 (* 1 = 0.910968 loss)
I0522 07:05:58.146862 19460 sgd_solver.cpp:106] Iteration 193500, lr = 0.005
I0522 07:06:10.280918 19460 solver.cpp:237] Iteration 194250, loss = 0.741593
I0522 07:06:10.280956 19460 solver.cpp:253]     Train net output #0: loss = 0.741593 (* 1 = 0.741593 loss)
I0522 07:06:10.280972 19460 sgd_solver.cpp:106] Iteration 194250, lr = 0.005
I0522 07:06:22.496414 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_195000.caffemodel
I0522 07:06:22.545266 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_195000.solverstate
I0522 07:06:22.571113 19460 solver.cpp:341] Iteration 195000, Testing net (#0)
I0522 07:07:14.633447 19460 solver.cpp:409]     Test net output #0: accuracy = 0.891375
I0522 07:07:14.633638 19460 solver.cpp:409]     Test net output #1: loss = 0.335794 (* 1 = 0.335794 loss)
I0522 07:07:35.540240 19460 solver.cpp:237] Iteration 195000, loss = 0.932961
I0522 07:07:35.540293 19460 solver.cpp:253]     Train net output #0: loss = 0.932962 (* 1 = 0.932962 loss)
I0522 07:07:35.540308 19460 sgd_solver.cpp:106] Iteration 195000, lr = 0.005
I0522 07:07:47.669315 19460 solver.cpp:237] Iteration 195750, loss = 1.09686
I0522 07:07:47.669487 19460 solver.cpp:253]     Train net output #0: loss = 1.09686 (* 1 = 1.09686 loss)
I0522 07:07:47.669500 19460 sgd_solver.cpp:106] Iteration 195750, lr = 0.005
I0522 07:07:59.800817 19460 solver.cpp:237] Iteration 196500, loss = 1.69529
I0522 07:07:59.800858 19460 solver.cpp:253]     Train net output #0: loss = 1.69529 (* 1 = 1.69529 loss)
I0522 07:07:59.800882 19460 sgd_solver.cpp:106] Iteration 196500, lr = 0.005
I0522 07:08:11.923019 19460 solver.cpp:237] Iteration 197250, loss = 1.25649
I0522 07:08:11.923056 19460 solver.cpp:253]     Train net output #0: loss = 1.25649 (* 1 = 1.25649 loss)
I0522 07:08:11.923074 19460 sgd_solver.cpp:106] Iteration 197250, lr = 0.005
I0522 07:08:24.048800 19460 solver.cpp:237] Iteration 198000, loss = 1.1826
I0522 07:08:24.048981 19460 solver.cpp:253]     Train net output #0: loss = 1.1826 (* 1 = 1.1826 loss)
I0522 07:08:24.048995 19460 sgd_solver.cpp:106] Iteration 198000, lr = 0.005
I0522 07:08:36.175535 19460 solver.cpp:237] Iteration 198750, loss = 1.28076
I0522 07:08:36.175570 19460 solver.cpp:253]     Train net output #0: loss = 1.28076 (* 1 = 1.28076 loss)
I0522 07:08:36.175586 19460 sgd_solver.cpp:106] Iteration 198750, lr = 0.005
I0522 07:08:48.300285 19460 solver.cpp:237] Iteration 199500, loss = 0.891285
I0522 07:08:48.300334 19460 solver.cpp:253]     Train net output #0: loss = 0.891285 (* 1 = 0.891285 loss)
I0522 07:08:48.300348 19460 sgd_solver.cpp:106] Iteration 199500, lr = 0.005
I0522 07:09:21.327591 19460 solver.cpp:237] Iteration 200250, loss = 1.36808
I0522 07:09:21.327776 19460 solver.cpp:253]     Train net output #0: loss = 1.36808 (* 1 = 1.36808 loss)
I0522 07:09:21.327792 19460 sgd_solver.cpp:106] Iteration 200250, lr = 0.005
I0522 07:09:33.516840 19460 solver.cpp:237] Iteration 201000, loss = 0.995252
I0522 07:09:33.516898 19460 solver.cpp:253]     Train net output #0: loss = 0.995252 (* 1 = 0.995252 loss)
I0522 07:09:33.516912 19460 sgd_solver.cpp:106] Iteration 201000, lr = 0.005
I0522 07:09:45.685415 19460 solver.cpp:237] Iteration 201750, loss = 1.33266
I0522 07:09:45.685451 19460 solver.cpp:253]     Train net output #0: loss = 1.33266 (* 1 = 1.33266 loss)
I0522 07:09:45.685467 19460 sgd_solver.cpp:106] Iteration 201750, lr = 0.005
I0522 07:09:57.819102 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_202500.caffemodel
I0522 07:09:57.869056 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_202500.solverstate
I0522 07:09:57.899556 19460 solver.cpp:237] Iteration 202500, loss = 1.03385
I0522 07:09:57.899598 19460 solver.cpp:253]     Train net output #0: loss = 1.03385 (* 1 = 1.03385 loss)
I0522 07:09:57.899616 19460 sgd_solver.cpp:106] Iteration 202500, lr = 0.005
I0522 07:10:10.045577 19460 solver.cpp:237] Iteration 203250, loss = 1.41258
I0522 07:10:10.045621 19460 solver.cpp:253]     Train net output #0: loss = 1.41258 (* 1 = 1.41258 loss)
I0522 07:10:10.045636 19460 sgd_solver.cpp:106] Iteration 203250, lr = 0.005
I0522 07:10:22.192432 19460 solver.cpp:237] Iteration 204000, loss = 1.63625
I0522 07:10:22.192468 19460 solver.cpp:253]     Train net output #0: loss = 1.63625 (* 1 = 1.63625 loss)
I0522 07:10:22.192484 19460 sgd_solver.cpp:106] Iteration 204000, lr = 0.005
I0522 07:10:34.324055 19460 solver.cpp:237] Iteration 204750, loss = 1.16876
I0522 07:10:34.324244 19460 solver.cpp:253]     Train net output #0: loss = 1.16876 (* 1 = 1.16876 loss)
I0522 07:10:34.324259 19460 sgd_solver.cpp:106] Iteration 204750, lr = 0.005
I0522 07:11:07.441442 19460 solver.cpp:237] Iteration 205500, loss = 0.99974
I0522 07:11:07.441632 19460 solver.cpp:253]     Train net output #0: loss = 0.99974 (* 1 = 0.99974 loss)
I0522 07:11:07.441648 19460 sgd_solver.cpp:106] Iteration 205500, lr = 0.005
I0522 07:11:19.585649 19460 solver.cpp:237] Iteration 206250, loss = 1.78085
I0522 07:11:19.585693 19460 solver.cpp:253]     Train net output #0: loss = 1.78085 (* 1 = 1.78085 loss)
I0522 07:11:19.585707 19460 sgd_solver.cpp:106] Iteration 206250, lr = 0.005
I0522 07:11:31.716059 19460 solver.cpp:237] Iteration 207000, loss = 1.20467
I0522 07:11:31.716095 19460 solver.cpp:253]     Train net output #0: loss = 1.20467 (* 1 = 1.20467 loss)
I0522 07:11:31.716111 19460 sgd_solver.cpp:106] Iteration 207000, lr = 0.005
I0522 07:11:43.857995 19460 solver.cpp:237] Iteration 207750, loss = 1.45628
I0522 07:11:43.858170 19460 solver.cpp:253]     Train net output #0: loss = 1.45628 (* 1 = 1.45628 loss)
I0522 07:11:43.858186 19460 sgd_solver.cpp:106] Iteration 207750, lr = 0.005
I0522 07:11:56.026653 19460 solver.cpp:237] Iteration 208500, loss = 1.06044
I0522 07:11:56.026690 19460 solver.cpp:253]     Train net output #0: loss = 1.06045 (* 1 = 1.06045 loss)
I0522 07:11:56.026705 19460 sgd_solver.cpp:106] Iteration 208500, lr = 0.005
I0522 07:12:08.194021 19460 solver.cpp:237] Iteration 209250, loss = 1.06821
I0522 07:12:08.194068 19460 solver.cpp:253]     Train net output #0: loss = 1.06821 (* 1 = 1.06821 loss)
I0522 07:12:08.194082 19460 sgd_solver.cpp:106] Iteration 209250, lr = 0.005
I0522 07:12:20.342012 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_210000.caffemodel
I0522 07:12:20.391692 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_210000.solverstate
I0522 07:12:20.417114 19460 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 07:13:33.350900 19460 solver.cpp:409]     Test net output #0: accuracy = 0.896223
I0522 07:13:33.351084 19460 solver.cpp:409]     Test net output #1: loss = 0.334804 (* 1 = 0.334804 loss)
I0522 07:13:54.289815 19460 solver.cpp:237] Iteration 210000, loss = 1.23042
I0522 07:13:54.289868 19460 solver.cpp:253]     Train net output #0: loss = 1.23042 (* 1 = 1.23042 loss)
I0522 07:13:54.289883 19460 sgd_solver.cpp:106] Iteration 210000, lr = 0.005
I0522 07:14:06.527449 19460 solver.cpp:237] Iteration 210750, loss = 1.4427
I0522 07:14:06.527621 19460 solver.cpp:253]     Train net output #0: loss = 1.4427 (* 1 = 1.4427 loss)
I0522 07:14:06.527634 19460 sgd_solver.cpp:106] Iteration 210750, lr = 0.005
I0522 07:14:18.720034 19460 solver.cpp:237] Iteration 211500, loss = 0.818375
I0522 07:14:18.720082 19460 solver.cpp:253]     Train net output #0: loss = 0.818377 (* 1 = 0.818377 loss)
I0522 07:14:18.720095 19460 sgd_solver.cpp:106] Iteration 211500, lr = 0.005
I0522 07:14:30.917259 19460 solver.cpp:237] Iteration 212250, loss = 1.17165
I0522 07:14:30.917295 19460 solver.cpp:253]     Train net output #0: loss = 1.17165 (* 1 = 1.17165 loss)
I0522 07:14:30.917309 19460 sgd_solver.cpp:106] Iteration 212250, lr = 0.005
I0522 07:14:43.100685 19460 solver.cpp:237] Iteration 213000, loss = 1.25312
I0522 07:14:43.100883 19460 solver.cpp:253]     Train net output #0: loss = 1.25312 (* 1 = 1.25312 loss)
I0522 07:14:43.100898 19460 sgd_solver.cpp:106] Iteration 213000, lr = 0.005
I0522 07:14:55.279088 19460 solver.cpp:237] Iteration 213750, loss = 0.521285
I0522 07:14:55.279124 19460 solver.cpp:253]     Train net output #0: loss = 0.521286 (* 1 = 0.521286 loss)
I0522 07:14:55.279140 19460 sgd_solver.cpp:106] Iteration 213750, lr = 0.005
I0522 07:15:07.497090 19460 solver.cpp:237] Iteration 214500, loss = 1.63817
I0522 07:15:07.497139 19460 solver.cpp:253]     Train net output #0: loss = 1.63817 (* 1 = 1.63817 loss)
I0522 07:15:07.497155 19460 sgd_solver.cpp:106] Iteration 214500, lr = 0.005
I0522 07:15:40.617202 19460 solver.cpp:237] Iteration 215250, loss = 1.13398
I0522 07:15:40.617398 19460 solver.cpp:253]     Train net output #0: loss = 1.13398 (* 1 = 1.13398 loss)
I0522 07:15:40.617414 19460 sgd_solver.cpp:106] Iteration 215250, lr = 0.005
I0522 07:15:52.799115 19460 solver.cpp:237] Iteration 216000, loss = 1.35207
I0522 07:15:52.799161 19460 solver.cpp:253]     Train net output #0: loss = 1.35207 (* 1 = 1.35207 loss)
I0522 07:15:52.799177 19460 sgd_solver.cpp:106] Iteration 216000, lr = 0.005
I0522 07:16:04.985126 19460 solver.cpp:237] Iteration 216750, loss = 0.790223
I0522 07:16:04.985162 19460 solver.cpp:253]     Train net output #0: loss = 0.790224 (* 1 = 0.790224 loss)
I0522 07:16:04.985178 19460 sgd_solver.cpp:106] Iteration 216750, lr = 0.005
I0522 07:16:17.185458 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_217500.caffemodel
I0522 07:16:17.236256 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_217500.solverstate
I0522 07:16:17.268123 19460 solver.cpp:237] Iteration 217500, loss = 1.12504
I0522 07:16:17.268168 19460 solver.cpp:253]     Train net output #0: loss = 1.12504 (* 1 = 1.12504 loss)
I0522 07:16:17.268185 19460 sgd_solver.cpp:106] Iteration 217500, lr = 0.005
I0522 07:16:29.529207 19460 solver.cpp:237] Iteration 218250, loss = 0.959889
I0522 07:16:29.529244 19460 solver.cpp:253]     Train net output #0: loss = 0.95989 (* 1 = 0.95989 loss)
I0522 07:16:29.529258 19460 sgd_solver.cpp:106] Iteration 218250, lr = 0.005
I0522 07:16:41.791450 19460 solver.cpp:237] Iteration 219000, loss = 3.41637
I0522 07:16:41.791499 19460 solver.cpp:253]     Train net output #0: loss = 3.41637 (* 1 = 3.41637 loss)
I0522 07:16:41.791514 19460 sgd_solver.cpp:106] Iteration 219000, lr = 0.005
I0522 07:16:54.050442 19460 solver.cpp:237] Iteration 219750, loss = 0.860557
I0522 07:16:54.050626 19460 solver.cpp:253]     Train net output #0: loss = 0.860559 (* 1 = 0.860559 loss)
I0522 07:16:54.050642 19460 sgd_solver.cpp:106] Iteration 219750, lr = 0.005
I0522 07:17:27.166786 19460 solver.cpp:237] Iteration 220500, loss = 0.875544
I0522 07:17:27.166976 19460 solver.cpp:253]     Train net output #0: loss = 0.875545 (* 1 = 0.875545 loss)
I0522 07:17:27.166992 19460 sgd_solver.cpp:106] Iteration 220500, lr = 0.005
I0522 07:17:39.383131 19460 solver.cpp:237] Iteration 221250, loss = 1.24944
I0522 07:17:39.383179 19460 solver.cpp:253]     Train net output #0: loss = 1.24944 (* 1 = 1.24944 loss)
I0522 07:17:39.383193 19460 sgd_solver.cpp:106] Iteration 221250, lr = 0.005
I0522 07:17:51.587700 19460 solver.cpp:237] Iteration 222000, loss = 0.924383
I0522 07:17:51.587738 19460 solver.cpp:253]     Train net output #0: loss = 0.924384 (* 1 = 0.924384 loss)
I0522 07:17:51.587754 19460 sgd_solver.cpp:106] Iteration 222000, lr = 0.005
I0522 07:18:03.799630 19460 solver.cpp:237] Iteration 222750, loss = 1.39837
I0522 07:18:03.799813 19460 solver.cpp:253]     Train net output #0: loss = 1.39837 (* 1 = 1.39837 loss)
I0522 07:18:03.799829 19460 sgd_solver.cpp:106] Iteration 222750, lr = 0.005
I0522 07:18:16.008167 19460 solver.cpp:237] Iteration 223500, loss = 1.21469
I0522 07:18:16.008203 19460 solver.cpp:253]     Train net output #0: loss = 1.21469 (* 1 = 1.21469 loss)
I0522 07:18:16.008220 19460 sgd_solver.cpp:106] Iteration 223500, lr = 0.005
I0522 07:18:28.233077 19460 solver.cpp:237] Iteration 224250, loss = 1.70879
I0522 07:18:28.233122 19460 solver.cpp:253]     Train net output #0: loss = 1.70879 (* 1 = 1.70879 loss)
I0522 07:18:28.233139 19460 sgd_solver.cpp:106] Iteration 224250, lr = 0.005
I0522 07:18:40.459429 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_225000.caffemodel
I0522 07:18:40.510191 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_225000.solverstate
I0522 07:18:40.538658 19460 solver.cpp:341] Iteration 225000, Testing net (#0)
I0522 07:19:32.201117 19460 solver.cpp:409]     Test net output #0: accuracy = 0.895816
I0522 07:19:32.201303 19460 solver.cpp:409]     Test net output #1: loss = 0.346676 (* 1 = 0.346676 loss)
I0522 07:19:53.079519 19460 solver.cpp:237] Iteration 225000, loss = 1.12574
I0522 07:19:53.079569 19460 solver.cpp:253]     Train net output #0: loss = 1.12574 (* 1 = 1.12574 loss)
I0522 07:19:53.079584 19460 sgd_solver.cpp:106] Iteration 225000, lr = 0.005
I0522 07:20:05.236001 19460 solver.cpp:237] Iteration 225750, loss = 0.776928
I0522 07:20:05.236186 19460 solver.cpp:253]     Train net output #0: loss = 0.776929 (* 1 = 0.776929 loss)
I0522 07:20:05.236201 19460 sgd_solver.cpp:106] Iteration 225750, lr = 0.005
I0522 07:20:17.297482 19460 solver.cpp:237] Iteration 226500, loss = 1.31854
I0522 07:20:17.297518 19460 solver.cpp:253]     Train net output #0: loss = 1.31854 (* 1 = 1.31854 loss)
I0522 07:20:17.297533 19460 sgd_solver.cpp:106] Iteration 226500, lr = 0.005
I0522 07:20:29.368057 19460 solver.cpp:237] Iteration 227250, loss = 1.22916
I0522 07:20:29.368099 19460 solver.cpp:253]     Train net output #0: loss = 1.22917 (* 1 = 1.22917 loss)
I0522 07:20:29.368113 19460 sgd_solver.cpp:106] Iteration 227250, lr = 0.005
I0522 07:20:41.572906 19460 solver.cpp:237] Iteration 228000, loss = 0.821948
I0522 07:20:41.573074 19460 solver.cpp:253]     Train net output #0: loss = 0.821949 (* 1 = 0.821949 loss)
I0522 07:20:41.573091 19460 sgd_solver.cpp:106] Iteration 228000, lr = 0.005
I0522 07:20:53.810380 19460 solver.cpp:237] Iteration 228750, loss = 1.48314
I0522 07:20:53.810423 19460 solver.cpp:253]     Train net output #0: loss = 1.48314 (* 1 = 1.48314 loss)
I0522 07:20:53.810441 19460 sgd_solver.cpp:106] Iteration 228750, lr = 0.005
I0522 07:21:06.052924 19460 solver.cpp:237] Iteration 229500, loss = 1.18704
I0522 07:21:06.052961 19460 solver.cpp:253]     Train net output #0: loss = 1.18705 (* 1 = 1.18705 loss)
I0522 07:21:06.052978 19460 sgd_solver.cpp:106] Iteration 229500, lr = 0.005
I0522 07:21:39.136845 19460 solver.cpp:237] Iteration 230250, loss = 1.58457
I0522 07:21:39.137037 19460 solver.cpp:253]     Train net output #0: loss = 1.58457 (* 1 = 1.58457 loss)
I0522 07:21:39.137051 19460 sgd_solver.cpp:106] Iteration 230250, lr = 0.005
I0522 07:21:51.348706 19460 solver.cpp:237] Iteration 231000, loss = 1.21898
I0522 07:21:51.348740 19460 solver.cpp:253]     Train net output #0: loss = 1.21898 (* 1 = 1.21898 loss)
I0522 07:21:51.348757 19460 sgd_solver.cpp:106] Iteration 231000, lr = 0.005
I0522 07:22:03.538677 19460 solver.cpp:237] Iteration 231750, loss = 1.64259
I0522 07:22:03.538719 19460 solver.cpp:253]     Train net output #0: loss = 1.64259 (* 1 = 1.64259 loss)
I0522 07:22:03.538733 19460 sgd_solver.cpp:106] Iteration 231750, lr = 0.005
I0522 07:22:15.725956 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_232500.caffemodel
I0522 07:22:15.775604 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_232500.solverstate
I0522 07:22:15.806324 19460 solver.cpp:237] Iteration 232500, loss = 0.888209
I0522 07:22:15.806370 19460 solver.cpp:253]     Train net output #0: loss = 0.88821 (* 1 = 0.88821 loss)
I0522 07:22:15.806383 19460 sgd_solver.cpp:106] Iteration 232500, lr = 0.005
I0522 07:22:28.007812 19460 solver.cpp:237] Iteration 233250, loss = 0.89594
I0522 07:22:28.007849 19460 solver.cpp:253]     Train net output #0: loss = 0.895942 (* 1 = 0.895942 loss)
I0522 07:22:28.007864 19460 sgd_solver.cpp:106] Iteration 233250, lr = 0.005
I0522 07:22:40.189267 19460 solver.cpp:237] Iteration 234000, loss = 1.03751
I0522 07:22:40.189306 19460 solver.cpp:253]     Train net output #0: loss = 1.03752 (* 1 = 1.03752 loss)
I0522 07:22:40.189321 19460 sgd_solver.cpp:106] Iteration 234000, lr = 0.005
I0522 07:22:52.342311 19460 solver.cpp:237] Iteration 234750, loss = 1.20008
I0522 07:22:52.342495 19460 solver.cpp:253]     Train net output #0: loss = 1.20008 (* 1 = 1.20008 loss)
I0522 07:22:52.342509 19460 sgd_solver.cpp:106] Iteration 234750, lr = 0.005
I0522 07:23:25.338569 19460 solver.cpp:237] Iteration 235500, loss = 0.932522
I0522 07:23:25.338768 19460 solver.cpp:253]     Train net output #0: loss = 0.932523 (* 1 = 0.932523 loss)
I0522 07:23:25.338784 19460 sgd_solver.cpp:106] Iteration 235500, lr = 0.005
I0522 07:23:37.444036 19460 solver.cpp:237] Iteration 236250, loss = 0.991894
I0522 07:23:37.444073 19460 solver.cpp:253]     Train net output #0: loss = 0.991896 (* 1 = 0.991896 loss)
I0522 07:23:37.444089 19460 sgd_solver.cpp:106] Iteration 236250, lr = 0.005
I0522 07:23:49.559080 19460 solver.cpp:237] Iteration 237000, loss = 1.003
I0522 07:23:49.559125 19460 solver.cpp:253]     Train net output #0: loss = 1.003 (* 1 = 1.003 loss)
I0522 07:23:49.559141 19460 sgd_solver.cpp:106] Iteration 237000, lr = 0.005
I0522 07:24:01.668658 19460 solver.cpp:237] Iteration 237750, loss = 1.0984
I0522 07:24:01.668825 19460 solver.cpp:253]     Train net output #0: loss = 1.0984 (* 1 = 1.0984 loss)
I0522 07:24:01.668838 19460 sgd_solver.cpp:106] Iteration 237750, lr = 0.005
I0522 07:24:13.830687 19460 solver.cpp:237] Iteration 238500, loss = 1.38329
I0522 07:24:13.830737 19460 solver.cpp:253]     Train net output #0: loss = 1.38329 (* 1 = 1.38329 loss)
I0522 07:24:13.830752 19460 sgd_solver.cpp:106] Iteration 238500, lr = 0.005
I0522 07:24:26.011322 19460 solver.cpp:237] Iteration 239250, loss = 1.59476
I0522 07:24:26.011356 19460 solver.cpp:253]     Train net output #0: loss = 1.59477 (* 1 = 1.59477 loss)
I0522 07:24:26.011373 19460 sgd_solver.cpp:106] Iteration 239250, lr = 0.005
I0522 07:24:38.175266 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_240000.caffemodel
I0522 07:24:38.224360 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_240000.solverstate
I0522 07:24:38.249568 19460 solver.cpp:341] Iteration 240000, Testing net (#0)
I0522 07:25:50.981520 19460 solver.cpp:409]     Test net output #0: accuracy = 0.892215
I0522 07:25:50.981705 19460 solver.cpp:409]     Test net output #1: loss = 0.337988 (* 1 = 0.337988 loss)
I0522 07:26:11.860911 19460 solver.cpp:237] Iteration 240000, loss = 0.786746
I0522 07:26:11.860965 19460 solver.cpp:253]     Train net output #0: loss = 0.786748 (* 1 = 0.786748 loss)
I0522 07:26:11.860980 19460 sgd_solver.cpp:106] Iteration 240000, lr = 0.005
I0522 07:26:24.071596 19460 solver.cpp:237] Iteration 240750, loss = 1.10236
I0522 07:26:24.071779 19460 solver.cpp:253]     Train net output #0: loss = 1.10237 (* 1 = 1.10237 loss)
I0522 07:26:24.071792 19460 sgd_solver.cpp:106] Iteration 240750, lr = 0.005
I0522 07:26:36.259230 19460 solver.cpp:237] Iteration 241500, loss = 1.16945
I0522 07:26:36.259266 19460 solver.cpp:253]     Train net output #0: loss = 1.16945 (* 1 = 1.16945 loss)
I0522 07:26:36.259282 19460 sgd_solver.cpp:106] Iteration 241500, lr = 0.005
I0522 07:26:48.421075 19460 solver.cpp:237] Iteration 242250, loss = 0.994215
I0522 07:26:48.421123 19460 solver.cpp:253]     Train net output #0: loss = 0.994216 (* 1 = 0.994216 loss)
I0522 07:26:48.421139 19460 sgd_solver.cpp:106] Iteration 242250, lr = 0.005
I0522 07:27:00.650481 19460 solver.cpp:237] Iteration 243000, loss = 1.19003
I0522 07:27:00.650670 19460 solver.cpp:253]     Train net output #0: loss = 1.19003 (* 1 = 1.19003 loss)
I0522 07:27:00.650683 19460 sgd_solver.cpp:106] Iteration 243000, lr = 0.005
I0522 07:27:12.881877 19460 solver.cpp:237] Iteration 243750, loss = 1.23049
I0522 07:27:12.881923 19460 solver.cpp:253]     Train net output #0: loss = 1.23049 (* 1 = 1.23049 loss)
I0522 07:27:12.881938 19460 sgd_solver.cpp:106] Iteration 243750, lr = 0.005
I0522 07:27:25.098130 19460 solver.cpp:237] Iteration 244500, loss = 1.38836
I0522 07:27:25.098165 19460 solver.cpp:253]     Train net output #0: loss = 1.38836 (* 1 = 1.38836 loss)
I0522 07:27:25.098179 19460 sgd_solver.cpp:106] Iteration 244500, lr = 0.005
I0522 07:27:58.194967 19460 solver.cpp:237] Iteration 245250, loss = 1.3338
I0522 07:27:58.195159 19460 solver.cpp:253]     Train net output #0: loss = 1.3338 (* 1 = 1.3338 loss)
I0522 07:27:58.195174 19460 sgd_solver.cpp:106] Iteration 245250, lr = 0.005
I0522 07:28:10.369851 19460 solver.cpp:237] Iteration 246000, loss = 0.962237
I0522 07:28:10.369889 19460 solver.cpp:253]     Train net output #0: loss = 0.962238 (* 1 = 0.962238 loss)
I0522 07:28:10.369901 19460 sgd_solver.cpp:106] Iteration 246000, lr = 0.005
I0522 07:28:22.544425 19460 solver.cpp:237] Iteration 246750, loss = 0.810287
I0522 07:28:22.544471 19460 solver.cpp:253]     Train net output #0: loss = 0.810287 (* 1 = 0.810287 loss)
I0522 07:28:22.544486 19460 sgd_solver.cpp:106] Iteration 246750, lr = 0.005
I0522 07:28:34.722769 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_247500.caffemodel
I0522 07:28:34.771587 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_247500.solverstate
I0522 07:28:34.801933 19460 solver.cpp:237] Iteration 247500, loss = 1.05699
I0522 07:28:34.801971 19460 solver.cpp:253]     Train net output #0: loss = 1.05699 (* 1 = 1.05699 loss)
I0522 07:28:34.801990 19460 sgd_solver.cpp:106] Iteration 247500, lr = 0.005
I0522 07:28:46.971946 19460 solver.cpp:237] Iteration 248250, loss = 1.3625
I0522 07:28:46.971997 19460 solver.cpp:253]     Train net output #0: loss = 1.3625 (* 1 = 1.3625 loss)
I0522 07:28:46.972010 19460 sgd_solver.cpp:106] Iteration 248250, lr = 0.005
I0522 07:28:59.148365 19460 solver.cpp:237] Iteration 249000, loss = 1.22644
I0522 07:28:59.148401 19460 solver.cpp:253]     Train net output #0: loss = 1.22644 (* 1 = 1.22644 loss)
I0522 07:28:59.148414 19460 sgd_solver.cpp:106] Iteration 249000, lr = 0.005
I0522 07:29:11.335975 19460 solver.cpp:237] Iteration 249750, loss = 1.08297
I0522 07:29:11.336155 19460 solver.cpp:253]     Train net output #0: loss = 1.08297 (* 1 = 1.08297 loss)
I0522 07:29:11.336169 19460 sgd_solver.cpp:106] Iteration 249750, lr = 0.005
I0522 07:29:44.401968 19460 solver.cpp:237] Iteration 250500, loss = 0.899622
I0522 07:29:44.402163 19460 solver.cpp:253]     Train net output #0: loss = 0.899623 (* 1 = 0.899623 loss)
I0522 07:29:44.402178 19460 sgd_solver.cpp:106] Iteration 250500, lr = 0.005
I0522 07:29:56.621248 19460 solver.cpp:237] Iteration 251250, loss = 1.38198
I0522 07:29:56.621284 19460 solver.cpp:253]     Train net output #0: loss = 1.38198 (* 1 = 1.38198 loss)
I0522 07:29:56.621297 19460 sgd_solver.cpp:106] Iteration 251250, lr = 0.005
I0522 07:30:08.858964 19460 solver.cpp:237] Iteration 252000, loss = 1.45953
I0522 07:30:08.859014 19460 solver.cpp:253]     Train net output #0: loss = 1.45953 (* 1 = 1.45953 loss)
I0522 07:30:08.859030 19460 sgd_solver.cpp:106] Iteration 252000, lr = 0.005
I0522 07:30:21.012794 19460 solver.cpp:237] Iteration 252750, loss = 1.0718
I0522 07:30:21.012969 19460 solver.cpp:253]     Train net output #0: loss = 1.0718 (* 1 = 1.0718 loss)
I0522 07:30:21.012984 19460 sgd_solver.cpp:106] Iteration 252750, lr = 0.005
I0522 07:30:33.250162 19460 solver.cpp:237] Iteration 253500, loss = 1.47397
I0522 07:30:33.250206 19460 solver.cpp:253]     Train net output #0: loss = 1.47397 (* 1 = 1.47397 loss)
I0522 07:30:33.250221 19460 sgd_solver.cpp:106] Iteration 253500, lr = 0.005
I0522 07:30:45.437993 19460 solver.cpp:237] Iteration 254250, loss = 0.886821
I0522 07:30:45.438029 19460 solver.cpp:253]     Train net output #0: loss = 0.886822 (* 1 = 0.886822 loss)
I0522 07:30:45.438042 19460 sgd_solver.cpp:106] Iteration 254250, lr = 0.005
I0522 07:30:57.571172 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_255000.caffemodel
I0522 07:30:57.620194 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_255000.solverstate
I0522 07:30:57.645431 19460 solver.cpp:341] Iteration 255000, Testing net (#0)
I0522 07:31:49.699450 19460 solver.cpp:409]     Test net output #0: accuracy = 0.895545
I0522 07:31:49.699640 19460 solver.cpp:409]     Test net output #1: loss = 0.358064 (* 1 = 0.358064 loss)
I0522 07:32:10.582216 19460 solver.cpp:237] Iteration 255000, loss = 0.893147
I0522 07:32:10.582270 19460 solver.cpp:253]     Train net output #0: loss = 0.893147 (* 1 = 0.893147 loss)
I0522 07:32:10.582285 19460 sgd_solver.cpp:106] Iteration 255000, lr = 0.005
I0522 07:32:22.711207 19460 solver.cpp:237] Iteration 255750, loss = 1.68027
I0522 07:32:22.711385 19460 solver.cpp:253]     Train net output #0: loss = 1.68027 (* 1 = 1.68027 loss)
I0522 07:32:22.711398 19460 sgd_solver.cpp:106] Iteration 255750, lr = 0.005
I0522 07:32:34.859978 19460 solver.cpp:237] Iteration 256500, loss = 1.35861
I0522 07:32:34.860023 19460 solver.cpp:253]     Train net output #0: loss = 1.35861 (* 1 = 1.35861 loss)
I0522 07:32:34.860040 19460 sgd_solver.cpp:106] Iteration 256500, lr = 0.005
I0522 07:32:47.027359 19460 solver.cpp:237] Iteration 257250, loss = 1.4316
I0522 07:32:47.027395 19460 solver.cpp:253]     Train net output #0: loss = 1.4316 (* 1 = 1.4316 loss)
I0522 07:32:47.027410 19460 sgd_solver.cpp:106] Iteration 257250, lr = 0.005
I0522 07:32:59.196313 19460 solver.cpp:237] Iteration 258000, loss = 0.846046
I0522 07:32:59.196504 19460 solver.cpp:253]     Train net output #0: loss = 0.846047 (* 1 = 0.846047 loss)
I0522 07:32:59.196519 19460 sgd_solver.cpp:106] Iteration 258000, lr = 0.005
I0522 07:33:11.340520 19460 solver.cpp:237] Iteration 258750, loss = 1.08944
I0522 07:33:11.340556 19460 solver.cpp:253]     Train net output #0: loss = 1.08944 (* 1 = 1.08944 loss)
I0522 07:33:11.340572 19460 sgd_solver.cpp:106] Iteration 258750, lr = 0.005
I0522 07:33:23.476357 19460 solver.cpp:237] Iteration 259500, loss = 1.08536
I0522 07:33:23.476408 19460 solver.cpp:253]     Train net output #0: loss = 1.08536 (* 1 = 1.08536 loss)
I0522 07:33:23.476423 19460 sgd_solver.cpp:106] Iteration 259500, lr = 0.005
I0522 07:33:56.450589 19460 solver.cpp:237] Iteration 260250, loss = 1.38063
I0522 07:33:56.450785 19460 solver.cpp:253]     Train net output #0: loss = 1.38064 (* 1 = 1.38064 loss)
I0522 07:33:56.450801 19460 sgd_solver.cpp:106] Iteration 260250, lr = 0.005
I0522 07:34:08.576927 19460 solver.cpp:237] Iteration 261000, loss = 1.03003
I0522 07:34:08.576968 19460 solver.cpp:253]     Train net output #0: loss = 1.03003 (* 1 = 1.03003 loss)
I0522 07:34:08.576989 19460 sgd_solver.cpp:106] Iteration 261000, lr = 0.005
I0522 07:34:20.722108 19460 solver.cpp:237] Iteration 261750, loss = 1.16301
I0522 07:34:20.722144 19460 solver.cpp:253]     Train net output #0: loss = 1.16301 (* 1 = 1.16301 loss)
I0522 07:34:20.722157 19460 sgd_solver.cpp:106] Iteration 261750, lr = 0.005
I0522 07:34:32.839357 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_262500.caffemodel
I0522 07:34:32.890159 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_262500.solverstate
I0522 07:34:32.923151 19460 solver.cpp:237] Iteration 262500, loss = 1.56061
I0522 07:34:32.923199 19460 solver.cpp:253]     Train net output #0: loss = 1.56061 (* 1 = 1.56061 loss)
I0522 07:34:32.923216 19460 sgd_solver.cpp:106] Iteration 262500, lr = 0.005
I0522 07:34:45.042424 19460 solver.cpp:237] Iteration 263250, loss = 1.2181
I0522 07:34:45.042469 19460 solver.cpp:253]     Train net output #0: loss = 1.2181 (* 1 = 1.2181 loss)
I0522 07:34:45.042482 19460 sgd_solver.cpp:106] Iteration 263250, lr = 0.005
I0522 07:34:57.186261 19460 solver.cpp:237] Iteration 264000, loss = 0.964369
I0522 07:34:57.186298 19460 solver.cpp:253]     Train net output #0: loss = 0.964371 (* 1 = 0.964371 loss)
I0522 07:34:57.186313 19460 sgd_solver.cpp:106] Iteration 264000, lr = 0.005
I0522 07:35:09.281261 19460 solver.cpp:237] Iteration 264750, loss = 1.16845
I0522 07:35:09.281461 19460 solver.cpp:253]     Train net output #0: loss = 1.16845 (* 1 = 1.16845 loss)
I0522 07:35:09.281476 19460 sgd_solver.cpp:106] Iteration 264750, lr = 0.005
I0522 07:35:42.199666 19460 solver.cpp:237] Iteration 265500, loss = 0.931384
I0522 07:35:42.199862 19460 solver.cpp:253]     Train net output #0: loss = 0.931386 (* 1 = 0.931386 loss)
I0522 07:35:42.199877 19460 sgd_solver.cpp:106] Iteration 265500, lr = 0.005
I0522 07:35:54.303681 19460 solver.cpp:237] Iteration 266250, loss = 1.22306
I0522 07:35:54.303728 19460 solver.cpp:253]     Train net output #0: loss = 1.22306 (* 1 = 1.22306 loss)
I0522 07:35:54.303741 19460 sgd_solver.cpp:106] Iteration 266250, lr = 0.005
I0522 07:36:06.371145 19460 solver.cpp:237] Iteration 267000, loss = 1.07866
I0522 07:36:06.371181 19460 solver.cpp:253]     Train net output #0: loss = 1.07866 (* 1 = 1.07866 loss)
I0522 07:36:06.371197 19460 sgd_solver.cpp:106] Iteration 267000, lr = 0.005
I0522 07:36:18.439234 19460 solver.cpp:237] Iteration 267750, loss = 1.22375
I0522 07:36:18.439420 19460 solver.cpp:253]     Train net output #0: loss = 1.22375 (* 1 = 1.22375 loss)
I0522 07:36:18.439435 19460 sgd_solver.cpp:106] Iteration 267750, lr = 0.005
I0522 07:36:30.562532 19460 solver.cpp:237] Iteration 268500, loss = 1.03764
I0522 07:36:30.562567 19460 solver.cpp:253]     Train net output #0: loss = 1.03764 (* 1 = 1.03764 loss)
I0522 07:36:30.562584 19460 sgd_solver.cpp:106] Iteration 268500, lr = 0.005
I0522 07:36:42.739241 19460 solver.cpp:237] Iteration 269250, loss = 1.10197
I0522 07:36:42.739289 19460 solver.cpp:253]     Train net output #0: loss = 1.10197 (* 1 = 1.10197 loss)
I0522 07:36:42.739303 19460 sgd_solver.cpp:106] Iteration 269250, lr = 0.005
I0522 07:36:54.867439 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_270000.caffemodel
I0522 07:36:54.919087 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_270000.solverstate
I0522 07:36:54.946763 19460 solver.cpp:341] Iteration 270000, Testing net (#0)
I0522 07:38:07.842829 19460 solver.cpp:409]     Test net output #0: accuracy = 0.897938
I0522 07:38:07.843022 19460 solver.cpp:409]     Test net output #1: loss = 0.324253 (* 1 = 0.324253 loss)
I0522 07:38:28.692356 19460 solver.cpp:237] Iteration 270000, loss = 1.11575
I0522 07:38:28.692409 19460 solver.cpp:253]     Train net output #0: loss = 1.11575 (* 1 = 1.11575 loss)
I0522 07:38:28.692425 19460 sgd_solver.cpp:106] Iteration 270000, lr = 0.005
I0522 07:38:40.883808 19460 solver.cpp:237] Iteration 270750, loss = 1.3325
I0522 07:38:40.883987 19460 solver.cpp:253]     Train net output #0: loss = 1.3325 (* 1 = 1.3325 loss)
I0522 07:38:40.884001 19460 sgd_solver.cpp:106] Iteration 270750, lr = 0.005
I0522 07:38:53.075510 19460 solver.cpp:237] Iteration 271500, loss = 1.51832
I0522 07:38:53.075557 19460 solver.cpp:253]     Train net output #0: loss = 1.51832 (* 1 = 1.51832 loss)
I0522 07:38:53.075572 19460 sgd_solver.cpp:106] Iteration 271500, lr = 0.005
I0522 07:39:05.272589 19460 solver.cpp:237] Iteration 272250, loss = 1.40404
I0522 07:39:05.272625 19460 solver.cpp:253]     Train net output #0: loss = 1.40404 (* 1 = 1.40404 loss)
I0522 07:39:05.272641 19460 sgd_solver.cpp:106] Iteration 272250, lr = 0.005
I0522 07:39:17.430385 19460 solver.cpp:237] Iteration 273000, loss = 1.20911
I0522 07:39:17.430585 19460 solver.cpp:253]     Train net output #0: loss = 1.20912 (* 1 = 1.20912 loss)
I0522 07:39:17.430600 19460 sgd_solver.cpp:106] Iteration 273000, lr = 0.005
I0522 07:39:29.568641 19460 solver.cpp:237] Iteration 273750, loss = 1.09637
I0522 07:39:29.568676 19460 solver.cpp:253]     Train net output #0: loss = 1.09638 (* 1 = 1.09638 loss)
I0522 07:39:29.568691 19460 sgd_solver.cpp:106] Iteration 273750, lr = 0.005
I0522 07:39:41.718116 19460 solver.cpp:237] Iteration 274500, loss = 0.628585
I0522 07:39:41.718164 19460 solver.cpp:253]     Train net output #0: loss = 0.628587 (* 1 = 0.628587 loss)
I0522 07:39:41.718178 19460 sgd_solver.cpp:106] Iteration 274500, lr = 0.005
I0522 07:40:14.728806 19460 solver.cpp:237] Iteration 275250, loss = 1.00521
I0522 07:40:14.729009 19460 solver.cpp:253]     Train net output #0: loss = 1.00521 (* 1 = 1.00521 loss)
I0522 07:40:14.729024 19460 sgd_solver.cpp:106] Iteration 275250, lr = 0.005
I0522 07:40:26.917820 19460 solver.cpp:237] Iteration 276000, loss = 0.964164
I0522 07:40:26.917868 19460 solver.cpp:253]     Train net output #0: loss = 0.964166 (* 1 = 0.964166 loss)
I0522 07:40:26.917883 19460 sgd_solver.cpp:106] Iteration 276000, lr = 0.005
I0522 07:40:39.103688 19460 solver.cpp:237] Iteration 276750, loss = 1.23515
I0522 07:40:39.103724 19460 solver.cpp:253]     Train net output #0: loss = 1.23515 (* 1 = 1.23515 loss)
I0522 07:40:39.103739 19460 sgd_solver.cpp:106] Iteration 276750, lr = 0.005
I0522 07:40:51.323390 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_277500.caffemodel
I0522 07:40:51.372937 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_277500.solverstate
I0522 07:40:51.404325 19460 solver.cpp:237] Iteration 277500, loss = 1.43511
I0522 07:40:51.404371 19460 solver.cpp:253]     Train net output #0: loss = 1.43512 (* 1 = 1.43512 loss)
I0522 07:40:51.404384 19460 sgd_solver.cpp:106] Iteration 277500, lr = 0.005
I0522 07:41:03.614976 19460 solver.cpp:237] Iteration 278250, loss = 0.777356
I0522 07:41:03.615013 19460 solver.cpp:253]     Train net output #0: loss = 0.777358 (* 1 = 0.777358 loss)
I0522 07:41:03.615030 19460 sgd_solver.cpp:106] Iteration 278250, lr = 0.005
I0522 07:41:15.753298 19460 solver.cpp:237] Iteration 279000, loss = 1.02802
I0522 07:41:15.753345 19460 solver.cpp:253]     Train net output #0: loss = 1.02802 (* 1 = 1.02802 loss)
I0522 07:41:15.753357 19460 sgd_solver.cpp:106] Iteration 279000, lr = 0.005
I0522 07:41:27.882426 19460 solver.cpp:237] Iteration 279750, loss = 0.640246
I0522 07:41:27.882604 19460 solver.cpp:253]     Train net output #0: loss = 0.640248 (* 1 = 0.640248 loss)
I0522 07:41:27.882618 19460 sgd_solver.cpp:106] Iteration 279750, lr = 0.005
I0522 07:42:00.915523 19460 solver.cpp:237] Iteration 280500, loss = 1.47998
I0522 07:42:00.915719 19460 solver.cpp:253]     Train net output #0: loss = 1.47999 (* 1 = 1.47999 loss)
I0522 07:42:00.915735 19460 sgd_solver.cpp:106] Iteration 280500, lr = 0.005
I0522 07:42:13.080533 19460 solver.cpp:237] Iteration 281250, loss = 1.28313
I0522 07:42:13.080580 19460 solver.cpp:253]     Train net output #0: loss = 1.28313 (* 1 = 1.28313 loss)
I0522 07:42:13.080593 19460 sgd_solver.cpp:106] Iteration 281250, lr = 0.005
I0522 07:42:25.240557 19460 solver.cpp:237] Iteration 282000, loss = 1.13968
I0522 07:42:25.240593 19460 solver.cpp:253]     Train net output #0: loss = 1.13969 (* 1 = 1.13969 loss)
I0522 07:42:25.240607 19460 sgd_solver.cpp:106] Iteration 282000, lr = 0.005
I0522 07:42:37.386276 19460 solver.cpp:237] Iteration 282750, loss = 1.00345
I0522 07:42:37.386478 19460 solver.cpp:253]     Train net output #0: loss = 1.00345 (* 1 = 1.00345 loss)
I0522 07:42:37.386493 19460 sgd_solver.cpp:106] Iteration 282750, lr = 0.005
I0522 07:42:49.494710 19460 solver.cpp:237] Iteration 283500, loss = 1.32504
I0522 07:42:49.494747 19460 solver.cpp:253]     Train net output #0: loss = 1.32505 (* 1 = 1.32505 loss)
I0522 07:42:49.494778 19460 sgd_solver.cpp:106] Iteration 283500, lr = 0.005
I0522 07:43:01.624727 19460 solver.cpp:237] Iteration 284250, loss = 1.49204
I0522 07:43:01.624773 19460 solver.cpp:253]     Train net output #0: loss = 1.49204 (* 1 = 1.49204 loss)
I0522 07:43:01.624786 19460 sgd_solver.cpp:106] Iteration 284250, lr = 0.005
I0522 07:43:13.753509 19460 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_285000.caffemodel
I0522 07:43:13.803323 19460 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0050_2016-05-20T15.48.56.922305_iter_285000.solverstate
I0522 07:43:13.832180 19460 solver.cpp:341] Iteration 285000, Testing net (#0)
I0522 07:44:05.476233 19460 solver.cpp:409]     Test net output #0: accuracy = 0.892438
I0522 07:44:05.476429 19460 solver.cpp:409]     Test net output #1: loss = 0.332894 (* 1 = 0.332894 loss)
I0522 07:44:26.330083 19460 solver.cpp:237] Iteration 285000, loss = 1.28669
I0522 07:44:26.330135 19460 solver.cpp:253]     Train net output #0: loss = 1.28669 (* 1 = 1.28669 loss)
I0522 07:44:26.330152 19460 sgd_solver.cpp:106] Iteration 285000, lr = 0.005
I0522 07:44:38.525485 19460 solver.cpp:237] Iteration 285750, loss = 1.11319
I0522 07:44:38.525681 19460 solver.cpp:253]     Train net output #0: loss = 1.11319 (* 1 = 1.11319 loss)
I0522 07:44:38.525696 19460 sgd_solver.cpp:106] Iteration 285750, lr = 0.005
I0522 07:44:50.729158 19460 solver.cpp:237] Iteration 286500, loss = 0.672484
I0522 07:44:50.729194 19460 solver.cpp:253]     Train net output #0: loss = 0.672486 (* 1 = 0.672486 loss)
I0522 07:44:50.729207 19460 sgd_solver.cpp:106] Iteration 286500, lr = 0.005
I0522 07:45:02.926903 19460 solver.cpp:237] Iteration 287250, loss = 1.22692
I0522 07:45:02.926949 19460 solver.cpp:253]     Train net output #0: loss = 1.22693 (* 1 = 1.22693 loss)
I0522 07:45:02.926964 19460 sgd_solver.cpp:106] Iteration 287250, lr = 0.005
I0522 07:45:15.164404 19460 solver.cpp:237] Iteration 288000, loss = 1.30243
I0522 07:45:15.164577 19460 solver.cpp:253]     Train net output #0: loss = 1.30244 (* 1 = 1.30244 loss)
I0522 07:45:15.164592 19460 sgd_solver.cpp:106] Iteration 288000, lr = 0.005
I0522 07:45:27.372987 19460 solver.cpp:237] Iteration 288750, loss = 1.19503
I0522 07:45:27.373036 19460 solver.cpp:253]     Train net output #0: loss = 1.19503 (* 1 = 1.19503 loss)
I0522 07:45:27.373050 19460 sgd_solver.cpp:106] Iteration 288750, lr = 0.005
I0522 07:45:39.519094 19460 solver.cpp:237] Iteration 289500, loss = 0.806907
I0522 07:45:39.519131 19460 solver.cpp:253]     Train net output #0: loss = 0.806909 (* 1 = 0.806909 loss)
I0522 07:45:39.519145 19460 sgd_solver.cpp:106] Iteration 289500, lr = 0.005
I0522 07:46:12.538893 19460 solver.cpp:237] Iteration 290250, loss = 1.1153
I0522 07:46:12.539091 19460 solver.cpp:253]     Train net output #0: loss = 1.1153 (* 1 = 1.1153 loss)
I0522 07:46:12.539105 19460 sgd_solver.cpp:106] Iteration 290250, lr = 0.005
aprun: Apid 11245826: Caught signal Terminated, sending to application
aprun: Apid 11245826: Caught signal Terminated, sending to application
aprun: Apid 11245826: Caught signal Terminated, sending to application
*** Aborted at 1463917579 (unix time) try "date -d @1463917579" if you are using GNU date ***
aprun: Apid 11245826: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11245826: Caught signal Terminated, sending to application
*** SIGTERM (@0x4c01) received by PID 19460 (TID 0x2aaac746f900) from PID 19457; stack trace: ***
aprun: Apid 11245826: Caught signal Terminated, sending to application
aprun: Apid 11245826: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7229 exceeded limit 7200
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11245826: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11245826: Caught signal Terminated, sending to application
aprun: Apid 11245826: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11245826: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11245826: Caught signal Terminated, sending to application
aprun: Apid 11245826: Caught signal Terminated, sending to application
aprun: Apid 11245826: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11245826: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11245826: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
