2810876
I0525 18:54:17.710041  2318 caffe.cpp:184] Using GPUs 0
I0525 18:54:18.144129  2318 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.003
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282.prototxt"
I0525 18:54:18.145851  2318 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282.prototxt
I0525 18:54:18.168720  2318 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 18:54:18.168778  2318 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 18:54:18.169126  2318 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 18:54:18.169306  2318 layer_factory.hpp:77] Creating layer data_hdf5
I0525 18:54:18.169329  2318 net.cpp:106] Creating Layer data_hdf5
I0525 18:54:18.169344  2318 net.cpp:411] data_hdf5 -> data
I0525 18:54:18.169378  2318 net.cpp:411] data_hdf5 -> label
I0525 18:54:18.169411  2318 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 18:54:18.183357  2318 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 18:54:18.192078  2318 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 18:54:39.778655  2318 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 18:54:39.783921  2318 net.cpp:150] Setting up data_hdf5
I0525 18:54:39.783963  2318 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 18:54:39.783978  2318 net.cpp:157] Top shape: 100 (100)
I0525 18:54:39.783989  2318 net.cpp:165] Memory required for data: 2540400
I0525 18:54:39.784003  2318 layer_factory.hpp:77] Creating layer conv1
I0525 18:54:39.784037  2318 net.cpp:106] Creating Layer conv1
I0525 18:54:39.784049  2318 net.cpp:454] conv1 <- data
I0525 18:54:39.784072  2318 net.cpp:411] conv1 -> conv1
I0525 18:54:43.179265  2318 net.cpp:150] Setting up conv1
I0525 18:54:43.179312  2318 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:54:43.179323  2318 net.cpp:165] Memory required for data: 30188400
I0525 18:54:43.179353  2318 layer_factory.hpp:77] Creating layer relu1
I0525 18:54:43.179375  2318 net.cpp:106] Creating Layer relu1
I0525 18:54:43.179386  2318 net.cpp:454] relu1 <- conv1
I0525 18:54:43.179399  2318 net.cpp:397] relu1 -> conv1 (in-place)
I0525 18:54:43.179919  2318 net.cpp:150] Setting up relu1
I0525 18:54:43.179936  2318 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:54:43.179947  2318 net.cpp:165] Memory required for data: 57836400
I0525 18:54:43.179957  2318 layer_factory.hpp:77] Creating layer pool1
I0525 18:54:43.179975  2318 net.cpp:106] Creating Layer pool1
I0525 18:54:43.179985  2318 net.cpp:454] pool1 <- conv1
I0525 18:54:43.179998  2318 net.cpp:411] pool1 -> pool1
I0525 18:54:43.180078  2318 net.cpp:150] Setting up pool1
I0525 18:54:43.180102  2318 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 18:54:43.180114  2318 net.cpp:165] Memory required for data: 71660400
I0525 18:54:43.180124  2318 layer_factory.hpp:77] Creating layer conv2
I0525 18:54:43.180145  2318 net.cpp:106] Creating Layer conv2
I0525 18:54:43.180155  2318 net.cpp:454] conv2 <- pool1
I0525 18:54:43.180168  2318 net.cpp:411] conv2 -> conv2
I0525 18:54:43.182899  2318 net.cpp:150] Setting up conv2
I0525 18:54:43.182926  2318 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:54:43.182937  2318 net.cpp:165] Memory required for data: 91532400
I0525 18:54:43.182956  2318 layer_factory.hpp:77] Creating layer relu2
I0525 18:54:43.182971  2318 net.cpp:106] Creating Layer relu2
I0525 18:54:43.182981  2318 net.cpp:454] relu2 <- conv2
I0525 18:54:43.182993  2318 net.cpp:397] relu2 -> conv2 (in-place)
I0525 18:54:43.183325  2318 net.cpp:150] Setting up relu2
I0525 18:54:43.183338  2318 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:54:43.183348  2318 net.cpp:165] Memory required for data: 111404400
I0525 18:54:43.183359  2318 layer_factory.hpp:77] Creating layer pool2
I0525 18:54:43.183372  2318 net.cpp:106] Creating Layer pool2
I0525 18:54:43.183382  2318 net.cpp:454] pool2 <- conv2
I0525 18:54:43.183393  2318 net.cpp:411] pool2 -> pool2
I0525 18:54:43.183475  2318 net.cpp:150] Setting up pool2
I0525 18:54:43.183487  2318 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 18:54:43.183497  2318 net.cpp:165] Memory required for data: 121340400
I0525 18:54:43.183506  2318 layer_factory.hpp:77] Creating layer conv3
I0525 18:54:43.183524  2318 net.cpp:106] Creating Layer conv3
I0525 18:54:43.183534  2318 net.cpp:454] conv3 <- pool2
I0525 18:54:43.183548  2318 net.cpp:411] conv3 -> conv3
I0525 18:54:43.185556  2318 net.cpp:150] Setting up conv3
I0525 18:54:43.185580  2318 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:54:43.185592  2318 net.cpp:165] Memory required for data: 132182000
I0525 18:54:43.185612  2318 layer_factory.hpp:77] Creating layer relu3
I0525 18:54:43.185628  2318 net.cpp:106] Creating Layer relu3
I0525 18:54:43.185639  2318 net.cpp:454] relu3 <- conv3
I0525 18:54:43.185652  2318 net.cpp:397] relu3 -> conv3 (in-place)
I0525 18:54:43.186122  2318 net.cpp:150] Setting up relu3
I0525 18:54:43.186139  2318 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:54:43.186149  2318 net.cpp:165] Memory required for data: 143023600
I0525 18:54:43.186161  2318 layer_factory.hpp:77] Creating layer pool3
I0525 18:54:43.186173  2318 net.cpp:106] Creating Layer pool3
I0525 18:54:43.186182  2318 net.cpp:454] pool3 <- conv3
I0525 18:54:43.186195  2318 net.cpp:411] pool3 -> pool3
I0525 18:54:43.186262  2318 net.cpp:150] Setting up pool3
I0525 18:54:43.186275  2318 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 18:54:43.186285  2318 net.cpp:165] Memory required for data: 148444400
I0525 18:54:43.186293  2318 layer_factory.hpp:77] Creating layer conv4
I0525 18:54:43.186311  2318 net.cpp:106] Creating Layer conv4
I0525 18:54:43.186322  2318 net.cpp:454] conv4 <- pool3
I0525 18:54:43.186336  2318 net.cpp:411] conv4 -> conv4
I0525 18:54:43.189302  2318 net.cpp:150] Setting up conv4
I0525 18:54:43.189332  2318 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:54:43.189342  2318 net.cpp:165] Memory required for data: 152073200
I0525 18:54:43.189357  2318 layer_factory.hpp:77] Creating layer relu4
I0525 18:54:43.189371  2318 net.cpp:106] Creating Layer relu4
I0525 18:54:43.189381  2318 net.cpp:454] relu4 <- conv4
I0525 18:54:43.189394  2318 net.cpp:397] relu4 -> conv4 (in-place)
I0525 18:54:43.189858  2318 net.cpp:150] Setting up relu4
I0525 18:54:43.189874  2318 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:54:43.189884  2318 net.cpp:165] Memory required for data: 155702000
I0525 18:54:43.189895  2318 layer_factory.hpp:77] Creating layer pool4
I0525 18:54:43.189908  2318 net.cpp:106] Creating Layer pool4
I0525 18:54:43.189918  2318 net.cpp:454] pool4 <- conv4
I0525 18:54:43.189931  2318 net.cpp:411] pool4 -> pool4
I0525 18:54:43.189998  2318 net.cpp:150] Setting up pool4
I0525 18:54:43.190012  2318 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 18:54:43.190022  2318 net.cpp:165] Memory required for data: 157516400
I0525 18:54:43.190031  2318 layer_factory.hpp:77] Creating layer ip1
I0525 18:54:43.190050  2318 net.cpp:106] Creating Layer ip1
I0525 18:54:43.190060  2318 net.cpp:454] ip1 <- pool4
I0525 18:54:43.190074  2318 net.cpp:411] ip1 -> ip1
I0525 18:54:43.205575  2318 net.cpp:150] Setting up ip1
I0525 18:54:43.205607  2318 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:54:43.205620  2318 net.cpp:165] Memory required for data: 157594800
I0525 18:54:43.205646  2318 layer_factory.hpp:77] Creating layer relu5
I0525 18:54:43.205660  2318 net.cpp:106] Creating Layer relu5
I0525 18:54:43.205670  2318 net.cpp:454] relu5 <- ip1
I0525 18:54:43.205684  2318 net.cpp:397] relu5 -> ip1 (in-place)
I0525 18:54:43.206024  2318 net.cpp:150] Setting up relu5
I0525 18:54:43.206038  2318 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:54:43.206048  2318 net.cpp:165] Memory required for data: 157673200
I0525 18:54:43.206058  2318 layer_factory.hpp:77] Creating layer drop1
I0525 18:54:43.206080  2318 net.cpp:106] Creating Layer drop1
I0525 18:54:43.206090  2318 net.cpp:454] drop1 <- ip1
I0525 18:54:43.206104  2318 net.cpp:397] drop1 -> ip1 (in-place)
I0525 18:54:43.206162  2318 net.cpp:150] Setting up drop1
I0525 18:54:43.206176  2318 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:54:43.206185  2318 net.cpp:165] Memory required for data: 157751600
I0525 18:54:43.206195  2318 layer_factory.hpp:77] Creating layer ip2
I0525 18:54:43.206214  2318 net.cpp:106] Creating Layer ip2
I0525 18:54:43.206224  2318 net.cpp:454] ip2 <- ip1
I0525 18:54:43.206235  2318 net.cpp:411] ip2 -> ip2
I0525 18:54:43.206701  2318 net.cpp:150] Setting up ip2
I0525 18:54:43.206714  2318 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:54:43.206724  2318 net.cpp:165] Memory required for data: 157790800
I0525 18:54:43.206739  2318 layer_factory.hpp:77] Creating layer relu6
I0525 18:54:43.206751  2318 net.cpp:106] Creating Layer relu6
I0525 18:54:43.206761  2318 net.cpp:454] relu6 <- ip2
I0525 18:54:43.206773  2318 net.cpp:397] relu6 -> ip2 (in-place)
I0525 18:54:43.207291  2318 net.cpp:150] Setting up relu6
I0525 18:54:43.207307  2318 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:54:43.207317  2318 net.cpp:165] Memory required for data: 157830000
I0525 18:54:43.207327  2318 layer_factory.hpp:77] Creating layer drop2
I0525 18:54:43.207340  2318 net.cpp:106] Creating Layer drop2
I0525 18:54:43.207350  2318 net.cpp:454] drop2 <- ip2
I0525 18:54:43.207362  2318 net.cpp:397] drop2 -> ip2 (in-place)
I0525 18:54:43.207406  2318 net.cpp:150] Setting up drop2
I0525 18:54:43.207418  2318 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:54:43.207429  2318 net.cpp:165] Memory required for data: 157869200
I0525 18:54:43.207439  2318 layer_factory.hpp:77] Creating layer ip3
I0525 18:54:43.207453  2318 net.cpp:106] Creating Layer ip3
I0525 18:54:43.207463  2318 net.cpp:454] ip3 <- ip2
I0525 18:54:43.207475  2318 net.cpp:411] ip3 -> ip3
I0525 18:54:43.207684  2318 net.cpp:150] Setting up ip3
I0525 18:54:43.207697  2318 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:54:43.207708  2318 net.cpp:165] Memory required for data: 157873600
I0525 18:54:43.207723  2318 layer_factory.hpp:77] Creating layer drop3
I0525 18:54:43.207736  2318 net.cpp:106] Creating Layer drop3
I0525 18:54:43.207746  2318 net.cpp:454] drop3 <- ip3
I0525 18:54:43.207758  2318 net.cpp:397] drop3 -> ip3 (in-place)
I0525 18:54:43.207798  2318 net.cpp:150] Setting up drop3
I0525 18:54:43.207810  2318 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:54:43.207820  2318 net.cpp:165] Memory required for data: 157878000
I0525 18:54:43.207830  2318 layer_factory.hpp:77] Creating layer loss
I0525 18:54:43.207849  2318 net.cpp:106] Creating Layer loss
I0525 18:54:43.207859  2318 net.cpp:454] loss <- ip3
I0525 18:54:43.207870  2318 net.cpp:454] loss <- label
I0525 18:54:43.207883  2318 net.cpp:411] loss -> loss
I0525 18:54:43.207901  2318 layer_factory.hpp:77] Creating layer loss
I0525 18:54:43.208549  2318 net.cpp:150] Setting up loss
I0525 18:54:43.208570  2318 net.cpp:157] Top shape: (1)
I0525 18:54:43.208583  2318 net.cpp:160]     with loss weight 1
I0525 18:54:43.208626  2318 net.cpp:165] Memory required for data: 157878004
I0525 18:54:43.208639  2318 net.cpp:226] loss needs backward computation.
I0525 18:54:43.208650  2318 net.cpp:226] drop3 needs backward computation.
I0525 18:54:43.208658  2318 net.cpp:226] ip3 needs backward computation.
I0525 18:54:43.208668  2318 net.cpp:226] drop2 needs backward computation.
I0525 18:54:43.208678  2318 net.cpp:226] relu6 needs backward computation.
I0525 18:54:43.208688  2318 net.cpp:226] ip2 needs backward computation.
I0525 18:54:43.208698  2318 net.cpp:226] drop1 needs backward computation.
I0525 18:54:43.208709  2318 net.cpp:226] relu5 needs backward computation.
I0525 18:54:43.208717  2318 net.cpp:226] ip1 needs backward computation.
I0525 18:54:43.208727  2318 net.cpp:226] pool4 needs backward computation.
I0525 18:54:43.208739  2318 net.cpp:226] relu4 needs backward computation.
I0525 18:54:43.208748  2318 net.cpp:226] conv4 needs backward computation.
I0525 18:54:43.208758  2318 net.cpp:226] pool3 needs backward computation.
I0525 18:54:43.208770  2318 net.cpp:226] relu3 needs backward computation.
I0525 18:54:43.208788  2318 net.cpp:226] conv3 needs backward computation.
I0525 18:54:43.208801  2318 net.cpp:226] pool2 needs backward computation.
I0525 18:54:43.208811  2318 net.cpp:226] relu2 needs backward computation.
I0525 18:54:43.208820  2318 net.cpp:226] conv2 needs backward computation.
I0525 18:54:43.208832  2318 net.cpp:226] pool1 needs backward computation.
I0525 18:54:43.208842  2318 net.cpp:226] relu1 needs backward computation.
I0525 18:54:43.208853  2318 net.cpp:226] conv1 needs backward computation.
I0525 18:54:43.208863  2318 net.cpp:228] data_hdf5 does not need backward computation.
I0525 18:54:43.208873  2318 net.cpp:270] This network produces output loss
I0525 18:54:43.208897  2318 net.cpp:283] Network initialization done.
I0525 18:54:43.210597  2318 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282.prototxt
I0525 18:54:43.210669  2318 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 18:54:43.211024  2318 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 18:54:43.211212  2318 layer_factory.hpp:77] Creating layer data_hdf5
I0525 18:54:43.211228  2318 net.cpp:106] Creating Layer data_hdf5
I0525 18:54:43.211241  2318 net.cpp:411] data_hdf5 -> data
I0525 18:54:43.211258  2318 net.cpp:411] data_hdf5 -> label
I0525 18:54:43.211274  2318 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 18:54:43.238121  2318 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 18:55:04.609536  2318 net.cpp:150] Setting up data_hdf5
I0525 18:55:04.609700  2318 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 18:55:04.609715  2318 net.cpp:157] Top shape: 100 (100)
I0525 18:55:04.609729  2318 net.cpp:165] Memory required for data: 2540400
I0525 18:55:04.609741  2318 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 18:55:04.609769  2318 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 18:55:04.609781  2318 net.cpp:454] label_data_hdf5_1_split <- label
I0525 18:55:04.609796  2318 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 18:55:04.609817  2318 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 18:55:04.609889  2318 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 18:55:04.609902  2318 net.cpp:157] Top shape: 100 (100)
I0525 18:55:04.609915  2318 net.cpp:157] Top shape: 100 (100)
I0525 18:55:04.609923  2318 net.cpp:165] Memory required for data: 2541200
I0525 18:55:04.609933  2318 layer_factory.hpp:77] Creating layer conv1
I0525 18:55:04.609956  2318 net.cpp:106] Creating Layer conv1
I0525 18:55:04.609967  2318 net.cpp:454] conv1 <- data
I0525 18:55:04.609982  2318 net.cpp:411] conv1 -> conv1
I0525 18:55:04.611903  2318 net.cpp:150] Setting up conv1
I0525 18:55:04.611927  2318 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:55:04.611939  2318 net.cpp:165] Memory required for data: 30189200
I0525 18:55:04.611959  2318 layer_factory.hpp:77] Creating layer relu1
I0525 18:55:04.611974  2318 net.cpp:106] Creating Layer relu1
I0525 18:55:04.611984  2318 net.cpp:454] relu1 <- conv1
I0525 18:55:04.611997  2318 net.cpp:397] relu1 -> conv1 (in-place)
I0525 18:55:04.612504  2318 net.cpp:150] Setting up relu1
I0525 18:55:04.612520  2318 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:55:04.612531  2318 net.cpp:165] Memory required for data: 57837200
I0525 18:55:04.612541  2318 layer_factory.hpp:77] Creating layer pool1
I0525 18:55:04.612558  2318 net.cpp:106] Creating Layer pool1
I0525 18:55:04.612568  2318 net.cpp:454] pool1 <- conv1
I0525 18:55:04.612581  2318 net.cpp:411] pool1 -> pool1
I0525 18:55:04.612658  2318 net.cpp:150] Setting up pool1
I0525 18:55:04.612670  2318 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 18:55:04.612680  2318 net.cpp:165] Memory required for data: 71661200
I0525 18:55:04.612690  2318 layer_factory.hpp:77] Creating layer conv2
I0525 18:55:04.612709  2318 net.cpp:106] Creating Layer conv2
I0525 18:55:04.612720  2318 net.cpp:454] conv2 <- pool1
I0525 18:55:04.612733  2318 net.cpp:411] conv2 -> conv2
I0525 18:55:04.614650  2318 net.cpp:150] Setting up conv2
I0525 18:55:04.614672  2318 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:55:04.614686  2318 net.cpp:165] Memory required for data: 91533200
I0525 18:55:04.614702  2318 layer_factory.hpp:77] Creating layer relu2
I0525 18:55:04.614717  2318 net.cpp:106] Creating Layer relu2
I0525 18:55:04.614727  2318 net.cpp:454] relu2 <- conv2
I0525 18:55:04.614738  2318 net.cpp:397] relu2 -> conv2 (in-place)
I0525 18:55:04.615074  2318 net.cpp:150] Setting up relu2
I0525 18:55:04.615088  2318 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:55:04.615098  2318 net.cpp:165] Memory required for data: 111405200
I0525 18:55:04.615108  2318 layer_factory.hpp:77] Creating layer pool2
I0525 18:55:04.615123  2318 net.cpp:106] Creating Layer pool2
I0525 18:55:04.615133  2318 net.cpp:454] pool2 <- conv2
I0525 18:55:04.615144  2318 net.cpp:411] pool2 -> pool2
I0525 18:55:04.615216  2318 net.cpp:150] Setting up pool2
I0525 18:55:04.615229  2318 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 18:55:04.615239  2318 net.cpp:165] Memory required for data: 121341200
I0525 18:55:04.615249  2318 layer_factory.hpp:77] Creating layer conv3
I0525 18:55:04.615269  2318 net.cpp:106] Creating Layer conv3
I0525 18:55:04.615280  2318 net.cpp:454] conv3 <- pool2
I0525 18:55:04.615294  2318 net.cpp:411] conv3 -> conv3
I0525 18:55:04.617286  2318 net.cpp:150] Setting up conv3
I0525 18:55:04.617310  2318 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:55:04.617321  2318 net.cpp:165] Memory required for data: 132182800
I0525 18:55:04.617353  2318 layer_factory.hpp:77] Creating layer relu3
I0525 18:55:04.617367  2318 net.cpp:106] Creating Layer relu3
I0525 18:55:04.617377  2318 net.cpp:454] relu3 <- conv3
I0525 18:55:04.617390  2318 net.cpp:397] relu3 -> conv3 (in-place)
I0525 18:55:04.617863  2318 net.cpp:150] Setting up relu3
I0525 18:55:04.617879  2318 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:55:04.617890  2318 net.cpp:165] Memory required for data: 143024400
I0525 18:55:04.617900  2318 layer_factory.hpp:77] Creating layer pool3
I0525 18:55:04.617913  2318 net.cpp:106] Creating Layer pool3
I0525 18:55:04.617923  2318 net.cpp:454] pool3 <- conv3
I0525 18:55:04.617936  2318 net.cpp:411] pool3 -> pool3
I0525 18:55:04.618007  2318 net.cpp:150] Setting up pool3
I0525 18:55:04.618021  2318 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 18:55:04.618031  2318 net.cpp:165] Memory required for data: 148445200
I0525 18:55:04.618041  2318 layer_factory.hpp:77] Creating layer conv4
I0525 18:55:04.618060  2318 net.cpp:106] Creating Layer conv4
I0525 18:55:04.618070  2318 net.cpp:454] conv4 <- pool3
I0525 18:55:04.618085  2318 net.cpp:411] conv4 -> conv4
I0525 18:55:04.620170  2318 net.cpp:150] Setting up conv4
I0525 18:55:04.620193  2318 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:55:04.620205  2318 net.cpp:165] Memory required for data: 152074000
I0525 18:55:04.620220  2318 layer_factory.hpp:77] Creating layer relu4
I0525 18:55:04.620235  2318 net.cpp:106] Creating Layer relu4
I0525 18:55:04.620245  2318 net.cpp:454] relu4 <- conv4
I0525 18:55:04.620259  2318 net.cpp:397] relu4 -> conv4 (in-place)
I0525 18:55:04.620731  2318 net.cpp:150] Setting up relu4
I0525 18:55:04.620748  2318 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:55:04.620757  2318 net.cpp:165] Memory required for data: 155702800
I0525 18:55:04.620767  2318 layer_factory.hpp:77] Creating layer pool4
I0525 18:55:04.620781  2318 net.cpp:106] Creating Layer pool4
I0525 18:55:04.620791  2318 net.cpp:454] pool4 <- conv4
I0525 18:55:04.620805  2318 net.cpp:411] pool4 -> pool4
I0525 18:55:04.620875  2318 net.cpp:150] Setting up pool4
I0525 18:55:04.620889  2318 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 18:55:04.620898  2318 net.cpp:165] Memory required for data: 157517200
I0525 18:55:04.620908  2318 layer_factory.hpp:77] Creating layer ip1
I0525 18:55:04.620923  2318 net.cpp:106] Creating Layer ip1
I0525 18:55:04.620934  2318 net.cpp:454] ip1 <- pool4
I0525 18:55:04.620947  2318 net.cpp:411] ip1 -> ip1
I0525 18:55:04.636440  2318 net.cpp:150] Setting up ip1
I0525 18:55:04.636469  2318 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:55:04.636482  2318 net.cpp:165] Memory required for data: 157595600
I0525 18:55:04.636504  2318 layer_factory.hpp:77] Creating layer relu5
I0525 18:55:04.636519  2318 net.cpp:106] Creating Layer relu5
I0525 18:55:04.636530  2318 net.cpp:454] relu5 <- ip1
I0525 18:55:04.636543  2318 net.cpp:397] relu5 -> ip1 (in-place)
I0525 18:55:04.636894  2318 net.cpp:150] Setting up relu5
I0525 18:55:04.636909  2318 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:55:04.636917  2318 net.cpp:165] Memory required for data: 157674000
I0525 18:55:04.636929  2318 layer_factory.hpp:77] Creating layer drop1
I0525 18:55:04.636946  2318 net.cpp:106] Creating Layer drop1
I0525 18:55:04.636956  2318 net.cpp:454] drop1 <- ip1
I0525 18:55:04.636970  2318 net.cpp:397] drop1 -> ip1 (in-place)
I0525 18:55:04.637014  2318 net.cpp:150] Setting up drop1
I0525 18:55:04.637027  2318 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:55:04.637037  2318 net.cpp:165] Memory required for data: 157752400
I0525 18:55:04.637047  2318 layer_factory.hpp:77] Creating layer ip2
I0525 18:55:04.637061  2318 net.cpp:106] Creating Layer ip2
I0525 18:55:04.637071  2318 net.cpp:454] ip2 <- ip1
I0525 18:55:04.637085  2318 net.cpp:411] ip2 -> ip2
I0525 18:55:04.637563  2318 net.cpp:150] Setting up ip2
I0525 18:55:04.637578  2318 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:55:04.637588  2318 net.cpp:165] Memory required for data: 157791600
I0525 18:55:04.637603  2318 layer_factory.hpp:77] Creating layer relu6
I0525 18:55:04.637629  2318 net.cpp:106] Creating Layer relu6
I0525 18:55:04.637640  2318 net.cpp:454] relu6 <- ip2
I0525 18:55:04.637653  2318 net.cpp:397] relu6 -> ip2 (in-place)
I0525 18:55:04.638190  2318 net.cpp:150] Setting up relu6
I0525 18:55:04.638206  2318 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:55:04.638216  2318 net.cpp:165] Memory required for data: 157830800
I0525 18:55:04.638226  2318 layer_factory.hpp:77] Creating layer drop2
I0525 18:55:04.638241  2318 net.cpp:106] Creating Layer drop2
I0525 18:55:04.638250  2318 net.cpp:454] drop2 <- ip2
I0525 18:55:04.638264  2318 net.cpp:397] drop2 -> ip2 (in-place)
I0525 18:55:04.638309  2318 net.cpp:150] Setting up drop2
I0525 18:55:04.638321  2318 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:55:04.638331  2318 net.cpp:165] Memory required for data: 157870000
I0525 18:55:04.638340  2318 layer_factory.hpp:77] Creating layer ip3
I0525 18:55:04.638355  2318 net.cpp:106] Creating Layer ip3
I0525 18:55:04.638365  2318 net.cpp:454] ip3 <- ip2
I0525 18:55:04.638378  2318 net.cpp:411] ip3 -> ip3
I0525 18:55:04.638602  2318 net.cpp:150] Setting up ip3
I0525 18:55:04.638615  2318 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:55:04.638624  2318 net.cpp:165] Memory required for data: 157874400
I0525 18:55:04.638640  2318 layer_factory.hpp:77] Creating layer drop3
I0525 18:55:04.638653  2318 net.cpp:106] Creating Layer drop3
I0525 18:55:04.638664  2318 net.cpp:454] drop3 <- ip3
I0525 18:55:04.638676  2318 net.cpp:397] drop3 -> ip3 (in-place)
I0525 18:55:04.638717  2318 net.cpp:150] Setting up drop3
I0525 18:55:04.638731  2318 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:55:04.638741  2318 net.cpp:165] Memory required for data: 157878800
I0525 18:55:04.638751  2318 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 18:55:04.638764  2318 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 18:55:04.638774  2318 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 18:55:04.638787  2318 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 18:55:04.638803  2318 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 18:55:04.638876  2318 net.cpp:150] Setting up ip3_drop3_0_split
I0525 18:55:04.638890  2318 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:55:04.638902  2318 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:55:04.638912  2318 net.cpp:165] Memory required for data: 157887600
I0525 18:55:04.638922  2318 layer_factory.hpp:77] Creating layer accuracy
I0525 18:55:04.638944  2318 net.cpp:106] Creating Layer accuracy
I0525 18:55:04.638954  2318 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 18:55:04.638965  2318 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 18:55:04.638979  2318 net.cpp:411] accuracy -> accuracy
I0525 18:55:04.639003  2318 net.cpp:150] Setting up accuracy
I0525 18:55:04.639015  2318 net.cpp:157] Top shape: (1)
I0525 18:55:04.639025  2318 net.cpp:165] Memory required for data: 157887604
I0525 18:55:04.639035  2318 layer_factory.hpp:77] Creating layer loss
I0525 18:55:04.639050  2318 net.cpp:106] Creating Layer loss
I0525 18:55:04.639060  2318 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 18:55:04.639071  2318 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 18:55:04.639084  2318 net.cpp:411] loss -> loss
I0525 18:55:04.639103  2318 layer_factory.hpp:77] Creating layer loss
I0525 18:55:04.639590  2318 net.cpp:150] Setting up loss
I0525 18:55:04.639603  2318 net.cpp:157] Top shape: (1)
I0525 18:55:04.639613  2318 net.cpp:160]     with loss weight 1
I0525 18:55:04.639632  2318 net.cpp:165] Memory required for data: 157887608
I0525 18:55:04.639642  2318 net.cpp:226] loss needs backward computation.
I0525 18:55:04.639654  2318 net.cpp:228] accuracy does not need backward computation.
I0525 18:55:04.639665  2318 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 18:55:04.639677  2318 net.cpp:226] drop3 needs backward computation.
I0525 18:55:04.639686  2318 net.cpp:226] ip3 needs backward computation.
I0525 18:55:04.639698  2318 net.cpp:226] drop2 needs backward computation.
I0525 18:55:04.639715  2318 net.cpp:226] relu6 needs backward computation.
I0525 18:55:04.639725  2318 net.cpp:226] ip2 needs backward computation.
I0525 18:55:04.639735  2318 net.cpp:226] drop1 needs backward computation.
I0525 18:55:04.639745  2318 net.cpp:226] relu5 needs backward computation.
I0525 18:55:04.639755  2318 net.cpp:226] ip1 needs backward computation.
I0525 18:55:04.639766  2318 net.cpp:226] pool4 needs backward computation.
I0525 18:55:04.639776  2318 net.cpp:226] relu4 needs backward computation.
I0525 18:55:04.639785  2318 net.cpp:226] conv4 needs backward computation.
I0525 18:55:04.639796  2318 net.cpp:226] pool3 needs backward computation.
I0525 18:55:04.639806  2318 net.cpp:226] relu3 needs backward computation.
I0525 18:55:04.639816  2318 net.cpp:226] conv3 needs backward computation.
I0525 18:55:04.639827  2318 net.cpp:226] pool2 needs backward computation.
I0525 18:55:04.639837  2318 net.cpp:226] relu2 needs backward computation.
I0525 18:55:04.639847  2318 net.cpp:226] conv2 needs backward computation.
I0525 18:55:04.639858  2318 net.cpp:226] pool1 needs backward computation.
I0525 18:55:04.639868  2318 net.cpp:226] relu1 needs backward computation.
I0525 18:55:04.639878  2318 net.cpp:226] conv1 needs backward computation.
I0525 18:55:04.639888  2318 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 18:55:04.639899  2318 net.cpp:228] data_hdf5 does not need backward computation.
I0525 18:55:04.639910  2318 net.cpp:270] This network produces output accuracy
I0525 18:55:04.639921  2318 net.cpp:270] This network produces output loss
I0525 18:55:04.639948  2318 net.cpp:283] Network initialization done.
I0525 18:55:04.640082  2318 solver.cpp:60] Solver scaffolding done.
I0525 18:55:04.641230  2318 caffe.cpp:212] Starting Optimization
I0525 18:55:04.641249  2318 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 18:55:04.641263  2318 solver.cpp:289] Learning Rate Policy: fixed
I0525 18:55:04.642323  2318 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 18:55:52.519049  2318 solver.cpp:409]     Test net output #0: accuracy = 0.0591534
I0525 18:55:52.519212  2318 solver.cpp:409]     Test net output #1: loss = 2.39852 (* 1 = 2.39852 loss)
I0525 18:55:52.551923  2318 solver.cpp:237] Iteration 0, loss = 2.3978
I0525 18:55:52.551959  2318 solver.cpp:253]     Train net output #0: loss = 2.3978 (* 1 = 2.3978 loss)
I0525 18:55:52.551977  2318 sgd_solver.cpp:106] Iteration 0, lr = 0.003
I0525 18:56:01.268606  2318 solver.cpp:237] Iteration 150, loss = 2.31553
I0525 18:56:01.268653  2318 solver.cpp:253]     Train net output #0: loss = 2.31553 (* 1 = 2.31553 loss)
I0525 18:56:01.268671  2318 sgd_solver.cpp:106] Iteration 150, lr = 0.003
I0525 18:56:09.997128  2318 solver.cpp:237] Iteration 300, loss = 2.15252
I0525 18:56:09.997164  2318 solver.cpp:253]     Train net output #0: loss = 2.15252 (* 1 = 2.15252 loss)
I0525 18:56:09.997181  2318 sgd_solver.cpp:106] Iteration 300, lr = 0.003
I0525 18:56:18.720458  2318 solver.cpp:237] Iteration 450, loss = 2.04118
I0525 18:56:18.720494  2318 solver.cpp:253]     Train net output #0: loss = 2.04118 (* 1 = 2.04118 loss)
I0525 18:56:18.720507  2318 sgd_solver.cpp:106] Iteration 450, lr = 0.003
I0525 18:56:27.446008  2318 solver.cpp:237] Iteration 600, loss = 1.99909
I0525 18:56:27.446171  2318 solver.cpp:253]     Train net output #0: loss = 1.99909 (* 1 = 1.99909 loss)
I0525 18:56:27.446187  2318 sgd_solver.cpp:106] Iteration 600, lr = 0.003
I0525 18:56:36.167192  2318 solver.cpp:237] Iteration 750, loss = 2.08116
I0525 18:56:36.167227  2318 solver.cpp:253]     Train net output #0: loss = 2.08116 (* 1 = 2.08116 loss)
I0525 18:56:36.167244  2318 sgd_solver.cpp:106] Iteration 750, lr = 0.003
I0525 18:56:44.890554  2318 solver.cpp:237] Iteration 900, loss = 1.91451
I0525 18:56:44.890590  2318 solver.cpp:253]     Train net output #0: loss = 1.91451 (* 1 = 1.91451 loss)
I0525 18:56:44.890604  2318 sgd_solver.cpp:106] Iteration 900, lr = 0.003
I0525 18:57:15.828629  2318 solver.cpp:237] Iteration 1050, loss = 1.88613
I0525 18:57:15.828790  2318 solver.cpp:253]     Train net output #0: loss = 1.88613 (* 1 = 1.88613 loss)
I0525 18:57:15.828806  2318 sgd_solver.cpp:106] Iteration 1050, lr = 0.003
I0525 18:57:24.559914  2318 solver.cpp:237] Iteration 1200, loss = 1.85074
I0525 18:57:24.559949  2318 solver.cpp:253]     Train net output #0: loss = 1.85074 (* 1 = 1.85074 loss)
I0525 18:57:24.559968  2318 sgd_solver.cpp:106] Iteration 1200, lr = 0.003
I0525 18:57:33.285593  2318 solver.cpp:237] Iteration 1350, loss = 1.67827
I0525 18:57:33.285629  2318 solver.cpp:253]     Train net output #0: loss = 1.67827 (* 1 = 1.67827 loss)
I0525 18:57:33.285646  2318 sgd_solver.cpp:106] Iteration 1350, lr = 0.003
I0525 18:57:41.963963  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_1500.caffemodel
I0525 18:57:42.046360  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_1500.solverstate
I0525 18:57:42.092571  2318 solver.cpp:237] Iteration 1500, loss = 1.85243
I0525 18:57:42.092620  2318 solver.cpp:253]     Train net output #0: loss = 1.85243 (* 1 = 1.85243 loss)
I0525 18:57:42.092634  2318 sgd_solver.cpp:106] Iteration 1500, lr = 0.003
I0525 18:57:50.822088  2318 solver.cpp:237] Iteration 1650, loss = 1.7891
I0525 18:57:50.822242  2318 solver.cpp:253]     Train net output #0: loss = 1.7891 (* 1 = 1.7891 loss)
I0525 18:57:50.822255  2318 sgd_solver.cpp:106] Iteration 1650, lr = 0.003
I0525 18:57:59.546167  2318 solver.cpp:237] Iteration 1800, loss = 1.50506
I0525 18:57:59.546201  2318 solver.cpp:253]     Train net output #0: loss = 1.50506 (* 1 = 1.50506 loss)
I0525 18:57:59.546216  2318 sgd_solver.cpp:106] Iteration 1800, lr = 0.003
I0525 18:58:08.272902  2318 solver.cpp:237] Iteration 1950, loss = 1.69767
I0525 18:58:08.272943  2318 solver.cpp:253]     Train net output #0: loss = 1.69767 (* 1 = 1.69767 loss)
I0525 18:58:08.272964  2318 sgd_solver.cpp:106] Iteration 1950, lr = 0.003
I0525 18:58:39.201978  2318 solver.cpp:237] Iteration 2100, loss = 1.5401
I0525 18:58:39.202136  2318 solver.cpp:253]     Train net output #0: loss = 1.5401 (* 1 = 1.5401 loss)
I0525 18:58:39.202149  2318 sgd_solver.cpp:106] Iteration 2100, lr = 0.003
I0525 18:58:47.927659  2318 solver.cpp:237] Iteration 2250, loss = 1.80761
I0525 18:58:47.927693  2318 solver.cpp:253]     Train net output #0: loss = 1.80761 (* 1 = 1.80761 loss)
I0525 18:58:47.927711  2318 sgd_solver.cpp:106] Iteration 2250, lr = 0.003
I0525 18:58:56.653204  2318 solver.cpp:237] Iteration 2400, loss = 1.7338
I0525 18:58:56.653247  2318 solver.cpp:253]     Train net output #0: loss = 1.7338 (* 1 = 1.7338 loss)
I0525 18:58:56.653266  2318 sgd_solver.cpp:106] Iteration 2400, lr = 0.003
I0525 18:59:05.383265  2318 solver.cpp:237] Iteration 2550, loss = 1.74777
I0525 18:59:05.383299  2318 solver.cpp:253]     Train net output #0: loss = 1.74777 (* 1 = 1.74777 loss)
I0525 18:59:05.383317  2318 sgd_solver.cpp:106] Iteration 2550, lr = 0.003
I0525 18:59:14.103466  2318 solver.cpp:237] Iteration 2700, loss = 1.62805
I0525 18:59:14.103612  2318 solver.cpp:253]     Train net output #0: loss = 1.62805 (* 1 = 1.62805 loss)
I0525 18:59:14.103626  2318 sgd_solver.cpp:106] Iteration 2700, lr = 0.003
I0525 18:59:22.829277  2318 solver.cpp:237] Iteration 2850, loss = 1.76902
I0525 18:59:22.829322  2318 solver.cpp:253]     Train net output #0: loss = 1.76902 (* 1 = 1.76902 loss)
I0525 18:59:22.829339  2318 sgd_solver.cpp:106] Iteration 2850, lr = 0.003
I0525 18:59:31.498700  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_3000.caffemodel
I0525 18:59:31.578187  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_3000.solverstate
I0525 18:59:31.604826  2318 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 19:00:18.505944  2318 solver.cpp:409]     Test net output #0: accuracy = 0.71774
I0525 19:00:18.506120  2318 solver.cpp:409]     Test net output #1: loss = 0.986114 (* 1 = 0.986114 loss)
I0525 19:00:40.718443  2318 solver.cpp:237] Iteration 3000, loss = 1.54836
I0525 19:00:40.718497  2318 solver.cpp:253]     Train net output #0: loss = 1.54836 (* 1 = 1.54836 loss)
I0525 19:00:40.718513  2318 sgd_solver.cpp:106] Iteration 3000, lr = 0.003
I0525 19:00:49.460232  2318 solver.cpp:237] Iteration 3150, loss = 1.54646
I0525 19:00:49.460369  2318 solver.cpp:253]     Train net output #0: loss = 1.54646 (* 1 = 1.54646 loss)
I0525 19:00:49.460383  2318 sgd_solver.cpp:106] Iteration 3150, lr = 0.003
I0525 19:00:58.203677  2318 solver.cpp:237] Iteration 3300, loss = 1.95275
I0525 19:00:58.203712  2318 solver.cpp:253]     Train net output #0: loss = 1.95275 (* 1 = 1.95275 loss)
I0525 19:00:58.203728  2318 sgd_solver.cpp:106] Iteration 3300, lr = 0.003
I0525 19:01:06.942610  2318 solver.cpp:237] Iteration 3450, loss = 1.6317
I0525 19:01:06.942651  2318 solver.cpp:253]     Train net output #0: loss = 1.6317 (* 1 = 1.6317 loss)
I0525 19:01:06.942670  2318 sgd_solver.cpp:106] Iteration 3450, lr = 0.003
I0525 19:01:15.685554  2318 solver.cpp:237] Iteration 3600, loss = 1.53994
I0525 19:01:15.685588  2318 solver.cpp:253]     Train net output #0: loss = 1.53994 (* 1 = 1.53994 loss)
I0525 19:01:15.685605  2318 sgd_solver.cpp:106] Iteration 3600, lr = 0.003
I0525 19:01:24.424743  2318 solver.cpp:237] Iteration 3750, loss = 1.60465
I0525 19:01:24.424891  2318 solver.cpp:253]     Train net output #0: loss = 1.60465 (* 1 = 1.60465 loss)
I0525 19:01:24.424906  2318 sgd_solver.cpp:106] Iteration 3750, lr = 0.003
I0525 19:01:33.164703  2318 solver.cpp:237] Iteration 3900, loss = 1.39109
I0525 19:01:33.164738  2318 solver.cpp:253]     Train net output #0: loss = 1.39109 (* 1 = 1.39109 loss)
I0525 19:01:33.164754  2318 sgd_solver.cpp:106] Iteration 3900, lr = 0.003
I0525 19:02:04.154177  2318 solver.cpp:237] Iteration 4050, loss = 1.51349
I0525 19:02:04.154342  2318 solver.cpp:253]     Train net output #0: loss = 1.51349 (* 1 = 1.51349 loss)
I0525 19:02:04.154357  2318 sgd_solver.cpp:106] Iteration 4050, lr = 0.003
I0525 19:02:12.895252  2318 solver.cpp:237] Iteration 4200, loss = 1.37739
I0525 19:02:12.895287  2318 solver.cpp:253]     Train net output #0: loss = 1.37739 (* 1 = 1.37739 loss)
I0525 19:02:12.895304  2318 sgd_solver.cpp:106] Iteration 4200, lr = 0.003
I0525 19:02:21.632048  2318 solver.cpp:237] Iteration 4350, loss = 1.35957
I0525 19:02:21.632097  2318 solver.cpp:253]     Train net output #0: loss = 1.35957 (* 1 = 1.35957 loss)
I0525 19:02:21.632112  2318 sgd_solver.cpp:106] Iteration 4350, lr = 0.003
I0525 19:02:30.310092  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_4500.caffemodel
I0525 19:02:30.391235  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_4500.solverstate
I0525 19:02:30.437223  2318 solver.cpp:237] Iteration 4500, loss = 1.39771
I0525 19:02:30.437269  2318 solver.cpp:253]     Train net output #0: loss = 1.39771 (* 1 = 1.39771 loss)
I0525 19:02:30.437290  2318 sgd_solver.cpp:106] Iteration 4500, lr = 0.003
I0525 19:02:39.175283  2318 solver.cpp:237] Iteration 4650, loss = 1.58638
I0525 19:02:39.175444  2318 solver.cpp:253]     Train net output #0: loss = 1.58638 (* 1 = 1.58638 loss)
I0525 19:02:39.175458  2318 sgd_solver.cpp:106] Iteration 4650, lr = 0.003
I0525 19:02:47.910790  2318 solver.cpp:237] Iteration 4800, loss = 1.64903
I0525 19:02:47.910825  2318 solver.cpp:253]     Train net output #0: loss = 1.64903 (* 1 = 1.64903 loss)
I0525 19:02:47.910842  2318 sgd_solver.cpp:106] Iteration 4800, lr = 0.003
I0525 19:02:56.647083  2318 solver.cpp:237] Iteration 4950, loss = 1.66866
I0525 19:02:56.647119  2318 solver.cpp:253]     Train net output #0: loss = 1.66866 (* 1 = 1.66866 loss)
I0525 19:02:56.647135  2318 sgd_solver.cpp:106] Iteration 4950, lr = 0.003
I0525 19:03:27.613703  2318 solver.cpp:237] Iteration 5100, loss = 1.45238
I0525 19:03:27.613885  2318 solver.cpp:253]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0525 19:03:27.613901  2318 sgd_solver.cpp:106] Iteration 5100, lr = 0.003
I0525 19:03:36.352221  2318 solver.cpp:237] Iteration 5250, loss = 1.32328
I0525 19:03:36.352265  2318 solver.cpp:253]     Train net output #0: loss = 1.32328 (* 1 = 1.32328 loss)
I0525 19:03:36.352283  2318 sgd_solver.cpp:106] Iteration 5250, lr = 0.003
I0525 19:03:45.086563  2318 solver.cpp:237] Iteration 5400, loss = 1.46561
I0525 19:03:45.086599  2318 solver.cpp:253]     Train net output #0: loss = 1.46561 (* 1 = 1.46561 loss)
I0525 19:03:45.086616  2318 sgd_solver.cpp:106] Iteration 5400, lr = 0.003
I0525 19:03:53.829123  2318 solver.cpp:237] Iteration 5550, loss = 1.50688
I0525 19:03:53.829169  2318 solver.cpp:253]     Train net output #0: loss = 1.50688 (* 1 = 1.50688 loss)
I0525 19:03:53.829185  2318 sgd_solver.cpp:106] Iteration 5550, lr = 0.003
I0525 19:04:02.569455  2318 solver.cpp:237] Iteration 5700, loss = 1.3795
I0525 19:04:02.569596  2318 solver.cpp:253]     Train net output #0: loss = 1.3795 (* 1 = 1.3795 loss)
I0525 19:04:02.569609  2318 sgd_solver.cpp:106] Iteration 5700, lr = 0.003
I0525 19:04:11.311889  2318 solver.cpp:237] Iteration 5850, loss = 1.4139
I0525 19:04:11.311923  2318 solver.cpp:253]     Train net output #0: loss = 1.4139 (* 1 = 1.4139 loss)
I0525 19:04:11.311941  2318 sgd_solver.cpp:106] Iteration 5850, lr = 0.003
I0525 19:04:19.993540  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_6000.caffemodel
I0525 19:04:20.074568  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_6000.solverstate
I0525 19:04:20.102444  2318 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 19:05:27.877789  2318 solver.cpp:409]     Test net output #0: accuracy = 0.806387
I0525 19:05:27.877960  2318 solver.cpp:409]     Test net output #1: loss = 0.639249 (* 1 = 0.639249 loss)
I0525 19:05:50.160332  2318 solver.cpp:237] Iteration 6000, loss = 1.38822
I0525 19:05:50.160383  2318 solver.cpp:253]     Train net output #0: loss = 1.38822 (* 1 = 1.38822 loss)
I0525 19:05:50.160398  2318 sgd_solver.cpp:106] Iteration 6000, lr = 0.003
I0525 19:05:58.889529  2318 solver.cpp:237] Iteration 6150, loss = 1.34475
I0525 19:05:58.889688  2318 solver.cpp:253]     Train net output #0: loss = 1.34475 (* 1 = 1.34475 loss)
I0525 19:05:58.889703  2318 sgd_solver.cpp:106] Iteration 6150, lr = 0.003
I0525 19:06:07.617046  2318 solver.cpp:237] Iteration 6300, loss = 1.56
I0525 19:06:07.617081  2318 solver.cpp:253]     Train net output #0: loss = 1.56 (* 1 = 1.56 loss)
I0525 19:06:07.617099  2318 sgd_solver.cpp:106] Iteration 6300, lr = 0.003
I0525 19:06:16.347868  2318 solver.cpp:237] Iteration 6450, loss = 1.56873
I0525 19:06:16.347903  2318 solver.cpp:253]     Train net output #0: loss = 1.56873 (* 1 = 1.56873 loss)
I0525 19:06:16.347920  2318 sgd_solver.cpp:106] Iteration 6450, lr = 0.003
I0525 19:06:25.082478  2318 solver.cpp:237] Iteration 6600, loss = 1.5984
I0525 19:06:25.082517  2318 solver.cpp:253]     Train net output #0: loss = 1.5984 (* 1 = 1.5984 loss)
I0525 19:06:25.082538  2318 sgd_solver.cpp:106] Iteration 6600, lr = 0.003
I0525 19:06:33.807802  2318 solver.cpp:237] Iteration 6750, loss = 1.52957
I0525 19:06:33.807940  2318 solver.cpp:253]     Train net output #0: loss = 1.52957 (* 1 = 1.52957 loss)
I0525 19:06:33.807953  2318 sgd_solver.cpp:106] Iteration 6750, lr = 0.003
I0525 19:06:42.537664  2318 solver.cpp:237] Iteration 6900, loss = 1.38535
I0525 19:06:42.537698  2318 solver.cpp:253]     Train net output #0: loss = 1.38535 (* 1 = 1.38535 loss)
I0525 19:06:42.537716  2318 sgd_solver.cpp:106] Iteration 6900, lr = 0.003
I0525 19:07:13.470640  2318 solver.cpp:237] Iteration 7050, loss = 1.22073
I0525 19:07:13.470793  2318 solver.cpp:253]     Train net output #0: loss = 1.22073 (* 1 = 1.22073 loss)
I0525 19:07:13.470806  2318 sgd_solver.cpp:106] Iteration 7050, lr = 0.003
I0525 19:07:22.197412  2318 solver.cpp:237] Iteration 7200, loss = 1.32818
I0525 19:07:22.197446  2318 solver.cpp:253]     Train net output #0: loss = 1.32818 (* 1 = 1.32818 loss)
I0525 19:07:22.197464  2318 sgd_solver.cpp:106] Iteration 7200, lr = 0.003
I0525 19:07:30.932896  2318 solver.cpp:237] Iteration 7350, loss = 1.61881
I0525 19:07:30.932931  2318 solver.cpp:253]     Train net output #0: loss = 1.61881 (* 1 = 1.61881 loss)
I0525 19:07:30.932945  2318 sgd_solver.cpp:106] Iteration 7350, lr = 0.003
I0525 19:07:39.607795  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_7500.caffemodel
I0525 19:07:39.688668  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_7500.solverstate
I0525 19:07:39.734045  2318 solver.cpp:237] Iteration 7500, loss = 1.37046
I0525 19:07:39.734097  2318 solver.cpp:253]     Train net output #0: loss = 1.37046 (* 1 = 1.37046 loss)
I0525 19:07:39.734110  2318 sgd_solver.cpp:106] Iteration 7500, lr = 0.003
I0525 19:07:48.465155  2318 solver.cpp:237] Iteration 7650, loss = 1.48637
I0525 19:07:48.465312  2318 solver.cpp:253]     Train net output #0: loss = 1.48637 (* 1 = 1.48637 loss)
I0525 19:07:48.465324  2318 sgd_solver.cpp:106] Iteration 7650, lr = 0.003
I0525 19:07:57.194280  2318 solver.cpp:237] Iteration 7800, loss = 1.40654
I0525 19:07:57.194315  2318 solver.cpp:253]     Train net output #0: loss = 1.40654 (* 1 = 1.40654 loss)
I0525 19:07:57.194334  2318 sgd_solver.cpp:106] Iteration 7800, lr = 0.003
I0525 19:08:05.925212  2318 solver.cpp:237] Iteration 7950, loss = 1.40366
I0525 19:08:05.925257  2318 solver.cpp:253]     Train net output #0: loss = 1.40366 (* 1 = 1.40366 loss)
I0525 19:08:05.925271  2318 sgd_solver.cpp:106] Iteration 7950, lr = 0.003
I0525 19:08:36.912256  2318 solver.cpp:237] Iteration 8100, loss = 1.39623
I0525 19:08:36.912433  2318 solver.cpp:253]     Train net output #0: loss = 1.39623 (* 1 = 1.39623 loss)
I0525 19:08:36.912447  2318 sgd_solver.cpp:106] Iteration 8100, lr = 0.003
I0525 19:08:45.643829  2318 solver.cpp:237] Iteration 8250, loss = 1.53652
I0525 19:08:45.643864  2318 solver.cpp:253]     Train net output #0: loss = 1.53652 (* 1 = 1.53652 loss)
I0525 19:08:45.643882  2318 sgd_solver.cpp:106] Iteration 8250, lr = 0.003
I0525 19:08:54.378383  2318 solver.cpp:237] Iteration 8400, loss = 1.29511
I0525 19:08:54.378427  2318 solver.cpp:253]     Train net output #0: loss = 1.29511 (* 1 = 1.29511 loss)
I0525 19:08:54.378446  2318 sgd_solver.cpp:106] Iteration 8400, lr = 0.003
I0525 19:09:03.113945  2318 solver.cpp:237] Iteration 8550, loss = 1.28155
I0525 19:09:03.113981  2318 solver.cpp:253]     Train net output #0: loss = 1.28155 (* 1 = 1.28155 loss)
I0525 19:09:03.113997  2318 sgd_solver.cpp:106] Iteration 8550, lr = 0.003
I0525 19:09:11.846284  2318 solver.cpp:237] Iteration 8700, loss = 1.35838
I0525 19:09:11.846428  2318 solver.cpp:253]     Train net output #0: loss = 1.35838 (* 1 = 1.35838 loss)
I0525 19:09:11.846441  2318 sgd_solver.cpp:106] Iteration 8700, lr = 0.003
I0525 19:09:20.573254  2318 solver.cpp:237] Iteration 8850, loss = 1.12595
I0525 19:09:20.573298  2318 solver.cpp:253]     Train net output #0: loss = 1.12595 (* 1 = 1.12595 loss)
I0525 19:09:20.573315  2318 sgd_solver.cpp:106] Iteration 8850, lr = 0.003
I0525 19:09:29.244817  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_9000.caffemodel
I0525 19:09:29.323164  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_9000.solverstate
I0525 19:09:29.348260  2318 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 19:10:15.933866  2318 solver.cpp:409]     Test net output #0: accuracy = 0.83394
I0525 19:10:15.934023  2318 solver.cpp:409]     Test net output #1: loss = 0.583972 (* 1 = 0.583972 loss)
I0525 19:10:38.180935  2318 solver.cpp:237] Iteration 9000, loss = 1.51167
I0525 19:10:38.180987  2318 solver.cpp:253]     Train net output #0: loss = 1.51167 (* 1 = 1.51167 loss)
I0525 19:10:38.181002  2318 sgd_solver.cpp:106] Iteration 9000, lr = 0.003
I0525 19:10:46.917764  2318 solver.cpp:237] Iteration 9150, loss = 1.3844
I0525 19:10:46.917934  2318 solver.cpp:253]     Train net output #0: loss = 1.3844 (* 1 = 1.3844 loss)
I0525 19:10:46.917948  2318 sgd_solver.cpp:106] Iteration 9150, lr = 0.003
I0525 19:10:55.660373  2318 solver.cpp:237] Iteration 9300, loss = 1.3679
I0525 19:10:55.660408  2318 solver.cpp:253]     Train net output #0: loss = 1.3679 (* 1 = 1.3679 loss)
I0525 19:10:55.660426  2318 sgd_solver.cpp:106] Iteration 9300, lr = 0.003
I0525 19:11:04.399361  2318 solver.cpp:237] Iteration 9450, loss = 1.4127
I0525 19:11:04.399408  2318 solver.cpp:253]     Train net output #0: loss = 1.4127 (* 1 = 1.4127 loss)
I0525 19:11:04.399425  2318 sgd_solver.cpp:106] Iteration 9450, lr = 0.003
I0525 19:11:13.135689  2318 solver.cpp:237] Iteration 9600, loss = 1.35875
I0525 19:11:13.135723  2318 solver.cpp:253]     Train net output #0: loss = 1.35875 (* 1 = 1.35875 loss)
I0525 19:11:13.135740  2318 sgd_solver.cpp:106] Iteration 9600, lr = 0.003
I0525 19:11:21.880303  2318 solver.cpp:237] Iteration 9750, loss = 1.44022
I0525 19:11:21.880460  2318 solver.cpp:253]     Train net output #0: loss = 1.44022 (* 1 = 1.44022 loss)
I0525 19:11:21.880472  2318 sgd_solver.cpp:106] Iteration 9750, lr = 0.003
I0525 19:11:30.613667  2318 solver.cpp:237] Iteration 9900, loss = 1.31548
I0525 19:11:30.613701  2318 solver.cpp:253]     Train net output #0: loss = 1.31548 (* 1 = 1.31548 loss)
I0525 19:11:30.613725  2318 sgd_solver.cpp:106] Iteration 9900, lr = 0.003
I0525 19:12:01.614440  2318 solver.cpp:237] Iteration 10050, loss = 1.49681
I0525 19:12:01.614617  2318 solver.cpp:253]     Train net output #0: loss = 1.49681 (* 1 = 1.49681 loss)
I0525 19:12:01.614631  2318 sgd_solver.cpp:106] Iteration 10050, lr = 0.003
I0525 19:12:10.358541  2318 solver.cpp:237] Iteration 10200, loss = 1.30826
I0525 19:12:10.358577  2318 solver.cpp:253]     Train net output #0: loss = 1.30826 (* 1 = 1.30826 loss)
I0525 19:12:10.358590  2318 sgd_solver.cpp:106] Iteration 10200, lr = 0.003
I0525 19:12:19.094458  2318 solver.cpp:237] Iteration 10350, loss = 1.09861
I0525 19:12:19.094501  2318 solver.cpp:253]     Train net output #0: loss = 1.09861 (* 1 = 1.09861 loss)
I0525 19:12:19.094516  2318 sgd_solver.cpp:106] Iteration 10350, lr = 0.003
I0525 19:12:27.779937  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_10500.caffemodel
I0525 19:12:27.858149  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_10500.solverstate
I0525 19:12:27.902294  2318 solver.cpp:237] Iteration 10500, loss = 1.18275
I0525 19:12:27.902340  2318 solver.cpp:253]     Train net output #0: loss = 1.18275 (* 1 = 1.18275 loss)
I0525 19:12:27.902354  2318 sgd_solver.cpp:106] Iteration 10500, lr = 0.003
I0525 19:12:36.646308  2318 solver.cpp:237] Iteration 10650, loss = 1.28615
I0525 19:12:36.646458  2318 solver.cpp:253]     Train net output #0: loss = 1.28615 (* 1 = 1.28615 loss)
I0525 19:12:36.646471  2318 sgd_solver.cpp:106] Iteration 10650, lr = 0.003
I0525 19:12:45.386531  2318 solver.cpp:237] Iteration 10800, loss = 1.23417
I0525 19:12:45.386571  2318 solver.cpp:253]     Train net output #0: loss = 1.23417 (* 1 = 1.23417 loss)
I0525 19:12:45.386587  2318 sgd_solver.cpp:106] Iteration 10800, lr = 0.003
I0525 19:12:54.132917  2318 solver.cpp:237] Iteration 10950, loss = 1.574
I0525 19:12:54.132953  2318 solver.cpp:253]     Train net output #0: loss = 1.574 (* 1 = 1.574 loss)
I0525 19:12:54.132969  2318 sgd_solver.cpp:106] Iteration 10950, lr = 0.003
I0525 19:13:25.089830  2318 solver.cpp:237] Iteration 11100, loss = 1.16684
I0525 19:13:25.090029  2318 solver.cpp:253]     Train net output #0: loss = 1.16684 (* 1 = 1.16684 loss)
I0525 19:13:25.090044  2318 sgd_solver.cpp:106] Iteration 11100, lr = 0.003
I0525 19:13:33.830309  2318 solver.cpp:237] Iteration 11250, loss = 1.35871
I0525 19:13:33.830353  2318 solver.cpp:253]     Train net output #0: loss = 1.35871 (* 1 = 1.35871 loss)
I0525 19:13:33.830370  2318 sgd_solver.cpp:106] Iteration 11250, lr = 0.003
I0525 19:13:42.566525  2318 solver.cpp:237] Iteration 11400, loss = 1.35603
I0525 19:13:42.566561  2318 solver.cpp:253]     Train net output #0: loss = 1.35603 (* 1 = 1.35603 loss)
I0525 19:13:42.566577  2318 sgd_solver.cpp:106] Iteration 11400, lr = 0.003
I0525 19:13:51.301026  2318 solver.cpp:237] Iteration 11550, loss = 1.25993
I0525 19:13:51.301062  2318 solver.cpp:253]     Train net output #0: loss = 1.25993 (* 1 = 1.25993 loss)
I0525 19:13:51.301079  2318 sgd_solver.cpp:106] Iteration 11550, lr = 0.003
I0525 19:14:00.036914  2318 solver.cpp:237] Iteration 11700, loss = 1.37119
I0525 19:14:00.037080  2318 solver.cpp:253]     Train net output #0: loss = 1.37119 (* 1 = 1.37119 loss)
I0525 19:14:00.037094  2318 sgd_solver.cpp:106] Iteration 11700, lr = 0.003
I0525 19:14:08.773329  2318 solver.cpp:237] Iteration 11850, loss = 1.2419
I0525 19:14:08.773362  2318 solver.cpp:253]     Train net output #0: loss = 1.2419 (* 1 = 1.2419 loss)
I0525 19:14:08.773380  2318 sgd_solver.cpp:106] Iteration 11850, lr = 0.003
I0525 19:14:17.454352  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_12000.caffemodel
I0525 19:14:17.533545  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_12000.solverstate
I0525 19:14:17.559646  2318 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 19:15:25.306967  2318 solver.cpp:409]     Test net output #0: accuracy = 0.849146
I0525 19:15:25.307140  2318 solver.cpp:409]     Test net output #1: loss = 0.52179 (* 1 = 0.52179 loss)
I0525 19:15:47.533404  2318 solver.cpp:237] Iteration 12000, loss = 1.33367
I0525 19:15:47.533457  2318 solver.cpp:253]     Train net output #0: loss = 1.33367 (* 1 = 1.33367 loss)
I0525 19:15:47.533473  2318 sgd_solver.cpp:106] Iteration 12000, lr = 0.003
I0525 19:15:56.256860  2318 solver.cpp:237] Iteration 12150, loss = 1.43821
I0525 19:15:56.257017  2318 solver.cpp:253]     Train net output #0: loss = 1.43821 (* 1 = 1.43821 loss)
I0525 19:15:56.257030  2318 sgd_solver.cpp:106] Iteration 12150, lr = 0.003
I0525 19:16:04.984707  2318 solver.cpp:237] Iteration 12300, loss = 1.11568
I0525 19:16:04.984751  2318 solver.cpp:253]     Train net output #0: loss = 1.11568 (* 1 = 1.11568 loss)
I0525 19:16:04.984767  2318 sgd_solver.cpp:106] Iteration 12300, lr = 0.003
I0525 19:16:13.716780  2318 solver.cpp:237] Iteration 12450, loss = 1.1486
I0525 19:16:13.716814  2318 solver.cpp:253]     Train net output #0: loss = 1.1486 (* 1 = 1.1486 loss)
I0525 19:16:13.716830  2318 sgd_solver.cpp:106] Iteration 12450, lr = 0.003
I0525 19:16:22.441052  2318 solver.cpp:237] Iteration 12600, loss = 1.17473
I0525 19:16:22.441089  2318 solver.cpp:253]     Train net output #0: loss = 1.17473 (* 1 = 1.17473 loss)
I0525 19:16:22.441104  2318 sgd_solver.cpp:106] Iteration 12600, lr = 0.003
I0525 19:16:31.164242  2318 solver.cpp:237] Iteration 12750, loss = 1.44186
I0525 19:16:31.164402  2318 solver.cpp:253]     Train net output #0: loss = 1.44186 (* 1 = 1.44186 loss)
I0525 19:16:31.164417  2318 sgd_solver.cpp:106] Iteration 12750, lr = 0.003
I0525 19:16:39.888198  2318 solver.cpp:237] Iteration 12900, loss = 1.11482
I0525 19:16:39.888232  2318 solver.cpp:253]     Train net output #0: loss = 1.11482 (* 1 = 1.11482 loss)
I0525 19:16:39.888249  2318 sgd_solver.cpp:106] Iteration 12900, lr = 0.003
I0525 19:17:10.824547  2318 solver.cpp:237] Iteration 13050, loss = 1.4841
I0525 19:17:10.824715  2318 solver.cpp:253]     Train net output #0: loss = 1.4841 (* 1 = 1.4841 loss)
I0525 19:17:10.824731  2318 sgd_solver.cpp:106] Iteration 13050, lr = 0.003
I0525 19:17:19.556608  2318 solver.cpp:237] Iteration 13200, loss = 1.49832
I0525 19:17:19.556648  2318 solver.cpp:253]     Train net output #0: loss = 1.49832 (* 1 = 1.49832 loss)
I0525 19:17:19.556668  2318 sgd_solver.cpp:106] Iteration 13200, lr = 0.003
I0525 19:17:28.286188  2318 solver.cpp:237] Iteration 13350, loss = 1.37835
I0525 19:17:28.286223  2318 solver.cpp:253]     Train net output #0: loss = 1.37835 (* 1 = 1.37835 loss)
I0525 19:17:28.286240  2318 sgd_solver.cpp:106] Iteration 13350, lr = 0.003
I0525 19:17:36.957170  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_13500.caffemodel
I0525 19:17:37.037989  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_13500.solverstate
I0525 19:17:37.084563  2318 solver.cpp:237] Iteration 13500, loss = 1.30966
I0525 19:17:37.084614  2318 solver.cpp:253]     Train net output #0: loss = 1.30966 (* 1 = 1.30966 loss)
I0525 19:17:37.084630  2318 sgd_solver.cpp:106] Iteration 13500, lr = 0.003
I0525 19:17:45.816215  2318 solver.cpp:237] Iteration 13650, loss = 1.05093
I0525 19:17:45.816377  2318 solver.cpp:253]     Train net output #0: loss = 1.05093 (* 1 = 1.05093 loss)
I0525 19:17:45.816391  2318 sgd_solver.cpp:106] Iteration 13650, lr = 0.003
I0525 19:17:54.550886  2318 solver.cpp:237] Iteration 13800, loss = 1.61822
I0525 19:17:54.550920  2318 solver.cpp:253]     Train net output #0: loss = 1.61822 (* 1 = 1.61822 loss)
I0525 19:17:54.550938  2318 sgd_solver.cpp:106] Iteration 13800, lr = 0.003
I0525 19:18:03.284519  2318 solver.cpp:237] Iteration 13950, loss = 1.38051
I0525 19:18:03.284554  2318 solver.cpp:253]     Train net output #0: loss = 1.38051 (* 1 = 1.38051 loss)
I0525 19:18:03.284570  2318 sgd_solver.cpp:106] Iteration 13950, lr = 0.003
I0525 19:18:34.244267  2318 solver.cpp:237] Iteration 14100, loss = 1.36784
I0525 19:18:34.244451  2318 solver.cpp:253]     Train net output #0: loss = 1.36784 (* 1 = 1.36784 loss)
I0525 19:18:34.244467  2318 sgd_solver.cpp:106] Iteration 14100, lr = 0.003
I0525 19:18:42.971268  2318 solver.cpp:237] Iteration 14250, loss = 1.155
I0525 19:18:42.971302  2318 solver.cpp:253]     Train net output #0: loss = 1.155 (* 1 = 1.155 loss)
I0525 19:18:42.971319  2318 sgd_solver.cpp:106] Iteration 14250, lr = 0.003
I0525 19:18:51.701241  2318 solver.cpp:237] Iteration 14400, loss = 1.28804
I0525 19:18:51.701277  2318 solver.cpp:253]     Train net output #0: loss = 1.28804 (* 1 = 1.28804 loss)
I0525 19:18:51.701292  2318 sgd_solver.cpp:106] Iteration 14400, lr = 0.003
I0525 19:19:00.427099  2318 solver.cpp:237] Iteration 14550, loss = 1.22794
I0525 19:19:00.427145  2318 solver.cpp:253]     Train net output #0: loss = 1.22794 (* 1 = 1.22794 loss)
I0525 19:19:00.427160  2318 sgd_solver.cpp:106] Iteration 14550, lr = 0.003
I0525 19:19:09.159669  2318 solver.cpp:237] Iteration 14700, loss = 1.09943
I0525 19:19:09.159816  2318 solver.cpp:253]     Train net output #0: loss = 1.09943 (* 1 = 1.09943 loss)
I0525 19:19:09.159831  2318 sgd_solver.cpp:106] Iteration 14700, lr = 0.003
I0525 19:19:17.886204  2318 solver.cpp:237] Iteration 14850, loss = 1.41178
I0525 19:19:17.886240  2318 solver.cpp:253]     Train net output #0: loss = 1.41178 (* 1 = 1.41178 loss)
I0525 19:19:17.886256  2318 sgd_solver.cpp:106] Iteration 14850, lr = 0.003
I0525 19:19:26.556141  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_15000.caffemodel
I0525 19:19:26.637183  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_15000.solverstate
I0525 19:19:26.665724  2318 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 19:20:13.549906  2318 solver.cpp:409]     Test net output #0: accuracy = 0.857473
I0525 19:20:13.550071  2318 solver.cpp:409]     Test net output #1: loss = 0.502493 (* 1 = 0.502493 loss)
I0525 19:20:34.468895  2318 solver.cpp:237] Iteration 15000, loss = 1.22724
I0525 19:20:34.468947  2318 solver.cpp:253]     Train net output #0: loss = 1.22724 (* 1 = 1.22724 loss)
I0525 19:20:34.468966  2318 sgd_solver.cpp:106] Iteration 15000, lr = 0.003
I0525 19:20:43.211978  2318 solver.cpp:237] Iteration 15150, loss = 1.1468
I0525 19:20:43.212014  2318 solver.cpp:253]     Train net output #0: loss = 1.1468 (* 1 = 1.1468 loss)
I0525 19:20:43.212030  2318 sgd_solver.cpp:106] Iteration 15150, lr = 0.003
I0525 19:20:51.950494  2318 solver.cpp:237] Iteration 15300, loss = 1.42799
I0525 19:20:51.950647  2318 solver.cpp:253]     Train net output #0: loss = 1.42799 (* 1 = 1.42799 loss)
I0525 19:20:51.950660  2318 sgd_solver.cpp:106] Iteration 15300, lr = 0.003
I0525 19:21:00.688189  2318 solver.cpp:237] Iteration 15450, loss = 1.30452
I0525 19:21:00.688235  2318 solver.cpp:253]     Train net output #0: loss = 1.30452 (* 1 = 1.30452 loss)
I0525 19:21:00.688251  2318 sgd_solver.cpp:106] Iteration 15450, lr = 0.003
I0525 19:21:09.430794  2318 solver.cpp:237] Iteration 15600, loss = 1.19956
I0525 19:21:09.430830  2318 solver.cpp:253]     Train net output #0: loss = 1.19956 (* 1 = 1.19956 loss)
I0525 19:21:09.430845  2318 sgd_solver.cpp:106] Iteration 15600, lr = 0.003
I0525 19:21:18.171725  2318 solver.cpp:237] Iteration 15750, loss = 1.25909
I0525 19:21:18.171761  2318 solver.cpp:253]     Train net output #0: loss = 1.25909 (* 1 = 1.25909 loss)
I0525 19:21:18.171777  2318 sgd_solver.cpp:106] Iteration 15750, lr = 0.003
I0525 19:21:26.909698  2318 solver.cpp:237] Iteration 15900, loss = 1.40102
I0525 19:21:26.909885  2318 solver.cpp:253]     Train net output #0: loss = 1.40102 (* 1 = 1.40102 loss)
I0525 19:21:26.909899  2318 sgd_solver.cpp:106] Iteration 15900, lr = 0.003
I0525 19:21:56.533721  2318 solver.cpp:237] Iteration 16050, loss = 1.34585
I0525 19:21:56.533771  2318 solver.cpp:253]     Train net output #0: loss = 1.34585 (* 1 = 1.34585 loss)
I0525 19:21:56.533789  2318 sgd_solver.cpp:106] Iteration 16050, lr = 0.003
I0525 19:22:05.269381  2318 solver.cpp:237] Iteration 16200, loss = 1.17103
I0525 19:22:05.269533  2318 solver.cpp:253]     Train net output #0: loss = 1.17103 (* 1 = 1.17103 loss)
I0525 19:22:05.269546  2318 sgd_solver.cpp:106] Iteration 16200, lr = 0.003
I0525 19:22:13.999653  2318 solver.cpp:237] Iteration 16350, loss = 1.31666
I0525 19:22:13.999691  2318 solver.cpp:253]     Train net output #0: loss = 1.31666 (* 1 = 1.31666 loss)
I0525 19:22:13.999714  2318 sgd_solver.cpp:106] Iteration 16350, lr = 0.003
I0525 19:22:22.677518  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_16500.caffemodel
I0525 19:22:22.760874  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_16500.solverstate
I0525 19:22:22.804626  2318 solver.cpp:237] Iteration 16500, loss = 1.14451
I0525 19:22:22.804672  2318 solver.cpp:253]     Train net output #0: loss = 1.14451 (* 1 = 1.14451 loss)
I0525 19:22:22.804688  2318 sgd_solver.cpp:106] Iteration 16500, lr = 0.003
I0525 19:22:31.546330  2318 solver.cpp:237] Iteration 16650, loss = 1.33097
I0525 19:22:31.546365  2318 solver.cpp:253]     Train net output #0: loss = 1.33097 (* 1 = 1.33097 loss)
I0525 19:22:31.546380  2318 sgd_solver.cpp:106] Iteration 16650, lr = 0.003
I0525 19:22:40.283113  2318 solver.cpp:237] Iteration 16800, loss = 1.26176
I0525 19:22:40.283269  2318 solver.cpp:253]     Train net output #0: loss = 1.26176 (* 1 = 1.26176 loss)
I0525 19:22:40.283283  2318 sgd_solver.cpp:106] Iteration 16800, lr = 0.003
I0525 19:22:49.018887  2318 solver.cpp:237] Iteration 16950, loss = 1.24031
I0525 19:22:49.018921  2318 solver.cpp:253]     Train net output #0: loss = 1.24031 (* 1 = 1.24031 loss)
I0525 19:22:49.018939  2318 sgd_solver.cpp:106] Iteration 16950, lr = 0.003
I0525 19:23:18.677156  2318 solver.cpp:237] Iteration 17100, loss = 1.13803
I0525 19:23:18.677325  2318 solver.cpp:253]     Train net output #0: loss = 1.13803 (* 1 = 1.13803 loss)
I0525 19:23:18.677340  2318 sgd_solver.cpp:106] Iteration 17100, lr = 0.003
I0525 19:23:27.415336  2318 solver.cpp:237] Iteration 17250, loss = 1.13112
I0525 19:23:27.415371  2318 solver.cpp:253]     Train net output #0: loss = 1.13112 (* 1 = 1.13112 loss)
I0525 19:23:27.415390  2318 sgd_solver.cpp:106] Iteration 17250, lr = 0.003
I0525 19:23:36.158093  2318 solver.cpp:237] Iteration 17400, loss = 1.15889
I0525 19:23:36.158125  2318 solver.cpp:253]     Train net output #0: loss = 1.15889 (* 1 = 1.15889 loss)
I0525 19:23:36.158148  2318 sgd_solver.cpp:106] Iteration 17400, lr = 0.003
I0525 19:23:44.899144  2318 solver.cpp:237] Iteration 17550, loss = 1.25263
I0525 19:23:44.899179  2318 solver.cpp:253]     Train net output #0: loss = 1.25263 (* 1 = 1.25263 loss)
I0525 19:23:44.899196  2318 sgd_solver.cpp:106] Iteration 17550, lr = 0.003
I0525 19:23:53.637997  2318 solver.cpp:237] Iteration 17700, loss = 1.07591
I0525 19:23:53.638144  2318 solver.cpp:253]     Train net output #0: loss = 1.07591 (* 1 = 1.07591 loss)
I0525 19:23:53.638157  2318 sgd_solver.cpp:106] Iteration 17700, lr = 0.003
I0525 19:24:02.379879  2318 solver.cpp:237] Iteration 17850, loss = 1.26472
I0525 19:24:02.379915  2318 solver.cpp:253]     Train net output #0: loss = 1.26472 (* 1 = 1.26472 loss)
I0525 19:24:02.379931  2318 sgd_solver.cpp:106] Iteration 17850, lr = 0.003
I0525 19:24:11.062023  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_18000.caffemodel
I0525 19:24:11.140096  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_18000.solverstate
I0525 19:24:11.165663  2318 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 19:25:18.940210  2318 solver.cpp:409]     Test net output #0: accuracy = 0.864686
I0525 19:25:18.940387  2318 solver.cpp:409]     Test net output #1: loss = 0.449717 (* 1 = 0.449717 loss)
I0525 19:25:39.840749  2318 solver.cpp:237] Iteration 18000, loss = 1.08201
I0525 19:25:39.840801  2318 solver.cpp:253]     Train net output #0: loss = 1.08201 (* 1 = 1.08201 loss)
I0525 19:25:39.840816  2318 sgd_solver.cpp:106] Iteration 18000, lr = 0.003
I0525 19:25:48.573272  2318 solver.cpp:237] Iteration 18150, loss = 1.37895
I0525 19:25:48.573308  2318 solver.cpp:253]     Train net output #0: loss = 1.37895 (* 1 = 1.37895 loss)
I0525 19:25:48.573325  2318 sgd_solver.cpp:106] Iteration 18150, lr = 0.003
I0525 19:25:57.301316  2318 solver.cpp:237] Iteration 18300, loss = 1.1076
I0525 19:25:57.301470  2318 solver.cpp:253]     Train net output #0: loss = 1.1076 (* 1 = 1.1076 loss)
I0525 19:25:57.301483  2318 sgd_solver.cpp:106] Iteration 18300, lr = 0.003
I0525 19:26:06.032591  2318 solver.cpp:237] Iteration 18450, loss = 1.04929
I0525 19:26:06.032634  2318 solver.cpp:253]     Train net output #0: loss = 1.04929 (* 1 = 1.04929 loss)
I0525 19:26:06.032654  2318 sgd_solver.cpp:106] Iteration 18450, lr = 0.003
I0525 19:26:14.759857  2318 solver.cpp:237] Iteration 18600, loss = 1.11679
I0525 19:26:14.759892  2318 solver.cpp:253]     Train net output #0: loss = 1.11679 (* 1 = 1.11679 loss)
I0525 19:26:14.759907  2318 sgd_solver.cpp:106] Iteration 18600, lr = 0.003
I0525 19:26:23.494145  2318 solver.cpp:237] Iteration 18750, loss = 1.03917
I0525 19:26:23.494191  2318 solver.cpp:253]     Train net output #0: loss = 1.03917 (* 1 = 1.03917 loss)
I0525 19:26:23.494210  2318 sgd_solver.cpp:106] Iteration 18750, lr = 0.003
I0525 19:26:32.225013  2318 solver.cpp:237] Iteration 18900, loss = 1.33901
I0525 19:26:32.225162  2318 solver.cpp:253]     Train net output #0: loss = 1.33901 (* 1 = 1.33901 loss)
I0525 19:26:32.225175  2318 sgd_solver.cpp:106] Iteration 18900, lr = 0.003
I0525 19:27:01.854238  2318 solver.cpp:237] Iteration 19050, loss = 1.19502
I0525 19:27:01.854290  2318 solver.cpp:253]     Train net output #0: loss = 1.19502 (* 1 = 1.19502 loss)
I0525 19:27:01.854305  2318 sgd_solver.cpp:106] Iteration 19050, lr = 0.003
I0525 19:27:10.586061  2318 solver.cpp:237] Iteration 19200, loss = 1.18825
I0525 19:27:10.586215  2318 solver.cpp:253]     Train net output #0: loss = 1.18825 (* 1 = 1.18825 loss)
I0525 19:27:10.586228  2318 sgd_solver.cpp:106] Iteration 19200, lr = 0.003
I0525 19:27:19.319733  2318 solver.cpp:237] Iteration 19350, loss = 1.35
I0525 19:27:19.319779  2318 solver.cpp:253]     Train net output #0: loss = 1.35 (* 1 = 1.35 loss)
I0525 19:27:19.319797  2318 sgd_solver.cpp:106] Iteration 19350, lr = 0.003
I0525 19:27:27.992424  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_19500.caffemodel
I0525 19:27:28.071441  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_19500.solverstate
I0525 19:27:28.117362  2318 solver.cpp:237] Iteration 19500, loss = 1.24586
I0525 19:27:28.117411  2318 solver.cpp:253]     Train net output #0: loss = 1.24586 (* 1 = 1.24586 loss)
I0525 19:27:28.117429  2318 sgd_solver.cpp:106] Iteration 19500, lr = 0.003
I0525 19:27:36.850402  2318 solver.cpp:237] Iteration 19650, loss = 1.3164
I0525 19:27:36.850436  2318 solver.cpp:253]     Train net output #0: loss = 1.3164 (* 1 = 1.3164 loss)
I0525 19:27:36.850453  2318 sgd_solver.cpp:106] Iteration 19650, lr = 0.003
I0525 19:27:45.586123  2318 solver.cpp:237] Iteration 19800, loss = 1.30281
I0525 19:27:45.586292  2318 solver.cpp:253]     Train net output #0: loss = 1.30281 (* 1 = 1.30281 loss)
I0525 19:27:45.586305  2318 sgd_solver.cpp:106] Iteration 19800, lr = 0.003
I0525 19:27:54.313232  2318 solver.cpp:237] Iteration 19950, loss = 1.21551
I0525 19:27:54.313267  2318 solver.cpp:253]     Train net output #0: loss = 1.21551 (* 1 = 1.21551 loss)
I0525 19:27:54.313284  2318 sgd_solver.cpp:106] Iteration 19950, lr = 0.003
I0525 19:28:23.956917  2318 solver.cpp:237] Iteration 20100, loss = 1.13636
I0525 19:28:23.957093  2318 solver.cpp:253]     Train net output #0: loss = 1.13636 (* 1 = 1.13636 loss)
I0525 19:28:23.957106  2318 sgd_solver.cpp:106] Iteration 20100, lr = 0.003
I0525 19:28:32.691208  2318 solver.cpp:237] Iteration 20250, loss = 1.22733
I0525 19:28:32.691251  2318 solver.cpp:253]     Train net output #0: loss = 1.22733 (* 1 = 1.22733 loss)
I0525 19:28:32.691270  2318 sgd_solver.cpp:106] Iteration 20250, lr = 0.003
I0525 19:28:41.421214  2318 solver.cpp:237] Iteration 20400, loss = 1.31925
I0525 19:28:41.421249  2318 solver.cpp:253]     Train net output #0: loss = 1.31925 (* 1 = 1.31925 loss)
I0525 19:28:41.421267  2318 sgd_solver.cpp:106] Iteration 20400, lr = 0.003
I0525 19:28:50.152832  2318 solver.cpp:237] Iteration 20550, loss = 1.32646
I0525 19:28:50.152868  2318 solver.cpp:253]     Train net output #0: loss = 1.32646 (* 1 = 1.32646 loss)
I0525 19:28:50.152884  2318 sgd_solver.cpp:106] Iteration 20550, lr = 0.003
I0525 19:28:58.888234  2318 solver.cpp:237] Iteration 20700, loss = 1.30683
I0525 19:28:58.888394  2318 solver.cpp:253]     Train net output #0: loss = 1.30683 (* 1 = 1.30683 loss)
I0525 19:28:58.888408  2318 sgd_solver.cpp:106] Iteration 20700, lr = 0.003
I0525 19:29:07.623219  2318 solver.cpp:237] Iteration 20850, loss = 1.15693
I0525 19:29:07.623253  2318 solver.cpp:253]     Train net output #0: loss = 1.15693 (* 1 = 1.15693 loss)
I0525 19:29:07.623271  2318 sgd_solver.cpp:106] Iteration 20850, lr = 0.003
I0525 19:29:16.300241  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_21000.caffemodel
I0525 19:29:16.380118  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_21000.solverstate
I0525 19:29:16.407083  2318 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 19:30:02.956248  2318 solver.cpp:409]     Test net output #0: accuracy = 0.866226
I0525 19:30:02.956419  2318 solver.cpp:409]     Test net output #1: loss = 0.463162 (* 1 = 0.463162 loss)
I0525 19:30:23.862576  2318 solver.cpp:237] Iteration 21000, loss = 1.35369
I0525 19:30:23.862630  2318 solver.cpp:253]     Train net output #0: loss = 1.35369 (* 1 = 1.35369 loss)
I0525 19:30:23.862645  2318 sgd_solver.cpp:106] Iteration 21000, lr = 0.003
I0525 19:30:32.603607  2318 solver.cpp:237] Iteration 21150, loss = 1.34699
I0525 19:30:32.603643  2318 solver.cpp:253]     Train net output #0: loss = 1.34699 (* 1 = 1.34699 loss)
I0525 19:30:32.603658  2318 sgd_solver.cpp:106] Iteration 21150, lr = 0.003
I0525 19:30:41.343585  2318 solver.cpp:237] Iteration 21300, loss = 1.16116
I0525 19:30:41.343752  2318 solver.cpp:253]     Train net output #0: loss = 1.16116 (* 1 = 1.16116 loss)
I0525 19:30:41.343766  2318 sgd_solver.cpp:106] Iteration 21300, lr = 0.003
I0525 19:30:50.076138  2318 solver.cpp:237] Iteration 21450, loss = 1.30469
I0525 19:30:50.076172  2318 solver.cpp:253]     Train net output #0: loss = 1.30469 (* 1 = 1.30469 loss)
I0525 19:30:50.076189  2318 sgd_solver.cpp:106] Iteration 21450, lr = 0.003
I0525 19:30:58.809427  2318 solver.cpp:237] Iteration 21600, loss = 1.33223
I0525 19:30:58.809474  2318 solver.cpp:253]     Train net output #0: loss = 1.33223 (* 1 = 1.33223 loss)
I0525 19:30:58.809490  2318 sgd_solver.cpp:106] Iteration 21600, lr = 0.003
I0525 19:31:07.550770  2318 solver.cpp:237] Iteration 21750, loss = 1.43624
I0525 19:31:07.550806  2318 solver.cpp:253]     Train net output #0: loss = 1.43624 (* 1 = 1.43624 loss)
I0525 19:31:07.550823  2318 sgd_solver.cpp:106] Iteration 21750, lr = 0.003
I0525 19:31:16.285219  2318 solver.cpp:237] Iteration 21900, loss = 1.50027
I0525 19:31:16.285385  2318 solver.cpp:253]     Train net output #0: loss = 1.50027 (* 1 = 1.50027 loss)
I0525 19:31:16.285399  2318 sgd_solver.cpp:106] Iteration 21900, lr = 0.003
I0525 19:31:45.926576  2318 solver.cpp:237] Iteration 22050, loss = 1.0446
I0525 19:31:45.926627  2318 solver.cpp:253]     Train net output #0: loss = 1.0446 (* 1 = 1.0446 loss)
I0525 19:31:45.926640  2318 sgd_solver.cpp:106] Iteration 22050, lr = 0.003
I0525 19:31:54.662590  2318 solver.cpp:237] Iteration 22200, loss = 1.21918
I0525 19:31:54.662761  2318 solver.cpp:253]     Train net output #0: loss = 1.21918 (* 1 = 1.21918 loss)
I0525 19:31:54.662775  2318 sgd_solver.cpp:106] Iteration 22200, lr = 0.003
I0525 19:32:03.400094  2318 solver.cpp:237] Iteration 22350, loss = 1.06901
I0525 19:32:03.400128  2318 solver.cpp:253]     Train net output #0: loss = 1.06901 (* 1 = 1.06901 loss)
I0525 19:32:03.400147  2318 sgd_solver.cpp:106] Iteration 22350, lr = 0.003
I0525 19:32:12.080380  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_22500.caffemodel
I0525 19:32:12.160917  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_22500.solverstate
I0525 19:32:12.206502  2318 solver.cpp:237] Iteration 22500, loss = 1.33264
I0525 19:32:12.206552  2318 solver.cpp:253]     Train net output #0: loss = 1.33264 (* 1 = 1.33264 loss)
I0525 19:32:12.206567  2318 sgd_solver.cpp:106] Iteration 22500, lr = 0.003
I0525 19:32:20.946341  2318 solver.cpp:237] Iteration 22650, loss = 1.1995
I0525 19:32:20.946388  2318 solver.cpp:253]     Train net output #0: loss = 1.1995 (* 1 = 1.1995 loss)
I0525 19:32:20.946404  2318 sgd_solver.cpp:106] Iteration 22650, lr = 0.003
I0525 19:32:29.684855  2318 solver.cpp:237] Iteration 22800, loss = 1.21062
I0525 19:32:29.685011  2318 solver.cpp:253]     Train net output #0: loss = 1.21062 (* 1 = 1.21062 loss)
I0525 19:32:29.685025  2318 sgd_solver.cpp:106] Iteration 22800, lr = 0.003
I0525 19:32:38.422677  2318 solver.cpp:237] Iteration 22950, loss = 1.1506
I0525 19:32:38.422727  2318 solver.cpp:253]     Train net output #0: loss = 1.1506 (* 1 = 1.1506 loss)
I0525 19:32:38.422742  2318 sgd_solver.cpp:106] Iteration 22950, lr = 0.003
I0525 19:33:08.055634  2318 solver.cpp:237] Iteration 23100, loss = 0.979675
I0525 19:33:08.055809  2318 solver.cpp:253]     Train net output #0: loss = 0.979675 (* 1 = 0.979675 loss)
I0525 19:33:08.055824  2318 sgd_solver.cpp:106] Iteration 23100, lr = 0.003
I0525 19:33:16.791214  2318 solver.cpp:237] Iteration 23250, loss = 1.37502
I0525 19:33:16.791249  2318 solver.cpp:253]     Train net output #0: loss = 1.37502 (* 1 = 1.37502 loss)
I0525 19:33:16.791266  2318 sgd_solver.cpp:106] Iteration 23250, lr = 0.003
I0525 19:33:25.523197  2318 solver.cpp:237] Iteration 23400, loss = 1.05832
I0525 19:33:25.523231  2318 solver.cpp:253]     Train net output #0: loss = 1.05832 (* 1 = 1.05832 loss)
I0525 19:33:25.523248  2318 sgd_solver.cpp:106] Iteration 23400, lr = 0.003
I0525 19:33:34.257529  2318 solver.cpp:237] Iteration 23550, loss = 1.50605
I0525 19:33:34.257575  2318 solver.cpp:253]     Train net output #0: loss = 1.50605 (* 1 = 1.50605 loss)
I0525 19:33:34.257592  2318 sgd_solver.cpp:106] Iteration 23550, lr = 0.003
I0525 19:33:43.000747  2318 solver.cpp:237] Iteration 23700, loss = 1.23057
I0525 19:33:43.000895  2318 solver.cpp:253]     Train net output #0: loss = 1.23057 (* 1 = 1.23057 loss)
I0525 19:33:43.000910  2318 sgd_solver.cpp:106] Iteration 23700, lr = 0.003
I0525 19:33:51.742643  2318 solver.cpp:237] Iteration 23850, loss = 1.09723
I0525 19:33:51.742678  2318 solver.cpp:253]     Train net output #0: loss = 1.09723 (* 1 = 1.09723 loss)
I0525 19:33:51.742696  2318 sgd_solver.cpp:106] Iteration 23850, lr = 0.003
I0525 19:34:00.424011  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_24000.caffemodel
I0525 19:34:00.502032  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_24000.solverstate
I0525 19:34:00.527073  2318 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 19:35:08.303923  2318 solver.cpp:409]     Test net output #0: accuracy = 0.868514
I0525 19:35:08.304111  2318 solver.cpp:409]     Test net output #1: loss = 0.419705 (* 1 = 0.419705 loss)
I0525 19:35:29.228366  2318 solver.cpp:237] Iteration 24000, loss = 1.2079
I0525 19:35:29.228420  2318 solver.cpp:253]     Train net output #0: loss = 1.2079 (* 1 = 1.2079 loss)
I0525 19:35:29.228435  2318 sgd_solver.cpp:106] Iteration 24000, lr = 0.003
I0525 19:35:37.958580  2318 solver.cpp:237] Iteration 24150, loss = 1.15859
I0525 19:35:37.958628  2318 solver.cpp:253]     Train net output #0: loss = 1.15859 (* 1 = 1.15859 loss)
I0525 19:35:37.958645  2318 sgd_solver.cpp:106] Iteration 24150, lr = 0.003
I0525 19:35:46.686269  2318 solver.cpp:237] Iteration 24300, loss = 1.33506
I0525 19:35:46.686426  2318 solver.cpp:253]     Train net output #0: loss = 1.33506 (* 1 = 1.33506 loss)
I0525 19:35:46.686439  2318 sgd_solver.cpp:106] Iteration 24300, lr = 0.003
I0525 19:35:55.412668  2318 solver.cpp:237] Iteration 24450, loss = 1.14082
I0525 19:35:55.412703  2318 solver.cpp:253]     Train net output #0: loss = 1.14082 (* 1 = 1.14082 loss)
I0525 19:35:55.412720  2318 sgd_solver.cpp:106] Iteration 24450, lr = 0.003
I0525 19:36:04.140143  2318 solver.cpp:237] Iteration 24600, loss = 1.51811
I0525 19:36:04.140193  2318 solver.cpp:253]     Train net output #0: loss = 1.51811 (* 1 = 1.51811 loss)
I0525 19:36:04.140208  2318 sgd_solver.cpp:106] Iteration 24600, lr = 0.003
I0525 19:36:12.867779  2318 solver.cpp:237] Iteration 24750, loss = 1.48013
I0525 19:36:12.867815  2318 solver.cpp:253]     Train net output #0: loss = 1.48013 (* 1 = 1.48013 loss)
I0525 19:36:12.867830  2318 sgd_solver.cpp:106] Iteration 24750, lr = 0.003
I0525 19:36:21.592046  2318 solver.cpp:237] Iteration 24900, loss = 1.21652
I0525 19:36:21.592203  2318 solver.cpp:253]     Train net output #0: loss = 1.21652 (* 1 = 1.21652 loss)
I0525 19:36:21.592216  2318 sgd_solver.cpp:106] Iteration 24900, lr = 0.003
I0525 19:36:51.222529  2318 solver.cpp:237] Iteration 25050, loss = 1.26365
I0525 19:36:51.222579  2318 solver.cpp:253]     Train net output #0: loss = 1.26365 (* 1 = 1.26365 loss)
I0525 19:36:51.222596  2318 sgd_solver.cpp:106] Iteration 25050, lr = 0.003
I0525 19:36:59.950932  2318 solver.cpp:237] Iteration 25200, loss = 1.38699
I0525 19:36:59.951098  2318 solver.cpp:253]     Train net output #0: loss = 1.38699 (* 1 = 1.38699 loss)
I0525 19:36:59.951112  2318 sgd_solver.cpp:106] Iteration 25200, lr = 0.003
I0525 19:37:08.677008  2318 solver.cpp:237] Iteration 25350, loss = 1.06666
I0525 19:37:08.677043  2318 solver.cpp:253]     Train net output #0: loss = 1.06666 (* 1 = 1.06666 loss)
I0525 19:37:08.677060  2318 sgd_solver.cpp:106] Iteration 25350, lr = 0.003
I0525 19:37:17.346122  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_25500.caffemodel
I0525 19:37:17.424510  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_25500.solverstate
I0525 19:37:17.468200  2318 solver.cpp:237] Iteration 25500, loss = 1.13644
I0525 19:37:17.468242  2318 solver.cpp:253]     Train net output #0: loss = 1.13644 (* 1 = 1.13644 loss)
I0525 19:37:17.468261  2318 sgd_solver.cpp:106] Iteration 25500, lr = 0.003
I0525 19:37:26.196687  2318 solver.cpp:237] Iteration 25650, loss = 1.13682
I0525 19:37:26.196722  2318 solver.cpp:253]     Train net output #0: loss = 1.13682 (* 1 = 1.13682 loss)
I0525 19:37:26.196738  2318 sgd_solver.cpp:106] Iteration 25650, lr = 0.003
I0525 19:37:34.923156  2318 solver.cpp:237] Iteration 25800, loss = 1.24155
I0525 19:37:34.923331  2318 solver.cpp:253]     Train net output #0: loss = 1.24155 (* 1 = 1.24155 loss)
I0525 19:37:34.923346  2318 sgd_solver.cpp:106] Iteration 25800, lr = 0.003
I0525 19:37:43.653205  2318 solver.cpp:237] Iteration 25950, loss = 1.10001
I0525 19:37:43.653249  2318 solver.cpp:253]     Train net output #0: loss = 1.10001 (* 1 = 1.10001 loss)
I0525 19:37:43.653270  2318 sgd_solver.cpp:106] Iteration 25950, lr = 0.003
I0525 19:38:13.279896  2318 solver.cpp:237] Iteration 26100, loss = 1.08297
I0525 19:38:13.280071  2318 solver.cpp:253]     Train net output #0: loss = 1.08297 (* 1 = 1.08297 loss)
I0525 19:38:13.280092  2318 sgd_solver.cpp:106] Iteration 26100, lr = 0.003
I0525 19:38:22.003350  2318 solver.cpp:237] Iteration 26250, loss = 1.1895
I0525 19:38:22.003384  2318 solver.cpp:253]     Train net output #0: loss = 1.1895 (* 1 = 1.1895 loss)
I0525 19:38:22.003401  2318 sgd_solver.cpp:106] Iteration 26250, lr = 0.003
I0525 19:38:30.732774  2318 solver.cpp:237] Iteration 26400, loss = 1.06845
I0525 19:38:30.732817  2318 solver.cpp:253]     Train net output #0: loss = 1.06845 (* 1 = 1.06845 loss)
I0525 19:38:30.732837  2318 sgd_solver.cpp:106] Iteration 26400, lr = 0.003
I0525 19:38:39.459764  2318 solver.cpp:237] Iteration 26550, loss = 1.32473
I0525 19:38:39.459799  2318 solver.cpp:253]     Train net output #0: loss = 1.32473 (* 1 = 1.32473 loss)
I0525 19:38:39.459815  2318 sgd_solver.cpp:106] Iteration 26550, lr = 0.003
I0525 19:38:48.187505  2318 solver.cpp:237] Iteration 26700, loss = 0.991067
I0525 19:38:48.187659  2318 solver.cpp:253]     Train net output #0: loss = 0.991067 (* 1 = 0.991067 loss)
I0525 19:38:48.187674  2318 sgd_solver.cpp:106] Iteration 26700, lr = 0.003
I0525 19:38:56.916669  2318 solver.cpp:237] Iteration 26850, loss = 1.06745
I0525 19:38:56.916713  2318 solver.cpp:253]     Train net output #0: loss = 1.06745 (* 1 = 1.06745 loss)
I0525 19:38:56.916731  2318 sgd_solver.cpp:106] Iteration 26850, lr = 0.003
I0525 19:39:05.587086  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_27000.caffemodel
I0525 19:39:05.664873  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_27000.solverstate
I0525 19:39:05.690206  2318 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 19:39:52.570649  2318 solver.cpp:409]     Test net output #0: accuracy = 0.874346
I0525 19:39:52.570822  2318 solver.cpp:409]     Test net output #1: loss = 0.394351 (* 1 = 0.394351 loss)
I0525 19:40:13.517181  2318 solver.cpp:237] Iteration 27000, loss = 1.25233
I0525 19:40:13.517235  2318 solver.cpp:253]     Train net output #0: loss = 1.25233 (* 1 = 1.25233 loss)
I0525 19:40:13.517249  2318 sgd_solver.cpp:106] Iteration 27000, lr = 0.003
I0525 19:40:22.256839  2318 solver.cpp:237] Iteration 27150, loss = 0.925831
I0525 19:40:22.256875  2318 solver.cpp:253]     Train net output #0: loss = 0.925831 (* 1 = 0.925831 loss)
I0525 19:40:22.256891  2318 sgd_solver.cpp:106] Iteration 27150, lr = 0.003
I0525 19:40:30.994105  2318 solver.cpp:237] Iteration 27300, loss = 1.01063
I0525 19:40:30.994267  2318 solver.cpp:253]     Train net output #0: loss = 1.01063 (* 1 = 1.01063 loss)
I0525 19:40:30.994280  2318 sgd_solver.cpp:106] Iteration 27300, lr = 0.003
I0525 19:40:39.733085  2318 solver.cpp:237] Iteration 27450, loss = 1.07921
I0525 19:40:39.733134  2318 solver.cpp:253]     Train net output #0: loss = 1.07921 (* 1 = 1.07921 loss)
I0525 19:40:39.733150  2318 sgd_solver.cpp:106] Iteration 27450, lr = 0.003
I0525 19:40:48.472117  2318 solver.cpp:237] Iteration 27600, loss = 1.32883
I0525 19:40:48.472151  2318 solver.cpp:253]     Train net output #0: loss = 1.32883 (* 1 = 1.32883 loss)
I0525 19:40:48.472167  2318 sgd_solver.cpp:106] Iteration 27600, lr = 0.003
I0525 19:40:57.212301  2318 solver.cpp:237] Iteration 27750, loss = 1.17478
I0525 19:40:57.212335  2318 solver.cpp:253]     Train net output #0: loss = 1.17478 (* 1 = 1.17478 loss)
I0525 19:40:57.212352  2318 sgd_solver.cpp:106] Iteration 27750, lr = 0.003
I0525 19:41:05.952775  2318 solver.cpp:237] Iteration 27900, loss = 0.847172
I0525 19:41:05.952956  2318 solver.cpp:253]     Train net output #0: loss = 0.847172 (* 1 = 0.847172 loss)
I0525 19:41:05.952971  2318 sgd_solver.cpp:106] Iteration 27900, lr = 0.003
I0525 19:41:35.592357  2318 solver.cpp:237] Iteration 28050, loss = 1.39509
I0525 19:41:35.592404  2318 solver.cpp:253]     Train net output #0: loss = 1.39509 (* 1 = 1.39509 loss)
I0525 19:41:35.592418  2318 sgd_solver.cpp:106] Iteration 28050, lr = 0.003
I0525 19:41:44.337033  2318 solver.cpp:237] Iteration 28200, loss = 1.06303
I0525 19:41:44.337191  2318 solver.cpp:253]     Train net output #0: loss = 1.06303 (* 1 = 1.06303 loss)
I0525 19:41:44.337205  2318 sgd_solver.cpp:106] Iteration 28200, lr = 0.003
I0525 19:41:53.076503  2318 solver.cpp:237] Iteration 28350, loss = 1.25564
I0525 19:41:53.076546  2318 solver.cpp:253]     Train net output #0: loss = 1.25564 (* 1 = 1.25564 loss)
I0525 19:41:53.076565  2318 sgd_solver.cpp:106] Iteration 28350, lr = 0.003
I0525 19:42:01.759768  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_28500.caffemodel
I0525 19:42:01.841212  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_28500.solverstate
I0525 19:42:01.887156  2318 solver.cpp:237] Iteration 28500, loss = 1.28945
I0525 19:42:01.887205  2318 solver.cpp:253]     Train net output #0: loss = 1.28945 (* 1 = 1.28945 loss)
I0525 19:42:01.887222  2318 sgd_solver.cpp:106] Iteration 28500, lr = 0.003
I0525 19:42:10.629240  2318 solver.cpp:237] Iteration 28650, loss = 1.14961
I0525 19:42:10.629274  2318 solver.cpp:253]     Train net output #0: loss = 1.14961 (* 1 = 1.14961 loss)
I0525 19:42:10.629292  2318 sgd_solver.cpp:106] Iteration 28650, lr = 0.003
I0525 19:42:19.371997  2318 solver.cpp:237] Iteration 28800, loss = 1.42788
I0525 19:42:19.372175  2318 solver.cpp:253]     Train net output #0: loss = 1.42788 (* 1 = 1.42788 loss)
I0525 19:42:19.372190  2318 sgd_solver.cpp:106] Iteration 28800, lr = 0.003
I0525 19:42:28.112643  2318 solver.cpp:237] Iteration 28950, loss = 1.27792
I0525 19:42:28.112678  2318 solver.cpp:253]     Train net output #0: loss = 1.27792 (* 1 = 1.27792 loss)
I0525 19:42:28.112694  2318 sgd_solver.cpp:106] Iteration 28950, lr = 0.003
I0525 19:42:57.769474  2318 solver.cpp:237] Iteration 29100, loss = 1.13274
I0525 19:42:57.769654  2318 solver.cpp:253]     Train net output #0: loss = 1.13274 (* 1 = 1.13274 loss)
I0525 19:42:57.769667  2318 sgd_solver.cpp:106] Iteration 29100, lr = 0.003
I0525 19:43:06.509717  2318 solver.cpp:237] Iteration 29250, loss = 1.40514
I0525 19:43:06.509760  2318 solver.cpp:253]     Train net output #0: loss = 1.40514 (* 1 = 1.40514 loss)
I0525 19:43:06.509778  2318 sgd_solver.cpp:106] Iteration 29250, lr = 0.003
I0525 19:43:15.248931  2318 solver.cpp:237] Iteration 29400, loss = 0.999963
I0525 19:43:15.248968  2318 solver.cpp:253]     Train net output #0: loss = 0.999963 (* 1 = 0.999963 loss)
I0525 19:43:15.248981  2318 sgd_solver.cpp:106] Iteration 29400, lr = 0.003
I0525 19:43:23.987576  2318 solver.cpp:237] Iteration 29550, loss = 1.33047
I0525 19:43:23.987612  2318 solver.cpp:253]     Train net output #0: loss = 1.33047 (* 1 = 1.33047 loss)
I0525 19:43:23.987628  2318 sgd_solver.cpp:106] Iteration 29550, lr = 0.003
I0525 19:43:32.728188  2318 solver.cpp:237] Iteration 29700, loss = 1.24196
I0525 19:43:32.728355  2318 solver.cpp:253]     Train net output #0: loss = 1.24196 (* 1 = 1.24196 loss)
I0525 19:43:32.728369  2318 sgd_solver.cpp:106] Iteration 29700, lr = 0.003
I0525 19:43:41.467950  2318 solver.cpp:237] Iteration 29850, loss = 1.25329
I0525 19:43:41.467985  2318 solver.cpp:253]     Train net output #0: loss = 1.25329 (* 1 = 1.25329 loss)
I0525 19:43:41.468003  2318 sgd_solver.cpp:106] Iteration 29850, lr = 0.003
I0525 19:43:50.149029  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_30000.caffemodel
I0525 19:43:50.230020  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_30000.solverstate
I0525 19:43:50.257710  2318 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 19:44:58.017566  2318 solver.cpp:409]     Test net output #0: accuracy = 0.877768
I0525 19:44:58.017745  2318 solver.cpp:409]     Test net output #1: loss = 0.401682 (* 1 = 0.401682 loss)
I0525 19:45:18.943858  2318 solver.cpp:237] Iteration 30000, loss = 1.36699
I0525 19:45:18.943910  2318 solver.cpp:253]     Train net output #0: loss = 1.36699 (* 1 = 1.36699 loss)
I0525 19:45:18.943928  2318 sgd_solver.cpp:106] Iteration 30000, lr = 0.003
I0525 19:45:27.673750  2318 solver.cpp:237] Iteration 30150, loss = 1.11815
I0525 19:45:27.673786  2318 solver.cpp:253]     Train net output #0: loss = 1.11815 (* 1 = 1.11815 loss)
I0525 19:45:27.673802  2318 sgd_solver.cpp:106] Iteration 30150, lr = 0.003
I0525 19:45:36.406828  2318 solver.cpp:237] Iteration 30300, loss = 1.29426
I0525 19:45:36.406993  2318 solver.cpp:253]     Train net output #0: loss = 1.29426 (* 1 = 1.29426 loss)
I0525 19:45:36.407007  2318 sgd_solver.cpp:106] Iteration 30300, lr = 0.003
I0525 19:45:45.138680  2318 solver.cpp:237] Iteration 30450, loss = 1.22099
I0525 19:45:45.138715  2318 solver.cpp:253]     Train net output #0: loss = 1.22099 (* 1 = 1.22099 loss)
I0525 19:45:45.138731  2318 sgd_solver.cpp:106] Iteration 30450, lr = 0.003
I0525 19:45:53.874409  2318 solver.cpp:237] Iteration 30600, loss = 1.20826
I0525 19:45:53.874444  2318 solver.cpp:253]     Train net output #0: loss = 1.20826 (* 1 = 1.20826 loss)
I0525 19:45:53.874460  2318 sgd_solver.cpp:106] Iteration 30600, lr = 0.003
I0525 19:46:02.607545  2318 solver.cpp:237] Iteration 30750, loss = 1.05995
I0525 19:46:02.607589  2318 solver.cpp:253]     Train net output #0: loss = 1.05995 (* 1 = 1.05995 loss)
I0525 19:46:02.607606  2318 sgd_solver.cpp:106] Iteration 30750, lr = 0.003
I0525 19:46:11.341198  2318 solver.cpp:237] Iteration 30900, loss = 1.35788
I0525 19:46:11.341352  2318 solver.cpp:253]     Train net output #0: loss = 1.35788 (* 1 = 1.35788 loss)
I0525 19:46:11.341367  2318 sgd_solver.cpp:106] Iteration 30900, lr = 0.003
I0525 19:46:40.966231  2318 solver.cpp:237] Iteration 31050, loss = 1.27879
I0525 19:46:40.966281  2318 solver.cpp:253]     Train net output #0: loss = 1.27879 (* 1 = 1.27879 loss)
I0525 19:46:40.966300  2318 sgd_solver.cpp:106] Iteration 31050, lr = 0.003
I0525 19:46:49.703332  2318 solver.cpp:237] Iteration 31200, loss = 1.1002
I0525 19:46:49.703510  2318 solver.cpp:253]     Train net output #0: loss = 1.1002 (* 1 = 1.1002 loss)
I0525 19:46:49.703523  2318 sgd_solver.cpp:106] Iteration 31200, lr = 0.003
I0525 19:46:58.436359  2318 solver.cpp:237] Iteration 31350, loss = 1.47642
I0525 19:46:58.436394  2318 solver.cpp:253]     Train net output #0: loss = 1.47642 (* 1 = 1.47642 loss)
I0525 19:46:58.436411  2318 sgd_solver.cpp:106] Iteration 31350, lr = 0.003
I0525 19:47:07.117478  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_31500.caffemodel
I0525 19:47:07.196998  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_31500.solverstate
I0525 19:47:07.239990  2318 solver.cpp:237] Iteration 31500, loss = 1.30067
I0525 19:47:07.240036  2318 solver.cpp:253]     Train net output #0: loss = 1.30067 (* 1 = 1.30067 loss)
I0525 19:47:07.240054  2318 sgd_solver.cpp:106] Iteration 31500, lr = 0.003
I0525 19:47:15.975606  2318 solver.cpp:237] Iteration 31650, loss = 1.13314
I0525 19:47:15.975651  2318 solver.cpp:253]     Train net output #0: loss = 1.13314 (* 1 = 1.13314 loss)
I0525 19:47:15.975667  2318 sgd_solver.cpp:106] Iteration 31650, lr = 0.003
I0525 19:47:24.707716  2318 solver.cpp:237] Iteration 31800, loss = 1.17045
I0525 19:47:24.707890  2318 solver.cpp:253]     Train net output #0: loss = 1.17045 (* 1 = 1.17045 loss)
I0525 19:47:24.707902  2318 sgd_solver.cpp:106] Iteration 31800, lr = 0.003
I0525 19:47:33.441182  2318 solver.cpp:237] Iteration 31950, loss = 1.11133
I0525 19:47:33.441216  2318 solver.cpp:253]     Train net output #0: loss = 1.11133 (* 1 = 1.11133 loss)
I0525 19:47:33.441231  2318 sgd_solver.cpp:106] Iteration 31950, lr = 0.003
I0525 19:48:03.079928  2318 solver.cpp:237] Iteration 32100, loss = 1.02911
I0525 19:48:03.080114  2318 solver.cpp:253]     Train net output #0: loss = 1.02911 (* 1 = 1.02911 loss)
I0525 19:48:03.080128  2318 sgd_solver.cpp:106] Iteration 32100, lr = 0.003
I0525 19:48:11.817067  2318 solver.cpp:237] Iteration 32250, loss = 1.11256
I0525 19:48:11.817111  2318 solver.cpp:253]     Train net output #0: loss = 1.11256 (* 1 = 1.11256 loss)
I0525 19:48:11.817127  2318 sgd_solver.cpp:106] Iteration 32250, lr = 0.003
I0525 19:48:20.549686  2318 solver.cpp:237] Iteration 32400, loss = 1.40722
I0525 19:48:20.549721  2318 solver.cpp:253]     Train net output #0: loss = 1.40722 (* 1 = 1.40722 loss)
I0525 19:48:20.549738  2318 sgd_solver.cpp:106] Iteration 32400, lr = 0.003
I0525 19:48:29.282326  2318 solver.cpp:237] Iteration 32550, loss = 1.02719
I0525 19:48:29.282374  2318 solver.cpp:253]     Train net output #0: loss = 1.02719 (* 1 = 1.02719 loss)
I0525 19:48:29.282389  2318 sgd_solver.cpp:106] Iteration 32550, lr = 0.003
I0525 19:48:38.015842  2318 solver.cpp:237] Iteration 32700, loss = 1.0599
I0525 19:48:38.016000  2318 solver.cpp:253]     Train net output #0: loss = 1.0599 (* 1 = 1.0599 loss)
I0525 19:48:38.016013  2318 sgd_solver.cpp:106] Iteration 32700, lr = 0.003
I0525 19:48:46.750255  2318 solver.cpp:237] Iteration 32850, loss = 1.23143
I0525 19:48:46.750289  2318 solver.cpp:253]     Train net output #0: loss = 1.23143 (* 1 = 1.23143 loss)
I0525 19:48:46.750303  2318 sgd_solver.cpp:106] Iteration 32850, lr = 0.003
I0525 19:48:55.426445  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_33000.caffemodel
I0525 19:48:55.504987  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_33000.solverstate
I0525 19:48:55.530406  2318 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 19:49:42.073187  2318 solver.cpp:409]     Test net output #0: accuracy = 0.875587
I0525 19:49:42.073364  2318 solver.cpp:409]     Test net output #1: loss = 0.372309 (* 1 = 0.372309 loss)
I0525 19:50:02.975566  2318 solver.cpp:237] Iteration 33000, loss = 1.1651
I0525 19:50:02.975620  2318 solver.cpp:253]     Train net output #0: loss = 1.1651 (* 1 = 1.1651 loss)
I0525 19:50:02.975636  2318 sgd_solver.cpp:106] Iteration 33000, lr = 0.003
I0525 19:50:11.709740  2318 solver.cpp:237] Iteration 33150, loss = 1.17763
I0525 19:50:11.709784  2318 solver.cpp:253]     Train net output #0: loss = 1.17763 (* 1 = 1.17763 loss)
I0525 19:50:11.709802  2318 sgd_solver.cpp:106] Iteration 33150, lr = 0.003
I0525 19:50:20.447121  2318 solver.cpp:237] Iteration 33300, loss = 1.28621
I0525 19:50:20.447304  2318 solver.cpp:253]     Train net output #0: loss = 1.28621 (* 1 = 1.28621 loss)
I0525 19:50:20.447317  2318 sgd_solver.cpp:106] Iteration 33300, lr = 0.003
I0525 19:50:29.183374  2318 solver.cpp:237] Iteration 33450, loss = 1.27958
I0525 19:50:29.183408  2318 solver.cpp:253]     Train net output #0: loss = 1.27958 (* 1 = 1.27958 loss)
I0525 19:50:29.183426  2318 sgd_solver.cpp:106] Iteration 33450, lr = 0.003
I0525 19:50:37.923368  2318 solver.cpp:237] Iteration 33600, loss = 1.25577
I0525 19:50:37.923419  2318 solver.cpp:253]     Train net output #0: loss = 1.25577 (* 1 = 1.25577 loss)
I0525 19:50:37.923434  2318 sgd_solver.cpp:106] Iteration 33600, lr = 0.003
I0525 19:50:46.664620  2318 solver.cpp:237] Iteration 33750, loss = 1.08785
I0525 19:50:46.664655  2318 solver.cpp:253]     Train net output #0: loss = 1.08785 (* 1 = 1.08785 loss)
I0525 19:50:46.664671  2318 sgd_solver.cpp:106] Iteration 33750, lr = 0.003
I0525 19:50:55.403781  2318 solver.cpp:237] Iteration 33900, loss = 1.01375
I0525 19:50:55.403937  2318 solver.cpp:253]     Train net output #0: loss = 1.01375 (* 1 = 1.01375 loss)
I0525 19:50:55.403951  2318 sgd_solver.cpp:106] Iteration 33900, lr = 0.003
I0525 19:51:25.044361  2318 solver.cpp:237] Iteration 34050, loss = 1.33682
I0525 19:51:25.044411  2318 solver.cpp:253]     Train net output #0: loss = 1.33682 (* 1 = 1.33682 loss)
I0525 19:51:25.044428  2318 sgd_solver.cpp:106] Iteration 34050, lr = 0.003
I0525 19:51:33.782196  2318 solver.cpp:237] Iteration 34200, loss = 1.10761
I0525 19:51:33.782351  2318 solver.cpp:253]     Train net output #0: loss = 1.10761 (* 1 = 1.10761 loss)
I0525 19:51:33.782366  2318 sgd_solver.cpp:106] Iteration 34200, lr = 0.003
I0525 19:51:42.520977  2318 solver.cpp:237] Iteration 34350, loss = 1.43573
I0525 19:51:42.521011  2318 solver.cpp:253]     Train net output #0: loss = 1.43573 (* 1 = 1.43573 loss)
I0525 19:51:42.521029  2318 sgd_solver.cpp:106] Iteration 34350, lr = 0.003
I0525 19:51:51.204730  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_34500.caffemodel
I0525 19:51:51.283027  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_34500.solverstate
I0525 19:51:51.326347  2318 solver.cpp:237] Iteration 34500, loss = 1.15313
I0525 19:51:51.326395  2318 solver.cpp:253]     Train net output #0: loss = 1.15313 (* 1 = 1.15313 loss)
I0525 19:51:51.326408  2318 sgd_solver.cpp:106] Iteration 34500, lr = 0.003
I0525 19:52:00.061048  2318 solver.cpp:237] Iteration 34650, loss = 1.10631
I0525 19:52:00.061084  2318 solver.cpp:253]     Train net output #0: loss = 1.10631 (* 1 = 1.10631 loss)
I0525 19:52:00.061101  2318 sgd_solver.cpp:106] Iteration 34650, lr = 0.003
I0525 19:52:08.799758  2318 solver.cpp:237] Iteration 34800, loss = 1.09325
I0525 19:52:08.799917  2318 solver.cpp:253]     Train net output #0: loss = 1.09325 (* 1 = 1.09325 loss)
I0525 19:52:08.799932  2318 sgd_solver.cpp:106] Iteration 34800, lr = 0.003
I0525 19:52:17.537196  2318 solver.cpp:237] Iteration 34950, loss = 1.16075
I0525 19:52:17.537238  2318 solver.cpp:253]     Train net output #0: loss = 1.16075 (* 1 = 1.16075 loss)
I0525 19:52:17.537261  2318 sgd_solver.cpp:106] Iteration 34950, lr = 0.003
I0525 19:52:47.192970  2318 solver.cpp:237] Iteration 35100, loss = 0.820455
I0525 19:52:47.193148  2318 solver.cpp:253]     Train net output #0: loss = 0.820455 (* 1 = 0.820455 loss)
I0525 19:52:47.193162  2318 sgd_solver.cpp:106] Iteration 35100, lr = 0.003
I0525 19:52:55.932099  2318 solver.cpp:237] Iteration 35250, loss = 1.1046
I0525 19:52:55.932133  2318 solver.cpp:253]     Train net output #0: loss = 1.1046 (* 1 = 1.1046 loss)
I0525 19:52:55.932152  2318 sgd_solver.cpp:106] Iteration 35250, lr = 0.003
I0525 19:53:04.666903  2318 solver.cpp:237] Iteration 35400, loss = 1.10268
I0525 19:53:04.666944  2318 solver.cpp:253]     Train net output #0: loss = 1.10268 (* 1 = 1.10268 loss)
I0525 19:53:04.666965  2318 sgd_solver.cpp:106] Iteration 35400, lr = 0.003
I0525 19:53:13.400403  2318 solver.cpp:237] Iteration 35550, loss = 1.29625
I0525 19:53:13.400437  2318 solver.cpp:253]     Train net output #0: loss = 1.29625 (* 1 = 1.29625 loss)
I0525 19:53:13.400454  2318 sgd_solver.cpp:106] Iteration 35550, lr = 0.003
I0525 19:53:22.137974  2318 solver.cpp:237] Iteration 35700, loss = 1.29874
I0525 19:53:22.138139  2318 solver.cpp:253]     Train net output #0: loss = 1.29874 (* 1 = 1.29874 loss)
I0525 19:53:22.138154  2318 sgd_solver.cpp:106] Iteration 35700, lr = 0.003
I0525 19:53:30.878998  2318 solver.cpp:237] Iteration 35850, loss = 1.27254
I0525 19:53:30.879045  2318 solver.cpp:253]     Train net output #0: loss = 1.27254 (* 1 = 1.27254 loss)
I0525 19:53:30.879060  2318 sgd_solver.cpp:106] Iteration 35850, lr = 0.003
I0525 19:53:39.557350  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_36000.caffemodel
I0525 19:53:39.649507  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_36000.solverstate
I0525 19:53:39.676471  2318 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 19:54:47.370167  2318 solver.cpp:409]     Test net output #0: accuracy = 0.882448
I0525 19:54:47.370345  2318 solver.cpp:409]     Test net output #1: loss = 0.391146 (* 1 = 0.391146 loss)
I0525 19:55:08.247381  2318 solver.cpp:237] Iteration 36000, loss = 1.1651
I0525 19:55:08.247436  2318 solver.cpp:253]     Train net output #0: loss = 1.1651 (* 1 = 1.1651 loss)
I0525 19:55:08.247450  2318 sgd_solver.cpp:106] Iteration 36000, lr = 0.003
I0525 19:55:16.977440  2318 solver.cpp:237] Iteration 36150, loss = 1.31224
I0525 19:55:16.977475  2318 solver.cpp:253]     Train net output #0: loss = 1.31224 (* 1 = 1.31224 loss)
I0525 19:55:16.977494  2318 sgd_solver.cpp:106] Iteration 36150, lr = 0.003
I0525 19:55:25.703230  2318 solver.cpp:237] Iteration 36300, loss = 1.17886
I0525 19:55:25.703394  2318 solver.cpp:253]     Train net output #0: loss = 1.17886 (* 1 = 1.17886 loss)
I0525 19:55:25.703408  2318 sgd_solver.cpp:106] Iteration 36300, lr = 0.003
I0525 19:55:34.431663  2318 solver.cpp:237] Iteration 36450, loss = 1.53171
I0525 19:55:34.431711  2318 solver.cpp:253]     Train net output #0: loss = 1.53171 (* 1 = 1.53171 loss)
I0525 19:55:34.431725  2318 sgd_solver.cpp:106] Iteration 36450, lr = 0.003
I0525 19:55:43.162358  2318 solver.cpp:237] Iteration 36600, loss = 1.37213
I0525 19:55:43.162392  2318 solver.cpp:253]     Train net output #0: loss = 1.37213 (* 1 = 1.37213 loss)
I0525 19:55:43.162408  2318 sgd_solver.cpp:106] Iteration 36600, lr = 0.003
I0525 19:55:51.886924  2318 solver.cpp:237] Iteration 36750, loss = 1.18772
I0525 19:55:51.886960  2318 solver.cpp:253]     Train net output #0: loss = 1.18772 (* 1 = 1.18772 loss)
I0525 19:55:51.886975  2318 sgd_solver.cpp:106] Iteration 36750, lr = 0.003
I0525 19:56:00.613838  2318 solver.cpp:237] Iteration 36900, loss = 1.42139
I0525 19:56:00.614007  2318 solver.cpp:253]     Train net output #0: loss = 1.42139 (* 1 = 1.42139 loss)
I0525 19:56:00.614022  2318 sgd_solver.cpp:106] Iteration 36900, lr = 0.003
I0525 19:56:30.202769  2318 solver.cpp:237] Iteration 37050, loss = 1.19049
I0525 19:56:30.202817  2318 solver.cpp:253]     Train net output #0: loss = 1.19049 (* 1 = 1.19049 loss)
I0525 19:56:30.202836  2318 sgd_solver.cpp:106] Iteration 37050, lr = 0.003
I0525 19:56:38.930987  2318 solver.cpp:237] Iteration 37200, loss = 1.23145
I0525 19:56:38.931148  2318 solver.cpp:253]     Train net output #0: loss = 1.23145 (* 1 = 1.23145 loss)
I0525 19:56:38.931160  2318 sgd_solver.cpp:106] Iteration 37200, lr = 0.003
I0525 19:56:47.661373  2318 solver.cpp:237] Iteration 37350, loss = 1.43098
I0525 19:56:47.661407  2318 solver.cpp:253]     Train net output #0: loss = 1.43098 (* 1 = 1.43098 loss)
I0525 19:56:47.661425  2318 sgd_solver.cpp:106] Iteration 37350, lr = 0.003
I0525 19:56:56.333039  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_37500.caffemodel
I0525 19:56:56.413157  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_37500.solverstate
I0525 19:56:56.458912  2318 solver.cpp:237] Iteration 37500, loss = 1.24673
I0525 19:56:56.458962  2318 solver.cpp:253]     Train net output #0: loss = 1.24673 (* 1 = 1.24673 loss)
I0525 19:56:56.458978  2318 sgd_solver.cpp:106] Iteration 37500, lr = 0.003
I0525 19:57:05.193639  2318 solver.cpp:237] Iteration 37650, loss = 1.17511
I0525 19:57:05.193675  2318 solver.cpp:253]     Train net output #0: loss = 1.17511 (* 1 = 1.17511 loss)
I0525 19:57:05.193691  2318 sgd_solver.cpp:106] Iteration 37650, lr = 0.003
I0525 19:57:13.922951  2318 solver.cpp:237] Iteration 37800, loss = 1.14671
I0525 19:57:13.923137  2318 solver.cpp:253]     Train net output #0: loss = 1.14671 (* 1 = 1.14671 loss)
I0525 19:57:13.923151  2318 sgd_solver.cpp:106] Iteration 37800, lr = 0.003
I0525 19:57:22.651320  2318 solver.cpp:237] Iteration 37950, loss = 1.29531
I0525 19:57:22.651355  2318 solver.cpp:253]     Train net output #0: loss = 1.29531 (* 1 = 1.29531 loss)
I0525 19:57:22.651371  2318 sgd_solver.cpp:106] Iteration 37950, lr = 0.003
I0525 19:57:52.264289  2318 solver.cpp:237] Iteration 38100, loss = 1.15847
I0525 19:57:52.264472  2318 solver.cpp:253]     Train net output #0: loss = 1.15847 (* 1 = 1.15847 loss)
I0525 19:57:52.264487  2318 sgd_solver.cpp:106] Iteration 38100, lr = 0.003
I0525 19:58:00.985996  2318 solver.cpp:237] Iteration 38250, loss = 1.1414
I0525 19:58:00.986029  2318 solver.cpp:253]     Train net output #0: loss = 1.1414 (* 1 = 1.1414 loss)
I0525 19:58:00.986047  2318 sgd_solver.cpp:106] Iteration 38250, lr = 0.003
I0525 19:58:09.715390  2318 solver.cpp:237] Iteration 38400, loss = 1.20013
I0525 19:58:09.715440  2318 solver.cpp:253]     Train net output #0: loss = 1.20013 (* 1 = 1.20013 loss)
I0525 19:58:09.715453  2318 sgd_solver.cpp:106] Iteration 38400, lr = 0.003
I0525 19:58:18.445394  2318 solver.cpp:237] Iteration 38550, loss = 1.14667
I0525 19:58:18.445430  2318 solver.cpp:253]     Train net output #0: loss = 1.14667 (* 1 = 1.14667 loss)
I0525 19:58:18.445446  2318 sgd_solver.cpp:106] Iteration 38550, lr = 0.003
I0525 19:58:27.168840  2318 solver.cpp:237] Iteration 38700, loss = 1.35058
I0525 19:58:27.168999  2318 solver.cpp:253]     Train net output #0: loss = 1.35058 (* 1 = 1.35058 loss)
I0525 19:58:27.169013  2318 sgd_solver.cpp:106] Iteration 38700, lr = 0.003
I0525 19:58:35.897018  2318 solver.cpp:237] Iteration 38850, loss = 0.851728
I0525 19:58:35.897058  2318 solver.cpp:253]     Train net output #0: loss = 0.851728 (* 1 = 0.851728 loss)
I0525 19:58:35.897075  2318 sgd_solver.cpp:106] Iteration 38850, lr = 0.003
I0525 19:58:44.569205  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_39000.caffemodel
I0525 19:58:44.648082  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_39000.solverstate
I0525 19:58:44.673784  2318 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 19:59:31.529845  2318 solver.cpp:409]     Test net output #0: accuracy = 0.882281
I0525 19:59:31.530032  2318 solver.cpp:409]     Test net output #1: loss = 0.370337 (* 1 = 0.370337 loss)
I0525 19:59:52.409698  2318 solver.cpp:237] Iteration 39000, loss = 1.12445
I0525 19:59:52.409750  2318 solver.cpp:253]     Train net output #0: loss = 1.12445 (* 1 = 1.12445 loss)
I0525 19:59:52.409766  2318 sgd_solver.cpp:106] Iteration 39000, lr = 0.003
I0525 20:00:01.144615  2318 solver.cpp:237] Iteration 39150, loss = 1.15053
I0525 20:00:01.144651  2318 solver.cpp:253]     Train net output #0: loss = 1.15053 (* 1 = 1.15053 loss)
I0525 20:00:01.144668  2318 sgd_solver.cpp:106] Iteration 39150, lr = 0.003
I0525 20:00:09.890224  2318 solver.cpp:237] Iteration 39300, loss = 1.19049
I0525 20:00:09.890413  2318 solver.cpp:253]     Train net output #0: loss = 1.19049 (* 1 = 1.19049 loss)
I0525 20:00:09.890426  2318 sgd_solver.cpp:106] Iteration 39300, lr = 0.003
I0525 20:00:18.630592  2318 solver.cpp:237] Iteration 39450, loss = 1.12809
I0525 20:00:18.630627  2318 solver.cpp:253]     Train net output #0: loss = 1.12809 (* 1 = 1.12809 loss)
I0525 20:00:18.630645  2318 sgd_solver.cpp:106] Iteration 39450, lr = 0.003
I0525 20:00:27.373682  2318 solver.cpp:237] Iteration 39600, loss = 1.23814
I0525 20:00:27.373718  2318 solver.cpp:253]     Train net output #0: loss = 1.23814 (* 1 = 1.23814 loss)
I0525 20:00:27.373731  2318 sgd_solver.cpp:106] Iteration 39600, lr = 0.003
I0525 20:00:36.112782  2318 solver.cpp:237] Iteration 39750, loss = 1.17415
I0525 20:00:36.112825  2318 solver.cpp:253]     Train net output #0: loss = 1.17415 (* 1 = 1.17415 loss)
I0525 20:00:36.112841  2318 sgd_solver.cpp:106] Iteration 39750, lr = 0.003
I0525 20:00:44.851181  2318 solver.cpp:237] Iteration 39900, loss = 1.18229
I0525 20:00:44.851341  2318 solver.cpp:253]     Train net output #0: loss = 1.18229 (* 1 = 1.18229 loss)
I0525 20:00:44.851354  2318 sgd_solver.cpp:106] Iteration 39900, lr = 0.003
I0525 20:01:14.485579  2318 solver.cpp:237] Iteration 40050, loss = 1.05475
I0525 20:01:14.485630  2318 solver.cpp:253]     Train net output #0: loss = 1.05475 (* 1 = 1.05475 loss)
I0525 20:01:14.485648  2318 sgd_solver.cpp:106] Iteration 40050, lr = 0.003
I0525 20:01:23.228485  2318 solver.cpp:237] Iteration 40200, loss = 1.27915
I0525 20:01:23.228659  2318 solver.cpp:253]     Train net output #0: loss = 1.27915 (* 1 = 1.27915 loss)
I0525 20:01:23.228673  2318 sgd_solver.cpp:106] Iteration 40200, lr = 0.003
I0525 20:01:31.969985  2318 solver.cpp:237] Iteration 40350, loss = 1.12468
I0525 20:01:31.970031  2318 solver.cpp:253]     Train net output #0: loss = 1.12468 (* 1 = 1.12468 loss)
I0525 20:01:31.970048  2318 sgd_solver.cpp:106] Iteration 40350, lr = 0.003
I0525 20:01:40.650041  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_40500.caffemodel
I0525 20:01:40.729089  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_40500.solverstate
I0525 20:01:40.772423  2318 solver.cpp:237] Iteration 40500, loss = 1.08193
I0525 20:01:40.772462  2318 solver.cpp:253]     Train net output #0: loss = 1.08193 (* 1 = 1.08193 loss)
I0525 20:01:40.772482  2318 sgd_solver.cpp:106] Iteration 40500, lr = 0.003
I0525 20:01:49.511091  2318 solver.cpp:237] Iteration 40650, loss = 1.38132
I0525 20:01:49.511135  2318 solver.cpp:253]     Train net output #0: loss = 1.38132 (* 1 = 1.38132 loss)
I0525 20:01:49.511152  2318 sgd_solver.cpp:106] Iteration 40650, lr = 0.003
I0525 20:01:58.253881  2318 solver.cpp:237] Iteration 40800, loss = 1.29723
I0525 20:01:58.254046  2318 solver.cpp:253]     Train net output #0: loss = 1.29723 (* 1 = 1.29723 loss)
I0525 20:01:58.254060  2318 sgd_solver.cpp:106] Iteration 40800, lr = 0.003
I0525 20:02:06.993428  2318 solver.cpp:237] Iteration 40950, loss = 1.25948
I0525 20:02:06.993463  2318 solver.cpp:253]     Train net output #0: loss = 1.25948 (* 1 = 1.25948 loss)
I0525 20:02:06.993479  2318 sgd_solver.cpp:106] Iteration 40950, lr = 0.003
I0525 20:02:36.645787  2318 solver.cpp:237] Iteration 41100, loss = 1.25362
I0525 20:02:36.645972  2318 solver.cpp:253]     Train net output #0: loss = 1.25362 (* 1 = 1.25362 loss)
I0525 20:02:36.645987  2318 sgd_solver.cpp:106] Iteration 41100, lr = 0.003
I0525 20:02:45.384043  2318 solver.cpp:237] Iteration 41250, loss = 1.17629
I0525 20:02:45.384079  2318 solver.cpp:253]     Train net output #0: loss = 1.17629 (* 1 = 1.17629 loss)
I0525 20:02:45.384104  2318 sgd_solver.cpp:106] Iteration 41250, lr = 0.003
I0525 20:02:54.121318  2318 solver.cpp:237] Iteration 41400, loss = 1.36478
I0525 20:02:54.121354  2318 solver.cpp:253]     Train net output #0: loss = 1.36478 (* 1 = 1.36478 loss)
I0525 20:02:54.121371  2318 sgd_solver.cpp:106] Iteration 41400, lr = 0.003
I0525 20:03:02.860194  2318 solver.cpp:237] Iteration 41550, loss = 1.34192
I0525 20:03:02.860230  2318 solver.cpp:253]     Train net output #0: loss = 1.34192 (* 1 = 1.34192 loss)
I0525 20:03:02.860246  2318 sgd_solver.cpp:106] Iteration 41550, lr = 0.003
I0525 20:03:11.597909  2318 solver.cpp:237] Iteration 41700, loss = 1.13221
I0525 20:03:11.598095  2318 solver.cpp:253]     Train net output #0: loss = 1.13221 (* 1 = 1.13221 loss)
I0525 20:03:11.598109  2318 sgd_solver.cpp:106] Iteration 41700, lr = 0.003
I0525 20:03:20.334650  2318 solver.cpp:237] Iteration 41850, loss = 1.06086
I0525 20:03:20.334684  2318 solver.cpp:253]     Train net output #0: loss = 1.06086 (* 1 = 1.06086 loss)
I0525 20:03:20.334702  2318 sgd_solver.cpp:106] Iteration 41850, lr = 0.003
I0525 20:03:29.016386  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_42000.caffemodel
I0525 20:03:29.095260  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_42000.solverstate
I0525 20:03:29.120100  2318 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 20:04:36.888581  2318 solver.cpp:409]     Test net output #0: accuracy = 0.885555
I0525 20:04:36.888766  2318 solver.cpp:409]     Test net output #1: loss = 0.372569 (* 1 = 0.372569 loss)
I0525 20:04:57.801115  2318 solver.cpp:237] Iteration 42000, loss = 1.18423
I0525 20:04:57.801169  2318 solver.cpp:253]     Train net output #0: loss = 1.18423 (* 1 = 1.18423 loss)
I0525 20:04:57.801184  2318 sgd_solver.cpp:106] Iteration 42000, lr = 0.003
I0525 20:05:06.525931  2318 solver.cpp:237] Iteration 42150, loss = 1.27168
I0525 20:05:06.525967  2318 solver.cpp:253]     Train net output #0: loss = 1.27168 (* 1 = 1.27168 loss)
I0525 20:05:06.525985  2318 sgd_solver.cpp:106] Iteration 42150, lr = 0.003
I0525 20:05:15.257136  2318 solver.cpp:237] Iteration 42300, loss = 1.12463
I0525 20:05:15.257311  2318 solver.cpp:253]     Train net output #0: loss = 1.12463 (* 1 = 1.12463 loss)
I0525 20:05:15.257326  2318 sgd_solver.cpp:106] Iteration 42300, lr = 0.003
I0525 20:05:23.986937  2318 solver.cpp:237] Iteration 42450, loss = 1.35406
I0525 20:05:23.986971  2318 solver.cpp:253]     Train net output #0: loss = 1.35406 (* 1 = 1.35406 loss)
I0525 20:05:23.986989  2318 sgd_solver.cpp:106] Iteration 42450, lr = 0.003
I0525 20:05:32.719853  2318 solver.cpp:237] Iteration 42600, loss = 1.30547
I0525 20:05:32.719889  2318 solver.cpp:253]     Train net output #0: loss = 1.30547 (* 1 = 1.30547 loss)
I0525 20:05:32.719904  2318 sgd_solver.cpp:106] Iteration 42600, lr = 0.003
I0525 20:05:41.451820  2318 solver.cpp:237] Iteration 42750, loss = 1.19232
I0525 20:05:41.451858  2318 solver.cpp:253]     Train net output #0: loss = 1.19232 (* 1 = 1.19232 loss)
I0525 20:05:41.451879  2318 sgd_solver.cpp:106] Iteration 42750, lr = 0.003
I0525 20:05:50.184713  2318 solver.cpp:237] Iteration 42900, loss = 1.12771
I0525 20:05:50.184873  2318 solver.cpp:253]     Train net output #0: loss = 1.12771 (* 1 = 1.12771 loss)
I0525 20:05:50.184886  2318 sgd_solver.cpp:106] Iteration 42900, lr = 0.003
I0525 20:06:19.841800  2318 solver.cpp:237] Iteration 43050, loss = 1.08653
I0525 20:06:19.841851  2318 solver.cpp:253]     Train net output #0: loss = 1.08653 (* 1 = 1.08653 loss)
I0525 20:06:19.841866  2318 sgd_solver.cpp:106] Iteration 43050, lr = 0.003
I0525 20:06:28.577533  2318 solver.cpp:237] Iteration 43200, loss = 1.18702
I0525 20:06:28.577719  2318 solver.cpp:253]     Train net output #0: loss = 1.18702 (* 1 = 1.18702 loss)
I0525 20:06:28.577734  2318 sgd_solver.cpp:106] Iteration 43200, lr = 0.003
I0525 20:06:37.315117  2318 solver.cpp:237] Iteration 43350, loss = 1.16979
I0525 20:06:37.315152  2318 solver.cpp:253]     Train net output #0: loss = 1.16979 (* 1 = 1.16979 loss)
I0525 20:06:37.315171  2318 sgd_solver.cpp:106] Iteration 43350, lr = 0.003
I0525 20:06:45.988016  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_43500.caffemodel
I0525 20:06:46.069320  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_43500.solverstate
I0525 20:06:46.114912  2318 solver.cpp:237] Iteration 43500, loss = 1.26871
I0525 20:06:46.114964  2318 solver.cpp:253]     Train net output #0: loss = 1.26871 (* 1 = 1.26871 loss)
I0525 20:06:46.114976  2318 sgd_solver.cpp:106] Iteration 43500, lr = 0.003
I0525 20:06:54.845427  2318 solver.cpp:237] Iteration 43650, loss = 1.21389
I0525 20:06:54.845460  2318 solver.cpp:253]     Train net output #0: loss = 1.21389 (* 1 = 1.21389 loss)
I0525 20:06:54.845482  2318 sgd_solver.cpp:106] Iteration 43650, lr = 0.003
I0525 20:07:03.583442  2318 solver.cpp:237] Iteration 43800, loss = 1.24841
I0525 20:07:03.583611  2318 solver.cpp:253]     Train net output #0: loss = 1.24841 (* 1 = 1.24841 loss)
I0525 20:07:03.583626  2318 sgd_solver.cpp:106] Iteration 43800, lr = 0.003
I0525 20:07:12.316494  2318 solver.cpp:237] Iteration 43950, loss = 1.29485
I0525 20:07:12.316529  2318 solver.cpp:253]     Train net output #0: loss = 1.29485 (* 1 = 1.29485 loss)
I0525 20:07:12.316545  2318 sgd_solver.cpp:106] Iteration 43950, lr = 0.003
I0525 20:07:41.951721  2318 solver.cpp:237] Iteration 44100, loss = 1.08609
I0525 20:07:41.951905  2318 solver.cpp:253]     Train net output #0: loss = 1.08609 (* 1 = 1.08609 loss)
I0525 20:07:41.951920  2318 sgd_solver.cpp:106] Iteration 44100, lr = 0.003
I0525 20:07:50.688185  2318 solver.cpp:237] Iteration 44250, loss = 1.14657
I0525 20:07:50.688220  2318 solver.cpp:253]     Train net output #0: loss = 1.14657 (* 1 = 1.14657 loss)
I0525 20:07:50.688236  2318 sgd_solver.cpp:106] Iteration 44250, lr = 0.003
I0525 20:07:59.419965  2318 solver.cpp:237] Iteration 44400, loss = 1.05003
I0525 20:07:59.420001  2318 solver.cpp:253]     Train net output #0: loss = 1.05003 (* 1 = 1.05003 loss)
I0525 20:07:59.420017  2318 sgd_solver.cpp:106] Iteration 44400, lr = 0.003
I0525 20:08:08.153370  2318 solver.cpp:237] Iteration 44550, loss = 1.20736
I0525 20:08:08.153417  2318 solver.cpp:253]     Train net output #0: loss = 1.20736 (* 1 = 1.20736 loss)
I0525 20:08:08.153431  2318 sgd_solver.cpp:106] Iteration 44550, lr = 0.003
I0525 20:08:16.886001  2318 solver.cpp:237] Iteration 44700, loss = 1.04943
I0525 20:08:16.886164  2318 solver.cpp:253]     Train net output #0: loss = 1.04943 (* 1 = 1.04943 loss)
I0525 20:08:16.886178  2318 sgd_solver.cpp:106] Iteration 44700, lr = 0.003
I0525 20:08:25.619412  2318 solver.cpp:237] Iteration 44850, loss = 1.11822
I0525 20:08:25.619447  2318 solver.cpp:253]     Train net output #0: loss = 1.11822 (* 1 = 1.11822 loss)
I0525 20:08:25.619464  2318 sgd_solver.cpp:106] Iteration 44850, lr = 0.003
I0525 20:08:34.296816  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_45000.caffemodel
I0525 20:08:34.377851  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_45000.solverstate
I0525 20:08:34.405958  2318 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 20:09:20.909047  2318 solver.cpp:409]     Test net output #0: accuracy = 0.884875
I0525 20:09:20.909240  2318 solver.cpp:409]     Test net output #1: loss = 0.36055 (* 1 = 0.36055 loss)
I0525 20:09:41.781402  2318 solver.cpp:237] Iteration 45000, loss = 1.16122
I0525 20:09:41.781456  2318 solver.cpp:253]     Train net output #0: loss = 1.16122 (* 1 = 1.16122 loss)
I0525 20:09:41.781471  2318 sgd_solver.cpp:106] Iteration 45000, lr = 0.003
I0525 20:09:50.520095  2318 solver.cpp:237] Iteration 45150, loss = 1.12725
I0525 20:09:50.520143  2318 solver.cpp:253]     Train net output #0: loss = 1.12725 (* 1 = 1.12725 loss)
I0525 20:09:50.520160  2318 sgd_solver.cpp:106] Iteration 45150, lr = 0.003
I0525 20:09:59.256042  2318 solver.cpp:237] Iteration 45300, loss = 1.00691
I0525 20:09:59.256216  2318 solver.cpp:253]     Train net output #0: loss = 1.00691 (* 1 = 1.00691 loss)
I0525 20:09:59.256229  2318 sgd_solver.cpp:106] Iteration 45300, lr = 0.003
I0525 20:10:07.994585  2318 solver.cpp:237] Iteration 45450, loss = 1.0018
I0525 20:10:07.994621  2318 solver.cpp:253]     Train net output #0: loss = 1.0018 (* 1 = 1.0018 loss)
I0525 20:10:07.994638  2318 sgd_solver.cpp:106] Iteration 45450, lr = 0.003
I0525 20:10:16.739110  2318 solver.cpp:237] Iteration 45600, loss = 1.0614
I0525 20:10:16.739153  2318 solver.cpp:253]     Train net output #0: loss = 1.0614 (* 1 = 1.0614 loss)
I0525 20:10:16.739169  2318 sgd_solver.cpp:106] Iteration 45600, lr = 0.003
I0525 20:10:25.481580  2318 solver.cpp:237] Iteration 45750, loss = 1.10379
I0525 20:10:25.481616  2318 solver.cpp:253]     Train net output #0: loss = 1.10379 (* 1 = 1.10379 loss)
I0525 20:10:25.481631  2318 sgd_solver.cpp:106] Iteration 45750, lr = 0.003
I0525 20:10:34.217952  2318 solver.cpp:237] Iteration 45900, loss = 1.27778
I0525 20:10:34.218122  2318 solver.cpp:253]     Train net output #0: loss = 1.27778 (* 1 = 1.27778 loss)
I0525 20:10:34.218137  2318 sgd_solver.cpp:106] Iteration 45900, lr = 0.003
I0525 20:11:03.795860  2318 solver.cpp:237] Iteration 46050, loss = 1.3342
I0525 20:11:03.795910  2318 solver.cpp:253]     Train net output #0: loss = 1.3342 (* 1 = 1.3342 loss)
I0525 20:11:03.795925  2318 sgd_solver.cpp:106] Iteration 46050, lr = 0.003
I0525 20:11:12.542333  2318 solver.cpp:237] Iteration 46200, loss = 1.12939
I0525 20:11:12.542500  2318 solver.cpp:253]     Train net output #0: loss = 1.12939 (* 1 = 1.12939 loss)
I0525 20:11:12.542513  2318 sgd_solver.cpp:106] Iteration 46200, lr = 0.003
I0525 20:11:21.281431  2318 solver.cpp:237] Iteration 46350, loss = 1.26467
I0525 20:11:21.281466  2318 solver.cpp:253]     Train net output #0: loss = 1.26467 (* 1 = 1.26467 loss)
I0525 20:11:21.281483  2318 sgd_solver.cpp:106] Iteration 46350, lr = 0.003
I0525 20:11:29.958047  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_46500.caffemodel
I0525 20:11:30.037309  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_46500.solverstate
I0525 20:11:30.080335  2318 solver.cpp:237] Iteration 46500, loss = 1.17411
I0525 20:11:30.080376  2318 solver.cpp:253]     Train net output #0: loss = 1.17411 (* 1 = 1.17411 loss)
I0525 20:11:30.080397  2318 sgd_solver.cpp:106] Iteration 46500, lr = 0.003
I0525 20:11:38.819345  2318 solver.cpp:237] Iteration 46650, loss = 1.21755
I0525 20:11:38.819381  2318 solver.cpp:253]     Train net output #0: loss = 1.21755 (* 1 = 1.21755 loss)
I0525 20:11:38.819397  2318 sgd_solver.cpp:106] Iteration 46650, lr = 0.003
I0525 20:11:47.559921  2318 solver.cpp:237] Iteration 46800, loss = 1.26109
I0525 20:11:47.560093  2318 solver.cpp:253]     Train net output #0: loss = 1.26109 (* 1 = 1.26109 loss)
I0525 20:11:47.560107  2318 sgd_solver.cpp:106] Iteration 46800, lr = 0.003
I0525 20:11:56.296757  2318 solver.cpp:237] Iteration 46950, loss = 1.21698
I0525 20:11:56.296793  2318 solver.cpp:253]     Train net output #0: loss = 1.21698 (* 1 = 1.21698 loss)
I0525 20:11:56.296814  2318 sgd_solver.cpp:106] Iteration 46950, lr = 0.003
I0525 20:12:25.932055  2318 solver.cpp:237] Iteration 47100, loss = 1.14796
I0525 20:12:25.932256  2318 solver.cpp:253]     Train net output #0: loss = 1.14796 (* 1 = 1.14796 loss)
I0525 20:12:25.932271  2318 sgd_solver.cpp:106] Iteration 47100, lr = 0.003
I0525 20:12:34.672813  2318 solver.cpp:237] Iteration 47250, loss = 1.12058
I0525 20:12:34.672848  2318 solver.cpp:253]     Train net output #0: loss = 1.12058 (* 1 = 1.12058 loss)
I0525 20:12:34.672865  2318 sgd_solver.cpp:106] Iteration 47250, lr = 0.003
I0525 20:12:43.419034  2318 solver.cpp:237] Iteration 47400, loss = 1.28313
I0525 20:12:43.419080  2318 solver.cpp:253]     Train net output #0: loss = 1.28313 (* 1 = 1.28313 loss)
I0525 20:12:43.419097  2318 sgd_solver.cpp:106] Iteration 47400, lr = 0.003
I0525 20:12:52.157418  2318 solver.cpp:237] Iteration 47550, loss = 1.07031
I0525 20:12:52.157454  2318 solver.cpp:253]     Train net output #0: loss = 1.07031 (* 1 = 1.07031 loss)
I0525 20:12:52.157470  2318 sgd_solver.cpp:106] Iteration 47550, lr = 0.003
I0525 20:13:00.894980  2318 solver.cpp:237] Iteration 47700, loss = 1.11064
I0525 20:13:00.895148  2318 solver.cpp:253]     Train net output #0: loss = 1.11064 (* 1 = 1.11064 loss)
I0525 20:13:00.895161  2318 sgd_solver.cpp:106] Iteration 47700, lr = 0.003
I0525 20:13:09.632941  2318 solver.cpp:237] Iteration 47850, loss = 1.19606
I0525 20:13:09.632987  2318 solver.cpp:253]     Train net output #0: loss = 1.19606 (* 1 = 1.19606 loss)
I0525 20:13:09.633004  2318 sgd_solver.cpp:106] Iteration 47850, lr = 0.003
I0525 20:13:18.311687  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_48000.caffemodel
I0525 20:13:18.390123  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_48000.solverstate
I0525 20:13:18.415994  2318 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 20:14:26.115377  2318 solver.cpp:409]     Test net output #0: accuracy = 0.887415
I0525 20:14:26.115561  2318 solver.cpp:409]     Test net output #1: loss = 0.352044 (* 1 = 0.352044 loss)
I0525 20:14:47.050668  2318 solver.cpp:237] Iteration 48000, loss = 1.05279
I0525 20:14:47.050720  2318 solver.cpp:253]     Train net output #0: loss = 1.05279 (* 1 = 1.05279 loss)
I0525 20:14:47.050735  2318 sgd_solver.cpp:106] Iteration 48000, lr = 0.003
I0525 20:14:55.778789  2318 solver.cpp:237] Iteration 48150, loss = 1.10507
I0525 20:14:55.778825  2318 solver.cpp:253]     Train net output #0: loss = 1.10507 (* 1 = 1.10507 loss)
I0525 20:14:55.778841  2318 sgd_solver.cpp:106] Iteration 48150, lr = 0.003
I0525 20:15:04.507602  2318 solver.cpp:237] Iteration 48300, loss = 1.16729
I0525 20:15:04.507769  2318 solver.cpp:253]     Train net output #0: loss = 1.16729 (* 1 = 1.16729 loss)
I0525 20:15:04.507782  2318 sgd_solver.cpp:106] Iteration 48300, lr = 0.003
I0525 20:15:13.232641  2318 solver.cpp:237] Iteration 48450, loss = 1.1975
I0525 20:15:13.232686  2318 solver.cpp:253]     Train net output #0: loss = 1.1975 (* 1 = 1.1975 loss)
I0525 20:15:13.232703  2318 sgd_solver.cpp:106] Iteration 48450, lr = 0.003
I0525 20:15:21.962859  2318 solver.cpp:237] Iteration 48600, loss = 1.20137
I0525 20:15:21.962895  2318 solver.cpp:253]     Train net output #0: loss = 1.20137 (* 1 = 1.20137 loss)
I0525 20:15:21.962911  2318 sgd_solver.cpp:106] Iteration 48600, lr = 0.003
I0525 20:15:30.690930  2318 solver.cpp:237] Iteration 48750, loss = 1.14199
I0525 20:15:30.690966  2318 solver.cpp:253]     Train net output #0: loss = 1.14199 (* 1 = 1.14199 loss)
I0525 20:15:30.690982  2318 sgd_solver.cpp:106] Iteration 48750, lr = 0.003
I0525 20:15:39.415030  2318 solver.cpp:237] Iteration 48900, loss = 1.21199
I0525 20:15:39.415213  2318 solver.cpp:253]     Train net output #0: loss = 1.21199 (* 1 = 1.21199 loss)
I0525 20:15:39.415227  2318 sgd_solver.cpp:106] Iteration 48900, lr = 0.003
I0525 20:16:09.038311  2318 solver.cpp:237] Iteration 49050, loss = 1.2359
I0525 20:16:09.038359  2318 solver.cpp:253]     Train net output #0: loss = 1.2359 (* 1 = 1.2359 loss)
I0525 20:16:09.038377  2318 sgd_solver.cpp:106] Iteration 49050, lr = 0.003
I0525 20:16:17.765081  2318 solver.cpp:237] Iteration 49200, loss = 1.22766
I0525 20:16:17.765251  2318 solver.cpp:253]     Train net output #0: loss = 1.22766 (* 1 = 1.22766 loss)
I0525 20:16:17.765265  2318 sgd_solver.cpp:106] Iteration 49200, lr = 0.003
I0525 20:16:26.497069  2318 solver.cpp:237] Iteration 49350, loss = 1.30267
I0525 20:16:26.497114  2318 solver.cpp:253]     Train net output #0: loss = 1.30267 (* 1 = 1.30267 loss)
I0525 20:16:26.497133  2318 sgd_solver.cpp:106] Iteration 49350, lr = 0.003
I0525 20:16:35.170694  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_49500.caffemodel
I0525 20:16:35.248839  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_49500.solverstate
I0525 20:16:35.295534  2318 solver.cpp:237] Iteration 49500, loss = 1.06471
I0525 20:16:35.295583  2318 solver.cpp:253]     Train net output #0: loss = 1.06471 (* 1 = 1.06471 loss)
I0525 20:16:35.295599  2318 sgd_solver.cpp:106] Iteration 49500, lr = 0.003
I0525 20:16:44.019739  2318 solver.cpp:237] Iteration 49650, loss = 1.13786
I0525 20:16:44.019775  2318 solver.cpp:253]     Train net output #0: loss = 1.13786 (* 1 = 1.13786 loss)
I0525 20:16:44.019793  2318 sgd_solver.cpp:106] Iteration 49650, lr = 0.003
I0525 20:16:52.748551  2318 solver.cpp:237] Iteration 49800, loss = 1.11753
I0525 20:16:52.748741  2318 solver.cpp:253]     Train net output #0: loss = 1.11753 (* 1 = 1.11753 loss)
I0525 20:16:52.748756  2318 sgd_solver.cpp:106] Iteration 49800, lr = 0.003
I0525 20:17:01.474725  2318 solver.cpp:237] Iteration 49950, loss = 1.18868
I0525 20:17:01.474759  2318 solver.cpp:253]     Train net output #0: loss = 1.18868 (* 1 = 1.18868 loss)
I0525 20:17:01.474776  2318 sgd_solver.cpp:106] Iteration 49950, lr = 0.003
I0525 20:17:31.150440  2318 solver.cpp:237] Iteration 50100, loss = 1.02777
I0525 20:17:31.150629  2318 solver.cpp:253]     Train net output #0: loss = 1.02777 (* 1 = 1.02777 loss)
I0525 20:17:31.150643  2318 sgd_solver.cpp:106] Iteration 50100, lr = 0.003
I0525 20:17:39.871218  2318 solver.cpp:237] Iteration 50250, loss = 1.24849
I0525 20:17:39.871263  2318 solver.cpp:253]     Train net output #0: loss = 1.24849 (* 1 = 1.24849 loss)
I0525 20:17:39.871280  2318 sgd_solver.cpp:106] Iteration 50250, lr = 0.003
I0525 20:17:48.606809  2318 solver.cpp:237] Iteration 50400, loss = 1.19103
I0525 20:17:48.606845  2318 solver.cpp:253]     Train net output #0: loss = 1.19103 (* 1 = 1.19103 loss)
I0525 20:17:48.606861  2318 sgd_solver.cpp:106] Iteration 50400, lr = 0.003
I0525 20:17:57.335593  2318 solver.cpp:237] Iteration 50550, loss = 1.24381
I0525 20:17:57.335629  2318 solver.cpp:253]     Train net output #0: loss = 1.24381 (* 1 = 1.24381 loss)
I0525 20:17:57.335645  2318 sgd_solver.cpp:106] Iteration 50550, lr = 0.003
I0525 20:18:06.063917  2318 solver.cpp:237] Iteration 50700, loss = 1.21485
I0525 20:18:06.064111  2318 solver.cpp:253]     Train net output #0: loss = 1.21485 (* 1 = 1.21485 loss)
I0525 20:18:06.064126  2318 sgd_solver.cpp:106] Iteration 50700, lr = 0.003
I0525 20:18:14.792651  2318 solver.cpp:237] Iteration 50850, loss = 1.2547
I0525 20:18:14.792687  2318 solver.cpp:253]     Train net output #0: loss = 1.2547 (* 1 = 1.2547 loss)
I0525 20:18:14.792702  2318 sgd_solver.cpp:106] Iteration 50850, lr = 0.003
I0525 20:18:23.459002  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_51000.caffemodel
I0525 20:18:23.538743  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_51000.solverstate
I0525 20:18:23.565867  2318 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 20:19:10.427582  2318 solver.cpp:409]     Test net output #0: accuracy = 0.888762
I0525 20:19:10.427777  2318 solver.cpp:409]     Test net output #1: loss = 0.387047 (* 1 = 0.387047 loss)
I0525 20:19:31.345814  2318 solver.cpp:237] Iteration 51000, loss = 1.1547
I0525 20:19:31.345868  2318 solver.cpp:253]     Train net output #0: loss = 1.1547 (* 1 = 1.1547 loss)
I0525 20:19:31.345885  2318 sgd_solver.cpp:106] Iteration 51000, lr = 0.003
I0525 20:19:40.083678  2318 solver.cpp:237] Iteration 51150, loss = 1.31765
I0525 20:19:40.083714  2318 solver.cpp:253]     Train net output #0: loss = 1.31765 (* 1 = 1.31765 loss)
I0525 20:19:40.083729  2318 sgd_solver.cpp:106] Iteration 51150, lr = 0.003
I0525 20:19:48.819373  2318 solver.cpp:237] Iteration 51300, loss = 1.18806
I0525 20:19:48.819553  2318 solver.cpp:253]     Train net output #0: loss = 1.18806 (* 1 = 1.18806 loss)
I0525 20:19:48.819568  2318 sgd_solver.cpp:106] Iteration 51300, lr = 0.003
I0525 20:19:57.566455  2318 solver.cpp:237] Iteration 51450, loss = 1.23456
I0525 20:19:57.566489  2318 solver.cpp:253]     Train net output #0: loss = 1.23456 (* 1 = 1.23456 loss)
I0525 20:19:57.566507  2318 sgd_solver.cpp:106] Iteration 51450, lr = 0.003
I0525 20:20:06.308845  2318 solver.cpp:237] Iteration 51600, loss = 1.20624
I0525 20:20:06.308881  2318 solver.cpp:253]     Train net output #0: loss = 1.20624 (* 1 = 1.20624 loss)
I0525 20:20:06.308897  2318 sgd_solver.cpp:106] Iteration 51600, lr = 0.003
I0525 20:20:15.050007  2318 solver.cpp:237] Iteration 51750, loss = 1.30961
I0525 20:20:15.050050  2318 solver.cpp:253]     Train net output #0: loss = 1.30961 (* 1 = 1.30961 loss)
I0525 20:20:15.050068  2318 sgd_solver.cpp:106] Iteration 51750, lr = 0.003
I0525 20:20:23.791560  2318 solver.cpp:237] Iteration 51900, loss = 1.20507
I0525 20:20:23.791726  2318 solver.cpp:253]     Train net output #0: loss = 1.20507 (* 1 = 1.20507 loss)
I0525 20:20:23.791739  2318 sgd_solver.cpp:106] Iteration 51900, lr = 0.003
I0525 20:20:53.433125  2318 solver.cpp:237] Iteration 52050, loss = 1.01605
I0525 20:20:53.433176  2318 solver.cpp:253]     Train net output #0: loss = 1.01605 (* 1 = 1.01605 loss)
I0525 20:20:53.433192  2318 sgd_solver.cpp:106] Iteration 52050, lr = 0.003
I0525 20:21:02.170856  2318 solver.cpp:237] Iteration 52200, loss = 1.01894
I0525 20:21:02.171036  2318 solver.cpp:253]     Train net output #0: loss = 1.01894 (* 1 = 1.01894 loss)
I0525 20:21:02.171051  2318 sgd_solver.cpp:106] Iteration 52200, lr = 0.003
I0525 20:21:10.910583  2318 solver.cpp:237] Iteration 52350, loss = 1.14185
I0525 20:21:10.910616  2318 solver.cpp:253]     Train net output #0: loss = 1.14185 (* 1 = 1.14185 loss)
I0525 20:21:10.910634  2318 sgd_solver.cpp:106] Iteration 52350, lr = 0.003
I0525 20:21:19.593880  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_52500.caffemodel
I0525 20:21:19.675042  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_52500.solverstate
I0525 20:21:19.721009  2318 solver.cpp:237] Iteration 52500, loss = 1.08386
I0525 20:21:19.721055  2318 solver.cpp:253]     Train net output #0: loss = 1.08386 (* 1 = 1.08386 loss)
I0525 20:21:19.721076  2318 sgd_solver.cpp:106] Iteration 52500, lr = 0.003
I0525 20:21:28.462232  2318 solver.cpp:237] Iteration 52650, loss = 1.06564
I0525 20:21:28.462277  2318 solver.cpp:253]     Train net output #0: loss = 1.06564 (* 1 = 1.06564 loss)
I0525 20:21:28.462294  2318 sgd_solver.cpp:106] Iteration 52650, lr = 0.003
I0525 20:21:37.197533  2318 solver.cpp:237] Iteration 52800, loss = 1.27621
I0525 20:21:37.197716  2318 solver.cpp:253]     Train net output #0: loss = 1.27621 (* 1 = 1.27621 loss)
I0525 20:21:37.197729  2318 sgd_solver.cpp:106] Iteration 52800, lr = 0.003
I0525 20:21:45.936641  2318 solver.cpp:237] Iteration 52950, loss = 1.13927
I0525 20:21:45.936676  2318 solver.cpp:253]     Train net output #0: loss = 1.13927 (* 1 = 1.13927 loss)
I0525 20:21:45.936693  2318 sgd_solver.cpp:106] Iteration 52950, lr = 0.003
I0525 20:22:15.547865  2318 solver.cpp:237] Iteration 53100, loss = 1.27693
I0525 20:22:15.548051  2318 solver.cpp:253]     Train net output #0: loss = 1.27693 (* 1 = 1.27693 loss)
I0525 20:22:15.548066  2318 sgd_solver.cpp:106] Iteration 53100, lr = 0.003
I0525 20:22:24.287101  2318 solver.cpp:237] Iteration 53250, loss = 1.21716
I0525 20:22:24.287135  2318 solver.cpp:253]     Train net output #0: loss = 1.21716 (* 1 = 1.21716 loss)
I0525 20:22:24.287153  2318 sgd_solver.cpp:106] Iteration 53250, lr = 0.003
I0525 20:22:33.023468  2318 solver.cpp:237] Iteration 53400, loss = 1.34554
I0525 20:22:33.023504  2318 solver.cpp:253]     Train net output #0: loss = 1.34554 (* 1 = 1.34554 loss)
I0525 20:22:33.023520  2318 sgd_solver.cpp:106] Iteration 53400, lr = 0.003
I0525 20:22:41.764510  2318 solver.cpp:237] Iteration 53550, loss = 1.19017
I0525 20:22:41.764551  2318 solver.cpp:253]     Train net output #0: loss = 1.19017 (* 1 = 1.19017 loss)
I0525 20:22:41.764566  2318 sgd_solver.cpp:106] Iteration 53550, lr = 0.003
I0525 20:22:50.506093  2318 solver.cpp:237] Iteration 53700, loss = 1.37373
I0525 20:22:50.506255  2318 solver.cpp:253]     Train net output #0: loss = 1.37373 (* 1 = 1.37373 loss)
I0525 20:22:50.506268  2318 sgd_solver.cpp:106] Iteration 53700, lr = 0.003
I0525 20:22:59.247522  2318 solver.cpp:237] Iteration 53850, loss = 1.03748
I0525 20:22:59.247557  2318 solver.cpp:253]     Train net output #0: loss = 1.03748 (* 1 = 1.03748 loss)
I0525 20:22:59.247575  2318 sgd_solver.cpp:106] Iteration 53850, lr = 0.003
I0525 20:23:07.928436  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_54000.caffemodel
I0525 20:23:08.009212  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_54000.solverstate
I0525 20:23:08.037556  2318 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 20:24:15.781677  2318 solver.cpp:409]     Test net output #0: accuracy = 0.891749
I0525 20:24:15.781865  2318 solver.cpp:409]     Test net output #1: loss = 0.343504 (* 1 = 0.343504 loss)
I0525 20:24:36.686560  2318 solver.cpp:237] Iteration 54000, loss = 1.07824
I0525 20:24:36.686612  2318 solver.cpp:253]     Train net output #0: loss = 1.07824 (* 1 = 1.07824 loss)
I0525 20:24:36.686630  2318 sgd_solver.cpp:106] Iteration 54000, lr = 0.003
I0525 20:24:45.420250  2318 solver.cpp:237] Iteration 54150, loss = 1.11938
I0525 20:24:45.420296  2318 solver.cpp:253]     Train net output #0: loss = 1.11938 (* 1 = 1.11938 loss)
I0525 20:24:45.420315  2318 sgd_solver.cpp:106] Iteration 54150, lr = 0.003
I0525 20:24:54.150966  2318 solver.cpp:237] Iteration 54300, loss = 1.23975
I0525 20:24:54.151135  2318 solver.cpp:253]     Train net output #0: loss = 1.23975 (* 1 = 1.23975 loss)
I0525 20:24:54.151149  2318 sgd_solver.cpp:106] Iteration 54300, lr = 0.003
I0525 20:25:02.884685  2318 solver.cpp:237] Iteration 54450, loss = 1.31491
I0525 20:25:02.884721  2318 solver.cpp:253]     Train net output #0: loss = 1.31491 (* 1 = 1.31491 loss)
I0525 20:25:02.884737  2318 sgd_solver.cpp:106] Iteration 54450, lr = 0.003
I0525 20:25:11.621137  2318 solver.cpp:237] Iteration 54600, loss = 1.09462
I0525 20:25:11.621186  2318 solver.cpp:253]     Train net output #0: loss = 1.09462 (* 1 = 1.09462 loss)
I0525 20:25:11.621199  2318 sgd_solver.cpp:106] Iteration 54600, lr = 0.003
I0525 20:25:20.354022  2318 solver.cpp:237] Iteration 54750, loss = 1.11542
I0525 20:25:20.354058  2318 solver.cpp:253]     Train net output #0: loss = 1.11542 (* 1 = 1.11542 loss)
I0525 20:25:20.354075  2318 sgd_solver.cpp:106] Iteration 54750, lr = 0.003
I0525 20:25:29.086645  2318 solver.cpp:237] Iteration 54900, loss = 1.34601
I0525 20:25:29.086822  2318 solver.cpp:253]     Train net output #0: loss = 1.34601 (* 1 = 1.34601 loss)
I0525 20:25:29.086835  2318 sgd_solver.cpp:106] Iteration 54900, lr = 0.003
I0525 20:25:58.688310  2318 solver.cpp:237] Iteration 55050, loss = 1.1412
I0525 20:25:58.688360  2318 solver.cpp:253]     Train net output #0: loss = 1.1412 (* 1 = 1.1412 loss)
I0525 20:25:58.688380  2318 sgd_solver.cpp:106] Iteration 55050, lr = 0.003
I0525 20:26:07.422128  2318 solver.cpp:237] Iteration 55200, loss = 1.18562
I0525 20:26:07.422302  2318 solver.cpp:253]     Train net output #0: loss = 1.18562 (* 1 = 1.18562 loss)
I0525 20:26:07.422314  2318 sgd_solver.cpp:106] Iteration 55200, lr = 0.003
I0525 20:26:16.153537  2318 solver.cpp:237] Iteration 55350, loss = 1.09608
I0525 20:26:16.153571  2318 solver.cpp:253]     Train net output #0: loss = 1.09608 (* 1 = 1.09608 loss)
I0525 20:26:16.153589  2318 sgd_solver.cpp:106] Iteration 55350, lr = 0.003
I0525 20:26:24.826663  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_55500.caffemodel
I0525 20:26:24.905627  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_55500.solverstate
I0525 20:26:24.949014  2318 solver.cpp:237] Iteration 55500, loss = 1.21154
I0525 20:26:24.949060  2318 solver.cpp:253]     Train net output #0: loss = 1.21154 (* 1 = 1.21154 loss)
I0525 20:26:24.949074  2318 sgd_solver.cpp:106] Iteration 55500, lr = 0.003
I0525 20:26:33.685542  2318 solver.cpp:237] Iteration 55650, loss = 1.12242
I0525 20:26:33.685577  2318 solver.cpp:253]     Train net output #0: loss = 1.12242 (* 1 = 1.12242 loss)
I0525 20:26:33.685593  2318 sgd_solver.cpp:106] Iteration 55650, lr = 0.003
I0525 20:26:42.418700  2318 solver.cpp:237] Iteration 55800, loss = 1.17087
I0525 20:26:42.418872  2318 solver.cpp:253]     Train net output #0: loss = 1.17087 (* 1 = 1.17087 loss)
I0525 20:26:42.418885  2318 sgd_solver.cpp:106] Iteration 55800, lr = 0.003
I0525 20:26:51.147514  2318 solver.cpp:237] Iteration 55950, loss = 1.1317
I0525 20:26:51.147554  2318 solver.cpp:253]     Train net output #0: loss = 1.1317 (* 1 = 1.1317 loss)
I0525 20:26:51.147575  2318 sgd_solver.cpp:106] Iteration 55950, lr = 0.003
I0525 20:27:20.778142  2318 solver.cpp:237] Iteration 56100, loss = 1.05246
I0525 20:27:20.778333  2318 solver.cpp:253]     Train net output #0: loss = 1.05246 (* 1 = 1.05246 loss)
I0525 20:27:20.778348  2318 sgd_solver.cpp:106] Iteration 56100, lr = 0.003
I0525 20:27:29.512394  2318 solver.cpp:237] Iteration 56250, loss = 1.41395
I0525 20:27:29.512428  2318 solver.cpp:253]     Train net output #0: loss = 1.41395 (* 1 = 1.41395 loss)
I0525 20:27:29.512446  2318 sgd_solver.cpp:106] Iteration 56250, lr = 0.003
I0525 20:27:38.249961  2318 solver.cpp:237] Iteration 56400, loss = 1.19125
I0525 20:27:38.249995  2318 solver.cpp:253]     Train net output #0: loss = 1.19125 (* 1 = 1.19125 loss)
I0525 20:27:38.250011  2318 sgd_solver.cpp:106] Iteration 56400, lr = 0.003
I0525 20:27:46.975455  2318 solver.cpp:237] Iteration 56550, loss = 1.31841
I0525 20:27:46.975491  2318 solver.cpp:253]     Train net output #0: loss = 1.31841 (* 1 = 1.31841 loss)
I0525 20:27:46.975508  2318 sgd_solver.cpp:106] Iteration 56550, lr = 0.003
I0525 20:27:55.709381  2318 solver.cpp:237] Iteration 56700, loss = 1.06061
I0525 20:27:55.709549  2318 solver.cpp:253]     Train net output #0: loss = 1.06061 (* 1 = 1.06061 loss)
I0525 20:27:55.709563  2318 sgd_solver.cpp:106] Iteration 56700, lr = 0.003
I0525 20:28:04.444638  2318 solver.cpp:237] Iteration 56850, loss = 1.11568
I0525 20:28:04.444681  2318 solver.cpp:253]     Train net output #0: loss = 1.11568 (* 1 = 1.11568 loss)
I0525 20:28:04.444700  2318 sgd_solver.cpp:106] Iteration 56850, lr = 0.003
I0525 20:28:13.116358  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_57000.caffemodel
I0525 20:28:13.194524  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_57000.solverstate
I0525 20:28:13.219595  2318 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 20:28:59.751992  2318 solver.cpp:409]     Test net output #0: accuracy = 0.890869
I0525 20:28:59.752189  2318 solver.cpp:409]     Test net output #1: loss = 0.342406 (* 1 = 0.342406 loss)
I0525 20:29:20.643319  2318 solver.cpp:237] Iteration 57000, loss = 1.30827
I0525 20:29:20.643398  2318 solver.cpp:253]     Train net output #0: loss = 1.30827 (* 1 = 1.30827 loss)
I0525 20:29:20.643412  2318 sgd_solver.cpp:106] Iteration 57000, lr = 0.003
I0525 20:29:29.387672  2318 solver.cpp:237] Iteration 57150, loss = 1.21889
I0525 20:29:29.387708  2318 solver.cpp:253]     Train net output #0: loss = 1.21889 (* 1 = 1.21889 loss)
I0525 20:29:29.387725  2318 sgd_solver.cpp:106] Iteration 57150, lr = 0.003
I0525 20:29:38.130393  2318 solver.cpp:237] Iteration 57300, loss = 1.17404
I0525 20:29:38.130566  2318 solver.cpp:253]     Train net output #0: loss = 1.17404 (* 1 = 1.17404 loss)
I0525 20:29:38.130580  2318 sgd_solver.cpp:106] Iteration 57300, lr = 0.003
I0525 20:29:46.871068  2318 solver.cpp:237] Iteration 57450, loss = 1.34074
I0525 20:29:46.871110  2318 solver.cpp:253]     Train net output #0: loss = 1.34074 (* 1 = 1.34074 loss)
I0525 20:29:46.871131  2318 sgd_solver.cpp:106] Iteration 57450, lr = 0.003
I0525 20:29:55.610164  2318 solver.cpp:237] Iteration 57600, loss = 1.17637
I0525 20:29:55.610200  2318 solver.cpp:253]     Train net output #0: loss = 1.17637 (* 1 = 1.17637 loss)
I0525 20:29:55.610216  2318 sgd_solver.cpp:106] Iteration 57600, lr = 0.003
I0525 20:30:04.350821  2318 solver.cpp:237] Iteration 57750, loss = 1.068
I0525 20:30:04.350857  2318 solver.cpp:253]     Train net output #0: loss = 1.068 (* 1 = 1.068 loss)
I0525 20:30:04.350873  2318 sgd_solver.cpp:106] Iteration 57750, lr = 0.003
I0525 20:30:13.096392  2318 solver.cpp:237] Iteration 57900, loss = 1.03442
I0525 20:30:13.096582  2318 solver.cpp:253]     Train net output #0: loss = 1.03442 (* 1 = 1.03442 loss)
I0525 20:30:13.096597  2318 sgd_solver.cpp:106] Iteration 57900, lr = 0.003
I0525 20:30:42.721019  2318 solver.cpp:237] Iteration 58050, loss = 1.28144
I0525 20:30:42.721067  2318 solver.cpp:253]     Train net output #0: loss = 1.28144 (* 1 = 1.28144 loss)
I0525 20:30:42.721086  2318 sgd_solver.cpp:106] Iteration 58050, lr = 0.003
I0525 20:30:51.461225  2318 solver.cpp:237] Iteration 58200, loss = 1.05453
I0525 20:30:51.461397  2318 solver.cpp:253]     Train net output #0: loss = 1.05453 (* 1 = 1.05453 loss)
I0525 20:30:51.461410  2318 sgd_solver.cpp:106] Iteration 58200, lr = 0.003
I0525 20:31:00.195827  2318 solver.cpp:237] Iteration 58350, loss = 1.04728
I0525 20:31:00.195873  2318 solver.cpp:253]     Train net output #0: loss = 1.04728 (* 1 = 1.04728 loss)
I0525 20:31:00.195890  2318 sgd_solver.cpp:106] Iteration 58350, lr = 0.003
I0525 20:31:08.878859  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_58500.caffemodel
I0525 20:31:08.960322  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_58500.solverstate
I0525 20:31:09.005545  2318 solver.cpp:237] Iteration 58500, loss = 1.28845
I0525 20:31:09.005599  2318 solver.cpp:253]     Train net output #0: loss = 1.28845 (* 1 = 1.28845 loss)
I0525 20:31:09.005614  2318 sgd_solver.cpp:106] Iteration 58500, lr = 0.003
I0525 20:31:17.750504  2318 solver.cpp:237] Iteration 58650, loss = 1.13879
I0525 20:31:17.750540  2318 solver.cpp:253]     Train net output #0: loss = 1.13879 (* 1 = 1.13879 loss)
I0525 20:31:17.750556  2318 sgd_solver.cpp:106] Iteration 58650, lr = 0.003
I0525 20:31:26.486745  2318 solver.cpp:237] Iteration 58800, loss = 1.3827
I0525 20:31:26.486946  2318 solver.cpp:253]     Train net output #0: loss = 1.3827 (* 1 = 1.3827 loss)
I0525 20:31:26.486961  2318 sgd_solver.cpp:106] Iteration 58800, lr = 0.003
I0525 20:31:35.216372  2318 solver.cpp:237] Iteration 58950, loss = 1.3065
I0525 20:31:35.216406  2318 solver.cpp:253]     Train net output #0: loss = 1.3065 (* 1 = 1.3065 loss)
I0525 20:31:35.216424  2318 sgd_solver.cpp:106] Iteration 58950, lr = 0.003
I0525 20:32:04.846930  2318 solver.cpp:237] Iteration 59100, loss = 0.997033
I0525 20:32:04.847122  2318 solver.cpp:253]     Train net output #0: loss = 0.997033 (* 1 = 0.997033 loss)
I0525 20:32:04.847136  2318 sgd_solver.cpp:106] Iteration 59100, lr = 0.003
I0525 20:32:13.587173  2318 solver.cpp:237] Iteration 59250, loss = 0.884804
I0525 20:32:13.587222  2318 solver.cpp:253]     Train net output #0: loss = 0.884804 (* 1 = 0.884804 loss)
I0525 20:32:13.587239  2318 sgd_solver.cpp:106] Iteration 59250, lr = 0.003
I0525 20:32:22.326331  2318 solver.cpp:237] Iteration 59400, loss = 1.09379
I0525 20:32:22.326367  2318 solver.cpp:253]     Train net output #0: loss = 1.09379 (* 1 = 1.09379 loss)
I0525 20:32:22.326385  2318 sgd_solver.cpp:106] Iteration 59400, lr = 0.003
I0525 20:32:31.064769  2318 solver.cpp:237] Iteration 59550, loss = 1.29557
I0525 20:32:31.064803  2318 solver.cpp:253]     Train net output #0: loss = 1.29557 (* 1 = 1.29557 loss)
I0525 20:32:31.064821  2318 sgd_solver.cpp:106] Iteration 59550, lr = 0.003
I0525 20:32:39.803189  2318 solver.cpp:237] Iteration 59700, loss = 1.2144
I0525 20:32:39.803372  2318 solver.cpp:253]     Train net output #0: loss = 1.2144 (* 1 = 1.2144 loss)
I0525 20:32:39.803385  2318 sgd_solver.cpp:106] Iteration 59700, lr = 0.003
I0525 20:32:48.546010  2318 solver.cpp:237] Iteration 59850, loss = 1.16029
I0525 20:32:48.546044  2318 solver.cpp:253]     Train net output #0: loss = 1.16029 (* 1 = 1.16029 loss)
I0525 20:32:48.546061  2318 sgd_solver.cpp:106] Iteration 59850, lr = 0.003
I0525 20:32:57.225328  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_60000.caffemodel
I0525 20:32:57.306391  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_60000.solverstate
I0525 20:32:57.334434  2318 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 20:34:05.105118  2318 solver.cpp:409]     Test net output #0: accuracy = 0.886956
I0525 20:34:05.105309  2318 solver.cpp:409]     Test net output #1: loss = 0.376364 (* 1 = 0.376364 loss)
I0525 20:34:26.019132  2318 solver.cpp:237] Iteration 60000, loss = 1.10777
I0525 20:34:26.019186  2318 solver.cpp:253]     Train net output #0: loss = 1.10777 (* 1 = 1.10777 loss)
I0525 20:34:26.019201  2318 sgd_solver.cpp:106] Iteration 60000, lr = 0.003
I0525 20:34:34.747931  2318 solver.cpp:237] Iteration 60150, loss = 1.15625
I0525 20:34:34.747967  2318 solver.cpp:253]     Train net output #0: loss = 1.15625 (* 1 = 1.15625 loss)
I0525 20:34:34.747983  2318 sgd_solver.cpp:106] Iteration 60150, lr = 0.003
I0525 20:34:43.475462  2318 solver.cpp:237] Iteration 60300, loss = 1.16038
I0525 20:34:43.475647  2318 solver.cpp:253]     Train net output #0: loss = 1.16038 (* 1 = 1.16038 loss)
I0525 20:34:43.475662  2318 sgd_solver.cpp:106] Iteration 60300, lr = 0.003
I0525 20:34:52.206022  2318 solver.cpp:237] Iteration 60450, loss = 1.07431
I0525 20:34:52.206058  2318 solver.cpp:253]     Train net output #0: loss = 1.07431 (* 1 = 1.07431 loss)
I0525 20:34:52.206074  2318 sgd_solver.cpp:106] Iteration 60450, lr = 0.003
I0525 20:35:00.938019  2318 solver.cpp:237] Iteration 60600, loss = 1.0303
I0525 20:35:00.938053  2318 solver.cpp:253]     Train net output #0: loss = 1.0303 (* 1 = 1.0303 loss)
I0525 20:35:00.938071  2318 sgd_solver.cpp:106] Iteration 60600, lr = 0.003
I0525 20:35:09.669533  2318 solver.cpp:237] Iteration 60750, loss = 1.1032
I0525 20:35:09.669577  2318 solver.cpp:253]     Train net output #0: loss = 1.1032 (* 1 = 1.1032 loss)
I0525 20:35:09.669592  2318 sgd_solver.cpp:106] Iteration 60750, lr = 0.003
I0525 20:35:18.399454  2318 solver.cpp:237] Iteration 60900, loss = 1.0369
I0525 20:35:18.399642  2318 solver.cpp:253]     Train net output #0: loss = 1.0369 (* 1 = 1.0369 loss)
I0525 20:35:18.399657  2318 sgd_solver.cpp:106] Iteration 60900, lr = 0.003
I0525 20:35:48.054232  2318 solver.cpp:237] Iteration 61050, loss = 1.13307
I0525 20:35:48.054285  2318 solver.cpp:253]     Train net output #0: loss = 1.13307 (* 1 = 1.13307 loss)
I0525 20:35:48.054299  2318 sgd_solver.cpp:106] Iteration 61050, lr = 0.003
I0525 20:35:56.785697  2318 solver.cpp:237] Iteration 61200, loss = 0.928557
I0525 20:35:56.785892  2318 solver.cpp:253]     Train net output #0: loss = 0.928557 (* 1 = 0.928557 loss)
I0525 20:35:56.785905  2318 sgd_solver.cpp:106] Iteration 61200, lr = 0.003
I0525 20:36:05.516546  2318 solver.cpp:237] Iteration 61350, loss = 1.26913
I0525 20:36:05.516587  2318 solver.cpp:253]     Train net output #0: loss = 1.26913 (* 1 = 1.26913 loss)
I0525 20:36:05.516607  2318 sgd_solver.cpp:106] Iteration 61350, lr = 0.003
I0525 20:36:14.188678  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_61500.caffemodel
I0525 20:36:14.267283  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_61500.solverstate
I0525 20:36:14.311403  2318 solver.cpp:237] Iteration 61500, loss = 1.12172
I0525 20:36:14.311446  2318 solver.cpp:253]     Train net output #0: loss = 1.12172 (* 1 = 1.12172 loss)
I0525 20:36:14.311465  2318 sgd_solver.cpp:106] Iteration 61500, lr = 0.003
I0525 20:36:23.045573  2318 solver.cpp:237] Iteration 61650, loss = 1.15094
I0525 20:36:23.045608  2318 solver.cpp:253]     Train net output #0: loss = 1.15094 (* 1 = 1.15094 loss)
I0525 20:36:23.045624  2318 sgd_solver.cpp:106] Iteration 61650, lr = 0.003
I0525 20:36:31.770023  2318 solver.cpp:237] Iteration 61800, loss = 1.06169
I0525 20:36:31.770208  2318 solver.cpp:253]     Train net output #0: loss = 1.06169 (* 1 = 1.06169 loss)
I0525 20:36:31.770221  2318 sgd_solver.cpp:106] Iteration 61800, lr = 0.003
I0525 20:36:40.497808  2318 solver.cpp:237] Iteration 61950, loss = 1.13476
I0525 20:36:40.497843  2318 solver.cpp:253]     Train net output #0: loss = 1.13476 (* 1 = 1.13476 loss)
I0525 20:36:40.497859  2318 sgd_solver.cpp:106] Iteration 61950, lr = 0.003
I0525 20:37:10.053403  2318 solver.cpp:237] Iteration 62100, loss = 0.992519
I0525 20:37:10.053596  2318 solver.cpp:253]     Train net output #0: loss = 0.992519 (* 1 = 0.992519 loss)
I0525 20:37:10.053608  2318 sgd_solver.cpp:106] Iteration 62100, lr = 0.003
I0525 20:37:18.783498  2318 solver.cpp:237] Iteration 62250, loss = 1.22593
I0525 20:37:18.783546  2318 solver.cpp:253]     Train net output #0: loss = 1.22593 (* 1 = 1.22593 loss)
I0525 20:37:18.783560  2318 sgd_solver.cpp:106] Iteration 62250, lr = 0.003
I0525 20:37:27.504870  2318 solver.cpp:237] Iteration 62400, loss = 1.32231
I0525 20:37:27.504905  2318 solver.cpp:253]     Train net output #0: loss = 1.32231 (* 1 = 1.32231 loss)
I0525 20:37:27.504921  2318 sgd_solver.cpp:106] Iteration 62400, lr = 0.003
I0525 20:37:36.233140  2318 solver.cpp:237] Iteration 62550, loss = 1.06531
I0525 20:37:36.233176  2318 solver.cpp:253]     Train net output #0: loss = 1.06531 (* 1 = 1.06531 loss)
I0525 20:37:36.233191  2318 sgd_solver.cpp:106] Iteration 62550, lr = 0.003
I0525 20:37:44.963131  2318 solver.cpp:237] Iteration 62700, loss = 1.0935
I0525 20:37:44.963325  2318 solver.cpp:253]     Train net output #0: loss = 1.0935 (* 1 = 1.0935 loss)
I0525 20:37:44.963338  2318 sgd_solver.cpp:106] Iteration 62700, lr = 0.003
I0525 20:37:53.687940  2318 solver.cpp:237] Iteration 62850, loss = 1.26425
I0525 20:37:53.687974  2318 solver.cpp:253]     Train net output #0: loss = 1.26425 (* 1 = 1.26425 loss)
I0525 20:37:53.687989  2318 sgd_solver.cpp:106] Iteration 62850, lr = 0.003
I0525 20:38:02.351106  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_63000.caffemodel
I0525 20:38:02.429579  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_63000.solverstate
I0525 20:38:02.455402  2318 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 20:38:49.287761  2318 solver.cpp:409]     Test net output #0: accuracy = 0.890495
I0525 20:38:49.287953  2318 solver.cpp:409]     Test net output #1: loss = 0.339868 (* 1 = 0.339868 loss)
I0525 20:39:10.177423  2318 solver.cpp:237] Iteration 63000, loss = 0.957493
I0525 20:39:10.177476  2318 solver.cpp:253]     Train net output #0: loss = 0.957493 (* 1 = 0.957493 loss)
I0525 20:39:10.177492  2318 sgd_solver.cpp:106] Iteration 63000, lr = 0.003
I0525 20:39:18.915339  2318 solver.cpp:237] Iteration 63150, loss = 1.1952
I0525 20:39:18.915385  2318 solver.cpp:253]     Train net output #0: loss = 1.1952 (* 1 = 1.1952 loss)
I0525 20:39:18.915400  2318 sgd_solver.cpp:106] Iteration 63150, lr = 0.003
I0525 20:39:27.653796  2318 solver.cpp:237] Iteration 63300, loss = 1.23531
I0525 20:39:27.653971  2318 solver.cpp:253]     Train net output #0: loss = 1.23531 (* 1 = 1.23531 loss)
I0525 20:39:27.653985  2318 sgd_solver.cpp:106] Iteration 63300, lr = 0.003
I0525 20:39:36.393033  2318 solver.cpp:237] Iteration 63450, loss = 1.12764
I0525 20:39:36.393067  2318 solver.cpp:253]     Train net output #0: loss = 1.12764 (* 1 = 1.12764 loss)
I0525 20:39:36.393082  2318 sgd_solver.cpp:106] Iteration 63450, lr = 0.003
I0525 20:39:45.133599  2318 solver.cpp:237] Iteration 63600, loss = 1.23374
I0525 20:39:45.133642  2318 solver.cpp:253]     Train net output #0: loss = 1.23374 (* 1 = 1.23374 loss)
I0525 20:39:45.133664  2318 sgd_solver.cpp:106] Iteration 63600, lr = 0.003
I0525 20:39:53.875408  2318 solver.cpp:237] Iteration 63750, loss = 1.19437
I0525 20:39:53.875444  2318 solver.cpp:253]     Train net output #0: loss = 1.19437 (* 1 = 1.19437 loss)
I0525 20:39:53.875458  2318 sgd_solver.cpp:106] Iteration 63750, lr = 0.003
I0525 20:40:02.614056  2318 solver.cpp:237] Iteration 63900, loss = 0.882148
I0525 20:40:02.614240  2318 solver.cpp:253]     Train net output #0: loss = 0.882148 (* 1 = 0.882148 loss)
I0525 20:40:02.614253  2318 sgd_solver.cpp:106] Iteration 63900, lr = 0.003
I0525 20:40:32.240466  2318 solver.cpp:237] Iteration 64050, loss = 1.14083
I0525 20:40:32.240515  2318 solver.cpp:253]     Train net output #0: loss = 1.14083 (* 1 = 1.14083 loss)
I0525 20:40:32.240531  2318 sgd_solver.cpp:106] Iteration 64050, lr = 0.003
I0525 20:40:40.981514  2318 solver.cpp:237] Iteration 64200, loss = 1.1003
I0525 20:40:40.981694  2318 solver.cpp:253]     Train net output #0: loss = 1.1003 (* 1 = 1.1003 loss)
I0525 20:40:40.981709  2318 sgd_solver.cpp:106] Iteration 64200, lr = 0.003
I0525 20:40:49.718459  2318 solver.cpp:237] Iteration 64350, loss = 1.25269
I0525 20:40:49.718494  2318 solver.cpp:253]     Train net output #0: loss = 1.25269 (* 1 = 1.25269 loss)
I0525 20:40:49.718509  2318 sgd_solver.cpp:106] Iteration 64350, lr = 0.003
I0525 20:40:58.403146  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_64500.caffemodel
I0525 20:40:58.481672  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_64500.solverstate
I0525 20:40:58.525480  2318 solver.cpp:237] Iteration 64500, loss = 1.08184
I0525 20:40:58.525527  2318 solver.cpp:253]     Train net output #0: loss = 1.08184 (* 1 = 1.08184 loss)
I0525 20:40:58.525543  2318 sgd_solver.cpp:106] Iteration 64500, lr = 0.003
I0525 20:41:07.263010  2318 solver.cpp:237] Iteration 64650, loss = 1.22876
I0525 20:41:07.263046  2318 solver.cpp:253]     Train net output #0: loss = 1.22876 (* 1 = 1.22876 loss)
I0525 20:41:07.263061  2318 sgd_solver.cpp:106] Iteration 64650, lr = 0.003
I0525 20:41:16.004686  2318 solver.cpp:237] Iteration 64800, loss = 1.10656
I0525 20:41:16.004868  2318 solver.cpp:253]     Train net output #0: loss = 1.10656 (* 1 = 1.10656 loss)
I0525 20:41:16.004883  2318 sgd_solver.cpp:106] Iteration 64800, lr = 0.003
I0525 20:41:24.739720  2318 solver.cpp:237] Iteration 64950, loss = 1.02622
I0525 20:41:24.739763  2318 solver.cpp:253]     Train net output #0: loss = 1.02622 (* 1 = 1.02622 loss)
I0525 20:41:24.739779  2318 sgd_solver.cpp:106] Iteration 64950, lr = 0.003
I0525 20:41:54.385926  2318 solver.cpp:237] Iteration 65100, loss = 1.21238
I0525 20:41:54.386135  2318 solver.cpp:253]     Train net output #0: loss = 1.21238 (* 1 = 1.21238 loss)
I0525 20:41:54.386149  2318 sgd_solver.cpp:106] Iteration 65100, lr = 0.003
I0525 20:42:03.127228  2318 solver.cpp:237] Iteration 65250, loss = 1.24289
I0525 20:42:03.127262  2318 solver.cpp:253]     Train net output #0: loss = 1.24289 (* 1 = 1.24289 loss)
I0525 20:42:03.127277  2318 sgd_solver.cpp:106] Iteration 65250, lr = 0.003
I0525 20:42:11.867835  2318 solver.cpp:237] Iteration 65400, loss = 1.21322
I0525 20:42:11.867869  2318 solver.cpp:253]     Train net output #0: loss = 1.21322 (* 1 = 1.21322 loss)
I0525 20:42:11.867883  2318 sgd_solver.cpp:106] Iteration 65400, lr = 0.003
I0525 20:42:20.606751  2318 solver.cpp:237] Iteration 65550, loss = 1.10037
I0525 20:42:20.606791  2318 solver.cpp:253]     Train net output #0: loss = 1.10037 (* 1 = 1.10037 loss)
I0525 20:42:20.606811  2318 sgd_solver.cpp:106] Iteration 65550, lr = 0.003
I0525 20:42:29.348104  2318 solver.cpp:237] Iteration 65700, loss = 1.37672
I0525 20:42:29.348274  2318 solver.cpp:253]     Train net output #0: loss = 1.37672 (* 1 = 1.37672 loss)
I0525 20:42:29.348286  2318 sgd_solver.cpp:106] Iteration 65700, lr = 0.003
I0525 20:42:38.085855  2318 solver.cpp:237] Iteration 65850, loss = 1.23245
I0525 20:42:38.085889  2318 solver.cpp:253]     Train net output #0: loss = 1.23245 (* 1 = 1.23245 loss)
I0525 20:42:38.085906  2318 sgd_solver.cpp:106] Iteration 65850, lr = 0.003
I0525 20:42:46.767496  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_66000.caffemodel
I0525 20:42:46.848372  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_66000.solverstate
I0525 20:42:46.875591  2318 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 20:43:54.650948  2318 solver.cpp:409]     Test net output #0: accuracy = 0.891221
I0525 20:43:54.651146  2318 solver.cpp:409]     Test net output #1: loss = 0.388504 (* 1 = 0.388504 loss)
I0525 20:44:15.558698  2318 solver.cpp:237] Iteration 66000, loss = 1.2441
I0525 20:44:15.558751  2318 solver.cpp:253]     Train net output #0: loss = 1.2441 (* 1 = 1.2441 loss)
I0525 20:44:15.558766  2318 sgd_solver.cpp:106] Iteration 66000, lr = 0.003
I0525 20:44:24.291527  2318 solver.cpp:237] Iteration 66150, loss = 1.26725
I0525 20:44:24.291565  2318 solver.cpp:253]     Train net output #0: loss = 1.26725 (* 1 = 1.26725 loss)
I0525 20:44:24.291584  2318 sgd_solver.cpp:106] Iteration 66150, lr = 0.003
I0525 20:44:33.028102  2318 solver.cpp:237] Iteration 66300, loss = 1.12802
I0525 20:44:33.028291  2318 solver.cpp:253]     Train net output #0: loss = 1.12802 (* 1 = 1.12802 loss)
I0525 20:44:33.028306  2318 sgd_solver.cpp:106] Iteration 66300, lr = 0.003
I0525 20:44:41.757555  2318 solver.cpp:237] Iteration 66450, loss = 1.33463
I0525 20:44:41.757591  2318 solver.cpp:253]     Train net output #0: loss = 1.33463 (* 1 = 1.33463 loss)
I0525 20:44:41.757604  2318 sgd_solver.cpp:106] Iteration 66450, lr = 0.003
I0525 20:44:50.489869  2318 solver.cpp:237] Iteration 66600, loss = 1.09633
I0525 20:44:50.489908  2318 solver.cpp:253]     Train net output #0: loss = 1.09633 (* 1 = 1.09633 loss)
I0525 20:44:50.489922  2318 sgd_solver.cpp:106] Iteration 66600, lr = 0.003
I0525 20:44:59.220662  2318 solver.cpp:237] Iteration 66750, loss = 1.16245
I0525 20:44:59.220698  2318 solver.cpp:253]     Train net output #0: loss = 1.16245 (* 1 = 1.16245 loss)
I0525 20:44:59.220713  2318 sgd_solver.cpp:106] Iteration 66750, lr = 0.003
I0525 20:45:07.950628  2318 solver.cpp:237] Iteration 66900, loss = 0.993562
I0525 20:45:07.950806  2318 solver.cpp:253]     Train net output #0: loss = 0.993562 (* 1 = 0.993562 loss)
I0525 20:45:07.950819  2318 sgd_solver.cpp:106] Iteration 66900, lr = 0.003
I0525 20:45:37.605221  2318 solver.cpp:237] Iteration 67050, loss = 1.11046
I0525 20:45:37.605271  2318 solver.cpp:253]     Train net output #0: loss = 1.11046 (* 1 = 1.11046 loss)
I0525 20:45:37.605286  2318 sgd_solver.cpp:106] Iteration 67050, lr = 0.003
I0525 20:45:46.334230  2318 solver.cpp:237] Iteration 67200, loss = 1.19469
I0525 20:45:46.334409  2318 solver.cpp:253]     Train net output #0: loss = 1.19469 (* 1 = 1.19469 loss)
I0525 20:45:46.334424  2318 sgd_solver.cpp:106] Iteration 67200, lr = 0.003
I0525 20:45:55.061991  2318 solver.cpp:237] Iteration 67350, loss = 1.23509
I0525 20:45:55.062026  2318 solver.cpp:253]     Train net output #0: loss = 1.23509 (* 1 = 1.23509 loss)
I0525 20:45:55.062041  2318 sgd_solver.cpp:106] Iteration 67350, lr = 0.003
I0525 20:46:03.732355  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_67500.caffemodel
I0525 20:46:03.813168  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_67500.solverstate
I0525 20:46:03.860525  2318 solver.cpp:237] Iteration 67500, loss = 1.27123
I0525 20:46:03.860572  2318 solver.cpp:253]     Train net output #0: loss = 1.27123 (* 1 = 1.27123 loss)
I0525 20:46:03.860591  2318 sgd_solver.cpp:106] Iteration 67500, lr = 0.003
I0525 20:46:12.589231  2318 solver.cpp:237] Iteration 67650, loss = 1.16151
I0525 20:46:12.589265  2318 solver.cpp:253]     Train net output #0: loss = 1.16151 (* 1 = 1.16151 loss)
I0525 20:46:12.589279  2318 sgd_solver.cpp:106] Iteration 67650, lr = 0.003
I0525 20:46:21.320168  2318 solver.cpp:237] Iteration 67800, loss = 1.209
I0525 20:46:21.320346  2318 solver.cpp:253]     Train net output #0: loss = 1.209 (* 1 = 1.209 loss)
I0525 20:46:21.320360  2318 sgd_solver.cpp:106] Iteration 67800, lr = 0.003
I0525 20:46:30.055271  2318 solver.cpp:237] Iteration 67950, loss = 1.2118
I0525 20:46:30.055320  2318 solver.cpp:253]     Train net output #0: loss = 1.2118 (* 1 = 1.2118 loss)
I0525 20:46:30.055337  2318 sgd_solver.cpp:106] Iteration 67950, lr = 0.003
I0525 20:46:59.683507  2318 solver.cpp:237] Iteration 68100, loss = 1.2748
I0525 20:46:59.683706  2318 solver.cpp:253]     Train net output #0: loss = 1.2748 (* 1 = 1.2748 loss)
I0525 20:46:59.683719  2318 sgd_solver.cpp:106] Iteration 68100, lr = 0.003
I0525 20:47:08.414484  2318 solver.cpp:237] Iteration 68250, loss = 1.15877
I0525 20:47:08.414520  2318 solver.cpp:253]     Train net output #0: loss = 1.15877 (* 1 = 1.15877 loss)
I0525 20:47:08.414535  2318 sgd_solver.cpp:106] Iteration 68250, lr = 0.003
I0525 20:47:17.144618  2318 solver.cpp:237] Iteration 68400, loss = 1.14486
I0525 20:47:17.144664  2318 solver.cpp:253]     Train net output #0: loss = 1.14486 (* 1 = 1.14486 loss)
I0525 20:47:17.144680  2318 sgd_solver.cpp:106] Iteration 68400, lr = 0.003
I0525 20:47:25.876636  2318 solver.cpp:237] Iteration 68550, loss = 1.23727
I0525 20:47:25.876670  2318 solver.cpp:253]     Train net output #0: loss = 1.23727 (* 1 = 1.23727 loss)
I0525 20:47:25.876687  2318 sgd_solver.cpp:106] Iteration 68550, lr = 0.003
I0525 20:47:34.608319  2318 solver.cpp:237] Iteration 68700, loss = 1.42615
I0525 20:47:34.608513  2318 solver.cpp:253]     Train net output #0: loss = 1.42615 (* 1 = 1.42615 loss)
I0525 20:47:34.608527  2318 sgd_solver.cpp:106] Iteration 68700, lr = 0.003
I0525 20:47:43.340160  2318 solver.cpp:237] Iteration 68850, loss = 1.03339
I0525 20:47:43.340206  2318 solver.cpp:253]     Train net output #0: loss = 1.03339 (* 1 = 1.03339 loss)
I0525 20:47:43.340221  2318 sgd_solver.cpp:106] Iteration 68850, lr = 0.003
I0525 20:47:52.012758  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_69000.caffemodel
I0525 20:47:52.091398  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_69000.solverstate
I0525 20:47:52.116873  2318 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 20:48:38.669724  2318 solver.cpp:409]     Test net output #0: accuracy = 0.895122
I0525 20:48:38.669929  2318 solver.cpp:409]     Test net output #1: loss = 0.331411 (* 1 = 0.331411 loss)
I0525 20:48:59.565441  2318 solver.cpp:237] Iteration 69000, loss = 1.10715
I0525 20:48:59.565495  2318 solver.cpp:253]     Train net output #0: loss = 1.10715 (* 1 = 1.10715 loss)
I0525 20:48:59.565510  2318 sgd_solver.cpp:106] Iteration 69000, lr = 0.003
I0525 20:49:08.304888  2318 solver.cpp:237] Iteration 69150, loss = 1.11832
I0525 20:49:08.304924  2318 solver.cpp:253]     Train net output #0: loss = 1.11832 (* 1 = 1.11832 loss)
I0525 20:49:08.304939  2318 sgd_solver.cpp:106] Iteration 69150, lr = 0.003
I0525 20:49:17.044338  2318 solver.cpp:237] Iteration 69300, loss = 1.09941
I0525 20:49:17.044520  2318 solver.cpp:253]     Train net output #0: loss = 1.09941 (* 1 = 1.09941 loss)
I0525 20:49:17.044534  2318 sgd_solver.cpp:106] Iteration 69300, lr = 0.003
I0525 20:49:25.785341  2318 solver.cpp:237] Iteration 69450, loss = 1.11162
I0525 20:49:25.785380  2318 solver.cpp:253]     Train net output #0: loss = 1.11162 (* 1 = 1.11162 loss)
I0525 20:49:25.785393  2318 sgd_solver.cpp:106] Iteration 69450, lr = 0.003
I0525 20:49:34.527878  2318 solver.cpp:237] Iteration 69600, loss = 1.21024
I0525 20:49:34.527915  2318 solver.cpp:253]     Train net output #0: loss = 1.21024 (* 1 = 1.21024 loss)
I0525 20:49:34.527928  2318 sgd_solver.cpp:106] Iteration 69600, lr = 0.003
I0525 20:49:43.268968  2318 solver.cpp:237] Iteration 69750, loss = 1.08607
I0525 20:49:43.269002  2318 solver.cpp:253]     Train net output #0: loss = 1.08607 (* 1 = 1.08607 loss)
I0525 20:49:43.269017  2318 sgd_solver.cpp:106] Iteration 69750, lr = 0.003
I0525 20:49:52.006852  2318 solver.cpp:237] Iteration 69900, loss = 1.21926
I0525 20:49:52.007050  2318 solver.cpp:253]     Train net output #0: loss = 1.21926 (* 1 = 1.21926 loss)
I0525 20:49:52.007064  2318 sgd_solver.cpp:106] Iteration 69900, lr = 0.003
I0525 20:50:21.608207  2318 solver.cpp:237] Iteration 70050, loss = 1.28987
I0525 20:50:21.608258  2318 solver.cpp:253]     Train net output #0: loss = 1.28987 (* 1 = 1.28987 loss)
I0525 20:50:21.608273  2318 sgd_solver.cpp:106] Iteration 70050, lr = 0.003
I0525 20:50:30.353519  2318 solver.cpp:237] Iteration 70200, loss = 1.18074
I0525 20:50:30.353701  2318 solver.cpp:253]     Train net output #0: loss = 1.18074 (* 1 = 1.18074 loss)
I0525 20:50:30.353714  2318 sgd_solver.cpp:106] Iteration 70200, lr = 0.003
I0525 20:50:39.093797  2318 solver.cpp:237] Iteration 70350, loss = 1.12634
I0525 20:50:39.093844  2318 solver.cpp:253]     Train net output #0: loss = 1.12634 (* 1 = 1.12634 loss)
I0525 20:50:39.093861  2318 sgd_solver.cpp:106] Iteration 70350, lr = 0.003
I0525 20:50:47.771008  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_70500.caffemodel
I0525 20:50:47.849108  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_70500.solverstate
I0525 20:50:47.892776  2318 solver.cpp:237] Iteration 70500, loss = 1.16389
I0525 20:50:47.892822  2318 solver.cpp:253]     Train net output #0: loss = 1.16389 (* 1 = 1.16389 loss)
I0525 20:50:47.892838  2318 sgd_solver.cpp:106] Iteration 70500, lr = 0.003
I0525 20:50:56.632745  2318 solver.cpp:237] Iteration 70650, loss = 1.13894
I0525 20:50:56.632779  2318 solver.cpp:253]     Train net output #0: loss = 1.13894 (* 1 = 1.13894 loss)
I0525 20:50:56.632793  2318 sgd_solver.cpp:106] Iteration 70650, lr = 0.003
I0525 20:51:05.370167  2318 solver.cpp:237] Iteration 70800, loss = 1.13537
I0525 20:51:05.370378  2318 solver.cpp:253]     Train net output #0: loss = 1.13537 (* 1 = 1.13537 loss)
I0525 20:51:05.370393  2318 sgd_solver.cpp:106] Iteration 70800, lr = 0.003
I0525 20:51:14.109855  2318 solver.cpp:237] Iteration 70950, loss = 1.0808
I0525 20:51:14.109889  2318 solver.cpp:253]     Train net output #0: loss = 1.0808 (* 1 = 1.0808 loss)
I0525 20:51:14.109905  2318 sgd_solver.cpp:106] Iteration 70950, lr = 0.003
I0525 20:51:43.746289  2318 solver.cpp:237] Iteration 71100, loss = 1.12676
I0525 20:51:43.746490  2318 solver.cpp:253]     Train net output #0: loss = 1.12676 (* 1 = 1.12676 loss)
I0525 20:51:43.746503  2318 sgd_solver.cpp:106] Iteration 71100, lr = 0.003
I0525 20:51:52.485682  2318 solver.cpp:237] Iteration 71250, loss = 1.36423
I0525 20:51:52.485729  2318 solver.cpp:253]     Train net output #0: loss = 1.36423 (* 1 = 1.36423 loss)
I0525 20:51:52.485746  2318 sgd_solver.cpp:106] Iteration 71250, lr = 0.003
I0525 20:52:01.223959  2318 solver.cpp:237] Iteration 71400, loss = 1.15699
I0525 20:52:01.223996  2318 solver.cpp:253]     Train net output #0: loss = 1.15699 (* 1 = 1.15699 loss)
I0525 20:52:01.224010  2318 sgd_solver.cpp:106] Iteration 71400, lr = 0.003
I0525 20:52:09.965538  2318 solver.cpp:237] Iteration 71550, loss = 1.2273
I0525 20:52:09.965574  2318 solver.cpp:253]     Train net output #0: loss = 1.2273 (* 1 = 1.2273 loss)
I0525 20:52:09.965587  2318 sgd_solver.cpp:106] Iteration 71550, lr = 0.003
I0525 20:52:18.708848  2318 solver.cpp:237] Iteration 71700, loss = 1.23975
I0525 20:52:18.709036  2318 solver.cpp:253]     Train net output #0: loss = 1.23975 (* 1 = 1.23975 loss)
I0525 20:52:18.709050  2318 sgd_solver.cpp:106] Iteration 71700, lr = 0.003
I0525 20:52:27.445348  2318 solver.cpp:237] Iteration 71850, loss = 1.05601
I0525 20:52:27.445384  2318 solver.cpp:253]     Train net output #0: loss = 1.05601 (* 1 = 1.05601 loss)
I0525 20:52:27.445399  2318 sgd_solver.cpp:106] Iteration 71850, lr = 0.003
I0525 20:52:36.124572  2318 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_72000.caffemodel
I0525 20:52:36.203199  2318 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0030_2016-05-20T15.49.25.861282_iter_72000.solverstate
I0525 20:52:36.228423  2318 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 20:53:43.972010  2318 solver.cpp:409]     Test net output #0: accuracy = 0.895788
I0525 20:53:43.972213  2318 solver.cpp:409]     Test net output #1: loss = 0.335688 (* 1 = 0.335688 loss)
I0525 20:54:04.878453  2318 solver.cpp:237] Iteration 72000, loss = 1.30564
I0525 20:54:04.878504  2318 solver.cpp:253]     Train net output #0: loss = 1.30564 (* 1 = 1.30564 loss)
I0525 20:54:04.878520  2318 sgd_solver.cpp:106] Iteration 72000, lr = 0.003
I0525 20:54:13.607372  2318 solver.cpp:237] Iteration 72150, loss = 1.10234
I0525 20:54:13.607408  2318 solver.cpp:253]     Train net output #0: loss = 1.10234 (* 1 = 1.10234 loss)
I0525 20:54:13.607422  2318 sgd_solver.cpp:106] Iteration 72150, lr = 0.003
I0525 20:54:22.334738  2318 solver.cpp:237] Iteration 72300, loss = 1.03627
I0525 20:54:22.334942  2318 solver.cpp:253]     Train net output #0: loss = 1.03627 (* 1 = 1.03627 loss)
I0525 20:54:22.334956  2318 sgd_solver.cpp:106] Iteration 72300, lr = 0.003
aprun: Apid 11265512: Caught signal Terminated, sending to application
*** Aborted at 1464224065 (unix time) try "date -d @1464224065" if you are using GNU date ***
aprun: Apid 11265512: Caught signal Terminated, sending to application
aprun: Apid 11265512: Caught signal Terminated, sending to application
PC: @     0x2aaab9276640 (unknown)
*** SIGTERM (@0x90b) received by PID 2318 (TID 0x2aaac746f900) from PID 2315; stack trace: ***
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab9276640 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
=>> PBS: job killed: walltime 7220 exceeded limit 7200
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab928a3b8 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
aprun: Apid 11265512: Caught signal Terminated, sending to application
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11265512: Caught signal Terminated, sending to application
