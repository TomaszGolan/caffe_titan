2811277
I0526 02:58:56.781211 27450 caffe.cpp:184] Using GPUs 0
I0526 02:58:57.208391 27450 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0005
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163.prototxt"
I0526 02:58:57.210476 27450 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163.prototxt
I0526 02:58:57.218433 27450 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 02:58:57.218497 27450 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 02:58:57.218874 27450 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 02:58:57.219079 27450 layer_factory.hpp:77] Creating layer data_hdf5
I0526 02:58:57.219107 27450 net.cpp:106] Creating Layer data_hdf5
I0526 02:58:57.219130 27450 net.cpp:411] data_hdf5 -> data
I0526 02:58:57.219164 27450 net.cpp:411] data_hdf5 -> label
I0526 02:58:57.219202 27450 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 02:58:57.231899 27450 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 02:58:57.249451 27450 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 02:59:18.852133 27450 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 02:59:18.857372 27450 net.cpp:150] Setting up data_hdf5
I0526 02:59:18.857414 27450 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 02:59:18.857430 27450 net.cpp:157] Top shape: 10 (10)
I0526 02:59:18.857444 27450 net.cpp:165] Memory required for data: 254040
I0526 02:59:18.857462 27450 layer_factory.hpp:77] Creating layer conv1
I0526 02:59:18.857508 27450 net.cpp:106] Creating Layer conv1
I0526 02:59:18.857522 27450 net.cpp:454] conv1 <- data
I0526 02:59:18.857547 27450 net.cpp:411] conv1 -> conv1
I0526 02:59:19.913246 27450 net.cpp:150] Setting up conv1
I0526 02:59:19.913296 27450 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 02:59:19.913322 27450 net.cpp:165] Memory required for data: 3018840
I0526 02:59:19.913353 27450 layer_factory.hpp:77] Creating layer relu1
I0526 02:59:19.913375 27450 net.cpp:106] Creating Layer relu1
I0526 02:59:19.913395 27450 net.cpp:454] relu1 <- conv1
I0526 02:59:19.913431 27450 net.cpp:397] relu1 -> conv1 (in-place)
I0526 02:59:19.913967 27450 net.cpp:150] Setting up relu1
I0526 02:59:19.913990 27450 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 02:59:19.914003 27450 net.cpp:165] Memory required for data: 5783640
I0526 02:59:19.914021 27450 layer_factory.hpp:77] Creating layer pool1
I0526 02:59:19.914048 27450 net.cpp:106] Creating Layer pool1
I0526 02:59:19.914062 27450 net.cpp:454] pool1 <- conv1
I0526 02:59:19.914077 27450 net.cpp:411] pool1 -> pool1
I0526 02:59:19.914171 27450 net.cpp:150] Setting up pool1
I0526 02:59:19.914189 27450 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 02:59:19.914211 27450 net.cpp:165] Memory required for data: 7166040
I0526 02:59:19.914223 27450 layer_factory.hpp:77] Creating layer conv2
I0526 02:59:19.914247 27450 net.cpp:106] Creating Layer conv2
I0526 02:59:19.914260 27450 net.cpp:454] conv2 <- pool1
I0526 02:59:19.914280 27450 net.cpp:411] conv2 -> conv2
I0526 02:59:19.916997 27450 net.cpp:150] Setting up conv2
I0526 02:59:19.917028 27450 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 02:59:19.917043 27450 net.cpp:165] Memory required for data: 9153240
I0526 02:59:19.917070 27450 layer_factory.hpp:77] Creating layer relu2
I0526 02:59:19.917098 27450 net.cpp:106] Creating Layer relu2
I0526 02:59:19.917112 27450 net.cpp:454] relu2 <- conv2
I0526 02:59:19.917129 27450 net.cpp:397] relu2 -> conv2 (in-place)
I0526 02:59:19.917484 27450 net.cpp:150] Setting up relu2
I0526 02:59:19.917505 27450 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 02:59:19.917517 27450 net.cpp:165] Memory required for data: 11140440
I0526 02:59:19.917529 27450 layer_factory.hpp:77] Creating layer pool2
I0526 02:59:19.917556 27450 net.cpp:106] Creating Layer pool2
I0526 02:59:19.917568 27450 net.cpp:454] pool2 <- conv2
I0526 02:59:19.917584 27450 net.cpp:411] pool2 -> pool2
I0526 02:59:19.917680 27450 net.cpp:150] Setting up pool2
I0526 02:59:19.917697 27450 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 02:59:19.917711 27450 net.cpp:165] Memory required for data: 12134040
I0526 02:59:19.917731 27450 layer_factory.hpp:77] Creating layer conv3
I0526 02:59:19.917752 27450 net.cpp:106] Creating Layer conv3
I0526 02:59:19.917773 27450 net.cpp:454] conv3 <- pool2
I0526 02:59:19.917789 27450 net.cpp:411] conv3 -> conv3
I0526 02:59:19.919912 27450 net.cpp:150] Setting up conv3
I0526 02:59:19.919939 27450 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 02:59:19.919958 27450 net.cpp:165] Memory required for data: 13218200
I0526 02:59:19.919981 27450 layer_factory.hpp:77] Creating layer relu3
I0526 02:59:19.920003 27450 net.cpp:106] Creating Layer relu3
I0526 02:59:19.920025 27450 net.cpp:454] relu3 <- conv3
I0526 02:59:19.920042 27450 net.cpp:397] relu3 -> conv3 (in-place)
I0526 02:59:19.920536 27450 net.cpp:150] Setting up relu3
I0526 02:59:19.920562 27450 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 02:59:19.920574 27450 net.cpp:165] Memory required for data: 14302360
I0526 02:59:19.920590 27450 layer_factory.hpp:77] Creating layer pool3
I0526 02:59:19.920614 27450 net.cpp:106] Creating Layer pool3
I0526 02:59:19.920629 27450 net.cpp:454] pool3 <- conv3
I0526 02:59:19.920644 27450 net.cpp:411] pool3 -> pool3
I0526 02:59:19.920725 27450 net.cpp:150] Setting up pool3
I0526 02:59:19.920749 27450 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 02:59:19.920763 27450 net.cpp:165] Memory required for data: 14844440
I0526 02:59:19.920773 27450 layer_factory.hpp:77] Creating layer conv4
I0526 02:59:19.920801 27450 net.cpp:106] Creating Layer conv4
I0526 02:59:19.920815 27450 net.cpp:454] conv4 <- pool3
I0526 02:59:19.920831 27450 net.cpp:411] conv4 -> conv4
I0526 02:59:19.923570 27450 net.cpp:150] Setting up conv4
I0526 02:59:19.923602 27450 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 02:59:19.923617 27450 net.cpp:165] Memory required for data: 15207320
I0526 02:59:19.923636 27450 layer_factory.hpp:77] Creating layer relu4
I0526 02:59:19.923657 27450 net.cpp:106] Creating Layer relu4
I0526 02:59:19.923682 27450 net.cpp:454] relu4 <- conv4
I0526 02:59:19.923699 27450 net.cpp:397] relu4 -> conv4 (in-place)
I0526 02:59:19.924198 27450 net.cpp:150] Setting up relu4
I0526 02:59:19.924221 27450 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 02:59:19.924234 27450 net.cpp:165] Memory required for data: 15570200
I0526 02:59:19.924250 27450 layer_factory.hpp:77] Creating layer pool4
I0526 02:59:19.924274 27450 net.cpp:106] Creating Layer pool4
I0526 02:59:19.924288 27450 net.cpp:454] pool4 <- conv4
I0526 02:59:19.924304 27450 net.cpp:411] pool4 -> pool4
I0526 02:59:19.924386 27450 net.cpp:150] Setting up pool4
I0526 02:59:19.924409 27450 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 02:59:19.924424 27450 net.cpp:165] Memory required for data: 15751640
I0526 02:59:19.924437 27450 layer_factory.hpp:77] Creating layer ip1
I0526 02:59:19.924468 27450 net.cpp:106] Creating Layer ip1
I0526 02:59:19.924481 27450 net.cpp:454] ip1 <- pool4
I0526 02:59:19.924497 27450 net.cpp:411] ip1 -> ip1
I0526 02:59:19.939926 27450 net.cpp:150] Setting up ip1
I0526 02:59:19.939963 27450 net.cpp:157] Top shape: 10 196 (1960)
I0526 02:59:19.939977 27450 net.cpp:165] Memory required for data: 15759480
I0526 02:59:19.940007 27450 layer_factory.hpp:77] Creating layer relu5
I0526 02:59:19.940037 27450 net.cpp:106] Creating Layer relu5
I0526 02:59:19.940050 27450 net.cpp:454] relu5 <- ip1
I0526 02:59:19.940068 27450 net.cpp:397] relu5 -> ip1 (in-place)
I0526 02:59:19.940448 27450 net.cpp:150] Setting up relu5
I0526 02:59:19.940467 27450 net.cpp:157] Top shape: 10 196 (1960)
I0526 02:59:19.940479 27450 net.cpp:165] Memory required for data: 15767320
I0526 02:59:19.940492 27450 layer_factory.hpp:77] Creating layer drop1
I0526 02:59:19.940526 27450 net.cpp:106] Creating Layer drop1
I0526 02:59:19.940538 27450 net.cpp:454] drop1 <- ip1
I0526 02:59:19.940554 27450 net.cpp:397] drop1 -> ip1 (in-place)
I0526 02:59:19.940629 27450 net.cpp:150] Setting up drop1
I0526 02:59:19.940644 27450 net.cpp:157] Top shape: 10 196 (1960)
I0526 02:59:19.940657 27450 net.cpp:165] Memory required for data: 15775160
I0526 02:59:19.940672 27450 layer_factory.hpp:77] Creating layer ip2
I0526 02:59:19.940693 27450 net.cpp:106] Creating Layer ip2
I0526 02:59:19.940706 27450 net.cpp:454] ip2 <- ip1
I0526 02:59:19.940728 27450 net.cpp:411] ip2 -> ip2
I0526 02:59:19.941220 27450 net.cpp:150] Setting up ip2
I0526 02:59:19.941238 27450 net.cpp:157] Top shape: 10 98 (980)
I0526 02:59:19.941251 27450 net.cpp:165] Memory required for data: 15779080
I0526 02:59:19.941272 27450 layer_factory.hpp:77] Creating layer relu6
I0526 02:59:19.941293 27450 net.cpp:106] Creating Layer relu6
I0526 02:59:19.941306 27450 net.cpp:454] relu6 <- ip2
I0526 02:59:19.941321 27450 net.cpp:397] relu6 -> ip2 (in-place)
I0526 02:59:19.941867 27450 net.cpp:150] Setting up relu6
I0526 02:59:19.941890 27450 net.cpp:157] Top shape: 10 98 (980)
I0526 02:59:19.941903 27450 net.cpp:165] Memory required for data: 15783000
I0526 02:59:19.941920 27450 layer_factory.hpp:77] Creating layer drop2
I0526 02:59:19.941934 27450 net.cpp:106] Creating Layer drop2
I0526 02:59:19.941956 27450 net.cpp:454] drop2 <- ip2
I0526 02:59:19.941972 27450 net.cpp:397] drop2 -> ip2 (in-place)
I0526 02:59:19.942021 27450 net.cpp:150] Setting up drop2
I0526 02:59:19.942044 27450 net.cpp:157] Top shape: 10 98 (980)
I0526 02:59:19.942056 27450 net.cpp:165] Memory required for data: 15786920
I0526 02:59:19.942075 27450 layer_factory.hpp:77] Creating layer ip3
I0526 02:59:19.942092 27450 net.cpp:106] Creating Layer ip3
I0526 02:59:19.942104 27450 net.cpp:454] ip3 <- ip2
I0526 02:59:19.942122 27450 net.cpp:411] ip3 -> ip3
I0526 02:59:19.942350 27450 net.cpp:150] Setting up ip3
I0526 02:59:19.942369 27450 net.cpp:157] Top shape: 10 11 (110)
I0526 02:59:19.942383 27450 net.cpp:165] Memory required for data: 15787360
I0526 02:59:19.942402 27450 layer_factory.hpp:77] Creating layer drop3
I0526 02:59:19.942425 27450 net.cpp:106] Creating Layer drop3
I0526 02:59:19.942438 27450 net.cpp:454] drop3 <- ip3
I0526 02:59:19.942454 27450 net.cpp:397] drop3 -> ip3 (in-place)
I0526 02:59:19.942500 27450 net.cpp:150] Setting up drop3
I0526 02:59:19.942523 27450 net.cpp:157] Top shape: 10 11 (110)
I0526 02:59:19.942535 27450 net.cpp:165] Memory required for data: 15787800
I0526 02:59:19.942554 27450 layer_factory.hpp:77] Creating layer loss
I0526 02:59:19.942575 27450 net.cpp:106] Creating Layer loss
I0526 02:59:19.942590 27450 net.cpp:454] loss <- ip3
I0526 02:59:19.942611 27450 net.cpp:454] loss <- label
I0526 02:59:19.942627 27450 net.cpp:411] loss -> loss
I0526 02:59:19.942646 27450 layer_factory.hpp:77] Creating layer loss
I0526 02:59:19.943313 27450 net.cpp:150] Setting up loss
I0526 02:59:19.943334 27450 net.cpp:157] Top shape: (1)
I0526 02:59:19.943351 27450 net.cpp:160]     with loss weight 1
I0526 02:59:19.943410 27450 net.cpp:165] Memory required for data: 15787804
I0526 02:59:19.943424 27450 net.cpp:226] loss needs backward computation.
I0526 02:59:19.943439 27450 net.cpp:226] drop3 needs backward computation.
I0526 02:59:19.943450 27450 net.cpp:226] ip3 needs backward computation.
I0526 02:59:19.943464 27450 net.cpp:226] drop2 needs backward computation.
I0526 02:59:19.943475 27450 net.cpp:226] relu6 needs backward computation.
I0526 02:59:19.943490 27450 net.cpp:226] ip2 needs backward computation.
I0526 02:59:19.943509 27450 net.cpp:226] drop1 needs backward computation.
I0526 02:59:19.943523 27450 net.cpp:226] relu5 needs backward computation.
I0526 02:59:19.943536 27450 net.cpp:226] ip1 needs backward computation.
I0526 02:59:19.943550 27450 net.cpp:226] pool4 needs backward computation.
I0526 02:59:19.943563 27450 net.cpp:226] relu4 needs backward computation.
I0526 02:59:19.943578 27450 net.cpp:226] conv4 needs backward computation.
I0526 02:59:19.943590 27450 net.cpp:226] pool3 needs backward computation.
I0526 02:59:19.943610 27450 net.cpp:226] relu3 needs backward computation.
I0526 02:59:19.943624 27450 net.cpp:226] conv3 needs backward computation.
I0526 02:59:19.943645 27450 net.cpp:226] pool2 needs backward computation.
I0526 02:59:19.943658 27450 net.cpp:226] relu2 needs backward computation.
I0526 02:59:19.943673 27450 net.cpp:226] conv2 needs backward computation.
I0526 02:59:19.943692 27450 net.cpp:226] pool1 needs backward computation.
I0526 02:59:19.943706 27450 net.cpp:226] relu1 needs backward computation.
I0526 02:59:19.943719 27450 net.cpp:226] conv1 needs backward computation.
I0526 02:59:19.943737 27450 net.cpp:228] data_hdf5 does not need backward computation.
I0526 02:59:19.943749 27450 net.cpp:270] This network produces output loss
I0526 02:59:19.943778 27450 net.cpp:283] Network initialization done.
I0526 02:59:19.945581 27450 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163.prototxt
I0526 02:59:19.945660 27450 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 02:59:19.946039 27450 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 02:59:19.946264 27450 layer_factory.hpp:77] Creating layer data_hdf5
I0526 02:59:19.946282 27450 net.cpp:106] Creating Layer data_hdf5
I0526 02:59:19.946302 27450 net.cpp:411] data_hdf5 -> data
I0526 02:59:19.946321 27450 net.cpp:411] data_hdf5 -> label
I0526 02:59:19.946343 27450 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 02:59:19.962754 27450 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 02:59:41.389559 27450 net.cpp:150] Setting up data_hdf5
I0526 02:59:41.389727 27450 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 02:59:41.389745 27450 net.cpp:157] Top shape: 10 (10)
I0526 02:59:41.389758 27450 net.cpp:165] Memory required for data: 254040
I0526 02:59:41.389773 27450 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 02:59:41.389806 27450 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 02:59:41.389821 27450 net.cpp:454] label_data_hdf5_1_split <- label
I0526 02:59:41.389837 27450 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 02:59:41.389878 27450 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 02:59:41.389966 27450 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 02:59:41.389983 27450 net.cpp:157] Top shape: 10 (10)
I0526 02:59:41.389998 27450 net.cpp:157] Top shape: 10 (10)
I0526 02:59:41.390012 27450 net.cpp:165] Memory required for data: 254120
I0526 02:59:41.390022 27450 layer_factory.hpp:77] Creating layer conv1
I0526 02:59:41.390055 27450 net.cpp:106] Creating Layer conv1
I0526 02:59:41.390069 27450 net.cpp:454] conv1 <- data
I0526 02:59:41.390085 27450 net.cpp:411] conv1 -> conv1
I0526 02:59:41.392036 27450 net.cpp:150] Setting up conv1
I0526 02:59:41.392062 27450 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 02:59:41.392083 27450 net.cpp:165] Memory required for data: 3018920
I0526 02:59:41.392107 27450 layer_factory.hpp:77] Creating layer relu1
I0526 02:59:41.392137 27450 net.cpp:106] Creating Layer relu1
I0526 02:59:41.392163 27450 net.cpp:454] relu1 <- conv1
I0526 02:59:41.392181 27450 net.cpp:397] relu1 -> conv1 (in-place)
I0526 02:59:41.392712 27450 net.cpp:150] Setting up relu1
I0526 02:59:41.392735 27450 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 02:59:41.392748 27450 net.cpp:165] Memory required for data: 5783720
I0526 02:59:41.392765 27450 layer_factory.hpp:77] Creating layer pool1
I0526 02:59:41.392791 27450 net.cpp:106] Creating Layer pool1
I0526 02:59:41.392803 27450 net.cpp:454] pool1 <- conv1
I0526 02:59:41.392819 27450 net.cpp:411] pool1 -> pool1
I0526 02:59:41.392909 27450 net.cpp:150] Setting up pool1
I0526 02:59:41.392925 27450 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 02:59:41.392940 27450 net.cpp:165] Memory required for data: 7166120
I0526 02:59:41.392958 27450 layer_factory.hpp:77] Creating layer conv2
I0526 02:59:41.392979 27450 net.cpp:106] Creating Layer conv2
I0526 02:59:41.393002 27450 net.cpp:454] conv2 <- pool1
I0526 02:59:41.393018 27450 net.cpp:411] conv2 -> conv2
I0526 02:59:41.394958 27450 net.cpp:150] Setting up conv2
I0526 02:59:41.394981 27450 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 02:59:41.395002 27450 net.cpp:165] Memory required for data: 9153320
I0526 02:59:41.395025 27450 layer_factory.hpp:77] Creating layer relu2
I0526 02:59:41.395045 27450 net.cpp:106] Creating Layer relu2
I0526 02:59:41.395066 27450 net.cpp:454] relu2 <- conv2
I0526 02:59:41.395082 27450 net.cpp:397] relu2 -> conv2 (in-place)
I0526 02:59:41.395434 27450 net.cpp:150] Setting up relu2
I0526 02:59:41.395454 27450 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 02:59:41.395467 27450 net.cpp:165] Memory required for data: 11140520
I0526 02:59:41.395481 27450 layer_factory.hpp:77] Creating layer pool2
I0526 02:59:41.395504 27450 net.cpp:106] Creating Layer pool2
I0526 02:59:41.395517 27450 net.cpp:454] pool2 <- conv2
I0526 02:59:41.395534 27450 net.cpp:411] pool2 -> pool2
I0526 02:59:41.395622 27450 net.cpp:150] Setting up pool2
I0526 02:59:41.395639 27450 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 02:59:41.395654 27450 net.cpp:165] Memory required for data: 12134120
I0526 02:59:41.395666 27450 layer_factory.hpp:77] Creating layer conv3
I0526 02:59:41.395696 27450 net.cpp:106] Creating Layer conv3
I0526 02:59:41.395709 27450 net.cpp:454] conv3 <- pool2
I0526 02:59:41.395725 27450 net.cpp:411] conv3 -> conv3
I0526 02:59:41.397771 27450 net.cpp:150] Setting up conv3
I0526 02:59:41.397796 27450 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 02:59:41.397817 27450 net.cpp:165] Memory required for data: 13218280
I0526 02:59:41.397840 27450 layer_factory.hpp:77] Creating layer relu3
I0526 02:59:41.397881 27450 net.cpp:106] Creating Layer relu3
I0526 02:59:41.397896 27450 net.cpp:454] relu3 <- conv3
I0526 02:59:41.397912 27450 net.cpp:397] relu3 -> conv3 (in-place)
I0526 02:59:41.398406 27450 net.cpp:150] Setting up relu3
I0526 02:59:41.398428 27450 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 02:59:41.398442 27450 net.cpp:165] Memory required for data: 14302440
I0526 02:59:41.398458 27450 layer_factory.hpp:77] Creating layer pool3
I0526 02:59:41.398473 27450 net.cpp:106] Creating Layer pool3
I0526 02:59:41.398494 27450 net.cpp:454] pool3 <- conv3
I0526 02:59:41.398510 27450 net.cpp:411] pool3 -> pool3
I0526 02:59:41.398597 27450 net.cpp:150] Setting up pool3
I0526 02:59:41.398614 27450 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 02:59:41.398628 27450 net.cpp:165] Memory required for data: 14844520
I0526 02:59:41.398640 27450 layer_factory.hpp:77] Creating layer conv4
I0526 02:59:41.398668 27450 net.cpp:106] Creating Layer conv4
I0526 02:59:41.398680 27450 net.cpp:454] conv4 <- pool3
I0526 02:59:41.398697 27450 net.cpp:411] conv4 -> conv4
I0526 02:59:41.400791 27450 net.cpp:150] Setting up conv4
I0526 02:59:41.400815 27450 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 02:59:41.400830 27450 net.cpp:165] Memory required for data: 15207400
I0526 02:59:41.400851 27450 layer_factory.hpp:77] Creating layer relu4
I0526 02:59:41.400876 27450 net.cpp:106] Creating Layer relu4
I0526 02:59:41.400890 27450 net.cpp:454] relu4 <- conv4
I0526 02:59:41.400907 27450 net.cpp:397] relu4 -> conv4 (in-place)
I0526 02:59:41.401399 27450 net.cpp:150] Setting up relu4
I0526 02:59:41.401422 27450 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 02:59:41.401435 27450 net.cpp:165] Memory required for data: 15570280
I0526 02:59:41.401451 27450 layer_factory.hpp:77] Creating layer pool4
I0526 02:59:41.401475 27450 net.cpp:106] Creating Layer pool4
I0526 02:59:41.401489 27450 net.cpp:454] pool4 <- conv4
I0526 02:59:41.401505 27450 net.cpp:411] pool4 -> pool4
I0526 02:59:41.401592 27450 net.cpp:150] Setting up pool4
I0526 02:59:41.401608 27450 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 02:59:41.401620 27450 net.cpp:165] Memory required for data: 15751720
I0526 02:59:41.401635 27450 layer_factory.hpp:77] Creating layer ip1
I0526 02:59:41.401659 27450 net.cpp:106] Creating Layer ip1
I0526 02:59:41.401672 27450 net.cpp:454] ip1 <- pool4
I0526 02:59:41.401695 27450 net.cpp:411] ip1 -> ip1
I0526 02:59:41.417129 27450 net.cpp:150] Setting up ip1
I0526 02:59:41.417161 27450 net.cpp:157] Top shape: 10 196 (1960)
I0526 02:59:41.417182 27450 net.cpp:165] Memory required for data: 15759560
I0526 02:59:41.417208 27450 layer_factory.hpp:77] Creating layer relu5
I0526 02:59:41.417230 27450 net.cpp:106] Creating Layer relu5
I0526 02:59:41.417255 27450 net.cpp:454] relu5 <- ip1
I0526 02:59:41.417273 27450 net.cpp:397] relu5 -> ip1 (in-place)
I0526 02:59:41.417639 27450 net.cpp:150] Setting up relu5
I0526 02:59:41.417659 27450 net.cpp:157] Top shape: 10 196 (1960)
I0526 02:59:41.417671 27450 net.cpp:165] Memory required for data: 15767400
I0526 02:59:41.417687 27450 layer_factory.hpp:77] Creating layer drop1
I0526 02:59:41.417716 27450 net.cpp:106] Creating Layer drop1
I0526 02:59:41.417731 27450 net.cpp:454] drop1 <- ip1
I0526 02:59:41.417745 27450 net.cpp:397] drop1 -> ip1 (in-place)
I0526 02:59:41.417804 27450 net.cpp:150] Setting up drop1
I0526 02:59:41.417820 27450 net.cpp:157] Top shape: 10 196 (1960)
I0526 02:59:41.417834 27450 net.cpp:165] Memory required for data: 15775240
I0526 02:59:41.417845 27450 layer_factory.hpp:77] Creating layer ip2
I0526 02:59:41.417865 27450 net.cpp:106] Creating Layer ip2
I0526 02:59:41.417877 27450 net.cpp:454] ip2 <- ip1
I0526 02:59:41.417901 27450 net.cpp:411] ip2 -> ip2
I0526 02:59:41.418396 27450 net.cpp:150] Setting up ip2
I0526 02:59:41.418416 27450 net.cpp:157] Top shape: 10 98 (980)
I0526 02:59:41.418428 27450 net.cpp:165] Memory required for data: 15779160
I0526 02:59:41.418449 27450 layer_factory.hpp:77] Creating layer relu6
I0526 02:59:41.418483 27450 net.cpp:106] Creating Layer relu6
I0526 02:59:41.418496 27450 net.cpp:454] relu6 <- ip2
I0526 02:59:41.418512 27450 net.cpp:397] relu6 -> ip2 (in-place)
I0526 02:59:41.419071 27450 net.cpp:150] Setting up relu6
I0526 02:59:41.419095 27450 net.cpp:157] Top shape: 10 98 (980)
I0526 02:59:41.419107 27450 net.cpp:165] Memory required for data: 15783080
I0526 02:59:41.419119 27450 layer_factory.hpp:77] Creating layer drop2
I0526 02:59:41.419138 27450 net.cpp:106] Creating Layer drop2
I0526 02:59:41.419160 27450 net.cpp:454] drop2 <- ip2
I0526 02:59:41.419176 27450 net.cpp:397] drop2 -> ip2 (in-place)
I0526 02:59:41.419234 27450 net.cpp:150] Setting up drop2
I0526 02:59:41.419257 27450 net.cpp:157] Top shape: 10 98 (980)
I0526 02:59:41.419270 27450 net.cpp:165] Memory required for data: 15787000
I0526 02:59:41.419282 27450 layer_factory.hpp:77] Creating layer ip3
I0526 02:59:41.419301 27450 net.cpp:106] Creating Layer ip3
I0526 02:59:41.419312 27450 net.cpp:454] ip3 <- ip2
I0526 02:59:41.419332 27450 net.cpp:411] ip3 -> ip3
I0526 02:59:41.419572 27450 net.cpp:150] Setting up ip3
I0526 02:59:41.419591 27450 net.cpp:157] Top shape: 10 11 (110)
I0526 02:59:41.419605 27450 net.cpp:165] Memory required for data: 15787440
I0526 02:59:41.419625 27450 layer_factory.hpp:77] Creating layer drop3
I0526 02:59:41.419647 27450 net.cpp:106] Creating Layer drop3
I0526 02:59:41.419661 27450 net.cpp:454] drop3 <- ip3
I0526 02:59:41.419677 27450 net.cpp:397] drop3 -> ip3 (in-place)
I0526 02:59:41.419724 27450 net.cpp:150] Setting up drop3
I0526 02:59:41.419746 27450 net.cpp:157] Top shape: 10 11 (110)
I0526 02:59:41.419759 27450 net.cpp:165] Memory required for data: 15787880
I0526 02:59:41.419777 27450 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 02:59:41.419793 27450 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 02:59:41.419808 27450 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 02:59:41.419823 27450 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 02:59:41.419842 27450 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 02:59:41.419929 27450 net.cpp:150] Setting up ip3_drop3_0_split
I0526 02:59:41.419945 27450 net.cpp:157] Top shape: 10 11 (110)
I0526 02:59:41.419968 27450 net.cpp:157] Top shape: 10 11 (110)
I0526 02:59:41.419983 27450 net.cpp:165] Memory required for data: 15788760
I0526 02:59:41.419996 27450 layer_factory.hpp:77] Creating layer accuracy
I0526 02:59:41.420018 27450 net.cpp:106] Creating Layer accuracy
I0526 02:59:41.420037 27450 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 02:59:41.420053 27450 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 02:59:41.420071 27450 net.cpp:411] accuracy -> accuracy
I0526 02:59:41.420096 27450 net.cpp:150] Setting up accuracy
I0526 02:59:41.420119 27450 net.cpp:157] Top shape: (1)
I0526 02:59:41.420135 27450 net.cpp:165] Memory required for data: 15788764
I0526 02:59:41.420153 27450 layer_factory.hpp:77] Creating layer loss
I0526 02:59:41.420172 27450 net.cpp:106] Creating Layer loss
I0526 02:59:41.420186 27450 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 02:59:41.420207 27450 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 02:59:41.420223 27450 net.cpp:411] loss -> loss
I0526 02:59:41.420243 27450 layer_factory.hpp:77] Creating layer loss
I0526 02:59:41.420753 27450 net.cpp:150] Setting up loss
I0526 02:59:41.420773 27450 net.cpp:157] Top shape: (1)
I0526 02:59:41.420785 27450 net.cpp:160]     with loss weight 1
I0526 02:59:41.420811 27450 net.cpp:165] Memory required for data: 15788768
I0526 02:59:41.420831 27450 net.cpp:226] loss needs backward computation.
I0526 02:59:41.420846 27450 net.cpp:228] accuracy does not need backward computation.
I0526 02:59:41.420863 27450 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 02:59:41.420876 27450 net.cpp:226] drop3 needs backward computation.
I0526 02:59:41.420888 27450 net.cpp:226] ip3 needs backward computation.
I0526 02:59:41.420904 27450 net.cpp:226] drop2 needs backward computation.
I0526 02:59:41.420917 27450 net.cpp:226] relu6 needs backward computation.
I0526 02:59:41.420943 27450 net.cpp:226] ip2 needs backward computation.
I0526 02:59:41.420956 27450 net.cpp:226] drop1 needs backward computation.
I0526 02:59:41.420969 27450 net.cpp:226] relu5 needs backward computation.
I0526 02:59:41.420981 27450 net.cpp:226] ip1 needs backward computation.
I0526 02:59:41.420996 27450 net.cpp:226] pool4 needs backward computation.
I0526 02:59:41.421008 27450 net.cpp:226] relu4 needs backward computation.
I0526 02:59:41.421028 27450 net.cpp:226] conv4 needs backward computation.
I0526 02:59:41.421041 27450 net.cpp:226] pool3 needs backward computation.
I0526 02:59:41.421057 27450 net.cpp:226] relu3 needs backward computation.
I0526 02:59:41.421071 27450 net.cpp:226] conv3 needs backward computation.
I0526 02:59:41.421082 27450 net.cpp:226] pool2 needs backward computation.
I0526 02:59:41.421098 27450 net.cpp:226] relu2 needs backward computation.
I0526 02:59:41.421110 27450 net.cpp:226] conv2 needs backward computation.
I0526 02:59:41.421130 27450 net.cpp:226] pool1 needs backward computation.
I0526 02:59:41.421144 27450 net.cpp:226] relu1 needs backward computation.
I0526 02:59:41.421159 27450 net.cpp:226] conv1 needs backward computation.
I0526 02:59:41.421174 27450 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 02:59:41.421187 27450 net.cpp:228] data_hdf5 does not need backward computation.
I0526 02:59:41.421201 27450 net.cpp:270] This network produces output accuracy
I0526 02:59:41.421214 27450 net.cpp:270] This network produces output loss
I0526 02:59:41.421244 27450 net.cpp:283] Network initialization done.
I0526 02:59:41.421381 27450 solver.cpp:60] Solver scaffolding done.
I0526 02:59:41.422523 27450 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_450000.solverstate
I0526 02:59:41.640539 27450 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 02:59:41.645967 27450 caffe.cpp:212] Starting Optimization
I0526 02:59:41.646010 27450 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 02:59:41.646034 27450 solver.cpp:289] Learning Rate Policy: fixed
I0526 02:59:41.647259 27450 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 03:00:42.330097 27450 solver.cpp:409]     Test net output #0: accuracy = 0.890095
I0526 03:00:42.330257 27450 solver.cpp:409]     Test net output #1: loss = 0.360292 (* 1 = 0.360292 loss)
I0526 03:00:42.348052 27450 solver.cpp:237] Iteration 450000, loss = 0.991668
I0526 03:00:42.348093 27450 solver.cpp:253]     Train net output #0: loss = 0.991668 (* 1 = 0.991668 loss)
I0526 03:00:42.348114 27450 sgd_solver.cpp:106] Iteration 450000, lr = 0.0005
I0526 03:00:59.143821 27450 solver.cpp:237] Iteration 451500, loss = 0.964697
I0526 03:00:59.143860 27450 solver.cpp:253]     Train net output #0: loss = 0.964696 (* 1 = 0.964696 loss)
I0526 03:00:59.143884 27450 sgd_solver.cpp:106] Iteration 451500, lr = 0.0005
I0526 03:01:15.836973 27450 solver.cpp:237] Iteration 453000, loss = 1.31444
I0526 03:01:15.837137 27450 solver.cpp:253]     Train net output #0: loss = 1.31444 (* 1 = 1.31444 loss)
I0526 03:01:15.837154 27450 sgd_solver.cpp:106] Iteration 453000, lr = 0.0005
I0526 03:01:32.522305 27450 solver.cpp:237] Iteration 454500, loss = 1.05481
I0526 03:01:32.522358 27450 solver.cpp:253]     Train net output #0: loss = 1.05481 (* 1 = 1.05481 loss)
I0526 03:01:32.522375 27450 sgd_solver.cpp:106] Iteration 454500, lr = 0.0005
I0526 03:01:49.490942 27450 solver.cpp:237] Iteration 456000, loss = 0.887283
I0526 03:01:49.491086 27450 solver.cpp:253]     Train net output #0: loss = 0.887281 (* 1 = 0.887281 loss)
I0526 03:01:49.491102 27450 sgd_solver.cpp:106] Iteration 456000, lr = 0.0005
I0526 03:02:06.249795 27450 solver.cpp:237] Iteration 457500, loss = 1.06867
I0526 03:02:06.249850 27450 solver.cpp:253]     Train net output #0: loss = 1.06867 (* 1 = 1.06867 loss)
I0526 03:02:06.249866 27450 sgd_solver.cpp:106] Iteration 457500, lr = 0.0005
I0526 03:02:22.946383 27450 solver.cpp:237] Iteration 459000, loss = 0.516615
I0526 03:02:22.946547 27450 solver.cpp:253]     Train net output #0: loss = 0.516613 (* 1 = 0.516613 loss)
I0526 03:02:22.946564 27450 sgd_solver.cpp:106] Iteration 459000, lr = 0.0005
I0526 03:03:02.399765 27450 solver.cpp:237] Iteration 460500, loss = 0.421378
I0526 03:03:02.399940 27450 solver.cpp:253]     Train net output #0: loss = 0.421376 (* 1 = 0.421376 loss)
I0526 03:03:02.399960 27450 sgd_solver.cpp:106] Iteration 460500, lr = 0.0005
I0526 03:03:19.328660 27450 solver.cpp:237] Iteration 462000, loss = 0.790785
I0526 03:03:19.328714 27450 solver.cpp:253]     Train net output #0: loss = 0.790783 (* 1 = 0.790783 loss)
I0526 03:03:19.328733 27450 sgd_solver.cpp:106] Iteration 462000, lr = 0.0005
I0526 03:03:35.950753 27450 solver.cpp:237] Iteration 463500, loss = 1.47942
I0526 03:03:35.950897 27450 solver.cpp:253]     Train net output #0: loss = 1.47942 (* 1 = 1.47942 loss)
I0526 03:03:35.950914 27450 sgd_solver.cpp:106] Iteration 463500, lr = 0.0005
I0526 03:03:53.114801 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_465000.caffemodel
I0526 03:03:53.163836 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_465000.solverstate
I0526 03:03:53.194778 27450 solver.cpp:237] Iteration 465000, loss = 0.567095
I0526 03:03:53.194839 27450 solver.cpp:253]     Train net output #0: loss = 0.567092 (* 1 = 0.567092 loss)
I0526 03:03:53.194866 27450 sgd_solver.cpp:106] Iteration 465000, lr = 0.0005
I0526 03:04:10.343312 27450 solver.cpp:237] Iteration 466500, loss = 1.14857
I0526 03:04:10.343477 27450 solver.cpp:253]     Train net output #0: loss = 1.14857 (* 1 = 1.14857 loss)
I0526 03:04:10.343494 27450 sgd_solver.cpp:106] Iteration 466500, lr = 0.0005
I0526 03:04:27.388038 27450 solver.cpp:237] Iteration 468000, loss = 1.06415
I0526 03:04:27.388098 27450 solver.cpp:253]     Train net output #0: loss = 1.06415 (* 1 = 1.06415 loss)
I0526 03:04:27.388125 27450 sgd_solver.cpp:106] Iteration 468000, lr = 0.0005
I0526 03:04:44.378253 27450 solver.cpp:237] Iteration 469500, loss = 1.45695
I0526 03:04:44.378398 27450 solver.cpp:253]     Train net output #0: loss = 1.45695 (* 1 = 1.45695 loss)
I0526 03:04:44.378415 27450 sgd_solver.cpp:106] Iteration 469500, lr = 0.0005
I0526 03:05:23.563864 27450 solver.cpp:237] Iteration 471000, loss = 1.17632
I0526 03:05:23.564046 27450 solver.cpp:253]     Train net output #0: loss = 1.17631 (* 1 = 1.17631 loss)
I0526 03:05:23.564066 27450 sgd_solver.cpp:106] Iteration 471000, lr = 0.0005
I0526 03:05:40.615527 27450 solver.cpp:237] Iteration 472500, loss = 1.43323
I0526 03:05:40.615566 27450 solver.cpp:253]     Train net output #0: loss = 1.43323 (* 1 = 1.43323 loss)
I0526 03:05:40.615589 27450 sgd_solver.cpp:106] Iteration 472500, lr = 0.0005
I0526 03:05:57.272742 27450 solver.cpp:237] Iteration 474000, loss = 1.37241
I0526 03:05:57.272905 27450 solver.cpp:253]     Train net output #0: loss = 1.37241 (* 1 = 1.37241 loss)
I0526 03:05:57.272922 27450 sgd_solver.cpp:106] Iteration 474000, lr = 0.0005
I0526 03:06:14.090944 27450 solver.cpp:237] Iteration 475500, loss = 1.73544
I0526 03:06:14.091001 27450 solver.cpp:253]     Train net output #0: loss = 1.73544 (* 1 = 1.73544 loss)
I0526 03:06:14.091018 27450 sgd_solver.cpp:106] Iteration 475500, lr = 0.0005
I0526 03:06:31.160604 27450 solver.cpp:237] Iteration 477000, loss = 1.18455
I0526 03:06:31.160748 27450 solver.cpp:253]     Train net output #0: loss = 1.18455 (* 1 = 1.18455 loss)
I0526 03:06:31.160765 27450 sgd_solver.cpp:106] Iteration 477000, lr = 0.0005
I0526 03:06:48.124366 27450 solver.cpp:237] Iteration 478500, loss = 1.04324
I0526 03:06:48.124421 27450 solver.cpp:253]     Train net output #0: loss = 1.04324 (* 1 = 1.04324 loss)
I0526 03:06:48.124439 27450 sgd_solver.cpp:106] Iteration 478500, lr = 0.0005
I0526 03:07:04.928764 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_480000.caffemodel
I0526 03:07:04.976071 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_480000.solverstate
I0526 03:07:05.004950 27450 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 03:08:04.660259 27450 solver.cpp:409]     Test net output #0: accuracy = 0.88801
I0526 03:08:04.660431 27450 solver.cpp:409]     Test net output #1: loss = 0.360511 (* 1 = 0.360511 loss)
I0526 03:08:26.853534 27450 solver.cpp:237] Iteration 480000, loss = 0.655848
I0526 03:08:26.853600 27450 solver.cpp:253]     Train net output #0: loss = 0.655842 (* 1 = 0.655842 loss)
I0526 03:08:26.853629 27450 sgd_solver.cpp:106] Iteration 480000, lr = 0.0005
I0526 03:08:43.871480 27450 solver.cpp:237] Iteration 481500, loss = 1.22591
I0526 03:08:43.871649 27450 solver.cpp:253]     Train net output #0: loss = 1.22591 (* 1 = 1.22591 loss)
I0526 03:08:43.871666 27450 sgd_solver.cpp:106] Iteration 481500, lr = 0.0005
I0526 03:09:00.857606 27450 solver.cpp:237] Iteration 483000, loss = 1.43702
I0526 03:09:00.857645 27450 solver.cpp:253]     Train net output #0: loss = 1.43701 (* 1 = 1.43701 loss)
I0526 03:09:00.857669 27450 sgd_solver.cpp:106] Iteration 483000, lr = 0.0005
I0526 03:09:17.799006 27450 solver.cpp:237] Iteration 484500, loss = 1.4314
I0526 03:09:17.799167 27450 solver.cpp:253]     Train net output #0: loss = 1.4314 (* 1 = 1.4314 loss)
I0526 03:09:17.799185 27450 sgd_solver.cpp:106] Iteration 484500, lr = 0.0005
I0526 03:09:34.744283 27450 solver.cpp:237] Iteration 486000, loss = 0.985323
I0526 03:09:34.744341 27450 solver.cpp:253]     Train net output #0: loss = 0.985317 (* 1 = 0.985317 loss)
I0526 03:09:34.744359 27450 sgd_solver.cpp:106] Iteration 486000, lr = 0.0005
I0526 03:09:51.790407 27450 solver.cpp:237] Iteration 487500, loss = 1.33239
I0526 03:09:51.790573 27450 solver.cpp:253]     Train net output #0: loss = 1.33238 (* 1 = 1.33238 loss)
I0526 03:09:51.790591 27450 sgd_solver.cpp:106] Iteration 487500, lr = 0.0005
I0526 03:10:08.996949 27450 solver.cpp:237] Iteration 489000, loss = 1.2522
I0526 03:10:08.996989 27450 solver.cpp:253]     Train net output #0: loss = 1.2522 (* 1 = 1.2522 loss)
I0526 03:10:08.997009 27450 sgd_solver.cpp:106] Iteration 489000, lr = 0.0005
I0526 03:10:48.273392 27450 solver.cpp:237] Iteration 490500, loss = 1.47762
I0526 03:10:48.273576 27450 solver.cpp:253]     Train net output #0: loss = 1.47762 (* 1 = 1.47762 loss)
I0526 03:10:48.273594 27450 sgd_solver.cpp:106] Iteration 490500, lr = 0.0005
I0526 03:11:05.174264 27450 solver.cpp:237] Iteration 492000, loss = 1.55458
I0526 03:11:05.174304 27450 solver.cpp:253]     Train net output #0: loss = 1.55457 (* 1 = 1.55457 loss)
I0526 03:11:05.174320 27450 sgd_solver.cpp:106] Iteration 492000, lr = 0.0005
I0526 03:11:22.142979 27450 solver.cpp:237] Iteration 493500, loss = 1.14931
I0526 03:11:22.143143 27450 solver.cpp:253]     Train net output #0: loss = 1.1493 (* 1 = 1.1493 loss)
I0526 03:11:22.143160 27450 sgd_solver.cpp:106] Iteration 493500, lr = 0.0005
I0526 03:11:39.229871 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_495000.caffemodel
I0526 03:11:39.278422 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_495000.solverstate
I0526 03:11:39.309320 27450 solver.cpp:237] Iteration 495000, loss = 1.05163
I0526 03:11:39.309384 27450 solver.cpp:253]     Train net output #0: loss = 1.05162 (* 1 = 1.05162 loss)
I0526 03:11:39.309403 27450 sgd_solver.cpp:106] Iteration 495000, lr = 0.0005
I0526 03:11:56.515187 27450 solver.cpp:237] Iteration 496500, loss = 1.21031
I0526 03:11:56.515336 27450 solver.cpp:253]     Train net output #0: loss = 1.2103 (* 1 = 1.2103 loss)
I0526 03:11:56.515353 27450 sgd_solver.cpp:106] Iteration 496500, lr = 0.0005
I0526 03:12:13.300043 27450 solver.cpp:237] Iteration 498000, loss = 0.906131
I0526 03:12:13.300099 27450 solver.cpp:253]     Train net output #0: loss = 0.906124 (* 1 = 0.906124 loss)
I0526 03:12:13.300117 27450 sgd_solver.cpp:106] Iteration 498000, lr = 0.0005
I0526 03:12:30.025684 27450 solver.cpp:237] Iteration 499500, loss = 1.3445
I0526 03:12:30.025846 27450 solver.cpp:253]     Train net output #0: loss = 1.3445 (* 1 = 1.3445 loss)
I0526 03:12:30.025863 27450 sgd_solver.cpp:106] Iteration 499500, lr = 0.0005
I0526 03:13:09.058152 27450 solver.cpp:237] Iteration 501000, loss = 1.28332
I0526 03:13:09.058326 27450 solver.cpp:253]     Train net output #0: loss = 1.28331 (* 1 = 1.28331 loss)
I0526 03:13:09.058343 27450 sgd_solver.cpp:106] Iteration 501000, lr = 0.0005
I0526 03:13:26.053099 27450 solver.cpp:237] Iteration 502500, loss = 1.20697
I0526 03:13:26.053153 27450 solver.cpp:253]     Train net output #0: loss = 1.20696 (* 1 = 1.20696 loss)
I0526 03:13:26.053172 27450 sgd_solver.cpp:106] Iteration 502500, lr = 0.0005
I0526 03:13:42.946024 27450 solver.cpp:237] Iteration 504000, loss = 0.944356
I0526 03:13:42.946192 27450 solver.cpp:253]     Train net output #0: loss = 0.944349 (* 1 = 0.944349 loss)
I0526 03:13:42.946209 27450 sgd_solver.cpp:106] Iteration 504000, lr = 0.0005
I0526 03:13:59.575639 27450 solver.cpp:237] Iteration 505500, loss = 1.52205
I0526 03:13:59.575677 27450 solver.cpp:253]     Train net output #0: loss = 1.52204 (* 1 = 1.52204 loss)
I0526 03:13:59.575700 27450 sgd_solver.cpp:106] Iteration 505500, lr = 0.0005
I0526 03:14:16.327023 27450 solver.cpp:237] Iteration 507000, loss = 1.35395
I0526 03:14:16.327183 27450 solver.cpp:253]     Train net output #0: loss = 1.35394 (* 1 = 1.35394 loss)
I0526 03:14:16.327198 27450 sgd_solver.cpp:106] Iteration 507000, lr = 0.0005
I0526 03:14:33.139770 27450 solver.cpp:237] Iteration 508500, loss = 1.13088
I0526 03:14:33.139828 27450 solver.cpp:253]     Train net output #0: loss = 1.13087 (* 1 = 1.13087 loss)
I0526 03:14:33.139853 27450 sgd_solver.cpp:106] Iteration 508500, lr = 0.0005
I0526 03:14:49.963635 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_510000.caffemodel
I0526 03:14:50.011672 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_510000.solverstate
I0526 03:14:50.039495 27450 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 03:16:10.573462 27450 solver.cpp:409]     Test net output #0: accuracy = 0.88875
I0526 03:16:10.573632 27450 solver.cpp:409]     Test net output #1: loss = 0.363724 (* 1 = 0.363724 loss)
I0526 03:16:32.770229 27450 solver.cpp:237] Iteration 510000, loss = 1.34072
I0526 03:16:32.770293 27450 solver.cpp:253]     Train net output #0: loss = 1.34071 (* 1 = 1.34071 loss)
I0526 03:16:32.770313 27450 sgd_solver.cpp:106] Iteration 510000, lr = 0.0005
I0526 03:16:49.828181 27450 solver.cpp:237] Iteration 511500, loss = 0.986697
I0526 03:16:49.828333 27450 solver.cpp:253]     Train net output #0: loss = 0.98669 (* 1 = 0.98669 loss)
I0526 03:16:49.828351 27450 sgd_solver.cpp:106] Iteration 511500, lr = 0.0005
I0526 03:17:06.781888 27450 solver.cpp:237] Iteration 513000, loss = 1.26446
I0526 03:17:06.781939 27450 solver.cpp:253]     Train net output #0: loss = 1.26446 (* 1 = 1.26446 loss)
I0526 03:17:06.781960 27450 sgd_solver.cpp:106] Iteration 513000, lr = 0.0005
I0526 03:17:23.627415 27450 solver.cpp:237] Iteration 514500, loss = 0.842661
I0526 03:17:23.627578 27450 solver.cpp:253]     Train net output #0: loss = 0.842654 (* 1 = 0.842654 loss)
I0526 03:17:23.627595 27450 sgd_solver.cpp:106] Iteration 514500, lr = 0.0005
I0526 03:17:40.398847 27450 solver.cpp:237] Iteration 516000, loss = 1.313
I0526 03:17:40.398886 27450 solver.cpp:253]     Train net output #0: loss = 1.31299 (* 1 = 1.31299 loss)
I0526 03:17:40.398903 27450 sgd_solver.cpp:106] Iteration 516000, lr = 0.0005
I0526 03:17:57.083982 27450 solver.cpp:237] Iteration 517500, loss = 1.4751
I0526 03:17:57.084137 27450 solver.cpp:253]     Train net output #0: loss = 1.4751 (* 1 = 1.4751 loss)
I0526 03:17:57.084162 27450 sgd_solver.cpp:106] Iteration 517500, lr = 0.0005
I0526 03:18:13.724835 27450 solver.cpp:237] Iteration 519000, loss = 0.941041
I0526 03:18:13.724892 27450 solver.cpp:253]     Train net output #0: loss = 0.941034 (* 1 = 0.941034 loss)
I0526 03:18:13.724917 27450 sgd_solver.cpp:106] Iteration 519000, lr = 0.0005
I0526 03:18:52.756883 27450 solver.cpp:237] Iteration 520500, loss = 1.85109
I0526 03:18:52.757050 27450 solver.cpp:253]     Train net output #0: loss = 1.85108 (* 1 = 1.85108 loss)
I0526 03:18:52.757068 27450 sgd_solver.cpp:106] Iteration 520500, lr = 0.0005
I0526 03:19:09.492853 27450 solver.cpp:237] Iteration 522000, loss = 0.974497
I0526 03:19:09.492910 27450 solver.cpp:253]     Train net output #0: loss = 0.97449 (* 1 = 0.97449 loss)
I0526 03:19:09.492928 27450 sgd_solver.cpp:106] Iteration 522000, lr = 0.0005
I0526 03:19:26.135248 27450 solver.cpp:237] Iteration 523500, loss = 0.931429
I0526 03:19:26.135396 27450 solver.cpp:253]     Train net output #0: loss = 0.931423 (* 1 = 0.931423 loss)
I0526 03:19:26.135413 27450 sgd_solver.cpp:106] Iteration 523500, lr = 0.0005
I0526 03:19:43.180346 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_525000.caffemodel
I0526 03:19:43.229233 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_525000.solverstate
I0526 03:19:43.260982 27450 solver.cpp:237] Iteration 525000, loss = 1.17171
I0526 03:19:43.261046 27450 solver.cpp:253]     Train net output #0: loss = 1.17171 (* 1 = 1.17171 loss)
I0526 03:19:43.261064 27450 sgd_solver.cpp:106] Iteration 525000, lr = 0.0005
I0526 03:20:00.203819 27450 solver.cpp:237] Iteration 526500, loss = 1.84354
I0526 03:20:00.203987 27450 solver.cpp:253]     Train net output #0: loss = 1.84353 (* 1 = 1.84353 loss)
I0526 03:20:00.204005 27450 sgd_solver.cpp:106] Iteration 526500, lr = 0.0005
I0526 03:20:16.995184 27450 solver.cpp:237] Iteration 528000, loss = 1.18995
I0526 03:20:16.995244 27450 solver.cpp:253]     Train net output #0: loss = 1.18995 (* 1 = 1.18995 loss)
I0526 03:20:16.995262 27450 sgd_solver.cpp:106] Iteration 528000, lr = 0.0005
I0526 03:20:33.620394 27450 solver.cpp:237] Iteration 529500, loss = 0.747255
I0526 03:20:33.620553 27450 solver.cpp:253]     Train net output #0: loss = 0.74725 (* 1 = 0.74725 loss)
I0526 03:20:33.620570 27450 sgd_solver.cpp:106] Iteration 529500, lr = 0.0005
I0526 03:21:12.603229 27450 solver.cpp:237] Iteration 531000, loss = 0.99419
I0526 03:21:12.603400 27450 solver.cpp:253]     Train net output #0: loss = 0.994185 (* 1 = 0.994185 loss)
I0526 03:21:12.603418 27450 sgd_solver.cpp:106] Iteration 531000, lr = 0.0005
I0526 03:21:29.389140 27450 solver.cpp:237] Iteration 532500, loss = 1.03596
I0526 03:21:29.389178 27450 solver.cpp:253]     Train net output #0: loss = 1.03595 (* 1 = 1.03595 loss)
I0526 03:21:29.389202 27450 sgd_solver.cpp:106] Iteration 532500, lr = 0.0005
I0526 03:21:46.272594 27450 solver.cpp:237] Iteration 534000, loss = 1.0173
I0526 03:21:46.272758 27450 solver.cpp:253]     Train net output #0: loss = 1.01729 (* 1 = 1.01729 loss)
I0526 03:21:46.272774 27450 sgd_solver.cpp:106] Iteration 534000, lr = 0.0005
I0526 03:22:03.284292 27450 solver.cpp:237] Iteration 535500, loss = 0.908162
I0526 03:22:03.284349 27450 solver.cpp:253]     Train net output #0: loss = 0.908157 (* 1 = 0.908157 loss)
I0526 03:22:03.284374 27450 sgd_solver.cpp:106] Iteration 535500, lr = 0.0005
I0526 03:22:20.493185 27450 solver.cpp:237] Iteration 537000, loss = 1.17869
I0526 03:22:20.493333 27450 solver.cpp:253]     Train net output #0: loss = 1.17869 (* 1 = 1.17869 loss)
I0526 03:22:20.493350 27450 sgd_solver.cpp:106] Iteration 537000, lr = 0.0005
I0526 03:22:37.340837 27450 solver.cpp:237] Iteration 538500, loss = 0.88941
I0526 03:22:37.340889 27450 solver.cpp:253]     Train net output #0: loss = 0.889406 (* 1 = 0.889406 loss)
I0526 03:22:37.340908 27450 sgd_solver.cpp:106] Iteration 538500, lr = 0.0005
I0526 03:22:54.198082 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_540000.caffemodel
I0526 03:22:54.243851 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_540000.solverstate
I0526 03:22:54.270233 27450 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 03:23:53.533663 27450 solver.cpp:409]     Test net output #0: accuracy = 0.894684
I0526 03:23:53.533840 27450 solver.cpp:409]     Test net output #1: loss = 0.329617 (* 1 = 0.329617 loss)
I0526 03:24:15.754951 27450 solver.cpp:237] Iteration 540000, loss = 1.01436
I0526 03:24:15.755012 27450 solver.cpp:253]     Train net output #0: loss = 1.01436 (* 1 = 1.01436 loss)
I0526 03:24:15.755033 27450 sgd_solver.cpp:106] Iteration 540000, lr = 0.0005
I0526 03:24:32.530421 27450 solver.cpp:237] Iteration 541500, loss = 1.15686
I0526 03:24:32.530594 27450 solver.cpp:253]     Train net output #0: loss = 1.15685 (* 1 = 1.15685 loss)
I0526 03:24:32.530612 27450 sgd_solver.cpp:106] Iteration 541500, lr = 0.0005
I0526 03:24:49.146396 27450 solver.cpp:237] Iteration 543000, loss = 0.654689
I0526 03:24:49.146436 27450 solver.cpp:253]     Train net output #0: loss = 0.654685 (* 1 = 0.654685 loss)
I0526 03:24:49.146455 27450 sgd_solver.cpp:106] Iteration 543000, lr = 0.0005
I0526 03:25:06.060554 27450 solver.cpp:237] Iteration 544500, loss = 1.43514
I0526 03:25:06.060724 27450 solver.cpp:253]     Train net output #0: loss = 1.43514 (* 1 = 1.43514 loss)
I0526 03:25:06.060741 27450 sgd_solver.cpp:106] Iteration 544500, lr = 0.0005
I0526 03:25:22.890662 27450 solver.cpp:237] Iteration 546000, loss = 1.0422
I0526 03:25:22.890720 27450 solver.cpp:253]     Train net output #0: loss = 1.0422 (* 1 = 1.0422 loss)
I0526 03:25:22.890745 27450 sgd_solver.cpp:106] Iteration 546000, lr = 0.0005
I0526 03:25:39.519714 27450 solver.cpp:237] Iteration 547500, loss = 1.40004
I0526 03:25:39.519871 27450 solver.cpp:253]     Train net output #0: loss = 1.40004 (* 1 = 1.40004 loss)
I0526 03:25:39.519888 27450 sgd_solver.cpp:106] Iteration 547500, lr = 0.0005
I0526 03:25:56.270756 27450 solver.cpp:237] Iteration 549000, loss = 1.61777
I0526 03:25:56.270803 27450 solver.cpp:253]     Train net output #0: loss = 1.61777 (* 1 = 1.61777 loss)
I0526 03:25:56.270822 27450 sgd_solver.cpp:106] Iteration 549000, lr = 0.0005
I0526 03:26:35.274305 27450 solver.cpp:237] Iteration 550500, loss = 1.70746
I0526 03:26:35.274482 27450 solver.cpp:253]     Train net output #0: loss = 1.70745 (* 1 = 1.70745 loss)
I0526 03:26:35.274502 27450 sgd_solver.cpp:106] Iteration 550500, lr = 0.0005
I0526 03:26:52.041775 27450 solver.cpp:237] Iteration 552000, loss = 0.220233
I0526 03:26:52.041815 27450 solver.cpp:253]     Train net output #0: loss = 0.220227 (* 1 = 0.220227 loss)
I0526 03:26:52.041832 27450 sgd_solver.cpp:106] Iteration 552000, lr = 0.0005
I0526 03:27:08.897765 27450 solver.cpp:237] Iteration 553500, loss = 0.863824
I0526 03:27:08.897949 27450 solver.cpp:253]     Train net output #0: loss = 0.863818 (* 1 = 0.863818 loss)
I0526 03:27:08.897966 27450 sgd_solver.cpp:106] Iteration 553500, lr = 0.0005
I0526 03:27:25.655205 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_555000.caffemodel
I0526 03:27:25.700927 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_555000.solverstate
I0526 03:27:25.729678 27450 solver.cpp:237] Iteration 555000, loss = 1.54412
I0526 03:27:25.729732 27450 solver.cpp:253]     Train net output #0: loss = 1.54411 (* 1 = 1.54411 loss)
I0526 03:27:25.729758 27450 sgd_solver.cpp:106] Iteration 555000, lr = 0.0005
I0526 03:27:42.363361 27450 solver.cpp:237] Iteration 556500, loss = 0.711925
I0526 03:27:42.363514 27450 solver.cpp:253]     Train net output #0: loss = 0.711918 (* 1 = 0.711918 loss)
I0526 03:27:42.363531 27450 sgd_solver.cpp:106] Iteration 556500, lr = 0.0005
I0526 03:27:59.122942 27450 solver.cpp:237] Iteration 558000, loss = 1.26763
I0526 03:27:59.122994 27450 solver.cpp:253]     Train net output #0: loss = 1.26763 (* 1 = 1.26763 loss)
I0526 03:27:59.123013 27450 sgd_solver.cpp:106] Iteration 558000, lr = 0.0005
I0526 03:28:15.982389 27450 solver.cpp:237] Iteration 559500, loss = 0.789257
I0526 03:28:15.982559 27450 solver.cpp:253]     Train net output #0: loss = 0.78925 (* 1 = 0.78925 loss)
I0526 03:28:15.982578 27450 sgd_solver.cpp:106] Iteration 559500, lr = 0.0005
I0526 03:28:55.157768 27450 solver.cpp:237] Iteration 561000, loss = 1.31822
I0526 03:28:55.157943 27450 solver.cpp:253]     Train net output #0: loss = 1.31821 (* 1 = 1.31821 loss)
I0526 03:28:55.157960 27450 sgd_solver.cpp:106] Iteration 561000, lr = 0.0005
I0526 03:29:12.063938 27450 solver.cpp:237] Iteration 562500, loss = 2.15948
I0526 03:29:12.063997 27450 solver.cpp:253]     Train net output #0: loss = 2.15947 (* 1 = 2.15947 loss)
I0526 03:29:12.064014 27450 sgd_solver.cpp:106] Iteration 562500, lr = 0.0005
I0526 03:29:28.893584 27450 solver.cpp:237] Iteration 564000, loss = 1.27537
I0526 03:29:28.893749 27450 solver.cpp:253]     Train net output #0: loss = 1.27536 (* 1 = 1.27536 loss)
I0526 03:29:28.893769 27450 sgd_solver.cpp:106] Iteration 564000, lr = 0.0005
I0526 03:29:45.850627 27450 solver.cpp:237] Iteration 565500, loss = 1.2927
I0526 03:29:45.850724 27450 solver.cpp:253]     Train net output #0: loss = 1.29269 (* 1 = 1.29269 loss)
I0526 03:29:45.850742 27450 sgd_solver.cpp:106] Iteration 565500, lr = 0.0005
I0526 03:30:02.610214 27450 solver.cpp:237] Iteration 567000, loss = 1.30995
I0526 03:30:02.610381 27450 solver.cpp:253]     Train net output #0: loss = 1.30995 (* 1 = 1.30995 loss)
I0526 03:30:02.610399 27450 sgd_solver.cpp:106] Iteration 567000, lr = 0.0005
I0526 03:30:19.308387 27450 solver.cpp:237] Iteration 568500, loss = 1.47576
I0526 03:30:19.308441 27450 solver.cpp:253]     Train net output #0: loss = 1.47575 (* 1 = 1.47575 loss)
I0526 03:30:19.308459 27450 sgd_solver.cpp:106] Iteration 568500, lr = 0.0005
I0526 03:30:36.245466 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_570000.caffemodel
I0526 03:30:36.291471 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_570000.solverstate
I0526 03:30:36.316922 27450 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 03:31:56.674830 27450 solver.cpp:409]     Test net output #0: accuracy = 0.893263
I0526 03:31:56.675003 27450 solver.cpp:409]     Test net output #1: loss = 0.32451 (* 1 = 0.32451 loss)
I0526 03:32:18.906106 27450 solver.cpp:237] Iteration 570000, loss = 1.63934
I0526 03:32:18.906169 27450 solver.cpp:253]     Train net output #0: loss = 1.63933 (* 1 = 1.63933 loss)
I0526 03:32:18.906199 27450 sgd_solver.cpp:106] Iteration 570000, lr = 0.0005
I0526 03:32:36.100632 27450 solver.cpp:237] Iteration 571500, loss = 1.94284
I0526 03:32:36.100805 27450 solver.cpp:253]     Train net output #0: loss = 1.94283 (* 1 = 1.94283 loss)
I0526 03:32:36.100822 27450 sgd_solver.cpp:106] Iteration 571500, lr = 0.0005
I0526 03:32:53.196878 27450 solver.cpp:237] Iteration 573000, loss = 0.821864
I0526 03:32:53.196936 27450 solver.cpp:253]     Train net output #0: loss = 0.821857 (* 1 = 0.821857 loss)
I0526 03:32:53.196961 27450 sgd_solver.cpp:106] Iteration 573000, lr = 0.0005
I0526 03:33:10.201040 27450 solver.cpp:237] Iteration 574500, loss = 1.03289
I0526 03:33:10.201191 27450 solver.cpp:253]     Train net output #0: loss = 1.03288 (* 1 = 1.03288 loss)
I0526 03:33:10.201208 27450 sgd_solver.cpp:106] Iteration 574500, lr = 0.0005
I0526 03:33:27.022650 27450 solver.cpp:237] Iteration 576000, loss = 0.972891
I0526 03:33:27.022708 27450 solver.cpp:253]     Train net output #0: loss = 0.972883 (* 1 = 0.972883 loss)
I0526 03:33:27.022727 27450 sgd_solver.cpp:106] Iteration 576000, lr = 0.0005
I0526 03:33:43.904556 27450 solver.cpp:237] Iteration 577500, loss = 1.06763
I0526 03:33:43.904737 27450 solver.cpp:253]     Train net output #0: loss = 1.06762 (* 1 = 1.06762 loss)
I0526 03:33:43.904755 27450 sgd_solver.cpp:106] Iteration 577500, lr = 0.0005
I0526 03:34:00.864197 27450 solver.cpp:237] Iteration 579000, loss = 1.19324
I0526 03:34:00.864234 27450 solver.cpp:253]     Train net output #0: loss = 1.19323 (* 1 = 1.19323 loss)
I0526 03:34:00.864254 27450 sgd_solver.cpp:106] Iteration 579000, lr = 0.0005
I0526 03:34:39.961251 27450 solver.cpp:237] Iteration 580500, loss = 0.664988
I0526 03:34:39.961426 27450 solver.cpp:253]     Train net output #0: loss = 0.664979 (* 1 = 0.664979 loss)
I0526 03:34:39.961442 27450 sgd_solver.cpp:106] Iteration 580500, lr = 0.0005
I0526 03:34:56.890404 27450 solver.cpp:237] Iteration 582000, loss = 0.715019
I0526 03:34:56.890465 27450 solver.cpp:253]     Train net output #0: loss = 0.71501 (* 1 = 0.71501 loss)
I0526 03:34:56.890491 27450 sgd_solver.cpp:106] Iteration 582000, lr = 0.0005
I0526 03:35:13.858445 27450 solver.cpp:237] Iteration 583500, loss = 1.18146
I0526 03:35:13.858595 27450 solver.cpp:253]     Train net output #0: loss = 1.18145 (* 1 = 1.18145 loss)
I0526 03:35:13.858611 27450 sgd_solver.cpp:106] Iteration 583500, lr = 0.0005
I0526 03:35:30.861320 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_585000.caffemodel
I0526 03:35:30.909855 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_585000.solverstate
I0526 03:35:30.940832 27450 solver.cpp:237] Iteration 585000, loss = 1.55847
I0526 03:35:30.940896 27450 solver.cpp:253]     Train net output #0: loss = 1.55846 (* 1 = 1.55846 loss)
I0526 03:35:30.940914 27450 sgd_solver.cpp:106] Iteration 585000, lr = 0.0005
I0526 03:35:48.042997 27450 solver.cpp:237] Iteration 586500, loss = 0.630937
I0526 03:35:48.043186 27450 solver.cpp:253]     Train net output #0: loss = 0.630929 (* 1 = 0.630929 loss)
I0526 03:35:48.043205 27450 sgd_solver.cpp:106] Iteration 586500, lr = 0.0005
I0526 03:36:05.250149 27450 solver.cpp:237] Iteration 588000, loss = 2.36034
I0526 03:36:05.250188 27450 solver.cpp:253]     Train net output #0: loss = 2.36033 (* 1 = 2.36033 loss)
I0526 03:36:05.250207 27450 sgd_solver.cpp:106] Iteration 588000, lr = 0.0005
I0526 03:36:22.039221 27450 solver.cpp:237] Iteration 589500, loss = 1.29182
I0526 03:36:22.039386 27450 solver.cpp:253]     Train net output #0: loss = 1.29181 (* 1 = 1.29181 loss)
I0526 03:36:22.039402 27450 sgd_solver.cpp:106] Iteration 589500, lr = 0.0005
I0526 03:37:01.038285 27450 solver.cpp:237] Iteration 591000, loss = 1.19689
I0526 03:37:01.038461 27450 solver.cpp:253]     Train net output #0: loss = 1.19688 (* 1 = 1.19688 loss)
I0526 03:37:01.038480 27450 sgd_solver.cpp:106] Iteration 591000, lr = 0.0005
I0526 03:37:17.666437 27450 solver.cpp:237] Iteration 592500, loss = 1.39341
I0526 03:37:17.666476 27450 solver.cpp:253]     Train net output #0: loss = 1.3934 (* 1 = 1.3934 loss)
I0526 03:37:17.666496 27450 sgd_solver.cpp:106] Iteration 592500, lr = 0.0005
I0526 03:37:34.286312 27450 solver.cpp:237] Iteration 594000, loss = 0.969202
I0526 03:37:34.286474 27450 solver.cpp:253]     Train net output #0: loss = 0.969194 (* 1 = 0.969194 loss)
I0526 03:37:34.286491 27450 sgd_solver.cpp:106] Iteration 594000, lr = 0.0005
I0526 03:37:51.031735 27450 solver.cpp:237] Iteration 595500, loss = 1.90032
I0526 03:37:51.031795 27450 solver.cpp:253]     Train net output #0: loss = 1.90031 (* 1 = 1.90031 loss)
I0526 03:37:51.031821 27450 sgd_solver.cpp:106] Iteration 595500, lr = 0.0005
I0526 03:38:08.010040 27450 solver.cpp:237] Iteration 597000, loss = 1.53948
I0526 03:38:08.010188 27450 solver.cpp:253]     Train net output #0: loss = 1.53947 (* 1 = 1.53947 loss)
I0526 03:38:08.010205 27450 sgd_solver.cpp:106] Iteration 597000, lr = 0.0005
I0526 03:38:24.845077 27450 solver.cpp:237] Iteration 598500, loss = 1.21034
I0526 03:38:24.845129 27450 solver.cpp:253]     Train net output #0: loss = 1.21033 (* 1 = 1.21033 loss)
I0526 03:38:24.845147 27450 sgd_solver.cpp:106] Iteration 598500, lr = 0.0005
I0526 03:38:41.693331 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_600000.caffemodel
I0526 03:38:41.741555 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_600000.solverstate
I0526 03:38:41.769134 27450 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 03:39:41.299715 27450 solver.cpp:409]     Test net output #0: accuracy = 0.897185
I0526 03:39:41.299885 27450 solver.cpp:409]     Test net output #1: loss = 0.323704 (* 1 = 0.323704 loss)
I0526 03:40:02.197317 27450 solver.cpp:237] Iteration 600000, loss = 1.36171
I0526 03:40:02.197381 27450 solver.cpp:253]     Train net output #0: loss = 1.3617 (* 1 = 1.3617 loss)
I0526 03:40:02.197408 27450 sgd_solver.cpp:106] Iteration 600000, lr = 0.0005
I0526 03:40:19.005584 27450 solver.cpp:237] Iteration 601500, loss = 0.839144
I0526 03:40:19.005766 27450 solver.cpp:253]     Train net output #0: loss = 0.839136 (* 1 = 0.839136 loss)
I0526 03:40:19.005785 27450 sgd_solver.cpp:106] Iteration 601500, lr = 0.0005
I0526 03:40:35.660553 27450 solver.cpp:237] Iteration 603000, loss = 1.13556
I0526 03:40:35.660590 27450 solver.cpp:253]     Train net output #0: loss = 1.13555 (* 1 = 1.13555 loss)
I0526 03:40:35.660609 27450 sgd_solver.cpp:106] Iteration 603000, lr = 0.0005
I0526 03:40:52.653607 27450 solver.cpp:237] Iteration 604500, loss = 1.45644
I0526 03:40:52.653790 27450 solver.cpp:253]     Train net output #0: loss = 1.45643 (* 1 = 1.45643 loss)
I0526 03:40:52.653807 27450 sgd_solver.cpp:106] Iteration 604500, lr = 0.0005
I0526 03:41:09.839409 27450 solver.cpp:237] Iteration 606000, loss = 1.22106
I0526 03:41:09.839464 27450 solver.cpp:253]     Train net output #0: loss = 1.22106 (* 1 = 1.22106 loss)
I0526 03:41:09.839483 27450 sgd_solver.cpp:106] Iteration 606000, lr = 0.0005
I0526 03:41:26.920635 27450 solver.cpp:237] Iteration 607500, loss = 0.972397
I0526 03:41:26.920790 27450 solver.cpp:253]     Train net output #0: loss = 0.972389 (* 1 = 0.972389 loss)
I0526 03:41:26.920807 27450 sgd_solver.cpp:106] Iteration 607500, lr = 0.0005
I0526 03:41:44.086527 27450 solver.cpp:237] Iteration 609000, loss = 1.07009
I0526 03:41:44.086582 27450 solver.cpp:253]     Train net output #0: loss = 1.07008 (* 1 = 1.07008 loss)
I0526 03:41:44.086601 27450 sgd_solver.cpp:106] Iteration 609000, lr = 0.0005
I0526 03:42:22.202714 27450 solver.cpp:237] Iteration 610500, loss = 1.36786
I0526 03:42:22.202893 27450 solver.cpp:253]     Train net output #0: loss = 1.36785 (* 1 = 1.36785 loss)
I0526 03:42:22.202919 27450 sgd_solver.cpp:106] Iteration 610500, lr = 0.0005
I0526 03:42:38.818586 27450 solver.cpp:237] Iteration 612000, loss = 1.49193
I0526 03:42:38.818625 27450 solver.cpp:253]     Train net output #0: loss = 1.49192 (* 1 = 1.49192 loss)
I0526 03:42:38.818644 27450 sgd_solver.cpp:106] Iteration 612000, lr = 0.0005
I0526 03:42:55.474527 27450 solver.cpp:237] Iteration 613500, loss = 1.8584
I0526 03:42:55.474694 27450 solver.cpp:253]     Train net output #0: loss = 1.8584 (* 1 = 1.8584 loss)
I0526 03:42:55.474711 27450 sgd_solver.cpp:106] Iteration 613500, lr = 0.0005
I0526 03:43:12.102802 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_615000.caffemodel
I0526 03:43:12.148607 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_615000.solverstate
I0526 03:43:12.177485 27450 solver.cpp:237] Iteration 615000, loss = 0.944148
I0526 03:43:12.177544 27450 solver.cpp:253]     Train net output #0: loss = 0.94414 (* 1 = 0.94414 loss)
I0526 03:43:12.177562 27450 sgd_solver.cpp:106] Iteration 615000, lr = 0.0005
I0526 03:43:29.121019 27450 solver.cpp:237] Iteration 616500, loss = 1.26383
I0526 03:43:29.121175 27450 solver.cpp:253]     Train net output #0: loss = 1.26382 (* 1 = 1.26382 loss)
I0526 03:43:29.121191 27450 sgd_solver.cpp:106] Iteration 616500, lr = 0.0005
I0526 03:43:45.894858 27450 solver.cpp:237] Iteration 618000, loss = 0.844212
I0526 03:43:45.894917 27450 solver.cpp:253]     Train net output #0: loss = 0.844203 (* 1 = 0.844203 loss)
I0526 03:43:45.894933 27450 sgd_solver.cpp:106] Iteration 618000, lr = 0.0005
I0526 03:44:02.518462 27450 solver.cpp:237] Iteration 619500, loss = 1.27896
I0526 03:44:02.518632 27450 solver.cpp:253]     Train net output #0: loss = 1.27895 (* 1 = 1.27895 loss)
I0526 03:44:02.518651 27450 sgd_solver.cpp:106] Iteration 619500, lr = 0.0005
I0526 03:44:40.058094 27450 solver.cpp:237] Iteration 621000, loss = 0.915471
I0526 03:44:40.058274 27450 solver.cpp:253]     Train net output #0: loss = 0.915463 (* 1 = 0.915463 loss)
I0526 03:44:40.058292 27450 sgd_solver.cpp:106] Iteration 621000, lr = 0.0005
I0526 03:44:56.754070 27450 solver.cpp:237] Iteration 622500, loss = 1.13348
I0526 03:44:56.754125 27450 solver.cpp:253]     Train net output #0: loss = 1.13347 (* 1 = 1.13347 loss)
I0526 03:44:56.754153 27450 sgd_solver.cpp:106] Iteration 622500, lr = 0.0005
I0526 03:45:13.544847 27450 solver.cpp:237] Iteration 624000, loss = 1.11336
I0526 03:45:13.544997 27450 solver.cpp:253]     Train net output #0: loss = 1.11335 (* 1 = 1.11335 loss)
I0526 03:45:13.545014 27450 sgd_solver.cpp:106] Iteration 624000, lr = 0.0005
I0526 03:45:30.474462 27450 solver.cpp:237] Iteration 625500, loss = 0.505441
I0526 03:45:30.474521 27450 solver.cpp:253]     Train net output #0: loss = 0.505432 (* 1 = 0.505432 loss)
I0526 03:45:30.474539 27450 sgd_solver.cpp:106] Iteration 625500, lr = 0.0005
I0526 03:45:47.332968 27450 solver.cpp:237] Iteration 627000, loss = 1.44397
I0526 03:45:47.333149 27450 solver.cpp:253]     Train net output #0: loss = 1.44396 (* 1 = 1.44396 loss)
I0526 03:45:47.333168 27450 sgd_solver.cpp:106] Iteration 627000, lr = 0.0005
I0526 03:46:03.985124 27450 solver.cpp:237] Iteration 628500, loss = 1.63643
I0526 03:46:03.985162 27450 solver.cpp:253]     Train net output #0: loss = 1.63642 (* 1 = 1.63642 loss)
I0526 03:46:03.985182 27450 sgd_solver.cpp:106] Iteration 628500, lr = 0.0005
I0526 03:46:21.105659 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_630000.caffemodel
I0526 03:46:21.153666 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_630000.solverstate
I0526 03:46:21.179000 27450 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 03:47:41.453127 27450 solver.cpp:409]     Test net output #0: accuracy = 0.892729
I0526 03:47:41.453299 27450 solver.cpp:409]     Test net output #1: loss = 0.356019 (* 1 = 0.356019 loss)
I0526 03:48:02.276708 27450 solver.cpp:237] Iteration 630000, loss = 1.30947
I0526 03:48:02.276772 27450 solver.cpp:253]     Train net output #0: loss = 1.30946 (* 1 = 1.30946 loss)
I0526 03:48:02.276793 27450 sgd_solver.cpp:106] Iteration 630000, lr = 0.0005
I0526 03:48:19.167865 27450 solver.cpp:237] Iteration 631500, loss = 0.868275
I0526 03:48:19.168040 27450 solver.cpp:253]     Train net output #0: loss = 0.868265 (* 1 = 0.868265 loss)
I0526 03:48:19.168058 27450 sgd_solver.cpp:106] Iteration 631500, lr = 0.0005
I0526 03:48:36.367333 27450 solver.cpp:237] Iteration 633000, loss = 0.730046
I0526 03:48:36.367372 27450 solver.cpp:253]     Train net output #0: loss = 0.730036 (* 1 = 0.730036 loss)
I0526 03:48:36.367390 27450 sgd_solver.cpp:106] Iteration 633000, lr = 0.0005
I0526 03:48:52.996927 27450 solver.cpp:237] Iteration 634500, loss = 1.75992
I0526 03:48:52.997095 27450 solver.cpp:253]     Train net output #0: loss = 1.75991 (* 1 = 1.75991 loss)
I0526 03:48:52.997112 27450 sgd_solver.cpp:106] Iteration 634500, lr = 0.0005
I0526 03:49:09.692806 27450 solver.cpp:237] Iteration 636000, loss = 0.773714
I0526 03:49:09.692862 27450 solver.cpp:253]     Train net output #0: loss = 0.773703 (* 1 = 0.773703 loss)
I0526 03:49:09.692880 27450 sgd_solver.cpp:106] Iteration 636000, lr = 0.0005
I0526 03:49:26.473729 27450 solver.cpp:237] Iteration 637500, loss = 1.45883
I0526 03:49:26.473880 27450 solver.cpp:253]     Train net output #0: loss = 1.45882 (* 1 = 1.45882 loss)
I0526 03:49:26.473896 27450 sgd_solver.cpp:106] Iteration 637500, lr = 0.0005
I0526 03:49:43.534289 27450 solver.cpp:237] Iteration 639000, loss = 0.896676
I0526 03:49:43.534344 27450 solver.cpp:253]     Train net output #0: loss = 0.896665 (* 1 = 0.896665 loss)
I0526 03:49:43.534361 27450 sgd_solver.cpp:106] Iteration 639000, lr = 0.0005
I0526 03:50:21.457633 27450 solver.cpp:237] Iteration 640500, loss = 1.70006
I0526 03:50:21.457811 27450 solver.cpp:253]     Train net output #0: loss = 1.70005 (* 1 = 1.70005 loss)
I0526 03:50:21.457830 27450 sgd_solver.cpp:106] Iteration 640500, lr = 0.0005
I0526 03:50:38.644495 27450 solver.cpp:237] Iteration 642000, loss = 1.22382
I0526 03:50:38.644533 27450 solver.cpp:253]     Train net output #0: loss = 1.22381 (* 1 = 1.22381 loss)
I0526 03:50:38.644552 27450 sgd_solver.cpp:106] Iteration 642000, lr = 0.0005
I0526 03:50:55.621316 27450 solver.cpp:237] Iteration 643500, loss = 0.831238
I0526 03:50:55.621491 27450 solver.cpp:253]     Train net output #0: loss = 0.831227 (* 1 = 0.831227 loss)
I0526 03:50:55.621510 27450 sgd_solver.cpp:106] Iteration 643500, lr = 0.0005
I0526 03:51:12.465086 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_645000.caffemodel
I0526 03:51:12.510514 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_645000.solverstate
I0526 03:51:12.542670 27450 solver.cpp:237] Iteration 645000, loss = 0.7422
I0526 03:51:12.542731 27450 solver.cpp:253]     Train net output #0: loss = 0.742189 (* 1 = 0.742189 loss)
I0526 03:51:12.542750 27450 sgd_solver.cpp:106] Iteration 645000, lr = 0.0005
I0526 03:51:29.185816 27450 solver.cpp:237] Iteration 646500, loss = 0.910188
I0526 03:51:29.185984 27450 solver.cpp:253]     Train net output #0: loss = 0.910178 (* 1 = 0.910178 loss)
I0526 03:51:29.186002 27450 sgd_solver.cpp:106] Iteration 646500, lr = 0.0005
I0526 03:51:46.192770 27450 solver.cpp:237] Iteration 648000, loss = 0.850936
I0526 03:51:46.192826 27450 solver.cpp:253]     Train net output #0: loss = 0.850926 (* 1 = 0.850926 loss)
I0526 03:51:46.192844 27450 sgd_solver.cpp:106] Iteration 648000, lr = 0.0005
I0526 03:52:03.181519 27450 solver.cpp:237] Iteration 649500, loss = 0.752941
I0526 03:52:03.181699 27450 solver.cpp:253]     Train net output #0: loss = 0.752931 (* 1 = 0.752931 loss)
I0526 03:52:03.181716 27450 sgd_solver.cpp:106] Iteration 649500, lr = 0.0005
I0526 03:52:40.927458 27450 solver.cpp:237] Iteration 651000, loss = 0.69966
I0526 03:52:40.927636 27450 solver.cpp:253]     Train net output #0: loss = 0.699651 (* 1 = 0.699651 loss)
I0526 03:52:40.927654 27450 sgd_solver.cpp:106] Iteration 651000, lr = 0.0005
I0526 03:52:58.007560 27450 solver.cpp:237] Iteration 652500, loss = 0.979094
I0526 03:52:58.007617 27450 solver.cpp:253]     Train net output #0: loss = 0.979085 (* 1 = 0.979085 loss)
I0526 03:52:58.007637 27450 sgd_solver.cpp:106] Iteration 652500, lr = 0.0005
I0526 03:53:15.117527 27450 solver.cpp:237] Iteration 654000, loss = 1.15658
I0526 03:53:15.117698 27450 solver.cpp:253]     Train net output #0: loss = 1.15657 (* 1 = 1.15657 loss)
I0526 03:53:15.117717 27450 sgd_solver.cpp:106] Iteration 654000, lr = 0.0005
I0526 03:53:31.775840 27450 solver.cpp:237] Iteration 655500, loss = 0.999629
I0526 03:53:31.775877 27450 solver.cpp:253]     Train net output #0: loss = 0.999621 (* 1 = 0.999621 loss)
I0526 03:53:31.775897 27450 sgd_solver.cpp:106] Iteration 655500, lr = 0.0005
I0526 03:53:48.408217 27450 solver.cpp:237] Iteration 657000, loss = 0.729003
I0526 03:53:48.408392 27450 solver.cpp:253]     Train net output #0: loss = 0.728994 (* 1 = 0.728994 loss)
I0526 03:53:48.408409 27450 sgd_solver.cpp:106] Iteration 657000, lr = 0.0005
I0526 03:54:05.074331 27450 solver.cpp:237] Iteration 658500, loss = 0.57206
I0526 03:54:05.074390 27450 solver.cpp:253]     Train net output #0: loss = 0.57205 (* 1 = 0.57205 loss)
I0526 03:54:05.074414 27450 sgd_solver.cpp:106] Iteration 658500, lr = 0.0005
I0526 03:54:21.865129 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_660000.caffemodel
I0526 03:54:21.912299 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_660000.solverstate
I0526 03:54:21.939211 27450 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 03:55:21.101790 27450 solver.cpp:409]     Test net output #0: accuracy = 0.897132
I0526 03:55:21.101964 27450 solver.cpp:409]     Test net output #1: loss = 0.339286 (* 1 = 0.339286 loss)
I0526 03:55:41.981634 27450 solver.cpp:237] Iteration 660000, loss = 1.07563
I0526 03:55:41.981700 27450 solver.cpp:253]     Train net output #0: loss = 1.07562 (* 1 = 1.07562 loss)
I0526 03:55:41.981719 27450 sgd_solver.cpp:106] Iteration 660000, lr = 0.0005
I0526 03:55:59.189003 27450 solver.cpp:237] Iteration 661500, loss = 0.681207
I0526 03:55:59.189172 27450 solver.cpp:253]     Train net output #0: loss = 0.681199 (* 1 = 0.681199 loss)
I0526 03:55:59.189188 27450 sgd_solver.cpp:106] Iteration 661500, lr = 0.0005
I0526 03:56:16.160635 27450 solver.cpp:237] Iteration 663000, loss = 1.14087
I0526 03:56:16.160688 27450 solver.cpp:253]     Train net output #0: loss = 1.14086 (* 1 = 1.14086 loss)
I0526 03:56:16.160706 27450 sgd_solver.cpp:106] Iteration 663000, lr = 0.0005
I0526 03:56:33.031493 27450 solver.cpp:237] Iteration 664500, loss = 0.785616
I0526 03:56:33.031673 27450 solver.cpp:253]     Train net output #0: loss = 0.785607 (* 1 = 0.785607 loss)
I0526 03:56:33.031693 27450 sgd_solver.cpp:106] Iteration 664500, lr = 0.0005
I0526 03:56:49.707507 27450 solver.cpp:237] Iteration 666000, loss = 0.773201
I0526 03:56:49.707547 27450 solver.cpp:253]     Train net output #0: loss = 0.773192 (* 1 = 0.773192 loss)
I0526 03:56:49.707564 27450 sgd_solver.cpp:106] Iteration 666000, lr = 0.0005
I0526 03:57:06.419325 27450 solver.cpp:237] Iteration 667500, loss = 0.599565
I0526 03:57:06.419502 27450 solver.cpp:253]     Train net output #0: loss = 0.599557 (* 1 = 0.599557 loss)
I0526 03:57:06.419519 27450 sgd_solver.cpp:106] Iteration 667500, lr = 0.0005
I0526 03:57:23.247989 27450 solver.cpp:237] Iteration 669000, loss = 0.987594
I0526 03:57:23.248049 27450 solver.cpp:253]     Train net output #0: loss = 0.987586 (* 1 = 0.987586 loss)
I0526 03:57:23.248075 27450 sgd_solver.cpp:106] Iteration 669000, lr = 0.0005
I0526 03:58:01.174649 27450 solver.cpp:237] Iteration 670500, loss = 1.44531
I0526 03:58:01.174834 27450 solver.cpp:253]     Train net output #0: loss = 1.4453 (* 1 = 1.4453 loss)
I0526 03:58:01.174852 27450 sgd_solver.cpp:106] Iteration 670500, lr = 0.0005
I0526 03:58:18.171798 27450 solver.cpp:237] Iteration 672000, loss = 1.04498
I0526 03:58:18.171855 27450 solver.cpp:253]     Train net output #0: loss = 1.04497 (* 1 = 1.04497 loss)
I0526 03:58:18.171880 27450 sgd_solver.cpp:106] Iteration 672000, lr = 0.0005
I0526 03:58:35.040446 27450 solver.cpp:237] Iteration 673500, loss = 1.14862
I0526 03:58:35.040598 27450 solver.cpp:253]     Train net output #0: loss = 1.14861 (* 1 = 1.14861 loss)
I0526 03:58:35.040616 27450 sgd_solver.cpp:106] Iteration 673500, lr = 0.0005
I0526 03:58:51.692360 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_675000.caffemodel
I0526 03:58:51.740840 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_675000.solverstate
I0526 03:58:51.772477 27450 solver.cpp:237] Iteration 675000, loss = 1.06763
I0526 03:58:51.772536 27450 solver.cpp:253]     Train net output #0: loss = 1.06762 (* 1 = 1.06762 loss)
I0526 03:58:51.772554 27450 sgd_solver.cpp:106] Iteration 675000, lr = 0.0005
I0526 03:59:08.639547 27450 solver.cpp:237] Iteration 676500, loss = 1.91951
I0526 03:59:08.639724 27450 solver.cpp:253]     Train net output #0: loss = 1.9195 (* 1 = 1.9195 loss)
I0526 03:59:08.639741 27450 sgd_solver.cpp:106] Iteration 676500, lr = 0.0005
I0526 03:59:25.884727 27450 solver.cpp:237] Iteration 678000, loss = 1.32667
I0526 03:59:25.884768 27450 solver.cpp:253]     Train net output #0: loss = 1.32666 (* 1 = 1.32666 loss)
I0526 03:59:25.884785 27450 sgd_solver.cpp:106] Iteration 678000, lr = 0.0005
I0526 03:59:42.681957 27450 solver.cpp:237] Iteration 679500, loss = 1.10307
I0526 03:59:42.682124 27450 solver.cpp:253]     Train net output #0: loss = 1.10306 (* 1 = 1.10306 loss)
I0526 03:59:42.682142 27450 sgd_solver.cpp:106] Iteration 679500, lr = 0.0005
I0526 04:00:20.403291 27450 solver.cpp:237] Iteration 681000, loss = 0.831254
I0526 04:00:20.403472 27450 solver.cpp:253]     Train net output #0: loss = 0.831246 (* 1 = 0.831246 loss)
I0526 04:00:20.403491 27450 sgd_solver.cpp:106] Iteration 681000, lr = 0.0005
I0526 04:00:37.442414 27450 solver.cpp:237] Iteration 682500, loss = 0.980991
I0526 04:00:37.442451 27450 solver.cpp:253]     Train net output #0: loss = 0.980983 (* 1 = 0.980983 loss)
I0526 04:00:37.442469 27450 sgd_solver.cpp:106] Iteration 682500, lr = 0.0005
I0526 04:00:54.203142 27450 solver.cpp:237] Iteration 684000, loss = 1.75784
I0526 04:00:54.203326 27450 solver.cpp:253]     Train net output #0: loss = 1.75783 (* 1 = 1.75783 loss)
I0526 04:00:54.203343 27450 sgd_solver.cpp:106] Iteration 684000, lr = 0.0005
I0526 04:01:10.871881 27450 solver.cpp:237] Iteration 685500, loss = 1.29657
I0526 04:01:10.871937 27450 solver.cpp:253]     Train net output #0: loss = 1.29656 (* 1 = 1.29656 loss)
I0526 04:01:10.871953 27450 sgd_solver.cpp:106] Iteration 685500, lr = 0.0005
I0526 04:01:27.654270 27450 solver.cpp:237] Iteration 687000, loss = 1.9384
I0526 04:01:27.654438 27450 solver.cpp:253]     Train net output #0: loss = 1.93839 (* 1 = 1.93839 loss)
I0526 04:01:27.654455 27450 sgd_solver.cpp:106] Iteration 687000, lr = 0.0005
I0526 04:01:44.770488 27450 solver.cpp:237] Iteration 688500, loss = 0.825968
I0526 04:01:44.770545 27450 solver.cpp:253]     Train net output #0: loss = 0.82596 (* 1 = 0.82596 loss)
I0526 04:01:44.770562 27450 sgd_solver.cpp:106] Iteration 688500, lr = 0.0005
I0526 04:02:01.778041 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_690000.caffemodel
I0526 04:02:01.823740 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_690000.solverstate
I0526 04:02:01.849484 27450 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 04:03:22.394321 27450 solver.cpp:409]     Test net output #0: accuracy = 0.896965
I0526 04:03:22.394498 27450 solver.cpp:409]     Test net output #1: loss = 0.341103 (* 1 = 0.341103 loss)
I0526 04:03:43.251314 27450 solver.cpp:237] Iteration 690000, loss = 1.12236
I0526 04:03:43.251374 27450 solver.cpp:253]     Train net output #0: loss = 1.12236 (* 1 = 1.12236 loss)
I0526 04:03:43.251404 27450 sgd_solver.cpp:106] Iteration 690000, lr = 0.0005
I0526 04:04:00.019634 27450 solver.cpp:237] Iteration 691500, loss = 1.05987
I0526 04:04:00.019799 27450 solver.cpp:253]     Train net output #0: loss = 1.05986 (* 1 = 1.05986 loss)
I0526 04:04:00.019816 27450 sgd_solver.cpp:106] Iteration 691500, lr = 0.0005
I0526 04:04:16.752970 27450 solver.cpp:237] Iteration 693000, loss = 1.42836
I0526 04:04:16.753024 27450 solver.cpp:253]     Train net output #0: loss = 1.42835 (* 1 = 1.42835 loss)
I0526 04:04:16.753042 27450 sgd_solver.cpp:106] Iteration 693000, lr = 0.0005
I0526 04:04:33.376576 27450 solver.cpp:237] Iteration 694500, loss = 1.12408
I0526 04:04:33.376754 27450 solver.cpp:253]     Train net output #0: loss = 1.12408 (* 1 = 1.12408 loss)
I0526 04:04:33.376771 27450 sgd_solver.cpp:106] Iteration 694500, lr = 0.0005
I0526 04:04:50.021986 27450 solver.cpp:237] Iteration 696000, loss = 0.753282
I0526 04:04:50.022027 27450 solver.cpp:253]     Train net output #0: loss = 0.753274 (* 1 = 0.753274 loss)
I0526 04:04:50.022044 27450 sgd_solver.cpp:106] Iteration 696000, lr = 0.0005
I0526 04:05:06.850512 27450 solver.cpp:237] Iteration 697500, loss = 1.00441
I0526 04:05:06.850687 27450 solver.cpp:253]     Train net output #0: loss = 1.0044 (* 1 = 1.0044 loss)
I0526 04:05:06.850704 27450 sgd_solver.cpp:106] Iteration 697500, lr = 0.0005
I0526 04:05:23.833940 27450 solver.cpp:237] Iteration 699000, loss = 1.39154
I0526 04:05:23.833994 27450 solver.cpp:253]     Train net output #0: loss = 1.39153 (* 1 = 1.39153 loss)
I0526 04:05:23.834013 27450 sgd_solver.cpp:106] Iteration 699000, lr = 0.0005
I0526 04:06:01.798449 27450 solver.cpp:237] Iteration 700500, loss = 1.18472
I0526 04:06:01.798625 27450 solver.cpp:253]     Train net output #0: loss = 1.18471 (* 1 = 1.18471 loss)
I0526 04:06:01.798642 27450 sgd_solver.cpp:106] Iteration 700500, lr = 0.0005
I0526 04:06:18.859890 27450 solver.cpp:237] Iteration 702000, loss = 0.61093
I0526 04:06:18.859944 27450 solver.cpp:253]     Train net output #0: loss = 0.610921 (* 1 = 0.610921 loss)
I0526 04:06:18.859961 27450 sgd_solver.cpp:106] Iteration 702000, lr = 0.0005
I0526 04:06:35.806396 27450 solver.cpp:237] Iteration 703500, loss = 1.21957
I0526 04:06:35.806581 27450 solver.cpp:253]     Train net output #0: loss = 1.21956 (* 1 = 1.21956 loss)
I0526 04:06:35.806598 27450 sgd_solver.cpp:106] Iteration 703500, lr = 0.0005
I0526 04:06:52.424127 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_705000.caffemodel
I0526 04:06:52.470859 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_705000.solverstate
I0526 04:06:52.500437 27450 solver.cpp:237] Iteration 705000, loss = 2.0958
I0526 04:06:52.500494 27450 solver.cpp:253]     Train net output #0: loss = 2.09579 (* 1 = 2.09579 loss)
I0526 04:06:52.500511 27450 sgd_solver.cpp:106] Iteration 705000, lr = 0.0005
I0526 04:07:09.183399 27450 solver.cpp:237] Iteration 706500, loss = 1.3497
I0526 04:07:09.183579 27450 solver.cpp:253]     Train net output #0: loss = 1.34969 (* 1 = 1.34969 loss)
I0526 04:07:09.183596 27450 sgd_solver.cpp:106] Iteration 706500, lr = 0.0005
I0526 04:07:25.896205 27450 solver.cpp:237] Iteration 708000, loss = 0.872061
I0526 04:07:25.896265 27450 solver.cpp:253]     Train net output #0: loss = 0.872051 (* 1 = 0.872051 loss)
I0526 04:07:25.896291 27450 sgd_solver.cpp:106] Iteration 708000, lr = 0.0005
I0526 04:07:42.944816 27450 solver.cpp:237] Iteration 709500, loss = 0.966911
I0526 04:07:42.944978 27450 solver.cpp:253]     Train net output #0: loss = 0.9669 (* 1 = 0.9669 loss)
I0526 04:07:42.944995 27450 sgd_solver.cpp:106] Iteration 709500, lr = 0.0005
I0526 04:08:20.812561 27450 solver.cpp:237] Iteration 711000, loss = 1.3746
I0526 04:08:20.812744 27450 solver.cpp:253]     Train net output #0: loss = 1.37459 (* 1 = 1.37459 loss)
I0526 04:08:20.812762 27450 sgd_solver.cpp:106] Iteration 711000, lr = 0.0005
I0526 04:08:37.844956 27450 solver.cpp:237] Iteration 712500, loss = 1.16686
I0526 04:08:37.845013 27450 solver.cpp:253]     Train net output #0: loss = 1.16685 (* 1 = 1.16685 loss)
I0526 04:08:37.845031 27450 sgd_solver.cpp:106] Iteration 712500, lr = 0.0005
I0526 04:08:54.486362 27450 solver.cpp:237] Iteration 714000, loss = 1.33952
I0526 04:08:54.486521 27450 solver.cpp:253]     Train net output #0: loss = 1.33951 (* 1 = 1.33951 loss)
I0526 04:08:54.486537 27450 sgd_solver.cpp:106] Iteration 714000, lr = 0.0005
I0526 04:09:11.309916 27450 solver.cpp:237] Iteration 715500, loss = 1.36923
I0526 04:09:11.309973 27450 solver.cpp:253]     Train net output #0: loss = 1.36922 (* 1 = 1.36922 loss)
I0526 04:09:11.309990 27450 sgd_solver.cpp:106] Iteration 715500, lr = 0.0005
I0526 04:09:28.284191 27450 solver.cpp:237] Iteration 717000, loss = 1.35109
I0526 04:09:28.284370 27450 solver.cpp:253]     Train net output #0: loss = 1.35108 (* 1 = 1.35108 loss)
I0526 04:09:28.284389 27450 sgd_solver.cpp:106] Iteration 717000, lr = 0.0005
I0526 04:09:44.958639 27450 solver.cpp:237] Iteration 718500, loss = 1.58711
I0526 04:09:44.958678 27450 solver.cpp:253]     Train net output #0: loss = 1.5871 (* 1 = 1.5871 loss)
I0526 04:09:44.958695 27450 sgd_solver.cpp:106] Iteration 718500, lr = 0.0005
I0526 04:10:01.676961 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_720000.caffemodel
I0526 04:10:01.723752 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_720000.solverstate
I0526 04:10:01.749341 27450 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 04:11:01.290117 27450 solver.cpp:409]     Test net output #0: accuracy = 0.897896
I0526 04:11:01.290305 27450 solver.cpp:409]     Test net output #1: loss = 0.319129 (* 1 = 0.319129 loss)
I0526 04:11:22.156630 27450 solver.cpp:237] Iteration 720000, loss = 1.50428
I0526 04:11:22.156694 27450 solver.cpp:253]     Train net output #0: loss = 1.50427 (* 1 = 1.50427 loss)
I0526 04:11:22.156723 27450 sgd_solver.cpp:106] Iteration 720000, lr = 0.0005
I0526 04:11:39.142400 27450 solver.cpp:237] Iteration 721500, loss = 1.3477
I0526 04:11:39.142585 27450 solver.cpp:253]     Train net output #0: loss = 1.34769 (* 1 = 1.34769 loss)
I0526 04:11:39.142603 27450 sgd_solver.cpp:106] Iteration 721500, lr = 0.0005
I0526 04:11:56.194705 27450 solver.cpp:237] Iteration 723000, loss = 1.00093
I0526 04:11:56.194744 27450 solver.cpp:253]     Train net output #0: loss = 1.00093 (* 1 = 1.00093 loss)
I0526 04:11:56.194761 27450 sgd_solver.cpp:106] Iteration 723000, lr = 0.0005
I0526 04:12:13.402436 27450 solver.cpp:237] Iteration 724500, loss = 1.01406
I0526 04:12:13.402607 27450 solver.cpp:253]     Train net output #0: loss = 1.01405 (* 1 = 1.01405 loss)
I0526 04:12:13.402624 27450 sgd_solver.cpp:106] Iteration 724500, lr = 0.0005
I0526 04:12:30.377120 27450 solver.cpp:237] Iteration 726000, loss = 0.801615
I0526 04:12:30.377176 27450 solver.cpp:253]     Train net output #0: loss = 0.801606 (* 1 = 0.801606 loss)
I0526 04:12:30.377193 27450 sgd_solver.cpp:106] Iteration 726000, lr = 0.0005
I0526 04:12:47.162945 27450 solver.cpp:237] Iteration 727500, loss = 1.27943
I0526 04:12:47.163121 27450 solver.cpp:253]     Train net output #0: loss = 1.27942 (* 1 = 1.27942 loss)
I0526 04:12:47.163139 27450 sgd_solver.cpp:106] Iteration 727500, lr = 0.0005
I0526 04:13:03.813827 27450 solver.cpp:237] Iteration 729000, loss = 0.570461
I0526 04:13:03.813866 27450 solver.cpp:253]     Train net output #0: loss = 0.570452 (* 1 = 0.570452 loss)
I0526 04:13:03.813886 27450 sgd_solver.cpp:106] Iteration 729000, lr = 0.0005
I0526 04:13:41.450280 27450 solver.cpp:237] Iteration 730500, loss = 1.03784
I0526 04:13:41.450466 27450 solver.cpp:253]     Train net output #0: loss = 1.03783 (* 1 = 1.03783 loss)
I0526 04:13:41.450486 27450 sgd_solver.cpp:106] Iteration 730500, lr = 0.0005
I0526 04:13:58.421756 27450 solver.cpp:237] Iteration 732000, loss = 0.637885
I0526 04:13:58.421797 27450 solver.cpp:253]     Train net output #0: loss = 0.637876 (* 1 = 0.637876 loss)
I0526 04:13:58.421815 27450 sgd_solver.cpp:106] Iteration 732000, lr = 0.0005
I0526 04:14:15.590541 27450 solver.cpp:237] Iteration 733500, loss = 0.993444
I0526 04:14:15.590715 27450 solver.cpp:253]     Train net output #0: loss = 0.993435 (* 1 = 0.993435 loss)
I0526 04:14:15.590734 27450 sgd_solver.cpp:106] Iteration 733500, lr = 0.0005
I0526 04:14:32.652474 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_735000.caffemodel
I0526 04:14:32.702908 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_735000.solverstate
I0526 04:14:32.734081 27450 solver.cpp:237] Iteration 735000, loss = 1.64791
I0526 04:14:32.734146 27450 solver.cpp:253]     Train net output #0: loss = 1.6479 (* 1 = 1.6479 loss)
I0526 04:14:32.734164 27450 sgd_solver.cpp:106] Iteration 735000, lr = 0.0005
I0526 04:14:49.639473 27450 solver.cpp:237] Iteration 736500, loss = 0.902874
I0526 04:14:49.639641 27450 solver.cpp:253]     Train net output #0: loss = 0.902865 (* 1 = 0.902865 loss)
I0526 04:14:49.639658 27450 sgd_solver.cpp:106] Iteration 736500, lr = 0.0005
I0526 04:15:06.695339 27450 solver.cpp:237] Iteration 738000, loss = 1.13756
I0526 04:15:06.695392 27450 solver.cpp:253]     Train net output #0: loss = 1.13755 (* 1 = 1.13755 loss)
I0526 04:15:06.695410 27450 sgd_solver.cpp:106] Iteration 738000, lr = 0.0005
I0526 04:15:23.679546 27450 solver.cpp:237] Iteration 739500, loss = 1.26801
I0526 04:15:23.679735 27450 solver.cpp:253]     Train net output #0: loss = 1.26801 (* 1 = 1.26801 loss)
I0526 04:15:23.679754 27450 sgd_solver.cpp:106] Iteration 739500, lr = 0.0005
I0526 04:16:01.364178 27450 solver.cpp:237] Iteration 741000, loss = 0.558899
I0526 04:16:01.364373 27450 solver.cpp:253]     Train net output #0: loss = 0.558891 (* 1 = 0.558891 loss)
I0526 04:16:01.364390 27450 sgd_solver.cpp:106] Iteration 741000, lr = 0.0005
I0526 04:16:18.301404 27450 solver.cpp:237] Iteration 742500, loss = 1.64782
I0526 04:16:18.301455 27450 solver.cpp:253]     Train net output #0: loss = 1.64781 (* 1 = 1.64781 loss)
I0526 04:16:18.301475 27450 sgd_solver.cpp:106] Iteration 742500, lr = 0.0005
I0526 04:16:35.207926 27450 solver.cpp:237] Iteration 744000, loss = 1.01057
I0526 04:16:35.208101 27450 solver.cpp:253]     Train net output #0: loss = 1.01057 (* 1 = 1.01057 loss)
I0526 04:16:35.208120 27450 sgd_solver.cpp:106] Iteration 744000, lr = 0.0005
I0526 04:16:51.798416 27450 solver.cpp:237] Iteration 745500, loss = 1.86168
I0526 04:16:51.798454 27450 solver.cpp:253]     Train net output #0: loss = 1.86167 (* 1 = 1.86167 loss)
I0526 04:16:51.798473 27450 sgd_solver.cpp:106] Iteration 745500, lr = 0.0005
I0526 04:17:08.755662 27450 solver.cpp:237] Iteration 747000, loss = 1.0814
I0526 04:17:08.755903 27450 solver.cpp:253]     Train net output #0: loss = 1.08139 (* 1 = 1.08139 loss)
I0526 04:17:08.755920 27450 sgd_solver.cpp:106] Iteration 747000, lr = 0.0005
I0526 04:17:25.720975 27450 solver.cpp:237] Iteration 748500, loss = 1.18835
I0526 04:17:25.721032 27450 solver.cpp:253]     Train net output #0: loss = 1.18835 (* 1 = 1.18835 loss)
I0526 04:17:25.721057 27450 sgd_solver.cpp:106] Iteration 748500, lr = 0.0005
I0526 04:17:42.341471 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_750000.caffemodel
I0526 04:17:42.390218 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_750000.solverstate
I0526 04:17:42.418074 27450 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 04:19:02.895623 27450 solver.cpp:409]     Test net output #0: accuracy = 0.899261
I0526 04:19:02.895805 27450 solver.cpp:409]     Test net output #1: loss = 0.318663 (* 1 = 0.318663 loss)
I0526 04:19:23.783331 27450 solver.cpp:237] Iteration 750000, loss = 1.44344
I0526 04:19:23.783390 27450 solver.cpp:253]     Train net output #0: loss = 1.44343 (* 1 = 1.44343 loss)
I0526 04:19:23.783416 27450 sgd_solver.cpp:106] Iteration 750000, lr = 0.0005
I0526 04:19:40.959997 27450 solver.cpp:237] Iteration 751500, loss = 0.981158
I0526 04:19:40.960188 27450 solver.cpp:253]     Train net output #0: loss = 0.981149 (* 1 = 0.981149 loss)
I0526 04:19:40.960206 27450 sgd_solver.cpp:106] Iteration 751500, lr = 0.0005
I0526 04:19:58.024401 27450 solver.cpp:237] Iteration 753000, loss = 1.47735
I0526 04:19:58.024458 27450 solver.cpp:253]     Train net output #0: loss = 1.47734 (* 1 = 1.47734 loss)
I0526 04:19:58.024485 27450 sgd_solver.cpp:106] Iteration 753000, lr = 0.0005
I0526 04:20:14.695732 27450 solver.cpp:237] Iteration 754500, loss = 1.93911
I0526 04:20:14.695894 27450 solver.cpp:253]     Train net output #0: loss = 1.9391 (* 1 = 1.9391 loss)
I0526 04:20:14.695910 27450 sgd_solver.cpp:106] Iteration 754500, lr = 0.0005
I0526 04:20:31.622202 27450 solver.cpp:237] Iteration 756000, loss = 1.14625
I0526 04:20:31.622256 27450 solver.cpp:253]     Train net output #0: loss = 1.14624 (* 1 = 1.14624 loss)
I0526 04:20:31.622274 27450 sgd_solver.cpp:106] Iteration 756000, lr = 0.0005
I0526 04:20:48.522656 27450 solver.cpp:237] Iteration 757500, loss = 1.4146
I0526 04:20:48.522832 27450 solver.cpp:253]     Train net output #0: loss = 1.41459 (* 1 = 1.41459 loss)
I0526 04:20:48.522850 27450 sgd_solver.cpp:106] Iteration 757500, lr = 0.0005
I0526 04:21:05.405246 27450 solver.cpp:237] Iteration 759000, loss = 0.829687
I0526 04:21:05.405284 27450 solver.cpp:253]     Train net output #0: loss = 0.829679 (* 1 = 0.829679 loss)
I0526 04:21:05.405303 27450 sgd_solver.cpp:106] Iteration 759000, lr = 0.0005
I0526 04:21:43.310703 27450 solver.cpp:237] Iteration 760500, loss = 1.00573
I0526 04:21:43.310895 27450 solver.cpp:253]     Train net output #0: loss = 1.00573 (* 1 = 1.00573 loss)
I0526 04:21:43.310914 27450 sgd_solver.cpp:106] Iteration 760500, lr = 0.0005
I0526 04:22:00.348072 27450 solver.cpp:237] Iteration 762000, loss = 1.70954
I0526 04:22:00.348130 27450 solver.cpp:253]     Train net output #0: loss = 1.70953 (* 1 = 1.70953 loss)
I0526 04:22:00.348166 27450 sgd_solver.cpp:106] Iteration 762000, lr = 0.0005
I0526 04:22:17.303263 27450 solver.cpp:237] Iteration 763500, loss = 0.780329
I0526 04:22:17.303429 27450 solver.cpp:253]     Train net output #0: loss = 0.780322 (* 1 = 0.780322 loss)
I0526 04:22:17.303447 27450 sgd_solver.cpp:106] Iteration 763500, lr = 0.0005
I0526 04:22:34.227638 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_765000.caffemodel
I0526 04:22:34.274204 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_765000.solverstate
I0526 04:22:34.303719 27450 solver.cpp:237] Iteration 765000, loss = 1.37555
I0526 04:22:34.303774 27450 solver.cpp:253]     Train net output #0: loss = 1.37554 (* 1 = 1.37554 loss)
I0526 04:22:34.303800 27450 sgd_solver.cpp:106] Iteration 765000, lr = 0.0005
I0526 04:22:51.228063 27450 solver.cpp:237] Iteration 766500, loss = 0.156577
I0526 04:22:51.228250 27450 solver.cpp:253]     Train net output #0: loss = 0.15657 (* 1 = 0.15657 loss)
I0526 04:22:51.228268 27450 sgd_solver.cpp:106] Iteration 766500, lr = 0.0005
I0526 04:23:08.299446 27450 solver.cpp:237] Iteration 768000, loss = 0.922534
I0526 04:23:08.299492 27450 solver.cpp:253]     Train net output #0: loss = 0.922526 (* 1 = 0.922526 loss)
I0526 04:23:08.299510 27450 sgd_solver.cpp:106] Iteration 768000, lr = 0.0005
I0526 04:23:25.276726 27450 solver.cpp:237] Iteration 769500, loss = 1.21926
I0526 04:23:25.276898 27450 solver.cpp:253]     Train net output #0: loss = 1.21925 (* 1 = 1.21925 loss)
I0526 04:23:25.276916 27450 sgd_solver.cpp:106] Iteration 769500, lr = 0.0005
I0526 04:24:03.070814 27450 solver.cpp:237] Iteration 771000, loss = 1.23169
I0526 04:24:03.070998 27450 solver.cpp:253]     Train net output #0: loss = 1.23168 (* 1 = 1.23168 loss)
I0526 04:24:03.071023 27450 sgd_solver.cpp:106] Iteration 771000, lr = 0.0005
I0526 04:24:20.150109 27450 solver.cpp:237] Iteration 772500, loss = 0.782821
I0526 04:24:20.150147 27450 solver.cpp:253]     Train net output #0: loss = 0.782813 (* 1 = 0.782813 loss)
I0526 04:24:20.150164 27450 sgd_solver.cpp:106] Iteration 772500, lr = 0.0005
I0526 04:24:36.933655 27450 solver.cpp:237] Iteration 774000, loss = 1.0287
I0526 04:24:36.933830 27450 solver.cpp:253]     Train net output #0: loss = 1.02869 (* 1 = 1.02869 loss)
I0526 04:24:36.933846 27450 sgd_solver.cpp:106] Iteration 774000, lr = 0.0005
I0526 04:24:53.607583 27450 solver.cpp:237] Iteration 775500, loss = 1.14583
I0526 04:24:53.607635 27450 solver.cpp:253]     Train net output #0: loss = 1.14582 (* 1 = 1.14582 loss)
I0526 04:24:53.607652 27450 sgd_solver.cpp:106] Iteration 775500, lr = 0.0005
I0526 04:25:10.349187 27450 solver.cpp:237] Iteration 777000, loss = 1.29371
I0526 04:25:10.349349 27450 solver.cpp:253]     Train net output #0: loss = 1.2937 (* 1 = 1.2937 loss)
I0526 04:25:10.349366 27450 sgd_solver.cpp:106] Iteration 777000, lr = 0.0005
I0526 04:25:27.367786 27450 solver.cpp:237] Iteration 778500, loss = 0.938502
I0526 04:25:27.367847 27450 solver.cpp:253]     Train net output #0: loss = 0.938494 (* 1 = 0.938494 loss)
I0526 04:25:27.367864 27450 sgd_solver.cpp:106] Iteration 778500, lr = 0.0005
I0526 04:25:44.501055 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_780000.caffemodel
I0526 04:25:44.546785 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_780000.solverstate
I0526 04:25:44.572558 27450 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 04:26:43.826117 27450 solver.cpp:409]     Test net output #0: accuracy = 0.900136
I0526 04:26:43.826303 27450 solver.cpp:409]     Test net output #1: loss = 0.318383 (* 1 = 0.318383 loss)
I0526 04:27:04.697824 27450 solver.cpp:237] Iteration 780000, loss = 1.12524
I0526 04:27:04.697888 27450 solver.cpp:253]     Train net output #0: loss = 1.12523 (* 1 = 1.12523 loss)
I0526 04:27:04.697908 27450 sgd_solver.cpp:106] Iteration 780000, lr = 0.0005
I0526 04:27:21.325294 27450 solver.cpp:237] Iteration 781500, loss = 1.03789
I0526 04:27:21.325460 27450 solver.cpp:253]     Train net output #0: loss = 1.03788 (* 1 = 1.03788 loss)
I0526 04:27:21.325477 27450 sgd_solver.cpp:106] Iteration 781500, lr = 0.0005
I0526 04:27:38.010637 27450 solver.cpp:237] Iteration 783000, loss = 0.711652
I0526 04:27:38.010694 27450 solver.cpp:253]     Train net output #0: loss = 0.711644 (* 1 = 0.711644 loss)
I0526 04:27:38.010711 27450 sgd_solver.cpp:106] Iteration 783000, lr = 0.0005
I0526 04:27:54.942760 27450 solver.cpp:237] Iteration 784500, loss = 1.88737
I0526 04:27:54.942941 27450 solver.cpp:253]     Train net output #0: loss = 1.88736 (* 1 = 1.88736 loss)
I0526 04:27:54.942960 27450 sgd_solver.cpp:106] Iteration 784500, lr = 0.0005
I0526 04:28:12.142925 27450 solver.cpp:237] Iteration 786000, loss = 1.02271
I0526 04:28:12.142983 27450 solver.cpp:253]     Train net output #0: loss = 1.02271 (* 1 = 1.02271 loss)
I0526 04:28:12.143012 27450 sgd_solver.cpp:106] Iteration 786000, lr = 0.0005
I0526 04:28:28.795651 27450 solver.cpp:237] Iteration 787500, loss = 0.36078
I0526 04:28:28.795814 27450 solver.cpp:253]     Train net output #0: loss = 0.360773 (* 1 = 0.360773 loss)
I0526 04:28:28.795830 27450 sgd_solver.cpp:106] Iteration 787500, lr = 0.0005
I0526 04:28:45.422592 27450 solver.cpp:237] Iteration 789000, loss = 0.793697
I0526 04:28:45.422651 27450 solver.cpp:253]     Train net output #0: loss = 0.793691 (* 1 = 0.793691 loss)
I0526 04:28:45.422668 27450 sgd_solver.cpp:106] Iteration 789000, lr = 0.0005
I0526 04:29:22.897490 27450 solver.cpp:237] Iteration 790500, loss = 1.57108
I0526 04:29:22.897675 27450 solver.cpp:253]     Train net output #0: loss = 1.57108 (* 1 = 1.57108 loss)
I0526 04:29:22.897693 27450 sgd_solver.cpp:106] Iteration 790500, lr = 0.0005
I0526 04:29:39.950029 27450 solver.cpp:237] Iteration 792000, loss = 1.31997
I0526 04:29:39.950083 27450 solver.cpp:253]     Train net output #0: loss = 1.31997 (* 1 = 1.31997 loss)
I0526 04:29:39.950101 27450 sgd_solver.cpp:106] Iteration 792000, lr = 0.0005
I0526 04:29:57.057324 27450 solver.cpp:237] Iteration 793500, loss = 1.23831
I0526 04:29:57.057507 27450 solver.cpp:253]     Train net output #0: loss = 1.2383 (* 1 = 1.2383 loss)
I0526 04:29:57.057525 27450 sgd_solver.cpp:106] Iteration 793500, lr = 0.0005
I0526 04:30:13.816648 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_795000.caffemodel
I0526 04:30:13.862069 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_795000.solverstate
I0526 04:30:13.891207 27450 solver.cpp:237] Iteration 795000, loss = 1.17207
I0526 04:30:13.891264 27450 solver.cpp:253]     Train net output #0: loss = 1.17206 (* 1 = 1.17206 loss)
I0526 04:30:13.891290 27450 sgd_solver.cpp:106] Iteration 795000, lr = 0.0005
I0526 04:30:30.575042 27450 solver.cpp:237] Iteration 796500, loss = 1.30767
I0526 04:30:30.575237 27450 solver.cpp:253]     Train net output #0: loss = 1.30767 (* 1 = 1.30767 loss)
I0526 04:30:30.575254 27450 sgd_solver.cpp:106] Iteration 796500, lr = 0.0005
I0526 04:30:47.321578 27450 solver.cpp:237] Iteration 798000, loss = 1.25759
I0526 04:30:47.321636 27450 solver.cpp:253]     Train net output #0: loss = 1.25758 (* 1 = 1.25758 loss)
I0526 04:30:47.321662 27450 sgd_solver.cpp:106] Iteration 798000, lr = 0.0005
I0526 04:31:04.184433 27450 solver.cpp:237] Iteration 799500, loss = 1.30612
I0526 04:31:04.184609 27450 solver.cpp:253]     Train net output #0: loss = 1.30611 (* 1 = 1.30611 loss)
I0526 04:31:04.184626 27450 sgd_solver.cpp:106] Iteration 799500, lr = 0.0005
I0526 04:31:41.765874 27450 solver.cpp:237] Iteration 801000, loss = 1.19031
I0526 04:31:41.766064 27450 solver.cpp:253]     Train net output #0: loss = 1.19031 (* 1 = 1.19031 loss)
I0526 04:31:41.766083 27450 sgd_solver.cpp:106] Iteration 801000, lr = 0.0005
I0526 04:31:58.413955 27450 solver.cpp:237] Iteration 802500, loss = 1.17856
I0526 04:31:58.414011 27450 solver.cpp:253]     Train net output #0: loss = 1.17855 (* 1 = 1.17855 loss)
I0526 04:31:58.414029 27450 sgd_solver.cpp:106] Iteration 802500, lr = 0.0005
I0526 04:32:15.228698 27450 solver.cpp:237] Iteration 804000, loss = 0.561629
I0526 04:32:15.228864 27450 solver.cpp:253]     Train net output #0: loss = 0.561622 (* 1 = 0.561622 loss)
I0526 04:32:15.228881 27450 sgd_solver.cpp:106] Iteration 804000, lr = 0.0005
I0526 04:32:32.067778 27450 solver.cpp:237] Iteration 805500, loss = 0.905388
I0526 04:32:32.067836 27450 solver.cpp:253]     Train net output #0: loss = 0.905382 (* 1 = 0.905382 loss)
I0526 04:32:32.067853 27450 sgd_solver.cpp:106] Iteration 805500, lr = 0.0005
I0526 04:32:48.894634 27450 solver.cpp:237] Iteration 807000, loss = 1.74355
I0526 04:32:48.894815 27450 solver.cpp:253]     Train net output #0: loss = 1.74354 (* 1 = 1.74354 loss)
I0526 04:32:48.894832 27450 sgd_solver.cpp:106] Iteration 807000, lr = 0.0005
I0526 04:33:05.538907 27450 solver.cpp:237] Iteration 808500, loss = 1.2753
I0526 04:33:05.538945 27450 solver.cpp:253]     Train net output #0: loss = 1.27529 (* 1 = 1.27529 loss)
I0526 04:33:05.538964 27450 sgd_solver.cpp:106] Iteration 808500, lr = 0.0005
I0526 04:33:22.393488 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_810000.caffemodel
I0526 04:33:22.442674 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_810000.solverstate
I0526 04:33:22.470041 27450 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 04:34:42.768209 27450 solver.cpp:409]     Test net output #0: accuracy = 0.898625
I0526 04:34:42.768399 27450 solver.cpp:409]     Test net output #1: loss = 0.333792 (* 1 = 0.333792 loss)
I0526 04:35:03.642583 27450 solver.cpp:237] Iteration 810000, loss = 1.21021
I0526 04:35:03.642647 27450 solver.cpp:253]     Train net output #0: loss = 1.2102 (* 1 = 1.2102 loss)
I0526 04:35:03.642676 27450 sgd_solver.cpp:106] Iteration 810000, lr = 0.0005
I0526 04:35:20.704850 27450 solver.cpp:237] Iteration 811500, loss = 0.515152
I0526 04:35:20.705039 27450 solver.cpp:253]     Train net output #0: loss = 0.515146 (* 1 = 0.515146 loss)
I0526 04:35:20.705059 27450 sgd_solver.cpp:106] Iteration 811500, lr = 0.0005
I0526 04:35:37.362859 27450 solver.cpp:237] Iteration 813000, loss = 0.825755
I0526 04:35:37.362898 27450 solver.cpp:253]     Train net output #0: loss = 0.825749 (* 1 = 0.825749 loss)
I0526 04:35:37.362916 27450 sgd_solver.cpp:106] Iteration 813000, lr = 0.0005
I0526 04:35:54.435717 27450 solver.cpp:237] Iteration 814500, loss = 0.875871
I0526 04:35:54.435902 27450 solver.cpp:253]     Train net output #0: loss = 0.875866 (* 1 = 0.875866 loss)
I0526 04:35:54.435920 27450 sgd_solver.cpp:106] Iteration 814500, lr = 0.0005
I0526 04:36:11.437880 27450 solver.cpp:237] Iteration 816000, loss = 1.24536
I0526 04:36:11.437935 27450 solver.cpp:253]     Train net output #0: loss = 1.24535 (* 1 = 1.24535 loss)
I0526 04:36:11.437952 27450 sgd_solver.cpp:106] Iteration 816000, lr = 0.0005
I0526 04:36:28.080536 27450 solver.cpp:237] Iteration 817500, loss = 1.14632
I0526 04:36:28.080711 27450 solver.cpp:253]     Train net output #0: loss = 1.14631 (* 1 = 1.14631 loss)
I0526 04:36:28.080729 27450 sgd_solver.cpp:106] Iteration 817500, lr = 0.0005
I0526 04:36:45.054286 27450 solver.cpp:237] Iteration 819000, loss = 0.701295
I0526 04:36:45.054342 27450 solver.cpp:253]     Train net output #0: loss = 0.701289 (* 1 = 0.701289 loss)
I0526 04:36:45.054360 27450 sgd_solver.cpp:106] Iteration 819000, lr = 0.0005
I0526 04:37:22.564790 27450 solver.cpp:237] Iteration 820500, loss = 1.27955
I0526 04:37:22.564980 27450 solver.cpp:253]     Train net output #0: loss = 1.27954 (* 1 = 1.27954 loss)
I0526 04:37:22.564999 27450 sgd_solver.cpp:106] Iteration 820500, lr = 0.0005
I0526 04:37:39.428591 27450 solver.cpp:237] Iteration 822000, loss = 1.10903
I0526 04:37:39.428628 27450 solver.cpp:253]     Train net output #0: loss = 1.10903 (* 1 = 1.10903 loss)
I0526 04:37:39.428645 27450 sgd_solver.cpp:106] Iteration 822000, lr = 0.0005
I0526 04:37:56.255617 27450 solver.cpp:237] Iteration 823500, loss = 0.443744
I0526 04:37:56.255810 27450 solver.cpp:253]     Train net output #0: loss = 0.443738 (* 1 = 0.443738 loss)
I0526 04:37:56.255828 27450 sgd_solver.cpp:106] Iteration 823500, lr = 0.0005
I0526 04:38:13.069804 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_825000.caffemodel
I0526 04:38:13.117822 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_825000.solverstate
I0526 04:38:13.149123 27450 solver.cpp:237] Iteration 825000, loss = 1.53542
I0526 04:38:13.149181 27450 solver.cpp:253]     Train net output #0: loss = 1.53541 (* 1 = 1.53541 loss)
I0526 04:38:13.149209 27450 sgd_solver.cpp:106] Iteration 825000, lr = 0.0005
I0526 04:38:30.110371 27450 solver.cpp:237] Iteration 826500, loss = 1.34897
I0526 04:38:30.110543 27450 solver.cpp:253]     Train net output #0: loss = 1.34897 (* 1 = 1.34897 loss)
I0526 04:38:30.110559 27450 sgd_solver.cpp:106] Iteration 826500, lr = 0.0005
I0526 04:38:47.096714 27450 solver.cpp:237] Iteration 828000, loss = 0.841156
I0526 04:38:47.096772 27450 solver.cpp:253]     Train net output #0: loss = 0.841151 (* 1 = 0.841151 loss)
I0526 04:38:47.096789 27450 sgd_solver.cpp:106] Iteration 828000, lr = 0.0005
I0526 04:39:04.086465 27450 solver.cpp:237] Iteration 829500, loss = 1.39528
I0526 04:39:04.086649 27450 solver.cpp:253]     Train net output #0: loss = 1.39528 (* 1 = 1.39528 loss)
I0526 04:39:04.086668 27450 sgd_solver.cpp:106] Iteration 829500, lr = 0.0005
I0526 04:39:41.600941 27450 solver.cpp:237] Iteration 831000, loss = 0.931736
I0526 04:39:41.601133 27450 solver.cpp:253]     Train net output #0: loss = 0.931732 (* 1 = 0.931732 loss)
I0526 04:39:41.601151 27450 sgd_solver.cpp:106] Iteration 831000, lr = 0.0005
I0526 04:39:58.415930 27450 solver.cpp:237] Iteration 832500, loss = 0.678213
I0526 04:39:58.415985 27450 solver.cpp:253]     Train net output #0: loss = 0.678208 (* 1 = 0.678208 loss)
I0526 04:39:58.416004 27450 sgd_solver.cpp:106] Iteration 832500, lr = 0.0005
I0526 04:40:15.448729 27450 solver.cpp:237] Iteration 834000, loss = 0.854369
I0526 04:40:15.448896 27450 solver.cpp:253]     Train net output #0: loss = 0.854365 (* 1 = 0.854365 loss)
I0526 04:40:15.448914 27450 sgd_solver.cpp:106] Iteration 834000, lr = 0.0005
I0526 04:40:32.419855 27450 solver.cpp:237] Iteration 835500, loss = 0.776017
I0526 04:40:32.419914 27450 solver.cpp:253]     Train net output #0: loss = 0.776013 (* 1 = 0.776013 loss)
I0526 04:40:32.419931 27450 sgd_solver.cpp:106] Iteration 835500, lr = 0.0005
I0526 04:40:49.237815 27450 solver.cpp:237] Iteration 837000, loss = 0.973148
I0526 04:40:49.238013 27450 solver.cpp:253]     Train net output #0: loss = 0.973145 (* 1 = 0.973145 loss)
I0526 04:40:49.238030 27450 sgd_solver.cpp:106] Iteration 837000, lr = 0.0005
I0526 04:41:05.853766 27450 solver.cpp:237] Iteration 838500, loss = 0.789448
I0526 04:41:05.853806 27450 solver.cpp:253]     Train net output #0: loss = 0.789444 (* 1 = 0.789444 loss)
I0526 04:41:05.853823 27450 sgd_solver.cpp:106] Iteration 838500, lr = 0.0005
I0526 04:41:22.496184 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_840000.caffemodel
I0526 04:41:22.541988 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_840000.solverstate
I0526 04:41:22.567441 27450 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 04:42:21.870646 27450 solver.cpp:409]     Test net output #0: accuracy = 0.897697
I0526 04:42:21.870836 27450 solver.cpp:409]     Test net output #1: loss = 0.319354 (* 1 = 0.319354 loss)
I0526 04:42:42.712045 27450 solver.cpp:237] Iteration 840000, loss = 1.05147
I0526 04:42:42.712105 27450 solver.cpp:253]     Train net output #0: loss = 1.05147 (* 1 = 1.05147 loss)
I0526 04:42:42.712131 27450 sgd_solver.cpp:106] Iteration 840000, lr = 0.0005
I0526 04:42:59.656292 27450 solver.cpp:237] Iteration 841500, loss = 0.729505
I0526 04:42:59.656479 27450 solver.cpp:253]     Train net output #0: loss = 0.729501 (* 1 = 0.729501 loss)
I0526 04:42:59.656497 27450 sgd_solver.cpp:106] Iteration 841500, lr = 0.0005
I0526 04:43:16.573393 27450 solver.cpp:237] Iteration 843000, loss = 1.35513
I0526 04:43:16.573451 27450 solver.cpp:253]     Train net output #0: loss = 1.35513 (* 1 = 1.35513 loss)
I0526 04:43:16.573479 27450 sgd_solver.cpp:106] Iteration 843000, lr = 0.0005
I0526 04:43:33.330145 27450 solver.cpp:237] Iteration 844500, loss = 1.20951
I0526 04:43:33.330314 27450 solver.cpp:253]     Train net output #0: loss = 1.20951 (* 1 = 1.20951 loss)
I0526 04:43:33.330332 27450 sgd_solver.cpp:106] Iteration 844500, lr = 0.0005
I0526 04:43:50.373291 27450 solver.cpp:237] Iteration 846000, loss = 0.8416
I0526 04:43:50.373347 27450 solver.cpp:253]     Train net output #0: loss = 0.841596 (* 1 = 0.841596 loss)
I0526 04:43:50.373365 27450 sgd_solver.cpp:106] Iteration 846000, lr = 0.0005
I0526 04:44:07.355592 27450 solver.cpp:237] Iteration 847500, loss = 1.47339
I0526 04:44:07.355779 27450 solver.cpp:253]     Train net output #0: loss = 1.47339 (* 1 = 1.47339 loss)
I0526 04:44:07.355797 27450 sgd_solver.cpp:106] Iteration 847500, lr = 0.0005
I0526 04:44:24.212869 27450 solver.cpp:237] Iteration 849000, loss = 1.1884
I0526 04:44:24.212908 27450 solver.cpp:253]     Train net output #0: loss = 1.1884 (* 1 = 1.1884 loss)
I0526 04:44:24.212925 27450 sgd_solver.cpp:106] Iteration 849000, lr = 0.0005
I0526 04:45:01.721632 27450 solver.cpp:237] Iteration 850500, loss = 1.35069
I0526 04:45:01.721827 27450 solver.cpp:253]     Train net output #0: loss = 1.35069 (* 1 = 1.35069 loss)
I0526 04:45:01.721844 27450 sgd_solver.cpp:106] Iteration 850500, lr = 0.0005
I0526 04:45:18.424290 27450 solver.cpp:237] Iteration 852000, loss = 0.992184
I0526 04:45:18.424350 27450 solver.cpp:253]     Train net output #0: loss = 0.99218 (* 1 = 0.99218 loss)
I0526 04:45:18.424376 27450 sgd_solver.cpp:106] Iteration 852000, lr = 0.0005
I0526 04:45:35.479625 27450 solver.cpp:237] Iteration 853500, loss = 0.720712
I0526 04:45:35.479796 27450 solver.cpp:253]     Train net output #0: loss = 0.720708 (* 1 = 0.720708 loss)
I0526 04:45:35.479814 27450 sgd_solver.cpp:106] Iteration 853500, lr = 0.0005
I0526 04:45:52.645103 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_855000.caffemodel
I0526 04:45:52.692006 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_855000.solverstate
I0526 04:45:52.721086 27450 solver.cpp:237] Iteration 855000, loss = 1.41539
I0526 04:45:52.721143 27450 solver.cpp:253]     Train net output #0: loss = 1.41539 (* 1 = 1.41539 loss)
I0526 04:45:52.721168 27450 sgd_solver.cpp:106] Iteration 855000, lr = 0.0005
I0526 04:46:09.925142 27450 solver.cpp:237] Iteration 856500, loss = 1.13835
I0526 04:46:09.925340 27450 solver.cpp:253]     Train net output #0: loss = 1.13834 (* 1 = 1.13834 loss)
I0526 04:46:09.925359 27450 sgd_solver.cpp:106] Iteration 856500, lr = 0.0005
I0526 04:46:27.024341 27450 solver.cpp:237] Iteration 858000, loss = 0.947612
I0526 04:46:27.024384 27450 solver.cpp:253]     Train net output #0: loss = 0.947607 (* 1 = 0.947607 loss)
I0526 04:46:27.024401 27450 sgd_solver.cpp:106] Iteration 858000, lr = 0.0005
I0526 04:46:43.887856 27450 solver.cpp:237] Iteration 859500, loss = 1.12804
I0526 04:46:43.888044 27450 solver.cpp:253]     Train net output #0: loss = 1.12804 (* 1 = 1.12804 loss)
I0526 04:46:43.888062 27450 sgd_solver.cpp:106] Iteration 859500, lr = 0.0005
I0526 04:47:21.522177 27450 solver.cpp:237] Iteration 861000, loss = 1.57078
I0526 04:47:21.522367 27450 solver.cpp:253]     Train net output #0: loss = 1.57078 (* 1 = 1.57078 loss)
I0526 04:47:21.522384 27450 sgd_solver.cpp:106] Iteration 861000, lr = 0.0005
I0526 04:47:38.565665 27450 solver.cpp:237] Iteration 862500, loss = 1.52636
I0526 04:47:38.565717 27450 solver.cpp:253]     Train net output #0: loss = 1.52635 (* 1 = 1.52635 loss)
I0526 04:47:38.565737 27450 sgd_solver.cpp:106] Iteration 862500, lr = 0.0005
I0526 04:47:55.275456 27450 solver.cpp:237] Iteration 864000, loss = 1.51077
I0526 04:47:55.275641 27450 solver.cpp:253]     Train net output #0: loss = 1.51076 (* 1 = 1.51076 loss)
I0526 04:47:55.275658 27450 sgd_solver.cpp:106] Iteration 864000, lr = 0.0005
I0526 04:48:12.052845 27450 solver.cpp:237] Iteration 865500, loss = 1.3134
I0526 04:48:12.052898 27450 solver.cpp:253]     Train net output #0: loss = 1.3134 (* 1 = 1.3134 loss)
I0526 04:48:12.052916 27450 sgd_solver.cpp:106] Iteration 865500, lr = 0.0005
I0526 04:48:28.686816 27450 solver.cpp:237] Iteration 867000, loss = 0.80711
I0526 04:48:28.686986 27450 solver.cpp:253]     Train net output #0: loss = 0.807104 (* 1 = 0.807104 loss)
I0526 04:48:28.687003 27450 sgd_solver.cpp:106] Iteration 867000, lr = 0.0005
I0526 04:48:45.644158 27450 solver.cpp:237] Iteration 868500, loss = 1.3895
I0526 04:48:45.644214 27450 solver.cpp:253]     Train net output #0: loss = 1.38949 (* 1 = 1.38949 loss)
I0526 04:48:45.644232 27450 sgd_solver.cpp:106] Iteration 868500, lr = 0.0005
I0526 04:49:02.798957 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_870000.caffemodel
I0526 04:49:02.846034 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_870000.solverstate
I0526 04:49:02.871749 27450 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 04:50:23.035562 27450 solver.cpp:409]     Test net output #0: accuracy = 0.90146
I0526 04:50:23.035753 27450 solver.cpp:409]     Test net output #1: loss = 0.305524 (* 1 = 0.305524 loss)
I0526 04:50:43.910663 27450 solver.cpp:237] Iteration 870000, loss = 1.72978
I0526 04:50:43.910722 27450 solver.cpp:253]     Train net output #0: loss = 1.72977 (* 1 = 1.72977 loss)
I0526 04:50:43.910749 27450 sgd_solver.cpp:106] Iteration 870000, lr = 0.0005
I0526 04:51:00.687185 27450 solver.cpp:237] Iteration 871500, loss = 1.34311
I0526 04:51:00.687358 27450 solver.cpp:253]     Train net output #0: loss = 1.3431 (* 1 = 1.3431 loss)
I0526 04:51:00.687376 27450 sgd_solver.cpp:106] Iteration 871500, lr = 0.0005
I0526 04:51:17.365337 27450 solver.cpp:237] Iteration 873000, loss = 1.72368
I0526 04:51:17.365393 27450 solver.cpp:253]     Train net output #0: loss = 1.72368 (* 1 = 1.72368 loss)
I0526 04:51:17.365411 27450 sgd_solver.cpp:106] Iteration 873000, lr = 0.0005
I0526 04:51:33.983031 27450 solver.cpp:237] Iteration 874500, loss = 1.08032
I0526 04:51:33.983229 27450 solver.cpp:253]     Train net output #0: loss = 1.08031 (* 1 = 1.08031 loss)
I0526 04:51:33.983248 27450 sgd_solver.cpp:106] Iteration 874500, lr = 0.0005
I0526 04:51:50.653468 27450 solver.cpp:237] Iteration 876000, loss = 1.33925
I0526 04:51:50.653506 27450 solver.cpp:253]     Train net output #0: loss = 1.33925 (* 1 = 1.33925 loss)
I0526 04:51:50.653530 27450 sgd_solver.cpp:106] Iteration 876000, lr = 0.0005
I0526 04:52:07.659965 27450 solver.cpp:237] Iteration 877500, loss = 1.44971
I0526 04:52:07.660161 27450 solver.cpp:253]     Train net output #0: loss = 1.4497 (* 1 = 1.4497 loss)
I0526 04:52:07.660178 27450 sgd_solver.cpp:106] Iteration 877500, lr = 0.0005
I0526 04:52:24.844744 27450 solver.cpp:237] Iteration 879000, loss = 1.00029
I0526 04:52:24.844800 27450 solver.cpp:253]     Train net output #0: loss = 1.00028 (* 1 = 1.00028 loss)
I0526 04:52:24.844817 27450 sgd_solver.cpp:106] Iteration 879000, lr = 0.0005
I0526 04:53:02.790377 27450 solver.cpp:237] Iteration 880500, loss = 1.10327
I0526 04:53:02.790572 27450 solver.cpp:253]     Train net output #0: loss = 1.10327 (* 1 = 1.10327 loss)
I0526 04:53:02.790591 27450 sgd_solver.cpp:106] Iteration 880500, lr = 0.0005
I0526 04:53:19.708896 27450 solver.cpp:237] Iteration 882000, loss = 0.714164
I0526 04:53:19.708956 27450 solver.cpp:253]     Train net output #0: loss = 0.714158 (* 1 = 0.714158 loss)
I0526 04:53:19.708974 27450 sgd_solver.cpp:106] Iteration 882000, lr = 0.0005
I0526 04:53:36.508728 27450 solver.cpp:237] Iteration 883500, loss = 0.682251
I0526 04:53:36.508900 27450 solver.cpp:253]     Train net output #0: loss = 0.682244 (* 1 = 0.682244 loss)
I0526 04:53:36.508918 27450 sgd_solver.cpp:106] Iteration 883500, lr = 0.0005
I0526 04:53:53.685533 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_885000.caffemodel
I0526 04:53:53.733252 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_885000.solverstate
I0526 04:53:53.764551 27450 solver.cpp:237] Iteration 885000, loss = 1.49115
I0526 04:53:53.764611 27450 solver.cpp:253]     Train net output #0: loss = 1.49115 (* 1 = 1.49115 loss)
I0526 04:53:53.764627 27450 sgd_solver.cpp:106] Iteration 885000, lr = 0.0005
I0526 04:54:10.666190 27450 solver.cpp:237] Iteration 886500, loss = 1.16512
I0526 04:54:10.666381 27450 solver.cpp:253]     Train net output #0: loss = 1.16512 (* 1 = 1.16512 loss)
I0526 04:54:10.666399 27450 sgd_solver.cpp:106] Iteration 886500, lr = 0.0005
I0526 04:54:27.325222 27450 solver.cpp:237] Iteration 888000, loss = 4.22714
I0526 04:54:27.325278 27450 solver.cpp:253]     Train net output #0: loss = 4.22713 (* 1 = 4.22713 loss)
I0526 04:54:27.325294 27450 sgd_solver.cpp:106] Iteration 888000, lr = 0.0005
I0526 04:54:44.389842 27450 solver.cpp:237] Iteration 889500, loss = 1.27508
I0526 04:54:44.390015 27450 solver.cpp:253]     Train net output #0: loss = 1.27507 (* 1 = 1.27507 loss)
I0526 04:54:44.390031 27450 sgd_solver.cpp:106] Iteration 889500, lr = 0.0005
I0526 04:55:22.203817 27450 solver.cpp:237] Iteration 891000, loss = 1.14544
I0526 04:55:22.204012 27450 solver.cpp:253]     Train net output #0: loss = 1.14543 (* 1 = 1.14543 loss)
I0526 04:55:22.204031 27450 sgd_solver.cpp:106] Iteration 891000, lr = 0.0005
I0526 04:55:38.845064 27450 solver.cpp:237] Iteration 892500, loss = 1.49637
I0526 04:55:38.845108 27450 solver.cpp:253]     Train net output #0: loss = 1.49636 (* 1 = 1.49636 loss)
I0526 04:55:38.845124 27450 sgd_solver.cpp:106] Iteration 892500, lr = 0.0005
I0526 04:55:55.946203 27450 solver.cpp:237] Iteration 894000, loss = 1.08124
I0526 04:55:55.946400 27450 solver.cpp:253]     Train net output #0: loss = 1.08123 (* 1 = 1.08123 loss)
I0526 04:55:55.946418 27450 sgd_solver.cpp:106] Iteration 894000, lr = 0.0005
I0526 04:56:12.978847 27450 solver.cpp:237] Iteration 895500, loss = 1.18871
I0526 04:56:12.978904 27450 solver.cpp:253]     Train net output #0: loss = 1.18871 (* 1 = 1.18871 loss)
I0526 04:56:12.978927 27450 sgd_solver.cpp:106] Iteration 895500, lr = 0.0005
I0526 04:56:29.769747 27450 solver.cpp:237] Iteration 897000, loss = 1.06725
I0526 04:56:29.769922 27450 solver.cpp:253]     Train net output #0: loss = 1.06724 (* 1 = 1.06724 loss)
I0526 04:56:29.769938 27450 sgd_solver.cpp:106] Iteration 897000, lr = 0.0005
I0526 04:56:46.419725 27450 solver.cpp:237] Iteration 898500, loss = 0.800667
I0526 04:56:46.419778 27450 solver.cpp:253]     Train net output #0: loss = 0.80066 (* 1 = 0.80066 loss)
I0526 04:56:46.419796 27450 sgd_solver.cpp:106] Iteration 898500, lr = 0.0005
I0526 04:57:03.025614 27450 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_900000.caffemodel
I0526 04:57:03.073859 27450 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_900000.solverstate
I0526 04:57:03.101838 27450 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 04:58:02.529203 27450 solver.cpp:409]     Test net output #0: accuracy = 0.904246
I0526 04:58:02.529397 27450 solver.cpp:409]     Test net output #1: loss = 0.311568 (* 1 = 0.311568 loss)
I0526 04:58:23.414911 27450 solver.cpp:237] Iteration 900000, loss = 1.47146
I0526 04:58:23.414973 27450 solver.cpp:253]     Train net output #0: loss = 1.47145 (* 1 = 1.47145 loss)
I0526 04:58:23.415005 27450 sgd_solver.cpp:106] Iteration 900000, lr = 0.0005
I0526 04:58:40.047484 27450 solver.cpp:237] Iteration 901500, loss = 0.958307
I0526 04:58:40.047678 27450 solver.cpp:253]     Train net output #0: loss = 0.958299 (* 1 = 0.958299 loss)
I0526 04:58:40.047695 27450 sgd_solver.cpp:106] Iteration 901500, lr = 0.0005
I0526 04:58:56.667064 27450 solver.cpp:237] Iteration 903000, loss = 1.06847
I0526 04:58:56.667104 27450 solver.cpp:253]     Train net output #0: loss = 1.06846 (* 1 = 1.06846 loss)
I0526 04:58:56.667122 27450 sgd_solver.cpp:106] Iteration 903000, lr = 0.0005
I0526 04:59:13.472985 27450 solver.cpp:237] Iteration 904500, loss = 0.91941
I0526 04:59:13.473173 27450 solver.cpp:253]     Train net output #0: loss = 0.919402 (* 1 = 0.919402 loss)
I0526 04:59:13.473191 27450 sgd_solver.cpp:106] Iteration 904500, lr = 0.0005
aprun: Apid 11266630: Caught signal Terminated, sending to application
*** Aborted at 1464253153 (unix time) try "date -d @1464253153" if you are using GNU date ***
aprun: Apid 11266630: Caught signal Terminated, sending to application
aprun: Apid 11266630: Caught signal Terminated, sending to application
PC: @     0x2aaab928d328 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
*** SIGTERM (@0x6b37) received by PID 27450 (TID 0x2aaac746f900) from PID 27447; stack trace: ***
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab928d328 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab9288a91 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab9288d63 (unknown)
=>> PBS: job killed: walltime 7228 exceeded limit 7200
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab9261342 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab927da66 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab91d1cf6 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab91d1f13 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaab91bab60 cuLaunchKernel
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaaaace01b0 (unknown)
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @     0x2aaaaacfa6bd cudaLaunch
    @           0x62617f __device_stub__ZN5caffe15DropoutBackwardIfEEviPKT_PKjjfPS1_()
aprun: Apid 11266630: Caught signal Terminated, sending to application
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @           0x626887 caffe::DropoutLayer<>::Backward_gpu()
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @           0x5f02f3 caffe::Net<>::BackwardFromTo()
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @           0x5f033f caffe::Net<>::Backward()
aprun: Apid 11266630: Caught signal Terminated, sending to application
aprun: Apid 11266630: Caught signal Terminated, sending to application
    @           0x5ca111 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 02344] [c6-1c0s4n2] [Thu May 26 04:59:15 2016] PE RANK 0 exit signal Terminated
Application 11266630 exit codes: 143
Application 11266630 resources: utime ~6320s, stime ~896s, Rss ~5329588, inblocks ~10491319, outblocks ~474920
