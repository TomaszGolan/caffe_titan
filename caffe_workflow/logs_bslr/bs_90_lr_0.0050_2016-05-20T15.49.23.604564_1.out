2810391
I0525 12:52:08.562680 21963 caffe.cpp:184] Using GPUs 0
I0525 12:52:09.012922 21963 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1666
test_interval: 3333
base_lr: 0.005
display: 166
max_iter: 166660
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1666
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564.prototxt"
I0525 12:52:09.014689 21963 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564.prototxt
I0525 12:52:09.026377 21963 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 12:52:09.026437 21963 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 12:52:09.026784 21963 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 12:52:09.026965 21963 layer_factory.hpp:77] Creating layer data_hdf5
I0525 12:52:09.026989 21963 net.cpp:106] Creating Layer data_hdf5
I0525 12:52:09.027005 21963 net.cpp:411] data_hdf5 -> data
I0525 12:52:09.027040 21963 net.cpp:411] data_hdf5 -> label
I0525 12:52:09.027071 21963 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 12:52:09.028429 21963 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 12:52:09.045485 21963 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 12:52:30.632119 21963 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 12:52:30.637271 21963 net.cpp:150] Setting up data_hdf5
I0525 12:52:30.637306 21963 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 12:52:30.637322 21963 net.cpp:157] Top shape: 90 (90)
I0525 12:52:30.637332 21963 net.cpp:165] Memory required for data: 2286360
I0525 12:52:30.637346 21963 layer_factory.hpp:77] Creating layer conv1
I0525 12:52:30.637380 21963 net.cpp:106] Creating Layer conv1
I0525 12:52:30.637392 21963 net.cpp:454] conv1 <- data
I0525 12:52:30.637414 21963 net.cpp:411] conv1 -> conv1
I0525 12:52:33.534238 21963 net.cpp:150] Setting up conv1
I0525 12:52:33.534282 21963 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 12:52:33.534293 21963 net.cpp:165] Memory required for data: 27169560
I0525 12:52:33.534324 21963 layer_factory.hpp:77] Creating layer relu1
I0525 12:52:33.534345 21963 net.cpp:106] Creating Layer relu1
I0525 12:52:33.534356 21963 net.cpp:454] relu1 <- conv1
I0525 12:52:33.534369 21963 net.cpp:397] relu1 -> conv1 (in-place)
I0525 12:52:33.534885 21963 net.cpp:150] Setting up relu1
I0525 12:52:33.534903 21963 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 12:52:33.534912 21963 net.cpp:165] Memory required for data: 52052760
I0525 12:52:33.534924 21963 layer_factory.hpp:77] Creating layer pool1
I0525 12:52:33.534940 21963 net.cpp:106] Creating Layer pool1
I0525 12:52:33.534950 21963 net.cpp:454] pool1 <- conv1
I0525 12:52:33.534963 21963 net.cpp:411] pool1 -> pool1
I0525 12:52:33.535043 21963 net.cpp:150] Setting up pool1
I0525 12:52:33.535058 21963 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 12:52:33.535068 21963 net.cpp:165] Memory required for data: 64494360
I0525 12:52:33.535079 21963 layer_factory.hpp:77] Creating layer conv2
I0525 12:52:33.535101 21963 net.cpp:106] Creating Layer conv2
I0525 12:52:33.535111 21963 net.cpp:454] conv2 <- pool1
I0525 12:52:33.535125 21963 net.cpp:411] conv2 -> conv2
I0525 12:52:33.537863 21963 net.cpp:150] Setting up conv2
I0525 12:52:33.537890 21963 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 12:52:33.537900 21963 net.cpp:165] Memory required for data: 82379160
I0525 12:52:33.537920 21963 layer_factory.hpp:77] Creating layer relu2
I0525 12:52:33.537935 21963 net.cpp:106] Creating Layer relu2
I0525 12:52:33.537945 21963 net.cpp:454] relu2 <- conv2
I0525 12:52:33.537956 21963 net.cpp:397] relu2 -> conv2 (in-place)
I0525 12:52:33.538287 21963 net.cpp:150] Setting up relu2
I0525 12:52:33.538302 21963 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 12:52:33.538312 21963 net.cpp:165] Memory required for data: 100263960
I0525 12:52:33.538322 21963 layer_factory.hpp:77] Creating layer pool2
I0525 12:52:33.538336 21963 net.cpp:106] Creating Layer pool2
I0525 12:52:33.538344 21963 net.cpp:454] pool2 <- conv2
I0525 12:52:33.538357 21963 net.cpp:411] pool2 -> pool2
I0525 12:52:33.538439 21963 net.cpp:150] Setting up pool2
I0525 12:52:33.538451 21963 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 12:52:33.538461 21963 net.cpp:165] Memory required for data: 109206360
I0525 12:52:33.538471 21963 layer_factory.hpp:77] Creating layer conv3
I0525 12:52:33.538489 21963 net.cpp:106] Creating Layer conv3
I0525 12:52:33.538499 21963 net.cpp:454] conv3 <- pool2
I0525 12:52:33.538513 21963 net.cpp:411] conv3 -> conv3
I0525 12:52:33.540432 21963 net.cpp:150] Setting up conv3
I0525 12:52:33.540455 21963 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 12:52:33.540468 21963 net.cpp:165] Memory required for data: 118963800
I0525 12:52:33.540487 21963 layer_factory.hpp:77] Creating layer relu3
I0525 12:52:33.540503 21963 net.cpp:106] Creating Layer relu3
I0525 12:52:33.540513 21963 net.cpp:454] relu3 <- conv3
I0525 12:52:33.540524 21963 net.cpp:397] relu3 -> conv3 (in-place)
I0525 12:52:33.540992 21963 net.cpp:150] Setting up relu3
I0525 12:52:33.541009 21963 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 12:52:33.541020 21963 net.cpp:165] Memory required for data: 128721240
I0525 12:52:33.541030 21963 layer_factory.hpp:77] Creating layer pool3
I0525 12:52:33.541043 21963 net.cpp:106] Creating Layer pool3
I0525 12:52:33.541054 21963 net.cpp:454] pool3 <- conv3
I0525 12:52:33.541066 21963 net.cpp:411] pool3 -> pool3
I0525 12:52:33.541133 21963 net.cpp:150] Setting up pool3
I0525 12:52:33.541146 21963 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 12:52:33.541157 21963 net.cpp:165] Memory required for data: 133599960
I0525 12:52:33.541167 21963 layer_factory.hpp:77] Creating layer conv4
I0525 12:52:33.541183 21963 net.cpp:106] Creating Layer conv4
I0525 12:52:33.541194 21963 net.cpp:454] conv4 <- pool3
I0525 12:52:33.541208 21963 net.cpp:411] conv4 -> conv4
I0525 12:52:33.544152 21963 net.cpp:150] Setting up conv4
I0525 12:52:33.544180 21963 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 12:52:33.544190 21963 net.cpp:165] Memory required for data: 136865880
I0525 12:52:33.544206 21963 layer_factory.hpp:77] Creating layer relu4
I0525 12:52:33.544221 21963 net.cpp:106] Creating Layer relu4
I0525 12:52:33.544231 21963 net.cpp:454] relu4 <- conv4
I0525 12:52:33.544244 21963 net.cpp:397] relu4 -> conv4 (in-place)
I0525 12:52:33.544703 21963 net.cpp:150] Setting up relu4
I0525 12:52:33.544718 21963 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 12:52:33.544728 21963 net.cpp:165] Memory required for data: 140131800
I0525 12:52:33.544739 21963 layer_factory.hpp:77] Creating layer pool4
I0525 12:52:33.544751 21963 net.cpp:106] Creating Layer pool4
I0525 12:52:33.544761 21963 net.cpp:454] pool4 <- conv4
I0525 12:52:33.544775 21963 net.cpp:411] pool4 -> pool4
I0525 12:52:33.544842 21963 net.cpp:150] Setting up pool4
I0525 12:52:33.544855 21963 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 12:52:33.544864 21963 net.cpp:165] Memory required for data: 141764760
I0525 12:52:33.544874 21963 layer_factory.hpp:77] Creating layer ip1
I0525 12:52:33.544894 21963 net.cpp:106] Creating Layer ip1
I0525 12:52:33.544904 21963 net.cpp:454] ip1 <- pool4
I0525 12:52:33.544917 21963 net.cpp:411] ip1 -> ip1
I0525 12:52:33.560322 21963 net.cpp:150] Setting up ip1
I0525 12:52:33.560349 21963 net.cpp:157] Top shape: 90 196 (17640)
I0525 12:52:33.560365 21963 net.cpp:165] Memory required for data: 141835320
I0525 12:52:33.560392 21963 layer_factory.hpp:77] Creating layer relu5
I0525 12:52:33.560407 21963 net.cpp:106] Creating Layer relu5
I0525 12:52:33.560417 21963 net.cpp:454] relu5 <- ip1
I0525 12:52:33.560431 21963 net.cpp:397] relu5 -> ip1 (in-place)
I0525 12:52:33.560771 21963 net.cpp:150] Setting up relu5
I0525 12:52:33.560786 21963 net.cpp:157] Top shape: 90 196 (17640)
I0525 12:52:33.560796 21963 net.cpp:165] Memory required for data: 141905880
I0525 12:52:33.560806 21963 layer_factory.hpp:77] Creating layer drop1
I0525 12:52:33.560827 21963 net.cpp:106] Creating Layer drop1
I0525 12:52:33.560837 21963 net.cpp:454] drop1 <- ip1
I0525 12:52:33.560848 21963 net.cpp:397] drop1 -> ip1 (in-place)
I0525 12:52:33.560909 21963 net.cpp:150] Setting up drop1
I0525 12:52:33.560922 21963 net.cpp:157] Top shape: 90 196 (17640)
I0525 12:52:33.560932 21963 net.cpp:165] Memory required for data: 141976440
I0525 12:52:33.560942 21963 layer_factory.hpp:77] Creating layer ip2
I0525 12:52:33.560961 21963 net.cpp:106] Creating Layer ip2
I0525 12:52:33.560972 21963 net.cpp:454] ip2 <- ip1
I0525 12:52:33.560986 21963 net.cpp:411] ip2 -> ip2
I0525 12:52:33.561450 21963 net.cpp:150] Setting up ip2
I0525 12:52:33.561463 21963 net.cpp:157] Top shape: 90 98 (8820)
I0525 12:52:33.561473 21963 net.cpp:165] Memory required for data: 142011720
I0525 12:52:33.561488 21963 layer_factory.hpp:77] Creating layer relu6
I0525 12:52:33.561501 21963 net.cpp:106] Creating Layer relu6
I0525 12:52:33.561511 21963 net.cpp:454] relu6 <- ip2
I0525 12:52:33.561522 21963 net.cpp:397] relu6 -> ip2 (in-place)
I0525 12:52:33.562041 21963 net.cpp:150] Setting up relu6
I0525 12:52:33.562057 21963 net.cpp:157] Top shape: 90 98 (8820)
I0525 12:52:33.562067 21963 net.cpp:165] Memory required for data: 142047000
I0525 12:52:33.562077 21963 layer_factory.hpp:77] Creating layer drop2
I0525 12:52:33.562090 21963 net.cpp:106] Creating Layer drop2
I0525 12:52:33.562100 21963 net.cpp:454] drop2 <- ip2
I0525 12:52:33.562114 21963 net.cpp:397] drop2 -> ip2 (in-place)
I0525 12:52:33.562155 21963 net.cpp:150] Setting up drop2
I0525 12:52:33.562168 21963 net.cpp:157] Top shape: 90 98 (8820)
I0525 12:52:33.562178 21963 net.cpp:165] Memory required for data: 142082280
I0525 12:52:33.562188 21963 layer_factory.hpp:77] Creating layer ip3
I0525 12:52:33.562202 21963 net.cpp:106] Creating Layer ip3
I0525 12:52:33.562212 21963 net.cpp:454] ip3 <- ip2
I0525 12:52:33.562224 21963 net.cpp:411] ip3 -> ip3
I0525 12:52:33.562510 21963 net.cpp:150] Setting up ip3
I0525 12:52:33.562523 21963 net.cpp:157] Top shape: 90 11 (990)
I0525 12:52:33.562533 21963 net.cpp:165] Memory required for data: 142086240
I0525 12:52:33.562548 21963 layer_factory.hpp:77] Creating layer drop3
I0525 12:52:33.562561 21963 net.cpp:106] Creating Layer drop3
I0525 12:52:33.562572 21963 net.cpp:454] drop3 <- ip3
I0525 12:52:33.562583 21963 net.cpp:397] drop3 -> ip3 (in-place)
I0525 12:52:33.562624 21963 net.cpp:150] Setting up drop3
I0525 12:52:33.562638 21963 net.cpp:157] Top shape: 90 11 (990)
I0525 12:52:33.562646 21963 net.cpp:165] Memory required for data: 142090200
I0525 12:52:33.562656 21963 layer_factory.hpp:77] Creating layer loss
I0525 12:52:33.562675 21963 net.cpp:106] Creating Layer loss
I0525 12:52:33.562685 21963 net.cpp:454] loss <- ip3
I0525 12:52:33.562695 21963 net.cpp:454] loss <- label
I0525 12:52:33.562707 21963 net.cpp:411] loss -> loss
I0525 12:52:33.562724 21963 layer_factory.hpp:77] Creating layer loss
I0525 12:52:33.563382 21963 net.cpp:150] Setting up loss
I0525 12:52:33.563403 21963 net.cpp:157] Top shape: (1)
I0525 12:52:33.563416 21963 net.cpp:160]     with loss weight 1
I0525 12:52:33.563459 21963 net.cpp:165] Memory required for data: 142090204
I0525 12:52:33.563470 21963 net.cpp:226] loss needs backward computation.
I0525 12:52:33.563482 21963 net.cpp:226] drop3 needs backward computation.
I0525 12:52:33.563491 21963 net.cpp:226] ip3 needs backward computation.
I0525 12:52:33.563501 21963 net.cpp:226] drop2 needs backward computation.
I0525 12:52:33.563511 21963 net.cpp:226] relu6 needs backward computation.
I0525 12:52:33.563521 21963 net.cpp:226] ip2 needs backward computation.
I0525 12:52:33.563531 21963 net.cpp:226] drop1 needs backward computation.
I0525 12:52:33.563541 21963 net.cpp:226] relu5 needs backward computation.
I0525 12:52:33.563550 21963 net.cpp:226] ip1 needs backward computation.
I0525 12:52:33.563560 21963 net.cpp:226] pool4 needs backward computation.
I0525 12:52:33.563570 21963 net.cpp:226] relu4 needs backward computation.
I0525 12:52:33.563580 21963 net.cpp:226] conv4 needs backward computation.
I0525 12:52:33.563591 21963 net.cpp:226] pool3 needs backward computation.
I0525 12:52:33.563601 21963 net.cpp:226] relu3 needs backward computation.
I0525 12:52:33.563619 21963 net.cpp:226] conv3 needs backward computation.
I0525 12:52:33.563632 21963 net.cpp:226] pool2 needs backward computation.
I0525 12:52:33.563642 21963 net.cpp:226] relu2 needs backward computation.
I0525 12:52:33.563652 21963 net.cpp:226] conv2 needs backward computation.
I0525 12:52:33.563663 21963 net.cpp:226] pool1 needs backward computation.
I0525 12:52:33.563673 21963 net.cpp:226] relu1 needs backward computation.
I0525 12:52:33.563683 21963 net.cpp:226] conv1 needs backward computation.
I0525 12:52:33.563694 21963 net.cpp:228] data_hdf5 does not need backward computation.
I0525 12:52:33.563704 21963 net.cpp:270] This network produces output loss
I0525 12:52:33.563729 21963 net.cpp:283] Network initialization done.
I0525 12:52:33.565449 21963 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564.prototxt
I0525 12:52:33.565521 21963 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 12:52:33.565876 21963 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 12:52:33.566063 21963 layer_factory.hpp:77] Creating layer data_hdf5
I0525 12:52:33.566078 21963 net.cpp:106] Creating Layer data_hdf5
I0525 12:52:33.566092 21963 net.cpp:411] data_hdf5 -> data
I0525 12:52:33.566108 21963 net.cpp:411] data_hdf5 -> label
I0525 12:52:33.566124 21963 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 12:52:33.582792 21963 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 12:52:54.979171 21963 net.cpp:150] Setting up data_hdf5
I0525 12:52:54.979343 21963 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 12:52:54.979357 21963 net.cpp:157] Top shape: 90 (90)
I0525 12:52:54.979368 21963 net.cpp:165] Memory required for data: 2286360
I0525 12:52:54.979382 21963 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 12:52:54.979409 21963 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 12:52:54.979420 21963 net.cpp:454] label_data_hdf5_1_split <- label
I0525 12:52:54.979436 21963 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 12:52:54.979457 21963 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 12:52:54.979532 21963 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 12:52:54.979545 21963 net.cpp:157] Top shape: 90 (90)
I0525 12:52:54.979557 21963 net.cpp:157] Top shape: 90 (90)
I0525 12:52:54.979567 21963 net.cpp:165] Memory required for data: 2287080
I0525 12:52:54.979575 21963 layer_factory.hpp:77] Creating layer conv1
I0525 12:52:54.979595 21963 net.cpp:106] Creating Layer conv1
I0525 12:52:54.979604 21963 net.cpp:454] conv1 <- data
I0525 12:52:54.979619 21963 net.cpp:411] conv1 -> conv1
I0525 12:52:54.981570 21963 net.cpp:150] Setting up conv1
I0525 12:52:54.981593 21963 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 12:52:54.981606 21963 net.cpp:165] Memory required for data: 27170280
I0525 12:52:54.981626 21963 layer_factory.hpp:77] Creating layer relu1
I0525 12:52:54.981640 21963 net.cpp:106] Creating Layer relu1
I0525 12:52:54.981650 21963 net.cpp:454] relu1 <- conv1
I0525 12:52:54.981662 21963 net.cpp:397] relu1 -> conv1 (in-place)
I0525 12:52:54.982154 21963 net.cpp:150] Setting up relu1
I0525 12:52:54.982170 21963 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 12:52:54.982182 21963 net.cpp:165] Memory required for data: 52053480
I0525 12:52:54.982192 21963 layer_factory.hpp:77] Creating layer pool1
I0525 12:52:54.982208 21963 net.cpp:106] Creating Layer pool1
I0525 12:52:54.982218 21963 net.cpp:454] pool1 <- conv1
I0525 12:52:54.982230 21963 net.cpp:411] pool1 -> pool1
I0525 12:52:54.982306 21963 net.cpp:150] Setting up pool1
I0525 12:52:54.982319 21963 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 12:52:54.982328 21963 net.cpp:165] Memory required for data: 64495080
I0525 12:52:54.982336 21963 layer_factory.hpp:77] Creating layer conv2
I0525 12:52:54.982354 21963 net.cpp:106] Creating Layer conv2
I0525 12:52:54.982364 21963 net.cpp:454] conv2 <- pool1
I0525 12:52:54.982378 21963 net.cpp:411] conv2 -> conv2
I0525 12:52:54.984293 21963 net.cpp:150] Setting up conv2
I0525 12:52:54.984315 21963 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 12:52:54.984328 21963 net.cpp:165] Memory required for data: 82379880
I0525 12:52:54.984345 21963 layer_factory.hpp:77] Creating layer relu2
I0525 12:52:54.984359 21963 net.cpp:106] Creating Layer relu2
I0525 12:52:54.984369 21963 net.cpp:454] relu2 <- conv2
I0525 12:52:54.984381 21963 net.cpp:397] relu2 -> conv2 (in-place)
I0525 12:52:54.984715 21963 net.cpp:150] Setting up relu2
I0525 12:52:54.984730 21963 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 12:52:54.984740 21963 net.cpp:165] Memory required for data: 100264680
I0525 12:52:54.984750 21963 layer_factory.hpp:77] Creating layer pool2
I0525 12:52:54.984763 21963 net.cpp:106] Creating Layer pool2
I0525 12:52:54.984773 21963 net.cpp:454] pool2 <- conv2
I0525 12:52:54.984786 21963 net.cpp:411] pool2 -> pool2
I0525 12:52:54.984858 21963 net.cpp:150] Setting up pool2
I0525 12:52:54.984871 21963 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 12:52:54.984881 21963 net.cpp:165] Memory required for data: 109207080
I0525 12:52:54.984891 21963 layer_factory.hpp:77] Creating layer conv3
I0525 12:52:54.984908 21963 net.cpp:106] Creating Layer conv3
I0525 12:52:54.984920 21963 net.cpp:454] conv3 <- pool2
I0525 12:52:54.984933 21963 net.cpp:411] conv3 -> conv3
I0525 12:52:54.986915 21963 net.cpp:150] Setting up conv3
I0525 12:52:54.986937 21963 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 12:52:54.986949 21963 net.cpp:165] Memory required for data: 118964520
I0525 12:52:54.986982 21963 layer_factory.hpp:77] Creating layer relu3
I0525 12:52:54.986995 21963 net.cpp:106] Creating Layer relu3
I0525 12:52:54.987006 21963 net.cpp:454] relu3 <- conv3
I0525 12:52:54.987018 21963 net.cpp:397] relu3 -> conv3 (in-place)
I0525 12:52:54.987499 21963 net.cpp:150] Setting up relu3
I0525 12:52:54.987515 21963 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 12:52:54.987526 21963 net.cpp:165] Memory required for data: 128721960
I0525 12:52:54.987536 21963 layer_factory.hpp:77] Creating layer pool3
I0525 12:52:54.987550 21963 net.cpp:106] Creating Layer pool3
I0525 12:52:54.987560 21963 net.cpp:454] pool3 <- conv3
I0525 12:52:54.987572 21963 net.cpp:411] pool3 -> pool3
I0525 12:52:54.987643 21963 net.cpp:150] Setting up pool3
I0525 12:52:54.987656 21963 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 12:52:54.987665 21963 net.cpp:165] Memory required for data: 133600680
I0525 12:52:54.987676 21963 layer_factory.hpp:77] Creating layer conv4
I0525 12:52:54.987694 21963 net.cpp:106] Creating Layer conv4
I0525 12:52:54.987704 21963 net.cpp:454] conv4 <- pool3
I0525 12:52:54.987718 21963 net.cpp:411] conv4 -> conv4
I0525 12:52:54.989792 21963 net.cpp:150] Setting up conv4
I0525 12:52:54.989815 21963 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 12:52:54.989827 21963 net.cpp:165] Memory required for data: 136866600
I0525 12:52:54.989842 21963 layer_factory.hpp:77] Creating layer relu4
I0525 12:52:54.989856 21963 net.cpp:106] Creating Layer relu4
I0525 12:52:54.989866 21963 net.cpp:454] relu4 <- conv4
I0525 12:52:54.989879 21963 net.cpp:397] relu4 -> conv4 (in-place)
I0525 12:52:54.990350 21963 net.cpp:150] Setting up relu4
I0525 12:52:54.990365 21963 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 12:52:54.990375 21963 net.cpp:165] Memory required for data: 140132520
I0525 12:52:54.990386 21963 layer_factory.hpp:77] Creating layer pool4
I0525 12:52:54.990398 21963 net.cpp:106] Creating Layer pool4
I0525 12:52:54.990408 21963 net.cpp:454] pool4 <- conv4
I0525 12:52:54.990420 21963 net.cpp:411] pool4 -> pool4
I0525 12:52:54.990491 21963 net.cpp:150] Setting up pool4
I0525 12:52:54.990504 21963 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 12:52:54.990514 21963 net.cpp:165] Memory required for data: 141765480
I0525 12:52:54.990523 21963 layer_factory.hpp:77] Creating layer ip1
I0525 12:52:54.990537 21963 net.cpp:106] Creating Layer ip1
I0525 12:52:54.990548 21963 net.cpp:454] ip1 <- pool4
I0525 12:52:54.990561 21963 net.cpp:411] ip1 -> ip1
I0525 12:52:55.006144 21963 net.cpp:150] Setting up ip1
I0525 12:52:55.006171 21963 net.cpp:157] Top shape: 90 196 (17640)
I0525 12:52:55.006187 21963 net.cpp:165] Memory required for data: 141836040
I0525 12:52:55.006211 21963 layer_factory.hpp:77] Creating layer relu5
I0525 12:52:55.006225 21963 net.cpp:106] Creating Layer relu5
I0525 12:52:55.006237 21963 net.cpp:454] relu5 <- ip1
I0525 12:52:55.006249 21963 net.cpp:397] relu5 -> ip1 (in-place)
I0525 12:52:55.006598 21963 net.cpp:150] Setting up relu5
I0525 12:52:55.006613 21963 net.cpp:157] Top shape: 90 196 (17640)
I0525 12:52:55.006623 21963 net.cpp:165] Memory required for data: 141906600
I0525 12:52:55.006633 21963 layer_factory.hpp:77] Creating layer drop1
I0525 12:52:55.006651 21963 net.cpp:106] Creating Layer drop1
I0525 12:52:55.006661 21963 net.cpp:454] drop1 <- ip1
I0525 12:52:55.006672 21963 net.cpp:397] drop1 -> ip1 (in-place)
I0525 12:52:55.006719 21963 net.cpp:150] Setting up drop1
I0525 12:52:55.006732 21963 net.cpp:157] Top shape: 90 196 (17640)
I0525 12:52:55.006744 21963 net.cpp:165] Memory required for data: 141977160
I0525 12:52:55.006753 21963 layer_factory.hpp:77] Creating layer ip2
I0525 12:52:55.006765 21963 net.cpp:106] Creating Layer ip2
I0525 12:52:55.006777 21963 net.cpp:454] ip2 <- ip1
I0525 12:52:55.006789 21963 net.cpp:411] ip2 -> ip2
I0525 12:52:55.007274 21963 net.cpp:150] Setting up ip2
I0525 12:52:55.007287 21963 net.cpp:157] Top shape: 90 98 (8820)
I0525 12:52:55.007297 21963 net.cpp:165] Memory required for data: 142012440
I0525 12:52:55.007313 21963 layer_factory.hpp:77] Creating layer relu6
I0525 12:52:55.007339 21963 net.cpp:106] Creating Layer relu6
I0525 12:52:55.007349 21963 net.cpp:454] relu6 <- ip2
I0525 12:52:55.007361 21963 net.cpp:397] relu6 -> ip2 (in-place)
I0525 12:52:55.007897 21963 net.cpp:150] Setting up relu6
I0525 12:52:55.007918 21963 net.cpp:157] Top shape: 90 98 (8820)
I0525 12:52:55.007928 21963 net.cpp:165] Memory required for data: 142047720
I0525 12:52:55.007938 21963 layer_factory.hpp:77] Creating layer drop2
I0525 12:52:55.007952 21963 net.cpp:106] Creating Layer drop2
I0525 12:52:55.007962 21963 net.cpp:454] drop2 <- ip2
I0525 12:52:55.007974 21963 net.cpp:397] drop2 -> ip2 (in-place)
I0525 12:52:55.008018 21963 net.cpp:150] Setting up drop2
I0525 12:52:55.008031 21963 net.cpp:157] Top shape: 90 98 (8820)
I0525 12:52:55.008041 21963 net.cpp:165] Memory required for data: 142083000
I0525 12:52:55.008050 21963 layer_factory.hpp:77] Creating layer ip3
I0525 12:52:55.008064 21963 net.cpp:106] Creating Layer ip3
I0525 12:52:55.008074 21963 net.cpp:454] ip3 <- ip2
I0525 12:52:55.008087 21963 net.cpp:411] ip3 -> ip3
I0525 12:52:55.008309 21963 net.cpp:150] Setting up ip3
I0525 12:52:55.008322 21963 net.cpp:157] Top shape: 90 11 (990)
I0525 12:52:55.008332 21963 net.cpp:165] Memory required for data: 142086960
I0525 12:52:55.008347 21963 layer_factory.hpp:77] Creating layer drop3
I0525 12:52:55.008360 21963 net.cpp:106] Creating Layer drop3
I0525 12:52:55.008370 21963 net.cpp:454] drop3 <- ip3
I0525 12:52:55.008383 21963 net.cpp:397] drop3 -> ip3 (in-place)
I0525 12:52:55.008424 21963 net.cpp:150] Setting up drop3
I0525 12:52:55.008437 21963 net.cpp:157] Top shape: 90 11 (990)
I0525 12:52:55.008447 21963 net.cpp:165] Memory required for data: 142090920
I0525 12:52:55.008456 21963 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 12:52:55.008471 21963 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 12:52:55.008479 21963 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 12:52:55.008492 21963 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 12:52:55.008507 21963 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 12:52:55.008581 21963 net.cpp:150] Setting up ip3_drop3_0_split
I0525 12:52:55.008594 21963 net.cpp:157] Top shape: 90 11 (990)
I0525 12:52:55.008606 21963 net.cpp:157] Top shape: 90 11 (990)
I0525 12:52:55.008616 21963 net.cpp:165] Memory required for data: 142098840
I0525 12:52:55.008626 21963 layer_factory.hpp:77] Creating layer accuracy
I0525 12:52:55.008647 21963 net.cpp:106] Creating Layer accuracy
I0525 12:52:55.008657 21963 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 12:52:55.008668 21963 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 12:52:55.008682 21963 net.cpp:411] accuracy -> accuracy
I0525 12:52:55.008705 21963 net.cpp:150] Setting up accuracy
I0525 12:52:55.008718 21963 net.cpp:157] Top shape: (1)
I0525 12:52:55.008728 21963 net.cpp:165] Memory required for data: 142098844
I0525 12:52:55.008738 21963 layer_factory.hpp:77] Creating layer loss
I0525 12:52:55.008750 21963 net.cpp:106] Creating Layer loss
I0525 12:52:55.008760 21963 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 12:52:55.008771 21963 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 12:52:55.008785 21963 net.cpp:411] loss -> loss
I0525 12:52:55.008803 21963 layer_factory.hpp:77] Creating layer loss
I0525 12:52:55.009294 21963 net.cpp:150] Setting up loss
I0525 12:52:55.009306 21963 net.cpp:157] Top shape: (1)
I0525 12:52:55.009316 21963 net.cpp:160]     with loss weight 1
I0525 12:52:55.009335 21963 net.cpp:165] Memory required for data: 142098848
I0525 12:52:55.009344 21963 net.cpp:226] loss needs backward computation.
I0525 12:52:55.009356 21963 net.cpp:228] accuracy does not need backward computation.
I0525 12:52:55.009367 21963 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 12:52:55.009377 21963 net.cpp:226] drop3 needs backward computation.
I0525 12:52:55.009387 21963 net.cpp:226] ip3 needs backward computation.
I0525 12:52:55.009398 21963 net.cpp:226] drop2 needs backward computation.
I0525 12:52:55.009407 21963 net.cpp:226] relu6 needs backward computation.
I0525 12:52:55.009425 21963 net.cpp:226] ip2 needs backward computation.
I0525 12:52:55.009435 21963 net.cpp:226] drop1 needs backward computation.
I0525 12:52:55.009444 21963 net.cpp:226] relu5 needs backward computation.
I0525 12:52:55.009454 21963 net.cpp:226] ip1 needs backward computation.
I0525 12:52:55.009464 21963 net.cpp:226] pool4 needs backward computation.
I0525 12:52:55.009474 21963 net.cpp:226] relu4 needs backward computation.
I0525 12:52:55.009485 21963 net.cpp:226] conv4 needs backward computation.
I0525 12:52:55.009495 21963 net.cpp:226] pool3 needs backward computation.
I0525 12:52:55.009505 21963 net.cpp:226] relu3 needs backward computation.
I0525 12:52:55.009516 21963 net.cpp:226] conv3 needs backward computation.
I0525 12:52:55.009526 21963 net.cpp:226] pool2 needs backward computation.
I0525 12:52:55.009536 21963 net.cpp:226] relu2 needs backward computation.
I0525 12:52:55.009546 21963 net.cpp:226] conv2 needs backward computation.
I0525 12:52:55.009555 21963 net.cpp:226] pool1 needs backward computation.
I0525 12:52:55.009567 21963 net.cpp:226] relu1 needs backward computation.
I0525 12:52:55.009575 21963 net.cpp:226] conv1 needs backward computation.
I0525 12:52:55.009588 21963 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 12:52:55.009599 21963 net.cpp:228] data_hdf5 does not need backward computation.
I0525 12:52:55.009609 21963 net.cpp:270] This network produces output accuracy
I0525 12:52:55.009619 21963 net.cpp:270] This network produces output loss
I0525 12:52:55.009647 21963 net.cpp:283] Network initialization done.
I0525 12:52:55.009780 21963 solver.cpp:60] Solver scaffolding done.
I0525 12:52:55.010917 21963 caffe.cpp:212] Starting Optimization
I0525 12:52:55.010936 21963 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 12:52:55.010949 21963 solver.cpp:289] Learning Rate Policy: fixed
I0525 12:52:55.012022 21963 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 12:53:43.153739 21963 solver.cpp:409]     Test net output #0: accuracy = 0.168781
I0525 12:53:43.153895 21963 solver.cpp:409]     Test net output #1: loss = 2.39572 (* 1 = 2.39572 loss)
I0525 12:53:43.185019 21963 solver.cpp:237] Iteration 0, loss = 2.39594
I0525 12:53:43.185055 21963 solver.cpp:253]     Train net output #0: loss = 2.39594 (* 1 = 2.39594 loss)
I0525 12:53:43.185073 21963 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0525 12:53:52.005228 21963 solver.cpp:237] Iteration 166, loss = 2.21219
I0525 12:53:52.005264 21963 solver.cpp:253]     Train net output #0: loss = 2.21219 (* 1 = 2.21219 loss)
I0525 12:53:52.005281 21963 sgd_solver.cpp:106] Iteration 166, lr = 0.005
I0525 12:54:00.835512 21963 solver.cpp:237] Iteration 332, loss = 2.0015
I0525 12:54:00.835547 21963 solver.cpp:253]     Train net output #0: loss = 2.0015 (* 1 = 2.0015 loss)
I0525 12:54:00.835562 21963 sgd_solver.cpp:106] Iteration 332, lr = 0.005
I0525 12:54:09.668690 21963 solver.cpp:237] Iteration 498, loss = 1.96286
I0525 12:54:09.668740 21963 solver.cpp:253]     Train net output #0: loss = 1.96286 (* 1 = 1.96286 loss)
I0525 12:54:09.668753 21963 sgd_solver.cpp:106] Iteration 498, lr = 0.005
I0525 12:54:18.494058 21963 solver.cpp:237] Iteration 664, loss = 1.98042
I0525 12:54:18.494204 21963 solver.cpp:253]     Train net output #0: loss = 1.98042 (* 1 = 1.98042 loss)
I0525 12:54:18.494218 21963 sgd_solver.cpp:106] Iteration 664, lr = 0.005
I0525 12:54:27.328857 21963 solver.cpp:237] Iteration 830, loss = 1.72849
I0525 12:54:27.328892 21963 solver.cpp:253]     Train net output #0: loss = 1.72849 (* 1 = 1.72849 loss)
I0525 12:54:27.328909 21963 sgd_solver.cpp:106] Iteration 830, lr = 0.005
I0525 12:54:36.165385 21963 solver.cpp:237] Iteration 996, loss = 1.73793
I0525 12:54:36.165428 21963 solver.cpp:253]     Train net output #0: loss = 1.73793 (* 1 = 1.73793 loss)
I0525 12:54:36.165446 21963 sgd_solver.cpp:106] Iteration 996, lr = 0.005
I0525 12:55:07.187571 21963 solver.cpp:237] Iteration 1162, loss = 1.6238
I0525 12:55:07.187731 21963 solver.cpp:253]     Train net output #0: loss = 1.6238 (* 1 = 1.6238 loss)
I0525 12:55:07.187747 21963 sgd_solver.cpp:106] Iteration 1162, lr = 0.005
I0525 12:55:16.015745 21963 solver.cpp:237] Iteration 1328, loss = 1.72535
I0525 12:55:16.015779 21963 solver.cpp:253]     Train net output #0: loss = 1.72535 (* 1 = 1.72535 loss)
I0525 12:55:16.015794 21963 sgd_solver.cpp:106] Iteration 1328, lr = 0.005
I0525 12:55:24.856300 21963 solver.cpp:237] Iteration 1494, loss = 1.74923
I0525 12:55:24.856344 21963 solver.cpp:253]     Train net output #0: loss = 1.74923 (* 1 = 1.74923 loss)
I0525 12:55:24.856361 21963 sgd_solver.cpp:106] Iteration 1494, lr = 0.005
I0525 12:55:33.682533 21963 solver.cpp:237] Iteration 1660, loss = 1.54976
I0525 12:55:33.682569 21963 solver.cpp:253]     Train net output #0: loss = 1.54976 (* 1 = 1.54976 loss)
I0525 12:55:33.682585 21963 sgd_solver.cpp:106] Iteration 1660, lr = 0.005
I0525 12:55:33.949092 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_1666.caffemodel
I0525 12:55:34.027894 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_1666.solverstate
I0525 12:55:42.579879 21963 solver.cpp:237] Iteration 1826, loss = 1.57304
I0525 12:55:42.580046 21963 solver.cpp:253]     Train net output #0: loss = 1.57304 (* 1 = 1.57304 loss)
I0525 12:55:42.580060 21963 sgd_solver.cpp:106] Iteration 1826, lr = 0.005
I0525 12:55:51.417464 21963 solver.cpp:237] Iteration 1992, loss = 1.67622
I0525 12:55:51.417510 21963 solver.cpp:253]     Train net output #0: loss = 1.67622 (* 1 = 1.67622 loss)
I0525 12:55:51.417529 21963 sgd_solver.cpp:106] Iteration 1992, lr = 0.005
I0525 12:56:00.252358 21963 solver.cpp:237] Iteration 2158, loss = 1.53461
I0525 12:56:00.252394 21963 solver.cpp:253]     Train net output #0: loss = 1.53461 (* 1 = 1.53461 loss)
I0525 12:56:00.252410 21963 sgd_solver.cpp:106] Iteration 2158, lr = 0.005
I0525 12:56:31.318742 21963 solver.cpp:237] Iteration 2324, loss = 1.4555
I0525 12:56:31.318900 21963 solver.cpp:253]     Train net output #0: loss = 1.4555 (* 1 = 1.4555 loss)
I0525 12:56:31.318917 21963 sgd_solver.cpp:106] Iteration 2324, lr = 0.005
I0525 12:56:40.151554 21963 solver.cpp:237] Iteration 2490, loss = 1.66265
I0525 12:56:40.151592 21963 solver.cpp:253]     Train net output #0: loss = 1.66265 (* 1 = 1.66265 loss)
I0525 12:56:40.151612 21963 sgd_solver.cpp:106] Iteration 2490, lr = 0.005
I0525 12:56:48.982815 21963 solver.cpp:237] Iteration 2656, loss = 1.81099
I0525 12:56:48.982851 21963 solver.cpp:253]     Train net output #0: loss = 1.81099 (* 1 = 1.81099 loss)
I0525 12:56:48.982867 21963 sgd_solver.cpp:106] Iteration 2656, lr = 0.005
I0525 12:56:57.817709 21963 solver.cpp:237] Iteration 2822, loss = 1.38428
I0525 12:56:57.817744 21963 solver.cpp:253]     Train net output #0: loss = 1.38428 (* 1 = 1.38428 loss)
I0525 12:56:57.817760 21963 sgd_solver.cpp:106] Iteration 2822, lr = 0.005
I0525 12:57:06.665398 21963 solver.cpp:237] Iteration 2988, loss = 1.64351
I0525 12:57:06.665570 21963 solver.cpp:253]     Train net output #0: loss = 1.64351 (* 1 = 1.64351 loss)
I0525 12:57:06.665583 21963 sgd_solver.cpp:106] Iteration 2988, lr = 0.005
I0525 12:57:15.502460 21963 solver.cpp:237] Iteration 3154, loss = 1.31228
I0525 12:57:15.502495 21963 solver.cpp:253]     Train net output #0: loss = 1.31228 (* 1 = 1.31228 loss)
I0525 12:57:15.502511 21963 sgd_solver.cpp:106] Iteration 3154, lr = 0.005
I0525 12:57:24.338343 21963 solver.cpp:237] Iteration 3320, loss = 1.65964
I0525 12:57:24.338378 21963 solver.cpp:253]     Train net output #0: loss = 1.65964 (* 1 = 1.65964 loss)
I0525 12:57:24.338394 21963 sgd_solver.cpp:106] Iteration 3320, lr = 0.005
I0525 12:57:24.924013 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_3332.caffemodel
I0525 12:57:24.999622 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_3332.solverstate
I0525 12:57:25.043041 21963 solver.cpp:341] Iteration 3333, Testing net (#0)
I0525 12:58:12.395503 21963 solver.cpp:409]     Test net output #0: accuracy = 0.793447
I0525 12:58:12.395661 21963 solver.cpp:409]     Test net output #1: loss = 0.70413 (* 1 = 0.70413 loss)
I0525 12:58:42.739351 21963 solver.cpp:237] Iteration 3486, loss = 1.48854
I0525 12:58:42.739498 21963 solver.cpp:253]     Train net output #0: loss = 1.48854 (* 1 = 1.48854 loss)
I0525 12:58:42.739513 21963 sgd_solver.cpp:106] Iteration 3486, lr = 0.005
I0525 12:58:51.563915 21963 solver.cpp:237] Iteration 3652, loss = 1.41089
I0525 12:58:51.563951 21963 solver.cpp:253]     Train net output #0: loss = 1.41089 (* 1 = 1.41089 loss)
I0525 12:58:51.563969 21963 sgd_solver.cpp:106] Iteration 3652, lr = 0.005
I0525 12:59:00.402043 21963 solver.cpp:237] Iteration 3818, loss = 1.37081
I0525 12:59:00.402078 21963 solver.cpp:253]     Train net output #0: loss = 1.37081 (* 1 = 1.37081 loss)
I0525 12:59:00.402094 21963 sgd_solver.cpp:106] Iteration 3818, lr = 0.005
I0525 12:59:09.223073 21963 solver.cpp:237] Iteration 3984, loss = 1.46345
I0525 12:59:09.223114 21963 solver.cpp:253]     Train net output #0: loss = 1.46345 (* 1 = 1.46345 loss)
I0525 12:59:09.223132 21963 sgd_solver.cpp:106] Iteration 3984, lr = 0.005
I0525 12:59:18.053748 21963 solver.cpp:237] Iteration 4150, loss = 1.43498
I0525 12:59:18.053886 21963 solver.cpp:253]     Train net output #0: loss = 1.43498 (* 1 = 1.43498 loss)
I0525 12:59:18.053900 21963 sgd_solver.cpp:106] Iteration 4150, lr = 0.005
I0525 12:59:26.879724 21963 solver.cpp:237] Iteration 4316, loss = 1.37006
I0525 12:59:26.879760 21963 solver.cpp:253]     Train net output #0: loss = 1.37006 (* 1 = 1.37006 loss)
I0525 12:59:26.879776 21963 sgd_solver.cpp:106] Iteration 4316, lr = 0.005
I0525 12:59:57.923228 21963 solver.cpp:237] Iteration 4482, loss = 1.49776
I0525 12:59:57.935662 21963 solver.cpp:253]     Train net output #0: loss = 1.49776 (* 1 = 1.49776 loss)
I0525 12:59:57.935679 21963 sgd_solver.cpp:106] Iteration 4482, lr = 0.005
I0525 13:00:06.759635 21963 solver.cpp:237] Iteration 4648, loss = 1.37336
I0525 13:00:06.759671 21963 solver.cpp:253]     Train net output #0: loss = 1.37336 (* 1 = 1.37336 loss)
I0525 13:00:06.759685 21963 sgd_solver.cpp:106] Iteration 4648, lr = 0.005
I0525 13:00:15.584596 21963 solver.cpp:237] Iteration 4814, loss = 1.38208
I0525 13:00:15.584632 21963 solver.cpp:253]     Train net output #0: loss = 1.38208 (* 1 = 1.38208 loss)
I0525 13:00:15.584648 21963 sgd_solver.cpp:106] Iteration 4814, lr = 0.005
I0525 13:00:24.418210 21963 solver.cpp:237] Iteration 4980, loss = 1.19972
I0525 13:00:24.418259 21963 solver.cpp:253]     Train net output #0: loss = 1.19972 (* 1 = 1.19972 loss)
I0525 13:00:24.418273 21963 sgd_solver.cpp:106] Iteration 4980, lr = 0.005
I0525 13:00:25.321959 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_4998.caffemodel
I0525 13:00:25.398075 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_4998.solverstate
I0525 13:00:33.308112 21963 solver.cpp:237] Iteration 5146, loss = 1.16852
I0525 13:00:33.308282 21963 solver.cpp:253]     Train net output #0: loss = 1.16852 (* 1 = 1.16852 loss)
I0525 13:00:33.308296 21963 sgd_solver.cpp:106] Iteration 5146, lr = 0.005
I0525 13:00:42.136703 21963 solver.cpp:237] Iteration 5312, loss = 1.4448
I0525 13:00:42.136734 21963 solver.cpp:253]     Train net output #0: loss = 1.4448 (* 1 = 1.4448 loss)
I0525 13:00:42.136747 21963 sgd_solver.cpp:106] Iteration 5312, lr = 0.005
I0525 13:00:50.960233 21963 solver.cpp:237] Iteration 5478, loss = 1.3296
I0525 13:00:50.960281 21963 solver.cpp:253]     Train net output #0: loss = 1.3296 (* 1 = 1.3296 loss)
I0525 13:00:50.960299 21963 sgd_solver.cpp:106] Iteration 5478, lr = 0.005
I0525 13:01:22.056097 21963 solver.cpp:237] Iteration 5644, loss = 1.24414
I0525 13:01:22.056260 21963 solver.cpp:253]     Train net output #0: loss = 1.24414 (* 1 = 1.24414 loss)
I0525 13:01:22.056277 21963 sgd_solver.cpp:106] Iteration 5644, lr = 0.005
I0525 13:01:30.880477 21963 solver.cpp:237] Iteration 5810, loss = 1.58848
I0525 13:01:30.880511 21963 solver.cpp:253]     Train net output #0: loss = 1.58848 (* 1 = 1.58848 loss)
I0525 13:01:30.880529 21963 sgd_solver.cpp:106] Iteration 5810, lr = 0.005
I0525 13:01:39.712918 21963 solver.cpp:237] Iteration 5976, loss = 1.08861
I0525 13:01:39.712962 21963 solver.cpp:253]     Train net output #0: loss = 1.08861 (* 1 = 1.08861 loss)
I0525 13:01:39.712980 21963 sgd_solver.cpp:106] Iteration 5976, lr = 0.005
I0525 13:01:48.546319 21963 solver.cpp:237] Iteration 6142, loss = 1.27369
I0525 13:01:48.546353 21963 solver.cpp:253]     Train net output #0: loss = 1.27369 (* 1 = 1.27369 loss)
I0525 13:01:48.546370 21963 sgd_solver.cpp:106] Iteration 6142, lr = 0.005
I0525 13:01:57.374213 21963 solver.cpp:237] Iteration 6308, loss = 1.33329
I0525 13:01:57.374351 21963 solver.cpp:253]     Train net output #0: loss = 1.33329 (* 1 = 1.33329 loss)
I0525 13:01:57.374363 21963 sgd_solver.cpp:106] Iteration 6308, lr = 0.005
I0525 13:02:06.202893 21963 solver.cpp:237] Iteration 6474, loss = 1.48477
I0525 13:02:06.202932 21963 solver.cpp:253]     Train net output #0: loss = 1.48477 (* 1 = 1.48477 loss)
I0525 13:02:06.202952 21963 sgd_solver.cpp:106] Iteration 6474, lr = 0.005
I0525 13:02:15.035622 21963 solver.cpp:237] Iteration 6640, loss = 1.19802
I0525 13:02:15.035657 21963 solver.cpp:253]     Train net output #0: loss = 1.19802 (* 1 = 1.19802 loss)
I0525 13:02:15.035676 21963 sgd_solver.cpp:106] Iteration 6640, lr = 0.005
I0525 13:02:16.259727 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_6664.caffemodel
I0525 13:02:16.338335 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_6664.solverstate
I0525 13:02:16.452697 21963 solver.cpp:341] Iteration 6666, Testing net (#0)
I0525 13:03:24.429031 21963 solver.cpp:409]     Test net output #0: accuracy = 0.83444
I0525 13:03:24.429211 21963 solver.cpp:409]     Test net output #1: loss = 0.533403 (* 1 = 0.533403 loss)
I0525 13:03:54.133605 21963 solver.cpp:237] Iteration 6806, loss = 1.38405
I0525 13:03:54.133653 21963 solver.cpp:253]     Train net output #0: loss = 1.38405 (* 1 = 1.38405 loss)
I0525 13:03:54.133667 21963 sgd_solver.cpp:106] Iteration 6806, lr = 0.005
I0525 13:04:02.965543 21963 solver.cpp:237] Iteration 6972, loss = 1.34661
I0525 13:04:02.965689 21963 solver.cpp:253]     Train net output #0: loss = 1.34661 (* 1 = 1.34661 loss)
I0525 13:04:02.965703 21963 sgd_solver.cpp:106] Iteration 6972, lr = 0.005
I0525 13:04:11.805505 21963 solver.cpp:237] Iteration 7138, loss = 1.11992
I0525 13:04:11.805546 21963 solver.cpp:253]     Train net output #0: loss = 1.11992 (* 1 = 1.11992 loss)
I0525 13:04:11.805564 21963 sgd_solver.cpp:106] Iteration 7138, lr = 0.005
I0525 13:04:20.642962 21963 solver.cpp:237] Iteration 7304, loss = 1.30754
I0525 13:04:20.642997 21963 solver.cpp:253]     Train net output #0: loss = 1.30754 (* 1 = 1.30754 loss)
I0525 13:04:20.643013 21963 sgd_solver.cpp:106] Iteration 7304, lr = 0.005
I0525 13:04:29.478849 21963 solver.cpp:237] Iteration 7470, loss = 1.26415
I0525 13:04:29.478884 21963 solver.cpp:253]     Train net output #0: loss = 1.26415 (* 1 = 1.26415 loss)
I0525 13:04:29.478900 21963 sgd_solver.cpp:106] Iteration 7470, lr = 0.005
I0525 13:04:38.316210 21963 solver.cpp:237] Iteration 7636, loss = 1.25276
I0525 13:04:38.316376 21963 solver.cpp:253]     Train net output #0: loss = 1.25276 (* 1 = 1.25276 loss)
I0525 13:04:38.316390 21963 sgd_solver.cpp:106] Iteration 7636, lr = 0.005
I0525 13:05:09.370950 21963 solver.cpp:237] Iteration 7802, loss = 1.28921
I0525 13:05:09.371112 21963 solver.cpp:253]     Train net output #0: loss = 1.28921 (* 1 = 1.28921 loss)
I0525 13:05:09.371129 21963 sgd_solver.cpp:106] Iteration 7802, lr = 0.005
I0525 13:05:18.209282 21963 solver.cpp:237] Iteration 7968, loss = 1.42202
I0525 13:05:18.209317 21963 solver.cpp:253]     Train net output #0: loss = 1.42202 (* 1 = 1.42202 loss)
I0525 13:05:18.209334 21963 sgd_solver.cpp:106] Iteration 7968, lr = 0.005
I0525 13:05:27.044421 21963 solver.cpp:237] Iteration 8134, loss = 1.32365
I0525 13:05:27.044463 21963 solver.cpp:253]     Train net output #0: loss = 1.32365 (* 1 = 1.32365 loss)
I0525 13:05:27.044481 21963 sgd_solver.cpp:106] Iteration 8134, lr = 0.005
I0525 13:05:35.883096 21963 solver.cpp:237] Iteration 8300, loss = 1.1847
I0525 13:05:35.883132 21963 solver.cpp:253]     Train net output #0: loss = 1.1847 (* 1 = 1.1847 loss)
I0525 13:05:35.883148 21963 sgd_solver.cpp:106] Iteration 8300, lr = 0.005
I0525 13:05:37.424702 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_8330.caffemodel
I0525 13:05:37.502195 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_8330.solverstate
I0525 13:05:44.787683 21963 solver.cpp:237] Iteration 8466, loss = 1.46661
I0525 13:05:44.787842 21963 solver.cpp:253]     Train net output #0: loss = 1.46661 (* 1 = 1.46661 loss)
I0525 13:05:44.787855 21963 sgd_solver.cpp:106] Iteration 8466, lr = 0.005
I0525 13:05:53.613281 21963 solver.cpp:237] Iteration 8632, loss = 1.32418
I0525 13:05:53.613329 21963 solver.cpp:253]     Train net output #0: loss = 1.32418 (* 1 = 1.32418 loss)
I0525 13:05:53.613348 21963 sgd_solver.cpp:106] Iteration 8632, lr = 0.005
I0525 13:06:02.447520 21963 solver.cpp:237] Iteration 8798, loss = 1.26593
I0525 13:06:02.447556 21963 solver.cpp:253]     Train net output #0: loss = 1.26593 (* 1 = 1.26593 loss)
I0525 13:06:02.447571 21963 sgd_solver.cpp:106] Iteration 8798, lr = 0.005
I0525 13:06:33.510331 21963 solver.cpp:237] Iteration 8964, loss = 1.24201
I0525 13:06:33.510506 21963 solver.cpp:253]     Train net output #0: loss = 1.24201 (* 1 = 1.24201 loss)
I0525 13:06:33.510522 21963 sgd_solver.cpp:106] Iteration 8964, lr = 0.005
I0525 13:06:42.347949 21963 solver.cpp:237] Iteration 9130, loss = 1.53027
I0525 13:06:42.347990 21963 solver.cpp:253]     Train net output #0: loss = 1.53027 (* 1 = 1.53027 loss)
I0525 13:06:42.348012 21963 sgd_solver.cpp:106] Iteration 9130, lr = 0.005
I0525 13:06:51.186341 21963 solver.cpp:237] Iteration 9296, loss = 1.22303
I0525 13:06:51.186374 21963 solver.cpp:253]     Train net output #0: loss = 1.22303 (* 1 = 1.22303 loss)
I0525 13:06:51.186391 21963 sgd_solver.cpp:106] Iteration 9296, lr = 0.005
I0525 13:07:00.024032 21963 solver.cpp:237] Iteration 9462, loss = 1.29237
I0525 13:07:00.024068 21963 solver.cpp:253]     Train net output #0: loss = 1.29237 (* 1 = 1.29237 loss)
I0525 13:07:00.024085 21963 sgd_solver.cpp:106] Iteration 9462, lr = 0.005
I0525 13:07:08.867900 21963 solver.cpp:237] Iteration 9628, loss = 1.11101
I0525 13:07:08.868054 21963 solver.cpp:253]     Train net output #0: loss = 1.11101 (* 1 = 1.11101 loss)
I0525 13:07:08.868068 21963 sgd_solver.cpp:106] Iteration 9628, lr = 0.005
I0525 13:07:17.697916 21963 solver.cpp:237] Iteration 9794, loss = 1.42273
I0525 13:07:17.697950 21963 solver.cpp:253]     Train net output #0: loss = 1.42273 (* 1 = 1.42273 loss)
I0525 13:07:17.697968 21963 sgd_solver.cpp:106] Iteration 9794, lr = 0.005
I0525 13:07:26.539250 21963 solver.cpp:237] Iteration 9960, loss = 1.08534
I0525 13:07:26.539285 21963 solver.cpp:253]     Train net output #0: loss = 1.08534 (* 1 = 1.08534 loss)
I0525 13:07:26.539301 21963 sgd_solver.cpp:106] Iteration 9960, lr = 0.005
I0525 13:07:28.404609 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_9996.caffemodel
I0525 13:07:28.480370 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_9996.solverstate
I0525 13:07:28.629348 21963 solver.cpp:341] Iteration 9999, Testing net (#0)
I0525 13:08:15.438851 21963 solver.cpp:409]     Test net output #0: accuracy = 0.852462
I0525 13:08:15.439013 21963 solver.cpp:409]     Test net output #1: loss = 0.472664 (* 1 = 0.472664 loss)
I0525 13:08:44.398344 21963 solver.cpp:237] Iteration 10126, loss = 1.19493
I0525 13:08:44.398391 21963 solver.cpp:253]     Train net output #0: loss = 1.19493 (* 1 = 1.19493 loss)
I0525 13:08:44.398409 21963 sgd_solver.cpp:106] Iteration 10126, lr = 0.005
I0525 13:08:53.220685 21963 solver.cpp:237] Iteration 10292, loss = 1.25626
I0525 13:08:53.220834 21963 solver.cpp:253]     Train net output #0: loss = 1.25626 (* 1 = 1.25626 loss)
I0525 13:08:53.220847 21963 sgd_solver.cpp:106] Iteration 10292, lr = 0.005
I0525 13:09:02.044080 21963 solver.cpp:237] Iteration 10458, loss = 1.26283
I0525 13:09:02.044113 21963 solver.cpp:253]     Train net output #0: loss = 1.26283 (* 1 = 1.26283 loss)
I0525 13:09:02.044131 21963 sgd_solver.cpp:106] Iteration 10458, lr = 0.005
I0525 13:09:10.866394 21963 solver.cpp:237] Iteration 10624, loss = 1.18135
I0525 13:09:10.866436 21963 solver.cpp:253]     Train net output #0: loss = 1.18135 (* 1 = 1.18135 loss)
I0525 13:09:10.866452 21963 sgd_solver.cpp:106] Iteration 10624, lr = 0.005
I0525 13:09:19.680498 21963 solver.cpp:237] Iteration 10790, loss = 1.18075
I0525 13:09:19.680533 21963 solver.cpp:253]     Train net output #0: loss = 1.18075 (* 1 = 1.18075 loss)
I0525 13:09:19.680549 21963 sgd_solver.cpp:106] Iteration 10790, lr = 0.005
I0525 13:09:28.500776 21963 solver.cpp:237] Iteration 10956, loss = 1.37327
I0525 13:09:28.500932 21963 solver.cpp:253]     Train net output #0: loss = 1.37327 (* 1 = 1.37327 loss)
I0525 13:09:28.500946 21963 sgd_solver.cpp:106] Iteration 10956, lr = 0.005
I0525 13:09:59.503394 21963 solver.cpp:237] Iteration 11122, loss = 1.10818
I0525 13:09:59.503569 21963 solver.cpp:253]     Train net output #0: loss = 1.10818 (* 1 = 1.10818 loss)
I0525 13:09:59.503585 21963 sgd_solver.cpp:106] Iteration 11122, lr = 0.005
I0525 13:10:08.322127 21963 solver.cpp:237] Iteration 11288, loss = 1.18575
I0525 13:10:08.322160 21963 solver.cpp:253]     Train net output #0: loss = 1.18575 (* 1 = 1.18575 loss)
I0525 13:10:08.322175 21963 sgd_solver.cpp:106] Iteration 11288, lr = 0.005
I0525 13:10:17.142024 21963 solver.cpp:237] Iteration 11454, loss = 1.14649
I0525 13:10:17.142060 21963 solver.cpp:253]     Train net output #0: loss = 1.14649 (* 1 = 1.14649 loss)
I0525 13:10:17.142072 21963 sgd_solver.cpp:106] Iteration 11454, lr = 0.005
I0525 13:10:25.963168 21963 solver.cpp:237] Iteration 11620, loss = 1.2179
I0525 13:10:25.963215 21963 solver.cpp:253]     Train net output #0: loss = 1.2179 (* 1 = 1.2179 loss)
I0525 13:10:25.963230 21963 sgd_solver.cpp:106] Iteration 11620, lr = 0.005
I0525 13:10:28.146445 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_11662.caffemodel
I0525 13:10:28.221009 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_11662.solverstate
I0525 13:10:34.851672 21963 solver.cpp:237] Iteration 11786, loss = 1.22016
I0525 13:10:34.851832 21963 solver.cpp:253]     Train net output #0: loss = 1.22016 (* 1 = 1.22016 loss)
I0525 13:10:34.851846 21963 sgd_solver.cpp:106] Iteration 11786, lr = 0.005
I0525 13:10:43.675237 21963 solver.cpp:237] Iteration 11952, loss = 1.12234
I0525 13:10:43.675271 21963 solver.cpp:253]     Train net output #0: loss = 1.12234 (* 1 = 1.12234 loss)
I0525 13:10:43.675288 21963 sgd_solver.cpp:106] Iteration 11952, lr = 0.005
I0525 13:10:52.499857 21963 solver.cpp:237] Iteration 12118, loss = 1.23656
I0525 13:10:52.499907 21963 solver.cpp:253]     Train net output #0: loss = 1.23656 (* 1 = 1.23656 loss)
I0525 13:10:52.499920 21963 sgd_solver.cpp:106] Iteration 12118, lr = 0.005
I0525 13:11:23.587709 21963 solver.cpp:237] Iteration 12284, loss = 1.21775
I0525 13:11:23.587877 21963 solver.cpp:253]     Train net output #0: loss = 1.21775 (* 1 = 1.21775 loss)
I0525 13:11:23.587893 21963 sgd_solver.cpp:106] Iteration 12284, lr = 0.005
I0525 13:11:32.405145 21963 solver.cpp:237] Iteration 12450, loss = 1.38172
I0525 13:11:32.405180 21963 solver.cpp:253]     Train net output #0: loss = 1.38172 (* 1 = 1.38172 loss)
I0525 13:11:32.405196 21963 sgd_solver.cpp:106] Iteration 12450, lr = 0.005
I0525 13:11:41.232834 21963 solver.cpp:237] Iteration 12616, loss = 1.5277
I0525 13:11:41.232885 21963 solver.cpp:253]     Train net output #0: loss = 1.5277 (* 1 = 1.5277 loss)
I0525 13:11:41.232898 21963 sgd_solver.cpp:106] Iteration 12616, lr = 0.005
I0525 13:11:50.055379 21963 solver.cpp:237] Iteration 12782, loss = 1.38451
I0525 13:11:50.055414 21963 solver.cpp:253]     Train net output #0: loss = 1.38451 (* 1 = 1.38451 loss)
I0525 13:11:50.055430 21963 sgd_solver.cpp:106] Iteration 12782, lr = 0.005
I0525 13:11:58.883477 21963 solver.cpp:237] Iteration 12948, loss = 1.38553
I0525 13:11:58.883618 21963 solver.cpp:253]     Train net output #0: loss = 1.38553 (* 1 = 1.38553 loss)
I0525 13:11:58.883632 21963 sgd_solver.cpp:106] Iteration 12948, lr = 0.005
I0525 13:12:07.701431 21963 solver.cpp:237] Iteration 13114, loss = 1.31431
I0525 13:12:07.701473 21963 solver.cpp:253]     Train net output #0: loss = 1.31431 (* 1 = 1.31431 loss)
I0525 13:12:07.701493 21963 sgd_solver.cpp:106] Iteration 13114, lr = 0.005
I0525 13:12:16.530688 21963 solver.cpp:237] Iteration 13280, loss = 1.16899
I0525 13:12:16.530722 21963 solver.cpp:253]     Train net output #0: loss = 1.16899 (* 1 = 1.16899 loss)
I0525 13:12:16.530740 21963 sgd_solver.cpp:106] Iteration 13280, lr = 0.005
I0525 13:12:19.029543 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_13328.caffemodel
I0525 13:12:19.104321 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_13328.solverstate
I0525 13:12:19.305757 21963 solver.cpp:341] Iteration 13332, Testing net (#0)
I0525 13:13:27.365250 21963 solver.cpp:409]     Test net output #0: accuracy = 0.86813
I0525 13:13:27.365425 21963 solver.cpp:409]     Test net output #1: loss = 0.446282 (* 1 = 0.446282 loss)
I0525 13:13:55.663955 21963 solver.cpp:237] Iteration 13446, loss = 1.46678
I0525 13:13:55.664005 21963 solver.cpp:253]     Train net output #0: loss = 1.46678 (* 1 = 1.46678 loss)
I0525 13:13:55.664021 21963 sgd_solver.cpp:106] Iteration 13446, lr = 0.005
I0525 13:14:04.498610 21963 solver.cpp:237] Iteration 13612, loss = 1.17539
I0525 13:14:04.498764 21963 solver.cpp:253]     Train net output #0: loss = 1.17539 (* 1 = 1.17539 loss)
I0525 13:14:04.498776 21963 sgd_solver.cpp:106] Iteration 13612, lr = 0.005
I0525 13:14:13.337074 21963 solver.cpp:237] Iteration 13778, loss = 1.21078
I0525 13:14:13.337116 21963 solver.cpp:253]     Train net output #0: loss = 1.21078 (* 1 = 1.21078 loss)
I0525 13:14:13.337134 21963 sgd_solver.cpp:106] Iteration 13778, lr = 0.005
I0525 13:14:22.173645 21963 solver.cpp:237] Iteration 13944, loss = 1.37195
I0525 13:14:22.173678 21963 solver.cpp:253]     Train net output #0: loss = 1.37195 (* 1 = 1.37195 loss)
I0525 13:14:22.173696 21963 sgd_solver.cpp:106] Iteration 13944, lr = 0.005
I0525 13:14:31.007639 21963 solver.cpp:237] Iteration 14110, loss = 1.33429
I0525 13:14:31.007674 21963 solver.cpp:253]     Train net output #0: loss = 1.33429 (* 1 = 1.33429 loss)
I0525 13:14:31.007691 21963 sgd_solver.cpp:106] Iteration 14110, lr = 0.005
I0525 13:14:39.849894 21963 solver.cpp:237] Iteration 14276, loss = 1.07026
I0525 13:14:39.850044 21963 solver.cpp:253]     Train net output #0: loss = 1.07026 (* 1 = 1.07026 loss)
I0525 13:14:39.850057 21963 sgd_solver.cpp:106] Iteration 14276, lr = 0.005
I0525 13:14:48.686862 21963 solver.cpp:237] Iteration 14442, loss = 1.28325
I0525 13:14:48.686895 21963 solver.cpp:253]     Train net output #0: loss = 1.28325 (* 1 = 1.28325 loss)
I0525 13:14:48.686913 21963 sgd_solver.cpp:106] Iteration 14442, lr = 0.005
I0525 13:15:19.750172 21963 solver.cpp:237] Iteration 14608, loss = 1.33672
I0525 13:15:19.750335 21963 solver.cpp:253]     Train net output #0: loss = 1.33672 (* 1 = 1.33672 loss)
I0525 13:15:19.750351 21963 sgd_solver.cpp:106] Iteration 14608, lr = 0.005
I0525 13:15:28.587329 21963 solver.cpp:237] Iteration 14774, loss = 1.25808
I0525 13:15:28.587369 21963 solver.cpp:253]     Train net output #0: loss = 1.25808 (* 1 = 1.25808 loss)
I0525 13:15:28.587388 21963 sgd_solver.cpp:106] Iteration 14774, lr = 0.005
I0525 13:15:37.417181 21963 solver.cpp:237] Iteration 14940, loss = 1.14999
I0525 13:15:37.417214 21963 solver.cpp:253]     Train net output #0: loss = 1.14999 (* 1 = 1.14999 loss)
I0525 13:15:37.417232 21963 sgd_solver.cpp:106] Iteration 14940, lr = 0.005
I0525 13:15:40.235399 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_14994.caffemodel
I0525 13:15:40.312842 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_14994.solverstate
I0525 13:15:46.310295 21963 solver.cpp:237] Iteration 15106, loss = 1.09483
I0525 13:15:46.310340 21963 solver.cpp:253]     Train net output #0: loss = 1.09483 (* 1 = 1.09483 loss)
I0525 13:15:46.310358 21963 sgd_solver.cpp:106] Iteration 15106, lr = 0.005
I0525 13:15:55.157662 21963 solver.cpp:237] Iteration 15272, loss = 1.26047
I0525 13:15:55.157819 21963 solver.cpp:253]     Train net output #0: loss = 1.26047 (* 1 = 1.26047 loss)
I0525 13:15:55.157832 21963 sgd_solver.cpp:106] Iteration 15272, lr = 0.005
I0525 13:16:03.998946 21963 solver.cpp:237] Iteration 15438, loss = 1.26135
I0525 13:16:03.998981 21963 solver.cpp:253]     Train net output #0: loss = 1.26135 (* 1 = 1.26135 loss)
I0525 13:16:03.998999 21963 sgd_solver.cpp:106] Iteration 15438, lr = 0.005
I0525 13:16:35.062564 21963 solver.cpp:237] Iteration 15604, loss = 1.37243
I0525 13:16:35.062743 21963 solver.cpp:253]     Train net output #0: loss = 1.37243 (* 1 = 1.37243 loss)
I0525 13:16:35.062758 21963 sgd_solver.cpp:106] Iteration 15604, lr = 0.005
I0525 13:16:43.894759 21963 solver.cpp:237] Iteration 15770, loss = 1.38721
I0525 13:16:43.894804 21963 solver.cpp:253]     Train net output #0: loss = 1.38721 (* 1 = 1.38721 loss)
I0525 13:16:43.894817 21963 sgd_solver.cpp:106] Iteration 15770, lr = 0.005
I0525 13:16:52.730671 21963 solver.cpp:237] Iteration 15936, loss = 1.13972
I0525 13:16:52.730706 21963 solver.cpp:253]     Train net output #0: loss = 1.13972 (* 1 = 1.13972 loss)
I0525 13:16:52.730722 21963 sgd_solver.cpp:106] Iteration 15936, lr = 0.005
I0525 13:17:01.565552 21963 solver.cpp:237] Iteration 16102, loss = 1.23643
I0525 13:17:01.565588 21963 solver.cpp:253]     Train net output #0: loss = 1.23643 (* 1 = 1.23643 loss)
I0525 13:17:01.565603 21963 sgd_solver.cpp:106] Iteration 16102, lr = 0.005
I0525 13:17:10.396816 21963 solver.cpp:237] Iteration 16268, loss = 1.35321
I0525 13:17:10.396970 21963 solver.cpp:253]     Train net output #0: loss = 1.35321 (* 1 = 1.35321 loss)
I0525 13:17:10.396986 21963 sgd_solver.cpp:106] Iteration 16268, lr = 0.005
I0525 13:17:19.230424 21963 solver.cpp:237] Iteration 16434, loss = 1.31604
I0525 13:17:19.230458 21963 solver.cpp:253]     Train net output #0: loss = 1.31604 (* 1 = 1.31604 loss)
I0525 13:17:19.230475 21963 sgd_solver.cpp:106] Iteration 16434, lr = 0.005
I0525 13:17:28.062783 21963 solver.cpp:237] Iteration 16600, loss = 1.28534
I0525 13:17:28.062827 21963 solver.cpp:253]     Train net output #0: loss = 1.28534 (* 1 = 1.28534 loss)
I0525 13:17:28.062844 21963 sgd_solver.cpp:106] Iteration 16600, lr = 0.005
I0525 13:17:31.208649 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_16660.caffemodel
I0525 13:17:31.285544 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_16660.solverstate
I0525 13:17:31.542397 21963 solver.cpp:341] Iteration 16665, Testing net (#0)
I0525 13:18:18.750720 21963 solver.cpp:409]     Test net output #0: accuracy = 0.872805
I0525 13:18:18.750882 21963 solver.cpp:409]     Test net output #1: loss = 0.443072 (* 1 = 0.443072 loss)
I0525 13:18:45.032696 21963 solver.cpp:237] Iteration 16766, loss = 1.20498
I0525 13:18:45.032747 21963 solver.cpp:253]     Train net output #0: loss = 1.20498 (* 1 = 1.20498 loss)
I0525 13:18:45.032763 21963 sgd_solver.cpp:106] Iteration 16766, lr = 0.005
I0525 13:18:53.856750 21963 solver.cpp:237] Iteration 16932, loss = 1.40945
I0525 13:18:53.856899 21963 solver.cpp:253]     Train net output #0: loss = 1.40945 (* 1 = 1.40945 loss)
I0525 13:18:53.856914 21963 sgd_solver.cpp:106] Iteration 16932, lr = 0.005
I0525 13:19:02.684243 21963 solver.cpp:237] Iteration 17098, loss = 1.28523
I0525 13:19:02.684278 21963 solver.cpp:253]     Train net output #0: loss = 1.28523 (* 1 = 1.28523 loss)
I0525 13:19:02.684296 21963 sgd_solver.cpp:106] Iteration 17098, lr = 0.005
I0525 13:19:11.510711 21963 solver.cpp:237] Iteration 17264, loss = 1.22748
I0525 13:19:11.510747 21963 solver.cpp:253]     Train net output #0: loss = 1.22748 (* 1 = 1.22748 loss)
I0525 13:19:11.510766 21963 sgd_solver.cpp:106] Iteration 17264, lr = 0.005
I0525 13:19:20.332270 21963 solver.cpp:237] Iteration 17430, loss = 1.46339
I0525 13:19:20.332304 21963 solver.cpp:253]     Train net output #0: loss = 1.46339 (* 1 = 1.46339 loss)
I0525 13:19:20.332321 21963 sgd_solver.cpp:106] Iteration 17430, lr = 0.005
I0525 13:19:29.150969 21963 solver.cpp:237] Iteration 17596, loss = 1.19384
I0525 13:19:29.151123 21963 solver.cpp:253]     Train net output #0: loss = 1.19384 (* 1 = 1.19384 loss)
I0525 13:19:29.151136 21963 sgd_solver.cpp:106] Iteration 17596, lr = 0.005
I0525 13:19:37.981613 21963 solver.cpp:237] Iteration 17762, loss = 1.18664
I0525 13:19:37.981659 21963 solver.cpp:253]     Train net output #0: loss = 1.18664 (* 1 = 1.18664 loss)
I0525 13:19:37.981673 21963 sgd_solver.cpp:106] Iteration 17762, lr = 0.005
I0525 13:20:07.672744 21963 solver.cpp:237] Iteration 17928, loss = 1.21016
I0525 13:20:07.672912 21963 solver.cpp:253]     Train net output #0: loss = 1.21016 (* 1 = 1.21016 loss)
I0525 13:20:07.672929 21963 sgd_solver.cpp:106] Iteration 17928, lr = 0.005
I0525 13:20:16.507908 21963 solver.cpp:237] Iteration 18094, loss = 1.29738
I0525 13:20:16.507942 21963 solver.cpp:253]     Train net output #0: loss = 1.29738 (* 1 = 1.29738 loss)
I0525 13:20:16.507959 21963 sgd_solver.cpp:106] Iteration 18094, lr = 0.005
I0525 13:20:25.327525 21963 solver.cpp:237] Iteration 18260, loss = 1.21886
I0525 13:20:25.327569 21963 solver.cpp:253]     Train net output #0: loss = 1.21886 (* 1 = 1.21886 loss)
I0525 13:20:25.327589 21963 sgd_solver.cpp:106] Iteration 18260, lr = 0.005
I0525 13:20:28.781903 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_18326.caffemodel
I0525 13:20:28.860795 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_18326.solverstate
I0525 13:20:34.223884 21963 solver.cpp:237] Iteration 18426, loss = 1.37339
I0525 13:20:34.223927 21963 solver.cpp:253]     Train net output #0: loss = 1.37339 (* 1 = 1.37339 loss)
I0525 13:20:34.223943 21963 sgd_solver.cpp:106] Iteration 18426, lr = 0.005
I0525 13:20:43.053877 21963 solver.cpp:237] Iteration 18592, loss = 1.18301
I0525 13:20:43.054038 21963 solver.cpp:253]     Train net output #0: loss = 1.18301 (* 1 = 1.18301 loss)
I0525 13:20:43.054051 21963 sgd_solver.cpp:106] Iteration 18592, lr = 0.005
I0525 13:20:51.884377 21963 solver.cpp:237] Iteration 18758, loss = 1.23031
I0525 13:20:51.884415 21963 solver.cpp:253]     Train net output #0: loss = 1.23031 (* 1 = 1.23031 loss)
I0525 13:20:51.884436 21963 sgd_solver.cpp:106] Iteration 18758, lr = 0.005
I0525 13:21:21.603399 21963 solver.cpp:237] Iteration 18924, loss = 1.07837
I0525 13:21:21.603576 21963 solver.cpp:253]     Train net output #0: loss = 1.07837 (* 1 = 1.07837 loss)
I0525 13:21:21.603590 21963 sgd_solver.cpp:106] Iteration 18924, lr = 0.005
I0525 13:21:30.432075 21963 solver.cpp:237] Iteration 19090, loss = 1.40994
I0525 13:21:30.432108 21963 solver.cpp:253]     Train net output #0: loss = 1.40994 (* 1 = 1.40994 loss)
I0525 13:21:30.432127 21963 sgd_solver.cpp:106] Iteration 19090, lr = 0.005
I0525 13:21:39.261382 21963 solver.cpp:237] Iteration 19256, loss = 1.26441
I0525 13:21:39.261426 21963 solver.cpp:253]     Train net output #0: loss = 1.26441 (* 1 = 1.26441 loss)
I0525 13:21:39.261443 21963 sgd_solver.cpp:106] Iteration 19256, lr = 0.005
I0525 13:21:48.087396 21963 solver.cpp:237] Iteration 19422, loss = 1.29187
I0525 13:21:48.087431 21963 solver.cpp:253]     Train net output #0: loss = 1.29187 (* 1 = 1.29187 loss)
I0525 13:21:48.087448 21963 sgd_solver.cpp:106] Iteration 19422, lr = 0.005
I0525 13:21:56.912750 21963 solver.cpp:237] Iteration 19588, loss = 0.954422
I0525 13:21:56.912891 21963 solver.cpp:253]     Train net output #0: loss = 0.954422 (* 1 = 0.954422 loss)
I0525 13:21:56.912905 21963 sgd_solver.cpp:106] Iteration 19588, lr = 0.005
I0525 13:22:05.738243 21963 solver.cpp:237] Iteration 19754, loss = 1.12604
I0525 13:22:05.738283 21963 solver.cpp:253]     Train net output #0: loss = 1.12604 (* 1 = 1.12604 loss)
I0525 13:22:05.738304 21963 sgd_solver.cpp:106] Iteration 19754, lr = 0.005
I0525 13:22:14.558112 21963 solver.cpp:237] Iteration 19920, loss = 1.14572
I0525 13:22:14.558146 21963 solver.cpp:253]     Train net output #0: loss = 1.14572 (* 1 = 1.14572 loss)
I0525 13:22:14.558163 21963 sgd_solver.cpp:106] Iteration 19920, lr = 0.005
I0525 13:22:18.334789 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_19992.caffemodel
I0525 13:22:18.408999 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_19992.solverstate
I0525 13:22:18.717916 21963 solver.cpp:341] Iteration 19998, Testing net (#0)
I0525 13:23:26.782930 21963 solver.cpp:409]     Test net output #0: accuracy = 0.875674
I0525 13:23:26.783102 21963 solver.cpp:409]     Test net output #1: loss = 0.407087 (* 1 = 0.407087 loss)
I0525 13:23:52.348047 21963 solver.cpp:237] Iteration 20086, loss = 1.25437
I0525 13:23:52.348096 21963 solver.cpp:253]     Train net output #0: loss = 1.25437 (* 1 = 1.25437 loss)
I0525 13:23:52.348109 21963 sgd_solver.cpp:106] Iteration 20086, lr = 0.005
I0525 13:24:01.175139 21963 solver.cpp:237] Iteration 20252, loss = 1.01496
I0525 13:24:01.175298 21963 solver.cpp:253]     Train net output #0: loss = 1.01496 (* 1 = 1.01496 loss)
I0525 13:24:01.175312 21963 sgd_solver.cpp:106] Iteration 20252, lr = 0.005
I0525 13:24:10.001607 21963 solver.cpp:237] Iteration 20418, loss = 1.12442
I0525 13:24:10.001647 21963 solver.cpp:253]     Train net output #0: loss = 1.12442 (* 1 = 1.12442 loss)
I0525 13:24:10.001665 21963 sgd_solver.cpp:106] Iteration 20418, lr = 0.005
I0525 13:24:18.828301 21963 solver.cpp:237] Iteration 20584, loss = 1.32436
I0525 13:24:18.828336 21963 solver.cpp:253]     Train net output #0: loss = 1.32436 (* 1 = 1.32436 loss)
I0525 13:24:18.828352 21963 sgd_solver.cpp:106] Iteration 20584, lr = 0.005
I0525 13:24:27.658295 21963 solver.cpp:237] Iteration 20750, loss = 1.04787
I0525 13:24:27.658330 21963 solver.cpp:253]     Train net output #0: loss = 1.04787 (* 1 = 1.04787 loss)
I0525 13:24:27.658346 21963 sgd_solver.cpp:106] Iteration 20750, lr = 0.005
I0525 13:24:36.490644 21963 solver.cpp:237] Iteration 20916, loss = 1.25761
I0525 13:24:36.490806 21963 solver.cpp:253]     Train net output #0: loss = 1.25761 (* 1 = 1.25761 loss)
I0525 13:24:36.490820 21963 sgd_solver.cpp:106] Iteration 20916, lr = 0.005
I0525 13:24:45.321982 21963 solver.cpp:237] Iteration 21082, loss = 1.15059
I0525 13:24:45.322016 21963 solver.cpp:253]     Train net output #0: loss = 1.15059 (* 1 = 1.15059 loss)
I0525 13:24:45.322033 21963 sgd_solver.cpp:106] Iteration 21082, lr = 0.005
I0525 13:25:15.040877 21963 solver.cpp:237] Iteration 21248, loss = 1.28635
I0525 13:25:15.041043 21963 solver.cpp:253]     Train net output #0: loss = 1.28635 (* 1 = 1.28635 loss)
I0525 13:25:15.041059 21963 sgd_solver.cpp:106] Iteration 21248, lr = 0.005
I0525 13:25:23.878762 21963 solver.cpp:237] Iteration 21414, loss = 1.07227
I0525 13:25:23.878816 21963 solver.cpp:253]     Train net output #0: loss = 1.07227 (* 1 = 1.07227 loss)
I0525 13:25:23.878830 21963 sgd_solver.cpp:106] Iteration 21414, lr = 0.005
I0525 13:25:32.704130 21963 solver.cpp:237] Iteration 21580, loss = 1.24847
I0525 13:25:32.704165 21963 solver.cpp:253]     Train net output #0: loss = 1.24847 (* 1 = 1.24847 loss)
I0525 13:25:32.704182 21963 sgd_solver.cpp:106] Iteration 21580, lr = 0.005
I0525 13:25:36.800709 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_21658.caffemodel
I0525 13:25:36.875033 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_21658.solverstate
I0525 13:25:41.601254 21963 solver.cpp:237] Iteration 21746, loss = 1.19403
I0525 13:25:41.601301 21963 solver.cpp:253]     Train net output #0: loss = 1.19403 (* 1 = 1.19403 loss)
I0525 13:25:41.601315 21963 sgd_solver.cpp:106] Iteration 21746, lr = 0.005
I0525 13:25:50.440284 21963 solver.cpp:237] Iteration 21912, loss = 1.31929
I0525 13:25:50.440459 21963 solver.cpp:253]     Train net output #0: loss = 1.31929 (* 1 = 1.31929 loss)
I0525 13:25:50.440474 21963 sgd_solver.cpp:106] Iteration 21912, lr = 0.005
I0525 13:25:59.275045 21963 solver.cpp:237] Iteration 22078, loss = 1.21947
I0525 13:25:59.275079 21963 solver.cpp:253]     Train net output #0: loss = 1.21947 (* 1 = 1.21947 loss)
I0525 13:25:59.275096 21963 sgd_solver.cpp:106] Iteration 22078, lr = 0.005
I0525 13:26:28.965471 21963 solver.cpp:237] Iteration 22244, loss = 1.2679
I0525 13:26:28.965641 21963 solver.cpp:253]     Train net output #0: loss = 1.2679 (* 1 = 1.2679 loss)
I0525 13:26:28.965656 21963 sgd_solver.cpp:106] Iteration 22244, lr = 0.005
I0525 13:26:37.782981 21963 solver.cpp:237] Iteration 22410, loss = 1.21742
I0525 13:26:37.783015 21963 solver.cpp:253]     Train net output #0: loss = 1.21742 (* 1 = 1.21742 loss)
I0525 13:26:37.783032 21963 sgd_solver.cpp:106] Iteration 22410, lr = 0.005
I0525 13:26:46.602640 21963 solver.cpp:237] Iteration 22576, loss = 1.12844
I0525 13:26:46.602679 21963 solver.cpp:253]     Train net output #0: loss = 1.12844 (* 1 = 1.12844 loss)
I0525 13:26:46.602699 21963 sgd_solver.cpp:106] Iteration 22576, lr = 0.005
I0525 13:26:55.426723 21963 solver.cpp:237] Iteration 22742, loss = 1.16575
I0525 13:26:55.426758 21963 solver.cpp:253]     Train net output #0: loss = 1.16575 (* 1 = 1.16575 loss)
I0525 13:26:55.426774 21963 sgd_solver.cpp:106] Iteration 22742, lr = 0.005
I0525 13:27:04.261461 21963 solver.cpp:237] Iteration 22908, loss = 1.2247
I0525 13:27:04.261620 21963 solver.cpp:253]     Train net output #0: loss = 1.2247 (* 1 = 1.2247 loss)
I0525 13:27:04.261634 21963 sgd_solver.cpp:106] Iteration 22908, lr = 0.005
I0525 13:27:13.087239 21963 solver.cpp:237] Iteration 23074, loss = 1.15494
I0525 13:27:13.087272 21963 solver.cpp:253]     Train net output #0: loss = 1.15494 (* 1 = 1.15494 loss)
I0525 13:27:13.087290 21963 sgd_solver.cpp:106] Iteration 23074, lr = 0.005
I0525 13:27:21.921502 21963 solver.cpp:237] Iteration 23240, loss = 0.928635
I0525 13:27:21.921532 21963 solver.cpp:253]     Train net output #0: loss = 0.928635 (* 1 = 0.928635 loss)
I0525 13:27:21.921550 21963 sgd_solver.cpp:106] Iteration 23240, lr = 0.005
I0525 13:27:26.336114 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_23324.caffemodel
I0525 13:27:26.412422 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_23324.solverstate
I0525 13:27:26.774034 21963 solver.cpp:341] Iteration 23331, Testing net (#0)
I0525 13:28:13.592658 21963 solver.cpp:409]     Test net output #0: accuracy = 0.878701
I0525 13:28:13.592828 21963 solver.cpp:409]     Test net output #1: loss = 0.42289 (* 1 = 0.42289 loss)
I0525 13:28:38.511802 21963 solver.cpp:237] Iteration 23406, loss = 1.25793
I0525 13:28:38.511853 21963 solver.cpp:253]     Train net output #0: loss = 1.25793 (* 1 = 1.25793 loss)
I0525 13:28:38.511868 21963 sgd_solver.cpp:106] Iteration 23406, lr = 0.005
I0525 13:28:47.348821 21963 solver.cpp:237] Iteration 23572, loss = 1.18662
I0525 13:28:47.348990 21963 solver.cpp:253]     Train net output #0: loss = 1.18662 (* 1 = 1.18662 loss)
I0525 13:28:47.349004 21963 sgd_solver.cpp:106] Iteration 23572, lr = 0.005
I0525 13:28:56.183244 21963 solver.cpp:237] Iteration 23738, loss = 1.02858
I0525 13:28:56.183279 21963 solver.cpp:253]     Train net output #0: loss = 1.02858 (* 1 = 1.02858 loss)
I0525 13:28:56.183295 21963 sgd_solver.cpp:106] Iteration 23738, lr = 0.005
I0525 13:29:05.015282 21963 solver.cpp:237] Iteration 23904, loss = 0.97875
I0525 13:29:05.015317 21963 solver.cpp:253]     Train net output #0: loss = 0.97875 (* 1 = 0.97875 loss)
I0525 13:29:05.015334 21963 sgd_solver.cpp:106] Iteration 23904, lr = 0.005
I0525 13:29:13.859900 21963 solver.cpp:237] Iteration 24070, loss = 1.35884
I0525 13:29:13.859947 21963 solver.cpp:253]     Train net output #0: loss = 1.35884 (* 1 = 1.35884 loss)
I0525 13:29:13.859963 21963 sgd_solver.cpp:106] Iteration 24070, lr = 0.005
I0525 13:29:22.700865 21963 solver.cpp:237] Iteration 24236, loss = 1.11346
I0525 13:29:22.701025 21963 solver.cpp:253]     Train net output #0: loss = 1.11346 (* 1 = 1.11346 loss)
I0525 13:29:22.701038 21963 sgd_solver.cpp:106] Iteration 24236, lr = 0.005
I0525 13:29:31.530217 21963 solver.cpp:237] Iteration 24402, loss = 1.32707
I0525 13:29:31.530251 21963 solver.cpp:253]     Train net output #0: loss = 1.32707 (* 1 = 1.32707 loss)
I0525 13:29:31.530268 21963 sgd_solver.cpp:106] Iteration 24402, lr = 0.005
I0525 13:30:01.290766 21963 solver.cpp:237] Iteration 24568, loss = 1.07888
I0525 13:30:01.290941 21963 solver.cpp:253]     Train net output #0: loss = 1.07888 (* 1 = 1.07888 loss)
I0525 13:30:01.290956 21963 sgd_solver.cpp:106] Iteration 24568, lr = 0.005
I0525 13:30:10.133319 21963 solver.cpp:237] Iteration 24734, loss = 1.18405
I0525 13:30:10.133354 21963 solver.cpp:253]     Train net output #0: loss = 1.18405 (* 1 = 1.18405 loss)
I0525 13:30:10.133371 21963 sgd_solver.cpp:106] Iteration 24734, lr = 0.005
I0525 13:30:18.964651 21963 solver.cpp:237] Iteration 24900, loss = 1.23358
I0525 13:30:18.964687 21963 solver.cpp:253]     Train net output #0: loss = 1.23358 (* 1 = 1.23358 loss)
I0525 13:30:18.964704 21963 sgd_solver.cpp:106] Iteration 24900, lr = 0.005
I0525 13:30:23.709363 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_24990.caffemodel
I0525 13:30:23.785909 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_24990.solverstate
I0525 13:30:27.876256 21963 solver.cpp:237] Iteration 25066, loss = 1.04087
I0525 13:30:27.876302 21963 solver.cpp:253]     Train net output #0: loss = 1.04087 (* 1 = 1.04087 loss)
I0525 13:30:27.876317 21963 sgd_solver.cpp:106] Iteration 25066, lr = 0.005
I0525 13:30:36.709393 21963 solver.cpp:237] Iteration 25232, loss = 1.15453
I0525 13:30:36.709558 21963 solver.cpp:253]     Train net output #0: loss = 1.15453 (* 1 = 1.15453 loss)
I0525 13:30:36.709571 21963 sgd_solver.cpp:106] Iteration 25232, lr = 0.005
I0525 13:30:45.546788 21963 solver.cpp:237] Iteration 25398, loss = 0.93773
I0525 13:30:45.546823 21963 solver.cpp:253]     Train net output #0: loss = 0.93773 (* 1 = 0.93773 loss)
I0525 13:30:45.546840 21963 sgd_solver.cpp:106] Iteration 25398, lr = 0.005
I0525 13:31:15.297245 21963 solver.cpp:237] Iteration 25564, loss = 1.31087
I0525 13:31:15.297416 21963 solver.cpp:253]     Train net output #0: loss = 1.31087 (* 1 = 1.31087 loss)
I0525 13:31:15.297431 21963 sgd_solver.cpp:106] Iteration 25564, lr = 0.005
I0525 13:31:24.134531 21963 solver.cpp:237] Iteration 25730, loss = 1.11586
I0525 13:31:24.134562 21963 solver.cpp:253]     Train net output #0: loss = 1.11586 (* 1 = 1.11586 loss)
I0525 13:31:24.134588 21963 sgd_solver.cpp:106] Iteration 25730, lr = 0.005
I0525 13:31:32.965129 21963 solver.cpp:237] Iteration 25896, loss = 1.11674
I0525 13:31:32.965165 21963 solver.cpp:253]     Train net output #0: loss = 1.11674 (* 1 = 1.11674 loss)
I0525 13:31:32.965181 21963 sgd_solver.cpp:106] Iteration 25896, lr = 0.005
I0525 13:31:41.798620 21963 solver.cpp:237] Iteration 26062, loss = 1.36988
I0525 13:31:41.798668 21963 solver.cpp:253]     Train net output #0: loss = 1.36988 (* 1 = 1.36988 loss)
I0525 13:31:41.798682 21963 sgd_solver.cpp:106] Iteration 26062, lr = 0.005
I0525 13:31:50.627358 21963 solver.cpp:237] Iteration 26228, loss = 1.26422
I0525 13:31:50.627511 21963 solver.cpp:253]     Train net output #0: loss = 1.26422 (* 1 = 1.26422 loss)
I0525 13:31:50.627526 21963 sgd_solver.cpp:106] Iteration 26228, lr = 0.005
I0525 13:31:59.460063 21963 solver.cpp:237] Iteration 26394, loss = 1.14624
I0525 13:31:59.460098 21963 solver.cpp:253]     Train net output #0: loss = 1.14624 (* 1 = 1.14624 loss)
I0525 13:31:59.460115 21963 sgd_solver.cpp:106] Iteration 26394, lr = 0.005
I0525 13:32:08.294028 21963 solver.cpp:237] Iteration 26560, loss = 1.44568
I0525 13:32:08.294061 21963 solver.cpp:253]     Train net output #0: loss = 1.44568 (* 1 = 1.44568 loss)
I0525 13:32:08.294083 21963 sgd_solver.cpp:106] Iteration 26560, lr = 0.005
I0525 13:32:13.351433 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_26656.caffemodel
I0525 13:32:13.426173 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_26656.solverstate
I0525 13:32:13.841614 21963 solver.cpp:341] Iteration 26664, Testing net (#0)
I0525 13:33:21.889863 21963 solver.cpp:409]     Test net output #0: accuracy = 0.881497
I0525 13:33:21.890043 21963 solver.cpp:409]     Test net output #1: loss = 0.370925 (* 1 = 0.370925 loss)
I0525 13:33:46.076232 21963 solver.cpp:237] Iteration 26726, loss = 1.03104
I0525 13:33:46.076282 21963 solver.cpp:253]     Train net output #0: loss = 1.03104 (* 1 = 1.03104 loss)
I0525 13:33:46.076299 21963 sgd_solver.cpp:106] Iteration 26726, lr = 0.005
I0525 13:33:54.911038 21963 solver.cpp:237] Iteration 26892, loss = 1.14987
I0525 13:33:54.911207 21963 solver.cpp:253]     Train net output #0: loss = 1.14987 (* 1 = 1.14987 loss)
I0525 13:33:54.911221 21963 sgd_solver.cpp:106] Iteration 26892, lr = 0.005
I0525 13:34:03.740444 21963 solver.cpp:237] Iteration 27058, loss = 1.13065
I0525 13:34:03.740479 21963 solver.cpp:253]     Train net output #0: loss = 1.13065 (* 1 = 1.13065 loss)
I0525 13:34:03.740496 21963 sgd_solver.cpp:106] Iteration 27058, lr = 0.005
I0525 13:34:12.567770 21963 solver.cpp:237] Iteration 27224, loss = 1.19326
I0525 13:34:12.567818 21963 solver.cpp:253]     Train net output #0: loss = 1.19326 (* 1 = 1.19326 loss)
I0525 13:34:12.567831 21963 sgd_solver.cpp:106] Iteration 27224, lr = 0.005
I0525 13:34:21.398080 21963 solver.cpp:237] Iteration 27390, loss = 1.07978
I0525 13:34:21.398115 21963 solver.cpp:253]     Train net output #0: loss = 1.07978 (* 1 = 1.07978 loss)
I0525 13:34:21.398131 21963 sgd_solver.cpp:106] Iteration 27390, lr = 0.005
I0525 13:34:30.226922 21963 solver.cpp:237] Iteration 27556, loss = 1.27811
I0525 13:34:30.227074 21963 solver.cpp:253]     Train net output #0: loss = 1.27811 (* 1 = 1.27811 loss)
I0525 13:34:30.227087 21963 sgd_solver.cpp:106] Iteration 27556, lr = 0.005
I0525 13:34:39.055946 21963 solver.cpp:237] Iteration 27722, loss = 1.11972
I0525 13:34:39.055989 21963 solver.cpp:253]     Train net output #0: loss = 1.11972 (* 1 = 1.11972 loss)
I0525 13:34:39.056008 21963 sgd_solver.cpp:106] Iteration 27722, lr = 0.005
I0525 13:35:08.753947 21963 solver.cpp:237] Iteration 27888, loss = 1.13178
I0525 13:35:08.754120 21963 solver.cpp:253]     Train net output #0: loss = 1.13178 (* 1 = 1.13178 loss)
I0525 13:35:08.754137 21963 sgd_solver.cpp:106] Iteration 27888, lr = 0.005
I0525 13:35:17.579620 21963 solver.cpp:237] Iteration 28054, loss = 1.24752
I0525 13:35:17.579655 21963 solver.cpp:253]     Train net output #0: loss = 1.24752 (* 1 = 1.24752 loss)
I0525 13:35:17.579670 21963 sgd_solver.cpp:106] Iteration 28054, lr = 0.005
I0525 13:35:26.410784 21963 solver.cpp:237] Iteration 28220, loss = 1.04921
I0525 13:35:26.410827 21963 solver.cpp:253]     Train net output #0: loss = 1.04921 (* 1 = 1.04921 loss)
I0525 13:35:26.410843 21963 sgd_solver.cpp:106] Iteration 28220, lr = 0.005
I0525 13:35:31.779978 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_28322.caffemodel
I0525 13:35:31.856853 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_28322.solverstate
I0525 13:35:35.300961 21963 solver.cpp:237] Iteration 28386, loss = 1.08066
I0525 13:35:35.301003 21963 solver.cpp:253]     Train net output #0: loss = 1.08066 (* 1 = 1.08066 loss)
I0525 13:35:35.301023 21963 sgd_solver.cpp:106] Iteration 28386, lr = 0.005
I0525 13:35:44.133682 21963 solver.cpp:237] Iteration 28552, loss = 1.30364
I0525 13:35:44.133847 21963 solver.cpp:253]     Train net output #0: loss = 1.30364 (* 1 = 1.30364 loss)
I0525 13:35:44.133862 21963 sgd_solver.cpp:106] Iteration 28552, lr = 0.005
I0525 13:35:52.957494 21963 solver.cpp:237] Iteration 28718, loss = 1.28159
I0525 13:35:52.957536 21963 solver.cpp:253]     Train net output #0: loss = 1.28159 (* 1 = 1.28159 loss)
I0525 13:35:52.957551 21963 sgd_solver.cpp:106] Iteration 28718, lr = 0.005
I0525 13:36:01.793987 21963 solver.cpp:237] Iteration 28884, loss = 1.08455
I0525 13:36:01.794023 21963 solver.cpp:253]     Train net output #0: loss = 1.08455 (* 1 = 1.08455 loss)
I0525 13:36:01.794039 21963 sgd_solver.cpp:106] Iteration 28884, lr = 0.005
I0525 13:36:31.488119 21963 solver.cpp:237] Iteration 29050, loss = 1.32163
I0525 13:36:31.488297 21963 solver.cpp:253]     Train net output #0: loss = 1.32163 (* 1 = 1.32163 loss)
I0525 13:36:31.488312 21963 sgd_solver.cpp:106] Iteration 29050, lr = 0.005
I0525 13:36:40.312708 21963 solver.cpp:237] Iteration 29216, loss = 1.07053
I0525 13:36:40.312750 21963 solver.cpp:253]     Train net output #0: loss = 1.07053 (* 1 = 1.07053 loss)
I0525 13:36:40.312767 21963 sgd_solver.cpp:106] Iteration 29216, lr = 0.005
I0525 13:36:49.138573 21963 solver.cpp:237] Iteration 29382, loss = 1.07385
I0525 13:36:49.138608 21963 solver.cpp:253]     Train net output #0: loss = 1.07385 (* 1 = 1.07385 loss)
I0525 13:36:49.138627 21963 sgd_solver.cpp:106] Iteration 29382, lr = 0.005
I0525 13:36:57.969156 21963 solver.cpp:237] Iteration 29548, loss = 1.10156
I0525 13:36:57.969192 21963 solver.cpp:253]     Train net output #0: loss = 1.10156 (* 1 = 1.10156 loss)
I0525 13:36:57.969207 21963 sgd_solver.cpp:106] Iteration 29548, lr = 0.005
I0525 13:37:06.793843 21963 solver.cpp:237] Iteration 29714, loss = 1.18836
I0525 13:37:06.794013 21963 solver.cpp:253]     Train net output #0: loss = 1.18836 (* 1 = 1.18836 loss)
I0525 13:37:06.794026 21963 sgd_solver.cpp:106] Iteration 29714, lr = 0.005
I0525 13:37:15.622457 21963 solver.cpp:237] Iteration 29880, loss = 1.17606
I0525 13:37:15.622491 21963 solver.cpp:253]     Train net output #0: loss = 1.17606 (* 1 = 1.17606 loss)
I0525 13:37:15.622509 21963 sgd_solver.cpp:106] Iteration 29880, lr = 0.005
I0525 13:37:21.308827 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_29988.caffemodel
I0525 13:37:21.384459 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_29988.solverstate
I0525 13:37:21.851141 21963 solver.cpp:341] Iteration 29997, Testing net (#0)
I0525 13:38:09.003855 21963 solver.cpp:409]     Test net output #0: accuracy = 0.885245
I0525 13:38:09.004025 21963 solver.cpp:409]     Test net output #1: loss = 0.365656 (* 1 = 0.365656 loss)
I0525 13:38:32.529973 21963 solver.cpp:237] Iteration 30046, loss = 1.1969
I0525 13:38:32.530021 21963 solver.cpp:253]     Train net output #0: loss = 1.1969 (* 1 = 1.1969 loss)
I0525 13:38:32.530036 21963 sgd_solver.cpp:106] Iteration 30046, lr = 0.005
I0525 13:38:41.362932 21963 solver.cpp:237] Iteration 30212, loss = 1.04438
I0525 13:38:41.363098 21963 solver.cpp:253]     Train net output #0: loss = 1.04438 (* 1 = 1.04438 loss)
I0525 13:38:41.363111 21963 sgd_solver.cpp:106] Iteration 30212, lr = 0.005
I0525 13:38:50.191438 21963 solver.cpp:237] Iteration 30378, loss = 1.17135
I0525 13:38:50.191480 21963 solver.cpp:253]     Train net output #0: loss = 1.17135 (* 1 = 1.17135 loss)
I0525 13:38:50.191498 21963 sgd_solver.cpp:106] Iteration 30378, lr = 0.005
I0525 13:38:59.022178 21963 solver.cpp:237] Iteration 30544, loss = 1.28976
I0525 13:38:59.022213 21963 solver.cpp:253]     Train net output #0: loss = 1.28976 (* 1 = 1.28976 loss)
I0525 13:38:59.022230 21963 sgd_solver.cpp:106] Iteration 30544, lr = 0.005
I0525 13:39:07.856103 21963 solver.cpp:237] Iteration 30710, loss = 1.23584
I0525 13:39:07.856138 21963 solver.cpp:253]     Train net output #0: loss = 1.23584 (* 1 = 1.23584 loss)
I0525 13:39:07.856154 21963 sgd_solver.cpp:106] Iteration 30710, lr = 0.005
I0525 13:39:16.684689 21963 solver.cpp:237] Iteration 30876, loss = 1.14318
I0525 13:39:16.684870 21963 solver.cpp:253]     Train net output #0: loss = 1.14318 (* 1 = 1.14318 loss)
I0525 13:39:16.684885 21963 sgd_solver.cpp:106] Iteration 30876, lr = 0.005
I0525 13:39:25.525954 21963 solver.cpp:237] Iteration 31042, loss = 1.42214
I0525 13:39:25.525987 21963 solver.cpp:253]     Train net output #0: loss = 1.42214 (* 1 = 1.42214 loss)
I0525 13:39:25.526005 21963 sgd_solver.cpp:106] Iteration 31042, lr = 0.005
I0525 13:39:55.252744 21963 solver.cpp:237] Iteration 31208, loss = 1.04291
I0525 13:39:55.252921 21963 solver.cpp:253]     Train net output #0: loss = 1.04291 (* 1 = 1.04291 loss)
I0525 13:39:55.252938 21963 sgd_solver.cpp:106] Iteration 31208, lr = 0.005
I0525 13:40:04.089893 21963 solver.cpp:237] Iteration 31374, loss = 1.19455
I0525 13:40:04.089934 21963 solver.cpp:253]     Train net output #0: loss = 1.19455 (* 1 = 1.19455 loss)
I0525 13:40:04.089952 21963 sgd_solver.cpp:106] Iteration 31374, lr = 0.005
I0525 13:40:12.922456 21963 solver.cpp:237] Iteration 31540, loss = 1.10117
I0525 13:40:12.922492 21963 solver.cpp:253]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0525 13:40:12.922504 21963 sgd_solver.cpp:106] Iteration 31540, lr = 0.005
I0525 13:40:18.934221 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_31654.caffemodel
I0525 13:40:19.012670 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_31654.solverstate
I0525 13:40:21.824200 21963 solver.cpp:237] Iteration 31706, loss = 1.2186
I0525 13:40:21.824249 21963 solver.cpp:253]     Train net output #0: loss = 1.2186 (* 1 = 1.2186 loss)
I0525 13:40:21.824265 21963 sgd_solver.cpp:106] Iteration 31706, lr = 0.005
I0525 13:40:30.658861 21963 solver.cpp:237] Iteration 31872, loss = 1.16345
I0525 13:40:30.659030 21963 solver.cpp:253]     Train net output #0: loss = 1.16345 (* 1 = 1.16345 loss)
I0525 13:40:30.659044 21963 sgd_solver.cpp:106] Iteration 31872, lr = 0.005
I0525 13:40:39.496971 21963 solver.cpp:237] Iteration 32038, loss = 1.09748
I0525 13:40:39.497005 21963 solver.cpp:253]     Train net output #0: loss = 1.09748 (* 1 = 1.09748 loss)
I0525 13:40:39.497020 21963 sgd_solver.cpp:106] Iteration 32038, lr = 0.005
I0525 13:40:48.334043 21963 solver.cpp:237] Iteration 32204, loss = 1.18721
I0525 13:40:48.334094 21963 solver.cpp:253]     Train net output #0: loss = 1.18721 (* 1 = 1.18721 loss)
I0525 13:40:48.334108 21963 sgd_solver.cpp:106] Iteration 32204, lr = 0.005
I0525 13:41:18.080435 21963 solver.cpp:237] Iteration 32370, loss = 1.09717
I0525 13:41:18.080610 21963 solver.cpp:253]     Train net output #0: loss = 1.09717 (* 1 = 1.09717 loss)
I0525 13:41:18.080626 21963 sgd_solver.cpp:106] Iteration 32370, lr = 0.005
I0525 13:41:26.921830 21963 solver.cpp:237] Iteration 32536, loss = 0.97122
I0525 13:41:26.921866 21963 solver.cpp:253]     Train net output #0: loss = 0.97122 (* 1 = 0.97122 loss)
I0525 13:41:26.921881 21963 sgd_solver.cpp:106] Iteration 32536, lr = 0.005
I0525 13:41:35.762951 21963 solver.cpp:237] Iteration 32702, loss = 1.31368
I0525 13:41:35.762986 21963 solver.cpp:253]     Train net output #0: loss = 1.31368 (* 1 = 1.31368 loss)
I0525 13:41:35.763002 21963 sgd_solver.cpp:106] Iteration 32702, lr = 0.005
I0525 13:41:44.602115 21963 solver.cpp:237] Iteration 32868, loss = 1.10944
I0525 13:41:44.602160 21963 solver.cpp:253]     Train net output #0: loss = 1.10944 (* 1 = 1.10944 loss)
I0525 13:41:44.602177 21963 sgd_solver.cpp:106] Iteration 32868, lr = 0.005
I0525 13:41:53.440212 21963 solver.cpp:237] Iteration 33034, loss = 1.25047
I0525 13:41:53.440378 21963 solver.cpp:253]     Train net output #0: loss = 1.25047 (* 1 = 1.25047 loss)
I0525 13:41:53.440392 21963 sgd_solver.cpp:106] Iteration 33034, lr = 0.005
I0525 13:42:02.278496 21963 solver.cpp:237] Iteration 33200, loss = 1.2482
I0525 13:42:02.278530 21963 solver.cpp:253]     Train net output #0: loss = 1.2482 (* 1 = 1.2482 loss)
I0525 13:42:02.278543 21963 sgd_solver.cpp:106] Iteration 33200, lr = 0.005
I0525 13:42:08.612191 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_33320.caffemodel
I0525 13:42:08.689934 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_33320.solverstate
I0525 13:42:09.213892 21963 solver.cpp:341] Iteration 33330, Testing net (#0)
I0525 13:43:17.253123 21963 solver.cpp:409]     Test net output #0: accuracy = 0.886085
I0525 13:43:17.253294 21963 solver.cpp:409]     Test net output #1: loss = 0.38072 (* 1 = 0.38072 loss)
I0525 13:43:40.093611 21963 solver.cpp:237] Iteration 33366, loss = 1.393
I0525 13:43:40.093659 21963 solver.cpp:253]     Train net output #0: loss = 1.393 (* 1 = 1.393 loss)
I0525 13:43:40.093677 21963 sgd_solver.cpp:106] Iteration 33366, lr = 0.005
I0525 13:43:48.912634 21963 solver.cpp:237] Iteration 33532, loss = 1.37925
I0525 13:43:48.912808 21963 solver.cpp:253]     Train net output #0: loss = 1.37925 (* 1 = 1.37925 loss)
I0525 13:43:48.912822 21963 sgd_solver.cpp:106] Iteration 33532, lr = 0.005
I0525 13:43:57.735204 21963 solver.cpp:237] Iteration 33698, loss = 1.14147
I0525 13:43:57.735239 21963 solver.cpp:253]     Train net output #0: loss = 1.14147 (* 1 = 1.14147 loss)
I0525 13:43:57.735256 21963 sgd_solver.cpp:106] Iteration 33698, lr = 0.005
I0525 13:44:06.555213 21963 solver.cpp:237] Iteration 33864, loss = 1.23956
I0525 13:44:06.555248 21963 solver.cpp:253]     Train net output #0: loss = 1.23956 (* 1 = 1.23956 loss)
I0525 13:44:06.555265 21963 sgd_solver.cpp:106] Iteration 33864, lr = 0.005
I0525 13:44:15.378505 21963 solver.cpp:237] Iteration 34030, loss = 1.09255
I0525 13:44:15.378551 21963 solver.cpp:253]     Train net output #0: loss = 1.09255 (* 1 = 1.09255 loss)
I0525 13:44:15.378564 21963 sgd_solver.cpp:106] Iteration 34030, lr = 0.005
I0525 13:44:24.200151 21963 solver.cpp:237] Iteration 34196, loss = 1.05205
I0525 13:44:24.200305 21963 solver.cpp:253]     Train net output #0: loss = 1.05205 (* 1 = 1.05205 loss)
I0525 13:44:24.200320 21963 sgd_solver.cpp:106] Iteration 34196, lr = 0.005
I0525 13:44:33.021785 21963 solver.cpp:237] Iteration 34362, loss = 1.36853
I0525 13:44:33.021829 21963 solver.cpp:253]     Train net output #0: loss = 1.36853 (* 1 = 1.36853 loss)
I0525 13:44:33.021847 21963 sgd_solver.cpp:106] Iteration 34362, lr = 0.005
I0525 13:45:02.704171 21963 solver.cpp:237] Iteration 34528, loss = 1.21327
I0525 13:45:02.704349 21963 solver.cpp:253]     Train net output #0: loss = 1.21327 (* 1 = 1.21327 loss)
I0525 13:45:02.704363 21963 sgd_solver.cpp:106] Iteration 34528, lr = 0.005
I0525 13:45:11.529306 21963 solver.cpp:237] Iteration 34694, loss = 1.22299
I0525 13:45:11.529341 21963 solver.cpp:253]     Train net output #0: loss = 1.22299 (* 1 = 1.22299 loss)
I0525 13:45:11.529358 21963 sgd_solver.cpp:106] Iteration 34694, lr = 0.005
I0525 13:45:20.343406 21963 solver.cpp:237] Iteration 34860, loss = 1.14789
I0525 13:45:20.343442 21963 solver.cpp:253]     Train net output #0: loss = 1.14789 (* 1 = 1.14789 loss)
I0525 13:45:20.343456 21963 sgd_solver.cpp:106] Iteration 34860, lr = 0.005
I0525 13:45:26.989094 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_34986.caffemodel
I0525 13:45:27.063467 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_34986.solverstate
I0525 13:45:29.233654 21963 solver.cpp:237] Iteration 35026, loss = 1.16608
I0525 13:45:29.233698 21963 solver.cpp:253]     Train net output #0: loss = 1.16608 (* 1 = 1.16608 loss)
I0525 13:45:29.233714 21963 sgd_solver.cpp:106] Iteration 35026, lr = 0.005
I0525 13:45:38.060400 21963 solver.cpp:237] Iteration 35192, loss = 1.1278
I0525 13:45:38.060565 21963 solver.cpp:253]     Train net output #0: loss = 1.1278 (* 1 = 1.1278 loss)
I0525 13:45:38.060580 21963 sgd_solver.cpp:106] Iteration 35192, lr = 0.005
I0525 13:45:46.887223 21963 solver.cpp:237] Iteration 35358, loss = 1.02082
I0525 13:45:46.887255 21963 solver.cpp:253]     Train net output #0: loss = 1.02082 (* 1 = 1.02082 loss)
I0525 13:45:46.887274 21963 sgd_solver.cpp:106] Iteration 35358, lr = 0.005
I0525 13:45:55.713634 21963 solver.cpp:237] Iteration 35524, loss = 1.19472
I0525 13:45:55.713671 21963 solver.cpp:253]     Train net output #0: loss = 1.19472 (* 1 = 1.19472 loss)
I0525 13:45:55.713690 21963 sgd_solver.cpp:106] Iteration 35524, lr = 0.005
I0525 13:46:25.410081 21963 solver.cpp:237] Iteration 35690, loss = 1.33829
I0525 13:46:25.410257 21963 solver.cpp:253]     Train net output #0: loss = 1.33829 (* 1 = 1.33829 loss)
I0525 13:46:25.410274 21963 sgd_solver.cpp:106] Iteration 35690, lr = 0.005
I0525 13:46:34.233492 21963 solver.cpp:237] Iteration 35856, loss = 1.12686
I0525 13:46:34.233527 21963 solver.cpp:253]     Train net output #0: loss = 1.12686 (* 1 = 1.12686 loss)
I0525 13:46:34.233544 21963 sgd_solver.cpp:106] Iteration 35856, lr = 0.005
I0525 13:46:43.054222 21963 solver.cpp:237] Iteration 36022, loss = 1.04928
I0525 13:46:43.054270 21963 solver.cpp:253]     Train net output #0: loss = 1.04928 (* 1 = 1.04928 loss)
I0525 13:46:43.054286 21963 sgd_solver.cpp:106] Iteration 36022, lr = 0.005
I0525 13:46:51.879947 21963 solver.cpp:237] Iteration 36188, loss = 1.12687
I0525 13:46:51.879982 21963 solver.cpp:253]     Train net output #0: loss = 1.12687 (* 1 = 1.12687 loss)
I0525 13:46:51.879999 21963 sgd_solver.cpp:106] Iteration 36188, lr = 0.005
I0525 13:47:00.707299 21963 solver.cpp:237] Iteration 36354, loss = 1.10885
I0525 13:47:00.707458 21963 solver.cpp:253]     Train net output #0: loss = 1.10885 (* 1 = 1.10885 loss)
I0525 13:47:00.707470 21963 sgd_solver.cpp:106] Iteration 36354, lr = 0.005
I0525 13:47:09.524546 21963 solver.cpp:237] Iteration 36520, loss = 1.00209
I0525 13:47:09.524585 21963 solver.cpp:253]     Train net output #0: loss = 1.00209 (* 1 = 1.00209 loss)
I0525 13:47:09.524606 21963 sgd_solver.cpp:106] Iteration 36520, lr = 0.005
I0525 13:47:16.485224 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_36652.caffemodel
I0525 13:47:16.560410 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_36652.solverstate
I0525 13:47:17.135262 21963 solver.cpp:341] Iteration 36663, Testing net (#0)
I0525 13:48:03.998121 21963 solver.cpp:409]     Test net output #0: accuracy = 0.886979
I0525 13:48:03.998306 21963 solver.cpp:409]     Test net output #1: loss = 0.355066 (* 1 = 0.355066 loss)
I0525 13:48:26.129233 21963 solver.cpp:237] Iteration 36686, loss = 1.17936
I0525 13:48:26.129283 21963 solver.cpp:253]     Train net output #0: loss = 1.17936 (* 1 = 1.17936 loss)
I0525 13:48:26.129298 21963 sgd_solver.cpp:106] Iteration 36686, lr = 0.005
I0525 13:48:34.968397 21963 solver.cpp:237] Iteration 36852, loss = 1.16075
I0525 13:48:34.968567 21963 solver.cpp:253]     Train net output #0: loss = 1.16075 (* 1 = 1.16075 loss)
I0525 13:48:34.968581 21963 sgd_solver.cpp:106] Iteration 36852, lr = 0.005
I0525 13:48:43.792029 21963 solver.cpp:237] Iteration 37018, loss = 1.01251
I0525 13:48:43.792073 21963 solver.cpp:253]     Train net output #0: loss = 1.01251 (* 1 = 1.01251 loss)
I0525 13:48:43.792089 21963 sgd_solver.cpp:106] Iteration 37018, lr = 0.005
I0525 13:48:52.627729 21963 solver.cpp:237] Iteration 37184, loss = 0.831082
I0525 13:48:52.627765 21963 solver.cpp:253]     Train net output #0: loss = 0.831082 (* 1 = 0.831082 loss)
I0525 13:48:52.627781 21963 sgd_solver.cpp:106] Iteration 37184, lr = 0.005
I0525 13:49:01.461884 21963 solver.cpp:237] Iteration 37350, loss = 1.02015
I0525 13:49:01.461918 21963 solver.cpp:253]     Train net output #0: loss = 1.02015 (* 1 = 1.02015 loss)
I0525 13:49:01.461935 21963 sgd_solver.cpp:106] Iteration 37350, lr = 0.005
I0525 13:49:10.294991 21963 solver.cpp:237] Iteration 37516, loss = 1.12665
I0525 13:49:10.295162 21963 solver.cpp:253]     Train net output #0: loss = 1.12665 (* 1 = 1.12665 loss)
I0525 13:49:10.295176 21963 sgd_solver.cpp:106] Iteration 37516, lr = 0.005
I0525 13:49:19.131875 21963 solver.cpp:237] Iteration 37682, loss = 1.02781
I0525 13:49:19.131909 21963 solver.cpp:253]     Train net output #0: loss = 1.02781 (* 1 = 1.02781 loss)
I0525 13:49:19.131929 21963 sgd_solver.cpp:106] Iteration 37682, lr = 0.005
I0525 13:49:48.865978 21963 solver.cpp:237] Iteration 37848, loss = 1.20885
I0525 13:49:48.866158 21963 solver.cpp:253]     Train net output #0: loss = 1.20885 (* 1 = 1.20885 loss)
I0525 13:49:48.866174 21963 sgd_solver.cpp:106] Iteration 37848, lr = 0.005
I0525 13:49:57.702419 21963 solver.cpp:237] Iteration 38014, loss = 1.29598
I0525 13:49:57.702455 21963 solver.cpp:253]     Train net output #0: loss = 1.29598 (* 1 = 1.29598 loss)
I0525 13:49:57.702471 21963 sgd_solver.cpp:106] Iteration 38014, lr = 0.005
I0525 13:50:06.538995 21963 solver.cpp:237] Iteration 38180, loss = 1.05504
I0525 13:50:06.539043 21963 solver.cpp:253]     Train net output #0: loss = 1.05504 (* 1 = 1.05504 loss)
I0525 13:50:06.539057 21963 sgd_solver.cpp:106] Iteration 38180, lr = 0.005
I0525 13:50:13.829217 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_38318.caffemodel
I0525 13:50:13.904811 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_38318.solverstate
I0525 13:50:15.439460 21963 solver.cpp:237] Iteration 38346, loss = 1.20239
I0525 13:50:15.439507 21963 solver.cpp:253]     Train net output #0: loss = 1.20239 (* 1 = 1.20239 loss)
I0525 13:50:15.439522 21963 sgd_solver.cpp:106] Iteration 38346, lr = 0.005
I0525 13:50:24.275084 21963 solver.cpp:237] Iteration 38512, loss = 1.38867
I0525 13:50:24.275264 21963 solver.cpp:253]     Train net output #0: loss = 1.38867 (* 1 = 1.38867 loss)
I0525 13:50:24.275279 21963 sgd_solver.cpp:106] Iteration 38512, lr = 0.005
I0525 13:50:33.115229 21963 solver.cpp:237] Iteration 38678, loss = 1.13587
I0525 13:50:33.115264 21963 solver.cpp:253]     Train net output #0: loss = 1.13587 (* 1 = 1.13587 loss)
I0525 13:50:33.115283 21963 sgd_solver.cpp:106] Iteration 38678, lr = 0.005
I0525 13:50:41.954622 21963 solver.cpp:237] Iteration 38844, loss = 1.0966
I0525 13:50:41.954658 21963 solver.cpp:253]     Train net output #0: loss = 1.0966 (* 1 = 1.0966 loss)
I0525 13:50:41.954674 21963 sgd_solver.cpp:106] Iteration 38844, lr = 0.005
I0525 13:51:11.671520 21963 solver.cpp:237] Iteration 39010, loss = 1.20503
I0525 13:51:11.671713 21963 solver.cpp:253]     Train net output #0: loss = 1.20503 (* 1 = 1.20503 loss)
I0525 13:51:11.671730 21963 sgd_solver.cpp:106] Iteration 39010, lr = 0.005
I0525 13:51:20.510534 21963 solver.cpp:237] Iteration 39176, loss = 1.0646
I0525 13:51:20.510579 21963 solver.cpp:253]     Train net output #0: loss = 1.0646 (* 1 = 1.0646 loss)
I0525 13:51:20.510596 21963 sgd_solver.cpp:106] Iteration 39176, lr = 0.005
I0525 13:51:29.343906 21963 solver.cpp:237] Iteration 39342, loss = 1.01785
I0525 13:51:29.343942 21963 solver.cpp:253]     Train net output #0: loss = 1.01785 (* 1 = 1.01785 loss)
I0525 13:51:29.343957 21963 sgd_solver.cpp:106] Iteration 39342, lr = 0.005
I0525 13:51:38.179510 21963 solver.cpp:237] Iteration 39508, loss = 1.3113
I0525 13:51:38.179548 21963 solver.cpp:253]     Train net output #0: loss = 1.3113 (* 1 = 1.3113 loss)
I0525 13:51:38.179570 21963 sgd_solver.cpp:106] Iteration 39508, lr = 0.005
I0525 13:51:47.006302 21963 solver.cpp:237] Iteration 39674, loss = 1.21096
I0525 13:51:47.006489 21963 solver.cpp:253]     Train net output #0: loss = 1.21096 (* 1 = 1.21096 loss)
I0525 13:51:47.006502 21963 sgd_solver.cpp:106] Iteration 39674, lr = 0.005
I0525 13:51:55.828058 21963 solver.cpp:237] Iteration 39840, loss = 1.19207
I0525 13:51:55.828091 21963 solver.cpp:253]     Train net output #0: loss = 1.19207 (* 1 = 1.19207 loss)
I0525 13:51:55.828109 21963 sgd_solver.cpp:106] Iteration 39840, lr = 0.005
I0525 13:52:03.426028 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_39984.caffemodel
I0525 13:52:03.504215 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_39984.solverstate
I0525 13:52:04.131808 21963 solver.cpp:341] Iteration 39996, Testing net (#0)
I0525 13:53:12.224061 21963 solver.cpp:409]     Test net output #0: accuracy = 0.883851
I0525 13:53:12.224249 21963 solver.cpp:409]     Test net output #1: loss = 0.386474 (* 1 = 0.386474 loss)
I0525 13:53:33.667819 21963 solver.cpp:237] Iteration 40006, loss = 1.07657
I0525 13:53:33.667870 21963 solver.cpp:253]     Train net output #0: loss = 1.07657 (* 1 = 1.07657 loss)
I0525 13:53:33.667884 21963 sgd_solver.cpp:106] Iteration 40006, lr = 0.005
I0525 13:53:42.491901 21963 solver.cpp:237] Iteration 40172, loss = 1.21269
I0525 13:53:42.492065 21963 solver.cpp:253]     Train net output #0: loss = 1.21269 (* 1 = 1.21269 loss)
I0525 13:53:42.492079 21963 sgd_solver.cpp:106] Iteration 40172, lr = 0.005
I0525 13:53:51.312458 21963 solver.cpp:237] Iteration 40338, loss = 1.28877
I0525 13:53:51.312497 21963 solver.cpp:253]     Train net output #0: loss = 1.28877 (* 1 = 1.28877 loss)
I0525 13:53:51.312516 21963 sgd_solver.cpp:106] Iteration 40338, lr = 0.005
I0525 13:54:00.129658 21963 solver.cpp:237] Iteration 40504, loss = 0.956467
I0525 13:54:00.129694 21963 solver.cpp:253]     Train net output #0: loss = 0.956467 (* 1 = 0.956467 loss)
I0525 13:54:00.129714 21963 sgd_solver.cpp:106] Iteration 40504, lr = 0.005
I0525 13:54:08.958472 21963 solver.cpp:237] Iteration 40670, loss = 0.808379
I0525 13:54:08.958513 21963 solver.cpp:253]     Train net output #0: loss = 0.808379 (* 1 = 0.808379 loss)
I0525 13:54:08.958528 21963 sgd_solver.cpp:106] Iteration 40670, lr = 0.005
I0525 13:54:17.778621 21963 solver.cpp:237] Iteration 40836, loss = 1.28971
I0525 13:54:17.778779 21963 solver.cpp:253]     Train net output #0: loss = 1.28971 (* 1 = 1.28971 loss)
I0525 13:54:17.778794 21963 sgd_solver.cpp:106] Iteration 40836, lr = 0.005
I0525 13:54:26.605839 21963 solver.cpp:237] Iteration 41002, loss = 0.997313
I0525 13:54:26.605873 21963 solver.cpp:253]     Train net output #0: loss = 0.997313 (* 1 = 0.997313 loss)
I0525 13:54:26.605890 21963 sgd_solver.cpp:106] Iteration 41002, lr = 0.005
I0525 13:54:56.341466 21963 solver.cpp:237] Iteration 41168, loss = 1.09991
I0525 13:54:56.341647 21963 solver.cpp:253]     Train net output #0: loss = 1.09991 (* 1 = 1.09991 loss)
I0525 13:54:56.341663 21963 sgd_solver.cpp:106] Iteration 41168, lr = 0.005
I0525 13:55:05.168696 21963 solver.cpp:237] Iteration 41334, loss = 1.14216
I0525 13:55:05.168737 21963 solver.cpp:253]     Train net output #0: loss = 1.14216 (* 1 = 1.14216 loss)
I0525 13:55:05.168757 21963 sgd_solver.cpp:106] Iteration 41334, lr = 0.005
I0525 13:55:13.991236 21963 solver.cpp:237] Iteration 41500, loss = 1.15017
I0525 13:55:13.991271 21963 solver.cpp:253]     Train net output #0: loss = 1.15017 (* 1 = 1.15017 loss)
I0525 13:55:13.991288 21963 sgd_solver.cpp:106] Iteration 41500, lr = 0.005
I0525 13:55:21.918653 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_41650.caffemodel
I0525 13:55:21.996068 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_41650.solverstate
I0525 13:55:22.893537 21963 solver.cpp:237] Iteration 41666, loss = 1.0964
I0525 13:55:22.893585 21963 solver.cpp:253]     Train net output #0: loss = 1.0964 (* 1 = 1.0964 loss)
I0525 13:55:22.893601 21963 sgd_solver.cpp:106] Iteration 41666, lr = 0.005
I0525 13:55:31.726444 21963 solver.cpp:237] Iteration 41832, loss = 1.09804
I0525 13:55:31.726635 21963 solver.cpp:253]     Train net output #0: loss = 1.09804 (* 1 = 1.09804 loss)
I0525 13:55:31.726649 21963 sgd_solver.cpp:106] Iteration 41832, lr = 0.005
I0525 13:55:40.556951 21963 solver.cpp:237] Iteration 41998, loss = 1.06938
I0525 13:55:40.556984 21963 solver.cpp:253]     Train net output #0: loss = 1.06938 (* 1 = 1.06938 loss)
I0525 13:55:40.557001 21963 sgd_solver.cpp:106] Iteration 41998, lr = 0.005
I0525 13:55:49.382515 21963 solver.cpp:237] Iteration 42164, loss = 1.08447
I0525 13:55:49.382551 21963 solver.cpp:253]     Train net output #0: loss = 1.08447 (* 1 = 1.08447 loss)
I0525 13:55:49.382570 21963 sgd_solver.cpp:106] Iteration 42164, lr = 0.005
I0525 13:56:19.091122 21963 solver.cpp:237] Iteration 42330, loss = 1.13943
I0525 13:56:19.091306 21963 solver.cpp:253]     Train net output #0: loss = 1.13943 (* 1 = 1.13943 loss)
I0525 13:56:19.091321 21963 sgd_solver.cpp:106] Iteration 42330, lr = 0.005
I0525 13:56:27.919451 21963 solver.cpp:237] Iteration 42496, loss = 1.23559
I0525 13:56:27.919484 21963 solver.cpp:253]     Train net output #0: loss = 1.23559 (* 1 = 1.23559 loss)
I0525 13:56:27.919498 21963 sgd_solver.cpp:106] Iteration 42496, lr = 0.005
I0525 13:56:36.751071 21963 solver.cpp:237] Iteration 42662, loss = 1.2699
I0525 13:56:36.751106 21963 solver.cpp:253]     Train net output #0: loss = 1.2699 (* 1 = 1.2699 loss)
I0525 13:56:36.751122 21963 sgd_solver.cpp:106] Iteration 42662, lr = 0.005
I0525 13:56:45.579305 21963 solver.cpp:237] Iteration 42828, loss = 1.27843
I0525 13:56:45.579341 21963 solver.cpp:253]     Train net output #0: loss = 1.27843 (* 1 = 1.27843 loss)
I0525 13:56:45.579357 21963 sgd_solver.cpp:106] Iteration 42828, lr = 0.005
I0525 13:56:54.409168 21963 solver.cpp:237] Iteration 42994, loss = 1.14098
I0525 13:56:54.409319 21963 solver.cpp:253]     Train net output #0: loss = 1.14098 (* 1 = 1.14098 loss)
I0525 13:56:54.409333 21963 sgd_solver.cpp:106] Iteration 42994, lr = 0.005
I0525 13:57:03.235756 21963 solver.cpp:237] Iteration 43160, loss = 1.17818
I0525 13:57:03.235805 21963 solver.cpp:253]     Train net output #0: loss = 1.17818 (* 1 = 1.17818 loss)
I0525 13:57:03.235817 21963 sgd_solver.cpp:106] Iteration 43160, lr = 0.005
I0525 13:57:11.484503 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_43316.caffemodel
I0525 13:57:11.559321 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_43316.solverstate
I0525 13:57:12.134351 21963 solver.cpp:237] Iteration 43326, loss = 1.33536
I0525 13:57:12.134393 21963 solver.cpp:253]     Train net output #0: loss = 1.33536 (* 1 = 1.33536 loss)
I0525 13:57:12.134413 21963 sgd_solver.cpp:106] Iteration 43326, lr = 0.005
I0525 13:57:12.240582 21963 solver.cpp:341] Iteration 43329, Testing net (#0)
I0525 13:57:59.424574 21963 solver.cpp:409]     Test net output #0: accuracy = 0.893182
I0525 13:57:59.424762 21963 solver.cpp:409]     Test net output #1: loss = 0.342967 (* 1 = 0.342967 loss)
I0525 13:58:28.971689 21963 solver.cpp:237] Iteration 43492, loss = 1.11241
I0525 13:58:28.971738 21963 solver.cpp:253]     Train net output #0: loss = 1.11241 (* 1 = 1.11241 loss)
I0525 13:58:28.971755 21963 sgd_solver.cpp:106] Iteration 43492, lr = 0.005
I0525 13:58:37.809695 21963 solver.cpp:237] Iteration 43658, loss = 1.26931
I0525 13:58:37.809861 21963 solver.cpp:253]     Train net output #0: loss = 1.26931 (* 1 = 1.26931 loss)
I0525 13:58:37.809875 21963 sgd_solver.cpp:106] Iteration 43658, lr = 0.005
I0525 13:58:46.643652 21963 solver.cpp:237] Iteration 43824, loss = 1.26371
I0525 13:58:46.643693 21963 solver.cpp:253]     Train net output #0: loss = 1.26371 (* 1 = 1.26371 loss)
I0525 13:58:46.643707 21963 sgd_solver.cpp:106] Iteration 43824, lr = 0.005
I0525 13:58:55.465103 21963 solver.cpp:237] Iteration 43990, loss = 1.20892
I0525 13:58:55.465138 21963 solver.cpp:253]     Train net output #0: loss = 1.20892 (* 1 = 1.20892 loss)
I0525 13:58:55.465155 21963 sgd_solver.cpp:106] Iteration 43990, lr = 0.005
I0525 13:59:04.294597 21963 solver.cpp:237] Iteration 44156, loss = 1.12822
I0525 13:59:04.294632 21963 solver.cpp:253]     Train net output #0: loss = 1.12822 (* 1 = 1.12822 loss)
I0525 13:59:04.294646 21963 sgd_solver.cpp:106] Iteration 44156, lr = 0.005
I0525 13:59:13.128968 21963 solver.cpp:237] Iteration 44322, loss = 0.952912
I0525 13:59:13.129142 21963 solver.cpp:253]     Train net output #0: loss = 0.952912 (* 1 = 0.952912 loss)
I0525 13:59:13.129155 21963 sgd_solver.cpp:106] Iteration 44322, lr = 0.005
I0525 13:59:42.845862 21963 solver.cpp:237] Iteration 44488, loss = 1.27635
I0525 13:59:42.845913 21963 solver.cpp:253]     Train net output #0: loss = 1.27635 (* 1 = 1.27635 loss)
I0525 13:59:42.845927 21963 sgd_solver.cpp:106] Iteration 44488, lr = 0.005
I0525 13:59:51.672194 21963 solver.cpp:237] Iteration 44654, loss = 1.25145
I0525 13:59:51.672360 21963 solver.cpp:253]     Train net output #0: loss = 1.25145 (* 1 = 1.25145 loss)
I0525 13:59:51.672374 21963 sgd_solver.cpp:106] Iteration 44654, lr = 0.005
I0525 14:00:00.502262 21963 solver.cpp:237] Iteration 44820, loss = 1.4386
I0525 14:00:00.502310 21963 solver.cpp:253]     Train net output #0: loss = 1.4386 (* 1 = 1.4386 loss)
I0525 14:00:00.502323 21963 sgd_solver.cpp:106] Iteration 44820, lr = 0.005
I0525 14:00:09.080652 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_44982.caffemodel
I0525 14:00:09.155073 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_44982.solverstate
I0525 14:00:09.409642 21963 solver.cpp:237] Iteration 44986, loss = 1.06883
I0525 14:00:09.409682 21963 solver.cpp:253]     Train net output #0: loss = 1.06883 (* 1 = 1.06883 loss)
I0525 14:00:09.409703 21963 sgd_solver.cpp:106] Iteration 44986, lr = 0.005
I0525 14:00:18.244065 21963 solver.cpp:237] Iteration 45152, loss = 0.992219
I0525 14:00:18.244101 21963 solver.cpp:253]     Train net output #0: loss = 0.992219 (* 1 = 0.992219 loss)
I0525 14:00:18.244115 21963 sgd_solver.cpp:106] Iteration 45152, lr = 0.005
I0525 14:00:27.071180 21963 solver.cpp:237] Iteration 45318, loss = 1.05825
I0525 14:00:27.071362 21963 solver.cpp:253]     Train net output #0: loss = 1.05825 (* 1 = 1.05825 loss)
I0525 14:00:27.071375 21963 sgd_solver.cpp:106] Iteration 45318, lr = 0.005
I0525 14:00:35.909656 21963 solver.cpp:237] Iteration 45484, loss = 1.38289
I0525 14:00:35.909689 21963 solver.cpp:253]     Train net output #0: loss = 1.38289 (* 1 = 1.38289 loss)
I0525 14:00:35.909706 21963 sgd_solver.cpp:106] Iteration 45484, lr = 0.005
I0525 14:01:05.607493 21963 solver.cpp:237] Iteration 45650, loss = 1.21143
I0525 14:01:05.607688 21963 solver.cpp:253]     Train net output #0: loss = 1.21143 (* 1 = 1.21143 loss)
I0525 14:01:05.607704 21963 sgd_solver.cpp:106] Iteration 45650, lr = 0.005
I0525 14:01:14.443361 21963 solver.cpp:237] Iteration 45816, loss = 1.18279
I0525 14:01:14.443404 21963 solver.cpp:253]     Train net output #0: loss = 1.18279 (* 1 = 1.18279 loss)
I0525 14:01:14.443423 21963 sgd_solver.cpp:106] Iteration 45816, lr = 0.005
I0525 14:01:23.273826 21963 solver.cpp:237] Iteration 45982, loss = 1.1512
I0525 14:01:23.273862 21963 solver.cpp:253]     Train net output #0: loss = 1.1512 (* 1 = 1.1512 loss)
I0525 14:01:23.273877 21963 sgd_solver.cpp:106] Iteration 45982, lr = 0.005
I0525 14:01:32.105700 21963 solver.cpp:237] Iteration 46148, loss = 1.20053
I0525 14:01:32.105734 21963 solver.cpp:253]     Train net output #0: loss = 1.20053 (* 1 = 1.20053 loss)
I0525 14:01:32.105751 21963 sgd_solver.cpp:106] Iteration 46148, lr = 0.005
I0525 14:01:40.933362 21963 solver.cpp:237] Iteration 46314, loss = 1.36526
I0525 14:01:40.933542 21963 solver.cpp:253]     Train net output #0: loss = 1.36526 (* 1 = 1.36526 loss)
I0525 14:01:40.933557 21963 sgd_solver.cpp:106] Iteration 46314, lr = 0.005
I0525 14:01:49.766659 21963 solver.cpp:237] Iteration 46480, loss = 1.07578
I0525 14:01:49.766693 21963 solver.cpp:253]     Train net output #0: loss = 1.07578 (* 1 = 1.07578 loss)
I0525 14:01:49.766710 21963 sgd_solver.cpp:106] Iteration 46480, lr = 0.005
I0525 14:01:58.604143 21963 solver.cpp:237] Iteration 46646, loss = 1.06269
I0525 14:01:58.604178 21963 solver.cpp:253]     Train net output #0: loss = 1.06269 (* 1 = 1.06269 loss)
I0525 14:01:58.604194 21963 sgd_solver.cpp:106] Iteration 46646, lr = 0.005
I0525 14:01:58.657316 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_46648.caffemodel
I0525 14:01:58.731842 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_46648.solverstate
I0525 14:01:59.467573 21963 solver.cpp:341] Iteration 46662, Testing net (#0)
I0525 14:03:07.524010 21963 solver.cpp:409]     Test net output #0: accuracy = 0.890861
I0525 14:03:07.524201 21963 solver.cpp:409]     Test net output #1: loss = 0.345612 (* 1 = 0.345612 loss)
I0525 14:03:36.371003 21963 solver.cpp:237] Iteration 46812, loss = 1.34837
I0525 14:03:36.371052 21963 solver.cpp:253]     Train net output #0: loss = 1.34837 (* 1 = 1.34837 loss)
I0525 14:03:36.371068 21963 sgd_solver.cpp:106] Iteration 46812, lr = 0.005
I0525 14:03:45.197305 21963 solver.cpp:237] Iteration 46978, loss = 1.11128
I0525 14:03:45.197481 21963 solver.cpp:253]     Train net output #0: loss = 1.11128 (* 1 = 1.11128 loss)
I0525 14:03:45.197495 21963 sgd_solver.cpp:106] Iteration 46978, lr = 0.005
I0525 14:03:54.023309 21963 solver.cpp:237] Iteration 47144, loss = 1.14262
I0525 14:03:54.023344 21963 solver.cpp:253]     Train net output #0: loss = 1.14262 (* 1 = 1.14262 loss)
I0525 14:03:54.023358 21963 sgd_solver.cpp:106] Iteration 47144, lr = 0.005
I0525 14:04:02.852272 21963 solver.cpp:237] Iteration 47310, loss = 1.29143
I0525 14:04:02.852308 21963 solver.cpp:253]     Train net output #0: loss = 1.29143 (* 1 = 1.29143 loss)
I0525 14:04:02.852324 21963 sgd_solver.cpp:106] Iteration 47310, lr = 0.005
I0525 14:04:11.673282 21963 solver.cpp:237] Iteration 47476, loss = 1.17617
I0525 14:04:11.673317 21963 solver.cpp:253]     Train net output #0: loss = 1.17617 (* 1 = 1.17617 loss)
I0525 14:04:11.673338 21963 sgd_solver.cpp:106] Iteration 47476, lr = 0.005
I0525 14:04:20.500471 21963 solver.cpp:237] Iteration 47642, loss = 1.53326
I0525 14:04:20.500633 21963 solver.cpp:253]     Train net output #0: loss = 1.53326 (* 1 = 1.53326 loss)
I0525 14:04:20.500646 21963 sgd_solver.cpp:106] Iteration 47642, lr = 0.005
I0525 14:04:50.225237 21963 solver.cpp:237] Iteration 47808, loss = 1.30688
I0525 14:04:50.225287 21963 solver.cpp:253]     Train net output #0: loss = 1.30688 (* 1 = 1.30688 loss)
I0525 14:04:50.225302 21963 sgd_solver.cpp:106] Iteration 47808, lr = 0.005
I0525 14:04:59.046901 21963 solver.cpp:237] Iteration 47974, loss = 1.35382
I0525 14:04:59.047080 21963 solver.cpp:253]     Train net output #0: loss = 1.35382 (* 1 = 1.35382 loss)
I0525 14:04:59.047094 21963 sgd_solver.cpp:106] Iteration 47974, lr = 0.005
I0525 14:05:07.880728 21963 solver.cpp:237] Iteration 48140, loss = 0.96416
I0525 14:05:07.880762 21963 solver.cpp:253]     Train net output #0: loss = 0.96416 (* 1 = 0.96416 loss)
I0525 14:05:07.880779 21963 sgd_solver.cpp:106] Iteration 48140, lr = 0.005
I0525 14:05:16.698496 21963 solver.cpp:237] Iteration 48306, loss = 1.16761
I0525 14:05:16.698531 21963 solver.cpp:253]     Train net output #0: loss = 1.16761 (* 1 = 1.16761 loss)
I0525 14:05:16.698547 21963 sgd_solver.cpp:106] Iteration 48306, lr = 0.005
I0525 14:05:17.070335 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_48314.caffemodel
I0525 14:05:17.146911 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_48314.solverstate
I0525 14:05:25.593868 21963 solver.cpp:237] Iteration 48472, loss = 0.958187
I0525 14:05:25.593919 21963 solver.cpp:253]     Train net output #0: loss = 0.958187 (* 1 = 0.958187 loss)
I0525 14:05:25.593932 21963 sgd_solver.cpp:106] Iteration 48472, lr = 0.005
I0525 14:05:34.414952 21963 solver.cpp:237] Iteration 48638, loss = 1.07966
I0525 14:05:34.415119 21963 solver.cpp:253]     Train net output #0: loss = 1.07966 (* 1 = 1.07966 loss)
I0525 14:05:34.415133 21963 sgd_solver.cpp:106] Iteration 48638, lr = 0.005
I0525 14:05:43.241076 21963 solver.cpp:237] Iteration 48804, loss = 1.25424
I0525 14:05:43.241111 21963 solver.cpp:253]     Train net output #0: loss = 1.25424 (* 1 = 1.25424 loss)
I0525 14:05:43.241128 21963 sgd_solver.cpp:106] Iteration 48804, lr = 0.005
I0525 14:06:12.947345 21963 solver.cpp:237] Iteration 48970, loss = 1.04537
I0525 14:06:12.947522 21963 solver.cpp:253]     Train net output #0: loss = 1.04537 (* 1 = 1.04537 loss)
I0525 14:06:12.947536 21963 sgd_solver.cpp:106] Iteration 48970, lr = 0.005
I0525 14:06:21.773571 21963 solver.cpp:237] Iteration 49136, loss = 1.21558
I0525 14:06:21.773605 21963 solver.cpp:253]     Train net output #0: loss = 1.21558 (* 1 = 1.21558 loss)
I0525 14:06:21.773622 21963 sgd_solver.cpp:106] Iteration 49136, lr = 0.005
I0525 14:06:30.594557 21963 solver.cpp:237] Iteration 49302, loss = 1.01832
I0525 14:06:30.594591 21963 solver.cpp:253]     Train net output #0: loss = 1.01832 (* 1 = 1.01832 loss)
I0525 14:06:30.594607 21963 sgd_solver.cpp:106] Iteration 49302, lr = 0.005
I0525 14:06:39.413470 21963 solver.cpp:237] Iteration 49468, loss = 1.30718
I0525 14:06:39.413517 21963 solver.cpp:253]     Train net output #0: loss = 1.30718 (* 1 = 1.30718 loss)
I0525 14:06:39.413533 21963 sgd_solver.cpp:106] Iteration 49468, lr = 0.005
I0525 14:06:48.243373 21963 solver.cpp:237] Iteration 49634, loss = 1.07487
I0525 14:06:48.243536 21963 solver.cpp:253]     Train net output #0: loss = 1.07487 (* 1 = 1.07487 loss)
I0525 14:06:48.243551 21963 sgd_solver.cpp:106] Iteration 49634, lr = 0.005
I0525 14:06:57.065223 21963 solver.cpp:237] Iteration 49800, loss = 1.2513
I0525 14:06:57.065258 21963 solver.cpp:253]     Train net output #0: loss = 1.2513 (* 1 = 1.2513 loss)
I0525 14:06:57.065274 21963 sgd_solver.cpp:106] Iteration 49800, lr = 0.005
I0525 14:07:05.888169 21963 solver.cpp:237] Iteration 49966, loss = 1.05713
I0525 14:07:05.888207 21963 solver.cpp:253]     Train net output #0: loss = 1.05713 (* 1 = 1.05713 loss)
I0525 14:07:05.888231 21963 sgd_solver.cpp:106] Iteration 49966, lr = 0.005
I0525 14:07:06.577759 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_49980.caffemodel
I0525 14:07:06.654383 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_49980.solverstate
I0525 14:07:07.444181 21963 solver.cpp:341] Iteration 49995, Testing net (#0)
I0525 14:07:54.335477 21963 solver.cpp:409]     Test net output #0: accuracy = 0.891881
I0525 14:07:54.335669 21963 solver.cpp:409]     Test net output #1: loss = 0.34113 (* 1 = 0.34113 loss)
I0525 14:08:22.507899 21963 solver.cpp:237] Iteration 50132, loss = 1.17946
I0525 14:08:22.507947 21963 solver.cpp:253]     Train net output #0: loss = 1.17946 (* 1 = 1.17946 loss)
I0525 14:08:22.507962 21963 sgd_solver.cpp:106] Iteration 50132, lr = 0.005
I0525 14:08:31.332672 21963 solver.cpp:237] Iteration 50298, loss = 1.29306
I0525 14:08:31.332841 21963 solver.cpp:253]     Train net output #0: loss = 1.29306 (* 1 = 1.29306 loss)
I0525 14:08:31.332854 21963 sgd_solver.cpp:106] Iteration 50298, lr = 0.005
I0525 14:08:40.159514 21963 solver.cpp:237] Iteration 50464, loss = 1.16032
I0525 14:08:40.159549 21963 solver.cpp:253]     Train net output #0: loss = 1.16032 (* 1 = 1.16032 loss)
I0525 14:08:40.159566 21963 sgd_solver.cpp:106] Iteration 50464, lr = 0.005
I0525 14:08:48.983896 21963 solver.cpp:237] Iteration 50630, loss = 1.33192
I0525 14:08:48.983938 21963 solver.cpp:253]     Train net output #0: loss = 1.33192 (* 1 = 1.33192 loss)
I0525 14:08:48.983958 21963 sgd_solver.cpp:106] Iteration 50630, lr = 0.005
I0525 14:08:57.810372 21963 solver.cpp:237] Iteration 50796, loss = 1.19209
I0525 14:08:57.810408 21963 solver.cpp:253]     Train net output #0: loss = 1.19209 (* 1 = 1.19209 loss)
I0525 14:08:57.810425 21963 sgd_solver.cpp:106] Iteration 50796, lr = 0.005
I0525 14:09:06.638000 21963 solver.cpp:237] Iteration 50962, loss = 1.05362
I0525 14:09:06.638164 21963 solver.cpp:253]     Train net output #0: loss = 1.05362 (* 1 = 1.05362 loss)
I0525 14:09:06.638177 21963 sgd_solver.cpp:106] Iteration 50962, lr = 0.005
I0525 14:09:36.341573 21963 solver.cpp:237] Iteration 51128, loss = 1.203
I0525 14:09:36.341624 21963 solver.cpp:253]     Train net output #0: loss = 1.203 (* 1 = 1.203 loss)
I0525 14:09:36.341639 21963 sgd_solver.cpp:106] Iteration 51128, lr = 0.005
I0525 14:09:45.160845 21963 solver.cpp:237] Iteration 51294, loss = 1.11533
I0525 14:09:45.161011 21963 solver.cpp:253]     Train net output #0: loss = 1.11533 (* 1 = 1.11533 loss)
I0525 14:09:45.161026 21963 sgd_solver.cpp:106] Iteration 51294, lr = 0.005
I0525 14:09:53.988365 21963 solver.cpp:237] Iteration 51460, loss = 1.02014
I0525 14:09:53.988399 21963 solver.cpp:253]     Train net output #0: loss = 1.02014 (* 1 = 1.02014 loss)
I0525 14:09:53.988417 21963 sgd_solver.cpp:106] Iteration 51460, lr = 0.005
I0525 14:10:02.812314 21963 solver.cpp:237] Iteration 51626, loss = 1.04114
I0525 14:10:02.812350 21963 solver.cpp:253]     Train net output #0: loss = 1.04114 (* 1 = 1.04114 loss)
I0525 14:10:02.812371 21963 sgd_solver.cpp:106] Iteration 51626, lr = 0.005
I0525 14:10:03.824833 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_51646.caffemodel
I0525 14:10:03.899368 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_51646.solverstate
I0525 14:10:11.699558 21963 solver.cpp:237] Iteration 51792, loss = 1.19836
I0525 14:10:11.699599 21963 solver.cpp:253]     Train net output #0: loss = 1.19836 (* 1 = 1.19836 loss)
I0525 14:10:11.699618 21963 sgd_solver.cpp:106] Iteration 51792, lr = 0.005
I0525 14:10:20.525341 21963 solver.cpp:237] Iteration 51958, loss = 0.9714
I0525 14:10:20.525506 21963 solver.cpp:253]     Train net output #0: loss = 0.9714 (* 1 = 0.9714 loss)
I0525 14:10:20.525522 21963 sgd_solver.cpp:106] Iteration 51958, lr = 0.005
I0525 14:10:29.353603 21963 solver.cpp:237] Iteration 52124, loss = 1.0553
I0525 14:10:29.353638 21963 solver.cpp:253]     Train net output #0: loss = 1.0553 (* 1 = 1.0553 loss)
I0525 14:10:29.353660 21963 sgd_solver.cpp:106] Iteration 52124, lr = 0.005
I0525 14:10:59.082314 21963 solver.cpp:237] Iteration 52290, loss = 1.1802
I0525 14:10:59.082509 21963 solver.cpp:253]     Train net output #0: loss = 1.1802 (* 1 = 1.1802 loss)
I0525 14:10:59.082522 21963 sgd_solver.cpp:106] Iteration 52290, lr = 0.005
I0525 14:11:07.899129 21963 solver.cpp:237] Iteration 52456, loss = 0.994199
I0525 14:11:07.899163 21963 solver.cpp:253]     Train net output #0: loss = 0.994199 (* 1 = 0.994199 loss)
I0525 14:11:07.899183 21963 sgd_solver.cpp:106] Iteration 52456, lr = 0.005
I0525 14:11:16.725143 21963 solver.cpp:237] Iteration 52622, loss = 1.32902
I0525 14:11:16.725190 21963 solver.cpp:253]     Train net output #0: loss = 1.32902 (* 1 = 1.32902 loss)
I0525 14:11:16.725205 21963 sgd_solver.cpp:106] Iteration 52622, lr = 0.005
I0525 14:11:25.549108 21963 solver.cpp:237] Iteration 52788, loss = 1.01418
I0525 14:11:25.549144 21963 solver.cpp:253]     Train net output #0: loss = 1.01418 (* 1 = 1.01418 loss)
I0525 14:11:25.549160 21963 sgd_solver.cpp:106] Iteration 52788, lr = 0.005
I0525 14:11:34.378778 21963 solver.cpp:237] Iteration 52954, loss = 1.42443
I0525 14:11:34.378944 21963 solver.cpp:253]     Train net output #0: loss = 1.42443 (* 1 = 1.42443 loss)
I0525 14:11:34.378958 21963 sgd_solver.cpp:106] Iteration 52954, lr = 0.005
I0525 14:11:43.195498 21963 solver.cpp:237] Iteration 53120, loss = 1.00952
I0525 14:11:43.195538 21963 solver.cpp:253]     Train net output #0: loss = 1.00952 (* 1 = 1.00952 loss)
I0525 14:11:43.195557 21963 sgd_solver.cpp:106] Iteration 53120, lr = 0.005
I0525 14:11:52.011350 21963 solver.cpp:237] Iteration 53286, loss = 1.07867
I0525 14:11:52.011385 21963 solver.cpp:253]     Train net output #0: loss = 1.07867 (* 1 = 1.07867 loss)
I0525 14:11:52.011402 21963 sgd_solver.cpp:106] Iteration 53286, lr = 0.005
I0525 14:11:53.342273 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_53312.caffemodel
I0525 14:11:53.417984 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_53312.solverstate
I0525 14:11:54.259523 21963 solver.cpp:341] Iteration 53328, Testing net (#0)
I0525 14:13:02.241034 21963 solver.cpp:409]     Test net output #0: accuracy = 0.893642
I0525 14:13:02.241216 21963 solver.cpp:409]     Test net output #1: loss = 0.336105 (* 1 = 0.336105 loss)
I0525 14:13:29.724603 21963 solver.cpp:237] Iteration 53452, loss = 1.24736
I0525 14:13:29.724653 21963 solver.cpp:253]     Train net output #0: loss = 1.24736 (* 1 = 1.24736 loss)
I0525 14:13:29.724669 21963 sgd_solver.cpp:106] Iteration 53452, lr = 0.005
I0525 14:13:38.556716 21963 solver.cpp:237] Iteration 53618, loss = 1.2058
I0525 14:13:38.556886 21963 solver.cpp:253]     Train net output #0: loss = 1.2058 (* 1 = 1.2058 loss)
I0525 14:13:38.556900 21963 sgd_solver.cpp:106] Iteration 53618, lr = 0.005
I0525 14:13:47.385221 21963 solver.cpp:237] Iteration 53784, loss = 0.981999
I0525 14:13:47.385263 21963 solver.cpp:253]     Train net output #0: loss = 0.981999 (* 1 = 0.981999 loss)
I0525 14:13:47.385280 21963 sgd_solver.cpp:106] Iteration 53784, lr = 0.005
I0525 14:13:56.216747 21963 solver.cpp:237] Iteration 53950, loss = 0.999176
I0525 14:13:56.216783 21963 solver.cpp:253]     Train net output #0: loss = 0.999176 (* 1 = 0.999176 loss)
I0525 14:13:56.216797 21963 sgd_solver.cpp:106] Iteration 53950, lr = 0.005
I0525 14:14:05.038887 21963 solver.cpp:237] Iteration 54116, loss = 1.28266
I0525 14:14:05.038923 21963 solver.cpp:253]     Train net output #0: loss = 1.28266 (* 1 = 1.28266 loss)
I0525 14:14:05.038941 21963 sgd_solver.cpp:106] Iteration 54116, lr = 0.005
I0525 14:14:13.864287 21963 solver.cpp:237] Iteration 54282, loss = 1.13074
I0525 14:14:13.864477 21963 solver.cpp:253]     Train net output #0: loss = 1.13074 (* 1 = 1.13074 loss)
I0525 14:14:13.864491 21963 sgd_solver.cpp:106] Iteration 54282, lr = 0.005
I0525 14:14:43.538940 21963 solver.cpp:237] Iteration 54448, loss = 1.01064
I0525 14:14:43.538990 21963 solver.cpp:253]     Train net output #0: loss = 1.01064 (* 1 = 1.01064 loss)
I0525 14:14:43.539005 21963 sgd_solver.cpp:106] Iteration 54448, lr = 0.005
I0525 14:14:52.361569 21963 solver.cpp:237] Iteration 54614, loss = 1.18851
I0525 14:14:52.361739 21963 solver.cpp:253]     Train net output #0: loss = 1.18851 (* 1 = 1.18851 loss)
I0525 14:14:52.361752 21963 sgd_solver.cpp:106] Iteration 54614, lr = 0.005
I0525 14:15:01.185457 21963 solver.cpp:237] Iteration 54780, loss = 1.30493
I0525 14:15:01.185492 21963 solver.cpp:253]     Train net output #0: loss = 1.30493 (* 1 = 1.30493 loss)
I0525 14:15:01.185514 21963 sgd_solver.cpp:106] Iteration 54780, lr = 0.005
I0525 14:15:10.013010 21963 solver.cpp:237] Iteration 54946, loss = 0.988066
I0525 14:15:10.013047 21963 solver.cpp:253]     Train net output #0: loss = 0.988066 (* 1 = 0.988066 loss)
I0525 14:15:10.013064 21963 sgd_solver.cpp:106] Iteration 54946, lr = 0.005
I0525 14:15:11.659201 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_54978.caffemodel
I0525 14:15:11.735525 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_54978.solverstate
I0525 14:15:18.912720 21963 solver.cpp:237] Iteration 55112, loss = 1.03648
I0525 14:15:18.912770 21963 solver.cpp:253]     Train net output #0: loss = 1.03648 (* 1 = 1.03648 loss)
I0525 14:15:18.912786 21963 sgd_solver.cpp:106] Iteration 55112, lr = 0.005
I0525 14:15:27.735388 21963 solver.cpp:237] Iteration 55278, loss = 1.19233
I0525 14:15:27.735572 21963 solver.cpp:253]     Train net output #0: loss = 1.19233 (* 1 = 1.19233 loss)
I0525 14:15:27.735586 21963 sgd_solver.cpp:106] Iteration 55278, lr = 0.005
I0525 14:15:36.559713 21963 solver.cpp:237] Iteration 55444, loss = 1.0757
I0525 14:15:36.559747 21963 solver.cpp:253]     Train net output #0: loss = 1.0757 (* 1 = 1.0757 loss)
I0525 14:15:36.559764 21963 sgd_solver.cpp:106] Iteration 55444, lr = 0.005
I0525 14:16:06.271345 21963 solver.cpp:237] Iteration 55610, loss = 1.42016
I0525 14:16:06.271533 21963 solver.cpp:253]     Train net output #0: loss = 1.42016 (* 1 = 1.42016 loss)
I0525 14:16:06.271548 21963 sgd_solver.cpp:106] Iteration 55610, lr = 0.005
I0525 14:16:15.105872 21963 solver.cpp:237] Iteration 55776, loss = 1.28551
I0525 14:16:15.105911 21963 solver.cpp:253]     Train net output #0: loss = 1.28551 (* 1 = 1.28551 loss)
I0525 14:16:15.105928 21963 sgd_solver.cpp:106] Iteration 55776, lr = 0.005
I0525 14:16:23.934828 21963 solver.cpp:237] Iteration 55942, loss = 1.04768
I0525 14:16:23.934862 21963 solver.cpp:253]     Train net output #0: loss = 1.04768 (* 1 = 1.04768 loss)
I0525 14:16:23.934876 21963 sgd_solver.cpp:106] Iteration 55942, lr = 0.005
I0525 14:16:32.764488 21963 solver.cpp:237] Iteration 56108, loss = 1.267
I0525 14:16:32.764523 21963 solver.cpp:253]     Train net output #0: loss = 1.267 (* 1 = 1.267 loss)
I0525 14:16:32.764539 21963 sgd_solver.cpp:106] Iteration 56108, lr = 0.005
I0525 14:16:41.601248 21963 solver.cpp:237] Iteration 56274, loss = 1.02479
I0525 14:16:41.601419 21963 solver.cpp:253]     Train net output #0: loss = 1.02479 (* 1 = 1.02479 loss)
I0525 14:16:41.601433 21963 sgd_solver.cpp:106] Iteration 56274, lr = 0.005
I0525 14:16:50.427433 21963 solver.cpp:237] Iteration 56440, loss = 1.17739
I0525 14:16:50.427467 21963 solver.cpp:253]     Train net output #0: loss = 1.17739 (* 1 = 1.17739 loss)
I0525 14:16:50.427484 21963 sgd_solver.cpp:106] Iteration 56440, lr = 0.005
I0525 14:16:59.263635 21963 solver.cpp:237] Iteration 56606, loss = 1.18306
I0525 14:16:59.263670 21963 solver.cpp:253]     Train net output #0: loss = 1.18306 (* 1 = 1.18306 loss)
I0525 14:16:59.263686 21963 sgd_solver.cpp:106] Iteration 56606, lr = 0.005
I0525 14:17:01.231947 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_56644.caffemodel
I0525 14:17:01.308533 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_56644.solverstate
I0525 14:17:02.203019 21963 solver.cpp:341] Iteration 56661, Testing net (#0)
I0525 14:17:49.398380 21963 solver.cpp:409]     Test net output #0: accuracy = 0.894556
I0525 14:17:49.398573 21963 solver.cpp:409]     Test net output #1: loss = 0.352997 (* 1 = 0.352997 loss)
I0525 14:18:16.171123 21963 solver.cpp:237] Iteration 56772, loss = 1.01004
I0525 14:18:16.171172 21963 solver.cpp:253]     Train net output #0: loss = 1.01004 (* 1 = 1.01004 loss)
I0525 14:18:16.171190 21963 sgd_solver.cpp:106] Iteration 56772, lr = 0.005
I0525 14:18:24.994369 21963 solver.cpp:237] Iteration 56938, loss = 1.47957
I0525 14:18:24.994544 21963 solver.cpp:253]     Train net output #0: loss = 1.47957 (* 1 = 1.47957 loss)
I0525 14:18:24.994559 21963 sgd_solver.cpp:106] Iteration 56938, lr = 0.005
I0525 14:18:33.821157 21963 solver.cpp:237] Iteration 57104, loss = 1.23527
I0525 14:18:33.821192 21963 solver.cpp:253]     Train net output #0: loss = 1.23527 (* 1 = 1.23527 loss)
I0525 14:18:33.821208 21963 sgd_solver.cpp:106] Iteration 57104, lr = 0.005
I0525 14:18:42.648897 21963 solver.cpp:237] Iteration 57270, loss = 1.28827
I0525 14:18:42.648932 21963 solver.cpp:253]     Train net output #0: loss = 1.28827 (* 1 = 1.28827 loss)
I0525 14:18:42.648947 21963 sgd_solver.cpp:106] Iteration 57270, lr = 0.005
I0525 14:18:51.477335 21963 solver.cpp:237] Iteration 57436, loss = 1.13084
I0525 14:18:51.477380 21963 solver.cpp:253]     Train net output #0: loss = 1.13084 (* 1 = 1.13084 loss)
I0525 14:18:51.477394 21963 sgd_solver.cpp:106] Iteration 57436, lr = 0.005
I0525 14:19:00.309021 21963 solver.cpp:237] Iteration 57602, loss = 1.41633
I0525 14:19:00.309187 21963 solver.cpp:253]     Train net output #0: loss = 1.41633 (* 1 = 1.41633 loss)
I0525 14:19:00.309201 21963 sgd_solver.cpp:106] Iteration 57602, lr = 0.005
I0525 14:19:09.124873 21963 solver.cpp:237] Iteration 57768, loss = 1.21655
I0525 14:19:09.124919 21963 solver.cpp:253]     Train net output #0: loss = 1.21655 (* 1 = 1.21655 loss)
I0525 14:19:09.124936 21963 sgd_solver.cpp:106] Iteration 57768, lr = 0.005
I0525 14:19:38.849273 21963 solver.cpp:237] Iteration 57934, loss = 1.19715
I0525 14:19:38.849459 21963 solver.cpp:253]     Train net output #0: loss = 1.19715 (* 1 = 1.19715 loss)
I0525 14:19:38.849473 21963 sgd_solver.cpp:106] Iteration 57934, lr = 0.005
I0525 14:19:47.665127 21963 solver.cpp:237] Iteration 58100, loss = 1.29249
I0525 14:19:47.665155 21963 solver.cpp:253]     Train net output #0: loss = 1.29249 (* 1 = 1.29249 loss)
I0525 14:19:47.665177 21963 sgd_solver.cpp:106] Iteration 58100, lr = 0.005
I0525 14:19:56.487303 21963 solver.cpp:237] Iteration 58266, loss = 0.999987
I0525 14:19:56.487339 21963 solver.cpp:253]     Train net output #0: loss = 0.999987 (* 1 = 0.999987 loss)
I0525 14:19:56.487355 21963 sgd_solver.cpp:106] Iteration 58266, lr = 0.005
I0525 14:19:58.773250 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_58310.caffemodel
I0525 14:19:58.849647 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_58310.solverstate
I0525 14:20:05.379362 21963 solver.cpp:237] Iteration 58432, loss = 1.00956
I0525 14:20:05.379408 21963 solver.cpp:253]     Train net output #0: loss = 1.00956 (* 1 = 1.00956 loss)
I0525 14:20:05.379426 21963 sgd_solver.cpp:106] Iteration 58432, lr = 0.005
I0525 14:20:14.209091 21963 solver.cpp:237] Iteration 58598, loss = 1.16777
I0525 14:20:14.209275 21963 solver.cpp:253]     Train net output #0: loss = 1.16777 (* 1 = 1.16777 loss)
I0525 14:20:14.209290 21963 sgd_solver.cpp:106] Iteration 58598, lr = 0.005
I0525 14:20:23.040283 21963 solver.cpp:237] Iteration 58764, loss = 1.11542
I0525 14:20:23.040320 21963 solver.cpp:253]     Train net output #0: loss = 1.11542 (* 1 = 1.11542 loss)
I0525 14:20:23.040338 21963 sgd_solver.cpp:106] Iteration 58764, lr = 0.005
I0525 14:20:52.741971 21963 solver.cpp:237] Iteration 58930, loss = 1.19405
I0525 14:20:52.742161 21963 solver.cpp:253]     Train net output #0: loss = 1.19405 (* 1 = 1.19405 loss)
I0525 14:20:52.742174 21963 sgd_solver.cpp:106] Iteration 58930, lr = 0.005
I0525 14:21:01.569900 21963 solver.cpp:237] Iteration 59096, loss = 1.15954
I0525 14:21:01.569934 21963 solver.cpp:253]     Train net output #0: loss = 1.15954 (* 1 = 1.15954 loss)
I0525 14:21:01.569950 21963 sgd_solver.cpp:106] Iteration 59096, lr = 0.005
I0525 14:21:10.391719 21963 solver.cpp:237] Iteration 59262, loss = 1.03788
I0525 14:21:10.391753 21963 solver.cpp:253]     Train net output #0: loss = 1.03788 (* 1 = 1.03788 loss)
I0525 14:21:10.391770 21963 sgd_solver.cpp:106] Iteration 59262, lr = 0.005
I0525 14:21:19.214989 21963 solver.cpp:237] Iteration 59428, loss = 1.11254
I0525 14:21:19.215032 21963 solver.cpp:253]     Train net output #0: loss = 1.11254 (* 1 = 1.11254 loss)
I0525 14:21:19.215047 21963 sgd_solver.cpp:106] Iteration 59428, lr = 0.005
I0525 14:21:28.052075 21963 solver.cpp:237] Iteration 59594, loss = 1.14914
I0525 14:21:28.052242 21963 solver.cpp:253]     Train net output #0: loss = 1.14914 (* 1 = 1.14914 loss)
I0525 14:21:28.052255 21963 sgd_solver.cpp:106] Iteration 59594, lr = 0.005
I0525 14:21:36.879068 21963 solver.cpp:237] Iteration 59760, loss = 1.22707
I0525 14:21:36.879103 21963 solver.cpp:253]     Train net output #0: loss = 1.22707 (* 1 = 1.22707 loss)
I0525 14:21:36.879120 21963 sgd_solver.cpp:106] Iteration 59760, lr = 0.005
I0525 14:21:45.709486 21963 solver.cpp:237] Iteration 59926, loss = 1.26043
I0525 14:21:45.709524 21963 solver.cpp:253]     Train net output #0: loss = 1.26043 (* 1 = 1.26043 loss)
I0525 14:21:45.709544 21963 sgd_solver.cpp:106] Iteration 59926, lr = 0.005
I0525 14:21:48.317479 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_59976.caffemodel
I0525 14:21:48.394987 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_59976.solverstate
I0525 14:21:49.343212 21963 solver.cpp:341] Iteration 59994, Testing net (#0)
I0525 14:22:57.478610 21963 solver.cpp:409]     Test net output #0: accuracy = 0.896637
I0525 14:22:57.478797 21963 solver.cpp:409]     Test net output #1: loss = 0.331729 (* 1 = 0.331729 loss)
I0525 14:23:23.572356 21963 solver.cpp:237] Iteration 60092, loss = 1.20584
I0525 14:23:23.572405 21963 solver.cpp:253]     Train net output #0: loss = 1.20584 (* 1 = 1.20584 loss)
I0525 14:23:23.572422 21963 sgd_solver.cpp:106] Iteration 60092, lr = 0.005
I0525 14:23:32.399315 21963 solver.cpp:237] Iteration 60258, loss = 1.09843
I0525 14:23:32.399489 21963 solver.cpp:253]     Train net output #0: loss = 1.09843 (* 1 = 1.09843 loss)
I0525 14:23:32.399503 21963 sgd_solver.cpp:106] Iteration 60258, lr = 0.005
I0525 14:23:41.226742 21963 solver.cpp:237] Iteration 60424, loss = 1.44764
I0525 14:23:41.226775 21963 solver.cpp:253]     Train net output #0: loss = 1.44764 (* 1 = 1.44764 loss)
I0525 14:23:41.226793 21963 sgd_solver.cpp:106] Iteration 60424, lr = 0.005
I0525 14:23:50.054451 21963 solver.cpp:237] Iteration 60590, loss = 1.15062
I0525 14:23:50.054488 21963 solver.cpp:253]     Train net output #0: loss = 1.15062 (* 1 = 1.15062 loss)
I0525 14:23:50.054507 21963 sgd_solver.cpp:106] Iteration 60590, lr = 0.005
I0525 14:23:58.881736 21963 solver.cpp:237] Iteration 60756, loss = 1.20969
I0525 14:23:58.881770 21963 solver.cpp:253]     Train net output #0: loss = 1.20969 (* 1 = 1.20969 loss)
I0525 14:23:58.881784 21963 sgd_solver.cpp:106] Iteration 60756, lr = 0.005
I0525 14:24:07.711444 21963 solver.cpp:237] Iteration 60922, loss = 1.06722
I0525 14:24:07.711619 21963 solver.cpp:253]     Train net output #0: loss = 1.06722 (* 1 = 1.06722 loss)
I0525 14:24:07.711632 21963 sgd_solver.cpp:106] Iteration 60922, lr = 0.005
I0525 14:24:16.543298 21963 solver.cpp:237] Iteration 61088, loss = 1.08909
I0525 14:24:16.543339 21963 solver.cpp:253]     Train net output #0: loss = 1.08909 (* 1 = 1.08909 loss)
I0525 14:24:16.543356 21963 sgd_solver.cpp:106] Iteration 61088, lr = 0.005
I0525 14:24:46.256659 21963 solver.cpp:237] Iteration 61254, loss = 1.05599
I0525 14:24:46.256853 21963 solver.cpp:253]     Train net output #0: loss = 1.05599 (* 1 = 1.05599 loss)
I0525 14:24:46.256868 21963 sgd_solver.cpp:106] Iteration 61254, lr = 0.005
I0525 14:24:55.083251 21963 solver.cpp:237] Iteration 61420, loss = 1.03326
I0525 14:24:55.083286 21963 solver.cpp:253]     Train net output #0: loss = 1.03326 (* 1 = 1.03326 loss)
I0525 14:24:55.083302 21963 sgd_solver.cpp:106] Iteration 61420, lr = 0.005
I0525 14:25:03.910776 21963 solver.cpp:237] Iteration 61586, loss = 1.09995
I0525 14:25:03.910816 21963 solver.cpp:253]     Train net output #0: loss = 1.09995 (* 1 = 1.09995 loss)
I0525 14:25:03.910835 21963 sgd_solver.cpp:106] Iteration 61586, lr = 0.005
I0525 14:25:06.836951 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_61642.caffemodel
I0525 14:25:06.912346 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_61642.solverstate
I0525 14:25:12.804925 21963 solver.cpp:237] Iteration 61752, loss = 1.02795
I0525 14:25:12.804967 21963 solver.cpp:253]     Train net output #0: loss = 1.02795 (* 1 = 1.02795 loss)
I0525 14:25:12.804987 21963 sgd_solver.cpp:106] Iteration 61752, lr = 0.005
I0525 14:25:21.631777 21963 solver.cpp:237] Iteration 61918, loss = 1.13039
I0525 14:25:21.631952 21963 solver.cpp:253]     Train net output #0: loss = 1.13039 (* 1 = 1.13039 loss)
I0525 14:25:21.631965 21963 sgd_solver.cpp:106] Iteration 61918, lr = 0.005
I0525 14:25:30.461233 21963 solver.cpp:237] Iteration 62084, loss = 1.15611
I0525 14:25:30.461277 21963 solver.cpp:253]     Train net output #0: loss = 1.15611 (* 1 = 1.15611 loss)
I0525 14:25:30.461297 21963 sgd_solver.cpp:106] Iteration 62084, lr = 0.005
I0525 14:26:00.199558 21963 solver.cpp:237] Iteration 62250, loss = 1.20209
I0525 14:26:00.199745 21963 solver.cpp:253]     Train net output #0: loss = 1.20209 (* 1 = 1.20209 loss)
I0525 14:26:00.199760 21963 sgd_solver.cpp:106] Iteration 62250, lr = 0.005
I0525 14:26:09.026176 21963 solver.cpp:237] Iteration 62416, loss = 1.19528
I0525 14:26:09.026211 21963 solver.cpp:253]     Train net output #0: loss = 1.19528 (* 1 = 1.19528 loss)
I0525 14:26:09.026228 21963 sgd_solver.cpp:106] Iteration 62416, lr = 0.005
I0525 14:26:17.848847 21963 solver.cpp:237] Iteration 62582, loss = 1.17456
I0525 14:26:17.848886 21963 solver.cpp:253]     Train net output #0: loss = 1.17456 (* 1 = 1.17456 loss)
I0525 14:26:17.848903 21963 sgd_solver.cpp:106] Iteration 62582, lr = 0.005
I0525 14:26:26.678310 21963 solver.cpp:237] Iteration 62748, loss = 1.11969
I0525 14:26:26.678346 21963 solver.cpp:253]     Train net output #0: loss = 1.11969 (* 1 = 1.11969 loss)
I0525 14:26:26.678362 21963 sgd_solver.cpp:106] Iteration 62748, lr = 0.005
I0525 14:26:35.511519 21963 solver.cpp:237] Iteration 62914, loss = 1.17777
I0525 14:26:35.511687 21963 solver.cpp:253]     Train net output #0: loss = 1.17777 (* 1 = 1.17777 loss)
I0525 14:26:35.511701 21963 sgd_solver.cpp:106] Iteration 62914, lr = 0.005
I0525 14:26:44.335021 21963 solver.cpp:237] Iteration 63080, loss = 1.29806
I0525 14:26:44.335053 21963 solver.cpp:253]     Train net output #0: loss = 1.29806 (* 1 = 1.29806 loss)
I0525 14:26:44.335075 21963 sgd_solver.cpp:106] Iteration 63080, lr = 0.005
I0525 14:26:53.166218 21963 solver.cpp:237] Iteration 63246, loss = 1.14464
I0525 14:26:53.166252 21963 solver.cpp:253]     Train net output #0: loss = 1.14464 (* 1 = 1.14464 loss)
I0525 14:26:53.166270 21963 sgd_solver.cpp:106] Iteration 63246, lr = 0.005
I0525 14:26:56.411710 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_63308.caffemodel
I0525 14:26:56.486167 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_63308.solverstate
I0525 14:26:57.487236 21963 solver.cpp:341] Iteration 63327, Testing net (#0)
I0525 14:27:44.341015 21963 solver.cpp:409]     Test net output #0: accuracy = 0.896156
I0525 14:27:44.341215 21963 solver.cpp:409]     Test net output #1: loss = 0.330921 (* 1 = 0.330921 loss)
I0525 14:28:09.776034 21963 solver.cpp:237] Iteration 63412, loss = 1.083
I0525 14:28:09.776085 21963 solver.cpp:253]     Train net output #0: loss = 1.083 (* 1 = 1.083 loss)
I0525 14:28:09.776099 21963 sgd_solver.cpp:106] Iteration 63412, lr = 0.005
I0525 14:28:18.605846 21963 solver.cpp:237] Iteration 63578, loss = 1.31116
I0525 14:28:18.606035 21963 solver.cpp:253]     Train net output #0: loss = 1.31116 (* 1 = 1.31116 loss)
I0525 14:28:18.606050 21963 sgd_solver.cpp:106] Iteration 63578, lr = 0.005
I0525 14:28:27.435659 21963 solver.cpp:237] Iteration 63744, loss = 1.08353
I0525 14:28:27.435695 21963 solver.cpp:253]     Train net output #0: loss = 1.08353 (* 1 = 1.08353 loss)
I0525 14:28:27.435713 21963 sgd_solver.cpp:106] Iteration 63744, lr = 0.005
I0525 14:28:36.259202 21963 solver.cpp:237] Iteration 63910, loss = 1.16332
I0525 14:28:36.259237 21963 solver.cpp:253]     Train net output #0: loss = 1.16332 (* 1 = 1.16332 loss)
I0525 14:28:36.259251 21963 sgd_solver.cpp:106] Iteration 63910, lr = 0.005
I0525 14:28:45.085695 21963 solver.cpp:237] Iteration 64076, loss = 1.25044
I0525 14:28:45.085734 21963 solver.cpp:253]     Train net output #0: loss = 1.25044 (* 1 = 1.25044 loss)
I0525 14:28:45.085757 21963 sgd_solver.cpp:106] Iteration 64076, lr = 0.005
I0525 14:28:53.910678 21963 solver.cpp:237] Iteration 64242, loss = 0.972854
I0525 14:28:53.910850 21963 solver.cpp:253]     Train net output #0: loss = 0.972854 (* 1 = 0.972854 loss)
I0525 14:28:53.910864 21963 sgd_solver.cpp:106] Iteration 64242, lr = 0.005
I0525 14:29:02.748538 21963 solver.cpp:237] Iteration 64408, loss = 1.19782
I0525 14:29:02.748572 21963 solver.cpp:253]     Train net output #0: loss = 1.19782 (* 1 = 1.19782 loss)
I0525 14:29:02.748589 21963 sgd_solver.cpp:106] Iteration 64408, lr = 0.005
I0525 14:29:32.421314 21963 solver.cpp:237] Iteration 64574, loss = 1.22766
I0525 14:29:32.421504 21963 solver.cpp:253]     Train net output #0: loss = 1.22766 (* 1 = 1.22766 loss)
I0525 14:29:32.421520 21963 sgd_solver.cpp:106] Iteration 64574, lr = 0.005
I0525 14:29:41.244696 21963 solver.cpp:237] Iteration 64740, loss = 1.09894
I0525 14:29:41.244732 21963 solver.cpp:253]     Train net output #0: loss = 1.09894 (* 1 = 1.09894 loss)
I0525 14:29:41.244755 21963 sgd_solver.cpp:106] Iteration 64740, lr = 0.005
I0525 14:29:50.070863 21963 solver.cpp:237] Iteration 64906, loss = 1.11401
I0525 14:29:50.070897 21963 solver.cpp:253]     Train net output #0: loss = 1.11401 (* 1 = 1.11401 loss)
I0525 14:29:50.070914 21963 sgd_solver.cpp:106] Iteration 64906, lr = 0.005
I0525 14:29:53.629559 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_64974.caffemodel
I0525 14:29:53.706653 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_64974.solverstate
I0525 14:29:58.959538 21963 solver.cpp:237] Iteration 65072, loss = 1.02665
I0525 14:29:58.959583 21963 solver.cpp:253]     Train net output #0: loss = 1.02665 (* 1 = 1.02665 loss)
I0525 14:29:58.959604 21963 sgd_solver.cpp:106] Iteration 65072, lr = 0.005
I0525 14:30:07.787590 21963 solver.cpp:237] Iteration 65238, loss = 1.10564
I0525 14:30:07.787775 21963 solver.cpp:253]     Train net output #0: loss = 1.10564 (* 1 = 1.10564 loss)
I0525 14:30:07.787789 21963 sgd_solver.cpp:106] Iteration 65238, lr = 0.005
I0525 14:30:16.608338 21963 solver.cpp:237] Iteration 65404, loss = 1.11388
I0525 14:30:16.608372 21963 solver.cpp:253]     Train net output #0: loss = 1.11388 (* 1 = 1.11388 loss)
I0525 14:30:16.608389 21963 sgd_solver.cpp:106] Iteration 65404, lr = 0.005
I0525 14:30:46.300269 21963 solver.cpp:237] Iteration 65570, loss = 0.998208
I0525 14:30:46.300463 21963 solver.cpp:253]     Train net output #0: loss = 0.998208 (* 1 = 0.998208 loss)
I0525 14:30:46.300479 21963 sgd_solver.cpp:106] Iteration 65570, lr = 0.005
I0525 14:30:55.128320 21963 solver.cpp:237] Iteration 65736, loss = 1.08585
I0525 14:30:55.128360 21963 solver.cpp:253]     Train net output #0: loss = 1.08585 (* 1 = 1.08585 loss)
I0525 14:30:55.128381 21963 sgd_solver.cpp:106] Iteration 65736, lr = 0.005
I0525 14:31:03.945894 21963 solver.cpp:237] Iteration 65902, loss = 1.09512
I0525 14:31:03.945930 21963 solver.cpp:253]     Train net output #0: loss = 1.09512 (* 1 = 1.09512 loss)
I0525 14:31:03.945946 21963 sgd_solver.cpp:106] Iteration 65902, lr = 0.005
I0525 14:31:12.771762 21963 solver.cpp:237] Iteration 66068, loss = 1.16947
I0525 14:31:12.771797 21963 solver.cpp:253]     Train net output #0: loss = 1.16947 (* 1 = 1.16947 loss)
I0525 14:31:12.771813 21963 sgd_solver.cpp:106] Iteration 66068, lr = 0.005
I0525 14:31:21.610013 21963 solver.cpp:237] Iteration 66234, loss = 1.00518
I0525 14:31:21.610200 21963 solver.cpp:253]     Train net output #0: loss = 1.00518 (* 1 = 1.00518 loss)
I0525 14:31:21.610214 21963 sgd_solver.cpp:106] Iteration 66234, lr = 0.005
I0525 14:31:30.439748 21963 solver.cpp:237] Iteration 66400, loss = 1.28968
I0525 14:31:30.439782 21963 solver.cpp:253]     Train net output #0: loss = 1.28968 (* 1 = 1.28968 loss)
I0525 14:31:30.439800 21963 sgd_solver.cpp:106] Iteration 66400, lr = 0.005
I0525 14:31:39.276245 21963 solver.cpp:237] Iteration 66566, loss = 1.1351
I0525 14:31:39.276289 21963 solver.cpp:253]     Train net output #0: loss = 1.1351 (* 1 = 1.1351 loss)
I0525 14:31:39.276306 21963 sgd_solver.cpp:106] Iteration 66566, lr = 0.005
I0525 14:31:43.161823 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_66640.caffemodel
I0525 14:31:43.238579 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_66640.solverstate
I0525 14:31:44.296849 21963 solver.cpp:341] Iteration 66660, Testing net (#0)
I0525 14:32:52.346504 21963 solver.cpp:409]     Test net output #0: accuracy = 0.897317
I0525 14:32:52.346701 21963 solver.cpp:409]     Test net output #1: loss = 0.32816 (* 1 = 0.32816 loss)
I0525 14:33:17.036691 21963 solver.cpp:237] Iteration 66732, loss = 1.01594
I0525 14:33:17.036742 21963 solver.cpp:253]     Train net output #0: loss = 1.01594 (* 1 = 1.01594 loss)
I0525 14:33:17.036757 21963 sgd_solver.cpp:106] Iteration 66732, lr = 0.005
I0525 14:33:25.864888 21963 solver.cpp:237] Iteration 66898, loss = 1.16735
I0525 14:33:25.865066 21963 solver.cpp:253]     Train net output #0: loss = 1.16735 (* 1 = 1.16735 loss)
I0525 14:33:25.865079 21963 sgd_solver.cpp:106] Iteration 66898, lr = 0.005
I0525 14:33:34.702723 21963 solver.cpp:237] Iteration 67064, loss = 1.03843
I0525 14:33:34.702757 21963 solver.cpp:253]     Train net output #0: loss = 1.03843 (* 1 = 1.03843 loss)
I0525 14:33:34.702771 21963 sgd_solver.cpp:106] Iteration 67064, lr = 0.005
I0525 14:33:43.535312 21963 solver.cpp:237] Iteration 67230, loss = 1.07714
I0525 14:33:43.535356 21963 solver.cpp:253]     Train net output #0: loss = 1.07714 (* 1 = 1.07714 loss)
I0525 14:33:43.535374 21963 sgd_solver.cpp:106] Iteration 67230, lr = 0.005
I0525 14:33:52.367460 21963 solver.cpp:237] Iteration 67396, loss = 1.17896
I0525 14:33:52.367496 21963 solver.cpp:253]     Train net output #0: loss = 1.17896 (* 1 = 1.17896 loss)
I0525 14:33:52.367508 21963 sgd_solver.cpp:106] Iteration 67396, lr = 0.005
I0525 14:34:01.200544 21963 solver.cpp:237] Iteration 67562, loss = 1.11706
I0525 14:34:01.200727 21963 solver.cpp:253]     Train net output #0: loss = 1.11706 (* 1 = 1.11706 loss)
I0525 14:34:01.200742 21963 sgd_solver.cpp:106] Iteration 67562, lr = 0.005
I0525 14:34:10.027688 21963 solver.cpp:237] Iteration 67728, loss = 1.00207
I0525 14:34:10.027729 21963 solver.cpp:253]     Train net output #0: loss = 1.00207 (* 1 = 1.00207 loss)
I0525 14:34:10.027745 21963 sgd_solver.cpp:106] Iteration 67728, lr = 0.005
I0525 14:34:39.700969 21963 solver.cpp:237] Iteration 67894, loss = 1.25896
I0525 14:34:39.701165 21963 solver.cpp:253]     Train net output #0: loss = 1.25896 (* 1 = 1.25896 loss)
I0525 14:34:39.701180 21963 sgd_solver.cpp:106] Iteration 67894, lr = 0.005
I0525 14:34:48.543018 21963 solver.cpp:237] Iteration 68060, loss = 1.03082
I0525 14:34:48.543051 21963 solver.cpp:253]     Train net output #0: loss = 1.03082 (* 1 = 1.03082 loss)
I0525 14:34:48.543069 21963 sgd_solver.cpp:106] Iteration 68060, lr = 0.005
I0525 14:34:57.383183 21963 solver.cpp:237] Iteration 68226, loss = 1.1266
I0525 14:34:57.383227 21963 solver.cpp:253]     Train net output #0: loss = 1.1266 (* 1 = 1.1266 loss)
I0525 14:34:57.383240 21963 sgd_solver.cpp:106] Iteration 68226, lr = 0.005
I0525 14:35:01.584456 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_68306.caffemodel
I0525 14:35:01.658599 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_68306.solverstate
I0525 14:35:06.279661 21963 solver.cpp:237] Iteration 68392, loss = 1.32078
I0525 14:35:06.279703 21963 solver.cpp:253]     Train net output #0: loss = 1.32078 (* 1 = 1.32078 loss)
I0525 14:35:06.279723 21963 sgd_solver.cpp:106] Iteration 68392, lr = 0.005
I0525 14:35:15.115270 21963 solver.cpp:237] Iteration 68558, loss = 1.30819
I0525 14:35:15.115443 21963 solver.cpp:253]     Train net output #0: loss = 1.30819 (* 1 = 1.30819 loss)
I0525 14:35:15.115456 21963 sgd_solver.cpp:106] Iteration 68558, lr = 0.005
I0525 14:35:23.954421 21963 solver.cpp:237] Iteration 68724, loss = 1.20906
I0525 14:35:23.954464 21963 solver.cpp:253]     Train net output #0: loss = 1.20906 (* 1 = 1.20906 loss)
I0525 14:35:23.954480 21963 sgd_solver.cpp:106] Iteration 68724, lr = 0.005
I0525 14:35:53.684430 21963 solver.cpp:237] Iteration 68890, loss = 1.12333
I0525 14:35:53.684633 21963 solver.cpp:253]     Train net output #0: loss = 1.12333 (* 1 = 1.12333 loss)
I0525 14:35:53.684646 21963 sgd_solver.cpp:106] Iteration 68890, lr = 0.005
I0525 14:36:02.518728 21963 solver.cpp:237] Iteration 69056, loss = 1.17173
I0525 14:36:02.518764 21963 solver.cpp:253]     Train net output #0: loss = 1.17173 (* 1 = 1.17173 loss)
I0525 14:36:02.518779 21963 sgd_solver.cpp:106] Iteration 69056, lr = 0.005
I0525 14:36:11.348453 21963 solver.cpp:237] Iteration 69222, loss = 1.02066
I0525 14:36:11.348487 21963 solver.cpp:253]     Train net output #0: loss = 1.02066 (* 1 = 1.02066 loss)
I0525 14:36:11.348503 21963 sgd_solver.cpp:106] Iteration 69222, lr = 0.005
I0525 14:36:20.193123 21963 solver.cpp:237] Iteration 69388, loss = 1.11814
I0525 14:36:20.193173 21963 solver.cpp:253]     Train net output #0: loss = 1.11814 (* 1 = 1.11814 loss)
I0525 14:36:20.193187 21963 sgd_solver.cpp:106] Iteration 69388, lr = 0.005
I0525 14:36:29.016268 21963 solver.cpp:237] Iteration 69554, loss = 1.10076
I0525 14:36:29.016453 21963 solver.cpp:253]     Train net output #0: loss = 1.10076 (* 1 = 1.10076 loss)
I0525 14:36:29.016468 21963 sgd_solver.cpp:106] Iteration 69554, lr = 0.005
I0525 14:36:37.859355 21963 solver.cpp:237] Iteration 69720, loss = 1.18083
I0525 14:36:37.859388 21963 solver.cpp:253]     Train net output #0: loss = 1.18083 (* 1 = 1.18083 loss)
I0525 14:36:37.859406 21963 sgd_solver.cpp:106] Iteration 69720, lr = 0.005
I0525 14:36:46.688598 21963 solver.cpp:237] Iteration 69886, loss = 1.19453
I0525 14:36:46.688640 21963 solver.cpp:253]     Train net output #0: loss = 1.19453 (* 1 = 1.19453 loss)
I0525 14:36:46.688657 21963 sgd_solver.cpp:106] Iteration 69886, lr = 0.005
I0525 14:36:51.212687 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_69972.caffemodel
I0525 14:36:51.287634 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_69972.solverstate
I0525 14:36:52.394920 21963 solver.cpp:341] Iteration 69993, Testing net (#0)
I0525 14:37:39.518043 21963 solver.cpp:409]     Test net output #0: accuracy = 0.89681
I0525 14:37:39.518235 21963 solver.cpp:409]     Test net output #1: loss = 0.334475 (* 1 = 0.334475 loss)
I0525 14:38:03.523624 21963 solver.cpp:237] Iteration 70052, loss = 0.960453
I0525 14:38:03.523674 21963 solver.cpp:253]     Train net output #0: loss = 0.960453 (* 1 = 0.960453 loss)
I0525 14:38:03.523689 21963 sgd_solver.cpp:106] Iteration 70052, lr = 0.005
I0525 14:38:12.345109 21963 solver.cpp:237] Iteration 70218, loss = 1.01074
I0525 14:38:12.345288 21963 solver.cpp:253]     Train net output #0: loss = 1.01074 (* 1 = 1.01074 loss)
I0525 14:38:12.345302 21963 sgd_solver.cpp:106] Iteration 70218, lr = 0.005
I0525 14:38:21.170369 21963 solver.cpp:237] Iteration 70384, loss = 1.0823
I0525 14:38:21.170409 21963 solver.cpp:253]     Train net output #0: loss = 1.0823 (* 1 = 1.0823 loss)
I0525 14:38:21.170428 21963 sgd_solver.cpp:106] Iteration 70384, lr = 0.005
I0525 14:38:30.000002 21963 solver.cpp:237] Iteration 70550, loss = 1.12696
I0525 14:38:30.000037 21963 solver.cpp:253]     Train net output #0: loss = 1.12696 (* 1 = 1.12696 loss)
I0525 14:38:30.000051 21963 sgd_solver.cpp:106] Iteration 70550, lr = 0.005
I0525 14:38:38.823824 21963 solver.cpp:237] Iteration 70716, loss = 0.976173
I0525 14:38:38.823860 21963 solver.cpp:253]     Train net output #0: loss = 0.976173 (* 1 = 0.976173 loss)
I0525 14:38:38.823875 21963 sgd_solver.cpp:106] Iteration 70716, lr = 0.005
I0525 14:38:47.649955 21963 solver.cpp:237] Iteration 70882, loss = 1.25291
I0525 14:38:47.650148 21963 solver.cpp:253]     Train net output #0: loss = 1.25291 (* 1 = 1.25291 loss)
I0525 14:38:47.650162 21963 sgd_solver.cpp:106] Iteration 70882, lr = 0.005
I0525 14:38:56.481465 21963 solver.cpp:237] Iteration 71048, loss = 1.04883
I0525 14:38:56.481499 21963 solver.cpp:253]     Train net output #0: loss = 1.04883 (* 1 = 1.04883 loss)
I0525 14:38:56.481513 21963 sgd_solver.cpp:106] Iteration 71048, lr = 0.005
I0525 14:39:26.185398 21963 solver.cpp:237] Iteration 71214, loss = 1.03217
I0525 14:39:26.185593 21963 solver.cpp:253]     Train net output #0: loss = 1.03217 (* 1 = 1.03217 loss)
I0525 14:39:26.185608 21963 sgd_solver.cpp:106] Iteration 71214, lr = 0.005
I0525 14:39:35.005023 21963 solver.cpp:237] Iteration 71380, loss = 1.09433
I0525 14:39:35.005069 21963 solver.cpp:253]     Train net output #0: loss = 1.09433 (* 1 = 1.09433 loss)
I0525 14:39:35.005086 21963 sgd_solver.cpp:106] Iteration 71380, lr = 0.005
I0525 14:39:43.828297 21963 solver.cpp:237] Iteration 71546, loss = 1.19783
I0525 14:39:43.828332 21963 solver.cpp:253]     Train net output #0: loss = 1.19783 (* 1 = 1.19783 loss)
I0525 14:39:43.828348 21963 sgd_solver.cpp:106] Iteration 71546, lr = 0.005
I0525 14:39:48.663743 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_71638.caffemodel
I0525 14:39:48.739260 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_71638.solverstate
I0525 14:39:52.717243 21963 solver.cpp:237] Iteration 71712, loss = 1.40551
I0525 14:39:52.717289 21963 solver.cpp:253]     Train net output #0: loss = 1.40551 (* 1 = 1.40551 loss)
I0525 14:39:52.717304 21963 sgd_solver.cpp:106] Iteration 71712, lr = 0.005
I0525 14:40:01.538594 21963 solver.cpp:237] Iteration 71878, loss = 1.05436
I0525 14:40:01.538794 21963 solver.cpp:253]     Train net output #0: loss = 1.05436 (* 1 = 1.05436 loss)
I0525 14:40:01.538808 21963 sgd_solver.cpp:106] Iteration 71878, lr = 0.005
I0525 14:40:10.349416 21963 solver.cpp:237] Iteration 72044, loss = 1.07195
I0525 14:40:10.349452 21963 solver.cpp:253]     Train net output #0: loss = 1.07195 (* 1 = 1.07195 loss)
I0525 14:40:10.349468 21963 sgd_solver.cpp:106] Iteration 72044, lr = 0.005
I0525 14:40:19.165362 21963 solver.cpp:237] Iteration 72210, loss = 1.19695
I0525 14:40:19.165397 21963 solver.cpp:253]     Train net output #0: loss = 1.19695 (* 1 = 1.19695 loss)
I0525 14:40:19.165411 21963 sgd_solver.cpp:106] Iteration 72210, lr = 0.005
I0525 14:40:48.884805 21963 solver.cpp:237] Iteration 72376, loss = 1.19441
I0525 14:40:48.884999 21963 solver.cpp:253]     Train net output #0: loss = 1.19441 (* 1 = 1.19441 loss)
I0525 14:40:48.885012 21963 sgd_solver.cpp:106] Iteration 72376, lr = 0.005
I0525 14:40:57.705759 21963 solver.cpp:237] Iteration 72542, loss = 1.14364
I0525 14:40:57.705792 21963 solver.cpp:253]     Train net output #0: loss = 1.14364 (* 1 = 1.14364 loss)
I0525 14:40:57.705809 21963 sgd_solver.cpp:106] Iteration 72542, lr = 0.005
I0525 14:41:06.521867 21963 solver.cpp:237] Iteration 72708, loss = 1.01818
I0525 14:41:06.521903 21963 solver.cpp:253]     Train net output #0: loss = 1.01818 (* 1 = 1.01818 loss)
I0525 14:41:06.521919 21963 sgd_solver.cpp:106] Iteration 72708, lr = 0.005
I0525 14:41:15.341001 21963 solver.cpp:237] Iteration 72874, loss = 1.21272
I0525 14:41:15.341040 21963 solver.cpp:253]     Train net output #0: loss = 1.21272 (* 1 = 1.21272 loss)
I0525 14:41:15.341058 21963 sgd_solver.cpp:106] Iteration 72874, lr = 0.005
I0525 14:41:24.167057 21963 solver.cpp:237] Iteration 73040, loss = 1.41259
I0525 14:41:24.167234 21963 solver.cpp:253]     Train net output #0: loss = 1.41259 (* 1 = 1.41259 loss)
I0525 14:41:24.167248 21963 sgd_solver.cpp:106] Iteration 73040, lr = 0.005
I0525 14:41:32.984022 21963 solver.cpp:237] Iteration 73206, loss = 1.21522
I0525 14:41:32.984056 21963 solver.cpp:253]     Train net output #0: loss = 1.21522 (* 1 = 1.21522 loss)
I0525 14:41:32.984071 21963 sgd_solver.cpp:106] Iteration 73206, lr = 0.005
I0525 14:41:38.140523 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_73304.caffemodel
I0525 14:41:38.216996 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_73304.solverstate
I0525 14:41:39.378942 21963 solver.cpp:341] Iteration 73326, Testing net (#0)
I0525 14:42:47.491797 21963 solver.cpp:409]     Test net output #0: accuracy = 0.899051
I0525 14:42:47.491991 21963 solver.cpp:409]     Test net output #1: loss = 0.329667 (* 1 = 0.329667 loss)
I0525 14:43:10.839237 21963 solver.cpp:237] Iteration 73372, loss = 1.0931
I0525 14:43:10.839287 21963 solver.cpp:253]     Train net output #0: loss = 1.0931 (* 1 = 1.0931 loss)
I0525 14:43:10.839303 21963 sgd_solver.cpp:106] Iteration 73372, lr = 0.005
I0525 14:43:19.662364 21963 solver.cpp:237] Iteration 73538, loss = 1.00529
I0525 14:43:19.662564 21963 solver.cpp:253]     Train net output #0: loss = 1.00529 (* 1 = 1.00529 loss)
I0525 14:43:19.662578 21963 sgd_solver.cpp:106] Iteration 73538, lr = 0.005
I0525 14:43:28.488875 21963 solver.cpp:237] Iteration 73704, loss = 1.12117
I0525 14:43:28.488910 21963 solver.cpp:253]     Train net output #0: loss = 1.12117 (* 1 = 1.12117 loss)
I0525 14:43:28.488927 21963 sgd_solver.cpp:106] Iteration 73704, lr = 0.005
I0525 14:43:37.310428 21963 solver.cpp:237] Iteration 73870, loss = 1.26713
I0525 14:43:37.310463 21963 solver.cpp:253]     Train net output #0: loss = 1.26713 (* 1 = 1.26713 loss)
I0525 14:43:37.310479 21963 sgd_solver.cpp:106] Iteration 73870, lr = 0.005
I0525 14:43:46.130455 21963 solver.cpp:237] Iteration 74036, loss = 1.06287
I0525 14:43:46.130498 21963 solver.cpp:253]     Train net output #0: loss = 1.06287 (* 1 = 1.06287 loss)
I0525 14:43:46.130514 21963 sgd_solver.cpp:106] Iteration 74036, lr = 0.005
I0525 14:43:54.956573 21963 solver.cpp:237] Iteration 74202, loss = 1.30698
I0525 14:43:54.956749 21963 solver.cpp:253]     Train net output #0: loss = 1.30698 (* 1 = 1.30698 loss)
I0525 14:43:54.956763 21963 sgd_solver.cpp:106] Iteration 74202, lr = 0.005
I0525 14:44:03.777365 21963 solver.cpp:237] Iteration 74368, loss = 1.04004
I0525 14:44:03.777400 21963 solver.cpp:253]     Train net output #0: loss = 1.04004 (* 1 = 1.04004 loss)
I0525 14:44:03.777416 21963 sgd_solver.cpp:106] Iteration 74368, lr = 0.005
I0525 14:44:33.495556 21963 solver.cpp:237] Iteration 74534, loss = 1.15706
I0525 14:44:33.495750 21963 solver.cpp:253]     Train net output #0: loss = 1.15706 (* 1 = 1.15706 loss)
I0525 14:44:33.495765 21963 sgd_solver.cpp:106] Iteration 74534, lr = 0.005
I0525 14:44:42.319226 21963 solver.cpp:237] Iteration 74700, loss = 0.966493
I0525 14:44:42.319257 21963 solver.cpp:253]     Train net output #0: loss = 0.966493 (* 1 = 0.966493 loss)
I0525 14:44:42.319278 21963 sgd_solver.cpp:106] Iteration 74700, lr = 0.005
I0525 14:44:51.152887 21963 solver.cpp:237] Iteration 74866, loss = 1.17076
I0525 14:44:51.152921 21963 solver.cpp:253]     Train net output #0: loss = 1.17076 (* 1 = 1.17076 loss)
I0525 14:44:51.152938 21963 sgd_solver.cpp:106] Iteration 74866, lr = 0.005
I0525 14:44:56.627429 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_74970.caffemodel
I0525 14:44:56.703734 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_74970.solverstate
I0525 14:45:00.041481 21963 solver.cpp:237] Iteration 75032, loss = 1.17611
I0525 14:45:00.041529 21963 solver.cpp:253]     Train net output #0: loss = 1.17611 (* 1 = 1.17611 loss)
I0525 14:45:00.041543 21963 sgd_solver.cpp:106] Iteration 75032, lr = 0.005
I0525 14:45:08.866348 21963 solver.cpp:237] Iteration 75198, loss = 1.1237
I0525 14:45:08.866529 21963 solver.cpp:253]     Train net output #0: loss = 1.1237 (* 1 = 1.1237 loss)
I0525 14:45:08.866544 21963 sgd_solver.cpp:106] Iteration 75198, lr = 0.005
I0525 14:45:17.692612 21963 solver.cpp:237] Iteration 75364, loss = 1.17086
I0525 14:45:17.692646 21963 solver.cpp:253]     Train net output #0: loss = 1.17086 (* 1 = 1.17086 loss)
I0525 14:45:17.692662 21963 sgd_solver.cpp:106] Iteration 75364, lr = 0.005
I0525 14:45:26.509932 21963 solver.cpp:237] Iteration 75530, loss = 1.30706
I0525 14:45:26.509979 21963 solver.cpp:253]     Train net output #0: loss = 1.30706 (* 1 = 1.30706 loss)
I0525 14:45:26.509994 21963 sgd_solver.cpp:106] Iteration 75530, lr = 0.005
I0525 14:45:56.214746 21963 solver.cpp:237] Iteration 75696, loss = 0.923378
I0525 14:45:56.214946 21963 solver.cpp:253]     Train net output #0: loss = 0.923378 (* 1 = 0.923378 loss)
I0525 14:45:56.214961 21963 sgd_solver.cpp:106] Iteration 75696, lr = 0.005
I0525 14:46:05.040104 21963 solver.cpp:237] Iteration 75862, loss = 1.2879
I0525 14:46:05.040139 21963 solver.cpp:253]     Train net output #0: loss = 1.2879 (* 1 = 1.2879 loss)
I0525 14:46:05.040158 21963 sgd_solver.cpp:106] Iteration 75862, lr = 0.005
I0525 14:46:13.866116 21963 solver.cpp:237] Iteration 76028, loss = 1.35449
I0525 14:46:13.866159 21963 solver.cpp:253]     Train net output #0: loss = 1.35449 (* 1 = 1.35449 loss)
I0525 14:46:13.866175 21963 sgd_solver.cpp:106] Iteration 76028, lr = 0.005
I0525 14:46:22.693980 21963 solver.cpp:237] Iteration 76194, loss = 0.881672
I0525 14:46:22.694016 21963 solver.cpp:253]     Train net output #0: loss = 0.881672 (* 1 = 0.881672 loss)
I0525 14:46:22.694031 21963 sgd_solver.cpp:106] Iteration 76194, lr = 0.005
I0525 14:46:31.521491 21963 solver.cpp:237] Iteration 76360, loss = 1.33779
I0525 14:46:31.521675 21963 solver.cpp:253]     Train net output #0: loss = 1.33779 (* 1 = 1.33779 loss)
I0525 14:46:31.521689 21963 sgd_solver.cpp:106] Iteration 76360, lr = 0.005
I0525 14:46:40.350284 21963 solver.cpp:237] Iteration 76526, loss = 1.11169
I0525 14:46:40.350327 21963 solver.cpp:253]     Train net output #0: loss = 1.11169 (* 1 = 1.11169 loss)
I0525 14:46:40.350344 21963 sgd_solver.cpp:106] Iteration 76526, lr = 0.005
I0525 14:46:46.143717 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_76636.caffemodel
I0525 14:46:46.218719 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_76636.solverstate
I0525 14:46:47.429471 21963 solver.cpp:341] Iteration 76659, Testing net (#0)
I0525 14:47:34.309782 21963 solver.cpp:409]     Test net output #0: accuracy = 0.901279
I0525 14:47:34.309988 21963 solver.cpp:409]     Test net output #1: loss = 0.317911 (* 1 = 0.317911 loss)
I0525 14:47:56.955481 21963 solver.cpp:237] Iteration 76692, loss = 1.16268
I0525 14:47:56.955530 21963 solver.cpp:253]     Train net output #0: loss = 1.16268 (* 1 = 1.16268 loss)
I0525 14:47:56.955546 21963 sgd_solver.cpp:106] Iteration 76692, lr = 0.005
I0525 14:48:05.782837 21963 solver.cpp:237] Iteration 76858, loss = 1.24961
I0525 14:48:05.783022 21963 solver.cpp:253]     Train net output #0: loss = 1.24961 (* 1 = 1.24961 loss)
I0525 14:48:05.783036 21963 sgd_solver.cpp:106] Iteration 76858, lr = 0.005
I0525 14:48:14.607841 21963 solver.cpp:237] Iteration 77024, loss = 1.34564
I0525 14:48:14.607874 21963 solver.cpp:253]     Train net output #0: loss = 1.34564 (* 1 = 1.34564 loss)
I0525 14:48:14.607892 21963 sgd_solver.cpp:106] Iteration 77024, lr = 0.005
I0525 14:48:23.431885 21963 solver.cpp:237] Iteration 77190, loss = 1.16932
I0525 14:48:23.431926 21963 solver.cpp:253]     Train net output #0: loss = 1.16932 (* 1 = 1.16932 loss)
I0525 14:48:23.431943 21963 sgd_solver.cpp:106] Iteration 77190, lr = 0.005
I0525 14:48:32.254973 21963 solver.cpp:237] Iteration 77356, loss = 1.25035
I0525 14:48:32.255008 21963 solver.cpp:253]     Train net output #0: loss = 1.25035 (* 1 = 1.25035 loss)
I0525 14:48:32.255024 21963 sgd_solver.cpp:106] Iteration 77356, lr = 0.005
I0525 14:48:41.084692 21963 solver.cpp:237] Iteration 77522, loss = 1.20736
I0525 14:48:41.084882 21963 solver.cpp:253]     Train net output #0: loss = 1.20736 (* 1 = 1.20736 loss)
I0525 14:48:41.084895 21963 sgd_solver.cpp:106] Iteration 77522, lr = 0.005
I0525 14:48:49.919055 21963 solver.cpp:237] Iteration 77688, loss = 1.15583
I0525 14:48:49.919102 21963 solver.cpp:253]     Train net output #0: loss = 1.15583 (* 1 = 1.15583 loss)
I0525 14:48:49.919117 21963 sgd_solver.cpp:106] Iteration 77688, lr = 0.005
I0525 14:49:19.596756 21963 solver.cpp:237] Iteration 77854, loss = 1.18109
I0525 14:49:19.596956 21963 solver.cpp:253]     Train net output #0: loss = 1.18109 (* 1 = 1.18109 loss)
I0525 14:49:19.596971 21963 sgd_solver.cpp:106] Iteration 77854, lr = 0.005
I0525 14:49:28.426420 21963 solver.cpp:237] Iteration 78020, loss = 1.11931
I0525 14:49:28.426455 21963 solver.cpp:253]     Train net output #0: loss = 1.11931 (* 1 = 1.11931 loss)
I0525 14:49:28.426472 21963 sgd_solver.cpp:106] Iteration 78020, lr = 0.005
I0525 14:49:37.256747 21963 solver.cpp:237] Iteration 78186, loss = 1.02818
I0525 14:49:37.256793 21963 solver.cpp:253]     Train net output #0: loss = 1.02818 (* 1 = 1.02818 loss)
I0525 14:49:37.256808 21963 sgd_solver.cpp:106] Iteration 78186, lr = 0.005
I0525 14:49:43.379809 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_78302.caffemodel
I0525 14:49:43.454957 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_78302.solverstate
I0525 14:49:46.157562 21963 solver.cpp:237] Iteration 78352, loss = 0.989611
I0525 14:49:46.157608 21963 solver.cpp:253]     Train net output #0: loss = 0.989611 (* 1 = 0.989611 loss)
I0525 14:49:46.157625 21963 sgd_solver.cpp:106] Iteration 78352, lr = 0.005
I0525 14:49:54.987053 21963 solver.cpp:237] Iteration 78518, loss = 1.27488
I0525 14:49:54.987264 21963 solver.cpp:253]     Train net output #0: loss = 1.27488 (* 1 = 1.27488 loss)
I0525 14:49:54.987277 21963 sgd_solver.cpp:106] Iteration 78518, lr = 0.005
I0525 14:50:03.811002 21963 solver.cpp:237] Iteration 78684, loss = 1.0164
I0525 14:50:03.811045 21963 solver.cpp:253]     Train net output #0: loss = 1.0164 (* 1 = 1.0164 loss)
I0525 14:50:03.811064 21963 sgd_solver.cpp:106] Iteration 78684, lr = 0.005
I0525 14:50:12.636075 21963 solver.cpp:237] Iteration 78850, loss = 1.07639
I0525 14:50:12.636109 21963 solver.cpp:253]     Train net output #0: loss = 1.07639 (* 1 = 1.07639 loss)
I0525 14:50:12.636126 21963 sgd_solver.cpp:106] Iteration 78850, lr = 0.005
I0525 14:50:42.354419 21963 solver.cpp:237] Iteration 79016, loss = 0.967643
I0525 14:50:42.354624 21963 solver.cpp:253]     Train net output #0: loss = 0.967643 (* 1 = 0.967643 loss)
I0525 14:50:42.354640 21963 sgd_solver.cpp:106] Iteration 79016, lr = 0.005
I0525 14:50:51.179471 21963 solver.cpp:237] Iteration 79182, loss = 1.00082
I0525 14:50:51.179512 21963 solver.cpp:253]     Train net output #0: loss = 1.00082 (* 1 = 1.00082 loss)
I0525 14:50:51.179528 21963 sgd_solver.cpp:106] Iteration 79182, lr = 0.005
I0525 14:51:00.006593 21963 solver.cpp:237] Iteration 79348, loss = 1.06474
I0525 14:51:00.006629 21963 solver.cpp:253]     Train net output #0: loss = 1.06474 (* 1 = 1.06474 loss)
I0525 14:51:00.006646 21963 sgd_solver.cpp:106] Iteration 79348, lr = 0.005
I0525 14:51:08.833848 21963 solver.cpp:237] Iteration 79514, loss = 1.0186
I0525 14:51:08.833884 21963 solver.cpp:253]     Train net output #0: loss = 1.0186 (* 1 = 1.0186 loss)
I0525 14:51:08.833899 21963 sgd_solver.cpp:106] Iteration 79514, lr = 0.005
I0525 14:51:17.661463 21963 solver.cpp:237] Iteration 79680, loss = 1.20114
I0525 14:51:17.661650 21963 solver.cpp:253]     Train net output #0: loss = 1.20114 (* 1 = 1.20114 loss)
I0525 14:51:17.661665 21963 sgd_solver.cpp:106] Iteration 79680, lr = 0.005
I0525 14:51:26.492251 21963 solver.cpp:237] Iteration 79846, loss = 1.21659
I0525 14:51:26.492285 21963 solver.cpp:253]     Train net output #0: loss = 1.21659 (* 1 = 1.21659 loss)
I0525 14:51:26.492303 21963 sgd_solver.cpp:106] Iteration 79846, lr = 0.005
I0525 14:51:32.930701 21963 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_79968.caffemodel
I0525 14:51:33.005113 21963 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0050_2016-05-20T15.49.23.604564_iter_79968.solverstate
I0525 14:51:34.273511 21963 solver.cpp:341] Iteration 79992, Testing net (#0)
aprun: Apid 11264233: Caught signal Terminated, sending to application
*** Aborted at 1464202323 (unix time) try "date -d @1464202323" if you are using GNU date ***
aprun: Apid 11264233: Caught signal Terminated, sending to application
PC: @     0x2aaab9899078 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
*** SIGTERM (@0x55c8) received by PID 21963 (TID 0x2aaac746f900) from PID 21960; stack trace: ***
aprun: Apid 11264233: Caught signal Terminated, sending to application
aprun: Apid 11264233: Caught signal Terminated, sending to application
aprun: Apid 11264233: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7208 exceeded limit 7200
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab9899078 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab928910d (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab928cda8 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab92892f0 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab928c039 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab9265cd0 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab9266458 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11264233: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 00813] [c2-1c0s6n3] [Wed May 25 14:52:05 2016] PE RANK 0 exit signal Terminated
Application 11264233 exit codes: 143
Application 11264233 resources: utime ~6207s, stime ~985s, Rss ~5332656, inblocks ~16309269, outblocks ~740496
