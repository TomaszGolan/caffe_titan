2807706
I0522 16:10:04.664059 31280 caffe.cpp:184] Using GPUs 0
I0522 16:10:05.094041 31280 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0005
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003.prototxt"
I0522 16:10:05.096053 31280 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003.prototxt
I0522 16:10:05.108098 31280 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 16:10:05.108157 31280 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 16:10:05.108505 31280 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 16:10:05.108687 31280 layer_factory.hpp:77] Creating layer data_hdf5
I0522 16:10:05.108711 31280 net.cpp:106] Creating Layer data_hdf5
I0522 16:10:05.108726 31280 net.cpp:411] data_hdf5 -> data
I0522 16:10:05.108760 31280 net.cpp:411] data_hdf5 -> label
I0522 16:10:05.108793 31280 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 16:10:05.110229 31280 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 16:10:05.112506 31280 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 16:10:26.639273 31280 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 16:10:26.644479 31280 net.cpp:150] Setting up data_hdf5
I0522 16:10:26.644523 31280 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 16:10:26.644537 31280 net.cpp:157] Top shape: 40 (40)
I0522 16:10:26.644547 31280 net.cpp:165] Memory required for data: 1016160
I0522 16:10:26.644561 31280 layer_factory.hpp:77] Creating layer conv1
I0522 16:10:26.644595 31280 net.cpp:106] Creating Layer conv1
I0522 16:10:26.644606 31280 net.cpp:454] conv1 <- data
I0522 16:10:26.644629 31280 net.cpp:411] conv1 -> conv1
I0522 16:10:27.006683 31280 net.cpp:150] Setting up conv1
I0522 16:10:27.006731 31280 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 16:10:27.006742 31280 net.cpp:165] Memory required for data: 12075360
I0522 16:10:27.006772 31280 layer_factory.hpp:77] Creating layer relu1
I0522 16:10:27.006793 31280 net.cpp:106] Creating Layer relu1
I0522 16:10:27.006805 31280 net.cpp:454] relu1 <- conv1
I0522 16:10:27.006819 31280 net.cpp:397] relu1 -> conv1 (in-place)
I0522 16:10:27.007335 31280 net.cpp:150] Setting up relu1
I0522 16:10:27.007351 31280 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 16:10:27.007362 31280 net.cpp:165] Memory required for data: 23134560
I0522 16:10:27.007374 31280 layer_factory.hpp:77] Creating layer pool1
I0522 16:10:27.007390 31280 net.cpp:106] Creating Layer pool1
I0522 16:10:27.007400 31280 net.cpp:454] pool1 <- conv1
I0522 16:10:27.007414 31280 net.cpp:411] pool1 -> pool1
I0522 16:10:27.007494 31280 net.cpp:150] Setting up pool1
I0522 16:10:27.007508 31280 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 16:10:27.007519 31280 net.cpp:165] Memory required for data: 28664160
I0522 16:10:27.007529 31280 layer_factory.hpp:77] Creating layer conv2
I0522 16:10:27.007552 31280 net.cpp:106] Creating Layer conv2
I0522 16:10:27.007562 31280 net.cpp:454] conv2 <- pool1
I0522 16:10:27.007575 31280 net.cpp:411] conv2 -> conv2
I0522 16:10:27.010256 31280 net.cpp:150] Setting up conv2
I0522 16:10:27.010284 31280 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 16:10:27.010295 31280 net.cpp:165] Memory required for data: 36612960
I0522 16:10:27.010314 31280 layer_factory.hpp:77] Creating layer relu2
I0522 16:10:27.010329 31280 net.cpp:106] Creating Layer relu2
I0522 16:10:27.010339 31280 net.cpp:454] relu2 <- conv2
I0522 16:10:27.010351 31280 net.cpp:397] relu2 -> conv2 (in-place)
I0522 16:10:27.010681 31280 net.cpp:150] Setting up relu2
I0522 16:10:27.010696 31280 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 16:10:27.010707 31280 net.cpp:165] Memory required for data: 44561760
I0522 16:10:27.010717 31280 layer_factory.hpp:77] Creating layer pool2
I0522 16:10:27.010730 31280 net.cpp:106] Creating Layer pool2
I0522 16:10:27.010740 31280 net.cpp:454] pool2 <- conv2
I0522 16:10:27.010756 31280 net.cpp:411] pool2 -> pool2
I0522 16:10:27.010838 31280 net.cpp:150] Setting up pool2
I0522 16:10:27.010851 31280 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 16:10:27.010861 31280 net.cpp:165] Memory required for data: 48536160
I0522 16:10:27.010871 31280 layer_factory.hpp:77] Creating layer conv3
I0522 16:10:27.010890 31280 net.cpp:106] Creating Layer conv3
I0522 16:10:27.010900 31280 net.cpp:454] conv3 <- pool2
I0522 16:10:27.010913 31280 net.cpp:411] conv3 -> conv3
I0522 16:10:27.012850 31280 net.cpp:150] Setting up conv3
I0522 16:10:27.012872 31280 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 16:10:27.012884 31280 net.cpp:165] Memory required for data: 52872800
I0522 16:10:27.012903 31280 layer_factory.hpp:77] Creating layer relu3
I0522 16:10:27.012919 31280 net.cpp:106] Creating Layer relu3
I0522 16:10:27.012929 31280 net.cpp:454] relu3 <- conv3
I0522 16:10:27.012943 31280 net.cpp:397] relu3 -> conv3 (in-place)
I0522 16:10:27.013408 31280 net.cpp:150] Setting up relu3
I0522 16:10:27.013425 31280 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 16:10:27.013437 31280 net.cpp:165] Memory required for data: 57209440
I0522 16:10:27.013447 31280 layer_factory.hpp:77] Creating layer pool3
I0522 16:10:27.013460 31280 net.cpp:106] Creating Layer pool3
I0522 16:10:27.013469 31280 net.cpp:454] pool3 <- conv3
I0522 16:10:27.013483 31280 net.cpp:411] pool3 -> pool3
I0522 16:10:27.013559 31280 net.cpp:150] Setting up pool3
I0522 16:10:27.013573 31280 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 16:10:27.013584 31280 net.cpp:165] Memory required for data: 59377760
I0522 16:10:27.013594 31280 layer_factory.hpp:77] Creating layer conv4
I0522 16:10:27.013612 31280 net.cpp:106] Creating Layer conv4
I0522 16:10:27.013622 31280 net.cpp:454] conv4 <- pool3
I0522 16:10:27.013636 31280 net.cpp:411] conv4 -> conv4
I0522 16:10:27.016383 31280 net.cpp:150] Setting up conv4
I0522 16:10:27.016412 31280 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 16:10:27.016422 31280 net.cpp:165] Memory required for data: 60829280
I0522 16:10:27.016438 31280 layer_factory.hpp:77] Creating layer relu4
I0522 16:10:27.016453 31280 net.cpp:106] Creating Layer relu4
I0522 16:10:27.016463 31280 net.cpp:454] relu4 <- conv4
I0522 16:10:27.016475 31280 net.cpp:397] relu4 -> conv4 (in-place)
I0522 16:10:27.016947 31280 net.cpp:150] Setting up relu4
I0522 16:10:27.016963 31280 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 16:10:27.016973 31280 net.cpp:165] Memory required for data: 62280800
I0522 16:10:27.016983 31280 layer_factory.hpp:77] Creating layer pool4
I0522 16:10:27.016996 31280 net.cpp:106] Creating Layer pool4
I0522 16:10:27.017006 31280 net.cpp:454] pool4 <- conv4
I0522 16:10:27.017019 31280 net.cpp:411] pool4 -> pool4
I0522 16:10:27.017086 31280 net.cpp:150] Setting up pool4
I0522 16:10:27.017101 31280 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 16:10:27.017112 31280 net.cpp:165] Memory required for data: 63006560
I0522 16:10:27.017122 31280 layer_factory.hpp:77] Creating layer ip1
I0522 16:10:27.017143 31280 net.cpp:106] Creating Layer ip1
I0522 16:10:27.017153 31280 net.cpp:454] ip1 <- pool4
I0522 16:10:27.017165 31280 net.cpp:411] ip1 -> ip1
I0522 16:10:27.032675 31280 net.cpp:150] Setting up ip1
I0522 16:10:27.032702 31280 net.cpp:157] Top shape: 40 196 (7840)
I0522 16:10:27.032721 31280 net.cpp:165] Memory required for data: 63037920
I0522 16:10:27.032749 31280 layer_factory.hpp:77] Creating layer relu5
I0522 16:10:27.032764 31280 net.cpp:106] Creating Layer relu5
I0522 16:10:27.032774 31280 net.cpp:454] relu5 <- ip1
I0522 16:10:27.032788 31280 net.cpp:397] relu5 -> ip1 (in-place)
I0522 16:10:27.033130 31280 net.cpp:150] Setting up relu5
I0522 16:10:27.033144 31280 net.cpp:157] Top shape: 40 196 (7840)
I0522 16:10:27.033155 31280 net.cpp:165] Memory required for data: 63069280
I0522 16:10:27.033165 31280 layer_factory.hpp:77] Creating layer drop1
I0522 16:10:27.033190 31280 net.cpp:106] Creating Layer drop1
I0522 16:10:27.033200 31280 net.cpp:454] drop1 <- ip1
I0522 16:10:27.033211 31280 net.cpp:397] drop1 -> ip1 (in-place)
I0522 16:10:27.033272 31280 net.cpp:150] Setting up drop1
I0522 16:10:27.033285 31280 net.cpp:157] Top shape: 40 196 (7840)
I0522 16:10:27.033295 31280 net.cpp:165] Memory required for data: 63100640
I0522 16:10:27.033305 31280 layer_factory.hpp:77] Creating layer ip2
I0522 16:10:27.033324 31280 net.cpp:106] Creating Layer ip2
I0522 16:10:27.033334 31280 net.cpp:454] ip2 <- ip1
I0522 16:10:27.033347 31280 net.cpp:411] ip2 -> ip2
I0522 16:10:27.033817 31280 net.cpp:150] Setting up ip2
I0522 16:10:27.033829 31280 net.cpp:157] Top shape: 40 98 (3920)
I0522 16:10:27.033839 31280 net.cpp:165] Memory required for data: 63116320
I0522 16:10:27.033854 31280 layer_factory.hpp:77] Creating layer relu6
I0522 16:10:27.033867 31280 net.cpp:106] Creating Layer relu6
I0522 16:10:27.033876 31280 net.cpp:454] relu6 <- ip2
I0522 16:10:27.033888 31280 net.cpp:397] relu6 -> ip2 (in-place)
I0522 16:10:27.034411 31280 net.cpp:150] Setting up relu6
I0522 16:10:27.034427 31280 net.cpp:157] Top shape: 40 98 (3920)
I0522 16:10:27.034437 31280 net.cpp:165] Memory required for data: 63132000
I0522 16:10:27.034448 31280 layer_factory.hpp:77] Creating layer drop2
I0522 16:10:27.034461 31280 net.cpp:106] Creating Layer drop2
I0522 16:10:27.034471 31280 net.cpp:454] drop2 <- ip2
I0522 16:10:27.034484 31280 net.cpp:397] drop2 -> ip2 (in-place)
I0522 16:10:27.034526 31280 net.cpp:150] Setting up drop2
I0522 16:10:27.034539 31280 net.cpp:157] Top shape: 40 98 (3920)
I0522 16:10:27.034550 31280 net.cpp:165] Memory required for data: 63147680
I0522 16:10:27.034559 31280 layer_factory.hpp:77] Creating layer ip3
I0522 16:10:27.034574 31280 net.cpp:106] Creating Layer ip3
I0522 16:10:27.034582 31280 net.cpp:454] ip3 <- ip2
I0522 16:10:27.034595 31280 net.cpp:411] ip3 -> ip3
I0522 16:10:27.034806 31280 net.cpp:150] Setting up ip3
I0522 16:10:27.034819 31280 net.cpp:157] Top shape: 40 11 (440)
I0522 16:10:27.034829 31280 net.cpp:165] Memory required for data: 63149440
I0522 16:10:27.034844 31280 layer_factory.hpp:77] Creating layer drop3
I0522 16:10:27.034857 31280 net.cpp:106] Creating Layer drop3
I0522 16:10:27.034867 31280 net.cpp:454] drop3 <- ip3
I0522 16:10:27.034878 31280 net.cpp:397] drop3 -> ip3 (in-place)
I0522 16:10:27.034919 31280 net.cpp:150] Setting up drop3
I0522 16:10:27.034930 31280 net.cpp:157] Top shape: 40 11 (440)
I0522 16:10:27.034940 31280 net.cpp:165] Memory required for data: 63151200
I0522 16:10:27.034950 31280 layer_factory.hpp:77] Creating layer loss
I0522 16:10:27.034970 31280 net.cpp:106] Creating Layer loss
I0522 16:10:27.034981 31280 net.cpp:454] loss <- ip3
I0522 16:10:27.034991 31280 net.cpp:454] loss <- label
I0522 16:10:27.035003 31280 net.cpp:411] loss -> loss
I0522 16:10:27.035022 31280 layer_factory.hpp:77] Creating layer loss
I0522 16:10:27.035663 31280 net.cpp:150] Setting up loss
I0522 16:10:27.035678 31280 net.cpp:157] Top shape: (1)
I0522 16:10:27.035689 31280 net.cpp:160]     with loss weight 1
I0522 16:10:27.035732 31280 net.cpp:165] Memory required for data: 63151204
I0522 16:10:27.035743 31280 net.cpp:226] loss needs backward computation.
I0522 16:10:27.035754 31280 net.cpp:226] drop3 needs backward computation.
I0522 16:10:27.035761 31280 net.cpp:226] ip3 needs backward computation.
I0522 16:10:27.035773 31280 net.cpp:226] drop2 needs backward computation.
I0522 16:10:27.035783 31280 net.cpp:226] relu6 needs backward computation.
I0522 16:10:27.035792 31280 net.cpp:226] ip2 needs backward computation.
I0522 16:10:27.035802 31280 net.cpp:226] drop1 needs backward computation.
I0522 16:10:27.035812 31280 net.cpp:226] relu5 needs backward computation.
I0522 16:10:27.035822 31280 net.cpp:226] ip1 needs backward computation.
I0522 16:10:27.035832 31280 net.cpp:226] pool4 needs backward computation.
I0522 16:10:27.035842 31280 net.cpp:226] relu4 needs backward computation.
I0522 16:10:27.035852 31280 net.cpp:226] conv4 needs backward computation.
I0522 16:10:27.035862 31280 net.cpp:226] pool3 needs backward computation.
I0522 16:10:27.035873 31280 net.cpp:226] relu3 needs backward computation.
I0522 16:10:27.035883 31280 net.cpp:226] conv3 needs backward computation.
I0522 16:10:27.035903 31280 net.cpp:226] pool2 needs backward computation.
I0522 16:10:27.035914 31280 net.cpp:226] relu2 needs backward computation.
I0522 16:10:27.035924 31280 net.cpp:226] conv2 needs backward computation.
I0522 16:10:27.035934 31280 net.cpp:226] pool1 needs backward computation.
I0522 16:10:27.035945 31280 net.cpp:226] relu1 needs backward computation.
I0522 16:10:27.035955 31280 net.cpp:226] conv1 needs backward computation.
I0522 16:10:27.035966 31280 net.cpp:228] data_hdf5 does not need backward computation.
I0522 16:10:27.035976 31280 net.cpp:270] This network produces output loss
I0522 16:10:27.036000 31280 net.cpp:283] Network initialization done.
I0522 16:10:27.037813 31280 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003.prototxt
I0522 16:10:27.037884 31280 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 16:10:27.038239 31280 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 16:10:27.038429 31280 layer_factory.hpp:77] Creating layer data_hdf5
I0522 16:10:27.038445 31280 net.cpp:106] Creating Layer data_hdf5
I0522 16:10:27.038457 31280 net.cpp:411] data_hdf5 -> data
I0522 16:10:27.038475 31280 net.cpp:411] data_hdf5 -> label
I0522 16:10:27.038491 31280 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 16:10:27.039842 31280 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 16:10:48.373061 31280 net.cpp:150] Setting up data_hdf5
I0522 16:10:48.373229 31280 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 16:10:48.373244 31280 net.cpp:157] Top shape: 40 (40)
I0522 16:10:48.373255 31280 net.cpp:165] Memory required for data: 1016160
I0522 16:10:48.373267 31280 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 16:10:48.373297 31280 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 16:10:48.373308 31280 net.cpp:454] label_data_hdf5_1_split <- label
I0522 16:10:48.373323 31280 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 16:10:48.373344 31280 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 16:10:48.373417 31280 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 16:10:48.373431 31280 net.cpp:157] Top shape: 40 (40)
I0522 16:10:48.373443 31280 net.cpp:157] Top shape: 40 (40)
I0522 16:10:48.373453 31280 net.cpp:165] Memory required for data: 1016480
I0522 16:10:48.373463 31280 layer_factory.hpp:77] Creating layer conv1
I0522 16:10:48.373486 31280 net.cpp:106] Creating Layer conv1
I0522 16:10:48.373497 31280 net.cpp:454] conv1 <- data
I0522 16:10:48.373510 31280 net.cpp:411] conv1 -> conv1
I0522 16:10:48.375460 31280 net.cpp:150] Setting up conv1
I0522 16:10:48.375479 31280 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 16:10:48.375489 31280 net.cpp:165] Memory required for data: 12075680
I0522 16:10:48.375511 31280 layer_factory.hpp:77] Creating layer relu1
I0522 16:10:48.375525 31280 net.cpp:106] Creating Layer relu1
I0522 16:10:48.375536 31280 net.cpp:454] relu1 <- conv1
I0522 16:10:48.375548 31280 net.cpp:397] relu1 -> conv1 (in-place)
I0522 16:10:48.376045 31280 net.cpp:150] Setting up relu1
I0522 16:10:48.376061 31280 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 16:10:48.376072 31280 net.cpp:165] Memory required for data: 23134880
I0522 16:10:48.376082 31280 layer_factory.hpp:77] Creating layer pool1
I0522 16:10:48.376099 31280 net.cpp:106] Creating Layer pool1
I0522 16:10:48.376108 31280 net.cpp:454] pool1 <- conv1
I0522 16:10:48.376123 31280 net.cpp:411] pool1 -> pool1
I0522 16:10:48.376199 31280 net.cpp:150] Setting up pool1
I0522 16:10:48.376212 31280 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 16:10:48.376224 31280 net.cpp:165] Memory required for data: 28664480
I0522 16:10:48.376233 31280 layer_factory.hpp:77] Creating layer conv2
I0522 16:10:48.376251 31280 net.cpp:106] Creating Layer conv2
I0522 16:10:48.376262 31280 net.cpp:454] conv2 <- pool1
I0522 16:10:48.376276 31280 net.cpp:411] conv2 -> conv2
I0522 16:10:48.378190 31280 net.cpp:150] Setting up conv2
I0522 16:10:48.378211 31280 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 16:10:48.378224 31280 net.cpp:165] Memory required for data: 36613280
I0522 16:10:48.378242 31280 layer_factory.hpp:77] Creating layer relu2
I0522 16:10:48.378254 31280 net.cpp:106] Creating Layer relu2
I0522 16:10:48.378264 31280 net.cpp:454] relu2 <- conv2
I0522 16:10:48.378278 31280 net.cpp:397] relu2 -> conv2 (in-place)
I0522 16:10:48.378607 31280 net.cpp:150] Setting up relu2
I0522 16:10:48.378620 31280 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 16:10:48.378630 31280 net.cpp:165] Memory required for data: 44562080
I0522 16:10:48.378641 31280 layer_factory.hpp:77] Creating layer pool2
I0522 16:10:48.378654 31280 net.cpp:106] Creating Layer pool2
I0522 16:10:48.378664 31280 net.cpp:454] pool2 <- conv2
I0522 16:10:48.378676 31280 net.cpp:411] pool2 -> pool2
I0522 16:10:48.378747 31280 net.cpp:150] Setting up pool2
I0522 16:10:48.378762 31280 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 16:10:48.378770 31280 net.cpp:165] Memory required for data: 48536480
I0522 16:10:48.378780 31280 layer_factory.hpp:77] Creating layer conv3
I0522 16:10:48.378800 31280 net.cpp:106] Creating Layer conv3
I0522 16:10:48.378811 31280 net.cpp:454] conv3 <- pool2
I0522 16:10:48.378824 31280 net.cpp:411] conv3 -> conv3
I0522 16:10:48.380785 31280 net.cpp:150] Setting up conv3
I0522 16:10:48.380808 31280 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 16:10:48.380821 31280 net.cpp:165] Memory required for data: 52873120
I0522 16:10:48.380853 31280 layer_factory.hpp:77] Creating layer relu3
I0522 16:10:48.380867 31280 net.cpp:106] Creating Layer relu3
I0522 16:10:48.380877 31280 net.cpp:454] relu3 <- conv3
I0522 16:10:48.380890 31280 net.cpp:397] relu3 -> conv3 (in-place)
I0522 16:10:48.381361 31280 net.cpp:150] Setting up relu3
I0522 16:10:48.381377 31280 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 16:10:48.381388 31280 net.cpp:165] Memory required for data: 57209760
I0522 16:10:48.381398 31280 layer_factory.hpp:77] Creating layer pool3
I0522 16:10:48.381412 31280 net.cpp:106] Creating Layer pool3
I0522 16:10:48.381422 31280 net.cpp:454] pool3 <- conv3
I0522 16:10:48.381434 31280 net.cpp:411] pool3 -> pool3
I0522 16:10:48.381505 31280 net.cpp:150] Setting up pool3
I0522 16:10:48.381526 31280 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 16:10:48.381536 31280 net.cpp:165] Memory required for data: 59378080
I0522 16:10:48.381546 31280 layer_factory.hpp:77] Creating layer conv4
I0522 16:10:48.381564 31280 net.cpp:106] Creating Layer conv4
I0522 16:10:48.381575 31280 net.cpp:454] conv4 <- pool3
I0522 16:10:48.381589 31280 net.cpp:411] conv4 -> conv4
I0522 16:10:48.383652 31280 net.cpp:150] Setting up conv4
I0522 16:10:48.383669 31280 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 16:10:48.383680 31280 net.cpp:165] Memory required for data: 60829600
I0522 16:10:48.383695 31280 layer_factory.hpp:77] Creating layer relu4
I0522 16:10:48.383709 31280 net.cpp:106] Creating Layer relu4
I0522 16:10:48.383719 31280 net.cpp:454] relu4 <- conv4
I0522 16:10:48.383731 31280 net.cpp:397] relu4 -> conv4 (in-place)
I0522 16:10:48.384201 31280 net.cpp:150] Setting up relu4
I0522 16:10:48.384217 31280 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 16:10:48.384227 31280 net.cpp:165] Memory required for data: 62281120
I0522 16:10:48.384238 31280 layer_factory.hpp:77] Creating layer pool4
I0522 16:10:48.384250 31280 net.cpp:106] Creating Layer pool4
I0522 16:10:48.384260 31280 net.cpp:454] pool4 <- conv4
I0522 16:10:48.384274 31280 net.cpp:411] pool4 -> pool4
I0522 16:10:48.384346 31280 net.cpp:150] Setting up pool4
I0522 16:10:48.384359 31280 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 16:10:48.384369 31280 net.cpp:165] Memory required for data: 63006880
I0522 16:10:48.384377 31280 layer_factory.hpp:77] Creating layer ip1
I0522 16:10:48.384393 31280 net.cpp:106] Creating Layer ip1
I0522 16:10:48.384404 31280 net.cpp:454] ip1 <- pool4
I0522 16:10:48.384418 31280 net.cpp:411] ip1 -> ip1
I0522 16:10:48.399907 31280 net.cpp:150] Setting up ip1
I0522 16:10:48.399935 31280 net.cpp:157] Top shape: 40 196 (7840)
I0522 16:10:48.399946 31280 net.cpp:165] Memory required for data: 63038240
I0522 16:10:48.399968 31280 layer_factory.hpp:77] Creating layer relu5
I0522 16:10:48.399983 31280 net.cpp:106] Creating Layer relu5
I0522 16:10:48.399994 31280 net.cpp:454] relu5 <- ip1
I0522 16:10:48.400008 31280 net.cpp:397] relu5 -> ip1 (in-place)
I0522 16:10:48.400355 31280 net.cpp:150] Setting up relu5
I0522 16:10:48.400369 31280 net.cpp:157] Top shape: 40 196 (7840)
I0522 16:10:48.400378 31280 net.cpp:165] Memory required for data: 63069600
I0522 16:10:48.400389 31280 layer_factory.hpp:77] Creating layer drop1
I0522 16:10:48.400408 31280 net.cpp:106] Creating Layer drop1
I0522 16:10:48.400418 31280 net.cpp:454] drop1 <- ip1
I0522 16:10:48.400431 31280 net.cpp:397] drop1 -> ip1 (in-place)
I0522 16:10:48.400476 31280 net.cpp:150] Setting up drop1
I0522 16:10:48.400490 31280 net.cpp:157] Top shape: 40 196 (7840)
I0522 16:10:48.400501 31280 net.cpp:165] Memory required for data: 63100960
I0522 16:10:48.400509 31280 layer_factory.hpp:77] Creating layer ip2
I0522 16:10:48.400524 31280 net.cpp:106] Creating Layer ip2
I0522 16:10:48.400534 31280 net.cpp:454] ip2 <- ip1
I0522 16:10:48.400547 31280 net.cpp:411] ip2 -> ip2
I0522 16:10:48.401026 31280 net.cpp:150] Setting up ip2
I0522 16:10:48.401038 31280 net.cpp:157] Top shape: 40 98 (3920)
I0522 16:10:48.401048 31280 net.cpp:165] Memory required for data: 63116640
I0522 16:10:48.401063 31280 layer_factory.hpp:77] Creating layer relu6
I0522 16:10:48.401088 31280 net.cpp:106] Creating Layer relu6
I0522 16:10:48.401098 31280 net.cpp:454] relu6 <- ip2
I0522 16:10:48.401111 31280 net.cpp:397] relu6 -> ip2 (in-place)
I0522 16:10:48.401659 31280 net.cpp:150] Setting up relu6
I0522 16:10:48.401679 31280 net.cpp:157] Top shape: 40 98 (3920)
I0522 16:10:48.401690 31280 net.cpp:165] Memory required for data: 63132320
I0522 16:10:48.401700 31280 layer_factory.hpp:77] Creating layer drop2
I0522 16:10:48.401715 31280 net.cpp:106] Creating Layer drop2
I0522 16:10:48.401724 31280 net.cpp:454] drop2 <- ip2
I0522 16:10:48.401737 31280 net.cpp:397] drop2 -> ip2 (in-place)
I0522 16:10:48.401782 31280 net.cpp:150] Setting up drop2
I0522 16:10:48.401794 31280 net.cpp:157] Top shape: 40 98 (3920)
I0522 16:10:48.401804 31280 net.cpp:165] Memory required for data: 63148000
I0522 16:10:48.401814 31280 layer_factory.hpp:77] Creating layer ip3
I0522 16:10:48.401829 31280 net.cpp:106] Creating Layer ip3
I0522 16:10:48.401839 31280 net.cpp:454] ip3 <- ip2
I0522 16:10:48.401852 31280 net.cpp:411] ip3 -> ip3
I0522 16:10:48.402076 31280 net.cpp:150] Setting up ip3
I0522 16:10:48.402089 31280 net.cpp:157] Top shape: 40 11 (440)
I0522 16:10:48.402098 31280 net.cpp:165] Memory required for data: 63149760
I0522 16:10:48.402114 31280 layer_factory.hpp:77] Creating layer drop3
I0522 16:10:48.402127 31280 net.cpp:106] Creating Layer drop3
I0522 16:10:48.402137 31280 net.cpp:454] drop3 <- ip3
I0522 16:10:48.402150 31280 net.cpp:397] drop3 -> ip3 (in-place)
I0522 16:10:48.402191 31280 net.cpp:150] Setting up drop3
I0522 16:10:48.402204 31280 net.cpp:157] Top shape: 40 11 (440)
I0522 16:10:48.402215 31280 net.cpp:165] Memory required for data: 63151520
I0522 16:10:48.402225 31280 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 16:10:48.402237 31280 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 16:10:48.402247 31280 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 16:10:48.402261 31280 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 16:10:48.402276 31280 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 16:10:48.402348 31280 net.cpp:150] Setting up ip3_drop3_0_split
I0522 16:10:48.402361 31280 net.cpp:157] Top shape: 40 11 (440)
I0522 16:10:48.402374 31280 net.cpp:157] Top shape: 40 11 (440)
I0522 16:10:48.402384 31280 net.cpp:165] Memory required for data: 63155040
I0522 16:10:48.402393 31280 layer_factory.hpp:77] Creating layer accuracy
I0522 16:10:48.402415 31280 net.cpp:106] Creating Layer accuracy
I0522 16:10:48.402425 31280 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 16:10:48.402436 31280 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 16:10:48.402449 31280 net.cpp:411] accuracy -> accuracy
I0522 16:10:48.402474 31280 net.cpp:150] Setting up accuracy
I0522 16:10:48.402487 31280 net.cpp:157] Top shape: (1)
I0522 16:10:48.402496 31280 net.cpp:165] Memory required for data: 63155044
I0522 16:10:48.402506 31280 layer_factory.hpp:77] Creating layer loss
I0522 16:10:48.402520 31280 net.cpp:106] Creating Layer loss
I0522 16:10:48.402530 31280 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 16:10:48.402541 31280 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 16:10:48.402554 31280 net.cpp:411] loss -> loss
I0522 16:10:48.402572 31280 layer_factory.hpp:77] Creating layer loss
I0522 16:10:48.403058 31280 net.cpp:150] Setting up loss
I0522 16:10:48.403071 31280 net.cpp:157] Top shape: (1)
I0522 16:10:48.403081 31280 net.cpp:160]     with loss weight 1
I0522 16:10:48.403100 31280 net.cpp:165] Memory required for data: 63155048
I0522 16:10:48.403110 31280 net.cpp:226] loss needs backward computation.
I0522 16:10:48.403121 31280 net.cpp:228] accuracy does not need backward computation.
I0522 16:10:48.403132 31280 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 16:10:48.403142 31280 net.cpp:226] drop3 needs backward computation.
I0522 16:10:48.403153 31280 net.cpp:226] ip3 needs backward computation.
I0522 16:10:48.403163 31280 net.cpp:226] drop2 needs backward computation.
I0522 16:10:48.403173 31280 net.cpp:226] relu6 needs backward computation.
I0522 16:10:48.403190 31280 net.cpp:226] ip2 needs backward computation.
I0522 16:10:48.403201 31280 net.cpp:226] drop1 needs backward computation.
I0522 16:10:48.403210 31280 net.cpp:226] relu5 needs backward computation.
I0522 16:10:48.403220 31280 net.cpp:226] ip1 needs backward computation.
I0522 16:10:48.403230 31280 net.cpp:226] pool4 needs backward computation.
I0522 16:10:48.403240 31280 net.cpp:226] relu4 needs backward computation.
I0522 16:10:48.403251 31280 net.cpp:226] conv4 needs backward computation.
I0522 16:10:48.403261 31280 net.cpp:226] pool3 needs backward computation.
I0522 16:10:48.403272 31280 net.cpp:226] relu3 needs backward computation.
I0522 16:10:48.403282 31280 net.cpp:226] conv3 needs backward computation.
I0522 16:10:48.403292 31280 net.cpp:226] pool2 needs backward computation.
I0522 16:10:48.403302 31280 net.cpp:226] relu2 needs backward computation.
I0522 16:10:48.403312 31280 net.cpp:226] conv2 needs backward computation.
I0522 16:10:48.403322 31280 net.cpp:226] pool1 needs backward computation.
I0522 16:10:48.403332 31280 net.cpp:226] relu1 needs backward computation.
I0522 16:10:48.403342 31280 net.cpp:226] conv1 needs backward computation.
I0522 16:10:48.403354 31280 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 16:10:48.403367 31280 net.cpp:228] data_hdf5 does not need backward computation.
I0522 16:10:48.403376 31280 net.cpp:270] This network produces output accuracy
I0522 16:10:48.403388 31280 net.cpp:270] This network produces output loss
I0522 16:10:48.403419 31280 net.cpp:283] Network initialization done.
I0522 16:10:48.403553 31280 solver.cpp:60] Solver scaffolding done.
I0522 16:10:48.404683 31280 caffe.cpp:212] Starting Optimization
I0522 16:10:48.404702 31280 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 16:10:48.404716 31280 solver.cpp:289] Learning Rate Policy: fixed
I0522 16:10:48.405947 31280 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 16:11:37.811832 31280 solver.cpp:409]     Test net output #0: accuracy = 0.12616
I0522 16:11:37.811993 31280 solver.cpp:409]     Test net output #1: loss = 2.39722 (* 1 = 2.39722 loss)
I0522 16:11:37.834631 31280 solver.cpp:237] Iteration 0, loss = 2.39445
I0522 16:11:37.834668 31280 solver.cpp:253]     Train net output #0: loss = 2.39445 (* 1 = 2.39445 loss)
I0522 16:11:37.834686 31280 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0522 16:11:47.688347 31280 solver.cpp:237] Iteration 375, loss = 2.33331
I0522 16:11:47.688392 31280 solver.cpp:253]     Train net output #0: loss = 2.33331 (* 1 = 2.33331 loss)
I0522 16:11:47.688410 31280 sgd_solver.cpp:106] Iteration 375, lr = 0.0005
I0522 16:11:57.544198 31280 solver.cpp:237] Iteration 750, loss = 2.29973
I0522 16:11:57.544234 31280 solver.cpp:253]     Train net output #0: loss = 2.29973 (* 1 = 2.29973 loss)
I0522 16:11:57.544250 31280 sgd_solver.cpp:106] Iteration 750, lr = 0.0005
I0522 16:12:07.385725 31280 solver.cpp:237] Iteration 1125, loss = 2.32298
I0522 16:12:07.385761 31280 solver.cpp:253]     Train net output #0: loss = 2.32298 (* 1 = 2.32298 loss)
I0522 16:12:07.385777 31280 sgd_solver.cpp:106] Iteration 1125, lr = 0.0005
I0522 16:12:17.236495 31280 solver.cpp:237] Iteration 1500, loss = 2.35638
I0522 16:12:17.236654 31280 solver.cpp:253]     Train net output #0: loss = 2.35638 (* 1 = 2.35638 loss)
I0522 16:12:17.236670 31280 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0522 16:12:27.075990 31280 solver.cpp:237] Iteration 1875, loss = 2.26039
I0522 16:12:27.076026 31280 solver.cpp:253]     Train net output #0: loss = 2.26039 (* 1 = 2.26039 loss)
I0522 16:12:27.076043 31280 sgd_solver.cpp:106] Iteration 1875, lr = 0.0005
I0522 16:12:36.925809 31280 solver.cpp:237] Iteration 2250, loss = 2.17504
I0522 16:12:36.925859 31280 solver.cpp:253]     Train net output #0: loss = 2.17504 (* 1 = 2.17504 loss)
I0522 16:12:36.925873 31280 sgd_solver.cpp:106] Iteration 2250, lr = 0.0005
I0522 16:13:08.902395 31280 solver.cpp:237] Iteration 2625, loss = 2.13341
I0522 16:13:08.902557 31280 solver.cpp:253]     Train net output #0: loss = 2.13341 (* 1 = 2.13341 loss)
I0522 16:13:08.902573 31280 sgd_solver.cpp:106] Iteration 2625, lr = 0.0005
I0522 16:13:18.759789 31280 solver.cpp:237] Iteration 3000, loss = 2.08374
I0522 16:13:18.759824 31280 solver.cpp:253]     Train net output #0: loss = 2.08374 (* 1 = 2.08374 loss)
I0522 16:13:18.759842 31280 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0522 16:13:28.606469 31280 solver.cpp:237] Iteration 3375, loss = 2.12322
I0522 16:13:28.606514 31280 solver.cpp:253]     Train net output #0: loss = 2.12322 (* 1 = 2.12322 loss)
I0522 16:13:28.606531 31280 sgd_solver.cpp:106] Iteration 3375, lr = 0.0005
I0522 16:13:38.437841 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_3750.caffemodel
I0522 16:13:38.497639 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_3750.solverstate
I0522 16:13:38.530864 31280 solver.cpp:237] Iteration 3750, loss = 1.93952
I0522 16:13:38.530910 31280 solver.cpp:253]     Train net output #0: loss = 1.93952 (* 1 = 1.93952 loss)
I0522 16:13:38.530925 31280 sgd_solver.cpp:106] Iteration 3750, lr = 0.0005
I0522 16:13:48.382464 31280 solver.cpp:237] Iteration 4125, loss = 2.04088
I0522 16:13:48.382606 31280 solver.cpp:253]     Train net output #0: loss = 2.04088 (* 1 = 2.04088 loss)
I0522 16:13:48.382619 31280 sgd_solver.cpp:106] Iteration 4125, lr = 0.0005
I0522 16:13:58.231780 31280 solver.cpp:237] Iteration 4500, loss = 1.54665
I0522 16:13:58.231824 31280 solver.cpp:253]     Train net output #0: loss = 1.54665 (* 1 = 1.54665 loss)
I0522 16:13:58.231842 31280 sgd_solver.cpp:106] Iteration 4500, lr = 0.0005
I0522 16:14:08.083016 31280 solver.cpp:237] Iteration 4875, loss = 2.1068
I0522 16:14:08.083051 31280 solver.cpp:253]     Train net output #0: loss = 2.1068 (* 1 = 2.1068 loss)
I0522 16:14:08.083068 31280 sgd_solver.cpp:106] Iteration 4875, lr = 0.0005
I0522 16:14:40.041623 31280 solver.cpp:237] Iteration 5250, loss = 1.75182
I0522 16:14:40.041780 31280 solver.cpp:253]     Train net output #0: loss = 1.75182 (* 1 = 1.75182 loss)
I0522 16:14:40.041795 31280 sgd_solver.cpp:106] Iteration 5250, lr = 0.0005
I0522 16:14:49.894026 31280 solver.cpp:237] Iteration 5625, loss = 1.96821
I0522 16:14:49.894075 31280 solver.cpp:253]     Train net output #0: loss = 1.96821 (* 1 = 1.96821 loss)
I0522 16:14:49.894090 31280 sgd_solver.cpp:106] Iteration 5625, lr = 0.0005
I0522 16:14:59.745728 31280 solver.cpp:237] Iteration 6000, loss = 1.55573
I0522 16:14:59.745762 31280 solver.cpp:253]     Train net output #0: loss = 1.55573 (* 1 = 1.55573 loss)
I0522 16:14:59.745780 31280 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0522 16:15:09.594759 31280 solver.cpp:237] Iteration 6375, loss = 1.72896
I0522 16:15:09.594800 31280 solver.cpp:253]     Train net output #0: loss = 1.72896 (* 1 = 1.72896 loss)
I0522 16:15:09.594821 31280 sgd_solver.cpp:106] Iteration 6375, lr = 0.0005
I0522 16:15:19.448225 31280 solver.cpp:237] Iteration 6750, loss = 1.92573
I0522 16:15:19.448376 31280 solver.cpp:253]     Train net output #0: loss = 1.92573 (* 1 = 1.92573 loss)
I0522 16:15:19.448390 31280 sgd_solver.cpp:106] Iteration 6750, lr = 0.0005
I0522 16:15:29.292904 31280 solver.cpp:237] Iteration 7125, loss = 1.87213
I0522 16:15:29.292940 31280 solver.cpp:253]     Train net output #0: loss = 1.87213 (* 1 = 1.87213 loss)
I0522 16:15:29.292954 31280 sgd_solver.cpp:106] Iteration 7125, lr = 0.0005
I0522 16:15:39.115324 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_7500.caffemodel
I0522 16:15:39.172539 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_7500.solverstate
I0522 16:15:39.198386 31280 solver.cpp:341] Iteration 7500, Testing net (#0)
I0522 16:16:27.740751 31280 solver.cpp:409]     Test net output #0: accuracy = 0.63366
I0522 16:16:27.740917 31280 solver.cpp:409]     Test net output #1: loss = 1.24355 (* 1 = 1.24355 loss)
I0522 16:16:49.871659 31280 solver.cpp:237] Iteration 7500, loss = 1.87932
I0522 16:16:49.871711 31280 solver.cpp:253]     Train net output #0: loss = 1.87932 (* 1 = 1.87932 loss)
I0522 16:16:49.871726 31280 sgd_solver.cpp:106] Iteration 7500, lr = 0.0005
I0522 16:16:59.784489 31280 solver.cpp:237] Iteration 7875, loss = 1.80605
I0522 16:16:59.784639 31280 solver.cpp:253]     Train net output #0: loss = 1.80605 (* 1 = 1.80605 loss)
I0522 16:16:59.784654 31280 sgd_solver.cpp:106] Iteration 7875, lr = 0.0005
I0522 16:17:09.696024 31280 solver.cpp:237] Iteration 8250, loss = 1.85215
I0522 16:17:09.696058 31280 solver.cpp:253]     Train net output #0: loss = 1.85215 (* 1 = 1.85215 loss)
I0522 16:17:09.696077 31280 sgd_solver.cpp:106] Iteration 8250, lr = 0.0005
I0522 16:17:19.608772 31280 solver.cpp:237] Iteration 8625, loss = 2.03517
I0522 16:17:19.608813 31280 solver.cpp:253]     Train net output #0: loss = 2.03517 (* 1 = 2.03517 loss)
I0522 16:17:19.608834 31280 sgd_solver.cpp:106] Iteration 8625, lr = 0.0005
I0522 16:17:29.517493 31280 solver.cpp:237] Iteration 9000, loss = 1.88659
I0522 16:17:29.517530 31280 solver.cpp:253]     Train net output #0: loss = 1.88659 (* 1 = 1.88659 loss)
I0522 16:17:29.517546 31280 sgd_solver.cpp:106] Iteration 9000, lr = 0.0005
I0522 16:17:39.429594 31280 solver.cpp:237] Iteration 9375, loss = 1.7812
I0522 16:17:39.429744 31280 solver.cpp:253]     Train net output #0: loss = 1.7812 (* 1 = 1.7812 loss)
I0522 16:17:39.429759 31280 sgd_solver.cpp:106] Iteration 9375, lr = 0.0005
I0522 16:17:49.338551 31280 solver.cpp:237] Iteration 9750, loss = 1.67804
I0522 16:17:49.338585 31280 solver.cpp:253]     Train net output #0: loss = 1.67804 (* 1 = 1.67804 loss)
I0522 16:17:49.338603 31280 sgd_solver.cpp:106] Iteration 9750, lr = 0.0005
I0522 16:18:21.439329 31280 solver.cpp:237] Iteration 10125, loss = 1.54812
I0522 16:18:21.439492 31280 solver.cpp:253]     Train net output #0: loss = 1.54812 (* 1 = 1.54812 loss)
I0522 16:18:21.439508 31280 sgd_solver.cpp:106] Iteration 10125, lr = 0.0005
I0522 16:18:31.353178 31280 solver.cpp:237] Iteration 10500, loss = 1.77846
I0522 16:18:31.353224 31280 solver.cpp:253]     Train net output #0: loss = 1.77846 (* 1 = 1.77846 loss)
I0522 16:18:31.353240 31280 sgd_solver.cpp:106] Iteration 10500, lr = 0.0005
I0522 16:18:41.257410 31280 solver.cpp:237] Iteration 10875, loss = 1.90612
I0522 16:18:41.257446 31280 solver.cpp:253]     Train net output #0: loss = 1.90612 (* 1 = 1.90612 loss)
I0522 16:18:41.257462 31280 sgd_solver.cpp:106] Iteration 10875, lr = 0.0005
I0522 16:18:51.142782 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_11250.caffemodel
I0522 16:18:51.201064 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_11250.solverstate
I0522 16:18:51.236920 31280 solver.cpp:237] Iteration 11250, loss = 1.61705
I0522 16:18:51.236971 31280 solver.cpp:253]     Train net output #0: loss = 1.61705 (* 1 = 1.61705 loss)
I0522 16:18:51.236985 31280 sgd_solver.cpp:106] Iteration 11250, lr = 0.0005
I0522 16:19:01.152387 31280 solver.cpp:237] Iteration 11625, loss = 1.60603
I0522 16:19:01.152554 31280 solver.cpp:253]     Train net output #0: loss = 1.60603 (* 1 = 1.60603 loss)
I0522 16:19:01.152567 31280 sgd_solver.cpp:106] Iteration 11625, lr = 0.0005
I0522 16:19:11.072948 31280 solver.cpp:237] Iteration 12000, loss = 1.73168
I0522 16:19:11.072984 31280 solver.cpp:253]     Train net output #0: loss = 1.73168 (* 1 = 1.73168 loss)
I0522 16:19:11.072999 31280 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0522 16:19:20.986506 31280 solver.cpp:237] Iteration 12375, loss = 1.66093
I0522 16:19:20.986548 31280 solver.cpp:253]     Train net output #0: loss = 1.66093 (* 1 = 1.66093 loss)
I0522 16:19:20.986569 31280 sgd_solver.cpp:106] Iteration 12375, lr = 0.0005
I0522 16:19:53.103251 31280 solver.cpp:237] Iteration 12750, loss = 1.7326
I0522 16:19:53.103415 31280 solver.cpp:253]     Train net output #0: loss = 1.7326 (* 1 = 1.7326 loss)
I0522 16:19:53.103430 31280 sgd_solver.cpp:106] Iteration 12750, lr = 0.0005
I0522 16:20:03.016095 31280 solver.cpp:237] Iteration 13125, loss = 1.64189
I0522 16:20:03.016130 31280 solver.cpp:253]     Train net output #0: loss = 1.64189 (* 1 = 1.64189 loss)
I0522 16:20:03.016147 31280 sgd_solver.cpp:106] Iteration 13125, lr = 0.0005
I0522 16:20:12.927309 31280 solver.cpp:237] Iteration 13500, loss = 1.60603
I0522 16:20:12.927358 31280 solver.cpp:253]     Train net output #0: loss = 1.60603 (* 1 = 1.60603 loss)
I0522 16:20:12.927373 31280 sgd_solver.cpp:106] Iteration 13500, lr = 0.0005
I0522 16:20:22.838129 31280 solver.cpp:237] Iteration 13875, loss = 1.55562
I0522 16:20:22.838166 31280 solver.cpp:253]     Train net output #0: loss = 1.55562 (* 1 = 1.55562 loss)
I0522 16:20:22.838182 31280 sgd_solver.cpp:106] Iteration 13875, lr = 0.0005
I0522 16:20:32.753428 31280 solver.cpp:237] Iteration 14250, loss = 1.45991
I0522 16:20:32.753588 31280 solver.cpp:253]     Train net output #0: loss = 1.45991 (* 1 = 1.45991 loss)
I0522 16:20:32.753602 31280 sgd_solver.cpp:106] Iteration 14250, lr = 0.0005
I0522 16:20:42.668644 31280 solver.cpp:237] Iteration 14625, loss = 1.45463
I0522 16:20:42.668680 31280 solver.cpp:253]     Train net output #0: loss = 1.45463 (* 1 = 1.45463 loss)
I0522 16:20:42.668696 31280 sgd_solver.cpp:106] Iteration 14625, lr = 0.0005
I0522 16:20:52.553136 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_15000.caffemodel
I0522 16:20:52.612210 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_15000.solverstate
I0522 16:20:52.641290 31280 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 16:22:02.076859 31280 solver.cpp:409]     Test net output #0: accuracy = 0.690707
I0522 16:22:02.077028 31280 solver.cpp:409]     Test net output #1: loss = 1.07943 (* 1 = 1.07943 loss)
I0522 16:22:24.306046 31280 solver.cpp:237] Iteration 15000, loss = 1.76258
I0522 16:22:24.306100 31280 solver.cpp:253]     Train net output #0: loss = 1.76258 (* 1 = 1.76258 loss)
I0522 16:22:24.306115 31280 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0522 16:22:34.134985 31280 solver.cpp:237] Iteration 15375, loss = 1.20121
I0522 16:22:34.135139 31280 solver.cpp:253]     Train net output #0: loss = 1.20121 (* 1 = 1.20121 loss)
I0522 16:22:34.135154 31280 sgd_solver.cpp:106] Iteration 15375, lr = 0.0005
I0522 16:22:43.961318 31280 solver.cpp:237] Iteration 15750, loss = 1.56878
I0522 16:22:43.961366 31280 solver.cpp:253]     Train net output #0: loss = 1.56878 (* 1 = 1.56878 loss)
I0522 16:22:43.961381 31280 sgd_solver.cpp:106] Iteration 15750, lr = 0.0005
I0522 16:22:53.781654 31280 solver.cpp:237] Iteration 16125, loss = 1.9395
I0522 16:22:53.781690 31280 solver.cpp:253]     Train net output #0: loss = 1.9395 (* 1 = 1.9395 loss)
I0522 16:22:53.781707 31280 sgd_solver.cpp:106] Iteration 16125, lr = 0.0005
I0522 16:23:03.602965 31280 solver.cpp:237] Iteration 16500, loss = 1.72482
I0522 16:23:03.603008 31280 solver.cpp:253]     Train net output #0: loss = 1.72482 (* 1 = 1.72482 loss)
I0522 16:23:03.603029 31280 sgd_solver.cpp:106] Iteration 16500, lr = 0.0005
I0522 16:23:13.413795 31280 solver.cpp:237] Iteration 16875, loss = 1.609
I0522 16:23:13.413939 31280 solver.cpp:253]     Train net output #0: loss = 1.609 (* 1 = 1.609 loss)
I0522 16:23:13.413952 31280 sgd_solver.cpp:106] Iteration 16875, lr = 0.0005
I0522 16:23:23.232401 31280 solver.cpp:237] Iteration 17250, loss = 1.83514
I0522 16:23:23.232436 31280 solver.cpp:253]     Train net output #0: loss = 1.83514 (* 1 = 1.83514 loss)
I0522 16:23:23.232453 31280 sgd_solver.cpp:106] Iteration 17250, lr = 0.0005
I0522 16:23:55.291213 31280 solver.cpp:237] Iteration 17625, loss = 1.58487
I0522 16:23:55.291380 31280 solver.cpp:253]     Train net output #0: loss = 1.58487 (* 1 = 1.58487 loss)
I0522 16:23:55.291396 31280 sgd_solver.cpp:106] Iteration 17625, lr = 0.0005
I0522 16:24:05.110075 31280 solver.cpp:237] Iteration 18000, loss = 1.92402
I0522 16:24:05.110110 31280 solver.cpp:253]     Train net output #0: loss = 1.92402 (* 1 = 1.92402 loss)
I0522 16:24:05.110127 31280 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0522 16:24:14.926034 31280 solver.cpp:237] Iteration 18375, loss = 1.56097
I0522 16:24:14.926069 31280 solver.cpp:253]     Train net output #0: loss = 1.56097 (* 1 = 1.56097 loss)
I0522 16:24:14.926086 31280 sgd_solver.cpp:106] Iteration 18375, lr = 0.0005
I0522 16:24:24.723945 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_18750.caffemodel
I0522 16:24:24.782650 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_18750.solverstate
I0522 16:24:24.819699 31280 solver.cpp:237] Iteration 18750, loss = 1.47061
I0522 16:24:24.819749 31280 solver.cpp:253]     Train net output #0: loss = 1.47061 (* 1 = 1.47061 loss)
I0522 16:24:24.819763 31280 sgd_solver.cpp:106] Iteration 18750, lr = 0.0005
I0522 16:24:34.637845 31280 solver.cpp:237] Iteration 19125, loss = 1.61408
I0522 16:24:34.637992 31280 solver.cpp:253]     Train net output #0: loss = 1.61408 (* 1 = 1.61408 loss)
I0522 16:24:34.638005 31280 sgd_solver.cpp:106] Iteration 19125, lr = 0.0005
I0522 16:24:44.461918 31280 solver.cpp:237] Iteration 19500, loss = 1.5833
I0522 16:24:44.461964 31280 solver.cpp:253]     Train net output #0: loss = 1.5833 (* 1 = 1.5833 loss)
I0522 16:24:44.461982 31280 sgd_solver.cpp:106] Iteration 19500, lr = 0.0005
I0522 16:24:54.278332 31280 solver.cpp:237] Iteration 19875, loss = 1.67501
I0522 16:24:54.278368 31280 solver.cpp:253]     Train net output #0: loss = 1.67501 (* 1 = 1.67501 loss)
I0522 16:24:54.278380 31280 sgd_solver.cpp:106] Iteration 19875, lr = 0.0005
I0522 16:25:26.250543 31280 solver.cpp:237] Iteration 20250, loss = 1.36696
I0522 16:25:26.250720 31280 solver.cpp:253]     Train net output #0: loss = 1.36696 (* 1 = 1.36696 loss)
I0522 16:25:26.250735 31280 sgd_solver.cpp:106] Iteration 20250, lr = 0.0005
I0522 16:25:36.068692 31280 solver.cpp:237] Iteration 20625, loss = 1.45128
I0522 16:25:36.068735 31280 solver.cpp:253]     Train net output #0: loss = 1.45128 (* 1 = 1.45128 loss)
I0522 16:25:36.068755 31280 sgd_solver.cpp:106] Iteration 20625, lr = 0.0005
I0522 16:25:45.886298 31280 solver.cpp:237] Iteration 21000, loss = 1.59386
I0522 16:25:45.886333 31280 solver.cpp:253]     Train net output #0: loss = 1.59386 (* 1 = 1.59386 loss)
I0522 16:25:45.886350 31280 sgd_solver.cpp:106] Iteration 21000, lr = 0.0005
I0522 16:25:55.700445 31280 solver.cpp:237] Iteration 21375, loss = 1.43381
I0522 16:25:55.700481 31280 solver.cpp:253]     Train net output #0: loss = 1.43381 (* 1 = 1.43381 loss)
I0522 16:25:55.700497 31280 sgd_solver.cpp:106] Iteration 21375, lr = 0.0005
I0522 16:26:05.503782 31280 solver.cpp:237] Iteration 21750, loss = 1.49122
I0522 16:26:05.503950 31280 solver.cpp:253]     Train net output #0: loss = 1.49122 (* 1 = 1.49122 loss)
I0522 16:26:05.503965 31280 sgd_solver.cpp:106] Iteration 21750, lr = 0.0005
I0522 16:26:15.309175 31280 solver.cpp:237] Iteration 22125, loss = 1.25517
I0522 16:26:15.309211 31280 solver.cpp:253]     Train net output #0: loss = 1.25517 (* 1 = 1.25517 loss)
I0522 16:26:15.309227 31280 sgd_solver.cpp:106] Iteration 22125, lr = 0.0005
I0522 16:26:25.092715 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_22500.caffemodel
I0522 16:26:25.148612 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_22500.solverstate
I0522 16:26:25.174973 31280 solver.cpp:341] Iteration 22500, Testing net (#0)
I0522 16:27:13.403280 31280 solver.cpp:409]     Test net output #0: accuracy = 0.763046
I0522 16:27:13.403439 31280 solver.cpp:409]     Test net output #1: loss = 0.843363 (* 1 = 0.843363 loss)
I0522 16:27:35.603513 31280 solver.cpp:237] Iteration 22500, loss = 1.25482
I0522 16:27:35.603564 31280 solver.cpp:253]     Train net output #0: loss = 1.25482 (* 1 = 1.25482 loss)
I0522 16:27:35.603579 31280 sgd_solver.cpp:106] Iteration 22500, lr = 0.0005
I0522 16:27:45.300551 31280 solver.cpp:237] Iteration 22875, loss = 1.34666
I0522 16:27:45.300707 31280 solver.cpp:253]     Train net output #0: loss = 1.34666 (* 1 = 1.34666 loss)
I0522 16:27:45.300721 31280 sgd_solver.cpp:106] Iteration 22875, lr = 0.0005
I0522 16:27:54.996469 31280 solver.cpp:237] Iteration 23250, loss = 1.61925
I0522 16:27:54.996503 31280 solver.cpp:253]     Train net output #0: loss = 1.61925 (* 1 = 1.61925 loss)
I0522 16:27:54.996520 31280 sgd_solver.cpp:106] Iteration 23250, lr = 0.0005
I0522 16:28:04.689638 31280 solver.cpp:237] Iteration 23625, loss = 1.52655
I0522 16:28:04.689685 31280 solver.cpp:253]     Train net output #0: loss = 1.52655 (* 1 = 1.52655 loss)
I0522 16:28:04.689699 31280 sgd_solver.cpp:106] Iteration 23625, lr = 0.0005
I0522 16:28:14.386590 31280 solver.cpp:237] Iteration 24000, loss = 2.04912
I0522 16:28:14.386626 31280 solver.cpp:253]     Train net output #0: loss = 2.04912 (* 1 = 2.04912 loss)
I0522 16:28:14.386642 31280 sgd_solver.cpp:106] Iteration 24000, lr = 0.0005
I0522 16:28:24.081475 31280 solver.cpp:237] Iteration 24375, loss = 1.61523
I0522 16:28:24.081631 31280 solver.cpp:253]     Train net output #0: loss = 1.61523 (* 1 = 1.61523 loss)
I0522 16:28:24.081645 31280 sgd_solver.cpp:106] Iteration 24375, lr = 0.0005
I0522 16:28:33.775051 31280 solver.cpp:237] Iteration 24750, loss = 1.4468
I0522 16:28:33.775096 31280 solver.cpp:253]     Train net output #0: loss = 1.4468 (* 1 = 1.4468 loss)
I0522 16:28:33.775115 31280 sgd_solver.cpp:106] Iteration 24750, lr = 0.0005
I0522 16:29:05.686715 31280 solver.cpp:237] Iteration 25125, loss = 1.38629
I0522 16:29:05.686887 31280 solver.cpp:253]     Train net output #0: loss = 1.38629 (* 1 = 1.38629 loss)
I0522 16:29:05.686902 31280 sgd_solver.cpp:106] Iteration 25125, lr = 0.0005
I0522 16:29:15.383993 31280 solver.cpp:237] Iteration 25500, loss = 1.4142
I0522 16:29:15.384028 31280 solver.cpp:253]     Train net output #0: loss = 1.4142 (* 1 = 1.4142 loss)
I0522 16:29:15.384047 31280 sgd_solver.cpp:106] Iteration 25500, lr = 0.0005
I0522 16:29:25.075019 31280 solver.cpp:237] Iteration 25875, loss = 1.3045
I0522 16:29:25.075067 31280 solver.cpp:253]     Train net output #0: loss = 1.3045 (* 1 = 1.3045 loss)
I0522 16:29:25.075083 31280 sgd_solver.cpp:106] Iteration 25875, lr = 0.0005
I0522 16:29:34.746824 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_26250.caffemodel
I0522 16:29:34.803313 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_26250.solverstate
I0522 16:29:34.838291 31280 solver.cpp:237] Iteration 26250, loss = 1.51478
I0522 16:29:34.838336 31280 solver.cpp:253]     Train net output #0: loss = 1.51478 (* 1 = 1.51478 loss)
I0522 16:29:34.838351 31280 sgd_solver.cpp:106] Iteration 26250, lr = 0.0005
I0522 16:29:44.529392 31280 solver.cpp:237] Iteration 26625, loss = 1.64052
I0522 16:29:44.529572 31280 solver.cpp:253]     Train net output #0: loss = 1.64052 (* 1 = 1.64052 loss)
I0522 16:29:44.529585 31280 sgd_solver.cpp:106] Iteration 26625, lr = 0.0005
I0522 16:29:54.230834 31280 solver.cpp:237] Iteration 27000, loss = 1.56393
I0522 16:29:54.230870 31280 solver.cpp:253]     Train net output #0: loss = 1.56393 (* 1 = 1.56393 loss)
I0522 16:29:54.230886 31280 sgd_solver.cpp:106] Iteration 27000, lr = 0.0005
I0522 16:30:03.926431 31280 solver.cpp:237] Iteration 27375, loss = 1.62142
I0522 16:30:03.926466 31280 solver.cpp:253]     Train net output #0: loss = 1.62142 (* 1 = 1.62142 loss)
I0522 16:30:03.926483 31280 sgd_solver.cpp:106] Iteration 27375, lr = 0.0005
I0522 16:30:35.829071 31280 solver.cpp:237] Iteration 27750, loss = 1.50891
I0522 16:30:35.829241 31280 solver.cpp:253]     Train net output #0: loss = 1.50891 (* 1 = 1.50891 loss)
I0522 16:30:35.829257 31280 sgd_solver.cpp:106] Iteration 27750, lr = 0.0005
I0522 16:30:45.525799 31280 solver.cpp:237] Iteration 28125, loss = 1.45985
I0522 16:30:45.525835 31280 solver.cpp:253]     Train net output #0: loss = 1.45985 (* 1 = 1.45985 loss)
I0522 16:30:45.525851 31280 sgd_solver.cpp:106] Iteration 28125, lr = 0.0005
I0522 16:30:55.232435 31280 solver.cpp:237] Iteration 28500, loss = 1.36405
I0522 16:30:55.232470 31280 solver.cpp:253]     Train net output #0: loss = 1.36405 (* 1 = 1.36405 loss)
I0522 16:30:55.232487 31280 sgd_solver.cpp:106] Iteration 28500, lr = 0.0005
I0522 16:31:04.935888 31280 solver.cpp:237] Iteration 28875, loss = 1.38129
I0522 16:31:04.935937 31280 solver.cpp:253]     Train net output #0: loss = 1.38129 (* 1 = 1.38129 loss)
I0522 16:31:04.935950 31280 sgd_solver.cpp:106] Iteration 28875, lr = 0.0005
I0522 16:31:14.636497 31280 solver.cpp:237] Iteration 29250, loss = 1.41577
I0522 16:31:14.636642 31280 solver.cpp:253]     Train net output #0: loss = 1.41577 (* 1 = 1.41577 loss)
I0522 16:31:14.636656 31280 sgd_solver.cpp:106] Iteration 29250, lr = 0.0005
I0522 16:31:24.341470 31280 solver.cpp:237] Iteration 29625, loss = 1.34965
I0522 16:31:24.341528 31280 solver.cpp:253]     Train net output #0: loss = 1.34965 (* 1 = 1.34965 loss)
I0522 16:31:24.341543 31280 sgd_solver.cpp:106] Iteration 29625, lr = 0.0005
I0522 16:31:34.012100 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_30000.caffemodel
I0522 16:31:34.068001 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_30000.solverstate
I0522 16:31:34.094331 31280 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 16:32:43.512725 31280 solver.cpp:409]     Test net output #0: accuracy = 0.797868
I0522 16:32:43.512894 31280 solver.cpp:409]     Test net output #1: loss = 0.722357 (* 1 = 0.722357 loss)
I0522 16:33:05.718575 31280 solver.cpp:237] Iteration 30000, loss = 1.67748
I0522 16:33:05.718627 31280 solver.cpp:253]     Train net output #0: loss = 1.67748 (* 1 = 1.67748 loss)
I0522 16:33:05.718646 31280 sgd_solver.cpp:106] Iteration 30000, lr = 0.0005
I0522 16:33:15.479909 31280 solver.cpp:237] Iteration 30375, loss = 1.94746
I0522 16:33:15.480057 31280 solver.cpp:253]     Train net output #0: loss = 1.94746 (* 1 = 1.94746 loss)
I0522 16:33:15.480072 31280 sgd_solver.cpp:106] Iteration 30375, lr = 0.0005
I0522 16:33:25.240645 31280 solver.cpp:237] Iteration 30750, loss = 1.62223
I0522 16:33:25.240680 31280 solver.cpp:253]     Train net output #0: loss = 1.62223 (* 1 = 1.62223 loss)
I0522 16:33:25.240697 31280 sgd_solver.cpp:106] Iteration 30750, lr = 0.0005
I0522 16:33:34.996896 31280 solver.cpp:237] Iteration 31125, loss = 1.27609
I0522 16:33:34.996942 31280 solver.cpp:253]     Train net output #0: loss = 1.27609 (* 1 = 1.27609 loss)
I0522 16:33:34.996956 31280 sgd_solver.cpp:106] Iteration 31125, lr = 0.0005
I0522 16:33:44.756610 31280 solver.cpp:237] Iteration 31500, loss = 1.21067
I0522 16:33:44.756646 31280 solver.cpp:253]     Train net output #0: loss = 1.21067 (* 1 = 1.21067 loss)
I0522 16:33:44.756660 31280 sgd_solver.cpp:106] Iteration 31500, lr = 0.0005
I0522 16:33:54.505385 31280 solver.cpp:237] Iteration 31875, loss = 1.34499
I0522 16:33:54.505549 31280 solver.cpp:253]     Train net output #0: loss = 1.34499 (* 1 = 1.34499 loss)
I0522 16:33:54.505563 31280 sgd_solver.cpp:106] Iteration 31875, lr = 0.0005
I0522 16:34:04.263916 31280 solver.cpp:237] Iteration 32250, loss = 1.14774
I0522 16:34:04.263950 31280 solver.cpp:253]     Train net output #0: loss = 1.14774 (* 1 = 1.14774 loss)
I0522 16:34:04.263968 31280 sgd_solver.cpp:106] Iteration 32250, lr = 0.0005
I0522 16:34:36.187896 31280 solver.cpp:237] Iteration 32625, loss = 1.31219
I0522 16:34:36.188061 31280 solver.cpp:253]     Train net output #0: loss = 1.31219 (* 1 = 1.31219 loss)
I0522 16:34:36.188076 31280 sgd_solver.cpp:106] Iteration 32625, lr = 0.0005
I0522 16:34:45.947219 31280 solver.cpp:237] Iteration 33000, loss = 1.54302
I0522 16:34:45.947269 31280 solver.cpp:253]     Train net output #0: loss = 1.54302 (* 1 = 1.54302 loss)
I0522 16:34:45.947284 31280 sgd_solver.cpp:106] Iteration 33000, lr = 0.0005
I0522 16:34:55.707083 31280 solver.cpp:237] Iteration 33375, loss = 1.34657
I0522 16:34:55.707119 31280 solver.cpp:253]     Train net output #0: loss = 1.34657 (* 1 = 1.34657 loss)
I0522 16:34:55.707137 31280 sgd_solver.cpp:106] Iteration 33375, lr = 0.0005
I0522 16:35:05.440615 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_33750.caffemodel
I0522 16:35:05.500053 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_33750.solverstate
I0522 16:35:05.537375 31280 solver.cpp:237] Iteration 33750, loss = 1.23889
I0522 16:35:05.537425 31280 solver.cpp:253]     Train net output #0: loss = 1.23889 (* 1 = 1.23889 loss)
I0522 16:35:05.537441 31280 sgd_solver.cpp:106] Iteration 33750, lr = 0.0005
I0522 16:35:15.295222 31280 solver.cpp:237] Iteration 34125, loss = 1.27545
I0522 16:35:15.295390 31280 solver.cpp:253]     Train net output #0: loss = 1.27545 (* 1 = 1.27545 loss)
I0522 16:35:15.295405 31280 sgd_solver.cpp:106] Iteration 34125, lr = 0.0005
I0522 16:35:25.049626 31280 solver.cpp:237] Iteration 34500, loss = 1.81491
I0522 16:35:25.049660 31280 solver.cpp:253]     Train net output #0: loss = 1.81491 (* 1 = 1.81491 loss)
I0522 16:35:25.049679 31280 sgd_solver.cpp:106] Iteration 34500, lr = 0.0005
I0522 16:35:34.809092 31280 solver.cpp:237] Iteration 34875, loss = 1.25693
I0522 16:35:34.809137 31280 solver.cpp:253]     Train net output #0: loss = 1.25693 (* 1 = 1.25693 loss)
I0522 16:35:34.809157 31280 sgd_solver.cpp:106] Iteration 34875, lr = 0.0005
I0522 16:36:06.764583 31280 solver.cpp:237] Iteration 35250, loss = 1.38156
I0522 16:36:06.764762 31280 solver.cpp:253]     Train net output #0: loss = 1.38156 (* 1 = 1.38156 loss)
I0522 16:36:06.764780 31280 sgd_solver.cpp:106] Iteration 35250, lr = 0.0005
I0522 16:36:16.524744 31280 solver.cpp:237] Iteration 35625, loss = 1.56023
I0522 16:36:16.524780 31280 solver.cpp:253]     Train net output #0: loss = 1.56023 (* 1 = 1.56023 loss)
I0522 16:36:16.524796 31280 sgd_solver.cpp:106] Iteration 35625, lr = 0.0005
I0522 16:36:26.282253 31280 solver.cpp:237] Iteration 36000, loss = 1.56599
I0522 16:36:26.282300 31280 solver.cpp:253]     Train net output #0: loss = 1.56599 (* 1 = 1.56599 loss)
I0522 16:36:26.282316 31280 sgd_solver.cpp:106] Iteration 36000, lr = 0.0005
I0522 16:36:36.037247 31280 solver.cpp:237] Iteration 36375, loss = 1.64165
I0522 16:36:36.037283 31280 solver.cpp:253]     Train net output #0: loss = 1.64165 (* 1 = 1.64165 loss)
I0522 16:36:36.037300 31280 sgd_solver.cpp:106] Iteration 36375, lr = 0.0005
I0522 16:36:45.797359 31280 solver.cpp:237] Iteration 36750, loss = 1.23798
I0522 16:36:45.797508 31280 solver.cpp:253]     Train net output #0: loss = 1.23798 (* 1 = 1.23798 loss)
I0522 16:36:45.797526 31280 sgd_solver.cpp:106] Iteration 36750, lr = 0.0005
I0522 16:36:55.554543 31280 solver.cpp:237] Iteration 37125, loss = 1.51946
I0522 16:36:55.554585 31280 solver.cpp:253]     Train net output #0: loss = 1.51946 (* 1 = 1.51946 loss)
I0522 16:36:55.554602 31280 sgd_solver.cpp:106] Iteration 37125, lr = 0.0005
I0522 16:37:05.288575 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_37500.caffemodel
I0522 16:37:05.347801 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_37500.solverstate
I0522 16:37:05.376406 31280 solver.cpp:341] Iteration 37500, Testing net (#0)
I0522 16:37:53.888031 31280 solver.cpp:409]     Test net output #0: accuracy = 0.817894
I0522 16:37:53.888195 31280 solver.cpp:409]     Test net output #1: loss = 0.651787 (* 1 = 0.651787 loss)
I0522 16:38:14.802706 31280 solver.cpp:237] Iteration 37500, loss = 1.33325
I0522 16:38:14.802758 31280 solver.cpp:253]     Train net output #0: loss = 1.33325 (* 1 = 1.33325 loss)
I0522 16:38:14.802773 31280 sgd_solver.cpp:106] Iteration 37500, lr = 0.0005
I0522 16:38:24.755687 31280 solver.cpp:237] Iteration 37875, loss = 1.52706
I0522 16:38:24.755841 31280 solver.cpp:253]     Train net output #0: loss = 1.52706 (* 1 = 1.52706 loss)
I0522 16:38:24.755856 31280 sgd_solver.cpp:106] Iteration 37875, lr = 0.0005
I0522 16:38:34.696813 31280 solver.cpp:237] Iteration 38250, loss = 1.58064
I0522 16:38:34.696854 31280 solver.cpp:253]     Train net output #0: loss = 1.58064 (* 1 = 1.58064 loss)
I0522 16:38:34.696874 31280 sgd_solver.cpp:106] Iteration 38250, lr = 0.0005
I0522 16:38:44.635562 31280 solver.cpp:237] Iteration 38625, loss = 1.00738
I0522 16:38:44.635597 31280 solver.cpp:253]     Train net output #0: loss = 1.00738 (* 1 = 1.00738 loss)
I0522 16:38:44.635614 31280 sgd_solver.cpp:106] Iteration 38625, lr = 0.0005
I0522 16:38:54.577502 31280 solver.cpp:237] Iteration 39000, loss = 1.2957
I0522 16:38:54.577558 31280 solver.cpp:253]     Train net output #0: loss = 1.2957 (* 1 = 1.2957 loss)
I0522 16:38:54.577570 31280 sgd_solver.cpp:106] Iteration 39000, lr = 0.0005
I0522 16:39:04.519944 31280 solver.cpp:237] Iteration 39375, loss = 1.1809
I0522 16:39:04.520090 31280 solver.cpp:253]     Train net output #0: loss = 1.1809 (* 1 = 1.1809 loss)
I0522 16:39:04.520104 31280 sgd_solver.cpp:106] Iteration 39375, lr = 0.0005
I0522 16:39:14.469853 31280 solver.cpp:237] Iteration 39750, loss = 1.3519
I0522 16:39:14.469888 31280 solver.cpp:253]     Train net output #0: loss = 1.3519 (* 1 = 1.3519 loss)
I0522 16:39:14.469904 31280 sgd_solver.cpp:106] Iteration 39750, lr = 0.0005
I0522 16:39:45.314725 31280 solver.cpp:237] Iteration 40125, loss = 1.36257
I0522 16:39:45.314898 31280 solver.cpp:253]     Train net output #0: loss = 1.36257 (* 1 = 1.36257 loss)
I0522 16:39:45.314913 31280 sgd_solver.cpp:106] Iteration 40125, lr = 0.0005
I0522 16:39:55.250686 31280 solver.cpp:237] Iteration 40500, loss = 1.08407
I0522 16:39:55.250721 31280 solver.cpp:253]     Train net output #0: loss = 1.08407 (* 1 = 1.08407 loss)
I0522 16:39:55.250735 31280 sgd_solver.cpp:106] Iteration 40500, lr = 0.0005
I0522 16:40:05.183372 31280 solver.cpp:237] Iteration 40875, loss = 1.51163
I0522 16:40:05.183406 31280 solver.cpp:253]     Train net output #0: loss = 1.51163 (* 1 = 1.51163 loss)
I0522 16:40:05.183423 31280 sgd_solver.cpp:106] Iteration 40875, lr = 0.0005
I0522 16:40:15.102527 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_41250.caffemodel
I0522 16:40:15.159016 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_41250.solverstate
I0522 16:40:15.193675 31280 solver.cpp:237] Iteration 41250, loss = 1.17293
I0522 16:40:15.193720 31280 solver.cpp:253]     Train net output #0: loss = 1.17293 (* 1 = 1.17293 loss)
I0522 16:40:15.193738 31280 sgd_solver.cpp:106] Iteration 41250, lr = 0.0005
I0522 16:40:25.133836 31280 solver.cpp:237] Iteration 41625, loss = 1.45581
I0522 16:40:25.133973 31280 solver.cpp:253]     Train net output #0: loss = 1.45581 (* 1 = 1.45581 loss)
I0522 16:40:25.133988 31280 sgd_solver.cpp:106] Iteration 41625, lr = 0.0005
I0522 16:40:35.074455 31280 solver.cpp:237] Iteration 42000, loss = 1.29272
I0522 16:40:35.074502 31280 solver.cpp:253]     Train net output #0: loss = 1.29272 (* 1 = 1.29272 loss)
I0522 16:40:35.074518 31280 sgd_solver.cpp:106] Iteration 42000, lr = 0.0005
I0522 16:40:45.006867 31280 solver.cpp:237] Iteration 42375, loss = 1.10696
I0522 16:40:45.006903 31280 solver.cpp:253]     Train net output #0: loss = 1.10696 (* 1 = 1.10696 loss)
I0522 16:40:45.006916 31280 sgd_solver.cpp:106] Iteration 42375, lr = 0.0005
I0522 16:41:15.876912 31280 solver.cpp:237] Iteration 42750, loss = 1.26891
I0522 16:41:15.877084 31280 solver.cpp:253]     Train net output #0: loss = 1.26891 (* 1 = 1.26891 loss)
I0522 16:41:15.877099 31280 sgd_solver.cpp:106] Iteration 42750, lr = 0.0005
I0522 16:41:25.817481 31280 solver.cpp:237] Iteration 43125, loss = 1.31505
I0522 16:41:25.817533 31280 solver.cpp:253]     Train net output #0: loss = 1.31505 (* 1 = 1.31505 loss)
I0522 16:41:25.817546 31280 sgd_solver.cpp:106] Iteration 43125, lr = 0.0005
I0522 16:41:35.760181 31280 solver.cpp:237] Iteration 43500, loss = 1.60616
I0522 16:41:35.760217 31280 solver.cpp:253]     Train net output #0: loss = 1.60616 (* 1 = 1.60616 loss)
I0522 16:41:35.760233 31280 sgd_solver.cpp:106] Iteration 43500, lr = 0.0005
I0522 16:41:45.699517 31280 solver.cpp:237] Iteration 43875, loss = 1.44015
I0522 16:41:45.699553 31280 solver.cpp:253]     Train net output #0: loss = 1.44015 (* 1 = 1.44015 loss)
I0522 16:41:45.699568 31280 sgd_solver.cpp:106] Iteration 43875, lr = 0.0005
I0522 16:41:55.636795 31280 solver.cpp:237] Iteration 44250, loss = 1.38731
I0522 16:41:55.636967 31280 solver.cpp:253]     Train net output #0: loss = 1.38731 (* 1 = 1.38731 loss)
I0522 16:41:55.636982 31280 sgd_solver.cpp:106] Iteration 44250, lr = 0.0005
I0522 16:42:05.580493 31280 solver.cpp:237] Iteration 44625, loss = 1.3824
I0522 16:42:05.580528 31280 solver.cpp:253]     Train net output #0: loss = 1.3824 (* 1 = 1.3824 loss)
I0522 16:42:05.580545 31280 sgd_solver.cpp:106] Iteration 44625, lr = 0.0005
I0522 16:42:15.484889 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_45000.caffemodel
I0522 16:42:15.542291 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_45000.solverstate
I0522 16:42:15.568861 31280 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 16:43:24.970645 31280 solver.cpp:409]     Test net output #0: accuracy = 0.825187
I0522 16:43:24.970819 31280 solver.cpp:409]     Test net output #1: loss = 0.579244 (* 1 = 0.579244 loss)
I0522 16:43:45.883424 31280 solver.cpp:237] Iteration 45000, loss = 1.36021
I0522 16:43:45.883476 31280 solver.cpp:253]     Train net output #0: loss = 1.36021 (* 1 = 1.36021 loss)
I0522 16:43:45.883491 31280 sgd_solver.cpp:106] Iteration 45000, lr = 0.0005
I0522 16:43:55.696892 31280 solver.cpp:237] Iteration 45375, loss = 1.05326
I0522 16:43:55.697058 31280 solver.cpp:253]     Train net output #0: loss = 1.05326 (* 1 = 1.05326 loss)
I0522 16:43:55.697072 31280 sgd_solver.cpp:106] Iteration 45375, lr = 0.0005
I0522 16:44:05.507678 31280 solver.cpp:237] Iteration 45750, loss = 1.3378
I0522 16:44:05.507712 31280 solver.cpp:253]     Train net output #0: loss = 1.3378 (* 1 = 1.3378 loss)
I0522 16:44:05.507726 31280 sgd_solver.cpp:106] Iteration 45750, lr = 0.0005
I0522 16:44:15.319054 31280 solver.cpp:237] Iteration 46125, loss = 1.52606
I0522 16:44:15.319090 31280 solver.cpp:253]     Train net output #0: loss = 1.52606 (* 1 = 1.52606 loss)
I0522 16:44:15.319103 31280 sgd_solver.cpp:106] Iteration 46125, lr = 0.0005
I0522 16:44:25.124459 31280 solver.cpp:237] Iteration 46500, loss = 1.23684
I0522 16:44:25.124502 31280 solver.cpp:253]     Train net output #0: loss = 1.23684 (* 1 = 1.23684 loss)
I0522 16:44:25.124519 31280 sgd_solver.cpp:106] Iteration 46500, lr = 0.0005
I0522 16:44:34.941565 31280 solver.cpp:237] Iteration 46875, loss = 1.58661
I0522 16:44:34.941715 31280 solver.cpp:253]     Train net output #0: loss = 1.58661 (* 1 = 1.58661 loss)
I0522 16:44:34.941728 31280 sgd_solver.cpp:106] Iteration 46875, lr = 0.0005
I0522 16:44:44.746672 31280 solver.cpp:237] Iteration 47250, loss = 1.31282
I0522 16:44:44.746719 31280 solver.cpp:253]     Train net output #0: loss = 1.31282 (* 1 = 1.31282 loss)
I0522 16:44:44.746737 31280 sgd_solver.cpp:106] Iteration 47250, lr = 0.0005
I0522 16:45:15.480937 31280 solver.cpp:237] Iteration 47625, loss = 1.38177
I0522 16:45:15.481112 31280 solver.cpp:253]     Train net output #0: loss = 1.38177 (* 1 = 1.38177 loss)
I0522 16:45:15.481127 31280 sgd_solver.cpp:106] Iteration 47625, lr = 0.0005
I0522 16:45:25.288956 31280 solver.cpp:237] Iteration 48000, loss = 0.8891
I0522 16:45:25.288991 31280 solver.cpp:253]     Train net output #0: loss = 0.8891 (* 1 = 0.8891 loss)
I0522 16:45:25.289010 31280 sgd_solver.cpp:106] Iteration 48000, lr = 0.0005
I0522 16:45:35.092895 31280 solver.cpp:237] Iteration 48375, loss = 1.54269
I0522 16:45:35.092943 31280 solver.cpp:253]     Train net output #0: loss = 1.54269 (* 1 = 1.54269 loss)
I0522 16:45:35.092959 31280 sgd_solver.cpp:106] Iteration 48375, lr = 0.0005
I0522 16:45:44.873607 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_48750.caffemodel
I0522 16:45:44.929672 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_48750.solverstate
I0522 16:45:44.964428 31280 solver.cpp:237] Iteration 48750, loss = 1.19665
I0522 16:45:44.964473 31280 solver.cpp:253]     Train net output #0: loss = 1.19665 (* 1 = 1.19665 loss)
I0522 16:45:44.964488 31280 sgd_solver.cpp:106] Iteration 48750, lr = 0.0005
I0522 16:45:54.773716 31280 solver.cpp:237] Iteration 49125, loss = 1.33381
I0522 16:45:54.773876 31280 solver.cpp:253]     Train net output #0: loss = 1.33381 (* 1 = 1.33381 loss)
I0522 16:45:54.773890 31280 sgd_solver.cpp:106] Iteration 49125, lr = 0.0005
I0522 16:46:04.578510 31280 solver.cpp:237] Iteration 49500, loss = 1.31815
I0522 16:46:04.578557 31280 solver.cpp:253]     Train net output #0: loss = 1.31815 (* 1 = 1.31815 loss)
I0522 16:46:04.578573 31280 sgd_solver.cpp:106] Iteration 49500, lr = 0.0005
I0522 16:46:14.384974 31280 solver.cpp:237] Iteration 49875, loss = 1.65349
I0522 16:46:14.385010 31280 solver.cpp:253]     Train net output #0: loss = 1.65349 (* 1 = 1.65349 loss)
I0522 16:46:14.385025 31280 sgd_solver.cpp:106] Iteration 49875, lr = 0.0005
I0522 16:46:45.054282 31280 solver.cpp:237] Iteration 50250, loss = 1.30826
I0522 16:46:45.054451 31280 solver.cpp:253]     Train net output #0: loss = 1.30826 (* 1 = 1.30826 loss)
I0522 16:46:45.054466 31280 sgd_solver.cpp:106] Iteration 50250, lr = 0.0005
I0522 16:46:54.856192 31280 solver.cpp:237] Iteration 50625, loss = 1.33751
I0522 16:46:54.856240 31280 solver.cpp:253]     Train net output #0: loss = 1.33751 (* 1 = 1.33751 loss)
I0522 16:46:54.856256 31280 sgd_solver.cpp:106] Iteration 50625, lr = 0.0005
I0522 16:47:04.655587 31280 solver.cpp:237] Iteration 51000, loss = 1.49336
I0522 16:47:04.655623 31280 solver.cpp:253]     Train net output #0: loss = 1.49336 (* 1 = 1.49336 loss)
I0522 16:47:04.655639 31280 sgd_solver.cpp:106] Iteration 51000, lr = 0.0005
I0522 16:47:14.476521 31280 solver.cpp:237] Iteration 51375, loss = 1.46218
I0522 16:47:14.476559 31280 solver.cpp:253]     Train net output #0: loss = 1.46218 (* 1 = 1.46218 loss)
I0522 16:47:14.476579 31280 sgd_solver.cpp:106] Iteration 51375, lr = 0.0005
I0522 16:47:24.349839 31280 solver.cpp:237] Iteration 51750, loss = 1.23902
I0522 16:47:24.349988 31280 solver.cpp:253]     Train net output #0: loss = 1.23902 (* 1 = 1.23902 loss)
I0522 16:47:24.350003 31280 sgd_solver.cpp:106] Iteration 51750, lr = 0.0005
I0522 16:47:34.221941 31280 solver.cpp:237] Iteration 52125, loss = 1.28431
I0522 16:47:34.221976 31280 solver.cpp:253]     Train net output #0: loss = 1.28431 (* 1 = 1.28431 loss)
I0522 16:47:34.221990 31280 sgd_solver.cpp:106] Iteration 52125, lr = 0.0005
I0522 16:47:44.043380 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_52500.caffemodel
I0522 16:47:44.100225 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_52500.solverstate
I0522 16:47:44.126916 31280 solver.cpp:341] Iteration 52500, Testing net (#0)
I0522 16:48:32.280551 31280 solver.cpp:409]     Test net output #0: accuracy = 0.836441
I0522 16:48:32.280726 31280 solver.cpp:409]     Test net output #1: loss = 0.570018 (* 1 = 0.570018 loss)
I0522 16:48:53.153019 31280 solver.cpp:237] Iteration 52500, loss = 1.35646
I0522 16:48:53.153074 31280 solver.cpp:253]     Train net output #0: loss = 1.35646 (* 1 = 1.35646 loss)
I0522 16:48:53.153089 31280 sgd_solver.cpp:106] Iteration 52500, lr = 0.0005
I0522 16:49:02.904716 31280 solver.cpp:237] Iteration 52875, loss = 0.944138
I0522 16:49:02.904882 31280 solver.cpp:253]     Train net output #0: loss = 0.944138 (* 1 = 0.944138 loss)
I0522 16:49:02.904896 31280 sgd_solver.cpp:106] Iteration 52875, lr = 0.0005
I0522 16:49:12.658069 31280 solver.cpp:237] Iteration 53250, loss = 1.63653
I0522 16:49:12.658104 31280 solver.cpp:253]     Train net output #0: loss = 1.63653 (* 1 = 1.63653 loss)
I0522 16:49:12.658123 31280 sgd_solver.cpp:106] Iteration 53250, lr = 0.0005
I0522 16:49:22.414481 31280 solver.cpp:237] Iteration 53625, loss = 1.32473
I0522 16:49:22.414525 31280 solver.cpp:253]     Train net output #0: loss = 1.32473 (* 1 = 1.32473 loss)
I0522 16:49:22.414543 31280 sgd_solver.cpp:106] Iteration 53625, lr = 0.0005
I0522 16:49:32.163372 31280 solver.cpp:237] Iteration 54000, loss = 1.488
I0522 16:49:32.163408 31280 solver.cpp:253]     Train net output #0: loss = 1.488 (* 1 = 1.488 loss)
I0522 16:49:32.163424 31280 sgd_solver.cpp:106] Iteration 54000, lr = 0.0005
I0522 16:49:41.915817 31280 solver.cpp:237] Iteration 54375, loss = 1.56204
I0522 16:49:41.915993 31280 solver.cpp:253]     Train net output #0: loss = 1.56204 (* 1 = 1.56204 loss)
I0522 16:49:41.916008 31280 sgd_solver.cpp:106] Iteration 54375, lr = 0.0005
I0522 16:49:51.670608 31280 solver.cpp:237] Iteration 54750, loss = 1.40548
I0522 16:49:51.670642 31280 solver.cpp:253]     Train net output #0: loss = 1.40548 (* 1 = 1.40548 loss)
I0522 16:49:51.670660 31280 sgd_solver.cpp:106] Iteration 54750, lr = 0.0005
I0522 16:50:22.316078 31280 solver.cpp:237] Iteration 55125, loss = 1.16259
I0522 16:50:22.316259 31280 solver.cpp:253]     Train net output #0: loss = 1.16259 (* 1 = 1.16259 loss)
I0522 16:50:22.316274 31280 sgd_solver.cpp:106] Iteration 55125, lr = 0.0005
I0522 16:50:32.074599 31280 solver.cpp:237] Iteration 55500, loss = 1.15533
I0522 16:50:32.074642 31280 solver.cpp:253]     Train net output #0: loss = 1.15533 (* 1 = 1.15533 loss)
I0522 16:50:32.074661 31280 sgd_solver.cpp:106] Iteration 55500, lr = 0.0005
I0522 16:50:41.821882 31280 solver.cpp:237] Iteration 55875, loss = 1.19263
I0522 16:50:41.821918 31280 solver.cpp:253]     Train net output #0: loss = 1.19263 (* 1 = 1.19263 loss)
I0522 16:50:41.821935 31280 sgd_solver.cpp:106] Iteration 55875, lr = 0.0005
I0522 16:50:51.544900 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_56250.caffemodel
I0522 16:50:51.602728 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_56250.solverstate
I0522 16:50:51.639480 31280 solver.cpp:237] Iteration 56250, loss = 1.12077
I0522 16:50:51.639530 31280 solver.cpp:253]     Train net output #0: loss = 1.12077 (* 1 = 1.12077 loss)
I0522 16:50:51.639545 31280 sgd_solver.cpp:106] Iteration 56250, lr = 0.0005
I0522 16:51:01.404569 31280 solver.cpp:237] Iteration 56625, loss = 1.32718
I0522 16:51:01.404737 31280 solver.cpp:253]     Train net output #0: loss = 1.32718 (* 1 = 1.32718 loss)
I0522 16:51:01.404752 31280 sgd_solver.cpp:106] Iteration 56625, lr = 0.0005
I0522 16:51:11.174499 31280 solver.cpp:237] Iteration 57000, loss = 1.27255
I0522 16:51:11.174535 31280 solver.cpp:253]     Train net output #0: loss = 1.27255 (* 1 = 1.27255 loss)
I0522 16:51:11.174553 31280 sgd_solver.cpp:106] Iteration 57000, lr = 0.0005
I0522 16:51:20.926991 31280 solver.cpp:237] Iteration 57375, loss = 1.93127
I0522 16:51:20.927026 31280 solver.cpp:253]     Train net output #0: loss = 1.93127 (* 1 = 1.93127 loss)
I0522 16:51:20.927043 31280 sgd_solver.cpp:106] Iteration 57375, lr = 0.0005
I0522 16:51:51.565064 31280 solver.cpp:237] Iteration 57750, loss = 1.28852
I0522 16:51:51.565238 31280 solver.cpp:253]     Train net output #0: loss = 1.28852 (* 1 = 1.28852 loss)
I0522 16:51:51.565255 31280 sgd_solver.cpp:106] Iteration 57750, lr = 0.0005
I0522 16:52:01.326455 31280 solver.cpp:237] Iteration 58125, loss = 1.32817
I0522 16:52:01.326490 31280 solver.cpp:253]     Train net output #0: loss = 1.32817 (* 1 = 1.32817 loss)
I0522 16:52:01.326508 31280 sgd_solver.cpp:106] Iteration 58125, lr = 0.0005
I0522 16:52:11.091694 31280 solver.cpp:237] Iteration 58500, loss = 1.29625
I0522 16:52:11.091730 31280 solver.cpp:253]     Train net output #0: loss = 1.29625 (* 1 = 1.29625 loss)
I0522 16:52:11.091747 31280 sgd_solver.cpp:106] Iteration 58500, lr = 0.0005
I0522 16:52:20.856426 31280 solver.cpp:237] Iteration 58875, loss = 1.24118
I0522 16:52:20.856469 31280 solver.cpp:253]     Train net output #0: loss = 1.24118 (* 1 = 1.24118 loss)
I0522 16:52:20.856489 31280 sgd_solver.cpp:106] Iteration 58875, lr = 0.0005
I0522 16:52:30.598749 31280 solver.cpp:237] Iteration 59250, loss = 1.24508
I0522 16:52:30.598913 31280 solver.cpp:253]     Train net output #0: loss = 1.24508 (* 1 = 1.24508 loss)
I0522 16:52:30.598927 31280 sgd_solver.cpp:106] Iteration 59250, lr = 0.0005
I0522 16:52:40.339756 31280 solver.cpp:237] Iteration 59625, loss = 0.827147
I0522 16:52:40.339805 31280 solver.cpp:253]     Train net output #0: loss = 0.827147 (* 1 = 0.827147 loss)
I0522 16:52:40.339820 31280 sgd_solver.cpp:106] Iteration 59625, lr = 0.0005
I0522 16:52:50.068774 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_60000.caffemodel
I0522 16:52:50.124094 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_60000.solverstate
I0522 16:52:50.150606 31280 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 16:53:59.494410 31280 solver.cpp:409]     Test net output #0: accuracy = 0.844206
I0522 16:53:59.494576 31280 solver.cpp:409]     Test net output #1: loss = 0.554934 (* 1 = 0.554934 loss)
I0522 16:54:20.380518 31280 solver.cpp:237] Iteration 60000, loss = 1.07113
I0522 16:54:20.380571 31280 solver.cpp:253]     Train net output #0: loss = 1.07113 (* 1 = 1.07113 loss)
I0522 16:54:20.380586 31280 sgd_solver.cpp:106] Iteration 60000, lr = 0.0005
I0522 16:54:30.203941 31280 solver.cpp:237] Iteration 60375, loss = 1.14196
I0522 16:54:30.204097 31280 solver.cpp:253]     Train net output #0: loss = 1.14196 (* 1 = 1.14196 loss)
I0522 16:54:30.204109 31280 sgd_solver.cpp:106] Iteration 60375, lr = 0.0005
I0522 16:54:40.040225 31280 solver.cpp:237] Iteration 60750, loss = 1.27347
I0522 16:54:40.040261 31280 solver.cpp:253]     Train net output #0: loss = 1.27347 (* 1 = 1.27347 loss)
I0522 16:54:40.040274 31280 sgd_solver.cpp:106] Iteration 60750, lr = 0.0005
I0522 16:54:49.871026 31280 solver.cpp:237] Iteration 61125, loss = 1.82279
I0522 16:54:49.871069 31280 solver.cpp:253]     Train net output #0: loss = 1.82279 (* 1 = 1.82279 loss)
I0522 16:54:49.871090 31280 sgd_solver.cpp:106] Iteration 61125, lr = 0.0005
I0522 16:54:59.699751 31280 solver.cpp:237] Iteration 61500, loss = 1.1304
I0522 16:54:59.699786 31280 solver.cpp:253]     Train net output #0: loss = 1.1304 (* 1 = 1.1304 loss)
I0522 16:54:59.699803 31280 sgd_solver.cpp:106] Iteration 61500, lr = 0.0005
I0522 16:55:09.524308 31280 solver.cpp:237] Iteration 61875, loss = 1.14529
I0522 16:55:09.524477 31280 solver.cpp:253]     Train net output #0: loss = 1.14529 (* 1 = 1.14529 loss)
I0522 16:55:09.524490 31280 sgd_solver.cpp:106] Iteration 61875, lr = 0.0005
I0522 16:55:19.348925 31280 solver.cpp:237] Iteration 62250, loss = 1.28841
I0522 16:55:19.348960 31280 solver.cpp:253]     Train net output #0: loss = 1.28841 (* 1 = 1.28841 loss)
I0522 16:55:19.348978 31280 sgd_solver.cpp:106] Iteration 62250, lr = 0.0005
I0522 16:55:50.055066 31280 solver.cpp:237] Iteration 62625, loss = 1.24807
I0522 16:55:50.055239 31280 solver.cpp:253]     Train net output #0: loss = 1.24807 (* 1 = 1.24807 loss)
I0522 16:55:50.055255 31280 sgd_solver.cpp:106] Iteration 62625, lr = 0.0005
I0522 16:55:59.882547 31280 solver.cpp:237] Iteration 63000, loss = 0.838151
I0522 16:55:59.882596 31280 solver.cpp:253]     Train net output #0: loss = 0.838151 (* 1 = 0.838151 loss)
I0522 16:55:59.882612 31280 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I0522 16:56:09.711299 31280 solver.cpp:237] Iteration 63375, loss = 0.896316
I0522 16:56:09.711336 31280 solver.cpp:253]     Train net output #0: loss = 0.896316 (* 1 = 0.896316 loss)
I0522 16:56:09.711352 31280 sgd_solver.cpp:106] Iteration 63375, lr = 0.0005
I0522 16:56:19.515084 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_63750.caffemodel
I0522 16:56:19.576787 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_63750.solverstate
I0522 16:56:19.611639 31280 solver.cpp:237] Iteration 63750, loss = 1.15281
I0522 16:56:19.611685 31280 solver.cpp:253]     Train net output #0: loss = 1.15281 (* 1 = 1.15281 loss)
I0522 16:56:19.611699 31280 sgd_solver.cpp:106] Iteration 63750, lr = 0.0005
I0522 16:56:29.439062 31280 solver.cpp:237] Iteration 64125, loss = 1.43442
I0522 16:56:29.439240 31280 solver.cpp:253]     Train net output #0: loss = 1.43442 (* 1 = 1.43442 loss)
I0522 16:56:29.439254 31280 sgd_solver.cpp:106] Iteration 64125, lr = 0.0005
I0522 16:56:39.262398 31280 solver.cpp:237] Iteration 64500, loss = 0.91583
I0522 16:56:39.262433 31280 solver.cpp:253]     Train net output #0: loss = 0.91583 (* 1 = 0.91583 loss)
I0522 16:56:39.262450 31280 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I0522 16:56:49.094110 31280 solver.cpp:237] Iteration 64875, loss = 1.29389
I0522 16:56:49.094156 31280 solver.cpp:253]     Train net output #0: loss = 1.29389 (* 1 = 1.29389 loss)
I0522 16:56:49.094172 31280 sgd_solver.cpp:106] Iteration 64875, lr = 0.0005
I0522 16:57:19.824944 31280 solver.cpp:237] Iteration 65250, loss = 1.19612
I0522 16:57:19.825122 31280 solver.cpp:253]     Train net output #0: loss = 1.19612 (* 1 = 1.19612 loss)
I0522 16:57:19.825139 31280 sgd_solver.cpp:106] Iteration 65250, lr = 0.0005
I0522 16:57:29.649734 31280 solver.cpp:237] Iteration 65625, loss = 1.29195
I0522 16:57:29.649770 31280 solver.cpp:253]     Train net output #0: loss = 1.29195 (* 1 = 1.29195 loss)
I0522 16:57:29.649783 31280 sgd_solver.cpp:106] Iteration 65625, lr = 0.0005
I0522 16:57:39.486104 31280 solver.cpp:237] Iteration 66000, loss = 1.13985
I0522 16:57:39.486151 31280 solver.cpp:253]     Train net output #0: loss = 1.13985 (* 1 = 1.13985 loss)
I0522 16:57:39.486168 31280 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I0522 16:57:49.309171 31280 solver.cpp:237] Iteration 66375, loss = 1.37006
I0522 16:57:49.309206 31280 solver.cpp:253]     Train net output #0: loss = 1.37006 (* 1 = 1.37006 loss)
I0522 16:57:49.309223 31280 sgd_solver.cpp:106] Iteration 66375, lr = 0.0005
I0522 16:57:59.135236 31280 solver.cpp:237] Iteration 66750, loss = 1.09282
I0522 16:57:59.135390 31280 solver.cpp:253]     Train net output #0: loss = 1.09282 (* 1 = 1.09282 loss)
I0522 16:57:59.135404 31280 sgd_solver.cpp:106] Iteration 66750, lr = 0.0005
I0522 16:58:08.966390 31280 solver.cpp:237] Iteration 67125, loss = 1.29744
I0522 16:58:08.966437 31280 solver.cpp:253]     Train net output #0: loss = 1.29744 (* 1 = 1.29744 loss)
I0522 16:58:08.966451 31280 sgd_solver.cpp:106] Iteration 67125, lr = 0.0005
I0522 16:58:18.763600 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_67500.caffemodel
I0522 16:58:18.819963 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_67500.solverstate
I0522 16:58:18.846237 31280 solver.cpp:341] Iteration 67500, Testing net (#0)
I0522 16:59:07.331563 31280 solver.cpp:409]     Test net output #0: accuracy = 0.849607
I0522 16:59:07.331743 31280 solver.cpp:409]     Test net output #1: loss = 0.519975 (* 1 = 0.519975 loss)
I0522 16:59:28.237320 31280 solver.cpp:237] Iteration 67500, loss = 1.1261
I0522 16:59:28.237373 31280 solver.cpp:253]     Train net output #0: loss = 1.1261 (* 1 = 1.1261 loss)
I0522 16:59:28.237388 31280 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I0522 16:59:38.027745 31280 solver.cpp:237] Iteration 67875, loss = 1.45779
I0522 16:59:38.027904 31280 solver.cpp:253]     Train net output #0: loss = 1.45779 (* 1 = 1.45779 loss)
I0522 16:59:38.027917 31280 sgd_solver.cpp:106] Iteration 67875, lr = 0.0005
I0522 16:59:47.790474 31280 solver.cpp:237] Iteration 68250, loss = 1.13275
I0522 16:59:47.790520 31280 solver.cpp:253]     Train net output #0: loss = 1.13275 (* 1 = 1.13275 loss)
I0522 16:59:47.790540 31280 sgd_solver.cpp:106] Iteration 68250, lr = 0.0005
I0522 16:59:57.538682 31280 solver.cpp:237] Iteration 68625, loss = 0.933981
I0522 16:59:57.538718 31280 solver.cpp:253]     Train net output #0: loss = 0.933981 (* 1 = 0.933981 loss)
I0522 16:59:57.538734 31280 sgd_solver.cpp:106] Iteration 68625, lr = 0.0005
I0522 17:00:07.285478 31280 solver.cpp:237] Iteration 69000, loss = 1.14521
I0522 17:00:07.285526 31280 solver.cpp:253]     Train net output #0: loss = 1.14521 (* 1 = 1.14521 loss)
I0522 17:00:07.285542 31280 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I0522 17:00:17.030594 31280 solver.cpp:237] Iteration 69375, loss = 1.24058
I0522 17:00:17.030777 31280 solver.cpp:253]     Train net output #0: loss = 1.24058 (* 1 = 1.24058 loss)
I0522 17:00:17.030791 31280 sgd_solver.cpp:106] Iteration 69375, lr = 0.0005
I0522 17:00:26.779448 31280 solver.cpp:237] Iteration 69750, loss = 1.2381
I0522 17:00:26.779484 31280 solver.cpp:253]     Train net output #0: loss = 1.2381 (* 1 = 1.2381 loss)
I0522 17:00:26.779498 31280 sgd_solver.cpp:106] Iteration 69750, lr = 0.0005
I0522 17:00:57.459980 31280 solver.cpp:237] Iteration 70125, loss = 1.34408
I0522 17:00:57.460157 31280 solver.cpp:253]     Train net output #0: loss = 1.34408 (* 1 = 1.34408 loss)
I0522 17:00:57.460173 31280 sgd_solver.cpp:106] Iteration 70125, lr = 0.0005
I0522 17:01:07.211237 31280 solver.cpp:237] Iteration 70500, loss = 1.7392
I0522 17:01:07.211272 31280 solver.cpp:253]     Train net output #0: loss = 1.7392 (* 1 = 1.7392 loss)
I0522 17:01:07.211289 31280 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I0522 17:01:16.962956 31280 solver.cpp:237] Iteration 70875, loss = 1.18189
I0522 17:01:16.962991 31280 solver.cpp:253]     Train net output #0: loss = 1.18189 (* 1 = 1.18189 loss)
I0522 17:01:16.963008 31280 sgd_solver.cpp:106] Iteration 70875, lr = 0.0005
I0522 17:01:26.686425 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_71250.caffemodel
I0522 17:01:26.744774 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_71250.solverstate
I0522 17:01:26.781746 31280 solver.cpp:237] Iteration 71250, loss = 1.59984
I0522 17:01:26.781797 31280 solver.cpp:253]     Train net output #0: loss = 1.59984 (* 1 = 1.59984 loss)
I0522 17:01:26.781812 31280 sgd_solver.cpp:106] Iteration 71250, lr = 0.0005
I0522 17:01:36.529947 31280 solver.cpp:237] Iteration 71625, loss = 1.185
I0522 17:01:36.530107 31280 solver.cpp:253]     Train net output #0: loss = 1.185 (* 1 = 1.185 loss)
I0522 17:01:36.530120 31280 sgd_solver.cpp:106] Iteration 71625, lr = 0.0005
I0522 17:01:46.263766 31280 solver.cpp:237] Iteration 72000, loss = 1.45403
I0522 17:01:46.263800 31280 solver.cpp:253]     Train net output #0: loss = 1.45403 (* 1 = 1.45403 loss)
I0522 17:01:46.263816 31280 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I0522 17:01:55.989100 31280 solver.cpp:237] Iteration 72375, loss = 1.50673
I0522 17:01:55.989135 31280 solver.cpp:253]     Train net output #0: loss = 1.50673 (* 1 = 1.50673 loss)
I0522 17:01:55.989152 31280 sgd_solver.cpp:106] Iteration 72375, lr = 0.0005
I0522 17:02:26.624168 31280 solver.cpp:237] Iteration 72750, loss = 1.18503
I0522 17:02:26.624347 31280 solver.cpp:253]     Train net output #0: loss = 1.18503 (* 1 = 1.18503 loss)
I0522 17:02:26.624363 31280 sgd_solver.cpp:106] Iteration 72750, lr = 0.0005
I0522 17:02:36.354032 31280 solver.cpp:237] Iteration 73125, loss = 1.29163
I0522 17:02:36.354068 31280 solver.cpp:253]     Train net output #0: loss = 1.29163 (* 1 = 1.29163 loss)
I0522 17:02:36.354084 31280 sgd_solver.cpp:106] Iteration 73125, lr = 0.0005
I0522 17:02:46.089501 31280 solver.cpp:237] Iteration 73500, loss = 1.26108
I0522 17:02:46.089540 31280 solver.cpp:253]     Train net output #0: loss = 1.26108 (* 1 = 1.26108 loss)
I0522 17:02:46.089560 31280 sgd_solver.cpp:106] Iteration 73500, lr = 0.0005
I0522 17:02:55.816099 31280 solver.cpp:237] Iteration 73875, loss = 1.61451
I0522 17:02:55.816135 31280 solver.cpp:253]     Train net output #0: loss = 1.61451 (* 1 = 1.61451 loss)
I0522 17:02:55.816153 31280 sgd_solver.cpp:106] Iteration 73875, lr = 0.0005
I0522 17:03:05.536898 31280 solver.cpp:237] Iteration 74250, loss = 1.26704
I0522 17:03:05.537080 31280 solver.cpp:253]     Train net output #0: loss = 1.26704 (* 1 = 1.26704 loss)
I0522 17:03:05.537094 31280 sgd_solver.cpp:106] Iteration 74250, lr = 0.0005
I0522 17:03:15.257460 31280 solver.cpp:237] Iteration 74625, loss = 1.3012
I0522 17:03:15.257495 31280 solver.cpp:253]     Train net output #0: loss = 1.3012 (* 1 = 1.3012 loss)
I0522 17:03:15.257519 31280 sgd_solver.cpp:106] Iteration 74625, lr = 0.0005
I0522 17:03:24.962370 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_75000.caffemodel
I0522 17:03:25.020503 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_75000.solverstate
I0522 17:03:25.049021 31280 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 17:04:34.474108 31280 solver.cpp:409]     Test net output #0: accuracy = 0.853334
I0522 17:04:34.474284 31280 solver.cpp:409]     Test net output #1: loss = 0.492937 (* 1 = 0.492937 loss)
I0522 17:04:55.412256 31280 solver.cpp:237] Iteration 75000, loss = 1.30472
I0522 17:04:55.412310 31280 solver.cpp:253]     Train net output #0: loss = 1.30472 (* 1 = 1.30472 loss)
I0522 17:04:55.412325 31280 sgd_solver.cpp:106] Iteration 75000, lr = 0.0005
I0522 17:05:05.172451 31280 solver.cpp:237] Iteration 75375, loss = 1.04512
I0522 17:05:05.172611 31280 solver.cpp:253]     Train net output #0: loss = 1.04512 (* 1 = 1.04512 loss)
I0522 17:05:05.172626 31280 sgd_solver.cpp:106] Iteration 75375, lr = 0.0005
I0522 17:05:14.930481 31280 solver.cpp:237] Iteration 75750, loss = 1.41322
I0522 17:05:14.930527 31280 solver.cpp:253]     Train net output #0: loss = 1.41322 (* 1 = 1.41322 loss)
I0522 17:05:14.930544 31280 sgd_solver.cpp:106] Iteration 75750, lr = 0.0005
I0522 17:05:24.695317 31280 solver.cpp:237] Iteration 76125, loss = 1.05444
I0522 17:05:24.695353 31280 solver.cpp:253]     Train net output #0: loss = 1.05444 (* 1 = 1.05444 loss)
I0522 17:05:24.695370 31280 sgd_solver.cpp:106] Iteration 76125, lr = 0.0005
I0522 17:05:34.464483 31280 solver.cpp:237] Iteration 76500, loss = 1.05043
I0522 17:05:34.464526 31280 solver.cpp:253]     Train net output #0: loss = 1.05043 (* 1 = 1.05043 loss)
I0522 17:05:34.464547 31280 sgd_solver.cpp:106] Iteration 76500, lr = 0.0005
I0522 17:05:44.229127 31280 solver.cpp:237] Iteration 76875, loss = 1.14173
I0522 17:05:44.229284 31280 solver.cpp:253]     Train net output #0: loss = 1.14173 (* 1 = 1.14173 loss)
I0522 17:05:44.229297 31280 sgd_solver.cpp:106] Iteration 76875, lr = 0.0005
I0522 17:05:53.993187 31280 solver.cpp:237] Iteration 77250, loss = 1.31496
I0522 17:05:53.993222 31280 solver.cpp:253]     Train net output #0: loss = 1.31496 (* 1 = 1.31496 loss)
I0522 17:05:53.993239 31280 sgd_solver.cpp:106] Iteration 77250, lr = 0.0005
I0522 17:06:24.655057 31280 solver.cpp:237] Iteration 77625, loss = 1.1268
I0522 17:06:24.655230 31280 solver.cpp:253]     Train net output #0: loss = 1.1268 (* 1 = 1.1268 loss)
I0522 17:06:24.655244 31280 sgd_solver.cpp:106] Iteration 77625, lr = 0.0005
I0522 17:06:34.481197 31280 solver.cpp:237] Iteration 78000, loss = 0.912008
I0522 17:06:34.481233 31280 solver.cpp:253]     Train net output #0: loss = 0.912008 (* 1 = 0.912008 loss)
I0522 17:06:34.481251 31280 sgd_solver.cpp:106] Iteration 78000, lr = 0.0005
I0522 17:06:44.311134 31280 solver.cpp:237] Iteration 78375, loss = 1.45398
I0522 17:06:44.311169 31280 solver.cpp:253]     Train net output #0: loss = 1.45398 (* 1 = 1.45398 loss)
I0522 17:06:44.311185 31280 sgd_solver.cpp:106] Iteration 78375, lr = 0.0005
I0522 17:06:54.109221 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_78750.caffemodel
I0522 17:06:54.165535 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_78750.solverstate
I0522 17:06:54.200115 31280 solver.cpp:237] Iteration 78750, loss = 1.30021
I0522 17:06:54.200156 31280 solver.cpp:253]     Train net output #0: loss = 1.30021 (* 1 = 1.30021 loss)
I0522 17:06:54.200177 31280 sgd_solver.cpp:106] Iteration 78750, lr = 0.0005
I0522 17:07:04.026572 31280 solver.cpp:237] Iteration 79125, loss = 1.289
I0522 17:07:04.026741 31280 solver.cpp:253]     Train net output #0: loss = 1.289 (* 1 = 1.289 loss)
I0522 17:07:04.026757 31280 sgd_solver.cpp:106] Iteration 79125, lr = 0.0005
I0522 17:07:13.853281 31280 solver.cpp:237] Iteration 79500, loss = 1.18406
I0522 17:07:13.853327 31280 solver.cpp:253]     Train net output #0: loss = 1.18406 (* 1 = 1.18406 loss)
I0522 17:07:13.853343 31280 sgd_solver.cpp:106] Iteration 79500, lr = 0.0005
I0522 17:07:23.676391 31280 solver.cpp:237] Iteration 79875, loss = 1.19544
I0522 17:07:23.676427 31280 solver.cpp:253]     Train net output #0: loss = 1.19544 (* 1 = 1.19544 loss)
I0522 17:07:23.676442 31280 sgd_solver.cpp:106] Iteration 79875, lr = 0.0005
I0522 17:07:54.417546 31280 solver.cpp:237] Iteration 80250, loss = 0.899583
I0522 17:07:54.417726 31280 solver.cpp:253]     Train net output #0: loss = 0.899583 (* 1 = 0.899583 loss)
I0522 17:07:54.417742 31280 sgd_solver.cpp:106] Iteration 80250, lr = 0.0005
I0522 17:08:04.245399 31280 solver.cpp:237] Iteration 80625, loss = 0.985289
I0522 17:08:04.245445 31280 solver.cpp:253]     Train net output #0: loss = 0.985289 (* 1 = 0.985289 loss)
I0522 17:08:04.245457 31280 sgd_solver.cpp:106] Iteration 80625, lr = 0.0005
I0522 17:08:14.070438 31280 solver.cpp:237] Iteration 81000, loss = 1.27321
I0522 17:08:14.070473 31280 solver.cpp:253]     Train net output #0: loss = 1.27321 (* 1 = 1.27321 loss)
I0522 17:08:14.070490 31280 sgd_solver.cpp:106] Iteration 81000, lr = 0.0005
I0522 17:08:23.896224 31280 solver.cpp:237] Iteration 81375, loss = 1.32774
I0522 17:08:23.896322 31280 solver.cpp:253]     Train net output #0: loss = 1.32774 (* 1 = 1.32774 loss)
I0522 17:08:23.896339 31280 sgd_solver.cpp:106] Iteration 81375, lr = 0.0005
I0522 17:08:33.720979 31280 solver.cpp:237] Iteration 81750, loss = 1.37417
I0522 17:08:33.721154 31280 solver.cpp:253]     Train net output #0: loss = 1.37417 (* 1 = 1.37417 loss)
I0522 17:08:33.721168 31280 sgd_solver.cpp:106] Iteration 81750, lr = 0.0005
I0522 17:08:43.549223 31280 solver.cpp:237] Iteration 82125, loss = 1.16292
I0522 17:08:43.549258 31280 solver.cpp:253]     Train net output #0: loss = 1.16292 (* 1 = 1.16292 loss)
I0522 17:08:43.549275 31280 sgd_solver.cpp:106] Iteration 82125, lr = 0.0005
I0522 17:08:53.350519 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_82500.caffemodel
I0522 17:08:53.406090 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_82500.solverstate
I0522 17:08:53.432674 31280 solver.cpp:341] Iteration 82500, Testing net (#0)
I0522 17:09:41.681232 31280 solver.cpp:409]     Test net output #0: accuracy = 0.856485
I0522 17:09:41.693559 31280 solver.cpp:409]     Test net output #1: loss = 0.472543 (* 1 = 0.472543 loss)
I0522 17:10:02.620842 31280 solver.cpp:237] Iteration 82500, loss = 1.36632
I0522 17:10:02.620895 31280 solver.cpp:253]     Train net output #0: loss = 1.36632 (* 1 = 1.36632 loss)
I0522 17:10:02.620910 31280 sgd_solver.cpp:106] Iteration 82500, lr = 0.0005
I0522 17:10:12.529450 31280 solver.cpp:237] Iteration 82875, loss = 1.04736
I0522 17:10:12.529636 31280 solver.cpp:253]     Train net output #0: loss = 1.04736 (* 1 = 1.04736 loss)
I0522 17:10:12.529650 31280 sgd_solver.cpp:106] Iteration 82875, lr = 0.0005
I0522 17:10:22.432584 31280 solver.cpp:237] Iteration 83250, loss = 0.932613
I0522 17:10:22.432620 31280 solver.cpp:253]     Train net output #0: loss = 0.932613 (* 1 = 0.932613 loss)
I0522 17:10:22.432637 31280 sgd_solver.cpp:106] Iteration 83250, lr = 0.0005
I0522 17:10:32.337884 31280 solver.cpp:237] Iteration 83625, loss = 1.42329
I0522 17:10:32.337931 31280 solver.cpp:253]     Train net output #0: loss = 1.42329 (* 1 = 1.42329 loss)
I0522 17:10:32.337949 31280 sgd_solver.cpp:106] Iteration 83625, lr = 0.0005
I0522 17:10:42.240262 31280 solver.cpp:237] Iteration 84000, loss = 1.15432
I0522 17:10:42.240298 31280 solver.cpp:253]     Train net output #0: loss = 1.15432 (* 1 = 1.15432 loss)
I0522 17:10:42.240310 31280 sgd_solver.cpp:106] Iteration 84000, lr = 0.0005
I0522 17:10:52.140669 31280 solver.cpp:237] Iteration 84375, loss = 1.23909
I0522 17:10:52.140830 31280 solver.cpp:253]     Train net output #0: loss = 1.23909 (* 1 = 1.23909 loss)
I0522 17:10:52.140843 31280 sgd_solver.cpp:106] Iteration 84375, lr = 0.0005
I0522 17:11:02.045812 31280 solver.cpp:237] Iteration 84750, loss = 1.21739
I0522 17:11:02.045861 31280 solver.cpp:253]     Train net output #0: loss = 1.21739 (* 1 = 1.21739 loss)
I0522 17:11:02.045878 31280 sgd_solver.cpp:106] Iteration 84750, lr = 0.0005
I0522 17:11:32.860720 31280 solver.cpp:237] Iteration 85125, loss = 1.33688
I0522 17:11:32.860899 31280 solver.cpp:253]     Train net output #0: loss = 1.33688 (* 1 = 1.33688 loss)
I0522 17:11:32.860915 31280 sgd_solver.cpp:106] Iteration 85125, lr = 0.0005
I0522 17:11:42.784621 31280 solver.cpp:237] Iteration 85500, loss = 1.1133
I0522 17:11:42.784657 31280 solver.cpp:253]     Train net output #0: loss = 1.1133 (* 1 = 1.1133 loss)
I0522 17:11:42.784673 31280 sgd_solver.cpp:106] Iteration 85500, lr = 0.0005
I0522 17:11:52.701874 31280 solver.cpp:237] Iteration 85875, loss = 1.09829
I0522 17:11:52.701923 31280 solver.cpp:253]     Train net output #0: loss = 1.09829 (* 1 = 1.09829 loss)
I0522 17:11:52.701938 31280 sgd_solver.cpp:106] Iteration 85875, lr = 0.0005
I0522 17:12:02.594596 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_86250.caffemodel
I0522 17:12:02.651401 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_86250.solverstate
I0522 17:12:02.685854 31280 solver.cpp:237] Iteration 86250, loss = 1.28758
I0522 17:12:02.685894 31280 solver.cpp:253]     Train net output #0: loss = 1.28758 (* 1 = 1.28758 loss)
I0522 17:12:02.685912 31280 sgd_solver.cpp:106] Iteration 86250, lr = 0.0005
I0522 17:12:12.601579 31280 solver.cpp:237] Iteration 86625, loss = 1.18216
I0522 17:12:12.601755 31280 solver.cpp:253]     Train net output #0: loss = 1.18216 (* 1 = 1.18216 loss)
I0522 17:12:12.601769 31280 sgd_solver.cpp:106] Iteration 86625, lr = 0.0005
I0522 17:12:22.521003 31280 solver.cpp:237] Iteration 87000, loss = 1.20742
I0522 17:12:22.521037 31280 solver.cpp:253]     Train net output #0: loss = 1.20742 (* 1 = 1.20742 loss)
I0522 17:12:22.521055 31280 sgd_solver.cpp:106] Iteration 87000, lr = 0.0005
I0522 17:12:32.439154 31280 solver.cpp:237] Iteration 87375, loss = 1.60427
I0522 17:12:32.439190 31280 solver.cpp:253]     Train net output #0: loss = 1.60427 (* 1 = 1.60427 loss)
I0522 17:12:32.439208 31280 sgd_solver.cpp:106] Iteration 87375, lr = 0.0005
I0522 17:13:03.276772 31280 solver.cpp:237] Iteration 87750, loss = 1.08294
I0522 17:13:03.276952 31280 solver.cpp:253]     Train net output #0: loss = 1.08294 (* 1 = 1.08294 loss)
I0522 17:13:03.276967 31280 sgd_solver.cpp:106] Iteration 87750, lr = 0.0005
I0522 17:13:13.188757 31280 solver.cpp:237] Iteration 88125, loss = 1.41572
I0522 17:13:13.188792 31280 solver.cpp:253]     Train net output #0: loss = 1.41572 (* 1 = 1.41572 loss)
I0522 17:13:13.188810 31280 sgd_solver.cpp:106] Iteration 88125, lr = 0.0005
I0522 17:13:23.100944 31280 solver.cpp:237] Iteration 88500, loss = 1.04401
I0522 17:13:23.100980 31280 solver.cpp:253]     Train net output #0: loss = 1.04401 (* 1 = 1.04401 loss)
I0522 17:13:23.100993 31280 sgd_solver.cpp:106] Iteration 88500, lr = 0.0005
I0522 17:13:33.011194 31280 solver.cpp:237] Iteration 88875, loss = 0.926469
I0522 17:13:33.011246 31280 solver.cpp:253]     Train net output #0: loss = 0.926469 (* 1 = 0.926469 loss)
I0522 17:13:33.011260 31280 sgd_solver.cpp:106] Iteration 88875, lr = 0.0005
I0522 17:13:42.928288 31280 solver.cpp:237] Iteration 89250, loss = 1.25774
I0522 17:13:42.928455 31280 solver.cpp:253]     Train net output #0: loss = 1.25774 (* 1 = 1.25774 loss)
I0522 17:13:42.928469 31280 sgd_solver.cpp:106] Iteration 89250, lr = 0.0005
I0522 17:13:52.846287 31280 solver.cpp:237] Iteration 89625, loss = 1.2087
I0522 17:13:52.846334 31280 solver.cpp:253]     Train net output #0: loss = 1.2087 (* 1 = 1.2087 loss)
I0522 17:13:52.846349 31280 sgd_solver.cpp:106] Iteration 89625, lr = 0.0005
I0522 17:14:02.734935 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_90000.caffemodel
I0522 17:14:02.791931 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_90000.solverstate
I0522 17:14:02.818619 31280 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 17:15:12.280169 31280 solver.cpp:409]     Test net output #0: accuracy = 0.861353
I0522 17:15:12.280345 31280 solver.cpp:409]     Test net output #1: loss = 0.449008 (* 1 = 0.449008 loss)
I0522 17:15:33.197921 31280 solver.cpp:237] Iteration 90000, loss = 1.14306
I0522 17:15:33.197976 31280 solver.cpp:253]     Train net output #0: loss = 1.14306 (* 1 = 1.14306 loss)
I0522 17:15:33.197990 31280 sgd_solver.cpp:106] Iteration 90000, lr = 0.0005
I0522 17:15:42.860958 31280 solver.cpp:237] Iteration 90375, loss = 1.08081
I0522 17:15:42.861121 31280 solver.cpp:253]     Train net output #0: loss = 1.08081 (* 1 = 1.08081 loss)
I0522 17:15:42.861135 31280 sgd_solver.cpp:106] Iteration 90375, lr = 0.0005
I0522 17:15:52.524279 31280 solver.cpp:237] Iteration 90750, loss = 1.35847
I0522 17:15:52.524313 31280 solver.cpp:253]     Train net output #0: loss = 1.35847 (* 1 = 1.35847 loss)
I0522 17:15:52.524330 31280 sgd_solver.cpp:106] Iteration 90750, lr = 0.0005
I0522 17:16:02.185101 31280 solver.cpp:237] Iteration 91125, loss = 1.2888
I0522 17:16:02.185142 31280 solver.cpp:253]     Train net output #0: loss = 1.2888 (* 1 = 1.2888 loss)
I0522 17:16:02.185159 31280 sgd_solver.cpp:106] Iteration 91125, lr = 0.0005
I0522 17:16:11.842430 31280 solver.cpp:237] Iteration 91500, loss = 1.41402
I0522 17:16:11.842466 31280 solver.cpp:253]     Train net output #0: loss = 1.41402 (* 1 = 1.41402 loss)
I0522 17:16:11.842483 31280 sgd_solver.cpp:106] Iteration 91500, lr = 0.0005
I0522 17:16:21.503932 31280 solver.cpp:237] Iteration 91875, loss = 1.2
I0522 17:16:21.504087 31280 solver.cpp:253]     Train net output #0: loss = 1.2 (* 1 = 1.2 loss)
I0522 17:16:21.504101 31280 sgd_solver.cpp:106] Iteration 91875, lr = 0.0005
I0522 17:16:31.166700 31280 solver.cpp:237] Iteration 92250, loss = 1.47162
I0522 17:16:31.166741 31280 solver.cpp:253]     Train net output #0: loss = 1.47162 (* 1 = 1.47162 loss)
I0522 17:16:31.166759 31280 sgd_solver.cpp:106] Iteration 92250, lr = 0.0005
I0522 17:17:01.744807 31280 solver.cpp:237] Iteration 92625, loss = 1.1268
I0522 17:17:01.744985 31280 solver.cpp:253]     Train net output #0: loss = 1.1268 (* 1 = 1.1268 loss)
I0522 17:17:01.744999 31280 sgd_solver.cpp:106] Iteration 92625, lr = 0.0005
I0522 17:17:11.421119 31280 solver.cpp:237] Iteration 93000, loss = 1.38185
I0522 17:17:11.421155 31280 solver.cpp:253]     Train net output #0: loss = 1.38185 (* 1 = 1.38185 loss)
I0522 17:17:11.421174 31280 sgd_solver.cpp:106] Iteration 93000, lr = 0.0005
I0522 17:17:21.087157 31280 solver.cpp:237] Iteration 93375, loss = 1.04645
I0522 17:17:21.087203 31280 solver.cpp:253]     Train net output #0: loss = 1.04645 (* 1 = 1.04645 loss)
I0522 17:17:21.087219 31280 sgd_solver.cpp:106] Iteration 93375, lr = 0.0005
I0522 17:17:30.724989 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_93750.caffemodel
I0522 17:17:30.782555 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_93750.solverstate
I0522 17:17:30.819459 31280 solver.cpp:237] Iteration 93750, loss = 1.4818
I0522 17:17:30.819510 31280 solver.cpp:253]     Train net output #0: loss = 1.4818 (* 1 = 1.4818 loss)
I0522 17:17:30.819525 31280 sgd_solver.cpp:106] Iteration 93750, lr = 0.0005
I0522 17:17:40.484120 31280 solver.cpp:237] Iteration 94125, loss = 1.54824
I0522 17:17:40.484305 31280 solver.cpp:253]     Train net output #0: loss = 1.54824 (* 1 = 1.54824 loss)
I0522 17:17:40.484319 31280 sgd_solver.cpp:106] Iteration 94125, lr = 0.0005
I0522 17:17:50.146914 31280 solver.cpp:237] Iteration 94500, loss = 1.34609
I0522 17:17:50.146950 31280 solver.cpp:253]     Train net output #0: loss = 1.34609 (* 1 = 1.34609 loss)
I0522 17:17:50.146966 31280 sgd_solver.cpp:106] Iteration 94500, lr = 0.0005
I0522 17:17:59.810817 31280 solver.cpp:237] Iteration 94875, loss = 1.55301
I0522 17:17:59.810850 31280 solver.cpp:253]     Train net output #0: loss = 1.55301 (* 1 = 1.55301 loss)
I0522 17:17:59.810869 31280 sgd_solver.cpp:106] Iteration 94875, lr = 0.0005
I0522 17:18:30.392312 31280 solver.cpp:237] Iteration 95250, loss = 1.06158
I0522 17:18:30.392491 31280 solver.cpp:253]     Train net output #0: loss = 1.06158 (* 1 = 1.06158 loss)
I0522 17:18:30.392508 31280 sgd_solver.cpp:106] Iteration 95250, lr = 0.0005
I0522 17:18:40.077852 31280 solver.cpp:237] Iteration 95625, loss = 1.07225
I0522 17:18:40.077883 31280 solver.cpp:253]     Train net output #0: loss = 1.07225 (* 1 = 1.07225 loss)
I0522 17:18:40.077898 31280 sgd_solver.cpp:106] Iteration 95625, lr = 0.0005
I0522 17:18:49.766247 31280 solver.cpp:237] Iteration 96000, loss = 1.16845
I0522 17:18:49.766283 31280 solver.cpp:253]     Train net output #0: loss = 1.16845 (* 1 = 1.16845 loss)
I0522 17:18:49.766299 31280 sgd_solver.cpp:106] Iteration 96000, lr = 0.0005
I0522 17:18:59.454831 31280 solver.cpp:237] Iteration 96375, loss = 1.21738
I0522 17:18:59.454879 31280 solver.cpp:253]     Train net output #0: loss = 1.21738 (* 1 = 1.21738 loss)
I0522 17:18:59.454895 31280 sgd_solver.cpp:106] Iteration 96375, lr = 0.0005
I0522 17:19:09.144953 31280 solver.cpp:237] Iteration 96750, loss = 1.27457
I0522 17:19:09.145113 31280 solver.cpp:253]     Train net output #0: loss = 1.27457 (* 1 = 1.27457 loss)
I0522 17:19:09.145128 31280 sgd_solver.cpp:106] Iteration 96750, lr = 0.0005
I0522 17:19:18.838403 31280 solver.cpp:237] Iteration 97125, loss = 0.839906
I0522 17:19:18.838451 31280 solver.cpp:253]     Train net output #0: loss = 0.839906 (* 1 = 0.839906 loss)
I0522 17:19:18.838471 31280 sgd_solver.cpp:106] Iteration 97125, lr = 0.0005
I0522 17:19:28.494359 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_97500.caffemodel
I0522 17:19:28.561148 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_97500.solverstate
I0522 17:19:28.594038 31280 solver.cpp:341] Iteration 97500, Testing net (#0)
I0522 17:20:17.105265 31280 solver.cpp:409]     Test net output #0: accuracy = 0.86354
I0522 17:20:17.105468 31280 solver.cpp:409]     Test net output #1: loss = 0.45423 (* 1 = 0.45423 loss)
I0522 17:20:37.947952 31280 solver.cpp:237] Iteration 97500, loss = 1.37209
I0522 17:20:37.948004 31280 solver.cpp:253]     Train net output #0: loss = 1.37209 (* 1 = 1.37209 loss)
I0522 17:20:37.948019 31280 sgd_solver.cpp:106] Iteration 97500, lr = 0.0005
I0522 17:20:47.779454 31280 solver.cpp:237] Iteration 97875, loss = 1.26599
I0522 17:20:47.779620 31280 solver.cpp:253]     Train net output #0: loss = 1.26599 (* 1 = 1.26599 loss)
I0522 17:20:47.779634 31280 sgd_solver.cpp:106] Iteration 97875, lr = 0.0005
I0522 17:20:57.611888 31280 solver.cpp:237] Iteration 98250, loss = 1.29797
I0522 17:20:57.611934 31280 solver.cpp:253]     Train net output #0: loss = 1.29797 (* 1 = 1.29797 loss)
I0522 17:20:57.611949 31280 sgd_solver.cpp:106] Iteration 98250, lr = 0.0005
I0522 17:21:07.450481 31280 solver.cpp:237] Iteration 98625, loss = 1.47414
I0522 17:21:07.450517 31280 solver.cpp:253]     Train net output #0: loss = 1.47414 (* 1 = 1.47414 loss)
I0522 17:21:07.450533 31280 sgd_solver.cpp:106] Iteration 98625, lr = 0.0005
I0522 17:21:17.289075 31280 solver.cpp:237] Iteration 99000, loss = 1.1976
I0522 17:21:17.289110 31280 solver.cpp:253]     Train net output #0: loss = 1.1976 (* 1 = 1.1976 loss)
I0522 17:21:17.289129 31280 sgd_solver.cpp:106] Iteration 99000, lr = 0.0005
I0522 17:21:27.122797 31280 solver.cpp:237] Iteration 99375, loss = 1.23103
I0522 17:21:27.122968 31280 solver.cpp:253]     Train net output #0: loss = 1.23103 (* 1 = 1.23103 loss)
I0522 17:21:27.122982 31280 sgd_solver.cpp:106] Iteration 99375, lr = 0.0005
I0522 17:21:36.956266 31280 solver.cpp:237] Iteration 99750, loss = 1.05314
I0522 17:21:36.956300 31280 solver.cpp:253]     Train net output #0: loss = 1.05314 (* 1 = 1.05314 loss)
I0522 17:21:36.956318 31280 sgd_solver.cpp:106] Iteration 99750, lr = 0.0005
I0522 17:22:07.664579 31280 solver.cpp:237] Iteration 100125, loss = 1.21398
I0522 17:22:07.664762 31280 solver.cpp:253]     Train net output #0: loss = 1.21398 (* 1 = 1.21398 loss)
I0522 17:22:07.664777 31280 sgd_solver.cpp:106] Iteration 100125, lr = 0.0005
I0522 17:22:17.501699 31280 solver.cpp:237] Iteration 100500, loss = 1.10339
I0522 17:22:17.501745 31280 solver.cpp:253]     Train net output #0: loss = 1.10339 (* 1 = 1.10339 loss)
I0522 17:22:17.501762 31280 sgd_solver.cpp:106] Iteration 100500, lr = 0.0005
I0522 17:22:27.333884 31280 solver.cpp:237] Iteration 100875, loss = 1.00973
I0522 17:22:27.333920 31280 solver.cpp:253]     Train net output #0: loss = 1.00973 (* 1 = 1.00973 loss)
I0522 17:22:27.333937 31280 sgd_solver.cpp:106] Iteration 100875, lr = 0.0005
I0522 17:22:37.144011 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_101250.caffemodel
I0522 17:22:37.200830 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_101250.solverstate
I0522 17:22:37.233928 31280 solver.cpp:237] Iteration 101250, loss = 1.19782
I0522 17:22:37.233968 31280 solver.cpp:253]     Train net output #0: loss = 1.19782 (* 1 = 1.19782 loss)
I0522 17:22:37.233991 31280 sgd_solver.cpp:106] Iteration 101250, lr = 0.0005
I0522 17:22:47.071743 31280 solver.cpp:237] Iteration 101625, loss = 1.44273
I0522 17:22:47.071908 31280 solver.cpp:253]     Train net output #0: loss = 1.44273 (* 1 = 1.44273 loss)
I0522 17:22:47.071923 31280 sgd_solver.cpp:106] Iteration 101625, lr = 0.0005
I0522 17:22:56.907654 31280 solver.cpp:237] Iteration 102000, loss = 0.916409
I0522 17:22:56.907690 31280 solver.cpp:253]     Train net output #0: loss = 0.916409 (* 1 = 0.916409 loss)
I0522 17:22:56.907706 31280 sgd_solver.cpp:106] Iteration 102000, lr = 0.0005
I0522 17:23:06.748889 31280 solver.cpp:237] Iteration 102375, loss = 1.19652
I0522 17:23:06.748939 31280 solver.cpp:253]     Train net output #0: loss = 1.19652 (* 1 = 1.19652 loss)
I0522 17:23:06.748955 31280 sgd_solver.cpp:106] Iteration 102375, lr = 0.0005
I0522 17:23:37.458035 31280 solver.cpp:237] Iteration 102750, loss = 0.9472
I0522 17:23:37.458230 31280 solver.cpp:253]     Train net output #0: loss = 0.9472 (* 1 = 0.9472 loss)
I0522 17:23:37.458245 31280 sgd_solver.cpp:106] Iteration 102750, lr = 0.0005
I0522 17:23:47.305074 31280 solver.cpp:237] Iteration 103125, loss = 1.60261
I0522 17:23:47.305109 31280 solver.cpp:253]     Train net output #0: loss = 1.60261 (* 1 = 1.60261 loss)
I0522 17:23:47.305126 31280 sgd_solver.cpp:106] Iteration 103125, lr = 0.0005
I0522 17:23:57.156283 31280 solver.cpp:237] Iteration 103500, loss = 1.32032
I0522 17:23:57.156323 31280 solver.cpp:253]     Train net output #0: loss = 1.32032 (* 1 = 1.32032 loss)
I0522 17:23:57.156344 31280 sgd_solver.cpp:106] Iteration 103500, lr = 0.0005
I0522 17:24:07.003015 31280 solver.cpp:237] Iteration 103875, loss = 1.51493
I0522 17:24:07.003051 31280 solver.cpp:253]     Train net output #0: loss = 1.51493 (* 1 = 1.51493 loss)
I0522 17:24:07.003065 31280 sgd_solver.cpp:106] Iteration 103875, lr = 0.0005
I0522 17:24:16.848950 31280 solver.cpp:237] Iteration 104250, loss = 1.0033
I0522 17:24:16.849123 31280 solver.cpp:253]     Train net output #0: loss = 1.0033 (* 1 = 1.0033 loss)
I0522 17:24:16.849138 31280 sgd_solver.cpp:106] Iteration 104250, lr = 0.0005
I0522 17:24:26.697479 31280 solver.cpp:237] Iteration 104625, loss = 1.22081
I0522 17:24:26.697525 31280 solver.cpp:253]     Train net output #0: loss = 1.22081 (* 1 = 1.22081 loss)
I0522 17:24:26.697540 31280 sgd_solver.cpp:106] Iteration 104625, lr = 0.0005
I0522 17:24:36.520349 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_105000.caffemodel
I0522 17:24:36.576932 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_105000.solverstate
I0522 17:24:36.603260 31280 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 17:25:45.942891 31280 solver.cpp:409]     Test net output #0: accuracy = 0.86564
I0522 17:25:45.943071 31280 solver.cpp:409]     Test net output #1: loss = 0.424624 (* 1 = 0.424624 loss)
I0522 17:26:06.829326 31280 solver.cpp:237] Iteration 105000, loss = 1.29518
I0522 17:26:06.829378 31280 solver.cpp:253]     Train net output #0: loss = 1.29518 (* 1 = 1.29518 loss)
I0522 17:26:06.829393 31280 sgd_solver.cpp:106] Iteration 105000, lr = 0.0005
I0522 17:26:16.559881 31280 solver.cpp:237] Iteration 105375, loss = 1.25285
I0522 17:26:16.560057 31280 solver.cpp:253]     Train net output #0: loss = 1.25285 (* 1 = 1.25285 loss)
I0522 17:26:16.560071 31280 sgd_solver.cpp:106] Iteration 105375, lr = 0.0005
I0522 17:26:26.287268 31280 solver.cpp:237] Iteration 105750, loss = 1.12548
I0522 17:26:26.287317 31280 solver.cpp:253]     Train net output #0: loss = 1.12548 (* 1 = 1.12548 loss)
I0522 17:26:26.287330 31280 sgd_solver.cpp:106] Iteration 105750, lr = 0.0005
I0522 17:26:36.009600 31280 solver.cpp:237] Iteration 106125, loss = 1.12183
I0522 17:26:36.009636 31280 solver.cpp:253]     Train net output #0: loss = 1.12183 (* 1 = 1.12183 loss)
I0522 17:26:36.009654 31280 sgd_solver.cpp:106] Iteration 106125, lr = 0.0005
I0522 17:26:45.738554 31280 solver.cpp:237] Iteration 106500, loss = 1.24301
I0522 17:26:45.738589 31280 solver.cpp:253]     Train net output #0: loss = 1.24301 (* 1 = 1.24301 loss)
I0522 17:26:45.738606 31280 sgd_solver.cpp:106] Iteration 106500, lr = 0.0005
I0522 17:26:55.468034 31280 solver.cpp:237] Iteration 106875, loss = 1.01303
I0522 17:26:55.468222 31280 solver.cpp:253]     Train net output #0: loss = 1.01303 (* 1 = 1.01303 loss)
I0522 17:26:55.468237 31280 sgd_solver.cpp:106] Iteration 106875, lr = 0.0005
I0522 17:27:05.198101 31280 solver.cpp:237] Iteration 107250, loss = 1.11
I0522 17:27:05.198137 31280 solver.cpp:253]     Train net output #0: loss = 1.11 (* 1 = 1.11 loss)
I0522 17:27:05.198154 31280 sgd_solver.cpp:106] Iteration 107250, lr = 0.0005
I0522 17:27:35.786882 31280 solver.cpp:237] Iteration 107625, loss = 1.03757
I0522 17:27:35.787075 31280 solver.cpp:253]     Train net output #0: loss = 1.03757 (* 1 = 1.03757 loss)
I0522 17:27:35.787091 31280 sgd_solver.cpp:106] Iteration 107625, lr = 0.0005
I0522 17:27:45.516963 31280 solver.cpp:237] Iteration 108000, loss = 1.17786
I0522 17:27:45.517002 31280 solver.cpp:253]     Train net output #0: loss = 1.17786 (* 1 = 1.17786 loss)
I0522 17:27:45.517024 31280 sgd_solver.cpp:106] Iteration 108000, lr = 0.0005
I0522 17:27:55.248577 31280 solver.cpp:237] Iteration 108375, loss = 0.983332
I0522 17:27:55.248615 31280 solver.cpp:253]     Train net output #0: loss = 0.983332 (* 1 = 0.983332 loss)
I0522 17:27:55.248631 31280 sgd_solver.cpp:106] Iteration 108375, lr = 0.0005
I0522 17:28:04.954368 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_108750.caffemodel
I0522 17:28:05.012293 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_108750.solverstate
I0522 17:28:05.047746 31280 solver.cpp:237] Iteration 108750, loss = 1.04638
I0522 17:28:05.047797 31280 solver.cpp:253]     Train net output #0: loss = 1.04638 (* 1 = 1.04638 loss)
I0522 17:28:05.047811 31280 sgd_solver.cpp:106] Iteration 108750, lr = 0.0005
I0522 17:28:14.776893 31280 solver.cpp:237] Iteration 109125, loss = 1.26527
I0522 17:28:14.777061 31280 solver.cpp:253]     Train net output #0: loss = 1.26527 (* 1 = 1.26527 loss)
I0522 17:28:14.777076 31280 sgd_solver.cpp:106] Iteration 109125, lr = 0.0005
I0522 17:28:24.506518 31280 solver.cpp:237] Iteration 109500, loss = 1.4363
I0522 17:28:24.506552 31280 solver.cpp:253]     Train net output #0: loss = 1.4363 (* 1 = 1.4363 loss)
I0522 17:28:24.506569 31280 sgd_solver.cpp:106] Iteration 109500, lr = 0.0005
I0522 17:28:34.241261 31280 solver.cpp:237] Iteration 109875, loss = 1.07982
I0522 17:28:34.241307 31280 solver.cpp:253]     Train net output #0: loss = 1.07982 (* 1 = 1.07982 loss)
I0522 17:28:34.241325 31280 sgd_solver.cpp:106] Iteration 109875, lr = 0.0005
I0522 17:29:04.842934 31280 solver.cpp:237] Iteration 110250, loss = 1.11342
I0522 17:29:04.843180 31280 solver.cpp:253]     Train net output #0: loss = 1.11342 (* 1 = 1.11342 loss)
I0522 17:29:04.843196 31280 sgd_solver.cpp:106] Iteration 110250, lr = 0.0005
I0522 17:29:14.570029 31280 solver.cpp:237] Iteration 110625, loss = 1.17585
I0522 17:29:14.570063 31280 solver.cpp:253]     Train net output #0: loss = 1.17585 (* 1 = 1.17585 loss)
I0522 17:29:14.570080 31280 sgd_solver.cpp:106] Iteration 110625, lr = 0.0005
I0522 17:29:24.295994 31280 solver.cpp:237] Iteration 111000, loss = 1.31188
I0522 17:29:24.296038 31280 solver.cpp:253]     Train net output #0: loss = 1.31188 (* 1 = 1.31188 loss)
I0522 17:29:24.296054 31280 sgd_solver.cpp:106] Iteration 111000, lr = 0.0005
I0522 17:29:34.023700 31280 solver.cpp:237] Iteration 111375, loss = 1.13294
I0522 17:29:34.023736 31280 solver.cpp:253]     Train net output #0: loss = 1.13294 (* 1 = 1.13294 loss)
I0522 17:29:34.023751 31280 sgd_solver.cpp:106] Iteration 111375, lr = 0.0005
I0522 17:29:43.757313 31280 solver.cpp:237] Iteration 111750, loss = 1.18389
I0522 17:29:43.757493 31280 solver.cpp:253]     Train net output #0: loss = 1.18389 (* 1 = 1.18389 loss)
I0522 17:29:43.757506 31280 sgd_solver.cpp:106] Iteration 111750, lr = 0.0005
I0522 17:29:53.509356 31280 solver.cpp:237] Iteration 112125, loss = 1.4845
I0522 17:29:53.509390 31280 solver.cpp:253]     Train net output #0: loss = 1.4845 (* 1 = 1.4845 loss)
I0522 17:29:53.509405 31280 sgd_solver.cpp:106] Iteration 112125, lr = 0.0005
I0522 17:30:03.241690 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_112500.caffemodel
I0522 17:30:03.299479 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_112500.solverstate
I0522 17:30:03.326855 31280 solver.cpp:341] Iteration 112500, Testing net (#0)
I0522 17:30:51.501878 31280 solver.cpp:409]     Test net output #0: accuracy = 0.870014
I0522 17:30:51.502068 31280 solver.cpp:409]     Test net output #1: loss = 0.438136 (* 1 = 0.438136 loss)
I0522 17:31:12.382336 31280 solver.cpp:237] Iteration 112500, loss = 1.19933
I0522 17:31:12.382388 31280 solver.cpp:253]     Train net output #0: loss = 1.19933 (* 1 = 1.19933 loss)
I0522 17:31:12.382403 31280 sgd_solver.cpp:106] Iteration 112500, lr = 0.0005
I0522 17:31:22.200413 31280 solver.cpp:237] Iteration 112875, loss = 1.43831
I0522 17:31:22.200588 31280 solver.cpp:253]     Train net output #0: loss = 1.43831 (* 1 = 1.43831 loss)
I0522 17:31:22.200603 31280 sgd_solver.cpp:106] Iteration 112875, lr = 0.0005
I0522 17:31:32.013826 31280 solver.cpp:237] Iteration 113250, loss = 1.58182
I0522 17:31:32.013861 31280 solver.cpp:253]     Train net output #0: loss = 1.58182 (* 1 = 1.58182 loss)
I0522 17:31:32.013875 31280 sgd_solver.cpp:106] Iteration 113250, lr = 0.0005
I0522 17:31:41.829715 31280 solver.cpp:237] Iteration 113625, loss = 1.23087
I0522 17:31:41.829751 31280 solver.cpp:253]     Train net output #0: loss = 1.23087 (* 1 = 1.23087 loss)
I0522 17:31:41.829768 31280 sgd_solver.cpp:106] Iteration 113625, lr = 0.0005
I0522 17:31:51.642518 31280 solver.cpp:237] Iteration 114000, loss = 1.09306
I0522 17:31:51.642560 31280 solver.cpp:253]     Train net output #0: loss = 1.09306 (* 1 = 1.09306 loss)
I0522 17:31:51.642580 31280 sgd_solver.cpp:106] Iteration 114000, lr = 0.0005
I0522 17:32:01.450950 31280 solver.cpp:237] Iteration 114375, loss = 1.33073
I0522 17:32:01.451113 31280 solver.cpp:253]     Train net output #0: loss = 1.33073 (* 1 = 1.33073 loss)
I0522 17:32:01.451128 31280 sgd_solver.cpp:106] Iteration 114375, lr = 0.0005
I0522 17:32:11.264888 31280 solver.cpp:237] Iteration 114750, loss = 1.22688
I0522 17:32:11.264922 31280 solver.cpp:253]     Train net output #0: loss = 1.22688 (* 1 = 1.22688 loss)
I0522 17:32:11.264940 31280 sgd_solver.cpp:106] Iteration 114750, lr = 0.0005
I0522 17:32:41.963100 31280 solver.cpp:237] Iteration 115125, loss = 1.30289
I0522 17:32:41.963284 31280 solver.cpp:253]     Train net output #0: loss = 1.30289 (* 1 = 1.30289 loss)
I0522 17:32:41.963299 31280 sgd_solver.cpp:106] Iteration 115125, lr = 0.0005
I0522 17:32:51.774159 31280 solver.cpp:237] Iteration 115500, loss = 0.960225
I0522 17:32:51.774195 31280 solver.cpp:253]     Train net output #0: loss = 0.960225 (* 1 = 0.960225 loss)
I0522 17:32:51.774214 31280 sgd_solver.cpp:106] Iteration 115500, lr = 0.0005
I0522 17:33:01.593899 31280 solver.cpp:237] Iteration 115875, loss = 1.57797
I0522 17:33:01.593935 31280 solver.cpp:253]     Train net output #0: loss = 1.57797 (* 1 = 1.57797 loss)
I0522 17:33:01.593953 31280 sgd_solver.cpp:106] Iteration 115875, lr = 0.0005
I0522 17:33:11.379576 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_116250.caffemodel
I0522 17:33:11.436034 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_116250.solverstate
I0522 17:33:11.470281 31280 solver.cpp:237] Iteration 116250, loss = 0.956531
I0522 17:33:11.470327 31280 solver.cpp:253]     Train net output #0: loss = 0.956531 (* 1 = 0.956531 loss)
I0522 17:33:11.470342 31280 sgd_solver.cpp:106] Iteration 116250, lr = 0.0005
I0522 17:33:21.282783 31280 solver.cpp:237] Iteration 116625, loss = 1.3854
I0522 17:33:21.282949 31280 solver.cpp:253]     Train net output #0: loss = 1.3854 (* 1 = 1.3854 loss)
I0522 17:33:21.282963 31280 sgd_solver.cpp:106] Iteration 116625, lr = 0.0005
I0522 17:33:31.110136 31280 solver.cpp:237] Iteration 117000, loss = 1.34272
I0522 17:33:31.110183 31280 solver.cpp:253]     Train net output #0: loss = 1.34272 (* 1 = 1.34272 loss)
I0522 17:33:31.110198 31280 sgd_solver.cpp:106] Iteration 117000, lr = 0.0005
I0522 17:33:40.954656 31280 solver.cpp:237] Iteration 117375, loss = 1.01699
I0522 17:33:40.954694 31280 solver.cpp:253]     Train net output #0: loss = 1.01699 (* 1 = 1.01699 loss)
I0522 17:33:40.954708 31280 sgd_solver.cpp:106] Iteration 117375, lr = 0.0005
I0522 17:34:11.661679 31280 solver.cpp:237] Iteration 117750, loss = 1.20392
I0522 17:34:11.661875 31280 solver.cpp:253]     Train net output #0: loss = 1.20392 (* 1 = 1.20392 loss)
I0522 17:34:11.661890 31280 sgd_solver.cpp:106] Iteration 117750, lr = 0.0005
I0522 17:34:21.501467 31280 solver.cpp:237] Iteration 118125, loss = 1.15262
I0522 17:34:21.501523 31280 solver.cpp:253]     Train net output #0: loss = 1.15262 (* 1 = 1.15262 loss)
I0522 17:34:21.501538 31280 sgd_solver.cpp:106] Iteration 118125, lr = 0.0005
I0522 17:34:31.343982 31280 solver.cpp:237] Iteration 118500, loss = 1.24466
I0522 17:34:31.344017 31280 solver.cpp:253]     Train net output #0: loss = 1.24466 (* 1 = 1.24466 loss)
I0522 17:34:31.344034 31280 sgd_solver.cpp:106] Iteration 118500, lr = 0.0005
I0522 17:34:41.185580 31280 solver.cpp:237] Iteration 118875, loss = 0.982235
I0522 17:34:41.185616 31280 solver.cpp:253]     Train net output #0: loss = 0.982235 (* 1 = 0.982235 loss)
I0522 17:34:41.185632 31280 sgd_solver.cpp:106] Iteration 118875, lr = 0.0005
I0522 17:34:51.021937 31280 solver.cpp:237] Iteration 119250, loss = 1.43622
I0522 17:34:51.022107 31280 solver.cpp:253]     Train net output #0: loss = 1.43622 (* 1 = 1.43622 loss)
I0522 17:34:51.022121 31280 sgd_solver.cpp:106] Iteration 119250, lr = 0.0005
I0522 17:35:00.854660 31280 solver.cpp:237] Iteration 119625, loss = 1.18119
I0522 17:35:00.854696 31280 solver.cpp:253]     Train net output #0: loss = 1.18119 (* 1 = 1.18119 loss)
I0522 17:35:00.854714 31280 sgd_solver.cpp:106] Iteration 119625, lr = 0.0005
I0522 17:35:10.658295 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_120000.caffemodel
I0522 17:35:10.715569 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_120000.solverstate
I0522 17:35:10.741417 31280 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 17:36:20.086881 31280 solver.cpp:409]     Test net output #0: accuracy = 0.863253
I0522 17:36:20.087065 31280 solver.cpp:409]     Test net output #1: loss = 0.433873 (* 1 = 0.433873 loss)
I0522 17:36:40.984935 31280 solver.cpp:237] Iteration 120000, loss = 1.10801
I0522 17:36:40.984987 31280 solver.cpp:253]     Train net output #0: loss = 1.10801 (* 1 = 1.10801 loss)
I0522 17:36:40.985003 31280 sgd_solver.cpp:106] Iteration 120000, lr = 0.0005
I0522 17:36:50.687325 31280 solver.cpp:237] Iteration 120375, loss = 1.25306
I0522 17:36:50.687515 31280 solver.cpp:253]     Train net output #0: loss = 1.25306 (* 1 = 1.25306 loss)
I0522 17:36:50.687530 31280 sgd_solver.cpp:106] Iteration 120375, lr = 0.0005
I0522 17:37:00.392869 31280 solver.cpp:237] Iteration 120750, loss = 1.22789
I0522 17:37:00.392904 31280 solver.cpp:253]     Train net output #0: loss = 1.22789 (* 1 = 1.22789 loss)
I0522 17:37:00.392918 31280 sgd_solver.cpp:106] Iteration 120750, lr = 0.0005
I0522 17:37:10.092455 31280 solver.cpp:237] Iteration 121125, loss = 1.2116
I0522 17:37:10.092491 31280 solver.cpp:253]     Train net output #0: loss = 1.2116 (* 1 = 1.2116 loss)
I0522 17:37:10.092507 31280 sgd_solver.cpp:106] Iteration 121125, lr = 0.0005
I0522 17:37:19.794008 31280 solver.cpp:237] Iteration 121500, loss = 1.29024
I0522 17:37:19.794052 31280 solver.cpp:253]     Train net output #0: loss = 1.29024 (* 1 = 1.29024 loss)
I0522 17:37:19.794071 31280 sgd_solver.cpp:106] Iteration 121500, lr = 0.0005
I0522 17:37:29.501072 31280 solver.cpp:237] Iteration 121875, loss = 1.29497
I0522 17:37:29.501248 31280 solver.cpp:253]     Train net output #0: loss = 1.29497 (* 1 = 1.29497 loss)
I0522 17:37:29.501261 31280 sgd_solver.cpp:106] Iteration 121875, lr = 0.0005
I0522 17:37:39.197463 31280 solver.cpp:237] Iteration 122250, loss = 1.09338
I0522 17:37:39.197509 31280 solver.cpp:253]     Train net output #0: loss = 1.09338 (* 1 = 1.09338 loss)
I0522 17:37:39.197531 31280 sgd_solver.cpp:106] Iteration 122250, lr = 0.0005
I0522 17:38:09.785145 31280 solver.cpp:237] Iteration 122625, loss = 1.47625
I0522 17:38:09.785331 31280 solver.cpp:253]     Train net output #0: loss = 1.47625 (* 1 = 1.47625 loss)
I0522 17:38:09.785347 31280 sgd_solver.cpp:106] Iteration 122625, lr = 0.0005
I0522 17:38:19.495291 31280 solver.cpp:237] Iteration 123000, loss = 0.972588
I0522 17:38:19.495327 31280 solver.cpp:253]     Train net output #0: loss = 0.972588 (* 1 = 0.972588 loss)
I0522 17:38:19.495344 31280 sgd_solver.cpp:106] Iteration 123000, lr = 0.0005
I0522 17:38:29.194520 31280 solver.cpp:237] Iteration 123375, loss = 1.28056
I0522 17:38:29.194567 31280 solver.cpp:253]     Train net output #0: loss = 1.28056 (* 1 = 1.28056 loss)
I0522 17:38:29.194581 31280 sgd_solver.cpp:106] Iteration 123375, lr = 0.0005
I0522 17:38:38.869151 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_123750.caffemodel
I0522 17:38:38.925222 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_123750.solverstate
I0522 17:38:38.958807 31280 solver.cpp:237] Iteration 123750, loss = 1.21001
I0522 17:38:38.958853 31280 solver.cpp:253]     Train net output #0: loss = 1.21001 (* 1 = 1.21001 loss)
I0522 17:38:38.958866 31280 sgd_solver.cpp:106] Iteration 123750, lr = 0.0005
I0522 17:38:48.661043 31280 solver.cpp:237] Iteration 124125, loss = 1.03971
I0522 17:38:48.661212 31280 solver.cpp:253]     Train net output #0: loss = 1.03971 (* 1 = 1.03971 loss)
I0522 17:38:48.661226 31280 sgd_solver.cpp:106] Iteration 124125, lr = 0.0005
I0522 17:38:58.367424 31280 solver.cpp:237] Iteration 124500, loss = 1.21694
I0522 17:38:58.367470 31280 solver.cpp:253]     Train net output #0: loss = 1.21694 (* 1 = 1.21694 loss)
I0522 17:38:58.367487 31280 sgd_solver.cpp:106] Iteration 124500, lr = 0.0005
I0522 17:39:08.067984 31280 solver.cpp:237] Iteration 124875, loss = 1.31927
I0522 17:39:08.068019 31280 solver.cpp:253]     Train net output #0: loss = 1.31927 (* 1 = 1.31927 loss)
I0522 17:39:08.068037 31280 sgd_solver.cpp:106] Iteration 124875, lr = 0.0005
I0522 17:39:38.622475 31280 solver.cpp:237] Iteration 125250, loss = 1.34141
I0522 17:39:38.622663 31280 solver.cpp:253]     Train net output #0: loss = 1.34141 (* 1 = 1.34141 loss)
I0522 17:39:38.622678 31280 sgd_solver.cpp:106] Iteration 125250, lr = 0.0005
I0522 17:39:48.323231 31280 solver.cpp:237] Iteration 125625, loss = 1.3238
I0522 17:39:48.323276 31280 solver.cpp:253]     Train net output #0: loss = 1.3238 (* 1 = 1.3238 loss)
I0522 17:39:48.323292 31280 sgd_solver.cpp:106] Iteration 125625, lr = 0.0005
I0522 17:39:58.025655 31280 solver.cpp:237] Iteration 126000, loss = 1.49772
I0522 17:39:58.025689 31280 solver.cpp:253]     Train net output #0: loss = 1.49772 (* 1 = 1.49772 loss)
I0522 17:39:58.025707 31280 sgd_solver.cpp:106] Iteration 126000, lr = 0.0005
I0522 17:40:07.730808 31280 solver.cpp:237] Iteration 126375, loss = 0.888685
I0522 17:40:07.730847 31280 solver.cpp:253]     Train net output #0: loss = 0.888685 (* 1 = 0.888685 loss)
I0522 17:40:07.730865 31280 sgd_solver.cpp:106] Iteration 126375, lr = 0.0005
I0522 17:40:17.429425 31280 solver.cpp:237] Iteration 126750, loss = 1.07756
I0522 17:40:17.429605 31280 solver.cpp:253]     Train net output #0: loss = 1.07756 (* 1 = 1.07756 loss)
I0522 17:40:17.429618 31280 sgd_solver.cpp:106] Iteration 126750, lr = 0.0005
I0522 17:40:27.127581 31280 solver.cpp:237] Iteration 127125, loss = 0.996119
I0522 17:40:27.127617 31280 solver.cpp:253]     Train net output #0: loss = 0.996119 (* 1 = 0.996119 loss)
I0522 17:40:27.127634 31280 sgd_solver.cpp:106] Iteration 127125, lr = 0.0005
I0522 17:40:36.810570 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_127500.caffemodel
I0522 17:40:36.866448 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_127500.solverstate
I0522 17:40:36.891749 31280 solver.cpp:341] Iteration 127500, Testing net (#0)
I0522 17:41:25.438953 31280 solver.cpp:409]     Test net output #0: accuracy = 0.872374
I0522 17:41:25.439157 31280 solver.cpp:409]     Test net output #1: loss = 0.408749 (* 1 = 0.408749 loss)
I0522 17:41:46.300278 31280 solver.cpp:237] Iteration 127500, loss = 1.19192
I0522 17:41:46.300333 31280 solver.cpp:253]     Train net output #0: loss = 1.19192 (* 1 = 1.19192 loss)
I0522 17:41:46.300348 31280 sgd_solver.cpp:106] Iteration 127500, lr = 0.0005
I0522 17:41:56.244842 31280 solver.cpp:237] Iteration 127875, loss = 0.939001
I0522 17:41:56.245021 31280 solver.cpp:253]     Train net output #0: loss = 0.939001 (* 1 = 0.939001 loss)
I0522 17:41:56.245035 31280 sgd_solver.cpp:106] Iteration 127875, lr = 0.0005
I0522 17:42:06.191125 31280 solver.cpp:237] Iteration 128250, loss = 1.5242
I0522 17:42:06.191160 31280 solver.cpp:253]     Train net output #0: loss = 1.5242 (* 1 = 1.5242 loss)
I0522 17:42:06.191174 31280 sgd_solver.cpp:106] Iteration 128250, lr = 0.0005
I0522 17:42:16.143576 31280 solver.cpp:237] Iteration 128625, loss = 0.933549
I0522 17:42:16.143627 31280 solver.cpp:253]     Train net output #0: loss = 0.933549 (* 1 = 0.933549 loss)
I0522 17:42:16.143641 31280 sgd_solver.cpp:106] Iteration 128625, lr = 0.0005
I0522 17:42:26.090330 31280 solver.cpp:237] Iteration 129000, loss = 1.48407
I0522 17:42:26.090365 31280 solver.cpp:253]     Train net output #0: loss = 1.48407 (* 1 = 1.48407 loss)
I0522 17:42:26.090383 31280 sgd_solver.cpp:106] Iteration 129000, lr = 0.0005
I0522 17:42:36.040109 31280 solver.cpp:237] Iteration 129375, loss = 0.964736
I0522 17:42:36.040277 31280 solver.cpp:253]     Train net output #0: loss = 0.964736 (* 1 = 0.964736 loss)
I0522 17:42:36.040292 31280 sgd_solver.cpp:106] Iteration 129375, lr = 0.0005
I0522 17:42:45.987392 31280 solver.cpp:237] Iteration 129750, loss = 0.966126
I0522 17:42:45.987427 31280 solver.cpp:253]     Train net output #0: loss = 0.966126 (* 1 = 0.966126 loss)
I0522 17:42:45.987448 31280 sgd_solver.cpp:106] Iteration 129750, lr = 0.0005
I0522 17:43:16.785272 31280 solver.cpp:237] Iteration 130125, loss = 1.18932
I0522 17:43:16.785459 31280 solver.cpp:253]     Train net output #0: loss = 1.18932 (* 1 = 1.18932 loss)
I0522 17:43:16.785475 31280 sgd_solver.cpp:106] Iteration 130125, lr = 0.0005
I0522 17:43:26.732741 31280 solver.cpp:237] Iteration 130500, loss = 1.03844
I0522 17:43:26.732784 31280 solver.cpp:253]     Train net output #0: loss = 1.03844 (* 1 = 1.03844 loss)
I0522 17:43:26.732802 31280 sgd_solver.cpp:106] Iteration 130500, lr = 0.0005
I0522 17:43:36.683153 31280 solver.cpp:237] Iteration 130875, loss = 1.21297
I0522 17:43:36.683188 31280 solver.cpp:253]     Train net output #0: loss = 1.21297 (* 1 = 1.21297 loss)
I0522 17:43:36.683203 31280 sgd_solver.cpp:106] Iteration 130875, lr = 0.0005
I0522 17:43:46.597944 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_131250.caffemodel
I0522 17:43:46.656410 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_131250.solverstate
I0522 17:43:46.691895 31280 solver.cpp:237] Iteration 131250, loss = 1.15208
I0522 17:43:46.691946 31280 solver.cpp:253]     Train net output #0: loss = 1.15208 (* 1 = 1.15208 loss)
I0522 17:43:46.691962 31280 sgd_solver.cpp:106] Iteration 131250, lr = 0.0005
I0522 17:43:56.642338 31280 solver.cpp:237] Iteration 131625, loss = 1.32444
I0522 17:43:56.642531 31280 solver.cpp:253]     Train net output #0: loss = 1.32444 (* 1 = 1.32444 loss)
I0522 17:43:56.642545 31280 sgd_solver.cpp:106] Iteration 131625, lr = 0.0005
I0522 17:44:06.591342 31280 solver.cpp:237] Iteration 132000, loss = 1.14424
I0522 17:44:06.591377 31280 solver.cpp:253]     Train net output #0: loss = 1.14424 (* 1 = 1.14424 loss)
I0522 17:44:06.591394 31280 sgd_solver.cpp:106] Iteration 132000, lr = 0.0005
I0522 17:44:16.542145 31280 solver.cpp:237] Iteration 132375, loss = 1.32632
I0522 17:44:16.542179 31280 solver.cpp:253]     Train net output #0: loss = 1.32632 (* 1 = 1.32632 loss)
I0522 17:44:16.542196 31280 sgd_solver.cpp:106] Iteration 132375, lr = 0.0005
I0522 17:44:47.371943 31280 solver.cpp:237] Iteration 132750, loss = 1.35972
I0522 17:44:47.372143 31280 solver.cpp:253]     Train net output #0: loss = 1.35972 (* 1 = 1.35972 loss)
I0522 17:44:47.372159 31280 sgd_solver.cpp:106] Iteration 132750, lr = 0.0005
I0522 17:44:57.322557 31280 solver.cpp:237] Iteration 133125, loss = 1.05891
I0522 17:44:57.322592 31280 solver.cpp:253]     Train net output #0: loss = 1.05891 (* 1 = 1.05891 loss)
I0522 17:44:57.322608 31280 sgd_solver.cpp:106] Iteration 133125, lr = 0.0005
I0522 17:45:07.271771 31280 solver.cpp:237] Iteration 133500, loss = 1.12919
I0522 17:45:07.271821 31280 solver.cpp:253]     Train net output #0: loss = 1.12919 (* 1 = 1.12919 loss)
I0522 17:45:07.271836 31280 sgd_solver.cpp:106] Iteration 133500, lr = 0.0005
I0522 17:45:17.219230 31280 solver.cpp:237] Iteration 133875, loss = 1.55175
I0522 17:45:17.219265 31280 solver.cpp:253]     Train net output #0: loss = 1.55175 (* 1 = 1.55175 loss)
I0522 17:45:17.219281 31280 sgd_solver.cpp:106] Iteration 133875, lr = 0.0005
I0522 17:45:27.164289 31280 solver.cpp:237] Iteration 134250, loss = 1.49315
I0522 17:45:27.164458 31280 solver.cpp:253]     Train net output #0: loss = 1.49315 (* 1 = 1.49315 loss)
I0522 17:45:27.164472 31280 sgd_solver.cpp:106] Iteration 134250, lr = 0.0005
I0522 17:45:37.111738 31280 solver.cpp:237] Iteration 134625, loss = 1.08123
I0522 17:45:37.111786 31280 solver.cpp:253]     Train net output #0: loss = 1.08123 (* 1 = 1.08123 loss)
I0522 17:45:37.111800 31280 sgd_solver.cpp:106] Iteration 134625, lr = 0.0005
I0522 17:45:47.035936 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_135000.caffemodel
I0522 17:45:47.094825 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_135000.solverstate
I0522 17:45:47.125967 31280 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 17:46:56.540535 31280 solver.cpp:409]     Test net output #0: accuracy = 0.872586
I0522 17:46:56.540722 31280 solver.cpp:409]     Test net output #1: loss = 0.415171 (* 1 = 0.415171 loss)
I0522 17:47:17.435382 31280 solver.cpp:237] Iteration 135000, loss = 1.09819
I0522 17:47:17.435434 31280 solver.cpp:253]     Train net output #0: loss = 1.09819 (* 1 = 1.09819 loss)
I0522 17:47:17.435448 31280 sgd_solver.cpp:106] Iteration 135000, lr = 0.0005
I0522 17:47:27.163784 31280 solver.cpp:237] Iteration 135375, loss = 1.02976
I0522 17:47:27.163957 31280 solver.cpp:253]     Train net output #0: loss = 1.02976 (* 1 = 1.02976 loss)
I0522 17:47:27.163970 31280 sgd_solver.cpp:106] Iteration 135375, lr = 0.0005
I0522 17:47:36.891836 31280 solver.cpp:237] Iteration 135750, loss = 1.44552
I0522 17:47:36.891886 31280 solver.cpp:253]     Train net output #0: loss = 1.44552 (* 1 = 1.44552 loss)
I0522 17:47:36.891902 31280 sgd_solver.cpp:106] Iteration 135750, lr = 0.0005
I0522 17:47:46.613739 31280 solver.cpp:237] Iteration 136125, loss = 1.29349
I0522 17:47:46.613775 31280 solver.cpp:253]     Train net output #0: loss = 1.29349 (* 1 = 1.29349 loss)
I0522 17:47:46.613792 31280 sgd_solver.cpp:106] Iteration 136125, lr = 0.0005
I0522 17:47:56.340472 31280 solver.cpp:237] Iteration 136500, loss = 1.21186
I0522 17:47:56.340508 31280 solver.cpp:253]     Train net output #0: loss = 1.21186 (* 1 = 1.21186 loss)
I0522 17:47:56.340524 31280 sgd_solver.cpp:106] Iteration 136500, lr = 0.0005
I0522 17:48:06.069947 31280 solver.cpp:237] Iteration 136875, loss = 1.65182
I0522 17:48:06.070150 31280 solver.cpp:253]     Train net output #0: loss = 1.65182 (* 1 = 1.65182 loss)
I0522 17:48:06.070164 31280 sgd_solver.cpp:106] Iteration 136875, lr = 0.0005
I0522 17:48:15.799388 31280 solver.cpp:237] Iteration 137250, loss = 0.948162
I0522 17:48:15.799423 31280 solver.cpp:253]     Train net output #0: loss = 0.948162 (* 1 = 0.948162 loss)
I0522 17:48:15.799437 31280 sgd_solver.cpp:106] Iteration 137250, lr = 0.0005
I0522 17:48:46.414119 31280 solver.cpp:237] Iteration 137625, loss = 1.2784
I0522 17:48:46.414311 31280 solver.cpp:253]     Train net output #0: loss = 1.2784 (* 1 = 1.2784 loss)
I0522 17:48:46.414325 31280 sgd_solver.cpp:106] Iteration 137625, lr = 0.0005
I0522 17:48:56.142895 31280 solver.cpp:237] Iteration 138000, loss = 1.10625
I0522 17:48:56.142940 31280 solver.cpp:253]     Train net output #0: loss = 1.10625 (* 1 = 1.10625 loss)
I0522 17:48:56.142957 31280 sgd_solver.cpp:106] Iteration 138000, lr = 0.0005
I0522 17:49:05.873195 31280 solver.cpp:237] Iteration 138375, loss = 0.990022
I0522 17:49:05.873232 31280 solver.cpp:253]     Train net output #0: loss = 0.990022 (* 1 = 0.990022 loss)
I0522 17:49:05.873250 31280 sgd_solver.cpp:106] Iteration 138375, lr = 0.0005
I0522 17:49:15.575394 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_138750.caffemodel
I0522 17:49:15.631304 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_138750.solverstate
I0522 17:49:15.664916 31280 solver.cpp:237] Iteration 138750, loss = 1.1987
I0522 17:49:15.664960 31280 solver.cpp:253]     Train net output #0: loss = 1.1987 (* 1 = 1.1987 loss)
I0522 17:49:15.664978 31280 sgd_solver.cpp:106] Iteration 138750, lr = 0.0005
I0522 17:49:25.392719 31280 solver.cpp:237] Iteration 139125, loss = 1.26792
I0522 17:49:25.392904 31280 solver.cpp:253]     Train net output #0: loss = 1.26792 (* 1 = 1.26792 loss)
I0522 17:49:25.392920 31280 sgd_solver.cpp:106] Iteration 139125, lr = 0.0005
I0522 17:49:35.119207 31280 solver.cpp:237] Iteration 139500, loss = 1.14952
I0522 17:49:35.119242 31280 solver.cpp:253]     Train net output #0: loss = 1.14952 (* 1 = 1.14952 loss)
I0522 17:49:35.119261 31280 sgd_solver.cpp:106] Iteration 139500, lr = 0.0005
I0522 17:49:44.841383 31280 solver.cpp:237] Iteration 139875, loss = 1.4619
I0522 17:49:44.841433 31280 solver.cpp:253]     Train net output #0: loss = 1.4619 (* 1 = 1.4619 loss)
I0522 17:49:44.841447 31280 sgd_solver.cpp:106] Iteration 139875, lr = 0.0005
I0522 17:50:15.462872 31280 solver.cpp:237] Iteration 140250, loss = 1.289
I0522 17:50:15.463073 31280 solver.cpp:253]     Train net output #0: loss = 1.289 (* 1 = 1.289 loss)
I0522 17:50:15.463088 31280 sgd_solver.cpp:106] Iteration 140250, lr = 0.0005
I0522 17:50:25.186417 31280 solver.cpp:237] Iteration 140625, loss = 1.1046
I0522 17:50:25.186452 31280 solver.cpp:253]     Train net output #0: loss = 1.1046 (* 1 = 1.1046 loss)
I0522 17:50:25.186470 31280 sgd_solver.cpp:106] Iteration 140625, lr = 0.0005
I0522 17:50:34.913877 31280 solver.cpp:237] Iteration 141000, loss = 1.23094
I0522 17:50:34.913924 31280 solver.cpp:253]     Train net output #0: loss = 1.23094 (* 1 = 1.23094 loss)
I0522 17:50:34.913940 31280 sgd_solver.cpp:106] Iteration 141000, lr = 0.0005
I0522 17:50:44.640925 31280 solver.cpp:237] Iteration 141375, loss = 1.22663
I0522 17:50:44.640961 31280 solver.cpp:253]     Train net output #0: loss = 1.22663 (* 1 = 1.22663 loss)
I0522 17:50:44.640974 31280 sgd_solver.cpp:106] Iteration 141375, lr = 0.0005
I0522 17:50:54.366757 31280 solver.cpp:237] Iteration 141750, loss = 1.17145
I0522 17:50:54.366950 31280 solver.cpp:253]     Train net output #0: loss = 1.17145 (* 1 = 1.17145 loss)
I0522 17:50:54.366964 31280 sgd_solver.cpp:106] Iteration 141750, lr = 0.0005
I0522 17:51:04.097972 31280 solver.cpp:237] Iteration 142125, loss = 0.862174
I0522 17:51:04.098019 31280 solver.cpp:253]     Train net output #0: loss = 0.862174 (* 1 = 0.862174 loss)
I0522 17:51:04.098034 31280 sgd_solver.cpp:106] Iteration 142125, lr = 0.0005
I0522 17:51:13.801653 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_142500.caffemodel
I0522 17:51:13.857599 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_142500.solverstate
I0522 17:51:13.882632 31280 solver.cpp:341] Iteration 142500, Testing net (#0)
I0522 17:52:02.091284 31280 solver.cpp:409]     Test net output #0: accuracy = 0.87514
I0522 17:52:02.091473 31280 solver.cpp:409]     Test net output #1: loss = 0.400738 (* 1 = 0.400738 loss)
I0522 17:52:22.987932 31280 solver.cpp:237] Iteration 142500, loss = 1.34226
I0522 17:52:22.987987 31280 solver.cpp:253]     Train net output #0: loss = 1.34226 (* 1 = 1.34226 loss)
I0522 17:52:22.988001 31280 sgd_solver.cpp:106] Iteration 142500, lr = 0.0005
I0522 17:52:32.844460 31280 solver.cpp:237] Iteration 142875, loss = 1.17299
I0522 17:52:32.844645 31280 solver.cpp:253]     Train net output #0: loss = 1.17299 (* 1 = 1.17299 loss)
I0522 17:52:32.844658 31280 sgd_solver.cpp:106] Iteration 142875, lr = 0.0005
I0522 17:52:42.702870 31280 solver.cpp:237] Iteration 143250, loss = 1.1751
I0522 17:52:42.702919 31280 solver.cpp:253]     Train net output #0: loss = 1.1751 (* 1 = 1.1751 loss)
I0522 17:52:42.702936 31280 sgd_solver.cpp:106] Iteration 143250, lr = 0.0005
I0522 17:52:52.549635 31280 solver.cpp:237] Iteration 143625, loss = 1.29081
I0522 17:52:52.549670 31280 solver.cpp:253]     Train net output #0: loss = 1.29081 (* 1 = 1.29081 loss)
I0522 17:52:52.549688 31280 sgd_solver.cpp:106] Iteration 143625, lr = 0.0005
I0522 17:53:02.406088 31280 solver.cpp:237] Iteration 144000, loss = 1.10146
I0522 17:53:02.406136 31280 solver.cpp:253]     Train net output #0: loss = 1.10146 (* 1 = 1.10146 loss)
I0522 17:53:02.406152 31280 sgd_solver.cpp:106] Iteration 144000, lr = 0.0005
I0522 17:53:12.250788 31280 solver.cpp:237] Iteration 144375, loss = 1.00489
I0522 17:53:12.250969 31280 solver.cpp:253]     Train net output #0: loss = 1.00489 (* 1 = 1.00489 loss)
I0522 17:53:12.250983 31280 sgd_solver.cpp:106] Iteration 144375, lr = 0.0005
I0522 17:53:22.102088 31280 solver.cpp:237] Iteration 144750, loss = 1.3131
I0522 17:53:22.102123 31280 solver.cpp:253]     Train net output #0: loss = 1.3131 (* 1 = 1.3131 loss)
I0522 17:53:22.102139 31280 sgd_solver.cpp:106] Iteration 144750, lr = 0.0005
I0522 17:53:52.855756 31280 solver.cpp:237] Iteration 145125, loss = 0.992196
I0522 17:53:52.855947 31280 solver.cpp:253]     Train net output #0: loss = 0.992196 (* 1 = 0.992196 loss)
I0522 17:53:52.855962 31280 sgd_solver.cpp:106] Iteration 145125, lr = 0.0005
I0522 17:54:02.706229 31280 solver.cpp:237] Iteration 145500, loss = 1.03235
I0522 17:54:02.706264 31280 solver.cpp:253]     Train net output #0: loss = 1.03235 (* 1 = 1.03235 loss)
I0522 17:54:02.706279 31280 sgd_solver.cpp:106] Iteration 145500, lr = 0.0005
I0522 17:54:12.552359 31280 solver.cpp:237] Iteration 145875, loss = 0.871831
I0522 17:54:12.552395 31280 solver.cpp:253]     Train net output #0: loss = 0.871831 (* 1 = 0.871831 loss)
I0522 17:54:12.552412 31280 sgd_solver.cpp:106] Iteration 145875, lr = 0.0005
I0522 17:54:22.375999 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_146250.caffemodel
I0522 17:54:22.432832 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_146250.solverstate
I0522 17:54:22.466063 31280 solver.cpp:237] Iteration 146250, loss = 1.27576
I0522 17:54:22.466109 31280 solver.cpp:253]     Train net output #0: loss = 1.27576 (* 1 = 1.27576 loss)
I0522 17:54:22.466127 31280 sgd_solver.cpp:106] Iteration 146250, lr = 0.0005
I0522 17:54:32.310138 31280 solver.cpp:237] Iteration 146625, loss = 1.22859
I0522 17:54:32.310320 31280 solver.cpp:253]     Train net output #0: loss = 1.22859 (* 1 = 1.22859 loss)
I0522 17:54:32.310334 31280 sgd_solver.cpp:106] Iteration 146625, lr = 0.0005
I0522 17:54:42.163856 31280 solver.cpp:237] Iteration 147000, loss = 1.66858
I0522 17:54:42.163907 31280 solver.cpp:253]     Train net output #0: loss = 1.66858 (* 1 = 1.66858 loss)
I0522 17:54:42.163923 31280 sgd_solver.cpp:106] Iteration 147000, lr = 0.0005
I0522 17:54:52.016345 31280 solver.cpp:237] Iteration 147375, loss = 1.3788
I0522 17:54:52.016382 31280 solver.cpp:253]     Train net output #0: loss = 1.3788 (* 1 = 1.3788 loss)
I0522 17:54:52.016398 31280 sgd_solver.cpp:106] Iteration 147375, lr = 0.0005
I0522 17:55:22.781657 31280 solver.cpp:237] Iteration 147750, loss = 1.25901
I0522 17:55:22.781837 31280 solver.cpp:253]     Train net output #0: loss = 1.25901 (* 1 = 1.25901 loss)
I0522 17:55:22.781852 31280 sgd_solver.cpp:106] Iteration 147750, lr = 0.0005
I0522 17:55:32.630564 31280 solver.cpp:237] Iteration 148125, loss = 1.6972
I0522 17:55:32.630609 31280 solver.cpp:253]     Train net output #0: loss = 1.6972 (* 1 = 1.6972 loss)
I0522 17:55:32.630626 31280 sgd_solver.cpp:106] Iteration 148125, lr = 0.0005
I0522 17:55:42.480412 31280 solver.cpp:237] Iteration 148500, loss = 1.12944
I0522 17:55:42.480448 31280 solver.cpp:253]     Train net output #0: loss = 1.12944 (* 1 = 1.12944 loss)
I0522 17:55:42.480464 31280 sgd_solver.cpp:106] Iteration 148500, lr = 0.0005
I0522 17:55:52.323755 31280 solver.cpp:237] Iteration 148875, loss = 1.19891
I0522 17:55:52.323791 31280 solver.cpp:253]     Train net output #0: loss = 1.19891 (* 1 = 1.19891 loss)
I0522 17:55:52.323807 31280 sgd_solver.cpp:106] Iteration 148875, lr = 0.0005
I0522 17:56:02.172220 31280 solver.cpp:237] Iteration 149250, loss = 1.25358
I0522 17:56:02.172401 31280 solver.cpp:253]     Train net output #0: loss = 1.25358 (* 1 = 1.25358 loss)
I0522 17:56:02.172415 31280 sgd_solver.cpp:106] Iteration 149250, lr = 0.0005
I0522 17:56:12.023113 31280 solver.cpp:237] Iteration 149625, loss = 1.36187
I0522 17:56:12.023149 31280 solver.cpp:253]     Train net output #0: loss = 1.36187 (* 1 = 1.36187 loss)
I0522 17:56:12.023164 31280 sgd_solver.cpp:106] Iteration 149625, lr = 0.0005
I0522 17:56:21.843201 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_150000.caffemodel
I0522 17:56:21.902299 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_150000.solverstate
I0522 17:56:21.929558 31280 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 17:57:31.357336 31280 solver.cpp:409]     Test net output #0: accuracy = 0.877513
I0522 17:57:31.357533 31280 solver.cpp:409]     Test net output #1: loss = 0.413955 (* 1 = 0.413955 loss)
I0522 17:57:52.273336 31280 solver.cpp:237] Iteration 150000, loss = 0.900409
I0522 17:57:52.273391 31280 solver.cpp:253]     Train net output #0: loss = 0.900409 (* 1 = 0.900409 loss)
I0522 17:57:52.273404 31280 sgd_solver.cpp:106] Iteration 150000, lr = 0.0005
I0522 17:58:01.971421 31280 solver.cpp:237] Iteration 150375, loss = 1.02444
I0522 17:58:01.971606 31280 solver.cpp:253]     Train net output #0: loss = 1.02444 (* 1 = 1.02444 loss)
I0522 17:58:01.971621 31280 sgd_solver.cpp:106] Iteration 150375, lr = 0.0005
I0522 17:58:11.668193 31280 solver.cpp:237] Iteration 150750, loss = 1.36403
I0522 17:58:11.668231 31280 solver.cpp:253]     Train net output #0: loss = 1.36403 (* 1 = 1.36403 loss)
I0522 17:58:11.668246 31280 sgd_solver.cpp:106] Iteration 150750, lr = 0.0005
I0522 17:58:21.359411 31280 solver.cpp:237] Iteration 151125, loss = 1.08717
I0522 17:58:21.359447 31280 solver.cpp:253]     Train net output #0: loss = 1.08717 (* 1 = 1.08717 loss)
I0522 17:58:21.359462 31280 sgd_solver.cpp:106] Iteration 151125, lr = 0.0005
I0522 17:58:31.046788 31280 solver.cpp:237] Iteration 151500, loss = 0.943723
I0522 17:58:31.046833 31280 solver.cpp:253]     Train net output #0: loss = 0.943723 (* 1 = 0.943723 loss)
I0522 17:58:31.046849 31280 sgd_solver.cpp:106] Iteration 151500, lr = 0.0005
I0522 17:58:40.745540 31280 solver.cpp:237] Iteration 151875, loss = 1.27175
I0522 17:58:40.745710 31280 solver.cpp:253]     Train net output #0: loss = 1.27175 (* 1 = 1.27175 loss)
I0522 17:58:40.745724 31280 sgd_solver.cpp:106] Iteration 151875, lr = 0.0005
I0522 17:58:50.443431 31280 solver.cpp:237] Iteration 152250, loss = 1.16245
I0522 17:58:50.443467 31280 solver.cpp:253]     Train net output #0: loss = 1.16245 (* 1 = 1.16245 loss)
I0522 17:58:50.443483 31280 sgd_solver.cpp:106] Iteration 152250, lr = 0.0005
I0522 17:59:21.043635 31280 solver.cpp:237] Iteration 152625, loss = 1.30985
I0522 17:59:21.043829 31280 solver.cpp:253]     Train net output #0: loss = 1.30985 (* 1 = 1.30985 loss)
I0522 17:59:21.043845 31280 sgd_solver.cpp:106] Iteration 152625, lr = 0.0005
I0522 17:59:30.732998 31280 solver.cpp:237] Iteration 153000, loss = 1.11521
I0522 17:59:30.733033 31280 solver.cpp:253]     Train net output #0: loss = 1.11521 (* 1 = 1.11521 loss)
I0522 17:59:30.733052 31280 sgd_solver.cpp:106] Iteration 153000, lr = 0.0005
I0522 17:59:40.431792 31280 solver.cpp:237] Iteration 153375, loss = 1.27656
I0522 17:59:40.431828 31280 solver.cpp:253]     Train net output #0: loss = 1.27656 (* 1 = 1.27656 loss)
I0522 17:59:40.431844 31280 sgd_solver.cpp:106] Iteration 153375, lr = 0.0005
I0522 17:59:50.100646 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_153750.caffemodel
I0522 17:59:50.156815 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_153750.solverstate
I0522 17:59:50.190228 31280 solver.cpp:237] Iteration 153750, loss = 1.00024
I0522 17:59:50.190274 31280 solver.cpp:253]     Train net output #0: loss = 1.00024 (* 1 = 1.00024 loss)
I0522 17:59:50.190289 31280 sgd_solver.cpp:106] Iteration 153750, lr = 0.0005
I0522 17:59:59.890990 31280 solver.cpp:237] Iteration 154125, loss = 1.54323
I0522 17:59:59.891175 31280 solver.cpp:253]     Train net output #0: loss = 1.54323 (* 1 = 1.54323 loss)
I0522 17:59:59.891188 31280 sgd_solver.cpp:106] Iteration 154125, lr = 0.0005
I0522 18:00:09.584192 31280 solver.cpp:237] Iteration 154500, loss = 1.14729
I0522 18:00:09.584233 31280 solver.cpp:253]     Train net output #0: loss = 1.14729 (* 1 = 1.14729 loss)
I0522 18:00:09.584255 31280 sgd_solver.cpp:106] Iteration 154500, lr = 0.0005
I0522 18:00:19.285506 31280 solver.cpp:237] Iteration 154875, loss = 1.26763
I0522 18:00:19.285545 31280 solver.cpp:253]     Train net output #0: loss = 1.26763 (* 1 = 1.26763 loss)
I0522 18:00:19.285562 31280 sgd_solver.cpp:106] Iteration 154875, lr = 0.0005
I0522 18:00:49.877879 31280 solver.cpp:237] Iteration 155250, loss = 0.944187
I0522 18:00:49.878073 31280 solver.cpp:253]     Train net output #0: loss = 0.944187 (* 1 = 0.944187 loss)
I0522 18:00:49.878089 31280 sgd_solver.cpp:106] Iteration 155250, lr = 0.0005
I0522 18:00:59.570503 31280 solver.cpp:237] Iteration 155625, loss = 1.02133
I0522 18:00:59.570552 31280 solver.cpp:253]     Train net output #0: loss = 1.02133 (* 1 = 1.02133 loss)
I0522 18:00:59.570566 31280 sgd_solver.cpp:106] Iteration 155625, lr = 0.0005
I0522 18:01:09.276199 31280 solver.cpp:237] Iteration 156000, loss = 1.6137
I0522 18:01:09.276234 31280 solver.cpp:253]     Train net output #0: loss = 1.6137 (* 1 = 1.6137 loss)
I0522 18:01:09.276252 31280 sgd_solver.cpp:106] Iteration 156000, lr = 0.0005
I0522 18:01:18.973532 31280 solver.cpp:237] Iteration 156375, loss = 1.25934
I0522 18:01:18.973568 31280 solver.cpp:253]     Train net output #0: loss = 1.25934 (* 1 = 1.25934 loss)
I0522 18:01:18.973584 31280 sgd_solver.cpp:106] Iteration 156375, lr = 0.0005
I0522 18:01:28.671290 31280 solver.cpp:237] Iteration 156750, loss = 1.03622
I0522 18:01:28.671485 31280 solver.cpp:253]     Train net output #0: loss = 1.03622 (* 1 = 1.03622 loss)
I0522 18:01:28.671499 31280 sgd_solver.cpp:106] Iteration 156750, lr = 0.0005
I0522 18:01:38.363363 31280 solver.cpp:237] Iteration 157125, loss = 0.926781
I0522 18:01:38.363399 31280 solver.cpp:253]     Train net output #0: loss = 0.926781 (* 1 = 0.926781 loss)
I0522 18:01:38.363415 31280 sgd_solver.cpp:106] Iteration 157125, lr = 0.0005
I0522 18:01:48.036229 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_157500.caffemodel
I0522 18:01:48.092394 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_157500.solverstate
I0522 18:01:48.117977 31280 solver.cpp:341] Iteration 157500, Testing net (#0)
I0522 18:02:36.657089 31280 solver.cpp:409]     Test net output #0: accuracy = 0.878366
I0522 18:02:36.657281 31280 solver.cpp:409]     Test net output #1: loss = 0.399494 (* 1 = 0.399494 loss)
I0522 18:02:57.566634 31280 solver.cpp:237] Iteration 157500, loss = 1.3409
I0522 18:02:57.566687 31280 solver.cpp:253]     Train net output #0: loss = 1.3409 (* 1 = 1.3409 loss)
I0522 18:02:57.566704 31280 sgd_solver.cpp:106] Iteration 157500, lr = 0.0005
I0522 18:03:07.342545 31280 solver.cpp:237] Iteration 157875, loss = 1.33421
I0522 18:03:07.342732 31280 solver.cpp:253]     Train net output #0: loss = 1.33421 (* 1 = 1.33421 loss)
I0522 18:03:07.342746 31280 sgd_solver.cpp:106] Iteration 157875, lr = 0.0005
I0522 18:03:17.127015 31280 solver.cpp:237] Iteration 158250, loss = 1.14304
I0522 18:03:17.127050 31280 solver.cpp:253]     Train net output #0: loss = 1.14304 (* 1 = 1.14304 loss)
I0522 18:03:17.127068 31280 sgd_solver.cpp:106] Iteration 158250, lr = 0.0005
I0522 18:03:26.911722 31280 solver.cpp:237] Iteration 158625, loss = 1.26988
I0522 18:03:26.911766 31280 solver.cpp:253]     Train net output #0: loss = 1.26988 (* 1 = 1.26988 loss)
I0522 18:03:26.911778 31280 sgd_solver.cpp:106] Iteration 158625, lr = 0.0005
I0522 18:03:36.699666 31280 solver.cpp:237] Iteration 159000, loss = 1.35523
I0522 18:03:36.699697 31280 solver.cpp:253]     Train net output #0: loss = 1.35523 (* 1 = 1.35523 loss)
I0522 18:03:36.699709 31280 sgd_solver.cpp:106] Iteration 159000, lr = 0.0005
I0522 18:03:46.484783 31280 solver.cpp:237] Iteration 159375, loss = 1.29596
I0522 18:03:46.484956 31280 solver.cpp:253]     Train net output #0: loss = 1.29596 (* 1 = 1.29596 loss)
I0522 18:03:46.484971 31280 sgd_solver.cpp:106] Iteration 159375, lr = 0.0005
I0522 18:03:56.263515 31280 solver.cpp:237] Iteration 159750, loss = 1.03905
I0522 18:03:56.263553 31280 solver.cpp:253]     Train net output #0: loss = 1.03905 (* 1 = 1.03905 loss)
I0522 18:03:56.263571 31280 sgd_solver.cpp:106] Iteration 159750, lr = 0.0005
I0522 18:04:26.973621 31280 solver.cpp:237] Iteration 160125, loss = 1.32125
I0522 18:04:26.973817 31280 solver.cpp:253]     Train net output #0: loss = 1.32125 (* 1 = 1.32125 loss)
I0522 18:04:26.973834 31280 sgd_solver.cpp:106] Iteration 160125, lr = 0.0005
I0522 18:04:36.763303 31280 solver.cpp:237] Iteration 160500, loss = 1.08515
I0522 18:04:36.763339 31280 solver.cpp:253]     Train net output #0: loss = 1.08515 (* 1 = 1.08515 loss)
I0522 18:04:36.763356 31280 sgd_solver.cpp:106] Iteration 160500, lr = 0.0005
I0522 18:04:46.543249 31280 solver.cpp:237] Iteration 160875, loss = 1.24485
I0522 18:04:46.543294 31280 solver.cpp:253]     Train net output #0: loss = 1.24485 (* 1 = 1.24485 loss)
I0522 18:04:46.543310 31280 sgd_solver.cpp:106] Iteration 160875, lr = 0.0005
I0522 18:04:56.299093 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_161250.caffemodel
I0522 18:04:56.355319 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_161250.solverstate
I0522 18:04:56.388844 31280 solver.cpp:237] Iteration 161250, loss = 1.15509
I0522 18:04:56.388890 31280 solver.cpp:253]     Train net output #0: loss = 1.15509 (* 1 = 1.15509 loss)
I0522 18:04:56.388902 31280 sgd_solver.cpp:106] Iteration 161250, lr = 0.0005
I0522 18:05:06.170605 31280 solver.cpp:237] Iteration 161625, loss = 1.05479
I0522 18:05:06.170792 31280 solver.cpp:253]     Train net output #0: loss = 1.05479 (* 1 = 1.05479 loss)
I0522 18:05:06.170806 31280 sgd_solver.cpp:106] Iteration 161625, lr = 0.0005
I0522 18:05:15.967023 31280 solver.cpp:237] Iteration 162000, loss = 1.23581
I0522 18:05:15.967073 31280 solver.cpp:253]     Train net output #0: loss = 1.23581 (* 1 = 1.23581 loss)
I0522 18:05:15.967087 31280 sgd_solver.cpp:106] Iteration 162000, lr = 0.0005
I0522 18:05:25.760931 31280 solver.cpp:237] Iteration 162375, loss = 1.33266
I0522 18:05:25.760967 31280 solver.cpp:253]     Train net output #0: loss = 1.33266 (* 1 = 1.33266 loss)
I0522 18:05:25.760985 31280 sgd_solver.cpp:106] Iteration 162375, lr = 0.0005
I0522 18:05:56.464826 31280 solver.cpp:237] Iteration 162750, loss = 1.25837
I0522 18:05:56.465025 31280 solver.cpp:253]     Train net output #0: loss = 1.25837 (* 1 = 1.25837 loss)
I0522 18:05:56.465039 31280 sgd_solver.cpp:106] Iteration 162750, lr = 0.0005
I0522 18:06:06.264024 31280 solver.cpp:237] Iteration 163125, loss = 1.20903
I0522 18:06:06.264068 31280 solver.cpp:253]     Train net output #0: loss = 1.20903 (* 1 = 1.20903 loss)
I0522 18:06:06.264086 31280 sgd_solver.cpp:106] Iteration 163125, lr = 0.0005
I0522 18:06:16.065461 31280 solver.cpp:237] Iteration 163500, loss = 1.07782
I0522 18:06:16.065495 31280 solver.cpp:253]     Train net output #0: loss = 1.07782 (* 1 = 1.07782 loss)
I0522 18:06:16.065520 31280 sgd_solver.cpp:106] Iteration 163500, lr = 0.0005
I0522 18:06:25.867156 31280 solver.cpp:237] Iteration 163875, loss = 1.03777
I0522 18:06:25.867194 31280 solver.cpp:253]     Train net output #0: loss = 1.03777 (* 1 = 1.03777 loss)
I0522 18:06:25.867215 31280 sgd_solver.cpp:106] Iteration 163875, lr = 0.0005
I0522 18:06:35.666620 31280 solver.cpp:237] Iteration 164250, loss = 1.15315
I0522 18:06:35.666793 31280 solver.cpp:253]     Train net output #0: loss = 1.15315 (* 1 = 1.15315 loss)
I0522 18:06:35.666807 31280 sgd_solver.cpp:106] Iteration 164250, lr = 0.0005
I0522 18:06:45.462138 31280 solver.cpp:237] Iteration 164625, loss = 1.2153
I0522 18:06:45.462173 31280 solver.cpp:253]     Train net output #0: loss = 1.2153 (* 1 = 1.2153 loss)
I0522 18:06:45.462190 31280 sgd_solver.cpp:106] Iteration 164625, lr = 0.0005
I0522 18:06:55.228351 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_165000.caffemodel
I0522 18:06:55.284870 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_165000.solverstate
I0522 18:06:55.310830 31280 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 18:08:04.809525 31280 solver.cpp:409]     Test net output #0: accuracy = 0.879426
I0522 18:08:04.809728 31280 solver.cpp:409]     Test net output #1: loss = 0.410114 (* 1 = 0.410114 loss)
I0522 18:08:25.732092 31280 solver.cpp:237] Iteration 165000, loss = 1.31506
I0522 18:08:25.732147 31280 solver.cpp:253]     Train net output #0: loss = 1.31506 (* 1 = 1.31506 loss)
I0522 18:08:25.732162 31280 sgd_solver.cpp:106] Iteration 165000, lr = 0.0005
I0522 18:08:35.411121 31280 solver.cpp:237] Iteration 165375, loss = 1.11574
I0522 18:08:35.411317 31280 solver.cpp:253]     Train net output #0: loss = 1.11574 (* 1 = 1.11574 loss)
I0522 18:08:35.411331 31280 sgd_solver.cpp:106] Iteration 165375, lr = 0.0005
I0522 18:08:45.092227 31280 solver.cpp:237] Iteration 165750, loss = 1.54385
I0522 18:08:45.092262 31280 solver.cpp:253]     Train net output #0: loss = 1.54385 (* 1 = 1.54385 loss)
I0522 18:08:45.092279 31280 sgd_solver.cpp:106] Iteration 165750, lr = 0.0005
I0522 18:08:54.766289 31280 solver.cpp:237] Iteration 166125, loss = 1.02091
I0522 18:08:54.766335 31280 solver.cpp:253]     Train net output #0: loss = 1.02091 (* 1 = 1.02091 loss)
I0522 18:08:54.766353 31280 sgd_solver.cpp:106] Iteration 166125, lr = 0.0005
I0522 18:09:04.442430 31280 solver.cpp:237] Iteration 166500, loss = 1.23209
I0522 18:09:04.442466 31280 solver.cpp:253]     Train net output #0: loss = 1.23209 (* 1 = 1.23209 loss)
I0522 18:09:04.442481 31280 sgd_solver.cpp:106] Iteration 166500, lr = 0.0005
I0522 18:09:14.121570 31280 solver.cpp:237] Iteration 166875, loss = 1.30103
I0522 18:09:14.121747 31280 solver.cpp:253]     Train net output #0: loss = 1.30103 (* 1 = 1.30103 loss)
I0522 18:09:14.121760 31280 sgd_solver.cpp:106] Iteration 166875, lr = 0.0005
I0522 18:09:23.830044 31280 solver.cpp:237] Iteration 167250, loss = 1.09229
I0522 18:09:23.830092 31280 solver.cpp:253]     Train net output #0: loss = 1.09229 (* 1 = 1.09229 loss)
I0522 18:09:23.830109 31280 sgd_solver.cpp:106] Iteration 167250, lr = 0.0005
I0522 18:09:54.431956 31280 solver.cpp:237] Iteration 167625, loss = 1.02725
I0522 18:09:54.432152 31280 solver.cpp:253]     Train net output #0: loss = 1.02725 (* 1 = 1.02725 loss)
I0522 18:09:54.432168 31280 sgd_solver.cpp:106] Iteration 167625, lr = 0.0005
I0522 18:10:04.141463 31280 solver.cpp:237] Iteration 168000, loss = 1.06575
I0522 18:10:04.141499 31280 solver.cpp:253]     Train net output #0: loss = 1.06575 (* 1 = 1.06575 loss)
I0522 18:10:04.141522 31280 sgd_solver.cpp:106] Iteration 168000, lr = 0.0005
I0522 18:10:13.851663 31280 solver.cpp:237] Iteration 168375, loss = 0.938107
I0522 18:10:13.851711 31280 solver.cpp:253]     Train net output #0: loss = 0.938107 (* 1 = 0.938107 loss)
I0522 18:10:13.851727 31280 sgd_solver.cpp:106] Iteration 168375, lr = 0.0005
I0522 18:10:23.537384 31280 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_168750.caffemodel
I0522 18:10:23.595273 31280 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_168750.solverstate
I0522 18:10:23.631132 31280 solver.cpp:237] Iteration 168750, loss = 1.01536
I0522 18:10:23.631186 31280 solver.cpp:253]     Train net output #0: loss = 1.01536 (* 1 = 1.01536 loss)
I0522 18:10:23.631201 31280 sgd_solver.cpp:106] Iteration 168750, lr = 0.0005
I0522 18:10:33.345729 31280 solver.cpp:237] Iteration 169125, loss = 1.29578
I0522 18:10:33.345921 31280 solver.cpp:253]     Train net output #0: loss = 1.29578 (* 1 = 1.29578 loss)
I0522 18:10:33.345935 31280 sgd_solver.cpp:106] Iteration 169125, lr = 0.0005
aprun: Apid 11249164: Caught signal Terminated, sending to application
*** Aborted at 1463955037 (unix time) try "date -d @1463955037" if you are using GNU date ***
=>> PBS: job killed: walltime 7242 exceeded limit 7200
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x7a2d) received by PID 31280 (TID 0x2aaac746f900) from PID 31277; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11249164: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11249164: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11249164: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11249164: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
aprun: Apid 11249164: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 00787] [c2-1c1s6n3] [Sun May 22 18:10:39 2016] PE RANK 0 exit signal Terminated
Application 11249164 exit codes: 143
Application 11249164 resources: utime ~6274s, stime ~959s, Rss ~5330336, inblocks ~15410626, outblocks ~696236
