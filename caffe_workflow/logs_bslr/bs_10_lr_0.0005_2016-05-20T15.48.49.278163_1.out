2806487
I0521 11:37:54.460253 20157 caffe.cpp:184] Using GPUs 0
I0521 11:37:54.883900 20157 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0005
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163.prototxt"
I0521 11:37:54.885629 20157 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163.prototxt
I0521 11:37:54.903070 20157 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 11:37:54.903129 20157 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 11:37:54.903478 20157 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 11:37:54.903661 20157 layer_factory.hpp:77] Creating layer data_hdf5
I0521 11:37:54.903686 20157 net.cpp:106] Creating Layer data_hdf5
I0521 11:37:54.903700 20157 net.cpp:411] data_hdf5 -> data
I0521 11:37:54.903733 20157 net.cpp:411] data_hdf5 -> label
I0521 11:37:54.903766 20157 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 11:37:54.905098 20157 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 11:37:54.907354 20157 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 11:38:16.470098 20157 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 11:38:16.475314 20157 net.cpp:150] Setting up data_hdf5
I0521 11:38:16.475354 20157 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 11:38:16.475368 20157 net.cpp:157] Top shape: 10 (10)
I0521 11:38:16.475381 20157 net.cpp:165] Memory required for data: 254040
I0521 11:38:16.475394 20157 layer_factory.hpp:77] Creating layer conv1
I0521 11:38:16.475430 20157 net.cpp:106] Creating Layer conv1
I0521 11:38:16.475440 20157 net.cpp:454] conv1 <- data
I0521 11:38:16.475462 20157 net.cpp:411] conv1 -> conv1
I0521 11:38:16.841440 20157 net.cpp:150] Setting up conv1
I0521 11:38:16.841486 20157 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 11:38:16.841497 20157 net.cpp:165] Memory required for data: 3018840
I0521 11:38:16.841528 20157 layer_factory.hpp:77] Creating layer relu1
I0521 11:38:16.841548 20157 net.cpp:106] Creating Layer relu1
I0521 11:38:16.841560 20157 net.cpp:454] relu1 <- conv1
I0521 11:38:16.841573 20157 net.cpp:397] relu1 -> conv1 (in-place)
I0521 11:38:16.842097 20157 net.cpp:150] Setting up relu1
I0521 11:38:16.842114 20157 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 11:38:16.842125 20157 net.cpp:165] Memory required for data: 5783640
I0521 11:38:16.842135 20157 layer_factory.hpp:77] Creating layer pool1
I0521 11:38:16.842152 20157 net.cpp:106] Creating Layer pool1
I0521 11:38:16.842162 20157 net.cpp:454] pool1 <- conv1
I0521 11:38:16.842176 20157 net.cpp:411] pool1 -> pool1
I0521 11:38:16.842255 20157 net.cpp:150] Setting up pool1
I0521 11:38:16.842268 20157 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 11:38:16.842278 20157 net.cpp:165] Memory required for data: 7166040
I0521 11:38:16.842286 20157 layer_factory.hpp:77] Creating layer conv2
I0521 11:38:16.842308 20157 net.cpp:106] Creating Layer conv2
I0521 11:38:16.842319 20157 net.cpp:454] conv2 <- pool1
I0521 11:38:16.842331 20157 net.cpp:411] conv2 -> conv2
I0521 11:38:16.845021 20157 net.cpp:150] Setting up conv2
I0521 11:38:16.845047 20157 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 11:38:16.845058 20157 net.cpp:165] Memory required for data: 9153240
I0521 11:38:16.845077 20157 layer_factory.hpp:77] Creating layer relu2
I0521 11:38:16.845093 20157 net.cpp:106] Creating Layer relu2
I0521 11:38:16.845103 20157 net.cpp:454] relu2 <- conv2
I0521 11:38:16.845115 20157 net.cpp:397] relu2 -> conv2 (in-place)
I0521 11:38:16.845448 20157 net.cpp:150] Setting up relu2
I0521 11:38:16.845463 20157 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 11:38:16.845473 20157 net.cpp:165] Memory required for data: 11140440
I0521 11:38:16.845482 20157 layer_factory.hpp:77] Creating layer pool2
I0521 11:38:16.845495 20157 net.cpp:106] Creating Layer pool2
I0521 11:38:16.845505 20157 net.cpp:454] pool2 <- conv2
I0521 11:38:16.845518 20157 net.cpp:411] pool2 -> pool2
I0521 11:38:16.845598 20157 net.cpp:150] Setting up pool2
I0521 11:38:16.845612 20157 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 11:38:16.845621 20157 net.cpp:165] Memory required for data: 12134040
I0521 11:38:16.845628 20157 layer_factory.hpp:77] Creating layer conv3
I0521 11:38:16.845648 20157 net.cpp:106] Creating Layer conv3
I0521 11:38:16.845657 20157 net.cpp:454] conv3 <- pool2
I0521 11:38:16.845670 20157 net.cpp:411] conv3 -> conv3
I0521 11:38:16.847769 20157 net.cpp:150] Setting up conv3
I0521 11:38:16.847792 20157 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 11:38:16.847805 20157 net.cpp:165] Memory required for data: 13218200
I0521 11:38:16.847834 20157 layer_factory.hpp:77] Creating layer relu3
I0521 11:38:16.847851 20157 net.cpp:106] Creating Layer relu3
I0521 11:38:16.847861 20157 net.cpp:454] relu3 <- conv3
I0521 11:38:16.847874 20157 net.cpp:397] relu3 -> conv3 (in-place)
I0521 11:38:16.848340 20157 net.cpp:150] Setting up relu3
I0521 11:38:16.848359 20157 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 11:38:16.848371 20157 net.cpp:165] Memory required for data: 14302360
I0521 11:38:16.848381 20157 layer_factory.hpp:77] Creating layer pool3
I0521 11:38:16.848393 20157 net.cpp:106] Creating Layer pool3
I0521 11:38:16.848402 20157 net.cpp:454] pool3 <- conv3
I0521 11:38:16.848415 20157 net.cpp:411] pool3 -> pool3
I0521 11:38:16.848484 20157 net.cpp:150] Setting up pool3
I0521 11:38:16.848496 20157 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 11:38:16.848506 20157 net.cpp:165] Memory required for data: 14844440
I0521 11:38:16.848515 20157 layer_factory.hpp:77] Creating layer conv4
I0521 11:38:16.848532 20157 net.cpp:106] Creating Layer conv4
I0521 11:38:16.848542 20157 net.cpp:454] conv4 <- pool3
I0521 11:38:16.848556 20157 net.cpp:411] conv4 -> conv4
I0521 11:38:16.851261 20157 net.cpp:150] Setting up conv4
I0521 11:38:16.851289 20157 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 11:38:16.851300 20157 net.cpp:165] Memory required for data: 15207320
I0521 11:38:16.851315 20157 layer_factory.hpp:77] Creating layer relu4
I0521 11:38:16.851330 20157 net.cpp:106] Creating Layer relu4
I0521 11:38:16.851339 20157 net.cpp:454] relu4 <- conv4
I0521 11:38:16.851351 20157 net.cpp:397] relu4 -> conv4 (in-place)
I0521 11:38:16.851826 20157 net.cpp:150] Setting up relu4
I0521 11:38:16.851842 20157 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 11:38:16.851853 20157 net.cpp:165] Memory required for data: 15570200
I0521 11:38:16.851863 20157 layer_factory.hpp:77] Creating layer pool4
I0521 11:38:16.851876 20157 net.cpp:106] Creating Layer pool4
I0521 11:38:16.851886 20157 net.cpp:454] pool4 <- conv4
I0521 11:38:16.851899 20157 net.cpp:411] pool4 -> pool4
I0521 11:38:16.851968 20157 net.cpp:150] Setting up pool4
I0521 11:38:16.851981 20157 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 11:38:16.851991 20157 net.cpp:165] Memory required for data: 15751640
I0521 11:38:16.852001 20157 layer_factory.hpp:77] Creating layer ip1
I0521 11:38:16.852021 20157 net.cpp:106] Creating Layer ip1
I0521 11:38:16.852031 20157 net.cpp:454] ip1 <- pool4
I0521 11:38:16.852044 20157 net.cpp:411] ip1 -> ip1
I0521 11:38:16.867498 20157 net.cpp:150] Setting up ip1
I0521 11:38:16.867527 20157 net.cpp:157] Top shape: 10 196 (1960)
I0521 11:38:16.867539 20157 net.cpp:165] Memory required for data: 15759480
I0521 11:38:16.867560 20157 layer_factory.hpp:77] Creating layer relu5
I0521 11:38:16.867575 20157 net.cpp:106] Creating Layer relu5
I0521 11:38:16.867585 20157 net.cpp:454] relu5 <- ip1
I0521 11:38:16.867599 20157 net.cpp:397] relu5 -> ip1 (in-place)
I0521 11:38:16.867947 20157 net.cpp:150] Setting up relu5
I0521 11:38:16.867961 20157 net.cpp:157] Top shape: 10 196 (1960)
I0521 11:38:16.867971 20157 net.cpp:165] Memory required for data: 15767320
I0521 11:38:16.867981 20157 layer_factory.hpp:77] Creating layer drop1
I0521 11:38:16.868003 20157 net.cpp:106] Creating Layer drop1
I0521 11:38:16.868013 20157 net.cpp:454] drop1 <- ip1
I0521 11:38:16.868026 20157 net.cpp:397] drop1 -> ip1 (in-place)
I0521 11:38:16.868084 20157 net.cpp:150] Setting up drop1
I0521 11:38:16.868098 20157 net.cpp:157] Top shape: 10 196 (1960)
I0521 11:38:16.868108 20157 net.cpp:165] Memory required for data: 15775160
I0521 11:38:16.868119 20157 layer_factory.hpp:77] Creating layer ip2
I0521 11:38:16.868136 20157 net.cpp:106] Creating Layer ip2
I0521 11:38:16.868146 20157 net.cpp:454] ip2 <- ip1
I0521 11:38:16.868160 20157 net.cpp:411] ip2 -> ip2
I0521 11:38:16.868624 20157 net.cpp:150] Setting up ip2
I0521 11:38:16.868638 20157 net.cpp:157] Top shape: 10 98 (980)
I0521 11:38:16.868648 20157 net.cpp:165] Memory required for data: 15779080
I0521 11:38:16.868662 20157 layer_factory.hpp:77] Creating layer relu6
I0521 11:38:16.868675 20157 net.cpp:106] Creating Layer relu6
I0521 11:38:16.868685 20157 net.cpp:454] relu6 <- ip2
I0521 11:38:16.868697 20157 net.cpp:397] relu6 -> ip2 (in-place)
I0521 11:38:16.869254 20157 net.cpp:150] Setting up relu6
I0521 11:38:16.869277 20157 net.cpp:157] Top shape: 10 98 (980)
I0521 11:38:16.869285 20157 net.cpp:165] Memory required for data: 15783000
I0521 11:38:16.869297 20157 layer_factory.hpp:77] Creating layer drop2
I0521 11:38:16.869309 20157 net.cpp:106] Creating Layer drop2
I0521 11:38:16.869318 20157 net.cpp:454] drop2 <- ip2
I0521 11:38:16.869331 20157 net.cpp:397] drop2 -> ip2 (in-place)
I0521 11:38:16.869374 20157 net.cpp:150] Setting up drop2
I0521 11:38:16.869387 20157 net.cpp:157] Top shape: 10 98 (980)
I0521 11:38:16.869397 20157 net.cpp:165] Memory required for data: 15786920
I0521 11:38:16.869408 20157 layer_factory.hpp:77] Creating layer ip3
I0521 11:38:16.869421 20157 net.cpp:106] Creating Layer ip3
I0521 11:38:16.869431 20157 net.cpp:454] ip3 <- ip2
I0521 11:38:16.869443 20157 net.cpp:411] ip3 -> ip3
I0521 11:38:16.869652 20157 net.cpp:150] Setting up ip3
I0521 11:38:16.869665 20157 net.cpp:157] Top shape: 10 11 (110)
I0521 11:38:16.869675 20157 net.cpp:165] Memory required for data: 15787360
I0521 11:38:16.869690 20157 layer_factory.hpp:77] Creating layer drop3
I0521 11:38:16.869704 20157 net.cpp:106] Creating Layer drop3
I0521 11:38:16.869714 20157 net.cpp:454] drop3 <- ip3
I0521 11:38:16.869725 20157 net.cpp:397] drop3 -> ip3 (in-place)
I0521 11:38:16.869765 20157 net.cpp:150] Setting up drop3
I0521 11:38:16.869777 20157 net.cpp:157] Top shape: 10 11 (110)
I0521 11:38:16.869787 20157 net.cpp:165] Memory required for data: 15787800
I0521 11:38:16.869797 20157 layer_factory.hpp:77] Creating layer loss
I0521 11:38:16.869817 20157 net.cpp:106] Creating Layer loss
I0521 11:38:16.869827 20157 net.cpp:454] loss <- ip3
I0521 11:38:16.869837 20157 net.cpp:454] loss <- label
I0521 11:38:16.869849 20157 net.cpp:411] loss -> loss
I0521 11:38:16.869866 20157 layer_factory.hpp:77] Creating layer loss
I0521 11:38:16.870515 20157 net.cpp:150] Setting up loss
I0521 11:38:16.870537 20157 net.cpp:157] Top shape: (1)
I0521 11:38:16.870549 20157 net.cpp:160]     with loss weight 1
I0521 11:38:16.870592 20157 net.cpp:165] Memory required for data: 15787804
I0521 11:38:16.870602 20157 net.cpp:226] loss needs backward computation.
I0521 11:38:16.870614 20157 net.cpp:226] drop3 needs backward computation.
I0521 11:38:16.870623 20157 net.cpp:226] ip3 needs backward computation.
I0521 11:38:16.870635 20157 net.cpp:226] drop2 needs backward computation.
I0521 11:38:16.870643 20157 net.cpp:226] relu6 needs backward computation.
I0521 11:38:16.870653 20157 net.cpp:226] ip2 needs backward computation.
I0521 11:38:16.870663 20157 net.cpp:226] drop1 needs backward computation.
I0521 11:38:16.870673 20157 net.cpp:226] relu5 needs backward computation.
I0521 11:38:16.870683 20157 net.cpp:226] ip1 needs backward computation.
I0521 11:38:16.870693 20157 net.cpp:226] pool4 needs backward computation.
I0521 11:38:16.870703 20157 net.cpp:226] relu4 needs backward computation.
I0521 11:38:16.870712 20157 net.cpp:226] conv4 needs backward computation.
I0521 11:38:16.870723 20157 net.cpp:226] pool3 needs backward computation.
I0521 11:38:16.870733 20157 net.cpp:226] relu3 needs backward computation.
I0521 11:38:16.870743 20157 net.cpp:226] conv3 needs backward computation.
I0521 11:38:16.870761 20157 net.cpp:226] pool2 needs backward computation.
I0521 11:38:16.870772 20157 net.cpp:226] relu2 needs backward computation.
I0521 11:38:16.870782 20157 net.cpp:226] conv2 needs backward computation.
I0521 11:38:16.870793 20157 net.cpp:226] pool1 needs backward computation.
I0521 11:38:16.870803 20157 net.cpp:226] relu1 needs backward computation.
I0521 11:38:16.870813 20157 net.cpp:226] conv1 needs backward computation.
I0521 11:38:16.870825 20157 net.cpp:228] data_hdf5 does not need backward computation.
I0521 11:38:16.870834 20157 net.cpp:270] This network produces output loss
I0521 11:38:16.870857 20157 net.cpp:283] Network initialization done.
I0521 11:38:16.872501 20157 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163.prototxt
I0521 11:38:16.872573 20157 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 11:38:16.872927 20157 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 11:38:16.873117 20157 layer_factory.hpp:77] Creating layer data_hdf5
I0521 11:38:16.873132 20157 net.cpp:106] Creating Layer data_hdf5
I0521 11:38:16.873144 20157 net.cpp:411] data_hdf5 -> data
I0521 11:38:16.873162 20157 net.cpp:411] data_hdf5 -> label
I0521 11:38:16.873177 20157 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 11:38:16.874537 20157 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 11:38:38.190363 20157 net.cpp:150] Setting up data_hdf5
I0521 11:38:38.190529 20157 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 11:38:38.190543 20157 net.cpp:157] Top shape: 10 (10)
I0521 11:38:38.190556 20157 net.cpp:165] Memory required for data: 254040
I0521 11:38:38.190568 20157 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 11:38:38.190596 20157 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 11:38:38.190608 20157 net.cpp:454] label_data_hdf5_1_split <- label
I0521 11:38:38.190623 20157 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 11:38:38.190644 20157 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 11:38:38.190717 20157 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 11:38:38.190732 20157 net.cpp:157] Top shape: 10 (10)
I0521 11:38:38.190742 20157 net.cpp:157] Top shape: 10 (10)
I0521 11:38:38.190752 20157 net.cpp:165] Memory required for data: 254120
I0521 11:38:38.190762 20157 layer_factory.hpp:77] Creating layer conv1
I0521 11:38:38.190783 20157 net.cpp:106] Creating Layer conv1
I0521 11:38:38.190794 20157 net.cpp:454] conv1 <- data
I0521 11:38:38.190809 20157 net.cpp:411] conv1 -> conv1
I0521 11:38:38.192793 20157 net.cpp:150] Setting up conv1
I0521 11:38:38.192816 20157 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 11:38:38.192829 20157 net.cpp:165] Memory required for data: 3018920
I0521 11:38:38.192849 20157 layer_factory.hpp:77] Creating layer relu1
I0521 11:38:38.192864 20157 net.cpp:106] Creating Layer relu1
I0521 11:38:38.192875 20157 net.cpp:454] relu1 <- conv1
I0521 11:38:38.192888 20157 net.cpp:397] relu1 -> conv1 (in-place)
I0521 11:38:38.193397 20157 net.cpp:150] Setting up relu1
I0521 11:38:38.193414 20157 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 11:38:38.193424 20157 net.cpp:165] Memory required for data: 5783720
I0521 11:38:38.193434 20157 layer_factory.hpp:77] Creating layer pool1
I0521 11:38:38.193451 20157 net.cpp:106] Creating Layer pool1
I0521 11:38:38.193461 20157 net.cpp:454] pool1 <- conv1
I0521 11:38:38.193475 20157 net.cpp:411] pool1 -> pool1
I0521 11:38:38.193550 20157 net.cpp:150] Setting up pool1
I0521 11:38:38.193563 20157 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 11:38:38.193573 20157 net.cpp:165] Memory required for data: 7166120
I0521 11:38:38.193585 20157 layer_factory.hpp:77] Creating layer conv2
I0521 11:38:38.193603 20157 net.cpp:106] Creating Layer conv2
I0521 11:38:38.193614 20157 net.cpp:454] conv2 <- pool1
I0521 11:38:38.193629 20157 net.cpp:411] conv2 -> conv2
I0521 11:38:38.195538 20157 net.cpp:150] Setting up conv2
I0521 11:38:38.195560 20157 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 11:38:38.195572 20157 net.cpp:165] Memory required for data: 9153320
I0521 11:38:38.195590 20157 layer_factory.hpp:77] Creating layer relu2
I0521 11:38:38.195605 20157 net.cpp:106] Creating Layer relu2
I0521 11:38:38.195614 20157 net.cpp:454] relu2 <- conv2
I0521 11:38:38.195626 20157 net.cpp:397] relu2 -> conv2 (in-place)
I0521 11:38:38.195971 20157 net.cpp:150] Setting up relu2
I0521 11:38:38.195986 20157 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 11:38:38.195996 20157 net.cpp:165] Memory required for data: 11140520
I0521 11:38:38.196005 20157 layer_factory.hpp:77] Creating layer pool2
I0521 11:38:38.196018 20157 net.cpp:106] Creating Layer pool2
I0521 11:38:38.196028 20157 net.cpp:454] pool2 <- conv2
I0521 11:38:38.196041 20157 net.cpp:411] pool2 -> pool2
I0521 11:38:38.196115 20157 net.cpp:150] Setting up pool2
I0521 11:38:38.196127 20157 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 11:38:38.196137 20157 net.cpp:165] Memory required for data: 12134120
I0521 11:38:38.196147 20157 layer_factory.hpp:77] Creating layer conv3
I0521 11:38:38.196164 20157 net.cpp:106] Creating Layer conv3
I0521 11:38:38.196176 20157 net.cpp:454] conv3 <- pool2
I0521 11:38:38.196189 20157 net.cpp:411] conv3 -> conv3
I0521 11:38:38.198199 20157 net.cpp:150] Setting up conv3
I0521 11:38:38.198223 20157 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 11:38:38.198235 20157 net.cpp:165] Memory required for data: 13218280
I0521 11:38:38.198253 20157 layer_factory.hpp:77] Creating layer relu3
I0521 11:38:38.198279 20157 net.cpp:106] Creating Layer relu3
I0521 11:38:38.198289 20157 net.cpp:454] relu3 <- conv3
I0521 11:38:38.198302 20157 net.cpp:397] relu3 -> conv3 (in-place)
I0521 11:38:38.198776 20157 net.cpp:150] Setting up relu3
I0521 11:38:38.198791 20157 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 11:38:38.198801 20157 net.cpp:165] Memory required for data: 14302440
I0521 11:38:38.198812 20157 layer_factory.hpp:77] Creating layer pool3
I0521 11:38:38.198824 20157 net.cpp:106] Creating Layer pool3
I0521 11:38:38.198834 20157 net.cpp:454] pool3 <- conv3
I0521 11:38:38.198848 20157 net.cpp:411] pool3 -> pool3
I0521 11:38:38.198920 20157 net.cpp:150] Setting up pool3
I0521 11:38:38.198933 20157 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 11:38:38.198942 20157 net.cpp:165] Memory required for data: 14844520
I0521 11:38:38.198952 20157 layer_factory.hpp:77] Creating layer conv4
I0521 11:38:38.198972 20157 net.cpp:106] Creating Layer conv4
I0521 11:38:38.198982 20157 net.cpp:454] conv4 <- pool3
I0521 11:38:38.198995 20157 net.cpp:411] conv4 -> conv4
I0521 11:38:38.201066 20157 net.cpp:150] Setting up conv4
I0521 11:38:38.201087 20157 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 11:38:38.201102 20157 net.cpp:165] Memory required for data: 15207400
I0521 11:38:38.201117 20157 layer_factory.hpp:77] Creating layer relu4
I0521 11:38:38.201129 20157 net.cpp:106] Creating Layer relu4
I0521 11:38:38.201139 20157 net.cpp:454] relu4 <- conv4
I0521 11:38:38.201151 20157 net.cpp:397] relu4 -> conv4 (in-place)
I0521 11:38:38.201622 20157 net.cpp:150] Setting up relu4
I0521 11:38:38.201639 20157 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 11:38:38.201649 20157 net.cpp:165] Memory required for data: 15570280
I0521 11:38:38.201659 20157 layer_factory.hpp:77] Creating layer pool4
I0521 11:38:38.201673 20157 net.cpp:106] Creating Layer pool4
I0521 11:38:38.201683 20157 net.cpp:454] pool4 <- conv4
I0521 11:38:38.201695 20157 net.cpp:411] pool4 -> pool4
I0521 11:38:38.201766 20157 net.cpp:150] Setting up pool4
I0521 11:38:38.201781 20157 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 11:38:38.201789 20157 net.cpp:165] Memory required for data: 15751720
I0521 11:38:38.201800 20157 layer_factory.hpp:77] Creating layer ip1
I0521 11:38:38.201815 20157 net.cpp:106] Creating Layer ip1
I0521 11:38:38.201827 20157 net.cpp:454] ip1 <- pool4
I0521 11:38:38.201840 20157 net.cpp:411] ip1 -> ip1
I0521 11:38:38.217336 20157 net.cpp:150] Setting up ip1
I0521 11:38:38.217365 20157 net.cpp:157] Top shape: 10 196 (1960)
I0521 11:38:38.217376 20157 net.cpp:165] Memory required for data: 15759560
I0521 11:38:38.217403 20157 layer_factory.hpp:77] Creating layer relu5
I0521 11:38:38.217418 20157 net.cpp:106] Creating Layer relu5
I0521 11:38:38.217429 20157 net.cpp:454] relu5 <- ip1
I0521 11:38:38.217442 20157 net.cpp:397] relu5 -> ip1 (in-place)
I0521 11:38:38.217792 20157 net.cpp:150] Setting up relu5
I0521 11:38:38.217805 20157 net.cpp:157] Top shape: 10 196 (1960)
I0521 11:38:38.217815 20157 net.cpp:165] Memory required for data: 15767400
I0521 11:38:38.217825 20157 layer_factory.hpp:77] Creating layer drop1
I0521 11:38:38.217844 20157 net.cpp:106] Creating Layer drop1
I0521 11:38:38.217855 20157 net.cpp:454] drop1 <- ip1
I0521 11:38:38.217869 20157 net.cpp:397] drop1 -> ip1 (in-place)
I0521 11:38:38.217913 20157 net.cpp:150] Setting up drop1
I0521 11:38:38.217926 20157 net.cpp:157] Top shape: 10 196 (1960)
I0521 11:38:38.217936 20157 net.cpp:165] Memory required for data: 15775240
I0521 11:38:38.217946 20157 layer_factory.hpp:77] Creating layer ip2
I0521 11:38:38.217960 20157 net.cpp:106] Creating Layer ip2
I0521 11:38:38.217970 20157 net.cpp:454] ip2 <- ip1
I0521 11:38:38.217984 20157 net.cpp:411] ip2 -> ip2
I0521 11:38:38.218461 20157 net.cpp:150] Setting up ip2
I0521 11:38:38.218474 20157 net.cpp:157] Top shape: 10 98 (980)
I0521 11:38:38.218484 20157 net.cpp:165] Memory required for data: 15779160
I0521 11:38:38.218499 20157 layer_factory.hpp:77] Creating layer relu6
I0521 11:38:38.218525 20157 net.cpp:106] Creating Layer relu6
I0521 11:38:38.218535 20157 net.cpp:454] relu6 <- ip2
I0521 11:38:38.218547 20157 net.cpp:397] relu6 -> ip2 (in-place)
I0521 11:38:38.219086 20157 net.cpp:150] Setting up relu6
I0521 11:38:38.219107 20157 net.cpp:157] Top shape: 10 98 (980)
I0521 11:38:38.219117 20157 net.cpp:165] Memory required for data: 15783080
I0521 11:38:38.219127 20157 layer_factory.hpp:77] Creating layer drop2
I0521 11:38:38.219141 20157 net.cpp:106] Creating Layer drop2
I0521 11:38:38.219151 20157 net.cpp:454] drop2 <- ip2
I0521 11:38:38.219163 20157 net.cpp:397] drop2 -> ip2 (in-place)
I0521 11:38:38.219208 20157 net.cpp:150] Setting up drop2
I0521 11:38:38.219220 20157 net.cpp:157] Top shape: 10 98 (980)
I0521 11:38:38.219230 20157 net.cpp:165] Memory required for data: 15787000
I0521 11:38:38.219240 20157 layer_factory.hpp:77] Creating layer ip3
I0521 11:38:38.219254 20157 net.cpp:106] Creating Layer ip3
I0521 11:38:38.219264 20157 net.cpp:454] ip3 <- ip2
I0521 11:38:38.219279 20157 net.cpp:411] ip3 -> ip3
I0521 11:38:38.219498 20157 net.cpp:150] Setting up ip3
I0521 11:38:38.219511 20157 net.cpp:157] Top shape: 10 11 (110)
I0521 11:38:38.219521 20157 net.cpp:165] Memory required for data: 15787440
I0521 11:38:38.219537 20157 layer_factory.hpp:77] Creating layer drop3
I0521 11:38:38.219549 20157 net.cpp:106] Creating Layer drop3
I0521 11:38:38.219559 20157 net.cpp:454] drop3 <- ip3
I0521 11:38:38.219571 20157 net.cpp:397] drop3 -> ip3 (in-place)
I0521 11:38:38.219612 20157 net.cpp:150] Setting up drop3
I0521 11:38:38.219625 20157 net.cpp:157] Top shape: 10 11 (110)
I0521 11:38:38.219635 20157 net.cpp:165] Memory required for data: 15787880
I0521 11:38:38.219645 20157 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 11:38:38.219658 20157 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 11:38:38.219668 20157 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 11:38:38.219681 20157 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 11:38:38.219696 20157 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 11:38:38.219769 20157 net.cpp:150] Setting up ip3_drop3_0_split
I0521 11:38:38.219782 20157 net.cpp:157] Top shape: 10 11 (110)
I0521 11:38:38.219794 20157 net.cpp:157] Top shape: 10 11 (110)
I0521 11:38:38.219805 20157 net.cpp:165] Memory required for data: 15788760
I0521 11:38:38.219822 20157 layer_factory.hpp:77] Creating layer accuracy
I0521 11:38:38.219843 20157 net.cpp:106] Creating Layer accuracy
I0521 11:38:38.219853 20157 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 11:38:38.219864 20157 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 11:38:38.219878 20157 net.cpp:411] accuracy -> accuracy
I0521 11:38:38.219902 20157 net.cpp:150] Setting up accuracy
I0521 11:38:38.219915 20157 net.cpp:157] Top shape: (1)
I0521 11:38:38.219925 20157 net.cpp:165] Memory required for data: 15788764
I0521 11:38:38.219935 20157 layer_factory.hpp:77] Creating layer loss
I0521 11:38:38.219950 20157 net.cpp:106] Creating Layer loss
I0521 11:38:38.219961 20157 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 11:38:38.219972 20157 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 11:38:38.219985 20157 net.cpp:411] loss -> loss
I0521 11:38:38.220002 20157 layer_factory.hpp:77] Creating layer loss
I0521 11:38:38.220487 20157 net.cpp:150] Setting up loss
I0521 11:38:38.220501 20157 net.cpp:157] Top shape: (1)
I0521 11:38:38.220511 20157 net.cpp:160]     with loss weight 1
I0521 11:38:38.220530 20157 net.cpp:165] Memory required for data: 15788768
I0521 11:38:38.220540 20157 net.cpp:226] loss needs backward computation.
I0521 11:38:38.220551 20157 net.cpp:228] accuracy does not need backward computation.
I0521 11:38:38.220562 20157 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 11:38:38.220572 20157 net.cpp:226] drop3 needs backward computation.
I0521 11:38:38.220583 20157 net.cpp:226] ip3 needs backward computation.
I0521 11:38:38.220594 20157 net.cpp:226] drop2 needs backward computation.
I0521 11:38:38.220604 20157 net.cpp:226] relu6 needs backward computation.
I0521 11:38:38.220623 20157 net.cpp:226] ip2 needs backward computation.
I0521 11:38:38.220633 20157 net.cpp:226] drop1 needs backward computation.
I0521 11:38:38.220643 20157 net.cpp:226] relu5 needs backward computation.
I0521 11:38:38.220651 20157 net.cpp:226] ip1 needs backward computation.
I0521 11:38:38.220662 20157 net.cpp:226] pool4 needs backward computation.
I0521 11:38:38.220672 20157 net.cpp:226] relu4 needs backward computation.
I0521 11:38:38.220684 20157 net.cpp:226] conv4 needs backward computation.
I0521 11:38:38.220695 20157 net.cpp:226] pool3 needs backward computation.
I0521 11:38:38.220705 20157 net.cpp:226] relu3 needs backward computation.
I0521 11:38:38.220715 20157 net.cpp:226] conv3 needs backward computation.
I0521 11:38:38.220724 20157 net.cpp:226] pool2 needs backward computation.
I0521 11:38:38.220734 20157 net.cpp:226] relu2 needs backward computation.
I0521 11:38:38.220744 20157 net.cpp:226] conv2 needs backward computation.
I0521 11:38:38.220755 20157 net.cpp:226] pool1 needs backward computation.
I0521 11:38:38.220765 20157 net.cpp:226] relu1 needs backward computation.
I0521 11:38:38.220774 20157 net.cpp:226] conv1 needs backward computation.
I0521 11:38:38.220787 20157 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 11:38:38.220798 20157 net.cpp:228] data_hdf5 does not need backward computation.
I0521 11:38:38.220809 20157 net.cpp:270] This network produces output accuracy
I0521 11:38:38.220819 20157 net.cpp:270] This network produces output loss
I0521 11:38:38.220849 20157 net.cpp:283] Network initialization done.
I0521 11:38:38.220983 20157 solver.cpp:60] Solver scaffolding done.
I0521 11:38:38.222123 20157 caffe.cpp:212] Starting Optimization
I0521 11:38:38.222136 20157 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 11:38:38.222151 20157 solver.cpp:289] Learning Rate Policy: fixed
I0521 11:38:38.223214 20157 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 11:39:38.675204 20157 solver.cpp:409]     Test net output #0: accuracy = 0.0482526
I0521 11:39:38.675367 20157 solver.cpp:409]     Test net output #1: loss = 2.39951 (* 1 = 2.39951 loss)
I0521 11:39:38.693152 20157 solver.cpp:237] Iteration 0, loss = 2.39658
I0521 11:39:38.693189 20157 solver.cpp:253]     Train net output #0: loss = 2.39658 (* 1 = 2.39658 loss)
I0521 11:39:38.693207 20157 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0521 11:39:55.410964 20157 solver.cpp:237] Iteration 1500, loss = 2.23616
I0521 11:39:55.411000 20157 solver.cpp:253]     Train net output #0: loss = 2.23616 (* 1 = 2.23616 loss)
I0521 11:39:55.411015 20157 sgd_solver.cpp:106] Iteration 1500, lr = 0.0005
I0521 11:40:12.139224 20157 solver.cpp:237] Iteration 3000, loss = 1.92929
I0521 11:40:12.139389 20157 solver.cpp:253]     Train net output #0: loss = 1.92929 (* 1 = 1.92929 loss)
I0521 11:40:12.139405 20157 sgd_solver.cpp:106] Iteration 3000, lr = 0.0005
I0521 11:40:28.902098 20157 solver.cpp:237] Iteration 4500, loss = 1.86345
I0521 11:40:28.902144 20157 solver.cpp:253]     Train net output #0: loss = 1.86345 (* 1 = 1.86345 loss)
I0521 11:40:28.902163 20157 sgd_solver.cpp:106] Iteration 4500, lr = 0.0005
I0521 11:40:45.662890 20157 solver.cpp:237] Iteration 6000, loss = 1.25466
I0521 11:40:45.663029 20157 solver.cpp:253]     Train net output #0: loss = 1.25466 (* 1 = 1.25466 loss)
I0521 11:40:45.663043 20157 sgd_solver.cpp:106] Iteration 6000, lr = 0.0005
I0521 11:41:02.432907 20157 solver.cpp:237] Iteration 7500, loss = 1.43997
I0521 11:41:02.432960 20157 solver.cpp:253]     Train net output #0: loss = 1.43997 (* 1 = 1.43997 loss)
I0521 11:41:02.432976 20157 sgd_solver.cpp:106] Iteration 7500, lr = 0.0005
I0521 11:41:19.201035 20157 solver.cpp:237] Iteration 9000, loss = 1.82729
I0521 11:41:19.201177 20157 solver.cpp:253]     Train net output #0: loss = 1.82729 (* 1 = 1.82729 loss)
I0521 11:41:19.201191 20157 sgd_solver.cpp:106] Iteration 9000, lr = 0.0005
I0521 11:41:58.079718 20157 solver.cpp:237] Iteration 10500, loss = 1.66434
I0521 11:41:58.079892 20157 solver.cpp:253]     Train net output #0: loss = 1.66434 (* 1 = 1.66434 loss)
I0521 11:41:58.079907 20157 sgd_solver.cpp:106] Iteration 10500, lr = 0.0005
I0521 11:42:14.847986 20157 solver.cpp:237] Iteration 12000, loss = 1.52074
I0521 11:42:14.848029 20157 solver.cpp:253]     Train net output #0: loss = 1.52074 (* 1 = 1.52074 loss)
I0521 11:42:14.848049 20157 sgd_solver.cpp:106] Iteration 12000, lr = 0.0005
I0521 11:42:31.610587 20157 solver.cpp:237] Iteration 13500, loss = 1.73616
I0521 11:42:31.610723 20157 solver.cpp:253]     Train net output #0: loss = 1.73616 (* 1 = 1.73616 loss)
I0521 11:42:31.610736 20157 sgd_solver.cpp:106] Iteration 13500, lr = 0.0005
I0521 11:42:48.571527 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_15000.caffemodel
I0521 11:42:48.621052 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_15000.solverstate
I0521 11:42:48.649808 20157 solver.cpp:237] Iteration 15000, loss = 1.52474
I0521 11:42:48.649853 20157 solver.cpp:253]     Train net output #0: loss = 1.52474 (* 1 = 1.52474 loss)
I0521 11:42:48.649868 20157 sgd_solver.cpp:106] Iteration 15000, lr = 0.0005
I0521 11:43:05.698838 20157 solver.cpp:237] Iteration 16500, loss = 1.63299
I0521 11:43:05.698989 20157 solver.cpp:253]     Train net output #0: loss = 1.63299 (* 1 = 1.63299 loss)
I0521 11:43:05.699005 20157 sgd_solver.cpp:106] Iteration 16500, lr = 0.0005
I0521 11:43:22.705360 20157 solver.cpp:237] Iteration 18000, loss = 1.03269
I0521 11:43:22.705396 20157 solver.cpp:253]     Train net output #0: loss = 1.03269 (* 1 = 1.03269 loss)
I0521 11:43:22.705413 20157 sgd_solver.cpp:106] Iteration 18000, lr = 0.0005
I0521 11:43:39.712687 20157 solver.cpp:237] Iteration 19500, loss = 1.88577
I0521 11:43:39.712834 20157 solver.cpp:253]     Train net output #0: loss = 1.88577 (* 1 = 1.88577 loss)
I0521 11:43:39.712851 20157 sgd_solver.cpp:106] Iteration 19500, lr = 0.0005
I0521 11:44:18.833397 20157 solver.cpp:237] Iteration 21000, loss = 1.51985
I0521 11:44:18.833556 20157 solver.cpp:253]     Train net output #0: loss = 1.51985 (* 1 = 1.51985 loss)
I0521 11:44:18.833570 20157 sgd_solver.cpp:106] Iteration 21000, lr = 0.0005
I0521 11:44:35.859781 20157 solver.cpp:237] Iteration 22500, loss = 1.03094
I0521 11:44:35.859822 20157 solver.cpp:253]     Train net output #0: loss = 1.03094 (* 1 = 1.03094 loss)
I0521 11:44:35.859836 20157 sgd_solver.cpp:106] Iteration 22500, lr = 0.0005
I0521 11:44:52.905813 20157 solver.cpp:237] Iteration 24000, loss = 1.74106
I0521 11:44:52.905982 20157 solver.cpp:253]     Train net output #0: loss = 1.74106 (* 1 = 1.74106 loss)
I0521 11:44:52.905997 20157 sgd_solver.cpp:106] Iteration 24000, lr = 0.0005
I0521 11:45:09.928128 20157 solver.cpp:237] Iteration 25500, loss = 1.286
I0521 11:45:09.928175 20157 solver.cpp:253]     Train net output #0: loss = 1.286 (* 1 = 1.286 loss)
I0521 11:45:09.928189 20157 sgd_solver.cpp:106] Iteration 25500, lr = 0.0005
I0521 11:45:26.968823 20157 solver.cpp:237] Iteration 27000, loss = 1.83315
I0521 11:45:26.968963 20157 solver.cpp:253]     Train net output #0: loss = 1.83315 (* 1 = 1.83315 loss)
I0521 11:45:26.968977 20157 sgd_solver.cpp:106] Iteration 27000, lr = 0.0005
I0521 11:45:43.993827 20157 solver.cpp:237] Iteration 28500, loss = 1.34121
I0521 11:45:43.993875 20157 solver.cpp:253]     Train net output #0: loss = 1.34121 (* 1 = 1.34121 loss)
I0521 11:45:43.993888 20157 sgd_solver.cpp:106] Iteration 28500, lr = 0.0005
I0521 11:46:01.006790 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_30000.caffemodel
I0521 11:46:01.053140 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_30000.solverstate
I0521 11:46:01.079715 20157 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 11:47:00.739729 20157 solver.cpp:409]     Test net output #0: accuracy = 0.800448
I0521 11:47:00.739893 20157 solver.cpp:409]     Test net output #1: loss = 0.711407 (* 1 = 0.711407 loss)
I0521 11:47:22.899426 20157 solver.cpp:237] Iteration 30000, loss = 1.67491
I0521 11:47:22.899480 20157 solver.cpp:253]     Train net output #0: loss = 1.67491 (* 1 = 1.67491 loss)
I0521 11:47:22.899495 20157 sgd_solver.cpp:106] Iteration 30000, lr = 0.0005
I0521 11:47:39.859865 20157 solver.cpp:237] Iteration 31500, loss = 1.37395
I0521 11:47:39.860025 20157 solver.cpp:253]     Train net output #0: loss = 1.37395 (* 1 = 1.37395 loss)
I0521 11:47:39.860039 20157 sgd_solver.cpp:106] Iteration 31500, lr = 0.0005
I0521 11:47:56.439743 20157 solver.cpp:237] Iteration 33000, loss = 1.57209
I0521 11:47:56.439779 20157 solver.cpp:253]     Train net output #0: loss = 1.57209 (* 1 = 1.57209 loss)
I0521 11:47:56.439795 20157 sgd_solver.cpp:106] Iteration 33000, lr = 0.0005
I0521 11:48:13.041780 20157 solver.cpp:237] Iteration 34500, loss = 0.892799
I0521 11:48:13.041932 20157 solver.cpp:253]     Train net output #0: loss = 0.8928 (* 1 = 0.8928 loss)
I0521 11:48:13.041947 20157 sgd_solver.cpp:106] Iteration 34500, lr = 0.0005
I0521 11:48:29.620872 20157 solver.cpp:237] Iteration 36000, loss = 1.28512
I0521 11:48:29.620920 20157 solver.cpp:253]     Train net output #0: loss = 1.28512 (* 1 = 1.28512 loss)
I0521 11:48:29.620935 20157 sgd_solver.cpp:106] Iteration 36000, lr = 0.0005
I0521 11:48:46.202960 20157 solver.cpp:237] Iteration 37500, loss = 1.00601
I0521 11:48:46.203099 20157 solver.cpp:253]     Train net output #0: loss = 1.00601 (* 1 = 1.00601 loss)
I0521 11:48:46.203114 20157 sgd_solver.cpp:106] Iteration 37500, lr = 0.0005
I0521 11:49:02.818693 20157 solver.cpp:237] Iteration 39000, loss = 0.767649
I0521 11:49:02.818744 20157 solver.cpp:253]     Train net output #0: loss = 0.767649 (* 1 = 0.767649 loss)
I0521 11:49:02.818758 20157 sgd_solver.cpp:106] Iteration 39000, lr = 0.0005
I0521 11:49:41.600807 20157 solver.cpp:237] Iteration 40500, loss = 1.25127
I0521 11:49:41.600971 20157 solver.cpp:253]     Train net output #0: loss = 1.25127 (* 1 = 1.25127 loss)
I0521 11:49:41.600986 20157 sgd_solver.cpp:106] Iteration 40500, lr = 0.0005
I0521 11:49:58.222875 20157 solver.cpp:237] Iteration 42000, loss = 1.85495
I0521 11:49:58.222910 20157 solver.cpp:253]     Train net output #0: loss = 1.85495 (* 1 = 1.85495 loss)
I0521 11:49:58.222929 20157 sgd_solver.cpp:106] Iteration 42000, lr = 0.0005
I0521 11:50:14.827425 20157 solver.cpp:237] Iteration 43500, loss = 1.25292
I0521 11:50:14.827594 20157 solver.cpp:253]     Train net output #0: loss = 1.25292 (* 1 = 1.25292 loss)
I0521 11:50:14.827608 20157 sgd_solver.cpp:106] Iteration 43500, lr = 0.0005
I0521 11:50:31.424772 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_45000.caffemodel
I0521 11:50:31.472913 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_45000.solverstate
I0521 11:50:31.504545 20157 solver.cpp:237] Iteration 45000, loss = 1.26034
I0521 11:50:31.504595 20157 solver.cpp:253]     Train net output #0: loss = 1.26035 (* 1 = 1.26035 loss)
I0521 11:50:31.504611 20157 sgd_solver.cpp:106] Iteration 45000, lr = 0.0005
I0521 11:50:48.103843 20157 solver.cpp:237] Iteration 46500, loss = 1.01734
I0521 11:50:48.103988 20157 solver.cpp:253]     Train net output #0: loss = 1.01734 (* 1 = 1.01734 loss)
I0521 11:50:48.104003 20157 sgd_solver.cpp:106] Iteration 46500, lr = 0.0005
I0521 11:51:04.714323 20157 solver.cpp:237] Iteration 48000, loss = 1.13828
I0521 11:51:04.714372 20157 solver.cpp:253]     Train net output #0: loss = 1.13828 (* 1 = 1.13828 loss)
I0521 11:51:04.714386 20157 sgd_solver.cpp:106] Iteration 48000, lr = 0.0005
I0521 11:51:21.320075 20157 solver.cpp:237] Iteration 49500, loss = 1.27447
I0521 11:51:21.320233 20157 solver.cpp:253]     Train net output #0: loss = 1.27447 (* 1 = 1.27447 loss)
I0521 11:51:21.320247 20157 sgd_solver.cpp:106] Iteration 49500, lr = 0.0005
I0521 11:52:00.109032 20157 solver.cpp:237] Iteration 51000, loss = 1.68584
I0521 11:52:00.109196 20157 solver.cpp:253]     Train net output #0: loss = 1.68584 (* 1 = 1.68584 loss)
I0521 11:52:00.109212 20157 sgd_solver.cpp:106] Iteration 51000, lr = 0.0005
I0521 11:52:16.689327 20157 solver.cpp:237] Iteration 52500, loss = 0.970441
I0521 11:52:16.689375 20157 solver.cpp:253]     Train net output #0: loss = 0.970442 (* 1 = 0.970442 loss)
I0521 11:52:16.689389 20157 sgd_solver.cpp:106] Iteration 52500, lr = 0.0005
I0521 11:52:33.299721 20157 solver.cpp:237] Iteration 54000, loss = 1.72695
I0521 11:52:33.299868 20157 solver.cpp:253]     Train net output #0: loss = 1.72695 (* 1 = 1.72695 loss)
I0521 11:52:33.299883 20157 sgd_solver.cpp:106] Iteration 54000, lr = 0.0005
I0521 11:52:49.943326 20157 solver.cpp:237] Iteration 55500, loss = 1.35595
I0521 11:52:49.943372 20157 solver.cpp:253]     Train net output #0: loss = 1.35595 (* 1 = 1.35595 loss)
I0521 11:52:49.943388 20157 sgd_solver.cpp:106] Iteration 55500, lr = 0.0005
I0521 11:53:06.545238 20157 solver.cpp:237] Iteration 57000, loss = 1.6105
I0521 11:53:06.545387 20157 solver.cpp:253]     Train net output #0: loss = 1.6105 (* 1 = 1.6105 loss)
I0521 11:53:06.545403 20157 sgd_solver.cpp:106] Iteration 57000, lr = 0.0005
I0521 11:53:23.162242 20157 solver.cpp:237] Iteration 58500, loss = 0.851588
I0521 11:53:23.162281 20157 solver.cpp:253]     Train net output #0: loss = 0.85159 (* 1 = 0.85159 loss)
I0521 11:53:23.162292 20157 sgd_solver.cpp:106] Iteration 58500, lr = 0.0005
I0521 11:53:39.761149 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_60000.caffemodel
I0521 11:53:39.808871 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_60000.solverstate
I0521 11:53:39.837504 20157 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 11:55:00.189808 20157 solver.cpp:409]     Test net output #0: accuracy = 0.835742
I0521 11:55:00.189978 20157 solver.cpp:409]     Test net output #1: loss = 0.597385 (* 1 = 0.597385 loss)
I0521 11:55:22.345207 20157 solver.cpp:237] Iteration 60000, loss = 1.53851
I0521 11:55:22.345262 20157 solver.cpp:253]     Train net output #0: loss = 1.53851 (* 1 = 1.53851 loss)
I0521 11:55:22.345278 20157 sgd_solver.cpp:106] Iteration 60000, lr = 0.0005
I0521 11:55:39.530798 20157 solver.cpp:237] Iteration 61500, loss = 0.532782
I0521 11:55:39.530963 20157 solver.cpp:253]     Train net output #0: loss = 0.532785 (* 1 = 0.532785 loss)
I0521 11:55:39.530978 20157 sgd_solver.cpp:106] Iteration 61500, lr = 0.0005
I0521 11:55:56.597120 20157 solver.cpp:237] Iteration 63000, loss = 1.50217
I0521 11:55:56.597167 20157 solver.cpp:253]     Train net output #0: loss = 1.50217 (* 1 = 1.50217 loss)
I0521 11:55:56.597182 20157 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I0521 11:56:13.199892 20157 solver.cpp:237] Iteration 64500, loss = 1.13837
I0521 11:56:13.200032 20157 solver.cpp:253]     Train net output #0: loss = 1.13837 (* 1 = 1.13837 loss)
I0521 11:56:13.200045 20157 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I0521 11:56:29.805163 20157 solver.cpp:237] Iteration 66000, loss = 1.54898
I0521 11:56:29.805209 20157 solver.cpp:253]     Train net output #0: loss = 1.54899 (* 1 = 1.54899 loss)
I0521 11:56:29.805227 20157 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I0521 11:56:46.429461 20157 solver.cpp:237] Iteration 67500, loss = 1.15708
I0521 11:56:46.429608 20157 solver.cpp:253]     Train net output #0: loss = 1.15708 (* 1 = 1.15708 loss)
I0521 11:56:46.429622 20157 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I0521 11:57:03.040524 20157 solver.cpp:237] Iteration 69000, loss = 1.27942
I0521 11:57:03.040560 20157 solver.cpp:253]     Train net output #0: loss = 1.27942 (* 1 = 1.27942 loss)
I0521 11:57:03.040573 20157 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I0521 11:57:41.801987 20157 solver.cpp:237] Iteration 70500, loss = 1.14982
I0521 11:57:41.802151 20157 solver.cpp:253]     Train net output #0: loss = 1.14982 (* 1 = 1.14982 loss)
I0521 11:57:41.802165 20157 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I0521 11:57:58.379928 20157 solver.cpp:237] Iteration 72000, loss = 1.49827
I0521 11:57:58.379964 20157 solver.cpp:253]     Train net output #0: loss = 1.49827 (* 1 = 1.49827 loss)
I0521 11:57:58.379978 20157 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I0521 11:58:14.992283 20157 solver.cpp:237] Iteration 73500, loss = 0.979787
I0521 11:58:14.992429 20157 solver.cpp:253]     Train net output #0: loss = 0.979791 (* 1 = 0.979791 loss)
I0521 11:58:14.992444 20157 sgd_solver.cpp:106] Iteration 73500, lr = 0.0005
I0521 11:58:31.609076 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_75000.caffemodel
I0521 11:58:31.656875 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_75000.solverstate
I0521 11:58:31.688875 20157 solver.cpp:237] Iteration 75000, loss = 1.37773
I0521 11:58:31.688925 20157 solver.cpp:253]     Train net output #0: loss = 1.37774 (* 1 = 1.37774 loss)
I0521 11:58:31.688940 20157 sgd_solver.cpp:106] Iteration 75000, lr = 0.0005
I0521 11:58:48.287782 20157 solver.cpp:237] Iteration 76500, loss = 1.51879
I0521 11:58:48.287932 20157 solver.cpp:253]     Train net output #0: loss = 1.51879 (* 1 = 1.51879 loss)
I0521 11:58:48.287947 20157 sgd_solver.cpp:106] Iteration 76500, lr = 0.0005
I0521 11:59:05.044302 20157 solver.cpp:237] Iteration 78000, loss = 1.41522
I0521 11:59:05.044350 20157 solver.cpp:253]     Train net output #0: loss = 1.41522 (* 1 = 1.41522 loss)
I0521 11:59:05.044366 20157 sgd_solver.cpp:106] Iteration 78000, lr = 0.0005
I0521 11:59:21.764744 20157 solver.cpp:237] Iteration 79500, loss = 1.13199
I0521 11:59:21.764895 20157 solver.cpp:253]     Train net output #0: loss = 1.13199 (* 1 = 1.13199 loss)
I0521 11:59:21.764910 20157 sgd_solver.cpp:106] Iteration 79500, lr = 0.0005
I0521 12:00:00.668751 20157 solver.cpp:237] Iteration 81000, loss = 0.953784
I0521 12:00:00.668927 20157 solver.cpp:253]     Train net output #0: loss = 0.95379 (* 1 = 0.95379 loss)
I0521 12:00:00.668942 20157 sgd_solver.cpp:106] Iteration 81000, lr = 0.0005
I0521 12:00:17.592144 20157 solver.cpp:237] Iteration 82500, loss = 1.52137
I0521 12:00:17.592195 20157 solver.cpp:253]     Train net output #0: loss = 1.52138 (* 1 = 1.52138 loss)
I0521 12:00:17.592208 20157 sgd_solver.cpp:106] Iteration 82500, lr = 0.0005
I0521 12:00:34.525229 20157 solver.cpp:237] Iteration 84000, loss = 1.38778
I0521 12:00:34.525388 20157 solver.cpp:253]     Train net output #0: loss = 1.38779 (* 1 = 1.38779 loss)
I0521 12:00:34.525401 20157 sgd_solver.cpp:106] Iteration 84000, lr = 0.0005
I0521 12:00:51.461549 20157 solver.cpp:237] Iteration 85500, loss = 1.65127
I0521 12:00:51.461586 20157 solver.cpp:253]     Train net output #0: loss = 1.65128 (* 1 = 1.65128 loss)
I0521 12:00:51.461599 20157 sgd_solver.cpp:106] Iteration 85500, lr = 0.0005
I0521 12:01:08.435997 20157 solver.cpp:237] Iteration 87000, loss = 1.30195
I0521 12:01:08.436151 20157 solver.cpp:253]     Train net output #0: loss = 1.30196 (* 1 = 1.30196 loss)
I0521 12:01:08.436167 20157 sgd_solver.cpp:106] Iteration 87000, lr = 0.0005
I0521 12:01:25.349808 20157 solver.cpp:237] Iteration 88500, loss = 1.20047
I0521 12:01:25.349855 20157 solver.cpp:253]     Train net output #0: loss = 1.20048 (* 1 = 1.20048 loss)
I0521 12:01:25.349869 20157 sgd_solver.cpp:106] Iteration 88500, lr = 0.0005
I0521 12:01:42.265801 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_90000.caffemodel
I0521 12:01:42.311753 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_90000.solverstate
I0521 12:01:42.338116 20157 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 12:02:41.469791 20157 solver.cpp:409]     Test net output #0: accuracy = 0.853253
I0521 12:02:41.469952 20157 solver.cpp:409]     Test net output #1: loss = 0.484011 (* 1 = 0.484011 loss)
I0521 12:03:03.612202 20157 solver.cpp:237] Iteration 90000, loss = 0.983935
I0521 12:03:03.612257 20157 solver.cpp:253]     Train net output #0: loss = 0.983941 (* 1 = 0.983941 loss)
I0521 12:03:03.612272 20157 sgd_solver.cpp:106] Iteration 90000, lr = 0.0005
I0521 12:03:20.363932 20157 solver.cpp:237] Iteration 91500, loss = 1.00423
I0521 12:03:20.364084 20157 solver.cpp:253]     Train net output #0: loss = 1.00423 (* 1 = 1.00423 loss)
I0521 12:03:20.364099 20157 sgd_solver.cpp:106] Iteration 91500, lr = 0.0005
I0521 12:03:37.133656 20157 solver.cpp:237] Iteration 93000, loss = 1.39785
I0521 12:03:37.133705 20157 solver.cpp:253]     Train net output #0: loss = 1.39785 (* 1 = 1.39785 loss)
I0521 12:03:37.133719 20157 sgd_solver.cpp:106] Iteration 93000, lr = 0.0005
I0521 12:03:53.864994 20157 solver.cpp:237] Iteration 94500, loss = 1.77137
I0521 12:03:53.865151 20157 solver.cpp:253]     Train net output #0: loss = 1.77138 (* 1 = 1.77138 loss)
I0521 12:03:53.865165 20157 sgd_solver.cpp:106] Iteration 94500, lr = 0.0005
I0521 12:04:10.661496 20157 solver.cpp:237] Iteration 96000, loss = 1.5597
I0521 12:04:10.661533 20157 solver.cpp:253]     Train net output #0: loss = 1.5597 (* 1 = 1.5597 loss)
I0521 12:04:10.661550 20157 sgd_solver.cpp:106] Iteration 96000, lr = 0.0005
I0521 12:04:27.777276 20157 solver.cpp:237] Iteration 97500, loss = 0.889978
I0521 12:04:27.777433 20157 solver.cpp:253]     Train net output #0: loss = 0.889986 (* 1 = 0.889986 loss)
I0521 12:04:27.777449 20157 sgd_solver.cpp:106] Iteration 97500, lr = 0.0005
I0521 12:04:44.969430 20157 solver.cpp:237] Iteration 99000, loss = 0.923617
I0521 12:04:44.969480 20157 solver.cpp:253]     Train net output #0: loss = 0.923624 (* 1 = 0.923624 loss)
I0521 12:04:44.969496 20157 sgd_solver.cpp:106] Iteration 99000, lr = 0.0005
I0521 12:05:24.325768 20157 solver.cpp:237] Iteration 100500, loss = 1.29715
I0521 12:05:24.325949 20157 solver.cpp:253]     Train net output #0: loss = 1.29716 (* 1 = 1.29716 loss)
I0521 12:05:24.325964 20157 sgd_solver.cpp:106] Iteration 100500, lr = 0.0005
I0521 12:05:41.478672 20157 solver.cpp:237] Iteration 102000, loss = 1.14093
I0521 12:05:41.478721 20157 solver.cpp:253]     Train net output #0: loss = 1.14093 (* 1 = 1.14093 loss)
I0521 12:05:41.478735 20157 sgd_solver.cpp:106] Iteration 102000, lr = 0.0005
I0521 12:05:58.665603 20157 solver.cpp:237] Iteration 103500, loss = 1.0904
I0521 12:05:58.665762 20157 solver.cpp:253]     Train net output #0: loss = 1.09041 (* 1 = 1.09041 loss)
I0521 12:05:58.665777 20157 sgd_solver.cpp:106] Iteration 103500, lr = 0.0005
I0521 12:06:15.825475 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_105000.caffemodel
I0521 12:06:15.875705 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_105000.solverstate
I0521 12:06:15.904410 20157 solver.cpp:237] Iteration 105000, loss = 1.16104
I0521 12:06:15.904453 20157 solver.cpp:253]     Train net output #0: loss = 1.16105 (* 1 = 1.16105 loss)
I0521 12:06:15.904474 20157 sgd_solver.cpp:106] Iteration 105000, lr = 0.0005
I0521 12:06:32.860270 20157 solver.cpp:237] Iteration 106500, loss = 1.38588
I0521 12:06:32.860433 20157 solver.cpp:253]     Train net output #0: loss = 1.38588 (* 1 = 1.38588 loss)
I0521 12:06:32.860450 20157 sgd_solver.cpp:106] Iteration 106500, lr = 0.0005
I0521 12:06:49.747226 20157 solver.cpp:237] Iteration 108000, loss = 1.55917
I0521 12:06:49.747275 20157 solver.cpp:253]     Train net output #0: loss = 1.55917 (* 1 = 1.55917 loss)
I0521 12:06:49.747292 20157 sgd_solver.cpp:106] Iteration 108000, lr = 0.0005
I0521 12:07:06.437619 20157 solver.cpp:237] Iteration 109500, loss = 1.22556
I0521 12:07:06.437765 20157 solver.cpp:253]     Train net output #0: loss = 1.22557 (* 1 = 1.22557 loss)
I0521 12:07:06.437779 20157 sgd_solver.cpp:106] Iteration 109500, lr = 0.0005
I0521 12:07:45.155378 20157 solver.cpp:237] Iteration 111000, loss = 1.81521
I0521 12:07:45.155547 20157 solver.cpp:253]     Train net output #0: loss = 1.81521 (* 1 = 1.81521 loss)
I0521 12:07:45.155562 20157 sgd_solver.cpp:106] Iteration 111000, lr = 0.0005
I0521 12:08:01.780753 20157 solver.cpp:237] Iteration 112500, loss = 1.76235
I0521 12:08:01.780802 20157 solver.cpp:253]     Train net output #0: loss = 1.76235 (* 1 = 1.76235 loss)
I0521 12:08:01.780815 20157 sgd_solver.cpp:106] Iteration 112500, lr = 0.0005
I0521 12:08:18.372190 20157 solver.cpp:237] Iteration 114000, loss = 1.43338
I0521 12:08:18.372335 20157 solver.cpp:253]     Train net output #0: loss = 1.43338 (* 1 = 1.43338 loss)
I0521 12:08:18.372349 20157 sgd_solver.cpp:106] Iteration 114000, lr = 0.0005
I0521 12:08:34.978497 20157 solver.cpp:237] Iteration 115500, loss = 1.38721
I0521 12:08:34.978548 20157 solver.cpp:253]     Train net output #0: loss = 1.38721 (* 1 = 1.38721 loss)
I0521 12:08:34.978561 20157 sgd_solver.cpp:106] Iteration 115500, lr = 0.0005
I0521 12:08:51.548490 20157 solver.cpp:237] Iteration 117000, loss = 0.850073
I0521 12:08:51.548652 20157 solver.cpp:253]     Train net output #0: loss = 0.850077 (* 1 = 0.850077 loss)
I0521 12:08:51.548666 20157 sgd_solver.cpp:106] Iteration 117000, lr = 0.0005
I0521 12:09:08.159282 20157 solver.cpp:237] Iteration 118500, loss = 1.80527
I0521 12:09:08.159319 20157 solver.cpp:253]     Train net output #0: loss = 1.80528 (* 1 = 1.80528 loss)
I0521 12:09:08.159335 20157 sgd_solver.cpp:106] Iteration 118500, lr = 0.0005
I0521 12:09:25.054704 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_120000.caffemodel
I0521 12:09:25.100760 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_120000.solverstate
I0521 12:09:25.126292 20157 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 12:10:45.636538 20157 solver.cpp:409]     Test net output #0: accuracy = 0.865241
I0521 12:10:45.636703 20157 solver.cpp:409]     Test net output #1: loss = 0.415278 (* 1 = 0.415278 loss)
I0521 12:11:07.774596 20157 solver.cpp:237] Iteration 120000, loss = 1.65042
I0521 12:11:07.774651 20157 solver.cpp:253]     Train net output #0: loss = 1.65043 (* 1 = 1.65043 loss)
I0521 12:11:07.774664 20157 sgd_solver.cpp:106] Iteration 120000, lr = 0.0005
I0521 12:11:24.330281 20157 solver.cpp:237] Iteration 121500, loss = 1.23093
I0521 12:11:24.330446 20157 solver.cpp:253]     Train net output #0: loss = 1.23093 (* 1 = 1.23093 loss)
I0521 12:11:24.330461 20157 sgd_solver.cpp:106] Iteration 121500, lr = 0.0005
I0521 12:11:40.933133 20157 solver.cpp:237] Iteration 123000, loss = 1.40921
I0521 12:11:40.933171 20157 solver.cpp:253]     Train net output #0: loss = 1.40922 (* 1 = 1.40922 loss)
I0521 12:11:40.933185 20157 sgd_solver.cpp:106] Iteration 123000, lr = 0.0005
I0521 12:11:57.569952 20157 solver.cpp:237] Iteration 124500, loss = 0.720367
I0521 12:11:57.570116 20157 solver.cpp:253]     Train net output #0: loss = 0.720371 (* 1 = 0.720371 loss)
I0521 12:11:57.570132 20157 sgd_solver.cpp:106] Iteration 124500, lr = 0.0005
I0521 12:12:14.160218 20157 solver.cpp:237] Iteration 126000, loss = 0.602006
I0521 12:12:14.160269 20157 solver.cpp:253]     Train net output #0: loss = 0.60201 (* 1 = 0.60201 loss)
I0521 12:12:14.160284 20157 sgd_solver.cpp:106] Iteration 126000, lr = 0.0005
I0521 12:12:30.754825 20157 solver.cpp:237] Iteration 127500, loss = 1.12078
I0521 12:12:30.754969 20157 solver.cpp:253]     Train net output #0: loss = 1.12079 (* 1 = 1.12079 loss)
I0521 12:12:30.754982 20157 sgd_solver.cpp:106] Iteration 127500, lr = 0.0005
I0521 12:12:47.364794 20157 solver.cpp:237] Iteration 129000, loss = 1.65839
I0521 12:12:47.364842 20157 solver.cpp:253]     Train net output #0: loss = 1.65839 (* 1 = 1.65839 loss)
I0521 12:12:47.364856 20157 sgd_solver.cpp:106] Iteration 129000, lr = 0.0005
I0521 12:13:26.093487 20157 solver.cpp:237] Iteration 130500, loss = 0.601261
I0521 12:13:26.093652 20157 solver.cpp:253]     Train net output #0: loss = 0.601265 (* 1 = 0.601265 loss)
I0521 12:13:26.093667 20157 sgd_solver.cpp:106] Iteration 130500, lr = 0.0005
I0521 12:13:42.690806 20157 solver.cpp:237] Iteration 132000, loss = 1.39908
I0521 12:13:42.690845 20157 solver.cpp:253]     Train net output #0: loss = 1.39908 (* 1 = 1.39908 loss)
I0521 12:13:42.690857 20157 sgd_solver.cpp:106] Iteration 132000, lr = 0.0005
I0521 12:13:59.323107 20157 solver.cpp:237] Iteration 133500, loss = 1.20164
I0521 12:13:59.323264 20157 solver.cpp:253]     Train net output #0: loss = 1.20165 (* 1 = 1.20165 loss)
I0521 12:13:59.323278 20157 sgd_solver.cpp:106] Iteration 133500, lr = 0.0005
I0521 12:14:15.913745 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_135000.caffemodel
I0521 12:14:15.961410 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_135000.solverstate
I0521 12:14:15.992184 20157 solver.cpp:237] Iteration 135000, loss = 1.13553
I0521 12:14:15.992236 20157 solver.cpp:253]     Train net output #0: loss = 1.13554 (* 1 = 1.13554 loss)
I0521 12:14:15.992250 20157 sgd_solver.cpp:106] Iteration 135000, lr = 0.0005
I0521 12:14:32.599463 20157 solver.cpp:237] Iteration 136500, loss = 0.972686
I0521 12:14:32.599617 20157 solver.cpp:253]     Train net output #0: loss = 0.972689 (* 1 = 0.972689 loss)
I0521 12:14:32.599632 20157 sgd_solver.cpp:106] Iteration 136500, lr = 0.0005
I0521 12:14:49.176065 20157 solver.cpp:237] Iteration 138000, loss = 1.83817
I0521 12:14:49.176117 20157 solver.cpp:253]     Train net output #0: loss = 1.83817 (* 1 = 1.83817 loss)
I0521 12:14:49.176131 20157 sgd_solver.cpp:106] Iteration 138000, lr = 0.0005
I0521 12:15:05.812348 20157 solver.cpp:237] Iteration 139500, loss = 0.974346
I0521 12:15:05.812518 20157 solver.cpp:253]     Train net output #0: loss = 0.974349 (* 1 = 0.974349 loss)
I0521 12:15:05.812533 20157 sgd_solver.cpp:106] Iteration 139500, lr = 0.0005
I0521 12:15:44.861484 20157 solver.cpp:237] Iteration 141000, loss = 1.316
I0521 12:15:44.861654 20157 solver.cpp:253]     Train net output #0: loss = 1.31601 (* 1 = 1.31601 loss)
I0521 12:15:44.861667 20157 sgd_solver.cpp:106] Iteration 141000, lr = 0.0005
I0521 12:16:01.779737 20157 solver.cpp:237] Iteration 142500, loss = 1.46901
I0521 12:16:01.779783 20157 solver.cpp:253]     Train net output #0: loss = 1.46902 (* 1 = 1.46902 loss)
I0521 12:16:01.779796 20157 sgd_solver.cpp:106] Iteration 142500, lr = 0.0005
I0521 12:16:18.603093 20157 solver.cpp:237] Iteration 144000, loss = 1.26777
I0521 12:16:18.603250 20157 solver.cpp:253]     Train net output #0: loss = 1.26777 (* 1 = 1.26777 loss)
I0521 12:16:18.603262 20157 sgd_solver.cpp:106] Iteration 144000, lr = 0.0005
I0521 12:16:35.450435 20157 solver.cpp:237] Iteration 145500, loss = 1.25297
I0521 12:16:35.450471 20157 solver.cpp:253]     Train net output #0: loss = 1.25297 (* 1 = 1.25297 loss)
I0521 12:16:35.450487 20157 sgd_solver.cpp:106] Iteration 145500, lr = 0.0005
I0521 12:16:52.309669 20157 solver.cpp:237] Iteration 147000, loss = 1.03393
I0521 12:16:52.309821 20157 solver.cpp:253]     Train net output #0: loss = 1.03393 (* 1 = 1.03393 loss)
I0521 12:16:52.309835 20157 sgd_solver.cpp:106] Iteration 147000, lr = 0.0005
I0521 12:17:09.136871 20157 solver.cpp:237] Iteration 148500, loss = 1.67166
I0521 12:17:09.136919 20157 solver.cpp:253]     Train net output #0: loss = 1.67166 (* 1 = 1.67166 loss)
I0521 12:17:09.136936 20157 sgd_solver.cpp:106] Iteration 148500, lr = 0.0005
I0521 12:17:25.957710 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_150000.caffemodel
I0521 12:17:26.005414 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_150000.solverstate
I0521 12:17:26.032815 20157 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 12:18:25.601404 20157 solver.cpp:409]     Test net output #0: accuracy = 0.872584
I0521 12:18:25.601567 20157 solver.cpp:409]     Test net output #1: loss = 0.420858 (* 1 = 0.420858 loss)
I0521 12:18:46.479542 20157 solver.cpp:237] Iteration 150000, loss = 1.29274
I0521 12:18:46.479596 20157 solver.cpp:253]     Train net output #0: loss = 1.29275 (* 1 = 1.29275 loss)
I0521 12:18:46.479612 20157 sgd_solver.cpp:106] Iteration 150000, lr = 0.0005
I0521 12:19:03.689038 20157 solver.cpp:237] Iteration 151500, loss = 1.67443
I0521 12:19:03.689204 20157 solver.cpp:253]     Train net output #0: loss = 1.67443 (* 1 = 1.67443 loss)
I0521 12:19:03.689218 20157 sgd_solver.cpp:106] Iteration 151500, lr = 0.0005
I0521 12:19:20.897421 20157 solver.cpp:237] Iteration 153000, loss = 1.6141
I0521 12:19:20.897469 20157 solver.cpp:253]     Train net output #0: loss = 1.6141 (* 1 = 1.6141 loss)
I0521 12:19:20.897483 20157 sgd_solver.cpp:106] Iteration 153000, lr = 0.0005
I0521 12:19:38.028605 20157 solver.cpp:237] Iteration 154500, loss = 1.03763
I0521 12:19:38.028751 20157 solver.cpp:253]     Train net output #0: loss = 1.03763 (* 1 = 1.03763 loss)
I0521 12:19:38.028767 20157 sgd_solver.cpp:106] Iteration 154500, lr = 0.0005
I0521 12:19:55.227380 20157 solver.cpp:237] Iteration 156000, loss = 1.10441
I0521 12:19:55.227427 20157 solver.cpp:253]     Train net output #0: loss = 1.10441 (* 1 = 1.10441 loss)
I0521 12:19:55.227442 20157 sgd_solver.cpp:106] Iteration 156000, lr = 0.0005
I0521 12:20:12.375845 20157 solver.cpp:237] Iteration 157500, loss = 1.03289
I0521 12:20:12.376019 20157 solver.cpp:253]     Train net output #0: loss = 1.03289 (* 1 = 1.03289 loss)
I0521 12:20:12.376035 20157 sgd_solver.cpp:106] Iteration 157500, lr = 0.0005
I0521 12:20:29.572125 20157 solver.cpp:237] Iteration 159000, loss = 1.14532
I0521 12:20:29.572171 20157 solver.cpp:253]     Train net output #0: loss = 1.14532 (* 1 = 1.14532 loss)
I0521 12:20:29.572188 20157 sgd_solver.cpp:106] Iteration 159000, lr = 0.0005
I0521 12:21:07.579309 20157 solver.cpp:237] Iteration 160500, loss = 1.74712
I0521 12:21:07.579479 20157 solver.cpp:253]     Train net output #0: loss = 1.74713 (* 1 = 1.74713 loss)
I0521 12:21:07.579494 20157 sgd_solver.cpp:106] Iteration 160500, lr = 0.0005
I0521 12:21:24.735597 20157 solver.cpp:237] Iteration 162000, loss = 1.25537
I0521 12:21:24.735649 20157 solver.cpp:253]     Train net output #0: loss = 1.25538 (* 1 = 1.25538 loss)
I0521 12:21:24.735663 20157 sgd_solver.cpp:106] Iteration 162000, lr = 0.0005
I0521 12:21:41.895211 20157 solver.cpp:237] Iteration 163500, loss = 1.45157
I0521 12:21:41.895359 20157 solver.cpp:253]     Train net output #0: loss = 1.45157 (* 1 = 1.45157 loss)
I0521 12:21:41.895372 20157 sgd_solver.cpp:106] Iteration 163500, lr = 0.0005
I0521 12:21:58.840692 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_165000.caffemodel
I0521 12:21:58.886735 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_165000.solverstate
I0521 12:21:58.915314 20157 solver.cpp:237] Iteration 165000, loss = 1.13256
I0521 12:21:58.915360 20157 solver.cpp:253]     Train net output #0: loss = 1.13256 (* 1 = 1.13256 loss)
I0521 12:21:58.915375 20157 sgd_solver.cpp:106] Iteration 165000, lr = 0.0005
I0521 12:22:15.867717 20157 solver.cpp:237] Iteration 166500, loss = 0.708336
I0521 12:22:15.867897 20157 solver.cpp:253]     Train net output #0: loss = 0.70834 (* 1 = 0.70834 loss)
I0521 12:22:15.867911 20157 sgd_solver.cpp:106] Iteration 166500, lr = 0.0005
I0521 12:22:32.812321 20157 solver.cpp:237] Iteration 168000, loss = 1.14846
I0521 12:22:32.812358 20157 solver.cpp:253]     Train net output #0: loss = 1.14846 (* 1 = 1.14846 loss)
I0521 12:22:32.812376 20157 sgd_solver.cpp:106] Iteration 168000, lr = 0.0005
I0521 12:22:49.750530 20157 solver.cpp:237] Iteration 169500, loss = 1.10939
I0521 12:22:49.750682 20157 solver.cpp:253]     Train net output #0: loss = 1.1094 (* 1 = 1.1094 loss)
I0521 12:22:49.750696 20157 sgd_solver.cpp:106] Iteration 169500, lr = 0.0005
I0521 12:23:27.508702 20157 solver.cpp:237] Iteration 171000, loss = 0.714198
I0521 12:23:27.508872 20157 solver.cpp:253]     Train net output #0: loss = 0.714201 (* 1 = 0.714201 loss)
I0521 12:23:27.508887 20157 sgd_solver.cpp:106] Iteration 171000, lr = 0.0005
I0521 12:23:44.445873 20157 solver.cpp:237] Iteration 172500, loss = 1.2464
I0521 12:23:44.445909 20157 solver.cpp:253]     Train net output #0: loss = 1.2464 (* 1 = 1.2464 loss)
I0521 12:23:44.445924 20157 sgd_solver.cpp:106] Iteration 172500, lr = 0.0005
I0521 12:24:01.415721 20157 solver.cpp:237] Iteration 174000, loss = 1.52618
I0521 12:24:01.415889 20157 solver.cpp:253]     Train net output #0: loss = 1.52618 (* 1 = 1.52618 loss)
I0521 12:24:01.415904 20157 sgd_solver.cpp:106] Iteration 174000, lr = 0.0005
I0521 12:24:18.336609 20157 solver.cpp:237] Iteration 175500, loss = 0.481922
I0521 12:24:18.336654 20157 solver.cpp:253]     Train net output #0: loss = 0.481926 (* 1 = 0.481926 loss)
I0521 12:24:18.336670 20157 sgd_solver.cpp:106] Iteration 175500, lr = 0.0005
I0521 12:24:35.299945 20157 solver.cpp:237] Iteration 177000, loss = 1.36331
I0521 12:24:35.300091 20157 solver.cpp:253]     Train net output #0: loss = 1.36332 (* 1 = 1.36332 loss)
I0521 12:24:35.300103 20157 sgd_solver.cpp:106] Iteration 177000, lr = 0.0005
I0521 12:24:52.397302 20157 solver.cpp:237] Iteration 178500, loss = 1.79508
I0521 12:24:52.397352 20157 solver.cpp:253]     Train net output #0: loss = 1.79508 (* 1 = 1.79508 loss)
I0521 12:24:52.397366 20157 sgd_solver.cpp:106] Iteration 178500, lr = 0.0005
I0521 12:25:09.564280 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_180000.caffemodel
I0521 12:25:09.610584 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_180000.solverstate
I0521 12:25:09.636222 20157 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 12:26:29.736852 20157 solver.cpp:409]     Test net output #0: accuracy = 0.876684
I0521 12:26:29.737030 20157 solver.cpp:409]     Test net output #1: loss = 0.381031 (* 1 = 0.381031 loss)
I0521 12:26:50.569025 20157 solver.cpp:237] Iteration 180000, loss = 0.940702
I0521 12:26:50.569079 20157 solver.cpp:253]     Train net output #0: loss = 0.940706 (* 1 = 0.940706 loss)
I0521 12:26:50.569094 20157 sgd_solver.cpp:106] Iteration 180000, lr = 0.0005
I0521 12:27:07.337585 20157 solver.cpp:237] Iteration 181500, loss = 1.16382
I0521 12:27:07.337741 20157 solver.cpp:253]     Train net output #0: loss = 1.16383 (* 1 = 1.16383 loss)
I0521 12:27:07.337756 20157 sgd_solver.cpp:106] Iteration 181500, lr = 0.0005
I0521 12:27:24.104032 20157 solver.cpp:237] Iteration 183000, loss = 1.3617
I0521 12:27:24.104079 20157 solver.cpp:253]     Train net output #0: loss = 1.3617 (* 1 = 1.3617 loss)
I0521 12:27:24.104094 20157 sgd_solver.cpp:106] Iteration 183000, lr = 0.0005
I0521 12:27:41.021513 20157 solver.cpp:237] Iteration 184500, loss = 1.33802
I0521 12:27:41.021677 20157 solver.cpp:253]     Train net output #0: loss = 1.33803 (* 1 = 1.33803 loss)
I0521 12:27:41.021692 20157 sgd_solver.cpp:106] Iteration 184500, lr = 0.0005
I0521 12:27:58.081182 20157 solver.cpp:237] Iteration 186000, loss = 1.04578
I0521 12:27:58.081218 20157 solver.cpp:253]     Train net output #0: loss = 1.04579 (* 1 = 1.04579 loss)
I0521 12:27:58.081233 20157 sgd_solver.cpp:106] Iteration 186000, lr = 0.0005
I0521 12:28:15.077870 20157 solver.cpp:237] Iteration 187500, loss = 1.52987
I0521 12:28:15.078033 20157 solver.cpp:253]     Train net output #0: loss = 1.52988 (* 1 = 1.52988 loss)
I0521 12:28:15.078048 20157 sgd_solver.cpp:106] Iteration 187500, lr = 0.0005
I0521 12:28:32.126006 20157 solver.cpp:237] Iteration 189000, loss = 0.652403
I0521 12:28:32.126054 20157 solver.cpp:253]     Train net output #0: loss = 0.652408 (* 1 = 0.652408 loss)
I0521 12:28:32.126067 20157 sgd_solver.cpp:106] Iteration 189000, lr = 0.0005
I0521 12:29:09.990043 20157 solver.cpp:237] Iteration 190500, loss = 0.910684
I0521 12:29:09.990216 20157 solver.cpp:253]     Train net output #0: loss = 0.910691 (* 1 = 0.910691 loss)
I0521 12:29:09.990231 20157 sgd_solver.cpp:106] Iteration 190500, lr = 0.0005
I0521 12:29:27.032580 20157 solver.cpp:237] Iteration 192000, loss = 0.670634
I0521 12:29:27.032631 20157 solver.cpp:253]     Train net output #0: loss = 0.670641 (* 1 = 0.670641 loss)
I0521 12:29:27.032645 20157 sgd_solver.cpp:106] Iteration 192000, lr = 0.0005
I0521 12:29:44.086868 20157 solver.cpp:237] Iteration 193500, loss = 1.27787
I0521 12:29:44.087033 20157 solver.cpp:253]     Train net output #0: loss = 1.27788 (* 1 = 1.27788 loss)
I0521 12:29:44.087047 20157 sgd_solver.cpp:106] Iteration 193500, lr = 0.0005
I0521 12:30:01.109866 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_195000.caffemodel
I0521 12:30:01.156251 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_195000.solverstate
I0521 12:30:01.184785 20157 solver.cpp:237] Iteration 195000, loss = 1.53094
I0521 12:30:01.184828 20157 solver.cpp:253]     Train net output #0: loss = 1.53094 (* 1 = 1.53094 loss)
I0521 12:30:01.184845 20157 sgd_solver.cpp:106] Iteration 195000, lr = 0.0005
I0521 12:30:18.216893 20157 solver.cpp:237] Iteration 196500, loss = 1.04112
I0521 12:30:18.217068 20157 solver.cpp:253]     Train net output #0: loss = 1.04113 (* 1 = 1.04113 loss)
I0521 12:30:18.217085 20157 sgd_solver.cpp:106] Iteration 196500, lr = 0.0005
I0521 12:30:35.246912 20157 solver.cpp:237] Iteration 198000, loss = 0.658066
I0521 12:30:35.246955 20157 solver.cpp:253]     Train net output #0: loss = 0.658071 (* 1 = 0.658071 loss)
I0521 12:30:35.246974 20157 sgd_solver.cpp:106] Iteration 198000, lr = 0.0005
I0521 12:30:52.263828 20157 solver.cpp:237] Iteration 199500, loss = 0.858798
I0521 12:30:52.263978 20157 solver.cpp:253]     Train net output #0: loss = 0.858803 (* 1 = 0.858803 loss)
I0521 12:30:52.263993 20157 sgd_solver.cpp:106] Iteration 199500, lr = 0.0005
I0521 12:31:30.153472 20157 solver.cpp:237] Iteration 201000, loss = 1.70779
I0521 12:31:30.153648 20157 solver.cpp:253]     Train net output #0: loss = 1.7078 (* 1 = 1.7078 loss)
I0521 12:31:30.153662 20157 sgd_solver.cpp:106] Iteration 201000, lr = 0.0005
I0521 12:31:47.171030 20157 solver.cpp:237] Iteration 202500, loss = 1.19039
I0521 12:31:47.171080 20157 solver.cpp:253]     Train net output #0: loss = 1.1904 (* 1 = 1.1904 loss)
I0521 12:31:47.171094 20157 sgd_solver.cpp:106] Iteration 202500, lr = 0.0005
I0521 12:32:04.213212 20157 solver.cpp:237] Iteration 204000, loss = 1.53415
I0521 12:32:04.213362 20157 solver.cpp:253]     Train net output #0: loss = 1.53416 (* 1 = 1.53416 loss)
I0521 12:32:04.213376 20157 sgd_solver.cpp:106] Iteration 204000, lr = 0.0005
I0521 12:32:21.262233 20157 solver.cpp:237] Iteration 205500, loss = 1.49836
I0521 12:32:21.262282 20157 solver.cpp:253]     Train net output #0: loss = 1.49837 (* 1 = 1.49837 loss)
I0521 12:32:21.262297 20157 sgd_solver.cpp:106] Iteration 205500, lr = 0.0005
I0521 12:32:38.310123 20157 solver.cpp:237] Iteration 207000, loss = 1.70424
I0521 12:32:38.310288 20157 solver.cpp:253]     Train net output #0: loss = 1.70424 (* 1 = 1.70424 loss)
I0521 12:32:38.310303 20157 sgd_solver.cpp:106] Iteration 207000, lr = 0.0005
I0521 12:32:55.328701 20157 solver.cpp:237] Iteration 208500, loss = 1.11361
I0521 12:32:55.328735 20157 solver.cpp:253]     Train net output #0: loss = 1.11361 (* 1 = 1.11361 loss)
I0521 12:32:55.328750 20157 sgd_solver.cpp:106] Iteration 208500, lr = 0.0005
I0521 12:33:12.340857 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_210000.caffemodel
I0521 12:33:12.386363 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_210000.solverstate
I0521 12:33:12.411713 20157 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 12:34:11.265180 20157 solver.cpp:409]     Test net output #0: accuracy = 0.876207
I0521 12:34:11.265357 20157 solver.cpp:409]     Test net output #1: loss = 0.429667 (* 1 = 0.429667 loss)
I0521 12:34:32.117652 20157 solver.cpp:237] Iteration 210000, loss = 1.17996
I0521 12:34:32.117707 20157 solver.cpp:253]     Train net output #0: loss = 1.17997 (* 1 = 1.17997 loss)
I0521 12:34:32.117722 20157 sgd_solver.cpp:106] Iteration 210000, lr = 0.0005
I0521 12:34:48.944871 20157 solver.cpp:237] Iteration 211500, loss = 0.931013
I0521 12:34:48.945040 20157 solver.cpp:253]     Train net output #0: loss = 0.931018 (* 1 = 0.931018 loss)
I0521 12:34:48.945056 20157 sgd_solver.cpp:106] Iteration 211500, lr = 0.0005
I0521 12:35:05.817339 20157 solver.cpp:237] Iteration 213000, loss = 0.957958
I0521 12:35:05.817384 20157 solver.cpp:253]     Train net output #0: loss = 0.957963 (* 1 = 0.957963 loss)
I0521 12:35:05.817401 20157 sgd_solver.cpp:106] Iteration 213000, lr = 0.0005
I0521 12:35:22.653370 20157 solver.cpp:237] Iteration 214500, loss = 1.63615
I0521 12:35:22.653532 20157 solver.cpp:253]     Train net output #0: loss = 1.63616 (* 1 = 1.63616 loss)
I0521 12:35:22.653545 20157 sgd_solver.cpp:106] Iteration 214500, lr = 0.0005
I0521 12:35:39.520215 20157 solver.cpp:237] Iteration 216000, loss = 1.10969
I0521 12:35:39.520262 20157 solver.cpp:253]     Train net output #0: loss = 1.1097 (* 1 = 1.1097 loss)
I0521 12:35:39.520277 20157 sgd_solver.cpp:106] Iteration 216000, lr = 0.0005
I0521 12:35:56.411645 20157 solver.cpp:237] Iteration 217500, loss = 1.64297
I0521 12:35:56.411821 20157 solver.cpp:253]     Train net output #0: loss = 1.64297 (* 1 = 1.64297 loss)
I0521 12:35:56.411835 20157 sgd_solver.cpp:106] Iteration 217500, lr = 0.0005
I0521 12:36:13.308471 20157 solver.cpp:237] Iteration 219000, loss = 1.10881
I0521 12:36:13.308507 20157 solver.cpp:253]     Train net output #0: loss = 1.10881 (* 1 = 1.10881 loss)
I0521 12:36:13.308523 20157 sgd_solver.cpp:106] Iteration 219000, lr = 0.0005
I0521 12:36:50.861318 20157 solver.cpp:237] Iteration 220500, loss = 1.00718
I0521 12:36:50.861493 20157 solver.cpp:253]     Train net output #0: loss = 1.00718 (* 1 = 1.00718 loss)
I0521 12:36:50.861508 20157 sgd_solver.cpp:106] Iteration 220500, lr = 0.0005
I0521 12:37:07.486126 20157 solver.cpp:237] Iteration 222000, loss = 1.30351
I0521 12:37:07.486163 20157 solver.cpp:253]     Train net output #0: loss = 1.30352 (* 1 = 1.30352 loss)
I0521 12:37:07.486176 20157 sgd_solver.cpp:106] Iteration 222000, lr = 0.0005
I0521 12:37:24.074610 20157 solver.cpp:237] Iteration 223500, loss = 0.894554
I0521 12:37:24.074784 20157 solver.cpp:253]     Train net output #0: loss = 0.894561 (* 1 = 0.894561 loss)
I0521 12:37:24.074800 20157 sgd_solver.cpp:106] Iteration 223500, lr = 0.0005
I0521 12:37:40.648306 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_225000.caffemodel
I0521 12:37:40.695511 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_225000.solverstate
I0521 12:37:40.725963 20157 solver.cpp:237] Iteration 225000, loss = 0.456951
I0521 12:37:40.726014 20157 solver.cpp:253]     Train net output #0: loss = 0.456958 (* 1 = 0.456958 loss)
I0521 12:37:40.726029 20157 sgd_solver.cpp:106] Iteration 225000, lr = 0.0005
I0521 12:37:57.338004 20157 solver.cpp:237] Iteration 226500, loss = 1.4736
I0521 12:37:57.338161 20157 solver.cpp:253]     Train net output #0: loss = 1.47361 (* 1 = 1.47361 loss)
I0521 12:37:57.338176 20157 sgd_solver.cpp:106] Iteration 226500, lr = 0.0005
I0521 12:38:14.107038 20157 solver.cpp:237] Iteration 228000, loss = 1.12057
I0521 12:38:14.107090 20157 solver.cpp:253]     Train net output #0: loss = 1.12058 (* 1 = 1.12058 loss)
I0521 12:38:14.107106 20157 sgd_solver.cpp:106] Iteration 228000, lr = 0.0005
I0521 12:38:30.867341 20157 solver.cpp:237] Iteration 229500, loss = 0.759035
I0521 12:38:30.867516 20157 solver.cpp:253]     Train net output #0: loss = 0.759042 (* 1 = 0.759042 loss)
I0521 12:38:30.867533 20157 sgd_solver.cpp:106] Iteration 229500, lr = 0.0005
I0521 12:39:08.465273 20157 solver.cpp:237] Iteration 231000, loss = 0.891974
I0521 12:39:08.465451 20157 solver.cpp:253]     Train net output #0: loss = 0.891981 (* 1 = 0.891981 loss)
I0521 12:39:08.465467 20157 sgd_solver.cpp:106] Iteration 231000, lr = 0.0005
I0521 12:39:25.198376 20157 solver.cpp:237] Iteration 232500, loss = 0.976065
I0521 12:39:25.198427 20157 solver.cpp:253]     Train net output #0: loss = 0.976072 (* 1 = 0.976072 loss)
I0521 12:39:25.198441 20157 sgd_solver.cpp:106] Iteration 232500, lr = 0.0005
I0521 12:39:41.957036 20157 solver.cpp:237] Iteration 234000, loss = 0.972701
I0521 12:39:41.957203 20157 solver.cpp:253]     Train net output #0: loss = 0.972708 (* 1 = 0.972708 loss)
I0521 12:39:41.957218 20157 sgd_solver.cpp:106] Iteration 234000, lr = 0.0005
I0521 12:39:58.693600 20157 solver.cpp:237] Iteration 235500, loss = 1.54071
I0521 12:39:58.693636 20157 solver.cpp:253]     Train net output #0: loss = 1.54072 (* 1 = 1.54072 loss)
I0521 12:39:58.693650 20157 sgd_solver.cpp:106] Iteration 235500, lr = 0.0005
I0521 12:40:15.455471 20157 solver.cpp:237] Iteration 237000, loss = 1.39129
I0521 12:40:15.455646 20157 solver.cpp:253]     Train net output #0: loss = 1.3913 (* 1 = 1.3913 loss)
I0521 12:40:15.455662 20157 sgd_solver.cpp:106] Iteration 237000, lr = 0.0005
I0521 12:40:32.198142 20157 solver.cpp:237] Iteration 238500, loss = 0.47492
I0521 12:40:32.198194 20157 solver.cpp:253]     Train net output #0: loss = 0.474927 (* 1 = 0.474927 loss)
I0521 12:40:32.198207 20157 sgd_solver.cpp:106] Iteration 238500, lr = 0.0005
I0521 12:40:48.936282 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_240000.caffemodel
I0521 12:40:48.982297 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_240000.solverstate
I0521 12:40:49.007961 20157 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 12:42:09.324012 20157 solver.cpp:409]     Test net output #0: accuracy = 0.882432
I0521 12:42:09.324182 20157 solver.cpp:409]     Test net output #1: loss = 0.371408 (* 1 = 0.371408 loss)
I0521 12:42:30.212420 20157 solver.cpp:237] Iteration 240000, loss = 1.10018
I0521 12:42:30.212474 20157 solver.cpp:253]     Train net output #0: loss = 1.10018 (* 1 = 1.10018 loss)
I0521 12:42:30.212489 20157 sgd_solver.cpp:106] Iteration 240000, lr = 0.0005
I0521 12:42:46.829068 20157 solver.cpp:237] Iteration 241500, loss = 0.863821
I0521 12:42:46.829241 20157 solver.cpp:253]     Train net output #0: loss = 0.863828 (* 1 = 0.863828 loss)
I0521 12:42:46.829255 20157 sgd_solver.cpp:106] Iteration 241500, lr = 0.0005
I0521 12:43:03.463580 20157 solver.cpp:237] Iteration 243000, loss = 1.20352
I0521 12:43:03.463631 20157 solver.cpp:253]     Train net output #0: loss = 1.20353 (* 1 = 1.20353 loss)
I0521 12:43:03.463645 20157 sgd_solver.cpp:106] Iteration 243000, lr = 0.0005
I0521 12:43:20.103277 20157 solver.cpp:237] Iteration 244500, loss = 1.27057
I0521 12:43:20.103430 20157 solver.cpp:253]     Train net output #0: loss = 1.27058 (* 1 = 1.27058 loss)
I0521 12:43:20.103443 20157 sgd_solver.cpp:106] Iteration 244500, lr = 0.0005
I0521 12:43:36.649623 20157 solver.cpp:237] Iteration 246000, loss = 1.32266
I0521 12:43:36.649674 20157 solver.cpp:253]     Train net output #0: loss = 1.32267 (* 1 = 1.32267 loss)
I0521 12:43:36.649688 20157 sgd_solver.cpp:106] Iteration 246000, lr = 0.0005
I0521 12:43:53.244925 20157 solver.cpp:237] Iteration 247500, loss = 1.14514
I0521 12:43:53.245110 20157 solver.cpp:253]     Train net output #0: loss = 1.14514 (* 1 = 1.14514 loss)
I0521 12:43:53.245123 20157 sgd_solver.cpp:106] Iteration 247500, lr = 0.0005
I0521 12:44:09.879793 20157 solver.cpp:237] Iteration 249000, loss = 1.28025
I0521 12:44:09.879830 20157 solver.cpp:253]     Train net output #0: loss = 1.28025 (* 1 = 1.28025 loss)
I0521 12:44:09.879847 20157 sgd_solver.cpp:106] Iteration 249000, lr = 0.0005
I0521 12:44:47.340021 20157 solver.cpp:237] Iteration 250500, loss = 1.11236
I0521 12:44:47.340198 20157 solver.cpp:253]     Train net output #0: loss = 1.11237 (* 1 = 1.11237 loss)
I0521 12:44:47.340212 20157 sgd_solver.cpp:106] Iteration 250500, lr = 0.0005
I0521 12:45:03.947829 20157 solver.cpp:237] Iteration 252000, loss = 1.34835
I0521 12:45:03.947872 20157 solver.cpp:253]     Train net output #0: loss = 1.34836 (* 1 = 1.34836 loss)
I0521 12:45:03.947895 20157 sgd_solver.cpp:106] Iteration 252000, lr = 0.0005
I0521 12:45:20.562273 20157 solver.cpp:237] Iteration 253500, loss = 1.08447
I0521 12:45:20.562425 20157 solver.cpp:253]     Train net output #0: loss = 1.08448 (* 1 = 1.08448 loss)
I0521 12:45:20.562439 20157 sgd_solver.cpp:106] Iteration 253500, lr = 0.0005
I0521 12:45:37.149325 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_255000.caffemodel
I0521 12:45:37.195070 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_255000.solverstate
I0521 12:45:37.224206 20157 solver.cpp:237] Iteration 255000, loss = 1.33135
I0521 12:45:37.224249 20157 solver.cpp:253]     Train net output #0: loss = 1.33136 (* 1 = 1.33136 loss)
I0521 12:45:37.224267 20157 sgd_solver.cpp:106] Iteration 255000, lr = 0.0005
I0521 12:45:53.853024 20157 solver.cpp:237] Iteration 256500, loss = 0.919586
I0521 12:45:53.853196 20157 solver.cpp:253]     Train net output #0: loss = 0.919595 (* 1 = 0.919595 loss)
I0521 12:45:53.853211 20157 sgd_solver.cpp:106] Iteration 256500, lr = 0.0005
I0521 12:46:10.491364 20157 solver.cpp:237] Iteration 258000, loss = 1.29858
I0521 12:46:10.491400 20157 solver.cpp:253]     Train net output #0: loss = 1.29859 (* 1 = 1.29859 loss)
I0521 12:46:10.491420 20157 sgd_solver.cpp:106] Iteration 258000, lr = 0.0005
I0521 12:46:27.094449 20157 solver.cpp:237] Iteration 259500, loss = 0.823249
I0521 12:46:27.094614 20157 solver.cpp:253]     Train net output #0: loss = 0.823256 (* 1 = 0.823256 loss)
I0521 12:46:27.094630 20157 sgd_solver.cpp:106] Iteration 259500, lr = 0.0005
I0521 12:47:04.588454 20157 solver.cpp:237] Iteration 261000, loss = 1.72942
I0521 12:47:04.588631 20157 solver.cpp:253]     Train net output #0: loss = 1.72943 (* 1 = 1.72943 loss)
I0521 12:47:04.588649 20157 sgd_solver.cpp:106] Iteration 261000, lr = 0.0005
I0521 12:47:21.198093 20157 solver.cpp:237] Iteration 262500, loss = 2.03806
I0521 12:47:21.198138 20157 solver.cpp:253]     Train net output #0: loss = 2.03807 (* 1 = 2.03807 loss)
I0521 12:47:21.198155 20157 sgd_solver.cpp:106] Iteration 262500, lr = 0.0005
I0521 12:47:37.825639 20157 solver.cpp:237] Iteration 264000, loss = 1.73582
I0521 12:47:37.825803 20157 solver.cpp:253]     Train net output #0: loss = 1.73583 (* 1 = 1.73583 loss)
I0521 12:47:37.825816 20157 sgd_solver.cpp:106] Iteration 264000, lr = 0.0005
I0521 12:47:54.434306 20157 solver.cpp:237] Iteration 265500, loss = 0.712406
I0521 12:47:54.434350 20157 solver.cpp:253]     Train net output #0: loss = 0.712414 (* 1 = 0.712414 loss)
I0521 12:47:54.434365 20157 sgd_solver.cpp:106] Iteration 265500, lr = 0.0005
I0521 12:48:11.033133 20157 solver.cpp:237] Iteration 267000, loss = 1.24972
I0521 12:48:11.033299 20157 solver.cpp:253]     Train net output #0: loss = 1.24972 (* 1 = 1.24972 loss)
I0521 12:48:11.033315 20157 sgd_solver.cpp:106] Iteration 267000, lr = 0.0005
I0521 12:48:27.652606 20157 solver.cpp:237] Iteration 268500, loss = 1.84653
I0521 12:48:27.652649 20157 solver.cpp:253]     Train net output #0: loss = 1.84654 (* 1 = 1.84654 loss)
I0521 12:48:27.652667 20157 sgd_solver.cpp:106] Iteration 268500, lr = 0.0005
I0521 12:48:44.232808 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_270000.caffemodel
I0521 12:48:44.279317 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_270000.solverstate
I0521 12:48:44.304711 20157 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 12:49:43.881333 20157 solver.cpp:409]     Test net output #0: accuracy = 0.882624
I0521 12:49:43.881513 20157 solver.cpp:409]     Test net output #1: loss = 0.371765 (* 1 = 0.371765 loss)
I0521 12:50:04.770297 20157 solver.cpp:237] Iteration 270000, loss = 2.67223
I0521 12:50:04.770350 20157 solver.cpp:253]     Train net output #0: loss = 2.67224 (* 1 = 2.67224 loss)
I0521 12:50:04.770364 20157 sgd_solver.cpp:106] Iteration 270000, lr = 0.0005
I0521 12:50:21.819620 20157 solver.cpp:237] Iteration 271500, loss = 1.70047
I0521 12:50:21.819792 20157 solver.cpp:253]     Train net output #0: loss = 1.70048 (* 1 = 1.70048 loss)
I0521 12:50:21.819807 20157 sgd_solver.cpp:106] Iteration 271500, lr = 0.0005
I0521 12:50:38.841756 20157 solver.cpp:237] Iteration 273000, loss = 1.04781
I0521 12:50:38.841804 20157 solver.cpp:253]     Train net output #0: loss = 1.04782 (* 1 = 1.04782 loss)
I0521 12:50:38.841820 20157 sgd_solver.cpp:106] Iteration 273000, lr = 0.0005
I0521 12:50:55.860868 20157 solver.cpp:237] Iteration 274500, loss = 1.16979
I0521 12:50:55.861037 20157 solver.cpp:253]     Train net output #0: loss = 1.16979 (* 1 = 1.16979 loss)
I0521 12:50:55.861050 20157 sgd_solver.cpp:106] Iteration 274500, lr = 0.0005
I0521 12:51:12.916254 20157 solver.cpp:237] Iteration 276000, loss = 1.03572
I0521 12:51:12.916285 20157 solver.cpp:253]     Train net output #0: loss = 1.03572 (* 1 = 1.03572 loss)
I0521 12:51:12.916302 20157 sgd_solver.cpp:106] Iteration 276000, lr = 0.0005
I0521 12:51:29.942543 20157 solver.cpp:237] Iteration 277500, loss = 1.69651
I0521 12:51:29.942711 20157 solver.cpp:253]     Train net output #0: loss = 1.69652 (* 1 = 1.69652 loss)
I0521 12:51:29.942724 20157 sgd_solver.cpp:106] Iteration 277500, lr = 0.0005
I0521 12:51:46.973125 20157 solver.cpp:237] Iteration 279000, loss = 1.05058
I0521 12:51:46.973175 20157 solver.cpp:253]     Train net output #0: loss = 1.05059 (* 1 = 1.05059 loss)
I0521 12:51:46.973187 20157 sgd_solver.cpp:106] Iteration 279000, lr = 0.0005
I0521 12:52:24.918948 20157 solver.cpp:237] Iteration 280500, loss = 0.795073
I0521 12:52:24.919136 20157 solver.cpp:253]     Train net output #0: loss = 0.79508 (* 1 = 0.79508 loss)
I0521 12:52:24.919152 20157 sgd_solver.cpp:106] Iteration 280500, lr = 0.0005
I0521 12:52:41.910769 20157 solver.cpp:237] Iteration 282000, loss = 0.759653
I0521 12:52:41.910820 20157 solver.cpp:253]     Train net output #0: loss = 0.759661 (* 1 = 0.759661 loss)
I0521 12:52:41.910833 20157 sgd_solver.cpp:106] Iteration 282000, lr = 0.0005
I0521 12:52:58.960342 20157 solver.cpp:237] Iteration 283500, loss = 1.00705
I0521 12:52:58.960510 20157 solver.cpp:253]     Train net output #0: loss = 1.00706 (* 1 = 1.00706 loss)
I0521 12:52:58.960525 20157 sgd_solver.cpp:106] Iteration 283500, lr = 0.0005
I0521 12:53:15.989332 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_285000.caffemodel
I0521 12:53:16.037587 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_285000.solverstate
I0521 12:53:16.068255 20157 solver.cpp:237] Iteration 285000, loss = 3.46393
I0521 12:53:16.068305 20157 solver.cpp:253]     Train net output #0: loss = 3.46394 (* 1 = 3.46394 loss)
I0521 12:53:16.068318 20157 sgd_solver.cpp:106] Iteration 285000, lr = 0.0005
I0521 12:53:33.112344 20157 solver.cpp:237] Iteration 286500, loss = 1.25955
I0521 12:53:33.112520 20157 solver.cpp:253]     Train net output #0: loss = 1.25956 (* 1 = 1.25956 loss)
I0521 12:53:33.112535 20157 sgd_solver.cpp:106] Iteration 286500, lr = 0.0005
I0521 12:53:50.150979 20157 solver.cpp:237] Iteration 288000, loss = 2.12735
I0521 12:53:50.151027 20157 solver.cpp:253]     Train net output #0: loss = 2.12736 (* 1 = 2.12736 loss)
I0521 12:53:50.151044 20157 sgd_solver.cpp:106] Iteration 288000, lr = 0.0005
I0521 12:54:07.166496 20157 solver.cpp:237] Iteration 289500, loss = 1.19392
I0521 12:54:07.166652 20157 solver.cpp:253]     Train net output #0: loss = 1.19393 (* 1 = 1.19393 loss)
I0521 12:54:07.166667 20157 sgd_solver.cpp:106] Iteration 289500, lr = 0.0005
I0521 12:54:45.096189 20157 solver.cpp:237] Iteration 291000, loss = 0.998663
I0521 12:54:45.096369 20157 solver.cpp:253]     Train net output #0: loss = 0.998671 (* 1 = 0.998671 loss)
I0521 12:54:45.096384 20157 sgd_solver.cpp:106] Iteration 291000, lr = 0.0005
I0521 12:55:02.110761 20157 solver.cpp:237] Iteration 292500, loss = 1.33753
I0521 12:55:02.110797 20157 solver.cpp:253]     Train net output #0: loss = 1.33754 (* 1 = 1.33754 loss)
I0521 12:55:02.110810 20157 sgd_solver.cpp:106] Iteration 292500, lr = 0.0005
I0521 12:55:19.170461 20157 solver.cpp:237] Iteration 294000, loss = 1.10452
I0521 12:55:19.170640 20157 solver.cpp:253]     Train net output #0: loss = 1.10453 (* 1 = 1.10453 loss)
I0521 12:55:19.170656 20157 sgd_solver.cpp:106] Iteration 294000, lr = 0.0005
I0521 12:55:36.214198 20157 solver.cpp:237] Iteration 295500, loss = 0.781652
I0521 12:55:36.214243 20157 solver.cpp:253]     Train net output #0: loss = 0.781659 (* 1 = 0.781659 loss)
I0521 12:55:36.214257 20157 sgd_solver.cpp:106] Iteration 295500, lr = 0.0005
I0521 12:55:53.239792 20157 solver.cpp:237] Iteration 297000, loss = 1.21708
I0521 12:55:53.239953 20157 solver.cpp:253]     Train net output #0: loss = 1.21709 (* 1 = 1.21709 loss)
I0521 12:55:53.239966 20157 sgd_solver.cpp:106] Iteration 297000, lr = 0.0005
I0521 12:56:10.278070 20157 solver.cpp:237] Iteration 298500, loss = 0.816834
I0521 12:56:10.278111 20157 solver.cpp:253]     Train net output #0: loss = 0.816841 (* 1 = 0.816841 loss)
I0521 12:56:10.278126 20157 sgd_solver.cpp:106] Iteration 298500, lr = 0.0005
I0521 12:56:27.335930 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_300000.caffemodel
I0521 12:56:27.384429 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_300000.solverstate
I0521 12:56:27.412042 20157 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 12:57:48.000790 20157 solver.cpp:409]     Test net output #0: accuracy = 0.885441
I0521 12:57:48.000967 20157 solver.cpp:409]     Test net output #1: loss = 0.36054 (* 1 = 0.36054 loss)
I0521 12:58:08.885821 20157 solver.cpp:237] Iteration 300000, loss = 0.91421
I0521 12:58:08.885874 20157 solver.cpp:253]     Train net output #0: loss = 0.914216 (* 1 = 0.914216 loss)
I0521 12:58:08.885890 20157 sgd_solver.cpp:106] Iteration 300000, lr = 0.0005
I0521 12:58:25.778565 20157 solver.cpp:237] Iteration 301500, loss = 0.553368
I0521 12:58:25.778739 20157 solver.cpp:253]     Train net output #0: loss = 0.553375 (* 1 = 0.553375 loss)
I0521 12:58:25.778753 20157 sgd_solver.cpp:106] Iteration 301500, lr = 0.0005
I0521 12:58:42.692301 20157 solver.cpp:237] Iteration 303000, loss = 1.48094
I0521 12:58:42.692337 20157 solver.cpp:253]     Train net output #0: loss = 1.48094 (* 1 = 1.48094 loss)
I0521 12:58:42.692353 20157 sgd_solver.cpp:106] Iteration 303000, lr = 0.0005
I0521 12:58:59.557795 20157 solver.cpp:237] Iteration 304500, loss = 0.684945
I0521 12:58:59.557962 20157 solver.cpp:253]     Train net output #0: loss = 0.684951 (* 1 = 0.684951 loss)
I0521 12:58:59.557976 20157 sgd_solver.cpp:106] Iteration 304500, lr = 0.0005
I0521 12:59:16.440659 20157 solver.cpp:237] Iteration 306000, loss = 0.910697
I0521 12:59:16.440706 20157 solver.cpp:253]     Train net output #0: loss = 0.910704 (* 1 = 0.910704 loss)
I0521 12:59:16.440721 20157 sgd_solver.cpp:106] Iteration 306000, lr = 0.0005
I0521 12:59:33.322299 20157 solver.cpp:237] Iteration 307500, loss = 1.02659
I0521 12:59:33.322453 20157 solver.cpp:253]     Train net output #0: loss = 1.02659 (* 1 = 1.02659 loss)
I0521 12:59:33.322468 20157 sgd_solver.cpp:106] Iteration 307500, lr = 0.0005
I0521 12:59:50.256564 20157 solver.cpp:237] Iteration 309000, loss = 1.00425
I0521 12:59:50.256608 20157 solver.cpp:253]     Train net output #0: loss = 1.00426 (* 1 = 1.00426 loss)
I0521 12:59:50.256625 20157 sgd_solver.cpp:106] Iteration 309000, lr = 0.0005
I0521 13:00:28.201118 20157 solver.cpp:237] Iteration 310500, loss = 1.6898
I0521 13:00:28.201297 20157 solver.cpp:253]     Train net output #0: loss = 1.68981 (* 1 = 1.68981 loss)
I0521 13:00:28.201310 20157 sgd_solver.cpp:106] Iteration 310500, lr = 0.0005
I0521 13:00:45.232545 20157 solver.cpp:237] Iteration 312000, loss = 1.71245
I0521 13:00:45.232591 20157 solver.cpp:253]     Train net output #0: loss = 1.71246 (* 1 = 1.71246 loss)
I0521 13:00:45.232604 20157 sgd_solver.cpp:106] Iteration 312000, lr = 0.0005
I0521 13:01:02.028465 20157 solver.cpp:237] Iteration 313500, loss = 1.44991
I0521 13:01:02.028651 20157 solver.cpp:253]     Train net output #0: loss = 1.44992 (* 1 = 1.44992 loss)
I0521 13:01:02.028666 20157 sgd_solver.cpp:106] Iteration 313500, lr = 0.0005
I0521 13:01:18.607730 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_315000.caffemodel
I0521 13:01:18.653528 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_315000.solverstate
I0521 13:01:18.681706 20157 solver.cpp:237] Iteration 315000, loss = 1.11676
I0521 13:01:18.681752 20157 solver.cpp:253]     Train net output #0: loss = 1.11677 (* 1 = 1.11677 loss)
I0521 13:01:18.681766 20157 sgd_solver.cpp:106] Iteration 315000, lr = 0.0005
I0521 13:01:35.297754 20157 solver.cpp:237] Iteration 316500, loss = 0.729119
I0521 13:01:35.297914 20157 solver.cpp:253]     Train net output #0: loss = 0.729124 (* 1 = 0.729124 loss)
I0521 13:01:35.297930 20157 sgd_solver.cpp:106] Iteration 316500, lr = 0.0005
I0521 13:01:51.915343 20157 solver.cpp:237] Iteration 318000, loss = 0.589986
I0521 13:01:51.915390 20157 solver.cpp:253]     Train net output #0: loss = 0.589992 (* 1 = 0.589992 loss)
I0521 13:01:51.915405 20157 sgd_solver.cpp:106] Iteration 318000, lr = 0.0005
I0521 13:02:08.531328 20157 solver.cpp:237] Iteration 319500, loss = 1.34822
I0521 13:02:08.531497 20157 solver.cpp:253]     Train net output #0: loss = 1.34823 (* 1 = 1.34823 loss)
I0521 13:02:08.531512 20157 sgd_solver.cpp:106] Iteration 319500, lr = 0.0005
I0521 13:02:46.064565 20157 solver.cpp:237] Iteration 321000, loss = 0.937021
I0521 13:02:46.064744 20157 solver.cpp:253]     Train net output #0: loss = 0.937027 (* 1 = 0.937027 loss)
I0521 13:02:46.064760 20157 sgd_solver.cpp:106] Iteration 321000, lr = 0.0005
I0521 13:03:02.680537 20157 solver.cpp:237] Iteration 322500, loss = 0.648369
I0521 13:03:02.680583 20157 solver.cpp:253]     Train net output #0: loss = 0.648375 (* 1 = 0.648375 loss)
I0521 13:03:02.680596 20157 sgd_solver.cpp:106] Iteration 322500, lr = 0.0005
I0521 13:03:19.290837 20157 solver.cpp:237] Iteration 324000, loss = 0.734281
I0521 13:03:19.290995 20157 solver.cpp:253]     Train net output #0: loss = 0.734288 (* 1 = 0.734288 loss)
I0521 13:03:19.291009 20157 sgd_solver.cpp:106] Iteration 324000, lr = 0.0005
I0521 13:03:35.908604 20157 solver.cpp:237] Iteration 325500, loss = 1.13743
I0521 13:03:35.908654 20157 solver.cpp:253]     Train net output #0: loss = 1.13744 (* 1 = 1.13744 loss)
I0521 13:03:35.908668 20157 sgd_solver.cpp:106] Iteration 325500, lr = 0.0005
I0521 13:03:52.496672 20157 solver.cpp:237] Iteration 327000, loss = 1.41634
I0521 13:03:52.496841 20157 solver.cpp:253]     Train net output #0: loss = 1.41635 (* 1 = 1.41635 loss)
I0521 13:03:52.496855 20157 sgd_solver.cpp:106] Iteration 327000, lr = 0.0005
I0521 13:04:09.090082 20157 solver.cpp:237] Iteration 328500, loss = 0.669586
I0521 13:04:09.090118 20157 solver.cpp:253]     Train net output #0: loss = 0.669593 (* 1 = 0.669593 loss)
I0521 13:04:09.090134 20157 sgd_solver.cpp:106] Iteration 328500, lr = 0.0005
I0521 13:04:25.673427 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_330000.caffemodel
I0521 13:04:25.719578 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_330000.solverstate
I0521 13:04:25.744702 20157 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 13:05:24.765729 20157 solver.cpp:409]     Test net output #0: accuracy = 0.888928
I0521 13:05:24.765915 20157 solver.cpp:409]     Test net output #1: loss = 0.357179 (* 1 = 0.357179 loss)
I0521 13:05:45.618252 20157 solver.cpp:237] Iteration 330000, loss = 0.588644
I0521 13:05:45.618305 20157 solver.cpp:253]     Train net output #0: loss = 0.588651 (* 1 = 0.588651 loss)
I0521 13:05:45.618320 20157 sgd_solver.cpp:106] Iteration 330000, lr = 0.0005
I0521 13:06:02.796314 20157 solver.cpp:237] Iteration 331500, loss = 0.998113
I0521 13:06:02.796491 20157 solver.cpp:253]     Train net output #0: loss = 0.998121 (* 1 = 0.998121 loss)
I0521 13:06:02.796506 20157 sgd_solver.cpp:106] Iteration 331500, lr = 0.0005
I0521 13:06:19.955759 20157 solver.cpp:237] Iteration 333000, loss = 0.64181
I0521 13:06:19.955804 20157 solver.cpp:253]     Train net output #0: loss = 0.641818 (* 1 = 0.641818 loss)
I0521 13:06:19.955827 20157 sgd_solver.cpp:106] Iteration 333000, lr = 0.0005
I0521 13:06:37.136540 20157 solver.cpp:237] Iteration 334500, loss = 1.22414
I0521 13:06:37.136699 20157 solver.cpp:253]     Train net output #0: loss = 1.22415 (* 1 = 1.22415 loss)
I0521 13:06:37.136714 20157 sgd_solver.cpp:106] Iteration 334500, lr = 0.0005
I0521 13:06:54.152751 20157 solver.cpp:237] Iteration 336000, loss = 1.03834
I0521 13:06:54.152802 20157 solver.cpp:253]     Train net output #0: loss = 1.03835 (* 1 = 1.03835 loss)
I0521 13:06:54.152815 20157 sgd_solver.cpp:106] Iteration 336000, lr = 0.0005
I0521 13:07:11.093031 20157 solver.cpp:237] Iteration 337500, loss = 1.29684
I0521 13:07:11.093204 20157 solver.cpp:253]     Train net output #0: loss = 1.29685 (* 1 = 1.29685 loss)
I0521 13:07:11.093217 20157 sgd_solver.cpp:106] Iteration 337500, lr = 0.0005
I0521 13:07:28.027585 20157 solver.cpp:237] Iteration 339000, loss = 0.463413
I0521 13:07:28.027621 20157 solver.cpp:253]     Train net output #0: loss = 0.46342 (* 1 = 0.46342 loss)
I0521 13:07:28.027636 20157 sgd_solver.cpp:106] Iteration 339000, lr = 0.0005
I0521 13:08:05.768568 20157 solver.cpp:237] Iteration 340500, loss = 0.820575
I0521 13:08:05.768748 20157 solver.cpp:253]     Train net output #0: loss = 0.820582 (* 1 = 0.820582 loss)
I0521 13:08:05.768761 20157 sgd_solver.cpp:106] Iteration 340500, lr = 0.0005
I0521 13:08:22.698400 20157 solver.cpp:237] Iteration 342000, loss = 1.4572
I0521 13:08:22.698436 20157 solver.cpp:253]     Train net output #0: loss = 1.4572 (* 1 = 1.4572 loss)
I0521 13:08:22.698453 20157 sgd_solver.cpp:106] Iteration 342000, lr = 0.0005
I0521 13:08:39.643610 20157 solver.cpp:237] Iteration 343500, loss = 0.702101
I0521 13:08:39.643782 20157 solver.cpp:253]     Train net output #0: loss = 0.702109 (* 1 = 0.702109 loss)
I0521 13:08:39.643797 20157 sgd_solver.cpp:106] Iteration 343500, lr = 0.0005
I0521 13:08:56.599189 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_345000.caffemodel
I0521 13:08:56.645397 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_345000.solverstate
I0521 13:08:56.674139 20157 solver.cpp:237] Iteration 345000, loss = 1.33015
I0521 13:08:56.674181 20157 solver.cpp:253]     Train net output #0: loss = 1.33016 (* 1 = 1.33016 loss)
I0521 13:08:56.674201 20157 sgd_solver.cpp:106] Iteration 345000, lr = 0.0005
I0521 13:09:13.590724 20157 solver.cpp:237] Iteration 346500, loss = 0.762512
I0521 13:09:13.590899 20157 solver.cpp:253]     Train net output #0: loss = 0.762519 (* 1 = 0.762519 loss)
I0521 13:09:13.590914 20157 sgd_solver.cpp:106] Iteration 346500, lr = 0.0005
I0521 13:09:30.532634 20157 solver.cpp:237] Iteration 348000, loss = 0.802949
I0521 13:09:30.532672 20157 solver.cpp:253]     Train net output #0: loss = 0.802957 (* 1 = 0.802957 loss)
I0521 13:09:30.532690 20157 sgd_solver.cpp:106] Iteration 348000, lr = 0.0005
I0521 13:09:47.499428 20157 solver.cpp:237] Iteration 349500, loss = 0.500085
I0521 13:09:47.499614 20157 solver.cpp:253]     Train net output #0: loss = 0.500093 (* 1 = 0.500093 loss)
I0521 13:09:47.499629 20157 sgd_solver.cpp:106] Iteration 349500, lr = 0.0005
I0521 13:10:25.327500 20157 solver.cpp:237] Iteration 351000, loss = 1.3267
I0521 13:10:25.327682 20157 solver.cpp:253]     Train net output #0: loss = 1.3267 (* 1 = 1.3267 loss)
I0521 13:10:25.327695 20157 sgd_solver.cpp:106] Iteration 351000, lr = 0.0005
I0521 13:10:42.275733 20157 solver.cpp:237] Iteration 352500, loss = 0.753996
I0521 13:10:42.275781 20157 solver.cpp:253]     Train net output #0: loss = 0.754004 (* 1 = 0.754004 loss)
I0521 13:10:42.275795 20157 sgd_solver.cpp:106] Iteration 352500, lr = 0.0005
I0521 13:10:59.118114 20157 solver.cpp:237] Iteration 354000, loss = 0.839118
I0521 13:10:59.118293 20157 solver.cpp:253]     Train net output #0: loss = 0.839126 (* 1 = 0.839126 loss)
I0521 13:10:59.118306 20157 sgd_solver.cpp:106] Iteration 354000, lr = 0.0005
I0521 13:11:15.733901 20157 solver.cpp:237] Iteration 355500, loss = 0.469859
I0521 13:11:15.733937 20157 solver.cpp:253]     Train net output #0: loss = 0.469868 (* 1 = 0.469868 loss)
I0521 13:11:15.733955 20157 sgd_solver.cpp:106] Iteration 355500, lr = 0.0005
I0521 13:11:32.355612 20157 solver.cpp:237] Iteration 357000, loss = 1.53969
I0521 13:11:32.355784 20157 solver.cpp:253]     Train net output #0: loss = 1.5397 (* 1 = 1.5397 loss)
I0521 13:11:32.355798 20157 sgd_solver.cpp:106] Iteration 357000, lr = 0.0005
I0521 13:11:49.070494 20157 solver.cpp:237] Iteration 358500, loss = 1.06448
I0521 13:11:49.070545 20157 solver.cpp:253]     Train net output #0: loss = 1.06449 (* 1 = 1.06449 loss)
I0521 13:11:49.070559 20157 sgd_solver.cpp:106] Iteration 358500, lr = 0.0005
I0521 13:12:05.981895 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_360000.caffemodel
I0521 13:12:06.028712 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_360000.solverstate
I0521 13:12:06.053843 20157 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 13:13:26.296499 20157 solver.cpp:409]     Test net output #0: accuracy = 0.888888
I0521 13:13:26.296677 20157 solver.cpp:409]     Test net output #1: loss = 0.397528 (* 1 = 0.397528 loss)
I0521 13:13:47.194263 20157 solver.cpp:237] Iteration 360000, loss = 1.4022
I0521 13:13:47.194317 20157 solver.cpp:253]     Train net output #0: loss = 1.40221 (* 1 = 1.40221 loss)
I0521 13:13:47.194332 20157 sgd_solver.cpp:106] Iteration 360000, lr = 0.0005
I0521 13:14:03.839172 20157 solver.cpp:237] Iteration 361500, loss = 0.403839
I0521 13:14:03.839345 20157 solver.cpp:253]     Train net output #0: loss = 0.403846 (* 1 = 0.403846 loss)
I0521 13:14:03.839359 20157 sgd_solver.cpp:106] Iteration 361500, lr = 0.0005
I0521 13:14:20.444838 20157 solver.cpp:237] Iteration 363000, loss = 1.40844
I0521 13:14:20.444885 20157 solver.cpp:253]     Train net output #0: loss = 1.40844 (* 1 = 1.40844 loss)
I0521 13:14:20.444898 20157 sgd_solver.cpp:106] Iteration 363000, lr = 0.0005
I0521 13:14:37.076432 20157 solver.cpp:237] Iteration 364500, loss = 1.00972
I0521 13:14:37.076593 20157 solver.cpp:253]     Train net output #0: loss = 1.00973 (* 1 = 1.00973 loss)
I0521 13:14:37.076608 20157 sgd_solver.cpp:106] Iteration 364500, lr = 0.0005
I0521 13:14:53.691323 20157 solver.cpp:237] Iteration 366000, loss = 1.14589
I0521 13:14:53.691368 20157 solver.cpp:253]     Train net output #0: loss = 1.1459 (* 1 = 1.1459 loss)
I0521 13:14:53.691386 20157 sgd_solver.cpp:106] Iteration 366000, lr = 0.0005
I0521 13:15:10.283740 20157 solver.cpp:237] Iteration 367500, loss = 1.15124
I0521 13:15:10.283921 20157 solver.cpp:253]     Train net output #0: loss = 1.15125 (* 1 = 1.15125 loss)
I0521 13:15:10.283936 20157 sgd_solver.cpp:106] Iteration 367500, lr = 0.0005
I0521 13:15:26.872251 20157 solver.cpp:237] Iteration 369000, loss = 1.58488
I0521 13:15:26.872287 20157 solver.cpp:253]     Train net output #0: loss = 1.58489 (* 1 = 1.58489 loss)
I0521 13:15:26.872301 20157 sgd_solver.cpp:106] Iteration 369000, lr = 0.0005
I0521 13:16:04.332484 20157 solver.cpp:237] Iteration 370500, loss = 1.27064
I0521 13:16:04.332676 20157 solver.cpp:253]     Train net output #0: loss = 1.27065 (* 1 = 1.27065 loss)
I0521 13:16:04.332690 20157 sgd_solver.cpp:106] Iteration 370500, lr = 0.0005
I0521 13:16:20.953347 20157 solver.cpp:237] Iteration 372000, loss = 0.965816
I0521 13:16:20.953394 20157 solver.cpp:253]     Train net output #0: loss = 0.965822 (* 1 = 0.965822 loss)
I0521 13:16:20.953408 20157 sgd_solver.cpp:106] Iteration 372000, lr = 0.0005
I0521 13:16:37.557366 20157 solver.cpp:237] Iteration 373500, loss = 1.36603
I0521 13:16:37.557528 20157 solver.cpp:253]     Train net output #0: loss = 1.36604 (* 1 = 1.36604 loss)
I0521 13:16:37.557541 20157 sgd_solver.cpp:106] Iteration 373500, lr = 0.0005
I0521 13:16:54.143240 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_375000.caffemodel
I0521 13:16:54.190609 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_375000.solverstate
I0521 13:16:54.221158 20157 solver.cpp:237] Iteration 375000, loss = 1.25747
I0521 13:16:54.221204 20157 solver.cpp:253]     Train net output #0: loss = 1.25748 (* 1 = 1.25748 loss)
I0521 13:16:54.221221 20157 sgd_solver.cpp:106] Iteration 375000, lr = 0.0005
I0521 13:17:10.822226 20157 solver.cpp:237] Iteration 376500, loss = 1.636
I0521 13:17:10.822407 20157 solver.cpp:253]     Train net output #0: loss = 1.63601 (* 1 = 1.63601 loss)
I0521 13:17:10.822420 20157 sgd_solver.cpp:106] Iteration 376500, lr = 0.0005
I0521 13:17:27.606540 20157 solver.cpp:237] Iteration 378000, loss = 1.17407
I0521 13:17:27.606576 20157 solver.cpp:253]     Train net output #0: loss = 1.17408 (* 1 = 1.17408 loss)
I0521 13:17:27.606596 20157 sgd_solver.cpp:106] Iteration 378000, lr = 0.0005
I0521 13:17:44.395433 20157 solver.cpp:237] Iteration 379500, loss = 1.0706
I0521 13:17:44.395604 20157 solver.cpp:253]     Train net output #0: loss = 1.07061 (* 1 = 1.07061 loss)
I0521 13:17:44.395618 20157 sgd_solver.cpp:106] Iteration 379500, lr = 0.0005
I0521 13:18:22.019596 20157 solver.cpp:237] Iteration 381000, loss = 0.548642
I0521 13:18:22.019780 20157 solver.cpp:253]     Train net output #0: loss = 0.548648 (* 1 = 0.548648 loss)
I0521 13:18:22.019795 20157 sgd_solver.cpp:106] Iteration 381000, lr = 0.0005
I0521 13:18:38.770934 20157 solver.cpp:237] Iteration 382500, loss = 1.11019
I0521 13:18:38.770983 20157 solver.cpp:253]     Train net output #0: loss = 1.1102 (* 1 = 1.1102 loss)
I0521 13:18:38.770998 20157 sgd_solver.cpp:106] Iteration 382500, lr = 0.0005
I0521 13:18:55.514762 20157 solver.cpp:237] Iteration 384000, loss = 1.20337
I0521 13:18:55.514935 20157 solver.cpp:253]     Train net output #0: loss = 1.20337 (* 1 = 1.20337 loss)
I0521 13:18:55.514950 20157 sgd_solver.cpp:106] Iteration 384000, lr = 0.0005
I0521 13:19:12.252022 20157 solver.cpp:237] Iteration 385500, loss = 0.854018
I0521 13:19:12.252059 20157 solver.cpp:253]     Train net output #0: loss = 0.854024 (* 1 = 0.854024 loss)
I0521 13:19:12.252073 20157 sgd_solver.cpp:106] Iteration 385500, lr = 0.0005
I0521 13:19:28.974328 20157 solver.cpp:237] Iteration 387000, loss = 1.24476
I0521 13:19:28.974504 20157 solver.cpp:253]     Train net output #0: loss = 1.24477 (* 1 = 1.24477 loss)
I0521 13:19:28.974519 20157 sgd_solver.cpp:106] Iteration 387000, lr = 0.0005
I0521 13:19:45.736771 20157 solver.cpp:237] Iteration 388500, loss = 1.14598
I0521 13:19:45.736820 20157 solver.cpp:253]     Train net output #0: loss = 1.14598 (* 1 = 1.14598 loss)
I0521 13:19:45.736837 20157 sgd_solver.cpp:106] Iteration 388500, lr = 0.0005
I0521 13:20:02.484644 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_390000.caffemodel
I0521 13:20:02.530123 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_390000.solverstate
I0521 13:20:02.555779 20157 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 13:21:01.771294 20157 solver.cpp:409]     Test net output #0: accuracy = 0.890261
I0521 13:21:01.771473 20157 solver.cpp:409]     Test net output #1: loss = 0.363818 (* 1 = 0.363818 loss)
I0521 13:21:22.679570 20157 solver.cpp:237] Iteration 390000, loss = 0.997796
I0521 13:21:22.679625 20157 solver.cpp:253]     Train net output #0: loss = 0.997802 (* 1 = 0.997802 loss)
I0521 13:21:22.679639 20157 sgd_solver.cpp:106] Iteration 390000, lr = 0.0005
I0521 13:21:39.618260 20157 solver.cpp:237] Iteration 391500, loss = 0.396518
I0521 13:21:39.618429 20157 solver.cpp:253]     Train net output #0: loss = 0.396525 (* 1 = 0.396525 loss)
I0521 13:21:39.618443 20157 sgd_solver.cpp:106] Iteration 391500, lr = 0.0005
I0521 13:21:56.548576 20157 solver.cpp:237] Iteration 393000, loss = 1.34065
I0521 13:21:56.548625 20157 solver.cpp:253]     Train net output #0: loss = 1.34066 (* 1 = 1.34066 loss)
I0521 13:21:56.548641 20157 sgd_solver.cpp:106] Iteration 393000, lr = 0.0005
I0521 13:22:13.495074 20157 solver.cpp:237] Iteration 394500, loss = 1.21453
I0521 13:22:13.495255 20157 solver.cpp:253]     Train net output #0: loss = 1.21454 (* 1 = 1.21454 loss)
I0521 13:22:13.495270 20157 sgd_solver.cpp:106] Iteration 394500, lr = 0.0005
I0521 13:22:30.447672 20157 solver.cpp:237] Iteration 396000, loss = 1.43715
I0521 13:22:30.447708 20157 solver.cpp:253]     Train net output #0: loss = 1.43716 (* 1 = 1.43716 loss)
I0521 13:22:30.447724 20157 sgd_solver.cpp:106] Iteration 396000, lr = 0.0005
I0521 13:22:47.287833 20157 solver.cpp:237] Iteration 397500, loss = 1.05412
I0521 13:22:47.288009 20157 solver.cpp:253]     Train net output #0: loss = 1.05412 (* 1 = 1.05412 loss)
I0521 13:22:47.288023 20157 sgd_solver.cpp:106] Iteration 397500, lr = 0.0005
I0521 13:23:04.170181 20157 solver.cpp:237] Iteration 399000, loss = 0.93588
I0521 13:23:04.170230 20157 solver.cpp:253]     Train net output #0: loss = 0.935888 (* 1 = 0.935888 loss)
I0521 13:23:04.170245 20157 sgd_solver.cpp:106] Iteration 399000, lr = 0.0005
I0521 13:23:41.871803 20157 solver.cpp:237] Iteration 400500, loss = 1.08302
I0521 13:23:41.871991 20157 solver.cpp:253]     Train net output #0: loss = 1.08302 (* 1 = 1.08302 loss)
I0521 13:23:41.872006 20157 sgd_solver.cpp:106] Iteration 400500, lr = 0.0005
I0521 13:23:58.729926 20157 solver.cpp:237] Iteration 402000, loss = 0.71644
I0521 13:23:58.729974 20157 solver.cpp:253]     Train net output #0: loss = 0.716449 (* 1 = 0.716449 loss)
I0521 13:23:58.729990 20157 sgd_solver.cpp:106] Iteration 402000, lr = 0.0005
I0521 13:24:15.594600 20157 solver.cpp:237] Iteration 403500, loss = 0.764171
I0521 13:24:15.594779 20157 solver.cpp:253]     Train net output #0: loss = 0.76418 (* 1 = 0.76418 loss)
I0521 13:24:15.594792 20157 sgd_solver.cpp:106] Iteration 403500, lr = 0.0005
I0521 13:24:32.392649 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_405000.caffemodel
I0521 13:24:32.439223 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_405000.solverstate
I0521 13:24:32.467828 20157 solver.cpp:237] Iteration 405000, loss = 1.48902
I0521 13:24:32.467874 20157 solver.cpp:253]     Train net output #0: loss = 1.48903 (* 1 = 1.48903 loss)
I0521 13:24:32.467887 20157 sgd_solver.cpp:106] Iteration 405000, lr = 0.0005
I0521 13:24:49.354604 20157 solver.cpp:237] Iteration 406500, loss = 1.5406
I0521 13:24:49.354795 20157 solver.cpp:253]     Train net output #0: loss = 1.54061 (* 1 = 1.54061 loss)
I0521 13:24:49.354810 20157 sgd_solver.cpp:106] Iteration 406500, lr = 0.0005
I0521 13:25:06.165252 20157 solver.cpp:237] Iteration 408000, loss = 1.13256
I0521 13:25:06.165300 20157 solver.cpp:253]     Train net output #0: loss = 1.13257 (* 1 = 1.13257 loss)
I0521 13:25:06.165318 20157 sgd_solver.cpp:106] Iteration 408000, lr = 0.0005
I0521 13:25:22.775888 20157 solver.cpp:237] Iteration 409500, loss = 0.913111
I0521 13:25:22.776054 20157 solver.cpp:253]     Train net output #0: loss = 0.91312 (* 1 = 0.91312 loss)
I0521 13:25:22.776069 20157 sgd_solver.cpp:106] Iteration 409500, lr = 0.0005
I0521 13:26:00.310369 20157 solver.cpp:237] Iteration 411000, loss = 1.39867
I0521 13:26:00.310554 20157 solver.cpp:253]     Train net output #0: loss = 1.39868 (* 1 = 1.39868 loss)
I0521 13:26:00.310569 20157 sgd_solver.cpp:106] Iteration 411000, lr = 0.0005
I0521 13:26:16.906174 20157 solver.cpp:237] Iteration 412500, loss = 1.79191
I0521 13:26:16.906210 20157 solver.cpp:253]     Train net output #0: loss = 1.79192 (* 1 = 1.79192 loss)
I0521 13:26:16.906226 20157 sgd_solver.cpp:106] Iteration 412500, lr = 0.0005
I0521 13:26:33.460360 20157 solver.cpp:237] Iteration 414000, loss = 1.73821
I0521 13:26:33.460528 20157 solver.cpp:253]     Train net output #0: loss = 1.73822 (* 1 = 1.73822 loss)
I0521 13:26:33.460542 20157 sgd_solver.cpp:106] Iteration 414000, lr = 0.0005
I0521 13:26:50.055047 20157 solver.cpp:237] Iteration 415500, loss = 0.921503
I0521 13:26:50.055096 20157 solver.cpp:253]     Train net output #0: loss = 0.921512 (* 1 = 0.921512 loss)
I0521 13:26:50.055111 20157 sgd_solver.cpp:106] Iteration 415500, lr = 0.0005
I0521 13:27:06.681023 20157 solver.cpp:237] Iteration 417000, loss = 1.16002
I0521 13:27:06.681187 20157 solver.cpp:253]     Train net output #0: loss = 1.16003 (* 1 = 1.16003 loss)
I0521 13:27:06.681200 20157 sgd_solver.cpp:106] Iteration 417000, lr = 0.0005
I0521 13:27:23.292815 20157 solver.cpp:237] Iteration 418500, loss = 1.0033
I0521 13:27:23.292863 20157 solver.cpp:253]     Train net output #0: loss = 1.0033 (* 1 = 1.0033 loss)
I0521 13:27:23.292877 20157 sgd_solver.cpp:106] Iteration 418500, lr = 0.0005
I0521 13:27:39.867177 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_420000.caffemodel
I0521 13:27:39.913326 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_420000.solverstate
I0521 13:27:39.938416 20157 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 13:29:00.028576 20157 solver.cpp:409]     Test net output #0: accuracy = 0.89005
I0521 13:29:00.028760 20157 solver.cpp:409]     Test net output #1: loss = 0.347711 (* 1 = 0.347711 loss)
I0521 13:29:20.963433 20157 solver.cpp:237] Iteration 420000, loss = 1.28011
I0521 13:29:20.963486 20157 solver.cpp:253]     Train net output #0: loss = 1.28012 (* 1 = 1.28012 loss)
I0521 13:29:20.963501 20157 sgd_solver.cpp:106] Iteration 420000, lr = 0.0005
I0521 13:29:37.909696 20157 solver.cpp:237] Iteration 421500, loss = 0.811552
I0521 13:29:37.909865 20157 solver.cpp:253]     Train net output #0: loss = 0.81156 (* 1 = 0.81156 loss)
I0521 13:29:37.909881 20157 sgd_solver.cpp:106] Iteration 421500, lr = 0.0005
I0521 13:29:54.867305 20157 solver.cpp:237] Iteration 423000, loss = 1.43016
I0521 13:29:54.867349 20157 solver.cpp:253]     Train net output #0: loss = 1.43016 (* 1 = 1.43016 loss)
I0521 13:29:54.867367 20157 sgd_solver.cpp:106] Iteration 423000, lr = 0.0005
I0521 13:30:11.827600 20157 solver.cpp:237] Iteration 424500, loss = 0.806015
I0521 13:30:11.827772 20157 solver.cpp:253]     Train net output #0: loss = 0.806023 (* 1 = 0.806023 loss)
I0521 13:30:11.827787 20157 sgd_solver.cpp:106] Iteration 424500, lr = 0.0005
I0521 13:30:28.778065 20157 solver.cpp:237] Iteration 426000, loss = 1.00102
I0521 13:30:28.778116 20157 solver.cpp:253]     Train net output #0: loss = 1.00103 (* 1 = 1.00103 loss)
I0521 13:30:28.778131 20157 sgd_solver.cpp:106] Iteration 426000, lr = 0.0005
I0521 13:30:45.702980 20157 solver.cpp:237] Iteration 427500, loss = 1.18484
I0521 13:30:45.703157 20157 solver.cpp:253]     Train net output #0: loss = 1.18485 (* 1 = 1.18485 loss)
I0521 13:30:45.703171 20157 sgd_solver.cpp:106] Iteration 427500, lr = 0.0005
I0521 13:31:02.641161 20157 solver.cpp:237] Iteration 429000, loss = 0.980519
I0521 13:31:02.641213 20157 solver.cpp:253]     Train net output #0: loss = 0.980527 (* 1 = 0.980527 loss)
I0521 13:31:02.641227 20157 sgd_solver.cpp:106] Iteration 429000, lr = 0.0005
I0521 13:31:40.492431 20157 solver.cpp:237] Iteration 430500, loss = 1.23823
I0521 13:31:40.492632 20157 solver.cpp:253]     Train net output #0: loss = 1.23824 (* 1 = 1.23824 loss)
I0521 13:31:40.492647 20157 sgd_solver.cpp:106] Iteration 430500, lr = 0.0005
I0521 13:31:57.440032 20157 solver.cpp:237] Iteration 432000, loss = 0.912396
I0521 13:31:57.440084 20157 solver.cpp:253]     Train net output #0: loss = 0.912403 (* 1 = 0.912403 loss)
I0521 13:31:57.440099 20157 sgd_solver.cpp:106] Iteration 432000, lr = 0.0005
I0521 13:32:14.347050 20157 solver.cpp:237] Iteration 433500, loss = 1.19824
I0521 13:32:14.347231 20157 solver.cpp:253]     Train net output #0: loss = 1.19825 (* 1 = 1.19825 loss)
I0521 13:32:14.347245 20157 sgd_solver.cpp:106] Iteration 433500, lr = 0.0005
I0521 13:32:31.257643 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_435000.caffemodel
I0521 13:32:31.305833 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_435000.solverstate
I0521 13:32:31.336652 20157 solver.cpp:237] Iteration 435000, loss = 2.08771
I0521 13:32:31.336701 20157 solver.cpp:253]     Train net output #0: loss = 2.08771 (* 1 = 2.08771 loss)
I0521 13:32:31.336715 20157 sgd_solver.cpp:106] Iteration 435000, lr = 0.0005
I0521 13:32:48.266330 20157 solver.cpp:237] Iteration 436500, loss = 1.4394
I0521 13:32:48.266507 20157 solver.cpp:253]     Train net output #0: loss = 1.43941 (* 1 = 1.43941 loss)
I0521 13:32:48.266522 20157 sgd_solver.cpp:106] Iteration 436500, lr = 0.0005
I0521 13:33:05.220937 20157 solver.cpp:237] Iteration 438000, loss = 2.56002
I0521 13:33:05.220985 20157 solver.cpp:253]     Train net output #0: loss = 2.56003 (* 1 = 2.56003 loss)
I0521 13:33:05.221002 20157 sgd_solver.cpp:106] Iteration 438000, lr = 0.0005
I0521 13:33:22.171566 20157 solver.cpp:237] Iteration 439500, loss = 1.12972
I0521 13:33:22.171732 20157 solver.cpp:253]     Train net output #0: loss = 1.12973 (* 1 = 1.12973 loss)
I0521 13:33:22.171746 20157 sgd_solver.cpp:106] Iteration 439500, lr = 0.0005
I0521 13:34:00.036798 20157 solver.cpp:237] Iteration 441000, loss = 1.14307
I0521 13:34:00.036980 20157 solver.cpp:253]     Train net output #0: loss = 1.14308 (* 1 = 1.14308 loss)
I0521 13:34:00.036995 20157 sgd_solver.cpp:106] Iteration 441000, lr = 0.0005
I0521 13:34:16.964908 20157 solver.cpp:237] Iteration 442500, loss = 1.75157
I0521 13:34:16.964951 20157 solver.cpp:253]     Train net output #0: loss = 1.75158 (* 1 = 1.75158 loss)
I0521 13:34:16.964972 20157 sgd_solver.cpp:106] Iteration 442500, lr = 0.0005
I0521 13:34:33.905988 20157 solver.cpp:237] Iteration 444000, loss = 1.62118
I0521 13:34:33.906153 20157 solver.cpp:253]     Train net output #0: loss = 1.62119 (* 1 = 1.62119 loss)
I0521 13:34:33.906167 20157 sgd_solver.cpp:106] Iteration 444000, lr = 0.0005
I0521 13:34:50.833560 20157 solver.cpp:237] Iteration 445500, loss = 1.37937
I0521 13:34:50.833611 20157 solver.cpp:253]     Train net output #0: loss = 1.37938 (* 1 = 1.37938 loss)
I0521 13:34:50.833624 20157 sgd_solver.cpp:106] Iteration 445500, lr = 0.0005
I0521 13:35:07.765168 20157 solver.cpp:237] Iteration 447000, loss = 1.73275
I0521 13:35:07.765372 20157 solver.cpp:253]     Train net output #0: loss = 1.73275 (* 1 = 1.73275 loss)
I0521 13:35:07.765386 20157 sgd_solver.cpp:106] Iteration 447000, lr = 0.0005
I0521 13:35:24.709636 20157 solver.cpp:237] Iteration 448500, loss = 1.27584
I0521 13:35:24.709673 20157 solver.cpp:253]     Train net output #0: loss = 1.27584 (* 1 = 1.27584 loss)
I0521 13:35:24.709686 20157 sgd_solver.cpp:106] Iteration 448500, lr = 0.0005
I0521 13:35:41.527925 20157 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_450000.caffemodel
I0521 13:35:41.575913 20157 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0005_2016-05-20T15.48.49.278163_iter_450000.solverstate
I0521 13:35:41.603381 20157 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 13:36:40.576592 20157 solver.cpp:409]     Test net output #0: accuracy = 0.890428
I0521 13:36:40.576777 20157 solver.cpp:409]     Test net output #1: loss = 0.359466 (* 1 = 0.359466 loss)
I0521 13:37:01.448477 20157 solver.cpp:237] Iteration 450000, loss = 1.38454
I0521 13:37:01.448529 20157 solver.cpp:253]     Train net output #0: loss = 1.38455 (* 1 = 1.38455 loss)
I0521 13:37:01.448546 20157 sgd_solver.cpp:106] Iteration 450000, lr = 0.0005
I0521 13:37:18.393741 20157 solver.cpp:237] Iteration 451500, loss = 0.744331
I0521 13:37:18.393930 20157 solver.cpp:253]     Train net output #0: loss = 0.744338 (* 1 = 0.744338 loss)
I0521 13:37:18.393945 20157 sgd_solver.cpp:106] Iteration 451500, lr = 0.0005
I0521 13:37:35.320873 20157 solver.cpp:237] Iteration 453000, loss = 1.69343
I0521 13:37:35.320924 20157 solver.cpp:253]     Train net output #0: loss = 1.69344 (* 1 = 1.69344 loss)
I0521 13:37:35.320937 20157 sgd_solver.cpp:106] Iteration 453000, lr = 0.0005
I0521 13:37:52.264160 20157 solver.cpp:237] Iteration 454500, loss = 1.38664
I0521 13:37:52.264328 20157 solver.cpp:253]     Train net output #0: loss = 1.38665 (* 1 = 1.38665 loss)
I0521 13:37:52.264340 20157 sgd_solver.cpp:106] Iteration 454500, lr = 0.0005
aprun: Apid 11237840: Caught signal Terminated, sending to application
*** Aborted at 1463852273 (unix time) try "date -d @1463852273" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x4eba) received by PID 20157 (TID 0x2aaac746f900) from PID 20154; stack trace: ***
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
=>> PBS: job killed: walltime 7208 exceeded limit 7200
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11237840: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
aprun: Apid 11237840: Caught signal Terminated, sending to application
