2812159
I0526 15:07:42.789608 12837 caffe.cpp:184] Using GPUs 0
I0526 15:07:43.218503 12837 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.002
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961.prototxt"
I0526 15:07:43.237674 12837 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961.prototxt
I0526 15:07:43.263926 12837 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 15:07:43.263983 12837 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 15:07:43.264343 12837 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 15:07:43.264523 12837 layer_factory.hpp:77] Creating layer data_hdf5
I0526 15:07:43.264547 12837 net.cpp:106] Creating Layer data_hdf5
I0526 15:07:43.264562 12837 net.cpp:411] data_hdf5 -> data
I0526 15:07:43.264595 12837 net.cpp:411] data_hdf5 -> label
I0526 15:07:43.264628 12837 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 15:07:43.288028 12837 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 15:07:43.307075 12837 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 15:08:05.055318 12837 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 15:08:05.068410 12837 net.cpp:150] Setting up data_hdf5
I0526 15:08:05.068454 12837 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 15:08:05.068467 12837 net.cpp:157] Top shape: 20 (20)
I0526 15:08:05.068481 12837 net.cpp:165] Memory required for data: 508080
I0526 15:08:05.068495 12837 layer_factory.hpp:77] Creating layer conv1
I0526 15:08:05.068528 12837 net.cpp:106] Creating Layer conv1
I0526 15:08:05.068539 12837 net.cpp:454] conv1 <- data
I0526 15:08:05.068562 12837 net.cpp:411] conv1 -> conv1
I0526 15:08:07.977326 12837 net.cpp:150] Setting up conv1
I0526 15:08:07.977375 12837 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:08:07.977385 12837 net.cpp:165] Memory required for data: 6037680
I0526 15:08:07.977413 12837 layer_factory.hpp:77] Creating layer relu1
I0526 15:08:07.977435 12837 net.cpp:106] Creating Layer relu1
I0526 15:08:07.977447 12837 net.cpp:454] relu1 <- conv1
I0526 15:08:07.977460 12837 net.cpp:397] relu1 -> conv1 (in-place)
I0526 15:08:07.977979 12837 net.cpp:150] Setting up relu1
I0526 15:08:07.977996 12837 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:08:07.978006 12837 net.cpp:165] Memory required for data: 11567280
I0526 15:08:07.978016 12837 layer_factory.hpp:77] Creating layer pool1
I0526 15:08:07.978032 12837 net.cpp:106] Creating Layer pool1
I0526 15:08:07.978044 12837 net.cpp:454] pool1 <- conv1
I0526 15:08:07.978056 12837 net.cpp:411] pool1 -> pool1
I0526 15:08:07.978137 12837 net.cpp:150] Setting up pool1
I0526 15:08:07.978150 12837 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 15:08:07.978160 12837 net.cpp:165] Memory required for data: 14332080
I0526 15:08:07.978168 12837 layer_factory.hpp:77] Creating layer conv2
I0526 15:08:07.978191 12837 net.cpp:106] Creating Layer conv2
I0526 15:08:07.978201 12837 net.cpp:454] conv2 <- pool1
I0526 15:08:07.978214 12837 net.cpp:411] conv2 -> conv2
I0526 15:08:07.980911 12837 net.cpp:150] Setting up conv2
I0526 15:08:07.980938 12837 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:08:07.980949 12837 net.cpp:165] Memory required for data: 18306480
I0526 15:08:07.980969 12837 layer_factory.hpp:77] Creating layer relu2
I0526 15:08:07.980983 12837 net.cpp:106] Creating Layer relu2
I0526 15:08:07.980994 12837 net.cpp:454] relu2 <- conv2
I0526 15:08:07.981006 12837 net.cpp:397] relu2 -> conv2 (in-place)
I0526 15:08:07.981338 12837 net.cpp:150] Setting up relu2
I0526 15:08:07.981351 12837 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:08:07.981361 12837 net.cpp:165] Memory required for data: 22280880
I0526 15:08:07.981371 12837 layer_factory.hpp:77] Creating layer pool2
I0526 15:08:07.981416 12837 net.cpp:106] Creating Layer pool2
I0526 15:08:07.981427 12837 net.cpp:454] pool2 <- conv2
I0526 15:08:07.981439 12837 net.cpp:411] pool2 -> pool2
I0526 15:08:07.981523 12837 net.cpp:150] Setting up pool2
I0526 15:08:07.981537 12837 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 15:08:07.981547 12837 net.cpp:165] Memory required for data: 24268080
I0526 15:08:07.981559 12837 layer_factory.hpp:77] Creating layer conv3
I0526 15:08:07.981575 12837 net.cpp:106] Creating Layer conv3
I0526 15:08:07.981585 12837 net.cpp:454] conv3 <- pool2
I0526 15:08:07.981600 12837 net.cpp:411] conv3 -> conv3
I0526 15:08:07.983546 12837 net.cpp:150] Setting up conv3
I0526 15:08:07.983569 12837 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:08:07.983582 12837 net.cpp:165] Memory required for data: 26436400
I0526 15:08:07.983599 12837 layer_factory.hpp:77] Creating layer relu3
I0526 15:08:07.983615 12837 net.cpp:106] Creating Layer relu3
I0526 15:08:07.983625 12837 net.cpp:454] relu3 <- conv3
I0526 15:08:07.983639 12837 net.cpp:397] relu3 -> conv3 (in-place)
I0526 15:08:07.984112 12837 net.cpp:150] Setting up relu3
I0526 15:08:07.984128 12837 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:08:07.984138 12837 net.cpp:165] Memory required for data: 28604720
I0526 15:08:07.984148 12837 layer_factory.hpp:77] Creating layer pool3
I0526 15:08:07.984161 12837 net.cpp:106] Creating Layer pool3
I0526 15:08:07.984170 12837 net.cpp:454] pool3 <- conv3
I0526 15:08:07.984184 12837 net.cpp:411] pool3 -> pool3
I0526 15:08:07.984251 12837 net.cpp:150] Setting up pool3
I0526 15:08:07.984264 12837 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 15:08:07.984273 12837 net.cpp:165] Memory required for data: 29688880
I0526 15:08:07.984283 12837 layer_factory.hpp:77] Creating layer conv4
I0526 15:08:07.984300 12837 net.cpp:106] Creating Layer conv4
I0526 15:08:07.984310 12837 net.cpp:454] conv4 <- pool3
I0526 15:08:07.984323 12837 net.cpp:411] conv4 -> conv4
I0526 15:08:07.987046 12837 net.cpp:150] Setting up conv4
I0526 15:08:07.987072 12837 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:08:07.987083 12837 net.cpp:165] Memory required for data: 30414640
I0526 15:08:07.987098 12837 layer_factory.hpp:77] Creating layer relu4
I0526 15:08:07.987112 12837 net.cpp:106] Creating Layer relu4
I0526 15:08:07.987123 12837 net.cpp:454] relu4 <- conv4
I0526 15:08:07.987135 12837 net.cpp:397] relu4 -> conv4 (in-place)
I0526 15:08:07.987612 12837 net.cpp:150] Setting up relu4
I0526 15:08:07.987627 12837 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:08:07.987638 12837 net.cpp:165] Memory required for data: 31140400
I0526 15:08:07.987648 12837 layer_factory.hpp:77] Creating layer pool4
I0526 15:08:07.987661 12837 net.cpp:106] Creating Layer pool4
I0526 15:08:07.987670 12837 net.cpp:454] pool4 <- conv4
I0526 15:08:07.987684 12837 net.cpp:411] pool4 -> pool4
I0526 15:08:07.987751 12837 net.cpp:150] Setting up pool4
I0526 15:08:07.987766 12837 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 15:08:07.987776 12837 net.cpp:165] Memory required for data: 31503280
I0526 15:08:07.987785 12837 layer_factory.hpp:77] Creating layer ip1
I0526 15:08:07.987805 12837 net.cpp:106] Creating Layer ip1
I0526 15:08:07.987815 12837 net.cpp:454] ip1 <- pool4
I0526 15:08:07.987826 12837 net.cpp:411] ip1 -> ip1
I0526 15:08:08.003259 12837 net.cpp:150] Setting up ip1
I0526 15:08:08.003288 12837 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:08:08.003299 12837 net.cpp:165] Memory required for data: 31518960
I0526 15:08:08.003321 12837 layer_factory.hpp:77] Creating layer relu5
I0526 15:08:08.003336 12837 net.cpp:106] Creating Layer relu5
I0526 15:08:08.003346 12837 net.cpp:454] relu5 <- ip1
I0526 15:08:08.003360 12837 net.cpp:397] relu5 -> ip1 (in-place)
I0526 15:08:08.003706 12837 net.cpp:150] Setting up relu5
I0526 15:08:08.003720 12837 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:08:08.003731 12837 net.cpp:165] Memory required for data: 31534640
I0526 15:08:08.003741 12837 layer_factory.hpp:77] Creating layer drop1
I0526 15:08:08.003762 12837 net.cpp:106] Creating Layer drop1
I0526 15:08:08.003772 12837 net.cpp:454] drop1 <- ip1
I0526 15:08:08.003784 12837 net.cpp:397] drop1 -> ip1 (in-place)
I0526 15:08:08.003844 12837 net.cpp:150] Setting up drop1
I0526 15:08:08.003856 12837 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:08:08.003866 12837 net.cpp:165] Memory required for data: 31550320
I0526 15:08:08.003876 12837 layer_factory.hpp:77] Creating layer ip2
I0526 15:08:08.003895 12837 net.cpp:106] Creating Layer ip2
I0526 15:08:08.003906 12837 net.cpp:454] ip2 <- ip1
I0526 15:08:08.003916 12837 net.cpp:411] ip2 -> ip2
I0526 15:08:08.004380 12837 net.cpp:150] Setting up ip2
I0526 15:08:08.004393 12837 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:08:08.004402 12837 net.cpp:165] Memory required for data: 31558160
I0526 15:08:08.004417 12837 layer_factory.hpp:77] Creating layer relu6
I0526 15:08:08.004429 12837 net.cpp:106] Creating Layer relu6
I0526 15:08:08.004438 12837 net.cpp:454] relu6 <- ip2
I0526 15:08:08.004451 12837 net.cpp:397] relu6 -> ip2 (in-place)
I0526 15:08:08.004969 12837 net.cpp:150] Setting up relu6
I0526 15:08:08.004986 12837 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:08:08.004997 12837 net.cpp:165] Memory required for data: 31566000
I0526 15:08:08.005005 12837 layer_factory.hpp:77] Creating layer drop2
I0526 15:08:08.005023 12837 net.cpp:106] Creating Layer drop2
I0526 15:08:08.005033 12837 net.cpp:454] drop2 <- ip2
I0526 15:08:08.005046 12837 net.cpp:397] drop2 -> ip2 (in-place)
I0526 15:08:08.005089 12837 net.cpp:150] Setting up drop2
I0526 15:08:08.005102 12837 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:08:08.005112 12837 net.cpp:165] Memory required for data: 31573840
I0526 15:08:08.005122 12837 layer_factory.hpp:77] Creating layer ip3
I0526 15:08:08.005136 12837 net.cpp:106] Creating Layer ip3
I0526 15:08:08.005146 12837 net.cpp:454] ip3 <- ip2
I0526 15:08:08.005159 12837 net.cpp:411] ip3 -> ip3
I0526 15:08:08.005372 12837 net.cpp:150] Setting up ip3
I0526 15:08:08.005384 12837 net.cpp:157] Top shape: 20 11 (220)
I0526 15:08:08.005393 12837 net.cpp:165] Memory required for data: 31574720
I0526 15:08:08.005409 12837 layer_factory.hpp:77] Creating layer drop3
I0526 15:08:08.005422 12837 net.cpp:106] Creating Layer drop3
I0526 15:08:08.005432 12837 net.cpp:454] drop3 <- ip3
I0526 15:08:08.005445 12837 net.cpp:397] drop3 -> ip3 (in-place)
I0526 15:08:08.005484 12837 net.cpp:150] Setting up drop3
I0526 15:08:08.005496 12837 net.cpp:157] Top shape: 20 11 (220)
I0526 15:08:08.005506 12837 net.cpp:165] Memory required for data: 31575600
I0526 15:08:08.005517 12837 layer_factory.hpp:77] Creating layer loss
I0526 15:08:08.005535 12837 net.cpp:106] Creating Layer loss
I0526 15:08:08.005545 12837 net.cpp:454] loss <- ip3
I0526 15:08:08.005556 12837 net.cpp:454] loss <- label
I0526 15:08:08.005569 12837 net.cpp:411] loss -> loss
I0526 15:08:08.005586 12837 layer_factory.hpp:77] Creating layer loss
I0526 15:08:08.006223 12837 net.cpp:150] Setting up loss
I0526 15:08:08.006245 12837 net.cpp:157] Top shape: (1)
I0526 15:08:08.006256 12837 net.cpp:160]     with loss weight 1
I0526 15:08:08.006300 12837 net.cpp:165] Memory required for data: 31575604
I0526 15:08:08.006310 12837 net.cpp:226] loss needs backward computation.
I0526 15:08:08.006322 12837 net.cpp:226] drop3 needs backward computation.
I0526 15:08:08.006331 12837 net.cpp:226] ip3 needs backward computation.
I0526 15:08:08.006341 12837 net.cpp:226] drop2 needs backward computation.
I0526 15:08:08.006351 12837 net.cpp:226] relu6 needs backward computation.
I0526 15:08:08.006361 12837 net.cpp:226] ip2 needs backward computation.
I0526 15:08:08.006371 12837 net.cpp:226] drop1 needs backward computation.
I0526 15:08:08.006381 12837 net.cpp:226] relu5 needs backward computation.
I0526 15:08:08.006391 12837 net.cpp:226] ip1 needs backward computation.
I0526 15:08:08.006400 12837 net.cpp:226] pool4 needs backward computation.
I0526 15:08:08.006412 12837 net.cpp:226] relu4 needs backward computation.
I0526 15:08:08.006422 12837 net.cpp:226] conv4 needs backward computation.
I0526 15:08:08.006433 12837 net.cpp:226] pool3 needs backward computation.
I0526 15:08:08.006443 12837 net.cpp:226] relu3 needs backward computation.
I0526 15:08:08.006453 12837 net.cpp:226] conv3 needs backward computation.
I0526 15:08:08.006470 12837 net.cpp:226] pool2 needs backward computation.
I0526 15:08:08.006481 12837 net.cpp:226] relu2 needs backward computation.
I0526 15:08:08.006492 12837 net.cpp:226] conv2 needs backward computation.
I0526 15:08:08.006502 12837 net.cpp:226] pool1 needs backward computation.
I0526 15:08:08.006511 12837 net.cpp:226] relu1 needs backward computation.
I0526 15:08:08.006521 12837 net.cpp:226] conv1 needs backward computation.
I0526 15:08:08.006532 12837 net.cpp:228] data_hdf5 does not need backward computation.
I0526 15:08:08.006542 12837 net.cpp:270] This network produces output loss
I0526 15:08:08.006567 12837 net.cpp:283] Network initialization done.
I0526 15:08:08.016266 12837 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961.prototxt
I0526 15:08:08.016345 12837 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 15:08:08.016705 12837 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 15:08:08.016898 12837 layer_factory.hpp:77] Creating layer data_hdf5
I0526 15:08:08.016913 12837 net.cpp:106] Creating Layer data_hdf5
I0526 15:08:08.016926 12837 net.cpp:411] data_hdf5 -> data
I0526 15:08:08.016942 12837 net.cpp:411] data_hdf5 -> label
I0526 15:08:08.016958 12837 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 15:08:08.039788 12837 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 15:08:29.482591 12837 net.cpp:150] Setting up data_hdf5
I0526 15:08:29.482756 12837 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 15:08:29.482771 12837 net.cpp:157] Top shape: 20 (20)
I0526 15:08:29.482784 12837 net.cpp:165] Memory required for data: 508080
I0526 15:08:29.482800 12837 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 15:08:29.482827 12837 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 15:08:29.482838 12837 net.cpp:454] label_data_hdf5_1_split <- label
I0526 15:08:29.482853 12837 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 15:08:29.482874 12837 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 15:08:29.482949 12837 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 15:08:29.482962 12837 net.cpp:157] Top shape: 20 (20)
I0526 15:08:29.482975 12837 net.cpp:157] Top shape: 20 (20)
I0526 15:08:29.482985 12837 net.cpp:165] Memory required for data: 508240
I0526 15:08:29.482995 12837 layer_factory.hpp:77] Creating layer conv1
I0526 15:08:29.483016 12837 net.cpp:106] Creating Layer conv1
I0526 15:08:29.483026 12837 net.cpp:454] conv1 <- data
I0526 15:08:29.483039 12837 net.cpp:411] conv1 -> conv1
I0526 15:08:29.484987 12837 net.cpp:150] Setting up conv1
I0526 15:08:29.485009 12837 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:08:29.485020 12837 net.cpp:165] Memory required for data: 6037840
I0526 15:08:29.485041 12837 layer_factory.hpp:77] Creating layer relu1
I0526 15:08:29.485056 12837 net.cpp:106] Creating Layer relu1
I0526 15:08:29.485066 12837 net.cpp:454] relu1 <- conv1
I0526 15:08:29.485080 12837 net.cpp:397] relu1 -> conv1 (in-place)
I0526 15:08:29.485589 12837 net.cpp:150] Setting up relu1
I0526 15:08:29.485605 12837 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:08:29.485615 12837 net.cpp:165] Memory required for data: 11567440
I0526 15:08:29.485625 12837 layer_factory.hpp:77] Creating layer pool1
I0526 15:08:29.485641 12837 net.cpp:106] Creating Layer pool1
I0526 15:08:29.485651 12837 net.cpp:454] pool1 <- conv1
I0526 15:08:29.485662 12837 net.cpp:411] pool1 -> pool1
I0526 15:08:29.485738 12837 net.cpp:150] Setting up pool1
I0526 15:08:29.485750 12837 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 15:08:29.485759 12837 net.cpp:165] Memory required for data: 14332240
I0526 15:08:29.485769 12837 layer_factory.hpp:77] Creating layer conv2
I0526 15:08:29.485786 12837 net.cpp:106] Creating Layer conv2
I0526 15:08:29.485797 12837 net.cpp:454] conv2 <- pool1
I0526 15:08:29.485811 12837 net.cpp:411] conv2 -> conv2
I0526 15:08:29.487735 12837 net.cpp:150] Setting up conv2
I0526 15:08:29.487757 12837 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:08:29.487769 12837 net.cpp:165] Memory required for data: 18306640
I0526 15:08:29.487787 12837 layer_factory.hpp:77] Creating layer relu2
I0526 15:08:29.487800 12837 net.cpp:106] Creating Layer relu2
I0526 15:08:29.487809 12837 net.cpp:454] relu2 <- conv2
I0526 15:08:29.487823 12837 net.cpp:397] relu2 -> conv2 (in-place)
I0526 15:08:29.488155 12837 net.cpp:150] Setting up relu2
I0526 15:08:29.488169 12837 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:08:29.488179 12837 net.cpp:165] Memory required for data: 22281040
I0526 15:08:29.488188 12837 layer_factory.hpp:77] Creating layer pool2
I0526 15:08:29.488203 12837 net.cpp:106] Creating Layer pool2
I0526 15:08:29.488212 12837 net.cpp:454] pool2 <- conv2
I0526 15:08:29.488224 12837 net.cpp:411] pool2 -> pool2
I0526 15:08:29.488296 12837 net.cpp:150] Setting up pool2
I0526 15:08:29.488309 12837 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 15:08:29.488319 12837 net.cpp:165] Memory required for data: 24268240
I0526 15:08:29.488328 12837 layer_factory.hpp:77] Creating layer conv3
I0526 15:08:29.488348 12837 net.cpp:106] Creating Layer conv3
I0526 15:08:29.488358 12837 net.cpp:454] conv3 <- pool2
I0526 15:08:29.488371 12837 net.cpp:411] conv3 -> conv3
I0526 15:08:29.490335 12837 net.cpp:150] Setting up conv3
I0526 15:08:29.490358 12837 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:08:29.490368 12837 net.cpp:165] Memory required for data: 26436560
I0526 15:08:29.490386 12837 layer_factory.hpp:77] Creating layer relu3
I0526 15:08:29.490412 12837 net.cpp:106] Creating Layer relu3
I0526 15:08:29.490423 12837 net.cpp:454] relu3 <- conv3
I0526 15:08:29.490437 12837 net.cpp:397] relu3 -> conv3 (in-place)
I0526 15:08:29.490906 12837 net.cpp:150] Setting up relu3
I0526 15:08:29.490923 12837 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:08:29.490933 12837 net.cpp:165] Memory required for data: 28604880
I0526 15:08:29.490942 12837 layer_factory.hpp:77] Creating layer pool3
I0526 15:08:29.490955 12837 net.cpp:106] Creating Layer pool3
I0526 15:08:29.490965 12837 net.cpp:454] pool3 <- conv3
I0526 15:08:29.490978 12837 net.cpp:411] pool3 -> pool3
I0526 15:08:29.491050 12837 net.cpp:150] Setting up pool3
I0526 15:08:29.491062 12837 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 15:08:29.491072 12837 net.cpp:165] Memory required for data: 29689040
I0526 15:08:29.491082 12837 layer_factory.hpp:77] Creating layer conv4
I0526 15:08:29.491099 12837 net.cpp:106] Creating Layer conv4
I0526 15:08:29.491109 12837 net.cpp:454] conv4 <- pool3
I0526 15:08:29.491122 12837 net.cpp:411] conv4 -> conv4
I0526 15:08:29.493183 12837 net.cpp:150] Setting up conv4
I0526 15:08:29.493206 12837 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:08:29.493216 12837 net.cpp:165] Memory required for data: 30414800
I0526 15:08:29.493232 12837 layer_factory.hpp:77] Creating layer relu4
I0526 15:08:29.493245 12837 net.cpp:106] Creating Layer relu4
I0526 15:08:29.493255 12837 net.cpp:454] relu4 <- conv4
I0526 15:08:29.493268 12837 net.cpp:397] relu4 -> conv4 (in-place)
I0526 15:08:29.493741 12837 net.cpp:150] Setting up relu4
I0526 15:08:29.493757 12837 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:08:29.493767 12837 net.cpp:165] Memory required for data: 31140560
I0526 15:08:29.493777 12837 layer_factory.hpp:77] Creating layer pool4
I0526 15:08:29.493790 12837 net.cpp:106] Creating Layer pool4
I0526 15:08:29.493800 12837 net.cpp:454] pool4 <- conv4
I0526 15:08:29.493813 12837 net.cpp:411] pool4 -> pool4
I0526 15:08:29.493885 12837 net.cpp:150] Setting up pool4
I0526 15:08:29.493898 12837 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 15:08:29.493908 12837 net.cpp:165] Memory required for data: 31503440
I0526 15:08:29.493918 12837 layer_factory.hpp:77] Creating layer ip1
I0526 15:08:29.493935 12837 net.cpp:106] Creating Layer ip1
I0526 15:08:29.493945 12837 net.cpp:454] ip1 <- pool4
I0526 15:08:29.493959 12837 net.cpp:411] ip1 -> ip1
I0526 15:08:29.509361 12837 net.cpp:150] Setting up ip1
I0526 15:08:29.509383 12837 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:08:29.509402 12837 net.cpp:165] Memory required for data: 31519120
I0526 15:08:29.509423 12837 layer_factory.hpp:77] Creating layer relu5
I0526 15:08:29.509438 12837 net.cpp:106] Creating Layer relu5
I0526 15:08:29.509449 12837 net.cpp:454] relu5 <- ip1
I0526 15:08:29.509464 12837 net.cpp:397] relu5 -> ip1 (in-place)
I0526 15:08:29.509812 12837 net.cpp:150] Setting up relu5
I0526 15:08:29.509826 12837 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:08:29.509836 12837 net.cpp:165] Memory required for data: 31534800
I0526 15:08:29.509845 12837 layer_factory.hpp:77] Creating layer drop1
I0526 15:08:29.509866 12837 net.cpp:106] Creating Layer drop1
I0526 15:08:29.509876 12837 net.cpp:454] drop1 <- ip1
I0526 15:08:29.509888 12837 net.cpp:397] drop1 -> ip1 (in-place)
I0526 15:08:29.509935 12837 net.cpp:150] Setting up drop1
I0526 15:08:29.509948 12837 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:08:29.509958 12837 net.cpp:165] Memory required for data: 31550480
I0526 15:08:29.509966 12837 layer_factory.hpp:77] Creating layer ip2
I0526 15:08:29.509981 12837 net.cpp:106] Creating Layer ip2
I0526 15:08:29.509991 12837 net.cpp:454] ip2 <- ip1
I0526 15:08:29.510005 12837 net.cpp:411] ip2 -> ip2
I0526 15:08:29.510488 12837 net.cpp:150] Setting up ip2
I0526 15:08:29.510500 12837 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:08:29.510510 12837 net.cpp:165] Memory required for data: 31558320
I0526 15:08:29.510525 12837 layer_factory.hpp:77] Creating layer relu6
I0526 15:08:29.510550 12837 net.cpp:106] Creating Layer relu6
I0526 15:08:29.510560 12837 net.cpp:454] relu6 <- ip2
I0526 15:08:29.510572 12837 net.cpp:397] relu6 -> ip2 (in-place)
I0526 15:08:29.511104 12837 net.cpp:150] Setting up relu6
I0526 15:08:29.511121 12837 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:08:29.511131 12837 net.cpp:165] Memory required for data: 31566160
I0526 15:08:29.511139 12837 layer_factory.hpp:77] Creating layer drop2
I0526 15:08:29.511152 12837 net.cpp:106] Creating Layer drop2
I0526 15:08:29.511162 12837 net.cpp:454] drop2 <- ip2
I0526 15:08:29.511175 12837 net.cpp:397] drop2 -> ip2 (in-place)
I0526 15:08:29.511219 12837 net.cpp:150] Setting up drop2
I0526 15:08:29.511232 12837 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:08:29.511242 12837 net.cpp:165] Memory required for data: 31574000
I0526 15:08:29.511252 12837 layer_factory.hpp:77] Creating layer ip3
I0526 15:08:29.511266 12837 net.cpp:106] Creating Layer ip3
I0526 15:08:29.511276 12837 net.cpp:454] ip3 <- ip2
I0526 15:08:29.511291 12837 net.cpp:411] ip3 -> ip3
I0526 15:08:29.511523 12837 net.cpp:150] Setting up ip3
I0526 15:08:29.511535 12837 net.cpp:157] Top shape: 20 11 (220)
I0526 15:08:29.511545 12837 net.cpp:165] Memory required for data: 31574880
I0526 15:08:29.511562 12837 layer_factory.hpp:77] Creating layer drop3
I0526 15:08:29.511575 12837 net.cpp:106] Creating Layer drop3
I0526 15:08:29.511585 12837 net.cpp:454] drop3 <- ip3
I0526 15:08:29.511598 12837 net.cpp:397] drop3 -> ip3 (in-place)
I0526 15:08:29.511639 12837 net.cpp:150] Setting up drop3
I0526 15:08:29.511652 12837 net.cpp:157] Top shape: 20 11 (220)
I0526 15:08:29.511663 12837 net.cpp:165] Memory required for data: 31575760
I0526 15:08:29.511672 12837 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 15:08:29.511685 12837 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 15:08:29.511695 12837 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 15:08:29.511708 12837 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 15:08:29.511723 12837 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 15:08:29.511795 12837 net.cpp:150] Setting up ip3_drop3_0_split
I0526 15:08:29.511809 12837 net.cpp:157] Top shape: 20 11 (220)
I0526 15:08:29.511822 12837 net.cpp:157] Top shape: 20 11 (220)
I0526 15:08:29.511831 12837 net.cpp:165] Memory required for data: 31577520
I0526 15:08:29.511842 12837 layer_factory.hpp:77] Creating layer accuracy
I0526 15:08:29.511862 12837 net.cpp:106] Creating Layer accuracy
I0526 15:08:29.511873 12837 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 15:08:29.511883 12837 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 15:08:29.511895 12837 net.cpp:411] accuracy -> accuracy
I0526 15:08:29.511919 12837 net.cpp:150] Setting up accuracy
I0526 15:08:29.511931 12837 net.cpp:157] Top shape: (1)
I0526 15:08:29.511941 12837 net.cpp:165] Memory required for data: 31577524
I0526 15:08:29.511950 12837 layer_factory.hpp:77] Creating layer loss
I0526 15:08:29.511965 12837 net.cpp:106] Creating Layer loss
I0526 15:08:29.511975 12837 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 15:08:29.511986 12837 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 15:08:29.511998 12837 net.cpp:411] loss -> loss
I0526 15:08:29.512015 12837 layer_factory.hpp:77] Creating layer loss
I0526 15:08:29.512497 12837 net.cpp:150] Setting up loss
I0526 15:08:29.512511 12837 net.cpp:157] Top shape: (1)
I0526 15:08:29.512521 12837 net.cpp:160]     with loss weight 1
I0526 15:08:29.512542 12837 net.cpp:165] Memory required for data: 31577528
I0526 15:08:29.512552 12837 net.cpp:226] loss needs backward computation.
I0526 15:08:29.512564 12837 net.cpp:228] accuracy does not need backward computation.
I0526 15:08:29.512575 12837 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 15:08:29.512586 12837 net.cpp:226] drop3 needs backward computation.
I0526 15:08:29.512594 12837 net.cpp:226] ip3 needs backward computation.
I0526 15:08:29.512604 12837 net.cpp:226] drop2 needs backward computation.
I0526 15:08:29.512614 12837 net.cpp:226] relu6 needs backward computation.
I0526 15:08:29.512632 12837 net.cpp:226] ip2 needs backward computation.
I0526 15:08:29.512644 12837 net.cpp:226] drop1 needs backward computation.
I0526 15:08:29.512653 12837 net.cpp:226] relu5 needs backward computation.
I0526 15:08:29.512665 12837 net.cpp:226] ip1 needs backward computation.
I0526 15:08:29.512675 12837 net.cpp:226] pool4 needs backward computation.
I0526 15:08:29.512686 12837 net.cpp:226] relu4 needs backward computation.
I0526 15:08:29.512696 12837 net.cpp:226] conv4 needs backward computation.
I0526 15:08:29.512706 12837 net.cpp:226] pool3 needs backward computation.
I0526 15:08:29.512715 12837 net.cpp:226] relu3 needs backward computation.
I0526 15:08:29.512725 12837 net.cpp:226] conv3 needs backward computation.
I0526 15:08:29.512737 12837 net.cpp:226] pool2 needs backward computation.
I0526 15:08:29.512747 12837 net.cpp:226] relu2 needs backward computation.
I0526 15:08:29.512754 12837 net.cpp:226] conv2 needs backward computation.
I0526 15:08:29.512765 12837 net.cpp:226] pool1 needs backward computation.
I0526 15:08:29.512776 12837 net.cpp:226] relu1 needs backward computation.
I0526 15:08:29.512786 12837 net.cpp:226] conv1 needs backward computation.
I0526 15:08:29.512799 12837 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 15:08:29.512810 12837 net.cpp:228] data_hdf5 does not need backward computation.
I0526 15:08:29.512820 12837 net.cpp:270] This network produces output accuracy
I0526 15:08:29.512830 12837 net.cpp:270] This network produces output loss
I0526 15:08:29.512857 12837 net.cpp:283] Network initialization done.
I0526 15:08:29.512990 12837 solver.cpp:60] Solver scaffolding done.
I0526 15:08:29.514125 12837 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_285000.solverstate
I0526 15:08:29.808413 12837 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 15:08:29.813913 12837 caffe.cpp:212] Starting Optimization
I0526 15:08:29.813953 12837 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 15:08:29.813966 12837 solver.cpp:289] Learning Rate Policy: fixed
I0526 15:08:29.815338 12837 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 15:09:22.789996 12837 solver.cpp:409]     Test net output #0: accuracy = 0.898798
I0526 15:09:22.790155 12837 solver.cpp:409]     Test net output #1: loss = 0.316358 (* 1 = 0.316358 loss)
I0526 15:09:22.809214 12837 solver.cpp:237] Iteration 285000, loss = 1.41219
I0526 15:09:22.809252 12837 solver.cpp:253]     Train net output #0: loss = 1.41219 (* 1 = 1.41219 loss)
I0526 15:09:22.809272 12837 sgd_solver.cpp:106] Iteration 285000, lr = 0.002
I0526 15:09:34.974540 12837 solver.cpp:237] Iteration 285750, loss = 0.989233
I0526 15:09:34.974577 12837 solver.cpp:253]     Train net output #0: loss = 0.989233 (* 1 = 0.989233 loss)
I0526 15:09:34.974591 12837 sgd_solver.cpp:106] Iteration 285750, lr = 0.002
I0526 15:09:47.125922 12837 solver.cpp:237] Iteration 286500, loss = 0.88738
I0526 15:09:47.125977 12837 solver.cpp:253]     Train net output #0: loss = 0.88738 (* 1 = 0.88738 loss)
I0526 15:09:47.125993 12837 sgd_solver.cpp:106] Iteration 286500, lr = 0.002
I0526 15:09:59.277662 12837 solver.cpp:237] Iteration 287250, loss = 0.749569
I0526 15:09:59.277806 12837 solver.cpp:253]     Train net output #0: loss = 0.749569 (* 1 = 0.749569 loss)
I0526 15:09:59.277820 12837 sgd_solver.cpp:106] Iteration 287250, lr = 0.002
I0526 15:10:11.442529 12837 solver.cpp:237] Iteration 288000, loss = 0.794414
I0526 15:10:11.442582 12837 solver.cpp:253]     Train net output #0: loss = 0.794414 (* 1 = 0.794414 loss)
I0526 15:10:11.442596 12837 sgd_solver.cpp:106] Iteration 288000, lr = 0.002
I0526 15:10:23.628119 12837 solver.cpp:237] Iteration 288750, loss = 1.41748
I0526 15:10:23.628155 12837 solver.cpp:253]     Train net output #0: loss = 1.41748 (* 1 = 1.41748 loss)
I0526 15:10:23.628170 12837 sgd_solver.cpp:106] Iteration 288750, lr = 0.002
I0526 15:10:35.815477 12837 solver.cpp:237] Iteration 289500, loss = 1.57371
I0526 15:10:35.815650 12837 solver.cpp:253]     Train net output #0: loss = 1.57371 (* 1 = 1.57371 loss)
I0526 15:10:35.815667 12837 sgd_solver.cpp:106] Iteration 289500, lr = 0.002
I0526 15:11:10.244370 12837 solver.cpp:237] Iteration 290250, loss = 1.16874
I0526 15:11:10.244534 12837 solver.cpp:253]     Train net output #0: loss = 1.16874 (* 1 = 1.16874 loss)
I0526 15:11:10.244547 12837 sgd_solver.cpp:106] Iteration 290250, lr = 0.002
I0526 15:11:22.422425 12837 solver.cpp:237] Iteration 291000, loss = 1.06268
I0526 15:11:22.422477 12837 solver.cpp:253]     Train net output #0: loss = 1.06268 (* 1 = 1.06268 loss)
I0526 15:11:22.422492 12837 sgd_solver.cpp:106] Iteration 291000, lr = 0.002
I0526 15:11:34.584043 12837 solver.cpp:237] Iteration 291750, loss = 2.28427
I0526 15:11:34.584080 12837 solver.cpp:253]     Train net output #0: loss = 2.28428 (* 1 = 2.28428 loss)
I0526 15:11:34.584094 12837 sgd_solver.cpp:106] Iteration 291750, lr = 0.002
I0526 15:11:46.723901 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_292500.caffemodel
I0526 15:11:46.781082 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_292500.solverstate
I0526 15:11:46.813612 12837 solver.cpp:237] Iteration 292500, loss = 0.862772
I0526 15:11:46.813662 12837 solver.cpp:253]     Train net output #0: loss = 0.862772 (* 1 = 0.862772 loss)
I0526 15:11:46.813676 12837 sgd_solver.cpp:106] Iteration 292500, lr = 0.002
I0526 15:11:58.975503 12837 solver.cpp:237] Iteration 293250, loss = 1.37871
I0526 15:11:58.975544 12837 solver.cpp:253]     Train net output #0: loss = 1.37871 (* 1 = 1.37871 loss)
I0526 15:11:58.975558 12837 sgd_solver.cpp:106] Iteration 293250, lr = 0.002
I0526 15:12:11.132171 12837 solver.cpp:237] Iteration 294000, loss = 0.582869
I0526 15:12:11.132225 12837 solver.cpp:253]     Train net output #0: loss = 0.582869 (* 1 = 0.582869 loss)
I0526 15:12:11.132239 12837 sgd_solver.cpp:106] Iteration 294000, lr = 0.002
I0526 15:12:23.322912 12837 solver.cpp:237] Iteration 294750, loss = 1.13015
I0526 15:12:23.323053 12837 solver.cpp:253]     Train net output #0: loss = 1.13015 (* 1 = 1.13015 loss)
I0526 15:12:23.323066 12837 sgd_solver.cpp:106] Iteration 294750, lr = 0.002
I0526 15:12:57.664607 12837 solver.cpp:237] Iteration 295500, loss = 1.26888
I0526 15:12:57.664775 12837 solver.cpp:253]     Train net output #0: loss = 1.26888 (* 1 = 1.26888 loss)
I0526 15:12:57.664790 12837 sgd_solver.cpp:106] Iteration 295500, lr = 0.002
I0526 15:13:09.843245 12837 solver.cpp:237] Iteration 296250, loss = 1.02684
I0526 15:13:09.843281 12837 solver.cpp:253]     Train net output #0: loss = 1.02684 (* 1 = 1.02684 loss)
I0526 15:13:09.843294 12837 sgd_solver.cpp:106] Iteration 296250, lr = 0.002
I0526 15:13:22.025074 12837 solver.cpp:237] Iteration 297000, loss = 0.850398
I0526 15:13:22.025111 12837 solver.cpp:253]     Train net output #0: loss = 0.850398 (* 1 = 0.850398 loss)
I0526 15:13:22.025126 12837 sgd_solver.cpp:106] Iteration 297000, lr = 0.002
I0526 15:13:34.185108 12837 solver.cpp:237] Iteration 297750, loss = 1.37222
I0526 15:13:34.185261 12837 solver.cpp:253]     Train net output #0: loss = 1.37222 (* 1 = 1.37222 loss)
I0526 15:13:34.185276 12837 sgd_solver.cpp:106] Iteration 297750, lr = 0.002
I0526 15:13:46.346068 12837 solver.cpp:237] Iteration 298500, loss = 1.05367
I0526 15:13:46.346104 12837 solver.cpp:253]     Train net output #0: loss = 1.05367 (* 1 = 1.05367 loss)
I0526 15:13:46.346118 12837 sgd_solver.cpp:106] Iteration 298500, lr = 0.002
I0526 15:13:58.538986 12837 solver.cpp:237] Iteration 299250, loss = 1.06791
I0526 15:13:58.539032 12837 solver.cpp:253]     Train net output #0: loss = 1.06792 (* 1 = 1.06792 loss)
I0526 15:13:58.539047 12837 sgd_solver.cpp:106] Iteration 299250, lr = 0.002
I0526 15:14:10.682171 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_300000.caffemodel
I0526 15:14:10.732450 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_300000.solverstate
I0526 15:14:10.759290 12837 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 15:15:02.784214 12837 solver.cpp:409]     Test net output #0: accuracy = 0.901557
I0526 15:15:02.784359 12837 solver.cpp:409]     Test net output #1: loss = 0.307359 (* 1 = 0.307359 loss)
I0526 15:15:25.012068 12837 solver.cpp:237] Iteration 300000, loss = 0.952858
I0526 15:15:25.012125 12837 solver.cpp:253]     Train net output #0: loss = 0.952858 (* 1 = 0.952858 loss)
I0526 15:15:25.012141 12837 sgd_solver.cpp:106] Iteration 300000, lr = 0.002
I0526 15:15:37.152295 12837 solver.cpp:237] Iteration 300750, loss = 1.05039
I0526 15:15:37.152449 12837 solver.cpp:253]     Train net output #0: loss = 1.05039 (* 1 = 1.05039 loss)
I0526 15:15:37.152462 12837 sgd_solver.cpp:106] Iteration 300750, lr = 0.002
I0526 15:15:49.284271 12837 solver.cpp:237] Iteration 301500, loss = 1.18576
I0526 15:15:49.284307 12837 solver.cpp:253]     Train net output #0: loss = 1.18576 (* 1 = 1.18576 loss)
I0526 15:15:49.284320 12837 sgd_solver.cpp:106] Iteration 301500, lr = 0.002
I0526 15:16:01.444895 12837 solver.cpp:237] Iteration 302250, loss = 1.2442
I0526 15:16:01.444941 12837 solver.cpp:253]     Train net output #0: loss = 1.2442 (* 1 = 1.2442 loss)
I0526 15:16:01.444954 12837 sgd_solver.cpp:106] Iteration 302250, lr = 0.002
I0526 15:16:13.582638 12837 solver.cpp:237] Iteration 303000, loss = 0.968261
I0526 15:16:13.582777 12837 solver.cpp:253]     Train net output #0: loss = 0.968262 (* 1 = 0.968262 loss)
I0526 15:16:13.582792 12837 sgd_solver.cpp:106] Iteration 303000, lr = 0.002
I0526 15:16:25.682440 12837 solver.cpp:237] Iteration 303750, loss = 1.62966
I0526 15:16:25.682487 12837 solver.cpp:253]     Train net output #0: loss = 1.62966 (* 1 = 1.62966 loss)
I0526 15:16:25.682502 12837 sgd_solver.cpp:106] Iteration 303750, lr = 0.002
I0526 15:16:37.764366 12837 solver.cpp:237] Iteration 304500, loss = 1.35187
I0526 15:16:37.764402 12837 solver.cpp:253]     Train net output #0: loss = 1.35187 (* 1 = 1.35187 loss)
I0526 15:16:37.764416 12837 sgd_solver.cpp:106] Iteration 304500, lr = 0.002
I0526 15:17:12.064321 12837 solver.cpp:237] Iteration 305250, loss = 1.55774
I0526 15:17:12.064497 12837 solver.cpp:253]     Train net output #0: loss = 1.55774 (* 1 = 1.55774 loss)
I0526 15:17:12.064512 12837 sgd_solver.cpp:106] Iteration 305250, lr = 0.002
I0526 15:17:24.149435 12837 solver.cpp:237] Iteration 306000, loss = 1.14501
I0526 15:17:24.149471 12837 solver.cpp:253]     Train net output #0: loss = 1.14501 (* 1 = 1.14501 loss)
I0526 15:17:24.149485 12837 sgd_solver.cpp:106] Iteration 306000, lr = 0.002
I0526 15:17:36.249240 12837 solver.cpp:237] Iteration 306750, loss = 0.99219
I0526 15:17:36.249289 12837 solver.cpp:253]     Train net output #0: loss = 0.99219 (* 1 = 0.99219 loss)
I0526 15:17:36.249303 12837 sgd_solver.cpp:106] Iteration 306750, lr = 0.002
I0526 15:17:48.372673 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_307500.caffemodel
I0526 15:17:48.424269 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_307500.solverstate
I0526 15:17:48.456356 12837 solver.cpp:237] Iteration 307500, loss = 1.09339
I0526 15:17:48.456408 12837 solver.cpp:253]     Train net output #0: loss = 1.09339 (* 1 = 1.09339 loss)
I0526 15:17:48.456425 12837 sgd_solver.cpp:106] Iteration 307500, lr = 0.002
I0526 15:18:00.581810 12837 solver.cpp:237] Iteration 308250, loss = 1.29355
I0526 15:18:00.581858 12837 solver.cpp:253]     Train net output #0: loss = 1.29355 (* 1 = 1.29355 loss)
I0526 15:18:00.581872 12837 sgd_solver.cpp:106] Iteration 308250, lr = 0.002
I0526 15:18:12.678048 12837 solver.cpp:237] Iteration 309000, loss = 1.01541
I0526 15:18:12.678083 12837 solver.cpp:253]     Train net output #0: loss = 1.01541 (* 1 = 1.01541 loss)
I0526 15:18:12.678097 12837 sgd_solver.cpp:106] Iteration 309000, lr = 0.002
I0526 15:18:24.795277 12837 solver.cpp:237] Iteration 309750, loss = 0.897306
I0526 15:18:24.795429 12837 solver.cpp:253]     Train net output #0: loss = 0.897306 (* 1 = 0.897306 loss)
I0526 15:18:24.795444 12837 sgd_solver.cpp:106] Iteration 309750, lr = 0.002
I0526 15:18:59.139662 12837 solver.cpp:237] Iteration 310500, loss = 1.04293
I0526 15:18:59.139829 12837 solver.cpp:253]     Train net output #0: loss = 1.04293 (* 1 = 1.04293 loss)
I0526 15:18:59.139843 12837 sgd_solver.cpp:106] Iteration 310500, lr = 0.002
I0526 15:19:11.326164 12837 solver.cpp:237] Iteration 311250, loss = 1.12739
I0526 15:19:11.326200 12837 solver.cpp:253]     Train net output #0: loss = 1.12739 (* 1 = 1.12739 loss)
I0526 15:19:11.326213 12837 sgd_solver.cpp:106] Iteration 311250, lr = 0.002
I0526 15:19:23.498523 12837 solver.cpp:237] Iteration 312000, loss = 1.44196
I0526 15:19:23.498571 12837 solver.cpp:253]     Train net output #0: loss = 1.44196 (* 1 = 1.44196 loss)
I0526 15:19:23.498585 12837 sgd_solver.cpp:106] Iteration 312000, lr = 0.002
I0526 15:19:35.626646 12837 solver.cpp:237] Iteration 312750, loss = 1.07787
I0526 15:19:35.626782 12837 solver.cpp:253]     Train net output #0: loss = 1.07787 (* 1 = 1.07787 loss)
I0526 15:19:35.626796 12837 sgd_solver.cpp:106] Iteration 312750, lr = 0.002
I0526 15:19:47.753509 12837 solver.cpp:237] Iteration 313500, loss = 1.18717
I0526 15:19:47.753556 12837 solver.cpp:253]     Train net output #0: loss = 1.18717 (* 1 = 1.18717 loss)
I0526 15:19:47.753569 12837 sgd_solver.cpp:106] Iteration 313500, lr = 0.002
I0526 15:19:59.886219 12837 solver.cpp:237] Iteration 314250, loss = 1.18178
I0526 15:19:59.886255 12837 solver.cpp:253]     Train net output #0: loss = 1.18178 (* 1 = 1.18178 loss)
I0526 15:19:59.886268 12837 sgd_solver.cpp:106] Iteration 314250, lr = 0.002
I0526 15:20:12.007642 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_315000.caffemodel
I0526 15:20:12.058558 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_315000.solverstate
I0526 15:20:12.086405 12837 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 15:21:25.099050 12837 solver.cpp:409]     Test net output #0: accuracy = 0.900745
I0526 15:21:25.099227 12837 solver.cpp:409]     Test net output #1: loss = 0.317035 (* 1 = 0.317035 loss)
I0526 15:21:47.334731 12837 solver.cpp:237] Iteration 315000, loss = 1.13051
I0526 15:21:47.334789 12837 solver.cpp:253]     Train net output #0: loss = 1.13051 (* 1 = 1.13051 loss)
I0526 15:21:47.334805 12837 sgd_solver.cpp:106] Iteration 315000, lr = 0.002
I0526 15:21:59.514138 12837 solver.cpp:237] Iteration 315750, loss = 0.86852
I0526 15:21:59.514284 12837 solver.cpp:253]     Train net output #0: loss = 0.86852 (* 1 = 0.86852 loss)
I0526 15:21:59.514298 12837 sgd_solver.cpp:106] Iteration 315750, lr = 0.002
I0526 15:22:11.671612 12837 solver.cpp:237] Iteration 316500, loss = 0.858198
I0526 15:22:11.671663 12837 solver.cpp:253]     Train net output #0: loss = 0.858198 (* 1 = 0.858198 loss)
I0526 15:22:11.671676 12837 sgd_solver.cpp:106] Iteration 316500, lr = 0.002
I0526 15:22:23.825021 12837 solver.cpp:237] Iteration 317250, loss = 1.14084
I0526 15:22:23.825057 12837 solver.cpp:253]     Train net output #0: loss = 1.14084 (* 1 = 1.14084 loss)
I0526 15:22:23.825072 12837 sgd_solver.cpp:106] Iteration 317250, lr = 0.002
I0526 15:22:36.003715 12837 solver.cpp:237] Iteration 318000, loss = 0.911131
I0526 15:22:36.003885 12837 solver.cpp:253]     Train net output #0: loss = 0.911131 (* 1 = 0.911131 loss)
I0526 15:22:36.003902 12837 sgd_solver.cpp:106] Iteration 318000, lr = 0.002
I0526 15:22:48.223722 12837 solver.cpp:237] Iteration 318750, loss = 1.01659
I0526 15:22:48.223758 12837 solver.cpp:253]     Train net output #0: loss = 1.01659 (* 1 = 1.01659 loss)
I0526 15:22:48.223773 12837 sgd_solver.cpp:106] Iteration 318750, lr = 0.002
I0526 15:23:00.441897 12837 solver.cpp:237] Iteration 319500, loss = 1.1064
I0526 15:23:00.441947 12837 solver.cpp:253]     Train net output #0: loss = 1.1064 (* 1 = 1.1064 loss)
I0526 15:23:00.441962 12837 sgd_solver.cpp:106] Iteration 319500, lr = 0.002
I0526 15:23:34.790642 12837 solver.cpp:237] Iteration 320250, loss = 1.51382
I0526 15:23:34.790812 12837 solver.cpp:253]     Train net output #0: loss = 1.51382 (* 1 = 1.51382 loss)
I0526 15:23:34.790827 12837 sgd_solver.cpp:106] Iteration 320250, lr = 0.002
I0526 15:23:46.863126 12837 solver.cpp:237] Iteration 321000, loss = 0.985516
I0526 15:23:46.863163 12837 solver.cpp:253]     Train net output #0: loss = 0.985516 (* 1 = 0.985516 loss)
I0526 15:23:46.863176 12837 sgd_solver.cpp:106] Iteration 321000, lr = 0.002
I0526 15:23:58.941521 12837 solver.cpp:237] Iteration 321750, loss = 1.27917
I0526 15:23:58.941561 12837 solver.cpp:253]     Train net output #0: loss = 1.27917 (* 1 = 1.27917 loss)
I0526 15:23:58.941576 12837 sgd_solver.cpp:106] Iteration 321750, lr = 0.002
I0526 15:24:11.005035 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_322500.caffemodel
I0526 15:24:11.056423 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_322500.solverstate
I0526 15:24:11.088903 12837 solver.cpp:237] Iteration 322500, loss = 1.46899
I0526 15:24:11.088958 12837 solver.cpp:253]     Train net output #0: loss = 1.46899 (* 1 = 1.46899 loss)
I0526 15:24:11.088973 12837 sgd_solver.cpp:106] Iteration 322500, lr = 0.002
I0526 15:24:23.167395 12837 solver.cpp:237] Iteration 323250, loss = 1.26412
I0526 15:24:23.167441 12837 solver.cpp:253]     Train net output #0: loss = 1.26412 (* 1 = 1.26412 loss)
I0526 15:24:23.167455 12837 sgd_solver.cpp:106] Iteration 323250, lr = 0.002
I0526 15:24:35.254264 12837 solver.cpp:237] Iteration 324000, loss = 1.094
I0526 15:24:35.254299 12837 solver.cpp:253]     Train net output #0: loss = 1.094 (* 1 = 1.094 loss)
I0526 15:24:35.254314 12837 sgd_solver.cpp:106] Iteration 324000, lr = 0.002
I0526 15:24:47.416345 12837 solver.cpp:237] Iteration 324750, loss = 0.911226
I0526 15:24:47.416530 12837 solver.cpp:253]     Train net output #0: loss = 0.911225 (* 1 = 0.911225 loss)
I0526 15:24:47.416544 12837 sgd_solver.cpp:106] Iteration 324750, lr = 0.002
I0526 15:25:21.791481 12837 solver.cpp:237] Iteration 325500, loss = 1.15771
I0526 15:25:21.791796 12837 solver.cpp:253]     Train net output #0: loss = 1.15771 (* 1 = 1.15771 loss)
I0526 15:25:21.791811 12837 sgd_solver.cpp:106] Iteration 325500, lr = 0.002
I0526 15:25:33.943693 12837 solver.cpp:237] Iteration 326250, loss = 0.653808
I0526 15:25:33.943750 12837 solver.cpp:253]     Train net output #0: loss = 0.653808 (* 1 = 0.653808 loss)
I0526 15:25:33.943764 12837 sgd_solver.cpp:106] Iteration 326250, lr = 0.002
I0526 15:25:46.096560 12837 solver.cpp:237] Iteration 327000, loss = 1.4616
I0526 15:25:46.096596 12837 solver.cpp:253]     Train net output #0: loss = 1.46159 (* 1 = 1.46159 loss)
I0526 15:25:46.096609 12837 sgd_solver.cpp:106] Iteration 327000, lr = 0.002
I0526 15:25:58.233134 12837 solver.cpp:237] Iteration 327750, loss = 1.18966
I0526 15:25:58.233309 12837 solver.cpp:253]     Train net output #0: loss = 1.18966 (* 1 = 1.18966 loss)
I0526 15:25:58.233324 12837 sgd_solver.cpp:106] Iteration 327750, lr = 0.002
I0526 15:26:10.348449 12837 solver.cpp:237] Iteration 328500, loss = 1.14741
I0526 15:26:10.348485 12837 solver.cpp:253]     Train net output #0: loss = 1.14741 (* 1 = 1.14741 loss)
I0526 15:26:10.348500 12837 sgd_solver.cpp:106] Iteration 328500, lr = 0.002
I0526 15:26:22.496858 12837 solver.cpp:237] Iteration 329250, loss = 0.778726
I0526 15:26:22.496912 12837 solver.cpp:253]     Train net output #0: loss = 0.778726 (* 1 = 0.778726 loss)
I0526 15:26:22.496925 12837 sgd_solver.cpp:106] Iteration 329250, lr = 0.002
I0526 15:26:34.628736 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_330000.caffemodel
I0526 15:26:34.678711 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_330000.solverstate
I0526 15:26:34.704360 12837 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 15:27:26.349375 12837 solver.cpp:409]     Test net output #0: accuracy = 0.902019
I0526 15:27:26.349539 12837 solver.cpp:409]     Test net output #1: loss = 0.328117 (* 1 = 0.328117 loss)
I0526 15:27:48.592967 12837 solver.cpp:237] Iteration 330000, loss = 0.90425
I0526 15:27:48.593024 12837 solver.cpp:253]     Train net output #0: loss = 0.90425 (* 1 = 0.90425 loss)
I0526 15:27:48.593040 12837 sgd_solver.cpp:106] Iteration 330000, lr = 0.002
I0526 15:28:00.790462 12837 solver.cpp:237] Iteration 330750, loss = 1.33371
I0526 15:28:00.790624 12837 solver.cpp:253]     Train net output #0: loss = 1.33371 (* 1 = 1.33371 loss)
I0526 15:28:00.790638 12837 sgd_solver.cpp:106] Iteration 330750, lr = 0.002
I0526 15:28:12.983379 12837 solver.cpp:237] Iteration 331500, loss = 1.67814
I0526 15:28:12.983414 12837 solver.cpp:253]     Train net output #0: loss = 1.67814 (* 1 = 1.67814 loss)
I0526 15:28:12.983428 12837 sgd_solver.cpp:106] Iteration 331500, lr = 0.002
I0526 15:28:25.196379 12837 solver.cpp:237] Iteration 332250, loss = 1.56789
I0526 15:28:25.196432 12837 solver.cpp:253]     Train net output #0: loss = 1.56789 (* 1 = 1.56789 loss)
I0526 15:28:25.196446 12837 sgd_solver.cpp:106] Iteration 332250, lr = 0.002
I0526 15:28:37.416522 12837 solver.cpp:237] Iteration 333000, loss = 1.16981
I0526 15:28:37.416663 12837 solver.cpp:253]     Train net output #0: loss = 1.16981 (* 1 = 1.16981 loss)
I0526 15:28:37.416677 12837 sgd_solver.cpp:106] Iteration 333000, lr = 0.002
I0526 15:28:49.622020 12837 solver.cpp:237] Iteration 333750, loss = 0.749128
I0526 15:28:49.622073 12837 solver.cpp:253]     Train net output #0: loss = 0.749127 (* 1 = 0.749127 loss)
I0526 15:28:49.622087 12837 sgd_solver.cpp:106] Iteration 333750, lr = 0.002
I0526 15:29:01.822535 12837 solver.cpp:237] Iteration 334500, loss = 0.809796
I0526 15:29:01.822572 12837 solver.cpp:253]     Train net output #0: loss = 0.809796 (* 1 = 0.809796 loss)
I0526 15:29:01.822587 12837 sgd_solver.cpp:106] Iteration 334500, lr = 0.002
I0526 15:29:36.265045 12837 solver.cpp:237] Iteration 335250, loss = 1.22863
I0526 15:29:36.265221 12837 solver.cpp:253]     Train net output #0: loss = 1.22863 (* 1 = 1.22863 loss)
I0526 15:29:36.265236 12837 sgd_solver.cpp:106] Iteration 335250, lr = 0.002
I0526 15:29:48.458297 12837 solver.cpp:237] Iteration 336000, loss = 0.939006
I0526 15:29:48.458343 12837 solver.cpp:253]     Train net output #0: loss = 0.939005 (* 1 = 0.939005 loss)
I0526 15:29:48.458358 12837 sgd_solver.cpp:106] Iteration 336000, lr = 0.002
I0526 15:30:00.652138 12837 solver.cpp:237] Iteration 336750, loss = 1.24126
I0526 15:30:00.652173 12837 solver.cpp:253]     Train net output #0: loss = 1.24126 (* 1 = 1.24126 loss)
I0526 15:30:00.652189 12837 sgd_solver.cpp:106] Iteration 336750, lr = 0.002
I0526 15:30:12.832861 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_337500.caffemodel
I0526 15:30:12.882405 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_337500.solverstate
I0526 15:30:12.912549 12837 solver.cpp:237] Iteration 337500, loss = 1.14084
I0526 15:30:12.912593 12837 solver.cpp:253]     Train net output #0: loss = 1.14084 (* 1 = 1.14084 loss)
I0526 15:30:12.912613 12837 sgd_solver.cpp:106] Iteration 337500, lr = 0.002
I0526 15:30:25.093545 12837 solver.cpp:237] Iteration 338250, loss = 1.23647
I0526 15:30:25.093580 12837 solver.cpp:253]     Train net output #0: loss = 1.23647 (* 1 = 1.23647 loss)
I0526 15:30:25.093596 12837 sgd_solver.cpp:106] Iteration 338250, lr = 0.002
I0526 15:30:37.236652 12837 solver.cpp:237] Iteration 339000, loss = 1.03699
I0526 15:30:37.236706 12837 solver.cpp:253]     Train net output #0: loss = 1.03699 (* 1 = 1.03699 loss)
I0526 15:30:37.236721 12837 sgd_solver.cpp:106] Iteration 339000, lr = 0.002
I0526 15:30:49.390710 12837 solver.cpp:237] Iteration 339750, loss = 0.978635
I0526 15:30:49.390858 12837 solver.cpp:253]     Train net output #0: loss = 0.978635 (* 1 = 0.978635 loss)
I0526 15:30:49.390872 12837 sgd_solver.cpp:106] Iteration 339750, lr = 0.002
I0526 15:31:23.839509 12837 solver.cpp:237] Iteration 340500, loss = 0.856597
I0526 15:31:23.839699 12837 solver.cpp:253]     Train net output #0: loss = 0.856596 (* 1 = 0.856596 loss)
I0526 15:31:23.839714 12837 sgd_solver.cpp:106] Iteration 340500, lr = 0.002
I0526 15:31:36.040071 12837 solver.cpp:237] Iteration 341250, loss = 1.56039
I0526 15:31:36.040105 12837 solver.cpp:253]     Train net output #0: loss = 1.56039 (* 1 = 1.56039 loss)
I0526 15:31:36.040119 12837 sgd_solver.cpp:106] Iteration 341250, lr = 0.002
I0526 15:31:48.229493 12837 solver.cpp:237] Iteration 342000, loss = 1.29397
I0526 15:31:48.229545 12837 solver.cpp:253]     Train net output #0: loss = 1.29397 (* 1 = 1.29397 loss)
I0526 15:31:48.229559 12837 sgd_solver.cpp:106] Iteration 342000, lr = 0.002
I0526 15:32:00.408495 12837 solver.cpp:237] Iteration 342750, loss = 0.926773
I0526 15:32:00.408653 12837 solver.cpp:253]     Train net output #0: loss = 0.926773 (* 1 = 0.926773 loss)
I0526 15:32:00.408666 12837 sgd_solver.cpp:106] Iteration 342750, lr = 0.002
I0526 15:32:12.565521 12837 solver.cpp:237] Iteration 343500, loss = 1.17309
I0526 15:32:12.565573 12837 solver.cpp:253]     Train net output #0: loss = 1.17309 (* 1 = 1.17309 loss)
I0526 15:32:12.565587 12837 sgd_solver.cpp:106] Iteration 343500, lr = 0.002
I0526 15:32:24.697924 12837 solver.cpp:237] Iteration 344250, loss = 1.365
I0526 15:32:24.697960 12837 solver.cpp:253]     Train net output #0: loss = 1.365 (* 1 = 1.365 loss)
I0526 15:32:24.697974 12837 sgd_solver.cpp:106] Iteration 344250, lr = 0.002
I0526 15:32:36.818498 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_345000.caffemodel
I0526 15:32:36.867777 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_345000.solverstate
I0526 15:32:36.893034 12837 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 15:33:49.816112 12837 solver.cpp:409]     Test net output #0: accuracy = 0.903745
I0526 15:33:49.816277 12837 solver.cpp:409]     Test net output #1: loss = 0.30843 (* 1 = 0.30843 loss)
I0526 15:34:12.076874 12837 solver.cpp:237] Iteration 345000, loss = 1.94228
I0526 15:34:12.076930 12837 solver.cpp:253]     Train net output #0: loss = 1.94228 (* 1 = 1.94228 loss)
I0526 15:34:12.076946 12837 sgd_solver.cpp:106] Iteration 345000, lr = 0.002
I0526 15:34:24.210592 12837 solver.cpp:237] Iteration 345750, loss = 1.1073
I0526 15:34:24.210760 12837 solver.cpp:253]     Train net output #0: loss = 1.1073 (* 1 = 1.1073 loss)
I0526 15:34:24.210777 12837 sgd_solver.cpp:106] Iteration 345750, lr = 0.002
I0526 15:34:36.351150 12837 solver.cpp:237] Iteration 346500, loss = 1.27021
I0526 15:34:36.351186 12837 solver.cpp:253]     Train net output #0: loss = 1.27021 (* 1 = 1.27021 loss)
I0526 15:34:36.351199 12837 sgd_solver.cpp:106] Iteration 346500, lr = 0.002
I0526 15:34:48.488411 12837 solver.cpp:237] Iteration 347250, loss = 0.897176
I0526 15:34:48.488462 12837 solver.cpp:253]     Train net output #0: loss = 0.897176 (* 1 = 0.897176 loss)
I0526 15:34:48.488476 12837 sgd_solver.cpp:106] Iteration 347250, lr = 0.002
I0526 15:35:00.630164 12837 solver.cpp:237] Iteration 348000, loss = 1.16086
I0526 15:35:00.630308 12837 solver.cpp:253]     Train net output #0: loss = 1.16086 (* 1 = 1.16086 loss)
I0526 15:35:00.630321 12837 sgd_solver.cpp:106] Iteration 348000, lr = 0.002
I0526 15:35:12.751327 12837 solver.cpp:237] Iteration 348750, loss = 1.24441
I0526 15:35:12.751374 12837 solver.cpp:253]     Train net output #0: loss = 1.24441 (* 1 = 1.24441 loss)
I0526 15:35:12.751387 12837 sgd_solver.cpp:106] Iteration 348750, lr = 0.002
I0526 15:35:24.860858 12837 solver.cpp:237] Iteration 349500, loss = 0.918078
I0526 15:35:24.860895 12837 solver.cpp:253]     Train net output #0: loss = 0.918077 (* 1 = 0.918077 loss)
I0526 15:35:24.860909 12837 sgd_solver.cpp:106] Iteration 349500, lr = 0.002
I0526 15:35:59.270335 12837 solver.cpp:237] Iteration 350250, loss = 0.927182
I0526 15:35:59.270520 12837 solver.cpp:253]     Train net output #0: loss = 0.927182 (* 1 = 0.927182 loss)
I0526 15:35:59.270534 12837 sgd_solver.cpp:106] Iteration 350250, lr = 0.002
I0526 15:36:11.405679 12837 solver.cpp:237] Iteration 351000, loss = 1.12937
I0526 15:36:11.405715 12837 solver.cpp:253]     Train net output #0: loss = 1.12937 (* 1 = 1.12937 loss)
I0526 15:36:11.405731 12837 sgd_solver.cpp:106] Iteration 351000, lr = 0.002
I0526 15:36:23.530436 12837 solver.cpp:237] Iteration 351750, loss = 1.2078
I0526 15:36:23.530483 12837 solver.cpp:253]     Train net output #0: loss = 1.2078 (* 1 = 1.2078 loss)
I0526 15:36:23.530498 12837 sgd_solver.cpp:106] Iteration 351750, lr = 0.002
I0526 15:36:35.638402 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_352500.caffemodel
I0526 15:36:35.690476 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_352500.solverstate
I0526 15:36:35.722959 12837 solver.cpp:237] Iteration 352500, loss = 1.26726
I0526 15:36:35.723013 12837 solver.cpp:253]     Train net output #0: loss = 1.26726 (* 1 = 1.26726 loss)
I0526 15:36:35.723029 12837 sgd_solver.cpp:106] Iteration 352500, lr = 0.002
I0526 15:36:47.838219 12837 solver.cpp:237] Iteration 353250, loss = 0.87308
I0526 15:36:47.838268 12837 solver.cpp:253]     Train net output #0: loss = 0.873079 (* 1 = 0.873079 loss)
I0526 15:36:47.838282 12837 sgd_solver.cpp:106] Iteration 353250, lr = 0.002
I0526 15:36:59.949709 12837 solver.cpp:237] Iteration 354000, loss = 1.98407
I0526 15:36:59.949746 12837 solver.cpp:253]     Train net output #0: loss = 1.98407 (* 1 = 1.98407 loss)
I0526 15:36:59.949760 12837 sgd_solver.cpp:106] Iteration 354000, lr = 0.002
I0526 15:37:12.071171 12837 solver.cpp:237] Iteration 354750, loss = 1.01708
I0526 15:37:12.071347 12837 solver.cpp:253]     Train net output #0: loss = 1.01707 (* 1 = 1.01707 loss)
I0526 15:37:12.071362 12837 sgd_solver.cpp:106] Iteration 354750, lr = 0.002
I0526 15:37:46.463654 12837 solver.cpp:237] Iteration 355500, loss = 1.23068
I0526 15:37:46.463846 12837 solver.cpp:253]     Train net output #0: loss = 1.23068 (* 1 = 1.23068 loss)
I0526 15:37:46.463860 12837 sgd_solver.cpp:106] Iteration 355500, lr = 0.002
I0526 15:37:58.611172 12837 solver.cpp:237] Iteration 356250, loss = 1.10788
I0526 15:37:58.611220 12837 solver.cpp:253]     Train net output #0: loss = 1.10788 (* 1 = 1.10788 loss)
I0526 15:37:58.611238 12837 sgd_solver.cpp:106] Iteration 356250, lr = 0.002
I0526 15:38:10.771219 12837 solver.cpp:237] Iteration 357000, loss = 1.00798
I0526 15:38:10.771255 12837 solver.cpp:253]     Train net output #0: loss = 1.00798 (* 1 = 1.00798 loss)
I0526 15:38:10.771271 12837 sgd_solver.cpp:106] Iteration 357000, lr = 0.002
I0526 15:38:22.937340 12837 solver.cpp:237] Iteration 357750, loss = 1.14596
I0526 15:38:22.937492 12837 solver.cpp:253]     Train net output #0: loss = 1.14596 (* 1 = 1.14596 loss)
I0526 15:38:22.937506 12837 sgd_solver.cpp:106] Iteration 357750, lr = 0.002
I0526 15:38:35.066282 12837 solver.cpp:237] Iteration 358500, loss = 1.1839
I0526 15:38:35.066318 12837 solver.cpp:253]     Train net output #0: loss = 1.1839 (* 1 = 1.1839 loss)
I0526 15:38:35.066332 12837 sgd_solver.cpp:106] Iteration 358500, lr = 0.002
I0526 15:38:47.206116 12837 solver.cpp:237] Iteration 359250, loss = 1.71082
I0526 15:38:47.206152 12837 solver.cpp:253]     Train net output #0: loss = 1.71082 (* 1 = 1.71082 loss)
I0526 15:38:47.206167 12837 sgd_solver.cpp:106] Iteration 359250, lr = 0.002
I0526 15:38:59.312965 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_360000.caffemodel
I0526 15:38:59.364014 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_360000.solverstate
I0526 15:38:59.391288 12837 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 15:39:51.459571 12837 solver.cpp:409]     Test net output #0: accuracy = 0.899884
I0526 15:39:51.459738 12837 solver.cpp:409]     Test net output #1: loss = 0.314944 (* 1 = 0.314944 loss)
I0526 15:40:12.371706 12837 solver.cpp:237] Iteration 360000, loss = 0.840146
I0526 15:40:12.371763 12837 solver.cpp:253]     Train net output #0: loss = 0.840145 (* 1 = 0.840145 loss)
I0526 15:40:12.371779 12837 sgd_solver.cpp:106] Iteration 360000, lr = 0.002
I0526 15:40:24.550683 12837 solver.cpp:237] Iteration 360750, loss = 1.30581
I0526 15:40:24.550832 12837 solver.cpp:253]     Train net output #0: loss = 1.3058 (* 1 = 1.3058 loss)
I0526 15:40:24.550845 12837 sgd_solver.cpp:106] Iteration 360750, lr = 0.002
I0526 15:40:36.731362 12837 solver.cpp:237] Iteration 361500, loss = 1.10454
I0526 15:40:36.731405 12837 solver.cpp:253]     Train net output #0: loss = 1.10454 (* 1 = 1.10454 loss)
I0526 15:40:36.731420 12837 sgd_solver.cpp:106] Iteration 361500, lr = 0.002
I0526 15:40:48.887326 12837 solver.cpp:237] Iteration 362250, loss = 1.27064
I0526 15:40:48.887362 12837 solver.cpp:253]     Train net output #0: loss = 1.27064 (* 1 = 1.27064 loss)
I0526 15:40:48.887375 12837 sgd_solver.cpp:106] Iteration 362250, lr = 0.002
I0526 15:41:01.044515 12837 solver.cpp:237] Iteration 363000, loss = 0.860543
I0526 15:41:01.044682 12837 solver.cpp:253]     Train net output #0: loss = 0.860542 (* 1 = 0.860542 loss)
I0526 15:41:01.044698 12837 sgd_solver.cpp:106] Iteration 363000, lr = 0.002
I0526 15:41:13.174700 12837 solver.cpp:237] Iteration 363750, loss = 1.04447
I0526 15:41:13.174736 12837 solver.cpp:253]     Train net output #0: loss = 1.04447 (* 1 = 1.04447 loss)
I0526 15:41:13.174751 12837 sgd_solver.cpp:106] Iteration 363750, lr = 0.002
I0526 15:41:25.268102 12837 solver.cpp:237] Iteration 364500, loss = 1.04784
I0526 15:41:25.268152 12837 solver.cpp:253]     Train net output #0: loss = 1.04784 (* 1 = 1.04784 loss)
I0526 15:41:25.268167 12837 sgd_solver.cpp:106] Iteration 364500, lr = 0.002
I0526 15:41:58.278301 12837 solver.cpp:237] Iteration 365250, loss = 1.45603
I0526 15:41:58.278475 12837 solver.cpp:253]     Train net output #0: loss = 1.45603 (* 1 = 1.45603 loss)
I0526 15:41:58.278491 12837 sgd_solver.cpp:106] Iteration 365250, lr = 0.002
I0526 15:42:10.398373 12837 solver.cpp:237] Iteration 366000, loss = 0.958107
I0526 15:42:10.398424 12837 solver.cpp:253]     Train net output #0: loss = 0.958106 (* 1 = 0.958106 loss)
I0526 15:42:10.398437 12837 sgd_solver.cpp:106] Iteration 366000, lr = 0.002
I0526 15:42:22.586388 12837 solver.cpp:237] Iteration 366750, loss = 1.63828
I0526 15:42:22.586423 12837 solver.cpp:253]     Train net output #0: loss = 1.63828 (* 1 = 1.63828 loss)
I0526 15:42:22.586441 12837 sgd_solver.cpp:106] Iteration 366750, lr = 0.002
I0526 15:42:34.717124 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_367500.caffemodel
I0526 15:42:34.766222 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_367500.solverstate
I0526 15:42:34.796772 12837 solver.cpp:237] Iteration 367500, loss = 0.757753
I0526 15:42:34.796821 12837 solver.cpp:253]     Train net output #0: loss = 0.757752 (* 1 = 0.757752 loss)
I0526 15:42:34.796838 12837 sgd_solver.cpp:106] Iteration 367500, lr = 0.002
I0526 15:42:46.906749 12837 solver.cpp:237] Iteration 368250, loss = 0.946528
I0526 15:42:46.906785 12837 solver.cpp:253]     Train net output #0: loss = 0.946527 (* 1 = 0.946527 loss)
I0526 15:42:46.906800 12837 sgd_solver.cpp:106] Iteration 368250, lr = 0.002
I0526 15:42:59.111495 12837 solver.cpp:237] Iteration 369000, loss = 1.20864
I0526 15:42:59.111549 12837 solver.cpp:253]     Train net output #0: loss = 1.20864 (* 1 = 1.20864 loss)
I0526 15:42:59.111565 12837 sgd_solver.cpp:106] Iteration 369000, lr = 0.002
I0526 15:43:11.236742 12837 solver.cpp:237] Iteration 369750, loss = 1.06999
I0526 15:43:11.236891 12837 solver.cpp:253]     Train net output #0: loss = 1.06999 (* 1 = 1.06999 loss)
I0526 15:43:11.236903 12837 sgd_solver.cpp:106] Iteration 369750, lr = 0.002
I0526 15:43:44.226105 12837 solver.cpp:237] Iteration 370500, loss = 0.918788
I0526 15:43:44.226271 12837 solver.cpp:253]     Train net output #0: loss = 0.918788 (* 1 = 0.918788 loss)
I0526 15:43:44.226287 12837 sgd_solver.cpp:106] Iteration 370500, lr = 0.002
I0526 15:43:56.307045 12837 solver.cpp:237] Iteration 371250, loss = 0.999372
I0526 15:43:56.307101 12837 solver.cpp:253]     Train net output #0: loss = 0.999371 (* 1 = 0.999371 loss)
I0526 15:43:56.307114 12837 sgd_solver.cpp:106] Iteration 371250, lr = 0.002
I0526 15:44:08.382557 12837 solver.cpp:237] Iteration 372000, loss = 1.45515
I0526 15:44:08.382593 12837 solver.cpp:253]     Train net output #0: loss = 1.45515 (* 1 = 1.45515 loss)
I0526 15:44:08.382606 12837 sgd_solver.cpp:106] Iteration 372000, lr = 0.002
I0526 15:44:20.460283 12837 solver.cpp:237] Iteration 372750, loss = 1.33381
I0526 15:44:20.460458 12837 solver.cpp:253]     Train net output #0: loss = 1.33381 (* 1 = 1.33381 loss)
I0526 15:44:20.460472 12837 sgd_solver.cpp:106] Iteration 372750, lr = 0.002
I0526 15:44:32.587606 12837 solver.cpp:237] Iteration 373500, loss = 1.39942
I0526 15:44:32.587642 12837 solver.cpp:253]     Train net output #0: loss = 1.39942 (* 1 = 1.39942 loss)
I0526 15:44:32.587658 12837 sgd_solver.cpp:106] Iteration 373500, lr = 0.002
I0526 15:44:44.732261 12837 solver.cpp:237] Iteration 374250, loss = 1.51492
I0526 15:44:44.732311 12837 solver.cpp:253]     Train net output #0: loss = 1.51492 (* 1 = 1.51492 loss)
I0526 15:44:44.732326 12837 sgd_solver.cpp:106] Iteration 374250, lr = 0.002
I0526 15:44:56.924716 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_375000.caffemodel
I0526 15:44:56.974485 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_375000.solverstate
I0526 15:44:56.999518 12837 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 15:46:09.920513 12837 solver.cpp:409]     Test net output #0: accuracy = 0.904959
I0526 15:46:09.920685 12837 solver.cpp:409]     Test net output #1: loss = 0.299043 (* 1 = 0.299043 loss)
I0526 15:46:30.816220 12837 solver.cpp:237] Iteration 375000, loss = 0.945834
I0526 15:46:30.816275 12837 solver.cpp:253]     Train net output #0: loss = 0.945833 (* 1 = 0.945833 loss)
I0526 15:46:30.816292 12837 sgd_solver.cpp:106] Iteration 375000, lr = 0.002
I0526 15:46:42.935642 12837 solver.cpp:237] Iteration 375750, loss = 0.570699
I0526 15:46:42.935812 12837 solver.cpp:253]     Train net output #0: loss = 0.570697 (* 1 = 0.570697 loss)
I0526 15:46:42.935827 12837 sgd_solver.cpp:106] Iteration 375750, lr = 0.002
I0526 15:46:55.036893 12837 solver.cpp:237] Iteration 376500, loss = 0.889157
I0526 15:46:55.036931 12837 solver.cpp:253]     Train net output #0: loss = 0.889156 (* 1 = 0.889156 loss)
I0526 15:46:55.036944 12837 sgd_solver.cpp:106] Iteration 376500, lr = 0.002
I0526 15:47:07.176879 12837 solver.cpp:237] Iteration 377250, loss = 1.39557
I0526 15:47:07.176915 12837 solver.cpp:253]     Train net output #0: loss = 1.39557 (* 1 = 1.39557 loss)
I0526 15:47:07.176930 12837 sgd_solver.cpp:106] Iteration 377250, lr = 0.002
I0526 15:47:19.307474 12837 solver.cpp:237] Iteration 378000, loss = 0.978416
I0526 15:47:19.307633 12837 solver.cpp:253]     Train net output #0: loss = 0.978415 (* 1 = 0.978415 loss)
I0526 15:47:19.307647 12837 sgd_solver.cpp:106] Iteration 378000, lr = 0.002
I0526 15:47:31.434118 12837 solver.cpp:237] Iteration 378750, loss = 1.18466
I0526 15:47:31.434154 12837 solver.cpp:253]     Train net output #0: loss = 1.18466 (* 1 = 1.18466 loss)
I0526 15:47:31.434168 12837 sgd_solver.cpp:106] Iteration 378750, lr = 0.002
I0526 15:47:43.607018 12837 solver.cpp:237] Iteration 379500, loss = 1.38523
I0526 15:47:43.607064 12837 solver.cpp:253]     Train net output #0: loss = 1.38522 (* 1 = 1.38522 loss)
I0526 15:47:43.607077 12837 sgd_solver.cpp:106] Iteration 379500, lr = 0.002
I0526 15:48:16.751688 12837 solver.cpp:237] Iteration 380250, loss = 1.38839
I0526 15:48:16.751859 12837 solver.cpp:253]     Train net output #0: loss = 1.38839 (* 1 = 1.38839 loss)
I0526 15:48:16.751876 12837 sgd_solver.cpp:106] Iteration 380250, lr = 0.002
I0526 15:48:28.929183 12837 solver.cpp:237] Iteration 381000, loss = 1.04989
I0526 15:48:28.929234 12837 solver.cpp:253]     Train net output #0: loss = 1.04989 (* 1 = 1.04989 loss)
I0526 15:48:28.929250 12837 sgd_solver.cpp:106] Iteration 381000, lr = 0.002
I0526 15:48:41.105499 12837 solver.cpp:237] Iteration 381750, loss = 1.33259
I0526 15:48:41.105535 12837 solver.cpp:253]     Train net output #0: loss = 1.33258 (* 1 = 1.33258 loss)
I0526 15:48:41.105550 12837 sgd_solver.cpp:106] Iteration 381750, lr = 0.002
I0526 15:48:53.203212 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_382500.caffemodel
I0526 15:48:53.251981 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_382500.solverstate
I0526 15:48:53.284900 12837 solver.cpp:237] Iteration 382500, loss = 0.841391
I0526 15:48:53.284955 12837 solver.cpp:253]     Train net output #0: loss = 0.841389 (* 1 = 0.841389 loss)
I0526 15:48:53.284970 12837 sgd_solver.cpp:106] Iteration 382500, lr = 0.002
I0526 15:49:05.325955 12837 solver.cpp:237] Iteration 383250, loss = 1.31655
I0526 15:49:05.325991 12837 solver.cpp:253]     Train net output #0: loss = 1.31654 (* 1 = 1.31654 loss)
I0526 15:49:05.326006 12837 sgd_solver.cpp:106] Iteration 383250, lr = 0.002
I0526 15:49:17.472750 12837 solver.cpp:237] Iteration 384000, loss = 1.02228
I0526 15:49:17.472803 12837 solver.cpp:253]     Train net output #0: loss = 1.02227 (* 1 = 1.02227 loss)
I0526 15:49:17.472818 12837 sgd_solver.cpp:106] Iteration 384000, lr = 0.002
I0526 15:49:29.610263 12837 solver.cpp:237] Iteration 384750, loss = 1.19373
I0526 15:49:29.610419 12837 solver.cpp:253]     Train net output #0: loss = 1.19373 (* 1 = 1.19373 loss)
I0526 15:49:29.610432 12837 sgd_solver.cpp:106] Iteration 384750, lr = 0.002
I0526 15:50:02.658658 12837 solver.cpp:237] Iteration 385500, loss = 0.736283
I0526 15:50:02.658830 12837 solver.cpp:253]     Train net output #0: loss = 0.736281 (* 1 = 0.736281 loss)
I0526 15:50:02.658845 12837 sgd_solver.cpp:106] Iteration 385500, lr = 0.002
I0526 15:50:14.756036 12837 solver.cpp:237] Iteration 386250, loss = 1.30202
I0526 15:50:14.756072 12837 solver.cpp:253]     Train net output #0: loss = 1.30202 (* 1 = 1.30202 loss)
I0526 15:50:14.756086 12837 sgd_solver.cpp:106] Iteration 386250, lr = 0.002
I0526 15:50:26.872941 12837 solver.cpp:237] Iteration 387000, loss = 1.0313
I0526 15:50:26.872977 12837 solver.cpp:253]     Train net output #0: loss = 1.0313 (* 1 = 1.0313 loss)
I0526 15:50:26.872992 12837 sgd_solver.cpp:106] Iteration 387000, lr = 0.002
I0526 15:50:38.979456 12837 solver.cpp:237] Iteration 387750, loss = 1.13631
I0526 15:50:38.979622 12837 solver.cpp:253]     Train net output #0: loss = 1.13631 (* 1 = 1.13631 loss)
I0526 15:50:38.979635 12837 sgd_solver.cpp:106] Iteration 387750, lr = 0.002
I0526 15:50:51.186295 12837 solver.cpp:237] Iteration 388500, loss = 0.994779
I0526 15:50:51.186332 12837 solver.cpp:253]     Train net output #0: loss = 0.994778 (* 1 = 0.994778 loss)
I0526 15:50:51.186347 12837 sgd_solver.cpp:106] Iteration 388500, lr = 0.002
I0526 15:51:03.328851 12837 solver.cpp:237] Iteration 389250, loss = 1.3894
I0526 15:51:03.328903 12837 solver.cpp:253]     Train net output #0: loss = 1.3894 (* 1 = 1.3894 loss)
I0526 15:51:03.328917 12837 sgd_solver.cpp:106] Iteration 389250, lr = 0.002
I0526 15:51:15.446419 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_390000.caffemodel
I0526 15:51:15.496894 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_390000.solverstate
I0526 15:51:15.523396 12837 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 15:52:07.144449 12837 solver.cpp:409]     Test net output #0: accuracy = 0.900332
I0526 15:52:07.144623 12837 solver.cpp:409]     Test net output #1: loss = 0.332894 (* 1 = 0.332894 loss)
I0526 15:52:28.082734 12837 solver.cpp:237] Iteration 390000, loss = 0.787757
I0526 15:52:28.082792 12837 solver.cpp:253]     Train net output #0: loss = 0.787755 (* 1 = 0.787755 loss)
I0526 15:52:28.082808 12837 sgd_solver.cpp:106] Iteration 390000, lr = 0.002
I0526 15:52:40.297972 12837 solver.cpp:237] Iteration 390750, loss = 1.13652
I0526 15:52:40.298143 12837 solver.cpp:253]     Train net output #0: loss = 1.13652 (* 1 = 1.13652 loss)
I0526 15:52:40.298157 12837 sgd_solver.cpp:106] Iteration 390750, lr = 0.002
I0526 15:52:52.501237 12837 solver.cpp:237] Iteration 391500, loss = 1.16437
I0526 15:52:52.501273 12837 solver.cpp:253]     Train net output #0: loss = 1.16437 (* 1 = 1.16437 loss)
I0526 15:52:52.501287 12837 sgd_solver.cpp:106] Iteration 391500, lr = 0.002
I0526 15:53:04.706506 12837 solver.cpp:237] Iteration 392250, loss = 1.09455
I0526 15:53:04.706555 12837 solver.cpp:253]     Train net output #0: loss = 1.09455 (* 1 = 1.09455 loss)
I0526 15:53:04.706569 12837 sgd_solver.cpp:106] Iteration 392250, lr = 0.002
I0526 15:53:16.928841 12837 solver.cpp:237] Iteration 393000, loss = 1.16095
I0526 15:53:16.929000 12837 solver.cpp:253]     Train net output #0: loss = 1.16095 (* 1 = 1.16095 loss)
I0526 15:53:16.929014 12837 sgd_solver.cpp:106] Iteration 393000, lr = 0.002
I0526 15:53:29.112187 12837 solver.cpp:237] Iteration 393750, loss = 1.03256
I0526 15:53:29.112233 12837 solver.cpp:253]     Train net output #0: loss = 1.03256 (* 1 = 1.03256 loss)
I0526 15:53:29.112247 12837 sgd_solver.cpp:106] Iteration 393750, lr = 0.002
I0526 15:53:41.321919 12837 solver.cpp:237] Iteration 394500, loss = 1.25548
I0526 15:53:41.321954 12837 solver.cpp:253]     Train net output #0: loss = 1.25548 (* 1 = 1.25548 loss)
I0526 15:53:41.321969 12837 sgd_solver.cpp:106] Iteration 394500, lr = 0.002
I0526 15:54:14.447182 12837 solver.cpp:237] Iteration 395250, loss = 0.858831
I0526 15:54:14.447365 12837 solver.cpp:253]     Train net output #0: loss = 0.858829 (* 1 = 0.858829 loss)
I0526 15:54:14.447379 12837 sgd_solver.cpp:106] Iteration 395250, lr = 0.002
I0526 15:54:26.634032 12837 solver.cpp:237] Iteration 396000, loss = 1.14959
I0526 15:54:26.634068 12837 solver.cpp:253]     Train net output #0: loss = 1.14959 (* 1 = 1.14959 loss)
I0526 15:54:26.634083 12837 sgd_solver.cpp:106] Iteration 396000, lr = 0.002
I0526 15:54:38.839736 12837 solver.cpp:237] Iteration 396750, loss = 1.10202
I0526 15:54:38.839786 12837 solver.cpp:253]     Train net output #0: loss = 1.10202 (* 1 = 1.10202 loss)
I0526 15:54:38.839802 12837 sgd_solver.cpp:106] Iteration 396750, lr = 0.002
I0526 15:54:51.005779 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_397500.caffemodel
I0526 15:54:51.057050 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_397500.solverstate
I0526 15:54:51.089366 12837 solver.cpp:237] Iteration 397500, loss = 1.15733
I0526 15:54:51.089416 12837 solver.cpp:253]     Train net output #0: loss = 1.15733 (* 1 = 1.15733 loss)
I0526 15:54:51.089429 12837 sgd_solver.cpp:106] Iteration 397500, lr = 0.002
I0526 15:55:03.303726 12837 solver.cpp:237] Iteration 398250, loss = 0.928858
I0526 15:55:03.303778 12837 solver.cpp:253]     Train net output #0: loss = 0.928857 (* 1 = 0.928857 loss)
I0526 15:55:03.303794 12837 sgd_solver.cpp:106] Iteration 398250, lr = 0.002
I0526 15:55:15.511951 12837 solver.cpp:237] Iteration 399000, loss = 1.3418
I0526 15:55:15.511986 12837 solver.cpp:253]     Train net output #0: loss = 1.3418 (* 1 = 1.3418 loss)
I0526 15:55:15.512002 12837 sgd_solver.cpp:106] Iteration 399000, lr = 0.002
I0526 15:55:27.716032 12837 solver.cpp:237] Iteration 399750, loss = 1.12787
I0526 15:55:27.716192 12837 solver.cpp:253]     Train net output #0: loss = 1.12786 (* 1 = 1.12786 loss)
I0526 15:55:27.716207 12837 sgd_solver.cpp:106] Iteration 399750, lr = 0.002
I0526 15:56:00.857048 12837 solver.cpp:237] Iteration 400500, loss = 0.993624
I0526 15:56:00.857226 12837 solver.cpp:253]     Train net output #0: loss = 0.993622 (* 1 = 0.993622 loss)
I0526 15:56:00.857241 12837 sgd_solver.cpp:106] Iteration 400500, lr = 0.002
I0526 15:56:13.062922 12837 solver.cpp:237] Iteration 401250, loss = 1.00892
I0526 15:56:13.062958 12837 solver.cpp:253]     Train net output #0: loss = 1.00892 (* 1 = 1.00892 loss)
I0526 15:56:13.062973 12837 sgd_solver.cpp:106] Iteration 401250, lr = 0.002
I0526 15:56:25.299260 12837 solver.cpp:237] Iteration 402000, loss = 1.29293
I0526 15:56:25.299314 12837 solver.cpp:253]     Train net output #0: loss = 1.29293 (* 1 = 1.29293 loss)
I0526 15:56:25.299327 12837 sgd_solver.cpp:106] Iteration 402000, lr = 0.002
I0526 15:56:37.521975 12837 solver.cpp:237] Iteration 402750, loss = 0.666943
I0526 15:56:37.522137 12837 solver.cpp:253]     Train net output #0: loss = 0.666942 (* 1 = 0.666942 loss)
I0526 15:56:37.522151 12837 sgd_solver.cpp:106] Iteration 402750, lr = 0.002
I0526 15:56:49.716508 12837 solver.cpp:237] Iteration 403500, loss = 0.978386
I0526 15:56:49.716559 12837 solver.cpp:253]     Train net output #0: loss = 0.978384 (* 1 = 0.978384 loss)
I0526 15:56:49.716573 12837 sgd_solver.cpp:106] Iteration 403500, lr = 0.002
I0526 15:57:01.911480 12837 solver.cpp:237] Iteration 404250, loss = 1.11345
I0526 15:57:01.911525 12837 solver.cpp:253]     Train net output #0: loss = 1.11345 (* 1 = 1.11345 loss)
I0526 15:57:01.911541 12837 sgd_solver.cpp:106] Iteration 404250, lr = 0.002
I0526 15:57:14.119379 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_405000.caffemodel
I0526 15:57:14.168581 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_405000.solverstate
I0526 15:57:14.194277 12837 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 15:58:27.145159 12837 solver.cpp:409]     Test net output #0: accuracy = 0.905067
I0526 15:58:27.145334 12837 solver.cpp:409]     Test net output #1: loss = 0.299255 (* 1 = 0.299255 loss)
I0526 15:58:48.114521 12837 solver.cpp:237] Iteration 405000, loss = 0.994635
I0526 15:58:48.114575 12837 solver.cpp:253]     Train net output #0: loss = 0.994633 (* 1 = 0.994633 loss)
I0526 15:58:48.114593 12837 sgd_solver.cpp:106] Iteration 405000, lr = 0.002
I0526 15:59:00.322226 12837 solver.cpp:237] Iteration 405750, loss = 0.827107
I0526 15:59:00.322386 12837 solver.cpp:253]     Train net output #0: loss = 0.827106 (* 1 = 0.827106 loss)
I0526 15:59:00.322399 12837 sgd_solver.cpp:106] Iteration 405750, lr = 0.002
I0526 15:59:12.536165 12837 solver.cpp:237] Iteration 406500, loss = 1.24035
I0526 15:59:12.536218 12837 solver.cpp:253]     Train net output #0: loss = 1.24035 (* 1 = 1.24035 loss)
I0526 15:59:12.536233 12837 sgd_solver.cpp:106] Iteration 406500, lr = 0.002
I0526 15:59:24.745115 12837 solver.cpp:237] Iteration 407250, loss = 0.824154
I0526 15:59:24.745152 12837 solver.cpp:253]     Train net output #0: loss = 0.824152 (* 1 = 0.824152 loss)
I0526 15:59:24.745167 12837 sgd_solver.cpp:106] Iteration 407250, lr = 0.002
I0526 15:59:36.962188 12837 solver.cpp:237] Iteration 408000, loss = 0.98618
I0526 15:59:36.962340 12837 solver.cpp:253]     Train net output #0: loss = 0.986178 (* 1 = 0.986178 loss)
I0526 15:59:36.962354 12837 sgd_solver.cpp:106] Iteration 408000, lr = 0.002
I0526 15:59:49.134613 12837 solver.cpp:237] Iteration 408750, loss = 0.999624
I0526 15:59:49.134659 12837 solver.cpp:253]     Train net output #0: loss = 0.999622 (* 1 = 0.999622 loss)
I0526 15:59:49.134672 12837 sgd_solver.cpp:106] Iteration 408750, lr = 0.002
I0526 16:00:01.301600 12837 solver.cpp:237] Iteration 409500, loss = 1.14369
I0526 16:00:01.301636 12837 solver.cpp:253]     Train net output #0: loss = 1.14369 (* 1 = 1.14369 loss)
I0526 16:00:01.301651 12837 sgd_solver.cpp:106] Iteration 409500, lr = 0.002
I0526 16:00:34.361382 12837 solver.cpp:237] Iteration 410250, loss = 1.23854
I0526 16:00:34.361557 12837 solver.cpp:253]     Train net output #0: loss = 1.23854 (* 1 = 1.23854 loss)
I0526 16:00:34.361572 12837 sgd_solver.cpp:106] Iteration 410250, lr = 0.002
I0526 16:00:46.482924 12837 solver.cpp:237] Iteration 411000, loss = 0.867043
I0526 16:00:46.482961 12837 solver.cpp:253]     Train net output #0: loss = 0.867041 (* 1 = 0.867041 loss)
I0526 16:00:46.482975 12837 sgd_solver.cpp:106] Iteration 411000, lr = 0.002
I0526 16:00:58.622190 12837 solver.cpp:237] Iteration 411750, loss = 1.52399
I0526 16:00:58.622237 12837 solver.cpp:253]     Train net output #0: loss = 1.52399 (* 1 = 1.52399 loss)
I0526 16:00:58.622252 12837 sgd_solver.cpp:106] Iteration 411750, lr = 0.002
I0526 16:01:10.725872 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_412500.caffemodel
I0526 16:01:10.776765 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_412500.solverstate
I0526 16:01:10.806725 12837 solver.cpp:237] Iteration 412500, loss = 1.12811
I0526 16:01:10.806771 12837 solver.cpp:253]     Train net output #0: loss = 1.12811 (* 1 = 1.12811 loss)
I0526 16:01:10.806788 12837 sgd_solver.cpp:106] Iteration 412500, lr = 0.002
I0526 16:01:22.957311 12837 solver.cpp:237] Iteration 413250, loss = 0.980012
I0526 16:01:22.957361 12837 solver.cpp:253]     Train net output #0: loss = 0.98001 (* 1 = 0.98001 loss)
I0526 16:01:22.957376 12837 sgd_solver.cpp:106] Iteration 413250, lr = 0.002
I0526 16:01:35.124869 12837 solver.cpp:237] Iteration 414000, loss = 1.28336
I0526 16:01:35.124907 12837 solver.cpp:253]     Train net output #0: loss = 1.28336 (* 1 = 1.28336 loss)
I0526 16:01:35.124920 12837 sgd_solver.cpp:106] Iteration 414000, lr = 0.002
I0526 16:01:47.250684 12837 solver.cpp:237] Iteration 414750, loss = 1.41932
I0526 16:01:47.250851 12837 solver.cpp:253]     Train net output #0: loss = 1.41932 (* 1 = 1.41932 loss)
I0526 16:01:47.250865 12837 sgd_solver.cpp:106] Iteration 414750, lr = 0.002
I0526 16:02:20.410899 12837 solver.cpp:237] Iteration 415500, loss = 0.975373
I0526 16:02:20.411080 12837 solver.cpp:253]     Train net output #0: loss = 0.975371 (* 1 = 0.975371 loss)
I0526 16:02:20.411094 12837 sgd_solver.cpp:106] Iteration 415500, lr = 0.002
I0526 16:02:32.584265 12837 solver.cpp:237] Iteration 416250, loss = 1.28889
I0526 16:02:32.584316 12837 solver.cpp:253]     Train net output #0: loss = 1.28889 (* 1 = 1.28889 loss)
I0526 16:02:32.584331 12837 sgd_solver.cpp:106] Iteration 416250, lr = 0.002
I0526 16:02:44.753303 12837 solver.cpp:237] Iteration 417000, loss = 1.12083
I0526 16:02:44.753339 12837 solver.cpp:253]     Train net output #0: loss = 1.12083 (* 1 = 1.12083 loss)
I0526 16:02:44.753353 12837 sgd_solver.cpp:106] Iteration 417000, lr = 0.002
I0526 16:02:56.925699 12837 solver.cpp:237] Iteration 417750, loss = 1.00774
I0526 16:02:56.925849 12837 solver.cpp:253]     Train net output #0: loss = 1.00774 (* 1 = 1.00774 loss)
I0526 16:02:56.925863 12837 sgd_solver.cpp:106] Iteration 417750, lr = 0.002
I0526 16:03:09.072703 12837 solver.cpp:237] Iteration 418500, loss = 1.3013
I0526 16:03:09.072753 12837 solver.cpp:253]     Train net output #0: loss = 1.3013 (* 1 = 1.3013 loss)
I0526 16:03:09.072768 12837 sgd_solver.cpp:106] Iteration 418500, lr = 0.002
I0526 16:03:21.205996 12837 solver.cpp:237] Iteration 419250, loss = 1.42593
I0526 16:03:21.206032 12837 solver.cpp:253]     Train net output #0: loss = 1.42592 (* 1 = 1.42592 loss)
I0526 16:03:21.206048 12837 sgd_solver.cpp:106] Iteration 419250, lr = 0.002
I0526 16:03:33.316557 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_420000.caffemodel
I0526 16:03:33.365389 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_420000.solverstate
I0526 16:03:33.390509 12837 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 16:04:25.453034 12837 solver.cpp:409]     Test net output #0: accuracy = 0.904924
I0526 16:04:25.453209 12837 solver.cpp:409]     Test net output #1: loss = 0.305678 (* 1 = 0.305678 loss)
I0526 16:04:46.406757 12837 solver.cpp:237] Iteration 420000, loss = 1.9267
I0526 16:04:46.406813 12837 solver.cpp:253]     Train net output #0: loss = 1.9267 (* 1 = 1.9267 loss)
I0526 16:04:46.406828 12837 sgd_solver.cpp:106] Iteration 420000, lr = 0.002
I0526 16:04:58.565343 12837 solver.cpp:237] Iteration 420750, loss = 1.27044
I0526 16:04:58.565515 12837 solver.cpp:253]     Train net output #0: loss = 1.27044 (* 1 = 1.27044 loss)
I0526 16:04:58.565528 12837 sgd_solver.cpp:106] Iteration 420750, lr = 0.002
I0526 16:05:10.670114 12837 solver.cpp:237] Iteration 421500, loss = 0.894551
I0526 16:05:10.670166 12837 solver.cpp:253]     Train net output #0: loss = 0.894549 (* 1 = 0.894549 loss)
I0526 16:05:10.670179 12837 sgd_solver.cpp:106] Iteration 421500, lr = 0.002
I0526 16:05:22.799218 12837 solver.cpp:237] Iteration 422250, loss = 0.834925
I0526 16:05:22.799255 12837 solver.cpp:253]     Train net output #0: loss = 0.834924 (* 1 = 0.834924 loss)
I0526 16:05:22.799269 12837 sgd_solver.cpp:106] Iteration 422250, lr = 0.002
I0526 16:05:34.931133 12837 solver.cpp:237] Iteration 423000, loss = 0.968494
I0526 16:05:34.931304 12837 solver.cpp:253]     Train net output #0: loss = 0.968493 (* 1 = 0.968493 loss)
I0526 16:05:34.931318 12837 sgd_solver.cpp:106] Iteration 423000, lr = 0.002
I0526 16:05:47.111582 12837 solver.cpp:237] Iteration 423750, loss = 0.899052
I0526 16:05:47.111619 12837 solver.cpp:253]     Train net output #0: loss = 0.899051 (* 1 = 0.899051 loss)
I0526 16:05:47.111634 12837 sgd_solver.cpp:106] Iteration 423750, lr = 0.002
I0526 16:05:59.262934 12837 solver.cpp:237] Iteration 424500, loss = 0.888442
I0526 16:05:59.262984 12837 solver.cpp:253]     Train net output #0: loss = 0.888441 (* 1 = 0.888441 loss)
I0526 16:05:59.262998 12837 sgd_solver.cpp:106] Iteration 424500, lr = 0.002
I0526 16:06:32.346938 12837 solver.cpp:237] Iteration 425250, loss = 0.94533
I0526 16:06:32.347122 12837 solver.cpp:253]     Train net output #0: loss = 0.945329 (* 1 = 0.945329 loss)
I0526 16:06:32.347137 12837 sgd_solver.cpp:106] Iteration 425250, lr = 0.002
I0526 16:06:44.469002 12837 solver.cpp:237] Iteration 426000, loss = 0.821734
I0526 16:06:44.469054 12837 solver.cpp:253]     Train net output #0: loss = 0.821733 (* 1 = 0.821733 loss)
I0526 16:06:44.469069 12837 sgd_solver.cpp:106] Iteration 426000, lr = 0.002
I0526 16:06:56.594578 12837 solver.cpp:237] Iteration 426750, loss = 1.35797
I0526 16:06:56.594614 12837 solver.cpp:253]     Train net output #0: loss = 1.35797 (* 1 = 1.35797 loss)
I0526 16:06:56.594629 12837 sgd_solver.cpp:106] Iteration 426750, lr = 0.002
I0526 16:07:08.713557 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_427500.caffemodel
I0526 16:07:08.766665 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_427500.solverstate
I0526 16:07:08.799443 12837 solver.cpp:237] Iteration 427500, loss = 2.35348
I0526 16:07:08.799496 12837 solver.cpp:253]     Train net output #0: loss = 2.35348 (* 1 = 2.35348 loss)
I0526 16:07:08.799517 12837 sgd_solver.cpp:106] Iteration 427500, lr = 0.002
I0526 16:07:20.969849 12837 solver.cpp:237] Iteration 428250, loss = 0.842501
I0526 16:07:20.969887 12837 solver.cpp:253]     Train net output #0: loss = 0.842499 (* 1 = 0.842499 loss)
I0526 16:07:20.969900 12837 sgd_solver.cpp:106] Iteration 428250, lr = 0.002
I0526 16:07:33.128120 12837 solver.cpp:237] Iteration 429000, loss = 1.50977
I0526 16:07:33.128170 12837 solver.cpp:253]     Train net output #0: loss = 1.50977 (* 1 = 1.50977 loss)
I0526 16:07:33.128188 12837 sgd_solver.cpp:106] Iteration 429000, lr = 0.002
I0526 16:07:45.291486 12837 solver.cpp:237] Iteration 429750, loss = 1.10585
I0526 16:07:45.291649 12837 solver.cpp:253]     Train net output #0: loss = 1.10585 (* 1 = 1.10585 loss)
I0526 16:07:45.291663 12837 sgd_solver.cpp:106] Iteration 429750, lr = 0.002
I0526 16:08:18.381810 12837 solver.cpp:237] Iteration 430500, loss = 0.934093
I0526 16:08:18.381996 12837 solver.cpp:253]     Train net output #0: loss = 0.934092 (* 1 = 0.934092 loss)
I0526 16:08:18.382011 12837 sgd_solver.cpp:106] Iteration 430500, lr = 0.002
I0526 16:08:30.491406 12837 solver.cpp:237] Iteration 431250, loss = 1.22115
I0526 16:08:30.491456 12837 solver.cpp:253]     Train net output #0: loss = 1.22115 (* 1 = 1.22115 loss)
I0526 16:08:30.491471 12837 sgd_solver.cpp:106] Iteration 431250, lr = 0.002
I0526 16:08:42.596362 12837 solver.cpp:237] Iteration 432000, loss = 0.992339
I0526 16:08:42.596398 12837 solver.cpp:253]     Train net output #0: loss = 0.992337 (* 1 = 0.992337 loss)
I0526 16:08:42.596415 12837 sgd_solver.cpp:106] Iteration 432000, lr = 0.002
I0526 16:08:54.733953 12837 solver.cpp:237] Iteration 432750, loss = 0.955358
I0526 16:08:54.734123 12837 solver.cpp:253]     Train net output #0: loss = 0.955356 (* 1 = 0.955356 loss)
I0526 16:08:54.734141 12837 sgd_solver.cpp:106] Iteration 432750, lr = 0.002
I0526 16:09:06.881093 12837 solver.cpp:237] Iteration 433500, loss = 1.51791
I0526 16:09:06.881129 12837 solver.cpp:253]     Train net output #0: loss = 1.51791 (* 1 = 1.51791 loss)
I0526 16:09:06.881144 12837 sgd_solver.cpp:106] Iteration 433500, lr = 0.002
I0526 16:09:19.065132 12837 solver.cpp:237] Iteration 434250, loss = 1.47516
I0526 16:09:19.065186 12837 solver.cpp:253]     Train net output #0: loss = 1.47516 (* 1 = 1.47516 loss)
I0526 16:09:19.065199 12837 sgd_solver.cpp:106] Iteration 434250, lr = 0.002
I0526 16:09:31.215348 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_435000.caffemodel
I0526 16:09:32.395372 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_435000.solverstate
I0526 16:09:32.451114 12837 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 16:10:46.126436 12837 solver.cpp:409]     Test net output #0: accuracy = 0.901532
I0526 16:10:46.126615 12837 solver.cpp:409]     Test net output #1: loss = 0.309628 (* 1 = 0.309628 loss)
I0526 16:11:07.103574 12837 solver.cpp:237] Iteration 435000, loss = 1.07834
I0526 16:11:07.103628 12837 solver.cpp:253]     Train net output #0: loss = 1.07834 (* 1 = 1.07834 loss)
I0526 16:11:07.103643 12837 sgd_solver.cpp:106] Iteration 435000, lr = 0.002
I0526 16:11:19.368959 12837 solver.cpp:237] Iteration 435750, loss = 1.1586
I0526 16:11:19.369132 12837 solver.cpp:253]     Train net output #0: loss = 1.15859 (* 1 = 1.15859 loss)
I0526 16:11:19.369145 12837 sgd_solver.cpp:106] Iteration 435750, lr = 0.002
I0526 16:11:31.628077 12837 solver.cpp:237] Iteration 436500, loss = 1.10343
I0526 16:11:31.628113 12837 solver.cpp:253]     Train net output #0: loss = 1.10343 (* 1 = 1.10343 loss)
I0526 16:11:31.628129 12837 sgd_solver.cpp:106] Iteration 436500, lr = 0.002
I0526 16:11:43.880336 12837 solver.cpp:237] Iteration 437250, loss = 0.804612
I0526 16:11:43.880386 12837 solver.cpp:253]     Train net output #0: loss = 0.80461 (* 1 = 0.80461 loss)
I0526 16:11:43.880399 12837 sgd_solver.cpp:106] Iteration 437250, lr = 0.002
I0526 16:11:56.134318 12837 solver.cpp:237] Iteration 438000, loss = 1.81605
I0526 16:11:56.134471 12837 solver.cpp:253]     Train net output #0: loss = 1.81605 (* 1 = 1.81605 loss)
I0526 16:11:56.134485 12837 sgd_solver.cpp:106] Iteration 438000, lr = 0.002
I0526 16:12:08.375763 12837 solver.cpp:237] Iteration 438750, loss = 1.43847
I0526 16:12:08.375798 12837 solver.cpp:253]     Train net output #0: loss = 1.43846 (* 1 = 1.43846 loss)
I0526 16:12:08.375819 12837 sgd_solver.cpp:106] Iteration 438750, lr = 0.002
I0526 16:12:20.607581 12837 solver.cpp:237] Iteration 439500, loss = 1.68837
I0526 16:12:20.607617 12837 solver.cpp:253]     Train net output #0: loss = 1.68837 (* 1 = 1.68837 loss)
I0526 16:12:20.607632 12837 sgd_solver.cpp:106] Iteration 439500, lr = 0.002
I0526 16:12:54.553707 12837 solver.cpp:237] Iteration 440250, loss = 1.33408
I0526 16:12:54.553900 12837 solver.cpp:253]     Train net output #0: loss = 1.33408 (* 1 = 1.33408 loss)
I0526 16:12:54.553915 12837 sgd_solver.cpp:106] Iteration 440250, lr = 0.002
I0526 16:13:06.765146 12837 solver.cpp:237] Iteration 441000, loss = 1.04326
I0526 16:13:06.765187 12837 solver.cpp:253]     Train net output #0: loss = 1.04326 (* 1 = 1.04326 loss)
I0526 16:13:06.765202 12837 sgd_solver.cpp:106] Iteration 441000, lr = 0.002
I0526 16:13:18.984109 12837 solver.cpp:237] Iteration 441750, loss = 1.54499
I0526 16:13:18.984144 12837 solver.cpp:253]     Train net output #0: loss = 1.54499 (* 1 = 1.54499 loss)
I0526 16:13:18.984159 12837 sgd_solver.cpp:106] Iteration 441750, lr = 0.002
I0526 16:13:31.178372 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_442500.caffemodel
I0526 16:13:31.251986 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_442500.solverstate
I0526 16:13:31.308655 12837 solver.cpp:237] Iteration 442500, loss = 1.15926
I0526 16:13:31.308706 12837 solver.cpp:253]     Train net output #0: loss = 1.15926 (* 1 = 1.15926 loss)
I0526 16:13:31.308723 12837 sgd_solver.cpp:106] Iteration 442500, lr = 0.002
I0526 16:13:43.517812 12837 solver.cpp:237] Iteration 443250, loss = 0.946177
I0526 16:13:43.517849 12837 solver.cpp:253]     Train net output #0: loss = 0.946175 (* 1 = 0.946175 loss)
I0526 16:13:43.517863 12837 sgd_solver.cpp:106] Iteration 443250, lr = 0.002
I0526 16:13:55.667351 12837 solver.cpp:237] Iteration 444000, loss = 0.595346
I0526 16:13:55.667392 12837 solver.cpp:253]     Train net output #0: loss = 0.595344 (* 1 = 0.595344 loss)
I0526 16:13:55.667407 12837 sgd_solver.cpp:106] Iteration 444000, lr = 0.002
I0526 16:14:07.857795 12837 solver.cpp:237] Iteration 444750, loss = 1.0785
I0526 16:14:07.857954 12837 solver.cpp:253]     Train net output #0: loss = 1.07849 (* 1 = 1.07849 loss)
I0526 16:14:07.857969 12837 sgd_solver.cpp:106] Iteration 444750, lr = 0.002
I0526 16:14:41.008388 12837 solver.cpp:237] Iteration 445500, loss = 0.979286
I0526 16:14:41.008569 12837 solver.cpp:253]     Train net output #0: loss = 0.979284 (* 1 = 0.979284 loss)
I0526 16:14:41.008584 12837 sgd_solver.cpp:106] Iteration 445500, lr = 0.002
I0526 16:14:53.156807 12837 solver.cpp:237] Iteration 446250, loss = 1.04311
I0526 16:14:53.156843 12837 solver.cpp:253]     Train net output #0: loss = 1.04311 (* 1 = 1.04311 loss)
I0526 16:14:53.156857 12837 sgd_solver.cpp:106] Iteration 446250, lr = 0.002
I0526 16:15:05.351683 12837 solver.cpp:237] Iteration 447000, loss = 0.939605
I0526 16:15:05.351729 12837 solver.cpp:253]     Train net output #0: loss = 0.939603 (* 1 = 0.939603 loss)
I0526 16:15:05.351743 12837 sgd_solver.cpp:106] Iteration 447000, lr = 0.002
I0526 16:15:17.548121 12837 solver.cpp:237] Iteration 447750, loss = 1.05092
I0526 16:15:17.548292 12837 solver.cpp:253]     Train net output #0: loss = 1.05092 (* 1 = 1.05092 loss)
I0526 16:15:17.548306 12837 sgd_solver.cpp:106] Iteration 447750, lr = 0.002
I0526 16:15:29.737124 12837 solver.cpp:237] Iteration 448500, loss = 1.28965
I0526 16:15:29.737166 12837 solver.cpp:253]     Train net output #0: loss = 1.28965 (* 1 = 1.28965 loss)
I0526 16:15:29.737182 12837 sgd_solver.cpp:106] Iteration 448500, lr = 0.002
I0526 16:15:41.901499 12837 solver.cpp:237] Iteration 449250, loss = 1.34751
I0526 16:15:41.901535 12837 solver.cpp:253]     Train net output #0: loss = 1.34751 (* 1 = 1.34751 loss)
I0526 16:15:41.901551 12837 sgd_solver.cpp:106] Iteration 449250, lr = 0.002
I0526 16:15:54.040710 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_450000.caffemodel
I0526 16:15:54.116835 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_450000.solverstate
I0526 16:15:54.167244 12837 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 16:16:45.977080 12837 solver.cpp:409]     Test net output #0: accuracy = 0.902917
I0526 16:16:45.977278 12837 solver.cpp:409]     Test net output #1: loss = 0.312313 (* 1 = 0.312313 loss)
I0526 16:17:06.891695 12837 solver.cpp:237] Iteration 450000, loss = 1.15514
I0526 16:17:06.891751 12837 solver.cpp:253]     Train net output #0: loss = 1.15514 (* 1 = 1.15514 loss)
I0526 16:17:06.891767 12837 sgd_solver.cpp:106] Iteration 450000, lr = 0.002
I0526 16:17:19.069839 12837 solver.cpp:237] Iteration 450750, loss = 0.805588
I0526 16:17:19.070030 12837 solver.cpp:253]     Train net output #0: loss = 0.805586 (* 1 = 0.805586 loss)
I0526 16:17:19.070047 12837 sgd_solver.cpp:106] Iteration 450750, lr = 0.002
I0526 16:17:31.198542 12837 solver.cpp:237] Iteration 451500, loss = 0.887805
I0526 16:17:31.198580 12837 solver.cpp:253]     Train net output #0: loss = 0.887802 (* 1 = 0.887802 loss)
I0526 16:17:31.198595 12837 sgd_solver.cpp:106] Iteration 451500, lr = 0.002
I0526 16:17:43.341467 12837 solver.cpp:237] Iteration 452250, loss = 1.37902
I0526 16:17:43.341514 12837 solver.cpp:253]     Train net output #0: loss = 1.37902 (* 1 = 1.37902 loss)
I0526 16:17:43.341528 12837 sgd_solver.cpp:106] Iteration 452250, lr = 0.002
I0526 16:17:55.462870 12837 solver.cpp:237] Iteration 453000, loss = 1.11527
I0526 16:17:55.463027 12837 solver.cpp:253]     Train net output #0: loss = 1.11527 (* 1 = 1.11527 loss)
I0526 16:17:55.463040 12837 sgd_solver.cpp:106] Iteration 453000, lr = 0.002
I0526 16:18:07.605919 12837 solver.cpp:237] Iteration 453750, loss = 1.16288
I0526 16:18:07.605963 12837 solver.cpp:253]     Train net output #0: loss = 1.16288 (* 1 = 1.16288 loss)
I0526 16:18:07.605978 12837 sgd_solver.cpp:106] Iteration 453750, lr = 0.002
I0526 16:18:19.786156 12837 solver.cpp:237] Iteration 454500, loss = 1.52914
I0526 16:18:19.786191 12837 solver.cpp:253]     Train net output #0: loss = 1.52913 (* 1 = 1.52913 loss)
I0526 16:18:19.786206 12837 sgd_solver.cpp:106] Iteration 454500, lr = 0.002
I0526 16:18:53.246292 12837 solver.cpp:237] Iteration 455250, loss = 1.35951
I0526 16:18:53.246475 12837 solver.cpp:253]     Train net output #0: loss = 1.35951 (* 1 = 1.35951 loss)
I0526 16:18:53.246490 12837 sgd_solver.cpp:106] Iteration 455250, lr = 0.002
I0526 16:19:05.404942 12837 solver.cpp:237] Iteration 456000, loss = 0.785718
I0526 16:19:05.404978 12837 solver.cpp:253]     Train net output #0: loss = 0.785716 (* 1 = 0.785716 loss)
I0526 16:19:05.404994 12837 sgd_solver.cpp:106] Iteration 456000, lr = 0.002
I0526 16:19:17.532436 12837 solver.cpp:237] Iteration 456750, loss = 1.07152
I0526 16:19:17.532480 12837 solver.cpp:253]     Train net output #0: loss = 1.07152 (* 1 = 1.07152 loss)
I0526 16:19:17.532493 12837 sgd_solver.cpp:106] Iteration 456750, lr = 0.002
I0526 16:19:29.669678 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_457500.caffemodel
I0526 16:19:29.744752 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_457500.solverstate
I0526 16:19:29.801064 12837 solver.cpp:237] Iteration 457500, loss = 1.0894
I0526 16:19:29.801113 12837 solver.cpp:253]     Train net output #0: loss = 1.0894 (* 1 = 1.0894 loss)
I0526 16:19:29.801129 12837 sgd_solver.cpp:106] Iteration 457500, lr = 0.002
I0526 16:19:41.958525 12837 solver.cpp:237] Iteration 458250, loss = 1.08951
I0526 16:19:41.958578 12837 solver.cpp:253]     Train net output #0: loss = 1.0895 (* 1 = 1.0895 loss)
I0526 16:19:41.958592 12837 sgd_solver.cpp:106] Iteration 458250, lr = 0.002
I0526 16:19:54.068693 12837 solver.cpp:237] Iteration 459000, loss = 0.960048
I0526 16:19:54.068730 12837 solver.cpp:253]     Train net output #0: loss = 0.960045 (* 1 = 0.960045 loss)
I0526 16:19:54.068744 12837 sgd_solver.cpp:106] Iteration 459000, lr = 0.002
I0526 16:20:06.230222 12837 solver.cpp:237] Iteration 459750, loss = 1.19831
I0526 16:20:06.230409 12837 solver.cpp:253]     Train net output #0: loss = 1.19831 (* 1 = 1.19831 loss)
I0526 16:20:06.230423 12837 sgd_solver.cpp:106] Iteration 459750, lr = 0.002
I0526 16:20:40.440662 12837 solver.cpp:237] Iteration 460500, loss = 1.25752
I0526 16:20:40.440841 12837 solver.cpp:253]     Train net output #0: loss = 1.25752 (* 1 = 1.25752 loss)
I0526 16:20:40.440856 12837 sgd_solver.cpp:106] Iteration 460500, lr = 0.002
I0526 16:20:52.622268 12837 solver.cpp:237] Iteration 461250, loss = 1.47045
I0526 16:20:52.622316 12837 solver.cpp:253]     Train net output #0: loss = 1.47044 (* 1 = 1.47044 loss)
I0526 16:20:52.622331 12837 sgd_solver.cpp:106] Iteration 461250, lr = 0.002
I0526 16:21:04.755107 12837 solver.cpp:237] Iteration 462000, loss = 0.910048
I0526 16:21:04.755144 12837 solver.cpp:253]     Train net output #0: loss = 0.910045 (* 1 = 0.910045 loss)
I0526 16:21:04.755158 12837 sgd_solver.cpp:106] Iteration 462000, lr = 0.002
I0526 16:21:16.872521 12837 solver.cpp:237] Iteration 462750, loss = 1.1218
I0526 16:21:16.872695 12837 solver.cpp:253]     Train net output #0: loss = 1.1218 (* 1 = 1.1218 loss)
I0526 16:21:16.872709 12837 sgd_solver.cpp:106] Iteration 462750, lr = 0.002
I0526 16:21:29.042268 12837 solver.cpp:237] Iteration 463500, loss = 1.31019
I0526 16:21:29.042316 12837 solver.cpp:253]     Train net output #0: loss = 1.31018 (* 1 = 1.31018 loss)
I0526 16:21:29.042330 12837 sgd_solver.cpp:106] Iteration 463500, lr = 0.002
I0526 16:21:41.235054 12837 solver.cpp:237] Iteration 464250, loss = 1.07877
I0526 16:21:41.235090 12837 solver.cpp:253]     Train net output #0: loss = 1.07877 (* 1 = 1.07877 loss)
I0526 16:21:41.235105 12837 sgd_solver.cpp:106] Iteration 464250, lr = 0.002
I0526 16:21:53.382004 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_465000.caffemodel
I0526 16:21:53.465729 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_465000.solverstate
I0526 16:21:53.521935 12837 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 16:23:12.318750 12837 solver.cpp:409]     Test net output #0: accuracy = 0.902846
I0526 16:23:12.318933 12837 solver.cpp:409]     Test net output #1: loss = 0.345645 (* 1 = 0.345645 loss)
I0526 16:23:33.231412 12837 solver.cpp:237] Iteration 465000, loss = 1.06324
I0526 16:23:33.231468 12837 solver.cpp:253]     Train net output #0: loss = 1.06323 (* 1 = 1.06323 loss)
I0526 16:23:33.231483 12837 sgd_solver.cpp:106] Iteration 465000, lr = 0.002
I0526 16:23:45.377543 12837 solver.cpp:237] Iteration 465750, loss = 0.824883
I0526 16:23:45.377709 12837 solver.cpp:253]     Train net output #0: loss = 0.824879 (* 1 = 0.824879 loss)
I0526 16:23:45.377723 12837 sgd_solver.cpp:106] Iteration 465750, lr = 0.002
I0526 16:23:57.546172 12837 solver.cpp:237] Iteration 466500, loss = 0.780855
I0526 16:23:57.546221 12837 solver.cpp:253]     Train net output #0: loss = 0.780851 (* 1 = 0.780851 loss)
I0526 16:23:57.546234 12837 sgd_solver.cpp:106] Iteration 466500, lr = 0.002
I0526 16:24:09.707012 12837 solver.cpp:237] Iteration 467250, loss = 1.26313
I0526 16:24:09.707048 12837 solver.cpp:253]     Train net output #0: loss = 1.26312 (* 1 = 1.26312 loss)
I0526 16:24:09.707063 12837 sgd_solver.cpp:106] Iteration 467250, lr = 0.002
I0526 16:24:21.874011 12837 solver.cpp:237] Iteration 468000, loss = 1.34218
I0526 16:24:21.874186 12837 solver.cpp:253]     Train net output #0: loss = 1.34217 (* 1 = 1.34217 loss)
I0526 16:24:21.874199 12837 sgd_solver.cpp:106] Iteration 468000, lr = 0.002
I0526 16:24:34.045470 12837 solver.cpp:237] Iteration 468750, loss = 1.16457
I0526 16:24:34.045506 12837 solver.cpp:253]     Train net output #0: loss = 1.16456 (* 1 = 1.16456 loss)
I0526 16:24:34.045521 12837 sgd_solver.cpp:106] Iteration 468750, lr = 0.002
I0526 16:24:46.245214 12837 solver.cpp:237] Iteration 469500, loss = 1.07219
I0526 16:24:46.245259 12837 solver.cpp:253]     Train net output #0: loss = 1.07218 (* 1 = 1.07218 loss)
I0526 16:24:46.245272 12837 sgd_solver.cpp:106] Iteration 469500, lr = 0.002
I0526 16:25:19.361176 12837 solver.cpp:237] Iteration 470250, loss = 1.15479
I0526 16:25:19.361369 12837 solver.cpp:253]     Train net output #0: loss = 1.15478 (* 1 = 1.15478 loss)
I0526 16:25:19.361383 12837 sgd_solver.cpp:106] Iteration 470250, lr = 0.002
I0526 16:25:31.505851 12837 solver.cpp:237] Iteration 471000, loss = 1.12936
I0526 16:25:31.505899 12837 solver.cpp:253]     Train net output #0: loss = 1.12935 (* 1 = 1.12935 loss)
I0526 16:25:31.505914 12837 sgd_solver.cpp:106] Iteration 471000, lr = 0.002
I0526 16:25:43.632238 12837 solver.cpp:237] Iteration 471750, loss = 0.796447
I0526 16:25:43.632275 12837 solver.cpp:253]     Train net output #0: loss = 0.796444 (* 1 = 0.796444 loss)
I0526 16:25:43.632289 12837 sgd_solver.cpp:106] Iteration 471750, lr = 0.002
I0526 16:25:55.742012 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_472500.caffemodel
I0526 16:25:55.803136 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_472500.solverstate
I0526 16:25:55.836925 12837 solver.cpp:237] Iteration 472500, loss = 1.24697
I0526 16:25:55.836976 12837 solver.cpp:253]     Train net output #0: loss = 1.24697 (* 1 = 1.24697 loss)
I0526 16:25:55.836994 12837 sgd_solver.cpp:106] Iteration 472500, lr = 0.002
I0526 16:26:07.977706 12837 solver.cpp:237] Iteration 473250, loss = 1.14842
I0526 16:26:07.977741 12837 solver.cpp:253]     Train net output #0: loss = 1.14842 (* 1 = 1.14842 loss)
I0526 16:26:07.977756 12837 sgd_solver.cpp:106] Iteration 473250, lr = 0.002
I0526 16:26:20.143112 12837 solver.cpp:237] Iteration 474000, loss = 0.964214
I0526 16:26:20.143162 12837 solver.cpp:253]     Train net output #0: loss = 0.964211 (* 1 = 0.964211 loss)
I0526 16:26:20.143177 12837 sgd_solver.cpp:106] Iteration 474000, lr = 0.002
I0526 16:26:32.330163 12837 solver.cpp:237] Iteration 474750, loss = 1.24863
I0526 16:26:32.330327 12837 solver.cpp:253]     Train net output #0: loss = 1.24863 (* 1 = 1.24863 loss)
I0526 16:26:32.330340 12837 sgd_solver.cpp:106] Iteration 474750, lr = 0.002
I0526 16:27:05.436750 12837 solver.cpp:237] Iteration 475500, loss = 0.879858
I0526 16:27:05.436944 12837 solver.cpp:253]     Train net output #0: loss = 0.879855 (* 1 = 0.879855 loss)
I0526 16:27:05.436959 12837 sgd_solver.cpp:106] Iteration 475500, lr = 0.002
I0526 16:27:17.568222 12837 solver.cpp:237] Iteration 476250, loss = 0.820102
I0526 16:27:17.568277 12837 solver.cpp:253]     Train net output #0: loss = 0.820099 (* 1 = 0.820099 loss)
I0526 16:27:17.568291 12837 sgd_solver.cpp:106] Iteration 476250, lr = 0.002
I0526 16:27:29.696511 12837 solver.cpp:237] Iteration 477000, loss = 1.46042
I0526 16:27:29.696547 12837 solver.cpp:253]     Train net output #0: loss = 1.46042 (* 1 = 1.46042 loss)
I0526 16:27:29.696562 12837 sgd_solver.cpp:106] Iteration 477000, lr = 0.002
I0526 16:27:41.804751 12837 solver.cpp:237] Iteration 477750, loss = 1.10371
I0526 16:27:41.804925 12837 solver.cpp:253]     Train net output #0: loss = 1.1037 (* 1 = 1.1037 loss)
I0526 16:27:41.804939 12837 sgd_solver.cpp:106] Iteration 477750, lr = 0.002
I0526 16:27:53.965183 12837 solver.cpp:237] Iteration 478500, loss = 1.08003
I0526 16:27:53.965219 12837 solver.cpp:253]     Train net output #0: loss = 1.08003 (* 1 = 1.08003 loss)
I0526 16:27:53.965234 12837 sgd_solver.cpp:106] Iteration 478500, lr = 0.002
I0526 16:28:06.108793 12837 solver.cpp:237] Iteration 479250, loss = 0.954198
I0526 16:28:06.108836 12837 solver.cpp:253]     Train net output #0: loss = 0.954195 (* 1 = 0.954195 loss)
I0526 16:28:06.108850 12837 sgd_solver.cpp:106] Iteration 479250, lr = 0.002
I0526 16:28:18.257026 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_480000.caffemodel
I0526 16:28:18.314571 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_480000.solverstate
I0526 16:28:18.339949 12837 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 16:29:10.503319 12837 solver.cpp:409]     Test net output #0: accuracy = 0.904958
I0526 16:29:10.503501 12837 solver.cpp:409]     Test net output #1: loss = 0.304614 (* 1 = 0.304614 loss)
I0526 16:29:31.427322 12837 solver.cpp:237] Iteration 480000, loss = 0.721616
I0526 16:29:31.427378 12837 solver.cpp:253]     Train net output #0: loss = 0.721612 (* 1 = 0.721612 loss)
I0526 16:29:31.427394 12837 sgd_solver.cpp:106] Iteration 480000, lr = 0.002
I0526 16:29:43.663889 12837 solver.cpp:237] Iteration 480750, loss = 1.26399
I0526 16:29:43.664072 12837 solver.cpp:253]     Train net output #0: loss = 1.26399 (* 1 = 1.26399 loss)
I0526 16:29:43.664085 12837 sgd_solver.cpp:106] Iteration 480750, lr = 0.002
I0526 16:29:55.886418 12837 solver.cpp:237] Iteration 481500, loss = 0.995514
I0526 16:29:55.886456 12837 solver.cpp:253]     Train net output #0: loss = 0.995511 (* 1 = 0.995511 loss)
I0526 16:29:55.886469 12837 sgd_solver.cpp:106] Iteration 481500, lr = 0.002
I0526 16:30:08.057291 12837 solver.cpp:237] Iteration 482250, loss = 0.91599
I0526 16:30:08.057343 12837 solver.cpp:253]     Train net output #0: loss = 0.915987 (* 1 = 0.915987 loss)
I0526 16:30:08.057356 12837 sgd_solver.cpp:106] Iteration 482250, lr = 0.002
I0526 16:30:20.249644 12837 solver.cpp:237] Iteration 483000, loss = 0.988327
I0526 16:30:20.249806 12837 solver.cpp:253]     Train net output #0: loss = 0.988324 (* 1 = 0.988324 loss)
I0526 16:30:20.249819 12837 sgd_solver.cpp:106] Iteration 483000, lr = 0.002
I0526 16:30:32.485576 12837 solver.cpp:237] Iteration 483750, loss = 1.30482
I0526 16:30:32.485621 12837 solver.cpp:253]     Train net output #0: loss = 1.30482 (* 1 = 1.30482 loss)
I0526 16:30:32.485637 12837 sgd_solver.cpp:106] Iteration 483750, lr = 0.002
I0526 16:30:44.650763 12837 solver.cpp:237] Iteration 484500, loss = 1.02719
I0526 16:30:44.650797 12837 solver.cpp:253]     Train net output #0: loss = 1.02719 (* 1 = 1.02719 loss)
I0526 16:30:44.650811 12837 sgd_solver.cpp:106] Iteration 484500, lr = 0.002
I0526 16:31:17.796735 12837 solver.cpp:237] Iteration 485250, loss = 1.00341
I0526 16:31:17.796913 12837 solver.cpp:253]     Train net output #0: loss = 1.00341 (* 1 = 1.00341 loss)
I0526 16:31:17.796927 12837 sgd_solver.cpp:106] Iteration 485250, lr = 0.002
I0526 16:31:30.018261 12837 solver.cpp:237] Iteration 486000, loss = 1.05663
I0526 16:31:30.018297 12837 solver.cpp:253]     Train net output #0: loss = 1.05663 (* 1 = 1.05663 loss)
I0526 16:31:30.018312 12837 sgd_solver.cpp:106] Iteration 486000, lr = 0.002
I0526 16:31:42.156357 12837 solver.cpp:237] Iteration 486750, loss = 1.50775
I0526 16:31:42.156393 12837 solver.cpp:253]     Train net output #0: loss = 1.50775 (* 1 = 1.50775 loss)
I0526 16:31:42.156407 12837 sgd_solver.cpp:106] Iteration 486750, lr = 0.002
I0526 16:31:54.361408 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_487500.caffemodel
I0526 16:31:54.411837 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_487500.solverstate
I0526 16:31:54.442610 12837 solver.cpp:237] Iteration 487500, loss = 1.26407
I0526 16:31:54.442657 12837 solver.cpp:253]     Train net output #0: loss = 1.26407 (* 1 = 1.26407 loss)
I0526 16:31:54.442672 12837 sgd_solver.cpp:106] Iteration 487500, lr = 0.002
I0526 16:32:06.654703 12837 solver.cpp:237] Iteration 488250, loss = 1.11027
I0526 16:32:06.654741 12837 solver.cpp:253]     Train net output #0: loss = 1.11027 (* 1 = 1.11027 loss)
I0526 16:32:06.654754 12837 sgd_solver.cpp:106] Iteration 488250, lr = 0.002
I0526 16:32:18.862435 12837 solver.cpp:237] Iteration 489000, loss = 1.10248
I0526 16:32:18.862476 12837 solver.cpp:253]     Train net output #0: loss = 1.10248 (* 1 = 1.10248 loss)
I0526 16:32:18.862489 12837 sgd_solver.cpp:106] Iteration 489000, lr = 0.002
I0526 16:32:31.054399 12837 solver.cpp:237] Iteration 489750, loss = 1.0853
I0526 16:32:31.054574 12837 solver.cpp:253]     Train net output #0: loss = 1.0853 (* 1 = 1.0853 loss)
I0526 16:32:31.054587 12837 sgd_solver.cpp:106] Iteration 489750, lr = 0.002
I0526 16:33:04.303220 12837 solver.cpp:237] Iteration 490500, loss = 1.08978
I0526 16:33:04.303407 12837 solver.cpp:253]     Train net output #0: loss = 1.08978 (* 1 = 1.08978 loss)
I0526 16:33:04.303422 12837 sgd_solver.cpp:106] Iteration 490500, lr = 0.002
I0526 16:33:16.474048 12837 solver.cpp:237] Iteration 491250, loss = 1.20348
I0526 16:33:16.474084 12837 solver.cpp:253]     Train net output #0: loss = 1.20348 (* 1 = 1.20348 loss)
I0526 16:33:16.474098 12837 sgd_solver.cpp:106] Iteration 491250, lr = 0.002
I0526 16:33:28.653717 12837 solver.cpp:237] Iteration 492000, loss = 1.53252
I0526 16:33:28.653753 12837 solver.cpp:253]     Train net output #0: loss = 1.53252 (* 1 = 1.53252 loss)
I0526 16:33:28.653769 12837 sgd_solver.cpp:106] Iteration 492000, lr = 0.002
I0526 16:33:40.856978 12837 solver.cpp:237] Iteration 492750, loss = 1.19475
I0526 16:33:40.857133 12837 solver.cpp:253]     Train net output #0: loss = 1.19475 (* 1 = 1.19475 loss)
I0526 16:33:40.857147 12837 sgd_solver.cpp:106] Iteration 492750, lr = 0.002
I0526 16:33:53.004621 12837 solver.cpp:237] Iteration 493500, loss = 1.38774
I0526 16:33:53.004670 12837 solver.cpp:253]     Train net output #0: loss = 1.38774 (* 1 = 1.38774 loss)
I0526 16:33:53.004684 12837 sgd_solver.cpp:106] Iteration 493500, lr = 0.002
I0526 16:34:05.184655 12837 solver.cpp:237] Iteration 494250, loss = 1.46147
I0526 16:34:05.184692 12837 solver.cpp:253]     Train net output #0: loss = 1.46147 (* 1 = 1.46147 loss)
I0526 16:34:05.184706 12837 sgd_solver.cpp:106] Iteration 494250, lr = 0.002
I0526 16:34:17.319757 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_495000.caffemodel
I0526 16:34:17.369742 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_495000.solverstate
I0526 16:34:17.395642 12837 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 16:35:30.457690 12837 solver.cpp:409]     Test net output #0: accuracy = 0.903505
I0526 16:35:30.457873 12837 solver.cpp:409]     Test net output #1: loss = 0.300999 (* 1 = 0.300999 loss)
I0526 16:35:51.392730 12837 solver.cpp:237] Iteration 495000, loss = 1.4236
I0526 16:35:51.392786 12837 solver.cpp:253]     Train net output #0: loss = 1.4236 (* 1 = 1.4236 loss)
I0526 16:35:51.392802 12837 sgd_solver.cpp:106] Iteration 495000, lr = 0.002
I0526 16:36:03.575501 12837 solver.cpp:237] Iteration 495750, loss = 1.04671
I0526 16:36:03.575700 12837 solver.cpp:253]     Train net output #0: loss = 1.04671 (* 1 = 1.04671 loss)
I0526 16:36:03.575714 12837 sgd_solver.cpp:106] Iteration 495750, lr = 0.002
I0526 16:36:15.681968 12837 solver.cpp:237] Iteration 496500, loss = 1.29434
I0526 16:36:15.682004 12837 solver.cpp:253]     Train net output #0: loss = 1.29434 (* 1 = 1.29434 loss)
I0526 16:36:15.682018 12837 sgd_solver.cpp:106] Iteration 496500, lr = 0.002
I0526 16:36:27.782655 12837 solver.cpp:237] Iteration 497250, loss = 0.888156
I0526 16:36:27.782707 12837 solver.cpp:253]     Train net output #0: loss = 0.888153 (* 1 = 0.888153 loss)
I0526 16:36:27.782721 12837 sgd_solver.cpp:106] Iteration 497250, lr = 0.002
I0526 16:36:39.894529 12837 solver.cpp:237] Iteration 498000, loss = 0.659895
I0526 16:36:39.894712 12837 solver.cpp:253]     Train net output #0: loss = 0.659892 (* 1 = 0.659892 loss)
I0526 16:36:39.894726 12837 sgd_solver.cpp:106] Iteration 498000, lr = 0.002
I0526 16:36:52.099050 12837 solver.cpp:237] Iteration 498750, loss = 1.39789
I0526 16:36:52.099097 12837 solver.cpp:253]     Train net output #0: loss = 1.39789 (* 1 = 1.39789 loss)
I0526 16:36:52.099110 12837 sgd_solver.cpp:106] Iteration 498750, lr = 0.002
I0526 16:37:04.209612 12837 solver.cpp:237] Iteration 499500, loss = 0.626259
I0526 16:37:04.209650 12837 solver.cpp:253]     Train net output #0: loss = 0.626257 (* 1 = 0.626257 loss)
I0526 16:37:04.209663 12837 sgd_solver.cpp:106] Iteration 499500, lr = 0.002
I0526 16:37:37.281028 12837 solver.cpp:237] Iteration 500250, loss = 1.32946
I0526 16:37:37.281219 12837 solver.cpp:253]     Train net output #0: loss = 1.32946 (* 1 = 1.32946 loss)
I0526 16:37:37.281234 12837 sgd_solver.cpp:106] Iteration 500250, lr = 0.002
I0526 16:37:49.418495 12837 solver.cpp:237] Iteration 501000, loss = 1.23795
I0526 16:37:49.418531 12837 solver.cpp:253]     Train net output #0: loss = 1.23795 (* 1 = 1.23795 loss)
I0526 16:37:49.418546 12837 sgd_solver.cpp:106] Iteration 501000, lr = 0.002
I0526 16:38:01.575402 12837 solver.cpp:237] Iteration 501750, loss = 1.53186
I0526 16:38:01.575449 12837 solver.cpp:253]     Train net output #0: loss = 1.53186 (* 1 = 1.53186 loss)
I0526 16:38:01.575464 12837 sgd_solver.cpp:106] Iteration 501750, lr = 0.002
I0526 16:38:13.721485 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_502500.caffemodel
I0526 16:38:13.772944 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_502500.solverstate
I0526 16:38:13.806476 12837 solver.cpp:237] Iteration 502500, loss = 1.521
I0526 16:38:13.806529 12837 solver.cpp:253]     Train net output #0: loss = 1.521 (* 1 = 1.521 loss)
I0526 16:38:13.806545 12837 sgd_solver.cpp:106] Iteration 502500, lr = 0.002
I0526 16:38:25.951596 12837 solver.cpp:237] Iteration 503250, loss = 1.08311
I0526 16:38:25.951653 12837 solver.cpp:253]     Train net output #0: loss = 1.08311 (* 1 = 1.08311 loss)
I0526 16:38:25.951668 12837 sgd_solver.cpp:106] Iteration 503250, lr = 0.002
I0526 16:38:38.080541 12837 solver.cpp:237] Iteration 504000, loss = 1.09222
I0526 16:38:38.080577 12837 solver.cpp:253]     Train net output #0: loss = 1.09222 (* 1 = 1.09222 loss)
I0526 16:38:38.080592 12837 sgd_solver.cpp:106] Iteration 504000, lr = 0.002
I0526 16:38:50.209523 12837 solver.cpp:237] Iteration 504750, loss = 1.04714
I0526 16:38:50.209705 12837 solver.cpp:253]     Train net output #0: loss = 1.04714 (* 1 = 1.04714 loss)
I0526 16:38:50.209719 12837 sgd_solver.cpp:106] Iteration 504750, lr = 0.002
I0526 16:39:23.499460 12837 solver.cpp:237] Iteration 505500, loss = 0.773377
I0526 16:39:23.499657 12837 solver.cpp:253]     Train net output #0: loss = 0.773374 (* 1 = 0.773374 loss)
I0526 16:39:23.499672 12837 sgd_solver.cpp:106] Iteration 505500, lr = 0.002
I0526 16:39:35.625092 12837 solver.cpp:237] Iteration 506250, loss = 0.75772
I0526 16:39:35.625128 12837 solver.cpp:253]     Train net output #0: loss = 0.757717 (* 1 = 0.757717 loss)
I0526 16:39:35.625144 12837 sgd_solver.cpp:106] Iteration 506250, lr = 0.002
I0526 16:39:47.750008 12837 solver.cpp:237] Iteration 507000, loss = 1.19553
I0526 16:39:47.750057 12837 solver.cpp:253]     Train net output #0: loss = 1.19553 (* 1 = 1.19553 loss)
I0526 16:39:47.750072 12837 sgd_solver.cpp:106] Iteration 507000, lr = 0.002
I0526 16:39:59.907618 12837 solver.cpp:237] Iteration 507750, loss = 1.04347
I0526 16:39:59.907809 12837 solver.cpp:253]     Train net output #0: loss = 1.04347 (* 1 = 1.04347 loss)
I0526 16:39:59.907825 12837 sgd_solver.cpp:106] Iteration 507750, lr = 0.002
I0526 16:40:12.073235 12837 solver.cpp:237] Iteration 508500, loss = 1.45399
I0526 16:40:12.073283 12837 solver.cpp:253]     Train net output #0: loss = 1.45399 (* 1 = 1.45399 loss)
I0526 16:40:12.073297 12837 sgd_solver.cpp:106] Iteration 508500, lr = 0.002
I0526 16:40:24.260334 12837 solver.cpp:237] Iteration 509250, loss = 1.27367
I0526 16:40:24.260370 12837 solver.cpp:253]     Train net output #0: loss = 1.27366 (* 1 = 1.27366 loss)
I0526 16:40:24.260383 12837 sgd_solver.cpp:106] Iteration 509250, lr = 0.002
I0526 16:40:36.424589 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_510000.caffemodel
I0526 16:40:36.477092 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_510000.solverstate
I0526 16:40:36.561859 12837 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 16:41:28.299623 12837 solver.cpp:409]     Test net output #0: accuracy = 0.904365
I0526 16:41:28.299826 12837 solver.cpp:409]     Test net output #1: loss = 0.308265 (* 1 = 0.308265 loss)
I0526 16:41:49.271556 12837 solver.cpp:237] Iteration 510000, loss = 1.08571
I0526 16:41:49.271612 12837 solver.cpp:253]     Train net output #0: loss = 1.08571 (* 1 = 1.08571 loss)
I0526 16:41:49.271627 12837 sgd_solver.cpp:106] Iteration 510000, lr = 0.002
I0526 16:42:01.458525 12837 solver.cpp:237] Iteration 510750, loss = 0.85164
I0526 16:42:01.458708 12837 solver.cpp:253]     Train net output #0: loss = 0.851637 (* 1 = 0.851637 loss)
I0526 16:42:01.458722 12837 sgd_solver.cpp:106] Iteration 510750, lr = 0.002
I0526 16:42:13.670320 12837 solver.cpp:237] Iteration 511500, loss = 0.961079
I0526 16:42:13.670372 12837 solver.cpp:253]     Train net output #0: loss = 0.961075 (* 1 = 0.961075 loss)
I0526 16:42:13.670385 12837 sgd_solver.cpp:106] Iteration 511500, lr = 0.002
I0526 16:42:25.865918 12837 solver.cpp:237] Iteration 512250, loss = 0.815278
I0526 16:42:25.865954 12837 solver.cpp:253]     Train net output #0: loss = 0.815275 (* 1 = 0.815275 loss)
I0526 16:42:25.865969 12837 sgd_solver.cpp:106] Iteration 512250, lr = 0.002
I0526 16:42:38.081542 12837 solver.cpp:237] Iteration 513000, loss = 1.29778
I0526 16:42:38.081727 12837 solver.cpp:253]     Train net output #0: loss = 1.29778 (* 1 = 1.29778 loss)
I0526 16:42:38.081743 12837 sgd_solver.cpp:106] Iteration 513000, lr = 0.002
I0526 16:42:50.330778 12837 solver.cpp:237] Iteration 513750, loss = 0.99953
I0526 16:42:50.330816 12837 solver.cpp:253]     Train net output #0: loss = 0.999527 (* 1 = 0.999527 loss)
I0526 16:42:50.330829 12837 sgd_solver.cpp:106] Iteration 513750, lr = 0.002
I0526 16:43:02.559317 12837 solver.cpp:237] Iteration 514500, loss = 1.52106
I0526 16:43:02.559370 12837 solver.cpp:253]     Train net output #0: loss = 1.52106 (* 1 = 1.52106 loss)
I0526 16:43:02.559384 12837 sgd_solver.cpp:106] Iteration 514500, lr = 0.002
I0526 16:43:35.752020 12837 solver.cpp:237] Iteration 515250, loss = 0.948191
I0526 16:43:35.752209 12837 solver.cpp:253]     Train net output #0: loss = 0.948188 (* 1 = 0.948188 loss)
I0526 16:43:35.752225 12837 sgd_solver.cpp:106] Iteration 515250, lr = 0.002
I0526 16:43:47.959961 12837 solver.cpp:237] Iteration 516000, loss = 1.32876
I0526 16:43:47.960006 12837 solver.cpp:253]     Train net output #0: loss = 1.32876 (* 1 = 1.32876 loss)
I0526 16:43:47.960021 12837 sgd_solver.cpp:106] Iteration 516000, lr = 0.002
I0526 16:44:00.141721 12837 solver.cpp:237] Iteration 516750, loss = 1.89443
I0526 16:44:00.141757 12837 solver.cpp:253]     Train net output #0: loss = 1.89442 (* 1 = 1.89442 loss)
I0526 16:44:00.141772 12837 sgd_solver.cpp:106] Iteration 516750, lr = 0.002
I0526 16:44:12.307952 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_517500.caffemodel
I0526 16:44:12.357395 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_517500.solverstate
I0526 16:44:12.414057 12837 solver.cpp:237] Iteration 517500, loss = 1.00554
I0526 16:44:12.414105 12837 solver.cpp:253]     Train net output #0: loss = 1.00554 (* 1 = 1.00554 loss)
I0526 16:44:12.414124 12837 sgd_solver.cpp:106] Iteration 517500, lr = 0.002
I0526 16:44:24.593799 12837 solver.cpp:237] Iteration 518250, loss = 1.39401
I0526 16:44:24.593837 12837 solver.cpp:253]     Train net output #0: loss = 1.39401 (* 1 = 1.39401 loss)
I0526 16:44:24.593850 12837 sgd_solver.cpp:106] Iteration 518250, lr = 0.002
I0526 16:44:36.773948 12837 solver.cpp:237] Iteration 519000, loss = 1.02636
I0526 16:44:36.773984 12837 solver.cpp:253]     Train net output #0: loss = 1.02635 (* 1 = 1.02635 loss)
I0526 16:44:36.773999 12837 sgd_solver.cpp:106] Iteration 519000, lr = 0.002
I0526 16:44:48.983117 12837 solver.cpp:237] Iteration 519750, loss = 0.774975
I0526 16:44:48.983316 12837 solver.cpp:253]     Train net output #0: loss = 0.774972 (* 1 = 0.774972 loss)
I0526 16:44:48.983330 12837 sgd_solver.cpp:106] Iteration 519750, lr = 0.002
I0526 16:45:22.136608 12837 solver.cpp:237] Iteration 520500, loss = 0.969217
I0526 16:45:22.136796 12837 solver.cpp:253]     Train net output #0: loss = 0.969213 (* 1 = 0.969213 loss)
I0526 16:45:22.136811 12837 sgd_solver.cpp:106] Iteration 520500, lr = 0.002
I0526 16:45:34.352344 12837 solver.cpp:237] Iteration 521250, loss = 1.34104
I0526 16:45:34.352392 12837 solver.cpp:253]     Train net output #0: loss = 1.34104 (* 1 = 1.34104 loss)
I0526 16:45:34.352406 12837 sgd_solver.cpp:106] Iteration 521250, lr = 0.002
I0526 16:45:46.501710 12837 solver.cpp:237] Iteration 522000, loss = 0.748248
I0526 16:45:46.501745 12837 solver.cpp:253]     Train net output #0: loss = 0.748244 (* 1 = 0.748244 loss)
I0526 16:45:46.501762 12837 sgd_solver.cpp:106] Iteration 522000, lr = 0.002
I0526 16:45:58.693783 12837 solver.cpp:237] Iteration 522750, loss = 0.910437
I0526 16:45:58.693959 12837 solver.cpp:253]     Train net output #0: loss = 0.910433 (* 1 = 0.910433 loss)
I0526 16:45:58.693974 12837 sgd_solver.cpp:106] Iteration 522750, lr = 0.002
I0526 16:46:10.897686 12837 solver.cpp:237] Iteration 523500, loss = 1.28093
I0526 16:46:10.897721 12837 solver.cpp:253]     Train net output #0: loss = 1.28092 (* 1 = 1.28092 loss)
I0526 16:46:10.897735 12837 sgd_solver.cpp:106] Iteration 523500, lr = 0.002
I0526 16:46:23.094183 12837 solver.cpp:237] Iteration 524250, loss = 1.17869
I0526 16:46:23.094234 12837 solver.cpp:253]     Train net output #0: loss = 1.17869 (* 1 = 1.17869 loss)
I0526 16:46:23.094249 12837 sgd_solver.cpp:106] Iteration 524250, lr = 0.002
I0526 16:46:35.265769 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_525000.caffemodel
I0526 16:46:35.315860 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_525000.solverstate
I0526 16:46:35.341281 12837 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 16:47:48.231750 12837 solver.cpp:409]     Test net output #0: accuracy = 0.905227
I0526 16:47:48.231957 12837 solver.cpp:409]     Test net output #1: loss = 0.294246 (* 1 = 0.294246 loss)
I0526 16:48:09.267601 12837 solver.cpp:237] Iteration 525000, loss = 1.22735
I0526 16:48:09.267653 12837 solver.cpp:253]     Train net output #0: loss = 1.22735 (* 1 = 1.22735 loss)
I0526 16:48:09.267668 12837 sgd_solver.cpp:106] Iteration 525000, lr = 0.002
I0526 16:48:21.419545 12837 solver.cpp:237] Iteration 525750, loss = 1.18783
I0526 16:48:21.419723 12837 solver.cpp:253]     Train net output #0: loss = 1.18782 (* 1 = 1.18782 loss)
I0526 16:48:21.419737 12837 sgd_solver.cpp:106] Iteration 525750, lr = 0.002
I0526 16:48:33.578560 12837 solver.cpp:237] Iteration 526500, loss = 0.841885
I0526 16:48:33.578606 12837 solver.cpp:253]     Train net output #0: loss = 0.841882 (* 1 = 0.841882 loss)
I0526 16:48:33.578620 12837 sgd_solver.cpp:106] Iteration 526500, lr = 0.002
I0526 16:48:45.759125 12837 solver.cpp:237] Iteration 527250, loss = 0.981308
I0526 16:48:45.759162 12837 solver.cpp:253]     Train net output #0: loss = 0.981304 (* 1 = 0.981304 loss)
I0526 16:48:45.759176 12837 sgd_solver.cpp:106] Iteration 527250, lr = 0.002
I0526 16:48:57.973470 12837 solver.cpp:237] Iteration 528000, loss = 1.10358
I0526 16:48:57.973650 12837 solver.cpp:253]     Train net output #0: loss = 1.10358 (* 1 = 1.10358 loss)
I0526 16:48:57.973664 12837 sgd_solver.cpp:106] Iteration 528000, lr = 0.002
I0526 16:49:10.177994 12837 solver.cpp:237] Iteration 528750, loss = 1.3505
I0526 16:49:10.178030 12837 solver.cpp:253]     Train net output #0: loss = 1.3505 (* 1 = 1.3505 loss)
I0526 16:49:10.178045 12837 sgd_solver.cpp:106] Iteration 528750, lr = 0.002
I0526 16:49:22.420421 12837 solver.cpp:237] Iteration 529500, loss = 1.49668
I0526 16:49:22.420466 12837 solver.cpp:253]     Train net output #0: loss = 1.49668 (* 1 = 1.49668 loss)
I0526 16:49:22.420482 12837 sgd_solver.cpp:106] Iteration 529500, lr = 0.002
I0526 16:49:55.500483 12837 solver.cpp:237] Iteration 530250, loss = 1.15396
I0526 16:49:55.500669 12837 solver.cpp:253]     Train net output #0: loss = 1.15395 (* 1 = 1.15395 loss)
I0526 16:49:55.500682 12837 sgd_solver.cpp:106] Iteration 530250, lr = 0.002
I0526 16:50:07.663857 12837 solver.cpp:237] Iteration 531000, loss = 0.735828
I0526 16:50:07.663905 12837 solver.cpp:253]     Train net output #0: loss = 0.735825 (* 1 = 0.735825 loss)
I0526 16:50:07.663919 12837 sgd_solver.cpp:106] Iteration 531000, lr = 0.002
I0526 16:50:19.804818 12837 solver.cpp:237] Iteration 531750, loss = 1.18726
I0526 16:50:19.804853 12837 solver.cpp:253]     Train net output #0: loss = 1.18726 (* 1 = 1.18726 loss)
I0526 16:50:19.804868 12837 sgd_solver.cpp:106] Iteration 531750, lr = 0.002
I0526 16:50:31.946619 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_532500.caffemodel
I0526 16:50:31.998172 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_532500.solverstate
I0526 16:50:32.032366 12837 solver.cpp:237] Iteration 532500, loss = 1.50902
I0526 16:50:32.032415 12837 solver.cpp:253]     Train net output #0: loss = 1.50902 (* 1 = 1.50902 loss)
I0526 16:50:32.032429 12837 sgd_solver.cpp:106] Iteration 532500, lr = 0.002
I0526 16:50:44.217491 12837 solver.cpp:237] Iteration 533250, loss = 1.6805
I0526 16:50:44.217526 12837 solver.cpp:253]     Train net output #0: loss = 1.6805 (* 1 = 1.6805 loss)
I0526 16:50:44.217541 12837 sgd_solver.cpp:106] Iteration 533250, lr = 0.002
I0526 16:50:56.379715 12837 solver.cpp:237] Iteration 534000, loss = 1.18759
I0526 16:50:56.379761 12837 solver.cpp:253]     Train net output #0: loss = 1.18759 (* 1 = 1.18759 loss)
I0526 16:50:56.379775 12837 sgd_solver.cpp:106] Iteration 534000, lr = 0.002
I0526 16:51:08.545354 12837 solver.cpp:237] Iteration 534750, loss = 1.12803
I0526 16:51:08.545533 12837 solver.cpp:253]     Train net output #0: loss = 1.12802 (* 1 = 1.12802 loss)
I0526 16:51:08.545547 12837 sgd_solver.cpp:106] Iteration 534750, lr = 0.002
I0526 16:51:41.658154 12837 solver.cpp:237] Iteration 535500, loss = 0.815404
I0526 16:51:41.658349 12837 solver.cpp:253]     Train net output #0: loss = 0.8154 (* 1 = 0.8154 loss)
I0526 16:51:41.658366 12837 sgd_solver.cpp:106] Iteration 535500, lr = 0.002
I0526 16:51:53.824046 12837 solver.cpp:237] Iteration 536250, loss = 1.33107
I0526 16:51:53.824086 12837 solver.cpp:253]     Train net output #0: loss = 1.33107 (* 1 = 1.33107 loss)
I0526 16:51:53.824101 12837 sgd_solver.cpp:106] Iteration 536250, lr = 0.002
I0526 16:52:06.341697 12837 solver.cpp:237] Iteration 537000, loss = 1.11086
I0526 16:52:06.341732 12837 solver.cpp:253]     Train net output #0: loss = 1.11086 (* 1 = 1.11086 loss)
I0526 16:52:06.341747 12837 sgd_solver.cpp:106] Iteration 537000, lr = 0.002
I0526 16:52:32.181767 12837 solver.cpp:237] Iteration 537750, loss = 0.984313
I0526 16:52:32.181962 12837 solver.cpp:253]     Train net output #0: loss = 0.98431 (* 1 = 0.98431 loss)
I0526 16:52:32.181977 12837 sgd_solver.cpp:106] Iteration 537750, lr = 0.002
I0526 16:52:44.326530 12837 solver.cpp:237] Iteration 538500, loss = 1.14373
I0526 16:52:44.326566 12837 solver.cpp:253]     Train net output #0: loss = 1.14373 (* 1 = 1.14373 loss)
I0526 16:52:44.326581 12837 sgd_solver.cpp:106] Iteration 538500, lr = 0.002
I0526 16:52:56.440816 12837 solver.cpp:237] Iteration 539250, loss = 1.05055
I0526 16:52:56.440852 12837 solver.cpp:253]     Train net output #0: loss = 1.05055 (* 1 = 1.05055 loss)
I0526 16:52:56.440866 12837 sgd_solver.cpp:106] Iteration 539250, lr = 0.002
I0526 16:53:08.551990 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_540000.caffemodel
I0526 16:53:08.606672 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_540000.solverstate
I0526 16:53:08.633991 12837 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 16:54:00.643052 12837 solver.cpp:409]     Test net output #0: accuracy = 0.906132
I0526 16:54:00.643252 12837 solver.cpp:409]     Test net output #1: loss = 0.307633 (* 1 = 0.307633 loss)
I0526 16:54:21.569764 12837 solver.cpp:237] Iteration 540000, loss = 1.3148
I0526 16:54:21.569820 12837 solver.cpp:253]     Train net output #0: loss = 1.3148 (* 1 = 1.3148 loss)
I0526 16:54:21.569835 12837 sgd_solver.cpp:106] Iteration 540000, lr = 0.002
I0526 16:54:33.694389 12837 solver.cpp:237] Iteration 540750, loss = 0.916746
I0526 16:54:33.694563 12837 solver.cpp:253]     Train net output #0: loss = 0.916742 (* 1 = 0.916742 loss)
I0526 16:54:33.694577 12837 sgd_solver.cpp:106] Iteration 540750, lr = 0.002
I0526 16:54:45.838120 12837 solver.cpp:237] Iteration 541500, loss = 0.579767
I0526 16:54:45.838172 12837 solver.cpp:253]     Train net output #0: loss = 0.579763 (* 1 = 0.579763 loss)
I0526 16:54:45.838187 12837 sgd_solver.cpp:106] Iteration 541500, lr = 0.002
I0526 16:54:58.011327 12837 solver.cpp:237] Iteration 542250, loss = 1.27329
I0526 16:54:58.011363 12837 solver.cpp:253]     Train net output #0: loss = 1.27328 (* 1 = 1.27328 loss)
I0526 16:54:58.011378 12837 sgd_solver.cpp:106] Iteration 542250, lr = 0.002
I0526 16:55:10.183360 12837 solver.cpp:237] Iteration 543000, loss = 1.09317
I0526 16:55:10.183552 12837 solver.cpp:253]     Train net output #0: loss = 1.09317 (* 1 = 1.09317 loss)
I0526 16:55:10.183568 12837 sgd_solver.cpp:106] Iteration 543000, lr = 0.002
I0526 16:55:22.371448 12837 solver.cpp:237] Iteration 543750, loss = 1.39779
I0526 16:55:22.371485 12837 solver.cpp:253]     Train net output #0: loss = 1.39779 (* 1 = 1.39779 loss)
I0526 16:55:22.371498 12837 sgd_solver.cpp:106] Iteration 543750, lr = 0.002
I0526 16:55:34.715965 12837 solver.cpp:237] Iteration 544500, loss = 1.02534
I0526 16:55:34.716014 12837 solver.cpp:253]     Train net output #0: loss = 1.02534 (* 1 = 1.02534 loss)
I0526 16:55:34.716029 12837 sgd_solver.cpp:106] Iteration 544500, lr = 0.002
I0526 16:56:07.832065 12837 solver.cpp:237] Iteration 545250, loss = 0.888946
I0526 16:56:07.832260 12837 solver.cpp:253]     Train net output #0: loss = 0.888943 (* 1 = 0.888943 loss)
I0526 16:56:07.832276 12837 sgd_solver.cpp:106] Iteration 545250, lr = 0.002
I0526 16:56:20.005022 12837 solver.cpp:237] Iteration 546000, loss = 1.04631
I0526 16:56:20.005074 12837 solver.cpp:253]     Train net output #0: loss = 1.04631 (* 1 = 1.04631 loss)
I0526 16:56:20.005087 12837 sgd_solver.cpp:106] Iteration 546000, lr = 0.002
I0526 16:56:32.159950 12837 solver.cpp:237] Iteration 546750, loss = 0.885195
I0526 16:56:32.159983 12837 solver.cpp:253]     Train net output #0: loss = 0.885191 (* 1 = 0.885191 loss)
I0526 16:56:32.159996 12837 sgd_solver.cpp:106] Iteration 546750, lr = 0.002
I0526 16:56:44.317101 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_547500.caffemodel
I0526 16:56:44.369315 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_547500.solverstate
I0526 16:56:44.402364 12837 solver.cpp:237] Iteration 547500, loss = 0.974666
I0526 16:56:44.402420 12837 solver.cpp:253]     Train net output #0: loss = 0.974663 (* 1 = 0.974663 loss)
I0526 16:56:44.402436 12837 sgd_solver.cpp:106] Iteration 547500, lr = 0.002
I0526 16:56:56.528231 12837 solver.cpp:237] Iteration 548250, loss = 1.34356
I0526 16:56:56.528267 12837 solver.cpp:253]     Train net output #0: loss = 1.34355 (* 1 = 1.34355 loss)
I0526 16:56:56.528282 12837 sgd_solver.cpp:106] Iteration 548250, lr = 0.002
I0526 16:57:08.658417 12837 solver.cpp:237] Iteration 549000, loss = 1.20291
I0526 16:57:08.658466 12837 solver.cpp:253]     Train net output #0: loss = 1.20291 (* 1 = 1.20291 loss)
I0526 16:57:08.658483 12837 sgd_solver.cpp:106] Iteration 549000, lr = 0.002
I0526 16:57:20.796468 12837 solver.cpp:237] Iteration 549750, loss = 1.04774
I0526 16:57:20.796643 12837 solver.cpp:253]     Train net output #0: loss = 1.04774 (* 1 = 1.04774 loss)
I0526 16:57:20.796658 12837 sgd_solver.cpp:106] Iteration 549750, lr = 0.002
I0526 16:57:53.883571 12837 solver.cpp:237] Iteration 550500, loss = 0.970598
I0526 16:57:53.883764 12837 solver.cpp:253]     Train net output #0: loss = 0.970595 (* 1 = 0.970595 loss)
I0526 16:57:53.883781 12837 sgd_solver.cpp:106] Iteration 550500, lr = 0.002
I0526 16:58:06.073964 12837 solver.cpp:237] Iteration 551250, loss = 0.995634
I0526 16:58:06.074012 12837 solver.cpp:253]     Train net output #0: loss = 0.995631 (* 1 = 0.995631 loss)
I0526 16:58:06.074028 12837 sgd_solver.cpp:106] Iteration 551250, lr = 0.002
I0526 16:58:18.231848 12837 solver.cpp:237] Iteration 552000, loss = 1.3171
I0526 16:58:18.231884 12837 solver.cpp:253]     Train net output #0: loss = 1.31709 (* 1 = 1.31709 loss)
I0526 16:58:18.231899 12837 sgd_solver.cpp:106] Iteration 552000, lr = 0.002
I0526 16:58:30.401114 12837 solver.cpp:237] Iteration 552750, loss = 1.21853
I0526 16:58:30.401296 12837 solver.cpp:253]     Train net output #0: loss = 1.21853 (* 1 = 1.21853 loss)
I0526 16:58:30.401311 12837 sgd_solver.cpp:106] Iteration 552750, lr = 0.002
I0526 16:58:42.577900 12837 solver.cpp:237] Iteration 553500, loss = 1.51075
I0526 16:58:42.577936 12837 solver.cpp:253]     Train net output #0: loss = 1.51074 (* 1 = 1.51074 loss)
I0526 16:58:42.577951 12837 sgd_solver.cpp:106] Iteration 553500, lr = 0.002
I0526 16:58:54.802214 12837 solver.cpp:237] Iteration 554250, loss = 0.722228
I0526 16:58:54.802260 12837 solver.cpp:253]     Train net output #0: loss = 0.722225 (* 1 = 0.722225 loss)
I0526 16:58:54.802275 12837 sgd_solver.cpp:106] Iteration 554250, lr = 0.002
I0526 16:59:06.897166 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_555000.caffemodel
I0526 16:59:06.952071 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_555000.solverstate
I0526 16:59:06.983187 12837 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 17:00:19.903269 12837 solver.cpp:409]     Test net output #0: accuracy = 0.903797
I0526 17:00:19.903470 12837 solver.cpp:409]     Test net output #1: loss = 0.297856 (* 1 = 0.297856 loss)
I0526 17:00:40.871623 12837 solver.cpp:237] Iteration 555000, loss = 0.818877
I0526 17:00:40.871678 12837 solver.cpp:253]     Train net output #0: loss = 0.818874 (* 1 = 0.818874 loss)
I0526 17:00:40.871695 12837 sgd_solver.cpp:106] Iteration 555000, lr = 0.002
I0526 17:00:53.031185 12837 solver.cpp:237] Iteration 555750, loss = 0.507881
I0526 17:00:53.031380 12837 solver.cpp:253]     Train net output #0: loss = 0.507878 (* 1 = 0.507878 loss)
I0526 17:00:53.031394 12837 sgd_solver.cpp:106] Iteration 555750, lr = 0.002
I0526 17:01:05.187360 12837 solver.cpp:237] Iteration 556500, loss = 1.34465
I0526 17:01:05.187397 12837 solver.cpp:253]     Train net output #0: loss = 1.34465 (* 1 = 1.34465 loss)
I0526 17:01:05.187409 12837 sgd_solver.cpp:106] Iteration 556500, lr = 0.002
I0526 17:01:17.349604 12837 solver.cpp:237] Iteration 557250, loss = 1.02179
I0526 17:01:17.349639 12837 solver.cpp:253]     Train net output #0: loss = 1.02179 (* 1 = 1.02179 loss)
I0526 17:01:17.349655 12837 sgd_solver.cpp:106] Iteration 557250, lr = 0.002
I0526 17:01:29.576112 12837 solver.cpp:237] Iteration 558000, loss = 0.874938
I0526 17:01:29.576311 12837 solver.cpp:253]     Train net output #0: loss = 0.874935 (* 1 = 0.874935 loss)
I0526 17:01:29.576326 12837 sgd_solver.cpp:106] Iteration 558000, lr = 0.002
I0526 17:01:41.766712 12837 solver.cpp:237] Iteration 558750, loss = 1.28501
I0526 17:01:41.766748 12837 solver.cpp:253]     Train net output #0: loss = 1.285 (* 1 = 1.285 loss)
I0526 17:01:41.766762 12837 sgd_solver.cpp:106] Iteration 558750, lr = 0.002
I0526 17:01:53.896301 12837 solver.cpp:237] Iteration 559500, loss = 0.935632
I0526 17:01:53.896350 12837 solver.cpp:253]     Train net output #0: loss = 0.93563 (* 1 = 0.93563 loss)
I0526 17:01:53.896363 12837 sgd_solver.cpp:106] Iteration 559500, lr = 0.002
I0526 17:02:27.037446 12837 solver.cpp:237] Iteration 560250, loss = 1.07481
I0526 17:02:27.037639 12837 solver.cpp:253]     Train net output #0: loss = 1.0748 (* 1 = 1.0748 loss)
I0526 17:02:27.037653 12837 sgd_solver.cpp:106] Iteration 560250, lr = 0.002
I0526 17:02:39.175709 12837 solver.cpp:237] Iteration 561000, loss = 1.12372
I0526 17:02:39.175761 12837 solver.cpp:253]     Train net output #0: loss = 1.12371 (* 1 = 1.12371 loss)
I0526 17:02:39.175776 12837 sgd_solver.cpp:106] Iteration 561000, lr = 0.002
I0526 17:02:51.352800 12837 solver.cpp:237] Iteration 561750, loss = 1.00094
I0526 17:02:51.352835 12837 solver.cpp:253]     Train net output #0: loss = 1.00094 (* 1 = 1.00094 loss)
I0526 17:02:51.352849 12837 sgd_solver.cpp:106] Iteration 561750, lr = 0.002
I0526 17:03:03.549340 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_562500.caffemodel
I0526 17:03:03.598950 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_562500.solverstate
I0526 17:03:03.629215 12837 solver.cpp:237] Iteration 562500, loss = 1.92133
I0526 17:03:03.629263 12837 solver.cpp:253]     Train net output #0: loss = 1.92132 (* 1 = 1.92132 loss)
I0526 17:03:03.629279 12837 sgd_solver.cpp:106] Iteration 562500, lr = 0.002
I0526 17:03:15.818440 12837 solver.cpp:237] Iteration 563250, loss = 0.793647
I0526 17:03:15.818476 12837 solver.cpp:253]     Train net output #0: loss = 0.793644 (* 1 = 0.793644 loss)
I0526 17:03:15.818490 12837 sgd_solver.cpp:106] Iteration 563250, lr = 0.002
I0526 17:03:27.952819 12837 solver.cpp:237] Iteration 564000, loss = 0.926564
I0526 17:03:27.952869 12837 solver.cpp:253]     Train net output #0: loss = 0.926561 (* 1 = 0.926561 loss)
I0526 17:03:27.952883 12837 sgd_solver.cpp:106] Iteration 564000, lr = 0.002
I0526 17:03:40.100476 12837 solver.cpp:237] Iteration 564750, loss = 0.698857
I0526 17:03:40.100651 12837 solver.cpp:253]     Train net output #0: loss = 0.698854 (* 1 = 0.698854 loss)
I0526 17:03:40.100666 12837 sgd_solver.cpp:106] Iteration 564750, lr = 0.002
I0526 17:04:13.265949 12837 solver.cpp:237] Iteration 565500, loss = 1.16036
I0526 17:04:13.266162 12837 solver.cpp:253]     Train net output #0: loss = 1.16036 (* 1 = 1.16036 loss)
I0526 17:04:13.266177 12837 sgd_solver.cpp:106] Iteration 565500, lr = 0.002
I0526 17:04:25.441156 12837 solver.cpp:237] Iteration 566250, loss = 1.1521
I0526 17:04:25.441192 12837 solver.cpp:253]     Train net output #0: loss = 1.1521 (* 1 = 1.1521 loss)
I0526 17:04:25.441207 12837 sgd_solver.cpp:106] Iteration 566250, lr = 0.002
I0526 17:04:37.620781 12837 solver.cpp:237] Iteration 567000, loss = 1.10199
I0526 17:04:37.620829 12837 solver.cpp:253]     Train net output #0: loss = 1.10198 (* 1 = 1.10198 loss)
I0526 17:04:37.620849 12837 sgd_solver.cpp:106] Iteration 567000, lr = 0.002
I0526 17:04:49.792620 12837 solver.cpp:237] Iteration 567750, loss = 0.852425
I0526 17:04:49.792791 12837 solver.cpp:253]     Train net output #0: loss = 0.852422 (* 1 = 0.852422 loss)
I0526 17:04:49.792809 12837 sgd_solver.cpp:106] Iteration 567750, lr = 0.002
I0526 17:05:01.926246 12837 solver.cpp:237] Iteration 568500, loss = 1.13741
I0526 17:05:01.926282 12837 solver.cpp:253]     Train net output #0: loss = 1.13741 (* 1 = 1.13741 loss)
I0526 17:05:01.926296 12837 sgd_solver.cpp:106] Iteration 568500, lr = 0.002
I0526 17:05:14.095986 12837 solver.cpp:237] Iteration 569250, loss = 1.32548
I0526 17:05:14.096029 12837 solver.cpp:253]     Train net output #0: loss = 1.32548 (* 1 = 1.32548 loss)
I0526 17:05:14.096042 12837 sgd_solver.cpp:106] Iteration 569250, lr = 0.002
I0526 17:05:26.239168 12837 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_570000.caffemodel
I0526 17:05:26.288684 12837 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_570000.solverstate
I0526 17:05:26.314363 12837 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 17:06:17.994370 12837 solver.cpp:409]     Test net output #0: accuracy = 0.902265
I0526 17:06:17.994560 12837 solver.cpp:409]     Test net output #1: loss = 0.302627 (* 1 = 0.302627 loss)
I0526 17:06:38.941125 12837 solver.cpp:237] Iteration 570000, loss = 1.15369
I0526 17:06:38.941181 12837 solver.cpp:253]     Train net output #0: loss = 1.15369 (* 1 = 1.15369 loss)
I0526 17:06:38.941196 12837 sgd_solver.cpp:106] Iteration 570000, lr = 0.002
I0526 17:06:51.136857 12837 solver.cpp:237] Iteration 570750, loss = 1.12292
I0526 17:06:51.137048 12837 solver.cpp:253]     Train net output #0: loss = 1.12292 (* 1 = 1.12292 loss)
I0526 17:06:51.137061 12837 sgd_solver.cpp:106] Iteration 570750, lr = 0.002
I0526 17:07:03.259574 12837 solver.cpp:237] Iteration 571500, loss = 1.16437
I0526 17:07:03.259609 12837 solver.cpp:253]     Train net output #0: loss = 1.16437 (* 1 = 1.16437 loss)
I0526 17:07:03.259625 12837 sgd_solver.cpp:106] Iteration 571500, lr = 0.002
I0526 17:07:15.463430 12837 solver.cpp:237] Iteration 572250, loss = 1.20204
I0526 17:07:15.463481 12837 solver.cpp:253]     Train net output #0: loss = 1.20204 (* 1 = 1.20204 loss)
I0526 17:07:15.463495 12837 sgd_solver.cpp:106] Iteration 572250, lr = 0.002
I0526 17:07:27.683852 12837 solver.cpp:237] Iteration 573000, loss = 0.795937
I0526 17:07:27.684022 12837 solver.cpp:253]     Train net output #0: loss = 0.795934 (* 1 = 0.795934 loss)
I0526 17:07:27.684036 12837 sgd_solver.cpp:106] Iteration 573000, lr = 0.002
I0526 17:07:39.908329 12837 solver.cpp:237] Iteration 573750, loss = 1.03119
I0526 17:07:39.908375 12837 solver.cpp:253]     Train net output #0: loss = 1.03118 (* 1 = 1.03118 loss)
I0526 17:07:39.908392 12837 sgd_solver.cpp:106] Iteration 573750, lr = 0.002
I0526 17:07:52.117285 12837 solver.cpp:237] Iteration 574500, loss = 1.01151
I0526 17:07:52.117321 12837 solver.cpp:253]     Train net output #0: loss = 1.01151 (* 1 = 1.01151 loss)
I0526 17:07:52.117336 12837 sgd_solver.cpp:106] Iteration 574500, lr = 0.002
aprun: Apid 11269505: Caught signal Terminated, sending to application
*** Aborted at 1464296893 (unix time) try "date -d @1464296893" if you are using GNU date ***
aprun: Apid 11269505: Caught signal Terminated, sending to application
aprun: Apid 11269505: Caught signal Terminated, sending to application
PC: @     0x2aaab7f0d502 __GI_memcpy
*** SIGTERM (@0x3222) received by PID 12837 (TID 0x2aaac746f900) from PID 12834; stack trace: ***
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab7f0d502 __GI_memcpy
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab7f04f96 _int_realloc
aprun: Apid 11269505: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7245 exceeded limit 7200
    @     0x2aaab7f053ba __GI___libc_realloc
aprun: Apid 11269505: Caught signal Terminated, sending to application
aprun: Apid 11269505: Caught signal Terminated, sending to application
aprun: Apid 11269505: Caught signal Terminated, sending to application
aprun: Apid 11269505: Caught signal Terminated, sending to application
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab1450ac4 H5Z_filter_deflate
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11269505: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
