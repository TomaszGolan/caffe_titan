2806898
I0521 18:02:10.180233 17204 caffe.cpp:184] Using GPUs 0
I0521 18:02:10.610891 17204 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0045
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324.prototxt"
I0521 18:02:10.612661 17204 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324.prototxt
I0521 18:02:10.624518 17204 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 18:02:10.624577 17204 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 18:02:10.624923 17204 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 18:02:10.625107 17204 layer_factory.hpp:77] Creating layer data_hdf5
I0521 18:02:10.625130 17204 net.cpp:106] Creating Layer data_hdf5
I0521 18:02:10.625144 17204 net.cpp:411] data_hdf5 -> data
I0521 18:02:10.625177 17204 net.cpp:411] data_hdf5 -> label
I0521 18:02:10.625211 17204 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 18:02:10.626456 17204 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 18:02:10.628626 17204 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 18:02:32.172950 17204 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 18:02:32.178087 17204 net.cpp:150] Setting up data_hdf5
I0521 18:02:32.178128 17204 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 18:02:32.178143 17204 net.cpp:157] Top shape: 10 (10)
I0521 18:02:32.178154 17204 net.cpp:165] Memory required for data: 254040
I0521 18:02:32.178167 17204 layer_factory.hpp:77] Creating layer conv1
I0521 18:02:32.178202 17204 net.cpp:106] Creating Layer conv1
I0521 18:02:32.178213 17204 net.cpp:454] conv1 <- data
I0521 18:02:32.178237 17204 net.cpp:411] conv1 -> conv1
I0521 18:02:33.053012 17204 net.cpp:150] Setting up conv1
I0521 18:02:33.053058 17204 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 18:02:33.053069 17204 net.cpp:165] Memory required for data: 3018840
I0521 18:02:33.053098 17204 layer_factory.hpp:77] Creating layer relu1
I0521 18:02:33.053119 17204 net.cpp:106] Creating Layer relu1
I0521 18:02:33.053129 17204 net.cpp:454] relu1 <- conv1
I0521 18:02:33.053143 17204 net.cpp:397] relu1 -> conv1 (in-place)
I0521 18:02:33.053663 17204 net.cpp:150] Setting up relu1
I0521 18:02:33.053679 17204 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 18:02:33.053691 17204 net.cpp:165] Memory required for data: 5783640
I0521 18:02:33.053702 17204 layer_factory.hpp:77] Creating layer pool1
I0521 18:02:33.053720 17204 net.cpp:106] Creating Layer pool1
I0521 18:02:33.053730 17204 net.cpp:454] pool1 <- conv1
I0521 18:02:33.053745 17204 net.cpp:411] pool1 -> pool1
I0521 18:02:33.053823 17204 net.cpp:150] Setting up pool1
I0521 18:02:33.053838 17204 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 18:02:33.053848 17204 net.cpp:165] Memory required for data: 7166040
I0521 18:02:33.053858 17204 layer_factory.hpp:77] Creating layer conv2
I0521 18:02:33.053879 17204 net.cpp:106] Creating Layer conv2
I0521 18:02:33.053890 17204 net.cpp:454] conv2 <- pool1
I0521 18:02:33.053903 17204 net.cpp:411] conv2 -> conv2
I0521 18:02:33.056612 17204 net.cpp:150] Setting up conv2
I0521 18:02:33.056639 17204 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 18:02:33.056650 17204 net.cpp:165] Memory required for data: 9153240
I0521 18:02:33.056669 17204 layer_factory.hpp:77] Creating layer relu2
I0521 18:02:33.056684 17204 net.cpp:106] Creating Layer relu2
I0521 18:02:33.056694 17204 net.cpp:454] relu2 <- conv2
I0521 18:02:33.056706 17204 net.cpp:397] relu2 -> conv2 (in-place)
I0521 18:02:33.057037 17204 net.cpp:150] Setting up relu2
I0521 18:02:33.057052 17204 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 18:02:33.057062 17204 net.cpp:165] Memory required for data: 11140440
I0521 18:02:33.057073 17204 layer_factory.hpp:77] Creating layer pool2
I0521 18:02:33.057086 17204 net.cpp:106] Creating Layer pool2
I0521 18:02:33.057096 17204 net.cpp:454] pool2 <- conv2
I0521 18:02:33.057109 17204 net.cpp:411] pool2 -> pool2
I0521 18:02:33.057189 17204 net.cpp:150] Setting up pool2
I0521 18:02:33.057202 17204 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 18:02:33.057210 17204 net.cpp:165] Memory required for data: 12134040
I0521 18:02:33.057220 17204 layer_factory.hpp:77] Creating layer conv3
I0521 18:02:33.057238 17204 net.cpp:106] Creating Layer conv3
I0521 18:02:33.057248 17204 net.cpp:454] conv3 <- pool2
I0521 18:02:33.057261 17204 net.cpp:411] conv3 -> conv3
I0521 18:02:33.059348 17204 net.cpp:150] Setting up conv3
I0521 18:02:33.059371 17204 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 18:02:33.059383 17204 net.cpp:165] Memory required for data: 13218200
I0521 18:02:33.059402 17204 layer_factory.hpp:77] Creating layer relu3
I0521 18:02:33.059417 17204 net.cpp:106] Creating Layer relu3
I0521 18:02:33.059427 17204 net.cpp:454] relu3 <- conv3
I0521 18:02:33.059440 17204 net.cpp:397] relu3 -> conv3 (in-place)
I0521 18:02:33.059917 17204 net.cpp:150] Setting up relu3
I0521 18:02:33.059937 17204 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 18:02:33.059947 17204 net.cpp:165] Memory required for data: 14302360
I0521 18:02:33.059957 17204 layer_factory.hpp:77] Creating layer pool3
I0521 18:02:33.059969 17204 net.cpp:106] Creating Layer pool3
I0521 18:02:33.059979 17204 net.cpp:454] pool3 <- conv3
I0521 18:02:33.059991 17204 net.cpp:411] pool3 -> pool3
I0521 18:02:33.060058 17204 net.cpp:150] Setting up pool3
I0521 18:02:33.060072 17204 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 18:02:33.060082 17204 net.cpp:165] Memory required for data: 14844440
I0521 18:02:33.060091 17204 layer_factory.hpp:77] Creating layer conv4
I0521 18:02:33.060108 17204 net.cpp:106] Creating Layer conv4
I0521 18:02:33.060118 17204 net.cpp:454] conv4 <- pool3
I0521 18:02:33.060132 17204 net.cpp:411] conv4 -> conv4
I0521 18:02:33.062825 17204 net.cpp:150] Setting up conv4
I0521 18:02:33.062855 17204 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 18:02:33.062865 17204 net.cpp:165] Memory required for data: 15207320
I0521 18:02:33.062880 17204 layer_factory.hpp:77] Creating layer relu4
I0521 18:02:33.062894 17204 net.cpp:106] Creating Layer relu4
I0521 18:02:33.062903 17204 net.cpp:454] relu4 <- conv4
I0521 18:02:33.062916 17204 net.cpp:397] relu4 -> conv4 (in-place)
I0521 18:02:33.063382 17204 net.cpp:150] Setting up relu4
I0521 18:02:33.063398 17204 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 18:02:33.063408 17204 net.cpp:165] Memory required for data: 15570200
I0521 18:02:33.063419 17204 layer_factory.hpp:77] Creating layer pool4
I0521 18:02:33.063432 17204 net.cpp:106] Creating Layer pool4
I0521 18:02:33.063441 17204 net.cpp:454] pool4 <- conv4
I0521 18:02:33.063454 17204 net.cpp:411] pool4 -> pool4
I0521 18:02:33.063522 17204 net.cpp:150] Setting up pool4
I0521 18:02:33.063536 17204 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 18:02:33.063545 17204 net.cpp:165] Memory required for data: 15751640
I0521 18:02:33.063555 17204 layer_factory.hpp:77] Creating layer ip1
I0521 18:02:33.063576 17204 net.cpp:106] Creating Layer ip1
I0521 18:02:33.063586 17204 net.cpp:454] ip1 <- pool4
I0521 18:02:33.063598 17204 net.cpp:411] ip1 -> ip1
I0521 18:02:33.079033 17204 net.cpp:150] Setting up ip1
I0521 18:02:33.079061 17204 net.cpp:157] Top shape: 10 196 (1960)
I0521 18:02:33.079076 17204 net.cpp:165] Memory required for data: 15759480
I0521 18:02:33.079103 17204 layer_factory.hpp:77] Creating layer relu5
I0521 18:02:33.079118 17204 net.cpp:106] Creating Layer relu5
I0521 18:02:33.079128 17204 net.cpp:454] relu5 <- ip1
I0521 18:02:33.079141 17204 net.cpp:397] relu5 -> ip1 (in-place)
I0521 18:02:33.079484 17204 net.cpp:150] Setting up relu5
I0521 18:02:33.079499 17204 net.cpp:157] Top shape: 10 196 (1960)
I0521 18:02:33.079509 17204 net.cpp:165] Memory required for data: 15767320
I0521 18:02:33.079519 17204 layer_factory.hpp:77] Creating layer drop1
I0521 18:02:33.079540 17204 net.cpp:106] Creating Layer drop1
I0521 18:02:33.079550 17204 net.cpp:454] drop1 <- ip1
I0521 18:02:33.079562 17204 net.cpp:397] drop1 -> ip1 (in-place)
I0521 18:02:33.079622 17204 net.cpp:150] Setting up drop1
I0521 18:02:33.079634 17204 net.cpp:157] Top shape: 10 196 (1960)
I0521 18:02:33.079644 17204 net.cpp:165] Memory required for data: 15775160
I0521 18:02:33.079654 17204 layer_factory.hpp:77] Creating layer ip2
I0521 18:02:33.079673 17204 net.cpp:106] Creating Layer ip2
I0521 18:02:33.079682 17204 net.cpp:454] ip2 <- ip1
I0521 18:02:33.079696 17204 net.cpp:411] ip2 -> ip2
I0521 18:02:33.080166 17204 net.cpp:150] Setting up ip2
I0521 18:02:33.080179 17204 net.cpp:157] Top shape: 10 98 (980)
I0521 18:02:33.080189 17204 net.cpp:165] Memory required for data: 15779080
I0521 18:02:33.080205 17204 layer_factory.hpp:77] Creating layer relu6
I0521 18:02:33.080217 17204 net.cpp:106] Creating Layer relu6
I0521 18:02:33.080227 17204 net.cpp:454] relu6 <- ip2
I0521 18:02:33.080240 17204 net.cpp:397] relu6 -> ip2 (in-place)
I0521 18:02:33.080756 17204 net.cpp:150] Setting up relu6
I0521 18:02:33.080773 17204 net.cpp:157] Top shape: 10 98 (980)
I0521 18:02:33.080782 17204 net.cpp:165] Memory required for data: 15783000
I0521 18:02:33.080793 17204 layer_factory.hpp:77] Creating layer drop2
I0521 18:02:33.080806 17204 net.cpp:106] Creating Layer drop2
I0521 18:02:33.080816 17204 net.cpp:454] drop2 <- ip2
I0521 18:02:33.080828 17204 net.cpp:397] drop2 -> ip2 (in-place)
I0521 18:02:33.080870 17204 net.cpp:150] Setting up drop2
I0521 18:02:33.080883 17204 net.cpp:157] Top shape: 10 98 (980)
I0521 18:02:33.080894 17204 net.cpp:165] Memory required for data: 15786920
I0521 18:02:33.080904 17204 layer_factory.hpp:77] Creating layer ip3
I0521 18:02:33.080917 17204 net.cpp:106] Creating Layer ip3
I0521 18:02:33.080927 17204 net.cpp:454] ip3 <- ip2
I0521 18:02:33.080940 17204 net.cpp:411] ip3 -> ip3
I0521 18:02:33.081146 17204 net.cpp:150] Setting up ip3
I0521 18:02:33.081159 17204 net.cpp:157] Top shape: 10 11 (110)
I0521 18:02:33.081169 17204 net.cpp:165] Memory required for data: 15787360
I0521 18:02:33.081184 17204 layer_factory.hpp:77] Creating layer drop3
I0521 18:02:33.081197 17204 net.cpp:106] Creating Layer drop3
I0521 18:02:33.081207 17204 net.cpp:454] drop3 <- ip3
I0521 18:02:33.081219 17204 net.cpp:397] drop3 -> ip3 (in-place)
I0521 18:02:33.081257 17204 net.cpp:150] Setting up drop3
I0521 18:02:33.081270 17204 net.cpp:157] Top shape: 10 11 (110)
I0521 18:02:33.081279 17204 net.cpp:165] Memory required for data: 15787800
I0521 18:02:33.081290 17204 layer_factory.hpp:77] Creating layer loss
I0521 18:02:33.081308 17204 net.cpp:106] Creating Layer loss
I0521 18:02:33.081318 17204 net.cpp:454] loss <- ip3
I0521 18:02:33.081329 17204 net.cpp:454] loss <- label
I0521 18:02:33.081341 17204 net.cpp:411] loss -> loss
I0521 18:02:33.081357 17204 layer_factory.hpp:77] Creating layer loss
I0521 18:02:33.081995 17204 net.cpp:150] Setting up loss
I0521 18:02:33.082010 17204 net.cpp:157] Top shape: (1)
I0521 18:02:33.082022 17204 net.cpp:160]     with loss weight 1
I0521 18:02:33.082065 17204 net.cpp:165] Memory required for data: 15787804
I0521 18:02:33.082075 17204 net.cpp:226] loss needs backward computation.
I0521 18:02:33.082087 17204 net.cpp:226] drop3 needs backward computation.
I0521 18:02:33.082096 17204 net.cpp:226] ip3 needs backward computation.
I0521 18:02:33.082106 17204 net.cpp:226] drop2 needs backward computation.
I0521 18:02:33.082116 17204 net.cpp:226] relu6 needs backward computation.
I0521 18:02:33.082126 17204 net.cpp:226] ip2 needs backward computation.
I0521 18:02:33.082136 17204 net.cpp:226] drop1 needs backward computation.
I0521 18:02:33.082146 17204 net.cpp:226] relu5 needs backward computation.
I0521 18:02:33.082155 17204 net.cpp:226] ip1 needs backward computation.
I0521 18:02:33.082165 17204 net.cpp:226] pool4 needs backward computation.
I0521 18:02:33.082175 17204 net.cpp:226] relu4 needs backward computation.
I0521 18:02:33.082185 17204 net.cpp:226] conv4 needs backward computation.
I0521 18:02:33.082195 17204 net.cpp:226] pool3 needs backward computation.
I0521 18:02:33.082206 17204 net.cpp:226] relu3 needs backward computation.
I0521 18:02:33.082216 17204 net.cpp:226] conv3 needs backward computation.
I0521 18:02:33.082236 17204 net.cpp:226] pool2 needs backward computation.
I0521 18:02:33.082247 17204 net.cpp:226] relu2 needs backward computation.
I0521 18:02:33.082257 17204 net.cpp:226] conv2 needs backward computation.
I0521 18:02:33.082267 17204 net.cpp:226] pool1 needs backward computation.
I0521 18:02:33.082278 17204 net.cpp:226] relu1 needs backward computation.
I0521 18:02:33.082286 17204 net.cpp:226] conv1 needs backward computation.
I0521 18:02:33.082298 17204 net.cpp:228] data_hdf5 does not need backward computation.
I0521 18:02:33.082307 17204 net.cpp:270] This network produces output loss
I0521 18:02:33.082331 17204 net.cpp:283] Network initialization done.
I0521 18:02:33.083956 17204 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324.prototxt
I0521 18:02:33.084028 17204 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 18:02:33.084379 17204 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 18:02:33.084569 17204 layer_factory.hpp:77] Creating layer data_hdf5
I0521 18:02:33.084585 17204 net.cpp:106] Creating Layer data_hdf5
I0521 18:02:33.084597 17204 net.cpp:411] data_hdf5 -> data
I0521 18:02:33.084614 17204 net.cpp:411] data_hdf5 -> label
I0521 18:02:33.084630 17204 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 18:02:33.085907 17204 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 18:02:54.351536 17204 net.cpp:150] Setting up data_hdf5
I0521 18:02:54.351711 17204 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 18:02:54.351725 17204 net.cpp:157] Top shape: 10 (10)
I0521 18:02:54.351735 17204 net.cpp:165] Memory required for data: 254040
I0521 18:02:54.351749 17204 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 18:02:54.351778 17204 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 18:02:54.351789 17204 net.cpp:454] label_data_hdf5_1_split <- label
I0521 18:02:54.351804 17204 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 18:02:54.351825 17204 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 18:02:54.351898 17204 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 18:02:54.351912 17204 net.cpp:157] Top shape: 10 (10)
I0521 18:02:54.351924 17204 net.cpp:157] Top shape: 10 (10)
I0521 18:02:54.351933 17204 net.cpp:165] Memory required for data: 254120
I0521 18:02:54.351943 17204 layer_factory.hpp:77] Creating layer conv1
I0521 18:02:54.351966 17204 net.cpp:106] Creating Layer conv1
I0521 18:02:54.351977 17204 net.cpp:454] conv1 <- data
I0521 18:02:54.351990 17204 net.cpp:411] conv1 -> conv1
I0521 18:02:54.353919 17204 net.cpp:150] Setting up conv1
I0521 18:02:54.353937 17204 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 18:02:54.353947 17204 net.cpp:165] Memory required for data: 3018920
I0521 18:02:54.353967 17204 layer_factory.hpp:77] Creating layer relu1
I0521 18:02:54.353982 17204 net.cpp:106] Creating Layer relu1
I0521 18:02:54.353992 17204 net.cpp:454] relu1 <- conv1
I0521 18:02:54.354006 17204 net.cpp:397] relu1 -> conv1 (in-place)
I0521 18:02:54.354513 17204 net.cpp:150] Setting up relu1
I0521 18:02:54.354529 17204 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 18:02:54.354539 17204 net.cpp:165] Memory required for data: 5783720
I0521 18:02:54.354549 17204 layer_factory.hpp:77] Creating layer pool1
I0521 18:02:54.354565 17204 net.cpp:106] Creating Layer pool1
I0521 18:02:54.354576 17204 net.cpp:454] pool1 <- conv1
I0521 18:02:54.354589 17204 net.cpp:411] pool1 -> pool1
I0521 18:02:54.354665 17204 net.cpp:150] Setting up pool1
I0521 18:02:54.354677 17204 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 18:02:54.354687 17204 net.cpp:165] Memory required for data: 7166120
I0521 18:02:54.354697 17204 layer_factory.hpp:77] Creating layer conv2
I0521 18:02:54.354714 17204 net.cpp:106] Creating Layer conv2
I0521 18:02:54.354725 17204 net.cpp:454] conv2 <- pool1
I0521 18:02:54.354738 17204 net.cpp:411] conv2 -> conv2
I0521 18:02:54.356653 17204 net.cpp:150] Setting up conv2
I0521 18:02:54.356675 17204 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 18:02:54.356688 17204 net.cpp:165] Memory required for data: 9153320
I0521 18:02:54.356705 17204 layer_factory.hpp:77] Creating layer relu2
I0521 18:02:54.356719 17204 net.cpp:106] Creating Layer relu2
I0521 18:02:54.356729 17204 net.cpp:454] relu2 <- conv2
I0521 18:02:54.356741 17204 net.cpp:397] relu2 -> conv2 (in-place)
I0521 18:02:54.357077 17204 net.cpp:150] Setting up relu2
I0521 18:02:54.357091 17204 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 18:02:54.357101 17204 net.cpp:165] Memory required for data: 11140520
I0521 18:02:54.357111 17204 layer_factory.hpp:77] Creating layer pool2
I0521 18:02:54.357125 17204 net.cpp:106] Creating Layer pool2
I0521 18:02:54.357134 17204 net.cpp:454] pool2 <- conv2
I0521 18:02:54.357146 17204 net.cpp:411] pool2 -> pool2
I0521 18:02:54.357219 17204 net.cpp:150] Setting up pool2
I0521 18:02:54.357233 17204 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 18:02:54.357242 17204 net.cpp:165] Memory required for data: 12134120
I0521 18:02:54.357252 17204 layer_factory.hpp:77] Creating layer conv3
I0521 18:02:54.357271 17204 net.cpp:106] Creating Layer conv3
I0521 18:02:54.357282 17204 net.cpp:454] conv3 <- pool2
I0521 18:02:54.357296 17204 net.cpp:411] conv3 -> conv3
I0521 18:02:54.359298 17204 net.cpp:150] Setting up conv3
I0521 18:02:54.359321 17204 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 18:02:54.359333 17204 net.cpp:165] Memory required for data: 13218280
I0521 18:02:54.359351 17204 layer_factory.hpp:77] Creating layer relu3
I0521 18:02:54.359377 17204 net.cpp:106] Creating Layer relu3
I0521 18:02:54.359388 17204 net.cpp:454] relu3 <- conv3
I0521 18:02:54.359402 17204 net.cpp:397] relu3 -> conv3 (in-place)
I0521 18:02:54.359880 17204 net.cpp:150] Setting up relu3
I0521 18:02:54.359896 17204 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 18:02:54.359906 17204 net.cpp:165] Memory required for data: 14302440
I0521 18:02:54.359916 17204 layer_factory.hpp:77] Creating layer pool3
I0521 18:02:54.359930 17204 net.cpp:106] Creating Layer pool3
I0521 18:02:54.359941 17204 net.cpp:454] pool3 <- conv3
I0521 18:02:54.359953 17204 net.cpp:411] pool3 -> pool3
I0521 18:02:54.360025 17204 net.cpp:150] Setting up pool3
I0521 18:02:54.360038 17204 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 18:02:54.360049 17204 net.cpp:165] Memory required for data: 14844520
I0521 18:02:54.360057 17204 layer_factory.hpp:77] Creating layer conv4
I0521 18:02:54.360075 17204 net.cpp:106] Creating Layer conv4
I0521 18:02:54.360085 17204 net.cpp:454] conv4 <- pool3
I0521 18:02:54.360100 17204 net.cpp:411] conv4 -> conv4
I0521 18:02:54.362160 17204 net.cpp:150] Setting up conv4
I0521 18:02:54.362182 17204 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 18:02:54.362195 17204 net.cpp:165] Memory required for data: 15207400
I0521 18:02:54.362210 17204 layer_factory.hpp:77] Creating layer relu4
I0521 18:02:54.362223 17204 net.cpp:106] Creating Layer relu4
I0521 18:02:54.362233 17204 net.cpp:454] relu4 <- conv4
I0521 18:02:54.362246 17204 net.cpp:397] relu4 -> conv4 (in-place)
I0521 18:02:54.362711 17204 net.cpp:150] Setting up relu4
I0521 18:02:54.362727 17204 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 18:02:54.362737 17204 net.cpp:165] Memory required for data: 15570280
I0521 18:02:54.362747 17204 layer_factory.hpp:77] Creating layer pool4
I0521 18:02:54.362761 17204 net.cpp:106] Creating Layer pool4
I0521 18:02:54.362771 17204 net.cpp:454] pool4 <- conv4
I0521 18:02:54.362784 17204 net.cpp:411] pool4 -> pool4
I0521 18:02:54.362855 17204 net.cpp:150] Setting up pool4
I0521 18:02:54.362869 17204 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 18:02:54.362879 17204 net.cpp:165] Memory required for data: 15751720
I0521 18:02:54.362886 17204 layer_factory.hpp:77] Creating layer ip1
I0521 18:02:54.362902 17204 net.cpp:106] Creating Layer ip1
I0521 18:02:54.362912 17204 net.cpp:454] ip1 <- pool4
I0521 18:02:54.362926 17204 net.cpp:411] ip1 -> ip1
I0521 18:02:54.378428 17204 net.cpp:150] Setting up ip1
I0521 18:02:54.378458 17204 net.cpp:157] Top shape: 10 196 (1960)
I0521 18:02:54.378468 17204 net.cpp:165] Memory required for data: 15759560
I0521 18:02:54.378490 17204 layer_factory.hpp:77] Creating layer relu5
I0521 18:02:54.378505 17204 net.cpp:106] Creating Layer relu5
I0521 18:02:54.378515 17204 net.cpp:454] relu5 <- ip1
I0521 18:02:54.378528 17204 net.cpp:397] relu5 -> ip1 (in-place)
I0521 18:02:54.378878 17204 net.cpp:150] Setting up relu5
I0521 18:02:54.378892 17204 net.cpp:157] Top shape: 10 196 (1960)
I0521 18:02:54.378903 17204 net.cpp:165] Memory required for data: 15767400
I0521 18:02:54.378913 17204 layer_factory.hpp:77] Creating layer drop1
I0521 18:02:54.378931 17204 net.cpp:106] Creating Layer drop1
I0521 18:02:54.378942 17204 net.cpp:454] drop1 <- ip1
I0521 18:02:54.378954 17204 net.cpp:397] drop1 -> ip1 (in-place)
I0521 18:02:54.379000 17204 net.cpp:150] Setting up drop1
I0521 18:02:54.379014 17204 net.cpp:157] Top shape: 10 196 (1960)
I0521 18:02:54.379024 17204 net.cpp:165] Memory required for data: 15775240
I0521 18:02:54.379032 17204 layer_factory.hpp:77] Creating layer ip2
I0521 18:02:54.379047 17204 net.cpp:106] Creating Layer ip2
I0521 18:02:54.379056 17204 net.cpp:454] ip2 <- ip1
I0521 18:02:54.379070 17204 net.cpp:411] ip2 -> ip2
I0521 18:02:54.379549 17204 net.cpp:150] Setting up ip2
I0521 18:02:54.379562 17204 net.cpp:157] Top shape: 10 98 (980)
I0521 18:02:54.379572 17204 net.cpp:165] Memory required for data: 15779160
I0521 18:02:54.379588 17204 layer_factory.hpp:77] Creating layer relu6
I0521 18:02:54.379613 17204 net.cpp:106] Creating Layer relu6
I0521 18:02:54.379623 17204 net.cpp:454] relu6 <- ip2
I0521 18:02:54.379637 17204 net.cpp:397] relu6 -> ip2 (in-place)
I0521 18:02:54.380182 17204 net.cpp:150] Setting up relu6
I0521 18:02:54.380203 17204 net.cpp:157] Top shape: 10 98 (980)
I0521 18:02:54.380213 17204 net.cpp:165] Memory required for data: 15783080
I0521 18:02:54.380223 17204 layer_factory.hpp:77] Creating layer drop2
I0521 18:02:54.380237 17204 net.cpp:106] Creating Layer drop2
I0521 18:02:54.380249 17204 net.cpp:454] drop2 <- ip2
I0521 18:02:54.380261 17204 net.cpp:397] drop2 -> ip2 (in-place)
I0521 18:02:54.380306 17204 net.cpp:150] Setting up drop2
I0521 18:02:54.380318 17204 net.cpp:157] Top shape: 10 98 (980)
I0521 18:02:54.380329 17204 net.cpp:165] Memory required for data: 15787000
I0521 18:02:54.380339 17204 layer_factory.hpp:77] Creating layer ip3
I0521 18:02:54.380353 17204 net.cpp:106] Creating Layer ip3
I0521 18:02:54.380364 17204 net.cpp:454] ip3 <- ip2
I0521 18:02:54.380378 17204 net.cpp:411] ip3 -> ip3
I0521 18:02:54.380599 17204 net.cpp:150] Setting up ip3
I0521 18:02:54.380611 17204 net.cpp:157] Top shape: 10 11 (110)
I0521 18:02:54.380621 17204 net.cpp:165] Memory required for data: 15787440
I0521 18:02:54.380636 17204 layer_factory.hpp:77] Creating layer drop3
I0521 18:02:54.380650 17204 net.cpp:106] Creating Layer drop3
I0521 18:02:54.380659 17204 net.cpp:454] drop3 <- ip3
I0521 18:02:54.380672 17204 net.cpp:397] drop3 -> ip3 (in-place)
I0521 18:02:54.380713 17204 net.cpp:150] Setting up drop3
I0521 18:02:54.380727 17204 net.cpp:157] Top shape: 10 11 (110)
I0521 18:02:54.380736 17204 net.cpp:165] Memory required for data: 15787880
I0521 18:02:54.380745 17204 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 18:02:54.380759 17204 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 18:02:54.380769 17204 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 18:02:54.380782 17204 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 18:02:54.380796 17204 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 18:02:54.380870 17204 net.cpp:150] Setting up ip3_drop3_0_split
I0521 18:02:54.380883 17204 net.cpp:157] Top shape: 10 11 (110)
I0521 18:02:54.380895 17204 net.cpp:157] Top shape: 10 11 (110)
I0521 18:02:54.380905 17204 net.cpp:165] Memory required for data: 15788760
I0521 18:02:54.380915 17204 layer_factory.hpp:77] Creating layer accuracy
I0521 18:02:54.380936 17204 net.cpp:106] Creating Layer accuracy
I0521 18:02:54.380946 17204 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 18:02:54.380957 17204 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 18:02:54.380971 17204 net.cpp:411] accuracy -> accuracy
I0521 18:02:54.380996 17204 net.cpp:150] Setting up accuracy
I0521 18:02:54.381008 17204 net.cpp:157] Top shape: (1)
I0521 18:02:54.381018 17204 net.cpp:165] Memory required for data: 15788764
I0521 18:02:54.381028 17204 layer_factory.hpp:77] Creating layer loss
I0521 18:02:54.381042 17204 net.cpp:106] Creating Layer loss
I0521 18:02:54.381052 17204 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 18:02:54.381063 17204 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 18:02:54.381077 17204 net.cpp:411] loss -> loss
I0521 18:02:54.381093 17204 layer_factory.hpp:77] Creating layer loss
I0521 18:02:54.381580 17204 net.cpp:150] Setting up loss
I0521 18:02:54.381594 17204 net.cpp:157] Top shape: (1)
I0521 18:02:54.381605 17204 net.cpp:160]     with loss weight 1
I0521 18:02:54.381623 17204 net.cpp:165] Memory required for data: 15788768
I0521 18:02:54.381633 17204 net.cpp:226] loss needs backward computation.
I0521 18:02:54.381644 17204 net.cpp:228] accuracy does not need backward computation.
I0521 18:02:54.381656 17204 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 18:02:54.381666 17204 net.cpp:226] drop3 needs backward computation.
I0521 18:02:54.381677 17204 net.cpp:226] ip3 needs backward computation.
I0521 18:02:54.381687 17204 net.cpp:226] drop2 needs backward computation.
I0521 18:02:54.381697 17204 net.cpp:226] relu6 needs backward computation.
I0521 18:02:54.381716 17204 net.cpp:226] ip2 needs backward computation.
I0521 18:02:54.381726 17204 net.cpp:226] drop1 needs backward computation.
I0521 18:02:54.381736 17204 net.cpp:226] relu5 needs backward computation.
I0521 18:02:54.381745 17204 net.cpp:226] ip1 needs backward computation.
I0521 18:02:54.381755 17204 net.cpp:226] pool4 needs backward computation.
I0521 18:02:54.381765 17204 net.cpp:226] relu4 needs backward computation.
I0521 18:02:54.381775 17204 net.cpp:226] conv4 needs backward computation.
I0521 18:02:54.381786 17204 net.cpp:226] pool3 needs backward computation.
I0521 18:02:54.381796 17204 net.cpp:226] relu3 needs backward computation.
I0521 18:02:54.381808 17204 net.cpp:226] conv3 needs backward computation.
I0521 18:02:54.381817 17204 net.cpp:226] pool2 needs backward computation.
I0521 18:02:54.381827 17204 net.cpp:226] relu2 needs backward computation.
I0521 18:02:54.381837 17204 net.cpp:226] conv2 needs backward computation.
I0521 18:02:54.381849 17204 net.cpp:226] pool1 needs backward computation.
I0521 18:02:54.381858 17204 net.cpp:226] relu1 needs backward computation.
I0521 18:02:54.381867 17204 net.cpp:226] conv1 needs backward computation.
I0521 18:02:54.381880 17204 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 18:02:54.381891 17204 net.cpp:228] data_hdf5 does not need backward computation.
I0521 18:02:54.381901 17204 net.cpp:270] This network produces output accuracy
I0521 18:02:54.381913 17204 net.cpp:270] This network produces output loss
I0521 18:02:54.381942 17204 net.cpp:283] Network initialization done.
I0521 18:02:54.382076 17204 solver.cpp:60] Solver scaffolding done.
I0521 18:02:54.383218 17204 caffe.cpp:212] Starting Optimization
I0521 18:02:54.383235 17204 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 18:02:54.383249 17204 solver.cpp:289] Learning Rate Policy: fixed
I0521 18:02:54.384320 17204 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 18:03:54.813206 17204 solver.cpp:409]     Test net output #0: accuracy = 0.0492591
I0521 18:03:54.813369 17204 solver.cpp:409]     Test net output #1: loss = 2.39944 (* 1 = 2.39944 loss)
I0521 18:03:54.831099 17204 solver.cpp:237] Iteration 0, loss = 2.40501
I0521 18:03:54.831136 17204 solver.cpp:253]     Train net output #0: loss = 2.40501 (* 1 = 2.40501 loss)
I0521 18:03:54.831154 17204 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0521 18:04:11.609025 17204 solver.cpp:237] Iteration 1500, loss = 2.46493
I0521 18:04:11.609073 17204 solver.cpp:253]     Train net output #0: loss = 2.46493 (* 1 = 2.46493 loss)
I0521 18:04:11.609091 17204 sgd_solver.cpp:106] Iteration 1500, lr = 0.0045
I0521 18:04:28.377342 17204 solver.cpp:237] Iteration 3000, loss = 1.87349
I0521 18:04:28.377492 17204 solver.cpp:253]     Train net output #0: loss = 1.87349 (* 1 = 1.87349 loss)
I0521 18:04:28.377508 17204 sgd_solver.cpp:106] Iteration 3000, lr = 0.0045
I0521 18:04:45.166153 17204 solver.cpp:237] Iteration 4500, loss = 1.29455
I0521 18:04:45.166200 17204 solver.cpp:253]     Train net output #0: loss = 1.29455 (* 1 = 1.29455 loss)
I0521 18:04:45.166213 17204 sgd_solver.cpp:106] Iteration 4500, lr = 0.0045
I0521 18:05:01.906972 17204 solver.cpp:237] Iteration 6000, loss = 1.03031
I0521 18:05:01.907127 17204 solver.cpp:253]     Train net output #0: loss = 1.03031 (* 1 = 1.03031 loss)
I0521 18:05:01.907142 17204 sgd_solver.cpp:106] Iteration 6000, lr = 0.0045
I0521 18:05:18.536113 17204 solver.cpp:237] Iteration 7500, loss = 1.19619
I0521 18:05:18.536149 17204 solver.cpp:253]     Train net output #0: loss = 1.19619 (* 1 = 1.19619 loss)
I0521 18:05:18.536164 17204 sgd_solver.cpp:106] Iteration 7500, lr = 0.0045
I0521 18:05:35.184289 17204 solver.cpp:237] Iteration 9000, loss = 1.32263
I0521 18:05:35.184443 17204 solver.cpp:253]     Train net output #0: loss = 1.32263 (* 1 = 1.32263 loss)
I0521 18:05:35.184458 17204 sgd_solver.cpp:106] Iteration 9000, lr = 0.0045
I0521 18:06:13.929042 17204 solver.cpp:237] Iteration 10500, loss = 1.59161
I0521 18:06:13.929203 17204 solver.cpp:253]     Train net output #0: loss = 1.5916 (* 1 = 1.5916 loss)
I0521 18:06:13.929217 17204 sgd_solver.cpp:106] Iteration 10500, lr = 0.0045
I0521 18:06:30.530586 17204 solver.cpp:237] Iteration 12000, loss = 1.65782
I0521 18:06:30.530622 17204 solver.cpp:253]     Train net output #0: loss = 1.65782 (* 1 = 1.65782 loss)
I0521 18:06:30.530638 17204 sgd_solver.cpp:106] Iteration 12000, lr = 0.0045
I0521 18:06:47.138378 17204 solver.cpp:237] Iteration 13500, loss = 1.26456
I0521 18:06:47.138530 17204 solver.cpp:253]     Train net output #0: loss = 1.26456 (* 1 = 1.26456 loss)
I0521 18:06:47.138545 17204 sgd_solver.cpp:106] Iteration 13500, lr = 0.0045
I0521 18:07:03.795574 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_15000.caffemodel
I0521 18:07:03.844972 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_15000.solverstate
I0521 18:07:03.873477 17204 solver.cpp:237] Iteration 15000, loss = 0.488692
I0521 18:07:03.873524 17204 solver.cpp:253]     Train net output #0: loss = 0.488692 (* 1 = 0.488692 loss)
I0521 18:07:03.873539 17204 sgd_solver.cpp:106] Iteration 15000, lr = 0.0045
I0521 18:07:20.551731 17204 solver.cpp:237] Iteration 16500, loss = 1.14201
I0521 18:07:20.551877 17204 solver.cpp:253]     Train net output #0: loss = 1.14201 (* 1 = 1.14201 loss)
I0521 18:07:20.551893 17204 sgd_solver.cpp:106] Iteration 16500, lr = 0.0045
I0521 18:07:37.515957 17204 solver.cpp:237] Iteration 18000, loss = 1.59822
I0521 18:07:37.516005 17204 solver.cpp:253]     Train net output #0: loss = 1.59822 (* 1 = 1.59822 loss)
I0521 18:07:37.516021 17204 sgd_solver.cpp:106] Iteration 18000, lr = 0.0045
I0521 18:07:54.450413 17204 solver.cpp:237] Iteration 19500, loss = 0.655748
I0521 18:07:54.450563 17204 solver.cpp:253]     Train net output #0: loss = 0.655748 (* 1 = 0.655748 loss)
I0521 18:07:54.450578 17204 sgd_solver.cpp:106] Iteration 19500, lr = 0.0045
I0521 18:08:33.598743 17204 solver.cpp:237] Iteration 21000, loss = 1.64572
I0521 18:08:33.598906 17204 solver.cpp:253]     Train net output #0: loss = 1.64572 (* 1 = 1.64572 loss)
I0521 18:08:33.598919 17204 sgd_solver.cpp:106] Iteration 21000, lr = 0.0045
I0521 18:08:50.472836 17204 solver.cpp:237] Iteration 22500, loss = 1.03416
I0521 18:08:50.472885 17204 solver.cpp:253]     Train net output #0: loss = 1.03416 (* 1 = 1.03416 loss)
I0521 18:08:50.472899 17204 sgd_solver.cpp:106] Iteration 22500, lr = 0.0045
I0521 18:09:07.259685 17204 solver.cpp:237] Iteration 24000, loss = 1.71234
I0521 18:09:07.259855 17204 solver.cpp:253]     Train net output #0: loss = 1.71234 (* 1 = 1.71234 loss)
I0521 18:09:07.259870 17204 sgd_solver.cpp:106] Iteration 24000, lr = 0.0045
I0521 18:09:24.035236 17204 solver.cpp:237] Iteration 25500, loss = 1.80867
I0521 18:09:24.035274 17204 solver.cpp:253]     Train net output #0: loss = 1.80867 (* 1 = 1.80867 loss)
I0521 18:09:24.035291 17204 sgd_solver.cpp:106] Iteration 25500, lr = 0.0045
I0521 18:09:40.793958 17204 solver.cpp:237] Iteration 27000, loss = 1.55503
I0521 18:09:40.794106 17204 solver.cpp:253]     Train net output #0: loss = 1.55502 (* 1 = 1.55502 loss)
I0521 18:09:40.794121 17204 sgd_solver.cpp:106] Iteration 27000, lr = 0.0045
I0521 18:09:57.536294 17204 solver.cpp:237] Iteration 28500, loss = 3.56362
I0521 18:09:57.536339 17204 solver.cpp:253]     Train net output #0: loss = 3.56362 (* 1 = 3.56362 loss)
I0521 18:09:57.536355 17204 sgd_solver.cpp:106] Iteration 28500, lr = 0.0045
I0521 18:10:14.310449 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_30000.caffemodel
I0521 18:10:14.355906 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_30000.solverstate
I0521 18:10:14.382189 17204 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 18:11:13.533377 17204 solver.cpp:409]     Test net output #0: accuracy = 0.846378
I0521 18:11:13.533535 17204 solver.cpp:409]     Test net output #1: loss = 0.510649 (* 1 = 0.510649 loss)
I0521 18:11:35.647271 17204 solver.cpp:237] Iteration 30000, loss = 1.5654
I0521 18:11:35.647325 17204 solver.cpp:253]     Train net output #0: loss = 1.5654 (* 1 = 1.5654 loss)
I0521 18:11:35.647339 17204 sgd_solver.cpp:106] Iteration 30000, lr = 0.0045
I0521 18:11:52.603444 17204 solver.cpp:237] Iteration 31500, loss = 0.765459
I0521 18:11:52.603601 17204 solver.cpp:253]     Train net output #0: loss = 0.765456 (* 1 = 0.765456 loss)
I0521 18:11:52.603616 17204 sgd_solver.cpp:106] Iteration 31500, lr = 0.0045
I0521 18:12:09.596688 17204 solver.cpp:237] Iteration 33000, loss = 1.16019
I0521 18:12:09.596736 17204 solver.cpp:253]     Train net output #0: loss = 1.16019 (* 1 = 1.16019 loss)
I0521 18:12:09.596750 17204 sgd_solver.cpp:106] Iteration 33000, lr = 0.0045
I0521 18:12:26.571859 17204 solver.cpp:237] Iteration 34500, loss = 1.68163
I0521 18:12:26.572011 17204 solver.cpp:253]     Train net output #0: loss = 1.68162 (* 1 = 1.68162 loss)
I0521 18:12:26.572026 17204 sgd_solver.cpp:106] Iteration 34500, lr = 0.0045
I0521 18:12:43.557891 17204 solver.cpp:237] Iteration 36000, loss = 1.00892
I0521 18:12:43.557929 17204 solver.cpp:253]     Train net output #0: loss = 1.00892 (* 1 = 1.00892 loss)
I0521 18:12:43.557945 17204 sgd_solver.cpp:106] Iteration 36000, lr = 0.0045
I0521 18:13:00.515394 17204 solver.cpp:237] Iteration 37500, loss = 1.35639
I0521 18:13:00.515549 17204 solver.cpp:253]     Train net output #0: loss = 1.35639 (* 1 = 1.35639 loss)
I0521 18:13:00.515564 17204 sgd_solver.cpp:106] Iteration 37500, lr = 0.0045
I0521 18:13:17.477579 17204 solver.cpp:237] Iteration 39000, loss = 1.66661
I0521 18:13:17.477619 17204 solver.cpp:253]     Train net output #0: loss = 1.6666 (* 1 = 1.6666 loss)
I0521 18:13:17.477640 17204 sgd_solver.cpp:106] Iteration 39000, lr = 0.0045
I0521 18:13:56.643941 17204 solver.cpp:237] Iteration 40500, loss = 1.48163
I0521 18:13:56.644106 17204 solver.cpp:253]     Train net output #0: loss = 1.48163 (* 1 = 1.48163 loss)
I0521 18:13:56.644121 17204 sgd_solver.cpp:106] Iteration 40500, lr = 0.0045
I0521 18:14:13.645308 17204 solver.cpp:237] Iteration 42000, loss = 0.802151
I0521 18:14:13.645354 17204 solver.cpp:253]     Train net output #0: loss = 0.80215 (* 1 = 0.80215 loss)
I0521 18:14:13.645370 17204 sgd_solver.cpp:106] Iteration 42000, lr = 0.0045
I0521 18:14:30.617911 17204 solver.cpp:237] Iteration 43500, loss = 1.23216
I0521 18:14:30.618059 17204 solver.cpp:253]     Train net output #0: loss = 1.23216 (* 1 = 1.23216 loss)
I0521 18:14:30.618073 17204 sgd_solver.cpp:106] Iteration 43500, lr = 0.0045
I0521 18:14:47.573730 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_45000.caffemodel
I0521 18:14:47.622087 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_45000.solverstate
I0521 18:14:47.654197 17204 solver.cpp:237] Iteration 45000, loss = 0.861604
I0521 18:14:47.654248 17204 solver.cpp:253]     Train net output #0: loss = 0.861602 (* 1 = 0.861602 loss)
I0521 18:14:47.654261 17204 sgd_solver.cpp:106] Iteration 45000, lr = 0.0045
I0521 18:15:04.602092 17204 solver.cpp:237] Iteration 46500, loss = 0.520372
I0521 18:15:04.602252 17204 solver.cpp:253]     Train net output #0: loss = 0.52037 (* 1 = 0.52037 loss)
I0521 18:15:04.602268 17204 sgd_solver.cpp:106] Iteration 46500, lr = 0.0045
I0521 18:15:21.558830 17204 solver.cpp:237] Iteration 48000, loss = 0.645029
I0521 18:15:21.558874 17204 solver.cpp:253]     Train net output #0: loss = 0.645028 (* 1 = 0.645028 loss)
I0521 18:15:21.558889 17204 sgd_solver.cpp:106] Iteration 48000, lr = 0.0045
I0521 18:15:38.513408 17204 solver.cpp:237] Iteration 49500, loss = 1.06953
I0521 18:15:38.513550 17204 solver.cpp:253]     Train net output #0: loss = 1.06952 (* 1 = 1.06952 loss)
I0521 18:15:38.513563 17204 sgd_solver.cpp:106] Iteration 49500, lr = 0.0045
I0521 18:16:17.723584 17204 solver.cpp:237] Iteration 51000, loss = 1.66539
I0521 18:16:17.723762 17204 solver.cpp:253]     Train net output #0: loss = 1.66539 (* 1 = 1.66539 loss)
I0521 18:16:17.723778 17204 sgd_solver.cpp:106] Iteration 51000, lr = 0.0045
I0521 18:16:34.701083 17204 solver.cpp:237] Iteration 52500, loss = 1.36353
I0521 18:16:34.701119 17204 solver.cpp:253]     Train net output #0: loss = 1.36353 (* 1 = 1.36353 loss)
I0521 18:16:34.701135 17204 sgd_solver.cpp:106] Iteration 52500, lr = 0.0045
I0521 18:16:51.674677 17204 solver.cpp:237] Iteration 54000, loss = 1.4228
I0521 18:16:51.674828 17204 solver.cpp:253]     Train net output #0: loss = 1.4228 (* 1 = 1.4228 loss)
I0521 18:16:51.674841 17204 sgd_solver.cpp:106] Iteration 54000, lr = 0.0045
I0521 18:17:08.585412 17204 solver.cpp:237] Iteration 55500, loss = 0.870014
I0521 18:17:08.585458 17204 solver.cpp:253]     Train net output #0: loss = 0.870012 (* 1 = 0.870012 loss)
I0521 18:17:08.585471 17204 sgd_solver.cpp:106] Iteration 55500, lr = 0.0045
I0521 18:17:25.562535 17204 solver.cpp:237] Iteration 57000, loss = 1.10304
I0521 18:17:25.562674 17204 solver.cpp:253]     Train net output #0: loss = 1.10304 (* 1 = 1.10304 loss)
I0521 18:17:25.562688 17204 sgd_solver.cpp:106] Iteration 57000, lr = 0.0045
I0521 18:17:42.513540 17204 solver.cpp:237] Iteration 58500, loss = 1.23064
I0521 18:17:42.513581 17204 solver.cpp:253]     Train net output #0: loss = 1.23064 (* 1 = 1.23064 loss)
I0521 18:17:42.513597 17204 sgd_solver.cpp:106] Iteration 58500, lr = 0.0045
I0521 18:17:59.451505 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_60000.caffemodel
I0521 18:17:59.499760 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_60000.solverstate
I0521 18:17:59.528229 17204 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 18:19:19.868227 17204 solver.cpp:409]     Test net output #0: accuracy = 0.85454
I0521 18:19:19.868399 17204 solver.cpp:409]     Test net output #1: loss = 0.491863 (* 1 = 0.491863 loss)
I0521 18:19:42.091763 17204 solver.cpp:237] Iteration 60000, loss = 1.38283
I0521 18:19:42.091814 17204 solver.cpp:253]     Train net output #0: loss = 1.38283 (* 1 = 1.38283 loss)
I0521 18:19:42.091832 17204 sgd_solver.cpp:106] Iteration 60000, lr = 0.0045
I0521 18:19:59.291455 17204 solver.cpp:237] Iteration 61500, loss = 0.819359
I0521 18:19:59.291621 17204 solver.cpp:253]     Train net output #0: loss = 0.819359 (* 1 = 0.819359 loss)
I0521 18:19:59.291635 17204 sgd_solver.cpp:106] Iteration 61500, lr = 0.0045
I0521 18:20:16.482506 17204 solver.cpp:237] Iteration 63000, loss = 1.24162
I0521 18:20:16.482543 17204 solver.cpp:253]     Train net output #0: loss = 1.24162 (* 1 = 1.24162 loss)
I0521 18:20:16.482556 17204 sgd_solver.cpp:106] Iteration 63000, lr = 0.0045
I0521 18:20:33.697679 17204 solver.cpp:237] Iteration 64500, loss = 1.17119
I0521 18:20:33.697832 17204 solver.cpp:253]     Train net output #0: loss = 1.17119 (* 1 = 1.17119 loss)
I0521 18:20:33.697846 17204 sgd_solver.cpp:106] Iteration 64500, lr = 0.0045
I0521 18:20:50.902603 17204 solver.cpp:237] Iteration 66000, loss = 1.10417
I0521 18:20:50.902645 17204 solver.cpp:253]     Train net output #0: loss = 1.10417 (* 1 = 1.10417 loss)
I0521 18:20:50.902662 17204 sgd_solver.cpp:106] Iteration 66000, lr = 0.0045
I0521 18:21:08.075062 17204 solver.cpp:237] Iteration 67500, loss = 0.612251
I0521 18:21:08.075212 17204 solver.cpp:253]     Train net output #0: loss = 0.612251 (* 1 = 0.612251 loss)
I0521 18:21:08.075224 17204 sgd_solver.cpp:106] Iteration 67500, lr = 0.0045
I0521 18:21:25.235810 17204 solver.cpp:237] Iteration 69000, loss = 0.823526
I0521 18:21:25.235859 17204 solver.cpp:253]     Train net output #0: loss = 0.823526 (* 1 = 0.823526 loss)
I0521 18:21:25.235874 17204 sgd_solver.cpp:106] Iteration 69000, lr = 0.0045
I0521 18:22:04.585285 17204 solver.cpp:237] Iteration 70500, loss = 1.48637
I0521 18:22:04.585451 17204 solver.cpp:253]     Train net output #0: loss = 1.48637 (* 1 = 1.48637 loss)
I0521 18:22:04.585465 17204 sgd_solver.cpp:106] Iteration 70500, lr = 0.0045
I0521 18:22:21.783928 17204 solver.cpp:237] Iteration 72000, loss = 1.04284
I0521 18:22:21.783964 17204 solver.cpp:253]     Train net output #0: loss = 1.04284 (* 1 = 1.04284 loss)
I0521 18:22:21.783977 17204 sgd_solver.cpp:106] Iteration 72000, lr = 0.0045
I0521 18:22:38.942033 17204 solver.cpp:237] Iteration 73500, loss = 1.03109
I0521 18:22:38.942188 17204 solver.cpp:253]     Train net output #0: loss = 1.03109 (* 1 = 1.03109 loss)
I0521 18:22:38.942203 17204 sgd_solver.cpp:106] Iteration 73500, lr = 0.0045
I0521 18:22:56.092172 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_75000.caffemodel
I0521 18:22:56.139840 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_75000.solverstate
I0521 18:22:56.171903 17204 solver.cpp:237] Iteration 75000, loss = 1.08977
I0521 18:22:56.171949 17204 solver.cpp:253]     Train net output #0: loss = 1.08977 (* 1 = 1.08977 loss)
I0521 18:22:56.171965 17204 sgd_solver.cpp:106] Iteration 75000, lr = 0.0045
I0521 18:23:13.352648 17204 solver.cpp:237] Iteration 76500, loss = 1.48279
I0521 18:23:13.352797 17204 solver.cpp:253]     Train net output #0: loss = 1.48279 (* 1 = 1.48279 loss)
I0521 18:23:13.352810 17204 sgd_solver.cpp:106] Iteration 76500, lr = 0.0045
I0521 18:23:30.506916 17204 solver.cpp:237] Iteration 78000, loss = 1.12453
I0521 18:23:30.506968 17204 solver.cpp:253]     Train net output #0: loss = 1.12453 (* 1 = 1.12453 loss)
I0521 18:23:30.506981 17204 sgd_solver.cpp:106] Iteration 78000, lr = 0.0045
I0521 18:23:47.685012 17204 solver.cpp:237] Iteration 79500, loss = 1.43855
I0521 18:23:47.685170 17204 solver.cpp:253]     Train net output #0: loss = 1.43855 (* 1 = 1.43855 loss)
I0521 18:23:47.685185 17204 sgd_solver.cpp:106] Iteration 79500, lr = 0.0045
I0521 18:24:27.016974 17204 solver.cpp:237] Iteration 81000, loss = 0.735501
I0521 18:24:27.017150 17204 solver.cpp:253]     Train net output #0: loss = 0.735502 (* 1 = 0.735502 loss)
I0521 18:24:27.017165 17204 sgd_solver.cpp:106] Iteration 81000, lr = 0.0045
I0521 18:24:44.155691 17204 solver.cpp:237] Iteration 82500, loss = 1.00021
I0521 18:24:44.155740 17204 solver.cpp:253]     Train net output #0: loss = 1.00021 (* 1 = 1.00021 loss)
I0521 18:24:44.155757 17204 sgd_solver.cpp:106] Iteration 82500, lr = 0.0045
I0521 18:25:01.307062 17204 solver.cpp:237] Iteration 84000, loss = 0.948325
I0521 18:25:01.307221 17204 solver.cpp:253]     Train net output #0: loss = 0.948327 (* 1 = 0.948327 loss)
I0521 18:25:01.307235 17204 sgd_solver.cpp:106] Iteration 84000, lr = 0.0045
I0521 18:25:18.477205 17204 solver.cpp:237] Iteration 85500, loss = 1.46513
I0521 18:25:18.477242 17204 solver.cpp:253]     Train net output #0: loss = 1.46514 (* 1 = 1.46514 loss)
I0521 18:25:18.477255 17204 sgd_solver.cpp:106] Iteration 85500, lr = 0.0045
I0521 18:25:35.625622 17204 solver.cpp:237] Iteration 87000, loss = 1.01897
I0521 18:25:35.625777 17204 solver.cpp:253]     Train net output #0: loss = 1.01898 (* 1 = 1.01898 loss)
I0521 18:25:35.625792 17204 sgd_solver.cpp:106] Iteration 87000, lr = 0.0045
I0521 18:25:52.877507 17204 solver.cpp:237] Iteration 88500, loss = 0.929863
I0521 18:25:52.877550 17204 solver.cpp:253]     Train net output #0: loss = 0.929865 (* 1 = 0.929865 loss)
I0521 18:25:52.877568 17204 sgd_solver.cpp:106] Iteration 88500, lr = 0.0045
I0521 18:26:10.047447 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_90000.caffemodel
I0521 18:26:10.093318 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_90000.solverstate
I0521 18:26:10.119566 17204 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 18:27:09.029464 17204 solver.cpp:409]     Test net output #0: accuracy = 0.863296
I0521 18:27:09.029624 17204 solver.cpp:409]     Test net output #1: loss = 0.473755 (* 1 = 0.473755 loss)
I0521 18:27:31.236199 17204 solver.cpp:237] Iteration 90000, loss = 1.24412
I0521 18:27:31.236249 17204 solver.cpp:253]     Train net output #0: loss = 1.24412 (* 1 = 1.24412 loss)
I0521 18:27:31.236268 17204 sgd_solver.cpp:106] Iteration 90000, lr = 0.0045
I0521 18:27:48.196959 17204 solver.cpp:237] Iteration 91500, loss = 0.799091
I0521 18:27:48.197114 17204 solver.cpp:253]     Train net output #0: loss = 0.799093 (* 1 = 0.799093 loss)
I0521 18:27:48.197129 17204 sgd_solver.cpp:106] Iteration 91500, lr = 0.0045
I0521 18:28:05.136071 17204 solver.cpp:237] Iteration 93000, loss = 1.44121
I0521 18:28:05.136116 17204 solver.cpp:253]     Train net output #0: loss = 1.44121 (* 1 = 1.44121 loss)
I0521 18:28:05.136133 17204 sgd_solver.cpp:106] Iteration 93000, lr = 0.0045
I0521 18:28:22.088824 17204 solver.cpp:237] Iteration 94500, loss = 1.67302
I0521 18:28:22.088976 17204 solver.cpp:253]     Train net output #0: loss = 1.67302 (* 1 = 1.67302 loss)
I0521 18:28:22.088990 17204 sgd_solver.cpp:106] Iteration 94500, lr = 0.0045
I0521 18:28:39.031806 17204 solver.cpp:237] Iteration 96000, loss = 1.46755
I0521 18:28:39.031841 17204 solver.cpp:253]     Train net output #0: loss = 1.46755 (* 1 = 1.46755 loss)
I0521 18:28:39.031857 17204 sgd_solver.cpp:106] Iteration 96000, lr = 0.0045
I0521 18:28:56.011118 17204 solver.cpp:237] Iteration 97500, loss = 1.08142
I0521 18:28:56.011276 17204 solver.cpp:253]     Train net output #0: loss = 1.08143 (* 1 = 1.08143 loss)
I0521 18:28:56.011292 17204 sgd_solver.cpp:106] Iteration 97500, lr = 0.0045
I0521 18:29:12.999399 17204 solver.cpp:237] Iteration 99000, loss = 0.928803
I0521 18:29:12.999447 17204 solver.cpp:253]     Train net output #0: loss = 0.928806 (* 1 = 0.928806 loss)
I0521 18:29:12.999464 17204 sgd_solver.cpp:106] Iteration 99000, lr = 0.0045
I0521 18:29:52.237259 17204 solver.cpp:237] Iteration 100500, loss = 1.43646
I0521 18:29:52.237427 17204 solver.cpp:253]     Train net output #0: loss = 1.43646 (* 1 = 1.43646 loss)
I0521 18:29:52.237442 17204 sgd_solver.cpp:106] Iteration 100500, lr = 0.0045
I0521 18:30:09.264430 17204 solver.cpp:237] Iteration 102000, loss = 0.754015
I0521 18:30:09.264479 17204 solver.cpp:253]     Train net output #0: loss = 0.754017 (* 1 = 0.754017 loss)
I0521 18:30:09.264493 17204 sgd_solver.cpp:106] Iteration 102000, lr = 0.0045
I0521 18:30:26.316553 17204 solver.cpp:237] Iteration 103500, loss = 1.3396
I0521 18:30:26.316715 17204 solver.cpp:253]     Train net output #0: loss = 1.3396 (* 1 = 1.3396 loss)
I0521 18:30:26.316730 17204 sgd_solver.cpp:106] Iteration 103500, lr = 0.0045
I0521 18:30:43.367971 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_105000.caffemodel
I0521 18:30:43.419113 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_105000.solverstate
I0521 18:30:43.447582 17204 solver.cpp:237] Iteration 105000, loss = 1.77069
I0521 18:30:43.447628 17204 solver.cpp:253]     Train net output #0: loss = 1.77069 (* 1 = 1.77069 loss)
I0521 18:30:43.447641 17204 sgd_solver.cpp:106] Iteration 105000, lr = 0.0045
I0521 18:31:00.478878 17204 solver.cpp:237] Iteration 106500, loss = 1.41367
I0521 18:31:00.479040 17204 solver.cpp:253]     Train net output #0: loss = 1.41367 (* 1 = 1.41367 loss)
I0521 18:31:00.479055 17204 sgd_solver.cpp:106] Iteration 106500, lr = 0.0045
I0521 18:31:17.504541 17204 solver.cpp:237] Iteration 108000, loss = 1.3007
I0521 18:31:17.504583 17204 solver.cpp:253]     Train net output #0: loss = 1.3007 (* 1 = 1.3007 loss)
I0521 18:31:17.504603 17204 sgd_solver.cpp:106] Iteration 108000, lr = 0.0045
I0521 18:31:34.546391 17204 solver.cpp:237] Iteration 109500, loss = 0.588393
I0521 18:31:34.546538 17204 solver.cpp:253]     Train net output #0: loss = 0.588394 (* 1 = 0.588394 loss)
I0521 18:31:34.546552 17204 sgd_solver.cpp:106] Iteration 109500, lr = 0.0045
I0521 18:32:13.762697 17204 solver.cpp:237] Iteration 111000, loss = 1.15404
I0521 18:32:13.762866 17204 solver.cpp:253]     Train net output #0: loss = 1.15404 (* 1 = 1.15404 loss)
I0521 18:32:13.762879 17204 sgd_solver.cpp:106] Iteration 111000, lr = 0.0045
I0521 18:32:30.780568 17204 solver.cpp:237] Iteration 112500, loss = 2.49859
I0521 18:32:30.780611 17204 solver.cpp:253]     Train net output #0: loss = 2.49859 (* 1 = 2.49859 loss)
I0521 18:32:30.780630 17204 sgd_solver.cpp:106] Iteration 112500, lr = 0.0045
I0521 18:32:47.814250 17204 solver.cpp:237] Iteration 114000, loss = 1.89291
I0521 18:32:47.814394 17204 solver.cpp:253]     Train net output #0: loss = 1.89291 (* 1 = 1.89291 loss)
I0521 18:32:47.814409 17204 sgd_solver.cpp:106] Iteration 114000, lr = 0.0045
I0521 18:33:04.849834 17204 solver.cpp:237] Iteration 115500, loss = 1.67268
I0521 18:33:04.849884 17204 solver.cpp:253]     Train net output #0: loss = 1.67269 (* 1 = 1.67269 loss)
I0521 18:33:04.849897 17204 sgd_solver.cpp:106] Iteration 115500, lr = 0.0045
I0521 18:33:21.837980 17204 solver.cpp:237] Iteration 117000, loss = 1.22013
I0521 18:33:21.838134 17204 solver.cpp:253]     Train net output #0: loss = 1.22013 (* 1 = 1.22013 loss)
I0521 18:33:21.838147 17204 sgd_solver.cpp:106] Iteration 117000, lr = 0.0045
I0521 18:33:38.890959 17204 solver.cpp:237] Iteration 118500, loss = 1.55055
I0521 18:33:38.890993 17204 solver.cpp:253]     Train net output #0: loss = 1.55055 (* 1 = 1.55055 loss)
I0521 18:33:38.891010 17204 sgd_solver.cpp:106] Iteration 118500, lr = 0.0045
I0521 18:33:55.905623 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_120000.caffemodel
I0521 18:33:55.951655 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_120000.solverstate
I0521 18:33:55.976713 17204 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 18:35:16.042049 17204 solver.cpp:409]     Test net output #0: accuracy = 0.864783
I0521 18:35:16.042215 17204 solver.cpp:409]     Test net output #1: loss = 0.429489 (* 1 = 0.429489 loss)
I0521 18:35:38.219455 17204 solver.cpp:237] Iteration 120000, loss = 1.31897
I0521 18:35:38.219508 17204 solver.cpp:253]     Train net output #0: loss = 1.31898 (* 1 = 1.31898 loss)
I0521 18:35:38.219523 17204 sgd_solver.cpp:106] Iteration 120000, lr = 0.0045
I0521 18:35:55.001072 17204 solver.cpp:237] Iteration 121500, loss = 1.34279
I0521 18:35:55.001245 17204 solver.cpp:253]     Train net output #0: loss = 1.3428 (* 1 = 1.3428 loss)
I0521 18:35:55.001260 17204 sgd_solver.cpp:106] Iteration 121500, lr = 0.0045
I0521 18:36:11.785511 17204 solver.cpp:237] Iteration 123000, loss = 0.92711
I0521 18:36:11.785558 17204 solver.cpp:253]     Train net output #0: loss = 0.927112 (* 1 = 0.927112 loss)
I0521 18:36:11.785573 17204 sgd_solver.cpp:106] Iteration 123000, lr = 0.0045
I0521 18:36:28.571816 17204 solver.cpp:237] Iteration 124500, loss = 0.908919
I0521 18:36:28.571965 17204 solver.cpp:253]     Train net output #0: loss = 0.908921 (* 1 = 0.908921 loss)
I0521 18:36:28.571979 17204 sgd_solver.cpp:106] Iteration 124500, lr = 0.0045
I0521 18:36:45.359818 17204 solver.cpp:237] Iteration 126000, loss = 1.25466
I0521 18:36:45.359865 17204 solver.cpp:253]     Train net output #0: loss = 1.25467 (* 1 = 1.25467 loss)
I0521 18:36:45.359879 17204 sgd_solver.cpp:106] Iteration 126000, lr = 0.0045
I0521 18:37:02.159108 17204 solver.cpp:237] Iteration 127500, loss = 0.771278
I0521 18:37:02.159272 17204 solver.cpp:253]     Train net output #0: loss = 0.77128 (* 1 = 0.77128 loss)
I0521 18:37:02.159286 17204 sgd_solver.cpp:106] Iteration 127500, lr = 0.0045
I0521 18:37:18.899875 17204 solver.cpp:237] Iteration 129000, loss = 1.48965
I0521 18:37:18.899912 17204 solver.cpp:253]     Train net output #0: loss = 1.48965 (* 1 = 1.48965 loss)
I0521 18:37:18.899926 17204 sgd_solver.cpp:106] Iteration 129000, lr = 0.0045
I0521 18:37:57.836434 17204 solver.cpp:237] Iteration 130500, loss = 1.57974
I0521 18:37:57.836602 17204 solver.cpp:253]     Train net output #0: loss = 1.57974 (* 1 = 1.57974 loss)
I0521 18:37:57.836616 17204 sgd_solver.cpp:106] Iteration 130500, lr = 0.0045
I0521 18:38:14.577142 17204 solver.cpp:237] Iteration 132000, loss = 1.11263
I0521 18:38:14.577178 17204 solver.cpp:253]     Train net output #0: loss = 1.11263 (* 1 = 1.11263 loss)
I0521 18:38:14.577193 17204 sgd_solver.cpp:106] Iteration 132000, lr = 0.0045
I0521 18:38:31.394227 17204 solver.cpp:237] Iteration 133500, loss = 1.30316
I0521 18:38:31.394381 17204 solver.cpp:253]     Train net output #0: loss = 1.30316 (* 1 = 1.30316 loss)
I0521 18:38:31.394393 17204 sgd_solver.cpp:106] Iteration 133500, lr = 0.0045
I0521 18:38:48.165002 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_135000.caffemodel
I0521 18:38:48.212927 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_135000.solverstate
I0521 18:38:48.243800 17204 solver.cpp:237] Iteration 135000, loss = 2.00294
I0521 18:38:48.243850 17204 solver.cpp:253]     Train net output #0: loss = 2.00294 (* 1 = 2.00294 loss)
I0521 18:38:48.243865 17204 sgd_solver.cpp:106] Iteration 135000, lr = 0.0045
I0521 18:39:05.045756 17204 solver.cpp:237] Iteration 136500, loss = 1.05297
I0521 18:39:05.045909 17204 solver.cpp:253]     Train net output #0: loss = 1.05298 (* 1 = 1.05298 loss)
I0521 18:39:05.045922 17204 sgd_solver.cpp:106] Iteration 136500, lr = 0.0045
I0521 18:39:21.842170 17204 solver.cpp:237] Iteration 138000, loss = 2.28858
I0521 18:39:21.842218 17204 solver.cpp:253]     Train net output #0: loss = 2.28858 (* 1 = 2.28858 loss)
I0521 18:39:21.842232 17204 sgd_solver.cpp:106] Iteration 138000, lr = 0.0045
I0521 18:39:38.605124 17204 solver.cpp:237] Iteration 139500, loss = 1.48486
I0521 18:39:38.605298 17204 solver.cpp:253]     Train net output #0: loss = 1.48487 (* 1 = 1.48487 loss)
I0521 18:39:38.605311 17204 sgd_solver.cpp:106] Iteration 139500, lr = 0.0045
I0521 18:40:17.535437 17204 solver.cpp:237] Iteration 141000, loss = 1.20199
I0521 18:40:17.535609 17204 solver.cpp:253]     Train net output #0: loss = 1.20199 (* 1 = 1.20199 loss)
I0521 18:40:17.535624 17204 sgd_solver.cpp:106] Iteration 141000, lr = 0.0045
I0521 18:40:34.316957 17204 solver.cpp:237] Iteration 142500, loss = 2.5687
I0521 18:40:34.317005 17204 solver.cpp:253]     Train net output #0: loss = 2.5687 (* 1 = 2.5687 loss)
I0521 18:40:34.317019 17204 sgd_solver.cpp:106] Iteration 142500, lr = 0.0045
I0521 18:40:51.092326 17204 solver.cpp:237] Iteration 144000, loss = 1.56078
I0521 18:40:51.092500 17204 solver.cpp:253]     Train net output #0: loss = 1.56078 (* 1 = 1.56078 loss)
I0521 18:40:51.092514 17204 sgd_solver.cpp:106] Iteration 144000, lr = 0.0045
I0521 18:41:07.858371 17204 solver.cpp:237] Iteration 145500, loss = 1.15944
I0521 18:41:07.858407 17204 solver.cpp:253]     Train net output #0: loss = 1.15944 (* 1 = 1.15944 loss)
I0521 18:41:07.858420 17204 sgd_solver.cpp:106] Iteration 145500, lr = 0.0045
I0521 18:41:24.617300 17204 solver.cpp:237] Iteration 147000, loss = 1.30207
I0521 18:41:24.617460 17204 solver.cpp:253]     Train net output #0: loss = 1.30207 (* 1 = 1.30207 loss)
I0521 18:41:24.617473 17204 sgd_solver.cpp:106] Iteration 147000, lr = 0.0045
I0521 18:41:41.409138 17204 solver.cpp:237] Iteration 148500, loss = 0.686024
I0521 18:41:41.409183 17204 solver.cpp:253]     Train net output #0: loss = 0.686026 (* 1 = 0.686026 loss)
I0521 18:41:41.409201 17204 sgd_solver.cpp:106] Iteration 148500, lr = 0.0045
I0521 18:41:58.175987 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_150000.caffemodel
I0521 18:41:58.223882 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_150000.solverstate
I0521 18:41:58.251189 17204 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 18:42:57.640578 17204 solver.cpp:409]     Test net output #0: accuracy = 0.872059
I0521 18:42:57.640751 17204 solver.cpp:409]     Test net output #1: loss = 0.415509 (* 1 = 0.415509 loss)
I0521 18:43:18.516578 17204 solver.cpp:237] Iteration 150000, loss = 1.27773
I0521 18:43:18.516630 17204 solver.cpp:253]     Train net output #0: loss = 1.27773 (* 1 = 1.27773 loss)
I0521 18:43:18.516645 17204 sgd_solver.cpp:106] Iteration 150000, lr = 0.0045
I0521 18:43:35.131763 17204 solver.cpp:237] Iteration 151500, loss = 0.96924
I0521 18:43:35.131916 17204 solver.cpp:253]     Train net output #0: loss = 0.969242 (* 1 = 0.969242 loss)
I0521 18:43:35.131929 17204 sgd_solver.cpp:106] Iteration 151500, lr = 0.0045
I0521 18:43:51.776746 17204 solver.cpp:237] Iteration 153000, loss = 2.74169
I0521 18:43:51.776793 17204 solver.cpp:253]     Train net output #0: loss = 2.74169 (* 1 = 2.74169 loss)
I0521 18:43:51.776806 17204 sgd_solver.cpp:106] Iteration 153000, lr = 0.0045
I0521 18:44:08.377815 17204 solver.cpp:237] Iteration 154500, loss = 1.25745
I0521 18:44:08.377976 17204 solver.cpp:253]     Train net output #0: loss = 1.25745 (* 1 = 1.25745 loss)
I0521 18:44:08.377990 17204 sgd_solver.cpp:106] Iteration 154500, lr = 0.0045
I0521 18:44:24.991413 17204 solver.cpp:237] Iteration 156000, loss = 1.43415
I0521 18:44:24.991449 17204 solver.cpp:253]     Train net output #0: loss = 1.43415 (* 1 = 1.43415 loss)
I0521 18:44:24.991462 17204 sgd_solver.cpp:106] Iteration 156000, lr = 0.0045
I0521 18:44:41.596418 17204 solver.cpp:237] Iteration 157500, loss = 1.14965
I0521 18:44:41.596582 17204 solver.cpp:253]     Train net output #0: loss = 1.14965 (* 1 = 1.14965 loss)
I0521 18:44:41.596596 17204 sgd_solver.cpp:106] Iteration 157500, lr = 0.0045
I0521 18:44:58.206877 17204 solver.cpp:237] Iteration 159000, loss = 1.78319
I0521 18:44:58.206919 17204 solver.cpp:253]     Train net output #0: loss = 1.78319 (* 1 = 1.78319 loss)
I0521 18:44:58.206938 17204 sgd_solver.cpp:106] Iteration 159000, lr = 0.0045
I0521 18:45:35.667541 17204 solver.cpp:237] Iteration 160500, loss = 1.22406
I0521 18:45:35.667716 17204 solver.cpp:253]     Train net output #0: loss = 1.22406 (* 1 = 1.22406 loss)
I0521 18:45:35.667731 17204 sgd_solver.cpp:106] Iteration 160500, lr = 0.0045
I0521 18:45:52.289814 17204 solver.cpp:237] Iteration 162000, loss = 0.715618
I0521 18:45:52.289863 17204 solver.cpp:253]     Train net output #0: loss = 0.715621 (* 1 = 0.715621 loss)
I0521 18:45:52.289877 17204 sgd_solver.cpp:106] Iteration 162000, lr = 0.0045
I0521 18:46:08.923300 17204 solver.cpp:237] Iteration 163500, loss = 1.40531
I0521 18:46:08.923465 17204 solver.cpp:253]     Train net output #0: loss = 1.40531 (* 1 = 1.40531 loss)
I0521 18:46:08.923478 17204 sgd_solver.cpp:106] Iteration 163500, lr = 0.0045
I0521 18:46:25.548697 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_165000.caffemodel
I0521 18:46:25.593940 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_165000.solverstate
I0521 18:46:25.622787 17204 solver.cpp:237] Iteration 165000, loss = 1.26837
I0521 18:46:25.622834 17204 solver.cpp:253]     Train net output #0: loss = 1.26838 (* 1 = 1.26838 loss)
I0521 18:46:25.622848 17204 sgd_solver.cpp:106] Iteration 165000, lr = 0.0045
I0521 18:46:42.255412 17204 solver.cpp:237] Iteration 166500, loss = 0.888149
I0521 18:46:42.255570 17204 solver.cpp:253]     Train net output #0: loss = 0.888154 (* 1 = 0.888154 loss)
I0521 18:46:42.255585 17204 sgd_solver.cpp:106] Iteration 166500, lr = 0.0045
I0521 18:46:58.891494 17204 solver.cpp:237] Iteration 168000, loss = 1.06302
I0521 18:46:58.891530 17204 solver.cpp:253]     Train net output #0: loss = 1.06302 (* 1 = 1.06302 loss)
I0521 18:46:58.891544 17204 sgd_solver.cpp:106] Iteration 168000, lr = 0.0045
I0521 18:47:15.516366 17204 solver.cpp:237] Iteration 169500, loss = 1.1408
I0521 18:47:15.516526 17204 solver.cpp:253]     Train net output #0: loss = 1.1408 (* 1 = 1.1408 loss)
I0521 18:47:15.516541 17204 sgd_solver.cpp:106] Iteration 169500, lr = 0.0045
I0521 18:47:53.052971 17204 solver.cpp:237] Iteration 171000, loss = 1.17973
I0521 18:47:53.053141 17204 solver.cpp:253]     Train net output #0: loss = 1.17973 (* 1 = 1.17973 loss)
I0521 18:47:53.053155 17204 sgd_solver.cpp:106] Iteration 171000, lr = 0.0045
I0521 18:48:09.696688 17204 solver.cpp:237] Iteration 172500, loss = 1.55998
I0521 18:48:09.696725 17204 solver.cpp:253]     Train net output #0: loss = 1.55998 (* 1 = 1.55998 loss)
I0521 18:48:09.696739 17204 sgd_solver.cpp:106] Iteration 172500, lr = 0.0045
I0521 18:48:26.336668 17204 solver.cpp:237] Iteration 174000, loss = 0.889693
I0521 18:48:26.336833 17204 solver.cpp:253]     Train net output #0: loss = 0.889696 (* 1 = 0.889696 loss)
I0521 18:48:26.336846 17204 sgd_solver.cpp:106] Iteration 174000, lr = 0.0045
I0521 18:48:42.979719 17204 solver.cpp:237] Iteration 175500, loss = 1.23279
I0521 18:48:42.979759 17204 solver.cpp:253]     Train net output #0: loss = 1.2328 (* 1 = 1.2328 loss)
I0521 18:48:42.979779 17204 sgd_solver.cpp:106] Iteration 175500, lr = 0.0045
I0521 18:48:59.591027 17204 solver.cpp:237] Iteration 177000, loss = 1.28414
I0521 18:48:59.591172 17204 solver.cpp:253]     Train net output #0: loss = 1.28414 (* 1 = 1.28414 loss)
I0521 18:48:59.591186 17204 sgd_solver.cpp:106] Iteration 177000, lr = 0.0045
I0521 18:49:16.204499 17204 solver.cpp:237] Iteration 178500, loss = 1.17175
I0521 18:49:16.204542 17204 solver.cpp:253]     Train net output #0: loss = 1.17176 (* 1 = 1.17176 loss)
I0521 18:49:16.204557 17204 sgd_solver.cpp:106] Iteration 178500, lr = 0.0045
I0521 18:49:32.819480 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_180000.caffemodel
I0521 18:49:32.864682 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_180000.solverstate
I0521 18:49:32.889456 17204 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 18:50:53.414443 17204 solver.cpp:409]     Test net output #0: accuracy = 0.877151
I0521 18:50:53.414608 17204 solver.cpp:409]     Test net output #1: loss = 0.387434 (* 1 = 0.387434 loss)
I0521 18:51:14.270162 17204 solver.cpp:237] Iteration 180000, loss = 0.563634
I0521 18:51:14.270216 17204 solver.cpp:253]     Train net output #0: loss = 0.563639 (* 1 = 0.563639 loss)
I0521 18:51:14.270231 17204 sgd_solver.cpp:106] Iteration 180000, lr = 0.0045
I0521 18:51:31.265503 17204 solver.cpp:237] Iteration 181500, loss = 1.18906
I0521 18:51:31.265658 17204 solver.cpp:253]     Train net output #0: loss = 1.18907 (* 1 = 1.18907 loss)
I0521 18:51:31.265671 17204 sgd_solver.cpp:106] Iteration 181500, lr = 0.0045
I0521 18:51:48.313565 17204 solver.cpp:237] Iteration 183000, loss = 1.17103
I0521 18:51:48.313616 17204 solver.cpp:253]     Train net output #0: loss = 1.17104 (* 1 = 1.17104 loss)
I0521 18:51:48.313628 17204 sgd_solver.cpp:106] Iteration 183000, lr = 0.0045
I0521 18:52:05.344120 17204 solver.cpp:237] Iteration 184500, loss = 1.14996
I0521 18:52:05.344290 17204 solver.cpp:253]     Train net output #0: loss = 1.14997 (* 1 = 1.14997 loss)
I0521 18:52:05.344303 17204 sgd_solver.cpp:106] Iteration 184500, lr = 0.0045
I0521 18:52:22.359889 17204 solver.cpp:237] Iteration 186000, loss = 0.988571
I0521 18:52:22.359923 17204 solver.cpp:253]     Train net output #0: loss = 0.988576 (* 1 = 0.988576 loss)
I0521 18:52:22.359940 17204 sgd_solver.cpp:106] Iteration 186000, lr = 0.0045
I0521 18:52:39.385056 17204 solver.cpp:237] Iteration 187500, loss = 1.10023
I0521 18:52:39.385201 17204 solver.cpp:253]     Train net output #0: loss = 1.10024 (* 1 = 1.10024 loss)
I0521 18:52:39.385215 17204 sgd_solver.cpp:106] Iteration 187500, lr = 0.0045
I0521 18:52:56.424378 17204 solver.cpp:237] Iteration 189000, loss = 0.755147
I0521 18:52:56.424418 17204 solver.cpp:253]     Train net output #0: loss = 0.755152 (* 1 = 0.755152 loss)
I0521 18:52:56.424438 17204 sgd_solver.cpp:106] Iteration 189000, lr = 0.0045
I0521 18:53:34.373358 17204 solver.cpp:237] Iteration 190500, loss = 1.27448
I0521 18:53:34.373529 17204 solver.cpp:253]     Train net output #0: loss = 1.27448 (* 1 = 1.27448 loss)
I0521 18:53:34.373543 17204 sgd_solver.cpp:106] Iteration 190500, lr = 0.0045
I0521 18:53:51.401199 17204 solver.cpp:237] Iteration 192000, loss = 1.02074
I0521 18:53:51.401242 17204 solver.cpp:253]     Train net output #0: loss = 1.02075 (* 1 = 1.02075 loss)
I0521 18:53:51.401257 17204 sgd_solver.cpp:106] Iteration 192000, lr = 0.0045
I0521 18:54:08.422798 17204 solver.cpp:237] Iteration 193500, loss = 1.29343
I0521 18:54:08.422955 17204 solver.cpp:253]     Train net output #0: loss = 1.29343 (* 1 = 1.29343 loss)
I0521 18:54:08.422969 17204 sgd_solver.cpp:106] Iteration 193500, lr = 0.0045
I0521 18:54:25.452509 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_195000.caffemodel
I0521 18:54:25.498430 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_195000.solverstate
I0521 18:54:25.526566 17204 solver.cpp:237] Iteration 195000, loss = 0.915821
I0521 18:54:25.526613 17204 solver.cpp:253]     Train net output #0: loss = 0.915826 (* 1 = 0.915826 loss)
I0521 18:54:25.526628 17204 sgd_solver.cpp:106] Iteration 195000, lr = 0.0045
I0521 18:54:42.542160 17204 solver.cpp:237] Iteration 196500, loss = 1.88374
I0521 18:54:42.542337 17204 solver.cpp:253]     Train net output #0: loss = 1.88374 (* 1 = 1.88374 loss)
I0521 18:54:42.542351 17204 sgd_solver.cpp:106] Iteration 196500, lr = 0.0045
I0521 18:54:59.583436 17204 solver.cpp:237] Iteration 198000, loss = 0.777614
I0521 18:54:59.583484 17204 solver.cpp:253]     Train net output #0: loss = 0.77762 (* 1 = 0.77762 loss)
I0521 18:54:59.583499 17204 sgd_solver.cpp:106] Iteration 198000, lr = 0.0045
I0521 18:55:16.614470 17204 solver.cpp:237] Iteration 199500, loss = 0.939137
I0521 18:55:16.614620 17204 solver.cpp:253]     Train net output #0: loss = 0.939142 (* 1 = 0.939142 loss)
I0521 18:55:16.614634 17204 sgd_solver.cpp:106] Iteration 199500, lr = 0.0045
I0521 18:55:54.523778 17204 solver.cpp:237] Iteration 201000, loss = 1.22109
I0521 18:55:54.523952 17204 solver.cpp:253]     Train net output #0: loss = 1.2211 (* 1 = 1.2211 loss)
I0521 18:55:54.523967 17204 sgd_solver.cpp:106] Iteration 201000, lr = 0.0045
I0521 18:56:11.559597 17204 solver.cpp:237] Iteration 202500, loss = 0.836374
I0521 18:56:11.559644 17204 solver.cpp:253]     Train net output #0: loss = 0.836378 (* 1 = 0.836378 loss)
I0521 18:56:11.559659 17204 sgd_solver.cpp:106] Iteration 202500, lr = 0.0045
I0521 18:56:28.553016 17204 solver.cpp:237] Iteration 204000, loss = 0.973501
I0521 18:56:28.553165 17204 solver.cpp:253]     Train net output #0: loss = 0.973506 (* 1 = 0.973506 loss)
I0521 18:56:28.553179 17204 sgd_solver.cpp:106] Iteration 204000, lr = 0.0045
I0521 18:56:45.413544 17204 solver.cpp:237] Iteration 205500, loss = 1.20632
I0521 18:56:45.413592 17204 solver.cpp:253]     Train net output #0: loss = 1.20633 (* 1 = 1.20633 loss)
I0521 18:56:45.413606 17204 sgd_solver.cpp:106] Iteration 205500, lr = 0.0045
I0521 18:57:02.197214 17204 solver.cpp:237] Iteration 207000, loss = 1.87279
I0521 18:57:02.197371 17204 solver.cpp:253]     Train net output #0: loss = 1.87279 (* 1 = 1.87279 loss)
I0521 18:57:02.197386 17204 sgd_solver.cpp:106] Iteration 207000, lr = 0.0045
I0521 18:57:18.967499 17204 solver.cpp:237] Iteration 208500, loss = 1.20053
I0521 18:57:18.967535 17204 solver.cpp:253]     Train net output #0: loss = 1.20053 (* 1 = 1.20053 loss)
I0521 18:57:18.967547 17204 sgd_solver.cpp:106] Iteration 208500, lr = 0.0045
I0521 18:57:35.724194 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_210000.caffemodel
I0521 18:57:35.769997 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_210000.solverstate
I0521 18:57:35.794606 17204 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 18:58:34.901496 17204 solver.cpp:409]     Test net output #0: accuracy = 0.872029
I0521 18:58:34.901664 17204 solver.cpp:409]     Test net output #1: loss = 0.407792 (* 1 = 0.407792 loss)
I0521 18:58:55.828847 17204 solver.cpp:237] Iteration 210000, loss = 1.45383
I0521 18:58:55.828901 17204 solver.cpp:253]     Train net output #0: loss = 1.45383 (* 1 = 1.45383 loss)
I0521 18:58:55.828915 17204 sgd_solver.cpp:106] Iteration 210000, lr = 0.0045
I0521 18:59:13.011207 17204 solver.cpp:237] Iteration 211500, loss = 0.869817
I0521 18:59:13.011378 17204 solver.cpp:253]     Train net output #0: loss = 0.869822 (* 1 = 0.869822 loss)
I0521 18:59:13.011391 17204 sgd_solver.cpp:106] Iteration 211500, lr = 0.0045
I0521 18:59:30.209091 17204 solver.cpp:237] Iteration 213000, loss = 0.665796
I0521 18:59:30.209128 17204 solver.cpp:253]     Train net output #0: loss = 0.665801 (* 1 = 0.665801 loss)
I0521 18:59:30.209142 17204 sgd_solver.cpp:106] Iteration 213000, lr = 0.0045
I0521 18:59:47.378777 17204 solver.cpp:237] Iteration 214500, loss = 1.03442
I0521 18:59:47.378947 17204 solver.cpp:253]     Train net output #0: loss = 1.03442 (* 1 = 1.03442 loss)
I0521 18:59:47.378959 17204 sgd_solver.cpp:106] Iteration 214500, lr = 0.0045
I0521 19:00:04.592263 17204 solver.cpp:237] Iteration 216000, loss = 1.18479
I0521 19:00:04.592310 17204 solver.cpp:253]     Train net output #0: loss = 1.1848 (* 1 = 1.1848 loss)
I0521 19:00:04.592324 17204 sgd_solver.cpp:106] Iteration 216000, lr = 0.0045
I0521 19:00:21.772696 17204 solver.cpp:237] Iteration 217500, loss = 1.15029
I0521 19:00:21.772861 17204 solver.cpp:253]     Train net output #0: loss = 1.1503 (* 1 = 1.1503 loss)
I0521 19:00:21.772873 17204 sgd_solver.cpp:106] Iteration 217500, lr = 0.0045
I0521 19:00:38.979038 17204 solver.cpp:237] Iteration 219000, loss = 0.451142
I0521 19:00:38.979075 17204 solver.cpp:253]     Train net output #0: loss = 0.451146 (* 1 = 0.451146 loss)
I0521 19:00:38.979089 17204 sgd_solver.cpp:106] Iteration 219000, lr = 0.0045
I0521 19:01:17.090173 17204 solver.cpp:237] Iteration 220500, loss = 1.28903
I0521 19:01:17.090349 17204 solver.cpp:253]     Train net output #0: loss = 1.28903 (* 1 = 1.28903 loss)
I0521 19:01:17.090363 17204 sgd_solver.cpp:106] Iteration 220500, lr = 0.0045
I0521 19:01:34.284814 17204 solver.cpp:237] Iteration 222000, loss = 1.09614
I0521 19:01:34.284850 17204 solver.cpp:253]     Train net output #0: loss = 1.09615 (* 1 = 1.09615 loss)
I0521 19:01:34.284864 17204 sgd_solver.cpp:106] Iteration 222000, lr = 0.0045
I0521 19:01:51.446535 17204 solver.cpp:237] Iteration 223500, loss = 0.780652
I0521 19:01:51.446699 17204 solver.cpp:253]     Train net output #0: loss = 0.780657 (* 1 = 0.780657 loss)
I0521 19:01:51.446713 17204 sgd_solver.cpp:106] Iteration 223500, lr = 0.0045
I0521 19:02:08.636620 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_225000.caffemodel
I0521 19:02:08.685313 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_225000.solverstate
I0521 19:02:08.716312 17204 solver.cpp:237] Iteration 225000, loss = 0.762985
I0521 19:02:08.716361 17204 solver.cpp:253]     Train net output #0: loss = 0.762991 (* 1 = 0.762991 loss)
I0521 19:02:08.716379 17204 sgd_solver.cpp:106] Iteration 225000, lr = 0.0045
I0521 19:02:25.913177 17204 solver.cpp:237] Iteration 226500, loss = 2.16638
I0521 19:02:25.913336 17204 solver.cpp:253]     Train net output #0: loss = 2.16639 (* 1 = 2.16639 loss)
I0521 19:02:25.913349 17204 sgd_solver.cpp:106] Iteration 226500, lr = 0.0045
I0521 19:02:43.117537 17204 solver.cpp:237] Iteration 228000, loss = 1.43977
I0521 19:02:43.117573 17204 solver.cpp:253]     Train net output #0: loss = 1.43978 (* 1 = 1.43978 loss)
I0521 19:02:43.117585 17204 sgd_solver.cpp:106] Iteration 228000, lr = 0.0045
I0521 19:03:00.320866 17204 solver.cpp:237] Iteration 229500, loss = 0.588357
I0521 19:03:00.321030 17204 solver.cpp:253]     Train net output #0: loss = 0.588362 (* 1 = 0.588362 loss)
I0521 19:03:00.321044 17204 sgd_solver.cpp:106] Iteration 229500, lr = 0.0045
I0521 19:03:38.379825 17204 solver.cpp:237] Iteration 231000, loss = 1.21075
I0521 19:03:38.380004 17204 solver.cpp:253]     Train net output #0: loss = 1.21076 (* 1 = 1.21076 loss)
I0521 19:03:38.380019 17204 sgd_solver.cpp:106] Iteration 231000, lr = 0.0045
I0521 19:03:55.553517 17204 solver.cpp:237] Iteration 232500, loss = 0.947647
I0521 19:03:55.553563 17204 solver.cpp:253]     Train net output #0: loss = 0.947652 (* 1 = 0.947652 loss)
I0521 19:03:55.553578 17204 sgd_solver.cpp:106] Iteration 232500, lr = 0.0045
I0521 19:04:12.744395 17204 solver.cpp:237] Iteration 234000, loss = 1.48327
I0521 19:04:12.744555 17204 solver.cpp:253]     Train net output #0: loss = 1.48327 (* 1 = 1.48327 loss)
I0521 19:04:12.744570 17204 sgd_solver.cpp:106] Iteration 234000, lr = 0.0045
I0521 19:04:29.910789 17204 solver.cpp:237] Iteration 235500, loss = 1.33857
I0521 19:04:29.910825 17204 solver.cpp:253]     Train net output #0: loss = 1.33858 (* 1 = 1.33858 loss)
I0521 19:04:29.910838 17204 sgd_solver.cpp:106] Iteration 235500, lr = 0.0045
I0521 19:04:47.111217 17204 solver.cpp:237] Iteration 237000, loss = 1.51337
I0521 19:04:47.111390 17204 solver.cpp:253]     Train net output #0: loss = 1.51338 (* 1 = 1.51338 loss)
I0521 19:04:47.111403 17204 sgd_solver.cpp:106] Iteration 237000, lr = 0.0045
I0521 19:05:04.240023 17204 solver.cpp:237] Iteration 238500, loss = 1.31906
I0521 19:05:04.240073 17204 solver.cpp:253]     Train net output #0: loss = 1.31907 (* 1 = 1.31907 loss)
I0521 19:05:04.240087 17204 sgd_solver.cpp:106] Iteration 238500, lr = 0.0045
I0521 19:05:21.428275 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_240000.caffemodel
I0521 19:05:21.474227 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_240000.solverstate
I0521 19:05:21.499723 17204 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 19:06:41.622437 17204 solver.cpp:409]     Test net output #0: accuracy = 0.881453
I0521 19:06:41.622608 17204 solver.cpp:409]     Test net output #1: loss = 0.378244 (* 1 = 0.378244 loss)
I0521 19:07:02.513391 17204 solver.cpp:237] Iteration 240000, loss = 1.2828
I0521 19:07:02.513442 17204 solver.cpp:253]     Train net output #0: loss = 1.28281 (* 1 = 1.28281 loss)
I0521 19:07:02.513458 17204 sgd_solver.cpp:106] Iteration 240000, lr = 0.0045
I0521 19:07:19.265574 17204 solver.cpp:237] Iteration 241500, loss = 0.419733
I0521 19:07:19.265735 17204 solver.cpp:253]     Train net output #0: loss = 0.419741 (* 1 = 0.419741 loss)
I0521 19:07:19.265749 17204 sgd_solver.cpp:106] Iteration 241500, lr = 0.0045
I0521 19:07:36.041499 17204 solver.cpp:237] Iteration 243000, loss = 0.943047
I0521 19:07:36.041550 17204 solver.cpp:253]     Train net output #0: loss = 0.943054 (* 1 = 0.943054 loss)
I0521 19:07:36.041564 17204 sgd_solver.cpp:106] Iteration 243000, lr = 0.0045
I0521 19:07:52.833652 17204 solver.cpp:237] Iteration 244500, loss = 0.870441
I0521 19:07:52.833817 17204 solver.cpp:253]     Train net output #0: loss = 0.87045 (* 1 = 0.87045 loss)
I0521 19:07:52.833830 17204 sgd_solver.cpp:106] Iteration 244500, lr = 0.0045
I0521 19:08:09.610991 17204 solver.cpp:237] Iteration 246000, loss = 1.12472
I0521 19:08:09.611027 17204 solver.cpp:253]     Train net output #0: loss = 1.12472 (* 1 = 1.12472 loss)
I0521 19:08:09.611042 17204 sgd_solver.cpp:106] Iteration 246000, lr = 0.0045
I0521 19:08:26.385346 17204 solver.cpp:237] Iteration 247500, loss = 1.44468
I0521 19:08:26.385515 17204 solver.cpp:253]     Train net output #0: loss = 1.44469 (* 1 = 1.44469 loss)
I0521 19:08:26.385529 17204 sgd_solver.cpp:106] Iteration 247500, lr = 0.0045
I0521 19:08:43.158825 17204 solver.cpp:237] Iteration 249000, loss = 0.48745
I0521 19:08:43.158867 17204 solver.cpp:253]     Train net output #0: loss = 0.487457 (* 1 = 0.487457 loss)
I0521 19:08:43.158886 17204 sgd_solver.cpp:106] Iteration 249000, lr = 0.0045
I0521 19:09:20.779043 17204 solver.cpp:237] Iteration 250500, loss = 1.31335
I0521 19:09:20.779218 17204 solver.cpp:253]     Train net output #0: loss = 1.31335 (* 1 = 1.31335 loss)
I0521 19:09:20.779232 17204 sgd_solver.cpp:106] Iteration 250500, lr = 0.0045
I0521 19:09:37.559358 17204 solver.cpp:237] Iteration 252000, loss = 0.994694
I0521 19:09:37.559403 17204 solver.cpp:253]     Train net output #0: loss = 0.994701 (* 1 = 0.994701 loss)
I0521 19:09:37.559419 17204 sgd_solver.cpp:106] Iteration 252000, lr = 0.0045
I0521 19:09:54.317929 17204 solver.cpp:237] Iteration 253500, loss = 1.29592
I0521 19:09:54.318081 17204 solver.cpp:253]     Train net output #0: loss = 1.29593 (* 1 = 1.29593 loss)
I0521 19:09:54.318094 17204 sgd_solver.cpp:106] Iteration 253500, lr = 0.0045
I0521 19:10:11.084492 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_255000.caffemodel
I0521 19:10:11.130513 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_255000.solverstate
I0521 19:10:11.159297 17204 solver.cpp:237] Iteration 255000, loss = 1.48037
I0521 19:10:11.159343 17204 solver.cpp:253]     Train net output #0: loss = 1.48038 (* 1 = 1.48038 loss)
I0521 19:10:11.159358 17204 sgd_solver.cpp:106] Iteration 255000, lr = 0.0045
I0521 19:10:27.923105 17204 solver.cpp:237] Iteration 256500, loss = 1.08792
I0521 19:10:27.923287 17204 solver.cpp:253]     Train net output #0: loss = 1.08793 (* 1 = 1.08793 loss)
I0521 19:10:27.923301 17204 sgd_solver.cpp:106] Iteration 256500, lr = 0.0045
I0521 19:10:44.693539 17204 solver.cpp:237] Iteration 258000, loss = 0.990844
I0521 19:10:44.693575 17204 solver.cpp:253]     Train net output #0: loss = 0.990851 (* 1 = 0.990851 loss)
I0521 19:10:44.693588 17204 sgd_solver.cpp:106] Iteration 258000, lr = 0.0045
I0521 19:11:01.480422 17204 solver.cpp:237] Iteration 259500, loss = 1.30628
I0521 19:11:01.480592 17204 solver.cpp:253]     Train net output #0: loss = 1.30628 (* 1 = 1.30628 loss)
I0521 19:11:01.480607 17204 sgd_solver.cpp:106] Iteration 259500, lr = 0.0045
I0521 19:11:39.130239 17204 solver.cpp:237] Iteration 261000, loss = 1.39792
I0521 19:11:39.130414 17204 solver.cpp:253]     Train net output #0: loss = 1.39793 (* 1 = 1.39793 loss)
I0521 19:11:39.130429 17204 sgd_solver.cpp:106] Iteration 261000, lr = 0.0045
I0521 19:11:55.921322 17204 solver.cpp:237] Iteration 262500, loss = 2.17934
I0521 19:11:55.921360 17204 solver.cpp:253]     Train net output #0: loss = 2.17935 (* 1 = 2.17935 loss)
I0521 19:11:55.921372 17204 sgd_solver.cpp:106] Iteration 262500, lr = 0.0045
I0521 19:12:12.704169 17204 solver.cpp:237] Iteration 264000, loss = 1.84286
I0521 19:12:12.704330 17204 solver.cpp:253]     Train net output #0: loss = 1.84287 (* 1 = 1.84287 loss)
I0521 19:12:12.704344 17204 sgd_solver.cpp:106] Iteration 264000, lr = 0.0045
I0521 19:12:29.497380 17204 solver.cpp:237] Iteration 265500, loss = 1.44724
I0521 19:12:29.497422 17204 solver.cpp:253]     Train net output #0: loss = 1.44725 (* 1 = 1.44725 loss)
I0521 19:12:29.497440 17204 sgd_solver.cpp:106] Iteration 265500, lr = 0.0045
I0521 19:12:46.277506 17204 solver.cpp:237] Iteration 267000, loss = 1.0065
I0521 19:12:46.277662 17204 solver.cpp:253]     Train net output #0: loss = 1.00651 (* 1 = 1.00651 loss)
I0521 19:12:46.277676 17204 sgd_solver.cpp:106] Iteration 267000, lr = 0.0045
I0521 19:13:03.067797 17204 solver.cpp:237] Iteration 268500, loss = 1.43787
I0521 19:13:03.067847 17204 solver.cpp:253]     Train net output #0: loss = 1.43788 (* 1 = 1.43788 loss)
I0521 19:13:03.067860 17204 sgd_solver.cpp:106] Iteration 268500, lr = 0.0045
I0521 19:13:19.841358 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_270000.caffemodel
I0521 19:13:19.886481 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_270000.solverstate
I0521 19:13:19.911826 17204 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 19:14:19.298677 17204 solver.cpp:409]     Test net output #0: accuracy = 0.87616
I0521 19:14:19.298851 17204 solver.cpp:409]     Test net output #1: loss = 0.395707 (* 1 = 0.395707 loss)
I0521 19:14:40.180944 17204 solver.cpp:237] Iteration 270000, loss = 1.98534
I0521 19:14:40.180997 17204 solver.cpp:253]     Train net output #0: loss = 1.98535 (* 1 = 1.98535 loss)
I0521 19:14:40.181011 17204 sgd_solver.cpp:106] Iteration 270000, lr = 0.0045
I0521 19:14:57.363396 17204 solver.cpp:237] Iteration 271500, loss = 1.58807
I0521 19:14:57.363590 17204 solver.cpp:253]     Train net output #0: loss = 1.58808 (* 1 = 1.58808 loss)
I0521 19:14:57.363603 17204 sgd_solver.cpp:106] Iteration 271500, lr = 0.0045
I0521 19:15:14.522915 17204 solver.cpp:237] Iteration 273000, loss = 0.880216
I0521 19:15:14.522953 17204 solver.cpp:253]     Train net output #0: loss = 0.880225 (* 1 = 0.880225 loss)
I0521 19:15:14.522966 17204 sgd_solver.cpp:106] Iteration 273000, lr = 0.0045
I0521 19:15:31.415928 17204 solver.cpp:237] Iteration 274500, loss = 0.943757
I0521 19:15:31.416097 17204 solver.cpp:253]     Train net output #0: loss = 0.943766 (* 1 = 0.943766 loss)
I0521 19:15:31.416110 17204 sgd_solver.cpp:106] Iteration 274500, lr = 0.0045
I0521 19:15:48.040073 17204 solver.cpp:237] Iteration 276000, loss = 0.860008
I0521 19:15:48.040119 17204 solver.cpp:253]     Train net output #0: loss = 0.860017 (* 1 = 0.860017 loss)
I0521 19:15:48.040134 17204 sgd_solver.cpp:106] Iteration 276000, lr = 0.0045
I0521 19:16:04.677762 17204 solver.cpp:237] Iteration 277500, loss = 1.48599
I0521 19:16:04.677917 17204 solver.cpp:253]     Train net output #0: loss = 1.486 (* 1 = 1.486 loss)
I0521 19:16:04.677930 17204 sgd_solver.cpp:106] Iteration 277500, lr = 0.0045
I0521 19:16:21.283848 17204 solver.cpp:237] Iteration 279000, loss = 1.18897
I0521 19:16:21.283892 17204 solver.cpp:253]     Train net output #0: loss = 1.18898 (* 1 = 1.18898 loss)
I0521 19:16:21.283906 17204 sgd_solver.cpp:106] Iteration 279000, lr = 0.0045
I0521 19:16:58.771178 17204 solver.cpp:237] Iteration 280500, loss = 0.737576
I0521 19:16:58.771356 17204 solver.cpp:253]     Train net output #0: loss = 0.737584 (* 1 = 0.737584 loss)
I0521 19:16:58.771371 17204 sgd_solver.cpp:106] Iteration 280500, lr = 0.0045
I0521 19:17:15.401202 17204 solver.cpp:237] Iteration 282000, loss = 0.747493
I0521 19:17:15.401249 17204 solver.cpp:253]     Train net output #0: loss = 0.747501 (* 1 = 0.747501 loss)
I0521 19:17:15.401263 17204 sgd_solver.cpp:106] Iteration 282000, lr = 0.0045
I0521 19:17:32.010578 17204 solver.cpp:237] Iteration 283500, loss = 0.668015
I0521 19:17:32.010751 17204 solver.cpp:253]     Train net output #0: loss = 0.668023 (* 1 = 0.668023 loss)
I0521 19:17:32.010764 17204 sgd_solver.cpp:106] Iteration 283500, lr = 0.0045
I0521 19:17:48.608495 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_285000.caffemodel
I0521 19:17:48.656373 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_285000.solverstate
I0521 19:17:48.687539 17204 solver.cpp:237] Iteration 285000, loss = 2.09021
I0521 19:17:48.687585 17204 solver.cpp:253]     Train net output #0: loss = 2.09022 (* 1 = 2.09022 loss)
I0521 19:17:48.687604 17204 sgd_solver.cpp:106] Iteration 285000, lr = 0.0045
I0521 19:18:05.303261 17204 solver.cpp:237] Iteration 286500, loss = 1.18416
I0521 19:18:05.303434 17204 solver.cpp:253]     Train net output #0: loss = 1.18417 (* 1 = 1.18417 loss)
I0521 19:18:05.303447 17204 sgd_solver.cpp:106] Iteration 286500, lr = 0.0045
I0521 19:18:21.935494 17204 solver.cpp:237] Iteration 288000, loss = 1.60441
I0521 19:18:21.935544 17204 solver.cpp:253]     Train net output #0: loss = 1.60441 (* 1 = 1.60441 loss)
I0521 19:18:21.935559 17204 sgd_solver.cpp:106] Iteration 288000, lr = 0.0045
I0521 19:18:38.531605 17204 solver.cpp:237] Iteration 289500, loss = 1.61901
I0521 19:18:38.531780 17204 solver.cpp:253]     Train net output #0: loss = 1.61901 (* 1 = 1.61901 loss)
I0521 19:18:38.531792 17204 sgd_solver.cpp:106] Iteration 289500, lr = 0.0045
I0521 19:19:16.009433 17204 solver.cpp:237] Iteration 291000, loss = 1.04546
I0521 19:19:16.009624 17204 solver.cpp:253]     Train net output #0: loss = 1.04547 (* 1 = 1.04547 loss)
I0521 19:19:16.009640 17204 sgd_solver.cpp:106] Iteration 291000, lr = 0.0045
I0521 19:19:32.604876 17204 solver.cpp:237] Iteration 292500, loss = 1.209
I0521 19:19:32.604915 17204 solver.cpp:253]     Train net output #0: loss = 1.209 (* 1 = 1.209 loss)
I0521 19:19:32.604938 17204 sgd_solver.cpp:106] Iteration 292500, lr = 0.0045
I0521 19:19:49.256551 17204 solver.cpp:237] Iteration 294000, loss = 0.91848
I0521 19:19:49.256736 17204 solver.cpp:253]     Train net output #0: loss = 0.918486 (* 1 = 0.918486 loss)
I0521 19:19:49.256750 17204 sgd_solver.cpp:106] Iteration 294000, lr = 0.0045
I0521 19:20:05.865015 17204 solver.cpp:237] Iteration 295500, loss = 1.34877
I0521 19:20:05.865063 17204 solver.cpp:253]     Train net output #0: loss = 1.34878 (* 1 = 1.34878 loss)
I0521 19:20:05.865077 17204 sgd_solver.cpp:106] Iteration 295500, lr = 0.0045
I0521 19:20:22.484309 17204 solver.cpp:237] Iteration 297000, loss = 2.7051
I0521 19:20:22.484482 17204 solver.cpp:253]     Train net output #0: loss = 2.70511 (* 1 = 2.70511 loss)
I0521 19:20:22.484496 17204 sgd_solver.cpp:106] Iteration 297000, lr = 0.0045
I0521 19:20:39.109038 17204 solver.cpp:237] Iteration 298500, loss = 1.18583
I0521 19:20:39.109076 17204 solver.cpp:253]     Train net output #0: loss = 1.18584 (* 1 = 1.18584 loss)
I0521 19:20:39.109089 17204 sgd_solver.cpp:106] Iteration 298500, lr = 0.0045
I0521 19:20:55.886457 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_300000.caffemodel
I0521 19:20:55.934283 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_300000.solverstate
I0521 19:20:55.961784 17204 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 19:22:16.248198 17204 solver.cpp:409]     Test net output #0: accuracy = 0.884715
I0521 19:22:16.248374 17204 solver.cpp:409]     Test net output #1: loss = 0.391997 (* 1 = 0.391997 loss)
I0521 19:22:37.130219 17204 solver.cpp:237] Iteration 300000, loss = 1.12777
I0521 19:22:37.130272 17204 solver.cpp:253]     Train net output #0: loss = 1.12778 (* 1 = 1.12778 loss)
I0521 19:22:37.130288 17204 sgd_solver.cpp:106] Iteration 300000, lr = 0.0045
I0521 19:22:54.178447 17204 solver.cpp:237] Iteration 301500, loss = 0.714235
I0521 19:22:54.178622 17204 solver.cpp:253]     Train net output #0: loss = 0.714243 (* 1 = 0.714243 loss)
I0521 19:22:54.178637 17204 sgd_solver.cpp:106] Iteration 301500, lr = 0.0045
I0521 19:23:11.219503 17204 solver.cpp:237] Iteration 303000, loss = 1.47073
I0521 19:23:11.219539 17204 solver.cpp:253]     Train net output #0: loss = 1.47073 (* 1 = 1.47073 loss)
I0521 19:23:11.219554 17204 sgd_solver.cpp:106] Iteration 303000, lr = 0.0045
I0521 19:23:28.291479 17204 solver.cpp:237] Iteration 304500, loss = 1.73225
I0521 19:23:28.291652 17204 solver.cpp:253]     Train net output #0: loss = 1.73226 (* 1 = 1.73226 loss)
I0521 19:23:28.291666 17204 sgd_solver.cpp:106] Iteration 304500, lr = 0.0045
I0521 19:23:45.325625 17204 solver.cpp:237] Iteration 306000, loss = 1.1722
I0521 19:23:45.325667 17204 solver.cpp:253]     Train net output #0: loss = 1.17221 (* 1 = 1.17221 loss)
I0521 19:23:45.325685 17204 sgd_solver.cpp:106] Iteration 306000, lr = 0.0045
I0521 19:24:02.324359 17204 solver.cpp:237] Iteration 307500, loss = 0.464919
I0521 19:24:02.324517 17204 solver.cpp:253]     Train net output #0: loss = 0.464927 (* 1 = 0.464927 loss)
I0521 19:24:02.324530 17204 sgd_solver.cpp:106] Iteration 307500, lr = 0.0045
I0521 19:24:19.378577 17204 solver.cpp:237] Iteration 309000, loss = 1.61176
I0521 19:24:19.378624 17204 solver.cpp:253]     Train net output #0: loss = 1.61177 (* 1 = 1.61177 loss)
I0521 19:24:19.378638 17204 sgd_solver.cpp:106] Iteration 309000, lr = 0.0045
I0521 19:24:57.284462 17204 solver.cpp:237] Iteration 310500, loss = 0.8935
I0521 19:24:57.284639 17204 solver.cpp:253]     Train net output #0: loss = 0.893507 (* 1 = 0.893507 loss)
I0521 19:24:57.284653 17204 sgd_solver.cpp:106] Iteration 310500, lr = 0.0045
I0521 19:25:14.281452 17204 solver.cpp:237] Iteration 312000, loss = 1.08182
I0521 19:25:14.281487 17204 solver.cpp:253]     Train net output #0: loss = 1.08183 (* 1 = 1.08183 loss)
I0521 19:25:14.281504 17204 sgd_solver.cpp:106] Iteration 312000, lr = 0.0045
I0521 19:25:31.289986 17204 solver.cpp:237] Iteration 313500, loss = 1.2874
I0521 19:25:31.290163 17204 solver.cpp:253]     Train net output #0: loss = 1.28741 (* 1 = 1.28741 loss)
I0521 19:25:31.290176 17204 sgd_solver.cpp:106] Iteration 313500, lr = 0.0045
I0521 19:25:48.296425 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_315000.caffemodel
I0521 19:25:48.342268 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_315000.solverstate
I0521 19:25:48.370679 17204 solver.cpp:237] Iteration 315000, loss = 1.02675
I0521 19:25:48.370725 17204 solver.cpp:253]     Train net output #0: loss = 1.02676 (* 1 = 1.02676 loss)
I0521 19:25:48.370739 17204 sgd_solver.cpp:106] Iteration 315000, lr = 0.0045
I0521 19:26:05.412752 17204 solver.cpp:237] Iteration 316500, loss = 1.12573
I0521 19:26:05.412915 17204 solver.cpp:253]     Train net output #0: loss = 1.12573 (* 1 = 1.12573 loss)
I0521 19:26:05.412928 17204 sgd_solver.cpp:106] Iteration 316500, lr = 0.0045
I0521 19:26:22.479202 17204 solver.cpp:237] Iteration 318000, loss = 1.17923
I0521 19:26:22.479248 17204 solver.cpp:253]     Train net output #0: loss = 1.17923 (* 1 = 1.17923 loss)
I0521 19:26:22.479261 17204 sgd_solver.cpp:106] Iteration 318000, lr = 0.0045
I0521 19:26:39.492610 17204 solver.cpp:237] Iteration 319500, loss = 0.416642
I0521 19:26:39.492777 17204 solver.cpp:253]     Train net output #0: loss = 0.416648 (* 1 = 0.416648 loss)
I0521 19:26:39.492791 17204 sgd_solver.cpp:106] Iteration 319500, lr = 0.0045
I0521 19:27:17.426754 17204 solver.cpp:237] Iteration 321000, loss = 1.19059
I0521 19:27:17.426934 17204 solver.cpp:253]     Train net output #0: loss = 1.1906 (* 1 = 1.1906 loss)
I0521 19:27:17.426947 17204 sgd_solver.cpp:106] Iteration 321000, lr = 0.0045
I0521 19:27:34.473835 17204 solver.cpp:237] Iteration 322500, loss = 1.00756
I0521 19:27:34.473875 17204 solver.cpp:253]     Train net output #0: loss = 1.00757 (* 1 = 1.00757 loss)
I0521 19:27:34.473888 17204 sgd_solver.cpp:106] Iteration 322500, lr = 0.0045
I0521 19:27:51.521066 17204 solver.cpp:237] Iteration 324000, loss = 1.24531
I0521 19:27:51.521240 17204 solver.cpp:253]     Train net output #0: loss = 1.24532 (* 1 = 1.24532 loss)
I0521 19:27:51.521255 17204 sgd_solver.cpp:106] Iteration 324000, lr = 0.0045
I0521 19:28:08.554839 17204 solver.cpp:237] Iteration 325500, loss = 1.48396
I0521 19:28:08.554875 17204 solver.cpp:253]     Train net output #0: loss = 1.48396 (* 1 = 1.48396 loss)
I0521 19:28:08.554889 17204 sgd_solver.cpp:106] Iteration 325500, lr = 0.0045
I0521 19:28:25.599886 17204 solver.cpp:237] Iteration 327000, loss = 1.41254
I0521 19:28:25.600054 17204 solver.cpp:253]     Train net output #0: loss = 1.41254 (* 1 = 1.41254 loss)
I0521 19:28:25.600069 17204 sgd_solver.cpp:106] Iteration 327000, lr = 0.0045
I0521 19:28:42.645472 17204 solver.cpp:237] Iteration 328500, loss = 1.40574
I0521 19:28:42.645512 17204 solver.cpp:253]     Train net output #0: loss = 1.40574 (* 1 = 1.40574 loss)
I0521 19:28:42.645531 17204 sgd_solver.cpp:106] Iteration 328500, lr = 0.0045
I0521 19:28:59.664759 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_330000.caffemodel
I0521 19:28:59.710554 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_330000.solverstate
I0521 19:28:59.735618 17204 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 19:29:58.575800 17204 solver.cpp:409]     Test net output #0: accuracy = 0.884473
I0521 19:29:58.575987 17204 solver.cpp:409]     Test net output #1: loss = 0.362777 (* 1 = 0.362777 loss)
I0521 19:30:19.447429 17204 solver.cpp:237] Iteration 330000, loss = 1.44733
I0521 19:30:19.447481 17204 solver.cpp:253]     Train net output #0: loss = 1.44733 (* 1 = 1.44733 loss)
I0521 19:30:19.447495 17204 sgd_solver.cpp:106] Iteration 330000, lr = 0.0045
I0521 19:30:36.586066 17204 solver.cpp:237] Iteration 331500, loss = 0.767373
I0521 19:30:36.586243 17204 solver.cpp:253]     Train net output #0: loss = 0.767375 (* 1 = 0.767375 loss)
I0521 19:30:36.586257 17204 sgd_solver.cpp:106] Iteration 331500, lr = 0.0045
I0521 19:30:53.765326 17204 solver.cpp:237] Iteration 333000, loss = 1.44031
I0521 19:30:53.765368 17204 solver.cpp:253]     Train net output #0: loss = 1.44031 (* 1 = 1.44031 loss)
I0521 19:30:53.765383 17204 sgd_solver.cpp:106] Iteration 333000, lr = 0.0045
I0521 19:31:10.977066 17204 solver.cpp:237] Iteration 334500, loss = 1.28711
I0521 19:31:10.995764 17204 solver.cpp:253]     Train net output #0: loss = 1.28711 (* 1 = 1.28711 loss)
I0521 19:31:10.995780 17204 sgd_solver.cpp:106] Iteration 334500, lr = 0.0045
I0521 19:31:28.152942 17204 solver.cpp:237] Iteration 336000, loss = 1.32952
I0521 19:31:28.152979 17204 solver.cpp:253]     Train net output #0: loss = 1.32952 (* 1 = 1.32952 loss)
I0521 19:31:28.152993 17204 sgd_solver.cpp:106] Iteration 336000, lr = 0.0045
I0521 19:31:45.310506 17204 solver.cpp:237] Iteration 337500, loss = 1.91032
I0521 19:31:45.310683 17204 solver.cpp:253]     Train net output #0: loss = 1.91032 (* 1 = 1.91032 loss)
I0521 19:31:45.310695 17204 sgd_solver.cpp:106] Iteration 337500, lr = 0.0045
I0521 19:32:02.485194 17204 solver.cpp:237] Iteration 339000, loss = 1.12631
I0521 19:32:02.485234 17204 solver.cpp:253]     Train net output #0: loss = 1.12631 (* 1 = 1.12631 loss)
I0521 19:32:02.485254 17204 sgd_solver.cpp:106] Iteration 339000, lr = 0.0045
I0521 19:32:40.544078 17204 solver.cpp:237] Iteration 340500, loss = 2.16387
I0521 19:32:40.544260 17204 solver.cpp:253]     Train net output #0: loss = 2.16387 (* 1 = 2.16387 loss)
I0521 19:32:40.544275 17204 sgd_solver.cpp:106] Iteration 340500, lr = 0.0045
I0521 19:32:57.703814 17204 solver.cpp:237] Iteration 342000, loss = 1.05345
I0521 19:32:57.703856 17204 solver.cpp:253]     Train net output #0: loss = 1.05345 (* 1 = 1.05345 loss)
I0521 19:32:57.703873 17204 sgd_solver.cpp:106] Iteration 342000, lr = 0.0045
I0521 19:33:14.886378 17204 solver.cpp:237] Iteration 343500, loss = 1.45823
I0521 19:33:14.886533 17204 solver.cpp:253]     Train net output #0: loss = 1.45823 (* 1 = 1.45823 loss)
I0521 19:33:14.886546 17204 sgd_solver.cpp:106] Iteration 343500, lr = 0.0045
I0521 19:33:32.054028 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_345000.caffemodel
I0521 19:33:32.100929 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_345000.solverstate
I0521 19:33:32.129994 17204 solver.cpp:237] Iteration 345000, loss = 0.770708
I0521 19:33:32.130043 17204 solver.cpp:253]     Train net output #0: loss = 0.770711 (* 1 = 0.770711 loss)
I0521 19:33:32.130059 17204 sgd_solver.cpp:106] Iteration 345000, lr = 0.0045
I0521 19:33:49.318477 17204 solver.cpp:237] Iteration 346500, loss = 1.13933
I0521 19:33:49.318650 17204 solver.cpp:253]     Train net output #0: loss = 1.13933 (* 1 = 1.13933 loss)
I0521 19:33:49.318665 17204 sgd_solver.cpp:106] Iteration 346500, lr = 0.0045
I0521 19:34:06.525912 17204 solver.cpp:237] Iteration 348000, loss = 1.39416
I0521 19:34:06.525961 17204 solver.cpp:253]     Train net output #0: loss = 1.39416 (* 1 = 1.39416 loss)
I0521 19:34:06.525975 17204 sgd_solver.cpp:106] Iteration 348000, lr = 0.0045
I0521 19:34:23.674831 17204 solver.cpp:237] Iteration 349500, loss = 1.0414
I0521 19:34:23.675005 17204 solver.cpp:253]     Train net output #0: loss = 1.0414 (* 1 = 1.0414 loss)
I0521 19:34:23.675019 17204 sgd_solver.cpp:106] Iteration 349500, lr = 0.0045
I0521 19:35:01.725381 17204 solver.cpp:237] Iteration 351000, loss = 1.63811
I0521 19:35:01.725561 17204 solver.cpp:253]     Train net output #0: loss = 1.63811 (* 1 = 1.63811 loss)
I0521 19:35:01.725575 17204 sgd_solver.cpp:106] Iteration 351000, lr = 0.0045
I0521 19:35:18.915431 17204 solver.cpp:237] Iteration 352500, loss = 0.452941
I0521 19:35:18.915467 17204 solver.cpp:253]     Train net output #0: loss = 0.452943 (* 1 = 0.452943 loss)
I0521 19:35:18.915482 17204 sgd_solver.cpp:106] Iteration 352500, lr = 0.0045
I0521 19:35:36.133399 17204 solver.cpp:237] Iteration 354000, loss = 1.40076
I0521 19:35:36.133566 17204 solver.cpp:253]     Train net output #0: loss = 1.40076 (* 1 = 1.40076 loss)
I0521 19:35:36.133580 17204 sgd_solver.cpp:106] Iteration 354000, lr = 0.0045
I0521 19:35:53.281620 17204 solver.cpp:237] Iteration 355500, loss = 1.07146
I0521 19:35:53.281663 17204 solver.cpp:253]     Train net output #0: loss = 1.07147 (* 1 = 1.07147 loss)
I0521 19:35:53.281677 17204 sgd_solver.cpp:106] Iteration 355500, lr = 0.0045
I0521 19:36:10.455893 17204 solver.cpp:237] Iteration 357000, loss = 1.17928
I0521 19:36:10.456048 17204 solver.cpp:253]     Train net output #0: loss = 1.17928 (* 1 = 1.17928 loss)
I0521 19:36:10.456063 17204 sgd_solver.cpp:106] Iteration 357000, lr = 0.0045
I0521 19:36:27.660106 17204 solver.cpp:237] Iteration 358500, loss = 0.810438
I0521 19:36:27.660152 17204 solver.cpp:253]     Train net output #0: loss = 0.810441 (* 1 = 0.810441 loss)
I0521 19:36:27.660166 17204 sgd_solver.cpp:106] Iteration 358500, lr = 0.0045
I0521 19:36:44.850942 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_360000.caffemodel
I0521 19:36:44.896800 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_360000.solverstate
I0521 19:36:44.921916 17204 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 19:38:05.408015 17204 solver.cpp:409]     Test net output #0: accuracy = 0.875918
I0521 19:38:05.408195 17204 solver.cpp:409]     Test net output #1: loss = 0.46208 (* 1 = 0.46208 loss)
I0521 19:38:26.306828 17204 solver.cpp:237] Iteration 360000, loss = 1.23629
I0521 19:38:26.306881 17204 solver.cpp:253]     Train net output #0: loss = 1.23629 (* 1 = 1.23629 loss)
I0521 19:38:26.306897 17204 sgd_solver.cpp:106] Iteration 360000, lr = 0.0045
I0521 19:38:43.165098 17204 solver.cpp:237] Iteration 361500, loss = 1.09075
I0521 19:38:43.165274 17204 solver.cpp:253]     Train net output #0: loss = 1.09075 (* 1 = 1.09075 loss)
I0521 19:38:43.165288 17204 sgd_solver.cpp:106] Iteration 361500, lr = 0.0045
I0521 19:39:00.028259 17204 solver.cpp:237] Iteration 363000, loss = 1.43244
I0521 19:39:00.028293 17204 solver.cpp:253]     Train net output #0: loss = 1.43244 (* 1 = 1.43244 loss)
I0521 19:39:00.028311 17204 sgd_solver.cpp:106] Iteration 363000, lr = 0.0045
I0521 19:39:16.829424 17204 solver.cpp:237] Iteration 364500, loss = 0.900656
I0521 19:39:16.829599 17204 solver.cpp:253]     Train net output #0: loss = 0.900658 (* 1 = 0.900658 loss)
I0521 19:39:16.829615 17204 sgd_solver.cpp:106] Iteration 364500, lr = 0.0045
I0521 19:39:33.655643 17204 solver.cpp:237] Iteration 366000, loss = 0.383259
I0521 19:39:33.655684 17204 solver.cpp:253]     Train net output #0: loss = 0.383262 (* 1 = 0.383262 loss)
I0521 19:39:33.655709 17204 sgd_solver.cpp:106] Iteration 366000, lr = 0.0045
I0521 19:39:50.520038 17204 solver.cpp:237] Iteration 367500, loss = 1.01929
I0521 19:39:50.520197 17204 solver.cpp:253]     Train net output #0: loss = 1.01929 (* 1 = 1.01929 loss)
I0521 19:39:50.520210 17204 sgd_solver.cpp:106] Iteration 367500, lr = 0.0045
I0521 19:40:07.379628 17204 solver.cpp:237] Iteration 369000, loss = 1.09427
I0521 19:40:07.379676 17204 solver.cpp:253]     Train net output #0: loss = 1.09427 (* 1 = 1.09427 loss)
I0521 19:40:07.379690 17204 sgd_solver.cpp:106] Iteration 369000, lr = 0.0045
I0521 19:40:45.110958 17204 solver.cpp:237] Iteration 370500, loss = 1.29077
I0521 19:40:45.111150 17204 solver.cpp:253]     Train net output #0: loss = 1.29078 (* 1 = 1.29078 loss)
I0521 19:40:45.111165 17204 sgd_solver.cpp:106] Iteration 370500, lr = 0.0045
I0521 19:41:02.004869 17204 solver.cpp:237] Iteration 372000, loss = 1.49586
I0521 19:41:02.004916 17204 solver.cpp:253]     Train net output #0: loss = 1.49587 (* 1 = 1.49587 loss)
I0521 19:41:02.004931 17204 sgd_solver.cpp:106] Iteration 372000, lr = 0.0045
I0521 19:41:18.907965 17204 solver.cpp:237] Iteration 373500, loss = 0.596482
I0521 19:41:18.908145 17204 solver.cpp:253]     Train net output #0: loss = 0.596485 (* 1 = 0.596485 loss)
I0521 19:41:18.908159 17204 sgd_solver.cpp:106] Iteration 373500, lr = 0.0045
I0521 19:41:35.744407 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_375000.caffemodel
I0521 19:41:35.792101 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_375000.solverstate
I0521 19:41:35.822638 17204 solver.cpp:237] Iteration 375000, loss = 1.17611
I0521 19:41:35.822688 17204 solver.cpp:253]     Train net output #0: loss = 1.17611 (* 1 = 1.17611 loss)
I0521 19:41:35.822702 17204 sgd_solver.cpp:106] Iteration 375000, lr = 0.0045
I0521 19:41:52.656182 17204 solver.cpp:237] Iteration 376500, loss = 1.69895
I0521 19:41:52.656361 17204 solver.cpp:253]     Train net output #0: loss = 1.69895 (* 1 = 1.69895 loss)
I0521 19:41:52.656374 17204 sgd_solver.cpp:106] Iteration 376500, lr = 0.0045
I0521 19:42:09.538645 17204 solver.cpp:237] Iteration 378000, loss = 1.23212
I0521 19:42:09.538691 17204 solver.cpp:253]     Train net output #0: loss = 1.23213 (* 1 = 1.23213 loss)
I0521 19:42:09.538704 17204 sgd_solver.cpp:106] Iteration 378000, lr = 0.0045
I0521 19:42:26.407086 17204 solver.cpp:237] Iteration 379500, loss = 0.777387
I0521 19:42:26.407351 17204 solver.cpp:253]     Train net output #0: loss = 0.777391 (* 1 = 0.777391 loss)
I0521 19:42:26.407366 17204 sgd_solver.cpp:106] Iteration 379500, lr = 0.0045
I0521 19:43:04.139755 17204 solver.cpp:237] Iteration 381000, loss = 0.988101
I0521 19:43:04.139935 17204 solver.cpp:253]     Train net output #0: loss = 0.988104 (* 1 = 0.988104 loss)
I0521 19:43:04.139950 17204 sgd_solver.cpp:106] Iteration 381000, lr = 0.0045
I0521 19:43:20.994472 17204 solver.cpp:237] Iteration 382500, loss = 1.09436
I0521 19:43:20.994520 17204 solver.cpp:253]     Train net output #0: loss = 1.09436 (* 1 = 1.09436 loss)
I0521 19:43:20.994534 17204 sgd_solver.cpp:106] Iteration 382500, lr = 0.0045
I0521 19:43:37.864259 17204 solver.cpp:237] Iteration 384000, loss = 0.710502
I0521 19:43:37.864424 17204 solver.cpp:253]     Train net output #0: loss = 0.710505 (* 1 = 0.710505 loss)
I0521 19:43:37.864439 17204 sgd_solver.cpp:106] Iteration 384000, lr = 0.0045
I0521 19:43:54.780982 17204 solver.cpp:237] Iteration 385500, loss = 2.69806
I0521 19:43:54.781028 17204 solver.cpp:253]     Train net output #0: loss = 2.69806 (* 1 = 2.69806 loss)
I0521 19:43:54.781043 17204 sgd_solver.cpp:106] Iteration 385500, lr = 0.0045
I0521 19:44:11.643847 17204 solver.cpp:237] Iteration 387000, loss = 0.939562
I0521 19:44:11.644026 17204 solver.cpp:253]     Train net output #0: loss = 0.939563 (* 1 = 0.939563 loss)
I0521 19:44:11.644039 17204 sgd_solver.cpp:106] Iteration 387000, lr = 0.0045
I0521 19:44:28.560134 17204 solver.cpp:237] Iteration 388500, loss = 1.1144
I0521 19:44:28.560170 17204 solver.cpp:253]     Train net output #0: loss = 1.1144 (* 1 = 1.1144 loss)
I0521 19:44:28.560184 17204 sgd_solver.cpp:106] Iteration 388500, lr = 0.0045
I0521 19:44:45.419806 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_390000.caffemodel
I0521 19:44:45.465420 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_390000.solverstate
I0521 19:44:45.490572 17204 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 19:45:45.097148 17204 solver.cpp:409]     Test net output #0: accuracy = 0.88266
I0521 19:45:45.097332 17204 solver.cpp:409]     Test net output #1: loss = 0.402505 (* 1 = 0.402505 loss)
I0521 19:46:05.967411 17204 solver.cpp:237] Iteration 390000, loss = 0.896415
I0521 19:46:05.967464 17204 solver.cpp:253]     Train net output #0: loss = 0.896417 (* 1 = 0.896417 loss)
I0521 19:46:05.967480 17204 sgd_solver.cpp:106] Iteration 390000, lr = 0.0045
I0521 19:46:23.181016 17204 solver.cpp:237] Iteration 391500, loss = 1.3775
I0521 19:46:23.181195 17204 solver.cpp:253]     Train net output #0: loss = 1.3775 (* 1 = 1.3775 loss)
I0521 19:46:23.181208 17204 sgd_solver.cpp:106] Iteration 391500, lr = 0.0045
I0521 19:46:40.366153 17204 solver.cpp:237] Iteration 393000, loss = 1.27469
I0521 19:46:40.366194 17204 solver.cpp:253]     Train net output #0: loss = 1.27469 (* 1 = 1.27469 loss)
I0521 19:46:40.366212 17204 sgd_solver.cpp:106] Iteration 393000, lr = 0.0045
I0521 19:46:57.546128 17204 solver.cpp:237] Iteration 394500, loss = 1.95226
I0521 19:46:57.546290 17204 solver.cpp:253]     Train net output #0: loss = 1.95227 (* 1 = 1.95227 loss)
I0521 19:46:57.546304 17204 sgd_solver.cpp:106] Iteration 394500, lr = 0.0045
I0521 19:47:14.708207 17204 solver.cpp:237] Iteration 396000, loss = 0.790303
I0521 19:47:14.708256 17204 solver.cpp:253]     Train net output #0: loss = 0.790305 (* 1 = 0.790305 loss)
I0521 19:47:14.708269 17204 sgd_solver.cpp:106] Iteration 396000, lr = 0.0045
I0521 19:47:31.887878 17204 solver.cpp:237] Iteration 397500, loss = 1.47466
I0521 19:47:31.888056 17204 solver.cpp:253]     Train net output #0: loss = 1.47467 (* 1 = 1.47467 loss)
I0521 19:47:31.888069 17204 sgd_solver.cpp:106] Iteration 397500, lr = 0.0045
I0521 19:47:49.041064 17204 solver.cpp:237] Iteration 399000, loss = 0.927059
I0521 19:47:49.041101 17204 solver.cpp:253]     Train net output #0: loss = 0.927061 (* 1 = 0.927061 loss)
I0521 19:47:49.041115 17204 sgd_solver.cpp:106] Iteration 399000, lr = 0.0045
I0521 19:48:27.163033 17204 solver.cpp:237] Iteration 400500, loss = 1.14906
I0521 19:48:27.163219 17204 solver.cpp:253]     Train net output #0: loss = 1.14906 (* 1 = 1.14906 loss)
I0521 19:48:27.163233 17204 sgd_solver.cpp:106] Iteration 400500, lr = 0.0045
I0521 19:48:44.362368 17204 solver.cpp:237] Iteration 402000, loss = 0.867743
I0521 19:48:44.362418 17204 solver.cpp:253]     Train net output #0: loss = 0.867746 (* 1 = 0.867746 loss)
I0521 19:48:44.362432 17204 sgd_solver.cpp:106] Iteration 402000, lr = 0.0045
I0521 19:49:01.549363 17204 solver.cpp:237] Iteration 403500, loss = 1.20917
I0521 19:49:01.549525 17204 solver.cpp:253]     Train net output #0: loss = 1.20917 (* 1 = 1.20917 loss)
I0521 19:49:01.549538 17204 sgd_solver.cpp:106] Iteration 403500, lr = 0.0045
I0521 19:49:18.691876 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_405000.caffemodel
I0521 19:49:18.737797 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_405000.solverstate
I0521 19:49:18.766362 17204 solver.cpp:237] Iteration 405000, loss = 1.59025
I0521 19:49:18.766407 17204 solver.cpp:253]     Train net output #0: loss = 1.59026 (* 1 = 1.59026 loss)
I0521 19:49:18.766422 17204 sgd_solver.cpp:106] Iteration 405000, lr = 0.0045
I0521 19:49:35.941694 17204 solver.cpp:237] Iteration 406500, loss = 1.22243
I0521 19:49:35.941884 17204 solver.cpp:253]     Train net output #0: loss = 1.22244 (* 1 = 1.22244 loss)
I0521 19:49:35.941897 17204 sgd_solver.cpp:106] Iteration 406500, lr = 0.0045
I0521 19:49:53.117612 17204 solver.cpp:237] Iteration 408000, loss = 0.569586
I0521 19:49:53.117650 17204 solver.cpp:253]     Train net output #0: loss = 0.56959 (* 1 = 0.56959 loss)
I0521 19:49:53.117663 17204 sgd_solver.cpp:106] Iteration 408000, lr = 0.0045
I0521 19:50:10.332201 17204 solver.cpp:237] Iteration 409500, loss = 1.37956
I0521 19:50:10.332381 17204 solver.cpp:253]     Train net output #0: loss = 1.37957 (* 1 = 1.37957 loss)
I0521 19:50:10.332396 17204 sgd_solver.cpp:106] Iteration 409500, lr = 0.0045
I0521 19:50:48.341162 17204 solver.cpp:237] Iteration 411000, loss = 1.32731
I0521 19:50:48.341348 17204 solver.cpp:253]     Train net output #0: loss = 1.32731 (* 1 = 1.32731 loss)
I0521 19:50:48.341362 17204 sgd_solver.cpp:106] Iteration 411000, lr = 0.0045
I0521 19:51:05.520979 17204 solver.cpp:237] Iteration 412500, loss = 1.34626
I0521 19:51:05.521015 17204 solver.cpp:253]     Train net output #0: loss = 1.34627 (* 1 = 1.34627 loss)
I0521 19:51:05.521028 17204 sgd_solver.cpp:106] Iteration 412500, lr = 0.0045
I0521 19:51:22.740813 17204 solver.cpp:237] Iteration 414000, loss = 1.59827
I0521 19:51:22.740986 17204 solver.cpp:253]     Train net output #0: loss = 1.59827 (* 1 = 1.59827 loss)
I0521 19:51:22.740999 17204 sgd_solver.cpp:106] Iteration 414000, lr = 0.0045
I0521 19:51:39.905221 17204 solver.cpp:237] Iteration 415500, loss = 1.47536
I0521 19:51:39.905262 17204 solver.cpp:253]     Train net output #0: loss = 1.47536 (* 1 = 1.47536 loss)
I0521 19:51:39.905282 17204 sgd_solver.cpp:106] Iteration 415500, lr = 0.0045
I0521 19:51:57.094295 17204 solver.cpp:237] Iteration 417000, loss = 1.13342
I0521 19:51:57.094460 17204 solver.cpp:253]     Train net output #0: loss = 1.13342 (* 1 = 1.13342 loss)
I0521 19:51:57.094472 17204 sgd_solver.cpp:106] Iteration 417000, lr = 0.0045
I0521 19:52:14.270784 17204 solver.cpp:237] Iteration 418500, loss = 2.13049
I0521 19:52:14.270831 17204 solver.cpp:253]     Train net output #0: loss = 2.1305 (* 1 = 2.1305 loss)
I0521 19:52:14.270845 17204 sgd_solver.cpp:106] Iteration 418500, lr = 0.0045
I0521 19:52:31.453367 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_420000.caffemodel
I0521 19:52:31.499222 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_420000.solverstate
I0521 19:52:31.524160 17204 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 19:53:52.029464 17204 solver.cpp:409]     Test net output #0: accuracy = 0.8798
I0521 19:53:52.029647 17204 solver.cpp:409]     Test net output #1: loss = 0.394854 (* 1 = 0.394854 loss)
I0521 19:54:12.926573 17204 solver.cpp:237] Iteration 420000, loss = 1.65055
I0521 19:54:12.926626 17204 solver.cpp:253]     Train net output #0: loss = 1.65055 (* 1 = 1.65055 loss)
I0521 19:54:12.926642 17204 sgd_solver.cpp:106] Iteration 420000, lr = 0.0045
I0521 19:54:29.960569 17204 solver.cpp:237] Iteration 421500, loss = 1.33958
I0521 19:54:29.960741 17204 solver.cpp:253]     Train net output #0: loss = 1.33958 (* 1 = 1.33958 loss)
I0521 19:54:29.960755 17204 sgd_solver.cpp:106] Iteration 421500, lr = 0.0045
I0521 19:54:46.989188 17204 solver.cpp:237] Iteration 423000, loss = 1.61358
I0521 19:54:46.989238 17204 solver.cpp:253]     Train net output #0: loss = 1.61359 (* 1 = 1.61359 loss)
I0521 19:54:46.989253 17204 sgd_solver.cpp:106] Iteration 423000, lr = 0.0045
I0521 19:55:04.054770 17204 solver.cpp:237] Iteration 424500, loss = 1.05542
I0521 19:55:04.054944 17204 solver.cpp:253]     Train net output #0: loss = 1.05542 (* 1 = 1.05542 loss)
I0521 19:55:04.054956 17204 sgd_solver.cpp:106] Iteration 424500, lr = 0.0045
I0521 19:55:21.047284 17204 solver.cpp:237] Iteration 426000, loss = 0.859569
I0521 19:55:21.047322 17204 solver.cpp:253]     Train net output #0: loss = 0.859573 (* 1 = 0.859573 loss)
I0521 19:55:21.047346 17204 sgd_solver.cpp:106] Iteration 426000, lr = 0.0045
I0521 19:55:38.091461 17204 solver.cpp:237] Iteration 427500, loss = 1.68471
I0521 19:55:38.091634 17204 solver.cpp:253]     Train net output #0: loss = 1.68471 (* 1 = 1.68471 loss)
I0521 19:55:38.091646 17204 sgd_solver.cpp:106] Iteration 427500, lr = 0.0045
I0521 19:55:55.127568 17204 solver.cpp:237] Iteration 429000, loss = 1.02993
I0521 19:55:55.127609 17204 solver.cpp:253]     Train net output #0: loss = 1.02993 (* 1 = 1.02993 loss)
I0521 19:55:55.127624 17204 sgd_solver.cpp:106] Iteration 429000, lr = 0.0045
I0521 19:56:33.102514 17204 solver.cpp:237] Iteration 430500, loss = 0.712366
I0521 19:56:33.102699 17204 solver.cpp:253]     Train net output #0: loss = 0.712369 (* 1 = 0.712369 loss)
I0521 19:56:33.102713 17204 sgd_solver.cpp:106] Iteration 430500, lr = 0.0045
I0521 19:56:50.149248 17204 solver.cpp:237] Iteration 432000, loss = 0.882404
I0521 19:56:50.149299 17204 solver.cpp:253]     Train net output #0: loss = 0.882407 (* 1 = 0.882407 loss)
I0521 19:56:50.149313 17204 sgd_solver.cpp:106] Iteration 432000, lr = 0.0045
I0521 19:57:07.187257 17204 solver.cpp:237] Iteration 433500, loss = 1.28803
I0521 19:57:07.187433 17204 solver.cpp:253]     Train net output #0: loss = 1.28803 (* 1 = 1.28803 loss)
I0521 19:57:07.187448 17204 sgd_solver.cpp:106] Iteration 433500, lr = 0.0045
I0521 19:57:24.210064 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_435000.caffemodel
I0521 19:57:24.258420 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_435000.solverstate
I0521 19:57:24.289504 17204 solver.cpp:237] Iteration 435000, loss = 3.72678
I0521 19:57:24.289549 17204 solver.cpp:253]     Train net output #0: loss = 3.72678 (* 1 = 3.72678 loss)
I0521 19:57:24.289563 17204 sgd_solver.cpp:106] Iteration 435000, lr = 0.0045
I0521 19:57:41.352686 17204 solver.cpp:237] Iteration 436500, loss = 1.4726
I0521 19:57:41.352867 17204 solver.cpp:253]     Train net output #0: loss = 1.4726 (* 1 = 1.4726 loss)
I0521 19:57:41.352881 17204 sgd_solver.cpp:106] Iteration 436500, lr = 0.0045
I0521 19:57:58.403566 17204 solver.cpp:237] Iteration 438000, loss = 2.02001
I0521 19:57:58.403616 17204 solver.cpp:253]     Train net output #0: loss = 2.02001 (* 1 = 2.02001 loss)
I0521 19:57:58.403630 17204 sgd_solver.cpp:106] Iteration 438000, lr = 0.0045
I0521 19:58:15.440480 17204 solver.cpp:237] Iteration 439500, loss = 1.74113
I0521 19:58:15.440649 17204 solver.cpp:253]     Train net output #0: loss = 1.74113 (* 1 = 1.74113 loss)
I0521 19:58:15.440664 17204 sgd_solver.cpp:106] Iteration 439500, lr = 0.0045
I0521 19:58:53.400060 17204 solver.cpp:237] Iteration 441000, loss = 0.784281
I0521 19:58:53.400248 17204 solver.cpp:253]     Train net output #0: loss = 0.784285 (* 1 = 0.784285 loss)
I0521 19:58:53.400261 17204 sgd_solver.cpp:106] Iteration 441000, lr = 0.0045
I0521 19:59:10.240296 17204 solver.cpp:237] Iteration 442500, loss = 1.69446
I0521 19:59:10.240339 17204 solver.cpp:253]     Train net output #0: loss = 1.69446 (* 1 = 1.69446 loss)
I0521 19:59:10.240356 17204 sgd_solver.cpp:106] Iteration 442500, lr = 0.0045
I0521 19:59:27.011425 17204 solver.cpp:237] Iteration 444000, loss = 1.07708
I0521 19:59:27.011592 17204 solver.cpp:253]     Train net output #0: loss = 1.07708 (* 1 = 1.07708 loss)
I0521 19:59:27.011605 17204 sgd_solver.cpp:106] Iteration 444000, lr = 0.0045
I0521 19:59:43.801242 17204 solver.cpp:237] Iteration 445500, loss = 1.46843
I0521 19:59:43.801292 17204 solver.cpp:253]     Train net output #0: loss = 1.46844 (* 1 = 1.46844 loss)
I0521 19:59:43.801306 17204 sgd_solver.cpp:106] Iteration 445500, lr = 0.0045
I0521 20:00:00.581115 17204 solver.cpp:237] Iteration 447000, loss = 0.88122
I0521 20:00:00.581301 17204 solver.cpp:253]     Train net output #0: loss = 0.881226 (* 1 = 0.881226 loss)
I0521 20:00:00.581315 17204 sgd_solver.cpp:106] Iteration 447000, lr = 0.0045
I0521 20:00:17.360007 17204 solver.cpp:237] Iteration 448500, loss = 1.31789
I0521 20:00:17.360043 17204 solver.cpp:253]     Train net output #0: loss = 1.3179 (* 1 = 1.3179 loss)
I0521 20:00:17.360055 17204 sgd_solver.cpp:106] Iteration 448500, lr = 0.0045
I0521 20:00:34.132040 17204 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_450000.caffemodel
I0521 20:00:34.179731 17204 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0045_2016-05-20T15.48.52.465324_iter_450000.solverstate
I0521 20:00:34.207047 17204 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 20:01:33.209846 17204 solver.cpp:409]     Test net output #0: accuracy = 0.883925
I0521 20:01:33.210032 17204 solver.cpp:409]     Test net output #1: loss = 0.368164 (* 1 = 0.368164 loss)
I0521 20:01:54.080056 17204 solver.cpp:237] Iteration 450000, loss = 1.46656
I0521 20:01:54.080109 17204 solver.cpp:253]     Train net output #0: loss = 1.46657 (* 1 = 1.46657 loss)
I0521 20:01:54.080124 17204 sgd_solver.cpp:106] Iteration 450000, lr = 0.0045
=>> PBS: job killed: walltime 7205 exceeded limit 7200
aprun: Apid 11240804: Caught signal Terminated, sending to application
*** Aborted at 1463875326 (unix time) try "date -d @1463875326" if you are using GNU date ***
PC: @     0x2aaab930eb5c (unknown)
*** SIGTERM (@0x4331) received by PID 17204 (TID 0x2aaac746f900) from PID 17201; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab930eb5c (unknown)
    @     0x2aaab928a408 (unknown)
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11240804: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11240804: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
aprun: Apid 11240804: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 00811] [c2-1c0s5n3] [Sat May 21 20:02:08 2016] PE RANK 0 exit signal Terminated
Application 11240804 exit codes: 143
Application 11240804 resources: utime ~6319s, stime ~878s, Rss ~5331796, inblocks ~10478902, outblocks ~474916
