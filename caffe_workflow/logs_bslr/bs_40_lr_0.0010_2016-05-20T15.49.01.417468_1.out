2807741
I0522 17:50:41.384969 12758 caffe.cpp:184] Using GPUs 0
I0522 17:50:41.810096 12758 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.001
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468.prototxt"
I0522 17:50:41.811748 12758 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468.prototxt
I0522 17:50:41.828090 12758 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 17:50:41.828156 12758 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 17:50:41.828534 12758 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 17:50:41.828742 12758 layer_factory.hpp:77] Creating layer data_hdf5
I0522 17:50:41.828768 12758 net.cpp:106] Creating Layer data_hdf5
I0522 17:50:41.828788 12758 net.cpp:411] data_hdf5 -> data
I0522 17:50:41.828827 12758 net.cpp:411] data_hdf5 -> label
I0522 17:50:41.828861 12758 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 17:50:41.846608 12758 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 17:50:41.863106 12758 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 17:51:03.464360 12758 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 17:51:03.469625 12758 net.cpp:150] Setting up data_hdf5
I0522 17:51:03.469666 12758 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 17:51:03.469684 12758 net.cpp:157] Top shape: 40 (40)
I0522 17:51:03.469697 12758 net.cpp:165] Memory required for data: 1016160
I0522 17:51:03.469717 12758 layer_factory.hpp:77] Creating layer conv1
I0522 17:51:03.469763 12758 net.cpp:106] Creating Layer conv1
I0522 17:51:03.469777 12758 net.cpp:454] conv1 <- data
I0522 17:51:03.469802 12758 net.cpp:411] conv1 -> conv1
I0522 17:51:06.514848 12758 net.cpp:150] Setting up conv1
I0522 17:51:06.514904 12758 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 17:51:06.514928 12758 net.cpp:165] Memory required for data: 12075360
I0522 17:51:06.514960 12758 layer_factory.hpp:77] Creating layer relu1
I0522 17:51:06.514981 12758 net.cpp:106] Creating Layer relu1
I0522 17:51:06.514996 12758 net.cpp:454] relu1 <- conv1
I0522 17:51:06.515017 12758 net.cpp:397] relu1 -> conv1 (in-place)
I0522 17:51:06.515573 12758 net.cpp:150] Setting up relu1
I0522 17:51:06.515595 12758 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 17:51:06.515609 12758 net.cpp:165] Memory required for data: 23134560
I0522 17:51:06.515625 12758 layer_factory.hpp:77] Creating layer pool1
I0522 17:51:06.515652 12758 net.cpp:106] Creating Layer pool1
I0522 17:51:06.515666 12758 net.cpp:454] pool1 <- conv1
I0522 17:51:06.515682 12758 net.cpp:411] pool1 -> pool1
I0522 17:51:06.515777 12758 net.cpp:150] Setting up pool1
I0522 17:51:06.515795 12758 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 17:51:06.515810 12758 net.cpp:165] Memory required for data: 28664160
I0522 17:51:06.515832 12758 layer_factory.hpp:77] Creating layer conv2
I0522 17:51:06.515856 12758 net.cpp:106] Creating Layer conv2
I0522 17:51:06.515869 12758 net.cpp:454] conv2 <- pool1
I0522 17:51:06.515885 12758 net.cpp:411] conv2 -> conv2
I0522 17:51:06.518587 12758 net.cpp:150] Setting up conv2
I0522 17:51:06.518618 12758 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 17:51:06.518635 12758 net.cpp:165] Memory required for data: 36612960
I0522 17:51:06.518657 12758 layer_factory.hpp:77] Creating layer relu2
I0522 17:51:06.518689 12758 net.cpp:106] Creating Layer relu2
I0522 17:51:06.518704 12758 net.cpp:454] relu2 <- conv2
I0522 17:51:06.518721 12758 net.cpp:397] relu2 -> conv2 (in-place)
I0522 17:51:06.519078 12758 net.cpp:150] Setting up relu2
I0522 17:51:06.519098 12758 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 17:51:06.519111 12758 net.cpp:165] Memory required for data: 44561760
I0522 17:51:06.519124 12758 layer_factory.hpp:77] Creating layer pool2
I0522 17:51:06.519148 12758 net.cpp:106] Creating Layer pool2
I0522 17:51:06.519162 12758 net.cpp:454] pool2 <- conv2
I0522 17:51:06.519179 12758 net.cpp:411] pool2 -> pool2
I0522 17:51:06.519275 12758 net.cpp:150] Setting up pool2
I0522 17:51:06.519292 12758 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 17:51:06.519309 12758 net.cpp:165] Memory required for data: 48536160
I0522 17:51:06.519326 12758 layer_factory.hpp:77] Creating layer conv3
I0522 17:51:06.519347 12758 net.cpp:106] Creating Layer conv3
I0522 17:51:06.519361 12758 net.cpp:454] conv3 <- pool2
I0522 17:51:06.519377 12758 net.cpp:411] conv3 -> conv3
I0522 17:51:06.521355 12758 net.cpp:150] Setting up conv3
I0522 17:51:06.521379 12758 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 17:51:06.521400 12758 net.cpp:165] Memory required for data: 52872800
I0522 17:51:06.521423 12758 layer_factory.hpp:77] Creating layer relu3
I0522 17:51:06.521445 12758 net.cpp:106] Creating Layer relu3
I0522 17:51:06.521458 12758 net.cpp:454] relu3 <- conv3
I0522 17:51:06.521483 12758 net.cpp:397] relu3 -> conv3 (in-place)
I0522 17:51:06.521972 12758 net.cpp:150] Setting up relu3
I0522 17:51:06.521996 12758 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 17:51:06.522009 12758 net.cpp:165] Memory required for data: 57209440
I0522 17:51:06.522025 12758 layer_factory.hpp:77] Creating layer pool3
I0522 17:51:06.522042 12758 net.cpp:106] Creating Layer pool3
I0522 17:51:06.522055 12758 net.cpp:454] pool3 <- conv3
I0522 17:51:06.522080 12758 net.cpp:411] pool3 -> pool3
I0522 17:51:06.522162 12758 net.cpp:150] Setting up pool3
I0522 17:51:06.522186 12758 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 17:51:06.522197 12758 net.cpp:165] Memory required for data: 59377760
I0522 17:51:06.522212 12758 layer_factory.hpp:77] Creating layer conv4
I0522 17:51:06.522233 12758 net.cpp:106] Creating Layer conv4
I0522 17:51:06.522245 12758 net.cpp:454] conv4 <- pool3
I0522 17:51:06.522269 12758 net.cpp:411] conv4 -> conv4
I0522 17:51:06.525074 12758 net.cpp:150] Setting up conv4
I0522 17:51:06.525105 12758 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 17:51:06.525120 12758 net.cpp:165] Memory required for data: 60829280
I0522 17:51:06.525141 12758 layer_factory.hpp:77] Creating layer relu4
I0522 17:51:06.525161 12758 net.cpp:106] Creating Layer relu4
I0522 17:51:06.525187 12758 net.cpp:454] relu4 <- conv4
I0522 17:51:06.525203 12758 net.cpp:397] relu4 -> conv4 (in-place)
I0522 17:51:06.525703 12758 net.cpp:150] Setting up relu4
I0522 17:51:06.525727 12758 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 17:51:06.525740 12758 net.cpp:165] Memory required for data: 62280800
I0522 17:51:06.525756 12758 layer_factory.hpp:77] Creating layer pool4
I0522 17:51:06.525773 12758 net.cpp:106] Creating Layer pool4
I0522 17:51:06.525794 12758 net.cpp:454] pool4 <- conv4
I0522 17:51:06.525810 12758 net.cpp:411] pool4 -> pool4
I0522 17:51:06.525893 12758 net.cpp:150] Setting up pool4
I0522 17:51:06.525914 12758 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 17:51:06.525928 12758 net.cpp:165] Memory required for data: 63006560
I0522 17:51:06.525940 12758 layer_factory.hpp:77] Creating layer ip1
I0522 17:51:06.525965 12758 net.cpp:106] Creating Layer ip1
I0522 17:51:06.525979 12758 net.cpp:454] ip1 <- pool4
I0522 17:51:06.526000 12758 net.cpp:411] ip1 -> ip1
I0522 17:51:06.541456 12758 net.cpp:150] Setting up ip1
I0522 17:51:06.541488 12758 net.cpp:157] Top shape: 40 196 (7840)
I0522 17:51:06.541512 12758 net.cpp:165] Memory required for data: 63037920
I0522 17:51:06.541538 12758 layer_factory.hpp:77] Creating layer relu5
I0522 17:51:06.541558 12758 net.cpp:106] Creating Layer relu5
I0522 17:51:06.541584 12758 net.cpp:454] relu5 <- ip1
I0522 17:51:06.541601 12758 net.cpp:397] relu5 -> ip1 (in-place)
I0522 17:51:06.541960 12758 net.cpp:150] Setting up relu5
I0522 17:51:06.541980 12758 net.cpp:157] Top shape: 40 196 (7840)
I0522 17:51:06.541993 12758 net.cpp:165] Memory required for data: 63069280
I0522 17:51:06.542006 12758 layer_factory.hpp:77] Creating layer drop1
I0522 17:51:06.542039 12758 net.cpp:106] Creating Layer drop1
I0522 17:51:06.542053 12758 net.cpp:454] drop1 <- ip1
I0522 17:51:06.542068 12758 net.cpp:397] drop1 -> ip1 (in-place)
I0522 17:51:06.542140 12758 net.cpp:150] Setting up drop1
I0522 17:51:06.542156 12758 net.cpp:157] Top shape: 40 196 (7840)
I0522 17:51:06.542171 12758 net.cpp:165] Memory required for data: 63100640
I0522 17:51:06.542182 12758 layer_factory.hpp:77] Creating layer ip2
I0522 17:51:06.542207 12758 net.cpp:106] Creating Layer ip2
I0522 17:51:06.542225 12758 net.cpp:454] ip2 <- ip1
I0522 17:51:06.542243 12758 net.cpp:411] ip2 -> ip2
I0522 17:51:06.542728 12758 net.cpp:150] Setting up ip2
I0522 17:51:06.542747 12758 net.cpp:157] Top shape: 40 98 (3920)
I0522 17:51:06.542760 12758 net.cpp:165] Memory required for data: 63116320
I0522 17:51:06.542780 12758 layer_factory.hpp:77] Creating layer relu6
I0522 17:51:06.542795 12758 net.cpp:106] Creating Layer relu6
I0522 17:51:06.542815 12758 net.cpp:454] relu6 <- ip2
I0522 17:51:06.542830 12758 net.cpp:397] relu6 -> ip2 (in-place)
I0522 17:51:06.543386 12758 net.cpp:150] Setting up relu6
I0522 17:51:06.543408 12758 net.cpp:157] Top shape: 40 98 (3920)
I0522 17:51:06.543422 12758 net.cpp:165] Memory required for data: 63132000
I0522 17:51:06.543439 12758 layer_factory.hpp:77] Creating layer drop2
I0522 17:51:06.543455 12758 net.cpp:106] Creating Layer drop2
I0522 17:51:06.543476 12758 net.cpp:454] drop2 <- ip2
I0522 17:51:06.543493 12758 net.cpp:397] drop2 -> ip2 (in-place)
I0522 17:51:06.543541 12758 net.cpp:150] Setting up drop2
I0522 17:51:06.543565 12758 net.cpp:157] Top shape: 40 98 (3920)
I0522 17:51:06.543578 12758 net.cpp:165] Memory required for data: 63147680
I0522 17:51:06.543596 12758 layer_factory.hpp:77] Creating layer ip3
I0522 17:51:06.543612 12758 net.cpp:106] Creating Layer ip3
I0522 17:51:06.543625 12758 net.cpp:454] ip3 <- ip2
I0522 17:51:06.543643 12758 net.cpp:411] ip3 -> ip3
I0522 17:51:06.543874 12758 net.cpp:150] Setting up ip3
I0522 17:51:06.543894 12758 net.cpp:157] Top shape: 40 11 (440)
I0522 17:51:06.543906 12758 net.cpp:165] Memory required for data: 63149440
I0522 17:51:06.543927 12758 layer_factory.hpp:77] Creating layer drop3
I0522 17:51:06.543967 12758 net.cpp:106] Creating Layer drop3
I0522 17:51:06.543980 12758 net.cpp:454] drop3 <- ip3
I0522 17:51:06.543995 12758 net.cpp:397] drop3 -> ip3 (in-place)
I0522 17:51:06.544049 12758 net.cpp:150] Setting up drop3
I0522 17:51:06.544064 12758 net.cpp:157] Top shape: 40 11 (440)
I0522 17:51:06.544080 12758 net.cpp:165] Memory required for data: 63151200
I0522 17:51:06.544091 12758 layer_factory.hpp:77] Creating layer loss
I0522 17:51:06.544116 12758 net.cpp:106] Creating Layer loss
I0522 17:51:06.544136 12758 net.cpp:454] loss <- ip3
I0522 17:51:06.544150 12758 net.cpp:454] loss <- label
I0522 17:51:06.544173 12758 net.cpp:411] loss -> loss
I0522 17:51:06.544193 12758 layer_factory.hpp:77] Creating layer loss
I0522 17:51:06.544860 12758 net.cpp:150] Setting up loss
I0522 17:51:06.544883 12758 net.cpp:157] Top shape: (1)
I0522 17:51:06.544899 12758 net.cpp:160]     with loss weight 1
I0522 17:51:06.544951 12758 net.cpp:165] Memory required for data: 63151204
I0522 17:51:06.544975 12758 net.cpp:226] loss needs backward computation.
I0522 17:51:06.544989 12758 net.cpp:226] drop3 needs backward computation.
I0522 17:51:06.545001 12758 net.cpp:226] ip3 needs backward computation.
I0522 17:51:06.545016 12758 net.cpp:226] drop2 needs backward computation.
I0522 17:51:06.545027 12758 net.cpp:226] relu6 needs backward computation.
I0522 17:51:06.545042 12758 net.cpp:226] ip2 needs backward computation.
I0522 17:51:06.545054 12758 net.cpp:226] drop1 needs backward computation.
I0522 17:51:06.545073 12758 net.cpp:226] relu5 needs backward computation.
I0522 17:51:06.545086 12758 net.cpp:226] ip1 needs backward computation.
I0522 17:51:06.545101 12758 net.cpp:226] pool4 needs backward computation.
I0522 17:51:06.545114 12758 net.cpp:226] relu4 needs backward computation.
I0522 17:51:06.545126 12758 net.cpp:226] conv4 needs backward computation.
I0522 17:51:06.545142 12758 net.cpp:226] pool3 needs backward computation.
I0522 17:51:06.545161 12758 net.cpp:226] relu3 needs backward computation.
I0522 17:51:06.545174 12758 net.cpp:226] conv3 needs backward computation.
I0522 17:51:06.545200 12758 net.cpp:226] pool2 needs backward computation.
I0522 17:51:06.545214 12758 net.cpp:226] relu2 needs backward computation.
I0522 17:51:06.545225 12758 net.cpp:226] conv2 needs backward computation.
I0522 17:51:06.545238 12758 net.cpp:226] pool1 needs backward computation.
I0522 17:51:06.545254 12758 net.cpp:226] relu1 needs backward computation.
I0522 17:51:06.545274 12758 net.cpp:226] conv1 needs backward computation.
I0522 17:51:06.545289 12758 net.cpp:228] data_hdf5 does not need backward computation.
I0522 17:51:06.545301 12758 net.cpp:270] This network produces output loss
I0522 17:51:06.545328 12758 net.cpp:283] Network initialization done.
I0522 17:51:06.547000 12758 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468.prototxt
I0522 17:51:06.547078 12758 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 17:51:06.547462 12758 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 17:51:06.547677 12758 layer_factory.hpp:77] Creating layer data_hdf5
I0522 17:51:06.547703 12758 net.cpp:106] Creating Layer data_hdf5
I0522 17:51:06.547719 12758 net.cpp:411] data_hdf5 -> data
I0522 17:51:06.547741 12758 net.cpp:411] data_hdf5 -> label
I0522 17:51:06.547760 12758 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 17:51:06.562569 12758 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 17:51:27.928045 12758 net.cpp:150] Setting up data_hdf5
I0522 17:51:27.928207 12758 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 17:51:27.928234 12758 net.cpp:157] Top shape: 40 (40)
I0522 17:51:27.928247 12758 net.cpp:165] Memory required for data: 1016160
I0522 17:51:27.928262 12758 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 17:51:27.928290 12758 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 17:51:27.928304 12758 net.cpp:454] label_data_hdf5_1_split <- label
I0522 17:51:27.928328 12758 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 17:51:27.928367 12758 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 17:51:27.928444 12758 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 17:51:27.928464 12758 net.cpp:157] Top shape: 40 (40)
I0522 17:51:27.928486 12758 net.cpp:157] Top shape: 40 (40)
I0522 17:51:27.928499 12758 net.cpp:165] Memory required for data: 1016480
I0522 17:51:27.928513 12758 layer_factory.hpp:77] Creating layer conv1
I0522 17:51:27.928539 12758 net.cpp:106] Creating Layer conv1
I0522 17:51:27.928551 12758 net.cpp:454] conv1 <- data
I0522 17:51:27.928572 12758 net.cpp:411] conv1 -> conv1
I0522 17:51:27.930519 12758 net.cpp:150] Setting up conv1
I0522 17:51:27.930546 12758 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 17:51:27.930564 12758 net.cpp:165] Memory required for data: 12075680
I0522 17:51:27.930588 12758 layer_factory.hpp:77] Creating layer relu1
I0522 17:51:27.930610 12758 net.cpp:106] Creating Layer relu1
I0522 17:51:27.930632 12758 net.cpp:454] relu1 <- conv1
I0522 17:51:27.930650 12758 net.cpp:397] relu1 -> conv1 (in-place)
I0522 17:51:27.931169 12758 net.cpp:150] Setting up relu1
I0522 17:51:27.931191 12758 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 17:51:27.931205 12758 net.cpp:165] Memory required for data: 23134880
I0522 17:51:27.931216 12758 layer_factory.hpp:77] Creating layer pool1
I0522 17:51:27.931238 12758 net.cpp:106] Creating Layer pool1
I0522 17:51:27.931260 12758 net.cpp:454] pool1 <- conv1
I0522 17:51:27.931277 12758 net.cpp:411] pool1 -> pool1
I0522 17:51:27.931371 12758 net.cpp:150] Setting up pool1
I0522 17:51:27.931388 12758 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 17:51:27.931401 12758 net.cpp:165] Memory required for data: 28664480
I0522 17:51:27.931412 12758 layer_factory.hpp:77] Creating layer conv2
I0522 17:51:27.931442 12758 net.cpp:106] Creating Layer conv2
I0522 17:51:27.931455 12758 net.cpp:454] conv2 <- pool1
I0522 17:51:27.931473 12758 net.cpp:411] conv2 -> conv2
I0522 17:51:27.933418 12758 net.cpp:150] Setting up conv2
I0522 17:51:27.933441 12758 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 17:51:27.933462 12758 net.cpp:165] Memory required for data: 36613280
I0522 17:51:27.933485 12758 layer_factory.hpp:77] Creating layer relu2
I0522 17:51:27.933503 12758 net.cpp:106] Creating Layer relu2
I0522 17:51:27.933524 12758 net.cpp:454] relu2 <- conv2
I0522 17:51:27.933542 12758 net.cpp:397] relu2 -> conv2 (in-place)
I0522 17:51:27.933889 12758 net.cpp:150] Setting up relu2
I0522 17:51:27.933909 12758 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 17:51:27.933923 12758 net.cpp:165] Memory required for data: 44562080
I0522 17:51:27.933934 12758 layer_factory.hpp:77] Creating layer pool2
I0522 17:51:27.933959 12758 net.cpp:106] Creating Layer pool2
I0522 17:51:27.933972 12758 net.cpp:454] pool2 <- conv2
I0522 17:51:27.933989 12758 net.cpp:411] pool2 -> pool2
I0522 17:51:27.934080 12758 net.cpp:150] Setting up pool2
I0522 17:51:27.934098 12758 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 17:51:27.934113 12758 net.cpp:165] Memory required for data: 48536480
I0522 17:51:27.934124 12758 layer_factory.hpp:77] Creating layer conv3
I0522 17:51:27.934156 12758 net.cpp:106] Creating Layer conv3
I0522 17:51:27.934170 12758 net.cpp:454] conv3 <- pool2
I0522 17:51:27.934187 12758 net.cpp:411] conv3 -> conv3
I0522 17:51:27.936197 12758 net.cpp:150] Setting up conv3
I0522 17:51:27.936221 12758 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 17:51:27.936234 12758 net.cpp:165] Memory required for data: 52873120
I0522 17:51:27.936274 12758 layer_factory.hpp:77] Creating layer relu3
I0522 17:51:27.936300 12758 net.cpp:106] Creating Layer relu3
I0522 17:51:27.936313 12758 net.cpp:454] relu3 <- conv3
I0522 17:51:27.936336 12758 net.cpp:397] relu3 -> conv3 (in-place)
I0522 17:51:27.936838 12758 net.cpp:150] Setting up relu3
I0522 17:51:27.936862 12758 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 17:51:27.936875 12758 net.cpp:165] Memory required for data: 57209760
I0522 17:51:27.936892 12758 layer_factory.hpp:77] Creating layer pool3
I0522 17:51:27.936908 12758 net.cpp:106] Creating Layer pool3
I0522 17:51:27.936928 12758 net.cpp:454] pool3 <- conv3
I0522 17:51:27.936944 12758 net.cpp:411] pool3 -> pool3
I0522 17:51:27.937031 12758 net.cpp:150] Setting up pool3
I0522 17:51:27.937048 12758 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 17:51:27.937063 12758 net.cpp:165] Memory required for data: 59378080
I0522 17:51:27.937075 12758 layer_factory.hpp:77] Creating layer conv4
I0522 17:51:27.937103 12758 net.cpp:106] Creating Layer conv4
I0522 17:51:27.937115 12758 net.cpp:454] conv4 <- pool3
I0522 17:51:27.937132 12758 net.cpp:411] conv4 -> conv4
I0522 17:51:27.939235 12758 net.cpp:150] Setting up conv4
I0522 17:51:27.939260 12758 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 17:51:27.939280 12758 net.cpp:165] Memory required for data: 60829600
I0522 17:51:27.939299 12758 layer_factory.hpp:77] Creating layer relu4
I0522 17:51:27.939319 12758 net.cpp:106] Creating Layer relu4
I0522 17:51:27.939332 12758 net.cpp:454] relu4 <- conv4
I0522 17:51:27.939347 12758 net.cpp:397] relu4 -> conv4 (in-place)
I0522 17:51:27.939847 12758 net.cpp:150] Setting up relu4
I0522 17:51:27.939870 12758 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 17:51:27.939883 12758 net.cpp:165] Memory required for data: 62281120
I0522 17:51:27.939900 12758 layer_factory.hpp:77] Creating layer pool4
I0522 17:51:27.939915 12758 net.cpp:106] Creating Layer pool4
I0522 17:51:27.939944 12758 net.cpp:454] pool4 <- conv4
I0522 17:51:27.939961 12758 net.cpp:411] pool4 -> pool4
I0522 17:51:27.940047 12758 net.cpp:150] Setting up pool4
I0522 17:51:27.940071 12758 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 17:51:27.940084 12758 net.cpp:165] Memory required for data: 63006880
I0522 17:51:27.940099 12758 layer_factory.hpp:77] Creating layer ip1
I0522 17:51:27.940116 12758 net.cpp:106] Creating Layer ip1
I0522 17:51:27.940136 12758 net.cpp:454] ip1 <- pool4
I0522 17:51:27.940153 12758 net.cpp:411] ip1 -> ip1
I0522 17:51:27.955618 12758 net.cpp:150] Setting up ip1
I0522 17:51:27.955651 12758 net.cpp:157] Top shape: 40 196 (7840)
I0522 17:51:27.955673 12758 net.cpp:165] Memory required for data: 63038240
I0522 17:51:27.955699 12758 layer_factory.hpp:77] Creating layer relu5
I0522 17:51:27.955721 12758 net.cpp:106] Creating Layer relu5
I0522 17:51:27.955746 12758 net.cpp:454] relu5 <- ip1
I0522 17:51:27.955765 12758 net.cpp:397] relu5 -> ip1 (in-place)
I0522 17:51:27.956133 12758 net.cpp:150] Setting up relu5
I0522 17:51:27.956153 12758 net.cpp:157] Top shape: 40 196 (7840)
I0522 17:51:27.956167 12758 net.cpp:165] Memory required for data: 63069600
I0522 17:51:27.956183 12758 layer_factory.hpp:77] Creating layer drop1
I0522 17:51:27.956205 12758 net.cpp:106] Creating Layer drop1
I0522 17:51:27.956226 12758 net.cpp:454] drop1 <- ip1
I0522 17:51:27.956243 12758 net.cpp:397] drop1 -> ip1 (in-place)
I0522 17:51:27.956300 12758 net.cpp:150] Setting up drop1
I0522 17:51:27.956318 12758 net.cpp:157] Top shape: 40 196 (7840)
I0522 17:51:27.956331 12758 net.cpp:165] Memory required for data: 63100960
I0522 17:51:27.956351 12758 layer_factory.hpp:77] Creating layer ip2
I0522 17:51:27.956369 12758 net.cpp:106] Creating Layer ip2
I0522 17:51:27.956382 12758 net.cpp:454] ip2 <- ip1
I0522 17:51:27.956401 12758 net.cpp:411] ip2 -> ip2
I0522 17:51:27.956898 12758 net.cpp:150] Setting up ip2
I0522 17:51:27.956918 12758 net.cpp:157] Top shape: 40 98 (3920)
I0522 17:51:27.956930 12758 net.cpp:165] Memory required for data: 63116640
I0522 17:51:27.956953 12758 layer_factory.hpp:77] Creating layer relu6
I0522 17:51:27.956986 12758 net.cpp:106] Creating Layer relu6
I0522 17:51:27.957000 12758 net.cpp:454] relu6 <- ip2
I0522 17:51:27.957015 12758 net.cpp:397] relu6 -> ip2 (in-place)
I0522 17:51:27.957576 12758 net.cpp:150] Setting up relu6
I0522 17:51:27.957599 12758 net.cpp:157] Top shape: 40 98 (3920)
I0522 17:51:27.957612 12758 net.cpp:165] Memory required for data: 63132320
I0522 17:51:27.957624 12758 layer_factory.hpp:77] Creating layer drop2
I0522 17:51:27.957644 12758 net.cpp:106] Creating Layer drop2
I0522 17:51:27.957666 12758 net.cpp:454] drop2 <- ip2
I0522 17:51:27.957684 12758 net.cpp:397] drop2 -> ip2 (in-place)
I0522 17:51:27.957733 12758 net.cpp:150] Setting up drop2
I0522 17:51:27.957756 12758 net.cpp:157] Top shape: 40 98 (3920)
I0522 17:51:27.957769 12758 net.cpp:165] Memory required for data: 63148000
I0522 17:51:27.957787 12758 layer_factory.hpp:77] Creating layer ip3
I0522 17:51:27.957805 12758 net.cpp:106] Creating Layer ip3
I0522 17:51:27.957818 12758 net.cpp:454] ip3 <- ip2
I0522 17:51:27.957837 12758 net.cpp:411] ip3 -> ip3
I0522 17:51:27.958083 12758 net.cpp:150] Setting up ip3
I0522 17:51:27.958102 12758 net.cpp:157] Top shape: 40 11 (440)
I0522 17:51:27.958115 12758 net.cpp:165] Memory required for data: 63149760
I0522 17:51:27.958137 12758 layer_factory.hpp:77] Creating layer drop3
I0522 17:51:27.958158 12758 net.cpp:106] Creating Layer drop3
I0522 17:51:27.958171 12758 net.cpp:454] drop3 <- ip3
I0522 17:51:27.958187 12758 net.cpp:397] drop3 -> ip3 (in-place)
I0522 17:51:27.958236 12758 net.cpp:150] Setting up drop3
I0522 17:51:27.958257 12758 net.cpp:157] Top shape: 40 11 (440)
I0522 17:51:27.958271 12758 net.cpp:165] Memory required for data: 63151520
I0522 17:51:27.958287 12758 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 17:51:27.958302 12758 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 17:51:27.958314 12758 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 17:51:27.958333 12758 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 17:51:27.958356 12758 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 17:51:27.958436 12758 net.cpp:150] Setting up ip3_drop3_0_split
I0522 17:51:27.958459 12758 net.cpp:157] Top shape: 40 11 (440)
I0522 17:51:27.958474 12758 net.cpp:157] Top shape: 40 11 (440)
I0522 17:51:27.958487 12758 net.cpp:165] Memory required for data: 63155040
I0522 17:51:27.958501 12758 layer_factory.hpp:77] Creating layer accuracy
I0522 17:51:27.958524 12758 net.cpp:106] Creating Layer accuracy
I0522 17:51:27.958544 12758 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 17:51:27.958559 12758 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 17:51:27.958575 12758 net.cpp:411] accuracy -> accuracy
I0522 17:51:27.958603 12758 net.cpp:150] Setting up accuracy
I0522 17:51:27.958624 12758 net.cpp:157] Top shape: (1)
I0522 17:51:27.958637 12758 net.cpp:165] Memory required for data: 63155044
I0522 17:51:27.958653 12758 layer_factory.hpp:77] Creating layer loss
I0522 17:51:27.958670 12758 net.cpp:106] Creating Layer loss
I0522 17:51:27.958683 12758 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 17:51:27.958698 12758 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 17:51:27.958714 12758 net.cpp:411] loss -> loss
I0522 17:51:27.958741 12758 layer_factory.hpp:77] Creating layer loss
I0522 17:51:27.959245 12758 net.cpp:150] Setting up loss
I0522 17:51:27.959265 12758 net.cpp:157] Top shape: (1)
I0522 17:51:27.959278 12758 net.cpp:160]     with loss weight 1
I0522 17:51:27.959306 12758 net.cpp:165] Memory required for data: 63155048
I0522 17:51:27.959324 12758 net.cpp:226] loss needs backward computation.
I0522 17:51:27.959339 12758 net.cpp:228] accuracy does not need backward computation.
I0522 17:51:27.959354 12758 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 17:51:27.959367 12758 net.cpp:226] drop3 needs backward computation.
I0522 17:51:27.959379 12758 net.cpp:226] ip3 needs backward computation.
I0522 17:51:27.959395 12758 net.cpp:226] drop2 needs backward computation.
I0522 17:51:27.959414 12758 net.cpp:226] relu6 needs backward computation.
I0522 17:51:27.959435 12758 net.cpp:226] ip2 needs backward computation.
I0522 17:51:27.959451 12758 net.cpp:226] drop1 needs backward computation.
I0522 17:51:27.959465 12758 net.cpp:226] relu5 needs backward computation.
I0522 17:51:27.959476 12758 net.cpp:226] ip1 needs backward computation.
I0522 17:51:27.959488 12758 net.cpp:226] pool4 needs backward computation.
I0522 17:51:27.959503 12758 net.cpp:226] relu4 needs backward computation.
I0522 17:51:27.959517 12758 net.cpp:226] conv4 needs backward computation.
I0522 17:51:27.959535 12758 net.cpp:226] pool3 needs backward computation.
I0522 17:51:27.959549 12758 net.cpp:226] relu3 needs backward computation.
I0522 17:51:27.959563 12758 net.cpp:226] conv3 needs backward computation.
I0522 17:51:27.959574 12758 net.cpp:226] pool2 needs backward computation.
I0522 17:51:27.959588 12758 net.cpp:226] relu2 needs backward computation.
I0522 17:51:27.959602 12758 net.cpp:226] conv2 needs backward computation.
I0522 17:51:27.959615 12758 net.cpp:226] pool1 needs backward computation.
I0522 17:51:27.959635 12758 net.cpp:226] relu1 needs backward computation.
I0522 17:51:27.959647 12758 net.cpp:226] conv1 needs backward computation.
I0522 17:51:27.959662 12758 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 17:51:27.959676 12758 net.cpp:228] data_hdf5 does not need backward computation.
I0522 17:51:27.959688 12758 net.cpp:270] This network produces output accuracy
I0522 17:51:27.959703 12758 net.cpp:270] This network produces output loss
I0522 17:51:27.959734 12758 net.cpp:283] Network initialization done.
I0522 17:51:27.959868 12758 solver.cpp:60] Solver scaffolding done.
I0522 17:51:27.961014 12758 caffe.cpp:212] Starting Optimization
I0522 17:51:27.961033 12758 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 17:51:27.961050 12758 solver.cpp:289] Learning Rate Policy: fixed
I0522 17:51:27.962282 12758 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 17:52:17.453816 12758 solver.cpp:409]     Test net output #0: accuracy = 0.119027
I0522 17:52:17.453995 12758 solver.cpp:409]     Test net output #1: loss = 2.39783 (* 1 = 2.39783 loss)
I0522 17:52:17.476639 12758 solver.cpp:237] Iteration 0, loss = 2.406
I0522 17:52:17.476678 12758 solver.cpp:253]     Train net output #0: loss = 2.406 (* 1 = 2.406 loss)
I0522 17:52:17.476699 12758 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0522 17:52:27.321979 12758 solver.cpp:237] Iteration 375, loss = 2.23475
I0522 17:52:27.322038 12758 solver.cpp:253]     Train net output #0: loss = 2.23475 (* 1 = 2.23475 loss)
I0522 17:52:27.322062 12758 sgd_solver.cpp:106] Iteration 375, lr = 0.001
I0522 17:52:37.151252 12758 solver.cpp:237] Iteration 750, loss = 2.00461
I0522 17:52:37.151289 12758 solver.cpp:253]     Train net output #0: loss = 2.00461 (* 1 = 2.00461 loss)
I0522 17:52:37.151307 12758 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0522 17:52:46.974797 12758 solver.cpp:237] Iteration 1125, loss = 2.07678
I0522 17:52:46.974834 12758 solver.cpp:253]     Train net output #0: loss = 2.07678 (* 1 = 2.07678 loss)
I0522 17:52:46.974853 12758 sgd_solver.cpp:106] Iteration 1125, lr = 0.001
I0522 17:52:56.766899 12758 solver.cpp:237] Iteration 1500, loss = 2.02725
I0522 17:52:56.767066 12758 solver.cpp:253]     Train net output #0: loss = 2.02725 (* 1 = 2.02725 loss)
I0522 17:52:56.767083 12758 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0522 17:53:06.553382 12758 solver.cpp:237] Iteration 1875, loss = 1.94945
I0522 17:53:06.553419 12758 solver.cpp:253]     Train net output #0: loss = 1.94945 (* 1 = 1.94945 loss)
I0522 17:53:06.553442 12758 sgd_solver.cpp:106] Iteration 1875, lr = 0.001
I0522 17:53:16.346096 12758 solver.cpp:237] Iteration 2250, loss = 1.95665
I0522 17:53:16.346154 12758 solver.cpp:253]     Train net output #0: loss = 1.95665 (* 1 = 1.95665 loss)
I0522 17:53:16.346180 12758 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0522 17:53:48.317626 12758 solver.cpp:237] Iteration 2625, loss = 1.7195
I0522 17:53:48.317795 12758 solver.cpp:253]     Train net output #0: loss = 1.7195 (* 1 = 1.7195 loss)
I0522 17:53:48.317811 12758 sgd_solver.cpp:106] Iteration 2625, lr = 0.001
I0522 17:53:58.150116 12758 solver.cpp:237] Iteration 3000, loss = 1.88496
I0522 17:53:58.150156 12758 solver.cpp:253]     Train net output #0: loss = 1.88496 (* 1 = 1.88496 loss)
I0522 17:53:58.150173 12758 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0522 17:54:07.990375 12758 solver.cpp:237] Iteration 3375, loss = 1.81483
I0522 17:54:07.990429 12758 solver.cpp:253]     Train net output #0: loss = 1.81483 (* 1 = 1.81483 loss)
I0522 17:54:07.990447 12758 sgd_solver.cpp:106] Iteration 3375, lr = 0.001
I0522 17:54:17.812346 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_3750.caffemodel
I0522 17:54:17.872032 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_3750.solverstate
I0522 17:54:17.906121 12758 solver.cpp:237] Iteration 3750, loss = 1.60287
I0522 17:54:17.906180 12758 solver.cpp:253]     Train net output #0: loss = 1.60287 (* 1 = 1.60287 loss)
I0522 17:54:17.906206 12758 sgd_solver.cpp:106] Iteration 3750, lr = 0.001
I0522 17:54:27.743053 12758 solver.cpp:237] Iteration 4125, loss = 1.71291
I0522 17:54:27.743197 12758 solver.cpp:253]     Train net output #0: loss = 1.71291 (* 1 = 1.71291 loss)
I0522 17:54:27.743214 12758 sgd_solver.cpp:106] Iteration 4125, lr = 0.001
I0522 17:54:37.459801 12758 solver.cpp:237] Iteration 4500, loss = 1.47561
I0522 17:54:37.459849 12758 solver.cpp:253]     Train net output #0: loss = 1.47561 (* 1 = 1.47561 loss)
I0522 17:54:37.459877 12758 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0522 17:54:47.170934 12758 solver.cpp:237] Iteration 4875, loss = 1.63968
I0522 17:54:47.170971 12758 solver.cpp:253]     Train net output #0: loss = 1.63968 (* 1 = 1.63968 loss)
I0522 17:54:47.170989 12758 sgd_solver.cpp:106] Iteration 4875, lr = 0.001
I0522 17:55:19.076530 12758 solver.cpp:237] Iteration 5250, loss = 1.71242
I0522 17:55:19.076692 12758 solver.cpp:253]     Train net output #0: loss = 1.71242 (* 1 = 1.71242 loss)
I0522 17:55:19.076711 12758 sgd_solver.cpp:106] Iteration 5250, lr = 0.001
I0522 17:55:28.786747 12758 solver.cpp:237] Iteration 5625, loss = 1.84859
I0522 17:55:28.786784 12758 solver.cpp:253]     Train net output #0: loss = 1.84859 (* 1 = 1.84859 loss)
I0522 17:55:28.786808 12758 sgd_solver.cpp:106] Iteration 5625, lr = 0.001
I0522 17:55:38.490393 12758 solver.cpp:237] Iteration 6000, loss = 1.87941
I0522 17:55:38.490432 12758 solver.cpp:253]     Train net output #0: loss = 1.87941 (* 1 = 1.87941 loss)
I0522 17:55:38.490452 12758 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0522 17:55:48.200848 12758 solver.cpp:237] Iteration 6375, loss = 1.50536
I0522 17:55:48.200907 12758 solver.cpp:253]     Train net output #0: loss = 1.50536 (* 1 = 1.50536 loss)
I0522 17:55:48.200933 12758 sgd_solver.cpp:106] Iteration 6375, lr = 0.001
I0522 17:55:57.910192 12758 solver.cpp:237] Iteration 6750, loss = 1.78152
I0522 17:55:57.910343 12758 solver.cpp:253]     Train net output #0: loss = 1.78152 (* 1 = 1.78152 loss)
I0522 17:55:57.910359 12758 sgd_solver.cpp:106] Iteration 6750, lr = 0.001
I0522 17:56:07.614704 12758 solver.cpp:237] Iteration 7125, loss = 1.74342
I0522 17:56:07.614740 12758 solver.cpp:253]     Train net output #0: loss = 1.74342 (* 1 = 1.74342 loss)
I0522 17:56:07.614764 12758 sgd_solver.cpp:106] Iteration 7125, lr = 0.001
I0522 17:56:17.299063 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_7500.caffemodel
I0522 17:56:17.354409 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_7500.solverstate
I0522 17:56:17.379799 12758 solver.cpp:341] Iteration 7500, Testing net (#0)
I0522 17:57:06.648025 12758 solver.cpp:409]     Test net output #0: accuracy = 0.716273
I0522 17:57:06.648191 12758 solver.cpp:409]     Test net output #1: loss = 0.971151 (* 1 = 0.971151 loss)
I0522 17:57:28.837055 12758 solver.cpp:237] Iteration 7500, loss = 1.60975
I0522 17:57:28.837121 12758 solver.cpp:253]     Train net output #0: loss = 1.60975 (* 1 = 1.60975 loss)
I0522 17:57:28.837139 12758 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0522 17:57:38.543354 12758 solver.cpp:237] Iteration 7875, loss = 1.35454
I0522 17:57:38.543498 12758 solver.cpp:253]     Train net output #0: loss = 1.35454 (* 1 = 1.35454 loss)
I0522 17:57:38.543514 12758 sgd_solver.cpp:106] Iteration 7875, lr = 0.001
I0522 17:57:48.246947 12758 solver.cpp:237] Iteration 8250, loss = 1.80578
I0522 17:57:48.246984 12758 solver.cpp:253]     Train net output #0: loss = 1.80578 (* 1 = 1.80578 loss)
I0522 17:57:48.247006 12758 sgd_solver.cpp:106] Iteration 8250, lr = 0.001
I0522 17:57:58.021256 12758 solver.cpp:237] Iteration 8625, loss = 1.56168
I0522 17:57:58.021312 12758 solver.cpp:253]     Train net output #0: loss = 1.56168 (* 1 = 1.56168 loss)
I0522 17:57:58.021338 12758 sgd_solver.cpp:106] Iteration 8625, lr = 0.001
I0522 17:58:07.801278 12758 solver.cpp:237] Iteration 9000, loss = 1.59181
I0522 17:58:07.801316 12758 solver.cpp:253]     Train net output #0: loss = 1.59181 (* 1 = 1.59181 loss)
I0522 17:58:07.801339 12758 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0522 17:58:17.543802 12758 solver.cpp:237] Iteration 9375, loss = 1.59585
I0522 17:58:17.543970 12758 solver.cpp:253]     Train net output #0: loss = 1.59585 (* 1 = 1.59585 loss)
I0522 17:58:17.543989 12758 sgd_solver.cpp:106] Iteration 9375, lr = 0.001
I0522 17:58:27.235038 12758 solver.cpp:237] Iteration 9750, loss = 1.37408
I0522 17:58:27.235074 12758 solver.cpp:253]     Train net output #0: loss = 1.37408 (* 1 = 1.37408 loss)
I0522 17:58:27.235097 12758 sgd_solver.cpp:106] Iteration 9750, lr = 0.001
I0522 17:58:59.173279 12758 solver.cpp:237] Iteration 10125, loss = 1.52714
I0522 17:58:59.173450 12758 solver.cpp:253]     Train net output #0: loss = 1.52714 (* 1 = 1.52714 loss)
I0522 17:58:59.173467 12758 sgd_solver.cpp:106] Iteration 10125, lr = 0.001
I0522 17:59:08.870190 12758 solver.cpp:237] Iteration 10500, loss = 1.38379
I0522 17:59:08.870241 12758 solver.cpp:253]     Train net output #0: loss = 1.38379 (* 1 = 1.38379 loss)
I0522 17:59:08.870260 12758 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0522 17:59:18.572944 12758 solver.cpp:237] Iteration 10875, loss = 1.39034
I0522 17:59:18.572981 12758 solver.cpp:253]     Train net output #0: loss = 1.39034 (* 1 = 1.39034 loss)
I0522 17:59:18.573005 12758 sgd_solver.cpp:106] Iteration 10875, lr = 0.001
I0522 17:59:28.255293 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_11250.caffemodel
I0522 17:59:28.321606 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_11250.solverstate
I0522 17:59:28.357606 12758 solver.cpp:237] Iteration 11250, loss = 1.75258
I0522 17:59:28.357671 12758 solver.cpp:253]     Train net output #0: loss = 1.75258 (* 1 = 1.75258 loss)
I0522 17:59:28.357688 12758 sgd_solver.cpp:106] Iteration 11250, lr = 0.001
I0522 17:59:38.257200 12758 solver.cpp:237] Iteration 11625, loss = 1.28472
I0522 17:59:38.257364 12758 solver.cpp:253]     Train net output #0: loss = 1.28472 (* 1 = 1.28472 loss)
I0522 17:59:38.257383 12758 sgd_solver.cpp:106] Iteration 11625, lr = 0.001
I0522 17:59:48.164140 12758 solver.cpp:237] Iteration 12000, loss = 1.5345
I0522 17:59:48.164176 12758 solver.cpp:253]     Train net output #0: loss = 1.5345 (* 1 = 1.5345 loss)
I0522 17:59:48.164193 12758 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0522 17:59:58.070778 12758 solver.cpp:237] Iteration 12375, loss = 1.35836
I0522 17:59:58.070834 12758 solver.cpp:253]     Train net output #0: loss = 1.35836 (* 1 = 1.35836 loss)
I0522 17:59:58.070858 12758 sgd_solver.cpp:106] Iteration 12375, lr = 0.001
I0522 18:00:30.249582 12758 solver.cpp:237] Iteration 12750, loss = 1.56559
I0522 18:00:30.249752 12758 solver.cpp:253]     Train net output #0: loss = 1.56559 (* 1 = 1.56559 loss)
I0522 18:00:30.249769 12758 sgd_solver.cpp:106] Iteration 12750, lr = 0.001
I0522 18:00:40.154734 12758 solver.cpp:237] Iteration 13125, loss = 1.54587
I0522 18:00:40.154770 12758 solver.cpp:253]     Train net output #0: loss = 1.54587 (* 1 = 1.54587 loss)
I0522 18:00:40.154794 12758 sgd_solver.cpp:106] Iteration 13125, lr = 0.001
I0522 18:00:49.968899 12758 solver.cpp:237] Iteration 13500, loss = 1.29561
I0522 18:00:49.968955 12758 solver.cpp:253]     Train net output #0: loss = 1.29561 (* 1 = 1.29561 loss)
I0522 18:00:49.968971 12758 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0522 18:00:59.720190 12758 solver.cpp:237] Iteration 13875, loss = 1.46718
I0522 18:00:59.720227 12758 solver.cpp:253]     Train net output #0: loss = 1.46718 (* 1 = 1.46718 loss)
I0522 18:00:59.720252 12758 sgd_solver.cpp:106] Iteration 13875, lr = 0.001
I0522 18:01:09.477078 12758 solver.cpp:237] Iteration 14250, loss = 1.0909
I0522 18:01:09.477241 12758 solver.cpp:253]     Train net output #0: loss = 1.0909 (* 1 = 1.0909 loss)
I0522 18:01:09.477262 12758 sgd_solver.cpp:106] Iteration 14250, lr = 0.001
I0522 18:01:19.237253 12758 solver.cpp:237] Iteration 14625, loss = 1.13674
I0522 18:01:19.237290 12758 solver.cpp:253]     Train net output #0: loss = 1.13674 (* 1 = 1.13674 loss)
I0522 18:01:19.237314 12758 sgd_solver.cpp:106] Iteration 14625, lr = 0.001
I0522 18:01:28.961870 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_15000.caffemodel
I0522 18:01:29.020555 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_15000.solverstate
I0522 18:01:29.049130 12758 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 18:02:38.503890 12758 solver.cpp:409]     Test net output #0: accuracy = 0.7964
I0522 18:02:38.504061 12758 solver.cpp:409]     Test net output #1: loss = 0.674802 (* 1 = 0.674802 loss)
I0522 18:03:00.741257 12758 solver.cpp:237] Iteration 15000, loss = 1.18312
I0522 18:03:00.741327 12758 solver.cpp:253]     Train net output #0: loss = 1.18312 (* 1 = 1.18312 loss)
I0522 18:03:00.741353 12758 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0522 18:03:10.590467 12758 solver.cpp:237] Iteration 15375, loss = 1.20794
I0522 18:03:10.590621 12758 solver.cpp:253]     Train net output #0: loss = 1.20794 (* 1 = 1.20794 loss)
I0522 18:03:10.590638 12758 sgd_solver.cpp:106] Iteration 15375, lr = 0.001
I0522 18:03:20.433173 12758 solver.cpp:237] Iteration 15750, loss = 1.55904
I0522 18:03:20.433230 12758 solver.cpp:253]     Train net output #0: loss = 1.55904 (* 1 = 1.55904 loss)
I0522 18:03:20.433256 12758 sgd_solver.cpp:106] Iteration 15750, lr = 0.001
I0522 18:03:30.281565 12758 solver.cpp:237] Iteration 16125, loss = 1.48416
I0522 18:03:30.281605 12758 solver.cpp:253]     Train net output #0: loss = 1.48416 (* 1 = 1.48416 loss)
I0522 18:03:30.281623 12758 sgd_solver.cpp:106] Iteration 16125, lr = 0.001
I0522 18:03:40.125036 12758 solver.cpp:237] Iteration 16500, loss = 1.44719
I0522 18:03:40.125095 12758 solver.cpp:253]     Train net output #0: loss = 1.44719 (* 1 = 1.44719 loss)
I0522 18:03:40.125114 12758 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0522 18:03:49.974192 12758 solver.cpp:237] Iteration 16875, loss = 1.48168
I0522 18:03:49.974341 12758 solver.cpp:253]     Train net output #0: loss = 1.48168 (* 1 = 1.48168 loss)
I0522 18:03:49.974359 12758 sgd_solver.cpp:106] Iteration 16875, lr = 0.001
I0522 18:03:59.819078 12758 solver.cpp:237] Iteration 17250, loss = 1.52166
I0522 18:03:59.819114 12758 solver.cpp:253]     Train net output #0: loss = 1.52166 (* 1 = 1.52166 loss)
I0522 18:03:59.819139 12758 sgd_solver.cpp:106] Iteration 17250, lr = 0.001
I0522 18:04:31.843749 12758 solver.cpp:237] Iteration 17625, loss = 0.970211
I0522 18:04:31.843924 12758 solver.cpp:253]     Train net output #0: loss = 0.970211 (* 1 = 0.970211 loss)
I0522 18:04:31.843950 12758 sgd_solver.cpp:106] Iteration 17625, lr = 0.001
I0522 18:04:41.543315 12758 solver.cpp:237] Iteration 18000, loss = 1.21113
I0522 18:04:41.543352 12758 solver.cpp:253]     Train net output #0: loss = 1.21113 (* 1 = 1.21113 loss)
I0522 18:04:41.543376 12758 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0522 18:04:51.252617 12758 solver.cpp:237] Iteration 18375, loss = 1.41166
I0522 18:04:51.252655 12758 solver.cpp:253]     Train net output #0: loss = 1.41166 (* 1 = 1.41166 loss)
I0522 18:04:51.252678 12758 sgd_solver.cpp:106] Iteration 18375, lr = 0.001
I0522 18:05:00.948501 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_18750.caffemodel
I0522 18:05:01.007127 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_18750.solverstate
I0522 18:05:01.044008 12758 solver.cpp:237] Iteration 18750, loss = 1.26694
I0522 18:05:01.044071 12758 solver.cpp:253]     Train net output #0: loss = 1.26694 (* 1 = 1.26694 loss)
I0522 18:05:01.044090 12758 sgd_solver.cpp:106] Iteration 18750, lr = 0.001
I0522 18:05:10.774194 12758 solver.cpp:237] Iteration 19125, loss = 1.43346
I0522 18:05:10.774343 12758 solver.cpp:253]     Train net output #0: loss = 1.43346 (* 1 = 1.43346 loss)
I0522 18:05:10.774360 12758 sgd_solver.cpp:106] Iteration 19125, lr = 0.001
I0522 18:05:20.536345 12758 solver.cpp:237] Iteration 19500, loss = 1.15302
I0522 18:05:20.536404 12758 solver.cpp:253]     Train net output #0: loss = 1.15302 (* 1 = 1.15302 loss)
I0522 18:05:20.536422 12758 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0522 18:05:30.451412 12758 solver.cpp:237] Iteration 19875, loss = 1.52128
I0522 18:05:30.451448 12758 solver.cpp:253]     Train net output #0: loss = 1.52128 (* 1 = 1.52128 loss)
I0522 18:05:30.451472 12758 sgd_solver.cpp:106] Iteration 19875, lr = 0.001
I0522 18:06:02.575860 12758 solver.cpp:237] Iteration 20250, loss = 1.38713
I0522 18:06:02.576046 12758 solver.cpp:253]     Train net output #0: loss = 1.38713 (* 1 = 1.38713 loss)
I0522 18:06:02.576064 12758 sgd_solver.cpp:106] Iteration 20250, lr = 0.001
I0522 18:06:12.498323 12758 solver.cpp:237] Iteration 20625, loss = 1.23606
I0522 18:06:12.498379 12758 solver.cpp:253]     Train net output #0: loss = 1.23606 (* 1 = 1.23606 loss)
I0522 18:06:12.498396 12758 sgd_solver.cpp:106] Iteration 20625, lr = 0.001
I0522 18:06:22.411140 12758 solver.cpp:237] Iteration 21000, loss = 1.38568
I0522 18:06:22.411178 12758 solver.cpp:253]     Train net output #0: loss = 1.38568 (* 1 = 1.38568 loss)
I0522 18:06:22.411201 12758 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0522 18:06:32.323776 12758 solver.cpp:237] Iteration 21375, loss = 1.73622
I0522 18:06:32.323813 12758 solver.cpp:253]     Train net output #0: loss = 1.73622 (* 1 = 1.73622 loss)
I0522 18:06:32.323837 12758 sgd_solver.cpp:106] Iteration 21375, lr = 0.001
I0522 18:06:42.240972 12758 solver.cpp:237] Iteration 21750, loss = 1.10061
I0522 18:06:42.241138 12758 solver.cpp:253]     Train net output #0: loss = 1.10061 (* 1 = 1.10061 loss)
I0522 18:06:42.241158 12758 sgd_solver.cpp:106] Iteration 21750, lr = 0.001
I0522 18:06:52.152050 12758 solver.cpp:237] Iteration 22125, loss = 1.04281
I0522 18:06:52.152086 12758 solver.cpp:253]     Train net output #0: loss = 1.04281 (* 1 = 1.04281 loss)
I0522 18:06:52.152110 12758 sgd_solver.cpp:106] Iteration 22125, lr = 0.001
I0522 18:07:02.030140 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_22500.caffemodel
I0522 18:07:02.085788 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_22500.solverstate
I0522 18:07:02.112434 12758 solver.cpp:341] Iteration 22500, Testing net (#0)
I0522 18:07:50.292762 12758 solver.cpp:409]     Test net output #0: accuracy = 0.82594
I0522 18:07:50.292932 12758 solver.cpp:409]     Test net output #1: loss = 0.641859 (* 1 = 0.641859 loss)
I0522 18:08:12.557808 12758 solver.cpp:237] Iteration 22500, loss = 1.02298
I0522 18:08:12.557871 12758 solver.cpp:253]     Train net output #0: loss = 1.02298 (* 1 = 1.02298 loss)
I0522 18:08:12.557904 12758 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0522 18:08:22.378067 12758 solver.cpp:237] Iteration 22875, loss = 1.24112
I0522 18:08:22.378239 12758 solver.cpp:253]     Train net output #0: loss = 1.24112 (* 1 = 1.24112 loss)
I0522 18:08:22.378258 12758 sgd_solver.cpp:106] Iteration 22875, lr = 0.001
I0522 18:08:32.209929 12758 solver.cpp:237] Iteration 23250, loss = 1.51439
I0522 18:08:32.209966 12758 solver.cpp:253]     Train net output #0: loss = 1.51439 (* 1 = 1.51439 loss)
I0522 18:08:32.209985 12758 sgd_solver.cpp:106] Iteration 23250, lr = 0.001
I0522 18:08:42.044723 12758 solver.cpp:237] Iteration 23625, loss = 1.78213
I0522 18:08:42.044778 12758 solver.cpp:253]     Train net output #0: loss = 1.78213 (* 1 = 1.78213 loss)
I0522 18:08:42.044795 12758 sgd_solver.cpp:106] Iteration 23625, lr = 0.001
I0522 18:08:51.868845 12758 solver.cpp:237] Iteration 24000, loss = 1.27018
I0522 18:08:51.868882 12758 solver.cpp:253]     Train net output #0: loss = 1.27018 (* 1 = 1.27018 loss)
I0522 18:08:51.868908 12758 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0522 18:09:01.695063 12758 solver.cpp:237] Iteration 24375, loss = 1.30442
I0522 18:09:01.695205 12758 solver.cpp:253]     Train net output #0: loss = 1.30442 (* 1 = 1.30442 loss)
I0522 18:09:01.695222 12758 sgd_solver.cpp:106] Iteration 24375, lr = 0.001
I0522 18:09:11.476122 12758 solver.cpp:237] Iteration 24750, loss = 1.17865
I0522 18:09:11.476177 12758 solver.cpp:253]     Train net output #0: loss = 1.17865 (* 1 = 1.17865 loss)
I0522 18:09:11.476194 12758 sgd_solver.cpp:106] Iteration 24750, lr = 0.001
I0522 18:09:43.439611 12758 solver.cpp:237] Iteration 25125, loss = 1.44929
I0522 18:09:43.439792 12758 solver.cpp:253]     Train net output #0: loss = 1.44929 (* 1 = 1.44929 loss)
I0522 18:09:43.439810 12758 sgd_solver.cpp:106] Iteration 25125, lr = 0.001
I0522 18:09:53.212976 12758 solver.cpp:237] Iteration 25500, loss = 1.04097
I0522 18:09:53.213014 12758 solver.cpp:253]     Train net output #0: loss = 1.04097 (* 1 = 1.04097 loss)
I0522 18:09:53.213037 12758 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0522 18:10:02.982182 12758 solver.cpp:237] Iteration 25875, loss = 0.941544
I0522 18:10:02.982235 12758 solver.cpp:253]     Train net output #0: loss = 0.941544 (* 1 = 0.941544 loss)
I0522 18:10:02.982262 12758 sgd_solver.cpp:106] Iteration 25875, lr = 0.001
I0522 18:10:12.726508 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_26250.caffemodel
I0522 18:10:12.787317 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_26250.solverstate
I0522 18:10:12.822140 12758 solver.cpp:237] Iteration 26250, loss = 1.60372
I0522 18:10:12.822196 12758 solver.cpp:253]     Train net output #0: loss = 1.60372 (* 1 = 1.60372 loss)
I0522 18:10:12.822222 12758 sgd_solver.cpp:106] Iteration 26250, lr = 0.001
I0522 18:10:22.632290 12758 solver.cpp:237] Iteration 26625, loss = 1.40894
I0522 18:10:22.632462 12758 solver.cpp:253]     Train net output #0: loss = 1.40894 (* 1 = 1.40894 loss)
I0522 18:10:22.632486 12758 sgd_solver.cpp:106] Iteration 26625, lr = 0.001
I0522 18:10:32.499341 12758 solver.cpp:237] Iteration 27000, loss = 1.13316
I0522 18:10:32.499378 12758 solver.cpp:253]     Train net output #0: loss = 1.13316 (* 1 = 1.13316 loss)
I0522 18:10:32.499403 12758 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0522 18:10:42.363165 12758 solver.cpp:237] Iteration 27375, loss = 1.25933
I0522 18:10:42.363204 12758 solver.cpp:253]     Train net output #0: loss = 1.25933 (* 1 = 1.25933 loss)
I0522 18:10:42.363222 12758 sgd_solver.cpp:106] Iteration 27375, lr = 0.001
I0522 18:11:14.381743 12758 solver.cpp:237] Iteration 27750, loss = 1.18215
I0522 18:11:14.381918 12758 solver.cpp:253]     Train net output #0: loss = 1.18215 (* 1 = 1.18215 loss)
I0522 18:11:14.381937 12758 sgd_solver.cpp:106] Iteration 27750, lr = 0.001
I0522 18:11:24.208958 12758 solver.cpp:237] Iteration 28125, loss = 1.54743
I0522 18:11:24.208997 12758 solver.cpp:253]     Train net output #0: loss = 1.54743 (* 1 = 1.54743 loss)
I0522 18:11:24.209019 12758 sgd_solver.cpp:106] Iteration 28125, lr = 0.001
I0522 18:11:34.029523 12758 solver.cpp:237] Iteration 28500, loss = 1.47228
I0522 18:11:34.029579 12758 solver.cpp:253]     Train net output #0: loss = 1.47228 (* 1 = 1.47228 loss)
I0522 18:11:34.029597 12758 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0522 18:11:43.852562 12758 solver.cpp:237] Iteration 28875, loss = 1.05654
I0522 18:11:43.852599 12758 solver.cpp:253]     Train net output #0: loss = 1.05654 (* 1 = 1.05654 loss)
I0522 18:11:43.852624 12758 sgd_solver.cpp:106] Iteration 28875, lr = 0.001
I0522 18:11:53.671677 12758 solver.cpp:237] Iteration 29250, loss = 1.2969
I0522 18:11:53.671824 12758 solver.cpp:253]     Train net output #0: loss = 1.2969 (* 1 = 1.2969 loss)
I0522 18:11:53.671841 12758 sgd_solver.cpp:106] Iteration 29250, lr = 0.001
I0522 18:12:03.485558 12758 solver.cpp:237] Iteration 29625, loss = 1.46708
I0522 18:12:03.485615 12758 solver.cpp:253]     Train net output #0: loss = 1.46708 (* 1 = 1.46708 loss)
I0522 18:12:03.485641 12758 sgd_solver.cpp:106] Iteration 29625, lr = 0.001
I0522 18:12:13.251302 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_30000.caffemodel
I0522 18:12:13.308501 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_30000.solverstate
I0522 18:12:13.334723 12758 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 18:13:22.749532 12758 solver.cpp:409]     Test net output #0: accuracy = 0.841161
I0522 18:13:22.749716 12758 solver.cpp:409]     Test net output #1: loss = 0.525905 (* 1 = 0.525905 loss)
I0522 18:13:44.997092 12758 solver.cpp:237] Iteration 30000, loss = 1.43273
I0522 18:13:44.997154 12758 solver.cpp:253]     Train net output #0: loss = 1.43273 (* 1 = 1.43273 loss)
I0522 18:13:44.997186 12758 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0522 18:13:54.835073 12758 solver.cpp:237] Iteration 30375, loss = 1.35053
I0522 18:13:54.835247 12758 solver.cpp:253]     Train net output #0: loss = 1.35053 (* 1 = 1.35053 loss)
I0522 18:13:54.835264 12758 sgd_solver.cpp:106] Iteration 30375, lr = 0.001
I0522 18:14:04.670513 12758 solver.cpp:237] Iteration 30750, loss = 1.26526
I0522 18:14:04.670567 12758 solver.cpp:253]     Train net output #0: loss = 1.26526 (* 1 = 1.26526 loss)
I0522 18:14:04.670584 12758 sgd_solver.cpp:106] Iteration 30750, lr = 0.001
I0522 18:14:14.509135 12758 solver.cpp:237] Iteration 31125, loss = 1.06339
I0522 18:14:14.509173 12758 solver.cpp:253]     Train net output #0: loss = 1.06339 (* 1 = 1.06339 loss)
I0522 18:14:14.509196 12758 sgd_solver.cpp:106] Iteration 31125, lr = 0.001
I0522 18:14:24.337791 12758 solver.cpp:237] Iteration 31500, loss = 1.08614
I0522 18:14:24.337828 12758 solver.cpp:253]     Train net output #0: loss = 1.08614 (* 1 = 1.08614 loss)
I0522 18:14:24.337852 12758 sgd_solver.cpp:106] Iteration 31500, lr = 0.001
I0522 18:14:34.185027 12758 solver.cpp:237] Iteration 31875, loss = 1.36819
I0522 18:14:34.185196 12758 solver.cpp:253]     Train net output #0: loss = 1.36819 (* 1 = 1.36819 loss)
I0522 18:14:34.185215 12758 sgd_solver.cpp:106] Iteration 31875, lr = 0.001
I0522 18:14:44.051102 12758 solver.cpp:237] Iteration 32250, loss = 0.974667
I0522 18:14:44.051141 12758 solver.cpp:253]     Train net output #0: loss = 0.974667 (* 1 = 0.974667 loss)
I0522 18:14:44.051161 12758 sgd_solver.cpp:106] Iteration 32250, lr = 0.001
I0522 18:15:16.157799 12758 solver.cpp:237] Iteration 32625, loss = 1.30808
I0522 18:15:16.157971 12758 solver.cpp:253]     Train net output #0: loss = 1.30808 (* 1 = 1.30808 loss)
I0522 18:15:16.157989 12758 sgd_solver.cpp:106] Iteration 32625, lr = 0.001
I0522 18:15:26.019026 12758 solver.cpp:237] Iteration 33000, loss = 1.23838
I0522 18:15:26.019084 12758 solver.cpp:253]     Train net output #0: loss = 1.23838 (* 1 = 1.23838 loss)
I0522 18:15:26.019112 12758 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0522 18:15:35.886406 12758 solver.cpp:237] Iteration 33375, loss = 1.37532
I0522 18:15:35.886443 12758 solver.cpp:253]     Train net output #0: loss = 1.37532 (* 1 = 1.37532 loss)
I0522 18:15:35.886467 12758 sgd_solver.cpp:106] Iteration 33375, lr = 0.001
I0522 18:15:45.724164 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_33750.caffemodel
I0522 18:15:45.783260 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_33750.solverstate
I0522 18:15:45.820165 12758 solver.cpp:237] Iteration 33750, loss = 1.56564
I0522 18:15:45.820225 12758 solver.cpp:253]     Train net output #0: loss = 1.56564 (* 1 = 1.56564 loss)
I0522 18:15:45.820242 12758 sgd_solver.cpp:106] Iteration 33750, lr = 0.001
I0522 18:15:55.687865 12758 solver.cpp:237] Iteration 34125, loss = 1.35132
I0522 18:15:55.688027 12758 solver.cpp:253]     Train net output #0: loss = 1.35132 (* 1 = 1.35132 loss)
I0522 18:15:55.688045 12758 sgd_solver.cpp:106] Iteration 34125, lr = 0.001
I0522 18:16:05.556136 12758 solver.cpp:237] Iteration 34500, loss = 1.48004
I0522 18:16:05.556174 12758 solver.cpp:253]     Train net output #0: loss = 1.48004 (* 1 = 1.48004 loss)
I0522 18:16:05.556197 12758 sgd_solver.cpp:106] Iteration 34500, lr = 0.001
I0522 18:16:15.425212 12758 solver.cpp:237] Iteration 34875, loss = 1.49437
I0522 18:16:15.425272 12758 solver.cpp:253]     Train net output #0: loss = 1.49437 (* 1 = 1.49437 loss)
I0522 18:16:15.425298 12758 sgd_solver.cpp:106] Iteration 34875, lr = 0.001
I0522 18:16:47.520810 12758 solver.cpp:237] Iteration 35250, loss = 1.54121
I0522 18:16:47.520997 12758 solver.cpp:253]     Train net output #0: loss = 1.54121 (* 1 = 1.54121 loss)
I0522 18:16:47.521014 12758 sgd_solver.cpp:106] Iteration 35250, lr = 0.001
I0522 18:16:57.381727 12758 solver.cpp:237] Iteration 35625, loss = 1.50161
I0522 18:16:57.381764 12758 solver.cpp:253]     Train net output #0: loss = 1.50161 (* 1 = 1.50161 loss)
I0522 18:16:57.381788 12758 sgd_solver.cpp:106] Iteration 35625, lr = 0.001
I0522 18:17:07.173472 12758 solver.cpp:237] Iteration 36000, loss = 1.46087
I0522 18:17:07.173527 12758 solver.cpp:253]     Train net output #0: loss = 1.46087 (* 1 = 1.46087 loss)
I0522 18:17:07.173544 12758 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0522 18:17:16.950172 12758 solver.cpp:237] Iteration 36375, loss = 1.29296
I0522 18:17:16.950211 12758 solver.cpp:253]     Train net output #0: loss = 1.29296 (* 1 = 1.29296 loss)
I0522 18:17:16.950229 12758 sgd_solver.cpp:106] Iteration 36375, lr = 0.001
I0522 18:17:26.732560 12758 solver.cpp:237] Iteration 36750, loss = 1.35585
I0522 18:17:26.732729 12758 solver.cpp:253]     Train net output #0: loss = 1.35585 (* 1 = 1.35585 loss)
I0522 18:17:26.732748 12758 sgd_solver.cpp:106] Iteration 36750, lr = 0.001
I0522 18:17:36.507882 12758 solver.cpp:237] Iteration 37125, loss = 1.49282
I0522 18:17:36.507920 12758 solver.cpp:253]     Train net output #0: loss = 1.49282 (* 1 = 1.49282 loss)
I0522 18:17:36.507948 12758 sgd_solver.cpp:106] Iteration 37125, lr = 0.001
I0522 18:17:46.260942 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_37500.caffemodel
I0522 18:17:46.319159 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_37500.solverstate
I0522 18:17:46.348047 12758 solver.cpp:341] Iteration 37500, Testing net (#0)
I0522 18:18:34.916535 12758 solver.cpp:409]     Test net output #0: accuracy = 0.852982
I0522 18:18:34.916705 12758 solver.cpp:409]     Test net output #1: loss = 0.478886 (* 1 = 0.478886 loss)
I0522 18:18:55.792132 12758 solver.cpp:237] Iteration 37500, loss = 1.14329
I0522 18:18:55.792193 12758 solver.cpp:253]     Train net output #0: loss = 1.14329 (* 1 = 1.14329 loss)
I0522 18:18:55.792222 12758 sgd_solver.cpp:106] Iteration 37500, lr = 0.001
I0522 18:19:05.636629 12758 solver.cpp:237] Iteration 37875, loss = 1.35289
I0522 18:19:05.636802 12758 solver.cpp:253]     Train net output #0: loss = 1.35289 (* 1 = 1.35289 loss)
I0522 18:19:05.636827 12758 sgd_solver.cpp:106] Iteration 37875, lr = 0.001
I0522 18:19:15.483032 12758 solver.cpp:237] Iteration 38250, loss = 1.44269
I0522 18:19:15.483069 12758 solver.cpp:253]     Train net output #0: loss = 1.44269 (* 1 = 1.44269 loss)
I0522 18:19:15.483093 12758 sgd_solver.cpp:106] Iteration 38250, lr = 0.001
I0522 18:19:25.327687 12758 solver.cpp:237] Iteration 38625, loss = 1.29092
I0522 18:19:25.327725 12758 solver.cpp:253]     Train net output #0: loss = 1.29092 (* 1 = 1.29092 loss)
I0522 18:19:25.327749 12758 sgd_solver.cpp:106] Iteration 38625, lr = 0.001
I0522 18:19:35.133066 12758 solver.cpp:237] Iteration 39000, loss = 1.18268
I0522 18:19:35.133121 12758 solver.cpp:253]     Train net output #0: loss = 1.18268 (* 1 = 1.18268 loss)
I0522 18:19:35.133139 12758 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0522 18:19:44.912997 12758 solver.cpp:237] Iteration 39375, loss = 1.14863
I0522 18:19:44.913147 12758 solver.cpp:253]     Train net output #0: loss = 1.14863 (* 1 = 1.14863 loss)
I0522 18:19:44.913164 12758 sgd_solver.cpp:106] Iteration 39375, lr = 0.001
I0522 18:19:54.693351 12758 solver.cpp:237] Iteration 39750, loss = 1.14897
I0522 18:19:54.693408 12758 solver.cpp:253]     Train net output #0: loss = 1.14897 (* 1 = 1.14897 loss)
I0522 18:19:54.693439 12758 sgd_solver.cpp:106] Iteration 39750, lr = 0.001
I0522 18:20:25.315534 12758 solver.cpp:237] Iteration 40125, loss = 1.15985
I0522 18:20:25.315716 12758 solver.cpp:253]     Train net output #0: loss = 1.15985 (* 1 = 1.15985 loss)
I0522 18:20:25.315733 12758 sgd_solver.cpp:106] Iteration 40125, lr = 0.001
I0522 18:20:35.090600 12758 solver.cpp:237] Iteration 40500, loss = 1.21295
I0522 18:20:35.090637 12758 solver.cpp:253]     Train net output #0: loss = 1.21295 (* 1 = 1.21295 loss)
I0522 18:20:35.090662 12758 sgd_solver.cpp:106] Iteration 40500, lr = 0.001
I0522 18:20:44.873597 12758 solver.cpp:237] Iteration 40875, loss = 1.51314
I0522 18:20:44.873654 12758 solver.cpp:253]     Train net output #0: loss = 1.51314 (* 1 = 1.51314 loss)
I0522 18:20:44.873672 12758 sgd_solver.cpp:106] Iteration 40875, lr = 0.001
I0522 18:20:54.678908 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_41250.caffemodel
I0522 18:20:54.734699 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_41250.solverstate
I0522 18:20:54.769369 12758 solver.cpp:237] Iteration 41250, loss = 1.18231
I0522 18:20:54.769426 12758 solver.cpp:253]     Train net output #0: loss = 1.18231 (* 1 = 1.18231 loss)
I0522 18:20:54.769446 12758 sgd_solver.cpp:106] Iteration 41250, lr = 0.001
I0522 18:21:04.601449 12758 solver.cpp:237] Iteration 41625, loss = 1.40785
I0522 18:21:04.601606 12758 solver.cpp:253]     Train net output #0: loss = 1.40785 (* 1 = 1.40785 loss)
I0522 18:21:04.601624 12758 sgd_solver.cpp:106] Iteration 41625, lr = 0.001
I0522 18:21:14.435309 12758 solver.cpp:237] Iteration 42000, loss = 1.28772
I0522 18:21:14.435365 12758 solver.cpp:253]     Train net output #0: loss = 1.28772 (* 1 = 1.28772 loss)
I0522 18:21:14.435382 12758 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0522 18:21:24.266852 12758 solver.cpp:237] Iteration 42375, loss = 0.924123
I0522 18:21:24.266891 12758 solver.cpp:253]     Train net output #0: loss = 0.924123 (* 1 = 0.924123 loss)
I0522 18:21:24.266913 12758 sgd_solver.cpp:106] Iteration 42375, lr = 0.001
I0522 18:21:54.995867 12758 solver.cpp:237] Iteration 42750, loss = 0.925372
I0522 18:21:54.996060 12758 solver.cpp:253]     Train net output #0: loss = 0.925372 (* 1 = 0.925372 loss)
I0522 18:21:54.996078 12758 sgd_solver.cpp:106] Iteration 42750, lr = 0.001
I0522 18:22:04.759760 12758 solver.cpp:237] Iteration 43125, loss = 1.11412
I0522 18:22:04.759819 12758 solver.cpp:253]     Train net output #0: loss = 1.11412 (* 1 = 1.11412 loss)
I0522 18:22:04.759845 12758 sgd_solver.cpp:106] Iteration 43125, lr = 0.001
I0522 18:22:14.484444 12758 solver.cpp:237] Iteration 43500, loss = 1.22676
I0522 18:22:14.484483 12758 solver.cpp:253]     Train net output #0: loss = 1.22676 (* 1 = 1.22676 loss)
I0522 18:22:14.484501 12758 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I0522 18:22:24.210906 12758 solver.cpp:237] Iteration 43875, loss = 1.36133
I0522 18:22:24.210964 12758 solver.cpp:253]     Train net output #0: loss = 1.36133 (* 1 = 1.36133 loss)
I0522 18:22:24.210984 12758 sgd_solver.cpp:106] Iteration 43875, lr = 0.001
I0522 18:22:33.947628 12758 solver.cpp:237] Iteration 44250, loss = 1.4651
I0522 18:22:33.947782 12758 solver.cpp:253]     Train net output #0: loss = 1.4651 (* 1 = 1.4651 loss)
I0522 18:22:33.947799 12758 sgd_solver.cpp:106] Iteration 44250, lr = 0.001
I0522 18:22:43.675969 12758 solver.cpp:237] Iteration 44625, loss = 1.10202
I0522 18:22:43.676005 12758 solver.cpp:253]     Train net output #0: loss = 1.10202 (* 1 = 1.10202 loss)
I0522 18:22:43.676029 12758 sgd_solver.cpp:106] Iteration 44625, lr = 0.001
I0522 18:22:53.391571 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_45000.caffemodel
I0522 18:22:53.448593 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_45000.solverstate
I0522 18:22:53.475023 12758 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 18:24:02.879771 12758 solver.cpp:409]     Test net output #0: accuracy = 0.856106
I0522 18:24:02.879976 12758 solver.cpp:409]     Test net output #1: loss = 0.442133 (* 1 = 0.442133 loss)
I0522 18:24:23.710836 12758 solver.cpp:237] Iteration 45000, loss = 1.31855
I0522 18:24:23.710901 12758 solver.cpp:253]     Train net output #0: loss = 1.31855 (* 1 = 1.31855 loss)
I0522 18:24:23.710921 12758 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0522 18:24:33.500257 12758 solver.cpp:237] Iteration 45375, loss = 1.33617
I0522 18:24:33.500437 12758 solver.cpp:253]     Train net output #0: loss = 1.33617 (* 1 = 1.33617 loss)
I0522 18:24:33.500455 12758 sgd_solver.cpp:106] Iteration 45375, lr = 0.001
I0522 18:24:43.182939 12758 solver.cpp:237] Iteration 45750, loss = 1.23283
I0522 18:24:43.182976 12758 solver.cpp:253]     Train net output #0: loss = 1.23283 (* 1 = 1.23283 loss)
I0522 18:24:43.182996 12758 sgd_solver.cpp:106] Iteration 45750, lr = 0.001
I0522 18:24:52.868181 12758 solver.cpp:237] Iteration 46125, loss = 1.37476
I0522 18:24:52.868219 12758 solver.cpp:253]     Train net output #0: loss = 1.37476 (* 1 = 1.37476 loss)
I0522 18:24:52.868243 12758 sgd_solver.cpp:106] Iteration 46125, lr = 0.001
I0522 18:25:02.551023 12758 solver.cpp:237] Iteration 46500, loss = 1.27526
I0522 18:25:02.551077 12758 solver.cpp:253]     Train net output #0: loss = 1.27526 (* 1 = 1.27526 loss)
I0522 18:25:02.551095 12758 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I0522 18:25:12.236852 12758 solver.cpp:237] Iteration 46875, loss = 1.38953
I0522 18:25:12.237004 12758 solver.cpp:253]     Train net output #0: loss = 1.38953 (* 1 = 1.38953 loss)
I0522 18:25:12.237021 12758 sgd_solver.cpp:106] Iteration 46875, lr = 0.001
I0522 18:25:21.930364 12758 solver.cpp:237] Iteration 47250, loss = 1.13271
I0522 18:25:21.930423 12758 solver.cpp:253]     Train net output #0: loss = 1.13271 (* 1 = 1.13271 loss)
I0522 18:25:21.930450 12758 sgd_solver.cpp:106] Iteration 47250, lr = 0.001
I0522 18:25:52.483898 12758 solver.cpp:237] Iteration 47625, loss = 1.28129
I0522 18:25:52.484079 12758 solver.cpp:253]     Train net output #0: loss = 1.28129 (* 1 = 1.28129 loss)
I0522 18:25:52.484097 12758 sgd_solver.cpp:106] Iteration 47625, lr = 0.001
I0522 18:26:02.190307 12758 solver.cpp:237] Iteration 48000, loss = 1.14525
I0522 18:26:02.190343 12758 solver.cpp:253]     Train net output #0: loss = 1.14525 (* 1 = 1.14525 loss)
I0522 18:26:02.190367 12758 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0522 18:26:11.905194 12758 solver.cpp:237] Iteration 48375, loss = 1.28791
I0522 18:26:11.905253 12758 solver.cpp:253]     Train net output #0: loss = 1.28791 (* 1 = 1.28791 loss)
I0522 18:26:11.905279 12758 sgd_solver.cpp:106] Iteration 48375, lr = 0.001
I0522 18:26:21.588551 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_48750.caffemodel
I0522 18:26:21.643985 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_48750.solverstate
I0522 18:26:21.679019 12758 solver.cpp:237] Iteration 48750, loss = 1.16248
I0522 18:26:21.679075 12758 solver.cpp:253]     Train net output #0: loss = 1.16248 (* 1 = 1.16248 loss)
I0522 18:26:21.679101 12758 sgd_solver.cpp:106] Iteration 48750, lr = 0.001
I0522 18:26:31.383318 12758 solver.cpp:237] Iteration 49125, loss = 1.16803
I0522 18:26:31.383483 12758 solver.cpp:253]     Train net output #0: loss = 1.16803 (* 1 = 1.16803 loss)
I0522 18:26:31.383501 12758 sgd_solver.cpp:106] Iteration 49125, lr = 0.001
I0522 18:26:41.129751 12758 solver.cpp:237] Iteration 49500, loss = 1.44374
I0522 18:26:41.129808 12758 solver.cpp:253]     Train net output #0: loss = 1.44374 (* 1 = 1.44374 loss)
I0522 18:26:41.129834 12758 sgd_solver.cpp:106] Iteration 49500, lr = 0.001
I0522 18:26:50.890650 12758 solver.cpp:237] Iteration 49875, loss = 1.52892
I0522 18:26:50.890686 12758 solver.cpp:253]     Train net output #0: loss = 1.52892 (* 1 = 1.52892 loss)
I0522 18:26:50.890709 12758 sgd_solver.cpp:106] Iteration 49875, lr = 0.001
I0522 18:27:21.493093 12758 solver.cpp:237] Iteration 50250, loss = 1.24163
I0522 18:27:21.493274 12758 solver.cpp:253]     Train net output #0: loss = 1.24163 (* 1 = 1.24163 loss)
I0522 18:27:21.493293 12758 sgd_solver.cpp:106] Iteration 50250, lr = 0.001
I0522 18:27:31.254966 12758 solver.cpp:237] Iteration 50625, loss = 1.12177
I0522 18:27:31.255023 12758 solver.cpp:253]     Train net output #0: loss = 1.12177 (* 1 = 1.12177 loss)
I0522 18:27:31.255049 12758 sgd_solver.cpp:106] Iteration 50625, lr = 0.001
I0522 18:27:41.018478 12758 solver.cpp:237] Iteration 51000, loss = 1.01633
I0522 18:27:41.018517 12758 solver.cpp:253]     Train net output #0: loss = 1.01633 (* 1 = 1.01633 loss)
I0522 18:27:41.018539 12758 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0522 18:27:50.762312 12758 solver.cpp:237] Iteration 51375, loss = 1.18782
I0522 18:27:50.762370 12758 solver.cpp:253]     Train net output #0: loss = 1.18782 (* 1 = 1.18782 loss)
I0522 18:27:50.762395 12758 sgd_solver.cpp:106] Iteration 51375, lr = 0.001
I0522 18:28:00.446823 12758 solver.cpp:237] Iteration 51750, loss = 1.36742
I0522 18:28:00.446977 12758 solver.cpp:253]     Train net output #0: loss = 1.36742 (* 1 = 1.36742 loss)
I0522 18:28:00.446995 12758 sgd_solver.cpp:106] Iteration 51750, lr = 0.001
I0522 18:28:10.134260 12758 solver.cpp:237] Iteration 52125, loss = 0.815746
I0522 18:28:10.134297 12758 solver.cpp:253]     Train net output #0: loss = 0.815746 (* 1 = 0.815746 loss)
I0522 18:28:10.134320 12758 sgd_solver.cpp:106] Iteration 52125, lr = 0.001
I0522 18:28:19.798382 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_52500.caffemodel
I0522 18:28:19.855984 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_52500.solverstate
I0522 18:28:19.882555 12758 solver.cpp:341] Iteration 52500, Testing net (#0)
I0522 18:29:08.098290 12758 solver.cpp:409]     Test net output #0: accuracy = 0.864793
I0522 18:29:08.098465 12758 solver.cpp:409]     Test net output #1: loss = 0.463253 (* 1 = 0.463253 loss)
I0522 18:29:28.957099 12758 solver.cpp:237] Iteration 52500, loss = 1.10191
I0522 18:29:28.957165 12758 solver.cpp:253]     Train net output #0: loss = 1.10191 (* 1 = 1.10191 loss)
I0522 18:29:28.957183 12758 sgd_solver.cpp:106] Iteration 52500, lr = 0.001
I0522 18:29:38.882174 12758 solver.cpp:237] Iteration 52875, loss = 0.983915
I0522 18:29:38.882336 12758 solver.cpp:253]     Train net output #0: loss = 0.983915 (* 1 = 0.983915 loss)
I0522 18:29:38.882354 12758 sgd_solver.cpp:106] Iteration 52875, lr = 0.001
I0522 18:29:48.806710 12758 solver.cpp:237] Iteration 53250, loss = 1.46003
I0522 18:29:48.806747 12758 solver.cpp:253]     Train net output #0: loss = 1.46003 (* 1 = 1.46003 loss)
I0522 18:29:48.806771 12758 sgd_solver.cpp:106] Iteration 53250, lr = 0.001
I0522 18:29:58.725008 12758 solver.cpp:237] Iteration 53625, loss = 1.12124
I0522 18:29:58.725064 12758 solver.cpp:253]     Train net output #0: loss = 1.12124 (* 1 = 1.12124 loss)
I0522 18:29:58.725083 12758 sgd_solver.cpp:106] Iteration 53625, lr = 0.001
I0522 18:30:08.649729 12758 solver.cpp:237] Iteration 54000, loss = 1.49702
I0522 18:30:08.649765 12758 solver.cpp:253]     Train net output #0: loss = 1.49702 (* 1 = 1.49702 loss)
I0522 18:30:08.649788 12758 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0522 18:30:18.574400 12758 solver.cpp:237] Iteration 54375, loss = 1.09822
I0522 18:30:18.574563 12758 solver.cpp:253]     Train net output #0: loss = 1.09822 (* 1 = 1.09822 loss)
I0522 18:30:18.574580 12758 sgd_solver.cpp:106] Iteration 54375, lr = 0.001
I0522 18:30:28.498986 12758 solver.cpp:237] Iteration 54750, loss = 0.83102
I0522 18:30:28.499042 12758 solver.cpp:253]     Train net output #0: loss = 0.83102 (* 1 = 0.83102 loss)
I0522 18:30:28.499065 12758 sgd_solver.cpp:106] Iteration 54750, lr = 0.001
I0522 18:30:59.270510 12758 solver.cpp:237] Iteration 55125, loss = 1.11013
I0522 18:30:59.270694 12758 solver.cpp:253]     Train net output #0: loss = 1.11013 (* 1 = 1.11013 loss)
I0522 18:30:59.270710 12758 sgd_solver.cpp:106] Iteration 55125, lr = 0.001
I0522 18:31:09.186245 12758 solver.cpp:237] Iteration 55500, loss = 1.26672
I0522 18:31:09.186306 12758 solver.cpp:253]     Train net output #0: loss = 1.26672 (* 1 = 1.26672 loss)
I0522 18:31:09.186332 12758 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I0522 18:31:19.111611 12758 solver.cpp:237] Iteration 55875, loss = 1.46925
I0522 18:31:19.111649 12758 solver.cpp:253]     Train net output #0: loss = 1.46925 (* 1 = 1.46925 loss)
I0522 18:31:19.111673 12758 sgd_solver.cpp:106] Iteration 55875, lr = 0.001
I0522 18:31:29.004283 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_56250.caffemodel
I0522 18:31:29.063725 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_56250.solverstate
I0522 18:31:29.100600 12758 solver.cpp:237] Iteration 56250, loss = 1.15397
I0522 18:31:29.100666 12758 solver.cpp:253]     Train net output #0: loss = 1.15397 (* 1 = 1.15397 loss)
I0522 18:31:29.100683 12758 sgd_solver.cpp:106] Iteration 56250, lr = 0.001
I0522 18:31:39.020696 12758 solver.cpp:237] Iteration 56625, loss = 1.1044
I0522 18:31:39.020874 12758 solver.cpp:253]     Train net output #0: loss = 1.1044 (* 1 = 1.1044 loss)
I0522 18:31:39.020891 12758 sgd_solver.cpp:106] Iteration 56625, lr = 0.001
I0522 18:31:48.938784 12758 solver.cpp:237] Iteration 57000, loss = 1.68158
I0522 18:31:48.938820 12758 solver.cpp:253]     Train net output #0: loss = 1.68158 (* 1 = 1.68158 loss)
I0522 18:31:48.938845 12758 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0522 18:31:58.853085 12758 solver.cpp:237] Iteration 57375, loss = 1.27921
I0522 18:31:58.853147 12758 solver.cpp:253]     Train net output #0: loss = 1.27921 (* 1 = 1.27921 loss)
I0522 18:31:58.853173 12758 sgd_solver.cpp:106] Iteration 57375, lr = 0.001
I0522 18:32:29.521877 12758 solver.cpp:237] Iteration 57750, loss = 1.45539
I0522 18:32:29.522053 12758 solver.cpp:253]     Train net output #0: loss = 1.45539 (* 1 = 1.45539 loss)
I0522 18:32:29.522070 12758 sgd_solver.cpp:106] Iteration 57750, lr = 0.001
I0522 18:32:39.281769 12758 solver.cpp:237] Iteration 58125, loss = 1.18102
I0522 18:32:39.281808 12758 solver.cpp:253]     Train net output #0: loss = 1.18102 (* 1 = 1.18102 loss)
I0522 18:32:39.281836 12758 sgd_solver.cpp:106] Iteration 58125, lr = 0.001
I0522 18:32:49.045181 12758 solver.cpp:237] Iteration 58500, loss = 1.55661
I0522 18:32:49.045239 12758 solver.cpp:253]     Train net output #0: loss = 1.55661 (* 1 = 1.55661 loss)
I0522 18:32:49.045259 12758 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I0522 18:32:58.891260 12758 solver.cpp:237] Iteration 58875, loss = 1.54312
I0522 18:32:58.891300 12758 solver.cpp:253]     Train net output #0: loss = 1.54312 (* 1 = 1.54312 loss)
I0522 18:32:58.891319 12758 sgd_solver.cpp:106] Iteration 58875, lr = 0.001
I0522 18:33:08.732830 12758 solver.cpp:237] Iteration 59250, loss = 0.993169
I0522 18:33:08.732996 12758 solver.cpp:253]     Train net output #0: loss = 0.993169 (* 1 = 0.993169 loss)
I0522 18:33:08.733013 12758 sgd_solver.cpp:106] Iteration 59250, lr = 0.001
I0522 18:33:18.611623 12758 solver.cpp:237] Iteration 59625, loss = 0.834817
I0522 18:33:18.611678 12758 solver.cpp:253]     Train net output #0: loss = 0.834817 (* 1 = 0.834817 loss)
I0522 18:33:18.611696 12758 sgd_solver.cpp:106] Iteration 59625, lr = 0.001
I0522 18:33:28.506624 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_60000.caffemodel
I0522 18:33:28.563792 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_60000.solverstate
I0522 18:33:28.590561 12758 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 18:34:37.972973 12758 solver.cpp:409]     Test net output #0: accuracy = 0.867674
I0522 18:34:37.973161 12758 solver.cpp:409]     Test net output #1: loss = 0.448726 (* 1 = 0.448726 loss)
I0522 18:34:58.844846 12758 solver.cpp:237] Iteration 60000, loss = 1.08759
I0522 18:34:58.844909 12758 solver.cpp:253]     Train net output #0: loss = 1.08759 (* 1 = 1.08759 loss)
I0522 18:34:58.844936 12758 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0522 18:35:08.579905 12758 solver.cpp:237] Iteration 60375, loss = 0.994216
I0522 18:35:08.580083 12758 solver.cpp:253]     Train net output #0: loss = 0.994216 (* 1 = 0.994216 loss)
I0522 18:35:08.580101 12758 sgd_solver.cpp:106] Iteration 60375, lr = 0.001
I0522 18:35:18.313374 12758 solver.cpp:237] Iteration 60750, loss = 1.3153
I0522 18:35:18.313410 12758 solver.cpp:253]     Train net output #0: loss = 1.3153 (* 1 = 1.3153 loss)
I0522 18:35:18.313428 12758 sgd_solver.cpp:106] Iteration 60750, lr = 0.001
I0522 18:35:28.046988 12758 solver.cpp:237] Iteration 61125, loss = 1.35398
I0522 18:35:28.047044 12758 solver.cpp:253]     Train net output #0: loss = 1.35398 (* 1 = 1.35398 loss)
I0522 18:35:28.047068 12758 sgd_solver.cpp:106] Iteration 61125, lr = 0.001
I0522 18:35:37.785540 12758 solver.cpp:237] Iteration 61500, loss = 1.31099
I0522 18:35:37.785578 12758 solver.cpp:253]     Train net output #0: loss = 1.31099 (* 1 = 1.31099 loss)
I0522 18:35:37.785596 12758 sgd_solver.cpp:106] Iteration 61500, lr = 0.001
I0522 18:35:47.523892 12758 solver.cpp:237] Iteration 61875, loss = 1.08177
I0522 18:35:47.524073 12758 solver.cpp:253]     Train net output #0: loss = 1.08177 (* 1 = 1.08177 loss)
I0522 18:35:47.524092 12758 sgd_solver.cpp:106] Iteration 61875, lr = 0.001
I0522 18:35:57.277943 12758 solver.cpp:237] Iteration 62250, loss = 1.14727
I0522 18:35:57.277982 12758 solver.cpp:253]     Train net output #0: loss = 1.14727 (* 1 = 1.14727 loss)
I0522 18:35:57.278002 12758 sgd_solver.cpp:106] Iteration 62250, lr = 0.001
I0522 18:36:27.880748 12758 solver.cpp:237] Iteration 62625, loss = 1.33876
I0522 18:36:27.880926 12758 solver.cpp:253]     Train net output #0: loss = 1.33876 (* 1 = 1.33876 loss)
I0522 18:36:27.880944 12758 sgd_solver.cpp:106] Iteration 62625, lr = 0.001
I0522 18:36:37.649003 12758 solver.cpp:237] Iteration 63000, loss = 1.05924
I0522 18:36:37.649061 12758 solver.cpp:253]     Train net output #0: loss = 1.05924 (* 1 = 1.05924 loss)
I0522 18:36:37.649080 12758 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I0522 18:36:47.427397 12758 solver.cpp:237] Iteration 63375, loss = 0.873081
I0522 18:36:47.427434 12758 solver.cpp:253]     Train net output #0: loss = 0.873081 (* 1 = 0.873081 loss)
I0522 18:36:47.427459 12758 sgd_solver.cpp:106] Iteration 63375, lr = 0.001
I0522 18:36:57.183713 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_63750.caffemodel
I0522 18:36:57.239624 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_63750.solverstate
I0522 18:36:57.274261 12758 solver.cpp:237] Iteration 63750, loss = 1.17365
I0522 18:36:57.274318 12758 solver.cpp:253]     Train net output #0: loss = 1.17365 (* 1 = 1.17365 loss)
I0522 18:36:57.274343 12758 sgd_solver.cpp:106] Iteration 63750, lr = 0.001
I0522 18:37:07.055305 12758 solver.cpp:237] Iteration 64125, loss = 1.0915
I0522 18:37:07.055492 12758 solver.cpp:253]     Train net output #0: loss = 1.0915 (* 1 = 1.0915 loss)
I0522 18:37:07.055510 12758 sgd_solver.cpp:106] Iteration 64125, lr = 0.001
I0522 18:37:16.836221 12758 solver.cpp:237] Iteration 64500, loss = 1.30908
I0522 18:37:16.836257 12758 solver.cpp:253]     Train net output #0: loss = 1.30908 (* 1 = 1.30908 loss)
I0522 18:37:16.836280 12758 sgd_solver.cpp:106] Iteration 64500, lr = 0.001
I0522 18:37:26.634307 12758 solver.cpp:237] Iteration 64875, loss = 1.30856
I0522 18:37:26.634363 12758 solver.cpp:253]     Train net output #0: loss = 1.30856 (* 1 = 1.30856 loss)
I0522 18:37:26.634389 12758 sgd_solver.cpp:106] Iteration 64875, lr = 0.001
I0522 18:37:57.352838 12758 solver.cpp:237] Iteration 65250, loss = 1.06256
I0522 18:37:57.353024 12758 solver.cpp:253]     Train net output #0: loss = 1.06256 (* 1 = 1.06256 loss)
I0522 18:37:57.353040 12758 sgd_solver.cpp:106] Iteration 65250, lr = 0.001
I0522 18:38:07.199321 12758 solver.cpp:237] Iteration 65625, loss = 1.32509
I0522 18:38:07.199359 12758 solver.cpp:253]     Train net output #0: loss = 1.32509 (* 1 = 1.32509 loss)
I0522 18:38:07.199378 12758 sgd_solver.cpp:106] Iteration 65625, lr = 0.001
I0522 18:38:16.998391 12758 solver.cpp:237] Iteration 66000, loss = 1.35069
I0522 18:38:16.998445 12758 solver.cpp:253]     Train net output #0: loss = 1.35069 (* 1 = 1.35069 loss)
I0522 18:38:16.998462 12758 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I0522 18:38:26.699067 12758 solver.cpp:237] Iteration 66375, loss = 1.17165
I0522 18:38:26.699111 12758 solver.cpp:253]     Train net output #0: loss = 1.17165 (* 1 = 1.17165 loss)
I0522 18:38:26.699128 12758 sgd_solver.cpp:106] Iteration 66375, lr = 0.001
I0522 18:38:36.401229 12758 solver.cpp:237] Iteration 66750, loss = 1.13391
I0522 18:38:36.401389 12758 solver.cpp:253]     Train net output #0: loss = 1.13391 (* 1 = 1.13391 loss)
I0522 18:38:36.401407 12758 sgd_solver.cpp:106] Iteration 66750, lr = 0.001
I0522 18:38:46.257761 12758 solver.cpp:237] Iteration 67125, loss = 1.48401
I0522 18:38:46.257817 12758 solver.cpp:253]     Train net output #0: loss = 1.48401 (* 1 = 1.48401 loss)
I0522 18:38:46.257834 12758 sgd_solver.cpp:106] Iteration 67125, lr = 0.001
I0522 18:38:56.142829 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_67500.caffemodel
I0522 18:38:56.199106 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_67500.solverstate
I0522 18:38:56.225874 12758 solver.cpp:341] Iteration 67500, Testing net (#0)
I0522 18:39:44.751932 12758 solver.cpp:409]     Test net output #0: accuracy = 0.86772
I0522 18:39:44.752122 12758 solver.cpp:409]     Test net output #1: loss = 0.41434 (* 1 = 0.41434 loss)
I0522 18:40:05.643740 12758 solver.cpp:237] Iteration 67500, loss = 1.28104
I0522 18:40:05.643808 12758 solver.cpp:253]     Train net output #0: loss = 1.28104 (* 1 = 1.28104 loss)
I0522 18:40:05.643826 12758 sgd_solver.cpp:106] Iteration 67500, lr = 0.001
I0522 18:40:15.429479 12758 solver.cpp:237] Iteration 67875, loss = 1.22788
I0522 18:40:15.429644 12758 solver.cpp:253]     Train net output #0: loss = 1.22788 (* 1 = 1.22788 loss)
I0522 18:40:15.429661 12758 sgd_solver.cpp:106] Iteration 67875, lr = 0.001
I0522 18:40:25.208438 12758 solver.cpp:237] Iteration 68250, loss = 1.29381
I0522 18:40:25.208497 12758 solver.cpp:253]     Train net output #0: loss = 1.29381 (* 1 = 1.29381 loss)
I0522 18:40:25.208523 12758 sgd_solver.cpp:106] Iteration 68250, lr = 0.001
I0522 18:40:34.992830 12758 solver.cpp:237] Iteration 68625, loss = 0.943626
I0522 18:40:34.992869 12758 solver.cpp:253]     Train net output #0: loss = 0.943626 (* 1 = 0.943626 loss)
I0522 18:40:34.992888 12758 sgd_solver.cpp:106] Iteration 68625, lr = 0.001
I0522 18:40:44.788969 12758 solver.cpp:237] Iteration 69000, loss = 1.20421
I0522 18:40:44.789023 12758 solver.cpp:253]     Train net output #0: loss = 1.20421 (* 1 = 1.20421 loss)
I0522 18:40:44.789041 12758 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I0522 18:40:54.708962 12758 solver.cpp:237] Iteration 69375, loss = 1.14577
I0522 18:40:54.709132 12758 solver.cpp:253]     Train net output #0: loss = 1.14577 (* 1 = 1.14577 loss)
I0522 18:40:54.709149 12758 sgd_solver.cpp:106] Iteration 69375, lr = 0.001
I0522 18:41:04.621758 12758 solver.cpp:237] Iteration 69750, loss = 1.25104
I0522 18:41:04.621796 12758 solver.cpp:253]     Train net output #0: loss = 1.25104 (* 1 = 1.25104 loss)
I0522 18:41:04.621815 12758 sgd_solver.cpp:106] Iteration 69750, lr = 0.001
I0522 18:41:35.303274 12758 solver.cpp:237] Iteration 70125, loss = 1.19111
I0522 18:41:35.303457 12758 solver.cpp:253]     Train net output #0: loss = 1.19111 (* 1 = 1.19111 loss)
I0522 18:41:35.303475 12758 sgd_solver.cpp:106] Iteration 70125, lr = 0.001
I0522 18:41:45.010190 12758 solver.cpp:237] Iteration 70500, loss = 1.20971
I0522 18:41:45.010226 12758 solver.cpp:253]     Train net output #0: loss = 1.20971 (* 1 = 1.20971 loss)
I0522 18:41:45.010251 12758 sgd_solver.cpp:106] Iteration 70500, lr = 0.001
I0522 18:41:54.718605 12758 solver.cpp:237] Iteration 70875, loss = 1.33813
I0522 18:41:54.718641 12758 solver.cpp:253]     Train net output #0: loss = 1.33813 (* 1 = 1.33813 loss)
I0522 18:41:54.718664 12758 sgd_solver.cpp:106] Iteration 70875, lr = 0.001
I0522 18:42:04.477979 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_71250.caffemodel
I0522 18:42:04.537008 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_71250.solverstate
I0522 18:42:04.573940 12758 solver.cpp:237] Iteration 71250, loss = 1.40872
I0522 18:42:04.574005 12758 solver.cpp:253]     Train net output #0: loss = 1.40872 (* 1 = 1.40872 loss)
I0522 18:42:04.574023 12758 sgd_solver.cpp:106] Iteration 71250, lr = 0.001
I0522 18:42:14.411927 12758 solver.cpp:237] Iteration 71625, loss = 0.986435
I0522 18:42:14.412096 12758 solver.cpp:253]     Train net output #0: loss = 0.986435 (* 1 = 0.986435 loss)
I0522 18:42:14.412114 12758 sgd_solver.cpp:106] Iteration 71625, lr = 0.001
I0522 18:42:24.243237 12758 solver.cpp:237] Iteration 72000, loss = 1.52033
I0522 18:42:24.243295 12758 solver.cpp:253]     Train net output #0: loss = 1.52033 (* 1 = 1.52033 loss)
I0522 18:42:24.243324 12758 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I0522 18:42:34.114410 12758 solver.cpp:237] Iteration 72375, loss = 1.15413
I0522 18:42:34.114447 12758 solver.cpp:253]     Train net output #0: loss = 1.15413 (* 1 = 1.15413 loss)
I0522 18:42:34.114472 12758 sgd_solver.cpp:106] Iteration 72375, lr = 0.001
I0522 18:43:04.881577 12758 solver.cpp:237] Iteration 72750, loss = 1.03275
I0522 18:43:04.881762 12758 solver.cpp:253]     Train net output #0: loss = 1.03275 (* 1 = 1.03275 loss)
I0522 18:43:04.881779 12758 sgd_solver.cpp:106] Iteration 72750, lr = 0.001
I0522 18:43:14.741883 12758 solver.cpp:237] Iteration 73125, loss = 1.48917
I0522 18:43:14.741941 12758 solver.cpp:253]     Train net output #0: loss = 1.48917 (* 1 = 1.48917 loss)
I0522 18:43:14.741961 12758 sgd_solver.cpp:106] Iteration 73125, lr = 0.001
I0522 18:43:24.512154 12758 solver.cpp:237] Iteration 73500, loss = 1.26921
I0522 18:43:24.512193 12758 solver.cpp:253]     Train net output #0: loss = 1.26921 (* 1 = 1.26921 loss)
I0522 18:43:24.512212 12758 sgd_solver.cpp:106] Iteration 73500, lr = 0.001
I0522 18:43:34.280730 12758 solver.cpp:237] Iteration 73875, loss = 1.3658
I0522 18:43:34.280768 12758 solver.cpp:253]     Train net output #0: loss = 1.3658 (* 1 = 1.3658 loss)
I0522 18:43:34.280786 12758 sgd_solver.cpp:106] Iteration 73875, lr = 0.001
I0522 18:43:44.036557 12758 solver.cpp:237] Iteration 74250, loss = 0.952157
I0522 18:43:44.036751 12758 solver.cpp:253]     Train net output #0: loss = 0.952157 (* 1 = 0.952157 loss)
I0522 18:43:44.036769 12758 sgd_solver.cpp:106] Iteration 74250, lr = 0.001
I0522 18:43:53.771812 12758 solver.cpp:237] Iteration 74625, loss = 1.17574
I0522 18:43:53.771849 12758 solver.cpp:253]     Train net output #0: loss = 1.17574 (* 1 = 1.17574 loss)
I0522 18:43:53.771873 12758 sgd_solver.cpp:106] Iteration 74625, lr = 0.001
I0522 18:44:03.486137 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_75000.caffemodel
I0522 18:44:03.544122 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_75000.solverstate
I0522 18:44:03.573153 12758 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 18:45:13.024586 12758 solver.cpp:409]     Test net output #0: accuracy = 0.875734
I0522 18:45:13.024772 12758 solver.cpp:409]     Test net output #1: loss = 0.436198 (* 1 = 0.436198 loss)
I0522 18:45:33.912214 12758 solver.cpp:237] Iteration 75000, loss = 1.28184
I0522 18:45:33.912279 12758 solver.cpp:253]     Train net output #0: loss = 1.28184 (* 1 = 1.28184 loss)
I0522 18:45:33.912309 12758 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I0522 18:45:43.591205 12758 solver.cpp:237] Iteration 75375, loss = 0.663832
I0522 18:45:43.591370 12758 solver.cpp:253]     Train net output #0: loss = 0.663832 (* 1 = 0.663832 loss)
I0522 18:45:43.591388 12758 sgd_solver.cpp:106] Iteration 75375, lr = 0.001
I0522 18:45:53.268851 12758 solver.cpp:237] Iteration 75750, loss = 1.43045
I0522 18:45:53.268905 12758 solver.cpp:253]     Train net output #0: loss = 1.43045 (* 1 = 1.43045 loss)
I0522 18:45:53.268931 12758 sgd_solver.cpp:106] Iteration 75750, lr = 0.001
I0522 18:46:02.943430 12758 solver.cpp:237] Iteration 76125, loss = 1.17686
I0522 18:46:02.943469 12758 solver.cpp:253]     Train net output #0: loss = 1.17686 (* 1 = 1.17686 loss)
I0522 18:46:02.943492 12758 sgd_solver.cpp:106] Iteration 76125, lr = 0.001
I0522 18:46:12.665943 12758 solver.cpp:237] Iteration 76500, loss = 1.26975
I0522 18:46:12.665998 12758 solver.cpp:253]     Train net output #0: loss = 1.26975 (* 1 = 1.26975 loss)
I0522 18:46:12.666016 12758 sgd_solver.cpp:106] Iteration 76500, lr = 0.001
I0522 18:46:22.451652 12758 solver.cpp:237] Iteration 76875, loss = 1.24117
I0522 18:46:22.451812 12758 solver.cpp:253]     Train net output #0: loss = 1.24117 (* 1 = 1.24117 loss)
I0522 18:46:22.451829 12758 sgd_solver.cpp:106] Iteration 76875, lr = 0.001
I0522 18:46:32.235326 12758 solver.cpp:237] Iteration 77250, loss = 1.31075
I0522 18:46:32.235363 12758 solver.cpp:253]     Train net output #0: loss = 1.31075 (* 1 = 1.31075 loss)
I0522 18:46:32.235386 12758 sgd_solver.cpp:106] Iteration 77250, lr = 0.001
I0522 18:47:02.939919 12758 solver.cpp:237] Iteration 77625, loss = 1.1314
I0522 18:47:02.940110 12758 solver.cpp:253]     Train net output #0: loss = 1.1314 (* 1 = 1.1314 loss)
I0522 18:47:02.940129 12758 sgd_solver.cpp:106] Iteration 77625, lr = 0.001
I0522 18:47:12.777376 12758 solver.cpp:237] Iteration 78000, loss = 1.11914
I0522 18:47:12.777413 12758 solver.cpp:253]     Train net output #0: loss = 1.11914 (* 1 = 1.11914 loss)
I0522 18:47:12.777437 12758 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I0522 18:47:22.616559 12758 solver.cpp:237] Iteration 78375, loss = 1.74932
I0522 18:47:22.616596 12758 solver.cpp:253]     Train net output #0: loss = 1.74932 (* 1 = 1.74932 loss)
I0522 18:47:22.616619 12758 sgd_solver.cpp:106] Iteration 78375, lr = 0.001
I0522 18:47:32.389264 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_78750.caffemodel
I0522 18:47:32.444828 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_78750.solverstate
I0522 18:47:32.479601 12758 solver.cpp:237] Iteration 78750, loss = 1.08216
I0522 18:47:32.479657 12758 solver.cpp:253]     Train net output #0: loss = 1.08216 (* 1 = 1.08216 loss)
I0522 18:47:32.479684 12758 sgd_solver.cpp:106] Iteration 78750, lr = 0.001
I0522 18:47:42.269871 12758 solver.cpp:237] Iteration 79125, loss = 1.21317
I0522 18:47:42.270056 12758 solver.cpp:253]     Train net output #0: loss = 1.21317 (* 1 = 1.21317 loss)
I0522 18:47:42.270072 12758 sgd_solver.cpp:106] Iteration 79125, lr = 0.001
I0522 18:47:52.082599 12758 solver.cpp:237] Iteration 79500, loss = 1.15065
I0522 18:47:52.082659 12758 solver.cpp:253]     Train net output #0: loss = 1.15065 (* 1 = 1.15065 loss)
I0522 18:47:52.082685 12758 sgd_solver.cpp:106] Iteration 79500, lr = 0.001
I0522 18:48:01.908252 12758 solver.cpp:237] Iteration 79875, loss = 1.32715
I0522 18:48:01.908289 12758 solver.cpp:253]     Train net output #0: loss = 1.32715 (* 1 = 1.32715 loss)
I0522 18:48:01.908313 12758 sgd_solver.cpp:106] Iteration 79875, lr = 0.001
I0522 18:48:32.621564 12758 solver.cpp:237] Iteration 80250, loss = 1.13933
I0522 18:48:32.621750 12758 solver.cpp:253]     Train net output #0: loss = 1.13933 (* 1 = 1.13933 loss)
I0522 18:48:32.621768 12758 sgd_solver.cpp:106] Iteration 80250, lr = 0.001
I0522 18:48:42.450878 12758 solver.cpp:237] Iteration 80625, loss = 0.986867
I0522 18:48:42.450938 12758 solver.cpp:253]     Train net output #0: loss = 0.986867 (* 1 = 0.986867 loss)
I0522 18:48:42.450964 12758 sgd_solver.cpp:106] Iteration 80625, lr = 0.001
I0522 18:48:52.279331 12758 solver.cpp:237] Iteration 81000, loss = 1.3077
I0522 18:48:52.279368 12758 solver.cpp:253]     Train net output #0: loss = 1.3077 (* 1 = 1.3077 loss)
I0522 18:48:52.279392 12758 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I0522 18:49:02.104462 12758 solver.cpp:237] Iteration 81375, loss = 1.32784
I0522 18:49:02.104501 12758 solver.cpp:253]     Train net output #0: loss = 1.32784 (* 1 = 1.32784 loss)
I0522 18:49:02.104519 12758 sgd_solver.cpp:106] Iteration 81375, lr = 0.001
I0522 18:49:11.804057 12758 solver.cpp:237] Iteration 81750, loss = 1.14884
I0522 18:49:11.804239 12758 solver.cpp:253]     Train net output #0: loss = 1.14884 (* 1 = 1.14884 loss)
I0522 18:49:11.804255 12758 sgd_solver.cpp:106] Iteration 81750, lr = 0.001
I0522 18:49:21.480185 12758 solver.cpp:237] Iteration 82125, loss = 1.05829
I0522 18:49:21.480222 12758 solver.cpp:253]     Train net output #0: loss = 1.05829 (* 1 = 1.05829 loss)
I0522 18:49:21.480245 12758 sgd_solver.cpp:106] Iteration 82125, lr = 0.001
I0522 18:49:31.195209 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_82500.caffemodel
I0522 18:49:31.255946 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_82500.solverstate
I0522 18:49:31.282677 12758 solver.cpp:341] Iteration 82500, Testing net (#0)
I0522 18:50:19.609732 12758 solver.cpp:409]     Test net output #0: accuracy = 0.877639
I0522 18:50:19.609915 12758 solver.cpp:409]     Test net output #1: loss = 0.383711 (* 1 = 0.383711 loss)
I0522 18:50:40.543862 12758 solver.cpp:237] Iteration 82500, loss = 0.948462
I0522 18:50:40.543928 12758 solver.cpp:253]     Train net output #0: loss = 0.948461 (* 1 = 0.948461 loss)
I0522 18:50:40.543953 12758 sgd_solver.cpp:106] Iteration 82500, lr = 0.001
I0522 18:50:50.293191 12758 solver.cpp:237] Iteration 82875, loss = 1.25517
I0522 18:50:50.293376 12758 solver.cpp:253]     Train net output #0: loss = 1.25517 (* 1 = 1.25517 loss)
I0522 18:50:50.293395 12758 sgd_solver.cpp:106] Iteration 82875, lr = 0.001
I0522 18:50:59.975189 12758 solver.cpp:237] Iteration 83250, loss = 0.780651
I0522 18:50:59.975226 12758 solver.cpp:253]     Train net output #0: loss = 0.78065 (* 1 = 0.78065 loss)
I0522 18:50:59.975245 12758 sgd_solver.cpp:106] Iteration 83250, lr = 0.001
I0522 18:51:09.656843 12758 solver.cpp:237] Iteration 83625, loss = 1.26218
I0522 18:51:09.656905 12758 solver.cpp:253]     Train net output #0: loss = 1.26218 (* 1 = 1.26218 loss)
I0522 18:51:09.656932 12758 sgd_solver.cpp:106] Iteration 83625, lr = 0.001
I0522 18:51:19.373139 12758 solver.cpp:237] Iteration 84000, loss = 0.937714
I0522 18:51:19.373177 12758 solver.cpp:253]     Train net output #0: loss = 0.937714 (* 1 = 0.937714 loss)
I0522 18:51:19.373201 12758 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I0522 18:51:29.091326 12758 solver.cpp:237] Iteration 84375, loss = 1.26591
I0522 18:51:29.091498 12758 solver.cpp:253]     Train net output #0: loss = 1.26591 (* 1 = 1.26591 loss)
I0522 18:51:29.091516 12758 sgd_solver.cpp:106] Iteration 84375, lr = 0.001
I0522 18:51:38.783797 12758 solver.cpp:237] Iteration 84750, loss = 1.04956
I0522 18:51:38.783855 12758 solver.cpp:253]     Train net output #0: loss = 1.04956 (* 1 = 1.04956 loss)
I0522 18:51:38.783881 12758 sgd_solver.cpp:106] Iteration 84750, lr = 0.001
I0522 18:52:09.353112 12758 solver.cpp:237] Iteration 85125, loss = 1.30301
I0522 18:52:09.353302 12758 solver.cpp:253]     Train net output #0: loss = 1.30301 (* 1 = 1.30301 loss)
I0522 18:52:09.353319 12758 sgd_solver.cpp:106] Iteration 85125, lr = 0.001
I0522 18:52:19.018743 12758 solver.cpp:237] Iteration 85500, loss = 1.30107
I0522 18:52:19.018779 12758 solver.cpp:253]     Train net output #0: loss = 1.30107 (* 1 = 1.30107 loss)
I0522 18:52:19.018801 12758 sgd_solver.cpp:106] Iteration 85500, lr = 0.001
I0522 18:52:28.716809 12758 solver.cpp:237] Iteration 85875, loss = 1.58933
I0522 18:52:28.716864 12758 solver.cpp:253]     Train net output #0: loss = 1.58933 (* 1 = 1.58933 loss)
I0522 18:52:28.716881 12758 sgd_solver.cpp:106] Iteration 85875, lr = 0.001
I0522 18:52:38.404909 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_86250.caffemodel
I0522 18:52:38.460371 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_86250.solverstate
I0522 18:52:38.495146 12758 solver.cpp:237] Iteration 86250, loss = 1.28998
I0522 18:52:38.495203 12758 solver.cpp:253]     Train net output #0: loss = 1.28998 (* 1 = 1.28998 loss)
I0522 18:52:38.495221 12758 sgd_solver.cpp:106] Iteration 86250, lr = 0.001
I0522 18:52:48.213583 12758 solver.cpp:237] Iteration 86625, loss = 0.96956
I0522 18:52:48.213807 12758 solver.cpp:253]     Train net output #0: loss = 0.96956 (* 1 = 0.96956 loss)
I0522 18:52:48.213825 12758 sgd_solver.cpp:106] Iteration 86625, lr = 0.001
I0522 18:52:58.029569 12758 solver.cpp:237] Iteration 87000, loss = 1.21892
I0522 18:52:58.029624 12758 solver.cpp:253]     Train net output #0: loss = 1.21892 (* 1 = 1.21892 loss)
I0522 18:52:58.029649 12758 sgd_solver.cpp:106] Iteration 87000, lr = 0.001
I0522 18:53:07.854526 12758 solver.cpp:237] Iteration 87375, loss = 1.29727
I0522 18:53:07.854564 12758 solver.cpp:253]     Train net output #0: loss = 1.29727 (* 1 = 1.29727 loss)
I0522 18:53:07.854583 12758 sgd_solver.cpp:106] Iteration 87375, lr = 0.001
I0522 18:53:38.565088 12758 solver.cpp:237] Iteration 87750, loss = 0.977649
I0522 18:53:38.565275 12758 solver.cpp:253]     Train net output #0: loss = 0.977649 (* 1 = 0.977649 loss)
I0522 18:53:38.565294 12758 sgd_solver.cpp:106] Iteration 87750, lr = 0.001
I0522 18:53:48.481570 12758 solver.cpp:237] Iteration 88125, loss = 1.19735
I0522 18:53:48.481621 12758 solver.cpp:253]     Train net output #0: loss = 1.19735 (* 1 = 1.19735 loss)
I0522 18:53:48.481639 12758 sgd_solver.cpp:106] Iteration 88125, lr = 0.001
I0522 18:53:58.394171 12758 solver.cpp:237] Iteration 88500, loss = 0.958539
I0522 18:53:58.394208 12758 solver.cpp:253]     Train net output #0: loss = 0.958539 (* 1 = 0.958539 loss)
I0522 18:53:58.394232 12758 sgd_solver.cpp:106] Iteration 88500, lr = 0.001
I0522 18:54:08.221966 12758 solver.cpp:237] Iteration 88875, loss = 0.966151
I0522 18:54:08.222023 12758 solver.cpp:253]     Train net output #0: loss = 0.96615 (* 1 = 0.96615 loss)
I0522 18:54:08.222040 12758 sgd_solver.cpp:106] Iteration 88875, lr = 0.001
I0522 18:54:17.941974 12758 solver.cpp:237] Iteration 89250, loss = 1.22385
I0522 18:54:17.942149 12758 solver.cpp:253]     Train net output #0: loss = 1.22385 (* 1 = 1.22385 loss)
I0522 18:54:17.942167 12758 sgd_solver.cpp:106] Iteration 89250, lr = 0.001
I0522 18:54:27.655491 12758 solver.cpp:237] Iteration 89625, loss = 1.0272
I0522 18:54:27.655529 12758 solver.cpp:253]     Train net output #0: loss = 1.0272 (* 1 = 1.0272 loss)
I0522 18:54:27.655552 12758 sgd_solver.cpp:106] Iteration 89625, lr = 0.001
I0522 18:54:37.424439 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_90000.caffemodel
I0522 18:54:37.480604 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_90000.solverstate
I0522 18:54:37.506896 12758 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 18:55:46.970692 12758 solver.cpp:409]     Test net output #0: accuracy = 0.87988
I0522 18:55:46.970878 12758 solver.cpp:409]     Test net output #1: loss = 0.408272 (* 1 = 0.408272 loss)
I0522 18:56:07.851121 12758 solver.cpp:237] Iteration 90000, loss = 1.00695
I0522 18:56:07.851189 12758 solver.cpp:253]     Train net output #0: loss = 1.00695 (* 1 = 1.00695 loss)
I0522 18:56:07.851208 12758 sgd_solver.cpp:106] Iteration 90000, lr = 0.001
I0522 18:56:17.767233 12758 solver.cpp:237] Iteration 90375, loss = 1.07093
I0522 18:56:17.767419 12758 solver.cpp:253]     Train net output #0: loss = 1.07093 (* 1 = 1.07093 loss)
I0522 18:56:17.767439 12758 sgd_solver.cpp:106] Iteration 90375, lr = 0.001
I0522 18:56:27.695045 12758 solver.cpp:237] Iteration 90750, loss = 1.62736
I0522 18:56:27.695083 12758 solver.cpp:253]     Train net output #0: loss = 1.62736 (* 1 = 1.62736 loss)
I0522 18:56:27.695106 12758 sgd_solver.cpp:106] Iteration 90750, lr = 0.001
I0522 18:56:37.621079 12758 solver.cpp:237] Iteration 91125, loss = 1.17443
I0522 18:56:37.621134 12758 solver.cpp:253]     Train net output #0: loss = 1.17443 (* 1 = 1.17443 loss)
I0522 18:56:37.621151 12758 sgd_solver.cpp:106] Iteration 91125, lr = 0.001
I0522 18:56:47.544236 12758 solver.cpp:237] Iteration 91500, loss = 0.985462
I0522 18:56:47.544275 12758 solver.cpp:253]     Train net output #0: loss = 0.985461 (* 1 = 0.985461 loss)
I0522 18:56:47.544293 12758 sgd_solver.cpp:106] Iteration 91500, lr = 0.001
I0522 18:56:57.459453 12758 solver.cpp:237] Iteration 91875, loss = 1.01794
I0522 18:56:57.459619 12758 solver.cpp:253]     Train net output #0: loss = 1.01794 (* 1 = 1.01794 loss)
I0522 18:56:57.459635 12758 sgd_solver.cpp:106] Iteration 91875, lr = 0.001
I0522 18:57:07.267828 12758 solver.cpp:237] Iteration 92250, loss = 1.09
I0522 18:57:07.267884 12758 solver.cpp:253]     Train net output #0: loss = 1.09 (* 1 = 1.09 loss)
I0522 18:57:07.267910 12758 sgd_solver.cpp:106] Iteration 92250, lr = 0.001
I0522 18:57:37.920176 12758 solver.cpp:237] Iteration 92625, loss = 1.382
I0522 18:57:37.920361 12758 solver.cpp:253]     Train net output #0: loss = 1.382 (* 1 = 1.382 loss)
I0522 18:57:37.920377 12758 sgd_solver.cpp:106] Iteration 92625, lr = 0.001
I0522 18:57:47.720197 12758 solver.cpp:237] Iteration 93000, loss = 1.15052
I0522 18:57:47.720234 12758 solver.cpp:253]     Train net output #0: loss = 1.15052 (* 1 = 1.15052 loss)
I0522 18:57:47.720259 12758 sgd_solver.cpp:106] Iteration 93000, lr = 0.001
I0522 18:57:57.381944 12758 solver.cpp:237] Iteration 93375, loss = 0.897749
I0522 18:57:57.382000 12758 solver.cpp:253]     Train net output #0: loss = 0.897749 (* 1 = 0.897749 loss)
I0522 18:57:57.382025 12758 sgd_solver.cpp:106] Iteration 93375, lr = 0.001
I0522 18:58:07.005193 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_93750.caffemodel
I0522 18:58:07.063848 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_93750.solverstate
I0522 18:58:07.101375 12758 solver.cpp:237] Iteration 93750, loss = 1.48519
I0522 18:58:07.101433 12758 solver.cpp:253]     Train net output #0: loss = 1.48519 (* 1 = 1.48519 loss)
I0522 18:58:07.101460 12758 sgd_solver.cpp:106] Iteration 93750, lr = 0.001
I0522 18:58:16.746882 12758 solver.cpp:237] Iteration 94125, loss = 1.11556
I0522 18:58:16.747079 12758 solver.cpp:253]     Train net output #0: loss = 1.11556 (* 1 = 1.11556 loss)
I0522 18:58:16.747105 12758 sgd_solver.cpp:106] Iteration 94125, lr = 0.001
I0522 18:58:26.399770 12758 solver.cpp:237] Iteration 94500, loss = 1.45349
I0522 18:58:26.399808 12758 solver.cpp:253]     Train net output #0: loss = 1.45349 (* 1 = 1.45349 loss)
I0522 18:58:26.399832 12758 sgd_solver.cpp:106] Iteration 94500, lr = 0.001
I0522 18:58:36.050112 12758 solver.cpp:237] Iteration 94875, loss = 1.54593
I0522 18:58:36.050148 12758 solver.cpp:253]     Train net output #0: loss = 1.54593 (* 1 = 1.54593 loss)
I0522 18:58:36.050171 12758 sgd_solver.cpp:106] Iteration 94875, lr = 0.001
I0522 18:59:06.745115 12758 solver.cpp:237] Iteration 95250, loss = 1.42495
I0522 18:59:06.745306 12758 solver.cpp:253]     Train net output #0: loss = 1.42495 (* 1 = 1.42495 loss)
I0522 18:59:06.745323 12758 sgd_solver.cpp:106] Iteration 95250, lr = 0.001
I0522 18:59:16.645381 12758 solver.cpp:237] Iteration 95625, loss = 1.16449
I0522 18:59:16.645421 12758 solver.cpp:253]     Train net output #0: loss = 1.16449 (* 1 = 1.16449 loss)
I0522 18:59:16.645439 12758 sgd_solver.cpp:106] Iteration 95625, lr = 0.001
I0522 18:59:26.554824 12758 solver.cpp:237] Iteration 96000, loss = 0.987378
I0522 18:59:26.554863 12758 solver.cpp:253]     Train net output #0: loss = 0.987377 (* 1 = 0.987377 loss)
I0522 18:59:26.554883 12758 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0522 18:59:36.458624 12758 solver.cpp:237] Iteration 96375, loss = 1.29238
I0522 18:59:36.458683 12758 solver.cpp:253]     Train net output #0: loss = 1.29238 (* 1 = 1.29238 loss)
I0522 18:59:36.458708 12758 sgd_solver.cpp:106] Iteration 96375, lr = 0.001
I0522 18:59:46.366542 12758 solver.cpp:237] Iteration 96750, loss = 1.55998
I0522 18:59:46.366709 12758 solver.cpp:253]     Train net output #0: loss = 1.55998 (* 1 = 1.55998 loss)
I0522 18:59:46.366726 12758 sgd_solver.cpp:106] Iteration 96750, lr = 0.001
I0522 18:59:56.271430 12758 solver.cpp:237] Iteration 97125, loss = 0.999433
I0522 18:59:56.271487 12758 solver.cpp:253]     Train net output #0: loss = 0.999432 (* 1 = 0.999432 loss)
I0522 18:59:56.271504 12758 sgd_solver.cpp:106] Iteration 97125, lr = 0.001
I0522 19:00:06.153564 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_97500.caffemodel
I0522 19:00:06.210394 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_97500.solverstate
I0522 19:00:06.236860 12758 solver.cpp:341] Iteration 97500, Testing net (#0)
I0522 19:00:54.759112 12758 solver.cpp:409]     Test net output #0: accuracy = 0.882952
I0522 19:00:54.759299 12758 solver.cpp:409]     Test net output #1: loss = 0.38944 (* 1 = 0.38944 loss)
I0522 19:01:15.613849 12758 solver.cpp:237] Iteration 97500, loss = 1.0364
I0522 19:01:15.613914 12758 solver.cpp:253]     Train net output #0: loss = 1.0364 (* 1 = 1.0364 loss)
I0522 19:01:15.613943 12758 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I0522 19:01:25.376257 12758 solver.cpp:237] Iteration 97875, loss = 0.976215
I0522 19:01:25.376441 12758 solver.cpp:253]     Train net output #0: loss = 0.976215 (* 1 = 0.976215 loss)
I0522 19:01:25.376457 12758 sgd_solver.cpp:106] Iteration 97875, lr = 0.001
I0522 19:01:35.133044 12758 solver.cpp:237] Iteration 98250, loss = 1.36977
I0522 19:01:35.133101 12758 solver.cpp:253]     Train net output #0: loss = 1.36977 (* 1 = 1.36977 loss)
I0522 19:01:35.133131 12758 sgd_solver.cpp:106] Iteration 98250, lr = 0.001
I0522 19:01:44.846434 12758 solver.cpp:237] Iteration 98625, loss = 1.44193
I0522 19:01:44.846472 12758 solver.cpp:253]     Train net output #0: loss = 1.44193 (* 1 = 1.44193 loss)
I0522 19:01:44.846492 12758 sgd_solver.cpp:106] Iteration 98625, lr = 0.001
I0522 19:01:54.552312 12758 solver.cpp:237] Iteration 99000, loss = 1.40295
I0522 19:01:54.552350 12758 solver.cpp:253]     Train net output #0: loss = 1.40295 (* 1 = 1.40295 loss)
I0522 19:01:54.552368 12758 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0522 19:02:04.387531 12758 solver.cpp:237] Iteration 99375, loss = 1.09308
I0522 19:02:04.387720 12758 solver.cpp:253]     Train net output #0: loss = 1.09308 (* 1 = 1.09308 loss)
I0522 19:02:04.387738 12758 sgd_solver.cpp:106] Iteration 99375, lr = 0.001
I0522 19:02:14.311769 12758 solver.cpp:237] Iteration 99750, loss = 1.16807
I0522 19:02:14.311805 12758 solver.cpp:253]     Train net output #0: loss = 1.16807 (* 1 = 1.16807 loss)
I0522 19:02:14.311828 12758 sgd_solver.cpp:106] Iteration 99750, lr = 0.001
I0522 19:02:45.108819 12758 solver.cpp:237] Iteration 100125, loss = 0.988483
I0522 19:02:45.109010 12758 solver.cpp:253]     Train net output #0: loss = 0.988482 (* 1 = 0.988482 loss)
I0522 19:02:45.109028 12758 sgd_solver.cpp:106] Iteration 100125, lr = 0.001
I0522 19:02:54.978286 12758 solver.cpp:237] Iteration 100500, loss = 1.12561
I0522 19:02:54.978343 12758 solver.cpp:253]     Train net output #0: loss = 1.12561 (* 1 = 1.12561 loss)
I0522 19:02:54.978359 12758 sgd_solver.cpp:106] Iteration 100500, lr = 0.001
I0522 19:03:04.806547 12758 solver.cpp:237] Iteration 100875, loss = 1.00891
I0522 19:03:04.806586 12758 solver.cpp:253]     Train net output #0: loss = 1.00891 (* 1 = 1.00891 loss)
I0522 19:03:04.806604 12758 sgd_solver.cpp:106] Iteration 100875, lr = 0.001
I0522 19:03:14.616040 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_101250.caffemodel
I0522 19:03:14.673171 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_101250.solverstate
I0522 19:03:14.706912 12758 solver.cpp:237] Iteration 101250, loss = 1.08957
I0522 19:03:14.706969 12758 solver.cpp:253]     Train net output #0: loss = 1.08957 (* 1 = 1.08957 loss)
I0522 19:03:14.706995 12758 sgd_solver.cpp:106] Iteration 101250, lr = 0.001
I0522 19:03:24.533759 12758 solver.cpp:237] Iteration 101625, loss = 1.0574
I0522 19:03:24.533931 12758 solver.cpp:253]     Train net output #0: loss = 1.0574 (* 1 = 1.0574 loss)
I0522 19:03:24.533948 12758 sgd_solver.cpp:106] Iteration 101625, lr = 0.001
I0522 19:03:34.368100 12758 solver.cpp:237] Iteration 102000, loss = 1.29495
I0522 19:03:34.368136 12758 solver.cpp:253]     Train net output #0: loss = 1.29495 (* 1 = 1.29495 loss)
I0522 19:03:34.368160 12758 sgd_solver.cpp:106] Iteration 102000, lr = 0.001
I0522 19:03:44.131994 12758 solver.cpp:237] Iteration 102375, loss = 1.34544
I0522 19:03:44.132053 12758 solver.cpp:253]     Train net output #0: loss = 1.34544 (* 1 = 1.34544 loss)
I0522 19:03:44.132079 12758 sgd_solver.cpp:106] Iteration 102375, lr = 0.001
I0522 19:04:14.707108 12758 solver.cpp:237] Iteration 102750, loss = 1.20907
I0522 19:04:14.707309 12758 solver.cpp:253]     Train net output #0: loss = 1.20907 (* 1 = 1.20907 loss)
I0522 19:04:14.707325 12758 sgd_solver.cpp:106] Iteration 102750, lr = 0.001
I0522 19:04:24.419324 12758 solver.cpp:237] Iteration 103125, loss = 1.16778
I0522 19:04:24.419363 12758 solver.cpp:253]     Train net output #0: loss = 1.16778 (* 1 = 1.16778 loss)
I0522 19:04:24.419386 12758 sgd_solver.cpp:106] Iteration 103125, lr = 0.001
I0522 19:04:34.214707 12758 solver.cpp:237] Iteration 103500, loss = 1.06318
I0522 19:04:34.214766 12758 solver.cpp:253]     Train net output #0: loss = 1.06318 (* 1 = 1.06318 loss)
I0522 19:04:34.214792 12758 sgd_solver.cpp:106] Iteration 103500, lr = 0.001
I0522 19:04:44.074991 12758 solver.cpp:237] Iteration 103875, loss = 1.22478
I0522 19:04:44.075029 12758 solver.cpp:253]     Train net output #0: loss = 1.22478 (* 1 = 1.22478 loss)
I0522 19:04:44.075053 12758 sgd_solver.cpp:106] Iteration 103875, lr = 0.001
I0522 19:04:53.938794 12758 solver.cpp:237] Iteration 104250, loss = 1.31936
I0522 19:04:53.938983 12758 solver.cpp:253]     Train net output #0: loss = 1.31936 (* 1 = 1.31936 loss)
I0522 19:04:53.939002 12758 sgd_solver.cpp:106] Iteration 104250, lr = 0.001
I0522 19:05:03.803877 12758 solver.cpp:237] Iteration 104625, loss = 0.979699
I0522 19:05:03.803916 12758 solver.cpp:253]     Train net output #0: loss = 0.979699 (* 1 = 0.979699 loss)
I0522 19:05:03.803941 12758 sgd_solver.cpp:106] Iteration 104625, lr = 0.001
I0522 19:05:13.639395 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_105000.caffemodel
I0522 19:05:13.696584 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_105000.solverstate
I0522 19:05:13.722306 12758 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 19:06:23.198268 12758 solver.cpp:409]     Test net output #0: accuracy = 0.880327
I0522 19:06:23.198458 12758 solver.cpp:409]     Test net output #1: loss = 0.385466 (* 1 = 0.385466 loss)
I0522 19:06:44.089879 12758 solver.cpp:237] Iteration 105000, loss = 1.18112
I0522 19:06:44.089941 12758 solver.cpp:253]     Train net output #0: loss = 1.18112 (* 1 = 1.18112 loss)
I0522 19:06:44.089967 12758 sgd_solver.cpp:106] Iteration 105000, lr = 0.001
I0522 19:06:53.810606 12758 solver.cpp:237] Iteration 105375, loss = 1.25006
I0522 19:06:53.810780 12758 solver.cpp:253]     Train net output #0: loss = 1.25006 (* 1 = 1.25006 loss)
I0522 19:06:53.810796 12758 sgd_solver.cpp:106] Iteration 105375, lr = 0.001
I0522 19:07:03.536592 12758 solver.cpp:237] Iteration 105750, loss = 1.2717
I0522 19:07:03.536653 12758 solver.cpp:253]     Train net output #0: loss = 1.2717 (* 1 = 1.2717 loss)
I0522 19:07:03.536679 12758 sgd_solver.cpp:106] Iteration 105750, lr = 0.001
I0522 19:07:13.247444 12758 solver.cpp:237] Iteration 106125, loss = 0.927799
I0522 19:07:13.247483 12758 solver.cpp:253]     Train net output #0: loss = 0.927799 (* 1 = 0.927799 loss)
I0522 19:07:13.247503 12758 sgd_solver.cpp:106] Iteration 106125, lr = 0.001
I0522 19:07:22.961835 12758 solver.cpp:237] Iteration 106500, loss = 1.16478
I0522 19:07:22.961874 12758 solver.cpp:253]     Train net output #0: loss = 1.16478 (* 1 = 1.16478 loss)
I0522 19:07:22.961892 12758 sgd_solver.cpp:106] Iteration 106500, lr = 0.001
I0522 19:07:32.677310 12758 solver.cpp:237] Iteration 106875, loss = 1.04712
I0522 19:07:32.677497 12758 solver.cpp:253]     Train net output #0: loss = 1.04712 (* 1 = 1.04712 loss)
I0522 19:07:32.677515 12758 sgd_solver.cpp:106] Iteration 106875, lr = 0.001
I0522 19:07:42.397653 12758 solver.cpp:237] Iteration 107250, loss = 1.18839
I0522 19:07:42.397691 12758 solver.cpp:253]     Train net output #0: loss = 1.18839 (* 1 = 1.18839 loss)
I0522 19:07:42.397713 12758 sgd_solver.cpp:106] Iteration 107250, lr = 0.001
I0522 19:08:12.968500 12758 solver.cpp:237] Iteration 107625, loss = 1.02542
I0522 19:08:12.968704 12758 solver.cpp:253]     Train net output #0: loss = 1.02542 (* 1 = 1.02542 loss)
I0522 19:08:12.968721 12758 sgd_solver.cpp:106] Iteration 107625, lr = 0.001
I0522 19:08:22.677337 12758 solver.cpp:237] Iteration 108000, loss = 1.77637
I0522 19:08:22.677381 12758 solver.cpp:253]     Train net output #0: loss = 1.77637 (* 1 = 1.77637 loss)
I0522 19:08:22.677398 12758 sgd_solver.cpp:106] Iteration 108000, lr = 0.001
I0522 19:08:32.379643 12758 solver.cpp:237] Iteration 108375, loss = 1.29362
I0522 19:08:32.379679 12758 solver.cpp:253]     Train net output #0: loss = 1.29362 (* 1 = 1.29362 loss)
I0522 19:08:32.379703 12758 sgd_solver.cpp:106] Iteration 108375, lr = 0.001
I0522 19:08:42.112290 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_108750.caffemodel
I0522 19:08:42.180083 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_108750.solverstate
I0522 19:08:42.242813 12758 solver.cpp:237] Iteration 108750, loss = 1.65683
I0522 19:08:42.242877 12758 solver.cpp:253]     Train net output #0: loss = 1.65683 (* 1 = 1.65683 loss)
I0522 19:08:42.242893 12758 sgd_solver.cpp:106] Iteration 108750, lr = 0.001
I0522 19:08:52.081866 12758 solver.cpp:237] Iteration 109125, loss = 0.944696
I0522 19:08:52.082043 12758 solver.cpp:253]     Train net output #0: loss = 0.944696 (* 1 = 0.944696 loss)
I0522 19:08:52.082061 12758 sgd_solver.cpp:106] Iteration 109125, lr = 0.001
I0522 19:09:01.922340 12758 solver.cpp:237] Iteration 109500, loss = 1.16409
I0522 19:09:01.922376 12758 solver.cpp:253]     Train net output #0: loss = 1.16409 (* 1 = 1.16409 loss)
I0522 19:09:01.922400 12758 sgd_solver.cpp:106] Iteration 109500, lr = 0.001
I0522 19:09:11.764942 12758 solver.cpp:237] Iteration 109875, loss = 1.20628
I0522 19:09:11.764998 12758 solver.cpp:253]     Train net output #0: loss = 1.20628 (* 1 = 1.20628 loss)
I0522 19:09:11.765017 12758 sgd_solver.cpp:106] Iteration 109875, lr = 0.001
I0522 19:09:42.465728 12758 solver.cpp:237] Iteration 110250, loss = 0.991215
I0522 19:09:42.465919 12758 solver.cpp:253]     Train net output #0: loss = 0.991214 (* 1 = 0.991214 loss)
I0522 19:09:42.465937 12758 sgd_solver.cpp:106] Iteration 110250, lr = 0.001
I0522 19:09:52.303237 12758 solver.cpp:237] Iteration 110625, loss = 1.5736
I0522 19:09:52.303274 12758 solver.cpp:253]     Train net output #0: loss = 1.5736 (* 1 = 1.5736 loss)
I0522 19:09:52.303297 12758 sgd_solver.cpp:106] Iteration 110625, lr = 0.001
I0522 19:10:02.173527 12758 solver.cpp:237] Iteration 111000, loss = 1.18683
I0522 19:10:02.173583 12758 solver.cpp:253]     Train net output #0: loss = 1.18683 (* 1 = 1.18683 loss)
I0522 19:10:02.173609 12758 sgd_solver.cpp:106] Iteration 111000, lr = 0.001
I0522 19:10:12.046747 12758 solver.cpp:237] Iteration 111375, loss = 1.20918
I0522 19:10:12.046784 12758 solver.cpp:253]     Train net output #0: loss = 1.20918 (* 1 = 1.20918 loss)
I0522 19:10:12.046803 12758 sgd_solver.cpp:106] Iteration 111375, lr = 0.001
I0522 19:10:21.897513 12758 solver.cpp:237] Iteration 111750, loss = 1.16969
I0522 19:10:21.897704 12758 solver.cpp:253]     Train net output #0: loss = 1.16969 (* 1 = 1.16969 loss)
I0522 19:10:21.897722 12758 sgd_solver.cpp:106] Iteration 111750, lr = 0.001
I0522 19:10:31.698457 12758 solver.cpp:237] Iteration 112125, loss = 1.32634
I0522 19:10:31.698493 12758 solver.cpp:253]     Train net output #0: loss = 1.32634 (* 1 = 1.32634 loss)
I0522 19:10:31.698518 12758 sgd_solver.cpp:106] Iteration 112125, lr = 0.001
I0522 19:10:41.475339 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_112500.caffemodel
I0522 19:10:41.534507 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_112500.solverstate
I0522 19:10:41.562551 12758 solver.cpp:341] Iteration 112500, Testing net (#0)
I0522 19:11:29.759253 12758 solver.cpp:409]     Test net output #0: accuracy = 0.887006
I0522 19:11:29.759462 12758 solver.cpp:409]     Test net output #1: loss = 0.379578 (* 1 = 0.379578 loss)
I0522 19:11:50.623970 12758 solver.cpp:237] Iteration 112500, loss = 1.09057
I0522 19:11:50.624034 12758 solver.cpp:253]     Train net output #0: loss = 1.09057 (* 1 = 1.09057 loss)
I0522 19:11:50.624060 12758 sgd_solver.cpp:106] Iteration 112500, lr = 0.001
I0522 19:12:00.402422 12758 solver.cpp:237] Iteration 112875, loss = 0.958445
I0522 19:12:00.402616 12758 solver.cpp:253]     Train net output #0: loss = 0.958445 (* 1 = 0.958445 loss)
I0522 19:12:00.402637 12758 sgd_solver.cpp:106] Iteration 112875, lr = 0.001
I0522 19:12:10.184768 12758 solver.cpp:237] Iteration 113250, loss = 1.13857
I0522 19:12:10.184805 12758 solver.cpp:253]     Train net output #0: loss = 1.13857 (* 1 = 1.13857 loss)
I0522 19:12:10.184829 12758 sgd_solver.cpp:106] Iteration 113250, lr = 0.001
I0522 19:12:19.962569 12758 solver.cpp:237] Iteration 113625, loss = 1.19683
I0522 19:12:19.962606 12758 solver.cpp:253]     Train net output #0: loss = 1.19683 (* 1 = 1.19683 loss)
I0522 19:12:19.962628 12758 sgd_solver.cpp:106] Iteration 113625, lr = 0.001
I0522 19:12:29.740489 12758 solver.cpp:237] Iteration 114000, loss = 1.25673
I0522 19:12:29.740546 12758 solver.cpp:253]     Train net output #0: loss = 1.25673 (* 1 = 1.25673 loss)
I0522 19:12:29.740573 12758 sgd_solver.cpp:106] Iteration 114000, lr = 0.001
I0522 19:12:39.524029 12758 solver.cpp:237] Iteration 114375, loss = 1.08783
I0522 19:12:39.524197 12758 solver.cpp:253]     Train net output #0: loss = 1.08783 (* 1 = 1.08783 loss)
I0522 19:12:39.524214 12758 sgd_solver.cpp:106] Iteration 114375, lr = 0.001
I0522 19:12:49.295212 12758 solver.cpp:237] Iteration 114750, loss = 1.24501
I0522 19:12:49.295267 12758 solver.cpp:253]     Train net output #0: loss = 1.24501 (* 1 = 1.24501 loss)
I0522 19:12:49.295284 12758 sgd_solver.cpp:106] Iteration 114750, lr = 0.001
I0522 19:13:19.895552 12758 solver.cpp:237] Iteration 115125, loss = 1.00407
I0522 19:13:19.895745 12758 solver.cpp:253]     Train net output #0: loss = 1.00407 (* 1 = 1.00407 loss)
I0522 19:13:19.895762 12758 sgd_solver.cpp:106] Iteration 115125, lr = 0.001
I0522 19:13:29.626500 12758 solver.cpp:237] Iteration 115500, loss = 1.26628
I0522 19:13:29.626538 12758 solver.cpp:253]     Train net output #0: loss = 1.26628 (* 1 = 1.26628 loss)
I0522 19:13:29.626560 12758 sgd_solver.cpp:106] Iteration 115500, lr = 0.001
I0522 19:13:39.357167 12758 solver.cpp:237] Iteration 115875, loss = 1.59527
I0522 19:13:39.357223 12758 solver.cpp:253]     Train net output #0: loss = 1.59527 (* 1 = 1.59527 loss)
I0522 19:13:39.357240 12758 sgd_solver.cpp:106] Iteration 115875, lr = 0.001
I0522 19:13:49.063735 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_116250.caffemodel
I0522 19:13:49.120998 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_116250.solverstate
I0522 19:13:49.154652 12758 solver.cpp:237] Iteration 116250, loss = 1.0131
I0522 19:13:49.154713 12758 solver.cpp:253]     Train net output #0: loss = 1.0131 (* 1 = 1.0131 loss)
I0522 19:13:49.154731 12758 sgd_solver.cpp:106] Iteration 116250, lr = 0.001
I0522 19:13:58.881989 12758 solver.cpp:237] Iteration 116625, loss = 1.57678
I0522 19:13:58.882164 12758 solver.cpp:253]     Train net output #0: loss = 1.57678 (* 1 = 1.57678 loss)
I0522 19:13:58.882181 12758 sgd_solver.cpp:106] Iteration 116625, lr = 0.001
I0522 19:14:08.649096 12758 solver.cpp:237] Iteration 117000, loss = 1.258
I0522 19:14:08.649153 12758 solver.cpp:253]     Train net output #0: loss = 1.258 (* 1 = 1.258 loss)
I0522 19:14:08.649173 12758 sgd_solver.cpp:106] Iteration 117000, lr = 0.001
I0522 19:14:18.431541 12758 solver.cpp:237] Iteration 117375, loss = 0.943568
I0522 19:14:18.431579 12758 solver.cpp:253]     Train net output #0: loss = 0.943568 (* 1 = 0.943568 loss)
I0522 19:14:18.431599 12758 sgd_solver.cpp:106] Iteration 117375, lr = 0.001
I0522 19:14:49.087592 12758 solver.cpp:237] Iteration 117750, loss = 1.19939
I0522 19:14:49.087796 12758 solver.cpp:253]     Train net output #0: loss = 1.19939 (* 1 = 1.19939 loss)
I0522 19:14:49.087813 12758 sgd_solver.cpp:106] Iteration 117750, lr = 0.001
I0522 19:14:58.856250 12758 solver.cpp:237] Iteration 118125, loss = 1.22863
I0522 19:14:58.856308 12758 solver.cpp:253]     Train net output #0: loss = 1.22863 (* 1 = 1.22863 loss)
I0522 19:14:58.856334 12758 sgd_solver.cpp:106] Iteration 118125, lr = 0.001
I0522 19:15:08.605394 12758 solver.cpp:237] Iteration 118500, loss = 1.41328
I0522 19:15:08.605432 12758 solver.cpp:253]     Train net output #0: loss = 1.41328 (* 1 = 1.41328 loss)
I0522 19:15:08.605450 12758 sgd_solver.cpp:106] Iteration 118500, lr = 0.001
I0522 19:15:18.346151 12758 solver.cpp:237] Iteration 118875, loss = 1.03842
I0522 19:15:18.346189 12758 solver.cpp:253]     Train net output #0: loss = 1.03842 (* 1 = 1.03842 loss)
I0522 19:15:18.346212 12758 sgd_solver.cpp:106] Iteration 118875, lr = 0.001
I0522 19:15:28.129842 12758 solver.cpp:237] Iteration 119250, loss = 0.791045
I0522 19:15:28.130036 12758 solver.cpp:253]     Train net output #0: loss = 0.791045 (* 1 = 0.791045 loss)
I0522 19:15:28.130053 12758 sgd_solver.cpp:106] Iteration 119250, lr = 0.001
I0522 19:15:37.918390 12758 solver.cpp:237] Iteration 119625, loss = 1.05229
I0522 19:15:37.918427 12758 solver.cpp:253]     Train net output #0: loss = 1.05229 (* 1 = 1.05229 loss)
I0522 19:15:37.918452 12758 sgd_solver.cpp:106] Iteration 119625, lr = 0.001
I0522 19:15:47.685246 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_120000.caffemodel
I0522 19:15:47.741936 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_120000.solverstate
I0522 19:15:47.767974 12758 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 19:16:57.212720 12758 solver.cpp:409]     Test net output #0: accuracy = 0.884107
I0522 19:16:57.212925 12758 solver.cpp:409]     Test net output #1: loss = 0.356577 (* 1 = 0.356577 loss)
I0522 19:17:18.066406 12758 solver.cpp:237] Iteration 120000, loss = 1.12291
I0522 19:17:18.066468 12758 solver.cpp:253]     Train net output #0: loss = 1.12291 (* 1 = 1.12291 loss)
I0522 19:17:18.066489 12758 sgd_solver.cpp:106] Iteration 120000, lr = 0.001
I0522 19:17:27.907681 12758 solver.cpp:237] Iteration 120375, loss = 0.958581
I0522 19:17:27.907876 12758 solver.cpp:253]     Train net output #0: loss = 0.95858 (* 1 = 0.95858 loss)
I0522 19:17:27.907896 12758 sgd_solver.cpp:106] Iteration 120375, lr = 0.001
I0522 19:17:37.755569 12758 solver.cpp:237] Iteration 120750, loss = 1.29837
I0522 19:17:37.755607 12758 solver.cpp:253]     Train net output #0: loss = 1.29836 (* 1 = 1.29836 loss)
I0522 19:17:37.755630 12758 sgd_solver.cpp:106] Iteration 120750, lr = 0.001
I0522 19:17:47.599375 12758 solver.cpp:237] Iteration 121125, loss = 1.2114
I0522 19:17:47.599412 12758 solver.cpp:253]     Train net output #0: loss = 1.2114 (* 1 = 1.2114 loss)
I0522 19:17:47.599431 12758 sgd_solver.cpp:106] Iteration 121125, lr = 0.001
I0522 19:17:57.441896 12758 solver.cpp:237] Iteration 121500, loss = 0.955751
I0522 19:17:57.441952 12758 solver.cpp:253]     Train net output #0: loss = 0.955751 (* 1 = 0.955751 loss)
I0522 19:17:57.441969 12758 sgd_solver.cpp:106] Iteration 121500, lr = 0.001
I0522 19:18:07.288393 12758 solver.cpp:237] Iteration 121875, loss = 1.44384
I0522 19:18:07.288566 12758 solver.cpp:253]     Train net output #0: loss = 1.44384 (* 1 = 1.44384 loss)
I0522 19:18:07.288583 12758 sgd_solver.cpp:106] Iteration 121875, lr = 0.001
I0522 19:18:17.097298 12758 solver.cpp:237] Iteration 122250, loss = 1.20713
I0522 19:18:17.097353 12758 solver.cpp:253]     Train net output #0: loss = 1.20713 (* 1 = 1.20713 loss)
I0522 19:18:17.097370 12758 sgd_solver.cpp:106] Iteration 122250, lr = 0.001
I0522 19:18:47.696131 12758 solver.cpp:237] Iteration 122625, loss = 1.13764
I0522 19:18:47.696334 12758 solver.cpp:253]     Train net output #0: loss = 1.13764 (* 1 = 1.13764 loss)
I0522 19:18:47.696352 12758 sgd_solver.cpp:106] Iteration 122625, lr = 0.001
I0522 19:18:57.435134 12758 solver.cpp:237] Iteration 123000, loss = 1.16415
I0522 19:18:57.435171 12758 solver.cpp:253]     Train net output #0: loss = 1.16415 (* 1 = 1.16415 loss)
I0522 19:18:57.435194 12758 sgd_solver.cpp:106] Iteration 123000, lr = 0.001
I0522 19:19:07.197294 12758 solver.cpp:237] Iteration 123375, loss = 1.41855
I0522 19:19:07.197350 12758 solver.cpp:253]     Train net output #0: loss = 1.41855 (* 1 = 1.41855 loss)
I0522 19:19:07.197367 12758 sgd_solver.cpp:106] Iteration 123375, lr = 0.001
I0522 19:19:16.979990 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_123750.caffemodel
I0522 19:19:17.035611 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_123750.solverstate
I0522 19:19:17.069552 12758 solver.cpp:237] Iteration 123750, loss = 1.37395
I0522 19:19:17.069608 12758 solver.cpp:253]     Train net output #0: loss = 1.37395 (* 1 = 1.37395 loss)
I0522 19:19:17.069633 12758 sgd_solver.cpp:106] Iteration 123750, lr = 0.001
I0522 19:19:26.874161 12758 solver.cpp:237] Iteration 124125, loss = 1.11692
I0522 19:19:26.874337 12758 solver.cpp:253]     Train net output #0: loss = 1.11692 (* 1 = 1.11692 loss)
I0522 19:19:26.874354 12758 sgd_solver.cpp:106] Iteration 124125, lr = 0.001
I0522 19:19:36.684507 12758 solver.cpp:237] Iteration 124500, loss = 1.23737
I0522 19:19:36.684563 12758 solver.cpp:253]     Train net output #0: loss = 1.23737 (* 1 = 1.23737 loss)
I0522 19:19:36.684581 12758 sgd_solver.cpp:106] Iteration 124500, lr = 0.001
I0522 19:19:46.492120 12758 solver.cpp:237] Iteration 124875, loss = 1.16022
I0522 19:19:46.492158 12758 solver.cpp:253]     Train net output #0: loss = 1.16022 (* 1 = 1.16022 loss)
I0522 19:19:46.492182 12758 sgd_solver.cpp:106] Iteration 124875, lr = 0.001
I0522 19:20:17.155530 12758 solver.cpp:237] Iteration 125250, loss = 1.13174
I0522 19:20:17.155727 12758 solver.cpp:253]     Train net output #0: loss = 1.13174 (* 1 = 1.13174 loss)
I0522 19:20:17.155745 12758 sgd_solver.cpp:106] Iteration 125250, lr = 0.001
I0522 19:20:26.961787 12758 solver.cpp:237] Iteration 125625, loss = 1.27331
I0522 19:20:26.961845 12758 solver.cpp:253]     Train net output #0: loss = 1.27331 (* 1 = 1.27331 loss)
I0522 19:20:26.961872 12758 sgd_solver.cpp:106] Iteration 125625, lr = 0.001
I0522 19:20:36.768450 12758 solver.cpp:237] Iteration 126000, loss = 1.14413
I0522 19:20:36.768488 12758 solver.cpp:253]     Train net output #0: loss = 1.14413 (* 1 = 1.14413 loss)
I0522 19:20:36.768512 12758 sgd_solver.cpp:106] Iteration 126000, lr = 0.001
I0522 19:20:46.575928 12758 solver.cpp:237] Iteration 126375, loss = 0.940571
I0522 19:20:46.575989 12758 solver.cpp:253]     Train net output #0: loss = 0.940571 (* 1 = 0.940571 loss)
I0522 19:20:46.576006 12758 sgd_solver.cpp:106] Iteration 126375, lr = 0.001
I0522 19:20:56.378566 12758 solver.cpp:237] Iteration 126750, loss = 1.28916
I0522 19:20:56.378741 12758 solver.cpp:253]     Train net output #0: loss = 1.28916 (* 1 = 1.28916 loss)
I0522 19:20:56.378757 12758 sgd_solver.cpp:106] Iteration 126750, lr = 0.001
I0522 19:21:06.184270 12758 solver.cpp:237] Iteration 127125, loss = 1.03646
I0522 19:21:06.184308 12758 solver.cpp:253]     Train net output #0: loss = 1.03646 (* 1 = 1.03646 loss)
I0522 19:21:06.184331 12758 sgd_solver.cpp:106] Iteration 127125, lr = 0.001
I0522 19:21:15.901190 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_127500.caffemodel
I0522 19:21:15.957638 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_127500.solverstate
I0522 19:21:15.983065 12758 solver.cpp:341] Iteration 127500, Testing net (#0)
I0522 19:22:04.555091 12758 solver.cpp:409]     Test net output #0: accuracy = 0.887312
I0522 19:22:04.555299 12758 solver.cpp:409]     Test net output #1: loss = 0.376038 (* 1 = 0.376038 loss)
I0522 19:22:25.467713 12758 solver.cpp:237] Iteration 127500, loss = 1.23892
I0522 19:22:25.467782 12758 solver.cpp:253]     Train net output #0: loss = 1.23892 (* 1 = 1.23892 loss)
I0522 19:22:25.467808 12758 sgd_solver.cpp:106] Iteration 127500, lr = 0.001
I0522 19:22:35.141237 12758 solver.cpp:237] Iteration 127875, loss = 0.92439
I0522 19:22:35.141417 12758 solver.cpp:253]     Train net output #0: loss = 0.924389 (* 1 = 0.924389 loss)
I0522 19:22:35.141434 12758 sgd_solver.cpp:106] Iteration 127875, lr = 0.001
I0522 19:22:44.818384 12758 solver.cpp:237] Iteration 128250, loss = 1.58502
I0522 19:22:44.818421 12758 solver.cpp:253]     Train net output #0: loss = 1.58502 (* 1 = 1.58502 loss)
I0522 19:22:44.818445 12758 sgd_solver.cpp:106] Iteration 128250, lr = 0.001
I0522 19:22:54.632820 12758 solver.cpp:237] Iteration 128625, loss = 1.12005
I0522 19:22:54.632876 12758 solver.cpp:253]     Train net output #0: loss = 1.12005 (* 1 = 1.12005 loss)
I0522 19:22:54.632901 12758 sgd_solver.cpp:106] Iteration 128625, lr = 0.001
I0522 19:23:04.533852 12758 solver.cpp:237] Iteration 129000, loss = 1.13376
I0522 19:23:04.533890 12758 solver.cpp:253]     Train net output #0: loss = 1.13376 (* 1 = 1.13376 loss)
I0522 19:23:04.533912 12758 sgd_solver.cpp:106] Iteration 129000, lr = 0.001
I0522 19:23:14.429651 12758 solver.cpp:237] Iteration 129375, loss = 1.18492
I0522 19:23:14.429844 12758 solver.cpp:253]     Train net output #0: loss = 1.18492 (* 1 = 1.18492 loss)
I0522 19:23:14.429865 12758 sgd_solver.cpp:106] Iteration 129375, lr = 0.001
I0522 19:23:24.137377 12758 solver.cpp:237] Iteration 129750, loss = 1.26466
I0522 19:23:24.137414 12758 solver.cpp:253]     Train net output #0: loss = 1.26466 (* 1 = 1.26466 loss)
I0522 19:23:24.137437 12758 sgd_solver.cpp:106] Iteration 129750, lr = 0.001
I0522 19:23:54.735404 12758 solver.cpp:237] Iteration 130125, loss = 0.960005
I0522 19:23:54.735604 12758 solver.cpp:253]     Train net output #0: loss = 0.960005 (* 1 = 0.960005 loss)
I0522 19:23:54.735621 12758 sgd_solver.cpp:106] Iteration 130125, lr = 0.001
I0522 19:24:04.447680 12758 solver.cpp:237] Iteration 130500, loss = 1.27315
I0522 19:24:04.447738 12758 solver.cpp:253]     Train net output #0: loss = 1.27315 (* 1 = 1.27315 loss)
I0522 19:24:04.447765 12758 sgd_solver.cpp:106] Iteration 130500, lr = 0.001
I0522 19:24:14.147682 12758 solver.cpp:237] Iteration 130875, loss = 0.86667
I0522 19:24:14.147722 12758 solver.cpp:253]     Train net output #0: loss = 0.86667 (* 1 = 0.86667 loss)
I0522 19:24:14.147747 12758 sgd_solver.cpp:106] Iteration 130875, lr = 0.001
I0522 19:24:23.825460 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_131250.caffemodel
I0522 19:24:23.884155 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_131250.solverstate
I0522 19:24:23.919489 12758 solver.cpp:237] Iteration 131250, loss = 0.956181
I0522 19:24:23.919553 12758 solver.cpp:253]     Train net output #0: loss = 0.956181 (* 1 = 0.956181 loss)
I0522 19:24:23.919571 12758 sgd_solver.cpp:106] Iteration 131250, lr = 0.001
I0522 19:24:33.738977 12758 solver.cpp:237] Iteration 131625, loss = 1.16192
I0522 19:24:33.739184 12758 solver.cpp:253]     Train net output #0: loss = 1.16192 (* 1 = 1.16192 loss)
I0522 19:24:33.739203 12758 sgd_solver.cpp:106] Iteration 131625, lr = 0.001
I0522 19:24:43.650380 12758 solver.cpp:237] Iteration 132000, loss = 1.42229
I0522 19:24:43.650418 12758 solver.cpp:253]     Train net output #0: loss = 1.42229 (* 1 = 1.42229 loss)
I0522 19:24:43.650440 12758 sgd_solver.cpp:106] Iteration 132000, lr = 0.001
I0522 19:24:53.558804 12758 solver.cpp:237] Iteration 132375, loss = 1.37196
I0522 19:24:53.558841 12758 solver.cpp:253]     Train net output #0: loss = 1.37196 (* 1 = 1.37196 loss)
I0522 19:24:53.558859 12758 sgd_solver.cpp:106] Iteration 132375, lr = 0.001
I0522 19:25:24.351531 12758 solver.cpp:237] Iteration 132750, loss = 1.1775
I0522 19:25:24.351729 12758 solver.cpp:253]     Train net output #0: loss = 1.1775 (* 1 = 1.1775 loss)
I0522 19:25:24.351747 12758 sgd_solver.cpp:106] Iteration 132750, lr = 0.001
I0522 19:25:34.226261 12758 solver.cpp:237] Iteration 133125, loss = 0.850319
I0522 19:25:34.226300 12758 solver.cpp:253]     Train net output #0: loss = 0.850319 (* 1 = 0.850319 loss)
I0522 19:25:34.226322 12758 sgd_solver.cpp:106] Iteration 133125, lr = 0.001
I0522 19:25:44.096541 12758 solver.cpp:237] Iteration 133500, loss = 0.998211
I0522 19:25:44.096603 12758 solver.cpp:253]     Train net output #0: loss = 0.998211 (* 1 = 0.998211 loss)
I0522 19:25:44.096631 12758 sgd_solver.cpp:106] Iteration 133500, lr = 0.001
I0522 19:25:53.850397 12758 solver.cpp:237] Iteration 133875, loss = 1.20553
I0522 19:25:53.850435 12758 solver.cpp:253]     Train net output #0: loss = 1.20553 (* 1 = 1.20553 loss)
I0522 19:25:53.850460 12758 sgd_solver.cpp:106] Iteration 133875, lr = 0.001
I0522 19:26:03.607002 12758 solver.cpp:237] Iteration 134250, loss = 1.02742
I0522 19:26:03.607178 12758 solver.cpp:253]     Train net output #0: loss = 1.02742 (* 1 = 1.02742 loss)
I0522 19:26:03.607195 12758 sgd_solver.cpp:106] Iteration 134250, lr = 0.001
I0522 19:26:13.344844 12758 solver.cpp:237] Iteration 134625, loss = 0.964216
I0522 19:26:13.344904 12758 solver.cpp:253]     Train net output #0: loss = 0.964216 (* 1 = 0.964216 loss)
I0522 19:26:13.344929 12758 sgd_solver.cpp:106] Iteration 134625, lr = 0.001
I0522 19:26:23.038511 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_135000.caffemodel
I0522 19:26:23.096727 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_135000.solverstate
I0522 19:26:23.125136 12758 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 19:27:32.641441 12758 solver.cpp:409]     Test net output #0: accuracy = 0.889992
I0522 19:27:32.641639 12758 solver.cpp:409]     Test net output #1: loss = 0.370499 (* 1 = 0.370499 loss)
I0522 19:27:53.516213 12758 solver.cpp:237] Iteration 135000, loss = 1.00105
I0522 19:27:53.516278 12758 solver.cpp:253]     Train net output #0: loss = 1.00105 (* 1 = 1.00105 loss)
I0522 19:27:53.516309 12758 sgd_solver.cpp:106] Iteration 135000, lr = 0.001
I0522 19:28:03.428208 12758 solver.cpp:237] Iteration 135375, loss = 0.974374
I0522 19:28:03.428385 12758 solver.cpp:253]     Train net output #0: loss = 0.974374 (* 1 = 0.974374 loss)
I0522 19:28:03.428401 12758 sgd_solver.cpp:106] Iteration 135375, lr = 0.001
I0522 19:28:13.349117 12758 solver.cpp:237] Iteration 135750, loss = 1.21627
I0522 19:28:13.349153 12758 solver.cpp:253]     Train net output #0: loss = 1.21627 (* 1 = 1.21627 loss)
I0522 19:28:13.349171 12758 sgd_solver.cpp:106] Iteration 135750, lr = 0.001
I0522 19:28:23.118696 12758 solver.cpp:237] Iteration 136125, loss = 1.01617
I0522 19:28:23.118751 12758 solver.cpp:253]     Train net output #0: loss = 1.01617 (* 1 = 1.01617 loss)
I0522 19:28:23.118767 12758 sgd_solver.cpp:106] Iteration 136125, lr = 0.001
I0522 19:28:32.887120 12758 solver.cpp:237] Iteration 136500, loss = 1.34763
I0522 19:28:32.887157 12758 solver.cpp:253]     Train net output #0: loss = 1.34763 (* 1 = 1.34763 loss)
I0522 19:28:32.887179 12758 sgd_solver.cpp:106] Iteration 136500, lr = 0.001
I0522 19:28:42.694562 12758 solver.cpp:237] Iteration 136875, loss = 1.40657
I0522 19:28:42.694768 12758 solver.cpp:253]     Train net output #0: loss = 1.40657 (* 1 = 1.40657 loss)
I0522 19:28:42.694787 12758 sgd_solver.cpp:106] Iteration 136875, lr = 0.001
I0522 19:28:52.568270 12758 solver.cpp:237] Iteration 137250, loss = 0.814276
I0522 19:28:52.568308 12758 solver.cpp:253]     Train net output #0: loss = 0.814275 (* 1 = 0.814275 loss)
I0522 19:28:52.568327 12758 sgd_solver.cpp:106] Iteration 137250, lr = 0.001
I0522 19:29:23.313308 12758 solver.cpp:237] Iteration 137625, loss = 1.35439
I0522 19:29:23.313513 12758 solver.cpp:253]     Train net output #0: loss = 1.35439 (* 1 = 1.35439 loss)
I0522 19:29:23.313529 12758 sgd_solver.cpp:106] Iteration 137625, lr = 0.001
I0522 19:29:33.113116 12758 solver.cpp:237] Iteration 138000, loss = 0.956383
I0522 19:29:33.113173 12758 solver.cpp:253]     Train net output #0: loss = 0.956383 (* 1 = 0.956383 loss)
I0522 19:29:33.113190 12758 sgd_solver.cpp:106] Iteration 138000, lr = 0.001
I0522 19:29:42.818495 12758 solver.cpp:237] Iteration 138375, loss = 0.795271
I0522 19:29:42.818533 12758 solver.cpp:253]     Train net output #0: loss = 0.79527 (* 1 = 0.79527 loss)
I0522 19:29:42.818552 12758 sgd_solver.cpp:106] Iteration 138375, lr = 0.001
I0522 19:29:52.489028 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_138750.caffemodel
I0522 19:29:52.545078 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_138750.solverstate
I0522 19:29:52.580142 12758 solver.cpp:237] Iteration 138750, loss = 1.13961
I0522 19:29:52.580204 12758 solver.cpp:253]     Train net output #0: loss = 1.13961 (* 1 = 1.13961 loss)
I0522 19:29:52.580234 12758 sgd_solver.cpp:106] Iteration 138750, lr = 0.001
I0522 19:30:02.511878 12758 solver.cpp:237] Iteration 139125, loss = 1.0869
I0522 19:30:02.512084 12758 solver.cpp:253]     Train net output #0: loss = 1.08689 (* 1 = 1.08689 loss)
I0522 19:30:02.512104 12758 sgd_solver.cpp:106] Iteration 139125, lr = 0.001
I0522 19:30:12.468308 12758 solver.cpp:237] Iteration 139500, loss = 1.10598
I0522 19:30:12.468346 12758 solver.cpp:253]     Train net output #0: loss = 1.10598 (* 1 = 1.10598 loss)
I0522 19:30:12.468370 12758 sgd_solver.cpp:106] Iteration 139500, lr = 0.001
I0522 19:30:22.410550 12758 solver.cpp:237] Iteration 139875, loss = 0.899993
I0522 19:30:22.410606 12758 solver.cpp:253]     Train net output #0: loss = 0.899993 (* 1 = 0.899993 loss)
I0522 19:30:22.410624 12758 sgd_solver.cpp:106] Iteration 139875, lr = 0.001
I0522 19:30:53.191714 12758 solver.cpp:237] Iteration 140250, loss = 0.94669
I0522 19:30:53.191925 12758 solver.cpp:253]     Train net output #0: loss = 0.94669 (* 1 = 0.94669 loss)
I0522 19:30:53.191952 12758 sgd_solver.cpp:106] Iteration 140250, lr = 0.001
I0522 19:31:03.098440 12758 solver.cpp:237] Iteration 140625, loss = 1.18248
I0522 19:31:03.098479 12758 solver.cpp:253]     Train net output #0: loss = 1.18248 (* 1 = 1.18248 loss)
I0522 19:31:03.098497 12758 sgd_solver.cpp:106] Iteration 140625, lr = 0.001
I0522 19:31:12.997144 12758 solver.cpp:237] Iteration 141000, loss = 1.08946
I0522 19:31:12.997205 12758 solver.cpp:253]     Train net output #0: loss = 1.08946 (* 1 = 1.08946 loss)
I0522 19:31:12.997230 12758 sgd_solver.cpp:106] Iteration 141000, lr = 0.001
I0522 19:31:22.876299 12758 solver.cpp:237] Iteration 141375, loss = 0.965189
I0522 19:31:22.876338 12758 solver.cpp:253]     Train net output #0: loss = 0.965189 (* 1 = 0.965189 loss)
I0522 19:31:22.876356 12758 sgd_solver.cpp:106] Iteration 141375, lr = 0.001
I0522 19:31:32.761921 12758 solver.cpp:237] Iteration 141750, loss = 1.43982
I0522 19:31:32.762111 12758 solver.cpp:253]     Train net output #0: loss = 1.43982 (* 1 = 1.43982 loss)
I0522 19:31:32.762127 12758 sgd_solver.cpp:106] Iteration 141750, lr = 0.001
I0522 19:31:42.612051 12758 solver.cpp:237] Iteration 142125, loss = 1.07607
I0522 19:31:42.612110 12758 solver.cpp:253]     Train net output #0: loss = 1.07607 (* 1 = 1.07607 loss)
I0522 19:31:42.612138 12758 sgd_solver.cpp:106] Iteration 142125, lr = 0.001
I0522 19:31:52.429059 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_142500.caffemodel
I0522 19:31:52.485996 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_142500.solverstate
I0522 19:31:52.511474 12758 solver.cpp:341] Iteration 142500, Testing net (#0)
I0522 19:32:40.780172 12758 solver.cpp:409]     Test net output #0: accuracy = 0.887648
I0522 19:32:40.780372 12758 solver.cpp:409]     Test net output #1: loss = 0.352914 (* 1 = 0.352914 loss)
I0522 19:33:01.687175 12758 solver.cpp:237] Iteration 142500, loss = 1.11404
I0522 19:33:01.687240 12758 solver.cpp:253]     Train net output #0: loss = 1.11404 (* 1 = 1.11404 loss)
I0522 19:33:01.687259 12758 sgd_solver.cpp:106] Iteration 142500, lr = 0.001
I0522 19:33:11.610576 12758 solver.cpp:237] Iteration 142875, loss = 1.15811
I0522 19:33:11.610759 12758 solver.cpp:253]     Train net output #0: loss = 1.15811 (* 1 = 1.15811 loss)
I0522 19:33:11.610776 12758 sgd_solver.cpp:106] Iteration 142875, lr = 0.001
I0522 19:33:21.528082 12758 solver.cpp:237] Iteration 143250, loss = 1.47101
I0522 19:33:21.528138 12758 solver.cpp:253]     Train net output #0: loss = 1.47101 (* 1 = 1.47101 loss)
I0522 19:33:21.528163 12758 sgd_solver.cpp:106] Iteration 143250, lr = 0.001
I0522 19:33:31.446780 12758 solver.cpp:237] Iteration 143625, loss = 1.18957
I0522 19:33:31.446817 12758 solver.cpp:253]     Train net output #0: loss = 1.18957 (* 1 = 1.18957 loss)
I0522 19:33:31.446836 12758 sgd_solver.cpp:106] Iteration 143625, lr = 0.001
I0522 19:33:41.377110 12758 solver.cpp:237] Iteration 144000, loss = 1.03693
I0522 19:33:41.377166 12758 solver.cpp:253]     Train net output #0: loss = 1.03693 (* 1 = 1.03693 loss)
I0522 19:33:41.377192 12758 sgd_solver.cpp:106] Iteration 144000, lr = 0.001
I0522 19:33:51.304168 12758 solver.cpp:237] Iteration 144375, loss = 1.18739
I0522 19:33:51.304348 12758 solver.cpp:253]     Train net output #0: loss = 1.18739 (* 1 = 1.18739 loss)
I0522 19:33:51.304365 12758 sgd_solver.cpp:106] Iteration 144375, lr = 0.001
I0522 19:34:01.228812 12758 solver.cpp:237] Iteration 144750, loss = 1.1833
I0522 19:34:01.228849 12758 solver.cpp:253]     Train net output #0: loss = 1.1833 (* 1 = 1.1833 loss)
I0522 19:34:01.228873 12758 sgd_solver.cpp:106] Iteration 144750, lr = 0.001
I0522 19:34:32.063804 12758 solver.cpp:237] Iteration 145125, loss = 0.793367
I0522 19:34:32.064015 12758 solver.cpp:253]     Train net output #0: loss = 0.793366 (* 1 = 0.793366 loss)
I0522 19:34:32.064033 12758 sgd_solver.cpp:106] Iteration 145125, lr = 0.001
I0522 19:34:41.988379 12758 solver.cpp:237] Iteration 145500, loss = 0.9414
I0522 19:34:41.988417 12758 solver.cpp:253]     Train net output #0: loss = 0.9414 (* 1 = 0.9414 loss)
I0522 19:34:41.988441 12758 sgd_solver.cpp:106] Iteration 145500, lr = 0.001
I0522 19:34:51.909531 12758 solver.cpp:237] Iteration 145875, loss = 0.919544
I0522 19:34:51.909569 12758 solver.cpp:253]     Train net output #0: loss = 0.919544 (* 1 = 0.919544 loss)
I0522 19:34:51.909590 12758 sgd_solver.cpp:106] Iteration 145875, lr = 0.001
I0522 19:35:01.807332 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_146250.caffemodel
I0522 19:35:01.863557 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_146250.solverstate
I0522 19:35:01.897135 12758 solver.cpp:237] Iteration 146250, loss = 1.23512
I0522 19:35:01.897192 12758 solver.cpp:253]     Train net output #0: loss = 1.23512 (* 1 = 1.23512 loss)
I0522 19:35:01.897212 12758 sgd_solver.cpp:106] Iteration 146250, lr = 0.001
I0522 19:35:11.828833 12758 solver.cpp:237] Iteration 146625, loss = 0.850884
I0522 19:35:11.829025 12758 solver.cpp:253]     Train net output #0: loss = 0.850884 (* 1 = 0.850884 loss)
I0522 19:35:11.829042 12758 sgd_solver.cpp:106] Iteration 146625, lr = 0.001
I0522 19:35:21.702203 12758 solver.cpp:237] Iteration 147000, loss = 1.7221
I0522 19:35:21.702257 12758 solver.cpp:253]     Train net output #0: loss = 1.7221 (* 1 = 1.7221 loss)
I0522 19:35:21.702275 12758 sgd_solver.cpp:106] Iteration 147000, lr = 0.001
I0522 19:35:31.445623 12758 solver.cpp:237] Iteration 147375, loss = 1.51005
I0522 19:35:31.445662 12758 solver.cpp:253]     Train net output #0: loss = 1.51005 (* 1 = 1.51005 loss)
I0522 19:35:31.445680 12758 sgd_solver.cpp:106] Iteration 147375, lr = 0.001
I0522 19:36:02.086765 12758 solver.cpp:237] Iteration 147750, loss = 0.938059
I0522 19:36:02.086969 12758 solver.cpp:253]     Train net output #0: loss = 0.938059 (* 1 = 0.938059 loss)
I0522 19:36:02.086987 12758 sgd_solver.cpp:106] Iteration 147750, lr = 0.001
I0522 19:36:11.860838 12758 solver.cpp:237] Iteration 148125, loss = 1.41918
I0522 19:36:11.860895 12758 solver.cpp:253]     Train net output #0: loss = 1.41918 (* 1 = 1.41918 loss)
I0522 19:36:11.860911 12758 sgd_solver.cpp:106] Iteration 148125, lr = 0.001
I0522 19:36:21.690086 12758 solver.cpp:237] Iteration 148500, loss = 1.08423
I0522 19:36:21.690124 12758 solver.cpp:253]     Train net output #0: loss = 1.08423 (* 1 = 1.08423 loss)
I0522 19:36:21.690140 12758 sgd_solver.cpp:106] Iteration 148500, lr = 0.001
I0522 19:36:31.516494 12758 solver.cpp:237] Iteration 148875, loss = 1.05781
I0522 19:36:31.516532 12758 solver.cpp:253]     Train net output #0: loss = 1.05781 (* 1 = 1.05781 loss)
I0522 19:36:31.516556 12758 sgd_solver.cpp:106] Iteration 148875, lr = 0.001
I0522 19:36:41.280225 12758 solver.cpp:237] Iteration 149250, loss = 1.12199
I0522 19:36:41.280422 12758 solver.cpp:253]     Train net output #0: loss = 1.12198 (* 1 = 1.12198 loss)
I0522 19:36:41.280447 12758 sgd_solver.cpp:106] Iteration 149250, lr = 0.001
I0522 19:36:51.020318 12758 solver.cpp:237] Iteration 149625, loss = 1.13436
I0522 19:36:51.020355 12758 solver.cpp:253]     Train net output #0: loss = 1.13436 (* 1 = 1.13436 loss)
I0522 19:36:51.020378 12758 sgd_solver.cpp:106] Iteration 149625, lr = 0.001
I0522 19:37:00.757660 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_150000.caffemodel
I0522 19:37:00.816336 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_150000.solverstate
I0522 19:37:00.844813 12758 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 19:38:10.320063 12758 solver.cpp:409]     Test net output #0: accuracy = 0.890019
I0522 19:38:10.320266 12758 solver.cpp:409]     Test net output #1: loss = 0.384648 (* 1 = 0.384648 loss)
I0522 19:38:31.215582 12758 solver.cpp:237] Iteration 150000, loss = 0.979444
I0522 19:38:31.215646 12758 solver.cpp:253]     Train net output #0: loss = 0.979444 (* 1 = 0.979444 loss)
I0522 19:38:31.215672 12758 sgd_solver.cpp:106] Iteration 150000, lr = 0.001
I0522 19:38:40.974895 12758 solver.cpp:237] Iteration 150375, loss = 1.09192
I0522 19:38:40.975095 12758 solver.cpp:253]     Train net output #0: loss = 1.09192 (* 1 = 1.09192 loss)
I0522 19:38:40.975121 12758 sgd_solver.cpp:106] Iteration 150375, lr = 0.001
I0522 19:38:50.949062 12758 solver.cpp:237] Iteration 150750, loss = 1.17179
I0522 19:38:50.949100 12758 solver.cpp:253]     Train net output #0: loss = 1.17179 (* 1 = 1.17179 loss)
I0522 19:38:50.949122 12758 sgd_solver.cpp:106] Iteration 150750, lr = 0.001
I0522 19:39:00.909056 12758 solver.cpp:237] Iteration 151125, loss = 1.17066
I0522 19:39:00.909093 12758 solver.cpp:253]     Train net output #0: loss = 1.17066 (* 1 = 1.17066 loss)
I0522 19:39:00.909117 12758 sgd_solver.cpp:106] Iteration 151125, lr = 0.001
I0522 19:39:10.805379 12758 solver.cpp:237] Iteration 151500, loss = 1.15182
I0522 19:39:10.805433 12758 solver.cpp:253]     Train net output #0: loss = 1.15182 (* 1 = 1.15182 loss)
I0522 19:39:10.805450 12758 sgd_solver.cpp:106] Iteration 151500, lr = 0.001
I0522 19:39:20.662381 12758 solver.cpp:237] Iteration 151875, loss = 0.90432
I0522 19:39:20.662574 12758 solver.cpp:253]     Train net output #0: loss = 0.90432 (* 1 = 0.90432 loss)
I0522 19:39:20.662590 12758 sgd_solver.cpp:106] Iteration 151875, lr = 0.001
I0522 19:39:30.485661 12758 solver.cpp:237] Iteration 152250, loss = 1.23167
I0522 19:39:30.485718 12758 solver.cpp:253]     Train net output #0: loss = 1.23167 (* 1 = 1.23167 loss)
I0522 19:39:30.485746 12758 sgd_solver.cpp:106] Iteration 152250, lr = 0.001
I0522 19:40:01.050498 12758 solver.cpp:237] Iteration 152625, loss = 1.44318
I0522 19:40:01.050705 12758 solver.cpp:253]     Train net output #0: loss = 1.44318 (* 1 = 1.44318 loss)
I0522 19:40:01.050722 12758 sgd_solver.cpp:106] Iteration 152625, lr = 0.001
I0522 19:40:10.717473 12758 solver.cpp:237] Iteration 153000, loss = 1.13365
I0522 19:40:10.717509 12758 solver.cpp:253]     Train net output #0: loss = 1.13365 (* 1 = 1.13365 loss)
I0522 19:40:10.717532 12758 sgd_solver.cpp:106] Iteration 153000, lr = 0.001
I0522 19:40:20.386916 12758 solver.cpp:237] Iteration 153375, loss = 1.38934
I0522 19:40:20.386970 12758 solver.cpp:253]     Train net output #0: loss = 1.38934 (* 1 = 1.38934 loss)
I0522 19:40:20.386986 12758 sgd_solver.cpp:106] Iteration 153375, lr = 0.001
I0522 19:40:30.029346 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_153750.caffemodel
I0522 19:40:30.085790 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_153750.solverstate
I0522 19:40:30.119315 12758 solver.cpp:237] Iteration 153750, loss = 1.21908
I0522 19:40:30.119370 12758 solver.cpp:253]     Train net output #0: loss = 1.21908 (* 1 = 1.21908 loss)
I0522 19:40:30.119396 12758 sgd_solver.cpp:106] Iteration 153750, lr = 0.001
I0522 19:40:39.780766 12758 solver.cpp:237] Iteration 154125, loss = 1.18022
I0522 19:40:39.780946 12758 solver.cpp:253]     Train net output #0: loss = 1.18022 (* 1 = 1.18022 loss)
I0522 19:40:39.780964 12758 sgd_solver.cpp:106] Iteration 154125, lr = 0.001
I0522 19:40:49.591346 12758 solver.cpp:237] Iteration 154500, loss = 0.984991
I0522 19:40:49.591408 12758 solver.cpp:253]     Train net output #0: loss = 0.984991 (* 1 = 0.984991 loss)
I0522 19:40:49.591431 12758 sgd_solver.cpp:106] Iteration 154500, lr = 0.001
I0522 19:40:59.494942 12758 solver.cpp:237] Iteration 154875, loss = 1.19792
I0522 19:40:59.494981 12758 solver.cpp:253]     Train net output #0: loss = 1.19792 (* 1 = 1.19792 loss)
I0522 19:40:59.494999 12758 sgd_solver.cpp:106] Iteration 154875, lr = 0.001
I0522 19:41:30.277438 12758 solver.cpp:237] Iteration 155250, loss = 1.27501
I0522 19:41:30.277643 12758 solver.cpp:253]     Train net output #0: loss = 1.27501 (* 1 = 1.27501 loss)
I0522 19:41:30.277660 12758 sgd_solver.cpp:106] Iteration 155250, lr = 0.001
I0522 19:41:40.178426 12758 solver.cpp:237] Iteration 155625, loss = 1.22392
I0522 19:41:40.178478 12758 solver.cpp:253]     Train net output #0: loss = 1.22392 (* 1 = 1.22392 loss)
I0522 19:41:40.178494 12758 sgd_solver.cpp:106] Iteration 155625, lr = 0.001
I0522 19:41:50.069020 12758 solver.cpp:237] Iteration 156000, loss = 1.283
I0522 19:41:50.069058 12758 solver.cpp:253]     Train net output #0: loss = 1.283 (* 1 = 1.283 loss)
I0522 19:41:50.069077 12758 sgd_solver.cpp:106] Iteration 156000, lr = 0.001
I0522 19:41:59.978744 12758 solver.cpp:237] Iteration 156375, loss = 1.37193
I0522 19:41:59.978799 12758 solver.cpp:253]     Train net output #0: loss = 1.37193 (* 1 = 1.37193 loss)
I0522 19:41:59.978816 12758 sgd_solver.cpp:106] Iteration 156375, lr = 0.001
I0522 19:42:09.881281 12758 solver.cpp:237] Iteration 156750, loss = 1.21426
I0522 19:42:09.881474 12758 solver.cpp:253]     Train net output #0: loss = 1.21426 (* 1 = 1.21426 loss)
I0522 19:42:09.881490 12758 sgd_solver.cpp:106] Iteration 156750, lr = 0.001
I0522 19:42:19.790498 12758 solver.cpp:237] Iteration 157125, loss = 1.06089
I0522 19:42:19.790536 12758 solver.cpp:253]     Train net output #0: loss = 1.06089 (* 1 = 1.06089 loss)
I0522 19:42:19.790555 12758 sgd_solver.cpp:106] Iteration 157125, lr = 0.001
I0522 19:42:29.614451 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_157500.caffemodel
I0522 19:42:29.671099 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_157500.solverstate
I0522 19:42:29.696653 12758 solver.cpp:341] Iteration 157500, Testing net (#0)
I0522 19:43:18.281589 12758 solver.cpp:409]     Test net output #0: accuracy = 0.891431
I0522 19:43:18.281791 12758 solver.cpp:409]     Test net output #1: loss = 0.347519 (* 1 = 0.347519 loss)
I0522 19:43:39.168927 12758 solver.cpp:237] Iteration 157500, loss = 1.34538
I0522 19:43:39.168992 12758 solver.cpp:253]     Train net output #0: loss = 1.34538 (* 1 = 1.34538 loss)
I0522 19:43:39.169010 12758 sgd_solver.cpp:106] Iteration 157500, lr = 0.001
I0522 19:43:49.093938 12758 solver.cpp:237] Iteration 157875, loss = 1.21599
I0522 19:43:49.094125 12758 solver.cpp:253]     Train net output #0: loss = 1.21599 (* 1 = 1.21599 loss)
I0522 19:43:49.094141 12758 sgd_solver.cpp:106] Iteration 157875, lr = 0.001
I0522 19:43:59.017254 12758 solver.cpp:237] Iteration 158250, loss = 1.26587
I0522 19:43:59.017292 12758 solver.cpp:253]     Train net output #0: loss = 1.26587 (* 1 = 1.26587 loss)
I0522 19:43:59.017315 12758 sgd_solver.cpp:106] Iteration 158250, lr = 0.001
I0522 19:44:08.938276 12758 solver.cpp:237] Iteration 158625, loss = 1.12147
I0522 19:44:08.938334 12758 solver.cpp:253]     Train net output #0: loss = 1.12147 (* 1 = 1.12147 loss)
I0522 19:44:08.938360 12758 sgd_solver.cpp:106] Iteration 158625, lr = 0.001
I0522 19:44:18.854157 12758 solver.cpp:237] Iteration 159000, loss = 0.946179
I0522 19:44:18.854194 12758 solver.cpp:253]     Train net output #0: loss = 0.946179 (* 1 = 0.946179 loss)
I0522 19:44:18.854213 12758 sgd_solver.cpp:106] Iteration 159000, lr = 0.001
I0522 19:44:28.773075 12758 solver.cpp:237] Iteration 159375, loss = 1.24224
I0522 19:44:28.773272 12758 solver.cpp:253]     Train net output #0: loss = 1.24224 (* 1 = 1.24224 loss)
I0522 19:44:28.773298 12758 sgd_solver.cpp:106] Iteration 159375, lr = 0.001
I0522 19:44:38.662993 12758 solver.cpp:237] Iteration 159750, loss = 1.22636
I0522 19:44:38.663030 12758 solver.cpp:253]     Train net output #0: loss = 1.22636 (* 1 = 1.22636 loss)
I0522 19:44:38.663054 12758 sgd_solver.cpp:106] Iteration 159750, lr = 0.001
I0522 19:45:09.472553 12758 solver.cpp:237] Iteration 160125, loss = 1.27481
I0522 19:45:09.472759 12758 solver.cpp:253]     Train net output #0: loss = 1.27481 (* 1 = 1.27481 loss)
I0522 19:45:09.472775 12758 sgd_solver.cpp:106] Iteration 160125, lr = 0.001
I0522 19:45:19.351371 12758 solver.cpp:237] Iteration 160500, loss = 1.22752
I0522 19:45:19.351423 12758 solver.cpp:253]     Train net output #0: loss = 1.22752 (* 1 = 1.22752 loss)
I0522 19:45:19.351440 12758 sgd_solver.cpp:106] Iteration 160500, lr = 0.001
I0522 19:45:29.242990 12758 solver.cpp:237] Iteration 160875, loss = 1.30679
I0522 19:45:29.243026 12758 solver.cpp:253]     Train net output #0: loss = 1.30678 (* 1 = 1.30678 loss)
I0522 19:45:29.243046 12758 sgd_solver.cpp:106] Iteration 160875, lr = 0.001
I0522 19:45:39.102280 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_161250.caffemodel
I0522 19:45:39.158990 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_161250.solverstate
I0522 19:45:39.192848 12758 solver.cpp:237] Iteration 161250, loss = 1.03659
I0522 19:45:39.192905 12758 solver.cpp:253]     Train net output #0: loss = 1.03659 (* 1 = 1.03659 loss)
I0522 19:45:39.192931 12758 sgd_solver.cpp:106] Iteration 161250, lr = 0.001
I0522 19:45:48.975442 12758 solver.cpp:237] Iteration 161625, loss = 0.96451
I0522 19:45:48.975654 12758 solver.cpp:253]     Train net output #0: loss = 0.96451 (* 1 = 0.96451 loss)
I0522 19:45:48.975673 12758 sgd_solver.cpp:106] Iteration 161625, lr = 0.001
I0522 19:45:58.674232 12758 solver.cpp:237] Iteration 162000, loss = 0.934699
I0522 19:45:58.674270 12758 solver.cpp:253]     Train net output #0: loss = 0.934698 (* 1 = 0.934698 loss)
I0522 19:45:58.674293 12758 sgd_solver.cpp:106] Iteration 162000, lr = 0.001
I0522 19:46:08.361671 12758 solver.cpp:237] Iteration 162375, loss = 0.966697
I0522 19:46:08.361709 12758 solver.cpp:253]     Train net output #0: loss = 0.966696 (* 1 = 0.966696 loss)
I0522 19:46:08.361729 12758 sgd_solver.cpp:106] Iteration 162375, lr = 0.001
I0522 19:46:39.005007 12758 solver.cpp:237] Iteration 162750, loss = 1.15781
I0522 19:46:39.005213 12758 solver.cpp:253]     Train net output #0: loss = 1.15781 (* 1 = 1.15781 loss)
I0522 19:46:39.005230 12758 sgd_solver.cpp:106] Iteration 162750, lr = 0.001
I0522 19:46:48.757808 12758 solver.cpp:237] Iteration 163125, loss = 1.2715
I0522 19:46:48.757845 12758 solver.cpp:253]     Train net output #0: loss = 1.2715 (* 1 = 1.2715 loss)
I0522 19:46:48.757869 12758 sgd_solver.cpp:106] Iteration 163125, lr = 0.001
I0522 19:46:58.511744 12758 solver.cpp:237] Iteration 163500, loss = 1.30259
I0522 19:46:58.511780 12758 solver.cpp:253]     Train net output #0: loss = 1.30259 (* 1 = 1.30259 loss)
I0522 19:46:58.511806 12758 sgd_solver.cpp:106] Iteration 163500, lr = 0.001
I0522 19:47:08.323081 12758 solver.cpp:237] Iteration 163875, loss = 0.897049
I0522 19:47:08.323138 12758 solver.cpp:253]     Train net output #0: loss = 0.897049 (* 1 = 0.897049 loss)
I0522 19:47:08.323163 12758 sgd_solver.cpp:106] Iteration 163875, lr = 0.001
I0522 19:47:18.134174 12758 solver.cpp:237] Iteration 164250, loss = 1.186
I0522 19:47:18.134367 12758 solver.cpp:253]     Train net output #0: loss = 1.186 (* 1 = 1.186 loss)
I0522 19:47:18.134384 12758 sgd_solver.cpp:106] Iteration 164250, lr = 0.001
I0522 19:47:27.945503 12758 solver.cpp:237] Iteration 164625, loss = 0.848314
I0522 19:47:27.945564 12758 solver.cpp:253]     Train net output #0: loss = 0.848314 (* 1 = 0.848314 loss)
I0522 19:47:27.945588 12758 sgd_solver.cpp:106] Iteration 164625, lr = 0.001
I0522 19:47:37.732070 12758 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_165000.caffemodel
I0522 19:47:37.787719 12758 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_165000.solverstate
I0522 19:47:37.813130 12758 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 19:48:47.311211 12758 solver.cpp:409]     Test net output #0: accuracy = 0.8918
I0522 19:48:47.311415 12758 solver.cpp:409]     Test net output #1: loss = 0.356593 (* 1 = 0.356593 loss)
I0522 19:49:08.212054 12758 solver.cpp:237] Iteration 165000, loss = 1.29616
I0522 19:49:08.212119 12758 solver.cpp:253]     Train net output #0: loss = 1.29616 (* 1 = 1.29616 loss)
I0522 19:49:08.212147 12758 sgd_solver.cpp:106] Iteration 165000, lr = 0.001
I0522 19:49:18.082073 12758 solver.cpp:237] Iteration 165375, loss = 1.11609
I0522 19:49:18.082272 12758 solver.cpp:253]     Train net output #0: loss = 1.11609 (* 1 = 1.11609 loss)
I0522 19:49:18.082288 12758 sgd_solver.cpp:106] Iteration 165375, lr = 0.001
I0522 19:49:27.943125 12758 solver.cpp:237] Iteration 165750, loss = 1.00477
I0522 19:49:27.943161 12758 solver.cpp:253]     Train net output #0: loss = 1.00477 (* 1 = 1.00477 loss)
I0522 19:49:27.943183 12758 sgd_solver.cpp:106] Iteration 165750, lr = 0.001
I0522 19:49:37.625800 12758 solver.cpp:237] Iteration 166125, loss = 1.28753
I0522 19:49:37.625859 12758 solver.cpp:253]     Train net output #0: loss = 1.28753 (* 1 = 1.28753 loss)
I0522 19:49:37.625887 12758 sgd_solver.cpp:106] Iteration 166125, lr = 0.001
I0522 19:49:47.294986 12758 solver.cpp:237] Iteration 166500, loss = 1.12503
I0522 19:49:47.295022 12758 solver.cpp:253]     Train net output #0: loss = 1.12503 (* 1 = 1.12503 loss)
I0522 19:49:47.295047 12758 sgd_solver.cpp:106] Iteration 166500, lr = 0.001
I0522 19:49:56.977428 12758 solver.cpp:237] Iteration 166875, loss = 0.964878
I0522 19:49:56.977630 12758 solver.cpp:253]     Train net output #0: loss = 0.964878 (* 1 = 0.964878 loss)
I0522 19:49:56.977648 12758 sgd_solver.cpp:106] Iteration 166875, lr = 0.001
I0522 19:50:06.681805 12758 solver.cpp:237] Iteration 167250, loss = 1.04196
I0522 19:50:06.681843 12758 solver.cpp:253]     Train net output #0: loss = 1.04196 (* 1 = 1.04196 loss)
I0522 19:50:06.681866 12758 sgd_solver.cpp:106] Iteration 167250, lr = 0.001
I0522 19:50:37.265102 12758 solver.cpp:237] Iteration 167625, loss = 1.23176
I0522 19:50:37.265308 12758 solver.cpp:253]     Train net output #0: loss = 1.23176 (* 1 = 1.23176 loss)
I0522 19:50:37.265326 12758 sgd_solver.cpp:106] Iteration 167625, lr = 0.001
I0522 19:50:47.035845 12758 solver.cpp:237] Iteration 168000, loss = 0.923736
I0522 19:50:47.035903 12758 solver.cpp:253]     Train net output #0: loss = 0.923736 (* 1 = 0.923736 loss)
I0522 19:50:47.035922 12758 sgd_solver.cpp:106] Iteration 168000, lr = 0.001
aprun: Apid 11249969: Caught signal Terminated, sending to application
*** Aborted at 1463961050 (unix time) try "date -d @1463961050" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x31d3) received by PID 12758 (TID 0x2aaac746f900) from PID 12755; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11249969: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7221 exceeded limit 7200
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
aprun: Apid 11249969: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11249969: Caught signal Terminated, sending to application
