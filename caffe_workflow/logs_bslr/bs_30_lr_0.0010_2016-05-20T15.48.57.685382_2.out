2812854
I0526 23:11:45.396034  4662 caffe.cpp:184] Using GPUs 0
I0526 23:11:45.823202  4662 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.001
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382.prototxt"
I0526 23:11:45.825328  4662 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382.prototxt
I0526 23:11:45.844290  4662 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 23:11:45.844348  4662 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 23:11:45.844694  4662 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 23:11:45.844874  4662 layer_factory.hpp:77] Creating layer data_hdf5
I0526 23:11:45.844898  4662 net.cpp:106] Creating Layer data_hdf5
I0526 23:11:45.844913  4662 net.cpp:411] data_hdf5 -> data
I0526 23:11:45.844946  4662 net.cpp:411] data_hdf5 -> label
I0526 23:11:45.844979  4662 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 23:11:45.846289  4662 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 23:11:45.848593  4662 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 23:12:07.378196  4662 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 23:12:07.383491  4662 net.cpp:150] Setting up data_hdf5
I0526 23:12:07.383532  4662 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0526 23:12:07.383546  4662 net.cpp:157] Top shape: 30 (30)
I0526 23:12:07.383558  4662 net.cpp:165] Memory required for data: 762120
I0526 23:12:07.383572  4662 layer_factory.hpp:77] Creating layer conv1
I0526 23:12:07.383605  4662 net.cpp:106] Creating Layer conv1
I0526 23:12:07.383616  4662 net.cpp:454] conv1 <- data
I0526 23:12:07.383640  4662 net.cpp:411] conv1 -> conv1
I0526 23:12:08.334261  4662 net.cpp:150] Setting up conv1
I0526 23:12:08.334309  4662 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0526 23:12:08.334321  4662 net.cpp:165] Memory required for data: 9056520
I0526 23:12:08.334349  4662 layer_factory.hpp:77] Creating layer relu1
I0526 23:12:08.334372  4662 net.cpp:106] Creating Layer relu1
I0526 23:12:08.334383  4662 net.cpp:454] relu1 <- conv1
I0526 23:12:08.334396  4662 net.cpp:397] relu1 -> conv1 (in-place)
I0526 23:12:08.334928  4662 net.cpp:150] Setting up relu1
I0526 23:12:08.334945  4662 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0526 23:12:08.334955  4662 net.cpp:165] Memory required for data: 17350920
I0526 23:12:08.334966  4662 layer_factory.hpp:77] Creating layer pool1
I0526 23:12:08.334982  4662 net.cpp:106] Creating Layer pool1
I0526 23:12:08.334993  4662 net.cpp:454] pool1 <- conv1
I0526 23:12:08.335006  4662 net.cpp:411] pool1 -> pool1
I0526 23:12:08.335088  4662 net.cpp:150] Setting up pool1
I0526 23:12:08.335101  4662 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0526 23:12:08.335111  4662 net.cpp:165] Memory required for data: 21498120
I0526 23:12:08.335120  4662 layer_factory.hpp:77] Creating layer conv2
I0526 23:12:08.335142  4662 net.cpp:106] Creating Layer conv2
I0526 23:12:08.335152  4662 net.cpp:454] conv2 <- pool1
I0526 23:12:08.335167  4662 net.cpp:411] conv2 -> conv2
I0526 23:12:08.337859  4662 net.cpp:150] Setting up conv2
I0526 23:12:08.337888  4662 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0526 23:12:08.337898  4662 net.cpp:165] Memory required for data: 27459720
I0526 23:12:08.337918  4662 layer_factory.hpp:77] Creating layer relu2
I0526 23:12:08.337931  4662 net.cpp:106] Creating Layer relu2
I0526 23:12:08.337941  4662 net.cpp:454] relu2 <- conv2
I0526 23:12:08.337954  4662 net.cpp:397] relu2 -> conv2 (in-place)
I0526 23:12:08.338285  4662 net.cpp:150] Setting up relu2
I0526 23:12:08.338299  4662 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0526 23:12:08.338310  4662 net.cpp:165] Memory required for data: 33421320
I0526 23:12:08.338320  4662 layer_factory.hpp:77] Creating layer pool2
I0526 23:12:08.338332  4662 net.cpp:106] Creating Layer pool2
I0526 23:12:08.338342  4662 net.cpp:454] pool2 <- conv2
I0526 23:12:08.338354  4662 net.cpp:411] pool2 -> pool2
I0526 23:12:08.338438  4662 net.cpp:150] Setting up pool2
I0526 23:12:08.338452  4662 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0526 23:12:08.338462  4662 net.cpp:165] Memory required for data: 36402120
I0526 23:12:08.338469  4662 layer_factory.hpp:77] Creating layer conv3
I0526 23:12:08.338488  4662 net.cpp:106] Creating Layer conv3
I0526 23:12:08.338498  4662 net.cpp:454] conv3 <- pool2
I0526 23:12:08.338512  4662 net.cpp:411] conv3 -> conv3
I0526 23:12:08.340487  4662 net.cpp:150] Setting up conv3
I0526 23:12:08.340505  4662 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0526 23:12:08.340517  4662 net.cpp:165] Memory required for data: 39654600
I0526 23:12:08.340536  4662 layer_factory.hpp:77] Creating layer relu3
I0526 23:12:08.340553  4662 net.cpp:106] Creating Layer relu3
I0526 23:12:08.340562  4662 net.cpp:454] relu3 <- conv3
I0526 23:12:08.340575  4662 net.cpp:397] relu3 -> conv3 (in-place)
I0526 23:12:08.341048  4662 net.cpp:150] Setting up relu3
I0526 23:12:08.341064  4662 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0526 23:12:08.341074  4662 net.cpp:165] Memory required for data: 42907080
I0526 23:12:08.341084  4662 layer_factory.hpp:77] Creating layer pool3
I0526 23:12:08.341097  4662 net.cpp:106] Creating Layer pool3
I0526 23:12:08.341107  4662 net.cpp:454] pool3 <- conv3
I0526 23:12:08.341120  4662 net.cpp:411] pool3 -> pool3
I0526 23:12:08.341188  4662 net.cpp:150] Setting up pool3
I0526 23:12:08.341202  4662 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0526 23:12:08.341212  4662 net.cpp:165] Memory required for data: 44533320
I0526 23:12:08.341219  4662 layer_factory.hpp:77] Creating layer conv4
I0526 23:12:08.341238  4662 net.cpp:106] Creating Layer conv4
I0526 23:12:08.341248  4662 net.cpp:454] conv4 <- pool3
I0526 23:12:08.341264  4662 net.cpp:411] conv4 -> conv4
I0526 23:12:08.343997  4662 net.cpp:150] Setting up conv4
I0526 23:12:08.344025  4662 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0526 23:12:08.344036  4662 net.cpp:165] Memory required for data: 45621960
I0526 23:12:08.344053  4662 layer_factory.hpp:77] Creating layer relu4
I0526 23:12:08.344066  4662 net.cpp:106] Creating Layer relu4
I0526 23:12:08.344076  4662 net.cpp:454] relu4 <- conv4
I0526 23:12:08.344089  4662 net.cpp:397] relu4 -> conv4 (in-place)
I0526 23:12:08.344552  4662 net.cpp:150] Setting up relu4
I0526 23:12:08.344568  4662 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0526 23:12:08.344578  4662 net.cpp:165] Memory required for data: 46710600
I0526 23:12:08.344589  4662 layer_factory.hpp:77] Creating layer pool4
I0526 23:12:08.344602  4662 net.cpp:106] Creating Layer pool4
I0526 23:12:08.344612  4662 net.cpp:454] pool4 <- conv4
I0526 23:12:08.344625  4662 net.cpp:411] pool4 -> pool4
I0526 23:12:08.344693  4662 net.cpp:150] Setting up pool4
I0526 23:12:08.344707  4662 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0526 23:12:08.344717  4662 net.cpp:165] Memory required for data: 47254920
I0526 23:12:08.344727  4662 layer_factory.hpp:77] Creating layer ip1
I0526 23:12:08.344748  4662 net.cpp:106] Creating Layer ip1
I0526 23:12:08.344758  4662 net.cpp:454] ip1 <- pool4
I0526 23:12:08.344772  4662 net.cpp:411] ip1 -> ip1
I0526 23:12:08.360219  4662 net.cpp:150] Setting up ip1
I0526 23:12:08.360247  4662 net.cpp:157] Top shape: 30 196 (5880)
I0526 23:12:08.360260  4662 net.cpp:165] Memory required for data: 47278440
I0526 23:12:08.360283  4662 layer_factory.hpp:77] Creating layer relu5
I0526 23:12:08.360297  4662 net.cpp:106] Creating Layer relu5
I0526 23:12:08.360308  4662 net.cpp:454] relu5 <- ip1
I0526 23:12:08.360324  4662 net.cpp:397] relu5 -> ip1 (in-place)
I0526 23:12:08.360666  4662 net.cpp:150] Setting up relu5
I0526 23:12:08.360680  4662 net.cpp:157] Top shape: 30 196 (5880)
I0526 23:12:08.360690  4662 net.cpp:165] Memory required for data: 47301960
I0526 23:12:08.360702  4662 layer_factory.hpp:77] Creating layer drop1
I0526 23:12:08.360724  4662 net.cpp:106] Creating Layer drop1
I0526 23:12:08.360734  4662 net.cpp:454] drop1 <- ip1
I0526 23:12:08.360748  4662 net.cpp:397] drop1 -> ip1 (in-place)
I0526 23:12:08.360807  4662 net.cpp:150] Setting up drop1
I0526 23:12:08.360821  4662 net.cpp:157] Top shape: 30 196 (5880)
I0526 23:12:08.360831  4662 net.cpp:165] Memory required for data: 47325480
I0526 23:12:08.360841  4662 layer_factory.hpp:77] Creating layer ip2
I0526 23:12:08.360860  4662 net.cpp:106] Creating Layer ip2
I0526 23:12:08.360870  4662 net.cpp:454] ip2 <- ip1
I0526 23:12:08.360883  4662 net.cpp:411] ip2 -> ip2
I0526 23:12:08.361343  4662 net.cpp:150] Setting up ip2
I0526 23:12:08.361356  4662 net.cpp:157] Top shape: 30 98 (2940)
I0526 23:12:08.361366  4662 net.cpp:165] Memory required for data: 47337240
I0526 23:12:08.361382  4662 layer_factory.hpp:77] Creating layer relu6
I0526 23:12:08.361394  4662 net.cpp:106] Creating Layer relu6
I0526 23:12:08.361403  4662 net.cpp:454] relu6 <- ip2
I0526 23:12:08.361415  4662 net.cpp:397] relu6 -> ip2 (in-place)
I0526 23:12:08.361937  4662 net.cpp:150] Setting up relu6
I0526 23:12:08.361953  4662 net.cpp:157] Top shape: 30 98 (2940)
I0526 23:12:08.361964  4662 net.cpp:165] Memory required for data: 47349000
I0526 23:12:08.361975  4662 layer_factory.hpp:77] Creating layer drop2
I0526 23:12:08.361989  4662 net.cpp:106] Creating Layer drop2
I0526 23:12:08.361997  4662 net.cpp:454] drop2 <- ip2
I0526 23:12:08.362010  4662 net.cpp:397] drop2 -> ip2 (in-place)
I0526 23:12:08.362053  4662 net.cpp:150] Setting up drop2
I0526 23:12:08.362066  4662 net.cpp:157] Top shape: 30 98 (2940)
I0526 23:12:08.362076  4662 net.cpp:165] Memory required for data: 47360760
I0526 23:12:08.362087  4662 layer_factory.hpp:77] Creating layer ip3
I0526 23:12:08.362099  4662 net.cpp:106] Creating Layer ip3
I0526 23:12:08.362109  4662 net.cpp:454] ip3 <- ip2
I0526 23:12:08.362123  4662 net.cpp:411] ip3 -> ip3
I0526 23:12:08.362337  4662 net.cpp:150] Setting up ip3
I0526 23:12:08.362350  4662 net.cpp:157] Top shape: 30 11 (330)
I0526 23:12:08.362360  4662 net.cpp:165] Memory required for data: 47362080
I0526 23:12:08.362375  4662 layer_factory.hpp:77] Creating layer drop3
I0526 23:12:08.362388  4662 net.cpp:106] Creating Layer drop3
I0526 23:12:08.362397  4662 net.cpp:454] drop3 <- ip3
I0526 23:12:08.362409  4662 net.cpp:397] drop3 -> ip3 (in-place)
I0526 23:12:08.362450  4662 net.cpp:150] Setting up drop3
I0526 23:12:08.362463  4662 net.cpp:157] Top shape: 30 11 (330)
I0526 23:12:08.362473  4662 net.cpp:165] Memory required for data: 47363400
I0526 23:12:08.362483  4662 layer_factory.hpp:77] Creating layer loss
I0526 23:12:08.362503  4662 net.cpp:106] Creating Layer loss
I0526 23:12:08.362511  4662 net.cpp:454] loss <- ip3
I0526 23:12:08.362524  4662 net.cpp:454] loss <- label
I0526 23:12:08.362535  4662 net.cpp:411] loss -> loss
I0526 23:12:08.362553  4662 layer_factory.hpp:77] Creating layer loss
I0526 23:12:08.363204  4662 net.cpp:150] Setting up loss
I0526 23:12:08.363224  4662 net.cpp:157] Top shape: (1)
I0526 23:12:08.363239  4662 net.cpp:160]     with loss weight 1
I0526 23:12:08.363281  4662 net.cpp:165] Memory required for data: 47363404
I0526 23:12:08.363291  4662 net.cpp:226] loss needs backward computation.
I0526 23:12:08.363302  4662 net.cpp:226] drop3 needs backward computation.
I0526 23:12:08.363311  4662 net.cpp:226] ip3 needs backward computation.
I0526 23:12:08.363322  4662 net.cpp:226] drop2 needs backward computation.
I0526 23:12:08.363332  4662 net.cpp:226] relu6 needs backward computation.
I0526 23:12:08.363342  4662 net.cpp:226] ip2 needs backward computation.
I0526 23:12:08.363353  4662 net.cpp:226] drop1 needs backward computation.
I0526 23:12:08.363361  4662 net.cpp:226] relu5 needs backward computation.
I0526 23:12:08.363371  4662 net.cpp:226] ip1 needs backward computation.
I0526 23:12:08.363381  4662 net.cpp:226] pool4 needs backward computation.
I0526 23:12:08.363392  4662 net.cpp:226] relu4 needs backward computation.
I0526 23:12:08.363401  4662 net.cpp:226] conv4 needs backward computation.
I0526 23:12:08.363412  4662 net.cpp:226] pool3 needs backward computation.
I0526 23:12:08.363423  4662 net.cpp:226] relu3 needs backward computation.
I0526 23:12:08.363433  4662 net.cpp:226] conv3 needs backward computation.
I0526 23:12:08.363452  4662 net.cpp:226] pool2 needs backward computation.
I0526 23:12:08.363463  4662 net.cpp:226] relu2 needs backward computation.
I0526 23:12:08.363474  4662 net.cpp:226] conv2 needs backward computation.
I0526 23:12:08.363487  4662 net.cpp:226] pool1 needs backward computation.
I0526 23:12:08.363497  4662 net.cpp:226] relu1 needs backward computation.
I0526 23:12:08.363507  4662 net.cpp:226] conv1 needs backward computation.
I0526 23:12:08.363517  4662 net.cpp:228] data_hdf5 does not need backward computation.
I0526 23:12:08.363528  4662 net.cpp:270] This network produces output loss
I0526 23:12:08.363553  4662 net.cpp:283] Network initialization done.
I0526 23:12:08.365290  4662 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382.prototxt
I0526 23:12:08.365362  4662 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 23:12:08.365717  4662 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 23:12:08.365906  4662 layer_factory.hpp:77] Creating layer data_hdf5
I0526 23:12:08.365921  4662 net.cpp:106] Creating Layer data_hdf5
I0526 23:12:08.365934  4662 net.cpp:411] data_hdf5 -> data
I0526 23:12:08.365952  4662 net.cpp:411] data_hdf5 -> label
I0526 23:12:08.365967  4662 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 23:12:08.378806  4662 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 23:12:29.724269  4662 net.cpp:150] Setting up data_hdf5
I0526 23:12:29.724434  4662 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0526 23:12:29.724448  4662 net.cpp:157] Top shape: 30 (30)
I0526 23:12:29.724459  4662 net.cpp:165] Memory required for data: 762120
I0526 23:12:29.724472  4662 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 23:12:29.724501  4662 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 23:12:29.724514  4662 net.cpp:454] label_data_hdf5_1_split <- label
I0526 23:12:29.724529  4662 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 23:12:29.724550  4662 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 23:12:29.724622  4662 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 23:12:29.724635  4662 net.cpp:157] Top shape: 30 (30)
I0526 23:12:29.724647  4662 net.cpp:157] Top shape: 30 (30)
I0526 23:12:29.724658  4662 net.cpp:165] Memory required for data: 762360
I0526 23:12:29.724668  4662 layer_factory.hpp:77] Creating layer conv1
I0526 23:12:29.724687  4662 net.cpp:106] Creating Layer conv1
I0526 23:12:29.724699  4662 net.cpp:454] conv1 <- data
I0526 23:12:29.724712  4662 net.cpp:411] conv1 -> conv1
I0526 23:12:29.726672  4662 net.cpp:150] Setting up conv1
I0526 23:12:29.726696  4662 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0526 23:12:29.726708  4662 net.cpp:165] Memory required for data: 9056760
I0526 23:12:29.726729  4662 layer_factory.hpp:77] Creating layer relu1
I0526 23:12:29.726744  4662 net.cpp:106] Creating Layer relu1
I0526 23:12:29.726753  4662 net.cpp:454] relu1 <- conv1
I0526 23:12:29.726766  4662 net.cpp:397] relu1 -> conv1 (in-place)
I0526 23:12:29.727268  4662 net.cpp:150] Setting up relu1
I0526 23:12:29.727284  4662 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0526 23:12:29.727295  4662 net.cpp:165] Memory required for data: 17351160
I0526 23:12:29.727305  4662 layer_factory.hpp:77] Creating layer pool1
I0526 23:12:29.727321  4662 net.cpp:106] Creating Layer pool1
I0526 23:12:29.727331  4662 net.cpp:454] pool1 <- conv1
I0526 23:12:29.727344  4662 net.cpp:411] pool1 -> pool1
I0526 23:12:29.727418  4662 net.cpp:150] Setting up pool1
I0526 23:12:29.727432  4662 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0526 23:12:29.727442  4662 net.cpp:165] Memory required for data: 21498360
I0526 23:12:29.727452  4662 layer_factory.hpp:77] Creating layer conv2
I0526 23:12:29.727469  4662 net.cpp:106] Creating Layer conv2
I0526 23:12:29.727480  4662 net.cpp:454] conv2 <- pool1
I0526 23:12:29.727494  4662 net.cpp:411] conv2 -> conv2
I0526 23:12:29.729408  4662 net.cpp:150] Setting up conv2
I0526 23:12:29.729430  4662 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0526 23:12:29.729444  4662 net.cpp:165] Memory required for data: 27459960
I0526 23:12:29.729461  4662 layer_factory.hpp:77] Creating layer relu2
I0526 23:12:29.729475  4662 net.cpp:106] Creating Layer relu2
I0526 23:12:29.729485  4662 net.cpp:454] relu2 <- conv2
I0526 23:12:29.729497  4662 net.cpp:397] relu2 -> conv2 (in-place)
I0526 23:12:29.729830  4662 net.cpp:150] Setting up relu2
I0526 23:12:29.729843  4662 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0526 23:12:29.729853  4662 net.cpp:165] Memory required for data: 33421560
I0526 23:12:29.729863  4662 layer_factory.hpp:77] Creating layer pool2
I0526 23:12:29.729877  4662 net.cpp:106] Creating Layer pool2
I0526 23:12:29.729887  4662 net.cpp:454] pool2 <- conv2
I0526 23:12:29.729899  4662 net.cpp:411] pool2 -> pool2
I0526 23:12:29.729971  4662 net.cpp:150] Setting up pool2
I0526 23:12:29.729984  4662 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0526 23:12:29.729995  4662 net.cpp:165] Memory required for data: 36402360
I0526 23:12:29.730005  4662 layer_factory.hpp:77] Creating layer conv3
I0526 23:12:29.730024  4662 net.cpp:106] Creating Layer conv3
I0526 23:12:29.730036  4662 net.cpp:454] conv3 <- pool2
I0526 23:12:29.730048  4662 net.cpp:411] conv3 -> conv3
I0526 23:12:29.732022  4662 net.cpp:150] Setting up conv3
I0526 23:12:29.732044  4662 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0526 23:12:29.732056  4662 net.cpp:165] Memory required for data: 39654840
I0526 23:12:29.732089  4662 layer_factory.hpp:77] Creating layer relu3
I0526 23:12:29.732103  4662 net.cpp:106] Creating Layer relu3
I0526 23:12:29.732113  4662 net.cpp:454] relu3 <- conv3
I0526 23:12:29.732126  4662 net.cpp:397] relu3 -> conv3 (in-place)
I0526 23:12:29.732602  4662 net.cpp:150] Setting up relu3
I0526 23:12:29.732619  4662 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0526 23:12:29.732630  4662 net.cpp:165] Memory required for data: 42907320
I0526 23:12:29.732640  4662 layer_factory.hpp:77] Creating layer pool3
I0526 23:12:29.732651  4662 net.cpp:106] Creating Layer pool3
I0526 23:12:29.732661  4662 net.cpp:454] pool3 <- conv3
I0526 23:12:29.732674  4662 net.cpp:411] pool3 -> pool3
I0526 23:12:29.732745  4662 net.cpp:150] Setting up pool3
I0526 23:12:29.732759  4662 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0526 23:12:29.732769  4662 net.cpp:165] Memory required for data: 44533560
I0526 23:12:29.732776  4662 layer_factory.hpp:77] Creating layer conv4
I0526 23:12:29.732795  4662 net.cpp:106] Creating Layer conv4
I0526 23:12:29.732805  4662 net.cpp:454] conv4 <- pool3
I0526 23:12:29.732820  4662 net.cpp:411] conv4 -> conv4
I0526 23:12:29.734881  4662 net.cpp:150] Setting up conv4
I0526 23:12:29.734904  4662 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0526 23:12:29.734915  4662 net.cpp:165] Memory required for data: 45622200
I0526 23:12:29.734931  4662 layer_factory.hpp:77] Creating layer relu4
I0526 23:12:29.734944  4662 net.cpp:106] Creating Layer relu4
I0526 23:12:29.734954  4662 net.cpp:454] relu4 <- conv4
I0526 23:12:29.734968  4662 net.cpp:397] relu4 -> conv4 (in-place)
I0526 23:12:29.735437  4662 net.cpp:150] Setting up relu4
I0526 23:12:29.735452  4662 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0526 23:12:29.735463  4662 net.cpp:165] Memory required for data: 46710840
I0526 23:12:29.735473  4662 layer_factory.hpp:77] Creating layer pool4
I0526 23:12:29.735486  4662 net.cpp:106] Creating Layer pool4
I0526 23:12:29.735496  4662 net.cpp:454] pool4 <- conv4
I0526 23:12:29.735509  4662 net.cpp:411] pool4 -> pool4
I0526 23:12:29.735581  4662 net.cpp:150] Setting up pool4
I0526 23:12:29.735595  4662 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0526 23:12:29.735605  4662 net.cpp:165] Memory required for data: 47255160
I0526 23:12:29.735613  4662 layer_factory.hpp:77] Creating layer ip1
I0526 23:12:29.735630  4662 net.cpp:106] Creating Layer ip1
I0526 23:12:29.735640  4662 net.cpp:454] ip1 <- pool4
I0526 23:12:29.735653  4662 net.cpp:411] ip1 -> ip1
I0526 23:12:29.750995  4662 net.cpp:150] Setting up ip1
I0526 23:12:29.751024  4662 net.cpp:157] Top shape: 30 196 (5880)
I0526 23:12:29.751034  4662 net.cpp:165] Memory required for data: 47278680
I0526 23:12:29.751056  4662 layer_factory.hpp:77] Creating layer relu5
I0526 23:12:29.751071  4662 net.cpp:106] Creating Layer relu5
I0526 23:12:29.751081  4662 net.cpp:454] relu5 <- ip1
I0526 23:12:29.751094  4662 net.cpp:397] relu5 -> ip1 (in-place)
I0526 23:12:29.751442  4662 net.cpp:150] Setting up relu5
I0526 23:12:29.751457  4662 net.cpp:157] Top shape: 30 196 (5880)
I0526 23:12:29.751466  4662 net.cpp:165] Memory required for data: 47302200
I0526 23:12:29.751477  4662 layer_factory.hpp:77] Creating layer drop1
I0526 23:12:29.751495  4662 net.cpp:106] Creating Layer drop1
I0526 23:12:29.751505  4662 net.cpp:454] drop1 <- ip1
I0526 23:12:29.751518  4662 net.cpp:397] drop1 -> ip1 (in-place)
I0526 23:12:29.751564  4662 net.cpp:150] Setting up drop1
I0526 23:12:29.751579  4662 net.cpp:157] Top shape: 30 196 (5880)
I0526 23:12:29.751588  4662 net.cpp:165] Memory required for data: 47325720
I0526 23:12:29.751597  4662 layer_factory.hpp:77] Creating layer ip2
I0526 23:12:29.751611  4662 net.cpp:106] Creating Layer ip2
I0526 23:12:29.751621  4662 net.cpp:454] ip2 <- ip1
I0526 23:12:29.751636  4662 net.cpp:411] ip2 -> ip2
I0526 23:12:29.752117  4662 net.cpp:150] Setting up ip2
I0526 23:12:29.752130  4662 net.cpp:157] Top shape: 30 98 (2940)
I0526 23:12:29.752140  4662 net.cpp:165] Memory required for data: 47337480
I0526 23:12:29.752156  4662 layer_factory.hpp:77] Creating layer relu6
I0526 23:12:29.752180  4662 net.cpp:106] Creating Layer relu6
I0526 23:12:29.752190  4662 net.cpp:454] relu6 <- ip2
I0526 23:12:29.752203  4662 net.cpp:397] relu6 -> ip2 (in-place)
I0526 23:12:29.752742  4662 net.cpp:150] Setting up relu6
I0526 23:12:29.752758  4662 net.cpp:157] Top shape: 30 98 (2940)
I0526 23:12:29.752768  4662 net.cpp:165] Memory required for data: 47349240
I0526 23:12:29.752779  4662 layer_factory.hpp:77] Creating layer drop2
I0526 23:12:29.752792  4662 net.cpp:106] Creating Layer drop2
I0526 23:12:29.752802  4662 net.cpp:454] drop2 <- ip2
I0526 23:12:29.752815  4662 net.cpp:397] drop2 -> ip2 (in-place)
I0526 23:12:29.752861  4662 net.cpp:150] Setting up drop2
I0526 23:12:29.752873  4662 net.cpp:157] Top shape: 30 98 (2940)
I0526 23:12:29.752883  4662 net.cpp:165] Memory required for data: 47361000
I0526 23:12:29.752892  4662 layer_factory.hpp:77] Creating layer ip3
I0526 23:12:29.752907  4662 net.cpp:106] Creating Layer ip3
I0526 23:12:29.752917  4662 net.cpp:454] ip3 <- ip2
I0526 23:12:29.752930  4662 net.cpp:411] ip3 -> ip3
I0526 23:12:29.753156  4662 net.cpp:150] Setting up ip3
I0526 23:12:29.753170  4662 net.cpp:157] Top shape: 30 11 (330)
I0526 23:12:29.753180  4662 net.cpp:165] Memory required for data: 47362320
I0526 23:12:29.753196  4662 layer_factory.hpp:77] Creating layer drop3
I0526 23:12:29.753207  4662 net.cpp:106] Creating Layer drop3
I0526 23:12:29.753217  4662 net.cpp:454] drop3 <- ip3
I0526 23:12:29.753229  4662 net.cpp:397] drop3 -> ip3 (in-place)
I0526 23:12:29.753271  4662 net.cpp:150] Setting up drop3
I0526 23:12:29.753284  4662 net.cpp:157] Top shape: 30 11 (330)
I0526 23:12:29.753294  4662 net.cpp:165] Memory required for data: 47363640
I0526 23:12:29.753304  4662 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 23:12:29.753317  4662 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 23:12:29.753327  4662 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 23:12:29.753340  4662 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 23:12:29.753355  4662 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 23:12:29.753429  4662 net.cpp:150] Setting up ip3_drop3_0_split
I0526 23:12:29.753443  4662 net.cpp:157] Top shape: 30 11 (330)
I0526 23:12:29.753455  4662 net.cpp:157] Top shape: 30 11 (330)
I0526 23:12:29.753465  4662 net.cpp:165] Memory required for data: 47366280
I0526 23:12:29.753475  4662 layer_factory.hpp:77] Creating layer accuracy
I0526 23:12:29.753496  4662 net.cpp:106] Creating Layer accuracy
I0526 23:12:29.753506  4662 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 23:12:29.753518  4662 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 23:12:29.753531  4662 net.cpp:411] accuracy -> accuracy
I0526 23:12:29.753556  4662 net.cpp:150] Setting up accuracy
I0526 23:12:29.753568  4662 net.cpp:157] Top shape: (1)
I0526 23:12:29.753578  4662 net.cpp:165] Memory required for data: 47366284
I0526 23:12:29.753588  4662 layer_factory.hpp:77] Creating layer loss
I0526 23:12:29.753602  4662 net.cpp:106] Creating Layer loss
I0526 23:12:29.753612  4662 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 23:12:29.753623  4662 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 23:12:29.753636  4662 net.cpp:411] loss -> loss
I0526 23:12:29.753654  4662 layer_factory.hpp:77] Creating layer loss
I0526 23:12:29.754142  4662 net.cpp:150] Setting up loss
I0526 23:12:29.754156  4662 net.cpp:157] Top shape: (1)
I0526 23:12:29.754165  4662 net.cpp:160]     with loss weight 1
I0526 23:12:29.754184  4662 net.cpp:165] Memory required for data: 47366288
I0526 23:12:29.754194  4662 net.cpp:226] loss needs backward computation.
I0526 23:12:29.754205  4662 net.cpp:228] accuracy does not need backward computation.
I0526 23:12:29.754216  4662 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 23:12:29.754226  4662 net.cpp:226] drop3 needs backward computation.
I0526 23:12:29.754237  4662 net.cpp:226] ip3 needs backward computation.
I0526 23:12:29.754248  4662 net.cpp:226] drop2 needs backward computation.
I0526 23:12:29.754257  4662 net.cpp:226] relu6 needs backward computation.
I0526 23:12:29.754276  4662 net.cpp:226] ip2 needs backward computation.
I0526 23:12:29.754287  4662 net.cpp:226] drop1 needs backward computation.
I0526 23:12:29.754297  4662 net.cpp:226] relu5 needs backward computation.
I0526 23:12:29.754305  4662 net.cpp:226] ip1 needs backward computation.
I0526 23:12:29.754315  4662 net.cpp:226] pool4 needs backward computation.
I0526 23:12:29.754326  4662 net.cpp:226] relu4 needs backward computation.
I0526 23:12:29.754336  4662 net.cpp:226] conv4 needs backward computation.
I0526 23:12:29.754344  4662 net.cpp:226] pool3 needs backward computation.
I0526 23:12:29.754355  4662 net.cpp:226] relu3 needs backward computation.
I0526 23:12:29.754366  4662 net.cpp:226] conv3 needs backward computation.
I0526 23:12:29.754376  4662 net.cpp:226] pool2 needs backward computation.
I0526 23:12:29.754386  4662 net.cpp:226] relu2 needs backward computation.
I0526 23:12:29.754396  4662 net.cpp:226] conv2 needs backward computation.
I0526 23:12:29.754406  4662 net.cpp:226] pool1 needs backward computation.
I0526 23:12:29.754417  4662 net.cpp:226] relu1 needs backward computation.
I0526 23:12:29.754427  4662 net.cpp:226] conv1 needs backward computation.
I0526 23:12:29.754438  4662 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 23:12:29.754451  4662 net.cpp:228] data_hdf5 does not need backward computation.
I0526 23:12:29.754461  4662 net.cpp:270] This network produces output accuracy
I0526 23:12:29.754472  4662 net.cpp:270] This network produces output loss
I0526 23:12:29.754499  4662 net.cpp:283] Network initialization done.
I0526 23:12:29.754638  4662 solver.cpp:60] Solver scaffolding done.
I0526 23:12:29.755779  4662 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_210000.solverstate
I0526 23:12:29.975469  4662 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 23:12:29.980947  4662 caffe.cpp:212] Starting Optimization
I0526 23:12:29.980985  4662 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 23:12:29.980996  4662 solver.cpp:289] Learning Rate Policy: fixed
I0526 23:12:29.982372  4662 solver.cpp:341] Iteration 210000, Testing net (#0)
I0526 23:13:20.538918  4662 solver.cpp:409]     Test net output #0: accuracy = 0.893087
I0526 23:13:20.539079  4662 solver.cpp:409]     Test net output #1: loss = 0.330255 (* 1 = 0.330255 loss)
I0526 23:13:20.560065  4662 solver.cpp:237] Iteration 210000, loss = 0.859244
I0526 23:13:20.560101  4662 solver.cpp:253]     Train net output #0: loss = 0.859244 (* 1 = 0.859244 loss)
I0526 23:13:20.560119  4662 sgd_solver.cpp:106] Iteration 210000, lr = 0.001
I0526 23:13:31.097173  4662 solver.cpp:237] Iteration 210500, loss = 1.10417
I0526 23:13:31.097223  4662 solver.cpp:253]     Train net output #0: loss = 1.10417 (* 1 = 1.10417 loss)
I0526 23:13:31.097236  4662 sgd_solver.cpp:106] Iteration 210500, lr = 0.001
I0526 23:13:41.644013  4662 solver.cpp:237] Iteration 211000, loss = 1.04112
I0526 23:13:41.644048  4662 solver.cpp:253]     Train net output #0: loss = 1.04112 (* 1 = 1.04112 loss)
I0526 23:13:41.644062  4662 sgd_solver.cpp:106] Iteration 211000, lr = 0.001
I0526 23:13:52.183125  4662 solver.cpp:237] Iteration 211500, loss = 1.30603
I0526 23:13:52.183272  4662 solver.cpp:253]     Train net output #0: loss = 1.30603 (* 1 = 1.30603 loss)
I0526 23:13:52.183289  4662 sgd_solver.cpp:106] Iteration 211500, lr = 0.001
I0526 23:14:02.739156  4662 solver.cpp:237] Iteration 212000, loss = 1.12705
I0526 23:14:02.739203  4662 solver.cpp:253]     Train net output #0: loss = 1.12705 (* 1 = 1.12705 loss)
I0526 23:14:02.739220  4662 sgd_solver.cpp:106] Iteration 212000, lr = 0.001
I0526 23:14:13.292143  4662 solver.cpp:237] Iteration 212500, loss = 1.15321
I0526 23:14:13.292178  4662 solver.cpp:253]     Train net output #0: loss = 1.15321 (* 1 = 1.15321 loss)
I0526 23:14:13.292196  4662 sgd_solver.cpp:106] Iteration 212500, lr = 0.001
I0526 23:14:23.838636  4662 solver.cpp:237] Iteration 213000, loss = 1.55142
I0526 23:14:23.838789  4662 solver.cpp:253]     Train net output #0: loss = 1.55142 (* 1 = 1.55142 loss)
I0526 23:14:23.838804  4662 sgd_solver.cpp:106] Iteration 213000, lr = 0.001
I0526 23:14:56.570632  4662 solver.cpp:237] Iteration 213500, loss = 1.17821
I0526 23:14:56.570796  4662 solver.cpp:253]     Train net output #0: loss = 1.17821 (* 1 = 1.17821 loss)
I0526 23:14:56.570811  4662 sgd_solver.cpp:106] Iteration 213500, lr = 0.001
I0526 23:15:07.108624  4662 solver.cpp:237] Iteration 214000, loss = 0.901463
I0526 23:15:07.108660  4662 solver.cpp:253]     Train net output #0: loss = 0.901462 (* 1 = 0.901462 loss)
I0526 23:15:07.108677  4662 sgd_solver.cpp:106] Iteration 214000, lr = 0.001
I0526 23:15:17.663534  4662 solver.cpp:237] Iteration 214500, loss = 1.46969
I0526 23:15:17.663580  4662 solver.cpp:253]     Train net output #0: loss = 1.46969 (* 1 = 1.46969 loss)
I0526 23:15:17.663594  4662 sgd_solver.cpp:106] Iteration 214500, lr = 0.001
I0526 23:15:28.185549  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_215000.caffemodel
I0526 23:15:28.240047  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_215000.solverstate
I0526 23:15:28.273730  4662 solver.cpp:237] Iteration 215000, loss = 0.93879
I0526 23:15:28.273780  4662 solver.cpp:253]     Train net output #0: loss = 0.93879 (* 1 = 0.93879 loss)
I0526 23:15:28.273794  4662 sgd_solver.cpp:106] Iteration 215000, lr = 0.001
I0526 23:15:38.829581  4662 solver.cpp:237] Iteration 215500, loss = 1.41756
I0526 23:15:38.829627  4662 solver.cpp:253]     Train net output #0: loss = 1.41756 (* 1 = 1.41756 loss)
I0526 23:15:38.829643  4662 sgd_solver.cpp:106] Iteration 215500, lr = 0.001
I0526 23:15:49.387214  4662 solver.cpp:237] Iteration 216000, loss = 0.993771
I0526 23:15:49.387251  4662 solver.cpp:253]     Train net output #0: loss = 0.993771 (* 1 = 0.993771 loss)
I0526 23:15:49.387264  4662 sgd_solver.cpp:106] Iteration 216000, lr = 0.001
I0526 23:15:59.953517  4662 solver.cpp:237] Iteration 216500, loss = 1.30408
I0526 23:15:59.953663  4662 solver.cpp:253]     Train net output #0: loss = 1.30408 (* 1 = 1.30408 loss)
I0526 23:15:59.953678  4662 sgd_solver.cpp:106] Iteration 216500, lr = 0.001
I0526 23:16:32.611845  4662 solver.cpp:237] Iteration 217000, loss = 1.10569
I0526 23:16:32.612020  4662 solver.cpp:253]     Train net output #0: loss = 1.10569 (* 1 = 1.10569 loss)
I0526 23:16:32.612035  4662 sgd_solver.cpp:106] Iteration 217000, lr = 0.001
I0526 23:16:43.173748  4662 solver.cpp:237] Iteration 217500, loss = 1.13917
I0526 23:16:43.173784  4662 solver.cpp:253]     Train net output #0: loss = 1.13917 (* 1 = 1.13917 loss)
I0526 23:16:43.173800  4662 sgd_solver.cpp:106] Iteration 217500, lr = 0.001
I0526 23:16:53.729739  4662 solver.cpp:237] Iteration 218000, loss = 1.08914
I0526 23:16:53.729789  4662 solver.cpp:253]     Train net output #0: loss = 1.08914 (* 1 = 1.08914 loss)
I0526 23:16:53.729804  4662 sgd_solver.cpp:106] Iteration 218000, lr = 0.001
I0526 23:17:04.247567  4662 solver.cpp:237] Iteration 218500, loss = 1.15454
I0526 23:17:04.247709  4662 solver.cpp:253]     Train net output #0: loss = 1.15454 (* 1 = 1.15454 loss)
I0526 23:17:04.247723  4662 sgd_solver.cpp:106] Iteration 218500, lr = 0.001
I0526 23:17:14.762614  4662 solver.cpp:237] Iteration 219000, loss = 1.26473
I0526 23:17:14.762661  4662 solver.cpp:253]     Train net output #0: loss = 1.26472 (* 1 = 1.26472 loss)
I0526 23:17:14.762676  4662 sgd_solver.cpp:106] Iteration 219000, lr = 0.001
I0526 23:17:25.285550  4662 solver.cpp:237] Iteration 219500, loss = 1.1802
I0526 23:17:25.285586  4662 solver.cpp:253]     Train net output #0: loss = 1.1802 (* 1 = 1.1802 loss)
I0526 23:17:25.285604  4662 sgd_solver.cpp:106] Iteration 219500, lr = 0.001
I0526 23:17:35.796965  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_220000.caffemodel
I0526 23:17:35.851104  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_220000.solverstate
I0526 23:17:35.877847  4662 solver.cpp:341] Iteration 220000, Testing net (#0)
I0526 23:18:25.496937  4662 solver.cpp:409]     Test net output #0: accuracy = 0.893959
I0526 23:18:25.497097  4662 solver.cpp:409]     Test net output #1: loss = 0.335942 (* 1 = 0.335942 loss)
I0526 23:18:47.659529  4662 solver.cpp:237] Iteration 220000, loss = 1.06317
I0526 23:18:47.659579  4662 solver.cpp:253]     Train net output #0: loss = 1.06317 (* 1 = 1.06317 loss)
I0526 23:18:47.659596  4662 sgd_solver.cpp:106] Iteration 220000, lr = 0.001
I0526 23:18:58.144425  4662 solver.cpp:237] Iteration 220500, loss = 1.15514
I0526 23:18:58.144585  4662 solver.cpp:253]     Train net output #0: loss = 1.15514 (* 1 = 1.15514 loss)
I0526 23:18:58.144601  4662 sgd_solver.cpp:106] Iteration 220500, lr = 0.001
I0526 23:19:08.631059  4662 solver.cpp:237] Iteration 221000, loss = 0.95276
I0526 23:19:08.631095  4662 solver.cpp:253]     Train net output #0: loss = 0.95276 (* 1 = 0.95276 loss)
I0526 23:19:08.631109  4662 sgd_solver.cpp:106] Iteration 221000, lr = 0.001
I0526 23:19:19.132611  4662 solver.cpp:237] Iteration 221500, loss = 1.37911
I0526 23:19:19.132647  4662 solver.cpp:253]     Train net output #0: loss = 1.37911 (* 1 = 1.37911 loss)
I0526 23:19:19.132660  4662 sgd_solver.cpp:106] Iteration 221500, lr = 0.001
I0526 23:19:29.635324  4662 solver.cpp:237] Iteration 222000, loss = 1.27208
I0526 23:19:29.635473  4662 solver.cpp:253]     Train net output #0: loss = 1.27208 (* 1 = 1.27208 loss)
I0526 23:19:29.635488  4662 sgd_solver.cpp:106] Iteration 222000, lr = 0.001
I0526 23:19:40.143589  4662 solver.cpp:237] Iteration 222500, loss = 1.21472
I0526 23:19:40.143625  4662 solver.cpp:253]     Train net output #0: loss = 1.21472 (* 1 = 1.21472 loss)
I0526 23:19:40.143642  4662 sgd_solver.cpp:106] Iteration 222500, lr = 0.001
I0526 23:19:50.642590  4662 solver.cpp:237] Iteration 223000, loss = 0.820931
I0526 23:19:50.642642  4662 solver.cpp:253]     Train net output #0: loss = 0.820931 (* 1 = 0.820931 loss)
I0526 23:19:50.642657  4662 sgd_solver.cpp:106] Iteration 223000, lr = 0.001
I0526 23:20:23.329455  4662 solver.cpp:237] Iteration 223500, loss = 1.26707
I0526 23:20:23.329630  4662 solver.cpp:253]     Train net output #0: loss = 1.26707 (* 1 = 1.26707 loss)
I0526 23:20:23.329644  4662 sgd_solver.cpp:106] Iteration 223500, lr = 0.001
I0526 23:20:33.827781  4662 solver.cpp:237] Iteration 224000, loss = 1.25406
I0526 23:20:33.827817  4662 solver.cpp:253]     Train net output #0: loss = 1.25406 (* 1 = 1.25406 loss)
I0526 23:20:33.827831  4662 sgd_solver.cpp:106] Iteration 224000, lr = 0.001
I0526 23:20:44.330443  4662 solver.cpp:237] Iteration 224500, loss = 1.34701
I0526 23:20:44.330490  4662 solver.cpp:253]     Train net output #0: loss = 1.34701 (* 1 = 1.34701 loss)
I0526 23:20:44.330504  4662 sgd_solver.cpp:106] Iteration 224500, lr = 0.001
I0526 23:20:54.823781  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_225000.caffemodel
I0526 23:20:54.878787  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_225000.solverstate
I0526 23:20:54.913352  4662 solver.cpp:237] Iteration 225000, loss = 1.27003
I0526 23:20:54.913401  4662 solver.cpp:253]     Train net output #0: loss = 1.27003 (* 1 = 1.27003 loss)
I0526 23:20:54.913417  4662 sgd_solver.cpp:106] Iteration 225000, lr = 0.001
I0526 23:21:05.433909  4662 solver.cpp:237] Iteration 225500, loss = 1.28687
I0526 23:21:05.433959  4662 solver.cpp:253]     Train net output #0: loss = 1.28687 (* 1 = 1.28687 loss)
I0526 23:21:05.433974  4662 sgd_solver.cpp:106] Iteration 225500, lr = 0.001
I0526 23:21:15.952185  4662 solver.cpp:237] Iteration 226000, loss = 0.996016
I0526 23:21:15.952221  4662 solver.cpp:253]     Train net output #0: loss = 0.996016 (* 1 = 0.996016 loss)
I0526 23:21:15.952235  4662 sgd_solver.cpp:106] Iteration 226000, lr = 0.001
I0526 23:21:26.468394  4662 solver.cpp:237] Iteration 226500, loss = 1.56008
I0526 23:21:26.468550  4662 solver.cpp:253]     Train net output #0: loss = 1.56008 (* 1 = 1.56008 loss)
I0526 23:21:26.468565  4662 sgd_solver.cpp:106] Iteration 226500, lr = 0.001
I0526 23:21:59.221343  4662 solver.cpp:237] Iteration 227000, loss = 1.02591
I0526 23:21:59.221503  4662 solver.cpp:253]     Train net output #0: loss = 1.02591 (* 1 = 1.02591 loss)
I0526 23:21:59.221518  4662 sgd_solver.cpp:106] Iteration 227000, lr = 0.001
I0526 23:22:09.804750  4662 solver.cpp:237] Iteration 227500, loss = 1.31655
I0526 23:22:09.804785  4662 solver.cpp:253]     Train net output #0: loss = 1.31655 (* 1 = 1.31655 loss)
I0526 23:22:09.804800  4662 sgd_solver.cpp:106] Iteration 227500, lr = 0.001
I0526 23:22:20.386803  4662 solver.cpp:237] Iteration 228000, loss = 1.18904
I0526 23:22:20.386847  4662 solver.cpp:253]     Train net output #0: loss = 1.18904 (* 1 = 1.18904 loss)
I0526 23:22:20.386860  4662 sgd_solver.cpp:106] Iteration 228000, lr = 0.001
I0526 23:22:30.964473  4662 solver.cpp:237] Iteration 228500, loss = 0.730207
I0526 23:22:30.964622  4662 solver.cpp:253]     Train net output #0: loss = 0.730207 (* 1 = 0.730207 loss)
I0526 23:22:30.964637  4662 sgd_solver.cpp:106] Iteration 228500, lr = 0.001
I0526 23:22:41.544600  4662 solver.cpp:237] Iteration 229000, loss = 1.4422
I0526 23:22:41.544646  4662 solver.cpp:253]     Train net output #0: loss = 1.4422 (* 1 = 1.4422 loss)
I0526 23:22:41.544658  4662 sgd_solver.cpp:106] Iteration 229000, lr = 0.001
I0526 23:22:52.115422  4662 solver.cpp:237] Iteration 229500, loss = 0.822478
I0526 23:22:52.115458  4662 solver.cpp:253]     Train net output #0: loss = 0.822478 (* 1 = 0.822478 loss)
I0526 23:22:52.115473  4662 sgd_solver.cpp:106] Iteration 229500, lr = 0.001
I0526 23:23:02.692592  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_230000.caffemodel
I0526 23:23:02.748471  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_230000.solverstate
I0526 23:23:02.776232  4662 solver.cpp:341] Iteration 230000, Testing net (#0)
I0526 23:24:13.232219  4662 solver.cpp:409]     Test net output #0: accuracy = 0.894692
I0526 23:24:13.232393  4662 solver.cpp:409]     Test net output #1: loss = 0.348207 (* 1 = 0.348207 loss)
I0526 23:24:35.386327  4662 solver.cpp:237] Iteration 230000, loss = 1.15568
I0526 23:24:35.386381  4662 solver.cpp:253]     Train net output #0: loss = 1.15568 (* 1 = 1.15568 loss)
I0526 23:24:35.386399  4662 sgd_solver.cpp:106] Iteration 230000, lr = 0.001
I0526 23:24:45.910966  4662 solver.cpp:237] Iteration 230500, loss = 0.845994
I0526 23:24:45.911123  4662 solver.cpp:253]     Train net output #0: loss = 0.845994 (* 1 = 0.845994 loss)
I0526 23:24:45.911139  4662 sgd_solver.cpp:106] Iteration 230500, lr = 0.001
I0526 23:24:56.437507  4662 solver.cpp:237] Iteration 231000, loss = 1.54772
I0526 23:24:56.437542  4662 solver.cpp:253]     Train net output #0: loss = 1.54772 (* 1 = 1.54772 loss)
I0526 23:24:56.437556  4662 sgd_solver.cpp:106] Iteration 231000, lr = 0.001
I0526 23:25:06.961585  4662 solver.cpp:237] Iteration 231500, loss = 0.938921
I0526 23:25:06.961621  4662 solver.cpp:253]     Train net output #0: loss = 0.938921 (* 1 = 0.938921 loss)
I0526 23:25:06.961635  4662 sgd_solver.cpp:106] Iteration 231500, lr = 0.001
I0526 23:25:17.502084  4662 solver.cpp:237] Iteration 232000, loss = 1.33936
I0526 23:25:17.502228  4662 solver.cpp:253]     Train net output #0: loss = 1.33936 (* 1 = 1.33936 loss)
I0526 23:25:17.502243  4662 sgd_solver.cpp:106] Iteration 232000, lr = 0.001
I0526 23:25:28.030243  4662 solver.cpp:237] Iteration 232500, loss = 0.943007
I0526 23:25:28.030280  4662 solver.cpp:253]     Train net output #0: loss = 0.943007 (* 1 = 0.943007 loss)
I0526 23:25:28.030293  4662 sgd_solver.cpp:106] Iteration 232500, lr = 0.001
I0526 23:25:38.557714  4662 solver.cpp:237] Iteration 233000, loss = 1.23448
I0526 23:25:38.557759  4662 solver.cpp:253]     Train net output #0: loss = 1.23447 (* 1 = 1.23447 loss)
I0526 23:25:38.557771  4662 sgd_solver.cpp:106] Iteration 233000, lr = 0.001
I0526 23:26:11.306880  4662 solver.cpp:237] Iteration 233500, loss = 1.10131
I0526 23:26:11.307049  4662 solver.cpp:253]     Train net output #0: loss = 1.10131 (* 1 = 1.10131 loss)
I0526 23:26:11.307065  4662 sgd_solver.cpp:106] Iteration 233500, lr = 0.001
I0526 23:26:21.833458  4662 solver.cpp:237] Iteration 234000, loss = 1.36546
I0526 23:26:21.833494  4662 solver.cpp:253]     Train net output #0: loss = 1.36546 (* 1 = 1.36546 loss)
I0526 23:26:21.833510  4662 sgd_solver.cpp:106] Iteration 234000, lr = 0.001
I0526 23:26:32.361116  4662 solver.cpp:237] Iteration 234500, loss = 0.929826
I0526 23:26:32.361163  4662 solver.cpp:253]     Train net output #0: loss = 0.929826 (* 1 = 0.929826 loss)
I0526 23:26:32.361177  4662 sgd_solver.cpp:106] Iteration 234500, lr = 0.001
I0526 23:26:42.874722  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_235000.caffemodel
I0526 23:26:42.930613  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_235000.solverstate
I0526 23:26:42.965528  4662 solver.cpp:237] Iteration 235000, loss = 1.39836
I0526 23:26:42.965577  4662 solver.cpp:253]     Train net output #0: loss = 1.39836 (* 1 = 1.39836 loss)
I0526 23:26:42.965591  4662 sgd_solver.cpp:106] Iteration 235000, lr = 0.001
I0526 23:26:53.498114  4662 solver.cpp:237] Iteration 235500, loss = 1.38162
I0526 23:26:53.498162  4662 solver.cpp:253]     Train net output #0: loss = 1.38162 (* 1 = 1.38162 loss)
I0526 23:26:53.498175  4662 sgd_solver.cpp:106] Iteration 235500, lr = 0.001
I0526 23:27:04.028316  4662 solver.cpp:237] Iteration 236000, loss = 1.40473
I0526 23:27:04.028353  4662 solver.cpp:253]     Train net output #0: loss = 1.40473 (* 1 = 1.40473 loss)
I0526 23:27:04.028367  4662 sgd_solver.cpp:106] Iteration 236000, lr = 0.001
I0526 23:27:14.561795  4662 solver.cpp:237] Iteration 236500, loss = 1.13604
I0526 23:27:14.561971  4662 solver.cpp:253]     Train net output #0: loss = 1.13604 (* 1 = 1.13604 loss)
I0526 23:27:14.561985  4662 sgd_solver.cpp:106] Iteration 236500, lr = 0.001
I0526 23:27:47.272897  4662 solver.cpp:237] Iteration 237000, loss = 1.13684
I0526 23:27:47.273059  4662 solver.cpp:253]     Train net output #0: loss = 1.13684 (* 1 = 1.13684 loss)
I0526 23:27:47.273073  4662 sgd_solver.cpp:106] Iteration 237000, lr = 0.001
I0526 23:27:57.783133  4662 solver.cpp:237] Iteration 237500, loss = 1.15439
I0526 23:27:57.783169  4662 solver.cpp:253]     Train net output #0: loss = 1.15439 (* 1 = 1.15439 loss)
I0526 23:27:57.783182  4662 sgd_solver.cpp:106] Iteration 237500, lr = 0.001
I0526 23:28:08.305491  4662 solver.cpp:237] Iteration 238000, loss = 1.43369
I0526 23:28:08.305538  4662 solver.cpp:253]     Train net output #0: loss = 1.43369 (* 1 = 1.43369 loss)
I0526 23:28:08.305552  4662 sgd_solver.cpp:106] Iteration 238000, lr = 0.001
I0526 23:28:18.830646  4662 solver.cpp:237] Iteration 238500, loss = 0.940116
I0526 23:28:18.830790  4662 solver.cpp:253]     Train net output #0: loss = 0.940116 (* 1 = 0.940116 loss)
I0526 23:28:18.830806  4662 sgd_solver.cpp:106] Iteration 238500, lr = 0.001
I0526 23:28:29.349901  4662 solver.cpp:237] Iteration 239000, loss = 0.878612
I0526 23:28:29.349954  4662 solver.cpp:253]     Train net output #0: loss = 0.878612 (* 1 = 0.878612 loss)
I0526 23:28:29.349967  4662 sgd_solver.cpp:106] Iteration 239000, lr = 0.001
I0526 23:28:39.850699  4662 solver.cpp:237] Iteration 239500, loss = 1.01025
I0526 23:28:39.850735  4662 solver.cpp:253]     Train net output #0: loss = 1.01025 (* 1 = 1.01025 loss)
I0526 23:28:39.850749  4662 sgd_solver.cpp:106] Iteration 239500, lr = 0.001
I0526 23:28:50.326128  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_240000.caffemodel
I0526 23:28:50.378772  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_240000.solverstate
I0526 23:28:50.404441  4662 solver.cpp:341] Iteration 240000, Testing net (#0)
I0526 23:29:39.693409  4662 solver.cpp:409]     Test net output #0: accuracy = 0.895952
I0526 23:29:39.693573  4662 solver.cpp:409]     Test net output #1: loss = 0.325922 (* 1 = 0.325922 loss)
I0526 23:30:01.905055  4662 solver.cpp:237] Iteration 240000, loss = 1.00988
I0526 23:30:01.905109  4662 solver.cpp:253]     Train net output #0: loss = 1.00988 (* 1 = 1.00988 loss)
I0526 23:30:01.905124  4662 sgd_solver.cpp:106] Iteration 240000, lr = 0.001
I0526 23:30:12.462299  4662 solver.cpp:237] Iteration 240500, loss = 0.989255
I0526 23:30:12.462465  4662 solver.cpp:253]     Train net output #0: loss = 0.989255 (* 1 = 0.989255 loss)
I0526 23:30:12.462481  4662 sgd_solver.cpp:106] Iteration 240500, lr = 0.001
I0526 23:30:23.020190  4662 solver.cpp:237] Iteration 241000, loss = 1.23144
I0526 23:30:23.020226  4662 solver.cpp:253]     Train net output #0: loss = 1.23144 (* 1 = 1.23144 loss)
I0526 23:30:23.020242  4662 sgd_solver.cpp:106] Iteration 241000, lr = 0.001
I0526 23:30:33.582495  4662 solver.cpp:237] Iteration 241500, loss = 1.25895
I0526 23:30:33.582531  4662 solver.cpp:253]     Train net output #0: loss = 1.25895 (* 1 = 1.25895 loss)
I0526 23:30:33.582547  4662 sgd_solver.cpp:106] Iteration 241500, lr = 0.001
I0526 23:30:44.157515  4662 solver.cpp:237] Iteration 242000, loss = 1.2438
I0526 23:30:44.157671  4662 solver.cpp:253]     Train net output #0: loss = 1.2438 (* 1 = 1.2438 loss)
I0526 23:30:44.157687  4662 sgd_solver.cpp:106] Iteration 242000, lr = 0.001
I0526 23:30:54.731112  4662 solver.cpp:237] Iteration 242500, loss = 0.861344
I0526 23:30:54.731148  4662 solver.cpp:253]     Train net output #0: loss = 0.861344 (* 1 = 0.861344 loss)
I0526 23:30:54.731161  4662 sgd_solver.cpp:106] Iteration 242500, lr = 0.001
I0526 23:31:05.290942  4662 solver.cpp:237] Iteration 243000, loss = 1.04772
I0526 23:31:05.290985  4662 solver.cpp:253]     Train net output #0: loss = 1.04772 (* 1 = 1.04772 loss)
I0526 23:31:05.290998  4662 sgd_solver.cpp:106] Iteration 243000, lr = 0.001
I0526 23:31:38.023666  4662 solver.cpp:237] Iteration 243500, loss = 1.63661
I0526 23:31:38.023844  4662 solver.cpp:253]     Train net output #0: loss = 1.63661 (* 1 = 1.63661 loss)
I0526 23:31:38.023859  4662 sgd_solver.cpp:106] Iteration 243500, lr = 0.001
I0526 23:31:48.581063  4662 solver.cpp:237] Iteration 244000, loss = 1.08858
I0526 23:31:48.581097  4662 solver.cpp:253]     Train net output #0: loss = 1.08858 (* 1 = 1.08858 loss)
I0526 23:31:48.581110  4662 sgd_solver.cpp:106] Iteration 244000, lr = 0.001
I0526 23:31:59.136617  4662 solver.cpp:237] Iteration 244500, loss = 1.35403
I0526 23:31:59.136662  4662 solver.cpp:253]     Train net output #0: loss = 1.35403 (* 1 = 1.35403 loss)
I0526 23:31:59.136678  4662 sgd_solver.cpp:106] Iteration 244500, lr = 0.001
I0526 23:32:09.677104  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_245000.caffemodel
I0526 23:32:09.729902  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_245000.solverstate
I0526 23:32:09.762258  4662 solver.cpp:237] Iteration 245000, loss = 1.37902
I0526 23:32:09.762302  4662 solver.cpp:253]     Train net output #0: loss = 1.37902 (* 1 = 1.37902 loss)
I0526 23:32:09.762320  4662 sgd_solver.cpp:106] Iteration 245000, lr = 0.001
I0526 23:32:20.325059  4662 solver.cpp:237] Iteration 245500, loss = 0.91608
I0526 23:32:20.325105  4662 solver.cpp:253]     Train net output #0: loss = 0.91608 (* 1 = 0.91608 loss)
I0526 23:32:20.325122  4662 sgd_solver.cpp:106] Iteration 245500, lr = 0.001
I0526 23:32:30.900688  4662 solver.cpp:237] Iteration 246000, loss = 0.855399
I0526 23:32:30.900724  4662 solver.cpp:253]     Train net output #0: loss = 0.855399 (* 1 = 0.855399 loss)
I0526 23:32:30.900743  4662 sgd_solver.cpp:106] Iteration 246000, lr = 0.001
I0526 23:32:41.470859  4662 solver.cpp:237] Iteration 246500, loss = 1.19459
I0526 23:32:41.471017  4662 solver.cpp:253]     Train net output #0: loss = 1.19459 (* 1 = 1.19459 loss)
I0526 23:32:41.471031  4662 sgd_solver.cpp:106] Iteration 246500, lr = 0.001
I0526 23:33:14.264780  4662 solver.cpp:237] Iteration 247000, loss = 0.908621
I0526 23:33:14.264950  4662 solver.cpp:253]     Train net output #0: loss = 0.908622 (* 1 = 0.908622 loss)
I0526 23:33:14.264966  4662 sgd_solver.cpp:106] Iteration 247000, lr = 0.001
I0526 23:33:24.810720  4662 solver.cpp:237] Iteration 247500, loss = 1.28031
I0526 23:33:24.810756  4662 solver.cpp:253]     Train net output #0: loss = 1.28032 (* 1 = 1.28032 loss)
I0526 23:33:24.810770  4662 sgd_solver.cpp:106] Iteration 247500, lr = 0.001
I0526 23:33:35.365270  4662 solver.cpp:237] Iteration 248000, loss = 1.37037
I0526 23:33:35.365320  4662 solver.cpp:253]     Train net output #0: loss = 1.37037 (* 1 = 1.37037 loss)
I0526 23:33:35.365336  4662 sgd_solver.cpp:106] Iteration 248000, lr = 0.001
I0526 23:33:45.929989  4662 solver.cpp:237] Iteration 248500, loss = 0.943899
I0526 23:33:45.930133  4662 solver.cpp:253]     Train net output #0: loss = 0.9439 (* 1 = 0.9439 loss)
I0526 23:33:45.930148  4662 sgd_solver.cpp:106] Iteration 248500, lr = 0.001
I0526 23:33:56.481884  4662 solver.cpp:237] Iteration 249000, loss = 1.21587
I0526 23:33:56.481928  4662 solver.cpp:253]     Train net output #0: loss = 1.21588 (* 1 = 1.21588 loss)
I0526 23:33:56.481943  4662 sgd_solver.cpp:106] Iteration 249000, lr = 0.001
I0526 23:34:07.045716  4662 solver.cpp:237] Iteration 249500, loss = 1.22078
I0526 23:34:07.045750  4662 solver.cpp:253]     Train net output #0: loss = 1.22078 (* 1 = 1.22078 loss)
I0526 23:34:07.045768  4662 sgd_solver.cpp:106] Iteration 249500, lr = 0.001
I0526 23:34:17.594521  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_250000.caffemodel
I0526 23:34:17.648211  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_250000.solverstate
I0526 23:34:17.673687  4662 solver.cpp:341] Iteration 250000, Testing net (#0)
I0526 23:35:28.079833  4662 solver.cpp:409]     Test net output #0: accuracy = 0.894865
I0526 23:35:28.080000  4662 solver.cpp:409]     Test net output #1: loss = 0.331413 (* 1 = 0.331413 loss)
I0526 23:35:50.334271  4662 solver.cpp:237] Iteration 250000, loss = 1.58674
I0526 23:35:50.334326  4662 solver.cpp:253]     Train net output #0: loss = 1.58674 (* 1 = 1.58674 loss)
I0526 23:35:50.334342  4662 sgd_solver.cpp:106] Iteration 250000, lr = 0.001
I0526 23:36:00.931196  4662 solver.cpp:237] Iteration 250500, loss = 0.955548
I0526 23:36:00.931361  4662 solver.cpp:253]     Train net output #0: loss = 0.955549 (* 1 = 0.955549 loss)
I0526 23:36:00.931376  4662 sgd_solver.cpp:106] Iteration 250500, lr = 0.001
I0526 23:36:11.546257  4662 solver.cpp:237] Iteration 251000, loss = 0.940012
I0526 23:36:11.546293  4662 solver.cpp:253]     Train net output #0: loss = 0.940012 (* 1 = 0.940012 loss)
I0526 23:36:11.546306  4662 sgd_solver.cpp:106] Iteration 251000, lr = 0.001
I0526 23:36:22.127517  4662 solver.cpp:237] Iteration 251500, loss = 0.928954
I0526 23:36:22.127553  4662 solver.cpp:253]     Train net output #0: loss = 0.928954 (* 1 = 0.928954 loss)
I0526 23:36:22.127568  4662 sgd_solver.cpp:106] Iteration 251500, lr = 0.001
I0526 23:36:32.719933  4662 solver.cpp:237] Iteration 252000, loss = 1.33885
I0526 23:36:32.720087  4662 solver.cpp:253]     Train net output #0: loss = 1.33885 (* 1 = 1.33885 loss)
I0526 23:36:32.720100  4662 sgd_solver.cpp:106] Iteration 252000, lr = 0.001
I0526 23:36:43.321743  4662 solver.cpp:237] Iteration 252500, loss = 1.26486
I0526 23:36:43.321779  4662 solver.cpp:253]     Train net output #0: loss = 1.26486 (* 1 = 1.26486 loss)
I0526 23:36:43.321792  4662 sgd_solver.cpp:106] Iteration 252500, lr = 0.001
I0526 23:36:53.922513  4662 solver.cpp:237] Iteration 253000, loss = 0.710809
I0526 23:36:53.922556  4662 solver.cpp:253]     Train net output #0: loss = 0.71081 (* 1 = 0.71081 loss)
I0526 23:36:53.922572  4662 sgd_solver.cpp:106] Iteration 253000, lr = 0.001
I0526 23:37:26.708683  4662 solver.cpp:237] Iteration 253500, loss = 1.28509
I0526 23:37:26.708852  4662 solver.cpp:253]     Train net output #0: loss = 1.28509 (* 1 = 1.28509 loss)
I0526 23:37:26.708865  4662 sgd_solver.cpp:106] Iteration 253500, lr = 0.001
I0526 23:37:37.293537  4662 solver.cpp:237] Iteration 254000, loss = 1.27658
I0526 23:37:37.293572  4662 solver.cpp:253]     Train net output #0: loss = 1.27658 (* 1 = 1.27658 loss)
I0526 23:37:37.293589  4662 sgd_solver.cpp:106] Iteration 254000, lr = 0.001
I0526 23:37:47.850204  4662 solver.cpp:237] Iteration 254500, loss = 1.26254
I0526 23:37:47.850251  4662 solver.cpp:253]     Train net output #0: loss = 1.26254 (* 1 = 1.26254 loss)
I0526 23:37:47.850265  4662 sgd_solver.cpp:106] Iteration 254500, lr = 0.001
I0526 23:37:58.377784  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_255000.caffemodel
I0526 23:37:58.432992  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_255000.solverstate
I0526 23:37:58.467253  4662 solver.cpp:237] Iteration 255000, loss = 1.34756
I0526 23:37:58.467300  4662 solver.cpp:253]     Train net output #0: loss = 1.34756 (* 1 = 1.34756 loss)
I0526 23:37:58.467320  4662 sgd_solver.cpp:106] Iteration 255000, lr = 0.001
I0526 23:38:09.022574  4662 solver.cpp:237] Iteration 255500, loss = 1.16539
I0526 23:38:09.022626  4662 solver.cpp:253]     Train net output #0: loss = 1.16539 (* 1 = 1.16539 loss)
I0526 23:38:09.022641  4662 sgd_solver.cpp:106] Iteration 255500, lr = 0.001
I0526 23:38:19.573045  4662 solver.cpp:237] Iteration 256000, loss = 1.31842
I0526 23:38:19.573081  4662 solver.cpp:253]     Train net output #0: loss = 1.31842 (* 1 = 1.31842 loss)
I0526 23:38:19.573094  4662 sgd_solver.cpp:106] Iteration 256000, lr = 0.001
I0526 23:38:30.117523  4662 solver.cpp:237] Iteration 256500, loss = 1.37214
I0526 23:38:30.117703  4662 solver.cpp:253]     Train net output #0: loss = 1.37214 (* 1 = 1.37214 loss)
I0526 23:38:30.117719  4662 sgd_solver.cpp:106] Iteration 256500, lr = 0.001
I0526 23:39:02.903108  4662 solver.cpp:237] Iteration 257000, loss = 1.12723
I0526 23:39:02.903280  4662 solver.cpp:253]     Train net output #0: loss = 1.12723 (* 1 = 1.12723 loss)
I0526 23:39:02.903295  4662 sgd_solver.cpp:106] Iteration 257000, lr = 0.001
I0526 23:39:13.513244  4662 solver.cpp:237] Iteration 257500, loss = 1.43443
I0526 23:39:13.513280  4662 solver.cpp:253]     Train net output #0: loss = 1.43443 (* 1 = 1.43443 loss)
I0526 23:39:13.513298  4662 sgd_solver.cpp:106] Iteration 257500, lr = 0.001
I0526 23:39:24.125331  4662 solver.cpp:237] Iteration 258000, loss = 1.16606
I0526 23:39:24.125375  4662 solver.cpp:253]     Train net output #0: loss = 1.16606 (* 1 = 1.16606 loss)
I0526 23:39:24.125392  4662 sgd_solver.cpp:106] Iteration 258000, lr = 0.001
I0526 23:39:34.729285  4662 solver.cpp:237] Iteration 258500, loss = 1.07719
I0526 23:39:34.729441  4662 solver.cpp:253]     Train net output #0: loss = 1.07719 (* 1 = 1.07719 loss)
I0526 23:39:34.729455  4662 sgd_solver.cpp:106] Iteration 258500, lr = 0.001
I0526 23:39:45.332728  4662 solver.cpp:237] Iteration 259000, loss = 1.00452
I0526 23:39:45.332777  4662 solver.cpp:253]     Train net output #0: loss = 1.00452 (* 1 = 1.00452 loss)
I0526 23:39:45.332792  4662 sgd_solver.cpp:106] Iteration 259000, lr = 0.001
I0526 23:39:55.926461  4662 solver.cpp:237] Iteration 259500, loss = 1.37472
I0526 23:39:55.926496  4662 solver.cpp:253]     Train net output #0: loss = 1.37472 (* 1 = 1.37472 loss)
I0526 23:39:55.926513  4662 sgd_solver.cpp:106] Iteration 259500, lr = 0.001
I0526 23:40:06.501696  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_260000.caffemodel
I0526 23:40:06.556478  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_260000.solverstate
I0526 23:40:06.584332  4662 solver.cpp:341] Iteration 260000, Testing net (#0)
I0526 23:40:56.163283  4662 solver.cpp:409]     Test net output #0: accuracy = 0.894012
I0526 23:40:56.163444  4662 solver.cpp:409]     Test net output #1: loss = 0.341338 (* 1 = 0.341338 loss)
I0526 23:41:17.027529  4662 solver.cpp:237] Iteration 260000, loss = 0.751206
I0526 23:41:17.027585  4662 solver.cpp:253]     Train net output #0: loss = 0.751206 (* 1 = 0.751206 loss)
I0526 23:41:17.027600  4662 sgd_solver.cpp:106] Iteration 260000, lr = 0.001
I0526 23:41:27.595541  4662 solver.cpp:237] Iteration 260500, loss = 0.852689
I0526 23:41:27.595705  4662 solver.cpp:253]     Train net output #0: loss = 0.852689 (* 1 = 0.852689 loss)
I0526 23:41:27.595721  4662 sgd_solver.cpp:106] Iteration 260500, lr = 0.001
I0526 23:41:38.154238  4662 solver.cpp:237] Iteration 261000, loss = 0.984592
I0526 23:41:38.154275  4662 solver.cpp:253]     Train net output #0: loss = 0.984592 (* 1 = 0.984592 loss)
I0526 23:41:38.154289  4662 sgd_solver.cpp:106] Iteration 261000, lr = 0.001
I0526 23:41:48.712283  4662 solver.cpp:237] Iteration 261500, loss = 1.33839
I0526 23:41:48.712319  4662 solver.cpp:253]     Train net output #0: loss = 1.33839 (* 1 = 1.33839 loss)
I0526 23:41:48.712337  4662 sgd_solver.cpp:106] Iteration 261500, lr = 0.001
I0526 23:41:59.266309  4662 solver.cpp:237] Iteration 262000, loss = 0.941689
I0526 23:41:59.266475  4662 solver.cpp:253]     Train net output #0: loss = 0.941689 (* 1 = 0.941689 loss)
I0526 23:41:59.266490  4662 sgd_solver.cpp:106] Iteration 262000, lr = 0.001
I0526 23:42:09.820920  4662 solver.cpp:237] Iteration 262500, loss = 0.993046
I0526 23:42:09.820957  4662 solver.cpp:253]     Train net output #0: loss = 0.993046 (* 1 = 0.993046 loss)
I0526 23:42:09.820973  4662 sgd_solver.cpp:106] Iteration 262500, lr = 0.001
I0526 23:42:20.385424  4662 solver.cpp:237] Iteration 263000, loss = 1.43206
I0526 23:42:20.385469  4662 solver.cpp:253]     Train net output #0: loss = 1.43206 (* 1 = 1.43206 loss)
I0526 23:42:20.385486  4662 sgd_solver.cpp:106] Iteration 263000, lr = 0.001
I0526 23:42:51.807184  4662 solver.cpp:237] Iteration 263500, loss = 0.935778
I0526 23:42:51.807355  4662 solver.cpp:253]     Train net output #0: loss = 0.935778 (* 1 = 0.935778 loss)
I0526 23:42:51.807371  4662 sgd_solver.cpp:106] Iteration 263500, lr = 0.001
I0526 23:43:02.351652  4662 solver.cpp:237] Iteration 264000, loss = 1.01524
I0526 23:43:02.351687  4662 solver.cpp:253]     Train net output #0: loss = 1.01524 (* 1 = 1.01524 loss)
I0526 23:43:02.351701  4662 sgd_solver.cpp:106] Iteration 264000, lr = 0.001
I0526 23:43:12.909054  4662 solver.cpp:237] Iteration 264500, loss = 1.73692
I0526 23:43:12.909101  4662 solver.cpp:253]     Train net output #0: loss = 1.73692 (* 1 = 1.73692 loss)
I0526 23:43:12.909116  4662 sgd_solver.cpp:106] Iteration 264500, lr = 0.001
I0526 23:43:23.445585  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_265000.caffemodel
I0526 23:43:23.499441  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_265000.solverstate
I0526 23:43:23.531726  4662 solver.cpp:237] Iteration 265000, loss = 1.32187
I0526 23:43:23.531769  4662 solver.cpp:253]     Train net output #0: loss = 1.32187 (* 1 = 1.32187 loss)
I0526 23:43:23.531790  4662 sgd_solver.cpp:106] Iteration 265000, lr = 0.001
I0526 23:43:34.091990  4662 solver.cpp:237] Iteration 265500, loss = 1.18895
I0526 23:43:34.092036  4662 solver.cpp:253]     Train net output #0: loss = 1.18895 (* 1 = 1.18895 loss)
I0526 23:43:34.092052  4662 sgd_solver.cpp:106] Iteration 265500, lr = 0.001
I0526 23:43:44.646631  4662 solver.cpp:237] Iteration 266000, loss = 1.26919
I0526 23:43:44.646666  4662 solver.cpp:253]     Train net output #0: loss = 1.26919 (* 1 = 1.26919 loss)
I0526 23:43:44.646679  4662 sgd_solver.cpp:106] Iteration 266000, lr = 0.001
I0526 23:43:55.199154  4662 solver.cpp:237] Iteration 266500, loss = 0.877135
I0526 23:43:55.199316  4662 solver.cpp:253]     Train net output #0: loss = 0.877135 (* 1 = 0.877135 loss)
I0526 23:43:55.199333  4662 sgd_solver.cpp:106] Iteration 266500, lr = 0.001
I0526 23:44:26.651769  4662 solver.cpp:237] Iteration 267000, loss = 1.15676
I0526 23:44:26.651937  4662 solver.cpp:253]     Train net output #0: loss = 1.15676 (* 1 = 1.15676 loss)
I0526 23:44:26.651952  4662 sgd_solver.cpp:106] Iteration 267000, lr = 0.001
I0526 23:44:37.216531  4662 solver.cpp:237] Iteration 267500, loss = 0.999632
I0526 23:44:37.216567  4662 solver.cpp:253]     Train net output #0: loss = 0.999633 (* 1 = 0.999633 loss)
I0526 23:44:37.216581  4662 sgd_solver.cpp:106] Iteration 267500, lr = 0.001
I0526 23:44:47.763567  4662 solver.cpp:237] Iteration 268000, loss = 1.43171
I0526 23:44:47.763613  4662 solver.cpp:253]     Train net output #0: loss = 1.43171 (* 1 = 1.43171 loss)
I0526 23:44:47.763627  4662 sgd_solver.cpp:106] Iteration 268000, lr = 0.001
I0526 23:44:58.321097  4662 solver.cpp:237] Iteration 268500, loss = 0.924571
I0526 23:44:58.321265  4662 solver.cpp:253]     Train net output #0: loss = 0.924571 (* 1 = 0.924571 loss)
I0526 23:44:58.321280  4662 sgd_solver.cpp:106] Iteration 268500, lr = 0.001
I0526 23:45:08.887753  4662 solver.cpp:237] Iteration 269000, loss = 1.28289
I0526 23:45:08.887786  4662 solver.cpp:253]     Train net output #0: loss = 1.28289 (* 1 = 1.28289 loss)
I0526 23:45:08.887801  4662 sgd_solver.cpp:106] Iteration 269000, lr = 0.001
I0526 23:45:19.429390  4662 solver.cpp:237] Iteration 269500, loss = 1.17389
I0526 23:45:19.429435  4662 solver.cpp:253]     Train net output #0: loss = 1.17389 (* 1 = 1.17389 loss)
I0526 23:45:19.429450  4662 sgd_solver.cpp:106] Iteration 269500, lr = 0.001
I0526 23:45:29.964360  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_270000.caffemodel
I0526 23:45:30.017292  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_270000.solverstate
I0526 23:45:30.042788  4662 solver.cpp:341] Iteration 270000, Testing net (#0)
I0526 23:46:40.386375  4662 solver.cpp:409]     Test net output #0: accuracy = 0.896793
I0526 23:46:40.386539  4662 solver.cpp:409]     Test net output #1: loss = 0.324417 (* 1 = 0.324417 loss)
I0526 23:47:01.229485  4662 solver.cpp:237] Iteration 270000, loss = 1.23133
I0526 23:47:01.229537  4662 solver.cpp:253]     Train net output #0: loss = 1.23133 (* 1 = 1.23133 loss)
I0526 23:47:01.229554  4662 sgd_solver.cpp:106] Iteration 270000, lr = 0.001
I0526 23:47:11.745051  4662 solver.cpp:237] Iteration 270500, loss = 1.12674
I0526 23:47:11.745208  4662 solver.cpp:253]     Train net output #0: loss = 1.12674 (* 1 = 1.12674 loss)
I0526 23:47:11.745221  4662 sgd_solver.cpp:106] Iteration 270500, lr = 0.001
I0526 23:47:22.260143  4662 solver.cpp:237] Iteration 271000, loss = 1.20418
I0526 23:47:22.260190  4662 solver.cpp:253]     Train net output #0: loss = 1.20418 (* 1 = 1.20418 loss)
I0526 23:47:22.260205  4662 sgd_solver.cpp:106] Iteration 271000, lr = 0.001
I0526 23:47:32.778867  4662 solver.cpp:237] Iteration 271500, loss = 1.28138
I0526 23:47:32.778903  4662 solver.cpp:253]     Train net output #0: loss = 1.28138 (* 1 = 1.28138 loss)
I0526 23:47:32.778916  4662 sgd_solver.cpp:106] Iteration 271500, lr = 0.001
I0526 23:47:43.295799  4662 solver.cpp:237] Iteration 272000, loss = 1.48194
I0526 23:47:43.295969  4662 solver.cpp:253]     Train net output #0: loss = 1.48194 (* 1 = 1.48194 loss)
I0526 23:47:43.295985  4662 sgd_solver.cpp:106] Iteration 272000, lr = 0.001
I0526 23:47:53.818348  4662 solver.cpp:237] Iteration 272500, loss = 1.17694
I0526 23:47:53.818383  4662 solver.cpp:253]     Train net output #0: loss = 1.17694 (* 1 = 1.17694 loss)
I0526 23:47:53.818397  4662 sgd_solver.cpp:106] Iteration 272500, lr = 0.001
I0526 23:48:04.333171  4662 solver.cpp:237] Iteration 273000, loss = 1.1948
I0526 23:48:04.333209  4662 solver.cpp:253]     Train net output #0: loss = 1.1948 (* 1 = 1.1948 loss)
I0526 23:48:04.333226  4662 sgd_solver.cpp:106] Iteration 273000, lr = 0.001
I0526 23:48:35.719463  4662 solver.cpp:237] Iteration 273500, loss = 1.12845
I0526 23:48:35.719630  4662 solver.cpp:253]     Train net output #0: loss = 1.12845 (* 1 = 1.12845 loss)
I0526 23:48:35.719645  4662 sgd_solver.cpp:106] Iteration 273500, lr = 0.001
I0526 23:48:46.234699  4662 solver.cpp:237] Iteration 274000, loss = 0.996313
I0526 23:48:46.234735  4662 solver.cpp:253]     Train net output #0: loss = 0.996313 (* 1 = 0.996313 loss)
I0526 23:48:46.234750  4662 sgd_solver.cpp:106] Iteration 274000, lr = 0.001
I0526 23:48:56.751458  4662 solver.cpp:237] Iteration 274500, loss = 1.21789
I0526 23:48:56.751505  4662 solver.cpp:253]     Train net output #0: loss = 1.21789 (* 1 = 1.21789 loss)
I0526 23:48:56.751520  4662 sgd_solver.cpp:106] Iteration 274500, lr = 0.001
I0526 23:49:07.240006  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_275000.caffemodel
I0526 23:49:07.292897  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_275000.solverstate
I0526 23:49:07.327742  4662 solver.cpp:237] Iteration 275000, loss = 0.943077
I0526 23:49:07.327791  4662 solver.cpp:253]     Train net output #0: loss = 0.943077 (* 1 = 0.943077 loss)
I0526 23:49:07.327811  4662 sgd_solver.cpp:106] Iteration 275000, lr = 0.001
I0526 23:49:17.853662  4662 solver.cpp:237] Iteration 275500, loss = 1.02815
I0526 23:49:17.853698  4662 solver.cpp:253]     Train net output #0: loss = 1.02815 (* 1 = 1.02815 loss)
I0526 23:49:17.853715  4662 sgd_solver.cpp:106] Iteration 275500, lr = 0.001
I0526 23:49:28.378947  4662 solver.cpp:237] Iteration 276000, loss = 1.14616
I0526 23:49:28.378998  4662 solver.cpp:253]     Train net output #0: loss = 1.14616 (* 1 = 1.14616 loss)
I0526 23:49:28.379012  4662 sgd_solver.cpp:106] Iteration 276000, lr = 0.001
I0526 23:49:38.883929  4662 solver.cpp:237] Iteration 276500, loss = 0.90686
I0526 23:49:38.884083  4662 solver.cpp:253]     Train net output #0: loss = 0.90686 (* 1 = 0.90686 loss)
I0526 23:49:38.884096  4662 sgd_solver.cpp:106] Iteration 276500, lr = 0.001
I0526 23:50:10.294111  4662 solver.cpp:237] Iteration 277000, loss = 1.11258
I0526 23:50:10.294283  4662 solver.cpp:253]     Train net output #0: loss = 1.11258 (* 1 = 1.11258 loss)
I0526 23:50:10.294297  4662 sgd_solver.cpp:106] Iteration 277000, lr = 0.001
I0526 23:50:20.830193  4662 solver.cpp:237] Iteration 277500, loss = 1.20465
I0526 23:50:20.830229  4662 solver.cpp:253]     Train net output #0: loss = 1.20465 (* 1 = 1.20465 loss)
I0526 23:50:20.830242  4662 sgd_solver.cpp:106] Iteration 277500, lr = 0.001
I0526 23:50:31.344140  4662 solver.cpp:237] Iteration 278000, loss = 1.41239
I0526 23:50:31.344174  4662 solver.cpp:253]     Train net output #0: loss = 1.41239 (* 1 = 1.41239 loss)
I0526 23:50:31.344188  4662 sgd_solver.cpp:106] Iteration 278000, lr = 0.001
I0526 23:50:41.848989  4662 solver.cpp:237] Iteration 278500, loss = 1.05214
I0526 23:50:41.849148  4662 solver.cpp:253]     Train net output #0: loss = 1.05214 (* 1 = 1.05214 loss)
I0526 23:50:41.849164  4662 sgd_solver.cpp:106] Iteration 278500, lr = 0.001
I0526 23:50:52.361858  4662 solver.cpp:237] Iteration 279000, loss = 1.09833
I0526 23:50:52.361893  4662 solver.cpp:253]     Train net output #0: loss = 1.09833 (* 1 = 1.09833 loss)
I0526 23:50:52.361910  4662 sgd_solver.cpp:106] Iteration 279000, lr = 0.001
I0526 23:51:02.865973  4662 solver.cpp:237] Iteration 279500, loss = 0.912542
I0526 23:51:02.866024  4662 solver.cpp:253]     Train net output #0: loss = 0.912542 (* 1 = 0.912542 loss)
I0526 23:51:02.866039  4662 sgd_solver.cpp:106] Iteration 279500, lr = 0.001
I0526 23:51:13.338917  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_280000.caffemodel
I0526 23:51:13.392303  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_280000.solverstate
I0526 23:51:13.418999  4662 solver.cpp:341] Iteration 280000, Testing net (#0)
I0526 23:52:02.714906  4662 solver.cpp:409]     Test net output #0: accuracy = 0.895207
I0526 23:52:02.715075  4662 solver.cpp:409]     Test net output #1: loss = 0.343454 (* 1 = 0.343454 loss)
I0526 23:52:23.593206  4662 solver.cpp:237] Iteration 280000, loss = 0.736764
I0526 23:52:23.593261  4662 solver.cpp:253]     Train net output #0: loss = 0.736764 (* 1 = 0.736764 loss)
I0526 23:52:23.593276  4662 sgd_solver.cpp:106] Iteration 280000, lr = 0.001
I0526 23:52:34.253386  4662 solver.cpp:237] Iteration 280500, loss = 1.17398
I0526 23:52:34.253547  4662 solver.cpp:253]     Train net output #0: loss = 1.17398 (* 1 = 1.17398 loss)
I0526 23:52:34.253561  4662 sgd_solver.cpp:106] Iteration 280500, lr = 0.001
I0526 23:52:44.899561  4662 solver.cpp:237] Iteration 281000, loss = 1.63343
I0526 23:52:44.899607  4662 solver.cpp:253]     Train net output #0: loss = 1.63343 (* 1 = 1.63343 loss)
I0526 23:52:44.899623  4662 sgd_solver.cpp:106] Iteration 281000, lr = 0.001
I0526 23:52:55.562499  4662 solver.cpp:237] Iteration 281500, loss = 1.23421
I0526 23:52:55.562535  4662 solver.cpp:253]     Train net output #0: loss = 1.23421 (* 1 = 1.23421 loss)
I0526 23:52:55.562551  4662 sgd_solver.cpp:106] Iteration 281500, lr = 0.001
I0526 23:53:06.206059  4662 solver.cpp:237] Iteration 282000, loss = 1.25644
I0526 23:53:06.206236  4662 solver.cpp:253]     Train net output #0: loss = 1.25644 (* 1 = 1.25644 loss)
I0526 23:53:06.206251  4662 sgd_solver.cpp:106] Iteration 282000, lr = 0.001
I0526 23:53:16.791580  4662 solver.cpp:237] Iteration 282500, loss = 1.08107
I0526 23:53:16.791616  4662 solver.cpp:253]     Train net output #0: loss = 1.08107 (* 1 = 1.08107 loss)
I0526 23:53:16.791631  4662 sgd_solver.cpp:106] Iteration 282500, lr = 0.001
I0526 23:53:27.392148  4662 solver.cpp:237] Iteration 283000, loss = 1.25349
I0526 23:53:27.392184  4662 solver.cpp:253]     Train net output #0: loss = 1.25349 (* 1 = 1.25349 loss)
I0526 23:53:27.392200  4662 sgd_solver.cpp:106] Iteration 283000, lr = 0.001
I0526 23:53:58.914592  4662 solver.cpp:237] Iteration 283500, loss = 1.29884
I0526 23:53:58.914770  4662 solver.cpp:253]     Train net output #0: loss = 1.29884 (* 1 = 1.29884 loss)
I0526 23:53:58.914786  4662 sgd_solver.cpp:106] Iteration 283500, lr = 0.001
I0526 23:54:09.512156  4662 solver.cpp:237] Iteration 284000, loss = 1.03153
I0526 23:54:09.512192  4662 solver.cpp:253]     Train net output #0: loss = 1.03153 (* 1 = 1.03153 loss)
I0526 23:54:09.512205  4662 sgd_solver.cpp:106] Iteration 284000, lr = 0.001
I0526 23:54:20.121242  4662 solver.cpp:237] Iteration 284500, loss = 0.779056
I0526 23:54:20.121290  4662 solver.cpp:253]     Train net output #0: loss = 0.779056 (* 1 = 0.779056 loss)
I0526 23:54:20.121305  4662 sgd_solver.cpp:106] Iteration 284500, lr = 0.001
I0526 23:54:30.708742  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_285000.caffemodel
I0526 23:54:30.763568  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_285000.solverstate
I0526 23:54:30.797888  4662 solver.cpp:237] Iteration 285000, loss = 1.20201
I0526 23:54:30.797940  4662 solver.cpp:253]     Train net output #0: loss = 1.20201 (* 1 = 1.20201 loss)
I0526 23:54:30.797955  4662 sgd_solver.cpp:106] Iteration 285000, lr = 0.001
I0526 23:54:41.410471  4662 solver.cpp:237] Iteration 285500, loss = 1.42007
I0526 23:54:41.410507  4662 solver.cpp:253]     Train net output #0: loss = 1.42007 (* 1 = 1.42007 loss)
I0526 23:54:41.410523  4662 sgd_solver.cpp:106] Iteration 285500, lr = 0.001
I0526 23:54:52.010735  4662 solver.cpp:237] Iteration 286000, loss = 1.01514
I0526 23:54:52.010784  4662 solver.cpp:253]     Train net output #0: loss = 1.01514 (* 1 = 1.01514 loss)
I0526 23:54:52.010800  4662 sgd_solver.cpp:106] Iteration 286000, lr = 0.001
I0526 23:55:02.618072  4662 solver.cpp:237] Iteration 286500, loss = 1.40604
I0526 23:55:02.618227  4662 solver.cpp:253]     Train net output #0: loss = 1.40604 (* 1 = 1.40604 loss)
I0526 23:55:02.618242  4662 sgd_solver.cpp:106] Iteration 286500, lr = 0.001
I0526 23:55:34.139591  4662 solver.cpp:237] Iteration 287000, loss = 0.899648
I0526 23:55:34.139767  4662 solver.cpp:253]     Train net output #0: loss = 0.899649 (* 1 = 0.899649 loss)
I0526 23:55:34.139782  4662 sgd_solver.cpp:106] Iteration 287000, lr = 0.001
I0526 23:55:44.735831  4662 solver.cpp:237] Iteration 287500, loss = 1.03773
I0526 23:55:44.735867  4662 solver.cpp:253]     Train net output #0: loss = 1.03773 (* 1 = 1.03773 loss)
I0526 23:55:44.735883  4662 sgd_solver.cpp:106] Iteration 287500, lr = 0.001
I0526 23:55:55.337574  4662 solver.cpp:237] Iteration 288000, loss = 1.29296
I0526 23:55:55.337607  4662 solver.cpp:253]     Train net output #0: loss = 1.29296 (* 1 = 1.29296 loss)
I0526 23:55:55.337626  4662 sgd_solver.cpp:106] Iteration 288000, lr = 0.001
I0526 23:56:05.943892  4662 solver.cpp:237] Iteration 288500, loss = 1.3862
I0526 23:56:05.944061  4662 solver.cpp:253]     Train net output #0: loss = 1.3862 (* 1 = 1.3862 loss)
I0526 23:56:05.944075  4662 sgd_solver.cpp:106] Iteration 288500, lr = 0.001
I0526 23:56:16.559846  4662 solver.cpp:237] Iteration 289000, loss = 1.12679
I0526 23:56:16.559882  4662 solver.cpp:253]     Train net output #0: loss = 1.12679 (* 1 = 1.12679 loss)
I0526 23:56:16.559895  4662 sgd_solver.cpp:106] Iteration 289000, lr = 0.001
I0526 23:56:27.165253  4662 solver.cpp:237] Iteration 289500, loss = 0.990774
I0526 23:56:27.165297  4662 solver.cpp:253]     Train net output #0: loss = 0.990775 (* 1 = 0.990775 loss)
I0526 23:56:27.165310  4662 sgd_solver.cpp:106] Iteration 289500, lr = 0.001
I0526 23:56:37.751164  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_290000.caffemodel
I0526 23:56:37.804142  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_290000.solverstate
I0526 23:56:37.829597  4662 solver.cpp:341] Iteration 290000, Testing net (#0)
I0526 23:57:48.228045  4662 solver.cpp:409]     Test net output #0: accuracy = 0.899753
I0526 23:57:48.228216  4662 solver.cpp:409]     Test net output #1: loss = 0.314748 (* 1 = 0.314748 loss)
I0526 23:58:09.094321  4662 solver.cpp:237] Iteration 290000, loss = 0.896927
I0526 23:58:09.094375  4662 solver.cpp:253]     Train net output #0: loss = 0.896928 (* 1 = 0.896928 loss)
I0526 23:58:09.094391  4662 sgd_solver.cpp:106] Iteration 290000, lr = 0.001
I0526 23:58:19.636426  4662 solver.cpp:237] Iteration 290500, loss = 0.831385
I0526 23:58:19.636585  4662 solver.cpp:253]     Train net output #0: loss = 0.831385 (* 1 = 0.831385 loss)
I0526 23:58:19.636600  4662 sgd_solver.cpp:106] Iteration 290500, lr = 0.001
I0526 23:58:30.161941  4662 solver.cpp:237] Iteration 291000, loss = 1.63769
I0526 23:58:30.161988  4662 solver.cpp:253]     Train net output #0: loss = 1.63769 (* 1 = 1.63769 loss)
I0526 23:58:30.162001  4662 sgd_solver.cpp:106] Iteration 291000, lr = 0.001
I0526 23:58:40.694363  4662 solver.cpp:237] Iteration 291500, loss = 1.46563
I0526 23:58:40.694398  4662 solver.cpp:253]     Train net output #0: loss = 1.46563 (* 1 = 1.46563 loss)
I0526 23:58:40.694412  4662 sgd_solver.cpp:106] Iteration 291500, lr = 0.001
I0526 23:58:51.220405  4662 solver.cpp:237] Iteration 292000, loss = 1.18663
I0526 23:58:51.220556  4662 solver.cpp:253]     Train net output #0: loss = 1.18663 (* 1 = 1.18663 loss)
I0526 23:58:51.220571  4662 sgd_solver.cpp:106] Iteration 292000, lr = 0.001
I0526 23:59:01.743749  4662 solver.cpp:237] Iteration 292500, loss = 1.21703
I0526 23:59:01.743798  4662 solver.cpp:253]     Train net output #0: loss = 1.21703 (* 1 = 1.21703 loss)
I0526 23:59:01.743811  4662 sgd_solver.cpp:106] Iteration 292500, lr = 0.001
I0526 23:59:12.274045  4662 solver.cpp:237] Iteration 293000, loss = 0.917566
I0526 23:59:12.274081  4662 solver.cpp:253]     Train net output #0: loss = 0.917566 (* 1 = 0.917566 loss)
I0526 23:59:12.274096  4662 sgd_solver.cpp:106] Iteration 293000, lr = 0.001
I0526 23:59:43.642814  4662 solver.cpp:237] Iteration 293500, loss = 1.15703
I0526 23:59:43.642987  4662 solver.cpp:253]     Train net output #0: loss = 1.15703 (* 1 = 1.15703 loss)
I0526 23:59:43.643002  4662 sgd_solver.cpp:106] Iteration 293500, lr = 0.001
I0526 23:59:54.167963  4662 solver.cpp:237] Iteration 294000, loss = 1.08519
I0526 23:59:54.168011  4662 solver.cpp:253]     Train net output #0: loss = 1.08519 (* 1 = 1.08519 loss)
I0526 23:59:54.168025  4662 sgd_solver.cpp:106] Iteration 294000, lr = 0.001
I0527 00:00:04.719475  4662 solver.cpp:237] Iteration 294500, loss = 1.25903
I0527 00:00:04.719511  4662 solver.cpp:253]     Train net output #0: loss = 1.25903 (* 1 = 1.25903 loss)
I0527 00:00:04.719527  4662 sgd_solver.cpp:106] Iteration 294500, lr = 0.001
I0527 00:00:15.232827  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_295000.caffemodel
I0527 00:00:15.286119  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_295000.solverstate
I0527 00:00:15.318070  4662 solver.cpp:237] Iteration 295000, loss = 1.26769
I0527 00:00:15.318111  4662 solver.cpp:253]     Train net output #0: loss = 1.26769 (* 1 = 1.26769 loss)
I0527 00:00:15.318125  4662 sgd_solver.cpp:106] Iteration 295000, lr = 0.001
I0527 00:00:25.860703  4662 solver.cpp:237] Iteration 295500, loss = 1.06422
I0527 00:00:25.860739  4662 solver.cpp:253]     Train net output #0: loss = 1.06422 (* 1 = 1.06422 loss)
I0527 00:00:25.860756  4662 sgd_solver.cpp:106] Iteration 295500, lr = 0.001
I0527 00:00:36.385911  4662 solver.cpp:237] Iteration 296000, loss = 1.13682
I0527 00:00:36.385959  4662 solver.cpp:253]     Train net output #0: loss = 1.13682 (* 1 = 1.13682 loss)
I0527 00:00:36.385973  4662 sgd_solver.cpp:106] Iteration 296000, lr = 0.001
I0527 00:00:46.959432  4662 solver.cpp:237] Iteration 296500, loss = 1.02073
I0527 00:00:46.959589  4662 solver.cpp:253]     Train net output #0: loss = 1.02073 (* 1 = 1.02073 loss)
I0527 00:00:46.959605  4662 sgd_solver.cpp:106] Iteration 296500, lr = 0.001
I0527 00:01:18.424093  4662 solver.cpp:237] Iteration 297000, loss = 1.58481
I0527 00:01:18.424279  4662 solver.cpp:253]     Train net output #0: loss = 1.58481 (* 1 = 1.58481 loss)
I0527 00:01:18.424295  4662 sgd_solver.cpp:106] Iteration 297000, lr = 0.001
I0527 00:01:29.016270  4662 solver.cpp:237] Iteration 297500, loss = 0.978539
I0527 00:01:29.016319  4662 solver.cpp:253]     Train net output #0: loss = 0.978539 (* 1 = 0.978539 loss)
I0527 00:01:29.016333  4662 sgd_solver.cpp:106] Iteration 297500, lr = 0.001
I0527 00:01:39.596429  4662 solver.cpp:237] Iteration 298000, loss = 1.31396
I0527 00:01:39.596465  4662 solver.cpp:253]     Train net output #0: loss = 1.31396 (* 1 = 1.31396 loss)
I0527 00:01:39.596479  4662 sgd_solver.cpp:106] Iteration 298000, lr = 0.001
I0527 00:01:50.179590  4662 solver.cpp:237] Iteration 298500, loss = 1.27814
I0527 00:01:50.179752  4662 solver.cpp:253]     Train net output #0: loss = 1.27814 (* 1 = 1.27814 loss)
I0527 00:01:50.179769  4662 sgd_solver.cpp:106] Iteration 298500, lr = 0.001
I0527 00:02:00.759135  4662 solver.cpp:237] Iteration 299000, loss = 1.35002
I0527 00:02:00.759171  4662 solver.cpp:253]     Train net output #0: loss = 1.35002 (* 1 = 1.35002 loss)
I0527 00:02:00.759188  4662 sgd_solver.cpp:106] Iteration 299000, lr = 0.001
I0527 00:02:11.337122  4662 solver.cpp:237] Iteration 299500, loss = 1.16743
I0527 00:02:11.337158  4662 solver.cpp:253]     Train net output #0: loss = 1.16743 (* 1 = 1.16743 loss)
I0527 00:02:11.337177  4662 sgd_solver.cpp:106] Iteration 299500, lr = 0.001
I0527 00:02:21.897269  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_300000.caffemodel
I0527 00:02:21.949942  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_300000.solverstate
I0527 00:02:21.975258  4662 solver.cpp:341] Iteration 300000, Testing net (#0)
I0527 00:03:11.618291  4662 solver.cpp:409]     Test net output #0: accuracy = 0.893059
I0527 00:03:11.618475  4662 solver.cpp:409]     Test net output #1: loss = 0.335621 (* 1 = 0.335621 loss)
I0527 00:03:32.502485  4662 solver.cpp:237] Iteration 300000, loss = 1.44148
I0527 00:03:32.502537  4662 solver.cpp:253]     Train net output #0: loss = 1.44148 (* 1 = 1.44148 loss)
I0527 00:03:32.502555  4662 sgd_solver.cpp:106] Iteration 300000, lr = 0.001
I0527 00:03:43.000833  4662 solver.cpp:237] Iteration 300500, loss = 1.10919
I0527 00:03:43.000993  4662 solver.cpp:253]     Train net output #0: loss = 1.10919 (* 1 = 1.10919 loss)
I0527 00:03:43.001008  4662 sgd_solver.cpp:106] Iteration 300500, lr = 0.001
I0527 00:03:53.516938  4662 solver.cpp:237] Iteration 301000, loss = 1.34244
I0527 00:03:53.516973  4662 solver.cpp:253]     Train net output #0: loss = 1.34244 (* 1 = 1.34244 loss)
I0527 00:03:53.516989  4662 sgd_solver.cpp:106] Iteration 301000, lr = 0.001
I0527 00:04:04.020956  4662 solver.cpp:237] Iteration 301500, loss = 0.818554
I0527 00:04:04.020998  4662 solver.cpp:253]     Train net output #0: loss = 0.818554 (* 1 = 0.818554 loss)
I0527 00:04:04.021014  4662 sgd_solver.cpp:106] Iteration 301500, lr = 0.001
I0527 00:04:14.526510  4662 solver.cpp:237] Iteration 302000, loss = 0.879003
I0527 00:04:14.526667  4662 solver.cpp:253]     Train net output #0: loss = 0.879003 (* 1 = 0.879003 loss)
I0527 00:04:14.526682  4662 sgd_solver.cpp:106] Iteration 302000, lr = 0.001
I0527 00:04:25.032191  4662 solver.cpp:237] Iteration 302500, loss = 1.32317
I0527 00:04:25.032232  4662 solver.cpp:253]     Train net output #0: loss = 1.32317 (* 1 = 1.32317 loss)
I0527 00:04:25.032246  4662 sgd_solver.cpp:106] Iteration 302500, lr = 0.001
I0527 00:04:35.547616  4662 solver.cpp:237] Iteration 303000, loss = 0.781969
I0527 00:04:35.547652  4662 solver.cpp:253]     Train net output #0: loss = 0.781969 (* 1 = 0.781969 loss)
I0527 00:04:35.547669  4662 sgd_solver.cpp:106] Iteration 303000, lr = 0.001
I0527 00:05:06.947641  4662 solver.cpp:237] Iteration 303500, loss = 1.15549
I0527 00:05:06.947818  4662 solver.cpp:253]     Train net output #0: loss = 1.15549 (* 1 = 1.15549 loss)
I0527 00:05:06.947834  4662 sgd_solver.cpp:106] Iteration 303500, lr = 0.001
I0527 00:05:17.515461  4662 solver.cpp:237] Iteration 304000, loss = 1.027
I0527 00:05:17.515506  4662 solver.cpp:253]     Train net output #0: loss = 1.027 (* 1 = 1.027 loss)
I0527 00:05:17.515522  4662 sgd_solver.cpp:106] Iteration 304000, lr = 0.001
I0527 00:05:28.076217  4662 solver.cpp:237] Iteration 304500, loss = 0.963813
I0527 00:05:28.076254  4662 solver.cpp:253]     Train net output #0: loss = 0.963813 (* 1 = 0.963813 loss)
I0527 00:05:28.076270  4662 sgd_solver.cpp:106] Iteration 304500, lr = 0.001
I0527 00:05:38.628847  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_305000.caffemodel
I0527 00:05:38.684877  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_305000.solverstate
I0527 00:05:38.719108  4662 solver.cpp:237] Iteration 305000, loss = 1.31678
I0527 00:05:38.719154  4662 solver.cpp:253]     Train net output #0: loss = 1.31678 (* 1 = 1.31678 loss)
I0527 00:05:38.719173  4662 sgd_solver.cpp:106] Iteration 305000, lr = 0.001
I0527 00:05:49.304636  4662 solver.cpp:237] Iteration 305500, loss = 0.994525
I0527 00:05:49.304672  4662 solver.cpp:253]     Train net output #0: loss = 0.994525 (* 1 = 0.994525 loss)
I0527 00:05:49.304687  4662 sgd_solver.cpp:106] Iteration 305500, lr = 0.001
I0527 00:05:59.854516  4662 solver.cpp:237] Iteration 306000, loss = 1.39772
I0527 00:05:59.854562  4662 solver.cpp:253]     Train net output #0: loss = 1.39773 (* 1 = 1.39773 loss)
I0527 00:05:59.854579  4662 sgd_solver.cpp:106] Iteration 306000, lr = 0.001
I0527 00:06:10.382777  4662 solver.cpp:237] Iteration 306500, loss = 1.33459
I0527 00:06:10.382935  4662 solver.cpp:253]     Train net output #0: loss = 1.33459 (* 1 = 1.33459 loss)
I0527 00:06:10.382949  4662 sgd_solver.cpp:106] Iteration 306500, lr = 0.001
I0527 00:06:41.833582  4662 solver.cpp:237] Iteration 307000, loss = 1.03927
I0527 00:06:41.833772  4662 solver.cpp:253]     Train net output #0: loss = 1.03927 (* 1 = 1.03927 loss)
I0527 00:06:41.833787  4662 sgd_solver.cpp:106] Iteration 307000, lr = 0.001
I0527 00:06:52.363536  4662 solver.cpp:237] Iteration 307500, loss = 1.48485
I0527 00:06:52.363584  4662 solver.cpp:253]     Train net output #0: loss = 1.48485 (* 1 = 1.48485 loss)
I0527 00:06:52.363600  4662 sgd_solver.cpp:106] Iteration 307500, lr = 0.001
I0527 00:07:02.891921  4662 solver.cpp:237] Iteration 308000, loss = 0.968373
I0527 00:07:02.891957  4662 solver.cpp:253]     Train net output #0: loss = 0.968373 (* 1 = 0.968373 loss)
I0527 00:07:02.891971  4662 sgd_solver.cpp:106] Iteration 308000, lr = 0.001
I0527 00:07:13.419603  4662 solver.cpp:237] Iteration 308500, loss = 1.48831
I0527 00:07:13.419759  4662 solver.cpp:253]     Train net output #0: loss = 1.48831 (* 1 = 1.48831 loss)
I0527 00:07:13.419775  4662 sgd_solver.cpp:106] Iteration 308500, lr = 0.001
I0527 00:07:23.942188  4662 solver.cpp:237] Iteration 309000, loss = 1.24601
I0527 00:07:23.942231  4662 solver.cpp:253]     Train net output #0: loss = 1.24601 (* 1 = 1.24601 loss)
I0527 00:07:23.942245  4662 sgd_solver.cpp:106] Iteration 309000, lr = 0.001
I0527 00:07:34.454448  4662 solver.cpp:237] Iteration 309500, loss = 1.49898
I0527 00:07:34.454484  4662 solver.cpp:253]     Train net output #0: loss = 1.49898 (* 1 = 1.49898 loss)
I0527 00:07:34.454499  4662 sgd_solver.cpp:106] Iteration 309500, lr = 0.001
I0527 00:07:44.952486  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_310000.caffemodel
I0527 00:07:45.007149  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_310000.solverstate
I0527 00:07:45.034821  4662 solver.cpp:341] Iteration 310000, Testing net (#0)
I0527 00:08:55.545783  4662 solver.cpp:409]     Test net output #0: accuracy = 0.896733
I0527 00:08:55.545953  4662 solver.cpp:409]     Test net output #1: loss = 0.341618 (* 1 = 0.341618 loss)
I0527 00:09:16.443435  4662 solver.cpp:237] Iteration 310000, loss = 1.13249
I0527 00:09:16.443490  4662 solver.cpp:253]     Train net output #0: loss = 1.1325 (* 1 = 1.1325 loss)
I0527 00:09:16.443505  4662 sgd_solver.cpp:106] Iteration 310000, lr = 0.001
I0527 00:09:26.987154  4662 solver.cpp:237] Iteration 310500, loss = 0.968017
I0527 00:09:26.987321  4662 solver.cpp:253]     Train net output #0: loss = 0.968018 (* 1 = 0.968018 loss)
I0527 00:09:26.987335  4662 sgd_solver.cpp:106] Iteration 310500, lr = 0.001
I0527 00:09:37.546180  4662 solver.cpp:237] Iteration 311000, loss = 1.35953
I0527 00:09:37.546216  4662 solver.cpp:253]     Train net output #0: loss = 1.35953 (* 1 = 1.35953 loss)
I0527 00:09:37.546231  4662 sgd_solver.cpp:106] Iteration 311000, lr = 0.001
I0527 00:09:48.043642  4662 solver.cpp:237] Iteration 311500, loss = 1.46209
I0527 00:09:48.043690  4662 solver.cpp:253]     Train net output #0: loss = 1.46209 (* 1 = 1.46209 loss)
I0527 00:09:48.043704  4662 sgd_solver.cpp:106] Iteration 311500, lr = 0.001
I0527 00:09:58.537438  4662 solver.cpp:237] Iteration 312000, loss = 0.945551
I0527 00:09:58.537595  4662 solver.cpp:253]     Train net output #0: loss = 0.945552 (* 1 = 0.945552 loss)
I0527 00:09:58.537609  4662 sgd_solver.cpp:106] Iteration 312000, lr = 0.001
I0527 00:10:09.043308  4662 solver.cpp:237] Iteration 312500, loss = 1.28491
I0527 00:10:09.043344  4662 solver.cpp:253]     Train net output #0: loss = 1.28491 (* 1 = 1.28491 loss)
I0527 00:10:09.043357  4662 sgd_solver.cpp:106] Iteration 312500, lr = 0.001
I0527 00:10:19.537315  4662 solver.cpp:237] Iteration 313000, loss = 1.21336
I0527 00:10:19.537361  4662 solver.cpp:253]     Train net output #0: loss = 1.21336 (* 1 = 1.21336 loss)
I0527 00:10:19.537376  4662 sgd_solver.cpp:106] Iteration 313000, lr = 0.001
I0527 00:10:50.963801  4662 solver.cpp:237] Iteration 313500, loss = 1.11579
I0527 00:10:50.963987  4662 solver.cpp:253]     Train net output #0: loss = 1.11579 (* 1 = 1.11579 loss)
I0527 00:10:50.964004  4662 sgd_solver.cpp:106] Iteration 313500, lr = 0.001
I0527 00:11:01.480293  4662 solver.cpp:237] Iteration 314000, loss = 0.960572
I0527 00:11:01.480345  4662 solver.cpp:253]     Train net output #0: loss = 0.960573 (* 1 = 0.960573 loss)
I0527 00:11:01.480358  4662 sgd_solver.cpp:106] Iteration 314000, lr = 0.001
I0527 00:11:12.022655  4662 solver.cpp:237] Iteration 314500, loss = 1.11513
I0527 00:11:12.022691  4662 solver.cpp:253]     Train net output #0: loss = 1.11513 (* 1 = 1.11513 loss)
I0527 00:11:12.022704  4662 sgd_solver.cpp:106] Iteration 314500, lr = 0.001
I0527 00:11:22.547246  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_315000.caffemodel
I0527 00:11:22.599773  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_315000.solverstate
I0527 00:11:22.631842  4662 solver.cpp:237] Iteration 315000, loss = 1.16194
I0527 00:11:22.631887  4662 solver.cpp:253]     Train net output #0: loss = 1.16194 (* 1 = 1.16194 loss)
I0527 00:11:22.631902  4662 sgd_solver.cpp:106] Iteration 315000, lr = 0.001
I0527 00:11:33.183475  4662 solver.cpp:237] Iteration 315500, loss = 1.20151
I0527 00:11:33.183524  4662 solver.cpp:253]     Train net output #0: loss = 1.20151 (* 1 = 1.20151 loss)
I0527 00:11:33.183538  4662 sgd_solver.cpp:106] Iteration 315500, lr = 0.001
I0527 00:11:43.731997  4662 solver.cpp:237] Iteration 316000, loss = 1.15044
I0527 00:11:43.732033  4662 solver.cpp:253]     Train net output #0: loss = 1.15044 (* 1 = 1.15044 loss)
I0527 00:11:43.732046  4662 sgd_solver.cpp:106] Iteration 316000, lr = 0.001
I0527 00:11:54.282867  4662 solver.cpp:237] Iteration 316500, loss = 0.915844
I0527 00:11:54.283040  4662 solver.cpp:253]     Train net output #0: loss = 0.915844 (* 1 = 0.915844 loss)
I0527 00:11:54.283056  4662 sgd_solver.cpp:106] Iteration 316500, lr = 0.001
I0527 00:12:25.714054  4662 solver.cpp:237] Iteration 317000, loss = 0.865287
I0527 00:12:25.714241  4662 solver.cpp:253]     Train net output #0: loss = 0.865288 (* 1 = 0.865288 loss)
I0527 00:12:25.714257  4662 sgd_solver.cpp:106] Iteration 317000, lr = 0.001
I0527 00:12:36.272532  4662 solver.cpp:237] Iteration 317500, loss = 0.913193
I0527 00:12:36.272568  4662 solver.cpp:253]     Train net output #0: loss = 0.913194 (* 1 = 0.913194 loss)
I0527 00:12:36.272584  4662 sgd_solver.cpp:106] Iteration 317500, lr = 0.001
I0527 00:12:46.811581  4662 solver.cpp:237] Iteration 318000, loss = 1.40092
I0527 00:12:46.811627  4662 solver.cpp:253]     Train net output #0: loss = 1.40092 (* 1 = 1.40092 loss)
I0527 00:12:46.811645  4662 sgd_solver.cpp:106] Iteration 318000, lr = 0.001
I0527 00:12:57.367861  4662 solver.cpp:237] Iteration 318500, loss = 1.12902
I0527 00:12:57.368017  4662 solver.cpp:253]     Train net output #0: loss = 1.12902 (* 1 = 1.12902 loss)
I0527 00:12:57.368033  4662 sgd_solver.cpp:106] Iteration 318500, lr = 0.001
I0527 00:13:07.930039  4662 solver.cpp:237] Iteration 319000, loss = 0.917884
I0527 00:13:07.930090  4662 solver.cpp:253]     Train net output #0: loss = 0.917885 (* 1 = 0.917885 loss)
I0527 00:13:07.930104  4662 sgd_solver.cpp:106] Iteration 319000, lr = 0.001
I0527 00:13:18.470845  4662 solver.cpp:237] Iteration 319500, loss = 1.30155
I0527 00:13:18.470881  4662 solver.cpp:253]     Train net output #0: loss = 1.30155 (* 1 = 1.30155 loss)
I0527 00:13:18.470895  4662 sgd_solver.cpp:106] Iteration 319500, lr = 0.001
I0527 00:13:29.011515  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_320000.caffemodel
I0527 00:13:29.065531  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_320000.solverstate
I0527 00:13:29.091060  4662 solver.cpp:341] Iteration 320000, Testing net (#0)
I0527 00:14:18.438591  4662 solver.cpp:409]     Test net output #0: accuracy = 0.897366
I0527 00:14:18.438772  4662 solver.cpp:409]     Test net output #1: loss = 0.323475 (* 1 = 0.323475 loss)
I0527 00:14:39.315346  4662 solver.cpp:237] Iteration 320000, loss = 1.05502
I0527 00:14:39.315398  4662 solver.cpp:253]     Train net output #0: loss = 1.05502 (* 1 = 1.05502 loss)
I0527 00:14:39.315412  4662 sgd_solver.cpp:106] Iteration 320000, lr = 0.001
I0527 00:14:49.862790  4662 solver.cpp:237] Iteration 320500, loss = 1.18866
I0527 00:14:49.862960  4662 solver.cpp:253]     Train net output #0: loss = 1.18866 (* 1 = 1.18866 loss)
I0527 00:14:49.862975  4662 sgd_solver.cpp:106] Iteration 320500, lr = 0.001
I0527 00:15:00.390271  4662 solver.cpp:237] Iteration 321000, loss = 0.820308
I0527 00:15:00.390307  4662 solver.cpp:253]     Train net output #0: loss = 0.820309 (* 1 = 0.820309 loss)
I0527 00:15:00.390324  4662 sgd_solver.cpp:106] Iteration 321000, lr = 0.001
I0527 00:15:10.927119  4662 solver.cpp:237] Iteration 321500, loss = 1.41212
I0527 00:15:10.927168  4662 solver.cpp:253]     Train net output #0: loss = 1.41212 (* 1 = 1.41212 loss)
I0527 00:15:10.927182  4662 sgd_solver.cpp:106] Iteration 321500, lr = 0.001
I0527 00:15:21.472678  4662 solver.cpp:237] Iteration 322000, loss = 0.996388
I0527 00:15:21.472839  4662 solver.cpp:253]     Train net output #0: loss = 0.996389 (* 1 = 0.996389 loss)
I0527 00:15:21.472854  4662 sgd_solver.cpp:106] Iteration 322000, lr = 0.001
I0527 00:15:32.008132  4662 solver.cpp:237] Iteration 322500, loss = 1.04783
I0527 00:15:32.008167  4662 solver.cpp:253]     Train net output #0: loss = 1.04783 (* 1 = 1.04783 loss)
I0527 00:15:32.008180  4662 sgd_solver.cpp:106] Iteration 322500, lr = 0.001
I0527 00:15:42.552074  4662 solver.cpp:237] Iteration 323000, loss = 1.31748
I0527 00:15:42.552120  4662 solver.cpp:253]     Train net output #0: loss = 1.31748 (* 1 = 1.31748 loss)
I0527 00:15:42.552136  4662 sgd_solver.cpp:106] Iteration 323000, lr = 0.001
I0527 00:16:13.995040  4662 solver.cpp:237] Iteration 323500, loss = 1.29774
I0527 00:16:13.995218  4662 solver.cpp:253]     Train net output #0: loss = 1.29774 (* 1 = 1.29774 loss)
I0527 00:16:13.995234  4662 sgd_solver.cpp:106] Iteration 323500, lr = 0.001
I0527 00:16:24.544239  4662 solver.cpp:237] Iteration 324000, loss = 1.32717
I0527 00:16:24.544288  4662 solver.cpp:253]     Train net output #0: loss = 1.32717 (* 1 = 1.32717 loss)
I0527 00:16:24.544303  4662 sgd_solver.cpp:106] Iteration 324000, lr = 0.001
I0527 00:16:35.083585  4662 solver.cpp:237] Iteration 324500, loss = 1.3113
I0527 00:16:35.083619  4662 solver.cpp:253]     Train net output #0: loss = 1.3113 (* 1 = 1.3113 loss)
I0527 00:16:35.083636  4662 sgd_solver.cpp:106] Iteration 324500, lr = 0.001
I0527 00:16:45.599931  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_325000.caffemodel
I0527 00:16:45.652683  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_325000.solverstate
I0527 00:16:45.684698  4662 solver.cpp:237] Iteration 325000, loss = 1.27019
I0527 00:16:45.684744  4662 solver.cpp:253]     Train net output #0: loss = 1.27019 (* 1 = 1.27019 loss)
I0527 00:16:45.684758  4662 sgd_solver.cpp:106] Iteration 325000, lr = 0.001
I0527 00:16:56.218406  4662 solver.cpp:237] Iteration 325500, loss = 1.23377
I0527 00:16:56.218449  4662 solver.cpp:253]     Train net output #0: loss = 1.23377 (* 1 = 1.23377 loss)
I0527 00:16:56.218466  4662 sgd_solver.cpp:106] Iteration 325500, lr = 0.001
I0527 00:17:06.760694  4662 solver.cpp:237] Iteration 326000, loss = 1.10235
I0527 00:17:06.760730  4662 solver.cpp:253]     Train net output #0: loss = 1.10235 (* 1 = 1.10235 loss)
I0527 00:17:06.760746  4662 sgd_solver.cpp:106] Iteration 326000, lr = 0.001
I0527 00:17:17.306334  4662 solver.cpp:237] Iteration 326500, loss = 1.67679
I0527 00:17:17.306514  4662 solver.cpp:253]     Train net output #0: loss = 1.67679 (* 1 = 1.67679 loss)
I0527 00:17:17.306530  4662 sgd_solver.cpp:106] Iteration 326500, lr = 0.001
I0527 00:17:48.738611  4662 solver.cpp:237] Iteration 327000, loss = 0.955999
I0527 00:17:48.738801  4662 solver.cpp:253]     Train net output #0: loss = 0.956 (* 1 = 0.956 loss)
I0527 00:17:48.738816  4662 sgd_solver.cpp:106] Iteration 327000, lr = 0.001
I0527 00:17:59.265331  4662 solver.cpp:237] Iteration 327500, loss = 1.33522
I0527 00:17:59.265367  4662 solver.cpp:253]     Train net output #0: loss = 1.33522 (* 1 = 1.33522 loss)
I0527 00:17:59.265383  4662 sgd_solver.cpp:106] Iteration 327500, lr = 0.001
I0527 00:18:09.806121  4662 solver.cpp:237] Iteration 328000, loss = 1.07328
I0527 00:18:09.806169  4662 solver.cpp:253]     Train net output #0: loss = 1.07328 (* 1 = 1.07328 loss)
I0527 00:18:09.806186  4662 sgd_solver.cpp:106] Iteration 328000, lr = 0.001
I0527 00:18:20.350597  4662 solver.cpp:237] Iteration 328500, loss = 1.11739
I0527 00:18:20.350771  4662 solver.cpp:253]     Train net output #0: loss = 1.11739 (* 1 = 1.11739 loss)
I0527 00:18:20.350786  4662 sgd_solver.cpp:106] Iteration 328500, lr = 0.001
I0527 00:18:30.897339  4662 solver.cpp:237] Iteration 329000, loss = 0.951139
I0527 00:18:30.897387  4662 solver.cpp:253]     Train net output #0: loss = 0.951139 (* 1 = 0.951139 loss)
I0527 00:18:30.897400  4662 sgd_solver.cpp:106] Iteration 329000, lr = 0.001
I0527 00:18:41.433223  4662 solver.cpp:237] Iteration 329500, loss = 0.936198
I0527 00:18:41.433260  4662 solver.cpp:253]     Train net output #0: loss = 0.936198 (* 1 = 0.936198 loss)
I0527 00:18:41.433274  4662 sgd_solver.cpp:106] Iteration 329500, lr = 0.001
I0527 00:18:51.945802  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_330000.caffemodel
I0527 00:18:52.003231  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_330000.solverstate
I0527 00:18:52.029834  4662 solver.cpp:341] Iteration 330000, Testing net (#0)
I0527 00:20:02.494698  4662 solver.cpp:409]     Test net output #0: accuracy = 0.897851
I0527 00:20:02.494874  4662 solver.cpp:409]     Test net output #1: loss = 0.322978 (* 1 = 0.322978 loss)
I0527 00:20:23.407289  4662 solver.cpp:237] Iteration 330000, loss = 1.022
I0527 00:20:23.407341  4662 solver.cpp:253]     Train net output #0: loss = 1.022 (* 1 = 1.022 loss)
I0527 00:20:23.407358  4662 sgd_solver.cpp:106] Iteration 330000, lr = 0.001
I0527 00:20:33.909229  4662 solver.cpp:237] Iteration 330500, loss = 0.940551
I0527 00:20:33.909401  4662 solver.cpp:253]     Train net output #0: loss = 0.940551 (* 1 = 0.940551 loss)
I0527 00:20:33.909416  4662 sgd_solver.cpp:106] Iteration 330500, lr = 0.001
I0527 00:20:44.418082  4662 solver.cpp:237] Iteration 331000, loss = 1.12043
I0527 00:20:44.418123  4662 solver.cpp:253]     Train net output #0: loss = 1.12043 (* 1 = 1.12043 loss)
I0527 00:20:44.418136  4662 sgd_solver.cpp:106] Iteration 331000, lr = 0.001
I0527 00:20:54.922814  4662 solver.cpp:237] Iteration 331500, loss = 1.31138
I0527 00:20:54.922849  4662 solver.cpp:253]     Train net output #0: loss = 1.31138 (* 1 = 1.31138 loss)
I0527 00:20:54.922866  4662 sgd_solver.cpp:106] Iteration 331500, lr = 0.001
I0527 00:21:05.436040  4662 solver.cpp:237] Iteration 332000, loss = 1.20887
I0527 00:21:05.436206  4662 solver.cpp:253]     Train net output #0: loss = 1.20887 (* 1 = 1.20887 loss)
I0527 00:21:05.436221  4662 sgd_solver.cpp:106] Iteration 332000, lr = 0.001
I0527 00:21:15.948346  4662 solver.cpp:237] Iteration 332500, loss = 0.811872
I0527 00:21:15.948384  4662 solver.cpp:253]     Train net output #0: loss = 0.811873 (* 1 = 0.811873 loss)
I0527 00:21:15.948397  4662 sgd_solver.cpp:106] Iteration 332500, lr = 0.001
I0527 00:21:26.460388  4662 solver.cpp:237] Iteration 333000, loss = 1.46304
I0527 00:21:26.460438  4662 solver.cpp:253]     Train net output #0: loss = 1.46304 (* 1 = 1.46304 loss)
I0527 00:21:26.460453  4662 sgd_solver.cpp:106] Iteration 333000, lr = 0.001
I0527 00:21:57.894089  4662 solver.cpp:237] Iteration 333500, loss = 1.013
I0527 00:21:57.894274  4662 solver.cpp:253]     Train net output #0: loss = 1.013 (* 1 = 1.013 loss)
I0527 00:21:57.894290  4662 sgd_solver.cpp:106] Iteration 333500, lr = 0.001
I0527 00:22:08.405220  4662 solver.cpp:237] Iteration 334000, loss = 0.979213
I0527 00:22:08.405256  4662 solver.cpp:253]     Train net output #0: loss = 0.979214 (* 1 = 0.979214 loss)
I0527 00:22:08.405269  4662 sgd_solver.cpp:106] Iteration 334000, lr = 0.001
I0527 00:22:18.926365  4662 solver.cpp:237] Iteration 334500, loss = 0.815412
I0527 00:22:18.926415  4662 solver.cpp:253]     Train net output #0: loss = 0.815412 (* 1 = 0.815412 loss)
I0527 00:22:18.926429  4662 sgd_solver.cpp:106] Iteration 334500, lr = 0.001
I0527 00:22:29.428135  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_335000.caffemodel
I0527 00:22:29.494632  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_335000.solverstate
I0527 00:22:29.528837  4662 solver.cpp:237] Iteration 335000, loss = 1.10356
I0527 00:22:29.528888  4662 solver.cpp:253]     Train net output #0: loss = 1.10356 (* 1 = 1.10356 loss)
I0527 00:22:29.528903  4662 sgd_solver.cpp:106] Iteration 335000, lr = 0.001
I0527 00:22:40.040666  4662 solver.cpp:237] Iteration 335500, loss = 0.972495
I0527 00:22:40.040714  4662 solver.cpp:253]     Train net output #0: loss = 0.972495 (* 1 = 0.972495 loss)
I0527 00:22:40.040729  4662 sgd_solver.cpp:106] Iteration 335500, lr = 0.001
I0527 00:22:50.570003  4662 solver.cpp:237] Iteration 336000, loss = 1.18386
I0527 00:22:50.570040  4662 solver.cpp:253]     Train net output #0: loss = 1.18386 (* 1 = 1.18386 loss)
I0527 00:22:50.570053  4662 sgd_solver.cpp:106] Iteration 336000, lr = 0.001
I0527 00:23:01.106281  4662 solver.cpp:237] Iteration 336500, loss = 0.896429
I0527 00:23:01.106449  4662 solver.cpp:253]     Train net output #0: loss = 0.896429 (* 1 = 0.896429 loss)
I0527 00:23:01.106464  4662 sgd_solver.cpp:106] Iteration 336500, lr = 0.001
I0527 00:23:32.541448  4662 solver.cpp:237] Iteration 337000, loss = 1.15241
I0527 00:23:32.541630  4662 solver.cpp:253]     Train net output #0: loss = 1.15242 (* 1 = 1.15242 loss)
I0527 00:23:32.541646  4662 sgd_solver.cpp:106] Iteration 337000, lr = 0.001
I0527 00:23:43.071409  4662 solver.cpp:237] Iteration 337500, loss = 1.35776
I0527 00:23:43.071444  4662 solver.cpp:253]     Train net output #0: loss = 1.35776 (* 1 = 1.35776 loss)
I0527 00:23:43.071458  4662 sgd_solver.cpp:106] Iteration 337500, lr = 0.001
I0527 00:23:53.600719  4662 solver.cpp:237] Iteration 338000, loss = 1.23955
I0527 00:23:53.600754  4662 solver.cpp:253]     Train net output #0: loss = 1.23955 (* 1 = 1.23955 loss)
I0527 00:23:53.600769  4662 sgd_solver.cpp:106] Iteration 338000, lr = 0.001
I0527 00:24:04.121449  4662 solver.cpp:237] Iteration 338500, loss = 1.1236
I0527 00:24:04.121618  4662 solver.cpp:253]     Train net output #0: loss = 1.1236 (* 1 = 1.1236 loss)
I0527 00:24:04.121634  4662 sgd_solver.cpp:106] Iteration 338500, lr = 0.001
I0527 00:24:14.648115  4662 solver.cpp:237] Iteration 339000, loss = 1.11476
I0527 00:24:14.648151  4662 solver.cpp:253]     Train net output #0: loss = 1.11476 (* 1 = 1.11476 loss)
I0527 00:24:14.648167  4662 sgd_solver.cpp:106] Iteration 339000, lr = 0.001
I0527 00:24:25.175757  4662 solver.cpp:237] Iteration 339500, loss = 1.12499
I0527 00:24:25.175804  4662 solver.cpp:253]     Train net output #0: loss = 1.12499 (* 1 = 1.12499 loss)
I0527 00:24:25.175818  4662 sgd_solver.cpp:106] Iteration 339500, lr = 0.001
I0527 00:24:35.668154  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_340000.caffemodel
I0527 00:24:35.720721  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_340000.solverstate
I0527 00:24:35.746423  4662 solver.cpp:341] Iteration 340000, Testing net (#0)
I0527 00:25:25.378296  4662 solver.cpp:409]     Test net output #0: accuracy = 0.897568
I0527 00:25:25.378475  4662 solver.cpp:409]     Test net output #1: loss = 0.320794 (* 1 = 0.320794 loss)
I0527 00:25:46.250646  4662 solver.cpp:237] Iteration 340000, loss = 1.06507
I0527 00:25:46.250699  4662 solver.cpp:253]     Train net output #0: loss = 1.06507 (* 1 = 1.06507 loss)
I0527 00:25:46.250715  4662 sgd_solver.cpp:106] Iteration 340000, lr = 0.001
I0527 00:25:56.791980  4662 solver.cpp:237] Iteration 340500, loss = 1.02588
I0527 00:25:56.792150  4662 solver.cpp:253]     Train net output #0: loss = 1.02588 (* 1 = 1.02588 loss)
I0527 00:25:56.792165  4662 sgd_solver.cpp:106] Iteration 340500, lr = 0.001
I0527 00:26:07.334662  4662 solver.cpp:237] Iteration 341000, loss = 1.31407
I0527 00:26:07.334710  4662 solver.cpp:253]     Train net output #0: loss = 1.31407 (* 1 = 1.31407 loss)
I0527 00:26:07.334724  4662 sgd_solver.cpp:106] Iteration 341000, lr = 0.001
I0527 00:26:17.880120  4662 solver.cpp:237] Iteration 341500, loss = 1.43685
I0527 00:26:17.880156  4662 solver.cpp:253]     Train net output #0: loss = 1.43685 (* 1 = 1.43685 loss)
I0527 00:26:17.880169  4662 sgd_solver.cpp:106] Iteration 341500, lr = 0.001
I0527 00:26:28.435515  4662 solver.cpp:237] Iteration 342000, loss = 1.1399
I0527 00:26:28.435690  4662 solver.cpp:253]     Train net output #0: loss = 1.1399 (* 1 = 1.1399 loss)
I0527 00:26:28.435706  4662 sgd_solver.cpp:106] Iteration 342000, lr = 0.001
I0527 00:26:38.968861  4662 solver.cpp:237] Iteration 342500, loss = 1.19173
I0527 00:26:38.968897  4662 solver.cpp:253]     Train net output #0: loss = 1.19173 (* 1 = 1.19173 loss)
I0527 00:26:38.968910  4662 sgd_solver.cpp:106] Iteration 342500, lr = 0.001
I0527 00:26:49.520099  4662 solver.cpp:237] Iteration 343000, loss = 0.920331
I0527 00:26:49.520148  4662 solver.cpp:253]     Train net output #0: loss = 0.920331 (* 1 = 0.920331 loss)
I0527 00:26:49.520162  4662 sgd_solver.cpp:106] Iteration 343000, lr = 0.001
I0527 00:27:20.949726  4662 solver.cpp:237] Iteration 343500, loss = 1.09415
I0527 00:27:20.949913  4662 solver.cpp:253]     Train net output #0: loss = 1.09415 (* 1 = 1.09415 loss)
I0527 00:27:20.949926  4662 sgd_solver.cpp:106] Iteration 343500, lr = 0.001
I0527 00:27:31.472816  4662 solver.cpp:237] Iteration 344000, loss = 0.844922
I0527 00:27:31.472853  4662 solver.cpp:253]     Train net output #0: loss = 0.844922 (* 1 = 0.844922 loss)
I0527 00:27:31.472867  4662 sgd_solver.cpp:106] Iteration 344000, lr = 0.001
I0527 00:27:42.023074  4662 solver.cpp:237] Iteration 344500, loss = 1.38934
I0527 00:27:42.023121  4662 solver.cpp:253]     Train net output #0: loss = 1.38935 (* 1 = 1.38935 loss)
I0527 00:27:42.023135  4662 sgd_solver.cpp:106] Iteration 344500, lr = 0.001
I0527 00:27:52.548223  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_345000.caffemodel
I0527 00:27:52.600589  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_345000.solverstate
I0527 00:27:52.632925  4662 solver.cpp:237] Iteration 345000, loss = 1.24791
I0527 00:27:52.632969  4662 solver.cpp:253]     Train net output #0: loss = 1.24791 (* 1 = 1.24791 loss)
I0527 00:27:52.632985  4662 sgd_solver.cpp:106] Iteration 345000, lr = 0.001
I0527 00:28:03.172849  4662 solver.cpp:237] Iteration 345500, loss = 1.24446
I0527 00:28:03.172885  4662 solver.cpp:253]     Train net output #0: loss = 1.24446 (* 1 = 1.24446 loss)
I0527 00:28:03.172899  4662 sgd_solver.cpp:106] Iteration 345500, lr = 0.001
I0527 00:28:13.717483  4662 solver.cpp:237] Iteration 346000, loss = 1.02785
I0527 00:28:13.717526  4662 solver.cpp:253]     Train net output #0: loss = 1.02785 (* 1 = 1.02785 loss)
I0527 00:28:13.717543  4662 sgd_solver.cpp:106] Iteration 346000, lr = 0.001
I0527 00:28:24.249435  4662 solver.cpp:237] Iteration 346500, loss = 1.32314
I0527 00:28:24.249610  4662 solver.cpp:253]     Train net output #0: loss = 1.32314 (* 1 = 1.32314 loss)
I0527 00:28:24.249626  4662 sgd_solver.cpp:106] Iteration 346500, lr = 0.001
I0527 00:28:55.650148  4662 solver.cpp:237] Iteration 347000, loss = 1.09954
I0527 00:28:55.650328  4662 solver.cpp:253]     Train net output #0: loss = 1.09954 (* 1 = 1.09954 loss)
I0527 00:28:55.650342  4662 sgd_solver.cpp:106] Iteration 347000, lr = 0.001
I0527 00:29:06.191715  4662 solver.cpp:237] Iteration 347500, loss = 1.54923
I0527 00:29:06.191751  4662 solver.cpp:253]     Train net output #0: loss = 1.54923 (* 1 = 1.54923 loss)
I0527 00:29:06.191764  4662 sgd_solver.cpp:106] Iteration 347500, lr = 0.001
I0527 00:29:16.737715  4662 solver.cpp:237] Iteration 348000, loss = 1.18819
I0527 00:29:16.737749  4662 solver.cpp:253]     Train net output #0: loss = 1.18819 (* 1 = 1.18819 loss)
I0527 00:29:16.737767  4662 sgd_solver.cpp:106] Iteration 348000, lr = 0.001
I0527 00:29:27.270345  4662 solver.cpp:237] Iteration 348500, loss = 1.03144
I0527 00:29:27.270509  4662 solver.cpp:253]     Train net output #0: loss = 1.03144 (* 1 = 1.03144 loss)
I0527 00:29:27.270524  4662 sgd_solver.cpp:106] Iteration 348500, lr = 0.001
I0527 00:29:37.825449  4662 solver.cpp:237] Iteration 349000, loss = 0.937211
I0527 00:29:37.825485  4662 solver.cpp:253]     Train net output #0: loss = 0.937211 (* 1 = 0.937211 loss)
I0527 00:29:37.825502  4662 sgd_solver.cpp:106] Iteration 349000, lr = 0.001
I0527 00:29:48.349038  4662 solver.cpp:237] Iteration 349500, loss = 0.971659
I0527 00:29:48.349086  4662 solver.cpp:253]     Train net output #0: loss = 0.97166 (* 1 = 0.97166 loss)
I0527 00:29:48.349102  4662 sgd_solver.cpp:106] Iteration 349500, lr = 0.001
I0527 00:29:58.875052  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_350000.caffemodel
I0527 00:29:58.927726  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_350000.solverstate
I0527 00:29:58.953261  4662 solver.cpp:341] Iteration 350000, Testing net (#0)
I0527 00:31:09.371783  4662 solver.cpp:409]     Test net output #0: accuracy = 0.90063
I0527 00:31:09.371959  4662 solver.cpp:409]     Test net output #1: loss = 0.319353 (* 1 = 0.319353 loss)
I0527 00:31:30.224761  4662 solver.cpp:237] Iteration 350000, loss = 1.19851
I0527 00:31:30.224814  4662 solver.cpp:253]     Train net output #0: loss = 1.19851 (* 1 = 1.19851 loss)
I0527 00:31:30.224830  4662 sgd_solver.cpp:106] Iteration 350000, lr = 0.001
I0527 00:31:40.785864  4662 solver.cpp:237] Iteration 350500, loss = 1.10958
I0527 00:31:40.786034  4662 solver.cpp:253]     Train net output #0: loss = 1.10958 (* 1 = 1.10958 loss)
I0527 00:31:40.786051  4662 sgd_solver.cpp:106] Iteration 350500, lr = 0.001
I0527 00:31:51.354429  4662 solver.cpp:237] Iteration 351000, loss = 1.04463
I0527 00:31:51.354475  4662 solver.cpp:253]     Train net output #0: loss = 1.04463 (* 1 = 1.04463 loss)
I0527 00:31:51.354490  4662 sgd_solver.cpp:106] Iteration 351000, lr = 0.001
I0527 00:32:01.924324  4662 solver.cpp:237] Iteration 351500, loss = 1.08821
I0527 00:32:01.924360  4662 solver.cpp:253]     Train net output #0: loss = 1.08821 (* 1 = 1.08821 loss)
I0527 00:32:01.924374  4662 sgd_solver.cpp:106] Iteration 351500, lr = 0.001
I0527 00:32:12.493374  4662 solver.cpp:237] Iteration 352000, loss = 0.950417
I0527 00:32:12.493547  4662 solver.cpp:253]     Train net output #0: loss = 0.950418 (* 1 = 0.950418 loss)
I0527 00:32:12.493562  4662 sgd_solver.cpp:106] Iteration 352000, lr = 0.001
I0527 00:32:23.071349  4662 solver.cpp:237] Iteration 352500, loss = 1.13502
I0527 00:32:23.071394  4662 solver.cpp:253]     Train net output #0: loss = 1.13502 (* 1 = 1.13502 loss)
I0527 00:32:23.071408  4662 sgd_solver.cpp:106] Iteration 352500, lr = 0.001
I0527 00:32:33.639719  4662 solver.cpp:237] Iteration 353000, loss = 1.10734
I0527 00:32:33.639755  4662 solver.cpp:253]     Train net output #0: loss = 1.10734 (* 1 = 1.10734 loss)
I0527 00:32:33.639771  4662 sgd_solver.cpp:106] Iteration 353000, lr = 0.001
I0527 00:33:05.056604  4662 solver.cpp:237] Iteration 353500, loss = 1.03534
I0527 00:33:05.056779  4662 solver.cpp:253]     Train net output #0: loss = 1.03534 (* 1 = 1.03534 loss)
I0527 00:33:05.056793  4662 sgd_solver.cpp:106] Iteration 353500, lr = 0.001
I0527 00:33:15.611124  4662 solver.cpp:237] Iteration 354000, loss = 1.08865
I0527 00:33:15.611160  4662 solver.cpp:253]     Train net output #0: loss = 1.08865 (* 1 = 1.08865 loss)
I0527 00:33:15.611176  4662 sgd_solver.cpp:106] Iteration 354000, lr = 0.001
I0527 00:33:26.167701  4662 solver.cpp:237] Iteration 354500, loss = 1.49428
I0527 00:33:26.167735  4662 solver.cpp:253]     Train net output #0: loss = 1.49428 (* 1 = 1.49428 loss)
I0527 00:33:26.167752  4662 sgd_solver.cpp:106] Iteration 354500, lr = 0.001
I0527 00:33:36.704946  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_355000.caffemodel
I0527 00:33:36.766032  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_355000.solverstate
I0527 00:33:36.800278  4662 solver.cpp:237] Iteration 355000, loss = 1.73489
I0527 00:33:36.800328  4662 solver.cpp:253]     Train net output #0: loss = 1.73489 (* 1 = 1.73489 loss)
I0527 00:33:36.800343  4662 sgd_solver.cpp:106] Iteration 355000, lr = 0.001
I0527 00:33:47.376235  4662 solver.cpp:237] Iteration 355500, loss = 1.05636
I0527 00:33:47.376271  4662 solver.cpp:253]     Train net output #0: loss = 1.05636 (* 1 = 1.05636 loss)
I0527 00:33:47.376284  4662 sgd_solver.cpp:106] Iteration 355500, lr = 0.001
I0527 00:33:57.936496  4662 solver.cpp:237] Iteration 356000, loss = 1.26796
I0527 00:33:57.936547  4662 solver.cpp:253]     Train net output #0: loss = 1.26796 (* 1 = 1.26796 loss)
I0527 00:33:57.936560  4662 sgd_solver.cpp:106] Iteration 356000, lr = 0.001
I0527 00:34:08.499321  4662 solver.cpp:237] Iteration 356500, loss = 0.954506
I0527 00:34:08.499496  4662 solver.cpp:253]     Train net output #0: loss = 0.954507 (* 1 = 0.954507 loss)
I0527 00:34:08.499511  4662 sgd_solver.cpp:106] Iteration 356500, lr = 0.001
I0527 00:34:39.975672  4662 solver.cpp:237] Iteration 357000, loss = 1.47188
I0527 00:34:39.975858  4662 solver.cpp:253]     Train net output #0: loss = 1.47188 (* 1 = 1.47188 loss)
I0527 00:34:39.975873  4662 sgd_solver.cpp:106] Iteration 357000, lr = 0.001
I0527 00:34:50.523561  4662 solver.cpp:237] Iteration 357500, loss = 1.30618
I0527 00:34:50.523610  4662 solver.cpp:253]     Train net output #0: loss = 1.30618 (* 1 = 1.30618 loss)
I0527 00:34:50.523625  4662 sgd_solver.cpp:106] Iteration 357500, lr = 0.001
I0527 00:35:01.060066  4662 solver.cpp:237] Iteration 358000, loss = 1.19066
I0527 00:35:01.060103  4662 solver.cpp:253]     Train net output #0: loss = 1.19066 (* 1 = 1.19066 loss)
I0527 00:35:01.060120  4662 sgd_solver.cpp:106] Iteration 358000, lr = 0.001
I0527 00:35:11.603621  4662 solver.cpp:237] Iteration 358500, loss = 1.14374
I0527 00:35:11.603806  4662 solver.cpp:253]     Train net output #0: loss = 1.14374 (* 1 = 1.14374 loss)
I0527 00:35:11.603821  4662 sgd_solver.cpp:106] Iteration 358500, lr = 0.001
I0527 00:35:22.143801  4662 solver.cpp:237] Iteration 359000, loss = 0.927855
I0527 00:35:22.143838  4662 solver.cpp:253]     Train net output #0: loss = 0.927855 (* 1 = 0.927855 loss)
I0527 00:35:22.143852  4662 sgd_solver.cpp:106] Iteration 359000, lr = 0.001
I0527 00:35:32.678756  4662 solver.cpp:237] Iteration 359500, loss = 1.40484
I0527 00:35:32.678792  4662 solver.cpp:253]     Train net output #0: loss = 1.40484 (* 1 = 1.40484 loss)
I0527 00:35:32.678808  4662 sgd_solver.cpp:106] Iteration 359500, lr = 0.001
I0527 00:35:43.199136  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_360000.caffemodel
I0527 00:35:43.254504  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_360000.solverstate
I0527 00:35:43.283850  4662 solver.cpp:341] Iteration 360000, Testing net (#0)
I0527 00:36:32.591382  4662 solver.cpp:409]     Test net output #0: accuracy = 0.899625
I0527 00:36:32.591565  4662 solver.cpp:409]     Test net output #1: loss = 0.320482 (* 1 = 0.320482 loss)
I0527 00:36:53.500653  4662 solver.cpp:237] Iteration 360000, loss = 1.21309
I0527 00:36:53.500705  4662 solver.cpp:253]     Train net output #0: loss = 1.21309 (* 1 = 1.21309 loss)
I0527 00:36:53.500720  4662 sgd_solver.cpp:106] Iteration 360000, lr = 0.001
I0527 00:37:04.134171  4662 solver.cpp:237] Iteration 360500, loss = 1.04883
I0527 00:37:04.134340  4662 solver.cpp:253]     Train net output #0: loss = 1.04883 (* 1 = 1.04883 loss)
I0527 00:37:04.134356  4662 sgd_solver.cpp:106] Iteration 360500, lr = 0.001
I0527 00:37:14.758290  4662 solver.cpp:237] Iteration 361000, loss = 1.08628
I0527 00:37:14.758333  4662 solver.cpp:253]     Train net output #0: loss = 1.08628 (* 1 = 1.08628 loss)
I0527 00:37:14.758350  4662 sgd_solver.cpp:106] Iteration 361000, lr = 0.001
I0527 00:37:25.406193  4662 solver.cpp:237] Iteration 361500, loss = 1.19651
I0527 00:37:25.406229  4662 solver.cpp:253]     Train net output #0: loss = 1.19651 (* 1 = 1.19651 loss)
I0527 00:37:25.406246  4662 sgd_solver.cpp:106] Iteration 361500, lr = 0.001
I0527 00:37:36.032100  4662 solver.cpp:237] Iteration 362000, loss = 1.30377
I0527 00:37:36.032276  4662 solver.cpp:253]     Train net output #0: loss = 1.30377 (* 1 = 1.30377 loss)
I0527 00:37:36.032291  4662 sgd_solver.cpp:106] Iteration 362000, lr = 0.001
I0527 00:37:46.666435  4662 solver.cpp:237] Iteration 362500, loss = 1.14078
I0527 00:37:46.666482  4662 solver.cpp:253]     Train net output #0: loss = 1.14078 (* 1 = 1.14078 loss)
I0527 00:37:46.666498  4662 sgd_solver.cpp:106] Iteration 362500, lr = 0.001
I0527 00:37:57.295622  4662 solver.cpp:237] Iteration 363000, loss = 1.0345
I0527 00:37:57.295658  4662 solver.cpp:253]     Train net output #0: loss = 1.03451 (* 1 = 1.03451 loss)
I0527 00:37:57.295671  4662 sgd_solver.cpp:106] Iteration 363000, lr = 0.001
I0527 00:38:28.842134  4662 solver.cpp:237] Iteration 363500, loss = 1.11745
I0527 00:38:28.842320  4662 solver.cpp:253]     Train net output #0: loss = 1.11745 (* 1 = 1.11745 loss)
I0527 00:38:28.842335  4662 sgd_solver.cpp:106] Iteration 363500, lr = 0.001
I0527 00:38:39.472251  4662 solver.cpp:237] Iteration 364000, loss = 1.06352
I0527 00:38:39.472300  4662 solver.cpp:253]     Train net output #0: loss = 1.06352 (* 1 = 1.06352 loss)
I0527 00:38:39.472313  4662 sgd_solver.cpp:106] Iteration 364000, lr = 0.001
I0527 00:38:50.097978  4662 solver.cpp:237] Iteration 364500, loss = 1.35879
I0527 00:38:50.098014  4662 solver.cpp:253]     Train net output #0: loss = 1.35879 (* 1 = 1.35879 loss)
I0527 00:38:50.098028  4662 sgd_solver.cpp:106] Iteration 364500, lr = 0.001
I0527 00:39:00.695579  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_365000.caffemodel
I0527 00:39:00.749862  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_365000.solverstate
I0527 00:39:00.782297  4662 solver.cpp:237] Iteration 365000, loss = 1.20428
I0527 00:39:00.782343  4662 solver.cpp:253]     Train net output #0: loss = 1.20428 (* 1 = 1.20428 loss)
I0527 00:39:00.782358  4662 sgd_solver.cpp:106] Iteration 365000, lr = 0.001
I0527 00:39:11.420300  4662 solver.cpp:237] Iteration 365500, loss = 1.21768
I0527 00:39:11.420333  4662 solver.cpp:253]     Train net output #0: loss = 1.21768 (* 1 = 1.21768 loss)
I0527 00:39:11.420347  4662 sgd_solver.cpp:106] Iteration 365500, lr = 0.001
I0527 00:39:22.046428  4662 solver.cpp:237] Iteration 366000, loss = 1.0446
I0527 00:39:22.046475  4662 solver.cpp:253]     Train net output #0: loss = 1.0446 (* 1 = 1.0446 loss)
I0527 00:39:22.046491  4662 sgd_solver.cpp:106] Iteration 366000, lr = 0.001
I0527 00:39:32.664445  4662 solver.cpp:237] Iteration 366500, loss = 0.920766
I0527 00:39:32.664614  4662 solver.cpp:253]     Train net output #0: loss = 0.920766 (* 1 = 0.920766 loss)
I0527 00:39:32.664629  4662 sgd_solver.cpp:106] Iteration 366500, lr = 0.001
I0527 00:40:04.204104  4662 solver.cpp:237] Iteration 367000, loss = 1.17292
I0527 00:40:04.204289  4662 solver.cpp:253]     Train net output #0: loss = 1.17292 (* 1 = 1.17292 loss)
I0527 00:40:04.204304  4662 sgd_solver.cpp:106] Iteration 367000, lr = 0.001
I0527 00:40:14.789834  4662 solver.cpp:237] Iteration 367500, loss = 1.30663
I0527 00:40:14.789880  4662 solver.cpp:253]     Train net output #0: loss = 1.30664 (* 1 = 1.30664 loss)
I0527 00:40:14.789893  4662 sgd_solver.cpp:106] Iteration 367500, lr = 0.001
I0527 00:40:25.334389  4662 solver.cpp:237] Iteration 368000, loss = 1.05157
I0527 00:40:25.334425  4662 solver.cpp:253]     Train net output #0: loss = 1.05157 (* 1 = 1.05157 loss)
I0527 00:40:25.334442  4662 sgd_solver.cpp:106] Iteration 368000, lr = 0.001
I0527 00:40:35.876137  4662 solver.cpp:237] Iteration 368500, loss = 1.16473
I0527 00:40:35.876319  4662 solver.cpp:253]     Train net output #0: loss = 1.16473 (* 1 = 1.16473 loss)
I0527 00:40:35.876334  4662 sgd_solver.cpp:106] Iteration 368500, lr = 0.001
I0527 00:40:46.413271  4662 solver.cpp:237] Iteration 369000, loss = 1.18077
I0527 00:40:46.413307  4662 solver.cpp:253]     Train net output #0: loss = 1.18077 (* 1 = 1.18077 loss)
I0527 00:40:46.413324  4662 sgd_solver.cpp:106] Iteration 369000, lr = 0.001
I0527 00:40:56.958956  4662 solver.cpp:237] Iteration 369500, loss = 1.33459
I0527 00:40:56.958992  4662 solver.cpp:253]     Train net output #0: loss = 1.33459 (* 1 = 1.33459 loss)
I0527 00:40:56.959009  4662 sgd_solver.cpp:106] Iteration 369500, lr = 0.001
I0527 00:41:07.475193  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_370000.caffemodel
I0527 00:41:07.527808  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_370000.solverstate
I0527 00:41:07.553376  4662 solver.cpp:341] Iteration 370000, Testing net (#0)
I0527 00:42:18.054584  4662 solver.cpp:409]     Test net output #0: accuracy = 0.897327
I0527 00:42:18.054771  4662 solver.cpp:409]     Test net output #1: loss = 0.316828 (* 1 = 0.316828 loss)
I0527 00:42:38.938540  4662 solver.cpp:237] Iteration 370000, loss = 1.12863
I0527 00:42:38.938593  4662 solver.cpp:253]     Train net output #0: loss = 1.12863 (* 1 = 1.12863 loss)
I0527 00:42:38.938616  4662 sgd_solver.cpp:106] Iteration 370000, lr = 0.001
I0527 00:42:49.483587  4662 solver.cpp:237] Iteration 370500, loss = 1.11279
I0527 00:42:49.483768  4662 solver.cpp:253]     Train net output #0: loss = 1.11279 (* 1 = 1.11279 loss)
I0527 00:42:49.483783  4662 sgd_solver.cpp:106] Iteration 370500, lr = 0.001
I0527 00:43:00.029713  4662 solver.cpp:237] Iteration 371000, loss = 0.89149
I0527 00:43:00.029750  4662 solver.cpp:253]     Train net output #0: loss = 0.89149 (* 1 = 0.89149 loss)
I0527 00:43:00.029767  4662 sgd_solver.cpp:106] Iteration 371000, lr = 0.001
I0527 00:43:10.557040  4662 solver.cpp:237] Iteration 371500, loss = 1.43724
I0527 00:43:10.557086  4662 solver.cpp:253]     Train net output #0: loss = 1.43724 (* 1 = 1.43724 loss)
I0527 00:43:10.557103  4662 sgd_solver.cpp:106] Iteration 371500, lr = 0.001
I0527 00:43:21.088382  4662 solver.cpp:237] Iteration 372000, loss = 0.897591
I0527 00:43:21.088560  4662 solver.cpp:253]     Train net output #0: loss = 0.897591 (* 1 = 0.897591 loss)
I0527 00:43:21.088575  4662 sgd_solver.cpp:106] Iteration 372000, lr = 0.001
I0527 00:43:31.620283  4662 solver.cpp:237] Iteration 372500, loss = 1.22661
I0527 00:43:31.620331  4662 solver.cpp:253]     Train net output #0: loss = 1.22661 (* 1 = 1.22661 loss)
I0527 00:43:31.620344  4662 sgd_solver.cpp:106] Iteration 372500, lr = 0.001
I0527 00:43:42.142324  4662 solver.cpp:237] Iteration 373000, loss = 0.873878
I0527 00:43:42.142361  4662 solver.cpp:253]     Train net output #0: loss = 0.873878 (* 1 = 0.873878 loss)
I0527 00:43:42.142375  4662 sgd_solver.cpp:106] Iteration 373000, lr = 0.001
I0527 00:44:13.549866  4662 solver.cpp:237] Iteration 373500, loss = 1.3851
I0527 00:44:13.550067  4662 solver.cpp:253]     Train net output #0: loss = 1.3851 (* 1 = 1.3851 loss)
I0527 00:44:13.550084  4662 sgd_solver.cpp:106] Iteration 373500, lr = 0.001
I0527 00:44:24.056617  4662 solver.cpp:237] Iteration 374000, loss = 0.999572
I0527 00:44:24.056661  4662 solver.cpp:253]     Train net output #0: loss = 0.999572 (* 1 = 0.999572 loss)
I0527 00:44:24.056675  4662 sgd_solver.cpp:106] Iteration 374000, lr = 0.001
I0527 00:44:34.576715  4662 solver.cpp:237] Iteration 374500, loss = 1.2717
I0527 00:44:34.576751  4662 solver.cpp:253]     Train net output #0: loss = 1.2717 (* 1 = 1.2717 loss)
I0527 00:44:34.576764  4662 sgd_solver.cpp:106] Iteration 374500, lr = 0.001
I0527 00:44:45.055934  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_375000.caffemodel
I0527 00:44:45.108839  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_375000.solverstate
I0527 00:44:45.143955  4662 solver.cpp:237] Iteration 375000, loss = 1.32516
I0527 00:44:45.144006  4662 solver.cpp:253]     Train net output #0: loss = 1.32516 (* 1 = 1.32516 loss)
I0527 00:44:45.144021  4662 sgd_solver.cpp:106] Iteration 375000, lr = 0.001
I0527 00:44:55.652681  4662 solver.cpp:237] Iteration 375500, loss = 0.825555
I0527 00:44:55.652719  4662 solver.cpp:253]     Train net output #0: loss = 0.825555 (* 1 = 0.825555 loss)
I0527 00:44:55.652734  4662 sgd_solver.cpp:106] Iteration 375500, lr = 0.001
I0527 00:45:06.157671  4662 solver.cpp:237] Iteration 376000, loss = 0.949343
I0527 00:45:06.157707  4662 solver.cpp:253]     Train net output #0: loss = 0.949343 (* 1 = 0.949343 loss)
I0527 00:45:06.157721  4662 sgd_solver.cpp:106] Iteration 376000, lr = 0.001
I0527 00:45:16.667364  4662 solver.cpp:237] Iteration 376500, loss = 1.27262
I0527 00:45:16.667556  4662 solver.cpp:253]     Train net output #0: loss = 1.27262 (* 1 = 1.27262 loss)
I0527 00:45:16.667570  4662 sgd_solver.cpp:106] Iteration 376500, lr = 0.001
I0527 00:45:48.088769  4662 solver.cpp:237] Iteration 377000, loss = 0.77362
I0527 00:45:48.088959  4662 solver.cpp:253]     Train net output #0: loss = 0.77362 (* 1 = 0.77362 loss)
I0527 00:45:48.088974  4662 sgd_solver.cpp:106] Iteration 377000, lr = 0.001
I0527 00:45:58.606772  4662 solver.cpp:237] Iteration 377500, loss = 1.16719
I0527 00:45:58.606808  4662 solver.cpp:253]     Train net output #0: loss = 1.16719 (* 1 = 1.16719 loss)
I0527 00:45:58.606822  4662 sgd_solver.cpp:106] Iteration 377500, lr = 0.001
I0527 00:46:09.108150  4662 solver.cpp:237] Iteration 378000, loss = 1.10971
I0527 00:46:09.108194  4662 solver.cpp:253]     Train net output #0: loss = 1.10971 (* 1 = 1.10971 loss)
I0527 00:46:09.108211  4662 sgd_solver.cpp:106] Iteration 378000, lr = 0.001
I0527 00:46:19.623509  4662 solver.cpp:237] Iteration 378500, loss = 1.30819
I0527 00:46:19.623687  4662 solver.cpp:253]     Train net output #0: loss = 1.30819 (* 1 = 1.30819 loss)
I0527 00:46:19.623702  4662 sgd_solver.cpp:106] Iteration 378500, lr = 0.001
I0527 00:46:30.135999  4662 solver.cpp:237] Iteration 379000, loss = 1.16021
I0527 00:46:30.136042  4662 solver.cpp:253]     Train net output #0: loss = 1.16021 (* 1 = 1.16021 loss)
I0527 00:46:30.136059  4662 sgd_solver.cpp:106] Iteration 379000, lr = 0.001
I0527 00:46:40.650908  4662 solver.cpp:237] Iteration 379500, loss = 0.816964
I0527 00:46:40.650944  4662 solver.cpp:253]     Train net output #0: loss = 0.816964 (* 1 = 0.816964 loss)
I0527 00:46:40.650959  4662 sgd_solver.cpp:106] Iteration 379500, lr = 0.001
I0527 00:46:51.135912  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_380000.caffemodel
I0527 00:46:51.189677  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_380000.solverstate
I0527 00:46:51.216447  4662 solver.cpp:341] Iteration 380000, Testing net (#0)
I0527 00:47:40.895911  4662 solver.cpp:409]     Test net output #0: accuracy = 0.901098
I0527 00:47:40.896106  4662 solver.cpp:409]     Test net output #1: loss = 0.318133 (* 1 = 0.318133 loss)
I0527 00:48:01.798926  4662 solver.cpp:237] Iteration 380000, loss = 0.842669
I0527 00:48:01.798981  4662 solver.cpp:253]     Train net output #0: loss = 0.842669 (* 1 = 0.842669 loss)
I0527 00:48:01.798997  4662 sgd_solver.cpp:106] Iteration 380000, lr = 0.001
I0527 00:48:12.337013  4662 solver.cpp:237] Iteration 380500, loss = 1.0932
I0527 00:48:12.337204  4662 solver.cpp:253]     Train net output #0: loss = 1.0932 (* 1 = 1.0932 loss)
I0527 00:48:12.337219  4662 sgd_solver.cpp:106] Iteration 380500, lr = 0.001
I0527 00:48:22.883896  4662 solver.cpp:237] Iteration 381000, loss = 1.29003
I0527 00:48:22.883932  4662 solver.cpp:253]     Train net output #0: loss = 1.29003 (* 1 = 1.29003 loss)
I0527 00:48:22.883946  4662 sgd_solver.cpp:106] Iteration 381000, lr = 0.001
I0527 00:48:33.434938  4662 solver.cpp:237] Iteration 381500, loss = 1.06118
I0527 00:48:33.434988  4662 solver.cpp:253]     Train net output #0: loss = 1.06118 (* 1 = 1.06118 loss)
I0527 00:48:33.435003  4662 sgd_solver.cpp:106] Iteration 381500, lr = 0.001
I0527 00:48:43.971833  4662 solver.cpp:237] Iteration 382000, loss = 1.59194
I0527 00:48:43.972003  4662 solver.cpp:253]     Train net output #0: loss = 1.59194 (* 1 = 1.59194 loss)
I0527 00:48:43.972018  4662 sgd_solver.cpp:106] Iteration 382000, lr = 0.001
I0527 00:48:54.505754  4662 solver.cpp:237] Iteration 382500, loss = 1.1005
I0527 00:48:54.505802  4662 solver.cpp:253]     Train net output #0: loss = 1.1005 (* 1 = 1.1005 loss)
I0527 00:48:54.505818  4662 sgd_solver.cpp:106] Iteration 382500, lr = 0.001
I0527 00:49:05.054689  4662 solver.cpp:237] Iteration 383000, loss = 0.878165
I0527 00:49:05.054725  4662 solver.cpp:253]     Train net output #0: loss = 0.878165 (* 1 = 0.878165 loss)
I0527 00:49:05.054739  4662 sgd_solver.cpp:106] Iteration 383000, lr = 0.001
I0527 00:49:36.533102  4662 solver.cpp:237] Iteration 383500, loss = 1.41309
I0527 00:49:36.533291  4662 solver.cpp:253]     Train net output #0: loss = 1.41309 (* 1 = 1.41309 loss)
I0527 00:49:36.533306  4662 sgd_solver.cpp:106] Iteration 383500, lr = 0.001
I0527 00:49:47.071554  4662 solver.cpp:237] Iteration 384000, loss = 1.39135
I0527 00:49:47.071601  4662 solver.cpp:253]     Train net output #0: loss = 1.39135 (* 1 = 1.39135 loss)
I0527 00:49:47.071615  4662 sgd_solver.cpp:106] Iteration 384000, lr = 0.001
I0527 00:49:57.622704  4662 solver.cpp:237] Iteration 384500, loss = 1.02449
I0527 00:49:57.622740  4662 solver.cpp:253]     Train net output #0: loss = 1.02449 (* 1 = 1.02449 loss)
I0527 00:49:57.622757  4662 sgd_solver.cpp:106] Iteration 384500, lr = 0.001
I0527 00:50:08.133657  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_385000.caffemodel
I0527 00:50:08.192190  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_385000.solverstate
I0527 00:50:08.226799  4662 solver.cpp:237] Iteration 385000, loss = 0.995833
I0527 00:50:08.226848  4662 solver.cpp:253]     Train net output #0: loss = 0.995834 (* 1 = 0.995834 loss)
I0527 00:50:08.226863  4662 sgd_solver.cpp:106] Iteration 385000, lr = 0.001
I0527 00:50:18.780019  4662 solver.cpp:237] Iteration 385500, loss = 1.37304
I0527 00:50:18.780063  4662 solver.cpp:253]     Train net output #0: loss = 1.37304 (* 1 = 1.37304 loss)
I0527 00:50:18.780079  4662 sgd_solver.cpp:106] Iteration 385500, lr = 0.001
I0527 00:50:29.327702  4662 solver.cpp:237] Iteration 386000, loss = 1.42364
I0527 00:50:29.327739  4662 solver.cpp:253]     Train net output #0: loss = 1.42364 (* 1 = 1.42364 loss)
I0527 00:50:29.327756  4662 sgd_solver.cpp:106] Iteration 386000, lr = 0.001
I0527 00:50:39.872972  4662 solver.cpp:237] Iteration 386500, loss = 1.13731
I0527 00:50:39.873160  4662 solver.cpp:253]     Train net output #0: loss = 1.13731 (* 1 = 1.13731 loss)
I0527 00:50:39.873175  4662 sgd_solver.cpp:106] Iteration 386500, lr = 0.001
I0527 00:51:11.299762  4662 solver.cpp:237] Iteration 387000, loss = 1.10708
I0527 00:51:11.299952  4662 solver.cpp:253]     Train net output #0: loss = 1.10708 (* 1 = 1.10708 loss)
I0527 00:51:11.299968  4662 sgd_solver.cpp:106] Iteration 387000, lr = 0.001
I0527 00:51:21.828447  4662 solver.cpp:237] Iteration 387500, loss = 1.20782
I0527 00:51:21.828482  4662 solver.cpp:253]     Train net output #0: loss = 1.20782 (* 1 = 1.20782 loss)
I0527 00:51:21.828496  4662 sgd_solver.cpp:106] Iteration 387500, lr = 0.001
I0527 00:51:32.387722  4662 solver.cpp:237] Iteration 388000, loss = 0.837094
I0527 00:51:32.387770  4662 solver.cpp:253]     Train net output #0: loss = 0.837094 (* 1 = 0.837094 loss)
I0527 00:51:32.387784  4662 sgd_solver.cpp:106] Iteration 388000, lr = 0.001
I0527 00:51:42.945183  4662 solver.cpp:237] Iteration 388500, loss = 1.07622
I0527 00:51:42.945351  4662 solver.cpp:253]     Train net output #0: loss = 1.07622 (* 1 = 1.07622 loss)
I0527 00:51:42.945366  4662 sgd_solver.cpp:106] Iteration 388500, lr = 0.001
I0527 00:51:53.487263  4662 solver.cpp:237] Iteration 389000, loss = 1.11226
I0527 00:51:53.487309  4662 solver.cpp:253]     Train net output #0: loss = 1.11226 (* 1 = 1.11226 loss)
I0527 00:51:53.487323  4662 sgd_solver.cpp:106] Iteration 389000, lr = 0.001
I0527 00:52:04.062707  4662 solver.cpp:237] Iteration 389500, loss = 0.811207
I0527 00:52:04.062743  4662 solver.cpp:253]     Train net output #0: loss = 0.811207 (* 1 = 0.811207 loss)
I0527 00:52:04.062762  4662 sgd_solver.cpp:106] Iteration 389500, lr = 0.001
I0527 00:52:14.608590  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_390000.caffemodel
I0527 00:52:14.667115  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_390000.solverstate
I0527 00:52:14.698173  4662 solver.cpp:341] Iteration 390000, Testing net (#0)
I0527 00:53:25.177386  4662 solver.cpp:409]     Test net output #0: accuracy = 0.901579
I0527 00:53:25.177583  4662 solver.cpp:409]     Test net output #1: loss = 0.303447 (* 1 = 0.303447 loss)
I0527 00:53:46.085388  4662 solver.cpp:237] Iteration 390000, loss = 1.04038
I0527 00:53:46.085439  4662 solver.cpp:253]     Train net output #0: loss = 1.04038 (* 1 = 1.04038 loss)
I0527 00:53:46.085458  4662 sgd_solver.cpp:106] Iteration 390000, lr = 0.001
I0527 00:53:56.622508  4662 solver.cpp:237] Iteration 390500, loss = 1.24223
I0527 00:53:56.622704  4662 solver.cpp:253]     Train net output #0: loss = 1.24223 (* 1 = 1.24223 loss)
I0527 00:53:56.622719  4662 sgd_solver.cpp:106] Iteration 390500, lr = 0.001
I0527 00:54:07.182297  4662 solver.cpp:237] Iteration 391000, loss = 1.10085
I0527 00:54:07.182333  4662 solver.cpp:253]     Train net output #0: loss = 1.10085 (* 1 = 1.10085 loss)
I0527 00:54:07.182348  4662 sgd_solver.cpp:106] Iteration 391000, lr = 0.001
I0527 00:54:17.708581  4662 solver.cpp:237] Iteration 391500, loss = 1.24115
I0527 00:54:17.708617  4662 solver.cpp:253]     Train net output #0: loss = 1.24115 (* 1 = 1.24115 loss)
I0527 00:54:17.708634  4662 sgd_solver.cpp:106] Iteration 391500, lr = 0.001
I0527 00:54:28.217147  4662 solver.cpp:237] Iteration 392000, loss = 0.87987
I0527 00:54:28.217339  4662 solver.cpp:253]     Train net output #0: loss = 0.87987 (* 1 = 0.87987 loss)
I0527 00:54:28.217355  4662 sgd_solver.cpp:106] Iteration 392000, lr = 0.001
I0527 00:54:38.745527  4662 solver.cpp:237] Iteration 392500, loss = 1.31494
I0527 00:54:38.745564  4662 solver.cpp:253]     Train net output #0: loss = 1.31494 (* 1 = 1.31494 loss)
I0527 00:54:38.745578  4662 sgd_solver.cpp:106] Iteration 392500, lr = 0.001
I0527 00:54:49.267240  4662 solver.cpp:237] Iteration 393000, loss = 0.973487
I0527 00:54:49.267284  4662 solver.cpp:253]     Train net output #0: loss = 0.973487 (* 1 = 0.973487 loss)
I0527 00:54:49.267302  4662 sgd_solver.cpp:106] Iteration 393000, lr = 0.001
I0527 00:55:20.726433  4662 solver.cpp:237] Iteration 393500, loss = 1.13536
I0527 00:55:20.726632  4662 solver.cpp:253]     Train net output #0: loss = 1.13536 (* 1 = 1.13536 loss)
I0527 00:55:20.726647  4662 sgd_solver.cpp:106] Iteration 393500, lr = 0.001
I0527 00:55:31.236291  4662 solver.cpp:237] Iteration 394000, loss = 0.533952
I0527 00:55:31.236327  4662 solver.cpp:253]     Train net output #0: loss = 0.533951 (* 1 = 0.533951 loss)
I0527 00:55:31.236341  4662 sgd_solver.cpp:106] Iteration 394000, lr = 0.001
I0527 00:55:41.764461  4662 solver.cpp:237] Iteration 394500, loss = 1.23292
I0527 00:55:41.764508  4662 solver.cpp:253]     Train net output #0: loss = 1.23292 (* 1 = 1.23292 loss)
I0527 00:55:41.764521  4662 sgd_solver.cpp:106] Iteration 394500, lr = 0.001
I0527 00:55:52.268272  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_395000.caffemodel
I0527 00:55:52.321205  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_395000.solverstate
I0527 00:55:52.353489  4662 solver.cpp:237] Iteration 395000, loss = 1.16788
I0527 00:55:52.353533  4662 solver.cpp:253]     Train net output #0: loss = 1.16788 (* 1 = 1.16788 loss)
I0527 00:55:52.353550  4662 sgd_solver.cpp:106] Iteration 395000, lr = 0.001
I0527 00:56:02.876678  4662 solver.cpp:237] Iteration 395500, loss = 1.19399
I0527 00:56:02.876786  4662 solver.cpp:253]     Train net output #0: loss = 1.19399 (* 1 = 1.19399 loss)
I0527 00:56:02.876801  4662 sgd_solver.cpp:106] Iteration 395500, lr = 0.001
I0527 00:56:13.396952  4662 solver.cpp:237] Iteration 396000, loss = 1.03205
I0527 00:56:13.396988  4662 solver.cpp:253]     Train net output #0: loss = 1.03205 (* 1 = 1.03205 loss)
I0527 00:56:13.397002  4662 sgd_solver.cpp:106] Iteration 396000, lr = 0.001
I0527 00:56:23.922688  4662 solver.cpp:237] Iteration 396500, loss = 1.22582
I0527 00:56:23.922863  4662 solver.cpp:253]     Train net output #0: loss = 1.22582 (* 1 = 1.22582 loss)
I0527 00:56:23.922876  4662 sgd_solver.cpp:106] Iteration 396500, lr = 0.001
I0527 00:56:55.347965  4662 solver.cpp:237] Iteration 397000, loss = 1.14526
I0527 00:56:55.348165  4662 solver.cpp:253]     Train net output #0: loss = 1.14526 (* 1 = 1.14526 loss)
I0527 00:56:55.348181  4662 sgd_solver.cpp:106] Iteration 397000, lr = 0.001
I0527 00:57:05.857393  4662 solver.cpp:237] Iteration 397500, loss = 0.842136
I0527 00:57:05.857429  4662 solver.cpp:253]     Train net output #0: loss = 0.842135 (* 1 = 0.842135 loss)
I0527 00:57:05.857445  4662 sgd_solver.cpp:106] Iteration 397500, lr = 0.001
I0527 00:57:16.386189  4662 solver.cpp:237] Iteration 398000, loss = 1.10312
I0527 00:57:16.386240  4662 solver.cpp:253]     Train net output #0: loss = 1.10312 (* 1 = 1.10312 loss)
I0527 00:57:16.386253  4662 sgd_solver.cpp:106] Iteration 398000, lr = 0.001
I0527 00:57:26.928241  4662 solver.cpp:237] Iteration 398500, loss = 1.27022
I0527 00:57:26.928422  4662 solver.cpp:253]     Train net output #0: loss = 1.27022 (* 1 = 1.27022 loss)
I0527 00:57:26.928438  4662 sgd_solver.cpp:106] Iteration 398500, lr = 0.001
I0527 00:57:37.482168  4662 solver.cpp:237] Iteration 399000, loss = 0.96721
I0527 00:57:37.482204  4662 solver.cpp:253]     Train net output #0: loss = 0.967209 (* 1 = 0.967209 loss)
I0527 00:57:37.482218  4662 sgd_solver.cpp:106] Iteration 399000, lr = 0.001
I0527 00:57:48.040269  4662 solver.cpp:237] Iteration 399500, loss = 1.15445
I0527 00:57:48.040319  4662 solver.cpp:253]     Train net output #0: loss = 1.15445 (* 1 = 1.15445 loss)
I0527 00:57:48.040333  4662 sgd_solver.cpp:106] Iteration 399500, lr = 0.001
I0527 00:57:58.571847  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_400000.caffemodel
I0527 00:57:58.625813  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_400000.solverstate
I0527 00:57:58.651373  4662 solver.cpp:341] Iteration 400000, Testing net (#0)
I0527 00:58:47.978163  4662 solver.cpp:409]     Test net output #0: accuracy = 0.902518
I0527 00:58:47.978363  4662 solver.cpp:409]     Test net output #1: loss = 0.30801 (* 1 = 0.30801 loss)
I0527 00:59:08.864018  4662 solver.cpp:237] Iteration 400000, loss = 1.41529
I0527 00:59:08.864069  4662 solver.cpp:253]     Train net output #0: loss = 1.41529 (* 1 = 1.41529 loss)
I0527 00:59:08.864084  4662 sgd_solver.cpp:106] Iteration 400000, lr = 0.001
I0527 00:59:19.404651  4662 solver.cpp:237] Iteration 400500, loss = 1.02923
I0527 00:59:19.404830  4662 solver.cpp:253]     Train net output #0: loss = 1.02923 (* 1 = 1.02923 loss)
I0527 00:59:19.404845  4662 sgd_solver.cpp:106] Iteration 400500, lr = 0.001
I0527 00:59:29.944015  4662 solver.cpp:237] Iteration 401000, loss = 1.09773
I0527 00:59:29.944051  4662 solver.cpp:253]     Train net output #0: loss = 1.09773 (* 1 = 1.09773 loss)
I0527 00:59:29.944063  4662 sgd_solver.cpp:106] Iteration 401000, lr = 0.001
I0527 00:59:40.492223  4662 solver.cpp:237] Iteration 401500, loss = 0.997371
I0527 00:59:40.492260  4662 solver.cpp:253]     Train net output #0: loss = 0.99737 (* 1 = 0.99737 loss)
I0527 00:59:40.492274  4662 sgd_solver.cpp:106] Iteration 401500, lr = 0.001
I0527 00:59:51.037413  4662 solver.cpp:237] Iteration 402000, loss = 1.24893
I0527 00:59:51.037607  4662 solver.cpp:253]     Train net output #0: loss = 1.24893 (* 1 = 1.24893 loss)
I0527 00:59:51.037622  4662 sgd_solver.cpp:106] Iteration 402000, lr = 0.001
I0527 01:00:01.578729  4662 solver.cpp:237] Iteration 402500, loss = 1.01362
I0527 01:00:01.578765  4662 solver.cpp:253]     Train net output #0: loss = 1.01362 (* 1 = 1.01362 loss)
I0527 01:00:01.578778  4662 sgd_solver.cpp:106] Iteration 402500, lr = 0.001
I0527 01:00:12.141216  4662 solver.cpp:237] Iteration 403000, loss = 1.04152
I0527 01:00:12.141263  4662 solver.cpp:253]     Train net output #0: loss = 1.04152 (* 1 = 1.04152 loss)
I0527 01:00:12.141278  4662 sgd_solver.cpp:106] Iteration 403000, lr = 0.001
I0527 01:00:43.538679  4662 solver.cpp:237] Iteration 403500, loss = 0.969728
I0527 01:00:43.538884  4662 solver.cpp:253]     Train net output #0: loss = 0.969728 (* 1 = 0.969728 loss)
I0527 01:00:43.538900  4662 sgd_solver.cpp:106] Iteration 403500, lr = 0.001
I0527 01:00:54.084327  4662 solver.cpp:237] Iteration 404000, loss = 1.25953
I0527 01:00:54.084362  4662 solver.cpp:253]     Train net output #0: loss = 1.25953 (* 1 = 1.25953 loss)
I0527 01:00:54.084377  4662 sgd_solver.cpp:106] Iteration 404000, lr = 0.001
I0527 01:01:04.647017  4662 solver.cpp:237] Iteration 404500, loss = 1.2594
I0527 01:01:04.647066  4662 solver.cpp:253]     Train net output #0: loss = 1.2594 (* 1 = 1.2594 loss)
I0527 01:01:04.647080  4662 sgd_solver.cpp:106] Iteration 404500, lr = 0.001
I0527 01:01:15.165482  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_405000.caffemodel
I0527 01:01:15.221091  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_405000.solverstate
I0527 01:01:15.254499  4662 solver.cpp:237] Iteration 405000, loss = 1.62707
I0527 01:01:15.254549  4662 solver.cpp:253]     Train net output #0: loss = 1.62707 (* 1 = 1.62707 loss)
I0527 01:01:15.254562  4662 sgd_solver.cpp:106] Iteration 405000, lr = 0.001
I0527 01:01:25.813081  4662 solver.cpp:237] Iteration 405500, loss = 0.886467
I0527 01:01:25.813133  4662 solver.cpp:253]     Train net output #0: loss = 0.886467 (* 1 = 0.886467 loss)
I0527 01:01:25.813148  4662 sgd_solver.cpp:106] Iteration 405500, lr = 0.001
I0527 01:01:36.364917  4662 solver.cpp:237] Iteration 406000, loss = 1.5837
I0527 01:01:36.364953  4662 solver.cpp:253]     Train net output #0: loss = 1.5837 (* 1 = 1.5837 loss)
I0527 01:01:36.364970  4662 sgd_solver.cpp:106] Iteration 406000, lr = 0.001
I0527 01:01:46.914981  4662 solver.cpp:237] Iteration 406500, loss = 1.30235
I0527 01:01:46.915156  4662 solver.cpp:253]     Train net output #0: loss = 1.30235 (* 1 = 1.30235 loss)
I0527 01:01:46.915170  4662 sgd_solver.cpp:106] Iteration 406500, lr = 0.001
I0527 01:02:18.337028  4662 solver.cpp:237] Iteration 407000, loss = 1.28724
I0527 01:02:18.337218  4662 solver.cpp:253]     Train net output #0: loss = 1.28724 (* 1 = 1.28724 loss)
I0527 01:02:18.337234  4662 sgd_solver.cpp:106] Iteration 407000, lr = 0.001
I0527 01:02:28.892730  4662 solver.cpp:237] Iteration 407500, loss = 1.18505
I0527 01:02:28.892766  4662 solver.cpp:253]     Train net output #0: loss = 1.18505 (* 1 = 1.18505 loss)
I0527 01:02:28.892779  4662 sgd_solver.cpp:106] Iteration 407500, lr = 0.001
I0527 01:02:39.454689  4662 solver.cpp:237] Iteration 408000, loss = 1.19937
I0527 01:02:39.454738  4662 solver.cpp:253]     Train net output #0: loss = 1.19937 (* 1 = 1.19937 loss)
I0527 01:02:39.454754  4662 sgd_solver.cpp:106] Iteration 408000, lr = 0.001
I0527 01:02:50.013597  4662 solver.cpp:237] Iteration 408500, loss = 1.29472
I0527 01:02:50.013769  4662 solver.cpp:253]     Train net output #0: loss = 1.29472 (* 1 = 1.29472 loss)
I0527 01:02:50.013785  4662 sgd_solver.cpp:106] Iteration 408500, lr = 0.001
I0527 01:03:00.558039  4662 solver.cpp:237] Iteration 409000, loss = 1.56239
I0527 01:03:00.558074  4662 solver.cpp:253]     Train net output #0: loss = 1.56239 (* 1 = 1.56239 loss)
I0527 01:03:00.558089  4662 sgd_solver.cpp:106] Iteration 409000, lr = 0.001
I0527 01:03:11.118217  4662 solver.cpp:237] Iteration 409500, loss = 1.37332
I0527 01:03:11.118265  4662 solver.cpp:253]     Train net output #0: loss = 1.37332 (* 1 = 1.37332 loss)
I0527 01:03:11.118279  4662 sgd_solver.cpp:106] Iteration 409500, lr = 0.001
I0527 01:03:21.634178  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_410000.caffemodel
I0527 01:03:21.689362  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_410000.solverstate
I0527 01:03:21.716146  4662 solver.cpp:341] Iteration 410000, Testing net (#0)
I0527 01:04:32.106914  4662 solver.cpp:409]     Test net output #0: accuracy = 0.900618
I0527 01:04:32.107105  4662 solver.cpp:409]     Test net output #1: loss = 0.315113 (* 1 = 0.315113 loss)
I0527 01:04:52.966768  4662 solver.cpp:237] Iteration 410000, loss = 1.14203
I0527 01:04:52.966820  4662 solver.cpp:253]     Train net output #0: loss = 1.14203 (* 1 = 1.14203 loss)
I0527 01:04:52.966836  4662 sgd_solver.cpp:106] Iteration 410000, lr = 0.001
I0527 01:05:03.532541  4662 solver.cpp:237] Iteration 410500, loss = 1.10652
I0527 01:05:03.532712  4662 solver.cpp:253]     Train net output #0: loss = 1.10652 (* 1 = 1.10652 loss)
I0527 01:05:03.532727  4662 sgd_solver.cpp:106] Iteration 410500, lr = 0.001
I0527 01:05:14.081486  4662 solver.cpp:237] Iteration 411000, loss = 0.874257
I0527 01:05:14.081529  4662 solver.cpp:253]     Train net output #0: loss = 0.874257 (* 1 = 0.874257 loss)
I0527 01:05:14.081543  4662 sgd_solver.cpp:106] Iteration 411000, lr = 0.001
I0527 01:05:24.628831  4662 solver.cpp:237] Iteration 411500, loss = 1.53253
I0527 01:05:24.628866  4662 solver.cpp:253]     Train net output #0: loss = 1.53253 (* 1 = 1.53253 loss)
I0527 01:05:24.628883  4662 sgd_solver.cpp:106] Iteration 411500, lr = 0.001
I0527 01:05:35.201778  4662 solver.cpp:237] Iteration 412000, loss = 0.902251
I0527 01:05:35.201962  4662 solver.cpp:253]     Train net output #0: loss = 0.90225 (* 1 = 0.90225 loss)
I0527 01:05:35.201979  4662 sgd_solver.cpp:106] Iteration 412000, lr = 0.001
I0527 01:05:45.791352  4662 solver.cpp:237] Iteration 412500, loss = 1.43706
I0527 01:05:45.791388  4662 solver.cpp:253]     Train net output #0: loss = 1.43706 (* 1 = 1.43706 loss)
I0527 01:05:45.791400  4662 sgd_solver.cpp:106] Iteration 412500, lr = 0.001
I0527 01:05:56.362059  4662 solver.cpp:237] Iteration 413000, loss = 1.39577
I0527 01:05:56.362094  4662 solver.cpp:253]     Train net output #0: loss = 1.39577 (* 1 = 1.39577 loss)
I0527 01:05:56.362112  4662 sgd_solver.cpp:106] Iteration 413000, lr = 0.001
I0527 01:06:27.800838  4662 solver.cpp:237] Iteration 413500, loss = 1.08209
I0527 01:06:27.801030  4662 solver.cpp:253]     Train net output #0: loss = 1.08209 (* 1 = 1.08209 loss)
I0527 01:06:27.801044  4662 sgd_solver.cpp:106] Iteration 413500, lr = 0.001
I0527 01:06:38.383481  4662 solver.cpp:237] Iteration 414000, loss = 1.02339
I0527 01:06:38.383515  4662 solver.cpp:253]     Train net output #0: loss = 1.02339 (* 1 = 1.02339 loss)
I0527 01:06:38.383529  4662 sgd_solver.cpp:106] Iteration 414000, lr = 0.001
I0527 01:06:48.972506  4662 solver.cpp:237] Iteration 414500, loss = 1.35116
I0527 01:06:48.972543  4662 solver.cpp:253]     Train net output #0: loss = 1.35116 (* 1 = 1.35116 loss)
I0527 01:06:48.972555  4662 sgd_solver.cpp:106] Iteration 414500, lr = 0.001
I0527 01:06:59.546129  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_415000.caffemodel
I0527 01:06:59.598877  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_415000.solverstate
I0527 01:06:59.630858  4662 solver.cpp:237] Iteration 415000, loss = 0.952538
I0527 01:06:59.630899  4662 solver.cpp:253]     Train net output #0: loss = 0.952537 (* 1 = 0.952537 loss)
I0527 01:06:59.630921  4662 sgd_solver.cpp:106] Iteration 415000, lr = 0.001
I0527 01:07:10.217751  4662 solver.cpp:237] Iteration 415500, loss = 1.48703
I0527 01:07:10.217788  4662 solver.cpp:253]     Train net output #0: loss = 1.48703 (* 1 = 1.48703 loss)
I0527 01:07:10.217803  4662 sgd_solver.cpp:106] Iteration 415500, lr = 0.001
I0527 01:07:20.811240  4662 solver.cpp:237] Iteration 416000, loss = 0.922029
I0527 01:07:20.811288  4662 solver.cpp:253]     Train net output #0: loss = 0.922029 (* 1 = 0.922029 loss)
I0527 01:07:20.811302  4662 sgd_solver.cpp:106] Iteration 416000, lr = 0.001
I0527 01:07:31.391351  4662 solver.cpp:237] Iteration 416500, loss = 1.0432
I0527 01:07:31.391538  4662 solver.cpp:253]     Train net output #0: loss = 1.0432 (* 1 = 1.0432 loss)
I0527 01:07:31.391553  4662 sgd_solver.cpp:106] Iteration 416500, lr = 0.001
I0527 01:08:02.852183  4662 solver.cpp:237] Iteration 417000, loss = 1.07618
I0527 01:08:02.852380  4662 solver.cpp:253]     Train net output #0: loss = 1.07618 (* 1 = 1.07618 loss)
I0527 01:08:02.852396  4662 sgd_solver.cpp:106] Iteration 417000, lr = 0.001
I0527 01:08:13.456641  4662 solver.cpp:237] Iteration 417500, loss = 1.27627
I0527 01:08:13.456683  4662 solver.cpp:253]     Train net output #0: loss = 1.27627 (* 1 = 1.27627 loss)
I0527 01:08:13.456701  4662 sgd_solver.cpp:106] Iteration 417500, lr = 0.001
I0527 01:08:24.036415  4662 solver.cpp:237] Iteration 418000, loss = 0.893308
I0527 01:08:24.036453  4662 solver.cpp:253]     Train net output #0: loss = 0.893308 (* 1 = 0.893308 loss)
I0527 01:08:24.036468  4662 sgd_solver.cpp:106] Iteration 418000, lr = 0.001
I0527 01:08:34.615121  4662 solver.cpp:237] Iteration 418500, loss = 1.2146
I0527 01:08:34.615310  4662 solver.cpp:253]     Train net output #0: loss = 1.2146 (* 1 = 1.2146 loss)
I0527 01:08:34.615324  4662 sgd_solver.cpp:106] Iteration 418500, lr = 0.001
I0527 01:08:45.197332  4662 solver.cpp:237] Iteration 419000, loss = 1.07279
I0527 01:08:45.197368  4662 solver.cpp:253]     Train net output #0: loss = 1.07279 (* 1 = 1.07279 loss)
I0527 01:08:45.197381  4662 sgd_solver.cpp:106] Iteration 419000, lr = 0.001
I0527 01:08:55.784169  4662 solver.cpp:237] Iteration 419500, loss = 1.0737
I0527 01:08:55.784216  4662 solver.cpp:253]     Train net output #0: loss = 1.07369 (* 1 = 1.07369 loss)
I0527 01:08:55.784230  4662 sgd_solver.cpp:106] Iteration 419500, lr = 0.001
I0527 01:09:06.354048  4662 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_420000.caffemodel
I0527 01:09:06.406842  4662 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0010_2016-05-20T15.48.57.685382_iter_420000.solverstate
I0527 01:09:06.432132  4662 solver.cpp:341] Iteration 420000, Testing net (#0)
I0527 01:09:56.024833  4662 solver.cpp:409]     Test net output #0: accuracy = 0.900311
I0527 01:09:56.025023  4662 solver.cpp:409]     Test net output #1: loss = 0.313371 (* 1 = 0.313371 loss)
I0527 01:10:16.951583  4662 solver.cpp:237] Iteration 420000, loss = 0.994154
I0527 01:10:16.951637  4662 solver.cpp:253]     Train net output #0: loss = 0.994154 (* 1 = 0.994154 loss)
I0527 01:10:16.951653  4662 sgd_solver.cpp:106] Iteration 420000, lr = 0.001
I0527 01:10:27.505538  4662 solver.cpp:237] Iteration 420500, loss = 1.10723
I0527 01:10:27.505718  4662 solver.cpp:253]     Train net output #0: loss = 1.10723 (* 1 = 1.10723 loss)
I0527 01:10:27.505733  4662 sgd_solver.cpp:106] Iteration 420500, lr = 0.001
I0527 01:10:38.043715  4662 solver.cpp:237] Iteration 421000, loss = 1.14058
I0527 01:10:38.043761  4662 solver.cpp:253]     Train net output #0: loss = 1.14058 (* 1 = 1.14058 loss)
I0527 01:10:38.043777  4662 sgd_solver.cpp:106] Iteration 421000, lr = 0.001
I0527 01:10:48.594310  4662 solver.cpp:237] Iteration 421500, loss = 1.39902
I0527 01:10:48.594347  4662 solver.cpp:253]     Train net output #0: loss = 1.39902 (* 1 = 1.39902 loss)
I0527 01:10:48.594364  4662 sgd_solver.cpp:106] Iteration 421500, lr = 0.001
I0527 01:10:59.142499  4662 solver.cpp:237] Iteration 422000, loss = 1.11813
I0527 01:10:59.142691  4662 solver.cpp:253]     Train net output #0: loss = 1.11812 (* 1 = 1.11812 loss)
I0527 01:10:59.142705  4662 sgd_solver.cpp:106] Iteration 422000, lr = 0.001
I0527 01:11:09.679879  4662 solver.cpp:237] Iteration 422500, loss = 0.805961
I0527 01:11:09.679927  4662 solver.cpp:253]     Train net output #0: loss = 0.80596 (* 1 = 0.80596 loss)
I0527 01:11:09.679942  4662 sgd_solver.cpp:106] Iteration 422500, lr = 0.001
I0527 01:11:20.230403  4662 solver.cpp:237] Iteration 423000, loss = 1.159
I0527 01:11:20.230439  4662 solver.cpp:253]     Train net output #0: loss = 1.159 (* 1 = 1.159 loss)
I0527 01:11:20.230455  4662 sgd_solver.cpp:106] Iteration 423000, lr = 0.001
I0527 01:11:51.666504  4662 solver.cpp:237] Iteration 423500, loss = 1.12119
I0527 01:11:51.666715  4662 solver.cpp:253]     Train net output #0: loss = 1.12118 (* 1 = 1.12118 loss)
I0527 01:11:51.666730  4662 sgd_solver.cpp:106] Iteration 423500, lr = 0.001
I0527 01:12:02.219192  4662 solver.cpp:237] Iteration 424000, loss = 0.934628
I0527 01:12:02.219229  4662 solver.cpp:253]     Train net output #0: loss = 0.934627 (* 1 = 0.934627 loss)
I0527 01:12:02.219245  4662 sgd_solver.cpp:106] Iteration 424000, lr = 0.001
I0527 01:12:12.761734  4662 solver.cpp:237] Iteration 424500, loss = 1.49511
I0527 01:12:12.761770  4662 solver.cpp:253]     Train net output #0: loss = 1.49511 (* 1 = 1.49511 loss)
I0527 01:12:12.761782  4662 sgd_solver.cpp:106] Iteration 424500, lr = 0.001
aprun: Apid 11270828: Caught signal Terminated, sending to application
*** Aborted at 1464325937 (unix time) try "date -d @1464325937" if you are using GNU date ***
aprun: Apid 11270828: Caught signal Terminated, sending to application
PC: @     0x2aaab9276640 (unknown)
aprun: Apid 11270828: Caught signal Terminated, sending to application
*** SIGTERM (@0x1231) received by PID 4662 (TID 0x2aaac746f900) from PID 4657; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab9276640 (unknown)
=>> PBS: job killed: walltime 7242 exceeded limit 7200
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
    @     0x2aaab928a368 (unknown)
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11270828: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
aprun: Apid 11270828: Caught signal Terminated, sending to application
