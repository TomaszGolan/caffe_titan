2809875
I0525 02:48:03.291618 22565 caffe.cpp:184] Using GPUs 0
I0525 02:48:03.717815 22565 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1875
test_interval: 3750
base_lr: 0.005
display: 187
max_iter: 187500
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1875
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379.prototxt"
I0525 02:48:03.719900 22565 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379.prototxt
I0525 02:48:03.730847 22565 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 02:48:03.730912 22565 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 02:48:03.731298 22565 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 80
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 02:48:03.731505 22565 layer_factory.hpp:77] Creating layer data_hdf5
I0525 02:48:03.731534 22565 net.cpp:106] Creating Layer data_hdf5
I0525 02:48:03.731552 22565 net.cpp:411] data_hdf5 -> data
I0525 02:48:03.731585 22565 net.cpp:411] data_hdf5 -> label
I0525 02:48:03.731631 22565 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 02:48:03.746742 22565 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 02:48:03.749047 22565 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 02:48:25.221295 22565 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 02:48:25.226501 22565 net.cpp:150] Setting up data_hdf5
I0525 02:48:25.226541 22565 net.cpp:157] Top shape: 80 1 127 50 (508000)
I0525 02:48:25.226559 22565 net.cpp:157] Top shape: 80 (80)
I0525 02:48:25.226572 22565 net.cpp:165] Memory required for data: 2032320
I0525 02:48:25.226591 22565 layer_factory.hpp:77] Creating layer conv1
I0525 02:48:25.226641 22565 net.cpp:106] Creating Layer conv1
I0525 02:48:25.226665 22565 net.cpp:454] conv1 <- data
I0525 02:48:25.226691 22565 net.cpp:411] conv1 -> conv1
I0525 02:48:25.604086 22565 net.cpp:150] Setting up conv1
I0525 02:48:25.604143 22565 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 02:48:25.604166 22565 net.cpp:165] Memory required for data: 24150720
I0525 02:48:25.604197 22565 layer_factory.hpp:77] Creating layer relu1
I0525 02:48:25.604218 22565 net.cpp:106] Creating Layer relu1
I0525 02:48:25.604239 22565 net.cpp:454] relu1 <- conv1
I0525 02:48:25.604284 22565 net.cpp:397] relu1 -> conv1 (in-place)
I0525 02:48:25.604811 22565 net.cpp:150] Setting up relu1
I0525 02:48:25.604835 22565 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 02:48:25.604849 22565 net.cpp:165] Memory required for data: 46269120
I0525 02:48:25.604866 22565 layer_factory.hpp:77] Creating layer pool1
I0525 02:48:25.604892 22565 net.cpp:106] Creating Layer pool1
I0525 02:48:25.604907 22565 net.cpp:454] pool1 <- conv1
I0525 02:48:25.604923 22565 net.cpp:411] pool1 -> pool1
I0525 02:48:25.605015 22565 net.cpp:150] Setting up pool1
I0525 02:48:25.605033 22565 net.cpp:157] Top shape: 80 12 60 48 (2764800)
I0525 02:48:25.605048 22565 net.cpp:165] Memory required for data: 57328320
I0525 02:48:25.605069 22565 layer_factory.hpp:77] Creating layer conv2
I0525 02:48:25.605094 22565 net.cpp:106] Creating Layer conv2
I0525 02:48:25.605108 22565 net.cpp:454] conv2 <- pool1
I0525 02:48:25.605128 22565 net.cpp:411] conv2 -> conv2
I0525 02:48:25.607851 22565 net.cpp:150] Setting up conv2
I0525 02:48:25.607882 22565 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 02:48:25.607897 22565 net.cpp:165] Memory required for data: 73225920
I0525 02:48:25.607920 22565 layer_factory.hpp:77] Creating layer relu2
I0525 02:48:25.607954 22565 net.cpp:106] Creating Layer relu2
I0525 02:48:25.607967 22565 net.cpp:454] relu2 <- conv2
I0525 02:48:25.607983 22565 net.cpp:397] relu2 -> conv2 (in-place)
I0525 02:48:25.608350 22565 net.cpp:150] Setting up relu2
I0525 02:48:25.608371 22565 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 02:48:25.608384 22565 net.cpp:165] Memory required for data: 89123520
I0525 02:48:25.608399 22565 layer_factory.hpp:77] Creating layer pool2
I0525 02:48:25.608422 22565 net.cpp:106] Creating Layer pool2
I0525 02:48:25.608436 22565 net.cpp:454] pool2 <- conv2
I0525 02:48:25.608451 22565 net.cpp:411] pool2 -> pool2
I0525 02:48:25.608547 22565 net.cpp:150] Setting up pool2
I0525 02:48:25.608566 22565 net.cpp:157] Top shape: 80 20 27 46 (1987200)
I0525 02:48:25.608580 22565 net.cpp:165] Memory required for data: 97072320
I0525 02:48:25.608598 22565 layer_factory.hpp:77] Creating layer conv3
I0525 02:48:25.608620 22565 net.cpp:106] Creating Layer conv3
I0525 02:48:25.608633 22565 net.cpp:454] conv3 <- pool2
I0525 02:48:25.608649 22565 net.cpp:411] conv3 -> conv3
I0525 02:48:25.610591 22565 net.cpp:150] Setting up conv3
I0525 02:48:25.610616 22565 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 02:48:25.610637 22565 net.cpp:165] Memory required for data: 105745600
I0525 02:48:25.610659 22565 layer_factory.hpp:77] Creating layer relu3
I0525 02:48:25.610682 22565 net.cpp:106] Creating Layer relu3
I0525 02:48:25.610704 22565 net.cpp:454] relu3 <- conv3
I0525 02:48:25.610720 22565 net.cpp:397] relu3 -> conv3 (in-place)
I0525 02:48:25.611208 22565 net.cpp:150] Setting up relu3
I0525 02:48:25.611232 22565 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 02:48:25.611245 22565 net.cpp:165] Memory required for data: 114418880
I0525 02:48:25.611261 22565 layer_factory.hpp:77] Creating layer pool3
I0525 02:48:25.611276 22565 net.cpp:106] Creating Layer pool3
I0525 02:48:25.611290 22565 net.cpp:454] pool3 <- conv3
I0525 02:48:25.611315 22565 net.cpp:411] pool3 -> pool3
I0525 02:48:25.611395 22565 net.cpp:150] Setting up pool3
I0525 02:48:25.611413 22565 net.cpp:157] Top shape: 80 28 11 44 (1084160)
I0525 02:48:25.611428 22565 net.cpp:165] Memory required for data: 118755520
I0525 02:48:25.611440 22565 layer_factory.hpp:77] Creating layer conv4
I0525 02:48:25.611460 22565 net.cpp:106] Creating Layer conv4
I0525 02:48:25.611480 22565 net.cpp:454] conv4 <- pool3
I0525 02:48:25.611498 22565 net.cpp:411] conv4 -> conv4
I0525 02:48:25.614459 22565 net.cpp:150] Setting up conv4
I0525 02:48:25.614493 22565 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 02:48:25.614507 22565 net.cpp:165] Memory required for data: 121658560
I0525 02:48:25.614531 22565 layer_factory.hpp:77] Creating layer relu4
I0525 02:48:25.614559 22565 net.cpp:106] Creating Layer relu4
I0525 02:48:25.614573 22565 net.cpp:454] relu4 <- conv4
I0525 02:48:25.614589 22565 net.cpp:397] relu4 -> conv4 (in-place)
I0525 02:48:25.615082 22565 net.cpp:150] Setting up relu4
I0525 02:48:25.615104 22565 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 02:48:25.615118 22565 net.cpp:165] Memory required for data: 124561600
I0525 02:48:25.615134 22565 layer_factory.hpp:77] Creating layer pool4
I0525 02:48:25.615156 22565 net.cpp:106] Creating Layer pool4
I0525 02:48:25.615170 22565 net.cpp:454] pool4 <- conv4
I0525 02:48:25.615186 22565 net.cpp:411] pool4 -> pool4
I0525 02:48:25.615268 22565 net.cpp:150] Setting up pool4
I0525 02:48:25.615285 22565 net.cpp:157] Top shape: 80 36 3 42 (362880)
I0525 02:48:25.615300 22565 net.cpp:165] Memory required for data: 126013120
I0525 02:48:25.615312 22565 layer_factory.hpp:77] Creating layer ip1
I0525 02:48:25.615340 22565 net.cpp:106] Creating Layer ip1
I0525 02:48:25.615355 22565 net.cpp:454] ip1 <- pool4
I0525 02:48:25.615370 22565 net.cpp:411] ip1 -> ip1
I0525 02:48:25.630723 22565 net.cpp:150] Setting up ip1
I0525 02:48:25.630753 22565 net.cpp:157] Top shape: 80 196 (15680)
I0525 02:48:25.630775 22565 net.cpp:165] Memory required for data: 126075840
I0525 02:48:25.630800 22565 layer_factory.hpp:77] Creating layer relu5
I0525 02:48:25.630823 22565 net.cpp:106] Creating Layer relu5
I0525 02:48:25.630848 22565 net.cpp:454] relu5 <- ip1
I0525 02:48:25.630866 22565 net.cpp:397] relu5 -> ip1 (in-place)
I0525 02:48:25.631222 22565 net.cpp:150] Setting up relu5
I0525 02:48:25.631242 22565 net.cpp:157] Top shape: 80 196 (15680)
I0525 02:48:25.631254 22565 net.cpp:165] Memory required for data: 126138560
I0525 02:48:25.631269 22565 layer_factory.hpp:77] Creating layer drop1
I0525 02:48:25.631299 22565 net.cpp:106] Creating Layer drop1
I0525 02:48:25.631314 22565 net.cpp:454] drop1 <- ip1
I0525 02:48:25.631337 22565 net.cpp:397] drop1 -> ip1 (in-place)
I0525 02:48:25.631412 22565 net.cpp:150] Setting up drop1
I0525 02:48:25.631436 22565 net.cpp:157] Top shape: 80 196 (15680)
I0525 02:48:25.631449 22565 net.cpp:165] Memory required for data: 126201280
I0525 02:48:25.631465 22565 layer_factory.hpp:77] Creating layer ip2
I0525 02:48:25.631492 22565 net.cpp:106] Creating Layer ip2
I0525 02:48:25.631506 22565 net.cpp:454] ip2 <- ip1
I0525 02:48:25.631522 22565 net.cpp:411] ip2 -> ip2
I0525 02:48:25.632009 22565 net.cpp:150] Setting up ip2
I0525 02:48:25.632027 22565 net.cpp:157] Top shape: 80 98 (7840)
I0525 02:48:25.632040 22565 net.cpp:165] Memory required for data: 126232640
I0525 02:48:25.632061 22565 layer_factory.hpp:77] Creating layer relu6
I0525 02:48:25.632076 22565 net.cpp:106] Creating Layer relu6
I0525 02:48:25.632094 22565 net.cpp:454] relu6 <- ip2
I0525 02:48:25.632110 22565 net.cpp:397] relu6 -> ip2 (in-place)
I0525 02:48:25.632673 22565 net.cpp:150] Setting up relu6
I0525 02:48:25.632694 22565 net.cpp:157] Top shape: 80 98 (7840)
I0525 02:48:25.632707 22565 net.cpp:165] Memory required for data: 126264000
I0525 02:48:25.632724 22565 layer_factory.hpp:77] Creating layer drop2
I0525 02:48:25.632740 22565 net.cpp:106] Creating Layer drop2
I0525 02:48:25.632761 22565 net.cpp:454] drop2 <- ip2
I0525 02:48:25.632776 22565 net.cpp:397] drop2 -> ip2 (in-place)
I0525 02:48:25.632827 22565 net.cpp:150] Setting up drop2
I0525 02:48:25.632843 22565 net.cpp:157] Top shape: 80 98 (7840)
I0525 02:48:25.632860 22565 net.cpp:165] Memory required for data: 126295360
I0525 02:48:25.632874 22565 layer_factory.hpp:77] Creating layer ip3
I0525 02:48:25.632892 22565 net.cpp:106] Creating Layer ip3
I0525 02:48:25.632905 22565 net.cpp:454] ip3 <- ip2
I0525 02:48:25.632921 22565 net.cpp:411] ip3 -> ip3
I0525 02:48:25.633152 22565 net.cpp:150] Setting up ip3
I0525 02:48:25.633170 22565 net.cpp:157] Top shape: 80 11 (880)
I0525 02:48:25.633183 22565 net.cpp:165] Memory required for data: 126298880
I0525 02:48:25.633203 22565 layer_factory.hpp:77] Creating layer drop3
I0525 02:48:25.633225 22565 net.cpp:106] Creating Layer drop3
I0525 02:48:25.633239 22565 net.cpp:454] drop3 <- ip3
I0525 02:48:25.633254 22565 net.cpp:397] drop3 -> ip3 (in-place)
I0525 02:48:25.633299 22565 net.cpp:150] Setting up drop3
I0525 02:48:25.633322 22565 net.cpp:157] Top shape: 80 11 (880)
I0525 02:48:25.633335 22565 net.cpp:165] Memory required for data: 126302400
I0525 02:48:25.633354 22565 layer_factory.hpp:77] Creating layer loss
I0525 02:48:25.633375 22565 net.cpp:106] Creating Layer loss
I0525 02:48:25.633390 22565 net.cpp:454] loss <- ip3
I0525 02:48:25.633410 22565 net.cpp:454] loss <- label
I0525 02:48:25.633426 22565 net.cpp:411] loss -> loss
I0525 02:48:25.633445 22565 layer_factory.hpp:77] Creating layer loss
I0525 02:48:25.634116 22565 net.cpp:150] Setting up loss
I0525 02:48:25.634138 22565 net.cpp:157] Top shape: (1)
I0525 02:48:25.634155 22565 net.cpp:160]     with loss weight 1
I0525 02:48:25.634207 22565 net.cpp:165] Memory required for data: 126302404
I0525 02:48:25.634229 22565 net.cpp:226] loss needs backward computation.
I0525 02:48:25.634243 22565 net.cpp:226] drop3 needs backward computation.
I0525 02:48:25.634256 22565 net.cpp:226] ip3 needs backward computation.
I0525 02:48:25.634269 22565 net.cpp:226] drop2 needs backward computation.
I0525 02:48:25.634281 22565 net.cpp:226] relu6 needs backward computation.
I0525 02:48:25.634296 22565 net.cpp:226] ip2 needs backward computation.
I0525 02:48:25.634315 22565 net.cpp:226] drop1 needs backward computation.
I0525 02:48:25.634327 22565 net.cpp:226] relu5 needs backward computation.
I0525 02:48:25.634341 22565 net.cpp:226] ip1 needs backward computation.
I0525 02:48:25.634353 22565 net.cpp:226] pool4 needs backward computation.
I0525 02:48:25.634366 22565 net.cpp:226] relu4 needs backward computation.
I0525 02:48:25.634380 22565 net.cpp:226] conv4 needs backward computation.
I0525 02:48:25.634393 22565 net.cpp:226] pool3 needs backward computation.
I0525 02:48:25.634413 22565 net.cpp:226] relu3 needs backward computation.
I0525 02:48:25.634435 22565 net.cpp:226] conv3 needs backward computation.
I0525 02:48:25.634449 22565 net.cpp:226] pool2 needs backward computation.
I0525 02:48:25.634462 22565 net.cpp:226] relu2 needs backward computation.
I0525 02:48:25.634477 22565 net.cpp:226] conv2 needs backward computation.
I0525 02:48:25.634497 22565 net.cpp:226] pool1 needs backward computation.
I0525 02:48:25.634511 22565 net.cpp:226] relu1 needs backward computation.
I0525 02:48:25.634523 22565 net.cpp:226] conv1 needs backward computation.
I0525 02:48:25.634537 22565 net.cpp:228] data_hdf5 does not need backward computation.
I0525 02:48:25.634549 22565 net.cpp:270] This network produces output loss
I0525 02:48:25.634578 22565 net.cpp:283] Network initialization done.
I0525 02:48:25.636296 22565 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379.prototxt
I0525 02:48:25.636371 22565 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 02:48:25.636728 22565 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 80
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 02:48:25.636927 22565 layer_factory.hpp:77] Creating layer data_hdf5
I0525 02:48:25.636945 22565 net.cpp:106] Creating Layer data_hdf5
I0525 02:48:25.636961 22565 net.cpp:411] data_hdf5 -> data
I0525 02:48:25.636981 22565 net.cpp:411] data_hdf5 -> label
I0525 02:48:25.636999 22565 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 02:48:25.638381 22565 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 02:48:46.922021 22565 net.cpp:150] Setting up data_hdf5
I0525 02:48:46.922191 22565 net.cpp:157] Top shape: 80 1 127 50 (508000)
I0525 02:48:46.922210 22565 net.cpp:157] Top shape: 80 (80)
I0525 02:48:46.922224 22565 net.cpp:165] Memory required for data: 2032320
I0525 02:48:46.922238 22565 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 02:48:46.922271 22565 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 02:48:46.922284 22565 net.cpp:454] label_data_hdf5_1_split <- label
I0525 02:48:46.922302 22565 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 02:48:46.922323 22565 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 02:48:46.922399 22565 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 02:48:46.922416 22565 net.cpp:157] Top shape: 80 (80)
I0525 02:48:46.922432 22565 net.cpp:157] Top shape: 80 (80)
I0525 02:48:46.922444 22565 net.cpp:165] Memory required for data: 2032960
I0525 02:48:46.922497 22565 layer_factory.hpp:77] Creating layer conv1
I0525 02:48:46.922521 22565 net.cpp:106] Creating Layer conv1
I0525 02:48:46.922549 22565 net.cpp:454] conv1 <- data
I0525 02:48:46.922575 22565 net.cpp:411] conv1 -> conv1
I0525 02:48:46.924564 22565 net.cpp:150] Setting up conv1
I0525 02:48:46.924590 22565 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 02:48:46.924603 22565 net.cpp:165] Memory required for data: 24151360
I0525 02:48:46.924630 22565 layer_factory.hpp:77] Creating layer relu1
I0525 02:48:46.924657 22565 net.cpp:106] Creating Layer relu1
I0525 02:48:46.924670 22565 net.cpp:454] relu1 <- conv1
I0525 02:48:46.924686 22565 net.cpp:397] relu1 -> conv1 (in-place)
I0525 02:48:46.925211 22565 net.cpp:150] Setting up relu1
I0525 02:48:46.925235 22565 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 02:48:46.925247 22565 net.cpp:165] Memory required for data: 46269760
I0525 02:48:46.925263 22565 layer_factory.hpp:77] Creating layer pool1
I0525 02:48:46.925289 22565 net.cpp:106] Creating Layer pool1
I0525 02:48:46.925303 22565 net.cpp:454] pool1 <- conv1
I0525 02:48:46.925319 22565 net.cpp:411] pool1 -> pool1
I0525 02:48:46.925407 22565 net.cpp:150] Setting up pool1
I0525 02:48:46.925425 22565 net.cpp:157] Top shape: 80 12 60 48 (2764800)
I0525 02:48:46.925439 22565 net.cpp:165] Memory required for data: 57328960
I0525 02:48:46.925451 22565 layer_factory.hpp:77] Creating layer conv2
I0525 02:48:46.925479 22565 net.cpp:106] Creating Layer conv2
I0525 02:48:46.925500 22565 net.cpp:454] conv2 <- pool1
I0525 02:48:46.925518 22565 net.cpp:411] conv2 -> conv2
I0525 02:48:46.927460 22565 net.cpp:150] Setting up conv2
I0525 02:48:46.927484 22565 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 02:48:46.927505 22565 net.cpp:165] Memory required for data: 73226560
I0525 02:48:46.927526 22565 layer_factory.hpp:77] Creating layer relu2
I0525 02:48:46.927546 22565 net.cpp:106] Creating Layer relu2
I0525 02:48:46.927558 22565 net.cpp:454] relu2 <- conv2
I0525 02:48:46.927583 22565 net.cpp:397] relu2 -> conv2 (in-place)
I0525 02:48:46.927934 22565 net.cpp:150] Setting up relu2
I0525 02:48:46.927953 22565 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 02:48:46.927966 22565 net.cpp:165] Memory required for data: 89124160
I0525 02:48:46.927978 22565 layer_factory.hpp:77] Creating layer pool2
I0525 02:48:46.927997 22565 net.cpp:106] Creating Layer pool2
I0525 02:48:46.928019 22565 net.cpp:454] pool2 <- conv2
I0525 02:48:46.928033 22565 net.cpp:411] pool2 -> pool2
I0525 02:48:46.928122 22565 net.cpp:150] Setting up pool2
I0525 02:48:46.928144 22565 net.cpp:157] Top shape: 80 20 27 46 (1987200)
I0525 02:48:46.928158 22565 net.cpp:165] Memory required for data: 97072960
I0525 02:48:46.928172 22565 layer_factory.hpp:77] Creating layer conv3
I0525 02:48:46.928200 22565 net.cpp:106] Creating Layer conv3
I0525 02:48:46.928215 22565 net.cpp:454] conv3 <- pool2
I0525 02:48:46.928231 22565 net.cpp:411] conv3 -> conv3
I0525 02:48:46.930256 22565 net.cpp:150] Setting up conv3
I0525 02:48:46.930281 22565 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 02:48:46.930300 22565 net.cpp:165] Memory required for data: 105746240
I0525 02:48:46.930340 22565 layer_factory.hpp:77] Creating layer relu3
I0525 02:48:46.930366 22565 net.cpp:106] Creating Layer relu3
I0525 02:48:46.930379 22565 net.cpp:454] relu3 <- conv3
I0525 02:48:46.930395 22565 net.cpp:397] relu3 -> conv3 (in-place)
I0525 02:48:46.930909 22565 net.cpp:150] Setting up relu3
I0525 02:48:46.930933 22565 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 02:48:46.930946 22565 net.cpp:165] Memory required for data: 114419520
I0525 02:48:46.930959 22565 layer_factory.hpp:77] Creating layer pool3
I0525 02:48:46.930979 22565 net.cpp:106] Creating Layer pool3
I0525 02:48:46.930994 22565 net.cpp:454] pool3 <- conv3
I0525 02:48:46.931018 22565 net.cpp:411] pool3 -> pool3
I0525 02:48:46.931098 22565 net.cpp:150] Setting up pool3
I0525 02:48:46.931120 22565 net.cpp:157] Top shape: 80 28 11 44 (1084160)
I0525 02:48:46.931133 22565 net.cpp:165] Memory required for data: 118756160
I0525 02:48:46.931145 22565 layer_factory.hpp:77] Creating layer conv4
I0525 02:48:46.931180 22565 net.cpp:106] Creating Layer conv4
I0525 02:48:46.931193 22565 net.cpp:454] conv4 <- pool3
I0525 02:48:46.931216 22565 net.cpp:411] conv4 -> conv4
I0525 02:48:46.933346 22565 net.cpp:150] Setting up conv4
I0525 02:48:46.933370 22565 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 02:48:46.933390 22565 net.cpp:165] Memory required for data: 121659200
I0525 02:48:46.933409 22565 layer_factory.hpp:77] Creating layer relu4
I0525 02:48:46.933429 22565 net.cpp:106] Creating Layer relu4
I0525 02:48:46.933442 22565 net.cpp:454] relu4 <- conv4
I0525 02:48:46.933467 22565 net.cpp:397] relu4 -> conv4 (in-place)
I0525 02:48:46.933962 22565 net.cpp:150] Setting up relu4
I0525 02:48:46.933985 22565 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 02:48:46.934000 22565 net.cpp:165] Memory required for data: 124562240
I0525 02:48:46.934015 22565 layer_factory.hpp:77] Creating layer pool4
I0525 02:48:46.934031 22565 net.cpp:106] Creating Layer pool4
I0525 02:48:46.934044 22565 net.cpp:454] pool4 <- conv4
I0525 02:48:46.934061 22565 net.cpp:411] pool4 -> pool4
I0525 02:48:46.934152 22565 net.cpp:150] Setting up pool4
I0525 02:48:46.934170 22565 net.cpp:157] Top shape: 80 36 3 42 (362880)
I0525 02:48:46.934190 22565 net.cpp:165] Memory required for data: 126013760
I0525 02:48:46.934206 22565 layer_factory.hpp:77] Creating layer ip1
I0525 02:48:46.934222 22565 net.cpp:106] Creating Layer ip1
I0525 02:48:46.934237 22565 net.cpp:454] ip1 <- pool4
I0525 02:48:46.934258 22565 net.cpp:411] ip1 -> ip1
I0525 02:48:46.949673 22565 net.cpp:150] Setting up ip1
I0525 02:48:46.949705 22565 net.cpp:157] Top shape: 80 196 (15680)
I0525 02:48:46.949728 22565 net.cpp:165] Memory required for data: 126076480
I0525 02:48:46.949753 22565 layer_factory.hpp:77] Creating layer relu5
I0525 02:48:46.949777 22565 net.cpp:106] Creating Layer relu5
I0525 02:48:46.949790 22565 net.cpp:454] relu5 <- ip1
I0525 02:48:46.949805 22565 net.cpp:397] relu5 -> ip1 (in-place)
I0525 02:48:46.950182 22565 net.cpp:150] Setting up relu5
I0525 02:48:46.950203 22565 net.cpp:157] Top shape: 80 196 (15680)
I0525 02:48:46.950217 22565 net.cpp:165] Memory required for data: 126139200
I0525 02:48:46.950232 22565 layer_factory.hpp:77] Creating layer drop1
I0525 02:48:46.950261 22565 net.cpp:106] Creating Layer drop1
I0525 02:48:46.950275 22565 net.cpp:454] drop1 <- ip1
I0525 02:48:46.950299 22565 net.cpp:397] drop1 -> ip1 (in-place)
I0525 02:48:46.950361 22565 net.cpp:150] Setting up drop1
I0525 02:48:46.950377 22565 net.cpp:157] Top shape: 80 196 (15680)
I0525 02:48:46.950397 22565 net.cpp:165] Memory required for data: 126201920
I0525 02:48:46.950409 22565 layer_factory.hpp:77] Creating layer ip2
I0525 02:48:46.950425 22565 net.cpp:106] Creating Layer ip2
I0525 02:48:46.950440 22565 net.cpp:454] ip2 <- ip1
I0525 02:48:46.950464 22565 net.cpp:411] ip2 -> ip2
I0525 02:48:46.950956 22565 net.cpp:150] Setting up ip2
I0525 02:48:46.950975 22565 net.cpp:157] Top shape: 80 98 (7840)
I0525 02:48:46.950989 22565 net.cpp:165] Memory required for data: 126233280
I0525 02:48:46.951009 22565 layer_factory.hpp:77] Creating layer relu6
I0525 02:48:46.951038 22565 net.cpp:106] Creating Layer relu6
I0525 02:48:46.951051 22565 net.cpp:454] relu6 <- ip2
I0525 02:48:46.951078 22565 net.cpp:397] relu6 -> ip2 (in-place)
I0525 02:48:46.951653 22565 net.cpp:150] Setting up relu6
I0525 02:48:46.951675 22565 net.cpp:157] Top shape: 80 98 (7840)
I0525 02:48:46.951689 22565 net.cpp:165] Memory required for data: 126264640
I0525 02:48:46.951700 22565 layer_factory.hpp:77] Creating layer drop2
I0525 02:48:46.951721 22565 net.cpp:106] Creating Layer drop2
I0525 02:48:46.951742 22565 net.cpp:454] drop2 <- ip2
I0525 02:48:46.951758 22565 net.cpp:397] drop2 -> ip2 (in-place)
I0525 02:48:46.951810 22565 net.cpp:150] Setting up drop2
I0525 02:48:46.951833 22565 net.cpp:157] Top shape: 80 98 (7840)
I0525 02:48:46.951846 22565 net.cpp:165] Memory required for data: 126296000
I0525 02:48:46.951859 22565 layer_factory.hpp:77] Creating layer ip3
I0525 02:48:46.951876 22565 net.cpp:106] Creating Layer ip3
I0525 02:48:46.951891 22565 net.cpp:454] ip3 <- ip2
I0525 02:48:46.951913 22565 net.cpp:411] ip3 -> ip3
I0525 02:48:46.952152 22565 net.cpp:150] Setting up ip3
I0525 02:48:46.952169 22565 net.cpp:157] Top shape: 80 11 (880)
I0525 02:48:46.952183 22565 net.cpp:165] Memory required for data: 126299520
I0525 02:48:46.952203 22565 layer_factory.hpp:77] Creating layer drop3
I0525 02:48:46.952225 22565 net.cpp:106] Creating Layer drop3
I0525 02:48:46.952239 22565 net.cpp:454] drop3 <- ip3
I0525 02:48:46.952255 22565 net.cpp:397] drop3 -> ip3 (in-place)
I0525 02:48:46.952322 22565 net.cpp:150] Setting up drop3
I0525 02:48:46.952337 22565 net.cpp:157] Top shape: 80 11 (880)
I0525 02:48:46.952353 22565 net.cpp:165] Memory required for data: 126303040
I0525 02:48:46.952365 22565 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 02:48:46.952380 22565 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 02:48:46.952395 22565 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 02:48:46.952419 22565 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 02:48:46.952437 22565 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 02:48:46.952524 22565 net.cpp:150] Setting up ip3_drop3_0_split
I0525 02:48:46.952543 22565 net.cpp:157] Top shape: 80 11 (880)
I0525 02:48:46.952558 22565 net.cpp:157] Top shape: 80 11 (880)
I0525 02:48:46.952574 22565 net.cpp:165] Memory required for data: 126310080
I0525 02:48:46.952585 22565 layer_factory.hpp:77] Creating layer accuracy
I0525 02:48:46.952615 22565 net.cpp:106] Creating Layer accuracy
I0525 02:48:46.952628 22565 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 02:48:46.952642 22565 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 02:48:46.952658 22565 net.cpp:411] accuracy -> accuracy
I0525 02:48:46.952692 22565 net.cpp:150] Setting up accuracy
I0525 02:48:46.952708 22565 net.cpp:157] Top shape: (1)
I0525 02:48:46.952724 22565 net.cpp:165] Memory required for data: 126310084
I0525 02:48:46.952738 22565 layer_factory.hpp:77] Creating layer loss
I0525 02:48:46.952752 22565 net.cpp:106] Creating Layer loss
I0525 02:48:46.952769 22565 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 02:48:46.952788 22565 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 02:48:46.952805 22565 net.cpp:411] loss -> loss
I0525 02:48:46.952826 22565 layer_factory.hpp:77] Creating layer loss
I0525 02:48:46.953342 22565 net.cpp:150] Setting up loss
I0525 02:48:46.953362 22565 net.cpp:157] Top shape: (1)
I0525 02:48:46.953375 22565 net.cpp:160]     with loss weight 1
I0525 02:48:46.953402 22565 net.cpp:165] Memory required for data: 126310088
I0525 02:48:46.953421 22565 net.cpp:226] loss needs backward computation.
I0525 02:48:46.953436 22565 net.cpp:228] accuracy does not need backward computation.
I0525 02:48:46.953454 22565 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 02:48:46.953467 22565 net.cpp:226] drop3 needs backward computation.
I0525 02:48:46.953480 22565 net.cpp:226] ip3 needs backward computation.
I0525 02:48:46.953495 22565 net.cpp:226] drop2 needs backward computation.
I0525 02:48:46.953513 22565 net.cpp:226] relu6 needs backward computation.
I0525 02:48:46.953536 22565 net.cpp:226] ip2 needs backward computation.
I0525 02:48:46.953552 22565 net.cpp:226] drop1 needs backward computation.
I0525 02:48:46.953564 22565 net.cpp:226] relu5 needs backward computation.
I0525 02:48:46.953575 22565 net.cpp:226] ip1 needs backward computation.
I0525 02:48:46.953591 22565 net.cpp:226] pool4 needs backward computation.
I0525 02:48:46.953603 22565 net.cpp:226] relu4 needs backward computation.
I0525 02:48:46.953616 22565 net.cpp:226] conv4 needs backward computation.
I0525 02:48:46.953630 22565 net.cpp:226] pool3 needs backward computation.
I0525 02:48:46.953652 22565 net.cpp:226] relu3 needs backward computation.
I0525 02:48:46.953665 22565 net.cpp:226] conv3 needs backward computation.
I0525 02:48:46.953678 22565 net.cpp:226] pool2 needs backward computation.
I0525 02:48:46.953691 22565 net.cpp:226] relu2 needs backward computation.
I0525 02:48:46.953706 22565 net.cpp:226] conv2 needs backward computation.
I0525 02:48:46.953718 22565 net.cpp:226] pool1 needs backward computation.
I0525 02:48:46.953732 22565 net.cpp:226] relu1 needs backward computation.
I0525 02:48:46.953744 22565 net.cpp:226] conv1 needs backward computation.
I0525 02:48:46.953765 22565 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 02:48:46.953779 22565 net.cpp:228] data_hdf5 does not need backward computation.
I0525 02:48:46.953794 22565 net.cpp:270] This network produces output accuracy
I0525 02:48:46.953806 22565 net.cpp:270] This network produces output loss
I0525 02:48:46.953838 22565 net.cpp:283] Network initialization done.
I0525 02:48:46.953977 22565 solver.cpp:60] Solver scaffolding done.
I0525 02:48:46.955124 22565 caffe.cpp:212] Starting Optimization
I0525 02:48:46.955142 22565 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 02:48:46.955155 22565 solver.cpp:289] Learning Rate Policy: fixed
I0525 02:48:46.956235 22565 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 02:49:35.155797 22565 solver.cpp:409]     Test net output #0: accuracy = 0.116227
I0525 02:49:35.155966 22565 solver.cpp:409]     Test net output #1: loss = 2.39847 (* 1 = 2.39847 loss)
I0525 02:49:35.185385 22565 solver.cpp:237] Iteration 0, loss = 2.39993
I0525 02:49:35.185425 22565 solver.cpp:253]     Train net output #0: loss = 2.39993 (* 1 = 2.39993 loss)
I0525 02:49:35.185446 22565 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0525 02:49:43.835770 22565 solver.cpp:237] Iteration 187, loss = 2.1261
I0525 02:49:43.835827 22565 solver.cpp:253]     Train net output #0: loss = 2.1261 (* 1 = 2.1261 loss)
I0525 02:49:43.835852 22565 sgd_solver.cpp:106] Iteration 187, lr = 0.005
I0525 02:49:52.485570 22565 solver.cpp:237] Iteration 374, loss = 1.99125
I0525 02:49:52.485608 22565 solver.cpp:253]     Train net output #0: loss = 1.99125 (* 1 = 1.99125 loss)
I0525 02:49:52.485631 22565 sgd_solver.cpp:106] Iteration 374, lr = 0.005
I0525 02:50:01.132527 22565 solver.cpp:237] Iteration 561, loss = 1.85506
I0525 02:50:01.132566 22565 solver.cpp:253]     Train net output #0: loss = 1.85506 (* 1 = 1.85506 loss)
I0525 02:50:01.132583 22565 sgd_solver.cpp:106] Iteration 561, lr = 0.005
I0525 02:50:09.784060 22565 solver.cpp:237] Iteration 748, loss = 1.91726
I0525 02:50:09.784231 22565 solver.cpp:253]     Train net output #0: loss = 1.91726 (* 1 = 1.91726 loss)
I0525 02:50:09.784251 22565 sgd_solver.cpp:106] Iteration 748, lr = 0.005
I0525 02:50:18.436650 22565 solver.cpp:237] Iteration 935, loss = 1.80664
I0525 02:50:18.436688 22565 solver.cpp:253]     Train net output #0: loss = 1.80664 (* 1 = 1.80664 loss)
I0525 02:50:18.436707 22565 sgd_solver.cpp:106] Iteration 935, lr = 0.005
I0525 02:50:27.087533 22565 solver.cpp:237] Iteration 1122, loss = 1.79602
I0525 02:50:27.087570 22565 solver.cpp:253]     Train net output #0: loss = 1.79602 (* 1 = 1.79602 loss)
I0525 02:50:27.087594 22565 sgd_solver.cpp:106] Iteration 1122, lr = 0.005
I0525 02:50:57.784930 22565 solver.cpp:237] Iteration 1309, loss = 1.77349
I0525 02:50:57.785099 22565 solver.cpp:253]     Train net output #0: loss = 1.77349 (* 1 = 1.77349 loss)
I0525 02:50:57.785115 22565 sgd_solver.cpp:106] Iteration 1309, lr = 0.005
I0525 02:51:06.447566 22565 solver.cpp:237] Iteration 1496, loss = 1.75985
I0525 02:51:06.447602 22565 solver.cpp:253]     Train net output #0: loss = 1.75985 (* 1 = 1.75985 loss)
I0525 02:51:06.447626 22565 sgd_solver.cpp:106] Iteration 1496, lr = 0.005
I0525 02:51:15.112563 22565 solver.cpp:237] Iteration 1683, loss = 1.5935
I0525 02:51:15.112601 22565 solver.cpp:253]     Train net output #0: loss = 1.5935 (* 1 = 1.5935 loss)
I0525 02:51:15.112619 22565 sgd_solver.cpp:106] Iteration 1683, lr = 0.005
I0525 02:51:23.776950 22565 solver.cpp:237] Iteration 1870, loss = 1.58925
I0525 02:51:23.777009 22565 solver.cpp:253]     Train net output #0: loss = 1.58925 (* 1 = 1.58925 loss)
I0525 02:51:23.777034 22565 sgd_solver.cpp:106] Iteration 1870, lr = 0.005
I0525 02:51:23.962529 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_1875.caffemodel
I0525 02:51:24.035750 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_1875.solverstate
I0525 02:51:32.507791 22565 solver.cpp:237] Iteration 2057, loss = 1.39618
I0525 02:51:32.507956 22565 solver.cpp:253]     Train net output #0: loss = 1.39618 (* 1 = 1.39618 loss)
I0525 02:51:32.507973 22565 sgd_solver.cpp:106] Iteration 2057, lr = 0.005
I0525 02:51:41.171859 22565 solver.cpp:237] Iteration 2244, loss = 1.57312
I0525 02:51:41.171895 22565 solver.cpp:253]     Train net output #0: loss = 1.57312 (* 1 = 1.57312 loss)
I0525 02:51:41.171913 22565 sgd_solver.cpp:106] Iteration 2244, lr = 0.005
I0525 02:51:49.837062 22565 solver.cpp:237] Iteration 2431, loss = 1.64682
I0525 02:51:49.837116 22565 solver.cpp:253]     Train net output #0: loss = 1.64682 (* 1 = 1.64682 loss)
I0525 02:51:49.837132 22565 sgd_solver.cpp:106] Iteration 2431, lr = 0.005
I0525 02:52:20.559124 22565 solver.cpp:237] Iteration 2618, loss = 1.56592
I0525 02:52:20.559286 22565 solver.cpp:253]     Train net output #0: loss = 1.56592 (* 1 = 1.56592 loss)
I0525 02:52:20.559303 22565 sgd_solver.cpp:106] Iteration 2618, lr = 0.005
I0525 02:52:29.219817 22565 solver.cpp:237] Iteration 2805, loss = 1.40294
I0525 02:52:29.219853 22565 solver.cpp:253]     Train net output #0: loss = 1.40294 (* 1 = 1.40294 loss)
I0525 02:52:29.219877 22565 sgd_solver.cpp:106] Iteration 2805, lr = 0.005
I0525 02:52:37.885017 22565 solver.cpp:237] Iteration 2992, loss = 1.64694
I0525 02:52:37.885068 22565 solver.cpp:253]     Train net output #0: loss = 1.64694 (* 1 = 1.64694 loss)
I0525 02:52:37.885084 22565 sgd_solver.cpp:106] Iteration 2992, lr = 0.005
I0525 02:52:46.549409 22565 solver.cpp:237] Iteration 3179, loss = 1.34192
I0525 02:52:46.549448 22565 solver.cpp:253]     Train net output #0: loss = 1.34192 (* 1 = 1.34192 loss)
I0525 02:52:46.549466 22565 sgd_solver.cpp:106] Iteration 3179, lr = 0.005
I0525 02:52:55.211107 22565 solver.cpp:237] Iteration 3366, loss = 1.65009
I0525 02:52:55.211257 22565 solver.cpp:253]     Train net output #0: loss = 1.65009 (* 1 = 1.65009 loss)
I0525 02:52:55.211273 22565 sgd_solver.cpp:106] Iteration 3366, lr = 0.005
I0525 02:53:03.877871 22565 solver.cpp:237] Iteration 3553, loss = 1.42505
I0525 02:53:03.877923 22565 solver.cpp:253]     Train net output #0: loss = 1.42505 (* 1 = 1.42505 loss)
I0525 02:53:03.877939 22565 sgd_solver.cpp:106] Iteration 3553, lr = 0.005
I0525 02:53:12.543463 22565 solver.cpp:237] Iteration 3740, loss = 1.23946
I0525 02:53:12.543499 22565 solver.cpp:253]     Train net output #0: loss = 1.23946 (* 1 = 1.23946 loss)
I0525 02:53:12.543522 22565 sgd_solver.cpp:106] Iteration 3740, lr = 0.005
I0525 02:53:12.960299 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_3750.caffemodel
I0525 02:53:13.030393 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_3750.solverstate
I0525 02:53:13.056196 22565 solver.cpp:341] Iteration 3750, Testing net (#0)
I0525 02:54:00.393234 22565 solver.cpp:409]     Test net output #0: accuracy = 0.81052
I0525 02:54:00.393401 22565 solver.cpp:409]     Test net output #1: loss = 0.676744 (* 1 = 0.676744 loss)
I0525 02:54:30.643084 22565 solver.cpp:237] Iteration 3927, loss = 1.3482
I0525 02:54:30.643256 22565 solver.cpp:253]     Train net output #0: loss = 1.3482 (* 1 = 1.3482 loss)
I0525 02:54:30.643275 22565 sgd_solver.cpp:106] Iteration 3927, lr = 0.005
I0525 02:54:39.295344 22565 solver.cpp:237] Iteration 4114, loss = 1.41293
I0525 02:54:39.295398 22565 solver.cpp:253]     Train net output #0: loss = 1.41293 (* 1 = 1.41293 loss)
I0525 02:54:39.295415 22565 sgd_solver.cpp:106] Iteration 4114, lr = 0.005
I0525 02:54:47.950474 22565 solver.cpp:237] Iteration 4301, loss = 1.23244
I0525 02:54:47.950511 22565 solver.cpp:253]     Train net output #0: loss = 1.23244 (* 1 = 1.23244 loss)
I0525 02:54:47.950536 22565 sgd_solver.cpp:106] Iteration 4301, lr = 0.005
I0525 02:54:56.602619 22565 solver.cpp:237] Iteration 4488, loss = 1.31596
I0525 02:54:56.602658 22565 solver.cpp:253]     Train net output #0: loss = 1.31596 (* 1 = 1.31596 loss)
I0525 02:54:56.602675 22565 sgd_solver.cpp:106] Iteration 4488, lr = 0.005
I0525 02:55:05.252429 22565 solver.cpp:237] Iteration 4675, loss = 1.29141
I0525 02:55:05.252602 22565 solver.cpp:253]     Train net output #0: loss = 1.29141 (* 1 = 1.29141 loss)
I0525 02:55:05.252621 22565 sgd_solver.cpp:106] Iteration 4675, lr = 0.005
I0525 02:55:13.907295 22565 solver.cpp:237] Iteration 4862, loss = 1.24322
I0525 02:55:13.907332 22565 solver.cpp:253]     Train net output #0: loss = 1.24322 (* 1 = 1.24322 loss)
I0525 02:55:13.907356 22565 sgd_solver.cpp:106] Iteration 4862, lr = 0.005
I0525 02:55:44.680577 22565 solver.cpp:237] Iteration 5049, loss = 1.24827
I0525 02:55:44.680749 22565 solver.cpp:253]     Train net output #0: loss = 1.24827 (* 1 = 1.24827 loss)
I0525 02:55:44.680766 22565 sgd_solver.cpp:106] Iteration 5049, lr = 0.005
I0525 02:55:53.337942 22565 solver.cpp:237] Iteration 5236, loss = 1.31492
I0525 02:55:53.337980 22565 solver.cpp:253]     Train net output #0: loss = 1.31492 (* 1 = 1.31492 loss)
I0525 02:55:53.338003 22565 sgd_solver.cpp:106] Iteration 5236, lr = 0.005
I0525 02:56:01.992594 22565 solver.cpp:237] Iteration 5423, loss = 1.57189
I0525 02:56:01.992648 22565 solver.cpp:253]     Train net output #0: loss = 1.57189 (* 1 = 1.57189 loss)
I0525 02:56:01.992673 22565 sgd_solver.cpp:106] Iteration 5423, lr = 0.005
I0525 02:56:10.644646 22565 solver.cpp:237] Iteration 5610, loss = 1.18421
I0525 02:56:10.644685 22565 solver.cpp:253]     Train net output #0: loss = 1.18421 (* 1 = 1.18421 loss)
I0525 02:56:10.644702 22565 sgd_solver.cpp:106] Iteration 5610, lr = 0.005
I0525 02:56:11.292464 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_5625.caffemodel
I0525 02:56:11.363517 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_5625.solverstate
I0525 02:56:19.364684 22565 solver.cpp:237] Iteration 5797, loss = 1.27123
I0525 02:56:19.364861 22565 solver.cpp:253]     Train net output #0: loss = 1.27123 (* 1 = 1.27123 loss)
I0525 02:56:19.364879 22565 sgd_solver.cpp:106] Iteration 5797, lr = 0.005
I0525 02:56:28.016851 22565 solver.cpp:237] Iteration 5984, loss = 1.4104
I0525 02:56:28.016890 22565 solver.cpp:253]     Train net output #0: loss = 1.4104 (* 1 = 1.4104 loss)
I0525 02:56:28.016907 22565 sgd_solver.cpp:106] Iteration 5984, lr = 0.005
I0525 02:56:36.670284 22565 solver.cpp:237] Iteration 6171, loss = 1.50973
I0525 02:56:36.670320 22565 solver.cpp:253]     Train net output #0: loss = 1.50973 (* 1 = 1.50973 loss)
I0525 02:56:36.670343 22565 sgd_solver.cpp:106] Iteration 6171, lr = 0.005
I0525 02:57:07.413682 22565 solver.cpp:237] Iteration 6358, loss = 1.45787
I0525 02:57:07.413852 22565 solver.cpp:253]     Train net output #0: loss = 1.45787 (* 1 = 1.45787 loss)
I0525 02:57:07.413869 22565 sgd_solver.cpp:106] Iteration 6358, lr = 0.005
I0525 02:57:16.061058 22565 solver.cpp:237] Iteration 6545, loss = 1.18304
I0525 02:57:16.061112 22565 solver.cpp:253]     Train net output #0: loss = 1.18304 (* 1 = 1.18304 loss)
I0525 02:57:16.061130 22565 sgd_solver.cpp:106] Iteration 6545, lr = 0.005
I0525 02:57:24.710057 22565 solver.cpp:237] Iteration 6732, loss = 1.19645
I0525 02:57:24.710095 22565 solver.cpp:253]     Train net output #0: loss = 1.19645 (* 1 = 1.19645 loss)
I0525 02:57:24.710114 22565 sgd_solver.cpp:106] Iteration 6732, lr = 0.005
I0525 02:57:33.359647 22565 solver.cpp:237] Iteration 6919, loss = 1.14317
I0525 02:57:33.359684 22565 solver.cpp:253]     Train net output #0: loss = 1.14317 (* 1 = 1.14317 loss)
I0525 02:57:33.359704 22565 sgd_solver.cpp:106] Iteration 6919, lr = 0.005
I0525 02:57:42.010504 22565 solver.cpp:237] Iteration 7106, loss = 1.24541
I0525 02:57:42.010663 22565 solver.cpp:253]     Train net output #0: loss = 1.24541 (* 1 = 1.24541 loss)
I0525 02:57:42.010679 22565 sgd_solver.cpp:106] Iteration 7106, lr = 0.005
I0525 02:57:50.659942 22565 solver.cpp:237] Iteration 7293, loss = 1.40426
I0525 02:57:50.659986 22565 solver.cpp:253]     Train net output #0: loss = 1.40426 (* 1 = 1.40426 loss)
I0525 02:57:50.660002 22565 sgd_solver.cpp:106] Iteration 7293, lr = 0.005
I0525 02:57:59.310699 22565 solver.cpp:237] Iteration 7480, loss = 1.55215
I0525 02:57:59.310753 22565 solver.cpp:253]     Train net output #0: loss = 1.55215 (* 1 = 1.55215 loss)
I0525 02:57:59.310770 22565 sgd_solver.cpp:106] Iteration 7480, lr = 0.005
I0525 02:58:00.190665 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_7500.caffemodel
I0525 02:58:00.261750 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_7500.solverstate
I0525 02:58:00.288260 22565 solver.cpp:341] Iteration 7500, Testing net (#0)
I0525 02:59:08.398900 22565 solver.cpp:409]     Test net output #0: accuracy = 0.845367
I0525 02:59:08.399078 22565 solver.cpp:409]     Test net output #1: loss = 0.5323 (* 1 = 0.5323 loss)
I0525 02:59:38.299784 22565 solver.cpp:237] Iteration 7667, loss = 1.20097
I0525 02:59:38.299845 22565 solver.cpp:253]     Train net output #0: loss = 1.20097 (* 1 = 1.20097 loss)
I0525 02:59:38.299870 22565 sgd_solver.cpp:106] Iteration 7667, lr = 0.005
I0525 02:59:46.966891 22565 solver.cpp:237] Iteration 7854, loss = 1.21708
I0525 02:59:46.967056 22565 solver.cpp:253]     Train net output #0: loss = 1.21708 (* 1 = 1.21708 loss)
I0525 02:59:46.967073 22565 sgd_solver.cpp:106] Iteration 7854, lr = 0.005
I0525 02:59:55.631700 22565 solver.cpp:237] Iteration 8041, loss = 1.33952
I0525 02:59:55.631737 22565 solver.cpp:253]     Train net output #0: loss = 1.33952 (* 1 = 1.33952 loss)
I0525 02:59:55.631755 22565 sgd_solver.cpp:106] Iteration 8041, lr = 0.005
I0525 03:00:04.299715 22565 solver.cpp:237] Iteration 8228, loss = 1.31286
I0525 03:00:04.299772 22565 solver.cpp:253]     Train net output #0: loss = 1.31286 (* 1 = 1.31286 loss)
I0525 03:00:04.299793 22565 sgd_solver.cpp:106] Iteration 8228, lr = 0.005
I0525 03:00:12.969775 22565 solver.cpp:237] Iteration 8415, loss = 1.15456
I0525 03:00:12.969812 22565 solver.cpp:253]     Train net output #0: loss = 1.15456 (* 1 = 1.15456 loss)
I0525 03:00:12.969836 22565 sgd_solver.cpp:106] Iteration 8415, lr = 0.005
I0525 03:00:21.634845 22565 solver.cpp:237] Iteration 8602, loss = 1.07616
I0525 03:00:21.634989 22565 solver.cpp:253]     Train net output #0: loss = 1.07616 (* 1 = 1.07616 loss)
I0525 03:00:21.635005 22565 sgd_solver.cpp:106] Iteration 8602, lr = 0.005
I0525 03:00:52.420398 22565 solver.cpp:237] Iteration 8789, loss = 1.42372
I0525 03:00:52.420567 22565 solver.cpp:253]     Train net output #0: loss = 1.42372 (* 1 = 1.42372 loss)
I0525 03:00:52.420585 22565 sgd_solver.cpp:106] Iteration 8789, lr = 0.005
I0525 03:01:01.088378 22565 solver.cpp:237] Iteration 8976, loss = 1.25694
I0525 03:01:01.088423 22565 solver.cpp:253]     Train net output #0: loss = 1.25694 (* 1 = 1.25694 loss)
I0525 03:01:01.088440 22565 sgd_solver.cpp:106] Iteration 8976, lr = 0.005
I0525 03:01:09.756917 22565 solver.cpp:237] Iteration 9163, loss = 1.37344
I0525 03:01:09.756954 22565 solver.cpp:253]     Train net output #0: loss = 1.37344 (* 1 = 1.37344 loss)
I0525 03:01:09.756973 22565 sgd_solver.cpp:106] Iteration 9163, lr = 0.005
I0525 03:01:18.421460 22565 solver.cpp:237] Iteration 9350, loss = 1.03551
I0525 03:01:18.421497 22565 solver.cpp:253]     Train net output #0: loss = 1.03551 (* 1 = 1.03551 loss)
I0525 03:01:18.421515 22565 sgd_solver.cpp:106] Iteration 9350, lr = 0.005
I0525 03:01:19.534816 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_9375.caffemodel
I0525 03:01:19.607003 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_9375.solverstate
I0525 03:01:27.157387 22565 solver.cpp:237] Iteration 9537, loss = 1.30064
I0525 03:01:27.157555 22565 solver.cpp:253]     Train net output #0: loss = 1.30064 (* 1 = 1.30064 loss)
I0525 03:01:27.157574 22565 sgd_solver.cpp:106] Iteration 9537, lr = 0.005
I0525 03:01:35.825155 22565 solver.cpp:237] Iteration 9724, loss = 1.20203
I0525 03:01:35.825191 22565 solver.cpp:253]     Train net output #0: loss = 1.20203 (* 1 = 1.20203 loss)
I0525 03:01:35.825211 22565 sgd_solver.cpp:106] Iteration 9724, lr = 0.005
I0525 03:01:44.495605 22565 solver.cpp:237] Iteration 9911, loss = 1.32193
I0525 03:01:44.495663 22565 solver.cpp:253]     Train net output #0: loss = 1.32193 (* 1 = 1.32193 loss)
I0525 03:01:44.495689 22565 sgd_solver.cpp:106] Iteration 9911, lr = 0.005
I0525 03:02:15.304759 22565 solver.cpp:237] Iteration 10098, loss = 1.43356
I0525 03:02:15.304944 22565 solver.cpp:253]     Train net output #0: loss = 1.43356 (* 1 = 1.43356 loss)
I0525 03:02:15.304961 22565 sgd_solver.cpp:106] Iteration 10098, lr = 0.005
I0525 03:02:23.975754 22565 solver.cpp:237] Iteration 10285, loss = 1.12817
I0525 03:02:23.975792 22565 solver.cpp:253]     Train net output #0: loss = 1.12817 (* 1 = 1.12817 loss)
I0525 03:02:23.975811 22565 sgd_solver.cpp:106] Iteration 10285, lr = 0.005
I0525 03:02:32.642526 22565 solver.cpp:237] Iteration 10472, loss = 1.582
I0525 03:02:32.642563 22565 solver.cpp:253]     Train net output #0: loss = 1.582 (* 1 = 1.582 loss)
I0525 03:02:32.642586 22565 sgd_solver.cpp:106] Iteration 10472, lr = 0.005
I0525 03:02:41.307587 22565 solver.cpp:237] Iteration 10659, loss = 1.126
I0525 03:02:41.307636 22565 solver.cpp:253]     Train net output #0: loss = 1.126 (* 1 = 1.126 loss)
I0525 03:02:41.307653 22565 sgd_solver.cpp:106] Iteration 10659, lr = 0.005
I0525 03:02:49.974341 22565 solver.cpp:237] Iteration 10846, loss = 1.35442
I0525 03:02:49.974489 22565 solver.cpp:253]     Train net output #0: loss = 1.35442 (* 1 = 1.35442 loss)
I0525 03:02:49.974505 22565 sgd_solver.cpp:106] Iteration 10846, lr = 0.005
I0525 03:02:58.636996 22565 solver.cpp:237] Iteration 11033, loss = 1.40413
I0525 03:02:58.637033 22565 solver.cpp:253]     Train net output #0: loss = 1.40413 (* 1 = 1.40413 loss)
I0525 03:02:58.637051 22565 sgd_solver.cpp:106] Iteration 11033, lr = 0.005
I0525 03:03:07.302870 22565 solver.cpp:237] Iteration 11220, loss = 1.3831
I0525 03:03:07.302917 22565 solver.cpp:253]     Train net output #0: loss = 1.3831 (* 1 = 1.3831 loss)
I0525 03:03:07.302945 22565 sgd_solver.cpp:106] Iteration 11220, lr = 0.005
I0525 03:03:08.645833 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_11250.caffemodel
I0525 03:03:08.715476 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_11250.solverstate
I0525 03:03:08.740428 22565 solver.cpp:341] Iteration 11250, Testing net (#0)
I0525 03:03:55.811688 22565 solver.cpp:409]     Test net output #0: accuracy = 0.855147
I0525 03:03:55.811859 22565 solver.cpp:409]     Test net output #1: loss = 0.483483 (* 1 = 0.483483 loss)
I0525 03:04:25.205858 22565 solver.cpp:237] Iteration 11407, loss = 1.19335
I0525 03:04:25.205915 22565 solver.cpp:253]     Train net output #0: loss = 1.19335 (* 1 = 1.19335 loss)
I0525 03:04:25.205940 22565 sgd_solver.cpp:106] Iteration 11407, lr = 0.005
I0525 03:04:33.849720 22565 solver.cpp:237] Iteration 11594, loss = 1.23728
I0525 03:04:33.849880 22565 solver.cpp:253]     Train net output #0: loss = 1.23728 (* 1 = 1.23728 loss)
I0525 03:04:33.849897 22565 sgd_solver.cpp:106] Iteration 11594, lr = 0.005
I0525 03:04:42.493896 22565 solver.cpp:237] Iteration 11781, loss = 1.4033
I0525 03:04:42.493955 22565 solver.cpp:253]     Train net output #0: loss = 1.4033 (* 1 = 1.4033 loss)
I0525 03:04:42.493979 22565 sgd_solver.cpp:106] Iteration 11781, lr = 0.005
I0525 03:04:51.133116 22565 solver.cpp:237] Iteration 11968, loss = 1.15877
I0525 03:04:51.133152 22565 solver.cpp:253]     Train net output #0: loss = 1.15877 (* 1 = 1.15877 loss)
I0525 03:04:51.133172 22565 sgd_solver.cpp:106] Iteration 11968, lr = 0.005
I0525 03:04:59.777050 22565 solver.cpp:237] Iteration 12155, loss = 1.16606
I0525 03:04:59.777086 22565 solver.cpp:253]     Train net output #0: loss = 1.16606 (* 1 = 1.16606 loss)
I0525 03:04:59.777103 22565 sgd_solver.cpp:106] Iteration 12155, lr = 0.005
I0525 03:05:08.418486 22565 solver.cpp:237] Iteration 12342, loss = 1.00532
I0525 03:05:08.418663 22565 solver.cpp:253]     Train net output #0: loss = 1.00532 (* 1 = 1.00532 loss)
I0525 03:05:08.418683 22565 sgd_solver.cpp:106] Iteration 12342, lr = 0.005
I0525 03:05:39.155427 22565 solver.cpp:237] Iteration 12529, loss = 0.953588
I0525 03:05:39.155611 22565 solver.cpp:253]     Train net output #0: loss = 0.953588 (* 1 = 0.953588 loss)
I0525 03:05:39.155629 22565 sgd_solver.cpp:106] Iteration 12529, lr = 0.005
I0525 03:05:47.791429 22565 solver.cpp:237] Iteration 12716, loss = 1.26694
I0525 03:05:47.791465 22565 solver.cpp:253]     Train net output #0: loss = 1.26694 (* 1 = 1.26694 loss)
I0525 03:05:47.791489 22565 sgd_solver.cpp:106] Iteration 12716, lr = 0.005
I0525 03:05:56.425817 22565 solver.cpp:237] Iteration 12903, loss = 1.06134
I0525 03:05:56.425873 22565 solver.cpp:253]     Train net output #0: loss = 1.06134 (* 1 = 1.06134 loss)
I0525 03:05:56.425900 22565 sgd_solver.cpp:106] Iteration 12903, lr = 0.005
I0525 03:06:05.062119 22565 solver.cpp:237] Iteration 13090, loss = 1.35221
I0525 03:06:05.062155 22565 solver.cpp:253]     Train net output #0: loss = 1.35221 (* 1 = 1.35221 loss)
I0525 03:06:05.062173 22565 sgd_solver.cpp:106] Iteration 13090, lr = 0.005
I0525 03:06:06.633483 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_13125.caffemodel
I0525 03:06:06.702772 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_13125.solverstate
I0525 03:06:13.759282 22565 solver.cpp:237] Iteration 13277, loss = 1.08784
I0525 03:06:13.759450 22565 solver.cpp:253]     Train net output #0: loss = 1.08784 (* 1 = 1.08784 loss)
I0525 03:06:13.759469 22565 sgd_solver.cpp:106] Iteration 13277, lr = 0.005
I0525 03:06:22.399525 22565 solver.cpp:237] Iteration 13464, loss = 1.14635
I0525 03:06:22.399579 22565 solver.cpp:253]     Train net output #0: loss = 1.14635 (* 1 = 1.14635 loss)
I0525 03:06:22.399598 22565 sgd_solver.cpp:106] Iteration 13464, lr = 0.005
I0525 03:06:31.049365 22565 solver.cpp:237] Iteration 13651, loss = 1.22161
I0525 03:06:31.049401 22565 solver.cpp:253]     Train net output #0: loss = 1.22161 (* 1 = 1.22161 loss)
I0525 03:06:31.049419 22565 sgd_solver.cpp:106] Iteration 13651, lr = 0.005
I0525 03:07:01.785589 22565 solver.cpp:237] Iteration 13838, loss = 1.14275
I0525 03:07:01.785764 22565 solver.cpp:253]     Train net output #0: loss = 1.14275 (* 1 = 1.14275 loss)
I0525 03:07:01.785781 22565 sgd_solver.cpp:106] Iteration 13838, lr = 0.005
I0525 03:07:10.437094 22565 solver.cpp:237] Iteration 14025, loss = 1.31383
I0525 03:07:10.437150 22565 solver.cpp:253]     Train net output #0: loss = 1.31383 (* 1 = 1.31383 loss)
I0525 03:07:10.437166 22565 sgd_solver.cpp:106] Iteration 14025, lr = 0.005
I0525 03:07:19.088256 22565 solver.cpp:237] Iteration 14212, loss = 1.16345
I0525 03:07:19.088297 22565 solver.cpp:253]     Train net output #0: loss = 1.16345 (* 1 = 1.16345 loss)
I0525 03:07:19.088320 22565 sgd_solver.cpp:106] Iteration 14212, lr = 0.005
I0525 03:07:27.740581 22565 solver.cpp:237] Iteration 14399, loss = 1.22539
I0525 03:07:27.740618 22565 solver.cpp:253]     Train net output #0: loss = 1.22539 (* 1 = 1.22539 loss)
I0525 03:07:27.740641 22565 sgd_solver.cpp:106] Iteration 14399, lr = 0.005
I0525 03:07:36.395033 22565 solver.cpp:237] Iteration 14586, loss = 1.34819
I0525 03:07:36.395200 22565 solver.cpp:253]     Train net output #0: loss = 1.34819 (* 1 = 1.34819 loss)
I0525 03:07:36.395218 22565 sgd_solver.cpp:106] Iteration 14586, lr = 0.005
I0525 03:07:45.047405 22565 solver.cpp:237] Iteration 14773, loss = 1.41937
I0525 03:07:45.047441 22565 solver.cpp:253]     Train net output #0: loss = 1.41937 (* 1 = 1.41937 loss)
I0525 03:07:45.047464 22565 sgd_solver.cpp:106] Iteration 14773, lr = 0.005
I0525 03:07:53.701306 22565 solver.cpp:237] Iteration 14960, loss = 1.2154
I0525 03:07:53.701344 22565 solver.cpp:253]     Train net output #0: loss = 1.2154 (* 1 = 1.2154 loss)
I0525 03:07:53.701361 22565 sgd_solver.cpp:106] Iteration 14960, lr = 0.005
I0525 03:07:55.506451 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_15000.caffemodel
I0525 03:07:55.576513 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_15000.solverstate
I0525 03:07:55.601833 22565 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 03:09:03.801975 22565 solver.cpp:409]     Test net output #0: accuracy = 0.86758
I0525 03:09:03.802167 22565 solver.cpp:409]     Test net output #1: loss = 0.404896 (* 1 = 0.404896 loss)
I0525 03:09:32.719609 22565 solver.cpp:237] Iteration 15147, loss = 1.22868
I0525 03:09:32.719667 22565 solver.cpp:253]     Train net output #0: loss = 1.22868 (* 1 = 1.22868 loss)
I0525 03:09:32.719691 22565 sgd_solver.cpp:106] Iteration 15147, lr = 0.005
I0525 03:09:41.372074 22565 solver.cpp:237] Iteration 15334, loss = 1.40658
I0525 03:09:41.372257 22565 solver.cpp:253]     Train net output #0: loss = 1.40658 (* 1 = 1.40658 loss)
I0525 03:09:41.372280 22565 sgd_solver.cpp:106] Iteration 15334, lr = 0.005
I0525 03:09:50.024598 22565 solver.cpp:237] Iteration 15521, loss = 1.01375
I0525 03:09:50.024636 22565 solver.cpp:253]     Train net output #0: loss = 1.01375 (* 1 = 1.01375 loss)
I0525 03:09:50.024653 22565 sgd_solver.cpp:106] Iteration 15521, lr = 0.005
I0525 03:09:58.672487 22565 solver.cpp:237] Iteration 15708, loss = 1.06742
I0525 03:09:58.672523 22565 solver.cpp:253]     Train net output #0: loss = 1.06742 (* 1 = 1.06742 loss)
I0525 03:09:58.672546 22565 sgd_solver.cpp:106] Iteration 15708, lr = 0.005
I0525 03:10:07.324340 22565 solver.cpp:237] Iteration 15895, loss = 1.20227
I0525 03:10:07.324398 22565 solver.cpp:253]     Train net output #0: loss = 1.20227 (* 1 = 1.20227 loss)
I0525 03:10:07.324415 22565 sgd_solver.cpp:106] Iteration 15895, lr = 0.005
I0525 03:10:15.979768 22565 solver.cpp:237] Iteration 16082, loss = 1.13627
I0525 03:10:15.979918 22565 solver.cpp:253]     Train net output #0: loss = 1.13627 (* 1 = 1.13627 loss)
I0525 03:10:15.979935 22565 sgd_solver.cpp:106] Iteration 16082, lr = 0.005
I0525 03:10:46.728694 22565 solver.cpp:237] Iteration 16269, loss = 1.11772
I0525 03:10:46.728866 22565 solver.cpp:253]     Train net output #0: loss = 1.11772 (* 1 = 1.11772 loss)
I0525 03:10:46.728883 22565 sgd_solver.cpp:106] Iteration 16269, lr = 0.005
I0525 03:10:55.384654 22565 solver.cpp:237] Iteration 16456, loss = 1.04005
I0525 03:10:55.384711 22565 solver.cpp:253]     Train net output #0: loss = 1.04005 (* 1 = 1.04005 loss)
I0525 03:10:55.384738 22565 sgd_solver.cpp:106] Iteration 16456, lr = 0.005
I0525 03:11:04.038877 22565 solver.cpp:237] Iteration 16643, loss = 1.18101
I0525 03:11:04.038914 22565 solver.cpp:253]     Train net output #0: loss = 1.18101 (* 1 = 1.18101 loss)
I0525 03:11:04.038938 22565 sgd_solver.cpp:106] Iteration 16643, lr = 0.005
I0525 03:11:12.694754 22565 solver.cpp:237] Iteration 16830, loss = 1.20806
I0525 03:11:12.694792 22565 solver.cpp:253]     Train net output #0: loss = 1.20806 (* 1 = 1.20806 loss)
I0525 03:11:12.694810 22565 sgd_solver.cpp:106] Iteration 16830, lr = 0.005
I0525 03:11:14.731539 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_16875.caffemodel
I0525 03:11:14.807576 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_16875.solverstate
I0525 03:11:21.424474 22565 solver.cpp:237] Iteration 17017, loss = 1.12955
I0525 03:11:21.424649 22565 solver.cpp:253]     Train net output #0: loss = 1.12955 (* 1 = 1.12955 loss)
I0525 03:11:21.424669 22565 sgd_solver.cpp:106] Iteration 17017, lr = 0.005
I0525 03:11:30.081764 22565 solver.cpp:237] Iteration 17204, loss = 1.25038
I0525 03:11:30.081801 22565 solver.cpp:253]     Train net output #0: loss = 1.25038 (* 1 = 1.25038 loss)
I0525 03:11:30.081820 22565 sgd_solver.cpp:106] Iteration 17204, lr = 0.005
I0525 03:11:38.738121 22565 solver.cpp:237] Iteration 17391, loss = 1.25901
I0525 03:11:38.738159 22565 solver.cpp:253]     Train net output #0: loss = 1.25901 (* 1 = 1.25901 loss)
I0525 03:11:38.738178 22565 sgd_solver.cpp:106] Iteration 17391, lr = 0.005
I0525 03:12:09.535646 22565 solver.cpp:237] Iteration 17578, loss = 1.19407
I0525 03:12:09.535830 22565 solver.cpp:253]     Train net output #0: loss = 1.19407 (* 1 = 1.19407 loss)
I0525 03:12:09.535847 22565 sgd_solver.cpp:106] Iteration 17578, lr = 0.005
I0525 03:12:18.190371 22565 solver.cpp:237] Iteration 17765, loss = 1.07034
I0525 03:12:18.190407 22565 solver.cpp:253]     Train net output #0: loss = 1.07034 (* 1 = 1.07034 loss)
I0525 03:12:18.190426 22565 sgd_solver.cpp:106] Iteration 17765, lr = 0.005
I0525 03:12:26.845754 22565 solver.cpp:237] Iteration 17952, loss = 0.891127
I0525 03:12:26.845793 22565 solver.cpp:253]     Train net output #0: loss = 0.891127 (* 1 = 0.891127 loss)
I0525 03:12:26.845811 22565 sgd_solver.cpp:106] Iteration 17952, lr = 0.005
I0525 03:12:35.500474 22565 solver.cpp:237] Iteration 18139, loss = 1.34521
I0525 03:12:35.500532 22565 solver.cpp:253]     Train net output #0: loss = 1.34521 (* 1 = 1.34521 loss)
I0525 03:12:35.500551 22565 sgd_solver.cpp:106] Iteration 18139, lr = 0.005
I0525 03:12:44.155732 22565 solver.cpp:237] Iteration 18326, loss = 1.10515
I0525 03:12:44.155884 22565 solver.cpp:253]     Train net output #0: loss = 1.10515 (* 1 = 1.10515 loss)
I0525 03:12:44.155901 22565 sgd_solver.cpp:106] Iteration 18326, lr = 0.005
I0525 03:12:52.806855 22565 solver.cpp:237] Iteration 18513, loss = 1.22975
I0525 03:12:52.806892 22565 solver.cpp:253]     Train net output #0: loss = 1.22975 (* 1 = 1.22975 loss)
I0525 03:12:52.806910 22565 sgd_solver.cpp:106] Iteration 18513, lr = 0.005
I0525 03:13:01.461455 22565 solver.cpp:237] Iteration 18700, loss = 1.74686
I0525 03:13:01.461510 22565 solver.cpp:253]     Train net output #0: loss = 1.74686 (* 1 = 1.74686 loss)
I0525 03:13:01.461527 22565 sgd_solver.cpp:106] Iteration 18700, lr = 0.005
I0525 03:13:03.728052 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_18750.caffemodel
I0525 03:13:03.799191 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_18750.solverstate
I0525 03:13:03.827018 22565 solver.cpp:341] Iteration 18750, Testing net (#0)
I0525 03:13:51.191773 22565 solver.cpp:409]     Test net output #0: accuracy = 0.875705
I0525 03:13:51.191946 22565 solver.cpp:409]     Test net output #1: loss = 0.416005 (* 1 = 0.416005 loss)
I0525 03:14:18.352417 22565 solver.cpp:237] Iteration 18887, loss = 1.17612
I0525 03:14:18.352478 22565 solver.cpp:253]     Train net output #0: loss = 1.17612 (* 1 = 1.17612 loss)
I0525 03:14:18.352502 22565 sgd_solver.cpp:106] Iteration 18887, lr = 0.005
I0525 03:14:27.012995 22565 solver.cpp:237] Iteration 19074, loss = 1.18342
I0525 03:14:27.013150 22565 solver.cpp:253]     Train net output #0: loss = 1.18342 (* 1 = 1.18342 loss)
I0525 03:14:27.013167 22565 sgd_solver.cpp:106] Iteration 19074, lr = 0.005
I0525 03:14:35.669270 22565 solver.cpp:237] Iteration 19261, loss = 1.26798
I0525 03:14:35.669308 22565 solver.cpp:253]     Train net output #0: loss = 1.26798 (* 1 = 1.26798 loss)
I0525 03:14:35.669327 22565 sgd_solver.cpp:106] Iteration 19261, lr = 0.005
I0525 03:14:44.327265 22565 solver.cpp:237] Iteration 19448, loss = 1.1579
I0525 03:14:44.327318 22565 solver.cpp:253]     Train net output #0: loss = 1.1579 (* 1 = 1.1579 loss)
I0525 03:14:44.327343 22565 sgd_solver.cpp:106] Iteration 19448, lr = 0.005
I0525 03:14:52.983954 22565 solver.cpp:237] Iteration 19635, loss = 1.26952
I0525 03:14:52.983992 22565 solver.cpp:253]     Train net output #0: loss = 1.26952 (* 1 = 1.26952 loss)
I0525 03:14:52.984010 22565 sgd_solver.cpp:106] Iteration 19635, lr = 0.005
I0525 03:15:01.637642 22565 solver.cpp:237] Iteration 19822, loss = 1.05153
I0525 03:15:01.637814 22565 solver.cpp:253]     Train net output #0: loss = 1.05153 (* 1 = 1.05153 loss)
I0525 03:15:01.637831 22565 sgd_solver.cpp:106] Iteration 19822, lr = 0.005
I0525 03:15:31.105451 22565 solver.cpp:237] Iteration 20009, loss = 1.36335
I0525 03:15:31.105510 22565 solver.cpp:253]     Train net output #0: loss = 1.36335 (* 1 = 1.36335 loss)
I0525 03:15:31.105537 22565 sgd_solver.cpp:106] Iteration 20009, lr = 0.005
I0525 03:15:39.765733 22565 solver.cpp:237] Iteration 20196, loss = 1.0016
I0525 03:15:39.765892 22565 solver.cpp:253]     Train net output #0: loss = 1.0016 (* 1 = 1.0016 loss)
I0525 03:15:39.765908 22565 sgd_solver.cpp:106] Iteration 20196, lr = 0.005
I0525 03:15:48.423046 22565 solver.cpp:237] Iteration 20383, loss = 1.32898
I0525 03:15:48.423084 22565 solver.cpp:253]     Train net output #0: loss = 1.32898 (* 1 = 1.32898 loss)
I0525 03:15:48.423101 22565 sgd_solver.cpp:106] Iteration 20383, lr = 0.005
I0525 03:15:57.079190 22565 solver.cpp:237] Iteration 20570, loss = 1.16017
I0525 03:15:57.079246 22565 solver.cpp:253]     Train net output #0: loss = 1.16017 (* 1 = 1.16017 loss)
I0525 03:15:57.079272 22565 sgd_solver.cpp:106] Iteration 20570, lr = 0.005
I0525 03:15:59.580327 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_20625.caffemodel
I0525 03:15:59.649801 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_20625.solverstate
I0525 03:16:05.802299 22565 solver.cpp:237] Iteration 20757, loss = 1.16706
I0525 03:16:05.802356 22565 solver.cpp:253]     Train net output #0: loss = 1.16706 (* 1 = 1.16706 loss)
I0525 03:16:05.802381 22565 sgd_solver.cpp:106] Iteration 20757, lr = 0.005
I0525 03:16:14.459309 22565 solver.cpp:237] Iteration 20944, loss = 1.14476
I0525 03:16:14.459465 22565 solver.cpp:253]     Train net output #0: loss = 1.14476 (* 1 = 1.14476 loss)
I0525 03:16:14.459481 22565 sgd_solver.cpp:106] Iteration 20944, lr = 0.005
I0525 03:16:23.117400 22565 solver.cpp:237] Iteration 21131, loss = 1.21172
I0525 03:16:23.117460 22565 solver.cpp:253]     Train net output #0: loss = 1.21172 (* 1 = 1.21172 loss)
I0525 03:16:23.117485 22565 sgd_solver.cpp:106] Iteration 21131, lr = 0.005
I0525 03:16:52.618325 22565 solver.cpp:237] Iteration 21318, loss = 1.08202
I0525 03:16:52.618505 22565 solver.cpp:253]     Train net output #0: loss = 1.08202 (* 1 = 1.08202 loss)
I0525 03:16:52.618523 22565 sgd_solver.cpp:106] Iteration 21318, lr = 0.005
I0525 03:17:01.276901 22565 solver.cpp:237] Iteration 21505, loss = 1.29665
I0525 03:17:01.276937 22565 solver.cpp:253]     Train net output #0: loss = 1.29665 (* 1 = 1.29665 loss)
I0525 03:17:01.276957 22565 sgd_solver.cpp:106] Iteration 21505, lr = 0.005
I0525 03:17:09.938601 22565 solver.cpp:237] Iteration 21692, loss = 1.3338
I0525 03:17:09.938654 22565 solver.cpp:253]     Train net output #0: loss = 1.3338 (* 1 = 1.3338 loss)
I0525 03:17:09.938671 22565 sgd_solver.cpp:106] Iteration 21692, lr = 0.005
I0525 03:17:18.593677 22565 solver.cpp:237] Iteration 21879, loss = 1.07513
I0525 03:17:18.593714 22565 solver.cpp:253]     Train net output #0: loss = 1.07513 (* 1 = 1.07513 loss)
I0525 03:17:18.593732 22565 sgd_solver.cpp:106] Iteration 21879, lr = 0.005
I0525 03:17:27.252414 22565 solver.cpp:237] Iteration 22066, loss = 1.11592
I0525 03:17:27.252567 22565 solver.cpp:253]     Train net output #0: loss = 1.11592 (* 1 = 1.11592 loss)
I0525 03:17:27.252583 22565 sgd_solver.cpp:106] Iteration 22066, lr = 0.005
I0525 03:17:35.910140 22565 solver.cpp:237] Iteration 22253, loss = 1.55466
I0525 03:17:35.910195 22565 solver.cpp:253]     Train net output #0: loss = 1.55466 (* 1 = 1.55466 loss)
I0525 03:17:35.910219 22565 sgd_solver.cpp:106] Iteration 22253, lr = 0.005
I0525 03:17:44.568419 22565 solver.cpp:237] Iteration 22440, loss = 1.19546
I0525 03:17:44.568456 22565 solver.cpp:253]     Train net output #0: loss = 1.19546 (* 1 = 1.19546 loss)
I0525 03:17:44.568475 22565 sgd_solver.cpp:106] Iteration 22440, lr = 0.005
I0525 03:17:47.299046 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_22500.caffemodel
I0525 03:17:47.368419 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_22500.solverstate
I0525 03:17:47.395282 22565 solver.cpp:341] Iteration 22500, Testing net (#0)
I0525 03:18:55.509116 22565 solver.cpp:409]     Test net output #0: accuracy = 0.87602
I0525 03:18:55.509311 22565 solver.cpp:409]     Test net output #1: loss = 0.383942 (* 1 = 0.383942 loss)
I0525 03:19:22.204447 22565 solver.cpp:237] Iteration 22627, loss = 1.29526
I0525 03:19:22.204502 22565 solver.cpp:253]     Train net output #0: loss = 1.29526 (* 1 = 1.29526 loss)
I0525 03:19:22.204527 22565 sgd_solver.cpp:106] Iteration 22627, lr = 0.005
I0525 03:19:30.847800 22565 solver.cpp:237] Iteration 22814, loss = 1.22433
I0525 03:19:30.847970 22565 solver.cpp:253]     Train net output #0: loss = 1.22433 (* 1 = 1.22433 loss)
I0525 03:19:30.847987 22565 sgd_solver.cpp:106] Iteration 22814, lr = 0.005
I0525 03:19:39.491976 22565 solver.cpp:237] Iteration 23001, loss = 1.21153
I0525 03:19:39.492032 22565 solver.cpp:253]     Train net output #0: loss = 1.21153 (* 1 = 1.21153 loss)
I0525 03:19:39.492056 22565 sgd_solver.cpp:106] Iteration 23001, lr = 0.005
I0525 03:19:48.134138 22565 solver.cpp:237] Iteration 23188, loss = 1.29263
I0525 03:19:48.134176 22565 solver.cpp:253]     Train net output #0: loss = 1.29263 (* 1 = 1.29263 loss)
I0525 03:19:48.134193 22565 sgd_solver.cpp:106] Iteration 23188, lr = 0.005
I0525 03:19:56.779486 22565 solver.cpp:237] Iteration 23375, loss = 1.10512
I0525 03:19:56.779523 22565 solver.cpp:253]     Train net output #0: loss = 1.10512 (* 1 = 1.10512 loss)
I0525 03:19:56.779541 22565 sgd_solver.cpp:106] Iteration 23375, lr = 0.005
I0525 03:20:05.424617 22565 solver.cpp:237] Iteration 23562, loss = 1.34524
I0525 03:20:05.424787 22565 solver.cpp:253]     Train net output #0: loss = 1.34524 (* 1 = 1.34524 loss)
I0525 03:20:05.424804 22565 sgd_solver.cpp:106] Iteration 23562, lr = 0.005
I0525 03:20:14.065165 22565 solver.cpp:237] Iteration 23749, loss = 0.951432
I0525 03:20:14.065203 22565 solver.cpp:253]     Train net output #0: loss = 0.951432 (* 1 = 0.951432 loss)
I0525 03:20:14.065222 22565 sgd_solver.cpp:106] Iteration 23749, lr = 0.005
I0525 03:20:43.552337 22565 solver.cpp:237] Iteration 23936, loss = 1.12974
I0525 03:20:43.552523 22565 solver.cpp:253]     Train net output #0: loss = 1.12974 (* 1 = 1.12974 loss)
I0525 03:20:43.552541 22565 sgd_solver.cpp:106] Iteration 23936, lr = 0.005
I0525 03:20:52.196120 22565 solver.cpp:237] Iteration 24123, loss = 1.43229
I0525 03:20:52.196156 22565 solver.cpp:253]     Train net output #0: loss = 1.43229 (* 1 = 1.43229 loss)
I0525 03:20:52.196174 22565 sgd_solver.cpp:106] Iteration 24123, lr = 0.005
I0525 03:21:00.846290 22565 solver.cpp:237] Iteration 24310, loss = 1.30344
I0525 03:21:00.846341 22565 solver.cpp:253]     Train net output #0: loss = 1.30344 (* 1 = 1.30344 loss)
I0525 03:21:00.846369 22565 sgd_solver.cpp:106] Iteration 24310, lr = 0.005
I0525 03:21:03.805369 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_24375.caffemodel
I0525 03:21:03.875159 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_24375.solverstate
I0525 03:21:09.559852 22565 solver.cpp:237] Iteration 24497, loss = 1.32666
I0525 03:21:09.559907 22565 solver.cpp:253]     Train net output #0: loss = 1.32666 (* 1 = 1.32666 loss)
I0525 03:21:09.559924 22565 sgd_solver.cpp:106] Iteration 24497, lr = 0.005
I0525 03:21:18.205693 22565 solver.cpp:237] Iteration 24684, loss = 1.19585
I0525 03:21:18.205860 22565 solver.cpp:253]     Train net output #0: loss = 1.19585 (* 1 = 1.19585 loss)
I0525 03:21:18.205876 22565 sgd_solver.cpp:106] Iteration 24684, lr = 0.005
I0525 03:21:26.867352 22565 solver.cpp:237] Iteration 24871, loss = 0.94774
I0525 03:21:26.867410 22565 solver.cpp:253]     Train net output #0: loss = 0.94774 (* 1 = 0.94774 loss)
I0525 03:21:26.867434 22565 sgd_solver.cpp:106] Iteration 24871, lr = 0.005
I0525 03:21:56.350735 22565 solver.cpp:237] Iteration 25058, loss = 1.19997
I0525 03:21:56.350919 22565 solver.cpp:253]     Train net output #0: loss = 1.19997 (* 1 = 1.19997 loss)
I0525 03:21:56.350936 22565 sgd_solver.cpp:106] Iteration 25058, lr = 0.005
I0525 03:22:05.010831 22565 solver.cpp:237] Iteration 25245, loss = 1.04294
I0525 03:22:05.010869 22565 solver.cpp:253]     Train net output #0: loss = 1.04294 (* 1 = 1.04294 loss)
I0525 03:22:05.010886 22565 sgd_solver.cpp:106] Iteration 25245, lr = 0.005
I0525 03:22:13.676237 22565 solver.cpp:237] Iteration 25432, loss = 1.15074
I0525 03:22:13.676301 22565 solver.cpp:253]     Train net output #0: loss = 1.15074 (* 1 = 1.15074 loss)
I0525 03:22:13.676326 22565 sgd_solver.cpp:106] Iteration 25432, lr = 0.005
I0525 03:22:22.340955 22565 solver.cpp:237] Iteration 25619, loss = 1.03702
I0525 03:22:22.340992 22565 solver.cpp:253]     Train net output #0: loss = 1.03702 (* 1 = 1.03702 loss)
I0525 03:22:22.341011 22565 sgd_solver.cpp:106] Iteration 25619, lr = 0.005
I0525 03:22:31.003731 22565 solver.cpp:237] Iteration 25806, loss = 1.2531
I0525 03:22:31.003886 22565 solver.cpp:253]     Train net output #0: loss = 1.2531 (* 1 = 1.2531 loss)
I0525 03:22:31.003903 22565 sgd_solver.cpp:106] Iteration 25806, lr = 0.005
I0525 03:22:39.668601 22565 solver.cpp:237] Iteration 25993, loss = 1.05373
I0525 03:22:39.668658 22565 solver.cpp:253]     Train net output #0: loss = 1.05373 (* 1 = 1.05373 loss)
I0525 03:22:39.668684 22565 sgd_solver.cpp:106] Iteration 25993, lr = 0.005
I0525 03:22:48.330754 22565 solver.cpp:237] Iteration 26180, loss = 1.09556
I0525 03:22:48.330790 22565 solver.cpp:253]     Train net output #0: loss = 1.09556 (* 1 = 1.09556 loss)
I0525 03:22:48.330808 22565 sgd_solver.cpp:106] Iteration 26180, lr = 0.005
I0525 03:22:51.525534 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_26250.caffemodel
I0525 03:22:51.595614 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_26250.solverstate
I0525 03:22:51.621863 22565 solver.cpp:341] Iteration 26250, Testing net (#0)
I0525 03:23:38.600996 22565 solver.cpp:409]     Test net output #0: accuracy = 0.8795
I0525 03:23:38.601173 22565 solver.cpp:409]     Test net output #1: loss = 0.4116 (* 1 = 0.4116 loss)
I0525 03:24:04.834333 22565 solver.cpp:237] Iteration 26367, loss = 1.13423
I0525 03:24:04.834393 22565 solver.cpp:253]     Train net output #0: loss = 1.13423 (* 1 = 1.13423 loss)
I0525 03:24:04.834413 22565 sgd_solver.cpp:106] Iteration 26367, lr = 0.005
I0525 03:24:13.478346 22565 solver.cpp:237] Iteration 26554, loss = 1.10648
I0525 03:24:13.478505 22565 solver.cpp:253]     Train net output #0: loss = 1.10648 (* 1 = 1.10648 loss)
I0525 03:24:13.478523 22565 sgd_solver.cpp:106] Iteration 26554, lr = 0.005
I0525 03:24:22.122686 22565 solver.cpp:237] Iteration 26741, loss = 0.943608
I0525 03:24:22.122742 22565 solver.cpp:253]     Train net output #0: loss = 0.943608 (* 1 = 0.943608 loss)
I0525 03:24:22.122767 22565 sgd_solver.cpp:106] Iteration 26741, lr = 0.005
I0525 03:24:30.767292 22565 solver.cpp:237] Iteration 26928, loss = 0.902317
I0525 03:24:30.767329 22565 solver.cpp:253]     Train net output #0: loss = 0.902317 (* 1 = 0.902317 loss)
I0525 03:24:30.767349 22565 sgd_solver.cpp:106] Iteration 26928, lr = 0.005
I0525 03:24:39.411980 22565 solver.cpp:237] Iteration 27115, loss = 1.31605
I0525 03:24:39.412036 22565 solver.cpp:253]     Train net output #0: loss = 1.31605 (* 1 = 1.31605 loss)
I0525 03:24:39.412063 22565 sgd_solver.cpp:106] Iteration 27115, lr = 0.005
I0525 03:24:48.055007 22565 solver.cpp:237] Iteration 27302, loss = 1.36374
I0525 03:24:48.055186 22565 solver.cpp:253]     Train net output #0: loss = 1.36374 (* 1 = 1.36374 loss)
I0525 03:24:48.055202 22565 sgd_solver.cpp:106] Iteration 27302, lr = 0.005
I0525 03:24:56.697597 22565 solver.cpp:237] Iteration 27489, loss = 1.18307
I0525 03:24:56.697634 22565 solver.cpp:253]     Train net output #0: loss = 1.18307 (* 1 = 1.18307 loss)
I0525 03:24:56.697652 22565 sgd_solver.cpp:106] Iteration 27489, lr = 0.005
I0525 03:25:26.121081 22565 solver.cpp:237] Iteration 27676, loss = 1.20847
I0525 03:25:26.121275 22565 solver.cpp:253]     Train net output #0: loss = 1.20847 (* 1 = 1.20847 loss)
I0525 03:25:26.121292 22565 sgd_solver.cpp:106] Iteration 27676, lr = 0.005
I0525 03:25:34.758347 22565 solver.cpp:237] Iteration 27863, loss = 1.23426
I0525 03:25:34.758406 22565 solver.cpp:253]     Train net output #0: loss = 1.23426 (* 1 = 1.23426 loss)
I0525 03:25:34.758431 22565 sgd_solver.cpp:106] Iteration 27863, lr = 0.005
I0525 03:25:43.394613 22565 solver.cpp:237] Iteration 28050, loss = 1.1782
I0525 03:25:43.394650 22565 solver.cpp:253]     Train net output #0: loss = 1.1782 (* 1 = 1.1782 loss)
I0525 03:25:43.394668 22565 sgd_solver.cpp:106] Iteration 28050, lr = 0.005
I0525 03:25:46.811765 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_28125.caffemodel
I0525 03:25:46.883541 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_28125.solverstate
I0525 03:25:52.098379 22565 solver.cpp:237] Iteration 28237, loss = 1.18896
I0525 03:25:52.098438 22565 solver.cpp:253]     Train net output #0: loss = 1.18896 (* 1 = 1.18896 loss)
I0525 03:25:52.098462 22565 sgd_solver.cpp:106] Iteration 28237, lr = 0.005
I0525 03:26:00.743553 22565 solver.cpp:237] Iteration 28424, loss = 1.1163
I0525 03:26:00.743733 22565 solver.cpp:253]     Train net output #0: loss = 1.1163 (* 1 = 1.1163 loss)
I0525 03:26:00.743752 22565 sgd_solver.cpp:106] Iteration 28424, lr = 0.005
I0525 03:26:09.386615 22565 solver.cpp:237] Iteration 28611, loss = 1.31044
I0525 03:26:09.386651 22565 solver.cpp:253]     Train net output #0: loss = 1.31044 (* 1 = 1.31044 loss)
I0525 03:26:09.386670 22565 sgd_solver.cpp:106] Iteration 28611, lr = 0.005
I0525 03:26:38.866740 22565 solver.cpp:237] Iteration 28798, loss = 1.38486
I0525 03:26:38.866922 22565 solver.cpp:253]     Train net output #0: loss = 1.38486 (* 1 = 1.38486 loss)
I0525 03:26:38.866940 22565 sgd_solver.cpp:106] Iteration 28798, lr = 0.005
I0525 03:26:47.509477 22565 solver.cpp:237] Iteration 28985, loss = 1.29868
I0525 03:26:47.509534 22565 solver.cpp:253]     Train net output #0: loss = 1.29868 (* 1 = 1.29868 loss)
I0525 03:26:47.509562 22565 sgd_solver.cpp:106] Iteration 28985, lr = 0.005
I0525 03:26:56.156321 22565 solver.cpp:237] Iteration 29172, loss = 1.4002
I0525 03:26:56.156357 22565 solver.cpp:253]     Train net output #0: loss = 1.4002 (* 1 = 1.4002 loss)
I0525 03:26:56.156379 22565 sgd_solver.cpp:106] Iteration 29172, lr = 0.005
I0525 03:27:04.799095 22565 solver.cpp:237] Iteration 29359, loss = 1.35528
I0525 03:27:04.799132 22565 solver.cpp:253]     Train net output #0: loss = 1.35528 (* 1 = 1.35528 loss)
I0525 03:27:04.799152 22565 sgd_solver.cpp:106] Iteration 29359, lr = 0.005
I0525 03:27:13.443951 22565 solver.cpp:237] Iteration 29546, loss = 1.1944
I0525 03:27:13.444136 22565 solver.cpp:253]     Train net output #0: loss = 1.1944 (* 1 = 1.1944 loss)
I0525 03:27:13.444154 22565 sgd_solver.cpp:106] Iteration 29546, lr = 0.005
I0525 03:27:22.089493 22565 solver.cpp:237] Iteration 29733, loss = 1.28989
I0525 03:27:22.089534 22565 solver.cpp:253]     Train net output #0: loss = 1.28989 (* 1 = 1.28989 loss)
I0525 03:27:22.089551 22565 sgd_solver.cpp:106] Iteration 29733, lr = 0.005
I0525 03:27:30.735069 22565 solver.cpp:237] Iteration 29920, loss = 1.22512
I0525 03:27:30.735107 22565 solver.cpp:253]     Train net output #0: loss = 1.22512 (* 1 = 1.22512 loss)
I0525 03:27:30.735126 22565 sgd_solver.cpp:106] Iteration 29920, lr = 0.005
I0525 03:27:34.390455 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_30000.caffemodel
I0525 03:27:34.460646 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_30000.solverstate
I0525 03:27:34.487382 22565 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 03:28:42.668256 22565 solver.cpp:409]     Test net output #0: accuracy = 0.883067
I0525 03:28:42.668445 22565 solver.cpp:409]     Test net output #1: loss = 0.365409 (* 1 = 0.365409 loss)
I0525 03:29:08.454201 22565 solver.cpp:237] Iteration 30107, loss = 1.2047
I0525 03:29:08.454262 22565 solver.cpp:253]     Train net output #0: loss = 1.2047 (* 1 = 1.2047 loss)
I0525 03:29:08.454282 22565 sgd_solver.cpp:106] Iteration 30107, lr = 0.005
I0525 03:29:17.125231 22565 solver.cpp:237] Iteration 30294, loss = 1.07586
I0525 03:29:17.125411 22565 solver.cpp:253]     Train net output #0: loss = 1.07586 (* 1 = 1.07586 loss)
I0525 03:29:17.125428 22565 sgd_solver.cpp:106] Iteration 30294, lr = 0.005
I0525 03:29:25.797334 22565 solver.cpp:237] Iteration 30481, loss = 1.33166
I0525 03:29:25.797371 22565 solver.cpp:253]     Train net output #0: loss = 1.33166 (* 1 = 1.33166 loss)
I0525 03:29:25.797390 22565 sgd_solver.cpp:106] Iteration 30481, lr = 0.005
I0525 03:29:34.468282 22565 solver.cpp:237] Iteration 30668, loss = 1.28973
I0525 03:29:34.468319 22565 solver.cpp:253]     Train net output #0: loss = 1.28973 (* 1 = 1.28973 loss)
I0525 03:29:34.468338 22565 sgd_solver.cpp:106] Iteration 30668, lr = 0.005
I0525 03:29:43.140626 22565 solver.cpp:237] Iteration 30855, loss = 1.16308
I0525 03:29:43.140683 22565 solver.cpp:253]     Train net output #0: loss = 1.16308 (* 1 = 1.16308 loss)
I0525 03:29:43.140700 22565 sgd_solver.cpp:106] Iteration 30855, lr = 0.005
I0525 03:29:51.813207 22565 solver.cpp:237] Iteration 31042, loss = 1.20891
I0525 03:29:51.813364 22565 solver.cpp:253]     Train net output #0: loss = 1.20891 (* 1 = 1.20891 loss)
I0525 03:29:51.813381 22565 sgd_solver.cpp:106] Iteration 31042, lr = 0.005
I0525 03:30:00.481389 22565 solver.cpp:237] Iteration 31229, loss = 1.31148
I0525 03:30:00.481426 22565 solver.cpp:253]     Train net output #0: loss = 1.31148 (* 1 = 1.31148 loss)
I0525 03:30:00.481446 22565 sgd_solver.cpp:106] Iteration 31229, lr = 0.005
I0525 03:30:29.950731 22565 solver.cpp:237] Iteration 31416, loss = 0.957518
I0525 03:30:29.950916 22565 solver.cpp:253]     Train net output #0: loss = 0.957518 (* 1 = 0.957518 loss)
I0525 03:30:29.950934 22565 sgd_solver.cpp:106] Iteration 31416, lr = 0.005
I0525 03:30:38.621367 22565 solver.cpp:237] Iteration 31603, loss = 1.08662
I0525 03:30:38.621404 22565 solver.cpp:253]     Train net output #0: loss = 1.08662 (* 1 = 1.08662 loss)
I0525 03:30:38.621428 22565 sgd_solver.cpp:106] Iteration 31603, lr = 0.005
I0525 03:30:47.292635 22565 solver.cpp:237] Iteration 31790, loss = 1.02362
I0525 03:30:47.292672 22565 solver.cpp:253]     Train net output #0: loss = 1.02362 (* 1 = 1.02362 loss)
I0525 03:30:47.292690 22565 sgd_solver.cpp:106] Iteration 31790, lr = 0.005
I0525 03:30:51.188048 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_31875.caffemodel
I0525 03:30:51.257172 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_31875.solverstate
I0525 03:30:56.031013 22565 solver.cpp:237] Iteration 31977, loss = 0.96002
I0525 03:30:56.031071 22565 solver.cpp:253]     Train net output #0: loss = 0.96002 (* 1 = 0.96002 loss)
I0525 03:30:56.031100 22565 sgd_solver.cpp:106] Iteration 31977, lr = 0.005
I0525 03:31:04.701473 22565 solver.cpp:237] Iteration 32164, loss = 1.2502
I0525 03:31:04.701645 22565 solver.cpp:253]     Train net output #0: loss = 1.2502 (* 1 = 1.2502 loss)
I0525 03:31:04.701661 22565 sgd_solver.cpp:106] Iteration 32164, lr = 0.005
I0525 03:31:13.370304 22565 solver.cpp:237] Iteration 32351, loss = 1.14157
I0525 03:31:13.370342 22565 solver.cpp:253]     Train net output #0: loss = 1.14157 (* 1 = 1.14157 loss)
I0525 03:31:13.370359 22565 sgd_solver.cpp:106] Iteration 32351, lr = 0.005
I0525 03:31:42.892761 22565 solver.cpp:237] Iteration 32538, loss = 1.12211
I0525 03:31:42.892957 22565 solver.cpp:253]     Train net output #0: loss = 1.12211 (* 1 = 1.12211 loss)
I0525 03:31:42.892976 22565 sgd_solver.cpp:106] Iteration 32538, lr = 0.005
I0525 03:31:51.547971 22565 solver.cpp:237] Iteration 32725, loss = 0.992179
I0525 03:31:51.548032 22565 solver.cpp:253]     Train net output #0: loss = 0.992179 (* 1 = 0.992179 loss)
I0525 03:31:51.548056 22565 sgd_solver.cpp:106] Iteration 32725, lr = 0.005
I0525 03:32:00.197439 22565 solver.cpp:237] Iteration 32912, loss = 1.08363
I0525 03:32:00.197475 22565 solver.cpp:253]     Train net output #0: loss = 1.08363 (* 1 = 1.08363 loss)
I0525 03:32:00.197499 22565 sgd_solver.cpp:106] Iteration 32912, lr = 0.005
I0525 03:32:08.851135 22565 solver.cpp:237] Iteration 33099, loss = 1.32449
I0525 03:32:08.851183 22565 solver.cpp:253]     Train net output #0: loss = 1.32449 (* 1 = 1.32449 loss)
I0525 03:32:08.851200 22565 sgd_solver.cpp:106] Iteration 33099, lr = 0.005
I0525 03:32:17.510336 22565 solver.cpp:237] Iteration 33286, loss = 1.26501
I0525 03:32:17.510499 22565 solver.cpp:253]     Train net output #0: loss = 1.26501 (* 1 = 1.26501 loss)
I0525 03:32:17.510515 22565 sgd_solver.cpp:106] Iteration 33286, lr = 0.005
I0525 03:32:26.170408 22565 solver.cpp:237] Iteration 33473, loss = 1.10974
I0525 03:32:26.170446 22565 solver.cpp:253]     Train net output #0: loss = 1.10974 (* 1 = 1.10974 loss)
I0525 03:32:26.170464 22565 sgd_solver.cpp:106] Iteration 33473, lr = 0.005
I0525 03:32:34.830095 22565 solver.cpp:237] Iteration 33660, loss = 1.03619
I0525 03:32:34.830152 22565 solver.cpp:253]     Train net output #0: loss = 1.03619 (* 1 = 1.03619 loss)
I0525 03:32:34.830178 22565 sgd_solver.cpp:106] Iteration 33660, lr = 0.005
I0525 03:32:38.950461 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_33750.caffemodel
I0525 03:32:39.020084 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_33750.solverstate
I0525 03:32:39.047448 22565 solver.cpp:341] Iteration 33750, Testing net (#0)
I0525 03:33:26.402884 22565 solver.cpp:409]     Test net output #0: accuracy = 0.88512
I0525 03:33:26.403065 22565 solver.cpp:409]     Test net output #1: loss = 0.356246 (* 1 = 0.356246 loss)
I0525 03:33:51.711575 22565 solver.cpp:237] Iteration 33847, loss = 1.06855
I0525 03:33:51.711637 22565 solver.cpp:253]     Train net output #0: loss = 1.06855 (* 1 = 1.06855 loss)
I0525 03:33:51.711661 22565 sgd_solver.cpp:106] Iteration 33847, lr = 0.005
I0525 03:34:00.351982 22565 solver.cpp:237] Iteration 34034, loss = 1.06803
I0525 03:34:00.352155 22565 solver.cpp:253]     Train net output #0: loss = 1.06803 (* 1 = 1.06803 loss)
I0525 03:34:00.352172 22565 sgd_solver.cpp:106] Iteration 34034, lr = 0.005
I0525 03:34:08.992854 22565 solver.cpp:237] Iteration 34221, loss = 1.2672
I0525 03:34:08.992890 22565 solver.cpp:253]     Train net output #0: loss = 1.2672 (* 1 = 1.2672 loss)
I0525 03:34:08.992913 22565 sgd_solver.cpp:106] Iteration 34221, lr = 0.005
I0525 03:34:17.631497 22565 solver.cpp:237] Iteration 34408, loss = 1.02458
I0525 03:34:17.631553 22565 solver.cpp:253]     Train net output #0: loss = 1.02458 (* 1 = 1.02458 loss)
I0525 03:34:17.631582 22565 sgd_solver.cpp:106] Iteration 34408, lr = 0.005
I0525 03:34:26.276541 22565 solver.cpp:237] Iteration 34595, loss = 0.941324
I0525 03:34:26.276582 22565 solver.cpp:253]     Train net output #0: loss = 0.941324 (* 1 = 0.941324 loss)
I0525 03:34:26.276598 22565 sgd_solver.cpp:106] Iteration 34595, lr = 0.005
I0525 03:34:34.922593 22565 solver.cpp:237] Iteration 34782, loss = 1.27959
I0525 03:34:34.922772 22565 solver.cpp:253]     Train net output #0: loss = 1.27959 (* 1 = 1.27959 loss)
I0525 03:34:34.922790 22565 sgd_solver.cpp:106] Iteration 34782, lr = 0.005
I0525 03:34:43.562666 22565 solver.cpp:237] Iteration 34969, loss = 1.01954
I0525 03:34:43.562721 22565 solver.cpp:253]     Train net output #0: loss = 1.01954 (* 1 = 1.01954 loss)
I0525 03:34:43.562748 22565 sgd_solver.cpp:106] Iteration 34969, lr = 0.005
I0525 03:35:13.045260 22565 solver.cpp:237] Iteration 35156, loss = 1.21453
I0525 03:35:13.045445 22565 solver.cpp:253]     Train net output #0: loss = 1.21453 (* 1 = 1.21453 loss)
I0525 03:35:13.045464 22565 sgd_solver.cpp:106] Iteration 35156, lr = 0.005
I0525 03:35:21.689553 22565 solver.cpp:237] Iteration 35343, loss = 1.14505
I0525 03:35:21.689589 22565 solver.cpp:253]     Train net output #0: loss = 1.14505 (* 1 = 1.14505 loss)
I0525 03:35:21.689613 22565 sgd_solver.cpp:106] Iteration 35343, lr = 0.005
I0525 03:35:30.328018 22565 solver.cpp:237] Iteration 35530, loss = 1.26012
I0525 03:35:30.328073 22565 solver.cpp:253]     Train net output #0: loss = 1.26012 (* 1 = 1.26012 loss)
I0525 03:35:30.328091 22565 sgd_solver.cpp:106] Iteration 35530, lr = 0.005
I0525 03:35:34.673261 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_35625.caffemodel
I0525 03:35:34.745997 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_35625.solverstate
I0525 03:35:39.039409 22565 solver.cpp:237] Iteration 35717, loss = 1.35101
I0525 03:35:39.039464 22565 solver.cpp:253]     Train net output #0: loss = 1.35101 (* 1 = 1.35101 loss)
I0525 03:35:39.039491 22565 sgd_solver.cpp:106] Iteration 35717, lr = 0.005
I0525 03:35:47.681712 22565 solver.cpp:237] Iteration 35904, loss = 1.37365
I0525 03:35:47.681875 22565 solver.cpp:253]     Train net output #0: loss = 1.37365 (* 1 = 1.37365 loss)
I0525 03:35:47.681892 22565 sgd_solver.cpp:106] Iteration 35904, lr = 0.005
I0525 03:35:56.327280 22565 solver.cpp:237] Iteration 36091, loss = 1.5031
I0525 03:35:56.327335 22565 solver.cpp:253]     Train net output #0: loss = 1.5031 (* 1 = 1.5031 loss)
I0525 03:35:56.327354 22565 sgd_solver.cpp:106] Iteration 36091, lr = 0.005
I0525 03:36:25.858425 22565 solver.cpp:237] Iteration 36278, loss = 1.28781
I0525 03:36:25.858595 22565 solver.cpp:253]     Train net output #0: loss = 1.28781 (* 1 = 1.28781 loss)
I0525 03:36:25.858615 22565 sgd_solver.cpp:106] Iteration 36278, lr = 0.005
I0525 03:36:34.500427 22565 solver.cpp:237] Iteration 36465, loss = 1.25498
I0525 03:36:34.500464 22565 solver.cpp:253]     Train net output #0: loss = 1.25498 (* 1 = 1.25498 loss)
I0525 03:36:34.500483 22565 sgd_solver.cpp:106] Iteration 36465, lr = 0.005
I0525 03:36:43.140777 22565 solver.cpp:237] Iteration 36652, loss = 1.00003
I0525 03:36:43.140813 22565 solver.cpp:253]     Train net output #0: loss = 1.00003 (* 1 = 1.00003 loss)
I0525 03:36:43.140837 22565 sgd_solver.cpp:106] Iteration 36652, lr = 0.005
I0525 03:36:51.787456 22565 solver.cpp:237] Iteration 36839, loss = 1.04588
I0525 03:36:51.787511 22565 solver.cpp:253]     Train net output #0: loss = 1.04588 (* 1 = 1.04588 loss)
I0525 03:36:51.787539 22565 sgd_solver.cpp:106] Iteration 36839, lr = 0.005
I0525 03:37:00.435755 22565 solver.cpp:237] Iteration 37026, loss = 1.05234
I0525 03:37:00.435925 22565 solver.cpp:253]     Train net output #0: loss = 1.05234 (* 1 = 1.05234 loss)
I0525 03:37:00.435942 22565 sgd_solver.cpp:106] Iteration 37026, lr = 0.005
I0525 03:37:09.084899 22565 solver.cpp:237] Iteration 37213, loss = 1.28163
I0525 03:37:09.084955 22565 solver.cpp:253]     Train net output #0: loss = 1.28163 (* 1 = 1.28163 loss)
I0525 03:37:09.084975 22565 sgd_solver.cpp:106] Iteration 37213, lr = 0.005
I0525 03:37:17.727505 22565 solver.cpp:237] Iteration 37400, loss = 1.27972
I0525 03:37:17.727543 22565 solver.cpp:253]     Train net output #0: loss = 1.27972 (* 1 = 1.27972 loss)
I0525 03:37:17.727561 22565 sgd_solver.cpp:106] Iteration 37400, lr = 0.005
I0525 03:37:22.303221 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_37500.caffemodel
I0525 03:37:22.374984 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_37500.solverstate
I0525 03:37:22.403230 22565 solver.cpp:341] Iteration 37500, Testing net (#0)
I0525 03:38:30.643759 22565 solver.cpp:409]     Test net output #0: accuracy = 0.885939
I0525 03:38:30.643944 22565 solver.cpp:409]     Test net output #1: loss = 0.370598 (* 1 = 0.370598 loss)
I0525 03:38:55.601107 22565 solver.cpp:237] Iteration 37587, loss = 1.13245
I0525 03:38:55.601166 22565 solver.cpp:253]     Train net output #0: loss = 1.13245 (* 1 = 1.13245 loss)
I0525 03:38:55.601186 22565 sgd_solver.cpp:106] Iteration 37587, lr = 0.005
I0525 03:39:04.259341 22565 solver.cpp:237] Iteration 37774, loss = 0.984428
I0525 03:39:04.259506 22565 solver.cpp:253]     Train net output #0: loss = 0.984428 (* 1 = 0.984428 loss)
I0525 03:39:04.259523 22565 sgd_solver.cpp:106] Iteration 37774, lr = 0.005
I0525 03:39:12.915668 22565 solver.cpp:237] Iteration 37961, loss = 1.12564
I0525 03:39:12.915705 22565 solver.cpp:253]     Train net output #0: loss = 1.12564 (* 1 = 1.12564 loss)
I0525 03:39:12.915724 22565 sgd_solver.cpp:106] Iteration 37961, lr = 0.005
I0525 03:39:21.572612 22565 solver.cpp:237] Iteration 38148, loss = 0.986928
I0525 03:39:21.572669 22565 solver.cpp:253]     Train net output #0: loss = 0.986928 (* 1 = 0.986928 loss)
I0525 03:39:21.572693 22565 sgd_solver.cpp:106] Iteration 38148, lr = 0.005
I0525 03:39:30.226400 22565 solver.cpp:237] Iteration 38335, loss = 1.24335
I0525 03:39:30.226438 22565 solver.cpp:253]     Train net output #0: loss = 1.24335 (* 1 = 1.24335 loss)
I0525 03:39:30.226460 22565 sgd_solver.cpp:106] Iteration 38335, lr = 0.005
I0525 03:39:38.881367 22565 solver.cpp:237] Iteration 38522, loss = 1.36319
I0525 03:39:38.881531 22565 solver.cpp:253]     Train net output #0: loss = 1.36319 (* 1 = 1.36319 loss)
I0525 03:39:38.881549 22565 sgd_solver.cpp:106] Iteration 38522, lr = 0.005
I0525 03:39:47.541326 22565 solver.cpp:237] Iteration 38709, loss = 1.04251
I0525 03:39:47.541363 22565 solver.cpp:253]     Train net output #0: loss = 1.04251 (* 1 = 1.04251 loss)
I0525 03:39:47.541383 22565 sgd_solver.cpp:106] Iteration 38709, lr = 0.005
I0525 03:40:17.049042 22565 solver.cpp:237] Iteration 38896, loss = 1.00897
I0525 03:40:17.049227 22565 solver.cpp:253]     Train net output #0: loss = 1.00897 (* 1 = 1.00897 loss)
I0525 03:40:17.049245 22565 sgd_solver.cpp:106] Iteration 38896, lr = 0.005
I0525 03:40:25.710109 22565 solver.cpp:237] Iteration 39083, loss = 0.959671
I0525 03:40:25.710147 22565 solver.cpp:253]     Train net output #0: loss = 0.959671 (* 1 = 0.959671 loss)
I0525 03:40:25.710166 22565 sgd_solver.cpp:106] Iteration 39083, lr = 0.005
I0525 03:40:34.375083 22565 solver.cpp:237] Iteration 39270, loss = 1.15931
I0525 03:40:34.375138 22565 solver.cpp:253]     Train net output #0: loss = 1.15931 (* 1 = 1.15931 loss)
I0525 03:40:34.375156 22565 sgd_solver.cpp:106] Iteration 39270, lr = 0.005
I0525 03:40:39.192661 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_39375.caffemodel
I0525 03:40:39.262504 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_39375.solverstate
I0525 03:40:43.101835 22565 solver.cpp:237] Iteration 39457, loss = 1.28903
I0525 03:40:43.101888 22565 solver.cpp:253]     Train net output #0: loss = 1.28903 (* 1 = 1.28903 loss)
I0525 03:40:43.101917 22565 sgd_solver.cpp:106] Iteration 39457, lr = 0.005
I0525 03:40:51.763654 22565 solver.cpp:237] Iteration 39644, loss = 1.07189
I0525 03:40:51.763835 22565 solver.cpp:253]     Train net output #0: loss = 1.07189 (* 1 = 1.07189 loss)
I0525 03:40:51.763852 22565 sgd_solver.cpp:106] Iteration 39644, lr = 0.005
I0525 03:41:00.427140 22565 solver.cpp:237] Iteration 39831, loss = 1.10542
I0525 03:41:00.427196 22565 solver.cpp:253]     Train net output #0: loss = 1.10542 (* 1 = 1.10542 loss)
I0525 03:41:00.427225 22565 sgd_solver.cpp:106] Iteration 39831, lr = 0.005
I0525 03:41:29.912914 22565 solver.cpp:237] Iteration 40018, loss = 1.03123
I0525 03:41:29.913101 22565 solver.cpp:253]     Train net output #0: loss = 1.03123 (* 1 = 1.03123 loss)
I0525 03:41:29.913120 22565 sgd_solver.cpp:106] Iteration 40018, lr = 0.005
I0525 03:41:38.575940 22565 solver.cpp:237] Iteration 40205, loss = 0.935586
I0525 03:41:38.575978 22565 solver.cpp:253]     Train net output #0: loss = 0.935586 (* 1 = 0.935586 loss)
I0525 03:41:38.575997 22565 sgd_solver.cpp:106] Iteration 40205, lr = 0.005
I0525 03:41:47.232808 22565 solver.cpp:237] Iteration 40392, loss = 1.1028
I0525 03:41:47.232863 22565 solver.cpp:253]     Train net output #0: loss = 1.1028 (* 1 = 1.1028 loss)
I0525 03:41:47.232880 22565 sgd_solver.cpp:106] Iteration 40392, lr = 0.005
I0525 03:41:55.888039 22565 solver.cpp:237] Iteration 40579, loss = 1.19008
I0525 03:41:55.888077 22565 solver.cpp:253]     Train net output #0: loss = 1.19008 (* 1 = 1.19008 loss)
I0525 03:41:55.888095 22565 sgd_solver.cpp:106] Iteration 40579, lr = 0.005
I0525 03:42:04.541746 22565 solver.cpp:237] Iteration 40766, loss = 1.3662
I0525 03:42:04.541908 22565 solver.cpp:253]     Train net output #0: loss = 1.3662 (* 1 = 1.3662 loss)
I0525 03:42:04.541925 22565 sgd_solver.cpp:106] Iteration 40766, lr = 0.005
I0525 03:42:13.198184 22565 solver.cpp:237] Iteration 40953, loss = 1.152
I0525 03:42:13.198240 22565 solver.cpp:253]     Train net output #0: loss = 1.152 (* 1 = 1.152 loss)
I0525 03:42:13.198256 22565 sgd_solver.cpp:106] Iteration 40953, lr = 0.005
I0525 03:42:21.857475 22565 solver.cpp:237] Iteration 41140, loss = 1.25834
I0525 03:42:21.857514 22565 solver.cpp:253]     Train net output #0: loss = 1.25834 (* 1 = 1.25834 loss)
I0525 03:42:21.857532 22565 sgd_solver.cpp:106] Iteration 41140, lr = 0.005
I0525 03:42:26.905784 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_41250.caffemodel
I0525 03:42:26.975466 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_41250.solverstate
I0525 03:42:27.001843 22565 solver.cpp:341] Iteration 41250, Testing net (#0)
I0525 03:43:14.058177 22565 solver.cpp:409]     Test net output #0: accuracy = 0.889826
I0525 03:43:14.058362 22565 solver.cpp:409]     Test net output #1: loss = 0.348437 (* 1 = 0.348437 loss)
I0525 03:43:38.483449 22565 solver.cpp:237] Iteration 41327, loss = 1.19306
I0525 03:43:38.483510 22565 solver.cpp:253]     Train net output #0: loss = 1.19306 (* 1 = 1.19306 loss)
I0525 03:43:38.483535 22565 sgd_solver.cpp:106] Iteration 41327, lr = 0.005
I0525 03:43:47.138959 22565 solver.cpp:237] Iteration 41514, loss = 1.0884
I0525 03:43:47.139135 22565 solver.cpp:253]     Train net output #0: loss = 1.0884 (* 1 = 1.0884 loss)
I0525 03:43:47.139152 22565 sgd_solver.cpp:106] Iteration 41514, lr = 0.005
I0525 03:43:55.798543 22565 solver.cpp:237] Iteration 41701, loss = 1.14887
I0525 03:43:55.798593 22565 solver.cpp:253]     Train net output #0: loss = 1.14887 (* 1 = 1.14887 loss)
I0525 03:43:55.798617 22565 sgd_solver.cpp:106] Iteration 41701, lr = 0.005
I0525 03:44:04.455833 22565 solver.cpp:237] Iteration 41888, loss = 1.45859
I0525 03:44:04.455871 22565 solver.cpp:253]     Train net output #0: loss = 1.45859 (* 1 = 1.45859 loss)
I0525 03:44:04.455888 22565 sgd_solver.cpp:106] Iteration 41888, lr = 0.005
I0525 03:44:13.114753 22565 solver.cpp:237] Iteration 42075, loss = 1.27932
I0525 03:44:13.114790 22565 solver.cpp:253]     Train net output #0: loss = 1.27932 (* 1 = 1.27932 loss)
I0525 03:44:13.114809 22565 sgd_solver.cpp:106] Iteration 42075, lr = 0.005
I0525 03:44:21.777465 22565 solver.cpp:237] Iteration 42262, loss = 1.07419
I0525 03:44:21.777637 22565 solver.cpp:253]     Train net output #0: loss = 1.07419 (* 1 = 1.07419 loss)
I0525 03:44:21.777655 22565 sgd_solver.cpp:106] Iteration 42262, lr = 0.005
I0525 03:44:30.432312 22565 solver.cpp:237] Iteration 42449, loss = 1.37098
I0525 03:44:30.432348 22565 solver.cpp:253]     Train net output #0: loss = 1.37098 (* 1 = 1.37098 loss)
I0525 03:44:30.432365 22565 sgd_solver.cpp:106] Iteration 42449, lr = 0.005
I0525 03:44:59.972226 22565 solver.cpp:237] Iteration 42636, loss = 1.16332
I0525 03:44:59.972419 22565 solver.cpp:253]     Train net output #0: loss = 1.16332 (* 1 = 1.16332 loss)
I0525 03:44:59.972437 22565 sgd_solver.cpp:106] Iteration 42636, lr = 0.005
I0525 03:45:08.630924 22565 solver.cpp:237] Iteration 42823, loss = 1.1263
I0525 03:45:08.630981 22565 solver.cpp:253]     Train net output #0: loss = 1.1263 (* 1 = 1.1263 loss)
I0525 03:45:08.631007 22565 sgd_solver.cpp:106] Iteration 42823, lr = 0.005
I0525 03:45:17.293349 22565 solver.cpp:237] Iteration 43010, loss = 1.00173
I0525 03:45:17.293386 22565 solver.cpp:253]     Train net output #0: loss = 1.00173 (* 1 = 1.00173 loss)
I0525 03:45:17.293404 22565 sgd_solver.cpp:106] Iteration 43010, lr = 0.005
I0525 03:45:22.571852 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_43125.caffemodel
I0525 03:45:22.641324 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_43125.solverstate
I0525 03:45:26.017849 22565 solver.cpp:237] Iteration 43197, loss = 1.27031
I0525 03:45:26.017905 22565 solver.cpp:253]     Train net output #0: loss = 1.27031 (* 1 = 1.27031 loss)
I0525 03:45:26.017931 22565 sgd_solver.cpp:106] Iteration 43197, lr = 0.005
I0525 03:45:34.673456 22565 solver.cpp:237] Iteration 43384, loss = 1.1805
I0525 03:45:34.673642 22565 solver.cpp:253]     Train net output #0: loss = 1.1805 (* 1 = 1.1805 loss)
I0525 03:45:34.673660 22565 sgd_solver.cpp:106] Iteration 43384, lr = 0.005
I0525 03:45:43.327426 22565 solver.cpp:237] Iteration 43571, loss = 1.0664
I0525 03:45:43.327463 22565 solver.cpp:253]     Train net output #0: loss = 1.0664 (* 1 = 1.0664 loss)
I0525 03:45:43.327487 22565 sgd_solver.cpp:106] Iteration 43571, lr = 0.005
I0525 03:46:12.842741 22565 solver.cpp:237] Iteration 43758, loss = 1.13451
I0525 03:46:12.842931 22565 solver.cpp:253]     Train net output #0: loss = 1.13451 (* 1 = 1.13451 loss)
I0525 03:46:12.842949 22565 sgd_solver.cpp:106] Iteration 43758, lr = 0.005
I0525 03:46:21.496356 22565 solver.cpp:237] Iteration 43945, loss = 0.89279
I0525 03:46:21.496415 22565 solver.cpp:253]     Train net output #0: loss = 0.89279 (* 1 = 0.89279 loss)
I0525 03:46:21.496443 22565 sgd_solver.cpp:106] Iteration 43945, lr = 0.005
I0525 03:46:30.150419 22565 solver.cpp:237] Iteration 44132, loss = 1.10078
I0525 03:46:30.150455 22565 solver.cpp:253]     Train net output #0: loss = 1.10078 (* 1 = 1.10078 loss)
I0525 03:46:30.150478 22565 sgd_solver.cpp:106] Iteration 44132, lr = 0.005
I0525 03:46:38.805707 22565 solver.cpp:237] Iteration 44319, loss = 1.14256
I0525 03:46:38.805744 22565 solver.cpp:253]     Train net output #0: loss = 1.14256 (* 1 = 1.14256 loss)
I0525 03:46:38.805763 22565 sgd_solver.cpp:106] Iteration 44319, lr = 0.005
I0525 03:46:47.460080 22565 solver.cpp:237] Iteration 44506, loss = 1.1609
I0525 03:46:47.460278 22565 solver.cpp:253]     Train net output #0: loss = 1.1609 (* 1 = 1.1609 loss)
I0525 03:46:47.460296 22565 sgd_solver.cpp:106] Iteration 44506, lr = 0.005
I0525 03:46:56.120018 22565 solver.cpp:237] Iteration 44693, loss = 1.06086
I0525 03:46:56.120055 22565 solver.cpp:253]     Train net output #0: loss = 1.06086 (* 1 = 1.06086 loss)
I0525 03:46:56.120074 22565 sgd_solver.cpp:106] Iteration 44693, lr = 0.005
I0525 03:47:04.773589 22565 solver.cpp:237] Iteration 44880, loss = 1.10011
I0525 03:47:04.773627 22565 solver.cpp:253]     Train net output #0: loss = 1.10011 (* 1 = 1.10011 loss)
I0525 03:47:04.773644 22565 sgd_solver.cpp:106] Iteration 44880, lr = 0.005
I0525 03:47:10.277912 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_45000.caffemodel
I0525 03:47:10.347606 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_45000.solverstate
I0525 03:47:10.375128 22565 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 03:48:18.589442 22565 solver.cpp:409]     Test net output #0: accuracy = 0.888426
I0525 03:48:18.589629 22565 solver.cpp:409]     Test net output #1: loss = 0.361962 (* 1 = 0.361962 loss)
I0525 03:48:42.528357 22565 solver.cpp:237] Iteration 45067, loss = 1.09571
I0525 03:48:42.528416 22565 solver.cpp:253]     Train net output #0: loss = 1.09571 (* 1 = 1.09571 loss)
I0525 03:48:42.528436 22565 sgd_solver.cpp:106] Iteration 45067, lr = 0.005
I0525 03:48:51.186527 22565 solver.cpp:237] Iteration 45254, loss = 1.17665
I0525 03:48:51.186713 22565 solver.cpp:253]     Train net output #0: loss = 1.17665 (* 1 = 1.17665 loss)
I0525 03:48:51.186733 22565 sgd_solver.cpp:106] Iteration 45254, lr = 0.005
I0525 03:48:59.845701 22565 solver.cpp:237] Iteration 45441, loss = 1.35175
I0525 03:48:59.845738 22565 solver.cpp:253]     Train net output #0: loss = 1.35175 (* 1 = 1.35175 loss)
I0525 03:48:59.845762 22565 sgd_solver.cpp:106] Iteration 45441, lr = 0.005
I0525 03:49:08.502130 22565 solver.cpp:237] Iteration 45628, loss = 1.22639
I0525 03:49:08.502168 22565 solver.cpp:253]     Train net output #0: loss = 1.22639 (* 1 = 1.22639 loss)
I0525 03:49:08.502187 22565 sgd_solver.cpp:106] Iteration 45628, lr = 0.005
I0525 03:49:17.160796 22565 solver.cpp:237] Iteration 45815, loss = 1.30854
I0525 03:49:17.160853 22565 solver.cpp:253]     Train net output #0: loss = 1.30854 (* 1 = 1.30854 loss)
I0525 03:49:17.160871 22565 sgd_solver.cpp:106] Iteration 45815, lr = 0.005
I0525 03:49:25.818733 22565 solver.cpp:237] Iteration 46002, loss = 0.811748
I0525 03:49:25.818897 22565 solver.cpp:253]     Train net output #0: loss = 0.811748 (* 1 = 0.811748 loss)
I0525 03:49:25.818913 22565 sgd_solver.cpp:106] Iteration 46002, lr = 0.005
I0525 03:49:34.478698 22565 solver.cpp:237] Iteration 46189, loss = 1.04181
I0525 03:49:34.478734 22565 solver.cpp:253]     Train net output #0: loss = 1.04181 (* 1 = 1.04181 loss)
I0525 03:49:34.478754 22565 sgd_solver.cpp:106] Iteration 46189, lr = 0.005
I0525 03:50:03.954794 22565 solver.cpp:237] Iteration 46376, loss = 1.20968
I0525 03:50:03.954987 22565 solver.cpp:253]     Train net output #0: loss = 1.20968 (* 1 = 1.20968 loss)
I0525 03:50:03.955004 22565 sgd_solver.cpp:106] Iteration 46376, lr = 0.005
I0525 03:50:12.613479 22565 solver.cpp:237] Iteration 46563, loss = 1.09323
I0525 03:50:12.613515 22565 solver.cpp:253]     Train net output #0: loss = 1.09323 (* 1 = 1.09323 loss)
I0525 03:50:12.613539 22565 sgd_solver.cpp:106] Iteration 46563, lr = 0.005
I0525 03:50:21.273066 22565 solver.cpp:237] Iteration 46750, loss = 0.953976
I0525 03:50:21.273103 22565 solver.cpp:253]     Train net output #0: loss = 0.953976 (* 1 = 0.953976 loss)
I0525 03:50:21.273121 22565 sgd_solver.cpp:106] Iteration 46750, lr = 0.005
I0525 03:50:27.014039 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_46875.caffemodel
I0525 03:50:27.084820 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_46875.solverstate
I0525 03:50:30.000069 22565 solver.cpp:237] Iteration 46937, loss = 1.16911
I0525 03:50:30.000126 22565 solver.cpp:253]     Train net output #0: loss = 1.16911 (* 1 = 1.16911 loss)
I0525 03:50:30.000144 22565 sgd_solver.cpp:106] Iteration 46937, lr = 0.005
I0525 03:50:38.654913 22565 solver.cpp:237] Iteration 47124, loss = 1.16412
I0525 03:50:38.655092 22565 solver.cpp:253]     Train net output #0: loss = 1.16412 (* 1 = 1.16412 loss)
I0525 03:50:38.655109 22565 sgd_solver.cpp:106] Iteration 47124, lr = 0.005
I0525 03:50:47.311610 22565 solver.cpp:237] Iteration 47311, loss = 1.36925
I0525 03:50:47.311646 22565 solver.cpp:253]     Train net output #0: loss = 1.36925 (* 1 = 1.36925 loss)
I0525 03:50:47.311669 22565 sgd_solver.cpp:106] Iteration 47311, lr = 0.005
I0525 03:50:55.966565 22565 solver.cpp:237] Iteration 47498, loss = 1.15408
I0525 03:50:55.966624 22565 solver.cpp:253]     Train net output #0: loss = 1.15408 (* 1 = 1.15408 loss)
I0525 03:50:55.966648 22565 sgd_solver.cpp:106] Iteration 47498, lr = 0.005
I0525 03:51:25.414949 22565 solver.cpp:237] Iteration 47685, loss = 1.21952
I0525 03:51:25.415141 22565 solver.cpp:253]     Train net output #0: loss = 1.21952 (* 1 = 1.21952 loss)
I0525 03:51:25.415158 22565 sgd_solver.cpp:106] Iteration 47685, lr = 0.005
I0525 03:51:34.057726 22565 solver.cpp:237] Iteration 47872, loss = 0.894604
I0525 03:51:34.057765 22565 solver.cpp:253]     Train net output #0: loss = 0.894604 (* 1 = 0.894604 loss)
I0525 03:51:34.057788 22565 sgd_solver.cpp:106] Iteration 47872, lr = 0.005
I0525 03:51:42.701485 22565 solver.cpp:237] Iteration 48059, loss = 1.17685
I0525 03:51:42.701521 22565 solver.cpp:253]     Train net output #0: loss = 1.17685 (* 1 = 1.17685 loss)
I0525 03:51:42.701540 22565 sgd_solver.cpp:106] Iteration 48059, lr = 0.005
I0525 03:51:51.343708 22565 solver.cpp:237] Iteration 48246, loss = 1.2413
I0525 03:51:51.343756 22565 solver.cpp:253]     Train net output #0: loss = 1.2413 (* 1 = 1.2413 loss)
I0525 03:51:51.343783 22565 sgd_solver.cpp:106] Iteration 48246, lr = 0.005
I0525 03:51:59.984644 22565 solver.cpp:237] Iteration 48433, loss = 1.26859
I0525 03:51:59.984809 22565 solver.cpp:253]     Train net output #0: loss = 1.26859 (* 1 = 1.26859 loss)
I0525 03:51:59.984827 22565 sgd_solver.cpp:106] Iteration 48433, lr = 0.005
I0525 03:52:08.628093 22565 solver.cpp:237] Iteration 48620, loss = 1.45189
I0525 03:52:08.628130 22565 solver.cpp:253]     Train net output #0: loss = 1.45189 (* 1 = 1.45189 loss)
I0525 03:52:08.628154 22565 sgd_solver.cpp:106] Iteration 48620, lr = 0.005
I0525 03:52:14.589562 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_48750.caffemodel
I0525 03:52:14.658629 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_48750.solverstate
I0525 03:52:14.685169 22565 solver.cpp:341] Iteration 48750, Testing net (#0)
I0525 03:53:02.042376 22565 solver.cpp:409]     Test net output #0: accuracy = 0.892926
I0525 03:53:02.042572 22565 solver.cpp:409]     Test net output #1: loss = 0.338704 (* 1 = 0.338704 loss)
I0525 03:53:25.520452 22565 solver.cpp:237] Iteration 48807, loss = 1.26267
I0525 03:53:25.520509 22565 solver.cpp:253]     Train net output #0: loss = 1.26267 (* 1 = 1.26267 loss)
I0525 03:53:25.520526 22565 sgd_solver.cpp:106] Iteration 48807, lr = 0.005
I0525 03:53:34.188072 22565 solver.cpp:237] Iteration 48994, loss = 0.993049
I0525 03:53:34.188246 22565 solver.cpp:253]     Train net output #0: loss = 0.993049 (* 1 = 0.993049 loss)
I0525 03:53:34.188267 22565 sgd_solver.cpp:106] Iteration 48994, lr = 0.005
I0525 03:53:42.857386 22565 solver.cpp:237] Iteration 49181, loss = 1.07866
I0525 03:53:42.857424 22565 solver.cpp:253]     Train net output #0: loss = 1.07866 (* 1 = 1.07866 loss)
I0525 03:53:42.857447 22565 sgd_solver.cpp:106] Iteration 49181, lr = 0.005
I0525 03:53:51.526944 22565 solver.cpp:237] Iteration 49368, loss = 1.14667
I0525 03:53:51.527003 22565 solver.cpp:253]     Train net output #0: loss = 1.14667 (* 1 = 1.14667 loss)
I0525 03:53:51.527030 22565 sgd_solver.cpp:106] Iteration 49368, lr = 0.005
I0525 03:54:00.191632 22565 solver.cpp:237] Iteration 49555, loss = 1.08543
I0525 03:54:00.191668 22565 solver.cpp:253]     Train net output #0: loss = 1.08543 (* 1 = 1.08543 loss)
I0525 03:54:00.191686 22565 sgd_solver.cpp:106] Iteration 49555, lr = 0.005
I0525 03:54:08.860975 22565 solver.cpp:237] Iteration 49742, loss = 1.1351
I0525 03:54:08.861150 22565 solver.cpp:253]     Train net output #0: loss = 1.1351 (* 1 = 1.1351 loss)
I0525 03:54:08.861166 22565 sgd_solver.cpp:106] Iteration 49742, lr = 0.005
I0525 03:54:17.534759 22565 solver.cpp:237] Iteration 49929, loss = 1.17777
I0525 03:54:17.534812 22565 solver.cpp:253]     Train net output #0: loss = 1.17777 (* 1 = 1.17777 loss)
I0525 03:54:17.534832 22565 sgd_solver.cpp:106] Iteration 49929, lr = 0.005
I0525 03:54:46.996067 22565 solver.cpp:237] Iteration 50116, loss = 0.950869
I0525 03:54:46.996259 22565 solver.cpp:253]     Train net output #0: loss = 0.950869 (* 1 = 0.950869 loss)
I0525 03:54:46.996284 22565 sgd_solver.cpp:106] Iteration 50116, lr = 0.005
I0525 03:54:55.669801 22565 solver.cpp:237] Iteration 50303, loss = 1.099
I0525 03:54:55.669839 22565 solver.cpp:253]     Train net output #0: loss = 1.099 (* 1 = 1.099 loss)
I0525 03:54:55.669857 22565 sgd_solver.cpp:106] Iteration 50303, lr = 0.005
I0525 03:55:04.341899 22565 solver.cpp:237] Iteration 50490, loss = 1.10405
I0525 03:55:04.341954 22565 solver.cpp:253]     Train net output #0: loss = 1.10405 (* 1 = 1.10405 loss)
I0525 03:55:04.341981 22565 sgd_solver.cpp:106] Iteration 50490, lr = 0.005
I0525 03:55:10.544461 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_50625.caffemodel
I0525 03:55:10.614018 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_50625.solverstate
I0525 03:55:13.066596 22565 solver.cpp:237] Iteration 50677, loss = 1.15321
I0525 03:55:13.066649 22565 solver.cpp:253]     Train net output #0: loss = 1.15321 (* 1 = 1.15321 loss)
I0525 03:55:13.066666 22565 sgd_solver.cpp:106] Iteration 50677, lr = 0.005
I0525 03:55:21.721753 22565 solver.cpp:237] Iteration 50864, loss = 1.13296
I0525 03:55:21.721925 22565 solver.cpp:253]     Train net output #0: loss = 1.13296 (* 1 = 1.13296 loss)
I0525 03:55:21.721941 22565 sgd_solver.cpp:106] Iteration 50864, lr = 0.005
I0525 03:55:30.381182 22565 solver.cpp:237] Iteration 51051, loss = 1.23645
I0525 03:55:30.381238 22565 solver.cpp:253]     Train net output #0: loss = 1.23645 (* 1 = 1.23645 loss)
I0525 03:55:30.381255 22565 sgd_solver.cpp:106] Iteration 51051, lr = 0.005
I0525 03:55:39.035496 22565 solver.cpp:237] Iteration 51238, loss = 1.07512
I0525 03:55:39.035534 22565 solver.cpp:253]     Train net output #0: loss = 1.07512 (* 1 = 1.07512 loss)
I0525 03:55:39.035558 22565 sgd_solver.cpp:106] Iteration 51238, lr = 0.005
I0525 03:56:08.522995 22565 solver.cpp:237] Iteration 51425, loss = 1.30267
I0525 03:56:08.523195 22565 solver.cpp:253]     Train net output #0: loss = 1.30267 (* 1 = 1.30267 loss)
I0525 03:56:08.523213 22565 sgd_solver.cpp:106] Iteration 51425, lr = 0.005
I0525 03:56:17.180541 22565 solver.cpp:237] Iteration 51612, loss = 1.16427
I0525 03:56:17.180578 22565 solver.cpp:253]     Train net output #0: loss = 1.16427 (* 1 = 1.16427 loss)
I0525 03:56:17.180603 22565 sgd_solver.cpp:106] Iteration 51612, lr = 0.005
I0525 03:56:25.840301 22565 solver.cpp:237] Iteration 51799, loss = 1.1912
I0525 03:56:25.840358 22565 solver.cpp:253]     Train net output #0: loss = 1.1912 (* 1 = 1.1912 loss)
I0525 03:56:25.840384 22565 sgd_solver.cpp:106] Iteration 51799, lr = 0.005
I0525 03:56:34.499693 22565 solver.cpp:237] Iteration 51986, loss = 1.29019
I0525 03:56:34.499730 22565 solver.cpp:253]     Train net output #0: loss = 1.29019 (* 1 = 1.29019 loss)
I0525 03:56:34.499749 22565 sgd_solver.cpp:106] Iteration 51986, lr = 0.005
I0525 03:56:43.158476 22565 solver.cpp:237] Iteration 52173, loss = 1.22681
I0525 03:56:43.158645 22565 solver.cpp:253]     Train net output #0: loss = 1.22681 (* 1 = 1.22681 loss)
I0525 03:56:43.158663 22565 sgd_solver.cpp:106] Iteration 52173, lr = 0.005
I0525 03:56:51.816761 22565 solver.cpp:237] Iteration 52360, loss = 1.33065
I0525 03:56:51.816815 22565 solver.cpp:253]     Train net output #0: loss = 1.33065 (* 1 = 1.33065 loss)
I0525 03:56:51.816840 22565 sgd_solver.cpp:106] Iteration 52360, lr = 0.005
I0525 03:56:58.253567 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_52500.caffemodel
I0525 03:56:58.323971 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_52500.solverstate
I0525 03:56:58.350476 22565 solver.cpp:341] Iteration 52500, Testing net (#0)
I0525 03:58:06.581400 22565 solver.cpp:409]     Test net output #0: accuracy = 0.893281
I0525 03:58:06.581590 22565 solver.cpp:409]     Test net output #1: loss = 0.346175 (* 1 = 0.346175 loss)
I0525 03:58:29.627619 22565 solver.cpp:237] Iteration 52547, loss = 1.27699
I0525 03:58:29.627677 22565 solver.cpp:253]     Train net output #0: loss = 1.27699 (* 1 = 1.27699 loss)
I0525 03:58:29.627703 22565 sgd_solver.cpp:106] Iteration 52547, lr = 0.005
I0525 03:58:38.289661 22565 solver.cpp:237] Iteration 52734, loss = 1.35415
I0525 03:58:38.289844 22565 solver.cpp:253]     Train net output #0: loss = 1.35415 (* 1 = 1.35415 loss)
I0525 03:58:38.289860 22565 sgd_solver.cpp:106] Iteration 52734, lr = 0.005
I0525 03:58:46.950043 22565 solver.cpp:237] Iteration 52921, loss = 1.07333
I0525 03:58:46.950080 22565 solver.cpp:253]     Train net output #0: loss = 1.07333 (* 1 = 1.07333 loss)
I0525 03:58:46.950099 22565 sgd_solver.cpp:106] Iteration 52921, lr = 0.005
I0525 03:58:55.613876 22565 solver.cpp:237] Iteration 53108, loss = 1.20922
I0525 03:58:55.613934 22565 solver.cpp:253]     Train net output #0: loss = 1.20922 (* 1 = 1.20922 loss)
I0525 03:58:55.613958 22565 sgd_solver.cpp:106] Iteration 53108, lr = 0.005
I0525 03:59:04.273452 22565 solver.cpp:237] Iteration 53295, loss = 1.23293
I0525 03:59:04.273489 22565 solver.cpp:253]     Train net output #0: loss = 1.23293 (* 1 = 1.23293 loss)
I0525 03:59:04.273514 22565 sgd_solver.cpp:106] Iteration 53295, lr = 0.005
I0525 03:59:12.936830 22565 solver.cpp:237] Iteration 53482, loss = 1.1381
I0525 03:59:12.936997 22565 solver.cpp:253]     Train net output #0: loss = 1.1381 (* 1 = 1.1381 loss)
I0525 03:59:12.937014 22565 sgd_solver.cpp:106] Iteration 53482, lr = 0.005
I0525 03:59:21.598675 22565 solver.cpp:237] Iteration 53669, loss = 1.08756
I0525 03:59:21.598729 22565 solver.cpp:253]     Train net output #0: loss = 1.08756 (* 1 = 1.08756 loss)
I0525 03:59:21.598754 22565 sgd_solver.cpp:106] Iteration 53669, lr = 0.005
I0525 03:59:51.113054 22565 solver.cpp:237] Iteration 53856, loss = 1.02471
I0525 03:59:51.113258 22565 solver.cpp:253]     Train net output #0: loss = 1.02471 (* 1 = 1.02471 loss)
I0525 03:59:51.113276 22565 sgd_solver.cpp:106] Iteration 53856, lr = 0.005
I0525 03:59:59.770411 22565 solver.cpp:237] Iteration 54043, loss = 1.03528
I0525 03:59:59.770447 22565 solver.cpp:253]     Train net output #0: loss = 1.03528 (* 1 = 1.03528 loss)
I0525 03:59:59.770472 22565 sgd_solver.cpp:106] Iteration 54043, lr = 0.005
I0525 04:00:08.433745 22565 solver.cpp:237] Iteration 54230, loss = 1.14669
I0525 04:00:08.433802 22565 solver.cpp:253]     Train net output #0: loss = 1.14669 (* 1 = 1.14669 loss)
I0525 04:00:08.433826 22565 sgd_solver.cpp:106] Iteration 54230, lr = 0.005
I0525 04:00:15.102140 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_54375.caffemodel
I0525 04:00:15.174623 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_54375.solverstate
I0525 04:00:17.163373 22565 solver.cpp:237] Iteration 54417, loss = 1.15222
I0525 04:00:17.163431 22565 solver.cpp:253]     Train net output #0: loss = 1.15222 (* 1 = 1.15222 loss)
I0525 04:00:17.163455 22565 sgd_solver.cpp:106] Iteration 54417, lr = 0.005
I0525 04:00:25.825741 22565 solver.cpp:237] Iteration 54604, loss = 0.91948
I0525 04:00:25.825916 22565 solver.cpp:253]     Train net output #0: loss = 0.91948 (* 1 = 0.91948 loss)
I0525 04:00:25.825932 22565 sgd_solver.cpp:106] Iteration 54604, lr = 0.005
I0525 04:00:34.488313 22565 solver.cpp:237] Iteration 54791, loss = 1.23885
I0525 04:00:34.488369 22565 solver.cpp:253]     Train net output #0: loss = 1.23885 (* 1 = 1.23885 loss)
I0525 04:00:34.488386 22565 sgd_solver.cpp:106] Iteration 54791, lr = 0.005
I0525 04:00:43.146538 22565 solver.cpp:237] Iteration 54978, loss = 1.45805
I0525 04:00:43.146575 22565 solver.cpp:253]     Train net output #0: loss = 1.45805 (* 1 = 1.45805 loss)
I0525 04:00:43.146598 22565 sgd_solver.cpp:106] Iteration 54978, lr = 0.005
I0525 04:01:12.655817 22565 solver.cpp:237] Iteration 55165, loss = 1.3448
I0525 04:01:12.656010 22565 solver.cpp:253]     Train net output #0: loss = 1.3448 (* 1 = 1.3448 loss)
I0525 04:01:12.656028 22565 sgd_solver.cpp:106] Iteration 55165, lr = 0.005
I0525 04:01:21.318769 22565 solver.cpp:237] Iteration 55352, loss = 1.10402
I0525 04:01:21.318824 22565 solver.cpp:253]     Train net output #0: loss = 1.10402 (* 1 = 1.10402 loss)
I0525 04:01:21.318841 22565 sgd_solver.cpp:106] Iteration 55352, lr = 0.005
I0525 04:01:29.983041 22565 solver.cpp:237] Iteration 55539, loss = 1.37022
I0525 04:01:29.983078 22565 solver.cpp:253]     Train net output #0: loss = 1.37022 (* 1 = 1.37022 loss)
I0525 04:01:29.983098 22565 sgd_solver.cpp:106] Iteration 55539, lr = 0.005
I0525 04:01:38.638134 22565 solver.cpp:237] Iteration 55726, loss = 1.23289
I0525 04:01:38.638171 22565 solver.cpp:253]     Train net output #0: loss = 1.23289 (* 1 = 1.23289 loss)
I0525 04:01:38.638190 22565 sgd_solver.cpp:106] Iteration 55726, lr = 0.005
I0525 04:01:47.298262 22565 solver.cpp:237] Iteration 55913, loss = 1.14327
I0525 04:01:47.298463 22565 solver.cpp:253]     Train net output #0: loss = 1.14327 (* 1 = 1.14327 loss)
I0525 04:01:47.298480 22565 sgd_solver.cpp:106] Iteration 55913, lr = 0.005
I0525 04:01:55.955037 22565 solver.cpp:237] Iteration 56100, loss = 1.08681
I0525 04:01:55.955075 22565 solver.cpp:253]     Train net output #0: loss = 1.08681 (* 1 = 1.08681 loss)
I0525 04:01:55.955092 22565 sgd_solver.cpp:106] Iteration 56100, lr = 0.005
I0525 04:02:02.853854 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_56250.caffemodel
I0525 04:02:02.924763 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_56250.solverstate
I0525 04:02:02.953120 22565 solver.cpp:341] Iteration 56250, Testing net (#0)
I0525 04:02:50.010954 22565 solver.cpp:409]     Test net output #0: accuracy = 0.892646
I0525 04:02:50.011165 22565 solver.cpp:409]     Test net output #1: loss = 0.346182 (* 1 = 0.346182 loss)
I0525 04:03:12.567126 22565 solver.cpp:237] Iteration 56287, loss = 1.36561
I0525 04:03:12.567186 22565 solver.cpp:253]     Train net output #0: loss = 1.36561 (* 1 = 1.36561 loss)
I0525 04:03:12.567206 22565 sgd_solver.cpp:106] Iteration 56287, lr = 0.005
I0525 04:03:21.207284 22565 solver.cpp:237] Iteration 56474, loss = 1.03927
I0525 04:03:21.207460 22565 solver.cpp:253]     Train net output #0: loss = 1.03927 (* 1 = 1.03927 loss)
I0525 04:03:21.207478 22565 sgd_solver.cpp:106] Iteration 56474, lr = 0.005
I0525 04:03:29.850458 22565 solver.cpp:237] Iteration 56661, loss = 1.08462
I0525 04:03:29.850515 22565 solver.cpp:253]     Train net output #0: loss = 1.08462 (* 1 = 1.08462 loss)
I0525 04:03:29.850539 22565 sgd_solver.cpp:106] Iteration 56661, lr = 0.005
I0525 04:03:38.490689 22565 solver.cpp:237] Iteration 56848, loss = 1.09658
I0525 04:03:38.490726 22565 solver.cpp:253]     Train net output #0: loss = 1.09658 (* 1 = 1.09658 loss)
I0525 04:03:38.490746 22565 sgd_solver.cpp:106] Iteration 56848, lr = 0.005
I0525 04:03:47.129994 22565 solver.cpp:237] Iteration 57035, loss = 0.936131
I0525 04:03:47.130033 22565 solver.cpp:253]     Train net output #0: loss = 0.936131 (* 1 = 0.936131 loss)
I0525 04:03:47.130050 22565 sgd_solver.cpp:106] Iteration 57035, lr = 0.005
I0525 04:03:55.781502 22565 solver.cpp:237] Iteration 57222, loss = 1.20024
I0525 04:03:55.781692 22565 solver.cpp:253]     Train net output #0: loss = 1.20024 (* 1 = 1.20024 loss)
I0525 04:03:55.781708 22565 sgd_solver.cpp:106] Iteration 57222, lr = 0.005
I0525 04:04:04.439293 22565 solver.cpp:237] Iteration 57409, loss = 0.940178
I0525 04:04:04.439332 22565 solver.cpp:253]     Train net output #0: loss = 0.940178 (* 1 = 0.940178 loss)
I0525 04:04:04.439350 22565 sgd_solver.cpp:106] Iteration 57409, lr = 0.005
I0525 04:04:33.959389 22565 solver.cpp:237] Iteration 57596, loss = 0.954225
I0525 04:04:33.959589 22565 solver.cpp:253]     Train net output #0: loss = 0.954225 (* 1 = 0.954225 loss)
I0525 04:04:33.959606 22565 sgd_solver.cpp:106] Iteration 57596, lr = 0.005
I0525 04:04:42.613912 22565 solver.cpp:237] Iteration 57783, loss = 1.05048
I0525 04:04:42.613971 22565 solver.cpp:253]     Train net output #0: loss = 1.05048 (* 1 = 1.05048 loss)
I0525 04:04:42.613997 22565 sgd_solver.cpp:106] Iteration 57783, lr = 0.005
I0525 04:04:51.271886 22565 solver.cpp:237] Iteration 57970, loss = 1.03139
I0525 04:04:51.271924 22565 solver.cpp:253]     Train net output #0: loss = 1.03139 (* 1 = 1.03139 loss)
I0525 04:04:51.271942 22565 sgd_solver.cpp:106] Iteration 57970, lr = 0.005
I0525 04:04:58.400573 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_58125.caffemodel
I0525 04:04:58.479485 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_58125.solverstate
I0525 04:05:00.002893 22565 solver.cpp:237] Iteration 58157, loss = 1.18897
I0525 04:05:00.002946 22565 solver.cpp:253]     Train net output #0: loss = 1.18897 (* 1 = 1.18897 loss)
I0525 04:05:00.002974 22565 sgd_solver.cpp:106] Iteration 58157, lr = 0.005
I0525 04:05:08.659901 22565 solver.cpp:237] Iteration 58344, loss = 1.0721
I0525 04:05:08.660091 22565 solver.cpp:253]     Train net output #0: loss = 1.0721 (* 1 = 1.0721 loss)
I0525 04:05:08.660109 22565 sgd_solver.cpp:106] Iteration 58344, lr = 0.005
I0525 04:05:17.316504 22565 solver.cpp:237] Iteration 58531, loss = 1.00901
I0525 04:05:17.316540 22565 solver.cpp:253]     Train net output #0: loss = 1.00901 (* 1 = 1.00901 loss)
I0525 04:05:17.316560 22565 sgd_solver.cpp:106] Iteration 58531, lr = 0.005
I0525 04:05:25.974561 22565 solver.cpp:237] Iteration 58718, loss = 1.16446
I0525 04:05:25.974598 22565 solver.cpp:253]     Train net output #0: loss = 1.16446 (* 1 = 1.16446 loss)
I0525 04:05:25.974617 22565 sgd_solver.cpp:106] Iteration 58718, lr = 0.005
I0525 04:05:55.488157 22565 solver.cpp:237] Iteration 58905, loss = 1.15187
I0525 04:05:55.488368 22565 solver.cpp:253]     Train net output #0: loss = 1.15187 (* 1 = 1.15187 loss)
I0525 04:05:55.488387 22565 sgd_solver.cpp:106] Iteration 58905, lr = 0.005
I0525 04:06:04.143478 22565 solver.cpp:237] Iteration 59092, loss = 0.985014
I0525 04:06:04.143517 22565 solver.cpp:253]     Train net output #0: loss = 0.985014 (* 1 = 0.985014 loss)
I0525 04:06:04.143534 22565 sgd_solver.cpp:106] Iteration 59092, lr = 0.005
I0525 04:06:12.797325 22565 solver.cpp:237] Iteration 59279, loss = 0.915383
I0525 04:06:12.797363 22565 solver.cpp:253]     Train net output #0: loss = 0.915383 (* 1 = 0.915383 loss)
I0525 04:06:12.797381 22565 sgd_solver.cpp:106] Iteration 59279, lr = 0.005
I0525 04:06:21.453076 22565 solver.cpp:237] Iteration 59466, loss = 1.20773
I0525 04:06:21.453132 22565 solver.cpp:253]     Train net output #0: loss = 1.20773 (* 1 = 1.20773 loss)
I0525 04:06:21.453158 22565 sgd_solver.cpp:106] Iteration 59466, lr = 0.005
I0525 04:06:30.109411 22565 solver.cpp:237] Iteration 59653, loss = 1.3597
I0525 04:06:30.109593 22565 solver.cpp:253]     Train net output #0: loss = 1.3597 (* 1 = 1.3597 loss)
I0525 04:06:30.109611 22565 sgd_solver.cpp:106] Iteration 59653, lr = 0.005
I0525 04:06:38.766057 22565 solver.cpp:237] Iteration 59840, loss = 1.26897
I0525 04:06:38.766096 22565 solver.cpp:253]     Train net output #0: loss = 1.26897 (* 1 = 1.26897 loss)
I0525 04:06:38.766114 22565 sgd_solver.cpp:106] Iteration 59840, lr = 0.005
I0525 04:06:46.128731 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_60000.caffemodel
I0525 04:06:46.198619 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_60000.solverstate
I0525 04:06:46.225374 22565 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 04:07:54.421490 22565 solver.cpp:409]     Test net output #0: accuracy = 0.894447
I0525 04:07:54.421686 22565 solver.cpp:409]     Test net output #1: loss = 0.339863 (* 1 = 0.339863 loss)
I0525 04:08:16.504201 22565 solver.cpp:237] Iteration 60027, loss = 1.10467
I0525 04:08:16.504256 22565 solver.cpp:253]     Train net output #0: loss = 1.10467 (* 1 = 1.10467 loss)
I0525 04:08:16.504281 22565 sgd_solver.cpp:106] Iteration 60027, lr = 0.005
I0525 04:08:25.150990 22565 solver.cpp:237] Iteration 60214, loss = 1.09078
I0525 04:08:25.151185 22565 solver.cpp:253]     Train net output #0: loss = 1.09078 (* 1 = 1.09078 loss)
I0525 04:08:25.151203 22565 sgd_solver.cpp:106] Iteration 60214, lr = 0.005
I0525 04:08:33.794724 22565 solver.cpp:237] Iteration 60401, loss = 1.19063
I0525 04:08:33.794761 22565 solver.cpp:253]     Train net output #0: loss = 1.19063 (* 1 = 1.19063 loss)
I0525 04:08:33.794785 22565 sgd_solver.cpp:106] Iteration 60401, lr = 0.005
I0525 04:08:42.438143 22565 solver.cpp:237] Iteration 60588, loss = 1.1057
I0525 04:08:42.438179 22565 solver.cpp:253]     Train net output #0: loss = 1.1057 (* 1 = 1.1057 loss)
I0525 04:08:42.438202 22565 sgd_solver.cpp:106] Iteration 60588, lr = 0.005
I0525 04:08:51.083569 22565 solver.cpp:237] Iteration 60775, loss = 1.00523
I0525 04:08:51.083623 22565 solver.cpp:253]     Train net output #0: loss = 1.00523 (* 1 = 1.00523 loss)
I0525 04:08:51.083650 22565 sgd_solver.cpp:106] Iteration 60775, lr = 0.005
I0525 04:08:59.730598 22565 solver.cpp:237] Iteration 60962, loss = 0.874157
I0525 04:08:59.730770 22565 solver.cpp:253]     Train net output #0: loss = 0.874157 (* 1 = 0.874157 loss)
I0525 04:08:59.730787 22565 sgd_solver.cpp:106] Iteration 60962, lr = 0.005
I0525 04:09:08.374527 22565 solver.cpp:237] Iteration 61149, loss = 1.14149
I0525 04:09:08.374563 22565 solver.cpp:253]     Train net output #0: loss = 1.14149 (* 1 = 1.14149 loss)
I0525 04:09:08.374583 22565 sgd_solver.cpp:106] Iteration 61149, lr = 0.005
I0525 04:09:37.843163 22565 solver.cpp:237] Iteration 61336, loss = 1.09025
I0525 04:09:37.843369 22565 solver.cpp:253]     Train net output #0: loss = 1.09025 (* 1 = 1.09025 loss)
I0525 04:09:37.843387 22565 sgd_solver.cpp:106] Iteration 61336, lr = 0.005
I0525 04:09:46.492655 22565 solver.cpp:237] Iteration 61523, loss = 1.07087
I0525 04:09:46.492708 22565 solver.cpp:253]     Train net output #0: loss = 1.07087 (* 1 = 1.07087 loss)
I0525 04:09:46.492733 22565 sgd_solver.cpp:106] Iteration 61523, lr = 0.005
I0525 04:09:55.137264 22565 solver.cpp:237] Iteration 61710, loss = 1.31402
I0525 04:09:55.137300 22565 solver.cpp:253]     Train net output #0: loss = 1.31402 (* 1 = 1.31402 loss)
I0525 04:09:55.137325 22565 sgd_solver.cpp:106] Iteration 61710, lr = 0.005
I0525 04:10:02.718477 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_61875.caffemodel
I0525 04:10:02.788228 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_61875.solverstate
I0525 04:10:03.849488 22565 solver.cpp:237] Iteration 61897, loss = 1.12268
I0525 04:10:03.849546 22565 solver.cpp:253]     Train net output #0: loss = 1.12268 (* 1 = 1.12268 loss)
I0525 04:10:03.849565 22565 sgd_solver.cpp:106] Iteration 61897, lr = 0.005
I0525 04:10:12.497845 22565 solver.cpp:237] Iteration 62084, loss = 1.00106
I0525 04:10:12.498023 22565 solver.cpp:253]     Train net output #0: loss = 1.00106 (* 1 = 1.00106 loss)
I0525 04:10:12.498040 22565 sgd_solver.cpp:106] Iteration 62084, lr = 0.005
I0525 04:10:21.146934 22565 solver.cpp:237] Iteration 62271, loss = 1.03132
I0525 04:10:21.146971 22565 solver.cpp:253]     Train net output #0: loss = 1.03132 (* 1 = 1.03132 loss)
I0525 04:10:21.146989 22565 sgd_solver.cpp:106] Iteration 62271, lr = 0.005
I0525 04:10:29.788955 22565 solver.cpp:237] Iteration 62458, loss = 1.08517
I0525 04:10:29.789006 22565 solver.cpp:253]     Train net output #0: loss = 1.08517 (* 1 = 1.08517 loss)
I0525 04:10:29.789024 22565 sgd_solver.cpp:106] Iteration 62458, lr = 0.005
I0525 04:10:59.266806 22565 solver.cpp:237] Iteration 62645, loss = 1.23971
I0525 04:10:59.267004 22565 solver.cpp:253]     Train net output #0: loss = 1.23971 (* 1 = 1.23971 loss)
I0525 04:10:59.267020 22565 sgd_solver.cpp:106] Iteration 62645, lr = 0.005
I0525 04:11:07.910492 22565 solver.cpp:237] Iteration 62832, loss = 1.07894
I0525 04:11:07.910529 22565 solver.cpp:253]     Train net output #0: loss = 1.07894 (* 1 = 1.07894 loss)
I0525 04:11:07.910547 22565 sgd_solver.cpp:106] Iteration 62832, lr = 0.005
I0525 04:11:16.555495 22565 solver.cpp:237] Iteration 63019, loss = 1.14177
I0525 04:11:16.555532 22565 solver.cpp:253]     Train net output #0: loss = 1.14177 (* 1 = 1.14177 loss)
I0525 04:11:16.555548 22565 sgd_solver.cpp:106] Iteration 63019, lr = 0.005
I0525 04:11:25.203382 22565 solver.cpp:237] Iteration 63206, loss = 1.00719
I0525 04:11:25.203431 22565 solver.cpp:253]     Train net output #0: loss = 1.00719 (* 1 = 1.00719 loss)
I0525 04:11:25.203449 22565 sgd_solver.cpp:106] Iteration 63206, lr = 0.005
I0525 04:11:33.851994 22565 solver.cpp:237] Iteration 63393, loss = 1.08042
I0525 04:11:33.852179 22565 solver.cpp:253]     Train net output #0: loss = 1.08042 (* 1 = 1.08042 loss)
I0525 04:11:33.852195 22565 sgd_solver.cpp:106] Iteration 63393, lr = 0.005
I0525 04:11:42.500262 22565 solver.cpp:237] Iteration 63580, loss = 1.04469
I0525 04:11:42.500303 22565 solver.cpp:253]     Train net output #0: loss = 1.04469 (* 1 = 1.04469 loss)
I0525 04:11:42.500325 22565 sgd_solver.cpp:106] Iteration 63580, lr = 0.005
I0525 04:11:50.315306 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_63750.caffemodel
I0525 04:11:50.384510 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_63750.solverstate
I0525 04:11:50.410918 22565 solver.cpp:341] Iteration 63750, Testing net (#0)
I0525 04:12:37.788198 22565 solver.cpp:409]     Test net output #0: accuracy = 0.896154
I0525 04:12:37.788409 22565 solver.cpp:409]     Test net output #1: loss = 0.357013 (* 1 = 0.357013 loss)
I0525 04:12:59.455576 22565 solver.cpp:237] Iteration 63767, loss = 1.16749
I0525 04:12:59.455633 22565 solver.cpp:253]     Train net output #0: loss = 1.16749 (* 1 = 1.16749 loss)
I0525 04:12:59.455651 22565 sgd_solver.cpp:106] Iteration 63767, lr = 0.005
I0525 04:13:08.102409 22565 solver.cpp:237] Iteration 63954, loss = 1.25357
I0525 04:13:08.102588 22565 solver.cpp:253]     Train net output #0: loss = 1.25357 (* 1 = 1.25357 loss)
I0525 04:13:08.102605 22565 sgd_solver.cpp:106] Iteration 63954, lr = 0.005
I0525 04:13:16.749248 22565 solver.cpp:237] Iteration 64141, loss = 1.08308
I0525 04:13:16.749284 22565 solver.cpp:253]     Train net output #0: loss = 1.08308 (* 1 = 1.08308 loss)
I0525 04:13:16.749301 22565 sgd_solver.cpp:106] Iteration 64141, lr = 0.005
I0525 04:13:25.397565 22565 solver.cpp:237] Iteration 64328, loss = 1.04226
I0525 04:13:25.397624 22565 solver.cpp:253]     Train net output #0: loss = 1.04226 (* 1 = 1.04226 loss)
I0525 04:13:25.397650 22565 sgd_solver.cpp:106] Iteration 64328, lr = 0.005
I0525 04:13:34.045137 22565 solver.cpp:237] Iteration 64515, loss = 1.13357
I0525 04:13:34.045174 22565 solver.cpp:253]     Train net output #0: loss = 1.13357 (* 1 = 1.13357 loss)
I0525 04:13:34.045192 22565 sgd_solver.cpp:106] Iteration 64515, lr = 0.005
I0525 04:13:42.695116 22565 solver.cpp:237] Iteration 64702, loss = 1.15772
I0525 04:13:42.695291 22565 solver.cpp:253]     Train net output #0: loss = 1.15772 (* 1 = 1.15772 loss)
I0525 04:13:42.695308 22565 sgd_solver.cpp:106] Iteration 64702, lr = 0.005
I0525 04:13:51.349571 22565 solver.cpp:237] Iteration 64889, loss = 1.16158
I0525 04:13:51.349627 22565 solver.cpp:253]     Train net output #0: loss = 1.16158 (* 1 = 1.16158 loss)
I0525 04:13:51.349653 22565 sgd_solver.cpp:106] Iteration 64889, lr = 0.005
I0525 04:14:20.885371 22565 solver.cpp:237] Iteration 65076, loss = 1.13302
I0525 04:14:20.885581 22565 solver.cpp:253]     Train net output #0: loss = 1.13302 (* 1 = 1.13302 loss)
I0525 04:14:20.885607 22565 sgd_solver.cpp:106] Iteration 65076, lr = 0.005
I0525 04:14:29.545521 22565 solver.cpp:237] Iteration 65263, loss = 1.31559
I0525 04:14:29.545557 22565 solver.cpp:253]     Train net output #0: loss = 1.31559 (* 1 = 1.31559 loss)
I0525 04:14:29.545581 22565 sgd_solver.cpp:106] Iteration 65263, lr = 0.005
I0525 04:14:38.207072 22565 solver.cpp:237] Iteration 65450, loss = 1.33513
I0525 04:14:38.207109 22565 solver.cpp:253]     Train net output #0: loss = 1.33513 (* 1 = 1.33513 loss)
I0525 04:14:38.207132 22565 sgd_solver.cpp:106] Iteration 65450, lr = 0.005
I0525 04:14:46.258538 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_65625.caffemodel
I0525 04:14:46.329463 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_65625.solverstate
I0525 04:14:46.929357 22565 solver.cpp:237] Iteration 65637, loss = 1.23447
I0525 04:14:46.929414 22565 solver.cpp:253]     Train net output #0: loss = 1.23447 (* 1 = 1.23447 loss)
I0525 04:14:46.929440 22565 sgd_solver.cpp:106] Iteration 65637, lr = 0.005
I0525 04:14:55.574985 22565 solver.cpp:237] Iteration 65824, loss = 1.05676
I0525 04:14:55.575182 22565 solver.cpp:253]     Train net output #0: loss = 1.05676 (* 1 = 1.05676 loss)
I0525 04:14:55.575198 22565 sgd_solver.cpp:106] Iteration 65824, lr = 0.005
I0525 04:15:04.222096 22565 solver.cpp:237] Iteration 66011, loss = 1.01884
I0525 04:15:04.222153 22565 solver.cpp:253]     Train net output #0: loss = 1.01884 (* 1 = 1.01884 loss)
I0525 04:15:04.222172 22565 sgd_solver.cpp:106] Iteration 66011, lr = 0.005
I0525 04:15:12.868237 22565 solver.cpp:237] Iteration 66198, loss = 0.969902
I0525 04:15:12.868283 22565 solver.cpp:253]     Train net output #0: loss = 0.969902 (* 1 = 0.969902 loss)
I0525 04:15:12.868301 22565 sgd_solver.cpp:106] Iteration 66198, lr = 0.005
I0525 04:15:42.335971 22565 solver.cpp:237] Iteration 66385, loss = 0.951419
I0525 04:15:42.336184 22565 solver.cpp:253]     Train net output #0: loss = 0.951419 (* 1 = 0.951419 loss)
I0525 04:15:42.336201 22565 sgd_solver.cpp:106] Iteration 66385, lr = 0.005
I0525 04:15:50.984218 22565 solver.cpp:237] Iteration 66572, loss = 1.16603
I0525 04:15:50.984256 22565 solver.cpp:253]     Train net output #0: loss = 1.16603 (* 1 = 1.16603 loss)
I0525 04:15:50.984278 22565 sgd_solver.cpp:106] Iteration 66572, lr = 0.005
I0525 04:15:59.628456 22565 solver.cpp:237] Iteration 66759, loss = 1.18631
I0525 04:15:59.628514 22565 solver.cpp:253]     Train net output #0: loss = 1.18631 (* 1 = 1.18631 loss)
I0525 04:15:59.628537 22565 sgd_solver.cpp:106] Iteration 66759, lr = 0.005
I0525 04:16:08.268890 22565 solver.cpp:237] Iteration 66946, loss = 1.13722
I0525 04:16:08.268929 22565 solver.cpp:253]     Train net output #0: loss = 1.13722 (* 1 = 1.13722 loss)
I0525 04:16:08.268946 22565 sgd_solver.cpp:106] Iteration 66946, lr = 0.005
I0525 04:16:16.910073 22565 solver.cpp:237] Iteration 67133, loss = 1.20375
I0525 04:16:16.910259 22565 solver.cpp:253]     Train net output #0: loss = 1.20375 (* 1 = 1.20375 loss)
I0525 04:16:16.910276 22565 sgd_solver.cpp:106] Iteration 67133, lr = 0.005
I0525 04:16:25.565322 22565 solver.cpp:237] Iteration 67320, loss = 1.06881
I0525 04:16:25.565377 22565 solver.cpp:253]     Train net output #0: loss = 1.06881 (* 1 = 1.06881 loss)
I0525 04:16:25.565394 22565 sgd_solver.cpp:106] Iteration 67320, lr = 0.005
I0525 04:16:33.851353 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_67500.caffemodel
I0525 04:16:33.923650 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_67500.solverstate
I0525 04:16:33.953341 22565 solver.cpp:341] Iteration 67500, Testing net (#0)
I0525 04:17:42.271457 22565 solver.cpp:409]     Test net output #0: accuracy = 0.895672
I0525 04:17:42.271657 22565 solver.cpp:409]     Test net output #1: loss = 0.325352 (* 1 = 0.325352 loss)
I0525 04:18:03.487051 22565 solver.cpp:237] Iteration 67507, loss = 1.24807
I0525 04:18:03.487112 22565 solver.cpp:253]     Train net output #0: loss = 1.24807 (* 1 = 1.24807 loss)
I0525 04:18:03.487130 22565 sgd_solver.cpp:106] Iteration 67507, lr = 0.005
I0525 04:18:12.143021 22565 solver.cpp:237] Iteration 67694, loss = 1.12956
I0525 04:18:12.143059 22565 solver.cpp:253]     Train net output #0: loss = 1.12956 (* 1 = 1.12956 loss)
I0525 04:18:12.143084 22565 sgd_solver.cpp:106] Iteration 67694, lr = 0.005
I0525 04:18:20.794915 22565 solver.cpp:237] Iteration 67881, loss = 1.02921
I0525 04:18:20.795094 22565 solver.cpp:253]     Train net output #0: loss = 1.02921 (* 1 = 1.02921 loss)
I0525 04:18:20.795111 22565 sgd_solver.cpp:106] Iteration 67881, lr = 0.005
I0525 04:18:29.451231 22565 solver.cpp:237] Iteration 68068, loss = 1.04004
I0525 04:18:29.451285 22565 solver.cpp:253]     Train net output #0: loss = 1.04004 (* 1 = 1.04004 loss)
I0525 04:18:29.451303 22565 sgd_solver.cpp:106] Iteration 68068, lr = 0.005
I0525 04:18:38.107110 22565 solver.cpp:237] Iteration 68255, loss = 1.08395
I0525 04:18:38.107147 22565 solver.cpp:253]     Train net output #0: loss = 1.08395 (* 1 = 1.08395 loss)
I0525 04:18:38.107166 22565 sgd_solver.cpp:106] Iteration 68255, lr = 0.005
I0525 04:18:46.764050 22565 solver.cpp:237] Iteration 68442, loss = 0.964171
I0525 04:18:46.764086 22565 solver.cpp:253]     Train net output #0: loss = 0.964171 (* 1 = 0.964171 loss)
I0525 04:18:46.764104 22565 sgd_solver.cpp:106] Iteration 68442, lr = 0.005
I0525 04:18:55.414369 22565 solver.cpp:237] Iteration 68629, loss = 1.15013
I0525 04:18:55.414574 22565 solver.cpp:253]     Train net output #0: loss = 1.15013 (* 1 = 1.15013 loss)
I0525 04:18:55.414594 22565 sgd_solver.cpp:106] Iteration 68629, lr = 0.005
I0525 04:19:24.922605 22565 solver.cpp:237] Iteration 68816, loss = 0.939838
I0525 04:19:24.922667 22565 solver.cpp:253]     Train net output #0: loss = 0.939838 (* 1 = 0.939838 loss)
I0525 04:19:24.922693 22565 sgd_solver.cpp:106] Iteration 68816, lr = 0.005
I0525 04:19:33.566301 22565 solver.cpp:237] Iteration 69003, loss = 1.09479
I0525 04:19:33.566481 22565 solver.cpp:253]     Train net output #0: loss = 1.09479 (* 1 = 1.09479 loss)
I0525 04:19:33.566498 22565 sgd_solver.cpp:106] Iteration 69003, lr = 0.005
I0525 04:19:42.216161 22565 solver.cpp:237] Iteration 69190, loss = 0.893864
I0525 04:19:42.216219 22565 solver.cpp:253]     Train net output #0: loss = 0.893864 (* 1 = 0.893864 loss)
I0525 04:19:42.216245 22565 sgd_solver.cpp:106] Iteration 69190, lr = 0.005
I0525 04:19:50.726924 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_69375.caffemodel
I0525 04:19:50.797359 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_69375.solverstate
I0525 04:19:50.931479 22565 solver.cpp:237] Iteration 69377, loss = 1.1878
I0525 04:19:50.931532 22565 solver.cpp:253]     Train net output #0: loss = 1.1878 (* 1 = 1.1878 loss)
I0525 04:19:50.931551 22565 sgd_solver.cpp:106] Iteration 69377, lr = 0.005
I0525 04:19:59.580464 22565 solver.cpp:237] Iteration 69564, loss = 1.28068
I0525 04:19:59.580502 22565 solver.cpp:253]     Train net output #0: loss = 1.28068 (* 1 = 1.28068 loss)
I0525 04:19:59.580520 22565 sgd_solver.cpp:106] Iteration 69564, lr = 0.005
I0525 04:20:08.232056 22565 solver.cpp:237] Iteration 69751, loss = 1.03591
I0525 04:20:08.232256 22565 solver.cpp:253]     Train net output #0: loss = 1.03591 (* 1 = 1.03591 loss)
I0525 04:20:08.232280 22565 sgd_solver.cpp:106] Iteration 69751, lr = 0.005
I0525 04:20:16.886554 22565 solver.cpp:237] Iteration 69938, loss = 1.25606
I0525 04:20:16.886590 22565 solver.cpp:253]     Train net output #0: loss = 1.25606 (* 1 = 1.25606 loss)
I0525 04:20:16.886608 22565 sgd_solver.cpp:106] Iteration 69938, lr = 0.005
I0525 04:20:46.422389 22565 solver.cpp:237] Iteration 70125, loss = 1.08202
I0525 04:20:46.422592 22565 solver.cpp:253]     Train net output #0: loss = 1.08202 (* 1 = 1.08202 loss)
I0525 04:20:46.422610 22565 sgd_solver.cpp:106] Iteration 70125, lr = 0.005
I0525 04:20:55.076515 22565 solver.cpp:237] Iteration 70312, loss = 1.36043
I0525 04:20:55.076575 22565 solver.cpp:253]     Train net output #0: loss = 1.36043 (* 1 = 1.36043 loss)
I0525 04:20:55.076602 22565 sgd_solver.cpp:106] Iteration 70312, lr = 0.005
I0525 04:21:03.732156 22565 solver.cpp:237] Iteration 70499, loss = 1.17148
I0525 04:21:03.732192 22565 solver.cpp:253]     Train net output #0: loss = 1.17148 (* 1 = 1.17148 loss)
I0525 04:21:03.732216 22565 sgd_solver.cpp:106] Iteration 70499, lr = 0.005
I0525 04:21:12.384848 22565 solver.cpp:237] Iteration 70686, loss = 0.802318
I0525 04:21:12.384886 22565 solver.cpp:253]     Train net output #0: loss = 0.802318 (* 1 = 0.802318 loss)
I0525 04:21:12.384905 22565 sgd_solver.cpp:106] Iteration 70686, lr = 0.005
I0525 04:21:21.038436 22565 solver.cpp:237] Iteration 70873, loss = 1.30598
I0525 04:21:21.038655 22565 solver.cpp:253]     Train net output #0: loss = 1.30598 (* 1 = 1.30598 loss)
I0525 04:21:21.038672 22565 sgd_solver.cpp:106] Iteration 70873, lr = 0.005
I0525 04:21:29.690204 22565 solver.cpp:237] Iteration 71060, loss = 1.10728
I0525 04:21:29.690242 22565 solver.cpp:253]     Train net output #0: loss = 1.10728 (* 1 = 1.10728 loss)
I0525 04:21:29.690264 22565 sgd_solver.cpp:106] Iteration 71060, lr = 0.005
I0525 04:21:38.338243 22565 solver.cpp:237] Iteration 71247, loss = 1.30009
I0525 04:21:38.338279 22565 solver.cpp:253]     Train net output #0: loss = 1.30009 (* 1 = 1.30009 loss)
I0525 04:21:38.338302 22565 sgd_solver.cpp:106] Iteration 71247, lr = 0.005
I0525 04:21:38.430704 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_71250.caffemodel
I0525 04:21:38.500488 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_71250.solverstate
I0525 04:21:38.527173 22565 solver.cpp:341] Iteration 71250, Testing net (#0)
I0525 04:22:25.646771 22565 solver.cpp:409]     Test net output #0: accuracy = 0.896747
I0525 04:22:25.646983 22565 solver.cpp:409]     Test net output #1: loss = 0.312534 (* 1 = 0.312534 loss)
I0525 04:22:54.996394 22565 solver.cpp:237] Iteration 71434, loss = 1.20102
I0525 04:22:54.996454 22565 solver.cpp:253]     Train net output #0: loss = 1.20102 (* 1 = 1.20102 loss)
I0525 04:22:54.996471 22565 sgd_solver.cpp:106] Iteration 71434, lr = 0.005
I0525 04:23:03.650053 22565 solver.cpp:237] Iteration 71621, loss = 1.22194
I0525 04:23:03.650251 22565 solver.cpp:253]     Train net output #0: loss = 1.22194 (* 1 = 1.22194 loss)
I0525 04:23:03.650269 22565 sgd_solver.cpp:106] Iteration 71621, lr = 0.005
I0525 04:23:12.294821 22565 solver.cpp:237] Iteration 71808, loss = 1.28981
I0525 04:23:12.294857 22565 solver.cpp:253]     Train net output #0: loss = 1.28981 (* 1 = 1.28981 loss)
I0525 04:23:12.294881 22565 sgd_solver.cpp:106] Iteration 71808, lr = 0.005
I0525 04:23:20.942368 22565 solver.cpp:237] Iteration 71995, loss = 1.24525
I0525 04:23:20.942404 22565 solver.cpp:253]     Train net output #0: loss = 1.24525 (* 1 = 1.24525 loss)
I0525 04:23:20.942428 22565 sgd_solver.cpp:106] Iteration 71995, lr = 0.005
I0525 04:23:29.592180 22565 solver.cpp:237] Iteration 72182, loss = 1.33027
I0525 04:23:29.592239 22565 solver.cpp:253]     Train net output #0: loss = 1.33027 (* 1 = 1.33027 loss)
I0525 04:23:29.592268 22565 sgd_solver.cpp:106] Iteration 72182, lr = 0.005
I0525 04:23:38.241508 22565 solver.cpp:237] Iteration 72369, loss = 1.24092
I0525 04:23:38.241685 22565 solver.cpp:253]     Train net output #0: loss = 1.24092 (* 1 = 1.24092 loss)
I0525 04:23:38.241701 22565 sgd_solver.cpp:106] Iteration 72369, lr = 0.005
I0525 04:24:07.711294 22565 solver.cpp:237] Iteration 72556, loss = 1.10699
I0525 04:24:07.711355 22565 solver.cpp:253]     Train net output #0: loss = 1.10699 (* 1 = 1.10699 loss)
I0525 04:24:07.711374 22565 sgd_solver.cpp:106] Iteration 72556, lr = 0.005
I0525 04:24:16.359946 22565 solver.cpp:237] Iteration 72743, loss = 1.06391
I0525 04:24:16.360144 22565 solver.cpp:253]     Train net output #0: loss = 1.06391 (* 1 = 1.06391 loss)
I0525 04:24:16.360162 22565 sgd_solver.cpp:106] Iteration 72743, lr = 0.005
I0525 04:24:25.005445 22565 solver.cpp:237] Iteration 72930, loss = 1.29847
I0525 04:24:25.005481 22565 solver.cpp:253]     Train net output #0: loss = 1.29847 (* 1 = 1.29847 loss)
I0525 04:24:25.005506 22565 sgd_solver.cpp:106] Iteration 72930, lr = 0.005
I0525 04:24:33.651623 22565 solver.cpp:237] Iteration 73117, loss = 1.27478
I0525 04:24:33.651661 22565 solver.cpp:253]     Train net output #0: loss = 1.27478 (* 1 = 1.27478 loss)
I0525 04:24:33.651679 22565 sgd_solver.cpp:106] Iteration 73117, lr = 0.005
I0525 04:24:33.976001 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_73125.caffemodel
I0525 04:24:34.045449 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_73125.solverstate
I0525 04:24:42.363134 22565 solver.cpp:237] Iteration 73304, loss = 1.07451
I0525 04:24:42.363193 22565 solver.cpp:253]     Train net output #0: loss = 1.07451 (* 1 = 1.07451 loss)
I0525 04:24:42.363210 22565 sgd_solver.cpp:106] Iteration 73304, lr = 0.005
I0525 04:24:51.007869 22565 solver.cpp:237] Iteration 73491, loss = 1.20225
I0525 04:24:51.008064 22565 solver.cpp:253]     Train net output #0: loss = 1.20225 (* 1 = 1.20225 loss)
I0525 04:24:51.008080 22565 sgd_solver.cpp:106] Iteration 73491, lr = 0.005
I0525 04:24:59.651973 22565 solver.cpp:237] Iteration 73678, loss = 0.993808
I0525 04:24:59.652011 22565 solver.cpp:253]     Train net output #0: loss = 0.993808 (* 1 = 0.993808 loss)
I0525 04:24:59.652030 22565 sgd_solver.cpp:106] Iteration 73678, lr = 0.005
I0525 04:25:29.194435 22565 solver.cpp:237] Iteration 73865, loss = 1.24539
I0525 04:25:29.194639 22565 solver.cpp:253]     Train net output #0: loss = 1.24539 (* 1 = 1.24539 loss)
I0525 04:25:29.194658 22565 sgd_solver.cpp:106] Iteration 73865, lr = 0.005
I0525 04:25:37.842468 22565 solver.cpp:237] Iteration 74052, loss = 1.1049
I0525 04:25:37.842505 22565 solver.cpp:253]     Train net output #0: loss = 1.1049 (* 1 = 1.1049 loss)
I0525 04:25:37.842525 22565 sgd_solver.cpp:106] Iteration 74052, lr = 0.005
I0525 04:25:46.491153 22565 solver.cpp:237] Iteration 74239, loss = 1.39276
I0525 04:25:46.491192 22565 solver.cpp:253]     Train net output #0: loss = 1.39276 (* 1 = 1.39276 loss)
I0525 04:25:46.491209 22565 sgd_solver.cpp:106] Iteration 74239, lr = 0.005
I0525 04:25:55.142515 22565 solver.cpp:237] Iteration 74426, loss = 1.27138
I0525 04:25:55.142573 22565 solver.cpp:253]     Train net output #0: loss = 1.27138 (* 1 = 1.27138 loss)
I0525 04:25:55.142601 22565 sgd_solver.cpp:106] Iteration 74426, lr = 0.005
I0525 04:26:03.788496 22565 solver.cpp:237] Iteration 74613, loss = 1.07626
I0525 04:26:03.788676 22565 solver.cpp:253]     Train net output #0: loss = 1.07626 (* 1 = 1.07626 loss)
I0525 04:26:03.788692 22565 sgd_solver.cpp:106] Iteration 74613, lr = 0.005
I0525 04:26:12.431989 22565 solver.cpp:237] Iteration 74800, loss = 0.990355
I0525 04:26:12.432026 22565 solver.cpp:253]     Train net output #0: loss = 0.990355 (* 1 = 0.990355 loss)
I0525 04:26:12.432045 22565 sgd_solver.cpp:106] Iteration 74800, lr = 0.005
I0525 04:26:21.075064 22565 solver.cpp:237] Iteration 74987, loss = 1.22862
I0525 04:26:21.075122 22565 solver.cpp:253]     Train net output #0: loss = 1.22862 (* 1 = 1.22862 loss)
I0525 04:26:21.075148 22565 sgd_solver.cpp:106] Iteration 74987, lr = 0.005
I0525 04:26:21.630362 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_75000.caffemodel
I0525 04:26:21.699929 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_75000.solverstate
I0525 04:26:21.729984 22565 solver.cpp:341] Iteration 75000, Testing net (#0)
I0525 04:27:30.003250 22565 solver.cpp:409]     Test net output #0: accuracy = 0.900007
I0525 04:27:30.003453 22565 solver.cpp:409]     Test net output #1: loss = 0.324512 (* 1 = 0.324512 loss)
I0525 04:27:58.970329 22565 solver.cpp:237] Iteration 75174, loss = 1.39115
I0525 04:27:58.970392 22565 solver.cpp:253]     Train net output #0: loss = 1.39115 (* 1 = 1.39115 loss)
I0525 04:27:58.970419 22565 sgd_solver.cpp:106] Iteration 75174, lr = 0.005
I0525 04:28:07.634088 22565 solver.cpp:237] Iteration 75361, loss = 0.885265
I0525 04:28:07.634270 22565 solver.cpp:253]     Train net output #0: loss = 0.885265 (* 1 = 0.885265 loss)
I0525 04:28:07.634287 22565 sgd_solver.cpp:106] Iteration 75361, lr = 0.005
I0525 04:28:16.295464 22565 solver.cpp:237] Iteration 75548, loss = 1.21739
I0525 04:28:16.295503 22565 solver.cpp:253]     Train net output #0: loss = 1.21739 (* 1 = 1.21739 loss)
I0525 04:28:16.295521 22565 sgd_solver.cpp:106] Iteration 75548, lr = 0.005
I0525 04:28:24.959341 22565 solver.cpp:237] Iteration 75735, loss = 1.05465
I0525 04:28:24.959398 22565 solver.cpp:253]     Train net output #0: loss = 1.05465 (* 1 = 1.05465 loss)
I0525 04:28:24.959424 22565 sgd_solver.cpp:106] Iteration 75735, lr = 0.005
I0525 04:28:33.625478 22565 solver.cpp:237] Iteration 75922, loss = 1.50553
I0525 04:28:33.625514 22565 solver.cpp:253]     Train net output #0: loss = 1.50553 (* 1 = 1.50553 loss)
I0525 04:28:33.625533 22565 sgd_solver.cpp:106] Iteration 75922, lr = 0.005
I0525 04:28:42.296810 22565 solver.cpp:237] Iteration 76109, loss = 1.11981
I0525 04:28:42.296999 22565 solver.cpp:253]     Train net output #0: loss = 1.11981 (* 1 = 1.11981 loss)
I0525 04:28:42.297016 22565 sgd_solver.cpp:106] Iteration 76109, lr = 0.005
I0525 04:29:11.832504 22565 solver.cpp:237] Iteration 76296, loss = 1.2486
I0525 04:29:11.832561 22565 solver.cpp:253]     Train net output #0: loss = 1.2486 (* 1 = 1.2486 loss)
I0525 04:29:11.832581 22565 sgd_solver.cpp:106] Iteration 76296, lr = 0.005
I0525 04:29:20.500553 22565 solver.cpp:237] Iteration 76483, loss = 1.28477
I0525 04:29:20.500756 22565 solver.cpp:253]     Train net output #0: loss = 1.28477 (* 1 = 1.28477 loss)
I0525 04:29:20.500773 22565 sgd_solver.cpp:106] Iteration 76483, lr = 0.005
I0525 04:29:29.170313 22565 solver.cpp:237] Iteration 76670, loss = 1.17245
I0525 04:29:29.170351 22565 solver.cpp:253]     Train net output #0: loss = 1.17245 (* 1 = 1.17245 loss)
I0525 04:29:29.170374 22565 sgd_solver.cpp:106] Iteration 76670, lr = 0.005
I0525 04:29:37.837111 22565 solver.cpp:237] Iteration 76857, loss = 1.30391
I0525 04:29:37.837151 22565 solver.cpp:253]     Train net output #0: loss = 1.30391 (* 1 = 1.30391 loss)
I0525 04:29:37.837167 22565 sgd_solver.cpp:106] Iteration 76857, lr = 0.005
I0525 04:29:38.625576 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_76875.caffemodel
I0525 04:29:38.695583 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_76875.solverstate
I0525 04:29:46.574514 22565 solver.cpp:237] Iteration 77044, loss = 1.28149
I0525 04:29:46.574573 22565 solver.cpp:253]     Train net output #0: loss = 1.28149 (* 1 = 1.28149 loss)
I0525 04:29:46.574589 22565 sgd_solver.cpp:106] Iteration 77044, lr = 0.005
I0525 04:29:55.244069 22565 solver.cpp:237] Iteration 77231, loss = 1.1685
I0525 04:29:55.244253 22565 solver.cpp:253]     Train net output #0: loss = 1.1685 (* 1 = 1.1685 loss)
I0525 04:29:55.244278 22565 sgd_solver.cpp:106] Iteration 77231, lr = 0.005
I0525 04:30:03.909948 22565 solver.cpp:237] Iteration 77418, loss = 1.19216
I0525 04:30:03.910009 22565 solver.cpp:253]     Train net output #0: loss = 1.19216 (* 1 = 1.19216 loss)
I0525 04:30:03.910038 22565 sgd_solver.cpp:106] Iteration 77418, lr = 0.005
I0525 04:30:33.417155 22565 solver.cpp:237] Iteration 77605, loss = 1.16968
I0525 04:30:33.417358 22565 solver.cpp:253]     Train net output #0: loss = 1.16968 (* 1 = 1.16968 loss)
I0525 04:30:33.417376 22565 sgd_solver.cpp:106] Iteration 77605, lr = 0.005
I0525 04:30:42.086836 22565 solver.cpp:237] Iteration 77792, loss = 1.32909
I0525 04:30:42.086874 22565 solver.cpp:253]     Train net output #0: loss = 1.32909 (* 1 = 1.32909 loss)
I0525 04:30:42.086892 22565 sgd_solver.cpp:106] Iteration 77792, lr = 0.005
I0525 04:30:50.757206 22565 solver.cpp:237] Iteration 77979, loss = 1.15736
I0525 04:30:50.757243 22565 solver.cpp:253]     Train net output #0: loss = 1.15736 (* 1 = 1.15736 loss)
I0525 04:30:50.757262 22565 sgd_solver.cpp:106] Iteration 77979, lr = 0.005
I0525 04:30:59.427558 22565 solver.cpp:237] Iteration 78166, loss = 1.0447
I0525 04:30:59.427615 22565 solver.cpp:253]     Train net output #0: loss = 1.0447 (* 1 = 1.0447 loss)
I0525 04:30:59.427639 22565 sgd_solver.cpp:106] Iteration 78166, lr = 0.005
I0525 04:31:08.096189 22565 solver.cpp:237] Iteration 78353, loss = 0.996493
I0525 04:31:08.096385 22565 solver.cpp:253]     Train net output #0: loss = 0.996493 (* 1 = 0.996493 loss)
I0525 04:31:08.096403 22565 sgd_solver.cpp:106] Iteration 78353, lr = 0.005
I0525 04:31:16.762434 22565 solver.cpp:237] Iteration 78540, loss = 1.00562
I0525 04:31:16.762471 22565 solver.cpp:253]     Train net output #0: loss = 1.00562 (* 1 = 1.00562 loss)
I0525 04:31:16.762490 22565 sgd_solver.cpp:106] Iteration 78540, lr = 0.005
I0525 04:31:25.432466 22565 solver.cpp:237] Iteration 78727, loss = 1.32197
I0525 04:31:25.432523 22565 solver.cpp:253]     Train net output #0: loss = 1.32197 (* 1 = 1.32197 loss)
I0525 04:31:25.432548 22565 sgd_solver.cpp:106] Iteration 78727, lr = 0.005
I0525 04:31:26.453591 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_78750.caffemodel
I0525 04:31:26.523672 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_78750.solverstate
I0525 04:31:26.550397 22565 solver.cpp:341] Iteration 78750, Testing net (#0)
I0525 04:32:13.899591 22565 solver.cpp:409]     Test net output #0: accuracy = 0.8967
I0525 04:32:13.899804 22565 solver.cpp:409]     Test net output #1: loss = 0.317335 (* 1 = 0.317335 loss)
I0525 04:32:42.336516 22565 solver.cpp:237] Iteration 78914, loss = 1.17851
I0525 04:32:42.336576 22565 solver.cpp:253]     Train net output #0: loss = 1.17851 (* 1 = 1.17851 loss)
I0525 04:32:42.336596 22565 sgd_solver.cpp:106] Iteration 78914, lr = 0.005
I0525 04:32:50.992156 22565 solver.cpp:237] Iteration 79101, loss = 1.29589
I0525 04:32:50.992347 22565 solver.cpp:253]     Train net output #0: loss = 1.29589 (* 1 = 1.29589 loss)
I0525 04:32:50.992363 22565 sgd_solver.cpp:106] Iteration 79101, lr = 0.005
I0525 04:32:59.645226 22565 solver.cpp:237] Iteration 79288, loss = 1.23212
I0525 04:32:59.645282 22565 solver.cpp:253]     Train net output #0: loss = 1.23212 (* 1 = 1.23212 loss)
I0525 04:32:59.645298 22565 sgd_solver.cpp:106] Iteration 79288, lr = 0.005
I0525 04:33:08.297078 22565 solver.cpp:237] Iteration 79475, loss = 0.990188
I0525 04:33:08.297116 22565 solver.cpp:253]     Train net output #0: loss = 0.990188 (* 1 = 0.990188 loss)
I0525 04:33:08.297135 22565 sgd_solver.cpp:106] Iteration 79475, lr = 0.005
I0525 04:33:16.948395 22565 solver.cpp:237] Iteration 79662, loss = 1.16033
I0525 04:33:16.948432 22565 solver.cpp:253]     Train net output #0: loss = 1.16033 (* 1 = 1.16033 loss)
I0525 04:33:16.948451 22565 sgd_solver.cpp:106] Iteration 79662, lr = 0.005
I0525 04:33:25.599647 22565 solver.cpp:237] Iteration 79849, loss = 1.03059
I0525 04:33:25.599848 22565 solver.cpp:253]     Train net output #0: loss = 1.03059 (* 1 = 1.03059 loss)
I0525 04:33:25.599866 22565 sgd_solver.cpp:106] Iteration 79849, lr = 0.005
I0525 04:33:55.084498 22565 solver.cpp:237] Iteration 80036, loss = 1.09281
I0525 04:33:55.084554 22565 solver.cpp:253]     Train net output #0: loss = 1.09281 (* 1 = 1.09281 loss)
I0525 04:33:55.084571 22565 sgd_solver.cpp:106] Iteration 80036, lr = 0.005
I0525 04:34:03.736413 22565 solver.cpp:237] Iteration 80223, loss = 1.49131
I0525 04:34:03.736596 22565 solver.cpp:253]     Train net output #0: loss = 1.49131 (* 1 = 1.49131 loss)
I0525 04:34:03.736613 22565 sgd_solver.cpp:106] Iteration 80223, lr = 0.005
I0525 04:34:12.391264 22565 solver.cpp:237] Iteration 80410, loss = 1.12839
I0525 04:34:12.391301 22565 solver.cpp:253]     Train net output #0: loss = 1.12839 (* 1 = 1.12839 loss)
I0525 04:34:12.391324 22565 sgd_solver.cpp:106] Iteration 80410, lr = 0.005
I0525 04:34:21.039181 22565 solver.cpp:237] Iteration 80597, loss = 1.19115
I0525 04:34:21.039238 22565 solver.cpp:253]     Train net output #0: loss = 1.19115 (* 1 = 1.19115 loss)
I0525 04:34:21.039263 22565 sgd_solver.cpp:106] Iteration 80597, lr = 0.005
I0525 04:34:22.289474 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_80625.caffemodel
I0525 04:34:22.359171 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_80625.solverstate
I0525 04:34:29.754142 22565 solver.cpp:237] Iteration 80784, loss = 1.33072
I0525 04:34:29.754195 22565 solver.cpp:253]     Train net output #0: loss = 1.33072 (* 1 = 1.33072 loss)
I0525 04:34:29.754214 22565 sgd_solver.cpp:106] Iteration 80784, lr = 0.005
I0525 04:34:38.403187 22565 solver.cpp:237] Iteration 80971, loss = 0.935981
I0525 04:34:38.403388 22565 solver.cpp:253]     Train net output #0: loss = 0.935981 (* 1 = 0.935981 loss)
I0525 04:34:38.403405 22565 sgd_solver.cpp:106] Iteration 80971, lr = 0.005
I0525 04:34:47.054913 22565 solver.cpp:237] Iteration 81158, loss = 0.967972
I0525 04:34:47.054968 22565 solver.cpp:253]     Train net output #0: loss = 0.967972 (* 1 = 0.967972 loss)
I0525 04:34:47.054992 22565 sgd_solver.cpp:106] Iteration 81158, lr = 0.005
I0525 04:35:16.577682 22565 solver.cpp:237] Iteration 81345, loss = 1.10198
I0525 04:35:16.577889 22565 solver.cpp:253]     Train net output #0: loss = 1.10198 (* 1 = 1.10198 loss)
I0525 04:35:16.577908 22565 sgd_solver.cpp:106] Iteration 81345, lr = 0.005
I0525 04:35:25.231426 22565 solver.cpp:237] Iteration 81532, loss = 1.06347
I0525 04:35:25.231464 22565 solver.cpp:253]     Train net output #0: loss = 1.06347 (* 1 = 1.06347 loss)
I0525 04:35:25.231483 22565 sgd_solver.cpp:106] Iteration 81532, lr = 0.005
I0525 04:35:33.876226 22565 solver.cpp:237] Iteration 81719, loss = 1.24617
I0525 04:35:33.876289 22565 solver.cpp:253]     Train net output #0: loss = 1.24617 (* 1 = 1.24617 loss)
I0525 04:35:33.876322 22565 sgd_solver.cpp:106] Iteration 81719, lr = 0.005
I0525 04:35:42.523071 22565 solver.cpp:237] Iteration 81906, loss = 1.09914
I0525 04:35:42.523108 22565 solver.cpp:253]     Train net output #0: loss = 1.09914 (* 1 = 1.09914 loss)
I0525 04:35:42.523128 22565 sgd_solver.cpp:106] Iteration 81906, lr = 0.005
I0525 04:35:51.163926 22565 solver.cpp:237] Iteration 82093, loss = 1.0472
I0525 04:35:51.164110 22565 solver.cpp:253]     Train net output #0: loss = 1.0472 (* 1 = 1.0472 loss)
I0525 04:35:51.164127 22565 sgd_solver.cpp:106] Iteration 82093, lr = 0.005
I0525 04:35:59.812134 22565 solver.cpp:237] Iteration 82280, loss = 1.22958
I0525 04:35:59.812191 22565 solver.cpp:253]     Train net output #0: loss = 1.22958 (* 1 = 1.22958 loss)
I0525 04:35:59.812216 22565 sgd_solver.cpp:106] Iteration 82280, lr = 0.005
I0525 04:36:08.458616 22565 solver.cpp:237] Iteration 82467, loss = 1.24132
I0525 04:36:08.458652 22565 solver.cpp:253]     Train net output #0: loss = 1.24132 (* 1 = 1.24132 loss)
I0525 04:36:08.458672 22565 sgd_solver.cpp:106] Iteration 82467, lr = 0.005
I0525 04:36:09.936491 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_82500.caffemodel
I0525 04:36:10.006397 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_82500.solverstate
I0525 04:36:10.032862 22565 solver.cpp:341] Iteration 82500, Testing net (#0)
I0525 04:37:18.193492 22565 solver.cpp:409]     Test net output #0: accuracy = 0.89934
I0525 04:37:18.193701 22565 solver.cpp:409]     Test net output #1: loss = 0.347676 (* 1 = 0.347676 loss)
I0525 04:37:46.167783 22565 solver.cpp:237] Iteration 82654, loss = 1.07194
I0525 04:37:46.167843 22565 solver.cpp:253]     Train net output #0: loss = 1.07194 (* 1 = 1.07194 loss)
I0525 04:37:46.167862 22565 sgd_solver.cpp:106] Iteration 82654, lr = 0.005
I0525 04:37:54.826031 22565 solver.cpp:237] Iteration 82841, loss = 1.0941
I0525 04:37:54.826237 22565 solver.cpp:253]     Train net output #0: loss = 1.0941 (* 1 = 1.0941 loss)
I0525 04:37:54.826254 22565 sgd_solver.cpp:106] Iteration 82841, lr = 0.005
I0525 04:38:03.483958 22565 solver.cpp:237] Iteration 83028, loss = 1.34701
I0525 04:38:03.484014 22565 solver.cpp:253]     Train net output #0: loss = 1.34701 (* 1 = 1.34701 loss)
I0525 04:38:03.484042 22565 sgd_solver.cpp:106] Iteration 83028, lr = 0.005
I0525 04:38:12.141309 22565 solver.cpp:237] Iteration 83215, loss = 1.31087
I0525 04:38:12.141345 22565 solver.cpp:253]     Train net output #0: loss = 1.31087 (* 1 = 1.31087 loss)
I0525 04:38:12.141368 22565 sgd_solver.cpp:106] Iteration 83215, lr = 0.005
I0525 04:38:20.797433 22565 solver.cpp:237] Iteration 83402, loss = 1.33474
I0525 04:38:20.797471 22565 solver.cpp:253]     Train net output #0: loss = 1.33474 (* 1 = 1.33474 loss)
I0525 04:38:20.797493 22565 sgd_solver.cpp:106] Iteration 83402, lr = 0.005
I0525 04:38:29.449880 22565 solver.cpp:237] Iteration 83589, loss = 1.25332
I0525 04:38:29.450083 22565 solver.cpp:253]     Train net output #0: loss = 1.25332 (* 1 = 1.25332 loss)
I0525 04:38:29.450100 22565 sgd_solver.cpp:106] Iteration 83589, lr = 0.005
I0525 04:38:58.927093 22565 solver.cpp:237] Iteration 83776, loss = 1.20902
I0525 04:38:58.927150 22565 solver.cpp:253]     Train net output #0: loss = 1.20902 (* 1 = 1.20902 loss)
I0525 04:38:58.927170 22565 sgd_solver.cpp:106] Iteration 83776, lr = 0.005
I0525 04:39:07.580289 22565 solver.cpp:237] Iteration 83963, loss = 1.04553
I0525 04:39:07.580479 22565 solver.cpp:253]     Train net output #0: loss = 1.04553 (* 1 = 1.04553 loss)
I0525 04:39:07.580497 22565 sgd_solver.cpp:106] Iteration 83963, lr = 0.005
I0525 04:39:16.230756 22565 solver.cpp:237] Iteration 84150, loss = 1.3164
I0525 04:39:16.230808 22565 solver.cpp:253]     Train net output #0: loss = 1.3164 (* 1 = 1.3164 loss)
I0525 04:39:16.230824 22565 sgd_solver.cpp:106] Iteration 84150, lr = 0.005
I0525 04:39:24.880924 22565 solver.cpp:237] Iteration 84337, loss = 1.02332
I0525 04:39:24.880961 22565 solver.cpp:253]     Train net output #0: loss = 1.02332 (* 1 = 1.02332 loss)
I0525 04:39:24.880980 22565 sgd_solver.cpp:106] Iteration 84337, lr = 0.005
I0525 04:39:26.593514 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_84375.caffemodel
I0525 04:39:26.664700 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_84375.solverstate
I0525 04:39:33.604037 22565 solver.cpp:237] Iteration 84524, loss = 1.21689
I0525 04:39:33.604092 22565 solver.cpp:253]     Train net output #0: loss = 1.21689 (* 1 = 1.21689 loss)
I0525 04:39:33.604110 22565 sgd_solver.cpp:106] Iteration 84524, lr = 0.005
I0525 04:39:42.255345 22565 solver.cpp:237] Iteration 84711, loss = 0.746071
I0525 04:39:42.255553 22565 solver.cpp:253]     Train net output #0: loss = 0.746071 (* 1 = 0.746071 loss)
I0525 04:39:42.255578 22565 sgd_solver.cpp:106] Iteration 84711, lr = 0.005
I0525 04:39:50.908810 22565 solver.cpp:237] Iteration 84898, loss = 1.13992
I0525 04:39:50.908848 22565 solver.cpp:253]     Train net output #0: loss = 1.13992 (* 1 = 1.13992 loss)
I0525 04:39:50.908870 22565 sgd_solver.cpp:106] Iteration 84898, lr = 0.005
I0525 04:40:20.398715 22565 solver.cpp:237] Iteration 85085, loss = 1.12724
I0525 04:40:20.398926 22565 solver.cpp:253]     Train net output #0: loss = 1.12724 (* 1 = 1.12724 loss)
I0525 04:40:20.398943 22565 sgd_solver.cpp:106] Iteration 85085, lr = 0.005
I0525 04:40:29.052805 22565 solver.cpp:237] Iteration 85272, loss = 1.24795
I0525 04:40:29.052858 22565 solver.cpp:253]     Train net output #0: loss = 1.24795 (* 1 = 1.24795 loss)
I0525 04:40:29.052877 22565 sgd_solver.cpp:106] Iteration 85272, lr = 0.005
I0525 04:40:37.703074 22565 solver.cpp:237] Iteration 85459, loss = 1.1765
I0525 04:40:37.703111 22565 solver.cpp:253]     Train net output #0: loss = 1.1765 (* 1 = 1.1765 loss)
I0525 04:40:37.703130 22565 sgd_solver.cpp:106] Iteration 85459, lr = 0.005
I0525 04:40:46.356159 22565 solver.cpp:237] Iteration 85646, loss = 1.07272
I0525 04:40:46.356195 22565 solver.cpp:253]     Train net output #0: loss = 1.07272 (* 1 = 1.07272 loss)
I0525 04:40:46.356220 22565 sgd_solver.cpp:106] Iteration 85646, lr = 0.005
I0525 04:40:55.009177 22565 solver.cpp:237] Iteration 85833, loss = 0.937194
I0525 04:40:55.009393 22565 solver.cpp:253]     Train net output #0: loss = 0.937194 (* 1 = 0.937194 loss)
I0525 04:40:55.009413 22565 sgd_solver.cpp:106] Iteration 85833, lr = 0.005
I0525 04:41:03.650202 22565 solver.cpp:237] Iteration 86020, loss = 1.36426
I0525 04:41:03.650240 22565 solver.cpp:253]     Train net output #0: loss = 1.36426 (* 1 = 1.36426 loss)
I0525 04:41:03.650259 22565 sgd_solver.cpp:106] Iteration 86020, lr = 0.005
I0525 04:41:12.293076 22565 solver.cpp:237] Iteration 86207, loss = 1.22378
I0525 04:41:12.293113 22565 solver.cpp:253]     Train net output #0: loss = 1.22378 (* 1 = 1.22378 loss)
I0525 04:41:12.293136 22565 sgd_solver.cpp:106] Iteration 86207, lr = 0.005
I0525 04:41:14.232836 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_86250.caffemodel
I0525 04:41:14.302839 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_86250.solverstate
I0525 04:41:14.329337 22565 solver.cpp:341] Iteration 86250, Testing net (#0)
I0525 04:42:01.380527 22565 solver.cpp:409]     Test net output #0: accuracy = 0.897087
I0525 04:42:01.380730 22565 solver.cpp:409]     Test net output #1: loss = 0.316983 (* 1 = 0.316983 loss)
I0525 04:42:28.877357 22565 solver.cpp:237] Iteration 86394, loss = 1.20349
I0525 04:42:28.877413 22565 solver.cpp:253]     Train net output #0: loss = 1.20349 (* 1 = 1.20349 loss)
I0525 04:42:28.877437 22565 sgd_solver.cpp:106] Iteration 86394, lr = 0.005
I0525 04:42:37.519484 22565 solver.cpp:237] Iteration 86581, loss = 1.14388
I0525 04:42:37.519687 22565 solver.cpp:253]     Train net output #0: loss = 1.14388 (* 1 = 1.14388 loss)
I0525 04:42:37.519706 22565 sgd_solver.cpp:106] Iteration 86581, lr = 0.005
I0525 04:42:46.159154 22565 solver.cpp:237] Iteration 86768, loss = 1.25787
I0525 04:42:46.159191 22565 solver.cpp:253]     Train net output #0: loss = 1.25787 (* 1 = 1.25787 loss)
I0525 04:42:46.159214 22565 sgd_solver.cpp:106] Iteration 86768, lr = 0.005
I0525 04:42:54.804335 22565 solver.cpp:237] Iteration 86955, loss = 1.18852
I0525 04:42:54.804373 22565 solver.cpp:253]     Train net output #0: loss = 1.18852 (* 1 = 1.18852 loss)
I0525 04:42:54.804390 22565 sgd_solver.cpp:106] Iteration 86955, lr = 0.005
I0525 04:43:03.452466 22565 solver.cpp:237] Iteration 87142, loss = 0.888569
I0525 04:43:03.452525 22565 solver.cpp:253]     Train net output #0: loss = 0.888569 (* 1 = 0.888569 loss)
I0525 04:43:03.452551 22565 sgd_solver.cpp:106] Iteration 87142, lr = 0.005
I0525 04:43:12.095976 22565 solver.cpp:237] Iteration 87329, loss = 1.07097
I0525 04:43:12.096160 22565 solver.cpp:253]     Train net output #0: loss = 1.07097 (* 1 = 1.07097 loss)
I0525 04:43:12.096177 22565 sgd_solver.cpp:106] Iteration 87329, lr = 0.005
I0525 04:43:41.587996 22565 solver.cpp:237] Iteration 87516, loss = 1.09115
I0525 04:43:41.588057 22565 solver.cpp:253]     Train net output #0: loss = 1.09115 (* 1 = 1.09115 loss)
I0525 04:43:41.588080 22565 sgd_solver.cpp:106] Iteration 87516, lr = 0.005
I0525 04:43:50.231792 22565 solver.cpp:237] Iteration 87703, loss = 1.22358
I0525 04:43:50.231998 22565 solver.cpp:253]     Train net output #0: loss = 1.22358 (* 1 = 1.22358 loss)
I0525 04:43:50.232018 22565 sgd_solver.cpp:106] Iteration 87703, lr = 0.005
I0525 04:43:58.894095 22565 solver.cpp:237] Iteration 87890, loss = 0.927369
I0525 04:43:58.894134 22565 solver.cpp:253]     Train net output #0: loss = 0.927369 (* 1 = 0.927369 loss)
I0525 04:43:58.894151 22565 sgd_solver.cpp:106] Iteration 87890, lr = 0.005
I0525 04:44:07.557770 22565 solver.cpp:237] Iteration 88077, loss = 0.86751
I0525 04:44:07.557807 22565 solver.cpp:253]     Train net output #0: loss = 0.86751 (* 1 = 0.86751 loss)
I0525 04:44:07.557824 22565 sgd_solver.cpp:106] Iteration 88077, lr = 0.005
I0525 04:44:09.735780 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_88125.caffemodel
I0525 04:44:09.806440 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_88125.solverstate
I0525 04:44:16.287763 22565 solver.cpp:237] Iteration 88264, loss = 0.908011
I0525 04:44:16.287820 22565 solver.cpp:253]     Train net output #0: loss = 0.908011 (* 1 = 0.908011 loss)
I0525 04:44:16.287837 22565 sgd_solver.cpp:106] Iteration 88264, lr = 0.005
I0525 04:44:24.951278 22565 solver.cpp:237] Iteration 88451, loss = 1.16705
I0525 04:44:24.951486 22565 solver.cpp:253]     Train net output #0: loss = 1.16705 (* 1 = 1.16705 loss)
I0525 04:44:24.951503 22565 sgd_solver.cpp:106] Iteration 88451, lr = 0.005
I0525 04:44:33.612375 22565 solver.cpp:237] Iteration 88638, loss = 1.23566
I0525 04:44:33.612411 22565 solver.cpp:253]     Train net output #0: loss = 1.23566 (* 1 = 1.23566 loss)
I0525 04:44:33.612433 22565 sgd_solver.cpp:106] Iteration 88638, lr = 0.005
I0525 04:45:03.097095 22565 solver.cpp:237] Iteration 88825, loss = 1.06177
I0525 04:45:03.097306 22565 solver.cpp:253]     Train net output #0: loss = 1.06177 (* 1 = 1.06177 loss)
I0525 04:45:03.097326 22565 sgd_solver.cpp:106] Iteration 88825, lr = 0.005
I0525 04:45:11.758410 22565 solver.cpp:237] Iteration 89012, loss = 0.932958
I0525 04:45:11.758465 22565 solver.cpp:253]     Train net output #0: loss = 0.932958 (* 1 = 0.932958 loss)
I0525 04:45:11.758483 22565 sgd_solver.cpp:106] Iteration 89012, lr = 0.005
I0525 04:45:20.423718 22565 solver.cpp:237] Iteration 89199, loss = 0.944435
I0525 04:45:20.423756 22565 solver.cpp:253]     Train net output #0: loss = 0.944435 (* 1 = 0.944435 loss)
I0525 04:45:20.423775 22565 sgd_solver.cpp:106] Iteration 89199, lr = 0.005
I0525 04:45:29.087944 22565 solver.cpp:237] Iteration 89386, loss = 1.16661
I0525 04:45:29.087999 22565 solver.cpp:253]     Train net output #0: loss = 1.16661 (* 1 = 1.16661 loss)
I0525 04:45:29.088028 22565 sgd_solver.cpp:106] Iteration 89386, lr = 0.005
I0525 04:45:37.750099 22565 solver.cpp:237] Iteration 89573, loss = 1.05597
I0525 04:45:37.750288 22565 solver.cpp:253]     Train net output #0: loss = 1.05597 (* 1 = 1.05597 loss)
I0525 04:45:37.750303 22565 sgd_solver.cpp:106] Iteration 89573, lr = 0.005
I0525 04:45:46.414343 22565 solver.cpp:237] Iteration 89760, loss = 1.02275
I0525 04:45:46.414381 22565 solver.cpp:253]     Train net output #0: loss = 1.02275 (* 1 = 1.02275 loss)
I0525 04:45:46.414403 22565 sgd_solver.cpp:106] Iteration 89760, lr = 0.005
I0525 04:45:55.078814 22565 solver.cpp:237] Iteration 89947, loss = 1.2897
I0525 04:45:55.078872 22565 solver.cpp:253]     Train net output #0: loss = 1.2897 (* 1 = 1.2897 loss)
I0525 04:45:55.078897 22565 sgd_solver.cpp:106] Iteration 89947, lr = 0.005
I0525 04:45:57.490078 22565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_90000.caffemodel
I0525 04:45:57.560045 22565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0050_2016-05-20T15.49.19.790379_iter_90000.solverstate
I0525 04:45:57.586942 22565 solver.cpp:341] Iteration 90000, Testing net (#0)
I0525 04:47:05.771355 22565 solver.cpp:409]     Test net output #0: accuracy = 0.901474
I0525 04:47:05.771576 22565 solver.cpp:409]     Test net output #1: loss = 0.314484 (* 1 = 0.314484 loss)
I0525 04:47:32.823541 22565 solver.cpp:237] Iteration 90134, loss = 0.954317
I0525 04:47:32.823602 22565 solver.cpp:253]     Train net output #0: loss = 0.954317 (* 1 = 0.954317 loss)
I0525 04:47:32.823627 22565 sgd_solver.cpp:106] Iteration 90134, lr = 0.005
I0525 04:47:41.478058 22565 solver.cpp:237] Iteration 90321, loss = 1.1749
I0525 04:47:41.478262 22565 solver.cpp:253]     Train net output #0: loss = 1.1749 (* 1 = 1.1749 loss)
I0525 04:47:41.478281 22565 sgd_solver.cpp:106] Iteration 90321, lr = 0.005
I0525 04:47:50.132726 22565 solver.cpp:237] Iteration 90508, loss = 1.29546
I0525 04:47:50.132762 22565 solver.cpp:253]     Train net output #0: loss = 1.29546 (* 1 = 1.29546 loss)
I0525 04:47:50.132781 22565 sgd_solver.cpp:106] Iteration 90508, lr = 0.005
I0525 04:47:58.787752 22565 solver.cpp:237] Iteration 90695, loss = 1.18849
I0525 04:47:58.787791 22565 solver.cpp:253]     Train net output #0: loss = 1.18849 (* 1 = 1.18849 loss)
I0525 04:47:58.787807 22565 sgd_solver.cpp:106] Iteration 90695, lr = 0.005
I0525 04:48:07.432986 22565 solver.cpp:237] Iteration 90882, loss = 1.20002
I0525 04:48:07.433037 22565 solver.cpp:253]     Train net output #0: loss = 1.20002 (* 1 = 1.20002 loss)
I0525 04:48:07.433065 22565 sgd_solver.cpp:106] Iteration 90882, lr = 0.005
I0525 04:48:16.072829 22565 solver.cpp:237] Iteration 91069, loss = 0.991132
I0525 04:48:16.073017 22565 solver.cpp:253]     Train net output #0: loss = 0.991132 (* 1 = 0.991132 loss)
I0525 04:48:16.073035 22565 sgd_solver.cpp:106] Iteration 91069, lr = 0.005
aprun: Apid 11262387: Caught signal Terminated, sending to application
*** Aborted at 1464166102 (unix time) try "date -d @1464166102" if you are using GNU date ***
aprun: Apid 11262387: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11262387: Caught signal Terminated, sending to application
*** SIGTERM (@0x5822) received by PID 22565 (TID 0x2aaac746f900) from PID 22562; stack trace: ***
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7230 exceeded limit 7200
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11262387: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11262387: Caught signal Terminated, sending to application
