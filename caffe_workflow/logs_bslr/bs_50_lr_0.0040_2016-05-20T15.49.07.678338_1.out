2808214
I0523 08:17:10.565882  3513 caffe.cpp:184] Using GPUs 0
I0523 08:17:10.992439  3513 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3000
test_interval: 6000
base_lr: 0.004
display: 300
max_iter: 300000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338.prototxt"
I0523 08:17:10.994274  3513 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338.prototxt
I0523 08:17:11.008015  3513 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 08:17:11.008077  3513 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 08:17:11.008424  3513 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 08:17:11.008602  3513 layer_factory.hpp:77] Creating layer data_hdf5
I0523 08:17:11.008626  3513 net.cpp:106] Creating Layer data_hdf5
I0523 08:17:11.008641  3513 net.cpp:411] data_hdf5 -> data
I0523 08:17:11.008674  3513 net.cpp:411] data_hdf5 -> label
I0523 08:17:11.008707  3513 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 08:17:11.010011  3513 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 08:17:11.026098  3513 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 08:17:32.594509  3513 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 08:17:32.599725  3513 net.cpp:150] Setting up data_hdf5
I0523 08:17:32.599766  3513 net.cpp:157] Top shape: 50 1 127 50 (317500)
I0523 08:17:32.599781  3513 net.cpp:157] Top shape: 50 (50)
I0523 08:17:32.599793  3513 net.cpp:165] Memory required for data: 1270200
I0523 08:17:32.599807  3513 layer_factory.hpp:77] Creating layer conv1
I0523 08:17:32.599849  3513 net.cpp:106] Creating Layer conv1
I0523 08:17:32.599861  3513 net.cpp:454] conv1 <- data
I0523 08:17:32.599884  3513 net.cpp:411] conv1 -> conv1
I0523 08:17:33.708032  3513 net.cpp:150] Setting up conv1
I0523 08:17:33.708082  3513 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 08:17:33.708093  3513 net.cpp:165] Memory required for data: 15094200
I0523 08:17:33.708122  3513 layer_factory.hpp:77] Creating layer relu1
I0523 08:17:33.708143  3513 net.cpp:106] Creating Layer relu1
I0523 08:17:33.708154  3513 net.cpp:454] relu1 <- conv1
I0523 08:17:33.708168  3513 net.cpp:397] relu1 -> conv1 (in-place)
I0523 08:17:33.708688  3513 net.cpp:150] Setting up relu1
I0523 08:17:33.708704  3513 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 08:17:33.708715  3513 net.cpp:165] Memory required for data: 28918200
I0523 08:17:33.708725  3513 layer_factory.hpp:77] Creating layer pool1
I0523 08:17:33.708742  3513 net.cpp:106] Creating Layer pool1
I0523 08:17:33.708752  3513 net.cpp:454] pool1 <- conv1
I0523 08:17:33.708765  3513 net.cpp:411] pool1 -> pool1
I0523 08:17:33.708847  3513 net.cpp:150] Setting up pool1
I0523 08:17:33.708861  3513 net.cpp:157] Top shape: 50 12 60 48 (1728000)
I0523 08:17:33.708871  3513 net.cpp:165] Memory required for data: 35830200
I0523 08:17:33.708881  3513 layer_factory.hpp:77] Creating layer conv2
I0523 08:17:33.708904  3513 net.cpp:106] Creating Layer conv2
I0523 08:17:33.708915  3513 net.cpp:454] conv2 <- pool1
I0523 08:17:33.708928  3513 net.cpp:411] conv2 -> conv2
I0523 08:17:33.711598  3513 net.cpp:150] Setting up conv2
I0523 08:17:33.711627  3513 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 08:17:33.711637  3513 net.cpp:165] Memory required for data: 45766200
I0523 08:17:33.711658  3513 layer_factory.hpp:77] Creating layer relu2
I0523 08:17:33.711671  3513 net.cpp:106] Creating Layer relu2
I0523 08:17:33.711681  3513 net.cpp:454] relu2 <- conv2
I0523 08:17:33.711694  3513 net.cpp:397] relu2 -> conv2 (in-place)
I0523 08:17:33.712036  3513 net.cpp:150] Setting up relu2
I0523 08:17:33.712051  3513 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 08:17:33.712061  3513 net.cpp:165] Memory required for data: 55702200
I0523 08:17:33.712072  3513 layer_factory.hpp:77] Creating layer pool2
I0523 08:17:33.712085  3513 net.cpp:106] Creating Layer pool2
I0523 08:17:33.712095  3513 net.cpp:454] pool2 <- conv2
I0523 08:17:33.712108  3513 net.cpp:411] pool2 -> pool2
I0523 08:17:33.712188  3513 net.cpp:150] Setting up pool2
I0523 08:17:33.712203  3513 net.cpp:157] Top shape: 50 20 27 46 (1242000)
I0523 08:17:33.712213  3513 net.cpp:165] Memory required for data: 60670200
I0523 08:17:33.712222  3513 layer_factory.hpp:77] Creating layer conv3
I0523 08:17:33.712241  3513 net.cpp:106] Creating Layer conv3
I0523 08:17:33.712251  3513 net.cpp:454] conv3 <- pool2
I0523 08:17:33.712265  3513 net.cpp:411] conv3 -> conv3
I0523 08:17:33.714203  3513 net.cpp:150] Setting up conv3
I0523 08:17:33.714227  3513 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 08:17:33.714238  3513 net.cpp:165] Memory required for data: 66091000
I0523 08:17:33.714257  3513 layer_factory.hpp:77] Creating layer relu3
I0523 08:17:33.714273  3513 net.cpp:106] Creating Layer relu3
I0523 08:17:33.714283  3513 net.cpp:454] relu3 <- conv3
I0523 08:17:33.714296  3513 net.cpp:397] relu3 -> conv3 (in-place)
I0523 08:17:33.714762  3513 net.cpp:150] Setting up relu3
I0523 08:17:33.714779  3513 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 08:17:33.714790  3513 net.cpp:165] Memory required for data: 71511800
I0523 08:17:33.714800  3513 layer_factory.hpp:77] Creating layer pool3
I0523 08:17:33.714813  3513 net.cpp:106] Creating Layer pool3
I0523 08:17:33.714823  3513 net.cpp:454] pool3 <- conv3
I0523 08:17:33.714836  3513 net.cpp:411] pool3 -> pool3
I0523 08:17:33.714902  3513 net.cpp:150] Setting up pool3
I0523 08:17:33.714916  3513 net.cpp:157] Top shape: 50 28 11 44 (677600)
I0523 08:17:33.714926  3513 net.cpp:165] Memory required for data: 74222200
I0523 08:17:33.714936  3513 layer_factory.hpp:77] Creating layer conv4
I0523 08:17:33.714951  3513 net.cpp:106] Creating Layer conv4
I0523 08:17:33.714962  3513 net.cpp:454] conv4 <- pool3
I0523 08:17:33.714975  3513 net.cpp:411] conv4 -> conv4
I0523 08:17:33.717743  3513 net.cpp:150] Setting up conv4
I0523 08:17:33.717767  3513 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 08:17:33.717778  3513 net.cpp:165] Memory required for data: 76036600
I0523 08:17:33.717795  3513 layer_factory.hpp:77] Creating layer relu4
I0523 08:17:33.717810  3513 net.cpp:106] Creating Layer relu4
I0523 08:17:33.717821  3513 net.cpp:454] relu4 <- conv4
I0523 08:17:33.717834  3513 net.cpp:397] relu4 -> conv4 (in-place)
I0523 08:17:33.718303  3513 net.cpp:150] Setting up relu4
I0523 08:17:33.718320  3513 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 08:17:33.718330  3513 net.cpp:165] Memory required for data: 77851000
I0523 08:17:33.718343  3513 layer_factory.hpp:77] Creating layer pool4
I0523 08:17:33.718355  3513 net.cpp:106] Creating Layer pool4
I0523 08:17:33.718365  3513 net.cpp:454] pool4 <- conv4
I0523 08:17:33.718379  3513 net.cpp:411] pool4 -> pool4
I0523 08:17:33.718446  3513 net.cpp:150] Setting up pool4
I0523 08:17:33.718461  3513 net.cpp:157] Top shape: 50 36 3 42 (226800)
I0523 08:17:33.718471  3513 net.cpp:165] Memory required for data: 78758200
I0523 08:17:33.718480  3513 layer_factory.hpp:77] Creating layer ip1
I0523 08:17:33.718499  3513 net.cpp:106] Creating Layer ip1
I0523 08:17:33.718509  3513 net.cpp:454] ip1 <- pool4
I0523 08:17:33.718523  3513 net.cpp:411] ip1 -> ip1
I0523 08:17:33.733943  3513 net.cpp:150] Setting up ip1
I0523 08:17:33.733968  3513 net.cpp:157] Top shape: 50 196 (9800)
I0523 08:17:33.733979  3513 net.cpp:165] Memory required for data: 78797400
I0523 08:17:33.734005  3513 layer_factory.hpp:77] Creating layer relu5
I0523 08:17:33.734020  3513 net.cpp:106] Creating Layer relu5
I0523 08:17:33.734031  3513 net.cpp:454] relu5 <- ip1
I0523 08:17:33.734045  3513 net.cpp:397] relu5 -> ip1 (in-place)
I0523 08:17:33.734385  3513 net.cpp:150] Setting up relu5
I0523 08:17:33.734400  3513 net.cpp:157] Top shape: 50 196 (9800)
I0523 08:17:33.734411  3513 net.cpp:165] Memory required for data: 78836600
I0523 08:17:33.734421  3513 layer_factory.hpp:77] Creating layer drop1
I0523 08:17:33.734444  3513 net.cpp:106] Creating Layer drop1
I0523 08:17:33.734454  3513 net.cpp:454] drop1 <- ip1
I0523 08:17:33.734467  3513 net.cpp:397] drop1 -> ip1 (in-place)
I0523 08:17:33.734527  3513 net.cpp:150] Setting up drop1
I0523 08:17:33.734540  3513 net.cpp:157] Top shape: 50 196 (9800)
I0523 08:17:33.734550  3513 net.cpp:165] Memory required for data: 78875800
I0523 08:17:33.734561  3513 layer_factory.hpp:77] Creating layer ip2
I0523 08:17:33.734580  3513 net.cpp:106] Creating Layer ip2
I0523 08:17:33.734591  3513 net.cpp:454] ip2 <- ip1
I0523 08:17:33.734603  3513 net.cpp:411] ip2 -> ip2
I0523 08:17:33.735065  3513 net.cpp:150] Setting up ip2
I0523 08:17:33.735077  3513 net.cpp:157] Top shape: 50 98 (4900)
I0523 08:17:33.735087  3513 net.cpp:165] Memory required for data: 78895400
I0523 08:17:33.735103  3513 layer_factory.hpp:77] Creating layer relu6
I0523 08:17:33.735116  3513 net.cpp:106] Creating Layer relu6
I0523 08:17:33.735124  3513 net.cpp:454] relu6 <- ip2
I0523 08:17:33.735136  3513 net.cpp:397] relu6 -> ip2 (in-place)
I0523 08:17:33.735661  3513 net.cpp:150] Setting up relu6
I0523 08:17:33.735678  3513 net.cpp:157] Top shape: 50 98 (4900)
I0523 08:17:33.735688  3513 net.cpp:165] Memory required for data: 78915000
I0523 08:17:33.735699  3513 layer_factory.hpp:77] Creating layer drop2
I0523 08:17:33.735713  3513 net.cpp:106] Creating Layer drop2
I0523 08:17:33.735721  3513 net.cpp:454] drop2 <- ip2
I0523 08:17:33.735734  3513 net.cpp:397] drop2 -> ip2 (in-place)
I0523 08:17:33.735775  3513 net.cpp:150] Setting up drop2
I0523 08:17:33.735790  3513 net.cpp:157] Top shape: 50 98 (4900)
I0523 08:17:33.735800  3513 net.cpp:165] Memory required for data: 78934600
I0523 08:17:33.735810  3513 layer_factory.hpp:77] Creating layer ip3
I0523 08:17:33.735831  3513 net.cpp:106] Creating Layer ip3
I0523 08:17:33.735841  3513 net.cpp:454] ip3 <- ip2
I0523 08:17:33.735854  3513 net.cpp:411] ip3 -> ip3
I0523 08:17:33.736063  3513 net.cpp:150] Setting up ip3
I0523 08:17:33.736078  3513 net.cpp:157] Top shape: 50 11 (550)
I0523 08:17:33.736088  3513 net.cpp:165] Memory required for data: 78936800
I0523 08:17:33.736102  3513 layer_factory.hpp:77] Creating layer drop3
I0523 08:17:33.736115  3513 net.cpp:106] Creating Layer drop3
I0523 08:17:33.736124  3513 net.cpp:454] drop3 <- ip3
I0523 08:17:33.736136  3513 net.cpp:397] drop3 -> ip3 (in-place)
I0523 08:17:33.736176  3513 net.cpp:150] Setting up drop3
I0523 08:17:33.736188  3513 net.cpp:157] Top shape: 50 11 (550)
I0523 08:17:33.736197  3513 net.cpp:165] Memory required for data: 78939000
I0523 08:17:33.736207  3513 layer_factory.hpp:77] Creating layer loss
I0523 08:17:33.736227  3513 net.cpp:106] Creating Layer loss
I0523 08:17:33.736238  3513 net.cpp:454] loss <- ip3
I0523 08:17:33.736248  3513 net.cpp:454] loss <- label
I0523 08:17:33.736259  3513 net.cpp:411] loss -> loss
I0523 08:17:33.736276  3513 layer_factory.hpp:77] Creating layer loss
I0523 08:17:33.736922  3513 net.cpp:150] Setting up loss
I0523 08:17:33.736943  3513 net.cpp:157] Top shape: (1)
I0523 08:17:33.736956  3513 net.cpp:160]     with loss weight 1
I0523 08:17:33.737001  3513 net.cpp:165] Memory required for data: 78939004
I0523 08:17:33.737012  3513 net.cpp:226] loss needs backward computation.
I0523 08:17:33.737022  3513 net.cpp:226] drop3 needs backward computation.
I0523 08:17:33.737031  3513 net.cpp:226] ip3 needs backward computation.
I0523 08:17:33.737042  3513 net.cpp:226] drop2 needs backward computation.
I0523 08:17:33.737051  3513 net.cpp:226] relu6 needs backward computation.
I0523 08:17:33.737061  3513 net.cpp:226] ip2 needs backward computation.
I0523 08:17:33.737072  3513 net.cpp:226] drop1 needs backward computation.
I0523 08:17:33.737082  3513 net.cpp:226] relu5 needs backward computation.
I0523 08:17:33.737092  3513 net.cpp:226] ip1 needs backward computation.
I0523 08:17:33.737102  3513 net.cpp:226] pool4 needs backward computation.
I0523 08:17:33.737112  3513 net.cpp:226] relu4 needs backward computation.
I0523 08:17:33.737121  3513 net.cpp:226] conv4 needs backward computation.
I0523 08:17:33.737133  3513 net.cpp:226] pool3 needs backward computation.
I0523 08:17:33.737143  3513 net.cpp:226] relu3 needs backward computation.
I0523 08:17:33.737152  3513 net.cpp:226] conv3 needs backward computation.
I0523 08:17:33.737172  3513 net.cpp:226] pool2 needs backward computation.
I0523 08:17:33.737184  3513 net.cpp:226] relu2 needs backward computation.
I0523 08:17:33.737193  3513 net.cpp:226] conv2 needs backward computation.
I0523 08:17:33.737205  3513 net.cpp:226] pool1 needs backward computation.
I0523 08:17:33.737215  3513 net.cpp:226] relu1 needs backward computation.
I0523 08:17:33.737226  3513 net.cpp:226] conv1 needs backward computation.
I0523 08:17:33.737236  3513 net.cpp:228] data_hdf5 does not need backward computation.
I0523 08:17:33.737246  3513 net.cpp:270] This network produces output loss
I0523 08:17:33.737270  3513 net.cpp:283] Network initialization done.
I0523 08:17:33.738960  3513 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338.prototxt
I0523 08:17:33.739030  3513 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 08:17:33.739387  3513 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 08:17:33.739576  3513 layer_factory.hpp:77] Creating layer data_hdf5
I0523 08:17:33.739591  3513 net.cpp:106] Creating Layer data_hdf5
I0523 08:17:33.739603  3513 net.cpp:411] data_hdf5 -> data
I0523 08:17:33.739619  3513 net.cpp:411] data_hdf5 -> label
I0523 08:17:33.739635  3513 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 08:17:33.740872  3513 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 08:17:55.105692  3513 net.cpp:150] Setting up data_hdf5
I0523 08:17:55.105859  3513 net.cpp:157] Top shape: 50 1 127 50 (317500)
I0523 08:17:55.105873  3513 net.cpp:157] Top shape: 50 (50)
I0523 08:17:55.105885  3513 net.cpp:165] Memory required for data: 1270200
I0523 08:17:55.105897  3513 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 08:17:55.105926  3513 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 08:17:55.105937  3513 net.cpp:454] label_data_hdf5_1_split <- label
I0523 08:17:55.105952  3513 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 08:17:55.105973  3513 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 08:17:55.106045  3513 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 08:17:55.106058  3513 net.cpp:157] Top shape: 50 (50)
I0523 08:17:55.106070  3513 net.cpp:157] Top shape: 50 (50)
I0523 08:17:55.106079  3513 net.cpp:165] Memory required for data: 1270600
I0523 08:17:55.106089  3513 layer_factory.hpp:77] Creating layer conv1
I0523 08:17:55.106112  3513 net.cpp:106] Creating Layer conv1
I0523 08:17:55.106122  3513 net.cpp:454] conv1 <- data
I0523 08:17:55.106133  3513 net.cpp:411] conv1 -> conv1
I0523 08:17:55.108089  3513 net.cpp:150] Setting up conv1
I0523 08:17:55.108114  3513 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 08:17:55.108125  3513 net.cpp:165] Memory required for data: 15094600
I0523 08:17:55.108145  3513 layer_factory.hpp:77] Creating layer relu1
I0523 08:17:55.108160  3513 net.cpp:106] Creating Layer relu1
I0523 08:17:55.108170  3513 net.cpp:454] relu1 <- conv1
I0523 08:17:55.108183  3513 net.cpp:397] relu1 -> conv1 (in-place)
I0523 08:17:55.108685  3513 net.cpp:150] Setting up relu1
I0523 08:17:55.108701  3513 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 08:17:55.108711  3513 net.cpp:165] Memory required for data: 28918600
I0523 08:17:55.108721  3513 layer_factory.hpp:77] Creating layer pool1
I0523 08:17:55.108737  3513 net.cpp:106] Creating Layer pool1
I0523 08:17:55.108747  3513 net.cpp:454] pool1 <- conv1
I0523 08:17:55.108760  3513 net.cpp:411] pool1 -> pool1
I0523 08:17:55.108834  3513 net.cpp:150] Setting up pool1
I0523 08:17:55.108847  3513 net.cpp:157] Top shape: 50 12 60 48 (1728000)
I0523 08:17:55.108857  3513 net.cpp:165] Memory required for data: 35830600
I0523 08:17:55.108867  3513 layer_factory.hpp:77] Creating layer conv2
I0523 08:17:55.108886  3513 net.cpp:106] Creating Layer conv2
I0523 08:17:55.108896  3513 net.cpp:454] conv2 <- pool1
I0523 08:17:55.108908  3513 net.cpp:411] conv2 -> conv2
I0523 08:17:55.110827  3513 net.cpp:150] Setting up conv2
I0523 08:17:55.110851  3513 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 08:17:55.110863  3513 net.cpp:165] Memory required for data: 45766600
I0523 08:17:55.110882  3513 layer_factory.hpp:77] Creating layer relu2
I0523 08:17:55.110894  3513 net.cpp:106] Creating Layer relu2
I0523 08:17:55.110904  3513 net.cpp:454] relu2 <- conv2
I0523 08:17:55.110916  3513 net.cpp:397] relu2 -> conv2 (in-place)
I0523 08:17:55.111248  3513 net.cpp:150] Setting up relu2
I0523 08:17:55.111263  3513 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 08:17:55.111273  3513 net.cpp:165] Memory required for data: 55702600
I0523 08:17:55.111282  3513 layer_factory.hpp:77] Creating layer pool2
I0523 08:17:55.111295  3513 net.cpp:106] Creating Layer pool2
I0523 08:17:55.111305  3513 net.cpp:454] pool2 <- conv2
I0523 08:17:55.111318  3513 net.cpp:411] pool2 -> pool2
I0523 08:17:55.111390  3513 net.cpp:150] Setting up pool2
I0523 08:17:55.111403  3513 net.cpp:157] Top shape: 50 20 27 46 (1242000)
I0523 08:17:55.111413  3513 net.cpp:165] Memory required for data: 60670600
I0523 08:17:55.111423  3513 layer_factory.hpp:77] Creating layer conv3
I0523 08:17:55.111440  3513 net.cpp:106] Creating Layer conv3
I0523 08:17:55.111450  3513 net.cpp:454] conv3 <- pool2
I0523 08:17:55.111464  3513 net.cpp:411] conv3 -> conv3
I0523 08:17:55.113445  3513 net.cpp:150] Setting up conv3
I0523 08:17:55.113468  3513 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 08:17:55.113478  3513 net.cpp:165] Memory required for data: 66091400
I0523 08:17:55.113509  3513 layer_factory.hpp:77] Creating layer relu3
I0523 08:17:55.113523  3513 net.cpp:106] Creating Layer relu3
I0523 08:17:55.113533  3513 net.cpp:454] relu3 <- conv3
I0523 08:17:55.113546  3513 net.cpp:397] relu3 -> conv3 (in-place)
I0523 08:17:55.114017  3513 net.cpp:150] Setting up relu3
I0523 08:17:55.114032  3513 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 08:17:55.114042  3513 net.cpp:165] Memory required for data: 71512200
I0523 08:17:55.114053  3513 layer_factory.hpp:77] Creating layer pool3
I0523 08:17:55.114065  3513 net.cpp:106] Creating Layer pool3
I0523 08:17:55.114074  3513 net.cpp:454] pool3 <- conv3
I0523 08:17:55.114089  3513 net.cpp:411] pool3 -> pool3
I0523 08:17:55.114159  3513 net.cpp:150] Setting up pool3
I0523 08:17:55.114172  3513 net.cpp:157] Top shape: 50 28 11 44 (677600)
I0523 08:17:55.114182  3513 net.cpp:165] Memory required for data: 74222600
I0523 08:17:55.114192  3513 layer_factory.hpp:77] Creating layer conv4
I0523 08:17:55.114207  3513 net.cpp:106] Creating Layer conv4
I0523 08:17:55.114218  3513 net.cpp:454] conv4 <- pool3
I0523 08:17:55.114233  3513 net.cpp:411] conv4 -> conv4
I0523 08:17:55.116297  3513 net.cpp:150] Setting up conv4
I0523 08:17:55.116313  3513 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 08:17:55.116328  3513 net.cpp:165] Memory required for data: 76037000
I0523 08:17:55.116344  3513 layer_factory.hpp:77] Creating layer relu4
I0523 08:17:55.116358  3513 net.cpp:106] Creating Layer relu4
I0523 08:17:55.116369  3513 net.cpp:454] relu4 <- conv4
I0523 08:17:55.116381  3513 net.cpp:397] relu4 -> conv4 (in-place)
I0523 08:17:55.116852  3513 net.cpp:150] Setting up relu4
I0523 08:17:55.116869  3513 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 08:17:55.116879  3513 net.cpp:165] Memory required for data: 77851400
I0523 08:17:55.116889  3513 layer_factory.hpp:77] Creating layer pool4
I0523 08:17:55.116902  3513 net.cpp:106] Creating Layer pool4
I0523 08:17:55.116912  3513 net.cpp:454] pool4 <- conv4
I0523 08:17:55.116925  3513 net.cpp:411] pool4 -> pool4
I0523 08:17:55.116997  3513 net.cpp:150] Setting up pool4
I0523 08:17:55.117010  3513 net.cpp:157] Top shape: 50 36 3 42 (226800)
I0523 08:17:55.117019  3513 net.cpp:165] Memory required for data: 78758600
I0523 08:17:55.117029  3513 layer_factory.hpp:77] Creating layer ip1
I0523 08:17:55.117043  3513 net.cpp:106] Creating Layer ip1
I0523 08:17:55.117053  3513 net.cpp:454] ip1 <- pool4
I0523 08:17:55.117066  3513 net.cpp:411] ip1 -> ip1
I0523 08:17:55.132519  3513 net.cpp:150] Setting up ip1
I0523 08:17:55.132542  3513 net.cpp:157] Top shape: 50 196 (9800)
I0523 08:17:55.132557  3513 net.cpp:165] Memory required for data: 78797800
I0523 08:17:55.132581  3513 layer_factory.hpp:77] Creating layer relu5
I0523 08:17:55.132596  3513 net.cpp:106] Creating Layer relu5
I0523 08:17:55.132607  3513 net.cpp:454] relu5 <- ip1
I0523 08:17:55.132621  3513 net.cpp:397] relu5 -> ip1 (in-place)
I0523 08:17:55.132968  3513 net.cpp:150] Setting up relu5
I0523 08:17:55.132982  3513 net.cpp:157] Top shape: 50 196 (9800)
I0523 08:17:55.132992  3513 net.cpp:165] Memory required for data: 78837000
I0523 08:17:55.133002  3513 layer_factory.hpp:77] Creating layer drop1
I0523 08:17:55.133021  3513 net.cpp:106] Creating Layer drop1
I0523 08:17:55.133031  3513 net.cpp:454] drop1 <- ip1
I0523 08:17:55.133044  3513 net.cpp:397] drop1 -> ip1 (in-place)
I0523 08:17:55.133090  3513 net.cpp:150] Setting up drop1
I0523 08:17:55.133102  3513 net.cpp:157] Top shape: 50 196 (9800)
I0523 08:17:55.133112  3513 net.cpp:165] Memory required for data: 78876200
I0523 08:17:55.133121  3513 layer_factory.hpp:77] Creating layer ip2
I0523 08:17:55.133136  3513 net.cpp:106] Creating Layer ip2
I0523 08:17:55.133147  3513 net.cpp:454] ip2 <- ip1
I0523 08:17:55.133159  3513 net.cpp:411] ip2 -> ip2
I0523 08:17:55.133636  3513 net.cpp:150] Setting up ip2
I0523 08:17:55.133651  3513 net.cpp:157] Top shape: 50 98 (4900)
I0523 08:17:55.133659  3513 net.cpp:165] Memory required for data: 78895800
I0523 08:17:55.133676  3513 layer_factory.hpp:77] Creating layer relu6
I0523 08:17:55.133700  3513 net.cpp:106] Creating Layer relu6
I0523 08:17:55.133710  3513 net.cpp:454] relu6 <- ip2
I0523 08:17:55.133724  3513 net.cpp:397] relu6 -> ip2 (in-place)
I0523 08:17:55.134260  3513 net.cpp:150] Setting up relu6
I0523 08:17:55.134284  3513 net.cpp:157] Top shape: 50 98 (4900)
I0523 08:17:55.134294  3513 net.cpp:165] Memory required for data: 78915400
I0523 08:17:55.134304  3513 layer_factory.hpp:77] Creating layer drop2
I0523 08:17:55.134316  3513 net.cpp:106] Creating Layer drop2
I0523 08:17:55.134326  3513 net.cpp:454] drop2 <- ip2
I0523 08:17:55.134340  3513 net.cpp:397] drop2 -> ip2 (in-place)
I0523 08:17:55.134383  3513 net.cpp:150] Setting up drop2
I0523 08:17:55.134397  3513 net.cpp:157] Top shape: 50 98 (4900)
I0523 08:17:55.134407  3513 net.cpp:165] Memory required for data: 78935000
I0523 08:17:55.134415  3513 layer_factory.hpp:77] Creating layer ip3
I0523 08:17:55.134430  3513 net.cpp:106] Creating Layer ip3
I0523 08:17:55.134440  3513 net.cpp:454] ip3 <- ip2
I0523 08:17:55.134454  3513 net.cpp:411] ip3 -> ip3
I0523 08:17:55.134673  3513 net.cpp:150] Setting up ip3
I0523 08:17:55.134687  3513 net.cpp:157] Top shape: 50 11 (550)
I0523 08:17:55.134697  3513 net.cpp:165] Memory required for data: 78937200
I0523 08:17:55.134712  3513 layer_factory.hpp:77] Creating layer drop3
I0523 08:17:55.134726  3513 net.cpp:106] Creating Layer drop3
I0523 08:17:55.134734  3513 net.cpp:454] drop3 <- ip3
I0523 08:17:55.134747  3513 net.cpp:397] drop3 -> ip3 (in-place)
I0523 08:17:55.134788  3513 net.cpp:150] Setting up drop3
I0523 08:17:55.134801  3513 net.cpp:157] Top shape: 50 11 (550)
I0523 08:17:55.134811  3513 net.cpp:165] Memory required for data: 78939400
I0523 08:17:55.134820  3513 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 08:17:55.134834  3513 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 08:17:55.134843  3513 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 08:17:55.134856  3513 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 08:17:55.134871  3513 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 08:17:55.134943  3513 net.cpp:150] Setting up ip3_drop3_0_split
I0523 08:17:55.134956  3513 net.cpp:157] Top shape: 50 11 (550)
I0523 08:17:55.134968  3513 net.cpp:157] Top shape: 50 11 (550)
I0523 08:17:55.134979  3513 net.cpp:165] Memory required for data: 78943800
I0523 08:17:55.134989  3513 layer_factory.hpp:77] Creating layer accuracy
I0523 08:17:55.135010  3513 net.cpp:106] Creating Layer accuracy
I0523 08:17:55.135020  3513 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 08:17:55.135031  3513 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 08:17:55.135045  3513 net.cpp:411] accuracy -> accuracy
I0523 08:17:55.135068  3513 net.cpp:150] Setting up accuracy
I0523 08:17:55.135082  3513 net.cpp:157] Top shape: (1)
I0523 08:17:55.135090  3513 net.cpp:165] Memory required for data: 78943804
I0523 08:17:55.135100  3513 layer_factory.hpp:77] Creating layer loss
I0523 08:17:55.135113  3513 net.cpp:106] Creating Layer loss
I0523 08:17:55.135123  3513 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 08:17:55.135134  3513 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 08:17:55.135148  3513 net.cpp:411] loss -> loss
I0523 08:17:55.135165  3513 layer_factory.hpp:77] Creating layer loss
I0523 08:17:55.135648  3513 net.cpp:150] Setting up loss
I0523 08:17:55.135663  3513 net.cpp:157] Top shape: (1)
I0523 08:17:55.135671  3513 net.cpp:160]     with loss weight 1
I0523 08:17:55.135691  3513 net.cpp:165] Memory required for data: 78943808
I0523 08:17:55.135702  3513 net.cpp:226] loss needs backward computation.
I0523 08:17:55.135713  3513 net.cpp:228] accuracy does not need backward computation.
I0523 08:17:55.135725  3513 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 08:17:55.135735  3513 net.cpp:226] drop3 needs backward computation.
I0523 08:17:55.135746  3513 net.cpp:226] ip3 needs backward computation.
I0523 08:17:55.135756  3513 net.cpp:226] drop2 needs backward computation.
I0523 08:17:55.135766  3513 net.cpp:226] relu6 needs backward computation.
I0523 08:17:55.135784  3513 net.cpp:226] ip2 needs backward computation.
I0523 08:17:55.135794  3513 net.cpp:226] drop1 needs backward computation.
I0523 08:17:55.135803  3513 net.cpp:226] relu5 needs backward computation.
I0523 08:17:55.135820  3513 net.cpp:226] ip1 needs backward computation.
I0523 08:17:55.135831  3513 net.cpp:226] pool4 needs backward computation.
I0523 08:17:55.135841  3513 net.cpp:226] relu4 needs backward computation.
I0523 08:17:55.135851  3513 net.cpp:226] conv4 needs backward computation.
I0523 08:17:55.135862  3513 net.cpp:226] pool3 needs backward computation.
I0523 08:17:55.135874  3513 net.cpp:226] relu3 needs backward computation.
I0523 08:17:55.135884  3513 net.cpp:226] conv3 needs backward computation.
I0523 08:17:55.135893  3513 net.cpp:226] pool2 needs backward computation.
I0523 08:17:55.135903  3513 net.cpp:226] relu2 needs backward computation.
I0523 08:17:55.135913  3513 net.cpp:226] conv2 needs backward computation.
I0523 08:17:55.135923  3513 net.cpp:226] pool1 needs backward computation.
I0523 08:17:55.135934  3513 net.cpp:226] relu1 needs backward computation.
I0523 08:17:55.135943  3513 net.cpp:226] conv1 needs backward computation.
I0523 08:17:55.135956  3513 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 08:17:55.135967  3513 net.cpp:228] data_hdf5 does not need backward computation.
I0523 08:17:55.135977  3513 net.cpp:270] This network produces output accuracy
I0523 08:17:55.135987  3513 net.cpp:270] This network produces output loss
I0523 08:17:55.136016  3513 net.cpp:283] Network initialization done.
I0523 08:17:55.136150  3513 solver.cpp:60] Solver scaffolding done.
I0523 08:17:55.137280  3513 caffe.cpp:212] Starting Optimization
I0523 08:17:55.137300  3513 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 08:17:55.137312  3513 solver.cpp:289] Learning Rate Policy: fixed
I0523 08:17:55.138535  3513 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 08:18:43.858544  3513 solver.cpp:409]     Test net output #0: accuracy = 0.104007
I0523 08:18:43.858710  3513 solver.cpp:409]     Test net output #1: loss = 2.39648 (* 1 = 2.39648 loss)
I0523 08:18:43.882941  3513 solver.cpp:237] Iteration 0, loss = 2.39137
I0523 08:18:43.882977  3513 solver.cpp:253]     Train net output #0: loss = 2.39137 (* 1 = 2.39137 loss)
I0523 08:18:43.882995  3513 sgd_solver.cpp:106] Iteration 0, lr = 0.004
I0523 08:18:53.172168  3513 solver.cpp:237] Iteration 300, loss = 2.26168
I0523 08:18:53.172214  3513 solver.cpp:253]     Train net output #0: loss = 2.26168 (* 1 = 2.26168 loss)
I0523 08:18:53.172233  3513 sgd_solver.cpp:106] Iteration 300, lr = 0.004
I0523 08:19:02.470779  3513 solver.cpp:237] Iteration 600, loss = 2.03101
I0523 08:19:02.470815  3513 solver.cpp:253]     Train net output #0: loss = 2.03101 (* 1 = 2.03101 loss)
I0523 08:19:02.470831  3513 sgd_solver.cpp:106] Iteration 600, lr = 0.004
I0523 08:19:11.763010  3513 solver.cpp:237] Iteration 900, loss = 1.74532
I0523 08:19:11.763044  3513 solver.cpp:253]     Train net output #0: loss = 1.74532 (* 1 = 1.74532 loss)
I0523 08:19:11.763061  3513 sgd_solver.cpp:106] Iteration 900, lr = 0.004
I0523 08:19:21.061328  3513 solver.cpp:237] Iteration 1200, loss = 1.69297
I0523 08:19:21.061498  3513 solver.cpp:253]     Train net output #0: loss = 1.69297 (* 1 = 1.69297 loss)
I0523 08:19:21.061512  3513 sgd_solver.cpp:106] Iteration 1200, lr = 0.004
I0523 08:19:30.355070  3513 solver.cpp:237] Iteration 1500, loss = 1.81797
I0523 08:19:30.355105  3513 solver.cpp:253]     Train net output #0: loss = 1.81797 (* 1 = 1.81797 loss)
I0523 08:19:30.355123  3513 sgd_solver.cpp:106] Iteration 1500, lr = 0.004
I0523 08:19:39.650760  3513 solver.cpp:237] Iteration 1800, loss = 1.57525
I0523 08:19:39.650811  3513 solver.cpp:253]     Train net output #0: loss = 1.57525 (* 1 = 1.57525 loss)
I0523 08:19:39.650828  3513 sgd_solver.cpp:106] Iteration 1800, lr = 0.004
I0523 08:20:11.076093  3513 solver.cpp:237] Iteration 2100, loss = 1.51645
I0523 08:20:11.076259  3513 solver.cpp:253]     Train net output #0: loss = 1.51645 (* 1 = 1.51645 loss)
I0523 08:20:11.076274  3513 sgd_solver.cpp:106] Iteration 2100, lr = 0.004
I0523 08:20:20.370403  3513 solver.cpp:237] Iteration 2400, loss = 1.46088
I0523 08:20:20.370437  3513 solver.cpp:253]     Train net output #0: loss = 1.46088 (* 1 = 1.46088 loss)
I0523 08:20:20.370455  3513 sgd_solver.cpp:106] Iteration 2400, lr = 0.004
I0523 08:20:29.673672  3513 solver.cpp:237] Iteration 2700, loss = 1.47098
I0523 08:20:29.673722  3513 solver.cpp:253]     Train net output #0: loss = 1.47098 (* 1 = 1.47098 loss)
I0523 08:20:29.673739  3513 sgd_solver.cpp:106] Iteration 2700, lr = 0.004
I0523 08:20:38.941591  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_3000.caffemodel
I0523 08:20:39.004943  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_3000.solverstate
I0523 08:20:39.040305  3513 solver.cpp:237] Iteration 3000, loss = 1.4996
I0523 08:20:39.040354  3513 solver.cpp:253]     Train net output #0: loss = 1.4996 (* 1 = 1.4996 loss)
I0523 08:20:39.040369  3513 sgd_solver.cpp:106] Iteration 3000, lr = 0.004
I0523 08:20:48.342404  3513 solver.cpp:237] Iteration 3300, loss = 1.64888
I0523 08:20:48.342546  3513 solver.cpp:253]     Train net output #0: loss = 1.64888 (* 1 = 1.64888 loss)
I0523 08:20:48.342560  3513 sgd_solver.cpp:106] Iteration 3300, lr = 0.004
I0523 08:20:57.639292  3513 solver.cpp:237] Iteration 3600, loss = 1.50134
I0523 08:20:57.639334  3513 solver.cpp:253]     Train net output #0: loss = 1.50134 (* 1 = 1.50134 loss)
I0523 08:20:57.639355  3513 sgd_solver.cpp:106] Iteration 3600, lr = 0.004
I0523 08:21:06.940433  3513 solver.cpp:237] Iteration 3900, loss = 1.2993
I0523 08:21:06.940467  3513 solver.cpp:253]     Train net output #0: loss = 1.2993 (* 1 = 1.2993 loss)
I0523 08:21:06.940484  3513 sgd_solver.cpp:106] Iteration 3900, lr = 0.004
I0523 08:21:38.395167  3513 solver.cpp:237] Iteration 4200, loss = 1.20823
I0523 08:21:38.395329  3513 solver.cpp:253]     Train net output #0: loss = 1.20823 (* 1 = 1.20823 loss)
I0523 08:21:38.395344  3513 sgd_solver.cpp:106] Iteration 4200, lr = 0.004
I0523 08:21:47.698459  3513 solver.cpp:237] Iteration 4500, loss = 1.35214
I0523 08:21:47.698503  3513 solver.cpp:253]     Train net output #0: loss = 1.35214 (* 1 = 1.35214 loss)
I0523 08:21:47.698520  3513 sgd_solver.cpp:106] Iteration 4500, lr = 0.004
I0523 08:21:56.995239  3513 solver.cpp:237] Iteration 4800, loss = 1.53423
I0523 08:21:56.995275  3513 solver.cpp:253]     Train net output #0: loss = 1.53423 (* 1 = 1.53423 loss)
I0523 08:21:56.995290  3513 sgd_solver.cpp:106] Iteration 4800, lr = 0.004
I0523 08:22:06.294776  3513 solver.cpp:237] Iteration 5100, loss = 1.37192
I0523 08:22:06.294812  3513 solver.cpp:253]     Train net output #0: loss = 1.37192 (* 1 = 1.37192 loss)
I0523 08:22:06.294828  3513 sgd_solver.cpp:106] Iteration 5100, lr = 0.004
I0523 08:22:15.590941  3513 solver.cpp:237] Iteration 5400, loss = 1.34835
I0523 08:22:15.591101  3513 solver.cpp:253]     Train net output #0: loss = 1.34835 (* 1 = 1.34835 loss)
I0523 08:22:15.591115  3513 sgd_solver.cpp:106] Iteration 5400, lr = 0.004
I0523 08:22:24.892971  3513 solver.cpp:237] Iteration 5700, loss = 1.54948
I0523 08:22:24.893005  3513 solver.cpp:253]     Train net output #0: loss = 1.54948 (* 1 = 1.54948 loss)
I0523 08:22:24.893023  3513 sgd_solver.cpp:106] Iteration 5700, lr = 0.004
I0523 08:22:34.165235  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_6000.caffemodel
I0523 08:22:34.224589  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_6000.solverstate
I0523 08:22:34.249923  3513 solver.cpp:341] Iteration 6000, Testing net (#0)
I0523 08:23:22.025113  3513 solver.cpp:409]     Test net output #0: accuracy = 0.824916
I0523 08:23:22.025281  3513 solver.cpp:409]     Test net output #1: loss = 0.616886 (* 1 = 0.616886 loss)
I0523 08:23:44.189582  3513 solver.cpp:237] Iteration 6000, loss = 1.17657
I0523 08:23:44.189640  3513 solver.cpp:253]     Train net output #0: loss = 1.17657 (* 1 = 1.17657 loss)
I0523 08:23:44.189654  3513 sgd_solver.cpp:106] Iteration 6000, lr = 0.004
I0523 08:23:53.479025  3513 solver.cpp:237] Iteration 6300, loss = 1.46484
I0523 08:23:53.479177  3513 solver.cpp:253]     Train net output #0: loss = 1.46484 (* 1 = 1.46484 loss)
I0523 08:23:53.479192  3513 sgd_solver.cpp:106] Iteration 6300, lr = 0.004
I0523 08:24:02.767879  3513 solver.cpp:237] Iteration 6600, loss = 1.52954
I0523 08:24:02.767913  3513 solver.cpp:253]     Train net output #0: loss = 1.52954 (* 1 = 1.52954 loss)
I0523 08:24:02.767930  3513 sgd_solver.cpp:106] Iteration 6600, lr = 0.004
I0523 08:24:12.057705  3513 solver.cpp:237] Iteration 6900, loss = 1.34827
I0523 08:24:12.057741  3513 solver.cpp:253]     Train net output #0: loss = 1.34827 (* 1 = 1.34827 loss)
I0523 08:24:12.057756  3513 sgd_solver.cpp:106] Iteration 6900, lr = 0.004
I0523 08:24:21.349215  3513 solver.cpp:237] Iteration 7200, loss = 1.41391
I0523 08:24:21.349261  3513 solver.cpp:253]     Train net output #0: loss = 1.41391 (* 1 = 1.41391 loss)
I0523 08:24:21.349278  3513 sgd_solver.cpp:106] Iteration 7200, lr = 0.004
I0523 08:24:30.639818  3513 solver.cpp:237] Iteration 7500, loss = 1.45588
I0523 08:24:30.639957  3513 solver.cpp:253]     Train net output #0: loss = 1.45588 (* 1 = 1.45588 loss)
I0523 08:24:30.639971  3513 sgd_solver.cpp:106] Iteration 7500, lr = 0.004
I0523 08:24:39.932981  3513 solver.cpp:237] Iteration 7800, loss = 1.43334
I0523 08:24:39.933032  3513 solver.cpp:253]     Train net output #0: loss = 1.43334 (* 1 = 1.43334 loss)
I0523 08:24:39.933048  3513 sgd_solver.cpp:106] Iteration 7800, lr = 0.004
I0523 08:25:11.407030  3513 solver.cpp:237] Iteration 8100, loss = 1.41565
I0523 08:25:11.407201  3513 solver.cpp:253]     Train net output #0: loss = 1.41565 (* 1 = 1.41565 loss)
I0523 08:25:11.407217  3513 sgd_solver.cpp:106] Iteration 8100, lr = 0.004
I0523 08:25:20.699947  3513 solver.cpp:237] Iteration 8400, loss = 1.30541
I0523 08:25:20.699982  3513 solver.cpp:253]     Train net output #0: loss = 1.30541 (* 1 = 1.30541 loss)
I0523 08:25:20.699998  3513 sgd_solver.cpp:106] Iteration 8400, lr = 0.004
I0523 08:25:29.992050  3513 solver.cpp:237] Iteration 8700, loss = 1.43928
I0523 08:25:29.992094  3513 solver.cpp:253]     Train net output #0: loss = 1.43928 (* 1 = 1.43928 loss)
I0523 08:25:29.992113  3513 sgd_solver.cpp:106] Iteration 8700, lr = 0.004
I0523 08:25:39.252914  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_9000.caffemodel
I0523 08:25:39.314327  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_9000.solverstate
I0523 08:25:39.351475  3513 solver.cpp:237] Iteration 9000, loss = 1.13573
I0523 08:25:39.351526  3513 solver.cpp:253]     Train net output #0: loss = 1.13573 (* 1 = 1.13573 loss)
I0523 08:25:39.351548  3513 sgd_solver.cpp:106] Iteration 9000, lr = 0.004
I0523 08:25:48.639380  3513 solver.cpp:237] Iteration 9300, loss = 1.23664
I0523 08:25:48.639535  3513 solver.cpp:253]     Train net output #0: loss = 1.23664 (* 1 = 1.23664 loss)
I0523 08:25:48.639549  3513 sgd_solver.cpp:106] Iteration 9300, lr = 0.004
I0523 08:25:57.927250  3513 solver.cpp:237] Iteration 9600, loss = 1.40762
I0523 08:25:57.927296  3513 solver.cpp:253]     Train net output #0: loss = 1.40762 (* 1 = 1.40762 loss)
I0523 08:25:57.927317  3513 sgd_solver.cpp:106] Iteration 9600, lr = 0.004
I0523 08:26:07.219282  3513 solver.cpp:237] Iteration 9900, loss = 1.32735
I0523 08:26:07.219318  3513 solver.cpp:253]     Train net output #0: loss = 1.32735 (* 1 = 1.32735 loss)
I0523 08:26:07.219334  3513 sgd_solver.cpp:106] Iteration 9900, lr = 0.004
I0523 08:26:38.682389  3513 solver.cpp:237] Iteration 10200, loss = 1.44656
I0523 08:26:38.682555  3513 solver.cpp:253]     Train net output #0: loss = 1.44656 (* 1 = 1.44656 loss)
I0523 08:26:38.682570  3513 sgd_solver.cpp:106] Iteration 10200, lr = 0.004
I0523 08:26:47.970386  3513 solver.cpp:237] Iteration 10500, loss = 1.54429
I0523 08:26:47.970437  3513 solver.cpp:253]     Train net output #0: loss = 1.54429 (* 1 = 1.54429 loss)
I0523 08:26:47.970453  3513 sgd_solver.cpp:106] Iteration 10500, lr = 0.004
I0523 08:26:57.262342  3513 solver.cpp:237] Iteration 10800, loss = 1.18953
I0523 08:26:57.262378  3513 solver.cpp:253]     Train net output #0: loss = 1.18953 (* 1 = 1.18953 loss)
I0523 08:26:57.262392  3513 sgd_solver.cpp:106] Iteration 10800, lr = 0.004
I0523 08:27:06.552402  3513 solver.cpp:237] Iteration 11100, loss = 1.18612
I0523 08:27:06.552438  3513 solver.cpp:253]     Train net output #0: loss = 1.18612 (* 1 = 1.18612 loss)
I0523 08:27:06.552451  3513 sgd_solver.cpp:106] Iteration 11100, lr = 0.004
I0523 08:27:15.841361  3513 solver.cpp:237] Iteration 11400, loss = 1.42306
I0523 08:27:15.841516  3513 solver.cpp:253]     Train net output #0: loss = 1.42306 (* 1 = 1.42306 loss)
I0523 08:27:15.841529  3513 sgd_solver.cpp:106] Iteration 11400, lr = 0.004
I0523 08:27:25.129925  3513 solver.cpp:237] Iteration 11700, loss = 0.871068
I0523 08:27:25.129961  3513 solver.cpp:253]     Train net output #0: loss = 0.871068 (* 1 = 0.871068 loss)
I0523 08:27:25.129974  3513 sgd_solver.cpp:106] Iteration 11700, lr = 0.004
I0523 08:27:34.388166  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_12000.caffemodel
I0523 08:27:34.449633  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_12000.solverstate
I0523 08:27:34.476773  3513 solver.cpp:341] Iteration 12000, Testing net (#0)
I0523 08:28:43.139461  3513 solver.cpp:409]     Test net output #0: accuracy = 0.854166
I0523 08:28:43.139622  3513 solver.cpp:409]     Test net output #1: loss = 0.488614 (* 1 = 0.488614 loss)
I0523 08:29:05.315831  3513 solver.cpp:237] Iteration 12000, loss = 1.09673
I0523 08:29:05.315889  3513 solver.cpp:253]     Train net output #0: loss = 1.09673 (* 1 = 1.09673 loss)
I0523 08:29:05.315907  3513 sgd_solver.cpp:106] Iteration 12000, lr = 0.004
I0523 08:29:14.622324  3513 solver.cpp:237] Iteration 12300, loss = 1.09194
I0523 08:29:14.622499  3513 solver.cpp:253]     Train net output #0: loss = 1.09194 (* 1 = 1.09194 loss)
I0523 08:29:14.622514  3513 sgd_solver.cpp:106] Iteration 12300, lr = 0.004
I0523 08:29:23.929177  3513 solver.cpp:237] Iteration 12600, loss = 1.33461
I0523 08:29:23.929213  3513 solver.cpp:253]     Train net output #0: loss = 1.33461 (* 1 = 1.33461 loss)
I0523 08:29:23.929229  3513 sgd_solver.cpp:106] Iteration 12600, lr = 0.004
I0523 08:29:33.235679  3513 solver.cpp:237] Iteration 12900, loss = 1.21886
I0523 08:29:33.235714  3513 solver.cpp:253]     Train net output #0: loss = 1.21886 (* 1 = 1.21886 loss)
I0523 08:29:33.235731  3513 sgd_solver.cpp:106] Iteration 12900, lr = 0.004
I0523 08:29:42.543695  3513 solver.cpp:237] Iteration 13200, loss = 1.49472
I0523 08:29:42.543740  3513 solver.cpp:253]     Train net output #0: loss = 1.49472 (* 1 = 1.49472 loss)
I0523 08:29:42.543759  3513 sgd_solver.cpp:106] Iteration 13200, lr = 0.004
I0523 08:29:51.851498  3513 solver.cpp:237] Iteration 13500, loss = 1.38628
I0523 08:29:51.851637  3513 solver.cpp:253]     Train net output #0: loss = 1.38628 (* 1 = 1.38628 loss)
I0523 08:29:51.851650  3513 sgd_solver.cpp:106] Iteration 13500, lr = 0.004
I0523 08:30:01.156235  3513 solver.cpp:237] Iteration 13800, loss = 1.10788
I0523 08:30:01.156270  3513 solver.cpp:253]     Train net output #0: loss = 1.10788 (* 1 = 1.10788 loss)
I0523 08:30:01.156285  3513 sgd_solver.cpp:106] Iteration 13800, lr = 0.004
I0523 08:30:32.625473  3513 solver.cpp:237] Iteration 14100, loss = 1.4663
I0523 08:30:32.625638  3513 solver.cpp:253]     Train net output #0: loss = 1.4663 (* 1 = 1.4663 loss)
I0523 08:30:32.625653  3513 sgd_solver.cpp:106] Iteration 14100, lr = 0.004
I0523 08:30:41.931581  3513 solver.cpp:237] Iteration 14400, loss = 1.11536
I0523 08:30:41.931615  3513 solver.cpp:253]     Train net output #0: loss = 1.11536 (* 1 = 1.11536 loss)
I0523 08:30:41.931632  3513 sgd_solver.cpp:106] Iteration 14400, lr = 0.004
I0523 08:30:51.239615  3513 solver.cpp:237] Iteration 14700, loss = 1.23288
I0523 08:30:51.239650  3513 solver.cpp:253]     Train net output #0: loss = 1.23288 (* 1 = 1.23288 loss)
I0523 08:30:51.239667  3513 sgd_solver.cpp:106] Iteration 14700, lr = 0.004
I0523 08:31:00.515671  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_15000.caffemodel
I0523 08:31:00.577177  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_15000.solverstate
I0523 08:31:00.614437  3513 solver.cpp:237] Iteration 15000, loss = 1.21577
I0523 08:31:00.614487  3513 solver.cpp:253]     Train net output #0: loss = 1.21577 (* 1 = 1.21577 loss)
I0523 08:31:00.614505  3513 sgd_solver.cpp:106] Iteration 15000, lr = 0.004
I0523 08:31:09.917140  3513 solver.cpp:237] Iteration 15300, loss = 1.35202
I0523 08:31:09.917286  3513 solver.cpp:253]     Train net output #0: loss = 1.35202 (* 1 = 1.35202 loss)
I0523 08:31:09.917300  3513 sgd_solver.cpp:106] Iteration 15300, lr = 0.004
I0523 08:31:19.228601  3513 solver.cpp:237] Iteration 15600, loss = 0.946612
I0523 08:31:19.228657  3513 solver.cpp:253]     Train net output #0: loss = 0.946611 (* 1 = 0.946611 loss)
I0523 08:31:19.228673  3513 sgd_solver.cpp:106] Iteration 15600, lr = 0.004
I0523 08:31:28.537081  3513 solver.cpp:237] Iteration 15900, loss = 1.35498
I0523 08:31:28.537112  3513 solver.cpp:253]     Train net output #0: loss = 1.35498 (* 1 = 1.35498 loss)
I0523 08:31:28.537133  3513 sgd_solver.cpp:106] Iteration 15900, lr = 0.004
I0523 08:32:00.019906  3513 solver.cpp:237] Iteration 16200, loss = 1.88089
I0523 08:32:00.020078  3513 solver.cpp:253]     Train net output #0: loss = 1.88089 (* 1 = 1.88089 loss)
I0523 08:32:00.020093  3513 sgd_solver.cpp:106] Iteration 16200, lr = 0.004
I0523 08:32:09.327256  3513 solver.cpp:237] Iteration 16500, loss = 0.987508
I0523 08:32:09.327308  3513 solver.cpp:253]     Train net output #0: loss = 0.987508 (* 1 = 0.987508 loss)
I0523 08:32:09.327325  3513 sgd_solver.cpp:106] Iteration 16500, lr = 0.004
I0523 08:32:18.636365  3513 solver.cpp:237] Iteration 16800, loss = 1.00096
I0523 08:32:18.636400  3513 solver.cpp:253]     Train net output #0: loss = 1.00096 (* 1 = 1.00096 loss)
I0523 08:32:18.636418  3513 sgd_solver.cpp:106] Iteration 16800, lr = 0.004
I0523 08:32:27.942888  3513 solver.cpp:237] Iteration 17100, loss = 1.41314
I0523 08:32:27.942922  3513 solver.cpp:253]     Train net output #0: loss = 1.41314 (* 1 = 1.41314 loss)
I0523 08:32:27.942939  3513 sgd_solver.cpp:106] Iteration 17100, lr = 0.004
I0523 08:32:37.251384  3513 solver.cpp:237] Iteration 17400, loss = 1.04549
I0523 08:32:37.251544  3513 solver.cpp:253]     Train net output #0: loss = 1.04549 (* 1 = 1.04549 loss)
I0523 08:32:37.251559  3513 sgd_solver.cpp:106] Iteration 17400, lr = 0.004
I0523 08:32:46.560360  3513 solver.cpp:237] Iteration 17700, loss = 0.835985
I0523 08:32:46.560396  3513 solver.cpp:253]     Train net output #0: loss = 0.835985 (* 1 = 0.835985 loss)
I0523 08:32:46.560412  3513 sgd_solver.cpp:106] Iteration 17700, lr = 0.004
I0523 08:32:55.837098  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_18000.caffemodel
I0523 08:32:55.896545  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_18000.solverstate
I0523 08:32:55.922739  3513 solver.cpp:341] Iteration 18000, Testing net (#0)
I0523 08:33:43.350647  3513 solver.cpp:409]     Test net output #0: accuracy = 0.868458
I0523 08:33:43.350816  3513 solver.cpp:409]     Test net output #1: loss = 0.439269 (* 1 = 0.439269 loss)
I0523 08:34:05.561667  3513 solver.cpp:237] Iteration 18000, loss = 1.07127
I0523 08:34:05.561724  3513 solver.cpp:253]     Train net output #0: loss = 1.07127 (* 1 = 1.07127 loss)
I0523 08:34:05.561739  3513 sgd_solver.cpp:106] Iteration 18000, lr = 0.004
I0523 08:34:14.851279  3513 solver.cpp:237] Iteration 18300, loss = 1.10528
I0523 08:34:14.851434  3513 solver.cpp:253]     Train net output #0: loss = 1.10528 (* 1 = 1.10528 loss)
I0523 08:34:14.851449  3513 sgd_solver.cpp:106] Iteration 18300, lr = 0.004
I0523 08:34:24.133558  3513 solver.cpp:237] Iteration 18600, loss = 1.17341
I0523 08:34:24.133592  3513 solver.cpp:253]     Train net output #0: loss = 1.17341 (* 1 = 1.17341 loss)
I0523 08:34:24.133610  3513 sgd_solver.cpp:106] Iteration 18600, lr = 0.004
I0523 08:34:33.419011  3513 solver.cpp:237] Iteration 18900, loss = 1.2854
I0523 08:34:33.419046  3513 solver.cpp:253]     Train net output #0: loss = 1.2854 (* 1 = 1.2854 loss)
I0523 08:34:33.419059  3513 sgd_solver.cpp:106] Iteration 18900, lr = 0.004
I0523 08:34:42.707134  3513 solver.cpp:237] Iteration 19200, loss = 1.36603
I0523 08:34:42.707175  3513 solver.cpp:253]     Train net output #0: loss = 1.36603 (* 1 = 1.36603 loss)
I0523 08:34:42.707195  3513 sgd_solver.cpp:106] Iteration 19200, lr = 0.004
I0523 08:34:51.995550  3513 solver.cpp:237] Iteration 19500, loss = 1.25024
I0523 08:34:51.995692  3513 solver.cpp:253]     Train net output #0: loss = 1.25024 (* 1 = 1.25024 loss)
I0523 08:34:51.995705  3513 sgd_solver.cpp:106] Iteration 19500, lr = 0.004
I0523 08:35:01.284940  3513 solver.cpp:237] Iteration 19800, loss = 1.13561
I0523 08:35:01.284976  3513 solver.cpp:253]     Train net output #0: loss = 1.13561 (* 1 = 1.13561 loss)
I0523 08:35:01.284991  3513 sgd_solver.cpp:106] Iteration 19800, lr = 0.004
I0523 08:35:32.807274  3513 solver.cpp:237] Iteration 20100, loss = 1.30924
I0523 08:35:32.807449  3513 solver.cpp:253]     Train net output #0: loss = 1.30924 (* 1 = 1.30924 loss)
I0523 08:35:32.807464  3513 sgd_solver.cpp:106] Iteration 20100, lr = 0.004
I0523 08:35:42.098970  3513 solver.cpp:237] Iteration 20400, loss = 1.21838
I0523 08:35:42.099004  3513 solver.cpp:253]     Train net output #0: loss = 1.21838 (* 1 = 1.21838 loss)
I0523 08:35:42.099020  3513 sgd_solver.cpp:106] Iteration 20400, lr = 0.004
I0523 08:35:51.386464  3513 solver.cpp:237] Iteration 20700, loss = 0.917052
I0523 08:35:51.386500  3513 solver.cpp:253]     Train net output #0: loss = 0.917052 (* 1 = 0.917052 loss)
I0523 08:35:51.386515  3513 sgd_solver.cpp:106] Iteration 20700, lr = 0.004
I0523 08:36:00.646119  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_21000.caffemodel
I0523 08:36:00.706104  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_21000.solverstate
I0523 08:36:00.742156  3513 solver.cpp:237] Iteration 21000, loss = 0.914689
I0523 08:36:00.742200  3513 solver.cpp:253]     Train net output #0: loss = 0.914689 (* 1 = 0.914689 loss)
I0523 08:36:00.742220  3513 sgd_solver.cpp:106] Iteration 21000, lr = 0.004
I0523 08:36:10.031167  3513 solver.cpp:237] Iteration 21300, loss = 1.14219
I0523 08:36:10.031313  3513 solver.cpp:253]     Train net output #0: loss = 1.14219 (* 1 = 1.14219 loss)
I0523 08:36:10.031327  3513 sgd_solver.cpp:106] Iteration 21300, lr = 0.004
I0523 08:36:19.316798  3513 solver.cpp:237] Iteration 21600, loss = 1.21592
I0523 08:36:19.316844  3513 solver.cpp:253]     Train net output #0: loss = 1.21592 (* 1 = 1.21592 loss)
I0523 08:36:19.316864  3513 sgd_solver.cpp:106] Iteration 21600, lr = 0.004
I0523 08:36:28.606564  3513 solver.cpp:237] Iteration 21900, loss = 1.36273
I0523 08:36:28.606598  3513 solver.cpp:253]     Train net output #0: loss = 1.36273 (* 1 = 1.36273 loss)
I0523 08:36:28.606614  3513 sgd_solver.cpp:106] Iteration 21900, lr = 0.004
I0523 08:37:00.103622  3513 solver.cpp:237] Iteration 22200, loss = 0.950094
I0523 08:37:00.103797  3513 solver.cpp:253]     Train net output #0: loss = 0.950094 (* 1 = 0.950094 loss)
I0523 08:37:00.103812  3513 sgd_solver.cpp:106] Iteration 22200, lr = 0.004
I0523 08:37:09.393187  3513 solver.cpp:237] Iteration 22500, loss = 1.30748
I0523 08:37:09.393229  3513 solver.cpp:253]     Train net output #0: loss = 1.30748 (* 1 = 1.30748 loss)
I0523 08:37:09.393244  3513 sgd_solver.cpp:106] Iteration 22500, lr = 0.004
I0523 08:37:18.680857  3513 solver.cpp:237] Iteration 22800, loss = 1.17277
I0523 08:37:18.680893  3513 solver.cpp:253]     Train net output #0: loss = 1.17277 (* 1 = 1.17277 loss)
I0523 08:37:18.680909  3513 sgd_solver.cpp:106] Iteration 22800, lr = 0.004
I0523 08:37:27.966398  3513 solver.cpp:237] Iteration 23100, loss = 1.32053
I0523 08:37:27.966434  3513 solver.cpp:253]     Train net output #0: loss = 1.32053 (* 1 = 1.32053 loss)
I0523 08:37:27.966449  3513 sgd_solver.cpp:106] Iteration 23100, lr = 0.004
I0523 08:37:37.258244  3513 solver.cpp:237] Iteration 23400, loss = 1.27096
I0523 08:37:37.258400  3513 solver.cpp:253]     Train net output #0: loss = 1.27096 (* 1 = 1.27096 loss)
I0523 08:37:37.258414  3513 sgd_solver.cpp:106] Iteration 23400, lr = 0.004
I0523 08:37:46.549830  3513 solver.cpp:237] Iteration 23700, loss = 1.16039
I0523 08:37:46.549865  3513 solver.cpp:253]     Train net output #0: loss = 1.16039 (* 1 = 1.16039 loss)
I0523 08:37:46.549883  3513 sgd_solver.cpp:106] Iteration 23700, lr = 0.004
I0523 08:37:55.806064  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_24000.caffemodel
I0523 08:37:55.865630  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_24000.solverstate
I0523 08:37:55.892087  3513 solver.cpp:341] Iteration 24000, Testing net (#0)
I0523 08:39:04.629731  3513 solver.cpp:409]     Test net output #0: accuracy = 0.875356
I0523 08:39:04.629911  3513 solver.cpp:409]     Test net output #1: loss = 0.401443 (* 1 = 0.401443 loss)
I0523 08:39:26.831838  3513 solver.cpp:237] Iteration 24000, loss = 1.30608
I0523 08:39:26.831895  3513 solver.cpp:253]     Train net output #0: loss = 1.30608 (* 1 = 1.30608 loss)
I0523 08:39:26.831912  3513 sgd_solver.cpp:106] Iteration 24000, lr = 0.004
I0523 08:39:36.134361  3513 solver.cpp:237] Iteration 24300, loss = 1.42086
I0523 08:39:36.134510  3513 solver.cpp:253]     Train net output #0: loss = 1.42086 (* 1 = 1.42086 loss)
I0523 08:39:36.134523  3513 sgd_solver.cpp:106] Iteration 24300, lr = 0.004
I0523 08:39:45.432920  3513 solver.cpp:237] Iteration 24600, loss = 1.27659
I0523 08:39:45.432965  3513 solver.cpp:253]     Train net output #0: loss = 1.27659 (* 1 = 1.27659 loss)
I0523 08:39:45.432982  3513 sgd_solver.cpp:106] Iteration 24600, lr = 0.004
I0523 08:39:54.732358  3513 solver.cpp:237] Iteration 24900, loss = 1.13673
I0523 08:39:54.732393  3513 solver.cpp:253]     Train net output #0: loss = 1.13673 (* 1 = 1.13673 loss)
I0523 08:39:54.732409  3513 sgd_solver.cpp:106] Iteration 24900, lr = 0.004
I0523 08:40:04.028703  3513 solver.cpp:237] Iteration 25200, loss = 1.08766
I0523 08:40:04.028754  3513 solver.cpp:253]     Train net output #0: loss = 1.08766 (* 1 = 1.08766 loss)
I0523 08:40:04.028770  3513 sgd_solver.cpp:106] Iteration 25200, lr = 0.004
I0523 08:40:13.325774  3513 solver.cpp:237] Iteration 25500, loss = 1.09288
I0523 08:40:13.325922  3513 solver.cpp:253]     Train net output #0: loss = 1.09288 (* 1 = 1.09288 loss)
I0523 08:40:13.325935  3513 sgd_solver.cpp:106] Iteration 25500, lr = 0.004
I0523 08:40:22.620960  3513 solver.cpp:237] Iteration 25800, loss = 1.09319
I0523 08:40:22.620995  3513 solver.cpp:253]     Train net output #0: loss = 1.09319 (* 1 = 1.09319 loss)
I0523 08:40:22.621011  3513 sgd_solver.cpp:106] Iteration 25800, lr = 0.004
I0523 08:40:54.131810  3513 solver.cpp:237] Iteration 26100, loss = 1.20573
I0523 08:40:54.131983  3513 solver.cpp:253]     Train net output #0: loss = 1.20573 (* 1 = 1.20573 loss)
I0523 08:40:54.131997  3513 sgd_solver.cpp:106] Iteration 26100, lr = 0.004
I0523 08:41:03.432253  3513 solver.cpp:237] Iteration 26400, loss = 1.44204
I0523 08:41:03.432288  3513 solver.cpp:253]     Train net output #0: loss = 1.44204 (* 1 = 1.44204 loss)
I0523 08:41:03.432302  3513 sgd_solver.cpp:106] Iteration 26400, lr = 0.004
I0523 08:41:12.728273  3513 solver.cpp:237] Iteration 26700, loss = 1.13283
I0523 08:41:12.728307  3513 solver.cpp:253]     Train net output #0: loss = 1.13283 (* 1 = 1.13283 loss)
I0523 08:41:12.728324  3513 sgd_solver.cpp:106] Iteration 26700, lr = 0.004
I0523 08:41:21.996384  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_27000.caffemodel
I0523 08:41:22.057734  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_27000.solverstate
I0523 08:41:22.095577  3513 solver.cpp:237] Iteration 27000, loss = 1.16439
I0523 08:41:22.095626  3513 solver.cpp:253]     Train net output #0: loss = 1.16439 (* 1 = 1.16439 loss)
I0523 08:41:22.095644  3513 sgd_solver.cpp:106] Iteration 27000, lr = 0.004
I0523 08:41:31.392173  3513 solver.cpp:237] Iteration 27300, loss = 1.1625
I0523 08:41:31.392323  3513 solver.cpp:253]     Train net output #0: loss = 1.1625 (* 1 = 1.1625 loss)
I0523 08:41:31.392336  3513 sgd_solver.cpp:106] Iteration 27300, lr = 0.004
I0523 08:41:40.691107  3513 solver.cpp:237] Iteration 27600, loss = 1.39859
I0523 08:41:40.691139  3513 solver.cpp:253]     Train net output #0: loss = 1.39859 (* 1 = 1.39859 loss)
I0523 08:41:40.691156  3513 sgd_solver.cpp:106] Iteration 27600, lr = 0.004
I0523 08:41:49.986232  3513 solver.cpp:237] Iteration 27900, loss = 1.03331
I0523 08:41:49.986286  3513 solver.cpp:253]     Train net output #0: loss = 1.03331 (* 1 = 1.03331 loss)
I0523 08:41:49.986300  3513 sgd_solver.cpp:106] Iteration 27900, lr = 0.004
I0523 08:42:21.515010  3513 solver.cpp:237] Iteration 28200, loss = 1.21432
I0523 08:42:21.515198  3513 solver.cpp:253]     Train net output #0: loss = 1.21432 (* 1 = 1.21432 loss)
I0523 08:42:21.515213  3513 sgd_solver.cpp:106] Iteration 28200, lr = 0.004
I0523 08:42:30.812242  3513 solver.cpp:237] Iteration 28500, loss = 1.36463
I0523 08:42:30.812276  3513 solver.cpp:253]     Train net output #0: loss = 1.36463 (* 1 = 1.36463 loss)
I0523 08:42:30.812294  3513 sgd_solver.cpp:106] Iteration 28500, lr = 0.004
I0523 08:42:40.106829  3513 solver.cpp:237] Iteration 28800, loss = 1.36647
I0523 08:42:40.106880  3513 solver.cpp:253]     Train net output #0: loss = 1.36647 (* 1 = 1.36647 loss)
I0523 08:42:40.106897  3513 sgd_solver.cpp:106] Iteration 28800, lr = 0.004
I0523 08:42:49.404711  3513 solver.cpp:237] Iteration 29100, loss = 1.27313
I0523 08:42:49.404747  3513 solver.cpp:253]     Train net output #0: loss = 1.27313 (* 1 = 1.27313 loss)
I0523 08:42:49.404764  3513 sgd_solver.cpp:106] Iteration 29100, lr = 0.004
I0523 08:42:58.701352  3513 solver.cpp:237] Iteration 29400, loss = 1.25979
I0523 08:42:58.701513  3513 solver.cpp:253]     Train net output #0: loss = 1.25979 (* 1 = 1.25979 loss)
I0523 08:42:58.701526  3513 sgd_solver.cpp:106] Iteration 29400, lr = 0.004
I0523 08:43:07.993511  3513 solver.cpp:237] Iteration 29700, loss = 1.14666
I0523 08:43:07.993546  3513 solver.cpp:253]     Train net output #0: loss = 1.14666 (* 1 = 1.14666 loss)
I0523 08:43:07.993562  3513 sgd_solver.cpp:106] Iteration 29700, lr = 0.004
I0523 08:43:17.258142  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_30000.caffemodel
I0523 08:43:17.319334  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_30000.solverstate
I0523 08:43:17.347780  3513 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 08:44:05.173043  3513 solver.cpp:409]     Test net output #0: accuracy = 0.880868
I0523 08:44:05.173212  3513 solver.cpp:409]     Test net output #1: loss = 0.384458 (* 1 = 0.384458 loss)
I0523 08:44:26.070094  3513 solver.cpp:237] Iteration 30000, loss = 1.19341
I0523 08:44:26.070152  3513 solver.cpp:253]     Train net output #0: loss = 1.19341 (* 1 = 1.19341 loss)
I0523 08:44:26.070168  3513 sgd_solver.cpp:106] Iteration 30000, lr = 0.004
I0523 08:44:35.369096  3513 solver.cpp:237] Iteration 30300, loss = 0.971409
I0523 08:44:35.369252  3513 solver.cpp:253]     Train net output #0: loss = 0.971409 (* 1 = 0.971409 loss)
I0523 08:44:35.369266  3513 sgd_solver.cpp:106] Iteration 30300, lr = 0.004
I0523 08:44:44.669536  3513 solver.cpp:237] Iteration 30600, loss = 1.3495
I0523 08:44:44.669587  3513 solver.cpp:253]     Train net output #0: loss = 1.3495 (* 1 = 1.3495 loss)
I0523 08:44:44.669603  3513 sgd_solver.cpp:106] Iteration 30600, lr = 0.004
I0523 08:44:53.970366  3513 solver.cpp:237] Iteration 30900, loss = 1.33964
I0523 08:44:53.970402  3513 solver.cpp:253]     Train net output #0: loss = 1.33964 (* 1 = 1.33964 loss)
I0523 08:44:53.970415  3513 sgd_solver.cpp:106] Iteration 30900, lr = 0.004
I0523 08:45:03.270650  3513 solver.cpp:237] Iteration 31200, loss = 1.14375
I0523 08:45:03.270686  3513 solver.cpp:253]     Train net output #0: loss = 1.14375 (* 1 = 1.14375 loss)
I0523 08:45:03.270702  3513 sgd_solver.cpp:106] Iteration 31200, lr = 0.004
I0523 08:45:12.571131  3513 solver.cpp:237] Iteration 31500, loss = 1.16977
I0523 08:45:12.571292  3513 solver.cpp:253]     Train net output #0: loss = 1.16977 (* 1 = 1.16977 loss)
I0523 08:45:12.571307  3513 sgd_solver.cpp:106] Iteration 31500, lr = 0.004
I0523 08:45:21.867497  3513 solver.cpp:237] Iteration 31800, loss = 1.29432
I0523 08:45:21.867532  3513 solver.cpp:253]     Train net output #0: loss = 1.29432 (* 1 = 1.29432 loss)
I0523 08:45:21.867550  3513 sgd_solver.cpp:106] Iteration 31800, lr = 0.004
I0523 08:45:52.080870  3513 solver.cpp:237] Iteration 32100, loss = 1.23088
I0523 08:45:52.081050  3513 solver.cpp:253]     Train net output #0: loss = 1.23088 (* 1 = 1.23088 loss)
I0523 08:45:52.081065  3513 sgd_solver.cpp:106] Iteration 32100, lr = 0.004
I0523 08:46:01.381382  3513 solver.cpp:237] Iteration 32400, loss = 1.38583
I0523 08:46:01.381428  3513 solver.cpp:253]     Train net output #0: loss = 1.38583 (* 1 = 1.38583 loss)
I0523 08:46:01.381448  3513 sgd_solver.cpp:106] Iteration 32400, lr = 0.004
I0523 08:46:10.678652  3513 solver.cpp:237] Iteration 32700, loss = 1.51807
I0523 08:46:10.678688  3513 solver.cpp:253]     Train net output #0: loss = 1.51807 (* 1 = 1.51807 loss)
I0523 08:46:10.678704  3513 sgd_solver.cpp:106] Iteration 32700, lr = 0.004
I0523 08:46:19.949443  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_33000.caffemodel
I0523 08:46:20.013998  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_33000.solverstate
I0523 08:46:20.049868  3513 solver.cpp:237] Iteration 33000, loss = 0.976113
I0523 08:46:20.049919  3513 solver.cpp:253]     Train net output #0: loss = 0.976113 (* 1 = 0.976113 loss)
I0523 08:46:20.049933  3513 sgd_solver.cpp:106] Iteration 33000, lr = 0.004
I0523 08:46:29.345441  3513 solver.cpp:237] Iteration 33300, loss = 1.17369
I0523 08:46:29.345607  3513 solver.cpp:253]     Train net output #0: loss = 1.17369 (* 1 = 1.17369 loss)
I0523 08:46:29.345620  3513 sgd_solver.cpp:106] Iteration 33300, lr = 0.004
I0523 08:46:38.646265  3513 solver.cpp:237] Iteration 33600, loss = 1.27772
I0523 08:46:38.646298  3513 solver.cpp:253]     Train net output #0: loss = 1.27772 (* 1 = 1.27772 loss)
I0523 08:46:38.646317  3513 sgd_solver.cpp:106] Iteration 33600, lr = 0.004
I0523 08:46:47.941339  3513 solver.cpp:237] Iteration 33900, loss = 1.13198
I0523 08:46:47.941378  3513 solver.cpp:253]     Train net output #0: loss = 1.13198 (* 1 = 1.13198 loss)
I0523 08:46:47.941400  3513 sgd_solver.cpp:106] Iteration 33900, lr = 0.004
I0523 08:47:18.139305  3513 solver.cpp:237] Iteration 34200, loss = 1.45541
I0523 08:47:18.139482  3513 solver.cpp:253]     Train net output #0: loss = 1.45541 (* 1 = 1.45541 loss)
I0523 08:47:18.139497  3513 sgd_solver.cpp:106] Iteration 34200, lr = 0.004
I0523 08:47:27.443383  3513 solver.cpp:237] Iteration 34500, loss = 0.818148
I0523 08:47:27.443418  3513 solver.cpp:253]     Train net output #0: loss = 0.818148 (* 1 = 0.818148 loss)
I0523 08:47:27.443435  3513 sgd_solver.cpp:106] Iteration 34500, lr = 0.004
I0523 08:47:36.738543  3513 solver.cpp:237] Iteration 34800, loss = 1.28244
I0523 08:47:36.738595  3513 solver.cpp:253]     Train net output #0: loss = 1.28244 (* 1 = 1.28244 loss)
I0523 08:47:36.738610  3513 sgd_solver.cpp:106] Iteration 34800, lr = 0.004
I0523 08:47:46.033939  3513 solver.cpp:237] Iteration 35100, loss = 1.14726
I0523 08:47:46.033969  3513 solver.cpp:253]     Train net output #0: loss = 1.14726 (* 1 = 1.14726 loss)
I0523 08:47:46.033982  3513 sgd_solver.cpp:106] Iteration 35100, lr = 0.004
I0523 08:47:55.337347  3513 solver.cpp:237] Iteration 35400, loss = 1.34761
I0523 08:47:55.337496  3513 solver.cpp:253]     Train net output #0: loss = 1.34761 (* 1 = 1.34761 loss)
I0523 08:47:55.337508  3513 sgd_solver.cpp:106] Iteration 35400, lr = 0.004
I0523 08:48:04.634093  3513 solver.cpp:237] Iteration 35700, loss = 1.0983
I0523 08:48:04.634136  3513 solver.cpp:253]     Train net output #0: loss = 1.0983 (* 1 = 1.0983 loss)
I0523 08:48:04.634156  3513 sgd_solver.cpp:106] Iteration 35700, lr = 0.004
I0523 08:48:13.904463  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_36000.caffemodel
I0523 08:48:13.963593  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_36000.solverstate
I0523 08:48:13.989990  3513 solver.cpp:341] Iteration 36000, Testing net (#0)
I0523 08:49:22.696981  3513 solver.cpp:409]     Test net output #0: accuracy = 0.882034
I0523 08:49:22.697162  3513 solver.cpp:409]     Test net output #1: loss = 0.373301 (* 1 = 0.373301 loss)
I0523 08:49:43.577625  3513 solver.cpp:237] Iteration 36000, loss = 1.06449
I0523 08:49:43.577682  3513 solver.cpp:253]     Train net output #0: loss = 1.06449 (* 1 = 1.06449 loss)
I0523 08:49:43.577698  3513 sgd_solver.cpp:106] Iteration 36000, lr = 0.004
I0523 08:49:52.863241  3513 solver.cpp:237] Iteration 36300, loss = 1.03528
I0523 08:49:52.863399  3513 solver.cpp:253]     Train net output #0: loss = 1.03528 (* 1 = 1.03528 loss)
I0523 08:49:52.863414  3513 sgd_solver.cpp:106] Iteration 36300, lr = 0.004
I0523 08:50:02.151856  3513 solver.cpp:237] Iteration 36600, loss = 1.1207
I0523 08:50:02.151891  3513 solver.cpp:253]     Train net output #0: loss = 1.1207 (* 1 = 1.1207 loss)
I0523 08:50:02.151906  3513 sgd_solver.cpp:106] Iteration 36600, lr = 0.004
I0523 08:50:11.440569  3513 solver.cpp:237] Iteration 36900, loss = 1.39847
I0523 08:50:11.440614  3513 solver.cpp:253]     Train net output #0: loss = 1.39847 (* 1 = 1.39847 loss)
I0523 08:50:11.440634  3513 sgd_solver.cpp:106] Iteration 36900, lr = 0.004
I0523 08:50:20.727251  3513 solver.cpp:237] Iteration 37200, loss = 1.07785
I0523 08:50:20.727286  3513 solver.cpp:253]     Train net output #0: loss = 1.07785 (* 1 = 1.07785 loss)
I0523 08:50:20.727301  3513 sgd_solver.cpp:106] Iteration 37200, lr = 0.004
I0523 08:50:30.016319  3513 solver.cpp:237] Iteration 37500, loss = 1.36579
I0523 08:50:30.016489  3513 solver.cpp:253]     Train net output #0: loss = 1.36579 (* 1 = 1.36579 loss)
I0523 08:50:30.016505  3513 sgd_solver.cpp:106] Iteration 37500, lr = 0.004
I0523 08:50:39.304612  3513 solver.cpp:237] Iteration 37800, loss = 1.30024
I0523 08:50:39.304647  3513 solver.cpp:253]     Train net output #0: loss = 1.30024 (* 1 = 1.30024 loss)
I0523 08:50:39.304664  3513 sgd_solver.cpp:106] Iteration 37800, lr = 0.004
I0523 08:51:09.470028  3513 solver.cpp:237] Iteration 38100, loss = 1.06621
I0523 08:51:09.470201  3513 solver.cpp:253]     Train net output #0: loss = 1.06621 (* 1 = 1.06621 loss)
I0523 08:51:09.470216  3513 sgd_solver.cpp:106] Iteration 38100, lr = 0.004
I0523 08:51:18.759682  3513 solver.cpp:237] Iteration 38400, loss = 1.05178
I0523 08:51:18.759732  3513 solver.cpp:253]     Train net output #0: loss = 1.05178 (* 1 = 1.05178 loss)
I0523 08:51:18.759748  3513 sgd_solver.cpp:106] Iteration 38400, lr = 0.004
I0523 08:51:28.047937  3513 solver.cpp:237] Iteration 38700, loss = 1.33275
I0523 08:51:28.047973  3513 solver.cpp:253]     Train net output #0: loss = 1.33275 (* 1 = 1.33275 loss)
I0523 08:51:28.047989  3513 sgd_solver.cpp:106] Iteration 38700, lr = 0.004
I0523 08:51:37.306905  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_39000.caffemodel
I0523 08:51:37.366529  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_39000.solverstate
I0523 08:51:37.402571  3513 solver.cpp:237] Iteration 39000, loss = 1.06467
I0523 08:51:37.402621  3513 solver.cpp:253]     Train net output #0: loss = 1.06467 (* 1 = 1.06467 loss)
I0523 08:51:37.402636  3513 sgd_solver.cpp:106] Iteration 39000, lr = 0.004
I0523 08:51:46.688591  3513 solver.cpp:237] Iteration 39300, loss = 1.13473
I0523 08:51:46.688771  3513 solver.cpp:253]     Train net output #0: loss = 1.13473 (* 1 = 1.13473 loss)
I0523 08:51:46.688786  3513 sgd_solver.cpp:106] Iteration 39300, lr = 0.004
I0523 08:51:55.979079  3513 solver.cpp:237] Iteration 39600, loss = 1.23501
I0523 08:51:55.979115  3513 solver.cpp:253]     Train net output #0: loss = 1.23501 (* 1 = 1.23501 loss)
I0523 08:51:55.979131  3513 sgd_solver.cpp:106] Iteration 39600, lr = 0.004
I0523 08:52:05.265207  3513 solver.cpp:237] Iteration 39900, loss = 1.43881
I0523 08:52:05.265242  3513 solver.cpp:253]     Train net output #0: loss = 1.43881 (* 1 = 1.43881 loss)
I0523 08:52:05.265257  3513 sgd_solver.cpp:106] Iteration 39900, lr = 0.004
I0523 08:52:35.472869  3513 solver.cpp:237] Iteration 40200, loss = 1.26812
I0523 08:52:35.473047  3513 solver.cpp:253]     Train net output #0: loss = 1.26812 (* 1 = 1.26812 loss)
I0523 08:52:35.473062  3513 sgd_solver.cpp:106] Iteration 40200, lr = 0.004
I0523 08:52:44.762593  3513 solver.cpp:237] Iteration 40500, loss = 1.16295
I0523 08:52:44.762626  3513 solver.cpp:253]     Train net output #0: loss = 1.16295 (* 1 = 1.16295 loss)
I0523 08:52:44.762644  3513 sgd_solver.cpp:106] Iteration 40500, lr = 0.004
I0523 08:52:54.052047  3513 solver.cpp:237] Iteration 40800, loss = 1.29884
I0523 08:52:54.052083  3513 solver.cpp:253]     Train net output #0: loss = 1.29884 (* 1 = 1.29884 loss)
I0523 08:52:54.052098  3513 sgd_solver.cpp:106] Iteration 40800, lr = 0.004
I0523 08:53:03.343400  3513 solver.cpp:237] Iteration 41100, loss = 1.34848
I0523 08:53:03.343443  3513 solver.cpp:253]     Train net output #0: loss = 1.34848 (* 1 = 1.34848 loss)
I0523 08:53:03.343463  3513 sgd_solver.cpp:106] Iteration 41100, lr = 0.004
I0523 08:53:12.628424  3513 solver.cpp:237] Iteration 41400, loss = 1.06643
I0523 08:53:12.628583  3513 solver.cpp:253]     Train net output #0: loss = 1.06643 (* 1 = 1.06643 loss)
I0523 08:53:12.628597  3513 sgd_solver.cpp:106] Iteration 41400, lr = 0.004
I0523 08:53:21.918462  3513 solver.cpp:237] Iteration 41700, loss = 1.17481
I0523 08:53:21.918496  3513 solver.cpp:253]     Train net output #0: loss = 1.17481 (* 1 = 1.17481 loss)
I0523 08:53:21.918514  3513 sgd_solver.cpp:106] Iteration 41700, lr = 0.004
I0523 08:53:31.176375  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_42000.caffemodel
I0523 08:53:31.235625  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_42000.solverstate
I0523 08:53:31.261984  3513 solver.cpp:341] Iteration 42000, Testing net (#0)
I0523 08:54:18.767499  3513 solver.cpp:409]     Test net output #0: accuracy = 0.884166
I0523 08:54:18.767668  3513 solver.cpp:409]     Test net output #1: loss = 0.397688 (* 1 = 0.397688 loss)
I0523 08:54:39.688359  3513 solver.cpp:237] Iteration 42000, loss = 1.12298
I0523 08:54:39.688416  3513 solver.cpp:253]     Train net output #0: loss = 1.12298 (* 1 = 1.12298 loss)
I0523 08:54:39.688434  3513 sgd_solver.cpp:106] Iteration 42000, lr = 0.004
I0523 08:54:48.984009  3513 solver.cpp:237] Iteration 42300, loss = 1.05824
I0523 08:54:48.984169  3513 solver.cpp:253]     Train net output #0: loss = 1.05824 (* 1 = 1.05824 loss)
I0523 08:54:48.984184  3513 sgd_solver.cpp:106] Iteration 42300, lr = 0.004
I0523 08:54:58.280115  3513 solver.cpp:237] Iteration 42600, loss = 1.50729
I0523 08:54:58.280150  3513 solver.cpp:253]     Train net output #0: loss = 1.50729 (* 1 = 1.50729 loss)
I0523 08:54:58.280167  3513 sgd_solver.cpp:106] Iteration 42600, lr = 0.004
I0523 08:55:07.576730  3513 solver.cpp:237] Iteration 42900, loss = 1.10279
I0523 08:55:07.576777  3513 solver.cpp:253]     Train net output #0: loss = 1.10279 (* 1 = 1.10279 loss)
I0523 08:55:07.576792  3513 sgd_solver.cpp:106] Iteration 42900, lr = 0.004
I0523 08:55:16.872792  3513 solver.cpp:237] Iteration 43200, loss = 1.29147
I0523 08:55:16.872828  3513 solver.cpp:253]     Train net output #0: loss = 1.29147 (* 1 = 1.29147 loss)
I0523 08:55:16.872843  3513 sgd_solver.cpp:106] Iteration 43200, lr = 0.004
I0523 08:55:26.169447  3513 solver.cpp:237] Iteration 43500, loss = 1.08157
I0523 08:55:26.169607  3513 solver.cpp:253]     Train net output #0: loss = 1.08157 (* 1 = 1.08157 loss)
I0523 08:55:26.169620  3513 sgd_solver.cpp:106] Iteration 43500, lr = 0.004
I0523 08:55:35.465664  3513 solver.cpp:237] Iteration 43800, loss = 1.1239
I0523 08:55:35.465708  3513 solver.cpp:253]     Train net output #0: loss = 1.1239 (* 1 = 1.1239 loss)
I0523 08:55:35.465728  3513 sgd_solver.cpp:106] Iteration 43800, lr = 0.004
I0523 08:56:05.669376  3513 solver.cpp:237] Iteration 44100, loss = 1.12864
I0523 08:56:05.669559  3513 solver.cpp:253]     Train net output #0: loss = 1.12864 (* 1 = 1.12864 loss)
I0523 08:56:05.669574  3513 sgd_solver.cpp:106] Iteration 44100, lr = 0.004
I0523 08:56:14.966498  3513 solver.cpp:237] Iteration 44400, loss = 1.1135
I0523 08:56:14.966533  3513 solver.cpp:253]     Train net output #0: loss = 1.1135 (* 1 = 1.1135 loss)
I0523 08:56:14.966549  3513 sgd_solver.cpp:106] Iteration 44400, lr = 0.004
I0523 08:56:24.264951  3513 solver.cpp:237] Iteration 44700, loss = 1.25011
I0523 08:56:24.264991  3513 solver.cpp:253]     Train net output #0: loss = 1.25011 (* 1 = 1.25011 loss)
I0523 08:56:24.265009  3513 sgd_solver.cpp:106] Iteration 44700, lr = 0.004
I0523 08:56:33.528985  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_45000.caffemodel
I0523 08:56:33.590401  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_45000.solverstate
I0523 08:56:33.628017  3513 solver.cpp:237] Iteration 45000, loss = 1.22167
I0523 08:56:33.628070  3513 solver.cpp:253]     Train net output #0: loss = 1.22167 (* 1 = 1.22167 loss)
I0523 08:56:33.628085  3513 sgd_solver.cpp:106] Iteration 45000, lr = 0.004
I0523 08:56:42.927121  3513 solver.cpp:237] Iteration 45300, loss = 1.11753
I0523 08:56:42.927276  3513 solver.cpp:253]     Train net output #0: loss = 1.11753 (* 1 = 1.11753 loss)
I0523 08:56:42.927290  3513 sgd_solver.cpp:106] Iteration 45300, lr = 0.004
I0523 08:56:52.221839  3513 solver.cpp:237] Iteration 45600, loss = 1.12047
I0523 08:56:52.221879  3513 solver.cpp:253]     Train net output #0: loss = 1.12047 (* 1 = 1.12047 loss)
I0523 08:56:52.221896  3513 sgd_solver.cpp:106] Iteration 45600, lr = 0.004
I0523 08:57:01.518441  3513 solver.cpp:237] Iteration 45900, loss = 1.29573
I0523 08:57:01.518476  3513 solver.cpp:253]     Train net output #0: loss = 1.29573 (* 1 = 1.29573 loss)
I0523 08:57:01.518489  3513 sgd_solver.cpp:106] Iteration 45900, lr = 0.004
I0523 08:57:31.770335  3513 solver.cpp:237] Iteration 46200, loss = 0.991676
I0523 08:57:31.770519  3513 solver.cpp:253]     Train net output #0: loss = 0.991675 (* 1 = 0.991675 loss)
I0523 08:57:31.770534  3513 sgd_solver.cpp:106] Iteration 46200, lr = 0.004
I0523 08:57:41.071718  3513 solver.cpp:237] Iteration 46500, loss = 1.12985
I0523 08:57:41.071769  3513 solver.cpp:253]     Train net output #0: loss = 1.12985 (* 1 = 1.12985 loss)
I0523 08:57:41.071784  3513 sgd_solver.cpp:106] Iteration 46500, lr = 0.004
I0523 08:57:50.367336  3513 solver.cpp:237] Iteration 46800, loss = 1.15373
I0523 08:57:50.367372  3513 solver.cpp:253]     Train net output #0: loss = 1.15373 (* 1 = 1.15373 loss)
I0523 08:57:50.367385  3513 sgd_solver.cpp:106] Iteration 46800, lr = 0.004
I0523 08:57:59.662804  3513 solver.cpp:237] Iteration 47100, loss = 1.09736
I0523 08:57:59.662853  3513 solver.cpp:253]     Train net output #0: loss = 1.09736 (* 1 = 1.09736 loss)
I0523 08:57:59.662868  3513 sgd_solver.cpp:106] Iteration 47100, lr = 0.004
I0523 08:58:08.961535  3513 solver.cpp:237] Iteration 47400, loss = 1.2191
I0523 08:58:08.961688  3513 solver.cpp:253]     Train net output #0: loss = 1.2191 (* 1 = 1.2191 loss)
I0523 08:58:08.961701  3513 sgd_solver.cpp:106] Iteration 47400, lr = 0.004
I0523 08:58:18.254942  3513 solver.cpp:237] Iteration 47700, loss = 0.96568
I0523 08:58:18.254977  3513 solver.cpp:253]     Train net output #0: loss = 0.96568 (* 1 = 0.96568 loss)
I0523 08:58:18.254994  3513 sgd_solver.cpp:106] Iteration 47700, lr = 0.004
I0523 08:58:27.518280  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_48000.caffemodel
I0523 08:58:27.577926  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_48000.solverstate
I0523 08:58:27.604001  3513 solver.cpp:341] Iteration 48000, Testing net (#0)
I0523 08:59:36.356688  3513 solver.cpp:409]     Test net output #0: accuracy = 0.888293
I0523 08:59:36.356880  3513 solver.cpp:409]     Test net output #1: loss = 0.371231 (* 1 = 0.371231 loss)
I0523 08:59:57.274888  3513 solver.cpp:237] Iteration 48000, loss = 1.06228
I0523 08:59:57.274945  3513 solver.cpp:253]     Train net output #0: loss = 1.06227 (* 1 = 1.06227 loss)
I0523 08:59:57.274960  3513 sgd_solver.cpp:106] Iteration 48000, lr = 0.004
I0523 09:00:06.570765  3513 solver.cpp:237] Iteration 48300, loss = 0.886622
I0523 09:00:06.570935  3513 solver.cpp:253]     Train net output #0: loss = 0.886621 (* 1 = 0.886621 loss)
I0523 09:00:06.570950  3513 sgd_solver.cpp:106] Iteration 48300, lr = 0.004
I0523 09:00:15.862709  3513 solver.cpp:237] Iteration 48600, loss = 1.25617
I0523 09:00:15.862742  3513 solver.cpp:253]     Train net output #0: loss = 1.25617 (* 1 = 1.25617 loss)
I0523 09:00:15.862759  3513 sgd_solver.cpp:106] Iteration 48600, lr = 0.004
I0523 09:00:25.156991  3513 solver.cpp:237] Iteration 48900, loss = 1.23595
I0523 09:00:25.157026  3513 solver.cpp:253]     Train net output #0: loss = 1.23595 (* 1 = 1.23595 loss)
I0523 09:00:25.157042  3513 sgd_solver.cpp:106] Iteration 48900, lr = 0.004
I0523 09:00:34.452549  3513 solver.cpp:237] Iteration 49200, loss = 1.14264
I0523 09:00:34.452594  3513 solver.cpp:253]     Train net output #0: loss = 1.14264 (* 1 = 1.14264 loss)
I0523 09:00:34.452610  3513 sgd_solver.cpp:106] Iteration 49200, lr = 0.004
I0523 09:00:43.746426  3513 solver.cpp:237] Iteration 49500, loss = 1.32478
I0523 09:00:43.746578  3513 solver.cpp:253]     Train net output #0: loss = 1.32478 (* 1 = 1.32478 loss)
I0523 09:00:43.746592  3513 sgd_solver.cpp:106] Iteration 49500, lr = 0.004
I0523 09:00:53.042395  3513 solver.cpp:237] Iteration 49800, loss = 1.07766
I0523 09:00:53.042429  3513 solver.cpp:253]     Train net output #0: loss = 1.07766 (* 1 = 1.07766 loss)
I0523 09:00:53.042448  3513 sgd_solver.cpp:106] Iteration 49800, lr = 0.004
I0523 09:01:23.236654  3513 solver.cpp:237] Iteration 50100, loss = 1.08116
I0523 09:01:23.236834  3513 solver.cpp:253]     Train net output #0: loss = 1.08116 (* 1 = 1.08116 loss)
I0523 09:01:23.236850  3513 sgd_solver.cpp:106] Iteration 50100, lr = 0.004
I0523 09:01:32.533260  3513 solver.cpp:237] Iteration 50400, loss = 1.07417
I0523 09:01:32.533296  3513 solver.cpp:253]     Train net output #0: loss = 1.07417 (* 1 = 1.07417 loss)
I0523 09:01:32.533311  3513 sgd_solver.cpp:106] Iteration 50400, lr = 0.004
I0523 09:01:41.826305  3513 solver.cpp:237] Iteration 50700, loss = 1.22415
I0523 09:01:41.826340  3513 solver.cpp:253]     Train net output #0: loss = 1.22415 (* 1 = 1.22415 loss)
I0523 09:01:41.826355  3513 sgd_solver.cpp:106] Iteration 50700, lr = 0.004
I0523 09:01:51.092206  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_51000.caffemodel
I0523 09:01:51.151224  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_51000.solverstate
I0523 09:01:51.187393  3513 solver.cpp:237] Iteration 51000, loss = 1.06765
I0523 09:01:51.187436  3513 solver.cpp:253]     Train net output #0: loss = 1.06765 (* 1 = 1.06765 loss)
I0523 09:01:51.187458  3513 sgd_solver.cpp:106] Iteration 51000, lr = 0.004
I0523 09:02:00.486448  3513 solver.cpp:237] Iteration 51300, loss = 1.17532
I0523 09:02:00.486613  3513 solver.cpp:253]     Train net output #0: loss = 1.17532 (* 1 = 1.17532 loss)
I0523 09:02:00.486626  3513 sgd_solver.cpp:106] Iteration 51300, lr = 0.004
I0523 09:02:09.783689  3513 solver.cpp:237] Iteration 51600, loss = 1.25875
I0523 09:02:09.783731  3513 solver.cpp:253]     Train net output #0: loss = 1.25875 (* 1 = 1.25875 loss)
I0523 09:02:09.783751  3513 sgd_solver.cpp:106] Iteration 51600, lr = 0.004
I0523 09:02:19.081197  3513 solver.cpp:237] Iteration 51900, loss = 1.23198
I0523 09:02:19.081231  3513 solver.cpp:253]     Train net output #0: loss = 1.23198 (* 1 = 1.23198 loss)
I0523 09:02:19.081248  3513 sgd_solver.cpp:106] Iteration 51900, lr = 0.004
I0523 09:02:49.315026  3513 solver.cpp:237] Iteration 52200, loss = 1.30658
I0523 09:02:49.315207  3513 solver.cpp:253]     Train net output #0: loss = 1.30658 (* 1 = 1.30658 loss)
I0523 09:02:49.315223  3513 sgd_solver.cpp:106] Iteration 52200, lr = 0.004
I0523 09:02:58.609894  3513 solver.cpp:237] Iteration 52500, loss = 1.36986
I0523 09:02:58.609941  3513 solver.cpp:253]     Train net output #0: loss = 1.36986 (* 1 = 1.36986 loss)
I0523 09:02:58.609953  3513 sgd_solver.cpp:106] Iteration 52500, lr = 0.004
I0523 09:03:07.902057  3513 solver.cpp:237] Iteration 52800, loss = 1.19432
I0523 09:03:07.902093  3513 solver.cpp:253]     Train net output #0: loss = 1.19432 (* 1 = 1.19432 loss)
I0523 09:03:07.902107  3513 sgd_solver.cpp:106] Iteration 52800, lr = 0.004
I0523 09:03:17.197926  3513 solver.cpp:237] Iteration 53100, loss = 1.30968
I0523 09:03:17.197960  3513 solver.cpp:253]     Train net output #0: loss = 1.30968 (* 1 = 1.30968 loss)
I0523 09:03:17.197974  3513 sgd_solver.cpp:106] Iteration 53100, lr = 0.004
I0523 09:03:26.496448  3513 solver.cpp:237] Iteration 53400, loss = 1.19261
I0523 09:03:26.496616  3513 solver.cpp:253]     Train net output #0: loss = 1.19261 (* 1 = 1.19261 loss)
I0523 09:03:26.496630  3513 sgd_solver.cpp:106] Iteration 53400, lr = 0.004
I0523 09:03:35.792814  3513 solver.cpp:237] Iteration 53700, loss = 0.98483
I0523 09:03:35.792848  3513 solver.cpp:253]     Train net output #0: loss = 0.98483 (* 1 = 0.98483 loss)
I0523 09:03:35.792862  3513 sgd_solver.cpp:106] Iteration 53700, lr = 0.004
I0523 09:03:45.058439  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_54000.caffemodel
I0523 09:03:45.117642  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_54000.solverstate
I0523 09:03:45.144088  3513 solver.cpp:341] Iteration 54000, Testing net (#0)
I0523 09:04:32.932080  3513 solver.cpp:409]     Test net output #0: accuracy = 0.884427
I0523 09:04:32.932256  3513 solver.cpp:409]     Test net output #1: loss = 0.363334 (* 1 = 0.363334 loss)
I0523 09:04:53.829047  3513 solver.cpp:237] Iteration 54000, loss = 1.18449
I0523 09:04:53.829104  3513 solver.cpp:253]     Train net output #0: loss = 1.18449 (* 1 = 1.18449 loss)
I0523 09:04:53.829123  3513 sgd_solver.cpp:106] Iteration 54000, lr = 0.004
I0523 09:05:03.126725  3513 solver.cpp:237] Iteration 54300, loss = 0.98466
I0523 09:05:03.126884  3513 solver.cpp:253]     Train net output #0: loss = 0.98466 (* 1 = 0.98466 loss)
I0523 09:05:03.126899  3513 sgd_solver.cpp:106] Iteration 54300, lr = 0.004
I0523 09:05:12.428623  3513 solver.cpp:237] Iteration 54600, loss = 1.04756
I0523 09:05:12.428654  3513 solver.cpp:253]     Train net output #0: loss = 1.04756 (* 1 = 1.04756 loss)
I0523 09:05:12.428681  3513 sgd_solver.cpp:106] Iteration 54600, lr = 0.004
I0523 09:05:21.728194  3513 solver.cpp:237] Iteration 54900, loss = 0.999695
I0523 09:05:21.728229  3513 solver.cpp:253]     Train net output #0: loss = 0.999695 (* 1 = 0.999695 loss)
I0523 09:05:21.728245  3513 sgd_solver.cpp:106] Iteration 54900, lr = 0.004
I0523 09:05:31.028362  3513 solver.cpp:237] Iteration 55200, loss = 1.05191
I0523 09:05:31.028403  3513 solver.cpp:253]     Train net output #0: loss = 1.05191 (* 1 = 1.05191 loss)
I0523 09:05:31.028425  3513 sgd_solver.cpp:106] Iteration 55200, lr = 0.004
I0523 09:05:40.328099  3513 solver.cpp:237] Iteration 55500, loss = 1.00137
I0523 09:05:40.328264  3513 solver.cpp:253]     Train net output #0: loss = 1.00137 (* 1 = 1.00137 loss)
I0523 09:05:40.328279  3513 sgd_solver.cpp:106] Iteration 55500, lr = 0.004
I0523 09:05:49.629132  3513 solver.cpp:237] Iteration 55800, loss = 1.19121
I0523 09:05:49.629166  3513 solver.cpp:253]     Train net output #0: loss = 1.19121 (* 1 = 1.19121 loss)
I0523 09:05:49.629184  3513 sgd_solver.cpp:106] Iteration 55800, lr = 0.004
I0523 09:06:19.862462  3513 solver.cpp:237] Iteration 56100, loss = 1.00264
I0523 09:06:19.862643  3513 solver.cpp:253]     Train net output #0: loss = 1.00264 (* 1 = 1.00264 loss)
I0523 09:06:19.862659  3513 sgd_solver.cpp:106] Iteration 56100, lr = 0.004
I0523 09:06:29.164554  3513 solver.cpp:237] Iteration 56400, loss = 1.50124
I0523 09:06:29.164588  3513 solver.cpp:253]     Train net output #0: loss = 1.50124 (* 1 = 1.50124 loss)
I0523 09:06:29.164603  3513 sgd_solver.cpp:106] Iteration 56400, lr = 0.004
I0523 09:06:38.462096  3513 solver.cpp:237] Iteration 56700, loss = 1.00554
I0523 09:06:38.462132  3513 solver.cpp:253]     Train net output #0: loss = 1.00554 (* 1 = 1.00554 loss)
I0523 09:06:38.462146  3513 sgd_solver.cpp:106] Iteration 56700, lr = 0.004
I0523 09:06:47.731075  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_57000.caffemodel
I0523 09:06:47.791895  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_57000.solverstate
I0523 09:06:47.829990  3513 solver.cpp:237] Iteration 57000, loss = 1.35093
I0523 09:06:47.830044  3513 solver.cpp:253]     Train net output #0: loss = 1.35093 (* 1 = 1.35093 loss)
I0523 09:06:47.830059  3513 sgd_solver.cpp:106] Iteration 57000, lr = 0.004
I0523 09:06:57.134871  3513 solver.cpp:237] Iteration 57300, loss = 1.12756
I0523 09:06:57.135033  3513 solver.cpp:253]     Train net output #0: loss = 1.12756 (* 1 = 1.12756 loss)
I0523 09:06:57.135046  3513 sgd_solver.cpp:106] Iteration 57300, lr = 0.004
I0523 09:07:06.434265  3513 solver.cpp:237] Iteration 57600, loss = 1.27584
I0523 09:07:06.434298  3513 solver.cpp:253]     Train net output #0: loss = 1.27584 (* 1 = 1.27584 loss)
I0523 09:07:06.434315  3513 sgd_solver.cpp:106] Iteration 57600, lr = 0.004
I0523 09:07:15.730901  3513 solver.cpp:237] Iteration 57900, loss = 1.4318
I0523 09:07:15.730942  3513 solver.cpp:253]     Train net output #0: loss = 1.4318 (* 1 = 1.4318 loss)
I0523 09:07:15.730962  3513 sgd_solver.cpp:106] Iteration 57900, lr = 0.004
I0523 09:07:45.977010  3513 solver.cpp:237] Iteration 58200, loss = 1.24903
I0523 09:07:45.977191  3513 solver.cpp:253]     Train net output #0: loss = 1.24903 (* 1 = 1.24903 loss)
I0523 09:07:45.977207  3513 sgd_solver.cpp:106] Iteration 58200, lr = 0.004
I0523 09:07:55.276687  3513 solver.cpp:237] Iteration 58500, loss = 1.05199
I0523 09:07:55.276722  3513 solver.cpp:253]     Train net output #0: loss = 1.05199 (* 1 = 1.05199 loss)
I0523 09:07:55.276741  3513 sgd_solver.cpp:106] Iteration 58500, lr = 0.004
I0523 09:08:04.572687  3513 solver.cpp:237] Iteration 58800, loss = 1.43654
I0523 09:08:04.572727  3513 solver.cpp:253]     Train net output #0: loss = 1.43654 (* 1 = 1.43654 loss)
I0523 09:08:04.572748  3513 sgd_solver.cpp:106] Iteration 58800, lr = 0.004
I0523 09:08:13.869799  3513 solver.cpp:237] Iteration 59100, loss = 1.32902
I0523 09:08:13.869834  3513 solver.cpp:253]     Train net output #0: loss = 1.32902 (* 1 = 1.32902 loss)
I0523 09:08:13.869851  3513 sgd_solver.cpp:106] Iteration 59100, lr = 0.004
I0523 09:08:23.164662  3513 solver.cpp:237] Iteration 59400, loss = 1.1673
I0523 09:08:23.164824  3513 solver.cpp:253]     Train net output #0: loss = 1.1673 (* 1 = 1.1673 loss)
I0523 09:08:23.164836  3513 sgd_solver.cpp:106] Iteration 59400, lr = 0.004
I0523 09:08:32.465416  3513 solver.cpp:237] Iteration 59700, loss = 1.21174
I0523 09:08:32.465456  3513 solver.cpp:253]     Train net output #0: loss = 1.21174 (* 1 = 1.21174 loss)
I0523 09:08:32.465477  3513 sgd_solver.cpp:106] Iteration 59700, lr = 0.004
I0523 09:08:41.736445  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_60000.caffemodel
I0523 09:08:41.797583  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_60000.solverstate
I0523 09:08:41.826409  3513 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 09:09:50.616498  3513 solver.cpp:409]     Test net output #0: accuracy = 0.890839
I0523 09:09:50.616683  3513 solver.cpp:409]     Test net output #1: loss = 0.360733 (* 1 = 0.360733 loss)
I0523 09:10:11.511615  3513 solver.cpp:237] Iteration 60000, loss = 1.0928
I0523 09:10:11.511670  3513 solver.cpp:253]     Train net output #0: loss = 1.0928 (* 1 = 1.0928 loss)
I0523 09:10:11.511685  3513 sgd_solver.cpp:106] Iteration 60000, lr = 0.004
I0523 09:10:20.797173  3513 solver.cpp:237] Iteration 60300, loss = 0.997715
I0523 09:10:20.797335  3513 solver.cpp:253]     Train net output #0: loss = 0.997715 (* 1 = 0.997715 loss)
I0523 09:10:20.797349  3513 sgd_solver.cpp:106] Iteration 60300, lr = 0.004
I0523 09:10:30.085080  3513 solver.cpp:237] Iteration 60600, loss = 1.17922
I0523 09:10:30.085129  3513 solver.cpp:253]     Train net output #0: loss = 1.17922 (* 1 = 1.17922 loss)
I0523 09:10:30.085145  3513 sgd_solver.cpp:106] Iteration 60600, lr = 0.004
I0523 09:10:39.370777  3513 solver.cpp:237] Iteration 60900, loss = 1.44203
I0523 09:10:39.370813  3513 solver.cpp:253]     Train net output #0: loss = 1.44203 (* 1 = 1.44203 loss)
I0523 09:10:39.370829  3513 sgd_solver.cpp:106] Iteration 60900, lr = 0.004
I0523 09:10:48.658768  3513 solver.cpp:237] Iteration 61200, loss = 1.08027
I0523 09:10:48.658803  3513 solver.cpp:253]     Train net output #0: loss = 1.08027 (* 1 = 1.08027 loss)
I0523 09:10:48.658819  3513 sgd_solver.cpp:106] Iteration 61200, lr = 0.004
I0523 09:10:57.949746  3513 solver.cpp:237] Iteration 61500, loss = 1.07423
I0523 09:10:57.949918  3513 solver.cpp:253]     Train net output #0: loss = 1.07423 (* 1 = 1.07423 loss)
I0523 09:10:57.949933  3513 sgd_solver.cpp:106] Iteration 61500, lr = 0.004
I0523 09:11:07.239058  3513 solver.cpp:237] Iteration 61800, loss = 1.452
I0523 09:11:07.239092  3513 solver.cpp:253]     Train net output #0: loss = 1.452 (* 1 = 1.452 loss)
I0523 09:11:07.239109  3513 sgd_solver.cpp:106] Iteration 61800, lr = 0.004
I0523 09:11:37.448905  3513 solver.cpp:237] Iteration 62100, loss = 1.07162
I0523 09:11:37.449087  3513 solver.cpp:253]     Train net output #0: loss = 1.07162 (* 1 = 1.07162 loss)
I0523 09:11:37.449103  3513 sgd_solver.cpp:106] Iteration 62100, lr = 0.004
I0523 09:11:46.733422  3513 solver.cpp:237] Iteration 62400, loss = 1.01177
I0523 09:11:46.733469  3513 solver.cpp:253]     Train net output #0: loss = 1.01177 (* 1 = 1.01177 loss)
I0523 09:11:46.733481  3513 sgd_solver.cpp:106] Iteration 62400, lr = 0.004
I0523 09:11:56.024583  3513 solver.cpp:237] Iteration 62700, loss = 1.46353
I0523 09:11:56.024618  3513 solver.cpp:253]     Train net output #0: loss = 1.46353 (* 1 = 1.46353 loss)
I0523 09:11:56.024632  3513 sgd_solver.cpp:106] Iteration 62700, lr = 0.004
I0523 09:12:05.281554  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_63000.caffemodel
I0523 09:12:05.340399  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_63000.solverstate
I0523 09:12:05.376489  3513 solver.cpp:237] Iteration 63000, loss = 1.2035
I0523 09:12:05.376538  3513 solver.cpp:253]     Train net output #0: loss = 1.2035 (* 1 = 1.2035 loss)
I0523 09:12:05.376554  3513 sgd_solver.cpp:106] Iteration 63000, lr = 0.004
I0523 09:12:14.664403  3513 solver.cpp:237] Iteration 63300, loss = 1.46806
I0523 09:12:14.664583  3513 solver.cpp:253]     Train net output #0: loss = 1.46806 (* 1 = 1.46806 loss)
I0523 09:12:14.664597  3513 sgd_solver.cpp:106] Iteration 63300, lr = 0.004
I0523 09:12:23.950644  3513 solver.cpp:237] Iteration 63600, loss = 1.01154
I0523 09:12:23.950677  3513 solver.cpp:253]     Train net output #0: loss = 1.01154 (* 1 = 1.01154 loss)
I0523 09:12:23.950695  3513 sgd_solver.cpp:106] Iteration 63600, lr = 0.004
I0523 09:12:33.237306  3513 solver.cpp:237] Iteration 63900, loss = 1.12297
I0523 09:12:33.237341  3513 solver.cpp:253]     Train net output #0: loss = 1.12297 (* 1 = 1.12297 loss)
I0523 09:12:33.237359  3513 sgd_solver.cpp:106] Iteration 63900, lr = 0.004
I0523 09:13:03.420166  3513 solver.cpp:237] Iteration 64200, loss = 1.22565
I0523 09:13:03.420344  3513 solver.cpp:253]     Train net output #0: loss = 1.22565 (* 1 = 1.22565 loss)
I0523 09:13:03.420361  3513 sgd_solver.cpp:106] Iteration 64200, lr = 0.004
I0523 09:13:12.707231  3513 solver.cpp:237] Iteration 64500, loss = 1.05597
I0523 09:13:12.707264  3513 solver.cpp:253]     Train net output #0: loss = 1.05597 (* 1 = 1.05597 loss)
I0523 09:13:12.707281  3513 sgd_solver.cpp:106] Iteration 64500, lr = 0.004
I0523 09:13:21.995952  3513 solver.cpp:237] Iteration 64800, loss = 1.27862
I0523 09:13:21.995987  3513 solver.cpp:253]     Train net output #0: loss = 1.27862 (* 1 = 1.27862 loss)
I0523 09:13:21.996004  3513 sgd_solver.cpp:106] Iteration 64800, lr = 0.004
I0523 09:13:31.283854  3513 solver.cpp:237] Iteration 65100, loss = 1.19819
I0523 09:13:31.283895  3513 solver.cpp:253]     Train net output #0: loss = 1.19819 (* 1 = 1.19819 loss)
I0523 09:13:31.283915  3513 sgd_solver.cpp:106] Iteration 65100, lr = 0.004
I0523 09:13:40.568327  3513 solver.cpp:237] Iteration 65400, loss = 1.21244
I0523 09:13:40.568486  3513 solver.cpp:253]     Train net output #0: loss = 1.21244 (* 1 = 1.21244 loss)
I0523 09:13:40.568500  3513 sgd_solver.cpp:106] Iteration 65400, lr = 0.004
I0523 09:13:49.853957  3513 solver.cpp:237] Iteration 65700, loss = 1.19262
I0523 09:13:49.854008  3513 solver.cpp:253]     Train net output #0: loss = 1.19262 (* 1 = 1.19262 loss)
I0523 09:13:49.854024  3513 sgd_solver.cpp:106] Iteration 65700, lr = 0.004
I0523 09:13:59.112563  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_66000.caffemodel
I0523 09:13:59.172112  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_66000.solverstate
I0523 09:13:59.198441  3513 solver.cpp:341] Iteration 66000, Testing net (#0)
I0523 09:14:46.722337  3513 solver.cpp:409]     Test net output #0: accuracy = 0.894083
I0523 09:14:46.722515  3513 solver.cpp:409]     Test net output #1: loss = 0.351937 (* 1 = 0.351937 loss)
I0523 09:15:07.713243  3513 solver.cpp:237] Iteration 66000, loss = 1.03206
I0523 09:15:07.713300  3513 solver.cpp:253]     Train net output #0: loss = 1.03206 (* 1 = 1.03206 loss)
I0523 09:15:07.713315  3513 sgd_solver.cpp:106] Iteration 66000, lr = 0.004
I0523 09:15:17.010807  3513 solver.cpp:237] Iteration 66300, loss = 1.33215
I0523 09:15:17.010970  3513 solver.cpp:253]     Train net output #0: loss = 1.33215 (* 1 = 1.33215 loss)
I0523 09:15:17.010984  3513 sgd_solver.cpp:106] Iteration 66300, lr = 0.004
I0523 09:15:26.307807  3513 solver.cpp:237] Iteration 66600, loss = 1.17472
I0523 09:15:26.307847  3513 solver.cpp:253]     Train net output #0: loss = 1.17472 (* 1 = 1.17472 loss)
I0523 09:15:26.307863  3513 sgd_solver.cpp:106] Iteration 66600, lr = 0.004
I0523 09:15:35.605479  3513 solver.cpp:237] Iteration 66900, loss = 1.33016
I0523 09:15:35.605530  3513 solver.cpp:253]     Train net output #0: loss = 1.33016 (* 1 = 1.33016 loss)
I0523 09:15:35.605548  3513 sgd_solver.cpp:106] Iteration 66900, lr = 0.004
I0523 09:15:44.900952  3513 solver.cpp:237] Iteration 67200, loss = 1.02169
I0523 09:15:44.900987  3513 solver.cpp:253]     Train net output #0: loss = 1.02169 (* 1 = 1.02169 loss)
I0523 09:15:44.901002  3513 sgd_solver.cpp:106] Iteration 67200, lr = 0.004
I0523 09:15:54.199481  3513 solver.cpp:237] Iteration 67500, loss = 1.3078
I0523 09:15:54.199668  3513 solver.cpp:253]     Train net output #0: loss = 1.3078 (* 1 = 1.3078 loss)
I0523 09:15:54.199682  3513 sgd_solver.cpp:106] Iteration 67500, lr = 0.004
I0523 09:16:03.492074  3513 solver.cpp:237] Iteration 67800, loss = 1.03882
I0523 09:16:03.492105  3513 solver.cpp:253]     Train net output #0: loss = 1.03881 (* 1 = 1.03881 loss)
I0523 09:16:03.492117  3513 sgd_solver.cpp:106] Iteration 67800, lr = 0.004
I0523 09:16:33.685279  3513 solver.cpp:237] Iteration 68100, loss = 1.20087
I0523 09:16:33.685464  3513 solver.cpp:253]     Train net output #0: loss = 1.20087 (* 1 = 1.20087 loss)
I0523 09:16:33.685480  3513 sgd_solver.cpp:106] Iteration 68100, lr = 0.004
I0523 09:16:42.978906  3513 solver.cpp:237] Iteration 68400, loss = 1.2795
I0523 09:16:42.978940  3513 solver.cpp:253]     Train net output #0: loss = 1.2795 (* 1 = 1.2795 loss)
I0523 09:16:42.978955  3513 sgd_solver.cpp:106] Iteration 68400, lr = 0.004
I0523 09:16:52.274847  3513 solver.cpp:237] Iteration 68700, loss = 1.04045
I0523 09:16:52.274889  3513 solver.cpp:253]     Train net output #0: loss = 1.04045 (* 1 = 1.04045 loss)
I0523 09:16:52.274906  3513 sgd_solver.cpp:106] Iteration 68700, lr = 0.004
I0523 09:17:01.540755  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_69000.caffemodel
I0523 09:17:01.600878  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_69000.solverstate
I0523 09:17:01.637104  3513 solver.cpp:237] Iteration 69000, loss = 1.38999
I0523 09:17:01.637153  3513 solver.cpp:253]     Train net output #0: loss = 1.38999 (* 1 = 1.38999 loss)
I0523 09:17:01.637167  3513 sgd_solver.cpp:106] Iteration 69000, lr = 0.004
I0523 09:17:10.933811  3513 solver.cpp:237] Iteration 69300, loss = 1.17646
I0523 09:17:10.933991  3513 solver.cpp:253]     Train net output #0: loss = 1.17646 (* 1 = 1.17646 loss)
I0523 09:17:10.934005  3513 sgd_solver.cpp:106] Iteration 69300, lr = 0.004
I0523 09:17:20.227350  3513 solver.cpp:237] Iteration 69600, loss = 1.14684
I0523 09:17:20.227385  3513 solver.cpp:253]     Train net output #0: loss = 1.14684 (* 1 = 1.14684 loss)
I0523 09:17:20.227399  3513 sgd_solver.cpp:106] Iteration 69600, lr = 0.004
I0523 09:17:29.521080  3513 solver.cpp:237] Iteration 69900, loss = 1.33653
I0523 09:17:29.521114  3513 solver.cpp:253]     Train net output #0: loss = 1.33653 (* 1 = 1.33653 loss)
I0523 09:17:29.521128  3513 sgd_solver.cpp:106] Iteration 69900, lr = 0.004
I0523 09:17:59.709928  3513 solver.cpp:237] Iteration 70200, loss = 0.908148
I0523 09:17:59.710109  3513 solver.cpp:253]     Train net output #0: loss = 0.908148 (* 1 = 0.908148 loss)
I0523 09:17:59.710125  3513 sgd_solver.cpp:106] Iteration 70200, lr = 0.004
I0523 09:18:09.004297  3513 solver.cpp:237] Iteration 70500, loss = 1.16113
I0523 09:18:09.004330  3513 solver.cpp:253]     Train net output #0: loss = 1.16113 (* 1 = 1.16113 loss)
I0523 09:18:09.004345  3513 sgd_solver.cpp:106] Iteration 70500, lr = 0.004
I0523 09:18:18.299865  3513 solver.cpp:237] Iteration 70800, loss = 1.06931
I0523 09:18:18.299901  3513 solver.cpp:253]     Train net output #0: loss = 1.06931 (* 1 = 1.06931 loss)
I0523 09:18:18.299918  3513 sgd_solver.cpp:106] Iteration 70800, lr = 0.004
I0523 09:18:27.596315  3513 solver.cpp:237] Iteration 71100, loss = 1.11081
I0523 09:18:27.596366  3513 solver.cpp:253]     Train net output #0: loss = 1.11081 (* 1 = 1.11081 loss)
I0523 09:18:27.596380  3513 sgd_solver.cpp:106] Iteration 71100, lr = 0.004
I0523 09:18:36.892384  3513 solver.cpp:237] Iteration 71400, loss = 1.13938
I0523 09:18:36.892551  3513 solver.cpp:253]     Train net output #0: loss = 1.13938 (* 1 = 1.13938 loss)
I0523 09:18:36.892565  3513 sgd_solver.cpp:106] Iteration 71400, lr = 0.004
I0523 09:18:46.190697  3513 solver.cpp:237] Iteration 71700, loss = 1.06792
I0523 09:18:46.190732  3513 solver.cpp:253]     Train net output #0: loss = 1.06792 (* 1 = 1.06792 loss)
I0523 09:18:46.190750  3513 sgd_solver.cpp:106] Iteration 71700, lr = 0.004
I0523 09:18:55.458668  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_72000.caffemodel
I0523 09:18:55.518391  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_72000.solverstate
I0523 09:18:55.544873  3513 solver.cpp:341] Iteration 72000, Testing net (#0)
I0523 09:20:04.202443  3513 solver.cpp:409]     Test net output #0: accuracy = 0.891587
I0523 09:20:04.202636  3513 solver.cpp:409]     Test net output #1: loss = 0.351899 (* 1 = 0.351899 loss)
I0523 09:20:25.061018  3513 solver.cpp:237] Iteration 72000, loss = 0.896383
I0523 09:20:25.061079  3513 solver.cpp:253]     Train net output #0: loss = 0.896382 (* 1 = 0.896382 loss)
I0523 09:20:25.061094  3513 sgd_solver.cpp:106] Iteration 72000, lr = 0.004
I0523 09:20:34.362207  3513 solver.cpp:237] Iteration 72300, loss = 1.00888
I0523 09:20:34.362377  3513 solver.cpp:253]     Train net output #0: loss = 1.00888 (* 1 = 1.00888 loss)
I0523 09:20:34.362392  3513 sgd_solver.cpp:106] Iteration 72300, lr = 0.004
I0523 09:20:43.657121  3513 solver.cpp:237] Iteration 72600, loss = 1.39153
I0523 09:20:43.657157  3513 solver.cpp:253]     Train net output #0: loss = 1.39153 (* 1 = 1.39153 loss)
I0523 09:20:43.657173  3513 sgd_solver.cpp:106] Iteration 72600, lr = 0.004
I0523 09:20:52.954133  3513 solver.cpp:237] Iteration 72900, loss = 1.06652
I0523 09:20:52.954167  3513 solver.cpp:253]     Train net output #0: loss = 1.06652 (* 1 = 1.06652 loss)
I0523 09:20:52.954185  3513 sgd_solver.cpp:106] Iteration 72900, lr = 0.004
I0523 09:21:02.248690  3513 solver.cpp:237] Iteration 73200, loss = 1.21064
I0523 09:21:02.248728  3513 solver.cpp:253]     Train net output #0: loss = 1.21064 (* 1 = 1.21064 loss)
I0523 09:21:02.248750  3513 sgd_solver.cpp:106] Iteration 73200, lr = 0.004
I0523 09:21:11.545380  3513 solver.cpp:237] Iteration 73500, loss = 1.40216
I0523 09:21:11.545547  3513 solver.cpp:253]     Train net output #0: loss = 1.40216 (* 1 = 1.40216 loss)
I0523 09:21:11.545559  3513 sgd_solver.cpp:106] Iteration 73500, lr = 0.004
I0523 09:21:20.841732  3513 solver.cpp:237] Iteration 73800, loss = 1.10155
I0523 09:21:20.841780  3513 solver.cpp:253]     Train net output #0: loss = 1.10155 (* 1 = 1.10155 loss)
I0523 09:21:20.841796  3513 sgd_solver.cpp:106] Iteration 73800, lr = 0.004
I0523 09:21:51.021818  3513 solver.cpp:237] Iteration 74100, loss = 1.11085
I0523 09:21:51.022006  3513 solver.cpp:253]     Train net output #0: loss = 1.11085 (* 1 = 1.11085 loss)
I0523 09:21:51.022022  3513 sgd_solver.cpp:106] Iteration 74100, lr = 0.004
I0523 09:22:00.316978  3513 solver.cpp:237] Iteration 74400, loss = 1.1013
I0523 09:22:00.317013  3513 solver.cpp:253]     Train net output #0: loss = 1.1013 (* 1 = 1.1013 loss)
I0523 09:22:00.317029  3513 sgd_solver.cpp:106] Iteration 74400, lr = 0.004
I0523 09:22:09.615823  3513 solver.cpp:237] Iteration 74700, loss = 1.3357
I0523 09:22:09.615864  3513 solver.cpp:253]     Train net output #0: loss = 1.3357 (* 1 = 1.3357 loss)
I0523 09:22:09.615885  3513 sgd_solver.cpp:106] Iteration 74700, lr = 0.004
I0523 09:22:18.884270  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_75000.caffemodel
I0523 09:22:18.945466  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_75000.solverstate
I0523 09:22:18.983670  3513 solver.cpp:237] Iteration 75000, loss = 1.09894
I0523 09:22:18.983726  3513 solver.cpp:253]     Train net output #0: loss = 1.09894 (* 1 = 1.09894 loss)
I0523 09:22:18.983739  3513 sgd_solver.cpp:106] Iteration 75000, lr = 0.004
I0523 09:22:28.283252  3513 solver.cpp:237] Iteration 75300, loss = 1.36886
I0523 09:22:28.283424  3513 solver.cpp:253]     Train net output #0: loss = 1.36886 (* 1 = 1.36886 loss)
I0523 09:22:28.283438  3513 sgd_solver.cpp:106] Iteration 75300, lr = 0.004
I0523 09:22:37.577080  3513 solver.cpp:237] Iteration 75600, loss = 1.28001
I0523 09:22:37.577126  3513 solver.cpp:253]     Train net output #0: loss = 1.28001 (* 1 = 1.28001 loss)
I0523 09:22:37.577143  3513 sgd_solver.cpp:106] Iteration 75600, lr = 0.004
I0523 09:22:46.877640  3513 solver.cpp:237] Iteration 75900, loss = 1.14762
I0523 09:22:46.877674  3513 solver.cpp:253]     Train net output #0: loss = 1.14762 (* 1 = 1.14762 loss)
I0523 09:22:46.877687  3513 sgd_solver.cpp:106] Iteration 75900, lr = 0.004
I0523 09:23:17.028975  3513 solver.cpp:237] Iteration 76200, loss = 1.1234
I0523 09:23:17.029163  3513 solver.cpp:253]     Train net output #0: loss = 1.1234 (* 1 = 1.1234 loss)
I0523 09:23:17.029180  3513 sgd_solver.cpp:106] Iteration 76200, lr = 0.004
I0523 09:23:26.327551  3513 solver.cpp:237] Iteration 76500, loss = 1.04417
I0523 09:23:26.327597  3513 solver.cpp:253]     Train net output #0: loss = 1.04417 (* 1 = 1.04417 loss)
I0523 09:23:26.327615  3513 sgd_solver.cpp:106] Iteration 76500, lr = 0.004
I0523 09:23:35.624049  3513 solver.cpp:237] Iteration 76800, loss = 1.20365
I0523 09:23:35.624079  3513 solver.cpp:253]     Train net output #0: loss = 1.20365 (* 1 = 1.20365 loss)
I0523 09:23:35.624094  3513 sgd_solver.cpp:106] Iteration 76800, lr = 0.004
I0523 09:23:44.921192  3513 solver.cpp:237] Iteration 77100, loss = 1.29154
I0523 09:23:44.921228  3513 solver.cpp:253]     Train net output #0: loss = 1.29154 (* 1 = 1.29154 loss)
I0523 09:23:44.921244  3513 sgd_solver.cpp:106] Iteration 77100, lr = 0.004
I0523 09:23:54.218964  3513 solver.cpp:237] Iteration 77400, loss = 0.997377
I0523 09:23:54.219141  3513 solver.cpp:253]     Train net output #0: loss = 0.997377 (* 1 = 0.997377 loss)
I0523 09:23:54.219156  3513 sgd_solver.cpp:106] Iteration 77400, lr = 0.004
I0523 09:24:03.514747  3513 solver.cpp:237] Iteration 77700, loss = 0.979398
I0523 09:24:03.514782  3513 solver.cpp:253]     Train net output #0: loss = 0.979398 (* 1 = 0.979398 loss)
I0523 09:24:03.514799  3513 sgd_solver.cpp:106] Iteration 77700, lr = 0.004
I0523 09:24:12.782454  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_78000.caffemodel
I0523 09:24:12.841672  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_78000.solverstate
I0523 09:24:12.867949  3513 solver.cpp:341] Iteration 78000, Testing net (#0)
I0523 09:25:00.649128  3513 solver.cpp:409]     Test net output #0: accuracy = 0.894024
I0523 09:25:00.649313  3513 solver.cpp:409]     Test net output #1: loss = 0.327708 (* 1 = 0.327708 loss)
I0523 09:25:21.487175  3513 solver.cpp:237] Iteration 78000, loss = 1.04972
I0523 09:25:21.487231  3513 solver.cpp:253]     Train net output #0: loss = 1.04972 (* 1 = 1.04972 loss)
I0523 09:25:21.487247  3513 sgd_solver.cpp:106] Iteration 78000, lr = 0.004
I0523 09:25:30.786078  3513 solver.cpp:237] Iteration 78300, loss = 1.12132
I0523 09:25:30.786272  3513 solver.cpp:253]     Train net output #0: loss = 1.12132 (* 1 = 1.12132 loss)
I0523 09:25:30.786285  3513 sgd_solver.cpp:106] Iteration 78300, lr = 0.004
I0523 09:25:40.089093  3513 solver.cpp:237] Iteration 78600, loss = 1.32258
I0523 09:25:40.089130  3513 solver.cpp:253]     Train net output #0: loss = 1.32258 (* 1 = 1.32258 loss)
I0523 09:25:40.089143  3513 sgd_solver.cpp:106] Iteration 78600, lr = 0.004
I0523 09:25:49.388043  3513 solver.cpp:237] Iteration 78900, loss = 1.04595
I0523 09:25:49.388079  3513 solver.cpp:253]     Train net output #0: loss = 1.04595 (* 1 = 1.04595 loss)
I0523 09:25:49.388092  3513 sgd_solver.cpp:106] Iteration 78900, lr = 0.004
I0523 09:25:58.689332  3513 solver.cpp:237] Iteration 79200, loss = 1.23637
I0523 09:25:58.689381  3513 solver.cpp:253]     Train net output #0: loss = 1.23637 (* 1 = 1.23637 loss)
I0523 09:25:58.689398  3513 sgd_solver.cpp:106] Iteration 79200, lr = 0.004
I0523 09:26:07.986675  3513 solver.cpp:237] Iteration 79500, loss = 1.00482
I0523 09:26:07.986846  3513 solver.cpp:253]     Train net output #0: loss = 1.00482 (* 1 = 1.00482 loss)
I0523 09:26:07.986860  3513 sgd_solver.cpp:106] Iteration 79500, lr = 0.004
I0523 09:26:17.280374  3513 solver.cpp:237] Iteration 79800, loss = 0.979483
I0523 09:26:17.280410  3513 solver.cpp:253]     Train net output #0: loss = 0.979483 (* 1 = 0.979483 loss)
I0523 09:26:17.280426  3513 sgd_solver.cpp:106] Iteration 79800, lr = 0.004
I0523 09:26:47.453820  3513 solver.cpp:237] Iteration 80100, loss = 1.12032
I0523 09:26:47.454006  3513 solver.cpp:253]     Train net output #0: loss = 1.12032 (* 1 = 1.12032 loss)
I0523 09:26:47.454022  3513 sgd_solver.cpp:106] Iteration 80100, lr = 0.004
I0523 09:26:56.754338  3513 solver.cpp:237] Iteration 80400, loss = 1.08932
I0523 09:26:56.754371  3513 solver.cpp:253]     Train net output #0: loss = 1.08932 (* 1 = 1.08932 loss)
I0523 09:26:56.754389  3513 sgd_solver.cpp:106] Iteration 80400, lr = 0.004
I0523 09:27:06.051975  3513 solver.cpp:237] Iteration 80700, loss = 1.24554
I0523 09:27:06.052011  3513 solver.cpp:253]     Train net output #0: loss = 1.24554 (* 1 = 1.24554 loss)
I0523 09:27:06.052026  3513 sgd_solver.cpp:106] Iteration 80700, lr = 0.004
I0523 09:27:15.323376  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_81000.caffemodel
I0523 09:27:15.383213  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_81000.solverstate
I0523 09:27:15.419477  3513 solver.cpp:237] Iteration 81000, loss = 0.911045
I0523 09:27:15.419528  3513 solver.cpp:253]     Train net output #0: loss = 0.911044 (* 1 = 0.911044 loss)
I0523 09:27:15.419541  3513 sgd_solver.cpp:106] Iteration 81000, lr = 0.004
I0523 09:27:24.720885  3513 solver.cpp:237] Iteration 81300, loss = 1.01574
I0523 09:27:24.721050  3513 solver.cpp:253]     Train net output #0: loss = 1.01574 (* 1 = 1.01574 loss)
I0523 09:27:24.721065  3513 sgd_solver.cpp:106] Iteration 81300, lr = 0.004
I0523 09:27:34.020117  3513 solver.cpp:237] Iteration 81600, loss = 1.31639
I0523 09:27:34.020165  3513 solver.cpp:253]     Train net output #0: loss = 1.31639 (* 1 = 1.31639 loss)
I0523 09:27:34.020179  3513 sgd_solver.cpp:106] Iteration 81600, lr = 0.004
I0523 09:27:43.324518  3513 solver.cpp:237] Iteration 81900, loss = 0.925876
I0523 09:27:43.324555  3513 solver.cpp:253]     Train net output #0: loss = 0.925875 (* 1 = 0.925875 loss)
I0523 09:27:43.324571  3513 sgd_solver.cpp:106] Iteration 81900, lr = 0.004
I0523 09:28:13.530283  3513 solver.cpp:237] Iteration 82200, loss = 1.01941
I0523 09:28:13.530473  3513 solver.cpp:253]     Train net output #0: loss = 1.01941 (* 1 = 1.01941 loss)
I0523 09:28:13.530488  3513 sgd_solver.cpp:106] Iteration 82200, lr = 0.004
I0523 09:28:22.829816  3513 solver.cpp:237] Iteration 82500, loss = 1.19518
I0523 09:28:22.829850  3513 solver.cpp:253]     Train net output #0: loss = 1.19518 (* 1 = 1.19518 loss)
I0523 09:28:22.829867  3513 sgd_solver.cpp:106] Iteration 82500, lr = 0.004
I0523 09:28:32.130024  3513 solver.cpp:237] Iteration 82800, loss = 0.852031
I0523 09:28:32.130069  3513 solver.cpp:253]     Train net output #0: loss = 0.852031 (* 1 = 0.852031 loss)
I0523 09:28:32.130089  3513 sgd_solver.cpp:106] Iteration 82800, lr = 0.004
I0523 09:28:41.433609  3513 solver.cpp:237] Iteration 83100, loss = 1.32287
I0523 09:28:41.433643  3513 solver.cpp:253]     Train net output #0: loss = 1.32287 (* 1 = 1.32287 loss)
I0523 09:28:41.433660  3513 sgd_solver.cpp:106] Iteration 83100, lr = 0.004
I0523 09:28:50.736724  3513 solver.cpp:237] Iteration 83400, loss = 1.13683
I0523 09:28:50.736917  3513 solver.cpp:253]     Train net output #0: loss = 1.13683 (* 1 = 1.13683 loss)
I0523 09:28:50.736932  3513 sgd_solver.cpp:106] Iteration 83400, lr = 0.004
I0523 09:29:00.037181  3513 solver.cpp:237] Iteration 83700, loss = 1.1093
I0523 09:29:00.037215  3513 solver.cpp:253]     Train net output #0: loss = 1.1093 (* 1 = 1.1093 loss)
I0523 09:29:00.037232  3513 sgd_solver.cpp:106] Iteration 83700, lr = 0.004
I0523 09:29:09.309154  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_84000.caffemodel
I0523 09:29:09.368271  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_84000.solverstate
I0523 09:29:09.394615  3513 solver.cpp:341] Iteration 84000, Testing net (#0)
I0523 09:30:18.105944  3513 solver.cpp:409]     Test net output #0: accuracy = 0.893818
I0523 09:30:18.106128  3513 solver.cpp:409]     Test net output #1: loss = 0.325938 (* 1 = 0.325938 loss)
I0523 09:30:38.983788  3513 solver.cpp:237] Iteration 84000, loss = 1.10147
I0523 09:30:38.983850  3513 solver.cpp:253]     Train net output #0: loss = 1.10147 (* 1 = 1.10147 loss)
I0523 09:30:38.983866  3513 sgd_solver.cpp:106] Iteration 84000, lr = 0.004
I0523 09:30:48.265141  3513 solver.cpp:237] Iteration 84300, loss = 1.36682
I0523 09:30:48.265305  3513 solver.cpp:253]     Train net output #0: loss = 1.36682 (* 1 = 1.36682 loss)
I0523 09:30:48.265319  3513 sgd_solver.cpp:106] Iteration 84300, lr = 0.004
I0523 09:30:57.545289  3513 solver.cpp:237] Iteration 84600, loss = 0.881095
I0523 09:30:57.545339  3513 solver.cpp:253]     Train net output #0: loss = 0.881095 (* 1 = 0.881095 loss)
I0523 09:30:57.545356  3513 sgd_solver.cpp:106] Iteration 84600, lr = 0.004
I0523 09:31:06.828361  3513 solver.cpp:237] Iteration 84900, loss = 0.95503
I0523 09:31:06.828397  3513 solver.cpp:253]     Train net output #0: loss = 0.95503 (* 1 = 0.95503 loss)
I0523 09:31:06.828413  3513 sgd_solver.cpp:106] Iteration 84900, lr = 0.004
I0523 09:31:16.109470  3513 solver.cpp:237] Iteration 85200, loss = 1.25794
I0523 09:31:16.109505  3513 solver.cpp:253]     Train net output #0: loss = 1.25794 (* 1 = 1.25794 loss)
I0523 09:31:16.109522  3513 sgd_solver.cpp:106] Iteration 85200, lr = 0.004
I0523 09:31:25.396352  3513 solver.cpp:237] Iteration 85500, loss = 0.929267
I0523 09:31:25.396527  3513 solver.cpp:253]     Train net output #0: loss = 0.929267 (* 1 = 0.929267 loss)
I0523 09:31:25.396540  3513 sgd_solver.cpp:106] Iteration 85500, lr = 0.004
I0523 09:31:34.679838  3513 solver.cpp:237] Iteration 85800, loss = 1.03368
I0523 09:31:34.679868  3513 solver.cpp:253]     Train net output #0: loss = 1.03368 (* 1 = 1.03368 loss)
I0523 09:31:34.679882  3513 sgd_solver.cpp:106] Iteration 85800, lr = 0.004
I0523 09:32:04.842927  3513 solver.cpp:237] Iteration 86100, loss = 1.03554
I0523 09:32:04.843114  3513 solver.cpp:253]     Train net output #0: loss = 1.03554 (* 1 = 1.03554 loss)
I0523 09:32:04.843129  3513 sgd_solver.cpp:106] Iteration 86100, lr = 0.004
I0523 09:32:14.127694  3513 solver.cpp:237] Iteration 86400, loss = 1.34742
I0523 09:32:14.127744  3513 solver.cpp:253]     Train net output #0: loss = 1.34742 (* 1 = 1.34742 loss)
I0523 09:32:14.127761  3513 sgd_solver.cpp:106] Iteration 86400, lr = 0.004
I0523 09:32:23.410367  3513 solver.cpp:237] Iteration 86700, loss = 1.30376
I0523 09:32:23.410403  3513 solver.cpp:253]     Train net output #0: loss = 1.30376 (* 1 = 1.30376 loss)
I0523 09:32:23.410418  3513 sgd_solver.cpp:106] Iteration 86700, lr = 0.004
I0523 09:32:32.659803  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_87000.caffemodel
I0523 09:32:32.721410  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_87000.solverstate
I0523 09:32:32.759493  3513 solver.cpp:237] Iteration 87000, loss = 1.22169
I0523 09:32:32.759547  3513 solver.cpp:253]     Train net output #0: loss = 1.22169 (* 1 = 1.22169 loss)
I0523 09:32:32.759562  3513 sgd_solver.cpp:106] Iteration 87000, lr = 0.004
I0523 09:32:42.043182  3513 solver.cpp:237] Iteration 87300, loss = 1.08079
I0523 09:32:42.043376  3513 solver.cpp:253]     Train net output #0: loss = 1.08079 (* 1 = 1.08079 loss)
I0523 09:32:42.043391  3513 sgd_solver.cpp:106] Iteration 87300, lr = 0.004
I0523 09:32:51.325877  3513 solver.cpp:237] Iteration 87600, loss = 1.38517
I0523 09:32:51.325911  3513 solver.cpp:253]     Train net output #0: loss = 1.38517 (* 1 = 1.38517 loss)
I0523 09:32:51.325927  3513 sgd_solver.cpp:106] Iteration 87600, lr = 0.004
I0523 09:33:00.610431  3513 solver.cpp:237] Iteration 87900, loss = 1.08551
I0523 09:33:00.610481  3513 solver.cpp:253]     Train net output #0: loss = 1.08551 (* 1 = 1.08551 loss)
I0523 09:33:00.610501  3513 sgd_solver.cpp:106] Iteration 87900, lr = 0.004
I0523 09:33:30.809443  3513 solver.cpp:237] Iteration 88200, loss = 1.05921
I0523 09:33:30.809630  3513 solver.cpp:253]     Train net output #0: loss = 1.05921 (* 1 = 1.05921 loss)
I0523 09:33:30.809645  3513 sgd_solver.cpp:106] Iteration 88200, lr = 0.004
I0523 09:33:40.093971  3513 solver.cpp:237] Iteration 88500, loss = 1.41092
I0523 09:33:40.094007  3513 solver.cpp:253]     Train net output #0: loss = 1.41092 (* 1 = 1.41092 loss)
I0523 09:33:40.094023  3513 sgd_solver.cpp:106] Iteration 88500, lr = 0.004
I0523 09:33:49.381512  3513 solver.cpp:237] Iteration 88800, loss = 1.40929
I0523 09:33:49.381556  3513 solver.cpp:253]     Train net output #0: loss = 1.40929 (* 1 = 1.40929 loss)
I0523 09:33:49.381577  3513 sgd_solver.cpp:106] Iteration 88800, lr = 0.004
I0523 09:33:58.663300  3513 solver.cpp:237] Iteration 89100, loss = 1.19933
I0523 09:33:58.663336  3513 solver.cpp:253]     Train net output #0: loss = 1.19933 (* 1 = 1.19933 loss)
I0523 09:33:58.663352  3513 sgd_solver.cpp:106] Iteration 89100, lr = 0.004
I0523 09:34:07.949293  3513 solver.cpp:237] Iteration 89400, loss = 1.02043
I0523 09:34:07.949453  3513 solver.cpp:253]     Train net output #0: loss = 1.02043 (* 1 = 1.02043 loss)
I0523 09:34:07.949467  3513 sgd_solver.cpp:106] Iteration 89400, lr = 0.004
I0523 09:34:17.234388  3513 solver.cpp:237] Iteration 89700, loss = 1.44205
I0523 09:34:17.234436  3513 solver.cpp:253]     Train net output #0: loss = 1.44205 (* 1 = 1.44205 loss)
I0523 09:34:17.234449  3513 sgd_solver.cpp:106] Iteration 89700, lr = 0.004
I0523 09:34:26.490289  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_90000.caffemodel
I0523 09:34:26.551537  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_90000.solverstate
I0523 09:34:26.579831  3513 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 09:35:14.072325  3513 solver.cpp:409]     Test net output #0: accuracy = 0.894971
I0523 09:35:14.072520  3513 solver.cpp:409]     Test net output #1: loss = 0.358169 (* 1 = 0.358169 loss)
I0523 09:35:34.997874  3513 solver.cpp:237] Iteration 90000, loss = 1.28555
I0523 09:35:34.997931  3513 solver.cpp:253]     Train net output #0: loss = 1.28555 (* 1 = 1.28555 loss)
I0523 09:35:34.997946  3513 sgd_solver.cpp:106] Iteration 90000, lr = 0.004
I0523 09:35:44.299697  3513 solver.cpp:237] Iteration 90300, loss = 1.05186
I0523 09:35:44.299885  3513 solver.cpp:253]     Train net output #0: loss = 1.05186 (* 1 = 1.05186 loss)
I0523 09:35:44.299898  3513 sgd_solver.cpp:106] Iteration 90300, lr = 0.004
I0523 09:35:53.602098  3513 solver.cpp:237] Iteration 90600, loss = 1.23265
I0523 09:35:53.602151  3513 solver.cpp:253]     Train net output #0: loss = 1.23265 (* 1 = 1.23265 loss)
I0523 09:35:53.602165  3513 sgd_solver.cpp:106] Iteration 90600, lr = 0.004
I0523 09:36:02.903463  3513 solver.cpp:237] Iteration 90900, loss = 0.931741
I0523 09:36:02.903499  3513 solver.cpp:253]     Train net output #0: loss = 0.93174 (* 1 = 0.93174 loss)
I0523 09:36:02.903515  3513 sgd_solver.cpp:106] Iteration 90900, lr = 0.004
I0523 09:36:12.202980  3513 solver.cpp:237] Iteration 91200, loss = 1.38014
I0523 09:36:12.203013  3513 solver.cpp:253]     Train net output #0: loss = 1.38014 (* 1 = 1.38014 loss)
I0523 09:36:12.203032  3513 sgd_solver.cpp:106] Iteration 91200, lr = 0.004
I0523 09:36:21.506613  3513 solver.cpp:237] Iteration 91500, loss = 1.18954
I0523 09:36:21.506791  3513 solver.cpp:253]     Train net output #0: loss = 1.18954 (* 1 = 1.18954 loss)
I0523 09:36:21.506805  3513 sgd_solver.cpp:106] Iteration 91500, lr = 0.004
I0523 09:36:30.804230  3513 solver.cpp:237] Iteration 91800, loss = 1.2535
I0523 09:36:30.804265  3513 solver.cpp:253]     Train net output #0: loss = 1.2535 (* 1 = 1.2535 loss)
I0523 09:36:30.804281  3513 sgd_solver.cpp:106] Iteration 91800, lr = 0.004
I0523 09:37:00.968597  3513 solver.cpp:237] Iteration 92100, loss = 1.18405
I0523 09:37:00.968791  3513 solver.cpp:253]     Train net output #0: loss = 1.18405 (* 1 = 1.18405 loss)
I0523 09:37:00.968806  3513 sgd_solver.cpp:106] Iteration 92100, lr = 0.004
I0523 09:37:10.270613  3513 solver.cpp:237] Iteration 92400, loss = 1.37964
I0523 09:37:10.270654  3513 solver.cpp:253]     Train net output #0: loss = 1.37964 (* 1 = 1.37964 loss)
I0523 09:37:10.270676  3513 sgd_solver.cpp:106] Iteration 92400, lr = 0.004
I0523 09:37:19.574692  3513 solver.cpp:237] Iteration 92700, loss = 1.60673
I0523 09:37:19.574728  3513 solver.cpp:253]     Train net output #0: loss = 1.60673 (* 1 = 1.60673 loss)
I0523 09:37:19.574744  3513 sgd_solver.cpp:106] Iteration 92700, lr = 0.004
I0523 09:37:28.846518  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_93000.caffemodel
I0523 09:37:28.906002  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_93000.solverstate
I0523 09:37:28.942034  3513 solver.cpp:237] Iteration 93000, loss = 0.880593
I0523 09:37:28.942085  3513 solver.cpp:253]     Train net output #0: loss = 0.880593 (* 1 = 0.880593 loss)
I0523 09:37:28.942100  3513 sgd_solver.cpp:106] Iteration 93000, lr = 0.004
I0523 09:37:38.246801  3513 solver.cpp:237] Iteration 93300, loss = 1.03661
I0523 09:37:38.246984  3513 solver.cpp:253]     Train net output #0: loss = 1.03661 (* 1 = 1.03661 loss)
I0523 09:37:38.246999  3513 sgd_solver.cpp:106] Iteration 93300, lr = 0.004
I0523 09:37:47.547618  3513 solver.cpp:237] Iteration 93600, loss = 1.13384
I0523 09:37:47.547653  3513 solver.cpp:253]     Train net output #0: loss = 1.13384 (* 1 = 1.13384 loss)
I0523 09:37:47.547670  3513 sgd_solver.cpp:106] Iteration 93600, lr = 0.004
I0523 09:37:56.849793  3513 solver.cpp:237] Iteration 93900, loss = 1.14204
I0523 09:37:56.849829  3513 solver.cpp:253]     Train net output #0: loss = 1.14204 (* 1 = 1.14204 loss)
I0523 09:37:56.849845  3513 sgd_solver.cpp:106] Iteration 93900, lr = 0.004
I0523 09:38:27.063220  3513 solver.cpp:237] Iteration 94200, loss = 1.15297
I0523 09:38:27.063421  3513 solver.cpp:253]     Train net output #0: loss = 1.15297 (* 1 = 1.15297 loss)
I0523 09:38:27.063436  3513 sgd_solver.cpp:106] Iteration 94200, lr = 0.004
I0523 09:38:36.363191  3513 solver.cpp:237] Iteration 94500, loss = 0.924546
I0523 09:38:36.363226  3513 solver.cpp:253]     Train net output #0: loss = 0.924546 (* 1 = 0.924546 loss)
I0523 09:38:36.363243  3513 sgd_solver.cpp:106] Iteration 94500, lr = 0.004
I0523 09:38:45.660838  3513 solver.cpp:237] Iteration 94800, loss = 1.30872
I0523 09:38:45.660873  3513 solver.cpp:253]     Train net output #0: loss = 1.30872 (* 1 = 1.30872 loss)
I0523 09:38:45.660890  3513 sgd_solver.cpp:106] Iteration 94800, lr = 0.004
I0523 09:38:54.962709  3513 solver.cpp:237] Iteration 95100, loss = 1.25948
I0523 09:38:54.962754  3513 solver.cpp:253]     Train net output #0: loss = 1.25948 (* 1 = 1.25948 loss)
I0523 09:38:54.962774  3513 sgd_solver.cpp:106] Iteration 95100, lr = 0.004
I0523 09:39:04.266826  3513 solver.cpp:237] Iteration 95400, loss = 1.10853
I0523 09:39:04.266994  3513 solver.cpp:253]     Train net output #0: loss = 1.10853 (* 1 = 1.10853 loss)
I0523 09:39:04.267009  3513 sgd_solver.cpp:106] Iteration 95400, lr = 0.004
I0523 09:39:13.571341  3513 solver.cpp:237] Iteration 95700, loss = 1.31109
I0523 09:39:13.571383  3513 solver.cpp:253]     Train net output #0: loss = 1.31109 (* 1 = 1.31109 loss)
I0523 09:39:13.571400  3513 sgd_solver.cpp:106] Iteration 95700, lr = 0.004
I0523 09:39:22.842617  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_96000.caffemodel
I0523 09:39:22.902228  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_96000.solverstate
I0523 09:39:22.928681  3513 solver.cpp:341] Iteration 96000, Testing net (#0)
I0523 09:40:31.629736  3513 solver.cpp:409]     Test net output #0: accuracy = 0.896604
I0523 09:40:31.629927  3513 solver.cpp:409]     Test net output #1: loss = 0.346139 (* 1 = 0.346139 loss)
I0523 09:40:52.560756  3513 solver.cpp:237] Iteration 96000, loss = 1.23112
I0523 09:40:52.560812  3513 solver.cpp:253]     Train net output #0: loss = 1.23112 (* 1 = 1.23112 loss)
I0523 09:40:52.560827  3513 sgd_solver.cpp:106] Iteration 96000, lr = 0.004
I0523 09:41:01.861587  3513 solver.cpp:237] Iteration 96300, loss = 1.17143
I0523 09:41:01.861773  3513 solver.cpp:253]     Train net output #0: loss = 1.17143 (* 1 = 1.17143 loss)
I0523 09:41:01.861786  3513 sgd_solver.cpp:106] Iteration 96300, lr = 0.004
I0523 09:41:11.166195  3513 solver.cpp:237] Iteration 96600, loss = 0.924488
I0523 09:41:11.166231  3513 solver.cpp:253]     Train net output #0: loss = 0.924488 (* 1 = 0.924488 loss)
I0523 09:41:11.166249  3513 sgd_solver.cpp:106] Iteration 96600, lr = 0.004
I0523 09:41:20.466285  3513 solver.cpp:237] Iteration 96900, loss = 1.07903
I0523 09:41:20.466328  3513 solver.cpp:253]     Train net output #0: loss = 1.07903 (* 1 = 1.07903 loss)
I0523 09:41:20.466349  3513 sgd_solver.cpp:106] Iteration 96900, lr = 0.004
I0523 09:41:29.772281  3513 solver.cpp:237] Iteration 97200, loss = 0.95816
I0523 09:41:29.772317  3513 solver.cpp:253]     Train net output #0: loss = 0.95816 (* 1 = 0.95816 loss)
I0523 09:41:29.772333  3513 sgd_solver.cpp:106] Iteration 97200, lr = 0.004
I0523 09:41:39.076220  3513 solver.cpp:237] Iteration 97500, loss = 1.21148
I0523 09:41:39.076390  3513 solver.cpp:253]     Train net output #0: loss = 1.21148 (* 1 = 1.21148 loss)
I0523 09:41:39.076403  3513 sgd_solver.cpp:106] Iteration 97500, lr = 0.004
I0523 09:41:48.382004  3513 solver.cpp:237] Iteration 97800, loss = 1.02291
I0523 09:41:48.382043  3513 solver.cpp:253]     Train net output #0: loss = 1.02291 (* 1 = 1.02291 loss)
I0523 09:41:48.382062  3513 sgd_solver.cpp:106] Iteration 97800, lr = 0.004
I0523 09:42:18.609843  3513 solver.cpp:237] Iteration 98100, loss = 1.17522
I0523 09:42:18.610045  3513 solver.cpp:253]     Train net output #0: loss = 1.17522 (* 1 = 1.17522 loss)
I0523 09:42:18.610061  3513 sgd_solver.cpp:106] Iteration 98100, lr = 0.004
I0523 09:42:27.914136  3513 solver.cpp:237] Iteration 98400, loss = 0.678683
I0523 09:42:27.914172  3513 solver.cpp:253]     Train net output #0: loss = 0.678683 (* 1 = 0.678683 loss)
I0523 09:42:27.914188  3513 sgd_solver.cpp:106] Iteration 98400, lr = 0.004
I0523 09:42:37.219435  3513 solver.cpp:237] Iteration 98700, loss = 1.48064
I0523 09:42:37.219481  3513 solver.cpp:253]     Train net output #0: loss = 1.48064 (* 1 = 1.48064 loss)
I0523 09:42:37.219499  3513 sgd_solver.cpp:106] Iteration 98700, lr = 0.004
I0523 09:42:46.494045  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_99000.caffemodel
I0523 09:42:46.553877  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_99000.solverstate
I0523 09:42:46.589815  3513 solver.cpp:237] Iteration 99000, loss = 1.11511
I0523 09:42:46.589862  3513 solver.cpp:253]     Train net output #0: loss = 1.11511 (* 1 = 1.11511 loss)
I0523 09:42:46.589875  3513 sgd_solver.cpp:106] Iteration 99000, lr = 0.004
I0523 09:42:55.896867  3513 solver.cpp:237] Iteration 99300, loss = 1.01212
I0523 09:42:55.897040  3513 solver.cpp:253]     Train net output #0: loss = 1.01212 (* 1 = 1.01212 loss)
I0523 09:42:55.897054  3513 sgd_solver.cpp:106] Iteration 99300, lr = 0.004
I0523 09:43:05.200732  3513 solver.cpp:237] Iteration 99600, loss = 1.08072
I0523 09:43:05.200775  3513 solver.cpp:253]     Train net output #0: loss = 1.08071 (* 1 = 1.08071 loss)
I0523 09:43:05.200796  3513 sgd_solver.cpp:106] Iteration 99600, lr = 0.004
I0523 09:43:14.506397  3513 solver.cpp:237] Iteration 99900, loss = 1.202
I0523 09:43:14.506433  3513 solver.cpp:253]     Train net output #0: loss = 1.202 (* 1 = 1.202 loss)
I0523 09:43:14.506448  3513 sgd_solver.cpp:106] Iteration 99900, lr = 0.004
I0523 09:43:44.713603  3513 solver.cpp:237] Iteration 100200, loss = 1.04872
I0523 09:43:44.713800  3513 solver.cpp:253]     Train net output #0: loss = 1.04872 (* 1 = 1.04872 loss)
I0523 09:43:44.713816  3513 sgd_solver.cpp:106] Iteration 100200, lr = 0.004
I0523 09:43:54.021600  3513 solver.cpp:237] Iteration 100500, loss = 1.14055
I0523 09:43:54.021648  3513 solver.cpp:253]     Train net output #0: loss = 1.14055 (* 1 = 1.14055 loss)
I0523 09:43:54.021667  3513 sgd_solver.cpp:106] Iteration 100500, lr = 0.004
I0523 09:44:03.326905  3513 solver.cpp:237] Iteration 100800, loss = 1.1182
I0523 09:44:03.326939  3513 solver.cpp:253]     Train net output #0: loss = 1.1182 (* 1 = 1.1182 loss)
I0523 09:44:03.326957  3513 sgd_solver.cpp:106] Iteration 100800, lr = 0.004
I0523 09:44:12.633332  3513 solver.cpp:237] Iteration 101100, loss = 0.789868
I0523 09:44:12.633368  3513 solver.cpp:253]     Train net output #0: loss = 0.789868 (* 1 = 0.789868 loss)
I0523 09:44:12.633383  3513 sgd_solver.cpp:106] Iteration 101100, lr = 0.004
I0523 09:44:21.941679  3513 solver.cpp:237] Iteration 101400, loss = 1.19492
I0523 09:44:21.941864  3513 solver.cpp:253]     Train net output #0: loss = 1.19492 (* 1 = 1.19492 loss)
I0523 09:44:21.941879  3513 sgd_solver.cpp:106] Iteration 101400, lr = 0.004
I0523 09:44:31.244724  3513 solver.cpp:237] Iteration 101700, loss = 0.968819
I0523 09:44:31.244760  3513 solver.cpp:253]     Train net output #0: loss = 0.968819 (* 1 = 0.968819 loss)
I0523 09:44:31.244776  3513 sgd_solver.cpp:106] Iteration 101700, lr = 0.004
I0523 09:44:40.513597  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_102000.caffemodel
I0523 09:44:40.572921  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_102000.solverstate
I0523 09:44:40.598078  3513 solver.cpp:341] Iteration 102000, Testing net (#0)
I0523 09:45:28.433603  3513 solver.cpp:409]     Test net output #0: accuracy = 0.899597
I0523 09:45:28.433804  3513 solver.cpp:409]     Test net output #1: loss = 0.326892 (* 1 = 0.326892 loss)
I0523 09:45:49.343222  3513 solver.cpp:237] Iteration 102000, loss = 0.967096
I0523 09:45:49.343281  3513 solver.cpp:253]     Train net output #0: loss = 0.967096 (* 1 = 0.967096 loss)
I0523 09:45:49.343296  3513 sgd_solver.cpp:106] Iteration 102000, lr = 0.004
I0523 09:45:58.628564  3513 solver.cpp:237] Iteration 102300, loss = 1.2878
I0523 09:45:58.628749  3513 solver.cpp:253]     Train net output #0: loss = 1.2878 (* 1 = 1.2878 loss)
I0523 09:45:58.628763  3513 sgd_solver.cpp:106] Iteration 102300, lr = 0.004
I0523 09:46:07.915282  3513 solver.cpp:237] Iteration 102600, loss = 1.32616
I0523 09:46:07.915318  3513 solver.cpp:253]     Train net output #0: loss = 1.32616 (* 1 = 1.32616 loss)
I0523 09:46:07.915335  3513 sgd_solver.cpp:106] Iteration 102600, lr = 0.004
I0523 09:46:17.197156  3513 solver.cpp:237] Iteration 102900, loss = 1.13643
I0523 09:46:17.197192  3513 solver.cpp:253]     Train net output #0: loss = 1.13643 (* 1 = 1.13643 loss)
I0523 09:46:17.197208  3513 sgd_solver.cpp:106] Iteration 102900, lr = 0.004
I0523 09:46:26.485226  3513 solver.cpp:237] Iteration 103200, loss = 1.19883
I0523 09:46:26.485273  3513 solver.cpp:253]     Train net output #0: loss = 1.19883 (* 1 = 1.19883 loss)
I0523 09:46:26.485291  3513 sgd_solver.cpp:106] Iteration 103200, lr = 0.004
I0523 09:46:35.773181  3513 solver.cpp:237] Iteration 103500, loss = 1.18712
I0523 09:46:35.773358  3513 solver.cpp:253]     Train net output #0: loss = 1.18712 (* 1 = 1.18712 loss)
I0523 09:46:35.773372  3513 sgd_solver.cpp:106] Iteration 103500, lr = 0.004
I0523 09:46:45.059823  3513 solver.cpp:237] Iteration 103800, loss = 0.935277
I0523 09:46:45.059876  3513 solver.cpp:253]     Train net output #0: loss = 0.935277 (* 1 = 0.935277 loss)
I0523 09:46:45.059891  3513 sgd_solver.cpp:106] Iteration 103800, lr = 0.004
I0523 09:47:15.258812  3513 solver.cpp:237] Iteration 104100, loss = 1.00959
I0523 09:47:15.259007  3513 solver.cpp:253]     Train net output #0: loss = 1.00959 (* 1 = 1.00959 loss)
I0523 09:47:15.259023  3513 sgd_solver.cpp:106] Iteration 104100, lr = 0.004
I0523 09:47:24.546370  3513 solver.cpp:237] Iteration 104400, loss = 1.26546
I0523 09:47:24.546406  3513 solver.cpp:253]     Train net output #0: loss = 1.26545 (* 1 = 1.26545 loss)
I0523 09:47:24.546419  3513 sgd_solver.cpp:106] Iteration 104400, lr = 0.004
I0523 09:47:33.837432  3513 solver.cpp:237] Iteration 104700, loss = 0.865857
I0523 09:47:33.837486  3513 solver.cpp:253]     Train net output #0: loss = 0.865857 (* 1 = 0.865857 loss)
I0523 09:47:33.837501  3513 sgd_solver.cpp:106] Iteration 104700, lr = 0.004
I0523 09:47:43.093639  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_105000.caffemodel
I0523 09:47:43.154960  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_105000.solverstate
I0523 09:47:43.191849  3513 solver.cpp:237] Iteration 105000, loss = 1.01074
I0523 09:47:43.191903  3513 solver.cpp:253]     Train net output #0: loss = 1.01074 (* 1 = 1.01074 loss)
I0523 09:47:43.191917  3513 sgd_solver.cpp:106] Iteration 105000, lr = 0.004
I0523 09:47:52.476555  3513 solver.cpp:237] Iteration 105300, loss = 1.37738
I0523 09:47:52.476729  3513 solver.cpp:253]     Train net output #0: loss = 1.37738 (* 1 = 1.37738 loss)
I0523 09:47:52.476742  3513 sgd_solver.cpp:106] Iteration 105300, lr = 0.004
I0523 09:48:01.760043  3513 solver.cpp:237] Iteration 105600, loss = 1.03286
I0523 09:48:01.760088  3513 solver.cpp:253]     Train net output #0: loss = 1.03285 (* 1 = 1.03285 loss)
I0523 09:48:01.760104  3513 sgd_solver.cpp:106] Iteration 105600, lr = 0.004
I0523 09:48:11.048354  3513 solver.cpp:237] Iteration 105900, loss = 1.27855
I0523 09:48:11.048389  3513 solver.cpp:253]     Train net output #0: loss = 1.27855 (* 1 = 1.27855 loss)
I0523 09:48:11.048406  3513 sgd_solver.cpp:106] Iteration 105900, lr = 0.004
I0523 09:48:41.238224  3513 solver.cpp:237] Iteration 106200, loss = 1.13455
I0523 09:48:41.238430  3513 solver.cpp:253]     Train net output #0: loss = 1.13455 (* 1 = 1.13455 loss)
I0523 09:48:41.238445  3513 sgd_solver.cpp:106] Iteration 106200, lr = 0.004
I0523 09:48:50.526000  3513 solver.cpp:237] Iteration 106500, loss = 1.21248
I0523 09:48:50.526041  3513 solver.cpp:253]     Train net output #0: loss = 1.21248 (* 1 = 1.21248 loss)
I0523 09:48:50.526062  3513 sgd_solver.cpp:106] Iteration 106500, lr = 0.004
I0523 09:48:59.816324  3513 solver.cpp:237] Iteration 106800, loss = 1.10977
I0523 09:48:59.816360  3513 solver.cpp:253]     Train net output #0: loss = 1.10977 (* 1 = 1.10977 loss)
I0523 09:48:59.816376  3513 sgd_solver.cpp:106] Iteration 106800, lr = 0.004
I0523 09:49:09.099203  3513 solver.cpp:237] Iteration 107100, loss = 1.14189
I0523 09:49:09.099238  3513 solver.cpp:253]     Train net output #0: loss = 1.14189 (* 1 = 1.14189 loss)
I0523 09:49:09.099254  3513 sgd_solver.cpp:106] Iteration 107100, lr = 0.004
I0523 09:49:18.382669  3513 solver.cpp:237] Iteration 107400, loss = 1.22505
I0523 09:49:18.382846  3513 solver.cpp:253]     Train net output #0: loss = 1.22505 (* 1 = 1.22505 loss)
I0523 09:49:18.382860  3513 sgd_solver.cpp:106] Iteration 107400, lr = 0.004
I0523 09:49:27.669558  3513 solver.cpp:237] Iteration 107700, loss = 0.975297
I0523 09:49:27.669591  3513 solver.cpp:253]     Train net output #0: loss = 0.975297 (* 1 = 0.975297 loss)
I0523 09:49:27.669610  3513 sgd_solver.cpp:106] Iteration 107700, lr = 0.004
I0523 09:49:36.919728  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_108000.caffemodel
I0523 09:49:36.981042  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_108000.solverstate
I0523 09:49:37.011127  3513 solver.cpp:341] Iteration 108000, Testing net (#0)
I0523 09:50:45.729360  3513 solver.cpp:409]     Test net output #0: accuracy = 0.898404
I0523 09:50:45.729554  3513 solver.cpp:409]     Test net output #1: loss = 0.312423 (* 1 = 0.312423 loss)
I0523 09:51:06.628865  3513 solver.cpp:237] Iteration 108000, loss = 0.929584
I0523 09:51:06.628922  3513 solver.cpp:253]     Train net output #0: loss = 0.929584 (* 1 = 0.929584 loss)
I0523 09:51:06.628938  3513 sgd_solver.cpp:106] Iteration 108000, lr = 0.004
I0523 09:51:15.928421  3513 solver.cpp:237] Iteration 108300, loss = 1.1646
I0523 09:51:15.928598  3513 solver.cpp:253]     Train net output #0: loss = 1.1646 (* 1 = 1.1646 loss)
I0523 09:51:15.928611  3513 sgd_solver.cpp:106] Iteration 108300, lr = 0.004
I0523 09:51:25.232980  3513 solver.cpp:237] Iteration 108600, loss = 1.36658
I0523 09:51:25.233031  3513 solver.cpp:253]     Train net output #0: loss = 1.36658 (* 1 = 1.36658 loss)
I0523 09:51:25.233043  3513 sgd_solver.cpp:106] Iteration 108600, lr = 0.004
I0523 09:51:34.539710  3513 solver.cpp:237] Iteration 108900, loss = 1.05953
I0523 09:51:34.539746  3513 solver.cpp:253]     Train net output #0: loss = 1.05953 (* 1 = 1.05953 loss)
I0523 09:51:34.539760  3513 sgd_solver.cpp:106] Iteration 108900, lr = 0.004
I0523 09:51:43.840921  3513 solver.cpp:237] Iteration 109200, loss = 1.20427
I0523 09:51:43.840970  3513 solver.cpp:253]     Train net output #0: loss = 1.20427 (* 1 = 1.20427 loss)
I0523 09:51:43.840986  3513 sgd_solver.cpp:106] Iteration 109200, lr = 0.004
I0523 09:51:53.140686  3513 solver.cpp:237] Iteration 109500, loss = 1.2334
I0523 09:51:53.140868  3513 solver.cpp:253]     Train net output #0: loss = 1.2334 (* 1 = 1.2334 loss)
I0523 09:51:53.140882  3513 sgd_solver.cpp:106] Iteration 109500, lr = 0.004
I0523 09:52:02.442349  3513 solver.cpp:237] Iteration 109800, loss = 1.04695
I0523 09:52:02.442384  3513 solver.cpp:253]     Train net output #0: loss = 1.04695 (* 1 = 1.04695 loss)
I0523 09:52:02.442401  3513 sgd_solver.cpp:106] Iteration 109800, lr = 0.004
I0523 09:52:32.652714  3513 solver.cpp:237] Iteration 110100, loss = 1.00805
I0523 09:52:32.652910  3513 solver.cpp:253]     Train net output #0: loss = 1.00805 (* 1 = 1.00805 loss)
I0523 09:52:32.652925  3513 sgd_solver.cpp:106] Iteration 110100, lr = 0.004
I0523 09:52:41.959368  3513 solver.cpp:237] Iteration 110400, loss = 0.889447
I0523 09:52:41.959422  3513 solver.cpp:253]     Train net output #0: loss = 0.889447 (* 1 = 0.889447 loss)
I0523 09:52:41.959436  3513 sgd_solver.cpp:106] Iteration 110400, lr = 0.004
I0523 09:52:51.260707  3513 solver.cpp:237] Iteration 110700, loss = 1.17129
I0523 09:52:51.260742  3513 solver.cpp:253]     Train net output #0: loss = 1.17129 (* 1 = 1.17129 loss)
I0523 09:52:51.260756  3513 sgd_solver.cpp:106] Iteration 110700, lr = 0.004
I0523 09:53:00.529206  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_111000.caffemodel
I0523 09:53:00.589305  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_111000.solverstate
I0523 09:53:00.624861  3513 solver.cpp:237] Iteration 111000, loss = 0.946815
I0523 09:53:00.624908  3513 solver.cpp:253]     Train net output #0: loss = 0.946814 (* 1 = 0.946814 loss)
I0523 09:53:00.624923  3513 sgd_solver.cpp:106] Iteration 111000, lr = 0.004
I0523 09:53:09.924038  3513 solver.cpp:237] Iteration 111300, loss = 1.16166
I0523 09:53:09.924216  3513 solver.cpp:253]     Train net output #0: loss = 1.16166 (* 1 = 1.16166 loss)
I0523 09:53:09.924229  3513 sgd_solver.cpp:106] Iteration 111300, lr = 0.004
I0523 09:53:19.228327  3513 solver.cpp:237] Iteration 111600, loss = 1.15849
I0523 09:53:19.228363  3513 solver.cpp:253]     Train net output #0: loss = 1.15849 (* 1 = 1.15849 loss)
I0523 09:53:19.228376  3513 sgd_solver.cpp:106] Iteration 111600, lr = 0.004
I0523 09:53:28.532615  3513 solver.cpp:237] Iteration 111900, loss = 0.941747
I0523 09:53:28.532667  3513 solver.cpp:253]     Train net output #0: loss = 0.941746 (* 1 = 0.941746 loss)
I0523 09:53:28.532681  3513 sgd_solver.cpp:106] Iteration 111900, lr = 0.004
I0523 09:53:58.733950  3513 solver.cpp:237] Iteration 112200, loss = 1.12391
I0523 09:53:58.734149  3513 solver.cpp:253]     Train net output #0: loss = 1.12391 (* 1 = 1.12391 loss)
I0523 09:53:58.734164  3513 sgd_solver.cpp:106] Iteration 112200, lr = 0.004
I0523 09:54:08.032294  3513 solver.cpp:237] Iteration 112500, loss = 1.50722
I0523 09:54:08.032328  3513 solver.cpp:253]     Train net output #0: loss = 1.50722 (* 1 = 1.50722 loss)
I0523 09:54:08.032346  3513 sgd_solver.cpp:106] Iteration 112500, lr = 0.004
I0523 09:54:17.334206  3513 solver.cpp:237] Iteration 112800, loss = 0.969323
I0523 09:54:17.334260  3513 solver.cpp:253]     Train net output #0: loss = 0.969323 (* 1 = 0.969323 loss)
I0523 09:54:17.334277  3513 sgd_solver.cpp:106] Iteration 112800, lr = 0.004
I0523 09:54:26.635982  3513 solver.cpp:237] Iteration 113100, loss = 1.15425
I0523 09:54:26.636018  3513 solver.cpp:253]     Train net output #0: loss = 1.15425 (* 1 = 1.15425 loss)
I0523 09:54:26.636034  3513 sgd_solver.cpp:106] Iteration 113100, lr = 0.004
I0523 09:54:35.936061  3513 solver.cpp:237] Iteration 113400, loss = 1.3912
I0523 09:54:35.936231  3513 solver.cpp:253]     Train net output #0: loss = 1.3912 (* 1 = 1.3912 loss)
I0523 09:54:35.936245  3513 sgd_solver.cpp:106] Iteration 113400, lr = 0.004
I0523 09:54:45.237969  3513 solver.cpp:237] Iteration 113700, loss = 1.12051
I0523 09:54:45.238020  3513 solver.cpp:253]     Train net output #0: loss = 1.12051 (* 1 = 1.12051 loss)
I0523 09:54:45.238034  3513 sgd_solver.cpp:106] Iteration 113700, lr = 0.004
I0523 09:54:54.506845  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_114000.caffemodel
I0523 09:54:54.566390  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_114000.solverstate
I0523 09:54:54.591835  3513 solver.cpp:341] Iteration 114000, Testing net (#0)
I0523 09:55:42.086249  3513 solver.cpp:409]     Test net output #0: accuracy = 0.898736
I0523 09:55:42.086455  3513 solver.cpp:409]     Test net output #1: loss = 0.312846 (* 1 = 0.312846 loss)
I0523 09:56:02.983269  3513 solver.cpp:237] Iteration 114000, loss = 1.10063
I0523 09:56:02.983325  3513 solver.cpp:253]     Train net output #0: loss = 1.10063 (* 1 = 1.10063 loss)
I0523 09:56:02.983341  3513 sgd_solver.cpp:106] Iteration 114000, lr = 0.004
I0523 09:56:12.278403  3513 solver.cpp:237] Iteration 114300, loss = 1.17632
I0523 09:56:12.278584  3513 solver.cpp:253]     Train net output #0: loss = 1.17632 (* 1 = 1.17632 loss)
I0523 09:56:12.278599  3513 sgd_solver.cpp:106] Iteration 114300, lr = 0.004
I0523 09:56:21.577713  3513 solver.cpp:237] Iteration 114600, loss = 1.05833
I0523 09:56:21.577759  3513 solver.cpp:253]     Train net output #0: loss = 1.05833 (* 1 = 1.05833 loss)
I0523 09:56:21.577778  3513 sgd_solver.cpp:106] Iteration 114600, lr = 0.004
I0523 09:56:30.879159  3513 solver.cpp:237] Iteration 114900, loss = 1.14738
I0523 09:56:30.879195  3513 solver.cpp:253]     Train net output #0: loss = 1.14738 (* 1 = 1.14738 loss)
I0523 09:56:30.879211  3513 sgd_solver.cpp:106] Iteration 114900, lr = 0.004
I0523 09:56:40.170743  3513 solver.cpp:237] Iteration 115200, loss = 1.02537
I0523 09:56:40.170778  3513 solver.cpp:253]     Train net output #0: loss = 1.02537 (* 1 = 1.02537 loss)
I0523 09:56:40.170792  3513 sgd_solver.cpp:106] Iteration 115200, lr = 0.004
I0523 09:56:49.465494  3513 solver.cpp:237] Iteration 115500, loss = 1.0884
I0523 09:56:49.465685  3513 solver.cpp:253]     Train net output #0: loss = 1.0884 (* 1 = 1.0884 loss)
I0523 09:56:49.465699  3513 sgd_solver.cpp:106] Iteration 115500, lr = 0.004
I0523 09:56:58.762007  3513 solver.cpp:237] Iteration 115800, loss = 1.00669
I0523 09:56:58.762042  3513 solver.cpp:253]     Train net output #0: loss = 1.00669 (* 1 = 1.00669 loss)
I0523 09:56:58.762058  3513 sgd_solver.cpp:106] Iteration 115800, lr = 0.004
I0523 09:57:28.969082  3513 solver.cpp:237] Iteration 116100, loss = 1.0947
I0523 09:57:28.969282  3513 solver.cpp:253]     Train net output #0: loss = 1.0947 (* 1 = 1.0947 loss)
I0523 09:57:28.969298  3513 sgd_solver.cpp:106] Iteration 116100, lr = 0.004
I0523 09:57:38.256903  3513 solver.cpp:237] Iteration 116400, loss = 1.1517
I0523 09:57:38.256947  3513 solver.cpp:253]     Train net output #0: loss = 1.1517 (* 1 = 1.1517 loss)
I0523 09:57:38.256961  3513 sgd_solver.cpp:106] Iteration 116400, lr = 0.004
I0523 09:57:47.551570  3513 solver.cpp:237] Iteration 116700, loss = 0.789153
I0523 09:57:47.551606  3513 solver.cpp:253]     Train net output #0: loss = 0.789153 (* 1 = 0.789153 loss)
I0523 09:57:47.551623  3513 sgd_solver.cpp:106] Iteration 116700, lr = 0.004
I0523 09:57:56.813902  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_117000.caffemodel
I0523 09:57:56.873497  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_117000.solverstate
I0523 09:57:56.908293  3513 solver.cpp:237] Iteration 117000, loss = 1.5341
I0523 09:57:56.908340  3513 solver.cpp:253]     Train net output #0: loss = 1.5341 (* 1 = 1.5341 loss)
I0523 09:57:56.908354  3513 sgd_solver.cpp:106] Iteration 117000, lr = 0.004
I0523 09:58:06.204795  3513 solver.cpp:237] Iteration 117300, loss = 1.10976
I0523 09:58:06.204998  3513 solver.cpp:253]     Train net output #0: loss = 1.10976 (* 1 = 1.10976 loss)
I0523 09:58:06.205013  3513 sgd_solver.cpp:106] Iteration 117300, lr = 0.004
I0523 09:58:15.500172  3513 solver.cpp:237] Iteration 117600, loss = 1.32534
I0523 09:58:15.500207  3513 solver.cpp:253]     Train net output #0: loss = 1.32534 (* 1 = 1.32534 loss)
I0523 09:58:15.500223  3513 sgd_solver.cpp:106] Iteration 117600, lr = 0.004
I0523 09:58:24.791283  3513 solver.cpp:237] Iteration 117900, loss = 1.097
I0523 09:58:24.791327  3513 solver.cpp:253]     Train net output #0: loss = 1.097 (* 1 = 1.097 loss)
I0523 09:58:24.791344  3513 sgd_solver.cpp:106] Iteration 117900, lr = 0.004
I0523 09:58:55.002235  3513 solver.cpp:237] Iteration 118200, loss = 1.16209
I0523 09:58:55.002439  3513 solver.cpp:253]     Train net output #0: loss = 1.16208 (* 1 = 1.16208 loss)
I0523 09:58:55.002454  3513 sgd_solver.cpp:106] Iteration 118200, lr = 0.004
I0523 09:59:04.299823  3513 solver.cpp:237] Iteration 118500, loss = 1.19208
I0523 09:59:04.299857  3513 solver.cpp:253]     Train net output #0: loss = 1.19208 (* 1 = 1.19208 loss)
I0523 09:59:04.299871  3513 sgd_solver.cpp:106] Iteration 118500, lr = 0.004
I0523 09:59:13.596981  3513 solver.cpp:237] Iteration 118800, loss = 1.22282
I0523 09:59:13.597026  3513 solver.cpp:253]     Train net output #0: loss = 1.22282 (* 1 = 1.22282 loss)
I0523 09:59:13.597048  3513 sgd_solver.cpp:106] Iteration 118800, lr = 0.004
I0523 09:59:22.891016  3513 solver.cpp:237] Iteration 119100, loss = 1.16243
I0523 09:59:22.891052  3513 solver.cpp:253]     Train net output #0: loss = 1.16243 (* 1 = 1.16243 loss)
I0523 09:59:22.891065  3513 sgd_solver.cpp:106] Iteration 119100, lr = 0.004
I0523 09:59:32.189739  3513 solver.cpp:237] Iteration 119400, loss = 1.26042
I0523 09:59:32.189909  3513 solver.cpp:253]     Train net output #0: loss = 1.26042 (* 1 = 1.26042 loss)
I0523 09:59:32.189923  3513 sgd_solver.cpp:106] Iteration 119400, lr = 0.004
I0523 09:59:41.489842  3513 solver.cpp:237] Iteration 119700, loss = 1.34112
I0523 09:59:41.489888  3513 solver.cpp:253]     Train net output #0: loss = 1.34112 (* 1 = 1.34112 loss)
I0523 09:59:41.489905  3513 sgd_solver.cpp:106] Iteration 119700, lr = 0.004
I0523 09:59:50.752177  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_120000.caffemodel
I0523 09:59:50.813088  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_120000.solverstate
I0523 09:59:50.840443  3513 solver.cpp:341] Iteration 120000, Testing net (#0)
I0523 10:00:59.554960  3513 solver.cpp:409]     Test net output #0: accuracy = 0.899643
I0523 10:00:59.555161  3513 solver.cpp:409]     Test net output #1: loss = 0.31152 (* 1 = 0.31152 loss)
I0523 10:01:20.435441  3513 solver.cpp:237] Iteration 120000, loss = 1.0106
I0523 10:01:20.435495  3513 solver.cpp:253]     Train net output #0: loss = 1.0106 (* 1 = 1.0106 loss)
I0523 10:01:20.435513  3513 sgd_solver.cpp:106] Iteration 120000, lr = 0.004
I0523 10:01:29.734740  3513 solver.cpp:237] Iteration 120300, loss = 0.93658
I0523 10:01:29.734921  3513 solver.cpp:253]     Train net output #0: loss = 0.93658 (* 1 = 0.93658 loss)
I0523 10:01:29.734935  3513 sgd_solver.cpp:106] Iteration 120300, lr = 0.004
I0523 10:01:39.035778  3513 solver.cpp:237] Iteration 120600, loss = 1.42284
I0523 10:01:39.035811  3513 solver.cpp:253]     Train net output #0: loss = 1.42284 (* 1 = 1.42284 loss)
I0523 10:01:39.035837  3513 sgd_solver.cpp:106] Iteration 120600, lr = 0.004
I0523 10:01:48.342979  3513 solver.cpp:237] Iteration 120900, loss = 1.20437
I0523 10:01:48.343020  3513 solver.cpp:253]     Train net output #0: loss = 1.20437 (* 1 = 1.20437 loss)
I0523 10:01:48.343042  3513 sgd_solver.cpp:106] Iteration 120900, lr = 0.004
I0523 10:01:57.647976  3513 solver.cpp:237] Iteration 121200, loss = 1.07149
I0523 10:01:57.648012  3513 solver.cpp:253]     Train net output #0: loss = 1.07149 (* 1 = 1.07149 loss)
I0523 10:01:57.648028  3513 sgd_solver.cpp:106] Iteration 121200, lr = 0.004
I0523 10:02:06.951776  3513 solver.cpp:237] Iteration 121500, loss = 1.32284
I0523 10:02:06.951963  3513 solver.cpp:253]     Train net output #0: loss = 1.32284 (* 1 = 1.32284 loss)
I0523 10:02:06.951977  3513 sgd_solver.cpp:106] Iteration 121500, lr = 0.004
I0523 10:02:16.257109  3513 solver.cpp:237] Iteration 121800, loss = 1.051
I0523 10:02:16.257158  3513 solver.cpp:253]     Train net output #0: loss = 1.051 (* 1 = 1.051 loss)
I0523 10:02:16.257174  3513 sgd_solver.cpp:106] Iteration 121800, lr = 0.004
I0523 10:02:46.454351  3513 solver.cpp:237] Iteration 122100, loss = 1.35826
I0523 10:02:46.454552  3513 solver.cpp:253]     Train net output #0: loss = 1.35826 (* 1 = 1.35826 loss)
I0523 10:02:46.454567  3513 sgd_solver.cpp:106] Iteration 122100, lr = 0.004
I0523 10:02:55.761234  3513 solver.cpp:237] Iteration 122400, loss = 1.29131
I0523 10:02:55.761270  3513 solver.cpp:253]     Train net output #0: loss = 1.29131 (* 1 = 1.29131 loss)
I0523 10:02:55.761286  3513 sgd_solver.cpp:106] Iteration 122400, lr = 0.004
I0523 10:03:05.062103  3513 solver.cpp:237] Iteration 122700, loss = 1.25521
I0523 10:03:05.062147  3513 solver.cpp:253]     Train net output #0: loss = 1.25521 (* 1 = 1.25521 loss)
I0523 10:03:05.062167  3513 sgd_solver.cpp:106] Iteration 122700, lr = 0.004
I0523 10:03:14.337236  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_123000.caffemodel
I0523 10:03:14.397153  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_123000.solverstate
I0523 10:03:14.432014  3513 solver.cpp:237] Iteration 123000, loss = 0.950859
I0523 10:03:14.432059  3513 solver.cpp:253]     Train net output #0: loss = 0.950859 (* 1 = 0.950859 loss)
I0523 10:03:14.432078  3513 sgd_solver.cpp:106] Iteration 123000, lr = 0.004
I0523 10:03:23.736428  3513 solver.cpp:237] Iteration 123300, loss = 1.31852
I0523 10:03:23.736611  3513 solver.cpp:253]     Train net output #0: loss = 1.31852 (* 1 = 1.31852 loss)
I0523 10:03:23.736625  3513 sgd_solver.cpp:106] Iteration 123300, lr = 0.004
I0523 10:03:33.039652  3513 solver.cpp:237] Iteration 123600, loss = 1.02638
I0523 10:03:33.039686  3513 solver.cpp:253]     Train net output #0: loss = 1.02638 (* 1 = 1.02638 loss)
I0523 10:03:33.039705  3513 sgd_solver.cpp:106] Iteration 123600, lr = 0.004
I0523 10:03:42.340145  3513 solver.cpp:237] Iteration 123900, loss = 1.17286
I0523 10:03:42.340180  3513 solver.cpp:253]     Train net output #0: loss = 1.17286 (* 1 = 1.17286 loss)
I0523 10:03:42.340196  3513 sgd_solver.cpp:106] Iteration 123900, lr = 0.004
I0523 10:04:12.540916  3513 solver.cpp:237] Iteration 124200, loss = 1.10211
I0523 10:04:12.541128  3513 solver.cpp:253]     Train net output #0: loss = 1.10211 (* 1 = 1.10211 loss)
I0523 10:04:12.541144  3513 sgd_solver.cpp:106] Iteration 124200, lr = 0.004
I0523 10:04:21.848014  3513 solver.cpp:237] Iteration 124500, loss = 0.754062
I0523 10:04:21.848058  3513 solver.cpp:253]     Train net output #0: loss = 0.754062 (* 1 = 0.754062 loss)
I0523 10:04:21.848079  3513 sgd_solver.cpp:106] Iteration 124500, lr = 0.004
I0523 10:04:31.156608  3513 solver.cpp:237] Iteration 124800, loss = 1.29262
I0523 10:04:31.156643  3513 solver.cpp:253]     Train net output #0: loss = 1.29262 (* 1 = 1.29262 loss)
I0523 10:04:31.156657  3513 sgd_solver.cpp:106] Iteration 124800, lr = 0.004
I0523 10:04:40.463410  3513 solver.cpp:237] Iteration 125100, loss = 1.21719
I0523 10:04:40.463459  3513 solver.cpp:253]     Train net output #0: loss = 1.21719 (* 1 = 1.21719 loss)
I0523 10:04:40.463477  3513 sgd_solver.cpp:106] Iteration 125100, lr = 0.004
I0523 10:04:49.767002  3513 solver.cpp:237] Iteration 125400, loss = 1.15557
I0523 10:04:49.767200  3513 solver.cpp:253]     Train net output #0: loss = 1.15557 (* 1 = 1.15557 loss)
I0523 10:04:49.767215  3513 sgd_solver.cpp:106] Iteration 125400, lr = 0.004
I0523 10:04:59.073127  3513 solver.cpp:237] Iteration 125700, loss = 0.907431
I0523 10:04:59.073163  3513 solver.cpp:253]     Train net output #0: loss = 0.90743 (* 1 = 0.90743 loss)
I0523 10:04:59.073176  3513 sgd_solver.cpp:106] Iteration 125700, lr = 0.004
I0523 10:05:08.347633  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_126000.caffemodel
I0523 10:05:08.406846  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_126000.solverstate
I0523 10:05:08.432034  3513 solver.cpp:341] Iteration 126000, Testing net (#0)
I0523 10:05:56.265811  3513 solver.cpp:409]     Test net output #0: accuracy = 0.901409
I0523 10:05:56.266015  3513 solver.cpp:409]     Test net output #1: loss = 0.331498 (* 1 = 0.331498 loss)
I0523 10:06:17.139060  3513 solver.cpp:237] Iteration 126000, loss = 1.12317
I0523 10:06:17.139116  3513 solver.cpp:253]     Train net output #0: loss = 1.12317 (* 1 = 1.12317 loss)
I0523 10:06:17.139130  3513 sgd_solver.cpp:106] Iteration 126000, lr = 0.004
I0523 10:06:26.427103  3513 solver.cpp:237] Iteration 126300, loss = 0.870665
I0523 10:06:26.427300  3513 solver.cpp:253]     Train net output #0: loss = 0.870665 (* 1 = 0.870665 loss)
I0523 10:06:26.427314  3513 sgd_solver.cpp:106] Iteration 126300, lr = 0.004
I0523 10:06:35.716724  3513 solver.cpp:237] Iteration 126600, loss = 1.10006
I0523 10:06:35.716758  3513 solver.cpp:253]     Train net output #0: loss = 1.10006 (* 1 = 1.10006 loss)
I0523 10:06:35.716773  3513 sgd_solver.cpp:106] Iteration 126600, lr = 0.004
I0523 10:06:45.002573  3513 solver.cpp:237] Iteration 126900, loss = 1.05525
I0523 10:06:45.002622  3513 solver.cpp:253]     Train net output #0: loss = 1.05524 (* 1 = 1.05524 loss)
I0523 10:06:45.002638  3513 sgd_solver.cpp:106] Iteration 126900, lr = 0.004
I0523 10:06:54.291851  3513 solver.cpp:237] Iteration 127200, loss = 1.19618
I0523 10:06:54.291887  3513 solver.cpp:253]     Train net output #0: loss = 1.19618 (* 1 = 1.19618 loss)
I0523 10:06:54.291904  3513 sgd_solver.cpp:106] Iteration 127200, lr = 0.004
I0523 10:07:03.578984  3513 solver.cpp:237] Iteration 127500, loss = 1.03417
I0523 10:07:03.579161  3513 solver.cpp:253]     Train net output #0: loss = 1.03417 (* 1 = 1.03417 loss)
I0523 10:07:03.579175  3513 sgd_solver.cpp:106] Iteration 127500, lr = 0.004
I0523 10:07:12.867123  3513 solver.cpp:237] Iteration 127800, loss = 1.02187
I0523 10:07:12.867177  3513 solver.cpp:253]     Train net output #0: loss = 1.02187 (* 1 = 1.02187 loss)
I0523 10:07:12.867192  3513 sgd_solver.cpp:106] Iteration 127800, lr = 0.004
I0523 10:07:43.031991  3513 solver.cpp:237] Iteration 128100, loss = 1.31999
I0523 10:07:43.032197  3513 solver.cpp:253]     Train net output #0: loss = 1.31999 (* 1 = 1.31999 loss)
I0523 10:07:43.032213  3513 sgd_solver.cpp:106] Iteration 128100, lr = 0.004
I0523 10:07:52.318403  3513 solver.cpp:237] Iteration 128400, loss = 1.16836
I0523 10:07:52.318437  3513 solver.cpp:253]     Train net output #0: loss = 1.16836 (* 1 = 1.16836 loss)
I0523 10:07:52.318455  3513 sgd_solver.cpp:106] Iteration 128400, lr = 0.004
I0523 10:08:01.602159  3513 solver.cpp:237] Iteration 128700, loss = 1.32098
I0523 10:08:01.602208  3513 solver.cpp:253]     Train net output #0: loss = 1.32098 (* 1 = 1.32098 loss)
I0523 10:08:01.602226  3513 sgd_solver.cpp:106] Iteration 128700, lr = 0.004
I0523 10:08:10.859714  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_129000.caffemodel
I0523 10:08:10.918493  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_129000.solverstate
I0523 10:08:10.953936  3513 solver.cpp:237] Iteration 129000, loss = 0.991061
I0523 10:08:10.953987  3513 solver.cpp:253]     Train net output #0: loss = 0.991061 (* 1 = 0.991061 loss)
I0523 10:08:10.954001  3513 sgd_solver.cpp:106] Iteration 129000, lr = 0.004
I0523 10:08:20.240706  3513 solver.cpp:237] Iteration 129300, loss = 1.07702
I0523 10:08:20.240892  3513 solver.cpp:253]     Train net output #0: loss = 1.07702 (* 1 = 1.07702 loss)
I0523 10:08:20.240906  3513 sgd_solver.cpp:106] Iteration 129300, lr = 0.004
I0523 10:08:29.527622  3513 solver.cpp:237] Iteration 129600, loss = 1.09804
I0523 10:08:29.527668  3513 solver.cpp:253]     Train net output #0: loss = 1.09804 (* 1 = 1.09804 loss)
I0523 10:08:29.527688  3513 sgd_solver.cpp:106] Iteration 129600, lr = 0.004
I0523 10:08:38.814239  3513 solver.cpp:237] Iteration 129900, loss = 1.11691
I0523 10:08:38.814275  3513 solver.cpp:253]     Train net output #0: loss = 1.11691 (* 1 = 1.11691 loss)
I0523 10:08:38.814291  3513 sgd_solver.cpp:106] Iteration 129900, lr = 0.004
I0523 10:09:08.990173  3513 solver.cpp:237] Iteration 130200, loss = 1.15548
I0523 10:09:08.990375  3513 solver.cpp:253]     Train net output #0: loss = 1.15548 (* 1 = 1.15548 loss)
I0523 10:09:08.990391  3513 sgd_solver.cpp:106] Iteration 130200, lr = 0.004
I0523 10:09:18.281172  3513 solver.cpp:237] Iteration 130500, loss = 1.02552
I0523 10:09:18.281220  3513 solver.cpp:253]     Train net output #0: loss = 1.02552 (* 1 = 1.02552 loss)
I0523 10:09:18.281239  3513 sgd_solver.cpp:106] Iteration 130500, lr = 0.004
I0523 10:09:27.570912  3513 solver.cpp:237] Iteration 130800, loss = 0.984323
I0523 10:09:27.570950  3513 solver.cpp:253]     Train net output #0: loss = 0.984323 (* 1 = 0.984323 loss)
I0523 10:09:27.570966  3513 sgd_solver.cpp:106] Iteration 130800, lr = 0.004
I0523 10:09:36.854013  3513 solver.cpp:237] Iteration 131100, loss = 0.956769
I0523 10:09:36.854048  3513 solver.cpp:253]     Train net output #0: loss = 0.956768 (* 1 = 0.956768 loss)
I0523 10:09:36.854064  3513 sgd_solver.cpp:106] Iteration 131100, lr = 0.004
I0523 10:09:46.145808  3513 solver.cpp:237] Iteration 131400, loss = 1.322
I0523 10:09:46.146003  3513 solver.cpp:253]     Train net output #0: loss = 1.322 (* 1 = 1.322 loss)
I0523 10:09:46.146018  3513 sgd_solver.cpp:106] Iteration 131400, lr = 0.004
I0523 10:09:55.427973  3513 solver.cpp:237] Iteration 131700, loss = 0.764032
I0523 10:09:55.428007  3513 solver.cpp:253]     Train net output #0: loss = 0.764031 (* 1 = 0.764031 loss)
I0523 10:09:55.428025  3513 sgd_solver.cpp:106] Iteration 131700, lr = 0.004
I0523 10:10:04.686486  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_132000.caffemodel
I0523 10:10:04.745746  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_132000.solverstate
I0523 10:10:04.770949  3513 solver.cpp:341] Iteration 132000, Testing net (#0)
I0523 10:11:13.478430  3513 solver.cpp:409]     Test net output #0: accuracy = 0.899836
I0523 10:11:13.478632  3513 solver.cpp:409]     Test net output #1: loss = 0.332598 (* 1 = 0.332598 loss)
I0523 10:11:34.399483  3513 solver.cpp:237] Iteration 132000, loss = 0.965409
I0523 10:11:34.399544  3513 solver.cpp:253]     Train net output #0: loss = 0.965409 (* 1 = 0.965409 loss)
I0523 10:11:34.399559  3513 sgd_solver.cpp:106] Iteration 132000, lr = 0.004
I0523 10:11:43.701102  3513 solver.cpp:237] Iteration 132300, loss = 0.905828
I0523 10:11:43.701314  3513 solver.cpp:253]     Train net output #0: loss = 0.905828 (* 1 = 0.905828 loss)
I0523 10:11:43.701328  3513 sgd_solver.cpp:106] Iteration 132300, lr = 0.004
I0523 10:11:53.002955  3513 solver.cpp:237] Iteration 132600, loss = 1.56279
I0523 10:11:53.002990  3513 solver.cpp:253]     Train net output #0: loss = 1.56279 (* 1 = 1.56279 loss)
I0523 10:11:53.003008  3513 sgd_solver.cpp:106] Iteration 132600, lr = 0.004
I0523 10:12:02.306430  3513 solver.cpp:237] Iteration 132900, loss = 0.980435
I0523 10:12:02.306465  3513 solver.cpp:253]     Train net output #0: loss = 0.980435 (* 1 = 0.980435 loss)
I0523 10:12:02.306483  3513 sgd_solver.cpp:106] Iteration 132900, lr = 0.004
I0523 10:12:11.611626  3513 solver.cpp:237] Iteration 133200, loss = 1.02272
I0523 10:12:11.611673  3513 solver.cpp:253]     Train net output #0: loss = 1.02272 (* 1 = 1.02272 loss)
I0523 10:12:11.611688  3513 sgd_solver.cpp:106] Iteration 133200, lr = 0.004
I0523 10:12:20.911993  3513 solver.cpp:237] Iteration 133500, loss = 1.29422
I0523 10:12:20.912170  3513 solver.cpp:253]     Train net output #0: loss = 1.29422 (* 1 = 1.29422 loss)
I0523 10:12:20.912184  3513 sgd_solver.cpp:106] Iteration 133500, lr = 0.004
I0523 10:12:30.212447  3513 solver.cpp:237] Iteration 133800, loss = 1.05259
I0523 10:12:30.212481  3513 solver.cpp:253]     Train net output #0: loss = 1.05259 (* 1 = 1.05259 loss)
I0523 10:12:30.212498  3513 sgd_solver.cpp:106] Iteration 133800, lr = 0.004
I0523 10:13:00.439244  3513 solver.cpp:237] Iteration 134100, loss = 0.942465
I0523 10:13:00.439448  3513 solver.cpp:253]     Train net output #0: loss = 0.942465 (* 1 = 0.942465 loss)
I0523 10:13:00.439465  3513 sgd_solver.cpp:106] Iteration 134100, lr = 0.004
I0523 10:13:09.742101  3513 solver.cpp:237] Iteration 134400, loss = 0.980591
I0523 10:13:09.742136  3513 solver.cpp:253]     Train net output #0: loss = 0.98059 (* 1 = 0.98059 loss)
I0523 10:13:09.742153  3513 sgd_solver.cpp:106] Iteration 134400, lr = 0.004
I0523 10:13:19.045382  3513 solver.cpp:237] Iteration 134700, loss = 1.12357
I0523 10:13:19.045416  3513 solver.cpp:253]     Train net output #0: loss = 1.12356 (* 1 = 1.12356 loss)
I0523 10:13:19.045433  3513 sgd_solver.cpp:106] Iteration 134700, lr = 0.004
I0523 10:13:28.315796  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_135000.caffemodel
I0523 10:13:28.377785  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_135000.solverstate
I0523 10:13:28.415076  3513 solver.cpp:237] Iteration 135000, loss = 1.07447
I0523 10:13:28.415127  3513 solver.cpp:253]     Train net output #0: loss = 1.07447 (* 1 = 1.07447 loss)
I0523 10:13:28.415148  3513 sgd_solver.cpp:106] Iteration 135000, lr = 0.004
I0523 10:13:37.719895  3513 solver.cpp:237] Iteration 135300, loss = 1.04753
I0523 10:13:37.720082  3513 solver.cpp:253]     Train net output #0: loss = 1.04753 (* 1 = 1.04753 loss)
I0523 10:13:37.720094  3513 sgd_solver.cpp:106] Iteration 135300, lr = 0.004
I0523 10:13:47.023545  3513 solver.cpp:237] Iteration 135600, loss = 1.28613
I0523 10:13:47.023579  3513 solver.cpp:253]     Train net output #0: loss = 1.28613 (* 1 = 1.28613 loss)
I0523 10:13:47.023597  3513 sgd_solver.cpp:106] Iteration 135600, lr = 0.004
I0523 10:13:56.329591  3513 solver.cpp:237] Iteration 135900, loss = 1.19633
I0523 10:13:56.329641  3513 solver.cpp:253]     Train net output #0: loss = 1.19633 (* 1 = 1.19633 loss)
I0523 10:13:56.329655  3513 sgd_solver.cpp:106] Iteration 135900, lr = 0.004
I0523 10:14:26.538645  3513 solver.cpp:237] Iteration 136200, loss = 1.25389
I0523 10:14:26.538851  3513 solver.cpp:253]     Train net output #0: loss = 1.25389 (* 1 = 1.25389 loss)
I0523 10:14:26.538866  3513 sgd_solver.cpp:106] Iteration 136200, lr = 0.004
I0523 10:14:35.841459  3513 solver.cpp:237] Iteration 136500, loss = 1.10345
I0523 10:14:35.841492  3513 solver.cpp:253]     Train net output #0: loss = 1.10345 (* 1 = 1.10345 loss)
I0523 10:14:35.841509  3513 sgd_solver.cpp:106] Iteration 136500, lr = 0.004
I0523 10:14:45.145345  3513 solver.cpp:237] Iteration 136800, loss = 1.31038
I0523 10:14:45.145391  3513 solver.cpp:253]     Train net output #0: loss = 1.31038 (* 1 = 1.31038 loss)
I0523 10:14:45.145412  3513 sgd_solver.cpp:106] Iteration 136800, lr = 0.004
I0523 10:14:54.447124  3513 solver.cpp:237] Iteration 137100, loss = 0.894603
I0523 10:14:54.447161  3513 solver.cpp:253]     Train net output #0: loss = 0.894603 (* 1 = 0.894603 loss)
I0523 10:14:54.447175  3513 sgd_solver.cpp:106] Iteration 137100, lr = 0.004
I0523 10:15:03.749289  3513 solver.cpp:237] Iteration 137400, loss = 1.11368
I0523 10:15:03.749493  3513 solver.cpp:253]     Train net output #0: loss = 1.11368 (* 1 = 1.11368 loss)
I0523 10:15:03.749507  3513 sgd_solver.cpp:106] Iteration 137400, lr = 0.004
I0523 10:15:13.053683  3513 solver.cpp:237] Iteration 137700, loss = 0.88677
I0523 10:15:13.053719  3513 solver.cpp:253]     Train net output #0: loss = 0.886769 (* 1 = 0.886769 loss)
I0523 10:15:13.053736  3513 sgd_solver.cpp:106] Iteration 137700, lr = 0.004
I0523 10:15:22.328240  3513 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_138000.caffemodel
I0523 10:15:22.387733  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0040_2016-05-20T15.49.07.678338_iter_138000.solverstate
I0523 10:15:22.413158  3513 solver.cpp:341] Iteration 138000, Testing net (#0)
I0523 10:16:09.928864  3513 solver.cpp:409]     Test net output #0: accuracy = 0.901496
I0523 10:16:09.929069  3513 solver.cpp:409]     Test net output #1: loss = 0.307615 (* 1 = 0.307615 loss)
I0523 10:16:30.807644  3513 solver.cpp:237] Iteration 138000, loss = 1.08905
I0523 10:16:30.807700  3513 solver.cpp:253]     Train net output #0: loss = 1.08905 (* 1 = 1.08905 loss)
I0523 10:16:30.807715  3513 sgd_solver.cpp:106] Iteration 138000, lr = 0.004
I0523 10:16:40.102273  3513 solver.cpp:237] Iteration 138300, loss = 0.922454
I0523 10:16:40.102458  3513 solver.cpp:253]     Train net output #0: loss = 0.922453 (* 1 = 0.922453 loss)
I0523 10:16:40.102471  3513 sgd_solver.cpp:106] Iteration 138300, lr = 0.004
I0523 10:16:49.396229  3513 solver.cpp:237] Iteration 138600, loss = 1.041
I0523 10:16:49.396275  3513 solver.cpp:253]     Train net output #0: loss = 1.041 (* 1 = 1.041 loss)
I0523 10:16:49.396291  3513 sgd_solver.cpp:106] Iteration 138600, lr = 0.004
I0523 10:16:58.693130  3513 solver.cpp:237] Iteration 138900, loss = 1.06617
I0523 10:16:58.693166  3513 solver.cpp:253]     Train net output #0: loss = 1.06617 (* 1 = 1.06617 loss)
I0523 10:16:58.693181  3513 sgd_solver.cpp:106] Iteration 138900, lr = 0.004
I0523 10:17:07.990263  3513 solver.cpp:237] Iteration 139200, loss = 1.34226
I0523 10:17:07.990298  3513 solver.cpp:253]     Train net output #0: loss = 1.34226 (* 1 = 1.34226 loss)
I0523 10:17:07.990314  3513 sgd_solver.cpp:106] Iteration 139200, lr = 0.004
I0523 10:17:17.287611  3513 solver.cpp:237] Iteration 139500, loss = 1.05334
I0523 10:17:17.287802  3513 solver.cpp:253]     Train net output #0: loss = 1.05334 (* 1 = 1.05334 loss)
I0523 10:17:17.287823  3513 sgd_solver.cpp:106] Iteration 139500, lr = 0.004
aprun: Apid 11253755: Caught signal Terminated, sending to application
aprun: Apid 11253755: Caught signal Terminated, sending to application
*** Aborted at 1464013040 (unix time) try "date -d @1464013040" if you are using GNU date ***
aprun: Apid 11253755: Caught signal Terminated, sending to application
PC: @     0x2aaab930eb81 (unknown)
*** SIGTERM (@0xdb6) received by PID 3513 (TID 0x2aaac746f900) from PID 3510; stack trace: ***
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab930eb81 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab928a368 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
=>> PBS: job killed: walltime 7219 exceeded limit 7200
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @           0x49ae02 caffe::Blob<>::gpu_data()
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11253755: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
