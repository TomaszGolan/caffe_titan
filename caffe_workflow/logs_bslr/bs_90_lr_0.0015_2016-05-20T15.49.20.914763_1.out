2809975
I0525 04:52:27.645555 20374 caffe.cpp:184] Using GPUs 0
I0525 04:52:28.068547 20374 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1666
test_interval: 3333
base_lr: 0.0015
display: 166
max_iter: 166660
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1666
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763.prototxt"
I0525 04:52:28.070488 20374 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763.prototxt
I0525 04:52:28.087363 20374 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 04:52:28.087429 20374 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 04:52:28.087808 20374 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 04:52:28.088004 20374 layer_factory.hpp:77] Creating layer data_hdf5
I0525 04:52:28.088032 20374 net.cpp:106] Creating Layer data_hdf5
I0525 04:52:28.088047 20374 net.cpp:411] data_hdf5 -> data
I0525 04:52:28.088079 20374 net.cpp:411] data_hdf5 -> label
I0525 04:52:28.088145 20374 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 04:52:28.089617 20374 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 04:52:28.092308 20374 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 04:52:49.655263 20374 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 04:52:49.660377 20374 net.cpp:150] Setting up data_hdf5
I0525 04:52:49.660418 20374 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 04:52:49.660436 20374 net.cpp:157] Top shape: 90 (90)
I0525 04:52:49.660449 20374 net.cpp:165] Memory required for data: 2286360
I0525 04:52:49.660480 20374 layer_factory.hpp:77] Creating layer conv1
I0525 04:52:49.660513 20374 net.cpp:106] Creating Layer conv1
I0525 04:52:49.660527 20374 net.cpp:454] conv1 <- data
I0525 04:52:49.660552 20374 net.cpp:411] conv1 -> conv1
I0525 04:52:50.025759 20374 net.cpp:150] Setting up conv1
I0525 04:52:50.025817 20374 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:52:50.025840 20374 net.cpp:165] Memory required for data: 27169560
I0525 04:52:50.025869 20374 layer_factory.hpp:77] Creating layer relu1
I0525 04:52:50.025898 20374 net.cpp:106] Creating Layer relu1
I0525 04:52:50.025933 20374 net.cpp:454] relu1 <- conv1
I0525 04:52:50.025949 20374 net.cpp:397] relu1 -> conv1 (in-place)
I0525 04:52:50.026478 20374 net.cpp:150] Setting up relu1
I0525 04:52:50.026500 20374 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:52:50.026513 20374 net.cpp:165] Memory required for data: 52052760
I0525 04:52:50.026530 20374 layer_factory.hpp:77] Creating layer pool1
I0525 04:52:50.026557 20374 net.cpp:106] Creating Layer pool1
I0525 04:52:50.026571 20374 net.cpp:454] pool1 <- conv1
I0525 04:52:50.026587 20374 net.cpp:411] pool1 -> pool1
I0525 04:52:50.026680 20374 net.cpp:150] Setting up pool1
I0525 04:52:50.026698 20374 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 04:52:50.026720 20374 net.cpp:165] Memory required for data: 64494360
I0525 04:52:50.026734 20374 layer_factory.hpp:77] Creating layer conv2
I0525 04:52:50.026758 20374 net.cpp:106] Creating Layer conv2
I0525 04:52:50.026772 20374 net.cpp:454] conv2 <- pool1
I0525 04:52:50.026790 20374 net.cpp:411] conv2 -> conv2
I0525 04:52:50.029556 20374 net.cpp:150] Setting up conv2
I0525 04:52:50.029587 20374 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:52:50.029603 20374 net.cpp:165] Memory required for data: 82379160
I0525 04:52:50.029630 20374 layer_factory.hpp:77] Creating layer relu2
I0525 04:52:50.029659 20374 net.cpp:106] Creating Layer relu2
I0525 04:52:50.029672 20374 net.cpp:454] relu2 <- conv2
I0525 04:52:50.029688 20374 net.cpp:397] relu2 -> conv2 (in-place)
I0525 04:52:50.030047 20374 net.cpp:150] Setting up relu2
I0525 04:52:50.030067 20374 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:52:50.030081 20374 net.cpp:165] Memory required for data: 100263960
I0525 04:52:50.030092 20374 layer_factory.hpp:77] Creating layer pool2
I0525 04:52:50.030118 20374 net.cpp:106] Creating Layer pool2
I0525 04:52:50.030131 20374 net.cpp:454] pool2 <- conv2
I0525 04:52:50.030148 20374 net.cpp:411] pool2 -> pool2
I0525 04:52:50.030242 20374 net.cpp:150] Setting up pool2
I0525 04:52:50.030261 20374 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 04:52:50.030283 20374 net.cpp:165] Memory required for data: 109206360
I0525 04:52:50.030297 20374 layer_factory.hpp:77] Creating layer conv3
I0525 04:52:50.030318 20374 net.cpp:106] Creating Layer conv3
I0525 04:52:50.030331 20374 net.cpp:454] conv3 <- pool2
I0525 04:52:50.030346 20374 net.cpp:411] conv3 -> conv3
I0525 04:52:50.032295 20374 net.cpp:150] Setting up conv3
I0525 04:52:50.032320 20374 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:52:50.032342 20374 net.cpp:165] Memory required for data: 118963800
I0525 04:52:50.032368 20374 layer_factory.hpp:77] Creating layer relu3
I0525 04:52:50.032397 20374 net.cpp:106] Creating Layer relu3
I0525 04:52:50.032410 20374 net.cpp:454] relu3 <- conv3
I0525 04:52:50.032426 20374 net.cpp:397] relu3 -> conv3 (in-place)
I0525 04:52:50.032925 20374 net.cpp:150] Setting up relu3
I0525 04:52:50.032949 20374 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:52:50.032963 20374 net.cpp:165] Memory required for data: 128721240
I0525 04:52:50.032979 20374 layer_factory.hpp:77] Creating layer pool3
I0525 04:52:50.033001 20374 net.cpp:106] Creating Layer pool3
I0525 04:52:50.033015 20374 net.cpp:454] pool3 <- conv3
I0525 04:52:50.033031 20374 net.cpp:411] pool3 -> pool3
I0525 04:52:50.033113 20374 net.cpp:150] Setting up pool3
I0525 04:52:50.033130 20374 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 04:52:50.033146 20374 net.cpp:165] Memory required for data: 133599960
I0525 04:52:50.033159 20374 layer_factory.hpp:77] Creating layer conv4
I0525 04:52:50.033185 20374 net.cpp:106] Creating Layer conv4
I0525 04:52:50.033200 20374 net.cpp:454] conv4 <- pool3
I0525 04:52:50.033216 20374 net.cpp:411] conv4 -> conv4
I0525 04:52:50.036193 20374 net.cpp:150] Setting up conv4
I0525 04:52:50.036226 20374 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:52:50.036240 20374 net.cpp:165] Memory required for data: 136865880
I0525 04:52:50.036259 20374 layer_factory.hpp:77] Creating layer relu4
I0525 04:52:50.036293 20374 net.cpp:106] Creating Layer relu4
I0525 04:52:50.036308 20374 net.cpp:454] relu4 <- conv4
I0525 04:52:50.036332 20374 net.cpp:397] relu4 -> conv4 (in-place)
I0525 04:52:50.036823 20374 net.cpp:150] Setting up relu4
I0525 04:52:50.036846 20374 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:52:50.036859 20374 net.cpp:165] Memory required for data: 140131800
I0525 04:52:50.036875 20374 layer_factory.hpp:77] Creating layer pool4
I0525 04:52:50.036900 20374 net.cpp:106] Creating Layer pool4
I0525 04:52:50.036912 20374 net.cpp:454] pool4 <- conv4
I0525 04:52:50.036928 20374 net.cpp:411] pool4 -> pool4
I0525 04:52:50.037011 20374 net.cpp:150] Setting up pool4
I0525 04:52:50.037029 20374 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 04:52:50.037044 20374 net.cpp:165] Memory required for data: 141764760
I0525 04:52:50.037055 20374 layer_factory.hpp:77] Creating layer ip1
I0525 04:52:50.037084 20374 net.cpp:106] Creating Layer ip1
I0525 04:52:50.037097 20374 net.cpp:454] ip1 <- pool4
I0525 04:52:50.037113 20374 net.cpp:411] ip1 -> ip1
I0525 04:52:50.052528 20374 net.cpp:150] Setting up ip1
I0525 04:52:50.052566 20374 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:52:50.052579 20374 net.cpp:165] Memory required for data: 141835320
I0525 04:52:50.052609 20374 layer_factory.hpp:77] Creating layer relu5
I0525 04:52:50.052626 20374 net.cpp:106] Creating Layer relu5
I0525 04:52:50.052639 20374 net.cpp:454] relu5 <- ip1
I0525 04:52:50.052669 20374 net.cpp:397] relu5 -> ip1 (in-place)
I0525 04:52:50.053037 20374 net.cpp:150] Setting up relu5
I0525 04:52:50.053057 20374 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:52:50.053071 20374 net.cpp:165] Memory required for data: 141905880
I0525 04:52:50.053086 20374 layer_factory.hpp:77] Creating layer drop1
I0525 04:52:50.053117 20374 net.cpp:106] Creating Layer drop1
I0525 04:52:50.053131 20374 net.cpp:454] drop1 <- ip1
I0525 04:52:50.053156 20374 net.cpp:397] drop1 -> ip1 (in-place)
I0525 04:52:50.053232 20374 net.cpp:150] Setting up drop1
I0525 04:52:50.053256 20374 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:52:50.053269 20374 net.cpp:165] Memory required for data: 141976440
I0525 04:52:50.053284 20374 layer_factory.hpp:77] Creating layer ip2
I0525 04:52:50.053311 20374 net.cpp:106] Creating Layer ip2
I0525 04:52:50.053325 20374 net.cpp:454] ip2 <- ip1
I0525 04:52:50.053341 20374 net.cpp:411] ip2 -> ip2
I0525 04:52:50.053829 20374 net.cpp:150] Setting up ip2
I0525 04:52:50.053849 20374 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:52:50.053861 20374 net.cpp:165] Memory required for data: 142011720
I0525 04:52:50.053882 20374 layer_factory.hpp:77] Creating layer relu6
I0525 04:52:50.053903 20374 net.cpp:106] Creating Layer relu6
I0525 04:52:50.053917 20374 net.cpp:454] relu6 <- ip2
I0525 04:52:50.053932 20374 net.cpp:397] relu6 -> ip2 (in-place)
I0525 04:52:50.054502 20374 net.cpp:150] Setting up relu6
I0525 04:52:50.054524 20374 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:52:50.054538 20374 net.cpp:165] Memory required for data: 142047000
I0525 04:52:50.054553 20374 layer_factory.hpp:77] Creating layer drop2
I0525 04:52:50.054569 20374 net.cpp:106] Creating Layer drop2
I0525 04:52:50.054591 20374 net.cpp:454] drop2 <- ip2
I0525 04:52:50.054607 20374 net.cpp:397] drop2 -> ip2 (in-place)
I0525 04:52:50.054662 20374 net.cpp:150] Setting up drop2
I0525 04:52:50.054678 20374 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:52:50.054692 20374 net.cpp:165] Memory required for data: 142082280
I0525 04:52:50.054707 20374 layer_factory.hpp:77] Creating layer ip3
I0525 04:52:50.054723 20374 net.cpp:106] Creating Layer ip3
I0525 04:52:50.054738 20374 net.cpp:454] ip3 <- ip2
I0525 04:52:50.054761 20374 net.cpp:411] ip3 -> ip3
I0525 04:52:50.054983 20374 net.cpp:150] Setting up ip3
I0525 04:52:50.055002 20374 net.cpp:157] Top shape: 90 11 (990)
I0525 04:52:50.055016 20374 net.cpp:165] Memory required for data: 142086240
I0525 04:52:50.055037 20374 layer_factory.hpp:77] Creating layer drop3
I0525 04:52:50.055058 20374 net.cpp:106] Creating Layer drop3
I0525 04:52:50.055073 20374 net.cpp:454] drop3 <- ip3
I0525 04:52:50.055088 20374 net.cpp:397] drop3 -> ip3 (in-place)
I0525 04:52:50.055132 20374 net.cpp:150] Setting up drop3
I0525 04:52:50.055155 20374 net.cpp:157] Top shape: 90 11 (990)
I0525 04:52:50.055167 20374 net.cpp:165] Memory required for data: 142090200
I0525 04:52:50.055188 20374 layer_factory.hpp:77] Creating layer loss
I0525 04:52:50.055209 20374 net.cpp:106] Creating Layer loss
I0525 04:52:50.055224 20374 net.cpp:454] loss <- ip3
I0525 04:52:50.055244 20374 net.cpp:454] loss <- label
I0525 04:52:50.055259 20374 net.cpp:411] loss -> loss
I0525 04:52:50.055279 20374 layer_factory.hpp:77] Creating layer loss
I0525 04:52:50.055951 20374 net.cpp:150] Setting up loss
I0525 04:52:50.055974 20374 net.cpp:157] Top shape: (1)
I0525 04:52:50.055990 20374 net.cpp:160]     with loss weight 1
I0525 04:52:50.056051 20374 net.cpp:165] Memory required for data: 142090204
I0525 04:52:50.056064 20374 net.cpp:226] loss needs backward computation.
I0525 04:52:50.056079 20374 net.cpp:226] drop3 needs backward computation.
I0525 04:52:50.056097 20374 net.cpp:226] ip3 needs backward computation.
I0525 04:52:50.056109 20374 net.cpp:226] drop2 needs backward computation.
I0525 04:52:50.056121 20374 net.cpp:226] relu6 needs backward computation.
I0525 04:52:50.056136 20374 net.cpp:226] ip2 needs backward computation.
I0525 04:52:50.056155 20374 net.cpp:226] drop1 needs backward computation.
I0525 04:52:50.056169 20374 net.cpp:226] relu5 needs backward computation.
I0525 04:52:50.056181 20374 net.cpp:226] ip1 needs backward computation.
I0525 04:52:50.056197 20374 net.cpp:226] pool4 needs backward computation.
I0525 04:52:50.056210 20374 net.cpp:226] relu4 needs backward computation.
I0525 04:52:50.056222 20374 net.cpp:226] conv4 needs backward computation.
I0525 04:52:50.056234 20374 net.cpp:226] pool3 needs backward computation.
I0525 04:52:50.056251 20374 net.cpp:226] relu3 needs backward computation.
I0525 04:52:50.056279 20374 net.cpp:226] conv3 needs backward computation.
I0525 04:52:50.056293 20374 net.cpp:226] pool2 needs backward computation.
I0525 04:52:50.056308 20374 net.cpp:226] relu2 needs backward computation.
I0525 04:52:50.056319 20374 net.cpp:226] conv2 needs backward computation.
I0525 04:52:50.056341 20374 net.cpp:226] pool1 needs backward computation.
I0525 04:52:50.056361 20374 net.cpp:226] relu1 needs backward computation.
I0525 04:52:50.056375 20374 net.cpp:226] conv1 needs backward computation.
I0525 04:52:50.056387 20374 net.cpp:228] data_hdf5 does not need backward computation.
I0525 04:52:50.056401 20374 net.cpp:270] This network produces output loss
I0525 04:52:50.056429 20374 net.cpp:283] Network initialization done.
I0525 04:52:50.058156 20374 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763.prototxt
I0525 04:52:50.058233 20374 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 04:52:50.058589 20374 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 04:52:50.058787 20374 layer_factory.hpp:77] Creating layer data_hdf5
I0525 04:52:50.058807 20374 net.cpp:106] Creating Layer data_hdf5
I0525 04:52:50.058823 20374 net.cpp:411] data_hdf5 -> data
I0525 04:52:50.058846 20374 net.cpp:411] data_hdf5 -> label
I0525 04:52:50.058866 20374 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 04:52:50.060209 20374 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 04:53:11.377465 20374 net.cpp:150] Setting up data_hdf5
I0525 04:53:11.377635 20374 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 04:53:11.377653 20374 net.cpp:157] Top shape: 90 (90)
I0525 04:53:11.377665 20374 net.cpp:165] Memory required for data: 2286360
I0525 04:53:11.377681 20374 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 04:53:11.377714 20374 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 04:53:11.377727 20374 net.cpp:454] label_data_hdf5_1_split <- label
I0525 04:53:11.377763 20374 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 04:53:11.377787 20374 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 04:53:11.377873 20374 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 04:53:11.377892 20374 net.cpp:157] Top shape: 90 (90)
I0525 04:53:11.377907 20374 net.cpp:157] Top shape: 90 (90)
I0525 04:53:11.377921 20374 net.cpp:165] Memory required for data: 2287080
I0525 04:53:11.377933 20374 layer_factory.hpp:77] Creating layer conv1
I0525 04:53:11.377959 20374 net.cpp:106] Creating Layer conv1
I0525 04:53:11.377981 20374 net.cpp:454] conv1 <- data
I0525 04:53:11.377998 20374 net.cpp:411] conv1 -> conv1
I0525 04:53:11.379958 20374 net.cpp:150] Setting up conv1
I0525 04:53:11.379984 20374 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:53:11.380004 20374 net.cpp:165] Memory required for data: 27170280
I0525 04:53:11.380028 20374 layer_factory.hpp:77] Creating layer relu1
I0525 04:53:11.380049 20374 net.cpp:106] Creating Layer relu1
I0525 04:53:11.380070 20374 net.cpp:454] relu1 <- conv1
I0525 04:53:11.380086 20374 net.cpp:397] relu1 -> conv1 (in-place)
I0525 04:53:11.380609 20374 net.cpp:150] Setting up relu1
I0525 04:53:11.380632 20374 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:53:11.380645 20374 net.cpp:165] Memory required for data: 52053480
I0525 04:53:11.380658 20374 layer_factory.hpp:77] Creating layer pool1
I0525 04:53:11.380688 20374 net.cpp:106] Creating Layer pool1
I0525 04:53:11.380702 20374 net.cpp:454] pool1 <- conv1
I0525 04:53:11.380717 20374 net.cpp:411] pool1 -> pool1
I0525 04:53:11.380806 20374 net.cpp:150] Setting up pool1
I0525 04:53:11.380823 20374 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 04:53:11.380836 20374 net.cpp:165] Memory required for data: 64495080
I0525 04:53:11.380848 20374 layer_factory.hpp:77] Creating layer conv2
I0525 04:53:11.380872 20374 net.cpp:106] Creating Layer conv2
I0525 04:53:11.380892 20374 net.cpp:454] conv2 <- pool1
I0525 04:53:11.380910 20374 net.cpp:411] conv2 -> conv2
I0525 04:53:11.382860 20374 net.cpp:150] Setting up conv2
I0525 04:53:11.382885 20374 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:53:11.382905 20374 net.cpp:165] Memory required for data: 82379880
I0525 04:53:11.382927 20374 layer_factory.hpp:77] Creating layer relu2
I0525 04:53:11.382947 20374 net.cpp:106] Creating Layer relu2
I0525 04:53:11.382968 20374 net.cpp:454] relu2 <- conv2
I0525 04:53:11.382985 20374 net.cpp:397] relu2 -> conv2 (in-place)
I0525 04:53:11.383337 20374 net.cpp:150] Setting up relu2
I0525 04:53:11.383358 20374 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:53:11.383370 20374 net.cpp:165] Memory required for data: 100264680
I0525 04:53:11.383385 20374 layer_factory.hpp:77] Creating layer pool2
I0525 04:53:11.383402 20374 net.cpp:106] Creating Layer pool2
I0525 04:53:11.383421 20374 net.cpp:454] pool2 <- conv2
I0525 04:53:11.383437 20374 net.cpp:411] pool2 -> pool2
I0525 04:53:11.383527 20374 net.cpp:150] Setting up pool2
I0525 04:53:11.383549 20374 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 04:53:11.383563 20374 net.cpp:165] Memory required for data: 109207080
I0525 04:53:11.383577 20374 layer_factory.hpp:77] Creating layer conv3
I0525 04:53:11.383605 20374 net.cpp:106] Creating Layer conv3
I0525 04:53:11.383620 20374 net.cpp:454] conv3 <- pool2
I0525 04:53:11.383635 20374 net.cpp:411] conv3 -> conv3
I0525 04:53:11.385665 20374 net.cpp:150] Setting up conv3
I0525 04:53:11.385690 20374 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:53:11.385710 20374 net.cpp:165] Memory required for data: 118964520
I0525 04:53:11.385749 20374 layer_factory.hpp:77] Creating layer relu3
I0525 04:53:11.385774 20374 net.cpp:106] Creating Layer relu3
I0525 04:53:11.385788 20374 net.cpp:454] relu3 <- conv3
I0525 04:53:11.385804 20374 net.cpp:397] relu3 -> conv3 (in-place)
I0525 04:53:11.386298 20374 net.cpp:150] Setting up relu3
I0525 04:53:11.386322 20374 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:53:11.386334 20374 net.cpp:165] Memory required for data: 128721960
I0525 04:53:11.386350 20374 layer_factory.hpp:77] Creating layer pool3
I0525 04:53:11.386374 20374 net.cpp:106] Creating Layer pool3
I0525 04:53:11.386387 20374 net.cpp:454] pool3 <- conv3
I0525 04:53:11.386404 20374 net.cpp:411] pool3 -> pool3
I0525 04:53:11.386489 20374 net.cpp:150] Setting up pool3
I0525 04:53:11.386507 20374 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 04:53:11.386521 20374 net.cpp:165] Memory required for data: 133600680
I0525 04:53:11.386534 20374 layer_factory.hpp:77] Creating layer conv4
I0525 04:53:11.386561 20374 net.cpp:106] Creating Layer conv4
I0525 04:53:11.386574 20374 net.cpp:454] conv4 <- pool3
I0525 04:53:11.386591 20374 net.cpp:411] conv4 -> conv4
I0525 04:53:11.388710 20374 net.cpp:150] Setting up conv4
I0525 04:53:11.388734 20374 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:53:11.388747 20374 net.cpp:165] Memory required for data: 136866600
I0525 04:53:11.388766 20374 layer_factory.hpp:77] Creating layer relu4
I0525 04:53:11.388784 20374 net.cpp:106] Creating Layer relu4
I0525 04:53:11.388797 20374 net.cpp:454] relu4 <- conv4
I0525 04:53:11.388813 20374 net.cpp:397] relu4 -> conv4 (in-place)
I0525 04:53:11.389314 20374 net.cpp:150] Setting up relu4
I0525 04:53:11.389338 20374 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:53:11.389350 20374 net.cpp:165] Memory required for data: 140132520
I0525 04:53:11.389365 20374 layer_factory.hpp:77] Creating layer pool4
I0525 04:53:11.389390 20374 net.cpp:106] Creating Layer pool4
I0525 04:53:11.389405 20374 net.cpp:454] pool4 <- conv4
I0525 04:53:11.389420 20374 net.cpp:411] pool4 -> pool4
I0525 04:53:11.389508 20374 net.cpp:150] Setting up pool4
I0525 04:53:11.389525 20374 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 04:53:11.389539 20374 net.cpp:165] Memory required for data: 141765480
I0525 04:53:11.389552 20374 layer_factory.hpp:77] Creating layer ip1
I0525 04:53:11.389576 20374 net.cpp:106] Creating Layer ip1
I0525 04:53:11.389590 20374 net.cpp:454] ip1 <- pool4
I0525 04:53:11.389605 20374 net.cpp:411] ip1 -> ip1
I0525 04:53:11.405138 20374 net.cpp:150] Setting up ip1
I0525 04:53:11.405174 20374 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:53:11.405186 20374 net.cpp:165] Memory required for data: 141836040
I0525 04:53:11.405216 20374 layer_factory.hpp:77] Creating layer relu5
I0525 04:53:11.405246 20374 net.cpp:106] Creating Layer relu5
I0525 04:53:11.405261 20374 net.cpp:454] relu5 <- ip1
I0525 04:53:11.405277 20374 net.cpp:397] relu5 -> ip1 (in-place)
I0525 04:53:11.405643 20374 net.cpp:150] Setting up relu5
I0525 04:53:11.405663 20374 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:53:11.405678 20374 net.cpp:165] Memory required for data: 141906600
I0525 04:53:11.405692 20374 layer_factory.hpp:77] Creating layer drop1
I0525 04:53:11.405720 20374 net.cpp:106] Creating Layer drop1
I0525 04:53:11.405735 20374 net.cpp:454] drop1 <- ip1
I0525 04:53:11.405750 20374 net.cpp:397] drop1 -> ip1 (in-place)
I0525 04:53:11.405812 20374 net.cpp:150] Setting up drop1
I0525 04:53:11.405827 20374 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:53:11.405848 20374 net.cpp:165] Memory required for data: 141977160
I0525 04:53:11.405860 20374 layer_factory.hpp:77] Creating layer ip2
I0525 04:53:11.405877 20374 net.cpp:106] Creating Layer ip2
I0525 04:53:11.405892 20374 net.cpp:454] ip2 <- ip1
I0525 04:53:11.405917 20374 net.cpp:411] ip2 -> ip2
I0525 04:53:11.406412 20374 net.cpp:150] Setting up ip2
I0525 04:53:11.406432 20374 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:53:11.406445 20374 net.cpp:165] Memory required for data: 142012440
I0525 04:53:11.406466 20374 layer_factory.hpp:77] Creating layer relu6
I0525 04:53:11.406502 20374 net.cpp:106] Creating Layer relu6
I0525 04:53:11.406514 20374 net.cpp:454] relu6 <- ip2
I0525 04:53:11.406530 20374 net.cpp:397] relu6 -> ip2 (in-place)
I0525 04:53:11.407091 20374 net.cpp:150] Setting up relu6
I0525 04:53:11.407114 20374 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:53:11.407127 20374 net.cpp:165] Memory required for data: 142047720
I0525 04:53:11.407140 20374 layer_factory.hpp:77] Creating layer drop2
I0525 04:53:11.407168 20374 net.cpp:106] Creating Layer drop2
I0525 04:53:11.407181 20374 net.cpp:454] drop2 <- ip2
I0525 04:53:11.407198 20374 net.cpp:397] drop2 -> ip2 (in-place)
I0525 04:53:11.407256 20374 net.cpp:150] Setting up drop2
I0525 04:53:11.407272 20374 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:53:11.407285 20374 net.cpp:165] Memory required for data: 142083000
I0525 04:53:11.407297 20374 layer_factory.hpp:77] Creating layer ip3
I0525 04:53:11.407317 20374 net.cpp:106] Creating Layer ip3
I0525 04:53:11.407330 20374 net.cpp:454] ip3 <- ip2
I0525 04:53:11.407353 20374 net.cpp:411] ip3 -> ip3
I0525 04:53:11.407591 20374 net.cpp:150] Setting up ip3
I0525 04:53:11.407610 20374 net.cpp:157] Top shape: 90 11 (990)
I0525 04:53:11.407624 20374 net.cpp:165] Memory required for data: 142086960
I0525 04:53:11.407644 20374 layer_factory.hpp:77] Creating layer drop3
I0525 04:53:11.407666 20374 net.cpp:106] Creating Layer drop3
I0525 04:53:11.407680 20374 net.cpp:454] drop3 <- ip3
I0525 04:53:11.407696 20374 net.cpp:397] drop3 -> ip3 (in-place)
I0525 04:53:11.407744 20374 net.cpp:150] Setting up drop3
I0525 04:53:11.407768 20374 net.cpp:157] Top shape: 90 11 (990)
I0525 04:53:11.407780 20374 net.cpp:165] Memory required for data: 142090920
I0525 04:53:11.407795 20374 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 04:53:11.407810 20374 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 04:53:11.407825 20374 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 04:53:11.407846 20374 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 04:53:11.407866 20374 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 04:53:11.407959 20374 net.cpp:150] Setting up ip3_drop3_0_split
I0525 04:53:11.407975 20374 net.cpp:157] Top shape: 90 11 (990)
I0525 04:53:11.407991 20374 net.cpp:157] Top shape: 90 11 (990)
I0525 04:53:11.408002 20374 net.cpp:165] Memory required for data: 142098840
I0525 04:53:11.408018 20374 layer_factory.hpp:77] Creating layer accuracy
I0525 04:53:11.408046 20374 net.cpp:106] Creating Layer accuracy
I0525 04:53:11.408059 20374 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 04:53:11.408079 20374 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 04:53:11.408097 20374 net.cpp:411] accuracy -> accuracy
I0525 04:53:11.408124 20374 net.cpp:150] Setting up accuracy
I0525 04:53:11.408145 20374 net.cpp:157] Top shape: (1)
I0525 04:53:11.408159 20374 net.cpp:165] Memory required for data: 142098844
I0525 04:53:11.408171 20374 layer_factory.hpp:77] Creating layer loss
I0525 04:53:11.408187 20374 net.cpp:106] Creating Layer loss
I0525 04:53:11.408200 20374 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 04:53:11.408215 20374 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 04:53:11.408231 20374 net.cpp:411] loss -> loss
I0525 04:53:11.408259 20374 layer_factory.hpp:77] Creating layer loss
I0525 04:53:11.408784 20374 net.cpp:150] Setting up loss
I0525 04:53:11.408805 20374 net.cpp:157] Top shape: (1)
I0525 04:53:11.408818 20374 net.cpp:160]     with loss weight 1
I0525 04:53:11.408843 20374 net.cpp:165] Memory required for data: 142098848
I0525 04:53:11.408865 20374 net.cpp:226] loss needs backward computation.
I0525 04:53:11.408879 20374 net.cpp:228] accuracy does not need backward computation.
I0525 04:53:11.408896 20374 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 04:53:11.408910 20374 net.cpp:226] drop3 needs backward computation.
I0525 04:53:11.408922 20374 net.cpp:226] ip3 needs backward computation.
I0525 04:53:11.408937 20374 net.cpp:226] drop2 needs backward computation.
I0525 04:53:11.408957 20374 net.cpp:226] relu6 needs backward computation.
I0525 04:53:11.408978 20374 net.cpp:226] ip2 needs backward computation.
I0525 04:53:11.408995 20374 net.cpp:226] drop1 needs backward computation.
I0525 04:53:11.409008 20374 net.cpp:226] relu5 needs backward computation.
I0525 04:53:11.409019 20374 net.cpp:226] ip1 needs backward computation.
I0525 04:53:11.409034 20374 net.cpp:226] pool4 needs backward computation.
I0525 04:53:11.409047 20374 net.cpp:226] relu4 needs backward computation.
I0525 04:53:11.409067 20374 net.cpp:226] conv4 needs backward computation.
I0525 04:53:11.409081 20374 net.cpp:226] pool3 needs backward computation.
I0525 04:53:11.409097 20374 net.cpp:226] relu3 needs backward computation.
I0525 04:53:11.409111 20374 net.cpp:226] conv3 needs backward computation.
I0525 04:53:11.409122 20374 net.cpp:226] pool2 needs backward computation.
I0525 04:53:11.409135 20374 net.cpp:226] relu2 needs backward computation.
I0525 04:53:11.409150 20374 net.cpp:226] conv2 needs backward computation.
I0525 04:53:11.409169 20374 net.cpp:226] pool1 needs backward computation.
I0525 04:53:11.409183 20374 net.cpp:226] relu1 needs backward computation.
I0525 04:53:11.409196 20374 net.cpp:226] conv1 needs backward computation.
I0525 04:53:11.409210 20374 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 04:53:11.409224 20374 net.cpp:228] data_hdf5 does not need backward computation.
I0525 04:53:11.409235 20374 net.cpp:270] This network produces output accuracy
I0525 04:53:11.409251 20374 net.cpp:270] This network produces output loss
I0525 04:53:11.409281 20374 net.cpp:283] Network initialization done.
I0525 04:53:11.409416 20374 solver.cpp:60] Solver scaffolding done.
I0525 04:53:11.410573 20374 caffe.cpp:212] Starting Optimization
I0525 04:53:11.410589 20374 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 04:53:11.410604 20374 solver.cpp:289] Learning Rate Policy: fixed
I0525 04:53:11.411684 20374 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 04:53:59.517379 20374 solver.cpp:409]     Test net output #0: accuracy = 0.126637
I0525 04:53:59.517550 20374 solver.cpp:409]     Test net output #1: loss = 2.39835 (* 1 = 2.39835 loss)
I0525 04:53:59.548707 20374 solver.cpp:237] Iteration 0, loss = 2.39738
I0525 04:53:59.548748 20374 solver.cpp:253]     Train net output #0: loss = 2.39738 (* 1 = 2.39738 loss)
I0525 04:53:59.548768 20374 sgd_solver.cpp:106] Iteration 0, lr = 0.0015
I0525 04:54:08.398030 20374 solver.cpp:237] Iteration 166, loss = 2.29424
I0525 04:54:08.398090 20374 solver.cpp:253]     Train net output #0: loss = 2.29424 (* 1 = 2.29424 loss)
I0525 04:54:08.398115 20374 sgd_solver.cpp:106] Iteration 166, lr = 0.0015
I0525 04:54:17.249562 20374 solver.cpp:237] Iteration 332, loss = 2.2897
I0525 04:54:17.249600 20374 solver.cpp:253]     Train net output #0: loss = 2.2897 (* 1 = 2.2897 loss)
I0525 04:54:17.249619 20374 sgd_solver.cpp:106] Iteration 332, lr = 0.0015
I0525 04:54:26.099710 20374 solver.cpp:237] Iteration 498, loss = 2.1975
I0525 04:54:26.099747 20374 solver.cpp:253]     Train net output #0: loss = 2.1975 (* 1 = 2.1975 loss)
I0525 04:54:26.099766 20374 sgd_solver.cpp:106] Iteration 498, lr = 0.0015
I0525 04:54:34.948698 20374 solver.cpp:237] Iteration 664, loss = 2.12712
I0525 04:54:34.948871 20374 solver.cpp:253]     Train net output #0: loss = 2.12712 (* 1 = 2.12712 loss)
I0525 04:54:34.948889 20374 sgd_solver.cpp:106] Iteration 664, lr = 0.0015
I0525 04:54:43.802343 20374 solver.cpp:237] Iteration 830, loss = 2.13065
I0525 04:54:43.802381 20374 solver.cpp:253]     Train net output #0: loss = 2.13065 (* 1 = 2.13065 loss)
I0525 04:54:43.802405 20374 sgd_solver.cpp:106] Iteration 830, lr = 0.0015
I0525 04:54:52.653046 20374 solver.cpp:237] Iteration 996, loss = 1.96394
I0525 04:54:52.653084 20374 solver.cpp:253]     Train net output #0: loss = 1.96394 (* 1 = 1.96394 loss)
I0525 04:54:52.653101 20374 sgd_solver.cpp:106] Iteration 996, lr = 0.0015
I0525 04:55:23.578371 20374 solver.cpp:237] Iteration 1162, loss = 1.9405
I0525 04:55:23.578537 20374 solver.cpp:253]     Train net output #0: loss = 1.9405 (* 1 = 1.9405 loss)
I0525 04:55:23.578554 20374 sgd_solver.cpp:106] Iteration 1162, lr = 0.0015
I0525 04:55:32.427872 20374 solver.cpp:237] Iteration 1328, loss = 2.00367
I0525 04:55:32.427909 20374 solver.cpp:253]     Train net output #0: loss = 2.00367 (* 1 = 2.00367 loss)
I0525 04:55:32.427929 20374 sgd_solver.cpp:106] Iteration 1328, lr = 0.0015
I0525 04:55:41.270364 20374 solver.cpp:237] Iteration 1494, loss = 1.91085
I0525 04:55:41.270401 20374 solver.cpp:253]     Train net output #0: loss = 1.91085 (* 1 = 1.91085 loss)
I0525 04:55:41.270423 20374 sgd_solver.cpp:106] Iteration 1494, lr = 0.0015
I0525 04:55:50.128012 20374 solver.cpp:237] Iteration 1660, loss = 1.84015
I0525 04:55:50.128065 20374 solver.cpp:253]     Train net output #0: loss = 1.84015 (* 1 = 1.84015 loss)
I0525 04:55:50.128082 20374 sgd_solver.cpp:106] Iteration 1660, lr = 0.0015
I0525 04:55:50.395560 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_1666.caffemodel
I0525 04:55:50.475013 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_1666.solverstate
I0525 04:55:59.047956 20374 solver.cpp:237] Iteration 1826, loss = 1.6388
I0525 04:55:59.048121 20374 solver.cpp:253]     Train net output #0: loss = 1.6388 (* 1 = 1.6388 loss)
I0525 04:55:59.048140 20374 sgd_solver.cpp:106] Iteration 1826, lr = 0.0015
I0525 04:56:07.901579 20374 solver.cpp:237] Iteration 1992, loss = 1.78558
I0525 04:56:07.901618 20374 solver.cpp:253]     Train net output #0: loss = 1.78558 (* 1 = 1.78558 loss)
I0525 04:56:07.901635 20374 sgd_solver.cpp:106] Iteration 1992, lr = 0.0015
I0525 04:56:16.746284 20374 solver.cpp:237] Iteration 2158, loss = 1.71334
I0525 04:56:16.746323 20374 solver.cpp:253]     Train net output #0: loss = 1.71334 (* 1 = 1.71334 loss)
I0525 04:56:16.746340 20374 sgd_solver.cpp:106] Iteration 2158, lr = 0.0015
I0525 04:56:47.677748 20374 solver.cpp:237] Iteration 2324, loss = 1.74824
I0525 04:56:47.677913 20374 solver.cpp:253]     Train net output #0: loss = 1.74824 (* 1 = 1.74824 loss)
I0525 04:56:47.677930 20374 sgd_solver.cpp:106] Iteration 2324, lr = 0.0015
I0525 04:56:56.538162 20374 solver.cpp:237] Iteration 2490, loss = 1.83604
I0525 04:56:56.538199 20374 solver.cpp:253]     Train net output #0: loss = 1.83604 (* 1 = 1.83604 loss)
I0525 04:56:56.538218 20374 sgd_solver.cpp:106] Iteration 2490, lr = 0.0015
I0525 04:57:05.388650 20374 solver.cpp:237] Iteration 2656, loss = 1.63531
I0525 04:57:05.388700 20374 solver.cpp:253]     Train net output #0: loss = 1.63531 (* 1 = 1.63531 loss)
I0525 04:57:05.388725 20374 sgd_solver.cpp:106] Iteration 2656, lr = 0.0015
I0525 04:57:14.238893 20374 solver.cpp:237] Iteration 2822, loss = 1.5976
I0525 04:57:14.238929 20374 solver.cpp:253]     Train net output #0: loss = 1.5976 (* 1 = 1.5976 loss)
I0525 04:57:14.238948 20374 sgd_solver.cpp:106] Iteration 2822, lr = 0.0015
I0525 04:57:23.087956 20374 solver.cpp:237] Iteration 2988, loss = 1.73569
I0525 04:57:23.088126 20374 solver.cpp:253]     Train net output #0: loss = 1.73569 (* 1 = 1.73569 loss)
I0525 04:57:23.088145 20374 sgd_solver.cpp:106] Iteration 2988, lr = 0.0015
I0525 04:57:31.950494 20374 solver.cpp:237] Iteration 3154, loss = 1.58458
I0525 04:57:31.950531 20374 solver.cpp:253]     Train net output #0: loss = 1.58458 (* 1 = 1.58458 loss)
I0525 04:57:31.950554 20374 sgd_solver.cpp:106] Iteration 3154, lr = 0.0015
I0525 04:57:40.798717 20374 solver.cpp:237] Iteration 3320, loss = 1.6067
I0525 04:57:40.798753 20374 solver.cpp:253]     Train net output #0: loss = 1.6067 (* 1 = 1.6067 loss)
I0525 04:57:40.798776 20374 sgd_solver.cpp:106] Iteration 3320, lr = 0.0015
I0525 04:57:41.387167 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_3332.caffemodel
I0525 04:57:41.462944 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_3332.solverstate
I0525 04:57:41.505399 20374 solver.cpp:341] Iteration 3333, Testing net (#0)
I0525 04:58:28.726239 20374 solver.cpp:409]     Test net output #0: accuracy = 0.671143
I0525 04:58:28.726398 20374 solver.cpp:409]     Test net output #1: loss = 1.14351 (* 1 = 1.14351 loss)
I0525 04:58:59.001809 20374 solver.cpp:237] Iteration 3486, loss = 1.65914
I0525 04:58:59.001972 20374 solver.cpp:253]     Train net output #0: loss = 1.65914 (* 1 = 1.65914 loss)
I0525 04:58:59.001989 20374 sgd_solver.cpp:106] Iteration 3486, lr = 0.0015
I0525 04:59:07.846968 20374 solver.cpp:237] Iteration 3652, loss = 1.65984
I0525 04:59:07.847020 20374 solver.cpp:253]     Train net output #0: loss = 1.65984 (* 1 = 1.65984 loss)
I0525 04:59:07.847048 20374 sgd_solver.cpp:106] Iteration 3652, lr = 0.0015
I0525 04:59:16.686728 20374 solver.cpp:237] Iteration 3818, loss = 1.75007
I0525 04:59:16.686766 20374 solver.cpp:253]     Train net output #0: loss = 1.75007 (* 1 = 1.75007 loss)
I0525 04:59:16.686784 20374 sgd_solver.cpp:106] Iteration 3818, lr = 0.0015
I0525 04:59:25.528281 20374 solver.cpp:237] Iteration 3984, loss = 1.61231
I0525 04:59:25.528318 20374 solver.cpp:253]     Train net output #0: loss = 1.61231 (* 1 = 1.61231 loss)
I0525 04:59:25.528340 20374 sgd_solver.cpp:106] Iteration 3984, lr = 0.0015
I0525 04:59:34.359232 20374 solver.cpp:237] Iteration 4150, loss = 1.59888
I0525 04:59:34.359396 20374 solver.cpp:253]     Train net output #0: loss = 1.59888 (* 1 = 1.59888 loss)
I0525 04:59:34.359414 20374 sgd_solver.cpp:106] Iteration 4150, lr = 0.0015
I0525 04:59:43.201166 20374 solver.cpp:237] Iteration 4316, loss = 1.56553
I0525 04:59:43.201203 20374 solver.cpp:253]     Train net output #0: loss = 1.56553 (* 1 = 1.56553 loss)
I0525 04:59:43.201226 20374 sgd_solver.cpp:106] Iteration 4316, lr = 0.0015
I0525 05:00:14.168012 20374 solver.cpp:237] Iteration 4482, loss = 1.66504
I0525 05:00:14.168184 20374 solver.cpp:253]     Train net output #0: loss = 1.66504 (* 1 = 1.66504 loss)
I0525 05:00:14.168201 20374 sgd_solver.cpp:106] Iteration 4482, lr = 0.0015
I0525 05:00:23.005386 20374 solver.cpp:237] Iteration 4648, loss = 1.71876
I0525 05:00:23.005435 20374 solver.cpp:253]     Train net output #0: loss = 1.71876 (* 1 = 1.71876 loss)
I0525 05:00:23.005465 20374 sgd_solver.cpp:106] Iteration 4648, lr = 0.0015
I0525 05:00:31.843503 20374 solver.cpp:237] Iteration 4814, loss = 1.45576
I0525 05:00:31.843541 20374 solver.cpp:253]     Train net output #0: loss = 1.45576 (* 1 = 1.45576 loss)
I0525 05:00:31.843561 20374 sgd_solver.cpp:106] Iteration 4814, lr = 0.0015
I0525 05:00:40.681545 20374 solver.cpp:237] Iteration 4980, loss = 1.47491
I0525 05:00:40.681582 20374 solver.cpp:253]     Train net output #0: loss = 1.47491 (* 1 = 1.47491 loss)
I0525 05:00:40.681607 20374 sgd_solver.cpp:106] Iteration 4980, lr = 0.0015
I0525 05:00:41.586786 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_4998.caffemodel
I0525 05:00:41.664130 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_4998.solverstate
I0525 05:00:49.594944 20374 solver.cpp:237] Iteration 5146, loss = 1.64286
I0525 05:00:49.595126 20374 solver.cpp:253]     Train net output #0: loss = 1.64286 (* 1 = 1.64286 loss)
I0525 05:00:49.595144 20374 sgd_solver.cpp:106] Iteration 5146, lr = 0.0015
I0525 05:00:58.433964 20374 solver.cpp:237] Iteration 5312, loss = 1.60313
I0525 05:00:58.434000 20374 solver.cpp:253]     Train net output #0: loss = 1.60313 (* 1 = 1.60313 loss)
I0525 05:00:58.434026 20374 sgd_solver.cpp:106] Iteration 5312, lr = 0.0015
I0525 05:01:07.277842 20374 solver.cpp:237] Iteration 5478, loss = 1.41609
I0525 05:01:07.277878 20374 solver.cpp:253]     Train net output #0: loss = 1.41609 (* 1 = 1.41609 loss)
I0525 05:01:07.277901 20374 sgd_solver.cpp:106] Iteration 5478, lr = 0.0015
I0525 05:01:38.247015 20374 solver.cpp:237] Iteration 5644, loss = 1.73242
I0525 05:01:38.247197 20374 solver.cpp:253]     Train net output #0: loss = 1.73242 (* 1 = 1.73242 loss)
I0525 05:01:38.247215 20374 sgd_solver.cpp:106] Iteration 5644, lr = 0.0015
I0525 05:01:47.099938 20374 solver.cpp:237] Iteration 5810, loss = 1.63932
I0525 05:01:47.099975 20374 solver.cpp:253]     Train net output #0: loss = 1.63932 (* 1 = 1.63932 loss)
I0525 05:01:47.099999 20374 sgd_solver.cpp:106] Iteration 5810, lr = 0.0015
I0525 05:01:55.947700 20374 solver.cpp:237] Iteration 5976, loss = 1.38553
I0525 05:01:55.947736 20374 solver.cpp:253]     Train net output #0: loss = 1.38553 (* 1 = 1.38553 loss)
I0525 05:01:55.947760 20374 sgd_solver.cpp:106] Iteration 5976, lr = 0.0015
I0525 05:02:04.804620 20374 solver.cpp:237] Iteration 6142, loss = 1.51273
I0525 05:02:04.804672 20374 solver.cpp:253]     Train net output #0: loss = 1.51273 (* 1 = 1.51273 loss)
I0525 05:02:04.804689 20374 sgd_solver.cpp:106] Iteration 6142, lr = 0.0015
I0525 05:02:13.656919 20374 solver.cpp:237] Iteration 6308, loss = 1.67879
I0525 05:02:13.657063 20374 solver.cpp:253]     Train net output #0: loss = 1.67879 (* 1 = 1.67879 loss)
I0525 05:02:13.657080 20374 sgd_solver.cpp:106] Iteration 6308, lr = 0.0015
I0525 05:02:22.503233 20374 solver.cpp:237] Iteration 6474, loss = 1.28481
I0525 05:02:22.503271 20374 solver.cpp:253]     Train net output #0: loss = 1.28481 (* 1 = 1.28481 loss)
I0525 05:02:22.503288 20374 sgd_solver.cpp:106] Iteration 6474, lr = 0.0015
I0525 05:02:31.344612 20374 solver.cpp:237] Iteration 6640, loss = 1.55977
I0525 05:02:31.344665 20374 solver.cpp:253]     Train net output #0: loss = 1.55977 (* 1 = 1.55977 loss)
I0525 05:02:31.344691 20374 sgd_solver.cpp:106] Iteration 6640, lr = 0.0015
I0525 05:02:32.573920 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_6664.caffemodel
I0525 05:02:32.651458 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_6664.solverstate
I0525 05:02:32.748884 20374 solver.cpp:341] Iteration 6666, Testing net (#0)
I0525 05:03:40.710036 20374 solver.cpp:409]     Test net output #0: accuracy = 0.759171
I0525 05:03:40.710216 20374 solver.cpp:409]     Test net output #1: loss = 0.839975 (* 1 = 0.839975 loss)
I0525 05:04:10.315680 20374 solver.cpp:237] Iteration 6806, loss = 1.59549
I0525 05:04:10.315737 20374 solver.cpp:253]     Train net output #0: loss = 1.59549 (* 1 = 1.59549 loss)
I0525 05:04:10.315754 20374 sgd_solver.cpp:106] Iteration 6806, lr = 0.0015
I0525 05:04:19.161595 20374 solver.cpp:237] Iteration 6972, loss = 1.30572
I0525 05:04:19.161754 20374 solver.cpp:253]     Train net output #0: loss = 1.30572 (* 1 = 1.30572 loss)
I0525 05:04:19.161770 20374 sgd_solver.cpp:106] Iteration 6972, lr = 0.0015
I0525 05:04:27.999480 20374 solver.cpp:237] Iteration 7138, loss = 1.52801
I0525 05:04:27.999533 20374 solver.cpp:253]     Train net output #0: loss = 1.52801 (* 1 = 1.52801 loss)
I0525 05:04:27.999562 20374 sgd_solver.cpp:106] Iteration 7138, lr = 0.0015
I0525 05:04:36.849103 20374 solver.cpp:237] Iteration 7304, loss = 1.44106
I0525 05:04:36.849144 20374 solver.cpp:253]     Train net output #0: loss = 1.44106 (* 1 = 1.44106 loss)
I0525 05:04:36.849169 20374 sgd_solver.cpp:106] Iteration 7304, lr = 0.0015
I0525 05:04:45.693799 20374 solver.cpp:237] Iteration 7470, loss = 1.32935
I0525 05:04:45.693835 20374 solver.cpp:253]     Train net output #0: loss = 1.32935 (* 1 = 1.32935 loss)
I0525 05:04:45.693853 20374 sgd_solver.cpp:106] Iteration 7470, lr = 0.0015
I0525 05:04:54.535941 20374 solver.cpp:237] Iteration 7636, loss = 1.27418
I0525 05:04:54.536097 20374 solver.cpp:253]     Train net output #0: loss = 1.27418 (* 1 = 1.27418 loss)
I0525 05:04:54.536113 20374 sgd_solver.cpp:106] Iteration 7636, lr = 0.0015
I0525 05:05:25.455436 20374 solver.cpp:237] Iteration 7802, loss = 1.44564
I0525 05:05:25.455607 20374 solver.cpp:253]     Train net output #0: loss = 1.44564 (* 1 = 1.44564 loss)
I0525 05:05:25.455626 20374 sgd_solver.cpp:106] Iteration 7802, lr = 0.0015
I0525 05:05:34.306483 20374 solver.cpp:237] Iteration 7968, loss = 1.31161
I0525 05:05:34.306524 20374 solver.cpp:253]     Train net output #0: loss = 1.31161 (* 1 = 1.31161 loss)
I0525 05:05:34.306541 20374 sgd_solver.cpp:106] Iteration 7968, lr = 0.0015
I0525 05:05:43.146904 20374 solver.cpp:237] Iteration 8134, loss = 1.48875
I0525 05:05:43.146960 20374 solver.cpp:253]     Train net output #0: loss = 1.48875 (* 1 = 1.48875 loss)
I0525 05:05:43.146987 20374 sgd_solver.cpp:106] Iteration 8134, lr = 0.0015
I0525 05:05:51.995229 20374 solver.cpp:237] Iteration 8300, loss = 1.46621
I0525 05:05:51.995267 20374 solver.cpp:253]     Train net output #0: loss = 1.46621 (* 1 = 1.46621 loss)
I0525 05:05:51.995285 20374 sgd_solver.cpp:106] Iteration 8300, lr = 0.0015
I0525 05:05:53.538383 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_8330.caffemodel
I0525 05:05:53.615152 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_8330.solverstate
I0525 05:06:00.900084 20374 solver.cpp:237] Iteration 8466, loss = 1.56861
I0525 05:06:00.900254 20374 solver.cpp:253]     Train net output #0: loss = 1.56861 (* 1 = 1.56861 loss)
I0525 05:06:00.900274 20374 sgd_solver.cpp:106] Iteration 8466, lr = 0.0015
I0525 05:06:09.742823 20374 solver.cpp:237] Iteration 8632, loss = 1.44066
I0525 05:06:09.742885 20374 solver.cpp:253]     Train net output #0: loss = 1.44066 (* 1 = 1.44066 loss)
I0525 05:06:09.742913 20374 sgd_solver.cpp:106] Iteration 8632, lr = 0.0015
I0525 05:06:18.593436 20374 solver.cpp:237] Iteration 8798, loss = 1.49809
I0525 05:06:18.593473 20374 solver.cpp:253]     Train net output #0: loss = 1.49809 (* 1 = 1.49809 loss)
I0525 05:06:18.593493 20374 sgd_solver.cpp:106] Iteration 8798, lr = 0.0015
I0525 05:06:49.553920 20374 solver.cpp:237] Iteration 8964, loss = 1.47536
I0525 05:06:49.554101 20374 solver.cpp:253]     Train net output #0: loss = 1.47536 (* 1 = 1.47536 loss)
I0525 05:06:49.554118 20374 sgd_solver.cpp:106] Iteration 8964, lr = 0.0015
I0525 05:06:58.395699 20374 solver.cpp:237] Iteration 9130, loss = 1.84361
I0525 05:06:58.395758 20374 solver.cpp:253]     Train net output #0: loss = 1.84361 (* 1 = 1.84361 loss)
I0525 05:06:58.395783 20374 sgd_solver.cpp:106] Iteration 9130, lr = 0.0015
I0525 05:07:07.237576 20374 solver.cpp:237] Iteration 9296, loss = 1.41443
I0525 05:07:07.237614 20374 solver.cpp:253]     Train net output #0: loss = 1.41443 (* 1 = 1.41443 loss)
I0525 05:07:07.237637 20374 sgd_solver.cpp:106] Iteration 9296, lr = 0.0015
I0525 05:07:16.072221 20374 solver.cpp:237] Iteration 9462, loss = 1.42185
I0525 05:07:16.072257 20374 solver.cpp:253]     Train net output #0: loss = 1.42185 (* 1 = 1.42185 loss)
I0525 05:07:16.072279 20374 sgd_solver.cpp:106] Iteration 9462, lr = 0.0015
I0525 05:07:24.910843 20374 solver.cpp:237] Iteration 9628, loss = 1.29591
I0525 05:07:24.911012 20374 solver.cpp:253]     Train net output #0: loss = 1.29591 (* 1 = 1.29591 loss)
I0525 05:07:24.911031 20374 sgd_solver.cpp:106] Iteration 9628, lr = 0.0015
I0525 05:07:33.749179 20374 solver.cpp:237] Iteration 9794, loss = 1.61173
I0525 05:07:33.749217 20374 solver.cpp:253]     Train net output #0: loss = 1.61173 (* 1 = 1.61173 loss)
I0525 05:07:33.749235 20374 sgd_solver.cpp:106] Iteration 9794, lr = 0.0015
I0525 05:07:42.591424 20374 solver.cpp:237] Iteration 9960, loss = 1.33703
I0525 05:07:42.591461 20374 solver.cpp:253]     Train net output #0: loss = 1.33703 (* 1 = 1.33703 loss)
I0525 05:07:42.591481 20374 sgd_solver.cpp:106] Iteration 9960, lr = 0.0015
I0525 05:07:44.458573 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_9996.caffemodel
I0525 05:07:44.533983 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_9996.solverstate
I0525 05:07:44.682785 20374 solver.cpp:341] Iteration 9999, Testing net (#0)
I0525 05:08:31.469120 20374 solver.cpp:409]     Test net output #0: accuracy = 0.804692
I0525 05:08:31.469290 20374 solver.cpp:409]     Test net output #1: loss = 0.660484 (* 1 = 0.660484 loss)
I0525 05:09:00.346760 20374 solver.cpp:237] Iteration 10126, loss = 1.47253
I0525 05:09:00.346819 20374 solver.cpp:253]     Train net output #0: loss = 1.47253 (* 1 = 1.47253 loss)
I0525 05:09:00.346843 20374 sgd_solver.cpp:106] Iteration 10126, lr = 0.0015
I0525 05:09:09.211287 20374 solver.cpp:237] Iteration 10292, loss = 1.39274
I0525 05:09:09.211462 20374 solver.cpp:253]     Train net output #0: loss = 1.39274 (* 1 = 1.39274 loss)
I0525 05:09:09.211478 20374 sgd_solver.cpp:106] Iteration 10292, lr = 0.0015
I0525 05:09:18.075333 20374 solver.cpp:237] Iteration 10458, loss = 1.23007
I0525 05:09:18.075371 20374 solver.cpp:253]     Train net output #0: loss = 1.23007 (* 1 = 1.23007 loss)
I0525 05:09:18.075388 20374 sgd_solver.cpp:106] Iteration 10458, lr = 0.0015
I0525 05:09:26.939522 20374 solver.cpp:237] Iteration 10624, loss = 1.48475
I0525 05:09:26.939558 20374 solver.cpp:253]     Train net output #0: loss = 1.48475 (* 1 = 1.48475 loss)
I0525 05:09:26.939582 20374 sgd_solver.cpp:106] Iteration 10624, lr = 0.0015
I0525 05:09:35.789398 20374 solver.cpp:237] Iteration 10790, loss = 1.26702
I0525 05:09:35.789453 20374 solver.cpp:253]     Train net output #0: loss = 1.26702 (* 1 = 1.26702 loss)
I0525 05:09:35.789472 20374 sgd_solver.cpp:106] Iteration 10790, lr = 0.0015
I0525 05:09:44.645314 20374 solver.cpp:237] Iteration 10956, loss = 1.38856
I0525 05:09:44.645462 20374 solver.cpp:253]     Train net output #0: loss = 1.38856 (* 1 = 1.38856 loss)
I0525 05:09:44.645479 20374 sgd_solver.cpp:106] Iteration 10956, lr = 0.0015
I0525 05:10:15.660003 20374 solver.cpp:237] Iteration 11122, loss = 1.24494
I0525 05:10:15.660188 20374 solver.cpp:253]     Train net output #0: loss = 1.24494 (* 1 = 1.24494 loss)
I0525 05:10:15.660205 20374 sgd_solver.cpp:106] Iteration 11122, lr = 0.0015
I0525 05:10:24.517818 20374 solver.cpp:237] Iteration 11288, loss = 1.25333
I0525 05:10:24.517876 20374 solver.cpp:253]     Train net output #0: loss = 1.25333 (* 1 = 1.25333 loss)
I0525 05:10:24.517901 20374 sgd_solver.cpp:106] Iteration 11288, lr = 0.0015
I0525 05:10:33.371369 20374 solver.cpp:237] Iteration 11454, loss = 1.31163
I0525 05:10:33.371405 20374 solver.cpp:253]     Train net output #0: loss = 1.31163 (* 1 = 1.31163 loss)
I0525 05:10:33.371424 20374 sgd_solver.cpp:106] Iteration 11454, lr = 0.0015
I0525 05:10:42.218660 20374 solver.cpp:237] Iteration 11620, loss = 1.31742
I0525 05:10:42.218698 20374 solver.cpp:253]     Train net output #0: loss = 1.31742 (* 1 = 1.31742 loss)
I0525 05:10:42.218715 20374 sgd_solver.cpp:106] Iteration 11620, lr = 0.0015
I0525 05:10:44.405704 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_11662.caffemodel
I0525 05:10:44.481649 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_11662.solverstate
I0525 05:10:51.135257 20374 solver.cpp:237] Iteration 11786, loss = 1.33626
I0525 05:10:51.135431 20374 solver.cpp:253]     Train net output #0: loss = 1.33626 (* 1 = 1.33626 loss)
I0525 05:10:51.135448 20374 sgd_solver.cpp:106] Iteration 11786, lr = 0.0015
I0525 05:10:59.976222 20374 solver.cpp:237] Iteration 11952, loss = 1.44024
I0525 05:10:59.976258 20374 solver.cpp:253]     Train net output #0: loss = 1.44024 (* 1 = 1.44024 loss)
I0525 05:10:59.976284 20374 sgd_solver.cpp:106] Iteration 11952, lr = 0.0015
I0525 05:11:08.839798 20374 solver.cpp:237] Iteration 12118, loss = 1.34474
I0525 05:11:08.839857 20374 solver.cpp:253]     Train net output #0: loss = 1.34474 (* 1 = 1.34474 loss)
I0525 05:11:08.839884 20374 sgd_solver.cpp:106] Iteration 12118, lr = 0.0015
I0525 05:11:39.792198 20374 solver.cpp:237] Iteration 12284, loss = 1.41443
I0525 05:11:39.792378 20374 solver.cpp:253]     Train net output #0: loss = 1.41443 (* 1 = 1.41443 loss)
I0525 05:11:39.792397 20374 sgd_solver.cpp:106] Iteration 12284, lr = 0.0015
I0525 05:11:48.644798 20374 solver.cpp:237] Iteration 12450, loss = 1.32357
I0525 05:11:48.644836 20374 solver.cpp:253]     Train net output #0: loss = 1.32357 (* 1 = 1.32357 loss)
I0525 05:11:48.644860 20374 sgd_solver.cpp:106] Iteration 12450, lr = 0.0015
I0525 05:11:57.494599 20374 solver.cpp:237] Iteration 12616, loss = 1.44714
I0525 05:11:57.494635 20374 solver.cpp:253]     Train net output #0: loss = 1.44714 (* 1 = 1.44714 loss)
I0525 05:11:57.494659 20374 sgd_solver.cpp:106] Iteration 12616, lr = 0.0015
I0525 05:12:06.348206 20374 solver.cpp:237] Iteration 12782, loss = 1.42807
I0525 05:12:06.348258 20374 solver.cpp:253]     Train net output #0: loss = 1.42807 (* 1 = 1.42807 loss)
I0525 05:12:06.348286 20374 sgd_solver.cpp:106] Iteration 12782, lr = 0.0015
I0525 05:12:15.194789 20374 solver.cpp:237] Iteration 12948, loss = 1.31261
I0525 05:12:15.194939 20374 solver.cpp:253]     Train net output #0: loss = 1.31261 (* 1 = 1.31261 loss)
I0525 05:12:15.194957 20374 sgd_solver.cpp:106] Iteration 12948, lr = 0.0015
I0525 05:12:24.046430 20374 solver.cpp:237] Iteration 13114, loss = 1.50417
I0525 05:12:24.046483 20374 solver.cpp:253]     Train net output #0: loss = 1.50417 (* 1 = 1.50417 loss)
I0525 05:12:24.046509 20374 sgd_solver.cpp:106] Iteration 13114, lr = 0.0015
I0525 05:12:32.899261 20374 solver.cpp:237] Iteration 13280, loss = 1.24892
I0525 05:12:32.899299 20374 solver.cpp:253]     Train net output #0: loss = 1.24892 (* 1 = 1.24892 loss)
I0525 05:12:32.899318 20374 sgd_solver.cpp:106] Iteration 13280, lr = 0.0015
I0525 05:12:35.406139 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_13328.caffemodel
I0525 05:12:35.482687 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_13328.solverstate
I0525 05:12:35.685685 20374 solver.cpp:341] Iteration 13332, Testing net (#0)
I0525 05:13:43.722151 20374 solver.cpp:409]     Test net output #0: accuracy = 0.830332
I0525 05:13:43.722342 20374 solver.cpp:409]     Test net output #1: loss = 0.609764 (* 1 = 0.609764 loss)
I0525 05:14:11.918146 20374 solver.cpp:237] Iteration 13446, loss = 1.53675
I0525 05:14:11.918203 20374 solver.cpp:253]     Train net output #0: loss = 1.53675 (* 1 = 1.53675 loss)
I0525 05:14:11.918227 20374 sgd_solver.cpp:106] Iteration 13446, lr = 0.0015
I0525 05:14:20.755856 20374 solver.cpp:237] Iteration 13612, loss = 1.34365
I0525 05:14:20.756016 20374 solver.cpp:253]     Train net output #0: loss = 1.34365 (* 1 = 1.34365 loss)
I0525 05:14:20.756032 20374 sgd_solver.cpp:106] Iteration 13612, lr = 0.0015
I0525 05:14:29.597465 20374 solver.cpp:237] Iteration 13778, loss = 1.22971
I0525 05:14:29.597522 20374 solver.cpp:253]     Train net output #0: loss = 1.22971 (* 1 = 1.22971 loss)
I0525 05:14:29.597546 20374 sgd_solver.cpp:106] Iteration 13778, lr = 0.0015
I0525 05:14:38.448307 20374 solver.cpp:237] Iteration 13944, loss = 1.332
I0525 05:14:38.448348 20374 solver.cpp:253]     Train net output #0: loss = 1.332 (* 1 = 1.332 loss)
I0525 05:14:38.448367 20374 sgd_solver.cpp:106] Iteration 13944, lr = 0.0015
I0525 05:14:47.301112 20374 solver.cpp:237] Iteration 14110, loss = 1.35292
I0525 05:14:47.301149 20374 solver.cpp:253]     Train net output #0: loss = 1.35292 (* 1 = 1.35292 loss)
I0525 05:14:47.301168 20374 sgd_solver.cpp:106] Iteration 14110, lr = 0.0015
I0525 05:14:56.149996 20374 solver.cpp:237] Iteration 14276, loss = 1.12723
I0525 05:14:56.150163 20374 solver.cpp:253]     Train net output #0: loss = 1.12723 (* 1 = 1.12723 loss)
I0525 05:14:56.150182 20374 sgd_solver.cpp:106] Iteration 14276, lr = 0.0015
I0525 05:15:05.005970 20374 solver.cpp:237] Iteration 14442, loss = 1.31689
I0525 05:15:05.006008 20374 solver.cpp:253]     Train net output #0: loss = 1.31689 (* 1 = 1.31689 loss)
I0525 05:15:05.006027 20374 sgd_solver.cpp:106] Iteration 14442, lr = 0.0015
I0525 05:15:36.027597 20374 solver.cpp:237] Iteration 14608, loss = 1.07019
I0525 05:15:36.027778 20374 solver.cpp:253]     Train net output #0: loss = 1.07019 (* 1 = 1.07019 loss)
I0525 05:15:36.027796 20374 sgd_solver.cpp:106] Iteration 14608, lr = 0.0015
I0525 05:15:44.873803 20374 solver.cpp:237] Iteration 14774, loss = 1.44055
I0525 05:15:44.873859 20374 solver.cpp:253]     Train net output #0: loss = 1.44055 (* 1 = 1.44055 loss)
I0525 05:15:44.873879 20374 sgd_solver.cpp:106] Iteration 14774, lr = 0.0015
I0525 05:15:53.710433 20374 solver.cpp:237] Iteration 14940, loss = 1.22621
I0525 05:15:53.710470 20374 solver.cpp:253]     Train net output #0: loss = 1.22621 (* 1 = 1.22621 loss)
I0525 05:15:53.710494 20374 sgd_solver.cpp:106] Iteration 14940, lr = 0.0015
I0525 05:15:56.529939 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_14994.caffemodel
I0525 05:15:56.606096 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_14994.solverstate
I0525 05:16:02.610169 20374 solver.cpp:237] Iteration 15106, loss = 1.34313
I0525 05:16:02.610225 20374 solver.cpp:253]     Train net output #0: loss = 1.34313 (* 1 = 1.34313 loss)
I0525 05:16:02.610250 20374 sgd_solver.cpp:106] Iteration 15106, lr = 0.0015
I0525 05:16:11.455930 20374 solver.cpp:237] Iteration 15272, loss = 1.55903
I0525 05:16:11.456104 20374 solver.cpp:253]     Train net output #0: loss = 1.55903 (* 1 = 1.55903 loss)
I0525 05:16:11.456120 20374 sgd_solver.cpp:106] Iteration 15272, lr = 0.0015
I0525 05:16:20.303525 20374 solver.cpp:237] Iteration 15438, loss = 1.46881
I0525 05:16:20.303563 20374 solver.cpp:253]     Train net output #0: loss = 1.46881 (* 1 = 1.46881 loss)
I0525 05:16:20.303581 20374 sgd_solver.cpp:106] Iteration 15438, lr = 0.0015
I0525 05:16:51.272367 20374 solver.cpp:237] Iteration 15604, loss = 1.38345
I0525 05:16:51.272557 20374 solver.cpp:253]     Train net output #0: loss = 1.38345 (* 1 = 1.38345 loss)
I0525 05:16:51.272574 20374 sgd_solver.cpp:106] Iteration 15604, lr = 0.0015
I0525 05:17:00.120193 20374 solver.cpp:237] Iteration 15770, loss = 1.12265
I0525 05:17:00.120250 20374 solver.cpp:253]     Train net output #0: loss = 1.12265 (* 1 = 1.12265 loss)
I0525 05:17:00.120275 20374 sgd_solver.cpp:106] Iteration 15770, lr = 0.0015
I0525 05:17:08.960187 20374 solver.cpp:237] Iteration 15936, loss = 1.19485
I0525 05:17:08.960224 20374 solver.cpp:253]     Train net output #0: loss = 1.19485 (* 1 = 1.19485 loss)
I0525 05:17:08.960243 20374 sgd_solver.cpp:106] Iteration 15936, lr = 0.0015
I0525 05:17:17.799288 20374 solver.cpp:237] Iteration 16102, loss = 1.19186
I0525 05:17:17.799324 20374 solver.cpp:253]     Train net output #0: loss = 1.19186 (* 1 = 1.19186 loss)
I0525 05:17:17.799342 20374 sgd_solver.cpp:106] Iteration 16102, lr = 0.0015
I0525 05:17:26.643432 20374 solver.cpp:237] Iteration 16268, loss = 1.33747
I0525 05:17:26.643605 20374 solver.cpp:253]     Train net output #0: loss = 1.33747 (* 1 = 1.33747 loss)
I0525 05:17:26.643622 20374 sgd_solver.cpp:106] Iteration 16268, lr = 0.0015
I0525 05:17:35.487571 20374 solver.cpp:237] Iteration 16434, loss = 1.39116
I0525 05:17:35.487610 20374 solver.cpp:253]     Train net output #0: loss = 1.39116 (* 1 = 1.39116 loss)
I0525 05:17:35.487627 20374 sgd_solver.cpp:106] Iteration 16434, lr = 0.0015
I0525 05:17:44.328716 20374 solver.cpp:237] Iteration 16600, loss = 1.5226
I0525 05:17:44.328752 20374 solver.cpp:253]     Train net output #0: loss = 1.5226 (* 1 = 1.5226 loss)
I0525 05:17:44.328776 20374 sgd_solver.cpp:106] Iteration 16600, lr = 0.0015
I0525 05:17:47.471732 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_16660.caffemodel
I0525 05:17:47.548509 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_16660.solverstate
I0525 05:17:47.808064 20374 solver.cpp:341] Iteration 16665, Testing net (#0)
I0525 05:18:34.994791 20374 solver.cpp:409]     Test net output #0: accuracy = 0.841423
I0525 05:18:34.994964 20374 solver.cpp:409]     Test net output #1: loss = 0.549649 (* 1 = 0.549649 loss)
I0525 05:19:01.253696 20374 solver.cpp:237] Iteration 16766, loss = 1.22582
I0525 05:19:01.253752 20374 solver.cpp:253]     Train net output #0: loss = 1.22582 (* 1 = 1.22582 loss)
I0525 05:19:01.253777 20374 sgd_solver.cpp:106] Iteration 16766, lr = 0.0015
I0525 05:19:10.095973 20374 solver.cpp:237] Iteration 16932, loss = 1.30602
I0525 05:19:10.096145 20374 solver.cpp:253]     Train net output #0: loss = 1.30602 (* 1 = 1.30602 loss)
I0525 05:19:10.096163 20374 sgd_solver.cpp:106] Iteration 16932, lr = 0.0015
I0525 05:19:18.943784 20374 solver.cpp:237] Iteration 17098, loss = 1.46493
I0525 05:19:18.943820 20374 solver.cpp:253]     Train net output #0: loss = 1.46493 (* 1 = 1.46493 loss)
I0525 05:19:18.943840 20374 sgd_solver.cpp:106] Iteration 17098, lr = 0.0015
I0525 05:19:27.794832 20374 solver.cpp:237] Iteration 17264, loss = 1.51913
I0525 05:19:27.794870 20374 solver.cpp:253]     Train net output #0: loss = 1.51913 (* 1 = 1.51913 loss)
I0525 05:19:27.794888 20374 sgd_solver.cpp:106] Iteration 17264, lr = 0.0015
I0525 05:19:36.639464 20374 solver.cpp:237] Iteration 17430, loss = 1.26844
I0525 05:19:36.639518 20374 solver.cpp:253]     Train net output #0: loss = 1.26844 (* 1 = 1.26844 loss)
I0525 05:19:36.639546 20374 sgd_solver.cpp:106] Iteration 17430, lr = 0.0015
I0525 05:19:45.484642 20374 solver.cpp:237] Iteration 17596, loss = 1.22399
I0525 05:19:45.484802 20374 solver.cpp:253]     Train net output #0: loss = 1.22399 (* 1 = 1.22399 loss)
I0525 05:19:45.484819 20374 sgd_solver.cpp:106] Iteration 17596, lr = 0.0015
I0525 05:19:54.329825 20374 solver.cpp:237] Iteration 17762, loss = 1.32439
I0525 05:19:54.329875 20374 solver.cpp:253]     Train net output #0: loss = 1.32439 (* 1 = 1.32439 loss)
I0525 05:19:54.329905 20374 sgd_solver.cpp:106] Iteration 17762, lr = 0.0015
I0525 05:20:23.998721 20374 solver.cpp:237] Iteration 17928, loss = 1.064
I0525 05:20:23.998901 20374 solver.cpp:253]     Train net output #0: loss = 1.064 (* 1 = 1.064 loss)
I0525 05:20:23.998919 20374 sgd_solver.cpp:106] Iteration 17928, lr = 0.0015
I0525 05:20:32.839975 20374 solver.cpp:237] Iteration 18094, loss = 1.33938
I0525 05:20:32.840013 20374 solver.cpp:253]     Train net output #0: loss = 1.33938 (* 1 = 1.33938 loss)
I0525 05:20:32.840032 20374 sgd_solver.cpp:106] Iteration 18094, lr = 0.0015
I0525 05:20:41.677093 20374 solver.cpp:237] Iteration 18260, loss = 1.53837
I0525 05:20:41.677130 20374 solver.cpp:253]     Train net output #0: loss = 1.53837 (* 1 = 1.53837 loss)
I0525 05:20:41.677148 20374 sgd_solver.cpp:106] Iteration 18260, lr = 0.0015
I0525 05:20:45.139478 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_18326.caffemodel
I0525 05:20:45.214701 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_18326.solverstate
I0525 05:20:50.588256 20374 solver.cpp:237] Iteration 18426, loss = 1.32056
I0525 05:20:50.588312 20374 solver.cpp:253]     Train net output #0: loss = 1.32056 (* 1 = 1.32056 loss)
I0525 05:20:50.588346 20374 sgd_solver.cpp:106] Iteration 18426, lr = 0.0015
I0525 05:20:59.426506 20374 solver.cpp:237] Iteration 18592, loss = 1.24407
I0525 05:20:59.426669 20374 solver.cpp:253]     Train net output #0: loss = 1.24407 (* 1 = 1.24407 loss)
I0525 05:20:59.426687 20374 sgd_solver.cpp:106] Iteration 18592, lr = 0.0015
I0525 05:21:08.280180 20374 solver.cpp:237] Iteration 18758, loss = 1.22276
I0525 05:21:08.280241 20374 solver.cpp:253]     Train net output #0: loss = 1.22276 (* 1 = 1.22276 loss)
I0525 05:21:08.280267 20374 sgd_solver.cpp:106] Iteration 18758, lr = 0.0015
I0525 05:21:37.951411 20374 solver.cpp:237] Iteration 18924, loss = 1.34604
I0525 05:21:37.951593 20374 solver.cpp:253]     Train net output #0: loss = 1.34604 (* 1 = 1.34604 loss)
I0525 05:21:37.951611 20374 sgd_solver.cpp:106] Iteration 18924, lr = 0.0015
I0525 05:21:46.798969 20374 solver.cpp:237] Iteration 19090, loss = 1.25745
I0525 05:21:46.799006 20374 solver.cpp:253]     Train net output #0: loss = 1.25745 (* 1 = 1.25745 loss)
I0525 05:21:46.799031 20374 sgd_solver.cpp:106] Iteration 19090, lr = 0.0015
I0525 05:21:55.642845 20374 solver.cpp:237] Iteration 19256, loss = 1.26009
I0525 05:21:55.642882 20374 solver.cpp:253]     Train net output #0: loss = 1.26009 (* 1 = 1.26009 loss)
I0525 05:21:55.642905 20374 sgd_solver.cpp:106] Iteration 19256, lr = 0.0015
I0525 05:22:04.492133 20374 solver.cpp:237] Iteration 19422, loss = 1.2979
I0525 05:22:04.492192 20374 solver.cpp:253]     Train net output #0: loss = 1.2979 (* 1 = 1.2979 loss)
I0525 05:22:04.492215 20374 sgd_solver.cpp:106] Iteration 19422, lr = 0.0015
I0525 05:22:13.335822 20374 solver.cpp:237] Iteration 19588, loss = 1.26962
I0525 05:22:13.335975 20374 solver.cpp:253]     Train net output #0: loss = 1.26962 (* 1 = 1.26962 loss)
I0525 05:22:13.335993 20374 sgd_solver.cpp:106] Iteration 19588, lr = 0.0015
I0525 05:22:22.179015 20374 solver.cpp:237] Iteration 19754, loss = 1.15
I0525 05:22:22.179052 20374 solver.cpp:253]     Train net output #0: loss = 1.15 (* 1 = 1.15 loss)
I0525 05:22:22.179071 20374 sgd_solver.cpp:106] Iteration 19754, lr = 0.0015
I0525 05:22:31.034723 20374 solver.cpp:237] Iteration 19920, loss = 1.07543
I0525 05:22:31.034776 20374 solver.cpp:253]     Train net output #0: loss = 1.07543 (* 1 = 1.07543 loss)
I0525 05:22:31.034803 20374 sgd_solver.cpp:106] Iteration 19920, lr = 0.0015
I0525 05:22:34.821156 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_19992.caffemodel
I0525 05:22:34.896136 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_19992.solverstate
I0525 05:22:35.208089 20374 solver.cpp:341] Iteration 19998, Testing net (#0)
I0525 05:23:43.291020 20374 solver.cpp:409]     Test net output #0: accuracy = 0.851174
I0525 05:23:43.291211 20374 solver.cpp:409]     Test net output #1: loss = 0.505186 (* 1 = 0.505186 loss)
I0525 05:24:08.839093 20374 solver.cpp:237] Iteration 20086, loss = 1.29242
I0525 05:24:08.839154 20374 solver.cpp:253]     Train net output #0: loss = 1.29242 (* 1 = 1.29242 loss)
I0525 05:24:08.839171 20374 sgd_solver.cpp:106] Iteration 20086, lr = 0.0015
I0525 05:24:17.681779 20374 solver.cpp:237] Iteration 20252, loss = 1.14375
I0525 05:24:17.681934 20374 solver.cpp:253]     Train net output #0: loss = 1.14375 (* 1 = 1.14375 loss)
I0525 05:24:17.681951 20374 sgd_solver.cpp:106] Iteration 20252, lr = 0.0015
I0525 05:24:26.525820 20374 solver.cpp:237] Iteration 20418, loss = 1.08992
I0525 05:24:26.525856 20374 solver.cpp:253]     Train net output #0: loss = 1.08992 (* 1 = 1.08992 loss)
I0525 05:24:26.525879 20374 sgd_solver.cpp:106] Iteration 20418, lr = 0.0015
I0525 05:24:35.371389 20374 solver.cpp:237] Iteration 20584, loss = 1.44657
I0525 05:24:35.371448 20374 solver.cpp:253]     Train net output #0: loss = 1.44657 (* 1 = 1.44657 loss)
I0525 05:24:35.371472 20374 sgd_solver.cpp:106] Iteration 20584, lr = 0.0015
I0525 05:24:44.218698 20374 solver.cpp:237] Iteration 20750, loss = 1.09399
I0525 05:24:44.218741 20374 solver.cpp:253]     Train net output #0: loss = 1.09399 (* 1 = 1.09399 loss)
I0525 05:24:44.218758 20374 sgd_solver.cpp:106] Iteration 20750, lr = 0.0015
I0525 05:24:53.062948 20374 solver.cpp:237] Iteration 20916, loss = 1.33264
I0525 05:24:53.063125 20374 solver.cpp:253]     Train net output #0: loss = 1.33264 (* 1 = 1.33264 loss)
I0525 05:24:53.063143 20374 sgd_solver.cpp:106] Iteration 20916, lr = 0.0015
I0525 05:25:01.901697 20374 solver.cpp:237] Iteration 21082, loss = 1.24021
I0525 05:25:01.901734 20374 solver.cpp:253]     Train net output #0: loss = 1.24021 (* 1 = 1.24021 loss)
I0525 05:25:01.901753 20374 sgd_solver.cpp:106] Iteration 21082, lr = 0.0015
I0525 05:25:31.639767 20374 solver.cpp:237] Iteration 21248, loss = 1.4527
I0525 05:25:31.639945 20374 solver.cpp:253]     Train net output #0: loss = 1.4527 (* 1 = 1.4527 loss)
I0525 05:25:31.639961 20374 sgd_solver.cpp:106] Iteration 21248, lr = 0.0015
I0525 05:25:40.478404 20374 solver.cpp:237] Iteration 21414, loss = 1.17632
I0525 05:25:40.478441 20374 solver.cpp:253]     Train net output #0: loss = 1.17632 (* 1 = 1.17632 loss)
I0525 05:25:40.478461 20374 sgd_solver.cpp:106] Iteration 21414, lr = 0.0015
I0525 05:25:49.327823 20374 solver.cpp:237] Iteration 21580, loss = 1.18107
I0525 05:25:49.327877 20374 solver.cpp:253]     Train net output #0: loss = 1.18107 (* 1 = 1.18107 loss)
I0525 05:25:49.327905 20374 sgd_solver.cpp:106] Iteration 21580, lr = 0.0015
I0525 05:25:53.429898 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_21658.caffemodel
I0525 05:25:53.505806 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_21658.solverstate
I0525 05:25:58.236156 20374 solver.cpp:237] Iteration 21746, loss = 1.16217
I0525 05:25:58.236213 20374 solver.cpp:253]     Train net output #0: loss = 1.16217 (* 1 = 1.16217 loss)
I0525 05:25:58.236239 20374 sgd_solver.cpp:106] Iteration 21746, lr = 0.0015
I0525 05:26:07.077083 20374 solver.cpp:237] Iteration 21912, loss = 1.15657
I0525 05:26:07.077250 20374 solver.cpp:253]     Train net output #0: loss = 1.15657 (* 1 = 1.15657 loss)
I0525 05:26:07.077266 20374 sgd_solver.cpp:106] Iteration 21912, lr = 0.0015
I0525 05:26:15.920963 20374 solver.cpp:237] Iteration 22078, loss = 1.20775
I0525 05:26:15.921013 20374 solver.cpp:253]     Train net output #0: loss = 1.20775 (* 1 = 1.20775 loss)
I0525 05:26:15.921042 20374 sgd_solver.cpp:106] Iteration 22078, lr = 0.0015
I0525 05:26:45.591176 20374 solver.cpp:237] Iteration 22244, loss = 1.06325
I0525 05:26:45.591368 20374 solver.cpp:253]     Train net output #0: loss = 1.06325 (* 1 = 1.06325 loss)
I0525 05:26:45.591385 20374 sgd_solver.cpp:106] Iteration 22244, lr = 0.0015
I0525 05:26:54.431594 20374 solver.cpp:237] Iteration 22410, loss = 1.37137
I0525 05:26:54.431632 20374 solver.cpp:253]     Train net output #0: loss = 1.37137 (* 1 = 1.37137 loss)
I0525 05:26:54.431656 20374 sgd_solver.cpp:106] Iteration 22410, lr = 0.0015
I0525 05:27:03.272758 20374 solver.cpp:237] Iteration 22576, loss = 1.15394
I0525 05:27:03.272814 20374 solver.cpp:253]     Train net output #0: loss = 1.15394 (* 1 = 1.15394 loss)
I0525 05:27:03.272842 20374 sgd_solver.cpp:106] Iteration 22576, lr = 0.0015
I0525 05:27:12.118036 20374 solver.cpp:237] Iteration 22742, loss = 1.13595
I0525 05:27:12.118072 20374 solver.cpp:253]     Train net output #0: loss = 1.13595 (* 1 = 1.13595 loss)
I0525 05:27:12.118090 20374 sgd_solver.cpp:106] Iteration 22742, lr = 0.0015
I0525 05:27:20.964663 20374 solver.cpp:237] Iteration 22908, loss = 1.23855
I0525 05:27:20.964817 20374 solver.cpp:253]     Train net output #0: loss = 1.23855 (* 1 = 1.23855 loss)
I0525 05:27:20.964833 20374 sgd_solver.cpp:106] Iteration 22908, lr = 0.0015
I0525 05:27:29.805482 20374 solver.cpp:237] Iteration 23074, loss = 1.3007
I0525 05:27:29.805541 20374 solver.cpp:253]     Train net output #0: loss = 1.3007 (* 1 = 1.3007 loss)
I0525 05:27:29.805564 20374 sgd_solver.cpp:106] Iteration 23074, lr = 0.0015
I0525 05:27:38.642616 20374 solver.cpp:237] Iteration 23240, loss = 1.26231
I0525 05:27:38.642654 20374 solver.cpp:253]     Train net output #0: loss = 1.26231 (* 1 = 1.26231 loss)
I0525 05:27:38.642671 20374 sgd_solver.cpp:106] Iteration 23240, lr = 0.0015
I0525 05:27:43.067324 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_23324.caffemodel
I0525 05:27:43.142894 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_23324.solverstate
I0525 05:27:43.505939 20374 solver.cpp:341] Iteration 23331, Testing net (#0)
I0525 05:28:30.372800 20374 solver.cpp:409]     Test net output #0: accuracy = 0.855363
I0525 05:28:30.372977 20374 solver.cpp:409]     Test net output #1: loss = 0.489993 (* 1 = 0.489993 loss)
I0525 05:28:55.254568 20374 solver.cpp:237] Iteration 23406, loss = 1.30668
I0525 05:28:55.254628 20374 solver.cpp:253]     Train net output #0: loss = 1.30668 (* 1 = 1.30668 loss)
I0525 05:28:55.254647 20374 sgd_solver.cpp:106] Iteration 23406, lr = 0.0015
I0525 05:29:04.111510 20374 solver.cpp:237] Iteration 23572, loss = 1.29962
I0525 05:29:04.111690 20374 solver.cpp:253]     Train net output #0: loss = 1.29962 (* 1 = 1.29962 loss)
I0525 05:29:04.111707 20374 sgd_solver.cpp:106] Iteration 23572, lr = 0.0015
I0525 05:29:12.952729 20374 solver.cpp:237] Iteration 23738, loss = 1.16479
I0525 05:29:12.952766 20374 solver.cpp:253]     Train net output #0: loss = 1.16479 (* 1 = 1.16479 loss)
I0525 05:29:12.952785 20374 sgd_solver.cpp:106] Iteration 23738, lr = 0.0015
I0525 05:29:21.802906 20374 solver.cpp:237] Iteration 23904, loss = 1.20941
I0525 05:29:21.802943 20374 solver.cpp:253]     Train net output #0: loss = 1.20941 (* 1 = 1.20941 loss)
I0525 05:29:21.802961 20374 sgd_solver.cpp:106] Iteration 23904, lr = 0.0015
I0525 05:29:30.649098 20374 solver.cpp:237] Iteration 24070, loss = 1.36515
I0525 05:29:30.649158 20374 solver.cpp:253]     Train net output #0: loss = 1.36515 (* 1 = 1.36515 loss)
I0525 05:29:30.649183 20374 sgd_solver.cpp:106] Iteration 24070, lr = 0.0015
I0525 05:29:39.491395 20374 solver.cpp:237] Iteration 24236, loss = 1.1694
I0525 05:29:39.491560 20374 solver.cpp:253]     Train net output #0: loss = 1.1694 (* 1 = 1.1694 loss)
I0525 05:29:39.491577 20374 sgd_solver.cpp:106] Iteration 24236, lr = 0.0015
I0525 05:29:48.343901 20374 solver.cpp:237] Iteration 24402, loss = 1.23953
I0525 05:29:48.343938 20374 solver.cpp:253]     Train net output #0: loss = 1.23953 (* 1 = 1.23953 loss)
I0525 05:29:48.343957 20374 sgd_solver.cpp:106] Iteration 24402, lr = 0.0015
I0525 05:30:18.062299 20374 solver.cpp:237] Iteration 24568, loss = 1.27357
I0525 05:30:18.062474 20374 solver.cpp:253]     Train net output #0: loss = 1.27357 (* 1 = 1.27357 loss)
I0525 05:30:18.062494 20374 sgd_solver.cpp:106] Iteration 24568, lr = 0.0015
I0525 05:30:26.906638 20374 solver.cpp:237] Iteration 24734, loss = 1.39115
I0525 05:30:26.906675 20374 solver.cpp:253]     Train net output #0: loss = 1.39115 (* 1 = 1.39115 loss)
I0525 05:30:26.906693 20374 sgd_solver.cpp:106] Iteration 24734, lr = 0.0015
I0525 05:30:35.742548 20374 solver.cpp:237] Iteration 24900, loss = 1.29007
I0525 05:30:35.742586 20374 solver.cpp:253]     Train net output #0: loss = 1.29007 (* 1 = 1.29007 loss)
I0525 05:30:35.742604 20374 sgd_solver.cpp:106] Iteration 24900, lr = 0.0015
I0525 05:30:40.480610 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_24990.caffemodel
I0525 05:30:40.556828 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_24990.solverstate
I0525 05:30:44.651713 20374 solver.cpp:237] Iteration 25066, loss = 1.15359
I0525 05:30:44.651774 20374 solver.cpp:253]     Train net output #0: loss = 1.15359 (* 1 = 1.15359 loss)
I0525 05:30:44.651800 20374 sgd_solver.cpp:106] Iteration 25066, lr = 0.0015
I0525 05:30:53.495931 20374 solver.cpp:237] Iteration 25232, loss = 1.26509
I0525 05:30:53.496090 20374 solver.cpp:253]     Train net output #0: loss = 1.26509 (* 1 = 1.26509 loss)
I0525 05:30:53.496106 20374 sgd_solver.cpp:106] Iteration 25232, lr = 0.0015
I0525 05:31:02.334233 20374 solver.cpp:237] Iteration 25398, loss = 1.19959
I0525 05:31:02.334269 20374 solver.cpp:253]     Train net output #0: loss = 1.19959 (* 1 = 1.19959 loss)
I0525 05:31:02.334287 20374 sgd_solver.cpp:106] Iteration 25398, lr = 0.0015
I0525 05:31:32.023861 20374 solver.cpp:237] Iteration 25564, loss = 1.33163
I0525 05:31:32.024045 20374 solver.cpp:253]     Train net output #0: loss = 1.33163 (* 1 = 1.33163 loss)
I0525 05:31:32.024062 20374 sgd_solver.cpp:106] Iteration 25564, lr = 0.0015
I0525 05:31:40.866302 20374 solver.cpp:237] Iteration 25730, loss = 1.2883
I0525 05:31:40.866358 20374 solver.cpp:253]     Train net output #0: loss = 1.2883 (* 1 = 1.2883 loss)
I0525 05:31:40.866384 20374 sgd_solver.cpp:106] Iteration 25730, lr = 0.0015
I0525 05:31:49.712486 20374 solver.cpp:237] Iteration 25896, loss = 1.36552
I0525 05:31:49.712523 20374 solver.cpp:253]     Train net output #0: loss = 1.36552 (* 1 = 1.36552 loss)
I0525 05:31:49.712548 20374 sgd_solver.cpp:106] Iteration 25896, lr = 0.0015
I0525 05:31:58.554463 20374 solver.cpp:237] Iteration 26062, loss = 1.22876
I0525 05:31:58.554518 20374 solver.cpp:253]     Train net output #0: loss = 1.22876 (* 1 = 1.22876 loss)
I0525 05:31:58.554545 20374 sgd_solver.cpp:106] Iteration 26062, lr = 0.0015
I0525 05:32:07.398450 20374 solver.cpp:237] Iteration 26228, loss = 1.35698
I0525 05:32:07.398617 20374 solver.cpp:253]     Train net output #0: loss = 1.35698 (* 1 = 1.35698 loss)
I0525 05:32:07.398634 20374 sgd_solver.cpp:106] Iteration 26228, lr = 0.0015
I0525 05:32:16.233217 20374 solver.cpp:237] Iteration 26394, loss = 1.30573
I0525 05:32:16.233253 20374 solver.cpp:253]     Train net output #0: loss = 1.30573 (* 1 = 1.30573 loss)
I0525 05:32:16.233271 20374 sgd_solver.cpp:106] Iteration 26394, lr = 0.0015
I0525 05:32:25.081078 20374 solver.cpp:237] Iteration 26560, loss = 1.31827
I0525 05:32:25.081133 20374 solver.cpp:253]     Train net output #0: loss = 1.31827 (* 1 = 1.31827 loss)
I0525 05:32:25.081161 20374 sgd_solver.cpp:106] Iteration 26560, lr = 0.0015
I0525 05:32:30.150009 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_26656.caffemodel
I0525 05:32:30.225915 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_26656.solverstate
I0525 05:32:30.640350 20374 solver.cpp:341] Iteration 26664, Testing net (#0)
I0525 05:33:38.629143 20374 solver.cpp:409]     Test net output #0: accuracy = 0.86148
I0525 05:33:38.629313 20374 solver.cpp:409]     Test net output #1: loss = 0.496242 (* 1 = 0.496242 loss)
I0525 05:34:02.744078 20374 solver.cpp:237] Iteration 26726, loss = 1.22803
I0525 05:34:02.744137 20374 solver.cpp:253]     Train net output #0: loss = 1.22803 (* 1 = 1.22803 loss)
I0525 05:34:02.744161 20374 sgd_solver.cpp:106] Iteration 26726, lr = 0.0015
I0525 05:34:11.593888 20374 solver.cpp:237] Iteration 26892, loss = 1.39379
I0525 05:34:11.594053 20374 solver.cpp:253]     Train net output #0: loss = 1.39379 (* 1 = 1.39379 loss)
I0525 05:34:11.594071 20374 sgd_solver.cpp:106] Iteration 26892, lr = 0.0015
I0525 05:34:20.444758 20374 solver.cpp:237] Iteration 27058, loss = 1.16552
I0525 05:34:20.444795 20374 solver.cpp:253]     Train net output #0: loss = 1.16552 (* 1 = 1.16552 loss)
I0525 05:34:20.444813 20374 sgd_solver.cpp:106] Iteration 27058, lr = 0.0015
I0525 05:34:29.293505 20374 solver.cpp:237] Iteration 27224, loss = 1.30003
I0525 05:34:29.293556 20374 solver.cpp:253]     Train net output #0: loss = 1.30003 (* 1 = 1.30003 loss)
I0525 05:34:29.293586 20374 sgd_solver.cpp:106] Iteration 27224, lr = 0.0015
I0525 05:34:38.139505 20374 solver.cpp:237] Iteration 27390, loss = 1.16832
I0525 05:34:38.139542 20374 solver.cpp:253]     Train net output #0: loss = 1.16832 (* 1 = 1.16832 loss)
I0525 05:34:38.139561 20374 sgd_solver.cpp:106] Iteration 27390, lr = 0.0015
I0525 05:34:46.985431 20374 solver.cpp:237] Iteration 27556, loss = 1.15582
I0525 05:34:46.985589 20374 solver.cpp:253]     Train net output #0: loss = 1.15582 (* 1 = 1.15582 loss)
I0525 05:34:46.985605 20374 sgd_solver.cpp:106] Iteration 27556, lr = 0.0015
I0525 05:34:55.836364 20374 solver.cpp:237] Iteration 27722, loss = 1.16425
I0525 05:34:55.836415 20374 solver.cpp:253]     Train net output #0: loss = 1.16425 (* 1 = 1.16425 loss)
I0525 05:34:55.836444 20374 sgd_solver.cpp:106] Iteration 27722, lr = 0.0015
I0525 05:35:25.528285 20374 solver.cpp:237] Iteration 27888, loss = 1.12657
I0525 05:35:25.528471 20374 solver.cpp:253]     Train net output #0: loss = 1.12657 (* 1 = 1.12657 loss)
I0525 05:35:25.528491 20374 sgd_solver.cpp:106] Iteration 27888, lr = 0.0015
I0525 05:35:34.379639 20374 solver.cpp:237] Iteration 28054, loss = 1.19892
I0525 05:35:34.379675 20374 solver.cpp:253]     Train net output #0: loss = 1.19892 (* 1 = 1.19892 loss)
I0525 05:35:34.379694 20374 sgd_solver.cpp:106] Iteration 28054, lr = 0.0015
I0525 05:35:43.236341 20374 solver.cpp:237] Iteration 28220, loss = 1.22094
I0525 05:35:43.236399 20374 solver.cpp:253]     Train net output #0: loss = 1.22094 (* 1 = 1.22094 loss)
I0525 05:35:43.236425 20374 sgd_solver.cpp:106] Iteration 28220, lr = 0.0015
I0525 05:35:48.616700 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_28322.caffemodel
I0525 05:35:48.691323 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_28322.solverstate
I0525 05:35:52.142426 20374 solver.cpp:237] Iteration 28386, loss = 1.21662
I0525 05:35:52.142479 20374 solver.cpp:253]     Train net output #0: loss = 1.21662 (* 1 = 1.21662 loss)
I0525 05:35:52.142503 20374 sgd_solver.cpp:106] Iteration 28386, lr = 0.0015
I0525 05:36:00.987037 20374 solver.cpp:237] Iteration 28552, loss = 1.04912
I0525 05:36:00.987208 20374 solver.cpp:253]     Train net output #0: loss = 1.04912 (* 1 = 1.04912 loss)
I0525 05:36:00.987224 20374 sgd_solver.cpp:106] Iteration 28552, lr = 0.0015
I0525 05:36:09.831075 20374 solver.cpp:237] Iteration 28718, loss = 1.20764
I0525 05:36:09.831131 20374 solver.cpp:253]     Train net output #0: loss = 1.20764 (* 1 = 1.20764 loss)
I0525 05:36:09.831159 20374 sgd_solver.cpp:106] Iteration 28718, lr = 0.0015
I0525 05:36:18.677850 20374 solver.cpp:237] Iteration 28884, loss = 1.08941
I0525 05:36:18.677892 20374 solver.cpp:253]     Train net output #0: loss = 1.08941 (* 1 = 1.08941 loss)
I0525 05:36:18.677916 20374 sgd_solver.cpp:106] Iteration 28884, lr = 0.0015
I0525 05:36:48.380471 20374 solver.cpp:237] Iteration 29050, loss = 1.33659
I0525 05:36:48.380661 20374 solver.cpp:253]     Train net output #0: loss = 1.33659 (* 1 = 1.33659 loss)
I0525 05:36:48.380678 20374 sgd_solver.cpp:106] Iteration 29050, lr = 0.0015
I0525 05:36:57.228751 20374 solver.cpp:237] Iteration 29216, loss = 1.10165
I0525 05:36:57.228788 20374 solver.cpp:253]     Train net output #0: loss = 1.10165 (* 1 = 1.10165 loss)
I0525 05:36:57.228807 20374 sgd_solver.cpp:106] Iteration 29216, lr = 0.0015
I0525 05:37:06.078657 20374 solver.cpp:237] Iteration 29382, loss = 1.50733
I0525 05:37:06.078716 20374 solver.cpp:253]     Train net output #0: loss = 1.50733 (* 1 = 1.50733 loss)
I0525 05:37:06.078739 20374 sgd_solver.cpp:106] Iteration 29382, lr = 0.0015
I0525 05:37:14.926259 20374 solver.cpp:237] Iteration 29548, loss = 1.3861
I0525 05:37:14.926297 20374 solver.cpp:253]     Train net output #0: loss = 1.3861 (* 1 = 1.3861 loss)
I0525 05:37:14.926316 20374 sgd_solver.cpp:106] Iteration 29548, lr = 0.0015
I0525 05:37:23.774124 20374 solver.cpp:237] Iteration 29714, loss = 1.08901
I0525 05:37:23.774312 20374 solver.cpp:253]     Train net output #0: loss = 1.08901 (* 1 = 1.08901 loss)
I0525 05:37:23.774329 20374 sgd_solver.cpp:106] Iteration 29714, lr = 0.0015
I0525 05:37:32.619081 20374 solver.cpp:237] Iteration 29880, loss = 1.2864
I0525 05:37:32.619118 20374 solver.cpp:253]     Train net output #0: loss = 1.2864 (* 1 = 1.2864 loss)
I0525 05:37:32.619137 20374 sgd_solver.cpp:106] Iteration 29880, lr = 0.0015
I0525 05:37:38.318680 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_29988.caffemodel
I0525 05:37:38.395565 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_29988.solverstate
I0525 05:37:38.865730 20374 solver.cpp:341] Iteration 29997, Testing net (#0)
I0525 05:38:26.081554 20374 solver.cpp:409]     Test net output #0: accuracy = 0.865269
I0525 05:38:26.081745 20374 solver.cpp:409]     Test net output #1: loss = 0.439188 (* 1 = 0.439188 loss)
I0525 05:38:49.578462 20374 solver.cpp:237] Iteration 30046, loss = 1.10297
I0525 05:38:49.578519 20374 solver.cpp:253]     Train net output #0: loss = 1.10297 (* 1 = 1.10297 loss)
I0525 05:38:49.578543 20374 sgd_solver.cpp:106] Iteration 30046, lr = 0.0015
I0525 05:38:58.421839 20374 solver.cpp:237] Iteration 30212, loss = 1.35866
I0525 05:38:58.422005 20374 solver.cpp:253]     Train net output #0: loss = 1.35866 (* 1 = 1.35866 loss)
I0525 05:38:58.422021 20374 sgd_solver.cpp:106] Iteration 30212, lr = 0.0015
I0525 05:39:07.254915 20374 solver.cpp:237] Iteration 30378, loss = 1.45774
I0525 05:39:07.254971 20374 solver.cpp:253]     Train net output #0: loss = 1.45774 (* 1 = 1.45774 loss)
I0525 05:39:07.254987 20374 sgd_solver.cpp:106] Iteration 30378, lr = 0.0015
I0525 05:39:16.105242 20374 solver.cpp:237] Iteration 30544, loss = 1.23903
I0525 05:39:16.105279 20374 solver.cpp:253]     Train net output #0: loss = 1.23903 (* 1 = 1.23903 loss)
I0525 05:39:16.105296 20374 sgd_solver.cpp:106] Iteration 30544, lr = 0.0015
I0525 05:39:24.957603 20374 solver.cpp:237] Iteration 30710, loss = 1.19579
I0525 05:39:24.957640 20374 solver.cpp:253]     Train net output #0: loss = 1.19579 (* 1 = 1.19579 loss)
I0525 05:39:24.957659 20374 sgd_solver.cpp:106] Iteration 30710, lr = 0.0015
I0525 05:39:33.805958 20374 solver.cpp:237] Iteration 30876, loss = 1.01964
I0525 05:39:33.806148 20374 solver.cpp:253]     Train net output #0: loss = 1.01964 (* 1 = 1.01964 loss)
I0525 05:39:33.806164 20374 sgd_solver.cpp:106] Iteration 30876, lr = 0.0015
I0525 05:39:42.654206 20374 solver.cpp:237] Iteration 31042, loss = 1.18997
I0525 05:39:42.654243 20374 solver.cpp:253]     Train net output #0: loss = 1.18997 (* 1 = 1.18997 loss)
I0525 05:39:42.654263 20374 sgd_solver.cpp:106] Iteration 31042, lr = 0.0015
I0525 05:40:12.369338 20374 solver.cpp:237] Iteration 31208, loss = 1.2596
I0525 05:40:12.369521 20374 solver.cpp:253]     Train net output #0: loss = 1.2596 (* 1 = 1.2596 loss)
I0525 05:40:12.369539 20374 sgd_solver.cpp:106] Iteration 31208, lr = 0.0015
I0525 05:40:21.208919 20374 solver.cpp:237] Iteration 31374, loss = 1.17447
I0525 05:40:21.208977 20374 solver.cpp:253]     Train net output #0: loss = 1.17447 (* 1 = 1.17447 loss)
I0525 05:40:21.209002 20374 sgd_solver.cpp:106] Iteration 31374, lr = 0.0015
I0525 05:40:30.052624 20374 solver.cpp:237] Iteration 31540, loss = 1.30554
I0525 05:40:30.052662 20374 solver.cpp:253]     Train net output #0: loss = 1.30554 (* 1 = 1.30554 loss)
I0525 05:40:30.052681 20374 sgd_solver.cpp:106] Iteration 31540, lr = 0.0015
I0525 05:40:36.078797 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_31654.caffemodel
I0525 05:40:36.157322 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_31654.solverstate
I0525 05:40:38.973431 20374 solver.cpp:237] Iteration 31706, loss = 1.18168
I0525 05:40:38.973487 20374 solver.cpp:253]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0525 05:40:38.973511 20374 sgd_solver.cpp:106] Iteration 31706, lr = 0.0015
I0525 05:40:47.821908 20374 solver.cpp:237] Iteration 31872, loss = 1.19318
I0525 05:40:47.822093 20374 solver.cpp:253]     Train net output #0: loss = 1.19318 (* 1 = 1.19318 loss)
I0525 05:40:47.822110 20374 sgd_solver.cpp:106] Iteration 31872, lr = 0.0015
I0525 05:40:56.678331 20374 solver.cpp:237] Iteration 32038, loss = 1.25802
I0525 05:40:56.678369 20374 solver.cpp:253]     Train net output #0: loss = 1.25802 (* 1 = 1.25802 loss)
I0525 05:40:56.678388 20374 sgd_solver.cpp:106] Iteration 32038, lr = 0.0015
I0525 05:41:05.525734 20374 solver.cpp:237] Iteration 32204, loss = 1.26669
I0525 05:41:05.525771 20374 solver.cpp:253]     Train net output #0: loss = 1.26669 (* 1 = 1.26669 loss)
I0525 05:41:05.525790 20374 sgd_solver.cpp:106] Iteration 32204, lr = 0.0015
I0525 05:41:35.237643 20374 solver.cpp:237] Iteration 32370, loss = 1.31779
I0525 05:41:35.237834 20374 solver.cpp:253]     Train net output #0: loss = 1.31779 (* 1 = 1.31779 loss)
I0525 05:41:35.237853 20374 sgd_solver.cpp:106] Iteration 32370, lr = 0.0015
I0525 05:41:44.087546 20374 solver.cpp:237] Iteration 32536, loss = 1.15674
I0525 05:41:44.087585 20374 solver.cpp:253]     Train net output #0: loss = 1.15674 (* 1 = 1.15674 loss)
I0525 05:41:44.087604 20374 sgd_solver.cpp:106] Iteration 32536, lr = 0.0015
I0525 05:41:52.923169 20374 solver.cpp:237] Iteration 32702, loss = 1.39796
I0525 05:41:52.923205 20374 solver.cpp:253]     Train net output #0: loss = 1.39796 (* 1 = 1.39796 loss)
I0525 05:41:52.923229 20374 sgd_solver.cpp:106] Iteration 32702, lr = 0.0015
I0525 05:42:01.768985 20374 solver.cpp:237] Iteration 32868, loss = 1.40789
I0525 05:42:01.769044 20374 solver.cpp:253]     Train net output #0: loss = 1.40789 (* 1 = 1.40789 loss)
I0525 05:42:01.769070 20374 sgd_solver.cpp:106] Iteration 32868, lr = 0.0015
I0525 05:42:10.609385 20374 solver.cpp:237] Iteration 33034, loss = 1.40392
I0525 05:42:10.609557 20374 solver.cpp:253]     Train net output #0: loss = 1.40392 (* 1 = 1.40392 loss)
I0525 05:42:10.609575 20374 sgd_solver.cpp:106] Iteration 33034, lr = 0.0015
I0525 05:42:19.455983 20374 solver.cpp:237] Iteration 33200, loss = 1.25537
I0525 05:42:19.456020 20374 solver.cpp:253]     Train net output #0: loss = 1.25537 (* 1 = 1.25537 loss)
I0525 05:42:19.456039 20374 sgd_solver.cpp:106] Iteration 33200, lr = 0.0015
I0525 05:42:25.800447 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_33320.caffemodel
I0525 05:42:25.877676 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_33320.solverstate
I0525 05:42:26.403939 20374 solver.cpp:341] Iteration 33330, Testing net (#0)
I0525 05:43:34.509636 20374 solver.cpp:409]     Test net output #0: accuracy = 0.865588
I0525 05:43:34.509821 20374 solver.cpp:409]     Test net output #1: loss = 0.474607 (* 1 = 0.474607 loss)
I0525 05:43:57.332818 20374 solver.cpp:237] Iteration 33366, loss = 1.49724
I0525 05:43:57.332877 20374 solver.cpp:253]     Train net output #0: loss = 1.49724 (* 1 = 1.49724 loss)
I0525 05:43:57.332896 20374 sgd_solver.cpp:106] Iteration 33366, lr = 0.0015
I0525 05:44:06.176602 20374 solver.cpp:237] Iteration 33532, loss = 1.47543
I0525 05:44:06.176784 20374 solver.cpp:253]     Train net output #0: loss = 1.47543 (* 1 = 1.47543 loss)
I0525 05:44:06.176803 20374 sgd_solver.cpp:106] Iteration 33532, lr = 0.0015
I0525 05:44:15.024227 20374 solver.cpp:237] Iteration 33698, loss = 1.11037
I0525 05:44:15.024266 20374 solver.cpp:253]     Train net output #0: loss = 1.11037 (* 1 = 1.11037 loss)
I0525 05:44:15.024282 20374 sgd_solver.cpp:106] Iteration 33698, lr = 0.0015
I0525 05:44:23.867553 20374 solver.cpp:237] Iteration 33864, loss = 1.14227
I0525 05:44:23.867589 20374 solver.cpp:253]     Train net output #0: loss = 1.14227 (* 1 = 1.14227 loss)
I0525 05:44:23.867607 20374 sgd_solver.cpp:106] Iteration 33864, lr = 0.0015
I0525 05:44:32.719873 20374 solver.cpp:237] Iteration 34030, loss = 1.24281
I0525 05:44:32.719931 20374 solver.cpp:253]     Train net output #0: loss = 1.24281 (* 1 = 1.24281 loss)
I0525 05:44:32.719956 20374 sgd_solver.cpp:106] Iteration 34030, lr = 0.0015
I0525 05:44:41.554000 20374 solver.cpp:237] Iteration 34196, loss = 1.21894
I0525 05:44:41.554160 20374 solver.cpp:253]     Train net output #0: loss = 1.21894 (* 1 = 1.21894 loss)
I0525 05:44:41.554177 20374 sgd_solver.cpp:106] Iteration 34196, lr = 0.0015
I0525 05:44:50.404006 20374 solver.cpp:237] Iteration 34362, loss = 1.16081
I0525 05:44:50.404042 20374 solver.cpp:253]     Train net output #0: loss = 1.16081 (* 1 = 1.16081 loss)
I0525 05:44:50.404065 20374 sgd_solver.cpp:106] Iteration 34362, lr = 0.0015
I0525 05:45:20.150548 20374 solver.cpp:237] Iteration 34528, loss = 1.26883
I0525 05:45:20.150732 20374 solver.cpp:253]     Train net output #0: loss = 1.26883 (* 1 = 1.26883 loss)
I0525 05:45:20.150748 20374 sgd_solver.cpp:106] Iteration 34528, lr = 0.0015
I0525 05:45:28.991724 20374 solver.cpp:237] Iteration 34694, loss = 1.24824
I0525 05:45:28.991760 20374 solver.cpp:253]     Train net output #0: loss = 1.24824 (* 1 = 1.24824 loss)
I0525 05:45:28.991780 20374 sgd_solver.cpp:106] Iteration 34694, lr = 0.0015
I0525 05:45:37.832029 20374 solver.cpp:237] Iteration 34860, loss = 1.26602
I0525 05:45:37.832067 20374 solver.cpp:253]     Train net output #0: loss = 1.26602 (* 1 = 1.26602 loss)
I0525 05:45:37.832084 20374 sgd_solver.cpp:106] Iteration 34860, lr = 0.0015
I0525 05:45:44.489161 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_34986.caffemodel
I0525 05:45:44.608358 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_34986.solverstate
I0525 05:45:46.781142 20374 solver.cpp:237] Iteration 35026, loss = 1.05373
I0525 05:45:46.781198 20374 solver.cpp:253]     Train net output #0: loss = 1.05373 (* 1 = 1.05373 loss)
I0525 05:45:46.781224 20374 sgd_solver.cpp:106] Iteration 35026, lr = 0.0015
I0525 05:45:55.639470 20374 solver.cpp:237] Iteration 35192, loss = 1.20663
I0525 05:45:55.639653 20374 solver.cpp:253]     Train net output #0: loss = 1.20663 (* 1 = 1.20663 loss)
I0525 05:45:55.639670 20374 sgd_solver.cpp:106] Iteration 35192, lr = 0.0015
I0525 05:46:04.490456 20374 solver.cpp:237] Iteration 35358, loss = 1.03812
I0525 05:46:04.490492 20374 solver.cpp:253]     Train net output #0: loss = 1.03812 (* 1 = 1.03812 loss)
I0525 05:46:04.490516 20374 sgd_solver.cpp:106] Iteration 35358, lr = 0.0015
I0525 05:46:13.335337 20374 solver.cpp:237] Iteration 35524, loss = 1.43571
I0525 05:46:13.335383 20374 solver.cpp:253]     Train net output #0: loss = 1.43571 (* 1 = 1.43571 loss)
I0525 05:46:13.335402 20374 sgd_solver.cpp:106] Iteration 35524, lr = 0.0015
I0525 05:46:43.025722 20374 solver.cpp:237] Iteration 35690, loss = 1.34186
I0525 05:46:43.025919 20374 solver.cpp:253]     Train net output #0: loss = 1.34186 (* 1 = 1.34186 loss)
I0525 05:46:43.025938 20374 sgd_solver.cpp:106] Iteration 35690, lr = 0.0015
I0525 05:46:51.879590 20374 solver.cpp:237] Iteration 35856, loss = 1.3496
I0525 05:46:51.879626 20374 solver.cpp:253]     Train net output #0: loss = 1.3496 (* 1 = 1.3496 loss)
I0525 05:46:51.879649 20374 sgd_solver.cpp:106] Iteration 35856, lr = 0.0015
I0525 05:47:00.715482 20374 solver.cpp:237] Iteration 36022, loss = 1.18248
I0525 05:47:00.715536 20374 solver.cpp:253]     Train net output #0: loss = 1.18248 (* 1 = 1.18248 loss)
I0525 05:47:00.715565 20374 sgd_solver.cpp:106] Iteration 36022, lr = 0.0015
I0525 05:47:09.559475 20374 solver.cpp:237] Iteration 36188, loss = 1.35695
I0525 05:47:09.559512 20374 solver.cpp:253]     Train net output #0: loss = 1.35695 (* 1 = 1.35695 loss)
I0525 05:47:09.559535 20374 sgd_solver.cpp:106] Iteration 36188, lr = 0.0015
I0525 05:47:18.401933 20374 solver.cpp:237] Iteration 36354, loss = 1.14207
I0525 05:47:18.402096 20374 solver.cpp:253]     Train net output #0: loss = 1.14207 (* 1 = 1.14207 loss)
I0525 05:47:18.402112 20374 sgd_solver.cpp:106] Iteration 36354, lr = 0.0015
I0525 05:47:27.240176 20374 solver.cpp:237] Iteration 36520, loss = 1.17289
I0525 05:47:27.240233 20374 solver.cpp:253]     Train net output #0: loss = 1.17289 (* 1 = 1.17289 loss)
I0525 05:47:27.240258 20374 sgd_solver.cpp:106] Iteration 36520, lr = 0.0015
I0525 05:47:34.219033 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_36652.caffemodel
I0525 05:47:34.299309 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_36652.solverstate
I0525 05:47:34.876451 20374 solver.cpp:341] Iteration 36663, Testing net (#0)
I0525 05:48:21.715901 20374 solver.cpp:409]     Test net output #0: accuracy = 0.872825
I0525 05:48:21.716084 20374 solver.cpp:409]     Test net output #1: loss = 0.412894 (* 1 = 0.412894 loss)
I0525 05:48:43.805619 20374 solver.cpp:237] Iteration 36686, loss = 1.28628
I0525 05:48:43.805678 20374 solver.cpp:253]     Train net output #0: loss = 1.28628 (* 1 = 1.28628 loss)
I0525 05:48:43.805697 20374 sgd_solver.cpp:106] Iteration 36686, lr = 0.0015
I0525 05:48:52.648850 20374 solver.cpp:237] Iteration 36852, loss = 1.31197
I0525 05:48:52.649029 20374 solver.cpp:253]     Train net output #0: loss = 1.31197 (* 1 = 1.31197 loss)
I0525 05:48:52.649046 20374 sgd_solver.cpp:106] Iteration 36852, lr = 0.0015
I0525 05:49:01.488366 20374 solver.cpp:237] Iteration 37018, loss = 1.18642
I0525 05:49:01.488404 20374 solver.cpp:253]     Train net output #0: loss = 1.18642 (* 1 = 1.18642 loss)
I0525 05:49:01.488426 20374 sgd_solver.cpp:106] Iteration 37018, lr = 0.0015
I0525 05:49:10.341039 20374 solver.cpp:237] Iteration 37184, loss = 1.11287
I0525 05:49:10.341096 20374 solver.cpp:253]     Train net output #0: loss = 1.11287 (* 1 = 1.11287 loss)
I0525 05:49:10.341120 20374 sgd_solver.cpp:106] Iteration 37184, lr = 0.0015
I0525 05:49:19.205013 20374 solver.cpp:237] Iteration 37350, loss = 1.0913
I0525 05:49:19.205049 20374 solver.cpp:253]     Train net output #0: loss = 1.0913 (* 1 = 1.0913 loss)
I0525 05:49:19.205068 20374 sgd_solver.cpp:106] Iteration 37350, lr = 0.0015
I0525 05:49:28.045567 20374 solver.cpp:237] Iteration 37516, loss = 1.40231
I0525 05:49:28.045764 20374 solver.cpp:253]     Train net output #0: loss = 1.40231 (* 1 = 1.40231 loss)
I0525 05:49:28.045783 20374 sgd_solver.cpp:106] Iteration 37516, lr = 0.0015
I0525 05:49:36.905500 20374 solver.cpp:237] Iteration 37682, loss = 1.09369
I0525 05:49:36.905539 20374 solver.cpp:253]     Train net output #0: loss = 1.09369 (* 1 = 1.09369 loss)
I0525 05:49:36.905557 20374 sgd_solver.cpp:106] Iteration 37682, lr = 0.0015
I0525 05:50:06.604038 20374 solver.cpp:237] Iteration 37848, loss = 1.01131
I0525 05:50:06.604224 20374 solver.cpp:253]     Train net output #0: loss = 1.01131 (* 1 = 1.01131 loss)
I0525 05:50:06.604243 20374 sgd_solver.cpp:106] Iteration 37848, lr = 0.0015
I0525 05:50:15.461231 20374 solver.cpp:237] Iteration 38014, loss = 1.35654
I0525 05:50:15.461268 20374 solver.cpp:253]     Train net output #0: loss = 1.35654 (* 1 = 1.35654 loss)
I0525 05:50:15.461287 20374 sgd_solver.cpp:106] Iteration 38014, lr = 0.0015
I0525 05:50:24.321794 20374 solver.cpp:237] Iteration 38180, loss = 1.15639
I0525 05:50:24.321841 20374 solver.cpp:253]     Train net output #0: loss = 1.15639 (* 1 = 1.15639 loss)
I0525 05:50:24.321869 20374 sgd_solver.cpp:106] Iteration 38180, lr = 0.0015
I0525 05:50:31.621184 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_38318.caffemodel
I0525 05:50:31.697739 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_38318.solverstate
I0525 05:50:33.231827 20374 solver.cpp:237] Iteration 38346, loss = 1.39568
I0525 05:50:33.231880 20374 solver.cpp:253]     Train net output #0: loss = 1.39568 (* 1 = 1.39568 loss)
I0525 05:50:33.231909 20374 sgd_solver.cpp:106] Iteration 38346, lr = 0.0015
I0525 05:50:42.076560 20374 solver.cpp:237] Iteration 38512, loss = 1.25051
I0525 05:50:42.076727 20374 solver.cpp:253]     Train net output #0: loss = 1.25051 (* 1 = 1.25051 loss)
I0525 05:50:42.076745 20374 sgd_solver.cpp:106] Iteration 38512, lr = 0.0015
I0525 05:50:50.925406 20374 solver.cpp:237] Iteration 38678, loss = 1.27864
I0525 05:50:50.925454 20374 solver.cpp:253]     Train net output #0: loss = 1.27864 (* 1 = 1.27864 loss)
I0525 05:50:50.925472 20374 sgd_solver.cpp:106] Iteration 38678, lr = 0.0015
I0525 05:50:59.770367 20374 solver.cpp:237] Iteration 38844, loss = 1.19214
I0525 05:50:59.770404 20374 solver.cpp:253]     Train net output #0: loss = 1.19214 (* 1 = 1.19214 loss)
I0525 05:50:59.770423 20374 sgd_solver.cpp:106] Iteration 38844, lr = 0.0015
I0525 05:51:29.465013 20374 solver.cpp:237] Iteration 39010, loss = 1.24048
I0525 05:51:29.465211 20374 solver.cpp:253]     Train net output #0: loss = 1.24048 (* 1 = 1.24048 loss)
I0525 05:51:29.465229 20374 sgd_solver.cpp:106] Iteration 39010, lr = 0.0015
I0525 05:51:38.325238 20374 solver.cpp:237] Iteration 39176, loss = 1.14841
I0525 05:51:38.325295 20374 solver.cpp:253]     Train net output #0: loss = 1.14841 (* 1 = 1.14841 loss)
I0525 05:51:38.325321 20374 sgd_solver.cpp:106] Iteration 39176, lr = 0.0015
I0525 05:51:47.174074 20374 solver.cpp:237] Iteration 39342, loss = 1.22984
I0525 05:51:47.174113 20374 solver.cpp:253]     Train net output #0: loss = 1.22984 (* 1 = 1.22984 loss)
I0525 05:51:47.174131 20374 sgd_solver.cpp:106] Iteration 39342, lr = 0.0015
I0525 05:51:56.031512 20374 solver.cpp:237] Iteration 39508, loss = 1.21247
I0525 05:51:56.031548 20374 solver.cpp:253]     Train net output #0: loss = 1.21247 (* 1 = 1.21247 loss)
I0525 05:51:56.031566 20374 sgd_solver.cpp:106] Iteration 39508, lr = 0.0015
I0525 05:52:04.870467 20374 solver.cpp:237] Iteration 39674, loss = 1.15258
I0525 05:52:04.870653 20374 solver.cpp:253]     Train net output #0: loss = 1.15258 (* 1 = 1.15258 loss)
I0525 05:52:04.870671 20374 sgd_solver.cpp:106] Iteration 39674, lr = 0.0015
I0525 05:52:13.712273 20374 solver.cpp:237] Iteration 39840, loss = 1.31861
I0525 05:52:13.712311 20374 solver.cpp:253]     Train net output #0: loss = 1.31861 (* 1 = 1.31861 loss)
I0525 05:52:13.712339 20374 sgd_solver.cpp:106] Iteration 39840, lr = 0.0015
I0525 05:52:21.331679 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_39984.caffemodel
I0525 05:52:21.407404 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_39984.solverstate
I0525 05:52:22.036700 20374 solver.cpp:341] Iteration 39996, Testing net (#0)
I0525 05:53:30.127827 20374 solver.cpp:409]     Test net output #0: accuracy = 0.875414
I0525 05:53:30.128026 20374 solver.cpp:409]     Test net output #1: loss = 0.435737 (* 1 = 0.435737 loss)
I0525 05:53:51.547281 20374 solver.cpp:237] Iteration 40006, loss = 1.37261
I0525 05:53:51.547341 20374 solver.cpp:253]     Train net output #0: loss = 1.37261 (* 1 = 1.37261 loss)
I0525 05:53:51.547360 20374 sgd_solver.cpp:106] Iteration 40006, lr = 0.0015
I0525 05:54:00.393931 20374 solver.cpp:237] Iteration 40172, loss = 1.14388
I0525 05:54:00.394101 20374 solver.cpp:253]     Train net output #0: loss = 1.14388 (* 1 = 1.14388 loss)
I0525 05:54:00.394117 20374 sgd_solver.cpp:106] Iteration 40172, lr = 0.0015
I0525 05:54:09.256896 20374 solver.cpp:237] Iteration 40338, loss = 1.29921
I0525 05:54:09.256952 20374 solver.cpp:253]     Train net output #0: loss = 1.29921 (* 1 = 1.29921 loss)
I0525 05:54:09.256980 20374 sgd_solver.cpp:106] Iteration 40338, lr = 0.0015
I0525 05:54:18.102826 20374 solver.cpp:237] Iteration 40504, loss = 1.19822
I0525 05:54:18.102864 20374 solver.cpp:253]     Train net output #0: loss = 1.19822 (* 1 = 1.19822 loss)
I0525 05:54:18.102886 20374 sgd_solver.cpp:106] Iteration 40504, lr = 0.0015
I0525 05:54:26.944638 20374 solver.cpp:237] Iteration 40670, loss = 1.15963
I0525 05:54:26.944674 20374 solver.cpp:253]     Train net output #0: loss = 1.15963 (* 1 = 1.15963 loss)
I0525 05:54:26.944694 20374 sgd_solver.cpp:106] Iteration 40670, lr = 0.0015
I0525 05:54:35.803230 20374 solver.cpp:237] Iteration 40836, loss = 1.25644
I0525 05:54:35.803414 20374 solver.cpp:253]     Train net output #0: loss = 1.25644 (* 1 = 1.25644 loss)
I0525 05:54:35.803432 20374 sgd_solver.cpp:106] Iteration 40836, lr = 0.0015
I0525 05:54:44.654135 20374 solver.cpp:237] Iteration 41002, loss = 1.23781
I0525 05:54:44.654172 20374 solver.cpp:253]     Train net output #0: loss = 1.23781 (* 1 = 1.23781 loss)
I0525 05:54:44.654191 20374 sgd_solver.cpp:106] Iteration 41002, lr = 0.0015
I0525 05:55:14.389865 20374 solver.cpp:237] Iteration 41168, loss = 1.14844
I0525 05:55:14.390055 20374 solver.cpp:253]     Train net output #0: loss = 1.14844 (* 1 = 1.14844 loss)
I0525 05:55:14.390072 20374 sgd_solver.cpp:106] Iteration 41168, lr = 0.0015
I0525 05:55:23.240077 20374 solver.cpp:237] Iteration 41334, loss = 1.17839
I0525 05:55:23.240134 20374 solver.cpp:253]     Train net output #0: loss = 1.17839 (* 1 = 1.17839 loss)
I0525 05:55:23.240157 20374 sgd_solver.cpp:106] Iteration 41334, lr = 0.0015
I0525 05:55:32.089249 20374 solver.cpp:237] Iteration 41500, loss = 1.15254
I0525 05:55:32.089287 20374 solver.cpp:253]     Train net output #0: loss = 1.15254 (* 1 = 1.15254 loss)
I0525 05:55:32.089305 20374 sgd_solver.cpp:106] Iteration 41500, lr = 0.0015
I0525 05:55:40.037531 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_41650.caffemodel
I0525 05:55:40.114723 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_41650.solverstate
I0525 05:55:41.015545 20374 solver.cpp:237] Iteration 41666, loss = 1.18339
I0525 05:55:41.015604 20374 solver.cpp:253]     Train net output #0: loss = 1.18339 (* 1 = 1.18339 loss)
I0525 05:55:41.015628 20374 sgd_solver.cpp:106] Iteration 41666, lr = 0.0015
I0525 05:55:49.866415 20374 solver.cpp:237] Iteration 41832, loss = 1.33242
I0525 05:55:49.866624 20374 solver.cpp:253]     Train net output #0: loss = 1.33242 (* 1 = 1.33242 loss)
I0525 05:55:49.866642 20374 sgd_solver.cpp:106] Iteration 41832, lr = 0.0015
I0525 05:55:58.720568 20374 solver.cpp:237] Iteration 41998, loss = 1.00203
I0525 05:55:58.720605 20374 solver.cpp:253]     Train net output #0: loss = 1.00203 (* 1 = 1.00203 loss)
I0525 05:55:58.720623 20374 sgd_solver.cpp:106] Iteration 41998, lr = 0.0015
I0525 05:56:07.567997 20374 solver.cpp:237] Iteration 42164, loss = 1.26258
I0525 05:56:07.568034 20374 solver.cpp:253]     Train net output #0: loss = 1.26258 (* 1 = 1.26258 loss)
I0525 05:56:07.568053 20374 sgd_solver.cpp:106] Iteration 42164, lr = 0.0015
I0525 05:56:37.307863 20374 solver.cpp:237] Iteration 42330, loss = 1.26487
I0525 05:56:37.308068 20374 solver.cpp:253]     Train net output #0: loss = 1.26487 (* 1 = 1.26487 loss)
I0525 05:56:37.308087 20374 sgd_solver.cpp:106] Iteration 42330, lr = 0.0015
I0525 05:56:46.157857 20374 solver.cpp:237] Iteration 42496, loss = 1.45712
I0525 05:56:46.157894 20374 solver.cpp:253]     Train net output #0: loss = 1.45712 (* 1 = 1.45712 loss)
I0525 05:56:46.157913 20374 sgd_solver.cpp:106] Iteration 42496, lr = 0.0015
I0525 05:56:55.001756 20374 solver.cpp:237] Iteration 42662, loss = 1.34327
I0525 05:56:55.001794 20374 solver.cpp:253]     Train net output #0: loss = 1.34327 (* 1 = 1.34327 loss)
I0525 05:56:55.001813 20374 sgd_solver.cpp:106] Iteration 42662, lr = 0.0015
I0525 05:57:03.850364 20374 solver.cpp:237] Iteration 42828, loss = 1.21917
I0525 05:57:03.850421 20374 solver.cpp:253]     Train net output #0: loss = 1.21917 (* 1 = 1.21917 loss)
I0525 05:57:03.850445 20374 sgd_solver.cpp:106] Iteration 42828, lr = 0.0015
I0525 05:57:12.703825 20374 solver.cpp:237] Iteration 42994, loss = 1.45974
I0525 05:57:12.703992 20374 solver.cpp:253]     Train net output #0: loss = 1.45974 (* 1 = 1.45974 loss)
I0525 05:57:12.704010 20374 sgd_solver.cpp:106] Iteration 42994, lr = 0.0015
I0525 05:57:21.550456 20374 solver.cpp:237] Iteration 43160, loss = 1.34322
I0525 05:57:21.550492 20374 solver.cpp:253]     Train net output #0: loss = 1.34322 (* 1 = 1.34322 loss)
I0525 05:57:21.550515 20374 sgd_solver.cpp:106] Iteration 43160, lr = 0.0015
I0525 05:57:29.816534 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_43316.caffemodel
I0525 05:57:29.892369 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_43316.solverstate
I0525 05:57:30.468511 20374 solver.cpp:237] Iteration 43326, loss = 1.19164
I0525 05:57:30.468565 20374 solver.cpp:253]     Train net output #0: loss = 1.19164 (* 1 = 1.19164 loss)
I0525 05:57:30.468590 20374 sgd_solver.cpp:106] Iteration 43326, lr = 0.0015
I0525 05:57:30.575594 20374 solver.cpp:341] Iteration 43329, Testing net (#0)
I0525 05:58:17.803367 20374 solver.cpp:409]     Test net output #0: accuracy = 0.8742
I0525 05:58:17.803568 20374 solver.cpp:409]     Test net output #1: loss = 0.416742 (* 1 = 0.416742 loss)
I0525 05:58:47.380662 20374 solver.cpp:237] Iteration 43492, loss = 1.29756
I0525 05:58:47.380722 20374 solver.cpp:253]     Train net output #0: loss = 1.29756 (* 1 = 1.29756 loss)
I0525 05:58:47.380748 20374 sgd_solver.cpp:106] Iteration 43492, lr = 0.0015
I0525 05:58:56.218200 20374 solver.cpp:237] Iteration 43658, loss = 1.20621
I0525 05:58:56.218369 20374 solver.cpp:253]     Train net output #0: loss = 1.20621 (* 1 = 1.20621 loss)
I0525 05:58:56.218385 20374 sgd_solver.cpp:106] Iteration 43658, lr = 0.0015
I0525 05:59:05.061388 20374 solver.cpp:237] Iteration 43824, loss = 1.18718
I0525 05:59:05.061442 20374 solver.cpp:253]     Train net output #0: loss = 1.18718 (* 1 = 1.18718 loss)
I0525 05:59:05.061467 20374 sgd_solver.cpp:106] Iteration 43824, lr = 0.0015
I0525 05:59:13.898655 20374 solver.cpp:237] Iteration 43990, loss = 1.02644
I0525 05:59:13.898692 20374 solver.cpp:253]     Train net output #0: loss = 1.02644 (* 1 = 1.02644 loss)
I0525 05:59:13.898710 20374 sgd_solver.cpp:106] Iteration 43990, lr = 0.0015
I0525 05:59:22.734778 20374 solver.cpp:237] Iteration 44156, loss = 1.11074
I0525 05:59:22.734815 20374 solver.cpp:253]     Train net output #0: loss = 1.11074 (* 1 = 1.11074 loss)
I0525 05:59:22.734834 20374 sgd_solver.cpp:106] Iteration 44156, lr = 0.0015
I0525 05:59:31.569993 20374 solver.cpp:237] Iteration 44322, loss = 1.07922
I0525 05:59:31.570175 20374 solver.cpp:253]     Train net output #0: loss = 1.07922 (* 1 = 1.07922 loss)
I0525 05:59:31.570194 20374 sgd_solver.cpp:106] Iteration 44322, lr = 0.0015
I0525 06:00:01.230207 20374 solver.cpp:237] Iteration 44488, loss = 1.21783
I0525 06:00:01.230268 20374 solver.cpp:253]     Train net output #0: loss = 1.21783 (* 1 = 1.21783 loss)
I0525 06:00:01.230293 20374 sgd_solver.cpp:106] Iteration 44488, lr = 0.0015
I0525 06:00:10.070893 20374 solver.cpp:237] Iteration 44654, loss = 1.24005
I0525 06:00:10.071064 20374 solver.cpp:253]     Train net output #0: loss = 1.24005 (* 1 = 1.24005 loss)
I0525 06:00:10.071081 20374 sgd_solver.cpp:106] Iteration 44654, lr = 0.0015
I0525 06:00:18.910408 20374 solver.cpp:237] Iteration 44820, loss = 0.989137
I0525 06:00:18.910466 20374 solver.cpp:253]     Train net output #0: loss = 0.989137 (* 1 = 0.989137 loss)
I0525 06:00:18.910493 20374 sgd_solver.cpp:106] Iteration 44820, lr = 0.0015
I0525 06:00:27.473448 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_44982.caffemodel
I0525 06:00:27.548972 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_44982.solverstate
I0525 06:00:27.806279 20374 solver.cpp:237] Iteration 44986, loss = 1.26935
I0525 06:00:27.806337 20374 solver.cpp:253]     Train net output #0: loss = 1.26935 (* 1 = 1.26935 loss)
I0525 06:00:27.806363 20374 sgd_solver.cpp:106] Iteration 44986, lr = 0.0015
I0525 06:00:36.652645 20374 solver.cpp:237] Iteration 45152, loss = 1.14868
I0525 06:00:36.652684 20374 solver.cpp:253]     Train net output #0: loss = 1.14868 (* 1 = 1.14868 loss)
I0525 06:00:36.652703 20374 sgd_solver.cpp:106] Iteration 45152, lr = 0.0015
I0525 06:00:45.494642 20374 solver.cpp:237] Iteration 45318, loss = 1.29263
I0525 06:00:45.494832 20374 solver.cpp:253]     Train net output #0: loss = 1.29263 (* 1 = 1.29263 loss)
I0525 06:00:45.494848 20374 sgd_solver.cpp:106] Iteration 45318, lr = 0.0015
I0525 06:00:54.345676 20374 solver.cpp:237] Iteration 45484, loss = 1.27633
I0525 06:00:54.345716 20374 solver.cpp:253]     Train net output #0: loss = 1.27633 (* 1 = 1.27633 loss)
I0525 06:00:54.345734 20374 sgd_solver.cpp:106] Iteration 45484, lr = 0.0015
I0525 06:01:24.045032 20374 solver.cpp:237] Iteration 45650, loss = 1.34047
I0525 06:01:24.045236 20374 solver.cpp:253]     Train net output #0: loss = 1.34047 (* 1 = 1.34047 loss)
I0525 06:01:24.045253 20374 sgd_solver.cpp:106] Iteration 45650, lr = 0.0015
I0525 06:01:32.895283 20374 solver.cpp:237] Iteration 45816, loss = 1.2525
I0525 06:01:32.895331 20374 solver.cpp:253]     Train net output #0: loss = 1.2525 (* 1 = 1.2525 loss)
I0525 06:01:32.895359 20374 sgd_solver.cpp:106] Iteration 45816, lr = 0.0015
I0525 06:01:41.734469 20374 solver.cpp:237] Iteration 45982, loss = 1.27816
I0525 06:01:41.734526 20374 solver.cpp:253]     Train net output #0: loss = 1.27816 (* 1 = 1.27816 loss)
I0525 06:01:41.734550 20374 sgd_solver.cpp:106] Iteration 45982, lr = 0.0015
I0525 06:01:50.579550 20374 solver.cpp:237] Iteration 46148, loss = 1.30864
I0525 06:01:50.579588 20374 solver.cpp:253]     Train net output #0: loss = 1.30864 (* 1 = 1.30864 loss)
I0525 06:01:50.579607 20374 sgd_solver.cpp:106] Iteration 46148, lr = 0.0015
I0525 06:01:59.422385 20374 solver.cpp:237] Iteration 46314, loss = 1.31597
I0525 06:01:59.422570 20374 solver.cpp:253]     Train net output #0: loss = 1.31597 (* 1 = 1.31597 loss)
I0525 06:01:59.422587 20374 sgd_solver.cpp:106] Iteration 46314, lr = 0.0015
I0525 06:02:08.272258 20374 solver.cpp:237] Iteration 46480, loss = 1.26718
I0525 06:02:08.272295 20374 solver.cpp:253]     Train net output #0: loss = 1.26718 (* 1 = 1.26718 loss)
I0525 06:02:08.272315 20374 sgd_solver.cpp:106] Iteration 46480, lr = 0.0015
I0525 06:02:17.118207 20374 solver.cpp:237] Iteration 46646, loss = 1.06205
I0525 06:02:17.118244 20374 solver.cpp:253]     Train net output #0: loss = 1.06205 (* 1 = 1.06205 loss)
I0525 06:02:17.118263 20374 sgd_solver.cpp:106] Iteration 46646, lr = 0.0015
I0525 06:02:17.171381 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_46648.caffemodel
I0525 06:02:17.246121 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_46648.solverstate
I0525 06:02:17.982396 20374 solver.cpp:341] Iteration 46662, Testing net (#0)
I0525 06:03:26.021697 20374 solver.cpp:409]     Test net output #0: accuracy = 0.877722
I0525 06:03:26.021894 20374 solver.cpp:409]     Test net output #1: loss = 0.40762 (* 1 = 0.40762 loss)
I0525 06:03:54.886160 20374 solver.cpp:237] Iteration 46812, loss = 1.35214
I0525 06:03:54.886216 20374 solver.cpp:253]     Train net output #0: loss = 1.35214 (* 1 = 1.35214 loss)
I0525 06:03:54.886245 20374 sgd_solver.cpp:106] Iteration 46812, lr = 0.0015
I0525 06:04:03.753531 20374 solver.cpp:237] Iteration 46978, loss = 1.24937
I0525 06:04:03.753716 20374 solver.cpp:253]     Train net output #0: loss = 1.24937 (* 1 = 1.24937 loss)
I0525 06:04:03.753736 20374 sgd_solver.cpp:106] Iteration 46978, lr = 0.0015
I0525 06:04:12.619712 20374 solver.cpp:237] Iteration 47144, loss = 1.08988
I0525 06:04:12.619750 20374 solver.cpp:253]     Train net output #0: loss = 1.08988 (* 1 = 1.08988 loss)
I0525 06:04:12.619772 20374 sgd_solver.cpp:106] Iteration 47144, lr = 0.0015
I0525 06:04:21.477279 20374 solver.cpp:237] Iteration 47310, loss = 1.08516
I0525 06:04:21.477315 20374 solver.cpp:253]     Train net output #0: loss = 1.08516 (* 1 = 1.08516 loss)
I0525 06:04:21.477339 20374 sgd_solver.cpp:106] Iteration 47310, lr = 0.0015
I0525 06:04:30.331269 20374 solver.cpp:237] Iteration 47476, loss = 1.30048
I0525 06:04:30.331321 20374 solver.cpp:253]     Train net output #0: loss = 1.30048 (* 1 = 1.30048 loss)
I0525 06:04:30.331337 20374 sgd_solver.cpp:106] Iteration 47476, lr = 0.0015
I0525 06:04:39.191143 20374 solver.cpp:237] Iteration 47642, loss = 1.40049
I0525 06:04:39.191319 20374 solver.cpp:253]     Train net output #0: loss = 1.40049 (* 1 = 1.40049 loss)
I0525 06:04:39.191336 20374 sgd_solver.cpp:106] Iteration 47642, lr = 0.0015
I0525 06:05:08.849189 20374 solver.cpp:237] Iteration 47808, loss = 1.49242
I0525 06:05:08.849248 20374 solver.cpp:253]     Train net output #0: loss = 1.49242 (* 1 = 1.49242 loss)
I0525 06:05:08.849274 20374 sgd_solver.cpp:106] Iteration 47808, lr = 0.0015
I0525 06:05:17.706779 20374 solver.cpp:237] Iteration 47974, loss = 1.18708
I0525 06:05:17.706955 20374 solver.cpp:253]     Train net output #0: loss = 1.18708 (* 1 = 1.18708 loss)
I0525 06:05:17.706971 20374 sgd_solver.cpp:106] Iteration 47974, lr = 0.0015
I0525 06:05:26.573510 20374 solver.cpp:237] Iteration 48140, loss = 1.3626
I0525 06:05:26.573567 20374 solver.cpp:253]     Train net output #0: loss = 1.3626 (* 1 = 1.3626 loss)
I0525 06:05:26.573592 20374 sgd_solver.cpp:106] Iteration 48140, lr = 0.0015
I0525 06:05:35.430390 20374 solver.cpp:237] Iteration 48306, loss = 1.19164
I0525 06:05:35.430426 20374 solver.cpp:253]     Train net output #0: loss = 1.19164 (* 1 = 1.19164 loss)
I0525 06:05:35.430449 20374 sgd_solver.cpp:106] Iteration 48306, lr = 0.0015
I0525 06:05:35.803257 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_48314.caffemodel
I0525 06:05:35.880400 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_48314.solverstate
I0525 06:05:44.364652 20374 solver.cpp:237] Iteration 48472, loss = 1.02163
I0525 06:05:44.364713 20374 solver.cpp:253]     Train net output #0: loss = 1.02163 (* 1 = 1.02163 loss)
I0525 06:05:44.364742 20374 sgd_solver.cpp:106] Iteration 48472, lr = 0.0015
I0525 06:05:53.226169 20374 solver.cpp:237] Iteration 48638, loss = 1.17546
I0525 06:05:53.226344 20374 solver.cpp:253]     Train net output #0: loss = 1.17546 (* 1 = 1.17546 loss)
I0525 06:05:53.226361 20374 sgd_solver.cpp:106] Iteration 48638, lr = 0.0015
I0525 06:06:02.083741 20374 solver.cpp:237] Iteration 48804, loss = 1.34643
I0525 06:06:02.083777 20374 solver.cpp:253]     Train net output #0: loss = 1.34643 (* 1 = 1.34643 loss)
I0525 06:06:02.083801 20374 sgd_solver.cpp:106] Iteration 48804, lr = 0.0015
I0525 06:06:31.803884 20374 solver.cpp:237] Iteration 48970, loss = 1.34059
I0525 06:06:31.804090 20374 solver.cpp:253]     Train net output #0: loss = 1.34059 (* 1 = 1.34059 loss)
I0525 06:06:31.804108 20374 sgd_solver.cpp:106] Iteration 48970, lr = 0.0015
I0525 06:06:40.668469 20374 solver.cpp:237] Iteration 49136, loss = 1.34384
I0525 06:06:40.668519 20374 solver.cpp:253]     Train net output #0: loss = 1.34384 (* 1 = 1.34384 loss)
I0525 06:06:40.668535 20374 sgd_solver.cpp:106] Iteration 49136, lr = 0.0015
I0525 06:06:49.527577 20374 solver.cpp:237] Iteration 49302, loss = 1.09654
I0525 06:06:49.527616 20374 solver.cpp:253]     Train net output #0: loss = 1.09654 (* 1 = 1.09654 loss)
I0525 06:06:49.527633 20374 sgd_solver.cpp:106] Iteration 49302, lr = 0.0015
I0525 06:06:58.380889 20374 solver.cpp:237] Iteration 49468, loss = 1.53289
I0525 06:06:58.380949 20374 solver.cpp:253]     Train net output #0: loss = 1.53289 (* 1 = 1.53289 loss)
I0525 06:06:58.380976 20374 sgd_solver.cpp:106] Iteration 49468, lr = 0.0015
I0525 06:07:07.242843 20374 solver.cpp:237] Iteration 49634, loss = 1.09051
I0525 06:07:07.243024 20374 solver.cpp:253]     Train net output #0: loss = 1.09051 (* 1 = 1.09051 loss)
I0525 06:07:07.243041 20374 sgd_solver.cpp:106] Iteration 49634, lr = 0.0015
I0525 06:07:16.100378 20374 solver.cpp:237] Iteration 49800, loss = 1.08476
I0525 06:07:16.100415 20374 solver.cpp:253]     Train net output #0: loss = 1.08476 (* 1 = 1.08476 loss)
I0525 06:07:16.100432 20374 sgd_solver.cpp:106] Iteration 49800, lr = 0.0015
I0525 06:07:24.961618 20374 solver.cpp:237] Iteration 49966, loss = 1.21288
I0525 06:07:24.961678 20374 solver.cpp:253]     Train net output #0: loss = 1.21288 (* 1 = 1.21288 loss)
I0525 06:07:24.961702 20374 sgd_solver.cpp:106] Iteration 49966, lr = 0.0015
I0525 06:07:25.656659 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_49980.caffemodel
I0525 06:07:25.734650 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_49980.solverstate
I0525 06:07:26.528245 20374 solver.cpp:341] Iteration 49995, Testing net (#0)
I0525 06:08:13.424743 20374 solver.cpp:409]     Test net output #0: accuracy = 0.877361
I0525 06:08:13.424945 20374 solver.cpp:409]     Test net output #1: loss = 0.387748 (* 1 = 0.387748 loss)
I0525 06:08:41.589686 20374 solver.cpp:237] Iteration 50132, loss = 1.08636
I0525 06:08:41.589745 20374 solver.cpp:253]     Train net output #0: loss = 1.08636 (* 1 = 1.08636 loss)
I0525 06:08:41.589762 20374 sgd_solver.cpp:106] Iteration 50132, lr = 0.0015
I0525 06:08:50.438632 20374 solver.cpp:237] Iteration 50298, loss = 1.11959
I0525 06:08:50.438805 20374 solver.cpp:253]     Train net output #0: loss = 1.11959 (* 1 = 1.11959 loss)
I0525 06:08:50.438822 20374 sgd_solver.cpp:106] Iteration 50298, lr = 0.0015
I0525 06:08:59.290469 20374 solver.cpp:237] Iteration 50464, loss = 1.1388
I0525 06:08:59.290508 20374 solver.cpp:253]     Train net output #0: loss = 1.1388 (* 1 = 1.1388 loss)
I0525 06:08:59.290530 20374 sgd_solver.cpp:106] Iteration 50464, lr = 0.0015
I0525 06:09:08.132701 20374 solver.cpp:237] Iteration 50630, loss = 1.25228
I0525 06:09:08.132761 20374 solver.cpp:253]     Train net output #0: loss = 1.25228 (* 1 = 1.25228 loss)
I0525 06:09:08.132786 20374 sgd_solver.cpp:106] Iteration 50630, lr = 0.0015
I0525 06:09:16.964334 20374 solver.cpp:237] Iteration 50796, loss = 1.33302
I0525 06:09:16.964370 20374 solver.cpp:253]     Train net output #0: loss = 1.33302 (* 1 = 1.33302 loss)
I0525 06:09:16.964395 20374 sgd_solver.cpp:106] Iteration 50796, lr = 0.0015
I0525 06:09:25.804626 20374 solver.cpp:237] Iteration 50962, loss = 1.15171
I0525 06:09:25.804797 20374 solver.cpp:253]     Train net output #0: loss = 1.15171 (* 1 = 1.15171 loss)
I0525 06:09:25.804813 20374 sgd_solver.cpp:106] Iteration 50962, lr = 0.0015
I0525 06:09:55.530268 20374 solver.cpp:237] Iteration 51128, loss = 1.15226
I0525 06:09:55.530325 20374 solver.cpp:253]     Train net output #0: loss = 1.15226 (* 1 = 1.15226 loss)
I0525 06:09:55.530344 20374 sgd_solver.cpp:106] Iteration 51128, lr = 0.0015
I0525 06:10:04.371968 20374 solver.cpp:237] Iteration 51294, loss = 1.22823
I0525 06:10:04.372143 20374 solver.cpp:253]     Train net output #0: loss = 1.22823 (* 1 = 1.22823 loss)
I0525 06:10:04.372159 20374 sgd_solver.cpp:106] Iteration 51294, lr = 0.0015
I0525 06:10:13.215487 20374 solver.cpp:237] Iteration 51460, loss = 1.15317
I0525 06:10:13.215523 20374 solver.cpp:253]     Train net output #0: loss = 1.15317 (* 1 = 1.15317 loss)
I0525 06:10:13.215548 20374 sgd_solver.cpp:106] Iteration 51460, lr = 0.0015
I0525 06:10:22.061421 20374 solver.cpp:237] Iteration 51626, loss = 1.08677
I0525 06:10:22.061477 20374 solver.cpp:253]     Train net output #0: loss = 1.08677 (* 1 = 1.08677 loss)
I0525 06:10:22.061506 20374 sgd_solver.cpp:106] Iteration 51626, lr = 0.0015
I0525 06:10:23.075992 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_51646.caffemodel
I0525 06:10:23.151492 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_51646.solverstate
I0525 06:10:30.977840 20374 solver.cpp:237] Iteration 51792, loss = 1.11065
I0525 06:10:30.977895 20374 solver.cpp:253]     Train net output #0: loss = 1.11065 (* 1 = 1.11065 loss)
I0525 06:10:30.977912 20374 sgd_solver.cpp:106] Iteration 51792, lr = 0.0015
I0525 06:10:39.829418 20374 solver.cpp:237] Iteration 51958, loss = 1.14141
I0525 06:10:39.829602 20374 solver.cpp:253]     Train net output #0: loss = 1.14141 (* 1 = 1.14141 loss)
I0525 06:10:39.829618 20374 sgd_solver.cpp:106] Iteration 51958, lr = 0.0015
I0525 06:10:48.676096 20374 solver.cpp:237] Iteration 52124, loss = 1.16768
I0525 06:10:48.676156 20374 solver.cpp:253]     Train net output #0: loss = 1.16768 (* 1 = 1.16768 loss)
I0525 06:10:48.676182 20374 sgd_solver.cpp:106] Iteration 52124, lr = 0.0015
I0525 06:11:18.359733 20374 solver.cpp:237] Iteration 52290, loss = 1.12165
I0525 06:11:18.359941 20374 solver.cpp:253]     Train net output #0: loss = 1.12165 (* 1 = 1.12165 loss)
I0525 06:11:18.359961 20374 sgd_solver.cpp:106] Iteration 52290, lr = 0.0015
I0525 06:11:27.204689 20374 solver.cpp:237] Iteration 52456, loss = 1.09751
I0525 06:11:27.204726 20374 solver.cpp:253]     Train net output #0: loss = 1.09751 (* 1 = 1.09751 loss)
I0525 06:11:27.204751 20374 sgd_solver.cpp:106] Iteration 52456, lr = 0.0015
I0525 06:11:36.060813 20374 solver.cpp:237] Iteration 52622, loss = 1.19915
I0525 06:11:36.060871 20374 solver.cpp:253]     Train net output #0: loss = 1.19915 (* 1 = 1.19915 loss)
I0525 06:11:36.060889 20374 sgd_solver.cpp:106] Iteration 52622, lr = 0.0015
I0525 06:11:44.901618 20374 solver.cpp:237] Iteration 52788, loss = 1.1522
I0525 06:11:44.901654 20374 solver.cpp:253]     Train net output #0: loss = 1.1522 (* 1 = 1.1522 loss)
I0525 06:11:44.901677 20374 sgd_solver.cpp:106] Iteration 52788, lr = 0.0015
I0525 06:11:53.736796 20374 solver.cpp:237] Iteration 52954, loss = 1.24953
I0525 06:11:53.736968 20374 solver.cpp:253]     Train net output #0: loss = 1.24953 (* 1 = 1.24953 loss)
I0525 06:11:53.736984 20374 sgd_solver.cpp:106] Iteration 52954, lr = 0.0015
I0525 06:12:02.570395 20374 solver.cpp:237] Iteration 53120, loss = 1.0494
I0525 06:12:02.570452 20374 solver.cpp:253]     Train net output #0: loss = 1.0494 (* 1 = 1.0494 loss)
I0525 06:12:02.570469 20374 sgd_solver.cpp:106] Iteration 53120, lr = 0.0015
I0525 06:12:11.412524 20374 solver.cpp:237] Iteration 53286, loss = 1.25555
I0525 06:12:11.412560 20374 solver.cpp:253]     Train net output #0: loss = 1.25555 (* 1 = 1.25555 loss)
I0525 06:12:11.412585 20374 sgd_solver.cpp:106] Iteration 53286, lr = 0.0015
I0525 06:12:12.745071 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_53312.caffemodel
I0525 06:12:12.819638 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_53312.solverstate
I0525 06:12:13.661773 20374 solver.cpp:341] Iteration 53328, Testing net (#0)
I0525 06:13:21.767338 20374 solver.cpp:409]     Test net output #0: accuracy = 0.88169
I0525 06:13:21.767535 20374 solver.cpp:409]     Test net output #1: loss = 0.387258 (* 1 = 0.387258 loss)
I0525 06:13:49.266293 20374 solver.cpp:237] Iteration 53452, loss = 1.16865
I0525 06:13:49.266348 20374 solver.cpp:253]     Train net output #0: loss = 1.16865 (* 1 = 1.16865 loss)
I0525 06:13:49.266366 20374 sgd_solver.cpp:106] Iteration 53452, lr = 0.0015
I0525 06:13:58.112378 20374 solver.cpp:237] Iteration 53618, loss = 1.16708
I0525 06:13:58.112556 20374 solver.cpp:253]     Train net output #0: loss = 1.16708 (* 1 = 1.16708 loss)
I0525 06:13:58.112573 20374 sgd_solver.cpp:106] Iteration 53618, lr = 0.0015
I0525 06:14:06.957166 20374 solver.cpp:237] Iteration 53784, loss = 1.13838
I0525 06:14:06.957221 20374 solver.cpp:253]     Train net output #0: loss = 1.13838 (* 1 = 1.13838 loss)
I0525 06:14:06.957237 20374 sgd_solver.cpp:106] Iteration 53784, lr = 0.0015
I0525 06:14:15.807135 20374 solver.cpp:237] Iteration 53950, loss = 1.10675
I0525 06:14:15.807175 20374 solver.cpp:253]     Train net output #0: loss = 1.10675 (* 1 = 1.10675 loss)
I0525 06:14:15.807193 20374 sgd_solver.cpp:106] Iteration 53950, lr = 0.0015
I0525 06:14:24.660121 20374 solver.cpp:237] Iteration 54116, loss = 1.23056
I0525 06:14:24.660158 20374 solver.cpp:253]     Train net output #0: loss = 1.23056 (* 1 = 1.23056 loss)
I0525 06:14:24.660183 20374 sgd_solver.cpp:106] Iteration 54116, lr = 0.0015
I0525 06:14:33.509007 20374 solver.cpp:237] Iteration 54282, loss = 1.15915
I0525 06:14:33.509218 20374 solver.cpp:253]     Train net output #0: loss = 1.15915 (* 1 = 1.15915 loss)
I0525 06:14:33.509238 20374 sgd_solver.cpp:106] Iteration 54282, lr = 0.0015
I0525 06:15:03.245322 20374 solver.cpp:237] Iteration 54448, loss = 1.19719
I0525 06:15:03.245383 20374 solver.cpp:253]     Train net output #0: loss = 1.19719 (* 1 = 1.19719 loss)
I0525 06:15:03.245409 20374 sgd_solver.cpp:106] Iteration 54448, lr = 0.0015
I0525 06:15:12.089824 20374 solver.cpp:237] Iteration 54614, loss = 1.35985
I0525 06:15:12.090000 20374 solver.cpp:253]     Train net output #0: loss = 1.35985 (* 1 = 1.35985 loss)
I0525 06:15:12.090016 20374 sgd_solver.cpp:106] Iteration 54614, lr = 0.0015
I0525 06:15:20.941196 20374 solver.cpp:237] Iteration 54780, loss = 1.09189
I0525 06:15:20.941254 20374 solver.cpp:253]     Train net output #0: loss = 1.09189 (* 1 = 1.09189 loss)
I0525 06:15:20.941279 20374 sgd_solver.cpp:106] Iteration 54780, lr = 0.0015
I0525 06:15:29.790518 20374 solver.cpp:237] Iteration 54946, loss = 1.27008
I0525 06:15:29.790561 20374 solver.cpp:253]     Train net output #0: loss = 1.27008 (* 1 = 1.27008 loss)
I0525 06:15:29.790578 20374 sgd_solver.cpp:106] Iteration 54946, lr = 0.0015
I0525 06:15:31.440927 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_54978.caffemodel
I0525 06:15:31.516566 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_54978.solverstate
I0525 06:15:38.705709 20374 solver.cpp:237] Iteration 55112, loss = 1.23568
I0525 06:15:38.705765 20374 solver.cpp:253]     Train net output #0: loss = 1.23568 (* 1 = 1.23568 loss)
I0525 06:15:38.705782 20374 sgd_solver.cpp:106] Iteration 55112, lr = 0.0015
I0525 06:15:47.551288 20374 solver.cpp:237] Iteration 55278, loss = 1.1734
I0525 06:15:47.551483 20374 solver.cpp:253]     Train net output #0: loss = 1.1734 (* 1 = 1.1734 loss)
I0525 06:15:47.551502 20374 sgd_solver.cpp:106] Iteration 55278, lr = 0.0015
I0525 06:15:56.397011 20374 solver.cpp:237] Iteration 55444, loss = 1.11505
I0525 06:15:56.397049 20374 solver.cpp:253]     Train net output #0: loss = 1.11505 (* 1 = 1.11505 loss)
I0525 06:15:56.397073 20374 sgd_solver.cpp:106] Iteration 55444, lr = 0.0015
I0525 06:16:26.117056 20374 solver.cpp:237] Iteration 55610, loss = 1.42689
I0525 06:16:26.117254 20374 solver.cpp:253]     Train net output #0: loss = 1.42689 (* 1 = 1.42689 loss)
I0525 06:16:26.117274 20374 sgd_solver.cpp:106] Iteration 55610, lr = 0.0015
I0525 06:16:34.961287 20374 solver.cpp:237] Iteration 55776, loss = 1.23968
I0525 06:16:34.961344 20374 solver.cpp:253]     Train net output #0: loss = 1.23968 (* 1 = 1.23968 loss)
I0525 06:16:34.961360 20374 sgd_solver.cpp:106] Iteration 55776, lr = 0.0015
I0525 06:16:43.811233 20374 solver.cpp:237] Iteration 55942, loss = 1.18775
I0525 06:16:43.811269 20374 solver.cpp:253]     Train net output #0: loss = 1.18775 (* 1 = 1.18775 loss)
I0525 06:16:43.811292 20374 sgd_solver.cpp:106] Iteration 55942, lr = 0.0015
I0525 06:16:52.655500 20374 solver.cpp:237] Iteration 56108, loss = 1.2162
I0525 06:16:52.655537 20374 solver.cpp:253]     Train net output #0: loss = 1.2162 (* 1 = 1.2162 loss)
I0525 06:16:52.655561 20374 sgd_solver.cpp:106] Iteration 56108, lr = 0.0015
I0525 06:17:01.511793 20374 solver.cpp:237] Iteration 56274, loss = 1.14881
I0525 06:17:01.511996 20374 solver.cpp:253]     Train net output #0: loss = 1.14881 (* 1 = 1.14881 loss)
I0525 06:17:01.512013 20374 sgd_solver.cpp:106] Iteration 56274, lr = 0.0015
I0525 06:17:10.360661 20374 solver.cpp:237] Iteration 56440, loss = 1.27176
I0525 06:17:10.360699 20374 solver.cpp:253]     Train net output #0: loss = 1.27176 (* 1 = 1.27176 loss)
I0525 06:17:10.360718 20374 sgd_solver.cpp:106] Iteration 56440, lr = 0.0015
I0525 06:17:19.210418 20374 solver.cpp:237] Iteration 56606, loss = 1.29107
I0525 06:17:19.210455 20374 solver.cpp:253]     Train net output #0: loss = 1.29107 (* 1 = 1.29107 loss)
I0525 06:17:19.210479 20374 sgd_solver.cpp:106] Iteration 56606, lr = 0.0015
I0525 06:17:21.180543 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_56644.caffemodel
I0525 06:17:21.255560 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_56644.solverstate
I0525 06:17:22.151984 20374 solver.cpp:341] Iteration 56661, Testing net (#0)
I0525 06:18:09.417652 20374 solver.cpp:409]     Test net output #0: accuracy = 0.882263
I0525 06:18:09.417865 20374 solver.cpp:409]     Test net output #1: loss = 0.412794 (* 1 = 0.412794 loss)
I0525 06:18:36.222306 20374 solver.cpp:237] Iteration 56772, loss = 1.26186
I0525 06:18:36.222365 20374 solver.cpp:253]     Train net output #0: loss = 1.26186 (* 1 = 1.26186 loss)
I0525 06:18:36.222390 20374 sgd_solver.cpp:106] Iteration 56772, lr = 0.0015
I0525 06:18:45.069031 20374 solver.cpp:237] Iteration 56938, loss = 1.23318
I0525 06:18:45.069227 20374 solver.cpp:253]     Train net output #0: loss = 1.23318 (* 1 = 1.23318 loss)
I0525 06:18:45.069247 20374 sgd_solver.cpp:106] Iteration 56938, lr = 0.0015
I0525 06:18:53.915393 20374 solver.cpp:237] Iteration 57104, loss = 1.22628
I0525 06:18:53.915431 20374 solver.cpp:253]     Train net output #0: loss = 1.22628 (* 1 = 1.22628 loss)
I0525 06:18:53.915449 20374 sgd_solver.cpp:106] Iteration 57104, lr = 0.0015
I0525 06:19:02.765213 20374 solver.cpp:237] Iteration 57270, loss = 1.1736
I0525 06:19:02.765250 20374 solver.cpp:253]     Train net output #0: loss = 1.1736 (* 1 = 1.1736 loss)
I0525 06:19:02.765275 20374 sgd_solver.cpp:106] Iteration 57270, lr = 0.0015
I0525 06:19:11.606530 20374 solver.cpp:237] Iteration 57436, loss = 1.00196
I0525 06:19:11.606585 20374 solver.cpp:253]     Train net output #0: loss = 1.00196 (* 1 = 1.00196 loss)
I0525 06:19:11.606609 20374 sgd_solver.cpp:106] Iteration 57436, lr = 0.0015
I0525 06:19:20.454224 20374 solver.cpp:237] Iteration 57602, loss = 1.5255
I0525 06:19:20.454397 20374 solver.cpp:253]     Train net output #0: loss = 1.5255 (* 1 = 1.5255 loss)
I0525 06:19:20.454414 20374 sgd_solver.cpp:106] Iteration 57602, lr = 0.0015
I0525 06:19:29.296715 20374 solver.cpp:237] Iteration 57768, loss = 1.0538
I0525 06:19:29.296771 20374 solver.cpp:253]     Train net output #0: loss = 1.0538 (* 1 = 1.0538 loss)
I0525 06:19:29.296797 20374 sgd_solver.cpp:106] Iteration 57768, lr = 0.0015
I0525 06:19:59.015835 20374 solver.cpp:237] Iteration 57934, loss = 1.10259
I0525 06:19:59.016033 20374 solver.cpp:253]     Train net output #0: loss = 1.10259 (* 1 = 1.10259 loss)
I0525 06:19:59.016052 20374 sgd_solver.cpp:106] Iteration 57934, lr = 0.0015
I0525 06:20:07.860707 20374 solver.cpp:237] Iteration 58100, loss = 1.18231
I0525 06:20:07.860744 20374 solver.cpp:253]     Train net output #0: loss = 1.18231 (* 1 = 1.18231 loss)
I0525 06:20:07.860769 20374 sgd_solver.cpp:106] Iteration 58100, lr = 0.0015
I0525 06:20:16.709430 20374 solver.cpp:237] Iteration 58266, loss = 1.08487
I0525 06:20:16.709467 20374 solver.cpp:253]     Train net output #0: loss = 1.08487 (* 1 = 1.08487 loss)
I0525 06:20:16.709486 20374 sgd_solver.cpp:106] Iteration 58266, lr = 0.0015
I0525 06:20:18.997856 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_58310.caffemodel
I0525 06:20:19.073856 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_58310.solverstate
I0525 06:20:25.615275 20374 solver.cpp:237] Iteration 58432, loss = 1.33954
I0525 06:20:25.615334 20374 solver.cpp:253]     Train net output #0: loss = 1.33954 (* 1 = 1.33954 loss)
I0525 06:20:25.615358 20374 sgd_solver.cpp:106] Iteration 58432, lr = 0.0015
I0525 06:20:34.466708 20374 solver.cpp:237] Iteration 58598, loss = 1.26856
I0525 06:20:34.466899 20374 solver.cpp:253]     Train net output #0: loss = 1.26856 (* 1 = 1.26856 loss)
I0525 06:20:34.466917 20374 sgd_solver.cpp:106] Iteration 58598, lr = 0.0015
I0525 06:20:43.307268 20374 solver.cpp:237] Iteration 58764, loss = 1.26729
I0525 06:20:43.307328 20374 solver.cpp:253]     Train net output #0: loss = 1.26729 (* 1 = 1.26729 loss)
I0525 06:20:43.307356 20374 sgd_solver.cpp:106] Iteration 58764, lr = 0.0015
I0525 06:21:13.048003 20374 solver.cpp:237] Iteration 58930, loss = 1.14861
I0525 06:21:13.048202 20374 solver.cpp:253]     Train net output #0: loss = 1.14861 (* 1 = 1.14861 loss)
I0525 06:21:13.048223 20374 sgd_solver.cpp:106] Iteration 58930, lr = 0.0015
I0525 06:21:21.895153 20374 solver.cpp:237] Iteration 59096, loss = 1.3088
I0525 06:21:21.895190 20374 solver.cpp:253]     Train net output #0: loss = 1.3088 (* 1 = 1.3088 loss)
I0525 06:21:21.895213 20374 sgd_solver.cpp:106] Iteration 59096, lr = 0.0015
I0525 06:21:30.737164 20374 solver.cpp:237] Iteration 59262, loss = 0.979201
I0525 06:21:30.737200 20374 solver.cpp:253]     Train net output #0: loss = 0.979201 (* 1 = 0.979201 loss)
I0525 06:21:30.737217 20374 sgd_solver.cpp:106] Iteration 59262, lr = 0.0015
I0525 06:21:39.585965 20374 solver.cpp:237] Iteration 59428, loss = 1.27379
I0525 06:21:39.586016 20374 solver.cpp:253]     Train net output #0: loss = 1.27379 (* 1 = 1.27379 loss)
I0525 06:21:39.586033 20374 sgd_solver.cpp:106] Iteration 59428, lr = 0.0015
I0525 06:21:48.436812 20374 solver.cpp:237] Iteration 59594, loss = 1.16683
I0525 06:21:48.436986 20374 solver.cpp:253]     Train net output #0: loss = 1.16683 (* 1 = 1.16683 loss)
I0525 06:21:48.437003 20374 sgd_solver.cpp:106] Iteration 59594, lr = 0.0015
I0525 06:21:57.285624 20374 solver.cpp:237] Iteration 59760, loss = 1.33014
I0525 06:21:57.285660 20374 solver.cpp:253]     Train net output #0: loss = 1.33014 (* 1 = 1.33014 loss)
I0525 06:21:57.285686 20374 sgd_solver.cpp:106] Iteration 59760, lr = 0.0015
I0525 06:22:06.138224 20374 solver.cpp:237] Iteration 59926, loss = 1.13087
I0525 06:22:06.138278 20374 solver.cpp:253]     Train net output #0: loss = 1.13087 (* 1 = 1.13087 loss)
I0525 06:22:06.138304 20374 sgd_solver.cpp:106] Iteration 59926, lr = 0.0015
I0525 06:22:08.752116 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_59976.caffemodel
I0525 06:22:08.828982 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_59976.solverstate
I0525 06:22:09.781369 20374 solver.cpp:341] Iteration 59994, Testing net (#0)
I0525 06:23:17.915463 20374 solver.cpp:409]     Test net output #0: accuracy = 0.881837
I0525 06:23:17.915669 20374 solver.cpp:409]     Test net output #1: loss = 0.392878 (* 1 = 0.392878 loss)
I0525 06:23:44.032723 20374 solver.cpp:237] Iteration 60092, loss = 1.08099
I0525 06:23:44.032784 20374 solver.cpp:253]     Train net output #0: loss = 1.08099 (* 1 = 1.08099 loss)
I0525 06:23:44.032804 20374 sgd_solver.cpp:106] Iteration 60092, lr = 0.0015
I0525 06:23:52.892559 20374 solver.cpp:237] Iteration 60258, loss = 1.17586
I0525 06:23:52.892740 20374 solver.cpp:253]     Train net output #0: loss = 1.17586 (* 1 = 1.17586 loss)
I0525 06:23:52.892756 20374 sgd_solver.cpp:106] Iteration 60258, lr = 0.0015
I0525 06:24:01.737210 20374 solver.cpp:237] Iteration 60424, loss = 1.30005
I0525 06:24:01.737246 20374 solver.cpp:253]     Train net output #0: loss = 1.30005 (* 1 = 1.30005 loss)
I0525 06:24:01.737269 20374 sgd_solver.cpp:106] Iteration 60424, lr = 0.0015
I0525 06:24:10.581066 20374 solver.cpp:237] Iteration 60590, loss = 1.1628
I0525 06:24:10.581112 20374 solver.cpp:253]     Train net output #0: loss = 1.1628 (* 1 = 1.1628 loss)
I0525 06:24:10.581130 20374 sgd_solver.cpp:106] Iteration 60590, lr = 0.0015
I0525 06:24:19.441756 20374 solver.cpp:237] Iteration 60756, loss = 1.36428
I0525 06:24:19.441792 20374 solver.cpp:253]     Train net output #0: loss = 1.36428 (* 1 = 1.36428 loss)
I0525 06:24:19.441817 20374 sgd_solver.cpp:106] Iteration 60756, lr = 0.0015
I0525 06:24:28.297610 20374 solver.cpp:237] Iteration 60922, loss = 1.46135
I0525 06:24:28.297814 20374 solver.cpp:253]     Train net output #0: loss = 1.46135 (* 1 = 1.46135 loss)
I0525 06:24:28.297833 20374 sgd_solver.cpp:106] Iteration 60922, lr = 0.0015
I0525 06:24:37.156009 20374 solver.cpp:237] Iteration 61088, loss = 1.34405
I0525 06:24:37.156045 20374 solver.cpp:253]     Train net output #0: loss = 1.34405 (* 1 = 1.34405 loss)
I0525 06:24:37.156069 20374 sgd_solver.cpp:106] Iteration 61088, lr = 0.0015
I0525 06:25:06.853595 20374 solver.cpp:237] Iteration 61254, loss = 1.05444
I0525 06:25:06.853806 20374 solver.cpp:253]     Train net output #0: loss = 1.05444 (* 1 = 1.05444 loss)
I0525 06:25:06.853826 20374 sgd_solver.cpp:106] Iteration 61254, lr = 0.0015
I0525 06:25:15.709447 20374 solver.cpp:237] Iteration 61420, loss = 1.02545
I0525 06:25:15.709484 20374 solver.cpp:253]     Train net output #0: loss = 1.02545 (* 1 = 1.02545 loss)
I0525 06:25:15.709508 20374 sgd_solver.cpp:106] Iteration 61420, lr = 0.0015
I0525 06:25:24.561924 20374 solver.cpp:237] Iteration 61586, loss = 1.06173
I0525 06:25:24.561970 20374 solver.cpp:253]     Train net output #0: loss = 1.06173 (* 1 = 1.06173 loss)
I0525 06:25:24.561987 20374 sgd_solver.cpp:106] Iteration 61586, lr = 0.0015
I0525 06:25:27.491406 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_61642.caffemodel
I0525 06:25:27.567720 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_61642.solverstate
I0525 06:25:33.474963 20374 solver.cpp:237] Iteration 61752, loss = 1.21504
I0525 06:25:33.475018 20374 solver.cpp:253]     Train net output #0: loss = 1.21504 (* 1 = 1.21504 loss)
I0525 06:25:33.475034 20374 sgd_solver.cpp:106] Iteration 61752, lr = 0.0015
I0525 06:25:42.322924 20374 solver.cpp:237] Iteration 61918, loss = 1.30533
I0525 06:25:42.323113 20374 solver.cpp:253]     Train net output #0: loss = 1.30533 (* 1 = 1.30533 loss)
I0525 06:25:42.323130 20374 sgd_solver.cpp:106] Iteration 61918, lr = 0.0015
I0525 06:25:51.172307 20374 solver.cpp:237] Iteration 62084, loss = 1.16324
I0525 06:25:51.172353 20374 solver.cpp:253]     Train net output #0: loss = 1.16324 (* 1 = 1.16324 loss)
I0525 06:25:51.172371 20374 sgd_solver.cpp:106] Iteration 62084, lr = 0.0015
I0525 06:26:20.948110 20374 solver.cpp:237] Iteration 62250, loss = 1.25313
I0525 06:26:20.948312 20374 solver.cpp:253]     Train net output #0: loss = 1.25313 (* 1 = 1.25313 loss)
I0525 06:26:20.948341 20374 sgd_solver.cpp:106] Iteration 62250, lr = 0.0015
I0525 06:26:29.803992 20374 solver.cpp:237] Iteration 62416, loss = 1.21824
I0525 06:26:29.804029 20374 solver.cpp:253]     Train net output #0: loss = 1.21824 (* 1 = 1.21824 loss)
I0525 06:26:29.804054 20374 sgd_solver.cpp:106] Iteration 62416, lr = 0.0015
I0525 06:26:38.660164 20374 solver.cpp:237] Iteration 62582, loss = 1.12284
I0525 06:26:38.660219 20374 solver.cpp:253]     Train net output #0: loss = 1.12284 (* 1 = 1.12284 loss)
I0525 06:26:38.660235 20374 sgd_solver.cpp:106] Iteration 62582, lr = 0.0015
I0525 06:26:47.498188 20374 solver.cpp:237] Iteration 62748, loss = 1.12889
I0525 06:26:47.498224 20374 solver.cpp:253]     Train net output #0: loss = 1.12889 (* 1 = 1.12889 loss)
I0525 06:26:47.498246 20374 sgd_solver.cpp:106] Iteration 62748, lr = 0.0015
I0525 06:26:56.342458 20374 solver.cpp:237] Iteration 62914, loss = 1.29119
I0525 06:26:56.342645 20374 solver.cpp:253]     Train net output #0: loss = 1.29119 (* 1 = 1.29119 loss)
I0525 06:26:56.342663 20374 sgd_solver.cpp:106] Iteration 62914, lr = 0.0015
I0525 06:27:05.179865 20374 solver.cpp:237] Iteration 63080, loss = 1.45438
I0525 06:27:05.179920 20374 solver.cpp:253]     Train net output #0: loss = 1.45438 (* 1 = 1.45438 loss)
I0525 06:27:05.179946 20374 sgd_solver.cpp:106] Iteration 63080, lr = 0.0015
I0525 06:27:14.027389 20374 solver.cpp:237] Iteration 63246, loss = 0.977904
I0525 06:27:14.027431 20374 solver.cpp:253]     Train net output #0: loss = 0.977904 (* 1 = 0.977904 loss)
I0525 06:27:14.027448 20374 sgd_solver.cpp:106] Iteration 63246, lr = 0.0015
I0525 06:27:17.282300 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_63308.caffemodel
I0525 06:27:17.357075 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_63308.solverstate
I0525 06:27:18.361613 20374 solver.cpp:341] Iteration 63327, Testing net (#0)
I0525 06:28:05.253780 20374 solver.cpp:409]     Test net output #0: accuracy = 0.881736
I0525 06:28:05.253991 20374 solver.cpp:409]     Test net output #1: loss = 0.371813 (* 1 = 0.371813 loss)
I0525 06:28:30.646236 20374 solver.cpp:237] Iteration 63412, loss = 1.25405
I0525 06:28:30.646297 20374 solver.cpp:253]     Train net output #0: loss = 1.25405 (* 1 = 1.25405 loss)
I0525 06:28:30.646317 20374 sgd_solver.cpp:106] Iteration 63412, lr = 0.0015
I0525 06:28:39.496978 20374 solver.cpp:237] Iteration 63578, loss = 1.19979
I0525 06:28:39.497175 20374 solver.cpp:253]     Train net output #0: loss = 1.19979 (* 1 = 1.19979 loss)
I0525 06:28:39.497195 20374 sgd_solver.cpp:106] Iteration 63578, lr = 0.0015
I0525 06:28:48.344393 20374 solver.cpp:237] Iteration 63744, loss = 1.18457
I0525 06:28:48.344430 20374 solver.cpp:253]     Train net output #0: loss = 1.18457 (* 1 = 1.18457 loss)
I0525 06:28:48.344455 20374 sgd_solver.cpp:106] Iteration 63744, lr = 0.0015
I0525 06:28:57.199719 20374 solver.cpp:237] Iteration 63910, loss = 1.17858
I0525 06:28:57.199762 20374 solver.cpp:253]     Train net output #0: loss = 1.17858 (* 1 = 1.17858 loss)
I0525 06:28:57.199779 20374 sgd_solver.cpp:106] Iteration 63910, lr = 0.0015
I0525 06:29:06.051414 20374 solver.cpp:237] Iteration 64076, loss = 1.35355
I0525 06:29:06.051471 20374 solver.cpp:253]     Train net output #0: loss = 1.35355 (* 1 = 1.35355 loss)
I0525 06:29:06.051498 20374 sgd_solver.cpp:106] Iteration 64076, lr = 0.0015
I0525 06:29:14.913082 20374 solver.cpp:237] Iteration 64242, loss = 1.11105
I0525 06:29:14.913271 20374 solver.cpp:253]     Train net output #0: loss = 1.11105 (* 1 = 1.11105 loss)
I0525 06:29:14.913288 20374 sgd_solver.cpp:106] Iteration 64242, lr = 0.0015
I0525 06:29:23.758553 20374 solver.cpp:237] Iteration 64408, loss = 1.15423
I0525 06:29:23.758590 20374 solver.cpp:253]     Train net output #0: loss = 1.15423 (* 1 = 1.15423 loss)
I0525 06:29:23.758615 20374 sgd_solver.cpp:106] Iteration 64408, lr = 0.0015
I0525 06:29:53.508293 20374 solver.cpp:237] Iteration 64574, loss = 1.4631
I0525 06:29:53.508505 20374 solver.cpp:253]     Train net output #0: loss = 1.4631 (* 1 = 1.4631 loss)
I0525 06:29:53.508530 20374 sgd_solver.cpp:106] Iteration 64574, lr = 0.0015
I0525 06:30:02.355486 20374 solver.cpp:237] Iteration 64740, loss = 1.14397
I0525 06:30:02.355525 20374 solver.cpp:253]     Train net output #0: loss = 1.14397 (* 1 = 1.14397 loss)
I0525 06:30:02.355548 20374 sgd_solver.cpp:106] Iteration 64740, lr = 0.0015
I0525 06:30:11.206604 20374 solver.cpp:237] Iteration 64906, loss = 1.0964
I0525 06:30:11.206645 20374 solver.cpp:253]     Train net output #0: loss = 1.0964 (* 1 = 1.0964 loss)
I0525 06:30:11.206662 20374 sgd_solver.cpp:106] Iteration 64906, lr = 0.0015
I0525 06:30:14.774549 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_64974.caffemodel
I0525 06:30:14.850198 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_64974.solverstate
I0525 06:30:20.120262 20374 solver.cpp:237] Iteration 65072, loss = 1.29477
I0525 06:30:20.120328 20374 solver.cpp:253]     Train net output #0: loss = 1.29477 (* 1 = 1.29477 loss)
I0525 06:30:20.120345 20374 sgd_solver.cpp:106] Iteration 65072, lr = 0.0015
I0525 06:30:28.976089 20374 solver.cpp:237] Iteration 65238, loss = 1.44362
I0525 06:30:28.976280 20374 solver.cpp:253]     Train net output #0: loss = 1.44362 (* 1 = 1.44362 loss)
I0525 06:30:28.976297 20374 sgd_solver.cpp:106] Iteration 65238, lr = 0.0015
I0525 06:30:37.832429 20374 solver.cpp:237] Iteration 65404, loss = 1.22388
I0525 06:30:37.832466 20374 solver.cpp:253]     Train net output #0: loss = 1.22388 (* 1 = 1.22388 loss)
I0525 06:30:37.832490 20374 sgd_solver.cpp:106] Iteration 65404, lr = 0.0015
I0525 06:31:07.527310 20374 solver.cpp:237] Iteration 65570, loss = 1.17234
I0525 06:31:07.527511 20374 solver.cpp:253]     Train net output #0: loss = 1.17234 (* 1 = 1.17234 loss)
I0525 06:31:07.527530 20374 sgd_solver.cpp:106] Iteration 65570, lr = 0.0015
I0525 06:31:16.381790 20374 solver.cpp:237] Iteration 65736, loss = 1.19368
I0525 06:31:16.381849 20374 solver.cpp:253]     Train net output #0: loss = 1.19368 (* 1 = 1.19368 loss)
I0525 06:31:16.381875 20374 sgd_solver.cpp:106] Iteration 65736, lr = 0.0015
I0525 06:31:25.232375 20374 solver.cpp:237] Iteration 65902, loss = 1.13658
I0525 06:31:25.232412 20374 solver.cpp:253]     Train net output #0: loss = 1.13658 (* 1 = 1.13658 loss)
I0525 06:31:25.232430 20374 sgd_solver.cpp:106] Iteration 65902, lr = 0.0015
I0525 06:31:34.099931 20374 solver.cpp:237] Iteration 66068, loss = 1.35763
I0525 06:31:34.099985 20374 solver.cpp:253]     Train net output #0: loss = 1.35763 (* 1 = 1.35763 loss)
I0525 06:31:34.100003 20374 sgd_solver.cpp:106] Iteration 66068, lr = 0.0015
I0525 06:31:42.946164 20374 solver.cpp:237] Iteration 66234, loss = 1.19296
I0525 06:31:42.946344 20374 solver.cpp:253]     Train net output #0: loss = 1.19296 (* 1 = 1.19296 loss)
I0525 06:31:42.946362 20374 sgd_solver.cpp:106] Iteration 66234, lr = 0.0015
I0525 06:31:51.786447 20374 solver.cpp:237] Iteration 66400, loss = 1.21099
I0525 06:31:51.786484 20374 solver.cpp:253]     Train net output #0: loss = 1.21099 (* 1 = 1.21099 loss)
I0525 06:31:51.786502 20374 sgd_solver.cpp:106] Iteration 66400, lr = 0.0015
I0525 06:32:00.640184 20374 solver.cpp:237] Iteration 66566, loss = 1.08107
I0525 06:32:00.640240 20374 solver.cpp:253]     Train net output #0: loss = 1.08107 (* 1 = 1.08107 loss)
I0525 06:32:00.640257 20374 sgd_solver.cpp:106] Iteration 66566, lr = 0.0015
I0525 06:32:04.528275 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_66640.caffemodel
I0525 06:32:04.605808 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_66640.solverstate
I0525 06:32:05.662626 20374 solver.cpp:341] Iteration 66660, Testing net (#0)
I0525 06:33:13.696079 20374 solver.cpp:409]     Test net output #0: accuracy = 0.884778
I0525 06:33:13.696277 20374 solver.cpp:409]     Test net output #1: loss = 0.370146 (* 1 = 0.370146 loss)
I0525 06:33:38.447520 20374 solver.cpp:237] Iteration 66732, loss = 1.17391
I0525 06:33:38.447581 20374 solver.cpp:253]     Train net output #0: loss = 1.17391 (* 1 = 1.17391 loss)
I0525 06:33:38.447600 20374 sgd_solver.cpp:106] Iteration 66732, lr = 0.0015
I0525 06:33:47.301612 20374 solver.cpp:237] Iteration 66898, loss = 1.05291
I0525 06:33:47.301807 20374 solver.cpp:253]     Train net output #0: loss = 1.05291 (* 1 = 1.05291 loss)
I0525 06:33:47.301823 20374 sgd_solver.cpp:106] Iteration 66898, lr = 0.0015
I0525 06:33:56.153919 20374 solver.cpp:237] Iteration 67064, loss = 1.15566
I0525 06:33:56.153956 20374 solver.cpp:253]     Train net output #0: loss = 1.15566 (* 1 = 1.15566 loss)
I0525 06:33:56.153980 20374 sgd_solver.cpp:106] Iteration 67064, lr = 0.0015
I0525 06:34:05.009305 20374 solver.cpp:237] Iteration 67230, loss = 1.11037
I0525 06:34:05.009362 20374 solver.cpp:253]     Train net output #0: loss = 1.11037 (* 1 = 1.11037 loss)
I0525 06:34:05.009389 20374 sgd_solver.cpp:106] Iteration 67230, lr = 0.0015
I0525 06:34:13.864368 20374 solver.cpp:237] Iteration 67396, loss = 1.33973
I0525 06:34:13.864404 20374 solver.cpp:253]     Train net output #0: loss = 1.33973 (* 1 = 1.33973 loss)
I0525 06:34:13.864423 20374 sgd_solver.cpp:106] Iteration 67396, lr = 0.0015
I0525 06:34:22.714268 20374 solver.cpp:237] Iteration 67562, loss = 1.14938
I0525 06:34:22.714449 20374 solver.cpp:253]     Train net output #0: loss = 1.14938 (* 1 = 1.14938 loss)
I0525 06:34:22.714465 20374 sgd_solver.cpp:106] Iteration 67562, lr = 0.0015
I0525 06:34:31.567262 20374 solver.cpp:237] Iteration 67728, loss = 0.948608
I0525 06:34:31.567320 20374 solver.cpp:253]     Train net output #0: loss = 0.948608 (* 1 = 0.948608 loss)
I0525 06:34:31.567345 20374 sgd_solver.cpp:106] Iteration 67728, lr = 0.0015
I0525 06:35:01.251751 20374 solver.cpp:237] Iteration 67894, loss = 1.2374
I0525 06:35:01.251957 20374 solver.cpp:253]     Train net output #0: loss = 1.2374 (* 1 = 1.2374 loss)
I0525 06:35:01.251982 20374 sgd_solver.cpp:106] Iteration 67894, lr = 0.0015
I0525 06:35:10.104729 20374 solver.cpp:237] Iteration 68060, loss = 1.08521
I0525 06:35:10.104766 20374 solver.cpp:253]     Train net output #0: loss = 1.08521 (* 1 = 1.08521 loss)
I0525 06:35:10.104789 20374 sgd_solver.cpp:106] Iteration 68060, lr = 0.0015
I0525 06:35:18.959453 20374 solver.cpp:237] Iteration 68226, loss = 1.23184
I0525 06:35:18.959512 20374 solver.cpp:253]     Train net output #0: loss = 1.23184 (* 1 = 1.23184 loss)
I0525 06:35:18.959539 20374 sgd_solver.cpp:106] Iteration 68226, lr = 0.0015
I0525 06:35:23.171067 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_68306.caffemodel
I0525 06:35:23.245470 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_68306.solverstate
I0525 06:35:27.869210 20374 solver.cpp:237] Iteration 68392, loss = 1.08018
I0525 06:35:27.869266 20374 solver.cpp:253]     Train net output #0: loss = 1.08018 (* 1 = 1.08018 loss)
I0525 06:35:27.869289 20374 sgd_solver.cpp:106] Iteration 68392, lr = 0.0015
I0525 06:35:36.712074 20374 solver.cpp:237] Iteration 68558, loss = 1.17937
I0525 06:35:36.712257 20374 solver.cpp:253]     Train net output #0: loss = 1.17937 (* 1 = 1.17937 loss)
I0525 06:35:36.712275 20374 sgd_solver.cpp:106] Iteration 68558, lr = 0.0015
I0525 06:35:45.555377 20374 solver.cpp:237] Iteration 68724, loss = 1.4109
I0525 06:35:45.555435 20374 solver.cpp:253]     Train net output #0: loss = 1.4109 (* 1 = 1.4109 loss)
I0525 06:35:45.555462 20374 sgd_solver.cpp:106] Iteration 68724, lr = 0.0015
I0525 06:36:15.292352 20374 solver.cpp:237] Iteration 68890, loss = 1.03816
I0525 06:36:15.292562 20374 solver.cpp:253]     Train net output #0: loss = 1.03816 (* 1 = 1.03816 loss)
I0525 06:36:15.292583 20374 sgd_solver.cpp:106] Iteration 68890, lr = 0.0015
I0525 06:36:24.137228 20374 solver.cpp:237] Iteration 69056, loss = 1.16467
I0525 06:36:24.137264 20374 solver.cpp:253]     Train net output #0: loss = 1.16467 (* 1 = 1.16467 loss)
I0525 06:36:24.137282 20374 sgd_solver.cpp:106] Iteration 69056, lr = 0.0015
I0525 06:36:32.985549 20374 solver.cpp:237] Iteration 69222, loss = 1.13669
I0525 06:36:32.985586 20374 solver.cpp:253]     Train net output #0: loss = 1.13669 (* 1 = 1.13669 loss)
I0525 06:36:32.985605 20374 sgd_solver.cpp:106] Iteration 69222, lr = 0.0015
I0525 06:36:41.826253 20374 solver.cpp:237] Iteration 69388, loss = 1.085
I0525 06:36:41.826303 20374 solver.cpp:253]     Train net output #0: loss = 1.085 (* 1 = 1.085 loss)
I0525 06:36:41.826319 20374 sgd_solver.cpp:106] Iteration 69388, lr = 0.0015
I0525 06:36:50.670174 20374 solver.cpp:237] Iteration 69554, loss = 1.04401
I0525 06:36:50.670366 20374 solver.cpp:253]     Train net output #0: loss = 1.04401 (* 1 = 1.04401 loss)
I0525 06:36:50.670382 20374 sgd_solver.cpp:106] Iteration 69554, lr = 0.0015
I0525 06:36:59.509196 20374 solver.cpp:237] Iteration 69720, loss = 1.08747
I0525 06:36:59.509254 20374 solver.cpp:253]     Train net output #0: loss = 1.08747 (* 1 = 1.08747 loss)
I0525 06:36:59.509281 20374 sgd_solver.cpp:106] Iteration 69720, lr = 0.0015
I0525 06:37:08.353615 20374 solver.cpp:237] Iteration 69886, loss = 1.09166
I0525 06:37:08.353652 20374 solver.cpp:253]     Train net output #0: loss = 1.09166 (* 1 = 1.09166 loss)
I0525 06:37:08.353670 20374 sgd_solver.cpp:106] Iteration 69886, lr = 0.0015
I0525 06:37:12.880054 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_69972.caffemodel
I0525 06:37:12.955687 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_69972.solverstate
I0525 06:37:14.065726 20374 solver.cpp:341] Iteration 69993, Testing net (#0)
I0525 06:38:01.215706 20374 solver.cpp:409]     Test net output #0: accuracy = 0.886679
I0525 06:38:01.215919 20374 solver.cpp:409]     Test net output #1: loss = 0.374638 (* 1 = 0.374638 loss)
I0525 06:38:25.169077 20374 solver.cpp:237] Iteration 70052, loss = 1.01626
I0525 06:38:25.169137 20374 solver.cpp:253]     Train net output #0: loss = 1.01626 (* 1 = 1.01626 loss)
I0525 06:38:25.169157 20374 sgd_solver.cpp:106] Iteration 70052, lr = 0.0015
I0525 06:38:34.023337 20374 solver.cpp:237] Iteration 70218, loss = 1.17815
I0525 06:38:34.023524 20374 solver.cpp:253]     Train net output #0: loss = 1.17815 (* 1 = 1.17815 loss)
I0525 06:38:34.023540 20374 sgd_solver.cpp:106] Iteration 70218, lr = 0.0015
I0525 06:38:42.877643 20374 solver.cpp:237] Iteration 70384, loss = 1.20169
I0525 06:38:42.877699 20374 solver.cpp:253]     Train net output #0: loss = 1.20169 (* 1 = 1.20169 loss)
I0525 06:38:42.877717 20374 sgd_solver.cpp:106] Iteration 70384, lr = 0.0015
I0525 06:38:51.723209 20374 solver.cpp:237] Iteration 70550, loss = 1.11268
I0525 06:38:51.723248 20374 solver.cpp:253]     Train net output #0: loss = 1.11268 (* 1 = 1.11268 loss)
I0525 06:38:51.723266 20374 sgd_solver.cpp:106] Iteration 70550, lr = 0.0015
I0525 06:39:00.580391 20374 solver.cpp:237] Iteration 70716, loss = 1.09161
I0525 06:39:00.580428 20374 solver.cpp:253]     Train net output #0: loss = 1.09161 (* 1 = 1.09161 loss)
I0525 06:39:00.580447 20374 sgd_solver.cpp:106] Iteration 70716, lr = 0.0015
I0525 06:39:09.422574 20374 solver.cpp:237] Iteration 70882, loss = 1.07129
I0525 06:39:09.422786 20374 solver.cpp:253]     Train net output #0: loss = 1.07129 (* 1 = 1.07129 loss)
I0525 06:39:09.422806 20374 sgd_solver.cpp:106] Iteration 70882, lr = 0.0015
I0525 06:39:18.267273 20374 solver.cpp:237] Iteration 71048, loss = 1.20253
I0525 06:39:18.267310 20374 solver.cpp:253]     Train net output #0: loss = 1.20253 (* 1 = 1.20253 loss)
I0525 06:39:18.267330 20374 sgd_solver.cpp:106] Iteration 71048, lr = 0.0015
I0525 06:39:47.949089 20374 solver.cpp:237] Iteration 71214, loss = 1.20529
I0525 06:39:47.949306 20374 solver.cpp:253]     Train net output #0: loss = 1.20529 (* 1 = 1.20529 loss)
I0525 06:39:47.949324 20374 sgd_solver.cpp:106] Iteration 71214, lr = 0.0015
I0525 06:39:56.796897 20374 solver.cpp:237] Iteration 71380, loss = 1.10851
I0525 06:39:56.796957 20374 solver.cpp:253]     Train net output #0: loss = 1.10851 (* 1 = 1.10851 loss)
I0525 06:39:56.796983 20374 sgd_solver.cpp:106] Iteration 71380, lr = 0.0015
I0525 06:40:05.646047 20374 solver.cpp:237] Iteration 71546, loss = 1.08207
I0525 06:40:05.646085 20374 solver.cpp:253]     Train net output #0: loss = 1.08207 (* 1 = 1.08207 loss)
I0525 06:40:05.646105 20374 sgd_solver.cpp:106] Iteration 71546, lr = 0.0015
I0525 06:40:10.500880 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_71638.caffemodel
I0525 06:40:10.576603 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_71638.solverstate
I0525 06:40:14.564028 20374 solver.cpp:237] Iteration 71712, loss = 1.2591
I0525 06:40:14.564085 20374 solver.cpp:253]     Train net output #0: loss = 1.2591 (* 1 = 1.2591 loss)
I0525 06:40:14.564110 20374 sgd_solver.cpp:106] Iteration 71712, lr = 0.0015
I0525 06:40:23.417819 20374 solver.cpp:237] Iteration 71878, loss = 1.16382
I0525 06:40:23.418031 20374 solver.cpp:253]     Train net output #0: loss = 1.16382 (* 1 = 1.16382 loss)
I0525 06:40:23.418048 20374 sgd_solver.cpp:106] Iteration 71878, lr = 0.0015
I0525 06:40:32.267933 20374 solver.cpp:237] Iteration 72044, loss = 1.23925
I0525 06:40:32.267971 20374 solver.cpp:253]     Train net output #0: loss = 1.23925 (* 1 = 1.23925 loss)
I0525 06:40:32.267987 20374 sgd_solver.cpp:106] Iteration 72044, lr = 0.0015
I0525 06:40:41.119457 20374 solver.cpp:237] Iteration 72210, loss = 0.971449
I0525 06:40:41.119495 20374 solver.cpp:253]     Train net output #0: loss = 0.971449 (* 1 = 0.971449 loss)
I0525 06:40:41.119519 20374 sgd_solver.cpp:106] Iteration 72210, lr = 0.0015
I0525 06:41:10.830351 20374 solver.cpp:237] Iteration 72376, loss = 1.06688
I0525 06:41:10.830555 20374 solver.cpp:253]     Train net output #0: loss = 1.06688 (* 1 = 1.06688 loss)
I0525 06:41:10.830574 20374 sgd_solver.cpp:106] Iteration 72376, lr = 0.0015
I0525 06:41:19.673130 20374 solver.cpp:237] Iteration 72542, loss = 1.22083
I0525 06:41:19.673167 20374 solver.cpp:253]     Train net output #0: loss = 1.22083 (* 1 = 1.22083 loss)
I0525 06:41:19.673190 20374 sgd_solver.cpp:106] Iteration 72542, lr = 0.0015
I0525 06:41:28.523886 20374 solver.cpp:237] Iteration 72708, loss = 1.2153
I0525 06:41:28.523923 20374 solver.cpp:253]     Train net output #0: loss = 1.2153 (* 1 = 1.2153 loss)
I0525 06:41:28.523947 20374 sgd_solver.cpp:106] Iteration 72708, lr = 0.0015
I0525 06:41:37.376302 20374 solver.cpp:237] Iteration 72874, loss = 1.217
I0525 06:41:37.376366 20374 solver.cpp:253]     Train net output #0: loss = 1.217 (* 1 = 1.217 loss)
I0525 06:41:37.376385 20374 sgd_solver.cpp:106] Iteration 72874, lr = 0.0015
I0525 06:41:46.233778 20374 solver.cpp:237] Iteration 73040, loss = 1.34494
I0525 06:41:46.233958 20374 solver.cpp:253]     Train net output #0: loss = 1.34494 (* 1 = 1.34494 loss)
I0525 06:41:46.233975 20374 sgd_solver.cpp:106] Iteration 73040, lr = 0.0015
I0525 06:41:55.087757 20374 solver.cpp:237] Iteration 73206, loss = 1.05586
I0525 06:41:55.087795 20374 solver.cpp:253]     Train net output #0: loss = 1.05586 (* 1 = 1.05586 loss)
I0525 06:41:55.087817 20374 sgd_solver.cpp:106] Iteration 73206, lr = 0.0015
I0525 06:42:00.256527 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_73304.caffemodel
I0525 06:42:00.332120 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_73304.solverstate
I0525 06:42:01.492066 20374 solver.cpp:341] Iteration 73326, Testing net (#0)
I0525 06:43:09.598803 20374 solver.cpp:409]     Test net output #0: accuracy = 0.887093
I0525 06:43:09.599031 20374 solver.cpp:409]     Test net output #1: loss = 0.38686 (* 1 = 0.38686 loss)
I0525 06:43:32.922587 20374 solver.cpp:237] Iteration 73372, loss = 1.12128
I0525 06:43:32.922646 20374 solver.cpp:253]     Train net output #0: loss = 1.12128 (* 1 = 1.12128 loss)
I0525 06:43:32.922665 20374 sgd_solver.cpp:106] Iteration 73372, lr = 0.0015
I0525 06:43:41.771047 20374 solver.cpp:237] Iteration 73538, loss = 1.11568
I0525 06:43:41.771253 20374 solver.cpp:253]     Train net output #0: loss = 1.11568 (* 1 = 1.11568 loss)
I0525 06:43:41.771272 20374 sgd_solver.cpp:106] Iteration 73538, lr = 0.0015
I0525 06:43:50.634130 20374 solver.cpp:237] Iteration 73704, loss = 1.10296
I0525 06:43:50.634166 20374 solver.cpp:253]     Train net output #0: loss = 1.10296 (* 1 = 1.10296 loss)
I0525 06:43:50.634189 20374 sgd_solver.cpp:106] Iteration 73704, lr = 0.0015
I0525 06:43:59.483350 20374 solver.cpp:237] Iteration 73870, loss = 1.26854
I0525 06:43:59.483387 20374 solver.cpp:253]     Train net output #0: loss = 1.26854 (* 1 = 1.26854 loss)
I0525 06:43:59.483407 20374 sgd_solver.cpp:106] Iteration 73870, lr = 0.0015
I0525 06:44:08.347450 20374 solver.cpp:237] Iteration 74036, loss = 1.13211
I0525 06:44:08.347503 20374 solver.cpp:253]     Train net output #0: loss = 1.13211 (* 1 = 1.13211 loss)
I0525 06:44:08.347520 20374 sgd_solver.cpp:106] Iteration 74036, lr = 0.0015
I0525 06:44:17.188884 20374 solver.cpp:237] Iteration 74202, loss = 1.03464
I0525 06:44:17.189079 20374 solver.cpp:253]     Train net output #0: loss = 1.03464 (* 1 = 1.03464 loss)
I0525 06:44:17.189095 20374 sgd_solver.cpp:106] Iteration 74202, lr = 0.0015
I0525 06:44:26.045421 20374 solver.cpp:237] Iteration 74368, loss = 1.10206
I0525 06:44:26.045459 20374 solver.cpp:253]     Train net output #0: loss = 1.10206 (* 1 = 1.10206 loss)
I0525 06:44:26.045481 20374 sgd_solver.cpp:106] Iteration 74368, lr = 0.0015
I0525 06:44:55.766163 20374 solver.cpp:237] Iteration 74534, loss = 1.27818
I0525 06:44:55.766372 20374 solver.cpp:253]     Train net output #0: loss = 1.27818 (* 1 = 1.27818 loss)
I0525 06:44:55.766392 20374 sgd_solver.cpp:106] Iteration 74534, lr = 0.0015
I0525 06:45:04.618784 20374 solver.cpp:237] Iteration 74700, loss = 1.29787
I0525 06:45:04.618821 20374 solver.cpp:253]     Train net output #0: loss = 1.29787 (* 1 = 1.29787 loss)
I0525 06:45:04.618845 20374 sgd_solver.cpp:106] Iteration 74700, lr = 0.0015
I0525 06:45:13.470445 20374 solver.cpp:237] Iteration 74866, loss = 1.2187
I0525 06:45:13.470482 20374 solver.cpp:253]     Train net output #0: loss = 1.2187 (* 1 = 1.2187 loss)
I0525 06:45:13.470505 20374 sgd_solver.cpp:106] Iteration 74866, lr = 0.0015
I0525 06:45:18.967164 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_74970.caffemodel
I0525 06:45:19.044098 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_74970.solverstate
I0525 06:45:22.393543 20374 solver.cpp:237] Iteration 75032, loss = 1.07025
I0525 06:45:22.393599 20374 solver.cpp:253]     Train net output #0: loss = 1.07025 (* 1 = 1.07025 loss)
I0525 06:45:22.393616 20374 sgd_solver.cpp:106] Iteration 75032, lr = 0.0015
I0525 06:45:31.263823 20374 solver.cpp:237] Iteration 75198, loss = 1.22704
I0525 06:45:31.264009 20374 solver.cpp:253]     Train net output #0: loss = 1.22704 (* 1 = 1.22704 loss)
I0525 06:45:31.264026 20374 sgd_solver.cpp:106] Iteration 75198, lr = 0.0015
I0525 06:45:40.122875 20374 solver.cpp:237] Iteration 75364, loss = 1.06876
I0525 06:45:40.122913 20374 solver.cpp:253]     Train net output #0: loss = 1.06876 (* 1 = 1.06876 loss)
I0525 06:45:40.122931 20374 sgd_solver.cpp:106] Iteration 75364, lr = 0.0015
I0525 06:45:48.981575 20374 solver.cpp:237] Iteration 75530, loss = 1.218
I0525 06:45:48.981636 20374 solver.cpp:253]     Train net output #0: loss = 1.218 (* 1 = 1.218 loss)
I0525 06:45:48.981655 20374 sgd_solver.cpp:106] Iteration 75530, lr = 0.0015
I0525 06:46:18.629972 20374 solver.cpp:237] Iteration 75696, loss = 1.163
I0525 06:46:18.630199 20374 solver.cpp:253]     Train net output #0: loss = 1.163 (* 1 = 1.163 loss)
I0525 06:46:18.630216 20374 sgd_solver.cpp:106] Iteration 75696, lr = 0.0015
I0525 06:46:27.495107 20374 solver.cpp:237] Iteration 75862, loss = 1.28221
I0525 06:46:27.495146 20374 solver.cpp:253]     Train net output #0: loss = 1.28221 (* 1 = 1.28221 loss)
I0525 06:46:27.495168 20374 sgd_solver.cpp:106] Iteration 75862, lr = 0.0015
I0525 06:46:36.352337 20374 solver.cpp:237] Iteration 76028, loss = 1.04263
I0525 06:46:36.352394 20374 solver.cpp:253]     Train net output #0: loss = 1.04263 (* 1 = 1.04263 loss)
I0525 06:46:36.352416 20374 sgd_solver.cpp:106] Iteration 76028, lr = 0.0015
I0525 06:46:45.210981 20374 solver.cpp:237] Iteration 76194, loss = 1.15655
I0525 06:46:45.211019 20374 solver.cpp:253]     Train net output #0: loss = 1.15655 (* 1 = 1.15655 loss)
I0525 06:46:45.211041 20374 sgd_solver.cpp:106] Iteration 76194, lr = 0.0015
I0525 06:46:54.059586 20374 solver.cpp:237] Iteration 76360, loss = 1.20405
I0525 06:46:54.059782 20374 solver.cpp:253]     Train net output #0: loss = 1.20405 (* 1 = 1.20405 loss)
I0525 06:46:54.059799 20374 sgd_solver.cpp:106] Iteration 76360, lr = 0.0015
I0525 06:47:02.918543 20374 solver.cpp:237] Iteration 76526, loss = 1.03637
I0525 06:47:02.918602 20374 solver.cpp:253]     Train net output #0: loss = 1.03637 (* 1 = 1.03637 loss)
I0525 06:47:02.918627 20374 sgd_solver.cpp:106] Iteration 76526, lr = 0.0015
I0525 06:47:08.728778 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_76636.caffemodel
I0525 06:47:08.803573 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_76636.solverstate
I0525 06:47:10.021212 20374 solver.cpp:341] Iteration 76659, Testing net (#0)
I0525 06:47:56.878350 20374 solver.cpp:409]     Test net output #0: accuracy = 0.887213
I0525 06:47:56.878558 20374 solver.cpp:409]     Test net output #1: loss = 0.36483 (* 1 = 0.36483 loss)
I0525 06:48:19.492519 20374 solver.cpp:237] Iteration 76692, loss = 1.20311
I0525 06:48:19.492580 20374 solver.cpp:253]     Train net output #0: loss = 1.20311 (* 1 = 1.20311 loss)
I0525 06:48:19.492597 20374 sgd_solver.cpp:106] Iteration 76692, lr = 0.0015
I0525 06:48:28.334908 20374 solver.cpp:237] Iteration 76858, loss = 1.19331
I0525 06:48:28.335096 20374 solver.cpp:253]     Train net output #0: loss = 1.19331 (* 1 = 1.19331 loss)
I0525 06:48:28.335113 20374 sgd_solver.cpp:106] Iteration 76858, lr = 0.0015
I0525 06:48:37.178678 20374 solver.cpp:237] Iteration 77024, loss = 1.17146
I0525 06:48:37.178714 20374 solver.cpp:253]     Train net output #0: loss = 1.17146 (* 1 = 1.17146 loss)
I0525 06:48:37.178738 20374 sgd_solver.cpp:106] Iteration 77024, lr = 0.0015
I0525 06:48:46.029636 20374 solver.cpp:237] Iteration 77190, loss = 1.15631
I0525 06:48:46.029695 20374 solver.cpp:253]     Train net output #0: loss = 1.15631 (* 1 = 1.15631 loss)
I0525 06:48:46.029714 20374 sgd_solver.cpp:106] Iteration 77190, lr = 0.0015
I0525 06:48:54.875828 20374 solver.cpp:237] Iteration 77356, loss = 1.22603
I0525 06:48:54.875864 20374 solver.cpp:253]     Train net output #0: loss = 1.22603 (* 1 = 1.22603 loss)
I0525 06:48:54.875887 20374 sgd_solver.cpp:106] Iteration 77356, lr = 0.0015
I0525 06:49:03.712553 20374 solver.cpp:237] Iteration 77522, loss = 1.29761
I0525 06:49:03.712754 20374 solver.cpp:253]     Train net output #0: loss = 1.29761 (* 1 = 1.29761 loss)
I0525 06:49:03.712770 20374 sgd_solver.cpp:106] Iteration 77522, lr = 0.0015
I0525 06:49:12.565997 20374 solver.cpp:237] Iteration 77688, loss = 1.19411
I0525 06:49:12.566035 20374 solver.cpp:253]     Train net output #0: loss = 1.19411 (* 1 = 1.19411 loss)
I0525 06:49:12.566053 20374 sgd_solver.cpp:106] Iteration 77688, lr = 0.0015
I0525 06:49:42.256878 20374 solver.cpp:237] Iteration 77854, loss = 1.23297
I0525 06:49:42.257098 20374 solver.cpp:253]     Train net output #0: loss = 1.23297 (* 1 = 1.23297 loss)
I0525 06:49:42.257117 20374 sgd_solver.cpp:106] Iteration 77854, lr = 0.0015
I0525 06:49:51.098423 20374 solver.cpp:237] Iteration 78020, loss = 1.14202
I0525 06:49:51.098459 20374 solver.cpp:253]     Train net output #0: loss = 1.14202 (* 1 = 1.14202 loss)
I0525 06:49:51.098482 20374 sgd_solver.cpp:106] Iteration 78020, lr = 0.0015
I0525 06:49:59.939714 20374 solver.cpp:237] Iteration 78186, loss = 1.2173
I0525 06:49:59.939774 20374 solver.cpp:253]     Train net output #0: loss = 1.2173 (* 1 = 1.2173 loss)
I0525 06:49:59.939797 20374 sgd_solver.cpp:106] Iteration 78186, lr = 0.0015
I0525 06:50:06.066079 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_78302.caffemodel
I0525 06:50:06.142288 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_78302.solverstate
I0525 06:50:08.848971 20374 solver.cpp:237] Iteration 78352, loss = 1.23587
I0525 06:50:08.849027 20374 solver.cpp:253]     Train net output #0: loss = 1.23587 (* 1 = 1.23587 loss)
I0525 06:50:08.849043 20374 sgd_solver.cpp:106] Iteration 78352, lr = 0.0015
I0525 06:50:17.698292 20374 solver.cpp:237] Iteration 78518, loss = 1.16488
I0525 06:50:17.698493 20374 solver.cpp:253]     Train net output #0: loss = 1.16488 (* 1 = 1.16488 loss)
I0525 06:50:17.698509 20374 sgd_solver.cpp:106] Iteration 78518, lr = 0.0015
I0525 06:50:26.548058 20374 solver.cpp:237] Iteration 78684, loss = 0.958142
I0525 06:50:26.548115 20374 solver.cpp:253]     Train net output #0: loss = 0.958142 (* 1 = 0.958142 loss)
I0525 06:50:26.548141 20374 sgd_solver.cpp:106] Iteration 78684, lr = 0.0015
I0525 06:50:35.395530 20374 solver.cpp:237] Iteration 78850, loss = 1.27077
I0525 06:50:35.395567 20374 solver.cpp:253]     Train net output #0: loss = 1.27077 (* 1 = 1.27077 loss)
I0525 06:50:35.395586 20374 sgd_solver.cpp:106] Iteration 78850, lr = 0.0015
I0525 06:51:05.148566 20374 solver.cpp:237] Iteration 79016, loss = 1.17099
I0525 06:51:05.148778 20374 solver.cpp:253]     Train net output #0: loss = 1.17099 (* 1 = 1.17099 loss)
I0525 06:51:05.148797 20374 sgd_solver.cpp:106] Iteration 79016, lr = 0.0015
I0525 06:51:14.003762 20374 solver.cpp:237] Iteration 79182, loss = 1.02878
I0525 06:51:14.003820 20374 solver.cpp:253]     Train net output #0: loss = 1.02878 (* 1 = 1.02878 loss)
I0525 06:51:14.003844 20374 sgd_solver.cpp:106] Iteration 79182, lr = 0.0015
I0525 06:51:22.851379 20374 solver.cpp:237] Iteration 79348, loss = 1.03911
I0525 06:51:22.851418 20374 solver.cpp:253]     Train net output #0: loss = 1.03911 (* 1 = 1.03911 loss)
I0525 06:51:22.851435 20374 sgd_solver.cpp:106] Iteration 79348, lr = 0.0015
I0525 06:51:31.695756 20374 solver.cpp:237] Iteration 79514, loss = 1.13057
I0525 06:51:31.695793 20374 solver.cpp:253]     Train net output #0: loss = 1.13057 (* 1 = 1.13057 loss)
I0525 06:51:31.695816 20374 sgd_solver.cpp:106] Iteration 79514, lr = 0.0015
I0525 06:51:40.549549 20374 solver.cpp:237] Iteration 79680, loss = 1.28302
I0525 06:51:40.549756 20374 solver.cpp:253]     Train net output #0: loss = 1.28302 (* 1 = 1.28302 loss)
I0525 06:51:40.549774 20374 sgd_solver.cpp:106] Iteration 79680, lr = 0.0015
I0525 06:51:49.392102 20374 solver.cpp:237] Iteration 79846, loss = 0.981547
I0525 06:51:49.392139 20374 solver.cpp:253]     Train net output #0: loss = 0.981547 (* 1 = 0.981547 loss)
I0525 06:51:49.392158 20374 sgd_solver.cpp:106] Iteration 79846, lr = 0.0015
I0525 06:51:55.844956 20374 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_79968.caffemodel
I0525 06:51:55.919430 20374 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0015_2016-05-20T15.49.20.914763_iter_79968.solverstate
I0525 06:51:57.187747 20374 solver.cpp:341] Iteration 79992, Testing net (#0)
aprun: Apid 11262734: Caught signal Terminated, sending to application
*** Aborted at 1464173558 (unix time) try "date -d @1464173558" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x4f93) received by PID 20374 (TID 0x2aaac746f900) from PID 20371; stack trace: ***
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7220 exceeded limit 7200
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11262734: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11262734: Caught signal Terminated, sending to application
aprun: Apid 11262734: Caught signal Terminated, sending to application
aprun: Apid 11262734: Caught signal Terminated, sending to application
aprun: Apid 11262734: Caught signal Terminated, sending to application
aprun: Apid 11262734: Caught signal Terminated, sending to application
aprun: Apid 11262734: Caught signal Terminated, sending to application
aprun: Apid 11262734: Caught signal Terminated, sending to application
