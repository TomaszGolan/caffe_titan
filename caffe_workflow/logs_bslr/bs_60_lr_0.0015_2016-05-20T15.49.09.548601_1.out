2808520
I0523 13:59:36.898286  1883 caffe.cpp:184] Using GPUs 0
I0523 13:59:37.333421  1883 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.0015
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601.prototxt"
I0523 13:59:37.335371  1883 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601.prototxt
I0523 13:59:37.364202  1883 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 13:59:37.364262  1883 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 13:59:37.364611  1883 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 13:59:37.364790  1883 layer_factory.hpp:77] Creating layer data_hdf5
I0523 13:59:37.364814  1883 net.cpp:106] Creating Layer data_hdf5
I0523 13:59:37.364830  1883 net.cpp:411] data_hdf5 -> data
I0523 13:59:37.364862  1883 net.cpp:411] data_hdf5 -> label
I0523 13:59:37.364894  1883 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 13:59:37.373838  1883 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 13:59:37.388057  1883 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 13:59:58.953004  1883 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 13:59:58.958145  1883 net.cpp:150] Setting up data_hdf5
I0523 13:59:58.958190  1883 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 13:59:58.958204  1883 net.cpp:157] Top shape: 60 (60)
I0523 13:59:58.958215  1883 net.cpp:165] Memory required for data: 1524240
I0523 13:59:58.958228  1883 layer_factory.hpp:77] Creating layer conv1
I0523 13:59:58.958262  1883 net.cpp:106] Creating Layer conv1
I0523 13:59:58.958274  1883 net.cpp:454] conv1 <- data
I0523 13:59:58.958298  1883 net.cpp:411] conv1 -> conv1
I0523 14:00:02.003244  1883 net.cpp:150] Setting up conv1
I0523 14:00:02.003293  1883 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 14:00:02.003304  1883 net.cpp:165] Memory required for data: 18113040
I0523 14:00:02.003334  1883 layer_factory.hpp:77] Creating layer relu1
I0523 14:00:02.003355  1883 net.cpp:106] Creating Layer relu1
I0523 14:00:02.003365  1883 net.cpp:454] relu1 <- conv1
I0523 14:00:02.003378  1883 net.cpp:397] relu1 -> conv1 (in-place)
I0523 14:00:02.003911  1883 net.cpp:150] Setting up relu1
I0523 14:00:02.003929  1883 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 14:00:02.003939  1883 net.cpp:165] Memory required for data: 34701840
I0523 14:00:02.003950  1883 layer_factory.hpp:77] Creating layer pool1
I0523 14:00:02.003967  1883 net.cpp:106] Creating Layer pool1
I0523 14:00:02.003976  1883 net.cpp:454] pool1 <- conv1
I0523 14:00:02.003989  1883 net.cpp:411] pool1 -> pool1
I0523 14:00:02.004070  1883 net.cpp:150] Setting up pool1
I0523 14:00:02.004084  1883 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 14:00:02.004094  1883 net.cpp:165] Memory required for data: 42996240
I0523 14:00:02.004104  1883 layer_factory.hpp:77] Creating layer conv2
I0523 14:00:02.004124  1883 net.cpp:106] Creating Layer conv2
I0523 14:00:02.004135  1883 net.cpp:454] conv2 <- pool1
I0523 14:00:02.004148  1883 net.cpp:411] conv2 -> conv2
I0523 14:00:02.006881  1883 net.cpp:150] Setting up conv2
I0523 14:00:02.006909  1883 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 14:00:02.006919  1883 net.cpp:165] Memory required for data: 54919440
I0523 14:00:02.006939  1883 layer_factory.hpp:77] Creating layer relu2
I0523 14:00:02.006953  1883 net.cpp:106] Creating Layer relu2
I0523 14:00:02.006963  1883 net.cpp:454] relu2 <- conv2
I0523 14:00:02.006976  1883 net.cpp:397] relu2 -> conv2 (in-place)
I0523 14:00:02.007308  1883 net.cpp:150] Setting up relu2
I0523 14:00:02.007323  1883 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 14:00:02.007333  1883 net.cpp:165] Memory required for data: 66842640
I0523 14:00:02.007344  1883 layer_factory.hpp:77] Creating layer pool2
I0523 14:00:02.007355  1883 net.cpp:106] Creating Layer pool2
I0523 14:00:02.007365  1883 net.cpp:454] pool2 <- conv2
I0523 14:00:02.007378  1883 net.cpp:411] pool2 -> pool2
I0523 14:00:02.007458  1883 net.cpp:150] Setting up pool2
I0523 14:00:02.007472  1883 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 14:00:02.007483  1883 net.cpp:165] Memory required for data: 72804240
I0523 14:00:02.007493  1883 layer_factory.hpp:77] Creating layer conv3
I0523 14:00:02.007510  1883 net.cpp:106] Creating Layer conv3
I0523 14:00:02.007520  1883 net.cpp:454] conv3 <- pool2
I0523 14:00:02.007534  1883 net.cpp:411] conv3 -> conv3
I0523 14:00:02.009490  1883 net.cpp:150] Setting up conv3
I0523 14:00:02.009513  1883 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 14:00:02.009524  1883 net.cpp:165] Memory required for data: 79309200
I0523 14:00:02.009543  1883 layer_factory.hpp:77] Creating layer relu3
I0523 14:00:02.009560  1883 net.cpp:106] Creating Layer relu3
I0523 14:00:02.009570  1883 net.cpp:454] relu3 <- conv3
I0523 14:00:02.009583  1883 net.cpp:397] relu3 -> conv3 (in-place)
I0523 14:00:02.010052  1883 net.cpp:150] Setting up relu3
I0523 14:00:02.010069  1883 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 14:00:02.010079  1883 net.cpp:165] Memory required for data: 85814160
I0523 14:00:02.010092  1883 layer_factory.hpp:77] Creating layer pool3
I0523 14:00:02.010104  1883 net.cpp:106] Creating Layer pool3
I0523 14:00:02.010114  1883 net.cpp:454] pool3 <- conv3
I0523 14:00:02.010126  1883 net.cpp:411] pool3 -> pool3
I0523 14:00:02.010193  1883 net.cpp:150] Setting up pool3
I0523 14:00:02.010206  1883 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 14:00:02.010216  1883 net.cpp:165] Memory required for data: 89066640
I0523 14:00:02.010226  1883 layer_factory.hpp:77] Creating layer conv4
I0523 14:00:02.010244  1883 net.cpp:106] Creating Layer conv4
I0523 14:00:02.010254  1883 net.cpp:454] conv4 <- pool3
I0523 14:00:02.010268  1883 net.cpp:411] conv4 -> conv4
I0523 14:00:02.013049  1883 net.cpp:150] Setting up conv4
I0523 14:00:02.013077  1883 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 14:00:02.013088  1883 net.cpp:165] Memory required for data: 91243920
I0523 14:00:02.013103  1883 layer_factory.hpp:77] Creating layer relu4
I0523 14:00:02.013118  1883 net.cpp:106] Creating Layer relu4
I0523 14:00:02.013128  1883 net.cpp:454] relu4 <- conv4
I0523 14:00:02.013141  1883 net.cpp:397] relu4 -> conv4 (in-place)
I0523 14:00:02.013620  1883 net.cpp:150] Setting up relu4
I0523 14:00:02.013638  1883 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 14:00:02.013648  1883 net.cpp:165] Memory required for data: 93421200
I0523 14:00:02.013658  1883 layer_factory.hpp:77] Creating layer pool4
I0523 14:00:02.013671  1883 net.cpp:106] Creating Layer pool4
I0523 14:00:02.013681  1883 net.cpp:454] pool4 <- conv4
I0523 14:00:02.013695  1883 net.cpp:411] pool4 -> pool4
I0523 14:00:02.013762  1883 net.cpp:150] Setting up pool4
I0523 14:00:02.013775  1883 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 14:00:02.013787  1883 net.cpp:165] Memory required for data: 94509840
I0523 14:00:02.013797  1883 layer_factory.hpp:77] Creating layer ip1
I0523 14:00:02.013814  1883 net.cpp:106] Creating Layer ip1
I0523 14:00:02.013824  1883 net.cpp:454] ip1 <- pool4
I0523 14:00:02.013838  1883 net.cpp:411] ip1 -> ip1
I0523 14:00:02.029263  1883 net.cpp:150] Setting up ip1
I0523 14:00:02.029291  1883 net.cpp:157] Top shape: 60 196 (11760)
I0523 14:00:02.029304  1883 net.cpp:165] Memory required for data: 94556880
I0523 14:00:02.029326  1883 layer_factory.hpp:77] Creating layer relu5
I0523 14:00:02.029341  1883 net.cpp:106] Creating Layer relu5
I0523 14:00:02.029351  1883 net.cpp:454] relu5 <- ip1
I0523 14:00:02.029368  1883 net.cpp:397] relu5 -> ip1 (in-place)
I0523 14:00:02.029711  1883 net.cpp:150] Setting up relu5
I0523 14:00:02.029724  1883 net.cpp:157] Top shape: 60 196 (11760)
I0523 14:00:02.029734  1883 net.cpp:165] Memory required for data: 94603920
I0523 14:00:02.029745  1883 layer_factory.hpp:77] Creating layer drop1
I0523 14:00:02.029767  1883 net.cpp:106] Creating Layer drop1
I0523 14:00:02.029778  1883 net.cpp:454] drop1 <- ip1
I0523 14:00:02.029789  1883 net.cpp:397] drop1 -> ip1 (in-place)
I0523 14:00:02.029850  1883 net.cpp:150] Setting up drop1
I0523 14:00:02.029862  1883 net.cpp:157] Top shape: 60 196 (11760)
I0523 14:00:02.029872  1883 net.cpp:165] Memory required for data: 94650960
I0523 14:00:02.029882  1883 layer_factory.hpp:77] Creating layer ip2
I0523 14:00:02.029901  1883 net.cpp:106] Creating Layer ip2
I0523 14:00:02.029912  1883 net.cpp:454] ip2 <- ip1
I0523 14:00:02.029925  1883 net.cpp:411] ip2 -> ip2
I0523 14:00:02.030387  1883 net.cpp:150] Setting up ip2
I0523 14:00:02.030400  1883 net.cpp:157] Top shape: 60 98 (5880)
I0523 14:00:02.030411  1883 net.cpp:165] Memory required for data: 94674480
I0523 14:00:02.030426  1883 layer_factory.hpp:77] Creating layer relu6
I0523 14:00:02.030439  1883 net.cpp:106] Creating Layer relu6
I0523 14:00:02.030448  1883 net.cpp:454] relu6 <- ip2
I0523 14:00:02.030462  1883 net.cpp:397] relu6 -> ip2 (in-place)
I0523 14:00:02.030980  1883 net.cpp:150] Setting up relu6
I0523 14:00:02.030997  1883 net.cpp:157] Top shape: 60 98 (5880)
I0523 14:00:02.031008  1883 net.cpp:165] Memory required for data: 94698000
I0523 14:00:02.031018  1883 layer_factory.hpp:77] Creating layer drop2
I0523 14:00:02.031030  1883 net.cpp:106] Creating Layer drop2
I0523 14:00:02.031040  1883 net.cpp:454] drop2 <- ip2
I0523 14:00:02.031052  1883 net.cpp:397] drop2 -> ip2 (in-place)
I0523 14:00:02.031095  1883 net.cpp:150] Setting up drop2
I0523 14:00:02.031108  1883 net.cpp:157] Top shape: 60 98 (5880)
I0523 14:00:02.031118  1883 net.cpp:165] Memory required for data: 94721520
I0523 14:00:02.031128  1883 layer_factory.hpp:77] Creating layer ip3
I0523 14:00:02.031142  1883 net.cpp:106] Creating Layer ip3
I0523 14:00:02.031152  1883 net.cpp:454] ip3 <- ip2
I0523 14:00:02.031164  1883 net.cpp:411] ip3 -> ip3
I0523 14:00:02.031376  1883 net.cpp:150] Setting up ip3
I0523 14:00:02.031389  1883 net.cpp:157] Top shape: 60 11 (660)
I0523 14:00:02.031399  1883 net.cpp:165] Memory required for data: 94724160
I0523 14:00:02.031414  1883 layer_factory.hpp:77] Creating layer drop3
I0523 14:00:02.031426  1883 net.cpp:106] Creating Layer drop3
I0523 14:00:02.031436  1883 net.cpp:454] drop3 <- ip3
I0523 14:00:02.031448  1883 net.cpp:397] drop3 -> ip3 (in-place)
I0523 14:00:02.031488  1883 net.cpp:150] Setting up drop3
I0523 14:00:02.031500  1883 net.cpp:157] Top shape: 60 11 (660)
I0523 14:00:02.031512  1883 net.cpp:165] Memory required for data: 94726800
I0523 14:00:02.031522  1883 layer_factory.hpp:77] Creating layer loss
I0523 14:00:02.031541  1883 net.cpp:106] Creating Layer loss
I0523 14:00:02.031551  1883 net.cpp:454] loss <- ip3
I0523 14:00:02.031563  1883 net.cpp:454] loss <- label
I0523 14:00:02.031576  1883 net.cpp:411] loss -> loss
I0523 14:00:02.031594  1883 layer_factory.hpp:77] Creating layer loss
I0523 14:00:02.032243  1883 net.cpp:150] Setting up loss
I0523 14:00:02.032264  1883 net.cpp:157] Top shape: (1)
I0523 14:00:02.032277  1883 net.cpp:160]     with loss weight 1
I0523 14:00:02.032320  1883 net.cpp:165] Memory required for data: 94726804
I0523 14:00:02.032330  1883 net.cpp:226] loss needs backward computation.
I0523 14:00:02.032341  1883 net.cpp:226] drop3 needs backward computation.
I0523 14:00:02.032351  1883 net.cpp:226] ip3 needs backward computation.
I0523 14:00:02.032361  1883 net.cpp:226] drop2 needs backward computation.
I0523 14:00:02.032371  1883 net.cpp:226] relu6 needs backward computation.
I0523 14:00:02.032382  1883 net.cpp:226] ip2 needs backward computation.
I0523 14:00:02.032392  1883 net.cpp:226] drop1 needs backward computation.
I0523 14:00:02.032402  1883 net.cpp:226] relu5 needs backward computation.
I0523 14:00:02.032410  1883 net.cpp:226] ip1 needs backward computation.
I0523 14:00:02.032420  1883 net.cpp:226] pool4 needs backward computation.
I0523 14:00:02.032431  1883 net.cpp:226] relu4 needs backward computation.
I0523 14:00:02.032440  1883 net.cpp:226] conv4 needs backward computation.
I0523 14:00:02.032451  1883 net.cpp:226] pool3 needs backward computation.
I0523 14:00:02.032461  1883 net.cpp:226] relu3 needs backward computation.
I0523 14:00:02.032471  1883 net.cpp:226] conv3 needs backward computation.
I0523 14:00:02.032491  1883 net.cpp:226] pool2 needs backward computation.
I0523 14:00:02.032502  1883 net.cpp:226] relu2 needs backward computation.
I0523 14:00:02.032513  1883 net.cpp:226] conv2 needs backward computation.
I0523 14:00:02.032523  1883 net.cpp:226] pool1 needs backward computation.
I0523 14:00:02.032534  1883 net.cpp:226] relu1 needs backward computation.
I0523 14:00:02.032544  1883 net.cpp:226] conv1 needs backward computation.
I0523 14:00:02.032555  1883 net.cpp:228] data_hdf5 does not need backward computation.
I0523 14:00:02.032565  1883 net.cpp:270] This network produces output loss
I0523 14:00:02.032589  1883 net.cpp:283] Network initialization done.
I0523 14:00:02.034307  1883 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601.prototxt
I0523 14:00:02.034378  1883 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 14:00:02.034734  1883 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 14:00:02.034922  1883 layer_factory.hpp:77] Creating layer data_hdf5
I0523 14:00:02.034937  1883 net.cpp:106] Creating Layer data_hdf5
I0523 14:00:02.034950  1883 net.cpp:411] data_hdf5 -> data
I0523 14:00:02.034965  1883 net.cpp:411] data_hdf5 -> label
I0523 14:00:02.034981  1883 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 14:00:02.046696  1883 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 14:00:23.491037  1883 net.cpp:150] Setting up data_hdf5
I0523 14:00:23.491204  1883 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 14:00:23.491217  1883 net.cpp:157] Top shape: 60 (60)
I0523 14:00:23.491230  1883 net.cpp:165] Memory required for data: 1524240
I0523 14:00:23.491243  1883 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 14:00:23.491271  1883 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 14:00:23.491283  1883 net.cpp:454] label_data_hdf5_1_split <- label
I0523 14:00:23.491297  1883 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 14:00:23.491319  1883 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 14:00:23.491391  1883 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 14:00:23.491405  1883 net.cpp:157] Top shape: 60 (60)
I0523 14:00:23.491416  1883 net.cpp:157] Top shape: 60 (60)
I0523 14:00:23.491426  1883 net.cpp:165] Memory required for data: 1524720
I0523 14:00:23.491436  1883 layer_factory.hpp:77] Creating layer conv1
I0523 14:00:23.491458  1883 net.cpp:106] Creating Layer conv1
I0523 14:00:23.491468  1883 net.cpp:454] conv1 <- data
I0523 14:00:23.491482  1883 net.cpp:411] conv1 -> conv1
I0523 14:00:23.493408  1883 net.cpp:150] Setting up conv1
I0523 14:00:23.493433  1883 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 14:00:23.493443  1883 net.cpp:165] Memory required for data: 18113520
I0523 14:00:23.493464  1883 layer_factory.hpp:77] Creating layer relu1
I0523 14:00:23.493479  1883 net.cpp:106] Creating Layer relu1
I0523 14:00:23.493489  1883 net.cpp:454] relu1 <- conv1
I0523 14:00:23.493502  1883 net.cpp:397] relu1 -> conv1 (in-place)
I0523 14:00:23.493999  1883 net.cpp:150] Setting up relu1
I0523 14:00:23.494014  1883 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 14:00:23.494025  1883 net.cpp:165] Memory required for data: 34702320
I0523 14:00:23.494035  1883 layer_factory.hpp:77] Creating layer pool1
I0523 14:00:23.494051  1883 net.cpp:106] Creating Layer pool1
I0523 14:00:23.494060  1883 net.cpp:454] pool1 <- conv1
I0523 14:00:23.494074  1883 net.cpp:411] pool1 -> pool1
I0523 14:00:23.494149  1883 net.cpp:150] Setting up pool1
I0523 14:00:23.494163  1883 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 14:00:23.494173  1883 net.cpp:165] Memory required for data: 42996720
I0523 14:00:23.494180  1883 layer_factory.hpp:77] Creating layer conv2
I0523 14:00:23.494199  1883 net.cpp:106] Creating Layer conv2
I0523 14:00:23.494210  1883 net.cpp:454] conv2 <- pool1
I0523 14:00:23.494222  1883 net.cpp:411] conv2 -> conv2
I0523 14:00:23.496142  1883 net.cpp:150] Setting up conv2
I0523 14:00:23.496165  1883 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 14:00:23.496178  1883 net.cpp:165] Memory required for data: 54919920
I0523 14:00:23.496196  1883 layer_factory.hpp:77] Creating layer relu2
I0523 14:00:23.496211  1883 net.cpp:106] Creating Layer relu2
I0523 14:00:23.496220  1883 net.cpp:454] relu2 <- conv2
I0523 14:00:23.496232  1883 net.cpp:397] relu2 -> conv2 (in-place)
I0523 14:00:23.496563  1883 net.cpp:150] Setting up relu2
I0523 14:00:23.496577  1883 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 14:00:23.496588  1883 net.cpp:165] Memory required for data: 66843120
I0523 14:00:23.496598  1883 layer_factory.hpp:77] Creating layer pool2
I0523 14:00:23.496611  1883 net.cpp:106] Creating Layer pool2
I0523 14:00:23.496621  1883 net.cpp:454] pool2 <- conv2
I0523 14:00:23.496634  1883 net.cpp:411] pool2 -> pool2
I0523 14:00:23.496703  1883 net.cpp:150] Setting up pool2
I0523 14:00:23.496717  1883 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 14:00:23.496726  1883 net.cpp:165] Memory required for data: 72804720
I0523 14:00:23.496737  1883 layer_factory.hpp:77] Creating layer conv3
I0523 14:00:23.496757  1883 net.cpp:106] Creating Layer conv3
I0523 14:00:23.496767  1883 net.cpp:454] conv3 <- pool2
I0523 14:00:23.496781  1883 net.cpp:411] conv3 -> conv3
I0523 14:00:23.498744  1883 net.cpp:150] Setting up conv3
I0523 14:00:23.498769  1883 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 14:00:23.498780  1883 net.cpp:165] Memory required for data: 79309680
I0523 14:00:23.498812  1883 layer_factory.hpp:77] Creating layer relu3
I0523 14:00:23.498826  1883 net.cpp:106] Creating Layer relu3
I0523 14:00:23.498836  1883 net.cpp:454] relu3 <- conv3
I0523 14:00:23.498848  1883 net.cpp:397] relu3 -> conv3 (in-place)
I0523 14:00:23.499322  1883 net.cpp:150] Setting up relu3
I0523 14:00:23.499338  1883 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 14:00:23.499348  1883 net.cpp:165] Memory required for data: 85814640
I0523 14:00:23.499358  1883 layer_factory.hpp:77] Creating layer pool3
I0523 14:00:23.499372  1883 net.cpp:106] Creating Layer pool3
I0523 14:00:23.499382  1883 net.cpp:454] pool3 <- conv3
I0523 14:00:23.499394  1883 net.cpp:411] pool3 -> pool3
I0523 14:00:23.499466  1883 net.cpp:150] Setting up pool3
I0523 14:00:23.499480  1883 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 14:00:23.499490  1883 net.cpp:165] Memory required for data: 89067120
I0523 14:00:23.499500  1883 layer_factory.hpp:77] Creating layer conv4
I0523 14:00:23.499518  1883 net.cpp:106] Creating Layer conv4
I0523 14:00:23.499528  1883 net.cpp:454] conv4 <- pool3
I0523 14:00:23.499542  1883 net.cpp:411] conv4 -> conv4
I0523 14:00:23.501608  1883 net.cpp:150] Setting up conv4
I0523 14:00:23.501626  1883 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 14:00:23.501637  1883 net.cpp:165] Memory required for data: 91244400
I0523 14:00:23.501653  1883 layer_factory.hpp:77] Creating layer relu4
I0523 14:00:23.501667  1883 net.cpp:106] Creating Layer relu4
I0523 14:00:23.501677  1883 net.cpp:454] relu4 <- conv4
I0523 14:00:23.501690  1883 net.cpp:397] relu4 -> conv4 (in-place)
I0523 14:00:23.502159  1883 net.cpp:150] Setting up relu4
I0523 14:00:23.502174  1883 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 14:00:23.502184  1883 net.cpp:165] Memory required for data: 93421680
I0523 14:00:23.502194  1883 layer_factory.hpp:77] Creating layer pool4
I0523 14:00:23.502207  1883 net.cpp:106] Creating Layer pool4
I0523 14:00:23.502218  1883 net.cpp:454] pool4 <- conv4
I0523 14:00:23.502231  1883 net.cpp:411] pool4 -> pool4
I0523 14:00:23.502302  1883 net.cpp:150] Setting up pool4
I0523 14:00:23.502315  1883 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 14:00:23.502326  1883 net.cpp:165] Memory required for data: 94510320
I0523 14:00:23.502334  1883 layer_factory.hpp:77] Creating layer ip1
I0523 14:00:23.502348  1883 net.cpp:106] Creating Layer ip1
I0523 14:00:23.502358  1883 net.cpp:454] ip1 <- pool4
I0523 14:00:23.502372  1883 net.cpp:411] ip1 -> ip1
I0523 14:00:23.517823  1883 net.cpp:150] Setting up ip1
I0523 14:00:23.517846  1883 net.cpp:157] Top shape: 60 196 (11760)
I0523 14:00:23.517856  1883 net.cpp:165] Memory required for data: 94557360
I0523 14:00:23.517879  1883 layer_factory.hpp:77] Creating layer relu5
I0523 14:00:23.517894  1883 net.cpp:106] Creating Layer relu5
I0523 14:00:23.517904  1883 net.cpp:454] relu5 <- ip1
I0523 14:00:23.517917  1883 net.cpp:397] relu5 -> ip1 (in-place)
I0523 14:00:23.518261  1883 net.cpp:150] Setting up relu5
I0523 14:00:23.518275  1883 net.cpp:157] Top shape: 60 196 (11760)
I0523 14:00:23.518285  1883 net.cpp:165] Memory required for data: 94604400
I0523 14:00:23.518296  1883 layer_factory.hpp:77] Creating layer drop1
I0523 14:00:23.518314  1883 net.cpp:106] Creating Layer drop1
I0523 14:00:23.518324  1883 net.cpp:454] drop1 <- ip1
I0523 14:00:23.518337  1883 net.cpp:397] drop1 -> ip1 (in-place)
I0523 14:00:23.518383  1883 net.cpp:150] Setting up drop1
I0523 14:00:23.518395  1883 net.cpp:157] Top shape: 60 196 (11760)
I0523 14:00:23.518405  1883 net.cpp:165] Memory required for data: 94651440
I0523 14:00:23.518414  1883 layer_factory.hpp:77] Creating layer ip2
I0523 14:00:23.518429  1883 net.cpp:106] Creating Layer ip2
I0523 14:00:23.518438  1883 net.cpp:454] ip2 <- ip1
I0523 14:00:23.518452  1883 net.cpp:411] ip2 -> ip2
I0523 14:00:23.518929  1883 net.cpp:150] Setting up ip2
I0523 14:00:23.518941  1883 net.cpp:157] Top shape: 60 98 (5880)
I0523 14:00:23.518951  1883 net.cpp:165] Memory required for data: 94674960
I0523 14:00:23.518967  1883 layer_factory.hpp:77] Creating layer relu6
I0523 14:00:23.518992  1883 net.cpp:106] Creating Layer relu6
I0523 14:00:23.519002  1883 net.cpp:454] relu6 <- ip2
I0523 14:00:23.519016  1883 net.cpp:397] relu6 -> ip2 (in-place)
I0523 14:00:23.519549  1883 net.cpp:150] Setting up relu6
I0523 14:00:23.519572  1883 net.cpp:157] Top shape: 60 98 (5880)
I0523 14:00:23.519582  1883 net.cpp:165] Memory required for data: 94698480
I0523 14:00:23.519593  1883 layer_factory.hpp:77] Creating layer drop2
I0523 14:00:23.519606  1883 net.cpp:106] Creating Layer drop2
I0523 14:00:23.519616  1883 net.cpp:454] drop2 <- ip2
I0523 14:00:23.519629  1883 net.cpp:397] drop2 -> ip2 (in-place)
I0523 14:00:23.519681  1883 net.cpp:150] Setting up drop2
I0523 14:00:23.519695  1883 net.cpp:157] Top shape: 60 98 (5880)
I0523 14:00:23.519706  1883 net.cpp:165] Memory required for data: 94722000
I0523 14:00:23.519714  1883 layer_factory.hpp:77] Creating layer ip3
I0523 14:00:23.519728  1883 net.cpp:106] Creating Layer ip3
I0523 14:00:23.519738  1883 net.cpp:454] ip3 <- ip2
I0523 14:00:23.519752  1883 net.cpp:411] ip3 -> ip3
I0523 14:00:23.519975  1883 net.cpp:150] Setting up ip3
I0523 14:00:23.519989  1883 net.cpp:157] Top shape: 60 11 (660)
I0523 14:00:23.519999  1883 net.cpp:165] Memory required for data: 94724640
I0523 14:00:23.520015  1883 layer_factory.hpp:77] Creating layer drop3
I0523 14:00:23.520026  1883 net.cpp:106] Creating Layer drop3
I0523 14:00:23.520036  1883 net.cpp:454] drop3 <- ip3
I0523 14:00:23.520050  1883 net.cpp:397] drop3 -> ip3 (in-place)
I0523 14:00:23.520090  1883 net.cpp:150] Setting up drop3
I0523 14:00:23.520103  1883 net.cpp:157] Top shape: 60 11 (660)
I0523 14:00:23.520112  1883 net.cpp:165] Memory required for data: 94727280
I0523 14:00:23.520123  1883 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 14:00:23.520135  1883 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 14:00:23.520145  1883 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 14:00:23.520159  1883 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 14:00:23.520174  1883 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 14:00:23.520246  1883 net.cpp:150] Setting up ip3_drop3_0_split
I0523 14:00:23.520261  1883 net.cpp:157] Top shape: 60 11 (660)
I0523 14:00:23.520272  1883 net.cpp:157] Top shape: 60 11 (660)
I0523 14:00:23.520282  1883 net.cpp:165] Memory required for data: 94732560
I0523 14:00:23.520292  1883 layer_factory.hpp:77] Creating layer accuracy
I0523 14:00:23.520313  1883 net.cpp:106] Creating Layer accuracy
I0523 14:00:23.520323  1883 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 14:00:23.520334  1883 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 14:00:23.520349  1883 net.cpp:411] accuracy -> accuracy
I0523 14:00:23.520372  1883 net.cpp:150] Setting up accuracy
I0523 14:00:23.520385  1883 net.cpp:157] Top shape: (1)
I0523 14:00:23.520395  1883 net.cpp:165] Memory required for data: 94732564
I0523 14:00:23.520404  1883 layer_factory.hpp:77] Creating layer loss
I0523 14:00:23.520417  1883 net.cpp:106] Creating Layer loss
I0523 14:00:23.520428  1883 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 14:00:23.520439  1883 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 14:00:23.520452  1883 net.cpp:411] loss -> loss
I0523 14:00:23.520469  1883 layer_factory.hpp:77] Creating layer loss
I0523 14:00:23.520956  1883 net.cpp:150] Setting up loss
I0523 14:00:23.520969  1883 net.cpp:157] Top shape: (1)
I0523 14:00:23.520978  1883 net.cpp:160]     with loss weight 1
I0523 14:00:23.520998  1883 net.cpp:165] Memory required for data: 94732568
I0523 14:00:23.521008  1883 net.cpp:226] loss needs backward computation.
I0523 14:00:23.521018  1883 net.cpp:228] accuracy does not need backward computation.
I0523 14:00:23.521029  1883 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 14:00:23.521039  1883 net.cpp:226] drop3 needs backward computation.
I0523 14:00:23.521049  1883 net.cpp:226] ip3 needs backward computation.
I0523 14:00:23.521059  1883 net.cpp:226] drop2 needs backward computation.
I0523 14:00:23.521069  1883 net.cpp:226] relu6 needs backward computation.
I0523 14:00:23.521086  1883 net.cpp:226] ip2 needs backward computation.
I0523 14:00:23.521096  1883 net.cpp:226] drop1 needs backward computation.
I0523 14:00:23.521106  1883 net.cpp:226] relu5 needs backward computation.
I0523 14:00:23.521116  1883 net.cpp:226] ip1 needs backward computation.
I0523 14:00:23.521126  1883 net.cpp:226] pool4 needs backward computation.
I0523 14:00:23.521136  1883 net.cpp:226] relu4 needs backward computation.
I0523 14:00:23.521145  1883 net.cpp:226] conv4 needs backward computation.
I0523 14:00:23.521157  1883 net.cpp:226] pool3 needs backward computation.
I0523 14:00:23.521167  1883 net.cpp:226] relu3 needs backward computation.
I0523 14:00:23.521178  1883 net.cpp:226] conv3 needs backward computation.
I0523 14:00:23.521188  1883 net.cpp:226] pool2 needs backward computation.
I0523 14:00:23.521199  1883 net.cpp:226] relu2 needs backward computation.
I0523 14:00:23.521209  1883 net.cpp:226] conv2 needs backward computation.
I0523 14:00:23.521219  1883 net.cpp:226] pool1 needs backward computation.
I0523 14:00:23.521229  1883 net.cpp:226] relu1 needs backward computation.
I0523 14:00:23.521239  1883 net.cpp:226] conv1 needs backward computation.
I0523 14:00:23.521251  1883 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 14:00:23.521262  1883 net.cpp:228] data_hdf5 does not need backward computation.
I0523 14:00:23.521271  1883 net.cpp:270] This network produces output accuracy
I0523 14:00:23.521281  1883 net.cpp:270] This network produces output loss
I0523 14:00:23.521311  1883 net.cpp:283] Network initialization done.
I0523 14:00:23.521443  1883 solver.cpp:60] Solver scaffolding done.
I0523 14:00:23.522574  1883 caffe.cpp:212] Starting Optimization
I0523 14:00:23.522593  1883 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 14:00:23.522606  1883 solver.cpp:289] Learning Rate Policy: fixed
I0523 14:00:23.523844  1883 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 14:01:11.807368  1883 solver.cpp:409]     Test net output #0: accuracy = 0.0384602
I0523 14:01:11.807531  1883 solver.cpp:409]     Test net output #1: loss = 2.39845 (* 1 = 2.39845 loss)
I0523 14:01:11.833379  1883 solver.cpp:237] Iteration 0, loss = 2.39554
I0523 14:01:11.833416  1883 solver.cpp:253]     Train net output #0: loss = 2.39554 (* 1 = 2.39554 loss)
I0523 14:01:11.833434  1883 sgd_solver.cpp:106] Iteration 0, lr = 0.0015
I0523 14:01:20.932636  1883 solver.cpp:237] Iteration 250, loss = 2.27038
I0523 14:01:20.932682  1883 solver.cpp:253]     Train net output #0: loss = 2.27038 (* 1 = 2.27038 loss)
I0523 14:01:20.932698  1883 sgd_solver.cpp:106] Iteration 250, lr = 0.0015
I0523 14:01:30.029269  1883 solver.cpp:237] Iteration 500, loss = 2.26837
I0523 14:01:30.029304  1883 solver.cpp:253]     Train net output #0: loss = 2.26837 (* 1 = 2.26837 loss)
I0523 14:01:30.029321  1883 sgd_solver.cpp:106] Iteration 500, lr = 0.0015
I0523 14:01:39.123308  1883 solver.cpp:237] Iteration 750, loss = 2.16975
I0523 14:01:39.123343  1883 solver.cpp:253]     Train net output #0: loss = 2.16975 (* 1 = 2.16975 loss)
I0523 14:01:39.123359  1883 sgd_solver.cpp:106] Iteration 750, lr = 0.0015
I0523 14:01:48.232594  1883 solver.cpp:237] Iteration 1000, loss = 1.99577
I0523 14:01:48.232743  1883 solver.cpp:253]     Train net output #0: loss = 1.99577 (* 1 = 1.99577 loss)
I0523 14:01:48.232756  1883 sgd_solver.cpp:106] Iteration 1000, lr = 0.0015
I0523 14:01:57.337455  1883 solver.cpp:237] Iteration 1250, loss = 2.03525
I0523 14:01:57.337489  1883 solver.cpp:253]     Train net output #0: loss = 2.03525 (* 1 = 2.03525 loss)
I0523 14:01:57.337507  1883 sgd_solver.cpp:106] Iteration 1250, lr = 0.0015
I0523 14:02:06.438980  1883 solver.cpp:237] Iteration 1500, loss = 2.05051
I0523 14:02:06.439019  1883 solver.cpp:253]     Train net output #0: loss = 2.05051 (* 1 = 2.05051 loss)
I0523 14:02:06.439034  1883 sgd_solver.cpp:106] Iteration 1500, lr = 0.0015
I0523 14:02:37.703572  1883 solver.cpp:237] Iteration 1750, loss = 1.83635
I0523 14:02:37.703763  1883 solver.cpp:253]     Train net output #0: loss = 1.83635 (* 1 = 1.83635 loss)
I0523 14:02:37.703778  1883 sgd_solver.cpp:106] Iteration 1750, lr = 0.0015
I0523 14:02:46.809017  1883 solver.cpp:237] Iteration 2000, loss = 1.79508
I0523 14:02:46.809051  1883 solver.cpp:253]     Train net output #0: loss = 1.79508 (* 1 = 1.79508 loss)
I0523 14:02:46.809069  1883 sgd_solver.cpp:106] Iteration 2000, lr = 0.0015
I0523 14:02:55.913311  1883 solver.cpp:237] Iteration 2250, loss = 1.90539
I0523 14:02:55.913358  1883 solver.cpp:253]     Train net output #0: loss = 1.90539 (* 1 = 1.90539 loss)
I0523 14:02:55.913372  1883 sgd_solver.cpp:106] Iteration 2250, lr = 0.0015
I0523 14:03:04.976585  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_2500.caffemodel
I0523 14:03:05.043097  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_2500.solverstate
I0523 14:03:05.079942  1883 solver.cpp:237] Iteration 2500, loss = 1.80113
I0523 14:03:05.079988  1883 solver.cpp:253]     Train net output #0: loss = 1.80113 (* 1 = 1.80113 loss)
I0523 14:03:05.080003  1883 sgd_solver.cpp:106] Iteration 2500, lr = 0.0015
I0523 14:03:14.188740  1883 solver.cpp:237] Iteration 2750, loss = 1.94298
I0523 14:03:14.188882  1883 solver.cpp:253]     Train net output #0: loss = 1.94298 (* 1 = 1.94298 loss)
I0523 14:03:14.188895  1883 sgd_solver.cpp:106] Iteration 2750, lr = 0.0015
I0523 14:03:23.295236  1883 solver.cpp:237] Iteration 3000, loss = 1.6745
I0523 14:03:23.295279  1883 solver.cpp:253]     Train net output #0: loss = 1.6745 (* 1 = 1.6745 loss)
I0523 14:03:23.295296  1883 sgd_solver.cpp:106] Iteration 3000, lr = 0.0015
I0523 14:03:32.404453  1883 solver.cpp:237] Iteration 3250, loss = 1.91697
I0523 14:03:32.404489  1883 solver.cpp:253]     Train net output #0: loss = 1.91697 (* 1 = 1.91697 loss)
I0523 14:03:32.404506  1883 sgd_solver.cpp:106] Iteration 3250, lr = 0.0015
I0523 14:04:03.699897  1883 solver.cpp:237] Iteration 3500, loss = 1.63515
I0523 14:04:03.700052  1883 solver.cpp:253]     Train net output #0: loss = 1.63515 (* 1 = 1.63515 loss)
I0523 14:04:03.700065  1883 sgd_solver.cpp:106] Iteration 3500, lr = 0.0015
I0523 14:04:12.799145  1883 solver.cpp:237] Iteration 3750, loss = 1.92231
I0523 14:04:12.799188  1883 solver.cpp:253]     Train net output #0: loss = 1.92231 (* 1 = 1.92231 loss)
I0523 14:04:12.799206  1883 sgd_solver.cpp:106] Iteration 3750, lr = 0.0015
I0523 14:04:21.914453  1883 solver.cpp:237] Iteration 4000, loss = 1.68861
I0523 14:04:21.914489  1883 solver.cpp:253]     Train net output #0: loss = 1.68861 (* 1 = 1.68861 loss)
I0523 14:04:21.914506  1883 sgd_solver.cpp:106] Iteration 4000, lr = 0.0015
I0523 14:04:31.027302  1883 solver.cpp:237] Iteration 4250, loss = 1.44775
I0523 14:04:31.027338  1883 solver.cpp:253]     Train net output #0: loss = 1.44775 (* 1 = 1.44775 loss)
I0523 14:04:31.027354  1883 sgd_solver.cpp:106] Iteration 4250, lr = 0.0015
I0523 14:04:40.125238  1883 solver.cpp:237] Iteration 4500, loss = 1.89797
I0523 14:04:40.125393  1883 solver.cpp:253]     Train net output #0: loss = 1.89797 (* 1 = 1.89797 loss)
I0523 14:04:40.125407  1883 sgd_solver.cpp:106] Iteration 4500, lr = 0.0015
I0523 14:04:49.228967  1883 solver.cpp:237] Iteration 4750, loss = 1.64784
I0523 14:04:49.229001  1883 solver.cpp:253]     Train net output #0: loss = 1.64784 (* 1 = 1.64784 loss)
I0523 14:04:49.229019  1883 sgd_solver.cpp:106] Iteration 4750, lr = 0.0015
I0523 14:04:58.299392  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_5000.caffemodel
I0523 14:04:58.363268  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_5000.solverstate
I0523 14:04:58.388533  1883 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 14:05:45.714161  1883 solver.cpp:409]     Test net output #0: accuracy = 0.681206
I0523 14:05:45.714323  1883 solver.cpp:409]     Test net output #1: loss = 1.04045 (* 1 = 1.04045 loss)
I0523 14:06:07.971410  1883 solver.cpp:237] Iteration 5000, loss = 1.77879
I0523 14:06:07.971464  1883 solver.cpp:253]     Train net output #0: loss = 1.77879 (* 1 = 1.77879 loss)
I0523 14:06:07.971479  1883 sgd_solver.cpp:106] Iteration 5000, lr = 0.0015
I0523 14:06:17.051764  1883 solver.cpp:237] Iteration 5250, loss = 1.81972
I0523 14:06:17.051914  1883 solver.cpp:253]     Train net output #0: loss = 1.81972 (* 1 = 1.81972 loss)
I0523 14:06:17.051928  1883 sgd_solver.cpp:106] Iteration 5250, lr = 0.0015
I0523 14:06:26.137363  1883 solver.cpp:237] Iteration 5500, loss = 1.71086
I0523 14:06:26.137398  1883 solver.cpp:253]     Train net output #0: loss = 1.71086 (* 1 = 1.71086 loss)
I0523 14:06:26.137411  1883 sgd_solver.cpp:106] Iteration 5500, lr = 0.0015
I0523 14:06:35.213052  1883 solver.cpp:237] Iteration 5750, loss = 1.61041
I0523 14:06:35.213086  1883 solver.cpp:253]     Train net output #0: loss = 1.61041 (* 1 = 1.61041 loss)
I0523 14:06:35.213104  1883 sgd_solver.cpp:106] Iteration 5750, lr = 0.0015
I0523 14:06:44.293213  1883 solver.cpp:237] Iteration 6000, loss = 1.62265
I0523 14:06:44.293257  1883 solver.cpp:253]     Train net output #0: loss = 1.62265 (* 1 = 1.62265 loss)
I0523 14:06:44.293273  1883 sgd_solver.cpp:106] Iteration 6000, lr = 0.0015
I0523 14:06:53.378206  1883 solver.cpp:237] Iteration 6250, loss = 1.54786
I0523 14:06:53.378341  1883 solver.cpp:253]     Train net output #0: loss = 1.54786 (* 1 = 1.54786 loss)
I0523 14:06:53.378355  1883 sgd_solver.cpp:106] Iteration 6250, lr = 0.0015
I0523 14:07:02.461153  1883 solver.cpp:237] Iteration 6500, loss = 1.50442
I0523 14:07:02.461187  1883 solver.cpp:253]     Train net output #0: loss = 1.50442 (* 1 = 1.50442 loss)
I0523 14:07:02.461201  1883 sgd_solver.cpp:106] Iteration 6500, lr = 0.0015
I0523 14:07:33.795255  1883 solver.cpp:237] Iteration 6750, loss = 1.53992
I0523 14:07:33.795414  1883 solver.cpp:253]     Train net output #0: loss = 1.53992 (* 1 = 1.53992 loss)
I0523 14:07:33.795429  1883 sgd_solver.cpp:106] Iteration 6750, lr = 0.0015
I0523 14:07:42.870312  1883 solver.cpp:237] Iteration 7000, loss = 1.44422
I0523 14:07:42.870345  1883 solver.cpp:253]     Train net output #0: loss = 1.44422 (* 1 = 1.44422 loss)
I0523 14:07:42.870363  1883 sgd_solver.cpp:106] Iteration 7000, lr = 0.0015
I0523 14:07:51.948238  1883 solver.cpp:237] Iteration 7250, loss = 1.59522
I0523 14:07:51.948273  1883 solver.cpp:253]     Train net output #0: loss = 1.59522 (* 1 = 1.59522 loss)
I0523 14:07:51.948292  1883 sgd_solver.cpp:106] Iteration 7250, lr = 0.0015
I0523 14:08:00.992573  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_7500.caffemodel
I0523 14:08:01.059669  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_7500.solverstate
I0523 14:08:01.099282  1883 solver.cpp:237] Iteration 7500, loss = 1.45817
I0523 14:08:01.099328  1883 solver.cpp:253]     Train net output #0: loss = 1.45817 (* 1 = 1.45817 loss)
I0523 14:08:01.099349  1883 sgd_solver.cpp:106] Iteration 7500, lr = 0.0015
I0523 14:08:10.178305  1883 solver.cpp:237] Iteration 7750, loss = 1.46906
I0523 14:08:10.178460  1883 solver.cpp:253]     Train net output #0: loss = 1.46906 (* 1 = 1.46906 loss)
I0523 14:08:10.178474  1883 sgd_solver.cpp:106] Iteration 7750, lr = 0.0015
I0523 14:08:19.254801  1883 solver.cpp:237] Iteration 8000, loss = 1.69664
I0523 14:08:19.254834  1883 solver.cpp:253]     Train net output #0: loss = 1.69664 (* 1 = 1.69664 loss)
I0523 14:08:19.254851  1883 sgd_solver.cpp:106] Iteration 8000, lr = 0.0015
I0523 14:08:28.338932  1883 solver.cpp:237] Iteration 8250, loss = 1.40608
I0523 14:08:28.338966  1883 solver.cpp:253]     Train net output #0: loss = 1.40608 (* 1 = 1.40608 loss)
I0523 14:08:28.338992  1883 sgd_solver.cpp:106] Iteration 8250, lr = 0.0015
I0523 14:08:59.674955  1883 solver.cpp:237] Iteration 8500, loss = 1.42885
I0523 14:08:59.675119  1883 solver.cpp:253]     Train net output #0: loss = 1.42885 (* 1 = 1.42885 loss)
I0523 14:08:59.675135  1883 sgd_solver.cpp:106] Iteration 8500, lr = 0.0015
I0523 14:09:08.755735  1883 solver.cpp:237] Iteration 8750, loss = 1.52595
I0523 14:09:08.755769  1883 solver.cpp:253]     Train net output #0: loss = 1.52595 (* 1 = 1.52595 loss)
I0523 14:09:08.755787  1883 sgd_solver.cpp:106] Iteration 8750, lr = 0.0015
I0523 14:09:17.844424  1883 solver.cpp:237] Iteration 9000, loss = 1.62915
I0523 14:09:17.844468  1883 solver.cpp:253]     Train net output #0: loss = 1.62915 (* 1 = 1.62915 loss)
I0523 14:09:17.844485  1883 sgd_solver.cpp:106] Iteration 9000, lr = 0.0015
I0523 14:09:26.927330  1883 solver.cpp:237] Iteration 9250, loss = 1.4208
I0523 14:09:26.927366  1883 solver.cpp:253]     Train net output #0: loss = 1.4208 (* 1 = 1.4208 loss)
I0523 14:09:26.927381  1883 sgd_solver.cpp:106] Iteration 9250, lr = 0.0015
I0523 14:09:36.003111  1883 solver.cpp:237] Iteration 9500, loss = 1.62147
I0523 14:09:36.003260  1883 solver.cpp:253]     Train net output #0: loss = 1.62147 (* 1 = 1.62147 loss)
I0523 14:09:36.003274  1883 sgd_solver.cpp:106] Iteration 9500, lr = 0.0015
I0523 14:09:45.079010  1883 solver.cpp:237] Iteration 9750, loss = 1.14026
I0523 14:09:45.079043  1883 solver.cpp:253]     Train net output #0: loss = 1.14026 (* 1 = 1.14026 loss)
I0523 14:09:45.079057  1883 sgd_solver.cpp:106] Iteration 9750, lr = 0.0015
I0523 14:09:54.120995  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_10000.caffemodel
I0523 14:09:54.186580  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_10000.solverstate
I0523 14:09:54.215545  1883 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 14:11:02.383754  1883 solver.cpp:409]     Test net output #0: accuracy = 0.774834
I0523 14:11:02.383925  1883 solver.cpp:409]     Test net output #1: loss = 0.739731 (* 1 = 0.739731 loss)
I0523 14:11:24.631366  1883 solver.cpp:237] Iteration 10000, loss = 1.39575
I0523 14:11:24.631419  1883 solver.cpp:253]     Train net output #0: loss = 1.39575 (* 1 = 1.39575 loss)
I0523 14:11:24.631433  1883 sgd_solver.cpp:106] Iteration 10000, lr = 0.0015
I0523 14:11:33.747987  1883 solver.cpp:237] Iteration 10250, loss = 1.47676
I0523 14:11:33.748141  1883 solver.cpp:253]     Train net output #0: loss = 1.47676 (* 1 = 1.47676 loss)
I0523 14:11:33.748154  1883 sgd_solver.cpp:106] Iteration 10250, lr = 0.0015
I0523 14:11:42.864322  1883 solver.cpp:237] Iteration 10500, loss = 1.6717
I0523 14:11:42.864363  1883 solver.cpp:253]     Train net output #0: loss = 1.6717 (* 1 = 1.6717 loss)
I0523 14:11:42.864380  1883 sgd_solver.cpp:106] Iteration 10500, lr = 0.0015
I0523 14:11:51.977715  1883 solver.cpp:237] Iteration 10750, loss = 1.6003
I0523 14:11:51.977748  1883 solver.cpp:253]     Train net output #0: loss = 1.6003 (* 1 = 1.6003 loss)
I0523 14:11:51.977766  1883 sgd_solver.cpp:106] Iteration 10750, lr = 0.0015
I0523 14:12:01.088872  1883 solver.cpp:237] Iteration 11000, loss = 1.53912
I0523 14:12:01.088907  1883 solver.cpp:253]     Train net output #0: loss = 1.53912 (* 1 = 1.53912 loss)
I0523 14:12:01.088923  1883 sgd_solver.cpp:106] Iteration 11000, lr = 0.0015
I0523 14:12:10.204792  1883 solver.cpp:237] Iteration 11250, loss = 1.30785
I0523 14:12:10.204947  1883 solver.cpp:253]     Train net output #0: loss = 1.30785 (* 1 = 1.30785 loss)
I0523 14:12:10.204962  1883 sgd_solver.cpp:106] Iteration 11250, lr = 0.0015
I0523 14:12:19.313410  1883 solver.cpp:237] Iteration 11500, loss = 1.5362
I0523 14:12:19.313443  1883 solver.cpp:253]     Train net output #0: loss = 1.5362 (* 1 = 1.5362 loss)
I0523 14:12:19.313462  1883 sgd_solver.cpp:106] Iteration 11500, lr = 0.0015
I0523 14:12:50.692492  1883 solver.cpp:237] Iteration 11750, loss = 1.27785
I0523 14:12:50.692654  1883 solver.cpp:253]     Train net output #0: loss = 1.27785 (* 1 = 1.27785 loss)
I0523 14:12:50.692670  1883 sgd_solver.cpp:106] Iteration 11750, lr = 0.0015
I0523 14:12:59.806927  1883 solver.cpp:237] Iteration 12000, loss = 1.20284
I0523 14:12:59.806967  1883 solver.cpp:253]     Train net output #0: loss = 1.20284 (* 1 = 1.20284 loss)
I0523 14:12:59.806985  1883 sgd_solver.cpp:106] Iteration 12000, lr = 0.0015
I0523 14:13:08.924669  1883 solver.cpp:237] Iteration 12250, loss = 1.44393
I0523 14:13:08.924705  1883 solver.cpp:253]     Train net output #0: loss = 1.44393 (* 1 = 1.44393 loss)
I0523 14:13:08.924721  1883 sgd_solver.cpp:106] Iteration 12250, lr = 0.0015
I0523 14:13:18.005950  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_12500.caffemodel
I0523 14:13:18.070545  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_12500.solverstate
I0523 14:13:18.109613  1883 solver.cpp:237] Iteration 12500, loss = 1.42814
I0523 14:13:18.109664  1883 solver.cpp:253]     Train net output #0: loss = 1.42814 (* 1 = 1.42814 loss)
I0523 14:13:18.109678  1883 sgd_solver.cpp:106] Iteration 12500, lr = 0.0015
I0523 14:13:27.223160  1883 solver.cpp:237] Iteration 12750, loss = 1.34985
I0523 14:13:27.223320  1883 solver.cpp:253]     Train net output #0: loss = 1.34985 (* 1 = 1.34985 loss)
I0523 14:13:27.223333  1883 sgd_solver.cpp:106] Iteration 12750, lr = 0.0015
I0523 14:13:36.339702  1883 solver.cpp:237] Iteration 13000, loss = 0.968577
I0523 14:13:36.339737  1883 solver.cpp:253]     Train net output #0: loss = 0.968577 (* 1 = 0.968577 loss)
I0523 14:13:36.339753  1883 sgd_solver.cpp:106] Iteration 13000, lr = 0.0015
I0523 14:13:45.458554  1883 solver.cpp:237] Iteration 13250, loss = 1.4852
I0523 14:13:45.458598  1883 solver.cpp:253]     Train net output #0: loss = 1.4852 (* 1 = 1.4852 loss)
I0523 14:13:45.458613  1883 sgd_solver.cpp:106] Iteration 13250, lr = 0.0015
I0523 14:14:16.828336  1883 solver.cpp:237] Iteration 13500, loss = 1.21008
I0523 14:14:16.828511  1883 solver.cpp:253]     Train net output #0: loss = 1.21008 (* 1 = 1.21008 loss)
I0523 14:14:16.828526  1883 sgd_solver.cpp:106] Iteration 13500, lr = 0.0015
I0523 14:14:25.942363  1883 solver.cpp:237] Iteration 13750, loss = 1.15363
I0523 14:14:25.942396  1883 solver.cpp:253]     Train net output #0: loss = 1.15363 (* 1 = 1.15363 loss)
I0523 14:14:25.942415  1883 sgd_solver.cpp:106] Iteration 13750, lr = 0.0015
I0523 14:14:35.065186  1883 solver.cpp:237] Iteration 14000, loss = 1.04821
I0523 14:14:35.065222  1883 solver.cpp:253]     Train net output #0: loss = 1.04821 (* 1 = 1.04821 loss)
I0523 14:14:35.065237  1883 sgd_solver.cpp:106] Iteration 14000, lr = 0.0015
I0523 14:14:44.182703  1883 solver.cpp:237] Iteration 14250, loss = 1.2145
I0523 14:14:44.182741  1883 solver.cpp:253]     Train net output #0: loss = 1.2145 (* 1 = 1.2145 loss)
I0523 14:14:44.182763  1883 sgd_solver.cpp:106] Iteration 14250, lr = 0.0015
I0523 14:14:53.294576  1883 solver.cpp:237] Iteration 14500, loss = 1.61136
I0523 14:14:53.294718  1883 solver.cpp:253]     Train net output #0: loss = 1.61136 (* 1 = 1.61136 loss)
I0523 14:14:53.294730  1883 sgd_solver.cpp:106] Iteration 14500, lr = 0.0015
I0523 14:15:02.410070  1883 solver.cpp:237] Iteration 14750, loss = 1.09687
I0523 14:15:02.410116  1883 solver.cpp:253]     Train net output #0: loss = 1.09687 (* 1 = 1.09687 loss)
I0523 14:15:02.410133  1883 sgd_solver.cpp:106] Iteration 14750, lr = 0.0015
I0523 14:15:11.499574  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_15000.caffemodel
I0523 14:15:11.563791  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_15000.solverstate
I0523 14:15:11.589553  1883 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 14:15:58.602460  1883 solver.cpp:409]     Test net output #0: accuracy = 0.804815
I0523 14:15:58.602620  1883 solver.cpp:409]     Test net output #1: loss = 0.634802 (* 1 = 0.634802 loss)
I0523 14:16:20.798960  1883 solver.cpp:237] Iteration 15000, loss = 1.42805
I0523 14:16:20.799013  1883 solver.cpp:253]     Train net output #0: loss = 1.42805 (* 1 = 1.42805 loss)
I0523 14:16:20.799028  1883 sgd_solver.cpp:106] Iteration 15000, lr = 0.0015
I0523 14:16:29.835530  1883 solver.cpp:237] Iteration 15250, loss = 1.22441
I0523 14:16:29.835688  1883 solver.cpp:253]     Train net output #0: loss = 1.22441 (* 1 = 1.22441 loss)
I0523 14:16:29.835702  1883 sgd_solver.cpp:106] Iteration 15250, lr = 0.0015
I0523 14:16:38.872738  1883 solver.cpp:237] Iteration 15500, loss = 1.1572
I0523 14:16:38.872772  1883 solver.cpp:253]     Train net output #0: loss = 1.1572 (* 1 = 1.1572 loss)
I0523 14:16:38.872789  1883 sgd_solver.cpp:106] Iteration 15500, lr = 0.0015
I0523 14:16:47.899893  1883 solver.cpp:237] Iteration 15750, loss = 1.55126
I0523 14:16:47.899933  1883 solver.cpp:253]     Train net output #0: loss = 1.55126 (* 1 = 1.55126 loss)
I0523 14:16:47.899947  1883 sgd_solver.cpp:106] Iteration 15750, lr = 0.0015
I0523 14:16:56.925091  1883 solver.cpp:237] Iteration 16000, loss = 1.58086
I0523 14:16:56.925125  1883 solver.cpp:253]     Train net output #0: loss = 1.58086 (* 1 = 1.58086 loss)
I0523 14:16:56.925142  1883 sgd_solver.cpp:106] Iteration 16000, lr = 0.0015
I0523 14:17:05.966678  1883 solver.cpp:237] Iteration 16250, loss = 1.6992
I0523 14:17:05.966827  1883 solver.cpp:253]     Train net output #0: loss = 1.6992 (* 1 = 1.6992 loss)
I0523 14:17:05.966841  1883 sgd_solver.cpp:106] Iteration 16250, lr = 0.0015
I0523 14:17:15.001744  1883 solver.cpp:237] Iteration 16500, loss = 1.18931
I0523 14:17:15.001777  1883 solver.cpp:253]     Train net output #0: loss = 1.18931 (* 1 = 1.18931 loss)
I0523 14:17:15.001796  1883 sgd_solver.cpp:106] Iteration 16500, lr = 0.0015
I0523 14:17:46.306867  1883 solver.cpp:237] Iteration 16750, loss = 1.42434
I0523 14:17:46.307046  1883 solver.cpp:253]     Train net output #0: loss = 1.42434 (* 1 = 1.42434 loss)
I0523 14:17:46.307060  1883 sgd_solver.cpp:106] Iteration 16750, lr = 0.0015
I0523 14:17:55.346213  1883 solver.cpp:237] Iteration 17000, loss = 1.68004
I0523 14:17:55.346248  1883 solver.cpp:253]     Train net output #0: loss = 1.68004 (* 1 = 1.68004 loss)
I0523 14:17:55.346262  1883 sgd_solver.cpp:106] Iteration 17000, lr = 0.0015
I0523 14:18:04.383399  1883 solver.cpp:237] Iteration 17250, loss = 1.22124
I0523 14:18:04.383445  1883 solver.cpp:253]     Train net output #0: loss = 1.22124 (* 1 = 1.22124 loss)
I0523 14:18:04.383460  1883 sgd_solver.cpp:106] Iteration 17250, lr = 0.0015
I0523 14:18:13.383658  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_17500.caffemodel
I0523 14:18:13.446403  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_17500.solverstate
I0523 14:18:13.484230  1883 solver.cpp:237] Iteration 17500, loss = 1.06262
I0523 14:18:13.484277  1883 solver.cpp:253]     Train net output #0: loss = 1.06262 (* 1 = 1.06262 loss)
I0523 14:18:13.484293  1883 sgd_solver.cpp:106] Iteration 17500, lr = 0.0015
I0523 14:18:22.522629  1883 solver.cpp:237] Iteration 17750, loss = 1.45384
I0523 14:18:22.522784  1883 solver.cpp:253]     Train net output #0: loss = 1.45384 (* 1 = 1.45384 loss)
I0523 14:18:22.522799  1883 sgd_solver.cpp:106] Iteration 17750, lr = 0.0015
I0523 14:18:31.553392  1883 solver.cpp:237] Iteration 18000, loss = 1.3295
I0523 14:18:31.553427  1883 solver.cpp:253]     Train net output #0: loss = 1.3295 (* 1 = 1.3295 loss)
I0523 14:18:31.553444  1883 sgd_solver.cpp:106] Iteration 18000, lr = 0.0015
I0523 14:18:40.591486  1883 solver.cpp:237] Iteration 18250, loss = 1.27052
I0523 14:18:40.591521  1883 solver.cpp:253]     Train net output #0: loss = 1.27052 (* 1 = 1.27052 loss)
I0523 14:18:40.591538  1883 sgd_solver.cpp:106] Iteration 18250, lr = 0.0015
I0523 14:19:11.833942  1883 solver.cpp:237] Iteration 18500, loss = 1.21867
I0523 14:19:11.834111  1883 solver.cpp:253]     Train net output #0: loss = 1.21867 (* 1 = 1.21867 loss)
I0523 14:19:11.834126  1883 sgd_solver.cpp:106] Iteration 18500, lr = 0.0015
I0523 14:19:20.874119  1883 solver.cpp:237] Iteration 18750, loss = 1.40449
I0523 14:19:20.874153  1883 solver.cpp:253]     Train net output #0: loss = 1.40449 (* 1 = 1.40449 loss)
I0523 14:19:20.874172  1883 sgd_solver.cpp:106] Iteration 18750, lr = 0.0015
I0523 14:19:29.907150  1883 solver.cpp:237] Iteration 19000, loss = 1.3405
I0523 14:19:29.907183  1883 solver.cpp:253]     Train net output #0: loss = 1.3405 (* 1 = 1.3405 loss)
I0523 14:19:29.907201  1883 sgd_solver.cpp:106] Iteration 19000, lr = 0.0015
I0523 14:19:38.938786  1883 solver.cpp:237] Iteration 19250, loss = 1.42653
I0523 14:19:38.938828  1883 solver.cpp:253]     Train net output #0: loss = 1.42653 (* 1 = 1.42653 loss)
I0523 14:19:38.938848  1883 sgd_solver.cpp:106] Iteration 19250, lr = 0.0015
I0523 14:19:47.971310  1883 solver.cpp:237] Iteration 19500, loss = 1.34211
I0523 14:19:47.971451  1883 solver.cpp:253]     Train net output #0: loss = 1.34211 (* 1 = 1.34211 loss)
I0523 14:19:47.971464  1883 sgd_solver.cpp:106] Iteration 19500, lr = 0.0015
I0523 14:19:57.013623  1883 solver.cpp:237] Iteration 19750, loss = 1.34515
I0523 14:19:57.013658  1883 solver.cpp:253]     Train net output #0: loss = 1.34515 (* 1 = 1.34515 loss)
I0523 14:19:57.013674  1883 sgd_solver.cpp:106] Iteration 19750, lr = 0.0015
I0523 14:20:06.013335  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_20000.caffemodel
I0523 14:20:06.076104  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_20000.solverstate
I0523 14:20:06.102461  1883 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 14:21:14.517664  1883 solver.cpp:409]     Test net output #0: accuracy = 0.831916
I0523 14:21:14.517839  1883 solver.cpp:409]     Test net output #1: loss = 0.572701 (* 1 = 0.572701 loss)
I0523 14:21:36.685233  1883 solver.cpp:237] Iteration 20000, loss = 1.19643
I0523 14:21:36.685284  1883 solver.cpp:253]     Train net output #0: loss = 1.19643 (* 1 = 1.19643 loss)
I0523 14:21:36.685302  1883 sgd_solver.cpp:106] Iteration 20000, lr = 0.0015
I0523 14:21:45.743131  1883 solver.cpp:237] Iteration 20250, loss = 1.59187
I0523 14:21:45.743297  1883 solver.cpp:253]     Train net output #0: loss = 1.59187 (* 1 = 1.59187 loss)
I0523 14:21:45.743311  1883 sgd_solver.cpp:106] Iteration 20250, lr = 0.0015
I0523 14:21:54.808784  1883 solver.cpp:237] Iteration 20500, loss = 1.25234
I0523 14:21:54.808818  1883 solver.cpp:253]     Train net output #0: loss = 1.25234 (* 1 = 1.25234 loss)
I0523 14:21:54.808836  1883 sgd_solver.cpp:106] Iteration 20500, lr = 0.0015
I0523 14:22:03.874312  1883 solver.cpp:237] Iteration 20750, loss = 1.24797
I0523 14:22:03.874347  1883 solver.cpp:253]     Train net output #0: loss = 1.24797 (* 1 = 1.24797 loss)
I0523 14:22:03.874361  1883 sgd_solver.cpp:106] Iteration 20750, lr = 0.0015
I0523 14:22:12.941227  1883 solver.cpp:237] Iteration 21000, loss = 1.16292
I0523 14:22:12.941272  1883 solver.cpp:253]     Train net output #0: loss = 1.16292 (* 1 = 1.16292 loss)
I0523 14:22:12.941287  1883 sgd_solver.cpp:106] Iteration 21000, lr = 0.0015
I0523 14:22:22.000975  1883 solver.cpp:237] Iteration 21250, loss = 1.25147
I0523 14:22:22.001137  1883 solver.cpp:253]     Train net output #0: loss = 1.25147 (* 1 = 1.25147 loss)
I0523 14:22:22.001150  1883 sgd_solver.cpp:106] Iteration 21250, lr = 0.0015
I0523 14:22:31.063853  1883 solver.cpp:237] Iteration 21500, loss = 1.0738
I0523 14:22:31.063894  1883 solver.cpp:253]     Train net output #0: loss = 1.0738 (* 1 = 1.0738 loss)
I0523 14:22:31.063906  1883 sgd_solver.cpp:106] Iteration 21500, lr = 0.0015
I0523 14:23:02.342473  1883 solver.cpp:237] Iteration 21750, loss = 1.47412
I0523 14:23:02.342641  1883 solver.cpp:253]     Train net output #0: loss = 1.47412 (* 1 = 1.47412 loss)
I0523 14:23:02.342656  1883 sgd_solver.cpp:106] Iteration 21750, lr = 0.0015
I0523 14:23:11.402549  1883 solver.cpp:237] Iteration 22000, loss = 1.35695
I0523 14:23:11.402582  1883 solver.cpp:253]     Train net output #0: loss = 1.35695 (* 1 = 1.35695 loss)
I0523 14:23:11.402601  1883 sgd_solver.cpp:106] Iteration 22000, lr = 0.0015
I0523 14:23:20.450636  1883 solver.cpp:237] Iteration 22250, loss = 1.38538
I0523 14:23:20.450686  1883 solver.cpp:253]     Train net output #0: loss = 1.38538 (* 1 = 1.38538 loss)
I0523 14:23:20.450701  1883 sgd_solver.cpp:106] Iteration 22250, lr = 0.0015
I0523 14:23:29.480870  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_22500.caffemodel
I0523 14:23:29.546279  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_22500.solverstate
I0523 14:23:29.585338  1883 solver.cpp:237] Iteration 22500, loss = 1.43202
I0523 14:23:29.585388  1883 solver.cpp:253]     Train net output #0: loss = 1.43202 (* 1 = 1.43202 loss)
I0523 14:23:29.585402  1883 sgd_solver.cpp:106] Iteration 22500, lr = 0.0015
I0523 14:23:38.652856  1883 solver.cpp:237] Iteration 22750, loss = 1.09283
I0523 14:23:38.653007  1883 solver.cpp:253]     Train net output #0: loss = 1.09283 (* 1 = 1.09283 loss)
I0523 14:23:38.653019  1883 sgd_solver.cpp:106] Iteration 22750, lr = 0.0015
I0523 14:23:47.707573  1883 solver.cpp:237] Iteration 23000, loss = 1.53111
I0523 14:23:47.707623  1883 solver.cpp:253]     Train net output #0: loss = 1.53111 (* 1 = 1.53111 loss)
I0523 14:23:47.707639  1883 sgd_solver.cpp:106] Iteration 23000, lr = 0.0015
I0523 14:23:56.774911  1883 solver.cpp:237] Iteration 23250, loss = 1.42241
I0523 14:23:56.774945  1883 solver.cpp:253]     Train net output #0: loss = 1.42241 (* 1 = 1.42241 loss)
I0523 14:23:56.774962  1883 sgd_solver.cpp:106] Iteration 23250, lr = 0.0015
I0523 14:24:28.072724  1883 solver.cpp:237] Iteration 23500, loss = 1.13655
I0523 14:24:28.072907  1883 solver.cpp:253]     Train net output #0: loss = 1.13655 (* 1 = 1.13655 loss)
I0523 14:24:28.072923  1883 sgd_solver.cpp:106] Iteration 23500, lr = 0.0015
I0523 14:24:37.131327  1883 solver.cpp:237] Iteration 23750, loss = 1.24352
I0523 14:24:37.131374  1883 solver.cpp:253]     Train net output #0: loss = 1.24352 (* 1 = 1.24352 loss)
I0523 14:24:37.131388  1883 sgd_solver.cpp:106] Iteration 23750, lr = 0.0015
I0523 14:24:46.178483  1883 solver.cpp:237] Iteration 24000, loss = 1.17761
I0523 14:24:46.178517  1883 solver.cpp:253]     Train net output #0: loss = 1.17761 (* 1 = 1.17761 loss)
I0523 14:24:46.178535  1883 sgd_solver.cpp:106] Iteration 24000, lr = 0.0015
I0523 14:24:55.234582  1883 solver.cpp:237] Iteration 24250, loss = 1.46473
I0523 14:24:55.234618  1883 solver.cpp:253]     Train net output #0: loss = 1.46473 (* 1 = 1.46473 loss)
I0523 14:24:55.234634  1883 sgd_solver.cpp:106] Iteration 24250, lr = 0.0015
I0523 14:25:04.301201  1883 solver.cpp:237] Iteration 24500, loss = 1.32243
I0523 14:25:04.301363  1883 solver.cpp:253]     Train net output #0: loss = 1.32243 (* 1 = 1.32243 loss)
I0523 14:25:04.301376  1883 sgd_solver.cpp:106] Iteration 24500, lr = 0.0015
I0523 14:25:13.363126  1883 solver.cpp:237] Iteration 24750, loss = 1.37569
I0523 14:25:13.363160  1883 solver.cpp:253]     Train net output #0: loss = 1.37569 (* 1 = 1.37569 loss)
I0523 14:25:13.363178  1883 sgd_solver.cpp:106] Iteration 24750, lr = 0.0015
I0523 14:25:22.385655  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_25000.caffemodel
I0523 14:25:22.450471  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_25000.solverstate
I0523 14:25:22.480710  1883 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 14:26:09.812409  1883 solver.cpp:409]     Test net output #0: accuracy = 0.837602
I0523 14:26:09.812575  1883 solver.cpp:409]     Test net output #1: loss = 0.51101 (* 1 = 0.51101 loss)
I0523 14:26:30.698627  1883 solver.cpp:237] Iteration 25000, loss = 1.23933
I0523 14:26:30.698681  1883 solver.cpp:253]     Train net output #0: loss = 1.23933 (* 1 = 1.23933 loss)
I0523 14:26:30.698698  1883 sgd_solver.cpp:106] Iteration 25000, lr = 0.0015
I0523 14:26:39.714869  1883 solver.cpp:237] Iteration 25250, loss = 0.98519
I0523 14:26:39.714905  1883 solver.cpp:253]     Train net output #0: loss = 0.98519 (* 1 = 0.98519 loss)
I0523 14:26:39.714921  1883 sgd_solver.cpp:106] Iteration 25250, lr = 0.0015
I0523 14:26:48.732939  1883 solver.cpp:237] Iteration 25500, loss = 1.31109
I0523 14:26:48.733100  1883 solver.cpp:253]     Train net output #0: loss = 1.31109 (* 1 = 1.31109 loss)
I0523 14:26:48.733114  1883 sgd_solver.cpp:106] Iteration 25500, lr = 0.0015
I0523 14:26:57.739394  1883 solver.cpp:237] Iteration 25750, loss = 1.31575
I0523 14:26:57.739429  1883 solver.cpp:253]     Train net output #0: loss = 1.31575 (* 1 = 1.31575 loss)
I0523 14:26:57.739446  1883 sgd_solver.cpp:106] Iteration 25750, lr = 0.0015
I0523 14:27:06.753906  1883 solver.cpp:237] Iteration 26000, loss = 1.47221
I0523 14:27:06.753952  1883 solver.cpp:253]     Train net output #0: loss = 1.47221 (* 1 = 1.47221 loss)
I0523 14:27:06.753968  1883 sgd_solver.cpp:106] Iteration 26000, lr = 0.0015
I0523 14:27:15.766772  1883 solver.cpp:237] Iteration 26250, loss = 1.19243
I0523 14:27:15.766808  1883 solver.cpp:253]     Train net output #0: loss = 1.19243 (* 1 = 1.19243 loss)
I0523 14:27:15.766824  1883 sgd_solver.cpp:106] Iteration 26250, lr = 0.0015
I0523 14:27:24.766378  1883 solver.cpp:237] Iteration 26500, loss = 1.29167
I0523 14:27:24.766536  1883 solver.cpp:253]     Train net output #0: loss = 1.29167 (* 1 = 1.29167 loss)
I0523 14:27:24.766549  1883 sgd_solver.cpp:106] Iteration 26500, lr = 0.0015
I0523 14:27:54.686560  1883 solver.cpp:237] Iteration 26750, loss = 1.49755
I0523 14:27:54.686610  1883 solver.cpp:253]     Train net output #0: loss = 1.49755 (* 1 = 1.49755 loss)
I0523 14:27:54.686626  1883 sgd_solver.cpp:106] Iteration 26750, lr = 0.0015
I0523 14:28:03.702350  1883 solver.cpp:237] Iteration 27000, loss = 1.00744
I0523 14:28:03.702503  1883 solver.cpp:253]     Train net output #0: loss = 1.00744 (* 1 = 1.00744 loss)
I0523 14:28:03.702517  1883 sgd_solver.cpp:106] Iteration 27000, lr = 0.0015
I0523 14:28:12.715467  1883 solver.cpp:237] Iteration 27250, loss = 1.75197
I0523 14:28:12.715502  1883 solver.cpp:253]     Train net output #0: loss = 1.75197 (* 1 = 1.75197 loss)
I0523 14:28:12.715519  1883 sgd_solver.cpp:106] Iteration 27250, lr = 0.0015
I0523 14:28:21.688447  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_27500.caffemodel
I0523 14:28:21.751098  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_27500.solverstate
I0523 14:28:21.789022  1883 solver.cpp:237] Iteration 27500, loss = 0.984769
I0523 14:28:21.789067  1883 solver.cpp:253]     Train net output #0: loss = 0.984769 (* 1 = 0.984769 loss)
I0523 14:28:21.789083  1883 sgd_solver.cpp:106] Iteration 27500, lr = 0.0015
I0523 14:28:30.807296  1883 solver.cpp:237] Iteration 27750, loss = 1.33969
I0523 14:28:30.807332  1883 solver.cpp:253]     Train net output #0: loss = 1.33969 (* 1 = 1.33969 loss)
I0523 14:28:30.807348  1883 sgd_solver.cpp:106] Iteration 27750, lr = 0.0015
I0523 14:28:39.817627  1883 solver.cpp:237] Iteration 28000, loss = 1.24661
I0523 14:28:39.817780  1883 solver.cpp:253]     Train net output #0: loss = 1.24661 (* 1 = 1.24661 loss)
I0523 14:28:39.817793  1883 sgd_solver.cpp:106] Iteration 28000, lr = 0.0015
I0523 14:28:48.821298  1883 solver.cpp:237] Iteration 28250, loss = 1.18118
I0523 14:28:48.821344  1883 solver.cpp:253]     Train net output #0: loss = 1.18118 (* 1 = 1.18118 loss)
I0523 14:28:48.821362  1883 sgd_solver.cpp:106] Iteration 28250, lr = 0.0015
I0523 14:29:18.738270  1883 solver.cpp:237] Iteration 28500, loss = 1.43437
I0523 14:29:18.738445  1883 solver.cpp:253]     Train net output #0: loss = 1.43437 (* 1 = 1.43437 loss)
I0523 14:29:18.738458  1883 sgd_solver.cpp:106] Iteration 28500, lr = 0.0015
I0523 14:29:27.747215  1883 solver.cpp:237] Iteration 28750, loss = 1.13807
I0523 14:29:27.747249  1883 solver.cpp:253]     Train net output #0: loss = 1.13807 (* 1 = 1.13807 loss)
I0523 14:29:27.747267  1883 sgd_solver.cpp:106] Iteration 28750, lr = 0.0015
I0523 14:29:36.756338  1883 solver.cpp:237] Iteration 29000, loss = 1.24787
I0523 14:29:36.756387  1883 solver.cpp:253]     Train net output #0: loss = 1.24787 (* 1 = 1.24787 loss)
I0523 14:29:36.756403  1883 sgd_solver.cpp:106] Iteration 29000, lr = 0.0015
I0523 14:29:45.757604  1883 solver.cpp:237] Iteration 29250, loss = 1.25257
I0523 14:29:45.757639  1883 solver.cpp:253]     Train net output #0: loss = 1.25257 (* 1 = 1.25257 loss)
I0523 14:29:45.757657  1883 sgd_solver.cpp:106] Iteration 29250, lr = 0.0015
I0523 14:29:54.773140  1883 solver.cpp:237] Iteration 29500, loss = 1.24047
I0523 14:29:54.773286  1883 solver.cpp:253]     Train net output #0: loss = 1.24047 (* 1 = 1.24047 loss)
I0523 14:29:54.773300  1883 sgd_solver.cpp:106] Iteration 29500, lr = 0.0015
I0523 14:30:03.783102  1883 solver.cpp:237] Iteration 29750, loss = 1.16507
I0523 14:30:03.783149  1883 solver.cpp:253]     Train net output #0: loss = 1.16507 (* 1 = 1.16507 loss)
I0523 14:30:03.783165  1883 sgd_solver.cpp:106] Iteration 29750, lr = 0.0015
I0523 14:30:12.767854  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_30000.caffemodel
I0523 14:30:12.830590  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_30000.solverstate
I0523 14:30:12.856967  1883 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 14:31:20.950316  1883 solver.cpp:409]     Test net output #0: accuracy = 0.84694
I0523 14:31:20.950495  1883 solver.cpp:409]     Test net output #1: loss = 0.474405 (* 1 = 0.474405 loss)
I0523 14:31:41.862233  1883 solver.cpp:237] Iteration 30000, loss = 1.0101
I0523 14:31:41.862284  1883 solver.cpp:253]     Train net output #0: loss = 1.0101 (* 1 = 1.0101 loss)
I0523 14:31:41.862301  1883 sgd_solver.cpp:106] Iteration 30000, lr = 0.0015
I0523 14:31:50.967933  1883 solver.cpp:237] Iteration 30250, loss = 1.27319
I0523 14:31:50.968089  1883 solver.cpp:253]     Train net output #0: loss = 1.27319 (* 1 = 1.27319 loss)
I0523 14:31:50.968103  1883 sgd_solver.cpp:106] Iteration 30250, lr = 0.0015
I0523 14:32:00.079494  1883 solver.cpp:237] Iteration 30500, loss = 1.05026
I0523 14:32:00.079529  1883 solver.cpp:253]     Train net output #0: loss = 1.05026 (* 1 = 1.05026 loss)
I0523 14:32:00.079546  1883 sgd_solver.cpp:106] Iteration 30500, lr = 0.0015
I0523 14:32:09.184444  1883 solver.cpp:237] Iteration 30750, loss = 1.37597
I0523 14:32:09.184484  1883 solver.cpp:253]     Train net output #0: loss = 1.37597 (* 1 = 1.37597 loss)
I0523 14:32:09.184504  1883 sgd_solver.cpp:106] Iteration 30750, lr = 0.0015
I0523 14:32:18.305502  1883 solver.cpp:237] Iteration 31000, loss = 1.16088
I0523 14:32:18.305537  1883 solver.cpp:253]     Train net output #0: loss = 1.16088 (* 1 = 1.16088 loss)
I0523 14:32:18.305554  1883 sgd_solver.cpp:106] Iteration 31000, lr = 0.0015
I0523 14:32:27.407539  1883 solver.cpp:237] Iteration 31250, loss = 1.61667
I0523 14:32:27.407691  1883 solver.cpp:253]     Train net output #0: loss = 1.61667 (* 1 = 1.61667 loss)
I0523 14:32:27.407706  1883 sgd_solver.cpp:106] Iteration 31250, lr = 0.0015
I0523 14:32:36.508394  1883 solver.cpp:237] Iteration 31500, loss = 1.12248
I0523 14:32:36.508431  1883 solver.cpp:253]     Train net output #0: loss = 1.12248 (* 1 = 1.12248 loss)
I0523 14:32:36.508450  1883 sgd_solver.cpp:106] Iteration 31500, lr = 0.0015
I0523 14:33:06.523468  1883 solver.cpp:237] Iteration 31750, loss = 1.56034
I0523 14:33:06.523633  1883 solver.cpp:253]     Train net output #0: loss = 1.56034 (* 1 = 1.56034 loss)
I0523 14:33:06.523648  1883 sgd_solver.cpp:106] Iteration 31750, lr = 0.0015
I0523 14:33:15.632179  1883 solver.cpp:237] Iteration 32000, loss = 1.07461
I0523 14:33:15.632213  1883 solver.cpp:253]     Train net output #0: loss = 1.07461 (* 1 = 1.07461 loss)
I0523 14:33:15.632231  1883 sgd_solver.cpp:106] Iteration 32000, lr = 0.0015
I0523 14:33:24.734447  1883 solver.cpp:237] Iteration 32250, loss = 1.05695
I0523 14:33:24.734491  1883 solver.cpp:253]     Train net output #0: loss = 1.05695 (* 1 = 1.05695 loss)
I0523 14:33:24.734508  1883 sgd_solver.cpp:106] Iteration 32250, lr = 0.0015
I0523 14:33:33.812842  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_32500.caffemodel
I0523 14:33:33.876052  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_32500.solverstate
I0523 14:33:33.913816  1883 solver.cpp:237] Iteration 32500, loss = 1.10376
I0523 14:33:33.913861  1883 solver.cpp:253]     Train net output #0: loss = 1.10376 (* 1 = 1.10376 loss)
I0523 14:33:33.913878  1883 sgd_solver.cpp:106] Iteration 32500, lr = 0.0015
I0523 14:33:43.020315  1883 solver.cpp:237] Iteration 32750, loss = 1.13421
I0523 14:33:43.020478  1883 solver.cpp:253]     Train net output #0: loss = 1.13421 (* 1 = 1.13421 loss)
I0523 14:33:43.020493  1883 sgd_solver.cpp:106] Iteration 32750, lr = 0.0015
I0523 14:33:52.125145  1883 solver.cpp:237] Iteration 33000, loss = 1.48532
I0523 14:33:52.125188  1883 solver.cpp:253]     Train net output #0: loss = 1.48532 (* 1 = 1.48532 loss)
I0523 14:33:52.125206  1883 sgd_solver.cpp:106] Iteration 33000, lr = 0.0015
I0523 14:34:01.230268  1883 solver.cpp:237] Iteration 33250, loss = 1.20886
I0523 14:34:01.230303  1883 solver.cpp:253]     Train net output #0: loss = 1.20886 (* 1 = 1.20886 loss)
I0523 14:34:01.230319  1883 sgd_solver.cpp:106] Iteration 33250, lr = 0.0015
I0523 14:34:31.212451  1883 solver.cpp:237] Iteration 33500, loss = 0.98711
I0523 14:34:31.212627  1883 solver.cpp:253]     Train net output #0: loss = 0.98711 (* 1 = 0.98711 loss)
I0523 14:34:31.212642  1883 sgd_solver.cpp:106] Iteration 33500, lr = 0.0015
I0523 14:34:40.310819  1883 solver.cpp:237] Iteration 33750, loss = 1.15331
I0523 14:34:40.310863  1883 solver.cpp:253]     Train net output #0: loss = 1.15331 (* 1 = 1.15331 loss)
I0523 14:34:40.310883  1883 sgd_solver.cpp:106] Iteration 33750, lr = 0.0015
I0523 14:34:49.414615  1883 solver.cpp:237] Iteration 34000, loss = 1.39591
I0523 14:34:49.414650  1883 solver.cpp:253]     Train net output #0: loss = 1.39591 (* 1 = 1.39591 loss)
I0523 14:34:49.414669  1883 sgd_solver.cpp:106] Iteration 34000, lr = 0.0015
I0523 14:34:58.513170  1883 solver.cpp:237] Iteration 34250, loss = 1.13648
I0523 14:34:58.513205  1883 solver.cpp:253]     Train net output #0: loss = 1.13648 (* 1 = 1.13648 loss)
I0523 14:34:58.513222  1883 sgd_solver.cpp:106] Iteration 34250, lr = 0.0015
I0523 14:35:07.613256  1883 solver.cpp:237] Iteration 34500, loss = 1.31455
I0523 14:35:07.613427  1883 solver.cpp:253]     Train net output #0: loss = 1.31455 (* 1 = 1.31455 loss)
I0523 14:35:07.613440  1883 sgd_solver.cpp:106] Iteration 34500, lr = 0.0015
I0523 14:35:16.723841  1883 solver.cpp:237] Iteration 34750, loss = 1.246
I0523 14:35:16.723875  1883 solver.cpp:253]     Train net output #0: loss = 1.246 (* 1 = 1.246 loss)
I0523 14:35:16.723889  1883 sgd_solver.cpp:106] Iteration 34750, lr = 0.0015
I0523 14:35:25.790853  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_35000.caffemodel
I0523 14:35:25.853258  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_35000.solverstate
I0523 14:35:25.879725  1883 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 14:36:12.862859  1883 solver.cpp:409]     Test net output #0: accuracy = 0.857275
I0523 14:36:12.863029  1883 solver.cpp:409]     Test net output #1: loss = 0.487824 (* 1 = 0.487824 loss)
I0523 14:36:33.766232  1883 solver.cpp:237] Iteration 35000, loss = 1.12167
I0523 14:36:33.766285  1883 solver.cpp:253]     Train net output #0: loss = 1.12167 (* 1 = 1.12167 loss)
I0523 14:36:33.766299  1883 sgd_solver.cpp:106] Iteration 35000, lr = 0.0015
I0523 14:36:42.842247  1883 solver.cpp:237] Iteration 35250, loss = 1.08265
I0523 14:36:42.842286  1883 solver.cpp:253]     Train net output #0: loss = 1.08265 (* 1 = 1.08265 loss)
I0523 14:36:42.842308  1883 sgd_solver.cpp:106] Iteration 35250, lr = 0.0015
I0523 14:36:51.929497  1883 solver.cpp:237] Iteration 35500, loss = 1.29687
I0523 14:36:51.929653  1883 solver.cpp:253]     Train net output #0: loss = 1.29687 (* 1 = 1.29687 loss)
I0523 14:36:51.929667  1883 sgd_solver.cpp:106] Iteration 35500, lr = 0.0015
I0523 14:37:01.006213  1883 solver.cpp:237] Iteration 35750, loss = 1.15453
I0523 14:37:01.006248  1883 solver.cpp:253]     Train net output #0: loss = 1.15453 (* 1 = 1.15453 loss)
I0523 14:37:01.006266  1883 sgd_solver.cpp:106] Iteration 35750, lr = 0.0015
I0523 14:37:10.089834  1883 solver.cpp:237] Iteration 36000, loss = 1.26295
I0523 14:37:10.089880  1883 solver.cpp:253]     Train net output #0: loss = 1.26295 (* 1 = 1.26295 loss)
I0523 14:37:10.089896  1883 sgd_solver.cpp:106] Iteration 36000, lr = 0.0015
I0523 14:37:19.164443  1883 solver.cpp:237] Iteration 36250, loss = 1.15411
I0523 14:37:19.164479  1883 solver.cpp:253]     Train net output #0: loss = 1.15411 (* 1 = 1.15411 loss)
I0523 14:37:19.164494  1883 sgd_solver.cpp:106] Iteration 36250, lr = 0.0015
I0523 14:37:28.236870  1883 solver.cpp:237] Iteration 36500, loss = 1.30478
I0523 14:37:28.237031  1883 solver.cpp:253]     Train net output #0: loss = 1.30478 (* 1 = 1.30478 loss)
I0523 14:37:28.237045  1883 sgd_solver.cpp:106] Iteration 36500, lr = 0.0015
I0523 14:37:58.203802  1883 solver.cpp:237] Iteration 36750, loss = 1.29625
I0523 14:37:58.203852  1883 solver.cpp:253]     Train net output #0: loss = 1.29625 (* 1 = 1.29625 loss)
I0523 14:37:58.203869  1883 sgd_solver.cpp:106] Iteration 36750, lr = 0.0015
I0523 14:38:07.278439  1883 solver.cpp:237] Iteration 37000, loss = 1.12019
I0523 14:38:07.278592  1883 solver.cpp:253]     Train net output #0: loss = 1.12019 (* 1 = 1.12019 loss)
I0523 14:38:07.278606  1883 sgd_solver.cpp:106] Iteration 37000, lr = 0.0015
I0523 14:38:16.357728  1883 solver.cpp:237] Iteration 37250, loss = 1.3566
I0523 14:38:16.357761  1883 solver.cpp:253]     Train net output #0: loss = 1.3566 (* 1 = 1.3566 loss)
I0523 14:38:16.357779  1883 sgd_solver.cpp:106] Iteration 37250, lr = 0.0015
I0523 14:38:25.399040  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_37500.caffemodel
I0523 14:38:25.464071  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_37500.solverstate
I0523 14:38:25.503635  1883 solver.cpp:237] Iteration 37500, loss = 1.15667
I0523 14:38:25.503691  1883 solver.cpp:253]     Train net output #0: loss = 1.15667 (* 1 = 1.15667 loss)
I0523 14:38:25.503705  1883 sgd_solver.cpp:106] Iteration 37500, lr = 0.0015
I0523 14:38:34.587424  1883 solver.cpp:237] Iteration 37750, loss = 1.34935
I0523 14:38:34.587460  1883 solver.cpp:253]     Train net output #0: loss = 1.34935 (* 1 = 1.34935 loss)
I0523 14:38:34.587476  1883 sgd_solver.cpp:106] Iteration 37750, lr = 0.0015
I0523 14:38:43.664213  1883 solver.cpp:237] Iteration 38000, loss = 1.61531
I0523 14:38:43.664368  1883 solver.cpp:253]     Train net output #0: loss = 1.61531 (* 1 = 1.61531 loss)
I0523 14:38:43.664383  1883 sgd_solver.cpp:106] Iteration 38000, lr = 0.0015
I0523 14:38:52.745014  1883 solver.cpp:237] Iteration 38250, loss = 1.25778
I0523 14:38:52.745060  1883 solver.cpp:253]     Train net output #0: loss = 1.25778 (* 1 = 1.25778 loss)
I0523 14:38:52.745075  1883 sgd_solver.cpp:106] Iteration 38250, lr = 0.0015
I0523 14:39:22.715136  1883 solver.cpp:237] Iteration 38500, loss = 1.25739
I0523 14:39:22.715309  1883 solver.cpp:253]     Train net output #0: loss = 1.25739 (* 1 = 1.25739 loss)
I0523 14:39:22.715323  1883 sgd_solver.cpp:106] Iteration 38500, lr = 0.0015
I0523 14:39:31.788488  1883 solver.cpp:237] Iteration 38750, loss = 1.28409
I0523 14:39:31.788523  1883 solver.cpp:253]     Train net output #0: loss = 1.28409 (* 1 = 1.28409 loss)
I0523 14:39:31.788540  1883 sgd_solver.cpp:106] Iteration 38750, lr = 0.0015
I0523 14:39:40.862438  1883 solver.cpp:237] Iteration 39000, loss = 1.36512
I0523 14:39:40.862476  1883 solver.cpp:253]     Train net output #0: loss = 1.36512 (* 1 = 1.36512 loss)
I0523 14:39:40.862498  1883 sgd_solver.cpp:106] Iteration 39000, lr = 0.0015
I0523 14:39:49.937983  1883 solver.cpp:237] Iteration 39250, loss = 1.24004
I0523 14:39:49.938017  1883 solver.cpp:253]     Train net output #0: loss = 1.24004 (* 1 = 1.24004 loss)
I0523 14:39:49.938033  1883 sgd_solver.cpp:106] Iteration 39250, lr = 0.0015
I0523 14:39:59.013797  1883 solver.cpp:237] Iteration 39500, loss = 0.978373
I0523 14:39:59.013959  1883 solver.cpp:253]     Train net output #0: loss = 0.978373 (* 1 = 0.978373 loss)
I0523 14:39:59.013972  1883 sgd_solver.cpp:106] Iteration 39500, lr = 0.0015
I0523 14:40:08.084841  1883 solver.cpp:237] Iteration 39750, loss = 0.920503
I0523 14:40:08.084887  1883 solver.cpp:253]     Train net output #0: loss = 0.920503 (* 1 = 0.920503 loss)
I0523 14:40:08.084903  1883 sgd_solver.cpp:106] Iteration 39750, lr = 0.0015
I0523 14:40:17.128096  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_40000.caffemodel
I0523 14:40:17.190897  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_40000.solverstate
I0523 14:40:17.217252  1883 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 14:41:25.354485  1883 solver.cpp:409]     Test net output #0: accuracy = 0.857215
I0523 14:41:25.354661  1883 solver.cpp:409]     Test net output #1: loss = 0.46769 (* 1 = 0.46769 loss)
I0523 14:41:46.255643  1883 solver.cpp:237] Iteration 40000, loss = 1.12388
I0523 14:41:46.255698  1883 solver.cpp:253]     Train net output #0: loss = 1.12388 (* 1 = 1.12388 loss)
I0523 14:41:46.255717  1883 sgd_solver.cpp:106] Iteration 40000, lr = 0.0015
I0523 14:41:55.372455  1883 solver.cpp:237] Iteration 40250, loss = 1.09085
I0523 14:41:55.372614  1883 solver.cpp:253]     Train net output #0: loss = 1.09085 (* 1 = 1.09085 loss)
I0523 14:41:55.372627  1883 sgd_solver.cpp:106] Iteration 40250, lr = 0.0015
I0523 14:42:04.485296  1883 solver.cpp:237] Iteration 40500, loss = 1.21341
I0523 14:42:04.485330  1883 solver.cpp:253]     Train net output #0: loss = 1.21341 (* 1 = 1.21341 loss)
I0523 14:42:04.485348  1883 sgd_solver.cpp:106] Iteration 40500, lr = 0.0015
I0523 14:42:13.604125  1883 solver.cpp:237] Iteration 40750, loss = 1.42028
I0523 14:42:13.604166  1883 solver.cpp:253]     Train net output #0: loss = 1.42028 (* 1 = 1.42028 loss)
I0523 14:42:13.604187  1883 sgd_solver.cpp:106] Iteration 40750, lr = 0.0015
I0523 14:42:22.720528  1883 solver.cpp:237] Iteration 41000, loss = 1.10625
I0523 14:42:22.720563  1883 solver.cpp:253]     Train net output #0: loss = 1.10625 (* 1 = 1.10625 loss)
I0523 14:42:22.720579  1883 sgd_solver.cpp:106] Iteration 41000, lr = 0.0015
I0523 14:42:31.836266  1883 solver.cpp:237] Iteration 41250, loss = 1.37367
I0523 14:42:31.836426  1883 solver.cpp:253]     Train net output #0: loss = 1.37367 (* 1 = 1.37367 loss)
I0523 14:42:31.836441  1883 sgd_solver.cpp:106] Iteration 41250, lr = 0.0015
I0523 14:42:40.951899  1883 solver.cpp:237] Iteration 41500, loss = 1.23445
I0523 14:42:40.951932  1883 solver.cpp:253]     Train net output #0: loss = 1.23445 (* 1 = 1.23445 loss)
I0523 14:42:40.951949  1883 sgd_solver.cpp:106] Iteration 41500, lr = 0.0015
I0523 14:43:10.971585  1883 solver.cpp:237] Iteration 41750, loss = 1.29836
I0523 14:43:10.971762  1883 solver.cpp:253]     Train net output #0: loss = 1.29836 (* 1 = 1.29836 loss)
I0523 14:43:10.971776  1883 sgd_solver.cpp:106] Iteration 41750, lr = 0.0015
I0523 14:43:20.076844  1883 solver.cpp:237] Iteration 42000, loss = 1.33841
I0523 14:43:20.076879  1883 solver.cpp:253]     Train net output #0: loss = 1.33841 (* 1 = 1.33841 loss)
I0523 14:43:20.076895  1883 sgd_solver.cpp:106] Iteration 42000, lr = 0.0015
I0523 14:43:29.188387  1883 solver.cpp:237] Iteration 42250, loss = 1.18331
I0523 14:43:29.188431  1883 solver.cpp:253]     Train net output #0: loss = 1.18331 (* 1 = 1.18331 loss)
I0523 14:43:29.188447  1883 sgd_solver.cpp:106] Iteration 42250, lr = 0.0015
I0523 14:43:38.270834  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_42500.caffemodel
I0523 14:43:38.334064  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_42500.solverstate
I0523 14:43:38.371685  1883 solver.cpp:237] Iteration 42500, loss = 1.05984
I0523 14:43:38.371726  1883 solver.cpp:253]     Train net output #0: loss = 1.05984 (* 1 = 1.05984 loss)
I0523 14:43:38.371745  1883 sgd_solver.cpp:106] Iteration 42500, lr = 0.0015
I0523 14:43:47.477519  1883 solver.cpp:237] Iteration 42750, loss = 1.36036
I0523 14:43:47.477699  1883 solver.cpp:253]     Train net output #0: loss = 1.36036 (* 1 = 1.36036 loss)
I0523 14:43:47.477712  1883 sgd_solver.cpp:106] Iteration 42750, lr = 0.0015
I0523 14:43:56.592855  1883 solver.cpp:237] Iteration 43000, loss = 1.24266
I0523 14:43:56.592890  1883 solver.cpp:253]     Train net output #0: loss = 1.24266 (* 1 = 1.24266 loss)
I0523 14:43:56.592908  1883 sgd_solver.cpp:106] Iteration 43000, lr = 0.0015
I0523 14:44:05.710535  1883 solver.cpp:237] Iteration 43250, loss = 0.893413
I0523 14:44:05.710569  1883 solver.cpp:253]     Train net output #0: loss = 0.893413 (* 1 = 0.893413 loss)
I0523 14:44:05.710585  1883 sgd_solver.cpp:106] Iteration 43250, lr = 0.0015
I0523 14:44:35.688463  1883 solver.cpp:237] Iteration 43500, loss = 1.03805
I0523 14:44:35.688632  1883 solver.cpp:253]     Train net output #0: loss = 1.03805 (* 1 = 1.03805 loss)
I0523 14:44:35.688647  1883 sgd_solver.cpp:106] Iteration 43500, lr = 0.0015
I0523 14:44:44.803611  1883 solver.cpp:237] Iteration 43750, loss = 1.33168
I0523 14:44:44.803645  1883 solver.cpp:253]     Train net output #0: loss = 1.33168 (* 1 = 1.33168 loss)
I0523 14:44:44.803663  1883 sgd_solver.cpp:106] Iteration 43750, lr = 0.0015
I0523 14:44:53.918339  1883 solver.cpp:237] Iteration 44000, loss = 1.02571
I0523 14:44:53.918373  1883 solver.cpp:253]     Train net output #0: loss = 1.02571 (* 1 = 1.02571 loss)
I0523 14:44:53.918391  1883 sgd_solver.cpp:106] Iteration 44000, lr = 0.0015
I0523 14:45:03.034971  1883 solver.cpp:237] Iteration 44250, loss = 1.38145
I0523 14:45:03.035017  1883 solver.cpp:253]     Train net output #0: loss = 1.38145 (* 1 = 1.38145 loss)
I0523 14:45:03.035034  1883 sgd_solver.cpp:106] Iteration 44250, lr = 0.0015
I0523 14:45:12.161149  1883 solver.cpp:237] Iteration 44500, loss = 1.40929
I0523 14:45:12.161301  1883 solver.cpp:253]     Train net output #0: loss = 1.40929 (* 1 = 1.40929 loss)
I0523 14:45:12.161315  1883 sgd_solver.cpp:106] Iteration 44500, lr = 0.0015
I0523 14:45:21.279268  1883 solver.cpp:237] Iteration 44750, loss = 1.2832
I0523 14:45:21.279302  1883 solver.cpp:253]     Train net output #0: loss = 1.2832 (* 1 = 1.2832 loss)
I0523 14:45:21.279320  1883 sgd_solver.cpp:106] Iteration 44750, lr = 0.0015
I0523 14:45:30.350738  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_45000.caffemodel
I0523 14:45:30.414993  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_45000.solverstate
I0523 14:45:30.441305  1883 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 14:46:17.699911  1883 solver.cpp:409]     Test net output #0: accuracy = 0.865013
I0523 14:46:17.700083  1883 solver.cpp:409]     Test net output #1: loss = 0.427289 (* 1 = 0.427289 loss)
I0523 14:46:38.568059  1883 solver.cpp:237] Iteration 45000, loss = 1.0663
I0523 14:46:38.568112  1883 solver.cpp:253]     Train net output #0: loss = 1.0663 (* 1 = 1.0663 loss)
I0523 14:46:38.568130  1883 sgd_solver.cpp:106] Iteration 45000, lr = 0.0015
I0523 14:46:47.610574  1883 solver.cpp:237] Iteration 45250, loss = 1.14879
I0523 14:46:47.610617  1883 solver.cpp:253]     Train net output #0: loss = 1.14879 (* 1 = 1.14879 loss)
I0523 14:46:47.610635  1883 sgd_solver.cpp:106] Iteration 45250, lr = 0.0015
I0523 14:46:56.644593  1883 solver.cpp:237] Iteration 45500, loss = 1.0377
I0523 14:46:56.644752  1883 solver.cpp:253]     Train net output #0: loss = 1.0377 (* 1 = 1.0377 loss)
I0523 14:46:56.644765  1883 sgd_solver.cpp:106] Iteration 45500, lr = 0.0015
I0523 14:47:05.675923  1883 solver.cpp:237] Iteration 45750, loss = 0.918685
I0523 14:47:05.675973  1883 solver.cpp:253]     Train net output #0: loss = 0.918685 (* 1 = 0.918685 loss)
I0523 14:47:05.675990  1883 sgd_solver.cpp:106] Iteration 45750, lr = 0.0015
I0523 14:47:14.714175  1883 solver.cpp:237] Iteration 46000, loss = 1.03635
I0523 14:47:14.714210  1883 solver.cpp:253]     Train net output #0: loss = 1.03635 (* 1 = 1.03635 loss)
I0523 14:47:14.714227  1883 sgd_solver.cpp:106] Iteration 46000, lr = 0.0015
I0523 14:47:23.746973  1883 solver.cpp:237] Iteration 46250, loss = 1.11639
I0523 14:47:23.747009  1883 solver.cpp:253]     Train net output #0: loss = 1.11639 (* 1 = 1.11639 loss)
I0523 14:47:23.747025  1883 sgd_solver.cpp:106] Iteration 46250, lr = 0.0015
I0523 14:47:32.785658  1883 solver.cpp:237] Iteration 46500, loss = 1.02638
I0523 14:47:32.785835  1883 solver.cpp:253]     Train net output #0: loss = 1.02638 (* 1 = 1.02638 loss)
I0523 14:47:32.785851  1883 sgd_solver.cpp:106] Iteration 46500, lr = 0.0015
I0523 14:48:02.711597  1883 solver.cpp:237] Iteration 46750, loss = 1.43841
I0523 14:48:02.711648  1883 solver.cpp:253]     Train net output #0: loss = 1.43841 (* 1 = 1.43841 loss)
I0523 14:48:02.711664  1883 sgd_solver.cpp:106] Iteration 46750, lr = 0.0015
I0523 14:48:11.745256  1883 solver.cpp:237] Iteration 47000, loss = 1.33363
I0523 14:48:11.745414  1883 solver.cpp:253]     Train net output #0: loss = 1.33363 (* 1 = 1.33363 loss)
I0523 14:48:11.745429  1883 sgd_solver.cpp:106] Iteration 47000, lr = 0.0015
I0523 14:48:20.779911  1883 solver.cpp:237] Iteration 47250, loss = 1.41548
I0523 14:48:20.779960  1883 solver.cpp:253]     Train net output #0: loss = 1.41548 (* 1 = 1.41548 loss)
I0523 14:48:20.779976  1883 sgd_solver.cpp:106] Iteration 47250, lr = 0.0015
I0523 14:48:29.772928  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_47500.caffemodel
I0523 14:48:29.838752  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_47500.solverstate
I0523 14:48:29.877780  1883 solver.cpp:237] Iteration 47500, loss = 1.30945
I0523 14:48:29.877830  1883 solver.cpp:253]     Train net output #0: loss = 1.30945 (* 1 = 1.30945 loss)
I0523 14:48:29.877845  1883 sgd_solver.cpp:106] Iteration 47500, lr = 0.0015
I0523 14:48:38.903548  1883 solver.cpp:237] Iteration 47750, loss = 1.33779
I0523 14:48:38.903583  1883 solver.cpp:253]     Train net output #0: loss = 1.33779 (* 1 = 1.33779 loss)
I0523 14:48:38.903595  1883 sgd_solver.cpp:106] Iteration 47750, lr = 0.0015
I0523 14:48:47.941030  1883 solver.cpp:237] Iteration 48000, loss = 1.20749
I0523 14:48:47.941200  1883 solver.cpp:253]     Train net output #0: loss = 1.20749 (* 1 = 1.20749 loss)
I0523 14:48:47.941215  1883 sgd_solver.cpp:106] Iteration 48000, lr = 0.0015
I0523 14:48:56.966943  1883 solver.cpp:237] Iteration 48250, loss = 1.32207
I0523 14:48:56.966977  1883 solver.cpp:253]     Train net output #0: loss = 1.32207 (* 1 = 1.32207 loss)
I0523 14:48:56.966995  1883 sgd_solver.cpp:106] Iteration 48250, lr = 0.0015
I0523 14:49:26.932057  1883 solver.cpp:237] Iteration 48500, loss = 1.43517
I0523 14:49:26.932232  1883 solver.cpp:253]     Train net output #0: loss = 1.43517 (* 1 = 1.43517 loss)
I0523 14:49:26.932246  1883 sgd_solver.cpp:106] Iteration 48500, lr = 0.0015
I0523 14:49:35.968210  1883 solver.cpp:237] Iteration 48750, loss = 1.52152
I0523 14:49:35.968256  1883 solver.cpp:253]     Train net output #0: loss = 1.52152 (* 1 = 1.52152 loss)
I0523 14:49:35.968273  1883 sgd_solver.cpp:106] Iteration 48750, lr = 0.0015
I0523 14:49:45.003845  1883 solver.cpp:237] Iteration 49000, loss = 1.26693
I0523 14:49:45.003880  1883 solver.cpp:253]     Train net output #0: loss = 1.26693 (* 1 = 1.26693 loss)
I0523 14:49:45.003896  1883 sgd_solver.cpp:106] Iteration 49000, lr = 0.0015
I0523 14:49:54.044040  1883 solver.cpp:237] Iteration 49250, loss = 1.08003
I0523 14:49:54.044075  1883 solver.cpp:253]     Train net output #0: loss = 1.08003 (* 1 = 1.08003 loss)
I0523 14:49:54.044091  1883 sgd_solver.cpp:106] Iteration 49250, lr = 0.0015
I0523 14:50:03.078567  1883 solver.cpp:237] Iteration 49500, loss = 1.30345
I0523 14:50:03.078738  1883 solver.cpp:253]     Train net output #0: loss = 1.30345 (* 1 = 1.30345 loss)
I0523 14:50:03.078752  1883 sgd_solver.cpp:106] Iteration 49500, lr = 0.0015
I0523 14:50:12.116602  1883 solver.cpp:237] Iteration 49750, loss = 1.34146
I0523 14:50:12.116636  1883 solver.cpp:253]     Train net output #0: loss = 1.34146 (* 1 = 1.34146 loss)
I0523 14:50:12.116654  1883 sgd_solver.cpp:106] Iteration 49750, lr = 0.0015
I0523 14:50:21.115800  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_50000.caffemodel
I0523 14:50:21.180965  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_50000.solverstate
I0523 14:50:21.208885  1883 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 14:51:29.459218  1883 solver.cpp:409]     Test net output #0: accuracy = 0.872899
I0523 14:51:29.459393  1883 solver.cpp:409]     Test net output #1: loss = 0.423989 (* 1 = 0.423989 loss)
I0523 14:51:50.374303  1883 solver.cpp:237] Iteration 50000, loss = 1.34899
I0523 14:51:50.374357  1883 solver.cpp:253]     Train net output #0: loss = 1.34899 (* 1 = 1.34899 loss)
I0523 14:51:50.374373  1883 sgd_solver.cpp:106] Iteration 50000, lr = 0.0015
I0523 14:51:59.429864  1883 solver.cpp:237] Iteration 50250, loss = 0.936769
I0523 14:51:59.429901  1883 solver.cpp:253]     Train net output #0: loss = 0.936769 (* 1 = 0.936769 loss)
I0523 14:51:59.429914  1883 sgd_solver.cpp:106] Iteration 50250, lr = 0.0015
I0523 14:52:08.494206  1883 solver.cpp:237] Iteration 50500, loss = 1.25209
I0523 14:52:08.494367  1883 solver.cpp:253]     Train net output #0: loss = 1.25209 (* 1 = 1.25209 loss)
I0523 14:52:08.494381  1883 sgd_solver.cpp:106] Iteration 50500, lr = 0.0015
I0523 14:52:17.543762  1883 solver.cpp:237] Iteration 50750, loss = 1.12
I0523 14:52:17.543797  1883 solver.cpp:253]     Train net output #0: loss = 1.12 (* 1 = 1.12 loss)
I0523 14:52:17.543813  1883 sgd_solver.cpp:106] Iteration 50750, lr = 0.0015
I0523 14:52:26.609964  1883 solver.cpp:237] Iteration 51000, loss = 1.22235
I0523 14:52:26.609999  1883 solver.cpp:253]     Train net output #0: loss = 1.22235 (* 1 = 1.22235 loss)
I0523 14:52:26.610016  1883 sgd_solver.cpp:106] Iteration 51000, lr = 0.0015
I0523 14:52:35.682529  1883 solver.cpp:237] Iteration 51250, loss = 1.1045
I0523 14:52:35.682566  1883 solver.cpp:253]     Train net output #0: loss = 1.1045 (* 1 = 1.1045 loss)
I0523 14:52:35.682585  1883 sgd_solver.cpp:106] Iteration 51250, lr = 0.0015
I0523 14:52:44.748333  1883 solver.cpp:237] Iteration 51500, loss = 1.42375
I0523 14:52:44.748483  1883 solver.cpp:253]     Train net output #0: loss = 1.42375 (* 1 = 1.42375 loss)
I0523 14:52:44.748497  1883 sgd_solver.cpp:106] Iteration 51500, lr = 0.0015
I0523 14:53:14.726524  1883 solver.cpp:237] Iteration 51750, loss = 0.978692
I0523 14:53:14.726575  1883 solver.cpp:253]     Train net output #0: loss = 0.978692 (* 1 = 0.978692 loss)
I0523 14:53:14.726589  1883 sgd_solver.cpp:106] Iteration 51750, lr = 0.0015
I0523 14:53:23.784554  1883 solver.cpp:237] Iteration 52000, loss = 1.01725
I0523 14:53:23.784719  1883 solver.cpp:253]     Train net output #0: loss = 1.01725 (* 1 = 1.01725 loss)
I0523 14:53:23.784734  1883 sgd_solver.cpp:106] Iteration 52000, lr = 0.0015
I0523 14:53:32.843314  1883 solver.cpp:237] Iteration 52250, loss = 1.4164
I0523 14:53:32.843348  1883 solver.cpp:253]     Train net output #0: loss = 1.4164 (* 1 = 1.4164 loss)
I0523 14:53:32.843366  1883 sgd_solver.cpp:106] Iteration 52250, lr = 0.0015
I0523 14:53:41.871897  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_52500.caffemodel
I0523 14:53:41.936744  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_52500.solverstate
I0523 14:53:41.974591  1883 solver.cpp:237] Iteration 52500, loss = 0.999687
I0523 14:53:41.974637  1883 solver.cpp:253]     Train net output #0: loss = 0.999687 (* 1 = 0.999687 loss)
I0523 14:53:41.974653  1883 sgd_solver.cpp:106] Iteration 52500, lr = 0.0015
I0523 14:53:51.038450  1883 solver.cpp:237] Iteration 52750, loss = 1.34641
I0523 14:53:51.038492  1883 solver.cpp:253]     Train net output #0: loss = 1.34641 (* 1 = 1.34641 loss)
I0523 14:53:51.038511  1883 sgd_solver.cpp:106] Iteration 52750, lr = 0.0015
I0523 14:54:00.105788  1883 solver.cpp:237] Iteration 53000, loss = 1.0806
I0523 14:54:00.105959  1883 solver.cpp:253]     Train net output #0: loss = 1.0806 (* 1 = 1.0806 loss)
I0523 14:54:00.105973  1883 sgd_solver.cpp:106] Iteration 53000, lr = 0.0015
I0523 14:54:09.163622  1883 solver.cpp:237] Iteration 53250, loss = 1.30506
I0523 14:54:09.163655  1883 solver.cpp:253]     Train net output #0: loss = 1.30506 (* 1 = 1.30506 loss)
I0523 14:54:09.163679  1883 sgd_solver.cpp:106] Iteration 53250, lr = 0.0015
I0523 14:54:39.122457  1883 solver.cpp:237] Iteration 53500, loss = 1.35146
I0523 14:54:39.122633  1883 solver.cpp:253]     Train net output #0: loss = 1.35146 (* 1 = 1.35146 loss)
I0523 14:54:39.122648  1883 sgd_solver.cpp:106] Iteration 53500, lr = 0.0015
I0523 14:54:48.178264  1883 solver.cpp:237] Iteration 53750, loss = 1.38756
I0523 14:54:48.178298  1883 solver.cpp:253]     Train net output #0: loss = 1.38756 (* 1 = 1.38756 loss)
I0523 14:54:48.178318  1883 sgd_solver.cpp:106] Iteration 53750, lr = 0.0015
I0523 14:54:57.239835  1883 solver.cpp:237] Iteration 54000, loss = 1.16043
I0523 14:54:57.239869  1883 solver.cpp:253]     Train net output #0: loss = 1.16043 (* 1 = 1.16043 loss)
I0523 14:54:57.239886  1883 sgd_solver.cpp:106] Iteration 54000, lr = 0.0015
I0523 14:55:06.291690  1883 solver.cpp:237] Iteration 54250, loss = 1.03751
I0523 14:55:06.291731  1883 solver.cpp:253]     Train net output #0: loss = 1.03751 (* 1 = 1.03751 loss)
I0523 14:55:06.291749  1883 sgd_solver.cpp:106] Iteration 54250, lr = 0.0015
I0523 14:55:15.356524  1883 solver.cpp:237] Iteration 54500, loss = 1.05537
I0523 14:55:15.356678  1883 solver.cpp:253]     Train net output #0: loss = 1.05537 (* 1 = 1.05537 loss)
I0523 14:55:15.356693  1883 sgd_solver.cpp:106] Iteration 54500, lr = 0.0015
I0523 14:55:24.430897  1883 solver.cpp:237] Iteration 54750, loss = 1.40174
I0523 14:55:24.430932  1883 solver.cpp:253]     Train net output #0: loss = 1.40174 (* 1 = 1.40174 loss)
I0523 14:55:24.430949  1883 sgd_solver.cpp:106] Iteration 54750, lr = 0.0015
I0523 14:55:33.469619  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_55000.caffemodel
I0523 14:55:33.532788  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_55000.solverstate
I0523 14:55:33.559217  1883 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 14:56:20.564952  1883 solver.cpp:409]     Test net output #0: accuracy = 0.868174
I0523 14:56:20.565135  1883 solver.cpp:409]     Test net output #1: loss = 0.401667 (* 1 = 0.401667 loss)
I0523 14:56:41.454268  1883 solver.cpp:237] Iteration 55000, loss = 1.14278
I0523 14:56:41.454320  1883 solver.cpp:253]     Train net output #0: loss = 1.14278 (* 1 = 1.14278 loss)
I0523 14:56:41.454336  1883 sgd_solver.cpp:106] Iteration 55000, lr = 0.0015
I0523 14:56:50.465790  1883 solver.cpp:237] Iteration 55250, loss = 1.07803
I0523 14:56:50.465824  1883 solver.cpp:253]     Train net output #0: loss = 1.07803 (* 1 = 1.07803 loss)
I0523 14:56:50.465842  1883 sgd_solver.cpp:106] Iteration 55250, lr = 0.0015
I0523 14:56:59.481063  1883 solver.cpp:237] Iteration 55500, loss = 1.0389
I0523 14:56:59.481231  1883 solver.cpp:253]     Train net output #0: loss = 1.0389 (* 1 = 1.0389 loss)
I0523 14:56:59.481245  1883 sgd_solver.cpp:106] Iteration 55500, lr = 0.0015
I0523 14:57:08.495422  1883 solver.cpp:237] Iteration 55750, loss = 1.2145
I0523 14:57:08.495470  1883 solver.cpp:253]     Train net output #0: loss = 1.2145 (* 1 = 1.2145 loss)
I0523 14:57:08.495482  1883 sgd_solver.cpp:106] Iteration 55750, lr = 0.0015
I0523 14:57:17.513715  1883 solver.cpp:237] Iteration 56000, loss = 1.14054
I0523 14:57:17.513749  1883 solver.cpp:253]     Train net output #0: loss = 1.14054 (* 1 = 1.14054 loss)
I0523 14:57:17.513768  1883 sgd_solver.cpp:106] Iteration 56000, lr = 0.0015
I0523 14:57:26.533097  1883 solver.cpp:237] Iteration 56250, loss = 1.18239
I0523 14:57:26.533131  1883 solver.cpp:253]     Train net output #0: loss = 1.18239 (* 1 = 1.18239 loss)
I0523 14:57:26.533148  1883 sgd_solver.cpp:106] Iteration 56250, lr = 0.0015
I0523 14:57:35.543615  1883 solver.cpp:237] Iteration 56500, loss = 1.14326
I0523 14:57:35.543790  1883 solver.cpp:253]     Train net output #0: loss = 1.14326 (* 1 = 1.14326 loss)
I0523 14:57:35.543804  1883 sgd_solver.cpp:106] Iteration 56500, lr = 0.0015
I0523 14:58:05.497612  1883 solver.cpp:237] Iteration 56750, loss = 1.17188
I0523 14:58:05.497664  1883 solver.cpp:253]     Train net output #0: loss = 1.17188 (* 1 = 1.17188 loss)
I0523 14:58:05.497681  1883 sgd_solver.cpp:106] Iteration 56750, lr = 0.0015
I0523 14:58:14.511423  1883 solver.cpp:237] Iteration 57000, loss = 0.99181
I0523 14:58:14.511589  1883 solver.cpp:253]     Train net output #0: loss = 0.99181 (* 1 = 0.99181 loss)
I0523 14:58:14.511601  1883 sgd_solver.cpp:106] Iteration 57000, lr = 0.0015
I0523 14:58:23.526319  1883 solver.cpp:237] Iteration 57250, loss = 1.34332
I0523 14:58:23.526368  1883 solver.cpp:253]     Train net output #0: loss = 1.34332 (* 1 = 1.34332 loss)
I0523 14:58:23.526381  1883 sgd_solver.cpp:106] Iteration 57250, lr = 0.0015
I0523 14:58:32.501811  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_57500.caffemodel
I0523 14:58:32.565913  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_57500.solverstate
I0523 14:58:32.603760  1883 solver.cpp:237] Iteration 57500, loss = 0.965281
I0523 14:58:32.603806  1883 solver.cpp:253]     Train net output #0: loss = 0.965281 (* 1 = 0.965281 loss)
I0523 14:58:32.603823  1883 sgd_solver.cpp:106] Iteration 57500, lr = 0.0015
I0523 14:58:41.616646  1883 solver.cpp:237] Iteration 57750, loss = 1.15253
I0523 14:58:41.616682  1883 solver.cpp:253]     Train net output #0: loss = 1.15253 (* 1 = 1.15253 loss)
I0523 14:58:41.616698  1883 sgd_solver.cpp:106] Iteration 57750, lr = 0.0015
I0523 14:58:50.622864  1883 solver.cpp:237] Iteration 58000, loss = 1.11155
I0523 14:58:50.623039  1883 solver.cpp:253]     Train net output #0: loss = 1.11155 (* 1 = 1.11155 loss)
I0523 14:58:50.623052  1883 sgd_solver.cpp:106] Iteration 58000, lr = 0.0015
I0523 14:58:59.631942  1883 solver.cpp:237] Iteration 58250, loss = 1.41478
I0523 14:58:59.631975  1883 solver.cpp:253]     Train net output #0: loss = 1.41478 (* 1 = 1.41478 loss)
I0523 14:58:59.631994  1883 sgd_solver.cpp:106] Iteration 58250, lr = 0.0015
I0523 14:59:29.599761  1883 solver.cpp:237] Iteration 58500, loss = 1.15327
I0523 14:59:29.599939  1883 solver.cpp:253]     Train net output #0: loss = 1.15327 (* 1 = 1.15327 loss)
I0523 14:59:29.599954  1883 sgd_solver.cpp:106] Iteration 58500, lr = 0.0015
I0523 14:59:38.610143  1883 solver.cpp:237] Iteration 58750, loss = 1.37958
I0523 14:59:38.610186  1883 solver.cpp:253]     Train net output #0: loss = 1.37958 (* 1 = 1.37958 loss)
I0523 14:59:38.610204  1883 sgd_solver.cpp:106] Iteration 58750, lr = 0.0015
I0523 14:59:47.624537  1883 solver.cpp:237] Iteration 59000, loss = 1.09437
I0523 14:59:47.624572  1883 solver.cpp:253]     Train net output #0: loss = 1.09437 (* 1 = 1.09437 loss)
I0523 14:59:47.624589  1883 sgd_solver.cpp:106] Iteration 59000, lr = 0.0015
I0523 14:59:56.638691  1883 solver.cpp:237] Iteration 59250, loss = 1.02805
I0523 14:59:56.638727  1883 solver.cpp:253]     Train net output #0: loss = 1.02805 (* 1 = 1.02805 loss)
I0523 14:59:56.638744  1883 sgd_solver.cpp:106] Iteration 59250, lr = 0.0015
I0523 15:00:05.648201  1883 solver.cpp:237] Iteration 59500, loss = 1.31025
I0523 15:00:05.648380  1883 solver.cpp:253]     Train net output #0: loss = 1.31025 (* 1 = 1.31025 loss)
I0523 15:00:05.648393  1883 sgd_solver.cpp:106] Iteration 59500, lr = 0.0015
I0523 15:00:14.665936  1883 solver.cpp:237] Iteration 59750, loss = 0.913555
I0523 15:00:14.665971  1883 solver.cpp:253]     Train net output #0: loss = 0.913555 (* 1 = 0.913555 loss)
I0523 15:00:14.665988  1883 sgd_solver.cpp:106] Iteration 59750, lr = 0.0015
I0523 15:00:23.635504  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_60000.caffemodel
I0523 15:00:23.699224  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_60000.solverstate
I0523 15:00:23.726006  1883 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 15:01:31.947571  1883 solver.cpp:409]     Test net output #0: accuracy = 0.8767
I0523 15:01:31.947754  1883 solver.cpp:409]     Test net output #1: loss = 0.414021 (* 1 = 0.414021 loss)
I0523 15:01:52.869333  1883 solver.cpp:237] Iteration 60000, loss = 1.15849
I0523 15:01:52.869386  1883 solver.cpp:253]     Train net output #0: loss = 1.15849 (* 1 = 1.15849 loss)
I0523 15:01:52.869402  1883 sgd_solver.cpp:106] Iteration 60000, lr = 0.0015
I0523 15:02:01.980522  1883 solver.cpp:237] Iteration 60250, loss = 1.27376
I0523 15:02:01.980686  1883 solver.cpp:253]     Train net output #0: loss = 1.27376 (* 1 = 1.27376 loss)
I0523 15:02:01.980700  1883 sgd_solver.cpp:106] Iteration 60250, lr = 0.0015
I0523 15:02:11.085775  1883 solver.cpp:237] Iteration 60500, loss = 1.44524
I0523 15:02:11.085821  1883 solver.cpp:253]     Train net output #0: loss = 1.44524 (* 1 = 1.44524 loss)
I0523 15:02:11.085837  1883 sgd_solver.cpp:106] Iteration 60500, lr = 0.0015
I0523 15:02:20.202563  1883 solver.cpp:237] Iteration 60750, loss = 1.35778
I0523 15:02:20.202597  1883 solver.cpp:253]     Train net output #0: loss = 1.35778 (* 1 = 1.35778 loss)
I0523 15:02:20.202615  1883 sgd_solver.cpp:106] Iteration 60750, lr = 0.0015
I0523 15:02:29.306668  1883 solver.cpp:237] Iteration 61000, loss = 1.0708
I0523 15:02:29.306702  1883 solver.cpp:253]     Train net output #0: loss = 1.0708 (* 1 = 1.0708 loss)
I0523 15:02:29.306718  1883 sgd_solver.cpp:106] Iteration 61000, lr = 0.0015
I0523 15:02:38.413576  1883 solver.cpp:237] Iteration 61250, loss = 1.04749
I0523 15:02:38.413746  1883 solver.cpp:253]     Train net output #0: loss = 1.04749 (* 1 = 1.04749 loss)
I0523 15:02:38.413760  1883 sgd_solver.cpp:106] Iteration 61250, lr = 0.0015
I0523 15:02:47.521842  1883 solver.cpp:237] Iteration 61500, loss = 0.952842
I0523 15:02:47.521878  1883 solver.cpp:253]     Train net output #0: loss = 0.952842 (* 1 = 0.952842 loss)
I0523 15:02:47.521895  1883 sgd_solver.cpp:106] Iteration 61500, lr = 0.0015
I0523 15:03:17.550331  1883 solver.cpp:237] Iteration 61750, loss = 1.04554
I0523 15:03:17.550510  1883 solver.cpp:253]     Train net output #0: loss = 1.04554 (* 1 = 1.04554 loss)
I0523 15:03:17.550524  1883 sgd_solver.cpp:106] Iteration 61750, lr = 0.0015
I0523 15:03:26.658241  1883 solver.cpp:237] Iteration 62000, loss = 1.17568
I0523 15:03:26.658288  1883 solver.cpp:253]     Train net output #0: loss = 1.17568 (* 1 = 1.17568 loss)
I0523 15:03:26.658304  1883 sgd_solver.cpp:106] Iteration 62000, lr = 0.0015
I0523 15:03:35.767737  1883 solver.cpp:237] Iteration 62250, loss = 1.15896
I0523 15:03:35.767772  1883 solver.cpp:253]     Train net output #0: loss = 1.15896 (* 1 = 1.15896 loss)
I0523 15:03:35.767789  1883 sgd_solver.cpp:106] Iteration 62250, lr = 0.0015
I0523 15:03:44.838738  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_62500.caffemodel
I0523 15:03:44.903736  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_62500.solverstate
I0523 15:03:44.942967  1883 solver.cpp:237] Iteration 62500, loss = 1.01788
I0523 15:03:44.943017  1883 solver.cpp:253]     Train net output #0: loss = 1.01788 (* 1 = 1.01788 loss)
I0523 15:03:44.943032  1883 sgd_solver.cpp:106] Iteration 62500, lr = 0.0015
I0523 15:03:54.043675  1883 solver.cpp:237] Iteration 62750, loss = 1.28523
I0523 15:03:54.043865  1883 solver.cpp:253]     Train net output #0: loss = 1.28523 (* 1 = 1.28523 loss)
I0523 15:03:54.043879  1883 sgd_solver.cpp:106] Iteration 62750, lr = 0.0015
I0523 15:04:03.148646  1883 solver.cpp:237] Iteration 63000, loss = 1.3501
I0523 15:04:03.148680  1883 solver.cpp:253]     Train net output #0: loss = 1.3501 (* 1 = 1.3501 loss)
I0523 15:04:03.148699  1883 sgd_solver.cpp:106] Iteration 63000, lr = 0.0015
I0523 15:04:12.253139  1883 solver.cpp:237] Iteration 63250, loss = 1.19661
I0523 15:04:12.253185  1883 solver.cpp:253]     Train net output #0: loss = 1.19661 (* 1 = 1.19661 loss)
I0523 15:04:12.253201  1883 sgd_solver.cpp:106] Iteration 63250, lr = 0.0015
I0523 15:04:42.274215  1883 solver.cpp:237] Iteration 63500, loss = 1.30942
I0523 15:04:42.274400  1883 solver.cpp:253]     Train net output #0: loss = 1.30942 (* 1 = 1.30942 loss)
I0523 15:04:42.274415  1883 sgd_solver.cpp:106] Iteration 63500, lr = 0.0015
I0523 15:04:51.387042  1883 solver.cpp:237] Iteration 63750, loss = 1.39506
I0523 15:04:51.387076  1883 solver.cpp:253]     Train net output #0: loss = 1.39506 (* 1 = 1.39506 loss)
I0523 15:04:51.387089  1883 sgd_solver.cpp:106] Iteration 63750, lr = 0.0015
I0523 15:05:00.494731  1883 solver.cpp:237] Iteration 64000, loss = 1.25028
I0523 15:05:00.494773  1883 solver.cpp:253]     Train net output #0: loss = 1.25028 (* 1 = 1.25028 loss)
I0523 15:05:00.494789  1883 sgd_solver.cpp:106] Iteration 64000, lr = 0.0015
I0523 15:05:09.603627  1883 solver.cpp:237] Iteration 64250, loss = 1.21698
I0523 15:05:09.603662  1883 solver.cpp:253]     Train net output #0: loss = 1.21698 (* 1 = 1.21698 loss)
I0523 15:05:09.603683  1883 sgd_solver.cpp:106] Iteration 64250, lr = 0.0015
I0523 15:05:18.715736  1883 solver.cpp:237] Iteration 64500, loss = 1.26199
I0523 15:05:18.715893  1883 solver.cpp:253]     Train net output #0: loss = 1.26199 (* 1 = 1.26199 loss)
I0523 15:05:18.715906  1883 sgd_solver.cpp:106] Iteration 64500, lr = 0.0015
I0523 15:05:27.836402  1883 solver.cpp:237] Iteration 64750, loss = 1.16468
I0523 15:05:27.836443  1883 solver.cpp:253]     Train net output #0: loss = 1.16468 (* 1 = 1.16468 loss)
I0523 15:05:27.836462  1883 sgd_solver.cpp:106] Iteration 64750, lr = 0.0015
I0523 15:05:36.905014  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_65000.caffemodel
I0523 15:05:36.968361  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_65000.solverstate
I0523 15:05:37.004132  1883 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 15:06:24.337591  1883 solver.cpp:409]     Test net output #0: accuracy = 0.876261
I0523 15:06:24.337782  1883 solver.cpp:409]     Test net output #1: loss = 0.391002 (* 1 = 0.391002 loss)
I0523 15:06:45.290056  1883 solver.cpp:237] Iteration 65000, loss = 1.03343
I0523 15:06:45.290108  1883 solver.cpp:253]     Train net output #0: loss = 1.03343 (* 1 = 1.03343 loss)
I0523 15:06:45.290123  1883 sgd_solver.cpp:106] Iteration 65000, lr = 0.0015
I0523 15:06:54.366891  1883 solver.cpp:237] Iteration 65250, loss = 1.00954
I0523 15:06:54.367058  1883 solver.cpp:253]     Train net output #0: loss = 1.00954 (* 1 = 1.00954 loss)
I0523 15:06:54.367072  1883 sgd_solver.cpp:106] Iteration 65250, lr = 0.0015
I0523 15:07:03.450198  1883 solver.cpp:237] Iteration 65500, loss = 1.25277
I0523 15:07:03.450232  1883 solver.cpp:253]     Train net output #0: loss = 1.25277 (* 1 = 1.25277 loss)
I0523 15:07:03.450250  1883 sgd_solver.cpp:106] Iteration 65500, lr = 0.0015
I0523 15:07:12.535050  1883 solver.cpp:237] Iteration 65750, loss = 1.20921
I0523 15:07:12.535099  1883 solver.cpp:253]     Train net output #0: loss = 1.20921 (* 1 = 1.20921 loss)
I0523 15:07:12.535115  1883 sgd_solver.cpp:106] Iteration 65750, lr = 0.0015
I0523 15:07:21.615236  1883 solver.cpp:237] Iteration 66000, loss = 1.1866
I0523 15:07:21.615270  1883 solver.cpp:253]     Train net output #0: loss = 1.1866 (* 1 = 1.1866 loss)
I0523 15:07:21.615288  1883 sgd_solver.cpp:106] Iteration 66000, lr = 0.0015
I0523 15:07:30.685199  1883 solver.cpp:237] Iteration 66250, loss = 1.04568
I0523 15:07:30.685366  1883 solver.cpp:253]     Train net output #0: loss = 1.04568 (* 1 = 1.04568 loss)
I0523 15:07:30.685381  1883 sgd_solver.cpp:106] Iteration 66250, lr = 0.0015
I0523 15:07:39.768748  1883 solver.cpp:237] Iteration 66500, loss = 0.886167
I0523 15:07:39.768784  1883 solver.cpp:253]     Train net output #0: loss = 0.886167 (* 1 = 0.886167 loss)
I0523 15:07:39.768801  1883 sgd_solver.cpp:106] Iteration 66500, lr = 0.0015
I0523 15:08:09.827116  1883 solver.cpp:237] Iteration 66750, loss = 1.04817
I0523 15:08:09.827301  1883 solver.cpp:253]     Train net output #0: loss = 1.04817 (* 1 = 1.04817 loss)
I0523 15:08:09.827316  1883 sgd_solver.cpp:106] Iteration 66750, lr = 0.0015
I0523 15:08:18.897168  1883 solver.cpp:237] Iteration 67000, loss = 1.13892
I0523 15:08:18.897202  1883 solver.cpp:253]     Train net output #0: loss = 1.13892 (* 1 = 1.13892 loss)
I0523 15:08:18.897220  1883 sgd_solver.cpp:106] Iteration 67000, lr = 0.0015
I0523 15:08:27.965430  1883 solver.cpp:237] Iteration 67250, loss = 1.14392
I0523 15:08:27.965476  1883 solver.cpp:253]     Train net output #0: loss = 1.14392 (* 1 = 1.14392 loss)
I0523 15:08:27.965493  1883 sgd_solver.cpp:106] Iteration 67250, lr = 0.0015
I0523 15:08:36.974926  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_67500.caffemodel
I0523 15:08:37.037339  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_67500.solverstate
I0523 15:08:37.075193  1883 solver.cpp:237] Iteration 67500, loss = 0.993168
I0523 15:08:37.075239  1883 solver.cpp:253]     Train net output #0: loss = 0.993168 (* 1 = 0.993168 loss)
I0523 15:08:37.075256  1883 sgd_solver.cpp:106] Iteration 67500, lr = 0.0015
I0523 15:08:46.121335  1883 solver.cpp:237] Iteration 67750, loss = 1.10363
I0523 15:08:46.121500  1883 solver.cpp:253]     Train net output #0: loss = 1.10363 (* 1 = 1.10363 loss)
I0523 15:08:46.121513  1883 sgd_solver.cpp:106] Iteration 67750, lr = 0.0015
I0523 15:08:55.162828  1883 solver.cpp:237] Iteration 68000, loss = 1.16796
I0523 15:08:55.162863  1883 solver.cpp:253]     Train net output #0: loss = 1.16796 (* 1 = 1.16796 loss)
I0523 15:08:55.162879  1883 sgd_solver.cpp:106] Iteration 68000, lr = 0.0015
I0523 15:09:04.200390  1883 solver.cpp:237] Iteration 68250, loss = 0.865807
I0523 15:09:04.200425  1883 solver.cpp:253]     Train net output #0: loss = 0.865807 (* 1 = 0.865807 loss)
I0523 15:09:04.200441  1883 sgd_solver.cpp:106] Iteration 68250, lr = 0.0015
I0523 15:09:34.115721  1883 solver.cpp:237] Iteration 68500, loss = 1.01853
I0523 15:09:34.115914  1883 solver.cpp:253]     Train net output #0: loss = 1.01853 (* 1 = 1.01853 loss)
I0523 15:09:34.115929  1883 sgd_solver.cpp:106] Iteration 68500, lr = 0.0015
I0523 15:09:43.152230  1883 solver.cpp:237] Iteration 68750, loss = 1.33974
I0523 15:09:43.152273  1883 solver.cpp:253]     Train net output #0: loss = 1.33974 (* 1 = 1.33974 loss)
I0523 15:09:43.152292  1883 sgd_solver.cpp:106] Iteration 68750, lr = 0.0015
I0523 15:09:52.195767  1883 solver.cpp:237] Iteration 69000, loss = 1.29897
I0523 15:09:52.195801  1883 solver.cpp:253]     Train net output #0: loss = 1.29897 (* 1 = 1.29897 loss)
I0523 15:09:52.195818  1883 sgd_solver.cpp:106] Iteration 69000, lr = 0.0015
I0523 15:10:01.218901  1883 solver.cpp:237] Iteration 69250, loss = 1.03591
I0523 15:10:01.218947  1883 solver.cpp:253]     Train net output #0: loss = 1.03591 (* 1 = 1.03591 loss)
I0523 15:10:01.218963  1883 sgd_solver.cpp:106] Iteration 69250, lr = 0.0015
I0523 15:10:10.257120  1883 solver.cpp:237] Iteration 69500, loss = 1.24685
I0523 15:10:10.257285  1883 solver.cpp:253]     Train net output #0: loss = 1.24685 (* 1 = 1.24685 loss)
I0523 15:10:10.257299  1883 sgd_solver.cpp:106] Iteration 69500, lr = 0.0015
I0523 15:10:19.285506  1883 solver.cpp:237] Iteration 69750, loss = 1.20872
I0523 15:10:19.285540  1883 solver.cpp:253]     Train net output #0: loss = 1.20872 (* 1 = 1.20872 loss)
I0523 15:10:19.285557  1883 sgd_solver.cpp:106] Iteration 69750, lr = 0.0015
I0523 15:10:28.288221  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_70000.caffemodel
I0523 15:10:28.351089  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_70000.solverstate
I0523 15:10:28.377681  1883 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 15:11:36.528795  1883 solver.cpp:409]     Test net output #0: accuracy = 0.879146
I0523 15:11:36.528990  1883 solver.cpp:409]     Test net output #1: loss = 0.374502 (* 1 = 0.374502 loss)
I0523 15:11:57.370998  1883 solver.cpp:237] Iteration 70000, loss = 1.06191
I0523 15:11:57.371052  1883 solver.cpp:253]     Train net output #0: loss = 1.06191 (* 1 = 1.06191 loss)
I0523 15:11:57.371067  1883 sgd_solver.cpp:106] Iteration 70000, lr = 0.0015
I0523 15:12:06.468874  1883 solver.cpp:237] Iteration 70250, loss = 1.20001
I0523 15:12:06.468921  1883 solver.cpp:253]     Train net output #0: loss = 1.20001 (* 1 = 1.20001 loss)
I0523 15:12:06.468938  1883 sgd_solver.cpp:106] Iteration 70250, lr = 0.0015
I0523 15:12:15.571497  1883 solver.cpp:237] Iteration 70500, loss = 1.09512
I0523 15:12:15.571667  1883 solver.cpp:253]     Train net output #0: loss = 1.09512 (* 1 = 1.09512 loss)
I0523 15:12:15.571687  1883 sgd_solver.cpp:106] Iteration 70500, lr = 0.0015
I0523 15:12:24.670425  1883 solver.cpp:237] Iteration 70750, loss = 0.938585
I0523 15:12:24.670460  1883 solver.cpp:253]     Train net output #0: loss = 0.938585 (* 1 = 0.938585 loss)
I0523 15:12:24.670477  1883 sgd_solver.cpp:106] Iteration 70750, lr = 0.0015
I0523 15:12:33.766048  1883 solver.cpp:237] Iteration 71000, loss = 1.09914
I0523 15:12:33.766086  1883 solver.cpp:253]     Train net output #0: loss = 1.09914 (* 1 = 1.09914 loss)
I0523 15:12:33.766108  1883 sgd_solver.cpp:106] Iteration 71000, lr = 0.0015
I0523 15:12:42.862339  1883 solver.cpp:237] Iteration 71250, loss = 1.16128
I0523 15:12:42.862373  1883 solver.cpp:253]     Train net output #0: loss = 1.16128 (* 1 = 1.16128 loss)
I0523 15:12:42.862390  1883 sgd_solver.cpp:106] Iteration 71250, lr = 0.0015
I0523 15:12:51.955514  1883 solver.cpp:237] Iteration 71500, loss = 1.06044
I0523 15:12:51.955682  1883 solver.cpp:253]     Train net output #0: loss = 1.06044 (* 1 = 1.06044 loss)
I0523 15:12:51.955695  1883 sgd_solver.cpp:106] Iteration 71500, lr = 0.0015
I0523 15:13:21.916975  1883 solver.cpp:237] Iteration 71750, loss = 1.35569
I0523 15:13:21.917026  1883 solver.cpp:253]     Train net output #0: loss = 1.35569 (* 1 = 1.35569 loss)
I0523 15:13:21.917039  1883 sgd_solver.cpp:106] Iteration 71750, lr = 0.0015
I0523 15:13:31.007136  1883 solver.cpp:237] Iteration 72000, loss = 1.46498
I0523 15:13:31.007309  1883 solver.cpp:253]     Train net output #0: loss = 1.46498 (* 1 = 1.46498 loss)
I0523 15:13:31.007323  1883 sgd_solver.cpp:106] Iteration 72000, lr = 0.0015
I0523 15:13:40.097666  1883 solver.cpp:237] Iteration 72250, loss = 1.21273
I0523 15:13:40.097700  1883 solver.cpp:253]     Train net output #0: loss = 1.21273 (* 1 = 1.21273 loss)
I0523 15:13:40.097714  1883 sgd_solver.cpp:106] Iteration 72250, lr = 0.0015
I0523 15:13:49.161958  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_72500.caffemodel
I0523 15:13:49.225742  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_72500.solverstate
I0523 15:13:49.264837  1883 solver.cpp:237] Iteration 72500, loss = 1.18804
I0523 15:13:49.264888  1883 solver.cpp:253]     Train net output #0: loss = 1.18804 (* 1 = 1.18804 loss)
I0523 15:13:49.264904  1883 sgd_solver.cpp:106] Iteration 72500, lr = 0.0015
I0523 15:13:58.355842  1883 solver.cpp:237] Iteration 72750, loss = 1.20456
I0523 15:13:58.355878  1883 solver.cpp:253]     Train net output #0: loss = 1.20456 (* 1 = 1.20456 loss)
I0523 15:13:58.355893  1883 sgd_solver.cpp:106] Iteration 72750, lr = 0.0015
I0523 15:14:07.449410  1883 solver.cpp:237] Iteration 73000, loss = 1.31962
I0523 15:14:07.449592  1883 solver.cpp:253]     Train net output #0: loss = 1.31962 (* 1 = 1.31962 loss)
I0523 15:14:07.449606  1883 sgd_solver.cpp:106] Iteration 73000, lr = 0.0015
I0523 15:14:16.546769  1883 solver.cpp:237] Iteration 73250, loss = 0.783963
I0523 15:14:16.546811  1883 solver.cpp:253]     Train net output #0: loss = 0.783963 (* 1 = 0.783963 loss)
I0523 15:14:16.546828  1883 sgd_solver.cpp:106] Iteration 73250, lr = 0.0015
I0523 15:14:46.522994  1883 solver.cpp:237] Iteration 73500, loss = 1.09014
I0523 15:14:46.523180  1883 solver.cpp:253]     Train net output #0: loss = 1.09014 (* 1 = 1.09014 loss)
I0523 15:14:46.523195  1883 sgd_solver.cpp:106] Iteration 73500, lr = 0.0015
I0523 15:14:55.614478  1883 solver.cpp:237] Iteration 73750, loss = 1.20924
I0523 15:14:55.614512  1883 solver.cpp:253]     Train net output #0: loss = 1.20924 (* 1 = 1.20924 loss)
I0523 15:14:55.614531  1883 sgd_solver.cpp:106] Iteration 73750, lr = 0.0015
I0523 15:15:04.706266  1883 solver.cpp:237] Iteration 74000, loss = 1.08143
I0523 15:15:04.706308  1883 solver.cpp:253]     Train net output #0: loss = 1.08143 (* 1 = 1.08143 loss)
I0523 15:15:04.706323  1883 sgd_solver.cpp:106] Iteration 74000, lr = 0.0015
I0523 15:15:13.801398  1883 solver.cpp:237] Iteration 74250, loss = 1.4699
I0523 15:15:13.801432  1883 solver.cpp:253]     Train net output #0: loss = 1.4699 (* 1 = 1.4699 loss)
I0523 15:15:13.801448  1883 sgd_solver.cpp:106] Iteration 74250, lr = 0.0015
I0523 15:15:22.890863  1883 solver.cpp:237] Iteration 74500, loss = 1.1647
I0523 15:15:22.891027  1883 solver.cpp:253]     Train net output #0: loss = 1.1647 (* 1 = 1.1647 loss)
I0523 15:15:22.891041  1883 sgd_solver.cpp:106] Iteration 74500, lr = 0.0015
I0523 15:15:31.989336  1883 solver.cpp:237] Iteration 74750, loss = 1.09654
I0523 15:15:31.989380  1883 solver.cpp:253]     Train net output #0: loss = 1.09654 (* 1 = 1.09654 loss)
I0523 15:15:31.989398  1883 sgd_solver.cpp:106] Iteration 74750, lr = 0.0015
I0523 15:15:41.050096  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_75000.caffemodel
I0523 15:15:41.114311  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_75000.solverstate
I0523 15:15:41.144554  1883 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 15:16:28.180224  1883 solver.cpp:409]     Test net output #0: accuracy = 0.878967
I0523 15:16:28.180418  1883 solver.cpp:409]     Test net output #1: loss = 0.405727 (* 1 = 0.405727 loss)
I0523 15:16:49.092607  1883 solver.cpp:237] Iteration 75000, loss = 1.24806
I0523 15:16:49.092660  1883 solver.cpp:253]     Train net output #0: loss = 1.24806 (* 1 = 1.24806 loss)
I0523 15:16:49.092676  1883 sgd_solver.cpp:106] Iteration 75000, lr = 0.0015
I0523 15:16:58.127284  1883 solver.cpp:237] Iteration 75250, loss = 1.03381
I0523 15:16:58.127320  1883 solver.cpp:253]     Train net output #0: loss = 1.03381 (* 1 = 1.03381 loss)
I0523 15:16:58.127336  1883 sgd_solver.cpp:106] Iteration 75250, lr = 0.0015
I0523 15:17:07.166434  1883 solver.cpp:237] Iteration 75500, loss = 1.0271
I0523 15:17:07.166622  1883 solver.cpp:253]     Train net output #0: loss = 1.0271 (* 1 = 1.0271 loss)
I0523 15:17:07.166636  1883 sgd_solver.cpp:106] Iteration 75500, lr = 0.0015
I0523 15:17:16.204836  1883 solver.cpp:237] Iteration 75750, loss = 1.14931
I0523 15:17:16.204871  1883 solver.cpp:253]     Train net output #0: loss = 1.14931 (* 1 = 1.14931 loss)
I0523 15:17:16.204888  1883 sgd_solver.cpp:106] Iteration 75750, lr = 0.0015
I0523 15:17:25.237004  1883 solver.cpp:237] Iteration 76000, loss = 1.28517
I0523 15:17:25.237040  1883 solver.cpp:253]     Train net output #0: loss = 1.28517 (* 1 = 1.28517 loss)
I0523 15:17:25.237056  1883 sgd_solver.cpp:106] Iteration 76000, lr = 0.0015
I0523 15:17:34.271592  1883 solver.cpp:237] Iteration 76250, loss = 0.951604
I0523 15:17:34.271641  1883 solver.cpp:253]     Train net output #0: loss = 0.951604 (* 1 = 0.951604 loss)
I0523 15:17:34.271656  1883 sgd_solver.cpp:106] Iteration 76250, lr = 0.0015
I0523 15:17:43.312537  1883 solver.cpp:237] Iteration 76500, loss = 1.45987
I0523 15:17:43.312701  1883 solver.cpp:253]     Train net output #0: loss = 1.45987 (* 1 = 1.45987 loss)
I0523 15:17:43.312716  1883 sgd_solver.cpp:106] Iteration 76500, lr = 0.0015
I0523 15:18:13.229549  1883 solver.cpp:237] Iteration 76750, loss = 1.03221
I0523 15:18:13.229600  1883 solver.cpp:253]     Train net output #0: loss = 1.03221 (* 1 = 1.03221 loss)
I0523 15:18:13.229617  1883 sgd_solver.cpp:106] Iteration 76750, lr = 0.0015
I0523 15:18:22.268363  1883 solver.cpp:237] Iteration 77000, loss = 1.2693
I0523 15:18:22.268539  1883 solver.cpp:253]     Train net output #0: loss = 1.2693 (* 1 = 1.2693 loss)
I0523 15:18:22.268553  1883 sgd_solver.cpp:106] Iteration 77000, lr = 0.0015
I0523 15:18:31.306530  1883 solver.cpp:237] Iteration 77250, loss = 1.38019
I0523 15:18:31.306565  1883 solver.cpp:253]     Train net output #0: loss = 1.38019 (* 1 = 1.38019 loss)
I0523 15:18:31.306581  1883 sgd_solver.cpp:106] Iteration 77250, lr = 0.0015
I0523 15:18:40.307225  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_77500.caffemodel
I0523 15:18:40.370682  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_77500.solverstate
I0523 15:18:40.408793  1883 solver.cpp:237] Iteration 77500, loss = 1.18645
I0523 15:18:40.408838  1883 solver.cpp:253]     Train net output #0: loss = 1.18645 (* 1 = 1.18645 loss)
I0523 15:18:40.408852  1883 sgd_solver.cpp:106] Iteration 77500, lr = 0.0015
I0523 15:18:49.442862  1883 solver.cpp:237] Iteration 77750, loss = 1.11965
I0523 15:18:49.442911  1883 solver.cpp:253]     Train net output #0: loss = 1.11965 (* 1 = 1.11965 loss)
I0523 15:18:49.442927  1883 sgd_solver.cpp:106] Iteration 77750, lr = 0.0015
I0523 15:18:58.483407  1883 solver.cpp:237] Iteration 78000, loss = 1.19889
I0523 15:18:58.483587  1883 solver.cpp:253]     Train net output #0: loss = 1.19889 (* 1 = 1.19889 loss)
I0523 15:18:58.483599  1883 sgd_solver.cpp:106] Iteration 78000, lr = 0.0015
I0523 15:19:07.518234  1883 solver.cpp:237] Iteration 78250, loss = 1.14419
I0523 15:19:07.518268  1883 solver.cpp:253]     Train net output #0: loss = 1.14419 (* 1 = 1.14419 loss)
I0523 15:19:07.518286  1883 sgd_solver.cpp:106] Iteration 78250, lr = 0.0015
I0523 15:19:37.430327  1883 solver.cpp:237] Iteration 78500, loss = 1.23946
I0523 15:19:37.430515  1883 solver.cpp:253]     Train net output #0: loss = 1.23946 (* 1 = 1.23946 loss)
I0523 15:19:37.430528  1883 sgd_solver.cpp:106] Iteration 78500, lr = 0.0015
I0523 15:19:46.469764  1883 solver.cpp:237] Iteration 78750, loss = 1.12349
I0523 15:19:46.469799  1883 solver.cpp:253]     Train net output #0: loss = 1.12349 (* 1 = 1.12349 loss)
I0523 15:19:46.469817  1883 sgd_solver.cpp:106] Iteration 78750, lr = 0.0015
I0523 15:19:55.507315  1883 solver.cpp:237] Iteration 79000, loss = 1.21521
I0523 15:19:55.507350  1883 solver.cpp:253]     Train net output #0: loss = 1.21521 (* 1 = 1.21521 loss)
I0523 15:19:55.507367  1883 sgd_solver.cpp:106] Iteration 79000, lr = 0.0015
I0523 15:20:04.538363  1883 solver.cpp:237] Iteration 79250, loss = 1.081
I0523 15:20:04.538408  1883 solver.cpp:253]     Train net output #0: loss = 1.081 (* 1 = 1.081 loss)
I0523 15:20:04.538425  1883 sgd_solver.cpp:106] Iteration 79250, lr = 0.0015
I0523 15:20:13.572664  1883 solver.cpp:237] Iteration 79500, loss = 1.2674
I0523 15:20:13.572829  1883 solver.cpp:253]     Train net output #0: loss = 1.2674 (* 1 = 1.2674 loss)
I0523 15:20:13.572842  1883 sgd_solver.cpp:106] Iteration 79500, lr = 0.0015
I0523 15:20:22.611284  1883 solver.cpp:237] Iteration 79750, loss = 1.24679
I0523 15:20:22.611318  1883 solver.cpp:253]     Train net output #0: loss = 1.24679 (* 1 = 1.24679 loss)
I0523 15:20:22.611335  1883 sgd_solver.cpp:106] Iteration 79750, lr = 0.0015
I0523 15:20:31.611158  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_80000.caffemodel
I0523 15:20:31.673715  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_80000.solverstate
I0523 15:20:31.700356  1883 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 15:21:39.878154  1883 solver.cpp:409]     Test net output #0: accuracy = 0.882487
I0523 15:21:39.878340  1883 solver.cpp:409]     Test net output #1: loss = 0.360223 (* 1 = 0.360223 loss)
I0523 15:22:00.814841  1883 solver.cpp:237] Iteration 80000, loss = 1.28161
I0523 15:22:00.814893  1883 solver.cpp:253]     Train net output #0: loss = 1.28161 (* 1 = 1.28161 loss)
I0523 15:22:00.814909  1883 sgd_solver.cpp:106] Iteration 80000, lr = 0.0015
I0523 15:22:09.782451  1883 solver.cpp:237] Iteration 80250, loss = 1.41149
I0523 15:22:09.782491  1883 solver.cpp:253]     Train net output #0: loss = 1.41149 (* 1 = 1.41149 loss)
I0523 15:22:09.782512  1883 sgd_solver.cpp:106] Iteration 80250, lr = 0.0015
I0523 15:22:18.748894  1883 solver.cpp:237] Iteration 80500, loss = 1.12528
I0523 15:22:18.749066  1883 solver.cpp:253]     Train net output #0: loss = 1.12528 (* 1 = 1.12528 loss)
I0523 15:22:18.749079  1883 sgd_solver.cpp:106] Iteration 80500, lr = 0.0015
I0523 15:22:27.709770  1883 solver.cpp:237] Iteration 80750, loss = 1.21795
I0523 15:22:27.709803  1883 solver.cpp:253]     Train net output #0: loss = 1.21795 (* 1 = 1.21795 loss)
I0523 15:22:27.709821  1883 sgd_solver.cpp:106] Iteration 80750, lr = 0.0015
I0523 15:22:36.680621  1883 solver.cpp:237] Iteration 81000, loss = 1.30965
I0523 15:22:36.680662  1883 solver.cpp:253]     Train net output #0: loss = 1.30965 (* 1 = 1.30965 loss)
I0523 15:22:36.680680  1883 sgd_solver.cpp:106] Iteration 81000, lr = 0.0015
I0523 15:22:45.653223  1883 solver.cpp:237] Iteration 81250, loss = 1.09127
I0523 15:22:45.653257  1883 solver.cpp:253]     Train net output #0: loss = 1.09127 (* 1 = 1.09127 loss)
I0523 15:22:45.653275  1883 sgd_solver.cpp:106] Iteration 81250, lr = 0.0015
I0523 15:22:54.625208  1883 solver.cpp:237] Iteration 81500, loss = 1.27082
I0523 15:22:54.625385  1883 solver.cpp:253]     Train net output #0: loss = 1.27082 (* 1 = 1.27082 loss)
I0523 15:22:54.625399  1883 sgd_solver.cpp:106] Iteration 81500, lr = 0.0015
I0523 15:23:24.525919  1883 solver.cpp:237] Iteration 81750, loss = 1.25019
I0523 15:23:24.525969  1883 solver.cpp:253]     Train net output #0: loss = 1.25019 (* 1 = 1.25019 loss)
I0523 15:23:24.525985  1883 sgd_solver.cpp:106] Iteration 81750, lr = 0.0015
I0523 15:23:33.492444  1883 solver.cpp:237] Iteration 82000, loss = 1.13366
I0523 15:23:33.492617  1883 solver.cpp:253]     Train net output #0: loss = 1.13366 (* 1 = 1.13366 loss)
I0523 15:23:33.492631  1883 sgd_solver.cpp:106] Iteration 82000, lr = 0.0015
I0523 15:23:42.469604  1883 solver.cpp:237] Iteration 82250, loss = 1.14326
I0523 15:23:42.469637  1883 solver.cpp:253]     Train net output #0: loss = 1.14326 (* 1 = 1.14326 loss)
I0523 15:23:42.469655  1883 sgd_solver.cpp:106] Iteration 82250, lr = 0.0015
I0523 15:23:51.403417  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_82500.caffemodel
I0523 15:23:51.465644  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_82500.solverstate
I0523 15:23:51.503192  1883 solver.cpp:237] Iteration 82500, loss = 0.892586
I0523 15:23:51.503238  1883 solver.cpp:253]     Train net output #0: loss = 0.892586 (* 1 = 0.892586 loss)
I0523 15:23:51.503254  1883 sgd_solver.cpp:106] Iteration 82500, lr = 0.0015
I0523 15:24:00.472496  1883 solver.cpp:237] Iteration 82750, loss = 0.924946
I0523 15:24:00.472532  1883 solver.cpp:253]     Train net output #0: loss = 0.924946 (* 1 = 0.924946 loss)
I0523 15:24:00.472545  1883 sgd_solver.cpp:106] Iteration 82750, lr = 0.0015
I0523 15:24:09.446068  1883 solver.cpp:237] Iteration 83000, loss = 1.10627
I0523 15:24:09.446234  1883 solver.cpp:253]     Train net output #0: loss = 1.10627 (* 1 = 1.10627 loss)
I0523 15:24:09.446249  1883 sgd_solver.cpp:106] Iteration 83000, lr = 0.0015
I0523 15:24:18.413820  1883 solver.cpp:237] Iteration 83250, loss = 0.988345
I0523 15:24:18.413866  1883 solver.cpp:253]     Train net output #0: loss = 0.988345 (* 1 = 0.988345 loss)
I0523 15:24:18.413882  1883 sgd_solver.cpp:106] Iteration 83250, lr = 0.0015
I0523 15:24:48.298749  1883 solver.cpp:237] Iteration 83500, loss = 1.09175
I0523 15:24:48.298940  1883 solver.cpp:253]     Train net output #0: loss = 1.09175 (* 1 = 1.09175 loss)
I0523 15:24:48.298954  1883 sgd_solver.cpp:106] Iteration 83500, lr = 0.0015
I0523 15:24:57.273638  1883 solver.cpp:237] Iteration 83750, loss = 1.05421
I0523 15:24:57.273672  1883 solver.cpp:253]     Train net output #0: loss = 1.05421 (* 1 = 1.05421 loss)
I0523 15:24:57.273689  1883 sgd_solver.cpp:106] Iteration 83750, lr = 0.0015
I0523 15:25:06.234673  1883 solver.cpp:237] Iteration 84000, loss = 1.13073
I0523 15:25:06.234719  1883 solver.cpp:253]     Train net output #0: loss = 1.13073 (* 1 = 1.13073 loss)
I0523 15:25:06.234735  1883 sgd_solver.cpp:106] Iteration 84000, lr = 0.0015
I0523 15:25:15.207988  1883 solver.cpp:237] Iteration 84250, loss = 1.02417
I0523 15:25:15.208024  1883 solver.cpp:253]     Train net output #0: loss = 1.02417 (* 1 = 1.02417 loss)
I0523 15:25:15.208040  1883 sgd_solver.cpp:106] Iteration 84250, lr = 0.0015
I0523 15:25:24.186003  1883 solver.cpp:237] Iteration 84500, loss = 1.27327
I0523 15:25:24.186179  1883 solver.cpp:253]     Train net output #0: loss = 1.27327 (* 1 = 1.27327 loss)
I0523 15:25:24.186193  1883 sgd_solver.cpp:106] Iteration 84500, lr = 0.0015
I0523 15:25:33.155433  1883 solver.cpp:237] Iteration 84750, loss = 1.09338
I0523 15:25:33.155480  1883 solver.cpp:253]     Train net output #0: loss = 1.09338 (* 1 = 1.09338 loss)
I0523 15:25:33.155496  1883 sgd_solver.cpp:106] Iteration 84750, lr = 0.0015
I0523 15:25:42.090178  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_85000.caffemodel
I0523 15:25:42.154137  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_85000.solverstate
I0523 15:25:42.180593  1883 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 15:26:29.544306  1883 solver.cpp:409]     Test net output #0: accuracy = 0.881106
I0523 15:26:29.544500  1883 solver.cpp:409]     Test net output #1: loss = 0.398845 (* 1 = 0.398845 loss)
I0523 15:26:50.482640  1883 solver.cpp:237] Iteration 85000, loss = 0.917823
I0523 15:26:50.482693  1883 solver.cpp:253]     Train net output #0: loss = 0.917823 (* 1 = 0.917823 loss)
I0523 15:26:50.482712  1883 sgd_solver.cpp:106] Iteration 85000, lr = 0.0015
I0523 15:26:59.605890  1883 solver.cpp:237] Iteration 85250, loss = 1.36166
I0523 15:26:59.606070  1883 solver.cpp:253]     Train net output #0: loss = 1.36166 (* 1 = 1.36166 loss)
I0523 15:26:59.606082  1883 sgd_solver.cpp:106] Iteration 85250, lr = 0.0015
I0523 15:27:08.724298  1883 solver.cpp:237] Iteration 85500, loss = 1.17194
I0523 15:27:08.724341  1883 solver.cpp:253]     Train net output #0: loss = 1.17194 (* 1 = 1.17194 loss)
I0523 15:27:08.724359  1883 sgd_solver.cpp:106] Iteration 85500, lr = 0.0015
I0523 15:27:17.828160  1883 solver.cpp:237] Iteration 85750, loss = 1.1868
I0523 15:27:17.828193  1883 solver.cpp:253]     Train net output #0: loss = 1.1868 (* 1 = 1.1868 loss)
I0523 15:27:17.828212  1883 sgd_solver.cpp:106] Iteration 85750, lr = 0.0015
I0523 15:27:26.942891  1883 solver.cpp:237] Iteration 86000, loss = 1.2788
I0523 15:27:26.942927  1883 solver.cpp:253]     Train net output #0: loss = 1.2788 (* 1 = 1.2788 loss)
I0523 15:27:26.942944  1883 sgd_solver.cpp:106] Iteration 86000, lr = 0.0015
I0523 15:27:36.051512  1883 solver.cpp:237] Iteration 86250, loss = 1.13959
I0523 15:27:36.051694  1883 solver.cpp:253]     Train net output #0: loss = 1.13959 (* 1 = 1.13959 loss)
I0523 15:27:36.051708  1883 sgd_solver.cpp:106] Iteration 86250, lr = 0.0015
I0523 15:27:45.176864  1883 solver.cpp:237] Iteration 86500, loss = 1.17099
I0523 15:27:45.176899  1883 solver.cpp:253]     Train net output #0: loss = 1.17099 (* 1 = 1.17099 loss)
I0523 15:27:45.176918  1883 sgd_solver.cpp:106] Iteration 86500, lr = 0.0015
I0523 15:28:15.250872  1883 solver.cpp:237] Iteration 86750, loss = 1.15061
I0523 15:28:15.251066  1883 solver.cpp:253]     Train net output #0: loss = 1.15061 (* 1 = 1.15061 loss)
I0523 15:28:15.251082  1883 sgd_solver.cpp:106] Iteration 86750, lr = 0.0015
I0523 15:28:24.362467  1883 solver.cpp:237] Iteration 87000, loss = 1.0684
I0523 15:28:24.362509  1883 solver.cpp:253]     Train net output #0: loss = 1.0684 (* 1 = 1.0684 loss)
I0523 15:28:24.362522  1883 sgd_solver.cpp:106] Iteration 87000, lr = 0.0015
I0523 15:28:33.478852  1883 solver.cpp:237] Iteration 87250, loss = 1.09605
I0523 15:28:33.478886  1883 solver.cpp:253]     Train net output #0: loss = 1.09605 (* 1 = 1.09605 loss)
I0523 15:28:33.478904  1883 sgd_solver.cpp:106] Iteration 87250, lr = 0.0015
I0523 15:28:42.568812  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_87500.caffemodel
I0523 15:28:42.632644  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_87500.solverstate
I0523 15:28:42.673804  1883 solver.cpp:237] Iteration 87500, loss = 1.43399
I0523 15:28:42.673854  1883 solver.cpp:253]     Train net output #0: loss = 1.43399 (* 1 = 1.43399 loss)
I0523 15:28:42.673871  1883 sgd_solver.cpp:106] Iteration 87500, lr = 0.0015
I0523 15:28:51.805658  1883 solver.cpp:237] Iteration 87750, loss = 1.31253
I0523 15:28:51.805852  1883 solver.cpp:253]     Train net output #0: loss = 1.31253 (* 1 = 1.31253 loss)
I0523 15:28:51.805866  1883 sgd_solver.cpp:106] Iteration 87750, lr = 0.0015
I0523 15:29:00.928445  1883 solver.cpp:237] Iteration 88000, loss = 1.23573
I0523 15:29:00.928479  1883 solver.cpp:253]     Train net output #0: loss = 1.23573 (* 1 = 1.23573 loss)
I0523 15:29:00.928498  1883 sgd_solver.cpp:106] Iteration 88000, lr = 0.0015
I0523 15:29:10.058081  1883 solver.cpp:237] Iteration 88250, loss = 1.2839
I0523 15:29:10.058117  1883 solver.cpp:253]     Train net output #0: loss = 1.2839 (* 1 = 1.2839 loss)
I0523 15:29:10.058135  1883 sgd_solver.cpp:106] Iteration 88250, lr = 0.0015
I0523 15:29:40.097749  1883 solver.cpp:237] Iteration 88500, loss = 1.27988
I0523 15:29:40.097940  1883 solver.cpp:253]     Train net output #0: loss = 1.27988 (* 1 = 1.27988 loss)
I0523 15:29:40.097956  1883 sgd_solver.cpp:106] Iteration 88500, lr = 0.0015
I0523 15:29:49.228189  1883 solver.cpp:237] Iteration 88750, loss = 1.14082
I0523 15:29:49.228224  1883 solver.cpp:253]     Train net output #0: loss = 1.14082 (* 1 = 1.14082 loss)
I0523 15:29:49.228240  1883 sgd_solver.cpp:106] Iteration 88750, lr = 0.0015
I0523 15:29:58.349550  1883 solver.cpp:237] Iteration 89000, loss = 1.05041
I0523 15:29:58.349586  1883 solver.cpp:253]     Train net output #0: loss = 1.05041 (* 1 = 1.05041 loss)
I0523 15:29:58.349601  1883 sgd_solver.cpp:106] Iteration 89000, lr = 0.0015
I0523 15:30:07.449633  1883 solver.cpp:237] Iteration 89250, loss = 1.16326
I0523 15:30:07.449674  1883 solver.cpp:253]     Train net output #0: loss = 1.16326 (* 1 = 1.16326 loss)
I0523 15:30:07.449697  1883 sgd_solver.cpp:106] Iteration 89250, lr = 0.0015
I0523 15:30:16.536761  1883 solver.cpp:237] Iteration 89500, loss = 1.15286
I0523 15:30:16.536942  1883 solver.cpp:253]     Train net output #0: loss = 1.15286 (* 1 = 1.15286 loss)
I0523 15:30:16.536957  1883 sgd_solver.cpp:106] Iteration 89500, lr = 0.0015
I0523 15:30:25.607739  1883 solver.cpp:237] Iteration 89750, loss = 0.772751
I0523 15:30:25.607789  1883 solver.cpp:253]     Train net output #0: loss = 0.772751 (* 1 = 0.772751 loss)
I0523 15:30:25.607807  1883 sgd_solver.cpp:106] Iteration 89750, lr = 0.0015
I0523 15:30:34.653385  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_90000.caffemodel
I0523 15:30:34.719487  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_90000.solverstate
I0523 15:30:34.748564  1883 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 15:31:42.945770  1883 solver.cpp:409]     Test net output #0: accuracy = 0.884593
I0523 15:31:42.945966  1883 solver.cpp:409]     Test net output #1: loss = 0.371465 (* 1 = 0.371465 loss)
I0523 15:32:03.812150  1883 solver.cpp:237] Iteration 90000, loss = 0.889039
I0523 15:32:03.812206  1883 solver.cpp:253]     Train net output #0: loss = 0.889039 (* 1 = 0.889039 loss)
I0523 15:32:03.812222  1883 sgd_solver.cpp:106] Iteration 90000, lr = 0.0015
I0523 15:32:12.778980  1883 solver.cpp:237] Iteration 90250, loss = 1.33297
I0523 15:32:12.779024  1883 solver.cpp:253]     Train net output #0: loss = 1.33297 (* 1 = 1.33297 loss)
I0523 15:32:12.779042  1883 sgd_solver.cpp:106] Iteration 90250, lr = 0.0015
I0523 15:32:21.738366  1883 solver.cpp:237] Iteration 90500, loss = 0.988145
I0523 15:32:21.738536  1883 solver.cpp:253]     Train net output #0: loss = 0.988145 (* 1 = 0.988145 loss)
I0523 15:32:21.738550  1883 sgd_solver.cpp:106] Iteration 90500, lr = 0.0015
I0523 15:32:30.702930  1883 solver.cpp:237] Iteration 90750, loss = 1.35667
I0523 15:32:30.702975  1883 solver.cpp:253]     Train net output #0: loss = 1.35667 (* 1 = 1.35667 loss)
I0523 15:32:30.702993  1883 sgd_solver.cpp:106] Iteration 90750, lr = 0.0015
I0523 15:32:39.665249  1883 solver.cpp:237] Iteration 91000, loss = 1.32261
I0523 15:32:39.665284  1883 solver.cpp:253]     Train net output #0: loss = 1.32261 (* 1 = 1.32261 loss)
I0523 15:32:39.665300  1883 sgd_solver.cpp:106] Iteration 91000, lr = 0.0015
I0523 15:32:48.626924  1883 solver.cpp:237] Iteration 91250, loss = 1.24134
I0523 15:32:48.626958  1883 solver.cpp:253]     Train net output #0: loss = 1.24134 (* 1 = 1.24134 loss)
I0523 15:32:48.626974  1883 sgd_solver.cpp:106] Iteration 91250, lr = 0.0015
I0523 15:32:57.593520  1883 solver.cpp:237] Iteration 91500, loss = 1.0089
I0523 15:32:57.593724  1883 solver.cpp:253]     Train net output #0: loss = 1.0089 (* 1 = 1.0089 loss)
I0523 15:32:57.593739  1883 sgd_solver.cpp:106] Iteration 91500, lr = 0.0015
I0523 15:33:27.422823  1883 solver.cpp:237] Iteration 91750, loss = 1.40292
I0523 15:33:27.422875  1883 solver.cpp:253]     Train net output #0: loss = 1.40292 (* 1 = 1.40292 loss)
I0523 15:33:27.422891  1883 sgd_solver.cpp:106] Iteration 91750, lr = 0.0015
I0523 15:33:36.385412  1883 solver.cpp:237] Iteration 92000, loss = 1.23425
I0523 15:33:36.385587  1883 solver.cpp:253]     Train net output #0: loss = 1.23425 (* 1 = 1.23425 loss)
I0523 15:33:36.385601  1883 sgd_solver.cpp:106] Iteration 92000, lr = 0.0015
I0523 15:33:45.348868  1883 solver.cpp:237] Iteration 92250, loss = 1.07437
I0523 15:33:45.348901  1883 solver.cpp:253]     Train net output #0: loss = 1.07437 (* 1 = 1.07437 loss)
I0523 15:33:45.348919  1883 sgd_solver.cpp:106] Iteration 92250, lr = 0.0015
I0523 15:33:54.270097  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_92500.caffemodel
I0523 15:33:54.333310  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_92500.solverstate
I0523 15:33:54.371132  1883 solver.cpp:237] Iteration 92500, loss = 1.069
I0523 15:33:54.371172  1883 solver.cpp:253]     Train net output #0: loss = 1.069 (* 1 = 1.069 loss)
I0523 15:33:54.371193  1883 sgd_solver.cpp:106] Iteration 92500, lr = 0.0015
I0523 15:34:03.340147  1883 solver.cpp:237] Iteration 92750, loss = 1.00148
I0523 15:34:03.340183  1883 solver.cpp:253]     Train net output #0: loss = 1.00148 (* 1 = 1.00148 loss)
I0523 15:34:03.340199  1883 sgd_solver.cpp:106] Iteration 92750, lr = 0.0015
I0523 15:34:12.305606  1883 solver.cpp:237] Iteration 93000, loss = 1.06693
I0523 15:34:12.305794  1883 solver.cpp:253]     Train net output #0: loss = 1.06693 (* 1 = 1.06693 loss)
I0523 15:34:12.305807  1883 sgd_solver.cpp:106] Iteration 93000, lr = 0.0015
I0523 15:34:21.269182  1883 solver.cpp:237] Iteration 93250, loss = 1.0613
I0523 15:34:21.269217  1883 solver.cpp:253]     Train net output #0: loss = 1.0613 (* 1 = 1.0613 loss)
I0523 15:34:21.269232  1883 sgd_solver.cpp:106] Iteration 93250, lr = 0.0015
I0523 15:34:51.132220  1883 solver.cpp:237] Iteration 93500, loss = 1.1345
I0523 15:34:51.132416  1883 solver.cpp:253]     Train net output #0: loss = 1.1345 (* 1 = 1.1345 loss)
I0523 15:34:51.132429  1883 sgd_solver.cpp:106] Iteration 93500, lr = 0.0015
I0523 15:35:00.096156  1883 solver.cpp:237] Iteration 93750, loss = 1.3919
I0523 15:35:00.096190  1883 solver.cpp:253]     Train net output #0: loss = 1.3919 (* 1 = 1.3919 loss)
I0523 15:35:00.096209  1883 sgd_solver.cpp:106] Iteration 93750, lr = 0.0015
I0523 15:35:09.053195  1883 solver.cpp:237] Iteration 94000, loss = 1.10892
I0523 15:35:09.053241  1883 solver.cpp:253]     Train net output #0: loss = 1.10892 (* 1 = 1.10892 loss)
I0523 15:35:09.053257  1883 sgd_solver.cpp:106] Iteration 94000, lr = 0.0015
I0523 15:35:18.025384  1883 solver.cpp:237] Iteration 94250, loss = 1.2944
I0523 15:35:18.025419  1883 solver.cpp:253]     Train net output #0: loss = 1.2944 (* 1 = 1.2944 loss)
I0523 15:35:18.025435  1883 sgd_solver.cpp:106] Iteration 94250, lr = 0.0015
I0523 15:35:26.993832  1883 solver.cpp:237] Iteration 94500, loss = 1.14084
I0523 15:35:26.994031  1883 solver.cpp:253]     Train net output #0: loss = 1.14084 (* 1 = 1.14084 loss)
I0523 15:35:26.994045  1883 sgd_solver.cpp:106] Iteration 94500, lr = 0.0015
I0523 15:35:35.962507  1883 solver.cpp:237] Iteration 94750, loss = 1.16166
I0523 15:35:35.962541  1883 solver.cpp:253]     Train net output #0: loss = 1.16166 (* 1 = 1.16166 loss)
I0523 15:35:35.962558  1883 sgd_solver.cpp:106] Iteration 94750, lr = 0.0015
I0523 15:35:44.891587  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_95000.caffemodel
I0523 15:35:44.954375  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_95000.solverstate
I0523 15:35:44.980782  1883 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 15:36:31.939767  1883 solver.cpp:409]     Test net output #0: accuracy = 0.886219
I0523 15:36:31.939960  1883 solver.cpp:409]     Test net output #1: loss = 0.357526 (* 1 = 0.357526 loss)
I0523 15:36:52.835587  1883 solver.cpp:237] Iteration 95000, loss = 1.30196
I0523 15:36:52.835638  1883 solver.cpp:253]     Train net output #0: loss = 1.30196 (* 1 = 1.30196 loss)
I0523 15:36:52.835656  1883 sgd_solver.cpp:106] Iteration 95000, lr = 0.0015
I0523 15:37:01.894569  1883 solver.cpp:237] Iteration 95250, loss = 1.43148
I0523 15:37:01.894605  1883 solver.cpp:253]     Train net output #0: loss = 1.43148 (* 1 = 1.43148 loss)
I0523 15:37:01.894621  1883 sgd_solver.cpp:106] Iteration 95250, lr = 0.0015
I0523 15:37:10.946903  1883 solver.cpp:237] Iteration 95500, loss = 1.3123
I0523 15:37:10.947091  1883 solver.cpp:253]     Train net output #0: loss = 1.3123 (* 1 = 1.3123 loss)
I0523 15:37:10.947105  1883 sgd_solver.cpp:106] Iteration 95500, lr = 0.0015
I0523 15:37:20.003245  1883 solver.cpp:237] Iteration 95750, loss = 1.21926
I0523 15:37:20.003279  1883 solver.cpp:253]     Train net output #0: loss = 1.21926 (* 1 = 1.21926 loss)
I0523 15:37:20.003296  1883 sgd_solver.cpp:106] Iteration 95750, lr = 0.0015
I0523 15:37:29.055300  1883 solver.cpp:237] Iteration 96000, loss = 1.39829
I0523 15:37:29.055335  1883 solver.cpp:253]     Train net output #0: loss = 1.39829 (* 1 = 1.39829 loss)
I0523 15:37:29.055351  1883 sgd_solver.cpp:106] Iteration 96000, lr = 0.0015
I0523 15:37:38.099041  1883 solver.cpp:237] Iteration 96250, loss = 1.25315
I0523 15:37:38.099086  1883 solver.cpp:253]     Train net output #0: loss = 1.25315 (* 1 = 1.25315 loss)
I0523 15:37:38.099103  1883 sgd_solver.cpp:106] Iteration 96250, lr = 0.0015
I0523 15:37:47.148197  1883 solver.cpp:237] Iteration 96500, loss = 0.904139
I0523 15:37:47.148372  1883 solver.cpp:253]     Train net output #0: loss = 0.904139 (* 1 = 0.904139 loss)
I0523 15:37:47.148386  1883 sgd_solver.cpp:106] Iteration 96500, lr = 0.0015
I0523 15:38:17.067962  1883 solver.cpp:237] Iteration 96750, loss = 1.32167
I0523 15:38:17.068011  1883 solver.cpp:253]     Train net output #0: loss = 1.32167 (* 1 = 1.32167 loss)
I0523 15:38:17.068028  1883 sgd_solver.cpp:106] Iteration 96750, lr = 0.0015
I0523 15:38:26.117691  1883 solver.cpp:237] Iteration 97000, loss = 1.47842
I0523 15:38:26.117880  1883 solver.cpp:253]     Train net output #0: loss = 1.47842 (* 1 = 1.47842 loss)
I0523 15:38:26.117894  1883 sgd_solver.cpp:106] Iteration 97000, lr = 0.0015
I0523 15:38:35.175968  1883 solver.cpp:237] Iteration 97250, loss = 1.22097
I0523 15:38:35.176003  1883 solver.cpp:253]     Train net output #0: loss = 1.22097 (* 1 = 1.22097 loss)
I0523 15:38:35.176020  1883 sgd_solver.cpp:106] Iteration 97250, lr = 0.0015
I0523 15:38:44.191172  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_97500.caffemodel
I0523 15:38:44.254259  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_97500.solverstate
I0523 15:38:44.291752  1883 solver.cpp:237] Iteration 97500, loss = 1.17534
I0523 15:38:44.291797  1883 solver.cpp:253]     Train net output #0: loss = 1.17534 (* 1 = 1.17534 loss)
I0523 15:38:44.291811  1883 sgd_solver.cpp:106] Iteration 97500, lr = 0.0015
I0523 15:38:53.346766  1883 solver.cpp:237] Iteration 97750, loss = 1.22614
I0523 15:38:53.346813  1883 solver.cpp:253]     Train net output #0: loss = 1.22614 (* 1 = 1.22614 loss)
I0523 15:38:53.346829  1883 sgd_solver.cpp:106] Iteration 97750, lr = 0.0015
I0523 15:39:02.405493  1883 solver.cpp:237] Iteration 98000, loss = 1.18414
I0523 15:39:02.405681  1883 solver.cpp:253]     Train net output #0: loss = 1.18414 (* 1 = 1.18414 loss)
I0523 15:39:02.405695  1883 sgd_solver.cpp:106] Iteration 98000, lr = 0.0015
I0523 15:39:11.456351  1883 solver.cpp:237] Iteration 98250, loss = 0.999145
I0523 15:39:11.456398  1883 solver.cpp:253]     Train net output #0: loss = 0.999145 (* 1 = 0.999145 loss)
I0523 15:39:11.456413  1883 sgd_solver.cpp:106] Iteration 98250, lr = 0.0015
I0523 15:39:41.423605  1883 solver.cpp:237] Iteration 98500, loss = 1.18842
I0523 15:39:41.423805  1883 solver.cpp:253]     Train net output #0: loss = 1.18842 (* 1 = 1.18842 loss)
I0523 15:39:41.423820  1883 sgd_solver.cpp:106] Iteration 98500, lr = 0.0015
I0523 15:39:50.475087  1883 solver.cpp:237] Iteration 98750, loss = 1.28385
I0523 15:39:50.475121  1883 solver.cpp:253]     Train net output #0: loss = 1.28385 (* 1 = 1.28385 loss)
I0523 15:39:50.475139  1883 sgd_solver.cpp:106] Iteration 98750, lr = 0.0015
I0523 15:39:59.518724  1883 solver.cpp:237] Iteration 99000, loss = 1.12493
I0523 15:39:59.518757  1883 solver.cpp:253]     Train net output #0: loss = 1.12493 (* 1 = 1.12493 loss)
I0523 15:39:59.518776  1883 sgd_solver.cpp:106] Iteration 99000, lr = 0.0015
I0523 15:40:08.565616  1883 solver.cpp:237] Iteration 99250, loss = 1.27309
I0523 15:40:08.565654  1883 solver.cpp:253]     Train net output #0: loss = 1.27309 (* 1 = 1.27309 loss)
I0523 15:40:08.565671  1883 sgd_solver.cpp:106] Iteration 99250, lr = 0.0015
I0523 15:40:17.615399  1883 solver.cpp:237] Iteration 99500, loss = 1.03314
I0523 15:40:17.615568  1883 solver.cpp:253]     Train net output #0: loss = 1.03314 (* 1 = 1.03314 loss)
I0523 15:40:17.615581  1883 sgd_solver.cpp:106] Iteration 99500, lr = 0.0015
I0523 15:40:26.665835  1883 solver.cpp:237] Iteration 99750, loss = 1.24025
I0523 15:40:26.665879  1883 solver.cpp:253]     Train net output #0: loss = 1.24025 (* 1 = 1.24025 loss)
I0523 15:40:26.665896  1883 sgd_solver.cpp:106] Iteration 99750, lr = 0.0015
I0523 15:40:35.682509  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_100000.caffemodel
I0523 15:40:35.749492  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_100000.solverstate
I0523 15:40:35.776187  1883 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 15:41:44.058931  1883 solver.cpp:409]     Test net output #0: accuracy = 0.886406
I0523 15:41:44.059123  1883 solver.cpp:409]     Test net output #1: loss = 0.358237 (* 1 = 0.358237 loss)
I0523 15:42:04.988653  1883 solver.cpp:237] Iteration 100000, loss = 1.29569
I0523 15:42:04.988706  1883 solver.cpp:253]     Train net output #0: loss = 1.29569 (* 1 = 1.29569 loss)
I0523 15:42:04.988721  1883 sgd_solver.cpp:106] Iteration 100000, lr = 0.0015
I0523 15:42:14.094665  1883 solver.cpp:237] Iteration 100250, loss = 1.01612
I0523 15:42:14.094844  1883 solver.cpp:253]     Train net output #0: loss = 1.01612 (* 1 = 1.01612 loss)
I0523 15:42:14.094858  1883 sgd_solver.cpp:106] Iteration 100250, lr = 0.0015
I0523 15:42:23.203052  1883 solver.cpp:237] Iteration 100500, loss = 1.11251
I0523 15:42:23.203086  1883 solver.cpp:253]     Train net output #0: loss = 1.11251 (* 1 = 1.11251 loss)
I0523 15:42:23.203104  1883 sgd_solver.cpp:106] Iteration 100500, lr = 0.0015
I0523 15:42:32.331437  1883 solver.cpp:237] Iteration 100750, loss = 1.26048
I0523 15:42:32.331476  1883 solver.cpp:253]     Train net output #0: loss = 1.26048 (* 1 = 1.26048 loss)
I0523 15:42:32.331499  1883 sgd_solver.cpp:106] Iteration 100750, lr = 0.0015
I0523 15:42:41.456156  1883 solver.cpp:237] Iteration 101000, loss = 1.15047
I0523 15:42:41.456192  1883 solver.cpp:253]     Train net output #0: loss = 1.15047 (* 1 = 1.15047 loss)
I0523 15:42:41.456208  1883 sgd_solver.cpp:106] Iteration 101000, lr = 0.0015
I0523 15:42:50.573776  1883 solver.cpp:237] Iteration 101250, loss = 1.09648
I0523 15:42:50.573961  1883 solver.cpp:253]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0523 15:42:50.573974  1883 sgd_solver.cpp:106] Iteration 101250, lr = 0.0015
I0523 15:42:59.691933  1883 solver.cpp:237] Iteration 101500, loss = 1.32295
I0523 15:42:59.691975  1883 solver.cpp:253]     Train net output #0: loss = 1.32295 (* 1 = 1.32295 loss)
I0523 15:42:59.691993  1883 sgd_solver.cpp:106] Iteration 101500, lr = 0.0015
I0523 15:43:29.737589  1883 solver.cpp:237] Iteration 101750, loss = 1.35007
I0523 15:43:29.737787  1883 solver.cpp:253]     Train net output #0: loss = 1.35007 (* 1 = 1.35007 loss)
I0523 15:43:29.737803  1883 sgd_solver.cpp:106] Iteration 101750, lr = 0.0015
I0523 15:43:38.865965  1883 solver.cpp:237] Iteration 102000, loss = 1.08652
I0523 15:43:38.865999  1883 solver.cpp:253]     Train net output #0: loss = 1.08652 (* 1 = 1.08652 loss)
I0523 15:43:38.866017  1883 sgd_solver.cpp:106] Iteration 102000, lr = 0.0015
I0523 15:43:47.985802  1883 solver.cpp:237] Iteration 102250, loss = 1.56436
I0523 15:43:47.985843  1883 solver.cpp:253]     Train net output #0: loss = 1.56436 (* 1 = 1.56436 loss)
I0523 15:43:47.985862  1883 sgd_solver.cpp:106] Iteration 102250, lr = 0.0015
I0523 15:43:57.061108  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_102500.caffemodel
I0523 15:43:57.124367  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_102500.solverstate
I0523 15:43:57.161618  1883 solver.cpp:237] Iteration 102500, loss = 1.2635
I0523 15:43:57.161664  1883 solver.cpp:253]     Train net output #0: loss = 1.2635 (* 1 = 1.2635 loss)
I0523 15:43:57.161680  1883 sgd_solver.cpp:106] Iteration 102500, lr = 0.0015
I0523 15:44:06.293195  1883 solver.cpp:237] Iteration 102750, loss = 1.12127
I0523 15:44:06.293375  1883 solver.cpp:253]     Train net output #0: loss = 1.12127 (* 1 = 1.12127 loss)
I0523 15:44:06.293388  1883 sgd_solver.cpp:106] Iteration 102750, lr = 0.0015
I0523 15:44:15.404431  1883 solver.cpp:237] Iteration 103000, loss = 1.27618
I0523 15:44:15.404474  1883 solver.cpp:253]     Train net output #0: loss = 1.27618 (* 1 = 1.27618 loss)
I0523 15:44:15.404490  1883 sgd_solver.cpp:106] Iteration 103000, lr = 0.0015
I0523 15:44:24.529768  1883 solver.cpp:237] Iteration 103250, loss = 0.996772
I0523 15:44:24.529803  1883 solver.cpp:253]     Train net output #0: loss = 0.996772 (* 1 = 0.996772 loss)
I0523 15:44:24.529819  1883 sgd_solver.cpp:106] Iteration 103250, lr = 0.0015
I0523 15:44:54.582113  1883 solver.cpp:237] Iteration 103500, loss = 1.13142
I0523 15:44:54.582304  1883 solver.cpp:253]     Train net output #0: loss = 1.13142 (* 1 = 1.13142 loss)
I0523 15:44:54.582319  1883 sgd_solver.cpp:106] Iteration 103500, lr = 0.0015
I0523 15:45:03.705452  1883 solver.cpp:237] Iteration 103750, loss = 0.930275
I0523 15:45:03.705490  1883 solver.cpp:253]     Train net output #0: loss = 0.930275 (* 1 = 0.930275 loss)
I0523 15:45:03.705513  1883 sgd_solver.cpp:106] Iteration 103750, lr = 0.0015
I0523 15:45:12.817220  1883 solver.cpp:237] Iteration 104000, loss = 1.46013
I0523 15:45:12.817255  1883 solver.cpp:253]     Train net output #0: loss = 1.46013 (* 1 = 1.46013 loss)
I0523 15:45:12.817272  1883 sgd_solver.cpp:106] Iteration 104000, lr = 0.0015
I0523 15:45:21.928167  1883 solver.cpp:237] Iteration 104250, loss = 1.22947
I0523 15:45:21.928203  1883 solver.cpp:253]     Train net output #0: loss = 1.22947 (* 1 = 1.22947 loss)
I0523 15:45:21.928220  1883 sgd_solver.cpp:106] Iteration 104250, lr = 0.0015
I0523 15:45:31.040264  1883 solver.cpp:237] Iteration 104500, loss = 1.04631
I0523 15:45:31.040458  1883 solver.cpp:253]     Train net output #0: loss = 1.04631 (* 1 = 1.04631 loss)
I0523 15:45:31.040472  1883 sgd_solver.cpp:106] Iteration 104500, lr = 0.0015
I0523 15:45:40.165537  1883 solver.cpp:237] Iteration 104750, loss = 1.40119
I0523 15:45:40.165571  1883 solver.cpp:253]     Train net output #0: loss = 1.40119 (* 1 = 1.40119 loss)
I0523 15:45:40.165588  1883 sgd_solver.cpp:106] Iteration 104750, lr = 0.0015
I0523 15:45:49.259780  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_105000.caffemodel
I0523 15:45:49.323614  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_105000.solverstate
I0523 15:45:49.349925  1883 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 15:46:36.702076  1883 solver.cpp:409]     Test net output #0: accuracy = 0.880786
I0523 15:46:36.702272  1883 solver.cpp:409]     Test net output #1: loss = 0.363992 (* 1 = 0.363992 loss)
I0523 15:46:57.641667  1883 solver.cpp:237] Iteration 105000, loss = 1.0665
I0523 15:46:57.641721  1883 solver.cpp:253]     Train net output #0: loss = 1.0665 (* 1 = 1.0665 loss)
I0523 15:46:57.641737  1883 sgd_solver.cpp:106] Iteration 105000, lr = 0.0015
I0523 15:47:06.656751  1883 solver.cpp:237] Iteration 105250, loss = 1.14765
I0523 15:47:06.656798  1883 solver.cpp:253]     Train net output #0: loss = 1.14765 (* 1 = 1.14765 loss)
I0523 15:47:06.656816  1883 sgd_solver.cpp:106] Iteration 105250, lr = 0.0015
I0523 15:47:15.674479  1883 solver.cpp:237] Iteration 105500, loss = 1.1685
I0523 15:47:15.674655  1883 solver.cpp:253]     Train net output #0: loss = 1.1685 (* 1 = 1.1685 loss)
I0523 15:47:15.674669  1883 sgd_solver.cpp:106] Iteration 105500, lr = 0.0015
I0523 15:47:24.688412  1883 solver.cpp:237] Iteration 105750, loss = 1.13746
I0523 15:47:24.688446  1883 solver.cpp:253]     Train net output #0: loss = 1.13746 (* 1 = 1.13746 loss)
I0523 15:47:24.688463  1883 sgd_solver.cpp:106] Iteration 105750, lr = 0.0015
I0523 15:47:33.706840  1883 solver.cpp:237] Iteration 106000, loss = 1.26426
I0523 15:47:33.706889  1883 solver.cpp:253]     Train net output #0: loss = 1.26426 (* 1 = 1.26426 loss)
I0523 15:47:33.706903  1883 sgd_solver.cpp:106] Iteration 106000, lr = 0.0015
I0523 15:47:42.721750  1883 solver.cpp:237] Iteration 106250, loss = 1.36924
I0523 15:47:42.721786  1883 solver.cpp:253]     Train net output #0: loss = 1.36924 (* 1 = 1.36924 loss)
I0523 15:47:42.721802  1883 sgd_solver.cpp:106] Iteration 106250, lr = 0.0015
I0523 15:47:51.742075  1883 solver.cpp:237] Iteration 106500, loss = 1.08395
I0523 15:47:51.742250  1883 solver.cpp:253]     Train net output #0: loss = 1.08395 (* 1 = 1.08395 loss)
I0523 15:47:51.742264  1883 sgd_solver.cpp:106] Iteration 106500, lr = 0.0015
I0523 15:48:21.684844  1883 solver.cpp:237] Iteration 106750, loss = 1.18967
I0523 15:48:21.684895  1883 solver.cpp:253]     Train net output #0: loss = 1.18967 (* 1 = 1.18967 loss)
I0523 15:48:21.684911  1883 sgd_solver.cpp:106] Iteration 106750, lr = 0.0015
I0523 15:48:30.705096  1883 solver.cpp:237] Iteration 107000, loss = 1.20827
I0523 15:48:30.705286  1883 solver.cpp:253]     Train net output #0: loss = 1.20827 (* 1 = 1.20827 loss)
I0523 15:48:30.705299  1883 sgd_solver.cpp:106] Iteration 107000, lr = 0.0015
I0523 15:48:39.726212  1883 solver.cpp:237] Iteration 107250, loss = 1.31342
I0523 15:48:39.726248  1883 solver.cpp:253]     Train net output #0: loss = 1.31342 (* 1 = 1.31342 loss)
I0523 15:48:39.726264  1883 sgd_solver.cpp:106] Iteration 107250, lr = 0.0015
I0523 15:48:48.703717  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_107500.caffemodel
I0523 15:48:48.767065  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_107500.solverstate
I0523 15:48:48.803436  1883 solver.cpp:237] Iteration 107500, loss = 0.760786
I0523 15:48:48.803483  1883 solver.cpp:253]     Train net output #0: loss = 0.760786 (* 1 = 0.760786 loss)
I0523 15:48:48.803496  1883 sgd_solver.cpp:106] Iteration 107500, lr = 0.0015
I0523 15:48:57.816764  1883 solver.cpp:237] Iteration 107750, loss = 1.04456
I0523 15:48:57.816800  1883 solver.cpp:253]     Train net output #0: loss = 1.04456 (* 1 = 1.04456 loss)
I0523 15:48:57.816817  1883 sgd_solver.cpp:106] Iteration 107750, lr = 0.0015
I0523 15:49:06.833673  1883 solver.cpp:237] Iteration 108000, loss = 1.13622
I0523 15:49:06.833863  1883 solver.cpp:253]     Train net output #0: loss = 1.13622 (* 1 = 1.13622 loss)
I0523 15:49:06.833875  1883 sgd_solver.cpp:106] Iteration 108000, lr = 0.0015
I0523 15:49:15.850801  1883 solver.cpp:237] Iteration 108250, loss = 1.05219
I0523 15:49:15.850847  1883 solver.cpp:253]     Train net output #0: loss = 1.05219 (* 1 = 1.05219 loss)
I0523 15:49:15.850865  1883 sgd_solver.cpp:106] Iteration 108250, lr = 0.0015
I0523 15:49:45.785171  1883 solver.cpp:237] Iteration 108500, loss = 1.06916
I0523 15:49:45.785368  1883 solver.cpp:253]     Train net output #0: loss = 1.06916 (* 1 = 1.06916 loss)
I0523 15:49:45.785382  1883 sgd_solver.cpp:106] Iteration 108500, lr = 0.0015
I0523 15:49:54.803249  1883 solver.cpp:237] Iteration 108750, loss = 1.3033
I0523 15:49:54.803283  1883 solver.cpp:253]     Train net output #0: loss = 1.3033 (* 1 = 1.3033 loss)
I0523 15:49:54.803302  1883 sgd_solver.cpp:106] Iteration 108750, lr = 0.0015
I0523 15:50:03.821955  1883 solver.cpp:237] Iteration 109000, loss = 1.23015
I0523 15:50:03.821997  1883 solver.cpp:253]     Train net output #0: loss = 1.23015 (* 1 = 1.23015 loss)
I0523 15:50:03.822018  1883 sgd_solver.cpp:106] Iteration 109000, lr = 0.0015
I0523 15:50:12.838798  1883 solver.cpp:237] Iteration 109250, loss = 1.16179
I0523 15:50:12.838835  1883 solver.cpp:253]     Train net output #0: loss = 1.16179 (* 1 = 1.16179 loss)
I0523 15:50:12.838850  1883 sgd_solver.cpp:106] Iteration 109250, lr = 0.0015
I0523 15:50:21.861230  1883 solver.cpp:237] Iteration 109500, loss = 1.40231
I0523 15:50:21.861405  1883 solver.cpp:253]     Train net output #0: loss = 1.40231 (* 1 = 1.40231 loss)
I0523 15:50:21.861419  1883 sgd_solver.cpp:106] Iteration 109500, lr = 0.0015
I0523 15:50:30.883738  1883 solver.cpp:237] Iteration 109750, loss = 1.01096
I0523 15:50:30.883780  1883 solver.cpp:253]     Train net output #0: loss = 1.01096 (* 1 = 1.01096 loss)
I0523 15:50:30.883800  1883 sgd_solver.cpp:106] Iteration 109750, lr = 0.0015
I0523 15:50:39.868437  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_110000.caffemodel
I0523 15:50:39.938812  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_110000.solverstate
I0523 15:50:39.965154  1883 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 15:51:48.177706  1883 solver.cpp:409]     Test net output #0: accuracy = 0.889173
I0523 15:51:48.177902  1883 solver.cpp:409]     Test net output #1: loss = 0.364388 (* 1 = 0.364388 loss)
I0523 15:52:09.114163  1883 solver.cpp:237] Iteration 110000, loss = 1.16724
I0523 15:52:09.114218  1883 solver.cpp:253]     Train net output #0: loss = 1.16724 (* 1 = 1.16724 loss)
I0523 15:52:09.114233  1883 sgd_solver.cpp:106] Iteration 110000, lr = 0.0015
I0523 15:52:18.154502  1883 solver.cpp:237] Iteration 110250, loss = 1.33742
I0523 15:52:18.154538  1883 solver.cpp:253]     Train net output #0: loss = 1.33742 (* 1 = 1.33742 loss)
I0523 15:52:18.154551  1883 sgd_solver.cpp:106] Iteration 110250, lr = 0.0015
I0523 15:52:27.198367  1883 solver.cpp:237] Iteration 110500, loss = 1.38834
I0523 15:52:27.198565  1883 solver.cpp:253]     Train net output #0: loss = 1.38834 (* 1 = 1.38834 loss)
I0523 15:52:27.198578  1883 sgd_solver.cpp:106] Iteration 110500, lr = 0.0015
I0523 15:52:36.241451  1883 solver.cpp:237] Iteration 110750, loss = 1.21012
I0523 15:52:36.241500  1883 solver.cpp:253]     Train net output #0: loss = 1.21012 (* 1 = 1.21012 loss)
I0523 15:52:36.241516  1883 sgd_solver.cpp:106] Iteration 110750, lr = 0.0015
I0523 15:52:45.281939  1883 solver.cpp:237] Iteration 111000, loss = 1.13653
I0523 15:52:45.281975  1883 solver.cpp:253]     Train net output #0: loss = 1.13653 (* 1 = 1.13653 loss)
I0523 15:52:45.281991  1883 sgd_solver.cpp:106] Iteration 111000, lr = 0.0015
I0523 15:52:54.326494  1883 solver.cpp:237] Iteration 111250, loss = 1.12723
I0523 15:52:54.326529  1883 solver.cpp:253]     Train net output #0: loss = 1.12723 (* 1 = 1.12723 loss)
I0523 15:52:54.326545  1883 sgd_solver.cpp:106] Iteration 111250, lr = 0.0015
I0523 15:53:03.374392  1883 solver.cpp:237] Iteration 111500, loss = 1.00952
I0523 15:53:03.374588  1883 solver.cpp:253]     Train net output #0: loss = 1.00952 (* 1 = 1.00952 loss)
I0523 15:53:03.374603  1883 sgd_solver.cpp:106] Iteration 111500, lr = 0.0015
I0523 15:53:33.345196  1883 solver.cpp:237] Iteration 111750, loss = 1.23849
I0523 15:53:33.345247  1883 solver.cpp:253]     Train net output #0: loss = 1.23849 (* 1 = 1.23849 loss)
I0523 15:53:33.345263  1883 sgd_solver.cpp:106] Iteration 111750, lr = 0.0015
I0523 15:53:42.389637  1883 solver.cpp:237] Iteration 112000, loss = 1.1278
I0523 15:53:42.389816  1883 solver.cpp:253]     Train net output #0: loss = 1.1278 (* 1 = 1.1278 loss)
I0523 15:53:42.389829  1883 sgd_solver.cpp:106] Iteration 112000, lr = 0.0015
I0523 15:53:51.443517  1883 solver.cpp:237] Iteration 112250, loss = 1.21869
I0523 15:53:51.443562  1883 solver.cpp:253]     Train net output #0: loss = 1.21869 (* 1 = 1.21869 loss)
I0523 15:53:51.443579  1883 sgd_solver.cpp:106] Iteration 112250, lr = 0.0015
I0523 15:54:00.459452  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_112500.caffemodel
I0523 15:54:00.525308  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_112500.solverstate
I0523 15:54:00.564390  1883 solver.cpp:237] Iteration 112500, loss = 1.06515
I0523 15:54:00.564440  1883 solver.cpp:253]     Train net output #0: loss = 1.06515 (* 1 = 1.06515 loss)
I0523 15:54:00.564457  1883 sgd_solver.cpp:106] Iteration 112500, lr = 0.0015
I0523 15:54:09.613925  1883 solver.cpp:237] Iteration 112750, loss = 1.22826
I0523 15:54:09.613960  1883 solver.cpp:253]     Train net output #0: loss = 1.22826 (* 1 = 1.22826 loss)
I0523 15:54:09.613978  1883 sgd_solver.cpp:106] Iteration 112750, lr = 0.0015
I0523 15:54:18.661983  1883 solver.cpp:237] Iteration 113000, loss = 1.12586
I0523 15:54:18.662176  1883 solver.cpp:253]     Train net output #0: loss = 1.12586 (* 1 = 1.12586 loss)
I0523 15:54:18.662190  1883 sgd_solver.cpp:106] Iteration 113000, lr = 0.0015
I0523 15:54:27.711382  1883 solver.cpp:237] Iteration 113250, loss = 1.25409
I0523 15:54:27.711416  1883 solver.cpp:253]     Train net output #0: loss = 1.25409 (* 1 = 1.25409 loss)
I0523 15:54:27.711436  1883 sgd_solver.cpp:106] Iteration 113250, lr = 0.0015
I0523 15:54:57.681668  1883 solver.cpp:237] Iteration 113500, loss = 1.1254
I0523 15:54:57.681879  1883 solver.cpp:253]     Train net output #0: loss = 1.1254 (* 1 = 1.1254 loss)
I0523 15:54:57.681893  1883 sgd_solver.cpp:106] Iteration 113500, lr = 0.0015
I0523 15:55:06.732053  1883 solver.cpp:237] Iteration 113750, loss = 1.11119
I0523 15:55:06.732097  1883 solver.cpp:253]     Train net output #0: loss = 1.11119 (* 1 = 1.11119 loss)
I0523 15:55:06.732115  1883 sgd_solver.cpp:106] Iteration 113750, lr = 0.0015
I0523 15:55:15.776154  1883 solver.cpp:237] Iteration 114000, loss = 1.03166
I0523 15:55:15.776190  1883 solver.cpp:253]     Train net output #0: loss = 1.03166 (* 1 = 1.03166 loss)
I0523 15:55:15.776206  1883 sgd_solver.cpp:106] Iteration 114000, lr = 0.0015
I0523 15:55:24.822331  1883 solver.cpp:237] Iteration 114250, loss = 1.29743
I0523 15:55:24.822367  1883 solver.cpp:253]     Train net output #0: loss = 1.29743 (* 1 = 1.29743 loss)
I0523 15:55:24.822383  1883 sgd_solver.cpp:106] Iteration 114250, lr = 0.0015
I0523 15:55:33.866570  1883 solver.cpp:237] Iteration 114500, loss = 1.14002
I0523 15:55:33.866766  1883 solver.cpp:253]     Train net output #0: loss = 1.14002 (* 1 = 1.14002 loss)
I0523 15:55:33.866780  1883 sgd_solver.cpp:106] Iteration 114500, lr = 0.0015
I0523 15:55:42.909797  1883 solver.cpp:237] Iteration 114750, loss = 0.848137
I0523 15:55:42.909832  1883 solver.cpp:253]     Train net output #0: loss = 0.848137 (* 1 = 0.848137 loss)
I0523 15:55:42.909848  1883 sgd_solver.cpp:106] Iteration 114750, lr = 0.0015
I0523 15:55:51.926242  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_115000.caffemodel
I0523 15:55:51.989063  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_115000.solverstate
I0523 15:55:52.014441  1883 solver.cpp:341] Iteration 115000, Testing net (#0)
I0523 15:56:39.027678  1883 solver.cpp:409]     Test net output #0: accuracy = 0.883326
I0523 15:56:39.027879  1883 solver.cpp:409]     Test net output #1: loss = 0.353775 (* 1 = 0.353775 loss)
I0523 15:56:59.931099  1883 solver.cpp:237] Iteration 115000, loss = 1.15357
I0523 15:56:59.931151  1883 solver.cpp:253]     Train net output #0: loss = 1.15357 (* 1 = 1.15357 loss)
I0523 15:56:59.931167  1883 sgd_solver.cpp:106] Iteration 115000, lr = 0.0015
I0523 15:57:09.021775  1883 solver.cpp:237] Iteration 115250, loss = 0.913115
I0523 15:57:09.021817  1883 solver.cpp:253]     Train net output #0: loss = 0.913115 (* 1 = 0.913115 loss)
I0523 15:57:09.021836  1883 sgd_solver.cpp:106] Iteration 115250, lr = 0.0015
I0523 15:57:18.112514  1883 solver.cpp:237] Iteration 115500, loss = 1.2623
I0523 15:57:18.112763  1883 solver.cpp:253]     Train net output #0: loss = 1.2623 (* 1 = 1.2623 loss)
I0523 15:57:18.112777  1883 sgd_solver.cpp:106] Iteration 115500, lr = 0.0015
I0523 15:57:27.189275  1883 solver.cpp:237] Iteration 115750, loss = 1.33538
I0523 15:57:27.189309  1883 solver.cpp:253]     Train net output #0: loss = 1.33538 (* 1 = 1.33538 loss)
I0523 15:57:27.189327  1883 sgd_solver.cpp:106] Iteration 115750, lr = 0.0015
I0523 15:57:36.261878  1883 solver.cpp:237] Iteration 116000, loss = 1.33922
I0523 15:57:36.261924  1883 solver.cpp:253]     Train net output #0: loss = 1.33922 (* 1 = 1.33922 loss)
I0523 15:57:36.261939  1883 sgd_solver.cpp:106] Iteration 116000, lr = 0.0015
I0523 15:57:45.355875  1883 solver.cpp:237] Iteration 116250, loss = 1.12522
I0523 15:57:45.355909  1883 solver.cpp:253]     Train net output #0: loss = 1.12522 (* 1 = 1.12522 loss)
I0523 15:57:45.355926  1883 sgd_solver.cpp:106] Iteration 116250, lr = 0.0015
I0523 15:57:54.443539  1883 solver.cpp:237] Iteration 116500, loss = 0.852171
I0523 15:57:54.443724  1883 solver.cpp:253]     Train net output #0: loss = 0.852171 (* 1 = 0.852171 loss)
I0523 15:57:54.443739  1883 sgd_solver.cpp:106] Iteration 116500, lr = 0.0015
I0523 15:58:24.466626  1883 solver.cpp:237] Iteration 116750, loss = 1.38862
I0523 15:58:24.466838  1883 solver.cpp:253]     Train net output #0: loss = 1.38862 (* 1 = 1.38862 loss)
I0523 15:58:24.466852  1883 sgd_solver.cpp:106] Iteration 116750, lr = 0.0015
I0523 15:58:33.557880  1883 solver.cpp:237] Iteration 117000, loss = 0.999035
I0523 15:58:33.557914  1883 solver.cpp:253]     Train net output #0: loss = 0.999035 (* 1 = 0.999035 loss)
I0523 15:58:33.557932  1883 sgd_solver.cpp:106] Iteration 117000, lr = 0.0015
I0523 15:58:42.650162  1883 solver.cpp:237] Iteration 117250, loss = 1.06281
I0523 15:58:42.650197  1883 solver.cpp:253]     Train net output #0: loss = 1.06281 (* 1 = 1.06281 loss)
I0523 15:58:42.650214  1883 sgd_solver.cpp:106] Iteration 117250, lr = 0.0015
I0523 15:58:51.709200  1883 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_117500.caffemodel
I0523 15:58:51.772241  1883 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0015_2016-05-20T15.49.09.548601_iter_117500.solverstate
I0523 15:58:51.808871  1883 solver.cpp:237] Iteration 117500, loss = 1.14985
I0523 15:58:51.808915  1883 solver.cpp:253]     Train net output #0: loss = 1.14985 (* 1 = 1.14985 loss)
I0523 15:58:51.808930  1883 sgd_solver.cpp:106] Iteration 117500, lr = 0.0015
I0523 15:59:00.883093  1883 solver.cpp:237] Iteration 117750, loss = 1.08337
I0523 15:59:00.883280  1883 solver.cpp:253]     Train net output #0: loss = 1.08337 (* 1 = 1.08337 loss)
I0523 15:59:00.883294  1883 sgd_solver.cpp:106] Iteration 117750, lr = 0.0015
I0523 15:59:09.965034  1883 solver.cpp:237] Iteration 118000, loss = 0.904941
I0523 15:59:09.965070  1883 solver.cpp:253]     Train net output #0: loss = 0.904941 (* 1 = 0.904941 loss)
I0523 15:59:09.965086  1883 sgd_solver.cpp:106] Iteration 118000, lr = 0.0015
I0523 15:59:19.057776  1883 solver.cpp:237] Iteration 118250, loss = 1.02595
I0523 15:59:19.057819  1883 solver.cpp:253]     Train net output #0: loss = 1.02595 (* 1 = 1.02595 loss)
I0523 15:59:19.057837  1883 sgd_solver.cpp:106] Iteration 118250, lr = 0.0015
I0523 15:59:49.066660  1883 solver.cpp:237] Iteration 118500, loss = 1.00307
I0523 15:59:49.066865  1883 solver.cpp:253]     Train net output #0: loss = 1.00307 (* 1 = 1.00307 loss)
I0523 15:59:49.066879  1883 sgd_solver.cpp:106] Iteration 118500, lr = 0.0015
I0523 15:59:58.162914  1883 solver.cpp:237] Iteration 118750, loss = 1.29624
I0523 15:59:58.162948  1883 solver.cpp:253]     Train net output #0: loss = 1.29624 (* 1 = 1.29624 loss)
I0523 15:59:58.162963  1883 sgd_solver.cpp:106] Iteration 118750, lr = 0.0015
aprun: Apid 11255869: Caught signal Terminated, sending to application
*** Aborted at 1464033599 (unix time) try "date -d @1464033599" if you are using GNU date ***
=>> PBS: job killed: walltime 7236 exceeded limit 7200
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x758) received by PID 1883 (TID 0x2aaac746f900) from PID 1880; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11255869: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11255869: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11255869: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11255869: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11255869: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
aprun: Apid 11255869: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02258] [c4-1c0s6n2] [Mon May 23 16:00:01 2016] PE RANK 0 exit signal Terminated
Application 11255869 exit codes: 143
Application 11255869 resources: utime ~6250s, stime ~969s, Rss ~5330868, inblocks ~16156521, outblocks ~725748
