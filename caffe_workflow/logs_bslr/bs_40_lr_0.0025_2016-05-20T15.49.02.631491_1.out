2807824
I0522 19:51:22.832528 22569 caffe.cpp:184] Using GPUs 0
I0522 19:51:23.258117 22569 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0025
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491.prototxt"
I0522 19:51:23.259969 22569 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491.prototxt
I0522 19:51:23.276828 22569 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 19:51:23.276897 22569 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 19:51:23.277251 22569 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 19:51:23.277433 22569 layer_factory.hpp:77] Creating layer data_hdf5
I0522 19:51:23.277456 22569 net.cpp:106] Creating Layer data_hdf5
I0522 19:51:23.277472 22569 net.cpp:411] data_hdf5 -> data
I0522 19:51:23.277505 22569 net.cpp:411] data_hdf5 -> label
I0522 19:51:23.277539 22569 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 19:51:23.287374 22569 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 19:51:23.305939 22569 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 19:51:44.870512 22569 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 19:51:44.875676 22569 net.cpp:150] Setting up data_hdf5
I0522 19:51:44.875716 22569 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 19:51:44.875731 22569 net.cpp:157] Top shape: 40 (40)
I0522 19:51:44.875742 22569 net.cpp:165] Memory required for data: 1016160
I0522 19:51:44.875756 22569 layer_factory.hpp:77] Creating layer conv1
I0522 19:51:44.875789 22569 net.cpp:106] Creating Layer conv1
I0522 19:51:44.875800 22569 net.cpp:454] conv1 <- data
I0522 19:51:44.875821 22569 net.cpp:411] conv1 -> conv1
I0522 19:51:49.398877 22569 net.cpp:150] Setting up conv1
I0522 19:51:49.398924 22569 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 19:51:49.398936 22569 net.cpp:165] Memory required for data: 12075360
I0522 19:51:49.398964 22569 layer_factory.hpp:77] Creating layer relu1
I0522 19:51:49.398986 22569 net.cpp:106] Creating Layer relu1
I0522 19:51:49.398996 22569 net.cpp:454] relu1 <- conv1
I0522 19:51:49.399010 22569 net.cpp:397] relu1 -> conv1 (in-place)
I0522 19:51:49.399526 22569 net.cpp:150] Setting up relu1
I0522 19:51:49.399543 22569 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 19:51:49.399552 22569 net.cpp:165] Memory required for data: 23134560
I0522 19:51:49.399564 22569 layer_factory.hpp:77] Creating layer pool1
I0522 19:51:49.399580 22569 net.cpp:106] Creating Layer pool1
I0522 19:51:49.399590 22569 net.cpp:454] pool1 <- conv1
I0522 19:51:49.399602 22569 net.cpp:411] pool1 -> pool1
I0522 19:51:49.399682 22569 net.cpp:150] Setting up pool1
I0522 19:51:49.399695 22569 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 19:51:49.399705 22569 net.cpp:165] Memory required for data: 28664160
I0522 19:51:49.399715 22569 layer_factory.hpp:77] Creating layer conv2
I0522 19:51:49.399735 22569 net.cpp:106] Creating Layer conv2
I0522 19:51:49.399746 22569 net.cpp:454] conv2 <- pool1
I0522 19:51:49.399760 22569 net.cpp:411] conv2 -> conv2
I0522 19:51:49.402432 22569 net.cpp:150] Setting up conv2
I0522 19:51:49.402461 22569 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 19:51:49.402472 22569 net.cpp:165] Memory required for data: 36612960
I0522 19:51:49.402493 22569 layer_factory.hpp:77] Creating layer relu2
I0522 19:51:49.402506 22569 net.cpp:106] Creating Layer relu2
I0522 19:51:49.402516 22569 net.cpp:454] relu2 <- conv2
I0522 19:51:49.402529 22569 net.cpp:397] relu2 -> conv2 (in-place)
I0522 19:51:49.402859 22569 net.cpp:150] Setting up relu2
I0522 19:51:49.402873 22569 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 19:51:49.402884 22569 net.cpp:165] Memory required for data: 44561760
I0522 19:51:49.402894 22569 layer_factory.hpp:77] Creating layer pool2
I0522 19:51:49.402906 22569 net.cpp:106] Creating Layer pool2
I0522 19:51:49.402916 22569 net.cpp:454] pool2 <- conv2
I0522 19:51:49.402928 22569 net.cpp:411] pool2 -> pool2
I0522 19:51:49.403009 22569 net.cpp:150] Setting up pool2
I0522 19:51:49.403023 22569 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 19:51:49.403033 22569 net.cpp:165] Memory required for data: 48536160
I0522 19:51:49.403043 22569 layer_factory.hpp:77] Creating layer conv3
I0522 19:51:49.403059 22569 net.cpp:106] Creating Layer conv3
I0522 19:51:49.403069 22569 net.cpp:454] conv3 <- pool2
I0522 19:51:49.403082 22569 net.cpp:411] conv3 -> conv3
I0522 19:51:49.405030 22569 net.cpp:150] Setting up conv3
I0522 19:51:49.405053 22569 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 19:51:49.405066 22569 net.cpp:165] Memory required for data: 52872800
I0522 19:51:49.405084 22569 layer_factory.hpp:77] Creating layer relu3
I0522 19:51:49.405100 22569 net.cpp:106] Creating Layer relu3
I0522 19:51:49.405110 22569 net.cpp:454] relu3 <- conv3
I0522 19:51:49.405123 22569 net.cpp:397] relu3 -> conv3 (in-place)
I0522 19:51:49.405597 22569 net.cpp:150] Setting up relu3
I0522 19:51:49.405614 22569 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 19:51:49.405624 22569 net.cpp:165] Memory required for data: 57209440
I0522 19:51:49.405635 22569 layer_factory.hpp:77] Creating layer pool3
I0522 19:51:49.405648 22569 net.cpp:106] Creating Layer pool3
I0522 19:51:49.405658 22569 net.cpp:454] pool3 <- conv3
I0522 19:51:49.405670 22569 net.cpp:411] pool3 -> pool3
I0522 19:51:49.405738 22569 net.cpp:150] Setting up pool3
I0522 19:51:49.405750 22569 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 19:51:49.405761 22569 net.cpp:165] Memory required for data: 59377760
I0522 19:51:49.405771 22569 layer_factory.hpp:77] Creating layer conv4
I0522 19:51:49.405786 22569 net.cpp:106] Creating Layer conv4
I0522 19:51:49.405797 22569 net.cpp:454] conv4 <- pool3
I0522 19:51:49.405812 22569 net.cpp:411] conv4 -> conv4
I0522 19:51:49.408561 22569 net.cpp:150] Setting up conv4
I0522 19:51:49.408589 22569 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 19:51:49.408601 22569 net.cpp:165] Memory required for data: 60829280
I0522 19:51:49.408615 22569 layer_factory.hpp:77] Creating layer relu4
I0522 19:51:49.408629 22569 net.cpp:106] Creating Layer relu4
I0522 19:51:49.408640 22569 net.cpp:454] relu4 <- conv4
I0522 19:51:49.408654 22569 net.cpp:397] relu4 -> conv4 (in-place)
I0522 19:51:49.409139 22569 net.cpp:150] Setting up relu4
I0522 19:51:49.409157 22569 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 19:51:49.409168 22569 net.cpp:165] Memory required for data: 62280800
I0522 19:51:49.409178 22569 layer_factory.hpp:77] Creating layer pool4
I0522 19:51:49.409191 22569 net.cpp:106] Creating Layer pool4
I0522 19:51:49.409201 22569 net.cpp:454] pool4 <- conv4
I0522 19:51:49.409214 22569 net.cpp:411] pool4 -> pool4
I0522 19:51:49.409282 22569 net.cpp:150] Setting up pool4
I0522 19:51:49.409296 22569 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 19:51:49.409307 22569 net.cpp:165] Memory required for data: 63006560
I0522 19:51:49.409317 22569 layer_factory.hpp:77] Creating layer ip1
I0522 19:51:49.409335 22569 net.cpp:106] Creating Layer ip1
I0522 19:51:49.409345 22569 net.cpp:454] ip1 <- pool4
I0522 19:51:49.409359 22569 net.cpp:411] ip1 -> ip1
I0522 19:51:49.424794 22569 net.cpp:150] Setting up ip1
I0522 19:51:49.424823 22569 net.cpp:157] Top shape: 40 196 (7840)
I0522 19:51:49.424837 22569 net.cpp:165] Memory required for data: 63037920
I0522 19:51:49.424860 22569 layer_factory.hpp:77] Creating layer relu5
I0522 19:51:49.424880 22569 net.cpp:106] Creating Layer relu5
I0522 19:51:49.424890 22569 net.cpp:454] relu5 <- ip1
I0522 19:51:49.424903 22569 net.cpp:397] relu5 -> ip1 (in-place)
I0522 19:51:49.425246 22569 net.cpp:150] Setting up relu5
I0522 19:51:49.425261 22569 net.cpp:157] Top shape: 40 196 (7840)
I0522 19:51:49.425271 22569 net.cpp:165] Memory required for data: 63069280
I0522 19:51:49.425281 22569 layer_factory.hpp:77] Creating layer drop1
I0522 19:51:49.425303 22569 net.cpp:106] Creating Layer drop1
I0522 19:51:49.425313 22569 net.cpp:454] drop1 <- ip1
I0522 19:51:49.425325 22569 net.cpp:397] drop1 -> ip1 (in-place)
I0522 19:51:49.425389 22569 net.cpp:150] Setting up drop1
I0522 19:51:49.425401 22569 net.cpp:157] Top shape: 40 196 (7840)
I0522 19:51:49.425411 22569 net.cpp:165] Memory required for data: 63100640
I0522 19:51:49.425421 22569 layer_factory.hpp:77] Creating layer ip2
I0522 19:51:49.425439 22569 net.cpp:106] Creating Layer ip2
I0522 19:51:49.425449 22569 net.cpp:454] ip2 <- ip1
I0522 19:51:49.425462 22569 net.cpp:411] ip2 -> ip2
I0522 19:51:49.425925 22569 net.cpp:150] Setting up ip2
I0522 19:51:49.425937 22569 net.cpp:157] Top shape: 40 98 (3920)
I0522 19:51:49.425946 22569 net.cpp:165] Memory required for data: 63116320
I0522 19:51:49.425961 22569 layer_factory.hpp:77] Creating layer relu6
I0522 19:51:49.425974 22569 net.cpp:106] Creating Layer relu6
I0522 19:51:49.425983 22569 net.cpp:454] relu6 <- ip2
I0522 19:51:49.425995 22569 net.cpp:397] relu6 -> ip2 (in-place)
I0522 19:51:49.426511 22569 net.cpp:150] Setting up relu6
I0522 19:51:49.426527 22569 net.cpp:157] Top shape: 40 98 (3920)
I0522 19:51:49.426538 22569 net.cpp:165] Memory required for data: 63132000
I0522 19:51:49.426549 22569 layer_factory.hpp:77] Creating layer drop2
I0522 19:51:49.426563 22569 net.cpp:106] Creating Layer drop2
I0522 19:51:49.426573 22569 net.cpp:454] drop2 <- ip2
I0522 19:51:49.426585 22569 net.cpp:397] drop2 -> ip2 (in-place)
I0522 19:51:49.426627 22569 net.cpp:150] Setting up drop2
I0522 19:51:49.426642 22569 net.cpp:157] Top shape: 40 98 (3920)
I0522 19:51:49.426652 22569 net.cpp:165] Memory required for data: 63147680
I0522 19:51:49.426661 22569 layer_factory.hpp:77] Creating layer ip3
I0522 19:51:49.426676 22569 net.cpp:106] Creating Layer ip3
I0522 19:51:49.426686 22569 net.cpp:454] ip3 <- ip2
I0522 19:51:49.426698 22569 net.cpp:411] ip3 -> ip3
I0522 19:51:49.426908 22569 net.cpp:150] Setting up ip3
I0522 19:51:49.426920 22569 net.cpp:157] Top shape: 40 11 (440)
I0522 19:51:49.426930 22569 net.cpp:165] Memory required for data: 63149440
I0522 19:51:49.426945 22569 layer_factory.hpp:77] Creating layer drop3
I0522 19:51:49.426959 22569 net.cpp:106] Creating Layer drop3
I0522 19:51:49.426967 22569 net.cpp:454] drop3 <- ip3
I0522 19:51:49.426980 22569 net.cpp:397] drop3 -> ip3 (in-place)
I0522 19:51:49.427019 22569 net.cpp:150] Setting up drop3
I0522 19:51:49.427032 22569 net.cpp:157] Top shape: 40 11 (440)
I0522 19:51:49.427042 22569 net.cpp:165] Memory required for data: 63151200
I0522 19:51:49.427052 22569 layer_factory.hpp:77] Creating layer loss
I0522 19:51:49.427072 22569 net.cpp:106] Creating Layer loss
I0522 19:51:49.427081 22569 net.cpp:454] loss <- ip3
I0522 19:51:49.427093 22569 net.cpp:454] loss <- label
I0522 19:51:49.427104 22569 net.cpp:411] loss -> loss
I0522 19:51:49.427121 22569 layer_factory.hpp:77] Creating layer loss
I0522 19:51:49.427759 22569 net.cpp:150] Setting up loss
I0522 19:51:49.427779 22569 net.cpp:157] Top shape: (1)
I0522 19:51:49.427793 22569 net.cpp:160]     with loss weight 1
I0522 19:51:49.427835 22569 net.cpp:165] Memory required for data: 63151204
I0522 19:51:49.427846 22569 net.cpp:226] loss needs backward computation.
I0522 19:51:49.427857 22569 net.cpp:226] drop3 needs backward computation.
I0522 19:51:49.427867 22569 net.cpp:226] ip3 needs backward computation.
I0522 19:51:49.427876 22569 net.cpp:226] drop2 needs backward computation.
I0522 19:51:49.427886 22569 net.cpp:226] relu6 needs backward computation.
I0522 19:51:49.427896 22569 net.cpp:226] ip2 needs backward computation.
I0522 19:51:49.427906 22569 net.cpp:226] drop1 needs backward computation.
I0522 19:51:49.427916 22569 net.cpp:226] relu5 needs backward computation.
I0522 19:51:49.427925 22569 net.cpp:226] ip1 needs backward computation.
I0522 19:51:49.427935 22569 net.cpp:226] pool4 needs backward computation.
I0522 19:51:49.427945 22569 net.cpp:226] relu4 needs backward computation.
I0522 19:51:49.427955 22569 net.cpp:226] conv4 needs backward computation.
I0522 19:51:49.427966 22569 net.cpp:226] pool3 needs backward computation.
I0522 19:51:49.427976 22569 net.cpp:226] relu3 needs backward computation.
I0522 19:51:49.427986 22569 net.cpp:226] conv3 needs backward computation.
I0522 19:51:49.428006 22569 net.cpp:226] pool2 needs backward computation.
I0522 19:51:49.428016 22569 net.cpp:226] relu2 needs backward computation.
I0522 19:51:49.428027 22569 net.cpp:226] conv2 needs backward computation.
I0522 19:51:49.428038 22569 net.cpp:226] pool1 needs backward computation.
I0522 19:51:49.428048 22569 net.cpp:226] relu1 needs backward computation.
I0522 19:51:49.428058 22569 net.cpp:226] conv1 needs backward computation.
I0522 19:51:49.428068 22569 net.cpp:228] data_hdf5 does not need backward computation.
I0522 19:51:49.428078 22569 net.cpp:270] This network produces output loss
I0522 19:51:49.428102 22569 net.cpp:283] Network initialization done.
I0522 19:51:49.429911 22569 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491.prototxt
I0522 19:51:49.429982 22569 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 19:51:49.430341 22569 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 19:51:49.430527 22569 layer_factory.hpp:77] Creating layer data_hdf5
I0522 19:51:49.430542 22569 net.cpp:106] Creating Layer data_hdf5
I0522 19:51:49.430554 22569 net.cpp:411] data_hdf5 -> data
I0522 19:51:49.430572 22569 net.cpp:411] data_hdf5 -> label
I0522 19:51:49.430586 22569 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 19:51:49.437335 22569 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 19:52:10.802747 22569 net.cpp:150] Setting up data_hdf5
I0522 19:52:10.802913 22569 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 19:52:10.802927 22569 net.cpp:157] Top shape: 40 (40)
I0522 19:52:10.802940 22569 net.cpp:165] Memory required for data: 1016160
I0522 19:52:10.802953 22569 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 19:52:10.802983 22569 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 19:52:10.802994 22569 net.cpp:454] label_data_hdf5_1_split <- label
I0522 19:52:10.803007 22569 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 19:52:10.803028 22569 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 19:52:10.803100 22569 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 19:52:10.803114 22569 net.cpp:157] Top shape: 40 (40)
I0522 19:52:10.803127 22569 net.cpp:157] Top shape: 40 (40)
I0522 19:52:10.803136 22569 net.cpp:165] Memory required for data: 1016480
I0522 19:52:10.803146 22569 layer_factory.hpp:77] Creating layer conv1
I0522 19:52:10.803167 22569 net.cpp:106] Creating Layer conv1
I0522 19:52:10.803179 22569 net.cpp:454] conv1 <- data
I0522 19:52:10.803194 22569 net.cpp:411] conv1 -> conv1
I0522 19:52:10.805119 22569 net.cpp:150] Setting up conv1
I0522 19:52:10.805143 22569 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 19:52:10.805155 22569 net.cpp:165] Memory required for data: 12075680
I0522 19:52:10.805176 22569 layer_factory.hpp:77] Creating layer relu1
I0522 19:52:10.805191 22569 net.cpp:106] Creating Layer relu1
I0522 19:52:10.805200 22569 net.cpp:454] relu1 <- conv1
I0522 19:52:10.805213 22569 net.cpp:397] relu1 -> conv1 (in-place)
I0522 19:52:10.805711 22569 net.cpp:150] Setting up relu1
I0522 19:52:10.805727 22569 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 19:52:10.805737 22569 net.cpp:165] Memory required for data: 23134880
I0522 19:52:10.805748 22569 layer_factory.hpp:77] Creating layer pool1
I0522 19:52:10.805764 22569 net.cpp:106] Creating Layer pool1
I0522 19:52:10.805774 22569 net.cpp:454] pool1 <- conv1
I0522 19:52:10.805786 22569 net.cpp:411] pool1 -> pool1
I0522 19:52:10.805861 22569 net.cpp:150] Setting up pool1
I0522 19:52:10.805874 22569 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 19:52:10.805883 22569 net.cpp:165] Memory required for data: 28664480
I0522 19:52:10.805891 22569 layer_factory.hpp:77] Creating layer conv2
I0522 19:52:10.805909 22569 net.cpp:106] Creating Layer conv2
I0522 19:52:10.805920 22569 net.cpp:454] conv2 <- pool1
I0522 19:52:10.805934 22569 net.cpp:411] conv2 -> conv2
I0522 19:52:10.807837 22569 net.cpp:150] Setting up conv2
I0522 19:52:10.807860 22569 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 19:52:10.807873 22569 net.cpp:165] Memory required for data: 36613280
I0522 19:52:10.807890 22569 layer_factory.hpp:77] Creating layer relu2
I0522 19:52:10.807904 22569 net.cpp:106] Creating Layer relu2
I0522 19:52:10.807914 22569 net.cpp:454] relu2 <- conv2
I0522 19:52:10.807925 22569 net.cpp:397] relu2 -> conv2 (in-place)
I0522 19:52:10.808259 22569 net.cpp:150] Setting up relu2
I0522 19:52:10.808272 22569 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 19:52:10.808282 22569 net.cpp:165] Memory required for data: 44562080
I0522 19:52:10.808292 22569 layer_factory.hpp:77] Creating layer pool2
I0522 19:52:10.808306 22569 net.cpp:106] Creating Layer pool2
I0522 19:52:10.808316 22569 net.cpp:454] pool2 <- conv2
I0522 19:52:10.808329 22569 net.cpp:411] pool2 -> pool2
I0522 19:52:10.808399 22569 net.cpp:150] Setting up pool2
I0522 19:52:10.808413 22569 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 19:52:10.808423 22569 net.cpp:165] Memory required for data: 48536480
I0522 19:52:10.808432 22569 layer_factory.hpp:77] Creating layer conv3
I0522 19:52:10.808449 22569 net.cpp:106] Creating Layer conv3
I0522 19:52:10.808459 22569 net.cpp:454] conv3 <- pool2
I0522 19:52:10.808473 22569 net.cpp:411] conv3 -> conv3
I0522 19:52:10.810446 22569 net.cpp:150] Setting up conv3
I0522 19:52:10.810469 22569 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 19:52:10.810479 22569 net.cpp:165] Memory required for data: 52873120
I0522 19:52:10.810511 22569 layer_factory.hpp:77] Creating layer relu3
I0522 19:52:10.810524 22569 net.cpp:106] Creating Layer relu3
I0522 19:52:10.810535 22569 net.cpp:454] relu3 <- conv3
I0522 19:52:10.810549 22569 net.cpp:397] relu3 -> conv3 (in-place)
I0522 19:52:10.811022 22569 net.cpp:150] Setting up relu3
I0522 19:52:10.811038 22569 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 19:52:10.811048 22569 net.cpp:165] Memory required for data: 57209760
I0522 19:52:10.811058 22569 layer_factory.hpp:77] Creating layer pool3
I0522 19:52:10.811071 22569 net.cpp:106] Creating Layer pool3
I0522 19:52:10.811081 22569 net.cpp:454] pool3 <- conv3
I0522 19:52:10.811094 22569 net.cpp:411] pool3 -> pool3
I0522 19:52:10.811166 22569 net.cpp:150] Setting up pool3
I0522 19:52:10.811179 22569 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 19:52:10.811188 22569 net.cpp:165] Memory required for data: 59378080
I0522 19:52:10.811198 22569 layer_factory.hpp:77] Creating layer conv4
I0522 19:52:10.811213 22569 net.cpp:106] Creating Layer conv4
I0522 19:52:10.811223 22569 net.cpp:454] conv4 <- pool3
I0522 19:52:10.811238 22569 net.cpp:411] conv4 -> conv4
I0522 19:52:10.813298 22569 net.cpp:150] Setting up conv4
I0522 19:52:10.813320 22569 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 19:52:10.813333 22569 net.cpp:165] Memory required for data: 60829600
I0522 19:52:10.813349 22569 layer_factory.hpp:77] Creating layer relu4
I0522 19:52:10.813361 22569 net.cpp:106] Creating Layer relu4
I0522 19:52:10.813371 22569 net.cpp:454] relu4 <- conv4
I0522 19:52:10.813383 22569 net.cpp:397] relu4 -> conv4 (in-place)
I0522 19:52:10.813853 22569 net.cpp:150] Setting up relu4
I0522 19:52:10.813869 22569 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 19:52:10.813880 22569 net.cpp:165] Memory required for data: 62281120
I0522 19:52:10.813889 22569 layer_factory.hpp:77] Creating layer pool4
I0522 19:52:10.813902 22569 net.cpp:106] Creating Layer pool4
I0522 19:52:10.813912 22569 net.cpp:454] pool4 <- conv4
I0522 19:52:10.813925 22569 net.cpp:411] pool4 -> pool4
I0522 19:52:10.813997 22569 net.cpp:150] Setting up pool4
I0522 19:52:10.814009 22569 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 19:52:10.814019 22569 net.cpp:165] Memory required for data: 63006880
I0522 19:52:10.814029 22569 layer_factory.hpp:77] Creating layer ip1
I0522 19:52:10.814044 22569 net.cpp:106] Creating Layer ip1
I0522 19:52:10.814055 22569 net.cpp:454] ip1 <- pool4
I0522 19:52:10.814067 22569 net.cpp:411] ip1 -> ip1
I0522 19:52:10.829506 22569 net.cpp:150] Setting up ip1
I0522 19:52:10.829535 22569 net.cpp:157] Top shape: 40 196 (7840)
I0522 19:52:10.829546 22569 net.cpp:165] Memory required for data: 63038240
I0522 19:52:10.829568 22569 layer_factory.hpp:77] Creating layer relu5
I0522 19:52:10.829583 22569 net.cpp:106] Creating Layer relu5
I0522 19:52:10.829593 22569 net.cpp:454] relu5 <- ip1
I0522 19:52:10.829607 22569 net.cpp:397] relu5 -> ip1 (in-place)
I0522 19:52:10.829953 22569 net.cpp:150] Setting up relu5
I0522 19:52:10.829967 22569 net.cpp:157] Top shape: 40 196 (7840)
I0522 19:52:10.829977 22569 net.cpp:165] Memory required for data: 63069600
I0522 19:52:10.829988 22569 layer_factory.hpp:77] Creating layer drop1
I0522 19:52:10.830006 22569 net.cpp:106] Creating Layer drop1
I0522 19:52:10.830016 22569 net.cpp:454] drop1 <- ip1
I0522 19:52:10.830029 22569 net.cpp:397] drop1 -> ip1 (in-place)
I0522 19:52:10.830075 22569 net.cpp:150] Setting up drop1
I0522 19:52:10.830088 22569 net.cpp:157] Top shape: 40 196 (7840)
I0522 19:52:10.830097 22569 net.cpp:165] Memory required for data: 63100960
I0522 19:52:10.830107 22569 layer_factory.hpp:77] Creating layer ip2
I0522 19:52:10.830121 22569 net.cpp:106] Creating Layer ip2
I0522 19:52:10.830132 22569 net.cpp:454] ip2 <- ip1
I0522 19:52:10.830145 22569 net.cpp:411] ip2 -> ip2
I0522 19:52:10.830624 22569 net.cpp:150] Setting up ip2
I0522 19:52:10.830637 22569 net.cpp:157] Top shape: 40 98 (3920)
I0522 19:52:10.830647 22569 net.cpp:165] Memory required for data: 63116640
I0522 19:52:10.830663 22569 layer_factory.hpp:77] Creating layer relu6
I0522 19:52:10.830688 22569 net.cpp:106] Creating Layer relu6
I0522 19:52:10.830698 22569 net.cpp:454] relu6 <- ip2
I0522 19:52:10.830711 22569 net.cpp:397] relu6 -> ip2 (in-place)
I0522 19:52:10.831251 22569 net.cpp:150] Setting up relu6
I0522 19:52:10.831274 22569 net.cpp:157] Top shape: 40 98 (3920)
I0522 19:52:10.831282 22569 net.cpp:165] Memory required for data: 63132320
I0522 19:52:10.831292 22569 layer_factory.hpp:77] Creating layer drop2
I0522 19:52:10.831305 22569 net.cpp:106] Creating Layer drop2
I0522 19:52:10.831315 22569 net.cpp:454] drop2 <- ip2
I0522 19:52:10.831328 22569 net.cpp:397] drop2 -> ip2 (in-place)
I0522 19:52:10.831372 22569 net.cpp:150] Setting up drop2
I0522 19:52:10.831385 22569 net.cpp:157] Top shape: 40 98 (3920)
I0522 19:52:10.831395 22569 net.cpp:165] Memory required for data: 63148000
I0522 19:52:10.831405 22569 layer_factory.hpp:77] Creating layer ip3
I0522 19:52:10.831419 22569 net.cpp:106] Creating Layer ip3
I0522 19:52:10.831429 22569 net.cpp:454] ip3 <- ip2
I0522 19:52:10.831444 22569 net.cpp:411] ip3 -> ip3
I0522 19:52:10.831666 22569 net.cpp:150] Setting up ip3
I0522 19:52:10.831679 22569 net.cpp:157] Top shape: 40 11 (440)
I0522 19:52:10.831689 22569 net.cpp:165] Memory required for data: 63149760
I0522 19:52:10.831704 22569 layer_factory.hpp:77] Creating layer drop3
I0522 19:52:10.831717 22569 net.cpp:106] Creating Layer drop3
I0522 19:52:10.831727 22569 net.cpp:454] drop3 <- ip3
I0522 19:52:10.831740 22569 net.cpp:397] drop3 -> ip3 (in-place)
I0522 19:52:10.831782 22569 net.cpp:150] Setting up drop3
I0522 19:52:10.831794 22569 net.cpp:157] Top shape: 40 11 (440)
I0522 19:52:10.831804 22569 net.cpp:165] Memory required for data: 63151520
I0522 19:52:10.831815 22569 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 19:52:10.831827 22569 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 19:52:10.831837 22569 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 19:52:10.831851 22569 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 19:52:10.831864 22569 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 19:52:10.831939 22569 net.cpp:150] Setting up ip3_drop3_0_split
I0522 19:52:10.831953 22569 net.cpp:157] Top shape: 40 11 (440)
I0522 19:52:10.831964 22569 net.cpp:157] Top shape: 40 11 (440)
I0522 19:52:10.831974 22569 net.cpp:165] Memory required for data: 63155040
I0522 19:52:10.831984 22569 layer_factory.hpp:77] Creating layer accuracy
I0522 19:52:10.832005 22569 net.cpp:106] Creating Layer accuracy
I0522 19:52:10.832015 22569 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 19:52:10.832027 22569 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 19:52:10.832041 22569 net.cpp:411] accuracy -> accuracy
I0522 19:52:10.832064 22569 net.cpp:150] Setting up accuracy
I0522 19:52:10.832077 22569 net.cpp:157] Top shape: (1)
I0522 19:52:10.832087 22569 net.cpp:165] Memory required for data: 63155044
I0522 19:52:10.832096 22569 layer_factory.hpp:77] Creating layer loss
I0522 19:52:10.832110 22569 net.cpp:106] Creating Layer loss
I0522 19:52:10.832121 22569 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 19:52:10.832132 22569 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 19:52:10.832145 22569 net.cpp:411] loss -> loss
I0522 19:52:10.832162 22569 layer_factory.hpp:77] Creating layer loss
I0522 19:52:10.832648 22569 net.cpp:150] Setting up loss
I0522 19:52:10.832660 22569 net.cpp:157] Top shape: (1)
I0522 19:52:10.832670 22569 net.cpp:160]     with loss weight 1
I0522 19:52:10.832690 22569 net.cpp:165] Memory required for data: 63155048
I0522 19:52:10.832700 22569 net.cpp:226] loss needs backward computation.
I0522 19:52:10.832710 22569 net.cpp:228] accuracy does not need backward computation.
I0522 19:52:10.832721 22569 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 19:52:10.832732 22569 net.cpp:226] drop3 needs backward computation.
I0522 19:52:10.832741 22569 net.cpp:226] ip3 needs backward computation.
I0522 19:52:10.832751 22569 net.cpp:226] drop2 needs backward computation.
I0522 19:52:10.832761 22569 net.cpp:226] relu6 needs backward computation.
I0522 19:52:10.832777 22569 net.cpp:226] ip2 needs backward computation.
I0522 19:52:10.832788 22569 net.cpp:226] drop1 needs backward computation.
I0522 19:52:10.832798 22569 net.cpp:226] relu5 needs backward computation.
I0522 19:52:10.832808 22569 net.cpp:226] ip1 needs backward computation.
I0522 19:52:10.832818 22569 net.cpp:226] pool4 needs backward computation.
I0522 19:52:10.832828 22569 net.cpp:226] relu4 needs backward computation.
I0522 19:52:10.832837 22569 net.cpp:226] conv4 needs backward computation.
I0522 19:52:10.832846 22569 net.cpp:226] pool3 needs backward computation.
I0522 19:52:10.832857 22569 net.cpp:226] relu3 needs backward computation.
I0522 19:52:10.832867 22569 net.cpp:226] conv3 needs backward computation.
I0522 19:52:10.832885 22569 net.cpp:226] pool2 needs backward computation.
I0522 19:52:10.832895 22569 net.cpp:226] relu2 needs backward computation.
I0522 19:52:10.832906 22569 net.cpp:226] conv2 needs backward computation.
I0522 19:52:10.832916 22569 net.cpp:226] pool1 needs backward computation.
I0522 19:52:10.832926 22569 net.cpp:226] relu1 needs backward computation.
I0522 19:52:10.832936 22569 net.cpp:226] conv1 needs backward computation.
I0522 19:52:10.832947 22569 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 19:52:10.832962 22569 net.cpp:228] data_hdf5 does not need backward computation.
I0522 19:52:10.832972 22569 net.cpp:270] This network produces output accuracy
I0522 19:52:10.832981 22569 net.cpp:270] This network produces output loss
I0522 19:52:10.833009 22569 net.cpp:283] Network initialization done.
I0522 19:52:10.833143 22569 solver.cpp:60] Solver scaffolding done.
I0522 19:52:10.834272 22569 caffe.cpp:212] Starting Optimization
I0522 19:52:10.834291 22569 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 19:52:10.834305 22569 solver.cpp:289] Learning Rate Policy: fixed
I0522 19:52:10.835589 22569 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 19:53:00.293712 22569 solver.cpp:409]     Test net output #0: accuracy = 0.12006
I0522 19:53:00.293872 22569 solver.cpp:409]     Test net output #1: loss = 2.39771 (* 1 = 2.39771 loss)
I0522 19:53:00.316349 22569 solver.cpp:237] Iteration 0, loss = 2.39482
I0522 19:53:00.316386 22569 solver.cpp:253]     Train net output #0: loss = 2.39482 (* 1 = 2.39482 loss)
I0522 19:53:00.316404 22569 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0522 19:53:10.163146 22569 solver.cpp:237] Iteration 375, loss = 2.1007
I0522 19:53:10.163180 22569 solver.cpp:253]     Train net output #0: loss = 2.1007 (* 1 = 2.1007 loss)
I0522 19:53:10.163194 22569 sgd_solver.cpp:106] Iteration 375, lr = 0.0025
I0522 19:53:20.014109 22569 solver.cpp:237] Iteration 750, loss = 1.91225
I0522 19:53:20.014156 22569 solver.cpp:253]     Train net output #0: loss = 1.91225 (* 1 = 1.91225 loss)
I0522 19:53:20.014170 22569 sgd_solver.cpp:106] Iteration 750, lr = 0.0025
I0522 19:53:29.867753 22569 solver.cpp:237] Iteration 1125, loss = 1.76253
I0522 19:53:29.867787 22569 solver.cpp:253]     Train net output #0: loss = 1.76253 (* 1 = 1.76253 loss)
I0522 19:53:29.867800 22569 sgd_solver.cpp:106] Iteration 1125, lr = 0.0025
I0522 19:53:39.715422 22569 solver.cpp:237] Iteration 1500, loss = 1.84551
I0522 19:53:39.715572 22569 solver.cpp:253]     Train net output #0: loss = 1.84551 (* 1 = 1.84551 loss)
I0522 19:53:39.715585 22569 sgd_solver.cpp:106] Iteration 1500, lr = 0.0025
I0522 19:53:49.568539 22569 solver.cpp:237] Iteration 1875, loss = 2.08399
I0522 19:53:49.568586 22569 solver.cpp:253]     Train net output #0: loss = 2.08399 (* 1 = 2.08399 loss)
I0522 19:53:49.568603 22569 sgd_solver.cpp:106] Iteration 1875, lr = 0.0025
I0522 19:53:59.421139 22569 solver.cpp:237] Iteration 2250, loss = 1.81204
I0522 19:53:59.421174 22569 solver.cpp:253]     Train net output #0: loss = 1.81204 (* 1 = 1.81204 loss)
I0522 19:53:59.421186 22569 sgd_solver.cpp:106] Iteration 2250, lr = 0.0025
I0522 19:54:31.425217 22569 solver.cpp:237] Iteration 2625, loss = 1.5153
I0522 19:54:31.425382 22569 solver.cpp:253]     Train net output #0: loss = 1.5153 (* 1 = 1.5153 loss)
I0522 19:54:31.425400 22569 sgd_solver.cpp:106] Iteration 2625, lr = 0.0025
I0522 19:54:41.278424 22569 solver.cpp:237] Iteration 3000, loss = 1.45525
I0522 19:54:41.278465 22569 solver.cpp:253]     Train net output #0: loss = 1.45525 (* 1 = 1.45525 loss)
I0522 19:54:41.278483 22569 sgd_solver.cpp:106] Iteration 3000, lr = 0.0025
I0522 19:54:51.133566 22569 solver.cpp:237] Iteration 3375, loss = 1.68437
I0522 19:54:51.133602 22569 solver.cpp:253]     Train net output #0: loss = 1.68437 (* 1 = 1.68437 loss)
I0522 19:54:51.133618 22569 sgd_solver.cpp:106] Iteration 3375, lr = 0.0025
I0522 19:55:00.966140 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_3750.caffemodel
I0522 19:55:01.025725 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_3750.solverstate
I0522 19:55:01.059195 22569 solver.cpp:237] Iteration 3750, loss = 1.71751
I0522 19:55:01.059240 22569 solver.cpp:253]     Train net output #0: loss = 1.71751 (* 1 = 1.71751 loss)
I0522 19:55:01.059254 22569 sgd_solver.cpp:106] Iteration 3750, lr = 0.0025
I0522 19:55:10.917065 22569 solver.cpp:237] Iteration 4125, loss = 1.62587
I0522 19:55:10.917217 22569 solver.cpp:253]     Train net output #0: loss = 1.62587 (* 1 = 1.62587 loss)
I0522 19:55:10.917232 22569 sgd_solver.cpp:106] Iteration 4125, lr = 0.0025
I0522 19:55:20.770813 22569 solver.cpp:237] Iteration 4500, loss = 1.46158
I0522 19:55:20.770848 22569 solver.cpp:253]     Train net output #0: loss = 1.46158 (* 1 = 1.46158 loss)
I0522 19:55:20.770864 22569 sgd_solver.cpp:106] Iteration 4500, lr = 0.0025
I0522 19:55:30.622861 22569 solver.cpp:237] Iteration 4875, loss = 1.73478
I0522 19:55:30.622905 22569 solver.cpp:253]     Train net output #0: loss = 1.73478 (* 1 = 1.73478 loss)
I0522 19:55:30.622921 22569 sgd_solver.cpp:106] Iteration 4875, lr = 0.0025
I0522 19:56:02.629354 22569 solver.cpp:237] Iteration 5250, loss = 1.3614
I0522 19:56:02.629510 22569 solver.cpp:253]     Train net output #0: loss = 1.3614 (* 1 = 1.3614 loss)
I0522 19:56:02.629525 22569 sgd_solver.cpp:106] Iteration 5250, lr = 0.0025
I0522 19:56:12.484009 22569 solver.cpp:237] Iteration 5625, loss = 1.35396
I0522 19:56:12.484045 22569 solver.cpp:253]     Train net output #0: loss = 1.35396 (* 1 = 1.35396 loss)
I0522 19:56:12.484062 22569 sgd_solver.cpp:106] Iteration 5625, lr = 0.0025
I0522 19:56:22.343891 22569 solver.cpp:237] Iteration 6000, loss = 1.68545
I0522 19:56:22.343936 22569 solver.cpp:253]     Train net output #0: loss = 1.68545 (* 1 = 1.68545 loss)
I0522 19:56:22.343955 22569 sgd_solver.cpp:106] Iteration 6000, lr = 0.0025
I0522 19:56:32.202289 22569 solver.cpp:237] Iteration 6375, loss = 1.45233
I0522 19:56:32.202325 22569 solver.cpp:253]     Train net output #0: loss = 1.45233 (* 1 = 1.45233 loss)
I0522 19:56:32.202338 22569 sgd_solver.cpp:106] Iteration 6375, lr = 0.0025
I0522 19:56:42.060040 22569 solver.cpp:237] Iteration 6750, loss = 1.41581
I0522 19:56:42.060201 22569 solver.cpp:253]     Train net output #0: loss = 1.41581 (* 1 = 1.41581 loss)
I0522 19:56:42.060216 22569 sgd_solver.cpp:106] Iteration 6750, lr = 0.0025
I0522 19:56:51.911725 22569 solver.cpp:237] Iteration 7125, loss = 1.42751
I0522 19:56:51.911761 22569 solver.cpp:253]     Train net output #0: loss = 1.42751 (* 1 = 1.42751 loss)
I0522 19:56:51.911777 22569 sgd_solver.cpp:106] Iteration 7125, lr = 0.0025
I0522 19:57:01.745975 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_7500.caffemodel
I0522 19:57:01.803179 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_7500.solverstate
I0522 19:57:01.829252 22569 solver.cpp:341] Iteration 7500, Testing net (#0)
I0522 19:57:50.423543 22569 solver.cpp:409]     Test net output #0: accuracy = 0.791766
I0522 19:57:50.423707 22569 solver.cpp:409]     Test net output #1: loss = 0.732818 (* 1 = 0.732818 loss)
I0522 19:58:12.581727 22569 solver.cpp:237] Iteration 7500, loss = 1.2857
I0522 19:58:12.581778 22569 solver.cpp:253]     Train net output #0: loss = 1.2857 (* 1 = 1.2857 loss)
I0522 19:58:12.581792 22569 sgd_solver.cpp:106] Iteration 7500, lr = 0.0025
I0522 19:58:22.503437 22569 solver.cpp:237] Iteration 7875, loss = 1.32195
I0522 19:58:22.503605 22569 solver.cpp:253]     Train net output #0: loss = 1.32195 (* 1 = 1.32195 loss)
I0522 19:58:22.503619 22569 sgd_solver.cpp:106] Iteration 7875, lr = 0.0025
I0522 19:58:32.421295 22569 solver.cpp:237] Iteration 8250, loss = 1.63264
I0522 19:58:32.421330 22569 solver.cpp:253]     Train net output #0: loss = 1.63264 (* 1 = 1.63264 loss)
I0522 19:58:32.421344 22569 sgd_solver.cpp:106] Iteration 8250, lr = 0.0025
I0522 19:58:42.335799 22569 solver.cpp:237] Iteration 8625, loss = 1.48899
I0522 19:58:42.335835 22569 solver.cpp:253]     Train net output #0: loss = 1.48899 (* 1 = 1.48899 loss)
I0522 19:58:42.335851 22569 sgd_solver.cpp:106] Iteration 8625, lr = 0.0025
I0522 19:58:52.254307 22569 solver.cpp:237] Iteration 9000, loss = 1.28225
I0522 19:58:52.254348 22569 solver.cpp:253]     Train net output #0: loss = 1.28225 (* 1 = 1.28225 loss)
I0522 19:58:52.254367 22569 sgd_solver.cpp:106] Iteration 9000, lr = 0.0025
I0522 19:59:02.167219 22569 solver.cpp:237] Iteration 9375, loss = 1.45472
I0522 19:59:02.167373 22569 solver.cpp:253]     Train net output #0: loss = 1.45472 (* 1 = 1.45472 loss)
I0522 19:59:02.167387 22569 sgd_solver.cpp:106] Iteration 9375, lr = 0.0025
I0522 19:59:12.086194 22569 solver.cpp:237] Iteration 9750, loss = 1.22516
I0522 19:59:12.086238 22569 solver.cpp:253]     Train net output #0: loss = 1.22516 (* 1 = 1.22516 loss)
I0522 19:59:12.086252 22569 sgd_solver.cpp:106] Iteration 9750, lr = 0.0025
I0522 19:59:44.148253 22569 solver.cpp:237] Iteration 10125, loss = 1.60448
I0522 19:59:44.148421 22569 solver.cpp:253]     Train net output #0: loss = 1.60448 (* 1 = 1.60448 loss)
I0522 19:59:44.148434 22569 sgd_solver.cpp:106] Iteration 10125, lr = 0.0025
I0522 19:59:54.070194 22569 solver.cpp:237] Iteration 10500, loss = 1.23653
I0522 19:59:54.070227 22569 solver.cpp:253]     Train net output #0: loss = 1.23653 (* 1 = 1.23653 loss)
I0522 19:59:54.070245 22569 sgd_solver.cpp:106] Iteration 10500, lr = 0.0025
I0522 20:00:03.989219 22569 solver.cpp:237] Iteration 10875, loss = 1.3351
I0522 20:00:03.989269 22569 solver.cpp:253]     Train net output #0: loss = 1.3351 (* 1 = 1.3351 loss)
I0522 20:00:03.989282 22569 sgd_solver.cpp:106] Iteration 10875, lr = 0.0025
I0522 20:00:13.869863 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_11250.caffemodel
I0522 20:00:13.929610 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_11250.solverstate
I0522 20:00:13.965440 22569 solver.cpp:237] Iteration 11250, loss = 1.45009
I0522 20:00:13.965487 22569 solver.cpp:253]     Train net output #0: loss = 1.45009 (* 1 = 1.45009 loss)
I0522 20:00:13.965504 22569 sgd_solver.cpp:106] Iteration 11250, lr = 0.0025
I0522 20:00:23.877434 22569 solver.cpp:237] Iteration 11625, loss = 1.06691
I0522 20:00:23.877605 22569 solver.cpp:253]     Train net output #0: loss = 1.06691 (* 1 = 1.06691 loss)
I0522 20:00:23.877619 22569 sgd_solver.cpp:106] Iteration 11625, lr = 0.0025
I0522 20:00:33.788684 22569 solver.cpp:237] Iteration 12000, loss = 1.44191
I0522 20:00:33.788719 22569 solver.cpp:253]     Train net output #0: loss = 1.44191 (* 1 = 1.44191 loss)
I0522 20:00:33.788738 22569 sgd_solver.cpp:106] Iteration 12000, lr = 0.0025
I0522 20:00:43.703223 22569 solver.cpp:237] Iteration 12375, loss = 1.39459
I0522 20:00:43.703258 22569 solver.cpp:253]     Train net output #0: loss = 1.39459 (* 1 = 1.39459 loss)
I0522 20:00:43.703275 22569 sgd_solver.cpp:106] Iteration 12375, lr = 0.0025
I0522 20:01:15.813153 22569 solver.cpp:237] Iteration 12750, loss = 1.62234
I0522 20:01:15.813314 22569 solver.cpp:253]     Train net output #0: loss = 1.62234 (* 1 = 1.62234 loss)
I0522 20:01:15.813330 22569 sgd_solver.cpp:106] Iteration 12750, lr = 0.0025
I0522 20:01:25.724764 22569 solver.cpp:237] Iteration 13125, loss = 1.4716
I0522 20:01:25.724798 22569 solver.cpp:253]     Train net output #0: loss = 1.4716 (* 1 = 1.4716 loss)
I0522 20:01:25.724818 22569 sgd_solver.cpp:106] Iteration 13125, lr = 0.0025
I0522 20:01:35.642166 22569 solver.cpp:237] Iteration 13500, loss = 1.31565
I0522 20:01:35.642202 22569 solver.cpp:253]     Train net output #0: loss = 1.31565 (* 1 = 1.31565 loss)
I0522 20:01:35.642220 22569 sgd_solver.cpp:106] Iteration 13500, lr = 0.0025
I0522 20:01:45.551336 22569 solver.cpp:237] Iteration 13875, loss = 1.28218
I0522 20:01:45.551383 22569 solver.cpp:253]     Train net output #0: loss = 1.28218 (* 1 = 1.28218 loss)
I0522 20:01:45.551398 22569 sgd_solver.cpp:106] Iteration 13875, lr = 0.0025
I0522 20:01:55.461246 22569 solver.cpp:237] Iteration 14250, loss = 1.41213
I0522 20:01:55.461388 22569 solver.cpp:253]     Train net output #0: loss = 1.41213 (* 1 = 1.41213 loss)
I0522 20:01:55.461402 22569 sgd_solver.cpp:106] Iteration 14250, lr = 0.0025
I0522 20:02:05.371973 22569 solver.cpp:237] Iteration 14625, loss = 1.2193
I0522 20:02:05.372019 22569 solver.cpp:253]     Train net output #0: loss = 1.2193 (* 1 = 1.2193 loss)
I0522 20:02:05.372035 22569 sgd_solver.cpp:106] Iteration 14625, lr = 0.0025
I0522 20:02:15.264853 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_15000.caffemodel
I0522 20:02:15.324093 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_15000.solverstate
I0522 20:02:15.351997 22569 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 20:03:24.731782 22569 solver.cpp:409]     Test net output #0: accuracy = 0.833399
I0522 20:03:24.731943 22569 solver.cpp:409]     Test net output #1: loss = 0.581908 (* 1 = 0.581908 loss)
I0522 20:03:46.892345 22569 solver.cpp:237] Iteration 15000, loss = 1.17629
I0522 20:03:46.892400 22569 solver.cpp:253]     Train net output #0: loss = 1.17629 (* 1 = 1.17629 loss)
I0522 20:03:46.892415 22569 sgd_solver.cpp:106] Iteration 15000, lr = 0.0025
I0522 20:03:56.712405 22569 solver.cpp:237] Iteration 15375, loss = 1.16736
I0522 20:03:56.712560 22569 solver.cpp:253]     Train net output #0: loss = 1.16736 (* 1 = 1.16736 loss)
I0522 20:03:56.712574 22569 sgd_solver.cpp:106] Iteration 15375, lr = 0.0025
I0522 20:04:06.529822 22569 solver.cpp:237] Iteration 15750, loss = 1.30572
I0522 20:04:06.529857 22569 solver.cpp:253]     Train net output #0: loss = 1.30572 (* 1 = 1.30572 loss)
I0522 20:04:06.529872 22569 sgd_solver.cpp:106] Iteration 15750, lr = 0.0025
I0522 20:04:16.349679 22569 solver.cpp:237] Iteration 16125, loss = 1.58322
I0522 20:04:16.349725 22569 solver.cpp:253]     Train net output #0: loss = 1.58322 (* 1 = 1.58322 loss)
I0522 20:04:16.349737 22569 sgd_solver.cpp:106] Iteration 16125, lr = 0.0025
I0522 20:04:26.170130 22569 solver.cpp:237] Iteration 16500, loss = 1.3577
I0522 20:04:26.170166 22569 solver.cpp:253]     Train net output #0: loss = 1.3577 (* 1 = 1.3577 loss)
I0522 20:04:26.170181 22569 sgd_solver.cpp:106] Iteration 16500, lr = 0.0025
I0522 20:04:35.993489 22569 solver.cpp:237] Iteration 16875, loss = 1.44522
I0522 20:04:35.993659 22569 solver.cpp:253]     Train net output #0: loss = 1.44522 (* 1 = 1.44522 loss)
I0522 20:04:35.993674 22569 sgd_solver.cpp:106] Iteration 16875, lr = 0.0025
I0522 20:04:45.817068 22569 solver.cpp:237] Iteration 17250, loss = 1.47531
I0522 20:04:45.817103 22569 solver.cpp:253]     Train net output #0: loss = 1.47531 (* 1 = 1.47531 loss)
I0522 20:04:45.817119 22569 sgd_solver.cpp:106] Iteration 17250, lr = 0.0025
I0522 20:05:17.774478 22569 solver.cpp:237] Iteration 17625, loss = 1.24645
I0522 20:05:17.774638 22569 solver.cpp:253]     Train net output #0: loss = 1.24645 (* 1 = 1.24645 loss)
I0522 20:05:17.774652 22569 sgd_solver.cpp:106] Iteration 17625, lr = 0.0025
I0522 20:05:27.592665 22569 solver.cpp:237] Iteration 18000, loss = 1.17734
I0522 20:05:27.592707 22569 solver.cpp:253]     Train net output #0: loss = 1.17734 (* 1 = 1.17734 loss)
I0522 20:05:27.592723 22569 sgd_solver.cpp:106] Iteration 18000, lr = 0.0025
I0522 20:05:37.409518 22569 solver.cpp:237] Iteration 18375, loss = 1.28764
I0522 20:05:37.409554 22569 solver.cpp:253]     Train net output #0: loss = 1.28764 (* 1 = 1.28764 loss)
I0522 20:05:37.409569 22569 sgd_solver.cpp:106] Iteration 18375, lr = 0.0025
I0522 20:05:47.206187 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_18750.caffemodel
I0522 20:05:47.264668 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_18750.solverstate
I0522 20:05:47.301257 22569 solver.cpp:237] Iteration 18750, loss = 1.42418
I0522 20:05:47.301306 22569 solver.cpp:253]     Train net output #0: loss = 1.42418 (* 1 = 1.42418 loss)
I0522 20:05:47.301322 22569 sgd_solver.cpp:106] Iteration 18750, lr = 0.0025
I0522 20:05:57.118515 22569 solver.cpp:237] Iteration 19125, loss = 1.19802
I0522 20:05:57.118672 22569 solver.cpp:253]     Train net output #0: loss = 1.19802 (* 1 = 1.19802 loss)
I0522 20:05:57.118686 22569 sgd_solver.cpp:106] Iteration 19125, lr = 0.0025
I0522 20:06:06.938093 22569 solver.cpp:237] Iteration 19500, loss = 1.34961
I0522 20:06:06.938127 22569 solver.cpp:253]     Train net output #0: loss = 1.34961 (* 1 = 1.34961 loss)
I0522 20:06:06.938143 22569 sgd_solver.cpp:106] Iteration 19500, lr = 0.0025
I0522 20:06:16.757963 22569 solver.cpp:237] Iteration 19875, loss = 1.3011
I0522 20:06:16.758013 22569 solver.cpp:253]     Train net output #0: loss = 1.3011 (* 1 = 1.3011 loss)
I0522 20:06:16.758028 22569 sgd_solver.cpp:106] Iteration 19875, lr = 0.0025
I0522 20:06:48.743083 22569 solver.cpp:237] Iteration 20250, loss = 1.43696
I0522 20:06:48.743259 22569 solver.cpp:253]     Train net output #0: loss = 1.43696 (* 1 = 1.43696 loss)
I0522 20:06:48.743274 22569 sgd_solver.cpp:106] Iteration 20250, lr = 0.0025
I0522 20:06:58.562491 22569 solver.cpp:237] Iteration 20625, loss = 1.09689
I0522 20:06:58.562526 22569 solver.cpp:253]     Train net output #0: loss = 1.09689 (* 1 = 1.09689 loss)
I0522 20:06:58.562542 22569 sgd_solver.cpp:106] Iteration 20625, lr = 0.0025
I0522 20:07:08.378996 22569 solver.cpp:237] Iteration 21000, loss = 1.37141
I0522 20:07:08.379039 22569 solver.cpp:253]     Train net output #0: loss = 1.37141 (* 1 = 1.37141 loss)
I0522 20:07:08.379057 22569 sgd_solver.cpp:106] Iteration 21000, lr = 0.0025
I0522 20:07:18.194507 22569 solver.cpp:237] Iteration 21375, loss = 1.26002
I0522 20:07:18.194543 22569 solver.cpp:253]     Train net output #0: loss = 1.26002 (* 1 = 1.26002 loss)
I0522 20:07:18.194558 22569 sgd_solver.cpp:106] Iteration 21375, lr = 0.0025
I0522 20:07:28.016602 22569 solver.cpp:237] Iteration 21750, loss = 1.37227
I0522 20:07:28.016746 22569 solver.cpp:253]     Train net output #0: loss = 1.37227 (* 1 = 1.37227 loss)
I0522 20:07:28.016760 22569 sgd_solver.cpp:106] Iteration 21750, lr = 0.0025
I0522 20:07:37.839474 22569 solver.cpp:237] Iteration 22125, loss = 1.17331
I0522 20:07:37.839517 22569 solver.cpp:253]     Train net output #0: loss = 1.17331 (* 1 = 1.17331 loss)
I0522 20:07:37.839532 22569 sgd_solver.cpp:106] Iteration 22125, lr = 0.0025
I0522 20:07:47.632359 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_22500.caffemodel
I0522 20:07:47.688100 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_22500.solverstate
I0522 20:07:47.714570 22569 solver.cpp:341] Iteration 22500, Testing net (#0)
I0522 20:08:35.873589 22569 solver.cpp:409]     Test net output #0: accuracy = 0.847762
I0522 20:08:35.873752 22569 solver.cpp:409]     Test net output #1: loss = 0.501734 (* 1 = 0.501734 loss)
I0522 20:08:57.963994 22569 solver.cpp:237] Iteration 22500, loss = 1.11021
I0522 20:08:57.964047 22569 solver.cpp:253]     Train net output #0: loss = 1.11021 (* 1 = 1.11021 loss)
I0522 20:08:57.964062 22569 sgd_solver.cpp:106] Iteration 22500, lr = 0.0025
I0522 20:09:07.751729 22569 solver.cpp:237] Iteration 22875, loss = 1.24548
I0522 20:09:07.751880 22569 solver.cpp:253]     Train net output #0: loss = 1.24548 (* 1 = 1.24548 loss)
I0522 20:09:07.751894 22569 sgd_solver.cpp:106] Iteration 22875, lr = 0.0025
I0522 20:09:17.544144 22569 solver.cpp:237] Iteration 23250, loss = 1.5686
I0522 20:09:17.544184 22569 solver.cpp:253]     Train net output #0: loss = 1.5686 (* 1 = 1.5686 loss)
I0522 20:09:17.544199 22569 sgd_solver.cpp:106] Iteration 23250, lr = 0.0025
I0522 20:09:27.335782 22569 solver.cpp:237] Iteration 23625, loss = 1.06613
I0522 20:09:27.335818 22569 solver.cpp:253]     Train net output #0: loss = 1.06613 (* 1 = 1.06613 loss)
I0522 20:09:27.335831 22569 sgd_solver.cpp:106] Iteration 23625, lr = 0.0025
I0522 20:09:37.128725 22569 solver.cpp:237] Iteration 24000, loss = 1.16257
I0522 20:09:37.128769 22569 solver.cpp:253]     Train net output #0: loss = 1.16257 (* 1 = 1.16257 loss)
I0522 20:09:37.128785 22569 sgd_solver.cpp:106] Iteration 24000, lr = 0.0025
I0522 20:09:46.923789 22569 solver.cpp:237] Iteration 24375, loss = 1.25527
I0522 20:09:46.923934 22569 solver.cpp:253]     Train net output #0: loss = 1.25527 (* 1 = 1.25527 loss)
I0522 20:09:46.923948 22569 sgd_solver.cpp:106] Iteration 24375, lr = 0.0025
I0522 20:09:56.717669 22569 solver.cpp:237] Iteration 24750, loss = 1.21485
I0522 20:09:56.717703 22569 solver.cpp:253]     Train net output #0: loss = 1.21485 (* 1 = 1.21485 loss)
I0522 20:09:56.717720 22569 sgd_solver.cpp:106] Iteration 24750, lr = 0.0025
I0522 20:10:28.691257 22569 solver.cpp:237] Iteration 25125, loss = 1.24471
I0522 20:10:28.691439 22569 solver.cpp:253]     Train net output #0: loss = 1.24471 (* 1 = 1.24471 loss)
I0522 20:10:28.691454 22569 sgd_solver.cpp:106] Iteration 25125, lr = 0.0025
I0522 20:10:38.488931 22569 solver.cpp:237] Iteration 25500, loss = 1.0362
I0522 20:10:38.488966 22569 solver.cpp:253]     Train net output #0: loss = 1.0362 (* 1 = 1.0362 loss)
I0522 20:10:38.488983 22569 sgd_solver.cpp:106] Iteration 25500, lr = 0.0025
I0522 20:10:48.276201 22569 solver.cpp:237] Iteration 25875, loss = 1.04918
I0522 20:10:48.276237 22569 solver.cpp:253]     Train net output #0: loss = 1.04918 (* 1 = 1.04918 loss)
I0522 20:10:48.276252 22569 sgd_solver.cpp:106] Iteration 25875, lr = 0.0025
I0522 20:10:58.038439 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_26250.caffemodel
I0522 20:10:58.093755 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_26250.solverstate
I0522 20:10:58.128485 22569 solver.cpp:237] Iteration 26250, loss = 1.25124
I0522 20:10:58.128530 22569 solver.cpp:253]     Train net output #0: loss = 1.25124 (* 1 = 1.25124 loss)
I0522 20:10:58.128546 22569 sgd_solver.cpp:106] Iteration 26250, lr = 0.0025
I0522 20:11:07.926241 22569 solver.cpp:237] Iteration 26625, loss = 1.3668
I0522 20:11:07.926393 22569 solver.cpp:253]     Train net output #0: loss = 1.3668 (* 1 = 1.3668 loss)
I0522 20:11:07.926405 22569 sgd_solver.cpp:106] Iteration 26625, lr = 0.0025
I0522 20:11:17.715977 22569 solver.cpp:237] Iteration 27000, loss = 1.27463
I0522 20:11:17.716019 22569 solver.cpp:253]     Train net output #0: loss = 1.27463 (* 1 = 1.27463 loss)
I0522 20:11:17.716040 22569 sgd_solver.cpp:106] Iteration 27000, lr = 0.0025
I0522 20:11:27.506717 22569 solver.cpp:237] Iteration 27375, loss = 1.45945
I0522 20:11:27.506753 22569 solver.cpp:253]     Train net output #0: loss = 1.45945 (* 1 = 1.45945 loss)
I0522 20:11:27.506769 22569 sgd_solver.cpp:106] Iteration 27375, lr = 0.0025
I0522 20:11:59.530511 22569 solver.cpp:237] Iteration 27750, loss = 1.26745
I0522 20:11:59.530684 22569 solver.cpp:253]     Train net output #0: loss = 1.26745 (* 1 = 1.26745 loss)
I0522 20:11:59.530699 22569 sgd_solver.cpp:106] Iteration 27750, lr = 0.0025
I0522 20:12:09.315971 22569 solver.cpp:237] Iteration 28125, loss = 1.30504
I0522 20:12:09.316016 22569 solver.cpp:253]     Train net output #0: loss = 1.30504 (* 1 = 1.30504 loss)
I0522 20:12:09.316030 22569 sgd_solver.cpp:106] Iteration 28125, lr = 0.0025
I0522 20:12:19.107945 22569 solver.cpp:237] Iteration 28500, loss = 1.2462
I0522 20:12:19.107980 22569 solver.cpp:253]     Train net output #0: loss = 1.2462 (* 1 = 1.2462 loss)
I0522 20:12:19.107995 22569 sgd_solver.cpp:106] Iteration 28500, lr = 0.0025
I0522 20:12:28.897413 22569 solver.cpp:237] Iteration 28875, loss = 1.08757
I0522 20:12:28.897460 22569 solver.cpp:253]     Train net output #0: loss = 1.08757 (* 1 = 1.08757 loss)
I0522 20:12:28.897475 22569 sgd_solver.cpp:106] Iteration 28875, lr = 0.0025
I0522 20:12:38.685475 22569 solver.cpp:237] Iteration 29250, loss = 1.26641
I0522 20:12:38.685621 22569 solver.cpp:253]     Train net output #0: loss = 1.26641 (* 1 = 1.26641 loss)
I0522 20:12:38.685634 22569 sgd_solver.cpp:106] Iteration 29250, lr = 0.0025
I0522 20:12:48.474019 22569 solver.cpp:237] Iteration 29625, loss = 1.37844
I0522 20:12:48.474052 22569 solver.cpp:253]     Train net output #0: loss = 1.37844 (* 1 = 1.37844 loss)
I0522 20:12:48.474068 22569 sgd_solver.cpp:106] Iteration 29625, lr = 0.0025
I0522 20:12:58.237335 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_30000.caffemodel
I0522 20:12:58.293958 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_30000.solverstate
I0522 20:12:58.320742 22569 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 20:14:07.737831 22569 solver.cpp:409]     Test net output #0: accuracy = 0.86222
I0522 20:14:07.738003 22569 solver.cpp:409]     Test net output #1: loss = 0.443618 (* 1 = 0.443618 loss)
I0522 20:14:29.886646 22569 solver.cpp:237] Iteration 30000, loss = 1.09639
I0522 20:14:29.886699 22569 solver.cpp:253]     Train net output #0: loss = 1.09639 (* 1 = 1.09639 loss)
I0522 20:14:29.886714 22569 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0522 20:14:39.763188 22569 solver.cpp:237] Iteration 30375, loss = 1.33564
I0522 20:14:39.763355 22569 solver.cpp:253]     Train net output #0: loss = 1.33564 (* 1 = 1.33564 loss)
I0522 20:14:39.763367 22569 sgd_solver.cpp:106] Iteration 30375, lr = 0.0025
I0522 20:14:49.646765 22569 solver.cpp:237] Iteration 30750, loss = 1.41065
I0522 20:14:49.646800 22569 solver.cpp:253]     Train net output #0: loss = 1.41065 (* 1 = 1.41065 loss)
I0522 20:14:49.646816 22569 sgd_solver.cpp:106] Iteration 30750, lr = 0.0025
I0522 20:14:59.522400 22569 solver.cpp:237] Iteration 31125, loss = 1.34364
I0522 20:14:59.522442 22569 solver.cpp:253]     Train net output #0: loss = 1.34364 (* 1 = 1.34364 loss)
I0522 20:14:59.522459 22569 sgd_solver.cpp:106] Iteration 31125, lr = 0.0025
I0522 20:15:09.400122 22569 solver.cpp:237] Iteration 31500, loss = 1.29843
I0522 20:15:09.400157 22569 solver.cpp:253]     Train net output #0: loss = 1.29843 (* 1 = 1.29843 loss)
I0522 20:15:09.400171 22569 sgd_solver.cpp:106] Iteration 31500, lr = 0.0025
I0522 20:15:19.272616 22569 solver.cpp:237] Iteration 31875, loss = 1.21623
I0522 20:15:19.272761 22569 solver.cpp:253]     Train net output #0: loss = 1.21623 (* 1 = 1.21623 loss)
I0522 20:15:19.272775 22569 sgd_solver.cpp:106] Iteration 31875, lr = 0.0025
I0522 20:15:29.143826 22569 solver.cpp:237] Iteration 32250, loss = 1.09116
I0522 20:15:29.143867 22569 solver.cpp:253]     Train net output #0: loss = 1.09116 (* 1 = 1.09116 loss)
I0522 20:15:29.143883 22569 sgd_solver.cpp:106] Iteration 32250, lr = 0.0025
I0522 20:16:01.179780 22569 solver.cpp:237] Iteration 32625, loss = 1.36979
I0522 20:16:01.179950 22569 solver.cpp:253]     Train net output #0: loss = 1.36979 (* 1 = 1.36979 loss)
I0522 20:16:01.179965 22569 sgd_solver.cpp:106] Iteration 32625, lr = 0.0025
I0522 20:16:11.058089 22569 solver.cpp:237] Iteration 33000, loss = 1.44049
I0522 20:16:11.058122 22569 solver.cpp:253]     Train net output #0: loss = 1.44049 (* 1 = 1.44049 loss)
I0522 20:16:11.058138 22569 sgd_solver.cpp:106] Iteration 33000, lr = 0.0025
I0522 20:16:20.935230 22569 solver.cpp:237] Iteration 33375, loss = 1.18805
I0522 20:16:20.935266 22569 solver.cpp:253]     Train net output #0: loss = 1.18805 (* 1 = 1.18805 loss)
I0522 20:16:20.935277 22569 sgd_solver.cpp:106] Iteration 33375, lr = 0.0025
I0522 20:16:30.786303 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_33750.caffemodel
I0522 20:16:30.843601 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_33750.solverstate
I0522 20:16:30.879652 22569 solver.cpp:237] Iteration 33750, loss = 1.34911
I0522 20:16:30.879701 22569 solver.cpp:253]     Train net output #0: loss = 1.34911 (* 1 = 1.34911 loss)
I0522 20:16:30.879716 22569 sgd_solver.cpp:106] Iteration 33750, lr = 0.0025
I0522 20:16:40.754107 22569 solver.cpp:237] Iteration 34125, loss = 1.17817
I0522 20:16:40.754271 22569 solver.cpp:253]     Train net output #0: loss = 1.17817 (* 1 = 1.17817 loss)
I0522 20:16:40.754284 22569 sgd_solver.cpp:106] Iteration 34125, lr = 0.0025
I0522 20:16:50.630861 22569 solver.cpp:237] Iteration 34500, loss = 1.6737
I0522 20:16:50.630894 22569 solver.cpp:253]     Train net output #0: loss = 1.6737 (* 1 = 1.6737 loss)
I0522 20:16:50.630910 22569 sgd_solver.cpp:106] Iteration 34500, lr = 0.0025
I0522 20:17:00.508950 22569 solver.cpp:237] Iteration 34875, loss = 1.29266
I0522 20:17:00.508985 22569 solver.cpp:253]     Train net output #0: loss = 1.29266 (* 1 = 1.29266 loss)
I0522 20:17:00.509001 22569 sgd_solver.cpp:106] Iteration 34875, lr = 0.0025
I0522 20:17:32.582942 22569 solver.cpp:237] Iteration 35250, loss = 1.09647
I0522 20:17:32.583123 22569 solver.cpp:253]     Train net output #0: loss = 1.09647 (* 1 = 1.09647 loss)
I0522 20:17:32.583138 22569 sgd_solver.cpp:106] Iteration 35250, lr = 0.0025
I0522 20:17:42.469267 22569 solver.cpp:237] Iteration 35625, loss = 1.19313
I0522 20:17:42.469302 22569 solver.cpp:253]     Train net output #0: loss = 1.19313 (* 1 = 1.19313 loss)
I0522 20:17:42.469317 22569 sgd_solver.cpp:106] Iteration 35625, lr = 0.0025
I0522 20:17:52.343315 22569 solver.cpp:237] Iteration 36000, loss = 1.12779
I0522 20:17:52.343351 22569 solver.cpp:253]     Train net output #0: loss = 1.12779 (* 1 = 1.12779 loss)
I0522 20:17:52.343364 22569 sgd_solver.cpp:106] Iteration 36000, lr = 0.0025
I0522 20:18:02.222654 22569 solver.cpp:237] Iteration 36375, loss = 1.47303
I0522 20:18:02.222695 22569 solver.cpp:253]     Train net output #0: loss = 1.47303 (* 1 = 1.47303 loss)
I0522 20:18:02.222712 22569 sgd_solver.cpp:106] Iteration 36375, lr = 0.0025
I0522 20:18:12.099932 22569 solver.cpp:237] Iteration 36750, loss = 1.20095
I0522 20:18:12.100080 22569 solver.cpp:253]     Train net output #0: loss = 1.20095 (* 1 = 1.20095 loss)
I0522 20:18:12.100093 22569 sgd_solver.cpp:106] Iteration 36750, lr = 0.0025
I0522 20:18:21.983805 22569 solver.cpp:237] Iteration 37125, loss = 1.58829
I0522 20:18:21.983855 22569 solver.cpp:253]     Train net output #0: loss = 1.58829 (* 1 = 1.58829 loss)
I0522 20:18:21.983870 22569 sgd_solver.cpp:106] Iteration 37125, lr = 0.0025
I0522 20:18:31.837128 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_37500.caffemodel
I0522 20:18:31.895211 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_37500.solverstate
I0522 20:18:31.924597 22569 solver.cpp:341] Iteration 37500, Testing net (#0)
I0522 20:19:20.482962 22569 solver.cpp:409]     Test net output #0: accuracy = 0.868079
I0522 20:19:20.483135 22569 solver.cpp:409]     Test net output #1: loss = 0.433524 (* 1 = 0.433524 loss)
I0522 20:19:41.397465 22569 solver.cpp:237] Iteration 37500, loss = 1.23313
I0522 20:19:41.397516 22569 solver.cpp:253]     Train net output #0: loss = 1.23313 (* 1 = 1.23313 loss)
I0522 20:19:41.397531 22569 sgd_solver.cpp:106] Iteration 37500, lr = 0.0025
I0522 20:19:51.314075 22569 solver.cpp:237] Iteration 37875, loss = 1.03202
I0522 20:19:51.314230 22569 solver.cpp:253]     Train net output #0: loss = 1.03202 (* 1 = 1.03202 loss)
I0522 20:19:51.314244 22569 sgd_solver.cpp:106] Iteration 37875, lr = 0.0025
I0522 20:20:01.233672 22569 solver.cpp:237] Iteration 38250, loss = 1.13243
I0522 20:20:01.233716 22569 solver.cpp:253]     Train net output #0: loss = 1.13243 (* 1 = 1.13243 loss)
I0522 20:20:01.233731 22569 sgd_solver.cpp:106] Iteration 38250, lr = 0.0025
I0522 20:20:11.139633 22569 solver.cpp:237] Iteration 38625, loss = 1.36383
I0522 20:20:11.139670 22569 solver.cpp:253]     Train net output #0: loss = 1.36383 (* 1 = 1.36383 loss)
I0522 20:20:11.139684 22569 sgd_solver.cpp:106] Iteration 38625, lr = 0.0025
I0522 20:20:21.059101 22569 solver.cpp:237] Iteration 39000, loss = 1.20329
I0522 20:20:21.059136 22569 solver.cpp:253]     Train net output #0: loss = 1.20329 (* 1 = 1.20329 loss)
I0522 20:20:21.059151 22569 sgd_solver.cpp:106] Iteration 39000, lr = 0.0025
I0522 20:20:30.971369 22569 solver.cpp:237] Iteration 39375, loss = 1.31655
I0522 20:20:30.971535 22569 solver.cpp:253]     Train net output #0: loss = 1.31655 (* 1 = 1.31655 loss)
I0522 20:20:30.971549 22569 sgd_solver.cpp:106] Iteration 39375, lr = 0.0025
I0522 20:20:40.888898 22569 solver.cpp:237] Iteration 39750, loss = 1.08173
I0522 20:20:40.888929 22569 solver.cpp:253]     Train net output #0: loss = 1.08173 (* 1 = 1.08173 loss)
I0522 20:20:40.888942 22569 sgd_solver.cpp:106] Iteration 39750, lr = 0.0025
I0522 20:21:11.645416 22569 solver.cpp:237] Iteration 40125, loss = 1.36729
I0522 20:21:11.645591 22569 solver.cpp:253]     Train net output #0: loss = 1.36729 (* 1 = 1.36729 loss)
I0522 20:21:11.645606 22569 sgd_solver.cpp:106] Iteration 40125, lr = 0.0025
I0522 20:21:21.556720 22569 solver.cpp:237] Iteration 40500, loss = 1.24235
I0522 20:21:21.556759 22569 solver.cpp:253]     Train net output #0: loss = 1.24235 (* 1 = 1.24235 loss)
I0522 20:21:21.556776 22569 sgd_solver.cpp:106] Iteration 40500, lr = 0.0025
I0522 20:21:31.458730 22569 solver.cpp:237] Iteration 40875, loss = 1.25027
I0522 20:21:31.458765 22569 solver.cpp:253]     Train net output #0: loss = 1.25027 (* 1 = 1.25027 loss)
I0522 20:21:31.458777 22569 sgd_solver.cpp:106] Iteration 40875, lr = 0.0025
I0522 20:21:41.313648 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_41250.caffemodel
I0522 20:21:41.369983 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_41250.solverstate
I0522 20:21:41.404367 22569 solver.cpp:237] Iteration 41250, loss = 1.2102
I0522 20:21:41.404412 22569 solver.cpp:253]     Train net output #0: loss = 1.2102 (* 1 = 1.2102 loss)
I0522 20:21:41.404428 22569 sgd_solver.cpp:106] Iteration 41250, lr = 0.0025
I0522 20:21:51.283213 22569 solver.cpp:237] Iteration 41625, loss = 1.30675
I0522 20:21:51.283367 22569 solver.cpp:253]     Train net output #0: loss = 1.30675 (* 1 = 1.30675 loss)
I0522 20:21:51.283380 22569 sgd_solver.cpp:106] Iteration 41625, lr = 0.0025
I0522 20:22:01.162400 22569 solver.cpp:237] Iteration 42000, loss = 1.60349
I0522 20:22:01.162433 22569 solver.cpp:253]     Train net output #0: loss = 1.60349 (* 1 = 1.60349 loss)
I0522 20:22:01.162448 22569 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0522 20:22:11.037423 22569 solver.cpp:237] Iteration 42375, loss = 1.28798
I0522 20:22:11.037472 22569 solver.cpp:253]     Train net output #0: loss = 1.28798 (* 1 = 1.28798 loss)
I0522 20:22:11.037485 22569 sgd_solver.cpp:106] Iteration 42375, lr = 0.0025
I0522 20:22:41.756296 22569 solver.cpp:237] Iteration 42750, loss = 0.929342
I0522 20:22:41.756466 22569 solver.cpp:253]     Train net output #0: loss = 0.929341 (* 1 = 0.929341 loss)
I0522 20:22:41.756484 22569 sgd_solver.cpp:106] Iteration 42750, lr = 0.0025
I0522 20:22:51.638622 22569 solver.cpp:237] Iteration 43125, loss = 1.02968
I0522 20:22:51.638658 22569 solver.cpp:253]     Train net output #0: loss = 1.02968 (* 1 = 1.02968 loss)
I0522 20:22:51.638674 22569 sgd_solver.cpp:106] Iteration 43125, lr = 0.0025
I0522 20:23:01.528481 22569 solver.cpp:237] Iteration 43500, loss = 1.4546
I0522 20:23:01.528522 22569 solver.cpp:253]     Train net output #0: loss = 1.4546 (* 1 = 1.4546 loss)
I0522 20:23:01.528543 22569 sgd_solver.cpp:106] Iteration 43500, lr = 0.0025
I0522 20:23:11.405613 22569 solver.cpp:237] Iteration 43875, loss = 1.33521
I0522 20:23:11.405647 22569 solver.cpp:253]     Train net output #0: loss = 1.33521 (* 1 = 1.33521 loss)
I0522 20:23:11.405663 22569 sgd_solver.cpp:106] Iteration 43875, lr = 0.0025
I0522 20:23:21.288271 22569 solver.cpp:237] Iteration 44250, loss = 1.08741
I0522 20:23:21.288440 22569 solver.cpp:253]     Train net output #0: loss = 1.08741 (* 1 = 1.08741 loss)
I0522 20:23:21.288455 22569 sgd_solver.cpp:106] Iteration 44250, lr = 0.0025
I0522 20:23:31.163642 22569 solver.cpp:237] Iteration 44625, loss = 1.00414
I0522 20:23:31.163677 22569 solver.cpp:253]     Train net output #0: loss = 1.00414 (* 1 = 1.00414 loss)
I0522 20:23:31.163692 22569 sgd_solver.cpp:106] Iteration 44625, lr = 0.0025
I0522 20:23:41.015646 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_45000.caffemodel
I0522 20:23:41.072295 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_45000.solverstate
I0522 20:23:41.098913 22569 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 20:24:50.380002 22569 solver.cpp:409]     Test net output #0: accuracy = 0.87654
I0522 20:24:50.380179 22569 solver.cpp:409]     Test net output #1: loss = 0.383999 (* 1 = 0.383999 loss)
I0522 20:25:11.221063 22569 solver.cpp:237] Iteration 45000, loss = 1.01759
I0522 20:25:11.221117 22569 solver.cpp:253]     Train net output #0: loss = 1.01759 (* 1 = 1.01759 loss)
I0522 20:25:11.221132 22569 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0522 20:25:21.053912 22569 solver.cpp:237] Iteration 45375, loss = 1.15766
I0522 20:25:21.054071 22569 solver.cpp:253]     Train net output #0: loss = 1.15766 (* 1 = 1.15766 loss)
I0522 20:25:21.054085 22569 sgd_solver.cpp:106] Iteration 45375, lr = 0.0025
I0522 20:25:30.886695 22569 solver.cpp:237] Iteration 45750, loss = 1.13084
I0522 20:25:30.886741 22569 solver.cpp:253]     Train net output #0: loss = 1.13084 (* 1 = 1.13084 loss)
I0522 20:25:30.886754 22569 sgd_solver.cpp:106] Iteration 45750, lr = 0.0025
I0522 20:25:40.719385 22569 solver.cpp:237] Iteration 46125, loss = 1.29764
I0522 20:25:40.719420 22569 solver.cpp:253]     Train net output #0: loss = 1.29764 (* 1 = 1.29764 loss)
I0522 20:25:40.719435 22569 sgd_solver.cpp:106] Iteration 46125, lr = 0.0025
I0522 20:25:50.552525 22569 solver.cpp:237] Iteration 46500, loss = 1.05435
I0522 20:25:50.552569 22569 solver.cpp:253]     Train net output #0: loss = 1.05435 (* 1 = 1.05435 loss)
I0522 20:25:50.552584 22569 sgd_solver.cpp:106] Iteration 46500, lr = 0.0025
I0522 20:26:00.387305 22569 solver.cpp:237] Iteration 46875, loss = 1.48522
I0522 20:26:00.387456 22569 solver.cpp:253]     Train net output #0: loss = 1.48522 (* 1 = 1.48522 loss)
I0522 20:26:00.387470 22569 sgd_solver.cpp:106] Iteration 46875, lr = 0.0025
I0522 20:26:10.216827 22569 solver.cpp:237] Iteration 47250, loss = 1.19594
I0522 20:26:10.216861 22569 solver.cpp:253]     Train net output #0: loss = 1.19594 (* 1 = 1.19594 loss)
I0522 20:26:10.216881 22569 sgd_solver.cpp:106] Iteration 47250, lr = 0.0025
I0522 20:26:40.908171 22569 solver.cpp:237] Iteration 47625, loss = 1.19579
I0522 20:26:40.908340 22569 solver.cpp:253]     Train net output #0: loss = 1.19579 (* 1 = 1.19579 loss)
I0522 20:26:40.908357 22569 sgd_solver.cpp:106] Iteration 47625, lr = 0.0025
I0522 20:26:50.738557 22569 solver.cpp:237] Iteration 48000, loss = 0.928619
I0522 20:26:50.738592 22569 solver.cpp:253]     Train net output #0: loss = 0.928619 (* 1 = 0.928619 loss)
I0522 20:26:50.738610 22569 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0522 20:27:00.567237 22569 solver.cpp:237] Iteration 48375, loss = 1.24385
I0522 20:27:00.567273 22569 solver.cpp:253]     Train net output #0: loss = 1.24385 (* 1 = 1.24385 loss)
I0522 20:27:00.567288 22569 sgd_solver.cpp:106] Iteration 48375, lr = 0.0025
I0522 20:27:10.376619 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_48750.caffemodel
I0522 20:27:10.432353 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_48750.solverstate
I0522 20:27:10.466889 22569 solver.cpp:237] Iteration 48750, loss = 1.1898
I0522 20:27:10.466931 22569 solver.cpp:253]     Train net output #0: loss = 1.1898 (* 1 = 1.1898 loss)
I0522 20:27:10.466945 22569 sgd_solver.cpp:106] Iteration 48750, lr = 0.0025
I0522 20:27:20.301195 22569 solver.cpp:237] Iteration 49125, loss = 1.17248
I0522 20:27:20.301358 22569 solver.cpp:253]     Train net output #0: loss = 1.17248 (* 1 = 1.17248 loss)
I0522 20:27:20.301373 22569 sgd_solver.cpp:106] Iteration 49125, lr = 0.0025
I0522 20:27:30.137471 22569 solver.cpp:237] Iteration 49500, loss = 1.26472
I0522 20:27:30.137518 22569 solver.cpp:253]     Train net output #0: loss = 1.26472 (* 1 = 1.26472 loss)
I0522 20:27:30.137532 22569 sgd_solver.cpp:106] Iteration 49500, lr = 0.0025
I0522 20:27:39.969684 22569 solver.cpp:237] Iteration 49875, loss = 1.27431
I0522 20:27:39.969719 22569 solver.cpp:253]     Train net output #0: loss = 1.27431 (* 1 = 1.27431 loss)
I0522 20:27:39.969734 22569 sgd_solver.cpp:106] Iteration 49875, lr = 0.0025
I0522 20:28:10.698582 22569 solver.cpp:237] Iteration 50250, loss = 1.25128
I0522 20:28:10.698755 22569 solver.cpp:253]     Train net output #0: loss = 1.25128 (* 1 = 1.25128 loss)
I0522 20:28:10.698768 22569 sgd_solver.cpp:106] Iteration 50250, lr = 0.0025
I0522 20:28:20.572270 22569 solver.cpp:237] Iteration 50625, loss = 0.943182
I0522 20:28:20.572315 22569 solver.cpp:253]     Train net output #0: loss = 0.943182 (* 1 = 0.943182 loss)
I0522 20:28:20.572331 22569 sgd_solver.cpp:106] Iteration 50625, lr = 0.0025
I0522 20:28:30.438029 22569 solver.cpp:237] Iteration 51000, loss = 1.00024
I0522 20:28:30.438063 22569 solver.cpp:253]     Train net output #0: loss = 1.00024 (* 1 = 1.00024 loss)
I0522 20:28:30.438078 22569 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0522 20:28:40.300772 22569 solver.cpp:237] Iteration 51375, loss = 1.0833
I0522 20:28:40.300807 22569 solver.cpp:253]     Train net output #0: loss = 1.0833 (* 1 = 1.0833 loss)
I0522 20:28:40.300822 22569 sgd_solver.cpp:106] Iteration 51375, lr = 0.0025
I0522 20:28:50.170578 22569 solver.cpp:237] Iteration 51750, loss = 1.137
I0522 20:28:50.170739 22569 solver.cpp:253]     Train net output #0: loss = 1.137 (* 1 = 1.137 loss)
I0522 20:28:50.170753 22569 sgd_solver.cpp:106] Iteration 51750, lr = 0.0025
I0522 20:29:00.041334 22569 solver.cpp:237] Iteration 52125, loss = 0.847797
I0522 20:29:00.041369 22569 solver.cpp:253]     Train net output #0: loss = 0.847797 (* 1 = 0.847797 loss)
I0522 20:29:00.041384 22569 sgd_solver.cpp:106] Iteration 52125, lr = 0.0025
I0522 20:29:09.882745 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_52500.caffemodel
I0522 20:29:09.938948 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_52500.solverstate
I0522 20:29:09.965440 22569 solver.cpp:341] Iteration 52500, Testing net (#0)
I0522 20:29:58.149189 22569 solver.cpp:409]     Test net output #0: accuracy = 0.877333
I0522 20:29:58.149361 22569 solver.cpp:409]     Test net output #1: loss = 0.407125 (* 1 = 0.407125 loss)
I0522 20:30:19.049485 22569 solver.cpp:237] Iteration 52500, loss = 0.926937
I0522 20:30:19.049541 22569 solver.cpp:253]     Train net output #0: loss = 0.926937 (* 1 = 0.926937 loss)
I0522 20:30:19.049556 22569 sgd_solver.cpp:106] Iteration 52500, lr = 0.0025
I0522 20:30:28.789506 22569 solver.cpp:237] Iteration 52875, loss = 0.86445
I0522 20:30:28.789675 22569 solver.cpp:253]     Train net output #0: loss = 0.864449 (* 1 = 0.864449 loss)
I0522 20:30:28.789690 22569 sgd_solver.cpp:106] Iteration 52875, lr = 0.0025
I0522 20:30:38.531368 22569 solver.cpp:237] Iteration 53250, loss = 0.954602
I0522 20:30:38.531404 22569 solver.cpp:253]     Train net output #0: loss = 0.954601 (* 1 = 0.954601 loss)
I0522 20:30:38.531419 22569 sgd_solver.cpp:106] Iteration 53250, lr = 0.0025
I0522 20:30:48.270758 22569 solver.cpp:237] Iteration 53625, loss = 1.12291
I0522 20:30:48.270794 22569 solver.cpp:253]     Train net output #0: loss = 1.12291 (* 1 = 1.12291 loss)
I0522 20:30:48.270808 22569 sgd_solver.cpp:106] Iteration 53625, lr = 0.0025
I0522 20:30:58.012717 22569 solver.cpp:237] Iteration 54000, loss = 1.40997
I0522 20:30:58.012758 22569 solver.cpp:253]     Train net output #0: loss = 1.40997 (* 1 = 1.40997 loss)
I0522 20:30:58.012778 22569 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0522 20:31:07.755054 22569 solver.cpp:237] Iteration 54375, loss = 1.26711
I0522 20:31:07.755218 22569 solver.cpp:253]     Train net output #0: loss = 1.2671 (* 1 = 1.2671 loss)
I0522 20:31:07.755231 22569 sgd_solver.cpp:106] Iteration 54375, lr = 0.0025
I0522 20:31:17.493371 22569 solver.cpp:237] Iteration 54750, loss = 1.12657
I0522 20:31:17.493420 22569 solver.cpp:253]     Train net output #0: loss = 1.12657 (* 1 = 1.12657 loss)
I0522 20:31:17.493433 22569 sgd_solver.cpp:106] Iteration 54750, lr = 0.0025
I0522 20:31:48.150146 22569 solver.cpp:237] Iteration 55125, loss = 1.50554
I0522 20:31:48.150318 22569 solver.cpp:253]     Train net output #0: loss = 1.50554 (* 1 = 1.50554 loss)
I0522 20:31:48.150334 22569 sgd_solver.cpp:106] Iteration 55125, lr = 0.0025
I0522 20:31:57.885421 22569 solver.cpp:237] Iteration 55500, loss = 1.11772
I0522 20:31:57.885455 22569 solver.cpp:253]     Train net output #0: loss = 1.11772 (* 1 = 1.11772 loss)
I0522 20:31:57.885471 22569 sgd_solver.cpp:106] Iteration 55500, lr = 0.0025
I0522 20:32:07.621477 22569 solver.cpp:237] Iteration 55875, loss = 1.11697
I0522 20:32:07.621521 22569 solver.cpp:253]     Train net output #0: loss = 1.11697 (* 1 = 1.11697 loss)
I0522 20:32:07.621536 22569 sgd_solver.cpp:106] Iteration 55875, lr = 0.0025
I0522 20:32:17.337047 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_56250.caffemodel
I0522 20:32:17.394642 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_56250.solverstate
I0522 20:32:17.430810 22569 solver.cpp:237] Iteration 56250, loss = 0.994393
I0522 20:32:17.430856 22569 solver.cpp:253]     Train net output #0: loss = 0.994393 (* 1 = 0.994393 loss)
I0522 20:32:17.430871 22569 sgd_solver.cpp:106] Iteration 56250, lr = 0.0025
I0522 20:32:27.162120 22569 solver.cpp:237] Iteration 56625, loss = 1.07548
I0522 20:32:27.162278 22569 solver.cpp:253]     Train net output #0: loss = 1.07548 (* 1 = 1.07548 loss)
I0522 20:32:27.162292 22569 sgd_solver.cpp:106] Iteration 56625, lr = 0.0025
I0522 20:32:36.901619 22569 solver.cpp:237] Iteration 57000, loss = 1.22979
I0522 20:32:36.901664 22569 solver.cpp:253]     Train net output #0: loss = 1.22979 (* 1 = 1.22979 loss)
I0522 20:32:36.901676 22569 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0522 20:32:46.635810 22569 solver.cpp:237] Iteration 57375, loss = 1.33231
I0522 20:32:46.635846 22569 solver.cpp:253]     Train net output #0: loss = 1.33231 (* 1 = 1.33231 loss)
I0522 20:32:46.635860 22569 sgd_solver.cpp:106] Iteration 57375, lr = 0.0025
I0522 20:33:17.279618 22569 solver.cpp:237] Iteration 57750, loss = 0.966943
I0522 20:33:17.279793 22569 solver.cpp:253]     Train net output #0: loss = 0.966943 (* 1 = 0.966943 loss)
I0522 20:33:17.279808 22569 sgd_solver.cpp:106] Iteration 57750, lr = 0.0025
I0522 20:33:27.020030 22569 solver.cpp:237] Iteration 58125, loss = 1.12197
I0522 20:33:27.020066 22569 solver.cpp:253]     Train net output #0: loss = 1.12197 (* 1 = 1.12197 loss)
I0522 20:33:27.020078 22569 sgd_solver.cpp:106] Iteration 58125, lr = 0.0025
I0522 20:33:36.755838 22569 solver.cpp:237] Iteration 58500, loss = 1.09899
I0522 20:33:36.755874 22569 solver.cpp:253]     Train net output #0: loss = 1.09899 (* 1 = 1.09899 loss)
I0522 20:33:36.755888 22569 sgd_solver.cpp:106] Iteration 58500, lr = 0.0025
I0522 20:33:46.491804 22569 solver.cpp:237] Iteration 58875, loss = 1.212
I0522 20:33:46.491847 22569 solver.cpp:253]     Train net output #0: loss = 1.212 (* 1 = 1.212 loss)
I0522 20:33:46.491863 22569 sgd_solver.cpp:106] Iteration 58875, lr = 0.0025
I0522 20:33:56.230926 22569 solver.cpp:237] Iteration 59250, loss = 1.33895
I0522 20:33:56.231086 22569 solver.cpp:253]     Train net output #0: loss = 1.33895 (* 1 = 1.33895 loss)
I0522 20:33:56.231099 22569 sgd_solver.cpp:106] Iteration 59250, lr = 0.0025
I0522 20:34:05.976253 22569 solver.cpp:237] Iteration 59625, loss = 1.08726
I0522 20:34:05.976287 22569 solver.cpp:253]     Train net output #0: loss = 1.08726 (* 1 = 1.08726 loss)
I0522 20:34:05.976302 22569 sgd_solver.cpp:106] Iteration 59625, lr = 0.0025
I0522 20:34:15.690585 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_60000.caffemodel
I0522 20:34:15.746368 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_60000.solverstate
I0522 20:34:15.772770 22569 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 20:35:25.175374 22569 solver.cpp:409]     Test net output #0: accuracy = 0.881414
I0522 20:35:25.175547 22569 solver.cpp:409]     Test net output #1: loss = 0.376767 (* 1 = 0.376767 loss)
I0522 20:35:46.054020 22569 solver.cpp:237] Iteration 60000, loss = 1.09514
I0522 20:35:46.054072 22569 solver.cpp:253]     Train net output #0: loss = 1.09514 (* 1 = 1.09514 loss)
I0522 20:35:46.054087 22569 sgd_solver.cpp:106] Iteration 60000, lr = 0.0025
I0522 20:35:55.938320 22569 solver.cpp:237] Iteration 60375, loss = 1.11808
I0522 20:35:55.938495 22569 solver.cpp:253]     Train net output #0: loss = 1.11808 (* 1 = 1.11808 loss)
I0522 20:35:55.938509 22569 sgd_solver.cpp:106] Iteration 60375, lr = 0.0025
I0522 20:36:05.818001 22569 solver.cpp:237] Iteration 60750, loss = 1.18376
I0522 20:36:05.818037 22569 solver.cpp:253]     Train net output #0: loss = 1.18376 (* 1 = 1.18376 loss)
I0522 20:36:05.818051 22569 sgd_solver.cpp:106] Iteration 60750, lr = 0.0025
I0522 20:36:15.693999 22569 solver.cpp:237] Iteration 61125, loss = 1.46546
I0522 20:36:15.694041 22569 solver.cpp:253]     Train net output #0: loss = 1.46546 (* 1 = 1.46546 loss)
I0522 20:36:15.694058 22569 sgd_solver.cpp:106] Iteration 61125, lr = 0.0025
I0522 20:36:25.574463 22569 solver.cpp:237] Iteration 61500, loss = 1.2155
I0522 20:36:25.574499 22569 solver.cpp:253]     Train net output #0: loss = 1.2155 (* 1 = 1.2155 loss)
I0522 20:36:25.574514 22569 sgd_solver.cpp:106] Iteration 61500, lr = 0.0025
I0522 20:36:35.459558 22569 solver.cpp:237] Iteration 61875, loss = 1.14237
I0522 20:36:35.459705 22569 solver.cpp:253]     Train net output #0: loss = 1.14237 (* 1 = 1.14237 loss)
I0522 20:36:35.459719 22569 sgd_solver.cpp:106] Iteration 61875, lr = 0.0025
I0522 20:36:45.339042 22569 solver.cpp:237] Iteration 62250, loss = 0.970558
I0522 20:36:45.339082 22569 solver.cpp:253]     Train net output #0: loss = 0.970558 (* 1 = 0.970558 loss)
I0522 20:36:45.339095 22569 sgd_solver.cpp:106] Iteration 62250, lr = 0.0025
I0522 20:37:16.097194 22569 solver.cpp:237] Iteration 62625, loss = 1.35907
I0522 20:37:16.097371 22569 solver.cpp:253]     Train net output #0: loss = 1.35907 (* 1 = 1.35907 loss)
I0522 20:37:16.097386 22569 sgd_solver.cpp:106] Iteration 62625, lr = 0.0025
I0522 20:37:25.975548 22569 solver.cpp:237] Iteration 63000, loss = 0.997402
I0522 20:37:25.975584 22569 solver.cpp:253]     Train net output #0: loss = 0.997401 (* 1 = 0.997401 loss)
I0522 20:37:25.975600 22569 sgd_solver.cpp:106] Iteration 63000, lr = 0.0025
I0522 20:37:35.853050 22569 solver.cpp:237] Iteration 63375, loss = 0.823541
I0522 20:37:35.853099 22569 solver.cpp:253]     Train net output #0: loss = 0.823541 (* 1 = 0.823541 loss)
I0522 20:37:35.853113 22569 sgd_solver.cpp:106] Iteration 63375, lr = 0.0025
I0522 20:37:45.705571 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_63750.caffemodel
I0522 20:37:45.761692 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_63750.solverstate
I0522 20:37:45.796211 22569 solver.cpp:237] Iteration 63750, loss = 1.32918
I0522 20:37:45.796257 22569 solver.cpp:253]     Train net output #0: loss = 1.32918 (* 1 = 1.32918 loss)
I0522 20:37:45.796272 22569 sgd_solver.cpp:106] Iteration 63750, lr = 0.0025
I0522 20:37:55.682826 22569 solver.cpp:237] Iteration 64125, loss = 1.30201
I0522 20:37:55.683009 22569 solver.cpp:253]     Train net output #0: loss = 1.30201 (* 1 = 1.30201 loss)
I0522 20:37:55.683023 22569 sgd_solver.cpp:106] Iteration 64125, lr = 0.0025
I0522 20:38:05.563989 22569 solver.cpp:237] Iteration 64500, loss = 1.07499
I0522 20:38:05.564023 22569 solver.cpp:253]     Train net output #0: loss = 1.07499 (* 1 = 1.07499 loss)
I0522 20:38:05.564039 22569 sgd_solver.cpp:106] Iteration 64500, lr = 0.0025
I0522 20:38:15.445427 22569 solver.cpp:237] Iteration 64875, loss = 1.13571
I0522 20:38:15.445462 22569 solver.cpp:253]     Train net output #0: loss = 1.13571 (* 1 = 1.13571 loss)
I0522 20:38:15.445477 22569 sgd_solver.cpp:106] Iteration 64875, lr = 0.0025
I0522 20:38:46.213346 22569 solver.cpp:237] Iteration 65250, loss = 1.41587
I0522 20:38:46.213523 22569 solver.cpp:253]     Train net output #0: loss = 1.41587 (* 1 = 1.41587 loss)
I0522 20:38:46.213538 22569 sgd_solver.cpp:106] Iteration 65250, lr = 0.0025
I0522 20:38:56.093111 22569 solver.cpp:237] Iteration 65625, loss = 1.4647
I0522 20:38:56.093145 22569 solver.cpp:253]     Train net output #0: loss = 1.4647 (* 1 = 1.4647 loss)
I0522 20:38:56.093161 22569 sgd_solver.cpp:106] Iteration 65625, lr = 0.0025
I0522 20:39:05.976601 22569 solver.cpp:237] Iteration 66000, loss = 1.24402
I0522 20:39:05.976637 22569 solver.cpp:253]     Train net output #0: loss = 1.24402 (* 1 = 1.24402 loss)
I0522 20:39:05.976652 22569 sgd_solver.cpp:106] Iteration 66000, lr = 0.0025
I0522 20:39:15.856716 22569 solver.cpp:237] Iteration 66375, loss = 1.18125
I0522 20:39:15.856762 22569 solver.cpp:253]     Train net output #0: loss = 1.18125 (* 1 = 1.18125 loss)
I0522 20:39:15.856777 22569 sgd_solver.cpp:106] Iteration 66375, lr = 0.0025
I0522 20:39:25.731818 22569 solver.cpp:237] Iteration 66750, loss = 1.05047
I0522 20:39:25.731973 22569 solver.cpp:253]     Train net output #0: loss = 1.05047 (* 1 = 1.05047 loss)
I0522 20:39:25.731987 22569 sgd_solver.cpp:106] Iteration 66750, lr = 0.0025
I0522 20:39:35.601265 22569 solver.cpp:237] Iteration 67125, loss = 1.42321
I0522 20:39:35.601315 22569 solver.cpp:253]     Train net output #0: loss = 1.42321 (* 1 = 1.42321 loss)
I0522 20:39:35.601328 22569 sgd_solver.cpp:106] Iteration 67125, lr = 0.0025
I0522 20:39:45.458792 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_67500.caffemodel
I0522 20:39:45.516163 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_67500.solverstate
I0522 20:39:45.542945 22569 solver.cpp:341] Iteration 67500, Testing net (#0)
I0522 20:40:34.064338 22569 solver.cpp:409]     Test net output #0: accuracy = 0.884233
I0522 20:40:34.064507 22569 solver.cpp:409]     Test net output #1: loss = 0.365366 (* 1 = 0.365366 loss)
I0522 20:40:54.928187 22569 solver.cpp:237] Iteration 67500, loss = 1.1353
I0522 20:40:54.928238 22569 solver.cpp:253]     Train net output #0: loss = 1.1353 (* 1 = 1.1353 loss)
I0522 20:40:54.928253 22569 sgd_solver.cpp:106] Iteration 67500, lr = 0.0025
I0522 20:41:04.632485 22569 solver.cpp:237] Iteration 67875, loss = 1.42698
I0522 20:41:04.632650 22569 solver.cpp:253]     Train net output #0: loss = 1.42698 (* 1 = 1.42698 loss)
I0522 20:41:04.632664 22569 sgd_solver.cpp:106] Iteration 67875, lr = 0.0025
I0522 20:41:14.345172 22569 solver.cpp:237] Iteration 68250, loss = 1.02469
I0522 20:41:14.345216 22569 solver.cpp:253]     Train net output #0: loss = 1.02469 (* 1 = 1.02469 loss)
I0522 20:41:14.345232 22569 sgd_solver.cpp:106] Iteration 68250, lr = 0.0025
I0522 20:41:24.051120 22569 solver.cpp:237] Iteration 68625, loss = 1.1261
I0522 20:41:24.051156 22569 solver.cpp:253]     Train net output #0: loss = 1.1261 (* 1 = 1.1261 loss)
I0522 20:41:24.051172 22569 sgd_solver.cpp:106] Iteration 68625, lr = 0.0025
I0522 20:41:33.762066 22569 solver.cpp:237] Iteration 69000, loss = 1.08193
I0522 20:41:33.762101 22569 solver.cpp:253]     Train net output #0: loss = 1.08193 (* 1 = 1.08193 loss)
I0522 20:41:33.762116 22569 sgd_solver.cpp:106] Iteration 69000, lr = 0.0025
I0522 20:41:43.467823 22569 solver.cpp:237] Iteration 69375, loss = 0.938077
I0522 20:41:43.467998 22569 solver.cpp:253]     Train net output #0: loss = 0.938077 (* 1 = 0.938077 loss)
I0522 20:41:43.468013 22569 sgd_solver.cpp:106] Iteration 69375, lr = 0.0025
I0522 20:41:53.176167 22569 solver.cpp:237] Iteration 69750, loss = 0.908291
I0522 20:41:53.176201 22569 solver.cpp:253]     Train net output #0: loss = 0.908291 (* 1 = 0.908291 loss)
I0522 20:41:53.176218 22569 sgd_solver.cpp:106] Iteration 69750, lr = 0.0025
I0522 20:42:23.718299 22569 solver.cpp:237] Iteration 70125, loss = 1.1493
I0522 20:42:23.718479 22569 solver.cpp:253]     Train net output #0: loss = 1.1493 (* 1 = 1.1493 loss)
I0522 20:42:23.718493 22569 sgd_solver.cpp:106] Iteration 70125, lr = 0.0025
I0522 20:42:33.426472 22569 solver.cpp:237] Iteration 70500, loss = 1.29848
I0522 20:42:33.426519 22569 solver.cpp:253]     Train net output #0: loss = 1.29848 (* 1 = 1.29848 loss)
I0522 20:42:33.426533 22569 sgd_solver.cpp:106] Iteration 70500, lr = 0.0025
I0522 20:42:43.125464 22569 solver.cpp:237] Iteration 70875, loss = 1.42134
I0522 20:42:43.125499 22569 solver.cpp:253]     Train net output #0: loss = 1.42134 (* 1 = 1.42134 loss)
I0522 20:42:43.125515 22569 sgd_solver.cpp:106] Iteration 70875, lr = 0.0025
I0522 20:42:52.808894 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_71250.caffemodel
I0522 20:42:52.867636 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_71250.solverstate
I0522 20:42:52.903987 22569 solver.cpp:237] Iteration 71250, loss = 1.34295
I0522 20:42:52.904036 22569 solver.cpp:253]     Train net output #0: loss = 1.34295 (* 1 = 1.34295 loss)
I0522 20:42:52.904052 22569 sgd_solver.cpp:106] Iteration 71250, lr = 0.0025
I0522 20:43:02.611121 22569 solver.cpp:237] Iteration 71625, loss = 1.17852
I0522 20:43:02.611292 22569 solver.cpp:253]     Train net output #0: loss = 1.17852 (* 1 = 1.17852 loss)
I0522 20:43:02.611306 22569 sgd_solver.cpp:106] Iteration 71625, lr = 0.0025
I0522 20:43:12.314301 22569 solver.cpp:237] Iteration 72000, loss = 1.53898
I0522 20:43:12.314335 22569 solver.cpp:253]     Train net output #0: loss = 1.53898 (* 1 = 1.53898 loss)
I0522 20:43:12.314350 22569 sgd_solver.cpp:106] Iteration 72000, lr = 0.0025
I0522 20:43:22.021914 22569 solver.cpp:237] Iteration 72375, loss = 1.29636
I0522 20:43:22.021962 22569 solver.cpp:253]     Train net output #0: loss = 1.29636 (* 1 = 1.29636 loss)
I0522 20:43:22.021976 22569 sgd_solver.cpp:106] Iteration 72375, lr = 0.0025
I0522 20:43:52.578657 22569 solver.cpp:237] Iteration 72750, loss = 1.1883
I0522 20:43:52.578835 22569 solver.cpp:253]     Train net output #0: loss = 1.1883 (* 1 = 1.1883 loss)
I0522 20:43:52.578850 22569 sgd_solver.cpp:106] Iteration 72750, lr = 0.0025
I0522 20:44:02.288028 22569 solver.cpp:237] Iteration 73125, loss = 1.201
I0522 20:44:02.288064 22569 solver.cpp:253]     Train net output #0: loss = 1.201 (* 1 = 1.201 loss)
I0522 20:44:02.288079 22569 sgd_solver.cpp:106] Iteration 73125, lr = 0.0025
I0522 20:44:12.000334 22569 solver.cpp:237] Iteration 73500, loss = 0.995215
I0522 20:44:12.000381 22569 solver.cpp:253]     Train net output #0: loss = 0.995215 (* 1 = 0.995215 loss)
I0522 20:44:12.000396 22569 sgd_solver.cpp:106] Iteration 73500, lr = 0.0025
I0522 20:44:21.706013 22569 solver.cpp:237] Iteration 73875, loss = 1.21535
I0522 20:44:21.706048 22569 solver.cpp:253]     Train net output #0: loss = 1.21535 (* 1 = 1.21535 loss)
I0522 20:44:21.706064 22569 sgd_solver.cpp:106] Iteration 73875, lr = 0.0025
I0522 20:44:31.405768 22569 solver.cpp:237] Iteration 74250, loss = 1.1419
I0522 20:44:31.405935 22569 solver.cpp:253]     Train net output #0: loss = 1.1419 (* 1 = 1.1419 loss)
I0522 20:44:31.405947 22569 sgd_solver.cpp:106] Iteration 74250, lr = 0.0025
I0522 20:44:41.115300 22569 solver.cpp:237] Iteration 74625, loss = 1.34818
I0522 20:44:41.115348 22569 solver.cpp:253]     Train net output #0: loss = 1.34818 (* 1 = 1.34818 loss)
I0522 20:44:41.115362 22569 sgd_solver.cpp:106] Iteration 74625, lr = 0.0025
I0522 20:44:50.791909 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_75000.caffemodel
I0522 20:44:50.850121 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_75000.solverstate
I0522 20:44:50.878031 22569 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 20:46:00.206136 22569 solver.cpp:409]     Test net output #0: accuracy = 0.88788
I0522 20:46:00.206313 22569 solver.cpp:409]     Test net output #1: loss = 0.357724 (* 1 = 0.357724 loss)
I0522 20:46:21.075673 22569 solver.cpp:237] Iteration 75000, loss = 1.31384
I0522 20:46:21.075724 22569 solver.cpp:253]     Train net output #0: loss = 1.31384 (* 1 = 1.31384 loss)
I0522 20:46:21.075739 22569 sgd_solver.cpp:106] Iteration 75000, lr = 0.0025
I0522 20:46:30.939556 22569 solver.cpp:237] Iteration 75375, loss = 0.979349
I0522 20:46:30.939721 22569 solver.cpp:253]     Train net output #0: loss = 0.979349 (* 1 = 0.979349 loss)
I0522 20:46:30.939735 22569 sgd_solver.cpp:106] Iteration 75375, lr = 0.0025
I0522 20:46:40.801676 22569 solver.cpp:237] Iteration 75750, loss = 0.988135
I0522 20:46:40.801724 22569 solver.cpp:253]     Train net output #0: loss = 0.988135 (* 1 = 0.988135 loss)
I0522 20:46:40.801739 22569 sgd_solver.cpp:106] Iteration 75750, lr = 0.0025
I0522 20:46:50.673264 22569 solver.cpp:237] Iteration 76125, loss = 1.2339
I0522 20:46:50.673300 22569 solver.cpp:253]     Train net output #0: loss = 1.2339 (* 1 = 1.2339 loss)
I0522 20:46:50.673316 22569 sgd_solver.cpp:106] Iteration 76125, lr = 0.0025
I0522 20:47:00.536064 22569 solver.cpp:237] Iteration 76500, loss = 0.989348
I0522 20:47:00.536101 22569 solver.cpp:253]     Train net output #0: loss = 0.989348 (* 1 = 0.989348 loss)
I0522 20:47:00.536114 22569 sgd_solver.cpp:106] Iteration 76500, lr = 0.0025
I0522 20:47:10.358978 22569 solver.cpp:237] Iteration 76875, loss = 0.99545
I0522 20:47:10.359153 22569 solver.cpp:253]     Train net output #0: loss = 0.99545 (* 1 = 0.99545 loss)
I0522 20:47:10.359168 22569 sgd_solver.cpp:106] Iteration 76875, lr = 0.0025
I0522 20:47:20.164566 22569 solver.cpp:237] Iteration 77250, loss = 1.39429
I0522 20:47:20.164600 22569 solver.cpp:253]     Train net output #0: loss = 1.39429 (* 1 = 1.39429 loss)
I0522 20:47:20.164616 22569 sgd_solver.cpp:106] Iteration 77250, lr = 0.0025
I0522 20:47:50.807173 22569 solver.cpp:237] Iteration 77625, loss = 1.20783
I0522 20:47:50.807353 22569 solver.cpp:253]     Train net output #0: loss = 1.20783 (* 1 = 1.20783 loss)
I0522 20:47:50.807368 22569 sgd_solver.cpp:106] Iteration 77625, lr = 0.0025
I0522 20:48:00.612494 22569 solver.cpp:237] Iteration 78000, loss = 0.925092
I0522 20:48:00.612537 22569 solver.cpp:253]     Train net output #0: loss = 0.925092 (* 1 = 0.925092 loss)
I0522 20:48:00.612553 22569 sgd_solver.cpp:106] Iteration 78000, lr = 0.0025
I0522 20:48:10.416698 22569 solver.cpp:237] Iteration 78375, loss = 1.56045
I0522 20:48:10.416733 22569 solver.cpp:253]     Train net output #0: loss = 1.56045 (* 1 = 1.56045 loss)
I0522 20:48:10.416748 22569 sgd_solver.cpp:106] Iteration 78375, lr = 0.0025
I0522 20:48:20.200227 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_78750.caffemodel
I0522 20:48:20.255977 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_78750.solverstate
I0522 20:48:20.290627 22569 solver.cpp:237] Iteration 78750, loss = 1.10421
I0522 20:48:20.290666 22569 solver.cpp:253]     Train net output #0: loss = 1.10421 (* 1 = 1.10421 loss)
I0522 20:48:20.290680 22569 sgd_solver.cpp:106] Iteration 78750, lr = 0.0025
I0522 20:48:30.100739 22569 solver.cpp:237] Iteration 79125, loss = 1.2662
I0522 20:48:30.100916 22569 solver.cpp:253]     Train net output #0: loss = 1.2662 (* 1 = 1.2662 loss)
I0522 20:48:30.100930 22569 sgd_solver.cpp:106] Iteration 79125, lr = 0.0025
I0522 20:48:39.906973 22569 solver.cpp:237] Iteration 79500, loss = 1.01161
I0522 20:48:39.907008 22569 solver.cpp:253]     Train net output #0: loss = 1.01161 (* 1 = 1.01161 loss)
I0522 20:48:39.907022 22569 sgd_solver.cpp:106] Iteration 79500, lr = 0.0025
I0522 20:48:49.717314 22569 solver.cpp:237] Iteration 79875, loss = 1.00753
I0522 20:48:49.717355 22569 solver.cpp:253]     Train net output #0: loss = 1.00753 (* 1 = 1.00753 loss)
I0522 20:48:49.717372 22569 sgd_solver.cpp:106] Iteration 79875, lr = 0.0025
I0522 20:49:20.370151 22569 solver.cpp:237] Iteration 80250, loss = 1.31557
I0522 20:49:20.370332 22569 solver.cpp:253]     Train net output #0: loss = 1.31557 (* 1 = 1.31557 loss)
I0522 20:49:20.370347 22569 sgd_solver.cpp:106] Iteration 80250, lr = 0.0025
I0522 20:49:30.178913 22569 solver.cpp:237] Iteration 80625, loss = 1.19334
I0522 20:49:30.178948 22569 solver.cpp:253]     Train net output #0: loss = 1.19334 (* 1 = 1.19334 loss)
I0522 20:49:30.178963 22569 sgd_solver.cpp:106] Iteration 80625, lr = 0.0025
I0522 20:49:39.985270 22569 solver.cpp:237] Iteration 81000, loss = 1.30867
I0522 20:49:39.985306 22569 solver.cpp:253]     Train net output #0: loss = 1.30867 (* 1 = 1.30867 loss)
I0522 20:49:39.985327 22569 sgd_solver.cpp:106] Iteration 81000, lr = 0.0025
I0522 20:49:49.795047 22569 solver.cpp:237] Iteration 81375, loss = 1.20287
I0522 20:49:49.795081 22569 solver.cpp:253]     Train net output #0: loss = 1.20287 (* 1 = 1.20287 loss)
I0522 20:49:49.795095 22569 sgd_solver.cpp:106] Iteration 81375, lr = 0.0025
I0522 20:49:59.606575 22569 solver.cpp:237] Iteration 81750, loss = 1.26865
I0522 20:49:59.606741 22569 solver.cpp:253]     Train net output #0: loss = 1.26865 (* 1 = 1.26865 loss)
I0522 20:49:59.606755 22569 sgd_solver.cpp:106] Iteration 81750, lr = 0.0025
I0522 20:50:09.417615 22569 solver.cpp:237] Iteration 82125, loss = 1.05225
I0522 20:50:09.417650 22569 solver.cpp:253]     Train net output #0: loss = 1.05225 (* 1 = 1.05225 loss)
I0522 20:50:09.417665 22569 sgd_solver.cpp:106] Iteration 82125, lr = 0.0025
I0522 20:50:19.195410 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_82500.caffemodel
I0522 20:50:19.251521 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_82500.solverstate
I0522 20:50:19.277992 22569 solver.cpp:341] Iteration 82500, Testing net (#0)
I0522 20:51:07.453889 22569 solver.cpp:409]     Test net output #0: accuracy = 0.888479
I0522 20:51:07.454069 22569 solver.cpp:409]     Test net output #1: loss = 0.364759 (* 1 = 0.364759 loss)
I0522 20:51:28.314447 22569 solver.cpp:237] Iteration 82500, loss = 1.21361
I0522 20:51:28.314501 22569 solver.cpp:253]     Train net output #0: loss = 1.21361 (* 1 = 1.21361 loss)
I0522 20:51:28.314517 22569 sgd_solver.cpp:106] Iteration 82500, lr = 0.0025
I0522 20:51:37.993391 22569 solver.cpp:237] Iteration 82875, loss = 1.47662
I0522 20:51:37.993559 22569 solver.cpp:253]     Train net output #0: loss = 1.47662 (* 1 = 1.47662 loss)
I0522 20:51:37.993573 22569 sgd_solver.cpp:106] Iteration 82875, lr = 0.0025
I0522 20:51:47.678102 22569 solver.cpp:237] Iteration 83250, loss = 1.17923
I0522 20:51:47.678146 22569 solver.cpp:253]     Train net output #0: loss = 1.17923 (* 1 = 1.17923 loss)
I0522 20:51:47.678160 22569 sgd_solver.cpp:106] Iteration 83250, lr = 0.0025
I0522 20:51:57.361845 22569 solver.cpp:237] Iteration 83625, loss = 1.1628
I0522 20:51:57.361881 22569 solver.cpp:253]     Train net output #0: loss = 1.1628 (* 1 = 1.1628 loss)
I0522 20:51:57.361894 22569 sgd_solver.cpp:106] Iteration 83625, lr = 0.0025
I0522 20:52:07.051223 22569 solver.cpp:237] Iteration 84000, loss = 1.18851
I0522 20:52:07.051266 22569 solver.cpp:253]     Train net output #0: loss = 1.18851 (* 1 = 1.18851 loss)
I0522 20:52:07.051282 22569 sgd_solver.cpp:106] Iteration 84000, lr = 0.0025
I0522 20:52:16.740631 22569 solver.cpp:237] Iteration 84375, loss = 1.34862
I0522 20:52:16.740792 22569 solver.cpp:253]     Train net output #0: loss = 1.34862 (* 1 = 1.34862 loss)
I0522 20:52:16.740805 22569 sgd_solver.cpp:106] Iteration 84375, lr = 0.0025
I0522 20:52:26.424319 22569 solver.cpp:237] Iteration 84750, loss = 1.0604
I0522 20:52:26.424352 22569 solver.cpp:253]     Train net output #0: loss = 1.0604 (* 1 = 1.0604 loss)
I0522 20:52:26.424367 22569 sgd_solver.cpp:106] Iteration 84750, lr = 0.0025
I0522 20:52:56.968291 22569 solver.cpp:237] Iteration 85125, loss = 1.15189
I0522 20:52:56.968473 22569 solver.cpp:253]     Train net output #0: loss = 1.15189 (* 1 = 1.15189 loss)
I0522 20:52:56.968487 22569 sgd_solver.cpp:106] Iteration 85125, lr = 0.0025
I0522 20:53:06.644512 22569 solver.cpp:237] Iteration 85500, loss = 0.983491
I0522 20:53:06.644547 22569 solver.cpp:253]     Train net output #0: loss = 0.983491 (* 1 = 0.983491 loss)
I0522 20:53:06.644563 22569 sgd_solver.cpp:106] Iteration 85500, lr = 0.0025
I0522 20:53:16.336086 22569 solver.cpp:237] Iteration 85875, loss = 1.37871
I0522 20:53:16.336119 22569 solver.cpp:253]     Train net output #0: loss = 1.37871 (* 1 = 1.37871 loss)
I0522 20:53:16.336135 22569 sgd_solver.cpp:106] Iteration 85875, lr = 0.0025
I0522 20:53:25.995355 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_86250.caffemodel
I0522 20:53:26.050920 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_86250.solverstate
I0522 20:53:26.085237 22569 solver.cpp:237] Iteration 86250, loss = 1.03497
I0522 20:53:26.085281 22569 solver.cpp:253]     Train net output #0: loss = 1.03497 (* 1 = 1.03497 loss)
I0522 20:53:26.085299 22569 sgd_solver.cpp:106] Iteration 86250, lr = 0.0025
I0522 20:53:35.770050 22569 solver.cpp:237] Iteration 86625, loss = 1.03053
I0522 20:53:35.770213 22569 solver.cpp:253]     Train net output #0: loss = 1.03053 (* 1 = 1.03053 loss)
I0522 20:53:35.770226 22569 sgd_solver.cpp:106] Iteration 86625, lr = 0.0025
I0522 20:53:45.451810 22569 solver.cpp:237] Iteration 87000, loss = 1.25547
I0522 20:53:45.451855 22569 solver.cpp:253]     Train net output #0: loss = 1.25547 (* 1 = 1.25547 loss)
I0522 20:53:45.451871 22569 sgd_solver.cpp:106] Iteration 87000, lr = 0.0025
I0522 20:53:55.133702 22569 solver.cpp:237] Iteration 87375, loss = 1.19074
I0522 20:53:55.133738 22569 solver.cpp:253]     Train net output #0: loss = 1.19074 (* 1 = 1.19074 loss)
I0522 20:53:55.133751 22569 sgd_solver.cpp:106] Iteration 87375, lr = 0.0025
I0522 20:54:25.673621 22569 solver.cpp:237] Iteration 87750, loss = 1.20097
I0522 20:54:25.673804 22569 solver.cpp:253]     Train net output #0: loss = 1.20097 (* 1 = 1.20097 loss)
I0522 20:54:25.673821 22569 sgd_solver.cpp:106] Iteration 87750, lr = 0.0025
I0522 20:54:35.357698 22569 solver.cpp:237] Iteration 88125, loss = 1.26147
I0522 20:54:35.357745 22569 solver.cpp:253]     Train net output #0: loss = 1.26147 (* 1 = 1.26147 loss)
I0522 20:54:35.357759 22569 sgd_solver.cpp:106] Iteration 88125, lr = 0.0025
I0522 20:54:45.042943 22569 solver.cpp:237] Iteration 88500, loss = 1.21084
I0522 20:54:45.042979 22569 solver.cpp:253]     Train net output #0: loss = 1.21084 (* 1 = 1.21084 loss)
I0522 20:54:45.042992 22569 sgd_solver.cpp:106] Iteration 88500, lr = 0.0025
I0522 20:54:54.731458 22569 solver.cpp:237] Iteration 88875, loss = 0.985532
I0522 20:54:54.731495 22569 solver.cpp:253]     Train net output #0: loss = 0.985532 (* 1 = 0.985532 loss)
I0522 20:54:54.731509 22569 sgd_solver.cpp:106] Iteration 88875, lr = 0.0025
I0522 20:55:04.412564 22569 solver.cpp:237] Iteration 89250, loss = 1.33814
I0522 20:55:04.412749 22569 solver.cpp:253]     Train net output #0: loss = 1.33814 (* 1 = 1.33814 loss)
I0522 20:55:04.412763 22569 sgd_solver.cpp:106] Iteration 89250, lr = 0.0025
I0522 20:55:14.096767 22569 solver.cpp:237] Iteration 89625, loss = 0.714862
I0522 20:55:14.096803 22569 solver.cpp:253]     Train net output #0: loss = 0.714862 (* 1 = 0.714862 loss)
I0522 20:55:14.096818 22569 sgd_solver.cpp:106] Iteration 89625, lr = 0.0025
I0522 20:55:23.746745 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_90000.caffemodel
I0522 20:55:23.803403 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_90000.solverstate
I0522 20:55:23.830183 22569 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 20:56:33.222728 22569 solver.cpp:409]     Test net output #0: accuracy = 0.888327
I0522 20:56:33.222908 22569 solver.cpp:409]     Test net output #1: loss = 0.37131 (* 1 = 0.37131 loss)
I0522 20:56:54.082029 22569 solver.cpp:237] Iteration 90000, loss = 0.900465
I0522 20:56:54.082084 22569 solver.cpp:253]     Train net output #0: loss = 0.900465 (* 1 = 0.900465 loss)
I0522 20:56:54.082099 22569 sgd_solver.cpp:106] Iteration 90000, lr = 0.0025
I0522 20:57:03.958557 22569 solver.cpp:237] Iteration 90375, loss = 1.04225
I0522 20:57:03.958721 22569 solver.cpp:253]     Train net output #0: loss = 1.04225 (* 1 = 1.04225 loss)
I0522 20:57:03.958735 22569 sgd_solver.cpp:106] Iteration 90375, lr = 0.0025
I0522 20:57:13.840466 22569 solver.cpp:237] Iteration 90750, loss = 1.4435
I0522 20:57:13.840502 22569 solver.cpp:253]     Train net output #0: loss = 1.4435 (* 1 = 1.4435 loss)
I0522 20:57:13.840517 22569 sgd_solver.cpp:106] Iteration 90750, lr = 0.0025
I0522 20:57:23.728047 22569 solver.cpp:237] Iteration 91125, loss = 1.26251
I0522 20:57:23.728083 22569 solver.cpp:253]     Train net output #0: loss = 1.26251 (* 1 = 1.26251 loss)
I0522 20:57:23.728097 22569 sgd_solver.cpp:106] Iteration 91125, lr = 0.0025
I0522 20:57:33.610359 22569 solver.cpp:237] Iteration 91500, loss = 1.12564
I0522 20:57:33.610397 22569 solver.cpp:253]     Train net output #0: loss = 1.12564 (* 1 = 1.12564 loss)
I0522 20:57:33.610414 22569 sgd_solver.cpp:106] Iteration 91500, lr = 0.0025
I0522 20:57:43.485255 22569 solver.cpp:237] Iteration 91875, loss = 1.2026
I0522 20:57:43.485420 22569 solver.cpp:253]     Train net output #0: loss = 1.2026 (* 1 = 1.2026 loss)
I0522 20:57:43.485435 22569 sgd_solver.cpp:106] Iteration 91875, lr = 0.0025
I0522 20:57:53.361202 22569 solver.cpp:237] Iteration 92250, loss = 1.06485
I0522 20:57:53.361237 22569 solver.cpp:253]     Train net output #0: loss = 1.06485 (* 1 = 1.06485 loss)
I0522 20:57:53.361250 22569 sgd_solver.cpp:106] Iteration 92250, lr = 0.0025
I0522 20:58:24.064167 22569 solver.cpp:237] Iteration 92625, loss = 1.24838
I0522 20:58:24.064347 22569 solver.cpp:253]     Train net output #0: loss = 1.24838 (* 1 = 1.24838 loss)
I0522 20:58:24.064360 22569 sgd_solver.cpp:106] Iteration 92625, lr = 0.0025
I0522 20:58:33.948104 22569 solver.cpp:237] Iteration 93000, loss = 1.0823
I0522 20:58:33.948137 22569 solver.cpp:253]     Train net output #0: loss = 1.0823 (* 1 = 1.0823 loss)
I0522 20:58:33.948154 22569 sgd_solver.cpp:106] Iteration 93000, lr = 0.0025
I0522 20:58:43.825647 22569 solver.cpp:237] Iteration 93375, loss = 1.21713
I0522 20:58:43.825693 22569 solver.cpp:253]     Train net output #0: loss = 1.21713 (* 1 = 1.21713 loss)
I0522 20:58:43.825708 22569 sgd_solver.cpp:106] Iteration 93375, lr = 0.0025
I0522 20:58:53.679960 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_93750.caffemodel
I0522 20:58:53.737977 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_93750.solverstate
I0522 20:58:53.773977 22569 solver.cpp:237] Iteration 93750, loss = 1.22679
I0522 20:58:53.774025 22569 solver.cpp:253]     Train net output #0: loss = 1.22679 (* 1 = 1.22679 loss)
I0522 20:58:53.774041 22569 sgd_solver.cpp:106] Iteration 93750, lr = 0.0025
I0522 20:59:03.652853 22569 solver.cpp:237] Iteration 94125, loss = 1.09158
I0522 20:59:03.653031 22569 solver.cpp:253]     Train net output #0: loss = 1.09158 (* 1 = 1.09158 loss)
I0522 20:59:03.653044 22569 sgd_solver.cpp:106] Iteration 94125, lr = 0.0025
I0522 20:59:13.539517 22569 solver.cpp:237] Iteration 94500, loss = 1.05096
I0522 20:59:13.539564 22569 solver.cpp:253]     Train net output #0: loss = 1.05096 (* 1 = 1.05096 loss)
I0522 20:59:13.539580 22569 sgd_solver.cpp:106] Iteration 94500, lr = 0.0025
I0522 20:59:23.416462 22569 solver.cpp:237] Iteration 94875, loss = 1.23428
I0522 20:59:23.416497 22569 solver.cpp:253]     Train net output #0: loss = 1.23428 (* 1 = 1.23428 loss)
I0522 20:59:23.416512 22569 sgd_solver.cpp:106] Iteration 94875, lr = 0.0025
I0522 20:59:54.158368 22569 solver.cpp:237] Iteration 95250, loss = 1.2779
I0522 20:59:54.158556 22569 solver.cpp:253]     Train net output #0: loss = 1.2779 (* 1 = 1.2779 loss)
I0522 20:59:54.158571 22569 sgd_solver.cpp:106] Iteration 95250, lr = 0.0025
I0522 21:00:04.035411 22569 solver.cpp:237] Iteration 95625, loss = 1.17511
I0522 21:00:04.035457 22569 solver.cpp:253]     Train net output #0: loss = 1.17511 (* 1 = 1.17511 loss)
I0522 21:00:04.035472 22569 sgd_solver.cpp:106] Iteration 95625, lr = 0.0025
I0522 21:00:13.917206 22569 solver.cpp:237] Iteration 96000, loss = 1.27693
I0522 21:00:13.917242 22569 solver.cpp:253]     Train net output #0: loss = 1.27693 (* 1 = 1.27693 loss)
I0522 21:00:13.917254 22569 sgd_solver.cpp:106] Iteration 96000, lr = 0.0025
I0522 21:00:23.797380 22569 solver.cpp:237] Iteration 96375, loss = 0.996468
I0522 21:00:23.797425 22569 solver.cpp:253]     Train net output #0: loss = 0.996468 (* 1 = 0.996468 loss)
I0522 21:00:23.797441 22569 sgd_solver.cpp:106] Iteration 96375, lr = 0.0025
I0522 21:00:33.675463 22569 solver.cpp:237] Iteration 96750, loss = 1.13059
I0522 21:00:33.675624 22569 solver.cpp:253]     Train net output #0: loss = 1.13059 (* 1 = 1.13059 loss)
I0522 21:00:33.675637 22569 sgd_solver.cpp:106] Iteration 96750, lr = 0.0025
I0522 21:00:43.554158 22569 solver.cpp:237] Iteration 97125, loss = 1.21639
I0522 21:00:43.554193 22569 solver.cpp:253]     Train net output #0: loss = 1.21639 (* 1 = 1.21639 loss)
I0522 21:00:43.554208 22569 sgd_solver.cpp:106] Iteration 97125, lr = 0.0025
I0522 21:00:53.406265 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_97500.caffemodel
I0522 21:00:53.462651 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_97500.solverstate
I0522 21:00:53.489187 22569 solver.cpp:341] Iteration 97500, Testing net (#0)
I0522 21:01:42.029836 22569 solver.cpp:409]     Test net output #0: accuracy = 0.892213
I0522 21:01:42.030024 22569 solver.cpp:409]     Test net output #1: loss = 0.343187 (* 1 = 0.343187 loss)
I0522 21:02:02.901442 22569 solver.cpp:237] Iteration 97500, loss = 0.830117
I0522 21:02:02.901496 22569 solver.cpp:253]     Train net output #0: loss = 0.830117 (* 1 = 0.830117 loss)
I0522 21:02:02.901511 22569 sgd_solver.cpp:106] Iteration 97500, lr = 0.0025
I0522 21:02:12.720885 22569 solver.cpp:237] Iteration 97875, loss = 1.00892
I0522 21:02:12.721057 22569 solver.cpp:253]     Train net output #0: loss = 1.00892 (* 1 = 1.00892 loss)
I0522 21:02:12.721071 22569 sgd_solver.cpp:106] Iteration 97875, lr = 0.0025
I0522 21:02:22.542251 22569 solver.cpp:237] Iteration 98250, loss = 1.20242
I0522 21:02:22.542286 22569 solver.cpp:253]     Train net output #0: loss = 1.20242 (* 1 = 1.20242 loss)
I0522 21:02:22.542302 22569 sgd_solver.cpp:106] Iteration 98250, lr = 0.0025
I0522 21:02:32.365754 22569 solver.cpp:237] Iteration 98625, loss = 1.07129
I0522 21:02:32.365793 22569 solver.cpp:253]     Train net output #0: loss = 1.07129 (* 1 = 1.07129 loss)
I0522 21:02:32.365806 22569 sgd_solver.cpp:106] Iteration 98625, lr = 0.0025
I0522 21:02:42.185719 22569 solver.cpp:237] Iteration 99000, loss = 1.2072
I0522 21:02:42.185755 22569 solver.cpp:253]     Train net output #0: loss = 1.2072 (* 1 = 1.2072 loss)
I0522 21:02:42.185770 22569 sgd_solver.cpp:106] Iteration 99000, lr = 0.0025
I0522 21:02:52.008045 22569 solver.cpp:237] Iteration 99375, loss = 1.1344
I0522 21:02:52.008224 22569 solver.cpp:253]     Train net output #0: loss = 1.1344 (* 1 = 1.1344 loss)
I0522 21:02:52.008236 22569 sgd_solver.cpp:106] Iteration 99375, lr = 0.0025
I0522 21:03:01.829768 22569 solver.cpp:237] Iteration 99750, loss = 1.19141
I0522 21:03:01.829810 22569 solver.cpp:253]     Train net output #0: loss = 1.19141 (* 1 = 1.19141 loss)
I0522 21:03:01.829826 22569 sgd_solver.cpp:106] Iteration 99750, lr = 0.0025
I0522 21:03:32.492847 22569 solver.cpp:237] Iteration 100125, loss = 1.11419
I0522 21:03:32.493038 22569 solver.cpp:253]     Train net output #0: loss = 1.11419 (* 1 = 1.11419 loss)
I0522 21:03:32.493055 22569 sgd_solver.cpp:106] Iteration 100125, lr = 0.0025
I0522 21:03:42.315672 22569 solver.cpp:237] Iteration 100500, loss = 0.934497
I0522 21:03:42.315708 22569 solver.cpp:253]     Train net output #0: loss = 0.934497 (* 1 = 0.934497 loss)
I0522 21:03:42.315723 22569 sgd_solver.cpp:106] Iteration 100500, lr = 0.0025
I0522 21:03:52.171938 22569 solver.cpp:237] Iteration 100875, loss = 1.04389
I0522 21:03:52.171986 22569 solver.cpp:253]     Train net output #0: loss = 1.04389 (* 1 = 1.04389 loss)
I0522 21:03:52.171999 22569 sgd_solver.cpp:106] Iteration 100875, lr = 0.0025
I0522 21:04:02.014382 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_101250.caffemodel
I0522 21:04:02.070312 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_101250.solverstate
I0522 21:04:02.104516 22569 solver.cpp:237] Iteration 101250, loss = 0.65846
I0522 21:04:02.104562 22569 solver.cpp:253]     Train net output #0: loss = 0.65846 (* 1 = 0.65846 loss)
I0522 21:04:02.104576 22569 sgd_solver.cpp:106] Iteration 101250, lr = 0.0025
I0522 21:04:11.968998 22569 solver.cpp:237] Iteration 101625, loss = 1.19121
I0522 21:04:11.969182 22569 solver.cpp:253]     Train net output #0: loss = 1.19121 (* 1 = 1.19121 loss)
I0522 21:04:11.969197 22569 sgd_solver.cpp:106] Iteration 101625, lr = 0.0025
I0522 21:04:21.834199 22569 solver.cpp:237] Iteration 102000, loss = 1.21634
I0522 21:04:21.834235 22569 solver.cpp:253]     Train net output #0: loss = 1.21634 (* 1 = 1.21634 loss)
I0522 21:04:21.834250 22569 sgd_solver.cpp:106] Iteration 102000, lr = 0.0025
I0522 21:04:31.698506 22569 solver.cpp:237] Iteration 102375, loss = 1.21429
I0522 21:04:31.698541 22569 solver.cpp:253]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0522 21:04:31.698557 22569 sgd_solver.cpp:106] Iteration 102375, lr = 0.0025
I0522 21:05:02.458235 22569 solver.cpp:237] Iteration 102750, loss = 1.08984
I0522 21:05:02.458425 22569 solver.cpp:253]     Train net output #0: loss = 1.08984 (* 1 = 1.08984 loss)
I0522 21:05:02.458441 22569 sgd_solver.cpp:106] Iteration 102750, lr = 0.0025
I0522 21:05:12.329042 22569 solver.cpp:237] Iteration 103125, loss = 1.41335
I0522 21:05:12.329073 22569 solver.cpp:253]     Train net output #0: loss = 1.41335 (* 1 = 1.41335 loss)
I0522 21:05:12.329087 22569 sgd_solver.cpp:106] Iteration 103125, lr = 0.0025
I0522 21:05:22.189913 22569 solver.cpp:237] Iteration 103500, loss = 1.15176
I0522 21:05:22.189949 22569 solver.cpp:253]     Train net output #0: loss = 1.15176 (* 1 = 1.15176 loss)
I0522 21:05:22.189965 22569 sgd_solver.cpp:106] Iteration 103500, lr = 0.0025
I0522 21:05:32.054666 22569 solver.cpp:237] Iteration 103875, loss = 1.65153
I0522 21:05:32.054707 22569 solver.cpp:253]     Train net output #0: loss = 1.65153 (* 1 = 1.65153 loss)
I0522 21:05:32.054728 22569 sgd_solver.cpp:106] Iteration 103875, lr = 0.0025
I0522 21:05:41.916441 22569 solver.cpp:237] Iteration 104250, loss = 1.20546
I0522 21:05:41.916609 22569 solver.cpp:253]     Train net output #0: loss = 1.20546 (* 1 = 1.20546 loss)
I0522 21:05:41.916621 22569 sgd_solver.cpp:106] Iteration 104250, lr = 0.0025
I0522 21:05:51.780467 22569 solver.cpp:237] Iteration 104625, loss = 0.934212
I0522 21:05:51.780514 22569 solver.cpp:253]     Train net output #0: loss = 0.934212 (* 1 = 0.934212 loss)
I0522 21:05:51.780529 22569 sgd_solver.cpp:106] Iteration 104625, lr = 0.0025
I0522 21:06:01.609868 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_105000.caffemodel
I0522 21:06:01.666116 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_105000.solverstate
I0522 21:06:01.691632 22569 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 21:07:11.108489 22569 solver.cpp:409]     Test net output #0: accuracy = 0.891479
I0522 21:07:11.108672 22569 solver.cpp:409]     Test net output #1: loss = 0.352627 (* 1 = 0.352627 loss)
I0522 21:07:32.004807 22569 solver.cpp:237] Iteration 105000, loss = 1.10177
I0522 21:07:32.004859 22569 solver.cpp:253]     Train net output #0: loss = 1.10177 (* 1 = 1.10177 loss)
I0522 21:07:32.004881 22569 sgd_solver.cpp:106] Iteration 105000, lr = 0.0025
I0522 21:07:41.797653 22569 solver.cpp:237] Iteration 105375, loss = 1.01893
I0522 21:07:41.797824 22569 solver.cpp:253]     Train net output #0: loss = 1.01893 (* 1 = 1.01893 loss)
I0522 21:07:41.797837 22569 sgd_solver.cpp:106] Iteration 105375, lr = 0.0025
I0522 21:07:51.583339 22569 solver.cpp:237] Iteration 105750, loss = 1.04742
I0522 21:07:51.583374 22569 solver.cpp:253]     Train net output #0: loss = 1.04742 (* 1 = 1.04742 loss)
I0522 21:07:51.583390 22569 sgd_solver.cpp:106] Iteration 105750, lr = 0.0025
I0522 21:08:01.376374 22569 solver.cpp:237] Iteration 106125, loss = 0.660256
I0522 21:08:01.376423 22569 solver.cpp:253]     Train net output #0: loss = 0.660256 (* 1 = 0.660256 loss)
I0522 21:08:01.376437 22569 sgd_solver.cpp:106] Iteration 106125, lr = 0.0025
I0522 21:08:11.161435 22569 solver.cpp:237] Iteration 106500, loss = 1.45405
I0522 21:08:11.161471 22569 solver.cpp:253]     Train net output #0: loss = 1.45405 (* 1 = 1.45405 loss)
I0522 21:08:11.161485 22569 sgd_solver.cpp:106] Iteration 106500, lr = 0.0025
I0522 21:08:20.951231 22569 solver.cpp:237] Iteration 106875, loss = 1.12938
I0522 21:08:20.951406 22569 solver.cpp:253]     Train net output #0: loss = 1.12938 (* 1 = 1.12938 loss)
I0522 21:08:20.951421 22569 sgd_solver.cpp:106] Iteration 106875, lr = 0.0025
I0522 21:08:30.744273 22569 solver.cpp:237] Iteration 107250, loss = 1.21126
I0522 21:08:30.744308 22569 solver.cpp:253]     Train net output #0: loss = 1.21126 (* 1 = 1.21126 loss)
I0522 21:08:30.744323 22569 sgd_solver.cpp:106] Iteration 107250, lr = 0.0025
I0522 21:09:01.423538 22569 solver.cpp:237] Iteration 107625, loss = 1.20956
I0522 21:09:01.423740 22569 solver.cpp:253]     Train net output #0: loss = 1.20956 (* 1 = 1.20956 loss)
I0522 21:09:01.423754 22569 sgd_solver.cpp:106] Iteration 107625, lr = 0.0025
I0522 21:09:11.215862 22569 solver.cpp:237] Iteration 108000, loss = 1.21491
I0522 21:09:11.215909 22569 solver.cpp:253]     Train net output #0: loss = 1.21491 (* 1 = 1.21491 loss)
I0522 21:09:11.215922 22569 sgd_solver.cpp:106] Iteration 108000, lr = 0.0025
I0522 21:09:21.012068 22569 solver.cpp:237] Iteration 108375, loss = 1.27815
I0522 21:09:21.012104 22569 solver.cpp:253]     Train net output #0: loss = 1.27815 (* 1 = 1.27815 loss)
I0522 21:09:21.012116 22569 sgd_solver.cpp:106] Iteration 108375, lr = 0.0025
I0522 21:09:30.778556 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_108750.caffemodel
I0522 21:09:30.835608 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_108750.solverstate
I0522 21:09:30.870620 22569 solver.cpp:237] Iteration 108750, loss = 1.06207
I0522 21:09:30.870663 22569 solver.cpp:253]     Train net output #0: loss = 1.06207 (* 1 = 1.06207 loss)
I0522 21:09:30.870677 22569 sgd_solver.cpp:106] Iteration 108750, lr = 0.0025
I0522 21:09:40.662176 22569 solver.cpp:237] Iteration 109125, loss = 1.15289
I0522 21:09:40.662369 22569 solver.cpp:253]     Train net output #0: loss = 1.15289 (* 1 = 1.15289 loss)
I0522 21:09:40.662384 22569 sgd_solver.cpp:106] Iteration 109125, lr = 0.0025
I0522 21:09:50.453145 22569 solver.cpp:237] Iteration 109500, loss = 1.24206
I0522 21:09:50.453181 22569 solver.cpp:253]     Train net output #0: loss = 1.24206 (* 1 = 1.24206 loss)
I0522 21:09:50.453193 22569 sgd_solver.cpp:106] Iteration 109500, lr = 0.0025
I0522 21:10:00.246037 22569 solver.cpp:237] Iteration 109875, loss = 1.17641
I0522 21:10:00.246088 22569 solver.cpp:253]     Train net output #0: loss = 1.17641 (* 1 = 1.17641 loss)
I0522 21:10:00.246104 22569 sgd_solver.cpp:106] Iteration 109875, lr = 0.0025
I0522 21:10:30.910092 22569 solver.cpp:237] Iteration 110250, loss = 1.11662
I0522 21:10:30.910280 22569 solver.cpp:253]     Train net output #0: loss = 1.11662 (* 1 = 1.11662 loss)
I0522 21:10:30.910295 22569 sgd_solver.cpp:106] Iteration 110250, lr = 0.0025
I0522 21:10:40.702040 22569 solver.cpp:237] Iteration 110625, loss = 1.39779
I0522 21:10:40.702075 22569 solver.cpp:253]     Train net output #0: loss = 1.39779 (* 1 = 1.39779 loss)
I0522 21:10:40.702091 22569 sgd_solver.cpp:106] Iteration 110625, lr = 0.0025
I0522 21:10:50.491185 22569 solver.cpp:237] Iteration 111000, loss = 1.09902
I0522 21:10:50.491230 22569 solver.cpp:253]     Train net output #0: loss = 1.09902 (* 1 = 1.09902 loss)
I0522 21:10:50.491246 22569 sgd_solver.cpp:106] Iteration 111000, lr = 0.0025
I0522 21:11:00.285648 22569 solver.cpp:237] Iteration 111375, loss = 1.16841
I0522 21:11:00.285684 22569 solver.cpp:253]     Train net output #0: loss = 1.16841 (* 1 = 1.16841 loss)
I0522 21:11:00.285699 22569 sgd_solver.cpp:106] Iteration 111375, lr = 0.0025
I0522 21:11:10.083511 22569 solver.cpp:237] Iteration 111750, loss = 1.38281
I0522 21:11:10.083676 22569 solver.cpp:253]     Train net output #0: loss = 1.38281 (* 1 = 1.38281 loss)
I0522 21:11:10.083690 22569 sgd_solver.cpp:106] Iteration 111750, lr = 0.0025
I0522 21:11:19.877020 22569 solver.cpp:237] Iteration 112125, loss = 1.52618
I0522 21:11:19.877068 22569 solver.cpp:253]     Train net output #0: loss = 1.52618 (* 1 = 1.52618 loss)
I0522 21:11:19.877084 22569 sgd_solver.cpp:106] Iteration 112125, lr = 0.0025
I0522 21:11:29.642938 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_112500.caffemodel
I0522 21:11:29.700048 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_112500.solverstate
I0522 21:11:29.728194 22569 solver.cpp:341] Iteration 112500, Testing net (#0)
I0522 21:12:17.900990 22569 solver.cpp:409]     Test net output #0: accuracy = 0.892139
I0522 21:12:17.901176 22569 solver.cpp:409]     Test net output #1: loss = 0.379481 (* 1 = 0.379481 loss)
I0522 21:12:38.747613 22569 solver.cpp:237] Iteration 112500, loss = 1.28927
I0522 21:12:38.747665 22569 solver.cpp:253]     Train net output #0: loss = 1.28927 (* 1 = 1.28927 loss)
I0522 21:12:38.747680 22569 sgd_solver.cpp:106] Iteration 112500, lr = 0.0025
I0522 21:12:48.534096 22569 solver.cpp:237] Iteration 112875, loss = 1.07914
I0522 21:12:48.534267 22569 solver.cpp:253]     Train net output #0: loss = 1.07914 (* 1 = 1.07914 loss)
I0522 21:12:48.534281 22569 sgd_solver.cpp:106] Iteration 112875, lr = 0.0025
I0522 21:12:58.325611 22569 solver.cpp:237] Iteration 113250, loss = 1.10616
I0522 21:12:58.325659 22569 solver.cpp:253]     Train net output #0: loss = 1.10616 (* 1 = 1.10616 loss)
I0522 21:12:58.325672 22569 sgd_solver.cpp:106] Iteration 113250, lr = 0.0025
I0522 21:13:08.121093 22569 solver.cpp:237] Iteration 113625, loss = 1.52132
I0522 21:13:08.121129 22569 solver.cpp:253]     Train net output #0: loss = 1.52132 (* 1 = 1.52132 loss)
I0522 21:13:08.121143 22569 sgd_solver.cpp:106] Iteration 113625, lr = 0.0025
I0522 21:13:17.909278 22569 solver.cpp:237] Iteration 114000, loss = 1.09908
I0522 21:13:17.909312 22569 solver.cpp:253]     Train net output #0: loss = 1.09908 (* 1 = 1.09908 loss)
I0522 21:13:17.909328 22569 sgd_solver.cpp:106] Iteration 114000, lr = 0.0025
I0522 21:13:27.696455 22569 solver.cpp:237] Iteration 114375, loss = 1.13217
I0522 21:13:27.696630 22569 solver.cpp:253]     Train net output #0: loss = 1.13217 (* 1 = 1.13217 loss)
I0522 21:13:27.696645 22569 sgd_solver.cpp:106] Iteration 114375, lr = 0.0025
I0522 21:13:37.484259 22569 solver.cpp:237] Iteration 114750, loss = 0.963306
I0522 21:13:37.484295 22569 solver.cpp:253]     Train net output #0: loss = 0.963305 (* 1 = 0.963305 loss)
I0522 21:13:37.484311 22569 sgd_solver.cpp:106] Iteration 114750, lr = 0.0025
I0522 21:14:08.092087 22569 solver.cpp:237] Iteration 115125, loss = 1.33365
I0522 21:14:08.092274 22569 solver.cpp:253]     Train net output #0: loss = 1.33365 (* 1 = 1.33365 loss)
I0522 21:14:08.092290 22569 sgd_solver.cpp:106] Iteration 115125, lr = 0.0025
I0522 21:14:17.882760 22569 solver.cpp:237] Iteration 115500, loss = 0.916412
I0522 21:14:17.882807 22569 solver.cpp:253]     Train net output #0: loss = 0.916411 (* 1 = 0.916411 loss)
I0522 21:14:17.882820 22569 sgd_solver.cpp:106] Iteration 115500, lr = 0.0025
I0522 21:14:27.672915 22569 solver.cpp:237] Iteration 115875, loss = 2.02222
I0522 21:14:27.672951 22569 solver.cpp:253]     Train net output #0: loss = 2.02222 (* 1 = 2.02222 loss)
I0522 21:14:27.672967 22569 sgd_solver.cpp:106] Iteration 115875, lr = 0.0025
I0522 21:14:37.440223 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_116250.caffemodel
I0522 21:14:37.495576 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_116250.solverstate
I0522 21:14:37.529209 22569 solver.cpp:237] Iteration 116250, loss = 1.09147
I0522 21:14:37.529249 22569 solver.cpp:253]     Train net output #0: loss = 1.09147 (* 1 = 1.09147 loss)
I0522 21:14:37.529263 22569 sgd_solver.cpp:106] Iteration 116250, lr = 0.0025
I0522 21:14:47.319869 22569 solver.cpp:237] Iteration 116625, loss = 1.45397
I0522 21:14:47.320050 22569 solver.cpp:253]     Train net output #0: loss = 1.45397 (* 1 = 1.45397 loss)
I0522 21:14:47.320063 22569 sgd_solver.cpp:106] Iteration 116625, lr = 0.0025
I0522 21:14:57.112279 22569 solver.cpp:237] Iteration 117000, loss = 1.27059
I0522 21:14:57.112314 22569 solver.cpp:253]     Train net output #0: loss = 1.27059 (* 1 = 1.27059 loss)
I0522 21:14:57.112330 22569 sgd_solver.cpp:106] Iteration 117000, lr = 0.0025
I0522 21:15:06.906345 22569 solver.cpp:237] Iteration 117375, loss = 1.01931
I0522 21:15:06.906383 22569 solver.cpp:253]     Train net output #0: loss = 1.01931 (* 1 = 1.01931 loss)
I0522 21:15:06.906402 22569 sgd_solver.cpp:106] Iteration 117375, lr = 0.0025
I0522 21:15:37.527700 22569 solver.cpp:237] Iteration 117750, loss = 1.00162
I0522 21:15:37.527894 22569 solver.cpp:253]     Train net output #0: loss = 1.00162 (* 1 = 1.00162 loss)
I0522 21:15:37.527909 22569 sgd_solver.cpp:106] Iteration 117750, lr = 0.0025
I0522 21:15:47.321458 22569 solver.cpp:237] Iteration 118125, loss = 1.01679
I0522 21:15:47.321493 22569 solver.cpp:253]     Train net output #0: loss = 1.01679 (* 1 = 1.01679 loss)
I0522 21:15:47.321508 22569 sgd_solver.cpp:106] Iteration 118125, lr = 0.0025
I0522 21:15:57.111727 22569 solver.cpp:237] Iteration 118500, loss = 1.369
I0522 21:15:57.111766 22569 solver.cpp:253]     Train net output #0: loss = 1.369 (* 1 = 1.369 loss)
I0522 21:15:57.111783 22569 sgd_solver.cpp:106] Iteration 118500, lr = 0.0025
I0522 21:16:06.906926 22569 solver.cpp:237] Iteration 118875, loss = 0.909867
I0522 21:16:06.906962 22569 solver.cpp:253]     Train net output #0: loss = 0.909867 (* 1 = 0.909867 loss)
I0522 21:16:06.906977 22569 sgd_solver.cpp:106] Iteration 118875, lr = 0.0025
I0522 21:16:16.693199 22569 solver.cpp:237] Iteration 119250, loss = 1.17827
I0522 21:16:16.693377 22569 solver.cpp:253]     Train net output #0: loss = 1.17827 (* 1 = 1.17827 loss)
I0522 21:16:16.693390 22569 sgd_solver.cpp:106] Iteration 119250, lr = 0.0025
I0522 21:16:26.489826 22569 solver.cpp:237] Iteration 119625, loss = 1.01617
I0522 21:16:26.489861 22569 solver.cpp:253]     Train net output #0: loss = 1.01617 (* 1 = 1.01617 loss)
I0522 21:16:26.489876 22569 sgd_solver.cpp:106] Iteration 119625, lr = 0.0025
I0522 21:16:36.258389 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_120000.caffemodel
I0522 21:16:36.314081 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_120000.solverstate
I0522 21:16:36.339493 22569 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 21:17:45.705736 22569 solver.cpp:409]     Test net output #0: accuracy = 0.892834
I0522 21:17:45.705926 22569 solver.cpp:409]     Test net output #1: loss = 0.333397 (* 1 = 0.333397 loss)
I0522 21:18:06.534721 22569 solver.cpp:237] Iteration 120000, loss = 1.07155
I0522 21:18:06.534775 22569 solver.cpp:253]     Train net output #0: loss = 1.07155 (* 1 = 1.07155 loss)
I0522 21:18:06.534790 22569 sgd_solver.cpp:106] Iteration 120000, lr = 0.0025
I0522 21:18:16.438401 22569 solver.cpp:237] Iteration 120375, loss = 1.13491
I0522 21:18:16.438575 22569 solver.cpp:253]     Train net output #0: loss = 1.13491 (* 1 = 1.13491 loss)
I0522 21:18:16.438587 22569 sgd_solver.cpp:106] Iteration 120375, lr = 0.0025
I0522 21:18:26.320827 22569 solver.cpp:237] Iteration 120750, loss = 0.922875
I0522 21:18:26.320881 22569 solver.cpp:253]     Train net output #0: loss = 0.922875 (* 1 = 0.922875 loss)
I0522 21:18:26.320895 22569 sgd_solver.cpp:106] Iteration 120750, lr = 0.0025
I0522 21:18:36.212649 22569 solver.cpp:237] Iteration 121125, loss = 1.37627
I0522 21:18:36.212685 22569 solver.cpp:253]     Train net output #0: loss = 1.37627 (* 1 = 1.37627 loss)
I0522 21:18:36.212699 22569 sgd_solver.cpp:106] Iteration 121125, lr = 0.0025
I0522 21:18:46.101960 22569 solver.cpp:237] Iteration 121500, loss = 1.0598
I0522 21:18:46.102007 22569 solver.cpp:253]     Train net output #0: loss = 1.0598 (* 1 = 1.0598 loss)
I0522 21:18:46.102022 22569 sgd_solver.cpp:106] Iteration 121500, lr = 0.0025
I0522 21:18:55.991241 22569 solver.cpp:237] Iteration 121875, loss = 1.44285
I0522 21:18:55.991425 22569 solver.cpp:253]     Train net output #0: loss = 1.44285 (* 1 = 1.44285 loss)
I0522 21:18:55.991437 22569 sgd_solver.cpp:106] Iteration 121875, lr = 0.0025
I0522 21:19:05.872771 22569 solver.cpp:237] Iteration 122250, loss = 0.865706
I0522 21:19:05.872805 22569 solver.cpp:253]     Train net output #0: loss = 0.865706 (* 1 = 0.865706 loss)
I0522 21:19:05.872820 22569 sgd_solver.cpp:106] Iteration 122250, lr = 0.0025
I0522 21:19:36.582707 22569 solver.cpp:237] Iteration 122625, loss = 1.13235
I0522 21:19:36.582898 22569 solver.cpp:253]     Train net output #0: loss = 1.13235 (* 1 = 1.13235 loss)
I0522 21:19:36.582913 22569 sgd_solver.cpp:106] Iteration 122625, lr = 0.0025
I0522 21:19:46.467878 22569 solver.cpp:237] Iteration 123000, loss = 0.930814
I0522 21:19:46.467916 22569 solver.cpp:253]     Train net output #0: loss = 0.930814 (* 1 = 0.930814 loss)
I0522 21:19:46.467929 22569 sgd_solver.cpp:106] Iteration 123000, lr = 0.0025
I0522 21:19:56.351305 22569 solver.cpp:237] Iteration 123375, loss = 1.12449
I0522 21:19:56.351341 22569 solver.cpp:253]     Train net output #0: loss = 1.12449 (* 1 = 1.12449 loss)
I0522 21:19:56.351356 22569 sgd_solver.cpp:106] Iteration 123375, lr = 0.0025
I0522 21:20:06.208914 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_123750.caffemodel
I0522 21:20:06.265180 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_123750.solverstate
I0522 21:20:06.298622 22569 solver.cpp:237] Iteration 123750, loss = 1.29782
I0522 21:20:06.298662 22569 solver.cpp:253]     Train net output #0: loss = 1.29782 (* 1 = 1.29782 loss)
I0522 21:20:06.298677 22569 sgd_solver.cpp:106] Iteration 123750, lr = 0.0025
I0522 21:20:16.189179 22569 solver.cpp:237] Iteration 124125, loss = 0.962352
I0522 21:20:16.189352 22569 solver.cpp:253]     Train net output #0: loss = 0.962352 (* 1 = 0.962352 loss)
I0522 21:20:16.189365 22569 sgd_solver.cpp:106] Iteration 124125, lr = 0.0025
I0522 21:20:26.069583 22569 solver.cpp:237] Iteration 124500, loss = 0.91261
I0522 21:20:26.069628 22569 solver.cpp:253]     Train net output #0: loss = 0.912609 (* 1 = 0.912609 loss)
I0522 21:20:26.069643 22569 sgd_solver.cpp:106] Iteration 124500, lr = 0.0025
I0522 21:20:35.961356 22569 solver.cpp:237] Iteration 124875, loss = 1.01262
I0522 21:20:35.961392 22569 solver.cpp:253]     Train net output #0: loss = 1.01262 (* 1 = 1.01262 loss)
I0522 21:20:35.961406 22569 sgd_solver.cpp:106] Iteration 124875, lr = 0.0025
I0522 21:21:06.693509 22569 solver.cpp:237] Iteration 125250, loss = 1.06673
I0522 21:21:06.693702 22569 solver.cpp:253]     Train net output #0: loss = 1.06673 (* 1 = 1.06673 loss)
I0522 21:21:06.693717 22569 sgd_solver.cpp:106] Iteration 125250, lr = 0.0025
I0522 21:21:16.579224 22569 solver.cpp:237] Iteration 125625, loss = 1.02892
I0522 21:21:16.579268 22569 solver.cpp:253]     Train net output #0: loss = 1.02892 (* 1 = 1.02892 loss)
I0522 21:21:16.579283 22569 sgd_solver.cpp:106] Iteration 125625, lr = 0.0025
I0522 21:21:26.462443 22569 solver.cpp:237] Iteration 126000, loss = 1.18306
I0522 21:21:26.462479 22569 solver.cpp:253]     Train net output #0: loss = 1.18306 (* 1 = 1.18306 loss)
I0522 21:21:26.462492 22569 sgd_solver.cpp:106] Iteration 126000, lr = 0.0025
I0522 21:21:36.353642 22569 solver.cpp:237] Iteration 126375, loss = 1.16242
I0522 21:21:36.353677 22569 solver.cpp:253]     Train net output #0: loss = 1.16242 (* 1 = 1.16242 loss)
I0522 21:21:36.353693 22569 sgd_solver.cpp:106] Iteration 126375, lr = 0.0025
I0522 21:21:46.243818 22569 solver.cpp:237] Iteration 126750, loss = 1.06347
I0522 21:21:46.244001 22569 solver.cpp:253]     Train net output #0: loss = 1.06347 (* 1 = 1.06347 loss)
I0522 21:21:46.244015 22569 sgd_solver.cpp:106] Iteration 126750, lr = 0.0025
I0522 21:21:56.133380 22569 solver.cpp:237] Iteration 127125, loss = 0.891821
I0522 21:21:56.133415 22569 solver.cpp:253]     Train net output #0: loss = 0.891821 (* 1 = 0.891821 loss)
I0522 21:21:56.133430 22569 sgd_solver.cpp:106] Iteration 127125, lr = 0.0025
I0522 21:22:05.995506 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_127500.caffemodel
I0522 21:22:06.052399 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_127500.solverstate
I0522 21:22:06.077698 22569 solver.cpp:341] Iteration 127500, Testing net (#0)
I0522 21:22:54.616600 22569 solver.cpp:409]     Test net output #0: accuracy = 0.893018
I0522 21:22:54.616793 22569 solver.cpp:409]     Test net output #1: loss = 0.359739 (* 1 = 0.359739 loss)
I0522 21:23:15.464951 22569 solver.cpp:237] Iteration 127500, loss = 1.28236
I0522 21:23:15.465003 22569 solver.cpp:253]     Train net output #0: loss = 1.28236 (* 1 = 1.28236 loss)
I0522 21:23:15.465024 22569 sgd_solver.cpp:106] Iteration 127500, lr = 0.0025
I0522 21:23:25.356884 22569 solver.cpp:237] Iteration 127875, loss = 1.25832
I0522 21:23:25.357060 22569 solver.cpp:253]     Train net output #0: loss = 1.25832 (* 1 = 1.25832 loss)
I0522 21:23:25.357075 22569 sgd_solver.cpp:106] Iteration 127875, lr = 0.0025
I0522 21:23:35.244415 22569 solver.cpp:237] Iteration 128250, loss = 1.25023
I0522 21:23:35.244449 22569 solver.cpp:253]     Train net output #0: loss = 1.25023 (* 1 = 1.25023 loss)
I0522 21:23:35.244467 22569 sgd_solver.cpp:106] Iteration 128250, lr = 0.0025
I0522 21:23:45.136842 22569 solver.cpp:237] Iteration 128625, loss = 1.03221
I0522 21:23:45.136896 22569 solver.cpp:253]     Train net output #0: loss = 1.03221 (* 1 = 1.03221 loss)
I0522 21:23:45.136912 22569 sgd_solver.cpp:106] Iteration 128625, lr = 0.0025
I0522 21:23:55.028532 22569 solver.cpp:237] Iteration 129000, loss = 1.04651
I0522 21:23:55.028566 22569 solver.cpp:253]     Train net output #0: loss = 1.04651 (* 1 = 1.04651 loss)
I0522 21:23:55.028583 22569 sgd_solver.cpp:106] Iteration 129000, lr = 0.0025
I0522 21:24:04.918339 22569 solver.cpp:237] Iteration 129375, loss = 1.15727
I0522 21:24:04.918511 22569 solver.cpp:253]     Train net output #0: loss = 1.15727 (* 1 = 1.15727 loss)
I0522 21:24:04.918525 22569 sgd_solver.cpp:106] Iteration 129375, lr = 0.0025
I0522 21:24:14.808439 22569 solver.cpp:237] Iteration 129750, loss = 1.00991
I0522 21:24:14.808483 22569 solver.cpp:253]     Train net output #0: loss = 1.00991 (* 1 = 1.00991 loss)
I0522 21:24:14.808501 22569 sgd_solver.cpp:106] Iteration 129750, lr = 0.0025
I0522 21:24:45.571632 22569 solver.cpp:237] Iteration 130125, loss = 1.21445
I0522 21:24:45.571825 22569 solver.cpp:253]     Train net output #0: loss = 1.21445 (* 1 = 1.21445 loss)
I0522 21:24:45.571841 22569 sgd_solver.cpp:106] Iteration 130125, lr = 0.0025
I0522 21:24:55.463526 22569 solver.cpp:237] Iteration 130500, loss = 1.15275
I0522 21:24:55.463560 22569 solver.cpp:253]     Train net output #0: loss = 1.15275 (* 1 = 1.15275 loss)
I0522 21:24:55.463577 22569 sgd_solver.cpp:106] Iteration 130500, lr = 0.0025
I0522 21:25:05.350795 22569 solver.cpp:237] Iteration 130875, loss = 1.0871
I0522 21:25:05.350841 22569 solver.cpp:253]     Train net output #0: loss = 1.0871 (* 1 = 1.0871 loss)
I0522 21:25:05.350857 22569 sgd_solver.cpp:106] Iteration 130875, lr = 0.0025
I0522 21:25:15.212643 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_131250.caffemodel
I0522 21:25:15.270452 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_131250.solverstate
I0522 21:25:15.306975 22569 solver.cpp:237] Iteration 131250, loss = 1.24489
I0522 21:25:15.307025 22569 solver.cpp:253]     Train net output #0: loss = 1.24489 (* 1 = 1.24489 loss)
I0522 21:25:15.307039 22569 sgd_solver.cpp:106] Iteration 131250, lr = 0.0025
I0522 21:25:25.203969 22569 solver.cpp:237] Iteration 131625, loss = 1.14597
I0522 21:25:25.204179 22569 solver.cpp:253]     Train net output #0: loss = 1.14597 (* 1 = 1.14597 loss)
I0522 21:25:25.204192 22569 sgd_solver.cpp:106] Iteration 131625, lr = 0.0025
I0522 21:25:35.095325 22569 solver.cpp:237] Iteration 132000, loss = 1.09783
I0522 21:25:35.095360 22569 solver.cpp:253]     Train net output #0: loss = 1.09783 (* 1 = 1.09783 loss)
I0522 21:25:35.095374 22569 sgd_solver.cpp:106] Iteration 132000, lr = 0.0025
I0522 21:25:44.989431 22569 solver.cpp:237] Iteration 132375, loss = 1.18191
I0522 21:25:44.989466 22569 solver.cpp:253]     Train net output #0: loss = 1.18191 (* 1 = 1.18191 loss)
I0522 21:25:44.989480 22569 sgd_solver.cpp:106] Iteration 132375, lr = 0.0025
I0522 21:26:15.764917 22569 solver.cpp:237] Iteration 132750, loss = 1.02405
I0522 21:26:15.765108 22569 solver.cpp:253]     Train net output #0: loss = 1.02405 (* 1 = 1.02405 loss)
I0522 21:26:15.765123 22569 sgd_solver.cpp:106] Iteration 132750, lr = 0.0025
I0522 21:26:25.650688 22569 solver.cpp:237] Iteration 133125, loss = 1.1803
I0522 21:26:25.650722 22569 solver.cpp:253]     Train net output #0: loss = 1.1803 (* 1 = 1.1803 loss)
I0522 21:26:25.650740 22569 sgd_solver.cpp:106] Iteration 133125, lr = 0.0025
I0522 21:26:35.546739 22569 solver.cpp:237] Iteration 133500, loss = 1.29585
I0522 21:26:35.546774 22569 solver.cpp:253]     Train net output #0: loss = 1.29585 (* 1 = 1.29585 loss)
I0522 21:26:35.546792 22569 sgd_solver.cpp:106] Iteration 133500, lr = 0.0025
I0522 21:26:45.438480 22569 solver.cpp:237] Iteration 133875, loss = 1.35428
I0522 21:26:45.438522 22569 solver.cpp:253]     Train net output #0: loss = 1.35428 (* 1 = 1.35428 loss)
I0522 21:26:45.438541 22569 sgd_solver.cpp:106] Iteration 133875, lr = 0.0025
I0522 21:26:55.333784 22569 solver.cpp:237] Iteration 134250, loss = 1.21206
I0522 21:26:55.333958 22569 solver.cpp:253]     Train net output #0: loss = 1.21206 (* 1 = 1.21206 loss)
I0522 21:26:55.333973 22569 sgd_solver.cpp:106] Iteration 134250, lr = 0.0025
I0522 21:27:05.218979 22569 solver.cpp:237] Iteration 134625, loss = 1.00831
I0522 21:27:05.219027 22569 solver.cpp:253]     Train net output #0: loss = 1.00831 (* 1 = 1.00831 loss)
I0522 21:27:05.219040 22569 sgd_solver.cpp:106] Iteration 134625, lr = 0.0025
I0522 21:27:15.090095 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_135000.caffemodel
I0522 21:27:15.147893 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_135000.solverstate
I0522 21:27:15.175137 22569 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 21:28:24.539685 22569 solver.cpp:409]     Test net output #0: accuracy = 0.89666
I0522 21:28:24.539875 22569 solver.cpp:409]     Test net output #1: loss = 0.323621 (* 1 = 0.323621 loss)
I0522 21:28:45.361783 22569 solver.cpp:237] Iteration 135000, loss = 0.891647
I0522 21:28:45.361837 22569 solver.cpp:253]     Train net output #0: loss = 0.891647 (* 1 = 0.891647 loss)
I0522 21:28:45.361852 22569 sgd_solver.cpp:106] Iteration 135000, lr = 0.0025
I0522 21:28:55.020369 22569 solver.cpp:237] Iteration 135375, loss = 1.22344
I0522 21:28:55.020546 22569 solver.cpp:253]     Train net output #0: loss = 1.22344 (* 1 = 1.22344 loss)
I0522 21:28:55.020560 22569 sgd_solver.cpp:106] Iteration 135375, lr = 0.0025
I0522 21:29:04.681354 22569 solver.cpp:237] Iteration 135750, loss = 1.45274
I0522 21:29:04.681390 22569 solver.cpp:253]     Train net output #0: loss = 1.45274 (* 1 = 1.45274 loss)
I0522 21:29:04.681403 22569 sgd_solver.cpp:106] Iteration 135750, lr = 0.0025
I0522 21:29:14.344197 22569 solver.cpp:237] Iteration 136125, loss = 1.23292
I0522 21:29:14.344243 22569 solver.cpp:253]     Train net output #0: loss = 1.23292 (* 1 = 1.23292 loss)
I0522 21:29:14.344259 22569 sgd_solver.cpp:106] Iteration 136125, lr = 0.0025
I0522 21:29:24.006036 22569 solver.cpp:237] Iteration 136500, loss = 1.13973
I0522 21:29:24.006072 22569 solver.cpp:253]     Train net output #0: loss = 1.13973 (* 1 = 1.13973 loss)
I0522 21:29:24.006088 22569 sgd_solver.cpp:106] Iteration 136500, lr = 0.0025
I0522 21:29:33.668512 22569 solver.cpp:237] Iteration 136875, loss = 1.32462
I0522 21:29:33.668709 22569 solver.cpp:253]     Train net output #0: loss = 1.32462 (* 1 = 1.32462 loss)
I0522 21:29:33.668723 22569 sgd_solver.cpp:106] Iteration 136875, lr = 0.0025
I0522 21:29:43.331149 22569 solver.cpp:237] Iteration 137250, loss = 0.799165
I0522 21:29:43.331187 22569 solver.cpp:253]     Train net output #0: loss = 0.799165 (* 1 = 0.799165 loss)
I0522 21:29:43.331200 22569 sgd_solver.cpp:106] Iteration 137250, lr = 0.0025
I0522 21:30:13.852010 22569 solver.cpp:237] Iteration 137625, loss = 1.4428
I0522 21:30:13.852207 22569 solver.cpp:253]     Train net output #0: loss = 1.4428 (* 1 = 1.4428 loss)
I0522 21:30:13.852221 22569 sgd_solver.cpp:106] Iteration 137625, lr = 0.0025
I0522 21:30:23.517341 22569 solver.cpp:237] Iteration 138000, loss = 0.995168
I0522 21:30:23.517395 22569 solver.cpp:253]     Train net output #0: loss = 0.995168 (* 1 = 0.995168 loss)
I0522 21:30:23.517410 22569 sgd_solver.cpp:106] Iteration 138000, lr = 0.0025
I0522 21:30:33.183753 22569 solver.cpp:237] Iteration 138375, loss = 0.955539
I0522 21:30:33.183789 22569 solver.cpp:253]     Train net output #0: loss = 0.955539 (* 1 = 0.955539 loss)
I0522 21:30:33.183805 22569 sgd_solver.cpp:106] Iteration 138375, lr = 0.0025
I0522 21:30:42.819627 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_138750.caffemodel
I0522 21:30:42.875586 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_138750.solverstate
I0522 21:30:42.909179 22569 solver.cpp:237] Iteration 138750, loss = 1.19995
I0522 21:30:42.909224 22569 solver.cpp:253]     Train net output #0: loss = 1.19995 (* 1 = 1.19995 loss)
I0522 21:30:42.909240 22569 sgd_solver.cpp:106] Iteration 138750, lr = 0.0025
I0522 21:30:52.572818 22569 solver.cpp:237] Iteration 139125, loss = 1.38843
I0522 21:30:52.573014 22569 solver.cpp:253]     Train net output #0: loss = 1.38843 (* 1 = 1.38843 loss)
I0522 21:30:52.573029 22569 sgd_solver.cpp:106] Iteration 139125, lr = 0.0025
I0522 21:31:02.234503 22569 solver.cpp:237] Iteration 139500, loss = 1.16631
I0522 21:31:02.234537 22569 solver.cpp:253]     Train net output #0: loss = 1.16631 (* 1 = 1.16631 loss)
I0522 21:31:02.234551 22569 sgd_solver.cpp:106] Iteration 139500, lr = 0.0025
I0522 21:31:11.895613 22569 solver.cpp:237] Iteration 139875, loss = 1.1913
I0522 21:31:11.895648 22569 solver.cpp:253]     Train net output #0: loss = 1.1913 (* 1 = 1.1913 loss)
I0522 21:31:11.895664 22569 sgd_solver.cpp:106] Iteration 139875, lr = 0.0025
I0522 21:31:42.393780 22569 solver.cpp:237] Iteration 140250, loss = 1.12082
I0522 21:31:42.393973 22569 solver.cpp:253]     Train net output #0: loss = 1.12082 (* 1 = 1.12082 loss)
I0522 21:31:42.393990 22569 sgd_solver.cpp:106] Iteration 140250, lr = 0.0025
I0522 21:31:52.058147 22569 solver.cpp:237] Iteration 140625, loss = 1.38454
I0522 21:31:52.058182 22569 solver.cpp:253]     Train net output #0: loss = 1.38454 (* 1 = 1.38454 loss)
I0522 21:31:52.058199 22569 sgd_solver.cpp:106] Iteration 140625, lr = 0.0025
I0522 21:32:01.724720 22569 solver.cpp:237] Iteration 141000, loss = 1.33403
I0522 21:32:01.724753 22569 solver.cpp:253]     Train net output #0: loss = 1.33403 (* 1 = 1.33403 loss)
I0522 21:32:01.724771 22569 sgd_solver.cpp:106] Iteration 141000, lr = 0.0025
I0522 21:32:11.387462 22569 solver.cpp:237] Iteration 141375, loss = 1.26837
I0522 21:32:11.387506 22569 solver.cpp:253]     Train net output #0: loss = 1.26837 (* 1 = 1.26837 loss)
I0522 21:32:11.387524 22569 sgd_solver.cpp:106] Iteration 141375, lr = 0.0025
I0522 21:32:21.052615 22569 solver.cpp:237] Iteration 141750, loss = 1.19547
I0522 21:32:21.052799 22569 solver.cpp:253]     Train net output #0: loss = 1.19547 (* 1 = 1.19547 loss)
I0522 21:32:21.052814 22569 sgd_solver.cpp:106] Iteration 141750, lr = 0.0025
I0522 21:32:30.715421 22569 solver.cpp:237] Iteration 142125, loss = 1.15816
I0522 21:32:30.715463 22569 solver.cpp:253]     Train net output #0: loss = 1.15816 (* 1 = 1.15816 loss)
I0522 21:32:30.715477 22569 sgd_solver.cpp:106] Iteration 142125, lr = 0.0025
I0522 21:32:40.352391 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_142500.caffemodel
I0522 21:32:40.408542 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_142500.solverstate
I0522 21:32:40.434377 22569 solver.cpp:341] Iteration 142500, Testing net (#0)
I0522 21:33:28.590490 22569 solver.cpp:409]     Test net output #0: accuracy = 0.896992
I0522 21:33:28.590687 22569 solver.cpp:409]     Test net output #1: loss = 0.326172 (* 1 = 0.326172 loss)
I0522 21:33:49.431784 22569 solver.cpp:237] Iteration 142500, loss = 1.132
I0522 21:33:49.431836 22569 solver.cpp:253]     Train net output #0: loss = 1.132 (* 1 = 1.132 loss)
I0522 21:33:49.431851 22569 sgd_solver.cpp:106] Iteration 142500, lr = 0.0025
I0522 21:33:59.201304 22569 solver.cpp:237] Iteration 142875, loss = 1.06932
I0522 21:33:59.201483 22569 solver.cpp:253]     Train net output #0: loss = 1.06932 (* 1 = 1.06932 loss)
I0522 21:33:59.201498 22569 sgd_solver.cpp:106] Iteration 142875, lr = 0.0025
I0522 21:34:08.970134 22569 solver.cpp:237] Iteration 143250, loss = 1.2523
I0522 21:34:08.970182 22569 solver.cpp:253]     Train net output #0: loss = 1.2523 (* 1 = 1.2523 loss)
I0522 21:34:08.970201 22569 sgd_solver.cpp:106] Iteration 143250, lr = 0.0025
I0522 21:34:18.743705 22569 solver.cpp:237] Iteration 143625, loss = 0.898856
I0522 21:34:18.743741 22569 solver.cpp:253]     Train net output #0: loss = 0.898855 (* 1 = 0.898855 loss)
I0522 21:34:18.743757 22569 sgd_solver.cpp:106] Iteration 143625, lr = 0.0025
I0522 21:34:28.519374 22569 solver.cpp:237] Iteration 144000, loss = 0.879659
I0522 21:34:28.519410 22569 solver.cpp:253]     Train net output #0: loss = 0.879659 (* 1 = 0.879659 loss)
I0522 21:34:28.519428 22569 sgd_solver.cpp:106] Iteration 144000, lr = 0.0025
I0522 21:34:38.289284 22569 solver.cpp:237] Iteration 144375, loss = 1.15909
I0522 21:34:38.289472 22569 solver.cpp:253]     Train net output #0: loss = 1.15909 (* 1 = 1.15909 loss)
I0522 21:34:38.289487 22569 sgd_solver.cpp:106] Iteration 144375, lr = 0.0025
I0522 21:34:48.062322 22569 solver.cpp:237] Iteration 144750, loss = 1.06706
I0522 21:34:48.062358 22569 solver.cpp:253]     Train net output #0: loss = 1.06706 (* 1 = 1.06706 loss)
I0522 21:34:48.062372 22569 sgd_solver.cpp:106] Iteration 144750, lr = 0.0025
I0522 21:35:18.627537 22569 solver.cpp:237] Iteration 145125, loss = 1.46264
I0522 21:35:18.627732 22569 solver.cpp:253]     Train net output #0: loss = 1.46264 (* 1 = 1.46264 loss)
I0522 21:35:18.627748 22569 sgd_solver.cpp:106] Iteration 145125, lr = 0.0025
I0522 21:35:28.404474 22569 solver.cpp:237] Iteration 145500, loss = 1.16922
I0522 21:35:28.404516 22569 solver.cpp:253]     Train net output #0: loss = 1.16922 (* 1 = 1.16922 loss)
I0522 21:35:28.404536 22569 sgd_solver.cpp:106] Iteration 145500, lr = 0.0025
I0522 21:35:38.176054 22569 solver.cpp:237] Iteration 145875, loss = 1.10547
I0522 21:35:38.176090 22569 solver.cpp:253]     Train net output #0: loss = 1.10547 (* 1 = 1.10547 loss)
I0522 21:35:38.176105 22569 sgd_solver.cpp:106] Iteration 145875, lr = 0.0025
I0522 21:35:47.918583 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_146250.caffemodel
I0522 21:35:47.975334 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_146250.solverstate
I0522 21:35:48.009400 22569 solver.cpp:237] Iteration 146250, loss = 1.22907
I0522 21:35:48.009441 22569 solver.cpp:253]     Train net output #0: loss = 1.22907 (* 1 = 1.22907 loss)
I0522 21:35:48.009457 22569 sgd_solver.cpp:106] Iteration 146250, lr = 0.0025
I0522 21:35:57.775786 22569 solver.cpp:237] Iteration 146625, loss = 0.81481
I0522 21:35:57.775998 22569 solver.cpp:253]     Train net output #0: loss = 0.814809 (* 1 = 0.814809 loss)
I0522 21:35:57.776013 22569 sgd_solver.cpp:106] Iteration 146625, lr = 0.0025
I0522 21:36:07.544366 22569 solver.cpp:237] Iteration 147000, loss = 1.24554
I0522 21:36:07.544401 22569 solver.cpp:253]     Train net output #0: loss = 1.24554 (* 1 = 1.24554 loss)
I0522 21:36:07.544420 22569 sgd_solver.cpp:106] Iteration 147000, lr = 0.0025
I0522 21:36:17.307941 22569 solver.cpp:237] Iteration 147375, loss = 1.20151
I0522 21:36:17.307986 22569 solver.cpp:253]     Train net output #0: loss = 1.20151 (* 1 = 1.20151 loss)
I0522 21:36:17.308003 22569 sgd_solver.cpp:106] Iteration 147375, lr = 0.0025
I0522 21:36:47.942667 22569 solver.cpp:237] Iteration 147750, loss = 0.99676
I0522 21:36:47.942876 22569 solver.cpp:253]     Train net output #0: loss = 0.99676 (* 1 = 0.99676 loss)
I0522 21:36:47.942891 22569 sgd_solver.cpp:106] Iteration 147750, lr = 0.0025
I0522 21:36:57.711603 22569 solver.cpp:237] Iteration 148125, loss = 1.32144
I0522 21:36:57.711638 22569 solver.cpp:253]     Train net output #0: loss = 1.32144 (* 1 = 1.32144 loss)
I0522 21:36:57.711654 22569 sgd_solver.cpp:106] Iteration 148125, lr = 0.0025
I0522 21:37:07.482844 22569 solver.cpp:237] Iteration 148500, loss = 1.03422
I0522 21:37:07.482884 22569 solver.cpp:253]     Train net output #0: loss = 1.03422 (* 1 = 1.03422 loss)
I0522 21:37:07.482906 22569 sgd_solver.cpp:106] Iteration 148500, lr = 0.0025
I0522 21:37:17.244268 22569 solver.cpp:237] Iteration 148875, loss = 1.42566
I0522 21:37:17.244303 22569 solver.cpp:253]     Train net output #0: loss = 1.42566 (* 1 = 1.42566 loss)
I0522 21:37:17.244319 22569 sgd_solver.cpp:106] Iteration 148875, lr = 0.0025
I0522 21:37:27.011626 22569 solver.cpp:237] Iteration 149250, loss = 1.54565
I0522 21:37:27.011800 22569 solver.cpp:253]     Train net output #0: loss = 1.54565 (* 1 = 1.54565 loss)
I0522 21:37:27.011813 22569 sgd_solver.cpp:106] Iteration 149250, lr = 0.0025
I0522 21:37:36.780529 22569 solver.cpp:237] Iteration 149625, loss = 1.34802
I0522 21:37:36.780567 22569 solver.cpp:253]     Train net output #0: loss = 1.34802 (* 1 = 1.34802 loss)
I0522 21:37:36.780582 22569 sgd_solver.cpp:106] Iteration 149625, lr = 0.0025
I0522 21:37:46.521193 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_150000.caffemodel
I0522 21:37:46.580807 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_150000.solverstate
I0522 21:37:46.607861 22569 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 21:38:56.116262 22569 solver.cpp:409]     Test net output #0: accuracy = 0.897346
I0522 21:38:56.116456 22569 solver.cpp:409]     Test net output #1: loss = 0.333428 (* 1 = 0.333428 loss)
I0522 21:39:17.004392 22569 solver.cpp:237] Iteration 150000, loss = 1.2299
I0522 21:39:17.004444 22569 solver.cpp:253]     Train net output #0: loss = 1.2299 (* 1 = 1.2299 loss)
I0522 21:39:17.004459 22569 sgd_solver.cpp:106] Iteration 150000, lr = 0.0025
I0522 21:39:26.894860 22569 solver.cpp:237] Iteration 150375, loss = 0.958762
I0522 21:39:26.895054 22569 solver.cpp:253]     Train net output #0: loss = 0.958762 (* 1 = 0.958762 loss)
I0522 21:39:26.895068 22569 sgd_solver.cpp:106] Iteration 150375, lr = 0.0025
I0522 21:39:36.783802 22569 solver.cpp:237] Iteration 150750, loss = 1.25449
I0522 21:39:36.783850 22569 solver.cpp:253]     Train net output #0: loss = 1.25449 (* 1 = 1.25449 loss)
I0522 21:39:36.783865 22569 sgd_solver.cpp:106] Iteration 150750, lr = 0.0025
I0522 21:39:46.663470 22569 solver.cpp:237] Iteration 151125, loss = 1.08047
I0522 21:39:46.663506 22569 solver.cpp:253]     Train net output #0: loss = 1.08047 (* 1 = 1.08047 loss)
I0522 21:39:46.663519 22569 sgd_solver.cpp:106] Iteration 151125, lr = 0.0025
I0522 21:39:56.547237 22569 solver.cpp:237] Iteration 151500, loss = 0.73699
I0522 21:39:56.547273 22569 solver.cpp:253]     Train net output #0: loss = 0.73699 (* 1 = 0.73699 loss)
I0522 21:39:56.547287 22569 sgd_solver.cpp:106] Iteration 151500, lr = 0.0025
I0522 21:40:06.433828 22569 solver.cpp:237] Iteration 151875, loss = 1.45159
I0522 21:40:06.434021 22569 solver.cpp:253]     Train net output #0: loss = 1.45159 (* 1 = 1.45159 loss)
I0522 21:40:06.434036 22569 sgd_solver.cpp:106] Iteration 151875, lr = 0.0025
I0522 21:40:16.319890 22569 solver.cpp:237] Iteration 152250, loss = 1.10099
I0522 21:40:16.319924 22569 solver.cpp:253]     Train net output #0: loss = 1.10099 (* 1 = 1.10099 loss)
I0522 21:40:16.319937 22569 sgd_solver.cpp:106] Iteration 152250, lr = 0.0025
I0522 21:40:47.061983 22569 solver.cpp:237] Iteration 152625, loss = 1.33032
I0522 21:40:47.062182 22569 solver.cpp:253]     Train net output #0: loss = 1.33032 (* 1 = 1.33032 loss)
I0522 21:40:47.062196 22569 sgd_solver.cpp:106] Iteration 152625, lr = 0.0025
I0522 21:40:56.948873 22569 solver.cpp:237] Iteration 153000, loss = 1.10385
I0522 21:40:56.948920 22569 solver.cpp:253]     Train net output #0: loss = 1.10385 (* 1 = 1.10385 loss)
I0522 21:40:56.948936 22569 sgd_solver.cpp:106] Iteration 153000, lr = 0.0025
I0522 21:41:06.828583 22569 solver.cpp:237] Iteration 153375, loss = 1.75507
I0522 21:41:06.828619 22569 solver.cpp:253]     Train net output #0: loss = 1.75507 (* 1 = 1.75507 loss)
I0522 21:41:06.828635 22569 sgd_solver.cpp:106] Iteration 153375, lr = 0.0025
I0522 21:41:16.680531 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_153750.caffemodel
I0522 21:41:16.736620 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_153750.solverstate
I0522 21:41:16.769842 22569 solver.cpp:237] Iteration 153750, loss = 0.953053
I0522 21:41:16.769886 22569 solver.cpp:253]     Train net output #0: loss = 0.953053 (* 1 = 0.953053 loss)
I0522 21:41:16.769902 22569 sgd_solver.cpp:106] Iteration 153750, lr = 0.0025
I0522 21:41:26.649178 22569 solver.cpp:237] Iteration 154125, loss = 1.42731
I0522 21:41:26.649358 22569 solver.cpp:253]     Train net output #0: loss = 1.42731 (* 1 = 1.42731 loss)
I0522 21:41:26.649372 22569 sgd_solver.cpp:106] Iteration 154125, lr = 0.0025
I0522 21:41:36.532917 22569 solver.cpp:237] Iteration 154500, loss = 1.15442
I0522 21:41:36.532953 22569 solver.cpp:253]     Train net output #0: loss = 1.15442 (* 1 = 1.15442 loss)
I0522 21:41:36.532970 22569 sgd_solver.cpp:106] Iteration 154500, lr = 0.0025
I0522 21:41:46.413133 22569 solver.cpp:237] Iteration 154875, loss = 0.864383
I0522 21:41:46.413180 22569 solver.cpp:253]     Train net output #0: loss = 0.864383 (* 1 = 0.864383 loss)
I0522 21:41:46.413195 22569 sgd_solver.cpp:106] Iteration 154875, lr = 0.0025
I0522 21:42:17.170384 22569 solver.cpp:237] Iteration 155250, loss = 1.03367
I0522 21:42:17.170579 22569 solver.cpp:253]     Train net output #0: loss = 1.03367 (* 1 = 1.03367 loss)
I0522 21:42:17.170594 22569 sgd_solver.cpp:106] Iteration 155250, lr = 0.0025
I0522 21:42:27.050357 22569 solver.cpp:237] Iteration 155625, loss = 0.895448
I0522 21:42:27.050393 22569 solver.cpp:253]     Train net output #0: loss = 0.895447 (* 1 = 0.895447 loss)
I0522 21:42:27.050410 22569 sgd_solver.cpp:106] Iteration 155625, lr = 0.0025
I0522 21:42:36.933296 22569 solver.cpp:237] Iteration 156000, loss = 1.12936
I0522 21:42:36.933346 22569 solver.cpp:253]     Train net output #0: loss = 1.12936 (* 1 = 1.12936 loss)
I0522 21:42:36.933360 22569 sgd_solver.cpp:106] Iteration 156000, lr = 0.0025
I0522 21:42:46.811048 22569 solver.cpp:237] Iteration 156375, loss = 1.25105
I0522 21:42:46.811082 22569 solver.cpp:253]     Train net output #0: loss = 1.25105 (* 1 = 1.25105 loss)
I0522 21:42:46.811095 22569 sgd_solver.cpp:106] Iteration 156375, lr = 0.0025
I0522 21:42:56.691385 22569 solver.cpp:237] Iteration 156750, loss = 1.12037
I0522 21:42:56.691583 22569 solver.cpp:253]     Train net output #0: loss = 1.12037 (* 1 = 1.12037 loss)
I0522 21:42:56.691597 22569 sgd_solver.cpp:106] Iteration 156750, lr = 0.0025
I0522 21:43:06.571568 22569 solver.cpp:237] Iteration 157125, loss = 1.24198
I0522 21:43:06.571602 22569 solver.cpp:253]     Train net output #0: loss = 1.24198 (* 1 = 1.24198 loss)
I0522 21:43:06.571619 22569 sgd_solver.cpp:106] Iteration 157125, lr = 0.0025
I0522 21:43:16.428278 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_157500.caffemodel
I0522 21:43:16.485026 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_157500.solverstate
I0522 21:43:16.510581 22569 solver.cpp:341] Iteration 157500, Testing net (#0)
I0522 21:44:04.977885 22569 solver.cpp:409]     Test net output #0: accuracy = 0.897
I0522 21:44:04.978087 22569 solver.cpp:409]     Test net output #1: loss = 0.323054 (* 1 = 0.323054 loss)
I0522 21:44:25.808226 22569 solver.cpp:237] Iteration 157500, loss = 0.936113
I0522 21:44:25.808279 22569 solver.cpp:253]     Train net output #0: loss = 0.936112 (* 1 = 0.936112 loss)
I0522 21:44:25.808295 22569 sgd_solver.cpp:106] Iteration 157500, lr = 0.0025
I0522 21:44:35.573249 22569 solver.cpp:237] Iteration 157875, loss = 1.32849
I0522 21:44:35.573437 22569 solver.cpp:253]     Train net output #0: loss = 1.32849 (* 1 = 1.32849 loss)
I0522 21:44:35.573451 22569 sgd_solver.cpp:106] Iteration 157875, lr = 0.0025
I0522 21:44:45.335280 22569 solver.cpp:237] Iteration 158250, loss = 1.18184
I0522 21:44:45.335314 22569 solver.cpp:253]     Train net output #0: loss = 1.18184 (* 1 = 1.18184 loss)
I0522 21:44:45.335331 22569 sgd_solver.cpp:106] Iteration 158250, lr = 0.0025
I0522 21:44:55.099452 22569 solver.cpp:237] Iteration 158625, loss = 1.10083
I0522 21:44:55.099488 22569 solver.cpp:253]     Train net output #0: loss = 1.10083 (* 1 = 1.10083 loss)
I0522 21:44:55.099500 22569 sgd_solver.cpp:106] Iteration 158625, lr = 0.0025
I0522 21:45:04.864848 22569 solver.cpp:237] Iteration 159000, loss = 1.00925
I0522 21:45:04.864889 22569 solver.cpp:253]     Train net output #0: loss = 1.00925 (* 1 = 1.00925 loss)
I0522 21:45:04.864909 22569 sgd_solver.cpp:106] Iteration 159000, lr = 0.0025
I0522 21:45:14.629976 22569 solver.cpp:237] Iteration 159375, loss = 1.19239
I0522 21:45:14.630151 22569 solver.cpp:253]     Train net output #0: loss = 1.19239 (* 1 = 1.19239 loss)
I0522 21:45:14.630164 22569 sgd_solver.cpp:106] Iteration 159375, lr = 0.0025
I0522 21:45:24.397531 22569 solver.cpp:237] Iteration 159750, loss = 0.635995
I0522 21:45:24.397578 22569 solver.cpp:253]     Train net output #0: loss = 0.635995 (* 1 = 0.635995 loss)
I0522 21:45:24.397593 22569 sgd_solver.cpp:106] Iteration 159750, lr = 0.0025
I0522 21:45:55.034500 22569 solver.cpp:237] Iteration 160125, loss = 1.22287
I0522 21:45:55.034698 22569 solver.cpp:253]     Train net output #0: loss = 1.22287 (* 1 = 1.22287 loss)
I0522 21:45:55.034713 22569 sgd_solver.cpp:106] Iteration 160125, lr = 0.0025
I0522 21:46:04.800241 22569 solver.cpp:237] Iteration 160500, loss = 0.923092
I0522 21:46:04.800277 22569 solver.cpp:253]     Train net output #0: loss = 0.923092 (* 1 = 0.923092 loss)
I0522 21:46:04.800292 22569 sgd_solver.cpp:106] Iteration 160500, lr = 0.0025
I0522 21:46:14.563333 22569 solver.cpp:237] Iteration 160875, loss = 1.40813
I0522 21:46:14.563374 22569 solver.cpp:253]     Train net output #0: loss = 1.40813 (* 1 = 1.40813 loss)
I0522 21:46:14.563395 22569 sgd_solver.cpp:106] Iteration 160875, lr = 0.0025
I0522 21:46:24.306138 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_161250.caffemodel
I0522 21:46:24.362179 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_161250.solverstate
I0522 21:46:24.396431 22569 solver.cpp:237] Iteration 161250, loss = 0.932133
I0522 21:46:24.396479 22569 solver.cpp:253]     Train net output #0: loss = 0.932133 (* 1 = 0.932133 loss)
I0522 21:46:24.396493 22569 sgd_solver.cpp:106] Iteration 161250, lr = 0.0025
I0522 21:46:34.165927 22569 solver.cpp:237] Iteration 161625, loss = 1.02994
I0522 21:46:34.166116 22569 solver.cpp:253]     Train net output #0: loss = 1.02994 (* 1 = 1.02994 loss)
I0522 21:46:34.166131 22569 sgd_solver.cpp:106] Iteration 161625, lr = 0.0025
I0522 21:46:43.926167 22569 solver.cpp:237] Iteration 162000, loss = 1.04978
I0522 21:46:43.926209 22569 solver.cpp:253]     Train net output #0: loss = 1.04978 (* 1 = 1.04978 loss)
I0522 21:46:43.926224 22569 sgd_solver.cpp:106] Iteration 162000, lr = 0.0025
I0522 21:46:53.689985 22569 solver.cpp:237] Iteration 162375, loss = 1.21707
I0522 21:46:53.690021 22569 solver.cpp:253]     Train net output #0: loss = 1.21707 (* 1 = 1.21707 loss)
I0522 21:46:53.690037 22569 sgd_solver.cpp:106] Iteration 162375, lr = 0.0025
I0522 21:47:24.304956 22569 solver.cpp:237] Iteration 162750, loss = 1.10865
I0522 21:47:24.305160 22569 solver.cpp:253]     Train net output #0: loss = 1.10865 (* 1 = 1.10865 loss)
I0522 21:47:24.305176 22569 sgd_solver.cpp:106] Iteration 162750, lr = 0.0025
I0522 21:47:34.068426 22569 solver.cpp:237] Iteration 163125, loss = 1.4674
I0522 21:47:34.068473 22569 solver.cpp:253]     Train net output #0: loss = 1.4674 (* 1 = 1.4674 loss)
I0522 21:47:34.068490 22569 sgd_solver.cpp:106] Iteration 163125, lr = 0.0025
I0522 21:47:43.827215 22569 solver.cpp:237] Iteration 163500, loss = 1.19644
I0522 21:47:43.827250 22569 solver.cpp:253]     Train net output #0: loss = 1.19644 (* 1 = 1.19644 loss)
I0522 21:47:43.827267 22569 sgd_solver.cpp:106] Iteration 163500, lr = 0.0025
I0522 21:47:53.581918 22569 solver.cpp:237] Iteration 163875, loss = 0.953666
I0522 21:47:53.581969 22569 solver.cpp:253]     Train net output #0: loss = 0.953666 (* 1 = 0.953666 loss)
I0522 21:47:53.581982 22569 sgd_solver.cpp:106] Iteration 163875, lr = 0.0025
I0522 21:48:03.342699 22569 solver.cpp:237] Iteration 164250, loss = 1.33532
I0522 21:48:03.342876 22569 solver.cpp:253]     Train net output #0: loss = 1.33532 (* 1 = 1.33532 loss)
I0522 21:48:03.342892 22569 sgd_solver.cpp:106] Iteration 164250, lr = 0.0025
I0522 21:48:13.105128 22569 solver.cpp:237] Iteration 164625, loss = 0.951157
I0522 21:48:13.105162 22569 solver.cpp:253]     Train net output #0: loss = 0.951156 (* 1 = 0.951156 loss)
I0522 21:48:13.105180 22569 sgd_solver.cpp:106] Iteration 164625, lr = 0.0025
I0522 21:48:22.841917 22569 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_165000.caffemodel
I0522 21:48:22.897572 22569 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_165000.solverstate
I0522 21:48:22.922848 22569 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 21:49:32.234383 22569 solver.cpp:409]     Test net output #0: accuracy = 0.89718
I0522 21:49:32.234591 22569 solver.cpp:409]     Test net output #1: loss = 0.339587 (* 1 = 0.339587 loss)
I0522 21:49:53.108206 22569 solver.cpp:237] Iteration 165000, loss = 0.955064
I0522 21:49:53.108260 22569 solver.cpp:253]     Train net output #0: loss = 0.955063 (* 1 = 0.955063 loss)
I0522 21:49:53.108276 22569 sgd_solver.cpp:106] Iteration 165000, lr = 0.0025
I0522 21:50:02.801512 22569 solver.cpp:237] Iteration 165375, loss = 1.03668
I0522 21:50:02.801703 22569 solver.cpp:253]     Train net output #0: loss = 1.03668 (* 1 = 1.03668 loss)
I0522 21:50:02.801717 22569 sgd_solver.cpp:106] Iteration 165375, lr = 0.0025
I0522 21:50:12.485760 22569 solver.cpp:237] Iteration 165750, loss = 1.27562
I0522 21:50:12.485795 22569 solver.cpp:253]     Train net output #0: loss = 1.27562 (* 1 = 1.27562 loss)
I0522 21:50:12.485815 22569 sgd_solver.cpp:106] Iteration 165750, lr = 0.0025
I0522 21:50:22.179226 22569 solver.cpp:237] Iteration 166125, loss = 1.09711
I0522 21:50:22.179261 22569 solver.cpp:253]     Train net output #0: loss = 1.09711 (* 1 = 1.09711 loss)
I0522 21:50:22.179275 22569 sgd_solver.cpp:106] Iteration 166125, lr = 0.0025
I0522 21:50:31.862145 22569 solver.cpp:237] Iteration 166500, loss = 1.07216
I0522 21:50:31.862185 22569 solver.cpp:253]     Train net output #0: loss = 1.07216 (* 1 = 1.07216 loss)
I0522 21:50:31.862205 22569 sgd_solver.cpp:106] Iteration 166500, lr = 0.0025
I0522 21:50:41.547899 22569 solver.cpp:237] Iteration 166875, loss = 1.24542
I0522 21:50:41.548075 22569 solver.cpp:253]     Train net output #0: loss = 1.24542 (* 1 = 1.24542 loss)
I0522 21:50:41.548089 22569 sgd_solver.cpp:106] Iteration 166875, lr = 0.0025
I0522 21:50:51.234675 22569 solver.cpp:237] Iteration 167250, loss = 1.16026
I0522 21:50:51.234720 22569 solver.cpp:253]     Train net output #0: loss = 1.16026 (* 1 = 1.16026 loss)
I0522 21:50:51.234736 22569 sgd_solver.cpp:106] Iteration 167250, lr = 0.0025
I0522 21:51:21.768052 22569 solver.cpp:237] Iteration 167625, loss = 1.36775
I0522 21:51:21.768254 22569 solver.cpp:253]     Train net output #0: loss = 1.36775 (* 1 = 1.36775 loss)
I0522 21:51:21.768268 22569 sgd_solver.cpp:106] Iteration 167625, lr = 0.0025
I0522 21:51:31.457908 22569 solver.cpp:237] Iteration 168000, loss = 0.904263
I0522 21:51:31.457944 22569 solver.cpp:253]     Train net output #0: loss = 0.904263 (* 1 = 0.904263 loss)
I0522 21:51:31.457958 22569 sgd_solver.cpp:106] Iteration 168000, lr = 0.0025
I0522 21:51:41.145864 22569 solver.cpp:237] Iteration 168375, loss = 0.835217
I0522 21:51:41.145906 22569 solver.cpp:253]     Train net output #0: loss = 0.835217 (* 1 = 0.835217 loss)
I0522 21:51:41.145928 22569 sgd_solver.cpp:106] Iteration 168375, lr = 0.0025
aprun: Apid 11250631: Caught signal Terminated, sending to application
*** Aborted at 1463968301 (unix time) try "date -d @1463968301" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x5826) received by PID 22569 (TID 0x2aaac746f900) from PID 22566; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7231 exceeded limit 7200
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11250631: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
aprun: Apid 11250631: Caught signal Terminated, sending to application
