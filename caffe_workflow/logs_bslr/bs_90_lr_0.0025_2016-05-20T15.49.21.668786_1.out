2810021
I0525 06:53:04.497102 20349 caffe.cpp:184] Using GPUs 0
I0525 06:53:04.923348 20349 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1666
test_interval: 3333
base_lr: 0.0025
display: 166
max_iter: 166660
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1666
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786.prototxt"
I0525 06:53:04.925236 20349 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786.prototxt
I0525 06:53:04.939306 20349 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 06:53:04.939365 20349 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 06:53:04.939713 20349 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 06:53:04.939895 20349 layer_factory.hpp:77] Creating layer data_hdf5
I0525 06:53:04.939918 20349 net.cpp:106] Creating Layer data_hdf5
I0525 06:53:04.939932 20349 net.cpp:411] data_hdf5 -> data
I0525 06:53:04.939965 20349 net.cpp:411] data_hdf5 -> label
I0525 06:53:04.939997 20349 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 06:53:04.941671 20349 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 06:53:04.956759 20349 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 06:53:26.488277 20349 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 06:53:26.493561 20349 net.cpp:150] Setting up data_hdf5
I0525 06:53:26.493602 20349 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 06:53:26.493616 20349 net.cpp:157] Top shape: 90 (90)
I0525 06:53:26.493628 20349 net.cpp:165] Memory required for data: 2286360
I0525 06:53:26.493643 20349 layer_factory.hpp:77] Creating layer conv1
I0525 06:53:26.493676 20349 net.cpp:106] Creating Layer conv1
I0525 06:53:26.493687 20349 net.cpp:454] conv1 <- data
I0525 06:53:26.493710 20349 net.cpp:411] conv1 -> conv1
I0525 06:53:26.866886 20349 net.cpp:150] Setting up conv1
I0525 06:53:26.866932 20349 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:53:26.866943 20349 net.cpp:165] Memory required for data: 27169560
I0525 06:53:26.866971 20349 layer_factory.hpp:77] Creating layer relu1
I0525 06:53:26.866993 20349 net.cpp:106] Creating Layer relu1
I0525 06:53:26.867004 20349 net.cpp:454] relu1 <- conv1
I0525 06:53:26.867017 20349 net.cpp:397] relu1 -> conv1 (in-place)
I0525 06:53:26.867534 20349 net.cpp:150] Setting up relu1
I0525 06:53:26.867552 20349 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:53:26.867561 20349 net.cpp:165] Memory required for data: 52052760
I0525 06:53:26.867573 20349 layer_factory.hpp:77] Creating layer pool1
I0525 06:53:26.867588 20349 net.cpp:106] Creating Layer pool1
I0525 06:53:26.867599 20349 net.cpp:454] pool1 <- conv1
I0525 06:53:26.867611 20349 net.cpp:411] pool1 -> pool1
I0525 06:53:26.867691 20349 net.cpp:150] Setting up pool1
I0525 06:53:26.867704 20349 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 06:53:26.867714 20349 net.cpp:165] Memory required for data: 64494360
I0525 06:53:26.867724 20349 layer_factory.hpp:77] Creating layer conv2
I0525 06:53:26.867748 20349 net.cpp:106] Creating Layer conv2
I0525 06:53:26.867758 20349 net.cpp:454] conv2 <- pool1
I0525 06:53:26.867771 20349 net.cpp:411] conv2 -> conv2
I0525 06:53:26.870486 20349 net.cpp:150] Setting up conv2
I0525 06:53:26.870514 20349 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:53:26.870525 20349 net.cpp:165] Memory required for data: 82379160
I0525 06:53:26.870544 20349 layer_factory.hpp:77] Creating layer relu2
I0525 06:53:26.870558 20349 net.cpp:106] Creating Layer relu2
I0525 06:53:26.870568 20349 net.cpp:454] relu2 <- conv2
I0525 06:53:26.870581 20349 net.cpp:397] relu2 -> conv2 (in-place)
I0525 06:53:26.870910 20349 net.cpp:150] Setting up relu2
I0525 06:53:26.870925 20349 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:53:26.870935 20349 net.cpp:165] Memory required for data: 100263960
I0525 06:53:26.870946 20349 layer_factory.hpp:77] Creating layer pool2
I0525 06:53:26.870959 20349 net.cpp:106] Creating Layer pool2
I0525 06:53:26.870968 20349 net.cpp:454] pool2 <- conv2
I0525 06:53:26.870981 20349 net.cpp:411] pool2 -> pool2
I0525 06:53:26.871062 20349 net.cpp:150] Setting up pool2
I0525 06:53:26.871075 20349 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 06:53:26.871085 20349 net.cpp:165] Memory required for data: 109206360
I0525 06:53:26.871095 20349 layer_factory.hpp:77] Creating layer conv3
I0525 06:53:26.871114 20349 net.cpp:106] Creating Layer conv3
I0525 06:53:26.871124 20349 net.cpp:454] conv3 <- pool2
I0525 06:53:26.871137 20349 net.cpp:411] conv3 -> conv3
I0525 06:53:26.873044 20349 net.cpp:150] Setting up conv3
I0525 06:53:26.873067 20349 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:53:26.873080 20349 net.cpp:165] Memory required for data: 118963800
I0525 06:53:26.873098 20349 layer_factory.hpp:77] Creating layer relu3
I0525 06:53:26.873113 20349 net.cpp:106] Creating Layer relu3
I0525 06:53:26.873123 20349 net.cpp:454] relu3 <- conv3
I0525 06:53:26.873136 20349 net.cpp:397] relu3 -> conv3 (in-place)
I0525 06:53:26.873615 20349 net.cpp:150] Setting up relu3
I0525 06:53:26.873632 20349 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:53:26.873642 20349 net.cpp:165] Memory required for data: 128721240
I0525 06:53:26.873652 20349 layer_factory.hpp:77] Creating layer pool3
I0525 06:53:26.873666 20349 net.cpp:106] Creating Layer pool3
I0525 06:53:26.873675 20349 net.cpp:454] pool3 <- conv3
I0525 06:53:26.873688 20349 net.cpp:411] pool3 -> pool3
I0525 06:53:26.873756 20349 net.cpp:150] Setting up pool3
I0525 06:53:26.873769 20349 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 06:53:26.873780 20349 net.cpp:165] Memory required for data: 133599960
I0525 06:53:26.873787 20349 layer_factory.hpp:77] Creating layer conv4
I0525 06:53:26.873805 20349 net.cpp:106] Creating Layer conv4
I0525 06:53:26.873814 20349 net.cpp:454] conv4 <- pool3
I0525 06:53:26.873828 20349 net.cpp:411] conv4 -> conv4
I0525 06:53:26.876766 20349 net.cpp:150] Setting up conv4
I0525 06:53:26.876796 20349 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:53:26.876806 20349 net.cpp:165] Memory required for data: 136865880
I0525 06:53:26.876822 20349 layer_factory.hpp:77] Creating layer relu4
I0525 06:53:26.876837 20349 net.cpp:106] Creating Layer relu4
I0525 06:53:26.876847 20349 net.cpp:454] relu4 <- conv4
I0525 06:53:26.876860 20349 net.cpp:397] relu4 -> conv4 (in-place)
I0525 06:53:26.877322 20349 net.cpp:150] Setting up relu4
I0525 06:53:26.877338 20349 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:53:26.877348 20349 net.cpp:165] Memory required for data: 140131800
I0525 06:53:26.877359 20349 layer_factory.hpp:77] Creating layer pool4
I0525 06:53:26.877372 20349 net.cpp:106] Creating Layer pool4
I0525 06:53:26.877382 20349 net.cpp:454] pool4 <- conv4
I0525 06:53:26.877394 20349 net.cpp:411] pool4 -> pool4
I0525 06:53:26.877472 20349 net.cpp:150] Setting up pool4
I0525 06:53:26.877486 20349 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 06:53:26.877496 20349 net.cpp:165] Memory required for data: 141764760
I0525 06:53:26.877506 20349 layer_factory.hpp:77] Creating layer ip1
I0525 06:53:26.877526 20349 net.cpp:106] Creating Layer ip1
I0525 06:53:26.877535 20349 net.cpp:454] ip1 <- pool4
I0525 06:53:26.877548 20349 net.cpp:411] ip1 -> ip1
I0525 06:53:26.892964 20349 net.cpp:150] Setting up ip1
I0525 06:53:26.892992 20349 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:53:26.893003 20349 net.cpp:165] Memory required for data: 141835320
I0525 06:53:26.893024 20349 layer_factory.hpp:77] Creating layer relu5
I0525 06:53:26.893039 20349 net.cpp:106] Creating Layer relu5
I0525 06:53:26.893050 20349 net.cpp:454] relu5 <- ip1
I0525 06:53:26.893064 20349 net.cpp:397] relu5 -> ip1 (in-place)
I0525 06:53:26.893411 20349 net.cpp:150] Setting up relu5
I0525 06:53:26.893424 20349 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:53:26.893435 20349 net.cpp:165] Memory required for data: 141905880
I0525 06:53:26.893445 20349 layer_factory.hpp:77] Creating layer drop1
I0525 06:53:26.893465 20349 net.cpp:106] Creating Layer drop1
I0525 06:53:26.893476 20349 net.cpp:454] drop1 <- ip1
I0525 06:53:26.893488 20349 net.cpp:397] drop1 -> ip1 (in-place)
I0525 06:53:26.893549 20349 net.cpp:150] Setting up drop1
I0525 06:53:26.893563 20349 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:53:26.893571 20349 net.cpp:165] Memory required for data: 141976440
I0525 06:53:26.893581 20349 layer_factory.hpp:77] Creating layer ip2
I0525 06:53:26.893600 20349 net.cpp:106] Creating Layer ip2
I0525 06:53:26.893611 20349 net.cpp:454] ip2 <- ip1
I0525 06:53:26.893625 20349 net.cpp:411] ip2 -> ip2
I0525 06:53:26.894089 20349 net.cpp:150] Setting up ip2
I0525 06:53:26.894103 20349 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:53:26.894112 20349 net.cpp:165] Memory required for data: 142011720
I0525 06:53:26.894127 20349 layer_factory.hpp:77] Creating layer relu6
I0525 06:53:26.894140 20349 net.cpp:106] Creating Layer relu6
I0525 06:53:26.894150 20349 net.cpp:454] relu6 <- ip2
I0525 06:53:26.894161 20349 net.cpp:397] relu6 -> ip2 (in-place)
I0525 06:53:26.894681 20349 net.cpp:150] Setting up relu6
I0525 06:53:26.894698 20349 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:53:26.894707 20349 net.cpp:165] Memory required for data: 142047000
I0525 06:53:26.894718 20349 layer_factory.hpp:77] Creating layer drop2
I0525 06:53:26.894731 20349 net.cpp:106] Creating Layer drop2
I0525 06:53:26.894740 20349 net.cpp:454] drop2 <- ip2
I0525 06:53:26.894752 20349 net.cpp:397] drop2 -> ip2 (in-place)
I0525 06:53:26.894795 20349 net.cpp:150] Setting up drop2
I0525 06:53:26.894809 20349 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:53:26.894819 20349 net.cpp:165] Memory required for data: 142082280
I0525 06:53:26.894829 20349 layer_factory.hpp:77] Creating layer ip3
I0525 06:53:26.894842 20349 net.cpp:106] Creating Layer ip3
I0525 06:53:26.894852 20349 net.cpp:454] ip3 <- ip2
I0525 06:53:26.894865 20349 net.cpp:411] ip3 -> ip3
I0525 06:53:26.895072 20349 net.cpp:150] Setting up ip3
I0525 06:53:26.895086 20349 net.cpp:157] Top shape: 90 11 (990)
I0525 06:53:26.895094 20349 net.cpp:165] Memory required for data: 142086240
I0525 06:53:26.895109 20349 layer_factory.hpp:77] Creating layer drop3
I0525 06:53:26.895123 20349 net.cpp:106] Creating Layer drop3
I0525 06:53:26.895131 20349 net.cpp:454] drop3 <- ip3
I0525 06:53:26.895143 20349 net.cpp:397] drop3 -> ip3 (in-place)
I0525 06:53:26.895182 20349 net.cpp:150] Setting up drop3
I0525 06:53:26.895195 20349 net.cpp:157] Top shape: 90 11 (990)
I0525 06:53:26.895205 20349 net.cpp:165] Memory required for data: 142090200
I0525 06:53:26.895215 20349 layer_factory.hpp:77] Creating layer loss
I0525 06:53:26.895234 20349 net.cpp:106] Creating Layer loss
I0525 06:53:26.895243 20349 net.cpp:454] loss <- ip3
I0525 06:53:26.895256 20349 net.cpp:454] loss <- label
I0525 06:53:26.895267 20349 net.cpp:411] loss -> loss
I0525 06:53:26.895284 20349 layer_factory.hpp:77] Creating layer loss
I0525 06:53:26.895930 20349 net.cpp:150] Setting up loss
I0525 06:53:26.895951 20349 net.cpp:157] Top shape: (1)
I0525 06:53:26.895963 20349 net.cpp:160]     with loss weight 1
I0525 06:53:26.896005 20349 net.cpp:165] Memory required for data: 142090204
I0525 06:53:26.896016 20349 net.cpp:226] loss needs backward computation.
I0525 06:53:26.896028 20349 net.cpp:226] drop3 needs backward computation.
I0525 06:53:26.896037 20349 net.cpp:226] ip3 needs backward computation.
I0525 06:53:26.896047 20349 net.cpp:226] drop2 needs backward computation.
I0525 06:53:26.896057 20349 net.cpp:226] relu6 needs backward computation.
I0525 06:53:26.896067 20349 net.cpp:226] ip2 needs backward computation.
I0525 06:53:26.896077 20349 net.cpp:226] drop1 needs backward computation.
I0525 06:53:26.896087 20349 net.cpp:226] relu5 needs backward computation.
I0525 06:53:26.896095 20349 net.cpp:226] ip1 needs backward computation.
I0525 06:53:26.896106 20349 net.cpp:226] pool4 needs backward computation.
I0525 06:53:26.896116 20349 net.cpp:226] relu4 needs backward computation.
I0525 06:53:26.896126 20349 net.cpp:226] conv4 needs backward computation.
I0525 06:53:26.896136 20349 net.cpp:226] pool3 needs backward computation.
I0525 06:53:26.896147 20349 net.cpp:226] relu3 needs backward computation.
I0525 06:53:26.896165 20349 net.cpp:226] conv3 needs backward computation.
I0525 06:53:26.896174 20349 net.cpp:226] pool2 needs backward computation.
I0525 06:53:26.896184 20349 net.cpp:226] relu2 needs backward computation.
I0525 06:53:26.896194 20349 net.cpp:226] conv2 needs backward computation.
I0525 06:53:26.896206 20349 net.cpp:226] pool1 needs backward computation.
I0525 06:53:26.896217 20349 net.cpp:226] relu1 needs backward computation.
I0525 06:53:26.896227 20349 net.cpp:226] conv1 needs backward computation.
I0525 06:53:26.896239 20349 net.cpp:228] data_hdf5 does not need backward computation.
I0525 06:53:26.896248 20349 net.cpp:270] This network produces output loss
I0525 06:53:26.896271 20349 net.cpp:283] Network initialization done.
I0525 06:53:26.898233 20349 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786.prototxt
I0525 06:53:26.898304 20349 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 06:53:26.898658 20349 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 06:53:26.898845 20349 layer_factory.hpp:77] Creating layer data_hdf5
I0525 06:53:26.898860 20349 net.cpp:106] Creating Layer data_hdf5
I0525 06:53:26.898872 20349 net.cpp:411] data_hdf5 -> data
I0525 06:53:26.898891 20349 net.cpp:411] data_hdf5 -> label
I0525 06:53:26.898908 20349 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 06:53:26.900336 20349 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 06:53:48.276885 20349 net.cpp:150] Setting up data_hdf5
I0525 06:53:48.277050 20349 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 06:53:48.277063 20349 net.cpp:157] Top shape: 90 (90)
I0525 06:53:48.277076 20349 net.cpp:165] Memory required for data: 2286360
I0525 06:53:48.277088 20349 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 06:53:48.277117 20349 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 06:53:48.277127 20349 net.cpp:454] label_data_hdf5_1_split <- label
I0525 06:53:48.277143 20349 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 06:53:48.277164 20349 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 06:53:48.277238 20349 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 06:53:48.277251 20349 net.cpp:157] Top shape: 90 (90)
I0525 06:53:48.277263 20349 net.cpp:157] Top shape: 90 (90)
I0525 06:53:48.277273 20349 net.cpp:165] Memory required for data: 2287080
I0525 06:53:48.277282 20349 layer_factory.hpp:77] Creating layer conv1
I0525 06:53:48.277304 20349 net.cpp:106] Creating Layer conv1
I0525 06:53:48.277315 20349 net.cpp:454] conv1 <- data
I0525 06:53:48.277330 20349 net.cpp:411] conv1 -> conv1
I0525 06:53:48.279273 20349 net.cpp:150] Setting up conv1
I0525 06:53:48.279297 20349 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:53:48.279309 20349 net.cpp:165] Memory required for data: 27170280
I0525 06:53:48.279330 20349 layer_factory.hpp:77] Creating layer relu1
I0525 06:53:48.279345 20349 net.cpp:106] Creating Layer relu1
I0525 06:53:48.279356 20349 net.cpp:454] relu1 <- conv1
I0525 06:53:48.279368 20349 net.cpp:397] relu1 -> conv1 (in-place)
I0525 06:53:48.279858 20349 net.cpp:150] Setting up relu1
I0525 06:53:48.279875 20349 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:53:48.279884 20349 net.cpp:165] Memory required for data: 52053480
I0525 06:53:48.279894 20349 layer_factory.hpp:77] Creating layer pool1
I0525 06:53:48.279911 20349 net.cpp:106] Creating Layer pool1
I0525 06:53:48.279920 20349 net.cpp:454] pool1 <- conv1
I0525 06:53:48.279933 20349 net.cpp:411] pool1 -> pool1
I0525 06:53:48.280009 20349 net.cpp:150] Setting up pool1
I0525 06:53:48.280021 20349 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 06:53:48.280031 20349 net.cpp:165] Memory required for data: 64495080
I0525 06:53:48.280041 20349 layer_factory.hpp:77] Creating layer conv2
I0525 06:53:48.280058 20349 net.cpp:106] Creating Layer conv2
I0525 06:53:48.280069 20349 net.cpp:454] conv2 <- pool1
I0525 06:53:48.280083 20349 net.cpp:411] conv2 -> conv2
I0525 06:53:48.282003 20349 net.cpp:150] Setting up conv2
I0525 06:53:48.282027 20349 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:53:48.282038 20349 net.cpp:165] Memory required for data: 82379880
I0525 06:53:48.282057 20349 layer_factory.hpp:77] Creating layer relu2
I0525 06:53:48.282069 20349 net.cpp:106] Creating Layer relu2
I0525 06:53:48.282079 20349 net.cpp:454] relu2 <- conv2
I0525 06:53:48.282091 20349 net.cpp:397] relu2 -> conv2 (in-place)
I0525 06:53:48.282428 20349 net.cpp:150] Setting up relu2
I0525 06:53:48.282441 20349 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:53:48.282451 20349 net.cpp:165] Memory required for data: 100264680
I0525 06:53:48.282461 20349 layer_factory.hpp:77] Creating layer pool2
I0525 06:53:48.282474 20349 net.cpp:106] Creating Layer pool2
I0525 06:53:48.282485 20349 net.cpp:454] pool2 <- conv2
I0525 06:53:48.282496 20349 net.cpp:411] pool2 -> pool2
I0525 06:53:48.282568 20349 net.cpp:150] Setting up pool2
I0525 06:53:48.282582 20349 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 06:53:48.282591 20349 net.cpp:165] Memory required for data: 109207080
I0525 06:53:48.282603 20349 layer_factory.hpp:77] Creating layer conv3
I0525 06:53:48.282621 20349 net.cpp:106] Creating Layer conv3
I0525 06:53:48.282632 20349 net.cpp:454] conv3 <- pool2
I0525 06:53:48.282646 20349 net.cpp:411] conv3 -> conv3
I0525 06:53:48.284618 20349 net.cpp:150] Setting up conv3
I0525 06:53:48.284641 20349 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:53:48.284653 20349 net.cpp:165] Memory required for data: 118964520
I0525 06:53:48.284685 20349 layer_factory.hpp:77] Creating layer relu3
I0525 06:53:48.284699 20349 net.cpp:106] Creating Layer relu3
I0525 06:53:48.284709 20349 net.cpp:454] relu3 <- conv3
I0525 06:53:48.284723 20349 net.cpp:397] relu3 -> conv3 (in-place)
I0525 06:53:48.285188 20349 net.cpp:150] Setting up relu3
I0525 06:53:48.285204 20349 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:53:48.285214 20349 net.cpp:165] Memory required for data: 128721960
I0525 06:53:48.285224 20349 layer_factory.hpp:77] Creating layer pool3
I0525 06:53:48.285238 20349 net.cpp:106] Creating Layer pool3
I0525 06:53:48.285246 20349 net.cpp:454] pool3 <- conv3
I0525 06:53:48.285260 20349 net.cpp:411] pool3 -> pool3
I0525 06:53:48.285331 20349 net.cpp:150] Setting up pool3
I0525 06:53:48.285344 20349 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 06:53:48.285353 20349 net.cpp:165] Memory required for data: 133600680
I0525 06:53:48.285363 20349 layer_factory.hpp:77] Creating layer conv4
I0525 06:53:48.285380 20349 net.cpp:106] Creating Layer conv4
I0525 06:53:48.285392 20349 net.cpp:454] conv4 <- pool3
I0525 06:53:48.285413 20349 net.cpp:411] conv4 -> conv4
I0525 06:53:48.287485 20349 net.cpp:150] Setting up conv4
I0525 06:53:48.287503 20349 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:53:48.287514 20349 net.cpp:165] Memory required for data: 136866600
I0525 06:53:48.287529 20349 layer_factory.hpp:77] Creating layer relu4
I0525 06:53:48.287542 20349 net.cpp:106] Creating Layer relu4
I0525 06:53:48.287552 20349 net.cpp:454] relu4 <- conv4
I0525 06:53:48.287565 20349 net.cpp:397] relu4 -> conv4 (in-place)
I0525 06:53:48.288039 20349 net.cpp:150] Setting up relu4
I0525 06:53:48.288055 20349 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:53:48.288066 20349 net.cpp:165] Memory required for data: 140132520
I0525 06:53:48.288076 20349 layer_factory.hpp:77] Creating layer pool4
I0525 06:53:48.288089 20349 net.cpp:106] Creating Layer pool4
I0525 06:53:48.288100 20349 net.cpp:454] pool4 <- conv4
I0525 06:53:48.288112 20349 net.cpp:411] pool4 -> pool4
I0525 06:53:48.288183 20349 net.cpp:150] Setting up pool4
I0525 06:53:48.288197 20349 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 06:53:48.288206 20349 net.cpp:165] Memory required for data: 141765480
I0525 06:53:48.288216 20349 layer_factory.hpp:77] Creating layer ip1
I0525 06:53:48.288233 20349 net.cpp:106] Creating Layer ip1
I0525 06:53:48.288242 20349 net.cpp:454] ip1 <- pool4
I0525 06:53:48.288256 20349 net.cpp:411] ip1 -> ip1
I0525 06:53:48.303779 20349 net.cpp:150] Setting up ip1
I0525 06:53:48.303808 20349 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:53:48.303819 20349 net.cpp:165] Memory required for data: 141836040
I0525 06:53:48.303841 20349 layer_factory.hpp:77] Creating layer relu5
I0525 06:53:48.303856 20349 net.cpp:106] Creating Layer relu5
I0525 06:53:48.303866 20349 net.cpp:454] relu5 <- ip1
I0525 06:53:48.303879 20349 net.cpp:397] relu5 -> ip1 (in-place)
I0525 06:53:48.304226 20349 net.cpp:150] Setting up relu5
I0525 06:53:48.304240 20349 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:53:48.304250 20349 net.cpp:165] Memory required for data: 141906600
I0525 06:53:48.304260 20349 layer_factory.hpp:77] Creating layer drop1
I0525 06:53:48.304278 20349 net.cpp:106] Creating Layer drop1
I0525 06:53:48.304288 20349 net.cpp:454] drop1 <- ip1
I0525 06:53:48.304301 20349 net.cpp:397] drop1 -> ip1 (in-place)
I0525 06:53:48.304348 20349 net.cpp:150] Setting up drop1
I0525 06:53:48.304361 20349 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:53:48.304371 20349 net.cpp:165] Memory required for data: 141977160
I0525 06:53:48.304380 20349 layer_factory.hpp:77] Creating layer ip2
I0525 06:53:48.304394 20349 net.cpp:106] Creating Layer ip2
I0525 06:53:48.304404 20349 net.cpp:454] ip2 <- ip1
I0525 06:53:48.304419 20349 net.cpp:411] ip2 -> ip2
I0525 06:53:48.304896 20349 net.cpp:150] Setting up ip2
I0525 06:53:48.304909 20349 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:53:48.304919 20349 net.cpp:165] Memory required for data: 142012440
I0525 06:53:48.304934 20349 layer_factory.hpp:77] Creating layer relu6
I0525 06:53:48.304961 20349 net.cpp:106] Creating Layer relu6
I0525 06:53:48.304971 20349 net.cpp:454] relu6 <- ip2
I0525 06:53:48.304985 20349 net.cpp:397] relu6 -> ip2 (in-place)
I0525 06:53:48.305521 20349 net.cpp:150] Setting up relu6
I0525 06:53:48.305537 20349 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:53:48.305547 20349 net.cpp:165] Memory required for data: 142047720
I0525 06:53:48.305558 20349 layer_factory.hpp:77] Creating layer drop2
I0525 06:53:48.305572 20349 net.cpp:106] Creating Layer drop2
I0525 06:53:48.305582 20349 net.cpp:454] drop2 <- ip2
I0525 06:53:48.305594 20349 net.cpp:397] drop2 -> ip2 (in-place)
I0525 06:53:48.305637 20349 net.cpp:150] Setting up drop2
I0525 06:53:48.305651 20349 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:53:48.305660 20349 net.cpp:165] Memory required for data: 142083000
I0525 06:53:48.305670 20349 layer_factory.hpp:77] Creating layer ip3
I0525 06:53:48.305685 20349 net.cpp:106] Creating Layer ip3
I0525 06:53:48.305694 20349 net.cpp:454] ip3 <- ip2
I0525 06:53:48.305708 20349 net.cpp:411] ip3 -> ip3
I0525 06:53:48.305932 20349 net.cpp:150] Setting up ip3
I0525 06:53:48.305944 20349 net.cpp:157] Top shape: 90 11 (990)
I0525 06:53:48.305954 20349 net.cpp:165] Memory required for data: 142086960
I0525 06:53:48.305970 20349 layer_factory.hpp:77] Creating layer drop3
I0525 06:53:48.305984 20349 net.cpp:106] Creating Layer drop3
I0525 06:53:48.305994 20349 net.cpp:454] drop3 <- ip3
I0525 06:53:48.306006 20349 net.cpp:397] drop3 -> ip3 (in-place)
I0525 06:53:48.306047 20349 net.cpp:150] Setting up drop3
I0525 06:53:48.306061 20349 net.cpp:157] Top shape: 90 11 (990)
I0525 06:53:48.306071 20349 net.cpp:165] Memory required for data: 142090920
I0525 06:53:48.306080 20349 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 06:53:48.306092 20349 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 06:53:48.306102 20349 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 06:53:48.306115 20349 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 06:53:48.306130 20349 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 06:53:48.306205 20349 net.cpp:150] Setting up ip3_drop3_0_split
I0525 06:53:48.306217 20349 net.cpp:157] Top shape: 90 11 (990)
I0525 06:53:48.306229 20349 net.cpp:157] Top shape: 90 11 (990)
I0525 06:53:48.306241 20349 net.cpp:165] Memory required for data: 142098840
I0525 06:53:48.306251 20349 layer_factory.hpp:77] Creating layer accuracy
I0525 06:53:48.306270 20349 net.cpp:106] Creating Layer accuracy
I0525 06:53:48.306282 20349 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 06:53:48.306293 20349 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 06:53:48.306305 20349 net.cpp:411] accuracy -> accuracy
I0525 06:53:48.306329 20349 net.cpp:150] Setting up accuracy
I0525 06:53:48.306340 20349 net.cpp:157] Top shape: (1)
I0525 06:53:48.306350 20349 net.cpp:165] Memory required for data: 142098844
I0525 06:53:48.306360 20349 layer_factory.hpp:77] Creating layer loss
I0525 06:53:48.306375 20349 net.cpp:106] Creating Layer loss
I0525 06:53:48.306385 20349 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 06:53:48.306396 20349 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 06:53:48.306409 20349 net.cpp:411] loss -> loss
I0525 06:53:48.306427 20349 layer_factory.hpp:77] Creating layer loss
I0525 06:53:48.306916 20349 net.cpp:150] Setting up loss
I0525 06:53:48.306931 20349 net.cpp:157] Top shape: (1)
I0525 06:53:48.306939 20349 net.cpp:160]     with loss weight 1
I0525 06:53:48.306957 20349 net.cpp:165] Memory required for data: 142098848
I0525 06:53:48.306967 20349 net.cpp:226] loss needs backward computation.
I0525 06:53:48.306979 20349 net.cpp:228] accuracy does not need backward computation.
I0525 06:53:48.306990 20349 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 06:53:48.307000 20349 net.cpp:226] drop3 needs backward computation.
I0525 06:53:48.307009 20349 net.cpp:226] ip3 needs backward computation.
I0525 06:53:48.307020 20349 net.cpp:226] drop2 needs backward computation.
I0525 06:53:48.307029 20349 net.cpp:226] relu6 needs backward computation.
I0525 06:53:48.307047 20349 net.cpp:226] ip2 needs backward computation.
I0525 06:53:48.307059 20349 net.cpp:226] drop1 needs backward computation.
I0525 06:53:48.307067 20349 net.cpp:226] relu5 needs backward computation.
I0525 06:53:48.307077 20349 net.cpp:226] ip1 needs backward computation.
I0525 06:53:48.307087 20349 net.cpp:226] pool4 needs backward computation.
I0525 06:53:48.307097 20349 net.cpp:226] relu4 needs backward computation.
I0525 06:53:48.307107 20349 net.cpp:226] conv4 needs backward computation.
I0525 06:53:48.307118 20349 net.cpp:226] pool3 needs backward computation.
I0525 06:53:48.307128 20349 net.cpp:226] relu3 needs backward computation.
I0525 06:53:48.307138 20349 net.cpp:226] conv3 needs backward computation.
I0525 06:53:48.307148 20349 net.cpp:226] pool2 needs backward computation.
I0525 06:53:48.307158 20349 net.cpp:226] relu2 needs backward computation.
I0525 06:53:48.307168 20349 net.cpp:226] conv2 needs backward computation.
I0525 06:53:48.307179 20349 net.cpp:226] pool1 needs backward computation.
I0525 06:53:48.307189 20349 net.cpp:226] relu1 needs backward computation.
I0525 06:53:48.307199 20349 net.cpp:226] conv1 needs backward computation.
I0525 06:53:48.307210 20349 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 06:53:48.307221 20349 net.cpp:228] data_hdf5 does not need backward computation.
I0525 06:53:48.307232 20349 net.cpp:270] This network produces output accuracy
I0525 06:53:48.307242 20349 net.cpp:270] This network produces output loss
I0525 06:53:48.307271 20349 net.cpp:283] Network initialization done.
I0525 06:53:48.307404 20349 solver.cpp:60] Solver scaffolding done.
I0525 06:53:48.308539 20349 caffe.cpp:212] Starting Optimization
I0525 06:53:48.308558 20349 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 06:53:48.308571 20349 solver.cpp:289] Learning Rate Policy: fixed
I0525 06:53:48.309646 20349 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 06:54:36.416723 20349 solver.cpp:409]     Test net output #0: accuracy = 0.0881819
I0525 06:54:36.416880 20349 solver.cpp:409]     Test net output #1: loss = 2.39976 (* 1 = 2.39976 loss)
I0525 06:54:36.448179 20349 solver.cpp:237] Iteration 0, loss = 2.40353
I0525 06:54:36.448215 20349 solver.cpp:253]     Train net output #0: loss = 2.40353 (* 1 = 2.40353 loss)
I0525 06:54:36.448233 20349 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0525 06:54:45.268613 20349 solver.cpp:237] Iteration 166, loss = 2.29961
I0525 06:54:45.268648 20349 solver.cpp:253]     Train net output #0: loss = 2.29961 (* 1 = 2.29961 loss)
I0525 06:54:45.268667 20349 sgd_solver.cpp:106] Iteration 166, lr = 0.0025
I0525 06:54:54.098059 20349 solver.cpp:237] Iteration 332, loss = 2.23363
I0525 06:54:54.098095 20349 solver.cpp:253]     Train net output #0: loss = 2.23363 (* 1 = 2.23363 loss)
I0525 06:54:54.098109 20349 sgd_solver.cpp:106] Iteration 332, lr = 0.0025
I0525 06:55:02.926009 20349 solver.cpp:237] Iteration 498, loss = 2.01896
I0525 06:55:02.926048 20349 solver.cpp:253]     Train net output #0: loss = 2.01896 (* 1 = 2.01896 loss)
I0525 06:55:02.926067 20349 sgd_solver.cpp:106] Iteration 498, lr = 0.0025
I0525 06:55:11.746095 20349 solver.cpp:237] Iteration 664, loss = 2.03192
I0525 06:55:11.746242 20349 solver.cpp:253]     Train net output #0: loss = 2.03192 (* 1 = 2.03192 loss)
I0525 06:55:11.746256 20349 sgd_solver.cpp:106] Iteration 664, lr = 0.0025
I0525 06:55:20.581377 20349 solver.cpp:237] Iteration 830, loss = 1.99643
I0525 06:55:20.581418 20349 solver.cpp:253]     Train net output #0: loss = 1.99643 (* 1 = 1.99643 loss)
I0525 06:55:20.581431 20349 sgd_solver.cpp:106] Iteration 830, lr = 0.0025
I0525 06:55:29.410414 20349 solver.cpp:237] Iteration 996, loss = 1.89871
I0525 06:55:29.410455 20349 solver.cpp:253]     Train net output #0: loss = 1.89871 (* 1 = 1.89871 loss)
I0525 06:55:29.410475 20349 sgd_solver.cpp:106] Iteration 996, lr = 0.0025
I0525 06:56:00.428272 20349 solver.cpp:237] Iteration 1162, loss = 1.73825
I0525 06:56:00.428442 20349 solver.cpp:253]     Train net output #0: loss = 1.73825 (* 1 = 1.73825 loss)
I0525 06:56:00.428457 20349 sgd_solver.cpp:106] Iteration 1162, lr = 0.0025
I0525 06:56:09.263192 20349 solver.cpp:237] Iteration 1328, loss = 1.78212
I0525 06:56:09.263226 20349 solver.cpp:253]     Train net output #0: loss = 1.78212 (* 1 = 1.78212 loss)
I0525 06:56:09.263242 20349 sgd_solver.cpp:106] Iteration 1328, lr = 0.0025
I0525 06:56:18.107013 20349 solver.cpp:237] Iteration 1494, loss = 1.71202
I0525 06:56:18.107054 20349 solver.cpp:253]     Train net output #0: loss = 1.71202 (* 1 = 1.71202 loss)
I0525 06:56:18.107075 20349 sgd_solver.cpp:106] Iteration 1494, lr = 0.0025
I0525 06:56:26.934185 20349 solver.cpp:237] Iteration 1660, loss = 1.66337
I0525 06:56:26.934221 20349 solver.cpp:253]     Train net output #0: loss = 1.66337 (* 1 = 1.66337 loss)
I0525 06:56:26.934237 20349 sgd_solver.cpp:106] Iteration 1660, lr = 0.0025
I0525 06:56:27.199964 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_1666.caffemodel
I0525 06:56:27.278257 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_1666.solverstate
I0525 06:56:35.832016 20349 solver.cpp:237] Iteration 1826, loss = 1.61811
I0525 06:56:35.832180 20349 solver.cpp:253]     Train net output #0: loss = 1.61811 (* 1 = 1.61811 loss)
I0525 06:56:35.832195 20349 sgd_solver.cpp:106] Iteration 1826, lr = 0.0025
I0525 06:56:44.668313 20349 solver.cpp:237] Iteration 1992, loss = 1.75386
I0525 06:56:44.668357 20349 solver.cpp:253]     Train net output #0: loss = 1.75386 (* 1 = 1.75386 loss)
I0525 06:56:44.668375 20349 sgd_solver.cpp:106] Iteration 1992, lr = 0.0025
I0525 06:56:53.497207 20349 solver.cpp:237] Iteration 2158, loss = 1.60504
I0525 06:56:53.497242 20349 solver.cpp:253]     Train net output #0: loss = 1.60504 (* 1 = 1.60504 loss)
I0525 06:56:53.497256 20349 sgd_solver.cpp:106] Iteration 2158, lr = 0.0025
I0525 06:57:24.507879 20349 solver.cpp:237] Iteration 2324, loss = 1.56563
I0525 06:57:24.508035 20349 solver.cpp:253]     Train net output #0: loss = 1.56563 (* 1 = 1.56563 loss)
I0525 06:57:24.508050 20349 sgd_solver.cpp:106] Iteration 2324, lr = 0.0025
I0525 06:57:33.340966 20349 solver.cpp:237] Iteration 2490, loss = 1.66466
I0525 06:57:33.341012 20349 solver.cpp:253]     Train net output #0: loss = 1.66466 (* 1 = 1.66466 loss)
I0525 06:57:33.341030 20349 sgd_solver.cpp:106] Iteration 2490, lr = 0.0025
I0525 06:57:42.178977 20349 solver.cpp:237] Iteration 2656, loss = 1.56359
I0525 06:57:42.179013 20349 solver.cpp:253]     Train net output #0: loss = 1.56359 (* 1 = 1.56359 loss)
I0525 06:57:42.179029 20349 sgd_solver.cpp:106] Iteration 2656, lr = 0.0025
I0525 06:57:51.018158 20349 solver.cpp:237] Iteration 2822, loss = 1.48495
I0525 06:57:51.018193 20349 solver.cpp:253]     Train net output #0: loss = 1.48495 (* 1 = 1.48495 loss)
I0525 06:57:51.018210 20349 sgd_solver.cpp:106] Iteration 2822, lr = 0.0025
I0525 06:57:59.857291 20349 solver.cpp:237] Iteration 2988, loss = 1.62007
I0525 06:57:59.857463 20349 solver.cpp:253]     Train net output #0: loss = 1.62007 (* 1 = 1.62007 loss)
I0525 06:57:59.857478 20349 sgd_solver.cpp:106] Iteration 2988, lr = 0.0025
I0525 06:58:08.689996 20349 solver.cpp:237] Iteration 3154, loss = 1.46984
I0525 06:58:08.690032 20349 solver.cpp:253]     Train net output #0: loss = 1.46984 (* 1 = 1.46984 loss)
I0525 06:58:08.690048 20349 sgd_solver.cpp:106] Iteration 3154, lr = 0.0025
I0525 06:58:17.523131 20349 solver.cpp:237] Iteration 3320, loss = 1.52315
I0525 06:58:17.523169 20349 solver.cpp:253]     Train net output #0: loss = 1.52315 (* 1 = 1.52315 loss)
I0525 06:58:17.523190 20349 sgd_solver.cpp:106] Iteration 3320, lr = 0.0025
I0525 06:58:18.108656 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_3332.caffemodel
I0525 06:58:18.183132 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_3332.solverstate
I0525 06:58:18.225260 20349 solver.cpp:341] Iteration 3333, Testing net (#0)
I0525 06:59:05.338775 20349 solver.cpp:409]     Test net output #0: accuracy = 0.741283
I0525 06:59:05.338949 20349 solver.cpp:409]     Test net output #1: loss = 0.879049 (* 1 = 0.879049 loss)
I0525 06:59:35.706311 20349 solver.cpp:237] Iteration 3486, loss = 1.56482
I0525 06:59:35.706467 20349 solver.cpp:253]     Train net output #0: loss = 1.56482 (* 1 = 1.56482 loss)
I0525 06:59:35.706483 20349 sgd_solver.cpp:106] Iteration 3486, lr = 0.0025
I0525 06:59:44.527479 20349 solver.cpp:237] Iteration 3652, loss = 1.60561
I0525 06:59:44.527514 20349 solver.cpp:253]     Train net output #0: loss = 1.60561 (* 1 = 1.60561 loss)
I0525 06:59:44.527531 20349 sgd_solver.cpp:106] Iteration 3652, lr = 0.0025
I0525 06:59:53.357486 20349 solver.cpp:237] Iteration 3818, loss = 1.36576
I0525 06:59:53.357522 20349 solver.cpp:253]     Train net output #0: loss = 1.36576 (* 1 = 1.36576 loss)
I0525 06:59:53.357538 20349 sgd_solver.cpp:106] Iteration 3818, lr = 0.0025
I0525 07:00:02.175390 20349 solver.cpp:237] Iteration 3984, loss = 1.56684
I0525 07:00:02.175437 20349 solver.cpp:253]     Train net output #0: loss = 1.56684 (* 1 = 1.56684 loss)
I0525 07:00:02.175453 20349 sgd_solver.cpp:106] Iteration 3984, lr = 0.0025
I0525 07:00:10.999689 20349 solver.cpp:237] Iteration 4150, loss = 1.45745
I0525 07:00:10.999828 20349 solver.cpp:253]     Train net output #0: loss = 1.45745 (* 1 = 1.45745 loss)
I0525 07:00:10.999841 20349 sgd_solver.cpp:106] Iteration 4150, lr = 0.0025
I0525 07:00:19.816774 20349 solver.cpp:237] Iteration 4316, loss = 1.46041
I0525 07:00:19.816808 20349 solver.cpp:253]     Train net output #0: loss = 1.46041 (* 1 = 1.46041 loss)
I0525 07:00:19.816825 20349 sgd_solver.cpp:106] Iteration 4316, lr = 0.0025
I0525 07:00:50.768085 20349 solver.cpp:237] Iteration 4482, loss = 1.5316
I0525 07:00:50.768249 20349 solver.cpp:253]     Train net output #0: loss = 1.5316 (* 1 = 1.5316 loss)
I0525 07:00:50.768265 20349 sgd_solver.cpp:106] Iteration 4482, lr = 0.0025
I0525 07:00:59.587123 20349 solver.cpp:237] Iteration 4648, loss = 1.2469
I0525 07:00:59.587157 20349 solver.cpp:253]     Train net output #0: loss = 1.2469 (* 1 = 1.2469 loss)
I0525 07:00:59.587173 20349 sgd_solver.cpp:106] Iteration 4648, lr = 0.0025
I0525 07:01:08.406149 20349 solver.cpp:237] Iteration 4814, loss = 1.3941
I0525 07:01:08.406185 20349 solver.cpp:253]     Train net output #0: loss = 1.3941 (* 1 = 1.3941 loss)
I0525 07:01:08.406198 20349 sgd_solver.cpp:106] Iteration 4814, lr = 0.0025
I0525 07:01:17.228464 20349 solver.cpp:237] Iteration 4980, loss = 1.3904
I0525 07:01:17.228510 20349 solver.cpp:253]     Train net output #0: loss = 1.3904 (* 1 = 1.3904 loss)
I0525 07:01:17.228528 20349 sgd_solver.cpp:106] Iteration 4980, lr = 0.0025
I0525 07:01:18.134455 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_4998.caffemodel
I0525 07:01:18.213488 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_4998.solverstate
I0525 07:01:26.119220 20349 solver.cpp:237] Iteration 5146, loss = 1.43549
I0525 07:01:26.119388 20349 solver.cpp:253]     Train net output #0: loss = 1.43549 (* 1 = 1.43549 loss)
I0525 07:01:26.119402 20349 sgd_solver.cpp:106] Iteration 5146, lr = 0.0025
I0525 07:01:34.941237 20349 solver.cpp:237] Iteration 5312, loss = 1.57161
I0525 07:01:34.941272 20349 solver.cpp:253]     Train net output #0: loss = 1.57161 (* 1 = 1.57161 loss)
I0525 07:01:34.941288 20349 sgd_solver.cpp:106] Iteration 5312, lr = 0.0025
I0525 07:01:43.756952 20349 solver.cpp:237] Iteration 5478, loss = 1.37999
I0525 07:01:43.756995 20349 solver.cpp:253]     Train net output #0: loss = 1.37999 (* 1 = 1.37999 loss)
I0525 07:01:43.757014 20349 sgd_solver.cpp:106] Iteration 5478, lr = 0.0025
I0525 07:02:14.789227 20349 solver.cpp:237] Iteration 5644, loss = 1.5114
I0525 07:02:14.789392 20349 solver.cpp:253]     Train net output #0: loss = 1.5114 (* 1 = 1.5114 loss)
I0525 07:02:14.789414 20349 sgd_solver.cpp:106] Iteration 5644, lr = 0.0025
I0525 07:02:23.602794 20349 solver.cpp:237] Iteration 5810, loss = 1.36943
I0525 07:02:23.602828 20349 solver.cpp:253]     Train net output #0: loss = 1.36943 (* 1 = 1.36943 loss)
I0525 07:02:23.602844 20349 sgd_solver.cpp:106] Iteration 5810, lr = 0.0025
I0525 07:02:32.428155 20349 solver.cpp:237] Iteration 5976, loss = 1.41493
I0525 07:02:32.428195 20349 solver.cpp:253]     Train net output #0: loss = 1.41493 (* 1 = 1.41493 loss)
I0525 07:02:32.428217 20349 sgd_solver.cpp:106] Iteration 5976, lr = 0.0025
I0525 07:02:41.246914 20349 solver.cpp:237] Iteration 6142, loss = 1.52016
I0525 07:02:41.246948 20349 solver.cpp:253]     Train net output #0: loss = 1.52016 (* 1 = 1.52016 loss)
I0525 07:02:41.246965 20349 sgd_solver.cpp:106] Iteration 6142, lr = 0.0025
I0525 07:02:50.069442 20349 solver.cpp:237] Iteration 6308, loss = 1.50663
I0525 07:02:50.069583 20349 solver.cpp:253]     Train net output #0: loss = 1.50663 (* 1 = 1.50663 loss)
I0525 07:02:50.069597 20349 sgd_solver.cpp:106] Iteration 6308, lr = 0.0025
I0525 07:02:58.887375 20349 solver.cpp:237] Iteration 6474, loss = 1.46456
I0525 07:02:58.887420 20349 solver.cpp:253]     Train net output #0: loss = 1.46456 (* 1 = 1.46456 loss)
I0525 07:02:58.887439 20349 sgd_solver.cpp:106] Iteration 6474, lr = 0.0025
I0525 07:03:07.708868 20349 solver.cpp:237] Iteration 6640, loss = 1.27144
I0525 07:03:07.708902 20349 solver.cpp:253]     Train net output #0: loss = 1.27144 (* 1 = 1.27144 loss)
I0525 07:03:07.708919 20349 sgd_solver.cpp:106] Iteration 6640, lr = 0.0025
I0525 07:03:08.932956 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_6664.caffemodel
I0525 07:03:09.009577 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_6664.solverstate
I0525 07:03:09.107309 20349 solver.cpp:341] Iteration 6666, Testing net (#0)
I0525 07:04:17.155655 20349 solver.cpp:409]     Test net output #0: accuracy = 0.808501
I0525 07:04:17.155823 20349 solver.cpp:409]     Test net output #1: loss = 0.672171 (* 1 = 0.672171 loss)
I0525 07:04:46.769018 20349 solver.cpp:237] Iteration 6806, loss = 1.37166
I0525 07:04:46.769069 20349 solver.cpp:253]     Train net output #0: loss = 1.37166 (* 1 = 1.37166 loss)
I0525 07:04:46.769084 20349 sgd_solver.cpp:106] Iteration 6806, lr = 0.0025
I0525 07:04:55.600585 20349 solver.cpp:237] Iteration 6972, loss = 1.45769
I0525 07:04:55.600729 20349 solver.cpp:253]     Train net output #0: loss = 1.45769 (* 1 = 1.45769 loss)
I0525 07:04:55.600744 20349 sgd_solver.cpp:106] Iteration 6972, lr = 0.0025
I0525 07:05:04.425218 20349 solver.cpp:237] Iteration 7138, loss = 1.13678
I0525 07:05:04.425249 20349 solver.cpp:253]     Train net output #0: loss = 1.13678 (* 1 = 1.13678 loss)
I0525 07:05:04.425273 20349 sgd_solver.cpp:106] Iteration 7138, lr = 0.0025
I0525 07:05:13.248883 20349 solver.cpp:237] Iteration 7304, loss = 1.23647
I0525 07:05:13.248917 20349 solver.cpp:253]     Train net output #0: loss = 1.23647 (* 1 = 1.23647 loss)
I0525 07:05:13.248934 20349 sgd_solver.cpp:106] Iteration 7304, lr = 0.0025
I0525 07:05:22.081439 20349 solver.cpp:237] Iteration 7470, loss = 1.30096
I0525 07:05:22.081477 20349 solver.cpp:253]     Train net output #0: loss = 1.30096 (* 1 = 1.30096 loss)
I0525 07:05:22.081496 20349 sgd_solver.cpp:106] Iteration 7470, lr = 0.0025
I0525 07:05:30.903218 20349 solver.cpp:237] Iteration 7636, loss = 1.19616
I0525 07:05:30.903364 20349 solver.cpp:253]     Train net output #0: loss = 1.19616 (* 1 = 1.19616 loss)
I0525 07:05:30.903379 20349 sgd_solver.cpp:106] Iteration 7636, lr = 0.0025
I0525 07:06:01.906759 20349 solver.cpp:237] Iteration 7802, loss = 1.39371
I0525 07:06:01.906924 20349 solver.cpp:253]     Train net output #0: loss = 1.39371 (* 1 = 1.39371 loss)
I0525 07:06:01.906940 20349 sgd_solver.cpp:106] Iteration 7802, lr = 0.0025
I0525 07:06:10.732792 20349 solver.cpp:237] Iteration 7968, loss = 1.22676
I0525 07:06:10.732827 20349 solver.cpp:253]     Train net output #0: loss = 1.22676 (* 1 = 1.22676 loss)
I0525 07:06:10.732844 20349 sgd_solver.cpp:106] Iteration 7968, lr = 0.0025
I0525 07:06:19.557423 20349 solver.cpp:237] Iteration 8134, loss = 1.45393
I0525 07:06:19.557456 20349 solver.cpp:253]     Train net output #0: loss = 1.45393 (* 1 = 1.45393 loss)
I0525 07:06:19.557474 20349 sgd_solver.cpp:106] Iteration 8134, lr = 0.0025
I0525 07:06:28.393044 20349 solver.cpp:237] Iteration 8300, loss = 1.25193
I0525 07:06:28.393080 20349 solver.cpp:253]     Train net output #0: loss = 1.25193 (* 1 = 1.25193 loss)
I0525 07:06:28.393097 20349 sgd_solver.cpp:106] Iteration 8300, lr = 0.0025
I0525 07:06:29.931772 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_8330.caffemodel
I0525 07:06:30.009377 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_8330.solverstate
I0525 07:06:37.276747 20349 solver.cpp:237] Iteration 8466, loss = 1.43417
I0525 07:06:37.276911 20349 solver.cpp:253]     Train net output #0: loss = 1.43417 (* 1 = 1.43417 loss)
I0525 07:06:37.276927 20349 sgd_solver.cpp:106] Iteration 8466, lr = 0.0025
I0525 07:06:46.100746 20349 solver.cpp:237] Iteration 8632, loss = 1.37386
I0525 07:06:46.100782 20349 solver.cpp:253]     Train net output #0: loss = 1.37386 (* 1 = 1.37386 loss)
I0525 07:06:46.100800 20349 sgd_solver.cpp:106] Iteration 8632, lr = 0.0025
I0525 07:06:54.922369 20349 solver.cpp:237] Iteration 8798, loss = 1.27103
I0525 07:06:54.922406 20349 solver.cpp:253]     Train net output #0: loss = 1.27103 (* 1 = 1.27103 loss)
I0525 07:06:54.922421 20349 sgd_solver.cpp:106] Iteration 8798, lr = 0.0025
I0525 07:07:25.899250 20349 solver.cpp:237] Iteration 8964, loss = 1.40939
I0525 07:07:25.899425 20349 solver.cpp:253]     Train net output #0: loss = 1.40939 (* 1 = 1.40939 loss)
I0525 07:07:25.899440 20349 sgd_solver.cpp:106] Iteration 8964, lr = 0.0025
I0525 07:07:34.726181 20349 solver.cpp:237] Iteration 9130, loss = 1.51973
I0525 07:07:34.726213 20349 solver.cpp:253]     Train net output #0: loss = 1.51973 (* 1 = 1.51973 loss)
I0525 07:07:34.726238 20349 sgd_solver.cpp:106] Iteration 9130, lr = 0.0025
I0525 07:07:43.553267 20349 solver.cpp:237] Iteration 9296, loss = 1.20741
I0525 07:07:43.553303 20349 solver.cpp:253]     Train net output #0: loss = 1.20741 (* 1 = 1.20741 loss)
I0525 07:07:43.553318 20349 sgd_solver.cpp:106] Iteration 9296, lr = 0.0025
I0525 07:07:52.380313 20349 solver.cpp:237] Iteration 9462, loss = 1.27436
I0525 07:07:52.380360 20349 solver.cpp:253]     Train net output #0: loss = 1.27436 (* 1 = 1.27436 loss)
I0525 07:07:52.380378 20349 sgd_solver.cpp:106] Iteration 9462, lr = 0.0025
I0525 07:08:01.204362 20349 solver.cpp:237] Iteration 9628, loss = 1.1391
I0525 07:08:01.204502 20349 solver.cpp:253]     Train net output #0: loss = 1.1391 (* 1 = 1.1391 loss)
I0525 07:08:01.204516 20349 sgd_solver.cpp:106] Iteration 9628, lr = 0.0025
I0525 07:08:10.021036 20349 solver.cpp:237] Iteration 9794, loss = 1.42789
I0525 07:08:10.021070 20349 solver.cpp:253]     Train net output #0: loss = 1.42789 (* 1 = 1.42789 loss)
I0525 07:08:10.021088 20349 sgd_solver.cpp:106] Iteration 9794, lr = 0.0025
I0525 07:08:18.847131 20349 solver.cpp:237] Iteration 9960, loss = 1.20897
I0525 07:08:18.847173 20349 solver.cpp:253]     Train net output #0: loss = 1.20897 (* 1 = 1.20897 loss)
I0525 07:08:18.847189 20349 sgd_solver.cpp:106] Iteration 9960, lr = 0.0025
I0525 07:08:20.707386 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_9996.caffemodel
I0525 07:08:20.781699 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_9996.solverstate
I0525 07:08:20.929338 20349 solver.cpp:341] Iteration 9999, Testing net (#0)
I0525 07:09:07.723229 20349 solver.cpp:409]     Test net output #0: accuracy = 0.823922
I0525 07:09:07.723389 20349 solver.cpp:409]     Test net output #1: loss = 0.584096 (* 1 = 0.584096 loss)
I0525 07:09:36.626962 20349 solver.cpp:237] Iteration 10126, loss = 1.24173
I0525 07:09:36.627012 20349 solver.cpp:253]     Train net output #0: loss = 1.24173 (* 1 = 1.24173 loss)
I0525 07:09:36.627027 20349 sgd_solver.cpp:106] Iteration 10126, lr = 0.0025
I0525 07:09:45.449669 20349 solver.cpp:237] Iteration 10292, loss = 1.42796
I0525 07:09:45.449820 20349 solver.cpp:253]     Train net output #0: loss = 1.42796 (* 1 = 1.42796 loss)
I0525 07:09:45.449832 20349 sgd_solver.cpp:106] Iteration 10292, lr = 0.0025
I0525 07:09:54.269794 20349 solver.cpp:237] Iteration 10458, loss = 1.24021
I0525 07:09:54.269827 20349 solver.cpp:253]     Train net output #0: loss = 1.24021 (* 1 = 1.24021 loss)
I0525 07:09:54.269845 20349 sgd_solver.cpp:106] Iteration 10458, lr = 0.0025
I0525 07:10:03.094699 20349 solver.cpp:237] Iteration 10624, loss = 1.26249
I0525 07:10:03.094738 20349 solver.cpp:253]     Train net output #0: loss = 1.26249 (* 1 = 1.26249 loss)
I0525 07:10:03.094756 20349 sgd_solver.cpp:106] Iteration 10624, lr = 0.0025
I0525 07:10:11.918162 20349 solver.cpp:237] Iteration 10790, loss = 1.24026
I0525 07:10:11.918197 20349 solver.cpp:253]     Train net output #0: loss = 1.24026 (* 1 = 1.24026 loss)
I0525 07:10:11.918212 20349 sgd_solver.cpp:106] Iteration 10790, lr = 0.0025
I0525 07:10:20.743695 20349 solver.cpp:237] Iteration 10956, loss = 1.25246
I0525 07:10:20.743832 20349 solver.cpp:253]     Train net output #0: loss = 1.25246 (* 1 = 1.25246 loss)
I0525 07:10:20.743846 20349 sgd_solver.cpp:106] Iteration 10956, lr = 0.0025
I0525 07:10:51.706758 20349 solver.cpp:237] Iteration 11122, loss = 1.19106
I0525 07:10:51.706930 20349 solver.cpp:253]     Train net output #0: loss = 1.19106 (* 1 = 1.19106 loss)
I0525 07:10:51.706946 20349 sgd_solver.cpp:106] Iteration 11122, lr = 0.0025
I0525 07:11:00.521085 20349 solver.cpp:237] Iteration 11288, loss = 1.19422
I0525 07:11:00.521121 20349 solver.cpp:253]     Train net output #0: loss = 1.19422 (* 1 = 1.19422 loss)
I0525 07:11:00.521134 20349 sgd_solver.cpp:106] Iteration 11288, lr = 0.0025
I0525 07:11:09.345860 20349 solver.cpp:237] Iteration 11454, loss = 1.29996
I0525 07:11:09.345896 20349 solver.cpp:253]     Train net output #0: loss = 1.29996 (* 1 = 1.29996 loss)
I0525 07:11:09.345914 20349 sgd_solver.cpp:106] Iteration 11454, lr = 0.0025
I0525 07:11:18.170588 20349 solver.cpp:237] Iteration 11620, loss = 1.17557
I0525 07:11:18.170629 20349 solver.cpp:253]     Train net output #0: loss = 1.17557 (* 1 = 1.17557 loss)
I0525 07:11:18.170650 20349 sgd_solver.cpp:106] Iteration 11620, lr = 0.0025
I0525 07:11:20.347095 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_11662.caffemodel
I0525 07:11:20.421639 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_11662.solverstate
I0525 07:11:27.050345 20349 solver.cpp:237] Iteration 11786, loss = 1.34605
I0525 07:11:27.050503 20349 solver.cpp:253]     Train net output #0: loss = 1.34605 (* 1 = 1.34605 loss)
I0525 07:11:27.050516 20349 sgd_solver.cpp:106] Iteration 11786, lr = 0.0025
I0525 07:11:35.868358 20349 solver.cpp:237] Iteration 11952, loss = 1.39329
I0525 07:11:35.868393 20349 solver.cpp:253]     Train net output #0: loss = 1.39329 (* 1 = 1.39329 loss)
I0525 07:11:35.868407 20349 sgd_solver.cpp:106] Iteration 11952, lr = 0.0025
I0525 07:11:44.690629 20349 solver.cpp:237] Iteration 12118, loss = 1.34831
I0525 07:11:44.690661 20349 solver.cpp:253]     Train net output #0: loss = 1.34831 (* 1 = 1.34831 loss)
I0525 07:11:44.690683 20349 sgd_solver.cpp:106] Iteration 12118, lr = 0.0025
I0525 07:12:15.680377 20349 solver.cpp:237] Iteration 12284, loss = 1.27885
I0525 07:12:15.680539 20349 solver.cpp:253]     Train net output #0: loss = 1.27885 (* 1 = 1.27885 loss)
I0525 07:12:15.680555 20349 sgd_solver.cpp:106] Iteration 12284, lr = 0.0025
I0525 07:12:24.509886 20349 solver.cpp:237] Iteration 12450, loss = 1.44232
I0525 07:12:24.509922 20349 solver.cpp:253]     Train net output #0: loss = 1.44232 (* 1 = 1.44232 loss)
I0525 07:12:24.509938 20349 sgd_solver.cpp:106] Iteration 12450, lr = 0.0025
I0525 07:12:33.332733 20349 solver.cpp:237] Iteration 12616, loss = 1.39765
I0525 07:12:33.332768 20349 solver.cpp:253]     Train net output #0: loss = 1.39765 (* 1 = 1.39765 loss)
I0525 07:12:33.332789 20349 sgd_solver.cpp:106] Iteration 12616, lr = 0.0025
I0525 07:12:42.152338 20349 solver.cpp:237] Iteration 12782, loss = 1.45683
I0525 07:12:42.152374 20349 solver.cpp:253]     Train net output #0: loss = 1.45683 (* 1 = 1.45683 loss)
I0525 07:12:42.152389 20349 sgd_solver.cpp:106] Iteration 12782, lr = 0.0025
I0525 07:12:50.966881 20349 solver.cpp:237] Iteration 12948, loss = 1.34388
I0525 07:12:50.967023 20349 solver.cpp:253]     Train net output #0: loss = 1.34388 (* 1 = 1.34388 loss)
I0525 07:12:50.967039 20349 sgd_solver.cpp:106] Iteration 12948, lr = 0.0025
I0525 07:12:59.784653 20349 solver.cpp:237] Iteration 13114, loss = 1.49639
I0525 07:12:59.784684 20349 solver.cpp:253]     Train net output #0: loss = 1.49639 (* 1 = 1.49639 loss)
I0525 07:12:59.784705 20349 sgd_solver.cpp:106] Iteration 13114, lr = 0.0025
I0525 07:13:08.602650 20349 solver.cpp:237] Iteration 13280, loss = 1.17608
I0525 07:13:08.602685 20349 solver.cpp:253]     Train net output #0: loss = 1.17608 (* 1 = 1.17608 loss)
I0525 07:13:08.602700 20349 sgd_solver.cpp:106] Iteration 13280, lr = 0.0025
I0525 07:13:11.097856 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_13328.caffemodel
I0525 07:13:11.172338 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_13328.solverstate
I0525 07:13:11.374707 20349 solver.cpp:341] Iteration 13332, Testing net (#0)
I0525 07:14:19.402259 20349 solver.cpp:409]     Test net output #0: accuracy = 0.845839
I0525 07:14:19.402427 20349 solver.cpp:409]     Test net output #1: loss = 0.515111 (* 1 = 0.515111 loss)
I0525 07:14:47.649308 20349 solver.cpp:237] Iteration 13446, loss = 1.3565
I0525 07:14:47.649358 20349 solver.cpp:253]     Train net output #0: loss = 1.3565 (* 1 = 1.3565 loss)
I0525 07:14:47.649374 20349 sgd_solver.cpp:106] Iteration 13446, lr = 0.0025
I0525 07:14:56.487013 20349 solver.cpp:237] Iteration 13612, loss = 1.15901
I0525 07:14:56.487166 20349 solver.cpp:253]     Train net output #0: loss = 1.15901 (* 1 = 1.15901 loss)
I0525 07:14:56.487180 20349 sgd_solver.cpp:106] Iteration 13612, lr = 0.0025
I0525 07:15:05.316613 20349 solver.cpp:237] Iteration 13778, loss = 1.22093
I0525 07:15:05.316648 20349 solver.cpp:253]     Train net output #0: loss = 1.22093 (* 1 = 1.22093 loss)
I0525 07:15:05.316663 20349 sgd_solver.cpp:106] Iteration 13778, lr = 0.0025
I0525 07:15:14.157137 20349 solver.cpp:237] Iteration 13944, loss = 1.09047
I0525 07:15:14.157172 20349 solver.cpp:253]     Train net output #0: loss = 1.09047 (* 1 = 1.09047 loss)
I0525 07:15:14.157189 20349 sgd_solver.cpp:106] Iteration 13944, lr = 0.0025
I0525 07:15:22.996747 20349 solver.cpp:237] Iteration 14110, loss = 1.42489
I0525 07:15:22.996783 20349 solver.cpp:253]     Train net output #0: loss = 1.42489 (* 1 = 1.42489 loss)
I0525 07:15:22.996803 20349 sgd_solver.cpp:106] Iteration 14110, lr = 0.0025
I0525 07:15:31.832151 20349 solver.cpp:237] Iteration 14276, loss = 1.06096
I0525 07:15:31.832289 20349 solver.cpp:253]     Train net output #0: loss = 1.06096 (* 1 = 1.06096 loss)
I0525 07:15:31.832304 20349 sgd_solver.cpp:106] Iteration 14276, lr = 0.0025
I0525 07:15:40.667399 20349 solver.cpp:237] Iteration 14442, loss = 1.28591
I0525 07:15:40.667433 20349 solver.cpp:253]     Train net output #0: loss = 1.28591 (* 1 = 1.28591 loss)
I0525 07:15:40.667448 20349 sgd_solver.cpp:106] Iteration 14442, lr = 0.0025
I0525 07:16:11.690090 20349 solver.cpp:237] Iteration 14608, loss = 1.31619
I0525 07:16:11.690256 20349 solver.cpp:253]     Train net output #0: loss = 1.31619 (* 1 = 1.31619 loss)
I0525 07:16:11.690271 20349 sgd_solver.cpp:106] Iteration 14608, lr = 0.0025
I0525 07:16:20.511912 20349 solver.cpp:237] Iteration 14774, loss = 1.22176
I0525 07:16:20.511947 20349 solver.cpp:253]     Train net output #0: loss = 1.22176 (* 1 = 1.22176 loss)
I0525 07:16:20.511965 20349 sgd_solver.cpp:106] Iteration 14774, lr = 0.0025
I0525 07:16:29.348177 20349 solver.cpp:237] Iteration 14940, loss = 1.13905
I0525 07:16:29.348212 20349 solver.cpp:253]     Train net output #0: loss = 1.13905 (* 1 = 1.13905 loss)
I0525 07:16:29.348228 20349 sgd_solver.cpp:106] Iteration 14940, lr = 0.0025
I0525 07:16:32.169546 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_14994.caffemodel
I0525 07:16:32.245584 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_14994.solverstate
I0525 07:16:38.254132 20349 solver.cpp:237] Iteration 15106, loss = 1.31539
I0525 07:16:38.254181 20349 solver.cpp:253]     Train net output #0: loss = 1.31539 (* 1 = 1.31539 loss)
I0525 07:16:38.254199 20349 sgd_solver.cpp:106] Iteration 15106, lr = 0.0025
I0525 07:16:47.088558 20349 solver.cpp:237] Iteration 15272, loss = 1.36925
I0525 07:16:47.088704 20349 solver.cpp:253]     Train net output #0: loss = 1.36925 (* 1 = 1.36925 loss)
I0525 07:16:47.088721 20349 sgd_solver.cpp:106] Iteration 15272, lr = 0.0025
I0525 07:16:55.918629 20349 solver.cpp:237] Iteration 15438, loss = 1.35864
I0525 07:16:55.918663 20349 solver.cpp:253]     Train net output #0: loss = 1.35864 (* 1 = 1.35864 loss)
I0525 07:16:55.918680 20349 sgd_solver.cpp:106] Iteration 15438, lr = 0.0025
I0525 07:17:26.899065 20349 solver.cpp:237] Iteration 15604, loss = 1.34542
I0525 07:17:26.899243 20349 solver.cpp:253]     Train net output #0: loss = 1.34542 (* 1 = 1.34542 loss)
I0525 07:17:26.899258 20349 sgd_solver.cpp:106] Iteration 15604, lr = 0.0025
I0525 07:17:35.726713 20349 solver.cpp:237] Iteration 15770, loss = 1.165
I0525 07:17:35.726747 20349 solver.cpp:253]     Train net output #0: loss = 1.165 (* 1 = 1.165 loss)
I0525 07:17:35.726761 20349 sgd_solver.cpp:106] Iteration 15770, lr = 0.0025
I0525 07:17:44.564460 20349 solver.cpp:237] Iteration 15936, loss = 1.2938
I0525 07:17:44.564496 20349 solver.cpp:253]     Train net output #0: loss = 1.2938 (* 1 = 1.2938 loss)
I0525 07:17:44.564508 20349 sgd_solver.cpp:106] Iteration 15936, lr = 0.0025
I0525 07:17:53.404721 20349 solver.cpp:237] Iteration 16102, loss = 1.29727
I0525 07:17:53.404769 20349 solver.cpp:253]     Train net output #0: loss = 1.29727 (* 1 = 1.29727 loss)
I0525 07:17:53.404783 20349 sgd_solver.cpp:106] Iteration 16102, lr = 0.0025
I0525 07:18:02.246183 20349 solver.cpp:237] Iteration 16268, loss = 1.14061
I0525 07:18:02.246331 20349 solver.cpp:253]     Train net output #0: loss = 1.14061 (* 1 = 1.14061 loss)
I0525 07:18:02.246345 20349 sgd_solver.cpp:106] Iteration 16268, lr = 0.0025
I0525 07:18:11.082620 20349 solver.cpp:237] Iteration 16434, loss = 1.22406
I0525 07:18:11.082654 20349 solver.cpp:253]     Train net output #0: loss = 1.22406 (* 1 = 1.22406 loss)
I0525 07:18:11.082672 20349 sgd_solver.cpp:106] Iteration 16434, lr = 0.0025
I0525 07:18:19.919239 20349 solver.cpp:237] Iteration 16600, loss = 1.53335
I0525 07:18:19.919286 20349 solver.cpp:253]     Train net output #0: loss = 1.53335 (* 1 = 1.53335 loss)
I0525 07:18:19.919301 20349 sgd_solver.cpp:106] Iteration 16600, lr = 0.0025
I0525 07:18:23.055788 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_16660.caffemodel
I0525 07:18:23.131562 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_16660.solverstate
I0525 07:18:23.390564 20349 solver.cpp:341] Iteration 16665, Testing net (#0)
I0525 07:19:10.530220 20349 solver.cpp:409]     Test net output #0: accuracy = 0.853996
I0525 07:19:10.530382 20349 solver.cpp:409]     Test net output #1: loss = 0.465851 (* 1 = 0.465851 loss)
I0525 07:19:36.809754 20349 solver.cpp:237] Iteration 16766, loss = 1.24539
I0525 07:19:36.809805 20349 solver.cpp:253]     Train net output #0: loss = 1.24539 (* 1 = 1.24539 loss)
I0525 07:19:36.809821 20349 sgd_solver.cpp:106] Iteration 16766, lr = 0.0025
I0525 07:19:45.628587 20349 solver.cpp:237] Iteration 16932, loss = 1.23495
I0525 07:19:45.628736 20349 solver.cpp:253]     Train net output #0: loss = 1.23495 (* 1 = 1.23495 loss)
I0525 07:19:45.628751 20349 sgd_solver.cpp:106] Iteration 16932, lr = 0.0025
I0525 07:19:54.451586 20349 solver.cpp:237] Iteration 17098, loss = 1.18491
I0525 07:19:54.451619 20349 solver.cpp:253]     Train net output #0: loss = 1.18491 (* 1 = 1.18491 loss)
I0525 07:19:54.451637 20349 sgd_solver.cpp:106] Iteration 17098, lr = 0.0025
I0525 07:20:03.281484 20349 solver.cpp:237] Iteration 17264, loss = 1.36524
I0525 07:20:03.281523 20349 solver.cpp:253]     Train net output #0: loss = 1.36524 (* 1 = 1.36524 loss)
I0525 07:20:03.281546 20349 sgd_solver.cpp:106] Iteration 17264, lr = 0.0025
I0525 07:20:12.092928 20349 solver.cpp:237] Iteration 17430, loss = 1.38952
I0525 07:20:12.092963 20349 solver.cpp:253]     Train net output #0: loss = 1.38952 (* 1 = 1.38952 loss)
I0525 07:20:12.092978 20349 sgd_solver.cpp:106] Iteration 17430, lr = 0.0025
I0525 07:20:20.922399 20349 solver.cpp:237] Iteration 17596, loss = 1.27541
I0525 07:20:20.922555 20349 solver.cpp:253]     Train net output #0: loss = 1.27541 (* 1 = 1.27541 loss)
I0525 07:20:20.922569 20349 sgd_solver.cpp:106] Iteration 17596, lr = 0.0025
I0525 07:20:29.740438 20349 solver.cpp:237] Iteration 17762, loss = 0.976046
I0525 07:20:29.740474 20349 solver.cpp:253]     Train net output #0: loss = 0.976046 (* 1 = 0.976046 loss)
I0525 07:20:29.740495 20349 sgd_solver.cpp:106] Iteration 17762, lr = 0.0025
I0525 07:20:59.410712 20349 solver.cpp:237] Iteration 17928, loss = 1.19067
I0525 07:20:59.410881 20349 solver.cpp:253]     Train net output #0: loss = 1.19067 (* 1 = 1.19067 loss)
I0525 07:20:59.410895 20349 sgd_solver.cpp:106] Iteration 17928, lr = 0.0025
I0525 07:21:08.238792 20349 solver.cpp:237] Iteration 18094, loss = 1.20954
I0525 07:21:08.238827 20349 solver.cpp:253]     Train net output #0: loss = 1.20954 (* 1 = 1.20954 loss)
I0525 07:21:08.238844 20349 sgd_solver.cpp:106] Iteration 18094, lr = 0.0025
I0525 07:21:17.059443 20349 solver.cpp:237] Iteration 18260, loss = 1.4621
I0525 07:21:17.059489 20349 solver.cpp:253]     Train net output #0: loss = 1.4621 (* 1 = 1.4621 loss)
I0525 07:21:17.059506 20349 sgd_solver.cpp:106] Iteration 18260, lr = 0.0025
I0525 07:21:20.517433 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_18326.caffemodel
I0525 07:21:20.591851 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_18326.solverstate
I0525 07:21:25.948070 20349 solver.cpp:237] Iteration 18426, loss = 1.37847
I0525 07:21:25.948115 20349 solver.cpp:253]     Train net output #0: loss = 1.37847 (* 1 = 1.37847 loss)
I0525 07:21:25.948132 20349 sgd_solver.cpp:106] Iteration 18426, lr = 0.0025
I0525 07:21:34.771793 20349 solver.cpp:237] Iteration 18592, loss = 1.21443
I0525 07:21:34.771942 20349 solver.cpp:253]     Train net output #0: loss = 1.21443 (* 1 = 1.21443 loss)
I0525 07:21:34.771955 20349 sgd_solver.cpp:106] Iteration 18592, lr = 0.0025
I0525 07:21:43.594483 20349 solver.cpp:237] Iteration 18758, loss = 1.2316
I0525 07:21:43.594524 20349 solver.cpp:253]     Train net output #0: loss = 1.2316 (* 1 = 1.2316 loss)
I0525 07:21:43.594544 20349 sgd_solver.cpp:106] Iteration 18758, lr = 0.0025
I0525 07:22:13.293287 20349 solver.cpp:237] Iteration 18924, loss = 1.19938
I0525 07:22:13.293463 20349 solver.cpp:253]     Train net output #0: loss = 1.19938 (* 1 = 1.19938 loss)
I0525 07:22:13.293478 20349 sgd_solver.cpp:106] Iteration 18924, lr = 0.0025
I0525 07:22:22.113200 20349 solver.cpp:237] Iteration 19090, loss = 1.54269
I0525 07:22:22.113234 20349 solver.cpp:253]     Train net output #0: loss = 1.54269 (* 1 = 1.54269 loss)
I0525 07:22:22.113251 20349 sgd_solver.cpp:106] Iteration 19090, lr = 0.0025
I0525 07:22:30.930589 20349 solver.cpp:237] Iteration 19256, loss = 1.17475
I0525 07:22:30.930634 20349 solver.cpp:253]     Train net output #0: loss = 1.17475 (* 1 = 1.17475 loss)
I0525 07:22:30.930647 20349 sgd_solver.cpp:106] Iteration 19256, lr = 0.0025
I0525 07:22:39.749395 20349 solver.cpp:237] Iteration 19422, loss = 1.57961
I0525 07:22:39.749435 20349 solver.cpp:253]     Train net output #0: loss = 1.57961 (* 1 = 1.57961 loss)
I0525 07:22:39.749451 20349 sgd_solver.cpp:106] Iteration 19422, lr = 0.0025
I0525 07:22:48.570910 20349 solver.cpp:237] Iteration 19588, loss = 1.2975
I0525 07:22:48.571063 20349 solver.cpp:253]     Train net output #0: loss = 1.2975 (* 1 = 1.2975 loss)
I0525 07:22:48.571076 20349 sgd_solver.cpp:106] Iteration 19588, lr = 0.0025
I0525 07:22:57.404939 20349 solver.cpp:237] Iteration 19754, loss = 1.07533
I0525 07:22:57.404986 20349 solver.cpp:253]     Train net output #0: loss = 1.07533 (* 1 = 1.07533 loss)
I0525 07:22:57.405005 20349 sgd_solver.cpp:106] Iteration 19754, lr = 0.0025
I0525 07:23:06.224285 20349 solver.cpp:237] Iteration 19920, loss = 1.36431
I0525 07:23:06.224320 20349 solver.cpp:253]     Train net output #0: loss = 1.36431 (* 1 = 1.36431 loss)
I0525 07:23:06.224337 20349 sgd_solver.cpp:106] Iteration 19920, lr = 0.0025
I0525 07:23:10.002019 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_19992.caffemodel
I0525 07:23:10.077507 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_19992.solverstate
I0525 07:23:10.385300 20349 solver.cpp:341] Iteration 19998, Testing net (#0)
I0525 07:24:18.354831 20349 solver.cpp:409]     Test net output #0: accuracy = 0.86358
I0525 07:24:18.355007 20349 solver.cpp:409]     Test net output #1: loss = 0.456569 (* 1 = 0.456569 loss)
I0525 07:24:43.876441 20349 solver.cpp:237] Iteration 20086, loss = 1.18522
I0525 07:24:43.876492 20349 solver.cpp:253]     Train net output #0: loss = 1.18522 (* 1 = 1.18522 loss)
I0525 07:24:43.876507 20349 sgd_solver.cpp:106] Iteration 20086, lr = 0.0025
I0525 07:24:52.696954 20349 solver.cpp:237] Iteration 20252, loss = 1.15446
I0525 07:24:52.697108 20349 solver.cpp:253]     Train net output #0: loss = 1.15446 (* 1 = 1.15446 loss)
I0525 07:24:52.697123 20349 sgd_solver.cpp:106] Iteration 20252, lr = 0.0025
I0525 07:25:01.527812 20349 solver.cpp:237] Iteration 20418, loss = 1.03756
I0525 07:25:01.527851 20349 solver.cpp:253]     Train net output #0: loss = 1.03756 (* 1 = 1.03756 loss)
I0525 07:25:01.527873 20349 sgd_solver.cpp:106] Iteration 20418, lr = 0.0025
I0525 07:25:10.351475 20349 solver.cpp:237] Iteration 20584, loss = 1.44334
I0525 07:25:10.351511 20349 solver.cpp:253]     Train net output #0: loss = 1.44334 (* 1 = 1.44334 loss)
I0525 07:25:10.351527 20349 sgd_solver.cpp:106] Iteration 20584, lr = 0.0025
I0525 07:25:19.177443 20349 solver.cpp:237] Iteration 20750, loss = 1.1652
I0525 07:25:19.177474 20349 solver.cpp:253]     Train net output #0: loss = 1.1652 (* 1 = 1.1652 loss)
I0525 07:25:19.177486 20349 sgd_solver.cpp:106] Iteration 20750, lr = 0.0025
I0525 07:25:28.010905 20349 solver.cpp:237] Iteration 20916, loss = 1.18546
I0525 07:25:28.011075 20349 solver.cpp:253]     Train net output #0: loss = 1.18546 (* 1 = 1.18546 loss)
I0525 07:25:28.011090 20349 sgd_solver.cpp:106] Iteration 20916, lr = 0.0025
I0525 07:25:36.830600 20349 solver.cpp:237] Iteration 21082, loss = 1.21051
I0525 07:25:36.830634 20349 solver.cpp:253]     Train net output #0: loss = 1.21051 (* 1 = 1.21051 loss)
I0525 07:25:36.830651 20349 sgd_solver.cpp:106] Iteration 21082, lr = 0.0025
I0525 07:26:06.546036 20349 solver.cpp:237] Iteration 21248, loss = 1.09979
I0525 07:26:06.546205 20349 solver.cpp:253]     Train net output #0: loss = 1.09979 (* 1 = 1.09979 loss)
I0525 07:26:06.546221 20349 sgd_solver.cpp:106] Iteration 21248, lr = 0.0025
I0525 07:26:15.367835 20349 solver.cpp:237] Iteration 21414, loss = 1.44754
I0525 07:26:15.367876 20349 solver.cpp:253]     Train net output #0: loss = 1.44754 (* 1 = 1.44754 loss)
I0525 07:26:15.367897 20349 sgd_solver.cpp:106] Iteration 21414, lr = 0.0025
I0525 07:26:24.192085 20349 solver.cpp:237] Iteration 21580, loss = 1.26828
I0525 07:26:24.192121 20349 solver.cpp:253]     Train net output #0: loss = 1.26828 (* 1 = 1.26828 loss)
I0525 07:26:24.192136 20349 sgd_solver.cpp:106] Iteration 21580, lr = 0.0025
I0525 07:26:28.284564 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_21658.caffemodel
I0525 07:26:28.359220 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_21658.solverstate
I0525 07:26:33.077955 20349 solver.cpp:237] Iteration 21746, loss = 1.10107
I0525 07:26:33.078001 20349 solver.cpp:253]     Train net output #0: loss = 1.10107 (* 1 = 1.10107 loss)
I0525 07:26:33.078014 20349 sgd_solver.cpp:106] Iteration 21746, lr = 0.0025
I0525 07:26:41.903671 20349 solver.cpp:237] Iteration 21912, loss = 1.11919
I0525 07:26:41.903844 20349 solver.cpp:253]     Train net output #0: loss = 1.11919 (* 1 = 1.11919 loss)
I0525 07:26:41.903859 20349 sgd_solver.cpp:106] Iteration 21912, lr = 0.0025
I0525 07:26:50.728127 20349 solver.cpp:237] Iteration 22078, loss = 1.201
I0525 07:26:50.728163 20349 solver.cpp:253]     Train net output #0: loss = 1.201 (* 1 = 1.201 loss)
I0525 07:26:50.728179 20349 sgd_solver.cpp:106] Iteration 22078, lr = 0.0025
I0525 07:27:20.420598 20349 solver.cpp:237] Iteration 22244, loss = 1.28148
I0525 07:27:20.420778 20349 solver.cpp:253]     Train net output #0: loss = 1.28148 (* 1 = 1.28148 loss)
I0525 07:27:20.420794 20349 sgd_solver.cpp:106] Iteration 22244, lr = 0.0025
I0525 07:27:29.243386 20349 solver.cpp:237] Iteration 22410, loss = 1.34697
I0525 07:27:29.243425 20349 solver.cpp:253]     Train net output #0: loss = 1.34697 (* 1 = 1.34697 loss)
I0525 07:27:29.243445 20349 sgd_solver.cpp:106] Iteration 22410, lr = 0.0025
I0525 07:27:38.070049 20349 solver.cpp:237] Iteration 22576, loss = 1.05512
I0525 07:27:38.070083 20349 solver.cpp:253]     Train net output #0: loss = 1.05512 (* 1 = 1.05512 loss)
I0525 07:27:38.070099 20349 sgd_solver.cpp:106] Iteration 22576, lr = 0.0025
I0525 07:27:46.888844 20349 solver.cpp:237] Iteration 22742, loss = 1.0367
I0525 07:27:46.888880 20349 solver.cpp:253]     Train net output #0: loss = 1.0367 (* 1 = 1.0367 loss)
I0525 07:27:46.888896 20349 sgd_solver.cpp:106] Iteration 22742, lr = 0.0025
I0525 07:27:55.713707 20349 solver.cpp:237] Iteration 22908, loss = 1.2506
I0525 07:27:55.713860 20349 solver.cpp:253]     Train net output #0: loss = 1.2506 (* 1 = 1.2506 loss)
I0525 07:27:55.713874 20349 sgd_solver.cpp:106] Iteration 22908, lr = 0.0025
I0525 07:28:04.533246 20349 solver.cpp:237] Iteration 23074, loss = 1.34001
I0525 07:28:04.533282 20349 solver.cpp:253]     Train net output #0: loss = 1.34001 (* 1 = 1.34001 loss)
I0525 07:28:04.533298 20349 sgd_solver.cpp:106] Iteration 23074, lr = 0.0025
I0525 07:28:13.357775 20349 solver.cpp:237] Iteration 23240, loss = 1.23826
I0525 07:28:13.357810 20349 solver.cpp:253]     Train net output #0: loss = 1.23826 (* 1 = 1.23826 loss)
I0525 07:28:13.357826 20349 sgd_solver.cpp:106] Iteration 23240, lr = 0.0025
I0525 07:28:17.767990 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_23324.caffemodel
I0525 07:28:17.842588 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_23324.solverstate
I0525 07:28:18.202591 20349 solver.cpp:341] Iteration 23331, Testing net (#0)
I0525 07:29:05.033661 20349 solver.cpp:409]     Test net output #0: accuracy = 0.863868
I0525 07:29:05.033830 20349 solver.cpp:409]     Test net output #1: loss = 0.457898 (* 1 = 0.457898 loss)
I0525 07:29:29.939672 20349 solver.cpp:237] Iteration 23406, loss = 1.1541
I0525 07:29:29.939723 20349 solver.cpp:253]     Train net output #0: loss = 1.1541 (* 1 = 1.1541 loss)
I0525 07:29:29.939738 20349 sgd_solver.cpp:106] Iteration 23406, lr = 0.0025
I0525 07:29:38.774166 20349 solver.cpp:237] Iteration 23572, loss = 1.12865
I0525 07:29:38.774327 20349 solver.cpp:253]     Train net output #0: loss = 1.12865 (* 1 = 1.12865 loss)
I0525 07:29:38.774341 20349 sgd_solver.cpp:106] Iteration 23572, lr = 0.0025
I0525 07:29:47.607820 20349 solver.cpp:237] Iteration 23738, loss = 1.18142
I0525 07:29:47.607853 20349 solver.cpp:253]     Train net output #0: loss = 1.18142 (* 1 = 1.18142 loss)
I0525 07:29:47.607870 20349 sgd_solver.cpp:106] Iteration 23738, lr = 0.0025
I0525 07:29:56.439375 20349 solver.cpp:237] Iteration 23904, loss = 1.27107
I0525 07:29:56.439419 20349 solver.cpp:253]     Train net output #0: loss = 1.27107 (* 1 = 1.27107 loss)
I0525 07:29:56.439435 20349 sgd_solver.cpp:106] Iteration 23904, lr = 0.0025
I0525 07:30:05.264955 20349 solver.cpp:237] Iteration 24070, loss = 1.33639
I0525 07:30:05.264991 20349 solver.cpp:253]     Train net output #0: loss = 1.33639 (* 1 = 1.33639 loss)
I0525 07:30:05.265005 20349 sgd_solver.cpp:106] Iteration 24070, lr = 0.0025
I0525 07:30:14.097988 20349 solver.cpp:237] Iteration 24236, loss = 1.43667
I0525 07:30:14.098146 20349 solver.cpp:253]     Train net output #0: loss = 1.43667 (* 1 = 1.43667 loss)
I0525 07:30:14.098160 20349 sgd_solver.cpp:106] Iteration 24236, lr = 0.0025
I0525 07:30:22.936558 20349 solver.cpp:237] Iteration 24402, loss = 1.37809
I0525 07:30:22.936602 20349 solver.cpp:253]     Train net output #0: loss = 1.37809 (* 1 = 1.37809 loss)
I0525 07:30:22.936620 20349 sgd_solver.cpp:106] Iteration 24402, lr = 0.0025
I0525 07:30:52.661777 20349 solver.cpp:237] Iteration 24568, loss = 1.09495
I0525 07:30:52.661950 20349 solver.cpp:253]     Train net output #0: loss = 1.09495 (* 1 = 1.09495 loss)
I0525 07:30:52.661967 20349 sgd_solver.cpp:106] Iteration 24568, lr = 0.0025
I0525 07:31:01.495383 20349 solver.cpp:237] Iteration 24734, loss = 1.38569
I0525 07:31:01.495416 20349 solver.cpp:253]     Train net output #0: loss = 1.38569 (* 1 = 1.38569 loss)
I0525 07:31:01.495434 20349 sgd_solver.cpp:106] Iteration 24734, lr = 0.0025
I0525 07:31:10.333637 20349 solver.cpp:237] Iteration 24900, loss = 1.19228
I0525 07:31:10.333673 20349 solver.cpp:253]     Train net output #0: loss = 1.19228 (* 1 = 1.19228 loss)
I0525 07:31:10.333689 20349 sgd_solver.cpp:106] Iteration 24900, lr = 0.0025
I0525 07:31:15.072759 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_24990.caffemodel
I0525 07:31:15.148815 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_24990.solverstate
I0525 07:31:19.246389 20349 solver.cpp:237] Iteration 25066, loss = 1.26112
I0525 07:31:19.246438 20349 solver.cpp:253]     Train net output #0: loss = 1.26112 (* 1 = 1.26112 loss)
I0525 07:31:19.246451 20349 sgd_solver.cpp:106] Iteration 25066, lr = 0.0025
I0525 07:31:28.076351 20349 solver.cpp:237] Iteration 25232, loss = 1.24636
I0525 07:31:28.076505 20349 solver.cpp:253]     Train net output #0: loss = 1.24636 (* 1 = 1.24636 loss)
I0525 07:31:28.076520 20349 sgd_solver.cpp:106] Iteration 25232, lr = 0.0025
I0525 07:31:36.905457 20349 solver.cpp:237] Iteration 25398, loss = 1.0745
I0525 07:31:36.905500 20349 solver.cpp:253]     Train net output #0: loss = 1.0745 (* 1 = 1.0745 loss)
I0525 07:31:36.905515 20349 sgd_solver.cpp:106] Iteration 25398, lr = 0.0025
I0525 07:32:06.609958 20349 solver.cpp:237] Iteration 25564, loss = 1.40617
I0525 07:32:06.610129 20349 solver.cpp:253]     Train net output #0: loss = 1.40617 (* 1 = 1.40617 loss)
I0525 07:32:06.610143 20349 sgd_solver.cpp:106] Iteration 25564, lr = 0.0025
I0525 07:32:15.447762 20349 solver.cpp:237] Iteration 25730, loss = 1.3037
I0525 07:32:15.447798 20349 solver.cpp:253]     Train net output #0: loss = 1.3037 (* 1 = 1.3037 loss)
I0525 07:32:15.447811 20349 sgd_solver.cpp:106] Iteration 25730, lr = 0.0025
I0525 07:32:24.278352 20349 solver.cpp:237] Iteration 25896, loss = 1.0616
I0525 07:32:24.278388 20349 solver.cpp:253]     Train net output #0: loss = 1.0616 (* 1 = 1.0616 loss)
I0525 07:32:24.278401 20349 sgd_solver.cpp:106] Iteration 25896, lr = 0.0025
I0525 07:32:33.108882 20349 solver.cpp:237] Iteration 26062, loss = 1.30668
I0525 07:32:33.108918 20349 solver.cpp:253]     Train net output #0: loss = 1.30668 (* 1 = 1.30668 loss)
I0525 07:32:33.108942 20349 sgd_solver.cpp:106] Iteration 26062, lr = 0.0025
I0525 07:32:41.944566 20349 solver.cpp:237] Iteration 26228, loss = 1.3106
I0525 07:32:41.944725 20349 solver.cpp:253]     Train net output #0: loss = 1.3106 (* 1 = 1.3106 loss)
I0525 07:32:41.944738 20349 sgd_solver.cpp:106] Iteration 26228, lr = 0.0025
I0525 07:32:50.780627 20349 solver.cpp:237] Iteration 26394, loss = 1.33553
I0525 07:32:50.780660 20349 solver.cpp:253]     Train net output #0: loss = 1.33553 (* 1 = 1.33553 loss)
I0525 07:32:50.780678 20349 sgd_solver.cpp:106] Iteration 26394, lr = 0.0025
I0525 07:32:59.618613 20349 solver.cpp:237] Iteration 26560, loss = 1.23522
I0525 07:32:59.618651 20349 solver.cpp:253]     Train net output #0: loss = 1.23522 (* 1 = 1.23522 loss)
I0525 07:32:59.618672 20349 sgd_solver.cpp:106] Iteration 26560, lr = 0.0025
I0525 07:33:04.674933 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_26656.caffemodel
I0525 07:33:04.749321 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_26656.solverstate
I0525 07:33:05.164994 20349 solver.cpp:341] Iteration 26664, Testing net (#0)
I0525 07:34:13.212258 20349 solver.cpp:409]     Test net output #0: accuracy = 0.859653
I0525 07:34:13.212431 20349 solver.cpp:409]     Test net output #1: loss = 0.435209 (* 1 = 0.435209 loss)
I0525 07:34:37.382055 20349 solver.cpp:237] Iteration 26726, loss = 1.11073
I0525 07:34:37.382107 20349 solver.cpp:253]     Train net output #0: loss = 1.11073 (* 1 = 1.11073 loss)
I0525 07:34:37.382122 20349 sgd_solver.cpp:106] Iteration 26726, lr = 0.0025
I0525 07:34:46.208430 20349 solver.cpp:237] Iteration 26892, loss = 1.34271
I0525 07:34:46.208586 20349 solver.cpp:253]     Train net output #0: loss = 1.34271 (* 1 = 1.34271 loss)
I0525 07:34:46.208600 20349 sgd_solver.cpp:106] Iteration 26892, lr = 0.0025
I0525 07:34:55.040478 20349 solver.cpp:237] Iteration 27058, loss = 1.04988
I0525 07:34:55.040513 20349 solver.cpp:253]     Train net output #0: loss = 1.04988 (* 1 = 1.04988 loss)
I0525 07:34:55.040529 20349 sgd_solver.cpp:106] Iteration 27058, lr = 0.0025
I0525 07:35:03.858938 20349 solver.cpp:237] Iteration 27224, loss = 1.13709
I0525 07:35:03.858976 20349 solver.cpp:253]     Train net output #0: loss = 1.13709 (* 1 = 1.13709 loss)
I0525 07:35:03.858994 20349 sgd_solver.cpp:106] Iteration 27224, lr = 0.0025
I0525 07:35:12.682000 20349 solver.cpp:237] Iteration 27390, loss = 0.975889
I0525 07:35:12.682036 20349 solver.cpp:253]     Train net output #0: loss = 0.975889 (* 1 = 0.975889 loss)
I0525 07:35:12.682051 20349 sgd_solver.cpp:106] Iteration 27390, lr = 0.0025
I0525 07:35:21.497990 20349 solver.cpp:237] Iteration 27556, loss = 0.995955
I0525 07:35:21.498139 20349 solver.cpp:253]     Train net output #0: loss = 0.995955 (* 1 = 0.995955 loss)
I0525 07:35:21.498152 20349 sgd_solver.cpp:106] Iteration 27556, lr = 0.0025
I0525 07:35:30.318223 20349 solver.cpp:237] Iteration 27722, loss = 1.33464
I0525 07:35:30.318258 20349 solver.cpp:253]     Train net output #0: loss = 1.33464 (* 1 = 1.33464 loss)
I0525 07:35:30.318276 20349 sgd_solver.cpp:106] Iteration 27722, lr = 0.0025
I0525 07:36:00.016032 20349 solver.cpp:237] Iteration 27888, loss = 1.33775
I0525 07:36:00.016203 20349 solver.cpp:253]     Train net output #0: loss = 1.33775 (* 1 = 1.33775 loss)
I0525 07:36:00.016219 20349 sgd_solver.cpp:106] Iteration 27888, lr = 0.0025
I0525 07:36:08.835482 20349 solver.cpp:237] Iteration 28054, loss = 1.22092
I0525 07:36:08.835516 20349 solver.cpp:253]     Train net output #0: loss = 1.22092 (* 1 = 1.22092 loss)
I0525 07:36:08.835530 20349 sgd_solver.cpp:106] Iteration 28054, lr = 0.0025
I0525 07:36:17.657888 20349 solver.cpp:237] Iteration 28220, loss = 1.11915
I0525 07:36:17.657925 20349 solver.cpp:253]     Train net output #0: loss = 1.11915 (* 1 = 1.11915 loss)
I0525 07:36:17.657943 20349 sgd_solver.cpp:106] Iteration 28220, lr = 0.0025
I0525 07:36:23.020280 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_28322.caffemodel
I0525 07:36:23.095672 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_28322.solverstate
I0525 07:36:26.540869 20349 solver.cpp:237] Iteration 28386, loss = 1.32982
I0525 07:36:26.540911 20349 solver.cpp:253]     Train net output #0: loss = 1.32982 (* 1 = 1.32982 loss)
I0525 07:36:26.540931 20349 sgd_solver.cpp:106] Iteration 28386, lr = 0.0025
I0525 07:36:35.359254 20349 solver.cpp:237] Iteration 28552, loss = 1.2168
I0525 07:36:35.359416 20349 solver.cpp:253]     Train net output #0: loss = 1.2168 (* 1 = 1.2168 loss)
I0525 07:36:35.359431 20349 sgd_solver.cpp:106] Iteration 28552, lr = 0.0025
I0525 07:36:44.182289 20349 solver.cpp:237] Iteration 28718, loss = 1.3151
I0525 07:36:44.182325 20349 solver.cpp:253]     Train net output #0: loss = 1.3151 (* 1 = 1.3151 loss)
I0525 07:36:44.182345 20349 sgd_solver.cpp:106] Iteration 28718, lr = 0.0025
I0525 07:36:53.000526 20349 solver.cpp:237] Iteration 28884, loss = 1.28185
I0525 07:36:53.000561 20349 solver.cpp:253]     Train net output #0: loss = 1.28185 (* 1 = 1.28185 loss)
I0525 07:36:53.000577 20349 sgd_solver.cpp:106] Iteration 28884, lr = 0.0025
I0525 07:37:22.726845 20349 solver.cpp:237] Iteration 29050, loss = 1.2238
I0525 07:37:22.727015 20349 solver.cpp:253]     Train net output #0: loss = 1.2238 (* 1 = 1.2238 loss)
I0525 07:37:22.727030 20349 sgd_solver.cpp:106] Iteration 29050, lr = 0.0025
I0525 07:37:31.555995 20349 solver.cpp:237] Iteration 29216, loss = 1.23146
I0525 07:37:31.556037 20349 solver.cpp:253]     Train net output #0: loss = 1.23146 (* 1 = 1.23146 loss)
I0525 07:37:31.556059 20349 sgd_solver.cpp:106] Iteration 29216, lr = 0.0025
I0525 07:37:40.376165 20349 solver.cpp:237] Iteration 29382, loss = 1.19182
I0525 07:37:40.376201 20349 solver.cpp:253]     Train net output #0: loss = 1.19182 (* 1 = 1.19182 loss)
I0525 07:37:40.376217 20349 sgd_solver.cpp:106] Iteration 29382, lr = 0.0025
I0525 07:37:49.200585 20349 solver.cpp:237] Iteration 29548, loss = 1.11577
I0525 07:37:49.200619 20349 solver.cpp:253]     Train net output #0: loss = 1.11577 (* 1 = 1.11577 loss)
I0525 07:37:49.200636 20349 sgd_solver.cpp:106] Iteration 29548, lr = 0.0025
I0525 07:37:58.017767 20349 solver.cpp:237] Iteration 29714, loss = 1.33291
I0525 07:37:58.017931 20349 solver.cpp:253]     Train net output #0: loss = 1.33291 (* 1 = 1.33291 loss)
I0525 07:37:58.017946 20349 sgd_solver.cpp:106] Iteration 29714, lr = 0.0025
I0525 07:38:06.839164 20349 solver.cpp:237] Iteration 29880, loss = 1.11534
I0525 07:38:06.839197 20349 solver.cpp:253]     Train net output #0: loss = 1.11534 (* 1 = 1.11534 loss)
I0525 07:38:06.839215 20349 sgd_solver.cpp:106] Iteration 29880, lr = 0.0025
I0525 07:38:12.522958 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_29988.caffemodel
I0525 07:38:12.597807 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_29988.solverstate
I0525 07:38:13.064687 20349 solver.cpp:341] Iteration 29997, Testing net (#0)
I0525 07:39:00.228725 20349 solver.cpp:409]     Test net output #0: accuracy = 0.871611
I0525 07:39:00.228898 20349 solver.cpp:409]     Test net output #1: loss = 0.411022 (* 1 = 0.411022 loss)
I0525 07:39:23.713779 20349 solver.cpp:237] Iteration 30046, loss = 1.3686
I0525 07:39:23.713829 20349 solver.cpp:253]     Train net output #0: loss = 1.3686 (* 1 = 1.3686 loss)
I0525 07:39:23.713845 20349 sgd_solver.cpp:106] Iteration 30046, lr = 0.0025
I0525 07:39:32.533854 20349 solver.cpp:237] Iteration 30212, loss = 1.23685
I0525 07:39:32.534025 20349 solver.cpp:253]     Train net output #0: loss = 1.23685 (* 1 = 1.23685 loss)
I0525 07:39:32.534039 20349 sgd_solver.cpp:106] Iteration 30212, lr = 0.0025
I0525 07:39:41.350687 20349 solver.cpp:237] Iteration 30378, loss = 1.31441
I0525 07:39:41.350723 20349 solver.cpp:253]     Train net output #0: loss = 1.31441 (* 1 = 1.31441 loss)
I0525 07:39:41.350740 20349 sgd_solver.cpp:106] Iteration 30378, lr = 0.0025
I0525 07:39:50.182183 20349 solver.cpp:237] Iteration 30544, loss = 1.36705
I0525 07:39:50.182217 20349 solver.cpp:253]     Train net output #0: loss = 1.36705 (* 1 = 1.36705 loss)
I0525 07:39:50.182232 20349 sgd_solver.cpp:106] Iteration 30544, lr = 0.0025
I0525 07:39:59.005221 20349 solver.cpp:237] Iteration 30710, loss = 1.12786
I0525 07:39:59.005259 20349 solver.cpp:253]     Train net output #0: loss = 1.12786 (* 1 = 1.12786 loss)
I0525 07:39:59.005276 20349 sgd_solver.cpp:106] Iteration 30710, lr = 0.0025
I0525 07:40:07.814299 20349 solver.cpp:237] Iteration 30876, loss = 1.14012
I0525 07:40:07.814460 20349 solver.cpp:253]     Train net output #0: loss = 1.14012 (* 1 = 1.14012 loss)
I0525 07:40:07.814473 20349 sgd_solver.cpp:106] Iteration 30876, lr = 0.0025
I0525 07:40:16.631217 20349 solver.cpp:237] Iteration 31042, loss = 1.2587
I0525 07:40:16.631252 20349 solver.cpp:253]     Train net output #0: loss = 1.2587 (* 1 = 1.2587 loss)
I0525 07:40:16.631266 20349 sgd_solver.cpp:106] Iteration 31042, lr = 0.0025
I0525 07:40:46.348320 20349 solver.cpp:237] Iteration 31208, loss = 1.24342
I0525 07:40:46.348494 20349 solver.cpp:253]     Train net output #0: loss = 1.24342 (* 1 = 1.24342 loss)
I0525 07:40:46.348508 20349 sgd_solver.cpp:106] Iteration 31208, lr = 0.0025
I0525 07:40:55.164361 20349 solver.cpp:237] Iteration 31374, loss = 1.27391
I0525 07:40:55.164394 20349 solver.cpp:253]     Train net output #0: loss = 1.27391 (* 1 = 1.27391 loss)
I0525 07:40:55.164412 20349 sgd_solver.cpp:106] Iteration 31374, lr = 0.0025
I0525 07:41:03.985679 20349 solver.cpp:237] Iteration 31540, loss = 1.05869
I0525 07:41:03.985715 20349 solver.cpp:253]     Train net output #0: loss = 1.05869 (* 1 = 1.05869 loss)
I0525 07:41:03.985730 20349 sgd_solver.cpp:106] Iteration 31540, lr = 0.0025
I0525 07:41:09.990939 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_31654.caffemodel
I0525 07:41:10.068231 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_31654.solverstate
I0525 07:41:12.881853 20349 solver.cpp:237] Iteration 31706, loss = 1.28501
I0525 07:41:12.881901 20349 solver.cpp:253]     Train net output #0: loss = 1.28501 (* 1 = 1.28501 loss)
I0525 07:41:12.881918 20349 sgd_solver.cpp:106] Iteration 31706, lr = 0.0025
I0525 07:41:21.704500 20349 solver.cpp:237] Iteration 31872, loss = 1.1642
I0525 07:41:21.704656 20349 solver.cpp:253]     Train net output #0: loss = 1.1642 (* 1 = 1.1642 loss)
I0525 07:41:21.704669 20349 sgd_solver.cpp:106] Iteration 31872, lr = 0.0025
I0525 07:41:30.530040 20349 solver.cpp:237] Iteration 32038, loss = 1.28352
I0525 07:41:30.530074 20349 solver.cpp:253]     Train net output #0: loss = 1.28352 (* 1 = 1.28352 loss)
I0525 07:41:30.530092 20349 sgd_solver.cpp:106] Iteration 32038, lr = 0.0025
I0525 07:41:39.353237 20349 solver.cpp:237] Iteration 32204, loss = 1.09293
I0525 07:41:39.353287 20349 solver.cpp:253]     Train net output #0: loss = 1.09293 (* 1 = 1.09293 loss)
I0525 07:41:39.353303 20349 sgd_solver.cpp:106] Iteration 32204, lr = 0.0025
I0525 07:42:09.026443 20349 solver.cpp:237] Iteration 32370, loss = 1.0753
I0525 07:42:09.026620 20349 solver.cpp:253]     Train net output #0: loss = 1.0753 (* 1 = 1.0753 loss)
I0525 07:42:09.026634 20349 sgd_solver.cpp:106] Iteration 32370, lr = 0.0025
I0525 07:42:17.844749 20349 solver.cpp:237] Iteration 32536, loss = 1.25676
I0525 07:42:17.844784 20349 solver.cpp:253]     Train net output #0: loss = 1.25676 (* 1 = 1.25676 loss)
I0525 07:42:17.844800 20349 sgd_solver.cpp:106] Iteration 32536, lr = 0.0025
I0525 07:42:26.667575 20349 solver.cpp:237] Iteration 32702, loss = 1.44534
I0525 07:42:26.667614 20349 solver.cpp:253]     Train net output #0: loss = 1.44534 (* 1 = 1.44534 loss)
I0525 07:42:26.667635 20349 sgd_solver.cpp:106] Iteration 32702, lr = 0.0025
I0525 07:42:35.486734 20349 solver.cpp:237] Iteration 32868, loss = 1.27092
I0525 07:42:35.486768 20349 solver.cpp:253]     Train net output #0: loss = 1.27092 (* 1 = 1.27092 loss)
I0525 07:42:35.486785 20349 sgd_solver.cpp:106] Iteration 32868, lr = 0.0025
I0525 07:42:44.308392 20349 solver.cpp:237] Iteration 33034, loss = 1.28443
I0525 07:42:44.308552 20349 solver.cpp:253]     Train net output #0: loss = 1.28443 (* 1 = 1.28443 loss)
I0525 07:42:44.308565 20349 sgd_solver.cpp:106] Iteration 33034, lr = 0.0025
I0525 07:42:53.126961 20349 solver.cpp:237] Iteration 33200, loss = 1.27221
I0525 07:42:53.127012 20349 solver.cpp:253]     Train net output #0: loss = 1.27221 (* 1 = 1.27221 loss)
I0525 07:42:53.127025 20349 sgd_solver.cpp:106] Iteration 33200, lr = 0.0025
I0525 07:42:59.453243 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_33320.caffemodel
I0525 07:42:59.529186 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_33320.solverstate
I0525 07:43:00.051923 20349 solver.cpp:341] Iteration 33330, Testing net (#0)
I0525 07:44:08.084048 20349 solver.cpp:409]     Test net output #0: accuracy = 0.874946
I0525 07:44:08.084220 20349 solver.cpp:409]     Test net output #1: loss = 0.422142 (* 1 = 0.422142 loss)
I0525 07:44:30.867924 20349 solver.cpp:237] Iteration 33366, loss = 1.41119
I0525 07:44:30.867974 20349 solver.cpp:253]     Train net output #0: loss = 1.41119 (* 1 = 1.41119 loss)
I0525 07:44:30.867990 20349 sgd_solver.cpp:106] Iteration 33366, lr = 0.0025
I0525 07:44:39.684317 20349 solver.cpp:237] Iteration 33532, loss = 1.22973
I0525 07:44:39.684490 20349 solver.cpp:253]     Train net output #0: loss = 1.22973 (* 1 = 1.22973 loss)
I0525 07:44:39.684504 20349 sgd_solver.cpp:106] Iteration 33532, lr = 0.0025
I0525 07:44:48.513162 20349 solver.cpp:237] Iteration 33698, loss = 1.15575
I0525 07:44:48.513197 20349 solver.cpp:253]     Train net output #0: loss = 1.15575 (* 1 = 1.15575 loss)
I0525 07:44:48.513214 20349 sgd_solver.cpp:106] Iteration 33698, lr = 0.0025
I0525 07:44:57.321710 20349 solver.cpp:237] Iteration 33864, loss = 1.2222
I0525 07:44:57.321748 20349 solver.cpp:253]     Train net output #0: loss = 1.2222 (* 1 = 1.2222 loss)
I0525 07:44:57.321766 20349 sgd_solver.cpp:106] Iteration 33864, lr = 0.0025
I0525 07:45:06.137341 20349 solver.cpp:237] Iteration 34030, loss = 1.20613
I0525 07:45:06.137377 20349 solver.cpp:253]     Train net output #0: loss = 1.20613 (* 1 = 1.20613 loss)
I0525 07:45:06.137390 20349 sgd_solver.cpp:106] Iteration 34030, lr = 0.0025
I0525 07:45:14.960332 20349 solver.cpp:237] Iteration 34196, loss = 1.0323
I0525 07:45:14.960484 20349 solver.cpp:253]     Train net output #0: loss = 1.0323 (* 1 = 1.0323 loss)
I0525 07:45:14.960497 20349 sgd_solver.cpp:106] Iteration 34196, lr = 0.0025
I0525 07:45:23.773972 20349 solver.cpp:237] Iteration 34362, loss = 1.10147
I0525 07:45:23.774008 20349 solver.cpp:253]     Train net output #0: loss = 1.10147 (* 1 = 1.10147 loss)
I0525 07:45:23.774029 20349 sgd_solver.cpp:106] Iteration 34362, lr = 0.0025
I0525 07:45:53.445982 20349 solver.cpp:237] Iteration 34528, loss = 1.08124
I0525 07:45:53.446166 20349 solver.cpp:253]     Train net output #0: loss = 1.08124 (* 1 = 1.08124 loss)
I0525 07:45:53.446180 20349 sgd_solver.cpp:106] Iteration 34528, lr = 0.0025
I0525 07:46:02.265015 20349 solver.cpp:237] Iteration 34694, loss = 1.2223
I0525 07:46:02.265050 20349 solver.cpp:253]     Train net output #0: loss = 1.2223 (* 1 = 1.2223 loss)
I0525 07:46:02.265066 20349 sgd_solver.cpp:106] Iteration 34694, lr = 0.0025
I0525 07:46:11.072804 20349 solver.cpp:237] Iteration 34860, loss = 1.31613
I0525 07:46:11.072839 20349 solver.cpp:253]     Train net output #0: loss = 1.31613 (* 1 = 1.31613 loss)
I0525 07:46:11.072856 20349 sgd_solver.cpp:106] Iteration 34860, lr = 0.0025
I0525 07:46:17.712258 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_34986.caffemodel
I0525 07:46:17.788188 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_34986.solverstate
I0525 07:46:19.959120 20349 solver.cpp:237] Iteration 35026, loss = 1.05433
I0525 07:46:19.959162 20349 solver.cpp:253]     Train net output #0: loss = 1.05433 (* 1 = 1.05433 loss)
I0525 07:46:19.959184 20349 sgd_solver.cpp:106] Iteration 35026, lr = 0.0025
I0525 07:46:28.782086 20349 solver.cpp:237] Iteration 35192, loss = 1.29929
I0525 07:46:28.782253 20349 solver.cpp:253]     Train net output #0: loss = 1.29929 (* 1 = 1.29929 loss)
I0525 07:46:28.782266 20349 sgd_solver.cpp:106] Iteration 35192, lr = 0.0025
I0525 07:46:37.608605 20349 solver.cpp:237] Iteration 35358, loss = 1.01865
I0525 07:46:37.608649 20349 solver.cpp:253]     Train net output #0: loss = 1.01865 (* 1 = 1.01865 loss)
I0525 07:46:37.608666 20349 sgd_solver.cpp:106] Iteration 35358, lr = 0.0025
I0525 07:46:46.435647 20349 solver.cpp:237] Iteration 35524, loss = 1.33463
I0525 07:46:46.435683 20349 solver.cpp:253]     Train net output #0: loss = 1.33463 (* 1 = 1.33463 loss)
I0525 07:46:46.435695 20349 sgd_solver.cpp:106] Iteration 35524, lr = 0.0025
I0525 07:47:16.086160 20349 solver.cpp:237] Iteration 35690, loss = 1.29526
I0525 07:47:16.086331 20349 solver.cpp:253]     Train net output #0: loss = 1.29526 (* 1 = 1.29526 loss)
I0525 07:47:16.086346 20349 sgd_solver.cpp:106] Iteration 35690, lr = 0.0025
I0525 07:47:24.901455 20349 solver.cpp:237] Iteration 35856, loss = 1.23695
I0525 07:47:24.901489 20349 solver.cpp:253]     Train net output #0: loss = 1.23695 (* 1 = 1.23695 loss)
I0525 07:47:24.901506 20349 sgd_solver.cpp:106] Iteration 35856, lr = 0.0025
I0525 07:47:33.730581 20349 solver.cpp:237] Iteration 36022, loss = 0.994183
I0525 07:47:33.730629 20349 solver.cpp:253]     Train net output #0: loss = 0.994183 (* 1 = 0.994183 loss)
I0525 07:47:33.730643 20349 sgd_solver.cpp:106] Iteration 36022, lr = 0.0025
I0525 07:47:42.551074 20349 solver.cpp:237] Iteration 36188, loss = 1.30591
I0525 07:47:42.551108 20349 solver.cpp:253]     Train net output #0: loss = 1.30591 (* 1 = 1.30591 loss)
I0525 07:47:42.551125 20349 sgd_solver.cpp:106] Iteration 36188, lr = 0.0025
I0525 07:47:51.373903 20349 solver.cpp:237] Iteration 36354, loss = 1.19277
I0525 07:47:51.374063 20349 solver.cpp:253]     Train net output #0: loss = 1.19277 (* 1 = 1.19277 loss)
I0525 07:47:51.374078 20349 sgd_solver.cpp:106] Iteration 36354, lr = 0.0025
I0525 07:48:00.197124 20349 solver.cpp:237] Iteration 36520, loss = 1.0925
I0525 07:48:00.197157 20349 solver.cpp:253]     Train net output #0: loss = 1.0925 (* 1 = 1.0925 loss)
I0525 07:48:00.197175 20349 sgd_solver.cpp:106] Iteration 36520, lr = 0.0025
I0525 07:48:07.153368 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_36652.caffemodel
I0525 07:48:07.227409 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_36652.solverstate
I0525 07:48:07.802283 20349 solver.cpp:341] Iteration 36663, Testing net (#0)
I0525 07:48:54.658957 20349 solver.cpp:409]     Test net output #0: accuracy = 0.877448
I0525 07:48:54.659132 20349 solver.cpp:409]     Test net output #1: loss = 0.382883 (* 1 = 0.382883 loss)
I0525 07:49:16.738433 20349 solver.cpp:237] Iteration 36686, loss = 1.26061
I0525 07:49:16.738486 20349 solver.cpp:253]     Train net output #0: loss = 1.26061 (* 1 = 1.26061 loss)
I0525 07:49:16.738499 20349 sgd_solver.cpp:106] Iteration 36686, lr = 0.0025
I0525 07:49:25.574271 20349 solver.cpp:237] Iteration 36852, loss = 1.32484
I0525 07:49:25.574436 20349 solver.cpp:253]     Train net output #0: loss = 1.32484 (* 1 = 1.32484 loss)
I0525 07:49:25.574450 20349 sgd_solver.cpp:106] Iteration 36852, lr = 0.0025
I0525 07:49:34.404610 20349 solver.cpp:237] Iteration 37018, loss = 1.14003
I0525 07:49:34.404649 20349 solver.cpp:253]     Train net output #0: loss = 1.14003 (* 1 = 1.14003 loss)
I0525 07:49:34.404667 20349 sgd_solver.cpp:106] Iteration 37018, lr = 0.0025
I0525 07:49:43.245369 20349 solver.cpp:237] Iteration 37184, loss = 1.12446
I0525 07:49:43.245410 20349 solver.cpp:253]     Train net output #0: loss = 1.12446 (* 1 = 1.12446 loss)
I0525 07:49:43.245424 20349 sgd_solver.cpp:106] Iteration 37184, lr = 0.0025
I0525 07:49:52.083422 20349 solver.cpp:237] Iteration 37350, loss = 1.19139
I0525 07:49:52.083456 20349 solver.cpp:253]     Train net output #0: loss = 1.19139 (* 1 = 1.19139 loss)
I0525 07:49:52.083470 20349 sgd_solver.cpp:106] Iteration 37350, lr = 0.0025
I0525 07:50:00.925088 20349 solver.cpp:237] Iteration 37516, loss = 1.17372
I0525 07:50:00.925251 20349 solver.cpp:253]     Train net output #0: loss = 1.17372 (* 1 = 1.17372 loss)
I0525 07:50:00.925266 20349 sgd_solver.cpp:106] Iteration 37516, lr = 0.0025
I0525 07:50:09.766782 20349 solver.cpp:237] Iteration 37682, loss = 1.10596
I0525 07:50:09.766816 20349 solver.cpp:253]     Train net output #0: loss = 1.10596 (* 1 = 1.10596 loss)
I0525 07:50:09.766834 20349 sgd_solver.cpp:106] Iteration 37682, lr = 0.0025
I0525 07:50:39.462709 20349 solver.cpp:237] Iteration 37848, loss = 1.13479
I0525 07:50:39.462887 20349 solver.cpp:253]     Train net output #0: loss = 1.13479 (* 1 = 1.13479 loss)
I0525 07:50:39.462901 20349 sgd_solver.cpp:106] Iteration 37848, lr = 0.0025
I0525 07:50:48.293174 20349 solver.cpp:237] Iteration 38014, loss = 1.21753
I0525 07:50:48.293211 20349 solver.cpp:253]     Train net output #0: loss = 1.21753 (* 1 = 1.21753 loss)
I0525 07:50:48.293232 20349 sgd_solver.cpp:106] Iteration 38014, lr = 0.0025
I0525 07:50:57.134806 20349 solver.cpp:237] Iteration 38180, loss = 1.06439
I0525 07:50:57.134842 20349 solver.cpp:253]     Train net output #0: loss = 1.06439 (* 1 = 1.06439 loss)
I0525 07:50:57.134858 20349 sgd_solver.cpp:106] Iteration 38180, lr = 0.0025
I0525 07:51:04.430477 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_38318.caffemodel
I0525 07:51:04.509979 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_38318.solverstate
I0525 07:51:06.041913 20349 solver.cpp:237] Iteration 38346, loss = 1.23308
I0525 07:51:06.041955 20349 solver.cpp:253]     Train net output #0: loss = 1.23308 (* 1 = 1.23308 loss)
I0525 07:51:06.041975 20349 sgd_solver.cpp:106] Iteration 38346, lr = 0.0025
I0525 07:51:14.890483 20349 solver.cpp:237] Iteration 38512, loss = 1.39399
I0525 07:51:14.890657 20349 solver.cpp:253]     Train net output #0: loss = 1.39399 (* 1 = 1.39399 loss)
I0525 07:51:14.890672 20349 sgd_solver.cpp:106] Iteration 38512, lr = 0.0025
I0525 07:51:23.720841 20349 solver.cpp:237] Iteration 38678, loss = 1.16403
I0525 07:51:23.720876 20349 solver.cpp:253]     Train net output #0: loss = 1.16403 (* 1 = 1.16403 loss)
I0525 07:51:23.720892 20349 sgd_solver.cpp:106] Iteration 38678, lr = 0.0025
I0525 07:51:32.551482 20349 solver.cpp:237] Iteration 38844, loss = 0.991077
I0525 07:51:32.551519 20349 solver.cpp:253]     Train net output #0: loss = 0.991077 (* 1 = 0.991077 loss)
I0525 07:51:32.551534 20349 sgd_solver.cpp:106] Iteration 38844, lr = 0.0025
I0525 07:52:02.258348 20349 solver.cpp:237] Iteration 39010, loss = 1.18809
I0525 07:52:02.258535 20349 solver.cpp:253]     Train net output #0: loss = 1.18809 (* 1 = 1.18809 loss)
I0525 07:52:02.258550 20349 sgd_solver.cpp:106] Iteration 39010, lr = 0.0025
I0525 07:52:11.093528 20349 solver.cpp:237] Iteration 39176, loss = 1.30843
I0525 07:52:11.093562 20349 solver.cpp:253]     Train net output #0: loss = 1.30843 (* 1 = 1.30843 loss)
I0525 07:52:11.093580 20349 sgd_solver.cpp:106] Iteration 39176, lr = 0.0025
I0525 07:52:19.930691 20349 solver.cpp:237] Iteration 39342, loss = 1.46206
I0525 07:52:19.930727 20349 solver.cpp:253]     Train net output #0: loss = 1.46206 (* 1 = 1.46206 loss)
I0525 07:52:19.930742 20349 sgd_solver.cpp:106] Iteration 39342, lr = 0.0025
I0525 07:52:28.771621 20349 solver.cpp:237] Iteration 39508, loss = 1.37903
I0525 07:52:28.771667 20349 solver.cpp:253]     Train net output #0: loss = 1.37903 (* 1 = 1.37903 loss)
I0525 07:52:28.771683 20349 sgd_solver.cpp:106] Iteration 39508, lr = 0.0025
I0525 07:52:37.610308 20349 solver.cpp:237] Iteration 39674, loss = 1.24419
I0525 07:52:37.610467 20349 solver.cpp:253]     Train net output #0: loss = 1.24419 (* 1 = 1.24419 loss)
I0525 07:52:37.610481 20349 sgd_solver.cpp:106] Iteration 39674, lr = 0.0025
I0525 07:52:46.443189 20349 solver.cpp:237] Iteration 39840, loss = 1.10784
I0525 07:52:46.443223 20349 solver.cpp:253]     Train net output #0: loss = 1.10784 (* 1 = 1.10784 loss)
I0525 07:52:46.443240 20349 sgd_solver.cpp:106] Iteration 39840, lr = 0.0025
I0525 07:52:54.054090 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_39984.caffemodel
I0525 07:52:54.129678 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_39984.solverstate
I0525 07:52:54.758024 20349 solver.cpp:341] Iteration 39996, Testing net (#0)
I0525 07:54:02.743492 20349 solver.cpp:409]     Test net output #0: accuracy = 0.876567
I0525 07:54:02.743669 20349 solver.cpp:409]     Test net output #1: loss = 0.407447 (* 1 = 0.407447 loss)
I0525 07:54:24.129863 20349 solver.cpp:237] Iteration 40006, loss = 1.19801
I0525 07:54:24.129914 20349 solver.cpp:253]     Train net output #0: loss = 1.19801 (* 1 = 1.19801 loss)
I0525 07:54:24.129932 20349 sgd_solver.cpp:106] Iteration 40006, lr = 0.0025
I0525 07:54:32.957696 20349 solver.cpp:237] Iteration 40172, loss = 1.27625
I0525 07:54:32.957869 20349 solver.cpp:253]     Train net output #0: loss = 1.27625 (* 1 = 1.27625 loss)
I0525 07:54:32.957882 20349 sgd_solver.cpp:106] Iteration 40172, lr = 0.0025
I0525 07:54:41.773562 20349 solver.cpp:237] Iteration 40338, loss = 1.10194
I0525 07:54:41.773597 20349 solver.cpp:253]     Train net output #0: loss = 1.10194 (* 1 = 1.10194 loss)
I0525 07:54:41.773613 20349 sgd_solver.cpp:106] Iteration 40338, lr = 0.0025
I0525 07:54:50.593510 20349 solver.cpp:237] Iteration 40504, loss = 1.06411
I0525 07:54:50.593545 20349 solver.cpp:253]     Train net output #0: loss = 1.06411 (* 1 = 1.06411 loss)
I0525 07:54:50.593560 20349 sgd_solver.cpp:106] Iteration 40504, lr = 0.0025
I0525 07:54:59.412145 20349 solver.cpp:237] Iteration 40670, loss = 1.0099
I0525 07:54:59.412191 20349 solver.cpp:253]     Train net output #0: loss = 1.0099 (* 1 = 1.0099 loss)
I0525 07:54:59.412211 20349 sgd_solver.cpp:106] Iteration 40670, lr = 0.0025
I0525 07:55:08.228694 20349 solver.cpp:237] Iteration 40836, loss = 1.22549
I0525 07:55:08.228854 20349 solver.cpp:253]     Train net output #0: loss = 1.22549 (* 1 = 1.22549 loss)
I0525 07:55:08.228868 20349 sgd_solver.cpp:106] Iteration 40836, lr = 0.0025
I0525 07:55:17.050510 20349 solver.cpp:237] Iteration 41002, loss = 1.33166
I0525 07:55:17.050544 20349 solver.cpp:253]     Train net output #0: loss = 1.33166 (* 1 = 1.33166 loss)
I0525 07:55:17.050561 20349 sgd_solver.cpp:106] Iteration 41002, lr = 0.0025
I0525 07:55:46.707823 20349 solver.cpp:237] Iteration 41168, loss = 1.23367
I0525 07:55:46.707999 20349 solver.cpp:253]     Train net output #0: loss = 1.23367 (* 1 = 1.23367 loss)
I0525 07:55:46.708014 20349 sgd_solver.cpp:106] Iteration 41168, lr = 0.0025
I0525 07:55:55.531415 20349 solver.cpp:237] Iteration 41334, loss = 1.11714
I0525 07:55:55.531448 20349 solver.cpp:253]     Train net output #0: loss = 1.11714 (* 1 = 1.11714 loss)
I0525 07:55:55.531466 20349 sgd_solver.cpp:106] Iteration 41334, lr = 0.0025
I0525 07:56:04.362478 20349 solver.cpp:237] Iteration 41500, loss = 1.17382
I0525 07:56:04.362512 20349 solver.cpp:253]     Train net output #0: loss = 1.17382 (* 1 = 1.17382 loss)
I0525 07:56:04.362525 20349 sgd_solver.cpp:106] Iteration 41500, lr = 0.0025
I0525 07:56:12.276749 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_41650.caffemodel
I0525 07:56:12.352444 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_41650.solverstate
I0525 07:56:13.246765 20349 solver.cpp:237] Iteration 41666, loss = 1.26957
I0525 07:56:13.246814 20349 solver.cpp:253]     Train net output #0: loss = 1.26957 (* 1 = 1.26957 loss)
I0525 07:56:13.246829 20349 sgd_solver.cpp:106] Iteration 41666, lr = 0.0025
I0525 07:56:22.063959 20349 solver.cpp:237] Iteration 41832, loss = 1.21864
I0525 07:56:22.064134 20349 solver.cpp:253]     Train net output #0: loss = 1.21864 (* 1 = 1.21864 loss)
I0525 07:56:22.064148 20349 sgd_solver.cpp:106] Iteration 41832, lr = 0.0025
I0525 07:56:30.885972 20349 solver.cpp:237] Iteration 41998, loss = 1.04631
I0525 07:56:30.886006 20349 solver.cpp:253]     Train net output #0: loss = 1.04631 (* 1 = 1.04631 loss)
I0525 07:56:30.886023 20349 sgd_solver.cpp:106] Iteration 41998, lr = 0.0025
I0525 07:56:39.713865 20349 solver.cpp:237] Iteration 42164, loss = 1.15904
I0525 07:56:39.713901 20349 solver.cpp:253]     Train net output #0: loss = 1.15904 (* 1 = 1.15904 loss)
I0525 07:56:39.713922 20349 sgd_solver.cpp:106] Iteration 42164, lr = 0.0025
I0525 07:57:09.346047 20349 solver.cpp:237] Iteration 42330, loss = 1.17781
I0525 07:57:09.346237 20349 solver.cpp:253]     Train net output #0: loss = 1.17781 (* 1 = 1.17781 loss)
I0525 07:57:09.346251 20349 sgd_solver.cpp:106] Iteration 42330, lr = 0.0025
I0525 07:57:18.172180 20349 solver.cpp:237] Iteration 42496, loss = 1.23309
I0525 07:57:18.172214 20349 solver.cpp:253]     Train net output #0: loss = 1.23309 (* 1 = 1.23309 loss)
I0525 07:57:18.172231 20349 sgd_solver.cpp:106] Iteration 42496, lr = 0.0025
I0525 07:57:26.988817 20349 solver.cpp:237] Iteration 42662, loss = 1.41725
I0525 07:57:26.988857 20349 solver.cpp:253]     Train net output #0: loss = 1.41725 (* 1 = 1.41725 loss)
I0525 07:57:26.988879 20349 sgd_solver.cpp:106] Iteration 42662, lr = 0.0025
I0525 07:57:35.813460 20349 solver.cpp:237] Iteration 42828, loss = 1.26247
I0525 07:57:35.813494 20349 solver.cpp:253]     Train net output #0: loss = 1.26247 (* 1 = 1.26247 loss)
I0525 07:57:35.813510 20349 sgd_solver.cpp:106] Iteration 42828, lr = 0.0025
I0525 07:57:44.633538 20349 solver.cpp:237] Iteration 42994, loss = 1.22397
I0525 07:57:44.633693 20349 solver.cpp:253]     Train net output #0: loss = 1.22397 (* 1 = 1.22397 loss)
I0525 07:57:44.633708 20349 sgd_solver.cpp:106] Iteration 42994, lr = 0.0025
I0525 07:57:53.458470 20349 solver.cpp:237] Iteration 43160, loss = 1.4119
I0525 07:57:53.458505 20349 solver.cpp:253]     Train net output #0: loss = 1.4119 (* 1 = 1.4119 loss)
I0525 07:57:53.458528 20349 sgd_solver.cpp:106] Iteration 43160, lr = 0.0025
I0525 07:58:01.688280 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_43316.caffemodel
I0525 07:58:01.763573 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_43316.solverstate
I0525 07:58:02.335010 20349 solver.cpp:237] Iteration 43326, loss = 1.27835
I0525 07:58:02.335054 20349 solver.cpp:253]     Train net output #0: loss = 1.27835 (* 1 = 1.27835 loss)
I0525 07:58:02.335070 20349 sgd_solver.cpp:106] Iteration 43326, lr = 0.0025
I0525 07:58:02.441213 20349 solver.cpp:341] Iteration 43329, Testing net (#0)
I0525 07:58:49.591975 20349 solver.cpp:409]     Test net output #0: accuracy = 0.879856
I0525 07:58:49.592164 20349 solver.cpp:409]     Test net output #1: loss = 0.391584 (* 1 = 0.391584 loss)
I0525 07:59:19.122931 20349 solver.cpp:237] Iteration 43492, loss = 1.18807
I0525 07:59:19.122982 20349 solver.cpp:253]     Train net output #0: loss = 1.18807 (* 1 = 1.18807 loss)
I0525 07:59:19.122997 20349 sgd_solver.cpp:106] Iteration 43492, lr = 0.0025
I0525 07:59:27.942828 20349 solver.cpp:237] Iteration 43658, loss = 1.27221
I0525 07:59:27.942996 20349 solver.cpp:253]     Train net output #0: loss = 1.27221 (* 1 = 1.27221 loss)
I0525 07:59:27.943008 20349 sgd_solver.cpp:106] Iteration 43658, lr = 0.0025
I0525 07:59:36.769094 20349 solver.cpp:237] Iteration 43824, loss = 1.04762
I0525 07:59:36.769139 20349 solver.cpp:253]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0525 07:59:36.769155 20349 sgd_solver.cpp:106] Iteration 43824, lr = 0.0025
I0525 07:59:45.590903 20349 solver.cpp:237] Iteration 43990, loss = 1.53982
I0525 07:59:45.590939 20349 solver.cpp:253]     Train net output #0: loss = 1.53982 (* 1 = 1.53982 loss)
I0525 07:59:45.590955 20349 sgd_solver.cpp:106] Iteration 43990, lr = 0.0025
I0525 07:59:54.419849 20349 solver.cpp:237] Iteration 44156, loss = 1.16746
I0525 07:59:54.419884 20349 solver.cpp:253]     Train net output #0: loss = 1.16746 (* 1 = 1.16746 loss)
I0525 07:59:54.419900 20349 sgd_solver.cpp:106] Iteration 44156, lr = 0.0025
I0525 08:00:03.244907 20349 solver.cpp:237] Iteration 44322, loss = 1.13631
I0525 08:00:03.245075 20349 solver.cpp:253]     Train net output #0: loss = 1.13631 (* 1 = 1.13631 loss)
I0525 08:00:03.245088 20349 sgd_solver.cpp:106] Iteration 44322, lr = 0.0025
I0525 08:00:32.902117 20349 solver.cpp:237] Iteration 44488, loss = 1.18111
I0525 08:00:32.902166 20349 solver.cpp:253]     Train net output #0: loss = 1.18111 (* 1 = 1.18111 loss)
I0525 08:00:32.902181 20349 sgd_solver.cpp:106] Iteration 44488, lr = 0.0025
I0525 08:00:41.726330 20349 solver.cpp:237] Iteration 44654, loss = 1.16061
I0525 08:00:41.726498 20349 solver.cpp:253]     Train net output #0: loss = 1.16061 (* 1 = 1.16061 loss)
I0525 08:00:41.726511 20349 sgd_solver.cpp:106] Iteration 44654, lr = 0.0025
I0525 08:00:50.549909 20349 solver.cpp:237] Iteration 44820, loss = 1.01317
I0525 08:00:50.549953 20349 solver.cpp:253]     Train net output #0: loss = 1.01317 (* 1 = 1.01317 loss)
I0525 08:00:50.549971 20349 sgd_solver.cpp:106] Iteration 44820, lr = 0.0025
I0525 08:00:59.111039 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_44982.caffemodel
I0525 08:00:59.185525 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_44982.solverstate
I0525 08:00:59.440661 20349 solver.cpp:237] Iteration 44986, loss = 1.2791
I0525 08:00:59.440702 20349 solver.cpp:253]     Train net output #0: loss = 1.2791 (* 1 = 1.2791 loss)
I0525 08:00:59.440723 20349 sgd_solver.cpp:106] Iteration 44986, lr = 0.0025
I0525 08:01:08.268934 20349 solver.cpp:237] Iteration 45152, loss = 0.981016
I0525 08:01:08.268970 20349 solver.cpp:253]     Train net output #0: loss = 0.981016 (* 1 = 0.981016 loss)
I0525 08:01:08.268985 20349 sgd_solver.cpp:106] Iteration 45152, lr = 0.0025
I0525 08:01:17.091783 20349 solver.cpp:237] Iteration 45318, loss = 1.08442
I0525 08:01:17.091960 20349 solver.cpp:253]     Train net output #0: loss = 1.08442 (* 1 = 1.08442 loss)
I0525 08:01:17.091975 20349 sgd_solver.cpp:106] Iteration 45318, lr = 0.0025
I0525 08:01:25.916980 20349 solver.cpp:237] Iteration 45484, loss = 1.28377
I0525 08:01:25.917013 20349 solver.cpp:253]     Train net output #0: loss = 1.28377 (* 1 = 1.28377 loss)
I0525 08:01:25.917031 20349 sgd_solver.cpp:106] Iteration 45484, lr = 0.0025
I0525 08:01:55.577080 20349 solver.cpp:237] Iteration 45650, loss = 0.92957
I0525 08:01:55.577272 20349 solver.cpp:253]     Train net output #0: loss = 0.92957 (* 1 = 0.92957 loss)
I0525 08:01:55.577287 20349 sgd_solver.cpp:106] Iteration 45650, lr = 0.0025
I0525 08:02:04.398002 20349 solver.cpp:237] Iteration 45816, loss = 1.38597
I0525 08:02:04.398046 20349 solver.cpp:253]     Train net output #0: loss = 1.38597 (* 1 = 1.38597 loss)
I0525 08:02:04.398064 20349 sgd_solver.cpp:106] Iteration 45816, lr = 0.0025
I0525 08:02:13.229332 20349 solver.cpp:237] Iteration 45982, loss = 1.05129
I0525 08:02:13.229367 20349 solver.cpp:253]     Train net output #0: loss = 1.05129 (* 1 = 1.05129 loss)
I0525 08:02:13.229383 20349 sgd_solver.cpp:106] Iteration 45982, lr = 0.0025
I0525 08:02:22.052305 20349 solver.cpp:237] Iteration 46148, loss = 1.19597
I0525 08:02:22.052340 20349 solver.cpp:253]     Train net output #0: loss = 1.19597 (* 1 = 1.19597 loss)
I0525 08:02:22.052356 20349 sgd_solver.cpp:106] Iteration 46148, lr = 0.0025
I0525 08:02:30.872683 20349 solver.cpp:237] Iteration 46314, loss = 1.23096
I0525 08:02:30.872850 20349 solver.cpp:253]     Train net output #0: loss = 1.23096 (* 1 = 1.23096 loss)
I0525 08:02:30.872865 20349 sgd_solver.cpp:106] Iteration 46314, lr = 0.0025
I0525 08:02:39.689582 20349 solver.cpp:237] Iteration 46480, loss = 1.1354
I0525 08:02:39.689616 20349 solver.cpp:253]     Train net output #0: loss = 1.1354 (* 1 = 1.1354 loss)
I0525 08:02:39.689633 20349 sgd_solver.cpp:106] Iteration 46480, lr = 0.0025
I0525 08:02:48.513799 20349 solver.cpp:237] Iteration 46646, loss = 1.11578
I0525 08:02:48.513833 20349 solver.cpp:253]     Train net output #0: loss = 1.11578 (* 1 = 1.11578 loss)
I0525 08:02:48.513850 20349 sgd_solver.cpp:106] Iteration 46646, lr = 0.0025
I0525 08:02:48.567313 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_46648.caffemodel
I0525 08:02:48.642896 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_46648.solverstate
I0525 08:02:49.378229 20349 solver.cpp:341] Iteration 46662, Testing net (#0)
I0525 08:03:57.402547 20349 solver.cpp:409]     Test net output #0: accuracy = 0.880309
I0525 08:03:57.402740 20349 solver.cpp:409]     Test net output #1: loss = 0.376265 (* 1 = 0.376265 loss)
I0525 08:04:26.248008 20349 solver.cpp:237] Iteration 46812, loss = 1.20966
I0525 08:04:26.248059 20349 solver.cpp:253]     Train net output #0: loss = 1.20966 (* 1 = 1.20966 loss)
I0525 08:04:26.248072 20349 sgd_solver.cpp:106] Iteration 46812, lr = 0.0025
I0525 08:04:35.074107 20349 solver.cpp:237] Iteration 46978, loss = 1.22325
I0525 08:04:35.074282 20349 solver.cpp:253]     Train net output #0: loss = 1.22325 (* 1 = 1.22325 loss)
I0525 08:04:35.074296 20349 sgd_solver.cpp:106] Iteration 46978, lr = 0.0025
I0525 08:04:43.909945 20349 solver.cpp:237] Iteration 47144, loss = 1.16093
I0525 08:04:43.909978 20349 solver.cpp:253]     Train net output #0: loss = 1.16093 (* 1 = 1.16093 loss)
I0525 08:04:43.909996 20349 sgd_solver.cpp:106] Iteration 47144, lr = 0.0025
I0525 08:04:52.748263 20349 solver.cpp:237] Iteration 47310, loss = 1.22167
I0525 08:04:52.748298 20349 solver.cpp:253]     Train net output #0: loss = 1.22167 (* 1 = 1.22167 loss)
I0525 08:04:52.748314 20349 sgd_solver.cpp:106] Iteration 47310, lr = 0.0025
I0525 08:05:01.583331 20349 solver.cpp:237] Iteration 47476, loss = 1.25336
I0525 08:05:01.583379 20349 solver.cpp:253]     Train net output #0: loss = 1.25336 (* 1 = 1.25336 loss)
I0525 08:05:01.583394 20349 sgd_solver.cpp:106] Iteration 47476, lr = 0.0025
I0525 08:05:10.410576 20349 solver.cpp:237] Iteration 47642, loss = 1.39019
I0525 08:05:10.410750 20349 solver.cpp:253]     Train net output #0: loss = 1.39019 (* 1 = 1.39019 loss)
I0525 08:05:10.410765 20349 sgd_solver.cpp:106] Iteration 47642, lr = 0.0025
I0525 08:05:40.148874 20349 solver.cpp:237] Iteration 47808, loss = 1.35114
I0525 08:05:40.148926 20349 solver.cpp:253]     Train net output #0: loss = 1.35114 (* 1 = 1.35114 loss)
I0525 08:05:40.148939 20349 sgd_solver.cpp:106] Iteration 47808, lr = 0.0025
I0525 08:05:48.982970 20349 solver.cpp:237] Iteration 47974, loss = 1.32786
I0525 08:05:48.983150 20349 solver.cpp:253]     Train net output #0: loss = 1.32786 (* 1 = 1.32786 loss)
I0525 08:05:48.983165 20349 sgd_solver.cpp:106] Iteration 47974, lr = 0.0025
I0525 08:05:57.814059 20349 solver.cpp:237] Iteration 48140, loss = 1.10996
I0525 08:05:57.814093 20349 solver.cpp:253]     Train net output #0: loss = 1.10996 (* 1 = 1.10996 loss)
I0525 08:05:57.814112 20349 sgd_solver.cpp:106] Iteration 48140, lr = 0.0025
I0525 08:06:06.652537 20349 solver.cpp:237] Iteration 48306, loss = 0.988241
I0525 08:06:06.652573 20349 solver.cpp:253]     Train net output #0: loss = 0.988241 (* 1 = 0.988241 loss)
I0525 08:06:06.652590 20349 sgd_solver.cpp:106] Iteration 48306, lr = 0.0025
I0525 08:06:07.025311 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_48314.caffemodel
I0525 08:06:07.102802 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_48314.solverstate
I0525 08:06:15.546360 20349 solver.cpp:237] Iteration 48472, loss = 1.30259
I0525 08:06:15.546409 20349 solver.cpp:253]     Train net output #0: loss = 1.30259 (* 1 = 1.30259 loss)
I0525 08:06:15.546425 20349 sgd_solver.cpp:106] Iteration 48472, lr = 0.0025
I0525 08:06:24.373514 20349 solver.cpp:237] Iteration 48638, loss = 1.13673
I0525 08:06:24.373675 20349 solver.cpp:253]     Train net output #0: loss = 1.13673 (* 1 = 1.13673 loss)
I0525 08:06:24.373690 20349 sgd_solver.cpp:106] Iteration 48638, lr = 0.0025
I0525 08:06:33.207137 20349 solver.cpp:237] Iteration 48804, loss = 1.0683
I0525 08:06:33.207171 20349 solver.cpp:253]     Train net output #0: loss = 1.0683 (* 1 = 1.0683 loss)
I0525 08:06:33.207190 20349 sgd_solver.cpp:106] Iteration 48804, lr = 0.0025
I0525 08:07:02.874038 20349 solver.cpp:237] Iteration 48970, loss = 1.34488
I0525 08:07:02.874222 20349 solver.cpp:253]     Train net output #0: loss = 1.34488 (* 1 = 1.34488 loss)
I0525 08:07:02.874238 20349 sgd_solver.cpp:106] Iteration 48970, lr = 0.0025
I0525 08:07:11.709822 20349 solver.cpp:237] Iteration 49136, loss = 1.31388
I0525 08:07:11.709856 20349 solver.cpp:253]     Train net output #0: loss = 1.31388 (* 1 = 1.31388 loss)
I0525 08:07:11.709873 20349 sgd_solver.cpp:106] Iteration 49136, lr = 0.0025
I0525 08:07:20.543467 20349 solver.cpp:237] Iteration 49302, loss = 1.04325
I0525 08:07:20.543500 20349 solver.cpp:253]     Train net output #0: loss = 1.04325 (* 1 = 1.04325 loss)
I0525 08:07:20.543519 20349 sgd_solver.cpp:106] Iteration 49302, lr = 0.0025
I0525 08:07:29.372867 20349 solver.cpp:237] Iteration 49468, loss = 1.37312
I0525 08:07:29.372908 20349 solver.cpp:253]     Train net output #0: loss = 1.37312 (* 1 = 1.37312 loss)
I0525 08:07:29.372926 20349 sgd_solver.cpp:106] Iteration 49468, lr = 0.0025
I0525 08:07:38.210271 20349 solver.cpp:237] Iteration 49634, loss = 1.28178
I0525 08:07:38.210433 20349 solver.cpp:253]     Train net output #0: loss = 1.28178 (* 1 = 1.28178 loss)
I0525 08:07:38.210446 20349 sgd_solver.cpp:106] Iteration 49634, lr = 0.0025
I0525 08:07:47.035498 20349 solver.cpp:237] Iteration 49800, loss = 1.20368
I0525 08:07:47.035531 20349 solver.cpp:253]     Train net output #0: loss = 1.20368 (* 1 = 1.20368 loss)
I0525 08:07:47.035549 20349 sgd_solver.cpp:106] Iteration 49800, lr = 0.0025
I0525 08:07:55.866462 20349 solver.cpp:237] Iteration 49966, loss = 1.24079
I0525 08:07:55.866503 20349 solver.cpp:253]     Train net output #0: loss = 1.24079 (* 1 = 1.24079 loss)
I0525 08:07:55.866523 20349 sgd_solver.cpp:106] Iteration 49966, lr = 0.0025
I0525 08:07:56.557488 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_49980.caffemodel
I0525 08:07:56.633744 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_49980.solverstate
I0525 08:07:57.426293 20349 solver.cpp:341] Iteration 49995, Testing net (#0)
I0525 08:08:44.224743 20349 solver.cpp:409]     Test net output #0: accuracy = 0.882116
I0525 08:08:44.224936 20349 solver.cpp:409]     Test net output #1: loss = 0.400202 (* 1 = 0.400202 loss)
I0525 08:09:12.376041 20349 solver.cpp:237] Iteration 50132, loss = 1.21772
I0525 08:09:12.376091 20349 solver.cpp:253]     Train net output #0: loss = 1.21772 (* 1 = 1.21772 loss)
I0525 08:09:12.376107 20349 sgd_solver.cpp:106] Iteration 50132, lr = 0.0025
I0525 08:09:21.200156 20349 solver.cpp:237] Iteration 50298, loss = 1.02449
I0525 08:09:21.200325 20349 solver.cpp:253]     Train net output #0: loss = 1.02449 (* 1 = 1.02449 loss)
I0525 08:09:21.200338 20349 sgd_solver.cpp:106] Iteration 50298, lr = 0.0025
I0525 08:09:30.025539 20349 solver.cpp:237] Iteration 50464, loss = 1.16383
I0525 08:09:30.025573 20349 solver.cpp:253]     Train net output #0: loss = 1.16383 (* 1 = 1.16383 loss)
I0525 08:09:30.025588 20349 sgd_solver.cpp:106] Iteration 50464, lr = 0.0025
I0525 08:09:38.850723 20349 solver.cpp:237] Iteration 50630, loss = 1.18175
I0525 08:09:38.850764 20349 solver.cpp:253]     Train net output #0: loss = 1.18175 (* 1 = 1.18175 loss)
I0525 08:09:38.850780 20349 sgd_solver.cpp:106] Iteration 50630, lr = 0.0025
I0525 08:09:47.678714 20349 solver.cpp:237] Iteration 50796, loss = 1.44366
I0525 08:09:47.678750 20349 solver.cpp:253]     Train net output #0: loss = 1.44366 (* 1 = 1.44366 loss)
I0525 08:09:47.678764 20349 sgd_solver.cpp:106] Iteration 50796, lr = 0.0025
I0525 08:09:56.501204 20349 solver.cpp:237] Iteration 50962, loss = 1.21355
I0525 08:09:56.501379 20349 solver.cpp:253]     Train net output #0: loss = 1.21355 (* 1 = 1.21355 loss)
I0525 08:09:56.501394 20349 sgd_solver.cpp:106] Iteration 50962, lr = 0.0025
I0525 08:10:26.165931 20349 solver.cpp:237] Iteration 51128, loss = 1.2958
I0525 08:10:26.165980 20349 solver.cpp:253]     Train net output #0: loss = 1.2958 (* 1 = 1.2958 loss)
I0525 08:10:26.165998 20349 sgd_solver.cpp:106] Iteration 51128, lr = 0.0025
I0525 08:10:34.993855 20349 solver.cpp:237] Iteration 51294, loss = 1.09295
I0525 08:10:34.994025 20349 solver.cpp:253]     Train net output #0: loss = 1.09295 (* 1 = 1.09295 loss)
I0525 08:10:34.994040 20349 sgd_solver.cpp:106] Iteration 51294, lr = 0.0025
I0525 08:10:43.813063 20349 solver.cpp:237] Iteration 51460, loss = 0.992297
I0525 08:10:43.813098 20349 solver.cpp:253]     Train net output #0: loss = 0.992297 (* 1 = 0.992297 loss)
I0525 08:10:43.813115 20349 sgd_solver.cpp:106] Iteration 51460, lr = 0.0025
I0525 08:10:52.643723 20349 solver.cpp:237] Iteration 51626, loss = 1.13546
I0525 08:10:52.643769 20349 solver.cpp:253]     Train net output #0: loss = 1.13546 (* 1 = 1.13546 loss)
I0525 08:10:52.643786 20349 sgd_solver.cpp:106] Iteration 51626, lr = 0.0025
I0525 08:10:53.653550 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_51646.caffemodel
I0525 08:10:53.728274 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_51646.solverstate
I0525 08:11:01.527951 20349 solver.cpp:237] Iteration 51792, loss = 0.911624
I0525 08:11:01.527992 20349 solver.cpp:253]     Train net output #0: loss = 0.911624 (* 1 = 0.911624 loss)
I0525 08:11:01.528012 20349 sgd_solver.cpp:106] Iteration 51792, lr = 0.0025
I0525 08:11:10.353592 20349 solver.cpp:237] Iteration 51958, loss = 1.11182
I0525 08:11:10.353767 20349 solver.cpp:253]     Train net output #0: loss = 1.11182 (* 1 = 1.11182 loss)
I0525 08:11:10.353782 20349 sgd_solver.cpp:106] Iteration 51958, lr = 0.0025
I0525 08:11:19.177181 20349 solver.cpp:237] Iteration 52124, loss = 0.917124
I0525 08:11:19.177228 20349 solver.cpp:253]     Train net output #0: loss = 0.917124 (* 1 = 0.917124 loss)
I0525 08:11:19.177245 20349 sgd_solver.cpp:106] Iteration 52124, lr = 0.0025
I0525 08:11:48.870199 20349 solver.cpp:237] Iteration 52290, loss = 1.31167
I0525 08:11:48.870386 20349 solver.cpp:253]     Train net output #0: loss = 1.31167 (* 1 = 1.31167 loss)
I0525 08:11:48.870404 20349 sgd_solver.cpp:106] Iteration 52290, lr = 0.0025
I0525 08:11:57.693480 20349 solver.cpp:237] Iteration 52456, loss = 1.01561
I0525 08:11:57.693514 20349 solver.cpp:253]     Train net output #0: loss = 1.01561 (* 1 = 1.01561 loss)
I0525 08:11:57.693531 20349 sgd_solver.cpp:106] Iteration 52456, lr = 0.0025
I0525 08:12:06.522917 20349 solver.cpp:237] Iteration 52622, loss = 1.28348
I0525 08:12:06.522958 20349 solver.cpp:253]     Train net output #0: loss = 1.28348 (* 1 = 1.28348 loss)
I0525 08:12:06.522979 20349 sgd_solver.cpp:106] Iteration 52622, lr = 0.0025
I0525 08:12:15.343336 20349 solver.cpp:237] Iteration 52788, loss = 1.22697
I0525 08:12:15.343371 20349 solver.cpp:253]     Train net output #0: loss = 1.22697 (* 1 = 1.22697 loss)
I0525 08:12:15.343389 20349 sgd_solver.cpp:106] Iteration 52788, lr = 0.0025
I0525 08:12:24.161906 20349 solver.cpp:237] Iteration 52954, loss = 1.26735
I0525 08:12:24.162070 20349 solver.cpp:253]     Train net output #0: loss = 1.26735 (* 1 = 1.26735 loss)
I0525 08:12:24.162083 20349 sgd_solver.cpp:106] Iteration 52954, lr = 0.0025
I0525 08:12:32.983746 20349 solver.cpp:237] Iteration 53120, loss = 1.06552
I0525 08:12:32.983786 20349 solver.cpp:253]     Train net output #0: loss = 1.06552 (* 1 = 1.06552 loss)
I0525 08:12:32.983804 20349 sgd_solver.cpp:106] Iteration 53120, lr = 0.0025
I0525 08:12:41.797946 20349 solver.cpp:237] Iteration 53286, loss = 1.11727
I0525 08:12:41.797981 20349 solver.cpp:253]     Train net output #0: loss = 1.11727 (* 1 = 1.11727 loss)
I0525 08:12:41.797996 20349 sgd_solver.cpp:106] Iteration 53286, lr = 0.0025
I0525 08:12:43.133072 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_53312.caffemodel
I0525 08:12:43.209995 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_53312.solverstate
I0525 08:12:44.051563 20349 solver.cpp:341] Iteration 53328, Testing net (#0)
I0525 08:13:52.039333 20349 solver.cpp:409]     Test net output #0: accuracy = 0.886799
I0525 08:13:52.039520 20349 solver.cpp:409]     Test net output #1: loss = 0.3611 (* 1 = 0.3611 loss)
I0525 08:14:19.448381 20349 solver.cpp:237] Iteration 53452, loss = 1.05643
I0525 08:14:19.448432 20349 solver.cpp:253]     Train net output #0: loss = 1.05643 (* 1 = 1.05643 loss)
I0525 08:14:19.448448 20349 sgd_solver.cpp:106] Iteration 53452, lr = 0.0025
I0525 08:14:28.276237 20349 solver.cpp:237] Iteration 53618, loss = 1.17312
I0525 08:14:28.276407 20349 solver.cpp:253]     Train net output #0: loss = 1.17312 (* 1 = 1.17312 loss)
I0525 08:14:28.276422 20349 sgd_solver.cpp:106] Iteration 53618, lr = 0.0025
I0525 08:14:37.093655 20349 solver.cpp:237] Iteration 53784, loss = 1.08767
I0525 08:14:37.093695 20349 solver.cpp:253]     Train net output #0: loss = 1.08767 (* 1 = 1.08767 loss)
I0525 08:14:37.093716 20349 sgd_solver.cpp:106] Iteration 53784, lr = 0.0025
I0525 08:14:45.917639 20349 solver.cpp:237] Iteration 53950, loss = 1.1389
I0525 08:14:45.917673 20349 solver.cpp:253]     Train net output #0: loss = 1.1389 (* 1 = 1.1389 loss)
I0525 08:14:45.917690 20349 sgd_solver.cpp:106] Iteration 53950, lr = 0.0025
I0525 08:14:54.745533 20349 solver.cpp:237] Iteration 54116, loss = 1.0315
I0525 08:14:54.745568 20349 solver.cpp:253]     Train net output #0: loss = 1.0315 (* 1 = 1.0315 loss)
I0525 08:14:54.745584 20349 sgd_solver.cpp:106] Iteration 54116, lr = 0.0025
I0525 08:15:03.568147 20349 solver.cpp:237] Iteration 54282, loss = 1.02343
I0525 08:15:03.568338 20349 solver.cpp:253]     Train net output #0: loss = 1.02343 (* 1 = 1.02343 loss)
I0525 08:15:03.568353 20349 sgd_solver.cpp:106] Iteration 54282, lr = 0.0025
I0525 08:15:33.203332 20349 solver.cpp:237] Iteration 54448, loss = 0.904986
I0525 08:15:33.203384 20349 solver.cpp:253]     Train net output #0: loss = 0.904986 (* 1 = 0.904986 loss)
I0525 08:15:33.203399 20349 sgd_solver.cpp:106] Iteration 54448, lr = 0.0025
I0525 08:15:42.015924 20349 solver.cpp:237] Iteration 54614, loss = 1.09349
I0525 08:15:42.016094 20349 solver.cpp:253]     Train net output #0: loss = 1.09349 (* 1 = 1.09349 loss)
I0525 08:15:42.016108 20349 sgd_solver.cpp:106] Iteration 54614, lr = 0.0025
I0525 08:15:50.833732 20349 solver.cpp:237] Iteration 54780, loss = 1.30029
I0525 08:15:50.833770 20349 solver.cpp:253]     Train net output #0: loss = 1.30029 (* 1 = 1.30029 loss)
I0525 08:15:50.833791 20349 sgd_solver.cpp:106] Iteration 54780, lr = 0.0025
I0525 08:15:59.657640 20349 solver.cpp:237] Iteration 54946, loss = 1.11375
I0525 08:15:59.657675 20349 solver.cpp:253]     Train net output #0: loss = 1.11375 (* 1 = 1.11375 loss)
I0525 08:15:59.657688 20349 sgd_solver.cpp:106] Iteration 54946, lr = 0.0025
I0525 08:16:01.305200 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_54978.caffemodel
I0525 08:16:01.379070 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_54978.solverstate
I0525 08:16:08.542276 20349 solver.cpp:237] Iteration 55112, loss = 1.26973
I0525 08:16:08.542323 20349 solver.cpp:253]     Train net output #0: loss = 1.26973 (* 1 = 1.26973 loss)
I0525 08:16:08.542340 20349 sgd_solver.cpp:106] Iteration 55112, lr = 0.0025
I0525 08:16:17.358680 20349 solver.cpp:237] Iteration 55278, loss = 1.04241
I0525 08:16:17.358865 20349 solver.cpp:253]     Train net output #0: loss = 1.04241 (* 1 = 1.04241 loss)
I0525 08:16:17.358880 20349 sgd_solver.cpp:106] Iteration 55278, lr = 0.0025
I0525 08:16:26.176367 20349 solver.cpp:237] Iteration 55444, loss = 1.05177
I0525 08:16:26.176403 20349 solver.cpp:253]     Train net output #0: loss = 1.05177 (* 1 = 1.05177 loss)
I0525 08:16:26.176419 20349 sgd_solver.cpp:106] Iteration 55444, lr = 0.0025
I0525 08:16:55.862684 20349 solver.cpp:237] Iteration 55610, loss = 1.56846
I0525 08:16:55.862880 20349 solver.cpp:253]     Train net output #0: loss = 1.56846 (* 1 = 1.56846 loss)
I0525 08:16:55.862895 20349 sgd_solver.cpp:106] Iteration 55610, lr = 0.0025
I0525 08:17:04.692085 20349 solver.cpp:237] Iteration 55776, loss = 1.35493
I0525 08:17:04.692127 20349 solver.cpp:253]     Train net output #0: loss = 1.35493 (* 1 = 1.35493 loss)
I0525 08:17:04.692148 20349 sgd_solver.cpp:106] Iteration 55776, lr = 0.0025
I0525 08:17:13.517606 20349 solver.cpp:237] Iteration 55942, loss = 0.878491
I0525 08:17:13.517642 20349 solver.cpp:253]     Train net output #0: loss = 0.878491 (* 1 = 0.878491 loss)
I0525 08:17:13.517658 20349 sgd_solver.cpp:106] Iteration 55942, lr = 0.0025
I0525 08:17:22.335738 20349 solver.cpp:237] Iteration 56108, loss = 1.22226
I0525 08:17:22.335772 20349 solver.cpp:253]     Train net output #0: loss = 1.22226 (* 1 = 1.22226 loss)
I0525 08:17:22.335789 20349 sgd_solver.cpp:106] Iteration 56108, lr = 0.0025
I0525 08:17:31.158815 20349 solver.cpp:237] Iteration 56274, loss = 1.22808
I0525 08:17:31.158989 20349 solver.cpp:253]     Train net output #0: loss = 1.22808 (* 1 = 1.22808 loss)
I0525 08:17:31.159003 20349 sgd_solver.cpp:106] Iteration 56274, lr = 0.0025
I0525 08:17:39.982007 20349 solver.cpp:237] Iteration 56440, loss = 1.06791
I0525 08:17:39.982040 20349 solver.cpp:253]     Train net output #0: loss = 1.06791 (* 1 = 1.06791 loss)
I0525 08:17:39.982059 20349 sgd_solver.cpp:106] Iteration 56440, lr = 0.0025
I0525 08:17:48.807188 20349 solver.cpp:237] Iteration 56606, loss = 1.26525
I0525 08:17:48.807222 20349 solver.cpp:253]     Train net output #0: loss = 1.26525 (* 1 = 1.26525 loss)
I0525 08:17:48.807238 20349 sgd_solver.cpp:106] Iteration 56606, lr = 0.0025
I0525 08:17:50.775986 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_56644.caffemodel
I0525 08:17:50.851560 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_56644.solverstate
I0525 08:17:51.744951 20349 solver.cpp:341] Iteration 56661, Testing net (#0)
I0525 08:18:38.942926 20349 solver.cpp:409]     Test net output #0: accuracy = 0.887072
I0525 08:18:38.943122 20349 solver.cpp:409]     Test net output #1: loss = 0.377977 (* 1 = 0.377977 loss)
I0525 08:19:05.737079 20349 solver.cpp:237] Iteration 56772, loss = 1.04563
I0525 08:19:05.737130 20349 solver.cpp:253]     Train net output #0: loss = 1.04563 (* 1 = 1.04563 loss)
I0525 08:19:05.737145 20349 sgd_solver.cpp:106] Iteration 56772, lr = 0.0025
I0525 08:19:14.553607 20349 solver.cpp:237] Iteration 56938, loss = 1.16615
I0525 08:19:14.553791 20349 solver.cpp:253]     Train net output #0: loss = 1.16615 (* 1 = 1.16615 loss)
I0525 08:19:14.553805 20349 sgd_solver.cpp:106] Iteration 56938, lr = 0.0025
I0525 08:19:23.366616 20349 solver.cpp:237] Iteration 57104, loss = 1.08666
I0525 08:19:23.366652 20349 solver.cpp:253]     Train net output #0: loss = 1.08666 (* 1 = 1.08666 loss)
I0525 08:19:23.366667 20349 sgd_solver.cpp:106] Iteration 57104, lr = 0.0025
I0525 08:19:32.187710 20349 solver.cpp:237] Iteration 57270, loss = 1.09637
I0525 08:19:32.187750 20349 solver.cpp:253]     Train net output #0: loss = 1.09637 (* 1 = 1.09637 loss)
I0525 08:19:32.187770 20349 sgd_solver.cpp:106] Iteration 57270, lr = 0.0025
I0525 08:19:41.007020 20349 solver.cpp:237] Iteration 57436, loss = 1.29549
I0525 08:19:41.007055 20349 solver.cpp:253]     Train net output #0: loss = 1.29549 (* 1 = 1.29549 loss)
I0525 08:19:41.007071 20349 sgd_solver.cpp:106] Iteration 57436, lr = 0.0025
I0525 08:19:49.838384 20349 solver.cpp:237] Iteration 57602, loss = 1.43418
I0525 08:19:49.838552 20349 solver.cpp:253]     Train net output #0: loss = 1.43418 (* 1 = 1.43418 loss)
I0525 08:19:49.838567 20349 sgd_solver.cpp:106] Iteration 57602, lr = 0.0025
I0525 08:19:58.655499 20349 solver.cpp:237] Iteration 57768, loss = 1.20582
I0525 08:19:58.655542 20349 solver.cpp:253]     Train net output #0: loss = 1.20582 (* 1 = 1.20582 loss)
I0525 08:19:58.655561 20349 sgd_solver.cpp:106] Iteration 57768, lr = 0.0025
I0525 08:20:28.368564 20349 solver.cpp:237] Iteration 57934, loss = 1.20657
I0525 08:20:28.368751 20349 solver.cpp:253]     Train net output #0: loss = 1.20657 (* 1 = 1.20657 loss)
I0525 08:20:28.368765 20349 sgd_solver.cpp:106] Iteration 57934, lr = 0.0025
I0525 08:20:37.189600 20349 solver.cpp:237] Iteration 58100, loss = 1.09586
I0525 08:20:37.189635 20349 solver.cpp:253]     Train net output #0: loss = 1.09586 (* 1 = 1.09586 loss)
I0525 08:20:37.189651 20349 sgd_solver.cpp:106] Iteration 58100, lr = 0.0025
I0525 08:20:46.001621 20349 solver.cpp:237] Iteration 58266, loss = 1.06999
I0525 08:20:46.001657 20349 solver.cpp:253]     Train net output #0: loss = 1.06999 (* 1 = 1.06999 loss)
I0525 08:20:46.001670 20349 sgd_solver.cpp:106] Iteration 58266, lr = 0.0025
I0525 08:20:48.287609 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_58310.caffemodel
I0525 08:20:48.363587 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_58310.solverstate
I0525 08:20:54.893986 20349 solver.cpp:237] Iteration 58432, loss = 1.30416
I0525 08:20:54.894032 20349 solver.cpp:253]     Train net output #0: loss = 1.30416 (* 1 = 1.30416 loss)
I0525 08:20:54.894052 20349 sgd_solver.cpp:106] Iteration 58432, lr = 0.0025
I0525 08:21:03.718144 20349 solver.cpp:237] Iteration 58598, loss = 1.01919
I0525 08:21:03.718327 20349 solver.cpp:253]     Train net output #0: loss = 1.01919 (* 1 = 1.01919 loss)
I0525 08:21:03.718343 20349 sgd_solver.cpp:106] Iteration 58598, lr = 0.0025
I0525 08:21:12.532001 20349 solver.cpp:237] Iteration 58764, loss = 1.1829
I0525 08:21:12.532042 20349 solver.cpp:253]     Train net output #0: loss = 1.1829 (* 1 = 1.1829 loss)
I0525 08:21:12.532060 20349 sgd_solver.cpp:106] Iteration 58764, lr = 0.0025
I0525 08:21:42.227028 20349 solver.cpp:237] Iteration 58930, loss = 1.18979
I0525 08:21:42.227222 20349 solver.cpp:253]     Train net output #0: loss = 1.18979 (* 1 = 1.18979 loss)
I0525 08:21:42.227236 20349 sgd_solver.cpp:106] Iteration 58930, lr = 0.0025
I0525 08:21:51.047103 20349 solver.cpp:237] Iteration 59096, loss = 1.23041
I0525 08:21:51.047137 20349 solver.cpp:253]     Train net output #0: loss = 1.23041 (* 1 = 1.23041 loss)
I0525 08:21:51.047154 20349 sgd_solver.cpp:106] Iteration 59096, lr = 0.0025
I0525 08:21:59.867311 20349 solver.cpp:237] Iteration 59262, loss = 1.07491
I0525 08:21:59.867347 20349 solver.cpp:253]     Train net output #0: loss = 1.07491 (* 1 = 1.07491 loss)
I0525 08:21:59.867359 20349 sgd_solver.cpp:106] Iteration 59262, lr = 0.0025
I0525 08:22:08.685825 20349 solver.cpp:237] Iteration 59428, loss = 1.24689
I0525 08:22:08.685870 20349 solver.cpp:253]     Train net output #0: loss = 1.24689 (* 1 = 1.24689 loss)
I0525 08:22:08.685886 20349 sgd_solver.cpp:106] Iteration 59428, lr = 0.0025
I0525 08:22:17.505102 20349 solver.cpp:237] Iteration 59594, loss = 1.08361
I0525 08:22:17.505270 20349 solver.cpp:253]     Train net output #0: loss = 1.08361 (* 1 = 1.08361 loss)
I0525 08:22:17.505285 20349 sgd_solver.cpp:106] Iteration 59594, lr = 0.0025
I0525 08:22:26.321655 20349 solver.cpp:237] Iteration 59760, loss = 1.42348
I0525 08:22:26.321696 20349 solver.cpp:253]     Train net output #0: loss = 1.42348 (* 1 = 1.42348 loss)
I0525 08:22:26.321713 20349 sgd_solver.cpp:106] Iteration 59760, lr = 0.0025
I0525 08:22:35.150082 20349 solver.cpp:237] Iteration 59926, loss = 1.25258
I0525 08:22:35.150117 20349 solver.cpp:253]     Train net output #0: loss = 1.25258 (* 1 = 1.25258 loss)
I0525 08:22:35.150135 20349 sgd_solver.cpp:106] Iteration 59926, lr = 0.0025
I0525 08:22:37.758036 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_59976.caffemodel
I0525 08:22:37.835221 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_59976.solverstate
I0525 08:22:38.786026 20349 solver.cpp:341] Iteration 59994, Testing net (#0)
I0525 08:23:46.882222 20349 solver.cpp:409]     Test net output #0: accuracy = 0.888567
I0525 08:23:46.882411 20349 solver.cpp:409]     Test net output #1: loss = 0.342703 (* 1 = 0.342703 loss)
I0525 08:24:12.989481 20349 solver.cpp:237] Iteration 60092, loss = 1.12254
I0525 08:24:12.989531 20349 solver.cpp:253]     Train net output #0: loss = 1.12254 (* 1 = 1.12254 loss)
I0525 08:24:12.989547 20349 sgd_solver.cpp:106] Iteration 60092, lr = 0.0025
I0525 08:24:21.824069 20349 solver.cpp:237] Iteration 60258, loss = 1.06011
I0525 08:24:21.824240 20349 solver.cpp:253]     Train net output #0: loss = 1.06011 (* 1 = 1.06011 loss)
I0525 08:24:21.824254 20349 sgd_solver.cpp:106] Iteration 60258, lr = 0.0025
I0525 08:24:30.654574 20349 solver.cpp:237] Iteration 60424, loss = 1.39165
I0525 08:24:30.654608 20349 solver.cpp:253]     Train net output #0: loss = 1.39165 (* 1 = 1.39165 loss)
I0525 08:24:30.654625 20349 sgd_solver.cpp:106] Iteration 60424, lr = 0.0025
I0525 08:24:39.487341 20349 solver.cpp:237] Iteration 60590, loss = 1.10167
I0525 08:24:39.487380 20349 solver.cpp:253]     Train net output #0: loss = 1.10167 (* 1 = 1.10167 loss)
I0525 08:24:39.487401 20349 sgd_solver.cpp:106] Iteration 60590, lr = 0.0025
I0525 08:24:48.319023 20349 solver.cpp:237] Iteration 60756, loss = 1.15421
I0525 08:24:48.319058 20349 solver.cpp:253]     Train net output #0: loss = 1.15421 (* 1 = 1.15421 loss)
I0525 08:24:48.319072 20349 sgd_solver.cpp:106] Iteration 60756, lr = 0.0025
I0525 08:24:57.151321 20349 solver.cpp:237] Iteration 60922, loss = 1.26669
I0525 08:24:57.151517 20349 solver.cpp:253]     Train net output #0: loss = 1.26669 (* 1 = 1.26669 loss)
I0525 08:24:57.151531 20349 sgd_solver.cpp:106] Iteration 60922, lr = 0.0025
I0525 08:25:05.980103 20349 solver.cpp:237] Iteration 61088, loss = 1.25776
I0525 08:25:05.980137 20349 solver.cpp:253]     Train net output #0: loss = 1.25776 (* 1 = 1.25776 loss)
I0525 08:25:05.980154 20349 sgd_solver.cpp:106] Iteration 61088, lr = 0.0025
I0525 08:25:35.690075 20349 solver.cpp:237] Iteration 61254, loss = 1.22173
I0525 08:25:35.690268 20349 solver.cpp:253]     Train net output #0: loss = 1.22173 (* 1 = 1.22173 loss)
I0525 08:25:35.690281 20349 sgd_solver.cpp:106] Iteration 61254, lr = 0.0025
I0525 08:25:44.533293 20349 solver.cpp:237] Iteration 61420, loss = 1.14897
I0525 08:25:44.533327 20349 solver.cpp:253]     Train net output #0: loss = 1.14897 (* 1 = 1.14897 loss)
I0525 08:25:44.533344 20349 sgd_solver.cpp:106] Iteration 61420, lr = 0.0025
I0525 08:25:53.364157 20349 solver.cpp:237] Iteration 61586, loss = 1.25737
I0525 08:25:53.364199 20349 solver.cpp:253]     Train net output #0: loss = 1.25737 (* 1 = 1.25737 loss)
I0525 08:25:53.364220 20349 sgd_solver.cpp:106] Iteration 61586, lr = 0.0025
I0525 08:25:56.295367 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_61642.caffemodel
I0525 08:25:56.370098 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_61642.solverstate
I0525 08:26:02.278918 20349 solver.cpp:237] Iteration 61752, loss = 1.01751
I0525 08:26:02.278966 20349 solver.cpp:253]     Train net output #0: loss = 1.01751 (* 1 = 1.01751 loss)
I0525 08:26:02.278980 20349 sgd_solver.cpp:106] Iteration 61752, lr = 0.0025
I0525 08:26:11.115481 20349 solver.cpp:237] Iteration 61918, loss = 1.07515
I0525 08:26:11.115654 20349 solver.cpp:253]     Train net output #0: loss = 1.07515 (* 1 = 1.07515 loss)
I0525 08:26:11.115669 20349 sgd_solver.cpp:106] Iteration 61918, lr = 0.0025
I0525 08:26:19.948765 20349 solver.cpp:237] Iteration 62084, loss = 1.06268
I0525 08:26:19.948806 20349 solver.cpp:253]     Train net output #0: loss = 1.06268 (* 1 = 1.06268 loss)
I0525 08:26:19.948825 20349 sgd_solver.cpp:106] Iteration 62084, lr = 0.0025
I0525 08:26:49.649749 20349 solver.cpp:237] Iteration 62250, loss = 1.09785
I0525 08:26:49.649940 20349 solver.cpp:253]     Train net output #0: loss = 1.09785 (* 1 = 1.09785 loss)
I0525 08:26:49.649955 20349 sgd_solver.cpp:106] Iteration 62250, lr = 0.0025
I0525 08:26:58.488246 20349 solver.cpp:237] Iteration 62416, loss = 1.30087
I0525 08:26:58.488281 20349 solver.cpp:253]     Train net output #0: loss = 1.30087 (* 1 = 1.30087 loss)
I0525 08:26:58.488294 20349 sgd_solver.cpp:106] Iteration 62416, lr = 0.0025
I0525 08:27:07.319954 20349 solver.cpp:237] Iteration 62582, loss = 1.15346
I0525 08:27:07.319994 20349 solver.cpp:253]     Train net output #0: loss = 1.15346 (* 1 = 1.15346 loss)
I0525 08:27:07.320013 20349 sgd_solver.cpp:106] Iteration 62582, lr = 0.0025
I0525 08:27:16.154474 20349 solver.cpp:237] Iteration 62748, loss = 1.14536
I0525 08:27:16.154510 20349 solver.cpp:253]     Train net output #0: loss = 1.14536 (* 1 = 1.14536 loss)
I0525 08:27:16.154528 20349 sgd_solver.cpp:106] Iteration 62748, lr = 0.0025
I0525 08:27:24.990236 20349 solver.cpp:237] Iteration 62914, loss = 1.30712
I0525 08:27:24.990417 20349 solver.cpp:253]     Train net output #0: loss = 1.30712 (* 1 = 1.30712 loss)
I0525 08:27:24.990430 20349 sgd_solver.cpp:106] Iteration 62914, lr = 0.0025
I0525 08:27:33.819890 20349 solver.cpp:237] Iteration 63080, loss = 1.35428
I0525 08:27:33.819936 20349 solver.cpp:253]     Train net output #0: loss = 1.35428 (* 1 = 1.35428 loss)
I0525 08:27:33.819952 20349 sgd_solver.cpp:106] Iteration 63080, lr = 0.0025
I0525 08:27:42.656903 20349 solver.cpp:237] Iteration 63246, loss = 1.25173
I0525 08:27:42.656937 20349 solver.cpp:253]     Train net output #0: loss = 1.25173 (* 1 = 1.25173 loss)
I0525 08:27:42.656954 20349 sgd_solver.cpp:106] Iteration 63246, lr = 0.0025
I0525 08:27:45.909637 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_63308.caffemodel
I0525 08:27:45.984676 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_63308.solverstate
I0525 08:27:46.985427 20349 solver.cpp:341] Iteration 63327, Testing net (#0)
I0525 08:28:33.844959 20349 solver.cpp:409]     Test net output #0: accuracy = 0.885458
I0525 08:28:33.845149 20349 solver.cpp:409]     Test net output #1: loss = 0.354899 (* 1 = 0.354899 loss)
I0525 08:28:59.220975 20349 solver.cpp:237] Iteration 63412, loss = 1.30792
I0525 08:28:59.221026 20349 solver.cpp:253]     Train net output #0: loss = 1.30792 (* 1 = 1.30792 loss)
I0525 08:28:59.221042 20349 sgd_solver.cpp:106] Iteration 63412, lr = 0.0025
I0525 08:29:08.044750 20349 solver.cpp:237] Iteration 63578, loss = 1.18191
I0525 08:29:08.044939 20349 solver.cpp:253]     Train net output #0: loss = 1.18191 (* 1 = 1.18191 loss)
I0525 08:29:08.044952 20349 sgd_solver.cpp:106] Iteration 63578, lr = 0.0025
I0525 08:29:16.872472 20349 solver.cpp:237] Iteration 63744, loss = 1.14475
I0525 08:29:16.872506 20349 solver.cpp:253]     Train net output #0: loss = 1.14475 (* 1 = 1.14475 loss)
I0525 08:29:16.872520 20349 sgd_solver.cpp:106] Iteration 63744, lr = 0.0025
I0525 08:29:25.694993 20349 solver.cpp:237] Iteration 63910, loss = 1.1939
I0525 08:29:25.695027 20349 solver.cpp:253]     Train net output #0: loss = 1.1939 (* 1 = 1.1939 loss)
I0525 08:29:25.695044 20349 sgd_solver.cpp:106] Iteration 63910, lr = 0.0025
I0525 08:29:34.518857 20349 solver.cpp:237] Iteration 64076, loss = 1.17626
I0525 08:29:34.518905 20349 solver.cpp:253]     Train net output #0: loss = 1.17626 (* 1 = 1.17626 loss)
I0525 08:29:34.518923 20349 sgd_solver.cpp:106] Iteration 64076, lr = 0.0025
I0525 08:29:43.345541 20349 solver.cpp:237] Iteration 64242, loss = 1.26077
I0525 08:29:43.345712 20349 solver.cpp:253]     Train net output #0: loss = 1.26077 (* 1 = 1.26077 loss)
I0525 08:29:43.345726 20349 sgd_solver.cpp:106] Iteration 64242, lr = 0.0025
I0525 08:29:52.177435 20349 solver.cpp:237] Iteration 64408, loss = 1.227
I0525 08:29:52.177465 20349 solver.cpp:253]     Train net output #0: loss = 1.227 (* 1 = 1.227 loss)
I0525 08:29:52.177479 20349 sgd_solver.cpp:106] Iteration 64408, lr = 0.0025
I0525 08:30:21.905989 20349 solver.cpp:237] Iteration 64574, loss = 1.37195
I0525 08:30:21.906174 20349 solver.cpp:253]     Train net output #0: loss = 1.37195 (* 1 = 1.37195 loss)
I0525 08:30:21.906189 20349 sgd_solver.cpp:106] Iteration 64574, lr = 0.0025
I0525 08:30:30.725304 20349 solver.cpp:237] Iteration 64740, loss = 1.24124
I0525 08:30:30.725338 20349 solver.cpp:253]     Train net output #0: loss = 1.24124 (* 1 = 1.24124 loss)
I0525 08:30:30.725355 20349 sgd_solver.cpp:106] Iteration 64740, lr = 0.0025
I0525 08:30:39.542253 20349 solver.cpp:237] Iteration 64906, loss = 1.19406
I0525 08:30:39.542289 20349 solver.cpp:253]     Train net output #0: loss = 1.19406 (* 1 = 1.19406 loss)
I0525 08:30:39.542304 20349 sgd_solver.cpp:106] Iteration 64906, lr = 0.0025
I0525 08:30:43.100965 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_64974.caffemodel
I0525 08:30:43.175031 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_64974.solverstate
I0525 08:30:48.427547 20349 solver.cpp:237] Iteration 65072, loss = 1.41333
I0525 08:30:48.427593 20349 solver.cpp:253]     Train net output #0: loss = 1.41333 (* 1 = 1.41333 loss)
I0525 08:30:48.427616 20349 sgd_solver.cpp:106] Iteration 65072, lr = 0.0025
I0525 08:30:57.259160 20349 solver.cpp:237] Iteration 65238, loss = 1.43725
I0525 08:30:57.259346 20349 solver.cpp:253]     Train net output #0: loss = 1.43725 (* 1 = 1.43725 loss)
I0525 08:30:57.259361 20349 sgd_solver.cpp:106] Iteration 65238, lr = 0.0025
I0525 08:31:06.078673 20349 solver.cpp:237] Iteration 65404, loss = 1.21974
I0525 08:31:06.078708 20349 solver.cpp:253]     Train net output #0: loss = 1.21974 (* 1 = 1.21974 loss)
I0525 08:31:06.078725 20349 sgd_solver.cpp:106] Iteration 65404, lr = 0.0025
I0525 08:31:35.796350 20349 solver.cpp:237] Iteration 65570, loss = 1.17319
I0525 08:31:35.796545 20349 solver.cpp:253]     Train net output #0: loss = 1.17319 (* 1 = 1.17319 loss)
I0525 08:31:35.796562 20349 sgd_solver.cpp:106] Iteration 65570, lr = 0.0025
I0525 08:31:44.614759 20349 solver.cpp:237] Iteration 65736, loss = 1.15114
I0525 08:31:44.614802 20349 solver.cpp:253]     Train net output #0: loss = 1.15114 (* 1 = 1.15114 loss)
I0525 08:31:44.614819 20349 sgd_solver.cpp:106] Iteration 65736, lr = 0.0025
I0525 08:31:53.429083 20349 solver.cpp:237] Iteration 65902, loss = 1.15091
I0525 08:31:53.429118 20349 solver.cpp:253]     Train net output #0: loss = 1.15091 (* 1 = 1.15091 loss)
I0525 08:31:53.429131 20349 sgd_solver.cpp:106] Iteration 65902, lr = 0.0025
I0525 08:32:02.240483 20349 solver.cpp:237] Iteration 66068, loss = 1.13325
I0525 08:32:02.240530 20349 solver.cpp:253]     Train net output #0: loss = 1.13325 (* 1 = 1.13325 loss)
I0525 08:32:02.240545 20349 sgd_solver.cpp:106] Iteration 66068, lr = 0.0025
I0525 08:32:11.062283 20349 solver.cpp:237] Iteration 66234, loss = 1.18007
I0525 08:32:11.062453 20349 solver.cpp:253]     Train net output #0: loss = 1.18007 (* 1 = 1.18007 loss)
I0525 08:32:11.062468 20349 sgd_solver.cpp:106] Iteration 66234, lr = 0.0025
I0525 08:32:19.878624 20349 solver.cpp:237] Iteration 66400, loss = 1.33079
I0525 08:32:19.878659 20349 solver.cpp:253]     Train net output #0: loss = 1.33079 (* 1 = 1.33079 loss)
I0525 08:32:19.878674 20349 sgd_solver.cpp:106] Iteration 66400, lr = 0.0025
I0525 08:32:28.699734 20349 solver.cpp:237] Iteration 66566, loss = 1.151
I0525 08:32:28.699771 20349 solver.cpp:253]     Train net output #0: loss = 1.151 (* 1 = 1.151 loss)
I0525 08:32:28.699791 20349 sgd_solver.cpp:106] Iteration 66566, lr = 0.0025
I0525 08:32:32.581902 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_66640.caffemodel
I0525 08:32:32.658427 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_66640.solverstate
I0525 08:32:33.713978 20349 solver.cpp:341] Iteration 66660, Testing net (#0)
I0525 08:33:41.760081 20349 solver.cpp:409]     Test net output #0: accuracy = 0.887687
I0525 08:33:41.760265 20349 solver.cpp:409]     Test net output #1: loss = 0.35711 (* 1 = 0.35711 loss)
I0525 08:34:06.490357 20349 solver.cpp:237] Iteration 66732, loss = 1.17105
I0525 08:34:06.490411 20349 solver.cpp:253]     Train net output #0: loss = 1.17105 (* 1 = 1.17105 loss)
I0525 08:34:06.490430 20349 sgd_solver.cpp:106] Iteration 66732, lr = 0.0025
I0525 08:34:15.311074 20349 solver.cpp:237] Iteration 66898, loss = 1.19782
I0525 08:34:15.311260 20349 solver.cpp:253]     Train net output #0: loss = 1.19782 (* 1 = 1.19782 loss)
I0525 08:34:15.311274 20349 sgd_solver.cpp:106] Iteration 66898, lr = 0.0025
I0525 08:34:24.143573 20349 solver.cpp:237] Iteration 67064, loss = 1.19785
I0525 08:34:24.143607 20349 solver.cpp:253]     Train net output #0: loss = 1.19785 (* 1 = 1.19785 loss)
I0525 08:34:24.143622 20349 sgd_solver.cpp:106] Iteration 67064, lr = 0.0025
I0525 08:34:32.968060 20349 solver.cpp:237] Iteration 67230, loss = 1.20725
I0525 08:34:32.968098 20349 solver.cpp:253]     Train net output #0: loss = 1.20725 (* 1 = 1.20725 loss)
I0525 08:34:32.968121 20349 sgd_solver.cpp:106] Iteration 67230, lr = 0.0025
I0525 08:34:41.793365 20349 solver.cpp:237] Iteration 67396, loss = 1.11485
I0525 08:34:41.793411 20349 solver.cpp:253]     Train net output #0: loss = 1.11485 (* 1 = 1.11485 loss)
I0525 08:34:41.793424 20349 sgd_solver.cpp:106] Iteration 67396, lr = 0.0025
I0525 08:34:50.615098 20349 solver.cpp:237] Iteration 67562, loss = 1.11419
I0525 08:34:50.615269 20349 solver.cpp:253]     Train net output #0: loss = 1.11419 (* 1 = 1.11419 loss)
I0525 08:34:50.615283 20349 sgd_solver.cpp:106] Iteration 67562, lr = 0.0025
I0525 08:34:59.441732 20349 solver.cpp:237] Iteration 67728, loss = 1.08919
I0525 08:34:59.441772 20349 solver.cpp:253]     Train net output #0: loss = 1.08919 (* 1 = 1.08919 loss)
I0525 08:34:59.441795 20349 sgd_solver.cpp:106] Iteration 67728, lr = 0.0025
I0525 08:35:29.122743 20349 solver.cpp:237] Iteration 67894, loss = 0.95306
I0525 08:35:29.122937 20349 solver.cpp:253]     Train net output #0: loss = 0.95306 (* 1 = 0.95306 loss)
I0525 08:35:29.122952 20349 sgd_solver.cpp:106] Iteration 67894, lr = 0.0025
I0525 08:35:37.952754 20349 solver.cpp:237] Iteration 68060, loss = 1.09776
I0525 08:35:37.952788 20349 solver.cpp:253]     Train net output #0: loss = 1.09776 (* 1 = 1.09776 loss)
I0525 08:35:37.952805 20349 sgd_solver.cpp:106] Iteration 68060, lr = 0.0025
I0525 08:35:46.772943 20349 solver.cpp:237] Iteration 68226, loss = 0.998612
I0525 08:35:46.772989 20349 solver.cpp:253]     Train net output #0: loss = 0.998612 (* 1 = 0.998612 loss)
I0525 08:35:46.773005 20349 sgd_solver.cpp:106] Iteration 68226, lr = 0.0025
I0525 08:35:50.970552 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_68306.caffemodel
I0525 08:35:51.044695 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_68306.solverstate
I0525 08:35:55.659505 20349 solver.cpp:237] Iteration 68392, loss = 1.15865
I0525 08:35:55.659549 20349 solver.cpp:253]     Train net output #0: loss = 1.15865 (* 1 = 1.15865 loss)
I0525 08:35:55.659569 20349 sgd_solver.cpp:106] Iteration 68392, lr = 0.0025
I0525 08:36:04.476692 20349 solver.cpp:237] Iteration 68558, loss = 1.29144
I0525 08:36:04.476871 20349 solver.cpp:253]     Train net output #0: loss = 1.29144 (* 1 = 1.29144 loss)
I0525 08:36:04.476883 20349 sgd_solver.cpp:106] Iteration 68558, lr = 0.0025
I0525 08:36:13.300143 20349 solver.cpp:237] Iteration 68724, loss = 1.21848
I0525 08:36:13.300184 20349 solver.cpp:253]     Train net output #0: loss = 1.21848 (* 1 = 1.21848 loss)
I0525 08:36:13.300205 20349 sgd_solver.cpp:106] Iteration 68724, lr = 0.0025
I0525 08:36:42.985841 20349 solver.cpp:237] Iteration 68890, loss = 1.37526
I0525 08:36:42.986040 20349 solver.cpp:253]     Train net output #0: loss = 1.37526 (* 1 = 1.37526 loss)
I0525 08:36:42.986054 20349 sgd_solver.cpp:106] Iteration 68890, lr = 0.0025
I0525 08:36:51.810956 20349 solver.cpp:237] Iteration 69056, loss = 1.07141
I0525 08:36:51.810989 20349 solver.cpp:253]     Train net output #0: loss = 1.07141 (* 1 = 1.07141 loss)
I0525 08:36:51.811003 20349 sgd_solver.cpp:106] Iteration 69056, lr = 0.0025
I0525 08:37:00.631536 20349 solver.cpp:237] Iteration 69222, loss = 0.988116
I0525 08:37:00.631572 20349 solver.cpp:253]     Train net output #0: loss = 0.988116 (* 1 = 0.988116 loss)
I0525 08:37:00.631587 20349 sgd_solver.cpp:106] Iteration 69222, lr = 0.0025
I0525 08:37:09.454207 20349 solver.cpp:237] Iteration 69388, loss = 1.30699
I0525 08:37:09.454249 20349 solver.cpp:253]     Train net output #0: loss = 1.30699 (* 1 = 1.30699 loss)
I0525 08:37:09.454268 20349 sgd_solver.cpp:106] Iteration 69388, lr = 0.0025
I0525 08:37:18.276882 20349 solver.cpp:237] Iteration 69554, loss = 1.20109
I0525 08:37:18.277065 20349 solver.cpp:253]     Train net output #0: loss = 1.20109 (* 1 = 1.20109 loss)
I0525 08:37:18.277079 20349 sgd_solver.cpp:106] Iteration 69554, lr = 0.0025
I0525 08:37:27.098249 20349 solver.cpp:237] Iteration 69720, loss = 1.07394
I0525 08:37:27.098292 20349 solver.cpp:253]     Train net output #0: loss = 1.07394 (* 1 = 1.07394 loss)
I0525 08:37:27.098312 20349 sgd_solver.cpp:106] Iteration 69720, lr = 0.0025
I0525 08:37:35.926071 20349 solver.cpp:237] Iteration 69886, loss = 1.41886
I0525 08:37:35.926107 20349 solver.cpp:253]     Train net output #0: loss = 1.41886 (* 1 = 1.41886 loss)
I0525 08:37:35.926123 20349 sgd_solver.cpp:106] Iteration 69886, lr = 0.0025
I0525 08:37:40.448448 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_69972.caffemodel
I0525 08:37:40.522589 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_69972.solverstate
I0525 08:37:41.628877 20349 solver.cpp:341] Iteration 69993, Testing net (#0)
I0525 08:38:28.814898 20349 solver.cpp:409]     Test net output #0: accuracy = 0.885004
I0525 08:38:28.815090 20349 solver.cpp:409]     Test net output #1: loss = 0.374784 (* 1 = 0.374784 loss)
I0525 08:38:52.818027 20349 solver.cpp:237] Iteration 70052, loss = 1.14099
I0525 08:38:52.818076 20349 solver.cpp:253]     Train net output #0: loss = 1.14099 (* 1 = 1.14099 loss)
I0525 08:38:52.818094 20349 sgd_solver.cpp:106] Iteration 70052, lr = 0.0025
I0525 08:39:01.650888 20349 solver.cpp:237] Iteration 70218, loss = 1.04491
I0525 08:39:01.651067 20349 solver.cpp:253]     Train net output #0: loss = 1.04491 (* 1 = 1.04491 loss)
I0525 08:39:01.651079 20349 sgd_solver.cpp:106] Iteration 70218, lr = 0.0025
I0525 08:39:10.484808 20349 solver.cpp:237] Iteration 70384, loss = 1.17741
I0525 08:39:10.484853 20349 solver.cpp:253]     Train net output #0: loss = 1.17741 (* 1 = 1.17741 loss)
I0525 08:39:10.484871 20349 sgd_solver.cpp:106] Iteration 70384, lr = 0.0025
I0525 08:39:19.314872 20349 solver.cpp:237] Iteration 70550, loss = 1.19392
I0525 08:39:19.314908 20349 solver.cpp:253]     Train net output #0: loss = 1.19392 (* 1 = 1.19392 loss)
I0525 08:39:19.314924 20349 sgd_solver.cpp:106] Iteration 70550, lr = 0.0025
I0525 08:39:28.155586 20349 solver.cpp:237] Iteration 70716, loss = 1.06852
I0525 08:39:28.155621 20349 solver.cpp:253]     Train net output #0: loss = 1.06852 (* 1 = 1.06852 loss)
I0525 08:39:28.155637 20349 sgd_solver.cpp:106] Iteration 70716, lr = 0.0025
I0525 08:39:37.001593 20349 solver.cpp:237] Iteration 70882, loss = 1.09601
I0525 08:39:37.001785 20349 solver.cpp:253]     Train net output #0: loss = 1.09601 (* 1 = 1.09601 loss)
I0525 08:39:37.001799 20349 sgd_solver.cpp:106] Iteration 70882, lr = 0.0025
I0525 08:39:45.833724 20349 solver.cpp:237] Iteration 71048, loss = 1.20294
I0525 08:39:45.833758 20349 solver.cpp:253]     Train net output #0: loss = 1.20294 (* 1 = 1.20294 loss)
I0525 08:39:45.833776 20349 sgd_solver.cpp:106] Iteration 71048, lr = 0.0025
I0525 08:40:15.546479 20349 solver.cpp:237] Iteration 71214, loss = 1.10236
I0525 08:40:15.546676 20349 solver.cpp:253]     Train net output #0: loss = 1.10236 (* 1 = 1.10236 loss)
I0525 08:40:15.546691 20349 sgd_solver.cpp:106] Iteration 71214, lr = 0.0025
I0525 08:40:24.386668 20349 solver.cpp:237] Iteration 71380, loss = 1.10693
I0525 08:40:24.386714 20349 solver.cpp:253]     Train net output #0: loss = 1.10693 (* 1 = 1.10693 loss)
I0525 08:40:24.386731 20349 sgd_solver.cpp:106] Iteration 71380, lr = 0.0025
I0525 08:40:33.223690 20349 solver.cpp:237] Iteration 71546, loss = 1.09788
I0525 08:40:33.223726 20349 solver.cpp:253]     Train net output #0: loss = 1.09788 (* 1 = 1.09788 loss)
I0525 08:40:33.223738 20349 sgd_solver.cpp:106] Iteration 71546, lr = 0.0025
I0525 08:40:38.073099 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_71638.caffemodel
I0525 08:40:38.147764 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_71638.solverstate
I0525 08:40:42.131743 20349 solver.cpp:237] Iteration 71712, loss = 1.36834
I0525 08:40:42.131793 20349 solver.cpp:253]     Train net output #0: loss = 1.36834 (* 1 = 1.36834 loss)
I0525 08:40:42.131806 20349 sgd_solver.cpp:106] Iteration 71712, lr = 0.0025
I0525 08:40:50.965078 20349 solver.cpp:237] Iteration 71878, loss = 1.11206
I0525 08:40:50.965277 20349 solver.cpp:253]     Train net output #0: loss = 1.11206 (* 1 = 1.11206 loss)
I0525 08:40:50.965291 20349 sgd_solver.cpp:106] Iteration 71878, lr = 0.0025
I0525 08:40:59.795228 20349 solver.cpp:237] Iteration 72044, loss = 1.20681
I0525 08:40:59.795263 20349 solver.cpp:253]     Train net output #0: loss = 1.20681 (* 1 = 1.20681 loss)
I0525 08:40:59.795280 20349 sgd_solver.cpp:106] Iteration 72044, lr = 0.0025
I0525 08:41:08.634091 20349 solver.cpp:237] Iteration 72210, loss = 1.08533
I0525 08:41:08.634125 20349 solver.cpp:253]     Train net output #0: loss = 1.08533 (* 1 = 1.08533 loss)
I0525 08:41:08.634141 20349 sgd_solver.cpp:106] Iteration 72210, lr = 0.0025
I0525 08:41:38.337390 20349 solver.cpp:237] Iteration 72376, loss = 1.36004
I0525 08:41:38.337594 20349 solver.cpp:253]     Train net output #0: loss = 1.36004 (* 1 = 1.36004 loss)
I0525 08:41:38.337609 20349 sgd_solver.cpp:106] Iteration 72376, lr = 0.0025
I0525 08:41:47.168894 20349 solver.cpp:237] Iteration 72542, loss = 1.17844
I0525 08:41:47.168928 20349 solver.cpp:253]     Train net output #0: loss = 1.17844 (* 1 = 1.17844 loss)
I0525 08:41:47.168944 20349 sgd_solver.cpp:106] Iteration 72542, lr = 0.0025
I0525 08:41:55.998594 20349 solver.cpp:237] Iteration 72708, loss = 0.867594
I0525 08:41:55.998631 20349 solver.cpp:253]     Train net output #0: loss = 0.867594 (* 1 = 0.867594 loss)
I0525 08:41:55.998646 20349 sgd_solver.cpp:106] Iteration 72708, lr = 0.0025
I0525 08:42:04.832099 20349 solver.cpp:237] Iteration 72874, loss = 1.21943
I0525 08:42:04.832141 20349 solver.cpp:253]     Train net output #0: loss = 1.21943 (* 1 = 1.21943 loss)
I0525 08:42:04.832161 20349 sgd_solver.cpp:106] Iteration 72874, lr = 0.0025
I0525 08:42:13.668103 20349 solver.cpp:237] Iteration 73040, loss = 1.18319
I0525 08:42:13.668278 20349 solver.cpp:253]     Train net output #0: loss = 1.18319 (* 1 = 1.18319 loss)
I0525 08:42:13.668292 20349 sgd_solver.cpp:106] Iteration 73040, lr = 0.0025
I0525 08:42:22.486064 20349 solver.cpp:237] Iteration 73206, loss = 1.09647
I0525 08:42:22.486099 20349 solver.cpp:253]     Train net output #0: loss = 1.09647 (* 1 = 1.09647 loss)
I0525 08:42:22.486114 20349 sgd_solver.cpp:106] Iteration 73206, lr = 0.0025
I0525 08:42:27.643463 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_73304.caffemodel
I0525 08:42:27.718835 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_73304.solverstate
I0525 08:42:28.880105 20349 solver.cpp:341] Iteration 73326, Testing net (#0)
I0525 08:43:36.958590 20349 solver.cpp:409]     Test net output #0: accuracy = 0.891648
I0525 08:43:36.958798 20349 solver.cpp:409]     Test net output #1: loss = 0.361994 (* 1 = 0.361994 loss)
I0525 08:44:00.299028 20349 solver.cpp:237] Iteration 73372, loss = 1.32368
I0525 08:44:00.299078 20349 solver.cpp:253]     Train net output #0: loss = 1.32368 (* 1 = 1.32368 loss)
I0525 08:44:00.299093 20349 sgd_solver.cpp:106] Iteration 73372, lr = 0.0025
I0525 08:44:09.129158 20349 solver.cpp:237] Iteration 73538, loss = 1.00772
I0525 08:44:09.129353 20349 solver.cpp:253]     Train net output #0: loss = 1.00772 (* 1 = 1.00772 loss)
I0525 08:44:09.129367 20349 sgd_solver.cpp:106] Iteration 73538, lr = 0.0025
I0525 08:44:17.944747 20349 solver.cpp:237] Iteration 73704, loss = 1.10849
I0525 08:44:17.944782 20349 solver.cpp:253]     Train net output #0: loss = 1.10849 (* 1 = 1.10849 loss)
I0525 08:44:17.944798 20349 sgd_solver.cpp:106] Iteration 73704, lr = 0.0025
I0525 08:44:26.770416 20349 solver.cpp:237] Iteration 73870, loss = 1.27838
I0525 08:44:26.770450 20349 solver.cpp:253]     Train net output #0: loss = 1.27838 (* 1 = 1.27838 loss)
I0525 08:44:26.770467 20349 sgd_solver.cpp:106] Iteration 73870, lr = 0.0025
I0525 08:44:35.599310 20349 solver.cpp:237] Iteration 74036, loss = 1.25352
I0525 08:44:35.599354 20349 solver.cpp:253]     Train net output #0: loss = 1.25352 (* 1 = 1.25352 loss)
I0525 08:44:35.599370 20349 sgd_solver.cpp:106] Iteration 74036, lr = 0.0025
I0525 08:44:44.419054 20349 solver.cpp:237] Iteration 74202, loss = 1.1476
I0525 08:44:44.419236 20349 solver.cpp:253]     Train net output #0: loss = 1.1476 (* 1 = 1.1476 loss)
I0525 08:44:44.419251 20349 sgd_solver.cpp:106] Iteration 74202, lr = 0.0025
I0525 08:44:53.241473 20349 solver.cpp:237] Iteration 74368, loss = 1.15732
I0525 08:44:53.241508 20349 solver.cpp:253]     Train net output #0: loss = 1.15732 (* 1 = 1.15732 loss)
I0525 08:44:53.241525 20349 sgd_solver.cpp:106] Iteration 74368, lr = 0.0025
I0525 08:45:22.938263 20349 solver.cpp:237] Iteration 74534, loss = 1.22375
I0525 08:45:22.938462 20349 solver.cpp:253]     Train net output #0: loss = 1.22375 (* 1 = 1.22375 loss)
I0525 08:45:22.938477 20349 sgd_solver.cpp:106] Iteration 74534, lr = 0.0025
I0525 08:45:31.758724 20349 solver.cpp:237] Iteration 74700, loss = 1.00795
I0525 08:45:31.758759 20349 solver.cpp:253]     Train net output #0: loss = 1.00795 (* 1 = 1.00795 loss)
I0525 08:45:31.758776 20349 sgd_solver.cpp:106] Iteration 74700, lr = 0.0025
I0525 08:45:40.572893 20349 solver.cpp:237] Iteration 74866, loss = 1.09982
I0525 08:45:40.572928 20349 solver.cpp:253]     Train net output #0: loss = 1.09982 (* 1 = 1.09982 loss)
I0525 08:45:40.572944 20349 sgd_solver.cpp:106] Iteration 74866, lr = 0.0025
I0525 08:45:46.044102 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_74970.caffemodel
I0525 08:45:46.121628 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_74970.solverstate
I0525 08:45:49.461096 20349 solver.cpp:237] Iteration 75032, loss = 1.01126
I0525 08:45:49.461144 20349 solver.cpp:253]     Train net output #0: loss = 1.01126 (* 1 = 1.01126 loss)
I0525 08:45:49.461161 20349 sgd_solver.cpp:106] Iteration 75032, lr = 0.0025
I0525 08:45:58.276921 20349 solver.cpp:237] Iteration 75198, loss = 1.04241
I0525 08:45:58.277102 20349 solver.cpp:253]     Train net output #0: loss = 1.04241 (* 1 = 1.04241 loss)
I0525 08:45:58.277117 20349 sgd_solver.cpp:106] Iteration 75198, lr = 0.0025
I0525 08:46:07.103174 20349 solver.cpp:237] Iteration 75364, loss = 1.21371
I0525 08:46:07.103205 20349 solver.cpp:253]     Train net output #0: loss = 1.21371 (* 1 = 1.21371 loss)
I0525 08:46:07.103222 20349 sgd_solver.cpp:106] Iteration 75364, lr = 0.0025
I0525 08:46:15.928103 20349 solver.cpp:237] Iteration 75530, loss = 1.13491
I0525 08:46:15.928154 20349 solver.cpp:253]     Train net output #0: loss = 1.13491 (* 1 = 1.13491 loss)
I0525 08:46:15.928169 20349 sgd_solver.cpp:106] Iteration 75530, lr = 0.0025
I0525 08:46:45.607115 20349 solver.cpp:237] Iteration 75696, loss = 1.19075
I0525 08:46:45.607337 20349 solver.cpp:253]     Train net output #0: loss = 1.19075 (* 1 = 1.19075 loss)
I0525 08:46:45.607352 20349 sgd_solver.cpp:106] Iteration 75696, lr = 0.0025
I0525 08:46:54.431433 20349 solver.cpp:237] Iteration 75862, loss = 1.04347
I0525 08:46:54.431468 20349 solver.cpp:253]     Train net output #0: loss = 1.04347 (* 1 = 1.04347 loss)
I0525 08:46:54.431485 20349 sgd_solver.cpp:106] Iteration 75862, lr = 0.0025
I0525 08:47:03.257890 20349 solver.cpp:237] Iteration 76028, loss = 1.18474
I0525 08:47:03.257938 20349 solver.cpp:253]     Train net output #0: loss = 1.18474 (* 1 = 1.18474 loss)
I0525 08:47:03.257952 20349 sgd_solver.cpp:106] Iteration 76028, lr = 0.0025
I0525 08:47:12.082020 20349 solver.cpp:237] Iteration 76194, loss = 1.04242
I0525 08:47:12.082056 20349 solver.cpp:253]     Train net output #0: loss = 1.04242 (* 1 = 1.04242 loss)
I0525 08:47:12.082070 20349 sgd_solver.cpp:106] Iteration 76194, lr = 0.0025
I0525 08:47:20.907704 20349 solver.cpp:237] Iteration 76360, loss = 1.28531
I0525 08:47:20.907884 20349 solver.cpp:253]     Train net output #0: loss = 1.28531 (* 1 = 1.28531 loss)
I0525 08:47:20.907897 20349 sgd_solver.cpp:106] Iteration 76360, lr = 0.0025
I0525 08:47:29.729475 20349 solver.cpp:237] Iteration 76526, loss = 1.12558
I0525 08:47:29.729511 20349 solver.cpp:253]     Train net output #0: loss = 1.12558 (* 1 = 1.12558 loss)
I0525 08:47:29.729533 20349 sgd_solver.cpp:106] Iteration 76526, lr = 0.0025
I0525 08:47:35.523360 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_76636.caffemodel
I0525 08:47:35.598708 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_76636.solverstate
I0525 08:47:36.812572 20349 solver.cpp:341] Iteration 76659, Testing net (#0)
I0525 08:48:23.643486 20349 solver.cpp:409]     Test net output #0: accuracy = 0.893088
I0525 08:48:23.643681 20349 solver.cpp:409]     Test net output #1: loss = 0.345683 (* 1 = 0.345683 loss)
I0525 08:48:46.268518 20349 solver.cpp:237] Iteration 76692, loss = 1.08731
I0525 08:48:46.268569 20349 solver.cpp:253]     Train net output #0: loss = 1.08731 (* 1 = 1.08731 loss)
I0525 08:48:46.268584 20349 sgd_solver.cpp:106] Iteration 76692, lr = 0.0025
I0525 08:48:55.082453 20349 solver.cpp:237] Iteration 76858, loss = 1.19695
I0525 08:48:55.082638 20349 solver.cpp:253]     Train net output #0: loss = 1.19695 (* 1 = 1.19695 loss)
I0525 08:48:55.082650 20349 sgd_solver.cpp:106] Iteration 76858, lr = 0.0025
I0525 08:49:03.908929 20349 solver.cpp:237] Iteration 77024, loss = 1.16136
I0525 08:49:03.908964 20349 solver.cpp:253]     Train net output #0: loss = 1.16136 (* 1 = 1.16136 loss)
I0525 08:49:03.908978 20349 sgd_solver.cpp:106] Iteration 77024, lr = 0.0025
I0525 08:49:12.732264 20349 solver.cpp:237] Iteration 77190, loss = 1.1399
I0525 08:49:12.732298 20349 solver.cpp:253]     Train net output #0: loss = 1.1399 (* 1 = 1.1399 loss)
I0525 08:49:12.732319 20349 sgd_solver.cpp:106] Iteration 77190, lr = 0.0025
I0525 08:49:21.553632 20349 solver.cpp:237] Iteration 77356, loss = 1.21838
I0525 08:49:21.553666 20349 solver.cpp:253]     Train net output #0: loss = 1.21838 (* 1 = 1.21838 loss)
I0525 08:49:21.553683 20349 sgd_solver.cpp:106] Iteration 77356, lr = 0.0025
I0525 08:49:30.382336 20349 solver.cpp:237] Iteration 77522, loss = 1.29336
I0525 08:49:30.382524 20349 solver.cpp:253]     Train net output #0: loss = 1.29336 (* 1 = 1.29336 loss)
I0525 08:49:30.382537 20349 sgd_solver.cpp:106] Iteration 77522, lr = 0.0025
I0525 08:49:39.205770 20349 solver.cpp:237] Iteration 77688, loss = 1.20135
I0525 08:49:39.205802 20349 solver.cpp:253]     Train net output #0: loss = 1.20135 (* 1 = 1.20135 loss)
I0525 08:49:39.205826 20349 sgd_solver.cpp:106] Iteration 77688, lr = 0.0025
I0525 08:50:08.851670 20349 solver.cpp:237] Iteration 77854, loss = 1.10114
I0525 08:50:08.851879 20349 solver.cpp:253]     Train net output #0: loss = 1.10114 (* 1 = 1.10114 loss)
I0525 08:50:08.851896 20349 sgd_solver.cpp:106] Iteration 77854, lr = 0.0025
I0525 08:50:17.679227 20349 solver.cpp:237] Iteration 78020, loss = 1.1296
I0525 08:50:17.679262 20349 solver.cpp:253]     Train net output #0: loss = 1.1296 (* 1 = 1.1296 loss)
I0525 08:50:17.679278 20349 sgd_solver.cpp:106] Iteration 78020, lr = 0.0025
I0525 08:50:26.504803 20349 solver.cpp:237] Iteration 78186, loss = 1.0907
I0525 08:50:26.504851 20349 solver.cpp:253]     Train net output #0: loss = 1.0907 (* 1 = 1.0907 loss)
I0525 08:50:26.504866 20349 sgd_solver.cpp:106] Iteration 78186, lr = 0.0025
I0525 08:50:32.612553 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_78302.caffemodel
I0525 08:50:32.688534 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_78302.solverstate
I0525 08:50:35.387449 20349 solver.cpp:237] Iteration 78352, loss = 1.31945
I0525 08:50:35.387492 20349 solver.cpp:253]     Train net output #0: loss = 1.31945 (* 1 = 1.31945 loss)
I0525 08:50:35.387511 20349 sgd_solver.cpp:106] Iteration 78352, lr = 0.0025
I0525 08:50:44.207903 20349 solver.cpp:237] Iteration 78518, loss = 1.33705
I0525 08:50:44.208086 20349 solver.cpp:253]     Train net output #0: loss = 1.33705 (* 1 = 1.33705 loss)
I0525 08:50:44.208101 20349 sgd_solver.cpp:106] Iteration 78518, lr = 0.0025
I0525 08:50:53.029973 20349 solver.cpp:237] Iteration 78684, loss = 1.14279
I0525 08:50:53.030009 20349 solver.cpp:253]     Train net output #0: loss = 1.14279 (* 1 = 1.14279 loss)
I0525 08:50:53.030030 20349 sgd_solver.cpp:106] Iteration 78684, lr = 0.0025
I0525 08:51:01.855595 20349 solver.cpp:237] Iteration 78850, loss = 1.16993
I0525 08:51:01.855630 20349 solver.cpp:253]     Train net output #0: loss = 1.16993 (* 1 = 1.16993 loss)
I0525 08:51:01.855644 20349 sgd_solver.cpp:106] Iteration 78850, lr = 0.0025
I0525 08:51:31.509320 20349 solver.cpp:237] Iteration 79016, loss = 1.086
I0525 08:51:31.509526 20349 solver.cpp:253]     Train net output #0: loss = 1.086 (* 1 = 1.086 loss)
I0525 08:51:31.509542 20349 sgd_solver.cpp:106] Iteration 79016, lr = 0.0025
I0525 08:51:40.332726 20349 solver.cpp:237] Iteration 79182, loss = 1.17665
I0525 08:51:40.332767 20349 solver.cpp:253]     Train net output #0: loss = 1.17665 (* 1 = 1.17665 loss)
I0525 08:51:40.332784 20349 sgd_solver.cpp:106] Iteration 79182, lr = 0.0025
I0525 08:51:49.162405 20349 solver.cpp:237] Iteration 79348, loss = 0.999069
I0525 08:51:49.162442 20349 solver.cpp:253]     Train net output #0: loss = 0.999069 (* 1 = 0.999069 loss)
I0525 08:51:49.162458 20349 sgd_solver.cpp:106] Iteration 79348, lr = 0.0025
I0525 08:51:57.980662 20349 solver.cpp:237] Iteration 79514, loss = 0.921945
I0525 08:51:57.980697 20349 solver.cpp:253]     Train net output #0: loss = 0.921945 (* 1 = 0.921945 loss)
I0525 08:51:57.980713 20349 sgd_solver.cpp:106] Iteration 79514, lr = 0.0025
I0525 08:52:06.806902 20349 solver.cpp:237] Iteration 79680, loss = 1.16002
I0525 08:52:06.807096 20349 solver.cpp:253]     Train net output #0: loss = 1.16002 (* 1 = 1.16002 loss)
I0525 08:52:06.807109 20349 sgd_solver.cpp:106] Iteration 79680, lr = 0.0025
I0525 08:52:15.630187 20349 solver.cpp:237] Iteration 79846, loss = 1.052
I0525 08:52:15.630221 20349 solver.cpp:253]     Train net output #0: loss = 1.052 (* 1 = 1.052 loss)
I0525 08:52:15.630236 20349 sgd_solver.cpp:106] Iteration 79846, lr = 0.0025
I0525 08:52:22.065765 20349 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_79968.caffemodel
I0525 08:52:22.140406 20349 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0025_2016-05-20T15.49.21.668786_iter_79968.solverstate
I0525 08:52:23.405407 20349 solver.cpp:341] Iteration 79992, Testing net (#0)
aprun: Apid 11262851: Caught signal Terminated, sending to application
*** Aborted at 1464180779 (unix time) try "date -d @1464180779" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x4f7a) received by PID 20349 (TID 0x2aaac746f900) from PID 20346; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7204 exceeded limit 7200
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @           0x5ca001 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11262851: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
aprun: Apid 11262851: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02351] [c6-1c0s7n3] [Wed May 25 08:53:01 2016] PE RANK 0 exit signal Terminated
Application 11262851 exit codes: 143
Application 11262851 resources: utime ~6220s, stime ~976s, Rss ~5332588, inblocks ~16311171, outblocks ~740498
