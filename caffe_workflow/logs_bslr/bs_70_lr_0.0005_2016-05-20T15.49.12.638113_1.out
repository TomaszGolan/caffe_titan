2809108
I0523 22:01:58.388116 23120 caffe.cpp:184] Using GPUs 0
I0523 22:01:58.815516 23120 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2142
test_interval: 4285
base_lr: 0.0005
display: 214
max_iter: 214280
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2142
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113.prototxt"
I0523 22:01:58.817322 23120 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113.prototxt
I0523 22:01:58.830641 23120 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 22:01:58.830701 23120 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 22:01:58.831050 23120 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 22:01:58.831230 23120 layer_factory.hpp:77] Creating layer data_hdf5
I0523 22:01:58.831255 23120 net.cpp:106] Creating Layer data_hdf5
I0523 22:01:58.831269 23120 net.cpp:411] data_hdf5 -> data
I0523 22:01:58.831303 23120 net.cpp:411] data_hdf5 -> label
I0523 22:01:58.831336 23120 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 22:01:58.841480 23120 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 22:01:58.850502 23120 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 22:02:20.413781 23120 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 22:02:20.418992 23120 net.cpp:150] Setting up data_hdf5
I0523 22:02:20.419036 23120 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0523 22:02:20.419050 23120 net.cpp:157] Top shape: 70 (70)
I0523 22:02:20.419060 23120 net.cpp:165] Memory required for data: 1778280
I0523 22:02:20.419073 23120 layer_factory.hpp:77] Creating layer conv1
I0523 22:02:20.419107 23120 net.cpp:106] Creating Layer conv1
I0523 22:02:20.419119 23120 net.cpp:454] conv1 <- data
I0523 22:02:20.419142 23120 net.cpp:411] conv1 -> conv1
I0523 22:02:23.250339 23120 net.cpp:150] Setting up conv1
I0523 22:02:23.250386 23120 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0523 22:02:23.250397 23120 net.cpp:165] Memory required for data: 21131880
I0523 22:02:23.250425 23120 layer_factory.hpp:77] Creating layer relu1
I0523 22:02:23.250447 23120 net.cpp:106] Creating Layer relu1
I0523 22:02:23.250458 23120 net.cpp:454] relu1 <- conv1
I0523 22:02:23.250471 23120 net.cpp:397] relu1 -> conv1 (in-place)
I0523 22:02:23.250988 23120 net.cpp:150] Setting up relu1
I0523 22:02:23.251003 23120 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0523 22:02:23.251014 23120 net.cpp:165] Memory required for data: 40485480
I0523 22:02:23.251025 23120 layer_factory.hpp:77] Creating layer pool1
I0523 22:02:23.251042 23120 net.cpp:106] Creating Layer pool1
I0523 22:02:23.251051 23120 net.cpp:454] pool1 <- conv1
I0523 22:02:23.251065 23120 net.cpp:411] pool1 -> pool1
I0523 22:02:23.251145 23120 net.cpp:150] Setting up pool1
I0523 22:02:23.251160 23120 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0523 22:02:23.251169 23120 net.cpp:165] Memory required for data: 50162280
I0523 22:02:23.251180 23120 layer_factory.hpp:77] Creating layer conv2
I0523 22:02:23.251202 23120 net.cpp:106] Creating Layer conv2
I0523 22:02:23.251219 23120 net.cpp:454] conv2 <- pool1
I0523 22:02:23.251230 23120 net.cpp:411] conv2 -> conv2
I0523 22:02:23.253979 23120 net.cpp:150] Setting up conv2
I0523 22:02:23.254007 23120 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0523 22:02:23.254019 23120 net.cpp:165] Memory required for data: 64072680
I0523 22:02:23.254037 23120 layer_factory.hpp:77] Creating layer relu2
I0523 22:02:23.254051 23120 net.cpp:106] Creating Layer relu2
I0523 22:02:23.254061 23120 net.cpp:454] relu2 <- conv2
I0523 22:02:23.254075 23120 net.cpp:397] relu2 -> conv2 (in-place)
I0523 22:02:23.254405 23120 net.cpp:150] Setting up relu2
I0523 22:02:23.254420 23120 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0523 22:02:23.254429 23120 net.cpp:165] Memory required for data: 77983080
I0523 22:02:23.254439 23120 layer_factory.hpp:77] Creating layer pool2
I0523 22:02:23.254452 23120 net.cpp:106] Creating Layer pool2
I0523 22:02:23.254462 23120 net.cpp:454] pool2 <- conv2
I0523 22:02:23.254474 23120 net.cpp:411] pool2 -> pool2
I0523 22:02:23.254556 23120 net.cpp:150] Setting up pool2
I0523 22:02:23.254570 23120 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0523 22:02:23.254580 23120 net.cpp:165] Memory required for data: 84938280
I0523 22:02:23.254590 23120 layer_factory.hpp:77] Creating layer conv3
I0523 22:02:23.254606 23120 net.cpp:106] Creating Layer conv3
I0523 22:02:23.254616 23120 net.cpp:454] conv3 <- pool2
I0523 22:02:23.254628 23120 net.cpp:411] conv3 -> conv3
I0523 22:02:23.256548 23120 net.cpp:150] Setting up conv3
I0523 22:02:23.256572 23120 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0523 22:02:23.256583 23120 net.cpp:165] Memory required for data: 92527400
I0523 22:02:23.256603 23120 layer_factory.hpp:77] Creating layer relu3
I0523 22:02:23.256618 23120 net.cpp:106] Creating Layer relu3
I0523 22:02:23.256628 23120 net.cpp:454] relu3 <- conv3
I0523 22:02:23.256640 23120 net.cpp:397] relu3 -> conv3 (in-place)
I0523 22:02:23.257107 23120 net.cpp:150] Setting up relu3
I0523 22:02:23.257125 23120 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0523 22:02:23.257135 23120 net.cpp:165] Memory required for data: 100116520
I0523 22:02:23.257146 23120 layer_factory.hpp:77] Creating layer pool3
I0523 22:02:23.257159 23120 net.cpp:106] Creating Layer pool3
I0523 22:02:23.257169 23120 net.cpp:454] pool3 <- conv3
I0523 22:02:23.257181 23120 net.cpp:411] pool3 -> pool3
I0523 22:02:23.257249 23120 net.cpp:150] Setting up pool3
I0523 22:02:23.257262 23120 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0523 22:02:23.257272 23120 net.cpp:165] Memory required for data: 103911080
I0523 22:02:23.257282 23120 layer_factory.hpp:77] Creating layer conv4
I0523 22:02:23.257297 23120 net.cpp:106] Creating Layer conv4
I0523 22:02:23.257308 23120 net.cpp:454] conv4 <- pool3
I0523 22:02:23.257321 23120 net.cpp:411] conv4 -> conv4
I0523 22:02:23.260123 23120 net.cpp:150] Setting up conv4
I0523 22:02:23.260152 23120 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0523 22:02:23.260162 23120 net.cpp:165] Memory required for data: 106451240
I0523 22:02:23.260179 23120 layer_factory.hpp:77] Creating layer relu4
I0523 22:02:23.260192 23120 net.cpp:106] Creating Layer relu4
I0523 22:02:23.260202 23120 net.cpp:454] relu4 <- conv4
I0523 22:02:23.260215 23120 net.cpp:397] relu4 -> conv4 (in-place)
I0523 22:02:23.260694 23120 net.cpp:150] Setting up relu4
I0523 22:02:23.260710 23120 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0523 22:02:23.260720 23120 net.cpp:165] Memory required for data: 108991400
I0523 22:02:23.260731 23120 layer_factory.hpp:77] Creating layer pool4
I0523 22:02:23.260745 23120 net.cpp:106] Creating Layer pool4
I0523 22:02:23.260754 23120 net.cpp:454] pool4 <- conv4
I0523 22:02:23.260767 23120 net.cpp:411] pool4 -> pool4
I0523 22:02:23.260835 23120 net.cpp:150] Setting up pool4
I0523 22:02:23.260848 23120 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0523 22:02:23.260859 23120 net.cpp:165] Memory required for data: 110261480
I0523 22:02:23.260869 23120 layer_factory.hpp:77] Creating layer ip1
I0523 22:02:23.260890 23120 net.cpp:106] Creating Layer ip1
I0523 22:02:23.260900 23120 net.cpp:454] ip1 <- pool4
I0523 22:02:23.260913 23120 net.cpp:411] ip1 -> ip1
I0523 22:02:23.276350 23120 net.cpp:150] Setting up ip1
I0523 22:02:23.276379 23120 net.cpp:157] Top shape: 70 196 (13720)
I0523 22:02:23.276391 23120 net.cpp:165] Memory required for data: 110316360
I0523 22:02:23.276413 23120 layer_factory.hpp:77] Creating layer relu5
I0523 22:02:23.276428 23120 net.cpp:106] Creating Layer relu5
I0523 22:02:23.276438 23120 net.cpp:454] relu5 <- ip1
I0523 22:02:23.276451 23120 net.cpp:397] relu5 -> ip1 (in-place)
I0523 22:02:23.276793 23120 net.cpp:150] Setting up relu5
I0523 22:02:23.276808 23120 net.cpp:157] Top shape: 70 196 (13720)
I0523 22:02:23.276818 23120 net.cpp:165] Memory required for data: 110371240
I0523 22:02:23.276829 23120 layer_factory.hpp:77] Creating layer drop1
I0523 22:02:23.276850 23120 net.cpp:106] Creating Layer drop1
I0523 22:02:23.276860 23120 net.cpp:454] drop1 <- ip1
I0523 22:02:23.276872 23120 net.cpp:397] drop1 -> ip1 (in-place)
I0523 22:02:23.276934 23120 net.cpp:150] Setting up drop1
I0523 22:02:23.276947 23120 net.cpp:157] Top shape: 70 196 (13720)
I0523 22:02:23.276957 23120 net.cpp:165] Memory required for data: 110426120
I0523 22:02:23.276968 23120 layer_factory.hpp:77] Creating layer ip2
I0523 22:02:23.276986 23120 net.cpp:106] Creating Layer ip2
I0523 22:02:23.276996 23120 net.cpp:454] ip2 <- ip1
I0523 22:02:23.277009 23120 net.cpp:411] ip2 -> ip2
I0523 22:02:23.277470 23120 net.cpp:150] Setting up ip2
I0523 22:02:23.277482 23120 net.cpp:157] Top shape: 70 98 (6860)
I0523 22:02:23.277493 23120 net.cpp:165] Memory required for data: 110453560
I0523 22:02:23.277508 23120 layer_factory.hpp:77] Creating layer relu6
I0523 22:02:23.277519 23120 net.cpp:106] Creating Layer relu6
I0523 22:02:23.277529 23120 net.cpp:454] relu6 <- ip2
I0523 22:02:23.277541 23120 net.cpp:397] relu6 -> ip2 (in-place)
I0523 22:02:23.278069 23120 net.cpp:150] Setting up relu6
I0523 22:02:23.278085 23120 net.cpp:157] Top shape: 70 98 (6860)
I0523 22:02:23.278096 23120 net.cpp:165] Memory required for data: 110481000
I0523 22:02:23.278107 23120 layer_factory.hpp:77] Creating layer drop2
I0523 22:02:23.278120 23120 net.cpp:106] Creating Layer drop2
I0523 22:02:23.278131 23120 net.cpp:454] drop2 <- ip2
I0523 22:02:23.278142 23120 net.cpp:397] drop2 -> ip2 (in-place)
I0523 22:02:23.278185 23120 net.cpp:150] Setting up drop2
I0523 22:02:23.278198 23120 net.cpp:157] Top shape: 70 98 (6860)
I0523 22:02:23.278209 23120 net.cpp:165] Memory required for data: 110508440
I0523 22:02:23.278219 23120 layer_factory.hpp:77] Creating layer ip3
I0523 22:02:23.278233 23120 net.cpp:106] Creating Layer ip3
I0523 22:02:23.278242 23120 net.cpp:454] ip3 <- ip2
I0523 22:02:23.278255 23120 net.cpp:411] ip3 -> ip3
I0523 22:02:23.278465 23120 net.cpp:150] Setting up ip3
I0523 22:02:23.278476 23120 net.cpp:157] Top shape: 70 11 (770)
I0523 22:02:23.278486 23120 net.cpp:165] Memory required for data: 110511520
I0523 22:02:23.278501 23120 layer_factory.hpp:77] Creating layer drop3
I0523 22:02:23.278514 23120 net.cpp:106] Creating Layer drop3
I0523 22:02:23.278523 23120 net.cpp:454] drop3 <- ip3
I0523 22:02:23.278535 23120 net.cpp:397] drop3 -> ip3 (in-place)
I0523 22:02:23.278575 23120 net.cpp:150] Setting up drop3
I0523 22:02:23.278589 23120 net.cpp:157] Top shape: 70 11 (770)
I0523 22:02:23.278599 23120 net.cpp:165] Memory required for data: 110514600
I0523 22:02:23.278609 23120 layer_factory.hpp:77] Creating layer loss
I0523 22:02:23.278628 23120 net.cpp:106] Creating Layer loss
I0523 22:02:23.278637 23120 net.cpp:454] loss <- ip3
I0523 22:02:23.278650 23120 net.cpp:454] loss <- label
I0523 22:02:23.278661 23120 net.cpp:411] loss -> loss
I0523 22:02:23.278678 23120 layer_factory.hpp:77] Creating layer loss
I0523 22:02:23.279320 23120 net.cpp:150] Setting up loss
I0523 22:02:23.279340 23120 net.cpp:157] Top shape: (1)
I0523 22:02:23.279350 23120 net.cpp:160]     with loss weight 1
I0523 22:02:23.279392 23120 net.cpp:165] Memory required for data: 110514604
I0523 22:02:23.279402 23120 net.cpp:226] loss needs backward computation.
I0523 22:02:23.279413 23120 net.cpp:226] drop3 needs backward computation.
I0523 22:02:23.279422 23120 net.cpp:226] ip3 needs backward computation.
I0523 22:02:23.279433 23120 net.cpp:226] drop2 needs backward computation.
I0523 22:02:23.279443 23120 net.cpp:226] relu6 needs backward computation.
I0523 22:02:23.279451 23120 net.cpp:226] ip2 needs backward computation.
I0523 22:02:23.279461 23120 net.cpp:226] drop1 needs backward computation.
I0523 22:02:23.279471 23120 net.cpp:226] relu5 needs backward computation.
I0523 22:02:23.279480 23120 net.cpp:226] ip1 needs backward computation.
I0523 22:02:23.279490 23120 net.cpp:226] pool4 needs backward computation.
I0523 22:02:23.279501 23120 net.cpp:226] relu4 needs backward computation.
I0523 22:02:23.279511 23120 net.cpp:226] conv4 needs backward computation.
I0523 22:02:23.279521 23120 net.cpp:226] pool3 needs backward computation.
I0523 22:02:23.279531 23120 net.cpp:226] relu3 needs backward computation.
I0523 22:02:23.279551 23120 net.cpp:226] conv3 needs backward computation.
I0523 22:02:23.279561 23120 net.cpp:226] pool2 needs backward computation.
I0523 22:02:23.279572 23120 net.cpp:226] relu2 needs backward computation.
I0523 22:02:23.279582 23120 net.cpp:226] conv2 needs backward computation.
I0523 22:02:23.279592 23120 net.cpp:226] pool1 needs backward computation.
I0523 22:02:23.279602 23120 net.cpp:226] relu1 needs backward computation.
I0523 22:02:23.279610 23120 net.cpp:226] conv1 needs backward computation.
I0523 22:02:23.279621 23120 net.cpp:228] data_hdf5 does not need backward computation.
I0523 22:02:23.279631 23120 net.cpp:270] This network produces output loss
I0523 22:02:23.279655 23120 net.cpp:283] Network initialization done.
I0523 22:02:23.281286 23120 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113.prototxt
I0523 22:02:23.281357 23120 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 22:02:23.281721 23120 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 22:02:23.281911 23120 layer_factory.hpp:77] Creating layer data_hdf5
I0523 22:02:23.281926 23120 net.cpp:106] Creating Layer data_hdf5
I0523 22:02:23.281939 23120 net.cpp:411] data_hdf5 -> data
I0523 22:02:23.281955 23120 net.cpp:411] data_hdf5 -> label
I0523 22:02:23.281971 23120 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 22:02:23.295372 23120 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 22:02:44.678555 23120 net.cpp:150] Setting up data_hdf5
I0523 22:02:44.678720 23120 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0523 22:02:44.678735 23120 net.cpp:157] Top shape: 70 (70)
I0523 22:02:44.678746 23120 net.cpp:165] Memory required for data: 1778280
I0523 22:02:44.678761 23120 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 22:02:44.678787 23120 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 22:02:44.678798 23120 net.cpp:454] label_data_hdf5_1_split <- label
I0523 22:02:44.678813 23120 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 22:02:44.678834 23120 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 22:02:44.678906 23120 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 22:02:44.678920 23120 net.cpp:157] Top shape: 70 (70)
I0523 22:02:44.678932 23120 net.cpp:157] Top shape: 70 (70)
I0523 22:02:44.678941 23120 net.cpp:165] Memory required for data: 1778840
I0523 22:02:44.678951 23120 layer_factory.hpp:77] Creating layer conv1
I0523 22:02:44.678973 23120 net.cpp:106] Creating Layer conv1
I0523 22:02:44.678984 23120 net.cpp:454] conv1 <- data
I0523 22:02:44.678998 23120 net.cpp:411] conv1 -> conv1
I0523 22:02:44.680938 23120 net.cpp:150] Setting up conv1
I0523 22:02:44.680963 23120 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0523 22:02:44.680974 23120 net.cpp:165] Memory required for data: 21132440
I0523 22:02:44.680995 23120 layer_factory.hpp:77] Creating layer relu1
I0523 22:02:44.681010 23120 net.cpp:106] Creating Layer relu1
I0523 22:02:44.681020 23120 net.cpp:454] relu1 <- conv1
I0523 22:02:44.681032 23120 net.cpp:397] relu1 -> conv1 (in-place)
I0523 22:02:44.681532 23120 net.cpp:150] Setting up relu1
I0523 22:02:44.681550 23120 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0523 22:02:44.681560 23120 net.cpp:165] Memory required for data: 40486040
I0523 22:02:44.681571 23120 layer_factory.hpp:77] Creating layer pool1
I0523 22:02:44.681586 23120 net.cpp:106] Creating Layer pool1
I0523 22:02:44.681596 23120 net.cpp:454] pool1 <- conv1
I0523 22:02:44.681608 23120 net.cpp:411] pool1 -> pool1
I0523 22:02:44.681684 23120 net.cpp:150] Setting up pool1
I0523 22:02:44.681696 23120 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0523 22:02:44.681715 23120 net.cpp:165] Memory required for data: 50162840
I0523 22:02:44.681725 23120 layer_factory.hpp:77] Creating layer conv2
I0523 22:02:44.681742 23120 net.cpp:106] Creating Layer conv2
I0523 22:02:44.681752 23120 net.cpp:454] conv2 <- pool1
I0523 22:02:44.681766 23120 net.cpp:411] conv2 -> conv2
I0523 22:02:44.683679 23120 net.cpp:150] Setting up conv2
I0523 22:02:44.683696 23120 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0523 22:02:44.683708 23120 net.cpp:165] Memory required for data: 64073240
I0523 22:02:44.683725 23120 layer_factory.hpp:77] Creating layer relu2
I0523 22:02:44.683738 23120 net.cpp:106] Creating Layer relu2
I0523 22:02:44.683748 23120 net.cpp:454] relu2 <- conv2
I0523 22:02:44.683761 23120 net.cpp:397] relu2 -> conv2 (in-place)
I0523 22:02:44.684093 23120 net.cpp:150] Setting up relu2
I0523 22:02:44.684108 23120 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0523 22:02:44.684118 23120 net.cpp:165] Memory required for data: 77983640
I0523 22:02:44.684128 23120 layer_factory.hpp:77] Creating layer pool2
I0523 22:02:44.684140 23120 net.cpp:106] Creating Layer pool2
I0523 22:02:44.684150 23120 net.cpp:454] pool2 <- conv2
I0523 22:02:44.684164 23120 net.cpp:411] pool2 -> pool2
I0523 22:02:44.684234 23120 net.cpp:150] Setting up pool2
I0523 22:02:44.684247 23120 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0523 22:02:44.684257 23120 net.cpp:165] Memory required for data: 84938840
I0523 22:02:44.684267 23120 layer_factory.hpp:77] Creating layer conv3
I0523 22:02:44.684288 23120 net.cpp:106] Creating Layer conv3
I0523 22:02:44.684298 23120 net.cpp:454] conv3 <- pool2
I0523 22:02:44.684311 23120 net.cpp:411] conv3 -> conv3
I0523 22:02:44.686292 23120 net.cpp:150] Setting up conv3
I0523 22:02:44.686316 23120 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0523 22:02:44.686327 23120 net.cpp:165] Memory required for data: 92527960
I0523 22:02:44.686362 23120 layer_factory.hpp:77] Creating layer relu3
I0523 22:02:44.686375 23120 net.cpp:106] Creating Layer relu3
I0523 22:02:44.686385 23120 net.cpp:454] relu3 <- conv3
I0523 22:02:44.686398 23120 net.cpp:397] relu3 -> conv3 (in-place)
I0523 22:02:44.686874 23120 net.cpp:150] Setting up relu3
I0523 22:02:44.686890 23120 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0523 22:02:44.686900 23120 net.cpp:165] Memory required for data: 100117080
I0523 22:02:44.686910 23120 layer_factory.hpp:77] Creating layer pool3
I0523 22:02:44.686923 23120 net.cpp:106] Creating Layer pool3
I0523 22:02:44.686933 23120 net.cpp:454] pool3 <- conv3
I0523 22:02:44.686946 23120 net.cpp:411] pool3 -> pool3
I0523 22:02:44.687018 23120 net.cpp:150] Setting up pool3
I0523 22:02:44.687031 23120 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0523 22:02:44.687041 23120 net.cpp:165] Memory required for data: 103911640
I0523 22:02:44.687049 23120 layer_factory.hpp:77] Creating layer conv4
I0523 22:02:44.687067 23120 net.cpp:106] Creating Layer conv4
I0523 22:02:44.687078 23120 net.cpp:454] conv4 <- pool3
I0523 22:02:44.687093 23120 net.cpp:411] conv4 -> conv4
I0523 22:02:44.689149 23120 net.cpp:150] Setting up conv4
I0523 22:02:44.689170 23120 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0523 22:02:44.689184 23120 net.cpp:165] Memory required for data: 106451800
I0523 22:02:44.689199 23120 layer_factory.hpp:77] Creating layer relu4
I0523 22:02:44.689213 23120 net.cpp:106] Creating Layer relu4
I0523 22:02:44.689224 23120 net.cpp:454] relu4 <- conv4
I0523 22:02:44.689236 23120 net.cpp:397] relu4 -> conv4 (in-place)
I0523 22:02:44.689713 23120 net.cpp:150] Setting up relu4
I0523 22:02:44.689729 23120 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0523 22:02:44.689739 23120 net.cpp:165] Memory required for data: 108991960
I0523 22:02:44.689749 23120 layer_factory.hpp:77] Creating layer pool4
I0523 22:02:44.689764 23120 net.cpp:106] Creating Layer pool4
I0523 22:02:44.689774 23120 net.cpp:454] pool4 <- conv4
I0523 22:02:44.689786 23120 net.cpp:411] pool4 -> pool4
I0523 22:02:44.689857 23120 net.cpp:150] Setting up pool4
I0523 22:02:44.689872 23120 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0523 22:02:44.689880 23120 net.cpp:165] Memory required for data: 110262040
I0523 22:02:44.689890 23120 layer_factory.hpp:77] Creating layer ip1
I0523 22:02:44.689905 23120 net.cpp:106] Creating Layer ip1
I0523 22:02:44.689916 23120 net.cpp:454] ip1 <- pool4
I0523 22:02:44.689930 23120 net.cpp:411] ip1 -> ip1
I0523 22:02:44.705374 23120 net.cpp:150] Setting up ip1
I0523 22:02:44.705404 23120 net.cpp:157] Top shape: 70 196 (13720)
I0523 22:02:44.705416 23120 net.cpp:165] Memory required for data: 110316920
I0523 22:02:44.705438 23120 layer_factory.hpp:77] Creating layer relu5
I0523 22:02:44.705453 23120 net.cpp:106] Creating Layer relu5
I0523 22:02:44.705463 23120 net.cpp:454] relu5 <- ip1
I0523 22:02:44.705477 23120 net.cpp:397] relu5 -> ip1 (in-place)
I0523 22:02:44.705832 23120 net.cpp:150] Setting up relu5
I0523 22:02:44.705847 23120 net.cpp:157] Top shape: 70 196 (13720)
I0523 22:02:44.705857 23120 net.cpp:165] Memory required for data: 110371800
I0523 22:02:44.705867 23120 layer_factory.hpp:77] Creating layer drop1
I0523 22:02:44.705885 23120 net.cpp:106] Creating Layer drop1
I0523 22:02:44.705895 23120 net.cpp:454] drop1 <- ip1
I0523 22:02:44.705909 23120 net.cpp:397] drop1 -> ip1 (in-place)
I0523 22:02:44.705955 23120 net.cpp:150] Setting up drop1
I0523 22:02:44.705968 23120 net.cpp:157] Top shape: 70 196 (13720)
I0523 22:02:44.705981 23120 net.cpp:165] Memory required for data: 110426680
I0523 22:02:44.705989 23120 layer_factory.hpp:77] Creating layer ip2
I0523 22:02:44.706003 23120 net.cpp:106] Creating Layer ip2
I0523 22:02:44.706013 23120 net.cpp:454] ip2 <- ip1
I0523 22:02:44.706027 23120 net.cpp:411] ip2 -> ip2
I0523 22:02:44.706506 23120 net.cpp:150] Setting up ip2
I0523 22:02:44.706519 23120 net.cpp:157] Top shape: 70 98 (6860)
I0523 22:02:44.706528 23120 net.cpp:165] Memory required for data: 110454120
I0523 22:02:44.706544 23120 layer_factory.hpp:77] Creating layer relu6
I0523 22:02:44.706570 23120 net.cpp:106] Creating Layer relu6
I0523 22:02:44.706580 23120 net.cpp:454] relu6 <- ip2
I0523 22:02:44.706593 23120 net.cpp:397] relu6 -> ip2 (in-place)
I0523 22:02:44.707129 23120 net.cpp:150] Setting up relu6
I0523 22:02:44.707151 23120 net.cpp:157] Top shape: 70 98 (6860)
I0523 22:02:44.707161 23120 net.cpp:165] Memory required for data: 110481560
I0523 22:02:44.707171 23120 layer_factory.hpp:77] Creating layer drop2
I0523 22:02:44.707183 23120 net.cpp:106] Creating Layer drop2
I0523 22:02:44.707195 23120 net.cpp:454] drop2 <- ip2
I0523 22:02:44.707207 23120 net.cpp:397] drop2 -> ip2 (in-place)
I0523 22:02:44.707252 23120 net.cpp:150] Setting up drop2
I0523 22:02:44.707265 23120 net.cpp:157] Top shape: 70 98 (6860)
I0523 22:02:44.707275 23120 net.cpp:165] Memory required for data: 110509000
I0523 22:02:44.707285 23120 layer_factory.hpp:77] Creating layer ip3
I0523 22:02:44.707299 23120 net.cpp:106] Creating Layer ip3
I0523 22:02:44.707309 23120 net.cpp:454] ip3 <- ip2
I0523 22:02:44.707324 23120 net.cpp:411] ip3 -> ip3
I0523 22:02:44.707546 23120 net.cpp:150] Setting up ip3
I0523 22:02:44.707559 23120 net.cpp:157] Top shape: 70 11 (770)
I0523 22:02:44.707568 23120 net.cpp:165] Memory required for data: 110512080
I0523 22:02:44.707584 23120 layer_factory.hpp:77] Creating layer drop3
I0523 22:02:44.707595 23120 net.cpp:106] Creating Layer drop3
I0523 22:02:44.707607 23120 net.cpp:454] drop3 <- ip3
I0523 22:02:44.707618 23120 net.cpp:397] drop3 -> ip3 (in-place)
I0523 22:02:44.707660 23120 net.cpp:150] Setting up drop3
I0523 22:02:44.707674 23120 net.cpp:157] Top shape: 70 11 (770)
I0523 22:02:44.707684 23120 net.cpp:165] Memory required for data: 110515160
I0523 22:02:44.707693 23120 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 22:02:44.707706 23120 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 22:02:44.707716 23120 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 22:02:44.707729 23120 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 22:02:44.707744 23120 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 22:02:44.707818 23120 net.cpp:150] Setting up ip3_drop3_0_split
I0523 22:02:44.707831 23120 net.cpp:157] Top shape: 70 11 (770)
I0523 22:02:44.707844 23120 net.cpp:157] Top shape: 70 11 (770)
I0523 22:02:44.707852 23120 net.cpp:165] Memory required for data: 110521320
I0523 22:02:44.707861 23120 layer_factory.hpp:77] Creating layer accuracy
I0523 22:02:44.707883 23120 net.cpp:106] Creating Layer accuracy
I0523 22:02:44.707895 23120 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 22:02:44.707906 23120 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 22:02:44.707919 23120 net.cpp:411] accuracy -> accuracy
I0523 22:02:44.707943 23120 net.cpp:150] Setting up accuracy
I0523 22:02:44.707955 23120 net.cpp:157] Top shape: (1)
I0523 22:02:44.707964 23120 net.cpp:165] Memory required for data: 110521324
I0523 22:02:44.707974 23120 layer_factory.hpp:77] Creating layer loss
I0523 22:02:44.707986 23120 net.cpp:106] Creating Layer loss
I0523 22:02:44.707996 23120 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 22:02:44.708008 23120 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 22:02:44.708021 23120 net.cpp:411] loss -> loss
I0523 22:02:44.708039 23120 layer_factory.hpp:77] Creating layer loss
I0523 22:02:44.708526 23120 net.cpp:150] Setting up loss
I0523 22:02:44.708539 23120 net.cpp:157] Top shape: (1)
I0523 22:02:44.708549 23120 net.cpp:160]     with loss weight 1
I0523 22:02:44.708567 23120 net.cpp:165] Memory required for data: 110521328
I0523 22:02:44.708577 23120 net.cpp:226] loss needs backward computation.
I0523 22:02:44.708590 23120 net.cpp:228] accuracy does not need backward computation.
I0523 22:02:44.708600 23120 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 22:02:44.708611 23120 net.cpp:226] drop3 needs backward computation.
I0523 22:02:44.708621 23120 net.cpp:226] ip3 needs backward computation.
I0523 22:02:44.708631 23120 net.cpp:226] drop2 needs backward computation.
I0523 22:02:44.708642 23120 net.cpp:226] relu6 needs backward computation.
I0523 22:02:44.708658 23120 net.cpp:226] ip2 needs backward computation.
I0523 22:02:44.708668 23120 net.cpp:226] drop1 needs backward computation.
I0523 22:02:44.708678 23120 net.cpp:226] relu5 needs backward computation.
I0523 22:02:44.708688 23120 net.cpp:226] ip1 needs backward computation.
I0523 22:02:44.708699 23120 net.cpp:226] pool4 needs backward computation.
I0523 22:02:44.708709 23120 net.cpp:226] relu4 needs backward computation.
I0523 22:02:44.708719 23120 net.cpp:226] conv4 needs backward computation.
I0523 22:02:44.708730 23120 net.cpp:226] pool3 needs backward computation.
I0523 22:02:44.708740 23120 net.cpp:226] relu3 needs backward computation.
I0523 22:02:44.708750 23120 net.cpp:226] conv3 needs backward computation.
I0523 22:02:44.708761 23120 net.cpp:226] pool2 needs backward computation.
I0523 22:02:44.708771 23120 net.cpp:226] relu2 needs backward computation.
I0523 22:02:44.708781 23120 net.cpp:226] conv2 needs backward computation.
I0523 22:02:44.708792 23120 net.cpp:226] pool1 needs backward computation.
I0523 22:02:44.708802 23120 net.cpp:226] relu1 needs backward computation.
I0523 22:02:44.708812 23120 net.cpp:226] conv1 needs backward computation.
I0523 22:02:44.708823 23120 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 22:02:44.708834 23120 net.cpp:228] data_hdf5 does not need backward computation.
I0523 22:02:44.708844 23120 net.cpp:270] This network produces output accuracy
I0523 22:02:44.708853 23120 net.cpp:270] This network produces output loss
I0523 22:02:44.708881 23120 net.cpp:283] Network initialization done.
I0523 22:02:44.709013 23120 solver.cpp:60] Solver scaffolding done.
I0523 22:02:44.710165 23120 caffe.cpp:212] Starting Optimization
I0523 22:02:44.710182 23120 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 22:02:44.710196 23120 solver.cpp:289] Learning Rate Policy: fixed
I0523 22:02:44.711421 23120 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 22:03:33.661334 23120 solver.cpp:409]     Test net output #0: accuracy = 0.0535013
I0523 22:03:33.661511 23120 solver.cpp:409]     Test net output #1: loss = 2.39855 (* 1 = 2.39855 loss)
I0523 22:03:33.689591 23120 solver.cpp:237] Iteration 0, loss = 2.39737
I0523 22:03:33.689628 23120 solver.cpp:253]     Train net output #0: loss = 2.39737 (* 1 = 2.39737 loss)
I0523 22:03:33.689646 23120 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0523 22:03:42.565374 23120 solver.cpp:237] Iteration 214, loss = 2.35674
I0523 22:03:42.565412 23120 solver.cpp:253]     Train net output #0: loss = 2.35674 (* 1 = 2.35674 loss)
I0523 22:03:42.565428 23120 sgd_solver.cpp:106] Iteration 214, lr = 0.0005
I0523 22:03:51.442169 23120 solver.cpp:237] Iteration 428, loss = 2.32501
I0523 22:03:51.442208 23120 solver.cpp:253]     Train net output #0: loss = 2.32501 (* 1 = 2.32501 loss)
I0523 22:03:51.442229 23120 sgd_solver.cpp:106] Iteration 428, lr = 0.0005
I0523 22:04:00.321465 23120 solver.cpp:237] Iteration 642, loss = 2.37145
I0523 22:04:00.321501 23120 solver.cpp:253]     Train net output #0: loss = 2.37145 (* 1 = 2.37145 loss)
I0523 22:04:00.321516 23120 sgd_solver.cpp:106] Iteration 642, lr = 0.0005
I0523 22:04:09.198776 23120 solver.cpp:237] Iteration 856, loss = 2.25809
I0523 22:04:09.211058 23120 solver.cpp:253]     Train net output #0: loss = 2.25809 (* 1 = 2.25809 loss)
I0523 22:04:09.211072 23120 sgd_solver.cpp:106] Iteration 856, lr = 0.0005
I0523 22:04:18.085938 23120 solver.cpp:237] Iteration 1070, loss = 2.30505
I0523 22:04:18.085973 23120 solver.cpp:253]     Train net output #0: loss = 2.30505 (* 1 = 2.30505 loss)
I0523 22:04:18.085989 23120 sgd_solver.cpp:106] Iteration 1070, lr = 0.0005
I0523 22:04:26.964175 23120 solver.cpp:237] Iteration 1284, loss = 2.34421
I0523 22:04:26.964211 23120 solver.cpp:253]     Train net output #0: loss = 2.34421 (* 1 = 2.34421 loss)
I0523 22:04:26.964228 23120 sgd_solver.cpp:106] Iteration 1284, lr = 0.0005
I0523 22:04:58.051553 23120 solver.cpp:237] Iteration 1498, loss = 2.2229
I0523 22:04:58.051717 23120 solver.cpp:253]     Train net output #0: loss = 2.2229 (* 1 = 2.2229 loss)
I0523 22:04:58.051730 23120 sgd_solver.cpp:106] Iteration 1498, lr = 0.0005
I0523 22:05:06.934626 23120 solver.cpp:237] Iteration 1712, loss = 2.12703
I0523 22:05:06.934664 23120 solver.cpp:253]     Train net output #0: loss = 2.12703 (* 1 = 2.12703 loss)
I0523 22:05:06.934685 23120 sgd_solver.cpp:106] Iteration 1712, lr = 0.0005
I0523 22:05:15.817617 23120 solver.cpp:237] Iteration 1926, loss = 2.07633
I0523 22:05:15.817652 23120 solver.cpp:253]     Train net output #0: loss = 2.07633 (* 1 = 2.07633 loss)
I0523 22:05:15.817669 23120 sgd_solver.cpp:106] Iteration 1926, lr = 0.0005
I0523 22:05:24.698492 23120 solver.cpp:237] Iteration 2140, loss = 2.02398
I0523 22:05:24.698539 23120 solver.cpp:253]     Train net output #0: loss = 2.02398 (* 1 = 2.02398 loss)
I0523 22:05:24.698552 23120 sgd_solver.cpp:106] Iteration 2140, lr = 0.0005
I0523 22:05:24.740737 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_2142.caffemodel
I0523 22:05:24.811069 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_2142.solverstate
I0523 22:05:33.656175 23120 solver.cpp:237] Iteration 2354, loss = 2.18877
I0523 22:05:33.656333 23120 solver.cpp:253]     Train net output #0: loss = 2.18877 (* 1 = 2.18877 loss)
I0523 22:05:33.656347 23120 sgd_solver.cpp:106] Iteration 2354, lr = 0.0005
I0523 22:05:42.540549 23120 solver.cpp:237] Iteration 2568, loss = 2.08328
I0523 22:05:42.540585 23120 solver.cpp:253]     Train net output #0: loss = 2.08328 (* 1 = 2.08328 loss)
I0523 22:05:42.540601 23120 sgd_solver.cpp:106] Iteration 2568, lr = 0.0005
I0523 22:05:51.426794 23120 solver.cpp:237] Iteration 2782, loss = 1.95313
I0523 22:05:51.426841 23120 solver.cpp:253]     Train net output #0: loss = 1.95313 (* 1 = 1.95313 loss)
I0523 22:05:51.426856 23120 sgd_solver.cpp:106] Iteration 2782, lr = 0.0005
I0523 22:06:22.463368 23120 solver.cpp:237] Iteration 2996, loss = 1.87124
I0523 22:06:22.463526 23120 solver.cpp:253]     Train net output #0: loss = 1.87124 (* 1 = 1.87124 loss)
I0523 22:06:22.463539 23120 sgd_solver.cpp:106] Iteration 2996, lr = 0.0005
I0523 22:06:31.350270 23120 solver.cpp:237] Iteration 3210, loss = 1.96403
I0523 22:06:31.350306 23120 solver.cpp:253]     Train net output #0: loss = 1.96403 (* 1 = 1.96403 loss)
I0523 22:06:31.350322 23120 sgd_solver.cpp:106] Iteration 3210, lr = 0.0005
I0523 22:06:40.237792 23120 solver.cpp:237] Iteration 3424, loss = 1.86423
I0523 22:06:40.237838 23120 solver.cpp:253]     Train net output #0: loss = 1.86423 (* 1 = 1.86423 loss)
I0523 22:06:40.237855 23120 sgd_solver.cpp:106] Iteration 3424, lr = 0.0005
I0523 22:06:49.121937 23120 solver.cpp:237] Iteration 3638, loss = 1.85412
I0523 22:06:49.121973 23120 solver.cpp:253]     Train net output #0: loss = 1.85412 (* 1 = 1.85412 loss)
I0523 22:06:49.121989 23120 sgd_solver.cpp:106] Iteration 3638, lr = 0.0005
I0523 22:06:58.011137 23120 solver.cpp:237] Iteration 3852, loss = 1.97784
I0523 22:06:58.011286 23120 solver.cpp:253]     Train net output #0: loss = 1.97784 (* 1 = 1.97784 loss)
I0523 22:06:58.011298 23120 sgd_solver.cpp:106] Iteration 3852, lr = 0.0005
I0523 22:07:06.898860 23120 solver.cpp:237] Iteration 4066, loss = 1.84522
I0523 22:07:06.898906 23120 solver.cpp:253]     Train net output #0: loss = 1.84522 (* 1 = 1.84522 loss)
I0523 22:07:06.898923 23120 sgd_solver.cpp:106] Iteration 4066, lr = 0.0005
I0523 22:07:15.783872 23120 solver.cpp:237] Iteration 4280, loss = 1.71329
I0523 22:07:15.783907 23120 solver.cpp:253]     Train net output #0: loss = 1.71329 (* 1 = 1.71329 loss)
I0523 22:07:15.783924 23120 sgd_solver.cpp:106] Iteration 4280, lr = 0.0005
I0523 22:07:15.908890 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_4284.caffemodel
I0523 22:07:15.975963 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_4284.solverstate
I0523 22:07:16.015462 23120 solver.cpp:341] Iteration 4285, Testing net (#0)
I0523 22:08:03.968314 23120 solver.cpp:409]     Test net output #0: accuracy = 0.609325
I0523 22:08:03.968490 23120 solver.cpp:409]     Test net output #1: loss = 1.44017 (* 1 = 1.44017 loss)
I0523 22:08:34.840270 23120 solver.cpp:237] Iteration 4494, loss = 1.65581
I0523 22:08:34.840430 23120 solver.cpp:253]     Train net output #0: loss = 1.65581 (* 1 = 1.65581 loss)
I0523 22:08:34.840445 23120 sgd_solver.cpp:106] Iteration 4494, lr = 0.0005
I0523 22:08:43.705471 23120 solver.cpp:237] Iteration 4708, loss = 1.66831
I0523 22:08:43.705507 23120 solver.cpp:253]     Train net output #0: loss = 1.66831 (* 1 = 1.66831 loss)
I0523 22:08:43.705523 23120 sgd_solver.cpp:106] Iteration 4708, lr = 0.0005
I0523 22:08:52.574399 23120 solver.cpp:237] Iteration 4922, loss = 1.79902
I0523 22:08:52.574441 23120 solver.cpp:253]     Train net output #0: loss = 1.79902 (* 1 = 1.79902 loss)
I0523 22:08:52.574458 23120 sgd_solver.cpp:106] Iteration 4922, lr = 0.0005
I0523 22:09:01.446331 23120 solver.cpp:237] Iteration 5136, loss = 1.69911
I0523 22:09:01.446367 23120 solver.cpp:253]     Train net output #0: loss = 1.69911 (* 1 = 1.69911 loss)
I0523 22:09:01.446383 23120 sgd_solver.cpp:106] Iteration 5136, lr = 0.0005
I0523 22:09:10.316473 23120 solver.cpp:237] Iteration 5350, loss = 1.79592
I0523 22:09:10.316624 23120 solver.cpp:253]     Train net output #0: loss = 1.79592 (* 1 = 1.79592 loss)
I0523 22:09:10.316638 23120 sgd_solver.cpp:106] Iteration 5350, lr = 0.0005
I0523 22:09:19.187497 23120 solver.cpp:237] Iteration 5564, loss = 1.76825
I0523 22:09:19.187531 23120 solver.cpp:253]     Train net output #0: loss = 1.76825 (* 1 = 1.76825 loss)
I0523 22:09:19.187548 23120 sgd_solver.cpp:106] Iteration 5564, lr = 0.0005
I0523 22:09:50.218178 23120 solver.cpp:237] Iteration 5778, loss = 1.86588
I0523 22:09:50.218341 23120 solver.cpp:253]     Train net output #0: loss = 1.86588 (* 1 = 1.86588 loss)
I0523 22:09:50.218358 23120 sgd_solver.cpp:106] Iteration 5778, lr = 0.0005
I0523 22:09:59.085302 23120 solver.cpp:237] Iteration 5992, loss = 1.7071
I0523 22:09:59.085337 23120 solver.cpp:253]     Train net output #0: loss = 1.7071 (* 1 = 1.7071 loss)
I0523 22:09:59.085355 23120 sgd_solver.cpp:106] Iteration 5992, lr = 0.0005
I0523 22:10:07.956878 23120 solver.cpp:237] Iteration 6206, loss = 1.74425
I0523 22:10:07.956915 23120 solver.cpp:253]     Train net output #0: loss = 1.74425 (* 1 = 1.74425 loss)
I0523 22:10:07.956933 23120 sgd_solver.cpp:106] Iteration 6206, lr = 0.0005
I0523 22:10:16.827021 23120 solver.cpp:237] Iteration 6420, loss = 1.61816
I0523 22:10:16.827056 23120 solver.cpp:253]     Train net output #0: loss = 1.61816 (* 1 = 1.61816 loss)
I0523 22:10:16.827075 23120 sgd_solver.cpp:106] Iteration 6420, lr = 0.0005
I0523 22:10:17.034643 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_6426.caffemodel
I0523 22:10:17.102597 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_6426.solverstate
I0523 22:10:25.759925 23120 solver.cpp:237] Iteration 6634, loss = 1.84335
I0523 22:10:25.760094 23120 solver.cpp:253]     Train net output #0: loss = 1.84335 (* 1 = 1.84335 loss)
I0523 22:10:25.760108 23120 sgd_solver.cpp:106] Iteration 6634, lr = 0.0005
I0523 22:10:34.624259 23120 solver.cpp:237] Iteration 6848, loss = 1.73724
I0523 22:10:34.624294 23120 solver.cpp:253]     Train net output #0: loss = 1.73724 (* 1 = 1.73724 loss)
I0523 22:10:34.624312 23120 sgd_solver.cpp:106] Iteration 6848, lr = 0.0005
I0523 22:10:43.496223 23120 solver.cpp:237] Iteration 7062, loss = 1.95949
I0523 22:10:43.496258 23120 solver.cpp:253]     Train net output #0: loss = 1.95949 (* 1 = 1.95949 loss)
I0523 22:10:43.496274 23120 sgd_solver.cpp:106] Iteration 7062, lr = 0.0005
I0523 22:11:14.586241 23120 solver.cpp:237] Iteration 7276, loss = 1.96996
I0523 22:11:14.586398 23120 solver.cpp:253]     Train net output #0: loss = 1.96996 (* 1 = 1.96996 loss)
I0523 22:11:14.586412 23120 sgd_solver.cpp:106] Iteration 7276, lr = 0.0005
I0523 22:11:23.453199 23120 solver.cpp:237] Iteration 7490, loss = 1.62795
I0523 22:11:23.453234 23120 solver.cpp:253]     Train net output #0: loss = 1.62795 (* 1 = 1.62795 loss)
I0523 22:11:23.453248 23120 sgd_solver.cpp:106] Iteration 7490, lr = 0.0005
I0523 22:11:32.326076 23120 solver.cpp:237] Iteration 7704, loss = 1.6418
I0523 22:11:32.326110 23120 solver.cpp:253]     Train net output #0: loss = 1.6418 (* 1 = 1.6418 loss)
I0523 22:11:32.326128 23120 sgd_solver.cpp:106] Iteration 7704, lr = 0.0005
I0523 22:11:41.197837 23120 solver.cpp:237] Iteration 7918, loss = 1.59888
I0523 22:11:41.197882 23120 solver.cpp:253]     Train net output #0: loss = 1.59888 (* 1 = 1.59888 loss)
I0523 22:11:41.197902 23120 sgd_solver.cpp:106] Iteration 7918, lr = 0.0005
I0523 22:11:50.068436 23120 solver.cpp:237] Iteration 8132, loss = 1.88897
I0523 22:11:50.068577 23120 solver.cpp:253]     Train net output #0: loss = 1.88897 (* 1 = 1.88897 loss)
I0523 22:11:50.068589 23120 sgd_solver.cpp:106] Iteration 8132, lr = 0.0005
I0523 22:11:58.937507 23120 solver.cpp:237] Iteration 8346, loss = 1.67674
I0523 22:11:58.937542 23120 solver.cpp:253]     Train net output #0: loss = 1.67674 (* 1 = 1.67674 loss)
I0523 22:11:58.937561 23120 sgd_solver.cpp:106] Iteration 8346, lr = 0.0005
I0523 22:12:07.811374 23120 solver.cpp:237] Iteration 8560, loss = 1.789
I0523 22:12:07.811419 23120 solver.cpp:253]     Train net output #0: loss = 1.789 (* 1 = 1.789 loss)
I0523 22:12:07.811435 23120 sgd_solver.cpp:106] Iteration 8560, lr = 0.0005
I0523 22:12:08.101511 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_8568.caffemodel
I0523 22:12:08.170011 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_8568.solverstate
I0523 22:12:08.253497 23120 solver.cpp:341] Iteration 8570, Testing net (#0)
I0523 22:13:17.071470 23120 solver.cpp:409]     Test net output #0: accuracy = 0.660831
I0523 22:13:17.071636 23120 solver.cpp:409]     Test net output #1: loss = 1.19798 (* 1 = 1.19798 loss)
I0523 22:13:47.784422 23120 solver.cpp:237] Iteration 8774, loss = 1.6925
I0523 22:13:47.784587 23120 solver.cpp:253]     Train net output #0: loss = 1.6925 (* 1 = 1.6925 loss)
I0523 22:13:47.784601 23120 sgd_solver.cpp:106] Iteration 8774, lr = 0.0005
I0523 22:13:56.683193 23120 solver.cpp:237] Iteration 8988, loss = 1.75602
I0523 22:13:56.683228 23120 solver.cpp:253]     Train net output #0: loss = 1.75602 (* 1 = 1.75602 loss)
I0523 22:13:56.683245 23120 sgd_solver.cpp:106] Iteration 8988, lr = 0.0005
I0523 22:14:05.575793 23120 solver.cpp:237] Iteration 9202, loss = 1.64386
I0523 22:14:05.575827 23120 solver.cpp:253]     Train net output #0: loss = 1.64386 (* 1 = 1.64386 loss)
I0523 22:14:05.575845 23120 sgd_solver.cpp:106] Iteration 9202, lr = 0.0005
I0523 22:14:14.467453 23120 solver.cpp:237] Iteration 9416, loss = 1.54762
I0523 22:14:14.467496 23120 solver.cpp:253]     Train net output #0: loss = 1.54762 (* 1 = 1.54762 loss)
I0523 22:14:14.467512 23120 sgd_solver.cpp:106] Iteration 9416, lr = 0.0005
I0523 22:14:23.360973 23120 solver.cpp:237] Iteration 9630, loss = 1.52112
I0523 22:14:23.361110 23120 solver.cpp:253]     Train net output #0: loss = 1.52112 (* 1 = 1.52112 loss)
I0523 22:14:23.361124 23120 sgd_solver.cpp:106] Iteration 9630, lr = 0.0005
I0523 22:14:32.261917 23120 solver.cpp:237] Iteration 9844, loss = 1.68822
I0523 22:14:32.261952 23120 solver.cpp:253]     Train net output #0: loss = 1.68822 (* 1 = 1.68822 loss)
I0523 22:14:32.261965 23120 sgd_solver.cpp:106] Iteration 9844, lr = 0.0005
I0523 22:15:03.377975 23120 solver.cpp:237] Iteration 10058, loss = 1.73522
I0523 22:15:03.378139 23120 solver.cpp:253]     Train net output #0: loss = 1.73522 (* 1 = 1.73522 loss)
I0523 22:15:03.378154 23120 sgd_solver.cpp:106] Iteration 10058, lr = 0.0005
I0523 22:15:12.284176 23120 solver.cpp:237] Iteration 10272, loss = 1.74716
I0523 22:15:12.284211 23120 solver.cpp:253]     Train net output #0: loss = 1.74716 (* 1 = 1.74716 loss)
I0523 22:15:12.284226 23120 sgd_solver.cpp:106] Iteration 10272, lr = 0.0005
I0523 22:15:21.187927 23120 solver.cpp:237] Iteration 10486, loss = 1.97921
I0523 22:15:21.187963 23120 solver.cpp:253]     Train net output #0: loss = 1.97921 (* 1 = 1.97921 loss)
I0523 22:15:21.187978 23120 sgd_solver.cpp:106] Iteration 10486, lr = 0.0005
I0523 22:15:30.093243 23120 solver.cpp:237] Iteration 10700, loss = 1.51438
I0523 22:15:30.093287 23120 solver.cpp:253]     Train net output #0: loss = 1.51438 (* 1 = 1.51438 loss)
I0523 22:15:30.093303 23120 sgd_solver.cpp:106] Iteration 10700, lr = 0.0005
I0523 22:15:30.468127 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_10710.caffemodel
I0523 22:15:30.536784 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_10710.solverstate
I0523 22:15:39.065577 23120 solver.cpp:237] Iteration 10914, loss = 1.92475
I0523 22:15:39.065747 23120 solver.cpp:253]     Train net output #0: loss = 1.92475 (* 1 = 1.92475 loss)
I0523 22:15:39.065760 23120 sgd_solver.cpp:106] Iteration 10914, lr = 0.0005
I0523 22:15:47.971370 23120 solver.cpp:237] Iteration 11128, loss = 1.55678
I0523 22:15:47.971405 23120 solver.cpp:253]     Train net output #0: loss = 1.55678 (* 1 = 1.55678 loss)
I0523 22:15:47.971418 23120 sgd_solver.cpp:106] Iteration 11128, lr = 0.0005
I0523 22:15:56.871976 23120 solver.cpp:237] Iteration 11342, loss = 1.63003
I0523 22:15:56.872022 23120 solver.cpp:253]     Train net output #0: loss = 1.63003 (* 1 = 1.63003 loss)
I0523 22:15:56.872040 23120 sgd_solver.cpp:106] Iteration 11342, lr = 0.0005
I0523 22:16:27.935567 23120 solver.cpp:237] Iteration 11556, loss = 1.61648
I0523 22:16:27.935744 23120 solver.cpp:253]     Train net output #0: loss = 1.61648 (* 1 = 1.61648 loss)
I0523 22:16:27.935760 23120 sgd_solver.cpp:106] Iteration 11556, lr = 0.0005
I0523 22:16:36.835886 23120 solver.cpp:237] Iteration 11770, loss = 1.67121
I0523 22:16:36.835921 23120 solver.cpp:253]     Train net output #0: loss = 1.67121 (* 1 = 1.67121 loss)
I0523 22:16:36.835938 23120 sgd_solver.cpp:106] Iteration 11770, lr = 0.0005
I0523 22:16:45.732465 23120 solver.cpp:237] Iteration 11984, loss = 1.69249
I0523 22:16:45.732508 23120 solver.cpp:253]     Train net output #0: loss = 1.69249 (* 1 = 1.69249 loss)
I0523 22:16:45.732525 23120 sgd_solver.cpp:106] Iteration 11984, lr = 0.0005
I0523 22:16:54.626433 23120 solver.cpp:237] Iteration 12198, loss = 1.68649
I0523 22:16:54.626468 23120 solver.cpp:253]     Train net output #0: loss = 1.68649 (* 1 = 1.68649 loss)
I0523 22:16:54.626484 23120 sgd_solver.cpp:106] Iteration 12198, lr = 0.0005
I0523 22:17:03.520740 23120 solver.cpp:237] Iteration 12412, loss = 1.52453
I0523 22:17:03.520900 23120 solver.cpp:253]     Train net output #0: loss = 1.52453 (* 1 = 1.52453 loss)
I0523 22:17:03.520912 23120 sgd_solver.cpp:106] Iteration 12412, lr = 0.0005
I0523 22:17:12.420632 23120 solver.cpp:237] Iteration 12626, loss = 1.64851
I0523 22:17:12.420678 23120 solver.cpp:253]     Train net output #0: loss = 1.64851 (* 1 = 1.64851 loss)
I0523 22:17:12.420696 23120 sgd_solver.cpp:106] Iteration 12626, lr = 0.0005
I0523 22:17:21.314311 23120 solver.cpp:237] Iteration 12840, loss = 1.53014
I0523 22:17:21.314347 23120 solver.cpp:253]     Train net output #0: loss = 1.53014 (* 1 = 1.53014 loss)
I0523 22:17:21.314363 23120 sgd_solver.cpp:106] Iteration 12840, lr = 0.0005
I0523 22:17:21.772559 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_12852.caffemodel
I0523 22:17:21.838474 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_12852.solverstate
I0523 22:17:21.960263 23120 solver.cpp:341] Iteration 12855, Testing net (#0)
I0523 22:18:09.594262 23120 solver.cpp:409]     Test net output #0: accuracy = 0.690004
I0523 22:18:09.594422 23120 solver.cpp:409]     Test net output #1: loss = 1.09418 (* 1 = 1.09418 loss)
I0523 22:18:40.086107 23120 solver.cpp:237] Iteration 13054, loss = 1.71828
I0523 22:18:40.086266 23120 solver.cpp:253]     Train net output #0: loss = 1.71828 (* 1 = 1.71828 loss)
I0523 22:18:40.086282 23120 sgd_solver.cpp:106] Iteration 13054, lr = 0.0005
I0523 22:18:48.965296 23120 solver.cpp:237] Iteration 13268, loss = 1.61292
I0523 22:18:48.965339 23120 solver.cpp:253]     Train net output #0: loss = 1.61292 (* 1 = 1.61292 loss)
I0523 22:18:48.965359 23120 sgd_solver.cpp:106] Iteration 13268, lr = 0.0005
I0523 22:18:57.840623 23120 solver.cpp:237] Iteration 13482, loss = 1.67463
I0523 22:18:57.840658 23120 solver.cpp:253]     Train net output #0: loss = 1.67463 (* 1 = 1.67463 loss)
I0523 22:18:57.840674 23120 sgd_solver.cpp:106] Iteration 13482, lr = 0.0005
I0523 22:19:06.717278 23120 solver.cpp:237] Iteration 13696, loss = 1.71736
I0523 22:19:06.717314 23120 solver.cpp:253]     Train net output #0: loss = 1.71736 (* 1 = 1.71736 loss)
I0523 22:19:06.717327 23120 sgd_solver.cpp:106] Iteration 13696, lr = 0.0005
I0523 22:19:15.589257 23120 solver.cpp:237] Iteration 13910, loss = 1.57415
I0523 22:19:15.589406 23120 solver.cpp:253]     Train net output #0: loss = 1.57415 (* 1 = 1.57415 loss)
I0523 22:19:15.589421 23120 sgd_solver.cpp:106] Iteration 13910, lr = 0.0005
I0523 22:19:24.464876 23120 solver.cpp:237] Iteration 14124, loss = 1.4415
I0523 22:19:24.464911 23120 solver.cpp:253]     Train net output #0: loss = 1.4415 (* 1 = 1.4415 loss)
I0523 22:19:24.464928 23120 sgd_solver.cpp:106] Iteration 14124, lr = 0.0005
I0523 22:19:55.517848 23120 solver.cpp:237] Iteration 14338, loss = 1.71489
I0523 22:19:55.518024 23120 solver.cpp:253]     Train net output #0: loss = 1.71489 (* 1 = 1.71489 loss)
I0523 22:19:55.518039 23120 sgd_solver.cpp:106] Iteration 14338, lr = 0.0005
I0523 22:20:04.395450 23120 solver.cpp:237] Iteration 14552, loss = 1.52195
I0523 22:20:04.395493 23120 solver.cpp:253]     Train net output #0: loss = 1.52195 (* 1 = 1.52195 loss)
I0523 22:20:04.395512 23120 sgd_solver.cpp:106] Iteration 14552, lr = 0.0005
I0523 22:20:13.266347 23120 solver.cpp:237] Iteration 14766, loss = 1.67796
I0523 22:20:13.266383 23120 solver.cpp:253]     Train net output #0: loss = 1.67796 (* 1 = 1.67796 loss)
I0523 22:20:13.266397 23120 sgd_solver.cpp:106] Iteration 14766, lr = 0.0005
I0523 22:20:22.146546 23120 solver.cpp:237] Iteration 14980, loss = 1.51944
I0523 22:20:22.146581 23120 solver.cpp:253]     Train net output #0: loss = 1.51944 (* 1 = 1.51944 loss)
I0523 22:20:22.146595 23120 sgd_solver.cpp:106] Iteration 14980, lr = 0.0005
I0523 22:20:22.686162 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_14994.caffemodel
I0523 22:20:22.752904 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_14994.solverstate
I0523 22:20:31.092779 23120 solver.cpp:237] Iteration 15194, loss = 1.73508
I0523 22:20:31.092942 23120 solver.cpp:253]     Train net output #0: loss = 1.73508 (* 1 = 1.73508 loss)
I0523 22:20:31.092957 23120 sgd_solver.cpp:106] Iteration 15194, lr = 0.0005
I0523 22:20:39.971875 23120 solver.cpp:237] Iteration 15408, loss = 1.57081
I0523 22:20:39.971909 23120 solver.cpp:253]     Train net output #0: loss = 1.57081 (* 1 = 1.57081 loss)
I0523 22:20:39.971927 23120 sgd_solver.cpp:106] Iteration 15408, lr = 0.0005
I0523 22:20:48.849783 23120 solver.cpp:237] Iteration 15622, loss = 1.45179
I0523 22:20:48.849818 23120 solver.cpp:253]     Train net output #0: loss = 1.45179 (* 1 = 1.45179 loss)
I0523 22:20:48.849834 23120 sgd_solver.cpp:106] Iteration 15622, lr = 0.0005
I0523 22:21:19.971597 23120 solver.cpp:237] Iteration 15836, loss = 1.47782
I0523 22:21:19.971768 23120 solver.cpp:253]     Train net output #0: loss = 1.47782 (* 1 = 1.47782 loss)
I0523 22:21:19.971783 23120 sgd_solver.cpp:106] Iteration 15836, lr = 0.0005
I0523 22:21:28.854034 23120 solver.cpp:237] Iteration 16050, loss = 1.53045
I0523 22:21:28.854068 23120 solver.cpp:253]     Train net output #0: loss = 1.53045 (* 1 = 1.53045 loss)
I0523 22:21:28.854086 23120 sgd_solver.cpp:106] Iteration 16050, lr = 0.0005
I0523 22:21:37.735838 23120 solver.cpp:237] Iteration 16264, loss = 1.65132
I0523 22:21:37.735869 23120 solver.cpp:253]     Train net output #0: loss = 1.65132 (* 1 = 1.65132 loss)
I0523 22:21:37.735882 23120 sgd_solver.cpp:106] Iteration 16264, lr = 0.0005
I0523 22:21:46.606569 23120 solver.cpp:237] Iteration 16478, loss = 1.59781
I0523 22:21:46.606612 23120 solver.cpp:253]     Train net output #0: loss = 1.59781 (* 1 = 1.59781 loss)
I0523 22:21:46.606631 23120 sgd_solver.cpp:106] Iteration 16478, lr = 0.0005
I0523 22:21:55.487015 23120 solver.cpp:237] Iteration 16692, loss = 1.60406
I0523 22:21:55.487155 23120 solver.cpp:253]     Train net output #0: loss = 1.60406 (* 1 = 1.60406 loss)
I0523 22:21:55.487169 23120 sgd_solver.cpp:106] Iteration 16692, lr = 0.0005
I0523 22:22:04.368083 23120 solver.cpp:237] Iteration 16906, loss = 1.6236
I0523 22:22:04.368130 23120 solver.cpp:253]     Train net output #0: loss = 1.6236 (* 1 = 1.6236 loss)
I0523 22:22:04.368146 23120 sgd_solver.cpp:106] Iteration 16906, lr = 0.0005
I0523 22:22:13.250551 23120 solver.cpp:237] Iteration 17120, loss = 1.51786
I0523 22:22:13.250587 23120 solver.cpp:253]     Train net output #0: loss = 1.51786 (* 1 = 1.51786 loss)
I0523 22:22:13.250603 23120 sgd_solver.cpp:106] Iteration 17120, lr = 0.0005
I0523 22:22:13.875216 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_17136.caffemodel
I0523 22:22:13.941781 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_17136.solverstate
I0523 22:22:14.106081 23120 solver.cpp:341] Iteration 17140, Testing net (#0)
I0523 22:23:22.972743 23120 solver.cpp:409]     Test net output #0: accuracy = 0.734724
I0523 22:23:22.972913 23120 solver.cpp:409]     Test net output #1: loss = 0.954274 (* 1 = 0.954274 loss)
I0523 22:23:53.245462 23120 solver.cpp:237] Iteration 17334, loss = 1.48239
I0523 22:23:53.245621 23120 solver.cpp:253]     Train net output #0: loss = 1.48239 (* 1 = 1.48239 loss)
I0523 22:23:53.245635 23120 sgd_solver.cpp:106] Iteration 17334, lr = 0.0005
I0523 22:24:02.122179 23120 solver.cpp:237] Iteration 17548, loss = 1.26314
I0523 22:24:02.122213 23120 solver.cpp:253]     Train net output #0: loss = 1.26314 (* 1 = 1.26314 loss)
I0523 22:24:02.122231 23120 sgd_solver.cpp:106] Iteration 17548, lr = 0.0005
I0523 22:24:10.994742 23120 solver.cpp:237] Iteration 17762, loss = 1.58812
I0523 22:24:10.994786 23120 solver.cpp:253]     Train net output #0: loss = 1.58812 (* 1 = 1.58812 loss)
I0523 22:24:10.994807 23120 sgd_solver.cpp:106] Iteration 17762, lr = 0.0005
I0523 22:24:19.883030 23120 solver.cpp:237] Iteration 17976, loss = 1.25806
I0523 22:24:19.883065 23120 solver.cpp:253]     Train net output #0: loss = 1.25806 (* 1 = 1.25806 loss)
I0523 22:24:19.883081 23120 sgd_solver.cpp:106] Iteration 17976, lr = 0.0005
I0523 22:24:28.763810 23120 solver.cpp:237] Iteration 18190, loss = 1.81785
I0523 22:24:28.763957 23120 solver.cpp:253]     Train net output #0: loss = 1.81785 (* 1 = 1.81785 loss)
I0523 22:24:28.763970 23120 sgd_solver.cpp:106] Iteration 18190, lr = 0.0005
I0523 22:24:37.653558 23120 solver.cpp:237] Iteration 18404, loss = 1.32892
I0523 22:24:37.653597 23120 solver.cpp:253]     Train net output #0: loss = 1.32892 (* 1 = 1.32892 loss)
I0523 22:24:37.653619 23120 sgd_solver.cpp:106] Iteration 18404, lr = 0.0005
I0523 22:25:08.740154 23120 solver.cpp:237] Iteration 18618, loss = 1.56029
I0523 22:25:08.740326 23120 solver.cpp:253]     Train net output #0: loss = 1.56029 (* 1 = 1.56029 loss)
I0523 22:25:08.740342 23120 sgd_solver.cpp:106] Iteration 18618, lr = 0.0005
I0523 22:25:17.617838 23120 solver.cpp:237] Iteration 18832, loss = 1.56287
I0523 22:25:17.617874 23120 solver.cpp:253]     Train net output #0: loss = 1.56287 (* 1 = 1.56287 loss)
I0523 22:25:17.617890 23120 sgd_solver.cpp:106] Iteration 18832, lr = 0.0005
I0523 22:25:26.498821 23120 solver.cpp:237] Iteration 19046, loss = 1.47709
I0523 22:25:26.498867 23120 solver.cpp:253]     Train net output #0: loss = 1.47709 (* 1 = 1.47709 loss)
I0523 22:25:26.498883 23120 sgd_solver.cpp:106] Iteration 19046, lr = 0.0005
I0523 22:25:35.382081 23120 solver.cpp:237] Iteration 19260, loss = 1.50991
I0523 22:25:35.382114 23120 solver.cpp:253]     Train net output #0: loss = 1.50991 (* 1 = 1.50991 loss)
I0523 22:25:35.382133 23120 sgd_solver.cpp:106] Iteration 19260, lr = 0.0005
I0523 22:25:36.089164 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_19278.caffemodel
I0523 22:25:36.161788 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_19278.solverstate
I0523 22:25:44.336252 23120 solver.cpp:237] Iteration 19474, loss = 1.41404
I0523 22:25:44.336418 23120 solver.cpp:253]     Train net output #0: loss = 1.41404 (* 1 = 1.41404 loss)
I0523 22:25:44.336432 23120 sgd_solver.cpp:106] Iteration 19474, lr = 0.0005
I0523 22:25:53.218972 23120 solver.cpp:237] Iteration 19688, loss = 1.44076
I0523 22:25:53.219022 23120 solver.cpp:253]     Train net output #0: loss = 1.44076 (* 1 = 1.44076 loss)
I0523 22:25:53.219036 23120 sgd_solver.cpp:106] Iteration 19688, lr = 0.0005
I0523 22:26:02.098994 23120 solver.cpp:237] Iteration 19902, loss = 1.46537
I0523 22:26:02.099030 23120 solver.cpp:253]     Train net output #0: loss = 1.46537 (* 1 = 1.46537 loss)
I0523 22:26:02.099046 23120 sgd_solver.cpp:106] Iteration 19902, lr = 0.0005
I0523 22:26:33.152611 23120 solver.cpp:237] Iteration 20116, loss = 1.66211
I0523 22:26:33.152799 23120 solver.cpp:253]     Train net output #0: loss = 1.66211 (* 1 = 1.66211 loss)
I0523 22:26:33.152815 23120 sgd_solver.cpp:106] Iteration 20116, lr = 0.0005
I0523 22:26:42.031726 23120 solver.cpp:237] Iteration 20330, loss = 1.55306
I0523 22:26:42.031769 23120 solver.cpp:253]     Train net output #0: loss = 1.55306 (* 1 = 1.55306 loss)
I0523 22:26:42.031781 23120 sgd_solver.cpp:106] Iteration 20330, lr = 0.0005
I0523 22:26:50.911031 23120 solver.cpp:237] Iteration 20544, loss = 1.33488
I0523 22:26:50.911067 23120 solver.cpp:253]     Train net output #0: loss = 1.33488 (* 1 = 1.33488 loss)
I0523 22:26:50.911083 23120 sgd_solver.cpp:106] Iteration 20544, lr = 0.0005
I0523 22:26:59.794594 23120 solver.cpp:237] Iteration 20758, loss = 1.6258
I0523 22:26:59.794628 23120 solver.cpp:253]     Train net output #0: loss = 1.6258 (* 1 = 1.6258 loss)
I0523 22:26:59.794644 23120 sgd_solver.cpp:106] Iteration 20758, lr = 0.0005
I0523 22:27:08.675428 23120 solver.cpp:237] Iteration 20972, loss = 1.35883
I0523 22:27:08.675591 23120 solver.cpp:253]     Train net output #0: loss = 1.35883 (* 1 = 1.35883 loss)
I0523 22:27:08.675606 23120 sgd_solver.cpp:106] Iteration 20972, lr = 0.0005
I0523 22:27:17.557867 23120 solver.cpp:237] Iteration 21186, loss = 1.60596
I0523 22:27:17.557900 23120 solver.cpp:253]     Train net output #0: loss = 1.60596 (* 1 = 1.60596 loss)
I0523 22:27:17.557917 23120 sgd_solver.cpp:106] Iteration 21186, lr = 0.0005
I0523 22:27:26.437542 23120 solver.cpp:237] Iteration 21400, loss = 1.63239
I0523 22:27:26.437578 23120 solver.cpp:253]     Train net output #0: loss = 1.63239 (* 1 = 1.63239 loss)
I0523 22:27:26.437593 23120 sgd_solver.cpp:106] Iteration 21400, lr = 0.0005
I0523 22:27:27.225989 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_21420.caffemodel
I0523 22:27:27.293965 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_21420.solverstate
I0523 22:27:27.502043 23120 solver.cpp:341] Iteration 21425, Testing net (#0)
I0523 22:28:15.440343 23120 solver.cpp:409]     Test net output #0: accuracy = 0.772988
I0523 22:28:15.440510 23120 solver.cpp:409]     Test net output #1: loss = 0.848002 (* 1 = 0.848002 loss)
I0523 22:28:44.195997 23120 solver.cpp:237] Iteration 21614, loss = 1.47383
I0523 22:28:44.196044 23120 solver.cpp:253]     Train net output #0: loss = 1.47383 (* 1 = 1.47383 loss)
I0523 22:28:44.196058 23120 sgd_solver.cpp:106] Iteration 21614, lr = 0.0005
I0523 22:28:53.074410 23120 solver.cpp:237] Iteration 21828, loss = 1.42587
I0523 22:28:53.074566 23120 solver.cpp:253]     Train net output #0: loss = 1.42587 (* 1 = 1.42587 loss)
I0523 22:28:53.074584 23120 sgd_solver.cpp:106] Iteration 21828, lr = 0.0005
I0523 22:29:01.960736 23120 solver.cpp:237] Iteration 22042, loss = 1.22135
I0523 22:29:01.960765 23120 solver.cpp:253]     Train net output #0: loss = 1.22135 (* 1 = 1.22135 loss)
I0523 22:29:01.960784 23120 sgd_solver.cpp:106] Iteration 22042, lr = 0.0005
I0523 22:29:10.840510 23120 solver.cpp:237] Iteration 22256, loss = 1.72783
I0523 22:29:10.840550 23120 solver.cpp:253]     Train net output #0: loss = 1.72783 (* 1 = 1.72783 loss)
I0523 22:29:10.840569 23120 sgd_solver.cpp:106] Iteration 22256, lr = 0.0005
I0523 22:29:19.720703 23120 solver.cpp:237] Iteration 22470, loss = 1.24609
I0523 22:29:19.720733 23120 solver.cpp:253]     Train net output #0: loss = 1.24609 (* 1 = 1.24609 loss)
I0523 22:29:19.720752 23120 sgd_solver.cpp:106] Iteration 22470, lr = 0.0005
I0523 22:29:28.592713 23120 solver.cpp:237] Iteration 22684, loss = 1.24641
I0523 22:29:28.592872 23120 solver.cpp:253]     Train net output #0: loss = 1.24641 (* 1 = 1.24641 loss)
I0523 22:29:28.592890 23120 sgd_solver.cpp:106] Iteration 22684, lr = 0.0005
I0523 22:29:58.332734 23120 solver.cpp:237] Iteration 22898, loss = 1.43249
I0523 22:29:58.332783 23120 solver.cpp:253]     Train net output #0: loss = 1.43249 (* 1 = 1.43249 loss)
I0523 22:29:58.332803 23120 sgd_solver.cpp:106] Iteration 22898, lr = 0.0005
I0523 22:30:07.213690 23120 solver.cpp:237] Iteration 23112, loss = 1.47169
I0523 22:30:07.213853 23120 solver.cpp:253]     Train net output #0: loss = 1.47169 (* 1 = 1.47169 loss)
I0523 22:30:07.213871 23120 sgd_solver.cpp:106] Iteration 23112, lr = 0.0005
I0523 22:30:16.097717 23120 solver.cpp:237] Iteration 23326, loss = 1.61202
I0523 22:30:16.097749 23120 solver.cpp:253]     Train net output #0: loss = 1.61202 (* 1 = 1.61202 loss)
I0523 22:30:16.097765 23120 sgd_solver.cpp:106] Iteration 23326, lr = 0.0005
I0523 22:30:24.978143 23120 solver.cpp:237] Iteration 23540, loss = 1.35026
I0523 22:30:24.978194 23120 solver.cpp:253]     Train net output #0: loss = 1.35026 (* 1 = 1.35026 loss)
I0523 22:30:24.978217 23120 sgd_solver.cpp:106] Iteration 23540, lr = 0.0005
I0523 22:30:25.849678 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_23562.caffemodel
I0523 22:30:25.915873 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_23562.solverstate
I0523 22:30:33.919617 23120 solver.cpp:237] Iteration 23754, loss = 1.3929
I0523 22:30:33.919661 23120 solver.cpp:253]     Train net output #0: loss = 1.3929 (* 1 = 1.3929 loss)
I0523 22:30:33.919678 23120 sgd_solver.cpp:106] Iteration 23754, lr = 0.0005
I0523 22:30:42.798924 23120 solver.cpp:237] Iteration 23968, loss = 1.45345
I0523 22:30:42.799077 23120 solver.cpp:253]     Train net output #0: loss = 1.45345 (* 1 = 1.45345 loss)
I0523 22:30:42.799093 23120 sgd_solver.cpp:106] Iteration 23968, lr = 0.0005
I0523 22:30:51.679342 23120 solver.cpp:237] Iteration 24182, loss = 1.54955
I0523 22:30:51.679384 23120 solver.cpp:253]     Train net output #0: loss = 1.54955 (* 1 = 1.54955 loss)
I0523 22:30:51.679401 23120 sgd_solver.cpp:106] Iteration 24182, lr = 0.0005
I0523 22:31:21.451153 23120 solver.cpp:237] Iteration 24396, loss = 1.31415
I0523 22:31:21.451323 23120 solver.cpp:253]     Train net output #0: loss = 1.31415 (* 1 = 1.31415 loss)
I0523 22:31:21.451339 23120 sgd_solver.cpp:106] Iteration 24396, lr = 0.0005
I0523 22:31:30.326917 23120 solver.cpp:237] Iteration 24610, loss = 1.23522
I0523 22:31:30.326947 23120 solver.cpp:253]     Train net output #0: loss = 1.23522 (* 1 = 1.23522 loss)
I0523 22:31:30.326966 23120 sgd_solver.cpp:106] Iteration 24610, lr = 0.0005
I0523 22:31:39.212785 23120 solver.cpp:237] Iteration 24824, loss = 1.32319
I0523 22:31:39.212836 23120 solver.cpp:253]     Train net output #0: loss = 1.32319 (* 1 = 1.32319 loss)
I0523 22:31:39.212852 23120 sgd_solver.cpp:106] Iteration 24824, lr = 0.0005
I0523 22:31:48.091606 23120 solver.cpp:237] Iteration 25038, loss = 1.31943
I0523 22:31:48.091636 23120 solver.cpp:253]     Train net output #0: loss = 1.31943 (* 1 = 1.31943 loss)
I0523 22:31:48.091655 23120 sgd_solver.cpp:106] Iteration 25038, lr = 0.0005
I0523 22:31:56.964289 23120 solver.cpp:237] Iteration 25252, loss = 1.32576
I0523 22:31:56.964439 23120 solver.cpp:253]     Train net output #0: loss = 1.32576 (* 1 = 1.32576 loss)
I0523 22:31:56.964457 23120 sgd_solver.cpp:106] Iteration 25252, lr = 0.0005
I0523 22:32:05.841837 23120 solver.cpp:237] Iteration 25466, loss = 1.42266
I0523 22:32:05.841881 23120 solver.cpp:253]     Train net output #0: loss = 1.42266 (* 1 = 1.42266 loss)
I0523 22:32:05.841897 23120 sgd_solver.cpp:106] Iteration 25466, lr = 0.0005
I0523 22:32:14.717628 23120 solver.cpp:237] Iteration 25680, loss = 1.40051
I0523 22:32:14.717658 23120 solver.cpp:253]     Train net output #0: loss = 1.40051 (* 1 = 1.40051 loss)
I0523 22:32:14.717677 23120 sgd_solver.cpp:106] Iteration 25680, lr = 0.0005
I0523 22:32:15.671404 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_25704.caffemodel
I0523 22:32:15.737447 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_25704.solverstate
I0523 22:32:15.984730 23120 solver.cpp:341] Iteration 25710, Testing net (#0)
I0523 22:33:24.755024 23120 solver.cpp:409]     Test net output #0: accuracy = 0.78715
I0523 22:33:24.755204 23120 solver.cpp:409]     Test net output #1: loss = 0.768324 (* 1 = 0.768324 loss)
I0523 22:33:53.249563 23120 solver.cpp:237] Iteration 25894, loss = 1.47525
I0523 22:33:53.249609 23120 solver.cpp:253]     Train net output #0: loss = 1.47525 (* 1 = 1.47525 loss)
I0523 22:33:53.249627 23120 sgd_solver.cpp:106] Iteration 25894, lr = 0.0005
I0523 22:34:02.118221 23120 solver.cpp:237] Iteration 26108, loss = 1.17202
I0523 22:34:02.118372 23120 solver.cpp:253]     Train net output #0: loss = 1.17202 (* 1 = 1.17202 loss)
I0523 22:34:02.118389 23120 sgd_solver.cpp:106] Iteration 26108, lr = 0.0005
I0523 22:34:10.988034 23120 solver.cpp:237] Iteration 26322, loss = 1.3155
I0523 22:34:10.988080 23120 solver.cpp:253]     Train net output #0: loss = 1.3155 (* 1 = 1.3155 loss)
I0523 22:34:10.988097 23120 sgd_solver.cpp:106] Iteration 26322, lr = 0.0005
I0523 22:34:19.854246 23120 solver.cpp:237] Iteration 26536, loss = 1.43385
I0523 22:34:19.854277 23120 solver.cpp:253]     Train net output #0: loss = 1.43385 (* 1 = 1.43385 loss)
I0523 22:34:19.854295 23120 sgd_solver.cpp:106] Iteration 26536, lr = 0.0005
I0523 22:34:28.718843 23120 solver.cpp:237] Iteration 26750, loss = 1.23219
I0523 22:34:28.718873 23120 solver.cpp:253]     Train net output #0: loss = 1.23219 (* 1 = 1.23219 loss)
I0523 22:34:28.718893 23120 sgd_solver.cpp:106] Iteration 26750, lr = 0.0005
I0523 22:34:37.594014 23120 solver.cpp:237] Iteration 26964, loss = 1.41774
I0523 22:34:37.594174 23120 solver.cpp:253]     Train net output #0: loss = 1.41774 (* 1 = 1.41774 loss)
I0523 22:34:37.594192 23120 sgd_solver.cpp:106] Iteration 26964, lr = 0.0005
I0523 22:35:07.334785 23120 solver.cpp:237] Iteration 27178, loss = 1.47404
I0523 22:35:07.334836 23120 solver.cpp:253]     Train net output #0: loss = 1.47404 (* 1 = 1.47404 loss)
I0523 22:35:07.334854 23120 sgd_solver.cpp:106] Iteration 27178, lr = 0.0005
I0523 22:35:16.207908 23120 solver.cpp:237] Iteration 27392, loss = 1.28613
I0523 22:35:16.208060 23120 solver.cpp:253]     Train net output #0: loss = 1.28613 (* 1 = 1.28613 loss)
I0523 22:35:16.208076 23120 sgd_solver.cpp:106] Iteration 27392, lr = 0.0005
I0523 22:35:25.076197 23120 solver.cpp:237] Iteration 27606, loss = 1.55326
I0523 22:35:25.076248 23120 solver.cpp:253]     Train net output #0: loss = 1.55326 (* 1 = 1.55326 loss)
I0523 22:35:25.076266 23120 sgd_solver.cpp:106] Iteration 27606, lr = 0.0005
I0523 22:35:33.944699 23120 solver.cpp:237] Iteration 27820, loss = 1.31601
I0523 22:35:33.944730 23120 solver.cpp:253]     Train net output #0: loss = 1.31601 (* 1 = 1.31601 loss)
I0523 22:35:33.944747 23120 sgd_solver.cpp:106] Iteration 27820, lr = 0.0005
I0523 22:35:34.979300 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_27846.caffemodel
I0523 22:35:35.045150 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_27846.solverstate
I0523 22:35:42.870004 23120 solver.cpp:237] Iteration 28034, loss = 1.38138
I0523 22:35:42.870048 23120 solver.cpp:253]     Train net output #0: loss = 1.38138 (* 1 = 1.38138 loss)
I0523 22:35:42.870067 23120 sgd_solver.cpp:106] Iteration 28034, lr = 0.0005
I0523 22:35:51.735946 23120 solver.cpp:237] Iteration 28248, loss = 1.62743
I0523 22:35:51.736135 23120 solver.cpp:253]     Train net output #0: loss = 1.62743 (* 1 = 1.62743 loss)
I0523 22:35:51.736151 23120 sgd_solver.cpp:106] Iteration 28248, lr = 0.0005
I0523 22:36:00.598704 23120 solver.cpp:237] Iteration 28462, loss = 1.72044
I0523 22:36:00.598739 23120 solver.cpp:253]     Train net output #0: loss = 1.72044 (* 1 = 1.72044 loss)
I0523 22:36:00.598757 23120 sgd_solver.cpp:106] Iteration 28462, lr = 0.0005
I0523 22:36:30.320650 23120 solver.cpp:237] Iteration 28676, loss = 1.55639
I0523 22:36:30.320824 23120 solver.cpp:253]     Train net output #0: loss = 1.55639 (* 1 = 1.55639 loss)
I0523 22:36:30.320842 23120 sgd_solver.cpp:106] Iteration 28676, lr = 0.0005
I0523 22:36:39.192282 23120 solver.cpp:237] Iteration 28890, loss = 1.40571
I0523 22:36:39.192318 23120 solver.cpp:253]     Train net output #0: loss = 1.40571 (* 1 = 1.40571 loss)
I0523 22:36:39.192335 23120 sgd_solver.cpp:106] Iteration 28890, lr = 0.0005
I0523 22:36:48.059368 23120 solver.cpp:237] Iteration 29104, loss = 1.25158
I0523 22:36:48.059402 23120 solver.cpp:253]     Train net output #0: loss = 1.25158 (* 1 = 1.25158 loss)
I0523 22:36:48.059420 23120 sgd_solver.cpp:106] Iteration 29104, lr = 0.0005
I0523 22:36:56.929256 23120 solver.cpp:237] Iteration 29318, loss = 1.35698
I0523 22:36:56.929286 23120 solver.cpp:253]     Train net output #0: loss = 1.35698 (* 1 = 1.35698 loss)
I0523 22:36:56.929304 23120 sgd_solver.cpp:106] Iteration 29318, lr = 0.0005
I0523 22:37:05.800678 23120 solver.cpp:237] Iteration 29532, loss = 1.31416
I0523 22:37:05.800845 23120 solver.cpp:253]     Train net output #0: loss = 1.31416 (* 1 = 1.31416 loss)
I0523 22:37:05.800863 23120 sgd_solver.cpp:106] Iteration 29532, lr = 0.0005
I0523 22:37:14.670267 23120 solver.cpp:237] Iteration 29746, loss = 1.34623
I0523 22:37:14.670297 23120 solver.cpp:253]     Train net output #0: loss = 1.34623 (* 1 = 1.34623 loss)
I0523 22:37:14.670316 23120 sgd_solver.cpp:106] Iteration 29746, lr = 0.0005
I0523 22:37:23.534778 23120 solver.cpp:237] Iteration 29960, loss = 1.52791
I0523 22:37:23.534808 23120 solver.cpp:253]     Train net output #0: loss = 1.52791 (* 1 = 1.52791 loss)
I0523 22:37:23.534826 23120 sgd_solver.cpp:106] Iteration 29960, lr = 0.0005
I0523 22:37:24.655032 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_29988.caffemodel
I0523 22:37:24.721426 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_29988.solverstate
I0523 22:37:25.008838 23120 solver.cpp:341] Iteration 29995, Testing net (#0)
I0523 22:38:12.594856 23120 solver.cpp:409]     Test net output #0: accuracy = 0.803518
I0523 22:38:12.595026 23120 solver.cpp:409]     Test net output #1: loss = 0.705349 (* 1 = 0.705349 loss)
I0523 22:38:40.932570 23120 solver.cpp:237] Iteration 30174, loss = 1.42258
I0523 22:38:40.932618 23120 solver.cpp:253]     Train net output #0: loss = 1.42258 (* 1 = 1.42258 loss)
I0523 22:38:40.932637 23120 sgd_solver.cpp:106] Iteration 30174, lr = 0.0005
I0523 22:38:49.809607 23120 solver.cpp:237] Iteration 30388, loss = 1.20857
I0523 22:38:49.809782 23120 solver.cpp:253]     Train net output #0: loss = 1.20857 (* 1 = 1.20857 loss)
I0523 22:38:49.809799 23120 sgd_solver.cpp:106] Iteration 30388, lr = 0.0005
I0523 22:38:58.695525 23120 solver.cpp:237] Iteration 30602, loss = 1.18945
I0523 22:38:58.695555 23120 solver.cpp:253]     Train net output #0: loss = 1.18945 (* 1 = 1.18945 loss)
I0523 22:38:58.695574 23120 sgd_solver.cpp:106] Iteration 30602, lr = 0.0005
I0523 22:39:07.582070 23120 solver.cpp:237] Iteration 30816, loss = 1.35761
I0523 22:39:07.582100 23120 solver.cpp:253]     Train net output #0: loss = 1.35761 (* 1 = 1.35761 loss)
I0523 22:39:07.582119 23120 sgd_solver.cpp:106] Iteration 30816, lr = 0.0005
I0523 22:39:16.463714 23120 solver.cpp:237] Iteration 31030, loss = 1.34598
I0523 22:39:16.463757 23120 solver.cpp:253]     Train net output #0: loss = 1.34598 (* 1 = 1.34598 loss)
I0523 22:39:16.463774 23120 sgd_solver.cpp:106] Iteration 31030, lr = 0.0005
I0523 22:39:25.349601 23120 solver.cpp:237] Iteration 31244, loss = 1.27698
I0523 22:39:25.349779 23120 solver.cpp:253]     Train net output #0: loss = 1.27698 (* 1 = 1.27698 loss)
I0523 22:39:25.349795 23120 sgd_solver.cpp:106] Iteration 31244, lr = 0.0005
I0523 22:39:55.153373 23120 solver.cpp:237] Iteration 31458, loss = 1.50957
I0523 22:39:55.153419 23120 solver.cpp:253]     Train net output #0: loss = 1.50957 (* 1 = 1.50957 loss)
I0523 22:39:55.153435 23120 sgd_solver.cpp:106] Iteration 31458, lr = 0.0005
I0523 22:40:04.039926 23120 solver.cpp:237] Iteration 31672, loss = 1.24843
I0523 22:40:04.040097 23120 solver.cpp:253]     Train net output #0: loss = 1.24843 (* 1 = 1.24843 loss)
I0523 22:40:04.040115 23120 sgd_solver.cpp:106] Iteration 31672, lr = 0.0005
I0523 22:40:12.920598 23120 solver.cpp:237] Iteration 31886, loss = 1.43124
I0523 22:40:12.920634 23120 solver.cpp:253]     Train net output #0: loss = 1.43124 (* 1 = 1.43124 loss)
I0523 22:40:12.920651 23120 sgd_solver.cpp:106] Iteration 31886, lr = 0.0005
I0523 22:40:21.809479 23120 solver.cpp:237] Iteration 32100, loss = 1.22426
I0523 22:40:21.809509 23120 solver.cpp:253]     Train net output #0: loss = 1.22426 (* 1 = 1.22426 loss)
I0523 22:40:21.809526 23120 sgd_solver.cpp:106] Iteration 32100, lr = 0.0005
I0523 22:40:23.013479 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_32130.caffemodel
I0523 22:40:23.082449 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_32130.solverstate
I0523 22:40:30.757762 23120 solver.cpp:237] Iteration 32314, loss = 1.3772
I0523 22:40:30.757810 23120 solver.cpp:253]     Train net output #0: loss = 1.3772 (* 1 = 1.3772 loss)
I0523 22:40:30.757829 23120 sgd_solver.cpp:106] Iteration 32314, lr = 0.0005
I0523 22:40:39.642779 23120 solver.cpp:237] Iteration 32528, loss = 1.48461
I0523 22:40:39.642937 23120 solver.cpp:253]     Train net output #0: loss = 1.48461 (* 1 = 1.48461 loss)
I0523 22:40:39.642953 23120 sgd_solver.cpp:106] Iteration 32528, lr = 0.0005
I0523 22:40:48.531127 23120 solver.cpp:237] Iteration 32742, loss = 1.46668
I0523 22:40:48.531163 23120 solver.cpp:253]     Train net output #0: loss = 1.46668 (* 1 = 1.46668 loss)
I0523 22:40:48.531180 23120 sgd_solver.cpp:106] Iteration 32742, lr = 0.0005
I0523 22:41:18.384354 23120 solver.cpp:237] Iteration 32956, loss = 1.39227
I0523 22:41:18.384527 23120 solver.cpp:253]     Train net output #0: loss = 1.39227 (* 1 = 1.39227 loss)
I0523 22:41:18.384544 23120 sgd_solver.cpp:106] Iteration 32956, lr = 0.0005
I0523 22:41:27.270314 23120 solver.cpp:237] Iteration 33170, loss = 1.38725
I0523 22:41:27.270345 23120 solver.cpp:253]     Train net output #0: loss = 1.38725 (* 1 = 1.38725 loss)
I0523 22:41:27.270364 23120 sgd_solver.cpp:106] Iteration 33170, lr = 0.0005
I0523 22:41:36.158169 23120 solver.cpp:237] Iteration 33384, loss = 1.55653
I0523 22:41:36.158203 23120 solver.cpp:253]     Train net output #0: loss = 1.55653 (* 1 = 1.55653 loss)
I0523 22:41:36.158221 23120 sgd_solver.cpp:106] Iteration 33384, lr = 0.0005
I0523 22:41:45.044503 23120 solver.cpp:237] Iteration 33598, loss = 1.12429
I0523 22:41:45.044550 23120 solver.cpp:253]     Train net output #0: loss = 1.12429 (* 1 = 1.12429 loss)
I0523 22:41:45.044569 23120 sgd_solver.cpp:106] Iteration 33598, lr = 0.0005
I0523 22:41:53.937264 23120 solver.cpp:237] Iteration 33812, loss = 1.28704
I0523 22:41:53.937428 23120 solver.cpp:253]     Train net output #0: loss = 1.28704 (* 1 = 1.28704 loss)
I0523 22:41:53.937444 23120 sgd_solver.cpp:106] Iteration 33812, lr = 0.0005
I0523 22:42:02.827695 23120 solver.cpp:237] Iteration 34026, loss = 1.52471
I0523 22:42:02.827725 23120 solver.cpp:253]     Train net output #0: loss = 1.52471 (* 1 = 1.52471 loss)
I0523 22:42:02.827744 23120 sgd_solver.cpp:106] Iteration 34026, lr = 0.0005
I0523 22:42:11.714637 23120 solver.cpp:237] Iteration 34240, loss = 1.30988
I0523 22:42:11.714681 23120 solver.cpp:253]     Train net output #0: loss = 1.30988 (* 1 = 1.30988 loss)
I0523 22:42:11.714699 23120 sgd_solver.cpp:106] Iteration 34240, lr = 0.0005
I0523 22:42:12.998687 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_34272.caffemodel
I0523 22:42:13.071172 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_34272.solverstate
I0523 22:42:13.401577 23120 solver.cpp:341] Iteration 34280, Testing net (#0)
I0523 22:43:22.247737 23120 solver.cpp:409]     Test net output #0: accuracy = 0.811976
I0523 22:43:22.247912 23120 solver.cpp:409]     Test net output #1: loss = 0.639084 (* 1 = 0.639084 loss)
I0523 22:43:50.318455 23120 solver.cpp:237] Iteration 34454, loss = 1.5026
I0523 22:43:50.318502 23120 solver.cpp:253]     Train net output #0: loss = 1.5026 (* 1 = 1.5026 loss)
I0523 22:43:50.318519 23120 sgd_solver.cpp:106] Iteration 34454, lr = 0.0005
I0523 22:43:59.187518 23120 solver.cpp:237] Iteration 34668, loss = 1.49926
I0523 22:43:59.187676 23120 solver.cpp:253]     Train net output #0: loss = 1.49926 (* 1 = 1.49926 loss)
I0523 22:43:59.187692 23120 sgd_solver.cpp:106] Iteration 34668, lr = 0.0005
I0523 22:44:08.052007 23120 solver.cpp:237] Iteration 34882, loss = 1.1239
I0523 22:44:08.052037 23120 solver.cpp:253]     Train net output #0: loss = 1.1239 (* 1 = 1.1239 loss)
I0523 22:44:08.052055 23120 sgd_solver.cpp:106] Iteration 34882, lr = 0.0005
I0523 22:44:16.924235 23120 solver.cpp:237] Iteration 35096, loss = 1.47755
I0523 22:44:16.924273 23120 solver.cpp:253]     Train net output #0: loss = 1.47755 (* 1 = 1.47755 loss)
I0523 22:44:16.924293 23120 sgd_solver.cpp:106] Iteration 35096, lr = 0.0005
I0523 22:44:25.789523 23120 solver.cpp:237] Iteration 35310, loss = 1.31437
I0523 22:44:25.789552 23120 solver.cpp:253]     Train net output #0: loss = 1.31437 (* 1 = 1.31437 loss)
I0523 22:44:25.789571 23120 sgd_solver.cpp:106] Iteration 35310, lr = 0.0005
I0523 22:44:34.656528 23120 solver.cpp:237] Iteration 35524, loss = 1.45762
I0523 22:44:34.656697 23120 solver.cpp:253]     Train net output #0: loss = 1.45762 (* 1 = 1.45762 loss)
I0523 22:44:34.656713 23120 sgd_solver.cpp:106] Iteration 35524, lr = 0.0005
I0523 22:45:04.417934 23120 solver.cpp:237] Iteration 35738, loss = 1.69549
I0523 22:45:04.417984 23120 solver.cpp:253]     Train net output #0: loss = 1.69549 (* 1 = 1.69549 loss)
I0523 22:45:04.418002 23120 sgd_solver.cpp:106] Iteration 35738, lr = 0.0005
I0523 22:45:13.285364 23120 solver.cpp:237] Iteration 35952, loss = 1.35259
I0523 22:45:13.285519 23120 solver.cpp:253]     Train net output #0: loss = 1.35259 (* 1 = 1.35259 loss)
I0523 22:45:13.285536 23120 sgd_solver.cpp:106] Iteration 35952, lr = 0.0005
I0523 22:45:22.153251 23120 solver.cpp:237] Iteration 36166, loss = 1.29114
I0523 22:45:22.153282 23120 solver.cpp:253]     Train net output #0: loss = 1.29114 (* 1 = 1.29114 loss)
I0523 22:45:22.153301 23120 sgd_solver.cpp:106] Iteration 36166, lr = 0.0005
I0523 22:45:31.021232 23120 solver.cpp:237] Iteration 36380, loss = 1.22943
I0523 22:45:31.021271 23120 solver.cpp:253]     Train net output #0: loss = 1.22943 (* 1 = 1.22943 loss)
I0523 22:45:31.021291 23120 sgd_solver.cpp:106] Iteration 36380, lr = 0.0005
I0523 22:45:32.390763 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_36414.caffemodel
I0523 22:45:32.456745 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_36414.solverstate
I0523 22:45:39.955418 23120 solver.cpp:237] Iteration 36594, loss = 1.43645
I0523 22:45:39.955462 23120 solver.cpp:253]     Train net output #0: loss = 1.43645 (* 1 = 1.43645 loss)
I0523 22:45:39.955479 23120 sgd_solver.cpp:106] Iteration 36594, lr = 0.0005
I0523 22:45:48.825839 23120 solver.cpp:237] Iteration 36808, loss = 1.12415
I0523 22:45:48.826005 23120 solver.cpp:253]     Train net output #0: loss = 1.12415 (* 1 = 1.12415 loss)
I0523 22:45:48.826021 23120 sgd_solver.cpp:106] Iteration 36808, lr = 0.0005
I0523 22:45:57.700275 23120 solver.cpp:237] Iteration 37022, loss = 1.3902
I0523 22:45:57.700309 23120 solver.cpp:253]     Train net output #0: loss = 1.3902 (* 1 = 1.3902 loss)
I0523 22:45:57.700328 23120 sgd_solver.cpp:106] Iteration 37022, lr = 0.0005
I0523 22:46:27.449213 23120 solver.cpp:237] Iteration 37236, loss = 1.50414
I0523 22:46:27.449391 23120 solver.cpp:253]     Train net output #0: loss = 1.50414 (* 1 = 1.50414 loss)
I0523 22:46:27.449409 23120 sgd_solver.cpp:106] Iteration 37236, lr = 0.0005
I0523 22:46:36.319427 23120 solver.cpp:237] Iteration 37450, loss = 1.24996
I0523 22:46:36.319458 23120 solver.cpp:253]     Train net output #0: loss = 1.24996 (* 1 = 1.24996 loss)
I0523 22:46:36.319475 23120 sgd_solver.cpp:106] Iteration 37450, lr = 0.0005
I0523 22:46:45.184558 23120 solver.cpp:237] Iteration 37664, loss = 1.41506
I0523 22:46:45.184600 23120 solver.cpp:253]     Train net output #0: loss = 1.41506 (* 1 = 1.41506 loss)
I0523 22:46:45.184617 23120 sgd_solver.cpp:106] Iteration 37664, lr = 0.0005
I0523 22:46:54.050941 23120 solver.cpp:237] Iteration 37878, loss = 1.22232
I0523 22:46:54.050972 23120 solver.cpp:253]     Train net output #0: loss = 1.22232 (* 1 = 1.22232 loss)
I0523 22:46:54.050988 23120 sgd_solver.cpp:106] Iteration 37878, lr = 0.0005
I0523 22:47:02.923976 23120 solver.cpp:237] Iteration 38092, loss = 1.22389
I0523 22:47:02.924129 23120 solver.cpp:253]     Train net output #0: loss = 1.22389 (* 1 = 1.22389 loss)
I0523 22:47:02.924144 23120 sgd_solver.cpp:106] Iteration 38092, lr = 0.0005
I0523 22:47:11.792747 23120 solver.cpp:237] Iteration 38306, loss = 1.50729
I0523 22:47:11.792783 23120 solver.cpp:253]     Train net output #0: loss = 1.50729 (* 1 = 1.50729 loss)
I0523 22:47:11.792801 23120 sgd_solver.cpp:106] Iteration 38306, lr = 0.0005
I0523 22:47:20.657268 23120 solver.cpp:237] Iteration 38520, loss = 1.52223
I0523 22:47:20.657297 23120 solver.cpp:253]     Train net output #0: loss = 1.52223 (* 1 = 1.52223 loss)
I0523 22:47:20.657315 23120 sgd_solver.cpp:106] Iteration 38520, lr = 0.0005
I0523 22:47:22.107806 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_38556.caffemodel
I0523 22:47:22.173885 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_38556.solverstate
I0523 22:47:22.546505 23120 solver.cpp:341] Iteration 38565, Testing net (#0)
I0523 22:48:10.501822 23120 solver.cpp:409]     Test net output #0: accuracy = 0.819047
I0523 22:48:10.501986 23120 solver.cpp:409]     Test net output #1: loss = 0.661557 (* 1 = 0.661557 loss)
I0523 22:48:38.422510 23120 solver.cpp:237] Iteration 38734, loss = 1.53932
I0523 22:48:38.422562 23120 solver.cpp:253]     Train net output #0: loss = 1.53932 (* 1 = 1.53932 loss)
I0523 22:48:38.422580 23120 sgd_solver.cpp:106] Iteration 38734, lr = 0.0005
I0523 22:48:47.325331 23120 solver.cpp:237] Iteration 38948, loss = 1.24279
I0523 22:48:47.325501 23120 solver.cpp:253]     Train net output #0: loss = 1.24279 (* 1 = 1.24279 loss)
I0523 22:48:47.325518 23120 sgd_solver.cpp:106] Iteration 38948, lr = 0.0005
I0523 22:48:56.220592 23120 solver.cpp:237] Iteration 39162, loss = 1.3087
I0523 22:48:56.220623 23120 solver.cpp:253]     Train net output #0: loss = 1.3087 (* 1 = 1.3087 loss)
I0523 22:48:56.220640 23120 sgd_solver.cpp:106] Iteration 39162, lr = 0.0005
I0523 22:49:05.121917 23120 solver.cpp:237] Iteration 39376, loss = 1.25685
I0523 22:49:05.121953 23120 solver.cpp:253]     Train net output #0: loss = 1.25685 (* 1 = 1.25685 loss)
I0523 22:49:05.121969 23120 sgd_solver.cpp:106] Iteration 39376, lr = 0.0005
I0523 22:49:14.020573 23120 solver.cpp:237] Iteration 39590, loss = 1.23423
I0523 22:49:14.020612 23120 solver.cpp:253]     Train net output #0: loss = 1.23423 (* 1 = 1.23423 loss)
I0523 22:49:14.020632 23120 sgd_solver.cpp:106] Iteration 39590, lr = 0.0005
I0523 22:49:22.917160 23120 solver.cpp:237] Iteration 39804, loss = 1.37878
I0523 22:49:22.917325 23120 solver.cpp:253]     Train net output #0: loss = 1.37878 (* 1 = 1.37878 loss)
I0523 22:49:22.917341 23120 sgd_solver.cpp:106] Iteration 39804, lr = 0.0005
I0523 22:49:52.705173 23120 solver.cpp:237] Iteration 40018, loss = 1.39303
I0523 22:49:52.705220 23120 solver.cpp:253]     Train net output #0: loss = 1.39303 (* 1 = 1.39303 loss)
I0523 22:49:52.705238 23120 sgd_solver.cpp:106] Iteration 40018, lr = 0.0005
I0523 22:50:01.603871 23120 solver.cpp:237] Iteration 40232, loss = 1.3933
I0523 22:50:01.604041 23120 solver.cpp:253]     Train net output #0: loss = 1.3933 (* 1 = 1.3933 loss)
I0523 22:50:01.604058 23120 sgd_solver.cpp:106] Iteration 40232, lr = 0.0005
I0523 22:50:10.510330 23120 solver.cpp:237] Iteration 40446, loss = 1.49769
I0523 22:50:10.510361 23120 solver.cpp:253]     Train net output #0: loss = 1.49769 (* 1 = 1.49769 loss)
I0523 22:50:10.510378 23120 sgd_solver.cpp:106] Iteration 40446, lr = 0.0005
I0523 22:50:19.406721 23120 solver.cpp:237] Iteration 40660, loss = 1.39903
I0523 22:50:19.406751 23120 solver.cpp:253]     Train net output #0: loss = 1.39903 (* 1 = 1.39903 loss)
I0523 22:50:19.406769 23120 sgd_solver.cpp:106] Iteration 40660, lr = 0.0005
I0523 22:50:20.946429 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_40698.caffemodel
I0523 22:50:21.015067 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_40698.solverstate
I0523 22:50:28.372431 23120 solver.cpp:237] Iteration 40874, loss = 1.29431
I0523 22:50:28.372480 23120 solver.cpp:253]     Train net output #0: loss = 1.29431 (* 1 = 1.29431 loss)
I0523 22:50:28.372498 23120 sgd_solver.cpp:106] Iteration 40874, lr = 0.0005
I0523 22:50:37.268188 23120 solver.cpp:237] Iteration 41088, loss = 1.1674
I0523 22:50:37.268359 23120 solver.cpp:253]     Train net output #0: loss = 1.1674 (* 1 = 1.1674 loss)
I0523 22:50:37.268374 23120 sgd_solver.cpp:106] Iteration 41088, lr = 0.0005
I0523 22:50:46.162909 23120 solver.cpp:237] Iteration 41302, loss = 1.32623
I0523 22:50:46.162940 23120 solver.cpp:253]     Train net output #0: loss = 1.32623 (* 1 = 1.32623 loss)
I0523 22:50:46.162957 23120 sgd_solver.cpp:106] Iteration 41302, lr = 0.0005
I0523 22:51:15.931023 23120 solver.cpp:237] Iteration 41516, loss = 1.24644
I0523 22:51:15.931200 23120 solver.cpp:253]     Train net output #0: loss = 1.24644 (* 1 = 1.24644 loss)
I0523 22:51:15.931216 23120 sgd_solver.cpp:106] Iteration 41516, lr = 0.0005
I0523 22:51:24.828372 23120 solver.cpp:237] Iteration 41730, loss = 1.32044
I0523 22:51:24.828402 23120 solver.cpp:253]     Train net output #0: loss = 1.32044 (* 1 = 1.32044 loss)
I0523 22:51:24.828420 23120 sgd_solver.cpp:106] Iteration 41730, lr = 0.0005
I0523 22:51:33.723167 23120 solver.cpp:237] Iteration 41944, loss = 1.49377
I0523 22:51:33.723197 23120 solver.cpp:253]     Train net output #0: loss = 1.49377 (* 1 = 1.49377 loss)
I0523 22:51:33.723217 23120 sgd_solver.cpp:106] Iteration 41944, lr = 0.0005
I0523 22:51:42.624071 23120 solver.cpp:237] Iteration 42158, loss = 1.27591
I0523 22:51:42.624110 23120 solver.cpp:253]     Train net output #0: loss = 1.27591 (* 1 = 1.27591 loss)
I0523 22:51:42.624130 23120 sgd_solver.cpp:106] Iteration 42158, lr = 0.0005
I0523 22:51:51.520308 23120 solver.cpp:237] Iteration 42372, loss = 1.38164
I0523 22:51:51.520483 23120 solver.cpp:253]     Train net output #0: loss = 1.38164 (* 1 = 1.38164 loss)
I0523 22:51:51.520498 23120 sgd_solver.cpp:106] Iteration 42372, lr = 0.0005
I0523 22:52:00.421195 23120 solver.cpp:237] Iteration 42586, loss = 1.14842
I0523 22:52:00.421231 23120 solver.cpp:253]     Train net output #0: loss = 1.14842 (* 1 = 1.14842 loss)
I0523 22:52:00.421247 23120 sgd_solver.cpp:106] Iteration 42586, lr = 0.0005
I0523 22:52:09.321208 23120 solver.cpp:237] Iteration 42800, loss = 1.81422
I0523 22:52:09.321247 23120 solver.cpp:253]     Train net output #0: loss = 1.81422 (* 1 = 1.81422 loss)
I0523 22:52:09.321264 23120 sgd_solver.cpp:106] Iteration 42800, lr = 0.0005
I0523 22:52:10.941844 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_42840.caffemodel
I0523 22:52:11.010493 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_42840.solverstate
I0523 22:52:11.427043 23120 solver.cpp:341] Iteration 42850, Testing net (#0)
I0523 22:53:20.210932 23120 solver.cpp:409]     Test net output #0: accuracy = 0.820633
I0523 22:53:20.211110 23120 solver.cpp:409]     Test net output #1: loss = 0.608876 (* 1 = 0.608876 loss)
I0523 22:53:47.935556 23120 solver.cpp:237] Iteration 43014, loss = 1.17432
I0523 22:53:47.935606 23120 solver.cpp:253]     Train net output #0: loss = 1.17432 (* 1 = 1.17432 loss)
I0523 22:53:47.935626 23120 sgd_solver.cpp:106] Iteration 43014, lr = 0.0005
I0523 22:53:56.809494 23120 solver.cpp:237] Iteration 43228, loss = 1.20363
I0523 22:53:56.809655 23120 solver.cpp:253]     Train net output #0: loss = 1.20363 (* 1 = 1.20363 loss)
I0523 22:53:56.809671 23120 sgd_solver.cpp:106] Iteration 43228, lr = 0.0005
I0523 22:54:05.682047 23120 solver.cpp:237] Iteration 43442, loss = 1.1174
I0523 22:54:05.682085 23120 solver.cpp:253]     Train net output #0: loss = 1.1174 (* 1 = 1.1174 loss)
I0523 22:54:05.682101 23120 sgd_solver.cpp:106] Iteration 43442, lr = 0.0005
I0523 22:54:14.558130 23120 solver.cpp:237] Iteration 43656, loss = 1.64185
I0523 22:54:14.558168 23120 solver.cpp:253]     Train net output #0: loss = 1.64185 (* 1 = 1.64185 loss)
I0523 22:54:14.558187 23120 sgd_solver.cpp:106] Iteration 43656, lr = 0.0005
I0523 22:54:23.441208 23120 solver.cpp:237] Iteration 43870, loss = 1.29434
I0523 22:54:23.441238 23120 solver.cpp:253]     Train net output #0: loss = 1.29434 (* 1 = 1.29434 loss)
I0523 22:54:23.441257 23120 sgd_solver.cpp:106] Iteration 43870, lr = 0.0005
I0523 22:54:32.308656 23120 solver.cpp:237] Iteration 44084, loss = 1.54318
I0523 22:54:32.308811 23120 solver.cpp:253]     Train net output #0: loss = 1.54318 (* 1 = 1.54318 loss)
I0523 22:54:32.308828 23120 sgd_solver.cpp:106] Iteration 44084, lr = 0.0005
I0523 22:55:02.045750 23120 solver.cpp:237] Iteration 44298, loss = 1.60563
I0523 22:55:02.045800 23120 solver.cpp:253]     Train net output #0: loss = 1.60563 (* 1 = 1.60563 loss)
I0523 22:55:02.045819 23120 sgd_solver.cpp:106] Iteration 44298, lr = 0.0005
I0523 22:55:10.923794 23120 solver.cpp:237] Iteration 44512, loss = 1.48519
I0523 22:55:10.923956 23120 solver.cpp:253]     Train net output #0: loss = 1.48519 (* 1 = 1.48519 loss)
I0523 22:55:10.923972 23120 sgd_solver.cpp:106] Iteration 44512, lr = 0.0005
I0523 22:55:19.804628 23120 solver.cpp:237] Iteration 44726, loss = 1.33391
I0523 22:55:19.804659 23120 solver.cpp:253]     Train net output #0: loss = 1.33391 (* 1 = 1.33391 loss)
I0523 22:55:19.804677 23120 sgd_solver.cpp:106] Iteration 44726, lr = 0.0005
I0523 22:55:28.679152 23120 solver.cpp:237] Iteration 44940, loss = 1.30343
I0523 22:55:28.679199 23120 solver.cpp:253]     Train net output #0: loss = 1.30343 (* 1 = 1.30343 loss)
I0523 22:55:28.679217 23120 sgd_solver.cpp:106] Iteration 44940, lr = 0.0005
I0523 22:55:30.381561 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_44982.caffemodel
I0523 22:55:30.447751 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_44982.solverstate
I0523 22:55:37.624018 23120 solver.cpp:237] Iteration 45154, loss = 1.52171
I0523 22:55:37.624061 23120 solver.cpp:253]     Train net output #0: loss = 1.52171 (* 1 = 1.52171 loss)
I0523 22:55:37.624078 23120 sgd_solver.cpp:106] Iteration 45154, lr = 0.0005
I0523 22:55:46.501349 23120 solver.cpp:237] Iteration 45368, loss = 1.25098
I0523 22:55:46.501518 23120 solver.cpp:253]     Train net output #0: loss = 1.25098 (* 1 = 1.25098 loss)
I0523 22:55:46.501534 23120 sgd_solver.cpp:106] Iteration 45368, lr = 0.0005
I0523 22:55:55.375840 23120 solver.cpp:237] Iteration 45582, loss = 1.19746
I0523 22:55:55.375881 23120 solver.cpp:253]     Train net output #0: loss = 1.19746 (* 1 = 1.19746 loss)
I0523 22:55:55.375900 23120 sgd_solver.cpp:106] Iteration 45582, lr = 0.0005
I0523 22:56:25.145285 23120 solver.cpp:237] Iteration 45796, loss = 1.34474
I0523 22:56:25.145467 23120 solver.cpp:253]     Train net output #0: loss = 1.34474 (* 1 = 1.34474 loss)
I0523 22:56:25.145483 23120 sgd_solver.cpp:106] Iteration 45796, lr = 0.0005
I0523 22:56:34.020289 23120 solver.cpp:237] Iteration 46010, loss = 1.30601
I0523 22:56:34.020319 23120 solver.cpp:253]     Train net output #0: loss = 1.30601 (* 1 = 1.30601 loss)
I0523 22:56:34.020339 23120 sgd_solver.cpp:106] Iteration 46010, lr = 0.0005
I0523 22:56:42.899876 23120 solver.cpp:237] Iteration 46224, loss = 1.21163
I0523 22:56:42.899917 23120 solver.cpp:253]     Train net output #0: loss = 1.21163 (* 1 = 1.21163 loss)
I0523 22:56:42.899935 23120 sgd_solver.cpp:106] Iteration 46224, lr = 0.0005
I0523 22:56:51.779217 23120 solver.cpp:237] Iteration 46438, loss = 1.46432
I0523 22:56:51.779253 23120 solver.cpp:253]     Train net output #0: loss = 1.46432 (* 1 = 1.46432 loss)
I0523 22:56:51.779268 23120 sgd_solver.cpp:106] Iteration 46438, lr = 0.0005
I0523 22:57:00.653470 23120 solver.cpp:237] Iteration 46652, loss = 1.27442
I0523 22:57:00.653628 23120 solver.cpp:253]     Train net output #0: loss = 1.27442 (* 1 = 1.27442 loss)
I0523 22:57:00.653645 23120 sgd_solver.cpp:106] Iteration 46652, lr = 0.0005
I0523 22:57:09.535150 23120 solver.cpp:237] Iteration 46866, loss = 1.35764
I0523 22:57:09.535189 23120 solver.cpp:253]     Train net output #0: loss = 1.35764 (* 1 = 1.35764 loss)
I0523 22:57:09.535207 23120 sgd_solver.cpp:106] Iteration 46866, lr = 0.0005
I0523 22:57:18.415688 23120 solver.cpp:237] Iteration 47080, loss = 1.43092
I0523 22:57:18.415719 23120 solver.cpp:253]     Train net output #0: loss = 1.43092 (* 1 = 1.43092 loss)
I0523 22:57:18.415736 23120 sgd_solver.cpp:106] Iteration 47080, lr = 0.0005
I0523 22:57:20.199986 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_47124.caffemodel
I0523 22:57:20.265887 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_47124.solverstate
I0523 22:57:20.720185 23120 solver.cpp:341] Iteration 47135, Testing net (#0)
I0523 22:58:08.313472 23120 solver.cpp:409]     Test net output #0: accuracy = 0.829557
I0523 22:58:08.313655 23120 solver.cpp:409]     Test net output #1: loss = 0.581299 (* 1 = 0.581299 loss)
I0523 22:58:35.863898 23120 solver.cpp:237] Iteration 47294, loss = 1.3414
I0523 22:58:35.863946 23120 solver.cpp:253]     Train net output #0: loss = 1.3414 (* 1 = 1.3414 loss)
I0523 22:58:35.863965 23120 sgd_solver.cpp:106] Iteration 47294, lr = 0.0005
I0523 22:58:44.745203 23120 solver.cpp:237] Iteration 47508, loss = 1.10433
I0523 22:58:44.745385 23120 solver.cpp:253]     Train net output #0: loss = 1.10433 (* 1 = 1.10433 loss)
I0523 22:58:44.745404 23120 sgd_solver.cpp:106] Iteration 47508, lr = 0.0005
I0523 22:58:53.625828 23120 solver.cpp:237] Iteration 47722, loss = 1.30442
I0523 22:58:53.625859 23120 solver.cpp:253]     Train net output #0: loss = 1.30442 (* 1 = 1.30442 loss)
I0523 22:58:53.625877 23120 sgd_solver.cpp:106] Iteration 47722, lr = 0.0005
I0523 22:59:02.504179 23120 solver.cpp:237] Iteration 47936, loss = 1.18071
I0523 22:59:02.504216 23120 solver.cpp:253]     Train net output #0: loss = 1.18071 (* 1 = 1.18071 loss)
I0523 22:59:02.504233 23120 sgd_solver.cpp:106] Iteration 47936, lr = 0.0005
I0523 22:59:11.383970 23120 solver.cpp:237] Iteration 48150, loss = 1.43508
I0523 22:59:11.384013 23120 solver.cpp:253]     Train net output #0: loss = 1.43508 (* 1 = 1.43508 loss)
I0523 22:59:11.384032 23120 sgd_solver.cpp:106] Iteration 48150, lr = 0.0005
I0523 22:59:20.262207 23120 solver.cpp:237] Iteration 48364, loss = 1.53571
I0523 22:59:20.262367 23120 solver.cpp:253]     Train net output #0: loss = 1.53571 (* 1 = 1.53571 loss)
I0523 22:59:20.262383 23120 sgd_solver.cpp:106] Iteration 48364, lr = 0.0005
I0523 22:59:50.049847 23120 solver.cpp:237] Iteration 48578, loss = 1.29345
I0523 22:59:50.049896 23120 solver.cpp:253]     Train net output #0: loss = 1.29345 (* 1 = 1.29345 loss)
I0523 22:59:50.049914 23120 sgd_solver.cpp:106] Iteration 48578, lr = 0.0005
I0523 22:59:58.932721 23120 solver.cpp:237] Iteration 48792, loss = 1.35543
I0523 22:59:58.932886 23120 solver.cpp:253]     Train net output #0: loss = 1.35543 (* 1 = 1.35543 loss)
I0523 22:59:58.932904 23120 sgd_solver.cpp:106] Iteration 48792, lr = 0.0005
I0523 23:00:07.815677 23120 solver.cpp:237] Iteration 49006, loss = 1.42794
I0523 23:00:07.815719 23120 solver.cpp:253]     Train net output #0: loss = 1.42794 (* 1 = 1.42794 loss)
I0523 23:00:07.815737 23120 sgd_solver.cpp:106] Iteration 49006, lr = 0.0005
I0523 23:00:16.697247 23120 solver.cpp:237] Iteration 49220, loss = 1.34332
I0523 23:00:16.697278 23120 solver.cpp:253]     Train net output #0: loss = 1.34332 (* 1 = 1.34332 loss)
I0523 23:00:16.697295 23120 sgd_solver.cpp:106] Iteration 49220, lr = 0.0005
I0523 23:00:18.563735 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_49266.caffemodel
I0523 23:00:18.629181 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_49266.solverstate
I0523 23:00:25.641935 23120 solver.cpp:237] Iteration 49434, loss = 1.56175
I0523 23:00:25.641980 23120 solver.cpp:253]     Train net output #0: loss = 1.56175 (* 1 = 1.56175 loss)
I0523 23:00:25.641998 23120 sgd_solver.cpp:106] Iteration 49434, lr = 0.0005
I0523 23:00:34.521963 23120 solver.cpp:237] Iteration 49648, loss = 1.36452
I0523 23:00:34.522127 23120 solver.cpp:253]     Train net output #0: loss = 1.36452 (* 1 = 1.36452 loss)
I0523 23:00:34.522145 23120 sgd_solver.cpp:106] Iteration 49648, lr = 0.0005
I0523 23:00:43.401566 23120 solver.cpp:237] Iteration 49862, loss = 1.38667
I0523 23:00:43.401597 23120 solver.cpp:253]     Train net output #0: loss = 1.38667 (* 1 = 1.38667 loss)
I0523 23:00:43.401614 23120 sgd_solver.cpp:106] Iteration 49862, lr = 0.0005
I0523 23:01:13.177989 23120 solver.cpp:237] Iteration 50076, loss = 1.09676
I0523 23:01:13.178171 23120 solver.cpp:253]     Train net output #0: loss = 1.09676 (* 1 = 1.09676 loss)
I0523 23:01:13.178189 23120 sgd_solver.cpp:106] Iteration 50076, lr = 0.0005
I0523 23:01:22.061172 23120 solver.cpp:237] Iteration 50290, loss = 1.13787
I0523 23:01:22.061214 23120 solver.cpp:253]     Train net output #0: loss = 1.13787 (* 1 = 1.13787 loss)
I0523 23:01:22.061233 23120 sgd_solver.cpp:106] Iteration 50290, lr = 0.0005
I0523 23:01:30.944021 23120 solver.cpp:237] Iteration 50504, loss = 1.26471
I0523 23:01:30.944051 23120 solver.cpp:253]     Train net output #0: loss = 1.26471 (* 1 = 1.26471 loss)
I0523 23:01:30.944069 23120 sgd_solver.cpp:106] Iteration 50504, lr = 0.0005
I0523 23:01:39.817170 23120 solver.cpp:237] Iteration 50718, loss = 1.22777
I0523 23:01:39.817214 23120 solver.cpp:253]     Train net output #0: loss = 1.22777 (* 1 = 1.22777 loss)
I0523 23:01:39.817231 23120 sgd_solver.cpp:106] Iteration 50718, lr = 0.0005
I0523 23:01:48.690768 23120 solver.cpp:237] Iteration 50932, loss = 1.31825
I0523 23:01:48.690942 23120 solver.cpp:253]     Train net output #0: loss = 1.31825 (* 1 = 1.31825 loss)
I0523 23:01:48.690958 23120 sgd_solver.cpp:106] Iteration 50932, lr = 0.0005
I0523 23:01:57.569154 23120 solver.cpp:237] Iteration 51146, loss = 1.17692
I0523 23:01:57.569183 23120 solver.cpp:253]     Train net output #0: loss = 1.17692 (* 1 = 1.17692 loss)
I0523 23:01:57.569202 23120 sgd_solver.cpp:106] Iteration 51146, lr = 0.0005
I0523 23:02:06.452172 23120 solver.cpp:237] Iteration 51360, loss = 1.31236
I0523 23:02:06.452213 23120 solver.cpp:253]     Train net output #0: loss = 1.31236 (* 1 = 1.31236 loss)
I0523 23:02:06.452231 23120 sgd_solver.cpp:106] Iteration 51360, lr = 0.0005
I0523 23:02:08.403461 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_51408.caffemodel
I0523 23:02:08.469349 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_51408.solverstate
I0523 23:02:08.966426 23120 solver.cpp:341] Iteration 51420, Testing net (#0)
I0523 23:03:17.850643 23120 solver.cpp:409]     Test net output #0: accuracy = 0.831972
I0523 23:03:17.850836 23120 solver.cpp:409]     Test net output #1: loss = 0.570746 (* 1 = 0.570746 loss)
I0523 23:03:45.184878 23120 solver.cpp:237] Iteration 51574, loss = 1.39905
I0523 23:03:45.184927 23120 solver.cpp:253]     Train net output #0: loss = 1.39905 (* 1 = 1.39905 loss)
I0523 23:03:45.184945 23120 sgd_solver.cpp:106] Iteration 51574, lr = 0.0005
I0523 23:03:54.054550 23120 solver.cpp:237] Iteration 51788, loss = 1.41258
I0523 23:03:54.054716 23120 solver.cpp:253]     Train net output #0: loss = 1.41258 (* 1 = 1.41258 loss)
I0523 23:03:54.054733 23120 sgd_solver.cpp:106] Iteration 51788, lr = 0.0005
I0523 23:04:02.932351 23120 solver.cpp:237] Iteration 52002, loss = 1.16892
I0523 23:04:02.932381 23120 solver.cpp:253]     Train net output #0: loss = 1.16892 (* 1 = 1.16892 loss)
I0523 23:04:02.932399 23120 sgd_solver.cpp:106] Iteration 52002, lr = 0.0005
I0523 23:04:11.812491 23120 solver.cpp:237] Iteration 52216, loss = 1.13718
I0523 23:04:11.812536 23120 solver.cpp:253]     Train net output #0: loss = 1.13718 (* 1 = 1.13718 loss)
I0523 23:04:11.812553 23120 sgd_solver.cpp:106] Iteration 52216, lr = 0.0005
I0523 23:04:20.691714 23120 solver.cpp:237] Iteration 52430, loss = 1.26401
I0523 23:04:20.691745 23120 solver.cpp:253]     Train net output #0: loss = 1.26401 (* 1 = 1.26401 loss)
I0523 23:04:20.691761 23120 sgd_solver.cpp:106] Iteration 52430, lr = 0.0005
I0523 23:04:29.564785 23120 solver.cpp:237] Iteration 52644, loss = 1.05726
I0523 23:04:29.564945 23120 solver.cpp:253]     Train net output #0: loss = 1.05726 (* 1 = 1.05726 loss)
I0523 23:04:29.564961 23120 sgd_solver.cpp:106] Iteration 52644, lr = 0.0005
I0523 23:04:59.332007 23120 solver.cpp:237] Iteration 52858, loss = 1.22713
I0523 23:04:59.332063 23120 solver.cpp:253]     Train net output #0: loss = 1.22713 (* 1 = 1.22713 loss)
I0523 23:04:59.332082 23120 sgd_solver.cpp:106] Iteration 52858, lr = 0.0005
I0523 23:05:08.205814 23120 solver.cpp:237] Iteration 53072, loss = 1.49186
I0523 23:05:08.205991 23120 solver.cpp:253]     Train net output #0: loss = 1.49186 (* 1 = 1.49186 loss)
I0523 23:05:08.206007 23120 sgd_solver.cpp:106] Iteration 53072, lr = 0.0005
I0523 23:05:17.092069 23120 solver.cpp:237] Iteration 53286, loss = 1.34909
I0523 23:05:17.092100 23120 solver.cpp:253]     Train net output #0: loss = 1.34909 (* 1 = 1.34909 loss)
I0523 23:05:17.092121 23120 sgd_solver.cpp:106] Iteration 53286, lr = 0.0005
I0523 23:05:25.972589 23120 solver.cpp:237] Iteration 53500, loss = 1.33425
I0523 23:05:25.972635 23120 solver.cpp:253]     Train net output #0: loss = 1.33425 (* 1 = 1.33425 loss)
I0523 23:05:25.972652 23120 sgd_solver.cpp:106] Iteration 53500, lr = 0.0005
I0523 23:05:28.003557 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_53550.caffemodel
I0523 23:05:28.130369 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_53550.solverstate
I0523 23:05:34.975359 23120 solver.cpp:237] Iteration 53714, loss = 1.17229
I0523 23:05:34.975407 23120 solver.cpp:253]     Train net output #0: loss = 1.17229 (* 1 = 1.17229 loss)
I0523 23:05:34.975426 23120 sgd_solver.cpp:106] Iteration 53714, lr = 0.0005
I0523 23:05:43.851809 23120 solver.cpp:237] Iteration 53928, loss = 1.40134
I0523 23:05:43.851975 23120 solver.cpp:253]     Train net output #0: loss = 1.40134 (* 1 = 1.40134 loss)
I0523 23:05:43.851989 23120 sgd_solver.cpp:106] Iteration 53928, lr = 0.0005
I0523 23:05:52.728473 23120 solver.cpp:237] Iteration 54142, loss = 1.48387
I0523 23:05:52.728516 23120 solver.cpp:253]     Train net output #0: loss = 1.48387 (* 1 = 1.48387 loss)
I0523 23:05:52.728535 23120 sgd_solver.cpp:106] Iteration 54142, lr = 0.0005
I0523 23:06:22.513764 23120 solver.cpp:237] Iteration 54356, loss = 1.1776
I0523 23:06:22.513947 23120 solver.cpp:253]     Train net output #0: loss = 1.1776 (* 1 = 1.1776 loss)
I0523 23:06:22.513962 23120 sgd_solver.cpp:106] Iteration 54356, lr = 0.0005
I0523 23:06:31.392012 23120 solver.cpp:237] Iteration 54570, loss = 1.28846
I0523 23:06:31.392047 23120 solver.cpp:253]     Train net output #0: loss = 1.28846 (* 1 = 1.28846 loss)
I0523 23:06:31.392063 23120 sgd_solver.cpp:106] Iteration 54570, lr = 0.0005
I0523 23:06:40.265784 23120 solver.cpp:237] Iteration 54784, loss = 1.15561
I0523 23:06:40.265822 23120 solver.cpp:253]     Train net output #0: loss = 1.15561 (* 1 = 1.15561 loss)
I0523 23:06:40.265843 23120 sgd_solver.cpp:106] Iteration 54784, lr = 0.0005
I0523 23:06:49.141340 23120 solver.cpp:237] Iteration 54998, loss = 1.42078
I0523 23:06:49.141371 23120 solver.cpp:253]     Train net output #0: loss = 1.42078 (* 1 = 1.42078 loss)
I0523 23:06:49.141392 23120 sgd_solver.cpp:106] Iteration 54998, lr = 0.0005
I0523 23:06:58.024817 23120 solver.cpp:237] Iteration 55212, loss = 1.32023
I0523 23:06:58.024986 23120 solver.cpp:253]     Train net output #0: loss = 1.32023 (* 1 = 1.32023 loss)
I0523 23:06:58.024998 23120 sgd_solver.cpp:106] Iteration 55212, lr = 0.0005
I0523 23:07:06.898275 23120 solver.cpp:237] Iteration 55426, loss = 1.17456
I0523 23:07:06.898315 23120 solver.cpp:253]     Train net output #0: loss = 1.17456 (* 1 = 1.17456 loss)
I0523 23:07:06.898339 23120 sgd_solver.cpp:106] Iteration 55426, lr = 0.0005
I0523 23:07:15.773584 23120 solver.cpp:237] Iteration 55640, loss = 1.26201
I0523 23:07:15.773614 23120 solver.cpp:253]     Train net output #0: loss = 1.26201 (* 1 = 1.26201 loss)
I0523 23:07:15.773636 23120 sgd_solver.cpp:106] Iteration 55640, lr = 0.0005
I0523 23:07:17.889567 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_55692.caffemodel
I0523 23:07:17.955322 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_55692.solverstate
I0523 23:07:18.493557 23120 solver.cpp:341] Iteration 55705, Testing net (#0)
I0523 23:08:06.464284 23120 solver.cpp:409]     Test net output #0: accuracy = 0.830312
I0523 23:08:06.464473 23120 solver.cpp:409]     Test net output #1: loss = 0.54009 (* 1 = 0.54009 loss)
I0523 23:08:33.555744 23120 solver.cpp:237] Iteration 55854, loss = 1.27606
I0523 23:08:33.555794 23120 solver.cpp:253]     Train net output #0: loss = 1.27606 (* 1 = 1.27606 loss)
I0523 23:08:33.555811 23120 sgd_solver.cpp:106] Iteration 55854, lr = 0.0005
I0523 23:08:42.416589 23120 solver.cpp:237] Iteration 56068, loss = 1.62968
I0523 23:08:42.416757 23120 solver.cpp:253]     Train net output #0: loss = 1.62968 (* 1 = 1.62968 loss)
I0523 23:08:42.416770 23120 sgd_solver.cpp:106] Iteration 56068, lr = 0.0005
I0523 23:08:51.283330 23120 solver.cpp:237] Iteration 56282, loss = 1.15313
I0523 23:08:51.283371 23120 solver.cpp:253]     Train net output #0: loss = 1.15313 (* 1 = 1.15313 loss)
I0523 23:08:51.283388 23120 sgd_solver.cpp:106] Iteration 56282, lr = 0.0005
I0523 23:09:00.153895 23120 solver.cpp:237] Iteration 56496, loss = 1.26837
I0523 23:09:00.153929 23120 solver.cpp:253]     Train net output #0: loss = 1.26837 (* 1 = 1.26837 loss)
I0523 23:09:00.153946 23120 sgd_solver.cpp:106] Iteration 56496, lr = 0.0005
I0523 23:09:09.027436 23120 solver.cpp:237] Iteration 56710, loss = 1.33055
I0523 23:09:09.027472 23120 solver.cpp:253]     Train net output #0: loss = 1.33055 (* 1 = 1.33055 loss)
I0523 23:09:09.027487 23120 sgd_solver.cpp:106] Iteration 56710, lr = 0.0005
I0523 23:09:17.897030 23120 solver.cpp:237] Iteration 56924, loss = 1.07796
I0523 23:09:17.897202 23120 solver.cpp:253]     Train net output #0: loss = 1.07796 (* 1 = 1.07796 loss)
I0523 23:09:17.897214 23120 sgd_solver.cpp:106] Iteration 56924, lr = 0.0005
I0523 23:09:26.764588 23120 solver.cpp:237] Iteration 57138, loss = 1.24206
I0523 23:09:26.764623 23120 solver.cpp:253]     Train net output #0: loss = 1.24206 (* 1 = 1.24206 loss)
I0523 23:09:26.764642 23120 sgd_solver.cpp:106] Iteration 57138, lr = 0.0005
I0523 23:09:56.521878 23120 solver.cpp:237] Iteration 57352, loss = 1.41059
I0523 23:09:56.522061 23120 solver.cpp:253]     Train net output #0: loss = 1.41059 (* 1 = 1.41059 loss)
I0523 23:09:56.522075 23120 sgd_solver.cpp:106] Iteration 57352, lr = 0.0005
I0523 23:10:05.384214 23120 solver.cpp:237] Iteration 57566, loss = 1.47063
I0523 23:10:05.384256 23120 solver.cpp:253]     Train net output #0: loss = 1.47063 (* 1 = 1.47063 loss)
I0523 23:10:05.384274 23120 sgd_solver.cpp:106] Iteration 57566, lr = 0.0005
I0523 23:10:14.253892 23120 solver.cpp:237] Iteration 57780, loss = 1.33618
I0523 23:10:14.253922 23120 solver.cpp:253]     Train net output #0: loss = 1.33618 (* 1 = 1.33618 loss)
I0523 23:10:14.253947 23120 sgd_solver.cpp:106] Iteration 57780, lr = 0.0005
I0523 23:10:16.453642 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_57834.caffemodel
I0523 23:10:16.520189 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_57834.solverstate
I0523 23:10:23.189674 23120 solver.cpp:237] Iteration 57994, loss = 1.23686
I0523 23:10:23.189723 23120 solver.cpp:253]     Train net output #0: loss = 1.23686 (* 1 = 1.23686 loss)
I0523 23:10:23.189736 23120 sgd_solver.cpp:106] Iteration 57994, lr = 0.0005
I0523 23:10:32.060657 23120 solver.cpp:237] Iteration 58208, loss = 1.62813
I0523 23:10:32.060834 23120 solver.cpp:253]     Train net output #0: loss = 1.62813 (* 1 = 1.62813 loss)
I0523 23:10:32.060847 23120 sgd_solver.cpp:106] Iteration 58208, lr = 0.0005
I0523 23:10:40.934464 23120 solver.cpp:237] Iteration 58422, loss = 0.978031
I0523 23:10:40.934495 23120 solver.cpp:253]     Train net output #0: loss = 0.978031 (* 1 = 0.978031 loss)
I0523 23:10:40.934519 23120 sgd_solver.cpp:106] Iteration 58422, lr = 0.0005
I0523 23:11:10.715934 23120 solver.cpp:237] Iteration 58636, loss = 1.28861
I0523 23:11:10.716128 23120 solver.cpp:253]     Train net output #0: loss = 1.28861 (* 1 = 1.28861 loss)
I0523 23:11:10.716142 23120 sgd_solver.cpp:106] Iteration 58636, lr = 0.0005
I0523 23:11:19.586998 23120 solver.cpp:237] Iteration 58850, loss = 1.46787
I0523 23:11:19.587045 23120 solver.cpp:253]     Train net output #0: loss = 1.46787 (* 1 = 1.46787 loss)
I0523 23:11:19.587065 23120 sgd_solver.cpp:106] Iteration 58850, lr = 0.0005
I0523 23:11:28.454780 23120 solver.cpp:237] Iteration 59064, loss = 1.33245
I0523 23:11:28.454812 23120 solver.cpp:253]     Train net output #0: loss = 1.33245 (* 1 = 1.33245 loss)
I0523 23:11:28.454831 23120 sgd_solver.cpp:106] Iteration 59064, lr = 0.0005
I0523 23:11:37.321915 23120 solver.cpp:237] Iteration 59278, loss = 1.37125
I0523 23:11:37.321945 23120 solver.cpp:253]     Train net output #0: loss = 1.37125 (* 1 = 1.37125 loss)
I0523 23:11:37.321966 23120 sgd_solver.cpp:106] Iteration 59278, lr = 0.0005
I0523 23:11:46.192896 23120 solver.cpp:237] Iteration 59492, loss = 1.29925
I0523 23:11:46.193073 23120 solver.cpp:253]     Train net output #0: loss = 1.29925 (* 1 = 1.29925 loss)
I0523 23:11:46.193087 23120 sgd_solver.cpp:106] Iteration 59492, lr = 0.0005
I0523 23:11:55.065253 23120 solver.cpp:237] Iteration 59706, loss = 1.228
I0523 23:11:55.065284 23120 solver.cpp:253]     Train net output #0: loss = 1.228 (* 1 = 1.228 loss)
I0523 23:11:55.065299 23120 sgd_solver.cpp:106] Iteration 59706, lr = 0.0005
I0523 23:12:03.935025 23120 solver.cpp:237] Iteration 59920, loss = 1.20499
I0523 23:12:03.935057 23120 solver.cpp:253]     Train net output #0: loss = 1.20499 (* 1 = 1.20499 loss)
I0523 23:12:03.935081 23120 sgd_solver.cpp:106] Iteration 59920, lr = 0.0005
I0523 23:12:06.215570 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_59976.caffemodel
I0523 23:12:06.281525 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_59976.solverstate
I0523 23:12:06.862242 23120 solver.cpp:341] Iteration 59990, Testing net (#0)
I0523 23:13:15.722363 23120 solver.cpp:409]     Test net output #0: accuracy = 0.838955
I0523 23:13:15.722545 23120 solver.cpp:409]     Test net output #1: loss = 0.521011 (* 1 = 0.521011 loss)
I0523 23:13:42.614015 23120 solver.cpp:237] Iteration 60134, loss = 1.3119
I0523 23:13:42.614065 23120 solver.cpp:253]     Train net output #0: loss = 1.3119 (* 1 = 1.3119 loss)
I0523 23:13:42.614084 23120 sgd_solver.cpp:106] Iteration 60134, lr = 0.0005
I0523 23:13:51.500030 23120 solver.cpp:237] Iteration 60348, loss = 1.29922
I0523 23:13:51.500200 23120 solver.cpp:253]     Train net output #0: loss = 1.29922 (* 1 = 1.29922 loss)
I0523 23:13:51.500214 23120 sgd_solver.cpp:106] Iteration 60348, lr = 0.0005
I0523 23:14:00.384435 23120 solver.cpp:237] Iteration 60562, loss = 1.29221
I0523 23:14:00.384465 23120 solver.cpp:253]     Train net output #0: loss = 1.29221 (* 1 = 1.29221 loss)
I0523 23:14:00.384491 23120 sgd_solver.cpp:106] Iteration 60562, lr = 0.0005
I0523 23:14:09.270005 23120 solver.cpp:237] Iteration 60776, loss = 1.32752
I0523 23:14:09.270051 23120 solver.cpp:253]     Train net output #0: loss = 1.32752 (* 1 = 1.32752 loss)
I0523 23:14:09.270069 23120 sgd_solver.cpp:106] Iteration 60776, lr = 0.0005
I0523 23:14:18.152868 23120 solver.cpp:237] Iteration 60990, loss = 1.40454
I0523 23:14:18.152899 23120 solver.cpp:253]     Train net output #0: loss = 1.40454 (* 1 = 1.40454 loss)
I0523 23:14:18.152918 23120 sgd_solver.cpp:106] Iteration 60990, lr = 0.0005
I0523 23:14:27.037356 23120 solver.cpp:237] Iteration 61204, loss = 1.19865
I0523 23:14:27.037519 23120 solver.cpp:253]     Train net output #0: loss = 1.19865 (* 1 = 1.19865 loss)
I0523 23:14:27.037533 23120 sgd_solver.cpp:106] Iteration 61204, lr = 0.0005
I0523 23:14:35.931561 23120 solver.cpp:237] Iteration 61418, loss = 1.35432
I0523 23:14:35.931608 23120 solver.cpp:253]     Train net output #0: loss = 1.35432 (* 1 = 1.35432 loss)
I0523 23:14:35.931625 23120 sgd_solver.cpp:106] Iteration 61418, lr = 0.0005
I0523 23:15:05.714084 23120 solver.cpp:237] Iteration 61632, loss = 1.40115
I0523 23:15:05.714277 23120 solver.cpp:253]     Train net output #0: loss = 1.40115 (* 1 = 1.40115 loss)
I0523 23:15:05.714292 23120 sgd_solver.cpp:106] Iteration 61632, lr = 0.0005
I0523 23:15:14.597676 23120 solver.cpp:237] Iteration 61846, loss = 1.199
I0523 23:15:14.597712 23120 solver.cpp:253]     Train net output #0: loss = 1.199 (* 1 = 1.199 loss)
I0523 23:15:14.597728 23120 sgd_solver.cpp:106] Iteration 61846, lr = 0.0005
I0523 23:15:23.483969 23120 solver.cpp:237] Iteration 62060, loss = 1.33595
I0523 23:15:23.483999 23120 solver.cpp:253]     Train net output #0: loss = 1.33595 (* 1 = 1.33595 loss)
I0523 23:15:23.484022 23120 sgd_solver.cpp:106] Iteration 62060, lr = 0.0005
I0523 23:15:25.850765 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_62118.caffemodel
I0523 23:15:25.919127 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_62118.solverstate
I0523 23:15:32.433575 23120 solver.cpp:237] Iteration 62274, loss = 1.24867
I0523 23:15:32.433620 23120 solver.cpp:253]     Train net output #0: loss = 1.24867 (* 1 = 1.24867 loss)
I0523 23:15:32.433643 23120 sgd_solver.cpp:106] Iteration 62274, lr = 0.0005
I0523 23:15:41.316568 23120 solver.cpp:237] Iteration 62488, loss = 1.39373
I0523 23:15:41.316738 23120 solver.cpp:253]     Train net output #0: loss = 1.39373 (* 1 = 1.39373 loss)
I0523 23:15:41.316751 23120 sgd_solver.cpp:106] Iteration 62488, lr = 0.0005
I0523 23:15:50.197072 23120 solver.cpp:237] Iteration 62702, loss = 1.44161
I0523 23:15:50.197124 23120 solver.cpp:253]     Train net output #0: loss = 1.44161 (* 1 = 1.44161 loss)
I0523 23:15:50.197139 23120 sgd_solver.cpp:106] Iteration 62702, lr = 0.0005
I0523 23:16:20.019290 23120 solver.cpp:237] Iteration 62916, loss = 1.29869
I0523 23:16:20.019475 23120 solver.cpp:253]     Train net output #0: loss = 1.29869 (* 1 = 1.29869 loss)
I0523 23:16:20.019490 23120 sgd_solver.cpp:106] Iteration 62916, lr = 0.0005
I0523 23:16:28.904556 23120 solver.cpp:237] Iteration 63130, loss = 1.48965
I0523 23:16:28.904587 23120 solver.cpp:253]     Train net output #0: loss = 1.48965 (* 1 = 1.48965 loss)
I0523 23:16:28.904609 23120 sgd_solver.cpp:106] Iteration 63130, lr = 0.0005
I0523 23:16:37.795106 23120 solver.cpp:237] Iteration 63344, loss = 1.15521
I0523 23:16:37.795141 23120 solver.cpp:253]     Train net output #0: loss = 1.15521 (* 1 = 1.15521 loss)
I0523 23:16:37.795157 23120 sgd_solver.cpp:106] Iteration 63344, lr = 0.0005
I0523 23:16:46.685515 23120 solver.cpp:237] Iteration 63558, loss = 1.17911
I0523 23:16:46.685559 23120 solver.cpp:253]     Train net output #0: loss = 1.17911 (* 1 = 1.17911 loss)
I0523 23:16:46.685575 23120 sgd_solver.cpp:106] Iteration 63558, lr = 0.0005
I0523 23:16:55.568605 23120 solver.cpp:237] Iteration 63772, loss = 1.30442
I0523 23:16:55.568778 23120 solver.cpp:253]     Train net output #0: loss = 1.30442 (* 1 = 1.30442 loss)
I0523 23:16:55.568792 23120 sgd_solver.cpp:106] Iteration 63772, lr = 0.0005
I0523 23:17:04.453043 23120 solver.cpp:237] Iteration 63986, loss = 1.18514
I0523 23:17:04.453093 23120 solver.cpp:253]     Train net output #0: loss = 1.18514 (* 1 = 1.18514 loss)
I0523 23:17:04.453107 23120 sgd_solver.cpp:106] Iteration 63986, lr = 0.0005
I0523 23:17:13.340684 23120 solver.cpp:237] Iteration 64200, loss = 1.39661
I0523 23:17:13.340714 23120 solver.cpp:253]     Train net output #0: loss = 1.39661 (* 1 = 1.39661 loss)
I0523 23:17:13.340735 23120 sgd_solver.cpp:106] Iteration 64200, lr = 0.0005
I0523 23:17:15.787709 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_64260.caffemodel
I0523 23:17:15.856456 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_64260.solverstate
I0523 23:17:16.479362 23120 solver.cpp:341] Iteration 64275, Testing net (#0)
I0523 23:18:04.137192 23120 solver.cpp:409]     Test net output #0: accuracy = 0.844024
I0523 23:18:04.137384 23120 solver.cpp:409]     Test net output #1: loss = 0.537553 (* 1 = 0.537553 loss)
I0523 23:18:30.830560 23120 solver.cpp:237] Iteration 64414, loss = 1.29818
I0523 23:18:30.830610 23120 solver.cpp:253]     Train net output #0: loss = 1.29818 (* 1 = 1.29818 loss)
I0523 23:18:30.830627 23120 sgd_solver.cpp:106] Iteration 64414, lr = 0.0005
I0523 23:18:39.696496 23120 solver.cpp:237] Iteration 64628, loss = 1.33582
I0523 23:18:39.696667 23120 solver.cpp:253]     Train net output #0: loss = 1.33582 (* 1 = 1.33582 loss)
I0523 23:18:39.696681 23120 sgd_solver.cpp:106] Iteration 64628, lr = 0.0005
I0523 23:18:48.558825 23120 solver.cpp:237] Iteration 64842, loss = 1.08098
I0523 23:18:48.558871 23120 solver.cpp:253]     Train net output #0: loss = 1.08098 (* 1 = 1.08098 loss)
I0523 23:18:48.558888 23120 sgd_solver.cpp:106] Iteration 64842, lr = 0.0005
I0523 23:18:57.422025 23120 solver.cpp:237] Iteration 65056, loss = 1.20315
I0523 23:18:57.422055 23120 solver.cpp:253]     Train net output #0: loss = 1.20315 (* 1 = 1.20315 loss)
I0523 23:18:57.422081 23120 sgd_solver.cpp:106] Iteration 65056, lr = 0.0005
I0523 23:19:06.291853 23120 solver.cpp:237] Iteration 65270, loss = 1.11857
I0523 23:19:06.291885 23120 solver.cpp:253]     Train net output #0: loss = 1.11857 (* 1 = 1.11857 loss)
I0523 23:19:06.291908 23120 sgd_solver.cpp:106] Iteration 65270, lr = 0.0005
I0523 23:19:15.154968 23120 solver.cpp:237] Iteration 65484, loss = 1.52871
I0523 23:19:15.155140 23120 solver.cpp:253]     Train net output #0: loss = 1.52871 (* 1 = 1.52871 loss)
I0523 23:19:15.155154 23120 sgd_solver.cpp:106] Iteration 65484, lr = 0.0005
I0523 23:19:24.022064 23120 solver.cpp:237] Iteration 65698, loss = 1.67384
I0523 23:19:24.022094 23120 solver.cpp:253]     Train net output #0: loss = 1.67384 (* 1 = 1.67384 loss)
I0523 23:19:24.022116 23120 sgd_solver.cpp:106] Iteration 65698, lr = 0.0005
I0523 23:19:53.787860 23120 solver.cpp:237] Iteration 65912, loss = 1.28846
I0523 23:19:53.788046 23120 solver.cpp:253]     Train net output #0: loss = 1.28846 (* 1 = 1.28846 loss)
I0523 23:19:53.788060 23120 sgd_solver.cpp:106] Iteration 65912, lr = 0.0005
I0523 23:20:02.659680 23120 solver.cpp:237] Iteration 66126, loss = 1.14701
I0523 23:20:02.659720 23120 solver.cpp:253]     Train net output #0: loss = 1.14701 (* 1 = 1.14701 loss)
I0523 23:20:02.659744 23120 sgd_solver.cpp:106] Iteration 66126, lr = 0.0005
I0523 23:20:11.533016 23120 solver.cpp:237] Iteration 66340, loss = 0.992119
I0523 23:20:11.533049 23120 solver.cpp:253]     Train net output #0: loss = 0.992119 (* 1 = 0.992119 loss)
I0523 23:20:11.533068 23120 sgd_solver.cpp:106] Iteration 66340, lr = 0.0005
I0523 23:20:14.062129 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_66402.caffemodel
I0523 23:20:14.128748 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_66402.solverstate
I0523 23:20:20.467938 23120 solver.cpp:237] Iteration 66554, loss = 1.14658
I0523 23:20:20.467980 23120 solver.cpp:253]     Train net output #0: loss = 1.14658 (* 1 = 1.14658 loss)
I0523 23:20:20.468003 23120 sgd_solver.cpp:106] Iteration 66554, lr = 0.0005
I0523 23:20:29.334990 23120 solver.cpp:237] Iteration 66768, loss = 1.35309
I0523 23:20:29.335177 23120 solver.cpp:253]     Train net output #0: loss = 1.35309 (* 1 = 1.35309 loss)
I0523 23:20:29.335191 23120 sgd_solver.cpp:106] Iteration 66768, lr = 0.0005
I0523 23:20:38.205996 23120 solver.cpp:237] Iteration 66982, loss = 1.3098
I0523 23:20:38.206028 23120 solver.cpp:253]     Train net output #0: loss = 1.3098 (* 1 = 1.3098 loss)
I0523 23:20:38.206048 23120 sgd_solver.cpp:106] Iteration 66982, lr = 0.0005
I0523 23:21:07.975302 23120 solver.cpp:237] Iteration 67196, loss = 1.24927
I0523 23:21:07.975492 23120 solver.cpp:253]     Train net output #0: loss = 1.24927 (* 1 = 1.24927 loss)
I0523 23:21:07.975505 23120 sgd_solver.cpp:106] Iteration 67196, lr = 0.0005
I0523 23:21:16.844184 23120 solver.cpp:237] Iteration 67410, loss = 1.15315
I0523 23:21:16.844233 23120 solver.cpp:253]     Train net output #0: loss = 1.15315 (* 1 = 1.15315 loss)
I0523 23:21:16.844249 23120 sgd_solver.cpp:106] Iteration 67410, lr = 0.0005
I0523 23:21:25.712654 23120 solver.cpp:237] Iteration 67624, loss = 1.24165
I0523 23:21:25.712685 23120 solver.cpp:253]     Train net output #0: loss = 1.24165 (* 1 = 1.24165 loss)
I0523 23:21:25.712708 23120 sgd_solver.cpp:106] Iteration 67624, lr = 0.0005
I0523 23:21:34.586293 23120 solver.cpp:237] Iteration 67838, loss = 1.33028
I0523 23:21:34.586326 23120 solver.cpp:253]     Train net output #0: loss = 1.33028 (* 1 = 1.33028 loss)
I0523 23:21:34.586345 23120 sgd_solver.cpp:106] Iteration 67838, lr = 0.0005
I0523 23:21:43.454474 23120 solver.cpp:237] Iteration 68052, loss = 1.1941
I0523 23:21:43.454653 23120 solver.cpp:253]     Train net output #0: loss = 1.1941 (* 1 = 1.1941 loss)
I0523 23:21:43.454666 23120 sgd_solver.cpp:106] Iteration 68052, lr = 0.0005
I0523 23:21:52.321244 23120 solver.cpp:237] Iteration 68266, loss = 1.17333
I0523 23:21:52.321274 23120 solver.cpp:253]     Train net output #0: loss = 1.17333 (* 1 = 1.17333 loss)
I0523 23:21:52.321295 23120 sgd_solver.cpp:106] Iteration 68266, lr = 0.0005
I0523 23:22:01.189091 23120 solver.cpp:237] Iteration 68480, loss = 1.26789
I0523 23:22:01.189121 23120 solver.cpp:253]     Train net output #0: loss = 1.26789 (* 1 = 1.26789 loss)
I0523 23:22:01.189146 23120 sgd_solver.cpp:106] Iteration 68480, lr = 0.0005
I0523 23:22:03.798161 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_68544.caffemodel
I0523 23:22:03.864192 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_68544.solverstate
I0523 23:22:04.526461 23120 solver.cpp:341] Iteration 68560, Testing net (#0)
I0523 23:23:13.345546 23120 solver.cpp:409]     Test net output #0: accuracy = 0.847051
I0523 23:23:13.345742 23120 solver.cpp:409]     Test net output #1: loss = 0.529104 (* 1 = 0.529104 loss)
I0523 23:23:39.864981 23120 solver.cpp:237] Iteration 68694, loss = 1.34093
I0523 23:23:39.865031 23120 solver.cpp:253]     Train net output #0: loss = 1.34093 (* 1 = 1.34093 loss)
I0523 23:23:39.865051 23120 sgd_solver.cpp:106] Iteration 68694, lr = 0.0005
I0523 23:23:48.761167 23120 solver.cpp:237] Iteration 68908, loss = 1.38673
I0523 23:23:48.761351 23120 solver.cpp:253]     Train net output #0: loss = 1.38673 (* 1 = 1.38673 loss)
I0523 23:23:48.761365 23120 sgd_solver.cpp:106] Iteration 68908, lr = 0.0005
I0523 23:23:57.661315 23120 solver.cpp:237] Iteration 69122, loss = 1.36976
I0523 23:23:57.661345 23120 solver.cpp:253]     Train net output #0: loss = 1.36976 (* 1 = 1.36976 loss)
I0523 23:23:57.661370 23120 sgd_solver.cpp:106] Iteration 69122, lr = 0.0005
I0523 23:24:06.557960 23120 solver.cpp:237] Iteration 69336, loss = 0.952194
I0523 23:24:06.557994 23120 solver.cpp:253]     Train net output #0: loss = 0.952194 (* 1 = 0.952194 loss)
I0523 23:24:06.558012 23120 sgd_solver.cpp:106] Iteration 69336, lr = 0.0005
I0523 23:24:15.457677 23120 solver.cpp:237] Iteration 69550, loss = 1.54378
I0523 23:24:15.457726 23120 solver.cpp:253]     Train net output #0: loss = 1.54378 (* 1 = 1.54378 loss)
I0523 23:24:15.457746 23120 sgd_solver.cpp:106] Iteration 69550, lr = 0.0005
I0523 23:24:24.351233 23120 solver.cpp:237] Iteration 69764, loss = 1.52066
I0523 23:24:24.351413 23120 solver.cpp:253]     Train net output #0: loss = 1.52066 (* 1 = 1.52066 loss)
I0523 23:24:24.351426 23120 sgd_solver.cpp:106] Iteration 69764, lr = 0.0005
I0523 23:24:33.250936 23120 solver.cpp:237] Iteration 69978, loss = 1.38178
I0523 23:24:33.250970 23120 solver.cpp:253]     Train net output #0: loss = 1.38178 (* 1 = 1.38178 loss)
I0523 23:24:33.250985 23120 sgd_solver.cpp:106] Iteration 69978, lr = 0.0005
I0523 23:25:03.076319 23120 solver.cpp:237] Iteration 70192, loss = 1.18243
I0523 23:25:03.076509 23120 solver.cpp:253]     Train net output #0: loss = 1.18243 (* 1 = 1.18243 loss)
I0523 23:25:03.076524 23120 sgd_solver.cpp:106] Iteration 70192, lr = 0.0005
I0523 23:25:11.974409 23120 solver.cpp:237] Iteration 70406, loss = 1.21629
I0523 23:25:11.974445 23120 solver.cpp:253]     Train net output #0: loss = 1.21629 (* 1 = 1.21629 loss)
I0523 23:25:11.974460 23120 sgd_solver.cpp:106] Iteration 70406, lr = 0.0005
I0523 23:25:20.872896 23120 solver.cpp:237] Iteration 70620, loss = 1.22822
I0523 23:25:20.872931 23120 solver.cpp:253]     Train net output #0: loss = 1.22822 (* 1 = 1.22822 loss)
I0523 23:25:20.872947 23120 sgd_solver.cpp:106] Iteration 70620, lr = 0.0005
I0523 23:25:23.576395 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_70686.caffemodel
I0523 23:25:23.643775 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_70686.solverstate
I0523 23:25:29.833572 23120 solver.cpp:237] Iteration 70834, loss = 1.28746
I0523 23:25:29.833621 23120 solver.cpp:253]     Train net output #0: loss = 1.28746 (* 1 = 1.28746 loss)
I0523 23:25:29.833642 23120 sgd_solver.cpp:106] Iteration 70834, lr = 0.0005
I0523 23:25:38.734411 23120 solver.cpp:237] Iteration 71048, loss = 1.29006
I0523 23:25:38.734586 23120 solver.cpp:253]     Train net output #0: loss = 1.29006 (* 1 = 1.29006 loss)
I0523 23:25:38.734598 23120 sgd_solver.cpp:106] Iteration 71048, lr = 0.0005
I0523 23:25:47.635767 23120 solver.cpp:237] Iteration 71262, loss = 1.11496
I0523 23:25:47.635797 23120 solver.cpp:253]     Train net output #0: loss = 1.11496 (* 1 = 1.11496 loss)
I0523 23:25:47.635821 23120 sgd_solver.cpp:106] Iteration 71262, lr = 0.0005
I0523 23:26:17.408359 23120 solver.cpp:237] Iteration 71476, loss = 1.13856
I0523 23:26:17.408550 23120 solver.cpp:253]     Train net output #0: loss = 1.13856 (* 1 = 1.13856 loss)
I0523 23:26:17.408563 23120 sgd_solver.cpp:106] Iteration 71476, lr = 0.0005
I0523 23:26:26.299466 23120 solver.cpp:237] Iteration 71690, loss = 1.34417
I0523 23:26:26.299501 23120 solver.cpp:253]     Train net output #0: loss = 1.34417 (* 1 = 1.34417 loss)
I0523 23:26:26.299517 23120 sgd_solver.cpp:106] Iteration 71690, lr = 0.0005
I0523 23:26:35.204195 23120 solver.cpp:237] Iteration 71904, loss = 1.21451
I0523 23:26:35.204223 23120 solver.cpp:253]     Train net output #0: loss = 1.21451 (* 1 = 1.21451 loss)
I0523 23:26:35.204249 23120 sgd_solver.cpp:106] Iteration 71904, lr = 0.0005
I0523 23:26:44.105020 23120 solver.cpp:237] Iteration 72118, loss = 1.52479
I0523 23:26:44.105067 23120 solver.cpp:253]     Train net output #0: loss = 1.52479 (* 1 = 1.52479 loss)
I0523 23:26:44.105083 23120 sgd_solver.cpp:106] Iteration 72118, lr = 0.0005
I0523 23:26:53.004283 23120 solver.cpp:237] Iteration 72332, loss = 1.25414
I0523 23:26:53.004451 23120 solver.cpp:253]     Train net output #0: loss = 1.25414 (* 1 = 1.25414 loss)
I0523 23:26:53.004464 23120 sgd_solver.cpp:106] Iteration 72332, lr = 0.0005
I0523 23:27:01.908255 23120 solver.cpp:237] Iteration 72546, loss = 1.36273
I0523 23:27:01.908285 23120 solver.cpp:253]     Train net output #0: loss = 1.36273 (* 1 = 1.36273 loss)
I0523 23:27:01.908308 23120 sgd_solver.cpp:106] Iteration 72546, lr = 0.0005
I0523 23:27:10.803912 23120 solver.cpp:237] Iteration 72760, loss = 1.41502
I0523 23:27:10.803956 23120 solver.cpp:253]     Train net output #0: loss = 1.41502 (* 1 = 1.41502 loss)
I0523 23:27:10.803972 23120 sgd_solver.cpp:106] Iteration 72760, lr = 0.0005
I0523 23:27:13.591740 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_72828.caffemodel
I0523 23:27:13.657830 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_72828.solverstate
I0523 23:27:14.363106 23120 solver.cpp:341] Iteration 72845, Testing net (#0)
I0523 23:28:02.327260 23120 solver.cpp:409]     Test net output #0: accuracy = 0.850553
I0523 23:28:02.327453 23120 solver.cpp:409]     Test net output #1: loss = 0.518042 (* 1 = 0.518042 loss)
I0523 23:28:28.586972 23120 solver.cpp:237] Iteration 72974, loss = 1.36421
I0523 23:28:28.587021 23120 solver.cpp:253]     Train net output #0: loss = 1.36421 (* 1 = 1.36421 loss)
I0523 23:28:28.587038 23120 sgd_solver.cpp:106] Iteration 72974, lr = 0.0005
I0523 23:28:37.461670 23120 solver.cpp:237] Iteration 73188, loss = 1.38837
I0523 23:28:37.461849 23120 solver.cpp:253]     Train net output #0: loss = 1.38837 (* 1 = 1.38837 loss)
I0523 23:28:37.461863 23120 sgd_solver.cpp:106] Iteration 73188, lr = 0.0005
I0523 23:28:46.343696 23120 solver.cpp:237] Iteration 73402, loss = 1.27823
I0523 23:28:46.343744 23120 solver.cpp:253]     Train net output #0: loss = 1.27823 (* 1 = 1.27823 loss)
I0523 23:28:46.343761 23120 sgd_solver.cpp:106] Iteration 73402, lr = 0.0005
I0523 23:28:55.221537 23120 solver.cpp:237] Iteration 73616, loss = 1.14188
I0523 23:28:55.221573 23120 solver.cpp:253]     Train net output #0: loss = 1.14188 (* 1 = 1.14188 loss)
I0523 23:28:55.221591 23120 sgd_solver.cpp:106] Iteration 73616, lr = 0.0005
I0523 23:29:04.100337 23120 solver.cpp:237] Iteration 73830, loss = 1.41381
I0523 23:29:04.100366 23120 solver.cpp:253]     Train net output #0: loss = 1.41381 (* 1 = 1.41381 loss)
I0523 23:29:04.100390 23120 sgd_solver.cpp:106] Iteration 73830, lr = 0.0005
I0523 23:29:12.979095 23120 solver.cpp:237] Iteration 74044, loss = 1.5514
I0523 23:29:12.979274 23120 solver.cpp:253]     Train net output #0: loss = 1.5514 (* 1 = 1.5514 loss)
I0523 23:29:12.979288 23120 sgd_solver.cpp:106] Iteration 74044, lr = 0.0005
I0523 23:29:21.856158 23120 solver.cpp:237] Iteration 74258, loss = 1.27285
I0523 23:29:21.856189 23120 solver.cpp:253]     Train net output #0: loss = 1.27285 (* 1 = 1.27285 loss)
I0523 23:29:21.856212 23120 sgd_solver.cpp:106] Iteration 74258, lr = 0.0005
I0523 23:29:51.601521 23120 solver.cpp:237] Iteration 74472, loss = 1.08829
I0523 23:29:51.601717 23120 solver.cpp:253]     Train net output #0: loss = 1.08829 (* 1 = 1.08829 loss)
I0523 23:29:51.601732 23120 sgd_solver.cpp:106] Iteration 74472, lr = 0.0005
I0523 23:30:00.481345 23120 solver.cpp:237] Iteration 74686, loss = 1.128
I0523 23:30:00.481386 23120 solver.cpp:253]     Train net output #0: loss = 1.128 (* 1 = 1.128 loss)
I0523 23:30:00.481410 23120 sgd_solver.cpp:106] Iteration 74686, lr = 0.0005
I0523 23:30:09.367543 23120 solver.cpp:237] Iteration 74900, loss = 1.37998
I0523 23:30:09.367573 23120 solver.cpp:253]     Train net output #0: loss = 1.37998 (* 1 = 1.37998 loss)
I0523 23:30:09.367589 23120 sgd_solver.cpp:106] Iteration 74900, lr = 0.0005
I0523 23:30:12.231488 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_74970.caffemodel
I0523 23:30:12.299520 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_74970.solverstate
I0523 23:30:18.317625 23120 solver.cpp:237] Iteration 75114, loss = 1.3615
I0523 23:30:18.317674 23120 solver.cpp:253]     Train net output #0: loss = 1.3615 (* 1 = 1.3615 loss)
I0523 23:30:18.317688 23120 sgd_solver.cpp:106] Iteration 75114, lr = 0.0005
I0523 23:30:27.195250 23120 solver.cpp:237] Iteration 75328, loss = 1.16422
I0523 23:30:27.195448 23120 solver.cpp:253]     Train net output #0: loss = 1.16422 (* 1 = 1.16422 loss)
I0523 23:30:27.195462 23120 sgd_solver.cpp:106] Iteration 75328, lr = 0.0005
I0523 23:30:36.079144 23120 solver.cpp:237] Iteration 75542, loss = 1.10333
I0523 23:30:36.079176 23120 solver.cpp:253]     Train net output #0: loss = 1.10333 (* 1 = 1.10333 loss)
I0523 23:30:36.079196 23120 sgd_solver.cpp:106] Iteration 75542, lr = 0.0005
I0523 23:31:05.856245 23120 solver.cpp:237] Iteration 75756, loss = 1.35475
I0523 23:31:05.856436 23120 solver.cpp:253]     Train net output #0: loss = 1.35475 (* 1 = 1.35475 loss)
I0523 23:31:05.856451 23120 sgd_solver.cpp:106] Iteration 75756, lr = 0.0005
I0523 23:31:14.734710 23120 solver.cpp:237] Iteration 75970, loss = 1.31625
I0523 23:31:14.734760 23120 solver.cpp:253]     Train net output #0: loss = 1.31625 (* 1 = 1.31625 loss)
I0523 23:31:14.734776 23120 sgd_solver.cpp:106] Iteration 75970, lr = 0.0005
I0523 23:31:23.607756 23120 solver.cpp:237] Iteration 76184, loss = 1.34813
I0523 23:31:23.607787 23120 solver.cpp:253]     Train net output #0: loss = 1.34813 (* 1 = 1.34813 loss)
I0523 23:31:23.607800 23120 sgd_solver.cpp:106] Iteration 76184, lr = 0.0005
I0523 23:31:32.485667 23120 solver.cpp:237] Iteration 76398, loss = 1.39508
I0523 23:31:32.485698 23120 solver.cpp:253]     Train net output #0: loss = 1.39508 (* 1 = 1.39508 loss)
I0523 23:31:32.485721 23120 sgd_solver.cpp:106] Iteration 76398, lr = 0.0005
I0523 23:31:41.365052 23120 solver.cpp:237] Iteration 76612, loss = 1.3107
I0523 23:31:41.365237 23120 solver.cpp:253]     Train net output #0: loss = 1.3107 (* 1 = 1.3107 loss)
I0523 23:31:41.365252 23120 sgd_solver.cpp:106] Iteration 76612, lr = 0.0005
I0523 23:31:50.248266 23120 solver.cpp:237] Iteration 76826, loss = 1.28882
I0523 23:31:50.248298 23120 solver.cpp:253]     Train net output #0: loss = 1.28882 (* 1 = 1.28882 loss)
I0523 23:31:50.248320 23120 sgd_solver.cpp:106] Iteration 76826, lr = 0.0005
I0523 23:31:59.130463 23120 solver.cpp:237] Iteration 77040, loss = 1.3189
I0523 23:31:59.130496 23120 solver.cpp:253]     Train net output #0: loss = 1.3189 (* 1 = 1.3189 loss)
I0523 23:31:59.130509 23120 sgd_solver.cpp:106] Iteration 77040, lr = 0.0005
I0523 23:32:02.077402 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_77112.caffemodel
I0523 23:32:02.146230 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_77112.solverstate
I0523 23:32:02.894227 23120 solver.cpp:341] Iteration 77130, Testing net (#0)
I0523 23:33:11.782305 23120 solver.cpp:409]     Test net output #0: accuracy = 0.853841
I0523 23:33:11.782496 23120 solver.cpp:409]     Test net output #1: loss = 0.50208 (* 1 = 0.50208 loss)
I0523 23:33:37.837221 23120 solver.cpp:237] Iteration 77254, loss = 1.25741
I0523 23:33:37.837271 23120 solver.cpp:253]     Train net output #0: loss = 1.25741 (* 1 = 1.25741 loss)
I0523 23:33:37.837288 23120 sgd_solver.cpp:106] Iteration 77254, lr = 0.0005
I0523 23:33:46.712313 23120 solver.cpp:237] Iteration 77468, loss = 1.11176
I0523 23:33:46.712502 23120 solver.cpp:253]     Train net output #0: loss = 1.11176 (* 1 = 1.11176 loss)
I0523 23:33:46.712515 23120 sgd_solver.cpp:106] Iteration 77468, lr = 0.0005
I0523 23:33:55.589911 23120 solver.cpp:237] Iteration 77682, loss = 1.1116
I0523 23:33:55.589941 23120 solver.cpp:253]     Train net output #0: loss = 1.1116 (* 1 = 1.1116 loss)
I0523 23:33:55.589957 23120 sgd_solver.cpp:106] Iteration 77682, lr = 0.0005
I0523 23:34:04.465840 23120 solver.cpp:237] Iteration 77896, loss = 1.22811
I0523 23:34:04.465873 23120 solver.cpp:253]     Train net output #0: loss = 1.22811 (* 1 = 1.22811 loss)
I0523 23:34:04.465894 23120 sgd_solver.cpp:106] Iteration 77896, lr = 0.0005
I0523 23:34:13.338507 23120 solver.cpp:237] Iteration 78110, loss = 1.24677
I0523 23:34:13.338553 23120 solver.cpp:253]     Train net output #0: loss = 1.24677 (* 1 = 1.24677 loss)
I0523 23:34:13.338572 23120 sgd_solver.cpp:106] Iteration 78110, lr = 0.0005
I0523 23:34:22.220922 23120 solver.cpp:237] Iteration 78324, loss = 1.31152
I0523 23:34:22.221115 23120 solver.cpp:253]     Train net output #0: loss = 1.31152 (* 1 = 1.31152 loss)
I0523 23:34:22.221128 23120 sgd_solver.cpp:106] Iteration 78324, lr = 0.0005
I0523 23:34:31.100519 23120 solver.cpp:237] Iteration 78538, loss = 1.30434
I0523 23:34:31.100549 23120 solver.cpp:253]     Train net output #0: loss = 1.30434 (* 1 = 1.30434 loss)
I0523 23:34:31.100574 23120 sgd_solver.cpp:106] Iteration 78538, lr = 0.0005
I0523 23:35:00.877543 23120 solver.cpp:237] Iteration 78752, loss = 1.3532
I0523 23:35:00.877743 23120 solver.cpp:253]     Train net output #0: loss = 1.3532 (* 1 = 1.3532 loss)
I0523 23:35:00.877756 23120 sgd_solver.cpp:106] Iteration 78752, lr = 0.0005
I0523 23:35:09.763000 23120 solver.cpp:237] Iteration 78966, loss = 1.34869
I0523 23:35:09.763036 23120 solver.cpp:253]     Train net output #0: loss = 1.34869 (* 1 = 1.34869 loss)
I0523 23:35:09.763053 23120 sgd_solver.cpp:106] Iteration 78966, lr = 0.0005
I0523 23:35:18.639868 23120 solver.cpp:237] Iteration 79180, loss = 1.27422
I0523 23:35:18.639897 23120 solver.cpp:253]     Train net output #0: loss = 1.27422 (* 1 = 1.27422 loss)
I0523 23:35:18.639914 23120 sgd_solver.cpp:106] Iteration 79180, lr = 0.0005
I0523 23:35:21.674131 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_79254.caffemodel
I0523 23:35:21.740650 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_79254.solverstate
I0523 23:35:27.588218 23120 solver.cpp:237] Iteration 79394, loss = 1.25287
I0523 23:35:27.588266 23120 solver.cpp:253]     Train net output #0: loss = 1.25287 (* 1 = 1.25287 loss)
I0523 23:35:27.588285 23120 sgd_solver.cpp:106] Iteration 79394, lr = 0.0005
I0523 23:35:36.468797 23120 solver.cpp:237] Iteration 79608, loss = 1.22182
I0523 23:35:36.468973 23120 solver.cpp:253]     Train net output #0: loss = 1.22182 (* 1 = 1.22182 loss)
I0523 23:35:36.468987 23120 sgd_solver.cpp:106] Iteration 79608, lr = 0.0005
I0523 23:35:45.350463 23120 solver.cpp:237] Iteration 79822, loss = 1.09167
I0523 23:35:45.350497 23120 solver.cpp:253]     Train net output #0: loss = 1.09167 (* 1 = 1.09167 loss)
I0523 23:35:45.350517 23120 sgd_solver.cpp:106] Iteration 79822, lr = 0.0005
I0523 23:36:15.172879 23120 solver.cpp:237] Iteration 80036, loss = 1.245
I0523 23:36:15.173070 23120 solver.cpp:253]     Train net output #0: loss = 1.245 (* 1 = 1.245 loss)
I0523 23:36:15.173084 23120 sgd_solver.cpp:106] Iteration 80036, lr = 0.0005
I0523 23:36:24.058127 23120 solver.cpp:237] Iteration 80250, loss = 1.32001
I0523 23:36:24.058161 23120 solver.cpp:253]     Train net output #0: loss = 1.32001 (* 1 = 1.32001 loss)
I0523 23:36:24.058179 23120 sgd_solver.cpp:106] Iteration 80250, lr = 0.0005
I0523 23:36:32.930950 23120 solver.cpp:237] Iteration 80464, loss = 0.99547
I0523 23:36:32.930981 23120 solver.cpp:253]     Train net output #0: loss = 0.99547 (* 1 = 0.99547 loss)
I0523 23:36:32.931005 23120 sgd_solver.cpp:106] Iteration 80464, lr = 0.0005
I0523 23:36:41.804060 23120 solver.cpp:237] Iteration 80678, loss = 1.26559
I0523 23:36:41.804102 23120 solver.cpp:253]     Train net output #0: loss = 1.26559 (* 1 = 1.26559 loss)
I0523 23:36:41.804124 23120 sgd_solver.cpp:106] Iteration 80678, lr = 0.0005
I0523 23:36:50.682471 23120 solver.cpp:237] Iteration 80892, loss = 1.0009
I0523 23:36:50.682654 23120 solver.cpp:253]     Train net output #0: loss = 1.0009 (* 1 = 1.0009 loss)
I0523 23:36:50.682668 23120 sgd_solver.cpp:106] Iteration 80892, lr = 0.0005
I0523 23:36:59.558711 23120 solver.cpp:237] Iteration 81106, loss = 1.31522
I0523 23:36:59.558740 23120 solver.cpp:253]     Train net output #0: loss = 1.31522 (* 1 = 1.31522 loss)
I0523 23:36:59.558763 23120 sgd_solver.cpp:106] Iteration 81106, lr = 0.0005
I0523 23:37:08.442925 23120 solver.cpp:237] Iteration 81320, loss = 1.2999
I0523 23:37:08.442968 23120 solver.cpp:253]     Train net output #0: loss = 1.2999 (* 1 = 1.2999 loss)
I0523 23:37:08.442986 23120 sgd_solver.cpp:106] Iteration 81320, lr = 0.0005
I0523 23:37:11.557353 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_81396.caffemodel
I0523 23:37:11.623692 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_81396.solverstate
I0523 23:37:12.410248 23120 solver.cpp:341] Iteration 81415, Testing net (#0)
I0523 23:38:00.024524 23120 solver.cpp:409]     Test net output #0: accuracy = 0.857157
I0523 23:38:00.024725 23120 solver.cpp:409]     Test net output #1: loss = 0.485019 (* 1 = 0.485019 loss)
I0523 23:38:25.883419 23120 solver.cpp:237] Iteration 81534, loss = 1.27793
I0523 23:38:25.883466 23120 solver.cpp:253]     Train net output #0: loss = 1.27793 (* 1 = 1.27793 loss)
I0523 23:38:25.883486 23120 sgd_solver.cpp:106] Iteration 81534, lr = 0.0005
I0523 23:38:34.760546 23120 solver.cpp:237] Iteration 81748, loss = 1.31384
I0523 23:38:34.760722 23120 solver.cpp:253]     Train net output #0: loss = 1.31384 (* 1 = 1.31384 loss)
I0523 23:38:34.760736 23120 sgd_solver.cpp:106] Iteration 81748, lr = 0.0005
I0523 23:38:43.636726 23120 solver.cpp:237] Iteration 81962, loss = 1.53615
I0523 23:38:43.636755 23120 solver.cpp:253]     Train net output #0: loss = 1.53615 (* 1 = 1.53615 loss)
I0523 23:38:43.636778 23120 sgd_solver.cpp:106] Iteration 81962, lr = 0.0005
I0523 23:38:52.520864 23120 solver.cpp:237] Iteration 82176, loss = 1.21341
I0523 23:38:52.520907 23120 solver.cpp:253]     Train net output #0: loss = 1.21341 (* 1 = 1.21341 loss)
I0523 23:38:52.520927 23120 sgd_solver.cpp:106] Iteration 82176, lr = 0.0005
I0523 23:39:01.399179 23120 solver.cpp:237] Iteration 82390, loss = 1.32137
I0523 23:39:01.399209 23120 solver.cpp:253]     Train net output #0: loss = 1.32137 (* 1 = 1.32137 loss)
I0523 23:39:01.399232 23120 sgd_solver.cpp:106] Iteration 82390, lr = 0.0005
I0523 23:39:10.281829 23120 solver.cpp:237] Iteration 82604, loss = 1.1485
I0523 23:39:10.282013 23120 solver.cpp:253]     Train net output #0: loss = 1.1485 (* 1 = 1.1485 loss)
I0523 23:39:10.282027 23120 sgd_solver.cpp:106] Iteration 82604, lr = 0.0005
I0523 23:39:19.162338 23120 solver.cpp:237] Iteration 82818, loss = 1.09652
I0523 23:39:19.162372 23120 solver.cpp:253]     Train net output #0: loss = 1.09652 (* 1 = 1.09652 loss)
I0523 23:39:19.162390 23120 sgd_solver.cpp:106] Iteration 82818, lr = 0.0005
I0523 23:39:48.955682 23120 solver.cpp:237] Iteration 83032, loss = 1.01613
I0523 23:39:48.955874 23120 solver.cpp:253]     Train net output #0: loss = 1.01613 (* 1 = 1.01613 loss)
I0523 23:39:48.955888 23120 sgd_solver.cpp:106] Iteration 83032, lr = 0.0005
I0523 23:39:57.833269 23120 solver.cpp:237] Iteration 83246, loss = 1.26426
I0523 23:39:57.833300 23120 solver.cpp:253]     Train net output #0: loss = 1.26426 (* 1 = 1.26426 loss)
I0523 23:39:57.833322 23120 sgd_solver.cpp:106] Iteration 83246, lr = 0.0005
I0523 23:40:06.714243 23120 solver.cpp:237] Iteration 83460, loss = 1.02179
I0523 23:40:06.714289 23120 solver.cpp:253]     Train net output #0: loss = 1.02179 (* 1 = 1.02179 loss)
I0523 23:40:06.714310 23120 sgd_solver.cpp:106] Iteration 83460, lr = 0.0005
I0523 23:40:09.908491 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_83538.caffemodel
I0523 23:40:09.974335 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_83538.solverstate
I0523 23:40:15.655082 23120 solver.cpp:237] Iteration 83674, loss = 1.21698
I0523 23:40:15.655124 23120 solver.cpp:253]     Train net output #0: loss = 1.21698 (* 1 = 1.21698 loss)
I0523 23:40:15.655140 23120 sgd_solver.cpp:106] Iteration 83674, lr = 0.0005
I0523 23:40:24.530264 23120 solver.cpp:237] Iteration 83888, loss = 1.24493
I0523 23:40:24.530452 23120 solver.cpp:253]     Train net output #0: loss = 1.24493 (* 1 = 1.24493 loss)
I0523 23:40:24.530467 23120 sgd_solver.cpp:106] Iteration 83888, lr = 0.0005
I0523 23:40:33.404013 23120 solver.cpp:237] Iteration 84102, loss = 1.22064
I0523 23:40:33.404049 23120 solver.cpp:253]     Train net output #0: loss = 1.22064 (* 1 = 1.22064 loss)
I0523 23:40:33.404067 23120 sgd_solver.cpp:106] Iteration 84102, lr = 0.0005
I0523 23:41:03.189028 23120 solver.cpp:237] Iteration 84316, loss = 1.32027
I0523 23:41:03.189229 23120 solver.cpp:253]     Train net output #0: loss = 1.32027 (* 1 = 1.32027 loss)
I0523 23:41:03.189244 23120 sgd_solver.cpp:106] Iteration 84316, lr = 0.0005
I0523 23:41:12.068387 23120 solver.cpp:237] Iteration 84530, loss = 1.01375
I0523 23:41:12.068418 23120 solver.cpp:253]     Train net output #0: loss = 1.01375 (* 1 = 1.01375 loss)
I0523 23:41:12.068439 23120 sgd_solver.cpp:106] Iteration 84530, lr = 0.0005
I0523 23:41:20.947499 23120 solver.cpp:237] Iteration 84744, loss = 1.33594
I0523 23:41:20.947540 23120 solver.cpp:253]     Train net output #0: loss = 1.33594 (* 1 = 1.33594 loss)
I0523 23:41:20.947558 23120 sgd_solver.cpp:106] Iteration 84744, lr = 0.0005
I0523 23:41:29.828989 23120 solver.cpp:237] Iteration 84958, loss = 1.17624
I0523 23:41:29.829020 23120 solver.cpp:253]     Train net output #0: loss = 1.17624 (* 1 = 1.17624 loss)
I0523 23:41:29.829042 23120 sgd_solver.cpp:106] Iteration 84958, lr = 0.0005
I0523 23:41:38.715517 23120 solver.cpp:237] Iteration 85172, loss = 1.14165
I0523 23:41:38.715687 23120 solver.cpp:253]     Train net output #0: loss = 1.14165 (* 1 = 1.14165 loss)
I0523 23:41:38.715700 23120 sgd_solver.cpp:106] Iteration 85172, lr = 0.0005
I0523 23:41:47.589761 23120 solver.cpp:237] Iteration 85386, loss = 1.27755
I0523 23:41:47.589800 23120 solver.cpp:253]     Train net output #0: loss = 1.27755 (* 1 = 1.27755 loss)
I0523 23:41:47.589820 23120 sgd_solver.cpp:106] Iteration 85386, lr = 0.0005
I0523 23:41:56.468288 23120 solver.cpp:237] Iteration 85600, loss = 1.19097
I0523 23:41:56.468317 23120 solver.cpp:253]     Train net output #0: loss = 1.19097 (* 1 = 1.19097 loss)
I0523 23:41:56.468339 23120 sgd_solver.cpp:106] Iteration 85600, lr = 0.0005
I0523 23:41:59.746271 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_85680.caffemodel
I0523 23:41:59.815659 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_85680.solverstate
I0523 23:42:00.646339 23120 solver.cpp:341] Iteration 85700, Testing net (#0)
I0523 23:43:09.424190 23120 solver.cpp:409]     Test net output #0: accuracy = 0.857329
I0523 23:43:09.424383 23120 solver.cpp:409]     Test net output #1: loss = 0.466106 (* 1 = 0.466106 loss)
I0523 23:43:35.084728 23120 solver.cpp:237] Iteration 85814, loss = 1.35612
I0523 23:43:35.084776 23120 solver.cpp:253]     Train net output #0: loss = 1.35612 (* 1 = 1.35612 loss)
I0523 23:43:35.084796 23120 sgd_solver.cpp:106] Iteration 85814, lr = 0.0005
I0523 23:43:43.942384 23120 solver.cpp:237] Iteration 86028, loss = 1.12336
I0523 23:43:43.942566 23120 solver.cpp:253]     Train net output #0: loss = 1.12336 (* 1 = 1.12336 loss)
I0523 23:43:43.942579 23120 sgd_solver.cpp:106] Iteration 86028, lr = 0.0005
I0523 23:43:52.809612 23120 solver.cpp:237] Iteration 86242, loss = 1.43745
I0523 23:43:52.809644 23120 solver.cpp:253]     Train net output #0: loss = 1.43745 (* 1 = 1.43745 loss)
I0523 23:43:52.809669 23120 sgd_solver.cpp:106] Iteration 86242, lr = 0.0005
I0523 23:44:01.675555 23120 solver.cpp:237] Iteration 86456, loss = 1.14566
I0523 23:44:01.675585 23120 solver.cpp:253]     Train net output #0: loss = 1.14566 (* 1 = 1.14566 loss)
I0523 23:44:01.675607 23120 sgd_solver.cpp:106] Iteration 86456, lr = 0.0005
I0523 23:44:10.542894 23120 solver.cpp:237] Iteration 86670, loss = 1.17231
I0523 23:44:10.542933 23120 solver.cpp:253]     Train net output #0: loss = 1.17231 (* 1 = 1.17231 loss)
I0523 23:44:10.542958 23120 sgd_solver.cpp:106] Iteration 86670, lr = 0.0005
I0523 23:44:19.410253 23120 solver.cpp:237] Iteration 86884, loss = 1.25557
I0523 23:44:19.410444 23120 solver.cpp:253]     Train net output #0: loss = 1.25557 (* 1 = 1.25557 loss)
I0523 23:44:19.410457 23120 sgd_solver.cpp:106] Iteration 86884, lr = 0.0005
I0523 23:44:28.274188 23120 solver.cpp:237] Iteration 87098, loss = 1.33346
I0523 23:44:28.274217 23120 solver.cpp:253]     Train net output #0: loss = 1.33346 (* 1 = 1.33346 loss)
I0523 23:44:28.274238 23120 sgd_solver.cpp:106] Iteration 87098, lr = 0.0005
I0523 23:44:57.982146 23120 solver.cpp:237] Iteration 87312, loss = 1.21022
I0523 23:44:57.982344 23120 solver.cpp:253]     Train net output #0: loss = 1.21022 (* 1 = 1.21022 loss)
I0523 23:44:57.982358 23120 sgd_solver.cpp:106] Iteration 87312, lr = 0.0005
I0523 23:45:06.847723 23120 solver.cpp:237] Iteration 87526, loss = 0.933696
I0523 23:45:06.847764 23120 solver.cpp:253]     Train net output #0: loss = 0.933696 (* 1 = 0.933696 loss)
I0523 23:45:06.847787 23120 sgd_solver.cpp:106] Iteration 87526, lr = 0.0005
I0523 23:45:15.712345 23120 solver.cpp:237] Iteration 87740, loss = 1.31738
I0523 23:45:15.712378 23120 solver.cpp:253]     Train net output #0: loss = 1.31738 (* 1 = 1.31738 loss)
I0523 23:45:15.712399 23120 sgd_solver.cpp:106] Iteration 87740, lr = 0.0005
I0523 23:45:19.066735 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_87822.caffemodel
I0523 23:45:19.133504 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_87822.solverstate
I0523 23:45:24.637850 23120 solver.cpp:237] Iteration 87954, loss = 1.15812
I0523 23:45:24.637898 23120 solver.cpp:253]     Train net output #0: loss = 1.15812 (* 1 = 1.15812 loss)
I0523 23:45:24.637919 23120 sgd_solver.cpp:106] Iteration 87954, lr = 0.0005
I0523 23:45:33.494200 23120 solver.cpp:237] Iteration 88168, loss = 1.30497
I0523 23:45:33.494379 23120 solver.cpp:253]     Train net output #0: loss = 1.30497 (* 1 = 1.30497 loss)
I0523 23:45:33.494392 23120 sgd_solver.cpp:106] Iteration 88168, lr = 0.0005
I0523 23:45:42.358228 23120 solver.cpp:237] Iteration 88382, loss = 1.0537
I0523 23:45:42.358260 23120 solver.cpp:253]     Train net output #0: loss = 1.0537 (* 1 = 1.0537 loss)
I0523 23:45:42.358279 23120 sgd_solver.cpp:106] Iteration 88382, lr = 0.0005
I0523 23:46:12.099694 23120 solver.cpp:237] Iteration 88596, loss = 1.02253
I0523 23:46:12.099892 23120 solver.cpp:253]     Train net output #0: loss = 1.02253 (* 1 = 1.02253 loss)
I0523 23:46:12.099907 23120 sgd_solver.cpp:106] Iteration 88596, lr = 0.0005
I0523 23:46:20.973109 23120 solver.cpp:237] Iteration 88810, loss = 1.33136
I0523 23:46:20.973152 23120 solver.cpp:253]     Train net output #0: loss = 1.33136 (* 1 = 1.33136 loss)
I0523 23:46:20.973173 23120 sgd_solver.cpp:106] Iteration 88810, lr = 0.0005
I0523 23:46:29.847234 23120 solver.cpp:237] Iteration 89024, loss = 1.33242
I0523 23:46:29.847268 23120 solver.cpp:253]     Train net output #0: loss = 1.33242 (* 1 = 1.33242 loss)
I0523 23:46:29.847288 23120 sgd_solver.cpp:106] Iteration 89024, lr = 0.0005
I0523 23:46:38.711308 23120 solver.cpp:237] Iteration 89238, loss = 1.18582
I0523 23:46:38.711338 23120 solver.cpp:253]     Train net output #0: loss = 1.18582 (* 1 = 1.18582 loss)
I0523 23:46:38.711359 23120 sgd_solver.cpp:106] Iteration 89238, lr = 0.0005
I0523 23:46:47.579978 23120 solver.cpp:237] Iteration 89452, loss = 1.18798
I0523 23:46:47.580176 23120 solver.cpp:253]     Train net output #0: loss = 1.18798 (* 1 = 1.18798 loss)
I0523 23:46:47.580190 23120 sgd_solver.cpp:106] Iteration 89452, lr = 0.0005
I0523 23:46:56.454164 23120 solver.cpp:237] Iteration 89666, loss = 1.1376
I0523 23:46:56.454196 23120 solver.cpp:253]     Train net output #0: loss = 1.1376 (* 1 = 1.1376 loss)
I0523 23:46:56.454216 23120 sgd_solver.cpp:106] Iteration 89666, lr = 0.0005
I0523 23:47:05.324323 23120 solver.cpp:237] Iteration 89880, loss = 0.990617
I0523 23:47:05.324362 23120 solver.cpp:253]     Train net output #0: loss = 0.990617 (* 1 = 0.990617 loss)
I0523 23:47:05.324385 23120 sgd_solver.cpp:106] Iteration 89880, lr = 0.0005
I0523 23:47:08.767647 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_89964.caffemodel
I0523 23:47:08.833809 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_89964.solverstate
I0523 23:47:09.703610 23120 solver.cpp:341] Iteration 89985, Testing net (#0)
I0523 23:47:57.610596 23120 solver.cpp:409]     Test net output #0: accuracy = 0.857469
I0523 23:47:57.610791 23120 solver.cpp:409]     Test net output #1: loss = 0.484803 (* 1 = 0.484803 loss)
I0523 23:48:23.035212 23120 solver.cpp:237] Iteration 90094, loss = 1.5274
I0523 23:48:23.035261 23120 solver.cpp:253]     Train net output #0: loss = 1.5274 (* 1 = 1.5274 loss)
I0523 23:48:23.035279 23120 sgd_solver.cpp:106] Iteration 90094, lr = 0.0005
I0523 23:48:31.920755 23120 solver.cpp:237] Iteration 90308, loss = 1.17037
I0523 23:48:31.920933 23120 solver.cpp:253]     Train net output #0: loss = 1.17037 (* 1 = 1.17037 loss)
I0523 23:48:31.920948 23120 sgd_solver.cpp:106] Iteration 90308, lr = 0.0005
I0523 23:48:40.805512 23120 solver.cpp:237] Iteration 90522, loss = 1.28248
I0523 23:48:40.805542 23120 solver.cpp:253]     Train net output #0: loss = 1.28248 (* 1 = 1.28248 loss)
I0523 23:48:40.805567 23120 sgd_solver.cpp:106] Iteration 90522, lr = 0.0005
I0523 23:48:49.691998 23120 solver.cpp:237] Iteration 90736, loss = 1.25819
I0523 23:48:49.692034 23120 solver.cpp:253]     Train net output #0: loss = 1.25819 (* 1 = 1.25819 loss)
I0523 23:48:49.692059 23120 sgd_solver.cpp:106] Iteration 90736, lr = 0.0005
I0523 23:48:58.579469 23120 solver.cpp:237] Iteration 90950, loss = 1.42235
I0523 23:48:58.579499 23120 solver.cpp:253]     Train net output #0: loss = 1.42235 (* 1 = 1.42235 loss)
I0523 23:48:58.579524 23120 sgd_solver.cpp:106] Iteration 90950, lr = 0.0005
I0523 23:49:07.459841 23120 solver.cpp:237] Iteration 91164, loss = 1.33216
I0523 23:49:07.460022 23120 solver.cpp:253]     Train net output #0: loss = 1.33216 (* 1 = 1.33216 loss)
I0523 23:49:07.460036 23120 sgd_solver.cpp:106] Iteration 91164, lr = 0.0005
I0523 23:49:16.348351 23120 solver.cpp:237] Iteration 91378, loss = 1.30694
I0523 23:49:16.348388 23120 solver.cpp:253]     Train net output #0: loss = 1.30694 (* 1 = 1.30694 loss)
I0523 23:49:16.348412 23120 sgd_solver.cpp:106] Iteration 91378, lr = 0.0005
I0523 23:49:46.080621 23120 solver.cpp:237] Iteration 91592, loss = 1.11483
I0523 23:49:46.080822 23120 solver.cpp:253]     Train net output #0: loss = 1.11483 (* 1 = 1.11483 loss)
I0523 23:49:46.080837 23120 sgd_solver.cpp:106] Iteration 91592, lr = 0.0005
I0523 23:49:54.962261 23120 solver.cpp:237] Iteration 91806, loss = 1.34287
I0523 23:49:54.962292 23120 solver.cpp:253]     Train net output #0: loss = 1.34287 (* 1 = 1.34287 loss)
I0523 23:49:54.962314 23120 sgd_solver.cpp:106] Iteration 91806, lr = 0.0005
I0523 23:50:03.847578 23120 solver.cpp:237] Iteration 92020, loss = 1.23019
I0523 23:50:03.847620 23120 solver.cpp:253]     Train net output #0: loss = 1.23019 (* 1 = 1.23019 loss)
I0523 23:50:03.847640 23120 sgd_solver.cpp:106] Iteration 92020, lr = 0.0005
I0523 23:50:07.376871 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_92106.caffemodel
I0523 23:50:07.443251 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_92106.solverstate
I0523 23:50:12.795601 23120 solver.cpp:237] Iteration 92234, loss = 1.21135
I0523 23:50:12.795650 23120 solver.cpp:253]     Train net output #0: loss = 1.21135 (* 1 = 1.21135 loss)
I0523 23:50:12.795665 23120 sgd_solver.cpp:106] Iteration 92234, lr = 0.0005
I0523 23:50:21.677492 23120 solver.cpp:237] Iteration 92448, loss = 1.3571
I0523 23:50:21.677692 23120 solver.cpp:253]     Train net output #0: loss = 1.3571 (* 1 = 1.3571 loss)
I0523 23:50:21.677711 23120 sgd_solver.cpp:106] Iteration 92448, lr = 0.0005
I0523 23:50:30.562016 23120 solver.cpp:237] Iteration 92662, loss = 1.39612
I0523 23:50:30.562053 23120 solver.cpp:253]     Train net output #0: loss = 1.39612 (* 1 = 1.39612 loss)
I0523 23:50:30.562077 23120 sgd_solver.cpp:106] Iteration 92662, lr = 0.0005
I0523 23:51:00.352640 23120 solver.cpp:237] Iteration 92876, loss = 1.11481
I0523 23:51:00.352852 23120 solver.cpp:253]     Train net output #0: loss = 1.11481 (* 1 = 1.11481 loss)
I0523 23:51:00.352867 23120 sgd_solver.cpp:106] Iteration 92876, lr = 0.0005
I0523 23:51:09.240161 23120 solver.cpp:237] Iteration 93090, loss = 1.12242
I0523 23:51:09.240195 23120 solver.cpp:253]     Train net output #0: loss = 1.12242 (* 1 = 1.12242 loss)
I0523 23:51:09.240216 23120 sgd_solver.cpp:106] Iteration 93090, lr = 0.0005
I0523 23:51:18.125520 23120 solver.cpp:237] Iteration 93304, loss = 1.1545
I0523 23:51:18.125560 23120 solver.cpp:253]     Train net output #0: loss = 1.1545 (* 1 = 1.1545 loss)
I0523 23:51:18.125574 23120 sgd_solver.cpp:106] Iteration 93304, lr = 0.0005
I0523 23:51:27.010417 23120 solver.cpp:237] Iteration 93518, loss = 1.07908
I0523 23:51:27.010447 23120 solver.cpp:253]     Train net output #0: loss = 1.07908 (* 1 = 1.07908 loss)
I0523 23:51:27.010465 23120 sgd_solver.cpp:106] Iteration 93518, lr = 0.0005
I0523 23:51:35.893277 23120 solver.cpp:237] Iteration 93732, loss = 1.17544
I0523 23:51:35.893450 23120 solver.cpp:253]     Train net output #0: loss = 1.17544 (* 1 = 1.17544 loss)
I0523 23:51:35.893463 23120 sgd_solver.cpp:106] Iteration 93732, lr = 0.0005
I0523 23:51:44.775355 23120 solver.cpp:237] Iteration 93946, loss = 1.37578
I0523 23:51:44.775403 23120 solver.cpp:253]     Train net output #0: loss = 1.37578 (* 1 = 1.37578 loss)
I0523 23:51:44.775419 23120 sgd_solver.cpp:106] Iteration 93946, lr = 0.0005
I0523 23:51:53.659226 23120 solver.cpp:237] Iteration 94160, loss = 1.50424
I0523 23:51:53.659260 23120 solver.cpp:253]     Train net output #0: loss = 1.50424 (* 1 = 1.50424 loss)
I0523 23:51:53.659272 23120 sgd_solver.cpp:106] Iteration 94160, lr = 0.0005
I0523 23:51:57.271677 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_94248.caffemodel
I0523 23:51:57.338109 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_94248.solverstate
I0523 23:51:58.251464 23120 solver.cpp:341] Iteration 94270, Testing net (#0)
I0523 23:53:07.170637 23120 solver.cpp:409]     Test net output #0: accuracy = 0.857182
I0523 23:53:07.170842 23120 solver.cpp:409]     Test net output #1: loss = 0.506221 (* 1 = 0.506221 loss)
I0523 23:53:32.429360 23120 solver.cpp:237] Iteration 94374, loss = 1.33644
I0523 23:53:32.429409 23120 solver.cpp:253]     Train net output #0: loss = 1.33644 (* 1 = 1.33644 loss)
I0523 23:53:32.429427 23120 sgd_solver.cpp:106] Iteration 94374, lr = 0.0005
I0523 23:53:41.294028 23120 solver.cpp:237] Iteration 94588, loss = 1.10922
I0523 23:53:41.294224 23120 solver.cpp:253]     Train net output #0: loss = 1.10922 (* 1 = 1.10922 loss)
I0523 23:53:41.294237 23120 sgd_solver.cpp:106] Iteration 94588, lr = 0.0005
I0523 23:53:50.162364 23120 solver.cpp:237] Iteration 94802, loss = 1.22555
I0523 23:53:50.162406 23120 solver.cpp:253]     Train net output #0: loss = 1.22555 (* 1 = 1.22555 loss)
I0523 23:53:50.162426 23120 sgd_solver.cpp:106] Iteration 94802, lr = 0.0005
I0523 23:53:59.027626 23120 solver.cpp:237] Iteration 95016, loss = 1.15648
I0523 23:53:59.027662 23120 solver.cpp:253]     Train net output #0: loss = 1.15648 (* 1 = 1.15648 loss)
I0523 23:53:59.027678 23120 sgd_solver.cpp:106] Iteration 95016, lr = 0.0005
I0523 23:54:07.892324 23120 solver.cpp:237] Iteration 95230, loss = 1.20957
I0523 23:54:07.892360 23120 solver.cpp:253]     Train net output #0: loss = 1.20957 (* 1 = 1.20957 loss)
I0523 23:54:07.892377 23120 sgd_solver.cpp:106] Iteration 95230, lr = 0.0005
I0523 23:54:16.755390 23120 solver.cpp:237] Iteration 95444, loss = 1.27602
I0523 23:54:16.755584 23120 solver.cpp:253]     Train net output #0: loss = 1.27602 (* 1 = 1.27602 loss)
I0523 23:54:16.755597 23120 sgd_solver.cpp:106] Iteration 95444, lr = 0.0005
I0523 23:54:25.619153 23120 solver.cpp:237] Iteration 95658, loss = 1.13899
I0523 23:54:25.619184 23120 solver.cpp:253]     Train net output #0: loss = 1.13899 (* 1 = 1.13899 loss)
I0523 23:54:25.619205 23120 sgd_solver.cpp:106] Iteration 95658, lr = 0.0005
I0523 23:54:55.391964 23120 solver.cpp:237] Iteration 95872, loss = 1.289
I0523 23:54:55.392166 23120 solver.cpp:253]     Train net output #0: loss = 1.289 (* 1 = 1.289 loss)
I0523 23:54:55.392181 23120 sgd_solver.cpp:106] Iteration 95872, lr = 0.0005
I0523 23:55:04.256288 23120 solver.cpp:237] Iteration 96086, loss = 1.23444
I0523 23:55:04.256331 23120 solver.cpp:253]     Train net output #0: loss = 1.23444 (* 1 = 1.23444 loss)
I0523 23:55:04.256350 23120 sgd_solver.cpp:106] Iteration 96086, lr = 0.0005
I0523 23:55:13.125500 23120 solver.cpp:237] Iteration 96300, loss = 1.09459
I0523 23:55:13.125530 23120 solver.cpp:253]     Train net output #0: loss = 1.09459 (* 1 = 1.09459 loss)
I0523 23:55:13.125555 23120 sgd_solver.cpp:106] Iteration 96300, lr = 0.0005
I0523 23:55:16.814908 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_96390.caffemodel
I0523 23:55:16.882771 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_96390.solverstate
I0523 23:55:22.064498 23120 solver.cpp:237] Iteration 96514, loss = 1.47735
I0523 23:55:22.064546 23120 solver.cpp:253]     Train net output #0: loss = 1.47735 (* 1 = 1.47735 loss)
I0523 23:55:22.064563 23120 sgd_solver.cpp:106] Iteration 96514, lr = 0.0005
I0523 23:55:30.931949 23120 solver.cpp:237] Iteration 96728, loss = 1.47787
I0523 23:55:30.932148 23120 solver.cpp:253]     Train net output #0: loss = 1.47787 (* 1 = 1.47787 loss)
I0523 23:55:30.932163 23120 sgd_solver.cpp:106] Iteration 96728, lr = 0.0005
I0523 23:55:39.807637 23120 solver.cpp:237] Iteration 96942, loss = 1.17611
I0523 23:55:39.807667 23120 solver.cpp:253]     Train net output #0: loss = 1.17611 (* 1 = 1.17611 loss)
I0523 23:55:39.807692 23120 sgd_solver.cpp:106] Iteration 96942, lr = 0.0005
I0523 23:56:09.589231 23120 solver.cpp:237] Iteration 97156, loss = 1.24043
I0523 23:56:09.589444 23120 solver.cpp:253]     Train net output #0: loss = 1.24043 (* 1 = 1.24043 loss)
I0523 23:56:09.589459 23120 sgd_solver.cpp:106] Iteration 97156, lr = 0.0005
I0523 23:56:18.457628 23120 solver.cpp:237] Iteration 97370, loss = 1.6063
I0523 23:56:18.457669 23120 solver.cpp:253]     Train net output #0: loss = 1.6063 (* 1 = 1.6063 loss)
I0523 23:56:18.457691 23120 sgd_solver.cpp:106] Iteration 97370, lr = 0.0005
I0523 23:56:27.320092 23120 solver.cpp:237] Iteration 97584, loss = 1.39017
I0523 23:56:27.320122 23120 solver.cpp:253]     Train net output #0: loss = 1.39017 (* 1 = 1.39017 loss)
I0523 23:56:27.320147 23120 sgd_solver.cpp:106] Iteration 97584, lr = 0.0005
I0523 23:56:36.177582 23120 solver.cpp:237] Iteration 97798, loss = 1.4414
I0523 23:56:36.177613 23120 solver.cpp:253]     Train net output #0: loss = 1.4414 (* 1 = 1.4414 loss)
I0523 23:56:36.177636 23120 sgd_solver.cpp:106] Iteration 97798, lr = 0.0005
I0523 23:56:45.045095 23120 solver.cpp:237] Iteration 98012, loss = 1.33354
I0523 23:56:45.045300 23120 solver.cpp:253]     Train net output #0: loss = 1.33354 (* 1 = 1.33354 loss)
I0523 23:56:45.045313 23120 sgd_solver.cpp:106] Iteration 98012, lr = 0.0005
I0523 23:56:53.909737 23120 solver.cpp:237] Iteration 98226, loss = 1.44586
I0523 23:56:53.909767 23120 solver.cpp:253]     Train net output #0: loss = 1.44586 (* 1 = 1.44586 loss)
I0523 23:56:53.909790 23120 sgd_solver.cpp:106] Iteration 98226, lr = 0.0005
I0523 23:57:02.766798 23120 solver.cpp:237] Iteration 98440, loss = 1.23043
I0523 23:57:02.766827 23120 solver.cpp:253]     Train net output #0: loss = 1.23043 (* 1 = 1.23043 loss)
I0523 23:57:02.766849 23120 sgd_solver.cpp:106] Iteration 98440, lr = 0.0005
I0523 23:57:06.536876 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_98532.caffemodel
I0523 23:57:06.603557 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_98532.solverstate
I0523 23:57:07.555980 23120 solver.cpp:341] Iteration 98555, Testing net (#0)
I0523 23:57:55.186281 23120 solver.cpp:409]     Test net output #0: accuracy = 0.861919
I0523 23:57:55.186481 23120 solver.cpp:409]     Test net output #1: loss = 0.449448 (* 1 = 0.449448 loss)
I0523 23:58:20.214596 23120 solver.cpp:237] Iteration 98654, loss = 1.24723
I0523 23:58:20.214644 23120 solver.cpp:253]     Train net output #0: loss = 1.24723 (* 1 = 1.24723 loss)
I0523 23:58:20.214663 23120 sgd_solver.cpp:106] Iteration 98654, lr = 0.0005
I0523 23:58:29.112476 23120 solver.cpp:237] Iteration 98868, loss = 1.36854
I0523 23:58:29.112659 23120 solver.cpp:253]     Train net output #0: loss = 1.36854 (* 1 = 1.36854 loss)
I0523 23:58:29.112673 23120 sgd_solver.cpp:106] Iteration 98868, lr = 0.0005
I0523 23:58:38.005561 23120 solver.cpp:237] Iteration 99082, loss = 1.36356
I0523 23:58:38.005591 23120 solver.cpp:253]     Train net output #0: loss = 1.36356 (* 1 = 1.36356 loss)
I0523 23:58:38.005617 23120 sgd_solver.cpp:106] Iteration 99082, lr = 0.0005
I0523 23:58:46.904332 23120 solver.cpp:237] Iteration 99296, loss = 1.17764
I0523 23:58:46.904376 23120 solver.cpp:253]     Train net output #0: loss = 1.17764 (* 1 = 1.17764 loss)
I0523 23:58:46.904389 23120 sgd_solver.cpp:106] Iteration 99296, lr = 0.0005
I0523 23:58:55.804937 23120 solver.cpp:237] Iteration 99510, loss = 1.26166
I0523 23:58:55.804971 23120 solver.cpp:253]     Train net output #0: loss = 1.26166 (* 1 = 1.26166 loss)
I0523 23:58:55.804989 23120 sgd_solver.cpp:106] Iteration 99510, lr = 0.0005
I0523 23:59:04.703141 23120 solver.cpp:237] Iteration 99724, loss = 1.25063
I0523 23:59:04.703321 23120 solver.cpp:253]     Train net output #0: loss = 1.25063 (* 1 = 1.25063 loss)
I0523 23:59:04.703335 23120 sgd_solver.cpp:106] Iteration 99724, lr = 0.0005
I0523 23:59:13.600399 23120 solver.cpp:237] Iteration 99938, loss = 1.31078
I0523 23:59:13.600440 23120 solver.cpp:253]     Train net output #0: loss = 1.31078 (* 1 = 1.31078 loss)
I0523 23:59:13.600461 23120 sgd_solver.cpp:106] Iteration 99938, lr = 0.0005
I0523 23:59:43.408891 23120 solver.cpp:237] Iteration 100152, loss = 1.45672
I0523 23:59:43.409106 23120 solver.cpp:253]     Train net output #0: loss = 1.45672 (* 1 = 1.45672 loss)
I0523 23:59:43.409119 23120 sgd_solver.cpp:106] Iteration 100152, lr = 0.0005
I0523 23:59:52.303225 23120 solver.cpp:237] Iteration 100366, loss = 1.30172
I0523 23:59:52.303254 23120 solver.cpp:253]     Train net output #0: loss = 1.30172 (* 1 = 1.30172 loss)
I0523 23:59:52.303275 23120 sgd_solver.cpp:106] Iteration 100366, lr = 0.0005
I0524 00:00:01.198042 23120 solver.cpp:237] Iteration 100580, loss = 1.39175
I0524 00:00:01.198091 23120 solver.cpp:253]     Train net output #0: loss = 1.39175 (* 1 = 1.39175 loss)
I0524 00:00:01.198110 23120 sgd_solver.cpp:106] Iteration 100580, lr = 0.0005
I0524 00:00:05.065747 23120 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_100674.caffemodel
I0524 00:00:05.133028 23120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0005_2016-05-20T15.49.12.638113_iter_100674.solverstate
I0524 00:00:10.163822 23120 solver.cpp:237] Iteration 100794, loss = 1.23435
I0524 00:00:10.163866 23120 solver.cpp:253]     Train net output #0: loss = 1.23435 (* 1 = 1.23435 loss)
I0524 00:00:10.163888 23120 sgd_solver.cpp:106] Iteration 100794, lr = 0.0005
I0524 00:00:19.061797 23120 solver.cpp:237] Iteration 101008, loss = 1.49615
I0524 00:00:19.061981 23120 solver.cpp:253]     Train net output #0: loss = 1.49615 (* 1 = 1.49615 loss)
I0524 00:00:19.061995 23120 sgd_solver.cpp:106] Iteration 101008, lr = 0.0005
I0524 00:00:27.958758 23120 solver.cpp:237] Iteration 101222, loss = 1.15787
I0524 00:00:27.958803 23120 solver.cpp:253]     Train net output #0: loss = 1.15787 (* 1 = 1.15787 loss)
I0524 00:00:27.958823 23120 sgd_solver.cpp:106] Iteration 101222, lr = 0.0005
I0524 00:00:57.765750 23120 solver.cpp:237] Iteration 101436, loss = 1.17892
I0524 00:00:57.765959 23120 solver.cpp:253]     Train net output #0: loss = 1.17892 (* 1 = 1.17892 loss)
I0524 00:00:57.765974 23120 sgd_solver.cpp:106] Iteration 101436, lr = 0.0005
I0524 00:01:06.663106 23120 solver.cpp:237] Iteration 101650, loss = 1.38492
I0524 00:01:06.663138 23120 solver.cpp:253]     Train net output #0: loss = 1.38492 (* 1 = 1.38492 loss)
I0524 00:01:06.663154 23120 sgd_solver.cpp:106] Iteration 101650, lr = 0.0005
I0524 00:01:15.567256 23120 solver.cpp:237] Iteration 101864, loss = 1.25385
I0524 00:01:15.567304 23120 solver.cpp:253]     Train net output #0: loss = 1.25385 (* 1 = 1.25385 loss)
I0524 00:01:15.567319 23120 sgd_solver.cpp:106] Iteration 101864, lr = 0.0005
I0524 00:01:24.468067 23120 solver.cpp:237] Iteration 102078, loss = 1.15058
I0524 00:01:24.468101 23120 solver.cpp:253]     Train net output #0: loss = 1.15058 (* 1 = 1.15058 loss)
I0524 00:01:24.468122 23120 sgd_solver.cpp:106] Iteration 102078, lr = 0.0005
I0524 00:01:33.369063 23120 solver.cpp:237] Iteration 102292, loss = 1.45856
I0524 00:01:33.369243 23120 solver.cpp:253]     Train net output #0: loss = 1.45856 (* 1 = 1.45856 loss)
I0524 00:01:33.369257 23120 sgd_solver.cpp:106] Iteration 102292, lr = 0.0005
I0524 00:01:42.270975 23120 solver.cpp:237] Iteration 102506, loss = 1.54744
I0524 00:01:42.271021 23120 solver.cpp:253]     Train net output #0: loss = 1.54744 (* 1 = 1.54744 loss)
I0524 00:01:42.271040 23120 sgd_solver.cpp:106] Iteration 102506, lr = 0.0005
I0524 00:01:51.166873 23120 solver.cpp:237] Iteration 102720, loss = 1.13356
I0524 00:01:51.166908 23120 solver.cpp:253]     Train net output #0: loss = 1.13356 (* 1 = 1.13356 loss)
I0524 00:01:51.166924 23120 sgd_solver.cpp:106] Iteration 102720, lr = 0.0005
aprun: Apid 11258484: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7208 exceeded limit 7200
*** Aborted at 1464062514 (unix time) try "date -d @1464062514" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x5a4d) received by PID 23120 (TID 0x2aaac746f900) from PID 23117; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11258484: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11258484: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11258484: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11258484: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
aprun: Apid 11258484: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03788] [c8-1c0s6n0] [Tue May 24 00:01:56 2016] PE RANK 0 exit signal Terminated
Application 11258484 exit codes: 143
Application 11258484 resources: utime ~6219s, stime ~975s, Rss ~5331056, inblocks ~16158529, outblocks ~725753
