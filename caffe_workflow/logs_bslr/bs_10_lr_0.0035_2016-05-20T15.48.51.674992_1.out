2806843
I0521 16:01:49.960209 28425 caffe.cpp:184] Using GPUs 0
I0521 16:01:50.387500 28425 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.0035
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992.prototxt"
I0521 16:01:50.391191 28425 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992.prototxt
I0521 16:01:50.409543 28425 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 16:01:50.409602 28425 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 16:01:50.409950 28425 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 16:01:50.410126 28425 layer_factory.hpp:77] Creating layer data_hdf5
I0521 16:01:50.410151 28425 net.cpp:106] Creating Layer data_hdf5
I0521 16:01:50.410164 28425 net.cpp:411] data_hdf5 -> data
I0521 16:01:50.410228 28425 net.cpp:411] data_hdf5 -> label
I0521 16:01:50.410260 28425 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 16:01:50.411558 28425 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 16:01:50.413794 28425 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 16:02:11.880520 28425 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 16:02:11.885704 28425 net.cpp:150] Setting up data_hdf5
I0521 16:02:11.885745 28425 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 16:02:11.885758 28425 net.cpp:157] Top shape: 10 (10)
I0521 16:02:11.885769 28425 net.cpp:165] Memory required for data: 254040
I0521 16:02:11.885782 28425 layer_factory.hpp:77] Creating layer conv1
I0521 16:02:11.885817 28425 net.cpp:106] Creating Layer conv1
I0521 16:02:11.885828 28425 net.cpp:454] conv1 <- data
I0521 16:02:11.885850 28425 net.cpp:411] conv1 -> conv1
I0521 16:02:13.033063 28425 net.cpp:150] Setting up conv1
I0521 16:02:13.033110 28425 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 16:02:13.033121 28425 net.cpp:165] Memory required for data: 3018840
I0521 16:02:13.033150 28425 layer_factory.hpp:77] Creating layer relu1
I0521 16:02:13.033171 28425 net.cpp:106] Creating Layer relu1
I0521 16:02:13.033182 28425 net.cpp:454] relu1 <- conv1
I0521 16:02:13.033196 28425 net.cpp:397] relu1 -> conv1 (in-place)
I0521 16:02:13.033720 28425 net.cpp:150] Setting up relu1
I0521 16:02:13.033737 28425 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 16:02:13.033747 28425 net.cpp:165] Memory required for data: 5783640
I0521 16:02:13.033756 28425 layer_factory.hpp:77] Creating layer pool1
I0521 16:02:13.033774 28425 net.cpp:106] Creating Layer pool1
I0521 16:02:13.033784 28425 net.cpp:454] pool1 <- conv1
I0521 16:02:13.033797 28425 net.cpp:411] pool1 -> pool1
I0521 16:02:13.033879 28425 net.cpp:150] Setting up pool1
I0521 16:02:13.033891 28425 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 16:02:13.033901 28425 net.cpp:165] Memory required for data: 7166040
I0521 16:02:13.033911 28425 layer_factory.hpp:77] Creating layer conv2
I0521 16:02:13.033933 28425 net.cpp:106] Creating Layer conv2
I0521 16:02:13.033943 28425 net.cpp:454] conv2 <- pool1
I0521 16:02:13.033957 28425 net.cpp:411] conv2 -> conv2
I0521 16:02:13.036653 28425 net.cpp:150] Setting up conv2
I0521 16:02:13.036681 28425 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 16:02:13.036691 28425 net.cpp:165] Memory required for data: 9153240
I0521 16:02:13.036710 28425 layer_factory.hpp:77] Creating layer relu2
I0521 16:02:13.036725 28425 net.cpp:106] Creating Layer relu2
I0521 16:02:13.036734 28425 net.cpp:454] relu2 <- conv2
I0521 16:02:13.036747 28425 net.cpp:397] relu2 -> conv2 (in-place)
I0521 16:02:13.037080 28425 net.cpp:150] Setting up relu2
I0521 16:02:13.037093 28425 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 16:02:13.037103 28425 net.cpp:165] Memory required for data: 11140440
I0521 16:02:13.037113 28425 layer_factory.hpp:77] Creating layer pool2
I0521 16:02:13.037127 28425 net.cpp:106] Creating Layer pool2
I0521 16:02:13.037137 28425 net.cpp:454] pool2 <- conv2
I0521 16:02:13.037148 28425 net.cpp:411] pool2 -> pool2
I0521 16:02:13.037227 28425 net.cpp:150] Setting up pool2
I0521 16:02:13.037241 28425 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 16:02:13.037251 28425 net.cpp:165] Memory required for data: 12134040
I0521 16:02:13.037261 28425 layer_factory.hpp:77] Creating layer conv3
I0521 16:02:13.037277 28425 net.cpp:106] Creating Layer conv3
I0521 16:02:13.037288 28425 net.cpp:454] conv3 <- pool2
I0521 16:02:13.037302 28425 net.cpp:411] conv3 -> conv3
I0521 16:02:13.039388 28425 net.cpp:150] Setting up conv3
I0521 16:02:13.039412 28425 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 16:02:13.039423 28425 net.cpp:165] Memory required for data: 13218200
I0521 16:02:13.039443 28425 layer_factory.hpp:77] Creating layer relu3
I0521 16:02:13.039458 28425 net.cpp:106] Creating Layer relu3
I0521 16:02:13.039469 28425 net.cpp:454] relu3 <- conv3
I0521 16:02:13.039481 28425 net.cpp:397] relu3 -> conv3 (in-place)
I0521 16:02:13.039954 28425 net.cpp:150] Setting up relu3
I0521 16:02:13.039973 28425 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 16:02:13.039983 28425 net.cpp:165] Memory required for data: 14302360
I0521 16:02:13.039994 28425 layer_factory.hpp:77] Creating layer pool3
I0521 16:02:13.040006 28425 net.cpp:106] Creating Layer pool3
I0521 16:02:13.040016 28425 net.cpp:454] pool3 <- conv3
I0521 16:02:13.040029 28425 net.cpp:411] pool3 -> pool3
I0521 16:02:13.040096 28425 net.cpp:150] Setting up pool3
I0521 16:02:13.040109 28425 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 16:02:13.040119 28425 net.cpp:165] Memory required for data: 14844440
I0521 16:02:13.040128 28425 layer_factory.hpp:77] Creating layer conv4
I0521 16:02:13.040146 28425 net.cpp:106] Creating Layer conv4
I0521 16:02:13.040158 28425 net.cpp:454] conv4 <- pool3
I0521 16:02:13.040170 28425 net.cpp:411] conv4 -> conv4
I0521 16:02:13.042867 28425 net.cpp:150] Setting up conv4
I0521 16:02:13.042896 28425 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 16:02:13.042906 28425 net.cpp:165] Memory required for data: 15207320
I0521 16:02:13.042922 28425 layer_factory.hpp:77] Creating layer relu4
I0521 16:02:13.042935 28425 net.cpp:106] Creating Layer relu4
I0521 16:02:13.042945 28425 net.cpp:454] relu4 <- conv4
I0521 16:02:13.042958 28425 net.cpp:397] relu4 -> conv4 (in-place)
I0521 16:02:13.043422 28425 net.cpp:150] Setting up relu4
I0521 16:02:13.043438 28425 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 16:02:13.043448 28425 net.cpp:165] Memory required for data: 15570200
I0521 16:02:13.043459 28425 layer_factory.hpp:77] Creating layer pool4
I0521 16:02:13.043473 28425 net.cpp:106] Creating Layer pool4
I0521 16:02:13.043481 28425 net.cpp:454] pool4 <- conv4
I0521 16:02:13.043494 28425 net.cpp:411] pool4 -> pool4
I0521 16:02:13.043562 28425 net.cpp:150] Setting up pool4
I0521 16:02:13.043576 28425 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 16:02:13.043586 28425 net.cpp:165] Memory required for data: 15751640
I0521 16:02:13.043596 28425 layer_factory.hpp:77] Creating layer ip1
I0521 16:02:13.043614 28425 net.cpp:106] Creating Layer ip1
I0521 16:02:13.043624 28425 net.cpp:454] ip1 <- pool4
I0521 16:02:13.043637 28425 net.cpp:411] ip1 -> ip1
I0521 16:02:13.059073 28425 net.cpp:150] Setting up ip1
I0521 16:02:13.059103 28425 net.cpp:157] Top shape: 10 196 (1960)
I0521 16:02:13.059113 28425 net.cpp:165] Memory required for data: 15759480
I0521 16:02:13.059136 28425 layer_factory.hpp:77] Creating layer relu5
I0521 16:02:13.059151 28425 net.cpp:106] Creating Layer relu5
I0521 16:02:13.059161 28425 net.cpp:454] relu5 <- ip1
I0521 16:02:13.059175 28425 net.cpp:397] relu5 -> ip1 (in-place)
I0521 16:02:13.059517 28425 net.cpp:150] Setting up relu5
I0521 16:02:13.059531 28425 net.cpp:157] Top shape: 10 196 (1960)
I0521 16:02:13.059541 28425 net.cpp:165] Memory required for data: 15767320
I0521 16:02:13.059552 28425 layer_factory.hpp:77] Creating layer drop1
I0521 16:02:13.059573 28425 net.cpp:106] Creating Layer drop1
I0521 16:02:13.059583 28425 net.cpp:454] drop1 <- ip1
I0521 16:02:13.059595 28425 net.cpp:397] drop1 -> ip1 (in-place)
I0521 16:02:13.059655 28425 net.cpp:150] Setting up drop1
I0521 16:02:13.059669 28425 net.cpp:157] Top shape: 10 196 (1960)
I0521 16:02:13.059679 28425 net.cpp:165] Memory required for data: 15775160
I0521 16:02:13.059689 28425 layer_factory.hpp:77] Creating layer ip2
I0521 16:02:13.059706 28425 net.cpp:106] Creating Layer ip2
I0521 16:02:13.059716 28425 net.cpp:454] ip2 <- ip1
I0521 16:02:13.059730 28425 net.cpp:411] ip2 -> ip2
I0521 16:02:13.060201 28425 net.cpp:150] Setting up ip2
I0521 16:02:13.060214 28425 net.cpp:157] Top shape: 10 98 (980)
I0521 16:02:13.060225 28425 net.cpp:165] Memory required for data: 15779080
I0521 16:02:13.060240 28425 layer_factory.hpp:77] Creating layer relu6
I0521 16:02:13.060252 28425 net.cpp:106] Creating Layer relu6
I0521 16:02:13.060262 28425 net.cpp:454] relu6 <- ip2
I0521 16:02:13.060274 28425 net.cpp:397] relu6 -> ip2 (in-place)
I0521 16:02:13.060796 28425 net.cpp:150] Setting up relu6
I0521 16:02:13.060811 28425 net.cpp:157] Top shape: 10 98 (980)
I0521 16:02:13.060822 28425 net.cpp:165] Memory required for data: 15783000
I0521 16:02:13.060832 28425 layer_factory.hpp:77] Creating layer drop2
I0521 16:02:13.060844 28425 net.cpp:106] Creating Layer drop2
I0521 16:02:13.060854 28425 net.cpp:454] drop2 <- ip2
I0521 16:02:13.060866 28425 net.cpp:397] drop2 -> ip2 (in-place)
I0521 16:02:13.060909 28425 net.cpp:150] Setting up drop2
I0521 16:02:13.060922 28425 net.cpp:157] Top shape: 10 98 (980)
I0521 16:02:13.060932 28425 net.cpp:165] Memory required for data: 15786920
I0521 16:02:13.060942 28425 layer_factory.hpp:77] Creating layer ip3
I0521 16:02:13.060956 28425 net.cpp:106] Creating Layer ip3
I0521 16:02:13.060964 28425 net.cpp:454] ip3 <- ip2
I0521 16:02:13.060977 28425 net.cpp:411] ip3 -> ip3
I0521 16:02:13.061187 28425 net.cpp:150] Setting up ip3
I0521 16:02:13.061200 28425 net.cpp:157] Top shape: 10 11 (110)
I0521 16:02:13.061210 28425 net.cpp:165] Memory required for data: 15787360
I0521 16:02:13.061225 28425 layer_factory.hpp:77] Creating layer drop3
I0521 16:02:13.061239 28425 net.cpp:106] Creating Layer drop3
I0521 16:02:13.061247 28425 net.cpp:454] drop3 <- ip3
I0521 16:02:13.061260 28425 net.cpp:397] drop3 -> ip3 (in-place)
I0521 16:02:13.061298 28425 net.cpp:150] Setting up drop3
I0521 16:02:13.061311 28425 net.cpp:157] Top shape: 10 11 (110)
I0521 16:02:13.061321 28425 net.cpp:165] Memory required for data: 15787800
I0521 16:02:13.061331 28425 layer_factory.hpp:77] Creating layer loss
I0521 16:02:13.061354 28425 net.cpp:106] Creating Layer loss
I0521 16:02:13.061364 28425 net.cpp:454] loss <- ip3
I0521 16:02:13.061375 28425 net.cpp:454] loss <- label
I0521 16:02:13.061388 28425 net.cpp:411] loss -> loss
I0521 16:02:13.061405 28425 layer_factory.hpp:77] Creating layer loss
I0521 16:02:13.062044 28425 net.cpp:150] Setting up loss
I0521 16:02:13.062059 28425 net.cpp:157] Top shape: (1)
I0521 16:02:13.062072 28425 net.cpp:160]     with loss weight 1
I0521 16:02:13.062116 28425 net.cpp:165] Memory required for data: 15787804
I0521 16:02:13.062126 28425 net.cpp:226] loss needs backward computation.
I0521 16:02:13.062137 28425 net.cpp:226] drop3 needs backward computation.
I0521 16:02:13.062147 28425 net.cpp:226] ip3 needs backward computation.
I0521 16:02:13.062158 28425 net.cpp:226] drop2 needs backward computation.
I0521 16:02:13.062167 28425 net.cpp:226] relu6 needs backward computation.
I0521 16:02:13.062177 28425 net.cpp:226] ip2 needs backward computation.
I0521 16:02:13.062188 28425 net.cpp:226] drop1 needs backward computation.
I0521 16:02:13.062197 28425 net.cpp:226] relu5 needs backward computation.
I0521 16:02:13.062207 28425 net.cpp:226] ip1 needs backward computation.
I0521 16:02:13.062217 28425 net.cpp:226] pool4 needs backward computation.
I0521 16:02:13.062227 28425 net.cpp:226] relu4 needs backward computation.
I0521 16:02:13.062237 28425 net.cpp:226] conv4 needs backward computation.
I0521 16:02:13.062248 28425 net.cpp:226] pool3 needs backward computation.
I0521 16:02:13.062258 28425 net.cpp:226] relu3 needs backward computation.
I0521 16:02:13.062268 28425 net.cpp:226] conv3 needs backward computation.
I0521 16:02:13.062288 28425 net.cpp:226] pool2 needs backward computation.
I0521 16:02:13.062299 28425 net.cpp:226] relu2 needs backward computation.
I0521 16:02:13.062309 28425 net.cpp:226] conv2 needs backward computation.
I0521 16:02:13.062319 28425 net.cpp:226] pool1 needs backward computation.
I0521 16:02:13.062330 28425 net.cpp:226] relu1 needs backward computation.
I0521 16:02:13.062337 28425 net.cpp:226] conv1 needs backward computation.
I0521 16:02:13.062350 28425 net.cpp:228] data_hdf5 does not need backward computation.
I0521 16:02:13.062358 28425 net.cpp:270] This network produces output loss
I0521 16:02:13.062382 28425 net.cpp:283] Network initialization done.
I0521 16:02:13.064018 28425 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992.prototxt
I0521 16:02:13.064088 28425 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 16:02:13.064440 28425 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 16:02:13.064630 28425 layer_factory.hpp:77] Creating layer data_hdf5
I0521 16:02:13.064646 28425 net.cpp:106] Creating Layer data_hdf5
I0521 16:02:13.064658 28425 net.cpp:411] data_hdf5 -> data
I0521 16:02:13.064674 28425 net.cpp:411] data_hdf5 -> label
I0521 16:02:13.064692 28425 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 16:02:13.065822 28425 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 16:02:34.354626 28425 net.cpp:150] Setting up data_hdf5
I0521 16:02:34.367938 28425 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 16:02:34.367956 28425 net.cpp:157] Top shape: 10 (10)
I0521 16:02:34.367967 28425 net.cpp:165] Memory required for data: 254040
I0521 16:02:34.367981 28425 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 16:02:34.368010 28425 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 16:02:34.368021 28425 net.cpp:454] label_data_hdf5_1_split <- label
I0521 16:02:34.368034 28425 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 16:02:34.368057 28425 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 16:02:34.368144 28425 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 16:02:34.368158 28425 net.cpp:157] Top shape: 10 (10)
I0521 16:02:34.368170 28425 net.cpp:157] Top shape: 10 (10)
I0521 16:02:34.368180 28425 net.cpp:165] Memory required for data: 254120
I0521 16:02:34.368188 28425 layer_factory.hpp:77] Creating layer conv1
I0521 16:02:34.368212 28425 net.cpp:106] Creating Layer conv1
I0521 16:02:34.368223 28425 net.cpp:454] conv1 <- data
I0521 16:02:34.368239 28425 net.cpp:411] conv1 -> conv1
I0521 16:02:34.370210 28425 net.cpp:150] Setting up conv1
I0521 16:02:34.370235 28425 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 16:02:34.370246 28425 net.cpp:165] Memory required for data: 3018920
I0521 16:02:34.370267 28425 layer_factory.hpp:77] Creating layer relu1
I0521 16:02:34.370282 28425 net.cpp:106] Creating Layer relu1
I0521 16:02:34.370292 28425 net.cpp:454] relu1 <- conv1
I0521 16:02:34.370306 28425 net.cpp:397] relu1 -> conv1 (in-place)
I0521 16:02:34.370817 28425 net.cpp:150] Setting up relu1
I0521 16:02:34.370833 28425 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 16:02:34.370844 28425 net.cpp:165] Memory required for data: 5783720
I0521 16:02:34.370854 28425 layer_factory.hpp:77] Creating layer pool1
I0521 16:02:34.370872 28425 net.cpp:106] Creating Layer pool1
I0521 16:02:34.370882 28425 net.cpp:454] pool1 <- conv1
I0521 16:02:34.370894 28425 net.cpp:411] pool1 -> pool1
I0521 16:02:34.370970 28425 net.cpp:150] Setting up pool1
I0521 16:02:34.370983 28425 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 16:02:34.370993 28425 net.cpp:165] Memory required for data: 7166120
I0521 16:02:34.371003 28425 layer_factory.hpp:77] Creating layer conv2
I0521 16:02:34.371021 28425 net.cpp:106] Creating Layer conv2
I0521 16:02:34.371031 28425 net.cpp:454] conv2 <- pool1
I0521 16:02:34.371045 28425 net.cpp:411] conv2 -> conv2
I0521 16:02:34.373004 28425 net.cpp:150] Setting up conv2
I0521 16:02:34.373028 28425 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 16:02:34.373040 28425 net.cpp:165] Memory required for data: 9153320
I0521 16:02:34.373059 28425 layer_factory.hpp:77] Creating layer relu2
I0521 16:02:34.373073 28425 net.cpp:106] Creating Layer relu2
I0521 16:02:34.373087 28425 net.cpp:454] relu2 <- conv2
I0521 16:02:34.373100 28425 net.cpp:397] relu2 -> conv2 (in-place)
I0521 16:02:34.373438 28425 net.cpp:150] Setting up relu2
I0521 16:02:34.373452 28425 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 16:02:34.373462 28425 net.cpp:165] Memory required for data: 11140520
I0521 16:02:34.373472 28425 layer_factory.hpp:77] Creating layer pool2
I0521 16:02:34.373486 28425 net.cpp:106] Creating Layer pool2
I0521 16:02:34.373497 28425 net.cpp:454] pool2 <- conv2
I0521 16:02:34.373509 28425 net.cpp:411] pool2 -> pool2
I0521 16:02:34.373582 28425 net.cpp:150] Setting up pool2
I0521 16:02:34.373595 28425 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 16:02:34.373605 28425 net.cpp:165] Memory required for data: 12134120
I0521 16:02:34.373615 28425 layer_factory.hpp:77] Creating layer conv3
I0521 16:02:34.373634 28425 net.cpp:106] Creating Layer conv3
I0521 16:02:34.373644 28425 net.cpp:454] conv3 <- pool2
I0521 16:02:34.373661 28425 net.cpp:411] conv3 -> conv3
I0521 16:02:34.375674 28425 net.cpp:150] Setting up conv3
I0521 16:02:34.375697 28425 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 16:02:34.375710 28425 net.cpp:165] Memory required for data: 13218280
I0521 16:02:34.375727 28425 layer_factory.hpp:77] Creating layer relu3
I0521 16:02:34.375756 28425 net.cpp:106] Creating Layer relu3
I0521 16:02:34.375766 28425 net.cpp:454] relu3 <- conv3
I0521 16:02:34.375778 28425 net.cpp:397] relu3 -> conv3 (in-place)
I0521 16:02:34.376258 28425 net.cpp:150] Setting up relu3
I0521 16:02:34.376276 28425 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 16:02:34.376286 28425 net.cpp:165] Memory required for data: 14302440
I0521 16:02:34.376296 28425 layer_factory.hpp:77] Creating layer pool3
I0521 16:02:34.376309 28425 net.cpp:106] Creating Layer pool3
I0521 16:02:34.376319 28425 net.cpp:454] pool3 <- conv3
I0521 16:02:34.376332 28425 net.cpp:411] pool3 -> pool3
I0521 16:02:34.376405 28425 net.cpp:150] Setting up pool3
I0521 16:02:34.376418 28425 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 16:02:34.376427 28425 net.cpp:165] Memory required for data: 14844520
I0521 16:02:34.376438 28425 layer_factory.hpp:77] Creating layer conv4
I0521 16:02:34.376456 28425 net.cpp:106] Creating Layer conv4
I0521 16:02:34.376466 28425 net.cpp:454] conv4 <- pool3
I0521 16:02:34.376482 28425 net.cpp:411] conv4 -> conv4
I0521 16:02:34.378541 28425 net.cpp:150] Setting up conv4
I0521 16:02:34.378563 28425 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 16:02:34.378576 28425 net.cpp:165] Memory required for data: 15207400
I0521 16:02:34.378593 28425 layer_factory.hpp:77] Creating layer relu4
I0521 16:02:34.378607 28425 net.cpp:106] Creating Layer relu4
I0521 16:02:34.378617 28425 net.cpp:454] relu4 <- conv4
I0521 16:02:34.378628 28425 net.cpp:397] relu4 -> conv4 (in-place)
I0521 16:02:34.379094 28425 net.cpp:150] Setting up relu4
I0521 16:02:34.379111 28425 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 16:02:34.379120 28425 net.cpp:165] Memory required for data: 15570280
I0521 16:02:34.379130 28425 layer_factory.hpp:77] Creating layer pool4
I0521 16:02:34.379143 28425 net.cpp:106] Creating Layer pool4
I0521 16:02:34.379153 28425 net.cpp:454] pool4 <- conv4
I0521 16:02:34.379166 28425 net.cpp:411] pool4 -> pool4
I0521 16:02:34.379238 28425 net.cpp:150] Setting up pool4
I0521 16:02:34.379252 28425 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 16:02:34.379262 28425 net.cpp:165] Memory required for data: 15751720
I0521 16:02:34.379271 28425 layer_factory.hpp:77] Creating layer ip1
I0521 16:02:34.379287 28425 net.cpp:106] Creating Layer ip1
I0521 16:02:34.379297 28425 net.cpp:454] ip1 <- pool4
I0521 16:02:34.379312 28425 net.cpp:411] ip1 -> ip1
I0521 16:02:34.394815 28425 net.cpp:150] Setting up ip1
I0521 16:02:34.394843 28425 net.cpp:157] Top shape: 10 196 (1960)
I0521 16:02:34.394855 28425 net.cpp:165] Memory required for data: 15759560
I0521 16:02:34.394876 28425 layer_factory.hpp:77] Creating layer relu5
I0521 16:02:34.394892 28425 net.cpp:106] Creating Layer relu5
I0521 16:02:34.394902 28425 net.cpp:454] relu5 <- ip1
I0521 16:02:34.394917 28425 net.cpp:397] relu5 -> ip1 (in-place)
I0521 16:02:34.395262 28425 net.cpp:150] Setting up relu5
I0521 16:02:34.395277 28425 net.cpp:157] Top shape: 10 196 (1960)
I0521 16:02:34.395285 28425 net.cpp:165] Memory required for data: 15767400
I0521 16:02:34.395295 28425 layer_factory.hpp:77] Creating layer drop1
I0521 16:02:34.395315 28425 net.cpp:106] Creating Layer drop1
I0521 16:02:34.395325 28425 net.cpp:454] drop1 <- ip1
I0521 16:02:34.395339 28425 net.cpp:397] drop1 -> ip1 (in-place)
I0521 16:02:34.395383 28425 net.cpp:150] Setting up drop1
I0521 16:02:34.395397 28425 net.cpp:157] Top shape: 10 196 (1960)
I0521 16:02:34.395407 28425 net.cpp:165] Memory required for data: 15775240
I0521 16:02:34.395417 28425 layer_factory.hpp:77] Creating layer ip2
I0521 16:02:34.395431 28425 net.cpp:106] Creating Layer ip2
I0521 16:02:34.395442 28425 net.cpp:454] ip2 <- ip1
I0521 16:02:34.395455 28425 net.cpp:411] ip2 -> ip2
I0521 16:02:34.395939 28425 net.cpp:150] Setting up ip2
I0521 16:02:34.395952 28425 net.cpp:157] Top shape: 10 98 (980)
I0521 16:02:34.395962 28425 net.cpp:165] Memory required for data: 15779160
I0521 16:02:34.395978 28425 layer_factory.hpp:77] Creating layer relu6
I0521 16:02:34.396003 28425 net.cpp:106] Creating Layer relu6
I0521 16:02:34.396013 28425 net.cpp:454] relu6 <- ip2
I0521 16:02:34.396026 28425 net.cpp:397] relu6 -> ip2 (in-place)
I0521 16:02:34.396560 28425 net.cpp:150] Setting up relu6
I0521 16:02:34.396576 28425 net.cpp:157] Top shape: 10 98 (980)
I0521 16:02:34.396590 28425 net.cpp:165] Memory required for data: 15783080
I0521 16:02:34.396600 28425 layer_factory.hpp:77] Creating layer drop2
I0521 16:02:34.396615 28425 net.cpp:106] Creating Layer drop2
I0521 16:02:34.396625 28425 net.cpp:454] drop2 <- ip2
I0521 16:02:34.396637 28425 net.cpp:397] drop2 -> ip2 (in-place)
I0521 16:02:34.396682 28425 net.cpp:150] Setting up drop2
I0521 16:02:34.396694 28425 net.cpp:157] Top shape: 10 98 (980)
I0521 16:02:34.396704 28425 net.cpp:165] Memory required for data: 15787000
I0521 16:02:34.396714 28425 layer_factory.hpp:77] Creating layer ip3
I0521 16:02:34.396728 28425 net.cpp:106] Creating Layer ip3
I0521 16:02:34.396739 28425 net.cpp:454] ip3 <- ip2
I0521 16:02:34.396752 28425 net.cpp:411] ip3 -> ip3
I0521 16:02:34.396971 28425 net.cpp:150] Setting up ip3
I0521 16:02:34.396986 28425 net.cpp:157] Top shape: 10 11 (110)
I0521 16:02:34.396994 28425 net.cpp:165] Memory required for data: 15787440
I0521 16:02:34.397011 28425 layer_factory.hpp:77] Creating layer drop3
I0521 16:02:34.397023 28425 net.cpp:106] Creating Layer drop3
I0521 16:02:34.397032 28425 net.cpp:454] drop3 <- ip3
I0521 16:02:34.397045 28425 net.cpp:397] drop3 -> ip3 (in-place)
I0521 16:02:34.397086 28425 net.cpp:150] Setting up drop3
I0521 16:02:34.397099 28425 net.cpp:157] Top shape: 10 11 (110)
I0521 16:02:34.397109 28425 net.cpp:165] Memory required for data: 15787880
I0521 16:02:34.397119 28425 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 16:02:34.397132 28425 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 16:02:34.397142 28425 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 16:02:34.397156 28425 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 16:02:34.397171 28425 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 16:02:34.397243 28425 net.cpp:150] Setting up ip3_drop3_0_split
I0521 16:02:34.397256 28425 net.cpp:157] Top shape: 10 11 (110)
I0521 16:02:34.397269 28425 net.cpp:157] Top shape: 10 11 (110)
I0521 16:02:34.397279 28425 net.cpp:165] Memory required for data: 15788760
I0521 16:02:34.397289 28425 layer_factory.hpp:77] Creating layer accuracy
I0521 16:02:34.397308 28425 net.cpp:106] Creating Layer accuracy
I0521 16:02:34.397318 28425 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 16:02:34.397330 28425 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 16:02:34.397344 28425 net.cpp:411] accuracy -> accuracy
I0521 16:02:34.397367 28425 net.cpp:150] Setting up accuracy
I0521 16:02:34.397379 28425 net.cpp:157] Top shape: (1)
I0521 16:02:34.397389 28425 net.cpp:165] Memory required for data: 15788764
I0521 16:02:34.397399 28425 layer_factory.hpp:77] Creating layer loss
I0521 16:02:34.397413 28425 net.cpp:106] Creating Layer loss
I0521 16:02:34.397423 28425 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 16:02:34.397433 28425 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 16:02:34.397446 28425 net.cpp:411] loss -> loss
I0521 16:02:34.397464 28425 layer_factory.hpp:77] Creating layer loss
I0521 16:02:34.397948 28425 net.cpp:150] Setting up loss
I0521 16:02:34.397963 28425 net.cpp:157] Top shape: (1)
I0521 16:02:34.397971 28425 net.cpp:160]     with loss weight 1
I0521 16:02:34.397992 28425 net.cpp:165] Memory required for data: 15788768
I0521 16:02:34.398002 28425 net.cpp:226] loss needs backward computation.
I0521 16:02:34.398013 28425 net.cpp:228] accuracy does not need backward computation.
I0521 16:02:34.398025 28425 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 16:02:34.398035 28425 net.cpp:226] drop3 needs backward computation.
I0521 16:02:34.398046 28425 net.cpp:226] ip3 needs backward computation.
I0521 16:02:34.398056 28425 net.cpp:226] drop2 needs backward computation.
I0521 16:02:34.398066 28425 net.cpp:226] relu6 needs backward computation.
I0521 16:02:34.398083 28425 net.cpp:226] ip2 needs backward computation.
I0521 16:02:34.398093 28425 net.cpp:226] drop1 needs backward computation.
I0521 16:02:34.398103 28425 net.cpp:226] relu5 needs backward computation.
I0521 16:02:34.398113 28425 net.cpp:226] ip1 needs backward computation.
I0521 16:02:34.398123 28425 net.cpp:226] pool4 needs backward computation.
I0521 16:02:34.398133 28425 net.cpp:226] relu4 needs backward computation.
I0521 16:02:34.398142 28425 net.cpp:226] conv4 needs backward computation.
I0521 16:02:34.398154 28425 net.cpp:226] pool3 needs backward computation.
I0521 16:02:34.398164 28425 net.cpp:226] relu3 needs backward computation.
I0521 16:02:34.398174 28425 net.cpp:226] conv3 needs backward computation.
I0521 16:02:34.398185 28425 net.cpp:226] pool2 needs backward computation.
I0521 16:02:34.398195 28425 net.cpp:226] relu2 needs backward computation.
I0521 16:02:34.398205 28425 net.cpp:226] conv2 needs backward computation.
I0521 16:02:34.398214 28425 net.cpp:226] pool1 needs backward computation.
I0521 16:02:34.398224 28425 net.cpp:226] relu1 needs backward computation.
I0521 16:02:34.398234 28425 net.cpp:226] conv1 needs backward computation.
I0521 16:02:34.398246 28425 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 16:02:34.398257 28425 net.cpp:228] data_hdf5 does not need backward computation.
I0521 16:02:34.398267 28425 net.cpp:270] This network produces output accuracy
I0521 16:02:34.398275 28425 net.cpp:270] This network produces output loss
I0521 16:02:34.398304 28425 net.cpp:283] Network initialization done.
I0521 16:02:34.398438 28425 solver.cpp:60] Solver scaffolding done.
I0521 16:02:34.399577 28425 caffe.cpp:212] Starting Optimization
I0521 16:02:34.399596 28425 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 16:02:34.399610 28425 solver.cpp:289] Learning Rate Policy: fixed
I0521 16:02:34.400691 28425 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 16:03:34.806211 28425 solver.cpp:409]     Test net output #0: accuracy = 0.120399
I0521 16:03:34.806378 28425 solver.cpp:409]     Test net output #1: loss = 2.39702 (* 1 = 2.39702 loss)
I0521 16:03:34.824081 28425 solver.cpp:237] Iteration 0, loss = 2.38968
I0521 16:03:34.824116 28425 solver.cpp:253]     Train net output #0: loss = 2.38968 (* 1 = 2.38968 loss)
I0521 16:03:34.824136 28425 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0521 16:03:51.596321 28425 solver.cpp:237] Iteration 1500, loss = 1.7403
I0521 16:03:51.596374 28425 solver.cpp:253]     Train net output #0: loss = 1.7403 (* 1 = 1.7403 loss)
I0521 16:03:51.596390 28425 sgd_solver.cpp:106] Iteration 1500, lr = 0.0035
I0521 16:04:08.321954 28425 solver.cpp:237] Iteration 3000, loss = 2.1854
I0521 16:04:08.322103 28425 solver.cpp:253]     Train net output #0: loss = 2.1854 (* 1 = 2.1854 loss)
I0521 16:04:08.322119 28425 sgd_solver.cpp:106] Iteration 3000, lr = 0.0035
I0521 16:04:25.095283 28425 solver.cpp:237] Iteration 4500, loss = 1.7369
I0521 16:04:25.095336 28425 solver.cpp:253]     Train net output #0: loss = 1.7369 (* 1 = 1.7369 loss)
I0521 16:04:25.095350 28425 sgd_solver.cpp:106] Iteration 4500, lr = 0.0035
I0521 16:04:41.865617 28425 solver.cpp:237] Iteration 6000, loss = 1.13211
I0521 16:04:41.865767 28425 solver.cpp:253]     Train net output #0: loss = 1.13211 (* 1 = 1.13211 loss)
I0521 16:04:41.865780 28425 sgd_solver.cpp:106] Iteration 6000, lr = 0.0035
I0521 16:04:58.613340 28425 solver.cpp:237] Iteration 7500, loss = 1.54982
I0521 16:04:58.613378 28425 solver.cpp:253]     Train net output #0: loss = 1.54982 (* 1 = 1.54982 loss)
I0521 16:04:58.613390 28425 sgd_solver.cpp:106] Iteration 7500, lr = 0.0035
I0521 16:05:15.422516 28425 solver.cpp:237] Iteration 9000, loss = 1.69426
I0521 16:05:15.422660 28425 solver.cpp:253]     Train net output #0: loss = 1.69426 (* 1 = 1.69426 loss)
I0521 16:05:15.422673 28425 sgd_solver.cpp:106] Iteration 9000, lr = 0.0035
I0521 16:05:54.235904 28425 solver.cpp:237] Iteration 10500, loss = 1.08578
I0521 16:05:54.236069 28425 solver.cpp:253]     Train net output #0: loss = 1.08578 (* 1 = 1.08578 loss)
I0521 16:05:54.236085 28425 sgd_solver.cpp:106] Iteration 10500, lr = 0.0035
I0521 16:06:11.034070 28425 solver.cpp:237] Iteration 12000, loss = 1.05243
I0521 16:06:11.034112 28425 solver.cpp:253]     Train net output #0: loss = 1.05243 (* 1 = 1.05243 loss)
I0521 16:06:11.034129 28425 sgd_solver.cpp:106] Iteration 12000, lr = 0.0035
I0521 16:06:27.841429 28425 solver.cpp:237] Iteration 13500, loss = 1.44882
I0521 16:06:27.841583 28425 solver.cpp:253]     Train net output #0: loss = 1.44881 (* 1 = 1.44881 loss)
I0521 16:06:27.841596 28425 sgd_solver.cpp:106] Iteration 13500, lr = 0.0035
I0521 16:06:44.607405 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_15000.caffemodel
I0521 16:06:44.656893 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_15000.solverstate
I0521 16:06:44.685214 28425 solver.cpp:237] Iteration 15000, loss = 1.21218
I0521 16:06:44.685262 28425 solver.cpp:253]     Train net output #0: loss = 1.21218 (* 1 = 1.21218 loss)
I0521 16:06:44.685281 28425 sgd_solver.cpp:106] Iteration 15000, lr = 0.0035
I0521 16:07:01.470299 28425 solver.cpp:237] Iteration 16500, loss = 1.34778
I0521 16:07:01.470451 28425 solver.cpp:253]     Train net output #0: loss = 1.34778 (* 1 = 1.34778 loss)
I0521 16:07:01.470466 28425 sgd_solver.cpp:106] Iteration 16500, lr = 0.0035
I0521 16:07:18.242858 28425 solver.cpp:237] Iteration 18000, loss = 0.625409
I0521 16:07:18.242911 28425 solver.cpp:253]     Train net output #0: loss = 0.62541 (* 1 = 0.62541 loss)
I0521 16:07:18.242924 28425 sgd_solver.cpp:106] Iteration 18000, lr = 0.0035
I0521 16:07:35.006922 28425 solver.cpp:237] Iteration 19500, loss = 1.67148
I0521 16:07:35.007078 28425 solver.cpp:253]     Train net output #0: loss = 1.67148 (* 1 = 1.67148 loss)
I0521 16:07:35.007092 28425 sgd_solver.cpp:106] Iteration 19500, lr = 0.0035
I0521 16:08:13.842494 28425 solver.cpp:237] Iteration 21000, loss = 0.918629
I0521 16:08:13.842663 28425 solver.cpp:253]     Train net output #0: loss = 0.91863 (* 1 = 0.91863 loss)
I0521 16:08:13.842679 28425 sgd_solver.cpp:106] Iteration 21000, lr = 0.0035
I0521 16:08:30.608996 28425 solver.cpp:237] Iteration 22500, loss = 0.956695
I0521 16:08:30.609048 28425 solver.cpp:253]     Train net output #0: loss = 0.956696 (* 1 = 0.956696 loss)
I0521 16:08:30.609066 28425 sgd_solver.cpp:106] Iteration 22500, lr = 0.0035
I0521 16:08:47.385696 28425 solver.cpp:237] Iteration 24000, loss = 1.30805
I0521 16:08:47.385844 28425 solver.cpp:253]     Train net output #0: loss = 1.30805 (* 1 = 1.30805 loss)
I0521 16:08:47.385859 28425 sgd_solver.cpp:106] Iteration 24000, lr = 0.0035
I0521 16:09:04.158843 28425 solver.cpp:237] Iteration 25500, loss = 1.50495
I0521 16:09:04.158886 28425 solver.cpp:253]     Train net output #0: loss = 1.50495 (* 1 = 1.50495 loss)
I0521 16:09:04.158903 28425 sgd_solver.cpp:106] Iteration 25500, lr = 0.0035
I0521 16:09:20.930627 28425 solver.cpp:237] Iteration 27000, loss = 0.983945
I0521 16:09:20.930778 28425 solver.cpp:253]     Train net output #0: loss = 0.983947 (* 1 = 0.983947 loss)
I0521 16:09:20.930793 28425 sgd_solver.cpp:106] Iteration 27000, lr = 0.0035
I0521 16:09:37.712724 28425 solver.cpp:237] Iteration 28500, loss = 1.30858
I0521 16:09:37.712760 28425 solver.cpp:253]     Train net output #0: loss = 1.30858 (* 1 = 1.30858 loss)
I0521 16:09:37.712777 28425 sgd_solver.cpp:106] Iteration 28500, lr = 0.0035
I0521 16:09:54.466701 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_30000.caffemodel
I0521 16:09:54.512152 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_30000.solverstate
I0521 16:09:54.538564 28425 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 16:10:54.083506 28425 solver.cpp:409]     Test net output #0: accuracy = 0.857186
I0521 16:10:54.083681 28425 solver.cpp:409]     Test net output #1: loss = 0.472893 (* 1 = 0.472893 loss)
I0521 16:11:16.201220 28425 solver.cpp:237] Iteration 30000, loss = 2.34423
I0521 16:11:16.201277 28425 solver.cpp:253]     Train net output #0: loss = 2.34423 (* 1 = 2.34423 loss)
I0521 16:11:16.201292 28425 sgd_solver.cpp:106] Iteration 30000, lr = 0.0035
I0521 16:11:32.817749 28425 solver.cpp:237] Iteration 31500, loss = 1.48079
I0521 16:11:32.817911 28425 solver.cpp:253]     Train net output #0: loss = 1.48079 (* 1 = 1.48079 loss)
I0521 16:11:32.817925 28425 sgd_solver.cpp:106] Iteration 31500, lr = 0.0035
I0521 16:11:49.447773 28425 solver.cpp:237] Iteration 33000, loss = 0.992918
I0521 16:11:49.447825 28425 solver.cpp:253]     Train net output #0: loss = 0.992921 (* 1 = 0.992921 loss)
I0521 16:11:49.447845 28425 sgd_solver.cpp:106] Iteration 33000, lr = 0.0035
I0521 16:12:06.033671 28425 solver.cpp:237] Iteration 34500, loss = 1.45001
I0521 16:12:06.033813 28425 solver.cpp:253]     Train net output #0: loss = 1.45001 (* 1 = 1.45001 loss)
I0521 16:12:06.033828 28425 sgd_solver.cpp:106] Iteration 34500, lr = 0.0035
I0521 16:12:22.659220 28425 solver.cpp:237] Iteration 36000, loss = 1.41543
I0521 16:12:22.659270 28425 solver.cpp:253]     Train net output #0: loss = 1.41543 (* 1 = 1.41543 loss)
I0521 16:12:22.659286 28425 sgd_solver.cpp:106] Iteration 36000, lr = 0.0035
I0521 16:12:39.260809 28425 solver.cpp:237] Iteration 37500, loss = 0.872159
I0521 16:12:39.260978 28425 solver.cpp:253]     Train net output #0: loss = 0.872161 (* 1 = 0.872161 loss)
I0521 16:12:39.260993 28425 sgd_solver.cpp:106] Iteration 37500, lr = 0.0035
I0521 16:12:55.848279 28425 solver.cpp:237] Iteration 39000, loss = 1.0784
I0521 16:12:55.848316 28425 solver.cpp:253]     Train net output #0: loss = 1.0784 (* 1 = 1.0784 loss)
I0521 16:12:55.848331 28425 sgd_solver.cpp:106] Iteration 39000, lr = 0.0035
I0521 16:13:34.589496 28425 solver.cpp:237] Iteration 40500, loss = 1.5839
I0521 16:13:34.589668 28425 solver.cpp:253]     Train net output #0: loss = 1.5839 (* 1 = 1.5839 loss)
I0521 16:13:34.589681 28425 sgd_solver.cpp:106] Iteration 40500, lr = 0.0035
I0521 16:13:51.197075 28425 solver.cpp:237] Iteration 42000, loss = 1.49168
I0521 16:13:51.197127 28425 solver.cpp:253]     Train net output #0: loss = 1.49168 (* 1 = 1.49168 loss)
I0521 16:13:51.197141 28425 sgd_solver.cpp:106] Iteration 42000, lr = 0.0035
I0521 16:14:07.809932 28425 solver.cpp:237] Iteration 43500, loss = 1.36883
I0521 16:14:07.810084 28425 solver.cpp:253]     Train net output #0: loss = 1.36883 (* 1 = 1.36883 loss)
I0521 16:14:07.810098 28425 sgd_solver.cpp:106] Iteration 43500, lr = 0.0035
I0521 16:14:24.411516 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_45000.caffemodel
I0521 16:14:24.459867 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_45000.solverstate
I0521 16:14:24.492087 28425 solver.cpp:237] Iteration 45000, loss = 1.59719
I0521 16:14:24.492141 28425 solver.cpp:253]     Train net output #0: loss = 1.59719 (* 1 = 1.59719 loss)
I0521 16:14:24.492154 28425 sgd_solver.cpp:106] Iteration 45000, lr = 0.0035
I0521 16:14:41.114320 28425 solver.cpp:237] Iteration 46500, loss = 0.986398
I0521 16:14:41.114480 28425 solver.cpp:253]     Train net output #0: loss = 0.9864 (* 1 = 0.9864 loss)
I0521 16:14:41.114495 28425 sgd_solver.cpp:106] Iteration 46500, lr = 0.0035
I0521 16:14:57.668999 28425 solver.cpp:237] Iteration 48000, loss = 1.32133
I0521 16:14:57.669035 28425 solver.cpp:253]     Train net output #0: loss = 1.32133 (* 1 = 1.32133 loss)
I0521 16:14:57.669054 28425 sgd_solver.cpp:106] Iteration 48000, lr = 0.0035
I0521 16:15:14.298457 28425 solver.cpp:237] Iteration 49500, loss = 1.00426
I0521 16:15:14.298607 28425 solver.cpp:253]     Train net output #0: loss = 1.00426 (* 1 = 1.00426 loss)
I0521 16:15:14.298621 28425 sgd_solver.cpp:106] Iteration 49500, lr = 0.0035
I0521 16:15:53.070101 28425 solver.cpp:237] Iteration 51000, loss = 1.49573
I0521 16:15:53.070268 28425 solver.cpp:253]     Train net output #0: loss = 1.49573 (* 1 = 1.49573 loss)
I0521 16:15:53.070282 28425 sgd_solver.cpp:106] Iteration 51000, lr = 0.0035
I0521 16:16:09.686980 28425 solver.cpp:237] Iteration 52500, loss = 0.77328
I0521 16:16:09.687028 28425 solver.cpp:253]     Train net output #0: loss = 0.773283 (* 1 = 0.773283 loss)
I0521 16:16:09.687044 28425 sgd_solver.cpp:106] Iteration 52500, lr = 0.0035
I0521 16:16:26.289417 28425 solver.cpp:237] Iteration 54000, loss = 1.25489
I0521 16:16:26.289577 28425 solver.cpp:253]     Train net output #0: loss = 1.25489 (* 1 = 1.25489 loss)
I0521 16:16:26.289592 28425 sgd_solver.cpp:106] Iteration 54000, lr = 0.0035
I0521 16:16:42.932451 28425 solver.cpp:237] Iteration 55500, loss = 1.33258
I0521 16:16:42.932487 28425 solver.cpp:253]     Train net output #0: loss = 1.33258 (* 1 = 1.33258 loss)
I0521 16:16:42.932503 28425 sgd_solver.cpp:106] Iteration 55500, lr = 0.0035
I0521 16:16:59.537025 28425 solver.cpp:237] Iteration 57000, loss = 1.16674
I0521 16:16:59.537179 28425 solver.cpp:253]     Train net output #0: loss = 1.16674 (* 1 = 1.16674 loss)
I0521 16:16:59.537194 28425 sgd_solver.cpp:106] Iteration 57000, lr = 0.0035
I0521 16:17:16.130430 28425 solver.cpp:237] Iteration 58500, loss = 1.01693
I0521 16:17:16.130484 28425 solver.cpp:253]     Train net output #0: loss = 1.01693 (* 1 = 1.01693 loss)
I0521 16:17:16.130499 28425 sgd_solver.cpp:106] Iteration 58500, lr = 0.0035
I0521 16:17:32.691823 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_60000.caffemodel
I0521 16:17:32.739871 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_60000.solverstate
I0521 16:17:32.768523 28425 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 16:18:53.061332 28425 solver.cpp:409]     Test net output #0: accuracy = 0.86883
I0521 16:18:53.061506 28425 solver.cpp:409]     Test net output #1: loss = 0.449615 (* 1 = 0.449615 loss)
I0521 16:19:15.162739 28425 solver.cpp:237] Iteration 60000, loss = 0.780995
I0521 16:19:15.162796 28425 solver.cpp:253]     Train net output #0: loss = 0.780997 (* 1 = 0.780997 loss)
I0521 16:19:15.162811 28425 sgd_solver.cpp:106] Iteration 60000, lr = 0.0035
I0521 16:19:32.036016 28425 solver.cpp:237] Iteration 61500, loss = 1.08609
I0521 16:19:32.036170 28425 solver.cpp:253]     Train net output #0: loss = 1.08609 (* 1 = 1.08609 loss)
I0521 16:19:32.036182 28425 sgd_solver.cpp:106] Iteration 61500, lr = 0.0035
I0521 16:19:48.862758 28425 solver.cpp:237] Iteration 63000, loss = 1.06457
I0521 16:19:48.862808 28425 solver.cpp:253]     Train net output #0: loss = 1.06457 (* 1 = 1.06457 loss)
I0521 16:19:48.862823 28425 sgd_solver.cpp:106] Iteration 63000, lr = 0.0035
I0521 16:20:05.711292 28425 solver.cpp:237] Iteration 64500, loss = 1.11292
I0521 16:20:05.711449 28425 solver.cpp:253]     Train net output #0: loss = 1.11292 (* 1 = 1.11292 loss)
I0521 16:20:05.711463 28425 sgd_solver.cpp:106] Iteration 64500, lr = 0.0035
I0521 16:20:22.562824 28425 solver.cpp:237] Iteration 66000, loss = 0.937273
I0521 16:20:22.562861 28425 solver.cpp:253]     Train net output #0: loss = 0.937277 (* 1 = 0.937277 loss)
I0521 16:20:22.562877 28425 sgd_solver.cpp:106] Iteration 66000, lr = 0.0035
I0521 16:20:39.440304 28425 solver.cpp:237] Iteration 67500, loss = 1.6289
I0521 16:20:39.440456 28425 solver.cpp:253]     Train net output #0: loss = 1.6289 (* 1 = 1.6289 loss)
I0521 16:20:39.440470 28425 sgd_solver.cpp:106] Iteration 67500, lr = 0.0035
I0521 16:20:56.348732 28425 solver.cpp:237] Iteration 69000, loss = 1.05491
I0521 16:20:56.348786 28425 solver.cpp:253]     Train net output #0: loss = 1.05491 (* 1 = 1.05491 loss)
I0521 16:20:56.348801 28425 sgd_solver.cpp:106] Iteration 69000, lr = 0.0035
I0521 16:21:35.350334 28425 solver.cpp:237] Iteration 70500, loss = 1.20206
I0521 16:21:35.350498 28425 solver.cpp:253]     Train net output #0: loss = 1.20206 (* 1 = 1.20206 loss)
I0521 16:21:35.350512 28425 sgd_solver.cpp:106] Iteration 70500, lr = 0.0035
I0521 16:21:52.242496 28425 solver.cpp:237] Iteration 72000, loss = 0.69374
I0521 16:21:52.242547 28425 solver.cpp:253]     Train net output #0: loss = 0.693742 (* 1 = 0.693742 loss)
I0521 16:21:52.242563 28425 sgd_solver.cpp:106] Iteration 72000, lr = 0.0035
I0521 16:22:09.091290 28425 solver.cpp:237] Iteration 73500, loss = 1.3351
I0521 16:22:09.091431 28425 solver.cpp:253]     Train net output #0: loss = 1.3351 (* 1 = 1.3351 loss)
I0521 16:22:09.091446 28425 sgd_solver.cpp:106] Iteration 73500, lr = 0.0035
I0521 16:22:25.971407 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_75000.caffemodel
I0521 16:22:26.019170 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_75000.solverstate
I0521 16:22:26.051136 28425 solver.cpp:237] Iteration 75000, loss = 1.5669
I0521 16:22:26.051188 28425 solver.cpp:253]     Train net output #0: loss = 1.5669 (* 1 = 1.5669 loss)
I0521 16:22:26.051203 28425 sgd_solver.cpp:106] Iteration 75000, lr = 0.0035
I0521 16:22:42.931890 28425 solver.cpp:237] Iteration 76500, loss = 1.44449
I0521 16:22:42.932055 28425 solver.cpp:253]     Train net output #0: loss = 1.44449 (* 1 = 1.44449 loss)
I0521 16:22:42.932071 28425 sgd_solver.cpp:106] Iteration 76500, lr = 0.0035
I0521 16:22:59.751060 28425 solver.cpp:237] Iteration 78000, loss = 1.32054
I0521 16:22:59.751111 28425 solver.cpp:253]     Train net output #0: loss = 1.32054 (* 1 = 1.32054 loss)
I0521 16:22:59.751127 28425 sgd_solver.cpp:106] Iteration 78000, lr = 0.0035
I0521 16:23:16.627426 28425 solver.cpp:237] Iteration 79500, loss = 1.28937
I0521 16:23:16.627580 28425 solver.cpp:253]     Train net output #0: loss = 1.28937 (* 1 = 1.28937 loss)
I0521 16:23:16.627594 28425 sgd_solver.cpp:106] Iteration 79500, lr = 0.0035
I0521 16:23:55.653403 28425 solver.cpp:237] Iteration 81000, loss = 1.48845
I0521 16:23:55.653584 28425 solver.cpp:253]     Train net output #0: loss = 1.48845 (* 1 = 1.48845 loss)
I0521 16:23:55.653599 28425 sgd_solver.cpp:106] Iteration 81000, lr = 0.0035
I0521 16:24:12.505702 28425 solver.cpp:237] Iteration 82500, loss = 0.460902
I0521 16:24:12.505740 28425 solver.cpp:253]     Train net output #0: loss = 0.460906 (* 1 = 0.460906 loss)
I0521 16:24:12.505756 28425 sgd_solver.cpp:106] Iteration 82500, lr = 0.0035
I0521 16:24:29.374557 28425 solver.cpp:237] Iteration 84000, loss = 1.00596
I0521 16:24:29.374714 28425 solver.cpp:253]     Train net output #0: loss = 1.00596 (* 1 = 1.00596 loss)
I0521 16:24:29.374728 28425 sgd_solver.cpp:106] Iteration 84000, lr = 0.0035
I0521 16:24:46.233691 28425 solver.cpp:237] Iteration 85500, loss = 0.86818
I0521 16:24:46.233741 28425 solver.cpp:253]     Train net output #0: loss = 0.868183 (* 1 = 0.868183 loss)
I0521 16:24:46.233755 28425 sgd_solver.cpp:106] Iteration 85500, lr = 0.0035
I0521 16:25:03.063686 28425 solver.cpp:237] Iteration 87000, loss = 1.54785
I0521 16:25:03.063828 28425 solver.cpp:253]     Train net output #0: loss = 1.54785 (* 1 = 1.54785 loss)
I0521 16:25:03.063849 28425 sgd_solver.cpp:106] Iteration 87000, lr = 0.0035
I0521 16:25:19.925987 28425 solver.cpp:237] Iteration 88500, loss = 1.26819
I0521 16:25:19.926034 28425 solver.cpp:253]     Train net output #0: loss = 1.26819 (* 1 = 1.26819 loss)
I0521 16:25:19.926050 28425 sgd_solver.cpp:106] Iteration 88500, lr = 0.0035
I0521 16:25:36.797103 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_90000.caffemodel
I0521 16:25:36.843616 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_90000.solverstate
I0521 16:25:36.870053 28425 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 16:26:36.174520 28425 solver.cpp:409]     Test net output #0: accuracy = 0.875739
I0521 16:26:36.174685 28425 solver.cpp:409]     Test net output #1: loss = 0.430624 (* 1 = 0.430624 loss)
I0521 16:26:58.366787 28425 solver.cpp:237] Iteration 90000, loss = 1.08048
I0521 16:26:58.366844 28425 solver.cpp:253]     Train net output #0: loss = 1.08049 (* 1 = 1.08049 loss)
I0521 16:26:58.366858 28425 sgd_solver.cpp:106] Iteration 90000, lr = 0.0035
I0521 16:27:15.003736 28425 solver.cpp:237] Iteration 91500, loss = 0.690182
I0521 16:27:15.003909 28425 solver.cpp:253]     Train net output #0: loss = 0.690185 (* 1 = 0.690185 loss)
I0521 16:27:15.003923 28425 sgd_solver.cpp:106] Iteration 91500, lr = 0.0035
I0521 16:27:31.610451 28425 solver.cpp:237] Iteration 93000, loss = 1.65801
I0521 16:27:31.610487 28425 solver.cpp:253]     Train net output #0: loss = 1.65801 (* 1 = 1.65801 loss)
I0521 16:27:31.610503 28425 sgd_solver.cpp:106] Iteration 93000, lr = 0.0035
I0521 16:27:48.212517 28425 solver.cpp:237] Iteration 94500, loss = 0.816835
I0521 16:27:48.212672 28425 solver.cpp:253]     Train net output #0: loss = 0.816837 (* 1 = 0.816837 loss)
I0521 16:27:48.212687 28425 sgd_solver.cpp:106] Iteration 94500, lr = 0.0035
I0521 16:28:04.866677 28425 solver.cpp:237] Iteration 96000, loss = 1.02274
I0521 16:28:04.866719 28425 solver.cpp:253]     Train net output #0: loss = 1.02274 (* 1 = 1.02274 loss)
I0521 16:28:04.866741 28425 sgd_solver.cpp:106] Iteration 96000, lr = 0.0035
I0521 16:28:21.460685 28425 solver.cpp:237] Iteration 97500, loss = 0.873137
I0521 16:28:21.460826 28425 solver.cpp:253]     Train net output #0: loss = 0.873139 (* 1 = 0.873139 loss)
I0521 16:28:21.460839 28425 sgd_solver.cpp:106] Iteration 97500, lr = 0.0035
I0521 16:28:38.039513 28425 solver.cpp:237] Iteration 99000, loss = 1.43376
I0521 16:28:38.039564 28425 solver.cpp:253]     Train net output #0: loss = 1.43376 (* 1 = 1.43376 loss)
I0521 16:28:38.039579 28425 sgd_solver.cpp:106] Iteration 99000, lr = 0.0035
I0521 16:29:16.836613 28425 solver.cpp:237] Iteration 100500, loss = 0.754859
I0521 16:29:16.836798 28425 solver.cpp:253]     Train net output #0: loss = 0.754862 (* 1 = 0.754862 loss)
I0521 16:29:16.836812 28425 sgd_solver.cpp:106] Iteration 100500, lr = 0.0035
I0521 16:29:33.428773 28425 solver.cpp:237] Iteration 102000, loss = 0.853049
I0521 16:29:33.428812 28425 solver.cpp:253]     Train net output #0: loss = 0.853051 (* 1 = 0.853051 loss)
I0521 16:29:33.428827 28425 sgd_solver.cpp:106] Iteration 102000, lr = 0.0035
I0521 16:29:50.041504 28425 solver.cpp:237] Iteration 103500, loss = 0.762446
I0521 16:29:50.041669 28425 solver.cpp:253]     Train net output #0: loss = 0.762447 (* 1 = 0.762447 loss)
I0521 16:29:50.041685 28425 sgd_solver.cpp:106] Iteration 103500, lr = 0.0035
I0521 16:30:06.902590 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_105000.caffemodel
I0521 16:30:06.948505 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_105000.solverstate
I0521 16:30:06.977283 28425 solver.cpp:237] Iteration 105000, loss = 1.3552
I0521 16:30:06.977334 28425 solver.cpp:253]     Train net output #0: loss = 1.3552 (* 1 = 1.3552 loss)
I0521 16:30:06.977351 28425 sgd_solver.cpp:106] Iteration 105000, lr = 0.0035
I0521 16:30:23.916352 28425 solver.cpp:237] Iteration 106500, loss = 1.40963
I0521 16:30:23.916502 28425 solver.cpp:253]     Train net output #0: loss = 1.40963 (* 1 = 1.40963 loss)
I0521 16:30:23.916517 28425 sgd_solver.cpp:106] Iteration 106500, lr = 0.0035
I0521 16:30:40.876108 28425 solver.cpp:237] Iteration 108000, loss = 1.48185
I0521 16:30:40.876160 28425 solver.cpp:253]     Train net output #0: loss = 1.48185 (* 1 = 1.48185 loss)
I0521 16:30:40.876176 28425 sgd_solver.cpp:106] Iteration 108000, lr = 0.0035
I0521 16:30:57.855742 28425 solver.cpp:237] Iteration 109500, loss = 0.815189
I0521 16:30:57.855914 28425 solver.cpp:253]     Train net output #0: loss = 0.81519 (* 1 = 0.81519 loss)
I0521 16:30:57.855928 28425 sgd_solver.cpp:106] Iteration 109500, lr = 0.0035
I0521 16:31:36.966099 28425 solver.cpp:237] Iteration 111000, loss = 1.43244
I0521 16:31:36.966274 28425 solver.cpp:253]     Train net output #0: loss = 1.43244 (* 1 = 1.43244 loss)
I0521 16:31:36.966287 28425 sgd_solver.cpp:106] Iteration 111000, lr = 0.0035
I0521 16:31:53.905160 28425 solver.cpp:237] Iteration 112500, loss = 2.15701
I0521 16:31:53.905211 28425 solver.cpp:253]     Train net output #0: loss = 2.15701 (* 1 = 2.15701 loss)
I0521 16:31:53.905225 28425 sgd_solver.cpp:106] Iteration 112500, lr = 0.0035
I0521 16:32:10.851073 28425 solver.cpp:237] Iteration 114000, loss = 1.67036
I0521 16:32:10.851229 28425 solver.cpp:253]     Train net output #0: loss = 1.67036 (* 1 = 1.67036 loss)
I0521 16:32:10.851243 28425 sgd_solver.cpp:106] Iteration 114000, lr = 0.0035
I0521 16:32:27.759680 28425 solver.cpp:237] Iteration 115500, loss = 1.23048
I0521 16:32:27.759716 28425 solver.cpp:253]     Train net output #0: loss = 1.23048 (* 1 = 1.23048 loss)
I0521 16:32:27.759732 28425 sgd_solver.cpp:106] Iteration 115500, lr = 0.0035
I0521 16:32:44.580283 28425 solver.cpp:237] Iteration 117000, loss = 0.789126
I0521 16:32:44.580447 28425 solver.cpp:253]     Train net output #0: loss = 0.789125 (* 1 = 0.789125 loss)
I0521 16:32:44.580462 28425 sgd_solver.cpp:106] Iteration 117000, lr = 0.0035
I0521 16:33:01.498152 28425 solver.cpp:237] Iteration 118500, loss = 1.67045
I0521 16:33:01.498203 28425 solver.cpp:253]     Train net output #0: loss = 1.67045 (* 1 = 1.67045 loss)
I0521 16:33:01.498216 28425 sgd_solver.cpp:106] Iteration 118500, lr = 0.0035
I0521 16:33:18.334614 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_120000.caffemodel
I0521 16:33:18.380713 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_120000.solverstate
I0521 16:33:18.405917 28425 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 16:34:38.464759 28425 solver.cpp:409]     Test net output #0: accuracy = 0.874939
I0521 16:34:38.464928 28425 solver.cpp:409]     Test net output #1: loss = 0.385199 (* 1 = 0.385199 loss)
I0521 16:35:00.616227 28425 solver.cpp:237] Iteration 120000, loss = 1.69327
I0521 16:35:00.616282 28425 solver.cpp:253]     Train net output #0: loss = 1.69327 (* 1 = 1.69327 loss)
I0521 16:35:00.616297 28425 sgd_solver.cpp:106] Iteration 120000, lr = 0.0035
I0521 16:35:17.203521 28425 solver.cpp:237] Iteration 121500, loss = 1.10951
I0521 16:35:17.203687 28425 solver.cpp:253]     Train net output #0: loss = 1.10951 (* 1 = 1.10951 loss)
I0521 16:35:17.203702 28425 sgd_solver.cpp:106] Iteration 121500, lr = 0.0035
I0521 16:35:33.796983 28425 solver.cpp:237] Iteration 123000, loss = 1.06573
I0521 16:35:33.797032 28425 solver.cpp:253]     Train net output #0: loss = 1.06573 (* 1 = 1.06573 loss)
I0521 16:35:33.797050 28425 sgd_solver.cpp:106] Iteration 123000, lr = 0.0035
I0521 16:35:50.417101 28425 solver.cpp:237] Iteration 124500, loss = 1.41025
I0521 16:35:50.417248 28425 solver.cpp:253]     Train net output #0: loss = 1.41025 (* 1 = 1.41025 loss)
I0521 16:35:50.417261 28425 sgd_solver.cpp:106] Iteration 124500, lr = 0.0035
I0521 16:36:07.004700 28425 solver.cpp:237] Iteration 126000, loss = 0.855106
I0521 16:36:07.004752 28425 solver.cpp:253]     Train net output #0: loss = 0.855106 (* 1 = 0.855106 loss)
I0521 16:36:07.004767 28425 sgd_solver.cpp:106] Iteration 126000, lr = 0.0035
I0521 16:36:23.632799 28425 solver.cpp:237] Iteration 127500, loss = 0.827639
I0521 16:36:23.632964 28425 solver.cpp:253]     Train net output #0: loss = 0.827639 (* 1 = 0.827639 loss)
I0521 16:36:23.632978 28425 sgd_solver.cpp:106] Iteration 127500, lr = 0.0035
I0521 16:36:40.236135 28425 solver.cpp:237] Iteration 129000, loss = 0.768086
I0521 16:36:40.236171 28425 solver.cpp:253]     Train net output #0: loss = 0.768087 (* 1 = 0.768087 loss)
I0521 16:36:40.236186 28425 sgd_solver.cpp:106] Iteration 129000, lr = 0.0035
I0521 16:37:19.116760 28425 solver.cpp:237] Iteration 130500, loss = 1.65048
I0521 16:37:19.116935 28425 solver.cpp:253]     Train net output #0: loss = 1.65048 (* 1 = 1.65048 loss)
I0521 16:37:19.116948 28425 sgd_solver.cpp:106] Iteration 130500, lr = 0.0035
I0521 16:37:35.892253 28425 solver.cpp:237] Iteration 132000, loss = 0.641863
I0521 16:37:35.892304 28425 solver.cpp:253]     Train net output #0: loss = 0.641863 (* 1 = 0.641863 loss)
I0521 16:37:35.892319 28425 sgd_solver.cpp:106] Iteration 132000, lr = 0.0035
I0521 16:37:52.688350 28425 solver.cpp:237] Iteration 133500, loss = 1.27026
I0521 16:37:52.688498 28425 solver.cpp:253]     Train net output #0: loss = 1.27026 (* 1 = 1.27026 loss)
I0521 16:37:52.688511 28425 sgd_solver.cpp:106] Iteration 133500, lr = 0.0035
I0521 16:38:09.464907 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_135000.caffemodel
I0521 16:38:09.512611 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_135000.solverstate
I0521 16:38:09.544127 28425 solver.cpp:237] Iteration 135000, loss = 2.95713
I0521 16:38:09.544180 28425 solver.cpp:253]     Train net output #0: loss = 2.95713 (* 1 = 2.95713 loss)
I0521 16:38:09.544194 28425 sgd_solver.cpp:106] Iteration 135000, lr = 0.0035
I0521 16:38:26.324718 28425 solver.cpp:237] Iteration 136500, loss = 1.12925
I0521 16:38:26.324880 28425 solver.cpp:253]     Train net output #0: loss = 1.12925 (* 1 = 1.12925 loss)
I0521 16:38:26.324894 28425 sgd_solver.cpp:106] Iteration 136500, lr = 0.0035
I0521 16:38:43.109416 28425 solver.cpp:237] Iteration 138000, loss = 1.77877
I0521 16:38:43.109452 28425 solver.cpp:253]     Train net output #0: loss = 1.77877 (* 1 = 1.77877 loss)
I0521 16:38:43.109467 28425 sgd_solver.cpp:106] Iteration 138000, lr = 0.0035
I0521 16:38:59.864950 28425 solver.cpp:237] Iteration 139500, loss = 0.875686
I0521 16:38:59.865114 28425 solver.cpp:253]     Train net output #0: loss = 0.875687 (* 1 = 0.875687 loss)
I0521 16:38:59.865129 28425 sgd_solver.cpp:106] Iteration 139500, lr = 0.0035
I0521 16:39:38.801986 28425 solver.cpp:237] Iteration 141000, loss = 0.936738
I0521 16:39:38.802161 28425 solver.cpp:253]     Train net output #0: loss = 0.936739 (* 1 = 0.936739 loss)
I0521 16:39:38.802176 28425 sgd_solver.cpp:106] Iteration 141000, lr = 0.0035
I0521 16:39:55.575964 28425 solver.cpp:237] Iteration 142500, loss = 1.46903
I0521 16:39:55.576014 28425 solver.cpp:253]     Train net output #0: loss = 1.46903 (* 1 = 1.46903 loss)
I0521 16:39:55.576031 28425 sgd_solver.cpp:106] Iteration 142500, lr = 0.0035
I0521 16:40:12.358049 28425 solver.cpp:237] Iteration 144000, loss = 1.88458
I0521 16:40:12.358214 28425 solver.cpp:253]     Train net output #0: loss = 1.88458 (* 1 = 1.88458 loss)
I0521 16:40:12.358229 28425 sgd_solver.cpp:106] Iteration 144000, lr = 0.0035
I0521 16:40:29.113934 28425 solver.cpp:237] Iteration 145500, loss = 1.41814
I0521 16:40:29.113971 28425 solver.cpp:253]     Train net output #0: loss = 1.41814 (* 1 = 1.41814 loss)
I0521 16:40:29.113986 28425 sgd_solver.cpp:106] Iteration 145500, lr = 0.0035
I0521 16:40:45.866092 28425 solver.cpp:237] Iteration 147000, loss = 1.20661
I0521 16:40:45.866248 28425 solver.cpp:253]     Train net output #0: loss = 1.20661 (* 1 = 1.20661 loss)
I0521 16:40:45.866262 28425 sgd_solver.cpp:106] Iteration 147000, lr = 0.0035
I0521 16:41:02.625269 28425 solver.cpp:237] Iteration 148500, loss = 1.15273
I0521 16:41:02.625318 28425 solver.cpp:253]     Train net output #0: loss = 1.15273 (* 1 = 1.15273 loss)
I0521 16:41:02.625334 28425 sgd_solver.cpp:106] Iteration 148500, lr = 0.0035
I0521 16:41:19.399616 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_150000.caffemodel
I0521 16:41:19.447720 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_150000.solverstate
I0521 16:41:19.475651 28425 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 16:42:18.612426 28425 solver.cpp:409]     Test net output #0: accuracy = 0.881086
I0521 16:42:18.612607 28425 solver.cpp:409]     Test net output #1: loss = 0.399722 (* 1 = 0.399722 loss)
I0521 16:42:39.480224 28425 solver.cpp:237] Iteration 150000, loss = 0.669369
I0521 16:42:39.480281 28425 solver.cpp:253]     Train net output #0: loss = 0.669371 (* 1 = 0.669371 loss)
I0521 16:42:39.480298 28425 sgd_solver.cpp:106] Iteration 150000, lr = 0.0035
I0521 16:42:56.449422 28425 solver.cpp:237] Iteration 151500, loss = 1.12528
I0521 16:42:56.449587 28425 solver.cpp:253]     Train net output #0: loss = 1.12528 (* 1 = 1.12528 loss)
I0521 16:42:56.449601 28425 sgd_solver.cpp:106] Iteration 151500, lr = 0.0035
I0521 16:43:13.397267 28425 solver.cpp:237] Iteration 153000, loss = 1.18687
I0521 16:43:13.397313 28425 solver.cpp:253]     Train net output #0: loss = 1.18687 (* 1 = 1.18687 loss)
I0521 16:43:13.397330 28425 sgd_solver.cpp:106] Iteration 153000, lr = 0.0035
I0521 16:43:30.356089 28425 solver.cpp:237] Iteration 154500, loss = 0.776563
I0521 16:43:30.356252 28425 solver.cpp:253]     Train net output #0: loss = 0.776565 (* 1 = 0.776565 loss)
I0521 16:43:30.356266 28425 sgd_solver.cpp:106] Iteration 154500, lr = 0.0035
I0521 16:43:47.314424 28425 solver.cpp:237] Iteration 156000, loss = 1.28753
I0521 16:43:47.314460 28425 solver.cpp:253]     Train net output #0: loss = 1.28753 (* 1 = 1.28753 loss)
I0521 16:43:47.314476 28425 sgd_solver.cpp:106] Iteration 156000, lr = 0.0035
I0521 16:44:04.259985 28425 solver.cpp:237] Iteration 157500, loss = 1.2939
I0521 16:44:04.260161 28425 solver.cpp:253]     Train net output #0: loss = 1.2939 (* 1 = 1.2939 loss)
I0521 16:44:04.260175 28425 sgd_solver.cpp:106] Iteration 157500, lr = 0.0035
I0521 16:44:21.202703 28425 solver.cpp:237] Iteration 159000, loss = 1.34268
I0521 16:44:21.202755 28425 solver.cpp:253]     Train net output #0: loss = 1.34268 (* 1 = 1.34268 loss)
I0521 16:44:21.202769 28425 sgd_solver.cpp:106] Iteration 159000, lr = 0.0035
I0521 16:44:59.004037 28425 solver.cpp:237] Iteration 160500, loss = 1.05372
I0521 16:44:59.004210 28425 solver.cpp:253]     Train net output #0: loss = 1.05372 (* 1 = 1.05372 loss)
I0521 16:44:59.004225 28425 sgd_solver.cpp:106] Iteration 160500, lr = 0.0035
I0521 16:45:15.950978 28425 solver.cpp:237] Iteration 162000, loss = 1.02619
I0521 16:45:15.951027 28425 solver.cpp:253]     Train net output #0: loss = 1.02619 (* 1 = 1.02619 loss)
I0521 16:45:15.951043 28425 sgd_solver.cpp:106] Iteration 162000, lr = 0.0035
I0521 16:45:32.871732 28425 solver.cpp:237] Iteration 163500, loss = 1.80152
I0521 16:45:32.871901 28425 solver.cpp:253]     Train net output #0: loss = 1.80152 (* 1 = 1.80152 loss)
I0521 16:45:32.871915 28425 sgd_solver.cpp:106] Iteration 163500, lr = 0.0035
I0521 16:45:49.817581 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_165000.caffemodel
I0521 16:45:49.863682 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_165000.solverstate
I0521 16:45:49.892141 28425 solver.cpp:237] Iteration 165000, loss = 0.82067
I0521 16:45:49.892190 28425 solver.cpp:253]     Train net output #0: loss = 0.820671 (* 1 = 0.820671 loss)
I0521 16:45:49.892204 28425 sgd_solver.cpp:106] Iteration 165000, lr = 0.0035
I0521 16:46:06.826378 28425 solver.cpp:237] Iteration 166500, loss = 1.50427
I0521 16:46:06.826544 28425 solver.cpp:253]     Train net output #0: loss = 1.50428 (* 1 = 1.50428 loss)
I0521 16:46:06.826560 28425 sgd_solver.cpp:106] Iteration 166500, lr = 0.0035
I0521 16:46:23.795965 28425 solver.cpp:237] Iteration 168000, loss = 1.16582
I0521 16:46:23.796010 28425 solver.cpp:253]     Train net output #0: loss = 1.16582 (* 1 = 1.16582 loss)
I0521 16:46:23.796031 28425 sgd_solver.cpp:106] Iteration 168000, lr = 0.0035
I0521 16:46:40.754703 28425 solver.cpp:237] Iteration 169500, loss = 1.14188
I0521 16:46:40.754850 28425 solver.cpp:253]     Train net output #0: loss = 1.14188 (* 1 = 1.14188 loss)
I0521 16:46:40.754863 28425 sgd_solver.cpp:106] Iteration 169500, lr = 0.0035
I0521 16:47:18.423666 28425 solver.cpp:237] Iteration 171000, loss = 1.33903
I0521 16:47:18.423846 28425 solver.cpp:253]     Train net output #0: loss = 1.33903 (* 1 = 1.33903 loss)
I0521 16:47:18.423861 28425 sgd_solver.cpp:106] Iteration 171000, lr = 0.0035
I0521 16:47:35.169067 28425 solver.cpp:237] Iteration 172500, loss = 0.397035
I0521 16:47:35.169118 28425 solver.cpp:253]     Train net output #0: loss = 0.397037 (* 1 = 0.397037 loss)
I0521 16:47:35.169134 28425 sgd_solver.cpp:106] Iteration 172500, lr = 0.0035
I0521 16:47:51.924661 28425 solver.cpp:237] Iteration 174000, loss = 1.09057
I0521 16:47:51.924813 28425 solver.cpp:253]     Train net output #0: loss = 1.09058 (* 1 = 1.09058 loss)
I0521 16:47:51.924825 28425 sgd_solver.cpp:106] Iteration 174000, lr = 0.0035
I0521 16:48:08.676790 28425 solver.cpp:237] Iteration 175500, loss = 0.875105
I0521 16:48:08.676839 28425 solver.cpp:253]     Train net output #0: loss = 0.875109 (* 1 = 0.875109 loss)
I0521 16:48:08.676854 28425 sgd_solver.cpp:106] Iteration 175500, lr = 0.0035
I0521 16:48:25.436329 28425 solver.cpp:237] Iteration 177000, loss = 1.57127
I0521 16:48:25.436499 28425 solver.cpp:253]     Train net output #0: loss = 1.57127 (* 1 = 1.57127 loss)
I0521 16:48:25.436514 28425 sgd_solver.cpp:106] Iteration 177000, lr = 0.0035
I0521 16:48:42.189997 28425 solver.cpp:237] Iteration 178500, loss = 1.2527
I0521 16:48:42.190032 28425 solver.cpp:253]     Train net output #0: loss = 1.2527 (* 1 = 1.2527 loss)
I0521 16:48:42.190047 28425 sgd_solver.cpp:106] Iteration 178500, lr = 0.0035
I0521 16:48:58.963410 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_180000.caffemodel
I0521 16:48:59.009528 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_180000.solverstate
I0521 16:48:59.035274 28425 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 16:50:19.353755 28425 solver.cpp:409]     Test net output #0: accuracy = 0.884661
I0521 16:50:19.353914 28425 solver.cpp:409]     Test net output #1: loss = 0.379784 (* 1 = 0.379784 loss)
I0521 16:50:40.245401 28425 solver.cpp:237] Iteration 180000, loss = 1.4543
I0521 16:50:40.245457 28425 solver.cpp:253]     Train net output #0: loss = 1.4543 (* 1 = 1.4543 loss)
I0521 16:50:40.245471 28425 sgd_solver.cpp:106] Iteration 180000, lr = 0.0035
I0521 16:50:57.407696 28425 solver.cpp:237] Iteration 181500, loss = 1.23902
I0521 16:50:57.407876 28425 solver.cpp:253]     Train net output #0: loss = 1.23902 (* 1 = 1.23902 loss)
I0521 16:50:57.407889 28425 sgd_solver.cpp:106] Iteration 181500, lr = 0.0035
I0521 16:51:14.579762 28425 solver.cpp:237] Iteration 183000, loss = 0.94264
I0521 16:51:14.579800 28425 solver.cpp:253]     Train net output #0: loss = 0.942641 (* 1 = 0.942641 loss)
I0521 16:51:14.579816 28425 sgd_solver.cpp:106] Iteration 183000, lr = 0.0035
I0521 16:51:31.710865 28425 solver.cpp:237] Iteration 184500, loss = 1.05471
I0521 16:51:31.711027 28425 solver.cpp:253]     Train net output #0: loss = 1.05471 (* 1 = 1.05471 loss)
I0521 16:51:31.711041 28425 sgd_solver.cpp:106] Iteration 184500, lr = 0.0035
I0521 16:51:48.888417 28425 solver.cpp:237] Iteration 186000, loss = 1.13043
I0521 16:51:48.888460 28425 solver.cpp:253]     Train net output #0: loss = 1.13043 (* 1 = 1.13043 loss)
I0521 16:51:48.888478 28425 sgd_solver.cpp:106] Iteration 186000, lr = 0.0035
I0521 16:52:06.069253 28425 solver.cpp:237] Iteration 187500, loss = 1.57649
I0521 16:52:06.069401 28425 solver.cpp:253]     Train net output #0: loss = 1.57649 (* 1 = 1.57649 loss)
I0521 16:52:06.069416 28425 sgd_solver.cpp:106] Iteration 187500, lr = 0.0035
I0521 16:52:23.231792 28425 solver.cpp:237] Iteration 189000, loss = 0.547147
I0521 16:52:23.231856 28425 solver.cpp:253]     Train net output #0: loss = 0.547149 (* 1 = 0.547149 loss)
I0521 16:52:23.231871 28425 sgd_solver.cpp:106] Iteration 189000, lr = 0.0035
I0521 16:53:01.273180 28425 solver.cpp:237] Iteration 190500, loss = 1.43631
I0521 16:53:01.273363 28425 solver.cpp:253]     Train net output #0: loss = 1.43632 (* 1 = 1.43632 loss)
I0521 16:53:01.273377 28425 sgd_solver.cpp:106] Iteration 190500, lr = 0.0035
I0521 16:53:18.445000 28425 solver.cpp:237] Iteration 192000, loss = 1.00968
I0521 16:53:18.445036 28425 solver.cpp:253]     Train net output #0: loss = 1.00969 (* 1 = 1.00969 loss)
I0521 16:53:18.445052 28425 sgd_solver.cpp:106] Iteration 192000, lr = 0.0035
I0521 16:53:35.610605 28425 solver.cpp:237] Iteration 193500, loss = 1.15203
I0521 16:53:35.610764 28425 solver.cpp:253]     Train net output #0: loss = 1.15203 (* 1 = 1.15203 loss)
I0521 16:53:35.610777 28425 sgd_solver.cpp:106] Iteration 193500, lr = 0.0035
I0521 16:53:52.789544 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_195000.caffemodel
I0521 16:53:52.835927 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_195000.solverstate
I0521 16:53:52.864864 28425 solver.cpp:237] Iteration 195000, loss = 1.13376
I0521 16:53:52.864912 28425 solver.cpp:253]     Train net output #0: loss = 1.13376 (* 1 = 1.13376 loss)
I0521 16:53:52.864926 28425 sgd_solver.cpp:106] Iteration 195000, lr = 0.0035
I0521 16:54:10.039970 28425 solver.cpp:237] Iteration 196500, loss = 2.23137
I0521 16:54:10.040135 28425 solver.cpp:253]     Train net output #0: loss = 2.23137 (* 1 = 2.23137 loss)
I0521 16:54:10.040149 28425 sgd_solver.cpp:106] Iteration 196500, lr = 0.0035
I0521 16:54:27.215064 28425 solver.cpp:237] Iteration 198000, loss = 1.2776
I0521 16:54:27.215108 28425 solver.cpp:253]     Train net output #0: loss = 1.2776 (* 1 = 1.2776 loss)
I0521 16:54:27.215124 28425 sgd_solver.cpp:106] Iteration 198000, lr = 0.0035
I0521 16:54:44.087453 28425 solver.cpp:237] Iteration 199500, loss = 0.916444
I0521 16:54:44.087621 28425 solver.cpp:253]     Train net output #0: loss = 0.916444 (* 1 = 0.916444 loss)
I0521 16:54:44.087635 28425 sgd_solver.cpp:106] Iteration 199500, lr = 0.0035
I0521 16:55:21.776952 28425 solver.cpp:237] Iteration 201000, loss = 1.3582
I0521 16:55:21.777132 28425 solver.cpp:253]     Train net output #0: loss = 1.3582 (* 1 = 1.3582 loss)
I0521 16:55:21.777145 28425 sgd_solver.cpp:106] Iteration 201000, lr = 0.0035
I0521 16:55:38.711765 28425 solver.cpp:237] Iteration 202500, loss = 1.28224
I0521 16:55:38.711814 28425 solver.cpp:253]     Train net output #0: loss = 1.28224 (* 1 = 1.28224 loss)
I0521 16:55:38.711835 28425 sgd_solver.cpp:106] Iteration 202500, lr = 0.0035
I0521 16:55:55.591065 28425 solver.cpp:237] Iteration 204000, loss = 1.16289
I0521 16:55:55.591233 28425 solver.cpp:253]     Train net output #0: loss = 1.16289 (* 1 = 1.16289 loss)
I0521 16:55:55.591246 28425 sgd_solver.cpp:106] Iteration 204000, lr = 0.0035
I0521 16:56:12.414041 28425 solver.cpp:237] Iteration 205500, loss = 0.922778
I0521 16:56:12.414077 28425 solver.cpp:253]     Train net output #0: loss = 0.92278 (* 1 = 0.92278 loss)
I0521 16:56:12.414091 28425 sgd_solver.cpp:106] Iteration 205500, lr = 0.0035
I0521 16:56:29.241498 28425 solver.cpp:237] Iteration 207000, loss = 1.36835
I0521 16:56:29.241668 28425 solver.cpp:253]     Train net output #0: loss = 1.36836 (* 1 = 1.36836 loss)
I0521 16:56:29.241683 28425 sgd_solver.cpp:106] Iteration 207000, lr = 0.0035
I0521 16:56:46.093201 28425 solver.cpp:237] Iteration 208500, loss = 1.00034
I0521 16:56:46.093248 28425 solver.cpp:253]     Train net output #0: loss = 1.00034 (* 1 = 1.00034 loss)
I0521 16:56:46.093266 28425 sgd_solver.cpp:106] Iteration 208500, lr = 0.0035
I0521 16:57:03.016639 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_210000.caffemodel
I0521 16:57:03.062810 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_210000.solverstate
I0521 16:57:03.088452 28425 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 16:58:02.384654 28425 solver.cpp:409]     Test net output #0: accuracy = 0.881881
I0521 16:58:02.384825 28425 solver.cpp:409]     Test net output #1: loss = 0.404713 (* 1 = 0.404713 loss)
I0521 16:58:23.280658 28425 solver.cpp:237] Iteration 210000, loss = 0.975162
I0521 16:58:23.280717 28425 solver.cpp:253]     Train net output #0: loss = 0.975163 (* 1 = 0.975163 loss)
I0521 16:58:23.280732 28425 sgd_solver.cpp:106] Iteration 210000, lr = 0.0035
I0521 16:58:39.864076 28425 solver.cpp:237] Iteration 211500, loss = 1.13484
I0521 16:58:39.864243 28425 solver.cpp:253]     Train net output #0: loss = 1.13485 (* 1 = 1.13485 loss)
I0521 16:58:39.864256 28425 sgd_solver.cpp:106] Iteration 211500, lr = 0.0035
I0521 16:58:56.491376 28425 solver.cpp:237] Iteration 213000, loss = 0.985686
I0521 16:58:56.491430 28425 solver.cpp:253]     Train net output #0: loss = 0.985688 (* 1 = 0.985688 loss)
I0521 16:58:56.491443 28425 sgd_solver.cpp:106] Iteration 213000, lr = 0.0035
I0521 16:59:13.118777 28425 solver.cpp:237] Iteration 214500, loss = 1.49416
I0521 16:59:13.118934 28425 solver.cpp:253]     Train net output #0: loss = 1.49416 (* 1 = 1.49416 loss)
I0521 16:59:13.118948 28425 sgd_solver.cpp:106] Iteration 214500, lr = 0.0035
I0521 16:59:29.715718 28425 solver.cpp:237] Iteration 216000, loss = 1.07788
I0521 16:59:29.715762 28425 solver.cpp:253]     Train net output #0: loss = 1.07788 (* 1 = 1.07788 loss)
I0521 16:59:29.715780 28425 sgd_solver.cpp:106] Iteration 216000, lr = 0.0035
I0521 16:59:46.307160 28425 solver.cpp:237] Iteration 217500, loss = 0.950777
I0521 16:59:46.307335 28425 solver.cpp:253]     Train net output #0: loss = 0.950778 (* 1 = 0.950778 loss)
I0521 16:59:46.307349 28425 sgd_solver.cpp:106] Iteration 217500, lr = 0.0035
I0521 17:00:02.907106 28425 solver.cpp:237] Iteration 219000, loss = 0.983706
I0521 17:00:02.907142 28425 solver.cpp:253]     Train net output #0: loss = 0.983706 (* 1 = 0.983706 loss)
I0521 17:00:02.907160 28425 sgd_solver.cpp:106] Iteration 219000, lr = 0.0035
I0521 17:00:40.393306 28425 solver.cpp:237] Iteration 220500, loss = 1.16496
I0521 17:00:40.393488 28425 solver.cpp:253]     Train net output #0: loss = 1.16496 (* 1 = 1.16496 loss)
I0521 17:00:40.393502 28425 sgd_solver.cpp:106] Iteration 220500, lr = 0.0035
I0521 17:00:57.019606 28425 solver.cpp:237] Iteration 222000, loss = 0.949408
I0521 17:00:57.019656 28425 solver.cpp:253]     Train net output #0: loss = 0.949408 (* 1 = 0.949408 loss)
I0521 17:00:57.019672 28425 sgd_solver.cpp:106] Iteration 222000, lr = 0.0035
I0521 17:01:13.600214 28425 solver.cpp:237] Iteration 223500, loss = 1.613
I0521 17:01:13.600368 28425 solver.cpp:253]     Train net output #0: loss = 1.613 (* 1 = 1.613 loss)
I0521 17:01:13.600380 28425 sgd_solver.cpp:106] Iteration 223500, lr = 0.0035
I0521 17:01:30.195981 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_225000.caffemodel
I0521 17:01:30.244191 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_225000.solverstate
I0521 17:01:30.275099 28425 solver.cpp:237] Iteration 225000, loss = 0.999439
I0521 17:01:30.275152 28425 solver.cpp:253]     Train net output #0: loss = 0.999438 (* 1 = 0.999438 loss)
I0521 17:01:30.275167 28425 sgd_solver.cpp:106] Iteration 225000, lr = 0.0035
I0521 17:01:46.902029 28425 solver.cpp:237] Iteration 226500, loss = 1.95712
I0521 17:01:46.902214 28425 solver.cpp:253]     Train net output #0: loss = 1.95712 (* 1 = 1.95712 loss)
I0521 17:01:46.902227 28425 sgd_solver.cpp:106] Iteration 226500, lr = 0.0035
I0521 17:02:03.485209 28425 solver.cpp:237] Iteration 228000, loss = 1.23551
I0521 17:02:03.485246 28425 solver.cpp:253]     Train net output #0: loss = 1.23551 (* 1 = 1.23551 loss)
I0521 17:02:03.485263 28425 sgd_solver.cpp:106] Iteration 228000, lr = 0.0035
I0521 17:02:20.076483 28425 solver.cpp:237] Iteration 229500, loss = 0.634318
I0521 17:02:20.076644 28425 solver.cpp:253]     Train net output #0: loss = 0.634316 (* 1 = 0.634316 loss)
I0521 17:02:20.076658 28425 sgd_solver.cpp:106] Iteration 229500, lr = 0.0035
I0521 17:02:57.533896 28425 solver.cpp:237] Iteration 231000, loss = 0.968357
I0521 17:02:57.534080 28425 solver.cpp:253]     Train net output #0: loss = 0.968355 (* 1 = 0.968355 loss)
I0521 17:02:57.534096 28425 sgd_solver.cpp:106] Iteration 231000, lr = 0.0035
I0521 17:03:14.162091 28425 solver.cpp:237] Iteration 232500, loss = 0.476994
I0521 17:03:14.162140 28425 solver.cpp:253]     Train net output #0: loss = 0.476992 (* 1 = 0.476992 loss)
I0521 17:03:14.162154 28425 sgd_solver.cpp:106] Iteration 232500, lr = 0.0035
I0521 17:03:30.743805 28425 solver.cpp:237] Iteration 234000, loss = 0.838341
I0521 17:03:30.743979 28425 solver.cpp:253]     Train net output #0: loss = 0.838339 (* 1 = 0.838339 loss)
I0521 17:03:30.743994 28425 sgd_solver.cpp:106] Iteration 234000, lr = 0.0035
I0521 17:03:47.345214 28425 solver.cpp:237] Iteration 235500, loss = 1.77126
I0521 17:03:47.345249 28425 solver.cpp:253]     Train net output #0: loss = 1.77126 (* 1 = 1.77126 loss)
I0521 17:03:47.345266 28425 sgd_solver.cpp:106] Iteration 235500, lr = 0.0035
I0521 17:04:03.904657 28425 solver.cpp:237] Iteration 237000, loss = 1.47489
I0521 17:04:03.904835 28425 solver.cpp:253]     Train net output #0: loss = 1.47489 (* 1 = 1.47489 loss)
I0521 17:04:03.904850 28425 sgd_solver.cpp:106] Iteration 237000, lr = 0.0035
I0521 17:04:20.489972 28425 solver.cpp:237] Iteration 238500, loss = 1.14826
I0521 17:04:20.490016 28425 solver.cpp:253]     Train net output #0: loss = 1.14826 (* 1 = 1.14826 loss)
I0521 17:04:20.490036 28425 sgd_solver.cpp:106] Iteration 238500, lr = 0.0035
I0521 17:04:37.073845 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_240000.caffemodel
I0521 17:04:37.137562 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_240000.solverstate
I0521 17:04:37.163187 28425 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 17:05:57.351549 28425 solver.cpp:409]     Test net output #0: accuracy = 0.885074
I0521 17:05:57.351742 28425 solver.cpp:409]     Test net output #1: loss = 0.376227 (* 1 = 0.376227 loss)
I0521 17:06:18.210532 28425 solver.cpp:237] Iteration 240000, loss = 0.439906
I0521 17:06:18.210590 28425 solver.cpp:253]     Train net output #0: loss = 0.439903 (* 1 = 0.439903 loss)
I0521 17:06:18.210605 28425 sgd_solver.cpp:106] Iteration 240000, lr = 0.0035
I0521 17:06:35.169939 28425 solver.cpp:237] Iteration 241500, loss = 1.74206
I0521 17:06:35.170105 28425 solver.cpp:253]     Train net output #0: loss = 1.74206 (* 1 = 1.74206 loss)
I0521 17:06:35.170120 28425 sgd_solver.cpp:106] Iteration 241500, lr = 0.0035
I0521 17:06:52.134400 28425 solver.cpp:237] Iteration 243000, loss = 0.94972
I0521 17:06:52.134451 28425 solver.cpp:253]     Train net output #0: loss = 0.949717 (* 1 = 0.949717 loss)
I0521 17:06:52.134465 28425 sgd_solver.cpp:106] Iteration 243000, lr = 0.0035
I0521 17:07:09.060308 28425 solver.cpp:237] Iteration 244500, loss = 1.46572
I0521 17:07:09.060475 28425 solver.cpp:253]     Train net output #0: loss = 1.46572 (* 1 = 1.46572 loss)
I0521 17:07:09.060489 28425 sgd_solver.cpp:106] Iteration 244500, lr = 0.0035
I0521 17:07:26.004962 28425 solver.cpp:237] Iteration 246000, loss = 0.812115
I0521 17:07:26.005005 28425 solver.cpp:253]     Train net output #0: loss = 0.812112 (* 1 = 0.812112 loss)
I0521 17:07:26.005022 28425 sgd_solver.cpp:106] Iteration 246000, lr = 0.0035
I0521 17:07:42.963034 28425 solver.cpp:237] Iteration 247500, loss = 0.952155
I0521 17:07:42.963206 28425 solver.cpp:253]     Train net output #0: loss = 0.952152 (* 1 = 0.952152 loss)
I0521 17:07:42.963220 28425 sgd_solver.cpp:106] Iteration 247500, lr = 0.0035
I0521 17:07:59.914197 28425 solver.cpp:237] Iteration 249000, loss = 1.04638
I0521 17:07:59.914247 28425 solver.cpp:253]     Train net output #0: loss = 1.04638 (* 1 = 1.04638 loss)
I0521 17:07:59.914265 28425 sgd_solver.cpp:106] Iteration 249000, lr = 0.0035
I0521 17:08:37.728364 28425 solver.cpp:237] Iteration 250500, loss = 0.896236
I0521 17:08:37.728548 28425 solver.cpp:253]     Train net output #0: loss = 0.896233 (* 1 = 0.896233 loss)
I0521 17:08:37.728564 28425 sgd_solver.cpp:106] Iteration 250500, lr = 0.0035
I0521 17:08:54.636134 28425 solver.cpp:237] Iteration 252000, loss = 1.0511
I0521 17:08:54.636188 28425 solver.cpp:253]     Train net output #0: loss = 1.0511 (* 1 = 1.0511 loss)
I0521 17:08:54.636204 28425 sgd_solver.cpp:106] Iteration 252000, lr = 0.0035
I0521 17:09:11.454694 28425 solver.cpp:237] Iteration 253500, loss = 0.912504
I0521 17:09:11.454849 28425 solver.cpp:253]     Train net output #0: loss = 0.912502 (* 1 = 0.912502 loss)
I0521 17:09:11.454864 28425 sgd_solver.cpp:106] Iteration 253500, lr = 0.0035
I0521 17:09:28.329294 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_255000.caffemodel
I0521 17:09:28.375195 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_255000.solverstate
I0521 17:09:28.403918 28425 solver.cpp:237] Iteration 255000, loss = 0.848784
I0521 17:09:28.403962 28425 solver.cpp:253]     Train net output #0: loss = 0.848781 (* 1 = 0.848781 loss)
I0521 17:09:28.403985 28425 sgd_solver.cpp:106] Iteration 255000, lr = 0.0035
I0521 17:09:45.255508 28425 solver.cpp:237] Iteration 256500, loss = 1.25396
I0521 17:09:45.255691 28425 solver.cpp:253]     Train net output #0: loss = 1.25396 (* 1 = 1.25396 loss)
I0521 17:09:45.255704 28425 sgd_solver.cpp:106] Iteration 256500, lr = 0.0035
I0521 17:10:02.096639 28425 solver.cpp:237] Iteration 258000, loss = 1.13293
I0521 17:10:02.096676 28425 solver.cpp:253]     Train net output #0: loss = 1.13293 (* 1 = 1.13293 loss)
I0521 17:10:02.096693 28425 sgd_solver.cpp:106] Iteration 258000, lr = 0.0035
I0521 17:10:18.922718 28425 solver.cpp:237] Iteration 259500, loss = 1.01532
I0521 17:10:18.922890 28425 solver.cpp:253]     Train net output #0: loss = 1.01532 (* 1 = 1.01532 loss)
I0521 17:10:18.922904 28425 sgd_solver.cpp:106] Iteration 259500, lr = 0.0035
I0521 17:10:56.588407 28425 solver.cpp:237] Iteration 261000, loss = 1.12099
I0521 17:10:56.588587 28425 solver.cpp:253]     Train net output #0: loss = 1.12098 (* 1 = 1.12098 loss)
I0521 17:10:56.588601 28425 sgd_solver.cpp:106] Iteration 261000, lr = 0.0035
I0521 17:11:13.498682 28425 solver.cpp:237] Iteration 262500, loss = 1.78221
I0521 17:11:13.498718 28425 solver.cpp:253]     Train net output #0: loss = 1.78221 (* 1 = 1.78221 loss)
I0521 17:11:13.498733 28425 sgd_solver.cpp:106] Iteration 262500, lr = 0.0035
I0521 17:11:30.301833 28425 solver.cpp:237] Iteration 264000, loss = 1.91099
I0521 17:11:30.302007 28425 solver.cpp:253]     Train net output #0: loss = 1.91099 (* 1 = 1.91099 loss)
I0521 17:11:30.302021 28425 sgd_solver.cpp:106] Iteration 264000, lr = 0.0035
I0521 17:11:47.181401 28425 solver.cpp:237] Iteration 265500, loss = 1.32288
I0521 17:11:47.181453 28425 solver.cpp:253]     Train net output #0: loss = 1.32287 (* 1 = 1.32287 loss)
I0521 17:11:47.181469 28425 sgd_solver.cpp:106] Iteration 265500, lr = 0.0035
I0521 17:12:04.071189 28425 solver.cpp:237] Iteration 267000, loss = 0.965291
I0521 17:12:04.071347 28425 solver.cpp:253]     Train net output #0: loss = 0.965288 (* 1 = 0.965288 loss)
I0521 17:12:04.071362 28425 sgd_solver.cpp:106] Iteration 267000, lr = 0.0035
I0521 17:12:20.948969 28425 solver.cpp:237] Iteration 268500, loss = 1.64292
I0521 17:12:20.949020 28425 solver.cpp:253]     Train net output #0: loss = 1.64292 (* 1 = 1.64292 loss)
I0521 17:12:20.949034 28425 sgd_solver.cpp:106] Iteration 268500, lr = 0.0035
I0521 17:12:37.751906 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_270000.caffemodel
I0521 17:12:37.797257 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_270000.solverstate
I0521 17:12:37.822736 28425 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 17:13:37.379397 28425 solver.cpp:409]     Test net output #0: accuracy = 0.883822
I0521 17:13:37.379572 28425 solver.cpp:409]     Test net output #1: loss = 0.355774 (* 1 = 0.355774 loss)
I0521 17:13:58.251651 28425 solver.cpp:237] Iteration 270000, loss = 1.83081
I0521 17:13:58.251706 28425 solver.cpp:253]     Train net output #0: loss = 1.83081 (* 1 = 1.83081 loss)
I0521 17:13:58.251721 28425 sgd_solver.cpp:106] Iteration 270000, lr = 0.0035
I0521 17:14:15.274463 28425 solver.cpp:237] Iteration 271500, loss = 2.11671
I0521 17:14:15.274643 28425 solver.cpp:253]     Train net output #0: loss = 2.11671 (* 1 = 2.11671 loss)
I0521 17:14:15.274657 28425 sgd_solver.cpp:106] Iteration 271500, lr = 0.0035
I0521 17:14:32.311573 28425 solver.cpp:237] Iteration 273000, loss = 1.14649
I0521 17:14:32.311609 28425 solver.cpp:253]     Train net output #0: loss = 1.14649 (* 1 = 1.14649 loss)
I0521 17:14:32.311625 28425 sgd_solver.cpp:106] Iteration 273000, lr = 0.0035
I0521 17:14:49.370479 28425 solver.cpp:237] Iteration 274500, loss = 0.993632
I0521 17:14:49.370651 28425 solver.cpp:253]     Train net output #0: loss = 0.993629 (* 1 = 0.993629 loss)
I0521 17:14:49.370666 28425 sgd_solver.cpp:106] Iteration 274500, lr = 0.0035
I0521 17:15:06.404657 28425 solver.cpp:237] Iteration 276000, loss = 0.270152
I0521 17:15:06.404706 28425 solver.cpp:253]     Train net output #0: loss = 0.270149 (* 1 = 0.270149 loss)
I0521 17:15:06.404718 28425 sgd_solver.cpp:106] Iteration 276000, lr = 0.0035
I0521 17:15:23.408663 28425 solver.cpp:237] Iteration 277500, loss = 1.13158
I0521 17:15:23.408819 28425 solver.cpp:253]     Train net output #0: loss = 1.13158 (* 1 = 1.13158 loss)
I0521 17:15:23.408833 28425 sgd_solver.cpp:106] Iteration 277500, lr = 0.0035
I0521 17:15:40.425032 28425 solver.cpp:237] Iteration 279000, loss = 1.085
I0521 17:15:40.425082 28425 solver.cpp:253]     Train net output #0: loss = 1.08499 (* 1 = 1.08499 loss)
I0521 17:15:40.425096 28425 sgd_solver.cpp:106] Iteration 279000, lr = 0.0035
I0521 17:16:18.296241 28425 solver.cpp:237] Iteration 280500, loss = 0.984651
I0521 17:16:18.296422 28425 solver.cpp:253]     Train net output #0: loss = 0.984647 (* 1 = 0.984647 loss)
I0521 17:16:18.296437 28425 sgd_solver.cpp:106] Iteration 280500, lr = 0.0035
I0521 17:16:35.308696 28425 solver.cpp:237] Iteration 282000, loss = 1.2673
I0521 17:16:35.308745 28425 solver.cpp:253]     Train net output #0: loss = 1.2673 (* 1 = 1.2673 loss)
I0521 17:16:35.308761 28425 sgd_solver.cpp:106] Iteration 282000, lr = 0.0035
I0521 17:16:52.341001 28425 solver.cpp:237] Iteration 283500, loss = 0.619132
I0521 17:16:52.341171 28425 solver.cpp:253]     Train net output #0: loss = 0.619127 (* 1 = 0.619127 loss)
I0521 17:16:52.341186 28425 sgd_solver.cpp:106] Iteration 283500, lr = 0.0035
I0521 17:17:09.368537 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_285000.caffemodel
I0521 17:17:09.415997 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_285000.solverstate
I0521 17:17:09.446702 28425 solver.cpp:237] Iteration 285000, loss = 1.16142
I0521 17:17:09.446751 28425 solver.cpp:253]     Train net output #0: loss = 1.16141 (* 1 = 1.16141 loss)
I0521 17:17:09.446768 28425 sgd_solver.cpp:106] Iteration 285000, lr = 0.0035
I0521 17:17:26.497803 28425 solver.cpp:237] Iteration 286500, loss = 0.808533
I0521 17:17:26.497966 28425 solver.cpp:253]     Train net output #0: loss = 0.808529 (* 1 = 0.808529 loss)
I0521 17:17:26.497980 28425 sgd_solver.cpp:106] Iteration 286500, lr = 0.0035
I0521 17:17:43.541393 28425 solver.cpp:237] Iteration 288000, loss = 2.05971
I0521 17:17:43.541448 28425 solver.cpp:253]     Train net output #0: loss = 2.0597 (* 1 = 2.0597 loss)
I0521 17:17:43.541463 28425 sgd_solver.cpp:106] Iteration 288000, lr = 0.0035
I0521 17:18:00.568326 28425 solver.cpp:237] Iteration 289500, loss = 1.14746
I0521 17:18:00.568502 28425 solver.cpp:253]     Train net output #0: loss = 1.14745 (* 1 = 1.14745 loss)
I0521 17:18:00.568516 28425 sgd_solver.cpp:106] Iteration 289500, lr = 0.0035
I0521 17:18:38.432847 28425 solver.cpp:237] Iteration 291000, loss = 1.15171
I0521 17:18:38.433032 28425 solver.cpp:253]     Train net output #0: loss = 1.1517 (* 1 = 1.1517 loss)
I0521 17:18:38.433046 28425 sgd_solver.cpp:106] Iteration 291000, lr = 0.0035
I0521 17:18:55.480317 28425 solver.cpp:237] Iteration 292500, loss = 1.83405
I0521 17:18:55.480370 28425 solver.cpp:253]     Train net output #0: loss = 1.83405 (* 1 = 1.83405 loss)
I0521 17:18:55.480386 28425 sgd_solver.cpp:106] Iteration 292500, lr = 0.0035
I0521 17:19:12.480957 28425 solver.cpp:237] Iteration 294000, loss = 0.69147
I0521 17:19:12.481138 28425 solver.cpp:253]     Train net output #0: loss = 0.691466 (* 1 = 0.691466 loss)
I0521 17:19:12.481153 28425 sgd_solver.cpp:106] Iteration 294000, lr = 0.0035
I0521 17:19:29.534276 28425 solver.cpp:237] Iteration 295500, loss = 1.87753
I0521 17:19:29.534329 28425 solver.cpp:253]     Train net output #0: loss = 1.87752 (* 1 = 1.87752 loss)
I0521 17:19:29.534345 28425 sgd_solver.cpp:106] Iteration 295500, lr = 0.0035
I0521 17:19:46.573392 28425 solver.cpp:237] Iteration 297000, loss = 1.72006
I0521 17:19:46.573568 28425 solver.cpp:253]     Train net output #0: loss = 1.72006 (* 1 = 1.72006 loss)
I0521 17:19:46.573583 28425 sgd_solver.cpp:106] Iteration 297000, lr = 0.0035
I0521 17:20:03.569496 28425 solver.cpp:237] Iteration 298500, loss = 1.08885
I0521 17:20:03.569532 28425 solver.cpp:253]     Train net output #0: loss = 1.08884 (* 1 = 1.08884 loss)
I0521 17:20:03.569548 28425 sgd_solver.cpp:106] Iteration 298500, lr = 0.0035
I0521 17:20:20.589825 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_300000.caffemodel
I0521 17:20:20.638288 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_300000.solverstate
I0521 17:20:20.665771 28425 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 17:21:41.123271 28425 solver.cpp:409]     Test net output #0: accuracy = 0.887681
I0521 17:21:41.123453 28425 solver.cpp:409]     Test net output #1: loss = 0.361865 (* 1 = 0.361865 loss)
I0521 17:22:01.968821 28425 solver.cpp:237] Iteration 300000, loss = 1.14349
I0521 17:22:01.968875 28425 solver.cpp:253]     Train net output #0: loss = 1.14349 (* 1 = 1.14349 loss)
I0521 17:22:01.968890 28425 sgd_solver.cpp:106] Iteration 300000, lr = 0.0035
I0521 17:22:18.904520 28425 solver.cpp:237] Iteration 301500, loss = 1.04317
I0521 17:22:18.904700 28425 solver.cpp:253]     Train net output #0: loss = 1.04317 (* 1 = 1.04317 loss)
I0521 17:22:18.904714 28425 sgd_solver.cpp:106] Iteration 301500, lr = 0.0035
I0521 17:22:36.074194 28425 solver.cpp:237] Iteration 303000, loss = 1.76298
I0521 17:22:36.074244 28425 solver.cpp:253]     Train net output #0: loss = 1.76297 (* 1 = 1.76297 loss)
I0521 17:22:36.074262 28425 sgd_solver.cpp:106] Iteration 303000, lr = 0.0035
I0521 17:22:53.258101 28425 solver.cpp:237] Iteration 304500, loss = 1.19676
I0521 17:22:53.258258 28425 solver.cpp:253]     Train net output #0: loss = 1.19676 (* 1 = 1.19676 loss)
I0521 17:22:53.258271 28425 sgd_solver.cpp:106] Iteration 304500, lr = 0.0035
I0521 17:23:10.446686 28425 solver.cpp:237] Iteration 306000, loss = 0.753451
I0521 17:23:10.446737 28425 solver.cpp:253]     Train net output #0: loss = 0.753446 (* 1 = 0.753446 loss)
I0521 17:23:10.446750 28425 sgd_solver.cpp:106] Iteration 306000, lr = 0.0035
I0521 17:23:27.587447 28425 solver.cpp:237] Iteration 307500, loss = 1.12758
I0521 17:23:27.587618 28425 solver.cpp:253]     Train net output #0: loss = 1.12757 (* 1 = 1.12757 loss)
I0521 17:23:27.587631 28425 sgd_solver.cpp:106] Iteration 307500, lr = 0.0035
I0521 17:23:44.760766 28425 solver.cpp:237] Iteration 309000, loss = 1.53259
I0521 17:23:44.760800 28425 solver.cpp:253]     Train net output #0: loss = 1.53259 (* 1 = 1.53259 loss)
I0521 17:23:44.760818 28425 sgd_solver.cpp:106] Iteration 309000, lr = 0.0035
I0521 17:24:22.778591 28425 solver.cpp:237] Iteration 310500, loss = 0.929309
I0521 17:24:22.778776 28425 solver.cpp:253]     Train net output #0: loss = 0.929306 (* 1 = 0.929306 loss)
I0521 17:24:22.778791 28425 sgd_solver.cpp:106] Iteration 310500, lr = 0.0035
I0521 17:24:39.939693 28425 solver.cpp:237] Iteration 312000, loss = 1.01725
I0521 17:24:39.939740 28425 solver.cpp:253]     Train net output #0: loss = 1.01725 (* 1 = 1.01725 loss)
I0521 17:24:39.939759 28425 sgd_solver.cpp:106] Iteration 312000, lr = 0.0035
I0521 17:24:57.112471 28425 solver.cpp:237] Iteration 313500, loss = 1.37346
I0521 17:24:57.112637 28425 solver.cpp:253]     Train net output #0: loss = 1.37346 (* 1 = 1.37346 loss)
I0521 17:24:57.112650 28425 sgd_solver.cpp:106] Iteration 313500, lr = 0.0035
I0521 17:25:14.292744 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_315000.caffemodel
I0521 17:25:14.339249 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_315000.solverstate
I0521 17:25:14.367547 28425 solver.cpp:237] Iteration 315000, loss = 0.896792
I0521 17:25:14.367597 28425 solver.cpp:253]     Train net output #0: loss = 0.896789 (* 1 = 0.896789 loss)
I0521 17:25:14.367615 28425 sgd_solver.cpp:106] Iteration 315000, lr = 0.0035
I0521 17:25:31.536749 28425 solver.cpp:237] Iteration 316500, loss = 1.15495
I0521 17:25:31.536931 28425 solver.cpp:253]     Train net output #0: loss = 1.15495 (* 1 = 1.15495 loss)
I0521 17:25:31.536945 28425 sgd_solver.cpp:106] Iteration 316500, lr = 0.0035
I0521 17:25:48.699787 28425 solver.cpp:237] Iteration 318000, loss = 1.63104
I0521 17:25:48.699823 28425 solver.cpp:253]     Train net output #0: loss = 1.63104 (* 1 = 1.63104 loss)
I0521 17:25:48.699844 28425 sgd_solver.cpp:106] Iteration 318000, lr = 0.0035
I0521 17:26:05.867051 28425 solver.cpp:237] Iteration 319500, loss = 1.33445
I0521 17:26:05.867223 28425 solver.cpp:253]     Train net output #0: loss = 1.33445 (* 1 = 1.33445 loss)
I0521 17:26:05.867236 28425 sgd_solver.cpp:106] Iteration 319500, lr = 0.0035
I0521 17:26:43.851022 28425 solver.cpp:237] Iteration 321000, loss = 1.07878
I0521 17:26:43.851204 28425 solver.cpp:253]     Train net output #0: loss = 1.07877 (* 1 = 1.07877 loss)
I0521 17:26:43.851219 28425 sgd_solver.cpp:106] Iteration 321000, lr = 0.0035
I0521 17:27:01.041867 28425 solver.cpp:237] Iteration 322500, loss = 1.01361
I0521 17:27:01.041911 28425 solver.cpp:253]     Train net output #0: loss = 1.01361 (* 1 = 1.01361 loss)
I0521 17:27:01.041926 28425 sgd_solver.cpp:106] Iteration 322500, lr = 0.0035
I0521 17:27:18.212841 28425 solver.cpp:237] Iteration 324000, loss = 1.35077
I0521 17:27:18.213019 28425 solver.cpp:253]     Train net output #0: loss = 1.35076 (* 1 = 1.35076 loss)
I0521 17:27:18.213034 28425 sgd_solver.cpp:106] Iteration 324000, lr = 0.0035
I0521 17:27:35.366950 28425 solver.cpp:237] Iteration 325500, loss = 1.4528
I0521 17:27:35.366996 28425 solver.cpp:253]     Train net output #0: loss = 1.4528 (* 1 = 1.4528 loss)
I0521 17:27:35.367012 28425 sgd_solver.cpp:106] Iteration 325500, lr = 0.0035
I0521 17:27:52.563063 28425 solver.cpp:237] Iteration 327000, loss = 1.36055
I0521 17:27:52.563233 28425 solver.cpp:253]     Train net output #0: loss = 1.36055 (* 1 = 1.36055 loss)
I0521 17:27:52.563246 28425 sgd_solver.cpp:106] Iteration 327000, lr = 0.0035
I0521 17:28:09.770939 28425 solver.cpp:237] Iteration 328500, loss = 0.924508
I0521 17:28:09.770989 28425 solver.cpp:253]     Train net output #0: loss = 0.924504 (* 1 = 0.924504 loss)
I0521 17:28:09.771004 28425 sgd_solver.cpp:106] Iteration 328500, lr = 0.0035
I0521 17:28:26.931741 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_330000.caffemodel
I0521 17:28:26.977844 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_330000.solverstate
I0521 17:28:27.002858 28425 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 17:29:26.185235 28425 solver.cpp:409]     Test net output #0: accuracy = 0.890615
I0521 17:29:26.185430 28425 solver.cpp:409]     Test net output #1: loss = 0.343498 (* 1 = 0.343498 loss)
I0521 17:29:47.003263 28425 solver.cpp:237] Iteration 330000, loss = 1.45449
I0521 17:29:47.003320 28425 solver.cpp:253]     Train net output #0: loss = 1.45448 (* 1 = 1.45448 loss)
I0521 17:29:47.003335 28425 sgd_solver.cpp:106] Iteration 330000, lr = 0.0035
I0521 17:30:03.782649 28425 solver.cpp:237] Iteration 331500, loss = 1.22978
I0521 17:30:03.782815 28425 solver.cpp:253]     Train net output #0: loss = 1.22978 (* 1 = 1.22978 loss)
I0521 17:30:03.782829 28425 sgd_solver.cpp:106] Iteration 331500, lr = 0.0035
I0521 17:30:20.546346 28425 solver.cpp:237] Iteration 333000, loss = 0.828498
I0521 17:30:20.546396 28425 solver.cpp:253]     Train net output #0: loss = 0.828495 (* 1 = 0.828495 loss)
I0521 17:30:20.546411 28425 sgd_solver.cpp:106] Iteration 333000, lr = 0.0035
I0521 17:30:37.322798 28425 solver.cpp:237] Iteration 334500, loss = 2.60489
I0521 17:30:37.322973 28425 solver.cpp:253]     Train net output #0: loss = 2.60489 (* 1 = 2.60489 loss)
I0521 17:30:37.322986 28425 sgd_solver.cpp:106] Iteration 334500, lr = 0.0035
I0521 17:30:54.097219 28425 solver.cpp:237] Iteration 336000, loss = 1.72242
I0521 17:30:54.097255 28425 solver.cpp:253]     Train net output #0: loss = 1.72242 (* 1 = 1.72242 loss)
I0521 17:30:54.097272 28425 sgd_solver.cpp:106] Iteration 336000, lr = 0.0035
I0521 17:31:10.859911 28425 solver.cpp:237] Iteration 337500, loss = 1.60933
I0521 17:31:10.860086 28425 solver.cpp:253]     Train net output #0: loss = 1.60933 (* 1 = 1.60933 loss)
I0521 17:31:10.860101 28425 sgd_solver.cpp:106] Iteration 337500, lr = 0.0035
I0521 17:31:27.772503 28425 solver.cpp:237] Iteration 339000, loss = 0.809235
I0521 17:31:27.772557 28425 solver.cpp:253]     Train net output #0: loss = 0.809232 (* 1 = 0.809232 loss)
I0521 17:31:27.772572 28425 sgd_solver.cpp:106] Iteration 339000, lr = 0.0035
I0521 17:32:05.639065 28425 solver.cpp:237] Iteration 340500, loss = 1.56522
I0521 17:32:05.639250 28425 solver.cpp:253]     Train net output #0: loss = 1.56522 (* 1 = 1.56522 loss)
I0521 17:32:05.639266 28425 sgd_solver.cpp:106] Iteration 340500, lr = 0.0035
I0521 17:32:22.695109 28425 solver.cpp:237] Iteration 342000, loss = 0.865353
I0521 17:32:22.695163 28425 solver.cpp:253]     Train net output #0: loss = 0.865349 (* 1 = 0.865349 loss)
I0521 17:32:22.695176 28425 sgd_solver.cpp:106] Iteration 342000, lr = 0.0035
I0521 17:32:39.715667 28425 solver.cpp:237] Iteration 343500, loss = 1.07886
I0521 17:32:39.715852 28425 solver.cpp:253]     Train net output #0: loss = 1.07885 (* 1 = 1.07885 loss)
I0521 17:32:39.715867 28425 sgd_solver.cpp:106] Iteration 343500, lr = 0.0035
I0521 17:32:56.735026 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_345000.caffemodel
I0521 17:32:56.781090 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_345000.solverstate
I0521 17:32:56.809303 28425 solver.cpp:237] Iteration 345000, loss = 0.846609
I0521 17:32:56.809352 28425 solver.cpp:253]     Train net output #0: loss = 0.846605 (* 1 = 0.846605 loss)
I0521 17:32:56.809370 28425 sgd_solver.cpp:106] Iteration 345000, lr = 0.0035
I0521 17:33:13.814328 28425 solver.cpp:237] Iteration 346500, loss = 0.619891
I0521 17:33:13.814508 28425 solver.cpp:253]     Train net output #0: loss = 0.619887 (* 1 = 0.619887 loss)
I0521 17:33:13.814523 28425 sgd_solver.cpp:106] Iteration 346500, lr = 0.0035
I0521 17:33:30.842651 28425 solver.cpp:237] Iteration 348000, loss = 1.16356
I0521 17:33:30.842702 28425 solver.cpp:253]     Train net output #0: loss = 1.16356 (* 1 = 1.16356 loss)
I0521 17:33:30.842720 28425 sgd_solver.cpp:106] Iteration 348000, lr = 0.0035
I0521 17:33:47.852916 28425 solver.cpp:237] Iteration 349500, loss = 0.839776
I0521 17:33:47.853088 28425 solver.cpp:253]     Train net output #0: loss = 0.839771 (* 1 = 0.839771 loss)
I0521 17:33:47.853103 28425 sgd_solver.cpp:106] Iteration 349500, lr = 0.0035
I0521 17:34:25.682183 28425 solver.cpp:237] Iteration 351000, loss = 1.0254
I0521 17:34:25.682370 28425 solver.cpp:253]     Train net output #0: loss = 1.02539 (* 1 = 1.02539 loss)
I0521 17:34:25.682384 28425 sgd_solver.cpp:106] Iteration 351000, lr = 0.0035
I0521 17:34:42.707875 28425 solver.cpp:237] Iteration 352500, loss = 0.980738
I0521 17:34:42.707922 28425 solver.cpp:253]     Train net output #0: loss = 0.980733 (* 1 = 0.980733 loss)
I0521 17:34:42.707940 28425 sgd_solver.cpp:106] Iteration 352500, lr = 0.0035
I0521 17:34:59.729821 28425 solver.cpp:237] Iteration 354000, loss = 1.63698
I0521 17:34:59.729981 28425 solver.cpp:253]     Train net output #0: loss = 1.63697 (* 1 = 1.63697 loss)
I0521 17:34:59.729995 28425 sgd_solver.cpp:106] Iteration 354000, lr = 0.0035
I0521 17:35:16.751673 28425 solver.cpp:237] Iteration 355500, loss = 0.832406
I0521 17:35:16.751721 28425 solver.cpp:253]     Train net output #0: loss = 0.832401 (* 1 = 0.832401 loss)
I0521 17:35:16.751736 28425 sgd_solver.cpp:106] Iteration 355500, lr = 0.0035
I0521 17:35:33.782513 28425 solver.cpp:237] Iteration 357000, loss = 1.15639
I0521 17:35:33.782683 28425 solver.cpp:253]     Train net output #0: loss = 1.15638 (* 1 = 1.15638 loss)
I0521 17:35:33.782697 28425 sgd_solver.cpp:106] Iteration 357000, lr = 0.0035
I0521 17:35:50.804919 28425 solver.cpp:237] Iteration 358500, loss = 1.28722
I0521 17:35:50.804955 28425 solver.cpp:253]     Train net output #0: loss = 1.28721 (* 1 = 1.28721 loss)
I0521 17:35:50.804970 28425 sgd_solver.cpp:106] Iteration 358500, lr = 0.0035
I0521 17:36:07.790551 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_360000.caffemodel
I0521 17:36:07.840662 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_360000.solverstate
I0521 17:36:07.865798 28425 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 17:37:28.083854 28425 solver.cpp:409]     Test net output #0: accuracy = 0.888047
I0521 17:37:28.084043 28425 solver.cpp:409]     Test net output #1: loss = 0.386805 (* 1 = 0.386805 loss)
I0521 17:37:48.920507 28425 solver.cpp:237] Iteration 360000, loss = 1.42336
I0521 17:37:48.920565 28425 solver.cpp:253]     Train net output #0: loss = 1.42336 (* 1 = 1.42336 loss)
I0521 17:37:48.920580 28425 sgd_solver.cpp:106] Iteration 360000, lr = 0.0035
I0521 17:38:05.659752 28425 solver.cpp:237] Iteration 361500, loss = 0.649681
I0521 17:38:05.659932 28425 solver.cpp:253]     Train net output #0: loss = 0.649677 (* 1 = 0.649677 loss)
I0521 17:38:05.659946 28425 sgd_solver.cpp:106] Iteration 361500, lr = 0.0035
I0521 17:38:22.458081 28425 solver.cpp:237] Iteration 363000, loss = 1.17677
I0521 17:38:22.458118 28425 solver.cpp:253]     Train net output #0: loss = 1.17677 (* 1 = 1.17677 loss)
I0521 17:38:22.458134 28425 sgd_solver.cpp:106] Iteration 363000, lr = 0.0035
I0521 17:38:39.219861 28425 solver.cpp:237] Iteration 364500, loss = 1.48073
I0521 17:38:39.220037 28425 solver.cpp:253]     Train net output #0: loss = 1.48073 (* 1 = 1.48073 loss)
I0521 17:38:39.220052 28425 sgd_solver.cpp:106] Iteration 364500, lr = 0.0035
I0521 17:38:55.978258 28425 solver.cpp:237] Iteration 366000, loss = 0.676258
I0521 17:38:55.978307 28425 solver.cpp:253]     Train net output #0: loss = 0.676253 (* 1 = 0.676253 loss)
I0521 17:38:55.978319 28425 sgd_solver.cpp:106] Iteration 366000, lr = 0.0035
I0521 17:39:12.760699 28425 solver.cpp:237] Iteration 367500, loss = 1.41144
I0521 17:39:12.760876 28425 solver.cpp:253]     Train net output #0: loss = 1.41144 (* 1 = 1.41144 loss)
I0521 17:39:12.760891 28425 sgd_solver.cpp:106] Iteration 367500, lr = 0.0035
I0521 17:39:29.513640 28425 solver.cpp:237] Iteration 369000, loss = 1.28148
I0521 17:39:29.513692 28425 solver.cpp:253]     Train net output #0: loss = 1.28147 (* 1 = 1.28147 loss)
I0521 17:39:29.513706 28425 sgd_solver.cpp:106] Iteration 369000, lr = 0.0035
I0521 17:40:07.150970 28425 solver.cpp:237] Iteration 370500, loss = 1.4585
I0521 17:40:07.151163 28425 solver.cpp:253]     Train net output #0: loss = 1.45849 (* 1 = 1.45849 loss)
I0521 17:40:07.151177 28425 sgd_solver.cpp:106] Iteration 370500, lr = 0.0035
I0521 17:40:23.935742 28425 solver.cpp:237] Iteration 372000, loss = 0.977671
I0521 17:40:23.935780 28425 solver.cpp:253]     Train net output #0: loss = 0.977666 (* 1 = 0.977666 loss)
I0521 17:40:23.935794 28425 sgd_solver.cpp:106] Iteration 372000, lr = 0.0035
I0521 17:40:40.724658 28425 solver.cpp:237] Iteration 373500, loss = 0.678306
I0521 17:40:40.724835 28425 solver.cpp:253]     Train net output #0: loss = 0.678301 (* 1 = 0.678301 loss)
I0521 17:40:40.724849 28425 sgd_solver.cpp:106] Iteration 373500, lr = 0.0035
I0521 17:40:57.490007 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_375000.caffemodel
I0521 17:40:57.537009 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_375000.solverstate
I0521 17:40:57.567611 28425 solver.cpp:237] Iteration 375000, loss = 1.04157
I0521 17:40:57.567662 28425 solver.cpp:253]     Train net output #0: loss = 1.04156 (* 1 = 1.04156 loss)
I0521 17:40:57.567677 28425 sgd_solver.cpp:106] Iteration 375000, lr = 0.0035
I0521 17:41:14.345106 28425 solver.cpp:237] Iteration 376500, loss = 1.98864
I0521 17:41:14.345273 28425 solver.cpp:253]     Train net output #0: loss = 1.98864 (* 1 = 1.98864 loss)
I0521 17:41:14.345288 28425 sgd_solver.cpp:106] Iteration 376500, lr = 0.0035
I0521 17:41:31.290125 28425 solver.cpp:237] Iteration 378000, loss = 0.973728
I0521 17:41:31.290182 28425 solver.cpp:253]     Train net output #0: loss = 0.973723 (* 1 = 0.973723 loss)
I0521 17:41:31.290196 28425 sgd_solver.cpp:106] Iteration 378000, lr = 0.0035
I0521 17:41:48.325896 28425 solver.cpp:237] Iteration 379500, loss = 1.00289
I0521 17:41:48.326073 28425 solver.cpp:253]     Train net output #0: loss = 1.00289 (* 1 = 1.00289 loss)
I0521 17:41:48.326088 28425 sgd_solver.cpp:106] Iteration 379500, lr = 0.0035
I0521 17:42:26.232300 28425 solver.cpp:237] Iteration 381000, loss = 0.861253
I0521 17:42:26.232488 28425 solver.cpp:253]     Train net output #0: loss = 0.861249 (* 1 = 0.861249 loss)
I0521 17:42:26.232504 28425 sgd_solver.cpp:106] Iteration 381000, lr = 0.0035
I0521 17:42:43.256690 28425 solver.cpp:237] Iteration 382500, loss = 1.17876
I0521 17:42:43.256743 28425 solver.cpp:253]     Train net output #0: loss = 1.17876 (* 1 = 1.17876 loss)
I0521 17:42:43.256757 28425 sgd_solver.cpp:106] Iteration 382500, lr = 0.0035
I0521 17:43:00.303050 28425 solver.cpp:237] Iteration 384000, loss = 1.93167
I0521 17:43:00.303225 28425 solver.cpp:253]     Train net output #0: loss = 1.93167 (* 1 = 1.93167 loss)
I0521 17:43:00.303239 28425 sgd_solver.cpp:106] Iteration 384000, lr = 0.0035
I0521 17:43:17.303921 28425 solver.cpp:237] Iteration 385500, loss = 0.907449
I0521 17:43:17.303958 28425 solver.cpp:253]     Train net output #0: loss = 0.907445 (* 1 = 0.907445 loss)
I0521 17:43:17.303974 28425 sgd_solver.cpp:106] Iteration 385500, lr = 0.0035
I0521 17:43:34.343256 28425 solver.cpp:237] Iteration 387000, loss = 1.10024
I0521 17:43:34.343437 28425 solver.cpp:253]     Train net output #0: loss = 1.10023 (* 1 = 1.10023 loss)
I0521 17:43:34.343451 28425 sgd_solver.cpp:106] Iteration 387000, lr = 0.0035
I0521 17:43:51.351373 28425 solver.cpp:237] Iteration 388500, loss = 1.19217
I0521 17:43:51.351428 28425 solver.cpp:253]     Train net output #0: loss = 1.19217 (* 1 = 1.19217 loss)
I0521 17:43:51.351440 28425 sgd_solver.cpp:106] Iteration 388500, lr = 0.0035
I0521 17:44:08.382800 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_390000.caffemodel
I0521 17:44:08.429141 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_390000.solverstate
I0521 17:44:08.454180 28425 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 17:45:08.078989 28425 solver.cpp:409]     Test net output #0: accuracy = 0.888915
I0521 17:45:08.079176 28425 solver.cpp:409]     Test net output #1: loss = 0.359773 (* 1 = 0.359773 loss)
I0521 17:45:28.917116 28425 solver.cpp:237] Iteration 390000, loss = 1.2651
I0521 17:45:28.917172 28425 solver.cpp:253]     Train net output #0: loss = 1.2651 (* 1 = 1.2651 loss)
I0521 17:45:28.917187 28425 sgd_solver.cpp:106] Iteration 390000, lr = 0.0035
I0521 17:45:45.718200 28425 solver.cpp:237] Iteration 391500, loss = 0.701062
I0521 17:45:45.718375 28425 solver.cpp:253]     Train net output #0: loss = 0.701058 (* 1 = 0.701058 loss)
I0521 17:45:45.718389 28425 sgd_solver.cpp:106] Iteration 391500, lr = 0.0035
I0521 17:46:02.510536 28425 solver.cpp:237] Iteration 393000, loss = 1.26951
I0521 17:46:02.510586 28425 solver.cpp:253]     Train net output #0: loss = 1.26951 (* 1 = 1.26951 loss)
I0521 17:46:02.510601 28425 sgd_solver.cpp:106] Iteration 393000, lr = 0.0035
I0521 17:46:19.273100 28425 solver.cpp:237] Iteration 394500, loss = 1.33795
I0521 17:46:19.273263 28425 solver.cpp:253]     Train net output #0: loss = 1.33794 (* 1 = 1.33794 loss)
I0521 17:46:19.273277 28425 sgd_solver.cpp:106] Iteration 394500, lr = 0.0035
I0521 17:46:36.037974 28425 solver.cpp:237] Iteration 396000, loss = 0.672385
I0521 17:46:36.038012 28425 solver.cpp:253]     Train net output #0: loss = 0.67238 (* 1 = 0.67238 loss)
I0521 17:46:36.038028 28425 sgd_solver.cpp:106] Iteration 396000, lr = 0.0035
I0521 17:46:52.809978 28425 solver.cpp:237] Iteration 397500, loss = 0.789481
I0521 17:46:52.810159 28425 solver.cpp:253]     Train net output #0: loss = 0.789476 (* 1 = 0.789476 loss)
I0521 17:46:52.810174 28425 sgd_solver.cpp:106] Iteration 397500, lr = 0.0035
I0521 17:47:09.589766 28425 solver.cpp:237] Iteration 399000, loss = 1.3129
I0521 17:47:09.589804 28425 solver.cpp:253]     Train net output #0: loss = 1.31289 (* 1 = 1.31289 loss)
I0521 17:47:09.589820 28425 sgd_solver.cpp:106] Iteration 399000, lr = 0.0035
I0521 17:47:47.215744 28425 solver.cpp:237] Iteration 400500, loss = 1.51108
I0521 17:47:47.215940 28425 solver.cpp:253]     Train net output #0: loss = 1.51108 (* 1 = 1.51108 loss)
I0521 17:47:47.215955 28425 sgd_solver.cpp:106] Iteration 400500, lr = 0.0035
I0521 17:48:03.992087 28425 solver.cpp:237] Iteration 402000, loss = 0.830587
I0521 17:48:03.992136 28425 solver.cpp:253]     Train net output #0: loss = 0.830583 (* 1 = 0.830583 loss)
I0521 17:48:03.992152 28425 sgd_solver.cpp:106] Iteration 402000, lr = 0.0035
I0521 17:48:20.756476 28425 solver.cpp:237] Iteration 403500, loss = 0.628639
I0521 17:48:20.756641 28425 solver.cpp:253]     Train net output #0: loss = 0.628634 (* 1 = 0.628634 loss)
I0521 17:48:20.756654 28425 sgd_solver.cpp:106] Iteration 403500, lr = 0.0035
I0521 17:48:37.483019 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_405000.caffemodel
I0521 17:48:37.528412 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_405000.solverstate
I0521 17:48:37.558759 28425 solver.cpp:237] Iteration 405000, loss = 0.942634
I0521 17:48:37.558809 28425 solver.cpp:253]     Train net output #0: loss = 0.942629 (* 1 = 0.942629 loss)
I0521 17:48:37.558823 28425 sgd_solver.cpp:106] Iteration 405000, lr = 0.0035
I0521 17:48:54.347807 28425 solver.cpp:237] Iteration 406500, loss = 1.55285
I0521 17:48:54.347996 28425 solver.cpp:253]     Train net output #0: loss = 1.55284 (* 1 = 1.55284 loss)
I0521 17:48:54.348011 28425 sgd_solver.cpp:106] Iteration 406500, lr = 0.0035
I0521 17:49:11.097687 28425 solver.cpp:237] Iteration 408000, loss = 1.11635
I0521 17:49:11.097723 28425 solver.cpp:253]     Train net output #0: loss = 1.11635 (* 1 = 1.11635 loss)
I0521 17:49:11.097738 28425 sgd_solver.cpp:106] Iteration 408000, lr = 0.0035
I0521 17:49:27.836305 28425 solver.cpp:237] Iteration 409500, loss = 1.10716
I0521 17:49:27.836480 28425 solver.cpp:253]     Train net output #0: loss = 1.10716 (* 1 = 1.10716 loss)
I0521 17:49:27.836494 28425 sgd_solver.cpp:106] Iteration 409500, lr = 0.0035
I0521 17:50:05.458668 28425 solver.cpp:237] Iteration 411000, loss = 1.27208
I0521 17:50:05.458880 28425 solver.cpp:253]     Train net output #0: loss = 1.27207 (* 1 = 1.27207 loss)
I0521 17:50:05.458894 28425 sgd_solver.cpp:106] Iteration 411000, lr = 0.0035
I0521 17:50:22.225416 28425 solver.cpp:237] Iteration 412500, loss = 2.09297
I0521 17:50:22.225452 28425 solver.cpp:253]     Train net output #0: loss = 2.09296 (* 1 = 2.09296 loss)
I0521 17:50:22.225467 28425 sgd_solver.cpp:106] Iteration 412500, lr = 0.0035
I0521 17:50:39.017807 28425 solver.cpp:237] Iteration 414000, loss = 2.38127
I0521 17:50:39.017985 28425 solver.cpp:253]     Train net output #0: loss = 2.38126 (* 1 = 2.38126 loss)
I0521 17:50:39.017999 28425 sgd_solver.cpp:106] Iteration 414000, lr = 0.0035
I0521 17:50:55.794819 28425 solver.cpp:237] Iteration 415500, loss = 1.22392
I0521 17:50:55.794872 28425 solver.cpp:253]     Train net output #0: loss = 1.22392 (* 1 = 1.22392 loss)
I0521 17:50:55.794888 28425 sgd_solver.cpp:106] Iteration 415500, lr = 0.0035
I0521 17:51:12.429566 28425 solver.cpp:237] Iteration 417000, loss = 0.86311
I0521 17:51:12.429733 28425 solver.cpp:253]     Train net output #0: loss = 0.863105 (* 1 = 0.863105 loss)
I0521 17:51:12.429749 28425 sgd_solver.cpp:106] Iteration 417000, lr = 0.0035
I0521 17:51:29.067528 28425 solver.cpp:237] Iteration 418500, loss = 1.53054
I0521 17:51:29.067579 28425 solver.cpp:253]     Train net output #0: loss = 1.53054 (* 1 = 1.53054 loss)
I0521 17:51:29.067595 28425 sgd_solver.cpp:106] Iteration 418500, lr = 0.0035
I0521 17:51:45.689632 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_420000.caffemodel
I0521 17:51:45.735549 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_420000.solverstate
I0521 17:51:45.760924 28425 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 17:53:05.823284 28425 solver.cpp:409]     Test net output #0: accuracy = 0.883741
I0521 17:53:05.823482 28425 solver.cpp:409]     Test net output #1: loss = 0.359132 (* 1 = 0.359132 loss)
I0521 17:53:26.647519 28425 solver.cpp:237] Iteration 420000, loss = 1.64357
I0521 17:53:26.647575 28425 solver.cpp:253]     Train net output #0: loss = 1.64357 (* 1 = 1.64357 loss)
I0521 17:53:26.647589 28425 sgd_solver.cpp:106] Iteration 420000, lr = 0.0035
I0521 17:53:43.604279 28425 solver.cpp:237] Iteration 421500, loss = 1.3048
I0521 17:53:43.604450 28425 solver.cpp:253]     Train net output #0: loss = 1.30479 (* 1 = 1.30479 loss)
I0521 17:53:43.604465 28425 sgd_solver.cpp:106] Iteration 421500, lr = 0.0035
I0521 17:54:00.552364 28425 solver.cpp:237] Iteration 423000, loss = 1.57822
I0521 17:54:00.552414 28425 solver.cpp:253]     Train net output #0: loss = 1.57821 (* 1 = 1.57821 loss)
I0521 17:54:00.552430 28425 sgd_solver.cpp:106] Iteration 423000, lr = 0.0035
I0521 17:54:17.507546 28425 solver.cpp:237] Iteration 424500, loss = 0.828964
I0521 17:54:17.507733 28425 solver.cpp:253]     Train net output #0: loss = 0.828956 (* 1 = 0.828956 loss)
I0521 17:54:17.507747 28425 sgd_solver.cpp:106] Iteration 424500, lr = 0.0035
I0521 17:54:34.480470 28425 solver.cpp:237] Iteration 426000, loss = 0.873564
I0521 17:54:34.480507 28425 solver.cpp:253]     Train net output #0: loss = 0.873556 (* 1 = 0.873556 loss)
I0521 17:54:34.480523 28425 sgd_solver.cpp:106] Iteration 426000, lr = 0.0035
I0521 17:54:51.442936 28425 solver.cpp:237] Iteration 427500, loss = 1.26208
I0521 17:54:51.443131 28425 solver.cpp:253]     Train net output #0: loss = 1.26208 (* 1 = 1.26208 loss)
I0521 17:54:51.443145 28425 sgd_solver.cpp:106] Iteration 427500, lr = 0.0035
I0521 17:55:08.401624 28425 solver.cpp:237] Iteration 429000, loss = 0.835356
I0521 17:55:08.401671 28425 solver.cpp:253]     Train net output #0: loss = 0.83535 (* 1 = 0.83535 loss)
I0521 17:55:08.401689 28425 sgd_solver.cpp:106] Iteration 429000, lr = 0.0035
I0521 17:55:46.202069 28425 solver.cpp:237] Iteration 430500, loss = 1.06049
I0521 17:55:46.202261 28425 solver.cpp:253]     Train net output #0: loss = 1.06048 (* 1 = 1.06048 loss)
I0521 17:55:46.202275 28425 sgd_solver.cpp:106] Iteration 430500, lr = 0.0035
I0521 17:56:03.123934 28425 solver.cpp:237] Iteration 432000, loss = 0.954954
I0521 17:56:03.123989 28425 solver.cpp:253]     Train net output #0: loss = 0.954948 (* 1 = 0.954948 loss)
I0521 17:56:03.124003 28425 sgd_solver.cpp:106] Iteration 432000, lr = 0.0035
I0521 17:56:20.071503 28425 solver.cpp:237] Iteration 433500, loss = 1.5825
I0521 17:56:20.071681 28425 solver.cpp:253]     Train net output #0: loss = 1.58249 (* 1 = 1.58249 loss)
I0521 17:56:20.071696 28425 sgd_solver.cpp:106] Iteration 433500, lr = 0.0035
I0521 17:56:37.007148 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_435000.caffemodel
I0521 17:56:37.054694 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_435000.solverstate
I0521 17:56:37.086323 28425 solver.cpp:237] Iteration 435000, loss = 3.19111
I0521 17:56:37.086376 28425 solver.cpp:253]     Train net output #0: loss = 3.19111 (* 1 = 3.19111 loss)
I0521 17:56:37.086390 28425 sgd_solver.cpp:106] Iteration 435000, lr = 0.0035
I0521 17:56:54.022241 28425 solver.cpp:237] Iteration 436500, loss = 0.593851
I0521 17:56:54.022426 28425 solver.cpp:253]     Train net output #0: loss = 0.593845 (* 1 = 0.593845 loss)
I0521 17:56:54.022441 28425 sgd_solver.cpp:106] Iteration 436500, lr = 0.0035
I0521 17:57:10.996532 28425 solver.cpp:237] Iteration 438000, loss = 1.45759
I0521 17:57:10.996582 28425 solver.cpp:253]     Train net output #0: loss = 1.45759 (* 1 = 1.45759 loss)
I0521 17:57:10.996598 28425 sgd_solver.cpp:106] Iteration 438000, lr = 0.0035
I0521 17:57:27.980845 28425 solver.cpp:237] Iteration 439500, loss = 0.737464
I0521 17:57:27.981011 28425 solver.cpp:253]     Train net output #0: loss = 0.737458 (* 1 = 0.737458 loss)
I0521 17:57:27.981025 28425 sgd_solver.cpp:106] Iteration 439500, lr = 0.0035
I0521 17:58:05.785810 28425 solver.cpp:237] Iteration 441000, loss = 1.57202
I0521 17:58:05.786001 28425 solver.cpp:253]     Train net output #0: loss = 1.57202 (* 1 = 1.57202 loss)
I0521 17:58:05.786015 28425 sgd_solver.cpp:106] Iteration 441000, lr = 0.0035
I0521 17:58:22.734717 28425 solver.cpp:237] Iteration 442500, loss = 1.69595
I0521 17:58:22.734751 28425 solver.cpp:253]     Train net output #0: loss = 1.69594 (* 1 = 1.69594 loss)
I0521 17:58:22.734766 28425 sgd_solver.cpp:106] Iteration 442500, lr = 0.0035
I0521 17:58:39.700285 28425 solver.cpp:237] Iteration 444000, loss = 1.50374
I0521 17:58:39.700464 28425 solver.cpp:253]     Train net output #0: loss = 1.50373 (* 1 = 1.50373 loss)
I0521 17:58:39.700476 28425 sgd_solver.cpp:106] Iteration 444000, lr = 0.0035
I0521 17:58:56.641077 28425 solver.cpp:237] Iteration 445500, loss = 1.42242
I0521 17:58:56.641127 28425 solver.cpp:253]     Train net output #0: loss = 1.42241 (* 1 = 1.42241 loss)
I0521 17:58:56.641144 28425 sgd_solver.cpp:106] Iteration 445500, lr = 0.0035
I0521 17:59:13.592372 28425 solver.cpp:237] Iteration 447000, loss = 0.980212
I0521 17:59:13.592550 28425 solver.cpp:253]     Train net output #0: loss = 0.980204 (* 1 = 0.980204 loss)
I0521 17:59:13.592566 28425 sgd_solver.cpp:106] Iteration 447000, lr = 0.0035
I0521 17:59:30.526273 28425 solver.cpp:237] Iteration 448500, loss = 1.0497
I0521 17:59:30.526319 28425 solver.cpp:253]     Train net output #0: loss = 1.04969 (* 1 = 1.04969 loss)
I0521 17:59:30.526335 28425 sgd_solver.cpp:106] Iteration 448500, lr = 0.0035
I0521 17:59:47.448570 28425 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_450000.caffemodel
I0521 17:59:47.497391 28425 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0035_2016-05-20T15.48.51.674992_iter_450000.solverstate
I0521 17:59:47.524857 28425 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 18:00:46.701923 28425 solver.cpp:409]     Test net output #0: accuracy = 0.894448
I0521 18:00:46.702114 28425 solver.cpp:409]     Test net output #1: loss = 0.337537 (* 1 = 0.337537 loss)
I0521 18:01:07.548457 28425 solver.cpp:237] Iteration 450000, loss = 1.08109
I0521 18:01:07.548514 28425 solver.cpp:253]     Train net output #0: loss = 1.08108 (* 1 = 1.08108 loss)
I0521 18:01:07.548529 28425 sgd_solver.cpp:106] Iteration 450000, lr = 0.0035
I0521 18:01:24.333739 28425 solver.cpp:237] Iteration 451500, loss = 0.478787
I0521 18:01:24.333928 28425 solver.cpp:253]     Train net output #0: loss = 0.478779 (* 1 = 0.478779 loss)
I0521 18:01:24.333942 28425 sgd_solver.cpp:106] Iteration 451500, lr = 0.0035
I0521 18:01:41.115911 28425 solver.cpp:237] Iteration 453000, loss = 1.27489
I0521 18:01:41.115947 28425 solver.cpp:253]     Train net output #0: loss = 1.27489 (* 1 = 1.27489 loss)
I0521 18:01:41.115960 28425 sgd_solver.cpp:106] Iteration 453000, lr = 0.0035
aprun: Apid 11239824: Caught signal Terminated, sending to application
*** Aborted at 1463868104 (unix time) try "date -d @1463868104" if you are using GNU date ***
aprun: Apid 11239824: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11239824: Caught signal Terminated, sending to application
*** SIGTERM (@0x6f06) received by PID 28425 (TID 0x2aaac746f900) from PID 28422; stack trace: ***
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
=>> PBS: job killed: walltime 7204 exceeded limit 7200
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x43020c main
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11239824: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
