2810877
I0525 18:57:16.164674 25020 caffe.cpp:184] Using GPUs 0
I0525 18:57:16.584453 25020 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.0035
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827.prototxt"
I0525 18:57:16.586427 25020 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827.prototxt
I0525 18:57:16.603373 25020 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 18:57:16.603433 25020 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 18:57:16.603777 25020 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 18:57:16.603960 25020 layer_factory.hpp:77] Creating layer data_hdf5
I0525 18:57:16.603983 25020 net.cpp:106] Creating Layer data_hdf5
I0525 18:57:16.603998 25020 net.cpp:411] data_hdf5 -> data
I0525 18:57:16.604032 25020 net.cpp:411] data_hdf5 -> label
I0525 18:57:16.604063 25020 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 18:57:16.605331 25020 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 18:57:16.607527 25020 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 18:57:38.154677 25020 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 18:57:38.159852 25020 net.cpp:150] Setting up data_hdf5
I0525 18:57:38.159895 25020 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 18:57:38.159910 25020 net.cpp:157] Top shape: 100 (100)
I0525 18:57:38.159920 25020 net.cpp:165] Memory required for data: 2540400
I0525 18:57:38.159934 25020 layer_factory.hpp:77] Creating layer conv1
I0525 18:57:38.159968 25020 net.cpp:106] Creating Layer conv1
I0525 18:57:38.159979 25020 net.cpp:454] conv1 <- data
I0525 18:57:38.160002 25020 net.cpp:411] conv1 -> conv1
I0525 18:57:38.520867 25020 net.cpp:150] Setting up conv1
I0525 18:57:38.520915 25020 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:57:38.520925 25020 net.cpp:165] Memory required for data: 30188400
I0525 18:57:38.520953 25020 layer_factory.hpp:77] Creating layer relu1
I0525 18:57:38.520974 25020 net.cpp:106] Creating Layer relu1
I0525 18:57:38.520985 25020 net.cpp:454] relu1 <- conv1
I0525 18:57:38.520998 25020 net.cpp:397] relu1 -> conv1 (in-place)
I0525 18:57:38.521527 25020 net.cpp:150] Setting up relu1
I0525 18:57:38.521543 25020 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:57:38.521553 25020 net.cpp:165] Memory required for data: 57836400
I0525 18:57:38.521564 25020 layer_factory.hpp:77] Creating layer pool1
I0525 18:57:38.521581 25020 net.cpp:106] Creating Layer pool1
I0525 18:57:38.521591 25020 net.cpp:454] pool1 <- conv1
I0525 18:57:38.521605 25020 net.cpp:411] pool1 -> pool1
I0525 18:57:38.521687 25020 net.cpp:150] Setting up pool1
I0525 18:57:38.521700 25020 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 18:57:38.521709 25020 net.cpp:165] Memory required for data: 71660400
I0525 18:57:38.521720 25020 layer_factory.hpp:77] Creating layer conv2
I0525 18:57:38.521744 25020 net.cpp:106] Creating Layer conv2
I0525 18:57:38.521754 25020 net.cpp:454] conv2 <- pool1
I0525 18:57:38.521766 25020 net.cpp:411] conv2 -> conv2
I0525 18:57:38.524492 25020 net.cpp:150] Setting up conv2
I0525 18:57:38.524519 25020 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:57:38.524529 25020 net.cpp:165] Memory required for data: 91532400
I0525 18:57:38.524549 25020 layer_factory.hpp:77] Creating layer relu2
I0525 18:57:38.524564 25020 net.cpp:106] Creating Layer relu2
I0525 18:57:38.524574 25020 net.cpp:454] relu2 <- conv2
I0525 18:57:38.524586 25020 net.cpp:397] relu2 -> conv2 (in-place)
I0525 18:57:38.524917 25020 net.cpp:150] Setting up relu2
I0525 18:57:38.524931 25020 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:57:38.524941 25020 net.cpp:165] Memory required for data: 111404400
I0525 18:57:38.524951 25020 layer_factory.hpp:77] Creating layer pool2
I0525 18:57:38.524963 25020 net.cpp:106] Creating Layer pool2
I0525 18:57:38.524974 25020 net.cpp:454] pool2 <- conv2
I0525 18:57:38.524986 25020 net.cpp:411] pool2 -> pool2
I0525 18:57:38.525077 25020 net.cpp:150] Setting up pool2
I0525 18:57:38.525091 25020 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 18:57:38.525101 25020 net.cpp:165] Memory required for data: 121340400
I0525 18:57:38.525111 25020 layer_factory.hpp:77] Creating layer conv3
I0525 18:57:38.525130 25020 net.cpp:106] Creating Layer conv3
I0525 18:57:38.525141 25020 net.cpp:454] conv3 <- pool2
I0525 18:57:38.525154 25020 net.cpp:411] conv3 -> conv3
I0525 18:57:38.527073 25020 net.cpp:150] Setting up conv3
I0525 18:57:38.527091 25020 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:57:38.527102 25020 net.cpp:165] Memory required for data: 132182000
I0525 18:57:38.527120 25020 layer_factory.hpp:77] Creating layer relu3
I0525 18:57:38.527137 25020 net.cpp:106] Creating Layer relu3
I0525 18:57:38.527146 25020 net.cpp:454] relu3 <- conv3
I0525 18:57:38.527158 25020 net.cpp:397] relu3 -> conv3 (in-place)
I0525 18:57:38.527631 25020 net.cpp:150] Setting up relu3
I0525 18:57:38.527647 25020 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:57:38.527657 25020 net.cpp:165] Memory required for data: 143023600
I0525 18:57:38.527667 25020 layer_factory.hpp:77] Creating layer pool3
I0525 18:57:38.527680 25020 net.cpp:106] Creating Layer pool3
I0525 18:57:38.527690 25020 net.cpp:454] pool3 <- conv3
I0525 18:57:38.527704 25020 net.cpp:411] pool3 -> pool3
I0525 18:57:38.527770 25020 net.cpp:150] Setting up pool3
I0525 18:57:38.527783 25020 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 18:57:38.527793 25020 net.cpp:165] Memory required for data: 148444400
I0525 18:57:38.527803 25020 layer_factory.hpp:77] Creating layer conv4
I0525 18:57:38.527822 25020 net.cpp:106] Creating Layer conv4
I0525 18:57:38.527832 25020 net.cpp:454] conv4 <- pool3
I0525 18:57:38.527844 25020 net.cpp:411] conv4 -> conv4
I0525 18:57:38.530789 25020 net.cpp:150] Setting up conv4
I0525 18:57:38.530812 25020 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:57:38.530823 25020 net.cpp:165] Memory required for data: 152073200
I0525 18:57:38.530839 25020 layer_factory.hpp:77] Creating layer relu4
I0525 18:57:38.530853 25020 net.cpp:106] Creating Layer relu4
I0525 18:57:38.530864 25020 net.cpp:454] relu4 <- conv4
I0525 18:57:38.530877 25020 net.cpp:397] relu4 -> conv4 (in-place)
I0525 18:57:38.531340 25020 net.cpp:150] Setting up relu4
I0525 18:57:38.531357 25020 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:57:38.531366 25020 net.cpp:165] Memory required for data: 155702000
I0525 18:57:38.531378 25020 layer_factory.hpp:77] Creating layer pool4
I0525 18:57:38.531390 25020 net.cpp:106] Creating Layer pool4
I0525 18:57:38.531401 25020 net.cpp:454] pool4 <- conv4
I0525 18:57:38.531414 25020 net.cpp:411] pool4 -> pool4
I0525 18:57:38.531481 25020 net.cpp:150] Setting up pool4
I0525 18:57:38.531496 25020 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 18:57:38.531504 25020 net.cpp:165] Memory required for data: 157516400
I0525 18:57:38.531515 25020 layer_factory.hpp:77] Creating layer ip1
I0525 18:57:38.531535 25020 net.cpp:106] Creating Layer ip1
I0525 18:57:38.531545 25020 net.cpp:454] ip1 <- pool4
I0525 18:57:38.531558 25020 net.cpp:411] ip1 -> ip1
I0525 18:57:38.546990 25020 net.cpp:150] Setting up ip1
I0525 18:57:38.547013 25020 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:57:38.547024 25020 net.cpp:165] Memory required for data: 157594800
I0525 18:57:38.547045 25020 layer_factory.hpp:77] Creating layer relu5
I0525 18:57:38.547060 25020 net.cpp:106] Creating Layer relu5
I0525 18:57:38.547070 25020 net.cpp:454] relu5 <- ip1
I0525 18:57:38.547083 25020 net.cpp:397] relu5 -> ip1 (in-place)
I0525 18:57:38.547425 25020 net.cpp:150] Setting up relu5
I0525 18:57:38.547438 25020 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:57:38.547448 25020 net.cpp:165] Memory required for data: 157673200
I0525 18:57:38.547458 25020 layer_factory.hpp:77] Creating layer drop1
I0525 18:57:38.547480 25020 net.cpp:106] Creating Layer drop1
I0525 18:57:38.547490 25020 net.cpp:454] drop1 <- ip1
I0525 18:57:38.547502 25020 net.cpp:397] drop1 -> ip1 (in-place)
I0525 18:57:38.547562 25020 net.cpp:150] Setting up drop1
I0525 18:57:38.547575 25020 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:57:38.547585 25020 net.cpp:165] Memory required for data: 157751600
I0525 18:57:38.547595 25020 layer_factory.hpp:77] Creating layer ip2
I0525 18:57:38.547615 25020 net.cpp:106] Creating Layer ip2
I0525 18:57:38.547624 25020 net.cpp:454] ip2 <- ip1
I0525 18:57:38.547637 25020 net.cpp:411] ip2 -> ip2
I0525 18:57:38.548102 25020 net.cpp:150] Setting up ip2
I0525 18:57:38.548116 25020 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:57:38.548126 25020 net.cpp:165] Memory required for data: 157790800
I0525 18:57:38.548141 25020 layer_factory.hpp:77] Creating layer relu6
I0525 18:57:38.548153 25020 net.cpp:106] Creating Layer relu6
I0525 18:57:38.548163 25020 net.cpp:454] relu6 <- ip2
I0525 18:57:38.548176 25020 net.cpp:397] relu6 -> ip2 (in-place)
I0525 18:57:38.548697 25020 net.cpp:150] Setting up relu6
I0525 18:57:38.548712 25020 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:57:38.548722 25020 net.cpp:165] Memory required for data: 157830000
I0525 18:57:38.548732 25020 layer_factory.hpp:77] Creating layer drop2
I0525 18:57:38.548745 25020 net.cpp:106] Creating Layer drop2
I0525 18:57:38.548755 25020 net.cpp:454] drop2 <- ip2
I0525 18:57:38.548768 25020 net.cpp:397] drop2 -> ip2 (in-place)
I0525 18:57:38.548810 25020 net.cpp:150] Setting up drop2
I0525 18:57:38.548822 25020 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:57:38.548832 25020 net.cpp:165] Memory required for data: 157869200
I0525 18:57:38.548842 25020 layer_factory.hpp:77] Creating layer ip3
I0525 18:57:38.548856 25020 net.cpp:106] Creating Layer ip3
I0525 18:57:38.548866 25020 net.cpp:454] ip3 <- ip2
I0525 18:57:38.548878 25020 net.cpp:411] ip3 -> ip3
I0525 18:57:38.549094 25020 net.cpp:150] Setting up ip3
I0525 18:57:38.549108 25020 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:57:38.549118 25020 net.cpp:165] Memory required for data: 157873600
I0525 18:57:38.549132 25020 layer_factory.hpp:77] Creating layer drop3
I0525 18:57:38.549145 25020 net.cpp:106] Creating Layer drop3
I0525 18:57:38.549155 25020 net.cpp:454] drop3 <- ip3
I0525 18:57:38.549167 25020 net.cpp:397] drop3 -> ip3 (in-place)
I0525 18:57:38.549206 25020 net.cpp:150] Setting up drop3
I0525 18:57:38.549219 25020 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:57:38.549229 25020 net.cpp:165] Memory required for data: 157878000
I0525 18:57:38.549239 25020 layer_factory.hpp:77] Creating layer loss
I0525 18:57:38.549259 25020 net.cpp:106] Creating Layer loss
I0525 18:57:38.549269 25020 net.cpp:454] loss <- ip3
I0525 18:57:38.549280 25020 net.cpp:454] loss <- label
I0525 18:57:38.549293 25020 net.cpp:411] loss -> loss
I0525 18:57:38.549309 25020 layer_factory.hpp:77] Creating layer loss
I0525 18:57:38.549952 25020 net.cpp:150] Setting up loss
I0525 18:57:38.549973 25020 net.cpp:157] Top shape: (1)
I0525 18:57:38.549985 25020 net.cpp:160]     with loss weight 1
I0525 18:57:38.550029 25020 net.cpp:165] Memory required for data: 157878004
I0525 18:57:38.550041 25020 net.cpp:226] loss needs backward computation.
I0525 18:57:38.550051 25020 net.cpp:226] drop3 needs backward computation.
I0525 18:57:38.550060 25020 net.cpp:226] ip3 needs backward computation.
I0525 18:57:38.550071 25020 net.cpp:226] drop2 needs backward computation.
I0525 18:57:38.550081 25020 net.cpp:226] relu6 needs backward computation.
I0525 18:57:38.550089 25020 net.cpp:226] ip2 needs backward computation.
I0525 18:57:38.550101 25020 net.cpp:226] drop1 needs backward computation.
I0525 18:57:38.550110 25020 net.cpp:226] relu5 needs backward computation.
I0525 18:57:38.550119 25020 net.cpp:226] ip1 needs backward computation.
I0525 18:57:38.550129 25020 net.cpp:226] pool4 needs backward computation.
I0525 18:57:38.550139 25020 net.cpp:226] relu4 needs backward computation.
I0525 18:57:38.550149 25020 net.cpp:226] conv4 needs backward computation.
I0525 18:57:38.550160 25020 net.cpp:226] pool3 needs backward computation.
I0525 18:57:38.550170 25020 net.cpp:226] relu3 needs backward computation.
I0525 18:57:38.550189 25020 net.cpp:226] conv3 needs backward computation.
I0525 18:57:38.550201 25020 net.cpp:226] pool2 needs backward computation.
I0525 18:57:38.550212 25020 net.cpp:226] relu2 needs backward computation.
I0525 18:57:38.550222 25020 net.cpp:226] conv2 needs backward computation.
I0525 18:57:38.550233 25020 net.cpp:226] pool1 needs backward computation.
I0525 18:57:38.550245 25020 net.cpp:226] relu1 needs backward computation.
I0525 18:57:38.550254 25020 net.cpp:226] conv1 needs backward computation.
I0525 18:57:38.550266 25020 net.cpp:228] data_hdf5 does not need backward computation.
I0525 18:57:38.550276 25020 net.cpp:270] This network produces output loss
I0525 18:57:38.550298 25020 net.cpp:283] Network initialization done.
I0525 18:57:38.552019 25020 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827.prototxt
I0525 18:57:38.552091 25020 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 18:57:38.552445 25020 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 18:57:38.552634 25020 layer_factory.hpp:77] Creating layer data_hdf5
I0525 18:57:38.552649 25020 net.cpp:106] Creating Layer data_hdf5
I0525 18:57:38.552661 25020 net.cpp:411] data_hdf5 -> data
I0525 18:57:38.552678 25020 net.cpp:411] data_hdf5 -> label
I0525 18:57:38.552695 25020 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 18:57:38.554065 25020 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 18:57:59.919479 25020 net.cpp:150] Setting up data_hdf5
I0525 18:57:59.919646 25020 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 18:57:59.919659 25020 net.cpp:157] Top shape: 100 (100)
I0525 18:57:59.919673 25020 net.cpp:165] Memory required for data: 2540400
I0525 18:57:59.919687 25020 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 18:57:59.919715 25020 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 18:57:59.919726 25020 net.cpp:454] label_data_hdf5_1_split <- label
I0525 18:57:59.919740 25020 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 18:57:59.919761 25020 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 18:57:59.919834 25020 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 18:57:59.919848 25020 net.cpp:157] Top shape: 100 (100)
I0525 18:57:59.919860 25020 net.cpp:157] Top shape: 100 (100)
I0525 18:57:59.919869 25020 net.cpp:165] Memory required for data: 2541200
I0525 18:57:59.919881 25020 layer_factory.hpp:77] Creating layer conv1
I0525 18:57:59.919901 25020 net.cpp:106] Creating Layer conv1
I0525 18:57:59.919912 25020 net.cpp:454] conv1 <- data
I0525 18:57:59.919926 25020 net.cpp:411] conv1 -> conv1
I0525 18:57:59.921890 25020 net.cpp:150] Setting up conv1
I0525 18:57:59.921914 25020 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:57:59.921926 25020 net.cpp:165] Memory required for data: 30189200
I0525 18:57:59.921947 25020 layer_factory.hpp:77] Creating layer relu1
I0525 18:57:59.921962 25020 net.cpp:106] Creating Layer relu1
I0525 18:57:59.921972 25020 net.cpp:454] relu1 <- conv1
I0525 18:57:59.921984 25020 net.cpp:397] relu1 -> conv1 (in-place)
I0525 18:57:59.922480 25020 net.cpp:150] Setting up relu1
I0525 18:57:59.922497 25020 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 18:57:59.922507 25020 net.cpp:165] Memory required for data: 57837200
I0525 18:57:59.922516 25020 layer_factory.hpp:77] Creating layer pool1
I0525 18:57:59.922533 25020 net.cpp:106] Creating Layer pool1
I0525 18:57:59.922543 25020 net.cpp:454] pool1 <- conv1
I0525 18:57:59.922554 25020 net.cpp:411] pool1 -> pool1
I0525 18:57:59.922629 25020 net.cpp:150] Setting up pool1
I0525 18:57:59.922642 25020 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 18:57:59.922652 25020 net.cpp:165] Memory required for data: 71661200
I0525 18:57:59.922662 25020 layer_factory.hpp:77] Creating layer conv2
I0525 18:57:59.922680 25020 net.cpp:106] Creating Layer conv2
I0525 18:57:59.922691 25020 net.cpp:454] conv2 <- pool1
I0525 18:57:59.922705 25020 net.cpp:411] conv2 -> conv2
I0525 18:57:59.924623 25020 net.cpp:150] Setting up conv2
I0525 18:57:59.924644 25020 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:57:59.924657 25020 net.cpp:165] Memory required for data: 91533200
I0525 18:57:59.924674 25020 layer_factory.hpp:77] Creating layer relu2
I0525 18:57:59.924688 25020 net.cpp:106] Creating Layer relu2
I0525 18:57:59.924698 25020 net.cpp:454] relu2 <- conv2
I0525 18:57:59.924710 25020 net.cpp:397] relu2 -> conv2 (in-place)
I0525 18:57:59.925053 25020 net.cpp:150] Setting up relu2
I0525 18:57:59.925067 25020 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 18:57:59.925077 25020 net.cpp:165] Memory required for data: 111405200
I0525 18:57:59.925087 25020 layer_factory.hpp:77] Creating layer pool2
I0525 18:57:59.925101 25020 net.cpp:106] Creating Layer pool2
I0525 18:57:59.925110 25020 net.cpp:454] pool2 <- conv2
I0525 18:57:59.925123 25020 net.cpp:411] pool2 -> pool2
I0525 18:57:59.925195 25020 net.cpp:150] Setting up pool2
I0525 18:57:59.925209 25020 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 18:57:59.925218 25020 net.cpp:165] Memory required for data: 121341200
I0525 18:57:59.925228 25020 layer_factory.hpp:77] Creating layer conv3
I0525 18:57:59.925246 25020 net.cpp:106] Creating Layer conv3
I0525 18:57:59.925256 25020 net.cpp:454] conv3 <- pool2
I0525 18:57:59.925269 25020 net.cpp:411] conv3 -> conv3
I0525 18:57:59.927268 25020 net.cpp:150] Setting up conv3
I0525 18:57:59.927285 25020 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:57:59.927296 25020 net.cpp:165] Memory required for data: 132182800
I0525 18:57:59.927328 25020 layer_factory.hpp:77] Creating layer relu3
I0525 18:57:59.927342 25020 net.cpp:106] Creating Layer relu3
I0525 18:57:59.927352 25020 net.cpp:454] relu3 <- conv3
I0525 18:57:59.927366 25020 net.cpp:397] relu3 -> conv3 (in-place)
I0525 18:57:59.927836 25020 net.cpp:150] Setting up relu3
I0525 18:57:59.927852 25020 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 18:57:59.927862 25020 net.cpp:165] Memory required for data: 143024400
I0525 18:57:59.927873 25020 layer_factory.hpp:77] Creating layer pool3
I0525 18:57:59.927886 25020 net.cpp:106] Creating Layer pool3
I0525 18:57:59.927896 25020 net.cpp:454] pool3 <- conv3
I0525 18:57:59.927909 25020 net.cpp:411] pool3 -> pool3
I0525 18:57:59.927979 25020 net.cpp:150] Setting up pool3
I0525 18:57:59.927992 25020 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 18:57:59.928002 25020 net.cpp:165] Memory required for data: 148445200
I0525 18:57:59.928012 25020 layer_factory.hpp:77] Creating layer conv4
I0525 18:57:59.928030 25020 net.cpp:106] Creating Layer conv4
I0525 18:57:59.928040 25020 net.cpp:454] conv4 <- pool3
I0525 18:57:59.928055 25020 net.cpp:411] conv4 -> conv4
I0525 18:57:59.930141 25020 net.cpp:150] Setting up conv4
I0525 18:57:59.930165 25020 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:57:59.930176 25020 net.cpp:165] Memory required for data: 152074000
I0525 18:57:59.930192 25020 layer_factory.hpp:77] Creating layer relu4
I0525 18:57:59.930207 25020 net.cpp:106] Creating Layer relu4
I0525 18:57:59.930217 25020 net.cpp:454] relu4 <- conv4
I0525 18:57:59.930229 25020 net.cpp:397] relu4 -> conv4 (in-place)
I0525 18:57:59.930702 25020 net.cpp:150] Setting up relu4
I0525 18:57:59.930718 25020 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 18:57:59.930728 25020 net.cpp:165] Memory required for data: 155702800
I0525 18:57:59.930739 25020 layer_factory.hpp:77] Creating layer pool4
I0525 18:57:59.930752 25020 net.cpp:106] Creating Layer pool4
I0525 18:57:59.930763 25020 net.cpp:454] pool4 <- conv4
I0525 18:57:59.930775 25020 net.cpp:411] pool4 -> pool4
I0525 18:57:59.930846 25020 net.cpp:150] Setting up pool4
I0525 18:57:59.930860 25020 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 18:57:59.930869 25020 net.cpp:165] Memory required for data: 157517200
I0525 18:57:59.930881 25020 layer_factory.hpp:77] Creating layer ip1
I0525 18:57:59.930896 25020 net.cpp:106] Creating Layer ip1
I0525 18:57:59.930907 25020 net.cpp:454] ip1 <- pool4
I0525 18:57:59.930920 25020 net.cpp:411] ip1 -> ip1
I0525 18:57:59.946427 25020 net.cpp:150] Setting up ip1
I0525 18:57:59.946456 25020 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:57:59.946467 25020 net.cpp:165] Memory required for data: 157595600
I0525 18:57:59.946488 25020 layer_factory.hpp:77] Creating layer relu5
I0525 18:57:59.946504 25020 net.cpp:106] Creating Layer relu5
I0525 18:57:59.946514 25020 net.cpp:454] relu5 <- ip1
I0525 18:57:59.946527 25020 net.cpp:397] relu5 -> ip1 (in-place)
I0525 18:57:59.946877 25020 net.cpp:150] Setting up relu5
I0525 18:57:59.946892 25020 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:57:59.946902 25020 net.cpp:165] Memory required for data: 157674000
I0525 18:57:59.946912 25020 layer_factory.hpp:77] Creating layer drop1
I0525 18:57:59.946930 25020 net.cpp:106] Creating Layer drop1
I0525 18:57:59.946940 25020 net.cpp:454] drop1 <- ip1
I0525 18:57:59.946954 25020 net.cpp:397] drop1 -> ip1 (in-place)
I0525 18:57:59.946998 25020 net.cpp:150] Setting up drop1
I0525 18:57:59.947011 25020 net.cpp:157] Top shape: 100 196 (19600)
I0525 18:57:59.947022 25020 net.cpp:165] Memory required for data: 157752400
I0525 18:57:59.947032 25020 layer_factory.hpp:77] Creating layer ip2
I0525 18:57:59.947046 25020 net.cpp:106] Creating Layer ip2
I0525 18:57:59.947057 25020 net.cpp:454] ip2 <- ip1
I0525 18:57:59.947070 25020 net.cpp:411] ip2 -> ip2
I0525 18:57:59.947551 25020 net.cpp:150] Setting up ip2
I0525 18:57:59.947563 25020 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:57:59.947573 25020 net.cpp:165] Memory required for data: 157791600
I0525 18:57:59.947589 25020 layer_factory.hpp:77] Creating layer relu6
I0525 18:57:59.947614 25020 net.cpp:106] Creating Layer relu6
I0525 18:57:59.947624 25020 net.cpp:454] relu6 <- ip2
I0525 18:57:59.947638 25020 net.cpp:397] relu6 -> ip2 (in-place)
I0525 18:57:59.948179 25020 net.cpp:150] Setting up relu6
I0525 18:57:59.948200 25020 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:57:59.948210 25020 net.cpp:165] Memory required for data: 157830800
I0525 18:57:59.948220 25020 layer_factory.hpp:77] Creating layer drop2
I0525 18:57:59.948235 25020 net.cpp:106] Creating Layer drop2
I0525 18:57:59.948245 25020 net.cpp:454] drop2 <- ip2
I0525 18:57:59.948257 25020 net.cpp:397] drop2 -> ip2 (in-place)
I0525 18:57:59.948300 25020 net.cpp:150] Setting up drop2
I0525 18:57:59.948314 25020 net.cpp:157] Top shape: 100 98 (9800)
I0525 18:57:59.948323 25020 net.cpp:165] Memory required for data: 157870000
I0525 18:57:59.948333 25020 layer_factory.hpp:77] Creating layer ip3
I0525 18:57:59.948348 25020 net.cpp:106] Creating Layer ip3
I0525 18:57:59.948357 25020 net.cpp:454] ip3 <- ip2
I0525 18:57:59.948371 25020 net.cpp:411] ip3 -> ip3
I0525 18:57:59.948595 25020 net.cpp:150] Setting up ip3
I0525 18:57:59.948608 25020 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:57:59.948617 25020 net.cpp:165] Memory required for data: 157874400
I0525 18:57:59.948633 25020 layer_factory.hpp:77] Creating layer drop3
I0525 18:57:59.948647 25020 net.cpp:106] Creating Layer drop3
I0525 18:57:59.948657 25020 net.cpp:454] drop3 <- ip3
I0525 18:57:59.948669 25020 net.cpp:397] drop3 -> ip3 (in-place)
I0525 18:57:59.948710 25020 net.cpp:150] Setting up drop3
I0525 18:57:59.948724 25020 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:57:59.948734 25020 net.cpp:165] Memory required for data: 157878800
I0525 18:57:59.948742 25020 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 18:57:59.948756 25020 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 18:57:59.948765 25020 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 18:57:59.948778 25020 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 18:57:59.948793 25020 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 18:57:59.948868 25020 net.cpp:150] Setting up ip3_drop3_0_split
I0525 18:57:59.948880 25020 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:57:59.948892 25020 net.cpp:157] Top shape: 100 11 (1100)
I0525 18:57:59.948904 25020 net.cpp:165] Memory required for data: 157887600
I0525 18:57:59.948915 25020 layer_factory.hpp:77] Creating layer accuracy
I0525 18:57:59.948935 25020 net.cpp:106] Creating Layer accuracy
I0525 18:57:59.948945 25020 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 18:57:59.948956 25020 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 18:57:59.948971 25020 net.cpp:411] accuracy -> accuracy
I0525 18:57:59.948993 25020 net.cpp:150] Setting up accuracy
I0525 18:57:59.949007 25020 net.cpp:157] Top shape: (1)
I0525 18:57:59.949017 25020 net.cpp:165] Memory required for data: 157887604
I0525 18:57:59.949026 25020 layer_factory.hpp:77] Creating layer loss
I0525 18:57:59.949046 25020 net.cpp:106] Creating Layer loss
I0525 18:57:59.949056 25020 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 18:57:59.949067 25020 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 18:57:59.949081 25020 net.cpp:411] loss -> loss
I0525 18:57:59.949100 25020 layer_factory.hpp:77] Creating layer loss
I0525 18:57:59.949586 25020 net.cpp:150] Setting up loss
I0525 18:57:59.949600 25020 net.cpp:157] Top shape: (1)
I0525 18:57:59.949610 25020 net.cpp:160]     with loss weight 1
I0525 18:57:59.949628 25020 net.cpp:165] Memory required for data: 157887608
I0525 18:57:59.949638 25020 net.cpp:226] loss needs backward computation.
I0525 18:57:59.949650 25020 net.cpp:228] accuracy does not need backward computation.
I0525 18:57:59.949661 25020 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 18:57:59.949671 25020 net.cpp:226] drop3 needs backward computation.
I0525 18:57:59.949681 25020 net.cpp:226] ip3 needs backward computation.
I0525 18:57:59.949692 25020 net.cpp:226] drop2 needs backward computation.
I0525 18:57:59.949710 25020 net.cpp:226] relu6 needs backward computation.
I0525 18:57:59.949719 25020 net.cpp:226] ip2 needs backward computation.
I0525 18:57:59.949729 25020 net.cpp:226] drop1 needs backward computation.
I0525 18:57:59.949739 25020 net.cpp:226] relu5 needs backward computation.
I0525 18:57:59.949748 25020 net.cpp:226] ip1 needs backward computation.
I0525 18:57:59.949759 25020 net.cpp:226] pool4 needs backward computation.
I0525 18:57:59.949769 25020 net.cpp:226] relu4 needs backward computation.
I0525 18:57:59.949779 25020 net.cpp:226] conv4 needs backward computation.
I0525 18:57:59.949789 25020 net.cpp:226] pool3 needs backward computation.
I0525 18:57:59.949796 25020 net.cpp:226] relu3 needs backward computation.
I0525 18:57:59.949807 25020 net.cpp:226] conv3 needs backward computation.
I0525 18:57:59.949817 25020 net.cpp:226] pool2 needs backward computation.
I0525 18:57:59.949826 25020 net.cpp:226] relu2 needs backward computation.
I0525 18:57:59.949836 25020 net.cpp:226] conv2 needs backward computation.
I0525 18:57:59.949847 25020 net.cpp:226] pool1 needs backward computation.
I0525 18:57:59.949857 25020 net.cpp:226] relu1 needs backward computation.
I0525 18:57:59.949867 25020 net.cpp:226] conv1 needs backward computation.
I0525 18:57:59.949877 25020 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 18:57:59.949889 25020 net.cpp:228] data_hdf5 does not need backward computation.
I0525 18:57:59.949898 25020 net.cpp:270] This network produces output accuracy
I0525 18:57:59.949909 25020 net.cpp:270] This network produces output loss
I0525 18:57:59.949939 25020 net.cpp:283] Network initialization done.
I0525 18:57:59.950070 25020 solver.cpp:60] Solver scaffolding done.
I0525 18:57:59.951239 25020 caffe.cpp:212] Starting Optimization
I0525 18:57:59.951252 25020 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 18:57:59.951266 25020 solver.cpp:289] Learning Rate Policy: fixed
I0525 18:57:59.952342 25020 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 18:58:47.782763 25020 solver.cpp:409]     Test net output #0: accuracy = 0.0499867
I0525 18:58:47.782922 25020 solver.cpp:409]     Test net output #1: loss = 2.39837 (* 1 = 2.39837 loss)
I0525 18:58:47.815873 25020 solver.cpp:237] Iteration 0, loss = 2.39593
I0525 18:58:47.815910 25020 solver.cpp:253]     Train net output #0: loss = 2.39593 (* 1 = 2.39593 loss)
I0525 18:58:47.815928 25020 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0525 18:58:56.535753 25020 solver.cpp:237] Iteration 150, loss = 2.29169
I0525 18:58:56.535789 25020 solver.cpp:253]     Train net output #0: loss = 2.29169 (* 1 = 2.29169 loss)
I0525 18:58:56.535806 25020 sgd_solver.cpp:106] Iteration 150, lr = 0.0035
I0525 18:59:05.255342 25020 solver.cpp:237] Iteration 300, loss = 2.25118
I0525 18:59:05.255388 25020 solver.cpp:253]     Train net output #0: loss = 2.25118 (* 1 = 2.25118 loss)
I0525 18:59:05.255405 25020 sgd_solver.cpp:106] Iteration 300, lr = 0.0035
I0525 18:59:13.974700 25020 solver.cpp:237] Iteration 450, loss = 1.93763
I0525 18:59:13.974736 25020 solver.cpp:253]     Train net output #0: loss = 1.93763 (* 1 = 1.93763 loss)
I0525 18:59:13.974753 25020 sgd_solver.cpp:106] Iteration 450, lr = 0.0035
I0525 18:59:22.693143 25020 solver.cpp:237] Iteration 600, loss = 2.03492
I0525 18:59:22.693292 25020 solver.cpp:253]     Train net output #0: loss = 2.03492 (* 1 = 2.03492 loss)
I0525 18:59:22.693307 25020 sgd_solver.cpp:106] Iteration 600, lr = 0.0035
I0525 18:59:31.414218 25020 solver.cpp:237] Iteration 750, loss = 1.75689
I0525 18:59:31.414263 25020 solver.cpp:253]     Train net output #0: loss = 1.75689 (* 1 = 1.75689 loss)
I0525 18:59:31.414280 25020 sgd_solver.cpp:106] Iteration 750, lr = 0.0035
I0525 18:59:40.130964 25020 solver.cpp:237] Iteration 900, loss = 1.97294
I0525 18:59:40.131000 25020 solver.cpp:253]     Train net output #0: loss = 1.97294 (* 1 = 1.97294 loss)
I0525 18:59:40.131016 25020 sgd_solver.cpp:106] Iteration 900, lr = 0.0035
I0525 19:00:10.968248 25020 solver.cpp:237] Iteration 1050, loss = 1.82621
I0525 19:00:10.968411 25020 solver.cpp:253]     Train net output #0: loss = 1.82621 (* 1 = 1.82621 loss)
I0525 19:00:10.968427 25020 sgd_solver.cpp:106] Iteration 1050, lr = 0.0035
I0525 19:00:19.695977 25020 solver.cpp:237] Iteration 1200, loss = 1.72781
I0525 19:00:19.696023 25020 solver.cpp:253]     Train net output #0: loss = 1.72781 (* 1 = 1.72781 loss)
I0525 19:00:19.696040 25020 sgd_solver.cpp:106] Iteration 1200, lr = 0.0035
I0525 19:00:28.415750 25020 solver.cpp:237] Iteration 1350, loss = 1.80718
I0525 19:00:28.415784 25020 solver.cpp:253]     Train net output #0: loss = 1.80718 (* 1 = 1.80718 loss)
I0525 19:00:28.415801 25020 sgd_solver.cpp:106] Iteration 1350, lr = 0.0035
I0525 19:00:37.083400 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_1500.caffemodel
I0525 19:00:37.165879 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_1500.solverstate
I0525 19:00:37.211163 25020 solver.cpp:237] Iteration 1500, loss = 1.82991
I0525 19:00:37.211212 25020 solver.cpp:253]     Train net output #0: loss = 1.82991 (* 1 = 1.82991 loss)
I0525 19:00:37.211226 25020 sgd_solver.cpp:106] Iteration 1500, lr = 0.0035
I0525 19:00:45.934623 25020 solver.cpp:237] Iteration 1650, loss = 1.77283
I0525 19:00:45.934772 25020 solver.cpp:253]     Train net output #0: loss = 1.77283 (* 1 = 1.77283 loss)
I0525 19:00:45.934787 25020 sgd_solver.cpp:106] Iteration 1650, lr = 0.0035
I0525 19:00:54.646685 25020 solver.cpp:237] Iteration 1800, loss = 1.42558
I0525 19:00:54.646719 25020 solver.cpp:253]     Train net output #0: loss = 1.42558 (* 1 = 1.42558 loss)
I0525 19:00:54.646734 25020 sgd_solver.cpp:106] Iteration 1800, lr = 0.0035
I0525 19:01:03.359555 25020 solver.cpp:237] Iteration 1950, loss = 1.63051
I0525 19:01:03.359589 25020 solver.cpp:253]     Train net output #0: loss = 1.63051 (* 1 = 1.63051 loss)
I0525 19:01:03.359606 25020 sgd_solver.cpp:106] Iteration 1950, lr = 0.0035
I0525 19:01:34.222200 25020 solver.cpp:237] Iteration 2100, loss = 1.43167
I0525 19:01:34.222357 25020 solver.cpp:253]     Train net output #0: loss = 1.43167 (* 1 = 1.43167 loss)
I0525 19:01:34.222371 25020 sgd_solver.cpp:106] Iteration 2100, lr = 0.0035
I0525 19:01:42.948741 25020 solver.cpp:237] Iteration 2250, loss = 1.64862
I0525 19:01:42.948776 25020 solver.cpp:253]     Train net output #0: loss = 1.64862 (* 1 = 1.64862 loss)
I0525 19:01:42.948792 25020 sgd_solver.cpp:106] Iteration 2250, lr = 0.0035
I0525 19:01:51.667183 25020 solver.cpp:237] Iteration 2400, loss = 1.62325
I0525 19:01:51.667219 25020 solver.cpp:253]     Train net output #0: loss = 1.62325 (* 1 = 1.62325 loss)
I0525 19:01:51.667237 25020 sgd_solver.cpp:106] Iteration 2400, lr = 0.0035
I0525 19:02:00.387739 25020 solver.cpp:237] Iteration 2550, loss = 1.68235
I0525 19:02:00.387778 25020 solver.cpp:253]     Train net output #0: loss = 1.68235 (* 1 = 1.68235 loss)
I0525 19:02:00.387799 25020 sgd_solver.cpp:106] Iteration 2550, lr = 0.0035
I0525 19:02:09.110121 25020 solver.cpp:237] Iteration 2700, loss = 1.62496
I0525 19:02:09.110267 25020 solver.cpp:253]     Train net output #0: loss = 1.62496 (* 1 = 1.62496 loss)
I0525 19:02:09.110281 25020 sgd_solver.cpp:106] Iteration 2700, lr = 0.0035
I0525 19:02:17.828269 25020 solver.cpp:237] Iteration 2850, loss = 1.56171
I0525 19:02:17.828304 25020 solver.cpp:253]     Train net output #0: loss = 1.56171 (* 1 = 1.56171 loss)
I0525 19:02:17.828320 25020 sgd_solver.cpp:106] Iteration 2850, lr = 0.0035
I0525 19:02:26.492784 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_3000.caffemodel
I0525 19:02:26.571856 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_3000.solverstate
I0525 19:02:26.597952 25020 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 19:03:13.470793 25020 solver.cpp:409]     Test net output #0: accuracy = 0.756287
I0525 19:03:13.470952 25020 solver.cpp:409]     Test net output #1: loss = 0.873901 (* 1 = 0.873901 loss)
I0525 19:03:35.629766 25020 solver.cpp:237] Iteration 3000, loss = 1.54423
I0525 19:03:35.629818 25020 solver.cpp:253]     Train net output #0: loss = 1.54423 (* 1 = 1.54423 loss)
I0525 19:03:35.629835 25020 sgd_solver.cpp:106] Iteration 3000, lr = 0.0035
I0525 19:03:44.356672 25020 solver.cpp:237] Iteration 3150, loss = 1.68005
I0525 19:03:44.356813 25020 solver.cpp:253]     Train net output #0: loss = 1.68005 (* 1 = 1.68005 loss)
I0525 19:03:44.356827 25020 sgd_solver.cpp:106] Iteration 3150, lr = 0.0035
I0525 19:03:53.078428 25020 solver.cpp:237] Iteration 3300, loss = 1.60763
I0525 19:03:53.078462 25020 solver.cpp:253]     Train net output #0: loss = 1.60763 (* 1 = 1.60763 loss)
I0525 19:03:53.078480 25020 sgd_solver.cpp:106] Iteration 3300, lr = 0.0035
I0525 19:04:01.804512 25020 solver.cpp:237] Iteration 3450, loss = 1.71955
I0525 19:04:01.804560 25020 solver.cpp:253]     Train net output #0: loss = 1.71955 (* 1 = 1.71955 loss)
I0525 19:04:01.804574 25020 sgd_solver.cpp:106] Iteration 3450, lr = 0.0035
I0525 19:04:10.531131 25020 solver.cpp:237] Iteration 3600, loss = 1.61565
I0525 19:04:10.531164 25020 solver.cpp:253]     Train net output #0: loss = 1.61565 (* 1 = 1.61565 loss)
I0525 19:04:10.531183 25020 sgd_solver.cpp:106] Iteration 3600, lr = 0.0035
I0525 19:04:19.255924 25020 solver.cpp:237] Iteration 3750, loss = 1.576
I0525 19:04:19.256062 25020 solver.cpp:253]     Train net output #0: loss = 1.576 (* 1 = 1.576 loss)
I0525 19:04:19.256077 25020 sgd_solver.cpp:106] Iteration 3750, lr = 0.0035
I0525 19:04:27.980036 25020 solver.cpp:237] Iteration 3900, loss = 1.32623
I0525 19:04:27.980072 25020 solver.cpp:253]     Train net output #0: loss = 1.32623 (* 1 = 1.32623 loss)
I0525 19:04:27.980095 25020 sgd_solver.cpp:106] Iteration 3900, lr = 0.0035
I0525 19:04:58.855170 25020 solver.cpp:237] Iteration 4050, loss = 1.53498
I0525 19:04:58.855332 25020 solver.cpp:253]     Train net output #0: loss = 1.53498 (* 1 = 1.53498 loss)
I0525 19:04:58.855348 25020 sgd_solver.cpp:106] Iteration 4050, lr = 0.0035
I0525 19:05:07.581822 25020 solver.cpp:237] Iteration 4200, loss = 1.34045
I0525 19:05:07.581856 25020 solver.cpp:253]     Train net output #0: loss = 1.34045 (* 1 = 1.34045 loss)
I0525 19:05:07.581873 25020 sgd_solver.cpp:106] Iteration 4200, lr = 0.0035
I0525 19:05:16.300611 25020 solver.cpp:237] Iteration 4350, loss = 1.37481
I0525 19:05:16.300650 25020 solver.cpp:253]     Train net output #0: loss = 1.37481 (* 1 = 1.37481 loss)
I0525 19:05:16.300670 25020 sgd_solver.cpp:106] Iteration 4350, lr = 0.0035
I0525 19:05:24.970825 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_4500.caffemodel
I0525 19:05:25.050545 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_4500.solverstate
I0525 19:05:25.095862 25020 solver.cpp:237] Iteration 4500, loss = 1.16952
I0525 19:05:25.095912 25020 solver.cpp:253]     Train net output #0: loss = 1.16952 (* 1 = 1.16952 loss)
I0525 19:05:25.095927 25020 sgd_solver.cpp:106] Iteration 4500, lr = 0.0035
I0525 19:05:33.822401 25020 solver.cpp:237] Iteration 4650, loss = 1.58148
I0525 19:05:33.822564 25020 solver.cpp:253]     Train net output #0: loss = 1.58148 (* 1 = 1.58148 loss)
I0525 19:05:33.822577 25020 sgd_solver.cpp:106] Iteration 4650, lr = 0.0035
I0525 19:05:42.548601 25020 solver.cpp:237] Iteration 4800, loss = 1.62987
I0525 19:05:42.548645 25020 solver.cpp:253]     Train net output #0: loss = 1.62987 (* 1 = 1.62987 loss)
I0525 19:05:42.548663 25020 sgd_solver.cpp:106] Iteration 4800, lr = 0.0035
I0525 19:05:51.274377 25020 solver.cpp:237] Iteration 4950, loss = 1.61324
I0525 19:05:51.274412 25020 solver.cpp:253]     Train net output #0: loss = 1.61324 (* 1 = 1.61324 loss)
I0525 19:05:51.274428 25020 sgd_solver.cpp:106] Iteration 4950, lr = 0.0035
I0525 19:06:22.126341 25020 solver.cpp:237] Iteration 5100, loss = 1.18966
I0525 19:06:22.126502 25020 solver.cpp:253]     Train net output #0: loss = 1.18966 (* 1 = 1.18966 loss)
I0525 19:06:22.126518 25020 sgd_solver.cpp:106] Iteration 5100, lr = 0.0035
I0525 19:06:30.850072 25020 solver.cpp:237] Iteration 5250, loss = 1.24565
I0525 19:06:30.850112 25020 solver.cpp:253]     Train net output #0: loss = 1.24565 (* 1 = 1.24565 loss)
I0525 19:06:30.850134 25020 sgd_solver.cpp:106] Iteration 5250, lr = 0.0035
I0525 19:06:39.575124 25020 solver.cpp:237] Iteration 5400, loss = 1.20931
I0525 19:06:39.575160 25020 solver.cpp:253]     Train net output #0: loss = 1.20931 (* 1 = 1.20931 loss)
I0525 19:06:39.575176 25020 sgd_solver.cpp:106] Iteration 5400, lr = 0.0035
I0525 19:06:48.308100 25020 solver.cpp:237] Iteration 5550, loss = 1.38755
I0525 19:06:48.308135 25020 solver.cpp:253]     Train net output #0: loss = 1.38755 (* 1 = 1.38755 loss)
I0525 19:06:48.308151 25020 sgd_solver.cpp:106] Iteration 5550, lr = 0.0035
I0525 19:06:57.038732 25020 solver.cpp:237] Iteration 5700, loss = 1.39711
I0525 19:06:57.038884 25020 solver.cpp:253]     Train net output #0: loss = 1.39711 (* 1 = 1.39711 loss)
I0525 19:06:57.038898 25020 sgd_solver.cpp:106] Iteration 5700, lr = 0.0035
I0525 19:07:05.763545 25020 solver.cpp:237] Iteration 5850, loss = 1.26655
I0525 19:07:05.763581 25020 solver.cpp:253]     Train net output #0: loss = 1.26655 (* 1 = 1.26655 loss)
I0525 19:07:05.763597 25020 sgd_solver.cpp:106] Iteration 5850, lr = 0.0035
I0525 19:07:14.426429 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_6000.caffemodel
I0525 19:07:14.506737 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_6000.solverstate
I0525 19:07:14.534137 25020 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 19:08:22.192167 25020 solver.cpp:409]     Test net output #0: accuracy = 0.8215
I0525 19:08:22.192338 25020 solver.cpp:409]     Test net output #1: loss = 0.69474 (* 1 = 0.69474 loss)
I0525 19:08:44.432055 25020 solver.cpp:237] Iteration 6000, loss = 1.45125
I0525 19:08:44.432106 25020 solver.cpp:253]     Train net output #0: loss = 1.45125 (* 1 = 1.45125 loss)
I0525 19:08:44.432126 25020 sgd_solver.cpp:106] Iteration 6000, lr = 0.0035
I0525 19:08:53.154258 25020 solver.cpp:237] Iteration 6150, loss = 1.26626
I0525 19:08:53.154407 25020 solver.cpp:253]     Train net output #0: loss = 1.26626 (* 1 = 1.26626 loss)
I0525 19:08:53.154423 25020 sgd_solver.cpp:106] Iteration 6150, lr = 0.0035
I0525 19:09:01.877621 25020 solver.cpp:237] Iteration 6300, loss = 1.51844
I0525 19:09:01.877662 25020 solver.cpp:253]     Train net output #0: loss = 1.51844 (* 1 = 1.51844 loss)
I0525 19:09:01.877682 25020 sgd_solver.cpp:106] Iteration 6300, lr = 0.0035
I0525 19:09:10.595444 25020 solver.cpp:237] Iteration 6450, loss = 1.51724
I0525 19:09:10.595479 25020 solver.cpp:253]     Train net output #0: loss = 1.51724 (* 1 = 1.51724 loss)
I0525 19:09:10.595495 25020 sgd_solver.cpp:106] Iteration 6450, lr = 0.0035
I0525 19:09:19.318877 25020 solver.cpp:237] Iteration 6600, loss = 1.45706
I0525 19:09:19.318912 25020 solver.cpp:253]     Train net output #0: loss = 1.45706 (* 1 = 1.45706 loss)
I0525 19:09:19.318936 25020 sgd_solver.cpp:106] Iteration 6600, lr = 0.0035
I0525 19:09:28.041379 25020 solver.cpp:237] Iteration 6750, loss = 1.4351
I0525 19:09:28.041529 25020 solver.cpp:253]     Train net output #0: loss = 1.4351 (* 1 = 1.4351 loss)
I0525 19:09:28.041543 25020 sgd_solver.cpp:106] Iteration 6750, lr = 0.0035
I0525 19:09:36.762295 25020 solver.cpp:237] Iteration 6900, loss = 1.31649
I0525 19:09:36.762329 25020 solver.cpp:253]     Train net output #0: loss = 1.31649 (* 1 = 1.31649 loss)
I0525 19:09:36.762346 25020 sgd_solver.cpp:106] Iteration 6900, lr = 0.0035
I0525 19:10:07.716925 25020 solver.cpp:237] Iteration 7050, loss = 1.29324
I0525 19:10:07.717092 25020 solver.cpp:253]     Train net output #0: loss = 1.29324 (* 1 = 1.29324 loss)
I0525 19:10:07.717108 25020 sgd_solver.cpp:106] Iteration 7050, lr = 0.0035
I0525 19:10:16.433200 25020 solver.cpp:237] Iteration 7200, loss = 1.36962
I0525 19:10:16.433243 25020 solver.cpp:253]     Train net output #0: loss = 1.36962 (* 1 = 1.36962 loss)
I0525 19:10:16.433259 25020 sgd_solver.cpp:106] Iteration 7200, lr = 0.0035
I0525 19:10:25.157627 25020 solver.cpp:237] Iteration 7350, loss = 1.22647
I0525 19:10:25.157663 25020 solver.cpp:253]     Train net output #0: loss = 1.22647 (* 1 = 1.22647 loss)
I0525 19:10:25.157676 25020 sgd_solver.cpp:106] Iteration 7350, lr = 0.0035
I0525 19:10:33.816577 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_7500.caffemodel
I0525 19:10:33.896953 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_7500.solverstate
I0525 19:10:33.942309 25020 solver.cpp:237] Iteration 7500, loss = 1.37152
I0525 19:10:33.942354 25020 solver.cpp:253]     Train net output #0: loss = 1.37152 (* 1 = 1.37152 loss)
I0525 19:10:33.942374 25020 sgd_solver.cpp:106] Iteration 7500, lr = 0.0035
I0525 19:10:42.664989 25020 solver.cpp:237] Iteration 7650, loss = 1.28538
I0525 19:10:42.665161 25020 solver.cpp:253]     Train net output #0: loss = 1.28538 (* 1 = 1.28538 loss)
I0525 19:10:42.665175 25020 sgd_solver.cpp:106] Iteration 7650, lr = 0.0035
I0525 19:10:51.377650 25020 solver.cpp:237] Iteration 7800, loss = 1.34472
I0525 19:10:51.377683 25020 solver.cpp:253]     Train net output #0: loss = 1.34472 (* 1 = 1.34472 loss)
I0525 19:10:51.377701 25020 sgd_solver.cpp:106] Iteration 7800, lr = 0.0035
I0525 19:11:00.097730 25020 solver.cpp:237] Iteration 7950, loss = 1.42156
I0525 19:11:00.097765 25020 solver.cpp:253]     Train net output #0: loss = 1.42156 (* 1 = 1.42156 loss)
I0525 19:11:00.097781 25020 sgd_solver.cpp:106] Iteration 7950, lr = 0.0035
I0525 19:11:31.070245 25020 solver.cpp:237] Iteration 8100, loss = 1.41249
I0525 19:11:31.070413 25020 solver.cpp:253]     Train net output #0: loss = 1.41249 (* 1 = 1.41249 loss)
I0525 19:11:31.070428 25020 sgd_solver.cpp:106] Iteration 8100, lr = 0.0035
I0525 19:11:39.793686 25020 solver.cpp:237] Iteration 8250, loss = 1.18258
I0525 19:11:39.793720 25020 solver.cpp:253]     Train net output #0: loss = 1.18258 (* 1 = 1.18258 loss)
I0525 19:11:39.793738 25020 sgd_solver.cpp:106] Iteration 8250, lr = 0.0035
I0525 19:11:48.514014 25020 solver.cpp:237] Iteration 8400, loss = 1.4338
I0525 19:11:48.514050 25020 solver.cpp:253]     Train net output #0: loss = 1.4338 (* 1 = 1.4338 loss)
I0525 19:11:48.514062 25020 sgd_solver.cpp:106] Iteration 8400, lr = 0.0035
I0525 19:11:57.237715 25020 solver.cpp:237] Iteration 8550, loss = 1.25141
I0525 19:11:57.237761 25020 solver.cpp:253]     Train net output #0: loss = 1.25141 (* 1 = 1.25141 loss)
I0525 19:11:57.237777 25020 sgd_solver.cpp:106] Iteration 8550, lr = 0.0035
I0525 19:12:05.958490 25020 solver.cpp:237] Iteration 8700, loss = 1.47654
I0525 19:12:05.958641 25020 solver.cpp:253]     Train net output #0: loss = 1.47654 (* 1 = 1.47654 loss)
I0525 19:12:05.958654 25020 sgd_solver.cpp:106] Iteration 8700, lr = 0.0035
I0525 19:12:14.679042 25020 solver.cpp:237] Iteration 8850, loss = 1.02452
I0525 19:12:14.679077 25020 solver.cpp:253]     Train net output #0: loss = 1.02452 (* 1 = 1.02452 loss)
I0525 19:12:14.679095 25020 sgd_solver.cpp:106] Iteration 8850, lr = 0.0035
I0525 19:12:23.345418 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_9000.caffemodel
I0525 19:12:23.423550 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_9000.solverstate
I0525 19:12:23.448534 25020 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 19:13:09.970223 25020 solver.cpp:409]     Test net output #0: accuracy = 0.835372
I0525 19:13:09.970402 25020 solver.cpp:409]     Test net output #1: loss = 0.538034 (* 1 = 0.538034 loss)
I0525 19:13:32.212368 25020 solver.cpp:237] Iteration 9000, loss = 1.25921
I0525 19:13:32.212420 25020 solver.cpp:253]     Train net output #0: loss = 1.25921 (* 1 = 1.25921 loss)
I0525 19:13:32.212435 25020 sgd_solver.cpp:106] Iteration 9000, lr = 0.0035
I0525 19:13:40.938733 25020 solver.cpp:237] Iteration 9150, loss = 1.13102
I0525 19:13:40.938894 25020 solver.cpp:253]     Train net output #0: loss = 1.13102 (* 1 = 1.13102 loss)
I0525 19:13:40.938907 25020 sgd_solver.cpp:106] Iteration 9150, lr = 0.0035
I0525 19:13:49.669140 25020 solver.cpp:237] Iteration 9300, loss = 1.17052
I0525 19:13:49.669175 25020 solver.cpp:253]     Train net output #0: loss = 1.17052 (* 1 = 1.17052 loss)
I0525 19:13:49.669190 25020 sgd_solver.cpp:106] Iteration 9300, lr = 0.0035
I0525 19:13:58.397363 25020 solver.cpp:237] Iteration 9450, loss = 1.45184
I0525 19:13:58.397398 25020 solver.cpp:253]     Train net output #0: loss = 1.45184 (* 1 = 1.45184 loss)
I0525 19:13:58.397414 25020 sgd_solver.cpp:106] Iteration 9450, lr = 0.0035
I0525 19:14:07.123400 25020 solver.cpp:237] Iteration 9600, loss = 1.39952
I0525 19:14:07.123431 25020 solver.cpp:253]     Train net output #0: loss = 1.39952 (* 1 = 1.39952 loss)
I0525 19:14:07.123456 25020 sgd_solver.cpp:106] Iteration 9600, lr = 0.0035
I0525 19:14:15.845496 25020 solver.cpp:237] Iteration 9750, loss = 1.4094
I0525 19:14:15.845638 25020 solver.cpp:253]     Train net output #0: loss = 1.4094 (* 1 = 1.4094 loss)
I0525 19:14:15.845650 25020 sgd_solver.cpp:106] Iteration 9750, lr = 0.0035
I0525 19:14:24.571132 25020 solver.cpp:237] Iteration 9900, loss = 1.15477
I0525 19:14:24.571171 25020 solver.cpp:253]     Train net output #0: loss = 1.15477 (* 1 = 1.15477 loss)
I0525 19:14:24.571193 25020 sgd_solver.cpp:106] Iteration 9900, lr = 0.0035
I0525 19:14:55.501446 25020 solver.cpp:237] Iteration 10050, loss = 1.16619
I0525 19:14:55.501623 25020 solver.cpp:253]     Train net output #0: loss = 1.16619 (* 1 = 1.16619 loss)
I0525 19:14:55.501638 25020 sgd_solver.cpp:106] Iteration 10050, lr = 0.0035
I0525 19:15:04.228585 25020 solver.cpp:237] Iteration 10200, loss = 1.39805
I0525 19:15:04.228618 25020 solver.cpp:253]     Train net output #0: loss = 1.39805 (* 1 = 1.39805 loss)
I0525 19:15:04.228636 25020 sgd_solver.cpp:106] Iteration 10200, lr = 0.0035
I0525 19:15:12.957629 25020 solver.cpp:237] Iteration 10350, loss = 1.18621
I0525 19:15:12.957664 25020 solver.cpp:253]     Train net output #0: loss = 1.18621 (* 1 = 1.18621 loss)
I0525 19:15:12.957679 25020 sgd_solver.cpp:106] Iteration 10350, lr = 0.0035
I0525 19:15:21.629945 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_10500.caffemodel
I0525 19:15:21.708395 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_10500.solverstate
I0525 19:15:21.752645 25020 solver.cpp:237] Iteration 10500, loss = 1.16559
I0525 19:15:21.752689 25020 solver.cpp:253]     Train net output #0: loss = 1.16559 (* 1 = 1.16559 loss)
I0525 19:15:21.752706 25020 sgd_solver.cpp:106] Iteration 10500, lr = 0.0035
I0525 19:15:30.482440 25020 solver.cpp:237] Iteration 10650, loss = 1.22391
I0525 19:15:30.482586 25020 solver.cpp:253]     Train net output #0: loss = 1.22391 (* 1 = 1.22391 loss)
I0525 19:15:30.482600 25020 sgd_solver.cpp:106] Iteration 10650, lr = 0.0035
I0525 19:15:39.209480 25020 solver.cpp:237] Iteration 10800, loss = 1.0761
I0525 19:15:39.209523 25020 solver.cpp:253]     Train net output #0: loss = 1.0761 (* 1 = 1.0761 loss)
I0525 19:15:39.209547 25020 sgd_solver.cpp:106] Iteration 10800, lr = 0.0035
I0525 19:15:47.936554 25020 solver.cpp:237] Iteration 10950, loss = 1.32992
I0525 19:15:47.936590 25020 solver.cpp:253]     Train net output #0: loss = 1.32992 (* 1 = 1.32992 loss)
I0525 19:15:47.936607 25020 sgd_solver.cpp:106] Iteration 10950, lr = 0.0035
I0525 19:16:18.861894 25020 solver.cpp:237] Iteration 11100, loss = 1.20124
I0525 19:16:18.862061 25020 solver.cpp:253]     Train net output #0: loss = 1.20124 (* 1 = 1.20124 loss)
I0525 19:16:18.862077 25020 sgd_solver.cpp:106] Iteration 11100, lr = 0.0035
I0525 19:16:27.591253 25020 solver.cpp:237] Iteration 11250, loss = 1.2626
I0525 19:16:27.591287 25020 solver.cpp:253]     Train net output #0: loss = 1.2626 (* 1 = 1.2626 loss)
I0525 19:16:27.591300 25020 sgd_solver.cpp:106] Iteration 11250, lr = 0.0035
I0525 19:16:36.320462 25020 solver.cpp:237] Iteration 11400, loss = 1.31049
I0525 19:16:36.320503 25020 solver.cpp:253]     Train net output #0: loss = 1.31049 (* 1 = 1.31049 loss)
I0525 19:16:36.320524 25020 sgd_solver.cpp:106] Iteration 11400, lr = 0.0035
I0525 19:16:45.053571 25020 solver.cpp:237] Iteration 11550, loss = 1.31579
I0525 19:16:45.053607 25020 solver.cpp:253]     Train net output #0: loss = 1.31579 (* 1 = 1.31579 loss)
I0525 19:16:45.053622 25020 sgd_solver.cpp:106] Iteration 11550, lr = 0.0035
I0525 19:16:53.779770 25020 solver.cpp:237] Iteration 11700, loss = 1.31662
I0525 19:16:53.779929 25020 solver.cpp:253]     Train net output #0: loss = 1.31662 (* 1 = 1.31662 loss)
I0525 19:16:53.779944 25020 sgd_solver.cpp:106] Iteration 11700, lr = 0.0035
I0525 19:17:02.510129 25020 solver.cpp:237] Iteration 11850, loss = 1.21394
I0525 19:17:02.510164 25020 solver.cpp:253]     Train net output #0: loss = 1.21394 (* 1 = 1.21394 loss)
I0525 19:17:02.510180 25020 sgd_solver.cpp:106] Iteration 11850, lr = 0.0035
I0525 19:17:11.176630 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_12000.caffemodel
I0525 19:17:11.254391 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_12000.solverstate
I0525 19:17:11.280539 25020 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 19:18:19.002514 25020 solver.cpp:409]     Test net output #0: accuracy = 0.853371
I0525 19:18:19.002691 25020 solver.cpp:409]     Test net output #1: loss = 0.478599 (* 1 = 0.478599 loss)
I0525 19:18:41.165798 25020 solver.cpp:237] Iteration 12000, loss = 1.30668
I0525 19:18:41.165853 25020 solver.cpp:253]     Train net output #0: loss = 1.30668 (* 1 = 1.30668 loss)
I0525 19:18:41.165866 25020 sgd_solver.cpp:106] Iteration 12000, lr = 0.0035
I0525 19:18:49.892833 25020 solver.cpp:237] Iteration 12150, loss = 1.23871
I0525 19:18:49.892987 25020 solver.cpp:253]     Train net output #0: loss = 1.23871 (* 1 = 1.23871 loss)
I0525 19:18:49.893002 25020 sgd_solver.cpp:106] Iteration 12150, lr = 0.0035
I0525 19:18:58.618058 25020 solver.cpp:237] Iteration 12300, loss = 1.18446
I0525 19:18:58.618101 25020 solver.cpp:253]     Train net output #0: loss = 1.18446 (* 1 = 1.18446 loss)
I0525 19:18:58.618116 25020 sgd_solver.cpp:106] Iteration 12300, lr = 0.0035
I0525 19:19:07.338248 25020 solver.cpp:237] Iteration 12450, loss = 1.20941
I0525 19:19:07.338284 25020 solver.cpp:253]     Train net output #0: loss = 1.20941 (* 1 = 1.20941 loss)
I0525 19:19:07.338300 25020 sgd_solver.cpp:106] Iteration 12450, lr = 0.0035
I0525 19:19:16.061563 25020 solver.cpp:237] Iteration 12600, loss = 1.12647
I0525 19:19:16.061599 25020 solver.cpp:253]     Train net output #0: loss = 1.12647 (* 1 = 1.12647 loss)
I0525 19:19:16.061614 25020 sgd_solver.cpp:106] Iteration 12600, lr = 0.0035
I0525 19:19:24.785544 25020 solver.cpp:237] Iteration 12750, loss = 1.25027
I0525 19:19:24.785702 25020 solver.cpp:253]     Train net output #0: loss = 1.25027 (* 1 = 1.25027 loss)
I0525 19:19:24.785717 25020 sgd_solver.cpp:106] Iteration 12750, lr = 0.0035
I0525 19:19:33.515110 25020 solver.cpp:237] Iteration 12900, loss = 1.01107
I0525 19:19:33.515144 25020 solver.cpp:253]     Train net output #0: loss = 1.01107 (* 1 = 1.01107 loss)
I0525 19:19:33.515161 25020 sgd_solver.cpp:106] Iteration 12900, lr = 0.0035
I0525 19:20:04.466250 25020 solver.cpp:237] Iteration 13050, loss = 1.34236
I0525 19:20:04.466416 25020 solver.cpp:253]     Train net output #0: loss = 1.34236 (* 1 = 1.34236 loss)
I0525 19:20:04.466433 25020 sgd_solver.cpp:106] Iteration 13050, lr = 0.0035
I0525 19:20:13.192239 25020 solver.cpp:237] Iteration 13200, loss = 1.31592
I0525 19:20:13.192272 25020 solver.cpp:253]     Train net output #0: loss = 1.31592 (* 1 = 1.31592 loss)
I0525 19:20:13.192291 25020 sgd_solver.cpp:106] Iteration 13200, lr = 0.0035
I0525 19:20:21.913664 25020 solver.cpp:237] Iteration 13350, loss = 1.20993
I0525 19:20:21.913702 25020 solver.cpp:253]     Train net output #0: loss = 1.20993 (* 1 = 1.20993 loss)
I0525 19:20:21.913723 25020 sgd_solver.cpp:106] Iteration 13350, lr = 0.0035
I0525 19:20:30.575675 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_13500.caffemodel
I0525 19:20:30.655340 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_13500.solverstate
I0525 19:20:30.701423 25020 solver.cpp:237] Iteration 13500, loss = 1.2579
I0525 19:20:30.701470 25020 solver.cpp:253]     Train net output #0: loss = 1.2579 (* 1 = 1.2579 loss)
I0525 19:20:30.701485 25020 sgd_solver.cpp:106] Iteration 13500, lr = 0.0035
I0525 19:20:39.431252 25020 solver.cpp:237] Iteration 13650, loss = 1.33777
I0525 19:20:39.431417 25020 solver.cpp:253]     Train net output #0: loss = 1.33777 (* 1 = 1.33777 loss)
I0525 19:20:39.431432 25020 sgd_solver.cpp:106] Iteration 13650, lr = 0.0035
I0525 19:20:48.147220 25020 solver.cpp:237] Iteration 13800, loss = 1.35571
I0525 19:20:48.147254 25020 solver.cpp:253]     Train net output #0: loss = 1.35571 (* 1 = 1.35571 loss)
I0525 19:20:48.147272 25020 sgd_solver.cpp:106] Iteration 13800, lr = 0.0035
I0525 19:20:56.869171 25020 solver.cpp:237] Iteration 13950, loss = 1.11871
I0525 19:20:56.869206 25020 solver.cpp:253]     Train net output #0: loss = 1.11871 (* 1 = 1.11871 loss)
I0525 19:20:56.869222 25020 sgd_solver.cpp:106] Iteration 13950, lr = 0.0035
I0525 19:21:27.750870 25020 solver.cpp:237] Iteration 14100, loss = 1.292
I0525 19:21:27.751049 25020 solver.cpp:253]     Train net output #0: loss = 1.292 (* 1 = 1.292 loss)
I0525 19:21:27.751066 25020 sgd_solver.cpp:106] Iteration 14100, lr = 0.0035
I0525 19:21:36.475520 25020 solver.cpp:237] Iteration 14250, loss = 1.19701
I0525 19:21:36.475569 25020 solver.cpp:253]     Train net output #0: loss = 1.19701 (* 1 = 1.19701 loss)
I0525 19:21:36.475582 25020 sgd_solver.cpp:106] Iteration 14250, lr = 0.0035
I0525 19:21:45.202615 25020 solver.cpp:237] Iteration 14400, loss = 1.28403
I0525 19:21:45.202649 25020 solver.cpp:253]     Train net output #0: loss = 1.28403 (* 1 = 1.28403 loss)
I0525 19:21:45.202662 25020 sgd_solver.cpp:106] Iteration 14400, lr = 0.0035
I0525 19:21:53.925637 25020 solver.cpp:237] Iteration 14550, loss = 1.45172
I0525 19:21:53.925679 25020 solver.cpp:253]     Train net output #0: loss = 1.45172 (* 1 = 1.45172 loss)
I0525 19:21:53.925696 25020 sgd_solver.cpp:106] Iteration 14550, lr = 0.0035
I0525 19:22:02.645691 25020 solver.cpp:237] Iteration 14700, loss = 1.06678
I0525 19:22:02.645848 25020 solver.cpp:253]     Train net output #0: loss = 1.06678 (* 1 = 1.06678 loss)
I0525 19:22:02.645862 25020 sgd_solver.cpp:106] Iteration 14700, lr = 0.0035
I0525 19:22:11.368523 25020 solver.cpp:237] Iteration 14850, loss = 1.31252
I0525 19:22:11.368558 25020 solver.cpp:253]     Train net output #0: loss = 1.31252 (* 1 = 1.31252 loss)
I0525 19:22:11.368576 25020 sgd_solver.cpp:106] Iteration 14850, lr = 0.0035
I0525 19:22:20.029641 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_15000.caffemodel
I0525 19:22:20.109050 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_15000.solverstate
I0525 19:22:20.137202 25020 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 19:23:06.969059 25020 solver.cpp:409]     Test net output #0: accuracy = 0.861926
I0525 19:23:06.969228 25020 solver.cpp:409]     Test net output #1: loss = 0.448017 (* 1 = 0.448017 loss)
I0525 19:23:27.865703 25020 solver.cpp:237] Iteration 15000, loss = 1.19899
I0525 19:23:27.865756 25020 solver.cpp:253]     Train net output #0: loss = 1.19899 (* 1 = 1.19899 loss)
I0525 19:23:27.865770 25020 sgd_solver.cpp:106] Iteration 15000, lr = 0.0035
I0525 19:23:36.595722 25020 solver.cpp:237] Iteration 15150, loss = 1.14646
I0525 19:23:36.595769 25020 solver.cpp:253]     Train net output #0: loss = 1.14646 (* 1 = 1.14646 loss)
I0525 19:23:36.595784 25020 sgd_solver.cpp:106] Iteration 15150, lr = 0.0035
I0525 19:23:45.323096 25020 solver.cpp:237] Iteration 15300, loss = 1.24028
I0525 19:23:45.323245 25020 solver.cpp:253]     Train net output #0: loss = 1.24028 (* 1 = 1.24028 loss)
I0525 19:23:45.323258 25020 sgd_solver.cpp:106] Iteration 15300, lr = 0.0035
I0525 19:23:54.053813 25020 solver.cpp:237] Iteration 15450, loss = 1.30411
I0525 19:23:54.053848 25020 solver.cpp:253]     Train net output #0: loss = 1.30411 (* 1 = 1.30411 loss)
I0525 19:23:54.053865 25020 sgd_solver.cpp:106] Iteration 15450, lr = 0.0035
I0525 19:24:02.780683 25020 solver.cpp:237] Iteration 15600, loss = 1.38686
I0525 19:24:02.780731 25020 solver.cpp:253]     Train net output #0: loss = 1.38686 (* 1 = 1.38686 loss)
I0525 19:24:02.780745 25020 sgd_solver.cpp:106] Iteration 15600, lr = 0.0035
I0525 19:24:11.509769 25020 solver.cpp:237] Iteration 15750, loss = 1.28291
I0525 19:24:11.509804 25020 solver.cpp:253]     Train net output #0: loss = 1.28291 (* 1 = 1.28291 loss)
I0525 19:24:11.509820 25020 sgd_solver.cpp:106] Iteration 15750, lr = 0.0035
I0525 19:24:20.240051 25020 solver.cpp:237] Iteration 15900, loss = 1.21636
I0525 19:24:20.240206 25020 solver.cpp:253]     Train net output #0: loss = 1.21636 (* 1 = 1.21636 loss)
I0525 19:24:20.240221 25020 sgd_solver.cpp:106] Iteration 15900, lr = 0.0035
I0525 19:24:49.835407 25020 solver.cpp:237] Iteration 16050, loss = 1.27982
I0525 19:24:49.835456 25020 solver.cpp:253]     Train net output #0: loss = 1.27982 (* 1 = 1.27982 loss)
I0525 19:24:49.835470 25020 sgd_solver.cpp:106] Iteration 16050, lr = 0.0035
I0525 19:24:58.562245 25020 solver.cpp:237] Iteration 16200, loss = 1.08319
I0525 19:24:58.562394 25020 solver.cpp:253]     Train net output #0: loss = 1.08319 (* 1 = 1.08319 loss)
I0525 19:24:58.562409 25020 sgd_solver.cpp:106] Iteration 16200, lr = 0.0035
I0525 19:25:07.284302 25020 solver.cpp:237] Iteration 16350, loss = 1.46522
I0525 19:25:07.284337 25020 solver.cpp:253]     Train net output #0: loss = 1.46522 (* 1 = 1.46522 loss)
I0525 19:25:07.284353 25020 sgd_solver.cpp:106] Iteration 16350, lr = 0.0035
I0525 19:25:15.952778 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_16500.caffemodel
I0525 19:25:16.030632 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_16500.solverstate
I0525 19:25:16.073801 25020 solver.cpp:237] Iteration 16500, loss = 1.15187
I0525 19:25:16.073842 25020 solver.cpp:253]     Train net output #0: loss = 1.15187 (* 1 = 1.15187 loss)
I0525 19:25:16.073861 25020 sgd_solver.cpp:106] Iteration 16500, lr = 0.0035
I0525 19:25:24.804730 25020 solver.cpp:237] Iteration 16650, loss = 1.50014
I0525 19:25:24.804765 25020 solver.cpp:253]     Train net output #0: loss = 1.50014 (* 1 = 1.50014 loss)
I0525 19:25:24.804781 25020 sgd_solver.cpp:106] Iteration 16650, lr = 0.0035
I0525 19:25:33.530517 25020 solver.cpp:237] Iteration 16800, loss = 1.11221
I0525 19:25:33.530668 25020 solver.cpp:253]     Train net output #0: loss = 1.11221 (* 1 = 1.11221 loss)
I0525 19:25:33.530680 25020 sgd_solver.cpp:106] Iteration 16800, lr = 0.0035
I0525 19:25:42.258476 25020 solver.cpp:237] Iteration 16950, loss = 1.43089
I0525 19:25:42.258514 25020 solver.cpp:253]     Train net output #0: loss = 1.43089 (* 1 = 1.43089 loss)
I0525 19:25:42.258534 25020 sgd_solver.cpp:106] Iteration 16950, lr = 0.0035
I0525 19:26:11.813860 25020 solver.cpp:237] Iteration 17100, loss = 1.10276
I0525 19:26:11.814031 25020 solver.cpp:253]     Train net output #0: loss = 1.10276 (* 1 = 1.10276 loss)
I0525 19:26:11.814045 25020 sgd_solver.cpp:106] Iteration 17100, lr = 0.0035
I0525 19:26:20.538926 25020 solver.cpp:237] Iteration 17250, loss = 1.16926
I0525 19:26:20.538959 25020 solver.cpp:253]     Train net output #0: loss = 1.16926 (* 1 = 1.16926 loss)
I0525 19:26:20.538971 25020 sgd_solver.cpp:106] Iteration 17250, lr = 0.0035
I0525 19:26:29.270721 25020 solver.cpp:237] Iteration 17400, loss = 1.03346
I0525 19:26:29.270768 25020 solver.cpp:253]     Train net output #0: loss = 1.03346 (* 1 = 1.03346 loss)
I0525 19:26:29.270781 25020 sgd_solver.cpp:106] Iteration 17400, lr = 0.0035
I0525 19:26:37.995349 25020 solver.cpp:237] Iteration 17550, loss = 1.11758
I0525 19:26:37.995384 25020 solver.cpp:253]     Train net output #0: loss = 1.11758 (* 1 = 1.11758 loss)
I0525 19:26:37.995398 25020 sgd_solver.cpp:106] Iteration 17550, lr = 0.0035
I0525 19:26:46.722131 25020 solver.cpp:237] Iteration 17700, loss = 1.19273
I0525 19:26:46.722277 25020 solver.cpp:253]     Train net output #0: loss = 1.19273 (* 1 = 1.19273 loss)
I0525 19:26:46.722291 25020 sgd_solver.cpp:106] Iteration 17700, lr = 0.0035
I0525 19:26:55.447722 25020 solver.cpp:237] Iteration 17850, loss = 1.32898
I0525 19:26:55.447769 25020 solver.cpp:253]     Train net output #0: loss = 1.32898 (* 1 = 1.32898 loss)
I0525 19:26:55.447787 25020 sgd_solver.cpp:106] Iteration 17850, lr = 0.0035
I0525 19:27:04.120582 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_18000.caffemodel
I0525 19:27:04.198691 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_18000.solverstate
I0525 19:27:04.223984 25020 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 19:28:11.890157 25020 solver.cpp:409]     Test net output #0: accuracy = 0.867014
I0525 19:28:11.890331 25020 solver.cpp:409]     Test net output #1: loss = 0.418871 (* 1 = 0.418871 loss)
I0525 19:28:32.764698 25020 solver.cpp:237] Iteration 18000, loss = 1.16977
I0525 19:28:32.764750 25020 solver.cpp:253]     Train net output #0: loss = 1.16977 (* 1 = 1.16977 loss)
I0525 19:28:32.764765 25020 sgd_solver.cpp:106] Iteration 18000, lr = 0.0035
I0525 19:28:41.484495 25020 solver.cpp:237] Iteration 18150, loss = 1.30911
I0525 19:28:41.484530 25020 solver.cpp:253]     Train net output #0: loss = 1.30911 (* 1 = 1.30911 loss)
I0525 19:28:41.484552 25020 sgd_solver.cpp:106] Iteration 18150, lr = 0.0035
I0525 19:28:50.205770 25020 solver.cpp:237] Iteration 18300, loss = 1.44859
I0525 19:28:50.205930 25020 solver.cpp:253]     Train net output #0: loss = 1.44859 (* 1 = 1.44859 loss)
I0525 19:28:50.205946 25020 sgd_solver.cpp:106] Iteration 18300, lr = 0.0035
I0525 19:28:58.927250 25020 solver.cpp:237] Iteration 18450, loss = 1.22658
I0525 19:28:58.927289 25020 solver.cpp:253]     Train net output #0: loss = 1.22658 (* 1 = 1.22658 loss)
I0525 19:28:58.927310 25020 sgd_solver.cpp:106] Iteration 18450, lr = 0.0035
I0525 19:29:07.645949 25020 solver.cpp:237] Iteration 18600, loss = 1.21823
I0525 19:29:07.645983 25020 solver.cpp:253]     Train net output #0: loss = 1.21823 (* 1 = 1.21823 loss)
I0525 19:29:07.645999 25020 sgd_solver.cpp:106] Iteration 18600, lr = 0.0035
I0525 19:29:16.371335 25020 solver.cpp:237] Iteration 18750, loss = 1.30818
I0525 19:29:16.371368 25020 solver.cpp:253]     Train net output #0: loss = 1.30818 (* 1 = 1.30818 loss)
I0525 19:29:16.371386 25020 sgd_solver.cpp:106] Iteration 18750, lr = 0.0035
I0525 19:29:25.098562 25020 solver.cpp:237] Iteration 18900, loss = 1.2413
I0525 19:29:25.098717 25020 solver.cpp:253]     Train net output #0: loss = 1.2413 (* 1 = 1.2413 loss)
I0525 19:29:25.098731 25020 sgd_solver.cpp:106] Iteration 18900, lr = 0.0035
I0525 19:29:54.721091 25020 solver.cpp:237] Iteration 19050, loss = 1.4446
I0525 19:29:54.721140 25020 solver.cpp:253]     Train net output #0: loss = 1.4446 (* 1 = 1.4446 loss)
I0525 19:29:54.721158 25020 sgd_solver.cpp:106] Iteration 19050, lr = 0.0035
I0525 19:30:03.431924 25020 solver.cpp:237] Iteration 19200, loss = 1.22276
I0525 19:30:03.432080 25020 solver.cpp:253]     Train net output #0: loss = 1.22276 (* 1 = 1.22276 loss)
I0525 19:30:03.432093 25020 sgd_solver.cpp:106] Iteration 19200, lr = 0.0035
I0525 19:30:12.150146 25020 solver.cpp:237] Iteration 19350, loss = 1.31201
I0525 19:30:12.150182 25020 solver.cpp:253]     Train net output #0: loss = 1.31201 (* 1 = 1.31201 loss)
I0525 19:30:12.150197 25020 sgd_solver.cpp:106] Iteration 19350, lr = 0.0035
I0525 19:30:20.817046 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_19500.caffemodel
I0525 19:30:20.895221 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_19500.solverstate
I0525 19:30:20.940320 25020 solver.cpp:237] Iteration 19500, loss = 1.22239
I0525 19:30:20.940366 25020 solver.cpp:253]     Train net output #0: loss = 1.22239 (* 1 = 1.22239 loss)
I0525 19:30:20.940387 25020 sgd_solver.cpp:106] Iteration 19500, lr = 0.0035
I0525 19:30:29.666456 25020 solver.cpp:237] Iteration 19650, loss = 1.205
I0525 19:30:29.666491 25020 solver.cpp:253]     Train net output #0: loss = 1.205 (* 1 = 1.205 loss)
I0525 19:30:29.666507 25020 sgd_solver.cpp:106] Iteration 19650, lr = 0.0035
I0525 19:30:38.392141 25020 solver.cpp:237] Iteration 19800, loss = 1.27761
I0525 19:30:38.392305 25020 solver.cpp:253]     Train net output #0: loss = 1.27761 (* 1 = 1.27761 loss)
I0525 19:30:38.392320 25020 sgd_solver.cpp:106] Iteration 19800, lr = 0.0035
I0525 19:30:47.115461 25020 solver.cpp:237] Iteration 19950, loss = 1.07076
I0525 19:30:47.115504 25020 solver.cpp:253]     Train net output #0: loss = 1.07076 (* 1 = 1.07076 loss)
I0525 19:30:47.115523 25020 sgd_solver.cpp:106] Iteration 19950, lr = 0.0035
I0525 19:31:16.743363 25020 solver.cpp:237] Iteration 20100, loss = 1.0401
I0525 19:31:16.743537 25020 solver.cpp:253]     Train net output #0: loss = 1.0401 (* 1 = 1.0401 loss)
I0525 19:31:16.743551 25020 sgd_solver.cpp:106] Iteration 20100, lr = 0.0035
I0525 19:31:25.469967 25020 solver.cpp:237] Iteration 20250, loss = 1.19463
I0525 19:31:25.470000 25020 solver.cpp:253]     Train net output #0: loss = 1.19463 (* 1 = 1.19463 loss)
I0525 19:31:25.470015 25020 sgd_solver.cpp:106] Iteration 20250, lr = 0.0035
I0525 19:31:34.196593 25020 solver.cpp:237] Iteration 20400, loss = 1.21766
I0525 19:31:34.196637 25020 solver.cpp:253]     Train net output #0: loss = 1.21766 (* 1 = 1.21766 loss)
I0525 19:31:34.196655 25020 sgd_solver.cpp:106] Iteration 20400, lr = 0.0035
I0525 19:31:42.917462 25020 solver.cpp:237] Iteration 20550, loss = 1.13235
I0525 19:31:42.917497 25020 solver.cpp:253]     Train net output #0: loss = 1.13235 (* 1 = 1.13235 loss)
I0525 19:31:42.917512 25020 sgd_solver.cpp:106] Iteration 20550, lr = 0.0035
I0525 19:31:51.636627 25020 solver.cpp:237] Iteration 20700, loss = 1.22697
I0525 19:31:51.636776 25020 solver.cpp:253]     Train net output #0: loss = 1.22697 (* 1 = 1.22697 loss)
I0525 19:31:51.636790 25020 sgd_solver.cpp:106] Iteration 20700, lr = 0.0035
I0525 19:32:00.357803 25020 solver.cpp:237] Iteration 20850, loss = 1.21145
I0525 19:32:00.357846 25020 solver.cpp:253]     Train net output #0: loss = 1.21145 (* 1 = 1.21145 loss)
I0525 19:32:00.357866 25020 sgd_solver.cpp:106] Iteration 20850, lr = 0.0035
I0525 19:32:09.025691 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_21000.caffemodel
I0525 19:32:09.105713 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_21000.solverstate
I0525 19:32:09.131918 25020 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 19:32:55.682248 25020 solver.cpp:409]     Test net output #0: accuracy = 0.872287
I0525 19:32:55.682425 25020 solver.cpp:409]     Test net output #1: loss = 0.438667 (* 1 = 0.438667 loss)
I0525 19:33:16.605377 25020 solver.cpp:237] Iteration 21000, loss = 1.1871
I0525 19:33:16.605430 25020 solver.cpp:253]     Train net output #0: loss = 1.1871 (* 1 = 1.1871 loss)
I0525 19:33:16.605445 25020 sgd_solver.cpp:106] Iteration 21000, lr = 0.0035
I0525 19:33:25.331821 25020 solver.cpp:237] Iteration 21150, loss = 1.16333
I0525 19:33:25.331857 25020 solver.cpp:253]     Train net output #0: loss = 1.16333 (* 1 = 1.16333 loss)
I0525 19:33:25.331872 25020 sgd_solver.cpp:106] Iteration 21150, lr = 0.0035
I0525 19:33:34.057780 25020 solver.cpp:237] Iteration 21300, loss = 1.15021
I0525 19:33:34.057942 25020 solver.cpp:253]     Train net output #0: loss = 1.15021 (* 1 = 1.15021 loss)
I0525 19:33:34.057956 25020 sgd_solver.cpp:106] Iteration 21300, lr = 0.0035
I0525 19:33:42.783463 25020 solver.cpp:237] Iteration 21450, loss = 1.23449
I0525 19:33:42.783498 25020 solver.cpp:253]     Train net output #0: loss = 1.23449 (* 1 = 1.23449 loss)
I0525 19:33:42.783514 25020 sgd_solver.cpp:106] Iteration 21450, lr = 0.0035
I0525 19:33:51.521107 25020 solver.cpp:237] Iteration 21600, loss = 1.33914
I0525 19:33:51.521136 25020 solver.cpp:253]     Train net output #0: loss = 1.33914 (* 1 = 1.33914 loss)
I0525 19:33:51.521149 25020 sgd_solver.cpp:106] Iteration 21600, lr = 0.0035
I0525 19:34:00.251811 25020 solver.cpp:237] Iteration 21750, loss = 1.21421
I0525 19:34:00.251847 25020 solver.cpp:253]     Train net output #0: loss = 1.21421 (* 1 = 1.21421 loss)
I0525 19:34:00.251865 25020 sgd_solver.cpp:106] Iteration 21750, lr = 0.0035
I0525 19:34:08.986156 25020 solver.cpp:237] Iteration 21900, loss = 1.06986
I0525 19:34:08.986330 25020 solver.cpp:253]     Train net output #0: loss = 1.06986 (* 1 = 1.06986 loss)
I0525 19:34:08.986345 25020 sgd_solver.cpp:106] Iteration 21900, lr = 0.0035
I0525 19:34:38.599987 25020 solver.cpp:237] Iteration 22050, loss = 1.20878
I0525 19:34:38.600038 25020 solver.cpp:253]     Train net output #0: loss = 1.20878 (* 1 = 1.20878 loss)
I0525 19:34:38.600054 25020 sgd_solver.cpp:106] Iteration 22050, lr = 0.0035
I0525 19:34:47.329195 25020 solver.cpp:237] Iteration 22200, loss = 1.04664
I0525 19:34:47.329357 25020 solver.cpp:253]     Train net output #0: loss = 1.04664 (* 1 = 1.04664 loss)
I0525 19:34:47.329370 25020 sgd_solver.cpp:106] Iteration 22200, lr = 0.0035
I0525 19:34:56.058812 25020 solver.cpp:237] Iteration 22350, loss = 1.03308
I0525 19:34:56.058856 25020 solver.cpp:253]     Train net output #0: loss = 1.03308 (* 1 = 1.03308 loss)
I0525 19:34:56.058876 25020 sgd_solver.cpp:106] Iteration 22350, lr = 0.0035
I0525 19:35:04.728417 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_22500.caffemodel
I0525 19:35:04.808264 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_22500.solverstate
I0525 19:35:04.853396 25020 solver.cpp:237] Iteration 22500, loss = 1.27281
I0525 19:35:04.853442 25020 solver.cpp:253]     Train net output #0: loss = 1.27281 (* 1 = 1.27281 loss)
I0525 19:35:04.853461 25020 sgd_solver.cpp:106] Iteration 22500, lr = 0.0035
I0525 19:35:13.583827 25020 solver.cpp:237] Iteration 22650, loss = 1.24132
I0525 19:35:13.583878 25020 solver.cpp:253]     Train net output #0: loss = 1.24132 (* 1 = 1.24132 loss)
I0525 19:35:13.583894 25020 sgd_solver.cpp:106] Iteration 22650, lr = 0.0035
I0525 19:35:22.315471 25020 solver.cpp:237] Iteration 22800, loss = 1.31737
I0525 19:35:22.315628 25020 solver.cpp:253]     Train net output #0: loss = 1.31737 (* 1 = 1.31737 loss)
I0525 19:35:22.315641 25020 sgd_solver.cpp:106] Iteration 22800, lr = 0.0035
I0525 19:35:31.043153 25020 solver.cpp:237] Iteration 22950, loss = 1.37012
I0525 19:35:31.043187 25020 solver.cpp:253]     Train net output #0: loss = 1.37012 (* 1 = 1.37012 loss)
I0525 19:35:31.043205 25020 sgd_solver.cpp:106] Iteration 22950, lr = 0.0035
I0525 19:36:00.673146 25020 solver.cpp:237] Iteration 23100, loss = 1.18515
I0525 19:36:00.673328 25020 solver.cpp:253]     Train net output #0: loss = 1.18515 (* 1 = 1.18515 loss)
I0525 19:36:00.673343 25020 sgd_solver.cpp:106] Iteration 23100, lr = 0.0035
I0525 19:36:09.401283 25020 solver.cpp:237] Iteration 23250, loss = 1.31945
I0525 19:36:09.401325 25020 solver.cpp:253]     Train net output #0: loss = 1.31945 (* 1 = 1.31945 loss)
I0525 19:36:09.401345 25020 sgd_solver.cpp:106] Iteration 23250, lr = 0.0035
I0525 19:36:18.129362 25020 solver.cpp:237] Iteration 23400, loss = 1.19356
I0525 19:36:18.129397 25020 solver.cpp:253]     Train net output #0: loss = 1.19356 (* 1 = 1.19356 loss)
I0525 19:36:18.129415 25020 sgd_solver.cpp:106] Iteration 23400, lr = 0.0035
I0525 19:36:26.862157 25020 solver.cpp:237] Iteration 23550, loss = 1.38838
I0525 19:36:26.862192 25020 solver.cpp:253]     Train net output #0: loss = 1.38838 (* 1 = 1.38838 loss)
I0525 19:36:26.862208 25020 sgd_solver.cpp:106] Iteration 23550, lr = 0.0035
I0525 19:36:35.590391 25020 solver.cpp:237] Iteration 23700, loss = 1.28697
I0525 19:36:35.590569 25020 solver.cpp:253]     Train net output #0: loss = 1.28697 (* 1 = 1.28697 loss)
I0525 19:36:35.590582 25020 sgd_solver.cpp:106] Iteration 23700, lr = 0.0035
I0525 19:36:44.315265 25020 solver.cpp:237] Iteration 23850, loss = 1.00251
I0525 19:36:44.315299 25020 solver.cpp:253]     Train net output #0: loss = 1.00251 (* 1 = 1.00251 loss)
I0525 19:36:44.315316 25020 sgd_solver.cpp:106] Iteration 23850, lr = 0.0035
I0525 19:36:52.983810 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_24000.caffemodel
I0525 19:36:53.061630 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_24000.solverstate
I0525 19:36:53.087816 25020 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 19:38:00.849515 25020 solver.cpp:409]     Test net output #0: accuracy = 0.873874
I0525 19:38:00.849686 25020 solver.cpp:409]     Test net output #1: loss = 0.401947 (* 1 = 0.401947 loss)
I0525 19:38:21.750025 25020 solver.cpp:237] Iteration 24000, loss = 1.10362
I0525 19:38:21.750075 25020 solver.cpp:253]     Train net output #0: loss = 1.10362 (* 1 = 1.10362 loss)
I0525 19:38:21.750089 25020 sgd_solver.cpp:106] Iteration 24000, lr = 0.0035
I0525 19:38:30.473546 25020 solver.cpp:237] Iteration 24150, loss = 1.15798
I0525 19:38:30.473582 25020 solver.cpp:253]     Train net output #0: loss = 1.15798 (* 1 = 1.15798 loss)
I0525 19:38:30.473598 25020 sgd_solver.cpp:106] Iteration 24150, lr = 0.0035
I0525 19:38:39.196523 25020 solver.cpp:237] Iteration 24300, loss = 1.12939
I0525 19:38:39.196686 25020 solver.cpp:253]     Train net output #0: loss = 1.12939 (* 1 = 1.12939 loss)
I0525 19:38:39.196701 25020 sgd_solver.cpp:106] Iteration 24300, lr = 0.0035
I0525 19:38:47.925923 25020 solver.cpp:237] Iteration 24450, loss = 1.3309
I0525 19:38:47.925957 25020 solver.cpp:253]     Train net output #0: loss = 1.3309 (* 1 = 1.3309 loss)
I0525 19:38:47.925972 25020 sgd_solver.cpp:106] Iteration 24450, lr = 0.0035
I0525 19:38:56.653318 25020 solver.cpp:237] Iteration 24600, loss = 1.16543
I0525 19:38:56.653353 25020 solver.cpp:253]     Train net output #0: loss = 1.16543 (* 1 = 1.16543 loss)
I0525 19:38:56.653369 25020 sgd_solver.cpp:106] Iteration 24600, lr = 0.0035
I0525 19:39:05.376238 25020 solver.cpp:237] Iteration 24750, loss = 1.30488
I0525 19:39:05.376282 25020 solver.cpp:253]     Train net output #0: loss = 1.30488 (* 1 = 1.30488 loss)
I0525 19:39:05.376297 25020 sgd_solver.cpp:106] Iteration 24750, lr = 0.0035
I0525 19:39:14.095831 25020 solver.cpp:237] Iteration 24900, loss = 0.961984
I0525 19:39:14.095983 25020 solver.cpp:253]     Train net output #0: loss = 0.961984 (* 1 = 0.961984 loss)
I0525 19:39:14.095998 25020 sgd_solver.cpp:106] Iteration 24900, lr = 0.0035
I0525 19:39:43.699805 25020 solver.cpp:237] Iteration 25050, loss = 1.32441
I0525 19:39:43.699856 25020 solver.cpp:253]     Train net output #0: loss = 1.32441 (* 1 = 1.32441 loss)
I0525 19:39:43.699872 25020 sgd_solver.cpp:106] Iteration 25050, lr = 0.0035
I0525 19:39:52.419153 25020 solver.cpp:237] Iteration 25200, loss = 1.47093
I0525 19:39:52.419322 25020 solver.cpp:253]     Train net output #0: loss = 1.47093 (* 1 = 1.47093 loss)
I0525 19:39:52.419337 25020 sgd_solver.cpp:106] Iteration 25200, lr = 0.0035
I0525 19:40:01.148450 25020 solver.cpp:237] Iteration 25350, loss = 1.1208
I0525 19:40:01.148484 25020 solver.cpp:253]     Train net output #0: loss = 1.1208 (* 1 = 1.1208 loss)
I0525 19:40:01.148499 25020 sgd_solver.cpp:106] Iteration 25350, lr = 0.0035
I0525 19:40:09.820626 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_25500.caffemodel
I0525 19:40:09.903661 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_25500.solverstate
I0525 19:40:09.947160 25020 solver.cpp:237] Iteration 25500, loss = 1.01908
I0525 19:40:09.947203 25020 solver.cpp:253]     Train net output #0: loss = 1.01908 (* 1 = 1.01908 loss)
I0525 19:40:09.947219 25020 sgd_solver.cpp:106] Iteration 25500, lr = 0.0035
I0525 19:40:18.669250 25020 solver.cpp:237] Iteration 25650, loss = 1.1501
I0525 19:40:18.669292 25020 solver.cpp:253]     Train net output #0: loss = 1.1501 (* 1 = 1.1501 loss)
I0525 19:40:18.669311 25020 sgd_solver.cpp:106] Iteration 25650, lr = 0.0035
I0525 19:40:27.396026 25020 solver.cpp:237] Iteration 25800, loss = 1.33215
I0525 19:40:27.396203 25020 solver.cpp:253]     Train net output #0: loss = 1.33215 (* 1 = 1.33215 loss)
I0525 19:40:27.396217 25020 sgd_solver.cpp:106] Iteration 25800, lr = 0.0035
I0525 19:40:36.123498 25020 solver.cpp:237] Iteration 25950, loss = 1.17968
I0525 19:40:36.123533 25020 solver.cpp:253]     Train net output #0: loss = 1.17968 (* 1 = 1.17968 loss)
I0525 19:40:36.123550 25020 sgd_solver.cpp:106] Iteration 25950, lr = 0.0035
I0525 19:41:05.732971 25020 solver.cpp:237] Iteration 26100, loss = 1.31588
I0525 19:41:05.733155 25020 solver.cpp:253]     Train net output #0: loss = 1.31588 (* 1 = 1.31588 loss)
I0525 19:41:05.733170 25020 sgd_solver.cpp:106] Iteration 26100, lr = 0.0035
I0525 19:41:14.455564 25020 solver.cpp:237] Iteration 26250, loss = 1.51997
I0525 19:41:14.455597 25020 solver.cpp:253]     Train net output #0: loss = 1.51997 (* 1 = 1.51997 loss)
I0525 19:41:14.455615 25020 sgd_solver.cpp:106] Iteration 26250, lr = 0.0035
I0525 19:41:23.176192 25020 solver.cpp:237] Iteration 26400, loss = 1.16138
I0525 19:41:23.176228 25020 solver.cpp:253]     Train net output #0: loss = 1.16138 (* 1 = 1.16138 loss)
I0525 19:41:23.176244 25020 sgd_solver.cpp:106] Iteration 26400, lr = 0.0035
I0525 19:41:31.895823 25020 solver.cpp:237] Iteration 26550, loss = 1.18996
I0525 19:41:31.895864 25020 solver.cpp:253]     Train net output #0: loss = 1.18996 (* 1 = 1.18996 loss)
I0525 19:41:31.895884 25020 sgd_solver.cpp:106] Iteration 26550, lr = 0.0035
I0525 19:41:40.618778 25020 solver.cpp:237] Iteration 26700, loss = 1.19049
I0525 19:41:40.618933 25020 solver.cpp:253]     Train net output #0: loss = 1.19049 (* 1 = 1.19049 loss)
I0525 19:41:40.618947 25020 sgd_solver.cpp:106] Iteration 26700, lr = 0.0035
I0525 19:41:49.335125 25020 solver.cpp:237] Iteration 26850, loss = 1.30864
I0525 19:41:49.335160 25020 solver.cpp:253]     Train net output #0: loss = 1.30864 (* 1 = 1.30864 loss)
I0525 19:41:49.335176 25020 sgd_solver.cpp:106] Iteration 26850, lr = 0.0035
I0525 19:41:57.999070 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_27000.caffemodel
I0525 19:41:58.077154 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_27000.solverstate
I0525 19:41:58.102308 25020 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 19:42:44.976789 25020 solver.cpp:409]     Test net output #0: accuracy = 0.876288
I0525 19:42:44.976960 25020 solver.cpp:409]     Test net output #1: loss = 0.398488 (* 1 = 0.398488 loss)
I0525 19:43:05.861424 25020 solver.cpp:237] Iteration 27000, loss = 1.16955
I0525 19:43:05.861477 25020 solver.cpp:253]     Train net output #0: loss = 1.16955 (* 1 = 1.16955 loss)
I0525 19:43:05.861492 25020 sgd_solver.cpp:106] Iteration 27000, lr = 0.0035
I0525 19:43:14.588608 25020 solver.cpp:237] Iteration 27150, loss = 1.14042
I0525 19:43:14.588646 25020 solver.cpp:253]     Train net output #0: loss = 1.14042 (* 1 = 1.14042 loss)
I0525 19:43:14.588670 25020 sgd_solver.cpp:106] Iteration 27150, lr = 0.0035
I0525 19:43:23.316464 25020 solver.cpp:237] Iteration 27300, loss = 1.05235
I0525 19:43:23.316645 25020 solver.cpp:253]     Train net output #0: loss = 1.05235 (* 1 = 1.05235 loss)
I0525 19:43:23.316659 25020 sgd_solver.cpp:106] Iteration 27300, lr = 0.0035
I0525 19:43:32.045049 25020 solver.cpp:237] Iteration 27450, loss = 1.27362
I0525 19:43:32.045083 25020 solver.cpp:253]     Train net output #0: loss = 1.27362 (* 1 = 1.27362 loss)
I0525 19:43:32.045100 25020 sgd_solver.cpp:106] Iteration 27450, lr = 0.0035
I0525 19:43:40.769156 25020 solver.cpp:237] Iteration 27600, loss = 1.32934
I0525 19:43:40.769198 25020 solver.cpp:253]     Train net output #0: loss = 1.32934 (* 1 = 1.32934 loss)
I0525 19:43:40.769217 25020 sgd_solver.cpp:106] Iteration 27600, lr = 0.0035
I0525 19:43:49.498389 25020 solver.cpp:237] Iteration 27750, loss = 1.1195
I0525 19:43:49.498423 25020 solver.cpp:253]     Train net output #0: loss = 1.1195 (* 1 = 1.1195 loss)
I0525 19:43:49.498440 25020 sgd_solver.cpp:106] Iteration 27750, lr = 0.0035
I0525 19:43:58.234287 25020 solver.cpp:237] Iteration 27900, loss = 1.17122
I0525 19:43:58.234443 25020 solver.cpp:253]     Train net output #0: loss = 1.17122 (* 1 = 1.17122 loss)
I0525 19:43:58.234457 25020 sgd_solver.cpp:106] Iteration 27900, lr = 0.0035
I0525 19:44:27.868896 25020 solver.cpp:237] Iteration 28050, loss = 1.17647
I0525 19:44:27.868945 25020 solver.cpp:253]     Train net output #0: loss = 1.17647 (* 1 = 1.17647 loss)
I0525 19:44:27.868963 25020 sgd_solver.cpp:106] Iteration 28050, lr = 0.0035
I0525 19:44:36.598932 25020 solver.cpp:237] Iteration 28200, loss = 1.19406
I0525 19:44:36.599094 25020 solver.cpp:253]     Train net output #0: loss = 1.19406 (* 1 = 1.19406 loss)
I0525 19:44:36.599107 25020 sgd_solver.cpp:106] Iteration 28200, lr = 0.0035
I0525 19:44:45.327492 25020 solver.cpp:237] Iteration 28350, loss = 1.09332
I0525 19:44:45.327527 25020 solver.cpp:253]     Train net output #0: loss = 1.09332 (* 1 = 1.09332 loss)
I0525 19:44:45.327543 25020 sgd_solver.cpp:106] Iteration 28350, lr = 0.0035
I0525 19:44:54.000187 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_28500.caffemodel
I0525 19:44:54.081068 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_28500.solverstate
I0525 19:44:54.125855 25020 solver.cpp:237] Iteration 28500, loss = 1.39001
I0525 19:44:54.125905 25020 solver.cpp:253]     Train net output #0: loss = 1.39001 (* 1 = 1.39001 loss)
I0525 19:44:54.125921 25020 sgd_solver.cpp:106] Iteration 28500, lr = 0.0035
I0525 19:45:02.853978 25020 solver.cpp:237] Iteration 28650, loss = 1.25184
I0525 19:45:02.854013 25020 solver.cpp:253]     Train net output #0: loss = 1.25184 (* 1 = 1.25184 loss)
I0525 19:45:02.854027 25020 sgd_solver.cpp:106] Iteration 28650, lr = 0.0035
I0525 19:45:11.578667 25020 solver.cpp:237] Iteration 28800, loss = 1.45225
I0525 19:45:11.578827 25020 solver.cpp:253]     Train net output #0: loss = 1.45225 (* 1 = 1.45225 loss)
I0525 19:45:11.578841 25020 sgd_solver.cpp:106] Iteration 28800, lr = 0.0035
I0525 19:45:20.306044 25020 solver.cpp:237] Iteration 28950, loss = 1.20522
I0525 19:45:20.306083 25020 solver.cpp:253]     Train net output #0: loss = 1.20522 (* 1 = 1.20522 loss)
I0525 19:45:20.306104 25020 sgd_solver.cpp:106] Iteration 28950, lr = 0.0035
I0525 19:45:49.924234 25020 solver.cpp:237] Iteration 29100, loss = 1.1523
I0525 19:45:49.924412 25020 solver.cpp:253]     Train net output #0: loss = 1.1523 (* 1 = 1.1523 loss)
I0525 19:45:49.924427 25020 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035
I0525 19:45:58.649128 25020 solver.cpp:237] Iteration 29250, loss = 1.08336
I0525 19:45:58.649163 25020 solver.cpp:253]     Train net output #0: loss = 1.08336 (* 1 = 1.08336 loss)
I0525 19:45:58.649179 25020 sgd_solver.cpp:106] Iteration 29250, lr = 0.0035
I0525 19:46:07.381273 25020 solver.cpp:237] Iteration 29400, loss = 1.04522
I0525 19:46:07.381311 25020 solver.cpp:253]     Train net output #0: loss = 1.04522 (* 1 = 1.04522 loss)
I0525 19:46:07.381332 25020 sgd_solver.cpp:106] Iteration 29400, lr = 0.0035
I0525 19:46:16.107254 25020 solver.cpp:237] Iteration 29550, loss = 1.36921
I0525 19:46:16.107288 25020 solver.cpp:253]     Train net output #0: loss = 1.36921 (* 1 = 1.36921 loss)
I0525 19:46:16.107305 25020 sgd_solver.cpp:106] Iteration 29550, lr = 0.0035
I0525 19:46:24.833307 25020 solver.cpp:237] Iteration 29700, loss = 1.23301
I0525 19:46:24.833465 25020 solver.cpp:253]     Train net output #0: loss = 1.23301 (* 1 = 1.23301 loss)
I0525 19:46:24.833479 25020 sgd_solver.cpp:106] Iteration 29700, lr = 0.0035
I0525 19:46:33.565440 25020 solver.cpp:237] Iteration 29850, loss = 1.29074
I0525 19:46:33.565479 25020 solver.cpp:253]     Train net output #0: loss = 1.29074 (* 1 = 1.29074 loss)
I0525 19:46:33.565502 25020 sgd_solver.cpp:106] Iteration 29850, lr = 0.0035
I0525 19:46:42.235875 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_30000.caffemodel
I0525 19:46:42.315516 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_30000.solverstate
I0525 19:46:42.343080 25020 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 19:47:50.164305 25020 solver.cpp:409]     Test net output #0: accuracy = 0.879701
I0525 19:47:50.164481 25020 solver.cpp:409]     Test net output #1: loss = 0.389184 (* 1 = 0.389184 loss)
I0525 19:48:11.086284 25020 solver.cpp:237] Iteration 30000, loss = 1.41475
I0525 19:48:11.086335 25020 solver.cpp:253]     Train net output #0: loss = 1.41475 (* 1 = 1.41475 loss)
I0525 19:48:11.086350 25020 sgd_solver.cpp:106] Iteration 30000, lr = 0.0035
I0525 19:48:19.812783 25020 solver.cpp:237] Iteration 30150, loss = 1.16654
I0525 19:48:19.812819 25020 solver.cpp:253]     Train net output #0: loss = 1.16654 (* 1 = 1.16654 loss)
I0525 19:48:19.812836 25020 sgd_solver.cpp:106] Iteration 30150, lr = 0.0035
I0525 19:48:28.528105 25020 solver.cpp:237] Iteration 30300, loss = 1.13421
I0525 19:48:28.528272 25020 solver.cpp:253]     Train net output #0: loss = 1.13421 (* 1 = 1.13421 loss)
I0525 19:48:28.528287 25020 sgd_solver.cpp:106] Iteration 30300, lr = 0.0035
I0525 19:48:37.250195 25020 solver.cpp:237] Iteration 30450, loss = 1.25184
I0525 19:48:37.250242 25020 solver.cpp:253]     Train net output #0: loss = 1.25184 (* 1 = 1.25184 loss)
I0525 19:48:37.250258 25020 sgd_solver.cpp:106] Iteration 30450, lr = 0.0035
I0525 19:48:45.977120 25020 solver.cpp:237] Iteration 30600, loss = 1.15832
I0525 19:48:45.977155 25020 solver.cpp:253]     Train net output #0: loss = 1.15832 (* 1 = 1.15832 loss)
I0525 19:48:45.977171 25020 sgd_solver.cpp:106] Iteration 30600, lr = 0.0035
I0525 19:48:54.697399 25020 solver.cpp:237] Iteration 30750, loss = 1.04388
I0525 19:48:54.697434 25020 solver.cpp:253]     Train net output #0: loss = 1.04388 (* 1 = 1.04388 loss)
I0525 19:48:54.697450 25020 sgd_solver.cpp:106] Iteration 30750, lr = 0.0035
I0525 19:49:03.420789 25020 solver.cpp:237] Iteration 30900, loss = 1.16962
I0525 19:49:03.420958 25020 solver.cpp:253]     Train net output #0: loss = 1.16962 (* 1 = 1.16962 loss)
I0525 19:49:03.420971 25020 sgd_solver.cpp:106] Iteration 30900, lr = 0.0035
I0525 19:49:33.057009 25020 solver.cpp:237] Iteration 31050, loss = 1.08993
I0525 19:49:33.057063 25020 solver.cpp:253]     Train net output #0: loss = 1.08993 (* 1 = 1.08993 loss)
I0525 19:49:33.057080 25020 sgd_solver.cpp:106] Iteration 31050, lr = 0.0035
I0525 19:49:41.783046 25020 solver.cpp:237] Iteration 31200, loss = 1.16497
I0525 19:49:41.783205 25020 solver.cpp:253]     Train net output #0: loss = 1.16497 (* 1 = 1.16497 loss)
I0525 19:49:41.783218 25020 sgd_solver.cpp:106] Iteration 31200, lr = 0.0035
I0525 19:49:50.503456 25020 solver.cpp:237] Iteration 31350, loss = 1.34808
I0525 19:49:50.503499 25020 solver.cpp:253]     Train net output #0: loss = 1.34808 (* 1 = 1.34808 loss)
I0525 19:49:50.503518 25020 sgd_solver.cpp:106] Iteration 31350, lr = 0.0035
I0525 19:49:59.163610 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_31500.caffemodel
I0525 19:49:59.241868 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_31500.solverstate
I0525 19:49:59.285284 25020 solver.cpp:237] Iteration 31500, loss = 1.1875
I0525 19:49:59.285328 25020 solver.cpp:253]     Train net output #0: loss = 1.1875 (* 1 = 1.1875 loss)
I0525 19:49:59.285343 25020 sgd_solver.cpp:106] Iteration 31500, lr = 0.0035
I0525 19:50:08.007472 25020 solver.cpp:237] Iteration 31650, loss = 1.16245
I0525 19:50:08.007508 25020 solver.cpp:253]     Train net output #0: loss = 1.16245 (* 1 = 1.16245 loss)
I0525 19:50:08.007524 25020 sgd_solver.cpp:106] Iteration 31650, lr = 0.0035
I0525 19:50:16.730226 25020 solver.cpp:237] Iteration 31800, loss = 1.19453
I0525 19:50:16.730417 25020 solver.cpp:253]     Train net output #0: loss = 1.19453 (* 1 = 1.19453 loss)
I0525 19:50:16.730430 25020 sgd_solver.cpp:106] Iteration 31800, lr = 0.0035
I0525 19:50:25.456051 25020 solver.cpp:237] Iteration 31950, loss = 1.33465
I0525 19:50:25.456085 25020 solver.cpp:253]     Train net output #0: loss = 1.33465 (* 1 = 1.33465 loss)
I0525 19:50:25.456100 25020 sgd_solver.cpp:106] Iteration 31950, lr = 0.0035
I0525 19:50:55.022686 25020 solver.cpp:237] Iteration 32100, loss = 1.01006
I0525 19:50:55.022866 25020 solver.cpp:253]     Train net output #0: loss = 1.01006 (* 1 = 1.01006 loss)
I0525 19:50:55.022881 25020 sgd_solver.cpp:106] Iteration 32100, lr = 0.0035
I0525 19:51:03.746384 25020 solver.cpp:237] Iteration 32250, loss = 1.19482
I0525 19:51:03.746430 25020 solver.cpp:253]     Train net output #0: loss = 1.19482 (* 1 = 1.19482 loss)
I0525 19:51:03.746448 25020 sgd_solver.cpp:106] Iteration 32250, lr = 0.0035
I0525 19:51:12.467849 25020 solver.cpp:237] Iteration 32400, loss = 1.22198
I0525 19:51:12.467883 25020 solver.cpp:253]     Train net output #0: loss = 1.22198 (* 1 = 1.22198 loss)
I0525 19:51:12.467900 25020 sgd_solver.cpp:106] Iteration 32400, lr = 0.0035
I0525 19:51:21.191392 25020 solver.cpp:237] Iteration 32550, loss = 1.02273
I0525 19:51:21.191428 25020 solver.cpp:253]     Train net output #0: loss = 1.02273 (* 1 = 1.02273 loss)
I0525 19:51:21.191442 25020 sgd_solver.cpp:106] Iteration 32550, lr = 0.0035
I0525 19:51:29.912703 25020 solver.cpp:237] Iteration 32700, loss = 1.05624
I0525 19:51:29.912870 25020 solver.cpp:253]     Train net output #0: loss = 1.05624 (* 1 = 1.05624 loss)
I0525 19:51:29.912885 25020 sgd_solver.cpp:106] Iteration 32700, lr = 0.0035
I0525 19:51:38.632752 25020 solver.cpp:237] Iteration 32850, loss = 1.21966
I0525 19:51:38.632786 25020 solver.cpp:253]     Train net output #0: loss = 1.21966 (* 1 = 1.21966 loss)
I0525 19:51:38.632803 25020 sgd_solver.cpp:106] Iteration 32850, lr = 0.0035
I0525 19:51:47.299767 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_33000.caffemodel
I0525 19:51:47.377667 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_33000.solverstate
I0525 19:51:47.402807 25020 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 19:52:33.948554 25020 solver.cpp:409]     Test net output #0: accuracy = 0.882495
I0525 19:52:33.948737 25020 solver.cpp:409]     Test net output #1: loss = 0.380222 (* 1 = 0.380222 loss)
I0525 19:52:54.828723 25020 solver.cpp:237] Iteration 33000, loss = 1.16043
I0525 19:52:54.828778 25020 solver.cpp:253]     Train net output #0: loss = 1.16043 (* 1 = 1.16043 loss)
I0525 19:52:54.828791 25020 sgd_solver.cpp:106] Iteration 33000, lr = 0.0035
I0525 19:53:03.550858 25020 solver.cpp:237] Iteration 33150, loss = 1.13279
I0525 19:53:03.550894 25020 solver.cpp:253]     Train net output #0: loss = 1.13279 (* 1 = 1.13279 loss)
I0525 19:53:03.550911 25020 sgd_solver.cpp:106] Iteration 33150, lr = 0.0035
I0525 19:53:12.284476 25020 solver.cpp:237] Iteration 33300, loss = 1.01065
I0525 19:53:12.284657 25020 solver.cpp:253]     Train net output #0: loss = 1.01065 (* 1 = 1.01065 loss)
I0525 19:53:12.284672 25020 sgd_solver.cpp:106] Iteration 33300, lr = 0.0035
I0525 19:53:21.011059 25020 solver.cpp:237] Iteration 33450, loss = 1.28676
I0525 19:53:21.011092 25020 solver.cpp:253]     Train net output #0: loss = 1.28676 (* 1 = 1.28676 loss)
I0525 19:53:21.011111 25020 sgd_solver.cpp:106] Iteration 33450, lr = 0.0035
I0525 19:53:29.739756 25020 solver.cpp:237] Iteration 33600, loss = 1.29829
I0525 19:53:29.739791 25020 solver.cpp:253]     Train net output #0: loss = 1.29829 (* 1 = 1.29829 loss)
I0525 19:53:29.739807 25020 sgd_solver.cpp:106] Iteration 33600, lr = 0.0035
I0525 19:53:38.465232 25020 solver.cpp:237] Iteration 33750, loss = 1.18892
I0525 19:53:38.465276 25020 solver.cpp:253]     Train net output #0: loss = 1.18892 (* 1 = 1.18892 loss)
I0525 19:53:38.465291 25020 sgd_solver.cpp:106] Iteration 33750, lr = 0.0035
I0525 19:53:47.192713 25020 solver.cpp:237] Iteration 33900, loss = 1.15625
I0525 19:53:47.192873 25020 solver.cpp:253]     Train net output #0: loss = 1.15625 (* 1 = 1.15625 loss)
I0525 19:53:47.192886 25020 sgd_solver.cpp:106] Iteration 33900, lr = 0.0035
I0525 19:54:16.816282 25020 solver.cpp:237] Iteration 34050, loss = 1.1959
I0525 19:54:16.816332 25020 solver.cpp:253]     Train net output #0: loss = 1.1959 (* 1 = 1.1959 loss)
I0525 19:54:16.816347 25020 sgd_solver.cpp:106] Iteration 34050, lr = 0.0035
I0525 19:54:25.542654 25020 solver.cpp:237] Iteration 34200, loss = 1.17239
I0525 19:54:25.542825 25020 solver.cpp:253]     Train net output #0: loss = 1.17239 (* 1 = 1.17239 loss)
I0525 19:54:25.542840 25020 sgd_solver.cpp:106] Iteration 34200, lr = 0.0035
I0525 19:54:34.270557 25020 solver.cpp:237] Iteration 34350, loss = 1.07038
I0525 19:54:34.270591 25020 solver.cpp:253]     Train net output #0: loss = 1.07038 (* 1 = 1.07038 loss)
I0525 19:54:34.270608 25020 sgd_solver.cpp:106] Iteration 34350, lr = 0.0035
I0525 19:54:42.937649 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_34500.caffemodel
I0525 19:54:43.015295 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_34500.solverstate
I0525 19:54:43.058266 25020 solver.cpp:237] Iteration 34500, loss = 1.08488
I0525 19:54:43.058312 25020 solver.cpp:253]     Train net output #0: loss = 1.08488 (* 1 = 1.08488 loss)
I0525 19:54:43.058327 25020 sgd_solver.cpp:106] Iteration 34500, lr = 0.0035
I0525 19:54:51.790575 25020 solver.cpp:237] Iteration 34650, loss = 1.12287
I0525 19:54:51.790622 25020 solver.cpp:253]     Train net output #0: loss = 1.12287 (* 1 = 1.12287 loss)
I0525 19:54:51.790637 25020 sgd_solver.cpp:106] Iteration 34650, lr = 0.0035
I0525 19:55:00.516549 25020 solver.cpp:237] Iteration 34800, loss = 1.27844
I0525 19:55:00.516710 25020 solver.cpp:253]     Train net output #0: loss = 1.27844 (* 1 = 1.27844 loss)
I0525 19:55:00.516724 25020 sgd_solver.cpp:106] Iteration 34800, lr = 0.0035
I0525 19:55:09.244294 25020 solver.cpp:237] Iteration 34950, loss = 1.11834
I0525 19:55:09.244328 25020 solver.cpp:253]     Train net output #0: loss = 1.11834 (* 1 = 1.11834 loss)
I0525 19:55:09.244344 25020 sgd_solver.cpp:106] Iteration 34950, lr = 0.0035
I0525 19:55:38.834213 25020 solver.cpp:237] Iteration 35100, loss = 1.13312
I0525 19:55:38.834381 25020 solver.cpp:253]     Train net output #0: loss = 1.13312 (* 1 = 1.13312 loss)
I0525 19:55:38.834396 25020 sgd_solver.cpp:106] Iteration 35100, lr = 0.0035
I0525 19:55:47.561388 25020 solver.cpp:237] Iteration 35250, loss = 1.22058
I0525 19:55:47.561422 25020 solver.cpp:253]     Train net output #0: loss = 1.22058 (* 1 = 1.22058 loss)
I0525 19:55:47.561439 25020 sgd_solver.cpp:106] Iteration 35250, lr = 0.0035
I0525 19:55:56.289160 25020 solver.cpp:237] Iteration 35400, loss = 1.31186
I0525 19:55:56.289189 25020 solver.cpp:253]     Train net output #0: loss = 1.31186 (* 1 = 1.31186 loss)
I0525 19:55:56.289202 25020 sgd_solver.cpp:106] Iteration 35400, lr = 0.0035
I0525 19:56:05.026015 25020 solver.cpp:237] Iteration 35550, loss = 1.25362
I0525 19:56:05.026062 25020 solver.cpp:253]     Train net output #0: loss = 1.25362 (* 1 = 1.25362 loss)
I0525 19:56:05.026078 25020 sgd_solver.cpp:106] Iteration 35550, lr = 0.0035
I0525 19:56:13.756232 25020 solver.cpp:237] Iteration 35700, loss = 1.33088
I0525 19:56:13.756402 25020 solver.cpp:253]     Train net output #0: loss = 1.33088 (* 1 = 1.33088 loss)
I0525 19:56:13.756417 25020 sgd_solver.cpp:106] Iteration 35700, lr = 0.0035
I0525 19:56:22.483286 25020 solver.cpp:237] Iteration 35850, loss = 1.08658
I0525 19:56:22.483320 25020 solver.cpp:253]     Train net output #0: loss = 1.08658 (* 1 = 1.08658 loss)
I0525 19:56:22.483337 25020 sgd_solver.cpp:106] Iteration 35850, lr = 0.0035
I0525 19:56:31.153789 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_36000.caffemodel
I0525 19:56:31.233638 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_36000.solverstate
I0525 19:56:31.259826 25020 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 19:57:38.967502 25020 solver.cpp:409]     Test net output #0: accuracy = 0.884848
I0525 19:57:38.967681 25020 solver.cpp:409]     Test net output #1: loss = 0.369524 (* 1 = 0.369524 loss)
I0525 19:57:59.854943 25020 solver.cpp:237] Iteration 36000, loss = 1.16342
I0525 19:57:59.854996 25020 solver.cpp:253]     Train net output #0: loss = 1.16342 (* 1 = 1.16342 loss)
I0525 19:57:59.855011 25020 sgd_solver.cpp:106] Iteration 36000, lr = 0.0035
I0525 19:58:08.574949 25020 solver.cpp:237] Iteration 36150, loss = 1.18251
I0525 19:58:08.574990 25020 solver.cpp:253]     Train net output #0: loss = 1.18251 (* 1 = 1.18251 loss)
I0525 19:58:08.575006 25020 sgd_solver.cpp:106] Iteration 36150, lr = 0.0035
I0525 19:58:17.301888 25020 solver.cpp:237] Iteration 36300, loss = 1.13851
I0525 19:58:17.302052 25020 solver.cpp:253]     Train net output #0: loss = 1.13851 (* 1 = 1.13851 loss)
I0525 19:58:17.302065 25020 sgd_solver.cpp:106] Iteration 36300, lr = 0.0035
I0525 19:58:26.029867 25020 solver.cpp:237] Iteration 36450, loss = 1.3406
I0525 19:58:26.029901 25020 solver.cpp:253]     Train net output #0: loss = 1.3406 (* 1 = 1.3406 loss)
I0525 19:58:26.029920 25020 sgd_solver.cpp:106] Iteration 36450, lr = 0.0035
I0525 19:58:34.758309 25020 solver.cpp:237] Iteration 36600, loss = 1.1453
I0525 19:58:34.758352 25020 solver.cpp:253]     Train net output #0: loss = 1.1453 (* 1 = 1.1453 loss)
I0525 19:58:34.758369 25020 sgd_solver.cpp:106] Iteration 36600, lr = 0.0035
I0525 19:58:43.476022 25020 solver.cpp:237] Iteration 36750, loss = 1.1508
I0525 19:58:43.476057 25020 solver.cpp:253]     Train net output #0: loss = 1.1508 (* 1 = 1.1508 loss)
I0525 19:58:43.476073 25020 sgd_solver.cpp:106] Iteration 36750, lr = 0.0035
I0525 19:58:52.202419 25020 solver.cpp:237] Iteration 36900, loss = 1.31399
I0525 19:58:52.202577 25020 solver.cpp:253]     Train net output #0: loss = 1.31399 (* 1 = 1.31399 loss)
I0525 19:58:52.202590 25020 sgd_solver.cpp:106] Iteration 36900, lr = 0.0035
I0525 19:59:21.773043 25020 solver.cpp:237] Iteration 37050, loss = 1.09611
I0525 19:59:21.773093 25020 solver.cpp:253]     Train net output #0: loss = 1.09611 (* 1 = 1.09611 loss)
I0525 19:59:21.773108 25020 sgd_solver.cpp:106] Iteration 37050, lr = 0.0035
I0525 19:59:30.500650 25020 solver.cpp:237] Iteration 37200, loss = 1.16075
I0525 19:59:30.500831 25020 solver.cpp:253]     Train net output #0: loss = 1.16075 (* 1 = 1.16075 loss)
I0525 19:59:30.500846 25020 sgd_solver.cpp:106] Iteration 37200, lr = 0.0035
I0525 19:59:39.220484 25020 solver.cpp:237] Iteration 37350, loss = 1.17856
I0525 19:59:39.220517 25020 solver.cpp:253]     Train net output #0: loss = 1.17856 (* 1 = 1.17856 loss)
I0525 19:59:39.220535 25020 sgd_solver.cpp:106] Iteration 37350, lr = 0.0035
I0525 19:59:47.888847 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_37500.caffemodel
I0525 19:59:47.969315 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_37500.solverstate
I0525 19:59:48.014662 25020 solver.cpp:237] Iteration 37500, loss = 1.29327
I0525 19:59:48.014711 25020 solver.cpp:253]     Train net output #0: loss = 1.29327 (* 1 = 1.29327 loss)
I0525 19:59:48.014726 25020 sgd_solver.cpp:106] Iteration 37500, lr = 0.0035
I0525 19:59:56.738620 25020 solver.cpp:237] Iteration 37650, loss = 1.24608
I0525 19:59:56.738662 25020 solver.cpp:253]     Train net output #0: loss = 1.24608 (* 1 = 1.24608 loss)
I0525 19:59:56.738680 25020 sgd_solver.cpp:106] Iteration 37650, lr = 0.0035
I0525 20:00:05.461767 25020 solver.cpp:237] Iteration 37800, loss = 1.27063
I0525 20:00:05.461933 25020 solver.cpp:253]     Train net output #0: loss = 1.27063 (* 1 = 1.27063 loss)
I0525 20:00:05.461947 25020 sgd_solver.cpp:106] Iteration 37800, lr = 0.0035
I0525 20:00:14.183400 25020 solver.cpp:237] Iteration 37950, loss = 1.1011
I0525 20:00:14.183447 25020 solver.cpp:253]     Train net output #0: loss = 1.1011 (* 1 = 1.1011 loss)
I0525 20:00:14.183464 25020 sgd_solver.cpp:106] Iteration 37950, lr = 0.0035
I0525 20:00:43.743165 25020 solver.cpp:237] Iteration 38100, loss = 1.1871
I0525 20:00:43.743345 25020 solver.cpp:253]     Train net output #0: loss = 1.1871 (* 1 = 1.1871 loss)
I0525 20:00:43.743358 25020 sgd_solver.cpp:106] Iteration 38100, lr = 0.0035
I0525 20:00:52.460682 25020 solver.cpp:237] Iteration 38250, loss = 1.07573
I0525 20:00:52.460717 25020 solver.cpp:253]     Train net output #0: loss = 1.07573 (* 1 = 1.07573 loss)
I0525 20:00:52.460733 25020 sgd_solver.cpp:106] Iteration 38250, lr = 0.0035
I0525 20:01:01.182061 25020 solver.cpp:237] Iteration 38400, loss = 1.07688
I0525 20:01:01.182097 25020 solver.cpp:253]     Train net output #0: loss = 1.07688 (* 1 = 1.07688 loss)
I0525 20:01:01.182111 25020 sgd_solver.cpp:106] Iteration 38400, lr = 0.0035
I0525 20:01:09.908097 25020 solver.cpp:237] Iteration 38550, loss = 1.29365
I0525 20:01:09.908139 25020 solver.cpp:253]     Train net output #0: loss = 1.29365 (* 1 = 1.29365 loss)
I0525 20:01:09.908160 25020 sgd_solver.cpp:106] Iteration 38550, lr = 0.0035
I0525 20:01:18.631217 25020 solver.cpp:237] Iteration 38700, loss = 1.064
I0525 20:01:18.631373 25020 solver.cpp:253]     Train net output #0: loss = 1.064 (* 1 = 1.064 loss)
I0525 20:01:18.631387 25020 sgd_solver.cpp:106] Iteration 38700, lr = 0.0035
I0525 20:01:27.352599 25020 solver.cpp:237] Iteration 38850, loss = 1.08575
I0525 20:01:27.352633 25020 solver.cpp:253]     Train net output #0: loss = 1.08575 (* 1 = 1.08575 loss)
I0525 20:01:27.352649 25020 sgd_solver.cpp:106] Iteration 38850, lr = 0.0035
I0525 20:01:36.017352 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_39000.caffemodel
I0525 20:01:36.096155 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_39000.solverstate
I0525 20:01:36.121403 25020 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 20:02:22.995249 25020 solver.cpp:409]     Test net output #0: accuracy = 0.885014
I0525 20:02:22.995440 25020 solver.cpp:409]     Test net output #1: loss = 0.366676 (* 1 = 0.366676 loss)
I0525 20:02:43.856773 25020 solver.cpp:237] Iteration 39000, loss = 0.870116
I0525 20:02:43.856829 25020 solver.cpp:253]     Train net output #0: loss = 0.870116 (* 1 = 0.870116 loss)
I0525 20:02:43.856848 25020 sgd_solver.cpp:106] Iteration 39000, lr = 0.0035
I0525 20:02:52.588994 25020 solver.cpp:237] Iteration 39150, loss = 1.22337
I0525 20:02:52.589028 25020 solver.cpp:253]     Train net output #0: loss = 1.22337 (* 1 = 1.22337 loss)
I0525 20:02:52.589088 25020 sgd_solver.cpp:106] Iteration 39150, lr = 0.0035
I0525 20:03:01.313163 25020 solver.cpp:237] Iteration 39300, loss = 1.16103
I0525 20:03:01.313329 25020 solver.cpp:253]     Train net output #0: loss = 1.16103 (* 1 = 1.16103 loss)
I0525 20:03:01.313344 25020 sgd_solver.cpp:106] Iteration 39300, lr = 0.0035
I0525 20:03:10.044337 25020 solver.cpp:237] Iteration 39450, loss = 1.15074
I0525 20:03:10.044373 25020 solver.cpp:253]     Train net output #0: loss = 1.15074 (* 1 = 1.15074 loss)
I0525 20:03:10.044395 25020 sgd_solver.cpp:106] Iteration 39450, lr = 0.0035
I0525 20:03:18.774670 25020 solver.cpp:237] Iteration 39600, loss = 1.21466
I0525 20:03:18.774705 25020 solver.cpp:253]     Train net output #0: loss = 1.21466 (* 1 = 1.21466 loss)
I0525 20:03:18.774721 25020 sgd_solver.cpp:106] Iteration 39600, lr = 0.0035
I0525 20:03:27.498412 25020 solver.cpp:237] Iteration 39750, loss = 1.24595
I0525 20:03:27.498447 25020 solver.cpp:253]     Train net output #0: loss = 1.24595 (* 1 = 1.24595 loss)
I0525 20:03:27.498464 25020 sgd_solver.cpp:106] Iteration 39750, lr = 0.0035
I0525 20:03:36.227566 25020 solver.cpp:237] Iteration 39900, loss = 1.08431
I0525 20:03:36.227735 25020 solver.cpp:253]     Train net output #0: loss = 1.08431 (* 1 = 1.08431 loss)
I0525 20:03:36.227749 25020 sgd_solver.cpp:106] Iteration 39900, lr = 0.0035
I0525 20:04:05.785768 25020 solver.cpp:237] Iteration 40050, loss = 1.16623
I0525 20:04:05.785816 25020 solver.cpp:253]     Train net output #0: loss = 1.16623 (* 1 = 1.16623 loss)
I0525 20:04:05.785832 25020 sgd_solver.cpp:106] Iteration 40050, lr = 0.0035
I0525 20:04:14.516962 25020 solver.cpp:237] Iteration 40200, loss = 1.09139
I0525 20:04:14.517133 25020 solver.cpp:253]     Train net output #0: loss = 1.09139 (* 1 = 1.09139 loss)
I0525 20:04:14.517148 25020 sgd_solver.cpp:106] Iteration 40200, lr = 0.0035
I0525 20:04:23.244148 25020 solver.cpp:237] Iteration 40350, loss = 1.00348
I0525 20:04:23.244182 25020 solver.cpp:253]     Train net output #0: loss = 1.00348 (* 1 = 1.00348 loss)
I0525 20:04:23.244199 25020 sgd_solver.cpp:106] Iteration 40350, lr = 0.0035
I0525 20:04:31.914608 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_40500.caffemodel
I0525 20:04:31.992511 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_40500.solverstate
I0525 20:04:32.035980 25020 solver.cpp:237] Iteration 40500, loss = 1.06167
I0525 20:04:32.036025 25020 solver.cpp:253]     Train net output #0: loss = 1.06167 (* 1 = 1.06167 loss)
I0525 20:04:32.036038 25020 sgd_solver.cpp:106] Iteration 40500, lr = 0.0035
I0525 20:04:40.762589 25020 solver.cpp:237] Iteration 40650, loss = 1.23542
I0525 20:04:40.762624 25020 solver.cpp:253]     Train net output #0: loss = 1.23542 (* 1 = 1.23542 loss)
I0525 20:04:40.762639 25020 sgd_solver.cpp:106] Iteration 40650, lr = 0.0035
I0525 20:04:49.489450 25020 solver.cpp:237] Iteration 40800, loss = 1.14222
I0525 20:04:49.489624 25020 solver.cpp:253]     Train net output #0: loss = 1.14222 (* 1 = 1.14222 loss)
I0525 20:04:49.489639 25020 sgd_solver.cpp:106] Iteration 40800, lr = 0.0035
I0525 20:04:58.213076 25020 solver.cpp:237] Iteration 40950, loss = 1.30749
I0525 20:04:58.213109 25020 solver.cpp:253]     Train net output #0: loss = 1.30749 (* 1 = 1.30749 loss)
I0525 20:04:58.213127 25020 sgd_solver.cpp:106] Iteration 40950, lr = 0.0035
I0525 20:05:27.792299 25020 solver.cpp:237] Iteration 41100, loss = 1.11903
I0525 20:05:27.792492 25020 solver.cpp:253]     Train net output #0: loss = 1.11903 (* 1 = 1.11903 loss)
I0525 20:05:27.792507 25020 sgd_solver.cpp:106] Iteration 41100, lr = 0.0035
I0525 20:05:36.520020 25020 solver.cpp:237] Iteration 41250, loss = 1.53631
I0525 20:05:36.520053 25020 solver.cpp:253]     Train net output #0: loss = 1.53631 (* 1 = 1.53631 loss)
I0525 20:05:36.520071 25020 sgd_solver.cpp:106] Iteration 41250, lr = 0.0035
I0525 20:05:45.247651 25020 solver.cpp:237] Iteration 41400, loss = 1.0697
I0525 20:05:45.247691 25020 solver.cpp:253]     Train net output #0: loss = 1.0697 (* 1 = 1.0697 loss)
I0525 20:05:45.247709 25020 sgd_solver.cpp:106] Iteration 41400, lr = 0.0035
I0525 20:05:53.971048 25020 solver.cpp:237] Iteration 41550, loss = 1.15456
I0525 20:05:53.971083 25020 solver.cpp:253]     Train net output #0: loss = 1.15456 (* 1 = 1.15456 loss)
I0525 20:05:53.971101 25020 sgd_solver.cpp:106] Iteration 41550, lr = 0.0035
I0525 20:06:02.698143 25020 solver.cpp:237] Iteration 41700, loss = 1.04157
I0525 20:06:02.698305 25020 solver.cpp:253]     Train net output #0: loss = 1.04157 (* 1 = 1.04157 loss)
I0525 20:06:02.698320 25020 sgd_solver.cpp:106] Iteration 41700, lr = 0.0035
I0525 20:06:11.428834 25020 solver.cpp:237] Iteration 41850, loss = 1.15484
I0525 20:06:11.428874 25020 solver.cpp:253]     Train net output #0: loss = 1.15484 (* 1 = 1.15484 loss)
I0525 20:06:11.428891 25020 sgd_solver.cpp:106] Iteration 41850, lr = 0.0035
I0525 20:06:20.098176 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_42000.caffemodel
I0525 20:06:20.176494 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_42000.solverstate
I0525 20:06:20.201413 25020 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 20:07:27.940690 25020 solver.cpp:409]     Test net output #0: accuracy = 0.886075
I0525 20:07:27.940873 25020 solver.cpp:409]     Test net output #1: loss = 0.372313 (* 1 = 0.372313 loss)
I0525 20:07:48.805141 25020 solver.cpp:237] Iteration 42000, loss = 1.25064
I0525 20:07:48.805188 25020 solver.cpp:253]     Train net output #0: loss = 1.25064 (* 1 = 1.25064 loss)
I0525 20:07:48.805203 25020 sgd_solver.cpp:106] Iteration 42000, lr = 0.0035
I0525 20:07:57.530122 25020 solver.cpp:237] Iteration 42150, loss = 1.20022
I0525 20:07:57.530158 25020 solver.cpp:253]     Train net output #0: loss = 1.20022 (* 1 = 1.20022 loss)
I0525 20:07:57.530174 25020 sgd_solver.cpp:106] Iteration 42150, lr = 0.0035
I0525 20:08:06.252519 25020 solver.cpp:237] Iteration 42300, loss = 1.19084
I0525 20:08:06.252701 25020 solver.cpp:253]     Train net output #0: loss = 1.19084 (* 1 = 1.19084 loss)
I0525 20:08:06.252714 25020 sgd_solver.cpp:106] Iteration 42300, lr = 0.0035
I0525 20:08:14.978432 25020 solver.cpp:237] Iteration 42450, loss = 1.19353
I0525 20:08:14.978474 25020 solver.cpp:253]     Train net output #0: loss = 1.19353 (* 1 = 1.19353 loss)
I0525 20:08:14.978493 25020 sgd_solver.cpp:106] Iteration 42450, lr = 0.0035
I0525 20:08:23.696190 25020 solver.cpp:237] Iteration 42600, loss = 1.40516
I0525 20:08:23.696225 25020 solver.cpp:253]     Train net output #0: loss = 1.40516 (* 1 = 1.40516 loss)
I0525 20:08:23.696241 25020 sgd_solver.cpp:106] Iteration 42600, lr = 0.0035
I0525 20:08:32.420030 25020 solver.cpp:237] Iteration 42750, loss = 1.18866
I0525 20:08:32.420065 25020 solver.cpp:253]     Train net output #0: loss = 1.18866 (* 1 = 1.18866 loss)
I0525 20:08:32.420081 25020 sgd_solver.cpp:106] Iteration 42750, lr = 0.0035
I0525 20:08:41.144179 25020 solver.cpp:237] Iteration 42900, loss = 1.10673
I0525 20:08:41.144353 25020 solver.cpp:253]     Train net output #0: loss = 1.10673 (* 1 = 1.10673 loss)
I0525 20:08:41.144367 25020 sgd_solver.cpp:106] Iteration 42900, lr = 0.0035
I0525 20:09:10.738322 25020 solver.cpp:237] Iteration 43050, loss = 1.10716
I0525 20:09:10.738371 25020 solver.cpp:253]     Train net output #0: loss = 1.10716 (* 1 = 1.10716 loss)
I0525 20:09:10.738387 25020 sgd_solver.cpp:106] Iteration 43050, lr = 0.0035
I0525 20:09:19.458705 25020 solver.cpp:237] Iteration 43200, loss = 1.3218
I0525 20:09:19.458884 25020 solver.cpp:253]     Train net output #0: loss = 1.3218 (* 1 = 1.3218 loss)
I0525 20:09:19.458897 25020 sgd_solver.cpp:106] Iteration 43200, lr = 0.0035
I0525 20:09:28.179545 25020 solver.cpp:237] Iteration 43350, loss = 1.06106
I0525 20:09:28.179580 25020 solver.cpp:253]     Train net output #0: loss = 1.06106 (* 1 = 1.06106 loss)
I0525 20:09:28.179601 25020 sgd_solver.cpp:106] Iteration 43350, lr = 0.0035
I0525 20:09:36.844161 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_43500.caffemodel
I0525 20:09:36.924631 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_43500.solverstate
I0525 20:09:36.969801 25020 solver.cpp:237] Iteration 43500, loss = 1.26049
I0525 20:09:36.969852 25020 solver.cpp:253]     Train net output #0: loss = 1.26049 (* 1 = 1.26049 loss)
I0525 20:09:36.969866 25020 sgd_solver.cpp:106] Iteration 43500, lr = 0.0035
I0525 20:09:45.691886 25020 solver.cpp:237] Iteration 43650, loss = 1.28174
I0525 20:09:45.691922 25020 solver.cpp:253]     Train net output #0: loss = 1.28174 (* 1 = 1.28174 loss)
I0525 20:09:45.691937 25020 sgd_solver.cpp:106] Iteration 43650, lr = 0.0035
I0525 20:09:54.416554 25020 solver.cpp:237] Iteration 43800, loss = 1.37626
I0525 20:09:54.416728 25020 solver.cpp:253]     Train net output #0: loss = 1.37626 (* 1 = 1.37626 loss)
I0525 20:09:54.416743 25020 sgd_solver.cpp:106] Iteration 43800, lr = 0.0035
I0525 20:10:03.141690 25020 solver.cpp:237] Iteration 43950, loss = 1.19993
I0525 20:10:03.141724 25020 solver.cpp:253]     Train net output #0: loss = 1.19993 (* 1 = 1.19993 loss)
I0525 20:10:03.141738 25020 sgd_solver.cpp:106] Iteration 43950, lr = 0.0035
I0525 20:10:32.738303 25020 solver.cpp:237] Iteration 44100, loss = 0.99766
I0525 20:10:32.738489 25020 solver.cpp:253]     Train net output #0: loss = 0.99766 (* 1 = 0.99766 loss)
I0525 20:10:32.738505 25020 sgd_solver.cpp:106] Iteration 44100, lr = 0.0035
I0525 20:10:41.461092 25020 solver.cpp:237] Iteration 44250, loss = 1.19004
I0525 20:10:41.461128 25020 solver.cpp:253]     Train net output #0: loss = 1.19004 (* 1 = 1.19004 loss)
I0525 20:10:41.461146 25020 sgd_solver.cpp:106] Iteration 44250, lr = 0.0035
I0525 20:10:50.181870 25020 solver.cpp:237] Iteration 44400, loss = 1.16409
I0525 20:10:50.181905 25020 solver.cpp:253]     Train net output #0: loss = 1.16409 (* 1 = 1.16409 loss)
I0525 20:10:50.181918 25020 sgd_solver.cpp:106] Iteration 44400, lr = 0.0035
I0525 20:10:58.908563 25020 solver.cpp:237] Iteration 44550, loss = 1.18718
I0525 20:10:58.908598 25020 solver.cpp:253]     Train net output #0: loss = 1.18718 (* 1 = 1.18718 loss)
I0525 20:10:58.908614 25020 sgd_solver.cpp:106] Iteration 44550, lr = 0.0035
I0525 20:11:07.631253 25020 solver.cpp:237] Iteration 44700, loss = 1.03823
I0525 20:11:07.631419 25020 solver.cpp:253]     Train net output #0: loss = 1.03823 (* 1 = 1.03823 loss)
I0525 20:11:07.631433 25020 sgd_solver.cpp:106] Iteration 44700, lr = 0.0035
I0525 20:11:16.352500 25020 solver.cpp:237] Iteration 44850, loss = 1.13263
I0525 20:11:16.352535 25020 solver.cpp:253]     Train net output #0: loss = 1.13263 (* 1 = 1.13263 loss)
I0525 20:11:16.352551 25020 sgd_solver.cpp:106] Iteration 44850, lr = 0.0035
I0525 20:11:25.020843 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_45000.caffemodel
I0525 20:11:25.101016 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_45000.solverstate
I0525 20:11:25.128489 25020 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 20:12:11.673012 25020 solver.cpp:409]     Test net output #0: accuracy = 0.888202
I0525 20:12:11.673209 25020 solver.cpp:409]     Test net output #1: loss = 0.379407 (* 1 = 0.379407 loss)
I0525 20:12:32.536331 25020 solver.cpp:237] Iteration 45000, loss = 1.10335
I0525 20:12:32.536383 25020 solver.cpp:253]     Train net output #0: loss = 1.10335 (* 1 = 1.10335 loss)
I0525 20:12:32.536398 25020 sgd_solver.cpp:106] Iteration 45000, lr = 0.0035
I0525 20:12:41.261451 25020 solver.cpp:237] Iteration 45150, loss = 1.09586
I0525 20:12:41.261481 25020 solver.cpp:253]     Train net output #0: loss = 1.09586 (* 1 = 1.09586 loss)
I0525 20:12:41.261497 25020 sgd_solver.cpp:106] Iteration 45150, lr = 0.0035
I0525 20:12:49.995343 25020 solver.cpp:237] Iteration 45300, loss = 1.30937
I0525 20:12:49.995524 25020 solver.cpp:253]     Train net output #0: loss = 1.30937 (* 1 = 1.30937 loss)
I0525 20:12:49.995539 25020 sgd_solver.cpp:106] Iteration 45300, lr = 0.0035
I0525 20:12:58.721107 25020 solver.cpp:237] Iteration 45450, loss = 1.04958
I0525 20:12:58.721141 25020 solver.cpp:253]     Train net output #0: loss = 1.04958 (* 1 = 1.04958 loss)
I0525 20:12:58.721158 25020 sgd_solver.cpp:106] Iteration 45450, lr = 0.0035
I0525 20:13:07.449877 25020 solver.cpp:237] Iteration 45600, loss = 1.25737
I0525 20:13:07.449913 25020 solver.cpp:253]     Train net output #0: loss = 1.25737 (* 1 = 1.25737 loss)
I0525 20:13:07.449928 25020 sgd_solver.cpp:106] Iteration 45600, lr = 0.0035
I0525 20:13:16.174963 25020 solver.cpp:237] Iteration 45750, loss = 1.02568
I0525 20:13:16.175006 25020 solver.cpp:253]     Train net output #0: loss = 1.02568 (* 1 = 1.02568 loss)
I0525 20:13:16.175024 25020 sgd_solver.cpp:106] Iteration 45750, lr = 0.0035
I0525 20:13:24.899860 25020 solver.cpp:237] Iteration 45900, loss = 1.02446
I0525 20:13:24.900033 25020 solver.cpp:253]     Train net output #0: loss = 1.02446 (* 1 = 1.02446 loss)
I0525 20:13:24.900049 25020 sgd_solver.cpp:106] Iteration 45900, lr = 0.0035
I0525 20:13:54.512645 25020 solver.cpp:237] Iteration 46050, loss = 1.15232
I0525 20:13:54.512693 25020 solver.cpp:253]     Train net output #0: loss = 1.15232 (* 1 = 1.15232 loss)
I0525 20:13:54.512712 25020 sgd_solver.cpp:106] Iteration 46050, lr = 0.0035
I0525 20:14:03.235857 25020 solver.cpp:237] Iteration 46200, loss = 1.07389
I0525 20:14:03.236033 25020 solver.cpp:253]     Train net output #0: loss = 1.07389 (* 1 = 1.07389 loss)
I0525 20:14:03.236048 25020 sgd_solver.cpp:106] Iteration 46200, lr = 0.0035
I0525 20:14:11.961534 25020 solver.cpp:237] Iteration 46350, loss = 1.29899
I0525 20:14:11.961568 25020 solver.cpp:253]     Train net output #0: loss = 1.29899 (* 1 = 1.29899 loss)
I0525 20:14:11.961585 25020 sgd_solver.cpp:106] Iteration 46350, lr = 0.0035
I0525 20:14:20.629127 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_46500.caffemodel
I0525 20:14:20.707454 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_46500.solverstate
I0525 20:14:20.750769 25020 solver.cpp:237] Iteration 46500, loss = 1.15123
I0525 20:14:20.750816 25020 solver.cpp:253]     Train net output #0: loss = 1.15123 (* 1 = 1.15123 loss)
I0525 20:14:20.750831 25020 sgd_solver.cpp:106] Iteration 46500, lr = 0.0035
I0525 20:14:29.478816 25020 solver.cpp:237] Iteration 46650, loss = 1.28824
I0525 20:14:29.478857 25020 solver.cpp:253]     Train net output #0: loss = 1.28824 (* 1 = 1.28824 loss)
I0525 20:14:29.478878 25020 sgd_solver.cpp:106] Iteration 46650, lr = 0.0035
I0525 20:14:38.205773 25020 solver.cpp:237] Iteration 46800, loss = 1.06182
I0525 20:14:38.205951 25020 solver.cpp:253]     Train net output #0: loss = 1.06182 (* 1 = 1.06182 loss)
I0525 20:14:38.205965 25020 sgd_solver.cpp:106] Iteration 46800, lr = 0.0035
I0525 20:14:46.929759 25020 solver.cpp:237] Iteration 46950, loss = 1.17868
I0525 20:14:46.929792 25020 solver.cpp:253]     Train net output #0: loss = 1.17868 (* 1 = 1.17868 loss)
I0525 20:14:46.929807 25020 sgd_solver.cpp:106] Iteration 46950, lr = 0.0035
I0525 20:15:16.490334 25020 solver.cpp:237] Iteration 47100, loss = 1.11553
I0525 20:15:16.490522 25020 solver.cpp:253]     Train net output #0: loss = 1.11553 (* 1 = 1.11553 loss)
I0525 20:15:16.490536 25020 sgd_solver.cpp:106] Iteration 47100, lr = 0.0035
I0525 20:15:25.216053 25020 solver.cpp:237] Iteration 47250, loss = 1.22688
I0525 20:15:25.216087 25020 solver.cpp:253]     Train net output #0: loss = 1.22688 (* 1 = 1.22688 loss)
I0525 20:15:25.216105 25020 sgd_solver.cpp:106] Iteration 47250, lr = 0.0035
I0525 20:15:33.940277 25020 solver.cpp:237] Iteration 47400, loss = 1.08322
I0525 20:15:33.940313 25020 solver.cpp:253]     Train net output #0: loss = 1.08322 (* 1 = 1.08322 loss)
I0525 20:15:33.940330 25020 sgd_solver.cpp:106] Iteration 47400, lr = 0.0035
I0525 20:15:42.668835 25020 solver.cpp:237] Iteration 47550, loss = 0.996716
I0525 20:15:42.668879 25020 solver.cpp:253]     Train net output #0: loss = 0.996716 (* 1 = 0.996716 loss)
I0525 20:15:42.668896 25020 sgd_solver.cpp:106] Iteration 47550, lr = 0.0035
I0525 20:15:51.392618 25020 solver.cpp:237] Iteration 47700, loss = 1.06423
I0525 20:15:51.392782 25020 solver.cpp:253]     Train net output #0: loss = 1.06423 (* 1 = 1.06423 loss)
I0525 20:15:51.392796 25020 sgd_solver.cpp:106] Iteration 47700, lr = 0.0035
I0525 20:16:00.115355 25020 solver.cpp:237] Iteration 47850, loss = 1.37656
I0525 20:16:00.115389 25020 solver.cpp:253]     Train net output #0: loss = 1.37656 (* 1 = 1.37656 loss)
I0525 20:16:00.115407 25020 sgd_solver.cpp:106] Iteration 47850, lr = 0.0035
I0525 20:16:08.780596 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_48000.caffemodel
I0525 20:16:08.858824 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_48000.solverstate
I0525 20:16:08.885197 25020 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 20:17:16.621109 25020 solver.cpp:409]     Test net output #0: accuracy = 0.887835
I0525 20:17:16.621305 25020 solver.cpp:409]     Test net output #1: loss = 0.363368 (* 1 = 0.363368 loss)
I0525 20:17:37.512171 25020 solver.cpp:237] Iteration 48000, loss = 1.07878
I0525 20:17:37.512223 25020 solver.cpp:253]     Train net output #0: loss = 1.07878 (* 1 = 1.07878 loss)
I0525 20:17:37.512241 25020 sgd_solver.cpp:106] Iteration 48000, lr = 0.0035
I0525 20:17:46.234232 25020 solver.cpp:237] Iteration 48150, loss = 1.17199
I0525 20:17:46.234278 25020 solver.cpp:253]     Train net output #0: loss = 1.17199 (* 1 = 1.17199 loss)
I0525 20:17:46.234294 25020 sgd_solver.cpp:106] Iteration 48150, lr = 0.0035
I0525 20:17:54.960225 25020 solver.cpp:237] Iteration 48300, loss = 1.12933
I0525 20:17:54.960405 25020 solver.cpp:253]     Train net output #0: loss = 1.12933 (* 1 = 1.12933 loss)
I0525 20:17:54.960420 25020 sgd_solver.cpp:106] Iteration 48300, lr = 0.0035
I0525 20:18:03.679596 25020 solver.cpp:237] Iteration 48450, loss = 1.19954
I0525 20:18:03.679631 25020 solver.cpp:253]     Train net output #0: loss = 1.19954 (* 1 = 1.19954 loss)
I0525 20:18:03.679649 25020 sgd_solver.cpp:106] Iteration 48450, lr = 0.0035
I0525 20:18:12.400784 25020 solver.cpp:237] Iteration 48600, loss = 1.03219
I0525 20:18:12.400823 25020 solver.cpp:253]     Train net output #0: loss = 1.03219 (* 1 = 1.03219 loss)
I0525 20:18:12.400841 25020 sgd_solver.cpp:106] Iteration 48600, lr = 0.0035
I0525 20:18:21.123356 25020 solver.cpp:237] Iteration 48750, loss = 1.13011
I0525 20:18:21.123391 25020 solver.cpp:253]     Train net output #0: loss = 1.13011 (* 1 = 1.13011 loss)
I0525 20:18:21.123407 25020 sgd_solver.cpp:106] Iteration 48750, lr = 0.0035
I0525 20:18:29.846755 25020 solver.cpp:237] Iteration 48900, loss = 1.12452
I0525 20:18:29.846931 25020 solver.cpp:253]     Train net output #0: loss = 1.12452 (* 1 = 1.12452 loss)
I0525 20:18:29.846945 25020 sgd_solver.cpp:106] Iteration 48900, lr = 0.0035
I0525 20:18:59.442204 25020 solver.cpp:237] Iteration 49050, loss = 1.2286
I0525 20:18:59.442256 25020 solver.cpp:253]     Train net output #0: loss = 1.2286 (* 1 = 1.2286 loss)
I0525 20:18:59.442271 25020 sgd_solver.cpp:106] Iteration 49050, lr = 0.0035
I0525 20:19:08.169983 25020 solver.cpp:237] Iteration 49200, loss = 1.04657
I0525 20:19:08.170156 25020 solver.cpp:253]     Train net output #0: loss = 1.04657 (* 1 = 1.04657 loss)
I0525 20:19:08.170169 25020 sgd_solver.cpp:106] Iteration 49200, lr = 0.0035
I0525 20:19:16.888128 25020 solver.cpp:237] Iteration 49350, loss = 1.1332
I0525 20:19:16.888160 25020 solver.cpp:253]     Train net output #0: loss = 1.1332 (* 1 = 1.1332 loss)
I0525 20:19:16.888178 25020 sgd_solver.cpp:106] Iteration 49350, lr = 0.0035
I0525 20:19:25.554443 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_49500.caffemodel
I0525 20:19:25.632361 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_49500.solverstate
I0525 20:19:25.677407 25020 solver.cpp:237] Iteration 49500, loss = 1.29859
I0525 20:19:25.677456 25020 solver.cpp:253]     Train net output #0: loss = 1.29859 (* 1 = 1.29859 loss)
I0525 20:19:25.677474 25020 sgd_solver.cpp:106] Iteration 49500, lr = 0.0035
I0525 20:19:34.394896 25020 solver.cpp:237] Iteration 49650, loss = 1.19162
I0525 20:19:34.394930 25020 solver.cpp:253]     Train net output #0: loss = 1.19162 (* 1 = 1.19162 loss)
I0525 20:19:34.394944 25020 sgd_solver.cpp:106] Iteration 49650, lr = 0.0035
I0525 20:19:43.117152 25020 solver.cpp:237] Iteration 49800, loss = 1.28026
I0525 20:19:43.117333 25020 solver.cpp:253]     Train net output #0: loss = 1.28026 (* 1 = 1.28026 loss)
I0525 20:19:43.117348 25020 sgd_solver.cpp:106] Iteration 49800, lr = 0.0035
I0525 20:19:51.837972 25020 solver.cpp:237] Iteration 49950, loss = 1.2706
I0525 20:19:51.838021 25020 solver.cpp:253]     Train net output #0: loss = 1.2706 (* 1 = 1.2706 loss)
I0525 20:19:51.838037 25020 sgd_solver.cpp:106] Iteration 49950, lr = 0.0035
I0525 20:20:21.436096 25020 solver.cpp:237] Iteration 50100, loss = 1.18528
I0525 20:20:21.436292 25020 solver.cpp:253]     Train net output #0: loss = 1.18528 (* 1 = 1.18528 loss)
I0525 20:20:21.436307 25020 sgd_solver.cpp:106] Iteration 50100, lr = 0.0035
I0525 20:20:30.162925 25020 solver.cpp:237] Iteration 50250, loss = 1.12699
I0525 20:20:30.162960 25020 solver.cpp:253]     Train net output #0: loss = 1.12699 (* 1 = 1.12699 loss)
I0525 20:20:30.162977 25020 sgd_solver.cpp:106] Iteration 50250, lr = 0.0035
I0525 20:20:38.891093 25020 solver.cpp:237] Iteration 50400, loss = 1.1916
I0525 20:20:38.891134 25020 solver.cpp:253]     Train net output #0: loss = 1.1916 (* 1 = 1.1916 loss)
I0525 20:20:38.891149 25020 sgd_solver.cpp:106] Iteration 50400, lr = 0.0035
I0525 20:20:47.612709 25020 solver.cpp:237] Iteration 50550, loss = 1.15727
I0525 20:20:47.612745 25020 solver.cpp:253]     Train net output #0: loss = 1.15727 (* 1 = 1.15727 loss)
I0525 20:20:47.612758 25020 sgd_solver.cpp:106] Iteration 50550, lr = 0.0035
I0525 20:20:56.338567 25020 solver.cpp:237] Iteration 50700, loss = 1.07093
I0525 20:20:56.338732 25020 solver.cpp:253]     Train net output #0: loss = 1.07093 (* 1 = 1.07093 loss)
I0525 20:20:56.338745 25020 sgd_solver.cpp:106] Iteration 50700, lr = 0.0035
I0525 20:21:05.062263 25020 solver.cpp:237] Iteration 50850, loss = 0.910243
I0525 20:21:05.062301 25020 solver.cpp:253]     Train net output #0: loss = 0.910243 (* 1 = 0.910243 loss)
I0525 20:21:05.062321 25020 sgd_solver.cpp:106] Iteration 50850, lr = 0.0035
I0525 20:21:13.726730 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_51000.caffemodel
I0525 20:21:13.805611 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_51000.solverstate
I0525 20:21:13.831727 25020 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 20:22:00.734150 25020 solver.cpp:409]     Test net output #0: accuracy = 0.890781
I0525 20:22:00.734346 25020 solver.cpp:409]     Test net output #1: loss = 0.378041 (* 1 = 0.378041 loss)
I0525 20:22:21.648604 25020 solver.cpp:237] Iteration 51000, loss = 1.15454
I0525 20:22:21.648658 25020 solver.cpp:253]     Train net output #0: loss = 1.15454 (* 1 = 1.15454 loss)
I0525 20:22:21.648674 25020 sgd_solver.cpp:106] Iteration 51000, lr = 0.0035
I0525 20:22:30.376945 25020 solver.cpp:237] Iteration 51150, loss = 1.15611
I0525 20:22:30.376979 25020 solver.cpp:253]     Train net output #0: loss = 1.15611 (* 1 = 1.15611 loss)
I0525 20:22:30.376994 25020 sgd_solver.cpp:106] Iteration 51150, lr = 0.0035
I0525 20:22:39.105156 25020 solver.cpp:237] Iteration 51300, loss = 1.29951
I0525 20:22:39.105331 25020 solver.cpp:253]     Train net output #0: loss = 1.29951 (* 1 = 1.29951 loss)
I0525 20:22:39.105345 25020 sgd_solver.cpp:106] Iteration 51300, lr = 0.0035
I0525 20:22:47.840277 25020 solver.cpp:237] Iteration 51450, loss = 1.07315
I0525 20:22:47.840323 25020 solver.cpp:253]     Train net output #0: loss = 1.07315 (* 1 = 1.07315 loss)
I0525 20:22:47.840340 25020 sgd_solver.cpp:106] Iteration 51450, lr = 0.0035
I0525 20:22:56.564558 25020 solver.cpp:237] Iteration 51600, loss = 1.33557
I0525 20:22:56.564594 25020 solver.cpp:253]     Train net output #0: loss = 1.33557 (* 1 = 1.33557 loss)
I0525 20:22:56.564609 25020 sgd_solver.cpp:106] Iteration 51600, lr = 0.0035
I0525 20:23:05.291087 25020 solver.cpp:237] Iteration 51750, loss = 1.07827
I0525 20:23:05.291123 25020 solver.cpp:253]     Train net output #0: loss = 1.07827 (* 1 = 1.07827 loss)
I0525 20:23:05.291139 25020 sgd_solver.cpp:106] Iteration 51750, lr = 0.0035
I0525 20:23:14.019438 25020 solver.cpp:237] Iteration 51900, loss = 1.25541
I0525 20:23:14.019616 25020 solver.cpp:253]     Train net output #0: loss = 1.25541 (* 1 = 1.25541 loss)
I0525 20:23:14.019630 25020 sgd_solver.cpp:106] Iteration 51900, lr = 0.0035
I0525 20:23:43.651954 25020 solver.cpp:237] Iteration 52050, loss = 1.24898
I0525 20:23:43.652004 25020 solver.cpp:253]     Train net output #0: loss = 1.24898 (* 1 = 1.24898 loss)
I0525 20:23:43.652021 25020 sgd_solver.cpp:106] Iteration 52050, lr = 0.0035
I0525 20:23:52.381467 25020 solver.cpp:237] Iteration 52200, loss = 1.08478
I0525 20:23:52.381640 25020 solver.cpp:253]     Train net output #0: loss = 1.08478 (* 1 = 1.08478 loss)
I0525 20:23:52.381655 25020 sgd_solver.cpp:106] Iteration 52200, lr = 0.0035
I0525 20:24:01.111883 25020 solver.cpp:237] Iteration 52350, loss = 1.05992
I0525 20:24:01.111920 25020 solver.cpp:253]     Train net output #0: loss = 1.05992 (* 1 = 1.05992 loss)
I0525 20:24:01.111942 25020 sgd_solver.cpp:106] Iteration 52350, lr = 0.0035
I0525 20:24:09.782019 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_52500.caffemodel
I0525 20:24:09.862048 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_52500.solverstate
I0525 20:24:09.907202 25020 solver.cpp:237] Iteration 52500, loss = 0.971704
I0525 20:24:09.907255 25020 solver.cpp:253]     Train net output #0: loss = 0.971704 (* 1 = 0.971704 loss)
I0525 20:24:09.907269 25020 sgd_solver.cpp:106] Iteration 52500, lr = 0.0035
I0525 20:24:18.633348 25020 solver.cpp:237] Iteration 52650, loss = 1.18081
I0525 20:24:18.633383 25020 solver.cpp:253]     Train net output #0: loss = 1.18081 (* 1 = 1.18081 loss)
I0525 20:24:18.633399 25020 sgd_solver.cpp:106] Iteration 52650, lr = 0.0035
I0525 20:24:27.362267 25020 solver.cpp:237] Iteration 52800, loss = 1.03671
I0525 20:24:27.362463 25020 solver.cpp:253]     Train net output #0: loss = 1.03671 (* 1 = 1.03671 loss)
I0525 20:24:27.362478 25020 sgd_solver.cpp:106] Iteration 52800, lr = 0.0035
I0525 20:24:36.091727 25020 solver.cpp:237] Iteration 52950, loss = 1.32305
I0525 20:24:36.091763 25020 solver.cpp:253]     Train net output #0: loss = 1.32305 (* 1 = 1.32305 loss)
I0525 20:24:36.091779 25020 sgd_solver.cpp:106] Iteration 52950, lr = 0.0035
I0525 20:25:05.727490 25020 solver.cpp:237] Iteration 53100, loss = 1.21835
I0525 20:25:05.727682 25020 solver.cpp:253]     Train net output #0: loss = 1.21835 (* 1 = 1.21835 loss)
I0525 20:25:05.727697 25020 sgd_solver.cpp:106] Iteration 53100, lr = 0.0035
I0525 20:25:14.453467 25020 solver.cpp:237] Iteration 53250, loss = 0.893001
I0525 20:25:14.453512 25020 solver.cpp:253]     Train net output #0: loss = 0.893001 (* 1 = 0.893001 loss)
I0525 20:25:14.453529 25020 sgd_solver.cpp:106] Iteration 53250, lr = 0.0035
I0525 20:25:23.181413 25020 solver.cpp:237] Iteration 53400, loss = 1.01824
I0525 20:25:23.181449 25020 solver.cpp:253]     Train net output #0: loss = 1.01824 (* 1 = 1.01824 loss)
I0525 20:25:23.181465 25020 sgd_solver.cpp:106] Iteration 53400, lr = 0.0035
I0525 20:25:31.910405 25020 solver.cpp:237] Iteration 53550, loss = 1.30282
I0525 20:25:31.910440 25020 solver.cpp:253]     Train net output #0: loss = 1.30282 (* 1 = 1.30282 loss)
I0525 20:25:31.910454 25020 sgd_solver.cpp:106] Iteration 53550, lr = 0.0035
I0525 20:25:40.635293 25020 solver.cpp:237] Iteration 53700, loss = 1.17188
I0525 20:25:40.635473 25020 solver.cpp:253]     Train net output #0: loss = 1.17188 (* 1 = 1.17188 loss)
I0525 20:25:40.635488 25020 sgd_solver.cpp:106] Iteration 53700, lr = 0.0035
I0525 20:25:49.364042 25020 solver.cpp:237] Iteration 53850, loss = 1.01853
I0525 20:25:49.364078 25020 solver.cpp:253]     Train net output #0: loss = 1.01853 (* 1 = 1.01853 loss)
I0525 20:25:49.364094 25020 sgd_solver.cpp:106] Iteration 53850, lr = 0.0035
I0525 20:25:58.034446 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_54000.caffemodel
I0525 20:25:58.116085 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_54000.solverstate
I0525 20:25:58.146455 25020 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 20:27:06.003031 25020 solver.cpp:409]     Test net output #0: accuracy = 0.893475
I0525 20:27:06.003232 25020 solver.cpp:409]     Test net output #1: loss = 0.329496 (* 1 = 0.329496 loss)
I0525 20:27:26.920583 25020 solver.cpp:237] Iteration 54000, loss = 1.08944
I0525 20:27:26.920635 25020 solver.cpp:253]     Train net output #0: loss = 1.08944 (* 1 = 1.08944 loss)
I0525 20:27:26.920651 25020 sgd_solver.cpp:106] Iteration 54000, lr = 0.0035
I0525 20:27:35.649092 25020 solver.cpp:237] Iteration 54150, loss = 0.863702
I0525 20:27:35.649128 25020 solver.cpp:253]     Train net output #0: loss = 0.863702 (* 1 = 0.863702 loss)
I0525 20:27:35.649145 25020 sgd_solver.cpp:106] Iteration 54150, lr = 0.0035
I0525 20:27:44.371583 25020 solver.cpp:237] Iteration 54300, loss = 1.04328
I0525 20:27:44.371767 25020 solver.cpp:253]     Train net output #0: loss = 1.04328 (* 1 = 1.04328 loss)
I0525 20:27:44.371781 25020 sgd_solver.cpp:106] Iteration 54300, lr = 0.0035
I0525 20:27:53.093019 25020 solver.cpp:237] Iteration 54450, loss = 1.19839
I0525 20:27:53.093057 25020 solver.cpp:253]     Train net output #0: loss = 1.19839 (* 1 = 1.19839 loss)
I0525 20:27:53.093075 25020 sgd_solver.cpp:106] Iteration 54450, lr = 0.0035
I0525 20:28:01.814662 25020 solver.cpp:237] Iteration 54600, loss = 1.07468
I0525 20:28:01.814697 25020 solver.cpp:253]     Train net output #0: loss = 1.07468 (* 1 = 1.07468 loss)
I0525 20:28:01.814713 25020 sgd_solver.cpp:106] Iteration 54600, lr = 0.0035
I0525 20:28:10.532410 25020 solver.cpp:237] Iteration 54750, loss = 1.29771
I0525 20:28:10.532449 25020 solver.cpp:253]     Train net output #0: loss = 1.29771 (* 1 = 1.29771 loss)
I0525 20:28:10.532469 25020 sgd_solver.cpp:106] Iteration 54750, lr = 0.0035
I0525 20:28:19.250125 25020 solver.cpp:237] Iteration 54900, loss = 1.2181
I0525 20:28:19.250315 25020 solver.cpp:253]     Train net output #0: loss = 1.2181 (* 1 = 1.2181 loss)
I0525 20:28:19.250329 25020 sgd_solver.cpp:106] Iteration 54900, lr = 0.0035
I0525 20:28:48.867193 25020 solver.cpp:237] Iteration 55050, loss = 1.23751
I0525 20:28:48.867244 25020 solver.cpp:253]     Train net output #0: loss = 1.23751 (* 1 = 1.23751 loss)
I0525 20:28:48.867260 25020 sgd_solver.cpp:106] Iteration 55050, lr = 0.0035
I0525 20:28:57.591929 25020 solver.cpp:237] Iteration 55200, loss = 1.22996
I0525 20:28:57.592106 25020 solver.cpp:253]     Train net output #0: loss = 1.22996 (* 1 = 1.22996 loss)
I0525 20:28:57.592119 25020 sgd_solver.cpp:106] Iteration 55200, lr = 0.0035
I0525 20:29:06.311470 25020 solver.cpp:237] Iteration 55350, loss = 1.07744
I0525 20:29:06.311512 25020 solver.cpp:253]     Train net output #0: loss = 1.07744 (* 1 = 1.07744 loss)
I0525 20:29:06.311530 25020 sgd_solver.cpp:106] Iteration 55350, lr = 0.0035
I0525 20:29:14.971417 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_55500.caffemodel
I0525 20:29:15.050411 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_55500.solverstate
I0525 20:29:15.093889 25020 solver.cpp:237] Iteration 55500, loss = 1.03717
I0525 20:29:15.093933 25020 solver.cpp:253]     Train net output #0: loss = 1.03717 (* 1 = 1.03717 loss)
I0525 20:29:15.093951 25020 sgd_solver.cpp:106] Iteration 55500, lr = 0.0035
I0525 20:29:23.819272 25020 solver.cpp:237] Iteration 55650, loss = 1.01626
I0525 20:29:23.819317 25020 solver.cpp:253]     Train net output #0: loss = 1.01626 (* 1 = 1.01626 loss)
I0525 20:29:23.819334 25020 sgd_solver.cpp:106] Iteration 55650, lr = 0.0035
I0525 20:29:32.538750 25020 solver.cpp:237] Iteration 55800, loss = 1.06982
I0525 20:29:32.538926 25020 solver.cpp:253]     Train net output #0: loss = 1.06982 (* 1 = 1.06982 loss)
I0525 20:29:32.538939 25020 sgd_solver.cpp:106] Iteration 55800, lr = 0.0035
I0525 20:29:41.255925 25020 solver.cpp:237] Iteration 55950, loss = 0.939692
I0525 20:29:41.255960 25020 solver.cpp:253]     Train net output #0: loss = 0.939692 (* 1 = 0.939692 loss)
I0525 20:29:41.255978 25020 sgd_solver.cpp:106] Iteration 55950, lr = 0.0035
I0525 20:30:10.865813 25020 solver.cpp:237] Iteration 56100, loss = 0.938892
I0525 20:30:10.866005 25020 solver.cpp:253]     Train net output #0: loss = 0.938892 (* 1 = 0.938892 loss)
I0525 20:30:10.866021 25020 sgd_solver.cpp:106] Iteration 56100, lr = 0.0035
I0525 20:30:19.584681 25020 solver.cpp:237] Iteration 56250, loss = 1.20884
I0525 20:30:19.584727 25020 solver.cpp:253]     Train net output #0: loss = 1.20884 (* 1 = 1.20884 loss)
I0525 20:30:19.584744 25020 sgd_solver.cpp:106] Iteration 56250, lr = 0.0035
I0525 20:30:28.304378 25020 solver.cpp:237] Iteration 56400, loss = 0.937394
I0525 20:30:28.304414 25020 solver.cpp:253]     Train net output #0: loss = 0.937394 (* 1 = 0.937394 loss)
I0525 20:30:28.304430 25020 sgd_solver.cpp:106] Iteration 56400, lr = 0.0035
I0525 20:30:37.028826 25020 solver.cpp:237] Iteration 56550, loss = 1.23518
I0525 20:30:37.028861 25020 solver.cpp:253]     Train net output #0: loss = 1.23518 (* 1 = 1.23518 loss)
I0525 20:30:37.028877 25020 sgd_solver.cpp:106] Iteration 56550, lr = 0.0035
I0525 20:30:45.754564 25020 solver.cpp:237] Iteration 56700, loss = 1.20323
I0525 20:30:45.754757 25020 solver.cpp:253]     Train net output #0: loss = 1.20323 (* 1 = 1.20323 loss)
I0525 20:30:45.754771 25020 sgd_solver.cpp:106] Iteration 56700, lr = 0.0035
I0525 20:30:54.470170 25020 solver.cpp:237] Iteration 56850, loss = 1.24837
I0525 20:30:54.470203 25020 solver.cpp:253]     Train net output #0: loss = 1.24837 (* 1 = 1.24837 loss)
I0525 20:30:54.470221 25020 sgd_solver.cpp:106] Iteration 56850, lr = 0.0035
I0525 20:31:03.134306 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_57000.caffemodel
I0525 20:31:03.213150 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_57000.solverstate
I0525 20:31:03.238821 25020 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 20:31:49.805263 25020 solver.cpp:409]     Test net output #0: accuracy = 0.886656
I0525 20:31:49.805454 25020 solver.cpp:409]     Test net output #1: loss = 0.356827 (* 1 = 0.356827 loss)
I0525 20:32:10.723019 25020 solver.cpp:237] Iteration 57000, loss = 1.28575
I0525 20:32:10.723073 25020 solver.cpp:253]     Train net output #0: loss = 1.28575 (* 1 = 1.28575 loss)
I0525 20:32:10.723088 25020 sgd_solver.cpp:106] Iteration 57000, lr = 0.0035
I0525 20:32:19.451925 25020 solver.cpp:237] Iteration 57150, loss = 1.18725
I0525 20:32:19.451973 25020 solver.cpp:253]     Train net output #0: loss = 1.18725 (* 1 = 1.18725 loss)
I0525 20:32:19.451989 25020 sgd_solver.cpp:106] Iteration 57150, lr = 0.0035
I0525 20:32:28.183357 25020 solver.cpp:237] Iteration 57300, loss = 1.06528
I0525 20:32:28.183534 25020 solver.cpp:253]     Train net output #0: loss = 1.06528 (* 1 = 1.06528 loss)
I0525 20:32:28.183547 25020 sgd_solver.cpp:106] Iteration 57300, lr = 0.0035
I0525 20:32:36.907937 25020 solver.cpp:237] Iteration 57450, loss = 1.28139
I0525 20:32:36.907971 25020 solver.cpp:253]     Train net output #0: loss = 1.28139 (* 1 = 1.28139 loss)
I0525 20:32:36.907989 25020 sgd_solver.cpp:106] Iteration 57450, lr = 0.0035
I0525 20:32:45.633265 25020 solver.cpp:237] Iteration 57600, loss = 1.14657
I0525 20:32:45.633311 25020 solver.cpp:253]     Train net output #0: loss = 1.14657 (* 1 = 1.14657 loss)
I0525 20:32:45.633327 25020 sgd_solver.cpp:106] Iteration 57600, lr = 0.0035
I0525 20:32:54.359946 25020 solver.cpp:237] Iteration 57750, loss = 1.29738
I0525 20:32:54.359982 25020 solver.cpp:253]     Train net output #0: loss = 1.29738 (* 1 = 1.29738 loss)
I0525 20:32:54.359997 25020 sgd_solver.cpp:106] Iteration 57750, lr = 0.0035
I0525 20:33:03.087663 25020 solver.cpp:237] Iteration 57900, loss = 1.07561
I0525 20:33:03.087836 25020 solver.cpp:253]     Train net output #0: loss = 1.07561 (* 1 = 1.07561 loss)
I0525 20:33:03.087851 25020 sgd_solver.cpp:106] Iteration 57900, lr = 0.0035
I0525 20:33:32.716560 25020 solver.cpp:237] Iteration 58050, loss = 1.08003
I0525 20:33:32.716611 25020 solver.cpp:253]     Train net output #0: loss = 1.08003 (* 1 = 1.08003 loss)
I0525 20:33:32.716629 25020 sgd_solver.cpp:106] Iteration 58050, lr = 0.0035
I0525 20:33:41.443727 25020 solver.cpp:237] Iteration 58200, loss = 1.33096
I0525 20:33:41.443922 25020 solver.cpp:253]     Train net output #0: loss = 1.33096 (* 1 = 1.33096 loss)
I0525 20:33:41.443936 25020 sgd_solver.cpp:106] Iteration 58200, lr = 0.0035
I0525 20:33:50.174522 25020 solver.cpp:237] Iteration 58350, loss = 1.35207
I0525 20:33:50.174556 25020 solver.cpp:253]     Train net output #0: loss = 1.35207 (* 1 = 1.35207 loss)
I0525 20:33:50.174571 25020 sgd_solver.cpp:106] Iteration 58350, lr = 0.0035
I0525 20:33:58.845360 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_58500.caffemodel
I0525 20:33:58.933866 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_58500.solverstate
I0525 20:33:58.977689 25020 solver.cpp:237] Iteration 58500, loss = 1.47813
I0525 20:33:58.977735 25020 solver.cpp:253]     Train net output #0: loss = 1.47813 (* 1 = 1.47813 loss)
I0525 20:33:58.977751 25020 sgd_solver.cpp:106] Iteration 58500, lr = 0.0035
I0525 20:34:07.702185 25020 solver.cpp:237] Iteration 58650, loss = 1.24393
I0525 20:34:07.702220 25020 solver.cpp:253]     Train net output #0: loss = 1.24393 (* 1 = 1.24393 loss)
I0525 20:34:07.702236 25020 sgd_solver.cpp:106] Iteration 58650, lr = 0.0035
I0525 20:34:16.428712 25020 solver.cpp:237] Iteration 58800, loss = 1.32751
I0525 20:34:16.428899 25020 solver.cpp:253]     Train net output #0: loss = 1.32751 (* 1 = 1.32751 loss)
I0525 20:34:16.428913 25020 sgd_solver.cpp:106] Iteration 58800, lr = 0.0035
I0525 20:34:25.163632 25020 solver.cpp:237] Iteration 58950, loss = 0.970157
I0525 20:34:25.163682 25020 solver.cpp:253]     Train net output #0: loss = 0.970157 (* 1 = 0.970157 loss)
I0525 20:34:25.163698 25020 sgd_solver.cpp:106] Iteration 58950, lr = 0.0035
I0525 20:34:54.794776 25020 solver.cpp:237] Iteration 59100, loss = 1.0545
I0525 20:34:54.794971 25020 solver.cpp:253]     Train net output #0: loss = 1.0545 (* 1 = 1.0545 loss)
I0525 20:34:54.794986 25020 sgd_solver.cpp:106] Iteration 59100, lr = 0.0035
I0525 20:35:03.521224 25020 solver.cpp:237] Iteration 59250, loss = 1.03904
I0525 20:35:03.521255 25020 solver.cpp:253]     Train net output #0: loss = 1.03904 (* 1 = 1.03904 loss)
I0525 20:35:03.521267 25020 sgd_solver.cpp:106] Iteration 59250, lr = 0.0035
I0525 20:35:12.250407 25020 solver.cpp:237] Iteration 59400, loss = 0.94001
I0525 20:35:12.250442 25020 solver.cpp:253]     Train net output #0: loss = 0.94001 (* 1 = 0.94001 loss)
I0525 20:35:12.250457 25020 sgd_solver.cpp:106] Iteration 59400, lr = 0.0035
I0525 20:35:20.977296 25020 solver.cpp:237] Iteration 59550, loss = 1.22467
I0525 20:35:20.977339 25020 solver.cpp:253]     Train net output #0: loss = 1.22467 (* 1 = 1.22467 loss)
I0525 20:35:20.977357 25020 sgd_solver.cpp:106] Iteration 59550, lr = 0.0035
I0525 20:35:29.703382 25020 solver.cpp:237] Iteration 59700, loss = 1.17618
I0525 20:35:29.703552 25020 solver.cpp:253]     Train net output #0: loss = 1.17618 (* 1 = 1.17618 loss)
I0525 20:35:29.703567 25020 sgd_solver.cpp:106] Iteration 59700, lr = 0.0035
I0525 20:35:38.427826 25020 solver.cpp:237] Iteration 59850, loss = 1.13126
I0525 20:35:38.427860 25020 solver.cpp:253]     Train net output #0: loss = 1.13126 (* 1 = 1.13126 loss)
I0525 20:35:38.427877 25020 sgd_solver.cpp:106] Iteration 59850, lr = 0.0035
I0525 20:35:47.100409 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_60000.caffemodel
I0525 20:35:47.181596 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_60000.solverstate
I0525 20:35:47.208833 25020 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 20:36:55.029425 25020 solver.cpp:409]     Test net output #0: accuracy = 0.895129
I0525 20:36:55.029618 25020 solver.cpp:409]     Test net output #1: loss = 0.339717 (* 1 = 0.339717 loss)
I0525 20:37:15.941170 25020 solver.cpp:237] Iteration 60000, loss = 1.09785
I0525 20:37:15.941223 25020 solver.cpp:253]     Train net output #0: loss = 1.09785 (* 1 = 1.09785 loss)
I0525 20:37:15.941238 25020 sgd_solver.cpp:106] Iteration 60000, lr = 0.0035
I0525 20:37:24.670605 25020 solver.cpp:237] Iteration 60150, loss = 1.00646
I0525 20:37:24.670644 25020 solver.cpp:253]     Train net output #0: loss = 1.00646 (* 1 = 1.00646 loss)
I0525 20:37:24.670661 25020 sgd_solver.cpp:106] Iteration 60150, lr = 0.0035
I0525 20:37:33.397649 25020 solver.cpp:237] Iteration 60300, loss = 1.2986
I0525 20:37:33.397837 25020 solver.cpp:253]     Train net output #0: loss = 1.2986 (* 1 = 1.2986 loss)
I0525 20:37:33.397851 25020 sgd_solver.cpp:106] Iteration 60300, lr = 0.0035
I0525 20:37:42.118942 25020 solver.cpp:237] Iteration 60450, loss = 1.13252
I0525 20:37:42.118975 25020 solver.cpp:253]     Train net output #0: loss = 1.13252 (* 1 = 1.13252 loss)
I0525 20:37:42.118993 25020 sgd_solver.cpp:106] Iteration 60450, lr = 0.0035
I0525 20:37:50.844089 25020 solver.cpp:237] Iteration 60600, loss = 1.25049
I0525 20:37:50.844136 25020 solver.cpp:253]     Train net output #0: loss = 1.25049 (* 1 = 1.25049 loss)
I0525 20:37:50.844151 25020 sgd_solver.cpp:106] Iteration 60600, lr = 0.0035
I0525 20:37:59.569370 25020 solver.cpp:237] Iteration 60750, loss = 0.896108
I0525 20:37:59.569406 25020 solver.cpp:253]     Train net output #0: loss = 0.896108 (* 1 = 0.896108 loss)
I0525 20:37:59.569419 25020 sgd_solver.cpp:106] Iteration 60750, lr = 0.0035
I0525 20:38:08.294226 25020 solver.cpp:237] Iteration 60900, loss = 1.21062
I0525 20:38:08.294401 25020 solver.cpp:253]     Train net output #0: loss = 1.21062 (* 1 = 1.21062 loss)
I0525 20:38:08.294415 25020 sgd_solver.cpp:106] Iteration 60900, lr = 0.0035
I0525 20:38:37.892385 25020 solver.cpp:237] Iteration 61050, loss = 1.14376
I0525 20:38:37.892433 25020 solver.cpp:253]     Train net output #0: loss = 1.14376 (* 1 = 1.14376 loss)
I0525 20:38:37.892452 25020 sgd_solver.cpp:106] Iteration 61050, lr = 0.0035
I0525 20:38:46.618793 25020 solver.cpp:237] Iteration 61200, loss = 1.08995
I0525 20:38:46.618971 25020 solver.cpp:253]     Train net output #0: loss = 1.08995 (* 1 = 1.08995 loss)
I0525 20:38:46.618984 25020 sgd_solver.cpp:106] Iteration 61200, lr = 0.0035
I0525 20:38:55.342965 25020 solver.cpp:237] Iteration 61350, loss = 1.18382
I0525 20:38:55.343000 25020 solver.cpp:253]     Train net output #0: loss = 1.18382 (* 1 = 1.18382 loss)
I0525 20:38:55.343017 25020 sgd_solver.cpp:106] Iteration 61350, lr = 0.0035
I0525 20:39:04.007278 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_61500.caffemodel
I0525 20:39:04.085069 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_61500.solverstate
I0525 20:39:04.128479 25020 solver.cpp:237] Iteration 61500, loss = 1.17975
I0525 20:39:04.128522 25020 solver.cpp:253]     Train net output #0: loss = 1.17975 (* 1 = 1.17975 loss)
I0525 20:39:04.128536 25020 sgd_solver.cpp:106] Iteration 61500, lr = 0.0035
I0525 20:39:12.852679 25020 solver.cpp:237] Iteration 61650, loss = 1.18069
I0525 20:39:12.852715 25020 solver.cpp:253]     Train net output #0: loss = 1.18069 (* 1 = 1.18069 loss)
I0525 20:39:12.852731 25020 sgd_solver.cpp:106] Iteration 61650, lr = 0.0035
I0525 20:39:21.568956 25020 solver.cpp:237] Iteration 61800, loss = 1.08812
I0525 20:39:21.569135 25020 solver.cpp:253]     Train net output #0: loss = 1.08812 (* 1 = 1.08812 loss)
I0525 20:39:21.569149 25020 sgd_solver.cpp:106] Iteration 61800, lr = 0.0035
I0525 20:39:30.293987 25020 solver.cpp:237] Iteration 61950, loss = 1.08206
I0525 20:39:30.294029 25020 solver.cpp:253]     Train net output #0: loss = 1.08206 (* 1 = 1.08206 loss)
I0525 20:39:30.294049 25020 sgd_solver.cpp:106] Iteration 61950, lr = 0.0035
I0525 20:39:59.916749 25020 solver.cpp:237] Iteration 62100, loss = 0.954093
I0525 20:39:59.916947 25020 solver.cpp:253]     Train net output #0: loss = 0.954093 (* 1 = 0.954093 loss)
I0525 20:39:59.916962 25020 sgd_solver.cpp:106] Iteration 62100, lr = 0.0035
I0525 20:40:08.639897 25020 solver.cpp:237] Iteration 62250, loss = 1.15373
I0525 20:40:08.639932 25020 solver.cpp:253]     Train net output #0: loss = 1.15373 (* 1 = 1.15373 loss)
I0525 20:40:08.639947 25020 sgd_solver.cpp:106] Iteration 62250, lr = 0.0035
I0525 20:40:17.361902 25020 solver.cpp:237] Iteration 62400, loss = 1.00674
I0525 20:40:17.361953 25020 solver.cpp:253]     Train net output #0: loss = 1.00674 (* 1 = 1.00674 loss)
I0525 20:40:17.361965 25020 sgd_solver.cpp:106] Iteration 62400, lr = 0.0035
I0525 20:40:26.083160 25020 solver.cpp:237] Iteration 62550, loss = 1.12924
I0525 20:40:26.083196 25020 solver.cpp:253]     Train net output #0: loss = 1.12924 (* 1 = 1.12924 loss)
I0525 20:40:26.083214 25020 sgd_solver.cpp:106] Iteration 62550, lr = 0.0035
I0525 20:40:34.809118 25020 solver.cpp:237] Iteration 62700, loss = 1.0334
I0525 20:40:34.809303 25020 solver.cpp:253]     Train net output #0: loss = 1.0334 (* 1 = 1.0334 loss)
I0525 20:40:34.809316 25020 sgd_solver.cpp:106] Iteration 62700, lr = 0.0035
I0525 20:40:43.538321 25020 solver.cpp:237] Iteration 62850, loss = 1.25617
I0525 20:40:43.538367 25020 solver.cpp:253]     Train net output #0: loss = 1.25617 (* 1 = 1.25617 loss)
I0525 20:40:43.538380 25020 sgd_solver.cpp:106] Iteration 62850, lr = 0.0035
I0525 20:40:52.200299 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_63000.caffemodel
I0525 20:40:52.278926 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_63000.solverstate
I0525 20:40:52.304440 25020 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 20:41:39.242781 25020 solver.cpp:409]     Test net output #0: accuracy = 0.894649
I0525 20:41:39.242976 25020 solver.cpp:409]     Test net output #1: loss = 0.34762 (* 1 = 0.34762 loss)
I0525 20:42:00.146710 25020 solver.cpp:237] Iteration 63000, loss = 1.07195
I0525 20:42:00.146762 25020 solver.cpp:253]     Train net output #0: loss = 1.07195 (* 1 = 1.07195 loss)
I0525 20:42:00.146778 25020 sgd_solver.cpp:106] Iteration 63000, lr = 0.0035
I0525 20:42:08.875708 25020 solver.cpp:237] Iteration 63150, loss = 1.21051
I0525 20:42:08.875744 25020 solver.cpp:253]     Train net output #0: loss = 1.21051 (* 1 = 1.21051 loss)
I0525 20:42:08.875761 25020 sgd_solver.cpp:106] Iteration 63150, lr = 0.0035
I0525 20:42:17.600289 25020 solver.cpp:237] Iteration 63300, loss = 1.10925
I0525 20:42:17.600471 25020 solver.cpp:253]     Train net output #0: loss = 1.10925 (* 1 = 1.10925 loss)
I0525 20:42:17.600483 25020 sgd_solver.cpp:106] Iteration 63300, lr = 0.0035
I0525 20:42:26.327939 25020 solver.cpp:237] Iteration 63450, loss = 1.09735
I0525 20:42:26.327973 25020 solver.cpp:253]     Train net output #0: loss = 1.09735 (* 1 = 1.09735 loss)
I0525 20:42:26.327994 25020 sgd_solver.cpp:106] Iteration 63450, lr = 0.0035
I0525 20:42:35.056293 25020 solver.cpp:237] Iteration 63600, loss = 1.26112
I0525 20:42:35.056329 25020 solver.cpp:253]     Train net output #0: loss = 1.26112 (* 1 = 1.26112 loss)
I0525 20:42:35.056344 25020 sgd_solver.cpp:106] Iteration 63600, lr = 0.0035
I0525 20:42:43.785578 25020 solver.cpp:237] Iteration 63750, loss = 1.29065
I0525 20:42:43.785620 25020 solver.cpp:253]     Train net output #0: loss = 1.29065 (* 1 = 1.29065 loss)
I0525 20:42:43.785637 25020 sgd_solver.cpp:106] Iteration 63750, lr = 0.0035
I0525 20:42:52.518936 25020 solver.cpp:237] Iteration 63900, loss = 0.955268
I0525 20:42:52.519110 25020 solver.cpp:253]     Train net output #0: loss = 0.955268 (* 1 = 0.955268 loss)
I0525 20:42:52.519125 25020 sgd_solver.cpp:106] Iteration 63900, lr = 0.0035
I0525 20:43:22.160020 25020 solver.cpp:237] Iteration 64050, loss = 1.27899
I0525 20:43:22.160071 25020 solver.cpp:253]     Train net output #0: loss = 1.27899 (* 1 = 1.27899 loss)
I0525 20:43:22.160089 25020 sgd_solver.cpp:106] Iteration 64050, lr = 0.0035
I0525 20:43:30.887558 25020 solver.cpp:237] Iteration 64200, loss = 1.2196
I0525 20:43:30.887739 25020 solver.cpp:253]     Train net output #0: loss = 1.2196 (* 1 = 1.2196 loss)
I0525 20:43:30.887753 25020 sgd_solver.cpp:106] Iteration 64200, lr = 0.0035
I0525 20:43:39.618021 25020 solver.cpp:237] Iteration 64350, loss = 1.33266
I0525 20:43:39.618063 25020 solver.cpp:253]     Train net output #0: loss = 1.33266 (* 1 = 1.33266 loss)
I0525 20:43:39.618084 25020 sgd_solver.cpp:106] Iteration 64350, lr = 0.0035
I0525 20:43:48.287951 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_64500.caffemodel
I0525 20:43:48.367437 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_64500.solverstate
I0525 20:43:48.410671 25020 solver.cpp:237] Iteration 64500, loss = 1.21834
I0525 20:43:48.410715 25020 solver.cpp:253]     Train net output #0: loss = 1.21834 (* 1 = 1.21834 loss)
I0525 20:43:48.410729 25020 sgd_solver.cpp:106] Iteration 64500, lr = 0.0035
I0525 20:43:57.140447 25020 solver.cpp:237] Iteration 64650, loss = 1.28913
I0525 20:43:57.140482 25020 solver.cpp:253]     Train net output #0: loss = 1.28913 (* 1 = 1.28913 loss)
I0525 20:43:57.140499 25020 sgd_solver.cpp:106] Iteration 64650, lr = 0.0035
I0525 20:44:05.874001 25020 solver.cpp:237] Iteration 64800, loss = 0.983071
I0525 20:44:05.874203 25020 solver.cpp:253]     Train net output #0: loss = 0.983071 (* 1 = 0.983071 loss)
I0525 20:44:05.874217 25020 sgd_solver.cpp:106] Iteration 64800, lr = 0.0035
I0525 20:44:14.601492 25020 solver.cpp:237] Iteration 64950, loss = 1.16739
I0525 20:44:14.601526 25020 solver.cpp:253]     Train net output #0: loss = 1.16739 (* 1 = 1.16739 loss)
I0525 20:44:14.601543 25020 sgd_solver.cpp:106] Iteration 64950, lr = 0.0035
I0525 20:44:44.222261 25020 solver.cpp:237] Iteration 65100, loss = 1.08804
I0525 20:44:44.222461 25020 solver.cpp:253]     Train net output #0: loss = 1.08804 (* 1 = 1.08804 loss)
I0525 20:44:44.222476 25020 sgd_solver.cpp:106] Iteration 65100, lr = 0.0035
I0525 20:44:52.951412 25020 solver.cpp:237] Iteration 65250, loss = 1.12571
I0525 20:44:52.951459 25020 solver.cpp:253]     Train net output #0: loss = 1.12571 (* 1 = 1.12571 loss)
I0525 20:44:52.951478 25020 sgd_solver.cpp:106] Iteration 65250, lr = 0.0035
I0525 20:45:01.682900 25020 solver.cpp:237] Iteration 65400, loss = 1.13714
I0525 20:45:01.682935 25020 solver.cpp:253]     Train net output #0: loss = 1.13714 (* 1 = 1.13714 loss)
I0525 20:45:01.682952 25020 sgd_solver.cpp:106] Iteration 65400, lr = 0.0035
I0525 20:45:10.410648 25020 solver.cpp:237] Iteration 65550, loss = 0.938587
I0525 20:45:10.410684 25020 solver.cpp:253]     Train net output #0: loss = 0.938587 (* 1 = 0.938587 loss)
I0525 20:45:10.410701 25020 sgd_solver.cpp:106] Iteration 65550, lr = 0.0035
I0525 20:45:19.137089 25020 solver.cpp:237] Iteration 65700, loss = 1.17363
I0525 20:45:19.137279 25020 solver.cpp:253]     Train net output #0: loss = 1.17363 (* 1 = 1.17363 loss)
I0525 20:45:19.137293 25020 sgd_solver.cpp:106] Iteration 65700, lr = 0.0035
I0525 20:45:27.868420 25020 solver.cpp:237] Iteration 65850, loss = 1.3304
I0525 20:45:27.868455 25020 solver.cpp:253]     Train net output #0: loss = 1.3304 (* 1 = 1.3304 loss)
I0525 20:45:27.868471 25020 sgd_solver.cpp:106] Iteration 65850, lr = 0.0035
I0525 20:45:36.539754 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_66000.caffemodel
I0525 20:45:36.619019 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_66000.solverstate
I0525 20:45:36.645460 25020 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 20:46:44.433054 25020 solver.cpp:409]     Test net output #0: accuracy = 0.895789
I0525 20:46:44.433253 25020 solver.cpp:409]     Test net output #1: loss = 0.35377 (* 1 = 0.35377 loss)
I0525 20:47:05.348618 25020 solver.cpp:237] Iteration 66000, loss = 1.14164
I0525 20:47:05.348670 25020 solver.cpp:253]     Train net output #0: loss = 1.14164 (* 1 = 1.14164 loss)
I0525 20:47:05.348685 25020 sgd_solver.cpp:106] Iteration 66000, lr = 0.0035
I0525 20:47:14.073698 25020 solver.cpp:237] Iteration 66150, loss = 1.32261
I0525 20:47:14.073734 25020 solver.cpp:253]     Train net output #0: loss = 1.32261 (* 1 = 1.32261 loss)
I0525 20:47:14.073747 25020 sgd_solver.cpp:106] Iteration 66150, lr = 0.0035
I0525 20:47:22.797282 25020 solver.cpp:237] Iteration 66300, loss = 1.15929
I0525 20:47:22.797487 25020 solver.cpp:253]     Train net output #0: loss = 1.15929 (* 1 = 1.15929 loss)
I0525 20:47:22.797500 25020 sgd_solver.cpp:106] Iteration 66300, lr = 0.0035
I0525 20:47:31.517129 25020 solver.cpp:237] Iteration 66450, loss = 1.20861
I0525 20:47:31.517163 25020 solver.cpp:253]     Train net output #0: loss = 1.20861 (* 1 = 1.20861 loss)
I0525 20:47:31.517177 25020 sgd_solver.cpp:106] Iteration 66450, lr = 0.0035
I0525 20:47:40.240991 25020 solver.cpp:237] Iteration 66600, loss = 1.0758
I0525 20:47:40.241026 25020 solver.cpp:253]     Train net output #0: loss = 1.0758 (* 1 = 1.0758 loss)
I0525 20:47:40.241046 25020 sgd_solver.cpp:106] Iteration 66600, lr = 0.0035
I0525 20:47:48.961971 25020 solver.cpp:237] Iteration 66750, loss = 1.08914
I0525 20:47:48.962018 25020 solver.cpp:253]     Train net output #0: loss = 1.08914 (* 1 = 1.08914 loss)
I0525 20:47:48.962033 25020 sgd_solver.cpp:106] Iteration 66750, lr = 0.0035
I0525 20:47:57.691439 25020 solver.cpp:237] Iteration 66900, loss = 1.16582
I0525 20:47:57.691619 25020 solver.cpp:253]     Train net output #0: loss = 1.16582 (* 1 = 1.16582 loss)
I0525 20:47:57.691632 25020 sgd_solver.cpp:106] Iteration 66900, lr = 0.0035
I0525 20:48:27.300732 25020 solver.cpp:237] Iteration 67050, loss = 1.14161
I0525 20:48:27.300781 25020 solver.cpp:253]     Train net output #0: loss = 1.14161 (* 1 = 1.14161 loss)
I0525 20:48:27.300796 25020 sgd_solver.cpp:106] Iteration 67050, lr = 0.0035
I0525 20:48:36.018579 25020 solver.cpp:237] Iteration 67200, loss = 1.20114
I0525 20:48:36.018774 25020 solver.cpp:253]     Train net output #0: loss = 1.20114 (* 1 = 1.20114 loss)
I0525 20:48:36.018788 25020 sgd_solver.cpp:106] Iteration 67200, lr = 0.0035
I0525 20:48:44.740154 25020 solver.cpp:237] Iteration 67350, loss = 1.15674
I0525 20:48:44.740183 25020 solver.cpp:253]     Train net output #0: loss = 1.15674 (* 1 = 1.15674 loss)
I0525 20:48:44.740205 25020 sgd_solver.cpp:106] Iteration 67350, lr = 0.0035
I0525 20:48:53.412274 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_67500.caffemodel
I0525 20:48:53.493099 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_67500.solverstate
I0525 20:48:53.538496 25020 solver.cpp:237] Iteration 67500, loss = 1.06677
I0525 20:48:53.538550 25020 solver.cpp:253]     Train net output #0: loss = 1.06677 (* 1 = 1.06677 loss)
I0525 20:48:53.538570 25020 sgd_solver.cpp:106] Iteration 67500, lr = 0.0035
I0525 20:49:02.261909 25020 solver.cpp:237] Iteration 67650, loss = 1.1145
I0525 20:49:02.261955 25020 solver.cpp:253]     Train net output #0: loss = 1.1145 (* 1 = 1.1145 loss)
I0525 20:49:02.261972 25020 sgd_solver.cpp:106] Iteration 67650, lr = 0.0035
I0525 20:49:10.981374 25020 solver.cpp:237] Iteration 67800, loss = 1.26504
I0525 20:49:10.981557 25020 solver.cpp:253]     Train net output #0: loss = 1.26504 (* 1 = 1.26504 loss)
I0525 20:49:10.981571 25020 sgd_solver.cpp:106] Iteration 67800, lr = 0.0035
I0525 20:49:19.695672 25020 solver.cpp:237] Iteration 67950, loss = 1.14539
I0525 20:49:19.695706 25020 solver.cpp:253]     Train net output #0: loss = 1.14539 (* 1 = 1.14539 loss)
I0525 20:49:19.695724 25020 sgd_solver.cpp:106] Iteration 67950, lr = 0.0035
I0525 20:49:49.312918 25020 solver.cpp:237] Iteration 68100, loss = 1.01703
I0525 20:49:49.313133 25020 solver.cpp:253]     Train net output #0: loss = 1.01703 (* 1 = 1.01703 loss)
I0525 20:49:49.313148 25020 sgd_solver.cpp:106] Iteration 68100, lr = 0.0035
I0525 20:49:58.041345 25020 solver.cpp:237] Iteration 68250, loss = 1.00218
I0525 20:49:58.041379 25020 solver.cpp:253]     Train net output #0: loss = 1.00218 (* 1 = 1.00218 loss)
I0525 20:49:58.041398 25020 sgd_solver.cpp:106] Iteration 68250, lr = 0.0035
I0525 20:50:06.764930 25020 solver.cpp:237] Iteration 68400, loss = 1.06981
I0525 20:50:06.764964 25020 solver.cpp:253]     Train net output #0: loss = 1.06981 (* 1 = 1.06981 loss)
I0525 20:50:06.764978 25020 sgd_solver.cpp:106] Iteration 68400, lr = 0.0035
I0525 20:50:15.489440 25020 solver.cpp:237] Iteration 68550, loss = 1.18766
I0525 20:50:15.489482 25020 solver.cpp:253]     Train net output #0: loss = 1.18766 (* 1 = 1.18766 loss)
I0525 20:50:15.489500 25020 sgd_solver.cpp:106] Iteration 68550, lr = 0.0035
I0525 20:50:24.214440 25020 solver.cpp:237] Iteration 68700, loss = 1.02651
I0525 20:50:24.214628 25020 solver.cpp:253]     Train net output #0: loss = 1.02651 (* 1 = 1.02651 loss)
I0525 20:50:24.214644 25020 sgd_solver.cpp:106] Iteration 68700, lr = 0.0035
I0525 20:50:32.939254 25020 solver.cpp:237] Iteration 68850, loss = 1.00396
I0525 20:50:32.939288 25020 solver.cpp:253]     Train net output #0: loss = 1.00396 (* 1 = 1.00396 loss)
I0525 20:50:32.939306 25020 sgd_solver.cpp:106] Iteration 68850, lr = 0.0035
I0525 20:50:41.603224 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_69000.caffemodel
I0525 20:50:41.681643 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_69000.solverstate
I0525 20:50:41.707072 25020 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 20:51:28.280428 25020 solver.cpp:409]     Test net output #0: accuracy = 0.890688
I0525 20:51:28.280629 25020 solver.cpp:409]     Test net output #1: loss = 0.352092 (* 1 = 0.352092 loss)
I0525 20:51:49.169984 25020 solver.cpp:237] Iteration 69000, loss = 1.10947
I0525 20:51:49.170037 25020 solver.cpp:253]     Train net output #0: loss = 1.10947 (* 1 = 1.10947 loss)
I0525 20:51:49.170053 25020 sgd_solver.cpp:106] Iteration 69000, lr = 0.0035
I0525 20:51:57.903404 25020 solver.cpp:237] Iteration 69150, loss = 0.971739
I0525 20:51:57.903445 25020 solver.cpp:253]     Train net output #0: loss = 0.971739 (* 1 = 0.971739 loss)
I0525 20:51:57.903465 25020 sgd_solver.cpp:106] Iteration 69150, lr = 0.0035
I0525 20:52:06.630749 25020 solver.cpp:237] Iteration 69300, loss = 0.996987
I0525 20:52:06.630935 25020 solver.cpp:253]     Train net output #0: loss = 0.996987 (* 1 = 0.996987 loss)
I0525 20:52:06.630950 25020 sgd_solver.cpp:106] Iteration 69300, lr = 0.0035
I0525 20:52:15.357985 25020 solver.cpp:237] Iteration 69450, loss = 1.19195
I0525 20:52:15.358019 25020 solver.cpp:253]     Train net output #0: loss = 1.19195 (* 1 = 1.19195 loss)
I0525 20:52:15.358037 25020 sgd_solver.cpp:106] Iteration 69450, lr = 0.0035
I0525 20:52:24.084528 25020 solver.cpp:237] Iteration 69600, loss = 1.43067
I0525 20:52:24.084573 25020 solver.cpp:253]     Train net output #0: loss = 1.43067 (* 1 = 1.43067 loss)
I0525 20:52:24.084590 25020 sgd_solver.cpp:106] Iteration 69600, lr = 0.0035
I0525 20:52:32.814724 25020 solver.cpp:237] Iteration 69750, loss = 1.37934
I0525 20:52:32.814759 25020 solver.cpp:253]     Train net output #0: loss = 1.37934 (* 1 = 1.37934 loss)
I0525 20:52:32.814776 25020 sgd_solver.cpp:106] Iteration 69750, lr = 0.0035
I0525 20:52:41.541512 25020 solver.cpp:237] Iteration 69900, loss = 1.13575
I0525 20:52:41.541692 25020 solver.cpp:253]     Train net output #0: loss = 1.13575 (* 1 = 1.13575 loss)
I0525 20:52:41.541713 25020 sgd_solver.cpp:106] Iteration 69900, lr = 0.0035
I0525 20:53:11.159077 25020 solver.cpp:237] Iteration 70050, loss = 1.20113
I0525 20:53:11.159126 25020 solver.cpp:253]     Train net output #0: loss = 1.20113 (* 1 = 1.20113 loss)
I0525 20:53:11.159143 25020 sgd_solver.cpp:106] Iteration 70050, lr = 0.0035
I0525 20:53:19.885716 25020 solver.cpp:237] Iteration 70200, loss = 1.11444
I0525 20:53:19.885917 25020 solver.cpp:253]     Train net output #0: loss = 1.11444 (* 1 = 1.11444 loss)
I0525 20:53:19.885931 25020 sgd_solver.cpp:106] Iteration 70200, lr = 0.0035
I0525 20:53:28.610626 25020 solver.cpp:237] Iteration 70350, loss = 1.18522
I0525 20:53:28.610661 25020 solver.cpp:253]     Train net output #0: loss = 1.18522 (* 1 = 1.18522 loss)
I0525 20:53:28.610677 25020 sgd_solver.cpp:106] Iteration 70350, lr = 0.0035
I0525 20:53:37.280311 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_70500.caffemodel
I0525 20:53:37.359098 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_70500.solverstate
I0525 20:53:37.402971 25020 solver.cpp:237] Iteration 70500, loss = 1.00973
I0525 20:53:37.403012 25020 solver.cpp:253]     Train net output #0: loss = 1.00973 (* 1 = 1.00973 loss)
I0525 20:53:37.403026 25020 sgd_solver.cpp:106] Iteration 70500, lr = 0.0035
I0525 20:53:46.130537 25020 solver.cpp:237] Iteration 70650, loss = 1.1218
I0525 20:53:46.130573 25020 solver.cpp:253]     Train net output #0: loss = 1.1218 (* 1 = 1.1218 loss)
I0525 20:53:46.130587 25020 sgd_solver.cpp:106] Iteration 70650, lr = 0.0035
I0525 20:53:54.860093 25020 solver.cpp:237] Iteration 70800, loss = 1.20682
I0525 20:53:54.860280 25020 solver.cpp:253]     Train net output #0: loss = 1.20682 (* 1 = 1.20682 loss)
I0525 20:53:54.860293 25020 sgd_solver.cpp:106] Iteration 70800, lr = 0.0035
I0525 20:54:03.590662 25020 solver.cpp:237] Iteration 70950, loss = 1.13875
I0525 20:54:03.590710 25020 solver.cpp:253]     Train net output #0: loss = 1.13875 (* 1 = 1.13875 loss)
I0525 20:54:03.590724 25020 sgd_solver.cpp:106] Iteration 70950, lr = 0.0035
I0525 20:54:33.174605 25020 solver.cpp:237] Iteration 71100, loss = 0.971061
I0525 20:54:33.174809 25020 solver.cpp:253]     Train net output #0: loss = 0.971061 (* 1 = 0.971061 loss)
I0525 20:54:33.174824 25020 sgd_solver.cpp:106] Iteration 71100, lr = 0.0035
I0525 20:54:41.901964 25020 solver.cpp:237] Iteration 71250, loss = 1.12408
I0525 20:54:41.901998 25020 solver.cpp:253]     Train net output #0: loss = 1.12408 (* 1 = 1.12408 loss)
I0525 20:54:41.902014 25020 sgd_solver.cpp:106] Iteration 71250, lr = 0.0035
I0525 20:54:50.629914 25020 solver.cpp:237] Iteration 71400, loss = 1.02677
I0525 20:54:50.629954 25020 solver.cpp:253]     Train net output #0: loss = 1.02677 (* 1 = 1.02677 loss)
I0525 20:54:50.629974 25020 sgd_solver.cpp:106] Iteration 71400, lr = 0.0035
I0525 20:54:59.358324 25020 solver.cpp:237] Iteration 71550, loss = 1.10515
I0525 20:54:59.358358 25020 solver.cpp:253]     Train net output #0: loss = 1.10515 (* 1 = 1.10515 loss)
I0525 20:54:59.358374 25020 sgd_solver.cpp:106] Iteration 71550, lr = 0.0035
I0525 20:55:08.082614 25020 solver.cpp:237] Iteration 71700, loss = 0.934417
I0525 20:55:08.082797 25020 solver.cpp:253]     Train net output #0: loss = 0.934417 (* 1 = 0.934417 loss)
I0525 20:55:08.082810 25020 sgd_solver.cpp:106] Iteration 71700, lr = 0.0035
I0525 20:55:16.812110 25020 solver.cpp:237] Iteration 71850, loss = 1.13574
I0525 20:55:16.812157 25020 solver.cpp:253]     Train net output #0: loss = 1.13574 (* 1 = 1.13574 loss)
I0525 20:55:16.812171 25020 sgd_solver.cpp:106] Iteration 71850, lr = 0.0035
I0525 20:55:25.480615 25020 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_72000.caffemodel
I0525 20:55:25.559160 25020 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0035_2016-05-20T15.49.26.227827_iter_72000.solverstate
I0525 20:55:25.584817 25020 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 20:56:33.262315 25020 solver.cpp:409]     Test net output #0: accuracy = 0.894162
I0525 20:56:33.262531 25020 solver.cpp:409]     Test net output #1: loss = 0.329045 (* 1 = 0.329045 loss)
I0525 20:56:54.112089 25020 solver.cpp:237] Iteration 72000, loss = 1.36165
I0525 20:56:54.112145 25020 solver.cpp:253]     Train net output #0: loss = 1.36165 (* 1 = 1.36165 loss)
I0525 20:56:54.112159 25020 sgd_solver.cpp:106] Iteration 72000, lr = 0.0035
I0525 20:57:02.832511 25020 solver.cpp:237] Iteration 72150, loss = 1.10462
I0525 20:57:02.832547 25020 solver.cpp:253]     Train net output #0: loss = 1.10462 (* 1 = 1.10462 loss)
I0525 20:57:02.832562 25020 sgd_solver.cpp:106] Iteration 72150, lr = 0.0035
I0525 20:57:11.553536 25020 solver.cpp:237] Iteration 72300, loss = 1.07054
I0525 20:57:11.553724 25020 solver.cpp:253]     Train net output #0: loss = 1.07054 (* 1 = 1.07054 loss)
I0525 20:57:11.553736 25020 sgd_solver.cpp:106] Iteration 72300, lr = 0.0035
I0525 20:57:20.276384 25020 solver.cpp:237] Iteration 72450, loss = 0.980014
I0525 20:57:20.276429 25020 solver.cpp:253]     Train net output #0: loss = 0.980014 (* 1 = 0.980014 loss)
I0525 20:57:20.276446 25020 sgd_solver.cpp:106] Iteration 72450, lr = 0.0035
aprun: Apid 11265518: Caught signal Terminated, sending to application
*** Aborted at 1464224244 (unix time) try "date -d @1464224244" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11265518: Caught signal Terminated, sending to application
*** SIGTERM (@0x61b9) received by PID 25020 (TID 0x2aaac746f900) from PID 25017; stack trace: ***
aprun: Apid 11265518: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7217 exceeded limit 7200
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
aprun: Apid 11265518: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11265518: Caught signal Terminated, sending to application
