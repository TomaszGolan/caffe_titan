2809224
I0524 02:03:13.397696 15289 caffe.cpp:184] Using GPUs 0
I0524 02:03:13.822970 15289 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2142
test_interval: 4285
base_lr: 0.003
display: 214
max_iter: 214280
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2142
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565.prototxt"
I0524 02:03:13.824609 15289 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565.prototxt
I0524 02:03:13.845837 15289 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0524 02:03:13.845896 15289 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0524 02:03:13.846243 15289 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 02:03:13.846426 15289 layer_factory.hpp:77] Creating layer data_hdf5
I0524 02:03:13.846449 15289 net.cpp:106] Creating Layer data_hdf5
I0524 02:03:13.846464 15289 net.cpp:411] data_hdf5 -> data
I0524 02:03:13.846498 15289 net.cpp:411] data_hdf5 -> label
I0524 02:03:13.846530 15289 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0524 02:03:13.847692 15289 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0524 02:03:13.849889 15289 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0524 02:03:35.361130 15289 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0524 02:03:35.366293 15289 net.cpp:150] Setting up data_hdf5
I0524 02:03:35.366333 15289 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0524 02:03:35.366348 15289 net.cpp:157] Top shape: 70 (70)
I0524 02:03:35.366359 15289 net.cpp:165] Memory required for data: 1778280
I0524 02:03:35.366372 15289 layer_factory.hpp:77] Creating layer conv1
I0524 02:03:35.366406 15289 net.cpp:106] Creating Layer conv1
I0524 02:03:35.366417 15289 net.cpp:454] conv1 <- data
I0524 02:03:35.366438 15289 net.cpp:411] conv1 -> conv1
I0524 02:03:36.991636 15289 net.cpp:150] Setting up conv1
I0524 02:03:36.991683 15289 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 02:03:36.991695 15289 net.cpp:165] Memory required for data: 21131880
I0524 02:03:36.991724 15289 layer_factory.hpp:77] Creating layer relu1
I0524 02:03:36.991745 15289 net.cpp:106] Creating Layer relu1
I0524 02:03:36.991756 15289 net.cpp:454] relu1 <- conv1
I0524 02:03:36.991770 15289 net.cpp:397] relu1 -> conv1 (in-place)
I0524 02:03:36.992286 15289 net.cpp:150] Setting up relu1
I0524 02:03:36.992303 15289 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 02:03:36.992313 15289 net.cpp:165] Memory required for data: 40485480
I0524 02:03:36.992324 15289 layer_factory.hpp:77] Creating layer pool1
I0524 02:03:36.992342 15289 net.cpp:106] Creating Layer pool1
I0524 02:03:36.992352 15289 net.cpp:454] pool1 <- conv1
I0524 02:03:36.992365 15289 net.cpp:411] pool1 -> pool1
I0524 02:03:36.992444 15289 net.cpp:150] Setting up pool1
I0524 02:03:36.992458 15289 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0524 02:03:36.992468 15289 net.cpp:165] Memory required for data: 50162280
I0524 02:03:36.992476 15289 layer_factory.hpp:77] Creating layer conv2
I0524 02:03:36.992499 15289 net.cpp:106] Creating Layer conv2
I0524 02:03:36.992509 15289 net.cpp:454] conv2 <- pool1
I0524 02:03:36.992523 15289 net.cpp:411] conv2 -> conv2
I0524 02:03:36.995270 15289 net.cpp:150] Setting up conv2
I0524 02:03:36.995298 15289 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 02:03:36.995309 15289 net.cpp:165] Memory required for data: 64072680
I0524 02:03:36.995328 15289 layer_factory.hpp:77] Creating layer relu2
I0524 02:03:36.995342 15289 net.cpp:106] Creating Layer relu2
I0524 02:03:36.995353 15289 net.cpp:454] relu2 <- conv2
I0524 02:03:36.995365 15289 net.cpp:397] relu2 -> conv2 (in-place)
I0524 02:03:36.995697 15289 net.cpp:150] Setting up relu2
I0524 02:03:36.995712 15289 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 02:03:36.995723 15289 net.cpp:165] Memory required for data: 77983080
I0524 02:03:36.995733 15289 layer_factory.hpp:77] Creating layer pool2
I0524 02:03:36.995744 15289 net.cpp:106] Creating Layer pool2
I0524 02:03:36.995754 15289 net.cpp:454] pool2 <- conv2
I0524 02:03:36.995767 15289 net.cpp:411] pool2 -> pool2
I0524 02:03:36.995847 15289 net.cpp:150] Setting up pool2
I0524 02:03:36.995860 15289 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0524 02:03:36.995870 15289 net.cpp:165] Memory required for data: 84938280
I0524 02:03:36.995880 15289 layer_factory.hpp:77] Creating layer conv3
I0524 02:03:36.995896 15289 net.cpp:106] Creating Layer conv3
I0524 02:03:36.995908 15289 net.cpp:454] conv3 <- pool2
I0524 02:03:36.995920 15289 net.cpp:411] conv3 -> conv3
I0524 02:03:36.997835 15289 net.cpp:150] Setting up conv3
I0524 02:03:36.997859 15289 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 02:03:36.997871 15289 net.cpp:165] Memory required for data: 92527400
I0524 02:03:36.997890 15289 layer_factory.hpp:77] Creating layer relu3
I0524 02:03:36.997906 15289 net.cpp:106] Creating Layer relu3
I0524 02:03:36.997916 15289 net.cpp:454] relu3 <- conv3
I0524 02:03:36.997928 15289 net.cpp:397] relu3 -> conv3 (in-place)
I0524 02:03:36.998394 15289 net.cpp:150] Setting up relu3
I0524 02:03:36.998411 15289 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 02:03:36.998421 15289 net.cpp:165] Memory required for data: 100116520
I0524 02:03:36.998432 15289 layer_factory.hpp:77] Creating layer pool3
I0524 02:03:36.998445 15289 net.cpp:106] Creating Layer pool3
I0524 02:03:36.998455 15289 net.cpp:454] pool3 <- conv3
I0524 02:03:36.998467 15289 net.cpp:411] pool3 -> pool3
I0524 02:03:36.998533 15289 net.cpp:150] Setting up pool3
I0524 02:03:36.998548 15289 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0524 02:03:36.998556 15289 net.cpp:165] Memory required for data: 103911080
I0524 02:03:36.998567 15289 layer_factory.hpp:77] Creating layer conv4
I0524 02:03:36.998581 15289 net.cpp:106] Creating Layer conv4
I0524 02:03:36.998592 15289 net.cpp:454] conv4 <- pool3
I0524 02:03:36.998606 15289 net.cpp:411] conv4 -> conv4
I0524 02:03:37.001396 15289 net.cpp:150] Setting up conv4
I0524 02:03:37.001425 15289 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 02:03:37.001435 15289 net.cpp:165] Memory required for data: 106451240
I0524 02:03:37.001451 15289 layer_factory.hpp:77] Creating layer relu4
I0524 02:03:37.001466 15289 net.cpp:106] Creating Layer relu4
I0524 02:03:37.001476 15289 net.cpp:454] relu4 <- conv4
I0524 02:03:37.001488 15289 net.cpp:397] relu4 -> conv4 (in-place)
I0524 02:03:37.001963 15289 net.cpp:150] Setting up relu4
I0524 02:03:37.001981 15289 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 02:03:37.001991 15289 net.cpp:165] Memory required for data: 108991400
I0524 02:03:37.002002 15289 layer_factory.hpp:77] Creating layer pool4
I0524 02:03:37.002014 15289 net.cpp:106] Creating Layer pool4
I0524 02:03:37.002024 15289 net.cpp:454] pool4 <- conv4
I0524 02:03:37.002038 15289 net.cpp:411] pool4 -> pool4
I0524 02:03:37.002105 15289 net.cpp:150] Setting up pool4
I0524 02:03:37.002120 15289 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0524 02:03:37.002130 15289 net.cpp:165] Memory required for data: 110261480
I0524 02:03:37.002140 15289 layer_factory.hpp:77] Creating layer ip1
I0524 02:03:37.002158 15289 net.cpp:106] Creating Layer ip1
I0524 02:03:37.002169 15289 net.cpp:454] ip1 <- pool4
I0524 02:03:37.002182 15289 net.cpp:411] ip1 -> ip1
I0524 02:03:37.017606 15289 net.cpp:150] Setting up ip1
I0524 02:03:37.017635 15289 net.cpp:157] Top shape: 70 196 (13720)
I0524 02:03:37.017652 15289 net.cpp:165] Memory required for data: 110316360
I0524 02:03:37.017678 15289 layer_factory.hpp:77] Creating layer relu5
I0524 02:03:37.017693 15289 net.cpp:106] Creating Layer relu5
I0524 02:03:37.017702 15289 net.cpp:454] relu5 <- ip1
I0524 02:03:37.017715 15289 net.cpp:397] relu5 -> ip1 (in-place)
I0524 02:03:37.018059 15289 net.cpp:150] Setting up relu5
I0524 02:03:37.018074 15289 net.cpp:157] Top shape: 70 196 (13720)
I0524 02:03:37.018084 15289 net.cpp:165] Memory required for data: 110371240
I0524 02:03:37.018095 15289 layer_factory.hpp:77] Creating layer drop1
I0524 02:03:37.018115 15289 net.cpp:106] Creating Layer drop1
I0524 02:03:37.018126 15289 net.cpp:454] drop1 <- ip1
I0524 02:03:37.018138 15289 net.cpp:397] drop1 -> ip1 (in-place)
I0524 02:03:37.018199 15289 net.cpp:150] Setting up drop1
I0524 02:03:37.018213 15289 net.cpp:157] Top shape: 70 196 (13720)
I0524 02:03:37.018224 15289 net.cpp:165] Memory required for data: 110426120
I0524 02:03:37.018234 15289 layer_factory.hpp:77] Creating layer ip2
I0524 02:03:37.018252 15289 net.cpp:106] Creating Layer ip2
I0524 02:03:37.018263 15289 net.cpp:454] ip2 <- ip1
I0524 02:03:37.018276 15289 net.cpp:411] ip2 -> ip2
I0524 02:03:37.018740 15289 net.cpp:150] Setting up ip2
I0524 02:03:37.018754 15289 net.cpp:157] Top shape: 70 98 (6860)
I0524 02:03:37.018764 15289 net.cpp:165] Memory required for data: 110453560
I0524 02:03:37.018779 15289 layer_factory.hpp:77] Creating layer relu6
I0524 02:03:37.018791 15289 net.cpp:106] Creating Layer relu6
I0524 02:03:37.018800 15289 net.cpp:454] relu6 <- ip2
I0524 02:03:37.018813 15289 net.cpp:397] relu6 -> ip2 (in-place)
I0524 02:03:37.019331 15289 net.cpp:150] Setting up relu6
I0524 02:03:37.019347 15289 net.cpp:157] Top shape: 70 98 (6860)
I0524 02:03:37.019358 15289 net.cpp:165] Memory required for data: 110481000
I0524 02:03:37.019368 15289 layer_factory.hpp:77] Creating layer drop2
I0524 02:03:37.019381 15289 net.cpp:106] Creating Layer drop2
I0524 02:03:37.019392 15289 net.cpp:454] drop2 <- ip2
I0524 02:03:37.019404 15289 net.cpp:397] drop2 -> ip2 (in-place)
I0524 02:03:37.019448 15289 net.cpp:150] Setting up drop2
I0524 02:03:37.019460 15289 net.cpp:157] Top shape: 70 98 (6860)
I0524 02:03:37.019471 15289 net.cpp:165] Memory required for data: 110508440
I0524 02:03:37.019481 15289 layer_factory.hpp:77] Creating layer ip3
I0524 02:03:37.019495 15289 net.cpp:106] Creating Layer ip3
I0524 02:03:37.019505 15289 net.cpp:454] ip3 <- ip2
I0524 02:03:37.019517 15289 net.cpp:411] ip3 -> ip3
I0524 02:03:37.019729 15289 net.cpp:150] Setting up ip3
I0524 02:03:37.019742 15289 net.cpp:157] Top shape: 70 11 (770)
I0524 02:03:37.019752 15289 net.cpp:165] Memory required for data: 110511520
I0524 02:03:37.019767 15289 layer_factory.hpp:77] Creating layer drop3
I0524 02:03:37.019779 15289 net.cpp:106] Creating Layer drop3
I0524 02:03:37.019789 15289 net.cpp:454] drop3 <- ip3
I0524 02:03:37.019801 15289 net.cpp:397] drop3 -> ip3 (in-place)
I0524 02:03:37.019841 15289 net.cpp:150] Setting up drop3
I0524 02:03:37.019855 15289 net.cpp:157] Top shape: 70 11 (770)
I0524 02:03:37.019865 15289 net.cpp:165] Memory required for data: 110514600
I0524 02:03:37.019875 15289 layer_factory.hpp:77] Creating layer loss
I0524 02:03:37.019894 15289 net.cpp:106] Creating Layer loss
I0524 02:03:37.019904 15289 net.cpp:454] loss <- ip3
I0524 02:03:37.019915 15289 net.cpp:454] loss <- label
I0524 02:03:37.019928 15289 net.cpp:411] loss -> loss
I0524 02:03:37.019945 15289 layer_factory.hpp:77] Creating layer loss
I0524 02:03:37.020589 15289 net.cpp:150] Setting up loss
I0524 02:03:37.020609 15289 net.cpp:157] Top shape: (1)
I0524 02:03:37.020623 15289 net.cpp:160]     with loss weight 1
I0524 02:03:37.020665 15289 net.cpp:165] Memory required for data: 110514604
I0524 02:03:37.020675 15289 net.cpp:226] loss needs backward computation.
I0524 02:03:37.020686 15289 net.cpp:226] drop3 needs backward computation.
I0524 02:03:37.020696 15289 net.cpp:226] ip3 needs backward computation.
I0524 02:03:37.020704 15289 net.cpp:226] drop2 needs backward computation.
I0524 02:03:37.020715 15289 net.cpp:226] relu6 needs backward computation.
I0524 02:03:37.020725 15289 net.cpp:226] ip2 needs backward computation.
I0524 02:03:37.020735 15289 net.cpp:226] drop1 needs backward computation.
I0524 02:03:37.020745 15289 net.cpp:226] relu5 needs backward computation.
I0524 02:03:37.020755 15289 net.cpp:226] ip1 needs backward computation.
I0524 02:03:37.020764 15289 net.cpp:226] pool4 needs backward computation.
I0524 02:03:37.020776 15289 net.cpp:226] relu4 needs backward computation.
I0524 02:03:37.020786 15289 net.cpp:226] conv4 needs backward computation.
I0524 02:03:37.020795 15289 net.cpp:226] pool3 needs backward computation.
I0524 02:03:37.020805 15289 net.cpp:226] relu3 needs backward computation.
I0524 02:03:37.020823 15289 net.cpp:226] conv3 needs backward computation.
I0524 02:03:37.020833 15289 net.cpp:226] pool2 needs backward computation.
I0524 02:03:37.020843 15289 net.cpp:226] relu2 needs backward computation.
I0524 02:03:37.020861 15289 net.cpp:226] conv2 needs backward computation.
I0524 02:03:37.020874 15289 net.cpp:226] pool1 needs backward computation.
I0524 02:03:37.020884 15289 net.cpp:226] relu1 needs backward computation.
I0524 02:03:37.020895 15289 net.cpp:226] conv1 needs backward computation.
I0524 02:03:37.020905 15289 net.cpp:228] data_hdf5 does not need backward computation.
I0524 02:03:37.020915 15289 net.cpp:270] This network produces output loss
I0524 02:03:37.020938 15289 net.cpp:283] Network initialization done.
I0524 02:03:37.022559 15289 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565.prototxt
I0524 02:03:37.022630 15289 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0524 02:03:37.022986 15289 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 02:03:37.023175 15289 layer_factory.hpp:77] Creating layer data_hdf5
I0524 02:03:37.023190 15289 net.cpp:106] Creating Layer data_hdf5
I0524 02:03:37.023202 15289 net.cpp:411] data_hdf5 -> data
I0524 02:03:37.023218 15289 net.cpp:411] data_hdf5 -> label
I0524 02:03:37.023234 15289 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0524 02:03:37.024518 15289 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0524 02:03:58.447809 15289 net.cpp:150] Setting up data_hdf5
I0524 02:03:58.447974 15289 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0524 02:03:58.447989 15289 net.cpp:157] Top shape: 70 (70)
I0524 02:03:58.448001 15289 net.cpp:165] Memory required for data: 1778280
I0524 02:03:58.448014 15289 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0524 02:03:58.448043 15289 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0524 02:03:58.448055 15289 net.cpp:454] label_data_hdf5_1_split <- label
I0524 02:03:58.448070 15289 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0524 02:03:58.448091 15289 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0524 02:03:58.448163 15289 net.cpp:150] Setting up label_data_hdf5_1_split
I0524 02:03:58.448178 15289 net.cpp:157] Top shape: 70 (70)
I0524 02:03:58.448189 15289 net.cpp:157] Top shape: 70 (70)
I0524 02:03:58.448199 15289 net.cpp:165] Memory required for data: 1778840
I0524 02:03:58.448209 15289 layer_factory.hpp:77] Creating layer conv1
I0524 02:03:58.448231 15289 net.cpp:106] Creating Layer conv1
I0524 02:03:58.448241 15289 net.cpp:454] conv1 <- data
I0524 02:03:58.448253 15289 net.cpp:411] conv1 -> conv1
I0524 02:03:58.450186 15289 net.cpp:150] Setting up conv1
I0524 02:03:58.450212 15289 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 02:03:58.450223 15289 net.cpp:165] Memory required for data: 21132440
I0524 02:03:58.450243 15289 layer_factory.hpp:77] Creating layer relu1
I0524 02:03:58.450259 15289 net.cpp:106] Creating Layer relu1
I0524 02:03:58.450269 15289 net.cpp:454] relu1 <- conv1
I0524 02:03:58.450281 15289 net.cpp:397] relu1 -> conv1 (in-place)
I0524 02:03:58.450776 15289 net.cpp:150] Setting up relu1
I0524 02:03:58.450793 15289 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 02:03:58.450803 15289 net.cpp:165] Memory required for data: 40486040
I0524 02:03:58.450812 15289 layer_factory.hpp:77] Creating layer pool1
I0524 02:03:58.450829 15289 net.cpp:106] Creating Layer pool1
I0524 02:03:58.450839 15289 net.cpp:454] pool1 <- conv1
I0524 02:03:58.450853 15289 net.cpp:411] pool1 -> pool1
I0524 02:03:58.450929 15289 net.cpp:150] Setting up pool1
I0524 02:03:58.450942 15289 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0524 02:03:58.450953 15289 net.cpp:165] Memory required for data: 50162840
I0524 02:03:58.450960 15289 layer_factory.hpp:77] Creating layer conv2
I0524 02:03:58.450978 15289 net.cpp:106] Creating Layer conv2
I0524 02:03:58.450989 15289 net.cpp:454] conv2 <- pool1
I0524 02:03:58.451004 15289 net.cpp:411] conv2 -> conv2
I0524 02:03:58.452919 15289 net.cpp:150] Setting up conv2
I0524 02:03:58.452940 15289 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 02:03:58.452953 15289 net.cpp:165] Memory required for data: 64073240
I0524 02:03:58.452971 15289 layer_factory.hpp:77] Creating layer relu2
I0524 02:03:58.452985 15289 net.cpp:106] Creating Layer relu2
I0524 02:03:58.452994 15289 net.cpp:454] relu2 <- conv2
I0524 02:03:58.453007 15289 net.cpp:397] relu2 -> conv2 (in-place)
I0524 02:03:58.453338 15289 net.cpp:150] Setting up relu2
I0524 02:03:58.453352 15289 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 02:03:58.453362 15289 net.cpp:165] Memory required for data: 77983640
I0524 02:03:58.453372 15289 layer_factory.hpp:77] Creating layer pool2
I0524 02:03:58.453387 15289 net.cpp:106] Creating Layer pool2
I0524 02:03:58.453397 15289 net.cpp:454] pool2 <- conv2
I0524 02:03:58.453408 15289 net.cpp:411] pool2 -> pool2
I0524 02:03:58.453481 15289 net.cpp:150] Setting up pool2
I0524 02:03:58.453495 15289 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0524 02:03:58.453505 15289 net.cpp:165] Memory required for data: 84938840
I0524 02:03:58.453513 15289 layer_factory.hpp:77] Creating layer conv3
I0524 02:03:58.453533 15289 net.cpp:106] Creating Layer conv3
I0524 02:03:58.453544 15289 net.cpp:454] conv3 <- pool2
I0524 02:03:58.453558 15289 net.cpp:411] conv3 -> conv3
I0524 02:03:58.455538 15289 net.cpp:150] Setting up conv3
I0524 02:03:58.455562 15289 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 02:03:58.455574 15289 net.cpp:165] Memory required for data: 92527960
I0524 02:03:58.455605 15289 layer_factory.hpp:77] Creating layer relu3
I0524 02:03:58.455620 15289 net.cpp:106] Creating Layer relu3
I0524 02:03:58.455631 15289 net.cpp:454] relu3 <- conv3
I0524 02:03:58.455643 15289 net.cpp:397] relu3 -> conv3 (in-place)
I0524 02:03:58.456115 15289 net.cpp:150] Setting up relu3
I0524 02:03:58.456130 15289 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 02:03:58.456140 15289 net.cpp:165] Memory required for data: 100117080
I0524 02:03:58.456151 15289 layer_factory.hpp:77] Creating layer pool3
I0524 02:03:58.456164 15289 net.cpp:106] Creating Layer pool3
I0524 02:03:58.456174 15289 net.cpp:454] pool3 <- conv3
I0524 02:03:58.456187 15289 net.cpp:411] pool3 -> pool3
I0524 02:03:58.456259 15289 net.cpp:150] Setting up pool3
I0524 02:03:58.456272 15289 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0524 02:03:58.456281 15289 net.cpp:165] Memory required for data: 103911640
I0524 02:03:58.456291 15289 layer_factory.hpp:77] Creating layer conv4
I0524 02:03:58.456306 15289 net.cpp:106] Creating Layer conv4
I0524 02:03:58.456317 15289 net.cpp:454] conv4 <- pool3
I0524 02:03:58.456331 15289 net.cpp:411] conv4 -> conv4
I0524 02:03:58.458397 15289 net.cpp:150] Setting up conv4
I0524 02:03:58.458418 15289 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 02:03:58.458428 15289 net.cpp:165] Memory required for data: 106451800
I0524 02:03:58.458443 15289 layer_factory.hpp:77] Creating layer relu4
I0524 02:03:58.458457 15289 net.cpp:106] Creating Layer relu4
I0524 02:03:58.458467 15289 net.cpp:454] relu4 <- conv4
I0524 02:03:58.458480 15289 net.cpp:397] relu4 -> conv4 (in-place)
I0524 02:03:58.458952 15289 net.cpp:150] Setting up relu4
I0524 02:03:58.458968 15289 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 02:03:58.458978 15289 net.cpp:165] Memory required for data: 108991960
I0524 02:03:58.458988 15289 layer_factory.hpp:77] Creating layer pool4
I0524 02:03:58.459002 15289 net.cpp:106] Creating Layer pool4
I0524 02:03:58.459012 15289 net.cpp:454] pool4 <- conv4
I0524 02:03:58.459024 15289 net.cpp:411] pool4 -> pool4
I0524 02:03:58.459095 15289 net.cpp:150] Setting up pool4
I0524 02:03:58.459110 15289 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0524 02:03:58.459118 15289 net.cpp:165] Memory required for data: 110262040
I0524 02:03:58.459128 15289 layer_factory.hpp:77] Creating layer ip1
I0524 02:03:58.459141 15289 net.cpp:106] Creating Layer ip1
I0524 02:03:58.459152 15289 net.cpp:454] ip1 <- pool4
I0524 02:03:58.459166 15289 net.cpp:411] ip1 -> ip1
I0524 02:03:58.474668 15289 net.cpp:150] Setting up ip1
I0524 02:03:58.474696 15289 net.cpp:157] Top shape: 70 196 (13720)
I0524 02:03:58.474709 15289 net.cpp:165] Memory required for data: 110316920
I0524 02:03:58.474735 15289 layer_factory.hpp:77] Creating layer relu5
I0524 02:03:58.474750 15289 net.cpp:106] Creating Layer relu5
I0524 02:03:58.474761 15289 net.cpp:454] relu5 <- ip1
I0524 02:03:58.474776 15289 net.cpp:397] relu5 -> ip1 (in-place)
I0524 02:03:58.475122 15289 net.cpp:150] Setting up relu5
I0524 02:03:58.475136 15289 net.cpp:157] Top shape: 70 196 (13720)
I0524 02:03:58.475147 15289 net.cpp:165] Memory required for data: 110371800
I0524 02:03:58.475157 15289 layer_factory.hpp:77] Creating layer drop1
I0524 02:03:58.475177 15289 net.cpp:106] Creating Layer drop1
I0524 02:03:58.475186 15289 net.cpp:454] drop1 <- ip1
I0524 02:03:58.475199 15289 net.cpp:397] drop1 -> ip1 (in-place)
I0524 02:03:58.475246 15289 net.cpp:150] Setting up drop1
I0524 02:03:58.475260 15289 net.cpp:157] Top shape: 70 196 (13720)
I0524 02:03:58.475270 15289 net.cpp:165] Memory required for data: 110426680
I0524 02:03:58.475278 15289 layer_factory.hpp:77] Creating layer ip2
I0524 02:03:58.475293 15289 net.cpp:106] Creating Layer ip2
I0524 02:03:58.475303 15289 net.cpp:454] ip2 <- ip1
I0524 02:03:58.475317 15289 net.cpp:411] ip2 -> ip2
I0524 02:03:58.475795 15289 net.cpp:150] Setting up ip2
I0524 02:03:58.475808 15289 net.cpp:157] Top shape: 70 98 (6860)
I0524 02:03:58.475818 15289 net.cpp:165] Memory required for data: 110454120
I0524 02:03:58.475833 15289 layer_factory.hpp:77] Creating layer relu6
I0524 02:03:58.475859 15289 net.cpp:106] Creating Layer relu6
I0524 02:03:58.475869 15289 net.cpp:454] relu6 <- ip2
I0524 02:03:58.475881 15289 net.cpp:397] relu6 -> ip2 (in-place)
I0524 02:03:58.476414 15289 net.cpp:150] Setting up relu6
I0524 02:03:58.476430 15289 net.cpp:157] Top shape: 70 98 (6860)
I0524 02:03:58.476441 15289 net.cpp:165] Memory required for data: 110481560
I0524 02:03:58.476451 15289 layer_factory.hpp:77] Creating layer drop2
I0524 02:03:58.476464 15289 net.cpp:106] Creating Layer drop2
I0524 02:03:58.476475 15289 net.cpp:454] drop2 <- ip2
I0524 02:03:58.476487 15289 net.cpp:397] drop2 -> ip2 (in-place)
I0524 02:03:58.476533 15289 net.cpp:150] Setting up drop2
I0524 02:03:58.476546 15289 net.cpp:157] Top shape: 70 98 (6860)
I0524 02:03:58.476555 15289 net.cpp:165] Memory required for data: 110509000
I0524 02:03:58.476565 15289 layer_factory.hpp:77] Creating layer ip3
I0524 02:03:58.476580 15289 net.cpp:106] Creating Layer ip3
I0524 02:03:58.476589 15289 net.cpp:454] ip3 <- ip2
I0524 02:03:58.476603 15289 net.cpp:411] ip3 -> ip3
I0524 02:03:58.476826 15289 net.cpp:150] Setting up ip3
I0524 02:03:58.476840 15289 net.cpp:157] Top shape: 70 11 (770)
I0524 02:03:58.476850 15289 net.cpp:165] Memory required for data: 110512080
I0524 02:03:58.476873 15289 layer_factory.hpp:77] Creating layer drop3
I0524 02:03:58.476886 15289 net.cpp:106] Creating Layer drop3
I0524 02:03:58.476897 15289 net.cpp:454] drop3 <- ip3
I0524 02:03:58.476909 15289 net.cpp:397] drop3 -> ip3 (in-place)
I0524 02:03:58.476953 15289 net.cpp:150] Setting up drop3
I0524 02:03:58.476965 15289 net.cpp:157] Top shape: 70 11 (770)
I0524 02:03:58.476975 15289 net.cpp:165] Memory required for data: 110515160
I0524 02:03:58.476984 15289 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0524 02:03:58.476997 15289 net.cpp:106] Creating Layer ip3_drop3_0_split
I0524 02:03:58.477007 15289 net.cpp:454] ip3_drop3_0_split <- ip3
I0524 02:03:58.477020 15289 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0524 02:03:58.477035 15289 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0524 02:03:58.477108 15289 net.cpp:150] Setting up ip3_drop3_0_split
I0524 02:03:58.477121 15289 net.cpp:157] Top shape: 70 11 (770)
I0524 02:03:58.477134 15289 net.cpp:157] Top shape: 70 11 (770)
I0524 02:03:58.477144 15289 net.cpp:165] Memory required for data: 110521320
I0524 02:03:58.477154 15289 layer_factory.hpp:77] Creating layer accuracy
I0524 02:03:58.477177 15289 net.cpp:106] Creating Layer accuracy
I0524 02:03:58.477187 15289 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0524 02:03:58.477198 15289 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0524 02:03:58.477212 15289 net.cpp:411] accuracy -> accuracy
I0524 02:03:58.477236 15289 net.cpp:150] Setting up accuracy
I0524 02:03:58.477248 15289 net.cpp:157] Top shape: (1)
I0524 02:03:58.477258 15289 net.cpp:165] Memory required for data: 110521324
I0524 02:03:58.477268 15289 layer_factory.hpp:77] Creating layer loss
I0524 02:03:58.477283 15289 net.cpp:106] Creating Layer loss
I0524 02:03:58.477293 15289 net.cpp:454] loss <- ip3_drop3_0_split_1
I0524 02:03:58.477304 15289 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0524 02:03:58.477318 15289 net.cpp:411] loss -> loss
I0524 02:03:58.477335 15289 layer_factory.hpp:77] Creating layer loss
I0524 02:03:58.477821 15289 net.cpp:150] Setting up loss
I0524 02:03:58.477835 15289 net.cpp:157] Top shape: (1)
I0524 02:03:58.477845 15289 net.cpp:160]     with loss weight 1
I0524 02:03:58.477864 15289 net.cpp:165] Memory required for data: 110521328
I0524 02:03:58.477874 15289 net.cpp:226] loss needs backward computation.
I0524 02:03:58.477885 15289 net.cpp:228] accuracy does not need backward computation.
I0524 02:03:58.477896 15289 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0524 02:03:58.477907 15289 net.cpp:226] drop3 needs backward computation.
I0524 02:03:58.477916 15289 net.cpp:226] ip3 needs backward computation.
I0524 02:03:58.477927 15289 net.cpp:226] drop2 needs backward computation.
I0524 02:03:58.477937 15289 net.cpp:226] relu6 needs backward computation.
I0524 02:03:58.477954 15289 net.cpp:226] ip2 needs backward computation.
I0524 02:03:58.477965 15289 net.cpp:226] drop1 needs backward computation.
I0524 02:03:58.477974 15289 net.cpp:226] relu5 needs backward computation.
I0524 02:03:58.477984 15289 net.cpp:226] ip1 needs backward computation.
I0524 02:03:58.477994 15289 net.cpp:226] pool4 needs backward computation.
I0524 02:03:58.478004 15289 net.cpp:226] relu4 needs backward computation.
I0524 02:03:58.478014 15289 net.cpp:226] conv4 needs backward computation.
I0524 02:03:58.478024 15289 net.cpp:226] pool3 needs backward computation.
I0524 02:03:58.478034 15289 net.cpp:226] relu3 needs backward computation.
I0524 02:03:58.478044 15289 net.cpp:226] conv3 needs backward computation.
I0524 02:03:58.478055 15289 net.cpp:226] pool2 needs backward computation.
I0524 02:03:58.478065 15289 net.cpp:226] relu2 needs backward computation.
I0524 02:03:58.478075 15289 net.cpp:226] conv2 needs backward computation.
I0524 02:03:58.478086 15289 net.cpp:226] pool1 needs backward computation.
I0524 02:03:58.478096 15289 net.cpp:226] relu1 needs backward computation.
I0524 02:03:58.478106 15289 net.cpp:226] conv1 needs backward computation.
I0524 02:03:58.478117 15289 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0524 02:03:58.478129 15289 net.cpp:228] data_hdf5 does not need backward computation.
I0524 02:03:58.478139 15289 net.cpp:270] This network produces output accuracy
I0524 02:03:58.478148 15289 net.cpp:270] This network produces output loss
I0524 02:03:58.478178 15289 net.cpp:283] Network initialization done.
I0524 02:03:58.478310 15289 solver.cpp:60] Solver scaffolding done.
I0524 02:03:58.479440 15289 caffe.cpp:212] Starting Optimization
I0524 02:03:58.479460 15289 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0524 02:03:58.479472 15289 solver.cpp:289] Learning Rate Policy: fixed
I0524 02:03:58.480692 15289 solver.cpp:341] Iteration 0, Testing net (#0)
I0524 02:04:47.388387 15289 solver.cpp:409]     Test net output #0: accuracy = 0.071782
I0524 02:04:47.388550 15289 solver.cpp:409]     Test net output #1: loss = 2.39745 (* 1 = 2.39745 loss)
I0524 02:04:47.416501 15289 solver.cpp:237] Iteration 0, loss = 2.39901
I0524 02:04:47.416538 15289 solver.cpp:253]     Train net output #0: loss = 2.39901 (* 1 = 2.39901 loss)
I0524 02:04:47.416556 15289 sgd_solver.cpp:106] Iteration 0, lr = 0.003
I0524 02:04:56.299113 15289 solver.cpp:237] Iteration 214, loss = 2.26434
I0524 02:04:56.299157 15289 solver.cpp:253]     Train net output #0: loss = 2.26434 (* 1 = 2.26434 loss)
I0524 02:04:56.299175 15289 sgd_solver.cpp:106] Iteration 214, lr = 0.003
I0524 02:05:05.191550 15289 solver.cpp:237] Iteration 428, loss = 2.12006
I0524 02:05:05.191586 15289 solver.cpp:253]     Train net output #0: loss = 2.12006 (* 1 = 2.12006 loss)
I0524 02:05:05.191601 15289 sgd_solver.cpp:106] Iteration 428, lr = 0.003
I0524 02:05:14.070344 15289 solver.cpp:237] Iteration 642, loss = 2.17687
I0524 02:05:14.070380 15289 solver.cpp:253]     Train net output #0: loss = 2.17687 (* 1 = 2.17687 loss)
I0524 02:05:14.070394 15289 sgd_solver.cpp:106] Iteration 642, lr = 0.003
I0524 02:05:22.955281 15289 solver.cpp:237] Iteration 856, loss = 1.98196
I0524 02:05:22.955442 15289 solver.cpp:253]     Train net output #0: loss = 1.98196 (* 1 = 1.98196 loss)
I0524 02:05:22.955456 15289 sgd_solver.cpp:106] Iteration 856, lr = 0.003
I0524 02:05:31.835273 15289 solver.cpp:237] Iteration 1070, loss = 1.77449
I0524 02:05:31.835306 15289 solver.cpp:253]     Train net output #0: loss = 1.77449 (* 1 = 1.77449 loss)
I0524 02:05:31.835325 15289 sgd_solver.cpp:106] Iteration 1070, lr = 0.003
I0524 02:05:40.715919 15289 solver.cpp:237] Iteration 1284, loss = 1.80751
I0524 02:05:40.715955 15289 solver.cpp:253]     Train net output #0: loss = 1.80751 (* 1 = 1.80751 loss)
I0524 02:05:40.715970 15289 sgd_solver.cpp:106] Iteration 1284, lr = 0.003
I0524 02:06:11.772428 15289 solver.cpp:237] Iteration 1498, loss = 2.06478
I0524 02:06:11.772591 15289 solver.cpp:253]     Train net output #0: loss = 2.06478 (* 1 = 2.06478 loss)
I0524 02:06:11.772606 15289 sgd_solver.cpp:106] Iteration 1498, lr = 0.003
I0524 02:06:20.664491 15289 solver.cpp:237] Iteration 1712, loss = 1.6897
I0524 02:06:20.664526 15289 solver.cpp:253]     Train net output #0: loss = 1.6897 (* 1 = 1.6897 loss)
I0524 02:06:20.664546 15289 sgd_solver.cpp:106] Iteration 1712, lr = 0.003
I0524 02:06:29.551302 15289 solver.cpp:237] Iteration 1926, loss = 1.75531
I0524 02:06:29.551337 15289 solver.cpp:253]     Train net output #0: loss = 1.75531 (* 1 = 1.75531 loss)
I0524 02:06:29.551352 15289 sgd_solver.cpp:106] Iteration 1926, lr = 0.003
I0524 02:06:38.436517 15289 solver.cpp:237] Iteration 2140, loss = 1.83547
I0524 02:06:38.436558 15289 solver.cpp:253]     Train net output #0: loss = 1.83547 (* 1 = 1.83547 loss)
I0524 02:06:38.436576 15289 sgd_solver.cpp:106] Iteration 2140, lr = 0.003
I0524 02:06:38.478951 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_2142.caffemodel
I0524 02:06:38.549543 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_2142.solverstate
I0524 02:06:47.391908 15289 solver.cpp:237] Iteration 2354, loss = 1.70861
I0524 02:06:47.392062 15289 solver.cpp:253]     Train net output #0: loss = 1.70861 (* 1 = 1.70861 loss)
I0524 02:06:47.392076 15289 sgd_solver.cpp:106] Iteration 2354, lr = 0.003
I0524 02:06:56.275391 15289 solver.cpp:237] Iteration 2568, loss = 1.83618
I0524 02:06:56.275425 15289 solver.cpp:253]     Train net output #0: loss = 1.83618 (* 1 = 1.83618 loss)
I0524 02:06:56.275442 15289 sgd_solver.cpp:106] Iteration 2568, lr = 0.003
I0524 02:07:05.160778 15289 solver.cpp:237] Iteration 2782, loss = 1.68138
I0524 02:07:05.160816 15289 solver.cpp:253]     Train net output #0: loss = 1.68138 (* 1 = 1.68138 loss)
I0524 02:07:05.160837 15289 sgd_solver.cpp:106] Iteration 2782, lr = 0.003
I0524 02:07:36.239740 15289 solver.cpp:237] Iteration 2996, loss = 1.65296
I0524 02:07:36.239897 15289 solver.cpp:253]     Train net output #0: loss = 1.65296 (* 1 = 1.65296 loss)
I0524 02:07:36.239913 15289 sgd_solver.cpp:106] Iteration 2996, lr = 0.003
I0524 02:07:45.131065 15289 solver.cpp:237] Iteration 3210, loss = 1.71038
I0524 02:07:45.131099 15289 solver.cpp:253]     Train net output #0: loss = 1.71038 (* 1 = 1.71038 loss)
I0524 02:07:45.131114 15289 sgd_solver.cpp:106] Iteration 3210, lr = 0.003
I0524 02:07:54.024018 15289 solver.cpp:237] Iteration 3424, loss = 1.40896
I0524 02:07:54.024066 15289 solver.cpp:253]     Train net output #0: loss = 1.40896 (* 1 = 1.40896 loss)
I0524 02:07:54.024081 15289 sgd_solver.cpp:106] Iteration 3424, lr = 0.003
I0524 02:08:02.909494 15289 solver.cpp:237] Iteration 3638, loss = 1.38288
I0524 02:08:02.909529 15289 solver.cpp:253]     Train net output #0: loss = 1.38288 (* 1 = 1.38288 loss)
I0524 02:08:02.909546 15289 sgd_solver.cpp:106] Iteration 3638, lr = 0.003
I0524 02:08:11.794136 15289 solver.cpp:237] Iteration 3852, loss = 1.47414
I0524 02:08:11.794298 15289 solver.cpp:253]     Train net output #0: loss = 1.47414 (* 1 = 1.47414 loss)
I0524 02:08:11.794312 15289 sgd_solver.cpp:106] Iteration 3852, lr = 0.003
I0524 02:08:20.676687 15289 solver.cpp:237] Iteration 4066, loss = 1.63499
I0524 02:08:20.676728 15289 solver.cpp:253]     Train net output #0: loss = 1.63499 (* 1 = 1.63499 loss)
I0524 02:08:20.676749 15289 sgd_solver.cpp:106] Iteration 4066, lr = 0.003
I0524 02:08:29.563446 15289 solver.cpp:237] Iteration 4280, loss = 1.39576
I0524 02:08:29.563480 15289 solver.cpp:253]     Train net output #0: loss = 1.39576 (* 1 = 1.39576 loss)
I0524 02:08:29.563498 15289 sgd_solver.cpp:106] Iteration 4280, lr = 0.003
I0524 02:08:29.689182 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_4284.caffemodel
I0524 02:08:29.755069 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_4284.solverstate
I0524 02:08:29.794369 15289 solver.cpp:341] Iteration 4285, Testing net (#0)
I0524 02:09:17.787814 15289 solver.cpp:409]     Test net output #0: accuracy = 0.769707
I0524 02:09:17.787991 15289 solver.cpp:409]     Test net output #1: loss = 0.890121 (* 1 = 0.890121 loss)
I0524 02:09:48.720731 15289 solver.cpp:237] Iteration 4494, loss = 1.25068
I0524 02:09:48.720893 15289 solver.cpp:253]     Train net output #0: loss = 1.25068 (* 1 = 1.25068 loss)
I0524 02:09:48.720909 15289 sgd_solver.cpp:106] Iteration 4494, lr = 0.003
I0524 02:09:57.588871 15289 solver.cpp:237] Iteration 4708, loss = 1.39766
I0524 02:09:57.588914 15289 solver.cpp:253]     Train net output #0: loss = 1.39766 (* 1 = 1.39766 loss)
I0524 02:09:57.588932 15289 sgd_solver.cpp:106] Iteration 4708, lr = 0.003
I0524 02:10:06.454468 15289 solver.cpp:237] Iteration 4922, loss = 1.55968
I0524 02:10:06.454502 15289 solver.cpp:253]     Train net output #0: loss = 1.55968 (* 1 = 1.55968 loss)
I0524 02:10:06.454519 15289 sgd_solver.cpp:106] Iteration 4922, lr = 0.003
I0524 02:10:15.325217 15289 solver.cpp:237] Iteration 5136, loss = 1.30903
I0524 02:10:15.325253 15289 solver.cpp:253]     Train net output #0: loss = 1.30903 (* 1 = 1.30903 loss)
I0524 02:10:15.325269 15289 sgd_solver.cpp:106] Iteration 5136, lr = 0.003
I0524 02:10:24.190626 15289 solver.cpp:237] Iteration 5350, loss = 1.57144
I0524 02:10:24.190784 15289 solver.cpp:253]     Train net output #0: loss = 1.57144 (* 1 = 1.57144 loss)
I0524 02:10:24.190798 15289 sgd_solver.cpp:106] Iteration 5350, lr = 0.003
I0524 02:10:33.059061 15289 solver.cpp:237] Iteration 5564, loss = 1.29278
I0524 02:10:33.059095 15289 solver.cpp:253]     Train net output #0: loss = 1.29278 (* 1 = 1.29278 loss)
I0524 02:10:33.059111 15289 sgd_solver.cpp:106] Iteration 5564, lr = 0.003
I0524 02:11:04.161757 15289 solver.cpp:237] Iteration 5778, loss = 1.50793
I0524 02:11:04.161923 15289 solver.cpp:253]     Train net output #0: loss = 1.50793 (* 1 = 1.50793 loss)
I0524 02:11:04.161939 15289 sgd_solver.cpp:106] Iteration 5778, lr = 0.003
I0524 02:11:13.024451 15289 solver.cpp:237] Iteration 5992, loss = 1.17172
I0524 02:11:13.024493 15289 solver.cpp:253]     Train net output #0: loss = 1.17172 (* 1 = 1.17172 loss)
I0524 02:11:13.024513 15289 sgd_solver.cpp:106] Iteration 5992, lr = 0.003
I0524 02:11:21.888543 15289 solver.cpp:237] Iteration 6206, loss = 1.42197
I0524 02:11:21.888579 15289 solver.cpp:253]     Train net output #0: loss = 1.42197 (* 1 = 1.42197 loss)
I0524 02:11:21.888595 15289 sgd_solver.cpp:106] Iteration 6206, lr = 0.003
I0524 02:11:30.757853 15289 solver.cpp:237] Iteration 6420, loss = 1.4738
I0524 02:11:30.757886 15289 solver.cpp:253]     Train net output #0: loss = 1.4738 (* 1 = 1.4738 loss)
I0524 02:11:30.757904 15289 sgd_solver.cpp:106] Iteration 6420, lr = 0.003
I0524 02:11:30.965193 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_6426.caffemodel
I0524 02:11:31.033668 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_6426.solverstate
I0524 02:11:39.693951 15289 solver.cpp:237] Iteration 6634, loss = 1.32494
I0524 02:11:39.694123 15289 solver.cpp:253]     Train net output #0: loss = 1.32494 (* 1 = 1.32494 loss)
I0524 02:11:39.694138 15289 sgd_solver.cpp:106] Iteration 6634, lr = 0.003
I0524 02:11:48.561468 15289 solver.cpp:237] Iteration 6848, loss = 1.42804
I0524 02:11:48.561504 15289 solver.cpp:253]     Train net output #0: loss = 1.42804 (* 1 = 1.42804 loss)
I0524 02:11:48.561522 15289 sgd_solver.cpp:106] Iteration 6848, lr = 0.003
I0524 02:11:57.431090 15289 solver.cpp:237] Iteration 7062, loss = 1.2592
I0524 02:11:57.431126 15289 solver.cpp:253]     Train net output #0: loss = 1.2592 (* 1 = 1.2592 loss)
I0524 02:11:57.431143 15289 sgd_solver.cpp:106] Iteration 7062, lr = 0.003
I0524 02:12:28.610270 15289 solver.cpp:237] Iteration 7276, loss = 1.62041
I0524 02:12:28.610430 15289 solver.cpp:253]     Train net output #0: loss = 1.62041 (* 1 = 1.62041 loss)
I0524 02:12:28.610445 15289 sgd_solver.cpp:106] Iteration 7276, lr = 0.003
I0524 02:12:37.482820 15289 solver.cpp:237] Iteration 7490, loss = 1.46807
I0524 02:12:37.482854 15289 solver.cpp:253]     Train net output #0: loss = 1.46807 (* 1 = 1.46807 loss)
I0524 02:12:37.482873 15289 sgd_solver.cpp:106] Iteration 7490, lr = 0.003
I0524 02:12:46.356546 15289 solver.cpp:237] Iteration 7704, loss = 1.51752
I0524 02:12:46.356582 15289 solver.cpp:253]     Train net output #0: loss = 1.51752 (* 1 = 1.51752 loss)
I0524 02:12:46.356598 15289 sgd_solver.cpp:106] Iteration 7704, lr = 0.003
I0524 02:12:55.222194 15289 solver.cpp:237] Iteration 7918, loss = 1.41684
I0524 02:12:55.222241 15289 solver.cpp:253]     Train net output #0: loss = 1.41684 (* 1 = 1.41684 loss)
I0524 02:12:55.222259 15289 sgd_solver.cpp:106] Iteration 7918, lr = 0.003
I0524 02:13:04.090317 15289 solver.cpp:237] Iteration 8132, loss = 1.12253
I0524 02:13:04.090458 15289 solver.cpp:253]     Train net output #0: loss = 1.12253 (* 1 = 1.12253 loss)
I0524 02:13:04.090472 15289 sgd_solver.cpp:106] Iteration 8132, lr = 0.003
I0524 02:13:12.954831 15289 solver.cpp:237] Iteration 8346, loss = 1.47268
I0524 02:13:12.954866 15289 solver.cpp:253]     Train net output #0: loss = 1.47268 (* 1 = 1.47268 loss)
I0524 02:13:12.954884 15289 sgd_solver.cpp:106] Iteration 8346, lr = 0.003
I0524 02:13:21.828500 15289 solver.cpp:237] Iteration 8560, loss = 1.41413
I0524 02:13:21.828547 15289 solver.cpp:253]     Train net output #0: loss = 1.41413 (* 1 = 1.41413 loss)
I0524 02:13:21.828562 15289 sgd_solver.cpp:106] Iteration 8560, lr = 0.003
I0524 02:13:22.118793 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_8568.caffemodel
I0524 02:13:22.186579 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_8568.solverstate
I0524 02:13:22.269282 15289 solver.cpp:341] Iteration 8570, Testing net (#0)
I0524 02:14:31.056103 15289 solver.cpp:409]     Test net output #0: accuracy = 0.815624
I0524 02:14:31.056272 15289 solver.cpp:409]     Test net output #1: loss = 0.653552 (* 1 = 0.653552 loss)
I0524 02:15:01.791604 15289 solver.cpp:237] Iteration 8774, loss = 1.36548
I0524 02:15:01.791769 15289 solver.cpp:253]     Train net output #0: loss = 1.36548 (* 1 = 1.36548 loss)
I0524 02:15:01.791785 15289 sgd_solver.cpp:106] Iteration 8774, lr = 0.003
I0524 02:15:10.688712 15289 solver.cpp:237] Iteration 8988, loss = 1.58426
I0524 02:15:10.688747 15289 solver.cpp:253]     Train net output #0: loss = 1.58426 (* 1 = 1.58426 loss)
I0524 02:15:10.688765 15289 sgd_solver.cpp:106] Iteration 8988, lr = 0.003
I0524 02:15:19.583586 15289 solver.cpp:237] Iteration 9202, loss = 1.22304
I0524 02:15:19.583629 15289 solver.cpp:253]     Train net output #0: loss = 1.22304 (* 1 = 1.22304 loss)
I0524 02:15:19.583642 15289 sgd_solver.cpp:106] Iteration 9202, lr = 0.003
I0524 02:15:28.481765 15289 solver.cpp:237] Iteration 9416, loss = 1.2776
I0524 02:15:28.481801 15289 solver.cpp:253]     Train net output #0: loss = 1.2776 (* 1 = 1.2776 loss)
I0524 02:15:28.481818 15289 sgd_solver.cpp:106] Iteration 9416, lr = 0.003
I0524 02:15:37.379149 15289 solver.cpp:237] Iteration 9630, loss = 1.15466
I0524 02:15:37.379286 15289 solver.cpp:253]     Train net output #0: loss = 1.15466 (* 1 = 1.15466 loss)
I0524 02:15:37.379299 15289 sgd_solver.cpp:106] Iteration 9630, lr = 0.003
I0524 02:15:46.282191 15289 solver.cpp:237] Iteration 9844, loss = 1.36863
I0524 02:15:46.282238 15289 solver.cpp:253]     Train net output #0: loss = 1.36863 (* 1 = 1.36863 loss)
I0524 02:15:46.282253 15289 sgd_solver.cpp:106] Iteration 9844, lr = 0.003
I0524 02:16:17.426266 15289 solver.cpp:237] Iteration 10058, loss = 1.35316
I0524 02:16:17.426435 15289 solver.cpp:253]     Train net output #0: loss = 1.35316 (* 1 = 1.35316 loss)
I0524 02:16:17.426450 15289 sgd_solver.cpp:106] Iteration 10058, lr = 0.003
I0524 02:16:26.325301 15289 solver.cpp:237] Iteration 10272, loss = 1.36456
I0524 02:16:26.325336 15289 solver.cpp:253]     Train net output #0: loss = 1.36456 (* 1 = 1.36456 loss)
I0524 02:16:26.325353 15289 sgd_solver.cpp:106] Iteration 10272, lr = 0.003
I0524 02:16:35.223912 15289 solver.cpp:237] Iteration 10486, loss = 1.78542
I0524 02:16:35.223958 15289 solver.cpp:253]     Train net output #0: loss = 1.78542 (* 1 = 1.78542 loss)
I0524 02:16:35.223974 15289 sgd_solver.cpp:106] Iteration 10486, lr = 0.003
I0524 02:16:44.121350 15289 solver.cpp:237] Iteration 10700, loss = 1.44088
I0524 02:16:44.121386 15289 solver.cpp:253]     Train net output #0: loss = 1.44088 (* 1 = 1.44088 loss)
I0524 02:16:44.121400 15289 sgd_solver.cpp:106] Iteration 10700, lr = 0.003
I0524 02:16:44.495115 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_10710.caffemodel
I0524 02:16:44.563532 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_10710.solverstate
I0524 02:16:53.104360 15289 solver.cpp:237] Iteration 10914, loss = 1.21219
I0524 02:16:53.104521 15289 solver.cpp:253]     Train net output #0: loss = 1.21219 (* 1 = 1.21219 loss)
I0524 02:16:53.104534 15289 sgd_solver.cpp:106] Iteration 10914, lr = 0.003
I0524 02:17:02.001224 15289 solver.cpp:237] Iteration 11128, loss = 1.13675
I0524 02:17:02.001266 15289 solver.cpp:253]     Train net output #0: loss = 1.13675 (* 1 = 1.13675 loss)
I0524 02:17:02.001284 15289 sgd_solver.cpp:106] Iteration 11128, lr = 0.003
I0524 02:17:10.899432 15289 solver.cpp:237] Iteration 11342, loss = 1.25757
I0524 02:17:10.899467 15289 solver.cpp:253]     Train net output #0: loss = 1.25757 (* 1 = 1.25757 loss)
I0524 02:17:10.899480 15289 sgd_solver.cpp:106] Iteration 11342, lr = 0.003
I0524 02:17:42.031760 15289 solver.cpp:237] Iteration 11556, loss = 1.48521
I0524 02:17:42.031936 15289 solver.cpp:253]     Train net output #0: loss = 1.48521 (* 1 = 1.48521 loss)
I0524 02:17:42.031954 15289 sgd_solver.cpp:106] Iteration 11556, lr = 0.003
I0524 02:17:50.929466 15289 solver.cpp:237] Iteration 11770, loss = 1.4059
I0524 02:17:50.929510 15289 solver.cpp:253]     Train net output #0: loss = 1.4059 (* 1 = 1.4059 loss)
I0524 02:17:50.929527 15289 sgd_solver.cpp:106] Iteration 11770, lr = 0.003
I0524 02:17:59.832612 15289 solver.cpp:237] Iteration 11984, loss = 1.51698
I0524 02:17:59.832646 15289 solver.cpp:253]     Train net output #0: loss = 1.51698 (* 1 = 1.51698 loss)
I0524 02:17:59.832660 15289 sgd_solver.cpp:106] Iteration 11984, lr = 0.003
I0524 02:18:08.729933 15289 solver.cpp:237] Iteration 12198, loss = 1.35833
I0524 02:18:08.729969 15289 solver.cpp:253]     Train net output #0: loss = 1.35833 (* 1 = 1.35833 loss)
I0524 02:18:08.729984 15289 sgd_solver.cpp:106] Iteration 12198, lr = 0.003
I0524 02:18:17.627171 15289 solver.cpp:237] Iteration 12412, loss = 1.0799
I0524 02:18:17.627321 15289 solver.cpp:253]     Train net output #0: loss = 1.0799 (* 1 = 1.0799 loss)
I0524 02:18:17.627336 15289 sgd_solver.cpp:106] Iteration 12412, lr = 0.003
I0524 02:18:26.527281 15289 solver.cpp:237] Iteration 12626, loss = 1.35066
I0524 02:18:26.527318 15289 solver.cpp:253]     Train net output #0: loss = 1.35066 (* 1 = 1.35066 loss)
I0524 02:18:26.527333 15289 sgd_solver.cpp:106] Iteration 12626, lr = 0.003
I0524 02:18:35.421051 15289 solver.cpp:237] Iteration 12840, loss = 1.64032
I0524 02:18:35.421087 15289 solver.cpp:253]     Train net output #0: loss = 1.64032 (* 1 = 1.64032 loss)
I0524 02:18:35.421103 15289 sgd_solver.cpp:106] Iteration 12840, lr = 0.003
I0524 02:18:35.879510 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_12852.caffemodel
I0524 02:18:36.139288 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_12852.solverstate
I0524 02:18:36.298429 15289 solver.cpp:341] Iteration 12855, Testing net (#0)
I0524 02:19:23.970767 15289 solver.cpp:409]     Test net output #0: accuracy = 0.846732
I0524 02:19:23.970928 15289 solver.cpp:409]     Test net output #1: loss = 0.484595 (* 1 = 0.484595 loss)
I0524 02:19:54.525743 15289 solver.cpp:237] Iteration 13054, loss = 1.12734
I0524 02:19:54.525897 15289 solver.cpp:253]     Train net output #0: loss = 1.12734 (* 1 = 1.12734 loss)
I0524 02:19:54.525912 15289 sgd_solver.cpp:106] Iteration 13054, lr = 0.003
I0524 02:20:03.404796 15289 solver.cpp:237] Iteration 13268, loss = 1.42749
I0524 02:20:03.404832 15289 solver.cpp:253]     Train net output #0: loss = 1.42749 (* 1 = 1.42749 loss)
I0524 02:20:03.404845 15289 sgd_solver.cpp:106] Iteration 13268, lr = 0.003
I0524 02:20:12.279443 15289 solver.cpp:237] Iteration 13482, loss = 1.34285
I0524 02:20:12.279477 15289 solver.cpp:253]     Train net output #0: loss = 1.34285 (* 1 = 1.34285 loss)
I0524 02:20:12.279490 15289 sgd_solver.cpp:106] Iteration 13482, lr = 0.003
I0524 02:20:21.152220 15289 solver.cpp:237] Iteration 13696, loss = 1.38271
I0524 02:20:21.152257 15289 solver.cpp:253]     Train net output #0: loss = 1.38271 (* 1 = 1.38271 loss)
I0524 02:20:21.152278 15289 sgd_solver.cpp:106] Iteration 13696, lr = 0.003
I0524 02:20:30.028117 15289 solver.cpp:237] Iteration 13910, loss = 1.37417
I0524 02:20:30.028257 15289 solver.cpp:253]     Train net output #0: loss = 1.37417 (* 1 = 1.37417 loss)
I0524 02:20:30.028273 15289 sgd_solver.cpp:106] Iteration 13910, lr = 0.003
I0524 02:20:38.906147 15289 solver.cpp:237] Iteration 14124, loss = 1.18426
I0524 02:20:38.906180 15289 solver.cpp:253]     Train net output #0: loss = 1.18426 (* 1 = 1.18426 loss)
I0524 02:20:38.906198 15289 sgd_solver.cpp:106] Iteration 14124, lr = 0.003
I0524 02:21:10.036895 15289 solver.cpp:237] Iteration 14338, loss = 1.20729
I0524 02:21:10.037070 15289 solver.cpp:253]     Train net output #0: loss = 1.20729 (* 1 = 1.20729 loss)
I0524 02:21:10.037084 15289 sgd_solver.cpp:106] Iteration 14338, lr = 0.003
I0524 02:21:18.910863 15289 solver.cpp:237] Iteration 14552, loss = 1.20384
I0524 02:21:18.910898 15289 solver.cpp:253]     Train net output #0: loss = 1.20384 (* 1 = 1.20384 loss)
I0524 02:21:18.910917 15289 sgd_solver.cpp:106] Iteration 14552, lr = 0.003
I0524 02:21:27.784162 15289 solver.cpp:237] Iteration 14766, loss = 1.23949
I0524 02:21:27.784198 15289 solver.cpp:253]     Train net output #0: loss = 1.23949 (* 1 = 1.23949 loss)
I0524 02:21:27.784214 15289 sgd_solver.cpp:106] Iteration 14766, lr = 0.003
I0524 02:21:36.659363 15289 solver.cpp:237] Iteration 14980, loss = 1.1766
I0524 02:21:36.659402 15289 solver.cpp:253]     Train net output #0: loss = 1.1766 (* 1 = 1.1766 loss)
I0524 02:21:36.659423 15289 sgd_solver.cpp:106] Iteration 14980, lr = 0.003
I0524 02:21:37.198684 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_14994.caffemodel
I0524 02:21:37.332762 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_14994.solverstate
I0524 02:21:45.688161 15289 solver.cpp:237] Iteration 15194, loss = 0.990251
I0524 02:21:45.688323 15289 solver.cpp:253]     Train net output #0: loss = 0.990251 (* 1 = 0.990251 loss)
I0524 02:21:45.688338 15289 sgd_solver.cpp:106] Iteration 15194, lr = 0.003
I0524 02:21:54.566050 15289 solver.cpp:237] Iteration 15408, loss = 1.19404
I0524 02:21:54.566083 15289 solver.cpp:253]     Train net output #0: loss = 1.19404 (* 1 = 1.19404 loss)
I0524 02:21:54.566100 15289 sgd_solver.cpp:106] Iteration 15408, lr = 0.003
I0524 02:22:03.447115 15289 solver.cpp:237] Iteration 15622, loss = 1.32508
I0524 02:22:03.447160 15289 solver.cpp:253]     Train net output #0: loss = 1.32508 (* 1 = 1.32508 loss)
I0524 02:22:03.447177 15289 sgd_solver.cpp:106] Iteration 15622, lr = 0.003
I0524 02:22:34.607941 15289 solver.cpp:237] Iteration 15836, loss = 1.23896
I0524 02:22:34.608113 15289 solver.cpp:253]     Train net output #0: loss = 1.23896 (* 1 = 1.23896 loss)
I0524 02:22:34.608126 15289 sgd_solver.cpp:106] Iteration 15836, lr = 0.003
I0524 02:22:43.480581 15289 solver.cpp:237] Iteration 16050, loss = 1.2835
I0524 02:22:43.480614 15289 solver.cpp:253]     Train net output #0: loss = 1.2835 (* 1 = 1.2835 loss)
I0524 02:22:43.480633 15289 sgd_solver.cpp:106] Iteration 16050, lr = 0.003
I0524 02:22:52.358690 15289 solver.cpp:237] Iteration 16264, loss = 1.12808
I0524 02:22:52.358734 15289 solver.cpp:253]     Train net output #0: loss = 1.12808 (* 1 = 1.12808 loss)
I0524 02:22:52.358755 15289 sgd_solver.cpp:106] Iteration 16264, lr = 0.003
I0524 02:23:01.232523 15289 solver.cpp:237] Iteration 16478, loss = 1.22874
I0524 02:23:01.232559 15289 solver.cpp:253]     Train net output #0: loss = 1.22874 (* 1 = 1.22874 loss)
I0524 02:23:01.232575 15289 sgd_solver.cpp:106] Iteration 16478, lr = 0.003
I0524 02:23:10.106783 15289 solver.cpp:237] Iteration 16692, loss = 1.18043
I0524 02:23:10.106940 15289 solver.cpp:253]     Train net output #0: loss = 1.18043 (* 1 = 1.18043 loss)
I0524 02:23:10.106955 15289 sgd_solver.cpp:106] Iteration 16692, lr = 0.003
I0524 02:23:18.983867 15289 solver.cpp:237] Iteration 16906, loss = 1.53137
I0524 02:23:18.983906 15289 solver.cpp:253]     Train net output #0: loss = 1.53137 (* 1 = 1.53137 loss)
I0524 02:23:18.983928 15289 sgd_solver.cpp:106] Iteration 16906, lr = 0.003
I0524 02:23:27.860514 15289 solver.cpp:237] Iteration 17120, loss = 1.39238
I0524 02:23:27.860549 15289 solver.cpp:253]     Train net output #0: loss = 1.39238 (* 1 = 1.39238 loss)
I0524 02:23:27.860565 15289 sgd_solver.cpp:106] Iteration 17120, lr = 0.003
I0524 02:23:28.483503 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_17136.caffemodel
I0524 02:23:29.146800 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_17136.solverstate
I0524 02:23:29.356060 15289 solver.cpp:341] Iteration 17140, Testing net (#0)
I0524 02:24:38.255642 15289 solver.cpp:409]     Test net output #0: accuracy = 0.860111
I0524 02:24:38.255812 15289 solver.cpp:409]     Test net output #1: loss = 0.443847 (* 1 = 0.443847 loss)
I0524 02:25:08.555675 15289 solver.cpp:237] Iteration 17334, loss = 1.3747
I0524 02:25:08.555837 15289 solver.cpp:253]     Train net output #0: loss = 1.3747 (* 1 = 1.3747 loss)
I0524 02:25:08.555853 15289 sgd_solver.cpp:106] Iteration 17334, lr = 0.003
I0524 02:25:17.437947 15289 solver.cpp:237] Iteration 17548, loss = 1.20834
I0524 02:25:17.437983 15289 solver.cpp:253]     Train net output #0: loss = 1.20834 (* 1 = 1.20834 loss)
I0524 02:25:17.437999 15289 sgd_solver.cpp:106] Iteration 17548, lr = 0.003
I0524 02:25:26.312515 15289 solver.cpp:237] Iteration 17762, loss = 1.16989
I0524 02:25:26.312563 15289 solver.cpp:253]     Train net output #0: loss = 1.16989 (* 1 = 1.16989 loss)
I0524 02:25:26.312577 15289 sgd_solver.cpp:106] Iteration 17762, lr = 0.003
I0524 02:25:35.185153 15289 solver.cpp:237] Iteration 17976, loss = 1.32799
I0524 02:25:35.185189 15289 solver.cpp:253]     Train net output #0: loss = 1.32799 (* 1 = 1.32799 loss)
I0524 02:25:35.185205 15289 sgd_solver.cpp:106] Iteration 17976, lr = 0.003
I0524 02:25:44.057307 15289 solver.cpp:237] Iteration 18190, loss = 1.29594
I0524 02:25:44.057452 15289 solver.cpp:253]     Train net output #0: loss = 1.29594 (* 1 = 1.29594 loss)
I0524 02:25:44.057466 15289 sgd_solver.cpp:106] Iteration 18190, lr = 0.003
I0524 02:25:52.929644 15289 solver.cpp:237] Iteration 18404, loss = 1.16171
I0524 02:25:52.929680 15289 solver.cpp:253]     Train net output #0: loss = 1.16171 (* 1 = 1.16171 loss)
I0524 02:25:52.929702 15289 sgd_solver.cpp:106] Iteration 18404, lr = 0.003
I0524 02:26:26.230813 15289 solver.cpp:237] Iteration 18618, loss = 1.1755
I0524 02:26:26.230983 15289 solver.cpp:253]     Train net output #0: loss = 1.1755 (* 1 = 1.1755 loss)
I0524 02:26:26.230999 15289 sgd_solver.cpp:106] Iteration 18618, lr = 0.003
I0524 02:26:35.110409 15289 solver.cpp:237] Iteration 18832, loss = 1.0742
I0524 02:26:35.110455 15289 solver.cpp:253]     Train net output #0: loss = 1.0742 (* 1 = 1.0742 loss)
I0524 02:26:35.110473 15289 sgd_solver.cpp:106] Iteration 18832, lr = 0.003
I0524 02:26:43.987989 15289 solver.cpp:237] Iteration 19046, loss = 0.986542
I0524 02:26:43.988025 15289 solver.cpp:253]     Train net output #0: loss = 0.986542 (* 1 = 0.986542 loss)
I0524 02:26:43.988041 15289 sgd_solver.cpp:106] Iteration 19046, lr = 0.003
I0524 02:26:52.866392 15289 solver.cpp:237] Iteration 19260, loss = 1.24464
I0524 02:26:52.866427 15289 solver.cpp:253]     Train net output #0: loss = 1.24464 (* 1 = 1.24464 loss)
I0524 02:26:52.866444 15289 sgd_solver.cpp:106] Iteration 19260, lr = 0.003
I0524 02:26:53.572480 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_19278.caffemodel
I0524 02:26:53.724546 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_19278.solverstate
I0524 02:27:01.900977 15289 solver.cpp:237] Iteration 19474, loss = 1.29505
I0524 02:27:01.901140 15289 solver.cpp:253]     Train net output #0: loss = 1.29505 (* 1 = 1.29505 loss)
I0524 02:27:01.901154 15289 sgd_solver.cpp:106] Iteration 19474, lr = 0.003
I0524 02:27:10.782620 15289 solver.cpp:237] Iteration 19688, loss = 1.0021
I0524 02:27:10.782655 15289 solver.cpp:253]     Train net output #0: loss = 1.0021 (* 1 = 1.0021 loss)
I0524 02:27:10.782672 15289 sgd_solver.cpp:106] Iteration 19688, lr = 0.003
I0524 02:27:19.666092 15289 solver.cpp:237] Iteration 19902, loss = 1.0062
I0524 02:27:19.666127 15289 solver.cpp:253]     Train net output #0: loss = 1.0062 (* 1 = 1.0062 loss)
I0524 02:27:19.666143 15289 sgd_solver.cpp:106] Iteration 19902, lr = 0.003
I0524 02:27:51.040350 15289 solver.cpp:237] Iteration 20116, loss = 1.10182
I0524 02:27:51.040524 15289 solver.cpp:253]     Train net output #0: loss = 1.10182 (* 1 = 1.10182 loss)
I0524 02:27:51.040539 15289 sgd_solver.cpp:106] Iteration 20116, lr = 0.003
I0524 02:27:59.917953 15289 solver.cpp:237] Iteration 20330, loss = 1.39002
I0524 02:27:59.917987 15289 solver.cpp:253]     Train net output #0: loss = 1.39002 (* 1 = 1.39002 loss)
I0524 02:27:59.918004 15289 sgd_solver.cpp:106] Iteration 20330, lr = 0.003
I0524 02:28:08.795083 15289 solver.cpp:237] Iteration 20544, loss = 1.25375
I0524 02:28:08.795117 15289 solver.cpp:253]     Train net output #0: loss = 1.25375 (* 1 = 1.25375 loss)
I0524 02:28:08.795133 15289 sgd_solver.cpp:106] Iteration 20544, lr = 0.003
I0524 02:28:17.683198 15289 solver.cpp:237] Iteration 20758, loss = 1.48967
I0524 02:28:17.683244 15289 solver.cpp:253]     Train net output #0: loss = 1.48967 (* 1 = 1.48967 loss)
I0524 02:28:17.683262 15289 sgd_solver.cpp:106] Iteration 20758, lr = 0.003
I0524 02:28:26.556255 15289 solver.cpp:237] Iteration 20972, loss = 1.26845
I0524 02:28:26.556402 15289 solver.cpp:253]     Train net output #0: loss = 1.26845 (* 1 = 1.26845 loss)
I0524 02:28:26.556416 15289 sgd_solver.cpp:106] Iteration 20972, lr = 0.003
I0524 02:28:35.435319 15289 solver.cpp:237] Iteration 21186, loss = 1.1756
I0524 02:28:35.435353 15289 solver.cpp:253]     Train net output #0: loss = 1.1756 (* 1 = 1.1756 loss)
I0524 02:28:35.435370 15289 sgd_solver.cpp:106] Iteration 21186, lr = 0.003
I0524 02:28:44.315069 15289 solver.cpp:237] Iteration 21400, loss = 1.19438
I0524 02:28:44.315109 15289 solver.cpp:253]     Train net output #0: loss = 1.19438 (* 1 = 1.19438 loss)
I0524 02:28:44.315129 15289 sgd_solver.cpp:106] Iteration 21400, lr = 0.003
I0524 02:28:45.104187 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_21420.caffemodel
I0524 02:28:45.207449 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_21420.solverstate
I0524 02:28:45.445904 15289 solver.cpp:341] Iteration 21425, Testing net (#0)
I0524 02:29:35.252815 15289 solver.cpp:409]     Test net output #0: accuracy = 0.867654
I0524 02:29:35.252984 15289 solver.cpp:409]     Test net output #1: loss = 0.437384 (* 1 = 0.437384 loss)
I0524 02:30:05.214308 15289 solver.cpp:237] Iteration 21614, loss = 1.37685
I0524 02:30:05.214359 15289 solver.cpp:253]     Train net output #0: loss = 1.37685 (* 1 = 1.37685 loss)
I0524 02:30:05.214372 15289 sgd_solver.cpp:106] Iteration 21614, lr = 0.003
I0524 02:30:14.093931 15289 solver.cpp:237] Iteration 21828, loss = 1.37522
I0524 02:30:14.094086 15289 solver.cpp:253]     Train net output #0: loss = 1.37522 (* 1 = 1.37522 loss)
I0524 02:30:14.094100 15289 sgd_solver.cpp:106] Iteration 21828, lr = 0.003
I0524 02:30:22.968619 15289 solver.cpp:237] Iteration 22042, loss = 1.27806
I0524 02:30:22.968660 15289 solver.cpp:253]     Train net output #0: loss = 1.27806 (* 1 = 1.27806 loss)
I0524 02:30:22.968678 15289 sgd_solver.cpp:106] Iteration 22042, lr = 0.003
I0524 02:30:31.851892 15289 solver.cpp:237] Iteration 22256, loss = 1.0772
I0524 02:30:31.851927 15289 solver.cpp:253]     Train net output #0: loss = 1.0772 (* 1 = 1.0772 loss)
I0524 02:30:31.851944 15289 sgd_solver.cpp:106] Iteration 22256, lr = 0.003
I0524 02:30:40.734207 15289 solver.cpp:237] Iteration 22470, loss = 1.11099
I0524 02:30:40.734243 15289 solver.cpp:253]     Train net output #0: loss = 1.11099 (* 1 = 1.11099 loss)
I0524 02:30:40.734259 15289 sgd_solver.cpp:106] Iteration 22470, lr = 0.003
I0524 02:30:49.619369 15289 solver.cpp:237] Iteration 22684, loss = 1.35938
I0524 02:30:49.619542 15289 solver.cpp:253]     Train net output #0: loss = 1.35938 (* 1 = 1.35938 loss)
I0524 02:30:49.619557 15289 sgd_solver.cpp:106] Iteration 22684, lr = 0.003
I0524 02:31:19.375478 15289 solver.cpp:237] Iteration 22898, loss = 1.0778
I0524 02:31:19.375529 15289 solver.cpp:253]     Train net output #0: loss = 1.0778 (* 1 = 1.0778 loss)
I0524 02:31:19.375545 15289 sgd_solver.cpp:106] Iteration 22898, lr = 0.003
I0524 02:31:28.260144 15289 solver.cpp:237] Iteration 23112, loss = 1.0982
I0524 02:31:28.260295 15289 solver.cpp:253]     Train net output #0: loss = 1.0982 (* 1 = 1.0982 loss)
I0524 02:31:28.260308 15289 sgd_solver.cpp:106] Iteration 23112, lr = 0.003
I0524 02:31:37.143079 15289 solver.cpp:237] Iteration 23326, loss = 1.02131
I0524 02:31:37.143126 15289 solver.cpp:253]     Train net output #0: loss = 1.02131 (* 1 = 1.02131 loss)
I0524 02:31:37.143142 15289 sgd_solver.cpp:106] Iteration 23326, lr = 0.003
I0524 02:31:46.021826 15289 solver.cpp:237] Iteration 23540, loss = 1.22101
I0524 02:31:46.021862 15289 solver.cpp:253]     Train net output #0: loss = 1.22101 (* 1 = 1.22101 loss)
I0524 02:31:46.021875 15289 sgd_solver.cpp:106] Iteration 23540, lr = 0.003
I0524 02:31:46.892937 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_23562.caffemodel
I0524 02:31:46.985165 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_23562.solverstate
I0524 02:31:55.012322 15289 solver.cpp:237] Iteration 23754, loss = 1.16983
I0524 02:31:55.012372 15289 solver.cpp:253]     Train net output #0: loss = 1.16983 (* 1 = 1.16983 loss)
I0524 02:31:55.012385 15289 sgd_solver.cpp:106] Iteration 23754, lr = 0.003
I0524 02:32:03.891774 15289 solver.cpp:237] Iteration 23968, loss = 1.20082
I0524 02:32:03.891938 15289 solver.cpp:253]     Train net output #0: loss = 1.20082 (* 1 = 1.20082 loss)
I0524 02:32:03.891952 15289 sgd_solver.cpp:106] Iteration 23968, lr = 0.003
I0524 02:32:12.768821 15289 solver.cpp:237] Iteration 24182, loss = 1.48708
I0524 02:32:12.768867 15289 solver.cpp:253]     Train net output #0: loss = 1.48708 (* 1 = 1.48708 loss)
I0524 02:32:12.768879 15289 sgd_solver.cpp:106] Iteration 24182, lr = 0.003
I0524 02:32:42.633287 15289 solver.cpp:237] Iteration 24396, loss = 1.16768
I0524 02:32:42.633455 15289 solver.cpp:253]     Train net output #0: loss = 1.16768 (* 1 = 1.16768 loss)
I0524 02:32:42.633469 15289 sgd_solver.cpp:106] Iteration 24396, lr = 0.003
I0524 02:32:51.508713 15289 solver.cpp:237] Iteration 24610, loss = 1.12814
I0524 02:32:51.508760 15289 solver.cpp:253]     Train net output #0: loss = 1.12814 (* 1 = 1.12814 loss)
I0524 02:32:51.508777 15289 sgd_solver.cpp:106] Iteration 24610, lr = 0.003
I0524 02:33:00.387795 15289 solver.cpp:237] Iteration 24824, loss = 1.09544
I0524 02:33:00.387831 15289 solver.cpp:253]     Train net output #0: loss = 1.09544 (* 1 = 1.09544 loss)
I0524 02:33:00.387846 15289 sgd_solver.cpp:106] Iteration 24824, lr = 0.003
I0524 02:33:09.261863 15289 solver.cpp:237] Iteration 25038, loss = 1.10595
I0524 02:33:09.261898 15289 solver.cpp:253]     Train net output #0: loss = 1.10595 (* 1 = 1.10595 loss)
I0524 02:33:09.261914 15289 sgd_solver.cpp:106] Iteration 25038, lr = 0.003
I0524 02:33:18.143785 15289 solver.cpp:237] Iteration 25252, loss = 1.19052
I0524 02:33:18.143945 15289 solver.cpp:253]     Train net output #0: loss = 1.19052 (* 1 = 1.19052 loss)
I0524 02:33:18.143959 15289 sgd_solver.cpp:106] Iteration 25252, lr = 0.003
I0524 02:33:27.026052 15289 solver.cpp:237] Iteration 25466, loss = 1.23677
I0524 02:33:27.026087 15289 solver.cpp:253]     Train net output #0: loss = 1.23677 (* 1 = 1.23677 loss)
I0524 02:33:27.026104 15289 sgd_solver.cpp:106] Iteration 25466, lr = 0.003
I0524 02:33:35.909366 15289 solver.cpp:237] Iteration 25680, loss = 1.41234
I0524 02:33:35.909401 15289 solver.cpp:253]     Train net output #0: loss = 1.41234 (* 1 = 1.41234 loss)
I0524 02:33:35.909417 15289 sgd_solver.cpp:106] Iteration 25680, lr = 0.003
I0524 02:33:36.863965 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_25704.caffemodel
I0524 02:33:36.929738 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_25704.solverstate
I0524 02:33:37.178339 15289 solver.cpp:341] Iteration 25710, Testing net (#0)
I0524 02:34:45.955265 15289 solver.cpp:409]     Test net output #0: accuracy = 0.865326
I0524 02:34:45.955446 15289 solver.cpp:409]     Test net output #1: loss = 0.414729 (* 1 = 0.414729 loss)
I0524 02:35:14.458554 15289 solver.cpp:237] Iteration 25894, loss = 1.18496
I0524 02:35:14.458606 15289 solver.cpp:253]     Train net output #0: loss = 1.18496 (* 1 = 1.18496 loss)
I0524 02:35:14.458619 15289 sgd_solver.cpp:106] Iteration 25894, lr = 0.003
I0524 02:35:23.321540 15289 solver.cpp:237] Iteration 26108, loss = 1.38454
I0524 02:35:23.321698 15289 solver.cpp:253]     Train net output #0: loss = 1.38454 (* 1 = 1.38454 loss)
I0524 02:35:23.321712 15289 sgd_solver.cpp:106] Iteration 26108, lr = 0.003
I0524 02:35:32.177920 15289 solver.cpp:237] Iteration 26322, loss = 1.24744
I0524 02:35:32.177955 15289 solver.cpp:253]     Train net output #0: loss = 1.24744 (* 1 = 1.24744 loss)
I0524 02:35:32.177971 15289 sgd_solver.cpp:106] Iteration 26322, lr = 0.003
I0524 02:35:41.045326 15289 solver.cpp:237] Iteration 26536, loss = 1.33317
I0524 02:35:41.045361 15289 solver.cpp:253]     Train net output #0: loss = 1.33317 (* 1 = 1.33317 loss)
I0524 02:35:41.045374 15289 sgd_solver.cpp:106] Iteration 26536, lr = 0.003
I0524 02:35:49.908548 15289 solver.cpp:237] Iteration 26750, loss = 1.27267
I0524 02:35:49.908583 15289 solver.cpp:253]     Train net output #0: loss = 1.27267 (* 1 = 1.27267 loss)
I0524 02:35:49.908602 15289 sgd_solver.cpp:106] Iteration 26750, lr = 0.003
I0524 02:35:58.779188 15289 solver.cpp:237] Iteration 26964, loss = 1.28692
I0524 02:35:58.779331 15289 solver.cpp:253]     Train net output #0: loss = 1.28692 (* 1 = 1.28692 loss)
I0524 02:35:58.779345 15289 sgd_solver.cpp:106] Iteration 26964, lr = 0.003
I0524 02:36:28.525933 15289 solver.cpp:237] Iteration 27178, loss = 1.20933
I0524 02:36:28.525985 15289 solver.cpp:253]     Train net output #0: loss = 1.20933 (* 1 = 1.20933 loss)
I0524 02:36:28.526001 15289 sgd_solver.cpp:106] Iteration 27178, lr = 0.003
I0524 02:36:37.389756 15289 solver.cpp:237] Iteration 27392, loss = 1.2222
I0524 02:36:37.389926 15289 solver.cpp:253]     Train net output #0: loss = 1.2222 (* 1 = 1.2222 loss)
I0524 02:36:37.389940 15289 sgd_solver.cpp:106] Iteration 27392, lr = 0.003
I0524 02:36:46.257599 15289 solver.cpp:237] Iteration 27606, loss = 1.07457
I0524 02:36:46.257634 15289 solver.cpp:253]     Train net output #0: loss = 1.07457 (* 1 = 1.07457 loss)
I0524 02:36:46.257649 15289 sgd_solver.cpp:106] Iteration 27606, lr = 0.003
I0524 02:36:55.126209 15289 solver.cpp:237] Iteration 27820, loss = 1.06738
I0524 02:36:55.126245 15289 solver.cpp:253]     Train net output #0: loss = 1.06738 (* 1 = 1.06738 loss)
I0524 02:36:55.126260 15289 sgd_solver.cpp:106] Iteration 27820, lr = 0.003
I0524 02:36:56.163363 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_27846.caffemodel
I0524 02:36:56.229459 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_27846.solverstate
I0524 02:37:04.058348 15289 solver.cpp:237] Iteration 28034, loss = 1.22048
I0524 02:37:04.058393 15289 solver.cpp:253]     Train net output #0: loss = 1.22048 (* 1 = 1.22048 loss)
I0524 02:37:04.058413 15289 sgd_solver.cpp:106] Iteration 28034, lr = 0.003
I0524 02:37:12.924813 15289 solver.cpp:237] Iteration 28248, loss = 1.10399
I0524 02:37:12.924981 15289 solver.cpp:253]     Train net output #0: loss = 1.10399 (* 1 = 1.10399 loss)
I0524 02:37:12.924994 15289 sgd_solver.cpp:106] Iteration 28248, lr = 0.003
I0524 02:37:21.790555 15289 solver.cpp:237] Iteration 28462, loss = 1.3584
I0524 02:37:21.790588 15289 solver.cpp:253]     Train net output #0: loss = 1.3584 (* 1 = 1.3584 loss)
I0524 02:37:21.790606 15289 sgd_solver.cpp:106] Iteration 28462, lr = 0.003
I0524 02:37:51.524194 15289 solver.cpp:237] Iteration 28676, loss = 1.01674
I0524 02:37:51.524369 15289 solver.cpp:253]     Train net output #0: loss = 1.01674 (* 1 = 1.01674 loss)
I0524 02:37:51.524384 15289 sgd_solver.cpp:106] Iteration 28676, lr = 0.003
I0524 02:38:00.392374 15289 solver.cpp:237] Iteration 28890, loss = 1.17084
I0524 02:38:00.392408 15289 solver.cpp:253]     Train net output #0: loss = 1.17084 (* 1 = 1.17084 loss)
I0524 02:38:00.392426 15289 sgd_solver.cpp:106] Iteration 28890, lr = 0.003
I0524 02:38:09.257794 15289 solver.cpp:237] Iteration 29104, loss = 1.2469
I0524 02:38:09.257830 15289 solver.cpp:253]     Train net output #0: loss = 1.2469 (* 1 = 1.2469 loss)
I0524 02:38:09.257843 15289 sgd_solver.cpp:106] Iteration 29104, lr = 0.003
I0524 02:38:18.125581 15289 solver.cpp:237] Iteration 29318, loss = 1.40704
I0524 02:38:18.125627 15289 solver.cpp:253]     Train net output #0: loss = 1.40704 (* 1 = 1.40704 loss)
I0524 02:38:18.125643 15289 sgd_solver.cpp:106] Iteration 29318, lr = 0.003
I0524 02:38:26.991405 15289 solver.cpp:237] Iteration 29532, loss = 1.20701
I0524 02:38:26.991564 15289 solver.cpp:253]     Train net output #0: loss = 1.20701 (* 1 = 1.20701 loss)
I0524 02:38:26.991577 15289 sgd_solver.cpp:106] Iteration 29532, lr = 0.003
I0524 02:38:35.861660 15289 solver.cpp:237] Iteration 29746, loss = 1.12154
I0524 02:38:35.861693 15289 solver.cpp:253]     Train net output #0: loss = 1.12154 (* 1 = 1.12154 loss)
I0524 02:38:35.861711 15289 sgd_solver.cpp:106] Iteration 29746, lr = 0.003
I0524 02:38:44.731166 15289 solver.cpp:237] Iteration 29960, loss = 1.09016
I0524 02:38:44.731209 15289 solver.cpp:253]     Train net output #0: loss = 1.09016 (* 1 = 1.09016 loss)
I0524 02:38:44.731225 15289 sgd_solver.cpp:106] Iteration 29960, lr = 0.003
I0524 02:38:45.852232 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_29988.caffemodel
I0524 02:38:45.918577 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_29988.solverstate
I0524 02:38:46.206863 15289 solver.cpp:341] Iteration 29995, Testing net (#0)
I0524 02:39:33.790988 15289 solver.cpp:409]     Test net output #0: accuracy = 0.872589
I0524 02:39:33.791154 15289 solver.cpp:409]     Test net output #1: loss = 0.407203 (* 1 = 0.407203 loss)
I0524 02:40:02.134954 15289 solver.cpp:237] Iteration 30174, loss = 1.12961
I0524 02:40:02.135004 15289 solver.cpp:253]     Train net output #0: loss = 1.12961 (* 1 = 1.12961 loss)
I0524 02:40:02.135021 15289 sgd_solver.cpp:106] Iteration 30174, lr = 0.003
I0524 02:40:11.022568 15289 solver.cpp:237] Iteration 30388, loss = 1.09755
I0524 02:40:11.022737 15289 solver.cpp:253]     Train net output #0: loss = 1.09755 (* 1 = 1.09755 loss)
I0524 02:40:11.022752 15289 sgd_solver.cpp:106] Iteration 30388, lr = 0.003
I0524 02:40:19.907572 15289 solver.cpp:237] Iteration 30602, loss = 1.23537
I0524 02:40:19.907620 15289 solver.cpp:253]     Train net output #0: loss = 1.23537 (* 1 = 1.23537 loss)
I0524 02:40:19.907637 15289 sgd_solver.cpp:106] Iteration 30602, lr = 0.003
I0524 02:40:28.793673 15289 solver.cpp:237] Iteration 30816, loss = 1.10941
I0524 02:40:28.793709 15289 solver.cpp:253]     Train net output #0: loss = 1.10941 (* 1 = 1.10941 loss)
I0524 02:40:28.793726 15289 sgd_solver.cpp:106] Iteration 30816, lr = 0.003
I0524 02:40:37.685405 15289 solver.cpp:237] Iteration 31030, loss = 1.35723
I0524 02:40:37.685439 15289 solver.cpp:253]     Train net output #0: loss = 1.35723 (* 1 = 1.35723 loss)
I0524 02:40:37.685453 15289 sgd_solver.cpp:106] Iteration 31030, lr = 0.003
I0524 02:40:46.577571 15289 solver.cpp:237] Iteration 31244, loss = 1.05307
I0524 02:40:46.577742 15289 solver.cpp:253]     Train net output #0: loss = 1.05307 (* 1 = 1.05307 loss)
I0524 02:40:46.577756 15289 sgd_solver.cpp:106] Iteration 31244, lr = 0.003
I0524 02:41:16.399741 15289 solver.cpp:237] Iteration 31458, loss = 1.14371
I0524 02:41:16.399790 15289 solver.cpp:253]     Train net output #0: loss = 1.14371 (* 1 = 1.14371 loss)
I0524 02:41:16.399807 15289 sgd_solver.cpp:106] Iteration 31458, lr = 0.003
I0524 02:41:25.291196 15289 solver.cpp:237] Iteration 31672, loss = 1.02979
I0524 02:41:25.291359 15289 solver.cpp:253]     Train net output #0: loss = 1.02979 (* 1 = 1.02979 loss)
I0524 02:41:25.291373 15289 sgd_solver.cpp:106] Iteration 31672, lr = 0.003
I0524 02:41:34.176007 15289 solver.cpp:237] Iteration 31886, loss = 1.19466
I0524 02:41:34.176040 15289 solver.cpp:253]     Train net output #0: loss = 1.19466 (* 1 = 1.19466 loss)
I0524 02:41:34.176056 15289 sgd_solver.cpp:106] Iteration 31886, lr = 0.003
I0524 02:41:43.061904 15289 solver.cpp:237] Iteration 32100, loss = 1.08581
I0524 02:41:43.061946 15289 solver.cpp:253]     Train net output #0: loss = 1.08581 (* 1 = 1.08581 loss)
I0524 02:41:43.061961 15289 sgd_solver.cpp:106] Iteration 32100, lr = 0.003
I0524 02:41:44.265226 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_32130.caffemodel
I0524 02:41:44.334403 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_32130.solverstate
I0524 02:41:52.015643 15289 solver.cpp:237] Iteration 32314, loss = 1.42115
I0524 02:41:52.015694 15289 solver.cpp:253]     Train net output #0: loss = 1.42115 (* 1 = 1.42115 loss)
I0524 02:41:52.015708 15289 sgd_solver.cpp:106] Iteration 32314, lr = 0.003
I0524 02:42:00.904801 15289 solver.cpp:237] Iteration 32528, loss = 1.10906
I0524 02:42:00.904978 15289 solver.cpp:253]     Train net output #0: loss = 1.10906 (* 1 = 1.10906 loss)
I0524 02:42:00.904992 15289 sgd_solver.cpp:106] Iteration 32528, lr = 0.003
I0524 02:42:09.790954 15289 solver.cpp:237] Iteration 32742, loss = 0.905805
I0524 02:42:09.790989 15289 solver.cpp:253]     Train net output #0: loss = 0.905805 (* 1 = 0.905805 loss)
I0524 02:42:09.791008 15289 sgd_solver.cpp:106] Iteration 32742, lr = 0.003
I0524 02:42:39.647162 15289 solver.cpp:237] Iteration 32956, loss = 1.09675
I0524 02:42:39.647333 15289 solver.cpp:253]     Train net output #0: loss = 1.09675 (* 1 = 1.09675 loss)
I0524 02:42:39.647347 15289 sgd_solver.cpp:106] Iteration 32956, lr = 0.003
I0524 02:42:48.532994 15289 solver.cpp:237] Iteration 33170, loss = 1.19754
I0524 02:42:48.533028 15289 solver.cpp:253]     Train net output #0: loss = 1.19754 (* 1 = 1.19754 loss)
I0524 02:42:48.533046 15289 sgd_solver.cpp:106] Iteration 33170, lr = 0.003
I0524 02:42:57.421142 15289 solver.cpp:237] Iteration 33384, loss = 1.28894
I0524 02:42:57.421180 15289 solver.cpp:253]     Train net output #0: loss = 1.28894 (* 1 = 1.28894 loss)
I0524 02:42:57.421200 15289 sgd_solver.cpp:106] Iteration 33384, lr = 0.003
I0524 02:43:06.301175 15289 solver.cpp:237] Iteration 33598, loss = 1.10072
I0524 02:43:06.301205 15289 solver.cpp:253]     Train net output #0: loss = 1.10072 (* 1 = 1.10072 loss)
I0524 02:43:06.301218 15289 sgd_solver.cpp:106] Iteration 33598, lr = 0.003
I0524 02:43:15.194686 15289 solver.cpp:237] Iteration 33812, loss = 1.39852
I0524 02:43:15.194851 15289 solver.cpp:253]     Train net output #0: loss = 1.39852 (* 1 = 1.39852 loss)
I0524 02:43:15.194866 15289 sgd_solver.cpp:106] Iteration 33812, lr = 0.003
I0524 02:43:24.075227 15289 solver.cpp:237] Iteration 34026, loss = 1.26143
I0524 02:43:24.075261 15289 solver.cpp:253]     Train net output #0: loss = 1.26143 (* 1 = 1.26143 loss)
I0524 02:43:24.075278 15289 sgd_solver.cpp:106] Iteration 34026, lr = 0.003
I0524 02:43:32.959314 15289 solver.cpp:237] Iteration 34240, loss = 1.26504
I0524 02:43:32.959349 15289 solver.cpp:253]     Train net output #0: loss = 1.26504 (* 1 = 1.26504 loss)
I0524 02:43:32.959365 15289 sgd_solver.cpp:106] Iteration 34240, lr = 0.003
I0524 02:43:34.245885 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_34272.caffemodel
I0524 02:43:34.318552 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_34272.solverstate
I0524 02:43:34.650014 15289 solver.cpp:341] Iteration 34280, Testing net (#0)
I0524 02:44:43.511718 15289 solver.cpp:409]     Test net output #0: accuracy = 0.879145
I0524 02:44:43.511898 15289 solver.cpp:409]     Test net output #1: loss = 0.399698 (* 1 = 0.399698 loss)
I0524 02:45:11.627624 15289 solver.cpp:237] Iteration 34454, loss = 1.23109
I0524 02:45:11.627674 15289 solver.cpp:253]     Train net output #0: loss = 1.23109 (* 1 = 1.23109 loss)
I0524 02:45:11.627691 15289 sgd_solver.cpp:106] Iteration 34454, lr = 0.003
I0524 02:45:20.492463 15289 solver.cpp:237] Iteration 34668, loss = 1.07656
I0524 02:45:20.492633 15289 solver.cpp:253]     Train net output #0: loss = 1.07656 (* 1 = 1.07656 loss)
I0524 02:45:20.492647 15289 sgd_solver.cpp:106] Iteration 34668, lr = 0.003
I0524 02:45:29.360002 15289 solver.cpp:237] Iteration 34882, loss = 1.11901
I0524 02:45:29.360035 15289 solver.cpp:253]     Train net output #0: loss = 1.11901 (* 1 = 1.11901 loss)
I0524 02:45:29.360052 15289 sgd_solver.cpp:106] Iteration 34882, lr = 0.003
I0524 02:45:38.230103 15289 solver.cpp:237] Iteration 35096, loss = 1.32771
I0524 02:45:38.230139 15289 solver.cpp:253]     Train net output #0: loss = 1.32771 (* 1 = 1.32771 loss)
I0524 02:45:38.230154 15289 sgd_solver.cpp:106] Iteration 35096, lr = 0.003
I0524 02:45:47.095175 15289 solver.cpp:237] Iteration 35310, loss = 1.39149
I0524 02:45:47.095214 15289 solver.cpp:253]     Train net output #0: loss = 1.39149 (* 1 = 1.39149 loss)
I0524 02:45:47.095234 15289 sgd_solver.cpp:106] Iteration 35310, lr = 0.003
I0524 02:45:55.959213 15289 solver.cpp:237] Iteration 35524, loss = 1.26884
I0524 02:45:55.959364 15289 solver.cpp:253]     Train net output #0: loss = 1.26884 (* 1 = 1.26884 loss)
I0524 02:45:55.959378 15289 sgd_solver.cpp:106] Iteration 35524, lr = 0.003
I0524 02:46:25.768136 15289 solver.cpp:237] Iteration 35738, loss = 1.06167
I0524 02:46:25.768187 15289 solver.cpp:253]     Train net output #0: loss = 1.06167 (* 1 = 1.06167 loss)
I0524 02:46:25.768199 15289 sgd_solver.cpp:106] Iteration 35738, lr = 0.003
I0524 02:46:34.635015 15289 solver.cpp:237] Iteration 35952, loss = 1.15128
I0524 02:46:34.635184 15289 solver.cpp:253]     Train net output #0: loss = 1.15128 (* 1 = 1.15128 loss)
I0524 02:46:34.635197 15289 sgd_solver.cpp:106] Iteration 35952, lr = 0.003
I0524 02:46:43.496685 15289 solver.cpp:237] Iteration 36166, loss = 1.13648
I0524 02:46:43.496719 15289 solver.cpp:253]     Train net output #0: loss = 1.13648 (* 1 = 1.13648 loss)
I0524 02:46:43.496738 15289 sgd_solver.cpp:106] Iteration 36166, lr = 0.003
I0524 02:46:52.360977 15289 solver.cpp:237] Iteration 36380, loss = 0.929717
I0524 02:46:52.361014 15289 solver.cpp:253]     Train net output #0: loss = 0.929717 (* 1 = 0.929717 loss)
I0524 02:46:52.361030 15289 sgd_solver.cpp:106] Iteration 36380, lr = 0.003
I0524 02:46:53.727896 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_36414.caffemodel
I0524 02:46:53.794644 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_36414.solverstate
I0524 02:47:01.286195 15289 solver.cpp:237] Iteration 36594, loss = 1.24733
I0524 02:47:01.286244 15289 solver.cpp:253]     Train net output #0: loss = 1.24733 (* 1 = 1.24733 loss)
I0524 02:47:01.286262 15289 sgd_solver.cpp:106] Iteration 36594, lr = 0.003
I0524 02:47:10.150924 15289 solver.cpp:237] Iteration 36808, loss = 1.16484
I0524 02:47:10.151090 15289 solver.cpp:253]     Train net output #0: loss = 1.16484 (* 1 = 1.16484 loss)
I0524 02:47:10.151104 15289 sgd_solver.cpp:106] Iteration 36808, lr = 0.003
I0524 02:47:19.017700 15289 solver.cpp:237] Iteration 37022, loss = 1.08372
I0524 02:47:19.017735 15289 solver.cpp:253]     Train net output #0: loss = 1.08372 (* 1 = 1.08372 loss)
I0524 02:47:19.017752 15289 sgd_solver.cpp:106] Iteration 37022, lr = 0.003
I0524 02:47:48.811368 15289 solver.cpp:237] Iteration 37236, loss = 1.33095
I0524 02:47:48.811547 15289 solver.cpp:253]     Train net output #0: loss = 1.33095 (* 1 = 1.33095 loss)
I0524 02:47:48.811561 15289 sgd_solver.cpp:106] Iteration 37236, lr = 0.003
I0524 02:47:57.677451 15289 solver.cpp:237] Iteration 37450, loss = 1.21254
I0524 02:47:57.677497 15289 solver.cpp:253]     Train net output #0: loss = 1.21254 (* 1 = 1.21254 loss)
I0524 02:47:57.677515 15289 sgd_solver.cpp:106] Iteration 37450, lr = 0.003
I0524 02:48:06.544679 15289 solver.cpp:237] Iteration 37664, loss = 1.24494
I0524 02:48:06.544714 15289 solver.cpp:253]     Train net output #0: loss = 1.24494 (* 1 = 1.24494 loss)
I0524 02:48:06.544733 15289 sgd_solver.cpp:106] Iteration 37664, lr = 0.003
I0524 02:48:15.417172 15289 solver.cpp:237] Iteration 37878, loss = 0.948881
I0524 02:48:15.417222 15289 solver.cpp:253]     Train net output #0: loss = 0.948881 (* 1 = 0.948881 loss)
I0524 02:48:15.417235 15289 sgd_solver.cpp:106] Iteration 37878, lr = 0.003
I0524 02:48:24.285058 15289 solver.cpp:237] Iteration 38092, loss = 1.07744
I0524 02:48:24.285223 15289 solver.cpp:253]     Train net output #0: loss = 1.07744 (* 1 = 1.07744 loss)
I0524 02:48:24.285236 15289 sgd_solver.cpp:106] Iteration 38092, lr = 0.003
I0524 02:48:33.150938 15289 solver.cpp:237] Iteration 38306, loss = 1.0979
I0524 02:48:33.150971 15289 solver.cpp:253]     Train net output #0: loss = 1.0979 (* 1 = 1.0979 loss)
I0524 02:48:33.150987 15289 sgd_solver.cpp:106] Iteration 38306, lr = 0.003
I0524 02:48:42.021512 15289 solver.cpp:237] Iteration 38520, loss = 1.54835
I0524 02:48:42.021553 15289 solver.cpp:253]     Train net output #0: loss = 1.54835 (* 1 = 1.54835 loss)
I0524 02:48:42.021569 15289 sgd_solver.cpp:106] Iteration 38520, lr = 0.003
I0524 02:48:43.473299 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_38556.caffemodel
I0524 02:48:43.541088 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_38556.solverstate
I0524 02:48:43.920485 15289 solver.cpp:341] Iteration 38565, Testing net (#0)
I0524 02:49:31.880728 15289 solver.cpp:409]     Test net output #0: accuracy = 0.882093
I0524 02:49:31.880903 15289 solver.cpp:409]     Test net output #1: loss = 0.373433 (* 1 = 0.373433 loss)
I0524 02:49:59.844053 15289 solver.cpp:237] Iteration 38734, loss = 1.00099
I0524 02:49:59.844101 15289 solver.cpp:253]     Train net output #0: loss = 1.00099 (* 1 = 1.00099 loss)
I0524 02:49:59.844116 15289 sgd_solver.cpp:106] Iteration 38734, lr = 0.003
I0524 02:50:08.738807 15289 solver.cpp:237] Iteration 38948, loss = 1.15481
I0524 02:50:08.738968 15289 solver.cpp:253]     Train net output #0: loss = 1.15481 (* 1 = 1.15481 loss)
I0524 02:50:08.738981 15289 sgd_solver.cpp:106] Iteration 38948, lr = 0.003
I0524 02:50:17.638535 15289 solver.cpp:237] Iteration 39162, loss = 1.35773
I0524 02:50:17.638571 15289 solver.cpp:253]     Train net output #0: loss = 1.35773 (* 1 = 1.35773 loss)
I0524 02:50:17.638587 15289 sgd_solver.cpp:106] Iteration 39162, lr = 0.003
I0524 02:50:26.534232 15289 solver.cpp:237] Iteration 39376, loss = 1.1277
I0524 02:50:26.534276 15289 solver.cpp:253]     Train net output #0: loss = 1.1277 (* 1 = 1.1277 loss)
I0524 02:50:26.534294 15289 sgd_solver.cpp:106] Iteration 39376, lr = 0.003
I0524 02:50:35.434790 15289 solver.cpp:237] Iteration 39590, loss = 1.29528
I0524 02:50:35.434826 15289 solver.cpp:253]     Train net output #0: loss = 1.29528 (* 1 = 1.29528 loss)
I0524 02:50:35.434842 15289 sgd_solver.cpp:106] Iteration 39590, lr = 0.003
I0524 02:50:44.334081 15289 solver.cpp:237] Iteration 39804, loss = 1.29384
I0524 02:50:44.334244 15289 solver.cpp:253]     Train net output #0: loss = 1.29384 (* 1 = 1.29384 loss)
I0524 02:50:44.334257 15289 sgd_solver.cpp:106] Iteration 39804, lr = 0.003
I0524 02:51:14.160346 15289 solver.cpp:237] Iteration 40018, loss = 1.18598
I0524 02:51:14.160394 15289 solver.cpp:253]     Train net output #0: loss = 1.18598 (* 1 = 1.18598 loss)
I0524 02:51:14.160413 15289 sgd_solver.cpp:106] Iteration 40018, lr = 0.003
I0524 02:51:23.061647 15289 solver.cpp:237] Iteration 40232, loss = 1.30622
I0524 02:51:23.061810 15289 solver.cpp:253]     Train net output #0: loss = 1.30622 (* 1 = 1.30622 loss)
I0524 02:51:23.061822 15289 sgd_solver.cpp:106] Iteration 40232, lr = 0.003
I0524 02:51:31.956372 15289 solver.cpp:237] Iteration 40446, loss = 1.1531
I0524 02:51:31.956408 15289 solver.cpp:253]     Train net output #0: loss = 1.1531 (* 1 = 1.1531 loss)
I0524 02:51:31.956423 15289 sgd_solver.cpp:106] Iteration 40446, lr = 0.003
I0524 02:51:40.855597 15289 solver.cpp:237] Iteration 40660, loss = 1.37147
I0524 02:51:40.855636 15289 solver.cpp:253]     Train net output #0: loss = 1.37147 (* 1 = 1.37147 loss)
I0524 02:51:40.855656 15289 sgd_solver.cpp:106] Iteration 40660, lr = 0.003
I0524 02:51:42.395211 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_40698.caffemodel
I0524 02:51:42.464839 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_40698.solverstate
I0524 02:51:49.825865 15289 solver.cpp:237] Iteration 40874, loss = 1.07282
I0524 02:51:49.825911 15289 solver.cpp:253]     Train net output #0: loss = 1.07282 (* 1 = 1.07282 loss)
I0524 02:51:49.825930 15289 sgd_solver.cpp:106] Iteration 40874, lr = 0.003
I0524 02:51:58.718618 15289 solver.cpp:237] Iteration 41088, loss = 1.01741
I0524 02:51:58.718787 15289 solver.cpp:253]     Train net output #0: loss = 1.01741 (* 1 = 1.01741 loss)
I0524 02:51:58.718801 15289 sgd_solver.cpp:106] Iteration 41088, lr = 0.003
I0524 02:52:07.609449 15289 solver.cpp:237] Iteration 41302, loss = 1.18936
I0524 02:52:07.609483 15289 solver.cpp:253]     Train net output #0: loss = 1.18936 (* 1 = 1.18936 loss)
I0524 02:52:07.609504 15289 sgd_solver.cpp:106] Iteration 41302, lr = 0.003
I0524 02:52:37.386152 15289 solver.cpp:237] Iteration 41516, loss = 1.05328
I0524 02:52:37.386330 15289 solver.cpp:253]     Train net output #0: loss = 1.05328 (* 1 = 1.05328 loss)
I0524 02:52:37.386345 15289 sgd_solver.cpp:106] Iteration 41516, lr = 0.003
I0524 02:52:46.278869 15289 solver.cpp:237] Iteration 41730, loss = 1.30922
I0524 02:52:46.278903 15289 solver.cpp:253]     Train net output #0: loss = 1.30922 (* 1 = 1.30922 loss)
I0524 02:52:46.278921 15289 sgd_solver.cpp:106] Iteration 41730, lr = 0.003
I0524 02:52:55.178553 15289 solver.cpp:237] Iteration 41944, loss = 1.25463
I0524 02:52:55.178599 15289 solver.cpp:253]     Train net output #0: loss = 1.25463 (* 1 = 1.25463 loss)
I0524 02:52:55.178613 15289 sgd_solver.cpp:106] Iteration 41944, lr = 0.003
I0524 02:53:04.075254 15289 solver.cpp:237] Iteration 42158, loss = 1.12267
I0524 02:53:04.075289 15289 solver.cpp:253]     Train net output #0: loss = 1.12267 (* 1 = 1.12267 loss)
I0524 02:53:04.075306 15289 sgd_solver.cpp:106] Iteration 42158, lr = 0.003
I0524 02:53:12.972249 15289 solver.cpp:237] Iteration 42372, loss = 1.13745
I0524 02:53:12.972414 15289 solver.cpp:253]     Train net output #0: loss = 1.13745 (* 1 = 1.13745 loss)
I0524 02:53:12.972429 15289 sgd_solver.cpp:106] Iteration 42372, lr = 0.003
I0524 02:53:21.873587 15289 solver.cpp:237] Iteration 42586, loss = 1.23385
I0524 02:53:21.873622 15289 solver.cpp:253]     Train net output #0: loss = 1.23385 (* 1 = 1.23385 loss)
I0524 02:53:21.873644 15289 sgd_solver.cpp:106] Iteration 42586, lr = 0.003
I0524 02:53:30.773409 15289 solver.cpp:237] Iteration 42800, loss = 1.37691
I0524 02:53:30.773443 15289 solver.cpp:253]     Train net output #0: loss = 1.37691 (* 1 = 1.37691 loss)
I0524 02:53:30.773460 15289 sgd_solver.cpp:106] Iteration 42800, lr = 0.003
I0524 02:53:32.396608 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_42840.caffemodel
I0524 02:53:32.465816 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_42840.solverstate
I0524 02:53:32.882371 15289 solver.cpp:341] Iteration 42850, Testing net (#0)
I0524 02:54:41.608865 15289 solver.cpp:409]     Test net output #0: accuracy = 0.882166
I0524 02:54:41.609040 15289 solver.cpp:409]     Test net output #1: loss = 0.394893 (* 1 = 0.394893 loss)
I0524 02:55:09.329737 15289 solver.cpp:237] Iteration 43014, loss = 1.10167
I0524 02:55:09.329787 15289 solver.cpp:253]     Train net output #0: loss = 1.10167 (* 1 = 1.10167 loss)
I0524 02:55:09.329802 15289 sgd_solver.cpp:106] Iteration 43014, lr = 0.003
I0524 02:55:18.208570 15289 solver.cpp:237] Iteration 43228, loss = 1.09356
I0524 02:55:18.208740 15289 solver.cpp:253]     Train net output #0: loss = 1.09356 (* 1 = 1.09356 loss)
I0524 02:55:18.208753 15289 sgd_solver.cpp:106] Iteration 43228, lr = 0.003
I0524 02:55:27.087440 15289 solver.cpp:237] Iteration 43442, loss = 1.18742
I0524 02:55:27.087476 15289 solver.cpp:253]     Train net output #0: loss = 1.18742 (* 1 = 1.18742 loss)
I0524 02:55:27.087494 15289 sgd_solver.cpp:106] Iteration 43442, lr = 0.003
I0524 02:55:35.960515 15289 solver.cpp:237] Iteration 43656, loss = 1.39925
I0524 02:55:35.960551 15289 solver.cpp:253]     Train net output #0: loss = 1.39925 (* 1 = 1.39925 loss)
I0524 02:55:35.960567 15289 sgd_solver.cpp:106] Iteration 43656, lr = 0.003
I0524 02:55:44.838553 15289 solver.cpp:237] Iteration 43870, loss = 1.24908
I0524 02:55:44.838593 15289 solver.cpp:253]     Train net output #0: loss = 1.24908 (* 1 = 1.24908 loss)
I0524 02:55:44.838610 15289 sgd_solver.cpp:106] Iteration 43870, lr = 0.003
I0524 02:55:53.715821 15289 solver.cpp:237] Iteration 44084, loss = 1.34674
I0524 02:55:53.715972 15289 solver.cpp:253]     Train net output #0: loss = 1.34674 (* 1 = 1.34674 loss)
I0524 02:55:53.715986 15289 sgd_solver.cpp:106] Iteration 44084, lr = 0.003
I0524 02:56:23.459913 15289 solver.cpp:237] Iteration 44298, loss = 1.31812
I0524 02:56:23.459964 15289 solver.cpp:253]     Train net output #0: loss = 1.31812 (* 1 = 1.31812 loss)
I0524 02:56:23.459980 15289 sgd_solver.cpp:106] Iteration 44298, lr = 0.003
I0524 02:56:32.334092 15289 solver.cpp:237] Iteration 44512, loss = 1.25933
I0524 02:56:32.334252 15289 solver.cpp:253]     Train net output #0: loss = 1.25933 (* 1 = 1.25933 loss)
I0524 02:56:32.334266 15289 sgd_solver.cpp:106] Iteration 44512, lr = 0.003
I0524 02:56:41.205018 15289 solver.cpp:237] Iteration 44726, loss = 1.16061
I0524 02:56:41.205059 15289 solver.cpp:253]     Train net output #0: loss = 1.16061 (* 1 = 1.16061 loss)
I0524 02:56:41.205075 15289 sgd_solver.cpp:106] Iteration 44726, lr = 0.003
I0524 02:56:50.083086 15289 solver.cpp:237] Iteration 44940, loss = 0.950874
I0524 02:56:50.083122 15289 solver.cpp:253]     Train net output #0: loss = 0.950874 (* 1 = 0.950874 loss)
I0524 02:56:50.083135 15289 sgd_solver.cpp:106] Iteration 44940, lr = 0.003
I0524 02:56:51.783870 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_44982.caffemodel
I0524 02:56:51.850356 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_44982.solverstate
I0524 02:56:59.023464 15289 solver.cpp:237] Iteration 45154, loss = 1.27212
I0524 02:56:59.023507 15289 solver.cpp:253]     Train net output #0: loss = 1.27212 (* 1 = 1.27212 loss)
I0524 02:56:59.023527 15289 sgd_solver.cpp:106] Iteration 45154, lr = 0.003
I0524 02:57:07.904620 15289 solver.cpp:237] Iteration 45368, loss = 1.2677
I0524 02:57:07.904798 15289 solver.cpp:253]     Train net output #0: loss = 1.2677 (* 1 = 1.2677 loss)
I0524 02:57:07.904813 15289 sgd_solver.cpp:106] Iteration 45368, lr = 0.003
I0524 02:57:16.780267 15289 solver.cpp:237] Iteration 45582, loss = 1.21046
I0524 02:57:16.780302 15289 solver.cpp:253]     Train net output #0: loss = 1.21046 (* 1 = 1.21046 loss)
I0524 02:57:16.780318 15289 sgd_solver.cpp:106] Iteration 45582, lr = 0.003
I0524 02:57:46.554119 15289 solver.cpp:237] Iteration 45796, loss = 1.0512
I0524 02:57:46.554299 15289 solver.cpp:253]     Train net output #0: loss = 1.0512 (* 1 = 1.0512 loss)
I0524 02:57:46.554314 15289 sgd_solver.cpp:106] Iteration 45796, lr = 0.003
I0524 02:57:55.428426 15289 solver.cpp:237] Iteration 46010, loss = 1.10316
I0524 02:57:55.428470 15289 solver.cpp:253]     Train net output #0: loss = 1.10316 (* 1 = 1.10316 loss)
I0524 02:57:55.428486 15289 sgd_solver.cpp:106] Iteration 46010, lr = 0.003
I0524 02:58:04.296965 15289 solver.cpp:237] Iteration 46224, loss = 1.03268
I0524 02:58:04.297000 15289 solver.cpp:253]     Train net output #0: loss = 1.03268 (* 1 = 1.03268 loss)
I0524 02:58:04.297018 15289 sgd_solver.cpp:106] Iteration 46224, lr = 0.003
I0524 02:58:13.174104 15289 solver.cpp:237] Iteration 46438, loss = 1.19491
I0524 02:58:13.174139 15289 solver.cpp:253]     Train net output #0: loss = 1.19491 (* 1 = 1.19491 loss)
I0524 02:58:13.174155 15289 sgd_solver.cpp:106] Iteration 46438, lr = 0.003
I0524 02:58:22.047703 15289 solver.cpp:237] Iteration 46652, loss = 1.05641
I0524 02:58:22.047866 15289 solver.cpp:253]     Train net output #0: loss = 1.05641 (* 1 = 1.05641 loss)
I0524 02:58:22.047880 15289 sgd_solver.cpp:106] Iteration 46652, lr = 0.003
I0524 02:58:30.926662 15289 solver.cpp:237] Iteration 46866, loss = 1.15547
I0524 02:58:30.926697 15289 solver.cpp:253]     Train net output #0: loss = 1.15547 (* 1 = 1.15547 loss)
I0524 02:58:30.926713 15289 sgd_solver.cpp:106] Iteration 46866, lr = 0.003
I0524 02:58:39.800313 15289 solver.cpp:237] Iteration 47080, loss = 1.13471
I0524 02:58:39.800359 15289 solver.cpp:253]     Train net output #0: loss = 1.13471 (* 1 = 1.13471 loss)
I0524 02:58:39.800379 15289 sgd_solver.cpp:106] Iteration 47080, lr = 0.003
I0524 02:58:41.578866 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_47124.caffemodel
I0524 02:58:41.645452 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_47124.solverstate
I0524 02:58:42.099483 15289 solver.cpp:341] Iteration 47135, Testing net (#0)
I0524 02:59:29.745702 15289 solver.cpp:409]     Test net output #0: accuracy = 0.88384
I0524 02:59:29.745867 15289 solver.cpp:409]     Test net output #1: loss = 0.393139 (* 1 = 0.393139 loss)
I0524 02:59:57.300266 15289 solver.cpp:237] Iteration 47294, loss = 1.2362
I0524 02:59:57.300317 15289 solver.cpp:253]     Train net output #0: loss = 1.2362 (* 1 = 1.2362 loss)
I0524 02:59:57.300333 15289 sgd_solver.cpp:106] Iteration 47294, lr = 0.003
I0524 03:00:06.181324 15289 solver.cpp:237] Iteration 47508, loss = 1.12732
I0524 03:00:06.181496 15289 solver.cpp:253]     Train net output #0: loss = 1.12732 (* 1 = 1.12732 loss)
I0524 03:00:06.181510 15289 sgd_solver.cpp:106] Iteration 47508, lr = 0.003
I0524 03:00:15.064458 15289 solver.cpp:237] Iteration 47722, loss = 0.907451
I0524 03:00:15.064494 15289 solver.cpp:253]     Train net output #0: loss = 0.907451 (* 1 = 0.907451 loss)
I0524 03:00:15.064512 15289 sgd_solver.cpp:106] Iteration 47722, lr = 0.003
I0524 03:00:23.945791 15289 solver.cpp:237] Iteration 47936, loss = 1.00681
I0524 03:00:23.945844 15289 solver.cpp:253]     Train net output #0: loss = 1.00681 (* 1 = 1.00681 loss)
I0524 03:00:23.945859 15289 sgd_solver.cpp:106] Iteration 47936, lr = 0.003
I0524 03:00:32.823635 15289 solver.cpp:237] Iteration 48150, loss = 1.21837
I0524 03:00:32.823671 15289 solver.cpp:253]     Train net output #0: loss = 1.21837 (* 1 = 1.21837 loss)
I0524 03:00:32.823688 15289 sgd_solver.cpp:106] Iteration 48150, lr = 0.003
I0524 03:00:41.701550 15289 solver.cpp:237] Iteration 48364, loss = 1.16491
I0524 03:00:41.701712 15289 solver.cpp:253]     Train net output #0: loss = 1.16491 (* 1 = 1.16491 loss)
I0524 03:00:41.701726 15289 sgd_solver.cpp:106] Iteration 48364, lr = 0.003
I0524 03:01:11.508342 15289 solver.cpp:237] Iteration 48578, loss = 1.07949
I0524 03:01:11.508393 15289 solver.cpp:253]     Train net output #0: loss = 1.07949 (* 1 = 1.07949 loss)
I0524 03:01:11.508407 15289 sgd_solver.cpp:106] Iteration 48578, lr = 0.003
I0524 03:01:20.389251 15289 solver.cpp:237] Iteration 48792, loss = 1.01623
I0524 03:01:20.389415 15289 solver.cpp:253]     Train net output #0: loss = 1.01623 (* 1 = 1.01623 loss)
I0524 03:01:20.389428 15289 sgd_solver.cpp:106] Iteration 48792, lr = 0.003
I0524 03:01:29.267500 15289 solver.cpp:237] Iteration 49006, loss = 1.2926
I0524 03:01:29.267535 15289 solver.cpp:253]     Train net output #0: loss = 1.2926 (* 1 = 1.2926 loss)
I0524 03:01:29.267552 15289 sgd_solver.cpp:106] Iteration 49006, lr = 0.003
I0524 03:01:38.148608 15289 solver.cpp:237] Iteration 49220, loss = 1.08794
I0524 03:01:38.148653 15289 solver.cpp:253]     Train net output #0: loss = 1.08794 (* 1 = 1.08794 loss)
I0524 03:01:38.148668 15289 sgd_solver.cpp:106] Iteration 49220, lr = 0.003
I0524 03:01:40.012748 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_49266.caffemodel
I0524 03:01:40.078866 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_49266.solverstate
I0524 03:01:47.086448 15289 solver.cpp:237] Iteration 49434, loss = 1.20561
I0524 03:01:47.086498 15289 solver.cpp:253]     Train net output #0: loss = 1.20561 (* 1 = 1.20561 loss)
I0524 03:01:47.086510 15289 sgd_solver.cpp:106] Iteration 49434, lr = 0.003
I0524 03:01:55.965884 15289 solver.cpp:237] Iteration 49648, loss = 1.25825
I0524 03:01:55.966047 15289 solver.cpp:253]     Train net output #0: loss = 1.25825 (* 1 = 1.25825 loss)
I0524 03:01:55.966059 15289 sgd_solver.cpp:106] Iteration 49648, lr = 0.003
I0524 03:02:04.845262 15289 solver.cpp:237] Iteration 49862, loss = 1.28339
I0524 03:02:04.845301 15289 solver.cpp:253]     Train net output #0: loss = 1.28339 (* 1 = 1.28339 loss)
I0524 03:02:04.845319 15289 sgd_solver.cpp:106] Iteration 49862, lr = 0.003
I0524 03:02:34.615909 15289 solver.cpp:237] Iteration 50076, loss = 0.917385
I0524 03:02:34.616086 15289 solver.cpp:253]     Train net output #0: loss = 0.917385 (* 1 = 0.917385 loss)
I0524 03:02:34.616101 15289 sgd_solver.cpp:106] Iteration 50076, lr = 0.003
I0524 03:02:43.496700 15289 solver.cpp:237] Iteration 50290, loss = 0.94364
I0524 03:02:43.496734 15289 solver.cpp:253]     Train net output #0: loss = 0.94364 (* 1 = 0.94364 loss)
I0524 03:02:43.496752 15289 sgd_solver.cpp:106] Iteration 50290, lr = 0.003
I0524 03:02:52.377965 15289 solver.cpp:237] Iteration 50504, loss = 1.02229
I0524 03:02:52.378005 15289 solver.cpp:253]     Train net output #0: loss = 1.02229 (* 1 = 1.02229 loss)
I0524 03:02:52.378024 15289 sgd_solver.cpp:106] Iteration 50504, lr = 0.003
I0524 03:03:01.259167 15289 solver.cpp:237] Iteration 50718, loss = 0.953427
I0524 03:03:01.259203 15289 solver.cpp:253]     Train net output #0: loss = 0.953427 (* 1 = 0.953427 loss)
I0524 03:03:01.259217 15289 sgd_solver.cpp:106] Iteration 50718, lr = 0.003
I0524 03:03:10.141999 15289 solver.cpp:237] Iteration 50932, loss = 1.07717
I0524 03:03:10.142166 15289 solver.cpp:253]     Train net output #0: loss = 1.07717 (* 1 = 1.07717 loss)
I0524 03:03:10.142182 15289 sgd_solver.cpp:106] Iteration 50932, lr = 0.003
I0524 03:03:19.020133 15289 solver.cpp:237] Iteration 51146, loss = 1.24478
I0524 03:03:19.020180 15289 solver.cpp:253]     Train net output #0: loss = 1.24478 (* 1 = 1.24478 loss)
I0524 03:03:19.020193 15289 sgd_solver.cpp:106] Iteration 51146, lr = 0.003
I0524 03:03:27.895766 15289 solver.cpp:237] Iteration 51360, loss = 1.16809
I0524 03:03:27.895802 15289 solver.cpp:253]     Train net output #0: loss = 1.16809 (* 1 = 1.16809 loss)
I0524 03:03:27.895817 15289 sgd_solver.cpp:106] Iteration 51360, lr = 0.003
I0524 03:03:29.847331 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_51408.caffemodel
I0524 03:03:29.914551 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_51408.solverstate
I0524 03:03:30.410701 15289 solver.cpp:341] Iteration 51420, Testing net (#0)
I0524 03:04:39.291610 15289 solver.cpp:409]     Test net output #0: accuracy = 0.883987
I0524 03:04:39.291790 15289 solver.cpp:409]     Test net output #1: loss = 0.390328 (* 1 = 0.390328 loss)
I0524 03:05:06.635515 15289 solver.cpp:237] Iteration 51574, loss = 1.26926
I0524 03:05:06.635565 15289 solver.cpp:253]     Train net output #0: loss = 1.26926 (* 1 = 1.26926 loss)
I0524 03:05:06.635581 15289 sgd_solver.cpp:106] Iteration 51574, lr = 0.003
I0524 03:05:15.521661 15289 solver.cpp:237] Iteration 51788, loss = 1.35568
I0524 03:05:15.521823 15289 solver.cpp:253]     Train net output #0: loss = 1.35568 (* 1 = 1.35568 loss)
I0524 03:05:15.521837 15289 sgd_solver.cpp:106] Iteration 51788, lr = 0.003
I0524 03:05:24.403084 15289 solver.cpp:237] Iteration 52002, loss = 1.10155
I0524 03:05:24.403125 15289 solver.cpp:253]     Train net output #0: loss = 1.10155 (* 1 = 1.10155 loss)
I0524 03:05:24.403139 15289 sgd_solver.cpp:106] Iteration 52002, lr = 0.003
I0524 03:05:33.278522 15289 solver.cpp:237] Iteration 52216, loss = 1.17082
I0524 03:05:33.278555 15289 solver.cpp:253]     Train net output #0: loss = 1.17082 (* 1 = 1.17082 loss)
I0524 03:05:33.278573 15289 sgd_solver.cpp:106] Iteration 52216, lr = 0.003
I0524 03:05:42.165578 15289 solver.cpp:237] Iteration 52430, loss = 1.19898
I0524 03:05:42.165614 15289 solver.cpp:253]     Train net output #0: loss = 1.19898 (* 1 = 1.19898 loss)
I0524 03:05:42.165629 15289 sgd_solver.cpp:106] Iteration 52430, lr = 0.003
I0524 03:05:51.048624 15289 solver.cpp:237] Iteration 52644, loss = 0.988523
I0524 03:05:51.048791 15289 solver.cpp:253]     Train net output #0: loss = 0.988523 (* 1 = 0.988523 loss)
I0524 03:05:51.048805 15289 sgd_solver.cpp:106] Iteration 52644, lr = 0.003
I0524 03:06:20.834288 15289 solver.cpp:237] Iteration 52858, loss = 0.964978
I0524 03:06:20.834342 15289 solver.cpp:253]     Train net output #0: loss = 0.964978 (* 1 = 0.964978 loss)
I0524 03:06:20.834357 15289 sgd_solver.cpp:106] Iteration 52858, lr = 0.003
I0524 03:06:29.713464 15289 solver.cpp:237] Iteration 53072, loss = 1.28825
I0524 03:06:29.713634 15289 solver.cpp:253]     Train net output #0: loss = 1.28825 (* 1 = 1.28825 loss)
I0524 03:06:29.713649 15289 sgd_solver.cpp:106] Iteration 53072, lr = 0.003
I0524 03:06:38.591567 15289 solver.cpp:237] Iteration 53286, loss = 0.98968
I0524 03:06:38.591614 15289 solver.cpp:253]     Train net output #0: loss = 0.98968 (* 1 = 0.98968 loss)
I0524 03:06:38.591630 15289 sgd_solver.cpp:106] Iteration 53286, lr = 0.003
I0524 03:06:47.473467 15289 solver.cpp:237] Iteration 53500, loss = 1.25393
I0524 03:06:47.473503 15289 solver.cpp:253]     Train net output #0: loss = 1.25393 (* 1 = 1.25393 loss)
I0524 03:06:47.473517 15289 sgd_solver.cpp:106] Iteration 53500, lr = 0.003
I0524 03:06:49.503741 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_53550.caffemodel
I0524 03:06:49.572021 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_53550.solverstate
I0524 03:06:56.417323 15289 solver.cpp:237] Iteration 53714, loss = 1.07754
I0524 03:06:56.417371 15289 solver.cpp:253]     Train net output #0: loss = 1.07754 (* 1 = 1.07754 loss)
I0524 03:06:56.417388 15289 sgd_solver.cpp:106] Iteration 53714, lr = 0.003
I0524 03:07:05.289260 15289 solver.cpp:237] Iteration 53928, loss = 1.03118
I0524 03:07:05.289449 15289 solver.cpp:253]     Train net output #0: loss = 1.03118 (* 1 = 1.03118 loss)
I0524 03:07:05.289464 15289 sgd_solver.cpp:106] Iteration 53928, lr = 0.003
I0524 03:07:14.175007 15289 solver.cpp:237] Iteration 54142, loss = 1.11153
I0524 03:07:14.175041 15289 solver.cpp:253]     Train net output #0: loss = 1.11153 (* 1 = 1.11153 loss)
I0524 03:07:14.175058 15289 sgd_solver.cpp:106] Iteration 54142, lr = 0.003
I0524 03:07:43.945142 15289 solver.cpp:237] Iteration 54356, loss = 1.29244
I0524 03:07:43.945323 15289 solver.cpp:253]     Train net output #0: loss = 1.29244 (* 1 = 1.29244 loss)
I0524 03:07:43.945338 15289 sgd_solver.cpp:106] Iteration 54356, lr = 0.003
I0524 03:07:52.826346 15289 solver.cpp:237] Iteration 54570, loss = 1.30753
I0524 03:07:52.826386 15289 solver.cpp:253]     Train net output #0: loss = 1.30753 (* 1 = 1.30753 loss)
I0524 03:07:52.826408 15289 sgd_solver.cpp:106] Iteration 54570, lr = 0.003
I0524 03:08:01.704193 15289 solver.cpp:237] Iteration 54784, loss = 1.03509
I0524 03:08:01.704229 15289 solver.cpp:253]     Train net output #0: loss = 1.03509 (* 1 = 1.03509 loss)
I0524 03:08:01.704244 15289 sgd_solver.cpp:106] Iteration 54784, lr = 0.003
I0524 03:08:10.580909 15289 solver.cpp:237] Iteration 54998, loss = 1.23812
I0524 03:08:10.580945 15289 solver.cpp:253]     Train net output #0: loss = 1.23812 (* 1 = 1.23812 loss)
I0524 03:08:10.580961 15289 sgd_solver.cpp:106] Iteration 54998, lr = 0.003
I0524 03:08:19.458992 15289 solver.cpp:237] Iteration 55212, loss = 1.09641
I0524 03:08:19.459163 15289 solver.cpp:253]     Train net output #0: loss = 1.09641 (* 1 = 1.09641 loss)
I0524 03:08:19.459177 15289 sgd_solver.cpp:106] Iteration 55212, lr = 0.003
I0524 03:08:28.347841 15289 solver.cpp:237] Iteration 55426, loss = 1.20192
I0524 03:08:28.347877 15289 solver.cpp:253]     Train net output #0: loss = 1.20192 (* 1 = 1.20192 loss)
I0524 03:08:28.347893 15289 sgd_solver.cpp:106] Iteration 55426, lr = 0.003
I0524 03:08:37.228324 15289 solver.cpp:237] Iteration 55640, loss = 1.15389
I0524 03:08:37.228360 15289 solver.cpp:253]     Train net output #0: loss = 1.15389 (* 1 = 1.15389 loss)
I0524 03:08:37.228375 15289 sgd_solver.cpp:106] Iteration 55640, lr = 0.003
I0524 03:08:39.343904 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_55692.caffemodel
I0524 03:08:39.409818 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_55692.solverstate
I0524 03:08:39.969491 15289 solver.cpp:341] Iteration 55705, Testing net (#0)
I0524 03:09:27.936820 15289 solver.cpp:409]     Test net output #0: accuracy = 0.885948
I0524 03:09:27.937014 15289 solver.cpp:409]     Test net output #1: loss = 0.362506 (* 1 = 0.362506 loss)
I0524 03:09:55.025292 15289 solver.cpp:237] Iteration 55854, loss = 1.28624
I0524 03:09:55.025342 15289 solver.cpp:253]     Train net output #0: loss = 1.28624 (* 1 = 1.28624 loss)
I0524 03:09:55.025359 15289 sgd_solver.cpp:106] Iteration 55854, lr = 0.003
I0524 03:10:03.897192 15289 solver.cpp:237] Iteration 56068, loss = 1.31187
I0524 03:10:03.897358 15289 solver.cpp:253]     Train net output #0: loss = 1.31187 (* 1 = 1.31187 loss)
I0524 03:10:03.897372 15289 sgd_solver.cpp:106] Iteration 56068, lr = 0.003
I0524 03:10:12.766932 15289 solver.cpp:237] Iteration 56282, loss = 0.959488
I0524 03:10:12.766968 15289 solver.cpp:253]     Train net output #0: loss = 0.959488 (* 1 = 0.959488 loss)
I0524 03:10:12.766984 15289 sgd_solver.cpp:106] Iteration 56282, lr = 0.003
I0524 03:10:21.635129 15289 solver.cpp:237] Iteration 56496, loss = 1.01672
I0524 03:10:21.635171 15289 solver.cpp:253]     Train net output #0: loss = 1.01672 (* 1 = 1.01672 loss)
I0524 03:10:21.635188 15289 sgd_solver.cpp:106] Iteration 56496, lr = 0.003
I0524 03:10:30.503514 15289 solver.cpp:237] Iteration 56710, loss = 1.03425
I0524 03:10:30.503550 15289 solver.cpp:253]     Train net output #0: loss = 1.03425 (* 1 = 1.03425 loss)
I0524 03:10:30.503566 15289 sgd_solver.cpp:106] Iteration 56710, lr = 0.003
I0524 03:10:39.369302 15289 solver.cpp:237] Iteration 56924, loss = 1.0671
I0524 03:10:39.369462 15289 solver.cpp:253]     Train net output #0: loss = 1.0671 (* 1 = 1.0671 loss)
I0524 03:10:39.369477 15289 sgd_solver.cpp:106] Iteration 56924, lr = 0.003
I0524 03:10:48.237406 15289 solver.cpp:237] Iteration 57138, loss = 1.11525
I0524 03:10:48.237449 15289 solver.cpp:253]     Train net output #0: loss = 1.11525 (* 1 = 1.11525 loss)
I0524 03:10:48.237465 15289 sgd_solver.cpp:106] Iteration 57138, lr = 0.003
I0524 03:11:17.979688 15289 solver.cpp:237] Iteration 57352, loss = 1.25297
I0524 03:11:17.979867 15289 solver.cpp:253]     Train net output #0: loss = 1.25297 (* 1 = 1.25297 loss)
I0524 03:11:17.979882 15289 sgd_solver.cpp:106] Iteration 57352, lr = 0.003
I0524 03:11:26.848904 15289 solver.cpp:237] Iteration 57566, loss = 1.12384
I0524 03:11:26.848938 15289 solver.cpp:253]     Train net output #0: loss = 1.12384 (* 1 = 1.12384 loss)
I0524 03:11:26.848958 15289 sgd_solver.cpp:106] Iteration 57566, lr = 0.003
I0524 03:11:35.718971 15289 solver.cpp:237] Iteration 57780, loss = 1.17729
I0524 03:11:35.719012 15289 solver.cpp:253]     Train net output #0: loss = 1.17729 (* 1 = 1.17729 loss)
I0524 03:11:35.719029 15289 sgd_solver.cpp:106] Iteration 57780, lr = 0.003
I0524 03:11:37.916146 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_57834.caffemodel
I0524 03:11:37.983093 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_57834.solverstate
I0524 03:11:44.655019 15289 solver.cpp:237] Iteration 57994, loss = 1.06859
I0524 03:11:44.655066 15289 solver.cpp:253]     Train net output #0: loss = 1.06859 (* 1 = 1.06859 loss)
I0524 03:11:44.655082 15289 sgd_solver.cpp:106] Iteration 57994, lr = 0.003
I0524 03:11:53.516336 15289 solver.cpp:237] Iteration 58208, loss = 1.18952
I0524 03:11:53.516513 15289 solver.cpp:253]     Train net output #0: loss = 1.18952 (* 1 = 1.18952 loss)
I0524 03:11:53.516527 15289 sgd_solver.cpp:106] Iteration 58208, lr = 0.003
I0524 03:12:02.392742 15289 solver.cpp:237] Iteration 58422, loss = 1.19737
I0524 03:12:02.392781 15289 solver.cpp:253]     Train net output #0: loss = 1.19737 (* 1 = 1.19737 loss)
I0524 03:12:02.392803 15289 sgd_solver.cpp:106] Iteration 58422, lr = 0.003
I0524 03:12:32.175531 15289 solver.cpp:237] Iteration 58636, loss = 1.25837
I0524 03:12:32.175714 15289 solver.cpp:253]     Train net output #0: loss = 1.25837 (* 1 = 1.25837 loss)
I0524 03:12:32.175729 15289 sgd_solver.cpp:106] Iteration 58636, lr = 0.003
I0524 03:12:41.039115 15289 solver.cpp:237] Iteration 58850, loss = 1.34722
I0524 03:12:41.039150 15289 solver.cpp:253]     Train net output #0: loss = 1.34722 (* 1 = 1.34722 loss)
I0524 03:12:41.039167 15289 sgd_solver.cpp:106] Iteration 58850, lr = 0.003
I0524 03:12:49.912664 15289 solver.cpp:237] Iteration 59064, loss = 1.18795
I0524 03:12:49.912714 15289 solver.cpp:253]     Train net output #0: loss = 1.18795 (* 1 = 1.18795 loss)
I0524 03:12:49.912729 15289 sgd_solver.cpp:106] Iteration 59064, lr = 0.003
I0524 03:12:58.782762 15289 solver.cpp:237] Iteration 59278, loss = 0.995047
I0524 03:12:58.782793 15289 solver.cpp:253]     Train net output #0: loss = 0.995047 (* 1 = 0.995047 loss)
I0524 03:12:58.782806 15289 sgd_solver.cpp:106] Iteration 59278, lr = 0.003
I0524 03:13:07.647821 15289 solver.cpp:237] Iteration 59492, loss = 1.26566
I0524 03:13:07.647994 15289 solver.cpp:253]     Train net output #0: loss = 1.26566 (* 1 = 1.26566 loss)
I0524 03:13:07.648007 15289 sgd_solver.cpp:106] Iteration 59492, lr = 0.003
I0524 03:13:16.513159 15289 solver.cpp:237] Iteration 59706, loss = 1.3088
I0524 03:13:16.513200 15289 solver.cpp:253]     Train net output #0: loss = 1.3088 (* 1 = 1.3088 loss)
I0524 03:13:16.513221 15289 sgd_solver.cpp:106] Iteration 59706, lr = 0.003
I0524 03:13:25.382205 15289 solver.cpp:237] Iteration 59920, loss = 1.06561
I0524 03:13:25.382241 15289 solver.cpp:253]     Train net output #0: loss = 1.06561 (* 1 = 1.06561 loss)
I0524 03:13:25.382256 15289 sgd_solver.cpp:106] Iteration 59920, lr = 0.003
I0524 03:13:27.660436 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_59976.caffemodel
I0524 03:13:27.727663 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_59976.solverstate
I0524 03:13:28.306289 15289 solver.cpp:341] Iteration 59990, Testing net (#0)
I0524 03:14:37.143153 15289 solver.cpp:409]     Test net output #0: accuracy = 0.890363
I0524 03:14:37.143338 15289 solver.cpp:409]     Test net output #1: loss = 0.354711 (* 1 = 0.354711 loss)
I0524 03:15:04.025017 15289 solver.cpp:237] Iteration 60134, loss = 1.27244
I0524 03:15:04.025068 15289 solver.cpp:253]     Train net output #0: loss = 1.27244 (* 1 = 1.27244 loss)
I0524 03:15:04.025084 15289 sgd_solver.cpp:106] Iteration 60134, lr = 0.003
I0524 03:15:12.915284 15289 solver.cpp:237] Iteration 60348, loss = 1.10645
I0524 03:15:12.915462 15289 solver.cpp:253]     Train net output #0: loss = 1.10645 (* 1 = 1.10645 loss)
I0524 03:15:12.915475 15289 sgd_solver.cpp:106] Iteration 60348, lr = 0.003
I0524 03:15:21.793227 15289 solver.cpp:237] Iteration 60562, loss = 1.02506
I0524 03:15:21.793267 15289 solver.cpp:253]     Train net output #0: loss = 1.02506 (* 1 = 1.02506 loss)
I0524 03:15:21.793282 15289 sgd_solver.cpp:106] Iteration 60562, lr = 0.003
I0524 03:15:30.683743 15289 solver.cpp:237] Iteration 60776, loss = 1.30068
I0524 03:15:30.683779 15289 solver.cpp:253]     Train net output #0: loss = 1.30068 (* 1 = 1.30068 loss)
I0524 03:15:30.683796 15289 sgd_solver.cpp:106] Iteration 60776, lr = 0.003
I0524 03:15:39.572557 15289 solver.cpp:237] Iteration 60990, loss = 1.2609
I0524 03:15:39.572592 15289 solver.cpp:253]     Train net output #0: loss = 1.2609 (* 1 = 1.2609 loss)
I0524 03:15:39.572608 15289 sgd_solver.cpp:106] Iteration 60990, lr = 0.003
I0524 03:15:48.462229 15289 solver.cpp:237] Iteration 61204, loss = 1.00253
I0524 03:15:48.462402 15289 solver.cpp:253]     Train net output #0: loss = 1.00253 (* 1 = 1.00253 loss)
I0524 03:15:48.462416 15289 sgd_solver.cpp:106] Iteration 61204, lr = 0.003
I0524 03:15:57.349135 15289 solver.cpp:237] Iteration 61418, loss = 0.929163
I0524 03:15:57.349170 15289 solver.cpp:253]     Train net output #0: loss = 0.929163 (* 1 = 0.929163 loss)
I0524 03:15:57.349187 15289 sgd_solver.cpp:106] Iteration 61418, lr = 0.003
I0524 03:16:27.127785 15289 solver.cpp:237] Iteration 61632, loss = 1.02442
I0524 03:16:27.127977 15289 solver.cpp:253]     Train net output #0: loss = 1.02442 (* 1 = 1.02442 loss)
I0524 03:16:27.127992 15289 sgd_solver.cpp:106] Iteration 61632, lr = 0.003
I0524 03:16:36.012928 15289 solver.cpp:237] Iteration 61846, loss = 1.04686
I0524 03:16:36.012974 15289 solver.cpp:253]     Train net output #0: loss = 1.04686 (* 1 = 1.04686 loss)
I0524 03:16:36.012987 15289 sgd_solver.cpp:106] Iteration 61846, lr = 0.003
I0524 03:16:44.902003 15289 solver.cpp:237] Iteration 62060, loss = 1.20026
I0524 03:16:44.902039 15289 solver.cpp:253]     Train net output #0: loss = 1.20026 (* 1 = 1.20026 loss)
I0524 03:16:44.902055 15289 sgd_solver.cpp:106] Iteration 62060, lr = 0.003
I0524 03:16:47.265017 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_62118.caffemodel
I0524 03:16:47.333103 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_62118.solverstate
I0524 03:16:53.845974 15289 solver.cpp:237] Iteration 62274, loss = 1.10286
I0524 03:16:53.846024 15289 solver.cpp:253]     Train net output #0: loss = 1.10286 (* 1 = 1.10286 loss)
I0524 03:16:53.846040 15289 sgd_solver.cpp:106] Iteration 62274, lr = 0.003
I0524 03:17:02.731665 15289 solver.cpp:237] Iteration 62488, loss = 1.32815
I0524 03:17:02.731851 15289 solver.cpp:253]     Train net output #0: loss = 1.32815 (* 1 = 1.32815 loss)
I0524 03:17:02.731866 15289 sgd_solver.cpp:106] Iteration 62488, lr = 0.003
I0524 03:17:11.624944 15289 solver.cpp:237] Iteration 62702, loss = 1.31618
I0524 03:17:11.624979 15289 solver.cpp:253]     Train net output #0: loss = 1.31618 (* 1 = 1.31618 loss)
I0524 03:17:11.624995 15289 sgd_solver.cpp:106] Iteration 62702, lr = 0.003
I0524 03:17:41.460674 15289 solver.cpp:237] Iteration 62916, loss = 1.09347
I0524 03:17:41.460863 15289 solver.cpp:253]     Train net output #0: loss = 1.09347 (* 1 = 1.09347 loss)
I0524 03:17:41.460878 15289 sgd_solver.cpp:106] Iteration 62916, lr = 0.003
I0524 03:17:50.348268 15289 solver.cpp:237] Iteration 63130, loss = 1.27637
I0524 03:17:50.348307 15289 solver.cpp:253]     Train net output #0: loss = 1.27637 (* 1 = 1.27637 loss)
I0524 03:17:50.348330 15289 sgd_solver.cpp:106] Iteration 63130, lr = 0.003
I0524 03:17:59.237216 15289 solver.cpp:237] Iteration 63344, loss = 1.22472
I0524 03:17:59.237251 15289 solver.cpp:253]     Train net output #0: loss = 1.22472 (* 1 = 1.22472 loss)
I0524 03:17:59.237267 15289 sgd_solver.cpp:106] Iteration 63344, lr = 0.003
I0524 03:18:08.121876 15289 solver.cpp:237] Iteration 63558, loss = 1.08611
I0524 03:18:08.121912 15289 solver.cpp:253]     Train net output #0: loss = 1.08611 (* 1 = 1.08611 loss)
I0524 03:18:08.121928 15289 sgd_solver.cpp:106] Iteration 63558, lr = 0.003
I0524 03:18:17.008795 15289 solver.cpp:237] Iteration 63772, loss = 0.866893
I0524 03:18:17.008978 15289 solver.cpp:253]     Train net output #0: loss = 0.866893 (* 1 = 0.866893 loss)
I0524 03:18:17.008993 15289 sgd_solver.cpp:106] Iteration 63772, lr = 0.003
I0524 03:18:25.897347 15289 solver.cpp:237] Iteration 63986, loss = 1.06092
I0524 03:18:25.897382 15289 solver.cpp:253]     Train net output #0: loss = 1.06092 (* 1 = 1.06092 loss)
I0524 03:18:25.897399 15289 sgd_solver.cpp:106] Iteration 63986, lr = 0.003
I0524 03:18:34.788718 15289 solver.cpp:237] Iteration 64200, loss = 1.29572
I0524 03:18:34.788753 15289 solver.cpp:253]     Train net output #0: loss = 1.29572 (* 1 = 1.29572 loss)
I0524 03:18:34.788771 15289 sgd_solver.cpp:106] Iteration 64200, lr = 0.003
I0524 03:18:37.242143 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_64260.caffemodel
I0524 03:18:37.310617 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_64260.solverstate
I0524 03:18:37.934548 15289 solver.cpp:341] Iteration 64275, Testing net (#0)
I0524 03:19:25.619453 15289 solver.cpp:409]     Test net output #0: accuracy = 0.890436
I0524 03:19:25.619648 15289 solver.cpp:409]     Test net output #1: loss = 0.343003 (* 1 = 0.343003 loss)
I0524 03:19:52.347404 15289 solver.cpp:237] Iteration 64414, loss = 1.10664
I0524 03:19:52.347455 15289 solver.cpp:253]     Train net output #0: loss = 1.10664 (* 1 = 1.10664 loss)
I0524 03:19:52.347468 15289 sgd_solver.cpp:106] Iteration 64414, lr = 0.003
I0524 03:20:01.214148 15289 solver.cpp:237] Iteration 64628, loss = 0.991646
I0524 03:20:01.214326 15289 solver.cpp:253]     Train net output #0: loss = 0.991646 (* 1 = 0.991646 loss)
I0524 03:20:01.214340 15289 sgd_solver.cpp:106] Iteration 64628, lr = 0.003
I0524 03:20:10.081086 15289 solver.cpp:237] Iteration 64842, loss = 1.17753
I0524 03:20:10.081121 15289 solver.cpp:253]     Train net output #0: loss = 1.17753 (* 1 = 1.17753 loss)
I0524 03:20:10.081138 15289 sgd_solver.cpp:106] Iteration 64842, lr = 0.003
I0524 03:20:18.947525 15289 solver.cpp:237] Iteration 65056, loss = 1.08573
I0524 03:20:18.947561 15289 solver.cpp:253]     Train net output #0: loss = 1.08573 (* 1 = 1.08573 loss)
I0524 03:20:18.947576 15289 sgd_solver.cpp:106] Iteration 65056, lr = 0.003
I0524 03:20:27.815143 15289 solver.cpp:237] Iteration 65270, loss = 1.50869
I0524 03:20:27.815189 15289 solver.cpp:253]     Train net output #0: loss = 1.50869 (* 1 = 1.50869 loss)
I0524 03:20:27.815206 15289 sgd_solver.cpp:106] Iteration 65270, lr = 0.003
I0524 03:20:36.684083 15289 solver.cpp:237] Iteration 65484, loss = 1.32335
I0524 03:20:36.684249 15289 solver.cpp:253]     Train net output #0: loss = 1.32335 (* 1 = 1.32335 loss)
I0524 03:20:36.684262 15289 sgd_solver.cpp:106] Iteration 65484, lr = 0.003
I0524 03:20:45.548887 15289 solver.cpp:237] Iteration 65698, loss = 1.26125
I0524 03:20:45.548923 15289 solver.cpp:253]     Train net output #0: loss = 1.26125 (* 1 = 1.26125 loss)
I0524 03:20:45.548945 15289 sgd_solver.cpp:106] Iteration 65698, lr = 0.003
I0524 03:21:15.323523 15289 solver.cpp:237] Iteration 65912, loss = 1.22853
I0524 03:21:15.323709 15289 solver.cpp:253]     Train net output #0: loss = 1.22853 (* 1 = 1.22853 loss)
I0524 03:21:15.323722 15289 sgd_solver.cpp:106] Iteration 65912, lr = 0.003
I0524 03:21:24.190354 15289 solver.cpp:237] Iteration 66126, loss = 1.22714
I0524 03:21:24.190389 15289 solver.cpp:253]     Train net output #0: loss = 1.22714 (* 1 = 1.22714 loss)
I0524 03:21:24.190405 15289 sgd_solver.cpp:106] Iteration 66126, lr = 0.003
I0524 03:21:33.059878 15289 solver.cpp:237] Iteration 66340, loss = 1.03673
I0524 03:21:33.059914 15289 solver.cpp:253]     Train net output #0: loss = 1.03673 (* 1 = 1.03673 loss)
I0524 03:21:33.059932 15289 sgd_solver.cpp:106] Iteration 66340, lr = 0.003
I0524 03:21:35.586550 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_66402.caffemodel
I0524 03:21:35.652952 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_66402.solverstate
I0524 03:21:41.990325 15289 solver.cpp:237] Iteration 66554, loss = 1.28142
I0524 03:21:41.990366 15289 solver.cpp:253]     Train net output #0: loss = 1.28142 (* 1 = 1.28142 loss)
I0524 03:21:41.990387 15289 sgd_solver.cpp:106] Iteration 66554, lr = 0.003
I0524 03:21:50.860736 15289 solver.cpp:237] Iteration 66768, loss = 1.10319
I0524 03:21:50.860913 15289 solver.cpp:253]     Train net output #0: loss = 1.10319 (* 1 = 1.10319 loss)
I0524 03:21:50.860926 15289 sgd_solver.cpp:106] Iteration 66768, lr = 0.003
I0524 03:21:59.726275 15289 solver.cpp:237] Iteration 66982, loss = 1.17668
I0524 03:21:59.726323 15289 solver.cpp:253]     Train net output #0: loss = 1.17668 (* 1 = 1.17668 loss)
I0524 03:21:59.726341 15289 sgd_solver.cpp:106] Iteration 66982, lr = 0.003
I0524 03:22:29.507673 15289 solver.cpp:237] Iteration 67196, loss = 1.33354
I0524 03:22:29.507866 15289 solver.cpp:253]     Train net output #0: loss = 1.33354 (* 1 = 1.33354 loss)
I0524 03:22:29.507880 15289 sgd_solver.cpp:106] Iteration 67196, lr = 0.003
I0524 03:22:38.385211 15289 solver.cpp:237] Iteration 67410, loss = 1.13313
I0524 03:22:38.385247 15289 solver.cpp:253]     Train net output #0: loss = 1.13313 (* 1 = 1.13313 loss)
I0524 03:22:38.385262 15289 sgd_solver.cpp:106] Iteration 67410, lr = 0.003
I0524 03:22:47.248103 15289 solver.cpp:237] Iteration 67624, loss = 1.06381
I0524 03:22:47.248138 15289 solver.cpp:253]     Train net output #0: loss = 1.06381 (* 1 = 1.06381 loss)
I0524 03:22:47.248154 15289 sgd_solver.cpp:106] Iteration 67624, lr = 0.003
I0524 03:22:56.121592 15289 solver.cpp:237] Iteration 67838, loss = 0.950067
I0524 03:22:56.121636 15289 solver.cpp:253]     Train net output #0: loss = 0.950067 (* 1 = 0.950067 loss)
I0524 03:22:56.121654 15289 sgd_solver.cpp:106] Iteration 67838, lr = 0.003
I0524 03:23:04.989946 15289 solver.cpp:237] Iteration 68052, loss = 1.01537
I0524 03:23:04.990111 15289 solver.cpp:253]     Train net output #0: loss = 1.01537 (* 1 = 1.01537 loss)
I0524 03:23:04.990125 15289 sgd_solver.cpp:106] Iteration 68052, lr = 0.003
I0524 03:23:13.857543 15289 solver.cpp:237] Iteration 68266, loss = 0.957499
I0524 03:23:13.857579 15289 solver.cpp:253]     Train net output #0: loss = 0.957499 (* 1 = 0.957499 loss)
I0524 03:23:13.857596 15289 sgd_solver.cpp:106] Iteration 68266, lr = 0.003
I0524 03:23:22.721926 15289 solver.cpp:237] Iteration 68480, loss = 1.17438
I0524 03:23:22.721971 15289 solver.cpp:253]     Train net output #0: loss = 1.17438 (* 1 = 1.17438 loss)
I0524 03:23:22.721988 15289 sgd_solver.cpp:106] Iteration 68480, lr = 0.003
I0524 03:23:25.333983 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_68544.caffemodel
I0524 03:23:25.400288 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_68544.solverstate
I0524 03:23:26.061888 15289 solver.cpp:341] Iteration 68560, Testing net (#0)
I0524 03:24:34.891923 15289 solver.cpp:409]     Test net output #0: accuracy = 0.890676
I0524 03:24:34.892107 15289 solver.cpp:409]     Test net output #1: loss = 0.335936 (* 1 = 0.335936 loss)
I0524 03:25:01.412427 15289 solver.cpp:237] Iteration 68694, loss = 1.07623
I0524 03:25:01.412477 15289 solver.cpp:253]     Train net output #0: loss = 1.07623 (* 1 = 1.07623 loss)
I0524 03:25:01.412493 15289 sgd_solver.cpp:106] Iteration 68694, lr = 0.003
I0524 03:25:10.307565 15289 solver.cpp:237] Iteration 68908, loss = 1.30582
I0524 03:25:10.307739 15289 solver.cpp:253]     Train net output #0: loss = 1.30582 (* 1 = 1.30582 loss)
I0524 03:25:10.307751 15289 sgd_solver.cpp:106] Iteration 68908, lr = 0.003
I0524 03:25:19.200484 15289 solver.cpp:237] Iteration 69122, loss = 1.35223
I0524 03:25:19.200518 15289 solver.cpp:253]     Train net output #0: loss = 1.35223 (* 1 = 1.35223 loss)
I0524 03:25:19.200536 15289 sgd_solver.cpp:106] Iteration 69122, lr = 0.003
I0524 03:25:28.096678 15289 solver.cpp:237] Iteration 69336, loss = 1.06252
I0524 03:25:28.096724 15289 solver.cpp:253]     Train net output #0: loss = 1.06252 (* 1 = 1.06252 loss)
I0524 03:25:28.096741 15289 sgd_solver.cpp:106] Iteration 69336, lr = 0.003
I0524 03:25:36.996526 15289 solver.cpp:237] Iteration 69550, loss = 1.24484
I0524 03:25:36.996561 15289 solver.cpp:253]     Train net output #0: loss = 1.24484 (* 1 = 1.24484 loss)
I0524 03:25:36.996578 15289 sgd_solver.cpp:106] Iteration 69550, lr = 0.003
I0524 03:25:45.900154 15289 solver.cpp:237] Iteration 69764, loss = 1.0639
I0524 03:25:45.900348 15289 solver.cpp:253]     Train net output #0: loss = 1.0639 (* 1 = 1.0639 loss)
I0524 03:25:45.900363 15289 sgd_solver.cpp:106] Iteration 69764, lr = 0.003
I0524 03:25:54.797372 15289 solver.cpp:237] Iteration 69978, loss = 1.28289
I0524 03:25:54.797406 15289 solver.cpp:253]     Train net output #0: loss = 1.28289 (* 1 = 1.28289 loss)
I0524 03:25:54.797425 15289 sgd_solver.cpp:106] Iteration 69978, lr = 0.003
I0524 03:26:24.611665 15289 solver.cpp:237] Iteration 70192, loss = 1.20773
I0524 03:26:24.611853 15289 solver.cpp:253]     Train net output #0: loss = 1.20773 (* 1 = 1.20773 loss)
I0524 03:26:24.611868 15289 sgd_solver.cpp:106] Iteration 70192, lr = 0.003
I0524 03:26:33.507794 15289 solver.cpp:237] Iteration 70406, loss = 1.10576
I0524 03:26:33.507829 15289 solver.cpp:253]     Train net output #0: loss = 1.10576 (* 1 = 1.10576 loss)
I0524 03:26:33.507846 15289 sgd_solver.cpp:106] Iteration 70406, lr = 0.003
I0524 03:26:42.400056 15289 solver.cpp:237] Iteration 70620, loss = 1.35899
I0524 03:26:42.400105 15289 solver.cpp:253]     Train net output #0: loss = 1.35899 (* 1 = 1.35899 loss)
I0524 03:26:42.400120 15289 sgd_solver.cpp:106] Iteration 70620, lr = 0.003
I0524 03:26:45.101528 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_70686.caffemodel
I0524 03:26:45.175495 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_70686.solverstate
I0524 03:26:51.368291 15289 solver.cpp:237] Iteration 70834, loss = 0.99567
I0524 03:26:51.368337 15289 solver.cpp:253]     Train net output #0: loss = 0.99567 (* 1 = 0.99567 loss)
I0524 03:26:51.368353 15289 sgd_solver.cpp:106] Iteration 70834, lr = 0.003
I0524 03:27:00.264197 15289 solver.cpp:237] Iteration 71048, loss = 1.07014
I0524 03:27:00.264380 15289 solver.cpp:253]     Train net output #0: loss = 1.07014 (* 1 = 1.07014 loss)
I0524 03:27:00.264394 15289 sgd_solver.cpp:106] Iteration 71048, lr = 0.003
I0524 03:27:09.162636 15289 solver.cpp:237] Iteration 71262, loss = 0.974656
I0524 03:27:09.162672 15289 solver.cpp:253]     Train net output #0: loss = 0.974656 (* 1 = 0.974656 loss)
I0524 03:27:09.162688 15289 sgd_solver.cpp:106] Iteration 71262, lr = 0.003
I0524 03:27:38.973388 15289 solver.cpp:237] Iteration 71476, loss = 1.05592
I0524 03:27:38.973578 15289 solver.cpp:253]     Train net output #0: loss = 1.05592 (* 1 = 1.05592 loss)
I0524 03:27:38.973592 15289 sgd_solver.cpp:106] Iteration 71476, lr = 0.003
I0524 03:27:47.868065 15289 solver.cpp:237] Iteration 71690, loss = 0.877151
I0524 03:27:47.868100 15289 solver.cpp:253]     Train net output #0: loss = 0.877151 (* 1 = 0.877151 loss)
I0524 03:27:47.868115 15289 sgd_solver.cpp:106] Iteration 71690, lr = 0.003
I0524 03:27:56.766222 15289 solver.cpp:237] Iteration 71904, loss = 1.22767
I0524 03:27:56.766257 15289 solver.cpp:253]     Train net output #0: loss = 1.22767 (* 1 = 1.22767 loss)
I0524 03:27:56.766278 15289 sgd_solver.cpp:106] Iteration 71904, lr = 0.003
I0524 03:28:05.671329 15289 solver.cpp:237] Iteration 72118, loss = 1.12597
I0524 03:28:05.671365 15289 solver.cpp:253]     Train net output #0: loss = 1.12597 (* 1 = 1.12597 loss)
I0524 03:28:05.671378 15289 sgd_solver.cpp:106] Iteration 72118, lr = 0.003
I0524 03:28:14.573684 15289 solver.cpp:237] Iteration 72332, loss = 0.91191
I0524 03:28:14.573853 15289 solver.cpp:253]     Train net output #0: loss = 0.91191 (* 1 = 0.91191 loss)
I0524 03:28:14.573868 15289 sgd_solver.cpp:106] Iteration 72332, lr = 0.003
I0524 03:28:23.472659 15289 solver.cpp:237] Iteration 72546, loss = 1.0256
I0524 03:28:23.472693 15289 solver.cpp:253]     Train net output #0: loss = 1.0256 (* 1 = 1.0256 loss)
I0524 03:28:23.472710 15289 sgd_solver.cpp:106] Iteration 72546, lr = 0.003
I0524 03:28:32.366857 15289 solver.cpp:237] Iteration 72760, loss = 1.11917
I0524 03:28:32.366891 15289 solver.cpp:253]     Train net output #0: loss = 1.11917 (* 1 = 1.11917 loss)
I0524 03:28:32.366907 15289 sgd_solver.cpp:106] Iteration 72760, lr = 0.003
I0524 03:28:35.154232 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_72828.caffemodel
I0524 03:28:35.221225 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_72828.solverstate
I0524 03:28:35.927868 15289 solver.cpp:341] Iteration 72845, Testing net (#0)
I0524 03:29:23.923192 15289 solver.cpp:409]     Test net output #0: accuracy = 0.891256
I0524 03:29:23.923390 15289 solver.cpp:409]     Test net output #1: loss = 0.351831 (* 1 = 0.351831 loss)
I0524 03:29:50.207469 15289 solver.cpp:237] Iteration 72974, loss = 1.26055
I0524 03:29:50.207520 15289 solver.cpp:253]     Train net output #0: loss = 1.26055 (* 1 = 1.26055 loss)
I0524 03:29:50.207536 15289 sgd_solver.cpp:106] Iteration 72974, lr = 0.003
I0524 03:29:59.081914 15289 solver.cpp:237] Iteration 73188, loss = 0.805618
I0524 03:29:59.082092 15289 solver.cpp:253]     Train net output #0: loss = 0.805618 (* 1 = 0.805618 loss)
I0524 03:29:59.082105 15289 sgd_solver.cpp:106] Iteration 73188, lr = 0.003
I0524 03:30:07.954856 15289 solver.cpp:237] Iteration 73402, loss = 1.3169
I0524 03:30:07.954890 15289 solver.cpp:253]     Train net output #0: loss = 1.3169 (* 1 = 1.3169 loss)
I0524 03:30:07.954908 15289 sgd_solver.cpp:106] Iteration 73402, lr = 0.003
I0524 03:30:16.827183 15289 solver.cpp:237] Iteration 73616, loss = 0.981548
I0524 03:30:16.827219 15289 solver.cpp:253]     Train net output #0: loss = 0.981548 (* 1 = 0.981548 loss)
I0524 03:30:16.827234 15289 sgd_solver.cpp:106] Iteration 73616, lr = 0.003
I0524 03:30:25.702595 15289 solver.cpp:237] Iteration 73830, loss = 1.11521
I0524 03:30:25.702630 15289 solver.cpp:253]     Train net output #0: loss = 1.11521 (* 1 = 1.11521 loss)
I0524 03:30:25.702651 15289 sgd_solver.cpp:106] Iteration 73830, lr = 0.003
I0524 03:30:34.576056 15289 solver.cpp:237] Iteration 74044, loss = 1.16105
I0524 03:30:34.576220 15289 solver.cpp:253]     Train net output #0: loss = 1.16105 (* 1 = 1.16105 loss)
I0524 03:30:34.576234 15289 sgd_solver.cpp:106] Iteration 74044, lr = 0.003
I0524 03:30:43.451822 15289 solver.cpp:237] Iteration 74258, loss = 0.872603
I0524 03:30:43.451858 15289 solver.cpp:253]     Train net output #0: loss = 0.872603 (* 1 = 0.872603 loss)
I0524 03:30:43.451874 15289 sgd_solver.cpp:106] Iteration 74258, lr = 0.003
I0524 03:31:13.259832 15289 solver.cpp:237] Iteration 74472, loss = 1.0882
I0524 03:31:13.260020 15289 solver.cpp:253]     Train net output #0: loss = 1.0882 (* 1 = 1.0882 loss)
I0524 03:31:13.260035 15289 sgd_solver.cpp:106] Iteration 74472, lr = 0.003
I0524 03:31:22.135032 15289 solver.cpp:237] Iteration 74686, loss = 1.19911
I0524 03:31:22.135066 15289 solver.cpp:253]     Train net output #0: loss = 1.19911 (* 1 = 1.19911 loss)
I0524 03:31:22.135083 15289 sgd_solver.cpp:106] Iteration 74686, lr = 0.003
I0524 03:31:31.013620 15289 solver.cpp:237] Iteration 74900, loss = 1.08358
I0524 03:31:31.013655 15289 solver.cpp:253]     Train net output #0: loss = 1.08358 (* 1 = 1.08358 loss)
I0524 03:31:31.013671 15289 sgd_solver.cpp:106] Iteration 74900, lr = 0.003
I0524 03:31:33.872802 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_74970.caffemodel
I0524 03:31:33.941097 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_74970.solverstate
I0524 03:31:39.954874 15289 solver.cpp:237] Iteration 75114, loss = 1.27828
I0524 03:31:39.954921 15289 solver.cpp:253]     Train net output #0: loss = 1.27828 (* 1 = 1.27828 loss)
I0524 03:31:39.954939 15289 sgd_solver.cpp:106] Iteration 75114, lr = 0.003
I0524 03:31:48.834283 15289 solver.cpp:237] Iteration 75328, loss = 1.10241
I0524 03:31:48.834465 15289 solver.cpp:253]     Train net output #0: loss = 1.10241 (* 1 = 1.10241 loss)
I0524 03:31:48.834480 15289 sgd_solver.cpp:106] Iteration 75328, lr = 0.003
I0524 03:31:57.711283 15289 solver.cpp:237] Iteration 75542, loss = 1.12252
I0524 03:31:57.711318 15289 solver.cpp:253]     Train net output #0: loss = 1.12252 (* 1 = 1.12252 loss)
I0524 03:31:57.711335 15289 sgd_solver.cpp:106] Iteration 75542, lr = 0.003
I0524 03:32:27.528595 15289 solver.cpp:237] Iteration 75756, loss = 1.34966
I0524 03:32:27.528795 15289 solver.cpp:253]     Train net output #0: loss = 1.34966 (* 1 = 1.34966 loss)
I0524 03:32:27.528810 15289 sgd_solver.cpp:106] Iteration 75756, lr = 0.003
I0524 03:32:36.400418 15289 solver.cpp:237] Iteration 75970, loss = 1.0645
I0524 03:32:36.400452 15289 solver.cpp:253]     Train net output #0: loss = 1.0645 (* 1 = 1.0645 loss)
I0524 03:32:36.400470 15289 sgd_solver.cpp:106] Iteration 75970, lr = 0.003
I0524 03:32:45.277601 15289 solver.cpp:237] Iteration 76184, loss = 0.881386
I0524 03:32:45.277637 15289 solver.cpp:253]     Train net output #0: loss = 0.881386 (* 1 = 0.881386 loss)
I0524 03:32:45.277652 15289 sgd_solver.cpp:106] Iteration 76184, lr = 0.003
I0524 03:32:54.157202 15289 solver.cpp:237] Iteration 76398, loss = 1.35843
I0524 03:32:54.157243 15289 solver.cpp:253]     Train net output #0: loss = 1.35843 (* 1 = 1.35843 loss)
I0524 03:32:54.157264 15289 sgd_solver.cpp:106] Iteration 76398, lr = 0.003
I0524 03:33:03.030237 15289 solver.cpp:237] Iteration 76612, loss = 1.20128
I0524 03:33:03.030405 15289 solver.cpp:253]     Train net output #0: loss = 1.20128 (* 1 = 1.20128 loss)
I0524 03:33:03.030418 15289 sgd_solver.cpp:106] Iteration 76612, lr = 0.003
I0524 03:33:11.899659 15289 solver.cpp:237] Iteration 76826, loss = 1.33833
I0524 03:33:11.899693 15289 solver.cpp:253]     Train net output #0: loss = 1.33833 (* 1 = 1.33833 loss)
I0524 03:33:11.899711 15289 sgd_solver.cpp:106] Iteration 76826, lr = 0.003
I0524 03:33:20.772593 15289 solver.cpp:237] Iteration 77040, loss = 1.22103
I0524 03:33:20.772636 15289 solver.cpp:253]     Train net output #0: loss = 1.22103 (* 1 = 1.22103 loss)
I0524 03:33:20.772653 15289 sgd_solver.cpp:106] Iteration 77040, lr = 0.003
I0524 03:33:23.716001 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_77112.caffemodel
I0524 03:33:23.784477 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_77112.solverstate
I0524 03:33:24.530346 15289 solver.cpp:341] Iteration 77130, Testing net (#0)
I0524 03:34:33.432903 15289 solver.cpp:409]     Test net output #0: accuracy = 0.890983
I0524 03:34:33.433090 15289 solver.cpp:409]     Test net output #1: loss = 0.362312 (* 1 = 0.362312 loss)
I0524 03:34:59.508632 15289 solver.cpp:237] Iteration 77254, loss = 1.15282
I0524 03:34:59.508682 15289 solver.cpp:253]     Train net output #0: loss = 1.15282 (* 1 = 1.15282 loss)
I0524 03:34:59.508699 15289 sgd_solver.cpp:106] Iteration 77254, lr = 0.003
I0524 03:35:08.385952 15289 solver.cpp:237] Iteration 77468, loss = 1.09798
I0524 03:35:08.386128 15289 solver.cpp:253]     Train net output #0: loss = 1.09798 (* 1 = 1.09798 loss)
I0524 03:35:08.386142 15289 sgd_solver.cpp:106] Iteration 77468, lr = 0.003
I0524 03:35:17.270793 15289 solver.cpp:237] Iteration 77682, loss = 1.09742
I0524 03:35:17.270828 15289 solver.cpp:253]     Train net output #0: loss = 1.09742 (* 1 = 1.09742 loss)
I0524 03:35:17.270843 15289 sgd_solver.cpp:106] Iteration 77682, lr = 0.003
I0524 03:35:26.145740 15289 solver.cpp:237] Iteration 77896, loss = 1.08764
I0524 03:35:26.145787 15289 solver.cpp:253]     Train net output #0: loss = 1.08764 (* 1 = 1.08764 loss)
I0524 03:35:26.145802 15289 sgd_solver.cpp:106] Iteration 77896, lr = 0.003
I0524 03:35:35.027109 15289 solver.cpp:237] Iteration 78110, loss = 1.05045
I0524 03:35:35.027145 15289 solver.cpp:253]     Train net output #0: loss = 1.05045 (* 1 = 1.05045 loss)
I0524 03:35:35.027158 15289 sgd_solver.cpp:106] Iteration 78110, lr = 0.003
I0524 03:35:43.907356 15289 solver.cpp:237] Iteration 78324, loss = 1.07343
I0524 03:35:43.907536 15289 solver.cpp:253]     Train net output #0: loss = 1.07343 (* 1 = 1.07343 loss)
I0524 03:35:43.907551 15289 sgd_solver.cpp:106] Iteration 78324, lr = 0.003
I0524 03:35:52.783341 15289 solver.cpp:237] Iteration 78538, loss = 1.23734
I0524 03:35:52.783383 15289 solver.cpp:253]     Train net output #0: loss = 1.23734 (* 1 = 1.23734 loss)
I0524 03:35:52.783402 15289 sgd_solver.cpp:106] Iteration 78538, lr = 0.003
I0524 03:36:22.575264 15289 solver.cpp:237] Iteration 78752, loss = 1.18621
I0524 03:36:22.575455 15289 solver.cpp:253]     Train net output #0: loss = 1.18621 (* 1 = 1.18621 loss)
I0524 03:36:22.575469 15289 sgd_solver.cpp:106] Iteration 78752, lr = 0.003
I0524 03:36:31.467424 15289 solver.cpp:237] Iteration 78966, loss = 1.26203
I0524 03:36:31.467458 15289 solver.cpp:253]     Train net output #0: loss = 1.26203 (* 1 = 1.26203 loss)
I0524 03:36:31.467478 15289 sgd_solver.cpp:106] Iteration 78966, lr = 0.003
I0524 03:36:40.350765 15289 solver.cpp:237] Iteration 79180, loss = 1.22239
I0524 03:36:40.350805 15289 solver.cpp:253]     Train net output #0: loss = 1.22239 (* 1 = 1.22239 loss)
I0524 03:36:40.350826 15289 sgd_solver.cpp:106] Iteration 79180, lr = 0.003
I0524 03:36:43.382035 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_79254.caffemodel
I0524 03:36:43.448761 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_79254.solverstate
I0524 03:36:49.299849 15289 solver.cpp:237] Iteration 79394, loss = 1.26281
I0524 03:36:49.299896 15289 solver.cpp:253]     Train net output #0: loss = 1.26281 (* 1 = 1.26281 loss)
I0524 03:36:49.299912 15289 sgd_solver.cpp:106] Iteration 79394, lr = 0.003
I0524 03:36:58.184728 15289 solver.cpp:237] Iteration 79608, loss = 1.03466
I0524 03:36:58.184911 15289 solver.cpp:253]     Train net output #0: loss = 1.03466 (* 1 = 1.03466 loss)
I0524 03:36:58.184924 15289 sgd_solver.cpp:106] Iteration 79608, lr = 0.003
I0524 03:37:07.061112 15289 solver.cpp:237] Iteration 79822, loss = 1.0752
I0524 03:37:07.061154 15289 solver.cpp:253]     Train net output #0: loss = 1.0752 (* 1 = 1.0752 loss)
I0524 03:37:07.061168 15289 sgd_solver.cpp:106] Iteration 79822, lr = 0.003
I0524 03:37:36.876471 15289 solver.cpp:237] Iteration 80036, loss = 1.09184
I0524 03:37:36.876665 15289 solver.cpp:253]     Train net output #0: loss = 1.09184 (* 1 = 1.09184 loss)
I0524 03:37:36.876679 15289 sgd_solver.cpp:106] Iteration 80036, lr = 0.003
I0524 03:37:45.753957 15289 solver.cpp:237] Iteration 80250, loss = 1.19819
I0524 03:37:45.753991 15289 solver.cpp:253]     Train net output #0: loss = 1.19819 (* 1 = 1.19819 loss)
I0524 03:37:45.754010 15289 sgd_solver.cpp:106] Iteration 80250, lr = 0.003
I0524 03:37:54.630102 15289 solver.cpp:237] Iteration 80464, loss = 1.1578
I0524 03:37:54.630143 15289 solver.cpp:253]     Train net output #0: loss = 1.1578 (* 1 = 1.1578 loss)
I0524 03:37:54.630165 15289 sgd_solver.cpp:106] Iteration 80464, lr = 0.003
I0524 03:38:03.509533 15289 solver.cpp:237] Iteration 80678, loss = 1.26895
I0524 03:38:03.509569 15289 solver.cpp:253]     Train net output #0: loss = 1.26895 (* 1 = 1.26895 loss)
I0524 03:38:03.509587 15289 sgd_solver.cpp:106] Iteration 80678, lr = 0.003
I0524 03:38:12.393945 15289 solver.cpp:237] Iteration 80892, loss = 1.25511
I0524 03:38:12.394112 15289 solver.cpp:253]     Train net output #0: loss = 1.25511 (* 1 = 1.25511 loss)
I0524 03:38:12.394126 15289 sgd_solver.cpp:106] Iteration 80892, lr = 0.003
I0524 03:38:21.274710 15289 solver.cpp:237] Iteration 81106, loss = 1.00484
I0524 03:38:21.274752 15289 solver.cpp:253]     Train net output #0: loss = 1.00484 (* 1 = 1.00484 loss)
I0524 03:38:21.274775 15289 sgd_solver.cpp:106] Iteration 81106, lr = 0.003
I0524 03:38:30.155405 15289 solver.cpp:237] Iteration 81320, loss = 1.01426
I0524 03:38:30.155442 15289 solver.cpp:253]     Train net output #0: loss = 1.01426 (* 1 = 1.01426 loss)
I0524 03:38:30.155458 15289 sgd_solver.cpp:106] Iteration 81320, lr = 0.003
I0524 03:38:33.264327 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_81396.caffemodel
I0524 03:38:33.331032 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_81396.solverstate
I0524 03:38:34.118064 15289 solver.cpp:341] Iteration 81415, Testing net (#0)
I0524 03:39:21.740378 15289 solver.cpp:409]     Test net output #0: accuracy = 0.893818
I0524 03:39:21.740581 15289 solver.cpp:409]     Test net output #1: loss = 0.341196 (* 1 = 0.341196 loss)
I0524 03:39:47.590075 15289 solver.cpp:237] Iteration 81534, loss = 1.20966
I0524 03:39:47.590126 15289 solver.cpp:253]     Train net output #0: loss = 1.20966 (* 1 = 1.20966 loss)
I0524 03:39:47.590142 15289 sgd_solver.cpp:106] Iteration 81534, lr = 0.003
I0524 03:39:56.466614 15289 solver.cpp:237] Iteration 81748, loss = 1.2728
I0524 03:39:56.466804 15289 solver.cpp:253]     Train net output #0: loss = 1.2728 (* 1 = 1.2728 loss)
I0524 03:39:56.466817 15289 sgd_solver.cpp:106] Iteration 81748, lr = 0.003
I0524 03:40:05.337507 15289 solver.cpp:237] Iteration 81962, loss = 1.23964
I0524 03:40:05.337543 15289 solver.cpp:253]     Train net output #0: loss = 1.23964 (* 1 = 1.23964 loss)
I0524 03:40:05.337559 15289 sgd_solver.cpp:106] Iteration 81962, lr = 0.003
I0524 03:40:14.218708 15289 solver.cpp:237] Iteration 82176, loss = 1.3074
I0524 03:40:14.218744 15289 solver.cpp:253]     Train net output #0: loss = 1.3074 (* 1 = 1.3074 loss)
I0524 03:40:14.218756 15289 sgd_solver.cpp:106] Iteration 82176, lr = 0.003
I0524 03:40:23.097808 15289 solver.cpp:237] Iteration 82390, loss = 1.15531
I0524 03:40:23.097849 15289 solver.cpp:253]     Train net output #0: loss = 1.15531 (* 1 = 1.15531 loss)
I0524 03:40:23.097867 15289 sgd_solver.cpp:106] Iteration 82390, lr = 0.003
I0524 03:40:31.975162 15289 solver.cpp:237] Iteration 82604, loss = 1.00112
I0524 03:40:31.975343 15289 solver.cpp:253]     Train net output #0: loss = 1.00112 (* 1 = 1.00112 loss)
I0524 03:40:31.975358 15289 sgd_solver.cpp:106] Iteration 82604, lr = 0.003
I0524 03:40:40.849584 15289 solver.cpp:237] Iteration 82818, loss = 1.12306
I0524 03:40:40.849618 15289 solver.cpp:253]     Train net output #0: loss = 1.12306 (* 1 = 1.12306 loss)
I0524 03:40:40.849635 15289 sgd_solver.cpp:106] Iteration 82818, lr = 0.003
I0524 03:41:10.648965 15289 solver.cpp:237] Iteration 83032, loss = 1.17955
I0524 03:41:10.649153 15289 solver.cpp:253]     Train net output #0: loss = 1.17955 (* 1 = 1.17955 loss)
I0524 03:41:10.649168 15289 sgd_solver.cpp:106] Iteration 83032, lr = 0.003
I0524 03:41:19.521589 15289 solver.cpp:237] Iteration 83246, loss = 0.948392
I0524 03:41:19.521625 15289 solver.cpp:253]     Train net output #0: loss = 0.948392 (* 1 = 0.948392 loss)
I0524 03:41:19.521638 15289 sgd_solver.cpp:106] Iteration 83246, lr = 0.003
I0524 03:41:28.401232 15289 solver.cpp:237] Iteration 83460, loss = 0.92185
I0524 03:41:28.401264 15289 solver.cpp:253]     Train net output #0: loss = 0.92185 (* 1 = 0.92185 loss)
I0524 03:41:28.401278 15289 sgd_solver.cpp:106] Iteration 83460, lr = 0.003
I0524 03:41:31.593267 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_83538.caffemodel
I0524 03:41:31.660046 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_83538.solverstate
I0524 03:41:37.352751 15289 solver.cpp:237] Iteration 83674, loss = 1.4695
I0524 03:41:37.352797 15289 solver.cpp:253]     Train net output #0: loss = 1.4695 (* 1 = 1.4695 loss)
I0524 03:41:37.352816 15289 sgd_solver.cpp:106] Iteration 83674, lr = 0.003
I0524 03:41:46.234076 15289 solver.cpp:237] Iteration 83888, loss = 1.11494
I0524 03:41:46.234261 15289 solver.cpp:253]     Train net output #0: loss = 1.11494 (* 1 = 1.11494 loss)
I0524 03:41:46.234273 15289 sgd_solver.cpp:106] Iteration 83888, lr = 0.003
I0524 03:41:55.110694 15289 solver.cpp:237] Iteration 84102, loss = 1.10677
I0524 03:41:55.110729 15289 solver.cpp:253]     Train net output #0: loss = 1.10677 (* 1 = 1.10677 loss)
I0524 03:41:55.110743 15289 sgd_solver.cpp:106] Iteration 84102, lr = 0.003
I0524 03:42:24.922314 15289 solver.cpp:237] Iteration 84316, loss = 0.966972
I0524 03:42:24.922515 15289 solver.cpp:253]     Train net output #0: loss = 0.966972 (* 1 = 0.966972 loss)
I0524 03:42:24.922531 15289 sgd_solver.cpp:106] Iteration 84316, lr = 0.003
I0524 03:42:33.803805 15289 solver.cpp:237] Iteration 84530, loss = 1.06477
I0524 03:42:33.803839 15289 solver.cpp:253]     Train net output #0: loss = 1.06477 (* 1 = 1.06477 loss)
I0524 03:42:33.803855 15289 sgd_solver.cpp:106] Iteration 84530, lr = 0.003
I0524 03:42:42.686264 15289 solver.cpp:237] Iteration 84744, loss = 1.03477
I0524 03:42:42.686298 15289 solver.cpp:253]     Train net output #0: loss = 1.03477 (* 1 = 1.03477 loss)
I0524 03:42:42.686316 15289 sgd_solver.cpp:106] Iteration 84744, lr = 0.003
I0524 03:42:51.566184 15289 solver.cpp:237] Iteration 84958, loss = 0.952983
I0524 03:42:51.566222 15289 solver.cpp:253]     Train net output #0: loss = 0.952983 (* 1 = 0.952983 loss)
I0524 03:42:51.566242 15289 sgd_solver.cpp:106] Iteration 84958, lr = 0.003
I0524 03:43:00.444383 15289 solver.cpp:237] Iteration 85172, loss = 0.956012
I0524 03:43:00.444551 15289 solver.cpp:253]     Train net output #0: loss = 0.956012 (* 1 = 0.956012 loss)
I0524 03:43:00.444566 15289 sgd_solver.cpp:106] Iteration 85172, lr = 0.003
I0524 03:43:09.321698 15289 solver.cpp:237] Iteration 85386, loss = 1.16346
I0524 03:43:09.321733 15289 solver.cpp:253]     Train net output #0: loss = 1.16346 (* 1 = 1.16346 loss)
I0524 03:43:09.321750 15289 sgd_solver.cpp:106] Iteration 85386, lr = 0.003
I0524 03:43:18.201354 15289 solver.cpp:237] Iteration 85600, loss = 1.12946
I0524 03:43:18.201398 15289 solver.cpp:253]     Train net output #0: loss = 1.12946 (* 1 = 1.12946 loss)
I0524 03:43:18.201416 15289 sgd_solver.cpp:106] Iteration 85600, lr = 0.003
I0524 03:43:21.477051 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_85680.caffemodel
I0524 03:43:21.546525 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_85680.solverstate
I0524 03:43:22.376760 15289 solver.cpp:341] Iteration 85700, Testing net (#0)
I0524 03:44:31.237177 15289 solver.cpp:409]     Test net output #0: accuracy = 0.894264
I0524 03:44:31.237368 15289 solver.cpp:409]     Test net output #1: loss = 0.335973 (* 1 = 0.335973 loss)
I0524 03:44:56.935858 15289 solver.cpp:237] Iteration 85814, loss = 1.11403
I0524 03:44:56.935905 15289 solver.cpp:253]     Train net output #0: loss = 1.11403 (* 1 = 1.11403 loss)
I0524 03:44:56.935923 15289 sgd_solver.cpp:106] Iteration 85814, lr = 0.003
I0524 03:45:05.804134 15289 solver.cpp:237] Iteration 86028, loss = 0.976287
I0524 03:45:05.804311 15289 solver.cpp:253]     Train net output #0: loss = 0.976287 (* 1 = 0.976287 loss)
I0524 03:45:05.804324 15289 sgd_solver.cpp:106] Iteration 86028, lr = 0.003
I0524 03:45:14.670455 15289 solver.cpp:237] Iteration 86242, loss = 1.14618
I0524 03:45:14.670490 15289 solver.cpp:253]     Train net output #0: loss = 1.14618 (* 1 = 1.14618 loss)
I0524 03:45:14.670508 15289 sgd_solver.cpp:106] Iteration 86242, lr = 0.003
I0524 03:45:23.543598 15289 solver.cpp:237] Iteration 86456, loss = 1.1838
I0524 03:45:23.543644 15289 solver.cpp:253]     Train net output #0: loss = 1.1838 (* 1 = 1.1838 loss)
I0524 03:45:23.543660 15289 sgd_solver.cpp:106] Iteration 86456, lr = 0.003
I0524 03:45:32.405134 15289 solver.cpp:237] Iteration 86670, loss = 1.09933
I0524 03:45:32.405170 15289 solver.cpp:253]     Train net output #0: loss = 1.09933 (* 1 = 1.09933 loss)
I0524 03:45:32.405186 15289 sgd_solver.cpp:106] Iteration 86670, lr = 0.003
I0524 03:45:41.270874 15289 solver.cpp:237] Iteration 86884, loss = 1.17457
I0524 03:45:41.271055 15289 solver.cpp:253]     Train net output #0: loss = 1.17457 (* 1 = 1.17457 loss)
I0524 03:45:41.271070 15289 sgd_solver.cpp:106] Iteration 86884, lr = 0.003
I0524 03:45:50.135833 15289 solver.cpp:237] Iteration 87098, loss = 0.978054
I0524 03:45:50.135879 15289 solver.cpp:253]     Train net output #0: loss = 0.978054 (* 1 = 0.978054 loss)
I0524 03:45:50.135895 15289 sgd_solver.cpp:106] Iteration 87098, lr = 0.003
I0524 03:46:19.908345 15289 solver.cpp:237] Iteration 87312, loss = 1.26122
I0524 03:46:19.908540 15289 solver.cpp:253]     Train net output #0: loss = 1.26122 (* 1 = 1.26122 loss)
I0524 03:46:19.908555 15289 sgd_solver.cpp:106] Iteration 87312, lr = 0.003
I0524 03:46:28.775135 15289 solver.cpp:237] Iteration 87526, loss = 1.03278
I0524 03:46:28.775169 15289 solver.cpp:253]     Train net output #0: loss = 1.03278 (* 1 = 1.03278 loss)
I0524 03:46:28.775188 15289 sgd_solver.cpp:106] Iteration 87526, lr = 0.003
I0524 03:46:37.639199 15289 solver.cpp:237] Iteration 87740, loss = 0.995808
I0524 03:46:37.639242 15289 solver.cpp:253]     Train net output #0: loss = 0.995808 (* 1 = 0.995808 loss)
I0524 03:46:37.639259 15289 sgd_solver.cpp:106] Iteration 87740, lr = 0.003
I0524 03:46:40.996744 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_87822.caffemodel
I0524 03:46:41.063432 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_87822.solverstate
I0524 03:46:46.577188 15289 solver.cpp:237] Iteration 87954, loss = 1.32216
I0524 03:46:46.577234 15289 solver.cpp:253]     Train net output #0: loss = 1.32216 (* 1 = 1.32216 loss)
I0524 03:46:46.577250 15289 sgd_solver.cpp:106] Iteration 87954, lr = 0.003
I0524 03:46:55.441023 15289 solver.cpp:237] Iteration 88168, loss = 1.16693
I0524 03:46:55.441200 15289 solver.cpp:253]     Train net output #0: loss = 1.16693 (* 1 = 1.16693 loss)
I0524 03:46:55.441213 15289 sgd_solver.cpp:106] Iteration 88168, lr = 0.003
I0524 03:47:04.310855 15289 solver.cpp:237] Iteration 88382, loss = 0.921996
I0524 03:47:04.310902 15289 solver.cpp:253]     Train net output #0: loss = 0.921996 (* 1 = 0.921996 loss)
I0524 03:47:04.310920 15289 sgd_solver.cpp:106] Iteration 88382, lr = 0.003
I0524 03:47:34.097579 15289 solver.cpp:237] Iteration 88596, loss = 1.01421
I0524 03:47:34.097772 15289 solver.cpp:253]     Train net output #0: loss = 1.01421 (* 1 = 1.01421 loss)
I0524 03:47:34.097786 15289 sgd_solver.cpp:106] Iteration 88596, lr = 0.003
I0524 03:47:42.957350 15289 solver.cpp:237] Iteration 88810, loss = 1.02896
I0524 03:47:42.957384 15289 solver.cpp:253]     Train net output #0: loss = 1.02896 (* 1 = 1.02896 loss)
I0524 03:47:42.957402 15289 sgd_solver.cpp:106] Iteration 88810, lr = 0.003
I0524 03:47:51.826738 15289 solver.cpp:237] Iteration 89024, loss = 1.33202
I0524 03:47:51.826786 15289 solver.cpp:253]     Train net output #0: loss = 1.33202 (* 1 = 1.33202 loss)
I0524 03:47:51.826803 15289 sgd_solver.cpp:106] Iteration 89024, lr = 0.003
I0524 03:48:00.693992 15289 solver.cpp:237] Iteration 89238, loss = 1.09425
I0524 03:48:00.694030 15289 solver.cpp:253]     Train net output #0: loss = 1.09425 (* 1 = 1.09425 loss)
I0524 03:48:00.694044 15289 sgd_solver.cpp:106] Iteration 89238, lr = 0.003
I0524 03:48:09.555915 15289 solver.cpp:237] Iteration 89452, loss = 1.1075
I0524 03:48:09.556102 15289 solver.cpp:253]     Train net output #0: loss = 1.1075 (* 1 = 1.1075 loss)
I0524 03:48:09.556115 15289 sgd_solver.cpp:106] Iteration 89452, lr = 0.003
I0524 03:48:18.424206 15289 solver.cpp:237] Iteration 89666, loss = 1.07627
I0524 03:48:18.424250 15289 solver.cpp:253]     Train net output #0: loss = 1.07627 (* 1 = 1.07627 loss)
I0524 03:48:18.424264 15289 sgd_solver.cpp:106] Iteration 89666, lr = 0.003
I0524 03:48:27.287757 15289 solver.cpp:237] Iteration 89880, loss = 0.992333
I0524 03:48:27.287796 15289 solver.cpp:253]     Train net output #0: loss = 0.992333 (* 1 = 0.992333 loss)
I0524 03:48:27.287811 15289 sgd_solver.cpp:106] Iteration 89880, lr = 0.003
I0524 03:48:30.730702 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_89964.caffemodel
I0524 03:48:30.797235 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_89964.solverstate
I0524 03:48:31.665057 15289 solver.cpp:341] Iteration 89985, Testing net (#0)
I0524 03:49:19.587378 15289 solver.cpp:409]     Test net output #0: accuracy = 0.894891
I0524 03:49:19.587569 15289 solver.cpp:409]     Test net output #1: loss = 0.338775 (* 1 = 0.338775 loss)
I0524 03:49:45.056718 15289 solver.cpp:237] Iteration 90094, loss = 1.11768
I0524 03:49:45.056769 15289 solver.cpp:253]     Train net output #0: loss = 1.11768 (* 1 = 1.11768 loss)
I0524 03:49:45.056785 15289 sgd_solver.cpp:106] Iteration 90094, lr = 0.003
I0524 03:49:53.943965 15289 solver.cpp:237] Iteration 90308, loss = 0.97997
I0524 03:49:53.944147 15289 solver.cpp:253]     Train net output #0: loss = 0.97997 (* 1 = 0.97997 loss)
I0524 03:49:53.944160 15289 sgd_solver.cpp:106] Iteration 90308, lr = 0.003
I0524 03:50:02.834957 15289 solver.cpp:237] Iteration 90522, loss = 1.05307
I0524 03:50:02.835002 15289 solver.cpp:253]     Train net output #0: loss = 1.05307 (* 1 = 1.05307 loss)
I0524 03:50:02.835019 15289 sgd_solver.cpp:106] Iteration 90522, lr = 0.003
I0524 03:50:11.721519 15289 solver.cpp:237] Iteration 90736, loss = 1.17662
I0524 03:50:11.721554 15289 solver.cpp:253]     Train net output #0: loss = 1.17662 (* 1 = 1.17662 loss)
I0524 03:50:11.721572 15289 sgd_solver.cpp:106] Iteration 90736, lr = 0.003
I0524 03:50:20.602877 15289 solver.cpp:237] Iteration 90950, loss = 1.1967
I0524 03:50:20.602918 15289 solver.cpp:253]     Train net output #0: loss = 1.1967 (* 1 = 1.1967 loss)
I0524 03:50:20.602939 15289 sgd_solver.cpp:106] Iteration 90950, lr = 0.003
I0524 03:50:29.487848 15289 solver.cpp:237] Iteration 91164, loss = 1.13512
I0524 03:50:29.488019 15289 solver.cpp:253]     Train net output #0: loss = 1.13512 (* 1 = 1.13512 loss)
I0524 03:50:29.488034 15289 sgd_solver.cpp:106] Iteration 91164, lr = 0.003
I0524 03:50:38.376895 15289 solver.cpp:237] Iteration 91378, loss = 1.22649
I0524 03:50:38.376930 15289 solver.cpp:253]     Train net output #0: loss = 1.22649 (* 1 = 1.22649 loss)
I0524 03:50:38.376948 15289 sgd_solver.cpp:106] Iteration 91378, lr = 0.003
I0524 03:51:08.152972 15289 solver.cpp:237] Iteration 91592, loss = 0.903942
I0524 03:51:08.153168 15289 solver.cpp:253]     Train net output #0: loss = 0.903942 (* 1 = 0.903942 loss)
I0524 03:51:08.153185 15289 sgd_solver.cpp:106] Iteration 91592, lr = 0.003
I0524 03:51:17.040725 15289 solver.cpp:237] Iteration 91806, loss = 1.16506
I0524 03:51:17.040766 15289 solver.cpp:253]     Train net output #0: loss = 1.16506 (* 1 = 1.16506 loss)
I0524 03:51:17.040784 15289 sgd_solver.cpp:106] Iteration 91806, lr = 0.003
I0524 03:51:25.924331 15289 solver.cpp:237] Iteration 92020, loss = 1.06946
I0524 03:51:25.924367 15289 solver.cpp:253]     Train net output #0: loss = 1.06946 (* 1 = 1.06946 loss)
I0524 03:51:25.924384 15289 sgd_solver.cpp:106] Iteration 92020, lr = 0.003
I0524 03:51:29.455569 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_92106.caffemodel
I0524 03:51:29.521935 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_92106.solverstate
I0524 03:51:34.874022 15289 solver.cpp:237] Iteration 92234, loss = 1.18509
I0524 03:51:34.874073 15289 solver.cpp:253]     Train net output #0: loss = 1.18509 (* 1 = 1.18509 loss)
I0524 03:51:34.874089 15289 sgd_solver.cpp:106] Iteration 92234, lr = 0.003
I0524 03:51:43.758117 15289 solver.cpp:237] Iteration 92448, loss = 1.1968
I0524 03:51:43.758306 15289 solver.cpp:253]     Train net output #0: loss = 1.1968 (* 1 = 1.1968 loss)
I0524 03:51:43.758321 15289 sgd_solver.cpp:106] Iteration 92448, lr = 0.003
I0524 03:51:52.645790 15289 solver.cpp:237] Iteration 92662, loss = 1.0274
I0524 03:51:52.645824 15289 solver.cpp:253]     Train net output #0: loss = 1.0274 (* 1 = 1.0274 loss)
I0524 03:51:52.645843 15289 sgd_solver.cpp:106] Iteration 92662, lr = 0.003
I0524 03:52:22.441328 15289 solver.cpp:237] Iteration 92876, loss = 1.27285
I0524 03:52:22.441526 15289 solver.cpp:253]     Train net output #0: loss = 1.27285 (* 1 = 1.27285 loss)
I0524 03:52:22.441542 15289 sgd_solver.cpp:106] Iteration 92876, lr = 0.003
I0524 03:52:31.323922 15289 solver.cpp:237] Iteration 93090, loss = 1.00118
I0524 03:52:31.323966 15289 solver.cpp:253]     Train net output #0: loss = 1.00118 (* 1 = 1.00118 loss)
I0524 03:52:31.323984 15289 sgd_solver.cpp:106] Iteration 93090, lr = 0.003
I0524 03:52:40.209810 15289 solver.cpp:237] Iteration 93304, loss = 1.1385
I0524 03:52:40.209846 15289 solver.cpp:253]     Train net output #0: loss = 1.1385 (* 1 = 1.1385 loss)
I0524 03:52:40.209861 15289 sgd_solver.cpp:106] Iteration 93304, lr = 0.003
I0524 03:52:49.102051 15289 solver.cpp:237] Iteration 93518, loss = 1.03729
I0524 03:52:49.102087 15289 solver.cpp:253]     Train net output #0: loss = 1.03729 (* 1 = 1.03729 loss)
I0524 03:52:49.102102 15289 sgd_solver.cpp:106] Iteration 93518, lr = 0.003
I0524 03:52:57.987911 15289 solver.cpp:237] Iteration 93732, loss = 1.00757
I0524 03:52:57.988104 15289 solver.cpp:253]     Train net output #0: loss = 1.00757 (* 1 = 1.00757 loss)
I0524 03:52:57.988118 15289 sgd_solver.cpp:106] Iteration 93732, lr = 0.003
I0524 03:53:06.874014 15289 solver.cpp:237] Iteration 93946, loss = 1.21121
I0524 03:53:06.874049 15289 solver.cpp:253]     Train net output #0: loss = 1.21121 (* 1 = 1.21121 loss)
I0524 03:53:06.874066 15289 sgd_solver.cpp:106] Iteration 93946, lr = 0.003
I0524 03:53:15.762673 15289 solver.cpp:237] Iteration 94160, loss = 1.20426
I0524 03:53:15.762722 15289 solver.cpp:253]     Train net output #0: loss = 1.20426 (* 1 = 1.20426 loss)
I0524 03:53:15.762738 15289 sgd_solver.cpp:106] Iteration 94160, lr = 0.003
I0524 03:53:19.377923 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_94248.caffemodel
I0524 03:53:19.443996 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_94248.solverstate
I0524 03:53:20.357882 15289 solver.cpp:341] Iteration 94270, Testing net (#0)
I0524 03:54:29.291692 15289 solver.cpp:409]     Test net output #0: accuracy = 0.896845
I0524 03:54:29.291888 15289 solver.cpp:409]     Test net output #1: loss = 0.33985 (* 1 = 0.33985 loss)
I0524 03:54:54.557631 15289 solver.cpp:237] Iteration 94374, loss = 1.1004
I0524 03:54:54.557682 15289 solver.cpp:253]     Train net output #0: loss = 1.1004 (* 1 = 1.1004 loss)
I0524 03:54:54.557700 15289 sgd_solver.cpp:106] Iteration 94374, lr = 0.003
I0524 03:55:03.424922 15289 solver.cpp:237] Iteration 94588, loss = 1.4116
I0524 03:55:03.425102 15289 solver.cpp:253]     Train net output #0: loss = 1.4116 (* 1 = 1.4116 loss)
I0524 03:55:03.425117 15289 sgd_solver.cpp:106] Iteration 94588, lr = 0.003
I0524 03:55:12.291179 15289 solver.cpp:237] Iteration 94802, loss = 1.43753
I0524 03:55:12.291213 15289 solver.cpp:253]     Train net output #0: loss = 1.43753 (* 1 = 1.43753 loss)
I0524 03:55:12.291230 15289 sgd_solver.cpp:106] Iteration 94802, lr = 0.003
I0524 03:55:21.159629 15289 solver.cpp:237] Iteration 95016, loss = 1.20512
I0524 03:55:21.159672 15289 solver.cpp:253]     Train net output #0: loss = 1.20512 (* 1 = 1.20512 loss)
I0524 03:55:21.159687 15289 sgd_solver.cpp:106] Iteration 95016, lr = 0.003
I0524 03:55:30.024127 15289 solver.cpp:237] Iteration 95230, loss = 0.983833
I0524 03:55:30.024164 15289 solver.cpp:253]     Train net output #0: loss = 0.983833 (* 1 = 0.983833 loss)
I0524 03:55:30.024179 15289 sgd_solver.cpp:106] Iteration 95230, lr = 0.003
I0524 03:55:38.889204 15289 solver.cpp:237] Iteration 95444, loss = 1.25244
I0524 03:55:38.889379 15289 solver.cpp:253]     Train net output #0: loss = 1.25244 (* 1 = 1.25244 loss)
I0524 03:55:38.889392 15289 sgd_solver.cpp:106] Iteration 95444, lr = 0.003
I0524 03:55:47.756767 15289 solver.cpp:237] Iteration 95658, loss = 1.01974
I0524 03:55:47.756811 15289 solver.cpp:253]     Train net output #0: loss = 1.01974 (* 1 = 1.01974 loss)
I0524 03:55:47.756824 15289 sgd_solver.cpp:106] Iteration 95658, lr = 0.003
I0524 03:56:17.541522 15289 solver.cpp:237] Iteration 95872, loss = 1.24248
I0524 03:56:17.541717 15289 solver.cpp:253]     Train net output #0: loss = 1.24248 (* 1 = 1.24248 loss)
I0524 03:56:17.541730 15289 sgd_solver.cpp:106] Iteration 95872, lr = 0.003
I0524 03:56:26.408576 15289 solver.cpp:237] Iteration 96086, loss = 1.15906
I0524 03:56:26.408610 15289 solver.cpp:253]     Train net output #0: loss = 1.15906 (* 1 = 1.15906 loss)
I0524 03:56:26.408627 15289 sgd_solver.cpp:106] Iteration 96086, lr = 0.003
I0524 03:56:35.277698 15289 solver.cpp:237] Iteration 96300, loss = 1.09785
I0524 03:56:35.277740 15289 solver.cpp:253]     Train net output #0: loss = 1.09785 (* 1 = 1.09785 loss)
I0524 03:56:35.277755 15289 sgd_solver.cpp:106] Iteration 96300, lr = 0.003
I0524 03:56:38.969147 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_96390.caffemodel
I0524 03:56:39.037346 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_96390.solverstate
I0524 03:56:44.217572 15289 solver.cpp:237] Iteration 96514, loss = 1.23148
I0524 03:56:44.217622 15289 solver.cpp:253]     Train net output #0: loss = 1.23148 (* 1 = 1.23148 loss)
I0524 03:56:44.217638 15289 sgd_solver.cpp:106] Iteration 96514, lr = 0.003
I0524 03:56:53.082367 15289 solver.cpp:237] Iteration 96728, loss = 1.14876
I0524 03:56:53.082550 15289 solver.cpp:253]     Train net output #0: loss = 1.14876 (* 1 = 1.14876 loss)
I0524 03:56:53.082563 15289 sgd_solver.cpp:106] Iteration 96728, lr = 0.003
I0524 03:57:01.949153 15289 solver.cpp:237] Iteration 96942, loss = 1.13285
I0524 03:57:01.949193 15289 solver.cpp:253]     Train net output #0: loss = 1.13285 (* 1 = 1.13285 loss)
I0524 03:57:01.949214 15289 sgd_solver.cpp:106] Iteration 96942, lr = 0.003
I0524 03:57:31.720525 15289 solver.cpp:237] Iteration 97156, loss = 1.23885
I0524 03:57:31.720723 15289 solver.cpp:253]     Train net output #0: loss = 1.23885 (* 1 = 1.23885 loss)
I0524 03:57:31.720737 15289 sgd_solver.cpp:106] Iteration 97156, lr = 0.003
I0524 03:57:40.588910 15289 solver.cpp:237] Iteration 97370, loss = 1.2037
I0524 03:57:40.588945 15289 solver.cpp:253]     Train net output #0: loss = 1.2037 (* 1 = 1.2037 loss)
I0524 03:57:40.588963 15289 sgd_solver.cpp:106] Iteration 97370, lr = 0.003
I0524 03:57:49.455998 15289 solver.cpp:237] Iteration 97584, loss = 1.11543
I0524 03:57:49.456046 15289 solver.cpp:253]     Train net output #0: loss = 1.11543 (* 1 = 1.11543 loss)
I0524 03:57:49.456063 15289 sgd_solver.cpp:106] Iteration 97584, lr = 0.003
I0524 03:57:58.326750 15289 solver.cpp:237] Iteration 97798, loss = 1.04961
I0524 03:57:58.326786 15289 solver.cpp:253]     Train net output #0: loss = 1.04961 (* 1 = 1.04961 loss)
I0524 03:57:58.326802 15289 sgd_solver.cpp:106] Iteration 97798, lr = 0.003
I0524 03:58:07.193672 15289 solver.cpp:237] Iteration 98012, loss = 1.6108
I0524 03:58:07.193859 15289 solver.cpp:253]     Train net output #0: loss = 1.6108 (* 1 = 1.6108 loss)
I0524 03:58:07.193873 15289 sgd_solver.cpp:106] Iteration 98012, lr = 0.003
I0524 03:58:16.063459 15289 solver.cpp:237] Iteration 98226, loss = 1.03113
I0524 03:58:16.063499 15289 solver.cpp:253]     Train net output #0: loss = 1.03113 (* 1 = 1.03113 loss)
I0524 03:58:16.063519 15289 sgd_solver.cpp:106] Iteration 98226, lr = 0.003
I0524 03:58:24.930310 15289 solver.cpp:237] Iteration 98440, loss = 1.01927
I0524 03:58:24.930346 15289 solver.cpp:253]     Train net output #0: loss = 1.01927 (* 1 = 1.01927 loss)
I0524 03:58:24.930361 15289 sgd_solver.cpp:106] Iteration 98440, lr = 0.003
I0524 03:58:28.704809 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_98532.caffemodel
I0524 03:58:28.771698 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_98532.solverstate
I0524 03:58:29.723548 15289 solver.cpp:341] Iteration 98555, Testing net (#0)
I0524 03:59:17.297092 15289 solver.cpp:409]     Test net output #0: accuracy = 0.897453
I0524 03:59:17.297289 15289 solver.cpp:409]     Test net output #1: loss = 0.336122 (* 1 = 0.336122 loss)
I0524 03:59:42.296197 15289 solver.cpp:237] Iteration 98654, loss = 0.913075
I0524 03:59:42.296248 15289 solver.cpp:253]     Train net output #0: loss = 0.913075 (* 1 = 0.913075 loss)
I0524 03:59:42.296264 15289 sgd_solver.cpp:106] Iteration 98654, lr = 0.003
I0524 03:59:51.194545 15289 solver.cpp:237] Iteration 98868, loss = 1.13043
I0524 03:59:51.194727 15289 solver.cpp:253]     Train net output #0: loss = 1.13043 (* 1 = 1.13043 loss)
I0524 03:59:51.194741 15289 sgd_solver.cpp:106] Iteration 98868, lr = 0.003
I0524 04:00:00.097018 15289 solver.cpp:237] Iteration 99082, loss = 1.12209
I0524 04:00:00.097062 15289 solver.cpp:253]     Train net output #0: loss = 1.12209 (* 1 = 1.12209 loss)
I0524 04:00:00.097081 15289 sgd_solver.cpp:106] Iteration 99082, lr = 0.003
I0524 04:00:08.993513 15289 solver.cpp:237] Iteration 99296, loss = 1.3081
I0524 04:00:08.993549 15289 solver.cpp:253]     Train net output #0: loss = 1.3081 (* 1 = 1.3081 loss)
I0524 04:00:08.993562 15289 sgd_solver.cpp:106] Iteration 99296, lr = 0.003
I0524 04:00:17.887547 15289 solver.cpp:237] Iteration 99510, loss = 1.288
I0524 04:00:17.887583 15289 solver.cpp:253]     Train net output #0: loss = 1.288 (* 1 = 1.288 loss)
I0524 04:00:17.887598 15289 sgd_solver.cpp:106] Iteration 99510, lr = 0.003
I0524 04:00:26.787030 15289 solver.cpp:237] Iteration 99724, loss = 1.12336
I0524 04:00:26.787230 15289 solver.cpp:253]     Train net output #0: loss = 1.12336 (* 1 = 1.12336 loss)
I0524 04:00:26.787243 15289 sgd_solver.cpp:106] Iteration 99724, lr = 0.003
I0524 04:00:35.692299 15289 solver.cpp:237] Iteration 99938, loss = 1.23935
I0524 04:00:35.692333 15289 solver.cpp:253]     Train net output #0: loss = 1.23935 (* 1 = 1.23935 loss)
I0524 04:00:35.692351 15289 sgd_solver.cpp:106] Iteration 99938, lr = 0.003
I0524 04:01:05.460114 15289 solver.cpp:237] Iteration 100152, loss = 1.06746
I0524 04:01:05.460309 15289 solver.cpp:253]     Train net output #0: loss = 1.06746 (* 1 = 1.06746 loss)
I0524 04:01:05.460325 15289 sgd_solver.cpp:106] Iteration 100152, lr = 0.003
I0524 04:01:14.358997 15289 solver.cpp:237] Iteration 100366, loss = 1.33368
I0524 04:01:14.359040 15289 solver.cpp:253]     Train net output #0: loss = 1.33368 (* 1 = 1.33368 loss)
I0524 04:01:14.359057 15289 sgd_solver.cpp:106] Iteration 100366, lr = 0.003
I0524 04:01:23.254922 15289 solver.cpp:237] Iteration 100580, loss = 1.23274
I0524 04:01:23.254957 15289 solver.cpp:253]     Train net output #0: loss = 1.23274 (* 1 = 1.23274 loss)
I0524 04:01:23.254971 15289 sgd_solver.cpp:106] Iteration 100580, lr = 0.003
I0524 04:01:27.124001 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_100674.caffemodel
I0524 04:01:27.191540 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_100674.solverstate
I0524 04:01:32.222136 15289 solver.cpp:237] Iteration 100794, loss = 1.0195
I0524 04:01:32.222179 15289 solver.cpp:253]     Train net output #0: loss = 1.0195 (* 1 = 1.0195 loss)
I0524 04:01:32.222199 15289 sgd_solver.cpp:106] Iteration 100794, lr = 0.003
I0524 04:01:41.120194 15289 solver.cpp:237] Iteration 101008, loss = 1.15314
I0524 04:01:41.120393 15289 solver.cpp:253]     Train net output #0: loss = 1.15314 (* 1 = 1.15314 loss)
I0524 04:01:41.120407 15289 sgd_solver.cpp:106] Iteration 101008, lr = 0.003
I0524 04:01:50.021630 15289 solver.cpp:237] Iteration 101222, loss = 0.945406
I0524 04:01:50.021664 15289 solver.cpp:253]     Train net output #0: loss = 0.945406 (* 1 = 0.945406 loss)
I0524 04:01:50.021682 15289 sgd_solver.cpp:106] Iteration 101222, lr = 0.003
I0524 04:02:19.828873 15289 solver.cpp:237] Iteration 101436, loss = 1.07263
I0524 04:02:19.829084 15289 solver.cpp:253]     Train net output #0: loss = 1.07263 (* 1 = 1.07263 loss)
I0524 04:02:19.829098 15289 sgd_solver.cpp:106] Iteration 101436, lr = 0.003
I0524 04:02:28.721922 15289 solver.cpp:237] Iteration 101650, loss = 1.31849
I0524 04:02:28.721967 15289 solver.cpp:253]     Train net output #0: loss = 1.31849 (* 1 = 1.31849 loss)
I0524 04:02:28.721984 15289 sgd_solver.cpp:106] Iteration 101650, lr = 0.003
I0524 04:02:37.620101 15289 solver.cpp:237] Iteration 101864, loss = 1.23978
I0524 04:02:37.620137 15289 solver.cpp:253]     Train net output #0: loss = 1.23978 (* 1 = 1.23978 loss)
I0524 04:02:37.620151 15289 sgd_solver.cpp:106] Iteration 101864, lr = 0.003
I0524 04:02:46.517953 15289 solver.cpp:237] Iteration 102078, loss = 1.08811
I0524 04:02:46.517989 15289 solver.cpp:253]     Train net output #0: loss = 1.08811 (* 1 = 1.08811 loss)
I0524 04:02:46.518005 15289 sgd_solver.cpp:106] Iteration 102078, lr = 0.003
I0524 04:02:55.417739 15289 solver.cpp:237] Iteration 102292, loss = 1.44165
I0524 04:02:55.417933 15289 solver.cpp:253]     Train net output #0: loss = 1.44165 (* 1 = 1.44165 loss)
I0524 04:02:55.417948 15289 sgd_solver.cpp:106] Iteration 102292, lr = 0.003
I0524 04:03:04.314293 15289 solver.cpp:237] Iteration 102506, loss = 1.51342
I0524 04:03:04.314328 15289 solver.cpp:253]     Train net output #0: loss = 1.51342 (* 1 = 1.51342 loss)
I0524 04:03:04.314345 15289 sgd_solver.cpp:106] Iteration 102506, lr = 0.003
I0524 04:03:13.212199 15289 solver.cpp:237] Iteration 102720, loss = 1.13459
I0524 04:03:13.212235 15289 solver.cpp:253]     Train net output #0: loss = 1.13459 (* 1 = 1.13459 loss)
I0524 04:03:13.212251 15289 sgd_solver.cpp:106] Iteration 102720, lr = 0.003
I0524 04:03:17.161949 15289 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_102816.caffemodel
I0524 04:03:17.229058 15289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0030_2016-05-20T15.49.14.533565_iter_102816.solverstate
I0524 04:03:18.224441 15289 solver.cpp:341] Iteration 102840, Testing net (#0)
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7224 exceeded limit 7200
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
aprun: Apid 11259577: Caught signal Terminated, sending to application
