2807075
I0521 23:42:28.333032 13093 caffe.cpp:184] Using GPUs 0
I0521 23:42:28.760383 13093 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.002
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961.prototxt"
I0521 23:42:28.762320 13093 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961.prototxt
I0521 23:42:28.781539 13093 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 23:42:28.781599 13093 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 23:42:28.781946 13093 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 23:42:28.782124 13093 layer_factory.hpp:77] Creating layer data_hdf5
I0521 23:42:28.782147 13093 net.cpp:106] Creating Layer data_hdf5
I0521 23:42:28.782162 13093 net.cpp:411] data_hdf5 -> data
I0521 23:42:28.782196 13093 net.cpp:411] data_hdf5 -> label
I0521 23:42:28.782228 13093 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 23:42:28.792814 13093 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 23:42:28.795114 13093 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 23:42:50.322046 13093 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 23:42:50.327301 13093 net.cpp:150] Setting up data_hdf5
I0521 23:42:50.327340 13093 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0521 23:42:50.327355 13093 net.cpp:157] Top shape: 20 (20)
I0521 23:42:50.327368 13093 net.cpp:165] Memory required for data: 508080
I0521 23:42:50.327381 13093 layer_factory.hpp:77] Creating layer conv1
I0521 23:42:50.327415 13093 net.cpp:106] Creating Layer conv1
I0521 23:42:50.327426 13093 net.cpp:454] conv1 <- data
I0521 23:42:50.327448 13093 net.cpp:411] conv1 -> conv1
I0521 23:42:51.785075 13093 net.cpp:150] Setting up conv1
I0521 23:42:51.785117 13093 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 23:42:51.785128 13093 net.cpp:165] Memory required for data: 6037680
I0521 23:42:51.785157 13093 layer_factory.hpp:77] Creating layer relu1
I0521 23:42:51.785178 13093 net.cpp:106] Creating Layer relu1
I0521 23:42:51.785189 13093 net.cpp:454] relu1 <- conv1
I0521 23:42:51.785202 13093 net.cpp:397] relu1 -> conv1 (in-place)
I0521 23:42:51.785718 13093 net.cpp:150] Setting up relu1
I0521 23:42:51.785735 13093 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 23:42:51.785747 13093 net.cpp:165] Memory required for data: 11567280
I0521 23:42:51.785756 13093 layer_factory.hpp:77] Creating layer pool1
I0521 23:42:51.785773 13093 net.cpp:106] Creating Layer pool1
I0521 23:42:51.785783 13093 net.cpp:454] pool1 <- conv1
I0521 23:42:51.785796 13093 net.cpp:411] pool1 -> pool1
I0521 23:42:51.785876 13093 net.cpp:150] Setting up pool1
I0521 23:42:51.785889 13093 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0521 23:42:51.785899 13093 net.cpp:165] Memory required for data: 14332080
I0521 23:42:51.785907 13093 layer_factory.hpp:77] Creating layer conv2
I0521 23:42:51.785931 13093 net.cpp:106] Creating Layer conv2
I0521 23:42:51.785941 13093 net.cpp:454] conv2 <- pool1
I0521 23:42:51.785955 13093 net.cpp:411] conv2 -> conv2
I0521 23:42:51.788636 13093 net.cpp:150] Setting up conv2
I0521 23:42:51.788664 13093 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 23:42:51.788676 13093 net.cpp:165] Memory required for data: 18306480
I0521 23:42:51.788694 13093 layer_factory.hpp:77] Creating layer relu2
I0521 23:42:51.788708 13093 net.cpp:106] Creating Layer relu2
I0521 23:42:51.788719 13093 net.cpp:454] relu2 <- conv2
I0521 23:42:51.788733 13093 net.cpp:397] relu2 -> conv2 (in-place)
I0521 23:42:51.789062 13093 net.cpp:150] Setting up relu2
I0521 23:42:51.789077 13093 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 23:42:51.789086 13093 net.cpp:165] Memory required for data: 22280880
I0521 23:42:51.789098 13093 layer_factory.hpp:77] Creating layer pool2
I0521 23:42:51.789110 13093 net.cpp:106] Creating Layer pool2
I0521 23:42:51.789120 13093 net.cpp:454] pool2 <- conv2
I0521 23:42:51.789132 13093 net.cpp:411] pool2 -> pool2
I0521 23:42:51.789212 13093 net.cpp:150] Setting up pool2
I0521 23:42:51.789225 13093 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0521 23:42:51.789235 13093 net.cpp:165] Memory required for data: 24268080
I0521 23:42:51.789243 13093 layer_factory.hpp:77] Creating layer conv3
I0521 23:42:51.789261 13093 net.cpp:106] Creating Layer conv3
I0521 23:42:51.789273 13093 net.cpp:454] conv3 <- pool2
I0521 23:42:51.789285 13093 net.cpp:411] conv3 -> conv3
I0521 23:42:51.791218 13093 net.cpp:150] Setting up conv3
I0521 23:42:51.791242 13093 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 23:42:51.791257 13093 net.cpp:165] Memory required for data: 26436400
I0521 23:42:51.791275 13093 layer_factory.hpp:77] Creating layer relu3
I0521 23:42:51.791291 13093 net.cpp:106] Creating Layer relu3
I0521 23:42:51.791302 13093 net.cpp:454] relu3 <- conv3
I0521 23:42:51.791314 13093 net.cpp:397] relu3 -> conv3 (in-place)
I0521 23:42:51.791787 13093 net.cpp:150] Setting up relu3
I0521 23:42:51.791805 13093 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 23:42:51.791815 13093 net.cpp:165] Memory required for data: 28604720
I0521 23:42:51.791826 13093 layer_factory.hpp:77] Creating layer pool3
I0521 23:42:51.791838 13093 net.cpp:106] Creating Layer pool3
I0521 23:42:51.791847 13093 net.cpp:454] pool3 <- conv3
I0521 23:42:51.791860 13093 net.cpp:411] pool3 -> pool3
I0521 23:42:51.791928 13093 net.cpp:150] Setting up pool3
I0521 23:42:51.791940 13093 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0521 23:42:51.791950 13093 net.cpp:165] Memory required for data: 29688880
I0521 23:42:51.791959 13093 layer_factory.hpp:77] Creating layer conv4
I0521 23:42:51.791976 13093 net.cpp:106] Creating Layer conv4
I0521 23:42:51.791986 13093 net.cpp:454] conv4 <- pool3
I0521 23:42:51.791999 13093 net.cpp:411] conv4 -> conv4
I0521 23:42:51.794692 13093 net.cpp:150] Setting up conv4
I0521 23:42:51.794718 13093 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 23:42:51.794729 13093 net.cpp:165] Memory required for data: 30414640
I0521 23:42:51.794744 13093 layer_factory.hpp:77] Creating layer relu4
I0521 23:42:51.794759 13093 net.cpp:106] Creating Layer relu4
I0521 23:42:51.794769 13093 net.cpp:454] relu4 <- conv4
I0521 23:42:51.794781 13093 net.cpp:397] relu4 -> conv4 (in-place)
I0521 23:42:51.795258 13093 net.cpp:150] Setting up relu4
I0521 23:42:51.795274 13093 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 23:42:51.795285 13093 net.cpp:165] Memory required for data: 31140400
I0521 23:42:51.795295 13093 layer_factory.hpp:77] Creating layer pool4
I0521 23:42:51.795308 13093 net.cpp:106] Creating Layer pool4
I0521 23:42:51.795318 13093 net.cpp:454] pool4 <- conv4
I0521 23:42:51.795331 13093 net.cpp:411] pool4 -> pool4
I0521 23:42:51.795399 13093 net.cpp:150] Setting up pool4
I0521 23:42:51.795413 13093 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0521 23:42:51.795423 13093 net.cpp:165] Memory required for data: 31503280
I0521 23:42:51.795433 13093 layer_factory.hpp:77] Creating layer ip1
I0521 23:42:51.795454 13093 net.cpp:106] Creating Layer ip1
I0521 23:42:51.795464 13093 net.cpp:454] ip1 <- pool4
I0521 23:42:51.795476 13093 net.cpp:411] ip1 -> ip1
I0521 23:42:51.810847 13093 net.cpp:150] Setting up ip1
I0521 23:42:51.810875 13093 net.cpp:157] Top shape: 20 196 (3920)
I0521 23:42:51.810889 13093 net.cpp:165] Memory required for data: 31518960
I0521 23:42:51.810911 13093 layer_factory.hpp:77] Creating layer relu5
I0521 23:42:51.810926 13093 net.cpp:106] Creating Layer relu5
I0521 23:42:51.810936 13093 net.cpp:454] relu5 <- ip1
I0521 23:42:51.810950 13093 net.cpp:397] relu5 -> ip1 (in-place)
I0521 23:42:51.811296 13093 net.cpp:150] Setting up relu5
I0521 23:42:51.811310 13093 net.cpp:157] Top shape: 20 196 (3920)
I0521 23:42:51.811321 13093 net.cpp:165] Memory required for data: 31534640
I0521 23:42:51.811331 13093 layer_factory.hpp:77] Creating layer drop1
I0521 23:42:51.811352 13093 net.cpp:106] Creating Layer drop1
I0521 23:42:51.811362 13093 net.cpp:454] drop1 <- ip1
I0521 23:42:51.811374 13093 net.cpp:397] drop1 -> ip1 (in-place)
I0521 23:42:51.811434 13093 net.cpp:150] Setting up drop1
I0521 23:42:51.811446 13093 net.cpp:157] Top shape: 20 196 (3920)
I0521 23:42:51.811456 13093 net.cpp:165] Memory required for data: 31550320
I0521 23:42:51.811466 13093 layer_factory.hpp:77] Creating layer ip2
I0521 23:42:51.811485 13093 net.cpp:106] Creating Layer ip2
I0521 23:42:51.811494 13093 net.cpp:454] ip2 <- ip1
I0521 23:42:51.811508 13093 net.cpp:411] ip2 -> ip2
I0521 23:42:51.811970 13093 net.cpp:150] Setting up ip2
I0521 23:42:51.811983 13093 net.cpp:157] Top shape: 20 98 (1960)
I0521 23:42:51.811995 13093 net.cpp:165] Memory required for data: 31558160
I0521 23:42:51.812010 13093 layer_factory.hpp:77] Creating layer relu6
I0521 23:42:51.812022 13093 net.cpp:106] Creating Layer relu6
I0521 23:42:51.812031 13093 net.cpp:454] relu6 <- ip2
I0521 23:42:51.812044 13093 net.cpp:397] relu6 -> ip2 (in-place)
I0521 23:42:51.812564 13093 net.cpp:150] Setting up relu6
I0521 23:42:51.812582 13093 net.cpp:157] Top shape: 20 98 (1960)
I0521 23:42:51.812592 13093 net.cpp:165] Memory required for data: 31566000
I0521 23:42:51.812603 13093 layer_factory.hpp:77] Creating layer drop2
I0521 23:42:51.812616 13093 net.cpp:106] Creating Layer drop2
I0521 23:42:51.812626 13093 net.cpp:454] drop2 <- ip2
I0521 23:42:51.812638 13093 net.cpp:397] drop2 -> ip2 (in-place)
I0521 23:42:51.812681 13093 net.cpp:150] Setting up drop2
I0521 23:42:51.812700 13093 net.cpp:157] Top shape: 20 98 (1960)
I0521 23:42:51.812711 13093 net.cpp:165] Memory required for data: 31573840
I0521 23:42:51.812721 13093 layer_factory.hpp:77] Creating layer ip3
I0521 23:42:51.812734 13093 net.cpp:106] Creating Layer ip3
I0521 23:42:51.812744 13093 net.cpp:454] ip3 <- ip2
I0521 23:42:51.812757 13093 net.cpp:411] ip3 -> ip3
I0521 23:42:51.812966 13093 net.cpp:150] Setting up ip3
I0521 23:42:51.812979 13093 net.cpp:157] Top shape: 20 11 (220)
I0521 23:42:51.812989 13093 net.cpp:165] Memory required for data: 31574720
I0521 23:42:51.813004 13093 layer_factory.hpp:77] Creating layer drop3
I0521 23:42:51.813016 13093 net.cpp:106] Creating Layer drop3
I0521 23:42:51.813025 13093 net.cpp:454] drop3 <- ip3
I0521 23:42:51.813038 13093 net.cpp:397] drop3 -> ip3 (in-place)
I0521 23:42:51.813077 13093 net.cpp:150] Setting up drop3
I0521 23:42:51.813091 13093 net.cpp:157] Top shape: 20 11 (220)
I0521 23:42:51.813100 13093 net.cpp:165] Memory required for data: 31575600
I0521 23:42:51.813110 13093 layer_factory.hpp:77] Creating layer loss
I0521 23:42:51.813129 13093 net.cpp:106] Creating Layer loss
I0521 23:42:51.813139 13093 net.cpp:454] loss <- ip3
I0521 23:42:51.813150 13093 net.cpp:454] loss <- label
I0521 23:42:51.813164 13093 net.cpp:411] loss -> loss
I0521 23:42:51.813181 13093 layer_factory.hpp:77] Creating layer loss
I0521 23:42:51.813818 13093 net.cpp:150] Setting up loss
I0521 23:42:51.813838 13093 net.cpp:157] Top shape: (1)
I0521 23:42:51.813853 13093 net.cpp:160]     with loss weight 1
I0521 23:42:51.813894 13093 net.cpp:165] Memory required for data: 31575604
I0521 23:42:51.813905 13093 net.cpp:226] loss needs backward computation.
I0521 23:42:51.813915 13093 net.cpp:226] drop3 needs backward computation.
I0521 23:42:51.813923 13093 net.cpp:226] ip3 needs backward computation.
I0521 23:42:51.813935 13093 net.cpp:226] drop2 needs backward computation.
I0521 23:42:51.813944 13093 net.cpp:226] relu6 needs backward computation.
I0521 23:42:51.813954 13093 net.cpp:226] ip2 needs backward computation.
I0521 23:42:51.813964 13093 net.cpp:226] drop1 needs backward computation.
I0521 23:42:51.813974 13093 net.cpp:226] relu5 needs backward computation.
I0521 23:42:51.813984 13093 net.cpp:226] ip1 needs backward computation.
I0521 23:42:51.813994 13093 net.cpp:226] pool4 needs backward computation.
I0521 23:42:51.814005 13093 net.cpp:226] relu4 needs backward computation.
I0521 23:42:51.814014 13093 net.cpp:226] conv4 needs backward computation.
I0521 23:42:51.814025 13093 net.cpp:226] pool3 needs backward computation.
I0521 23:42:51.814035 13093 net.cpp:226] relu3 needs backward computation.
I0521 23:42:51.814045 13093 net.cpp:226] conv3 needs backward computation.
I0521 23:42:51.814064 13093 net.cpp:226] pool2 needs backward computation.
I0521 23:42:51.814075 13093 net.cpp:226] relu2 needs backward computation.
I0521 23:42:51.814085 13093 net.cpp:226] conv2 needs backward computation.
I0521 23:42:51.814096 13093 net.cpp:226] pool1 needs backward computation.
I0521 23:42:51.814107 13093 net.cpp:226] relu1 needs backward computation.
I0521 23:42:51.814117 13093 net.cpp:226] conv1 needs backward computation.
I0521 23:42:51.814128 13093 net.cpp:228] data_hdf5 does not need backward computation.
I0521 23:42:51.814138 13093 net.cpp:270] This network produces output loss
I0521 23:42:51.814162 13093 net.cpp:283] Network initialization done.
I0521 23:42:51.815901 13093 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961.prototxt
I0521 23:42:51.815971 13093 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 23:42:51.816328 13093 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 23:42:51.816517 13093 layer_factory.hpp:77] Creating layer data_hdf5
I0521 23:42:51.816534 13093 net.cpp:106] Creating Layer data_hdf5
I0521 23:42:51.816545 13093 net.cpp:411] data_hdf5 -> data
I0521 23:42:51.816562 13093 net.cpp:411] data_hdf5 -> label
I0521 23:42:51.816578 13093 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 23:42:51.817909 13093 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 23:43:13.089332 13093 net.cpp:150] Setting up data_hdf5
I0521 23:43:13.089486 13093 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0521 23:43:13.089501 13093 net.cpp:157] Top shape: 20 (20)
I0521 23:43:13.089514 13093 net.cpp:165] Memory required for data: 508080
I0521 23:43:13.089526 13093 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 23:43:13.089555 13093 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 23:43:13.089565 13093 net.cpp:454] label_data_hdf5_1_split <- label
I0521 23:43:13.089581 13093 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 23:43:13.089601 13093 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 23:43:13.089674 13093 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 23:43:13.089689 13093 net.cpp:157] Top shape: 20 (20)
I0521 23:43:13.089700 13093 net.cpp:157] Top shape: 20 (20)
I0521 23:43:13.089709 13093 net.cpp:165] Memory required for data: 508240
I0521 23:43:13.089720 13093 layer_factory.hpp:77] Creating layer conv1
I0521 23:43:13.089740 13093 net.cpp:106] Creating Layer conv1
I0521 23:43:13.089751 13093 net.cpp:454] conv1 <- data
I0521 23:43:13.089766 13093 net.cpp:411] conv1 -> conv1
I0521 23:43:13.091702 13093 net.cpp:150] Setting up conv1
I0521 23:43:13.091724 13093 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 23:43:13.091737 13093 net.cpp:165] Memory required for data: 6037840
I0521 23:43:13.091758 13093 layer_factory.hpp:77] Creating layer relu1
I0521 23:43:13.091773 13093 net.cpp:106] Creating Layer relu1
I0521 23:43:13.091783 13093 net.cpp:454] relu1 <- conv1
I0521 23:43:13.091795 13093 net.cpp:397] relu1 -> conv1 (in-place)
I0521 23:43:13.092290 13093 net.cpp:150] Setting up relu1
I0521 23:43:13.092306 13093 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0521 23:43:13.092319 13093 net.cpp:165] Memory required for data: 11567440
I0521 23:43:13.092329 13093 layer_factory.hpp:77] Creating layer pool1
I0521 23:43:13.092344 13093 net.cpp:106] Creating Layer pool1
I0521 23:43:13.092355 13093 net.cpp:454] pool1 <- conv1
I0521 23:43:13.092367 13093 net.cpp:411] pool1 -> pool1
I0521 23:43:13.092442 13093 net.cpp:150] Setting up pool1
I0521 23:43:13.092455 13093 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0521 23:43:13.092468 13093 net.cpp:165] Memory required for data: 14332240
I0521 23:43:13.092478 13093 layer_factory.hpp:77] Creating layer conv2
I0521 23:43:13.092496 13093 net.cpp:106] Creating Layer conv2
I0521 23:43:13.092506 13093 net.cpp:454] conv2 <- pool1
I0521 23:43:13.092520 13093 net.cpp:411] conv2 -> conv2
I0521 23:43:13.094426 13093 net.cpp:150] Setting up conv2
I0521 23:43:13.094449 13093 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 23:43:13.094462 13093 net.cpp:165] Memory required for data: 18306640
I0521 23:43:13.094480 13093 layer_factory.hpp:77] Creating layer relu2
I0521 23:43:13.094493 13093 net.cpp:106] Creating Layer relu2
I0521 23:43:13.094503 13093 net.cpp:454] relu2 <- conv2
I0521 23:43:13.094516 13093 net.cpp:397] relu2 -> conv2 (in-place)
I0521 23:43:13.094848 13093 net.cpp:150] Setting up relu2
I0521 23:43:13.094862 13093 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0521 23:43:13.094872 13093 net.cpp:165] Memory required for data: 22281040
I0521 23:43:13.094882 13093 layer_factory.hpp:77] Creating layer pool2
I0521 23:43:13.094894 13093 net.cpp:106] Creating Layer pool2
I0521 23:43:13.094904 13093 net.cpp:454] pool2 <- conv2
I0521 23:43:13.094918 13093 net.cpp:411] pool2 -> pool2
I0521 23:43:13.094990 13093 net.cpp:150] Setting up pool2
I0521 23:43:13.095003 13093 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0521 23:43:13.095012 13093 net.cpp:165] Memory required for data: 24268240
I0521 23:43:13.095022 13093 layer_factory.hpp:77] Creating layer conv3
I0521 23:43:13.095039 13093 net.cpp:106] Creating Layer conv3
I0521 23:43:13.095051 13093 net.cpp:454] conv3 <- pool2
I0521 23:43:13.095064 13093 net.cpp:411] conv3 -> conv3
I0521 23:43:13.097048 13093 net.cpp:150] Setting up conv3
I0521 23:43:13.097070 13093 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 23:43:13.097095 13093 net.cpp:165] Memory required for data: 26436560
I0521 23:43:13.097115 13093 layer_factory.hpp:77] Creating layer relu3
I0521 23:43:13.097141 13093 net.cpp:106] Creating Layer relu3
I0521 23:43:13.097151 13093 net.cpp:454] relu3 <- conv3
I0521 23:43:13.097164 13093 net.cpp:397] relu3 -> conv3 (in-place)
I0521 23:43:13.097640 13093 net.cpp:150] Setting up relu3
I0521 23:43:13.097656 13093 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0521 23:43:13.097666 13093 net.cpp:165] Memory required for data: 28604880
I0521 23:43:13.097676 13093 layer_factory.hpp:77] Creating layer pool3
I0521 23:43:13.097690 13093 net.cpp:106] Creating Layer pool3
I0521 23:43:13.097700 13093 net.cpp:454] pool3 <- conv3
I0521 23:43:13.097712 13093 net.cpp:411] pool3 -> pool3
I0521 23:43:13.097784 13093 net.cpp:150] Setting up pool3
I0521 23:43:13.097797 13093 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0521 23:43:13.097806 13093 net.cpp:165] Memory required for data: 29689040
I0521 23:43:13.097816 13093 layer_factory.hpp:77] Creating layer conv4
I0521 23:43:13.097834 13093 net.cpp:106] Creating Layer conv4
I0521 23:43:13.097844 13093 net.cpp:454] conv4 <- pool3
I0521 23:43:13.097859 13093 net.cpp:411] conv4 -> conv4
I0521 23:43:13.099921 13093 net.cpp:150] Setting up conv4
I0521 23:43:13.099943 13093 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 23:43:13.099956 13093 net.cpp:165] Memory required for data: 30414800
I0521 23:43:13.099972 13093 layer_factory.hpp:77] Creating layer relu4
I0521 23:43:13.099984 13093 net.cpp:106] Creating Layer relu4
I0521 23:43:13.099994 13093 net.cpp:454] relu4 <- conv4
I0521 23:43:13.100008 13093 net.cpp:397] relu4 -> conv4 (in-place)
I0521 23:43:13.100476 13093 net.cpp:150] Setting up relu4
I0521 23:43:13.100492 13093 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0521 23:43:13.100503 13093 net.cpp:165] Memory required for data: 31140560
I0521 23:43:13.100513 13093 layer_factory.hpp:77] Creating layer pool4
I0521 23:43:13.100527 13093 net.cpp:106] Creating Layer pool4
I0521 23:43:13.100536 13093 net.cpp:454] pool4 <- conv4
I0521 23:43:13.100549 13093 net.cpp:411] pool4 -> pool4
I0521 23:43:13.100621 13093 net.cpp:150] Setting up pool4
I0521 23:43:13.100635 13093 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0521 23:43:13.100644 13093 net.cpp:165] Memory required for data: 31503440
I0521 23:43:13.100656 13093 layer_factory.hpp:77] Creating layer ip1
I0521 23:43:13.100667 13093 net.cpp:106] Creating Layer ip1
I0521 23:43:13.100678 13093 net.cpp:454] ip1 <- pool4
I0521 23:43:13.100692 13093 net.cpp:411] ip1 -> ip1
I0521 23:43:13.116140 13093 net.cpp:150] Setting up ip1
I0521 23:43:13.116169 13093 net.cpp:157] Top shape: 20 196 (3920)
I0521 23:43:13.116185 13093 net.cpp:165] Memory required for data: 31519120
I0521 23:43:13.116212 13093 layer_factory.hpp:77] Creating layer relu5
I0521 23:43:13.116227 13093 net.cpp:106] Creating Layer relu5
I0521 23:43:13.116237 13093 net.cpp:454] relu5 <- ip1
I0521 23:43:13.116251 13093 net.cpp:397] relu5 -> ip1 (in-place)
I0521 23:43:13.116597 13093 net.cpp:150] Setting up relu5
I0521 23:43:13.116611 13093 net.cpp:157] Top shape: 20 196 (3920)
I0521 23:43:13.116621 13093 net.cpp:165] Memory required for data: 31534800
I0521 23:43:13.116631 13093 layer_factory.hpp:77] Creating layer drop1
I0521 23:43:13.116650 13093 net.cpp:106] Creating Layer drop1
I0521 23:43:13.116660 13093 net.cpp:454] drop1 <- ip1
I0521 23:43:13.116673 13093 net.cpp:397] drop1 -> ip1 (in-place)
I0521 23:43:13.116724 13093 net.cpp:150] Setting up drop1
I0521 23:43:13.116739 13093 net.cpp:157] Top shape: 20 196 (3920)
I0521 23:43:13.116750 13093 net.cpp:165] Memory required for data: 31550480
I0521 23:43:13.116760 13093 layer_factory.hpp:77] Creating layer ip2
I0521 23:43:13.116775 13093 net.cpp:106] Creating Layer ip2
I0521 23:43:13.116785 13093 net.cpp:454] ip2 <- ip1
I0521 23:43:13.116797 13093 net.cpp:411] ip2 -> ip2
I0521 23:43:13.117276 13093 net.cpp:150] Setting up ip2
I0521 23:43:13.117290 13093 net.cpp:157] Top shape: 20 98 (1960)
I0521 23:43:13.117300 13093 net.cpp:165] Memory required for data: 31558320
I0521 23:43:13.117316 13093 layer_factory.hpp:77] Creating layer relu6
I0521 23:43:13.117341 13093 net.cpp:106] Creating Layer relu6
I0521 23:43:13.117350 13093 net.cpp:454] relu6 <- ip2
I0521 23:43:13.117363 13093 net.cpp:397] relu6 -> ip2 (in-place)
I0521 23:43:13.117897 13093 net.cpp:150] Setting up relu6
I0521 23:43:13.117919 13093 net.cpp:157] Top shape: 20 98 (1960)
I0521 23:43:13.117928 13093 net.cpp:165] Memory required for data: 31566160
I0521 23:43:13.117938 13093 layer_factory.hpp:77] Creating layer drop2
I0521 23:43:13.117952 13093 net.cpp:106] Creating Layer drop2
I0521 23:43:13.117964 13093 net.cpp:454] drop2 <- ip2
I0521 23:43:13.117976 13093 net.cpp:397] drop2 -> ip2 (in-place)
I0521 23:43:13.118021 13093 net.cpp:150] Setting up drop2
I0521 23:43:13.118033 13093 net.cpp:157] Top shape: 20 98 (1960)
I0521 23:43:13.118043 13093 net.cpp:165] Memory required for data: 31574000
I0521 23:43:13.118053 13093 layer_factory.hpp:77] Creating layer ip3
I0521 23:43:13.118067 13093 net.cpp:106] Creating Layer ip3
I0521 23:43:13.118077 13093 net.cpp:454] ip3 <- ip2
I0521 23:43:13.118090 13093 net.cpp:411] ip3 -> ip3
I0521 23:43:13.118311 13093 net.cpp:150] Setting up ip3
I0521 23:43:13.118324 13093 net.cpp:157] Top shape: 20 11 (220)
I0521 23:43:13.118335 13093 net.cpp:165] Memory required for data: 31574880
I0521 23:43:13.118350 13093 layer_factory.hpp:77] Creating layer drop3
I0521 23:43:13.118362 13093 net.cpp:106] Creating Layer drop3
I0521 23:43:13.118372 13093 net.cpp:454] drop3 <- ip3
I0521 23:43:13.118386 13093 net.cpp:397] drop3 -> ip3 (in-place)
I0521 23:43:13.118425 13093 net.cpp:150] Setting up drop3
I0521 23:43:13.118438 13093 net.cpp:157] Top shape: 20 11 (220)
I0521 23:43:13.118448 13093 net.cpp:165] Memory required for data: 31575760
I0521 23:43:13.118458 13093 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 23:43:13.118471 13093 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 23:43:13.118480 13093 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 23:43:13.118494 13093 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 23:43:13.118508 13093 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 23:43:13.118582 13093 net.cpp:150] Setting up ip3_drop3_0_split
I0521 23:43:13.118594 13093 net.cpp:157] Top shape: 20 11 (220)
I0521 23:43:13.118607 13093 net.cpp:157] Top shape: 20 11 (220)
I0521 23:43:13.118618 13093 net.cpp:165] Memory required for data: 31577520
I0521 23:43:13.118628 13093 layer_factory.hpp:77] Creating layer accuracy
I0521 23:43:13.118649 13093 net.cpp:106] Creating Layer accuracy
I0521 23:43:13.118659 13093 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 23:43:13.118669 13093 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 23:43:13.118683 13093 net.cpp:411] accuracy -> accuracy
I0521 23:43:13.118706 13093 net.cpp:150] Setting up accuracy
I0521 23:43:13.118719 13093 net.cpp:157] Top shape: (1)
I0521 23:43:13.118728 13093 net.cpp:165] Memory required for data: 31577524
I0521 23:43:13.118738 13093 layer_factory.hpp:77] Creating layer loss
I0521 23:43:13.118753 13093 net.cpp:106] Creating Layer loss
I0521 23:43:13.118763 13093 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 23:43:13.118774 13093 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 23:43:13.118788 13093 net.cpp:411] loss -> loss
I0521 23:43:13.118806 13093 layer_factory.hpp:77] Creating layer loss
I0521 23:43:13.119295 13093 net.cpp:150] Setting up loss
I0521 23:43:13.119308 13093 net.cpp:157] Top shape: (1)
I0521 23:43:13.119318 13093 net.cpp:160]     with loss weight 1
I0521 23:43:13.119338 13093 net.cpp:165] Memory required for data: 31577528
I0521 23:43:13.119348 13093 net.cpp:226] loss needs backward computation.
I0521 23:43:13.119359 13093 net.cpp:228] accuracy does not need backward computation.
I0521 23:43:13.119370 13093 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 23:43:13.119380 13093 net.cpp:226] drop3 needs backward computation.
I0521 23:43:13.119391 13093 net.cpp:226] ip3 needs backward computation.
I0521 23:43:13.119401 13093 net.cpp:226] drop2 needs backward computation.
I0521 23:43:13.119411 13093 net.cpp:226] relu6 needs backward computation.
I0521 23:43:13.119429 13093 net.cpp:226] ip2 needs backward computation.
I0521 23:43:13.119441 13093 net.cpp:226] drop1 needs backward computation.
I0521 23:43:13.119449 13093 net.cpp:226] relu5 needs backward computation.
I0521 23:43:13.119458 13093 net.cpp:226] ip1 needs backward computation.
I0521 23:43:13.119469 13093 net.cpp:226] pool4 needs backward computation.
I0521 23:43:13.119479 13093 net.cpp:226] relu4 needs backward computation.
I0521 23:43:13.119489 13093 net.cpp:226] conv4 needs backward computation.
I0521 23:43:13.119498 13093 net.cpp:226] pool3 needs backward computation.
I0521 23:43:13.119508 13093 net.cpp:226] relu3 needs backward computation.
I0521 23:43:13.119518 13093 net.cpp:226] conv3 needs backward computation.
I0521 23:43:13.119529 13093 net.cpp:226] pool2 needs backward computation.
I0521 23:43:13.119539 13093 net.cpp:226] relu2 needs backward computation.
I0521 23:43:13.119549 13093 net.cpp:226] conv2 needs backward computation.
I0521 23:43:13.119560 13093 net.cpp:226] pool1 needs backward computation.
I0521 23:43:13.119570 13093 net.cpp:226] relu1 needs backward computation.
I0521 23:43:13.119580 13093 net.cpp:226] conv1 needs backward computation.
I0521 23:43:13.119590 13093 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 23:43:13.119602 13093 net.cpp:228] data_hdf5 does not need backward computation.
I0521 23:43:13.119612 13093 net.cpp:270] This network produces output accuracy
I0521 23:43:13.119623 13093 net.cpp:270] This network produces output loss
I0521 23:43:13.119652 13093 net.cpp:283] Network initialization done.
I0521 23:43:13.119786 13093 solver.cpp:60] Solver scaffolding done.
I0521 23:43:13.120928 13093 caffe.cpp:212] Starting Optimization
I0521 23:43:13.120946 13093 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 23:43:13.120955 13093 solver.cpp:289] Learning Rate Policy: fixed
I0521 23:43:13.122164 13093 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 23:44:05.960721 13093 solver.cpp:409]     Test net output #0: accuracy = 0.118499
I0521 23:44:05.960881 13093 solver.cpp:409]     Test net output #1: loss = 2.39777 (* 1 = 2.39777 loss)
I0521 23:44:05.979861 13093 solver.cpp:237] Iteration 0, loss = 2.41018
I0521 23:44:05.979897 13093 solver.cpp:253]     Train net output #0: loss = 2.41018 (* 1 = 2.41018 loss)
I0521 23:44:05.979915 13093 sgd_solver.cpp:106] Iteration 0, lr = 0.002
I0521 23:44:18.132939 13093 solver.cpp:237] Iteration 750, loss = 2.08878
I0521 23:44:18.132988 13093 solver.cpp:253]     Train net output #0: loss = 2.08878 (* 1 = 2.08878 loss)
I0521 23:44:18.133002 13093 sgd_solver.cpp:106] Iteration 750, lr = 0.002
I0521 23:44:30.282418 13093 solver.cpp:237] Iteration 1500, loss = 2.12597
I0521 23:44:30.282454 13093 solver.cpp:253]     Train net output #0: loss = 2.12597 (* 1 = 2.12597 loss)
I0521 23:44:30.282470 13093 sgd_solver.cpp:106] Iteration 1500, lr = 0.002
I0521 23:44:42.452967 13093 solver.cpp:237] Iteration 2250, loss = 1.77239
I0521 23:44:42.453133 13093 solver.cpp:253]     Train net output #0: loss = 1.77239 (* 1 = 1.77239 loss)
I0521 23:44:42.453150 13093 sgd_solver.cpp:106] Iteration 2250, lr = 0.002
I0521 23:44:54.620715 13093 solver.cpp:237] Iteration 3000, loss = 1.29513
I0521 23:44:54.620753 13093 solver.cpp:253]     Train net output #0: loss = 1.29513 (* 1 = 1.29513 loss)
I0521 23:44:54.620766 13093 sgd_solver.cpp:106] Iteration 3000, lr = 0.002
I0521 23:45:06.781568 13093 solver.cpp:237] Iteration 3750, loss = 1.53353
I0521 23:45:06.781616 13093 solver.cpp:253]     Train net output #0: loss = 1.53353 (* 1 = 1.53353 loss)
I0521 23:45:06.781630 13093 sgd_solver.cpp:106] Iteration 3750, lr = 0.002
I0521 23:45:18.905902 13093 solver.cpp:237] Iteration 4500, loss = 1.62522
I0521 23:45:18.906044 13093 solver.cpp:253]     Train net output #0: loss = 1.62522 (* 1 = 1.62522 loss)
I0521 23:45:18.906059 13093 sgd_solver.cpp:106] Iteration 4500, lr = 0.002
I0521 23:45:53.163611 13093 solver.cpp:237] Iteration 5250, loss = 1.74556
I0521 23:45:53.163769 13093 solver.cpp:253]     Train net output #0: loss = 1.74556 (* 1 = 1.74556 loss)
I0521 23:45:53.163784 13093 sgd_solver.cpp:106] Iteration 5250, lr = 0.002
I0521 23:46:05.326059 13093 solver.cpp:237] Iteration 6000, loss = 1.46339
I0521 23:46:05.326095 13093 solver.cpp:253]     Train net output #0: loss = 1.46339 (* 1 = 1.46339 loss)
I0521 23:46:05.326112 13093 sgd_solver.cpp:106] Iteration 6000, lr = 0.002
I0521 23:46:17.477183 13093 solver.cpp:237] Iteration 6750, loss = 1.5978
I0521 23:46:17.477224 13093 solver.cpp:253]     Train net output #0: loss = 1.5978 (* 1 = 1.5978 loss)
I0521 23:46:17.477246 13093 sgd_solver.cpp:106] Iteration 6750, lr = 0.002
I0521 23:46:29.622622 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_7500.caffemodel
I0521 23:46:29.675621 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_7500.solverstate
I0521 23:46:29.706065 13093 solver.cpp:237] Iteration 7500, loss = 1.11984
I0521 23:46:29.706106 13093 solver.cpp:253]     Train net output #0: loss = 1.11984 (* 1 = 1.11984 loss)
I0521 23:46:29.706127 13093 sgd_solver.cpp:106] Iteration 7500, lr = 0.002
I0521 23:46:41.866613 13093 solver.cpp:237] Iteration 8250, loss = 1.5939
I0521 23:46:41.866662 13093 solver.cpp:253]     Train net output #0: loss = 1.5939 (* 1 = 1.5939 loss)
I0521 23:46:41.866677 13093 sgd_solver.cpp:106] Iteration 8250, lr = 0.002
I0521 23:46:54.017474 13093 solver.cpp:237] Iteration 9000, loss = 1.21037
I0521 23:46:54.017511 13093 solver.cpp:253]     Train net output #0: loss = 1.21037 (* 1 = 1.21037 loss)
I0521 23:46:54.017529 13093 sgd_solver.cpp:106] Iteration 9000, lr = 0.002
I0521 23:47:06.173501 13093 solver.cpp:237] Iteration 9750, loss = 1.32914
I0521 23:47:06.173655 13093 solver.cpp:253]     Train net output #0: loss = 1.32914 (* 1 = 1.32914 loss)
I0521 23:47:06.173669 13093 sgd_solver.cpp:106] Iteration 9750, lr = 0.002
I0521 23:47:40.430793 13093 solver.cpp:237] Iteration 10500, loss = 1.61552
I0521 23:47:40.430953 13093 solver.cpp:253]     Train net output #0: loss = 1.61552 (* 1 = 1.61552 loss)
I0521 23:47:40.430968 13093 sgd_solver.cpp:106] Iteration 10500, lr = 0.002
I0521 23:47:52.580489 13093 solver.cpp:237] Iteration 11250, loss = 1.09734
I0521 23:47:52.580525 13093 solver.cpp:253]     Train net output #0: loss = 1.09734 (* 1 = 1.09734 loss)
I0521 23:47:52.580539 13093 sgd_solver.cpp:106] Iteration 11250, lr = 0.002
I0521 23:48:04.758544 13093 solver.cpp:237] Iteration 12000, loss = 1.6118
I0521 23:48:04.758592 13093 solver.cpp:253]     Train net output #0: loss = 1.6118 (* 1 = 1.6118 loss)
I0521 23:48:04.758606 13093 sgd_solver.cpp:106] Iteration 12000, lr = 0.002
I0521 23:48:16.945709 13093 solver.cpp:237] Iteration 12750, loss = 1.17335
I0521 23:48:16.945873 13093 solver.cpp:253]     Train net output #0: loss = 1.17335 (* 1 = 1.17335 loss)
I0521 23:48:16.945888 13093 sgd_solver.cpp:106] Iteration 12750, lr = 0.002
I0521 23:48:29.109086 13093 solver.cpp:237] Iteration 13500, loss = 1.27602
I0521 23:48:29.109132 13093 solver.cpp:253]     Train net output #0: loss = 1.27602 (* 1 = 1.27602 loss)
I0521 23:48:29.109145 13093 sgd_solver.cpp:106] Iteration 13500, lr = 0.002
I0521 23:48:41.270596 13093 solver.cpp:237] Iteration 14250, loss = 1.45325
I0521 23:48:41.270632 13093 solver.cpp:253]     Train net output #0: loss = 1.45325 (* 1 = 1.45325 loss)
I0521 23:48:41.270649 13093 sgd_solver.cpp:106] Iteration 14250, lr = 0.002
I0521 23:48:53.429044 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_15000.caffemodel
I0521 23:48:53.477782 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_15000.solverstate
I0521 23:48:53.502720 13093 solver.cpp:341] Iteration 15000, Testing net (#0)
I0521 23:49:45.337270 13093 solver.cpp:409]     Test net output #0: accuracy = 0.833706
I0521 23:49:45.337427 13093 solver.cpp:409]     Test net output #1: loss = 0.598319 (* 1 = 0.598319 loss)
I0521 23:50:07.426964 13093 solver.cpp:237] Iteration 15000, loss = 1.03691
I0521 23:50:07.427016 13093 solver.cpp:253]     Train net output #0: loss = 1.03691 (* 1 = 1.03691 loss)
I0521 23:50:07.427031 13093 sgd_solver.cpp:106] Iteration 15000, lr = 0.002
I0521 23:50:19.477888 13093 solver.cpp:237] Iteration 15750, loss = 1.64832
I0521 23:50:19.478034 13093 solver.cpp:253]     Train net output #0: loss = 1.64832 (* 1 = 1.64832 loss)
I0521 23:50:19.478047 13093 sgd_solver.cpp:106] Iteration 15750, lr = 0.002
I0521 23:50:31.526695 13093 solver.cpp:237] Iteration 16500, loss = 1.87361
I0521 23:50:31.526744 13093 solver.cpp:253]     Train net output #0: loss = 1.87361 (* 1 = 1.87361 loss)
I0521 23:50:31.526759 13093 sgd_solver.cpp:106] Iteration 16500, lr = 0.002
I0521 23:50:43.658010 13093 solver.cpp:237] Iteration 17250, loss = 0.89236
I0521 23:50:43.658047 13093 solver.cpp:253]     Train net output #0: loss = 0.89236 (* 1 = 0.89236 loss)
I0521 23:50:43.658063 13093 sgd_solver.cpp:106] Iteration 17250, lr = 0.002
I0521 23:50:55.802147 13093 solver.cpp:237] Iteration 18000, loss = 1.35151
I0521 23:50:55.802294 13093 solver.cpp:253]     Train net output #0: loss = 1.35151 (* 1 = 1.35151 loss)
I0521 23:50:55.802309 13093 sgd_solver.cpp:106] Iteration 18000, lr = 0.002
I0521 23:51:07.896725 13093 solver.cpp:237] Iteration 18750, loss = 1.35319
I0521 23:51:07.896760 13093 solver.cpp:253]     Train net output #0: loss = 1.35319 (* 1 = 1.35319 loss)
I0521 23:51:07.896777 13093 sgd_solver.cpp:106] Iteration 18750, lr = 0.002
I0521 23:51:19.949892 13093 solver.cpp:237] Iteration 19500, loss = 1.25049
I0521 23:51:19.949934 13093 solver.cpp:253]     Train net output #0: loss = 1.25049 (* 1 = 1.25049 loss)
I0521 23:51:19.949949 13093 sgd_solver.cpp:106] Iteration 19500, lr = 0.002
I0521 23:51:54.142920 13093 solver.cpp:237] Iteration 20250, loss = 0.988637
I0521 23:51:54.143082 13093 solver.cpp:253]     Train net output #0: loss = 0.988636 (* 1 = 0.988636 loss)
I0521 23:51:54.143098 13093 sgd_solver.cpp:106] Iteration 20250, lr = 0.002
I0521 23:52:06.195164 13093 solver.cpp:237] Iteration 21000, loss = 1.11367
I0521 23:52:06.195210 13093 solver.cpp:253]     Train net output #0: loss = 1.11367 (* 1 = 1.11367 loss)
I0521 23:52:06.195230 13093 sgd_solver.cpp:106] Iteration 21000, lr = 0.002
I0521 23:52:18.249763 13093 solver.cpp:237] Iteration 21750, loss = 1.25061
I0521 23:52:18.249799 13093 solver.cpp:253]     Train net output #0: loss = 1.25061 (* 1 = 1.25061 loss)
I0521 23:52:18.249817 13093 sgd_solver.cpp:106] Iteration 21750, lr = 0.002
I0521 23:52:30.290796 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_22500.caffemodel
I0521 23:52:30.346942 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_22500.solverstate
I0521 23:52:30.382230 13093 solver.cpp:237] Iteration 22500, loss = 1.4883
I0521 23:52:30.382278 13093 solver.cpp:253]     Train net output #0: loss = 1.4883 (* 1 = 1.4883 loss)
I0521 23:52:30.382292 13093 sgd_solver.cpp:106] Iteration 22500, lr = 0.002
I0521 23:52:42.449259 13093 solver.cpp:237] Iteration 23250, loss = 1.01674
I0521 23:52:42.449304 13093 solver.cpp:253]     Train net output #0: loss = 1.01674 (* 1 = 1.01674 loss)
I0521 23:52:42.449321 13093 sgd_solver.cpp:106] Iteration 23250, lr = 0.002
I0521 23:52:54.500521 13093 solver.cpp:237] Iteration 24000, loss = 1.1189
I0521 23:52:54.500557 13093 solver.cpp:253]     Train net output #0: loss = 1.1189 (* 1 = 1.1189 loss)
I0521 23:52:54.500574 13093 sgd_solver.cpp:106] Iteration 24000, lr = 0.002
I0521 23:53:06.619983 13093 solver.cpp:237] Iteration 24750, loss = 1.15383
I0521 23:53:06.620136 13093 solver.cpp:253]     Train net output #0: loss = 1.15383 (* 1 = 1.15383 loss)
I0521 23:53:06.620151 13093 sgd_solver.cpp:106] Iteration 24750, lr = 0.002
I0521 23:53:40.919620 13093 solver.cpp:237] Iteration 25500, loss = 1.46447
I0521 23:53:40.919797 13093 solver.cpp:253]     Train net output #0: loss = 1.46447 (* 1 = 1.46447 loss)
I0521 23:53:40.919812 13093 sgd_solver.cpp:106] Iteration 25500, lr = 0.002
I0521 23:53:52.993346 13093 solver.cpp:237] Iteration 26250, loss = 1.65007
I0521 23:53:52.993394 13093 solver.cpp:253]     Train net output #0: loss = 1.65006 (* 1 = 1.65006 loss)
I0521 23:53:52.993408 13093 sgd_solver.cpp:106] Iteration 26250, lr = 0.002
I0521 23:54:05.121173 13093 solver.cpp:237] Iteration 27000, loss = 1.36017
I0521 23:54:05.121209 13093 solver.cpp:253]     Train net output #0: loss = 1.36017 (* 1 = 1.36017 loss)
I0521 23:54:05.121227 13093 sgd_solver.cpp:106] Iteration 27000, lr = 0.002
I0521 23:54:17.169613 13093 solver.cpp:237] Iteration 27750, loss = 0.93007
I0521 23:54:17.169765 13093 solver.cpp:253]     Train net output #0: loss = 0.930069 (* 1 = 0.930069 loss)
I0521 23:54:17.169781 13093 sgd_solver.cpp:106] Iteration 27750, lr = 0.002
I0521 23:54:29.286921 13093 solver.cpp:237] Iteration 28500, loss = 1.49203
I0521 23:54:29.286957 13093 solver.cpp:253]     Train net output #0: loss = 1.49203 (* 1 = 1.49203 loss)
I0521 23:54:29.286974 13093 sgd_solver.cpp:106] Iteration 28500, lr = 0.002
I0521 23:54:41.396885 13093 solver.cpp:237] Iteration 29250, loss = 0.991735
I0521 23:54:41.396935 13093 solver.cpp:253]     Train net output #0: loss = 0.991734 (* 1 = 0.991734 loss)
I0521 23:54:41.396949 13093 sgd_solver.cpp:106] Iteration 29250, lr = 0.002
I0521 23:54:53.493266 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_30000.caffemodel
I0521 23:54:53.544600 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_30000.solverstate
I0521 23:54:53.573469 13093 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 23:56:06.217528 13093 solver.cpp:409]     Test net output #0: accuracy = 0.858733
I0521 23:56:06.217684 13093 solver.cpp:409]     Test net output #1: loss = 0.495744 (* 1 = 0.495744 loss)
I0521 23:56:28.353181 13093 solver.cpp:237] Iteration 30000, loss = 0.667451
I0521 23:56:28.353237 13093 solver.cpp:253]     Train net output #0: loss = 0.66745 (* 1 = 0.66745 loss)
I0521 23:56:28.353251 13093 sgd_solver.cpp:106] Iteration 30000, lr = 0.002
I0521 23:56:40.580790 13093 solver.cpp:237] Iteration 30750, loss = 0.841952
I0521 23:56:40.580943 13093 solver.cpp:253]     Train net output #0: loss = 0.841951 (* 1 = 0.841951 loss)
I0521 23:56:40.580957 13093 sgd_solver.cpp:106] Iteration 30750, lr = 0.002
I0521 23:56:52.820983 13093 solver.cpp:237] Iteration 31500, loss = 1.02654
I0521 23:56:52.821017 13093 solver.cpp:253]     Train net output #0: loss = 1.02654 (* 1 = 1.02654 loss)
I0521 23:56:52.821034 13093 sgd_solver.cpp:106] Iteration 31500, lr = 0.002
I0521 23:57:05.063081 13093 solver.cpp:237] Iteration 32250, loss = 1.53855
I0521 23:57:05.063117 13093 solver.cpp:253]     Train net output #0: loss = 1.53855 (* 1 = 1.53855 loss)
I0521 23:57:05.063133 13093 sgd_solver.cpp:106] Iteration 32250, lr = 0.002
I0521 23:57:17.283956 13093 solver.cpp:237] Iteration 33000, loss = 0.902911
I0521 23:57:17.284106 13093 solver.cpp:253]     Train net output #0: loss = 0.90291 (* 1 = 0.90291 loss)
I0521 23:57:17.284121 13093 sgd_solver.cpp:106] Iteration 33000, lr = 0.002
I0521 23:57:29.480111 13093 solver.cpp:237] Iteration 33750, loss = 1.43378
I0521 23:57:29.480149 13093 solver.cpp:253]     Train net output #0: loss = 1.43377 (* 1 = 1.43377 loss)
I0521 23:57:29.480165 13093 sgd_solver.cpp:106] Iteration 33750, lr = 0.002
I0521 23:57:41.679056 13093 solver.cpp:237] Iteration 34500, loss = 0.95234
I0521 23:57:41.679100 13093 solver.cpp:253]     Train net output #0: loss = 0.952339 (* 1 = 0.952339 loss)
I0521 23:57:41.679117 13093 sgd_solver.cpp:106] Iteration 34500, lr = 0.002
I0521 23:58:16.025754 13093 solver.cpp:237] Iteration 35250, loss = 1.49137
I0521 23:58:16.025919 13093 solver.cpp:253]     Train net output #0: loss = 1.49137 (* 1 = 1.49137 loss)
I0521 23:58:16.025933 13093 sgd_solver.cpp:106] Iteration 35250, lr = 0.002
I0521 23:58:28.237681 13093 solver.cpp:237] Iteration 36000, loss = 1.15011
I0521 23:58:28.237727 13093 solver.cpp:253]     Train net output #0: loss = 1.15011 (* 1 = 1.15011 loss)
I0521 23:58:28.237743 13093 sgd_solver.cpp:106] Iteration 36000, lr = 0.002
I0521 23:58:40.458189 13093 solver.cpp:237] Iteration 36750, loss = 1.06865
I0521 23:58:40.458225 13093 solver.cpp:253]     Train net output #0: loss = 1.06865 (* 1 = 1.06865 loss)
I0521 23:58:40.458241 13093 sgd_solver.cpp:106] Iteration 36750, lr = 0.002
I0521 23:58:52.646292 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_37500.caffemodel
I0521 23:58:52.702435 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_37500.solverstate
I0521 23:58:52.735783 13093 solver.cpp:237] Iteration 37500, loss = 1.79984
I0521 23:58:52.735833 13093 solver.cpp:253]     Train net output #0: loss = 1.79984 (* 1 = 1.79984 loss)
I0521 23:58:52.735851 13093 sgd_solver.cpp:106] Iteration 37500, lr = 0.002
I0521 23:59:04.955538 13093 solver.cpp:237] Iteration 38250, loss = 1.74962
I0521 23:59:04.955574 13093 solver.cpp:253]     Train net output #0: loss = 1.74962 (* 1 = 1.74962 loss)
I0521 23:59:04.955590 13093 sgd_solver.cpp:106] Iteration 38250, lr = 0.002
I0521 23:59:17.133592 13093 solver.cpp:237] Iteration 39000, loss = 1.23
I0521 23:59:17.133643 13093 solver.cpp:253]     Train net output #0: loss = 1.23 (* 1 = 1.23 loss)
I0521 23:59:17.133657 13093 sgd_solver.cpp:106] Iteration 39000, lr = 0.002
I0521 23:59:29.270130 13093 solver.cpp:237] Iteration 39750, loss = 0.882678
I0521 23:59:29.270277 13093 solver.cpp:253]     Train net output #0: loss = 0.882676 (* 1 = 0.882676 loss)
I0521 23:59:29.270292 13093 sgd_solver.cpp:106] Iteration 39750, lr = 0.002
I0522 00:00:03.547318 13093 solver.cpp:237] Iteration 40500, loss = 1.15757
I0522 00:00:03.547495 13093 solver.cpp:253]     Train net output #0: loss = 1.15757 (* 1 = 1.15757 loss)
I0522 00:00:03.547510 13093 sgd_solver.cpp:106] Iteration 40500, lr = 0.002
I0522 00:00:15.682715 13093 solver.cpp:237] Iteration 41250, loss = 1.05279
I0522 00:00:15.682751 13093 solver.cpp:253]     Train net output #0: loss = 1.05279 (* 1 = 1.05279 loss)
I0522 00:00:15.682768 13093 sgd_solver.cpp:106] Iteration 41250, lr = 0.002
I0522 00:00:27.832638 13093 solver.cpp:237] Iteration 42000, loss = 1.53103
I0522 00:00:27.832682 13093 solver.cpp:253]     Train net output #0: loss = 1.53103 (* 1 = 1.53103 loss)
I0522 00:00:27.832698 13093 sgd_solver.cpp:106] Iteration 42000, lr = 0.002
I0522 00:00:39.992846 13093 solver.cpp:237] Iteration 42750, loss = 1.46669
I0522 00:00:39.992988 13093 solver.cpp:253]     Train net output #0: loss = 1.46669 (* 1 = 1.46669 loss)
I0522 00:00:39.993005 13093 sgd_solver.cpp:106] Iteration 42750, lr = 0.002
I0522 00:00:52.158218 13093 solver.cpp:237] Iteration 43500, loss = 0.813859
I0522 00:00:52.158257 13093 solver.cpp:253]     Train net output #0: loss = 0.813857 (* 1 = 0.813857 loss)
I0522 00:00:52.158279 13093 sgd_solver.cpp:106] Iteration 43500, lr = 0.002
I0522 00:01:04.327270 13093 solver.cpp:237] Iteration 44250, loss = 0.910969
I0522 00:01:04.327306 13093 solver.cpp:253]     Train net output #0: loss = 0.910967 (* 1 = 0.910967 loss)
I0522 00:01:04.327322 13093 sgd_solver.cpp:106] Iteration 44250, lr = 0.002
I0522 00:01:16.481282 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_45000.caffemodel
I0522 00:01:16.530922 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_45000.solverstate
I0522 00:01:16.557099 13093 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 00:02:08.238298 13093 solver.cpp:409]     Test net output #0: accuracy = 0.872242
I0522 00:02:08.238456 13093 solver.cpp:409]     Test net output #1: loss = 0.432041 (* 1 = 0.432041 loss)
I0522 00:02:30.330332 13093 solver.cpp:237] Iteration 45000, loss = 1.10791
I0522 00:02:30.330384 13093 solver.cpp:253]     Train net output #0: loss = 1.10791 (* 1 = 1.10791 loss)
I0522 00:02:30.330399 13093 sgd_solver.cpp:106] Iteration 45000, lr = 0.002
I0522 00:02:42.466337 13093 solver.cpp:237] Iteration 45750, loss = 1.09435
I0522 00:02:42.466495 13093 solver.cpp:253]     Train net output #0: loss = 1.09435 (* 1 = 1.09435 loss)
I0522 00:02:42.466508 13093 sgd_solver.cpp:106] Iteration 45750, lr = 0.002
I0522 00:02:54.628408 13093 solver.cpp:237] Iteration 46500, loss = 1.58129
I0522 00:02:54.628444 13093 solver.cpp:253]     Train net output #0: loss = 1.58129 (* 1 = 1.58129 loss)
I0522 00:02:54.628460 13093 sgd_solver.cpp:106] Iteration 46500, lr = 0.002
I0522 00:03:06.789683 13093 solver.cpp:237] Iteration 47250, loss = 1.02801
I0522 00:03:06.789728 13093 solver.cpp:253]     Train net output #0: loss = 1.02801 (* 1 = 1.02801 loss)
I0522 00:03:06.789743 13093 sgd_solver.cpp:106] Iteration 47250, lr = 0.002
I0522 00:03:18.885112 13093 solver.cpp:237] Iteration 48000, loss = 1.37232
I0522 00:03:18.885249 13093 solver.cpp:253]     Train net output #0: loss = 1.37232 (* 1 = 1.37232 loss)
I0522 00:03:18.885264 13093 sgd_solver.cpp:106] Iteration 48000, lr = 0.002
I0522 00:03:31.009871 13093 solver.cpp:237] Iteration 48750, loss = 1.40679
I0522 00:03:31.009915 13093 solver.cpp:253]     Train net output #0: loss = 1.40678 (* 1 = 1.40678 loss)
I0522 00:03:31.009932 13093 sgd_solver.cpp:106] Iteration 48750, lr = 0.002
I0522 00:03:43.139950 13093 solver.cpp:237] Iteration 49500, loss = 1.13128
I0522 00:03:43.139986 13093 solver.cpp:253]     Train net output #0: loss = 1.13128 (* 1 = 1.13128 loss)
I0522 00:03:43.140002 13093 sgd_solver.cpp:106] Iteration 49500, lr = 0.002
I0522 00:04:17.369449 13093 solver.cpp:237] Iteration 50250, loss = 1.42631
I0522 00:04:17.369622 13093 solver.cpp:253]     Train net output #0: loss = 1.42631 (* 1 = 1.42631 loss)
I0522 00:04:17.369637 13093 sgd_solver.cpp:106] Iteration 50250, lr = 0.002
I0522 00:04:29.492378 13093 solver.cpp:237] Iteration 51000, loss = 1.00606
I0522 00:04:29.492413 13093 solver.cpp:253]     Train net output #0: loss = 1.00605 (* 1 = 1.00605 loss)
I0522 00:04:29.492432 13093 sgd_solver.cpp:106] Iteration 51000, lr = 0.002
I0522 00:04:41.636450 13093 solver.cpp:237] Iteration 51750, loss = 1.68382
I0522 00:04:41.636498 13093 solver.cpp:253]     Train net output #0: loss = 1.68382 (* 1 = 1.68382 loss)
I0522 00:04:41.636513 13093 sgd_solver.cpp:106] Iteration 51750, lr = 0.002
I0522 00:04:53.767153 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_52500.caffemodel
I0522 00:04:53.816754 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_52500.solverstate
I0522 00:04:53.847903 13093 solver.cpp:237] Iteration 52500, loss = 1.11933
I0522 00:04:53.847949 13093 solver.cpp:253]     Train net output #0: loss = 1.11933 (* 1 = 1.11933 loss)
I0522 00:04:53.847970 13093 sgd_solver.cpp:106] Iteration 52500, lr = 0.002
I0522 00:05:05.964646 13093 solver.cpp:237] Iteration 53250, loss = 1.09918
I0522 00:05:05.964695 13093 solver.cpp:253]     Train net output #0: loss = 1.09918 (* 1 = 1.09918 loss)
I0522 00:05:05.964709 13093 sgd_solver.cpp:106] Iteration 53250, lr = 0.002
I0522 00:05:18.032071 13093 solver.cpp:237] Iteration 54000, loss = 1.11862
I0522 00:05:18.032107 13093 solver.cpp:253]     Train net output #0: loss = 1.11862 (* 1 = 1.11862 loss)
I0522 00:05:18.032124 13093 sgd_solver.cpp:106] Iteration 54000, lr = 0.002
I0522 00:05:30.066546 13093 solver.cpp:237] Iteration 54750, loss = 1.17803
I0522 00:05:30.066706 13093 solver.cpp:253]     Train net output #0: loss = 1.17803 (* 1 = 1.17803 loss)
I0522 00:05:30.066720 13093 sgd_solver.cpp:106] Iteration 54750, lr = 0.002
I0522 00:06:04.294348 13093 solver.cpp:237] Iteration 55500, loss = 1.42933
I0522 00:06:04.294513 13093 solver.cpp:253]     Train net output #0: loss = 1.42933 (* 1 = 1.42933 loss)
I0522 00:06:04.294528 13093 sgd_solver.cpp:106] Iteration 55500, lr = 0.002
I0522 00:06:16.417908 13093 solver.cpp:237] Iteration 56250, loss = 0.748421
I0522 00:06:16.417951 13093 solver.cpp:253]     Train net output #0: loss = 0.748421 (* 1 = 0.748421 loss)
I0522 00:06:16.417971 13093 sgd_solver.cpp:106] Iteration 56250, lr = 0.002
I0522 00:06:28.531970 13093 solver.cpp:237] Iteration 57000, loss = 1.37259
I0522 00:06:28.532006 13093 solver.cpp:253]     Train net output #0: loss = 1.37259 (* 1 = 1.37259 loss)
I0522 00:06:28.532022 13093 sgd_solver.cpp:106] Iteration 57000, lr = 0.002
I0522 00:06:40.641969 13093 solver.cpp:237] Iteration 57750, loss = 1.41016
I0522 00:06:40.642115 13093 solver.cpp:253]     Train net output #0: loss = 1.41016 (* 1 = 1.41016 loss)
I0522 00:06:40.642129 13093 sgd_solver.cpp:106] Iteration 57750, lr = 0.002
I0522 00:06:52.687403 13093 solver.cpp:237] Iteration 58500, loss = 1.13691
I0522 00:06:52.687440 13093 solver.cpp:253]     Train net output #0: loss = 1.13691 (* 1 = 1.13691 loss)
I0522 00:06:52.687456 13093 sgd_solver.cpp:106] Iteration 58500, lr = 0.002
I0522 00:07:04.739017 13093 solver.cpp:237] Iteration 59250, loss = 1.20685
I0522 00:07:04.739053 13093 solver.cpp:253]     Train net output #0: loss = 1.20685 (* 1 = 1.20685 loss)
I0522 00:07:04.739069 13093 sgd_solver.cpp:106] Iteration 59250, lr = 0.002
I0522 00:07:16.878684 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_60000.caffemodel
I0522 00:07:16.928241 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_60000.solverstate
I0522 00:07:16.954432 13093 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 00:08:29.672862 13093 solver.cpp:409]     Test net output #0: accuracy = 0.874729
I0522 00:08:29.673033 13093 solver.cpp:409]     Test net output #1: loss = 0.421614 (* 1 = 0.421614 loss)
I0522 00:08:51.804159 13093 solver.cpp:237] Iteration 60000, loss = 1.72355
I0522 00:08:51.804213 13093 solver.cpp:253]     Train net output #0: loss = 1.72355 (* 1 = 1.72355 loss)
I0522 00:08:51.804226 13093 sgd_solver.cpp:106] Iteration 60000, lr = 0.002
I0522 00:09:04.028823 13093 solver.cpp:237] Iteration 60750, loss = 1.26363
I0522 00:09:04.028980 13093 solver.cpp:253]     Train net output #0: loss = 1.26363 (* 1 = 1.26363 loss)
I0522 00:09:04.028992 13093 sgd_solver.cpp:106] Iteration 60750, lr = 0.002
I0522 00:09:16.242606 13093 solver.cpp:237] Iteration 61500, loss = 1.0537
I0522 00:09:16.242650 13093 solver.cpp:253]     Train net output #0: loss = 1.0537 (* 1 = 1.0537 loss)
I0522 00:09:16.242666 13093 sgd_solver.cpp:106] Iteration 61500, lr = 0.002
I0522 00:09:28.434360 13093 solver.cpp:237] Iteration 62250, loss = 0.996242
I0522 00:09:28.434396 13093 solver.cpp:253]     Train net output #0: loss = 0.996242 (* 1 = 0.996242 loss)
I0522 00:09:28.434414 13093 sgd_solver.cpp:106] Iteration 62250, lr = 0.002
I0522 00:09:40.649665 13093 solver.cpp:237] Iteration 63000, loss = 0.831426
I0522 00:09:40.649814 13093 solver.cpp:253]     Train net output #0: loss = 0.831425 (* 1 = 0.831425 loss)
I0522 00:09:40.649828 13093 sgd_solver.cpp:106] Iteration 63000, lr = 0.002
I0522 00:09:52.825065 13093 solver.cpp:237] Iteration 63750, loss = 1.17397
I0522 00:09:52.825101 13093 solver.cpp:253]     Train net output #0: loss = 1.17397 (* 1 = 1.17397 loss)
I0522 00:09:52.825117 13093 sgd_solver.cpp:106] Iteration 63750, lr = 0.002
I0522 00:10:05.001682 13093 solver.cpp:237] Iteration 64500, loss = 1.0702
I0522 00:10:05.001729 13093 solver.cpp:253]     Train net output #0: loss = 1.0702 (* 1 = 1.0702 loss)
I0522 00:10:05.001744 13093 sgd_solver.cpp:106] Iteration 64500, lr = 0.002
I0522 00:10:39.297170 13093 solver.cpp:237] Iteration 65250, loss = 1.05282
I0522 00:10:39.297338 13093 solver.cpp:253]     Train net output #0: loss = 1.05282 (* 1 = 1.05282 loss)
I0522 00:10:39.297353 13093 sgd_solver.cpp:106] Iteration 65250, lr = 0.002
I0522 00:10:51.418314 13093 solver.cpp:237] Iteration 66000, loss = 1.4604
I0522 00:10:51.418359 13093 solver.cpp:253]     Train net output #0: loss = 1.4604 (* 1 = 1.4604 loss)
I0522 00:10:51.418372 13093 sgd_solver.cpp:106] Iteration 66000, lr = 0.002
I0522 00:11:03.559473 13093 solver.cpp:237] Iteration 66750, loss = 1.43992
I0522 00:11:03.559509 13093 solver.cpp:253]     Train net output #0: loss = 1.43992 (* 1 = 1.43992 loss)
I0522 00:11:03.559525 13093 sgd_solver.cpp:106] Iteration 66750, lr = 0.002
I0522 00:11:15.672392 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_67500.caffemodel
I0522 00:11:15.723685 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_67500.solverstate
I0522 00:11:15.756871 13093 solver.cpp:237] Iteration 67500, loss = 1.37615
I0522 00:11:15.756922 13093 solver.cpp:253]     Train net output #0: loss = 1.37615 (* 1 = 1.37615 loss)
I0522 00:11:15.756937 13093 sgd_solver.cpp:106] Iteration 67500, lr = 0.002
I0522 00:11:27.910645 13093 solver.cpp:237] Iteration 68250, loss = 1.30855
I0522 00:11:27.910681 13093 solver.cpp:253]     Train net output #0: loss = 1.30855 (* 1 = 1.30855 loss)
I0522 00:11:27.910696 13093 sgd_solver.cpp:106] Iteration 68250, lr = 0.002
I0522 00:11:40.055776 13093 solver.cpp:237] Iteration 69000, loss = 2.11501
I0522 00:11:40.055814 13093 solver.cpp:253]     Train net output #0: loss = 2.11501 (* 1 = 2.11501 loss)
I0522 00:11:40.055829 13093 sgd_solver.cpp:106] Iteration 69000, lr = 0.002
I0522 00:11:52.179630 13093 solver.cpp:237] Iteration 69750, loss = 1.00446
I0522 00:11:52.179795 13093 solver.cpp:253]     Train net output #0: loss = 1.00446 (* 1 = 1.00446 loss)
I0522 00:11:52.179808 13093 sgd_solver.cpp:106] Iteration 69750, lr = 0.002
I0522 00:12:26.490819 13093 solver.cpp:237] Iteration 70500, loss = 0.945271
I0522 00:12:26.490990 13093 solver.cpp:253]     Train net output #0: loss = 0.945271 (* 1 = 0.945271 loss)
I0522 00:12:26.491006 13093 sgd_solver.cpp:106] Iteration 70500, lr = 0.002
I0522 00:12:38.642151 13093 solver.cpp:237] Iteration 71250, loss = 1.25457
I0522 00:12:38.642195 13093 solver.cpp:253]     Train net output #0: loss = 1.25457 (* 1 = 1.25457 loss)
I0522 00:12:38.642210 13093 sgd_solver.cpp:106] Iteration 71250, lr = 0.002
I0522 00:12:50.767923 13093 solver.cpp:237] Iteration 72000, loss = 1.02693
I0522 00:12:50.767959 13093 solver.cpp:253]     Train net output #0: loss = 1.02693 (* 1 = 1.02693 loss)
I0522 00:12:50.767976 13093 sgd_solver.cpp:106] Iteration 72000, lr = 0.002
I0522 00:13:02.909000 13093 solver.cpp:237] Iteration 72750, loss = 1.41987
I0522 00:13:02.909153 13093 solver.cpp:253]     Train net output #0: loss = 1.41987 (* 1 = 1.41987 loss)
I0522 00:13:02.909168 13093 sgd_solver.cpp:106] Iteration 72750, lr = 0.002
I0522 00:13:15.081990 13093 solver.cpp:237] Iteration 73500, loss = 1.37903
I0522 00:13:15.082025 13093 solver.cpp:253]     Train net output #0: loss = 1.37903 (* 1 = 1.37903 loss)
I0522 00:13:15.082038 13093 sgd_solver.cpp:106] Iteration 73500, lr = 0.002
I0522 00:13:27.255025 13093 solver.cpp:237] Iteration 74250, loss = 1.73138
I0522 00:13:27.255072 13093 solver.cpp:253]     Train net output #0: loss = 1.73138 (* 1 = 1.73138 loss)
I0522 00:13:27.255086 13093 sgd_solver.cpp:106] Iteration 74250, lr = 0.002
I0522 00:13:39.417155 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_75000.caffemodel
I0522 00:13:39.468821 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_75000.solverstate
I0522 00:13:39.497159 13093 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 00:14:31.384208 13093 solver.cpp:409]     Test net output #0: accuracy = 0.884274
I0522 00:14:31.384369 13093 solver.cpp:409]     Test net output #1: loss = 0.38041 (* 1 = 0.38041 loss)
I0522 00:14:52.209972 13093 solver.cpp:237] Iteration 75000, loss = 1.20414
I0522 00:14:52.210024 13093 solver.cpp:253]     Train net output #0: loss = 1.20414 (* 1 = 1.20414 loss)
I0522 00:14:52.210039 13093 sgd_solver.cpp:106] Iteration 75000, lr = 0.002
I0522 00:15:04.324105 13093 solver.cpp:237] Iteration 75750, loss = 1.42764
I0522 00:15:04.324265 13093 solver.cpp:253]     Train net output #0: loss = 1.42764 (* 1 = 1.42764 loss)
I0522 00:15:04.324280 13093 sgd_solver.cpp:106] Iteration 75750, lr = 0.002
I0522 00:15:16.435549 13093 solver.cpp:237] Iteration 76500, loss = 0.850581
I0522 00:15:16.435585 13093 solver.cpp:253]     Train net output #0: loss = 0.850582 (* 1 = 0.850582 loss)
I0522 00:15:16.435598 13093 sgd_solver.cpp:106] Iteration 76500, lr = 0.002
I0522 00:15:28.546982 13093 solver.cpp:237] Iteration 77250, loss = 1.08587
I0522 00:15:28.547026 13093 solver.cpp:253]     Train net output #0: loss = 1.08587 (* 1 = 1.08587 loss)
I0522 00:15:28.547044 13093 sgd_solver.cpp:106] Iteration 77250, lr = 0.002
I0522 00:15:40.660207 13093 solver.cpp:237] Iteration 78000, loss = 0.905891
I0522 00:15:40.660352 13093 solver.cpp:253]     Train net output #0: loss = 0.905892 (* 1 = 0.905892 loss)
I0522 00:15:40.660367 13093 sgd_solver.cpp:106] Iteration 78000, lr = 0.002
I0522 00:15:52.787645 13093 solver.cpp:237] Iteration 78750, loss = 1.36337
I0522 00:15:52.787695 13093 solver.cpp:253]     Train net output #0: loss = 1.36337 (* 1 = 1.36337 loss)
I0522 00:15:52.787709 13093 sgd_solver.cpp:106] Iteration 78750, lr = 0.002
I0522 00:16:04.997689 13093 solver.cpp:237] Iteration 79500, loss = 1.24139
I0522 00:16:04.997725 13093 solver.cpp:253]     Train net output #0: loss = 1.24139 (* 1 = 1.24139 loss)
I0522 00:16:04.997741 13093 sgd_solver.cpp:106] Iteration 79500, lr = 0.002
I0522 00:16:38.043221 13093 solver.cpp:237] Iteration 80250, loss = 0.94668
I0522 00:16:38.043400 13093 solver.cpp:253]     Train net output #0: loss = 0.946681 (* 1 = 0.946681 loss)
I0522 00:16:38.043414 13093 sgd_solver.cpp:106] Iteration 80250, lr = 0.002
I0522 00:16:50.299513 13093 solver.cpp:237] Iteration 81000, loss = 0.825523
I0522 00:16:50.299562 13093 solver.cpp:253]     Train net output #0: loss = 0.825524 (* 1 = 0.825524 loss)
I0522 00:16:50.299576 13093 sgd_solver.cpp:106] Iteration 81000, lr = 0.002
I0522 00:17:02.542728 13093 solver.cpp:237] Iteration 81750, loss = 1.73999
I0522 00:17:02.542764 13093 solver.cpp:253]     Train net output #0: loss = 1.73999 (* 1 = 1.73999 loss)
I0522 00:17:02.542781 13093 sgd_solver.cpp:106] Iteration 81750, lr = 0.002
I0522 00:17:14.756973 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_82500.caffemodel
I0522 00:17:14.805696 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_82500.solverstate
I0522 00:17:14.836756 13093 solver.cpp:237] Iteration 82500, loss = 0.958409
I0522 00:17:14.836802 13093 solver.cpp:253]     Train net output #0: loss = 0.958409 (* 1 = 0.958409 loss)
I0522 00:17:14.836817 13093 sgd_solver.cpp:106] Iteration 82500, lr = 0.002
I0522 00:17:27.063469 13093 solver.cpp:237] Iteration 83250, loss = 1.66877
I0522 00:17:27.063506 13093 solver.cpp:253]     Train net output #0: loss = 1.66877 (* 1 = 1.66877 loss)
I0522 00:17:27.063522 13093 sgd_solver.cpp:106] Iteration 83250, lr = 0.002
I0522 00:17:39.241111 13093 solver.cpp:237] Iteration 84000, loss = 1.00226
I0522 00:17:39.241159 13093 solver.cpp:253]     Train net output #0: loss = 1.00226 (* 1 = 1.00226 loss)
I0522 00:17:39.241174 13093 sgd_solver.cpp:106] Iteration 84000, lr = 0.002
I0522 00:17:51.428928 13093 solver.cpp:237] Iteration 84750, loss = 1.37444
I0522 00:17:51.429080 13093 solver.cpp:253]     Train net output #0: loss = 1.37444 (* 1 = 1.37444 loss)
I0522 00:17:51.429095 13093 sgd_solver.cpp:106] Iteration 84750, lr = 0.002
I0522 00:18:24.417129 13093 solver.cpp:237] Iteration 85500, loss = 1.04574
I0522 00:18:24.417297 13093 solver.cpp:253]     Train net output #0: loss = 1.04574 (* 1 = 1.04574 loss)
I0522 00:18:24.417311 13093 sgd_solver.cpp:106] Iteration 85500, lr = 0.002
I0522 00:18:36.602840 13093 solver.cpp:237] Iteration 86250, loss = 1.2462
I0522 00:18:36.602876 13093 solver.cpp:253]     Train net output #0: loss = 1.2462 (* 1 = 1.2462 loss)
I0522 00:18:36.602892 13093 sgd_solver.cpp:106] Iteration 86250, lr = 0.002
I0522 00:18:48.792876 13093 solver.cpp:237] Iteration 87000, loss = 0.92419
I0522 00:18:48.792925 13093 solver.cpp:253]     Train net output #0: loss = 0.924191 (* 1 = 0.924191 loss)
I0522 00:18:48.792939 13093 sgd_solver.cpp:106] Iteration 87000, lr = 0.002
I0522 00:19:01.030664 13093 solver.cpp:237] Iteration 87750, loss = 0.909861
I0522 00:19:01.030813 13093 solver.cpp:253]     Train net output #0: loss = 0.909862 (* 1 = 0.909862 loss)
I0522 00:19:01.030827 13093 sgd_solver.cpp:106] Iteration 87750, lr = 0.002
I0522 00:19:13.252627 13093 solver.cpp:237] Iteration 88500, loss = 1.58761
I0522 00:19:13.252676 13093 solver.cpp:253]     Train net output #0: loss = 1.58761 (* 1 = 1.58761 loss)
I0522 00:19:13.252691 13093 sgd_solver.cpp:106] Iteration 88500, lr = 0.002
I0522 00:19:25.455467 13093 solver.cpp:237] Iteration 89250, loss = 1.50438
I0522 00:19:25.455504 13093 solver.cpp:253]     Train net output #0: loss = 1.50438 (* 1 = 1.50438 loss)
I0522 00:19:25.455521 13093 sgd_solver.cpp:106] Iteration 89250, lr = 0.002
I0522 00:19:37.634968 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_90000.caffemodel
I0522 00:19:37.683997 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_90000.solverstate
I0522 00:19:37.710157 13093 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 00:20:50.525882 13093 solver.cpp:409]     Test net output #0: accuracy = 0.884494
I0522 00:20:50.526051 13093 solver.cpp:409]     Test net output #1: loss = 0.374783 (* 1 = 0.374783 loss)
I0522 00:21:11.409906 13093 solver.cpp:237] Iteration 90000, loss = 0.692361
I0522 00:21:11.409961 13093 solver.cpp:253]     Train net output #0: loss = 0.692361 (* 1 = 0.692361 loss)
I0522 00:21:11.409976 13093 sgd_solver.cpp:106] Iteration 90000, lr = 0.002
I0522 00:21:23.606987 13093 solver.cpp:237] Iteration 90750, loss = 1.68569
I0522 00:21:23.607159 13093 solver.cpp:253]     Train net output #0: loss = 1.68569 (* 1 = 1.68569 loss)
I0522 00:21:23.607175 13093 sgd_solver.cpp:106] Iteration 90750, lr = 0.002
I0522 00:21:35.722306 13093 solver.cpp:237] Iteration 91500, loss = 1.00127
I0522 00:21:35.722342 13093 solver.cpp:253]     Train net output #0: loss = 1.00127 (* 1 = 1.00127 loss)
I0522 00:21:35.722358 13093 sgd_solver.cpp:106] Iteration 91500, lr = 0.002
I0522 00:21:47.873466 13093 solver.cpp:237] Iteration 92250, loss = 0.823289
I0522 00:21:47.873517 13093 solver.cpp:253]     Train net output #0: loss = 0.82329 (* 1 = 0.82329 loss)
I0522 00:21:47.873530 13093 sgd_solver.cpp:106] Iteration 92250, lr = 0.002
I0522 00:22:00.006963 13093 solver.cpp:237] Iteration 93000, loss = 0.931032
I0522 00:22:00.007114 13093 solver.cpp:253]     Train net output #0: loss = 0.931033 (* 1 = 0.931033 loss)
I0522 00:22:00.007129 13093 sgd_solver.cpp:106] Iteration 93000, lr = 0.002
I0522 00:22:12.137240 13093 solver.cpp:237] Iteration 93750, loss = 1.12862
I0522 00:22:12.137289 13093 solver.cpp:253]     Train net output #0: loss = 1.12862 (* 1 = 1.12862 loss)
I0522 00:22:12.137305 13093 sgd_solver.cpp:106] Iteration 93750, lr = 0.002
I0522 00:22:24.285655 13093 solver.cpp:237] Iteration 94500, loss = 1.29753
I0522 00:22:24.285691 13093 solver.cpp:253]     Train net output #0: loss = 1.29753 (* 1 = 1.29753 loss)
I0522 00:22:24.285706 13093 sgd_solver.cpp:106] Iteration 94500, lr = 0.002
I0522 00:22:57.290029 13093 solver.cpp:237] Iteration 95250, loss = 1.21038
I0522 00:22:57.290197 13093 solver.cpp:253]     Train net output #0: loss = 1.21038 (* 1 = 1.21038 loss)
I0522 00:22:57.290211 13093 sgd_solver.cpp:106] Iteration 95250, lr = 0.002
I0522 00:23:09.397228 13093 solver.cpp:237] Iteration 96000, loss = 1.54319
I0522 00:23:09.397264 13093 solver.cpp:253]     Train net output #0: loss = 1.54319 (* 1 = 1.54319 loss)
I0522 00:23:09.397279 13093 sgd_solver.cpp:106] Iteration 96000, lr = 0.002
I0522 00:23:21.584959 13093 solver.cpp:237] Iteration 96750, loss = 1.16975
I0522 00:23:21.584998 13093 solver.cpp:253]     Train net output #0: loss = 1.16975 (* 1 = 1.16975 loss)
I0522 00:23:21.585016 13093 sgd_solver.cpp:106] Iteration 96750, lr = 0.002
I0522 00:23:33.739926 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_97500.caffemodel
I0522 00:23:33.789341 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_97500.solverstate
I0522 00:23:33.820664 13093 solver.cpp:237] Iteration 97500, loss = 1.44964
I0522 00:23:33.820710 13093 solver.cpp:253]     Train net output #0: loss = 1.44964 (* 1 = 1.44964 loss)
I0522 00:23:33.820725 13093 sgd_solver.cpp:106] Iteration 97500, lr = 0.002
I0522 00:23:45.988008 13093 solver.cpp:237] Iteration 98250, loss = 1.04984
I0522 00:23:45.988054 13093 solver.cpp:253]     Train net output #0: loss = 1.04984 (* 1 = 1.04984 loss)
I0522 00:23:45.988073 13093 sgd_solver.cpp:106] Iteration 98250, lr = 0.002
I0522 00:23:58.123023 13093 solver.cpp:237] Iteration 99000, loss = 1.08084
I0522 00:23:58.123059 13093 solver.cpp:253]     Train net output #0: loss = 1.08085 (* 1 = 1.08085 loss)
I0522 00:23:58.123075 13093 sgd_solver.cpp:106] Iteration 99000, lr = 0.002
I0522 00:24:10.237422 13093 solver.cpp:237] Iteration 99750, loss = 1.00076
I0522 00:24:10.237584 13093 solver.cpp:253]     Train net output #0: loss = 1.00076 (* 1 = 1.00076 loss)
I0522 00:24:10.237597 13093 sgd_solver.cpp:106] Iteration 99750, lr = 0.002
I0522 00:24:43.195129 13093 solver.cpp:237] Iteration 100500, loss = 0.867485
I0522 00:24:43.195317 13093 solver.cpp:253]     Train net output #0: loss = 0.867486 (* 1 = 0.867486 loss)
I0522 00:24:43.195333 13093 sgd_solver.cpp:106] Iteration 100500, lr = 0.002
I0522 00:24:55.309202 13093 solver.cpp:237] Iteration 101250, loss = 1.11711
I0522 00:24:55.309238 13093 solver.cpp:253]     Train net output #0: loss = 1.11711 (* 1 = 1.11711 loss)
I0522 00:24:55.309254 13093 sgd_solver.cpp:106] Iteration 101250, lr = 0.002
I0522 00:25:07.419256 13093 solver.cpp:237] Iteration 102000, loss = 1.24922
I0522 00:25:07.419301 13093 solver.cpp:253]     Train net output #0: loss = 1.24922 (* 1 = 1.24922 loss)
I0522 00:25:07.419317 13093 sgd_solver.cpp:106] Iteration 102000, lr = 0.002
I0522 00:25:19.569315 13093 solver.cpp:237] Iteration 102750, loss = 1.39263
I0522 00:25:19.569463 13093 solver.cpp:253]     Train net output #0: loss = 1.39263 (* 1 = 1.39263 loss)
I0522 00:25:19.569478 13093 sgd_solver.cpp:106] Iteration 102750, lr = 0.002
I0522 00:25:31.709281 13093 solver.cpp:237] Iteration 103500, loss = 1.16608
I0522 00:25:31.709327 13093 solver.cpp:253]     Train net output #0: loss = 1.16608 (* 1 = 1.16608 loss)
I0522 00:25:31.709344 13093 sgd_solver.cpp:106] Iteration 103500, lr = 0.002
I0522 00:25:43.825789 13093 solver.cpp:237] Iteration 104250, loss = 1.06352
I0522 00:25:43.825826 13093 solver.cpp:253]     Train net output #0: loss = 1.06352 (* 1 = 1.06352 loss)
I0522 00:25:43.825842 13093 sgd_solver.cpp:106] Iteration 104250, lr = 0.002
I0522 00:25:55.950086 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_105000.caffemodel
I0522 00:25:55.999249 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_105000.solverstate
I0522 00:25:56.024130 13093 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 00:26:47.569777 13093 solver.cpp:409]     Test net output #0: accuracy = 0.884595
I0522 00:26:47.569942 13093 solver.cpp:409]     Test net output #1: loss = 0.422809 (* 1 = 0.422809 loss)
I0522 00:27:08.431869 13093 solver.cpp:237] Iteration 105000, loss = 1.13069
I0522 00:27:08.431922 13093 solver.cpp:253]     Train net output #0: loss = 1.13069 (* 1 = 1.13069 loss)
I0522 00:27:08.431937 13093 sgd_solver.cpp:106] Iteration 105000, lr = 0.002
I0522 00:27:20.578017 13093 solver.cpp:237] Iteration 105750, loss = 0.804012
I0522 00:27:20.578177 13093 solver.cpp:253]     Train net output #0: loss = 0.804013 (* 1 = 0.804013 loss)
I0522 00:27:20.578192 13093 sgd_solver.cpp:106] Iteration 105750, lr = 0.002
I0522 00:27:32.665562 13093 solver.cpp:237] Iteration 106500, loss = 1.3423
I0522 00:27:32.665606 13093 solver.cpp:253]     Train net output #0: loss = 1.3423 (* 1 = 1.3423 loss)
I0522 00:27:32.665622 13093 sgd_solver.cpp:106] Iteration 106500, lr = 0.002
I0522 00:27:44.738106 13093 solver.cpp:237] Iteration 107250, loss = 1.01249
I0522 00:27:44.738140 13093 solver.cpp:253]     Train net output #0: loss = 1.01249 (* 1 = 1.01249 loss)
I0522 00:27:44.738157 13093 sgd_solver.cpp:106] Iteration 107250, lr = 0.002
I0522 00:27:56.856086 13093 solver.cpp:237] Iteration 108000, loss = 0.809295
I0522 00:27:56.856250 13093 solver.cpp:253]     Train net output #0: loss = 0.809296 (* 1 = 0.809296 loss)
I0522 00:27:56.856264 13093 sgd_solver.cpp:106] Iteration 108000, lr = 0.002
I0522 00:28:08.997753 13093 solver.cpp:237] Iteration 108750, loss = 1.1933
I0522 00:28:08.997788 13093 solver.cpp:253]     Train net output #0: loss = 1.1933 (* 1 = 1.1933 loss)
I0522 00:28:08.997805 13093 sgd_solver.cpp:106] Iteration 108750, lr = 0.002
I0522 00:28:21.158148 13093 solver.cpp:237] Iteration 109500, loss = 1.38295
I0522 00:28:21.158187 13093 solver.cpp:253]     Train net output #0: loss = 1.38295 (* 1 = 1.38295 loss)
I0522 00:28:21.158206 13093 sgd_solver.cpp:106] Iteration 109500, lr = 0.002
I0522 00:28:54.102864 13093 solver.cpp:237] Iteration 110250, loss = 1.35872
I0522 00:28:54.103045 13093 solver.cpp:253]     Train net output #0: loss = 1.35872 (* 1 = 1.35872 loss)
I0522 00:28:54.103060 13093 sgd_solver.cpp:106] Iteration 110250, lr = 0.002
I0522 00:29:06.241595 13093 solver.cpp:237] Iteration 111000, loss = 1.56126
I0522 00:29:06.241632 13093 solver.cpp:253]     Train net output #0: loss = 1.56126 (* 1 = 1.56126 loss)
I0522 00:29:06.241649 13093 sgd_solver.cpp:106] Iteration 111000, lr = 0.002
I0522 00:29:18.396553 13093 solver.cpp:237] Iteration 111750, loss = 0.801752
I0522 00:29:18.396595 13093 solver.cpp:253]     Train net output #0: loss = 0.801753 (* 1 = 0.801753 loss)
I0522 00:29:18.396610 13093 sgd_solver.cpp:106] Iteration 111750, lr = 0.002
I0522 00:29:30.520216 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_112500.caffemodel
I0522 00:29:30.571447 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_112500.solverstate
I0522 00:29:30.603734 13093 solver.cpp:237] Iteration 112500, loss = 1.20451
I0522 00:29:30.603781 13093 solver.cpp:253]     Train net output #0: loss = 1.20451 (* 1 = 1.20451 loss)
I0522 00:29:30.603801 13093 sgd_solver.cpp:106] Iteration 112500, lr = 0.002
I0522 00:29:42.711304 13093 solver.cpp:237] Iteration 113250, loss = 1.3887
I0522 00:29:42.711349 13093 solver.cpp:253]     Train net output #0: loss = 1.3887 (* 1 = 1.3887 loss)
I0522 00:29:42.711364 13093 sgd_solver.cpp:106] Iteration 113250, lr = 0.002
I0522 00:29:54.825803 13093 solver.cpp:237] Iteration 114000, loss = 1.41434
I0522 00:29:54.825840 13093 solver.cpp:253]     Train net output #0: loss = 1.41434 (* 1 = 1.41434 loss)
I0522 00:29:54.825855 13093 sgd_solver.cpp:106] Iteration 114000, lr = 0.002
I0522 00:30:06.940294 13093 solver.cpp:237] Iteration 114750, loss = 1.03977
I0522 00:30:06.940461 13093 solver.cpp:253]     Train net output #0: loss = 1.03977 (* 1 = 1.03977 loss)
I0522 00:30:06.940476 13093 sgd_solver.cpp:106] Iteration 114750, lr = 0.002
I0522 00:30:39.953650 13093 solver.cpp:237] Iteration 115500, loss = 1.05011
I0522 00:30:39.953822 13093 solver.cpp:253]     Train net output #0: loss = 1.05011 (* 1 = 1.05011 loss)
I0522 00:30:39.953838 13093 sgd_solver.cpp:106] Iteration 115500, lr = 0.002
I0522 00:30:52.065716 13093 solver.cpp:237] Iteration 116250, loss = 0.704275
I0522 00:30:52.065763 13093 solver.cpp:253]     Train net output #0: loss = 0.704276 (* 1 = 0.704276 loss)
I0522 00:30:52.065781 13093 sgd_solver.cpp:106] Iteration 116250, lr = 0.002
I0522 00:31:04.173096 13093 solver.cpp:237] Iteration 117000, loss = 1.46787
I0522 00:31:04.173131 13093 solver.cpp:253]     Train net output #0: loss = 1.46787 (* 1 = 1.46787 loss)
I0522 00:31:04.173147 13093 sgd_solver.cpp:106] Iteration 117000, lr = 0.002
I0522 00:31:16.278758 13093 solver.cpp:237] Iteration 117750, loss = 1.15592
I0522 00:31:16.278916 13093 solver.cpp:253]     Train net output #0: loss = 1.15592 (* 1 = 1.15592 loss)
I0522 00:31:16.278930 13093 sgd_solver.cpp:106] Iteration 117750, lr = 0.002
I0522 00:31:28.424067 13093 solver.cpp:237] Iteration 118500, loss = 1.03066
I0522 00:31:28.424101 13093 solver.cpp:253]     Train net output #0: loss = 1.03066 (* 1 = 1.03066 loss)
I0522 00:31:28.424116 13093 sgd_solver.cpp:106] Iteration 118500, lr = 0.002
I0522 00:31:40.528005 13093 solver.cpp:237] Iteration 119250, loss = 1.33758
I0522 00:31:40.528056 13093 solver.cpp:253]     Train net output #0: loss = 1.33758 (* 1 = 1.33758 loss)
I0522 00:31:40.528077 13093 sgd_solver.cpp:106] Iteration 119250, lr = 0.002
I0522 00:31:52.645920 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_120000.caffemodel
I0522 00:31:52.694743 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_120000.solverstate
I0522 00:31:52.719926 13093 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 00:33:05.529309 13093 solver.cpp:409]     Test net output #0: accuracy = 0.891116
I0522 00:33:05.529479 13093 solver.cpp:409]     Test net output #1: loss = 0.358605 (* 1 = 0.358605 loss)
I0522 00:33:26.389242 13093 solver.cpp:237] Iteration 120000, loss = 1.13849
I0522 00:33:26.389295 13093 solver.cpp:253]     Train net output #0: loss = 1.13849 (* 1 = 1.13849 loss)
I0522 00:33:26.389312 13093 sgd_solver.cpp:106] Iteration 120000, lr = 0.002
I0522 00:33:38.517551 13093 solver.cpp:237] Iteration 120750, loss = 1.05759
I0522 00:33:38.517720 13093 solver.cpp:253]     Train net output #0: loss = 1.05759 (* 1 = 1.05759 loss)
I0522 00:33:38.517734 13093 sgd_solver.cpp:106] Iteration 120750, lr = 0.002
I0522 00:33:50.646181 13093 solver.cpp:237] Iteration 121500, loss = 1.16106
I0522 00:33:50.646226 13093 solver.cpp:253]     Train net output #0: loss = 1.16106 (* 1 = 1.16106 loss)
I0522 00:33:50.646241 13093 sgd_solver.cpp:106] Iteration 121500, lr = 0.002
I0522 00:34:02.769819 13093 solver.cpp:237] Iteration 122250, loss = 1.30127
I0522 00:34:02.769856 13093 solver.cpp:253]     Train net output #0: loss = 1.30128 (* 1 = 1.30128 loss)
I0522 00:34:02.769870 13093 sgd_solver.cpp:106] Iteration 122250, lr = 0.002
I0522 00:34:14.877837 13093 solver.cpp:237] Iteration 123000, loss = 1.18053
I0522 00:34:14.877997 13093 solver.cpp:253]     Train net output #0: loss = 1.18053 (* 1 = 1.18053 loss)
I0522 00:34:14.878011 13093 sgd_solver.cpp:106] Iteration 123000, lr = 0.002
I0522 00:34:26.951077 13093 solver.cpp:237] Iteration 123750, loss = 0.82552
I0522 00:34:26.951115 13093 solver.cpp:253]     Train net output #0: loss = 0.825521 (* 1 = 0.825521 loss)
I0522 00:34:26.951129 13093 sgd_solver.cpp:106] Iteration 123750, lr = 0.002
I0522 00:34:39.064448 13093 solver.cpp:237] Iteration 124500, loss = 0.865388
I0522 00:34:39.064496 13093 solver.cpp:253]     Train net output #0: loss = 0.865389 (* 1 = 0.865389 loss)
I0522 00:34:39.064509 13093 sgd_solver.cpp:106] Iteration 124500, lr = 0.002
I0522 00:35:12.070329 13093 solver.cpp:237] Iteration 125250, loss = 1.3663
I0522 00:35:12.070504 13093 solver.cpp:253]     Train net output #0: loss = 1.3663 (* 1 = 1.3663 loss)
I0522 00:35:12.070518 13093 sgd_solver.cpp:106] Iteration 125250, lr = 0.002
I0522 00:35:24.231221 13093 solver.cpp:237] Iteration 126000, loss = 1.19829
I0522 00:35:24.231252 13093 solver.cpp:253]     Train net output #0: loss = 1.19829 (* 1 = 1.19829 loss)
I0522 00:35:24.231266 13093 sgd_solver.cpp:106] Iteration 126000, lr = 0.002
I0522 00:35:36.366628 13093 solver.cpp:237] Iteration 126750, loss = 1.27972
I0522 00:35:36.366674 13093 solver.cpp:253]     Train net output #0: loss = 1.27972 (* 1 = 1.27972 loss)
I0522 00:35:36.366688 13093 sgd_solver.cpp:106] Iteration 126750, lr = 0.002
I0522 00:35:48.490686 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_127500.caffemodel
I0522 00:35:48.539705 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_127500.solverstate
I0522 00:35:48.571724 13093 solver.cpp:237] Iteration 127500, loss = 0.969124
I0522 00:35:48.571771 13093 solver.cpp:253]     Train net output #0: loss = 0.969125 (* 1 = 0.969125 loss)
I0522 00:35:48.571787 13093 sgd_solver.cpp:106] Iteration 127500, lr = 0.002
I0522 00:36:00.698623 13093 solver.cpp:237] Iteration 128250, loss = 1.36338
I0522 00:36:00.698665 13093 solver.cpp:253]     Train net output #0: loss = 1.36338 (* 1 = 1.36338 loss)
I0522 00:36:00.698680 13093 sgd_solver.cpp:106] Iteration 128250, lr = 0.002
I0522 00:36:12.834894 13093 solver.cpp:237] Iteration 129000, loss = 1.15333
I0522 00:36:12.834931 13093 solver.cpp:253]     Train net output #0: loss = 1.15333 (* 1 = 1.15333 loss)
I0522 00:36:12.834945 13093 sgd_solver.cpp:106] Iteration 129000, lr = 0.002
I0522 00:36:24.962119 13093 solver.cpp:237] Iteration 129750, loss = 1.0072
I0522 00:36:24.962296 13093 solver.cpp:253]     Train net output #0: loss = 1.0072 (* 1 = 1.0072 loss)
I0522 00:36:24.962309 13093 sgd_solver.cpp:106] Iteration 129750, lr = 0.002
I0522 00:36:57.908905 13093 solver.cpp:237] Iteration 130500, loss = 1.31012
I0522 00:36:57.909083 13093 solver.cpp:253]     Train net output #0: loss = 1.31012 (* 1 = 1.31012 loss)
I0522 00:36:57.909098 13093 sgd_solver.cpp:106] Iteration 130500, lr = 0.002
I0522 00:37:10.042700 13093 solver.cpp:237] Iteration 131250, loss = 1.43119
I0522 00:37:10.042762 13093 solver.cpp:253]     Train net output #0: loss = 1.43119 (* 1 = 1.43119 loss)
I0522 00:37:10.042776 13093 sgd_solver.cpp:106] Iteration 131250, lr = 0.002
I0522 00:37:22.176931 13093 solver.cpp:237] Iteration 132000, loss = 0.91849
I0522 00:37:22.176967 13093 solver.cpp:253]     Train net output #0: loss = 0.918491 (* 1 = 0.918491 loss)
I0522 00:37:22.176981 13093 sgd_solver.cpp:106] Iteration 132000, lr = 0.002
I0522 00:37:34.305769 13093 solver.cpp:237] Iteration 132750, loss = 1.23506
I0522 00:37:34.305937 13093 solver.cpp:253]     Train net output #0: loss = 1.23506 (* 1 = 1.23506 loss)
I0522 00:37:34.305950 13093 sgd_solver.cpp:106] Iteration 132750, lr = 0.002
I0522 00:37:46.492280 13093 solver.cpp:237] Iteration 133500, loss = 1.46548
I0522 00:37:46.492316 13093 solver.cpp:253]     Train net output #0: loss = 1.46548 (* 1 = 1.46548 loss)
I0522 00:37:46.492331 13093 sgd_solver.cpp:106] Iteration 133500, lr = 0.002
I0522 00:37:58.664783 13093 solver.cpp:237] Iteration 134250, loss = 1.00636
I0522 00:37:58.664822 13093 solver.cpp:253]     Train net output #0: loss = 1.00636 (* 1 = 1.00636 loss)
I0522 00:37:58.664837 13093 sgd_solver.cpp:106] Iteration 134250, lr = 0.002
I0522 00:38:10.822492 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_135000.caffemodel
I0522 00:38:10.871749 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_135000.solverstate
I0522 00:38:10.896901 13093 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 00:39:02.831027 13093 solver.cpp:409]     Test net output #0: accuracy = 0.890192
I0522 00:39:02.831207 13093 solver.cpp:409]     Test net output #1: loss = 0.349915 (* 1 = 0.349915 loss)
I0522 00:39:23.670436 13093 solver.cpp:237] Iteration 135000, loss = 1.09467
I0522 00:39:23.670488 13093 solver.cpp:253]     Train net output #0: loss = 1.09467 (* 1 = 1.09467 loss)
I0522 00:39:23.670505 13093 sgd_solver.cpp:106] Iteration 135000, lr = 0.002
I0522 00:39:35.852226 13093 solver.cpp:237] Iteration 135750, loss = 0.80159
I0522 00:39:35.852396 13093 solver.cpp:253]     Train net output #0: loss = 0.80159 (* 1 = 0.80159 loss)
I0522 00:39:35.852411 13093 sgd_solver.cpp:106] Iteration 135750, lr = 0.002
I0522 00:39:48.022758 13093 solver.cpp:237] Iteration 136500, loss = 0.940188
I0522 00:39:48.022795 13093 solver.cpp:253]     Train net output #0: loss = 0.940188 (* 1 = 0.940188 loss)
I0522 00:39:48.022809 13093 sgd_solver.cpp:106] Iteration 136500, lr = 0.002
I0522 00:40:00.196424 13093 solver.cpp:237] Iteration 137250, loss = 1.20605
I0522 00:40:00.196460 13093 solver.cpp:253]     Train net output #0: loss = 1.20605 (* 1 = 1.20605 loss)
I0522 00:40:00.196473 13093 sgd_solver.cpp:106] Iteration 137250, lr = 0.002
I0522 00:40:12.426033 13093 solver.cpp:237] Iteration 138000, loss = 1.07588
I0522 00:40:12.426201 13093 solver.cpp:253]     Train net output #0: loss = 1.07588 (* 1 = 1.07588 loss)
I0522 00:40:12.426215 13093 sgd_solver.cpp:106] Iteration 138000, lr = 0.002
I0522 00:40:24.628911 13093 solver.cpp:237] Iteration 138750, loss = 0.980478
I0522 00:40:24.628948 13093 solver.cpp:253]     Train net output #0: loss = 0.980478 (* 1 = 0.980478 loss)
I0522 00:40:24.628962 13093 sgd_solver.cpp:106] Iteration 138750, lr = 0.002
I0522 00:40:36.825659 13093 solver.cpp:237] Iteration 139500, loss = 0.857246
I0522 00:40:36.825701 13093 solver.cpp:253]     Train net output #0: loss = 0.857246 (* 1 = 0.857246 loss)
I0522 00:40:36.825716 13093 sgd_solver.cpp:106] Iteration 139500, lr = 0.002
I0522 00:41:09.828270 13093 solver.cpp:237] Iteration 140250, loss = 1.09813
I0522 00:41:09.828446 13093 solver.cpp:253]     Train net output #0: loss = 1.09813 (* 1 = 1.09813 loss)
I0522 00:41:09.828460 13093 sgd_solver.cpp:106] Iteration 140250, lr = 0.002
I0522 00:41:22.029402 13093 solver.cpp:237] Iteration 141000, loss = 0.967433
I0522 00:41:22.029450 13093 solver.cpp:253]     Train net output #0: loss = 0.967432 (* 1 = 0.967432 loss)
I0522 00:41:22.029465 13093 sgd_solver.cpp:106] Iteration 141000, lr = 0.002
I0522 00:41:34.271556 13093 solver.cpp:237] Iteration 141750, loss = 0.924771
I0522 00:41:34.271594 13093 solver.cpp:253]     Train net output #0: loss = 0.924771 (* 1 = 0.924771 loss)
I0522 00:41:34.271608 13093 sgd_solver.cpp:106] Iteration 141750, lr = 0.002
I0522 00:41:46.427777 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_142500.caffemodel
I0522 00:41:46.479027 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_142500.solverstate
I0522 00:41:46.511675 13093 solver.cpp:237] Iteration 142500, loss = 1.24961
I0522 00:41:46.511724 13093 solver.cpp:253]     Train net output #0: loss = 1.24961 (* 1 = 1.24961 loss)
I0522 00:41:46.511741 13093 sgd_solver.cpp:106] Iteration 142500, lr = 0.002
I0522 00:41:58.654036 13093 solver.cpp:237] Iteration 143250, loss = 1.16208
I0522 00:41:58.654072 13093 solver.cpp:253]     Train net output #0: loss = 1.16208 (* 1 = 1.16208 loss)
I0522 00:41:58.654086 13093 sgd_solver.cpp:106] Iteration 143250, lr = 0.002
I0522 00:42:10.795948 13093 solver.cpp:237] Iteration 144000, loss = 1.56725
I0522 00:42:10.795999 13093 solver.cpp:253]     Train net output #0: loss = 1.56725 (* 1 = 1.56725 loss)
I0522 00:42:10.796012 13093 sgd_solver.cpp:106] Iteration 144000, lr = 0.002
I0522 00:42:22.982412 13093 solver.cpp:237] Iteration 144750, loss = 1.15861
I0522 00:42:22.982573 13093 solver.cpp:253]     Train net output #0: loss = 1.15861 (* 1 = 1.15861 loss)
I0522 00:42:22.982586 13093 sgd_solver.cpp:106] Iteration 144750, lr = 0.002
I0522 00:42:56.026598 13093 solver.cpp:237] Iteration 145500, loss = 1.21511
I0522 00:42:56.026779 13093 solver.cpp:253]     Train net output #0: loss = 1.21511 (* 1 = 1.21511 loss)
I0522 00:42:56.026793 13093 sgd_solver.cpp:106] Iteration 145500, lr = 0.002
I0522 00:43:08.263319 13093 solver.cpp:237] Iteration 146250, loss = 1.24567
I0522 00:43:08.263356 13093 solver.cpp:253]     Train net output #0: loss = 1.24567 (* 1 = 1.24567 loss)
I0522 00:43:08.263370 13093 sgd_solver.cpp:106] Iteration 146250, lr = 0.002
I0522 00:43:20.494926 13093 solver.cpp:237] Iteration 147000, loss = 1.17063
I0522 00:43:20.494976 13093 solver.cpp:253]     Train net output #0: loss = 1.17063 (* 1 = 1.17063 loss)
I0522 00:43:20.494989 13093 sgd_solver.cpp:106] Iteration 147000, lr = 0.002
I0522 00:43:32.665730 13093 solver.cpp:237] Iteration 147750, loss = 1.04425
I0522 00:43:32.665896 13093 solver.cpp:253]     Train net output #0: loss = 1.04425 (* 1 = 1.04425 loss)
I0522 00:43:32.665910 13093 sgd_solver.cpp:106] Iteration 147750, lr = 0.002
I0522 00:43:44.831794 13093 solver.cpp:237] Iteration 148500, loss = 1.43668
I0522 00:43:44.831830 13093 solver.cpp:253]     Train net output #0: loss = 1.43668 (* 1 = 1.43668 loss)
I0522 00:43:44.831845 13093 sgd_solver.cpp:106] Iteration 148500, lr = 0.002
I0522 00:43:57.017334 13093 solver.cpp:237] Iteration 149250, loss = 1.26273
I0522 00:43:57.017379 13093 solver.cpp:253]     Train net output #0: loss = 1.26273 (* 1 = 1.26273 loss)
I0522 00:43:57.017392 13093 sgd_solver.cpp:106] Iteration 149250, lr = 0.002
I0522 00:44:09.137898 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_150000.caffemodel
I0522 00:44:09.190606 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_150000.solverstate
I0522 00:44:09.217998 13093 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 00:45:22.103395 13093 solver.cpp:409]     Test net output #0: accuracy = 0.890764
I0522 00:45:22.103570 13093 solver.cpp:409]     Test net output #1: loss = 0.341849 (* 1 = 0.341849 loss)
I0522 00:45:42.937662 13093 solver.cpp:237] Iteration 150000, loss = 1.11344
I0522 00:45:42.937714 13093 solver.cpp:253]     Train net output #0: loss = 1.11344 (* 1 = 1.11344 loss)
I0522 00:45:42.937729 13093 sgd_solver.cpp:106] Iteration 150000, lr = 0.002
I0522 00:45:55.099104 13093 solver.cpp:237] Iteration 150750, loss = 1.36028
I0522 00:45:55.099287 13093 solver.cpp:253]     Train net output #0: loss = 1.36028 (* 1 = 1.36028 loss)
I0522 00:45:55.099301 13093 sgd_solver.cpp:106] Iteration 150750, lr = 0.002
I0522 00:46:07.232368 13093 solver.cpp:237] Iteration 151500, loss = 1.21996
I0522 00:46:07.232404 13093 solver.cpp:253]     Train net output #0: loss = 1.21996 (* 1 = 1.21996 loss)
I0522 00:46:07.232419 13093 sgd_solver.cpp:106] Iteration 151500, lr = 0.002
I0522 00:46:19.371572 13093 solver.cpp:237] Iteration 152250, loss = 1.20476
I0522 00:46:19.371615 13093 solver.cpp:253]     Train net output #0: loss = 1.20476 (* 1 = 1.20476 loss)
I0522 00:46:19.371630 13093 sgd_solver.cpp:106] Iteration 152250, lr = 0.002
I0522 00:46:31.495404 13093 solver.cpp:237] Iteration 153000, loss = 0.752152
I0522 00:46:31.495568 13093 solver.cpp:253]     Train net output #0: loss = 0.752152 (* 1 = 0.752152 loss)
I0522 00:46:31.495582 13093 sgd_solver.cpp:106] Iteration 153000, lr = 0.002
I0522 00:46:43.628717 13093 solver.cpp:237] Iteration 153750, loss = 1.01215
I0522 00:46:43.628759 13093 solver.cpp:253]     Train net output #0: loss = 1.01215 (* 1 = 1.01215 loss)
I0522 00:46:43.628773 13093 sgd_solver.cpp:106] Iteration 153750, lr = 0.002
I0522 00:46:55.752341 13093 solver.cpp:237] Iteration 154500, loss = 1.29731
I0522 00:46:55.752377 13093 solver.cpp:253]     Train net output #0: loss = 1.29731 (* 1 = 1.29731 loss)
I0522 00:46:55.752390 13093 sgd_solver.cpp:106] Iteration 154500, lr = 0.002
I0522 00:47:28.671121 13093 solver.cpp:237] Iteration 155250, loss = 1.18375
I0522 00:47:28.671300 13093 solver.cpp:253]     Train net output #0: loss = 1.18375 (* 1 = 1.18375 loss)
I0522 00:47:28.671314 13093 sgd_solver.cpp:106] Iteration 155250, lr = 0.002
I0522 00:47:40.786877 13093 solver.cpp:237] Iteration 156000, loss = 1.05576
I0522 00:47:40.786921 13093 solver.cpp:253]     Train net output #0: loss = 1.05576 (* 1 = 1.05576 loss)
I0522 00:47:40.786934 13093 sgd_solver.cpp:106] Iteration 156000, lr = 0.002
I0522 00:47:52.930510 13093 solver.cpp:237] Iteration 156750, loss = 2.46698
I0522 00:47:52.930546 13093 solver.cpp:253]     Train net output #0: loss = 2.46698 (* 1 = 2.46698 loss)
I0522 00:47:52.930560 13093 sgd_solver.cpp:106] Iteration 156750, lr = 0.002
I0522 00:48:05.059058 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_157500.caffemodel
I0522 00:48:05.108073 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_157500.solverstate
I0522 00:48:05.138218 13093 solver.cpp:237] Iteration 157500, loss = 1.16686
I0522 00:48:05.138264 13093 solver.cpp:253]     Train net output #0: loss = 1.16687 (* 1 = 1.16687 loss)
I0522 00:48:05.138280 13093 sgd_solver.cpp:106] Iteration 157500, lr = 0.002
I0522 00:48:17.303124 13093 solver.cpp:237] Iteration 158250, loss = 1.39279
I0522 00:48:17.303161 13093 solver.cpp:253]     Train net output #0: loss = 1.39279 (* 1 = 1.39279 loss)
I0522 00:48:17.303175 13093 sgd_solver.cpp:106] Iteration 158250, lr = 0.002
I0522 00:48:29.489565 13093 solver.cpp:237] Iteration 159000, loss = 0.933655
I0522 00:48:29.489612 13093 solver.cpp:253]     Train net output #0: loss = 0.933656 (* 1 = 0.933656 loss)
I0522 00:48:29.489626 13093 sgd_solver.cpp:106] Iteration 159000, lr = 0.002
I0522 00:48:41.630030 13093 solver.cpp:237] Iteration 159750, loss = 1.27501
I0522 00:48:41.630185 13093 solver.cpp:253]     Train net output #0: loss = 1.27501 (* 1 = 1.27501 loss)
I0522 00:48:41.630199 13093 sgd_solver.cpp:106] Iteration 159750, lr = 0.002
I0522 00:49:14.660099 13093 solver.cpp:237] Iteration 160500, loss = 0.876667
I0522 00:49:14.660279 13093 solver.cpp:253]     Train net output #0: loss = 0.876667 (* 1 = 0.876667 loss)
I0522 00:49:14.660295 13093 sgd_solver.cpp:106] Iteration 160500, lr = 0.002
I0522 00:49:26.854537 13093 solver.cpp:237] Iteration 161250, loss = 0.666854
I0522 00:49:26.854574 13093 solver.cpp:253]     Train net output #0: loss = 0.666855 (* 1 = 0.666855 loss)
I0522 00:49:26.854589 13093 sgd_solver.cpp:106] Iteration 161250, lr = 0.002
I0522 00:49:39.048282 13093 solver.cpp:237] Iteration 162000, loss = 1.28852
I0522 00:49:39.048331 13093 solver.cpp:253]     Train net output #0: loss = 1.28852 (* 1 = 1.28852 loss)
I0522 00:49:39.048346 13093 sgd_solver.cpp:106] Iteration 162000, lr = 0.002
I0522 00:49:51.247364 13093 solver.cpp:237] Iteration 162750, loss = 1.20011
I0522 00:49:51.247520 13093 solver.cpp:253]     Train net output #0: loss = 1.20011 (* 1 = 1.20011 loss)
I0522 00:49:51.247534 13093 sgd_solver.cpp:106] Iteration 162750, lr = 0.002
I0522 00:50:03.404507 13093 solver.cpp:237] Iteration 163500, loss = 1.31371
I0522 00:50:03.404558 13093 solver.cpp:253]     Train net output #0: loss = 1.31371 (* 1 = 1.31371 loss)
I0522 00:50:03.404572 13093 sgd_solver.cpp:106] Iteration 163500, lr = 0.002
I0522 00:50:15.537335 13093 solver.cpp:237] Iteration 164250, loss = 1.36549
I0522 00:50:15.537371 13093 solver.cpp:253]     Train net output #0: loss = 1.36549 (* 1 = 1.36549 loss)
I0522 00:50:15.537386 13093 sgd_solver.cpp:106] Iteration 164250, lr = 0.002
I0522 00:50:27.619889 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_165000.caffemodel
I0522 00:50:27.669036 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_165000.solverstate
I0522 00:50:27.693960 13093 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 00:51:19.231086 13093 solver.cpp:409]     Test net output #0: accuracy = 0.895389
I0522 00:51:19.231263 13093 solver.cpp:409]     Test net output #1: loss = 0.342109 (* 1 = 0.342109 loss)
I0522 00:51:40.064751 13093 solver.cpp:237] Iteration 165000, loss = 1.04986
I0522 00:51:40.064805 13093 solver.cpp:253]     Train net output #0: loss = 1.04986 (* 1 = 1.04986 loss)
I0522 00:51:40.064820 13093 sgd_solver.cpp:106] Iteration 165000, lr = 0.002
I0522 00:51:52.216249 13093 solver.cpp:237] Iteration 165750, loss = 1.19586
I0522 00:51:52.216434 13093 solver.cpp:253]     Train net output #0: loss = 1.19586 (* 1 = 1.19586 loss)
I0522 00:51:52.216447 13093 sgd_solver.cpp:106] Iteration 165750, lr = 0.002
I0522 00:52:04.391798 13093 solver.cpp:237] Iteration 166500, loss = 0.933929
I0522 00:52:04.391834 13093 solver.cpp:253]     Train net output #0: loss = 0.933929 (* 1 = 0.933929 loss)
I0522 00:52:04.391849 13093 sgd_solver.cpp:106] Iteration 166500, lr = 0.002
I0522 00:52:16.533967 13093 solver.cpp:237] Iteration 167250, loss = 1.25258
I0522 00:52:16.534015 13093 solver.cpp:253]     Train net output #0: loss = 1.25258 (* 1 = 1.25258 loss)
I0522 00:52:16.534029 13093 sgd_solver.cpp:106] Iteration 167250, lr = 0.002
I0522 00:52:28.722878 13093 solver.cpp:237] Iteration 168000, loss = 0.803724
I0522 00:52:28.723040 13093 solver.cpp:253]     Train net output #0: loss = 0.803723 (* 1 = 0.803723 loss)
I0522 00:52:28.723054 13093 sgd_solver.cpp:106] Iteration 168000, lr = 0.002
I0522 00:52:40.918160 13093 solver.cpp:237] Iteration 168750, loss = 1.88494
I0522 00:52:40.918210 13093 solver.cpp:253]     Train net output #0: loss = 1.88494 (* 1 = 1.88494 loss)
I0522 00:52:40.918223 13093 sgd_solver.cpp:106] Iteration 168750, lr = 0.002
I0522 00:52:53.129896 13093 solver.cpp:237] Iteration 169500, loss = 1.23019
I0522 00:52:53.129932 13093 solver.cpp:253]     Train net output #0: loss = 1.23019 (* 1 = 1.23019 loss)
I0522 00:52:53.129947 13093 sgd_solver.cpp:106] Iteration 169500, lr = 0.002
I0522 00:53:26.137892 13093 solver.cpp:237] Iteration 170250, loss = 1.10268
I0522 00:53:26.138082 13093 solver.cpp:253]     Train net output #0: loss = 1.10268 (* 1 = 1.10268 loss)
I0522 00:53:26.138097 13093 sgd_solver.cpp:106] Iteration 170250, lr = 0.002
I0522 00:53:38.252676 13093 solver.cpp:237] Iteration 171000, loss = 0.860898
I0522 00:53:38.252712 13093 solver.cpp:253]     Train net output #0: loss = 0.860898 (* 1 = 0.860898 loss)
I0522 00:53:38.252727 13093 sgd_solver.cpp:106] Iteration 171000, lr = 0.002
I0522 00:53:50.444814 13093 solver.cpp:237] Iteration 171750, loss = 1.27438
I0522 00:53:50.444861 13093 solver.cpp:253]     Train net output #0: loss = 1.27438 (* 1 = 1.27438 loss)
I0522 00:53:50.444875 13093 sgd_solver.cpp:106] Iteration 171750, lr = 0.002
I0522 00:54:02.611295 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_172500.caffemodel
I0522 00:54:02.660987 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_172500.solverstate
I0522 00:54:02.691037 13093 solver.cpp:237] Iteration 172500, loss = 1.01521
I0522 00:54:02.691084 13093 solver.cpp:253]     Train net output #0: loss = 1.01521 (* 1 = 1.01521 loss)
I0522 00:54:02.691099 13093 sgd_solver.cpp:106] Iteration 172500, lr = 0.002
I0522 00:54:14.894788 13093 solver.cpp:237] Iteration 173250, loss = 1.059
I0522 00:54:14.894836 13093 solver.cpp:253]     Train net output #0: loss = 1.059 (* 1 = 1.059 loss)
I0522 00:54:14.894851 13093 sgd_solver.cpp:106] Iteration 173250, lr = 0.002
I0522 00:54:27.108978 13093 solver.cpp:237] Iteration 174000, loss = 0.93126
I0522 00:54:27.109015 13093 solver.cpp:253]     Train net output #0: loss = 0.93126 (* 1 = 0.93126 loss)
I0522 00:54:27.109030 13093 sgd_solver.cpp:106] Iteration 174000, lr = 0.002
I0522 00:54:39.335935 13093 solver.cpp:237] Iteration 174750, loss = 1.00095
I0522 00:54:39.336113 13093 solver.cpp:253]     Train net output #0: loss = 1.00095 (* 1 = 1.00095 loss)
I0522 00:54:39.336128 13093 sgd_solver.cpp:106] Iteration 174750, lr = 0.002
I0522 00:55:12.388383 13093 solver.cpp:237] Iteration 175500, loss = 0.752717
I0522 00:55:12.388563 13093 solver.cpp:253]     Train net output #0: loss = 0.752717 (* 1 = 0.752717 loss)
I0522 00:55:12.388581 13093 sgd_solver.cpp:106] Iteration 175500, lr = 0.002
I0522 00:55:24.602074 13093 solver.cpp:237] Iteration 176250, loss = 1.83668
I0522 00:55:24.602110 13093 solver.cpp:253]     Train net output #0: loss = 1.83668 (* 1 = 1.83668 loss)
I0522 00:55:24.602124 13093 sgd_solver.cpp:106] Iteration 176250, lr = 0.002
I0522 00:55:36.816890 13093 solver.cpp:237] Iteration 177000, loss = 1.12306
I0522 00:55:36.816934 13093 solver.cpp:253]     Train net output #0: loss = 1.12305 (* 1 = 1.12305 loss)
I0522 00:55:36.816948 13093 sgd_solver.cpp:106] Iteration 177000, lr = 0.002
I0522 00:55:49.032280 13093 solver.cpp:237] Iteration 177750, loss = 0.720553
I0522 00:55:49.032449 13093 solver.cpp:253]     Train net output #0: loss = 0.720553 (* 1 = 0.720553 loss)
I0522 00:55:49.032461 13093 sgd_solver.cpp:106] Iteration 177750, lr = 0.002
I0522 00:56:01.264721 13093 solver.cpp:237] Iteration 178500, loss = 1.38924
I0522 00:56:01.264770 13093 solver.cpp:253]     Train net output #0: loss = 1.38924 (* 1 = 1.38924 loss)
I0522 00:56:01.264783 13093 sgd_solver.cpp:106] Iteration 178500, lr = 0.002
I0522 00:56:13.419695 13093 solver.cpp:237] Iteration 179250, loss = 0.959764
I0522 00:56:13.419731 13093 solver.cpp:253]     Train net output #0: loss = 0.959764 (* 1 = 0.959764 loss)
I0522 00:56:13.419746 13093 sgd_solver.cpp:106] Iteration 179250, lr = 0.002
I0522 00:56:25.547425 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_180000.caffemodel
I0522 00:56:25.597473 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_180000.solverstate
I0522 00:56:25.623105 13093 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 00:57:38.560395 13093 solver.cpp:409]     Test net output #0: accuracy = 0.895324
I0522 00:57:38.560570 13093 solver.cpp:409]     Test net output #1: loss = 0.355174 (* 1 = 0.355174 loss)
I0522 00:57:59.416441 13093 solver.cpp:237] Iteration 180000, loss = 0.995231
I0522 00:57:59.416496 13093 solver.cpp:253]     Train net output #0: loss = 0.995231 (* 1 = 0.995231 loss)
I0522 00:57:59.416512 13093 sgd_solver.cpp:106] Iteration 180000, lr = 0.002
I0522 00:58:11.569033 13093 solver.cpp:237] Iteration 180750, loss = 0.530572
I0522 00:58:11.569200 13093 solver.cpp:253]     Train net output #0: loss = 0.530572 (* 1 = 0.530572 loss)
I0522 00:58:11.569214 13093 sgd_solver.cpp:106] Iteration 180750, lr = 0.002
I0522 00:58:23.719022 13093 solver.cpp:237] Iteration 181500, loss = 0.782675
I0522 00:58:23.719071 13093 solver.cpp:253]     Train net output #0: loss = 0.782675 (* 1 = 0.782675 loss)
I0522 00:58:23.719086 13093 sgd_solver.cpp:106] Iteration 181500, lr = 0.002
I0522 00:58:35.838388 13093 solver.cpp:237] Iteration 182250, loss = 1.29512
I0522 00:58:35.838425 13093 solver.cpp:253]     Train net output #0: loss = 1.29512 (* 1 = 1.29512 loss)
I0522 00:58:35.838439 13093 sgd_solver.cpp:106] Iteration 182250, lr = 0.002
I0522 00:58:48.005998 13093 solver.cpp:237] Iteration 183000, loss = 1.13392
I0522 00:58:48.006168 13093 solver.cpp:253]     Train net output #0: loss = 1.13392 (* 1 = 1.13392 loss)
I0522 00:58:48.006183 13093 sgd_solver.cpp:106] Iteration 183000, lr = 0.002
I0522 00:59:00.128588 13093 solver.cpp:237] Iteration 183750, loss = 1.22775
I0522 00:59:00.128625 13093 solver.cpp:253]     Train net output #0: loss = 1.22775 (* 1 = 1.22775 loss)
I0522 00:59:00.128639 13093 sgd_solver.cpp:106] Iteration 183750, lr = 0.002
I0522 00:59:12.252087 13093 solver.cpp:237] Iteration 184500, loss = 1.17271
I0522 00:59:12.252136 13093 solver.cpp:253]     Train net output #0: loss = 1.17271 (* 1 = 1.17271 loss)
I0522 00:59:12.252151 13093 sgd_solver.cpp:106] Iteration 184500, lr = 0.002
I0522 00:59:45.268684 13093 solver.cpp:237] Iteration 185250, loss = 1.18056
I0522 00:59:45.268863 13093 solver.cpp:253]     Train net output #0: loss = 1.18056 (* 1 = 1.18056 loss)
I0522 00:59:45.268877 13093 sgd_solver.cpp:106] Iteration 185250, lr = 0.002
I0522 00:59:57.363251 13093 solver.cpp:237] Iteration 186000, loss = 1.38742
I0522 00:59:57.363287 13093 solver.cpp:253]     Train net output #0: loss = 1.38742 (* 1 = 1.38742 loss)
I0522 00:59:57.363301 13093 sgd_solver.cpp:106] Iteration 186000, lr = 0.002
I0522 01:00:09.489250 13093 solver.cpp:237] Iteration 186750, loss = 0.693239
I0522 01:00:09.489297 13093 solver.cpp:253]     Train net output #0: loss = 0.69324 (* 1 = 0.69324 loss)
I0522 01:00:09.489312 13093 sgd_solver.cpp:106] Iteration 186750, lr = 0.002
I0522 01:00:21.580770 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_187500.caffemodel
I0522 01:00:21.632123 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_187500.solverstate
I0522 01:00:21.664888 13093 solver.cpp:237] Iteration 187500, loss = 1.41724
I0522 01:00:21.664934 13093 solver.cpp:253]     Train net output #0: loss = 1.41724 (* 1 = 1.41724 loss)
I0522 01:00:21.664948 13093 sgd_solver.cpp:106] Iteration 187500, lr = 0.002
I0522 01:00:33.777930 13093 solver.cpp:237] Iteration 188250, loss = 1.38977
I0522 01:00:33.777981 13093 solver.cpp:253]     Train net output #0: loss = 1.38977 (* 1 = 1.38977 loss)
I0522 01:00:33.777995 13093 sgd_solver.cpp:106] Iteration 188250, lr = 0.002
I0522 01:00:45.886873 13093 solver.cpp:237] Iteration 189000, loss = 1.3698
I0522 01:00:45.886909 13093 solver.cpp:253]     Train net output #0: loss = 1.3698 (* 1 = 1.3698 loss)
I0522 01:00:45.886924 13093 sgd_solver.cpp:106] Iteration 189000, lr = 0.002
I0522 01:00:58.022603 13093 solver.cpp:237] Iteration 189750, loss = 0.973594
I0522 01:00:58.022783 13093 solver.cpp:253]     Train net output #0: loss = 0.973594 (* 1 = 0.973594 loss)
I0522 01:00:58.022797 13093 sgd_solver.cpp:106] Iteration 189750, lr = 0.002
I0522 01:01:31.030726 13093 solver.cpp:237] Iteration 190500, loss = 1.21566
I0522 01:01:31.030907 13093 solver.cpp:253]     Train net output #0: loss = 1.21566 (* 1 = 1.21566 loss)
I0522 01:01:31.030922 13093 sgd_solver.cpp:106] Iteration 190500, lr = 0.002
I0522 01:01:43.187037 13093 solver.cpp:237] Iteration 191250, loss = 1.05936
I0522 01:01:43.187086 13093 solver.cpp:253]     Train net output #0: loss = 1.05936 (* 1 = 1.05936 loss)
I0522 01:01:43.187100 13093 sgd_solver.cpp:106] Iteration 191250, lr = 0.002
I0522 01:01:55.356305 13093 solver.cpp:237] Iteration 192000, loss = 1.30233
I0522 01:01:55.356341 13093 solver.cpp:253]     Train net output #0: loss = 1.30233 (* 1 = 1.30233 loss)
I0522 01:01:55.356356 13093 sgd_solver.cpp:106] Iteration 192000, lr = 0.002
I0522 01:02:07.514652 13093 solver.cpp:237] Iteration 192750, loss = 1.15837
I0522 01:02:07.514827 13093 solver.cpp:253]     Train net output #0: loss = 1.15837 (* 1 = 1.15837 loss)
I0522 01:02:07.514842 13093 sgd_solver.cpp:106] Iteration 192750, lr = 0.002
I0522 01:02:19.683818 13093 solver.cpp:237] Iteration 193500, loss = 0.980468
I0522 01:02:19.683856 13093 solver.cpp:253]     Train net output #0: loss = 0.980468 (* 1 = 0.980468 loss)
I0522 01:02:19.683869 13093 sgd_solver.cpp:106] Iteration 193500, lr = 0.002
I0522 01:02:31.825808 13093 solver.cpp:237] Iteration 194250, loss = 1.43917
I0522 01:02:31.825856 13093 solver.cpp:253]     Train net output #0: loss = 1.43917 (* 1 = 1.43917 loss)
I0522 01:02:31.825870 13093 sgd_solver.cpp:106] Iteration 194250, lr = 0.002
I0522 01:02:43.973425 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_195000.caffemodel
I0522 01:02:44.022903 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_195000.solverstate
I0522 01:02:44.048409 13093 solver.cpp:341] Iteration 195000, Testing net (#0)
I0522 01:03:35.981480 13093 solver.cpp:409]     Test net output #0: accuracy = 0.895598
I0522 01:03:35.981670 13093 solver.cpp:409]     Test net output #1: loss = 0.329115 (* 1 = 0.329115 loss)
I0522 01:03:56.818981 13093 solver.cpp:237] Iteration 195000, loss = 1.07984
I0522 01:03:56.819033 13093 solver.cpp:253]     Train net output #0: loss = 1.07984 (* 1 = 1.07984 loss)
I0522 01:03:56.819049 13093 sgd_solver.cpp:106] Iteration 195000, lr = 0.002
I0522 01:04:08.992804 13093 solver.cpp:237] Iteration 195750, loss = 0.840581
I0522 01:04:08.992972 13093 solver.cpp:253]     Train net output #0: loss = 0.840581 (* 1 = 0.840581 loss)
I0522 01:04:08.992986 13093 sgd_solver.cpp:106] Iteration 195750, lr = 0.002
I0522 01:04:21.122758 13093 solver.cpp:237] Iteration 196500, loss = 1.35211
I0522 01:04:21.122799 13093 solver.cpp:253]     Train net output #0: loss = 1.35211 (* 1 = 1.35211 loss)
I0522 01:04:21.122814 13093 sgd_solver.cpp:106] Iteration 196500, lr = 0.002
I0522 01:04:33.251864 13093 solver.cpp:237] Iteration 197250, loss = 1.23
I0522 01:04:33.251900 13093 solver.cpp:253]     Train net output #0: loss = 1.23 (* 1 = 1.23 loss)
I0522 01:04:33.251914 13093 sgd_solver.cpp:106] Iteration 197250, lr = 0.002
I0522 01:04:45.378578 13093 solver.cpp:237] Iteration 198000, loss = 0.828635
I0522 01:04:45.378751 13093 solver.cpp:253]     Train net output #0: loss = 0.828635 (* 1 = 0.828635 loss)
I0522 01:04:45.378765 13093 sgd_solver.cpp:106] Iteration 198000, lr = 0.002
I0522 01:04:57.510432 13093 solver.cpp:237] Iteration 198750, loss = 0.978558
I0522 01:04:57.510469 13093 solver.cpp:253]     Train net output #0: loss = 0.978558 (* 1 = 0.978558 loss)
I0522 01:04:57.510484 13093 sgd_solver.cpp:106] Iteration 198750, lr = 0.002
I0522 01:05:09.643352 13093 solver.cpp:237] Iteration 199500, loss = 0.752236
I0522 01:05:09.643399 13093 solver.cpp:253]     Train net output #0: loss = 0.752236 (* 1 = 0.752236 loss)
I0522 01:05:09.643427 13093 sgd_solver.cpp:106] Iteration 199500, lr = 0.002
I0522 01:05:42.631037 13093 solver.cpp:237] Iteration 200250, loss = 1.14206
I0522 01:05:42.631225 13093 solver.cpp:253]     Train net output #0: loss = 1.14206 (* 1 = 1.14206 loss)
I0522 01:05:42.631239 13093 sgd_solver.cpp:106] Iteration 200250, lr = 0.002
I0522 01:05:54.743306 13093 solver.cpp:237] Iteration 201000, loss = 0.963834
I0522 01:05:54.743355 13093 solver.cpp:253]     Train net output #0: loss = 0.963833 (* 1 = 0.963833 loss)
I0522 01:05:54.743368 13093 sgd_solver.cpp:106] Iteration 201000, lr = 0.002
I0522 01:06:06.844817 13093 solver.cpp:237] Iteration 201750, loss = 1.48926
I0522 01:06:06.844852 13093 solver.cpp:253]     Train net output #0: loss = 1.48926 (* 1 = 1.48926 loss)
I0522 01:06:06.844868 13093 sgd_solver.cpp:106] Iteration 201750, lr = 0.002
I0522 01:06:18.956104 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_202500.caffemodel
I0522 01:06:19.005846 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_202500.solverstate
I0522 01:06:19.035722 13093 solver.cpp:237] Iteration 202500, loss = 1.05387
I0522 01:06:19.035763 13093 solver.cpp:253]     Train net output #0: loss = 1.05387 (* 1 = 1.05387 loss)
I0522 01:06:19.035776 13093 sgd_solver.cpp:106] Iteration 202500, lr = 0.002
I0522 01:06:31.164067 13093 solver.cpp:237] Iteration 203250, loss = 1.2501
I0522 01:06:31.164103 13093 solver.cpp:253]     Train net output #0: loss = 1.2501 (* 1 = 1.2501 loss)
I0522 01:06:31.164118 13093 sgd_solver.cpp:106] Iteration 203250, lr = 0.002
I0522 01:06:43.330124 13093 solver.cpp:237] Iteration 204000, loss = 1.13435
I0522 01:06:43.330174 13093 solver.cpp:253]     Train net output #0: loss = 1.13435 (* 1 = 1.13435 loss)
I0522 01:06:43.330189 13093 sgd_solver.cpp:106] Iteration 204000, lr = 0.002
I0522 01:06:55.470271 13093 solver.cpp:237] Iteration 204750, loss = 0.794366
I0522 01:06:55.470450 13093 solver.cpp:253]     Train net output #0: loss = 0.794365 (* 1 = 0.794365 loss)
I0522 01:06:55.470464 13093 sgd_solver.cpp:106] Iteration 204750, lr = 0.002
I0522 01:07:28.502959 13093 solver.cpp:237] Iteration 205500, loss = 1.46565
I0522 01:07:28.503144 13093 solver.cpp:253]     Train net output #0: loss = 1.46565 (* 1 = 1.46565 loss)
I0522 01:07:28.503157 13093 sgd_solver.cpp:106] Iteration 205500, lr = 0.002
I0522 01:07:40.647590 13093 solver.cpp:237] Iteration 206250, loss = 1.75203
I0522 01:07:40.647641 13093 solver.cpp:253]     Train net output #0: loss = 1.75203 (* 1 = 1.75203 loss)
I0522 01:07:40.647655 13093 sgd_solver.cpp:106] Iteration 206250, lr = 0.002
I0522 01:07:52.805990 13093 solver.cpp:237] Iteration 207000, loss = 1.55768
I0522 01:07:52.806026 13093 solver.cpp:253]     Train net output #0: loss = 1.55768 (* 1 = 1.55768 loss)
I0522 01:07:52.806041 13093 sgd_solver.cpp:106] Iteration 207000, lr = 0.002
I0522 01:08:04.987962 13093 solver.cpp:237] Iteration 207750, loss = 0.861055
I0522 01:08:04.988147 13093 solver.cpp:253]     Train net output #0: loss = 0.861054 (* 1 = 0.861054 loss)
I0522 01:08:04.988160 13093 sgd_solver.cpp:106] Iteration 207750, lr = 0.002
I0522 01:08:17.183480 13093 solver.cpp:237] Iteration 208500, loss = 0.950813
I0522 01:08:17.183517 13093 solver.cpp:253]     Train net output #0: loss = 0.950813 (* 1 = 0.950813 loss)
I0522 01:08:17.183531 13093 sgd_solver.cpp:106] Iteration 208500, lr = 0.002
I0522 01:08:29.383590 13093 solver.cpp:237] Iteration 209250, loss = 1.18589
I0522 01:08:29.383635 13093 solver.cpp:253]     Train net output #0: loss = 1.18589 (* 1 = 1.18589 loss)
I0522 01:08:29.383649 13093 sgd_solver.cpp:106] Iteration 209250, lr = 0.002
I0522 01:08:41.540118 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_210000.caffemodel
I0522 01:08:41.589561 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_210000.solverstate
I0522 01:08:41.614941 13093 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 01:09:54.474345 13093 solver.cpp:409]     Test net output #0: accuracy = 0.898398
I0522 01:09:54.474526 13093 solver.cpp:409]     Test net output #1: loss = 0.32803 (* 1 = 0.32803 loss)
I0522 01:10:15.333516 13093 solver.cpp:237] Iteration 210000, loss = 1.02516
I0522 01:10:15.333668 13093 solver.cpp:253]     Train net output #0: loss = 1.02516 (* 1 = 1.02516 loss)
I0522 01:10:15.333684 13093 sgd_solver.cpp:106] Iteration 210000, lr = 0.002
I0522 01:10:27.496664 13093 solver.cpp:237] Iteration 210750, loss = 1.20769
I0522 01:10:27.496846 13093 solver.cpp:253]     Train net output #0: loss = 1.20769 (* 1 = 1.20769 loss)
I0522 01:10:27.496860 13093 sgd_solver.cpp:106] Iteration 210750, lr = 0.002
I0522 01:10:39.678913 13093 solver.cpp:237] Iteration 211500, loss = 0.423662
I0522 01:10:39.678949 13093 solver.cpp:253]     Train net output #0: loss = 0.423662 (* 1 = 0.423662 loss)
I0522 01:10:39.678963 13093 sgd_solver.cpp:106] Iteration 211500, lr = 0.002
I0522 01:10:51.868594 13093 solver.cpp:237] Iteration 212250, loss = 1.09991
I0522 01:10:51.868633 13093 solver.cpp:253]     Train net output #0: loss = 1.09991 (* 1 = 1.09991 loss)
I0522 01:10:51.868644 13093 sgd_solver.cpp:106] Iteration 212250, lr = 0.002
I0522 01:11:04.028153 13093 solver.cpp:237] Iteration 213000, loss = 0.589533
I0522 01:11:04.028314 13093 solver.cpp:253]     Train net output #0: loss = 0.589532 (* 1 = 0.589532 loss)
I0522 01:11:04.028328 13093 sgd_solver.cpp:106] Iteration 213000, lr = 0.002
I0522 01:11:16.185178 13093 solver.cpp:237] Iteration 213750, loss = 1.17385
I0522 01:11:16.185219 13093 solver.cpp:253]     Train net output #0: loss = 1.17384 (* 1 = 1.17384 loss)
I0522 01:11:16.185230 13093 sgd_solver.cpp:106] Iteration 213750, lr = 0.002
I0522 01:11:28.341248 13093 solver.cpp:237] Iteration 214500, loss = 0.893913
I0522 01:11:28.341284 13093 solver.cpp:253]     Train net output #0: loss = 0.893912 (* 1 = 0.893912 loss)
I0522 01:11:28.341297 13093 sgd_solver.cpp:106] Iteration 214500, lr = 0.002
I0522 01:12:01.421710 13093 solver.cpp:237] Iteration 215250, loss = 1.38258
I0522 01:12:01.421903 13093 solver.cpp:253]     Train net output #0: loss = 1.38258 (* 1 = 1.38258 loss)
I0522 01:12:01.421918 13093 sgd_solver.cpp:106] Iteration 215250, lr = 0.002
I0522 01:12:13.598918 13093 solver.cpp:237] Iteration 216000, loss = 1.19851
I0522 01:12:13.598961 13093 solver.cpp:253]     Train net output #0: loss = 1.19851 (* 1 = 1.19851 loss)
I0522 01:12:13.598976 13093 sgd_solver.cpp:106] Iteration 216000, lr = 0.002
I0522 01:12:25.711896 13093 solver.cpp:237] Iteration 216750, loss = 0.894135
I0522 01:12:25.711932 13093 solver.cpp:253]     Train net output #0: loss = 0.894134 (* 1 = 0.894134 loss)
I0522 01:12:25.711947 13093 sgd_solver.cpp:106] Iteration 216750, lr = 0.002
I0522 01:12:37.805335 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_217500.caffemodel
I0522 01:12:37.856389 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_217500.solverstate
I0522 01:12:37.888293 13093 solver.cpp:237] Iteration 217500, loss = 1.39862
I0522 01:12:37.888344 13093 solver.cpp:253]     Train net output #0: loss = 1.39862 (* 1 = 1.39862 loss)
I0522 01:12:37.888358 13093 sgd_solver.cpp:106] Iteration 217500, lr = 0.002
I0522 01:12:49.995844 13093 solver.cpp:237] Iteration 218250, loss = 1.22787
I0522 01:12:49.995880 13093 solver.cpp:253]     Train net output #0: loss = 1.22787 (* 1 = 1.22787 loss)
I0522 01:12:49.995894 13093 sgd_solver.cpp:106] Iteration 218250, lr = 0.002
I0522 01:13:02.142405 13093 solver.cpp:237] Iteration 219000, loss = 2.30911
I0522 01:13:02.142447 13093 solver.cpp:253]     Train net output #0: loss = 2.30911 (* 1 = 2.30911 loss)
I0522 01:13:02.142462 13093 sgd_solver.cpp:106] Iteration 219000, lr = 0.002
I0522 01:13:14.323746 13093 solver.cpp:237] Iteration 219750, loss = 0.953897
I0522 01:13:14.323915 13093 solver.cpp:253]     Train net output #0: loss = 0.953896 (* 1 = 0.953896 loss)
I0522 01:13:14.323928 13093 sgd_solver.cpp:106] Iteration 219750, lr = 0.002
I0522 01:13:47.363975 13093 solver.cpp:237] Iteration 220500, loss = 0.931506
I0522 01:13:47.364156 13093 solver.cpp:253]     Train net output #0: loss = 0.931506 (* 1 = 0.931506 loss)
I0522 01:13:47.364171 13093 sgd_solver.cpp:106] Iteration 220500, lr = 0.002
I0522 01:13:59.569780 13093 solver.cpp:237] Iteration 221250, loss = 1.40722
I0522 01:13:59.569816 13093 solver.cpp:253]     Train net output #0: loss = 1.40722 (* 1 = 1.40722 loss)
I0522 01:13:59.569830 13093 sgd_solver.cpp:106] Iteration 221250, lr = 0.002
I0522 01:14:11.776012 13093 solver.cpp:237] Iteration 222000, loss = 1.09857
I0522 01:14:11.776059 13093 solver.cpp:253]     Train net output #0: loss = 1.09857 (* 1 = 1.09857 loss)
I0522 01:14:11.776075 13093 sgd_solver.cpp:106] Iteration 222000, lr = 0.002
I0522 01:14:23.980761 13093 solver.cpp:237] Iteration 222750, loss = 1.03671
I0522 01:14:23.980927 13093 solver.cpp:253]     Train net output #0: loss = 1.03671 (* 1 = 1.03671 loss)
I0522 01:14:23.980940 13093 sgd_solver.cpp:106] Iteration 222750, lr = 0.002
I0522 01:14:36.185760 13093 solver.cpp:237] Iteration 223500, loss = 1.50391
I0522 01:14:36.185804 13093 solver.cpp:253]     Train net output #0: loss = 1.50391 (* 1 = 1.50391 loss)
I0522 01:14:36.185820 13093 sgd_solver.cpp:106] Iteration 223500, lr = 0.002
I0522 01:14:48.408434 13093 solver.cpp:237] Iteration 224250, loss = 1.5645
I0522 01:14:48.408470 13093 solver.cpp:253]     Train net output #0: loss = 1.5645 (* 1 = 1.5645 loss)
I0522 01:14:48.408484 13093 sgd_solver.cpp:106] Iteration 224250, lr = 0.002
I0522 01:15:00.615767 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_225000.caffemodel
I0522 01:15:00.667178 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_225000.solverstate
I0522 01:15:00.694921 13093 solver.cpp:341] Iteration 225000, Testing net (#0)
I0522 01:15:52.260159 13093 solver.cpp:409]     Test net output #0: accuracy = 0.897877
I0522 01:15:52.260340 13093 solver.cpp:409]     Test net output #1: loss = 0.333242 (* 1 = 0.333242 loss)
I0522 01:16:13.101472 13093 solver.cpp:237] Iteration 225000, loss = 1.38912
I0522 01:16:13.101524 13093 solver.cpp:253]     Train net output #0: loss = 1.38912 (* 1 = 1.38912 loss)
I0522 01:16:13.101539 13093 sgd_solver.cpp:106] Iteration 225000, lr = 0.002
I0522 01:16:25.212044 13093 solver.cpp:237] Iteration 225750, loss = 1.00952
I0522 01:16:25.212225 13093 solver.cpp:253]     Train net output #0: loss = 1.00952 (* 1 = 1.00952 loss)
I0522 01:16:25.212239 13093 sgd_solver.cpp:106] Iteration 225750, lr = 0.002
I0522 01:16:37.323397 13093 solver.cpp:237] Iteration 226500, loss = 0.963794
I0522 01:16:37.323434 13093 solver.cpp:253]     Train net output #0: loss = 0.963794 (* 1 = 0.963794 loss)
I0522 01:16:37.323448 13093 sgd_solver.cpp:106] Iteration 226500, lr = 0.002
I0522 01:16:49.498585 13093 solver.cpp:237] Iteration 227250, loss = 0.946292
I0522 01:16:49.498636 13093 solver.cpp:253]     Train net output #0: loss = 0.946293 (* 1 = 0.946293 loss)
I0522 01:16:49.498651 13093 sgd_solver.cpp:106] Iteration 227250, lr = 0.002
I0522 01:17:01.679774 13093 solver.cpp:237] Iteration 228000, loss = 0.902026
I0522 01:17:01.679941 13093 solver.cpp:253]     Train net output #0: loss = 0.902026 (* 1 = 0.902026 loss)
I0522 01:17:01.679955 13093 sgd_solver.cpp:106] Iteration 228000, lr = 0.002
I0522 01:17:13.824832 13093 solver.cpp:237] Iteration 228750, loss = 1.01188
I0522 01:17:13.824880 13093 solver.cpp:253]     Train net output #0: loss = 1.01188 (* 1 = 1.01188 loss)
I0522 01:17:13.824894 13093 sgd_solver.cpp:106] Iteration 228750, lr = 0.002
I0522 01:17:25.923337 13093 solver.cpp:237] Iteration 229500, loss = 1.42397
I0522 01:17:25.923373 13093 solver.cpp:253]     Train net output #0: loss = 1.42397 (* 1 = 1.42397 loss)
I0522 01:17:25.923388 13093 sgd_solver.cpp:106] Iteration 229500, lr = 0.002
I0522 01:17:58.909577 13093 solver.cpp:237] Iteration 230250, loss = 1.32316
I0522 01:17:58.909762 13093 solver.cpp:253]     Train net output #0: loss = 1.32316 (* 1 = 1.32316 loss)
I0522 01:17:58.909776 13093 sgd_solver.cpp:106] Iteration 230250, lr = 0.002
I0522 01:18:10.992570 13093 solver.cpp:237] Iteration 231000, loss = 1.012
I0522 01:18:10.992606 13093 solver.cpp:253]     Train net output #0: loss = 1.012 (* 1 = 1.012 loss)
I0522 01:18:10.992620 13093 sgd_solver.cpp:106] Iteration 231000, lr = 0.002
I0522 01:18:23.104285 13093 solver.cpp:237] Iteration 231750, loss = 1.31023
I0522 01:18:23.104332 13093 solver.cpp:253]     Train net output #0: loss = 1.31023 (* 1 = 1.31023 loss)
I0522 01:18:23.104346 13093 sgd_solver.cpp:106] Iteration 231750, lr = 0.002
I0522 01:18:35.242434 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_232500.caffemodel
I0522 01:18:35.292243 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_232500.solverstate
I0522 01:18:35.322629 13093 solver.cpp:237] Iteration 232500, loss = 0.776115
I0522 01:18:35.322671 13093 solver.cpp:253]     Train net output #0: loss = 0.776116 (* 1 = 0.776116 loss)
I0522 01:18:35.322692 13093 sgd_solver.cpp:106] Iteration 232500, lr = 0.002
I0522 01:18:47.474602 13093 solver.cpp:237] Iteration 233250, loss = 1.01298
I0522 01:18:47.474653 13093 solver.cpp:253]     Train net output #0: loss = 1.01299 (* 1 = 1.01299 loss)
I0522 01:18:47.474668 13093 sgd_solver.cpp:106] Iteration 233250, lr = 0.002
I0522 01:18:59.560367 13093 solver.cpp:237] Iteration 234000, loss = 0.871082
I0522 01:18:59.560405 13093 solver.cpp:253]     Train net output #0: loss = 0.871083 (* 1 = 0.871083 loss)
I0522 01:18:59.560418 13093 sgd_solver.cpp:106] Iteration 234000, lr = 0.002
I0522 01:19:11.647716 13093 solver.cpp:237] Iteration 234750, loss = 0.957388
I0522 01:19:11.647909 13093 solver.cpp:253]     Train net output #0: loss = 0.957389 (* 1 = 0.957389 loss)
I0522 01:19:11.647924 13093 sgd_solver.cpp:106] Iteration 234750, lr = 0.002
I0522 01:19:44.648013 13093 solver.cpp:237] Iteration 235500, loss = 0.994554
I0522 01:19:44.648200 13093 solver.cpp:253]     Train net output #0: loss = 0.994555 (* 1 = 0.994555 loss)
I0522 01:19:44.648214 13093 sgd_solver.cpp:106] Iteration 235500, lr = 0.002
I0522 01:19:56.761879 13093 solver.cpp:237] Iteration 236250, loss = 0.846886
I0522 01:19:56.761915 13093 solver.cpp:253]     Train net output #0: loss = 0.846887 (* 1 = 0.846887 loss)
I0522 01:19:56.761929 13093 sgd_solver.cpp:106] Iteration 236250, lr = 0.002
I0522 01:20:08.866632 13093 solver.cpp:237] Iteration 237000, loss = 1.33561
I0522 01:20:08.866683 13093 solver.cpp:253]     Train net output #0: loss = 1.33561 (* 1 = 1.33561 loss)
I0522 01:20:08.866696 13093 sgd_solver.cpp:106] Iteration 237000, lr = 0.002
I0522 01:20:20.971470 13093 solver.cpp:237] Iteration 237750, loss = 1.24494
I0522 01:20:20.971637 13093 solver.cpp:253]     Train net output #0: loss = 1.24494 (* 1 = 1.24494 loss)
I0522 01:20:20.971650 13093 sgd_solver.cpp:106] Iteration 237750, lr = 0.002
I0522 01:20:33.136826 13093 solver.cpp:237] Iteration 238500, loss = 1.22214
I0522 01:20:33.136873 13093 solver.cpp:253]     Train net output #0: loss = 1.22214 (* 1 = 1.22214 loss)
I0522 01:20:33.136888 13093 sgd_solver.cpp:106] Iteration 238500, lr = 0.002
I0522 01:20:45.292601 13093 solver.cpp:237] Iteration 239250, loss = 1.52611
I0522 01:20:45.292637 13093 solver.cpp:253]     Train net output #0: loss = 1.52611 (* 1 = 1.52611 loss)
I0522 01:20:45.292651 13093 sgd_solver.cpp:106] Iteration 239250, lr = 0.002
I0522 01:20:57.403151 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_240000.caffemodel
I0522 01:20:57.452307 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_240000.solverstate
I0522 01:20:57.477514 13093 solver.cpp:341] Iteration 240000, Testing net (#0)
I0522 01:22:10.372179 13093 solver.cpp:409]     Test net output #0: accuracy = 0.898397
I0522 01:22:10.372365 13093 solver.cpp:409]     Test net output #1: loss = 0.324365 (* 1 = 0.324365 loss)
I0522 01:22:31.216563 13093 solver.cpp:237] Iteration 240000, loss = 1.17334
I0522 01:22:31.216614 13093 solver.cpp:253]     Train net output #0: loss = 1.17334 (* 1 = 1.17334 loss)
I0522 01:22:31.216631 13093 sgd_solver.cpp:106] Iteration 240000, lr = 0.002
I0522 01:22:43.281180 13093 solver.cpp:237] Iteration 240750, loss = 0.880567
I0522 01:22:43.281352 13093 solver.cpp:253]     Train net output #0: loss = 0.880568 (* 1 = 0.880568 loss)
I0522 01:22:43.281365 13093 sgd_solver.cpp:106] Iteration 240750, lr = 0.002
I0522 01:22:55.423297 13093 solver.cpp:237] Iteration 241500, loss = 1.01006
I0522 01:22:55.423331 13093 solver.cpp:253]     Train net output #0: loss = 1.01006 (* 1 = 1.01006 loss)
I0522 01:22:55.423343 13093 sgd_solver.cpp:106] Iteration 241500, lr = 0.002
I0522 01:23:07.522532 13093 solver.cpp:237] Iteration 242250, loss = 1.31252
I0522 01:23:07.522569 13093 solver.cpp:253]     Train net output #0: loss = 1.31252 (* 1 = 1.31252 loss)
I0522 01:23:07.522583 13093 sgd_solver.cpp:106] Iteration 242250, lr = 0.002
I0522 01:23:19.616364 13093 solver.cpp:237] Iteration 243000, loss = 1.19982
I0522 01:23:19.616549 13093 solver.cpp:253]     Train net output #0: loss = 1.19982 (* 1 = 1.19982 loss)
I0522 01:23:19.616562 13093 sgd_solver.cpp:106] Iteration 243000, lr = 0.002
I0522 01:23:31.731693 13093 solver.cpp:237] Iteration 243750, loss = 1.53728
I0522 01:23:31.731735 13093 solver.cpp:253]     Train net output #0: loss = 1.53728 (* 1 = 1.53728 loss)
I0522 01:23:31.731750 13093 sgd_solver.cpp:106] Iteration 243750, lr = 0.002
I0522 01:23:43.881078 13093 solver.cpp:237] Iteration 244500, loss = 1.43054
I0522 01:23:43.881114 13093 solver.cpp:253]     Train net output #0: loss = 1.43054 (* 1 = 1.43054 loss)
I0522 01:23:43.881129 13093 sgd_solver.cpp:106] Iteration 244500, lr = 0.002
I0522 01:24:16.886140 13093 solver.cpp:237] Iteration 245250, loss = 1.17978
I0522 01:24:16.886332 13093 solver.cpp:253]     Train net output #0: loss = 1.17978 (* 1 = 1.17978 loss)
I0522 01:24:16.886345 13093 sgd_solver.cpp:106] Iteration 245250, lr = 0.002
I0522 01:24:29.026528 13093 solver.cpp:237] Iteration 246000, loss = 0.716919
I0522 01:24:29.026566 13093 solver.cpp:253]     Train net output #0: loss = 0.71692 (* 1 = 0.71692 loss)
I0522 01:24:29.026579 13093 sgd_solver.cpp:106] Iteration 246000, lr = 0.002
I0522 01:24:41.162791 13093 solver.cpp:237] Iteration 246750, loss = 1.19232
I0522 01:24:41.162837 13093 solver.cpp:253]     Train net output #0: loss = 1.19232 (* 1 = 1.19232 loss)
I0522 01:24:41.162850 13093 sgd_solver.cpp:106] Iteration 246750, lr = 0.002
I0522 01:24:53.279355 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_247500.caffemodel
I0522 01:24:53.328956 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_247500.solverstate
I0522 01:24:53.359122 13093 solver.cpp:237] Iteration 247500, loss = 1.05625
I0522 01:24:53.359161 13093 solver.cpp:253]     Train net output #0: loss = 1.05625 (* 1 = 1.05625 loss)
I0522 01:24:53.359175 13093 sgd_solver.cpp:106] Iteration 247500, lr = 0.002
I0522 01:25:05.480043 13093 solver.cpp:237] Iteration 248250, loss = 1.69987
I0522 01:25:05.480092 13093 solver.cpp:253]     Train net output #0: loss = 1.69987 (* 1 = 1.69987 loss)
I0522 01:25:05.480105 13093 sgd_solver.cpp:106] Iteration 248250, lr = 0.002
I0522 01:25:17.512718 13093 solver.cpp:237] Iteration 249000, loss = 1.12574
I0522 01:25:17.512754 13093 solver.cpp:253]     Train net output #0: loss = 1.12574 (* 1 = 1.12574 loss)
I0522 01:25:17.512769 13093 sgd_solver.cpp:106] Iteration 249000, lr = 0.002
I0522 01:25:29.622308 13093 solver.cpp:237] Iteration 249750, loss = 1.28193
I0522 01:25:29.622489 13093 solver.cpp:253]     Train net output #0: loss = 1.28193 (* 1 = 1.28193 loss)
I0522 01:25:29.622503 13093 sgd_solver.cpp:106] Iteration 249750, lr = 0.002
I0522 01:26:02.540518 13093 solver.cpp:237] Iteration 250500, loss = 1.1441
I0522 01:26:02.540706 13093 solver.cpp:253]     Train net output #0: loss = 1.1441 (* 1 = 1.1441 loss)
I0522 01:26:02.540719 13093 sgd_solver.cpp:106] Iteration 250500, lr = 0.002
I0522 01:26:14.639957 13093 solver.cpp:237] Iteration 251250, loss = 1.1919
I0522 01:26:14.639994 13093 solver.cpp:253]     Train net output #0: loss = 1.19191 (* 1 = 1.19191 loss)
I0522 01:26:14.640009 13093 sgd_solver.cpp:106] Iteration 251250, lr = 0.002
I0522 01:26:26.749351 13093 solver.cpp:237] Iteration 252000, loss = 1.01638
I0522 01:26:26.749395 13093 solver.cpp:253]     Train net output #0: loss = 1.01638 (* 1 = 1.01638 loss)
I0522 01:26:26.749409 13093 sgd_solver.cpp:106] Iteration 252000, lr = 0.002
I0522 01:26:38.876818 13093 solver.cpp:237] Iteration 252750, loss = 1.14037
I0522 01:26:38.876986 13093 solver.cpp:253]     Train net output #0: loss = 1.14037 (* 1 = 1.14037 loss)
I0522 01:26:38.876999 13093 sgd_solver.cpp:106] Iteration 252750, lr = 0.002
I0522 01:26:50.988430 13093 solver.cpp:237] Iteration 253500, loss = 1.2542
I0522 01:26:50.988478 13093 solver.cpp:253]     Train net output #0: loss = 1.2542 (* 1 = 1.2542 loss)
I0522 01:26:50.988492 13093 sgd_solver.cpp:106] Iteration 253500, lr = 0.002
I0522 01:27:03.053668 13093 solver.cpp:237] Iteration 254250, loss = 1.27792
I0522 01:27:03.053704 13093 solver.cpp:253]     Train net output #0: loss = 1.27792 (* 1 = 1.27792 loss)
I0522 01:27:03.053717 13093 sgd_solver.cpp:106] Iteration 254250, lr = 0.002
I0522 01:27:15.157523 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_255000.caffemodel
I0522 01:27:15.206512 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_255000.solverstate
I0522 01:27:15.231890 13093 solver.cpp:341] Iteration 255000, Testing net (#0)
I0522 01:28:07.172400 13093 solver.cpp:409]     Test net output #0: accuracy = 0.898725
I0522 01:28:07.172587 13093 solver.cpp:409]     Test net output #1: loss = 0.325397 (* 1 = 0.325397 loss)
I0522 01:28:28.001180 13093 solver.cpp:237] Iteration 255000, loss = 1.03813
I0522 01:28:28.001235 13093 solver.cpp:253]     Train net output #0: loss = 1.03813 (* 1 = 1.03813 loss)
I0522 01:28:28.001250 13093 sgd_solver.cpp:106] Iteration 255000, lr = 0.002
I0522 01:28:40.124953 13093 solver.cpp:237] Iteration 255750, loss = 1.10949
I0522 01:28:40.125123 13093 solver.cpp:253]     Train net output #0: loss = 1.10949 (* 1 = 1.10949 loss)
I0522 01:28:40.125136 13093 sgd_solver.cpp:106] Iteration 255750, lr = 0.002
I0522 01:28:52.275688 13093 solver.cpp:237] Iteration 256500, loss = 0.577829
I0522 01:28:52.275732 13093 solver.cpp:253]     Train net output #0: loss = 0.57783 (* 1 = 0.57783 loss)
I0522 01:28:52.275748 13093 sgd_solver.cpp:106] Iteration 256500, lr = 0.002
I0522 01:29:04.437038 13093 solver.cpp:237] Iteration 257250, loss = 1.292
I0522 01:29:04.437074 13093 solver.cpp:253]     Train net output #0: loss = 1.292 (* 1 = 1.292 loss)
I0522 01:29:04.437089 13093 sgd_solver.cpp:106] Iteration 257250, lr = 0.002
I0522 01:29:16.603976 13093 solver.cpp:237] Iteration 258000, loss = 1.01714
I0522 01:29:16.604153 13093 solver.cpp:253]     Train net output #0: loss = 1.01714 (* 1 = 1.01714 loss)
I0522 01:29:16.604166 13093 sgd_solver.cpp:106] Iteration 258000, lr = 0.002
I0522 01:29:28.766229 13093 solver.cpp:237] Iteration 258750, loss = 1.55769
I0522 01:29:28.766264 13093 solver.cpp:253]     Train net output #0: loss = 1.55769 (* 1 = 1.55769 loss)
I0522 01:29:28.766279 13093 sgd_solver.cpp:106] Iteration 258750, lr = 0.002
I0522 01:29:40.932768 13093 solver.cpp:237] Iteration 259500, loss = 1.27242
I0522 01:29:40.932816 13093 solver.cpp:253]     Train net output #0: loss = 1.27243 (* 1 = 1.27243 loss)
I0522 01:29:40.932831 13093 sgd_solver.cpp:106] Iteration 259500, lr = 0.002
I0522 01:30:13.934337 13093 solver.cpp:237] Iteration 260250, loss = 1.5736
I0522 01:30:13.934527 13093 solver.cpp:253]     Train net output #0: loss = 1.5736 (* 1 = 1.5736 loss)
I0522 01:30:13.934541 13093 sgd_solver.cpp:106] Iteration 260250, lr = 0.002
I0522 01:30:26.109411 13093 solver.cpp:237] Iteration 261000, loss = 1.00579
I0522 01:30:26.109458 13093 solver.cpp:253]     Train net output #0: loss = 1.0058 (* 1 = 1.0058 loss)
I0522 01:30:26.109474 13093 sgd_solver.cpp:106] Iteration 261000, lr = 0.002
I0522 01:30:38.261313 13093 solver.cpp:237] Iteration 261750, loss = 1.14016
I0522 01:30:38.261349 13093 solver.cpp:253]     Train net output #0: loss = 1.14016 (* 1 = 1.14016 loss)
I0522 01:30:38.261364 13093 sgd_solver.cpp:106] Iteration 261750, lr = 0.002
I0522 01:30:50.414660 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_262500.caffemodel
I0522 01:30:50.474825 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_262500.solverstate
I0522 01:30:50.507361 13093 solver.cpp:237] Iteration 262500, loss = 1.29017
I0522 01:30:50.507411 13093 solver.cpp:253]     Train net output #0: loss = 1.29017 (* 1 = 1.29017 loss)
I0522 01:30:50.507427 13093 sgd_solver.cpp:106] Iteration 262500, lr = 0.002
I0522 01:31:02.659204 13093 solver.cpp:237] Iteration 263250, loss = 1.4319
I0522 01:31:02.659240 13093 solver.cpp:253]     Train net output #0: loss = 1.43191 (* 1 = 1.43191 loss)
I0522 01:31:02.659255 13093 sgd_solver.cpp:106] Iteration 263250, lr = 0.002
I0522 01:31:14.795063 13093 solver.cpp:237] Iteration 264000, loss = 1.45908
I0522 01:31:14.795100 13093 solver.cpp:253]     Train net output #0: loss = 1.45908 (* 1 = 1.45908 loss)
I0522 01:31:14.795114 13093 sgd_solver.cpp:106] Iteration 264000, lr = 0.002
I0522 01:31:26.899919 13093 solver.cpp:237] Iteration 264750, loss = 0.88219
I0522 01:31:26.900118 13093 solver.cpp:253]     Train net output #0: loss = 0.882191 (* 1 = 0.882191 loss)
I0522 01:31:26.900133 13093 sgd_solver.cpp:106] Iteration 264750, lr = 0.002
I0522 01:31:59.850234 13093 solver.cpp:237] Iteration 265500, loss = 1.27581
I0522 01:31:59.850428 13093 solver.cpp:253]     Train net output #0: loss = 1.27582 (* 1 = 1.27582 loss)
I0522 01:31:59.850445 13093 sgd_solver.cpp:106] Iteration 265500, lr = 0.002
I0522 01:32:12.002038 13093 solver.cpp:237] Iteration 266250, loss = 0.899383
I0522 01:32:12.002084 13093 solver.cpp:253]     Train net output #0: loss = 0.899384 (* 1 = 0.899384 loss)
I0522 01:32:12.002099 13093 sgd_solver.cpp:106] Iteration 266250, lr = 0.002
I0522 01:32:24.129930 13093 solver.cpp:237] Iteration 267000, loss = 1.7869
I0522 01:32:24.129966 13093 solver.cpp:253]     Train net output #0: loss = 1.7869 (* 1 = 1.7869 loss)
I0522 01:32:24.129981 13093 sgd_solver.cpp:106] Iteration 267000, lr = 0.002
I0522 01:32:36.184499 13093 solver.cpp:237] Iteration 267750, loss = 1.11226
I0522 01:32:36.184681 13093 solver.cpp:253]     Train net output #0: loss = 1.11226 (* 1 = 1.11226 loss)
I0522 01:32:36.184695 13093 sgd_solver.cpp:106] Iteration 267750, lr = 0.002
I0522 01:32:48.298208 13093 solver.cpp:237] Iteration 268500, loss = 1.2153
I0522 01:32:48.298244 13093 solver.cpp:253]     Train net output #0: loss = 1.2153 (* 1 = 1.2153 loss)
I0522 01:32:48.298259 13093 sgd_solver.cpp:106] Iteration 268500, lr = 0.002
I0522 01:33:00.404714 13093 solver.cpp:237] Iteration 269250, loss = 1.25137
I0522 01:33:00.404760 13093 solver.cpp:253]     Train net output #0: loss = 1.25137 (* 1 = 1.25137 loss)
I0522 01:33:00.404774 13093 sgd_solver.cpp:106] Iteration 269250, lr = 0.002
I0522 01:33:12.537047 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_270000.caffemodel
I0522 01:33:12.588469 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_270000.solverstate
I0522 01:33:12.615742 13093 solver.cpp:341] Iteration 270000, Testing net (#0)
I0522 01:34:25.450768 13093 solver.cpp:409]     Test net output #0: accuracy = 0.901046
I0522 01:34:25.450966 13093 solver.cpp:409]     Test net output #1: loss = 0.315405 (* 1 = 0.315405 loss)
I0522 01:34:46.316169 13093 solver.cpp:237] Iteration 270000, loss = 1.20295
I0522 01:34:46.316221 13093 solver.cpp:253]     Train net output #0: loss = 1.20296 (* 1 = 1.20296 loss)
I0522 01:34:46.316237 13093 sgd_solver.cpp:106] Iteration 270000, lr = 0.002
I0522 01:34:58.455921 13093 solver.cpp:237] Iteration 270750, loss = 0.871561
I0522 01:34:58.456094 13093 solver.cpp:253]     Train net output #0: loss = 0.871562 (* 1 = 0.871562 loss)
I0522 01:34:58.456109 13093 sgd_solver.cpp:106] Iteration 270750, lr = 0.002
I0522 01:35:10.666856 13093 solver.cpp:237] Iteration 271500, loss = 1.70883
I0522 01:35:10.666901 13093 solver.cpp:253]     Train net output #0: loss = 1.70884 (* 1 = 1.70884 loss)
I0522 01:35:10.666915 13093 sgd_solver.cpp:106] Iteration 271500, lr = 0.002
I0522 01:35:22.852215 13093 solver.cpp:237] Iteration 272250, loss = 1.06124
I0522 01:35:22.852252 13093 solver.cpp:253]     Train net output #0: loss = 1.06124 (* 1 = 1.06124 loss)
I0522 01:35:22.852265 13093 sgd_solver.cpp:106] Iteration 272250, lr = 0.002
I0522 01:35:34.986387 13093 solver.cpp:237] Iteration 273000, loss = 1.20162
I0522 01:35:34.986582 13093 solver.cpp:253]     Train net output #0: loss = 1.20162 (* 1 = 1.20162 loss)
I0522 01:35:34.986595 13093 sgd_solver.cpp:106] Iteration 273000, lr = 0.002
I0522 01:35:47.108394 13093 solver.cpp:237] Iteration 273750, loss = 1.2704
I0522 01:35:47.108430 13093 solver.cpp:253]     Train net output #0: loss = 1.2704 (* 1 = 1.2704 loss)
I0522 01:35:47.108445 13093 sgd_solver.cpp:106] Iteration 273750, lr = 0.002
I0522 01:35:59.266460 13093 solver.cpp:237] Iteration 274500, loss = 1.05364
I0522 01:35:59.266510 13093 solver.cpp:253]     Train net output #0: loss = 1.05364 (* 1 = 1.05364 loss)
I0522 01:35:59.266525 13093 sgd_solver.cpp:106] Iteration 274500, lr = 0.002
I0522 01:36:32.228546 13093 solver.cpp:237] Iteration 275250, loss = 1.22581
I0522 01:36:32.228739 13093 solver.cpp:253]     Train net output #0: loss = 1.22581 (* 1 = 1.22581 loss)
I0522 01:36:32.228752 13093 sgd_solver.cpp:106] Iteration 275250, lr = 0.002
I0522 01:36:44.347968 13093 solver.cpp:237] Iteration 276000, loss = 0.912579
I0522 01:36:44.348012 13093 solver.cpp:253]     Train net output #0: loss = 0.912581 (* 1 = 0.912581 loss)
I0522 01:36:44.348026 13093 sgd_solver.cpp:106] Iteration 276000, lr = 0.002
I0522 01:36:56.489513 13093 solver.cpp:237] Iteration 276750, loss = 1.42603
I0522 01:36:56.489549 13093 solver.cpp:253]     Train net output #0: loss = 1.42604 (* 1 = 1.42604 loss)
I0522 01:36:56.489564 13093 sgd_solver.cpp:106] Iteration 276750, lr = 0.002
I0522 01:37:08.615095 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_277500.caffemodel
I0522 01:37:08.664619 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_277500.solverstate
I0522 01:37:08.695168 13093 solver.cpp:237] Iteration 277500, loss = 1.08658
I0522 01:37:08.695221 13093 solver.cpp:253]     Train net output #0: loss = 1.08659 (* 1 = 1.08659 loss)
I0522 01:37:08.695237 13093 sgd_solver.cpp:106] Iteration 277500, lr = 0.002
I0522 01:37:20.868171 13093 solver.cpp:237] Iteration 278250, loss = 1.33052
I0522 01:37:20.868208 13093 solver.cpp:253]     Train net output #0: loss = 1.33052 (* 1 = 1.33052 loss)
I0522 01:37:20.868222 13093 sgd_solver.cpp:106] Iteration 278250, lr = 0.002
I0522 01:37:33.051955 13093 solver.cpp:237] Iteration 279000, loss = 1.28236
I0522 01:37:33.052005 13093 solver.cpp:253]     Train net output #0: loss = 1.28236 (* 1 = 1.28236 loss)
I0522 01:37:33.052018 13093 sgd_solver.cpp:106] Iteration 279000, lr = 0.002
I0522 01:37:45.181182 13093 solver.cpp:237] Iteration 279750, loss = 1.12198
I0522 01:37:45.181359 13093 solver.cpp:253]     Train net output #0: loss = 1.12198 (* 1 = 1.12198 loss)
I0522 01:37:45.181372 13093 sgd_solver.cpp:106] Iteration 279750, lr = 0.002
I0522 01:38:18.189051 13093 solver.cpp:237] Iteration 280500, loss = 1.55448
I0522 01:38:18.189242 13093 solver.cpp:253]     Train net output #0: loss = 1.55449 (* 1 = 1.55449 loss)
I0522 01:38:18.189256 13093 sgd_solver.cpp:106] Iteration 280500, lr = 0.002
I0522 01:38:30.351550 13093 solver.cpp:237] Iteration 281250, loss = 1.60594
I0522 01:38:30.351594 13093 solver.cpp:253]     Train net output #0: loss = 1.60594 (* 1 = 1.60594 loss)
I0522 01:38:30.351609 13093 sgd_solver.cpp:106] Iteration 281250, lr = 0.002
I0522 01:38:42.489857 13093 solver.cpp:237] Iteration 282000, loss = 1.36426
I0522 01:38:42.489894 13093 solver.cpp:253]     Train net output #0: loss = 1.36426 (* 1 = 1.36426 loss)
I0522 01:38:42.489908 13093 sgd_solver.cpp:106] Iteration 282000, lr = 0.002
I0522 01:38:54.679473 13093 solver.cpp:237] Iteration 282750, loss = 1.28567
I0522 01:38:54.679668 13093 solver.cpp:253]     Train net output #0: loss = 1.28567 (* 1 = 1.28567 loss)
I0522 01:38:54.679682 13093 sgd_solver.cpp:106] Iteration 282750, lr = 0.002
I0522 01:39:06.874795 13093 solver.cpp:237] Iteration 283500, loss = 1.30929
I0522 01:39:06.874831 13093 solver.cpp:253]     Train net output #0: loss = 1.30929 (* 1 = 1.30929 loss)
I0522 01:39:06.874846 13093 sgd_solver.cpp:106] Iteration 283500, lr = 0.002
I0522 01:39:18.987337 13093 solver.cpp:237] Iteration 284250, loss = 0.985797
I0522 01:39:18.987387 13093 solver.cpp:253]     Train net output #0: loss = 0.985798 (* 1 = 0.985798 loss)
I0522 01:39:18.987401 13093 sgd_solver.cpp:106] Iteration 284250, lr = 0.002
I0522 01:39:31.080521 13093 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_285000.caffemodel
I0522 01:39:31.129375 13093 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0020_2016-05-20T15.48.54.568961_iter_285000.solverstate
I0522 01:39:31.154397 13093 solver.cpp:341] Iteration 285000, Testing net (#0)
I0522 01:40:22.715932 13093 solver.cpp:409]     Test net output #0: accuracy = 0.899059
I0522 01:40:22.716125 13093 solver.cpp:409]     Test net output #1: loss = 0.315307 (* 1 = 0.315307 loss)
I0522 01:40:43.529301 13093 solver.cpp:237] Iteration 285000, loss = 1.71803
I0522 01:40:43.529355 13093 solver.cpp:253]     Train net output #0: loss = 1.71803 (* 1 = 1.71803 loss)
I0522 01:40:43.529371 13093 sgd_solver.cpp:106] Iteration 285000, lr = 0.002
I0522 01:40:55.709436 13093 solver.cpp:237] Iteration 285750, loss = 1.17222
I0522 01:40:55.709624 13093 solver.cpp:253]     Train net output #0: loss = 1.17222 (* 1 = 1.17222 loss)
I0522 01:40:55.709637 13093 sgd_solver.cpp:106] Iteration 285750, lr = 0.002
I0522 01:41:07.910562 13093 solver.cpp:237] Iteration 286500, loss = 0.695048
I0522 01:41:07.910600 13093 solver.cpp:253]     Train net output #0: loss = 0.695049 (* 1 = 0.695049 loss)
I0522 01:41:07.910615 13093 sgd_solver.cpp:106] Iteration 286500, lr = 0.002
I0522 01:41:20.143954 13093 solver.cpp:237] Iteration 287250, loss = 0.898482
I0522 01:41:20.144003 13093 solver.cpp:253]     Train net output #0: loss = 0.898483 (* 1 = 0.898483 loss)
I0522 01:41:20.144017 13093 sgd_solver.cpp:106] Iteration 287250, lr = 0.002
I0522 01:41:32.386606 13093 solver.cpp:237] Iteration 288000, loss = 0.77283
I0522 01:41:32.386780 13093 solver.cpp:253]     Train net output #0: loss = 0.772831 (* 1 = 0.772831 loss)
I0522 01:41:32.386793 13093 sgd_solver.cpp:106] Iteration 288000, lr = 0.002
I0522 01:41:44.634059 13093 solver.cpp:237] Iteration 288750, loss = 0.851745
I0522 01:41:44.634107 13093 solver.cpp:253]     Train net output #0: loss = 0.851747 (* 1 = 0.851747 loss)
I0522 01:41:44.634121 13093 sgd_solver.cpp:106] Iteration 288750, lr = 0.002
I0522 01:41:56.870920 13093 solver.cpp:237] Iteration 289500, loss = 0.941045
I0522 01:41:56.870957 13093 solver.cpp:253]     Train net output #0: loss = 0.941046 (* 1 = 0.941046 loss)
I0522 01:41:56.870971 13093 sgd_solver.cpp:106] Iteration 289500, lr = 0.002
I0522 01:42:29.941694 13093 solver.cpp:237] Iteration 290250, loss = 1.00004
I0522 01:42:29.941889 13093 solver.cpp:253]     Train net output #0: loss = 1.00004 (* 1 = 1.00004 loss)
I0522 01:42:29.941901 13093 sgd_solver.cpp:106] Iteration 290250, lr = 0.002
aprun: Apid 11243177: Caught signal Terminated, sending to application
*** Aborted at 1463895758 (unix time) try "date -d @1463895758" if you are using GNU date ***
aprun: Apid 11243177: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11243177: Caught signal Terminated, sending to application
*** SIGTERM (@0x3322) received by PID 13093 (TID 0x2aaac746f900) from PID 13090; stack trace: ***
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11243177: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7220 exceeded limit 7200
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11243177: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11243177: Caught signal Terminated, sending to application
