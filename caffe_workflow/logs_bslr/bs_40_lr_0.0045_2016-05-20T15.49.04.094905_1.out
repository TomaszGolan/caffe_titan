2807978
I0522 23:52:56.214514  3818 caffe.cpp:184] Using GPUs 0
I0522 23:52:56.639745  3818 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0045
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905.prototxt"
I0522 23:52:56.641301  3818 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905.prototxt
I0522 23:52:56.657068  3818 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 23:52:56.657127  3818 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 23:52:56.657474  3818 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 23:52:56.657652  3818 layer_factory.hpp:77] Creating layer data_hdf5
I0522 23:52:56.657676  3818 net.cpp:106] Creating Layer data_hdf5
I0522 23:52:56.657691  3818 net.cpp:411] data_hdf5 -> data
I0522 23:52:56.657724  3818 net.cpp:411] data_hdf5 -> label
I0522 23:52:56.657757  3818 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 23:52:56.669703  3818 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 23:52:56.671885  3818 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 23:53:18.259035  3818 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 23:53:18.264179  3818 net.cpp:150] Setting up data_hdf5
I0522 23:53:18.264224  3818 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 23:53:18.264238  3818 net.cpp:157] Top shape: 40 (40)
I0522 23:53:18.264248  3818 net.cpp:165] Memory required for data: 1016160
I0522 23:53:18.264262  3818 layer_factory.hpp:77] Creating layer conv1
I0522 23:53:18.264297  3818 net.cpp:106] Creating Layer conv1
I0522 23:53:18.264309  3818 net.cpp:454] conv1 <- data
I0522 23:53:18.264331  3818 net.cpp:411] conv1 -> conv1
I0522 23:53:19.112471  3818 net.cpp:150] Setting up conv1
I0522 23:53:19.112516  3818 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 23:53:19.112527  3818 net.cpp:165] Memory required for data: 12075360
I0522 23:53:19.112557  3818 layer_factory.hpp:77] Creating layer relu1
I0522 23:53:19.112578  3818 net.cpp:106] Creating Layer relu1
I0522 23:53:19.112589  3818 net.cpp:454] relu1 <- conv1
I0522 23:53:19.112603  3818 net.cpp:397] relu1 -> conv1 (in-place)
I0522 23:53:19.113123  3818 net.cpp:150] Setting up relu1
I0522 23:53:19.113140  3818 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 23:53:19.113152  3818 net.cpp:165] Memory required for data: 23134560
I0522 23:53:19.113162  3818 layer_factory.hpp:77] Creating layer pool1
I0522 23:53:19.113179  3818 net.cpp:106] Creating Layer pool1
I0522 23:53:19.113189  3818 net.cpp:454] pool1 <- conv1
I0522 23:53:19.113204  3818 net.cpp:411] pool1 -> pool1
I0522 23:53:19.113284  3818 net.cpp:150] Setting up pool1
I0522 23:53:19.113298  3818 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 23:53:19.113308  3818 net.cpp:165] Memory required for data: 28664160
I0522 23:53:19.113319  3818 layer_factory.hpp:77] Creating layer conv2
I0522 23:53:19.113342  3818 net.cpp:106] Creating Layer conv2
I0522 23:53:19.113353  3818 net.cpp:454] conv2 <- pool1
I0522 23:53:19.113365  3818 net.cpp:411] conv2 -> conv2
I0522 23:53:19.116088  3818 net.cpp:150] Setting up conv2
I0522 23:53:19.116117  3818 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 23:53:19.116127  3818 net.cpp:165] Memory required for data: 36612960
I0522 23:53:19.116147  3818 layer_factory.hpp:77] Creating layer relu2
I0522 23:53:19.116161  3818 net.cpp:106] Creating Layer relu2
I0522 23:53:19.116171  3818 net.cpp:454] relu2 <- conv2
I0522 23:53:19.116184  3818 net.cpp:397] relu2 -> conv2 (in-place)
I0522 23:53:19.116515  3818 net.cpp:150] Setting up relu2
I0522 23:53:19.116529  3818 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 23:53:19.116539  3818 net.cpp:165] Memory required for data: 44561760
I0522 23:53:19.116550  3818 layer_factory.hpp:77] Creating layer pool2
I0522 23:53:19.116562  3818 net.cpp:106] Creating Layer pool2
I0522 23:53:19.116572  3818 net.cpp:454] pool2 <- conv2
I0522 23:53:19.116585  3818 net.cpp:411] pool2 -> pool2
I0522 23:53:19.116667  3818 net.cpp:150] Setting up pool2
I0522 23:53:19.116680  3818 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 23:53:19.116690  3818 net.cpp:165] Memory required for data: 48536160
I0522 23:53:19.116700  3818 layer_factory.hpp:77] Creating layer conv3
I0522 23:53:19.116719  3818 net.cpp:106] Creating Layer conv3
I0522 23:53:19.116729  3818 net.cpp:454] conv3 <- pool2
I0522 23:53:19.116742  3818 net.cpp:411] conv3 -> conv3
I0522 23:53:19.118683  3818 net.cpp:150] Setting up conv3
I0522 23:53:19.118706  3818 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 23:53:19.118719  3818 net.cpp:165] Memory required for data: 52872800
I0522 23:53:19.118736  3818 layer_factory.hpp:77] Creating layer relu3
I0522 23:53:19.118752  3818 net.cpp:106] Creating Layer relu3
I0522 23:53:19.118762  3818 net.cpp:454] relu3 <- conv3
I0522 23:53:19.118775  3818 net.cpp:397] relu3 -> conv3 (in-place)
I0522 23:53:19.119257  3818 net.cpp:150] Setting up relu3
I0522 23:53:19.119276  3818 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 23:53:19.119285  3818 net.cpp:165] Memory required for data: 57209440
I0522 23:53:19.119295  3818 layer_factory.hpp:77] Creating layer pool3
I0522 23:53:19.119309  3818 net.cpp:106] Creating Layer pool3
I0522 23:53:19.119319  3818 net.cpp:454] pool3 <- conv3
I0522 23:53:19.119331  3818 net.cpp:411] pool3 -> pool3
I0522 23:53:19.119400  3818 net.cpp:150] Setting up pool3
I0522 23:53:19.119412  3818 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 23:53:19.119422  3818 net.cpp:165] Memory required for data: 59377760
I0522 23:53:19.119432  3818 layer_factory.hpp:77] Creating layer conv4
I0522 23:53:19.119451  3818 net.cpp:106] Creating Layer conv4
I0522 23:53:19.119462  3818 net.cpp:454] conv4 <- pool3
I0522 23:53:19.119474  3818 net.cpp:411] conv4 -> conv4
I0522 23:53:19.122234  3818 net.cpp:150] Setting up conv4
I0522 23:53:19.122263  3818 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 23:53:19.122275  3818 net.cpp:165] Memory required for data: 60829280
I0522 23:53:19.122292  3818 layer_factory.hpp:77] Creating layer relu4
I0522 23:53:19.122306  3818 net.cpp:106] Creating Layer relu4
I0522 23:53:19.122316  3818 net.cpp:454] relu4 <- conv4
I0522 23:53:19.122329  3818 net.cpp:397] relu4 -> conv4 (in-place)
I0522 23:53:19.122800  3818 net.cpp:150] Setting up relu4
I0522 23:53:19.122817  3818 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 23:53:19.122828  3818 net.cpp:165] Memory required for data: 62280800
I0522 23:53:19.122838  3818 layer_factory.hpp:77] Creating layer pool4
I0522 23:53:19.122851  3818 net.cpp:106] Creating Layer pool4
I0522 23:53:19.122861  3818 net.cpp:454] pool4 <- conv4
I0522 23:53:19.122874  3818 net.cpp:411] pool4 -> pool4
I0522 23:53:19.122942  3818 net.cpp:150] Setting up pool4
I0522 23:53:19.122956  3818 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 23:53:19.122967  3818 net.cpp:165] Memory required for data: 63006560
I0522 23:53:19.122977  3818 layer_factory.hpp:77] Creating layer ip1
I0522 23:53:19.123006  3818 net.cpp:106] Creating Layer ip1
I0522 23:53:19.123018  3818 net.cpp:454] ip1 <- pool4
I0522 23:53:19.123030  3818 net.cpp:411] ip1 -> ip1
I0522 23:53:19.138461  3818 net.cpp:150] Setting up ip1
I0522 23:53:19.138489  3818 net.cpp:157] Top shape: 40 196 (7840)
I0522 23:53:19.138501  3818 net.cpp:165] Memory required for data: 63037920
I0522 23:53:19.138525  3818 layer_factory.hpp:77] Creating layer relu5
I0522 23:53:19.138538  3818 net.cpp:106] Creating Layer relu5
I0522 23:53:19.138548  3818 net.cpp:454] relu5 <- ip1
I0522 23:53:19.138561  3818 net.cpp:397] relu5 -> ip1 (in-place)
I0522 23:53:19.138905  3818 net.cpp:150] Setting up relu5
I0522 23:53:19.138918  3818 net.cpp:157] Top shape: 40 196 (7840)
I0522 23:53:19.138929  3818 net.cpp:165] Memory required for data: 63069280
I0522 23:53:19.138939  3818 layer_factory.hpp:77] Creating layer drop1
I0522 23:53:19.138962  3818 net.cpp:106] Creating Layer drop1
I0522 23:53:19.138972  3818 net.cpp:454] drop1 <- ip1
I0522 23:53:19.138990  3818 net.cpp:397] drop1 -> ip1 (in-place)
I0522 23:53:19.139051  3818 net.cpp:150] Setting up drop1
I0522 23:53:19.139065  3818 net.cpp:157] Top shape: 40 196 (7840)
I0522 23:53:19.139075  3818 net.cpp:165] Memory required for data: 63100640
I0522 23:53:19.139086  3818 layer_factory.hpp:77] Creating layer ip2
I0522 23:53:19.139103  3818 net.cpp:106] Creating Layer ip2
I0522 23:53:19.139114  3818 net.cpp:454] ip2 <- ip1
I0522 23:53:19.139127  3818 net.cpp:411] ip2 -> ip2
I0522 23:53:19.139590  3818 net.cpp:150] Setting up ip2
I0522 23:53:19.139603  3818 net.cpp:157] Top shape: 40 98 (3920)
I0522 23:53:19.139613  3818 net.cpp:165] Memory required for data: 63116320
I0522 23:53:19.139628  3818 layer_factory.hpp:77] Creating layer relu6
I0522 23:53:19.139641  3818 net.cpp:106] Creating Layer relu6
I0522 23:53:19.139650  3818 net.cpp:454] relu6 <- ip2
I0522 23:53:19.139662  3818 net.cpp:397] relu6 -> ip2 (in-place)
I0522 23:53:19.140180  3818 net.cpp:150] Setting up relu6
I0522 23:53:19.140197  3818 net.cpp:157] Top shape: 40 98 (3920)
I0522 23:53:19.140207  3818 net.cpp:165] Memory required for data: 63132000
I0522 23:53:19.140218  3818 layer_factory.hpp:77] Creating layer drop2
I0522 23:53:19.140230  3818 net.cpp:106] Creating Layer drop2
I0522 23:53:19.140240  3818 net.cpp:454] drop2 <- ip2
I0522 23:53:19.140252  3818 net.cpp:397] drop2 -> ip2 (in-place)
I0522 23:53:19.140295  3818 net.cpp:150] Setting up drop2
I0522 23:53:19.140308  3818 net.cpp:157] Top shape: 40 98 (3920)
I0522 23:53:19.140319  3818 net.cpp:165] Memory required for data: 63147680
I0522 23:53:19.140329  3818 layer_factory.hpp:77] Creating layer ip3
I0522 23:53:19.140342  3818 net.cpp:106] Creating Layer ip3
I0522 23:53:19.140353  3818 net.cpp:454] ip3 <- ip2
I0522 23:53:19.140365  3818 net.cpp:411] ip3 -> ip3
I0522 23:53:19.140575  3818 net.cpp:150] Setting up ip3
I0522 23:53:19.140588  3818 net.cpp:157] Top shape: 40 11 (440)
I0522 23:53:19.140599  3818 net.cpp:165] Memory required for data: 63149440
I0522 23:53:19.140614  3818 layer_factory.hpp:77] Creating layer drop3
I0522 23:53:19.140625  3818 net.cpp:106] Creating Layer drop3
I0522 23:53:19.140635  3818 net.cpp:454] drop3 <- ip3
I0522 23:53:19.140647  3818 net.cpp:397] drop3 -> ip3 (in-place)
I0522 23:53:19.140687  3818 net.cpp:150] Setting up drop3
I0522 23:53:19.140699  3818 net.cpp:157] Top shape: 40 11 (440)
I0522 23:53:19.140710  3818 net.cpp:165] Memory required for data: 63151200
I0522 23:53:19.140719  3818 layer_factory.hpp:77] Creating layer loss
I0522 23:53:19.140739  3818 net.cpp:106] Creating Layer loss
I0522 23:53:19.140749  3818 net.cpp:454] loss <- ip3
I0522 23:53:19.140760  3818 net.cpp:454] loss <- label
I0522 23:53:19.140772  3818 net.cpp:411] loss -> loss
I0522 23:53:19.140790  3818 layer_factory.hpp:77] Creating layer loss
I0522 23:53:19.141429  3818 net.cpp:150] Setting up loss
I0522 23:53:19.141450  3818 net.cpp:157] Top shape: (1)
I0522 23:53:19.141463  3818 net.cpp:160]     with loss weight 1
I0522 23:53:19.141506  3818 net.cpp:165] Memory required for data: 63151204
I0522 23:53:19.141517  3818 net.cpp:226] loss needs backward computation.
I0522 23:53:19.141527  3818 net.cpp:226] drop3 needs backward computation.
I0522 23:53:19.141537  3818 net.cpp:226] ip3 needs backward computation.
I0522 23:53:19.141548  3818 net.cpp:226] drop2 needs backward computation.
I0522 23:53:19.141558  3818 net.cpp:226] relu6 needs backward computation.
I0522 23:53:19.141568  3818 net.cpp:226] ip2 needs backward computation.
I0522 23:53:19.141578  3818 net.cpp:226] drop1 needs backward computation.
I0522 23:53:19.141588  3818 net.cpp:226] relu5 needs backward computation.
I0522 23:53:19.141598  3818 net.cpp:226] ip1 needs backward computation.
I0522 23:53:19.141608  3818 net.cpp:226] pool4 needs backward computation.
I0522 23:53:19.141618  3818 net.cpp:226] relu4 needs backward computation.
I0522 23:53:19.141628  3818 net.cpp:226] conv4 needs backward computation.
I0522 23:53:19.141639  3818 net.cpp:226] pool3 needs backward computation.
I0522 23:53:19.141649  3818 net.cpp:226] relu3 needs backward computation.
I0522 23:53:19.141659  3818 net.cpp:226] conv3 needs backward computation.
I0522 23:53:19.141680  3818 net.cpp:226] pool2 needs backward computation.
I0522 23:53:19.141691  3818 net.cpp:226] relu2 needs backward computation.
I0522 23:53:19.141700  3818 net.cpp:226] conv2 needs backward computation.
I0522 23:53:19.141711  3818 net.cpp:226] pool1 needs backward computation.
I0522 23:53:19.141722  3818 net.cpp:226] relu1 needs backward computation.
I0522 23:53:19.141731  3818 net.cpp:226] conv1 needs backward computation.
I0522 23:53:19.141743  3818 net.cpp:228] data_hdf5 does not need backward computation.
I0522 23:53:19.141753  3818 net.cpp:270] This network produces output loss
I0522 23:53:19.141777  3818 net.cpp:283] Network initialization done.
I0522 23:53:19.143358  3818 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905.prototxt
I0522 23:53:19.143429  3818 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 23:53:19.143784  3818 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 23:53:19.143973  3818 layer_factory.hpp:77] Creating layer data_hdf5
I0522 23:53:19.143988  3818 net.cpp:106] Creating Layer data_hdf5
I0522 23:53:19.144001  3818 net.cpp:411] data_hdf5 -> data
I0522 23:53:19.144017  3818 net.cpp:411] data_hdf5 -> label
I0522 23:53:19.144033  3818 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 23:53:19.145182  3818 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 23:53:40.480257  3818 net.cpp:150] Setting up data_hdf5
I0522 23:53:40.480422  3818 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 23:53:40.480437  3818 net.cpp:157] Top shape: 40 (40)
I0522 23:53:40.480446  3818 net.cpp:165] Memory required for data: 1016160
I0522 23:53:40.480460  3818 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 23:53:40.480489  3818 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 23:53:40.480499  3818 net.cpp:454] label_data_hdf5_1_split <- label
I0522 23:53:40.480515  3818 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 23:53:40.480535  3818 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 23:53:40.480607  3818 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 23:53:40.480621  3818 net.cpp:157] Top shape: 40 (40)
I0522 23:53:40.480634  3818 net.cpp:157] Top shape: 40 (40)
I0522 23:53:40.480643  3818 net.cpp:165] Memory required for data: 1016480
I0522 23:53:40.480654  3818 layer_factory.hpp:77] Creating layer conv1
I0522 23:53:40.480675  3818 net.cpp:106] Creating Layer conv1
I0522 23:53:40.480685  3818 net.cpp:454] conv1 <- data
I0522 23:53:40.480701  3818 net.cpp:411] conv1 -> conv1
I0522 23:53:40.482615  3818 net.cpp:150] Setting up conv1
I0522 23:53:40.482640  3818 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 23:53:40.482650  3818 net.cpp:165] Memory required for data: 12075680
I0522 23:53:40.482671  3818 layer_factory.hpp:77] Creating layer relu1
I0522 23:53:40.482686  3818 net.cpp:106] Creating Layer relu1
I0522 23:53:40.482697  3818 net.cpp:454] relu1 <- conv1
I0522 23:53:40.482709  3818 net.cpp:397] relu1 -> conv1 (in-place)
I0522 23:53:40.483217  3818 net.cpp:150] Setting up relu1
I0522 23:53:40.483232  3818 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 23:53:40.483243  3818 net.cpp:165] Memory required for data: 23134880
I0522 23:53:40.483253  3818 layer_factory.hpp:77] Creating layer pool1
I0522 23:53:40.483268  3818 net.cpp:106] Creating Layer pool1
I0522 23:53:40.483278  3818 net.cpp:454] pool1 <- conv1
I0522 23:53:40.483291  3818 net.cpp:411] pool1 -> pool1
I0522 23:53:40.483366  3818 net.cpp:150] Setting up pool1
I0522 23:53:40.483379  3818 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 23:53:40.483389  3818 net.cpp:165] Memory required for data: 28664480
I0522 23:53:40.483399  3818 layer_factory.hpp:77] Creating layer conv2
I0522 23:53:40.483415  3818 net.cpp:106] Creating Layer conv2
I0522 23:53:40.483425  3818 net.cpp:454] conv2 <- pool1
I0522 23:53:40.483440  3818 net.cpp:411] conv2 -> conv2
I0522 23:53:40.485348  3818 net.cpp:150] Setting up conv2
I0522 23:53:40.485370  3818 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 23:53:40.485383  3818 net.cpp:165] Memory required for data: 36613280
I0522 23:53:40.485400  3818 layer_factory.hpp:77] Creating layer relu2
I0522 23:53:40.485414  3818 net.cpp:106] Creating Layer relu2
I0522 23:53:40.485424  3818 net.cpp:454] relu2 <- conv2
I0522 23:53:40.485436  3818 net.cpp:397] relu2 -> conv2 (in-place)
I0522 23:53:40.485767  3818 net.cpp:150] Setting up relu2
I0522 23:53:40.485781  3818 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 23:53:40.485791  3818 net.cpp:165] Memory required for data: 44562080
I0522 23:53:40.485801  3818 layer_factory.hpp:77] Creating layer pool2
I0522 23:53:40.485815  3818 net.cpp:106] Creating Layer pool2
I0522 23:53:40.485824  3818 net.cpp:454] pool2 <- conv2
I0522 23:53:40.485837  3818 net.cpp:411] pool2 -> pool2
I0522 23:53:40.485908  3818 net.cpp:150] Setting up pool2
I0522 23:53:40.485921  3818 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 23:53:40.485931  3818 net.cpp:165] Memory required for data: 48536480
I0522 23:53:40.485942  3818 layer_factory.hpp:77] Creating layer conv3
I0522 23:53:40.485960  3818 net.cpp:106] Creating Layer conv3
I0522 23:53:40.485970  3818 net.cpp:454] conv3 <- pool2
I0522 23:53:40.485985  3818 net.cpp:411] conv3 -> conv3
I0522 23:53:40.487960  3818 net.cpp:150] Setting up conv3
I0522 23:53:40.487983  3818 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 23:53:40.487995  3818 net.cpp:165] Memory required for data: 52873120
I0522 23:53:40.488029  3818 layer_factory.hpp:77] Creating layer relu3
I0522 23:53:40.488042  3818 net.cpp:106] Creating Layer relu3
I0522 23:53:40.488052  3818 net.cpp:454] relu3 <- conv3
I0522 23:53:40.488065  3818 net.cpp:397] relu3 -> conv3 (in-place)
I0522 23:53:40.488535  3818 net.cpp:150] Setting up relu3
I0522 23:53:40.488551  3818 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 23:53:40.488562  3818 net.cpp:165] Memory required for data: 57209760
I0522 23:53:40.488572  3818 layer_factory.hpp:77] Creating layer pool3
I0522 23:53:40.488585  3818 net.cpp:106] Creating Layer pool3
I0522 23:53:40.488595  3818 net.cpp:454] pool3 <- conv3
I0522 23:53:40.488607  3818 net.cpp:411] pool3 -> pool3
I0522 23:53:40.488678  3818 net.cpp:150] Setting up pool3
I0522 23:53:40.488692  3818 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 23:53:40.488701  3818 net.cpp:165] Memory required for data: 59378080
I0522 23:53:40.488710  3818 layer_factory.hpp:77] Creating layer conv4
I0522 23:53:40.488729  3818 net.cpp:106] Creating Layer conv4
I0522 23:53:40.488739  3818 net.cpp:454] conv4 <- pool3
I0522 23:53:40.488754  3818 net.cpp:411] conv4 -> conv4
I0522 23:53:40.490803  3818 net.cpp:150] Setting up conv4
I0522 23:53:40.490824  3818 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 23:53:40.490836  3818 net.cpp:165] Memory required for data: 60829600
I0522 23:53:40.490852  3818 layer_factory.hpp:77] Creating layer relu4
I0522 23:53:40.490865  3818 net.cpp:106] Creating Layer relu4
I0522 23:53:40.490875  3818 net.cpp:454] relu4 <- conv4
I0522 23:53:40.490888  3818 net.cpp:397] relu4 -> conv4 (in-place)
I0522 23:53:40.491365  3818 net.cpp:150] Setting up relu4
I0522 23:53:40.491382  3818 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 23:53:40.491392  3818 net.cpp:165] Memory required for data: 62281120
I0522 23:53:40.491402  3818 layer_factory.hpp:77] Creating layer pool4
I0522 23:53:40.491416  3818 net.cpp:106] Creating Layer pool4
I0522 23:53:40.491426  3818 net.cpp:454] pool4 <- conv4
I0522 23:53:40.491439  3818 net.cpp:411] pool4 -> pool4
I0522 23:53:40.491509  3818 net.cpp:150] Setting up pool4
I0522 23:53:40.491523  3818 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 23:53:40.491533  3818 net.cpp:165] Memory required for data: 63006880
I0522 23:53:40.491541  3818 layer_factory.hpp:77] Creating layer ip1
I0522 23:53:40.491557  3818 net.cpp:106] Creating Layer ip1
I0522 23:53:40.491569  3818 net.cpp:454] ip1 <- pool4
I0522 23:53:40.491581  3818 net.cpp:411] ip1 -> ip1
I0522 23:53:40.507030  3818 net.cpp:150] Setting up ip1
I0522 23:53:40.507058  3818 net.cpp:157] Top shape: 40 196 (7840)
I0522 23:53:40.507069  3818 net.cpp:165] Memory required for data: 63038240
I0522 23:53:40.507091  3818 layer_factory.hpp:77] Creating layer relu5
I0522 23:53:40.507107  3818 net.cpp:106] Creating Layer relu5
I0522 23:53:40.507117  3818 net.cpp:454] relu5 <- ip1
I0522 23:53:40.507130  3818 net.cpp:397] relu5 -> ip1 (in-place)
I0522 23:53:40.507477  3818 net.cpp:150] Setting up relu5
I0522 23:53:40.507490  3818 net.cpp:157] Top shape: 40 196 (7840)
I0522 23:53:40.507500  3818 net.cpp:165] Memory required for data: 63069600
I0522 23:53:40.507510  3818 layer_factory.hpp:77] Creating layer drop1
I0522 23:53:40.507529  3818 net.cpp:106] Creating Layer drop1
I0522 23:53:40.507539  3818 net.cpp:454] drop1 <- ip1
I0522 23:53:40.507552  3818 net.cpp:397] drop1 -> ip1 (in-place)
I0522 23:53:40.507598  3818 net.cpp:150] Setting up drop1
I0522 23:53:40.507611  3818 net.cpp:157] Top shape: 40 196 (7840)
I0522 23:53:40.507622  3818 net.cpp:165] Memory required for data: 63100960
I0522 23:53:40.507632  3818 layer_factory.hpp:77] Creating layer ip2
I0522 23:53:40.507645  3818 net.cpp:106] Creating Layer ip2
I0522 23:53:40.507655  3818 net.cpp:454] ip2 <- ip1
I0522 23:53:40.507669  3818 net.cpp:411] ip2 -> ip2
I0522 23:53:40.508147  3818 net.cpp:150] Setting up ip2
I0522 23:53:40.508162  3818 net.cpp:157] Top shape: 40 98 (3920)
I0522 23:53:40.508172  3818 net.cpp:165] Memory required for data: 63116640
I0522 23:53:40.508186  3818 layer_factory.hpp:77] Creating layer relu6
I0522 23:53:40.508213  3818 net.cpp:106] Creating Layer relu6
I0522 23:53:40.508221  3818 net.cpp:454] relu6 <- ip2
I0522 23:53:40.508234  3818 net.cpp:397] relu6 -> ip2 (in-place)
I0522 23:53:40.508772  3818 net.cpp:150] Setting up relu6
I0522 23:53:40.508795  3818 net.cpp:157] Top shape: 40 98 (3920)
I0522 23:53:40.508805  3818 net.cpp:165] Memory required for data: 63132320
I0522 23:53:40.508816  3818 layer_factory.hpp:77] Creating layer drop2
I0522 23:53:40.508829  3818 net.cpp:106] Creating Layer drop2
I0522 23:53:40.508839  3818 net.cpp:454] drop2 <- ip2
I0522 23:53:40.508852  3818 net.cpp:397] drop2 -> ip2 (in-place)
I0522 23:53:40.508896  3818 net.cpp:150] Setting up drop2
I0522 23:53:40.508909  3818 net.cpp:157] Top shape: 40 98 (3920)
I0522 23:53:40.508919  3818 net.cpp:165] Memory required for data: 63148000
I0522 23:53:40.508929  3818 layer_factory.hpp:77] Creating layer ip3
I0522 23:53:40.508944  3818 net.cpp:106] Creating Layer ip3
I0522 23:53:40.508954  3818 net.cpp:454] ip3 <- ip2
I0522 23:53:40.508967  3818 net.cpp:411] ip3 -> ip3
I0522 23:53:40.509188  3818 net.cpp:150] Setting up ip3
I0522 23:53:40.509202  3818 net.cpp:157] Top shape: 40 11 (440)
I0522 23:53:40.509212  3818 net.cpp:165] Memory required for data: 63149760
I0522 23:53:40.509227  3818 layer_factory.hpp:77] Creating layer drop3
I0522 23:53:40.509239  3818 net.cpp:106] Creating Layer drop3
I0522 23:53:40.509249  3818 net.cpp:454] drop3 <- ip3
I0522 23:53:40.509261  3818 net.cpp:397] drop3 -> ip3 (in-place)
I0522 23:53:40.509302  3818 net.cpp:150] Setting up drop3
I0522 23:53:40.509315  3818 net.cpp:157] Top shape: 40 11 (440)
I0522 23:53:40.509325  3818 net.cpp:165] Memory required for data: 63151520
I0522 23:53:40.509335  3818 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 23:53:40.509348  3818 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 23:53:40.509358  3818 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 23:53:40.509371  3818 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 23:53:40.509387  3818 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 23:53:40.509460  3818 net.cpp:150] Setting up ip3_drop3_0_split
I0522 23:53:40.509474  3818 net.cpp:157] Top shape: 40 11 (440)
I0522 23:53:40.509486  3818 net.cpp:157] Top shape: 40 11 (440)
I0522 23:53:40.509496  3818 net.cpp:165] Memory required for data: 63155040
I0522 23:53:40.509506  3818 layer_factory.hpp:77] Creating layer accuracy
I0522 23:53:40.509529  3818 net.cpp:106] Creating Layer accuracy
I0522 23:53:40.509539  3818 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 23:53:40.509551  3818 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 23:53:40.509564  3818 net.cpp:411] accuracy -> accuracy
I0522 23:53:40.509587  3818 net.cpp:150] Setting up accuracy
I0522 23:53:40.509599  3818 net.cpp:157] Top shape: (1)
I0522 23:53:40.509609  3818 net.cpp:165] Memory required for data: 63155044
I0522 23:53:40.509619  3818 layer_factory.hpp:77] Creating layer loss
I0522 23:53:40.509632  3818 net.cpp:106] Creating Layer loss
I0522 23:53:40.509642  3818 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 23:53:40.509654  3818 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 23:53:40.509666  3818 net.cpp:411] loss -> loss
I0522 23:53:40.509683  3818 layer_factory.hpp:77] Creating layer loss
I0522 23:53:40.510167  3818 net.cpp:150] Setting up loss
I0522 23:53:40.510181  3818 net.cpp:157] Top shape: (1)
I0522 23:53:40.510191  3818 net.cpp:160]     with loss weight 1
I0522 23:53:40.510210  3818 net.cpp:165] Memory required for data: 63155048
I0522 23:53:40.510221  3818 net.cpp:226] loss needs backward computation.
I0522 23:53:40.510231  3818 net.cpp:228] accuracy does not need backward computation.
I0522 23:53:40.510242  3818 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 23:53:40.510252  3818 net.cpp:226] drop3 needs backward computation.
I0522 23:53:40.510263  3818 net.cpp:226] ip3 needs backward computation.
I0522 23:53:40.510274  3818 net.cpp:226] drop2 needs backward computation.
I0522 23:53:40.510283  3818 net.cpp:226] relu6 needs backward computation.
I0522 23:53:40.510301  3818 net.cpp:226] ip2 needs backward computation.
I0522 23:53:40.510311  3818 net.cpp:226] drop1 needs backward computation.
I0522 23:53:40.510321  3818 net.cpp:226] relu5 needs backward computation.
I0522 23:53:40.510330  3818 net.cpp:226] ip1 needs backward computation.
I0522 23:53:40.510340  3818 net.cpp:226] pool4 needs backward computation.
I0522 23:53:40.510350  3818 net.cpp:226] relu4 needs backward computation.
I0522 23:53:40.510361  3818 net.cpp:226] conv4 needs backward computation.
I0522 23:53:40.510372  3818 net.cpp:226] pool3 needs backward computation.
I0522 23:53:40.510383  3818 net.cpp:226] relu3 needs backward computation.
I0522 23:53:40.510393  3818 net.cpp:226] conv3 needs backward computation.
I0522 23:53:40.510403  3818 net.cpp:226] pool2 needs backward computation.
I0522 23:53:40.510413  3818 net.cpp:226] relu2 needs backward computation.
I0522 23:53:40.510423  3818 net.cpp:226] conv2 needs backward computation.
I0522 23:53:40.510433  3818 net.cpp:226] pool1 needs backward computation.
I0522 23:53:40.510444  3818 net.cpp:226] relu1 needs backward computation.
I0522 23:53:40.510454  3818 net.cpp:226] conv1 needs backward computation.
I0522 23:53:40.510465  3818 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 23:53:40.510478  3818 net.cpp:228] data_hdf5 does not need backward computation.
I0522 23:53:40.510486  3818 net.cpp:270] This network produces output accuracy
I0522 23:53:40.510495  3818 net.cpp:270] This network produces output loss
I0522 23:53:40.510524  3818 net.cpp:283] Network initialization done.
I0522 23:53:40.510658  3818 solver.cpp:60] Solver scaffolding done.
I0522 23:53:40.511793  3818 caffe.cpp:212] Starting Optimization
I0522 23:53:40.511811  3818 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 23:53:40.511826  3818 solver.cpp:289] Learning Rate Policy: fixed
I0522 23:53:40.513039  3818 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 23:54:29.967797  3818 solver.cpp:409]     Test net output #0: accuracy = 0.0629466
I0522 23:54:29.967958  3818 solver.cpp:409]     Test net output #1: loss = 2.39909 (* 1 = 2.39909 loss)
I0522 23:54:29.990532  3818 solver.cpp:237] Iteration 0, loss = 2.39697
I0522 23:54:29.990569  3818 solver.cpp:253]     Train net output #0: loss = 2.39697 (* 1 = 2.39697 loss)
I0522 23:54:29.990588  3818 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0522 23:54:39.841856  3818 solver.cpp:237] Iteration 375, loss = 2.15216
I0522 23:54:39.841893  3818 solver.cpp:253]     Train net output #0: loss = 2.15216 (* 1 = 2.15216 loss)
I0522 23:54:39.841910  3818 sgd_solver.cpp:106] Iteration 375, lr = 0.0045
I0522 23:54:49.693646  3818 solver.cpp:237] Iteration 750, loss = 1.89844
I0522 23:54:49.693687  3818 solver.cpp:253]     Train net output #0: loss = 1.89844 (* 1 = 1.89844 loss)
I0522 23:54:49.693706  3818 sgd_solver.cpp:106] Iteration 750, lr = 0.0045
I0522 23:54:59.542444  3818 solver.cpp:237] Iteration 1125, loss = 1.85894
I0522 23:54:59.542480  3818 solver.cpp:253]     Train net output #0: loss = 1.85894 (* 1 = 1.85894 loss)
I0522 23:54:59.542496  3818 sgd_solver.cpp:106] Iteration 1125, lr = 0.0045
I0522 23:55:09.394531  3818 solver.cpp:237] Iteration 1500, loss = 1.64685
I0522 23:55:09.394691  3818 solver.cpp:253]     Train net output #0: loss = 1.64685 (* 1 = 1.64685 loss)
I0522 23:55:09.394706  3818 sgd_solver.cpp:106] Iteration 1500, lr = 0.0045
I0522 23:55:19.242467  3818 solver.cpp:237] Iteration 1875, loss = 1.65187
I0522 23:55:19.242502  3818 solver.cpp:253]     Train net output #0: loss = 1.65187 (* 1 = 1.65187 loss)
I0522 23:55:19.242521  3818 sgd_solver.cpp:106] Iteration 1875, lr = 0.0045
I0522 23:55:29.098275  3818 solver.cpp:237] Iteration 2250, loss = 1.45793
I0522 23:55:29.098310  3818 solver.cpp:253]     Train net output #0: loss = 1.45793 (* 1 = 1.45793 loss)
I0522 23:55:29.098326  3818 sgd_solver.cpp:106] Iteration 2250, lr = 0.0045
I0522 23:56:01.104295  3818 solver.cpp:237] Iteration 2625, loss = 1.36914
I0522 23:56:01.104459  3818 solver.cpp:253]     Train net output #0: loss = 1.36914 (* 1 = 1.36914 loss)
I0522 23:56:01.104473  3818 sgd_solver.cpp:106] Iteration 2625, lr = 0.0045
I0522 23:56:10.960999  3818 solver.cpp:237] Iteration 3000, loss = 1.18775
I0522 23:56:10.961035  3818 solver.cpp:253]     Train net output #0: loss = 1.18775 (* 1 = 1.18775 loss)
I0522 23:56:10.961051  3818 sgd_solver.cpp:106] Iteration 3000, lr = 0.0045
I0522 23:56:20.820199  3818 solver.cpp:237] Iteration 3375, loss = 1.48137
I0522 23:56:20.820235  3818 solver.cpp:253]     Train net output #0: loss = 1.48137 (* 1 = 1.48137 loss)
I0522 23:56:20.820251  3818 sgd_solver.cpp:106] Iteration 3375, lr = 0.0045
I0522 23:56:30.646724  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_3750.caffemodel
I0522 23:56:30.706703  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_3750.solverstate
I0522 23:56:30.740118  3818 solver.cpp:237] Iteration 3750, loss = 1.45076
I0522 23:56:30.740164  3818 solver.cpp:253]     Train net output #0: loss = 1.45076 (* 1 = 1.45076 loss)
I0522 23:56:30.740182  3818 sgd_solver.cpp:106] Iteration 3750, lr = 0.0045
I0522 23:56:40.593209  3818 solver.cpp:237] Iteration 4125, loss = 1.41292
I0522 23:56:40.593350  3818 solver.cpp:253]     Train net output #0: loss = 1.41292 (* 1 = 1.41292 loss)
I0522 23:56:40.593364  3818 sgd_solver.cpp:106] Iteration 4125, lr = 0.0045
I0522 23:56:50.444846  3818 solver.cpp:237] Iteration 4500, loss = 1.54967
I0522 23:56:50.444892  3818 solver.cpp:253]     Train net output #0: loss = 1.54967 (* 1 = 1.54967 loss)
I0522 23:56:50.444907  3818 sgd_solver.cpp:106] Iteration 4500, lr = 0.0045
I0522 23:57:00.296100  3818 solver.cpp:237] Iteration 4875, loss = 1.24624
I0522 23:57:00.296136  3818 solver.cpp:253]     Train net output #0: loss = 1.24624 (* 1 = 1.24624 loss)
I0522 23:57:00.296152  3818 sgd_solver.cpp:106] Iteration 4875, lr = 0.0045
I0522 23:57:32.323604  3818 solver.cpp:237] Iteration 5250, loss = 1.10846
I0522 23:57:32.323760  3818 solver.cpp:253]     Train net output #0: loss = 1.10846 (* 1 = 1.10846 loss)
I0522 23:57:32.323776  3818 sgd_solver.cpp:106] Iteration 5250, lr = 0.0045
I0522 23:57:42.183468  3818 solver.cpp:237] Iteration 5625, loss = 1.41928
I0522 23:57:42.183514  3818 solver.cpp:253]     Train net output #0: loss = 1.41928 (* 1 = 1.41928 loss)
I0522 23:57:42.183531  3818 sgd_solver.cpp:106] Iteration 5625, lr = 0.0045
I0522 23:57:52.040568  3818 solver.cpp:237] Iteration 6000, loss = 1.8344
I0522 23:57:52.040606  3818 solver.cpp:253]     Train net output #0: loss = 1.8344 (* 1 = 1.8344 loss)
I0522 23:57:52.040618  3818 sgd_solver.cpp:106] Iteration 6000, lr = 0.0045
I0522 23:58:01.892570  3818 solver.cpp:237] Iteration 6375, loss = 1.32714
I0522 23:58:01.892611  3818 solver.cpp:253]     Train net output #0: loss = 1.32714 (* 1 = 1.32714 loss)
I0522 23:58:01.892634  3818 sgd_solver.cpp:106] Iteration 6375, lr = 0.0045
I0522 23:58:11.748636  3818 solver.cpp:237] Iteration 6750, loss = 1.34866
I0522 23:58:11.748786  3818 solver.cpp:253]     Train net output #0: loss = 1.34866 (* 1 = 1.34866 loss)
I0522 23:58:11.748800  3818 sgd_solver.cpp:106] Iteration 6750, lr = 0.0045
I0522 23:58:21.602015  3818 solver.cpp:237] Iteration 7125, loss = 1.2775
I0522 23:58:21.602051  3818 solver.cpp:253]     Train net output #0: loss = 1.2775 (* 1 = 1.2775 loss)
I0522 23:58:21.602068  3818 sgd_solver.cpp:106] Iteration 7125, lr = 0.0045
I0522 23:58:31.430778  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_7500.caffemodel
I0522 23:58:31.487823  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_7500.solverstate
I0522 23:58:31.513471  3818 solver.cpp:341] Iteration 7500, Testing net (#0)
I0522 23:59:20.029338  3818 solver.cpp:409]     Test net output #0: accuracy = 0.82806
I0522 23:59:20.029492  3818 solver.cpp:409]     Test net output #1: loss = 0.558712 (* 1 = 0.558712 loss)
I0522 23:59:42.226493  3818 solver.cpp:237] Iteration 7500, loss = 1.19596
I0522 23:59:42.226547  3818 solver.cpp:253]     Train net output #0: loss = 1.19596 (* 1 = 1.19596 loss)
I0522 23:59:42.226563  3818 sgd_solver.cpp:106] Iteration 7500, lr = 0.0045
I0522 23:59:52.134991  3818 solver.cpp:237] Iteration 7875, loss = 1.35468
I0522 23:59:52.135143  3818 solver.cpp:253]     Train net output #0: loss = 1.35468 (* 1 = 1.35468 loss)
I0522 23:59:52.135157  3818 sgd_solver.cpp:106] Iteration 7875, lr = 0.0045
I0523 00:00:02.053969  3818 solver.cpp:237] Iteration 8250, loss = 1.54201
I0523 00:00:02.054005  3818 solver.cpp:253]     Train net output #0: loss = 1.54201 (* 1 = 1.54201 loss)
I0523 00:00:02.054023  3818 sgd_solver.cpp:106] Iteration 8250, lr = 0.0045
I0523 00:00:11.976830  3818 solver.cpp:237] Iteration 8625, loss = 1.3319
I0523 00:00:11.976877  3818 solver.cpp:253]     Train net output #0: loss = 1.3319 (* 1 = 1.3319 loss)
I0523 00:00:11.976891  3818 sgd_solver.cpp:106] Iteration 8625, lr = 0.0045
I0523 00:00:21.889960  3818 solver.cpp:237] Iteration 9000, loss = 1.38333
I0523 00:00:21.889994  3818 solver.cpp:253]     Train net output #0: loss = 1.38333 (* 1 = 1.38333 loss)
I0523 00:00:21.890012  3818 sgd_solver.cpp:106] Iteration 9000, lr = 0.0045
I0523 00:00:31.802644  3818 solver.cpp:237] Iteration 9375, loss = 1.32394
I0523 00:00:31.802794  3818 solver.cpp:253]     Train net output #0: loss = 1.32394 (* 1 = 1.32394 loss)
I0523 00:00:31.802809  3818 sgd_solver.cpp:106] Iteration 9375, lr = 0.0045
I0523 00:00:41.724480  3818 solver.cpp:237] Iteration 9750, loss = 1.04994
I0523 00:00:41.724515  3818 solver.cpp:253]     Train net output #0: loss = 1.04994 (* 1 = 1.04994 loss)
I0523 00:00:41.724534  3818 sgd_solver.cpp:106] Iteration 9750, lr = 0.0045
I0523 00:01:13.809298  3818 solver.cpp:237] Iteration 10125, loss = 1.49635
I0523 00:01:13.809459  3818 solver.cpp:253]     Train net output #0: loss = 1.49635 (* 1 = 1.49635 loss)
I0523 00:01:13.809475  3818 sgd_solver.cpp:106] Iteration 10125, lr = 0.0045
I0523 00:01:23.731770  3818 solver.cpp:237] Iteration 10500, loss = 1.42862
I0523 00:01:23.731812  3818 solver.cpp:253]     Train net output #0: loss = 1.42862 (* 1 = 1.42862 loss)
I0523 00:01:23.731833  3818 sgd_solver.cpp:106] Iteration 10500, lr = 0.0045
I0523 00:01:33.649127  3818 solver.cpp:237] Iteration 10875, loss = 1.56317
I0523 00:01:33.649163  3818 solver.cpp:253]     Train net output #0: loss = 1.56317 (* 1 = 1.56317 loss)
I0523 00:01:33.649179  3818 sgd_solver.cpp:106] Iteration 10875, lr = 0.0045
I0523 00:01:43.538808  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_11250.caffemodel
I0523 00:01:43.597376  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_11250.solverstate
I0523 00:01:43.632621  3818 solver.cpp:237] Iteration 11250, loss = 1.37856
I0523 00:01:43.632671  3818 solver.cpp:253]     Train net output #0: loss = 1.37856 (* 1 = 1.37856 loss)
I0523 00:01:43.632688  3818 sgd_solver.cpp:106] Iteration 11250, lr = 0.0045
I0523 00:01:53.554749  3818 solver.cpp:237] Iteration 11625, loss = 1.0471
I0523 00:01:53.554916  3818 solver.cpp:253]     Train net output #0: loss = 1.0471 (* 1 = 1.0471 loss)
I0523 00:01:53.554931  3818 sgd_solver.cpp:106] Iteration 11625, lr = 0.0045
I0523 00:02:03.479039  3818 solver.cpp:237] Iteration 12000, loss = 1.12998
I0523 00:02:03.479074  3818 solver.cpp:253]     Train net output #0: loss = 1.12998 (* 1 = 1.12998 loss)
I0523 00:02:03.479089  3818 sgd_solver.cpp:106] Iteration 12000, lr = 0.0045
I0523 00:02:13.397326  3818 solver.cpp:237] Iteration 12375, loss = 1.22518
I0523 00:02:13.397374  3818 solver.cpp:253]     Train net output #0: loss = 1.22518 (* 1 = 1.22518 loss)
I0523 00:02:13.397392  3818 sgd_solver.cpp:106] Iteration 12375, lr = 0.0045
I0523 00:02:45.491058  3818 solver.cpp:237] Iteration 12750, loss = 1.60044
I0523 00:02:45.491224  3818 solver.cpp:253]     Train net output #0: loss = 1.60044 (* 1 = 1.60044 loss)
I0523 00:02:45.491238  3818 sgd_solver.cpp:106] Iteration 12750, lr = 0.0045
I0523 00:02:55.410176  3818 solver.cpp:237] Iteration 13125, loss = 1.40818
I0523 00:02:55.410210  3818 solver.cpp:253]     Train net output #0: loss = 1.40818 (* 1 = 1.40818 loss)
I0523 00:02:55.410228  3818 sgd_solver.cpp:106] Iteration 13125, lr = 0.0045
I0523 00:03:05.324431  3818 solver.cpp:237] Iteration 13500, loss = 1.39687
I0523 00:03:05.324470  3818 solver.cpp:253]     Train net output #0: loss = 1.39687 (* 1 = 1.39687 loss)
I0523 00:03:05.324491  3818 sgd_solver.cpp:106] Iteration 13500, lr = 0.0045
I0523 00:03:15.247973  3818 solver.cpp:237] Iteration 13875, loss = 1.40613
I0523 00:03:15.248008  3818 solver.cpp:253]     Train net output #0: loss = 1.40613 (* 1 = 1.40613 loss)
I0523 00:03:15.248023  3818 sgd_solver.cpp:106] Iteration 13875, lr = 0.0045
I0523 00:03:25.163198  3818 solver.cpp:237] Iteration 14250, loss = 1.02261
I0523 00:03:25.163338  3818 solver.cpp:253]     Train net output #0: loss = 1.02261 (* 1 = 1.02261 loss)
I0523 00:03:25.163352  3818 sgd_solver.cpp:106] Iteration 14250, lr = 0.0045
I0523 00:03:35.084795  3818 solver.cpp:237] Iteration 14625, loss = 1.24654
I0523 00:03:35.084831  3818 solver.cpp:253]     Train net output #0: loss = 1.24654 (* 1 = 1.24654 loss)
I0523 00:03:35.084849  3818 sgd_solver.cpp:106] Iteration 14625, lr = 0.0045
I0523 00:03:44.980259  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_15000.caffemodel
I0523 00:03:45.039338  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_15000.solverstate
I0523 00:03:45.067473  3818 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 00:04:54.501174  3818 solver.cpp:409]     Test net output #0: accuracy = 0.857365
I0523 00:04:54.501335  3818 solver.cpp:409]     Test net output #1: loss = 0.50536 (* 1 = 0.50536 loss)
I0523 00:05:16.698766  3818 solver.cpp:237] Iteration 15000, loss = 1.18397
I0523 00:05:16.698818  3818 solver.cpp:253]     Train net output #0: loss = 1.18397 (* 1 = 1.18397 loss)
I0523 00:05:16.698835  3818 sgd_solver.cpp:106] Iteration 15000, lr = 0.0045
I0523 00:05:26.512816  3818 solver.cpp:237] Iteration 15375, loss = 1.32806
I0523 00:05:26.512972  3818 solver.cpp:253]     Train net output #0: loss = 1.32806 (* 1 = 1.32806 loss)
I0523 00:05:26.512987  3818 sgd_solver.cpp:106] Iteration 15375, lr = 0.0045
I0523 00:05:36.329877  3818 solver.cpp:237] Iteration 15750, loss = 1.4268
I0523 00:05:36.329921  3818 solver.cpp:253]     Train net output #0: loss = 1.4268 (* 1 = 1.4268 loss)
I0523 00:05:36.329941  3818 sgd_solver.cpp:106] Iteration 15750, lr = 0.0045
I0523 00:05:46.155077  3818 solver.cpp:237] Iteration 16125, loss = 1.27872
I0523 00:05:46.155113  3818 solver.cpp:253]     Train net output #0: loss = 1.27872 (* 1 = 1.27872 loss)
I0523 00:05:46.155128  3818 sgd_solver.cpp:106] Iteration 16125, lr = 0.0045
I0523 00:05:55.981547  3818 solver.cpp:237] Iteration 16500, loss = 1.46799
I0523 00:05:55.981585  3818 solver.cpp:253]     Train net output #0: loss = 1.46799 (* 1 = 1.46799 loss)
I0523 00:05:55.981600  3818 sgd_solver.cpp:106] Iteration 16500, lr = 0.0045
I0523 00:06:05.811564  3818 solver.cpp:237] Iteration 16875, loss = 1.26129
I0523 00:06:05.811720  3818 solver.cpp:253]     Train net output #0: loss = 1.26129 (* 1 = 1.26129 loss)
I0523 00:06:05.811735  3818 sgd_solver.cpp:106] Iteration 16875, lr = 0.0045
I0523 00:06:15.636404  3818 solver.cpp:237] Iteration 17250, loss = 1.14486
I0523 00:06:15.636440  3818 solver.cpp:253]     Train net output #0: loss = 1.14486 (* 1 = 1.14486 loss)
I0523 00:06:15.636454  3818 sgd_solver.cpp:106] Iteration 17250, lr = 0.0045
I0523 00:06:47.655169  3818 solver.cpp:237] Iteration 17625, loss = 1.00917
I0523 00:06:47.655333  3818 solver.cpp:253]     Train net output #0: loss = 1.00917 (* 1 = 1.00917 loss)
I0523 00:06:47.655347  3818 sgd_solver.cpp:106] Iteration 17625, lr = 0.0045
I0523 00:06:57.479403  3818 solver.cpp:237] Iteration 18000, loss = 1.06988
I0523 00:06:57.479439  3818 solver.cpp:253]     Train net output #0: loss = 1.06988 (* 1 = 1.06988 loss)
I0523 00:06:57.479452  3818 sgd_solver.cpp:106] Iteration 18000, lr = 0.0045
I0523 00:07:07.299952  3818 solver.cpp:237] Iteration 18375, loss = 1.35458
I0523 00:07:07.299988  3818 solver.cpp:253]     Train net output #0: loss = 1.35458 (* 1 = 1.35458 loss)
I0523 00:07:07.300001  3818 sgd_solver.cpp:106] Iteration 18375, lr = 0.0045
I0523 00:07:17.096624  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_18750.caffemodel
I0523 00:07:17.154808  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_18750.solverstate
I0523 00:07:17.191802  3818 solver.cpp:237] Iteration 18750, loss = 1.05981
I0523 00:07:17.191853  3818 solver.cpp:253]     Train net output #0: loss = 1.05981 (* 1 = 1.05981 loss)
I0523 00:07:17.191867  3818 sgd_solver.cpp:106] Iteration 18750, lr = 0.0045
I0523 00:07:27.012419  3818 solver.cpp:237] Iteration 19125, loss = 1.30836
I0523 00:07:27.012565  3818 solver.cpp:253]     Train net output #0: loss = 1.30836 (* 1 = 1.30836 loss)
I0523 00:07:27.012579  3818 sgd_solver.cpp:106] Iteration 19125, lr = 0.0045
I0523 00:07:36.835081  3818 solver.cpp:237] Iteration 19500, loss = 1.15191
I0523 00:07:36.835132  3818 solver.cpp:253]     Train net output #0: loss = 1.15191 (* 1 = 1.15191 loss)
I0523 00:07:36.835149  3818 sgd_solver.cpp:106] Iteration 19500, lr = 0.0045
I0523 00:07:46.656610  3818 solver.cpp:237] Iteration 19875, loss = 1.04656
I0523 00:07:46.656646  3818 solver.cpp:253]     Train net output #0: loss = 1.04656 (* 1 = 1.04656 loss)
I0523 00:07:46.656662  3818 sgd_solver.cpp:106] Iteration 19875, lr = 0.0045
I0523 00:08:18.632347  3818 solver.cpp:237] Iteration 20250, loss = 1.06385
I0523 00:08:18.632524  3818 solver.cpp:253]     Train net output #0: loss = 1.06385 (* 1 = 1.06385 loss)
I0523 00:08:18.632539  3818 sgd_solver.cpp:106] Iteration 20250, lr = 0.0045
I0523 00:08:28.459848  3818 solver.cpp:237] Iteration 20625, loss = 1.2161
I0523 00:08:28.459898  3818 solver.cpp:253]     Train net output #0: loss = 1.2161 (* 1 = 1.2161 loss)
I0523 00:08:28.459913  3818 sgd_solver.cpp:106] Iteration 20625, lr = 0.0045
I0523 00:08:38.289147  3818 solver.cpp:237] Iteration 21000, loss = 1.16931
I0523 00:08:38.289182  3818 solver.cpp:253]     Train net output #0: loss = 1.16931 (* 1 = 1.16931 loss)
I0523 00:08:38.289198  3818 sgd_solver.cpp:106] Iteration 21000, lr = 0.0045
I0523 00:08:48.118902  3818 solver.cpp:237] Iteration 21375, loss = 1.21821
I0523 00:08:48.118938  3818 solver.cpp:253]     Train net output #0: loss = 1.21821 (* 1 = 1.21821 loss)
I0523 00:08:48.118954  3818 sgd_solver.cpp:106] Iteration 21375, lr = 0.0045
I0523 00:08:57.944674  3818 solver.cpp:237] Iteration 21750, loss = 0.778291
I0523 00:08:57.944834  3818 solver.cpp:253]     Train net output #0: loss = 0.778291 (* 1 = 0.778291 loss)
I0523 00:08:57.944849  3818 sgd_solver.cpp:106] Iteration 21750, lr = 0.0045
I0523 00:09:07.768159  3818 solver.cpp:237] Iteration 22125, loss = 0.908044
I0523 00:09:07.768196  3818 solver.cpp:253]     Train net output #0: loss = 0.908044 (* 1 = 0.908044 loss)
I0523 00:09:07.768213  3818 sgd_solver.cpp:106] Iteration 22125, lr = 0.0045
I0523 00:09:17.567567  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_22500.caffemodel
I0523 00:09:17.623996  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_22500.solverstate
I0523 00:09:17.650019  3818 solver.cpp:341] Iteration 22500, Testing net (#0)
I0523 00:10:05.869428  3818 solver.cpp:409]     Test net output #0: accuracy = 0.869381
I0523 00:10:05.869592  3818 solver.cpp:409]     Test net output #1: loss = 0.423905 (* 1 = 0.423905 loss)
I0523 00:10:28.015979  3818 solver.cpp:237] Iteration 22500, loss = 0.990054
I0523 00:10:28.016031  3818 solver.cpp:253]     Train net output #0: loss = 0.990054 (* 1 = 0.990054 loss)
I0523 00:10:28.016047  3818 sgd_solver.cpp:106] Iteration 22500, lr = 0.0045
I0523 00:10:37.763074  3818 solver.cpp:237] Iteration 22875, loss = 1.35027
I0523 00:10:37.763248  3818 solver.cpp:253]     Train net output #0: loss = 1.35027 (* 1 = 1.35027 loss)
I0523 00:10:37.763263  3818 sgd_solver.cpp:106] Iteration 22875, lr = 0.0045
I0523 00:10:47.517345  3818 solver.cpp:237] Iteration 23250, loss = 1.32472
I0523 00:10:47.517380  3818 solver.cpp:253]     Train net output #0: loss = 1.32472 (* 1 = 1.32472 loss)
I0523 00:10:47.517396  3818 sgd_solver.cpp:106] Iteration 23250, lr = 0.0045
I0523 00:10:57.281419  3818 solver.cpp:237] Iteration 23625, loss = 1.24433
I0523 00:10:57.281461  3818 solver.cpp:253]     Train net output #0: loss = 1.24433 (* 1 = 1.24433 loss)
I0523 00:10:57.281479  3818 sgd_solver.cpp:106] Iteration 23625, lr = 0.0045
I0523 00:11:07.036152  3818 solver.cpp:237] Iteration 24000, loss = 1.3996
I0523 00:11:07.036187  3818 solver.cpp:253]     Train net output #0: loss = 1.3996 (* 1 = 1.3996 loss)
I0523 00:11:07.036204  3818 sgd_solver.cpp:106] Iteration 24000, lr = 0.0045
I0523 00:11:16.790181  3818 solver.cpp:237] Iteration 24375, loss = 1.23757
I0523 00:11:16.790321  3818 solver.cpp:253]     Train net output #0: loss = 1.23757 (* 1 = 1.23757 loss)
I0523 00:11:16.790336  3818 sgd_solver.cpp:106] Iteration 24375, lr = 0.0045
I0523 00:11:26.542233  3818 solver.cpp:237] Iteration 24750, loss = 0.822662
I0523 00:11:26.542279  3818 solver.cpp:253]     Train net output #0: loss = 0.822662 (* 1 = 0.822662 loss)
I0523 00:11:26.542294  3818 sgd_solver.cpp:106] Iteration 24750, lr = 0.0045
I0523 00:11:58.486575  3818 solver.cpp:237] Iteration 25125, loss = 1.06783
I0523 00:11:58.486747  3818 solver.cpp:253]     Train net output #0: loss = 1.06783 (* 1 = 1.06783 loss)
I0523 00:11:58.486763  3818 sgd_solver.cpp:106] Iteration 25125, lr = 0.0045
I0523 00:12:08.242645  3818 solver.cpp:237] Iteration 25500, loss = 1.11251
I0523 00:12:08.242681  3818 solver.cpp:253]     Train net output #0: loss = 1.11251 (* 1 = 1.11251 loss)
I0523 00:12:08.242697  3818 sgd_solver.cpp:106] Iteration 25500, lr = 0.0045
I0523 00:12:18.000565  3818 solver.cpp:237] Iteration 25875, loss = 1.00767
I0523 00:12:18.000612  3818 solver.cpp:253]     Train net output #0: loss = 1.00767 (* 1 = 1.00767 loss)
I0523 00:12:18.000627  3818 sgd_solver.cpp:106] Iteration 25875, lr = 0.0045
I0523 00:12:27.724195  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_26250.caffemodel
I0523 00:12:27.781530  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_26250.solverstate
I0523 00:12:27.815943  3818 solver.cpp:237] Iteration 26250, loss = 1.23839
I0523 00:12:27.815989  3818 solver.cpp:253]     Train net output #0: loss = 1.23839 (* 1 = 1.23839 loss)
I0523 00:12:27.816002  3818 sgd_solver.cpp:106] Iteration 26250, lr = 0.0045
I0523 00:12:37.564465  3818 solver.cpp:237] Iteration 26625, loss = 1.03934
I0523 00:12:37.564626  3818 solver.cpp:253]     Train net output #0: loss = 1.03934 (* 1 = 1.03934 loss)
I0523 00:12:37.564641  3818 sgd_solver.cpp:106] Iteration 26625, lr = 0.0045
I0523 00:12:47.319238  3818 solver.cpp:237] Iteration 27000, loss = 1.16446
I0523 00:12:47.319273  3818 solver.cpp:253]     Train net output #0: loss = 1.16446 (* 1 = 1.16446 loss)
I0523 00:12:47.319290  3818 sgd_solver.cpp:106] Iteration 27000, lr = 0.0045
I0523 00:12:57.070922  3818 solver.cpp:237] Iteration 27375, loss = 1.1665
I0523 00:12:57.070957  3818 solver.cpp:253]     Train net output #0: loss = 1.1665 (* 1 = 1.1665 loss)
I0523 00:12:57.070973  3818 sgd_solver.cpp:106] Iteration 27375, lr = 0.0045
I0523 00:13:29.041319  3818 solver.cpp:237] Iteration 27750, loss = 1.20276
I0523 00:13:29.041489  3818 solver.cpp:253]     Train net output #0: loss = 1.20276 (* 1 = 1.20276 loss)
I0523 00:13:29.041506  3818 sgd_solver.cpp:106] Iteration 27750, lr = 0.0045
I0523 00:13:38.797456  3818 solver.cpp:237] Iteration 28125, loss = 1.50045
I0523 00:13:38.797493  3818 solver.cpp:253]     Train net output #0: loss = 1.50045 (* 1 = 1.50045 loss)
I0523 00:13:38.797508  3818 sgd_solver.cpp:106] Iteration 28125, lr = 0.0045
I0523 00:13:48.548609  3818 solver.cpp:237] Iteration 28500, loss = 1.33565
I0523 00:13:48.548645  3818 solver.cpp:253]     Train net output #0: loss = 1.33565 (* 1 = 1.33565 loss)
I0523 00:13:48.548658  3818 sgd_solver.cpp:106] Iteration 28500, lr = 0.0045
I0523 00:13:58.300372  3818 solver.cpp:237] Iteration 28875, loss = 1.2163
I0523 00:13:58.300415  3818 solver.cpp:253]     Train net output #0: loss = 1.2163 (* 1 = 1.2163 loss)
I0523 00:13:58.300431  3818 sgd_solver.cpp:106] Iteration 28875, lr = 0.0045
I0523 00:14:08.060273  3818 solver.cpp:237] Iteration 29250, loss = 1.23654
I0523 00:14:08.060415  3818 solver.cpp:253]     Train net output #0: loss = 1.23654 (* 1 = 1.23654 loss)
I0523 00:14:08.060430  3818 sgd_solver.cpp:106] Iteration 29250, lr = 0.0045
I0523 00:14:17.817373  3818 solver.cpp:237] Iteration 29625, loss = 1.21302
I0523 00:14:17.817417  3818 solver.cpp:253]     Train net output #0: loss = 1.21302 (* 1 = 1.21302 loss)
I0523 00:14:17.817431  3818 sgd_solver.cpp:106] Iteration 29625, lr = 0.0045
I0523 00:14:27.546723  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_30000.caffemodel
I0523 00:14:27.601958  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_30000.solverstate
I0523 00:14:27.628240  3818 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 00:15:37.099894  3818 solver.cpp:409]     Test net output #0: accuracy = 0.872773
I0523 00:15:37.100062  3818 solver.cpp:409]     Test net output #1: loss = 0.417586 (* 1 = 0.417586 loss)
I0523 00:15:59.276237  3818 solver.cpp:237] Iteration 30000, loss = 0.983954
I0523 00:15:59.276290  3818 solver.cpp:253]     Train net output #0: loss = 0.983954 (* 1 = 0.983954 loss)
I0523 00:15:59.276306  3818 sgd_solver.cpp:106] Iteration 30000, lr = 0.0045
I0523 00:16:08.939736  3818 solver.cpp:237] Iteration 30375, loss = 0.830426
I0523 00:16:08.939884  3818 solver.cpp:253]     Train net output #0: loss = 0.830426 (* 1 = 0.830426 loss)
I0523 00:16:08.939898  3818 sgd_solver.cpp:106] Iteration 30375, lr = 0.0045
I0523 00:16:18.597553  3818 solver.cpp:237] Iteration 30750, loss = 0.970124
I0523 00:16:18.597589  3818 solver.cpp:253]     Train net output #0: loss = 0.970124 (* 1 = 0.970124 loss)
I0523 00:16:18.597604  3818 sgd_solver.cpp:106] Iteration 30750, lr = 0.0045
I0523 00:16:28.262081  3818 solver.cpp:237] Iteration 31125, loss = 1.47595
I0523 00:16:28.262131  3818 solver.cpp:253]     Train net output #0: loss = 1.47595 (* 1 = 1.47595 loss)
I0523 00:16:28.262145  3818 sgd_solver.cpp:106] Iteration 31125, lr = 0.0045
I0523 00:16:37.925356  3818 solver.cpp:237] Iteration 31500, loss = 1.54263
I0523 00:16:37.925392  3818 solver.cpp:253]     Train net output #0: loss = 1.54263 (* 1 = 1.54263 loss)
I0523 00:16:37.925406  3818 sgd_solver.cpp:106] Iteration 31500, lr = 0.0045
I0523 00:16:47.585506  3818 solver.cpp:237] Iteration 31875, loss = 1.1205
I0523 00:16:47.585667  3818 solver.cpp:253]     Train net output #0: loss = 1.1205 (* 1 = 1.1205 loss)
I0523 00:16:47.585681  3818 sgd_solver.cpp:106] Iteration 31875, lr = 0.0045
I0523 00:16:57.246623  3818 solver.cpp:237] Iteration 32250, loss = 0.768013
I0523 00:16:57.246659  3818 solver.cpp:253]     Train net output #0: loss = 0.768013 (* 1 = 0.768013 loss)
I0523 00:16:57.246675  3818 sgd_solver.cpp:106] Iteration 32250, lr = 0.0045
I0523 00:17:29.118221  3818 solver.cpp:237] Iteration 32625, loss = 1.32102
I0523 00:17:29.118392  3818 solver.cpp:253]     Train net output #0: loss = 1.32102 (* 1 = 1.32102 loss)
I0523 00:17:29.118407  3818 sgd_solver.cpp:106] Iteration 32625, lr = 0.0045
I0523 00:17:38.786840  3818 solver.cpp:237] Iteration 33000, loss = 1.03498
I0523 00:17:38.786886  3818 solver.cpp:253]     Train net output #0: loss = 1.03498 (* 1 = 1.03498 loss)
I0523 00:17:38.786901  3818 sgd_solver.cpp:106] Iteration 33000, lr = 0.0045
I0523 00:17:48.453058  3818 solver.cpp:237] Iteration 33375, loss = 1.22572
I0523 00:17:48.453094  3818 solver.cpp:253]     Train net output #0: loss = 1.22572 (* 1 = 1.22572 loss)
I0523 00:17:48.453107  3818 sgd_solver.cpp:106] Iteration 33375, lr = 0.0045
I0523 00:17:58.092522  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_33750.caffemodel
I0523 00:17:58.150290  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_33750.solverstate
I0523 00:17:58.186898  3818 solver.cpp:237] Iteration 33750, loss = 1.41953
I0523 00:17:58.186947  3818 solver.cpp:253]     Train net output #0: loss = 1.41953 (* 1 = 1.41953 loss)
I0523 00:17:58.186964  3818 sgd_solver.cpp:106] Iteration 33750, lr = 0.0045
I0523 00:18:07.850162  3818 solver.cpp:237] Iteration 34125, loss = 1.21204
I0523 00:18:07.850324  3818 solver.cpp:253]     Train net output #0: loss = 1.21204 (* 1 = 1.21204 loss)
I0523 00:18:07.850338  3818 sgd_solver.cpp:106] Iteration 34125, lr = 0.0045
I0523 00:18:17.516122  3818 solver.cpp:237] Iteration 34500, loss = 1.2909
I0523 00:18:17.516156  3818 solver.cpp:253]     Train net output #0: loss = 1.2909 (* 1 = 1.2909 loss)
I0523 00:18:17.516172  3818 sgd_solver.cpp:106] Iteration 34500, lr = 0.0045
I0523 00:18:27.173925  3818 solver.cpp:237] Iteration 34875, loss = 1.23688
I0523 00:18:27.173966  3818 solver.cpp:253]     Train net output #0: loss = 1.23688 (* 1 = 1.23688 loss)
I0523 00:18:27.173987  3818 sgd_solver.cpp:106] Iteration 34875, lr = 0.0045
I0523 00:18:59.026906  3818 solver.cpp:237] Iteration 35250, loss = 0.924649
I0523 00:18:59.027093  3818 solver.cpp:253]     Train net output #0: loss = 0.924649 (* 1 = 0.924649 loss)
I0523 00:18:59.027110  3818 sgd_solver.cpp:106] Iteration 35250, lr = 0.0045
I0523 00:19:08.687695  3818 solver.cpp:237] Iteration 35625, loss = 1.37209
I0523 00:19:08.687731  3818 solver.cpp:253]     Train net output #0: loss = 1.37209 (* 1 = 1.37209 loss)
I0523 00:19:08.687746  3818 sgd_solver.cpp:106] Iteration 35625, lr = 0.0045
I0523 00:19:18.353828  3818 solver.cpp:237] Iteration 36000, loss = 1.27655
I0523 00:19:18.353871  3818 solver.cpp:253]     Train net output #0: loss = 1.27655 (* 1 = 1.27655 loss)
I0523 00:19:18.353888  3818 sgd_solver.cpp:106] Iteration 36000, lr = 0.0045
I0523 00:19:28.016697  3818 solver.cpp:237] Iteration 36375, loss = 1.53485
I0523 00:19:28.016731  3818 solver.cpp:253]     Train net output #0: loss = 1.53485 (* 1 = 1.53485 loss)
I0523 00:19:28.016747  3818 sgd_solver.cpp:106] Iteration 36375, lr = 0.0045
I0523 00:19:37.677012  3818 solver.cpp:237] Iteration 36750, loss = 1.13925
I0523 00:19:37.677165  3818 solver.cpp:253]     Train net output #0: loss = 1.13925 (* 1 = 1.13925 loss)
I0523 00:19:37.677180  3818 sgd_solver.cpp:106] Iteration 36750, lr = 0.0045
I0523 00:19:47.340690  3818 solver.cpp:237] Iteration 37125, loss = 1.40117
I0523 00:19:47.340733  3818 solver.cpp:253]     Train net output #0: loss = 1.40117 (* 1 = 1.40117 loss)
I0523 00:19:47.340749  3818 sgd_solver.cpp:106] Iteration 37125, lr = 0.0045
I0523 00:19:56.977494  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_37500.caffemodel
I0523 00:19:57.035342  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_37500.solverstate
I0523 00:19:57.063863  3818 solver.cpp:341] Iteration 37500, Testing net (#0)
I0523 00:20:45.641203  3818 solver.cpp:409]     Test net output #0: accuracy = 0.881093
I0523 00:20:45.641368  3818 solver.cpp:409]     Test net output #1: loss = 0.376393 (* 1 = 0.376393 loss)
I0523 00:21:06.541873  3818 solver.cpp:237] Iteration 37500, loss = 1.0553
I0523 00:21:06.541925  3818 solver.cpp:253]     Train net output #0: loss = 1.0553 (* 1 = 1.0553 loss)
I0523 00:21:06.541941  3818 sgd_solver.cpp:106] Iteration 37500, lr = 0.0045
I0523 00:21:16.289407  3818 solver.cpp:237] Iteration 37875, loss = 1.16698
I0523 00:21:16.289559  3818 solver.cpp:253]     Train net output #0: loss = 1.16698 (* 1 = 1.16698 loss)
I0523 00:21:16.289573  3818 sgd_solver.cpp:106] Iteration 37875, lr = 0.0045
I0523 00:21:26.037081  3818 solver.cpp:237] Iteration 38250, loss = 1.21333
I0523 00:21:26.037122  3818 solver.cpp:253]     Train net output #0: loss = 1.21333 (* 1 = 1.21333 loss)
I0523 00:21:26.037137  3818 sgd_solver.cpp:106] Iteration 38250, lr = 0.0045
I0523 00:21:35.786245  3818 solver.cpp:237] Iteration 38625, loss = 1.34089
I0523 00:21:35.786281  3818 solver.cpp:253]     Train net output #0: loss = 1.34089 (* 1 = 1.34089 loss)
I0523 00:21:35.786294  3818 sgd_solver.cpp:106] Iteration 38625, lr = 0.0045
I0523 00:21:45.536355  3818 solver.cpp:237] Iteration 39000, loss = 1.11889
I0523 00:21:45.536389  3818 solver.cpp:253]     Train net output #0: loss = 1.11889 (* 1 = 1.11889 loss)
I0523 00:21:45.536404  3818 sgd_solver.cpp:106] Iteration 39000, lr = 0.0045
I0523 00:21:55.282018  3818 solver.cpp:237] Iteration 39375, loss = 1.38784
I0523 00:21:55.282184  3818 solver.cpp:253]     Train net output #0: loss = 1.38784 (* 1 = 1.38784 loss)
I0523 00:21:55.282198  3818 sgd_solver.cpp:106] Iteration 39375, lr = 0.0045
I0523 00:22:05.033573  3818 solver.cpp:237] Iteration 39750, loss = 1.29755
I0523 00:22:05.033617  3818 solver.cpp:253]     Train net output #0: loss = 1.29755 (* 1 = 1.29755 loss)
I0523 00:22:05.033632  3818 sgd_solver.cpp:106] Iteration 39750, lr = 0.0045
I0523 00:22:35.688894  3818 solver.cpp:237] Iteration 40125, loss = 1.33095
I0523 00:22:35.689066  3818 solver.cpp:253]     Train net output #0: loss = 1.33095 (* 1 = 1.33095 loss)
I0523 00:22:35.689083  3818 sgd_solver.cpp:106] Iteration 40125, lr = 0.0045
I0523 00:22:45.433534  3818 solver.cpp:237] Iteration 40500, loss = 1.0877
I0523 00:22:45.433581  3818 solver.cpp:253]     Train net output #0: loss = 1.0877 (* 1 = 1.0877 loss)
I0523 00:22:45.433596  3818 sgd_solver.cpp:106] Iteration 40500, lr = 0.0045
I0523 00:22:55.183162  3818 solver.cpp:237] Iteration 40875, loss = 1.26253
I0523 00:22:55.183198  3818 solver.cpp:253]     Train net output #0: loss = 1.26253 (* 1 = 1.26253 loss)
I0523 00:22:55.183213  3818 sgd_solver.cpp:106] Iteration 40875, lr = 0.0045
I0523 00:23:04.911306  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_41250.caffemodel
I0523 00:23:04.975818  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_41250.solverstate
I0523 00:23:05.729701  3818 solver.cpp:237] Iteration 41250, loss = 1.00008
I0523 00:23:05.729864  3818 solver.cpp:253]     Train net output #0: loss = 1.00008 (* 1 = 1.00008 loss)
I0523 00:23:05.729878  3818 sgd_solver.cpp:106] Iteration 41250, lr = 0.0045
I0523 00:23:15.473601  3818 solver.cpp:237] Iteration 41625, loss = 1.09508
I0523 00:23:15.473636  3818 solver.cpp:253]     Train net output #0: loss = 1.09508 (* 1 = 1.09508 loss)
I0523 00:23:15.473651  3818 sgd_solver.cpp:106] Iteration 41625, lr = 0.0045
I0523 00:23:25.226650  3818 solver.cpp:237] Iteration 42000, loss = 1.30856
I0523 00:23:25.226686  3818 solver.cpp:253]     Train net output #0: loss = 1.30856 (* 1 = 1.30856 loss)
I0523 00:23:25.226701  3818 sgd_solver.cpp:106] Iteration 42000, lr = 0.0045
I0523 00:23:34.977210  3818 solver.cpp:237] Iteration 42375, loss = 0.984561
I0523 00:23:34.977255  3818 solver.cpp:253]     Train net output #0: loss = 0.98456 (* 1 = 0.98456 loss)
I0523 00:23:34.977272  3818 sgd_solver.cpp:106] Iteration 42375, lr = 0.0045
I0523 00:24:05.624495  3818 solver.cpp:237] Iteration 42750, loss = 1.11699
I0523 00:24:05.624668  3818 solver.cpp:253]     Train net output #0: loss = 1.11699 (* 1 = 1.11699 loss)
I0523 00:24:05.624682  3818 sgd_solver.cpp:106] Iteration 42750, lr = 0.0045
I0523 00:24:15.382519  3818 solver.cpp:237] Iteration 43125, loss = 1.06372
I0523 00:24:15.382555  3818 solver.cpp:253]     Train net output #0: loss = 1.06372 (* 1 = 1.06372 loss)
I0523 00:24:15.382570  3818 sgd_solver.cpp:106] Iteration 43125, lr = 0.0045
I0523 00:24:25.212234  3818 solver.cpp:237] Iteration 43500, loss = 1.46057
I0523 00:24:25.212280  3818 solver.cpp:253]     Train net output #0: loss = 1.46057 (* 1 = 1.46057 loss)
I0523 00:24:25.212292  3818 sgd_solver.cpp:106] Iteration 43500, lr = 0.0045
I0523 00:24:35.040114  3818 solver.cpp:237] Iteration 43875, loss = 1.0225
I0523 00:24:35.040150  3818 solver.cpp:253]     Train net output #0: loss = 1.0225 (* 1 = 1.0225 loss)
I0523 00:24:35.040163  3818 sgd_solver.cpp:106] Iteration 43875, lr = 0.0045
I0523 00:24:44.863677  3818 solver.cpp:237] Iteration 44250, loss = 1.10117
I0523 00:24:44.863837  3818 solver.cpp:253]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0523 00:24:44.863852  3818 sgd_solver.cpp:106] Iteration 44250, lr = 0.0045
I0523 00:24:54.681104  3818 solver.cpp:237] Iteration 44625, loss = 1.21622
I0523 00:24:54.681139  3818 solver.cpp:253]     Train net output #0: loss = 1.21622 (* 1 = 1.21622 loss)
I0523 00:24:54.681154  3818 sgd_solver.cpp:106] Iteration 44625, lr = 0.0045
I0523 00:25:04.481865  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_45000.caffemodel
I0523 00:25:04.536875  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_45000.solverstate
I0523 00:25:04.563015  3818 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 00:26:14.011032  3818 solver.cpp:409]     Test net output #0: accuracy = 0.883187
I0523 00:26:14.011209  3818 solver.cpp:409]     Test net output #1: loss = 0.369444 (* 1 = 0.369444 loss)
I0523 00:26:34.931357  3818 solver.cpp:237] Iteration 45000, loss = 0.868331
I0523 00:26:34.931412  3818 solver.cpp:253]     Train net output #0: loss = 0.868331 (* 1 = 0.868331 loss)
I0523 00:26:34.931427  3818 sgd_solver.cpp:106] Iteration 45000, lr = 0.0045
I0523 00:26:44.656791  3818 solver.cpp:237] Iteration 45375, loss = 1.16179
I0523 00:26:44.656947  3818 solver.cpp:253]     Train net output #0: loss = 1.16179 (* 1 = 1.16179 loss)
I0523 00:26:44.656961  3818 sgd_solver.cpp:106] Iteration 45375, lr = 0.0045
I0523 00:26:54.382884  3818 solver.cpp:237] Iteration 45750, loss = 1.21657
I0523 00:26:54.382927  3818 solver.cpp:253]     Train net output #0: loss = 1.21657 (* 1 = 1.21657 loss)
I0523 00:26:54.382943  3818 sgd_solver.cpp:106] Iteration 45750, lr = 0.0045
I0523 00:27:04.109243  3818 solver.cpp:237] Iteration 46125, loss = 1.29281
I0523 00:27:04.109278  3818 solver.cpp:253]     Train net output #0: loss = 1.29281 (* 1 = 1.29281 loss)
I0523 00:27:04.109294  3818 sgd_solver.cpp:106] Iteration 46125, lr = 0.0045
I0523 00:27:13.834445  3818 solver.cpp:237] Iteration 46500, loss = 0.830692
I0523 00:27:13.834484  3818 solver.cpp:253]     Train net output #0: loss = 0.830691 (* 1 = 0.830691 loss)
I0523 00:27:13.834502  3818 sgd_solver.cpp:106] Iteration 46500, lr = 0.0045
I0523 00:27:23.568824  3818 solver.cpp:237] Iteration 46875, loss = 1.16115
I0523 00:27:23.568972  3818 solver.cpp:253]     Train net output #0: loss = 1.16114 (* 1 = 1.16114 loss)
I0523 00:27:23.568985  3818 sgd_solver.cpp:106] Iteration 46875, lr = 0.0045
I0523 00:27:33.301534  3818 solver.cpp:237] Iteration 47250, loss = 1.40005
I0523 00:27:33.301568  3818 solver.cpp:253]     Train net output #0: loss = 1.40005 (* 1 = 1.40005 loss)
I0523 00:27:33.301584  3818 sgd_solver.cpp:106] Iteration 47250, lr = 0.0045
I0523 00:28:03.931831  3818 solver.cpp:237] Iteration 47625, loss = 0.936627
I0523 00:28:03.931999  3818 solver.cpp:253]     Train net output #0: loss = 0.936626 (* 1 = 0.936626 loss)
I0523 00:28:03.932014  3818 sgd_solver.cpp:106] Iteration 47625, lr = 0.0045
I0523 00:28:13.611610  3818 solver.cpp:237] Iteration 48000, loss = 1.05961
I0523 00:28:13.611644  3818 solver.cpp:253]     Train net output #0: loss = 1.05961 (* 1 = 1.05961 loss)
I0523 00:28:13.611660  3818 sgd_solver.cpp:106] Iteration 48000, lr = 0.0045
I0523 00:28:23.290725  3818 solver.cpp:237] Iteration 48375, loss = 0.963451
I0523 00:28:23.290761  3818 solver.cpp:253]     Train net output #0: loss = 0.963451 (* 1 = 0.963451 loss)
I0523 00:28:23.290776  3818 sgd_solver.cpp:106] Iteration 48375, lr = 0.0045
I0523 00:28:32.946183  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_48750.caffemodel
I0523 00:28:33.001561  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_48750.solverstate
I0523 00:28:33.036051  3818 solver.cpp:237] Iteration 48750, loss = 1.13487
I0523 00:28:33.036093  3818 solver.cpp:253]     Train net output #0: loss = 1.13487 (* 1 = 1.13487 loss)
I0523 00:28:33.036113  3818 sgd_solver.cpp:106] Iteration 48750, lr = 0.0045
I0523 00:28:42.716197  3818 solver.cpp:237] Iteration 49125, loss = 1.15118
I0523 00:28:42.716361  3818 solver.cpp:253]     Train net output #0: loss = 1.15118 (* 1 = 1.15118 loss)
I0523 00:28:42.716375  3818 sgd_solver.cpp:106] Iteration 49125, lr = 0.0045
I0523 00:28:52.398704  3818 solver.cpp:237] Iteration 49500, loss = 1.16456
I0523 00:28:52.398747  3818 solver.cpp:253]     Train net output #0: loss = 1.16456 (* 1 = 1.16456 loss)
I0523 00:28:52.398763  3818 sgd_solver.cpp:106] Iteration 49500, lr = 0.0045
I0523 00:29:02.081918  3818 solver.cpp:237] Iteration 49875, loss = 1.01997
I0523 00:29:02.081954  3818 solver.cpp:253]     Train net output #0: loss = 1.01997 (* 1 = 1.01997 loss)
I0523 00:29:02.081969  3818 sgd_solver.cpp:106] Iteration 49875, lr = 0.0045
I0523 00:29:32.673662  3818 solver.cpp:237] Iteration 50250, loss = 1.20951
I0523 00:29:32.673836  3818 solver.cpp:253]     Train net output #0: loss = 1.20951 (* 1 = 1.20951 loss)
I0523 00:29:32.673851  3818 sgd_solver.cpp:106] Iteration 50250, lr = 0.0045
I0523 00:29:42.358156  3818 solver.cpp:237] Iteration 50625, loss = 1.21557
I0523 00:29:42.358206  3818 solver.cpp:253]     Train net output #0: loss = 1.21557 (* 1 = 1.21557 loss)
I0523 00:29:42.358219  3818 sgd_solver.cpp:106] Iteration 50625, lr = 0.0045
I0523 00:29:52.040267  3818 solver.cpp:237] Iteration 51000, loss = 1.04678
I0523 00:29:52.040303  3818 solver.cpp:253]     Train net output #0: loss = 1.04678 (* 1 = 1.04678 loss)
I0523 00:29:52.040318  3818 sgd_solver.cpp:106] Iteration 51000, lr = 0.0045
I0523 00:30:01.716074  3818 solver.cpp:237] Iteration 51375, loss = 1.12729
I0523 00:30:01.716110  3818 solver.cpp:253]     Train net output #0: loss = 1.12729 (* 1 = 1.12729 loss)
I0523 00:30:01.716125  3818 sgd_solver.cpp:106] Iteration 51375, lr = 0.0045
I0523 00:30:11.394412  3818 solver.cpp:237] Iteration 51750, loss = 1.18359
I0523 00:30:11.394573  3818 solver.cpp:253]     Train net output #0: loss = 1.18359 (* 1 = 1.18359 loss)
I0523 00:30:11.394587  3818 sgd_solver.cpp:106] Iteration 51750, lr = 0.0045
I0523 00:30:21.070680  3818 solver.cpp:237] Iteration 52125, loss = 1.031
I0523 00:30:21.070715  3818 solver.cpp:253]     Train net output #0: loss = 1.031 (* 1 = 1.031 loss)
I0523 00:30:21.070730  3818 sgd_solver.cpp:106] Iteration 52125, lr = 0.0045
I0523 00:30:30.728840  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_52500.caffemodel
I0523 00:30:30.783965  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_52500.solverstate
I0523 00:30:30.810181  3818 solver.cpp:341] Iteration 52500, Testing net (#0)
I0523 00:31:19.001637  3818 solver.cpp:409]     Test net output #0: accuracy = 0.886666
I0523 00:31:19.001802  3818 solver.cpp:409]     Test net output #1: loss = 0.383825 (* 1 = 0.383825 loss)
I0523 00:31:39.919697  3818 solver.cpp:237] Iteration 52500, loss = 0.913024
I0523 00:31:39.919749  3818 solver.cpp:253]     Train net output #0: loss = 0.913024 (* 1 = 0.913024 loss)
I0523 00:31:39.919765  3818 sgd_solver.cpp:106] Iteration 52500, lr = 0.0045
I0523 00:31:49.786726  3818 solver.cpp:237] Iteration 52875, loss = 1.2166
I0523 00:31:49.786897  3818 solver.cpp:253]     Train net output #0: loss = 1.2166 (* 1 = 1.2166 loss)
I0523 00:31:49.786911  3818 sgd_solver.cpp:106] Iteration 52875, lr = 0.0045
I0523 00:31:59.653638  3818 solver.cpp:237] Iteration 53250, loss = 1.43516
I0523 00:31:59.653673  3818 solver.cpp:253]     Train net output #0: loss = 1.43516 (* 1 = 1.43516 loss)
I0523 00:31:59.653689  3818 sgd_solver.cpp:106] Iteration 53250, lr = 0.0045
I0523 00:32:09.526011  3818 solver.cpp:237] Iteration 53625, loss = 1.047
I0523 00:32:09.526047  3818 solver.cpp:253]     Train net output #0: loss = 1.047 (* 1 = 1.047 loss)
I0523 00:32:09.526060  3818 sgd_solver.cpp:106] Iteration 53625, lr = 0.0045
I0523 00:32:19.396842  3818 solver.cpp:237] Iteration 54000, loss = 0.951556
I0523 00:32:19.396891  3818 solver.cpp:253]     Train net output #0: loss = 0.951556 (* 1 = 0.951556 loss)
I0523 00:32:19.396905  3818 sgd_solver.cpp:106] Iteration 54000, lr = 0.0045
I0523 00:32:29.254683  3818 solver.cpp:237] Iteration 54375, loss = 0.975369
I0523 00:32:29.254847  3818 solver.cpp:253]     Train net output #0: loss = 0.975369 (* 1 = 0.975369 loss)
I0523 00:32:29.254860  3818 sgd_solver.cpp:106] Iteration 54375, lr = 0.0045
I0523 00:32:39.118794  3818 solver.cpp:237] Iteration 54750, loss = 0.938574
I0523 00:32:39.118841  3818 solver.cpp:253]     Train net output #0: loss = 0.938574 (* 1 = 0.938574 loss)
I0523 00:32:39.118856  3818 sgd_solver.cpp:106] Iteration 54750, lr = 0.0045
I0523 00:33:09.883882  3818 solver.cpp:237] Iteration 55125, loss = 1.15938
I0523 00:33:09.884057  3818 solver.cpp:253]     Train net output #0: loss = 1.15938 (* 1 = 1.15938 loss)
I0523 00:33:09.884073  3818 sgd_solver.cpp:106] Iteration 55125, lr = 0.0045
I0523 00:33:19.748627  3818 solver.cpp:237] Iteration 55500, loss = 0.949535
I0523 00:33:19.748662  3818 solver.cpp:253]     Train net output #0: loss = 0.949535 (* 1 = 0.949535 loss)
I0523 00:33:19.748677  3818 sgd_solver.cpp:106] Iteration 55500, lr = 0.0045
I0523 00:33:29.614209  3818 solver.cpp:237] Iteration 55875, loss = 0.977268
I0523 00:33:29.614260  3818 solver.cpp:253]     Train net output #0: loss = 0.977268 (* 1 = 0.977268 loss)
I0523 00:33:29.614274  3818 sgd_solver.cpp:106] Iteration 55875, lr = 0.0045
I0523 00:33:39.456132  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_56250.caffemodel
I0523 00:33:39.514742  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_56250.solverstate
I0523 00:33:39.551443  3818 solver.cpp:237] Iteration 56250, loss = 1.30144
I0523 00:33:39.551496  3818 solver.cpp:253]     Train net output #0: loss = 1.30144 (* 1 = 1.30144 loss)
I0523 00:33:39.551511  3818 sgd_solver.cpp:106] Iteration 56250, lr = 0.0045
I0523 00:33:49.418911  3818 solver.cpp:237] Iteration 56625, loss = 1.30903
I0523 00:33:49.419076  3818 solver.cpp:253]     Train net output #0: loss = 1.30903 (* 1 = 1.30903 loss)
I0523 00:33:49.419090  3818 sgd_solver.cpp:106] Iteration 56625, lr = 0.0045
I0523 00:33:59.290524  3818 solver.cpp:237] Iteration 57000, loss = 1.19888
I0523 00:33:59.290568  3818 solver.cpp:253]     Train net output #0: loss = 1.19888 (* 1 = 1.19888 loss)
I0523 00:33:59.290582  3818 sgd_solver.cpp:106] Iteration 57000, lr = 0.0045
I0523 00:34:09.157721  3818 solver.cpp:237] Iteration 57375, loss = 1.08617
I0523 00:34:09.157757  3818 solver.cpp:253]     Train net output #0: loss = 1.08617 (* 1 = 1.08617 loss)
I0523 00:34:09.157770  3818 sgd_solver.cpp:106] Iteration 57375, lr = 0.0045
I0523 00:34:39.945302  3818 solver.cpp:237] Iteration 57750, loss = 1.07119
I0523 00:34:39.945477  3818 solver.cpp:253]     Train net output #0: loss = 1.07119 (* 1 = 1.07119 loss)
I0523 00:34:39.945494  3818 sgd_solver.cpp:106] Iteration 57750, lr = 0.0045
I0523 00:34:49.810276  3818 solver.cpp:237] Iteration 58125, loss = 1.54692
I0523 00:34:49.810322  3818 solver.cpp:253]     Train net output #0: loss = 1.54692 (* 1 = 1.54692 loss)
I0523 00:34:49.810338  3818 sgd_solver.cpp:106] Iteration 58125, lr = 0.0045
I0523 00:34:59.680397  3818 solver.cpp:237] Iteration 58500, loss = 1.36025
I0523 00:34:59.680431  3818 solver.cpp:253]     Train net output #0: loss = 1.36025 (* 1 = 1.36025 loss)
I0523 00:34:59.680446  3818 sgd_solver.cpp:106] Iteration 58500, lr = 0.0045
I0523 00:35:09.548954  3818 solver.cpp:237] Iteration 58875, loss = 1.00658
I0523 00:35:09.549003  3818 solver.cpp:253]     Train net output #0: loss = 1.00658 (* 1 = 1.00658 loss)
I0523 00:35:09.549017  3818 sgd_solver.cpp:106] Iteration 58875, lr = 0.0045
I0523 00:35:19.417955  3818 solver.cpp:237] Iteration 59250, loss = 1.16139
I0523 00:35:19.418120  3818 solver.cpp:253]     Train net output #0: loss = 1.16138 (* 1 = 1.16138 loss)
I0523 00:35:19.418134  3818 sgd_solver.cpp:106] Iteration 59250, lr = 0.0045
I0523 00:35:29.286733  3818 solver.cpp:237] Iteration 59625, loss = 0.875527
I0523 00:35:29.286768  3818 solver.cpp:253]     Train net output #0: loss = 0.875526 (* 1 = 0.875526 loss)
I0523 00:35:29.286783  3818 sgd_solver.cpp:106] Iteration 59625, lr = 0.0045
I0523 00:35:39.131038  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_60000.caffemodel
I0523 00:35:39.187348  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_60000.solverstate
I0523 00:35:39.213479  3818 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 00:36:48.668639  3818 solver.cpp:409]     Test net output #0: accuracy = 0.885913
I0523 00:36:48.668809  3818 solver.cpp:409]     Test net output #1: loss = 0.346751 (* 1 = 0.346751 loss)
I0523 00:37:09.551946  3818 solver.cpp:237] Iteration 60000, loss = 1.13254
I0523 00:37:09.552000  3818 solver.cpp:253]     Train net output #0: loss = 1.13254 (* 1 = 1.13254 loss)
I0523 00:37:09.552016  3818 sgd_solver.cpp:106] Iteration 60000, lr = 0.0045
I0523 00:37:19.437886  3818 solver.cpp:237] Iteration 60375, loss = 0.938717
I0523 00:37:19.438056  3818 solver.cpp:253]     Train net output #0: loss = 0.938717 (* 1 = 0.938717 loss)
I0523 00:37:19.438071  3818 sgd_solver.cpp:106] Iteration 60375, lr = 0.0045
I0523 00:37:29.330381  3818 solver.cpp:237] Iteration 60750, loss = 1.1375
I0523 00:37:29.330415  3818 solver.cpp:253]     Train net output #0: loss = 1.1375 (* 1 = 1.1375 loss)
I0523 00:37:29.330430  3818 sgd_solver.cpp:106] Iteration 60750, lr = 0.0045
I0523 00:37:39.224133  3818 solver.cpp:237] Iteration 61125, loss = 1.41816
I0523 00:37:39.224174  3818 solver.cpp:253]     Train net output #0: loss = 1.41815 (* 1 = 1.41815 loss)
I0523 00:37:39.224189  3818 sgd_solver.cpp:106] Iteration 61125, lr = 0.0045
I0523 00:37:49.107381  3818 solver.cpp:237] Iteration 61500, loss = 0.873663
I0523 00:37:49.107417  3818 solver.cpp:253]     Train net output #0: loss = 0.873663 (* 1 = 0.873663 loss)
I0523 00:37:49.107431  3818 sgd_solver.cpp:106] Iteration 61500, lr = 0.0045
I0523 00:37:58.990651  3818 solver.cpp:237] Iteration 61875, loss = 1.4235
I0523 00:37:58.990800  3818 solver.cpp:253]     Train net output #0: loss = 1.4235 (* 1 = 1.4235 loss)
I0523 00:37:58.990814  3818 sgd_solver.cpp:106] Iteration 61875, lr = 0.0045
I0523 00:38:08.877929  3818 solver.cpp:237] Iteration 62250, loss = 1.05615
I0523 00:38:08.877977  3818 solver.cpp:253]     Train net output #0: loss = 1.05615 (* 1 = 1.05615 loss)
I0523 00:38:08.877991  3818 sgd_solver.cpp:106] Iteration 62250, lr = 0.0045
I0523 00:38:39.659952  3818 solver.cpp:237] Iteration 62625, loss = 0.906574
I0523 00:38:39.660128  3818 solver.cpp:253]     Train net output #0: loss = 0.906574 (* 1 = 0.906574 loss)
I0523 00:38:39.660145  3818 sgd_solver.cpp:106] Iteration 62625, lr = 0.0045
I0523 00:38:49.552382  3818 solver.cpp:237] Iteration 63000, loss = 0.91185
I0523 00:38:49.552419  3818 solver.cpp:253]     Train net output #0: loss = 0.911849 (* 1 = 0.911849 loss)
I0523 00:38:49.552433  3818 sgd_solver.cpp:106] Iteration 63000, lr = 0.0045
I0523 00:38:59.444587  3818 solver.cpp:237] Iteration 63375, loss = 0.831806
I0523 00:38:59.444633  3818 solver.cpp:253]     Train net output #0: loss = 0.831806 (* 1 = 0.831806 loss)
I0523 00:38:59.444646  3818 sgd_solver.cpp:106] Iteration 63375, lr = 0.0045
I0523 00:39:09.303928  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_63750.caffemodel
I0523 00:39:09.359635  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_63750.solverstate
I0523 00:39:09.393792  3818 solver.cpp:237] Iteration 63750, loss = 1.12226
I0523 00:39:09.393838  3818 solver.cpp:253]     Train net output #0: loss = 1.12226 (* 1 = 1.12226 loss)
I0523 00:39:09.393853  3818 sgd_solver.cpp:106] Iteration 63750, lr = 0.0045
I0523 00:39:19.283308  3818 solver.cpp:237] Iteration 64125, loss = 1.02733
I0523 00:39:19.283483  3818 solver.cpp:253]     Train net output #0: loss = 1.02733 (* 1 = 1.02733 loss)
I0523 00:39:19.283496  3818 sgd_solver.cpp:106] Iteration 64125, lr = 0.0045
I0523 00:39:29.170779  3818 solver.cpp:237] Iteration 64500, loss = 1.13935
I0523 00:39:29.170814  3818 solver.cpp:253]     Train net output #0: loss = 1.13935 (* 1 = 1.13935 loss)
I0523 00:39:29.170830  3818 sgd_solver.cpp:106] Iteration 64500, lr = 0.0045
I0523 00:39:39.055626  3818 solver.cpp:237] Iteration 64875, loss = 1.03276
I0523 00:39:39.055660  3818 solver.cpp:253]     Train net output #0: loss = 1.03276 (* 1 = 1.03276 loss)
I0523 00:39:39.055676  3818 sgd_solver.cpp:106] Iteration 64875, lr = 0.0045
I0523 00:40:09.865789  3818 solver.cpp:237] Iteration 65250, loss = 1.21281
I0523 00:40:09.865972  3818 solver.cpp:253]     Train net output #0: loss = 1.21281 (* 1 = 1.21281 loss)
I0523 00:40:09.865989  3818 sgd_solver.cpp:106] Iteration 65250, lr = 0.0045
I0523 00:40:19.754287  3818 solver.cpp:237] Iteration 65625, loss = 1.25667
I0523 00:40:19.754322  3818 solver.cpp:253]     Train net output #0: loss = 1.25667 (* 1 = 1.25667 loss)
I0523 00:40:19.754338  3818 sgd_solver.cpp:106] Iteration 65625, lr = 0.0045
I0523 00:40:29.646677  3818 solver.cpp:237] Iteration 66000, loss = 1.19373
I0523 00:40:29.646714  3818 solver.cpp:253]     Train net output #0: loss = 1.19373 (* 1 = 1.19373 loss)
I0523 00:40:29.646728  3818 sgd_solver.cpp:106] Iteration 66000, lr = 0.0045
I0523 00:40:39.533164  3818 solver.cpp:237] Iteration 66375, loss = 1.20116
I0523 00:40:39.533207  3818 solver.cpp:253]     Train net output #0: loss = 1.20116 (* 1 = 1.20116 loss)
I0523 00:40:39.533222  3818 sgd_solver.cpp:106] Iteration 66375, lr = 0.0045
I0523 00:40:49.419255  3818 solver.cpp:237] Iteration 66750, loss = 1.159
I0523 00:40:49.419409  3818 solver.cpp:253]     Train net output #0: loss = 1.159 (* 1 = 1.159 loss)
I0523 00:40:49.419423  3818 sgd_solver.cpp:106] Iteration 66750, lr = 0.0045
I0523 00:40:59.308840  3818 solver.cpp:237] Iteration 67125, loss = 1.22882
I0523 00:40:59.308888  3818 solver.cpp:253]     Train net output #0: loss = 1.22882 (* 1 = 1.22882 loss)
I0523 00:40:59.308902  3818 sgd_solver.cpp:106] Iteration 67125, lr = 0.0045
I0523 00:41:09.170754  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_67500.caffemodel
I0523 00:41:09.226729  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_67500.solverstate
I0523 00:41:09.252955  3818 solver.cpp:341] Iteration 67500, Testing net (#0)
I0523 00:41:57.769928  3818 solver.cpp:409]     Test net output #0: accuracy = 0.889373
I0523 00:41:57.770099  3818 solver.cpp:409]     Test net output #1: loss = 0.369345 (* 1 = 0.369345 loss)
I0523 00:42:18.679726  3818 solver.cpp:237] Iteration 67500, loss = 0.96319
I0523 00:42:18.679780  3818 solver.cpp:253]     Train net output #0: loss = 0.963189 (* 1 = 0.963189 loss)
I0523 00:42:18.679796  3818 sgd_solver.cpp:106] Iteration 67500, lr = 0.0045
I0523 00:42:28.518720  3818 solver.cpp:237] Iteration 67875, loss = 0.867523
I0523 00:42:28.518884  3818 solver.cpp:253]     Train net output #0: loss = 0.867522 (* 1 = 0.867522 loss)
I0523 00:42:28.518898  3818 sgd_solver.cpp:106] Iteration 67875, lr = 0.0045
I0523 00:42:38.354859  3818 solver.cpp:237] Iteration 68250, loss = 1.09007
I0523 00:42:38.354907  3818 solver.cpp:253]     Train net output #0: loss = 1.09007 (* 1 = 1.09007 loss)
I0523 00:42:38.354919  3818 sgd_solver.cpp:106] Iteration 68250, lr = 0.0045
I0523 00:42:48.193868  3818 solver.cpp:237] Iteration 68625, loss = 1.19503
I0523 00:42:48.193904  3818 solver.cpp:253]     Train net output #0: loss = 1.19503 (* 1 = 1.19503 loss)
I0523 00:42:48.193920  3818 sgd_solver.cpp:106] Iteration 68625, lr = 0.0045
I0523 00:42:58.035919  3818 solver.cpp:237] Iteration 69000, loss = 1.2935
I0523 00:42:58.035954  3818 solver.cpp:253]     Train net output #0: loss = 1.2935 (* 1 = 1.2935 loss)
I0523 00:42:58.035969  3818 sgd_solver.cpp:106] Iteration 69000, lr = 0.0045
I0523 00:43:07.876339  3818 solver.cpp:237] Iteration 69375, loss = 0.866469
I0523 00:43:07.876516  3818 solver.cpp:253]     Train net output #0: loss = 0.866468 (* 1 = 0.866468 loss)
I0523 00:43:07.876530  3818 sgd_solver.cpp:106] Iteration 69375, lr = 0.0045
I0523 00:43:17.715852  3818 solver.cpp:237] Iteration 69750, loss = 0.83481
I0523 00:43:17.715888  3818 solver.cpp:253]     Train net output #0: loss = 0.83481 (* 1 = 0.83481 loss)
I0523 00:43:17.715903  3818 sgd_solver.cpp:106] Iteration 69750, lr = 0.0045
I0523 00:43:48.450736  3818 solver.cpp:237] Iteration 70125, loss = 1.14011
I0523 00:43:48.450911  3818 solver.cpp:253]     Train net output #0: loss = 1.14011 (* 1 = 1.14011 loss)
I0523 00:43:48.450928  3818 sgd_solver.cpp:106] Iteration 70125, lr = 0.0045
I0523 00:43:58.296777  3818 solver.cpp:237] Iteration 70500, loss = 1.32169
I0523 00:43:58.296825  3818 solver.cpp:253]     Train net output #0: loss = 1.32169 (* 1 = 1.32169 loss)
I0523 00:43:58.296839  3818 sgd_solver.cpp:106] Iteration 70500, lr = 0.0045
I0523 00:44:08.140983  3818 solver.cpp:237] Iteration 70875, loss = 1.16901
I0523 00:44:08.141019  3818 solver.cpp:253]     Train net output #0: loss = 1.16901 (* 1 = 1.16901 loss)
I0523 00:44:08.141034  3818 sgd_solver.cpp:106] Iteration 70875, lr = 0.0045
I0523 00:44:17.957867  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_71250.caffemodel
I0523 00:44:18.018627  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_71250.solverstate
I0523 00:44:18.055136  3818 solver.cpp:237] Iteration 71250, loss = 1.24594
I0523 00:44:18.055182  3818 solver.cpp:253]     Train net output #0: loss = 1.24594 (* 1 = 1.24594 loss)
I0523 00:44:18.055200  3818 sgd_solver.cpp:106] Iteration 71250, lr = 0.0045
I0523 00:44:27.898692  3818 solver.cpp:237] Iteration 71625, loss = 1.1122
I0523 00:44:27.898847  3818 solver.cpp:253]     Train net output #0: loss = 1.1122 (* 1 = 1.1122 loss)
I0523 00:44:27.898860  3818 sgd_solver.cpp:106] Iteration 71625, lr = 0.0045
I0523 00:44:37.734695  3818 solver.cpp:237] Iteration 72000, loss = 1.4581
I0523 00:44:37.734730  3818 solver.cpp:253]     Train net output #0: loss = 1.4581 (* 1 = 1.4581 loss)
I0523 00:44:37.734745  3818 sgd_solver.cpp:106] Iteration 72000, lr = 0.0045
I0523 00:44:47.575124  3818 solver.cpp:237] Iteration 72375, loss = 1.29517
I0523 00:44:47.575172  3818 solver.cpp:253]     Train net output #0: loss = 1.29517 (* 1 = 1.29517 loss)
I0523 00:44:47.575186  3818 sgd_solver.cpp:106] Iteration 72375, lr = 0.0045
I0523 00:45:18.346341  3818 solver.cpp:237] Iteration 72750, loss = 1.09087
I0523 00:45:18.346523  3818 solver.cpp:253]     Train net output #0: loss = 1.09087 (* 1 = 1.09087 loss)
I0523 00:45:18.346539  3818 sgd_solver.cpp:106] Iteration 72750, lr = 0.0045
I0523 00:45:28.180160  3818 solver.cpp:237] Iteration 73125, loss = 1.1193
I0523 00:45:28.180194  3818 solver.cpp:253]     Train net output #0: loss = 1.1193 (* 1 = 1.1193 loss)
I0523 00:45:28.180209  3818 sgd_solver.cpp:106] Iteration 73125, lr = 0.0045
I0523 00:45:38.024427  3818 solver.cpp:237] Iteration 73500, loss = 1.12948
I0523 00:45:38.024474  3818 solver.cpp:253]     Train net output #0: loss = 1.12948 (* 1 = 1.12948 loss)
I0523 00:45:38.024489  3818 sgd_solver.cpp:106] Iteration 73500, lr = 0.0045
I0523 00:45:47.865087  3818 solver.cpp:237] Iteration 73875, loss = 1.46544
I0523 00:45:47.865116  3818 solver.cpp:253]     Train net output #0: loss = 1.46544 (* 1 = 1.46544 loss)
I0523 00:45:47.865130  3818 sgd_solver.cpp:106] Iteration 73875, lr = 0.0045
I0523 00:45:57.706015  3818 solver.cpp:237] Iteration 74250, loss = 1.20236
I0523 00:45:57.706189  3818 solver.cpp:253]     Train net output #0: loss = 1.20236 (* 1 = 1.20236 loss)
I0523 00:45:57.706203  3818 sgd_solver.cpp:106] Iteration 74250, lr = 0.0045
I0523 00:46:07.545646  3818 solver.cpp:237] Iteration 74625, loss = 1.58442
I0523 00:46:07.545681  3818 solver.cpp:253]     Train net output #0: loss = 1.58442 (* 1 = 1.58442 loss)
I0523 00:46:07.545696  3818 sgd_solver.cpp:106] Iteration 74625, lr = 0.0045
I0523 00:46:17.357833  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_75000.caffemodel
I0523 00:46:17.415995  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_75000.solverstate
I0523 00:46:17.444515  3818 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 00:47:26.864701  3818 solver.cpp:409]     Test net output #0: accuracy = 0.893373
I0523 00:47:26.864876  3818 solver.cpp:409]     Test net output #1: loss = 0.356816 (* 1 = 0.356816 loss)
I0523 00:47:47.772043  3818 solver.cpp:237] Iteration 75000, loss = 1.2292
I0523 00:47:47.772096  3818 solver.cpp:253]     Train net output #0: loss = 1.2292 (* 1 = 1.2292 loss)
I0523 00:47:47.772112  3818 sgd_solver.cpp:106] Iteration 75000, lr = 0.0045
I0523 00:47:57.452949  3818 solver.cpp:237] Iteration 75375, loss = 0.975453
I0523 00:47:57.453114  3818 solver.cpp:253]     Train net output #0: loss = 0.975453 (* 1 = 0.975453 loss)
I0523 00:47:57.453126  3818 sgd_solver.cpp:106] Iteration 75375, lr = 0.0045
I0523 00:48:07.130578  3818 solver.cpp:237] Iteration 75750, loss = 1.11822
I0523 00:48:07.130620  3818 solver.cpp:253]     Train net output #0: loss = 1.11822 (* 1 = 1.11822 loss)
I0523 00:48:07.130638  3818 sgd_solver.cpp:106] Iteration 75750, lr = 0.0045
I0523 00:48:16.815006  3818 solver.cpp:237] Iteration 76125, loss = 1.01284
I0523 00:48:16.815042  3818 solver.cpp:253]     Train net output #0: loss = 1.01284 (* 1 = 1.01284 loss)
I0523 00:48:16.815057  3818 sgd_solver.cpp:106] Iteration 76125, lr = 0.0045
I0523 00:48:26.497758  3818 solver.cpp:237] Iteration 76500, loss = 0.95969
I0523 00:48:26.497795  3818 solver.cpp:253]     Train net output #0: loss = 0.95969 (* 1 = 0.95969 loss)
I0523 00:48:26.497809  3818 sgd_solver.cpp:106] Iteration 76500, lr = 0.0045
I0523 00:48:36.175132  3818 solver.cpp:237] Iteration 76875, loss = 0.709562
I0523 00:48:36.175295  3818 solver.cpp:253]     Train net output #0: loss = 0.709562 (* 1 = 0.709562 loss)
I0523 00:48:36.175309  3818 sgd_solver.cpp:106] Iteration 76875, lr = 0.0045
I0523 00:48:45.860102  3818 solver.cpp:237] Iteration 77250, loss = 1.44657
I0523 00:48:45.860137  3818 solver.cpp:253]     Train net output #0: loss = 1.44657 (* 1 = 1.44657 loss)
I0523 00:48:45.860152  3818 sgd_solver.cpp:106] Iteration 77250, lr = 0.0045
I0523 00:49:16.432696  3818 solver.cpp:237] Iteration 77625, loss = 1.02599
I0523 00:49:16.432878  3818 solver.cpp:253]     Train net output #0: loss = 1.02599 (* 1 = 1.02599 loss)
I0523 00:49:16.432894  3818 sgd_solver.cpp:106] Iteration 77625, lr = 0.0045
I0523 00:49:26.114807  3818 solver.cpp:237] Iteration 78000, loss = 0.862906
I0523 00:49:26.114855  3818 solver.cpp:253]     Train net output #0: loss = 0.862906 (* 1 = 0.862906 loss)
I0523 00:49:26.114869  3818 sgd_solver.cpp:106] Iteration 78000, lr = 0.0045
I0523 00:49:35.792640  3818 solver.cpp:237] Iteration 78375, loss = 1.5587
I0523 00:49:35.792677  3818 solver.cpp:253]     Train net output #0: loss = 1.5587 (* 1 = 1.5587 loss)
I0523 00:49:35.792691  3818 sgd_solver.cpp:106] Iteration 78375, lr = 0.0045
I0523 00:49:45.446449  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_78750.caffemodel
I0523 00:49:45.501945  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_78750.solverstate
I0523 00:49:45.536228  3818 solver.cpp:237] Iteration 78750, loss = 1.16062
I0523 00:49:45.536270  3818 solver.cpp:253]     Train net output #0: loss = 1.16062 (* 1 = 1.16062 loss)
I0523 00:49:45.536291  3818 sgd_solver.cpp:106] Iteration 78750, lr = 0.0045
I0523 00:49:55.218966  3818 solver.cpp:237] Iteration 79125, loss = 1.28025
I0523 00:49:55.219141  3818 solver.cpp:253]     Train net output #0: loss = 1.28025 (* 1 = 1.28025 loss)
I0523 00:49:55.219156  3818 sgd_solver.cpp:106] Iteration 79125, lr = 0.0045
I0523 00:50:04.898643  3818 solver.cpp:237] Iteration 79500, loss = 1.03109
I0523 00:50:04.898679  3818 solver.cpp:253]     Train net output #0: loss = 1.03109 (* 1 = 1.03109 loss)
I0523 00:50:04.898694  3818 sgd_solver.cpp:106] Iteration 79500, lr = 0.0045
I0523 00:50:14.580775  3818 solver.cpp:237] Iteration 79875, loss = 1.18689
I0523 00:50:14.580819  3818 solver.cpp:253]     Train net output #0: loss = 1.18689 (* 1 = 1.18689 loss)
I0523 00:50:14.580833  3818 sgd_solver.cpp:106] Iteration 79875, lr = 0.0045
I0523 00:50:45.147104  3818 solver.cpp:237] Iteration 80250, loss = 0.88822
I0523 00:50:45.147287  3818 solver.cpp:253]     Train net output #0: loss = 0.88822 (* 1 = 0.88822 loss)
I0523 00:50:45.147303  3818 sgd_solver.cpp:106] Iteration 80250, lr = 0.0045
I0523 00:50:54.829577  3818 solver.cpp:237] Iteration 80625, loss = 0.994953
I0523 00:50:54.829613  3818 solver.cpp:253]     Train net output #0: loss = 0.994953 (* 1 = 0.994953 loss)
I0523 00:50:54.829628  3818 sgd_solver.cpp:106] Iteration 80625, lr = 0.0045
I0523 00:51:04.514758  3818 solver.cpp:237] Iteration 81000, loss = 1.67976
I0523 00:51:04.514809  3818 solver.cpp:253]     Train net output #0: loss = 1.67976 (* 1 = 1.67976 loss)
I0523 00:51:04.514823  3818 sgd_solver.cpp:106] Iteration 81000, lr = 0.0045
I0523 00:51:14.196511  3818 solver.cpp:237] Iteration 81375, loss = 1.12251
I0523 00:51:14.196547  3818 solver.cpp:253]     Train net output #0: loss = 1.12251 (* 1 = 1.12251 loss)
I0523 00:51:14.196562  3818 sgd_solver.cpp:106] Iteration 81375, lr = 0.0045
I0523 00:51:23.882212  3818 solver.cpp:237] Iteration 81750, loss = 1.34295
I0523 00:51:23.882375  3818 solver.cpp:253]     Train net output #0: loss = 1.34295 (* 1 = 1.34295 loss)
I0523 00:51:23.882388  3818 sgd_solver.cpp:106] Iteration 81750, lr = 0.0045
I0523 00:51:33.568223  3818 solver.cpp:237] Iteration 82125, loss = 1.38861
I0523 00:51:33.568259  3818 solver.cpp:253]     Train net output #0: loss = 1.38861 (* 1 = 1.38861 loss)
I0523 00:51:33.568274  3818 sgd_solver.cpp:106] Iteration 82125, lr = 0.0045
I0523 00:51:43.229657  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_82500.caffemodel
I0523 00:51:43.284759  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_82500.solverstate
I0523 00:51:43.310878  3818 solver.cpp:341] Iteration 82500, Testing net (#0)
I0523 00:52:31.511732  3818 solver.cpp:409]     Test net output #0: accuracy = 0.894574
I0523 00:52:31.511910  3818 solver.cpp:409]     Test net output #1: loss = 0.337453 (* 1 = 0.337453 loss)
I0523 00:52:52.449738  3818 solver.cpp:237] Iteration 82500, loss = 1.18462
I0523 00:52:52.449790  3818 solver.cpp:253]     Train net output #0: loss = 1.18462 (* 1 = 1.18462 loss)
I0523 00:52:52.449805  3818 sgd_solver.cpp:106] Iteration 82500, lr = 0.0045
I0523 00:53:02.310935  3818 solver.cpp:237] Iteration 82875, loss = 1.21614
I0523 00:53:02.311117  3818 solver.cpp:253]     Train net output #0: loss = 1.21614 (* 1 = 1.21614 loss)
I0523 00:53:02.311131  3818 sgd_solver.cpp:106] Iteration 82875, lr = 0.0045
I0523 00:53:12.177394  3818 solver.cpp:237] Iteration 83250, loss = 1.00405
I0523 00:53:12.177430  3818 solver.cpp:253]     Train net output #0: loss = 1.00405 (* 1 = 1.00405 loss)
I0523 00:53:12.177444  3818 sgd_solver.cpp:106] Iteration 83250, lr = 0.0045
I0523 00:53:22.045061  3818 solver.cpp:237] Iteration 83625, loss = 1.39086
I0523 00:53:22.045097  3818 solver.cpp:253]     Train net output #0: loss = 1.39086 (* 1 = 1.39086 loss)
I0523 00:53:22.045111  3818 sgd_solver.cpp:106] Iteration 83625, lr = 0.0045
I0523 00:53:31.904376  3818 solver.cpp:237] Iteration 84000, loss = 1.0152
I0523 00:53:31.904418  3818 solver.cpp:253]     Train net output #0: loss = 1.0152 (* 1 = 1.0152 loss)
I0523 00:53:31.904433  3818 sgd_solver.cpp:106] Iteration 84000, lr = 0.0045
I0523 00:53:41.768342  3818 solver.cpp:237] Iteration 84375, loss = 1.22892
I0523 00:53:41.768498  3818 solver.cpp:253]     Train net output #0: loss = 1.22892 (* 1 = 1.22892 loss)
I0523 00:53:41.768512  3818 sgd_solver.cpp:106] Iteration 84375, lr = 0.0045
I0523 00:53:51.631745  3818 solver.cpp:237] Iteration 84750, loss = 1.14251
I0523 00:53:51.631783  3818 solver.cpp:253]     Train net output #0: loss = 1.14251 (* 1 = 1.14251 loss)
I0523 00:53:51.631799  3818 sgd_solver.cpp:106] Iteration 84750, lr = 0.0045
I0523 00:54:22.398970  3818 solver.cpp:237] Iteration 85125, loss = 1.40913
I0523 00:54:22.399163  3818 solver.cpp:253]     Train net output #0: loss = 1.40913 (* 1 = 1.40913 loss)
I0523 00:54:22.399179  3818 sgd_solver.cpp:106] Iteration 85125, lr = 0.0045
I0523 00:54:32.264889  3818 solver.cpp:237] Iteration 85500, loss = 0.892848
I0523 00:54:32.264925  3818 solver.cpp:253]     Train net output #0: loss = 0.892848 (* 1 = 0.892848 loss)
I0523 00:54:32.264940  3818 sgd_solver.cpp:106] Iteration 85500, lr = 0.0045
I0523 00:54:42.128901  3818 solver.cpp:237] Iteration 85875, loss = 1.21464
I0523 00:54:42.128949  3818 solver.cpp:253]     Train net output #0: loss = 1.21464 (* 1 = 1.21464 loss)
I0523 00:54:42.128963  3818 sgd_solver.cpp:106] Iteration 85875, lr = 0.0045
I0523 00:54:51.962543  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_86250.caffemodel
I0523 00:54:52.018013  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_86250.solverstate
I0523 00:54:52.052358  3818 solver.cpp:237] Iteration 86250, loss = 1.07104
I0523 00:54:52.052403  3818 solver.cpp:253]     Train net output #0: loss = 1.07104 (* 1 = 1.07104 loss)
I0523 00:54:52.052419  3818 sgd_solver.cpp:106] Iteration 86250, lr = 0.0045
I0523 00:55:01.922678  3818 solver.cpp:237] Iteration 86625, loss = 1.17047
I0523 00:55:01.922833  3818 solver.cpp:253]     Train net output #0: loss = 1.17047 (* 1 = 1.17047 loss)
I0523 00:55:01.922847  3818 sgd_solver.cpp:106] Iteration 86625, lr = 0.0045
I0523 00:55:11.783958  3818 solver.cpp:237] Iteration 87000, loss = 1.13323
I0523 00:55:11.784003  3818 solver.cpp:253]     Train net output #0: loss = 1.13323 (* 1 = 1.13323 loss)
I0523 00:55:11.784021  3818 sgd_solver.cpp:106] Iteration 87000, lr = 0.0045
I0523 00:55:21.649562  3818 solver.cpp:237] Iteration 87375, loss = 1.17139
I0523 00:55:21.649598  3818 solver.cpp:253]     Train net output #0: loss = 1.17139 (* 1 = 1.17139 loss)
I0523 00:55:21.649613  3818 sgd_solver.cpp:106] Iteration 87375, lr = 0.0045
I0523 00:55:52.402077  3818 solver.cpp:237] Iteration 87750, loss = 1.03239
I0523 00:55:52.402258  3818 solver.cpp:253]     Train net output #0: loss = 1.03239 (* 1 = 1.03239 loss)
I0523 00:55:52.402276  3818 sgd_solver.cpp:106] Iteration 87750, lr = 0.0045
I0523 00:56:02.269744  3818 solver.cpp:237] Iteration 88125, loss = 1.49167
I0523 00:56:02.269789  3818 solver.cpp:253]     Train net output #0: loss = 1.49167 (* 1 = 1.49167 loss)
I0523 00:56:02.269805  3818 sgd_solver.cpp:106] Iteration 88125, lr = 0.0045
I0523 00:56:12.135614  3818 solver.cpp:237] Iteration 88500, loss = 1.2387
I0523 00:56:12.135649  3818 solver.cpp:253]     Train net output #0: loss = 1.2387 (* 1 = 1.2387 loss)
I0523 00:56:12.135664  3818 sgd_solver.cpp:106] Iteration 88500, lr = 0.0045
I0523 00:56:22.002362  3818 solver.cpp:237] Iteration 88875, loss = 1.20228
I0523 00:56:22.002406  3818 solver.cpp:253]     Train net output #0: loss = 1.20228 (* 1 = 1.20228 loss)
I0523 00:56:22.002421  3818 sgd_solver.cpp:106] Iteration 88875, lr = 0.0045
I0523 00:56:31.868562  3818 solver.cpp:237] Iteration 89250, loss = 1.18177
I0523 00:56:31.868728  3818 solver.cpp:253]     Train net output #0: loss = 1.18177 (* 1 = 1.18177 loss)
I0523 00:56:31.868742  3818 sgd_solver.cpp:106] Iteration 89250, lr = 0.0045
I0523 00:56:41.730741  3818 solver.cpp:237] Iteration 89625, loss = 1.12356
I0523 00:56:41.730774  3818 solver.cpp:253]     Train net output #0: loss = 1.12356 (* 1 = 1.12356 loss)
I0523 00:56:41.730790  3818 sgd_solver.cpp:106] Iteration 89625, lr = 0.0045
I0523 00:56:51.571549  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_90000.caffemodel
I0523 00:56:51.628823  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_90000.solverstate
I0523 00:56:51.655242  3818 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 00:58:01.146339  3818 solver.cpp:409]     Test net output #0: accuracy = 0.893286
I0523 00:58:01.146522  3818 solver.cpp:409]     Test net output #1: loss = 0.358177 (* 1 = 0.358177 loss)
I0523 00:58:22.035053  3818 solver.cpp:237] Iteration 90000, loss = 0.89852
I0523 00:58:22.035104  3818 solver.cpp:253]     Train net output #0: loss = 0.89852 (* 1 = 0.89852 loss)
I0523 00:58:22.035120  3818 sgd_solver.cpp:106] Iteration 90000, lr = 0.0045
I0523 00:58:31.920804  3818 solver.cpp:237] Iteration 90375, loss = 0.959434
I0523 00:58:31.920981  3818 solver.cpp:253]     Train net output #0: loss = 0.959434 (* 1 = 0.959434 loss)
I0523 00:58:31.920995  3818 sgd_solver.cpp:106] Iteration 90375, lr = 0.0045
I0523 00:58:41.809540  3818 solver.cpp:237] Iteration 90750, loss = 1.15714
I0523 00:58:41.809576  3818 solver.cpp:253]     Train net output #0: loss = 1.15714 (* 1 = 1.15714 loss)
I0523 00:58:41.809592  3818 sgd_solver.cpp:106] Iteration 90750, lr = 0.0045
I0523 00:58:51.698272  3818 solver.cpp:237] Iteration 91125, loss = 1.3301
I0523 00:58:51.698315  3818 solver.cpp:253]     Train net output #0: loss = 1.3301 (* 1 = 1.3301 loss)
I0523 00:58:51.698330  3818 sgd_solver.cpp:106] Iteration 91125, lr = 0.0045
I0523 00:59:01.587580  3818 solver.cpp:237] Iteration 91500, loss = 1.15062
I0523 00:59:01.587616  3818 solver.cpp:253]     Train net output #0: loss = 1.15062 (* 1 = 1.15062 loss)
I0523 00:59:01.587630  3818 sgd_solver.cpp:106] Iteration 91500, lr = 0.0045
I0523 00:59:11.474045  3818 solver.cpp:237] Iteration 91875, loss = 1.36261
I0523 00:59:11.474210  3818 solver.cpp:253]     Train net output #0: loss = 1.36261 (* 1 = 1.36261 loss)
I0523 00:59:11.474225  3818 sgd_solver.cpp:106] Iteration 91875, lr = 0.0045
I0523 00:59:21.365880  3818 solver.cpp:237] Iteration 92250, loss = 1.05413
I0523 00:59:21.365927  3818 solver.cpp:253]     Train net output #0: loss = 1.05413 (* 1 = 1.05413 loss)
I0523 00:59:21.365942  3818 sgd_solver.cpp:106] Iteration 92250, lr = 0.0045
I0523 00:59:52.149175  3818 solver.cpp:237] Iteration 92625, loss = 1.1226
I0523 00:59:52.149356  3818 solver.cpp:253]     Train net output #0: loss = 1.1226 (* 1 = 1.1226 loss)
I0523 00:59:52.149371  3818 sgd_solver.cpp:106] Iteration 92625, lr = 0.0045
I0523 01:00:02.030577  3818 solver.cpp:237] Iteration 93000, loss = 0.867779
I0523 01:00:02.030613  3818 solver.cpp:253]     Train net output #0: loss = 0.867779 (* 1 = 0.867779 loss)
I0523 01:00:02.030628  3818 sgd_solver.cpp:106] Iteration 93000, lr = 0.0045
I0523 01:00:11.916348  3818 solver.cpp:237] Iteration 93375, loss = 1.24081
I0523 01:00:11.916393  3818 solver.cpp:253]     Train net output #0: loss = 1.24081 (* 1 = 1.24081 loss)
I0523 01:00:11.916409  3818 sgd_solver.cpp:106] Iteration 93375, lr = 0.0045
I0523 01:00:21.778525  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_93750.caffemodel
I0523 01:00:21.836761  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_93750.solverstate
I0523 01:00:21.873340  3818 solver.cpp:237] Iteration 93750, loss = 0.929976
I0523 01:00:21.873392  3818 solver.cpp:253]     Train net output #0: loss = 0.929976 (* 1 = 0.929976 loss)
I0523 01:00:21.873407  3818 sgd_solver.cpp:106] Iteration 93750, lr = 0.0045
I0523 01:00:31.769088  3818 solver.cpp:237] Iteration 94125, loss = 1.32132
I0523 01:00:31.769282  3818 solver.cpp:253]     Train net output #0: loss = 1.32132 (* 1 = 1.32132 loss)
I0523 01:00:31.769297  3818 sgd_solver.cpp:106] Iteration 94125, lr = 0.0045
I0523 01:00:41.653951  3818 solver.cpp:237] Iteration 94500, loss = 1.26208
I0523 01:00:41.653986  3818 solver.cpp:253]     Train net output #0: loss = 1.26208 (* 1 = 1.26208 loss)
I0523 01:00:41.654001  3818 sgd_solver.cpp:106] Iteration 94500, lr = 0.0045
I0523 01:00:51.547732  3818 solver.cpp:237] Iteration 94875, loss = 1.13704
I0523 01:00:51.547768  3818 solver.cpp:253]     Train net output #0: loss = 1.13704 (* 1 = 1.13704 loss)
I0523 01:00:51.547782  3818 sgd_solver.cpp:106] Iteration 94875, lr = 0.0045
I0523 01:01:22.342988  3818 solver.cpp:237] Iteration 95250, loss = 1.05098
I0523 01:01:22.343168  3818 solver.cpp:253]     Train net output #0: loss = 1.05098 (* 1 = 1.05098 loss)
I0523 01:01:22.343183  3818 sgd_solver.cpp:106] Iteration 95250, lr = 0.0045
I0523 01:01:32.227893  3818 solver.cpp:237] Iteration 95625, loss = 1.09534
I0523 01:01:32.227928  3818 solver.cpp:253]     Train net output #0: loss = 1.09534 (* 1 = 1.09534 loss)
I0523 01:01:32.227943  3818 sgd_solver.cpp:106] Iteration 95625, lr = 0.0045
I0523 01:01:42.118098  3818 solver.cpp:237] Iteration 96000, loss = 1.28899
I0523 01:01:42.118134  3818 solver.cpp:253]     Train net output #0: loss = 1.28899 (* 1 = 1.28899 loss)
I0523 01:01:42.118149  3818 sgd_solver.cpp:106] Iteration 96000, lr = 0.0045
I0523 01:01:52.004375  3818 solver.cpp:237] Iteration 96375, loss = 1.26107
I0523 01:01:52.004423  3818 solver.cpp:253]     Train net output #0: loss = 1.26107 (* 1 = 1.26107 loss)
I0523 01:01:52.004437  3818 sgd_solver.cpp:106] Iteration 96375, lr = 0.0045
I0523 01:02:01.890238  3818 solver.cpp:237] Iteration 96750, loss = 1.20752
I0523 01:02:01.890395  3818 solver.cpp:253]     Train net output #0: loss = 1.20752 (* 1 = 1.20752 loss)
I0523 01:02:01.890408  3818 sgd_solver.cpp:106] Iteration 96750, lr = 0.0045
I0523 01:02:11.780992  3818 solver.cpp:237] Iteration 97125, loss = 0.832792
I0523 01:02:11.781034  3818 solver.cpp:253]     Train net output #0: loss = 0.832792 (* 1 = 0.832792 loss)
I0523 01:02:11.781049  3818 sgd_solver.cpp:106] Iteration 97125, lr = 0.0045
I0523 01:02:21.642849  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_97500.caffemodel
I0523 01:02:21.698807  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_97500.solverstate
I0523 01:02:21.724858  3818 solver.cpp:341] Iteration 97500, Testing net (#0)
I0523 01:03:10.234611  3818 solver.cpp:409]     Test net output #0: accuracy = 0.895777
I0523 01:03:10.234798  3818 solver.cpp:409]     Test net output #1: loss = 0.340343 (* 1 = 0.340343 loss)
I0523 01:03:31.138257  3818 solver.cpp:237] Iteration 97500, loss = 0.914887
I0523 01:03:31.138309  3818 solver.cpp:253]     Train net output #0: loss = 0.914887 (* 1 = 0.914887 loss)
I0523 01:03:31.138325  3818 sgd_solver.cpp:106] Iteration 97500, lr = 0.0045
I0523 01:03:40.978945  3818 solver.cpp:237] Iteration 97875, loss = 0.950181
I0523 01:03:40.979120  3818 solver.cpp:253]     Train net output #0: loss = 0.950181 (* 1 = 0.950181 loss)
I0523 01:03:40.979135  3818 sgd_solver.cpp:106] Iteration 97875, lr = 0.0045
I0523 01:03:50.816092  3818 solver.cpp:237] Iteration 98250, loss = 1.20755
I0523 01:03:50.816128  3818 solver.cpp:253]     Train net output #0: loss = 1.20755 (* 1 = 1.20755 loss)
I0523 01:03:50.816143  3818 sgd_solver.cpp:106] Iteration 98250, lr = 0.0045
I0523 01:04:00.655547  3818 solver.cpp:237] Iteration 98625, loss = 1.18065
I0523 01:04:00.655586  3818 solver.cpp:253]     Train net output #0: loss = 1.18065 (* 1 = 1.18065 loss)
I0523 01:04:00.655602  3818 sgd_solver.cpp:106] Iteration 98625, lr = 0.0045
I0523 01:04:10.495034  3818 solver.cpp:237] Iteration 99000, loss = 1.41531
I0523 01:04:10.495070  3818 solver.cpp:253]     Train net output #0: loss = 1.41531 (* 1 = 1.41531 loss)
I0523 01:04:10.495085  3818 sgd_solver.cpp:106] Iteration 99000, lr = 0.0045
I0523 01:04:20.334255  3818 solver.cpp:237] Iteration 99375, loss = 1.18611
I0523 01:04:20.334425  3818 solver.cpp:253]     Train net output #0: loss = 1.18611 (* 1 = 1.18611 loss)
I0523 01:04:20.334439  3818 sgd_solver.cpp:106] Iteration 99375, lr = 0.0045
I0523 01:04:30.176923  3818 solver.cpp:237] Iteration 99750, loss = 0.904102
I0523 01:04:30.176959  3818 solver.cpp:253]     Train net output #0: loss = 0.904102 (* 1 = 0.904102 loss)
I0523 01:04:30.176975  3818 sgd_solver.cpp:106] Iteration 99750, lr = 0.0045
I0523 01:05:00.911689  3818 solver.cpp:237] Iteration 100125, loss = 1.02674
I0523 01:05:00.911872  3818 solver.cpp:253]     Train net output #0: loss = 1.02674 (* 1 = 1.02674 loss)
I0523 01:05:00.911887  3818 sgd_solver.cpp:106] Iteration 100125, lr = 0.0045
I0523 01:05:10.746481  3818 solver.cpp:237] Iteration 100500, loss = 1.05388
I0523 01:05:10.746527  3818 solver.cpp:253]     Train net output #0: loss = 1.05388 (* 1 = 1.05388 loss)
I0523 01:05:10.746543  3818 sgd_solver.cpp:106] Iteration 100500, lr = 0.0045
I0523 01:05:20.579717  3818 solver.cpp:237] Iteration 100875, loss = 1.22751
I0523 01:05:20.579753  3818 solver.cpp:253]     Train net output #0: loss = 1.22751 (* 1 = 1.22751 loss)
I0523 01:05:20.579767  3818 sgd_solver.cpp:106] Iteration 100875, lr = 0.0045
I0523 01:05:30.390954  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_101250.caffemodel
I0523 01:05:30.446722  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_101250.solverstate
I0523 01:05:30.479442  3818 solver.cpp:237] Iteration 101250, loss = 1.17461
I0523 01:05:30.479487  3818 solver.cpp:253]     Train net output #0: loss = 1.17461 (* 1 = 1.17461 loss)
I0523 01:05:30.479504  3818 sgd_solver.cpp:106] Iteration 101250, lr = 0.0045
I0523 01:05:40.320960  3818 solver.cpp:237] Iteration 101625, loss = 1.13862
I0523 01:05:40.321137  3818 solver.cpp:253]     Train net output #0: loss = 1.13862 (* 1 = 1.13862 loss)
I0523 01:05:40.321152  3818 sgd_solver.cpp:106] Iteration 101625, lr = 0.0045
I0523 01:05:50.155939  3818 solver.cpp:237] Iteration 102000, loss = 1.02714
I0523 01:05:50.155974  3818 solver.cpp:253]     Train net output #0: loss = 1.02714 (* 1 = 1.02714 loss)
I0523 01:05:50.155990  3818 sgd_solver.cpp:106] Iteration 102000, lr = 0.0045
I0523 01:06:00.001010  3818 solver.cpp:237] Iteration 102375, loss = 1.11476
I0523 01:06:00.001055  3818 solver.cpp:253]     Train net output #0: loss = 1.11476 (* 1 = 1.11476 loss)
I0523 01:06:00.001070  3818 sgd_solver.cpp:106] Iteration 102375, lr = 0.0045
I0523 01:06:30.755928  3818 solver.cpp:237] Iteration 102750, loss = 1.17489
I0523 01:06:30.756120  3818 solver.cpp:253]     Train net output #0: loss = 1.17489 (* 1 = 1.17489 loss)
I0523 01:06:30.756139  3818 sgd_solver.cpp:106] Iteration 102750, lr = 0.0045
I0523 01:06:40.597385  3818 solver.cpp:237] Iteration 103125, loss = 1.30406
I0523 01:06:40.597421  3818 solver.cpp:253]     Train net output #0: loss = 1.30406 (* 1 = 1.30406 loss)
I0523 01:06:40.597435  3818 sgd_solver.cpp:106] Iteration 103125, lr = 0.0045
I0523 01:06:50.437052  3818 solver.cpp:237] Iteration 103500, loss = 1.31915
I0523 01:06:50.437098  3818 solver.cpp:253]     Train net output #0: loss = 1.31915 (* 1 = 1.31915 loss)
I0523 01:06:50.437113  3818 sgd_solver.cpp:106] Iteration 103500, lr = 0.0045
I0523 01:07:00.274667  3818 solver.cpp:237] Iteration 103875, loss = 1.00207
I0523 01:07:00.274703  3818 solver.cpp:253]     Train net output #0: loss = 1.00207 (* 1 = 1.00207 loss)
I0523 01:07:00.274716  3818 sgd_solver.cpp:106] Iteration 103875, lr = 0.0045
I0523 01:07:10.108805  3818 solver.cpp:237] Iteration 104250, loss = 1.17079
I0523 01:07:10.108971  3818 solver.cpp:253]     Train net output #0: loss = 1.17079 (* 1 = 1.17079 loss)
I0523 01:07:10.108985  3818 sgd_solver.cpp:106] Iteration 104250, lr = 0.0045
I0523 01:07:19.951149  3818 solver.cpp:237] Iteration 104625, loss = 1.25048
I0523 01:07:19.951196  3818 solver.cpp:253]     Train net output #0: loss = 1.25048 (* 1 = 1.25048 loss)
I0523 01:07:19.951210  3818 sgd_solver.cpp:106] Iteration 104625, lr = 0.0045
I0523 01:07:29.766082  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_105000.caffemodel
I0523 01:07:29.822185  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_105000.solverstate
I0523 01:07:29.847499  3818 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 01:08:39.306229  3818 solver.cpp:409]     Test net output #0: accuracy = 0.895526
I0523 01:08:39.306413  3818 solver.cpp:409]     Test net output #1: loss = 0.32759 (* 1 = 0.32759 loss)
I0523 01:09:00.263005  3818 solver.cpp:237] Iteration 105000, loss = 1.52457
I0523 01:09:00.263057  3818 solver.cpp:253]     Train net output #0: loss = 1.52457 (* 1 = 1.52457 loss)
I0523 01:09:00.263073  3818 sgd_solver.cpp:106] Iteration 105000, lr = 0.0045
I0523 01:09:09.945145  3818 solver.cpp:237] Iteration 105375, loss = 1.20843
I0523 01:09:09.945317  3818 solver.cpp:253]     Train net output #0: loss = 1.20843 (* 1 = 1.20843 loss)
I0523 01:09:09.945330  3818 sgd_solver.cpp:106] Iteration 105375, lr = 0.0045
I0523 01:09:19.634827  3818 solver.cpp:237] Iteration 105750, loss = 0.67703
I0523 01:09:19.634872  3818 solver.cpp:253]     Train net output #0: loss = 0.67703 (* 1 = 0.67703 loss)
I0523 01:09:19.634887  3818 sgd_solver.cpp:106] Iteration 105750, lr = 0.0045
I0523 01:09:29.315142  3818 solver.cpp:237] Iteration 106125, loss = 1.23122
I0523 01:09:29.315178  3818 solver.cpp:253]     Train net output #0: loss = 1.23122 (* 1 = 1.23122 loss)
I0523 01:09:29.315193  3818 sgd_solver.cpp:106] Iteration 106125, lr = 0.0045
I0523 01:09:38.994735  3818 solver.cpp:237] Iteration 106500, loss = 1.03023
I0523 01:09:38.994771  3818 solver.cpp:253]     Train net output #0: loss = 1.03023 (* 1 = 1.03023 loss)
I0523 01:09:38.994786  3818 sgd_solver.cpp:106] Iteration 106500, lr = 0.0045
I0523 01:09:48.707590  3818 solver.cpp:237] Iteration 106875, loss = 1.12466
I0523 01:09:48.707770  3818 solver.cpp:253]     Train net output #0: loss = 1.12466 (* 1 = 1.12466 loss)
I0523 01:09:48.707784  3818 sgd_solver.cpp:106] Iteration 106875, lr = 0.0045
I0523 01:09:58.421388  3818 solver.cpp:237] Iteration 107250, loss = 1.18502
I0523 01:09:58.421423  3818 solver.cpp:253]     Train net output #0: loss = 1.18502 (* 1 = 1.18502 loss)
I0523 01:09:58.421438  3818 sgd_solver.cpp:106] Iteration 107250, lr = 0.0045
I0523 01:10:29.076496  3818 solver.cpp:237] Iteration 107625, loss = 1.03341
I0523 01:10:29.076690  3818 solver.cpp:253]     Train net output #0: loss = 1.03341 (* 1 = 1.03341 loss)
I0523 01:10:29.076706  3818 sgd_solver.cpp:106] Iteration 107625, lr = 0.0045
I0523 01:10:38.795276  3818 solver.cpp:237] Iteration 108000, loss = 1.37462
I0523 01:10:38.795313  3818 solver.cpp:253]     Train net output #0: loss = 1.37462 (* 1 = 1.37462 loss)
I0523 01:10:38.795327  3818 sgd_solver.cpp:106] Iteration 108000, lr = 0.0045
I0523 01:10:48.521076  3818 solver.cpp:237] Iteration 108375, loss = 0.92936
I0523 01:10:48.521112  3818 solver.cpp:253]     Train net output #0: loss = 0.92936 (* 1 = 0.92936 loss)
I0523 01:10:48.521127  3818 sgd_solver.cpp:106] Iteration 108375, lr = 0.0045
I0523 01:10:58.218724  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_108750.caffemodel
I0523 01:10:58.276573  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_108750.solverstate
I0523 01:10:58.311923  3818 solver.cpp:237] Iteration 108750, loss = 1.49224
I0523 01:10:58.311975  3818 solver.cpp:253]     Train net output #0: loss = 1.49224 (* 1 = 1.49224 loss)
I0523 01:10:58.311990  3818 sgd_solver.cpp:106] Iteration 108750, lr = 0.0045
I0523 01:11:08.026034  3818 solver.cpp:237] Iteration 109125, loss = 1.37943
I0523 01:11:08.026207  3818 solver.cpp:253]     Train net output #0: loss = 1.37943 (* 1 = 1.37943 loss)
I0523 01:11:08.026221  3818 sgd_solver.cpp:106] Iteration 109125, lr = 0.0045
I0523 01:11:17.751688  3818 solver.cpp:237] Iteration 109500, loss = 1.3122
I0523 01:11:17.751724  3818 solver.cpp:253]     Train net output #0: loss = 1.3122 (* 1 = 1.3122 loss)
I0523 01:11:17.751739  3818 sgd_solver.cpp:106] Iteration 109500, lr = 0.0045
I0523 01:11:27.466629  3818 solver.cpp:237] Iteration 109875, loss = 1.12323
I0523 01:11:27.466670  3818 solver.cpp:253]     Train net output #0: loss = 1.12323 (* 1 = 1.12323 loss)
I0523 01:11:27.466688  3818 sgd_solver.cpp:106] Iteration 109875, lr = 0.0045
I0523 01:11:58.125651  3818 solver.cpp:237] Iteration 110250, loss = 1.12725
I0523 01:11:58.125836  3818 solver.cpp:253]     Train net output #0: loss = 1.12725 (* 1 = 1.12725 loss)
I0523 01:11:58.125850  3818 sgd_solver.cpp:106] Iteration 110250, lr = 0.0045
I0523 01:12:07.849726  3818 solver.cpp:237] Iteration 110625, loss = 0.909784
I0523 01:12:07.849758  3818 solver.cpp:253]     Train net output #0: loss = 0.909784 (* 1 = 0.909784 loss)
I0523 01:12:07.849776  3818 sgd_solver.cpp:106] Iteration 110625, lr = 0.0045
I0523 01:12:17.569710  3818 solver.cpp:237] Iteration 111000, loss = 1.0432
I0523 01:12:17.569756  3818 solver.cpp:253]     Train net output #0: loss = 1.0432 (* 1 = 1.0432 loss)
I0523 01:12:17.569772  3818 sgd_solver.cpp:106] Iteration 111000, lr = 0.0045
I0523 01:12:27.283926  3818 solver.cpp:237] Iteration 111375, loss = 1.29708
I0523 01:12:27.283962  3818 solver.cpp:253]     Train net output #0: loss = 1.29708 (* 1 = 1.29708 loss)
I0523 01:12:27.283975  3818 sgd_solver.cpp:106] Iteration 111375, lr = 0.0045
I0523 01:12:37.011292  3818 solver.cpp:237] Iteration 111750, loss = 1.17945
I0523 01:12:37.011464  3818 solver.cpp:253]     Train net output #0: loss = 1.17945 (* 1 = 1.17945 loss)
I0523 01:12:37.011479  3818 sgd_solver.cpp:106] Iteration 111750, lr = 0.0045
I0523 01:12:46.730865  3818 solver.cpp:237] Iteration 112125, loss = 1.23477
I0523 01:12:46.730900  3818 solver.cpp:253]     Train net output #0: loss = 1.23477 (* 1 = 1.23477 loss)
I0523 01:12:46.730916  3818 sgd_solver.cpp:106] Iteration 112125, lr = 0.0045
I0523 01:12:56.438387  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_112500.caffemodel
I0523 01:12:56.496654  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_112500.solverstate
I0523 01:12:56.524524  3818 solver.cpp:341] Iteration 112500, Testing net (#0)
I0523 01:13:44.758280  3818 solver.cpp:409]     Test net output #0: accuracy = 0.89898
I0523 01:13:44.758481  3818 solver.cpp:409]     Test net output #1: loss = 0.342327 (* 1 = 0.342327 loss)
I0523 01:14:05.706343  3818 solver.cpp:237] Iteration 112500, loss = 0.946015
I0523 01:14:05.706396  3818 solver.cpp:253]     Train net output #0: loss = 0.946015 (* 1 = 0.946015 loss)
I0523 01:14:05.706413  3818 sgd_solver.cpp:106] Iteration 112500, lr = 0.0045
I0523 01:14:15.575676  3818 solver.cpp:237] Iteration 112875, loss = 1.06706
I0523 01:14:15.575847  3818 solver.cpp:253]     Train net output #0: loss = 1.06706 (* 1 = 1.06706 loss)
I0523 01:14:15.575860  3818 sgd_solver.cpp:106] Iteration 112875, lr = 0.0045
I0523 01:14:25.449291  3818 solver.cpp:237] Iteration 113250, loss = 1.14824
I0523 01:14:25.449336  3818 solver.cpp:253]     Train net output #0: loss = 1.14824 (* 1 = 1.14824 loss)
I0523 01:14:25.449349  3818 sgd_solver.cpp:106] Iteration 113250, lr = 0.0045
I0523 01:14:35.319320  3818 solver.cpp:237] Iteration 113625, loss = 0.985968
I0523 01:14:35.319358  3818 solver.cpp:253]     Train net output #0: loss = 0.985968 (* 1 = 0.985968 loss)
I0523 01:14:35.319371  3818 sgd_solver.cpp:106] Iteration 113625, lr = 0.0045
I0523 01:14:45.195967  3818 solver.cpp:237] Iteration 114000, loss = 1.19437
I0523 01:14:45.196015  3818 solver.cpp:253]     Train net output #0: loss = 1.19437 (* 1 = 1.19437 loss)
I0523 01:14:45.196030  3818 sgd_solver.cpp:106] Iteration 114000, lr = 0.0045
I0523 01:14:55.071907  3818 solver.cpp:237] Iteration 114375, loss = 1.23487
I0523 01:14:55.072077  3818 solver.cpp:253]     Train net output #0: loss = 1.23487 (* 1 = 1.23487 loss)
I0523 01:14:55.072090  3818 sgd_solver.cpp:106] Iteration 114375, lr = 0.0045
I0523 01:15:04.947006  3818 solver.cpp:237] Iteration 114750, loss = 1.17404
I0523 01:15:04.947041  3818 solver.cpp:253]     Train net output #0: loss = 1.17404 (* 1 = 1.17404 loss)
I0523 01:15:04.947057  3818 sgd_solver.cpp:106] Iteration 114750, lr = 0.0045
I0523 01:15:35.742683  3818 solver.cpp:237] Iteration 115125, loss = 1.29429
I0523 01:15:35.742873  3818 solver.cpp:253]     Train net output #0: loss = 1.29429 (* 1 = 1.29429 loss)
I0523 01:15:35.742888  3818 sgd_solver.cpp:106] Iteration 115125, lr = 0.0045
I0523 01:15:45.614274  3818 solver.cpp:237] Iteration 115500, loss = 1.04843
I0523 01:15:45.614308  3818 solver.cpp:253]     Train net output #0: loss = 1.04843 (* 1 = 1.04843 loss)
I0523 01:15:45.614323  3818 sgd_solver.cpp:106] Iteration 115500, lr = 0.0045
I0523 01:15:55.484937  3818 solver.cpp:237] Iteration 115875, loss = 1.72636
I0523 01:15:55.484972  3818 solver.cpp:253]     Train net output #0: loss = 1.72636 (* 1 = 1.72636 loss)
I0523 01:15:55.484987  3818 sgd_solver.cpp:106] Iteration 115875, lr = 0.0045
I0523 01:16:05.330085  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_116250.caffemodel
I0523 01:16:05.386147  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_116250.solverstate
I0523 01:16:05.419327  3818 solver.cpp:237] Iteration 116250, loss = 1.10094
I0523 01:16:05.419371  3818 solver.cpp:253]     Train net output #0: loss = 1.10094 (* 1 = 1.10094 loss)
I0523 01:16:05.419387  3818 sgd_solver.cpp:106] Iteration 116250, lr = 0.0045
I0523 01:16:15.283762  3818 solver.cpp:237] Iteration 116625, loss = 1.1622
I0523 01:16:15.283942  3818 solver.cpp:253]     Train net output #0: loss = 1.1622 (* 1 = 1.1622 loss)
I0523 01:16:15.283957  3818 sgd_solver.cpp:106] Iteration 116625, lr = 0.0045
I0523 01:16:25.154688  3818 solver.cpp:237] Iteration 117000, loss = 1.02015
I0523 01:16:25.154727  3818 solver.cpp:253]     Train net output #0: loss = 1.02015 (* 1 = 1.02015 loss)
I0523 01:16:25.154739  3818 sgd_solver.cpp:106] Iteration 117000, lr = 0.0045
I0523 01:16:35.026008  3818 solver.cpp:237] Iteration 117375, loss = 0.934151
I0523 01:16:35.026044  3818 solver.cpp:253]     Train net output #0: loss = 0.934151 (* 1 = 0.934151 loss)
I0523 01:16:35.026058  3818 sgd_solver.cpp:106] Iteration 117375, lr = 0.0045
I0523 01:17:05.827518  3818 solver.cpp:237] Iteration 117750, loss = 1.19557
I0523 01:17:05.827708  3818 solver.cpp:253]     Train net output #0: loss = 1.19557 (* 1 = 1.19557 loss)
I0523 01:17:05.827721  3818 sgd_solver.cpp:106] Iteration 117750, lr = 0.0045
I0523 01:17:15.700458  3818 solver.cpp:237] Iteration 118125, loss = 1.21736
I0523 01:17:15.700501  3818 solver.cpp:253]     Train net output #0: loss = 1.21736 (* 1 = 1.21736 loss)
I0523 01:17:15.700518  3818 sgd_solver.cpp:106] Iteration 118125, lr = 0.0045
I0523 01:17:25.571291  3818 solver.cpp:237] Iteration 118500, loss = 1.39879
I0523 01:17:25.571326  3818 solver.cpp:253]     Train net output #0: loss = 1.39879 (* 1 = 1.39879 loss)
I0523 01:17:25.571341  3818 sgd_solver.cpp:106] Iteration 118500, lr = 0.0045
I0523 01:17:35.436343  3818 solver.cpp:237] Iteration 118875, loss = 1.18492
I0523 01:17:35.436379  3818 solver.cpp:253]     Train net output #0: loss = 1.18492 (* 1 = 1.18492 loss)
I0523 01:17:35.436393  3818 sgd_solver.cpp:106] Iteration 118875, lr = 0.0045
I0523 01:17:45.310888  3818 solver.cpp:237] Iteration 119250, loss = 1.13924
I0523 01:17:45.311079  3818 solver.cpp:253]     Train net output #0: loss = 1.13924 (* 1 = 1.13924 loss)
I0523 01:17:45.311092  3818 sgd_solver.cpp:106] Iteration 119250, lr = 0.0045
I0523 01:17:55.185207  3818 solver.cpp:237] Iteration 119625, loss = 1.03793
I0523 01:17:55.185242  3818 solver.cpp:253]     Train net output #0: loss = 1.03793 (* 1 = 1.03793 loss)
I0523 01:17:55.185256  3818 sgd_solver.cpp:106] Iteration 119625, lr = 0.0045
I0523 01:18:05.018779  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_120000.caffemodel
I0523 01:18:05.075253  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_120000.solverstate
I0523 01:18:05.100529  3818 solver.cpp:341] Iteration 120000, Testing net (#0)
I0523 01:19:14.625336  3818 solver.cpp:409]     Test net output #0: accuracy = 0.897167
I0523 01:19:14.625532  3818 solver.cpp:409]     Test net output #1: loss = 0.312673 (* 1 = 0.312673 loss)
I0523 01:19:35.583220  3818 solver.cpp:237] Iteration 120000, loss = 1.21256
I0523 01:19:35.583272  3818 solver.cpp:253]     Train net output #0: loss = 1.21256 (* 1 = 1.21256 loss)
I0523 01:19:35.583288  3818 sgd_solver.cpp:106] Iteration 120000, lr = 0.0045
I0523 01:19:45.480278  3818 solver.cpp:237] Iteration 120375, loss = 0.90408
I0523 01:19:45.480460  3818 solver.cpp:253]     Train net output #0: loss = 0.90408 (* 1 = 0.90408 loss)
I0523 01:19:45.480474  3818 sgd_solver.cpp:106] Iteration 120375, lr = 0.0045
I0523 01:19:55.377925  3818 solver.cpp:237] Iteration 120750, loss = 1.02297
I0523 01:19:55.377960  3818 solver.cpp:253]     Train net output #0: loss = 1.02297 (* 1 = 1.02297 loss)
I0523 01:19:55.377975  3818 sgd_solver.cpp:106] Iteration 120750, lr = 0.0045
I0523 01:20:05.263244  3818 solver.cpp:237] Iteration 121125, loss = 1.26488
I0523 01:20:05.263279  3818 solver.cpp:253]     Train net output #0: loss = 1.26488 (* 1 = 1.26488 loss)
I0523 01:20:05.263294  3818 sgd_solver.cpp:106] Iteration 121125, lr = 0.0045
I0523 01:20:15.154429  3818 solver.cpp:237] Iteration 121500, loss = 1.17386
I0523 01:20:15.154469  3818 solver.cpp:253]     Train net output #0: loss = 1.17386 (* 1 = 1.17386 loss)
I0523 01:20:15.154489  3818 sgd_solver.cpp:106] Iteration 121500, lr = 0.0045
I0523 01:20:25.038689  3818 solver.cpp:237] Iteration 121875, loss = 1.08755
I0523 01:20:25.038867  3818 solver.cpp:253]     Train net output #0: loss = 1.08755 (* 1 = 1.08755 loss)
I0523 01:20:25.038882  3818 sgd_solver.cpp:106] Iteration 121875, lr = 0.0045
I0523 01:20:34.940227  3818 solver.cpp:237] Iteration 122250, loss = 1.08993
I0523 01:20:34.940271  3818 solver.cpp:253]     Train net output #0: loss = 1.08993 (* 1 = 1.08993 loss)
I0523 01:20:34.940289  3818 sgd_solver.cpp:106] Iteration 122250, lr = 0.0045
I0523 01:21:05.772596  3818 solver.cpp:237] Iteration 122625, loss = 1.2664
I0523 01:21:05.772789  3818 solver.cpp:253]     Train net output #0: loss = 1.2664 (* 1 = 1.2664 loss)
I0523 01:21:05.772805  3818 sgd_solver.cpp:106] Iteration 122625, lr = 0.0045
I0523 01:21:15.662919  3818 solver.cpp:237] Iteration 123000, loss = 0.915196
I0523 01:21:15.662955  3818 solver.cpp:253]     Train net output #0: loss = 0.915196 (* 1 = 0.915196 loss)
I0523 01:21:15.662971  3818 sgd_solver.cpp:106] Iteration 123000, lr = 0.0045
I0523 01:21:25.557075  3818 solver.cpp:237] Iteration 123375, loss = 1.14319
I0523 01:21:25.557121  3818 solver.cpp:253]     Train net output #0: loss = 1.14319 (* 1 = 1.14319 loss)
I0523 01:21:25.557135  3818 sgd_solver.cpp:106] Iteration 123375, lr = 0.0045
I0523 01:21:35.429936  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_123750.caffemodel
I0523 01:21:35.485728  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_123750.solverstate
I0523 01:21:35.518760  3818 solver.cpp:237] Iteration 123750, loss = 1.29504
I0523 01:21:35.518806  3818 solver.cpp:253]     Train net output #0: loss = 1.29504 (* 1 = 1.29504 loss)
I0523 01:21:35.518822  3818 sgd_solver.cpp:106] Iteration 123750, lr = 0.0045
I0523 01:21:45.419878  3818 solver.cpp:237] Iteration 124125, loss = 1.33365
I0523 01:21:45.420058  3818 solver.cpp:253]     Train net output #0: loss = 1.33365 (* 1 = 1.33365 loss)
I0523 01:21:45.420073  3818 sgd_solver.cpp:106] Iteration 124125, lr = 0.0045
I0523 01:21:55.310014  3818 solver.cpp:237] Iteration 124500, loss = 1.03726
I0523 01:21:55.310061  3818 solver.cpp:253]     Train net output #0: loss = 1.03726 (* 1 = 1.03726 loss)
I0523 01:21:55.310076  3818 sgd_solver.cpp:106] Iteration 124500, lr = 0.0045
I0523 01:22:05.195948  3818 solver.cpp:237] Iteration 124875, loss = 1.14039
I0523 01:22:05.195986  3818 solver.cpp:253]     Train net output #0: loss = 1.14039 (* 1 = 1.14039 loss)
I0523 01:22:05.195999  3818 sgd_solver.cpp:106] Iteration 124875, lr = 0.0045
I0523 01:22:36.032040  3818 solver.cpp:237] Iteration 125250, loss = 1.23323
I0523 01:22:36.032233  3818 solver.cpp:253]     Train net output #0: loss = 1.23323 (* 1 = 1.23323 loss)
I0523 01:22:36.032248  3818 sgd_solver.cpp:106] Iteration 125250, lr = 0.0045
I0523 01:22:45.922150  3818 solver.cpp:237] Iteration 125625, loss = 1.11468
I0523 01:22:45.922183  3818 solver.cpp:253]     Train net output #0: loss = 1.11468 (* 1 = 1.11468 loss)
I0523 01:22:45.922195  3818 sgd_solver.cpp:106] Iteration 125625, lr = 0.0045
I0523 01:22:55.821120  3818 solver.cpp:237] Iteration 126000, loss = 1.21496
I0523 01:22:55.821156  3818 solver.cpp:253]     Train net output #0: loss = 1.21496 (* 1 = 1.21496 loss)
I0523 01:22:55.821171  3818 sgd_solver.cpp:106] Iteration 126000, lr = 0.0045
I0523 01:23:05.708529  3818 solver.cpp:237] Iteration 126375, loss = 1.19555
I0523 01:23:05.708572  3818 solver.cpp:253]     Train net output #0: loss = 1.19555 (* 1 = 1.19555 loss)
I0523 01:23:05.708587  3818 sgd_solver.cpp:106] Iteration 126375, lr = 0.0045
I0523 01:23:15.598943  3818 solver.cpp:237] Iteration 126750, loss = 0.993303
I0523 01:23:15.599128  3818 solver.cpp:253]     Train net output #0: loss = 0.993303 (* 1 = 0.993303 loss)
I0523 01:23:15.599143  3818 sgd_solver.cpp:106] Iteration 126750, lr = 0.0045
I0523 01:23:25.496819  3818 solver.cpp:237] Iteration 127125, loss = 0.96532
I0523 01:23:25.496855  3818 solver.cpp:253]     Train net output #0: loss = 0.96532 (* 1 = 0.96532 loss)
I0523 01:23:25.496867  3818 sgd_solver.cpp:106] Iteration 127125, lr = 0.0045
I0523 01:23:35.376282  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_127500.caffemodel
I0523 01:23:35.432497  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_127500.solverstate
I0523 01:23:35.458025  3818 solver.cpp:341] Iteration 127500, Testing net (#0)
I0523 01:24:24.059061  3818 solver.cpp:409]     Test net output #0: accuracy = 0.897459
I0523 01:24:24.059245  3818 solver.cpp:409]     Test net output #1: loss = 0.341863 (* 1 = 0.341863 loss)
I0523 01:24:45.005743  3818 solver.cpp:237] Iteration 127500, loss = 1.30614
I0523 01:24:45.005796  3818 solver.cpp:253]     Train net output #0: loss = 1.30614 (* 1 = 1.30614 loss)
I0523 01:24:45.005811  3818 sgd_solver.cpp:106] Iteration 127500, lr = 0.0045
I0523 01:24:54.789350  3818 solver.cpp:237] Iteration 127875, loss = 0.868408
I0523 01:24:54.789523  3818 solver.cpp:253]     Train net output #0: loss = 0.868408 (* 1 = 0.868408 loss)
I0523 01:24:54.789538  3818 sgd_solver.cpp:106] Iteration 127875, lr = 0.0045
I0523 01:25:04.567471  3818 solver.cpp:237] Iteration 128250, loss = 1.20969
I0523 01:25:04.567507  3818 solver.cpp:253]     Train net output #0: loss = 1.20969 (* 1 = 1.20969 loss)
I0523 01:25:04.567522  3818 sgd_solver.cpp:106] Iteration 128250, lr = 0.0045
I0523 01:25:14.351158  3818 solver.cpp:237] Iteration 128625, loss = 1.24042
I0523 01:25:14.351199  3818 solver.cpp:253]     Train net output #0: loss = 1.24042 (* 1 = 1.24042 loss)
I0523 01:25:14.351215  3818 sgd_solver.cpp:106] Iteration 128625, lr = 0.0045
I0523 01:25:24.131122  3818 solver.cpp:237] Iteration 129000, loss = 0.95038
I0523 01:25:24.131158  3818 solver.cpp:253]     Train net output #0: loss = 0.95038 (* 1 = 0.95038 loss)
I0523 01:25:24.131173  3818 sgd_solver.cpp:106] Iteration 129000, lr = 0.0045
I0523 01:25:33.916808  3818 solver.cpp:237] Iteration 129375, loss = 1.13186
I0523 01:25:33.916982  3818 solver.cpp:253]     Train net output #0: loss = 1.13186 (* 1 = 1.13186 loss)
I0523 01:25:33.916996  3818 sgd_solver.cpp:106] Iteration 129375, lr = 0.0045
I0523 01:25:43.702177  3818 solver.cpp:237] Iteration 129750, loss = 1.03698
I0523 01:25:43.702211  3818 solver.cpp:253]     Train net output #0: loss = 1.03698 (* 1 = 1.03698 loss)
I0523 01:25:43.702226  3818 sgd_solver.cpp:106] Iteration 129750, lr = 0.0045
I0523 01:26:14.413653  3818 solver.cpp:237] Iteration 130125, loss = 1.2737
I0523 01:26:14.413844  3818 solver.cpp:253]     Train net output #0: loss = 1.2737 (* 1 = 1.2737 loss)
I0523 01:26:14.413861  3818 sgd_solver.cpp:106] Iteration 130125, lr = 0.0045
I0523 01:26:24.195965  3818 solver.cpp:237] Iteration 130500, loss = 1.2165
I0523 01:26:24.196008  3818 solver.cpp:253]     Train net output #0: loss = 1.2165 (* 1 = 1.2165 loss)
I0523 01:26:24.196025  3818 sgd_solver.cpp:106] Iteration 130500, lr = 0.0045
I0523 01:26:33.983675  3818 solver.cpp:237] Iteration 130875, loss = 1.05657
I0523 01:26:33.983710  3818 solver.cpp:253]     Train net output #0: loss = 1.05657 (* 1 = 1.05657 loss)
I0523 01:26:33.983726  3818 sgd_solver.cpp:106] Iteration 130875, lr = 0.0045
I0523 01:26:43.736403  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_131250.caffemodel
I0523 01:26:43.794777  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_131250.solverstate
I0523 01:26:43.830449  3818 solver.cpp:237] Iteration 131250, loss = 1.21773
I0523 01:26:43.830497  3818 solver.cpp:253]     Train net output #0: loss = 1.21773 (* 1 = 1.21773 loss)
I0523 01:26:43.830516  3818 sgd_solver.cpp:106] Iteration 131250, lr = 0.0045
I0523 01:26:53.612062  3818 solver.cpp:237] Iteration 131625, loss = 1.11352
I0523 01:26:53.612252  3818 solver.cpp:253]     Train net output #0: loss = 1.11352 (* 1 = 1.11352 loss)
I0523 01:26:53.612267  3818 sgd_solver.cpp:106] Iteration 131625, lr = 0.0045
I0523 01:27:03.396353  3818 solver.cpp:237] Iteration 132000, loss = 1.51986
I0523 01:27:03.396389  3818 solver.cpp:253]     Train net output #0: loss = 1.51986 (* 1 = 1.51986 loss)
I0523 01:27:03.396404  3818 sgd_solver.cpp:106] Iteration 132000, lr = 0.0045
I0523 01:27:13.178047  3818 solver.cpp:237] Iteration 132375, loss = 0.970957
I0523 01:27:13.178092  3818 solver.cpp:253]     Train net output #0: loss = 0.970957 (* 1 = 0.970957 loss)
I0523 01:27:13.178109  3818 sgd_solver.cpp:106] Iteration 132375, lr = 0.0045
I0523 01:27:43.922139  3818 solver.cpp:237] Iteration 132750, loss = 0.910558
I0523 01:27:43.922333  3818 solver.cpp:253]     Train net output #0: loss = 0.910558 (* 1 = 0.910558 loss)
I0523 01:27:43.922349  3818 sgd_solver.cpp:106] Iteration 132750, lr = 0.0045
I0523 01:27:53.706274  3818 solver.cpp:237] Iteration 133125, loss = 1.00572
I0523 01:27:53.706310  3818 solver.cpp:253]     Train net output #0: loss = 1.00572 (* 1 = 1.00572 loss)
I0523 01:27:53.706324  3818 sgd_solver.cpp:106] Iteration 133125, lr = 0.0045
I0523 01:28:03.487922  3818 solver.cpp:237] Iteration 133500, loss = 1.39069
I0523 01:28:03.487965  3818 solver.cpp:253]     Train net output #0: loss = 1.39069 (* 1 = 1.39069 loss)
I0523 01:28:03.487984  3818 sgd_solver.cpp:106] Iteration 133500, lr = 0.0045
I0523 01:28:13.274507  3818 solver.cpp:237] Iteration 133875, loss = 1.11889
I0523 01:28:13.274544  3818 solver.cpp:253]     Train net output #0: loss = 1.11889 (* 1 = 1.11889 loss)
I0523 01:28:13.274557  3818 sgd_solver.cpp:106] Iteration 133875, lr = 0.0045
I0523 01:28:23.059376  3818 solver.cpp:237] Iteration 134250, loss = 1.08061
I0523 01:28:23.059540  3818 solver.cpp:253]     Train net output #0: loss = 1.08061 (* 1 = 1.08061 loss)
I0523 01:28:23.059554  3818 sgd_solver.cpp:106] Iteration 134250, lr = 0.0045
I0523 01:28:32.834230  3818 solver.cpp:237] Iteration 134625, loss = 1.03554
I0523 01:28:32.834272  3818 solver.cpp:253]     Train net output #0: loss = 1.03554 (* 1 = 1.03554 loss)
I0523 01:28:32.834290  3818 sgd_solver.cpp:106] Iteration 134625, lr = 0.0045
I0523 01:28:42.590198  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_135000.caffemodel
I0523 01:28:42.648442  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_135000.solverstate
I0523 01:28:42.676369  3818 solver.cpp:341] Iteration 135000, Testing net (#0)
I0523 01:29:52.196169  3818 solver.cpp:409]     Test net output #0: accuracy = 0.899326
I0523 01:29:52.196360  3818 solver.cpp:409]     Test net output #1: loss = 0.31928 (* 1 = 0.31928 loss)
I0523 01:30:13.138579  3818 solver.cpp:237] Iteration 135000, loss = 1.23979
I0523 01:30:13.138633  3818 solver.cpp:253]     Train net output #0: loss = 1.23979 (* 1 = 1.23979 loss)
I0523 01:30:13.138648  3818 sgd_solver.cpp:106] Iteration 135000, lr = 0.0045
I0523 01:30:22.838503  3818 solver.cpp:237] Iteration 135375, loss = 0.87584
I0523 01:30:22.838681  3818 solver.cpp:253]     Train net output #0: loss = 0.87584 (* 1 = 0.87584 loss)
I0523 01:30:22.838696  3818 sgd_solver.cpp:106] Iteration 135375, lr = 0.0045
I0523 01:30:32.535073  3818 solver.cpp:237] Iteration 135750, loss = 1.36187
I0523 01:30:32.535117  3818 solver.cpp:253]     Train net output #0: loss = 1.36187 (* 1 = 1.36187 loss)
I0523 01:30:32.535133  3818 sgd_solver.cpp:106] Iteration 135750, lr = 0.0045
I0523 01:30:42.243376  3818 solver.cpp:237] Iteration 136125, loss = 1.09948
I0523 01:30:42.243410  3818 solver.cpp:253]     Train net output #0: loss = 1.09948 (* 1 = 1.09948 loss)
I0523 01:30:42.243427  3818 sgd_solver.cpp:106] Iteration 136125, lr = 0.0045
I0523 01:30:51.951372  3818 solver.cpp:237] Iteration 136500, loss = 1.27797
I0523 01:30:51.951407  3818 solver.cpp:253]     Train net output #0: loss = 1.27797 (* 1 = 1.27797 loss)
I0523 01:30:51.951421  3818 sgd_solver.cpp:106] Iteration 136500, lr = 0.0045
I0523 01:31:01.650697  3818 solver.cpp:237] Iteration 136875, loss = 1.05397
I0523 01:31:01.650902  3818 solver.cpp:253]     Train net output #0: loss = 1.05397 (* 1 = 1.05397 loss)
I0523 01:31:01.650916  3818 sgd_solver.cpp:106] Iteration 136875, lr = 0.0045
I0523 01:31:11.353791  3818 solver.cpp:237] Iteration 137250, loss = 1.12299
I0523 01:31:11.353826  3818 solver.cpp:253]     Train net output #0: loss = 1.12299 (* 1 = 1.12299 loss)
I0523 01:31:11.353840  3818 sgd_solver.cpp:106] Iteration 137250, lr = 0.0045
I0523 01:31:41.987532  3818 solver.cpp:237] Iteration 137625, loss = 1.01179
I0523 01:31:41.987721  3818 solver.cpp:253]     Train net output #0: loss = 1.01179 (* 1 = 1.01179 loss)
I0523 01:31:41.987738  3818 sgd_solver.cpp:106] Iteration 137625, lr = 0.0045
I0523 01:31:51.694953  3818 solver.cpp:237] Iteration 138000, loss = 0.95955
I0523 01:31:51.695008  3818 solver.cpp:253]     Train net output #0: loss = 0.95955 (* 1 = 0.95955 loss)
I0523 01:31:51.695021  3818 sgd_solver.cpp:106] Iteration 138000, lr = 0.0045
I0523 01:32:01.401286  3818 solver.cpp:237] Iteration 138375, loss = 1.22336
I0523 01:32:01.401321  3818 solver.cpp:253]     Train net output #0: loss = 1.22336 (* 1 = 1.22336 loss)
I0523 01:32:01.401336  3818 sgd_solver.cpp:106] Iteration 138375, lr = 0.0045
I0523 01:32:11.080775  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_138750.caffemodel
I0523 01:32:11.136909  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_138750.solverstate
I0523 01:32:11.170871  3818 solver.cpp:237] Iteration 138750, loss = 1.26513
I0523 01:32:11.170917  3818 solver.cpp:253]     Train net output #0: loss = 1.26513 (* 1 = 1.26513 loss)
I0523 01:32:11.170931  3818 sgd_solver.cpp:106] Iteration 138750, lr = 0.0045
I0523 01:32:20.876292  3818 solver.cpp:237] Iteration 139125, loss = 1.16433
I0523 01:32:20.876480  3818 solver.cpp:253]     Train net output #0: loss = 1.16433 (* 1 = 1.16433 loss)
I0523 01:32:20.876494  3818 sgd_solver.cpp:106] Iteration 139125, lr = 0.0045
I0523 01:32:30.576912  3818 solver.cpp:237] Iteration 139500, loss = 1.29374
I0523 01:32:30.576947  3818 solver.cpp:253]     Train net output #0: loss = 1.29374 (* 1 = 1.29374 loss)
I0523 01:32:30.576963  3818 sgd_solver.cpp:106] Iteration 139500, lr = 0.0045
I0523 01:32:40.273506  3818 solver.cpp:237] Iteration 139875, loss = 0.903624
I0523 01:32:40.273552  3818 solver.cpp:253]     Train net output #0: loss = 0.903624 (* 1 = 0.903624 loss)
I0523 01:32:40.273567  3818 sgd_solver.cpp:106] Iteration 139875, lr = 0.0045
I0523 01:33:10.939908  3818 solver.cpp:237] Iteration 140250, loss = 1.06295
I0523 01:33:10.940102  3818 solver.cpp:253]     Train net output #0: loss = 1.06295 (* 1 = 1.06295 loss)
I0523 01:33:10.940119  3818 sgd_solver.cpp:106] Iteration 140250, lr = 0.0045
I0523 01:33:20.642680  3818 solver.cpp:237] Iteration 140625, loss = 1.23277
I0523 01:33:20.642717  3818 solver.cpp:253]     Train net output #0: loss = 1.23277 (* 1 = 1.23277 loss)
I0523 01:33:20.642731  3818 sgd_solver.cpp:106] Iteration 140625, lr = 0.0045
I0523 01:33:30.331074  3818 solver.cpp:237] Iteration 141000, loss = 1.13325
I0523 01:33:30.331121  3818 solver.cpp:253]     Train net output #0: loss = 1.13325 (* 1 = 1.13325 loss)
I0523 01:33:30.331135  3818 sgd_solver.cpp:106] Iteration 141000, lr = 0.0045
I0523 01:33:40.016769  3818 solver.cpp:237] Iteration 141375, loss = 0.920788
I0523 01:33:40.016806  3818 solver.cpp:253]     Train net output #0: loss = 0.920788 (* 1 = 0.920788 loss)
I0523 01:33:40.016820  3818 sgd_solver.cpp:106] Iteration 141375, lr = 0.0045
I0523 01:33:49.703322  3818 solver.cpp:237] Iteration 141750, loss = 1.10305
I0523 01:33:49.703506  3818 solver.cpp:253]     Train net output #0: loss = 1.10305 (* 1 = 1.10305 loss)
I0523 01:33:49.703521  3818 sgd_solver.cpp:106] Iteration 141750, lr = 0.0045
I0523 01:33:59.384207  3818 solver.cpp:237] Iteration 142125, loss = 0.971489
I0523 01:33:59.384248  3818 solver.cpp:253]     Train net output #0: loss = 0.971489 (* 1 = 0.971489 loss)
I0523 01:33:59.384265  3818 sgd_solver.cpp:106] Iteration 142125, lr = 0.0045
I0523 01:34:09.045503  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_142500.caffemodel
I0523 01:34:09.100618  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_142500.solverstate
I0523 01:34:09.125797  3818 solver.cpp:341] Iteration 142500, Testing net (#0)
I0523 01:34:57.362460  3818 solver.cpp:409]     Test net output #0: accuracy = 0.892853
I0523 01:34:57.362655  3818 solver.cpp:409]     Test net output #1: loss = 0.32849 (* 1 = 0.32849 loss)
I0523 01:35:18.250063  3818 solver.cpp:237] Iteration 142500, loss = 0.900396
I0523 01:35:18.250118  3818 solver.cpp:253]     Train net output #0: loss = 0.900396 (* 1 = 0.900396 loss)
I0523 01:35:18.250133  3818 sgd_solver.cpp:106] Iteration 142500, lr = 0.0045
I0523 01:35:28.076663  3818 solver.cpp:237] Iteration 142875, loss = 0.631182
I0523 01:35:28.076840  3818 solver.cpp:253]     Train net output #0: loss = 0.631182 (* 1 = 0.631182 loss)
I0523 01:35:28.076854  3818 sgd_solver.cpp:106] Iteration 142875, lr = 0.0045
I0523 01:35:37.894232  3818 solver.cpp:237] Iteration 143250, loss = 0.914823
I0523 01:35:37.894279  3818 solver.cpp:253]     Train net output #0: loss = 0.914823 (* 1 = 0.914823 loss)
I0523 01:35:37.894294  3818 sgd_solver.cpp:106] Iteration 143250, lr = 0.0045
I0523 01:35:47.725436  3818 solver.cpp:237] Iteration 143625, loss = 1.04041
I0523 01:35:47.725472  3818 solver.cpp:253]     Train net output #0: loss = 1.04041 (* 1 = 1.04041 loss)
I0523 01:35:47.725486  3818 sgd_solver.cpp:106] Iteration 143625, lr = 0.0045
I0523 01:35:57.554872  3818 solver.cpp:237] Iteration 144000, loss = 1.24698
I0523 01:35:57.554919  3818 solver.cpp:253]     Train net output #0: loss = 1.24698 (* 1 = 1.24698 loss)
I0523 01:35:57.554931  3818 sgd_solver.cpp:106] Iteration 144000, lr = 0.0045
I0523 01:36:07.386271  3818 solver.cpp:237] Iteration 144375, loss = 1.00669
I0523 01:36:07.386445  3818 solver.cpp:253]     Train net output #0: loss = 1.00669 (* 1 = 1.00669 loss)
I0523 01:36:07.386458  3818 sgd_solver.cpp:106] Iteration 144375, lr = 0.0045
I0523 01:36:17.218711  3818 solver.cpp:237] Iteration 144750, loss = 1.18638
I0523 01:36:17.218745  3818 solver.cpp:253]     Train net output #0: loss = 1.18638 (* 1 = 1.18638 loss)
I0523 01:36:17.218760  3818 sgd_solver.cpp:106] Iteration 144750, lr = 0.0045
I0523 01:36:47.945422  3818 solver.cpp:237] Iteration 145125, loss = 1.13403
I0523 01:36:47.945614  3818 solver.cpp:253]     Train net output #0: loss = 1.13403 (* 1 = 1.13403 loss)
I0523 01:36:47.945631  3818 sgd_solver.cpp:106] Iteration 145125, lr = 0.0045
I0523 01:36:57.770146  3818 solver.cpp:237] Iteration 145500, loss = 0.999085
I0523 01:36:57.770181  3818 solver.cpp:253]     Train net output #0: loss = 0.999085 (* 1 = 0.999085 loss)
I0523 01:36:57.770196  3818 sgd_solver.cpp:106] Iteration 145500, lr = 0.0045
I0523 01:37:07.593976  3818 solver.cpp:237] Iteration 145875, loss = 1.04565
I0523 01:37:07.594012  3818 solver.cpp:253]     Train net output #0: loss = 1.04565 (* 1 = 1.04565 loss)
I0523 01:37:07.594027  3818 sgd_solver.cpp:106] Iteration 145875, lr = 0.0045
I0523 01:37:17.394274  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_146250.caffemodel
I0523 01:37:17.450601  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_146250.solverstate
I0523 01:37:17.483954  3818 solver.cpp:237] Iteration 146250, loss = 1.53301
I0523 01:37:17.483994  3818 solver.cpp:253]     Train net output #0: loss = 1.53301 (* 1 = 1.53301 loss)
I0523 01:37:17.484012  3818 sgd_solver.cpp:106] Iteration 146250, lr = 0.0045
I0523 01:37:27.307163  3818 solver.cpp:237] Iteration 146625, loss = 1.21137
I0523 01:37:27.307345  3818 solver.cpp:253]     Train net output #0: loss = 1.21137 (* 1 = 1.21137 loss)
I0523 01:37:27.307359  3818 sgd_solver.cpp:106] Iteration 146625, lr = 0.0045
I0523 01:37:37.135042  3818 solver.cpp:237] Iteration 147000, loss = 1.85165
I0523 01:37:37.135089  3818 solver.cpp:253]     Train net output #0: loss = 1.85165 (* 1 = 1.85165 loss)
I0523 01:37:37.135103  3818 sgd_solver.cpp:106] Iteration 147000, lr = 0.0045
I0523 01:37:46.965348  3818 solver.cpp:237] Iteration 147375, loss = 1.29642
I0523 01:37:46.965384  3818 solver.cpp:253]     Train net output #0: loss = 1.29642 (* 1 = 1.29642 loss)
I0523 01:37:46.965397  3818 sgd_solver.cpp:106] Iteration 147375, lr = 0.0045
I0523 01:38:17.723809  3818 solver.cpp:237] Iteration 147750, loss = 0.967885
I0523 01:38:17.724005  3818 solver.cpp:253]     Train net output #0: loss = 0.967885 (* 1 = 0.967885 loss)
I0523 01:38:17.724020  3818 sgd_solver.cpp:106] Iteration 147750, lr = 0.0045
I0523 01:38:27.549233  3818 solver.cpp:237] Iteration 148125, loss = 1.18007
I0523 01:38:27.549278  3818 solver.cpp:253]     Train net output #0: loss = 1.18007 (* 1 = 1.18007 loss)
I0523 01:38:27.549293  3818 sgd_solver.cpp:106] Iteration 148125, lr = 0.0045
I0523 01:38:37.375403  3818 solver.cpp:237] Iteration 148500, loss = 0.943061
I0523 01:38:37.375440  3818 solver.cpp:253]     Train net output #0: loss = 0.943061 (* 1 = 0.943061 loss)
I0523 01:38:37.375453  3818 sgd_solver.cpp:106] Iteration 148500, lr = 0.0045
I0523 01:38:47.196966  3818 solver.cpp:237] Iteration 148875, loss = 1.0601
I0523 01:38:47.197002  3818 solver.cpp:253]     Train net output #0: loss = 1.0601 (* 1 = 1.0601 loss)
I0523 01:38:47.197017  3818 sgd_solver.cpp:106] Iteration 148875, lr = 0.0045
I0523 01:38:57.025389  3818 solver.cpp:237] Iteration 149250, loss = 1.2913
I0523 01:38:57.025580  3818 solver.cpp:253]     Train net output #0: loss = 1.2913 (* 1 = 1.2913 loss)
I0523 01:38:57.025594  3818 sgd_solver.cpp:106] Iteration 149250, lr = 0.0045
I0523 01:39:06.847995  3818 solver.cpp:237] Iteration 149625, loss = 1.56913
I0523 01:39:06.848031  3818 solver.cpp:253]     Train net output #0: loss = 1.56913 (* 1 = 1.56913 loss)
I0523 01:39:06.848045  3818 sgd_solver.cpp:106] Iteration 149625, lr = 0.0045
I0523 01:39:16.645886  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_150000.caffemodel
I0523 01:39:16.704375  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_150000.solverstate
I0523 01:39:16.731464  3818 solver.cpp:341] Iteration 150000, Testing net (#0)
I0523 01:40:26.201921  3818 solver.cpp:409]     Test net output #0: accuracy = 0.900454
I0523 01:40:26.202117  3818 solver.cpp:409]     Test net output #1: loss = 0.320874 (* 1 = 0.320874 loss)
I0523 01:40:47.097144  3818 solver.cpp:237] Iteration 150000, loss = 1.17229
I0523 01:40:47.097198  3818 solver.cpp:253]     Train net output #0: loss = 1.17229 (* 1 = 1.17229 loss)
I0523 01:40:47.097213  3818 sgd_solver.cpp:106] Iteration 150000, lr = 0.0045
I0523 01:40:56.970048  3818 solver.cpp:237] Iteration 150375, loss = 1.08413
I0523 01:40:56.970249  3818 solver.cpp:253]     Train net output #0: loss = 1.08413 (* 1 = 1.08413 loss)
I0523 01:40:56.970264  3818 sgd_solver.cpp:106] Iteration 150375, lr = 0.0045
I0523 01:41:06.839668  3818 solver.cpp:237] Iteration 150750, loss = 1.58308
I0523 01:41:06.839704  3818 solver.cpp:253]     Train net output #0: loss = 1.58308 (* 1 = 1.58308 loss)
I0523 01:41:06.839718  3818 sgd_solver.cpp:106] Iteration 150750, lr = 0.0045
I0523 01:41:16.724284  3818 solver.cpp:237] Iteration 151125, loss = 1.15403
I0523 01:41:16.724319  3818 solver.cpp:253]     Train net output #0: loss = 1.15403 (* 1 = 1.15403 loss)
I0523 01:41:16.724335  3818 sgd_solver.cpp:106] Iteration 151125, lr = 0.0045
I0523 01:41:26.605737  3818 solver.cpp:237] Iteration 151500, loss = 1.1692
I0523 01:41:26.605787  3818 solver.cpp:253]     Train net output #0: loss = 1.1692 (* 1 = 1.1692 loss)
I0523 01:41:26.605801  3818 sgd_solver.cpp:106] Iteration 151500, lr = 0.0045
I0523 01:41:36.486940  3818 solver.cpp:237] Iteration 151875, loss = 1.21871
I0523 01:41:36.487124  3818 solver.cpp:253]     Train net output #0: loss = 1.21871 (* 1 = 1.21871 loss)
I0523 01:41:36.487138  3818 sgd_solver.cpp:106] Iteration 151875, lr = 0.0045
I0523 01:41:46.357873  3818 solver.cpp:237] Iteration 152250, loss = 1.13925
I0523 01:41:46.357908  3818 solver.cpp:253]     Train net output #0: loss = 1.13925 (* 1 = 1.13925 loss)
I0523 01:41:46.357923  3818 sgd_solver.cpp:106] Iteration 152250, lr = 0.0045
I0523 01:42:17.114908  3818 solver.cpp:237] Iteration 152625, loss = 0.924173
I0523 01:42:17.115113  3818 solver.cpp:253]     Train net output #0: loss = 0.924173 (* 1 = 0.924173 loss)
I0523 01:42:17.115128  3818 sgd_solver.cpp:106] Iteration 152625, lr = 0.0045
I0523 01:42:26.995287  3818 solver.cpp:237] Iteration 153000, loss = 1.06023
I0523 01:42:26.995321  3818 solver.cpp:253]     Train net output #0: loss = 1.06023 (* 1 = 1.06023 loss)
I0523 01:42:26.995337  3818 sgd_solver.cpp:106] Iteration 153000, lr = 0.0045
I0523 01:42:36.881247  3818 solver.cpp:237] Iteration 153375, loss = 1.22929
I0523 01:42:36.881290  3818 solver.cpp:253]     Train net output #0: loss = 1.22929 (* 1 = 1.22929 loss)
I0523 01:42:36.881310  3818 sgd_solver.cpp:106] Iteration 153375, lr = 0.0045
I0523 01:42:46.733866  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_153750.caffemodel
I0523 01:42:46.790208  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_153750.solverstate
I0523 01:42:46.823215  3818 solver.cpp:237] Iteration 153750, loss = 1.14589
I0523 01:42:46.823261  3818 solver.cpp:253]     Train net output #0: loss = 1.14589 (* 1 = 1.14589 loss)
I0523 01:42:46.823276  3818 sgd_solver.cpp:106] Iteration 153750, lr = 0.0045
I0523 01:42:56.697491  3818 solver.cpp:237] Iteration 154125, loss = 1.2442
I0523 01:42:56.697671  3818 solver.cpp:253]     Train net output #0: loss = 1.2442 (* 1 = 1.2442 loss)
I0523 01:42:56.697686  3818 sgd_solver.cpp:106] Iteration 154125, lr = 0.0045
I0523 01:43:06.573742  3818 solver.cpp:237] Iteration 154500, loss = 1.23157
I0523 01:43:06.573787  3818 solver.cpp:253]     Train net output #0: loss = 1.23157 (* 1 = 1.23157 loss)
I0523 01:43:06.573803  3818 sgd_solver.cpp:106] Iteration 154500, lr = 0.0045
I0523 01:43:16.451598  3818 solver.cpp:237] Iteration 154875, loss = 0.827678
I0523 01:43:16.451637  3818 solver.cpp:253]     Train net output #0: loss = 0.827678 (* 1 = 0.827678 loss)
I0523 01:43:16.451650  3818 sgd_solver.cpp:106] Iteration 154875, lr = 0.0045
I0523 01:43:47.224730  3818 solver.cpp:237] Iteration 155250, loss = 0.964098
I0523 01:43:47.224931  3818 solver.cpp:253]     Train net output #0: loss = 0.964098 (* 1 = 0.964098 loss)
I0523 01:43:47.224947  3818 sgd_solver.cpp:106] Iteration 155250, lr = 0.0045
I0523 01:43:57.105592  3818 solver.cpp:237] Iteration 155625, loss = 1.11766
I0523 01:43:57.105633  3818 solver.cpp:253]     Train net output #0: loss = 1.11766 (* 1 = 1.11766 loss)
I0523 01:43:57.105654  3818 sgd_solver.cpp:106] Iteration 155625, lr = 0.0045
I0523 01:44:06.988664  3818 solver.cpp:237] Iteration 156000, loss = 1.39317
I0523 01:44:06.988699  3818 solver.cpp:253]     Train net output #0: loss = 1.39317 (* 1 = 1.39317 loss)
I0523 01:44:06.988714  3818 sgd_solver.cpp:106] Iteration 156000, lr = 0.0045
I0523 01:44:16.866948  3818 solver.cpp:237] Iteration 156375, loss = 1.1293
I0523 01:44:16.866993  3818 solver.cpp:253]     Train net output #0: loss = 1.1293 (* 1 = 1.1293 loss)
I0523 01:44:16.867007  3818 sgd_solver.cpp:106] Iteration 156375, lr = 0.0045
I0523 01:44:26.751884  3818 solver.cpp:237] Iteration 156750, loss = 1.05869
I0523 01:44:26.752084  3818 solver.cpp:253]     Train net output #0: loss = 1.05869 (* 1 = 1.05869 loss)
I0523 01:44:26.752096  3818 sgd_solver.cpp:106] Iteration 156750, lr = 0.0045
I0523 01:44:36.624003  3818 solver.cpp:237] Iteration 157125, loss = 1.12706
I0523 01:44:36.624038  3818 solver.cpp:253]     Train net output #0: loss = 1.12706 (* 1 = 1.12706 loss)
I0523 01:44:36.624053  3818 sgd_solver.cpp:106] Iteration 157125, lr = 0.0045
I0523 01:44:46.481596  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_157500.caffemodel
I0523 01:44:46.538091  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_157500.solverstate
I0523 01:44:46.563172  3818 solver.cpp:341] Iteration 157500, Testing net (#0)
I0523 01:45:35.112191  3818 solver.cpp:409]     Test net output #0: accuracy = 0.901434
I0523 01:45:35.112387  3818 solver.cpp:409]     Test net output #1: loss = 0.319061 (* 1 = 0.319061 loss)
I0523 01:45:55.975589  3818 solver.cpp:237] Iteration 157500, loss = 1.34615
I0523 01:45:55.975643  3818 solver.cpp:253]     Train net output #0: loss = 1.34615 (* 1 = 1.34615 loss)
I0523 01:45:55.975658  3818 sgd_solver.cpp:106] Iteration 157500, lr = 0.0045
I0523 01:46:05.830174  3818 solver.cpp:237] Iteration 157875, loss = 0.907177
I0523 01:46:05.830371  3818 solver.cpp:253]     Train net output #0: loss = 0.907177 (* 1 = 0.907177 loss)
I0523 01:46:05.830385  3818 sgd_solver.cpp:106] Iteration 157875, lr = 0.0045
I0523 01:46:15.680708  3818 solver.cpp:237] Iteration 158250, loss = 1.04334
I0523 01:46:15.680743  3818 solver.cpp:253]     Train net output #0: loss = 1.04334 (* 1 = 1.04334 loss)
I0523 01:46:15.680758  3818 sgd_solver.cpp:106] Iteration 158250, lr = 0.0045
I0523 01:46:25.538907  3818 solver.cpp:237] Iteration 158625, loss = 1.07126
I0523 01:46:25.538955  3818 solver.cpp:253]     Train net output #0: loss = 1.07126 (* 1 = 1.07126 loss)
I0523 01:46:25.538969  3818 sgd_solver.cpp:106] Iteration 158625, lr = 0.0045
I0523 01:46:35.389153  3818 solver.cpp:237] Iteration 159000, loss = 1.03124
I0523 01:46:35.389189  3818 solver.cpp:253]     Train net output #0: loss = 1.03124 (* 1 = 1.03124 loss)
I0523 01:46:35.389202  3818 sgd_solver.cpp:106] Iteration 159000, lr = 0.0045
I0523 01:46:45.235384  3818 solver.cpp:237] Iteration 159375, loss = 1.36701
I0523 01:46:45.235564  3818 solver.cpp:253]     Train net output #0: loss = 1.36701 (* 1 = 1.36701 loss)
I0523 01:46:45.235577  3818 sgd_solver.cpp:106] Iteration 159375, lr = 0.0045
I0523 01:46:55.086249  3818 solver.cpp:237] Iteration 159750, loss = 1.1192
I0523 01:46:55.086288  3818 solver.cpp:253]     Train net output #0: loss = 1.1192 (* 1 = 1.1192 loss)
I0523 01:46:55.086309  3818 sgd_solver.cpp:106] Iteration 159750, lr = 0.0045
I0523 01:47:25.827339  3818 solver.cpp:237] Iteration 160125, loss = 0.978264
I0523 01:47:25.827539  3818 solver.cpp:253]     Train net output #0: loss = 0.978264 (* 1 = 0.978264 loss)
I0523 01:47:25.827556  3818 sgd_solver.cpp:106] Iteration 160125, lr = 0.0045
I0523 01:47:35.680248  3818 solver.cpp:237] Iteration 160500, loss = 1.09857
I0523 01:47:35.680284  3818 solver.cpp:253]     Train net output #0: loss = 1.09857 (* 1 = 1.09857 loss)
I0523 01:47:35.680300  3818 sgd_solver.cpp:106] Iteration 160500, lr = 0.0045
I0523 01:47:45.529412  3818 solver.cpp:237] Iteration 160875, loss = 1.27552
I0523 01:47:45.529453  3818 solver.cpp:253]     Train net output #0: loss = 1.27552 (* 1 = 1.27552 loss)
I0523 01:47:45.529472  3818 sgd_solver.cpp:106] Iteration 160875, lr = 0.0045
I0523 01:47:55.354320  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_161250.caffemodel
I0523 01:47:55.409811  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_161250.solverstate
I0523 01:47:55.443651  3818 solver.cpp:237] Iteration 161250, loss = 0.94685
I0523 01:47:55.443698  3818 solver.cpp:253]     Train net output #0: loss = 0.94685 (* 1 = 0.94685 loss)
I0523 01:47:55.443713  3818 sgd_solver.cpp:106] Iteration 161250, lr = 0.0045
I0523 01:48:05.297114  3818 solver.cpp:237] Iteration 161625, loss = 1.14165
I0523 01:48:05.297319  3818 solver.cpp:253]     Train net output #0: loss = 1.14165 (* 1 = 1.14165 loss)
I0523 01:48:05.297334  3818 sgd_solver.cpp:106] Iteration 161625, lr = 0.0045
I0523 01:48:15.148737  3818 solver.cpp:237] Iteration 162000, loss = 1.27275
I0523 01:48:15.148772  3818 solver.cpp:253]     Train net output #0: loss = 1.27275 (* 1 = 1.27275 loss)
I0523 01:48:15.148788  3818 sgd_solver.cpp:106] Iteration 162000, lr = 0.0045
I0523 01:48:25.002805  3818 solver.cpp:237] Iteration 162375, loss = 1.071
I0523 01:48:25.002841  3818 solver.cpp:253]     Train net output #0: loss = 1.071 (* 1 = 1.071 loss)
I0523 01:48:25.002856  3818 sgd_solver.cpp:106] Iteration 162375, lr = 0.0045
I0523 01:48:55.766767  3818 solver.cpp:237] Iteration 162750, loss = 1.21891
I0523 01:48:55.766957  3818 solver.cpp:253]     Train net output #0: loss = 1.21891 (* 1 = 1.21891 loss)
I0523 01:48:55.766973  3818 sgd_solver.cpp:106] Iteration 162750, lr = 0.0045
I0523 01:49:05.621853  3818 solver.cpp:237] Iteration 163125, loss = 1.34783
I0523 01:49:05.621889  3818 solver.cpp:253]     Train net output #0: loss = 1.34783 (* 1 = 1.34783 loss)
I0523 01:49:05.621903  3818 sgd_solver.cpp:106] Iteration 163125, lr = 0.0045
I0523 01:49:15.467099  3818 solver.cpp:237] Iteration 163500, loss = 1.19288
I0523 01:49:15.467135  3818 solver.cpp:253]     Train net output #0: loss = 1.19288 (* 1 = 1.19288 loss)
I0523 01:49:15.467149  3818 sgd_solver.cpp:106] Iteration 163500, lr = 0.0045
I0523 01:49:25.320695  3818 solver.cpp:237] Iteration 163875, loss = 1.15048
I0523 01:49:25.320740  3818 solver.cpp:253]     Train net output #0: loss = 1.15048 (* 1 = 1.15048 loss)
I0523 01:49:25.320755  3818 sgd_solver.cpp:106] Iteration 163875, lr = 0.0045
I0523 01:49:35.174203  3818 solver.cpp:237] Iteration 164250, loss = 0.971185
I0523 01:49:35.174382  3818 solver.cpp:253]     Train net output #0: loss = 0.971184 (* 1 = 0.971184 loss)
I0523 01:49:35.174396  3818 sgd_solver.cpp:106] Iteration 164250, lr = 0.0045
I0523 01:49:45.031566  3818 solver.cpp:237] Iteration 164625, loss = 0.742305
I0523 01:49:45.031615  3818 solver.cpp:253]     Train net output #0: loss = 0.742305 (* 1 = 0.742305 loss)
I0523 01:49:45.031628  3818 sgd_solver.cpp:106] Iteration 164625, lr = 0.0045
I0523 01:49:54.857445  3818 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_165000.caffemodel
I0523 01:49:54.912874  3818 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0045_2016-05-20T15.49.04.094905_iter_165000.solverstate
I0523 01:49:54.937976  3818 solver.cpp:341] Iteration 165000, Testing net (#0)
I0523 01:51:04.374805  3818 solver.cpp:409]     Test net output #0: accuracy = 0.899754
I0523 01:51:04.375026  3818 solver.cpp:409]     Test net output #1: loss = 0.330705 (* 1 = 0.330705 loss)
I0523 01:51:25.292765  3818 solver.cpp:237] Iteration 165000, loss = 0.979209
I0523 01:51:25.292819  3818 solver.cpp:253]     Train net output #0: loss = 0.979209 (* 1 = 0.979209 loss)
I0523 01:51:25.292834  3818 sgd_solver.cpp:106] Iteration 165000, lr = 0.0045
I0523 01:51:34.961328  3818 solver.cpp:237] Iteration 165375, loss = 1.23303
I0523 01:51:34.961514  3818 solver.cpp:253]     Train net output #0: loss = 1.23303 (* 1 = 1.23303 loss)
I0523 01:51:34.961529  3818 sgd_solver.cpp:106] Iteration 165375, lr = 0.0045
I0523 01:51:44.622540  3818 solver.cpp:237] Iteration 165750, loss = 1.30958
I0523 01:51:44.622575  3818 solver.cpp:253]     Train net output #0: loss = 1.30958 (* 1 = 1.30958 loss)
I0523 01:51:44.622591  3818 sgd_solver.cpp:106] Iteration 165750, lr = 0.0045
I0523 01:51:54.289050  3818 solver.cpp:237] Iteration 166125, loss = 1.02855
I0523 01:51:54.289099  3818 solver.cpp:253]     Train net output #0: loss = 1.02855 (* 1 = 1.02855 loss)
I0523 01:51:54.289113  3818 sgd_solver.cpp:106] Iteration 166125, lr = 0.0045
I0523 01:52:03.956717  3818 solver.cpp:237] Iteration 166500, loss = 0.954013
I0523 01:52:03.956753  3818 solver.cpp:253]     Train net output #0: loss = 0.954013 (* 1 = 0.954013 loss)
I0523 01:52:03.956768  3818 sgd_solver.cpp:106] Iteration 166500, lr = 0.0045
I0523 01:52:13.636155  3818 solver.cpp:237] Iteration 166875, loss = 1.10542
I0523 01:52:13.636353  3818 solver.cpp:253]     Train net output #0: loss = 1.10542 (* 1 = 1.10542 loss)
I0523 01:52:13.636368  3818 sgd_solver.cpp:106] Iteration 166875, lr = 0.0045
I0523 01:52:23.300055  3818 solver.cpp:237] Iteration 167250, loss = 1.07467
I0523 01:52:23.300091  3818 solver.cpp:253]     Train net output #0: loss = 1.07467 (* 1 = 1.07467 loss)
I0523 01:52:23.300106  3818 sgd_solver.cpp:106] Iteration 167250, lr = 0.0045
I0523 01:52:53.884423  3818 solver.cpp:237] Iteration 167625, loss = 1.24687
I0523 01:52:53.884626  3818 solver.cpp:253]     Train net output #0: loss = 1.24687 (* 1 = 1.24687 loss)
I0523 01:52:53.884641  3818 sgd_solver.cpp:106] Iteration 167625, lr = 0.0045
aprun: Apid 11251849: Caught signal Terminated, sending to application
*** Aborted at 1463982774 (unix time) try "date -d @1463982774" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0xee7) received by PID 3818 (TID 0x2aaac746f900) from PID 3815; stack trace: ***
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7208 exceeded limit 7200
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11251849: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
aprun: Apid 11251849: Caught signal Terminated, sending to application
