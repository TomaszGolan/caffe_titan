2807900
I0522 21:52:07.880501  1275 caffe.cpp:184] Using GPUs 0
I0522 21:52:08.307752  1275 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0035
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033.prototxt"
I0522 21:52:08.309865  1275 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033.prototxt
I0522 21:52:08.322927  1275 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 21:52:08.322986  1275 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 21:52:08.323334  1275 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 21:52:08.323513  1275 layer_factory.hpp:77] Creating layer data_hdf5
I0522 21:52:08.323537  1275 net.cpp:106] Creating Layer data_hdf5
I0522 21:52:08.323552  1275 net.cpp:411] data_hdf5 -> data
I0522 21:52:08.323586  1275 net.cpp:411] data_hdf5 -> label
I0522 21:52:08.323618  1275 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 21:52:08.325065  1275 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 21:52:08.327414  1275 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 21:52:29.871217  1275 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 21:52:29.876425  1275 net.cpp:150] Setting up data_hdf5
I0522 21:52:29.876467  1275 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 21:52:29.876482  1275 net.cpp:157] Top shape: 40 (40)
I0522 21:52:29.876492  1275 net.cpp:165] Memory required for data: 1016160
I0522 21:52:29.876507  1275 layer_factory.hpp:77] Creating layer conv1
I0522 21:52:29.876540  1275 net.cpp:106] Creating Layer conv1
I0522 21:52:29.876552  1275 net.cpp:454] conv1 <- data
I0522 21:52:29.876575  1275 net.cpp:411] conv1 -> conv1
I0522 21:52:31.294308  1275 net.cpp:150] Setting up conv1
I0522 21:52:31.294355  1275 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 21:52:31.294366  1275 net.cpp:165] Memory required for data: 12075360
I0522 21:52:31.294396  1275 layer_factory.hpp:77] Creating layer relu1
I0522 21:52:31.294419  1275 net.cpp:106] Creating Layer relu1
I0522 21:52:31.294430  1275 net.cpp:454] relu1 <- conv1
I0522 21:52:31.294442  1275 net.cpp:397] relu1 -> conv1 (in-place)
I0522 21:52:31.294963  1275 net.cpp:150] Setting up relu1
I0522 21:52:31.294980  1275 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 21:52:31.294989  1275 net.cpp:165] Memory required for data: 23134560
I0522 21:52:31.295001  1275 layer_factory.hpp:77] Creating layer pool1
I0522 21:52:31.295017  1275 net.cpp:106] Creating Layer pool1
I0522 21:52:31.295027  1275 net.cpp:454] pool1 <- conv1
I0522 21:52:31.295039  1275 net.cpp:411] pool1 -> pool1
I0522 21:52:31.295120  1275 net.cpp:150] Setting up pool1
I0522 21:52:31.295133  1275 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 21:52:31.295143  1275 net.cpp:165] Memory required for data: 28664160
I0522 21:52:31.295155  1275 layer_factory.hpp:77] Creating layer conv2
I0522 21:52:31.295177  1275 net.cpp:106] Creating Layer conv2
I0522 21:52:31.295187  1275 net.cpp:454] conv2 <- pool1
I0522 21:52:31.295200  1275 net.cpp:411] conv2 -> conv2
I0522 21:52:31.297879  1275 net.cpp:150] Setting up conv2
I0522 21:52:31.297920  1275 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 21:52:31.297931  1275 net.cpp:165] Memory required for data: 36612960
I0522 21:52:31.297952  1275 layer_factory.hpp:77] Creating layer relu2
I0522 21:52:31.297966  1275 net.cpp:106] Creating Layer relu2
I0522 21:52:31.297976  1275 net.cpp:454] relu2 <- conv2
I0522 21:52:31.297987  1275 net.cpp:397] relu2 -> conv2 (in-place)
I0522 21:52:31.298319  1275 net.cpp:150] Setting up relu2
I0522 21:52:31.298333  1275 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 21:52:31.298343  1275 net.cpp:165] Memory required for data: 44561760
I0522 21:52:31.298353  1275 layer_factory.hpp:77] Creating layer pool2
I0522 21:52:31.298367  1275 net.cpp:106] Creating Layer pool2
I0522 21:52:31.298377  1275 net.cpp:454] pool2 <- conv2
I0522 21:52:31.298389  1275 net.cpp:411] pool2 -> pool2
I0522 21:52:31.298470  1275 net.cpp:150] Setting up pool2
I0522 21:52:31.298483  1275 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 21:52:31.298493  1275 net.cpp:165] Memory required for data: 48536160
I0522 21:52:31.298503  1275 layer_factory.hpp:77] Creating layer conv3
I0522 21:52:31.298521  1275 net.cpp:106] Creating Layer conv3
I0522 21:52:31.298532  1275 net.cpp:454] conv3 <- pool2
I0522 21:52:31.298544  1275 net.cpp:411] conv3 -> conv3
I0522 21:52:31.300482  1275 net.cpp:150] Setting up conv3
I0522 21:52:31.300505  1275 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 21:52:31.300518  1275 net.cpp:165] Memory required for data: 52872800
I0522 21:52:31.300535  1275 layer_factory.hpp:77] Creating layer relu3
I0522 21:52:31.300552  1275 net.cpp:106] Creating Layer relu3
I0522 21:52:31.300562  1275 net.cpp:454] relu3 <- conv3
I0522 21:52:31.300575  1275 net.cpp:397] relu3 -> conv3 (in-place)
I0522 21:52:31.301043  1275 net.cpp:150] Setting up relu3
I0522 21:52:31.301060  1275 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 21:52:31.301070  1275 net.cpp:165] Memory required for data: 57209440
I0522 21:52:31.301081  1275 layer_factory.hpp:77] Creating layer pool3
I0522 21:52:31.301095  1275 net.cpp:106] Creating Layer pool3
I0522 21:52:31.301105  1275 net.cpp:454] pool3 <- conv3
I0522 21:52:31.301116  1275 net.cpp:411] pool3 -> pool3
I0522 21:52:31.301184  1275 net.cpp:150] Setting up pool3
I0522 21:52:31.301198  1275 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 21:52:31.301208  1275 net.cpp:165] Memory required for data: 59377760
I0522 21:52:31.301216  1275 layer_factory.hpp:77] Creating layer conv4
I0522 21:52:31.301232  1275 net.cpp:106] Creating Layer conv4
I0522 21:52:31.301242  1275 net.cpp:454] conv4 <- pool3
I0522 21:52:31.301256  1275 net.cpp:411] conv4 -> conv4
I0522 21:52:31.304031  1275 net.cpp:150] Setting up conv4
I0522 21:52:31.304055  1275 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 21:52:31.304065  1275 net.cpp:165] Memory required for data: 60829280
I0522 21:52:31.304080  1275 layer_factory.hpp:77] Creating layer relu4
I0522 21:52:31.304095  1275 net.cpp:106] Creating Layer relu4
I0522 21:52:31.304105  1275 net.cpp:454] relu4 <- conv4
I0522 21:52:31.304118  1275 net.cpp:397] relu4 -> conv4 (in-place)
I0522 21:52:31.304589  1275 net.cpp:150] Setting up relu4
I0522 21:52:31.304605  1275 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 21:52:31.304615  1275 net.cpp:165] Memory required for data: 62280800
I0522 21:52:31.304625  1275 layer_factory.hpp:77] Creating layer pool4
I0522 21:52:31.304638  1275 net.cpp:106] Creating Layer pool4
I0522 21:52:31.304648  1275 net.cpp:454] pool4 <- conv4
I0522 21:52:31.304661  1275 net.cpp:411] pool4 -> pool4
I0522 21:52:31.304729  1275 net.cpp:150] Setting up pool4
I0522 21:52:31.304744  1275 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 21:52:31.304754  1275 net.cpp:165] Memory required for data: 63006560
I0522 21:52:31.304764  1275 layer_factory.hpp:77] Creating layer ip1
I0522 21:52:31.304785  1275 net.cpp:106] Creating Layer ip1
I0522 21:52:31.304795  1275 net.cpp:454] ip1 <- pool4
I0522 21:52:31.304807  1275 net.cpp:411] ip1 -> ip1
I0522 21:52:31.320253  1275 net.cpp:150] Setting up ip1
I0522 21:52:31.320283  1275 net.cpp:157] Top shape: 40 196 (7840)
I0522 21:52:31.320296  1275 net.cpp:165] Memory required for data: 63037920
I0522 21:52:31.320318  1275 layer_factory.hpp:77] Creating layer relu5
I0522 21:52:31.320333  1275 net.cpp:106] Creating Layer relu5
I0522 21:52:31.320343  1275 net.cpp:454] relu5 <- ip1
I0522 21:52:31.320358  1275 net.cpp:397] relu5 -> ip1 (in-place)
I0522 21:52:31.320699  1275 net.cpp:150] Setting up relu5
I0522 21:52:31.320713  1275 net.cpp:157] Top shape: 40 196 (7840)
I0522 21:52:31.320724  1275 net.cpp:165] Memory required for data: 63069280
I0522 21:52:31.320734  1275 layer_factory.hpp:77] Creating layer drop1
I0522 21:52:31.320756  1275 net.cpp:106] Creating Layer drop1
I0522 21:52:31.320767  1275 net.cpp:454] drop1 <- ip1
I0522 21:52:31.320780  1275 net.cpp:397] drop1 -> ip1 (in-place)
I0522 21:52:31.320839  1275 net.cpp:150] Setting up drop1
I0522 21:52:31.320852  1275 net.cpp:157] Top shape: 40 196 (7840)
I0522 21:52:31.320863  1275 net.cpp:165] Memory required for data: 63100640
I0522 21:52:31.320873  1275 layer_factory.hpp:77] Creating layer ip2
I0522 21:52:31.320893  1275 net.cpp:106] Creating Layer ip2
I0522 21:52:31.320902  1275 net.cpp:454] ip2 <- ip1
I0522 21:52:31.320916  1275 net.cpp:411] ip2 -> ip2
I0522 21:52:31.321378  1275 net.cpp:150] Setting up ip2
I0522 21:52:31.321393  1275 net.cpp:157] Top shape: 40 98 (3920)
I0522 21:52:31.321401  1275 net.cpp:165] Memory required for data: 63116320
I0522 21:52:31.321418  1275 layer_factory.hpp:77] Creating layer relu6
I0522 21:52:31.321429  1275 net.cpp:106] Creating Layer relu6
I0522 21:52:31.321439  1275 net.cpp:454] relu6 <- ip2
I0522 21:52:31.321451  1275 net.cpp:397] relu6 -> ip2 (in-place)
I0522 21:52:31.321977  1275 net.cpp:150] Setting up relu6
I0522 21:52:31.321993  1275 net.cpp:157] Top shape: 40 98 (3920)
I0522 21:52:31.322003  1275 net.cpp:165] Memory required for data: 63132000
I0522 21:52:31.322015  1275 layer_factory.hpp:77] Creating layer drop2
I0522 21:52:31.322027  1275 net.cpp:106] Creating Layer drop2
I0522 21:52:31.322037  1275 net.cpp:454] drop2 <- ip2
I0522 21:52:31.322051  1275 net.cpp:397] drop2 -> ip2 (in-place)
I0522 21:52:31.322093  1275 net.cpp:150] Setting up drop2
I0522 21:52:31.322106  1275 net.cpp:157] Top shape: 40 98 (3920)
I0522 21:52:31.322116  1275 net.cpp:165] Memory required for data: 63147680
I0522 21:52:31.322127  1275 layer_factory.hpp:77] Creating layer ip3
I0522 21:52:31.322140  1275 net.cpp:106] Creating Layer ip3
I0522 21:52:31.322150  1275 net.cpp:454] ip3 <- ip2
I0522 21:52:31.322161  1275 net.cpp:411] ip3 -> ip3
I0522 21:52:31.322373  1275 net.cpp:150] Setting up ip3
I0522 21:52:31.322386  1275 net.cpp:157] Top shape: 40 11 (440)
I0522 21:52:31.322396  1275 net.cpp:165] Memory required for data: 63149440
I0522 21:52:31.322410  1275 layer_factory.hpp:77] Creating layer drop3
I0522 21:52:31.322423  1275 net.cpp:106] Creating Layer drop3
I0522 21:52:31.322432  1275 net.cpp:454] drop3 <- ip3
I0522 21:52:31.322445  1275 net.cpp:397] drop3 -> ip3 (in-place)
I0522 21:52:31.322484  1275 net.cpp:150] Setting up drop3
I0522 21:52:31.322497  1275 net.cpp:157] Top shape: 40 11 (440)
I0522 21:52:31.322507  1275 net.cpp:165] Memory required for data: 63151200
I0522 21:52:31.322517  1275 layer_factory.hpp:77] Creating layer loss
I0522 21:52:31.322536  1275 net.cpp:106] Creating Layer loss
I0522 21:52:31.322546  1275 net.cpp:454] loss <- ip3
I0522 21:52:31.322557  1275 net.cpp:454] loss <- label
I0522 21:52:31.322571  1275 net.cpp:411] loss -> loss
I0522 21:52:31.322587  1275 layer_factory.hpp:77] Creating layer loss
I0522 21:52:31.323232  1275 net.cpp:150] Setting up loss
I0522 21:52:31.323252  1275 net.cpp:157] Top shape: (1)
I0522 21:52:31.323266  1275 net.cpp:160]     with loss weight 1
I0522 21:52:31.323310  1275 net.cpp:165] Memory required for data: 63151204
I0522 21:52:31.323323  1275 net.cpp:226] loss needs backward computation.
I0522 21:52:31.323333  1275 net.cpp:226] drop3 needs backward computation.
I0522 21:52:31.323341  1275 net.cpp:226] ip3 needs backward computation.
I0522 21:52:31.323353  1275 net.cpp:226] drop2 needs backward computation.
I0522 21:52:31.323362  1275 net.cpp:226] relu6 needs backward computation.
I0522 21:52:31.323372  1275 net.cpp:226] ip2 needs backward computation.
I0522 21:52:31.323382  1275 net.cpp:226] drop1 needs backward computation.
I0522 21:52:31.323392  1275 net.cpp:226] relu5 needs backward computation.
I0522 21:52:31.323401  1275 net.cpp:226] ip1 needs backward computation.
I0522 21:52:31.323412  1275 net.cpp:226] pool4 needs backward computation.
I0522 21:52:31.323422  1275 net.cpp:226] relu4 needs backward computation.
I0522 21:52:31.323432  1275 net.cpp:226] conv4 needs backward computation.
I0522 21:52:31.323442  1275 net.cpp:226] pool3 needs backward computation.
I0522 21:52:31.323453  1275 net.cpp:226] relu3 needs backward computation.
I0522 21:52:31.323462  1275 net.cpp:226] conv3 needs backward computation.
I0522 21:52:31.323482  1275 net.cpp:226] pool2 needs backward computation.
I0522 21:52:31.323493  1275 net.cpp:226] relu2 needs backward computation.
I0522 21:52:31.323503  1275 net.cpp:226] conv2 needs backward computation.
I0522 21:52:31.323514  1275 net.cpp:226] pool1 needs backward computation.
I0522 21:52:31.323524  1275 net.cpp:226] relu1 needs backward computation.
I0522 21:52:31.323534  1275 net.cpp:226] conv1 needs backward computation.
I0522 21:52:31.323545  1275 net.cpp:228] data_hdf5 does not need backward computation.
I0522 21:52:31.323555  1275 net.cpp:270] This network produces output loss
I0522 21:52:31.323580  1275 net.cpp:283] Network initialization done.
I0522 21:52:31.325268  1275 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033.prototxt
I0522 21:52:31.325340  1275 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 21:52:31.325697  1275 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 21:52:31.325886  1275 layer_factory.hpp:77] Creating layer data_hdf5
I0522 21:52:31.325916  1275 net.cpp:106] Creating Layer data_hdf5
I0522 21:52:31.325928  1275 net.cpp:411] data_hdf5 -> data
I0522 21:52:31.325945  1275 net.cpp:411] data_hdf5 -> label
I0522 21:52:31.325961  1275 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 21:52:31.336889  1275 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 21:52:52.852973  1275 net.cpp:150] Setting up data_hdf5
I0522 21:52:52.853139  1275 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0522 21:52:52.853153  1275 net.cpp:157] Top shape: 40 (40)
I0522 21:52:52.853165  1275 net.cpp:165] Memory required for data: 1016160
I0522 21:52:52.853179  1275 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 21:52:52.853207  1275 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 21:52:52.853219  1275 net.cpp:454] label_data_hdf5_1_split <- label
I0522 21:52:52.853234  1275 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 21:52:52.853255  1275 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 21:52:52.853327  1275 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 21:52:52.853341  1275 net.cpp:157] Top shape: 40 (40)
I0522 21:52:52.853353  1275 net.cpp:157] Top shape: 40 (40)
I0522 21:52:52.853363  1275 net.cpp:165] Memory required for data: 1016480
I0522 21:52:52.853373  1275 layer_factory.hpp:77] Creating layer conv1
I0522 21:52:52.853392  1275 net.cpp:106] Creating Layer conv1
I0522 21:52:52.853404  1275 net.cpp:454] conv1 <- data
I0522 21:52:52.853417  1275 net.cpp:411] conv1 -> conv1
I0522 21:52:52.855376  1275 net.cpp:150] Setting up conv1
I0522 21:52:52.855406  1275 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 21:52:52.855415  1275 net.cpp:165] Memory required for data: 12075680
I0522 21:52:52.855437  1275 layer_factory.hpp:77] Creating layer relu1
I0522 21:52:52.855453  1275 net.cpp:106] Creating Layer relu1
I0522 21:52:52.855463  1275 net.cpp:454] relu1 <- conv1
I0522 21:52:52.855476  1275 net.cpp:397] relu1 -> conv1 (in-place)
I0522 21:52:52.855973  1275 net.cpp:150] Setting up relu1
I0522 21:52:52.855989  1275 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0522 21:52:52.855999  1275 net.cpp:165] Memory required for data: 23134880
I0522 21:52:52.856009  1275 layer_factory.hpp:77] Creating layer pool1
I0522 21:52:52.856025  1275 net.cpp:106] Creating Layer pool1
I0522 21:52:52.856035  1275 net.cpp:454] pool1 <- conv1
I0522 21:52:52.856048  1275 net.cpp:411] pool1 -> pool1
I0522 21:52:52.856122  1275 net.cpp:150] Setting up pool1
I0522 21:52:52.856137  1275 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0522 21:52:52.856147  1275 net.cpp:165] Memory required for data: 28664480
I0522 21:52:52.856156  1275 layer_factory.hpp:77] Creating layer conv2
I0522 21:52:52.856173  1275 net.cpp:106] Creating Layer conv2
I0522 21:52:52.856184  1275 net.cpp:454] conv2 <- pool1
I0522 21:52:52.856199  1275 net.cpp:411] conv2 -> conv2
I0522 21:52:52.858106  1275 net.cpp:150] Setting up conv2
I0522 21:52:52.858129  1275 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 21:52:52.858141  1275 net.cpp:165] Memory required for data: 36613280
I0522 21:52:52.858158  1275 layer_factory.hpp:77] Creating layer relu2
I0522 21:52:52.858172  1275 net.cpp:106] Creating Layer relu2
I0522 21:52:52.858182  1275 net.cpp:454] relu2 <- conv2
I0522 21:52:52.858196  1275 net.cpp:397] relu2 -> conv2 (in-place)
I0522 21:52:52.858526  1275 net.cpp:150] Setting up relu2
I0522 21:52:52.858541  1275 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0522 21:52:52.858549  1275 net.cpp:165] Memory required for data: 44562080
I0522 21:52:52.858559  1275 layer_factory.hpp:77] Creating layer pool2
I0522 21:52:52.858572  1275 net.cpp:106] Creating Layer pool2
I0522 21:52:52.858582  1275 net.cpp:454] pool2 <- conv2
I0522 21:52:52.858594  1275 net.cpp:411] pool2 -> pool2
I0522 21:52:52.858665  1275 net.cpp:150] Setting up pool2
I0522 21:52:52.858678  1275 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0522 21:52:52.858687  1275 net.cpp:165] Memory required for data: 48536480
I0522 21:52:52.858697  1275 layer_factory.hpp:77] Creating layer conv3
I0522 21:52:52.858717  1275 net.cpp:106] Creating Layer conv3
I0522 21:52:52.858727  1275 net.cpp:454] conv3 <- pool2
I0522 21:52:52.858741  1275 net.cpp:411] conv3 -> conv3
I0522 21:52:52.860698  1275 net.cpp:150] Setting up conv3
I0522 21:52:52.860721  1275 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 21:52:52.860733  1275 net.cpp:165] Memory required for data: 52873120
I0522 21:52:52.860765  1275 layer_factory.hpp:77] Creating layer relu3
I0522 21:52:52.860779  1275 net.cpp:106] Creating Layer relu3
I0522 21:52:52.860790  1275 net.cpp:454] relu3 <- conv3
I0522 21:52:52.860802  1275 net.cpp:397] relu3 -> conv3 (in-place)
I0522 21:52:52.861277  1275 net.cpp:150] Setting up relu3
I0522 21:52:52.861294  1275 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0522 21:52:52.861304  1275 net.cpp:165] Memory required for data: 57209760
I0522 21:52:52.861313  1275 layer_factory.hpp:77] Creating layer pool3
I0522 21:52:52.861326  1275 net.cpp:106] Creating Layer pool3
I0522 21:52:52.861336  1275 net.cpp:454] pool3 <- conv3
I0522 21:52:52.861349  1275 net.cpp:411] pool3 -> pool3
I0522 21:52:52.861421  1275 net.cpp:150] Setting up pool3
I0522 21:52:52.861434  1275 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0522 21:52:52.861444  1275 net.cpp:165] Memory required for data: 59378080
I0522 21:52:52.861454  1275 layer_factory.hpp:77] Creating layer conv4
I0522 21:52:52.861472  1275 net.cpp:106] Creating Layer conv4
I0522 21:52:52.861482  1275 net.cpp:454] conv4 <- pool3
I0522 21:52:52.861495  1275 net.cpp:411] conv4 -> conv4
I0522 21:52:52.863554  1275 net.cpp:150] Setting up conv4
I0522 21:52:52.863577  1275 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 21:52:52.863587  1275 net.cpp:165] Memory required for data: 60829600
I0522 21:52:52.863603  1275 layer_factory.hpp:77] Creating layer relu4
I0522 21:52:52.863616  1275 net.cpp:106] Creating Layer relu4
I0522 21:52:52.863626  1275 net.cpp:454] relu4 <- conv4
I0522 21:52:52.863639  1275 net.cpp:397] relu4 -> conv4 (in-place)
I0522 21:52:52.864109  1275 net.cpp:150] Setting up relu4
I0522 21:52:52.864123  1275 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0522 21:52:52.864133  1275 net.cpp:165] Memory required for data: 62281120
I0522 21:52:52.864143  1275 layer_factory.hpp:77] Creating layer pool4
I0522 21:52:52.864157  1275 net.cpp:106] Creating Layer pool4
I0522 21:52:52.864166  1275 net.cpp:454] pool4 <- conv4
I0522 21:52:52.864181  1275 net.cpp:411] pool4 -> pool4
I0522 21:52:52.864251  1275 net.cpp:150] Setting up pool4
I0522 21:52:52.864264  1275 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0522 21:52:52.864274  1275 net.cpp:165] Memory required for data: 63006880
I0522 21:52:52.864284  1275 layer_factory.hpp:77] Creating layer ip1
I0522 21:52:52.864298  1275 net.cpp:106] Creating Layer ip1
I0522 21:52:52.864310  1275 net.cpp:454] ip1 <- pool4
I0522 21:52:52.864322  1275 net.cpp:411] ip1 -> ip1
I0522 21:52:52.879760  1275 net.cpp:150] Setting up ip1
I0522 21:52:52.879786  1275 net.cpp:157] Top shape: 40 196 (7840)
I0522 21:52:52.879797  1275 net.cpp:165] Memory required for data: 63038240
I0522 21:52:52.879820  1275 layer_factory.hpp:77] Creating layer relu5
I0522 21:52:52.879835  1275 net.cpp:106] Creating Layer relu5
I0522 21:52:52.879845  1275 net.cpp:454] relu5 <- ip1
I0522 21:52:52.879863  1275 net.cpp:397] relu5 -> ip1 (in-place)
I0522 21:52:52.880208  1275 net.cpp:150] Setting up relu5
I0522 21:52:52.880223  1275 net.cpp:157] Top shape: 40 196 (7840)
I0522 21:52:52.880233  1275 net.cpp:165] Memory required for data: 63069600
I0522 21:52:52.880242  1275 layer_factory.hpp:77] Creating layer drop1
I0522 21:52:52.880261  1275 net.cpp:106] Creating Layer drop1
I0522 21:52:52.880271  1275 net.cpp:454] drop1 <- ip1
I0522 21:52:52.880285  1275 net.cpp:397] drop1 -> ip1 (in-place)
I0522 21:52:52.880331  1275 net.cpp:150] Setting up drop1
I0522 21:52:52.880344  1275 net.cpp:157] Top shape: 40 196 (7840)
I0522 21:52:52.880354  1275 net.cpp:165] Memory required for data: 63100960
I0522 21:52:52.880364  1275 layer_factory.hpp:77] Creating layer ip2
I0522 21:52:52.880379  1275 net.cpp:106] Creating Layer ip2
I0522 21:52:52.880388  1275 net.cpp:454] ip2 <- ip1
I0522 21:52:52.880403  1275 net.cpp:411] ip2 -> ip2
I0522 21:52:52.880879  1275 net.cpp:150] Setting up ip2
I0522 21:52:52.880892  1275 net.cpp:157] Top shape: 40 98 (3920)
I0522 21:52:52.880903  1275 net.cpp:165] Memory required for data: 63116640
I0522 21:52:52.880918  1275 layer_factory.hpp:77] Creating layer relu6
I0522 21:52:52.880944  1275 net.cpp:106] Creating Layer relu6
I0522 21:52:52.880954  1275 net.cpp:454] relu6 <- ip2
I0522 21:52:52.880966  1275 net.cpp:397] relu6 -> ip2 (in-place)
I0522 21:52:52.881496  1275 net.cpp:150] Setting up relu6
I0522 21:52:52.881513  1275 net.cpp:157] Top shape: 40 98 (3920)
I0522 21:52:52.881522  1275 net.cpp:165] Memory required for data: 63132320
I0522 21:52:52.881532  1275 layer_factory.hpp:77] Creating layer drop2
I0522 21:52:52.881546  1275 net.cpp:106] Creating Layer drop2
I0522 21:52:52.881556  1275 net.cpp:454] drop2 <- ip2
I0522 21:52:52.881569  1275 net.cpp:397] drop2 -> ip2 (in-place)
I0522 21:52:52.881613  1275 net.cpp:150] Setting up drop2
I0522 21:52:52.881625  1275 net.cpp:157] Top shape: 40 98 (3920)
I0522 21:52:52.881635  1275 net.cpp:165] Memory required for data: 63148000
I0522 21:52:52.881645  1275 layer_factory.hpp:77] Creating layer ip3
I0522 21:52:52.881659  1275 net.cpp:106] Creating Layer ip3
I0522 21:52:52.881669  1275 net.cpp:454] ip3 <- ip2
I0522 21:52:52.881683  1275 net.cpp:411] ip3 -> ip3
I0522 21:52:52.881912  1275 net.cpp:150] Setting up ip3
I0522 21:52:52.881925  1275 net.cpp:157] Top shape: 40 11 (440)
I0522 21:52:52.881935  1275 net.cpp:165] Memory required for data: 63149760
I0522 21:52:52.881952  1275 layer_factory.hpp:77] Creating layer drop3
I0522 21:52:52.881964  1275 net.cpp:106] Creating Layer drop3
I0522 21:52:52.881974  1275 net.cpp:454] drop3 <- ip3
I0522 21:52:52.881988  1275 net.cpp:397] drop3 -> ip3 (in-place)
I0522 21:52:52.882028  1275 net.cpp:150] Setting up drop3
I0522 21:52:52.882040  1275 net.cpp:157] Top shape: 40 11 (440)
I0522 21:52:52.882050  1275 net.cpp:165] Memory required for data: 63151520
I0522 21:52:52.882061  1275 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 21:52:52.882073  1275 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 21:52:52.882083  1275 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 21:52:52.882097  1275 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 21:52:52.882112  1275 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 21:52:52.882184  1275 net.cpp:150] Setting up ip3_drop3_0_split
I0522 21:52:52.882199  1275 net.cpp:157] Top shape: 40 11 (440)
I0522 21:52:52.882210  1275 net.cpp:157] Top shape: 40 11 (440)
I0522 21:52:52.882220  1275 net.cpp:165] Memory required for data: 63155040
I0522 21:52:52.882230  1275 layer_factory.hpp:77] Creating layer accuracy
I0522 21:52:52.882251  1275 net.cpp:106] Creating Layer accuracy
I0522 21:52:52.882261  1275 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 21:52:52.882272  1275 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 21:52:52.882287  1275 net.cpp:411] accuracy -> accuracy
I0522 21:52:52.882310  1275 net.cpp:150] Setting up accuracy
I0522 21:52:52.882323  1275 net.cpp:157] Top shape: (1)
I0522 21:52:52.882333  1275 net.cpp:165] Memory required for data: 63155044
I0522 21:52:52.882342  1275 layer_factory.hpp:77] Creating layer loss
I0522 21:52:52.882356  1275 net.cpp:106] Creating Layer loss
I0522 21:52:52.882366  1275 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 21:52:52.882377  1275 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 21:52:52.882391  1275 net.cpp:411] loss -> loss
I0522 21:52:52.882408  1275 layer_factory.hpp:77] Creating layer loss
I0522 21:52:52.882894  1275 net.cpp:150] Setting up loss
I0522 21:52:52.882907  1275 net.cpp:157] Top shape: (1)
I0522 21:52:52.882917  1275 net.cpp:160]     with loss weight 1
I0522 21:52:52.882937  1275 net.cpp:165] Memory required for data: 63155048
I0522 21:52:52.882948  1275 net.cpp:226] loss needs backward computation.
I0522 21:52:52.882961  1275 net.cpp:228] accuracy does not need backward computation.
I0522 21:52:52.882972  1275 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 21:52:52.882982  1275 net.cpp:226] drop3 needs backward computation.
I0522 21:52:52.882992  1275 net.cpp:226] ip3 needs backward computation.
I0522 21:52:52.883003  1275 net.cpp:226] drop2 needs backward computation.
I0522 21:52:52.883013  1275 net.cpp:226] relu6 needs backward computation.
I0522 21:52:52.883030  1275 net.cpp:226] ip2 needs backward computation.
I0522 21:52:52.883040  1275 net.cpp:226] drop1 needs backward computation.
I0522 21:52:52.883050  1275 net.cpp:226] relu5 needs backward computation.
I0522 21:52:52.883060  1275 net.cpp:226] ip1 needs backward computation.
I0522 21:52:52.883070  1275 net.cpp:226] pool4 needs backward computation.
I0522 21:52:52.883080  1275 net.cpp:226] relu4 needs backward computation.
I0522 21:52:52.883090  1275 net.cpp:226] conv4 needs backward computation.
I0522 21:52:52.883100  1275 net.cpp:226] pool3 needs backward computation.
I0522 21:52:52.883111  1275 net.cpp:226] relu3 needs backward computation.
I0522 21:52:52.883121  1275 net.cpp:226] conv3 needs backward computation.
I0522 21:52:52.883131  1275 net.cpp:226] pool2 needs backward computation.
I0522 21:52:52.883142  1275 net.cpp:226] relu2 needs backward computation.
I0522 21:52:52.883152  1275 net.cpp:226] conv2 needs backward computation.
I0522 21:52:52.883162  1275 net.cpp:226] pool1 needs backward computation.
I0522 21:52:52.883173  1275 net.cpp:226] relu1 needs backward computation.
I0522 21:52:52.883183  1275 net.cpp:226] conv1 needs backward computation.
I0522 21:52:52.883194  1275 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 21:52:52.883206  1275 net.cpp:228] data_hdf5 does not need backward computation.
I0522 21:52:52.883216  1275 net.cpp:270] This network produces output accuracy
I0522 21:52:52.883227  1275 net.cpp:270] This network produces output loss
I0522 21:52:52.883255  1275 net.cpp:283] Network initialization done.
I0522 21:52:52.883389  1275 solver.cpp:60] Solver scaffolding done.
I0522 21:52:52.884518  1275 caffe.cpp:212] Starting Optimization
I0522 21:52:52.884536  1275 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 21:52:52.884551  1275 solver.cpp:289] Learning Rate Policy: fixed
I0522 21:52:52.885792  1275 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 21:53:42.460026  1275 solver.cpp:409]     Test net output #0: accuracy = 0.124974
I0522 21:53:42.460191  1275 solver.cpp:409]     Test net output #1: loss = 2.39699 (* 1 = 2.39699 loss)
I0522 21:53:42.482861  1275 solver.cpp:237] Iteration 0, loss = 2.39907
I0522 21:53:42.482898  1275 solver.cpp:253]     Train net output #0: loss = 2.39907 (* 1 = 2.39907 loss)
I0522 21:53:42.482918  1275 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0522 21:53:52.330173  1275 solver.cpp:237] Iteration 375, loss = 2.11294
I0522 21:53:52.330207  1275 solver.cpp:253]     Train net output #0: loss = 2.11294 (* 1 = 2.11294 loss)
I0522 21:53:52.330225  1275 sgd_solver.cpp:106] Iteration 375, lr = 0.0035
I0522 21:54:02.177242  1275 solver.cpp:237] Iteration 750, loss = 2.09756
I0522 21:54:02.177278  1275 solver.cpp:253]     Train net output #0: loss = 2.09756 (* 1 = 2.09756 loss)
I0522 21:54:02.177294  1275 sgd_solver.cpp:106] Iteration 750, lr = 0.0035
I0522 21:54:12.089373  1275 solver.cpp:237] Iteration 1125, loss = 1.81962
I0522 21:54:12.089426  1275 solver.cpp:253]     Train net output #0: loss = 1.81962 (* 1 = 1.81962 loss)
I0522 21:54:12.089442  1275 sgd_solver.cpp:106] Iteration 1125, lr = 0.0035
I0522 21:54:21.998947  1275 solver.cpp:237] Iteration 1500, loss = 1.59383
I0522 21:54:21.999097  1275 solver.cpp:253]     Train net output #0: loss = 1.59383 (* 1 = 1.59383 loss)
I0522 21:54:21.999111  1275 sgd_solver.cpp:106] Iteration 1500, lr = 0.0035
I0522 21:54:31.903628  1275 solver.cpp:237] Iteration 1875, loss = 2.04214
I0522 21:54:31.903681  1275 solver.cpp:253]     Train net output #0: loss = 2.04214 (* 1 = 2.04214 loss)
I0522 21:54:31.903694  1275 sgd_solver.cpp:106] Iteration 1875, lr = 0.0035
I0522 21:54:41.810489  1275 solver.cpp:237] Iteration 2250, loss = 1.63646
I0522 21:54:41.810525  1275 solver.cpp:253]     Train net output #0: loss = 1.63646 (* 1 = 1.63646 loss)
I0522 21:54:41.810541  1275 sgd_solver.cpp:106] Iteration 2250, lr = 0.0035
I0522 21:55:13.919055  1275 solver.cpp:237] Iteration 2625, loss = 1.59104
I0522 21:55:13.919221  1275 solver.cpp:253]     Train net output #0: loss = 1.59104 (* 1 = 1.59104 loss)
I0522 21:55:13.919236  1275 sgd_solver.cpp:106] Iteration 2625, lr = 0.0035
I0522 21:55:23.831315  1275 solver.cpp:237] Iteration 3000, loss = 1.49529
I0522 21:55:23.831359  1275 solver.cpp:253]     Train net output #0: loss = 1.49529 (* 1 = 1.49529 loss)
I0522 21:55:23.831378  1275 sgd_solver.cpp:106] Iteration 3000, lr = 0.0035
I0522 21:55:33.737717  1275 solver.cpp:237] Iteration 3375, loss = 1.72137
I0522 21:55:33.737753  1275 solver.cpp:253]     Train net output #0: loss = 1.72137 (* 1 = 1.72137 loss)
I0522 21:55:33.737769  1275 sgd_solver.cpp:106] Iteration 3375, lr = 0.0035
I0522 21:55:43.622921  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_3750.caffemodel
I0522 21:55:43.682121  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_3750.solverstate
I0522 21:55:43.715378  1275 solver.cpp:237] Iteration 3750, loss = 1.36849
I0522 21:55:43.715427  1275 solver.cpp:253]     Train net output #0: loss = 1.36849 (* 1 = 1.36849 loss)
I0522 21:55:43.715441  1275 sgd_solver.cpp:106] Iteration 3750, lr = 0.0035
I0522 21:55:53.629807  1275 solver.cpp:237] Iteration 4125, loss = 1.68143
I0522 21:55:53.629963  1275 solver.cpp:253]     Train net output #0: loss = 1.68143 (* 1 = 1.68143 loss)
I0522 21:55:53.629976  1275 sgd_solver.cpp:106] Iteration 4125, lr = 0.0035
I0522 21:56:03.543941  1275 solver.cpp:237] Iteration 4500, loss = 1.62531
I0522 21:56:03.543975  1275 solver.cpp:253]     Train net output #0: loss = 1.62531 (* 1 = 1.62531 loss)
I0522 21:56:03.543989  1275 sgd_solver.cpp:106] Iteration 4500, lr = 0.0035
I0522 21:56:13.455636  1275 solver.cpp:237] Iteration 4875, loss = 1.18382
I0522 21:56:13.455678  1275 solver.cpp:253]     Train net output #0: loss = 1.18382 (* 1 = 1.18382 loss)
I0522 21:56:13.455692  1275 sgd_solver.cpp:106] Iteration 4875, lr = 0.0035
I0522 21:56:45.560479  1275 solver.cpp:237] Iteration 5250, loss = 1.18125
I0522 21:56:45.560628  1275 solver.cpp:253]     Train net output #0: loss = 1.18125 (* 1 = 1.18125 loss)
I0522 21:56:45.560642  1275 sgd_solver.cpp:106] Iteration 5250, lr = 0.0035
I0522 21:56:55.471597  1275 solver.cpp:237] Iteration 5625, loss = 1.44916
I0522 21:56:55.471632  1275 solver.cpp:253]     Train net output #0: loss = 1.44916 (* 1 = 1.44916 loss)
I0522 21:56:55.471648  1275 sgd_solver.cpp:106] Iteration 5625, lr = 0.0035
I0522 21:57:05.385617  1275 solver.cpp:237] Iteration 6000, loss = 1.55468
I0522 21:57:05.385665  1275 solver.cpp:253]     Train net output #0: loss = 1.55468 (* 1 = 1.55468 loss)
I0522 21:57:05.385682  1275 sgd_solver.cpp:106] Iteration 6000, lr = 0.0035
I0522 21:57:15.301169  1275 solver.cpp:237] Iteration 6375, loss = 1.34694
I0522 21:57:15.301205  1275 solver.cpp:253]     Train net output #0: loss = 1.34694 (* 1 = 1.34694 loss)
I0522 21:57:15.301221  1275 sgd_solver.cpp:106] Iteration 6375, lr = 0.0035
I0522 21:57:25.210423  1275 solver.cpp:237] Iteration 6750, loss = 1.36107
I0522 21:57:25.210583  1275 solver.cpp:253]     Train net output #0: loss = 1.36107 (* 1 = 1.36107 loss)
I0522 21:57:25.210597  1275 sgd_solver.cpp:106] Iteration 6750, lr = 0.0035
I0522 21:57:35.126497  1275 solver.cpp:237] Iteration 7125, loss = 1.39955
I0522 21:57:35.126533  1275 solver.cpp:253]     Train net output #0: loss = 1.39955 (* 1 = 1.39955 loss)
I0522 21:57:35.126549  1275 sgd_solver.cpp:106] Iteration 7125, lr = 0.0035
I0522 21:57:45.011282  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_7500.caffemodel
I0522 21:57:45.067898  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_7500.solverstate
I0522 21:57:45.093930  1275 solver.cpp:341] Iteration 7500, Testing net (#0)
I0522 21:58:33.671352  1275 solver.cpp:409]     Test net output #0: accuracy = 0.829306
I0522 21:58:33.671517  1275 solver.cpp:409]     Test net output #1: loss = 0.558331 (* 1 = 0.558331 loss)
I0522 21:58:55.939954  1275 solver.cpp:237] Iteration 7500, loss = 1.32644
I0522 21:58:55.940011  1275 solver.cpp:253]     Train net output #0: loss = 1.32644 (* 1 = 1.32644 loss)
I0522 21:58:55.940026  1275 sgd_solver.cpp:106] Iteration 7500, lr = 0.0035
I0522 21:59:05.846863  1275 solver.cpp:237] Iteration 7875, loss = 1.15765
I0522 21:59:05.847023  1275 solver.cpp:253]     Train net output #0: loss = 1.15765 (* 1 = 1.15765 loss)
I0522 21:59:05.847036  1275 sgd_solver.cpp:106] Iteration 7875, lr = 0.0035
I0522 21:59:15.751487  1275 solver.cpp:237] Iteration 8250, loss = 1.64385
I0522 21:59:15.751521  1275 solver.cpp:253]     Train net output #0: loss = 1.64385 (* 1 = 1.64385 loss)
I0522 21:59:15.751540  1275 sgd_solver.cpp:106] Iteration 8250, lr = 0.0035
I0522 21:59:25.665905  1275 solver.cpp:237] Iteration 8625, loss = 1.34332
I0522 21:59:25.665940  1275 solver.cpp:253]     Train net output #0: loss = 1.34332 (* 1 = 1.34332 loss)
I0522 21:59:25.665957  1275 sgd_solver.cpp:106] Iteration 8625, lr = 0.0035
I0522 21:59:35.572835  1275 solver.cpp:237] Iteration 9000, loss = 1.49784
I0522 21:59:35.572883  1275 solver.cpp:253]     Train net output #0: loss = 1.49784 (* 1 = 1.49784 loss)
I0522 21:59:35.572901  1275 sgd_solver.cpp:106] Iteration 9000, lr = 0.0035
I0522 21:59:45.480139  1275 solver.cpp:237] Iteration 9375, loss = 1.53825
I0522 21:59:45.480290  1275 solver.cpp:253]     Train net output #0: loss = 1.53825 (* 1 = 1.53825 loss)
I0522 21:59:45.480304  1275 sgd_solver.cpp:106] Iteration 9375, lr = 0.0035
I0522 21:59:55.380673  1275 solver.cpp:237] Iteration 9750, loss = 1.39426
I0522 21:59:55.380718  1275 solver.cpp:253]     Train net output #0: loss = 1.39426 (* 1 = 1.39426 loss)
I0522 21:59:55.380735  1275 sgd_solver.cpp:106] Iteration 9750, lr = 0.0035
I0522 22:00:27.494608  1275 solver.cpp:237] Iteration 10125, loss = 1.40602
I0522 22:00:27.494772  1275 solver.cpp:253]     Train net output #0: loss = 1.40602 (* 1 = 1.40602 loss)
I0522 22:00:27.494788  1275 sgd_solver.cpp:106] Iteration 10125, lr = 0.0035
I0522 22:00:37.405661  1275 solver.cpp:237] Iteration 10500, loss = 1.36608
I0522 22:00:37.405696  1275 solver.cpp:253]     Train net output #0: loss = 1.36608 (* 1 = 1.36608 loss)
I0522 22:00:37.405714  1275 sgd_solver.cpp:106] Iteration 10500, lr = 0.0035
I0522 22:00:47.312971  1275 solver.cpp:237] Iteration 10875, loss = 1.58509
I0522 22:00:47.313025  1275 solver.cpp:253]     Train net output #0: loss = 1.58509 (* 1 = 1.58509 loss)
I0522 22:00:47.313040  1275 sgd_solver.cpp:106] Iteration 10875, lr = 0.0035
I0522 22:00:57.185845  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_11250.caffemodel
I0522 22:00:57.244338  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_11250.solverstate
I0522 22:00:57.279942  1275 solver.cpp:237] Iteration 11250, loss = 1.35435
I0522 22:00:57.279997  1275 solver.cpp:253]     Train net output #0: loss = 1.35435 (* 1 = 1.35435 loss)
I0522 22:00:57.280011  1275 sgd_solver.cpp:106] Iteration 11250, lr = 0.0035
I0522 22:01:07.185950  1275 solver.cpp:237] Iteration 11625, loss = 1.26226
I0522 22:01:07.186106  1275 solver.cpp:253]     Train net output #0: loss = 1.26226 (* 1 = 1.26226 loss)
I0522 22:01:07.186120  1275 sgd_solver.cpp:106] Iteration 11625, lr = 0.0035
I0522 22:01:17.089207  1275 solver.cpp:237] Iteration 12000, loss = 1.32005
I0522 22:01:17.089251  1275 solver.cpp:253]     Train net output #0: loss = 1.32005 (* 1 = 1.32005 loss)
I0522 22:01:17.089265  1275 sgd_solver.cpp:106] Iteration 12000, lr = 0.0035
I0522 22:01:26.993962  1275 solver.cpp:237] Iteration 12375, loss = 1.24996
I0522 22:01:26.993998  1275 solver.cpp:253]     Train net output #0: loss = 1.24996 (* 1 = 1.24996 loss)
I0522 22:01:26.994010  1275 sgd_solver.cpp:106] Iteration 12375, lr = 0.0035
I0522 22:01:59.125255  1275 solver.cpp:237] Iteration 12750, loss = 1.22205
I0522 22:01:59.125423  1275 solver.cpp:253]     Train net output #0: loss = 1.22205 (* 1 = 1.22205 loss)
I0522 22:01:59.125438  1275 sgd_solver.cpp:106] Iteration 12750, lr = 0.0035
I0522 22:02:09.033242  1275 solver.cpp:237] Iteration 13125, loss = 1.54567
I0522 22:02:09.033277  1275 solver.cpp:253]     Train net output #0: loss = 1.54567 (* 1 = 1.54567 loss)
I0522 22:02:09.033291  1275 sgd_solver.cpp:106] Iteration 13125, lr = 0.0035
I0522 22:02:18.941884  1275 solver.cpp:237] Iteration 13500, loss = 1.51793
I0522 22:02:18.941925  1275 solver.cpp:253]     Train net output #0: loss = 1.51793 (* 1 = 1.51793 loss)
I0522 22:02:18.941941  1275 sgd_solver.cpp:106] Iteration 13500, lr = 0.0035
I0522 22:02:28.850498  1275 solver.cpp:237] Iteration 13875, loss = 0.924511
I0522 22:02:28.850544  1275 solver.cpp:253]     Train net output #0: loss = 0.924511 (* 1 = 0.924511 loss)
I0522 22:02:28.850559  1275 sgd_solver.cpp:106] Iteration 13875, lr = 0.0035
I0522 22:02:38.758635  1275 solver.cpp:237] Iteration 14250, loss = 1.40824
I0522 22:02:38.758767  1275 solver.cpp:253]     Train net output #0: loss = 1.40824 (* 1 = 1.40824 loss)
I0522 22:02:38.758780  1275 sgd_solver.cpp:106] Iteration 14250, lr = 0.0035
I0522 22:02:48.662336  1275 solver.cpp:237] Iteration 14625, loss = 1.23824
I0522 22:02:48.662381  1275 solver.cpp:253]     Train net output #0: loss = 1.23824 (* 1 = 1.23824 loss)
I0522 22:02:48.662403  1275 sgd_solver.cpp:106] Iteration 14625, lr = 0.0035
I0522 22:02:58.549446  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_15000.caffemodel
I0522 22:02:58.607669  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_15000.solverstate
I0522 22:02:58.635426  1275 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 22:04:08.123546  1275 solver.cpp:409]     Test net output #0: accuracy = 0.857278
I0522 22:04:08.123723  1275 solver.cpp:409]     Test net output #1: loss = 0.485458 (* 1 = 0.485458 loss)
I0522 22:04:30.427492  1275 solver.cpp:237] Iteration 15000, loss = 1.09141
I0522 22:04:30.427547  1275 solver.cpp:253]     Train net output #0: loss = 1.09141 (* 1 = 1.09141 loss)
I0522 22:04:30.427563  1275 sgd_solver.cpp:106] Iteration 15000, lr = 0.0035
I0522 22:04:40.169157  1275 solver.cpp:237] Iteration 15375, loss = 1.02689
I0522 22:04:40.169311  1275 solver.cpp:253]     Train net output #0: loss = 1.02689 (* 1 = 1.02689 loss)
I0522 22:04:40.169324  1275 sgd_solver.cpp:106] Iteration 15375, lr = 0.0035
I0522 22:04:49.916133  1275 solver.cpp:237] Iteration 15750, loss = 1.45996
I0522 22:04:49.916167  1275 solver.cpp:253]     Train net output #0: loss = 1.45996 (* 1 = 1.45996 loss)
I0522 22:04:49.916185  1275 sgd_solver.cpp:106] Iteration 15750, lr = 0.0035
I0522 22:04:59.666540  1275 solver.cpp:237] Iteration 16125, loss = 1.23979
I0522 22:04:59.666587  1275 solver.cpp:253]     Train net output #0: loss = 1.23979 (* 1 = 1.23979 loss)
I0522 22:04:59.666607  1275 sgd_solver.cpp:106] Iteration 16125, lr = 0.0035
I0522 22:05:09.411314  1275 solver.cpp:237] Iteration 16500, loss = 1.31725
I0522 22:05:09.411350  1275 solver.cpp:253]     Train net output #0: loss = 1.31725 (* 1 = 1.31725 loss)
I0522 22:05:09.411367  1275 sgd_solver.cpp:106] Iteration 16500, lr = 0.0035
I0522 22:05:19.154175  1275 solver.cpp:237] Iteration 16875, loss = 1.31993
I0522 22:05:19.154333  1275 solver.cpp:253]     Train net output #0: loss = 1.31993 (* 1 = 1.31993 loss)
I0522 22:05:19.154347  1275 sgd_solver.cpp:106] Iteration 16875, lr = 0.0035
I0522 22:05:28.922920  1275 solver.cpp:237] Iteration 17250, loss = 1.38133
I0522 22:05:28.922955  1275 solver.cpp:253]     Train net output #0: loss = 1.38133 (* 1 = 1.38133 loss)
I0522 22:05:28.922972  1275 sgd_solver.cpp:106] Iteration 17250, lr = 0.0035
I0522 22:06:00.906365  1275 solver.cpp:237] Iteration 17625, loss = 1.1081
I0522 22:06:00.906535  1275 solver.cpp:253]     Train net output #0: loss = 1.1081 (* 1 = 1.1081 loss)
I0522 22:06:00.906550  1275 sgd_solver.cpp:106] Iteration 17625, lr = 0.0035
I0522 22:06:10.667493  1275 solver.cpp:237] Iteration 18000, loss = 1.24629
I0522 22:06:10.667538  1275 solver.cpp:253]     Train net output #0: loss = 1.24629 (* 1 = 1.24629 loss)
I0522 22:06:10.667557  1275 sgd_solver.cpp:106] Iteration 18000, lr = 0.0035
I0522 22:06:20.431123  1275 solver.cpp:237] Iteration 18375, loss = 1.4397
I0522 22:06:20.431159  1275 solver.cpp:253]     Train net output #0: loss = 1.4397 (* 1 = 1.4397 loss)
I0522 22:06:20.431177  1275 sgd_solver.cpp:106] Iteration 18375, lr = 0.0035
I0522 22:06:30.163636  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_18750.caffemodel
I0522 22:06:30.221772  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_18750.solverstate
I0522 22:06:30.259023  1275 solver.cpp:237] Iteration 18750, loss = 1.02352
I0522 22:06:30.259073  1275 solver.cpp:253]     Train net output #0: loss = 1.02352 (* 1 = 1.02352 loss)
I0522 22:06:30.259091  1275 sgd_solver.cpp:106] Iteration 18750, lr = 0.0035
I0522 22:06:40.022284  1275 solver.cpp:237] Iteration 19125, loss = 1.07864
I0522 22:06:40.022444  1275 solver.cpp:253]     Train net output #0: loss = 1.07864 (* 1 = 1.07864 loss)
I0522 22:06:40.022459  1275 sgd_solver.cpp:106] Iteration 19125, lr = 0.0035
I0522 22:06:49.784296  1275 solver.cpp:237] Iteration 19500, loss = 1.55547
I0522 22:06:49.784330  1275 solver.cpp:253]     Train net output #0: loss = 1.55547 (* 1 = 1.55547 loss)
I0522 22:06:49.784348  1275 sgd_solver.cpp:106] Iteration 19500, lr = 0.0035
I0522 22:06:59.552137  1275 solver.cpp:237] Iteration 19875, loss = 1.32701
I0522 22:06:59.552189  1275 solver.cpp:253]     Train net output #0: loss = 1.32701 (* 1 = 1.32701 loss)
I0522 22:06:59.552203  1275 sgd_solver.cpp:106] Iteration 19875, lr = 0.0035
I0522 22:07:31.586782  1275 solver.cpp:237] Iteration 20250, loss = 1.46634
I0522 22:07:31.586957  1275 solver.cpp:253]     Train net output #0: loss = 1.46634 (* 1 = 1.46634 loss)
I0522 22:07:31.586973  1275 sgd_solver.cpp:106] Iteration 20250, lr = 0.0035
I0522 22:07:41.345067  1275 solver.cpp:237] Iteration 20625, loss = 1.16382
I0522 22:07:41.345101  1275 solver.cpp:253]     Train net output #0: loss = 1.16382 (* 1 = 1.16382 loss)
I0522 22:07:41.345119  1275 sgd_solver.cpp:106] Iteration 20625, lr = 0.0035
I0522 22:07:51.104296  1275 solver.cpp:237] Iteration 21000, loss = 1.37709
I0522 22:07:51.104342  1275 solver.cpp:253]     Train net output #0: loss = 1.37709 (* 1 = 1.37709 loss)
I0522 22:07:51.104357  1275 sgd_solver.cpp:106] Iteration 21000, lr = 0.0035
I0522 22:08:00.866955  1275 solver.cpp:237] Iteration 21375, loss = 1.16068
I0522 22:08:00.866992  1275 solver.cpp:253]     Train net output #0: loss = 1.16068 (* 1 = 1.16068 loss)
I0522 22:08:00.867007  1275 sgd_solver.cpp:106] Iteration 21375, lr = 0.0035
I0522 22:08:10.622323  1275 solver.cpp:237] Iteration 21750, loss = 1.26009
I0522 22:08:10.622467  1275 solver.cpp:253]     Train net output #0: loss = 1.26009 (* 1 = 1.26009 loss)
I0522 22:08:10.622480  1275 sgd_solver.cpp:106] Iteration 21750, lr = 0.0035
I0522 22:08:20.388453  1275 solver.cpp:237] Iteration 22125, loss = 0.998627
I0522 22:08:20.388506  1275 solver.cpp:253]     Train net output #0: loss = 0.998627 (* 1 = 0.998627 loss)
I0522 22:08:20.388525  1275 sgd_solver.cpp:106] Iteration 22125, lr = 0.0035
I0522 22:08:30.121855  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_22500.caffemodel
I0522 22:08:30.178460  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_22500.solverstate
I0522 22:08:30.204990  1275 solver.cpp:341] Iteration 22500, Testing net (#0)
I0522 22:09:18.435417  1275 solver.cpp:409]     Test net output #0: accuracy = 0.869587
I0522 22:09:18.435592  1275 solver.cpp:409]     Test net output #1: loss = 0.421816 (* 1 = 0.421816 loss)
I0522 22:09:40.632676  1275 solver.cpp:237] Iteration 22500, loss = 1.36039
I0522 22:09:40.632733  1275 solver.cpp:253]     Train net output #0: loss = 1.36039 (* 1 = 1.36039 loss)
I0522 22:09:40.632747  1275 sgd_solver.cpp:106] Iteration 22500, lr = 0.0035
I0522 22:09:50.532203  1275 solver.cpp:237] Iteration 22875, loss = 1.01139
I0522 22:09:50.532367  1275 solver.cpp:253]     Train net output #0: loss = 1.01139 (* 1 = 1.01139 loss)
I0522 22:09:50.532382  1275 sgd_solver.cpp:106] Iteration 22875, lr = 0.0035
I0522 22:10:00.432993  1275 solver.cpp:237] Iteration 23250, loss = 1.09546
I0522 22:10:00.433043  1275 solver.cpp:253]     Train net output #0: loss = 1.09546 (* 1 = 1.09546 loss)
I0522 22:10:00.433059  1275 sgd_solver.cpp:106] Iteration 23250, lr = 0.0035
I0522 22:10:10.345322  1275 solver.cpp:237] Iteration 23625, loss = 1.61266
I0522 22:10:10.345358  1275 solver.cpp:253]     Train net output #0: loss = 1.61266 (* 1 = 1.61266 loss)
I0522 22:10:10.345371  1275 sgd_solver.cpp:106] Iteration 23625, lr = 0.0035
I0522 22:10:20.245028  1275 solver.cpp:237] Iteration 24000, loss = 1.3701
I0522 22:10:20.245081  1275 solver.cpp:253]     Train net output #0: loss = 1.3701 (* 1 = 1.3701 loss)
I0522 22:10:20.245095  1275 sgd_solver.cpp:106] Iteration 24000, lr = 0.0035
I0522 22:10:30.152770  1275 solver.cpp:237] Iteration 24375, loss = 1.23386
I0522 22:10:30.152914  1275 solver.cpp:253]     Train net output #0: loss = 1.23386 (* 1 = 1.23386 loss)
I0522 22:10:30.152926  1275 sgd_solver.cpp:106] Iteration 24375, lr = 0.0035
I0522 22:10:40.054812  1275 solver.cpp:237] Iteration 24750, loss = 1.10032
I0522 22:10:40.054847  1275 solver.cpp:253]     Train net output #0: loss = 1.10032 (* 1 = 1.10032 loss)
I0522 22:10:40.054865  1275 sgd_solver.cpp:106] Iteration 24750, lr = 0.0035
I0522 22:11:12.132150  1275 solver.cpp:237] Iteration 25125, loss = 1.22415
I0522 22:11:12.132334  1275 solver.cpp:253]     Train net output #0: loss = 1.22415 (* 1 = 1.22415 loss)
I0522 22:11:12.132349  1275 sgd_solver.cpp:106] Iteration 25125, lr = 0.0035
I0522 22:11:22.036486  1275 solver.cpp:237] Iteration 25500, loss = 0.96569
I0522 22:11:22.036521  1275 solver.cpp:253]     Train net output #0: loss = 0.96569 (* 1 = 0.96569 loss)
I0522 22:11:22.036538  1275 sgd_solver.cpp:106] Iteration 25500, lr = 0.0035
I0522 22:11:31.935971  1275 solver.cpp:237] Iteration 25875, loss = 0.947738
I0522 22:11:31.936007  1275 solver.cpp:253]     Train net output #0: loss = 0.947738 (* 1 = 0.947738 loss)
I0522 22:11:31.936023  1275 sgd_solver.cpp:106] Iteration 25875, lr = 0.0035
I0522 22:11:41.817145  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_26250.caffemodel
I0522 22:11:41.877997  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_26250.solverstate
I0522 22:11:41.912266  1275 solver.cpp:237] Iteration 26250, loss = 0.927786
I0522 22:11:41.912317  1275 solver.cpp:253]     Train net output #0: loss = 0.927786 (* 1 = 0.927786 loss)
I0522 22:11:41.912330  1275 sgd_solver.cpp:106] Iteration 26250, lr = 0.0035
I0522 22:11:51.819478  1275 solver.cpp:237] Iteration 26625, loss = 1.14182
I0522 22:11:51.819628  1275 solver.cpp:253]     Train net output #0: loss = 1.14182 (* 1 = 1.14182 loss)
I0522 22:11:51.819641  1275 sgd_solver.cpp:106] Iteration 26625, lr = 0.0035
I0522 22:12:01.724453  1275 solver.cpp:237] Iteration 27000, loss = 1.24921
I0522 22:12:01.724503  1275 solver.cpp:253]     Train net output #0: loss = 1.24921 (* 1 = 1.24921 loss)
I0522 22:12:01.724519  1275 sgd_solver.cpp:106] Iteration 27000, lr = 0.0035
I0522 22:12:11.628202  1275 solver.cpp:237] Iteration 27375, loss = 1.17911
I0522 22:12:11.628237  1275 solver.cpp:253]     Train net output #0: loss = 1.17911 (* 1 = 1.17911 loss)
I0522 22:12:11.628253  1275 sgd_solver.cpp:106] Iteration 27375, lr = 0.0035
I0522 22:12:43.698642  1275 solver.cpp:237] Iteration 27750, loss = 1.32414
I0522 22:12:43.698815  1275 solver.cpp:253]     Train net output #0: loss = 1.32414 (* 1 = 1.32414 loss)
I0522 22:12:43.698832  1275 sgd_solver.cpp:106] Iteration 27750, lr = 0.0035
I0522 22:12:53.602546  1275 solver.cpp:237] Iteration 28125, loss = 1.62659
I0522 22:12:53.602598  1275 solver.cpp:253]     Train net output #0: loss = 1.62659 (* 1 = 1.62659 loss)
I0522 22:12:53.602614  1275 sgd_solver.cpp:106] Iteration 28125, lr = 0.0035
I0522 22:13:03.501286  1275 solver.cpp:237] Iteration 28500, loss = 1.0975
I0522 22:13:03.501322  1275 solver.cpp:253]     Train net output #0: loss = 1.0975 (* 1 = 1.0975 loss)
I0522 22:13:03.501338  1275 sgd_solver.cpp:106] Iteration 28500, lr = 0.0035
I0522 22:13:13.414633  1275 solver.cpp:237] Iteration 28875, loss = 1.3622
I0522 22:13:13.414683  1275 solver.cpp:253]     Train net output #0: loss = 1.3622 (* 1 = 1.3622 loss)
I0522 22:13:13.414705  1275 sgd_solver.cpp:106] Iteration 28875, lr = 0.0035
I0522 22:13:23.321036  1275 solver.cpp:237] Iteration 29250, loss = 1.19527
I0522 22:13:23.321182  1275 solver.cpp:253]     Train net output #0: loss = 1.19527 (* 1 = 1.19527 loss)
I0522 22:13:23.321195  1275 sgd_solver.cpp:106] Iteration 29250, lr = 0.0035
I0522 22:13:33.227085  1275 solver.cpp:237] Iteration 29625, loss = 1.33162
I0522 22:13:33.227119  1275 solver.cpp:253]     Train net output #0: loss = 1.33162 (* 1 = 1.33162 loss)
I0522 22:13:33.227136  1275 sgd_solver.cpp:106] Iteration 29625, lr = 0.0035
I0522 22:13:43.083575  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_30000.caffemodel
I0522 22:13:43.140280  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_30000.solverstate
I0522 22:13:43.166443  1275 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 22:14:52.636972  1275 solver.cpp:409]     Test net output #0: accuracy = 0.871327
I0522 22:14:52.637158  1275 solver.cpp:409]     Test net output #1: loss = 0.404034 (* 1 = 0.404034 loss)
I0522 22:15:14.907948  1275 solver.cpp:237] Iteration 30000, loss = 1.43149
I0522 22:15:14.908004  1275 solver.cpp:253]     Train net output #0: loss = 1.43149 (* 1 = 1.43149 loss)
I0522 22:15:14.908018  1275 sgd_solver.cpp:106] Iteration 30000, lr = 0.0035
I0522 22:15:24.776823  1275 solver.cpp:237] Iteration 30375, loss = 1.38503
I0522 22:15:24.776981  1275 solver.cpp:253]     Train net output #0: loss = 1.38503 (* 1 = 1.38503 loss)
I0522 22:15:24.776995  1275 sgd_solver.cpp:106] Iteration 30375, lr = 0.0035
I0522 22:15:34.645730  1275 solver.cpp:237] Iteration 30750, loss = 0.94464
I0522 22:15:34.645766  1275 solver.cpp:253]     Train net output #0: loss = 0.94464 (* 1 = 0.94464 loss)
I0522 22:15:34.645782  1275 sgd_solver.cpp:106] Iteration 30750, lr = 0.0035
I0522 22:15:44.513222  1275 solver.cpp:237] Iteration 31125, loss = 1.43001
I0522 22:15:44.513275  1275 solver.cpp:253]     Train net output #0: loss = 1.43001 (* 1 = 1.43001 loss)
I0522 22:15:44.513291  1275 sgd_solver.cpp:106] Iteration 31125, lr = 0.0035
I0522 22:15:54.384094  1275 solver.cpp:237] Iteration 31500, loss = 1.15828
I0522 22:15:54.384130  1275 solver.cpp:253]     Train net output #0: loss = 1.15828 (* 1 = 1.15828 loss)
I0522 22:15:54.384145  1275 sgd_solver.cpp:106] Iteration 31500, lr = 0.0035
I0522 22:16:04.250728  1275 solver.cpp:237] Iteration 31875, loss = 1.02423
I0522 22:16:04.250874  1275 solver.cpp:253]     Train net output #0: loss = 1.02423 (* 1 = 1.02423 loss)
I0522 22:16:04.250887  1275 sgd_solver.cpp:106] Iteration 31875, lr = 0.0035
I0522 22:16:14.121459  1275 solver.cpp:237] Iteration 32250, loss = 1.16094
I0522 22:16:14.121497  1275 solver.cpp:253]     Train net output #0: loss = 1.16094 (* 1 = 1.16094 loss)
I0522 22:16:14.121518  1275 sgd_solver.cpp:106] Iteration 32250, lr = 0.0035
I0522 22:16:46.210767  1275 solver.cpp:237] Iteration 32625, loss = 1.1558
I0522 22:16:46.210943  1275 solver.cpp:253]     Train net output #0: loss = 1.1558 (* 1 = 1.1558 loss)
I0522 22:16:46.210959  1275 sgd_solver.cpp:106] Iteration 32625, lr = 0.0035
I0522 22:16:56.076704  1275 solver.cpp:237] Iteration 33000, loss = 1.28311
I0522 22:16:56.076740  1275 solver.cpp:253]     Train net output #0: loss = 1.28311 (* 1 = 1.28311 loss)
I0522 22:16:56.076756  1275 sgd_solver.cpp:106] Iteration 33000, lr = 0.0035
I0522 22:17:05.941862  1275 solver.cpp:237] Iteration 33375, loss = 1.20337
I0522 22:17:05.941915  1275 solver.cpp:253]     Train net output #0: loss = 1.20337 (* 1 = 1.20337 loss)
I0522 22:17:05.941929  1275 sgd_solver.cpp:106] Iteration 33375, lr = 0.0035
I0522 22:17:15.782064  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_33750.caffemodel
I0522 22:17:15.839872  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_33750.solverstate
I0522 22:17:15.876723  1275 solver.cpp:237] Iteration 33750, loss = 1.23266
I0522 22:17:15.876775  1275 solver.cpp:253]     Train net output #0: loss = 1.23266 (* 1 = 1.23266 loss)
I0522 22:17:15.876791  1275 sgd_solver.cpp:106] Iteration 33750, lr = 0.0035
I0522 22:17:25.750265  1275 solver.cpp:237] Iteration 34125, loss = 1.0969
I0522 22:17:25.750427  1275 solver.cpp:253]     Train net output #0: loss = 1.0969 (* 1 = 1.0969 loss)
I0522 22:17:25.750440  1275 sgd_solver.cpp:106] Iteration 34125, lr = 0.0035
I0522 22:17:35.617996  1275 solver.cpp:237] Iteration 34500, loss = 1.59968
I0522 22:17:35.618031  1275 solver.cpp:253]     Train net output #0: loss = 1.59968 (* 1 = 1.59968 loss)
I0522 22:17:35.618046  1275 sgd_solver.cpp:106] Iteration 34500, lr = 0.0035
I0522 22:17:45.488268  1275 solver.cpp:237] Iteration 34875, loss = 0.882579
I0522 22:17:45.488303  1275 solver.cpp:253]     Train net output #0: loss = 0.882579 (* 1 = 0.882579 loss)
I0522 22:17:45.488317  1275 sgd_solver.cpp:106] Iteration 34875, lr = 0.0035
I0522 22:18:17.672389  1275 solver.cpp:237] Iteration 35250, loss = 1.01421
I0522 22:18:17.672574  1275 solver.cpp:253]     Train net output #0: loss = 1.01421 (* 1 = 1.01421 loss)
I0522 22:18:17.672590  1275 sgd_solver.cpp:106] Iteration 35250, lr = 0.0035
I0522 22:18:27.551775  1275 solver.cpp:237] Iteration 35625, loss = 1.2987
I0522 22:18:27.551810  1275 solver.cpp:253]     Train net output #0: loss = 1.2987 (* 1 = 1.2987 loss)
I0522 22:18:27.551827  1275 sgd_solver.cpp:106] Iteration 35625, lr = 0.0035
I0522 22:18:37.416551  1275 solver.cpp:237] Iteration 36000, loss = 1.16722
I0522 22:18:37.416587  1275 solver.cpp:253]     Train net output #0: loss = 1.16722 (* 1 = 1.16722 loss)
I0522 22:18:37.416604  1275 sgd_solver.cpp:106] Iteration 36000, lr = 0.0035
I0522 22:18:47.289356  1275 solver.cpp:237] Iteration 36375, loss = 1.33857
I0522 22:18:47.289399  1275 solver.cpp:253]     Train net output #0: loss = 1.33857 (* 1 = 1.33857 loss)
I0522 22:18:47.289417  1275 sgd_solver.cpp:106] Iteration 36375, lr = 0.0035
I0522 22:18:57.161186  1275 solver.cpp:237] Iteration 36750, loss = 1.23259
I0522 22:18:57.161334  1275 solver.cpp:253]     Train net output #0: loss = 1.23259 (* 1 = 1.23259 loss)
I0522 22:18:57.161346  1275 sgd_solver.cpp:106] Iteration 36750, lr = 0.0035
I0522 22:19:07.029521  1275 solver.cpp:237] Iteration 37125, loss = 1.45398
I0522 22:19:07.029572  1275 solver.cpp:253]     Train net output #0: loss = 1.45398 (* 1 = 1.45398 loss)
I0522 22:19:07.029587  1275 sgd_solver.cpp:106] Iteration 37125, lr = 0.0035
I0522 22:19:16.876480  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_37500.caffemodel
I0522 22:19:16.933781  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_37500.solverstate
I0522 22:19:16.962154  1275 solver.cpp:341] Iteration 37500, Testing net (#0)
I0522 22:20:05.555325  1275 solver.cpp:409]     Test net output #0: accuracy = 0.883067
I0522 22:20:05.555495  1275 solver.cpp:409]     Test net output #1: loss = 0.375799 (* 1 = 0.375799 loss)
I0522 22:20:26.442216  1275 solver.cpp:237] Iteration 37500, loss = 1.21724
I0522 22:20:26.442272  1275 solver.cpp:253]     Train net output #0: loss = 1.21724 (* 1 = 1.21724 loss)
I0522 22:20:26.442287  1275 sgd_solver.cpp:106] Iteration 37500, lr = 0.0035
I0522 22:20:36.304314  1275 solver.cpp:237] Iteration 37875, loss = 1.16513
I0522 22:20:36.304468  1275 solver.cpp:253]     Train net output #0: loss = 1.16513 (* 1 = 1.16513 loss)
I0522 22:20:36.304482  1275 sgd_solver.cpp:106] Iteration 37875, lr = 0.0035
I0522 22:20:46.172812  1275 solver.cpp:237] Iteration 38250, loss = 1.30916
I0522 22:20:46.172864  1275 solver.cpp:253]     Train net output #0: loss = 1.30916 (* 1 = 1.30916 loss)
I0522 22:20:46.172880  1275 sgd_solver.cpp:106] Iteration 38250, lr = 0.0035
I0522 22:20:56.034634  1275 solver.cpp:237] Iteration 38625, loss = 0.939301
I0522 22:20:56.034669  1275 solver.cpp:253]     Train net output #0: loss = 0.939301 (* 1 = 0.939301 loss)
I0522 22:20:56.034687  1275 sgd_solver.cpp:106] Iteration 38625, lr = 0.0035
I0522 22:21:05.894896  1275 solver.cpp:237] Iteration 39000, loss = 1.33366
I0522 22:21:05.894930  1275 solver.cpp:253]     Train net output #0: loss = 1.33366 (* 1 = 1.33366 loss)
I0522 22:21:05.894943  1275 sgd_solver.cpp:106] Iteration 39000, lr = 0.0035
I0522 22:21:15.764058  1275 solver.cpp:237] Iteration 39375, loss = 1.15249
I0522 22:21:15.764235  1275 solver.cpp:253]     Train net output #0: loss = 1.15249 (* 1 = 1.15249 loss)
I0522 22:21:15.764250  1275 sgd_solver.cpp:106] Iteration 39375, lr = 0.0035
I0522 22:21:25.617117  1275 solver.cpp:237] Iteration 39750, loss = 1.47083
I0522 22:21:25.617151  1275 solver.cpp:253]     Train net output #0: loss = 1.47083 (* 1 = 1.47083 loss)
I0522 22:21:25.617167  1275 sgd_solver.cpp:106] Iteration 39750, lr = 0.0035
I0522 22:21:56.424131  1275 solver.cpp:237] Iteration 40125, loss = 1.43994
I0522 22:21:56.424305  1275 solver.cpp:253]     Train net output #0: loss = 1.43994 (* 1 = 1.43994 loss)
I0522 22:21:56.424320  1275 sgd_solver.cpp:106] Iteration 40125, lr = 0.0035
I0522 22:22:06.292726  1275 solver.cpp:237] Iteration 40500, loss = 1.14565
I0522 22:22:06.292770  1275 solver.cpp:253]     Train net output #0: loss = 1.14565 (* 1 = 1.14565 loss)
I0522 22:22:06.292788  1275 sgd_solver.cpp:106] Iteration 40500, lr = 0.0035
I0522 22:22:16.153147  1275 solver.cpp:237] Iteration 40875, loss = 1.83385
I0522 22:22:16.153182  1275 solver.cpp:253]     Train net output #0: loss = 1.83385 (* 1 = 1.83385 loss)
I0522 22:22:16.153199  1275 sgd_solver.cpp:106] Iteration 40875, lr = 0.0035
I0522 22:22:25.998349  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_41250.caffemodel
I0522 22:22:26.054394  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_41250.solverstate
I0522 22:22:26.088759  1275 solver.cpp:237] Iteration 41250, loss = 1.36238
I0522 22:22:26.088807  1275 solver.cpp:253]     Train net output #0: loss = 1.36238 (* 1 = 1.36238 loss)
I0522 22:22:26.088824  1275 sgd_solver.cpp:106] Iteration 41250, lr = 0.0035
I0522 22:22:35.961282  1275 solver.cpp:237] Iteration 41625, loss = 1.12801
I0522 22:22:35.961434  1275 solver.cpp:253]     Train net output #0: loss = 1.12801 (* 1 = 1.12801 loss)
I0522 22:22:35.961447  1275 sgd_solver.cpp:106] Iteration 41625, lr = 0.0035
I0522 22:22:45.832067  1275 solver.cpp:237] Iteration 42000, loss = 1.14933
I0522 22:22:45.832103  1275 solver.cpp:253]     Train net output #0: loss = 1.14933 (* 1 = 1.14933 loss)
I0522 22:22:45.832119  1275 sgd_solver.cpp:106] Iteration 42000, lr = 0.0035
I0522 22:22:55.692844  1275 solver.cpp:237] Iteration 42375, loss = 1.1367
I0522 22:22:55.692890  1275 solver.cpp:253]     Train net output #0: loss = 1.1367 (* 1 = 1.1367 loss)
I0522 22:22:55.692908  1275 sgd_solver.cpp:106] Iteration 42375, lr = 0.0035
I0522 22:23:26.448431  1275 solver.cpp:237] Iteration 42750, loss = 1.13656
I0522 22:23:26.448604  1275 solver.cpp:253]     Train net output #0: loss = 1.13656 (* 1 = 1.13656 loss)
I0522 22:23:26.448619  1275 sgd_solver.cpp:106] Iteration 42750, lr = 0.0035
I0522 22:23:36.308641  1275 solver.cpp:237] Iteration 43125, loss = 1.05904
I0522 22:23:36.308676  1275 solver.cpp:253]     Train net output #0: loss = 1.05904 (* 1 = 1.05904 loss)
I0522 22:23:36.308694  1275 sgd_solver.cpp:106] Iteration 43125, lr = 0.0035
I0522 22:23:46.184136  1275 solver.cpp:237] Iteration 43500, loss = 1.26881
I0522 22:23:46.184188  1275 solver.cpp:253]     Train net output #0: loss = 1.26881 (* 1 = 1.26881 loss)
I0522 22:23:46.184206  1275 sgd_solver.cpp:106] Iteration 43500, lr = 0.0035
I0522 22:23:56.059509  1275 solver.cpp:237] Iteration 43875, loss = 1.47629
I0522 22:23:56.059546  1275 solver.cpp:253]     Train net output #0: loss = 1.47629 (* 1 = 1.47629 loss)
I0522 22:23:56.059562  1275 sgd_solver.cpp:106] Iteration 43875, lr = 0.0035
I0522 22:24:05.941689  1275 solver.cpp:237] Iteration 44250, loss = 1.53898
I0522 22:24:05.941849  1275 solver.cpp:253]     Train net output #0: loss = 1.53898 (* 1 = 1.53898 loss)
I0522 22:24:05.941864  1275 sgd_solver.cpp:106] Iteration 44250, lr = 0.0035
I0522 22:24:15.818584  1275 solver.cpp:237] Iteration 44625, loss = 1.0897
I0522 22:24:15.818619  1275 solver.cpp:253]     Train net output #0: loss = 1.0897 (* 1 = 1.0897 loss)
I0522 22:24:15.818636  1275 sgd_solver.cpp:106] Iteration 44625, lr = 0.0035
I0522 22:24:25.671424  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_45000.caffemodel
I0522 22:24:25.727602  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_45000.solverstate
I0522 22:24:25.753936  1275 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 22:25:35.251330  1275 solver.cpp:409]     Test net output #0: accuracy = 0.886319
I0522 22:25:35.251514  1275 solver.cpp:409]     Test net output #1: loss = 0.356245 (* 1 = 0.356245 loss)
I0522 22:25:56.200541  1275 solver.cpp:237] Iteration 45000, loss = 1.17969
I0522 22:25:56.200598  1275 solver.cpp:253]     Train net output #0: loss = 1.17969 (* 1 = 1.17969 loss)
I0522 22:25:56.200613  1275 sgd_solver.cpp:106] Iteration 45000, lr = 0.0035
I0522 22:26:05.960810  1275 solver.cpp:237] Iteration 45375, loss = 1.0746
I0522 22:26:05.960966  1275 solver.cpp:253]     Train net output #0: loss = 1.0746 (* 1 = 1.0746 loss)
I0522 22:26:05.960980  1275 sgd_solver.cpp:106] Iteration 45375, lr = 0.0035
I0522 22:26:15.727754  1275 solver.cpp:237] Iteration 45750, loss = 1.19338
I0522 22:26:15.727802  1275 solver.cpp:253]     Train net output #0: loss = 1.19338 (* 1 = 1.19338 loss)
I0522 22:26:15.727819  1275 sgd_solver.cpp:106] Iteration 45750, lr = 0.0035
I0522 22:26:25.487696  1275 solver.cpp:237] Iteration 46125, loss = 1.23917
I0522 22:26:25.487730  1275 solver.cpp:253]     Train net output #0: loss = 1.23917 (* 1 = 1.23917 loss)
I0522 22:26:25.487747  1275 sgd_solver.cpp:106] Iteration 46125, lr = 0.0035
I0522 22:26:35.248423  1275 solver.cpp:237] Iteration 46500, loss = 1.30766
I0522 22:26:35.248474  1275 solver.cpp:253]     Train net output #0: loss = 1.30766 (* 1 = 1.30766 loss)
I0522 22:26:35.248491  1275 sgd_solver.cpp:106] Iteration 46500, lr = 0.0035
I0522 22:26:45.009187  1275 solver.cpp:237] Iteration 46875, loss = 1.42735
I0522 22:26:45.009338  1275 solver.cpp:253]     Train net output #0: loss = 1.42735 (* 1 = 1.42735 loss)
I0522 22:26:45.009352  1275 sgd_solver.cpp:106] Iteration 46875, lr = 0.0035
I0522 22:26:54.772819  1275 solver.cpp:237] Iteration 47250, loss = 1.27712
I0522 22:26:54.772852  1275 solver.cpp:253]     Train net output #0: loss = 1.27712 (* 1 = 1.27712 loss)
I0522 22:26:54.772871  1275 sgd_solver.cpp:106] Iteration 47250, lr = 0.0035
I0522 22:27:25.455116  1275 solver.cpp:237] Iteration 47625, loss = 1.19832
I0522 22:27:25.455291  1275 solver.cpp:253]     Train net output #0: loss = 1.19832 (* 1 = 1.19832 loss)
I0522 22:27:25.455304  1275 sgd_solver.cpp:106] Iteration 47625, lr = 0.0035
I0522 22:27:35.213135  1275 solver.cpp:237] Iteration 48000, loss = 0.836677
I0522 22:27:35.213171  1275 solver.cpp:253]     Train net output #0: loss = 0.836677 (* 1 = 0.836677 loss)
I0522 22:27:35.213188  1275 sgd_solver.cpp:106] Iteration 48000, lr = 0.0035
I0522 22:27:44.979327  1275 solver.cpp:237] Iteration 48375, loss = 0.995941
I0522 22:27:44.979364  1275 solver.cpp:253]     Train net output #0: loss = 0.995941 (* 1 = 0.995941 loss)
I0522 22:27:44.979379  1275 sgd_solver.cpp:106] Iteration 48375, lr = 0.0035
I0522 22:27:54.711223  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_48750.caffemodel
I0522 22:27:54.767508  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_48750.solverstate
I0522 22:27:54.802104  1275 solver.cpp:237] Iteration 48750, loss = 1.07566
I0522 22:27:54.802153  1275 solver.cpp:253]     Train net output #0: loss = 1.07566 (* 1 = 1.07566 loss)
I0522 22:27:54.802168  1275 sgd_solver.cpp:106] Iteration 48750, lr = 0.0035
I0522 22:28:04.559634  1275 solver.cpp:237] Iteration 49125, loss = 0.954137
I0522 22:28:04.559809  1275 solver.cpp:253]     Train net output #0: loss = 0.954138 (* 1 = 0.954138 loss)
I0522 22:28:04.559824  1275 sgd_solver.cpp:106] Iteration 49125, lr = 0.0035
I0522 22:28:14.318970  1275 solver.cpp:237] Iteration 49500, loss = 1.41695
I0522 22:28:14.319021  1275 solver.cpp:253]     Train net output #0: loss = 1.41695 (* 1 = 1.41695 loss)
I0522 22:28:14.319038  1275 sgd_solver.cpp:106] Iteration 49500, lr = 0.0035
I0522 22:28:24.078446  1275 solver.cpp:237] Iteration 49875, loss = 1.0412
I0522 22:28:24.078481  1275 solver.cpp:253]     Train net output #0: loss = 1.0412 (* 1 = 1.0412 loss)
I0522 22:28:24.078497  1275 sgd_solver.cpp:106] Iteration 49875, lr = 0.0035
I0522 22:28:54.785853  1275 solver.cpp:237] Iteration 50250, loss = 1.34877
I0522 22:28:54.786037  1275 solver.cpp:253]     Train net output #0: loss = 1.34877 (* 1 = 1.34877 loss)
I0522 22:28:54.786052  1275 sgd_solver.cpp:106] Iteration 50250, lr = 0.0035
I0522 22:29:04.539278  1275 solver.cpp:237] Iteration 50625, loss = 1.32486
I0522 22:29:04.539325  1275 solver.cpp:253]     Train net output #0: loss = 1.32486 (* 1 = 1.32486 loss)
I0522 22:29:04.539343  1275 sgd_solver.cpp:106] Iteration 50625, lr = 0.0035
I0522 22:29:14.302140  1275 solver.cpp:237] Iteration 51000, loss = 1.30763
I0522 22:29:14.302175  1275 solver.cpp:253]     Train net output #0: loss = 1.30763 (* 1 = 1.30763 loss)
I0522 22:29:14.302192  1275 sgd_solver.cpp:106] Iteration 51000, lr = 0.0035
I0522 22:29:24.061420  1275 solver.cpp:237] Iteration 51375, loss = 1.52201
I0522 22:29:24.061456  1275 solver.cpp:253]     Train net output #0: loss = 1.52201 (* 1 = 1.52201 loss)
I0522 22:29:24.061475  1275 sgd_solver.cpp:106] Iteration 51375, lr = 0.0035
I0522 22:29:33.822280  1275 solver.cpp:237] Iteration 51750, loss = 1.50476
I0522 22:29:33.822450  1275 solver.cpp:253]     Train net output #0: loss = 1.50476 (* 1 = 1.50476 loss)
I0522 22:29:33.822464  1275 sgd_solver.cpp:106] Iteration 51750, lr = 0.0035
I0522 22:29:43.581140  1275 solver.cpp:237] Iteration 52125, loss = 1.25314
I0522 22:29:43.581176  1275 solver.cpp:253]     Train net output #0: loss = 1.25314 (* 1 = 1.25314 loss)
I0522 22:29:43.581190  1275 sgd_solver.cpp:106] Iteration 52125, lr = 0.0035
I0522 22:29:53.312719  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_52500.caffemodel
I0522 22:29:53.377816  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_52500.solverstate
I0522 22:29:53.403964  1275 solver.cpp:341] Iteration 52500, Testing net (#0)
I0522 22:30:41.648567  1275 solver.cpp:409]     Test net output #0: accuracy = 0.885446
I0522 22:30:41.648736  1275 solver.cpp:409]     Test net output #1: loss = 0.381071 (* 1 = 0.381071 loss)
I0522 22:31:02.592686  1275 solver.cpp:237] Iteration 52500, loss = 1.27756
I0522 22:31:02.592744  1275 solver.cpp:253]     Train net output #0: loss = 1.27756 (* 1 = 1.27756 loss)
I0522 22:31:02.592759  1275 sgd_solver.cpp:106] Iteration 52500, lr = 0.0035
I0522 22:31:12.240559  1275 solver.cpp:237] Iteration 52875, loss = 1.11187
I0522 22:31:12.240730  1275 solver.cpp:253]     Train net output #0: loss = 1.11187 (* 1 = 1.11187 loss)
I0522 22:31:12.240743  1275 sgd_solver.cpp:106] Iteration 52875, lr = 0.0035
I0522 22:31:21.893854  1275 solver.cpp:237] Iteration 53250, loss = 1.38643
I0522 22:31:21.893889  1275 solver.cpp:253]     Train net output #0: loss = 1.38643 (* 1 = 1.38643 loss)
I0522 22:31:21.893913  1275 sgd_solver.cpp:106] Iteration 53250, lr = 0.0035
I0522 22:31:31.540930  1275 solver.cpp:237] Iteration 53625, loss = 1.04224
I0522 22:31:31.540966  1275 solver.cpp:253]     Train net output #0: loss = 1.04224 (* 1 = 1.04224 loss)
I0522 22:31:31.540984  1275 sgd_solver.cpp:106] Iteration 53625, lr = 0.0035
I0522 22:31:41.197314  1275 solver.cpp:237] Iteration 54000, loss = 1.38083
I0522 22:31:41.197358  1275 solver.cpp:253]     Train net output #0: loss = 1.38083 (* 1 = 1.38083 loss)
I0522 22:31:41.197377  1275 sgd_solver.cpp:106] Iteration 54000, lr = 0.0035
I0522 22:31:50.852973  1275 solver.cpp:237] Iteration 54375, loss = 1.24827
I0522 22:31:50.853132  1275 solver.cpp:253]     Train net output #0: loss = 1.24827 (* 1 = 1.24827 loss)
I0522 22:31:50.853147  1275 sgd_solver.cpp:106] Iteration 54375, lr = 0.0035
I0522 22:32:00.511605  1275 solver.cpp:237] Iteration 54750, loss = 1.07315
I0522 22:32:00.511653  1275 solver.cpp:253]     Train net output #0: loss = 1.07315 (* 1 = 1.07315 loss)
I0522 22:32:00.511673  1275 sgd_solver.cpp:106] Iteration 54750, lr = 0.0035
I0522 22:32:31.130192  1275 solver.cpp:237] Iteration 55125, loss = 1.40672
I0522 22:32:31.130375  1275 solver.cpp:253]     Train net output #0: loss = 1.40672 (* 1 = 1.40672 loss)
I0522 22:32:31.130390  1275 sgd_solver.cpp:106] Iteration 55125, lr = 0.0035
I0522 22:32:40.778880  1275 solver.cpp:237] Iteration 55500, loss = 1.29389
I0522 22:32:40.778915  1275 solver.cpp:253]     Train net output #0: loss = 1.29389 (* 1 = 1.29389 loss)
I0522 22:32:40.778931  1275 sgd_solver.cpp:106] Iteration 55500, lr = 0.0035
I0522 22:32:50.435657  1275 solver.cpp:237] Iteration 55875, loss = 1.03456
I0522 22:32:50.435703  1275 solver.cpp:253]     Train net output #0: loss = 1.03456 (* 1 = 1.03456 loss)
I0522 22:32:50.435724  1275 sgd_solver.cpp:106] Iteration 55875, lr = 0.0035
I0522 22:33:00.061449  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_56250.caffemodel
I0522 22:33:00.118733  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_56250.solverstate
I0522 22:33:00.155448  1275 solver.cpp:237] Iteration 56250, loss = 1.21901
I0522 22:33:00.155501  1275 solver.cpp:253]     Train net output #0: loss = 1.21901 (* 1 = 1.21901 loss)
I0522 22:33:00.155516  1275 sgd_solver.cpp:106] Iteration 56250, lr = 0.0035
I0522 22:33:09.808531  1275 solver.cpp:237] Iteration 56625, loss = 1.23294
I0522 22:33:09.808687  1275 solver.cpp:253]     Train net output #0: loss = 1.23294 (* 1 = 1.23294 loss)
I0522 22:33:09.808701  1275 sgd_solver.cpp:106] Iteration 56625, lr = 0.0035
I0522 22:33:19.465375  1275 solver.cpp:237] Iteration 57000, loss = 1.31142
I0522 22:33:19.465425  1275 solver.cpp:253]     Train net output #0: loss = 1.31142 (* 1 = 1.31142 loss)
I0522 22:33:19.465443  1275 sgd_solver.cpp:106] Iteration 57000, lr = 0.0035
I0522 22:33:29.118319  1275 solver.cpp:237] Iteration 57375, loss = 1.2231
I0522 22:33:29.118355  1275 solver.cpp:253]     Train net output #0: loss = 1.2231 (* 1 = 1.2231 loss)
I0522 22:33:29.118371  1275 sgd_solver.cpp:106] Iteration 57375, lr = 0.0035
I0522 22:33:59.659863  1275 solver.cpp:237] Iteration 57750, loss = 1.30066
I0522 22:33:59.660044  1275 solver.cpp:253]     Train net output #0: loss = 1.30066 (* 1 = 1.30066 loss)
I0522 22:33:59.660059  1275 sgd_solver.cpp:106] Iteration 57750, lr = 0.0035
I0522 22:34:09.311884  1275 solver.cpp:237] Iteration 58125, loss = 1.26149
I0522 22:34:09.311931  1275 solver.cpp:253]     Train net output #0: loss = 1.26149 (* 1 = 1.26149 loss)
I0522 22:34:09.311949  1275 sgd_solver.cpp:106] Iteration 58125, lr = 0.0035
I0522 22:34:18.962451  1275 solver.cpp:237] Iteration 58500, loss = 1.13457
I0522 22:34:18.962487  1275 solver.cpp:253]     Train net output #0: loss = 1.13457 (* 1 = 1.13457 loss)
I0522 22:34:18.962503  1275 sgd_solver.cpp:106] Iteration 58500, lr = 0.0035
I0522 22:34:28.613265  1275 solver.cpp:237] Iteration 58875, loss = 1.26886
I0522 22:34:28.613313  1275 solver.cpp:253]     Train net output #0: loss = 1.26886 (* 1 = 1.26886 loss)
I0522 22:34:28.613329  1275 sgd_solver.cpp:106] Iteration 58875, lr = 0.0035
I0522 22:34:38.270014  1275 solver.cpp:237] Iteration 59250, loss = 1.08551
I0522 22:34:38.270177  1275 solver.cpp:253]     Train net output #0: loss = 1.08551 (* 1 = 1.08551 loss)
I0522 22:34:38.270191  1275 sgd_solver.cpp:106] Iteration 59250, lr = 0.0035
I0522 22:34:47.927500  1275 solver.cpp:237] Iteration 59625, loss = 0.961781
I0522 22:34:47.927536  1275 solver.cpp:253]     Train net output #0: loss = 0.961781 (* 1 = 0.961781 loss)
I0522 22:34:47.927549  1275 sgd_solver.cpp:106] Iteration 59625, lr = 0.0035
I0522 22:34:57.555795  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_60000.caffemodel
I0522 22:34:57.610561  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_60000.solverstate
I0522 22:34:57.636525  1275 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 22:36:07.073571  1275 solver.cpp:409]     Test net output #0: accuracy = 0.887608
I0522 22:36:07.073758  1275 solver.cpp:409]     Test net output #1: loss = 0.3694 (* 1 = 0.3694 loss)
I0522 22:36:27.939157  1275 solver.cpp:237] Iteration 60000, loss = 1.27206
I0522 22:36:27.939213  1275 solver.cpp:253]     Train net output #0: loss = 1.27206 (* 1 = 1.27206 loss)
I0522 22:36:27.939229  1275 sgd_solver.cpp:106] Iteration 60000, lr = 0.0035
I0522 22:36:37.768501  1275 solver.cpp:237] Iteration 60375, loss = 0.931049
I0522 22:36:37.768673  1275 solver.cpp:253]     Train net output #0: loss = 0.93105 (* 1 = 0.93105 loss)
I0522 22:36:37.768688  1275 sgd_solver.cpp:106] Iteration 60375, lr = 0.0035
I0522 22:36:47.602172  1275 solver.cpp:237] Iteration 60750, loss = 1.57714
I0522 22:36:47.602206  1275 solver.cpp:253]     Train net output #0: loss = 1.57714 (* 1 = 1.57714 loss)
I0522 22:36:47.602221  1275 sgd_solver.cpp:106] Iteration 60750, lr = 0.0035
I0522 22:36:57.440075  1275 solver.cpp:237] Iteration 61125, loss = 1.05857
I0522 22:36:57.440110  1275 solver.cpp:253]     Train net output #0: loss = 1.05857 (* 1 = 1.05857 loss)
I0522 22:36:57.440129  1275 sgd_solver.cpp:106] Iteration 61125, lr = 0.0035
I0522 22:37:07.267541  1275 solver.cpp:237] Iteration 61500, loss = 1.30559
I0522 22:37:07.267591  1275 solver.cpp:253]     Train net output #0: loss = 1.30559 (* 1 = 1.30559 loss)
I0522 22:37:07.267608  1275 sgd_solver.cpp:106] Iteration 61500, lr = 0.0035
I0522 22:37:17.104032  1275 solver.cpp:237] Iteration 61875, loss = 1.54611
I0522 22:37:17.104187  1275 solver.cpp:253]     Train net output #0: loss = 1.54611 (* 1 = 1.54611 loss)
I0522 22:37:17.104200  1275 sgd_solver.cpp:106] Iteration 61875, lr = 0.0035
I0522 22:37:26.942106  1275 solver.cpp:237] Iteration 62250, loss = 1.13082
I0522 22:37:26.942152  1275 solver.cpp:253]     Train net output #0: loss = 1.13082 (* 1 = 1.13082 loss)
I0522 22:37:26.942169  1275 sgd_solver.cpp:106] Iteration 62250, lr = 0.0035
I0522 22:37:57.660262  1275 solver.cpp:237] Iteration 62625, loss = 1.37412
I0522 22:37:57.660439  1275 solver.cpp:253]     Train net output #0: loss = 1.37412 (* 1 = 1.37412 loss)
I0522 22:37:57.660454  1275 sgd_solver.cpp:106] Iteration 62625, lr = 0.0035
I0522 22:38:07.499708  1275 solver.cpp:237] Iteration 63000, loss = 0.962316
I0522 22:38:07.499743  1275 solver.cpp:253]     Train net output #0: loss = 0.962317 (* 1 = 0.962317 loss)
I0522 22:38:07.499760  1275 sgd_solver.cpp:106] Iteration 63000, lr = 0.0035
I0522 22:38:17.338485  1275 solver.cpp:237] Iteration 63375, loss = 1.02918
I0522 22:38:17.338533  1275 solver.cpp:253]     Train net output #0: loss = 1.02918 (* 1 = 1.02918 loss)
I0522 22:38:17.338551  1275 sgd_solver.cpp:106] Iteration 63375, lr = 0.0035
I0522 22:38:27.149708  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_63750.caffemodel
I0522 22:38:27.206172  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_63750.solverstate
I0522 22:38:27.240445  1275 solver.cpp:237] Iteration 63750, loss = 1.22169
I0522 22:38:27.240489  1275 solver.cpp:253]     Train net output #0: loss = 1.22169 (* 1 = 1.22169 loss)
I0522 22:38:27.240507  1275 sgd_solver.cpp:106] Iteration 63750, lr = 0.0035
I0522 22:38:37.072726  1275 solver.cpp:237] Iteration 64125, loss = 0.951993
I0522 22:38:37.072893  1275 solver.cpp:253]     Train net output #0: loss = 0.951993 (* 1 = 0.951993 loss)
I0522 22:38:37.072907  1275 sgd_solver.cpp:106] Iteration 64125, lr = 0.0035
I0522 22:38:46.901365  1275 solver.cpp:237] Iteration 64500, loss = 1.14703
I0522 22:38:46.901412  1275 solver.cpp:253]     Train net output #0: loss = 1.14703 (* 1 = 1.14703 loss)
I0522 22:38:46.901427  1275 sgd_solver.cpp:106] Iteration 64500, lr = 0.0035
I0522 22:38:56.736706  1275 solver.cpp:237] Iteration 64875, loss = 1.34474
I0522 22:38:56.736742  1275 solver.cpp:253]     Train net output #0: loss = 1.34474 (* 1 = 1.34474 loss)
I0522 22:38:56.736757  1275 sgd_solver.cpp:106] Iteration 64875, lr = 0.0035
I0522 22:39:27.466915  1275 solver.cpp:237] Iteration 65250, loss = 1.1057
I0522 22:39:27.467097  1275 solver.cpp:253]     Train net output #0: loss = 1.1057 (* 1 = 1.1057 loss)
I0522 22:39:27.467113  1275 sgd_solver.cpp:106] Iteration 65250, lr = 0.0035
I0522 22:39:37.300875  1275 solver.cpp:237] Iteration 65625, loss = 1.10801
I0522 22:39:37.300917  1275 solver.cpp:253]     Train net output #0: loss = 1.10801 (* 1 = 1.10801 loss)
I0522 22:39:37.300937  1275 sgd_solver.cpp:106] Iteration 65625, lr = 0.0035
I0522 22:39:47.070550  1275 solver.cpp:237] Iteration 66000, loss = 1.38216
I0522 22:39:47.070586  1275 solver.cpp:253]     Train net output #0: loss = 1.38216 (* 1 = 1.38216 loss)
I0522 22:39:47.070601  1275 sgd_solver.cpp:106] Iteration 66000, lr = 0.0035
I0522 22:39:56.816539  1275 solver.cpp:237] Iteration 66375, loss = 0.905991
I0522 22:39:56.816579  1275 solver.cpp:253]     Train net output #0: loss = 0.905991 (* 1 = 0.905991 loss)
I0522 22:39:56.816601  1275 sgd_solver.cpp:106] Iteration 66375, lr = 0.0035
I0522 22:40:06.571688  1275 solver.cpp:237] Iteration 66750, loss = 1.28541
I0522 22:40:06.571838  1275 solver.cpp:253]     Train net output #0: loss = 1.28541 (* 1 = 1.28541 loss)
I0522 22:40:06.571851  1275 sgd_solver.cpp:106] Iteration 66750, lr = 0.0035
I0522 22:40:16.328472  1275 solver.cpp:237] Iteration 67125, loss = 1.2717
I0522 22:40:16.328507  1275 solver.cpp:253]     Train net output #0: loss = 1.2717 (* 1 = 1.2717 loss)
I0522 22:40:16.328523  1275 sgd_solver.cpp:106] Iteration 67125, lr = 0.0035
I0522 22:40:26.065160  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_67500.caffemodel
I0522 22:40:26.121242  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_67500.solverstate
I0522 22:40:26.147430  1275 solver.cpp:341] Iteration 67500, Testing net (#0)
I0522 22:41:14.737460  1275 solver.cpp:409]     Test net output #0: accuracy = 0.8897
I0522 22:41:14.737638  1275 solver.cpp:409]     Test net output #1: loss = 0.356282 (* 1 = 0.356282 loss)
I0522 22:41:35.632712  1275 solver.cpp:237] Iteration 67500, loss = 1.00745
I0522 22:41:35.632768  1275 solver.cpp:253]     Train net output #0: loss = 1.00745 (* 1 = 1.00745 loss)
I0522 22:41:35.632783  1275 sgd_solver.cpp:106] Iteration 67500, lr = 0.0035
I0522 22:41:45.575703  1275 solver.cpp:237] Iteration 67875, loss = 1.40198
I0522 22:41:45.575863  1275 solver.cpp:253]     Train net output #0: loss = 1.40198 (* 1 = 1.40198 loss)
I0522 22:41:45.575877  1275 sgd_solver.cpp:106] Iteration 67875, lr = 0.0035
I0522 22:41:55.527221  1275 solver.cpp:237] Iteration 68250, loss = 1.30974
I0522 22:41:55.527256  1275 solver.cpp:253]     Train net output #0: loss = 1.30974 (* 1 = 1.30974 loss)
I0522 22:41:55.527269  1275 sgd_solver.cpp:106] Iteration 68250, lr = 0.0035
I0522 22:42:05.484676  1275 solver.cpp:237] Iteration 68625, loss = 0.870268
I0522 22:42:05.484721  1275 solver.cpp:253]     Train net output #0: loss = 0.870268 (* 1 = 0.870268 loss)
I0522 22:42:05.484740  1275 sgd_solver.cpp:106] Iteration 68625, lr = 0.0035
I0522 22:42:15.445235  1275 solver.cpp:237] Iteration 69000, loss = 1.07304
I0522 22:42:15.445268  1275 solver.cpp:253]     Train net output #0: loss = 1.07304 (* 1 = 1.07304 loss)
I0522 22:42:15.445286  1275 sgd_solver.cpp:106] Iteration 69000, lr = 0.0035
I0522 22:42:25.396653  1275 solver.cpp:237] Iteration 69375, loss = 1.06762
I0522 22:42:25.396836  1275 solver.cpp:253]     Train net output #0: loss = 1.06762 (* 1 = 1.06762 loss)
I0522 22:42:25.396849  1275 sgd_solver.cpp:106] Iteration 69375, lr = 0.0035
I0522 22:42:35.346261  1275 solver.cpp:237] Iteration 69750, loss = 0.863963
I0522 22:42:35.346297  1275 solver.cpp:253]     Train net output #0: loss = 0.863963 (* 1 = 0.863963 loss)
I0522 22:42:35.346312  1275 sgd_solver.cpp:106] Iteration 69750, lr = 0.0035
I0522 22:43:06.177556  1275 solver.cpp:237] Iteration 70125, loss = 1.23236
I0522 22:43:06.177741  1275 solver.cpp:253]     Train net output #0: loss = 1.23236 (* 1 = 1.23236 loss)
I0522 22:43:06.177755  1275 sgd_solver.cpp:106] Iteration 70125, lr = 0.0035
I0522 22:43:16.126579  1275 solver.cpp:237] Iteration 70500, loss = 1.33742
I0522 22:43:16.126623  1275 solver.cpp:253]     Train net output #0: loss = 1.33742 (* 1 = 1.33742 loss)
I0522 22:43:16.126641  1275 sgd_solver.cpp:106] Iteration 70500, lr = 0.0035
I0522 22:43:26.073735  1275 solver.cpp:237] Iteration 70875, loss = 0.985324
I0522 22:43:26.073771  1275 solver.cpp:253]     Train net output #0: loss = 0.985324 (* 1 = 0.985324 loss)
I0522 22:43:26.073786  1275 sgd_solver.cpp:106] Iteration 70875, lr = 0.0035
I0522 22:43:35.994807  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_71250.caffemodel
I0522 22:43:36.053028  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_71250.solverstate
I0522 22:43:36.089507  1275 solver.cpp:237] Iteration 71250, loss = 1.00744
I0522 22:43:36.089561  1275 solver.cpp:253]     Train net output #0: loss = 1.00745 (* 1 = 1.00745 loss)
I0522 22:43:36.089576  1275 sgd_solver.cpp:106] Iteration 71250, lr = 0.0035
I0522 22:43:46.011214  1275 solver.cpp:237] Iteration 71625, loss = 1.11242
I0522 22:43:46.011389  1275 solver.cpp:253]     Train net output #0: loss = 1.11242 (* 1 = 1.11242 loss)
I0522 22:43:46.011402  1275 sgd_solver.cpp:106] Iteration 71625, lr = 0.0035
I0522 22:43:55.925122  1275 solver.cpp:237] Iteration 72000, loss = 1.79975
I0522 22:43:55.925156  1275 solver.cpp:253]     Train net output #0: loss = 1.79975 (* 1 = 1.79975 loss)
I0522 22:43:55.925173  1275 sgd_solver.cpp:106] Iteration 72000, lr = 0.0035
I0522 22:44:05.838937  1275 solver.cpp:237] Iteration 72375, loss = 1.05206
I0522 22:44:05.838992  1275 solver.cpp:253]     Train net output #0: loss = 1.05206 (* 1 = 1.05206 loss)
I0522 22:44:05.839009  1275 sgd_solver.cpp:106] Iteration 72375, lr = 0.0035
I0522 22:44:36.634909  1275 solver.cpp:237] Iteration 72750, loss = 1.21629
I0522 22:44:36.635094  1275 solver.cpp:253]     Train net output #0: loss = 1.2163 (* 1 = 1.2163 loss)
I0522 22:44:36.635110  1275 sgd_solver.cpp:106] Iteration 72750, lr = 0.0035
I0522 22:44:46.542167  1275 solver.cpp:237] Iteration 73125, loss = 1.32986
I0522 22:44:46.542202  1275 solver.cpp:253]     Train net output #0: loss = 1.32986 (* 1 = 1.32986 loss)
I0522 22:44:46.542220  1275 sgd_solver.cpp:106] Iteration 73125, lr = 0.0035
I0522 22:44:56.456127  1275 solver.cpp:237] Iteration 73500, loss = 1.29907
I0522 22:44:56.456172  1275 solver.cpp:253]     Train net output #0: loss = 1.29907 (* 1 = 1.29907 loss)
I0522 22:44:56.456190  1275 sgd_solver.cpp:106] Iteration 73500, lr = 0.0035
I0522 22:45:06.364141  1275 solver.cpp:237] Iteration 73875, loss = 1.10166
I0522 22:45:06.364177  1275 solver.cpp:253]     Train net output #0: loss = 1.10166 (* 1 = 1.10166 loss)
I0522 22:45:06.364193  1275 sgd_solver.cpp:106] Iteration 73875, lr = 0.0035
I0522 22:45:16.272857  1275 solver.cpp:237] Iteration 74250, loss = 1.14524
I0522 22:45:16.273022  1275 solver.cpp:253]     Train net output #0: loss = 1.14524 (* 1 = 1.14524 loss)
I0522 22:45:16.273036  1275 sgd_solver.cpp:106] Iteration 74250, lr = 0.0035
I0522 22:45:26.185933  1275 solver.cpp:237] Iteration 74625, loss = 1.5281
I0522 22:45:26.185977  1275 solver.cpp:253]     Train net output #0: loss = 1.5281 (* 1 = 1.5281 loss)
I0522 22:45:26.185992  1275 sgd_solver.cpp:106] Iteration 74625, lr = 0.0035
I0522 22:45:36.071036  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_75000.caffemodel
I0522 22:45:36.129449  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_75000.solverstate
I0522 22:45:36.158258  1275 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 22:46:45.689311  1275 solver.cpp:409]     Test net output #0: accuracy = 0.894126
I0522 22:46:45.689494  1275 solver.cpp:409]     Test net output #1: loss = 0.339922 (* 1 = 0.339922 loss)
I0522 22:47:06.624181  1275 solver.cpp:237] Iteration 75000, loss = 0.811438
I0522 22:47:06.624239  1275 solver.cpp:253]     Train net output #0: loss = 0.811438 (* 1 = 0.811438 loss)
I0522 22:47:06.624254  1275 sgd_solver.cpp:106] Iteration 75000, lr = 0.0035
I0522 22:47:16.483597  1275 solver.cpp:237] Iteration 75375, loss = 0.926508
I0522 22:47:16.483758  1275 solver.cpp:253]     Train net output #0: loss = 0.926508 (* 1 = 0.926508 loss)
I0522 22:47:16.483772  1275 sgd_solver.cpp:106] Iteration 75375, lr = 0.0035
I0522 22:47:26.341542  1275 solver.cpp:237] Iteration 75750, loss = 1.17464
I0522 22:47:26.341585  1275 solver.cpp:253]     Train net output #0: loss = 1.17464 (* 1 = 1.17464 loss)
I0522 22:47:26.341605  1275 sgd_solver.cpp:106] Iteration 75750, lr = 0.0035
I0522 22:47:36.209795  1275 solver.cpp:237] Iteration 76125, loss = 1.49331
I0522 22:47:36.209830  1275 solver.cpp:253]     Train net output #0: loss = 1.49331 (* 1 = 1.49331 loss)
I0522 22:47:36.209844  1275 sgd_solver.cpp:106] Iteration 76125, lr = 0.0035
I0522 22:47:46.070044  1275 solver.cpp:237] Iteration 76500, loss = 1.48668
I0522 22:47:46.070075  1275 solver.cpp:253]     Train net output #0: loss = 1.48668 (* 1 = 1.48668 loss)
I0522 22:47:46.070088  1275 sgd_solver.cpp:106] Iteration 76500, lr = 0.0035
I0522 22:47:55.930025  1275 solver.cpp:237] Iteration 76875, loss = 1.06632
I0522 22:47:55.930199  1275 solver.cpp:253]     Train net output #0: loss = 1.06632 (* 1 = 1.06632 loss)
I0522 22:47:55.930213  1275 sgd_solver.cpp:106] Iteration 76875, lr = 0.0035
I0522 22:48:05.791259  1275 solver.cpp:237] Iteration 77250, loss = 1.22373
I0522 22:48:05.791292  1275 solver.cpp:253]     Train net output #0: loss = 1.22373 (* 1 = 1.22373 loss)
I0522 22:48:05.791306  1275 sgd_solver.cpp:106] Iteration 77250, lr = 0.0035
I0522 22:48:36.545456  1275 solver.cpp:237] Iteration 77625, loss = 1.04502
I0522 22:48:36.545637  1275 solver.cpp:253]     Train net output #0: loss = 1.04502 (* 1 = 1.04502 loss)
I0522 22:48:36.545652  1275 sgd_solver.cpp:106] Iteration 77625, lr = 0.0035
I0522 22:48:46.403277  1275 solver.cpp:237] Iteration 78000, loss = 1.10931
I0522 22:48:46.403324  1275 solver.cpp:253]     Train net output #0: loss = 1.10931 (* 1 = 1.10931 loss)
I0522 22:48:46.403342  1275 sgd_solver.cpp:106] Iteration 78000, lr = 0.0035
I0522 22:48:56.262403  1275 solver.cpp:237] Iteration 78375, loss = 1.16246
I0522 22:48:56.262439  1275 solver.cpp:253]     Train net output #0: loss = 1.16246 (* 1 = 1.16246 loss)
I0522 22:48:56.262455  1275 sgd_solver.cpp:106] Iteration 78375, lr = 0.0035
I0522 22:49:06.099071  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_78750.caffemodel
I0522 22:49:06.155624  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_78750.solverstate
I0522 22:49:06.190052  1275 solver.cpp:237] Iteration 78750, loss = 1.11011
I0522 22:49:06.190096  1275 solver.cpp:253]     Train net output #0: loss = 1.11011 (* 1 = 1.11011 loss)
I0522 22:49:06.190114  1275 sgd_solver.cpp:106] Iteration 78750, lr = 0.0035
I0522 22:49:16.052702  1275 solver.cpp:237] Iteration 79125, loss = 1.50721
I0522 22:49:16.052875  1275 solver.cpp:253]     Train net output #0: loss = 1.50721 (* 1 = 1.50721 loss)
I0522 22:49:16.052888  1275 sgd_solver.cpp:106] Iteration 79125, lr = 0.0035
I0522 22:49:25.919512  1275 solver.cpp:237] Iteration 79500, loss = 1.1636
I0522 22:49:25.919545  1275 solver.cpp:253]     Train net output #0: loss = 1.1636 (* 1 = 1.1636 loss)
I0522 22:49:25.919564  1275 sgd_solver.cpp:106] Iteration 79500, lr = 0.0035
I0522 22:49:35.785305  1275 solver.cpp:237] Iteration 79875, loss = 0.961351
I0522 22:49:35.785344  1275 solver.cpp:253]     Train net output #0: loss = 0.961351 (* 1 = 0.961351 loss)
I0522 22:49:35.785362  1275 sgd_solver.cpp:106] Iteration 79875, lr = 0.0035
I0522 22:50:06.534580  1275 solver.cpp:237] Iteration 80250, loss = 1.29246
I0522 22:50:06.534773  1275 solver.cpp:253]     Train net output #0: loss = 1.29246 (* 1 = 1.29246 loss)
I0522 22:50:06.534790  1275 sgd_solver.cpp:106] Iteration 80250, lr = 0.0035
I0522 22:50:16.395391  1275 solver.cpp:237] Iteration 80625, loss = 1.03747
I0522 22:50:16.395426  1275 solver.cpp:253]     Train net output #0: loss = 1.03747 (* 1 = 1.03747 loss)
I0522 22:50:16.395444  1275 sgd_solver.cpp:106] Iteration 80625, lr = 0.0035
I0522 22:50:26.259542  1275 solver.cpp:237] Iteration 81000, loss = 1.3854
I0522 22:50:26.259583  1275 solver.cpp:253]     Train net output #0: loss = 1.3854 (* 1 = 1.3854 loss)
I0522 22:50:26.259601  1275 sgd_solver.cpp:106] Iteration 81000, lr = 0.0035
I0522 22:50:36.125347  1275 solver.cpp:237] Iteration 81375, loss = 1.15501
I0522 22:50:36.125382  1275 solver.cpp:253]     Train net output #0: loss = 1.15501 (* 1 = 1.15501 loss)
I0522 22:50:36.125398  1275 sgd_solver.cpp:106] Iteration 81375, lr = 0.0035
I0522 22:50:45.980007  1275 solver.cpp:237] Iteration 81750, loss = 1.25946
I0522 22:50:45.980171  1275 solver.cpp:253]     Train net output #0: loss = 1.25946 (* 1 = 1.25946 loss)
I0522 22:50:45.980185  1275 sgd_solver.cpp:106] Iteration 81750, lr = 0.0035
I0522 22:50:55.841538  1275 solver.cpp:237] Iteration 82125, loss = 1.13255
I0522 22:50:55.841573  1275 solver.cpp:253]     Train net output #0: loss = 1.13255 (* 1 = 1.13255 loss)
I0522 22:50:55.841590  1275 sgd_solver.cpp:106] Iteration 82125, lr = 0.0035
I0522 22:51:05.674298  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_82500.caffemodel
I0522 22:51:05.730600  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_82500.solverstate
I0522 22:51:05.756997  1275 solver.cpp:341] Iteration 82500, Testing net (#0)
I0522 22:51:53.972599  1275 solver.cpp:409]     Test net output #0: accuracy = 0.895106
I0522 22:51:53.972780  1275 solver.cpp:409]     Test net output #1: loss = 0.336872 (* 1 = 0.336872 loss)
I0522 22:52:14.886333  1275 solver.cpp:237] Iteration 82500, loss = 1.00617
I0522 22:52:14.886390  1275 solver.cpp:253]     Train net output #0: loss = 1.00617 (* 1 = 1.00617 loss)
I0522 22:52:14.886405  1275 sgd_solver.cpp:106] Iteration 82500, lr = 0.0035
I0522 22:52:24.636389  1275 solver.cpp:237] Iteration 82875, loss = 1.17847
I0522 22:52:24.636575  1275 solver.cpp:253]     Train net output #0: loss = 1.17847 (* 1 = 1.17847 loss)
I0522 22:52:24.636590  1275 sgd_solver.cpp:106] Iteration 82875, lr = 0.0035
I0522 22:52:34.387500  1275 solver.cpp:237] Iteration 83250, loss = 1.06633
I0522 22:52:34.387533  1275 solver.cpp:253]     Train net output #0: loss = 1.06633 (* 1 = 1.06633 loss)
I0522 22:52:34.387552  1275 sgd_solver.cpp:106] Iteration 83250, lr = 0.0035
I0522 22:52:44.135988  1275 solver.cpp:237] Iteration 83625, loss = 1.21664
I0522 22:52:44.136024  1275 solver.cpp:253]     Train net output #0: loss = 1.21664 (* 1 = 1.21664 loss)
I0522 22:52:44.136040  1275 sgd_solver.cpp:106] Iteration 83625, lr = 0.0035
I0522 22:52:53.887231  1275 solver.cpp:237] Iteration 84000, loss = 1.12945
I0522 22:52:53.887282  1275 solver.cpp:253]     Train net output #0: loss = 1.12945 (* 1 = 1.12945 loss)
I0522 22:52:53.887298  1275 sgd_solver.cpp:106] Iteration 84000, lr = 0.0035
I0522 22:53:03.643108  1275 solver.cpp:237] Iteration 84375, loss = 1.48697
I0522 22:53:03.643268  1275 solver.cpp:253]     Train net output #0: loss = 1.48697 (* 1 = 1.48697 loss)
I0522 22:53:03.643282  1275 sgd_solver.cpp:106] Iteration 84375, lr = 0.0035
I0522 22:53:13.400187  1275 solver.cpp:237] Iteration 84750, loss = 0.879918
I0522 22:53:13.400248  1275 solver.cpp:253]     Train net output #0: loss = 0.879918 (* 1 = 0.879918 loss)
I0522 22:53:13.400261  1275 sgd_solver.cpp:106] Iteration 84750, lr = 0.0035
I0522 22:53:44.000711  1275 solver.cpp:237] Iteration 85125, loss = 1.26806
I0522 22:53:44.000900  1275 solver.cpp:253]     Train net output #0: loss = 1.26806 (* 1 = 1.26806 loss)
I0522 22:53:44.000916  1275 sgd_solver.cpp:106] Iteration 85125, lr = 0.0035
I0522 22:53:53.759171  1275 solver.cpp:237] Iteration 85500, loss = 1.25996
I0522 22:53:53.759205  1275 solver.cpp:253]     Train net output #0: loss = 1.25996 (* 1 = 1.25996 loss)
I0522 22:53:53.759222  1275 sgd_solver.cpp:106] Iteration 85500, lr = 0.0035
I0522 22:54:03.512001  1275 solver.cpp:237] Iteration 85875, loss = 0.968242
I0522 22:54:03.512048  1275 solver.cpp:253]     Train net output #0: loss = 0.968242 (* 1 = 0.968242 loss)
I0522 22:54:03.512063  1275 sgd_solver.cpp:106] Iteration 85875, lr = 0.0035
I0522 22:54:13.171404  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_86250.caffemodel
I0522 22:54:13.227329  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_86250.solverstate
I0522 22:54:13.261600  1275 solver.cpp:237] Iteration 86250, loss = 1.13952
I0522 22:54:13.261644  1275 solver.cpp:253]     Train net output #0: loss = 1.13952 (* 1 = 1.13952 loss)
I0522 22:54:13.261661  1275 sgd_solver.cpp:106] Iteration 86250, lr = 0.0035
I0522 22:54:22.947273  1275 solver.cpp:237] Iteration 86625, loss = 0.968813
I0522 22:54:22.947445  1275 solver.cpp:253]     Train net output #0: loss = 0.968814 (* 1 = 0.968814 loss)
I0522 22:54:22.947460  1275 sgd_solver.cpp:106] Iteration 86625, lr = 0.0035
I0522 22:54:32.634578  1275 solver.cpp:237] Iteration 87000, loss = 0.995565
I0522 22:54:32.634631  1275 solver.cpp:253]     Train net output #0: loss = 0.995565 (* 1 = 0.995565 loss)
I0522 22:54:32.634649  1275 sgd_solver.cpp:106] Iteration 87000, lr = 0.0035
I0522 22:54:42.314436  1275 solver.cpp:237] Iteration 87375, loss = 1.02468
I0522 22:54:42.314471  1275 solver.cpp:253]     Train net output #0: loss = 1.02468 (* 1 = 1.02468 loss)
I0522 22:54:42.314486  1275 sgd_solver.cpp:106] Iteration 87375, lr = 0.0035
I0522 22:55:12.895164  1275 solver.cpp:237] Iteration 87750, loss = 1.08302
I0522 22:55:12.895349  1275 solver.cpp:253]     Train net output #0: loss = 1.08302 (* 1 = 1.08302 loss)
I0522 22:55:12.895365  1275 sgd_solver.cpp:106] Iteration 87750, lr = 0.0035
I0522 22:55:22.579996  1275 solver.cpp:237] Iteration 88125, loss = 0.824017
I0522 22:55:22.580047  1275 solver.cpp:253]     Train net output #0: loss = 0.824018 (* 1 = 0.824018 loss)
I0522 22:55:22.580063  1275 sgd_solver.cpp:106] Iteration 88125, lr = 0.0035
I0522 22:55:32.267364  1275 solver.cpp:237] Iteration 88500, loss = 1.31124
I0522 22:55:32.267400  1275 solver.cpp:253]     Train net output #0: loss = 1.31124 (* 1 = 1.31124 loss)
I0522 22:55:32.267412  1275 sgd_solver.cpp:106] Iteration 88500, lr = 0.0035
I0522 22:55:41.952158  1275 solver.cpp:237] Iteration 88875, loss = 1.02157
I0522 22:55:41.952193  1275 solver.cpp:253]     Train net output #0: loss = 1.02157 (* 1 = 1.02157 loss)
I0522 22:55:41.952209  1275 sgd_solver.cpp:106] Iteration 88875, lr = 0.0035
I0522 22:55:51.635139  1275 solver.cpp:237] Iteration 89250, loss = 0.937477
I0522 22:55:51.635324  1275 solver.cpp:253]     Train net output #0: loss = 0.937477 (* 1 = 0.937477 loss)
I0522 22:55:51.635339  1275 sgd_solver.cpp:106] Iteration 89250, lr = 0.0035
I0522 22:56:01.316175  1275 solver.cpp:237] Iteration 89625, loss = 1.23027
I0522 22:56:01.316210  1275 solver.cpp:253]     Train net output #0: loss = 1.23027 (* 1 = 1.23027 loss)
I0522 22:56:01.316227  1275 sgd_solver.cpp:106] Iteration 89625, lr = 0.0035
I0522 22:56:10.974385  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_90000.caffemodel
I0522 22:56:11.030494  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_90000.solverstate
I0522 22:56:11.057230  1275 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 22:57:20.502671  1275 solver.cpp:409]     Test net output #0: accuracy = 0.892314
I0522 22:57:20.502854  1275 solver.cpp:409]     Test net output #1: loss = 0.352536 (* 1 = 0.352536 loss)
I0522 22:57:41.375970  1275 solver.cpp:237] Iteration 90000, loss = 1.47271
I0522 22:57:41.376029  1275 solver.cpp:253]     Train net output #0: loss = 1.47271 (* 1 = 1.47271 loss)
I0522 22:57:41.376044  1275 sgd_solver.cpp:106] Iteration 90000, lr = 0.0035
I0522 22:57:51.144054  1275 solver.cpp:237] Iteration 90375, loss = 0.826406
I0522 22:57:51.144230  1275 solver.cpp:253]     Train net output #0: loss = 0.826406 (* 1 = 0.826406 loss)
I0522 22:57:51.144243  1275 sgd_solver.cpp:106] Iteration 90375, lr = 0.0035
I0522 22:58:00.917423  1275 solver.cpp:237] Iteration 90750, loss = 1.35121
I0522 22:58:00.917457  1275 solver.cpp:253]     Train net output #0: loss = 1.35121 (* 1 = 1.35121 loss)
I0522 22:58:00.917472  1275 sgd_solver.cpp:106] Iteration 90750, lr = 0.0035
I0522 22:58:10.692286  1275 solver.cpp:237] Iteration 91125, loss = 1.0519
I0522 22:58:10.692322  1275 solver.cpp:253]     Train net output #0: loss = 1.0519 (* 1 = 1.0519 loss)
I0522 22:58:10.692335  1275 sgd_solver.cpp:106] Iteration 91125, lr = 0.0035
I0522 22:58:20.461915  1275 solver.cpp:237] Iteration 91500, loss = 1.34222
I0522 22:58:20.461966  1275 solver.cpp:253]     Train net output #0: loss = 1.34222 (* 1 = 1.34222 loss)
I0522 22:58:20.461982  1275 sgd_solver.cpp:106] Iteration 91500, lr = 0.0035
I0522 22:58:30.227787  1275 solver.cpp:237] Iteration 91875, loss = 1.08211
I0522 22:58:30.227949  1275 solver.cpp:253]     Train net output #0: loss = 1.08211 (* 1 = 1.08211 loss)
I0522 22:58:30.227963  1275 sgd_solver.cpp:106] Iteration 91875, lr = 0.0035
I0522 22:58:39.991703  1275 solver.cpp:237] Iteration 92250, loss = 1.45232
I0522 22:58:39.991749  1275 solver.cpp:253]     Train net output #0: loss = 1.45233 (* 1 = 1.45233 loss)
I0522 22:58:39.991767  1275 sgd_solver.cpp:106] Iteration 92250, lr = 0.0035
I0522 22:59:10.619658  1275 solver.cpp:237] Iteration 92625, loss = 1.07989
I0522 22:59:10.619846  1275 solver.cpp:253]     Train net output #0: loss = 1.07989 (* 1 = 1.07989 loss)
I0522 22:59:10.619860  1275 sgd_solver.cpp:106] Iteration 92625, lr = 0.0035
I0522 22:59:20.389407  1275 solver.cpp:237] Iteration 93000, loss = 1.14751
I0522 22:59:20.389441  1275 solver.cpp:253]     Train net output #0: loss = 1.14751 (* 1 = 1.14751 loss)
I0522 22:59:20.389458  1275 sgd_solver.cpp:106] Iteration 93000, lr = 0.0035
I0522 22:59:30.153172  1275 solver.cpp:237] Iteration 93375, loss = 0.907088
I0522 22:59:30.153221  1275 solver.cpp:253]     Train net output #0: loss = 0.907088 (* 1 = 0.907088 loss)
I0522 22:59:30.153236  1275 sgd_solver.cpp:106] Iteration 93375, lr = 0.0035
I0522 22:59:39.898780  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_93750.caffemodel
I0522 22:59:39.957461  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_93750.solverstate
I0522 22:59:39.993974  1275 solver.cpp:237] Iteration 93750, loss = 0.949716
I0522 22:59:39.994025  1275 solver.cpp:253]     Train net output #0: loss = 0.949717 (* 1 = 0.949717 loss)
I0522 22:59:39.994045  1275 sgd_solver.cpp:106] Iteration 93750, lr = 0.0035
I0522 22:59:49.760530  1275 solver.cpp:237] Iteration 94125, loss = 1.15312
I0522 22:59:49.760706  1275 solver.cpp:253]     Train net output #0: loss = 1.15312 (* 1 = 1.15312 loss)
I0522 22:59:49.760720  1275 sgd_solver.cpp:106] Iteration 94125, lr = 0.0035
I0522 22:59:59.534169  1275 solver.cpp:237] Iteration 94500, loss = 1.0511
I0522 22:59:59.534220  1275 solver.cpp:253]     Train net output #0: loss = 1.0511 (* 1 = 1.0511 loss)
I0522 22:59:59.534237  1275 sgd_solver.cpp:106] Iteration 94500, lr = 0.0035
I0522 23:00:09.301229  1275 solver.cpp:237] Iteration 94875, loss = 1.27439
I0522 23:00:09.301265  1275 solver.cpp:253]     Train net output #0: loss = 1.27439 (* 1 = 1.27439 loss)
I0522 23:00:09.301280  1275 sgd_solver.cpp:106] Iteration 94875, lr = 0.0035
I0522 23:00:39.966833  1275 solver.cpp:237] Iteration 95250, loss = 1.23243
I0522 23:00:39.967023  1275 solver.cpp:253]     Train net output #0: loss = 1.23244 (* 1 = 1.23244 loss)
I0522 23:00:39.967039  1275 sgd_solver.cpp:106] Iteration 95250, lr = 0.0035
I0522 23:00:49.737606  1275 solver.cpp:237] Iteration 95625, loss = 1.3116
I0522 23:00:49.737651  1275 solver.cpp:253]     Train net output #0: loss = 1.3116 (* 1 = 1.3116 loss)
I0522 23:00:49.737668  1275 sgd_solver.cpp:106] Iteration 95625, lr = 0.0035
I0522 23:00:59.507560  1275 solver.cpp:237] Iteration 96000, loss = 1.45204
I0522 23:00:59.507596  1275 solver.cpp:253]     Train net output #0: loss = 1.45204 (* 1 = 1.45204 loss)
I0522 23:00:59.507611  1275 sgd_solver.cpp:106] Iteration 96000, lr = 0.0035
I0522 23:01:09.283053  1275 solver.cpp:237] Iteration 96375, loss = 1.26104
I0522 23:01:09.283107  1275 solver.cpp:253]     Train net output #0: loss = 1.26104 (* 1 = 1.26104 loss)
I0522 23:01:09.283120  1275 sgd_solver.cpp:106] Iteration 96375, lr = 0.0035
I0522 23:01:19.050979  1275 solver.cpp:237] Iteration 96750, loss = 1.45787
I0522 23:01:19.051143  1275 solver.cpp:253]     Train net output #0: loss = 1.45787 (* 1 = 1.45787 loss)
I0522 23:01:19.051157  1275 sgd_solver.cpp:106] Iteration 96750, lr = 0.0035
I0522 23:01:28.823248  1275 solver.cpp:237] Iteration 97125, loss = 0.893725
I0522 23:01:28.823283  1275 solver.cpp:253]     Train net output #0: loss = 0.893726 (* 1 = 0.893726 loss)
I0522 23:01:28.823299  1275 sgd_solver.cpp:106] Iteration 97125, lr = 0.0035
I0522 23:01:38.567553  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_97500.caffemodel
I0522 23:01:38.623847  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_97500.solverstate
I0522 23:01:38.649904  1275 solver.cpp:341] Iteration 97500, Testing net (#0)
I0522 23:02:27.197760  1275 solver.cpp:409]     Test net output #0: accuracy = 0.898018
I0522 23:02:27.197962  1275 solver.cpp:409]     Test net output #1: loss = 0.332082 (* 1 = 0.332082 loss)
I0522 23:02:48.085474  1275 solver.cpp:237] Iteration 97500, loss = 0.848249
I0522 23:02:48.085530  1275 solver.cpp:253]     Train net output #0: loss = 0.84825 (* 1 = 0.84825 loss)
I0522 23:02:48.085546  1275 sgd_solver.cpp:106] Iteration 97500, lr = 0.0035
I0522 23:02:57.994825  1275 solver.cpp:237] Iteration 97875, loss = 0.890341
I0522 23:02:57.995008  1275 solver.cpp:253]     Train net output #0: loss = 0.890341 (* 1 = 0.890341 loss)
I0522 23:02:57.995023  1275 sgd_solver.cpp:106] Iteration 97875, lr = 0.0035
I0522 23:03:07.894372  1275 solver.cpp:237] Iteration 98250, loss = 1.47576
I0522 23:03:07.894407  1275 solver.cpp:253]     Train net output #0: loss = 1.47576 (* 1 = 1.47576 loss)
I0522 23:03:07.894423  1275 sgd_solver.cpp:106] Iteration 98250, lr = 0.0035
I0522 23:03:17.796254  1275 solver.cpp:237] Iteration 98625, loss = 1.054
I0522 23:03:17.796301  1275 solver.cpp:253]     Train net output #0: loss = 1.054 (* 1 = 1.054 loss)
I0522 23:03:17.796317  1275 sgd_solver.cpp:106] Iteration 98625, lr = 0.0035
I0522 23:03:27.706971  1275 solver.cpp:237] Iteration 99000, loss = 1.29511
I0522 23:03:27.707007  1275 solver.cpp:253]     Train net output #0: loss = 1.29511 (* 1 = 1.29511 loss)
I0522 23:03:27.707020  1275 sgd_solver.cpp:106] Iteration 99000, lr = 0.0035
I0522 23:03:37.612982  1275 solver.cpp:237] Iteration 99375, loss = 1.0982
I0522 23:03:37.613143  1275 solver.cpp:253]     Train net output #0: loss = 1.0982 (* 1 = 1.0982 loss)
I0522 23:03:37.613157  1275 sgd_solver.cpp:106] Iteration 99375, lr = 0.0035
I0522 23:03:47.519500  1275 solver.cpp:237] Iteration 99750, loss = 1.01583
I0522 23:03:47.519552  1275 solver.cpp:253]     Train net output #0: loss = 1.01583 (* 1 = 1.01583 loss)
I0522 23:03:47.519567  1275 sgd_solver.cpp:106] Iteration 99750, lr = 0.0035
I0522 23:04:18.278509  1275 solver.cpp:237] Iteration 100125, loss = 1.0903
I0522 23:04:18.278699  1275 solver.cpp:253]     Train net output #0: loss = 1.0903 (* 1 = 1.0903 loss)
I0522 23:04:18.278715  1275 sgd_solver.cpp:106] Iteration 100125, lr = 0.0035
I0522 23:04:28.185343  1275 solver.cpp:237] Iteration 100500, loss = 1.47842
I0522 23:04:28.185377  1275 solver.cpp:253]     Train net output #0: loss = 1.47842 (* 1 = 1.47842 loss)
I0522 23:04:28.185392  1275 sgd_solver.cpp:106] Iteration 100500, lr = 0.0035
I0522 23:04:38.091017  1275 solver.cpp:237] Iteration 100875, loss = 1.23572
I0522 23:04:38.091058  1275 solver.cpp:253]     Train net output #0: loss = 1.23572 (* 1 = 1.23572 loss)
I0522 23:04:38.091076  1275 sgd_solver.cpp:106] Iteration 100875, lr = 0.0035
I0522 23:04:47.969372  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_101250.caffemodel
I0522 23:04:48.025187  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_101250.solverstate
I0522 23:04:48.058809  1275 solver.cpp:237] Iteration 101250, loss = 1.14785
I0522 23:04:48.058857  1275 solver.cpp:253]     Train net output #0: loss = 1.14785 (* 1 = 1.14785 loss)
I0522 23:04:48.058873  1275 sgd_solver.cpp:106] Iteration 101250, lr = 0.0035
I0522 23:04:57.963654  1275 solver.cpp:237] Iteration 101625, loss = 0.973948
I0522 23:04:57.963841  1275 solver.cpp:253]     Train net output #0: loss = 0.973949 (* 1 = 0.973949 loss)
I0522 23:04:57.963855  1275 sgd_solver.cpp:106] Iteration 101625, lr = 0.0035
I0522 23:05:07.866488  1275 solver.cpp:237] Iteration 102000, loss = 1.21555
I0522 23:05:07.866524  1275 solver.cpp:253]     Train net output #0: loss = 1.21555 (* 1 = 1.21555 loss)
I0522 23:05:07.866539  1275 sgd_solver.cpp:106] Iteration 102000, lr = 0.0035
I0522 23:05:17.769600  1275 solver.cpp:237] Iteration 102375, loss = 0.974628
I0522 23:05:17.769635  1275 solver.cpp:253]     Train net output #0: loss = 0.974629 (* 1 = 0.974629 loss)
I0522 23:05:17.769650  1275 sgd_solver.cpp:106] Iteration 102375, lr = 0.0035
I0522 23:05:48.563128  1275 solver.cpp:237] Iteration 102750, loss = 0.912194
I0522 23:05:48.563325  1275 solver.cpp:253]     Train net output #0: loss = 0.912195 (* 1 = 0.912195 loss)
I0522 23:05:48.563343  1275 sgd_solver.cpp:106] Iteration 102750, lr = 0.0035
I0522 23:05:58.466123  1275 solver.cpp:237] Iteration 103125, loss = 1.12332
I0522 23:05:58.466157  1275 solver.cpp:253]     Train net output #0: loss = 1.12332 (* 1 = 1.12332 loss)
I0522 23:05:58.466173  1275 sgd_solver.cpp:106] Iteration 103125, lr = 0.0035
I0522 23:06:08.365587  1275 solver.cpp:237] Iteration 103500, loss = 1.02091
I0522 23:06:08.365639  1275 solver.cpp:253]     Train net output #0: loss = 1.02091 (* 1 = 1.02091 loss)
I0522 23:06:08.365654  1275 sgd_solver.cpp:106] Iteration 103500, lr = 0.0035
I0522 23:06:18.272423  1275 solver.cpp:237] Iteration 103875, loss = 1.27537
I0522 23:06:18.272460  1275 solver.cpp:253]     Train net output #0: loss = 1.27537 (* 1 = 1.27537 loss)
I0522 23:06:18.272475  1275 sgd_solver.cpp:106] Iteration 103875, lr = 0.0035
I0522 23:06:28.183193  1275 solver.cpp:237] Iteration 104250, loss = 1.08181
I0522 23:06:28.183362  1275 solver.cpp:253]     Train net output #0: loss = 1.08181 (* 1 = 1.08181 loss)
I0522 23:06:28.183375  1275 sgd_solver.cpp:106] Iteration 104250, lr = 0.0035
I0522 23:06:38.087545  1275 solver.cpp:237] Iteration 104625, loss = 1.15731
I0522 23:06:38.087592  1275 solver.cpp:253]     Train net output #0: loss = 1.15731 (* 1 = 1.15731 loss)
I0522 23:06:38.087609  1275 sgd_solver.cpp:106] Iteration 104625, lr = 0.0035
I0522 23:06:47.967325  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_105000.caffemodel
I0522 23:06:48.023720  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_105000.solverstate
I0522 23:06:48.048712  1275 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 23:07:57.490476  1275 solver.cpp:409]     Test net output #0: accuracy = 0.896434
I0522 23:07:57.490664  1275 solver.cpp:409]     Test net output #1: loss = 0.3332 (* 1 = 0.3332 loss)
I0522 23:08:18.377920  1275 solver.cpp:237] Iteration 105000, loss = 1.38681
I0522 23:08:18.377975  1275 solver.cpp:253]     Train net output #0: loss = 1.38681 (* 1 = 1.38681 loss)
I0522 23:08:18.377990  1275 sgd_solver.cpp:106] Iteration 105000, lr = 0.0035
I0522 23:08:28.207365  1275 solver.cpp:237] Iteration 105375, loss = 1.18947
I0522 23:08:28.207535  1275 solver.cpp:253]     Train net output #0: loss = 1.18948 (* 1 = 1.18948 loss)
I0522 23:08:28.207547  1275 sgd_solver.cpp:106] Iteration 105375, lr = 0.0035
I0522 23:08:38.024659  1275 solver.cpp:237] Iteration 105750, loss = 1.12053
I0522 23:08:38.024693  1275 solver.cpp:253]     Train net output #0: loss = 1.12053 (* 1 = 1.12053 loss)
I0522 23:08:38.024709  1275 sgd_solver.cpp:106] Iteration 105750, lr = 0.0035
I0522 23:08:47.844946  1275 solver.cpp:237] Iteration 106125, loss = 1.07228
I0522 23:08:47.844995  1275 solver.cpp:253]     Train net output #0: loss = 1.07228 (* 1 = 1.07228 loss)
I0522 23:08:47.845010  1275 sgd_solver.cpp:106] Iteration 106125, lr = 0.0035
I0522 23:08:57.668611  1275 solver.cpp:237] Iteration 106500, loss = 1.19359
I0522 23:08:57.668645  1275 solver.cpp:253]     Train net output #0: loss = 1.19359 (* 1 = 1.19359 loss)
I0522 23:08:57.668660  1275 sgd_solver.cpp:106] Iteration 106500, lr = 0.0035
I0522 23:09:07.493449  1275 solver.cpp:237] Iteration 106875, loss = 0.893547
I0522 23:09:07.493623  1275 solver.cpp:253]     Train net output #0: loss = 0.893547 (* 1 = 0.893547 loss)
I0522 23:09:07.493638  1275 sgd_solver.cpp:106] Iteration 106875, lr = 0.0035
I0522 23:09:17.323971  1275 solver.cpp:237] Iteration 107250, loss = 1.1062
I0522 23:09:17.324005  1275 solver.cpp:253]     Train net output #0: loss = 1.1062 (* 1 = 1.1062 loss)
I0522 23:09:17.324023  1275 sgd_solver.cpp:106] Iteration 107250, lr = 0.0035
I0522 23:09:48.052466  1275 solver.cpp:237] Iteration 107625, loss = 1.13615
I0522 23:09:48.052669  1275 solver.cpp:253]     Train net output #0: loss = 1.13615 (* 1 = 1.13615 loss)
I0522 23:09:48.052683  1275 sgd_solver.cpp:106] Iteration 107625, lr = 0.0035
I0522 23:09:57.878108  1275 solver.cpp:237] Iteration 108000, loss = 1.12066
I0522 23:09:57.878155  1275 solver.cpp:253]     Train net output #0: loss = 1.12066 (* 1 = 1.12066 loss)
I0522 23:09:57.878171  1275 sgd_solver.cpp:106] Iteration 108000, lr = 0.0035
I0522 23:10:07.696400  1275 solver.cpp:237] Iteration 108375, loss = 1.20356
I0522 23:10:07.696436  1275 solver.cpp:253]     Train net output #0: loss = 1.20356 (* 1 = 1.20356 loss)
I0522 23:10:07.696450  1275 sgd_solver.cpp:106] Iteration 108375, lr = 0.0035
I0522 23:10:17.497086  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_108750.caffemodel
I0522 23:10:17.554752  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_108750.solverstate
I0522 23:10:17.590610  1275 solver.cpp:237] Iteration 108750, loss = 1.5043
I0522 23:10:17.590659  1275 solver.cpp:253]     Train net output #0: loss = 1.5043 (* 1 = 1.5043 loss)
I0522 23:10:17.590678  1275 sgd_solver.cpp:106] Iteration 108750, lr = 0.0035
I0522 23:10:27.415649  1275 solver.cpp:237] Iteration 109125, loss = 1.30135
I0522 23:10:27.415843  1275 solver.cpp:253]     Train net output #0: loss = 1.30135 (* 1 = 1.30135 loss)
I0522 23:10:27.415856  1275 sgd_solver.cpp:106] Iteration 109125, lr = 0.0035
I0522 23:10:37.239436  1275 solver.cpp:237] Iteration 109500, loss = 1.53453
I0522 23:10:37.239470  1275 solver.cpp:253]     Train net output #0: loss = 1.53453 (* 1 = 1.53453 loss)
I0522 23:10:37.239488  1275 sgd_solver.cpp:106] Iteration 109500, lr = 0.0035
I0522 23:10:47.070111  1275 solver.cpp:237] Iteration 109875, loss = 1.35309
I0522 23:10:47.070161  1275 solver.cpp:253]     Train net output #0: loss = 1.35309 (* 1 = 1.35309 loss)
I0522 23:10:47.070178  1275 sgd_solver.cpp:106] Iteration 109875, lr = 0.0035
I0522 23:11:17.771608  1275 solver.cpp:237] Iteration 110250, loss = 1.16894
I0522 23:11:17.771801  1275 solver.cpp:253]     Train net output #0: loss = 1.16895 (* 1 = 1.16895 loss)
I0522 23:11:17.771816  1275 sgd_solver.cpp:106] Iteration 110250, lr = 0.0035
I0522 23:11:27.596510  1275 solver.cpp:237] Iteration 110625, loss = 1.46189
I0522 23:11:27.596545  1275 solver.cpp:253]     Train net output #0: loss = 1.46189 (* 1 = 1.46189 loss)
I0522 23:11:27.596560  1275 sgd_solver.cpp:106] Iteration 110625, lr = 0.0035
I0522 23:11:37.439667  1275 solver.cpp:237] Iteration 111000, loss = 1.15355
I0522 23:11:37.439709  1275 solver.cpp:253]     Train net output #0: loss = 1.15355 (* 1 = 1.15355 loss)
I0522 23:11:37.439731  1275 sgd_solver.cpp:106] Iteration 111000, lr = 0.0035
I0522 23:11:47.302192  1275 solver.cpp:237] Iteration 111375, loss = 1.22932
I0522 23:11:47.302228  1275 solver.cpp:253]     Train net output #0: loss = 1.22933 (* 1 = 1.22933 loss)
I0522 23:11:47.302242  1275 sgd_solver.cpp:106] Iteration 111375, lr = 0.0035
I0522 23:11:57.171113  1275 solver.cpp:237] Iteration 111750, loss = 1.04334
I0522 23:11:57.171279  1275 solver.cpp:253]     Train net output #0: loss = 1.04334 (* 1 = 1.04334 loss)
I0522 23:11:57.171293  1275 sgd_solver.cpp:106] Iteration 111750, lr = 0.0035
I0522 23:12:07.033375  1275 solver.cpp:237] Iteration 112125, loss = 1.23824
I0522 23:12:07.033418  1275 solver.cpp:253]     Train net output #0: loss = 1.23824 (* 1 = 1.23824 loss)
I0522 23:12:07.033433  1275 sgd_solver.cpp:106] Iteration 112125, lr = 0.0035
I0522 23:12:16.877207  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_112500.caffemodel
I0522 23:12:16.934839  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_112500.solverstate
I0522 23:12:16.962291  1275 solver.cpp:341] Iteration 112500, Testing net (#0)
I0522 23:13:05.180841  1275 solver.cpp:409]     Test net output #0: accuracy = 0.898739
I0522 23:13:05.181042  1275 solver.cpp:409]     Test net output #1: loss = 0.319288 (* 1 = 0.319288 loss)
I0522 23:13:26.084305  1275 solver.cpp:237] Iteration 112500, loss = 1.13823
I0522 23:13:26.084362  1275 solver.cpp:253]     Train net output #0: loss = 1.13823 (* 1 = 1.13823 loss)
I0522 23:13:26.084377  1275 sgd_solver.cpp:106] Iteration 112500, lr = 0.0035
I0522 23:13:35.763720  1275 solver.cpp:237] Iteration 112875, loss = 1.01144
I0522 23:13:35.763893  1275 solver.cpp:253]     Train net output #0: loss = 1.01144 (* 1 = 1.01144 loss)
I0522 23:13:35.763907  1275 sgd_solver.cpp:106] Iteration 112875, lr = 0.0035
I0522 23:13:45.443624  1275 solver.cpp:237] Iteration 113250, loss = 0.849433
I0522 23:13:45.443670  1275 solver.cpp:253]     Train net output #0: loss = 0.849434 (* 1 = 0.849434 loss)
I0522 23:13:45.443686  1275 sgd_solver.cpp:106] Iteration 113250, lr = 0.0035
I0522 23:13:55.123325  1275 solver.cpp:237] Iteration 113625, loss = 1.17036
I0522 23:13:55.123360  1275 solver.cpp:253]     Train net output #0: loss = 1.17036 (* 1 = 1.17036 loss)
I0522 23:13:55.123375  1275 sgd_solver.cpp:106] Iteration 113625, lr = 0.0035
I0522 23:14:04.803264  1275 solver.cpp:237] Iteration 114000, loss = 1.1264
I0522 23:14:04.803313  1275 solver.cpp:253]     Train net output #0: loss = 1.1264 (* 1 = 1.1264 loss)
I0522 23:14:04.803329  1275 sgd_solver.cpp:106] Iteration 114000, lr = 0.0035
I0522 23:14:14.492291  1275 solver.cpp:237] Iteration 114375, loss = 1.31003
I0522 23:14:14.492467  1275 solver.cpp:253]     Train net output #0: loss = 1.31003 (* 1 = 1.31003 loss)
I0522 23:14:14.492481  1275 sgd_solver.cpp:106] Iteration 114375, lr = 0.0035
I0522 23:14:24.170596  1275 solver.cpp:237] Iteration 114750, loss = 1.30129
I0522 23:14:24.170630  1275 solver.cpp:253]     Train net output #0: loss = 1.30129 (* 1 = 1.30129 loss)
I0522 23:14:24.170646  1275 sgd_solver.cpp:106] Iteration 114750, lr = 0.0035
I0522 23:14:54.727761  1275 solver.cpp:237] Iteration 115125, loss = 1.12935
I0522 23:14:54.727952  1275 solver.cpp:253]     Train net output #0: loss = 1.12935 (* 1 = 1.12935 loss)
I0522 23:14:54.727968  1275 sgd_solver.cpp:106] Iteration 115125, lr = 0.0035
I0522 23:15:04.408195  1275 solver.cpp:237] Iteration 115500, loss = 1.15704
I0522 23:15:04.408228  1275 solver.cpp:253]     Train net output #0: loss = 1.15704 (* 1 = 1.15704 loss)
I0522 23:15:04.408244  1275 sgd_solver.cpp:106] Iteration 115500, lr = 0.0035
I0522 23:15:14.090430  1275 solver.cpp:237] Iteration 115875, loss = 1.58589
I0522 23:15:14.090466  1275 solver.cpp:253]     Train net output #0: loss = 1.5859 (* 1 = 1.5859 loss)
I0522 23:15:14.090481  1275 sgd_solver.cpp:106] Iteration 115875, lr = 0.0035
I0522 23:15:23.752125  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_116250.caffemodel
I0522 23:15:23.807626  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_116250.solverstate
I0522 23:15:23.841481  1275 solver.cpp:237] Iteration 116250, loss = 0.94224
I0522 23:15:23.841527  1275 solver.cpp:253]     Train net output #0: loss = 0.94224 (* 1 = 0.94224 loss)
I0522 23:15:23.841547  1275 sgd_solver.cpp:106] Iteration 116250, lr = 0.0035
I0522 23:15:33.536394  1275 solver.cpp:237] Iteration 116625, loss = 1.25388
I0522 23:15:33.536564  1275 solver.cpp:253]     Train net output #0: loss = 1.25388 (* 1 = 1.25388 loss)
I0522 23:15:33.536577  1275 sgd_solver.cpp:106] Iteration 116625, lr = 0.0035
I0522 23:15:43.227535  1275 solver.cpp:237] Iteration 117000, loss = 1.11768
I0522 23:15:43.227569  1275 solver.cpp:253]     Train net output #0: loss = 1.11768 (* 1 = 1.11768 loss)
I0522 23:15:43.227583  1275 sgd_solver.cpp:106] Iteration 117000, lr = 0.0035
I0522 23:15:52.926923  1275 solver.cpp:237] Iteration 117375, loss = 1.11272
I0522 23:15:52.926964  1275 solver.cpp:253]     Train net output #0: loss = 1.11272 (* 1 = 1.11272 loss)
I0522 23:15:52.926983  1275 sgd_solver.cpp:106] Iteration 117375, lr = 0.0035
I0522 23:16:23.506077  1275 solver.cpp:237] Iteration 117750, loss = 1.07172
I0522 23:16:23.506276  1275 solver.cpp:253]     Train net output #0: loss = 1.07172 (* 1 = 1.07172 loss)
I0522 23:16:23.506292  1275 sgd_solver.cpp:106] Iteration 117750, lr = 0.0035
I0522 23:16:33.200484  1275 solver.cpp:237] Iteration 118125, loss = 1.13326
I0522 23:16:33.200518  1275 solver.cpp:253]     Train net output #0: loss = 1.13326 (* 1 = 1.13326 loss)
I0522 23:16:33.200533  1275 sgd_solver.cpp:106] Iteration 118125, lr = 0.0035
I0522 23:16:42.899072  1275 solver.cpp:237] Iteration 118500, loss = 1.34008
I0522 23:16:42.899114  1275 solver.cpp:253]     Train net output #0: loss = 1.34008 (* 1 = 1.34008 loss)
I0522 23:16:42.899132  1275 sgd_solver.cpp:106] Iteration 118500, lr = 0.0035
I0522 23:16:52.595135  1275 solver.cpp:237] Iteration 118875, loss = 0.906482
I0522 23:16:52.595172  1275 solver.cpp:253]     Train net output #0: loss = 0.906483 (* 1 = 0.906483 loss)
I0522 23:16:52.595186  1275 sgd_solver.cpp:106] Iteration 118875, lr = 0.0035
I0522 23:17:02.301736  1275 solver.cpp:237] Iteration 119250, loss = 1.21999
I0522 23:17:02.301936  1275 solver.cpp:253]     Train net output #0: loss = 1.21999 (* 1 = 1.21999 loss)
I0522 23:17:02.301951  1275 sgd_solver.cpp:106] Iteration 119250, lr = 0.0035
I0522 23:17:12.004878  1275 solver.cpp:237] Iteration 119625, loss = 0.905159
I0522 23:17:12.004912  1275 solver.cpp:253]     Train net output #0: loss = 0.90516 (* 1 = 0.90516 loss)
I0522 23:17:12.004928  1275 sgd_solver.cpp:106] Iteration 119625, lr = 0.0035
I0522 23:17:21.673738  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_120000.caffemodel
I0522 23:17:21.730355  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_120000.solverstate
I0522 23:17:21.755455  1275 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 23:18:31.237565  1275 solver.cpp:409]     Test net output #0: accuracy = 0.896532
I0522 23:18:31.237756  1275 solver.cpp:409]     Test net output #1: loss = 0.339188 (* 1 = 0.339188 loss)
I0522 23:18:52.166689  1275 solver.cpp:237] Iteration 120000, loss = 0.743559
I0522 23:18:52.166748  1275 solver.cpp:253]     Train net output #0: loss = 0.74356 (* 1 = 0.74356 loss)
I0522 23:18:52.166762  1275 sgd_solver.cpp:106] Iteration 120000, lr = 0.0035
I0522 23:19:01.926972  1275 solver.cpp:237] Iteration 120375, loss = 1.45527
I0522 23:19:01.927147  1275 solver.cpp:253]     Train net output #0: loss = 1.45527 (* 1 = 1.45527 loss)
I0522 23:19:01.927160  1275 sgd_solver.cpp:106] Iteration 120375, lr = 0.0035
I0522 23:19:11.683594  1275 solver.cpp:237] Iteration 120750, loss = 0.838953
I0522 23:19:11.683645  1275 solver.cpp:253]     Train net output #0: loss = 0.838954 (* 1 = 0.838954 loss)
I0522 23:19:11.683660  1275 sgd_solver.cpp:106] Iteration 120750, lr = 0.0035
I0522 23:19:21.438549  1275 solver.cpp:237] Iteration 121125, loss = 1.1137
I0522 23:19:21.438597  1275 solver.cpp:253]     Train net output #0: loss = 1.1137 (* 1 = 1.1137 loss)
I0522 23:19:21.438611  1275 sgd_solver.cpp:106] Iteration 121125, lr = 0.0035
I0522 23:19:31.200601  1275 solver.cpp:237] Iteration 121500, loss = 0.962061
I0522 23:19:31.200645  1275 solver.cpp:253]     Train net output #0: loss = 0.962062 (* 1 = 0.962062 loss)
I0522 23:19:31.200662  1275 sgd_solver.cpp:106] Iteration 121500, lr = 0.0035
I0522 23:19:40.952177  1275 solver.cpp:237] Iteration 121875, loss = 1.3592
I0522 23:19:40.952358  1275 solver.cpp:253]     Train net output #0: loss = 1.3592 (* 1 = 1.3592 loss)
I0522 23:19:40.952371  1275 sgd_solver.cpp:106] Iteration 121875, lr = 0.0035
I0522 23:19:50.699430  1275 solver.cpp:237] Iteration 122250, loss = 1.03883
I0522 23:19:50.699465  1275 solver.cpp:253]     Train net output #0: loss = 1.03883 (* 1 = 1.03883 loss)
I0522 23:19:50.699481  1275 sgd_solver.cpp:106] Iteration 122250, lr = 0.0035
I0522 23:20:21.368119  1275 solver.cpp:237] Iteration 122625, loss = 1.21482
I0522 23:20:21.368311  1275 solver.cpp:253]     Train net output #0: loss = 1.21482 (* 1 = 1.21482 loss)
I0522 23:20:21.368325  1275 sgd_solver.cpp:106] Iteration 122625, lr = 0.0035
I0522 23:20:31.118918  1275 solver.cpp:237] Iteration 123000, loss = 1.05266
I0522 23:20:31.118952  1275 solver.cpp:253]     Train net output #0: loss = 1.05266 (* 1 = 1.05266 loss)
I0522 23:20:31.118969  1275 sgd_solver.cpp:106] Iteration 123000, lr = 0.0035
I0522 23:20:40.872040  1275 solver.cpp:237] Iteration 123375, loss = 1.22378
I0522 23:20:40.872076  1275 solver.cpp:253]     Train net output #0: loss = 1.22378 (* 1 = 1.22378 loss)
I0522 23:20:40.872090  1275 sgd_solver.cpp:106] Iteration 123375, lr = 0.0035
I0522 23:20:50.607502  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_123750.caffemodel
I0522 23:20:50.664031  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_123750.solverstate
I0522 23:20:50.697579  1275 solver.cpp:237] Iteration 123750, loss = 1.05576
I0522 23:20:50.697628  1275 solver.cpp:253]     Train net output #0: loss = 1.05577 (* 1 = 1.05577 loss)
I0522 23:20:50.697643  1275 sgd_solver.cpp:106] Iteration 123750, lr = 0.0035
I0522 23:21:00.455828  1275 solver.cpp:237] Iteration 124125, loss = 1.1752
I0522 23:21:00.456001  1275 solver.cpp:253]     Train net output #0: loss = 1.1752 (* 1 = 1.1752 loss)
I0522 23:21:00.456014  1275 sgd_solver.cpp:106] Iteration 124125, lr = 0.0035
I0522 23:21:10.214208  1275 solver.cpp:237] Iteration 124500, loss = 0.807249
I0522 23:21:10.214259  1275 solver.cpp:253]     Train net output #0: loss = 0.80725 (* 1 = 0.80725 loss)
I0522 23:21:10.214273  1275 sgd_solver.cpp:106] Iteration 124500, lr = 0.0035
I0522 23:21:19.967103  1275 solver.cpp:237] Iteration 124875, loss = 1.07598
I0522 23:21:19.967139  1275 solver.cpp:253]     Train net output #0: loss = 1.07598 (* 1 = 1.07598 loss)
I0522 23:21:19.967154  1275 sgd_solver.cpp:106] Iteration 124875, lr = 0.0035
I0522 23:21:50.673934  1275 solver.cpp:237] Iteration 125250, loss = 0.974171
I0522 23:21:50.674132  1275 solver.cpp:253]     Train net output #0: loss = 0.974172 (* 1 = 0.974172 loss)
I0522 23:21:50.674147  1275 sgd_solver.cpp:106] Iteration 125250, lr = 0.0035
I0522 23:22:00.437129  1275 solver.cpp:237] Iteration 125625, loss = 1.09572
I0522 23:22:00.437175  1275 solver.cpp:253]     Train net output #0: loss = 1.09572 (* 1 = 1.09572 loss)
I0522 23:22:00.437191  1275 sgd_solver.cpp:106] Iteration 125625, lr = 0.0035
I0522 23:22:10.192921  1275 solver.cpp:237] Iteration 126000, loss = 1.023
I0522 23:22:10.192956  1275 solver.cpp:253]     Train net output #0: loss = 1.023 (* 1 = 1.023 loss)
I0522 23:22:10.192971  1275 sgd_solver.cpp:106] Iteration 126000, lr = 0.0035
I0522 23:22:19.948159  1275 solver.cpp:237] Iteration 126375, loss = 1.04211
I0522 23:22:19.948194  1275 solver.cpp:253]     Train net output #0: loss = 1.04211 (* 1 = 1.04211 loss)
I0522 23:22:19.948210  1275 sgd_solver.cpp:106] Iteration 126375, lr = 0.0035
I0522 23:22:29.699357  1275 solver.cpp:237] Iteration 126750, loss = 1.451
I0522 23:22:29.699551  1275 solver.cpp:253]     Train net output #0: loss = 1.451 (* 1 = 1.451 loss)
I0522 23:22:29.699565  1275 sgd_solver.cpp:106] Iteration 126750, lr = 0.0035
I0522 23:22:39.458048  1275 solver.cpp:237] Iteration 127125, loss = 1.03924
I0522 23:22:39.458083  1275 solver.cpp:253]     Train net output #0: loss = 1.03924 (* 1 = 1.03924 loss)
I0522 23:22:39.458099  1275 sgd_solver.cpp:106] Iteration 127125, lr = 0.0035
I0522 23:22:49.187307  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_127500.caffemodel
I0522 23:22:49.244006  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_127500.solverstate
I0522 23:22:49.269832  1275 solver.cpp:341] Iteration 127500, Testing net (#0)
I0522 23:23:37.862973  1275 solver.cpp:409]     Test net output #0: accuracy = 0.896013
I0522 23:23:37.863168  1275 solver.cpp:409]     Test net output #1: loss = 0.347778 (* 1 = 0.347778 loss)
I0522 23:23:58.794517  1275 solver.cpp:237] Iteration 127500, loss = 1.03822
I0522 23:23:58.794574  1275 solver.cpp:253]     Train net output #0: loss = 1.03822 (* 1 = 1.03822 loss)
I0522 23:23:58.794589  1275 sgd_solver.cpp:106] Iteration 127500, lr = 0.0035
I0522 23:24:08.681236  1275 solver.cpp:237] Iteration 127875, loss = 1.04322
I0522 23:24:08.681421  1275 solver.cpp:253]     Train net output #0: loss = 1.04322 (* 1 = 1.04322 loss)
I0522 23:24:08.681435  1275 sgd_solver.cpp:106] Iteration 127875, lr = 0.0035
I0522 23:24:18.560853  1275 solver.cpp:237] Iteration 128250, loss = 1.47267
I0522 23:24:18.560889  1275 solver.cpp:253]     Train net output #0: loss = 1.47267 (* 1 = 1.47267 loss)
I0522 23:24:18.560904  1275 sgd_solver.cpp:106] Iteration 128250, lr = 0.0035
I0522 23:24:28.435181  1275 solver.cpp:237] Iteration 128625, loss = 1.21946
I0522 23:24:28.435225  1275 solver.cpp:253]     Train net output #0: loss = 1.21946 (* 1 = 1.21946 loss)
I0522 23:24:28.435245  1275 sgd_solver.cpp:106] Iteration 128625, lr = 0.0035
I0522 23:24:38.310443  1275 solver.cpp:237] Iteration 129000, loss = 1.34252
I0522 23:24:38.310477  1275 solver.cpp:253]     Train net output #0: loss = 1.34252 (* 1 = 1.34252 loss)
I0522 23:24:38.310492  1275 sgd_solver.cpp:106] Iteration 129000, lr = 0.0035
I0522 23:24:48.188808  1275 solver.cpp:237] Iteration 129375, loss = 1.32742
I0522 23:24:48.188977  1275 solver.cpp:253]     Train net output #0: loss = 1.32742 (* 1 = 1.32742 loss)
I0522 23:24:48.188990  1275 sgd_solver.cpp:106] Iteration 129375, lr = 0.0035
I0522 23:24:58.066637  1275 solver.cpp:237] Iteration 129750, loss = 0.935238
I0522 23:24:58.066681  1275 solver.cpp:253]     Train net output #0: loss = 0.935239 (* 1 = 0.935239 loss)
I0522 23:24:58.066699  1275 sgd_solver.cpp:106] Iteration 129750, lr = 0.0035
I0522 23:25:28.857033  1275 solver.cpp:237] Iteration 130125, loss = 1.29815
I0522 23:25:28.857230  1275 solver.cpp:253]     Train net output #0: loss = 1.29815 (* 1 = 1.29815 loss)
I0522 23:25:28.857244  1275 sgd_solver.cpp:106] Iteration 130125, lr = 0.0035
I0522 23:25:38.743075  1275 solver.cpp:237] Iteration 130500, loss = 1.19187
I0522 23:25:38.743110  1275 solver.cpp:253]     Train net output #0: loss = 1.19187 (* 1 = 1.19187 loss)
I0522 23:25:38.743125  1275 sgd_solver.cpp:106] Iteration 130500, lr = 0.0035
I0522 23:25:48.618968  1275 solver.cpp:237] Iteration 130875, loss = 1.13886
I0522 23:25:48.619012  1275 solver.cpp:253]     Train net output #0: loss = 1.13886 (* 1 = 1.13886 loss)
I0522 23:25:48.619030  1275 sgd_solver.cpp:106] Iteration 130875, lr = 0.0035
I0522 23:25:58.470036  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_131250.caffemodel
I0522 23:25:58.528451  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_131250.solverstate
I0522 23:25:58.563884  1275 solver.cpp:237] Iteration 131250, loss = 1.14168
I0522 23:25:58.563932  1275 solver.cpp:253]     Train net output #0: loss = 1.14168 (* 1 = 1.14168 loss)
I0522 23:25:58.563947  1275 sgd_solver.cpp:106] Iteration 131250, lr = 0.0035
I0522 23:26:08.434300  1275 solver.cpp:237] Iteration 131625, loss = 1.31008
I0522 23:26:08.434502  1275 solver.cpp:253]     Train net output #0: loss = 1.31008 (* 1 = 1.31008 loss)
I0522 23:26:08.434517  1275 sgd_solver.cpp:106] Iteration 131625, lr = 0.0035
I0522 23:26:18.314362  1275 solver.cpp:237] Iteration 132000, loss = 0.959593
I0522 23:26:18.314396  1275 solver.cpp:253]     Train net output #0: loss = 0.959593 (* 1 = 0.959593 loss)
I0522 23:26:18.314411  1275 sgd_solver.cpp:106] Iteration 132000, lr = 0.0035
I0522 23:26:28.187847  1275 solver.cpp:237] Iteration 132375, loss = 1.00434
I0522 23:26:28.187882  1275 solver.cpp:253]     Train net output #0: loss = 1.00434 (* 1 = 1.00434 loss)
I0522 23:26:28.187896  1275 sgd_solver.cpp:106] Iteration 132375, lr = 0.0035
I0522 23:26:58.965797  1275 solver.cpp:237] Iteration 132750, loss = 0.882591
I0522 23:26:58.966015  1275 solver.cpp:253]     Train net output #0: loss = 0.882591 (* 1 = 0.882591 loss)
I0522 23:26:58.966029  1275 sgd_solver.cpp:106] Iteration 132750, lr = 0.0035
I0522 23:27:08.846026  1275 solver.cpp:237] Iteration 133125, loss = 1.1387
I0522 23:27:08.846061  1275 solver.cpp:253]     Train net output #0: loss = 1.1387 (* 1 = 1.1387 loss)
I0522 23:27:08.846076  1275 sgd_solver.cpp:106] Iteration 133125, lr = 0.0035
I0522 23:27:18.715559  1275 solver.cpp:237] Iteration 133500, loss = 1.03805
I0522 23:27:18.715595  1275 solver.cpp:253]     Train net output #0: loss = 1.03805 (* 1 = 1.03805 loss)
I0522 23:27:18.715610  1275 sgd_solver.cpp:106] Iteration 133500, lr = 0.0035
I0522 23:27:28.591361  1275 solver.cpp:237] Iteration 133875, loss = 0.954541
I0522 23:27:28.591406  1275 solver.cpp:253]     Train net output #0: loss = 0.954542 (* 1 = 0.954542 loss)
I0522 23:27:28.591420  1275 sgd_solver.cpp:106] Iteration 133875, lr = 0.0035
I0522 23:27:38.460870  1275 solver.cpp:237] Iteration 134250, loss = 0.919794
I0522 23:27:38.461042  1275 solver.cpp:253]     Train net output #0: loss = 0.919794 (* 1 = 0.919794 loss)
I0522 23:27:38.461055  1275 sgd_solver.cpp:106] Iteration 134250, lr = 0.0035
I0522 23:27:48.336362  1275 solver.cpp:237] Iteration 134625, loss = 0.821629
I0522 23:27:48.336397  1275 solver.cpp:253]     Train net output #0: loss = 0.821629 (* 1 = 0.821629 loss)
I0522 23:27:48.336410  1275 sgd_solver.cpp:106] Iteration 134625, lr = 0.0035
I0522 23:27:58.189903  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_135000.caffemodel
I0522 23:27:58.248730  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_135000.solverstate
I0522 23:27:58.276453  1275 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 23:29:07.840266  1275 solver.cpp:409]     Test net output #0: accuracy = 0.901113
I0522 23:29:07.840459  1275 solver.cpp:409]     Test net output #1: loss = 0.308829 (* 1 = 0.308829 loss)
I0522 23:29:28.775580  1275 solver.cpp:237] Iteration 135000, loss = 1.12677
I0522 23:29:28.775637  1275 solver.cpp:253]     Train net output #0: loss = 1.12677 (* 1 = 1.12677 loss)
I0522 23:29:28.775652  1275 sgd_solver.cpp:106] Iteration 135000, lr = 0.0035
I0522 23:29:38.725716  1275 solver.cpp:237] Iteration 135375, loss = 0.980745
I0522 23:29:38.725899  1275 solver.cpp:253]     Train net output #0: loss = 0.980745 (* 1 = 0.980745 loss)
I0522 23:29:38.725914  1275 sgd_solver.cpp:106] Iteration 135375, lr = 0.0035
I0522 23:29:48.680142  1275 solver.cpp:237] Iteration 135750, loss = 1.09433
I0522 23:29:48.680176  1275 solver.cpp:253]     Train net output #0: loss = 1.09433 (* 1 = 1.09433 loss)
I0522 23:29:48.680191  1275 sgd_solver.cpp:106] Iteration 135750, lr = 0.0035
I0522 23:29:58.636207  1275 solver.cpp:237] Iteration 136125, loss = 1.16975
I0522 23:29:58.636253  1275 solver.cpp:253]     Train net output #0: loss = 1.16975 (* 1 = 1.16975 loss)
I0522 23:29:58.636270  1275 sgd_solver.cpp:106] Iteration 136125, lr = 0.0035
I0522 23:30:08.582674  1275 solver.cpp:237] Iteration 136500, loss = 1.35154
I0522 23:30:08.582708  1275 solver.cpp:253]     Train net output #0: loss = 1.35154 (* 1 = 1.35154 loss)
I0522 23:30:08.582722  1275 sgd_solver.cpp:106] Iteration 136500, lr = 0.0035
I0522 23:30:18.541703  1275 solver.cpp:237] Iteration 136875, loss = 1.11946
I0522 23:30:18.541903  1275 solver.cpp:253]     Train net output #0: loss = 1.11946 (* 1 = 1.11946 loss)
I0522 23:30:18.541918  1275 sgd_solver.cpp:106] Iteration 136875, lr = 0.0035
I0522 23:30:28.498219  1275 solver.cpp:237] Iteration 137250, loss = 0.926557
I0522 23:30:28.498253  1275 solver.cpp:253]     Train net output #0: loss = 0.926558 (* 1 = 0.926558 loss)
I0522 23:30:28.498270  1275 sgd_solver.cpp:106] Iteration 137250, lr = 0.0035
I0522 23:30:59.353898  1275 solver.cpp:237] Iteration 137625, loss = 1.27555
I0522 23:30:59.354100  1275 solver.cpp:253]     Train net output #0: loss = 1.27556 (* 1 = 1.27556 loss)
I0522 23:30:59.354117  1275 sgd_solver.cpp:106] Iteration 137625, lr = 0.0035
I0522 23:31:09.315944  1275 solver.cpp:237] Iteration 138000, loss = 0.790676
I0522 23:31:09.315999  1275 solver.cpp:253]     Train net output #0: loss = 0.790676 (* 1 = 0.790676 loss)
I0522 23:31:09.316014  1275 sgd_solver.cpp:106] Iteration 138000, lr = 0.0035
I0522 23:31:19.265348  1275 solver.cpp:237] Iteration 138375, loss = 1.11085
I0522 23:31:19.265383  1275 solver.cpp:253]     Train net output #0: loss = 1.11085 (* 1 = 1.11085 loss)
I0522 23:31:19.265398  1275 sgd_solver.cpp:106] Iteration 138375, lr = 0.0035
I0522 23:31:29.190949  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_138750.caffemodel
I0522 23:31:29.247674  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_138750.solverstate
I0522 23:31:29.281108  1275 solver.cpp:237] Iteration 138750, loss = 1.14325
I0522 23:31:29.281157  1275 solver.cpp:253]     Train net output #0: loss = 1.14326 (* 1 = 1.14326 loss)
I0522 23:31:29.281172  1275 sgd_solver.cpp:106] Iteration 138750, lr = 0.0035
I0522 23:31:39.232425  1275 solver.cpp:237] Iteration 139125, loss = 1.23676
I0522 23:31:39.232616  1275 solver.cpp:253]     Train net output #0: loss = 1.23676 (* 1 = 1.23676 loss)
I0522 23:31:39.232631  1275 sgd_solver.cpp:106] Iteration 139125, lr = 0.0035
I0522 23:31:49.180200  1275 solver.cpp:237] Iteration 139500, loss = 1.1028
I0522 23:31:49.180234  1275 solver.cpp:253]     Train net output #0: loss = 1.1028 (* 1 = 1.1028 loss)
I0522 23:31:49.180250  1275 sgd_solver.cpp:106] Iteration 139500, lr = 0.0035
I0522 23:31:59.137454  1275 solver.cpp:237] Iteration 139875, loss = 1.03054
I0522 23:31:59.137506  1275 solver.cpp:253]     Train net output #0: loss = 1.03054 (* 1 = 1.03054 loss)
I0522 23:31:59.137521  1275 sgd_solver.cpp:106] Iteration 139875, lr = 0.0035
I0522 23:32:29.996263  1275 solver.cpp:237] Iteration 140250, loss = 1.23082
I0522 23:32:29.996460  1275 solver.cpp:253]     Train net output #0: loss = 1.23082 (* 1 = 1.23082 loss)
I0522 23:32:29.996477  1275 sgd_solver.cpp:106] Iteration 140250, lr = 0.0035
I0522 23:32:39.945399  1275 solver.cpp:237] Iteration 140625, loss = 1.46508
I0522 23:32:39.945432  1275 solver.cpp:253]     Train net output #0: loss = 1.46508 (* 1 = 1.46508 loss)
I0522 23:32:39.945448  1275 sgd_solver.cpp:106] Iteration 140625, lr = 0.0035
I0522 23:32:49.895588  1275 solver.cpp:237] Iteration 141000, loss = 1.34061
I0522 23:32:49.895637  1275 solver.cpp:253]     Train net output #0: loss = 1.34062 (* 1 = 1.34062 loss)
I0522 23:32:49.895653  1275 sgd_solver.cpp:106] Iteration 141000, lr = 0.0035
I0522 23:32:59.841867  1275 solver.cpp:237] Iteration 141375, loss = 1.31818
I0522 23:32:59.841908  1275 solver.cpp:253]     Train net output #0: loss = 1.31818 (* 1 = 1.31818 loss)
I0522 23:32:59.841922  1275 sgd_solver.cpp:106] Iteration 141375, lr = 0.0035
I0522 23:33:09.795179  1275 solver.cpp:237] Iteration 141750, loss = 0.96138
I0522 23:33:09.795372  1275 solver.cpp:253]     Train net output #0: loss = 0.961381 (* 1 = 0.961381 loss)
I0522 23:33:09.795385  1275 sgd_solver.cpp:106] Iteration 141750, lr = 0.0035
I0522 23:33:19.746889  1275 solver.cpp:237] Iteration 142125, loss = 1.22673
I0522 23:33:19.746934  1275 solver.cpp:253]     Train net output #0: loss = 1.22674 (* 1 = 1.22674 loss)
I0522 23:33:19.746950  1275 sgd_solver.cpp:106] Iteration 142125, lr = 0.0035
I0522 23:33:29.676777  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_142500.caffemodel
I0522 23:33:29.733260  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_142500.solverstate
I0522 23:33:29.758455  1275 solver.cpp:341] Iteration 142500, Testing net (#0)
I0522 23:34:18.007310  1275 solver.cpp:409]     Test net output #0: accuracy = 0.900599
I0522 23:34:18.007513  1275 solver.cpp:409]     Test net output #1: loss = 0.311452 (* 1 = 0.311452 loss)
I0522 23:34:38.912716  1275 solver.cpp:237] Iteration 142500, loss = 1.71499
I0522 23:34:38.912773  1275 solver.cpp:253]     Train net output #0: loss = 1.71499 (* 1 = 1.71499 loss)
I0522 23:34:38.912788  1275 sgd_solver.cpp:106] Iteration 142500, lr = 0.0035
I0522 23:34:48.615402  1275 solver.cpp:237] Iteration 142875, loss = 1.06852
I0522 23:34:48.615578  1275 solver.cpp:253]     Train net output #0: loss = 1.06852 (* 1 = 1.06852 loss)
I0522 23:34:48.615592  1275 sgd_solver.cpp:106] Iteration 142875, lr = 0.0035
I0522 23:34:58.308143  1275 solver.cpp:237] Iteration 143250, loss = 0.836849
I0522 23:34:58.308197  1275 solver.cpp:253]     Train net output #0: loss = 0.83685 (* 1 = 0.83685 loss)
I0522 23:34:58.308212  1275 sgd_solver.cpp:106] Iteration 143250, lr = 0.0035
I0522 23:35:08.002075  1275 solver.cpp:237] Iteration 143625, loss = 0.877197
I0522 23:35:08.002112  1275 solver.cpp:253]     Train net output #0: loss = 0.877197 (* 1 = 0.877197 loss)
I0522 23:35:08.002125  1275 sgd_solver.cpp:106] Iteration 143625, lr = 0.0035
I0522 23:35:17.700788  1275 solver.cpp:237] Iteration 144000, loss = 1.02491
I0522 23:35:17.700824  1275 solver.cpp:253]     Train net output #0: loss = 1.02491 (* 1 = 1.02491 loss)
I0522 23:35:17.700839  1275 sgd_solver.cpp:106] Iteration 144000, lr = 0.0035
I0522 23:35:27.396983  1275 solver.cpp:237] Iteration 144375, loss = 1.00231
I0522 23:35:27.397171  1275 solver.cpp:253]     Train net output #0: loss = 1.00231 (* 1 = 1.00231 loss)
I0522 23:35:27.397186  1275 sgd_solver.cpp:106] Iteration 144375, lr = 0.0035
I0522 23:35:37.091171  1275 solver.cpp:237] Iteration 144750, loss = 1.21606
I0522 23:35:37.091205  1275 solver.cpp:253]     Train net output #0: loss = 1.21606 (* 1 = 1.21606 loss)
I0522 23:35:37.091222  1275 sgd_solver.cpp:106] Iteration 144750, lr = 0.0035
I0522 23:36:07.676698  1275 solver.cpp:237] Iteration 145125, loss = 0.992125
I0522 23:36:07.676900  1275 solver.cpp:253]     Train net output #0: loss = 0.992126 (* 1 = 0.992126 loss)
I0522 23:36:07.676916  1275 sgd_solver.cpp:106] Iteration 145125, lr = 0.0035
I0522 23:36:17.378451  1275 solver.cpp:237] Iteration 145500, loss = 1.49172
I0522 23:36:17.378495  1275 solver.cpp:253]     Train net output #0: loss = 1.49172 (* 1 = 1.49172 loss)
I0522 23:36:17.378512  1275 sgd_solver.cpp:106] Iteration 145500, lr = 0.0035
I0522 23:36:27.072194  1275 solver.cpp:237] Iteration 145875, loss = 1.38495
I0522 23:36:27.072230  1275 solver.cpp:253]     Train net output #0: loss = 1.38495 (* 1 = 1.38495 loss)
I0522 23:36:27.072245  1275 sgd_solver.cpp:106] Iteration 145875, lr = 0.0035
I0522 23:36:36.748234  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_146250.caffemodel
I0522 23:36:36.804126  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_146250.solverstate
I0522 23:36:36.837172  1275 solver.cpp:237] Iteration 146250, loss = 1.40271
I0522 23:36:36.837216  1275 solver.cpp:253]     Train net output #0: loss = 1.40271 (* 1 = 1.40271 loss)
I0522 23:36:36.837235  1275 sgd_solver.cpp:106] Iteration 146250, lr = 0.0035
I0522 23:36:46.531364  1275 solver.cpp:237] Iteration 146625, loss = 1.23905
I0522 23:36:46.531550  1275 solver.cpp:253]     Train net output #0: loss = 1.23905 (* 1 = 1.23905 loss)
I0522 23:36:46.531564  1275 sgd_solver.cpp:106] Iteration 146625, lr = 0.0035
I0522 23:36:56.220435  1275 solver.cpp:237] Iteration 147000, loss = 1.57418
I0522 23:36:56.220469  1275 solver.cpp:253]     Train net output #0: loss = 1.57418 (* 1 = 1.57418 loss)
I0522 23:36:56.220485  1275 sgd_solver.cpp:106] Iteration 147000, lr = 0.0035
I0522 23:37:05.916635  1275 solver.cpp:237] Iteration 147375, loss = 1.33384
I0522 23:37:05.916682  1275 solver.cpp:253]     Train net output #0: loss = 1.33384 (* 1 = 1.33384 loss)
I0522 23:37:05.916697  1275 sgd_solver.cpp:106] Iteration 147375, lr = 0.0035
I0522 23:37:36.555305  1275 solver.cpp:237] Iteration 147750, loss = 1.14709
I0522 23:37:36.555507  1275 solver.cpp:253]     Train net output #0: loss = 1.14709 (* 1 = 1.14709 loss)
I0522 23:37:36.555523  1275 sgd_solver.cpp:106] Iteration 147750, lr = 0.0035
I0522 23:37:46.253233  1275 solver.cpp:237] Iteration 148125, loss = 1.34689
I0522 23:37:46.253268  1275 solver.cpp:253]     Train net output #0: loss = 1.34689 (* 1 = 1.34689 loss)
I0522 23:37:46.253283  1275 sgd_solver.cpp:106] Iteration 148125, lr = 0.0035
I0522 23:37:55.951670  1275 solver.cpp:237] Iteration 148500, loss = 1.23431
I0522 23:37:55.951717  1275 solver.cpp:253]     Train net output #0: loss = 1.23431 (* 1 = 1.23431 loss)
I0522 23:37:55.951731  1275 sgd_solver.cpp:106] Iteration 148500, lr = 0.0035
I0522 23:38:05.651963  1275 solver.cpp:237] Iteration 148875, loss = 1.17564
I0522 23:38:05.651998  1275 solver.cpp:253]     Train net output #0: loss = 1.17564 (* 1 = 1.17564 loss)
I0522 23:38:05.652012  1275 sgd_solver.cpp:106] Iteration 148875, lr = 0.0035
I0522 23:38:15.344827  1275 solver.cpp:237] Iteration 149250, loss = 1.12272
I0522 23:38:15.345017  1275 solver.cpp:253]     Train net output #0: loss = 1.12272 (* 1 = 1.12272 loss)
I0522 23:38:15.345031  1275 sgd_solver.cpp:106] Iteration 149250, lr = 0.0035
I0522 23:38:25.048545  1275 solver.cpp:237] Iteration 149625, loss = 1.60348
I0522 23:38:25.048580  1275 solver.cpp:253]     Train net output #0: loss = 1.60348 (* 1 = 1.60348 loss)
I0522 23:38:25.048595  1275 sgd_solver.cpp:106] Iteration 149625, lr = 0.0035
I0522 23:38:34.710274  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_150000.caffemodel
I0522 23:38:34.767894  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_150000.solverstate
I0522 23:38:34.795029  1275 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 23:39:44.335077  1275 solver.cpp:409]     Test net output #0: accuracy = 0.901733
I0522 23:39:44.335274  1275 solver.cpp:409]     Test net output #1: loss = 0.323694 (* 1 = 0.323694 loss)
I0522 23:40:05.283526  1275 solver.cpp:237] Iteration 150000, loss = 1.28583
I0522 23:40:05.283583  1275 solver.cpp:253]     Train net output #0: loss = 1.28583 (* 1 = 1.28583 loss)
I0522 23:40:05.283598  1275 sgd_solver.cpp:106] Iteration 150000, lr = 0.0035
I0522 23:40:15.036677  1275 solver.cpp:237] Iteration 150375, loss = 0.911915
I0522 23:40:15.036870  1275 solver.cpp:253]     Train net output #0: loss = 0.911916 (* 1 = 0.911916 loss)
I0522 23:40:15.036885  1275 sgd_solver.cpp:106] Iteration 150375, lr = 0.0035
I0522 23:40:24.796905  1275 solver.cpp:237] Iteration 150750, loss = 1.33276
I0522 23:40:24.796952  1275 solver.cpp:253]     Train net output #0: loss = 1.33276 (* 1 = 1.33276 loss)
I0522 23:40:24.796967  1275 sgd_solver.cpp:106] Iteration 150750, lr = 0.0035
I0522 23:40:34.552193  1275 solver.cpp:237] Iteration 151125, loss = 0.720689
I0522 23:40:34.552230  1275 solver.cpp:253]     Train net output #0: loss = 0.72069 (* 1 = 0.72069 loss)
I0522 23:40:34.552245  1275 sgd_solver.cpp:106] Iteration 151125, lr = 0.0035
I0522 23:40:44.318372  1275 solver.cpp:237] Iteration 151500, loss = 0.942254
I0522 23:40:44.318428  1275 solver.cpp:253]     Train net output #0: loss = 0.942255 (* 1 = 0.942255 loss)
I0522 23:40:44.318444  1275 sgd_solver.cpp:106] Iteration 151500, lr = 0.0035
I0522 23:40:54.139735  1275 solver.cpp:237] Iteration 151875, loss = 0.970111
I0522 23:40:54.139916  1275 solver.cpp:253]     Train net output #0: loss = 0.970111 (* 1 = 0.970111 loss)
I0522 23:40:54.139930  1275 sgd_solver.cpp:106] Iteration 151875, lr = 0.0035
I0522 23:41:03.964606  1275 solver.cpp:237] Iteration 152250, loss = 1.1824
I0522 23:41:03.964639  1275 solver.cpp:253]     Train net output #0: loss = 1.1824 (* 1 = 1.1824 loss)
I0522 23:41:03.964655  1275 sgd_solver.cpp:106] Iteration 152250, lr = 0.0035
I0522 23:41:34.680809  1275 solver.cpp:237] Iteration 152625, loss = 1.21299
I0522 23:41:34.681010  1275 solver.cpp:253]     Train net output #0: loss = 1.21299 (* 1 = 1.21299 loss)
I0522 23:41:34.681023  1275 sgd_solver.cpp:106] Iteration 152625, lr = 0.0035
I0522 23:41:44.507117  1275 solver.cpp:237] Iteration 153000, loss = 1.06439
I0522 23:41:44.507151  1275 solver.cpp:253]     Train net output #0: loss = 1.06439 (* 1 = 1.06439 loss)
I0522 23:41:44.507167  1275 sgd_solver.cpp:106] Iteration 153000, lr = 0.0035
I0522 23:41:54.339859  1275 solver.cpp:237] Iteration 153375, loss = 1.48064
I0522 23:41:54.339895  1275 solver.cpp:253]     Train net output #0: loss = 1.48064 (* 1 = 1.48064 loss)
I0522 23:41:54.339910  1275 sgd_solver.cpp:106] Iteration 153375, lr = 0.0035
I0522 23:42:04.136807  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_153750.caffemodel
I0522 23:42:04.193979  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_153750.solverstate
I0522 23:42:04.226850  1275 solver.cpp:237] Iteration 153750, loss = 1.04923
I0522 23:42:04.226897  1275 solver.cpp:253]     Train net output #0: loss = 1.04923 (* 1 = 1.04923 loss)
I0522 23:42:04.226913  1275 sgd_solver.cpp:106] Iteration 153750, lr = 0.0035
I0522 23:42:14.054587  1275 solver.cpp:237] Iteration 154125, loss = 1.06215
I0522 23:42:14.054772  1275 solver.cpp:253]     Train net output #0: loss = 1.06215 (* 1 = 1.06215 loss)
I0522 23:42:14.054786  1275 sgd_solver.cpp:106] Iteration 154125, lr = 0.0035
I0522 23:42:23.883265  1275 solver.cpp:237] Iteration 154500, loss = 1.16961
I0522 23:42:23.883313  1275 solver.cpp:253]     Train net output #0: loss = 1.16961 (* 1 = 1.16961 loss)
I0522 23:42:23.883328  1275 sgd_solver.cpp:106] Iteration 154500, lr = 0.0035
I0522 23:42:33.710248  1275 solver.cpp:237] Iteration 154875, loss = 0.90591
I0522 23:42:33.710283  1275 solver.cpp:253]     Train net output #0: loss = 0.90591 (* 1 = 0.90591 loss)
I0522 23:42:33.710299  1275 sgd_solver.cpp:106] Iteration 154875, lr = 0.0035
I0522 23:43:04.468168  1275 solver.cpp:237] Iteration 155250, loss = 1.20958
I0522 23:43:04.468369  1275 solver.cpp:253]     Train net output #0: loss = 1.20959 (* 1 = 1.20959 loss)
I0522 23:43:04.468385  1275 sgd_solver.cpp:106] Iteration 155250, lr = 0.0035
I0522 23:43:14.299245  1275 solver.cpp:237] Iteration 155625, loss = 1.02378
I0522 23:43:14.299293  1275 solver.cpp:253]     Train net output #0: loss = 1.02378 (* 1 = 1.02378 loss)
I0522 23:43:14.299307  1275 sgd_solver.cpp:106] Iteration 155625, lr = 0.0035
I0522 23:43:24.125246  1275 solver.cpp:237] Iteration 156000, loss = 1.08517
I0522 23:43:24.125280  1275 solver.cpp:253]     Train net output #0: loss = 1.08517 (* 1 = 1.08517 loss)
I0522 23:43:24.125295  1275 sgd_solver.cpp:106] Iteration 156000, lr = 0.0035
I0522 23:43:33.952910  1275 solver.cpp:237] Iteration 156375, loss = 1.05341
I0522 23:43:33.952944  1275 solver.cpp:253]     Train net output #0: loss = 1.05341 (* 1 = 1.05341 loss)
I0522 23:43:33.952960  1275 sgd_solver.cpp:106] Iteration 156375, lr = 0.0035
I0522 23:43:43.771976  1275 solver.cpp:237] Iteration 156750, loss = 0.871753
I0522 23:43:43.772179  1275 solver.cpp:253]     Train net output #0: loss = 0.871754 (* 1 = 0.871754 loss)
I0522 23:43:43.772193  1275 sgd_solver.cpp:106] Iteration 156750, lr = 0.0035
I0522 23:43:53.596428  1275 solver.cpp:237] Iteration 157125, loss = 1.12042
I0522 23:43:53.596463  1275 solver.cpp:253]     Train net output #0: loss = 1.12042 (* 1 = 1.12042 loss)
I0522 23:43:53.596478  1275 sgd_solver.cpp:106] Iteration 157125, lr = 0.0035
I0522 23:44:03.400238  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_157500.caffemodel
I0522 23:44:03.456503  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_157500.solverstate
I0522 23:44:03.481287  1275 solver.cpp:341] Iteration 157500, Testing net (#0)
I0522 23:44:52.096204  1275 solver.cpp:409]     Test net output #0: accuracy = 0.903101
I0522 23:44:52.096415  1275 solver.cpp:409]     Test net output #1: loss = 0.310565 (* 1 = 0.310565 loss)
I0522 23:45:13.014798  1275 solver.cpp:237] Iteration 157500, loss = 1.01614
I0522 23:45:13.014856  1275 solver.cpp:253]     Train net output #0: loss = 1.01614 (* 1 = 1.01614 loss)
I0522 23:45:13.014871  1275 sgd_solver.cpp:106] Iteration 157500, lr = 0.0035
I0522 23:45:22.818176  1275 solver.cpp:237] Iteration 157875, loss = 1.0755
I0522 23:45:22.818372  1275 solver.cpp:253]     Train net output #0: loss = 1.0755 (* 1 = 1.0755 loss)
I0522 23:45:22.818385  1275 sgd_solver.cpp:106] Iteration 157875, lr = 0.0035
I0522 23:45:32.614456  1275 solver.cpp:237] Iteration 158250, loss = 1.12356
I0522 23:45:32.614491  1275 solver.cpp:253]     Train net output #0: loss = 1.12356 (* 1 = 1.12356 loss)
I0522 23:45:32.614506  1275 sgd_solver.cpp:106] Iteration 158250, lr = 0.0035
I0522 23:45:42.417045  1275 solver.cpp:237] Iteration 158625, loss = 1.26697
I0522 23:45:42.417083  1275 solver.cpp:253]     Train net output #0: loss = 1.26697 (* 1 = 1.26697 loss)
I0522 23:45:42.417098  1275 sgd_solver.cpp:106] Iteration 158625, lr = 0.0035
I0522 23:45:52.206437  1275 solver.cpp:237] Iteration 159000, loss = 1.00479
I0522 23:45:52.206480  1275 solver.cpp:253]     Train net output #0: loss = 1.00479 (* 1 = 1.00479 loss)
I0522 23:45:52.206501  1275 sgd_solver.cpp:106] Iteration 159000, lr = 0.0035
I0522 23:46:02.000764  1275 solver.cpp:237] Iteration 159375, loss = 1.08802
I0522 23:46:02.000943  1275 solver.cpp:253]     Train net output #0: loss = 1.08802 (* 1 = 1.08802 loss)
I0522 23:46:02.000957  1275 sgd_solver.cpp:106] Iteration 159375, lr = 0.0035
I0522 23:46:11.799067  1275 solver.cpp:237] Iteration 159750, loss = 1.20741
I0522 23:46:11.799110  1275 solver.cpp:253]     Train net output #0: loss = 1.20741 (* 1 = 1.20741 loss)
I0522 23:46:11.799126  1275 sgd_solver.cpp:106] Iteration 159750, lr = 0.0035
I0522 23:46:42.523366  1275 solver.cpp:237] Iteration 160125, loss = 1.11885
I0522 23:46:42.523572  1275 solver.cpp:253]     Train net output #0: loss = 1.11885 (* 1 = 1.11885 loss)
I0522 23:46:42.523586  1275 sgd_solver.cpp:106] Iteration 160125, lr = 0.0035
I0522 23:46:52.322630  1275 solver.cpp:237] Iteration 160500, loss = 1.10911
I0522 23:46:52.322665  1275 solver.cpp:253]     Train net output #0: loss = 1.10911 (* 1 = 1.10911 loss)
I0522 23:46:52.322682  1275 sgd_solver.cpp:106] Iteration 160500, lr = 0.0035
I0522 23:47:02.127228  1275 solver.cpp:237] Iteration 160875, loss = 1.34401
I0522 23:47:02.127279  1275 solver.cpp:253]     Train net output #0: loss = 1.34401 (* 1 = 1.34401 loss)
I0522 23:47:02.127292  1275 sgd_solver.cpp:106] Iteration 160875, lr = 0.0035
I0522 23:47:11.899116  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_161250.caffemodel
I0522 23:47:11.954900  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_161250.solverstate
I0522 23:47:11.987860  1275 solver.cpp:237] Iteration 161250, loss = 1.28821
I0522 23:47:11.987905  1275 solver.cpp:253]     Train net output #0: loss = 1.28821 (* 1 = 1.28821 loss)
I0522 23:47:11.987920  1275 sgd_solver.cpp:106] Iteration 161250, lr = 0.0035
I0522 23:47:21.786402  1275 solver.cpp:237] Iteration 161625, loss = 0.996237
I0522 23:47:21.786603  1275 solver.cpp:253]     Train net output #0: loss = 0.996237 (* 1 = 0.996237 loss)
I0522 23:47:21.786617  1275 sgd_solver.cpp:106] Iteration 161625, lr = 0.0035
I0522 23:47:31.590878  1275 solver.cpp:237] Iteration 162000, loss = 1.24325
I0522 23:47:31.590924  1275 solver.cpp:253]     Train net output #0: loss = 1.24326 (* 1 = 1.24326 loss)
I0522 23:47:31.590940  1275 sgd_solver.cpp:106] Iteration 162000, lr = 0.0035
I0522 23:47:41.395931  1275 solver.cpp:237] Iteration 162375, loss = 1.20899
I0522 23:47:41.395965  1275 solver.cpp:253]     Train net output #0: loss = 1.20899 (* 1 = 1.20899 loss)
I0522 23:47:41.395982  1275 sgd_solver.cpp:106] Iteration 162375, lr = 0.0035
I0522 23:48:12.139786  1275 solver.cpp:237] Iteration 162750, loss = 1.08188
I0522 23:48:12.139992  1275 solver.cpp:253]     Train net output #0: loss = 1.08188 (* 1 = 1.08188 loss)
I0522 23:48:12.140007  1275 sgd_solver.cpp:106] Iteration 162750, lr = 0.0035
I0522 23:48:21.941465  1275 solver.cpp:237] Iteration 163125, loss = 1.03686
I0522 23:48:21.941512  1275 solver.cpp:253]     Train net output #0: loss = 1.03686 (* 1 = 1.03686 loss)
I0522 23:48:21.941529  1275 sgd_solver.cpp:106] Iteration 163125, lr = 0.0035
I0522 23:48:31.735694  1275 solver.cpp:237] Iteration 163500, loss = 1.05872
I0522 23:48:31.735729  1275 solver.cpp:253]     Train net output #0: loss = 1.05872 (* 1 = 1.05872 loss)
I0522 23:48:31.735745  1275 sgd_solver.cpp:106] Iteration 163500, lr = 0.0035
I0522 23:48:41.543195  1275 solver.cpp:237] Iteration 163875, loss = 0.951127
I0522 23:48:41.543247  1275 solver.cpp:253]     Train net output #0: loss = 0.951128 (* 1 = 0.951128 loss)
I0522 23:48:41.543262  1275 sgd_solver.cpp:106] Iteration 163875, lr = 0.0035
I0522 23:48:51.373971  1275 solver.cpp:237] Iteration 164250, loss = 1.04798
I0522 23:48:51.374158  1275 solver.cpp:253]     Train net output #0: loss = 1.04798 (* 1 = 1.04798 loss)
I0522 23:48:51.374172  1275 sgd_solver.cpp:106] Iteration 164250, lr = 0.0035
I0522 23:49:01.204253  1275 solver.cpp:237] Iteration 164625, loss = 1.02474
I0522 23:49:01.204288  1275 solver.cpp:253]     Train net output #0: loss = 1.02474 (* 1 = 1.02474 loss)
I0522 23:49:01.204303  1275 sgd_solver.cpp:106] Iteration 164625, lr = 0.0035
I0522 23:49:10.976976  1275 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_165000.caffemodel
I0522 23:49:11.033526  1275 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_165000.solverstate
I0522 23:49:11.058369  1275 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 23:50:20.499513  1275 solver.cpp:409]     Test net output #0: accuracy = 0.90286
I0522 23:50:20.499727  1275 solver.cpp:409]     Test net output #1: loss = 0.342738 (* 1 = 0.342738 loss)
I0522 23:50:41.396126  1275 solver.cpp:237] Iteration 165000, loss = 1.34094
I0522 23:50:41.396184  1275 solver.cpp:253]     Train net output #0: loss = 1.34094 (* 1 = 1.34094 loss)
I0522 23:50:41.396200  1275 sgd_solver.cpp:106] Iteration 165000, lr = 0.0035
I0522 23:50:51.041395  1275 solver.cpp:237] Iteration 165375, loss = 0.982508
I0522 23:50:51.041594  1275 solver.cpp:253]     Train net output #0: loss = 0.982508 (* 1 = 0.982508 loss)
I0522 23:50:51.041609  1275 sgd_solver.cpp:106] Iteration 165375, lr = 0.0035
I0522 23:51:00.682617  1275 solver.cpp:237] Iteration 165750, loss = 1.31756
I0522 23:51:00.682651  1275 solver.cpp:253]     Train net output #0: loss = 1.31756 (* 1 = 1.31756 loss)
I0522 23:51:00.682667  1275 sgd_solver.cpp:106] Iteration 165750, lr = 0.0035
I0522 23:51:10.330127  1275 solver.cpp:237] Iteration 166125, loss = 0.924387
I0522 23:51:10.330181  1275 solver.cpp:253]     Train net output #0: loss = 0.924387 (* 1 = 0.924387 loss)
I0522 23:51:10.330195  1275 sgd_solver.cpp:106] Iteration 166125, lr = 0.0035
I0522 23:51:20.024379  1275 solver.cpp:237] Iteration 166500, loss = 1.12683
I0522 23:51:20.024415  1275 solver.cpp:253]     Train net output #0: loss = 1.12683 (* 1 = 1.12683 loss)
I0522 23:51:20.024428  1275 sgd_solver.cpp:106] Iteration 166500, lr = 0.0035
I0522 23:51:29.715523  1275 solver.cpp:237] Iteration 166875, loss = 1.09463
I0522 23:51:29.715704  1275 solver.cpp:253]     Train net output #0: loss = 1.09463 (* 1 = 1.09463 loss)
I0522 23:51:29.715718  1275 sgd_solver.cpp:106] Iteration 166875, lr = 0.0035
I0522 23:51:39.411922  1275 solver.cpp:237] Iteration 167250, loss = 1.22316
I0522 23:51:39.411972  1275 solver.cpp:253]     Train net output #0: loss = 1.22316 (* 1 = 1.22316 loss)
I0522 23:51:39.411988  1275 sgd_solver.cpp:106] Iteration 167250, lr = 0.0035
I0522 23:52:10.020719  1275 solver.cpp:237] Iteration 167625, loss = 1.11304
I0522 23:52:10.020925  1275 solver.cpp:253]     Train net output #0: loss = 1.11304 (* 1 = 1.11304 loss)
I0522 23:52:10.020942  1275 sgd_solver.cpp:106] Iteration 167625, lr = 0.0035
I0522 23:52:19.726126  1275 solver.cpp:237] Iteration 168000, loss = 1.10263
I0522 23:52:19.726161  1275 solver.cpp:253]     Train net output #0: loss = 1.10263 (* 1 = 1.10263 loss)
I0522 23:52:19.726176  1275 sgd_solver.cpp:106] Iteration 168000, lr = 0.0035
aprun: Apid 11251328: Caught signal Terminated, sending to application
*** Aborted at 1463975542 (unix time) try "date -d @1463975542" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x4f8) received by PID 1275 (TID 0x2aaac746f900) from PID 1272; stack trace: ***
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11251328: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7226 exceeded limit 7200
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11251328: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
aprun: Apid 11251328: Caught signal Terminated, sending to application
