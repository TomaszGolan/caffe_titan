2813227
I0527 09:47:15.349490 25403 caffe.cpp:184] Using GPUs 0
I0527 09:47:15.779405 25403 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0025
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491.prototxt"
I0527 09:47:15.781556 25403 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491.prototxt
I0527 09:47:15.796725 25403 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0527 09:47:15.796783 25403 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0527 09:47:15.797132 25403 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 09:47:15.797312 25403 layer_factory.hpp:77] Creating layer data_hdf5
I0527 09:47:15.797335 25403 net.cpp:106] Creating Layer data_hdf5
I0527 09:47:15.797349 25403 net.cpp:411] data_hdf5 -> data
I0527 09:47:15.797382 25403 net.cpp:411] data_hdf5 -> label
I0527 09:47:15.797415 25403 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0527 09:47:15.798729 25403 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0527 09:47:15.801136 25403 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0527 09:47:37.399760 25403 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0527 09:47:37.404861 25403 net.cpp:150] Setting up data_hdf5
I0527 09:47:37.404901 25403 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 09:47:37.404917 25403 net.cpp:157] Top shape: 40 (40)
I0527 09:47:37.404929 25403 net.cpp:165] Memory required for data: 1016160
I0527 09:47:37.404942 25403 layer_factory.hpp:77] Creating layer conv1
I0527 09:47:37.404978 25403 net.cpp:106] Creating Layer conv1
I0527 09:47:37.404989 25403 net.cpp:454] conv1 <- data
I0527 09:47:37.405009 25403 net.cpp:411] conv1 -> conv1
I0527 09:47:37.934664 25403 net.cpp:150] Setting up conv1
I0527 09:47:37.934711 25403 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:47:37.934722 25403 net.cpp:165] Memory required for data: 12075360
I0527 09:47:37.934751 25403 layer_factory.hpp:77] Creating layer relu1
I0527 09:47:37.934773 25403 net.cpp:106] Creating Layer relu1
I0527 09:47:37.934784 25403 net.cpp:454] relu1 <- conv1
I0527 09:47:37.934798 25403 net.cpp:397] relu1 -> conv1 (in-place)
I0527 09:47:37.935312 25403 net.cpp:150] Setting up relu1
I0527 09:47:37.935329 25403 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:47:37.935339 25403 net.cpp:165] Memory required for data: 23134560
I0527 09:47:37.935349 25403 layer_factory.hpp:77] Creating layer pool1
I0527 09:47:37.935366 25403 net.cpp:106] Creating Layer pool1
I0527 09:47:37.935376 25403 net.cpp:454] pool1 <- conv1
I0527 09:47:37.935389 25403 net.cpp:411] pool1 -> pool1
I0527 09:47:37.935470 25403 net.cpp:150] Setting up pool1
I0527 09:47:37.935484 25403 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 09:47:37.935494 25403 net.cpp:165] Memory required for data: 28664160
I0527 09:47:37.935503 25403 layer_factory.hpp:77] Creating layer conv2
I0527 09:47:37.935526 25403 net.cpp:106] Creating Layer conv2
I0527 09:47:37.935536 25403 net.cpp:454] conv2 <- pool1
I0527 09:47:37.935549 25403 net.cpp:411] conv2 -> conv2
I0527 09:47:37.938230 25403 net.cpp:150] Setting up conv2
I0527 09:47:37.938257 25403 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:47:37.938267 25403 net.cpp:165] Memory required for data: 36612960
I0527 09:47:37.938287 25403 layer_factory.hpp:77] Creating layer relu2
I0527 09:47:37.938302 25403 net.cpp:106] Creating Layer relu2
I0527 09:47:37.938311 25403 net.cpp:454] relu2 <- conv2
I0527 09:47:37.938324 25403 net.cpp:397] relu2 -> conv2 (in-place)
I0527 09:47:37.938655 25403 net.cpp:150] Setting up relu2
I0527 09:47:37.938670 25403 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:47:37.938681 25403 net.cpp:165] Memory required for data: 44561760
I0527 09:47:37.938691 25403 layer_factory.hpp:77] Creating layer pool2
I0527 09:47:37.938704 25403 net.cpp:106] Creating Layer pool2
I0527 09:47:37.938714 25403 net.cpp:454] pool2 <- conv2
I0527 09:47:37.938727 25403 net.cpp:411] pool2 -> pool2
I0527 09:47:37.938809 25403 net.cpp:150] Setting up pool2
I0527 09:47:37.938823 25403 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 09:47:37.938832 25403 net.cpp:165] Memory required for data: 48536160
I0527 09:47:37.938840 25403 layer_factory.hpp:77] Creating layer conv3
I0527 09:47:37.938859 25403 net.cpp:106] Creating Layer conv3
I0527 09:47:37.938869 25403 net.cpp:454] conv3 <- pool2
I0527 09:47:37.938884 25403 net.cpp:411] conv3 -> conv3
I0527 09:47:37.940834 25403 net.cpp:150] Setting up conv3
I0527 09:47:37.940852 25403 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:47:37.940866 25403 net.cpp:165] Memory required for data: 52872800
I0527 09:47:37.940886 25403 layer_factory.hpp:77] Creating layer relu3
I0527 09:47:37.940903 25403 net.cpp:106] Creating Layer relu3
I0527 09:47:37.940913 25403 net.cpp:454] relu3 <- conv3
I0527 09:47:37.940927 25403 net.cpp:397] relu3 -> conv3 (in-place)
I0527 09:47:37.941395 25403 net.cpp:150] Setting up relu3
I0527 09:47:37.941412 25403 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:47:37.941422 25403 net.cpp:165] Memory required for data: 57209440
I0527 09:47:37.941432 25403 layer_factory.hpp:77] Creating layer pool3
I0527 09:47:37.941445 25403 net.cpp:106] Creating Layer pool3
I0527 09:47:37.941455 25403 net.cpp:454] pool3 <- conv3
I0527 09:47:37.941468 25403 net.cpp:411] pool3 -> pool3
I0527 09:47:37.941536 25403 net.cpp:150] Setting up pool3
I0527 09:47:37.941550 25403 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 09:47:37.941560 25403 net.cpp:165] Memory required for data: 59377760
I0527 09:47:37.941570 25403 layer_factory.hpp:77] Creating layer conv4
I0527 09:47:37.941587 25403 net.cpp:106] Creating Layer conv4
I0527 09:47:37.941597 25403 net.cpp:454] conv4 <- pool3
I0527 09:47:37.941612 25403 net.cpp:411] conv4 -> conv4
I0527 09:47:37.944375 25403 net.cpp:150] Setting up conv4
I0527 09:47:37.944401 25403 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:47:37.944413 25403 net.cpp:165] Memory required for data: 60829280
I0527 09:47:37.944428 25403 layer_factory.hpp:77] Creating layer relu4
I0527 09:47:37.944443 25403 net.cpp:106] Creating Layer relu4
I0527 09:47:37.944453 25403 net.cpp:454] relu4 <- conv4
I0527 09:47:37.944468 25403 net.cpp:397] relu4 -> conv4 (in-place)
I0527 09:47:37.944938 25403 net.cpp:150] Setting up relu4
I0527 09:47:37.944954 25403 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:47:37.944965 25403 net.cpp:165] Memory required for data: 62280800
I0527 09:47:37.944977 25403 layer_factory.hpp:77] Creating layer pool4
I0527 09:47:37.944989 25403 net.cpp:106] Creating Layer pool4
I0527 09:47:37.944999 25403 net.cpp:454] pool4 <- conv4
I0527 09:47:37.945013 25403 net.cpp:411] pool4 -> pool4
I0527 09:47:37.945080 25403 net.cpp:150] Setting up pool4
I0527 09:47:37.945094 25403 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 09:47:37.945106 25403 net.cpp:165] Memory required for data: 63006560
I0527 09:47:37.945114 25403 layer_factory.hpp:77] Creating layer ip1
I0527 09:47:37.945135 25403 net.cpp:106] Creating Layer ip1
I0527 09:47:37.945145 25403 net.cpp:454] ip1 <- pool4
I0527 09:47:37.945158 25403 net.cpp:411] ip1 -> ip1
I0527 09:47:37.960708 25403 net.cpp:150] Setting up ip1
I0527 09:47:37.960737 25403 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:47:37.960754 25403 net.cpp:165] Memory required for data: 63037920
I0527 09:47:37.960777 25403 layer_factory.hpp:77] Creating layer relu5
I0527 09:47:37.960791 25403 net.cpp:106] Creating Layer relu5
I0527 09:47:37.960803 25403 net.cpp:454] relu5 <- ip1
I0527 09:47:37.960815 25403 net.cpp:397] relu5 -> ip1 (in-place)
I0527 09:47:37.961160 25403 net.cpp:150] Setting up relu5
I0527 09:47:37.961174 25403 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:47:37.961185 25403 net.cpp:165] Memory required for data: 63069280
I0527 09:47:37.961195 25403 layer_factory.hpp:77] Creating layer drop1
I0527 09:47:37.961216 25403 net.cpp:106] Creating Layer drop1
I0527 09:47:37.961226 25403 net.cpp:454] drop1 <- ip1
I0527 09:47:37.961239 25403 net.cpp:397] drop1 -> ip1 (in-place)
I0527 09:47:37.961302 25403 net.cpp:150] Setting up drop1
I0527 09:47:37.961316 25403 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:47:37.961326 25403 net.cpp:165] Memory required for data: 63100640
I0527 09:47:37.961336 25403 layer_factory.hpp:77] Creating layer ip2
I0527 09:47:37.961354 25403 net.cpp:106] Creating Layer ip2
I0527 09:47:37.961365 25403 net.cpp:454] ip2 <- ip1
I0527 09:47:37.961379 25403 net.cpp:411] ip2 -> ip2
I0527 09:47:37.961841 25403 net.cpp:150] Setting up ip2
I0527 09:47:37.961854 25403 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:47:37.961863 25403 net.cpp:165] Memory required for data: 63116320
I0527 09:47:37.961879 25403 layer_factory.hpp:77] Creating layer relu6
I0527 09:47:37.961892 25403 net.cpp:106] Creating Layer relu6
I0527 09:47:37.961902 25403 net.cpp:454] relu6 <- ip2
I0527 09:47:37.961915 25403 net.cpp:397] relu6 -> ip2 (in-place)
I0527 09:47:37.962435 25403 net.cpp:150] Setting up relu6
I0527 09:47:37.962450 25403 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:47:37.962461 25403 net.cpp:165] Memory required for data: 63132000
I0527 09:47:37.962471 25403 layer_factory.hpp:77] Creating layer drop2
I0527 09:47:37.962484 25403 net.cpp:106] Creating Layer drop2
I0527 09:47:37.962493 25403 net.cpp:454] drop2 <- ip2
I0527 09:47:37.962507 25403 net.cpp:397] drop2 -> ip2 (in-place)
I0527 09:47:37.962549 25403 net.cpp:150] Setting up drop2
I0527 09:47:37.962563 25403 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:47:37.962573 25403 net.cpp:165] Memory required for data: 63147680
I0527 09:47:37.962582 25403 layer_factory.hpp:77] Creating layer ip3
I0527 09:47:37.962595 25403 net.cpp:106] Creating Layer ip3
I0527 09:47:37.962605 25403 net.cpp:454] ip3 <- ip2
I0527 09:47:37.962618 25403 net.cpp:411] ip3 -> ip3
I0527 09:47:37.962831 25403 net.cpp:150] Setting up ip3
I0527 09:47:37.962843 25403 net.cpp:157] Top shape: 40 11 (440)
I0527 09:47:37.962853 25403 net.cpp:165] Memory required for data: 63149440
I0527 09:47:37.962868 25403 layer_factory.hpp:77] Creating layer drop3
I0527 09:47:37.962882 25403 net.cpp:106] Creating Layer drop3
I0527 09:47:37.962890 25403 net.cpp:454] drop3 <- ip3
I0527 09:47:37.962903 25403 net.cpp:397] drop3 -> ip3 (in-place)
I0527 09:47:37.962942 25403 net.cpp:150] Setting up drop3
I0527 09:47:37.962955 25403 net.cpp:157] Top shape: 40 11 (440)
I0527 09:47:37.962965 25403 net.cpp:165] Memory required for data: 63151200
I0527 09:47:37.962976 25403 layer_factory.hpp:77] Creating layer loss
I0527 09:47:37.962995 25403 net.cpp:106] Creating Layer loss
I0527 09:47:37.963004 25403 net.cpp:454] loss <- ip3
I0527 09:47:37.963016 25403 net.cpp:454] loss <- label
I0527 09:47:37.963028 25403 net.cpp:411] loss -> loss
I0527 09:47:37.963045 25403 layer_factory.hpp:77] Creating layer loss
I0527 09:47:37.963685 25403 net.cpp:150] Setting up loss
I0527 09:47:37.963704 25403 net.cpp:157] Top shape: (1)
I0527 09:47:37.963718 25403 net.cpp:160]     with loss weight 1
I0527 09:47:37.963763 25403 net.cpp:165] Memory required for data: 63151204
I0527 09:47:37.963774 25403 net.cpp:226] loss needs backward computation.
I0527 09:47:37.963793 25403 net.cpp:226] drop3 needs backward computation.
I0527 09:47:37.963804 25403 net.cpp:226] ip3 needs backward computation.
I0527 09:47:37.963814 25403 net.cpp:226] drop2 needs backward computation.
I0527 09:47:37.963824 25403 net.cpp:226] relu6 needs backward computation.
I0527 09:47:37.963834 25403 net.cpp:226] ip2 needs backward computation.
I0527 09:47:37.963843 25403 net.cpp:226] drop1 needs backward computation.
I0527 09:47:37.963853 25403 net.cpp:226] relu5 needs backward computation.
I0527 09:47:37.963862 25403 net.cpp:226] ip1 needs backward computation.
I0527 09:47:37.963872 25403 net.cpp:226] pool4 needs backward computation.
I0527 09:47:37.963883 25403 net.cpp:226] relu4 needs backward computation.
I0527 09:47:37.963893 25403 net.cpp:226] conv4 needs backward computation.
I0527 09:47:37.963903 25403 net.cpp:226] pool3 needs backward computation.
I0527 09:47:37.963912 25403 net.cpp:226] relu3 needs backward computation.
I0527 09:47:37.963922 25403 net.cpp:226] conv3 needs backward computation.
I0527 09:47:37.963942 25403 net.cpp:226] pool2 needs backward computation.
I0527 09:47:37.963953 25403 net.cpp:226] relu2 needs backward computation.
I0527 09:47:37.963963 25403 net.cpp:226] conv2 needs backward computation.
I0527 09:47:37.963973 25403 net.cpp:226] pool1 needs backward computation.
I0527 09:47:37.963984 25403 net.cpp:226] relu1 needs backward computation.
I0527 09:47:37.963994 25403 net.cpp:226] conv1 needs backward computation.
I0527 09:47:37.964004 25403 net.cpp:228] data_hdf5 does not need backward computation.
I0527 09:47:37.964015 25403 net.cpp:270] This network produces output loss
I0527 09:47:37.964038 25403 net.cpp:283] Network initialization done.
I0527 09:47:37.965790 25403 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491.prototxt
I0527 09:47:37.965863 25403 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0527 09:47:37.966220 25403 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 09:47:37.966408 25403 layer_factory.hpp:77] Creating layer data_hdf5
I0527 09:47:37.966423 25403 net.cpp:106] Creating Layer data_hdf5
I0527 09:47:37.966434 25403 net.cpp:411] data_hdf5 -> data
I0527 09:47:37.966451 25403 net.cpp:411] data_hdf5 -> label
I0527 09:47:37.966467 25403 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0527 09:47:37.967849 25403 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0527 09:47:59.338373 25403 net.cpp:150] Setting up data_hdf5
I0527 09:47:59.338541 25403 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 09:47:59.338556 25403 net.cpp:157] Top shape: 40 (40)
I0527 09:47:59.338565 25403 net.cpp:165] Memory required for data: 1016160
I0527 09:47:59.338579 25403 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0527 09:47:59.338608 25403 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0527 09:47:59.338618 25403 net.cpp:454] label_data_hdf5_1_split <- label
I0527 09:47:59.338634 25403 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0527 09:47:59.338655 25403 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0527 09:47:59.338728 25403 net.cpp:150] Setting up label_data_hdf5_1_split
I0527 09:47:59.338742 25403 net.cpp:157] Top shape: 40 (40)
I0527 09:47:59.338754 25403 net.cpp:157] Top shape: 40 (40)
I0527 09:47:59.338764 25403 net.cpp:165] Memory required for data: 1016480
I0527 09:47:59.338774 25403 layer_factory.hpp:77] Creating layer conv1
I0527 09:47:59.338796 25403 net.cpp:106] Creating Layer conv1
I0527 09:47:59.338807 25403 net.cpp:454] conv1 <- data
I0527 09:47:59.338821 25403 net.cpp:411] conv1 -> conv1
I0527 09:47:59.340771 25403 net.cpp:150] Setting up conv1
I0527 09:47:59.340795 25403 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:47:59.340807 25403 net.cpp:165] Memory required for data: 12075680
I0527 09:47:59.340828 25403 layer_factory.hpp:77] Creating layer relu1
I0527 09:47:59.340843 25403 net.cpp:106] Creating Layer relu1
I0527 09:47:59.340853 25403 net.cpp:454] relu1 <- conv1
I0527 09:47:59.340867 25403 net.cpp:397] relu1 -> conv1 (in-place)
I0527 09:47:59.341361 25403 net.cpp:150] Setting up relu1
I0527 09:47:59.341377 25403 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 09:47:59.341387 25403 net.cpp:165] Memory required for data: 23134880
I0527 09:47:59.341398 25403 layer_factory.hpp:77] Creating layer pool1
I0527 09:47:59.341413 25403 net.cpp:106] Creating Layer pool1
I0527 09:47:59.341423 25403 net.cpp:454] pool1 <- conv1
I0527 09:47:59.341436 25403 net.cpp:411] pool1 -> pool1
I0527 09:47:59.341511 25403 net.cpp:150] Setting up pool1
I0527 09:47:59.341524 25403 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 09:47:59.341534 25403 net.cpp:165] Memory required for data: 28664480
I0527 09:47:59.341544 25403 layer_factory.hpp:77] Creating layer conv2
I0527 09:47:59.341562 25403 net.cpp:106] Creating Layer conv2
I0527 09:47:59.341572 25403 net.cpp:454] conv2 <- pool1
I0527 09:47:59.341586 25403 net.cpp:411] conv2 -> conv2
I0527 09:47:59.343498 25403 net.cpp:150] Setting up conv2
I0527 09:47:59.343520 25403 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:47:59.343533 25403 net.cpp:165] Memory required for data: 36613280
I0527 09:47:59.343550 25403 layer_factory.hpp:77] Creating layer relu2
I0527 09:47:59.343564 25403 net.cpp:106] Creating Layer relu2
I0527 09:47:59.343575 25403 net.cpp:454] relu2 <- conv2
I0527 09:47:59.343587 25403 net.cpp:397] relu2 -> conv2 (in-place)
I0527 09:47:59.343929 25403 net.cpp:150] Setting up relu2
I0527 09:47:59.343942 25403 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 09:47:59.343953 25403 net.cpp:165] Memory required for data: 44562080
I0527 09:47:59.343963 25403 layer_factory.hpp:77] Creating layer pool2
I0527 09:47:59.343977 25403 net.cpp:106] Creating Layer pool2
I0527 09:47:59.343986 25403 net.cpp:454] pool2 <- conv2
I0527 09:47:59.343999 25403 net.cpp:411] pool2 -> pool2
I0527 09:47:59.344071 25403 net.cpp:150] Setting up pool2
I0527 09:47:59.344084 25403 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 09:47:59.344094 25403 net.cpp:165] Memory required for data: 48536480
I0527 09:47:59.344105 25403 layer_factory.hpp:77] Creating layer conv3
I0527 09:47:59.344122 25403 net.cpp:106] Creating Layer conv3
I0527 09:47:59.344132 25403 net.cpp:454] conv3 <- pool2
I0527 09:47:59.344146 25403 net.cpp:411] conv3 -> conv3
I0527 09:47:59.346109 25403 net.cpp:150] Setting up conv3
I0527 09:47:59.346132 25403 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:47:59.346144 25403 net.cpp:165] Memory required for data: 52873120
I0527 09:47:59.346177 25403 layer_factory.hpp:77] Creating layer relu3
I0527 09:47:59.346191 25403 net.cpp:106] Creating Layer relu3
I0527 09:47:59.346201 25403 net.cpp:454] relu3 <- conv3
I0527 09:47:59.346215 25403 net.cpp:397] relu3 -> conv3 (in-place)
I0527 09:47:59.346689 25403 net.cpp:150] Setting up relu3
I0527 09:47:59.346706 25403 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 09:47:59.346716 25403 net.cpp:165] Memory required for data: 57209760
I0527 09:47:59.346726 25403 layer_factory.hpp:77] Creating layer pool3
I0527 09:47:59.346740 25403 net.cpp:106] Creating Layer pool3
I0527 09:47:59.346750 25403 net.cpp:454] pool3 <- conv3
I0527 09:47:59.346763 25403 net.cpp:411] pool3 -> pool3
I0527 09:47:59.346835 25403 net.cpp:150] Setting up pool3
I0527 09:47:59.346848 25403 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 09:47:59.346858 25403 net.cpp:165] Memory required for data: 59378080
I0527 09:47:59.346868 25403 layer_factory.hpp:77] Creating layer conv4
I0527 09:47:59.346886 25403 net.cpp:106] Creating Layer conv4
I0527 09:47:59.346897 25403 net.cpp:454] conv4 <- pool3
I0527 09:47:59.346910 25403 net.cpp:411] conv4 -> conv4
I0527 09:47:59.348971 25403 net.cpp:150] Setting up conv4
I0527 09:47:59.348994 25403 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:47:59.349006 25403 net.cpp:165] Memory required for data: 60829600
I0527 09:47:59.349021 25403 layer_factory.hpp:77] Creating layer relu4
I0527 09:47:59.349035 25403 net.cpp:106] Creating Layer relu4
I0527 09:47:59.349045 25403 net.cpp:454] relu4 <- conv4
I0527 09:47:59.349058 25403 net.cpp:397] relu4 -> conv4 (in-place)
I0527 09:47:59.349524 25403 net.cpp:150] Setting up relu4
I0527 09:47:59.349540 25403 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 09:47:59.349551 25403 net.cpp:165] Memory required for data: 62281120
I0527 09:47:59.349561 25403 layer_factory.hpp:77] Creating layer pool4
I0527 09:47:59.349575 25403 net.cpp:106] Creating Layer pool4
I0527 09:47:59.349586 25403 net.cpp:454] pool4 <- conv4
I0527 09:47:59.349598 25403 net.cpp:411] pool4 -> pool4
I0527 09:47:59.349670 25403 net.cpp:150] Setting up pool4
I0527 09:47:59.349684 25403 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 09:47:59.349694 25403 net.cpp:165] Memory required for data: 63006880
I0527 09:47:59.349704 25403 layer_factory.hpp:77] Creating layer ip1
I0527 09:47:59.349720 25403 net.cpp:106] Creating Layer ip1
I0527 09:47:59.349730 25403 net.cpp:454] ip1 <- pool4
I0527 09:47:59.349745 25403 net.cpp:411] ip1 -> ip1
I0527 09:47:59.365159 25403 net.cpp:150] Setting up ip1
I0527 09:47:59.365187 25403 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:47:59.365200 25403 net.cpp:165] Memory required for data: 63038240
I0527 09:47:59.365222 25403 layer_factory.hpp:77] Creating layer relu5
I0527 09:47:59.365237 25403 net.cpp:106] Creating Layer relu5
I0527 09:47:59.365248 25403 net.cpp:454] relu5 <- ip1
I0527 09:47:59.365262 25403 net.cpp:397] relu5 -> ip1 (in-place)
I0527 09:47:59.365608 25403 net.cpp:150] Setting up relu5
I0527 09:47:59.365623 25403 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:47:59.365633 25403 net.cpp:165] Memory required for data: 63069600
I0527 09:47:59.365643 25403 layer_factory.hpp:77] Creating layer drop1
I0527 09:47:59.365663 25403 net.cpp:106] Creating Layer drop1
I0527 09:47:59.365672 25403 net.cpp:454] drop1 <- ip1
I0527 09:47:59.365686 25403 net.cpp:397] drop1 -> ip1 (in-place)
I0527 09:47:59.365731 25403 net.cpp:150] Setting up drop1
I0527 09:47:59.365744 25403 net.cpp:157] Top shape: 40 196 (7840)
I0527 09:47:59.365754 25403 net.cpp:165] Memory required for data: 63100960
I0527 09:47:59.365764 25403 layer_factory.hpp:77] Creating layer ip2
I0527 09:47:59.365779 25403 net.cpp:106] Creating Layer ip2
I0527 09:47:59.365789 25403 net.cpp:454] ip2 <- ip1
I0527 09:47:59.365803 25403 net.cpp:411] ip2 -> ip2
I0527 09:47:59.366286 25403 net.cpp:150] Setting up ip2
I0527 09:47:59.366300 25403 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:47:59.366310 25403 net.cpp:165] Memory required for data: 63116640
I0527 09:47:59.366327 25403 layer_factory.hpp:77] Creating layer relu6
I0527 09:47:59.366351 25403 net.cpp:106] Creating Layer relu6
I0527 09:47:59.366361 25403 net.cpp:454] relu6 <- ip2
I0527 09:47:59.366374 25403 net.cpp:397] relu6 -> ip2 (in-place)
I0527 09:47:59.366909 25403 net.cpp:150] Setting up relu6
I0527 09:47:59.366925 25403 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:47:59.366936 25403 net.cpp:165] Memory required for data: 63132320
I0527 09:47:59.366946 25403 layer_factory.hpp:77] Creating layer drop2
I0527 09:47:59.366961 25403 net.cpp:106] Creating Layer drop2
I0527 09:47:59.366971 25403 net.cpp:454] drop2 <- ip2
I0527 09:47:59.366983 25403 net.cpp:397] drop2 -> ip2 (in-place)
I0527 09:47:59.367027 25403 net.cpp:150] Setting up drop2
I0527 09:47:59.367041 25403 net.cpp:157] Top shape: 40 98 (3920)
I0527 09:47:59.367051 25403 net.cpp:165] Memory required for data: 63148000
I0527 09:47:59.367060 25403 layer_factory.hpp:77] Creating layer ip3
I0527 09:47:59.367074 25403 net.cpp:106] Creating Layer ip3
I0527 09:47:59.367084 25403 net.cpp:454] ip3 <- ip2
I0527 09:47:59.367099 25403 net.cpp:411] ip3 -> ip3
I0527 09:47:59.367323 25403 net.cpp:150] Setting up ip3
I0527 09:47:59.367336 25403 net.cpp:157] Top shape: 40 11 (440)
I0527 09:47:59.367347 25403 net.cpp:165] Memory required for data: 63149760
I0527 09:47:59.367362 25403 layer_factory.hpp:77] Creating layer drop3
I0527 09:47:59.367375 25403 net.cpp:106] Creating Layer drop3
I0527 09:47:59.367385 25403 net.cpp:454] drop3 <- ip3
I0527 09:47:59.367398 25403 net.cpp:397] drop3 -> ip3 (in-place)
I0527 09:47:59.367439 25403 net.cpp:150] Setting up drop3
I0527 09:47:59.367451 25403 net.cpp:157] Top shape: 40 11 (440)
I0527 09:47:59.367461 25403 net.cpp:165] Memory required for data: 63151520
I0527 09:47:59.367471 25403 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0527 09:47:59.367485 25403 net.cpp:106] Creating Layer ip3_drop3_0_split
I0527 09:47:59.367494 25403 net.cpp:454] ip3_drop3_0_split <- ip3
I0527 09:47:59.367507 25403 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0527 09:47:59.367523 25403 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0527 09:47:59.367599 25403 net.cpp:150] Setting up ip3_drop3_0_split
I0527 09:47:59.367611 25403 net.cpp:157] Top shape: 40 11 (440)
I0527 09:47:59.367624 25403 net.cpp:157] Top shape: 40 11 (440)
I0527 09:47:59.367635 25403 net.cpp:165] Memory required for data: 63155040
I0527 09:47:59.367645 25403 layer_factory.hpp:77] Creating layer accuracy
I0527 09:47:59.367666 25403 net.cpp:106] Creating Layer accuracy
I0527 09:47:59.367676 25403 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0527 09:47:59.367686 25403 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0527 09:47:59.367699 25403 net.cpp:411] accuracy -> accuracy
I0527 09:47:59.367723 25403 net.cpp:150] Setting up accuracy
I0527 09:47:59.367736 25403 net.cpp:157] Top shape: (1)
I0527 09:47:59.367745 25403 net.cpp:165] Memory required for data: 63155044
I0527 09:47:59.367755 25403 layer_factory.hpp:77] Creating layer loss
I0527 09:47:59.367769 25403 net.cpp:106] Creating Layer loss
I0527 09:47:59.367779 25403 net.cpp:454] loss <- ip3_drop3_0_split_1
I0527 09:47:59.367797 25403 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0527 09:47:59.367811 25403 net.cpp:411] loss -> loss
I0527 09:47:59.367830 25403 layer_factory.hpp:77] Creating layer loss
I0527 09:47:59.368315 25403 net.cpp:150] Setting up loss
I0527 09:47:59.368329 25403 net.cpp:157] Top shape: (1)
I0527 09:47:59.368338 25403 net.cpp:160]     with loss weight 1
I0527 09:47:59.368360 25403 net.cpp:165] Memory required for data: 63155048
I0527 09:47:59.368371 25403 net.cpp:226] loss needs backward computation.
I0527 09:47:59.368381 25403 net.cpp:228] accuracy does not need backward computation.
I0527 09:47:59.368392 25403 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0527 09:47:59.368403 25403 net.cpp:226] drop3 needs backward computation.
I0527 09:47:59.368413 25403 net.cpp:226] ip3 needs backward computation.
I0527 09:47:59.368424 25403 net.cpp:226] drop2 needs backward computation.
I0527 09:47:59.368433 25403 net.cpp:226] relu6 needs backward computation.
I0527 09:47:59.368451 25403 net.cpp:226] ip2 needs backward computation.
I0527 09:47:59.368463 25403 net.cpp:226] drop1 needs backward computation.
I0527 09:47:59.368472 25403 net.cpp:226] relu5 needs backward computation.
I0527 09:47:59.368481 25403 net.cpp:226] ip1 needs backward computation.
I0527 09:47:59.368491 25403 net.cpp:226] pool4 needs backward computation.
I0527 09:47:59.368502 25403 net.cpp:226] relu4 needs backward computation.
I0527 09:47:59.368512 25403 net.cpp:226] conv4 needs backward computation.
I0527 09:47:59.368521 25403 net.cpp:226] pool3 needs backward computation.
I0527 09:47:59.368531 25403 net.cpp:226] relu3 needs backward computation.
I0527 09:47:59.368541 25403 net.cpp:226] conv3 needs backward computation.
I0527 09:47:59.368552 25403 net.cpp:226] pool2 needs backward computation.
I0527 09:47:59.368562 25403 net.cpp:226] relu2 needs backward computation.
I0527 09:47:59.368572 25403 net.cpp:226] conv2 needs backward computation.
I0527 09:47:59.368583 25403 net.cpp:226] pool1 needs backward computation.
I0527 09:47:59.368593 25403 net.cpp:226] relu1 needs backward computation.
I0527 09:47:59.368603 25403 net.cpp:226] conv1 needs backward computation.
I0527 09:47:59.368615 25403 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0527 09:47:59.368628 25403 net.cpp:228] data_hdf5 does not need backward computation.
I0527 09:47:59.368638 25403 net.cpp:270] This network produces output accuracy
I0527 09:47:59.368649 25403 net.cpp:270] This network produces output loss
I0527 09:47:59.368677 25403 net.cpp:283] Network initialization done.
I0527 09:47:59.368810 25403 solver.cpp:60] Solver scaffolding done.
I0527 09:47:59.369946 25403 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_165000.solverstate
I0527 09:47:59.590865 25403 sgd_solver.cpp:318] SGDSolver: restoring history
I0527 09:47:59.596365 25403 caffe.cpp:212] Starting Optimization
I0527 09:47:59.596410 25403 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0527 09:47:59.596421 25403 solver.cpp:289] Learning Rate Policy: fixed
I0527 09:47:59.597800 25403 solver.cpp:341] Iteration 165000, Testing net (#0)
I0527 09:48:49.068102 25403 solver.cpp:409]     Test net output #0: accuracy = 0.896873
I0527 09:48:49.068271 25403 solver.cpp:409]     Test net output #1: loss = 0.340618 (* 1 = 0.340618 loss)
I0527 09:48:49.090914 25403 solver.cpp:237] Iteration 165000, loss = 0.788923
I0527 09:48:49.090951 25403 solver.cpp:253]     Train net output #0: loss = 0.788923 (* 1 = 0.788923 loss)
I0527 09:48:49.090970 25403 sgd_solver.cpp:106] Iteration 165000, lr = 0.0025
I0527 09:48:58.951081 25403 solver.cpp:237] Iteration 165375, loss = 0.905453
I0527 09:48:58.951117 25403 solver.cpp:253]     Train net output #0: loss = 0.905453 (* 1 = 0.905453 loss)
I0527 09:48:58.951133 25403 sgd_solver.cpp:106] Iteration 165375, lr = 0.0025
I0527 09:49:08.824828 25403 solver.cpp:237] Iteration 165750, loss = 1.51866
I0527 09:49:08.824872 25403 solver.cpp:253]     Train net output #0: loss = 1.51866 (* 1 = 1.51866 loss)
I0527 09:49:08.824890 25403 sgd_solver.cpp:106] Iteration 165750, lr = 0.0025
I0527 09:49:18.701694 25403 solver.cpp:237] Iteration 166125, loss = 1.25791
I0527 09:49:18.701730 25403 solver.cpp:253]     Train net output #0: loss = 1.25791 (* 1 = 1.25791 loss)
I0527 09:49:18.701746 25403 sgd_solver.cpp:106] Iteration 166125, lr = 0.0025
I0527 09:49:28.581295 25403 solver.cpp:237] Iteration 166500, loss = 0.91734
I0527 09:49:28.581442 25403 solver.cpp:253]     Train net output #0: loss = 0.91734 (* 1 = 0.91734 loss)
I0527 09:49:28.581456 25403 sgd_solver.cpp:106] Iteration 166500, lr = 0.0025
I0527 09:49:38.460680 25403 solver.cpp:237] Iteration 166875, loss = 1.01839
I0527 09:49:38.460724 25403 solver.cpp:253]     Train net output #0: loss = 1.01839 (* 1 = 1.01839 loss)
I0527 09:49:38.460746 25403 sgd_solver.cpp:106] Iteration 166875, lr = 0.0025
I0527 09:49:48.337579 25403 solver.cpp:237] Iteration 167250, loss = 1.09767
I0527 09:49:48.337615 25403 solver.cpp:253]     Train net output #0: loss = 1.09767 (* 1 = 1.09767 loss)
I0527 09:49:48.337628 25403 sgd_solver.cpp:106] Iteration 167250, lr = 0.0025
I0527 09:50:20.402281 25403 solver.cpp:237] Iteration 167625, loss = 1.26214
I0527 09:50:20.402448 25403 solver.cpp:253]     Train net output #0: loss = 1.26214 (* 1 = 1.26214 loss)
I0527 09:50:20.402464 25403 sgd_solver.cpp:106] Iteration 167625, lr = 0.0025
I0527 09:50:30.279752 25403 solver.cpp:237] Iteration 168000, loss = 1.23479
I0527 09:50:30.279803 25403 solver.cpp:253]     Train net output #0: loss = 1.23479 (* 1 = 1.23479 loss)
I0527 09:50:30.279817 25403 sgd_solver.cpp:106] Iteration 168000, lr = 0.0025
I0527 09:50:40.155939 25403 solver.cpp:237] Iteration 168375, loss = 1.18299
I0527 09:50:40.155974 25403 solver.cpp:253]     Train net output #0: loss = 1.18299 (* 1 = 1.18299 loss)
I0527 09:50:40.155990 25403 sgd_solver.cpp:106] Iteration 168375, lr = 0.0025
I0527 09:50:50.009508 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_168750.caffemodel
I0527 09:50:50.067503 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_168750.solverstate
I0527 09:50:50.101861 25403 solver.cpp:237] Iteration 168750, loss = 0.981312
I0527 09:50:50.101912 25403 solver.cpp:253]     Train net output #0: loss = 0.981312 (* 1 = 0.981312 loss)
I0527 09:50:50.101925 25403 sgd_solver.cpp:106] Iteration 168750, lr = 0.0025
I0527 09:50:59.975488 25403 solver.cpp:237] Iteration 169125, loss = 1.48942
I0527 09:50:59.975630 25403 solver.cpp:253]     Train net output #0: loss = 1.48942 (* 1 = 1.48942 loss)
I0527 09:50:59.975643 25403 sgd_solver.cpp:106] Iteration 169125, lr = 0.0025
I0527 09:51:09.856125 25403 solver.cpp:237] Iteration 169500, loss = 1.0626
I0527 09:51:09.856160 25403 solver.cpp:253]     Train net output #0: loss = 1.0626 (* 1 = 1.0626 loss)
I0527 09:51:09.856178 25403 sgd_solver.cpp:106] Iteration 169500, lr = 0.0025
I0527 09:51:19.728204 25403 solver.cpp:237] Iteration 169875, loss = 1.06971
I0527 09:51:19.728247 25403 solver.cpp:253]     Train net output #0: loss = 1.06971 (* 1 = 1.06971 loss)
I0527 09:51:19.728265 25403 sgd_solver.cpp:106] Iteration 169875, lr = 0.0025
I0527 09:51:51.796591 25403 solver.cpp:237] Iteration 170250, loss = 1.03159
I0527 09:51:51.796771 25403 solver.cpp:253]     Train net output #0: loss = 1.03159 (* 1 = 1.03159 loss)
I0527 09:51:51.796784 25403 sgd_solver.cpp:106] Iteration 170250, lr = 0.0025
I0527 09:52:01.678836 25403 solver.cpp:237] Iteration 170625, loss = 1.02742
I0527 09:52:01.678884 25403 solver.cpp:253]     Train net output #0: loss = 1.02742 (* 1 = 1.02742 loss)
I0527 09:52:01.678900 25403 sgd_solver.cpp:106] Iteration 170625, lr = 0.0025
I0527 09:52:11.559583 25403 solver.cpp:237] Iteration 171000, loss = 1.18081
I0527 09:52:11.559619 25403 solver.cpp:253]     Train net output #0: loss = 1.18081 (* 1 = 1.18081 loss)
I0527 09:52:11.559633 25403 sgd_solver.cpp:106] Iteration 171000, lr = 0.0025
I0527 09:52:21.439570 25403 solver.cpp:237] Iteration 171375, loss = 1.09134
I0527 09:52:21.439605 25403 solver.cpp:253]     Train net output #0: loss = 1.09134 (* 1 = 1.09134 loss)
I0527 09:52:21.439618 25403 sgd_solver.cpp:106] Iteration 171375, lr = 0.0025
I0527 09:52:31.315518 25403 solver.cpp:237] Iteration 171750, loss = 1.07061
I0527 09:52:31.315673 25403 solver.cpp:253]     Train net output #0: loss = 1.07061 (* 1 = 1.07061 loss)
I0527 09:52:31.315687 25403 sgd_solver.cpp:106] Iteration 171750, lr = 0.0025
I0527 09:52:41.196004 25403 solver.cpp:237] Iteration 172125, loss = 1.26155
I0527 09:52:41.196038 25403 solver.cpp:253]     Train net output #0: loss = 1.26155 (* 1 = 1.26155 loss)
I0527 09:52:41.196056 25403 sgd_solver.cpp:106] Iteration 172125, lr = 0.0025
I0527 09:52:51.046044 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_172500.caffemodel
I0527 09:52:51.103283 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_172500.solverstate
I0527 09:52:51.133827 25403 solver.cpp:341] Iteration 172500, Testing net (#0)
I0527 09:53:39.674619 25403 solver.cpp:409]     Test net output #0: accuracy = 0.900613
I0527 09:53:39.674787 25403 solver.cpp:409]     Test net output #1: loss = 0.32163 (* 1 = 0.32163 loss)
I0527 09:54:01.814174 25403 solver.cpp:237] Iteration 172500, loss = 1.17399
I0527 09:54:01.814231 25403 solver.cpp:253]     Train net output #0: loss = 1.17399 (* 1 = 1.17399 loss)
I0527 09:54:01.814246 25403 sgd_solver.cpp:106] Iteration 172500, lr = 0.0025
I0527 09:54:11.699069 25403 solver.cpp:237] Iteration 172875, loss = 1.17341
I0527 09:54:11.699224 25403 solver.cpp:253]     Train net output #0: loss = 1.17341 (* 1 = 1.17341 loss)
I0527 09:54:11.699239 25403 sgd_solver.cpp:106] Iteration 172875, lr = 0.0025
I0527 09:54:21.582515 25403 solver.cpp:237] Iteration 173250, loss = 0.976504
I0527 09:54:21.582551 25403 solver.cpp:253]     Train net output #0: loss = 0.976504 (* 1 = 0.976504 loss)
I0527 09:54:21.582566 25403 sgd_solver.cpp:106] Iteration 173250, lr = 0.0025
I0527 09:54:31.461415 25403 solver.cpp:237] Iteration 173625, loss = 1.17323
I0527 09:54:31.461467 25403 solver.cpp:253]     Train net output #0: loss = 1.17323 (* 1 = 1.17323 loss)
I0527 09:54:31.461480 25403 sgd_solver.cpp:106] Iteration 173625, lr = 0.0025
I0527 09:54:41.343930 25403 solver.cpp:237] Iteration 174000, loss = 0.833578
I0527 09:54:41.343966 25403 solver.cpp:253]     Train net output #0: loss = 0.833578 (* 1 = 0.833578 loss)
I0527 09:54:41.343997 25403 sgd_solver.cpp:106] Iteration 174000, lr = 0.0025
I0527 09:54:51.228688 25403 solver.cpp:237] Iteration 174375, loss = 1.08613
I0527 09:54:51.228837 25403 solver.cpp:253]     Train net output #0: loss = 1.08613 (* 1 = 1.08613 loss)
I0527 09:54:51.228850 25403 sgd_solver.cpp:106] Iteration 174375, lr = 0.0025
I0527 09:55:01.113070 25403 solver.cpp:237] Iteration 174750, loss = 0.946484
I0527 09:55:01.113113 25403 solver.cpp:253]     Train net output #0: loss = 0.946484 (* 1 = 0.946484 loss)
I0527 09:55:01.113131 25403 sgd_solver.cpp:106] Iteration 174750, lr = 0.0025
I0527 09:55:33.187409 25403 solver.cpp:237] Iteration 175125, loss = 1.09774
I0527 09:55:33.187587 25403 solver.cpp:253]     Train net output #0: loss = 1.09774 (* 1 = 1.09774 loss)
I0527 09:55:33.187602 25403 sgd_solver.cpp:106] Iteration 175125, lr = 0.0025
I0527 09:55:43.062847 25403 solver.cpp:237] Iteration 175500, loss = 0.921351
I0527 09:55:43.062883 25403 solver.cpp:253]     Train net output #0: loss = 0.921351 (* 1 = 0.921351 loss)
I0527 09:55:43.062899 25403 sgd_solver.cpp:106] Iteration 175500, lr = 0.0025
I0527 09:55:52.950264 25403 solver.cpp:237] Iteration 175875, loss = 1.54306
I0527 09:55:52.950307 25403 solver.cpp:253]     Train net output #0: loss = 1.54306 (* 1 = 1.54306 loss)
I0527 09:55:52.950326 25403 sgd_solver.cpp:106] Iteration 175875, lr = 0.0025
I0527 09:56:02.844568 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_176250.caffemodel
I0527 09:56:02.902786 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_176250.solverstate
I0527 09:56:02.938345 25403 solver.cpp:237] Iteration 176250, loss = 0.875936
I0527 09:56:02.938400 25403 solver.cpp:253]     Train net output #0: loss = 0.875936 (* 1 = 0.875936 loss)
I0527 09:56:02.938416 25403 sgd_solver.cpp:106] Iteration 176250, lr = 0.0025
I0527 09:56:12.860602 25403 solver.cpp:237] Iteration 176625, loss = 1.21894
I0527 09:56:12.860765 25403 solver.cpp:253]     Train net output #0: loss = 1.21894 (* 1 = 1.21894 loss)
I0527 09:56:12.860780 25403 sgd_solver.cpp:106] Iteration 176625, lr = 0.0025
I0527 09:56:22.778517 25403 solver.cpp:237] Iteration 177000, loss = 0.973163
I0527 09:56:22.778553 25403 solver.cpp:253]     Train net output #0: loss = 0.973163 (* 1 = 0.973163 loss)
I0527 09:56:22.778568 25403 sgd_solver.cpp:106] Iteration 177000, lr = 0.0025
I0527 09:56:32.698523 25403 solver.cpp:237] Iteration 177375, loss = 1.1071
I0527 09:56:32.698557 25403 solver.cpp:253]     Train net output #0: loss = 1.1071 (* 1 = 1.1071 loss)
I0527 09:56:32.698571 25403 sgd_solver.cpp:106] Iteration 177375, lr = 0.0025
I0527 09:57:04.816462 25403 solver.cpp:237] Iteration 177750, loss = 0.965746
I0527 09:57:04.816630 25403 solver.cpp:253]     Train net output #0: loss = 0.965746 (* 1 = 0.965746 loss)
I0527 09:57:04.816647 25403 sgd_solver.cpp:106] Iteration 177750, lr = 0.0025
I0527 09:57:14.738421 25403 solver.cpp:237] Iteration 178125, loss = 1.27762
I0527 09:57:14.738457 25403 solver.cpp:253]     Train net output #0: loss = 1.27762 (* 1 = 1.27762 loss)
I0527 09:57:14.738471 25403 sgd_solver.cpp:106] Iteration 178125, lr = 0.0025
I0527 09:57:24.658010 25403 solver.cpp:237] Iteration 178500, loss = 1.30677
I0527 09:57:24.658046 25403 solver.cpp:253]     Train net output #0: loss = 1.30677 (* 1 = 1.30677 loss)
I0527 09:57:24.658059 25403 sgd_solver.cpp:106] Iteration 178500, lr = 0.0025
I0527 09:57:34.575352 25403 solver.cpp:237] Iteration 178875, loss = 1.15039
I0527 09:57:34.575400 25403 solver.cpp:253]     Train net output #0: loss = 1.15039 (* 1 = 1.15039 loss)
I0527 09:57:34.575417 25403 sgd_solver.cpp:106] Iteration 178875, lr = 0.0025
I0527 09:57:44.493732 25403 solver.cpp:237] Iteration 179250, loss = 1.03175
I0527 09:57:44.493871 25403 solver.cpp:253]     Train net output #0: loss = 1.03175 (* 1 = 1.03175 loss)
I0527 09:57:44.493885 25403 sgd_solver.cpp:106] Iteration 179250, lr = 0.0025
I0527 09:57:54.413036 25403 solver.cpp:237] Iteration 179625, loss = 0.804727
I0527 09:57:54.413089 25403 solver.cpp:253]     Train net output #0: loss = 0.804727 (* 1 = 0.804727 loss)
I0527 09:57:54.413105 25403 sgd_solver.cpp:106] Iteration 179625, lr = 0.0025
I0527 09:58:04.301049 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_180000.caffemodel
I0527 09:58:04.360098 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_180000.solverstate
I0527 09:58:04.387625 25403 solver.cpp:341] Iteration 180000, Testing net (#0)
I0527 09:59:13.810844 25403 solver.cpp:409]     Test net output #0: accuracy = 0.900973
I0527 09:59:13.811014 25403 solver.cpp:409]     Test net output #1: loss = 0.327326 (* 1 = 0.327326 loss)
I0527 09:59:36.027902 25403 solver.cpp:237] Iteration 180000, loss = 0.940493
I0527 09:59:36.027961 25403 solver.cpp:253]     Train net output #0: loss = 0.940493 (* 1 = 0.940493 loss)
I0527 09:59:36.027976 25403 sgd_solver.cpp:106] Iteration 180000, lr = 0.0025
I0527 09:59:45.897970 25403 solver.cpp:237] Iteration 180375, loss = 0.820398
I0527 09:59:45.898115 25403 solver.cpp:253]     Train net output #0: loss = 0.820398 (* 1 = 0.820398 loss)
I0527 09:59:45.898130 25403 sgd_solver.cpp:106] Iteration 180375, lr = 0.0025
I0527 09:59:55.777186 25403 solver.cpp:237] Iteration 180750, loss = 1.59274
I0527 09:59:55.777220 25403 solver.cpp:253]     Train net output #0: loss = 1.59274 (* 1 = 1.59274 loss)
I0527 09:59:55.777237 25403 sgd_solver.cpp:106] Iteration 180750, lr = 0.0025
I0527 10:00:05.647433 25403 solver.cpp:237] Iteration 181125, loss = 1.13852
I0527 10:00:05.647476 25403 solver.cpp:253]     Train net output #0: loss = 1.13852 (* 1 = 1.13852 loss)
I0527 10:00:05.647496 25403 sgd_solver.cpp:106] Iteration 181125, lr = 0.0025
I0527 10:00:15.521250 25403 solver.cpp:237] Iteration 181500, loss = 1.28431
I0527 10:00:15.521284 25403 solver.cpp:253]     Train net output #0: loss = 1.28431 (* 1 = 1.28431 loss)
I0527 10:00:15.521298 25403 sgd_solver.cpp:106] Iteration 181500, lr = 0.0025
I0527 10:00:25.386844 25403 solver.cpp:237] Iteration 181875, loss = 1.13833
I0527 10:00:25.386999 25403 solver.cpp:253]     Train net output #0: loss = 1.13833 (* 1 = 1.13833 loss)
I0527 10:00:25.387013 25403 sgd_solver.cpp:106] Iteration 181875, lr = 0.0025
I0527 10:00:35.251960 25403 solver.cpp:237] Iteration 182250, loss = 1.16833
I0527 10:00:35.251994 25403 solver.cpp:253]     Train net output #0: loss = 1.16833 (* 1 = 1.16833 loss)
I0527 10:00:35.252012 25403 sgd_solver.cpp:106] Iteration 182250, lr = 0.0025
I0527 10:01:07.321516 25403 solver.cpp:237] Iteration 182625, loss = 1.32407
I0527 10:01:07.321679 25403 solver.cpp:253]     Train net output #0: loss = 1.32407 (* 1 = 1.32407 loss)
I0527 10:01:07.321696 25403 sgd_solver.cpp:106] Iteration 182625, lr = 0.0025
I0527 10:01:17.189146 25403 solver.cpp:237] Iteration 183000, loss = 1.08345
I0527 10:01:17.189193 25403 solver.cpp:253]     Train net output #0: loss = 1.08345 (* 1 = 1.08345 loss)
I0527 10:01:17.189213 25403 sgd_solver.cpp:106] Iteration 183000, lr = 0.0025
I0527 10:01:27.062475 25403 solver.cpp:237] Iteration 183375, loss = 0.95834
I0527 10:01:27.062511 25403 solver.cpp:253]     Train net output #0: loss = 0.95834 (* 1 = 0.95834 loss)
I0527 10:01:27.062528 25403 sgd_solver.cpp:106] Iteration 183375, lr = 0.0025
I0527 10:01:36.905211 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_183750.caffemodel
I0527 10:01:36.963663 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_183750.solverstate
I0527 10:01:36.999712 25403 solver.cpp:237] Iteration 183750, loss = 1.27909
I0527 10:01:36.999765 25403 solver.cpp:253]     Train net output #0: loss = 1.27909 (* 1 = 1.27909 loss)
I0527 10:01:36.999779 25403 sgd_solver.cpp:106] Iteration 183750, lr = 0.0025
I0527 10:01:46.870875 25403 solver.cpp:237] Iteration 184125, loss = 1.04322
I0527 10:01:46.871021 25403 solver.cpp:253]     Train net output #0: loss = 1.04322 (* 1 = 1.04322 loss)
I0527 10:01:46.871036 25403 sgd_solver.cpp:106] Iteration 184125, lr = 0.0025
I0527 10:01:56.746068 25403 solver.cpp:237] Iteration 184500, loss = 1.84765
I0527 10:01:56.746103 25403 solver.cpp:253]     Train net output #0: loss = 1.84765 (* 1 = 1.84765 loss)
I0527 10:01:56.746117 25403 sgd_solver.cpp:106] Iteration 184500, lr = 0.0025
I0527 10:02:06.620182 25403 solver.cpp:237] Iteration 184875, loss = 1.10154
I0527 10:02:06.620229 25403 solver.cpp:253]     Train net output #0: loss = 1.10154 (* 1 = 1.10154 loss)
I0527 10:02:06.620251 25403 sgd_solver.cpp:106] Iteration 184875, lr = 0.0025
I0527 10:02:38.721562 25403 solver.cpp:237] Iteration 185250, loss = 0.949148
I0527 10:02:38.721745 25403 solver.cpp:253]     Train net output #0: loss = 0.949148 (* 1 = 0.949148 loss)
I0527 10:02:38.721760 25403 sgd_solver.cpp:106] Iteration 185250, lr = 0.0025
I0527 10:02:48.595880 25403 solver.cpp:237] Iteration 185625, loss = 1.17317
I0527 10:02:48.595916 25403 solver.cpp:253]     Train net output #0: loss = 1.17317 (* 1 = 1.17317 loss)
I0527 10:02:48.595932 25403 sgd_solver.cpp:106] Iteration 185625, lr = 0.0025
I0527 10:02:58.459538 25403 solver.cpp:237] Iteration 186000, loss = 1.21676
I0527 10:02:58.459585 25403 solver.cpp:253]     Train net output #0: loss = 1.21676 (* 1 = 1.21676 loss)
I0527 10:02:58.459601 25403 sgd_solver.cpp:106] Iteration 186000, lr = 0.0025
I0527 10:03:08.324662 25403 solver.cpp:237] Iteration 186375, loss = 1.30464
I0527 10:03:08.324698 25403 solver.cpp:253]     Train net output #0: loss = 1.30464 (* 1 = 1.30464 loss)
I0527 10:03:08.324712 25403 sgd_solver.cpp:106] Iteration 186375, lr = 0.0025
I0527 10:03:18.193701 25403 solver.cpp:237] Iteration 186750, loss = 0.903117
I0527 10:03:18.193863 25403 solver.cpp:253]     Train net output #0: loss = 0.903117 (* 1 = 0.903117 loss)
I0527 10:03:18.193877 25403 sgd_solver.cpp:106] Iteration 186750, lr = 0.0025
I0527 10:03:28.069058 25403 solver.cpp:237] Iteration 187125, loss = 1.2467
I0527 10:03:28.069094 25403 solver.cpp:253]     Train net output #0: loss = 1.2467 (* 1 = 1.2467 loss)
I0527 10:03:28.069110 25403 sgd_solver.cpp:106] Iteration 187125, lr = 0.0025
I0527 10:03:37.911466 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_187500.caffemodel
I0527 10:03:37.972391 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_187500.solverstate
I0527 10:03:37.997774 25403 solver.cpp:341] Iteration 187500, Testing net (#0)
I0527 10:04:26.220053 25403 solver.cpp:409]     Test net output #0: accuracy = 0.895093
I0527 10:04:26.220219 25403 solver.cpp:409]     Test net output #1: loss = 0.341153 (* 1 = 0.341153 loss)
I0527 10:04:48.424603 25403 solver.cpp:237] Iteration 187500, loss = 1.11706
I0527 10:04:48.424659 25403 solver.cpp:253]     Train net output #0: loss = 1.11706 (* 1 = 1.11706 loss)
I0527 10:04:48.424674 25403 sgd_solver.cpp:106] Iteration 187500, lr = 0.0025
I0527 10:04:58.190263 25403 solver.cpp:237] Iteration 187875, loss = 1.01484
I0527 10:04:58.190426 25403 solver.cpp:253]     Train net output #0: loss = 1.01484 (* 1 = 1.01484 loss)
I0527 10:04:58.190440 25403 sgd_solver.cpp:106] Iteration 187875, lr = 0.0025
I0527 10:05:07.946126 25403 solver.cpp:237] Iteration 188250, loss = 1.64343
I0527 10:05:07.946161 25403 solver.cpp:253]     Train net output #0: loss = 1.64343 (* 1 = 1.64343 loss)
I0527 10:05:07.946176 25403 sgd_solver.cpp:106] Iteration 188250, lr = 0.0025
I0527 10:05:17.702992 25403 solver.cpp:237] Iteration 188625, loss = 1.40158
I0527 10:05:17.703028 25403 solver.cpp:253]     Train net output #0: loss = 1.40158 (* 1 = 1.40158 loss)
I0527 10:05:17.703042 25403 sgd_solver.cpp:106] Iteration 188625, lr = 0.0025
I0527 10:05:27.452961 25403 solver.cpp:237] Iteration 189000, loss = 1.21544
I0527 10:05:27.453008 25403 solver.cpp:253]     Train net output #0: loss = 1.21544 (* 1 = 1.21544 loss)
I0527 10:05:27.453022 25403 sgd_solver.cpp:106] Iteration 189000, lr = 0.0025
I0527 10:05:37.210460 25403 solver.cpp:237] Iteration 189375, loss = 1.25397
I0527 10:05:37.210614 25403 solver.cpp:253]     Train net output #0: loss = 1.25397 (* 1 = 1.25397 loss)
I0527 10:05:37.210629 25403 sgd_solver.cpp:106] Iteration 189375, lr = 0.0025
I0527 10:05:46.963567 25403 solver.cpp:237] Iteration 189750, loss = 1.04768
I0527 10:05:46.963614 25403 solver.cpp:253]     Train net output #0: loss = 1.04768 (* 1 = 1.04768 loss)
I0527 10:05:46.963629 25403 sgd_solver.cpp:106] Iteration 189750, lr = 0.0025
I0527 10:06:18.975494 25403 solver.cpp:237] Iteration 190125, loss = 1.33824
I0527 10:06:18.975668 25403 solver.cpp:253]     Train net output #0: loss = 1.33824 (* 1 = 1.33824 loss)
I0527 10:06:18.975684 25403 sgd_solver.cpp:106] Iteration 190125, lr = 0.0025
I0527 10:06:28.723783 25403 solver.cpp:237] Iteration 190500, loss = 0.900404
I0527 10:06:28.723822 25403 solver.cpp:253]     Train net output #0: loss = 0.900404 (* 1 = 0.900404 loss)
I0527 10:06:28.723836 25403 sgd_solver.cpp:106] Iteration 190500, lr = 0.0025
I0527 10:06:38.481964 25403 solver.cpp:237] Iteration 190875, loss = 1.23049
I0527 10:06:38.482012 25403 solver.cpp:253]     Train net output #0: loss = 1.23049 (* 1 = 1.23049 loss)
I0527 10:06:38.482028 25403 sgd_solver.cpp:106] Iteration 190875, lr = 0.0025
I0527 10:06:48.210902 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_191250.caffemodel
I0527 10:06:48.266660 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_191250.solverstate
I0527 10:06:48.300602 25403 solver.cpp:237] Iteration 191250, loss = 1.06728
I0527 10:06:48.300649 25403 solver.cpp:253]     Train net output #0: loss = 1.06728 (* 1 = 1.06728 loss)
I0527 10:06:48.300668 25403 sgd_solver.cpp:106] Iteration 191250, lr = 0.0025
I0527 10:06:58.058780 25403 solver.cpp:237] Iteration 191625, loss = 1.14388
I0527 10:06:58.058926 25403 solver.cpp:253]     Train net output #0: loss = 1.14388 (* 1 = 1.14388 loss)
I0527 10:06:58.058940 25403 sgd_solver.cpp:106] Iteration 191625, lr = 0.0025
I0527 10:07:07.812872 25403 solver.cpp:237] Iteration 192000, loss = 1.36508
I0527 10:07:07.812921 25403 solver.cpp:253]     Train net output #0: loss = 1.36508 (* 1 = 1.36508 loss)
I0527 10:07:07.812939 25403 sgd_solver.cpp:106] Iteration 192000, lr = 0.0025
I0527 10:07:17.574179 25403 solver.cpp:237] Iteration 192375, loss = 1.18595
I0527 10:07:17.574213 25403 solver.cpp:253]     Train net output #0: loss = 1.18595 (* 1 = 1.18595 loss)
I0527 10:07:17.574228 25403 sgd_solver.cpp:106] Iteration 192375, lr = 0.0025
I0527 10:07:49.540302 25403 solver.cpp:237] Iteration 192750, loss = 1.0984
I0527 10:07:49.540475 25403 solver.cpp:253]     Train net output #0: loss = 1.0984 (* 1 = 1.0984 loss)
I0527 10:07:49.540490 25403 sgd_solver.cpp:106] Iteration 192750, lr = 0.0025
I0527 10:07:59.296213 25403 solver.cpp:237] Iteration 193125, loss = 1.67558
I0527 10:07:59.296260 25403 solver.cpp:253]     Train net output #0: loss = 1.67558 (* 1 = 1.67558 loss)
I0527 10:07:59.296279 25403 sgd_solver.cpp:106] Iteration 193125, lr = 0.0025
I0527 10:08:09.048419 25403 solver.cpp:237] Iteration 193500, loss = 1.32352
I0527 10:08:09.048454 25403 solver.cpp:253]     Train net output #0: loss = 1.32352 (* 1 = 1.32352 loss)
I0527 10:08:09.048470 25403 sgd_solver.cpp:106] Iteration 193500, lr = 0.0025
I0527 10:08:18.805675 25403 solver.cpp:237] Iteration 193875, loss = 1.01455
I0527 10:08:18.805716 25403 solver.cpp:253]     Train net output #0: loss = 1.01455 (* 1 = 1.01455 loss)
I0527 10:08:18.805735 25403 sgd_solver.cpp:106] Iteration 193875, lr = 0.0025
I0527 10:08:28.557147 25403 solver.cpp:237] Iteration 194250, loss = 1.17058
I0527 10:08:28.557291 25403 solver.cpp:253]     Train net output #0: loss = 1.17058 (* 1 = 1.17058 loss)
I0527 10:08:28.557306 25403 sgd_solver.cpp:106] Iteration 194250, lr = 0.0025
I0527 10:08:38.311535 25403 solver.cpp:237] Iteration 194625, loss = 1.21252
I0527 10:08:38.311570 25403 solver.cpp:253]     Train net output #0: loss = 1.21252 (* 1 = 1.21252 loss)
I0527 10:08:38.311586 25403 sgd_solver.cpp:106] Iteration 194625, lr = 0.0025
I0527 10:08:48.043977 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_195000.caffemodel
I0527 10:08:48.100414 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_195000.solverstate
I0527 10:08:48.126118 25403 solver.cpp:341] Iteration 195000, Testing net (#0)
I0527 10:09:57.567126 25403 solver.cpp:409]     Test net output #0: accuracy = 0.899019
I0527 10:09:57.567304 25403 solver.cpp:409]     Test net output #1: loss = 0.318936 (* 1 = 0.318936 loss)
I0527 10:10:19.774236 25403 solver.cpp:237] Iteration 195000, loss = 0.985671
I0527 10:10:19.774293 25403 solver.cpp:253]     Train net output #0: loss = 0.985671 (* 1 = 0.985671 loss)
I0527 10:10:19.774308 25403 sgd_solver.cpp:106] Iteration 195000, lr = 0.0025
I0527 10:10:29.696049 25403 solver.cpp:237] Iteration 195375, loss = 1.53663
I0527 10:10:29.696213 25403 solver.cpp:253]     Train net output #0: loss = 1.53663 (* 1 = 1.53663 loss)
I0527 10:10:29.696228 25403 sgd_solver.cpp:106] Iteration 195375, lr = 0.0025
I0527 10:10:39.620702 25403 solver.cpp:237] Iteration 195750, loss = 1.23192
I0527 10:10:39.620736 25403 solver.cpp:253]     Train net output #0: loss = 1.23192 (* 1 = 1.23192 loss)
I0527 10:10:39.620750 25403 sgd_solver.cpp:106] Iteration 195750, lr = 0.0025
I0527 10:10:49.544867 25403 solver.cpp:237] Iteration 196125, loss = 0.960554
I0527 10:10:49.544915 25403 solver.cpp:253]     Train net output #0: loss = 0.960554 (* 1 = 0.960554 loss)
I0527 10:10:49.544931 25403 sgd_solver.cpp:106] Iteration 196125, lr = 0.0025
I0527 10:10:59.467280 25403 solver.cpp:237] Iteration 196500, loss = 1.08802
I0527 10:10:59.467314 25403 solver.cpp:253]     Train net output #0: loss = 1.08802 (* 1 = 1.08802 loss)
I0527 10:10:59.467330 25403 sgd_solver.cpp:106] Iteration 196500, lr = 0.0025
I0527 10:11:09.386591 25403 solver.cpp:237] Iteration 196875, loss = 1.04769
I0527 10:11:09.386734 25403 solver.cpp:253]     Train net output #0: loss = 1.04769 (* 1 = 1.04769 loss)
I0527 10:11:09.386747 25403 sgd_solver.cpp:106] Iteration 196875, lr = 0.0025
I0527 10:11:19.306663 25403 solver.cpp:237] Iteration 197250, loss = 1.00563
I0527 10:11:19.306710 25403 solver.cpp:253]     Train net output #0: loss = 1.00563 (* 1 = 1.00563 loss)
I0527 10:11:19.306722 25403 sgd_solver.cpp:106] Iteration 197250, lr = 0.0025
I0527 10:11:51.413144 25403 solver.cpp:237] Iteration 197625, loss = 1.10268
I0527 10:11:51.413318 25403 solver.cpp:253]     Train net output #0: loss = 1.10268 (* 1 = 1.10268 loss)
I0527 10:11:51.413333 25403 sgd_solver.cpp:106] Iteration 197625, lr = 0.0025
I0527 10:12:01.342672 25403 solver.cpp:237] Iteration 198000, loss = 1.2806
I0527 10:12:01.342712 25403 solver.cpp:253]     Train net output #0: loss = 1.2806 (* 1 = 1.2806 loss)
I0527 10:12:01.342726 25403 sgd_solver.cpp:106] Iteration 198000, lr = 0.0025
I0527 10:12:11.266214 25403 solver.cpp:237] Iteration 198375, loss = 0.834369
I0527 10:12:11.266252 25403 solver.cpp:253]     Train net output #0: loss = 0.83437 (* 1 = 0.83437 loss)
I0527 10:12:11.266265 25403 sgd_solver.cpp:106] Iteration 198375, lr = 0.0025
I0527 10:12:21.165731 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_198750.caffemodel
I0527 10:12:21.224386 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_198750.solverstate
I0527 10:12:21.260005 25403 solver.cpp:237] Iteration 198750, loss = 1.4657
I0527 10:12:21.260054 25403 solver.cpp:253]     Train net output #0: loss = 1.4657 (* 1 = 1.4657 loss)
I0527 10:12:21.260073 25403 sgd_solver.cpp:106] Iteration 198750, lr = 0.0025
I0527 10:12:31.182119 25403 solver.cpp:237] Iteration 199125, loss = 1.26086
I0527 10:12:31.182296 25403 solver.cpp:253]     Train net output #0: loss = 1.26086 (* 1 = 1.26086 loss)
I0527 10:12:31.182310 25403 sgd_solver.cpp:106] Iteration 199125, lr = 0.0025
I0527 10:12:41.096386 25403 solver.cpp:237] Iteration 199500, loss = 1.42864
I0527 10:12:41.096421 25403 solver.cpp:253]     Train net output #0: loss = 1.42864 (* 1 = 1.42864 loss)
I0527 10:12:41.096436 25403 sgd_solver.cpp:106] Iteration 199500, lr = 0.0025
I0527 10:12:51.017554 25403 solver.cpp:237] Iteration 199875, loss = 1.17862
I0527 10:12:51.017590 25403 solver.cpp:253]     Train net output #0: loss = 1.17862 (* 1 = 1.17862 loss)
I0527 10:12:51.017604 25403 sgd_solver.cpp:106] Iteration 199875, lr = 0.0025
I0527 10:13:23.158681 25403 solver.cpp:237] Iteration 200250, loss = 0.943975
I0527 10:13:23.158860 25403 solver.cpp:253]     Train net output #0: loss = 0.943975 (* 1 = 0.943975 loss)
I0527 10:13:23.158874 25403 sgd_solver.cpp:106] Iteration 200250, lr = 0.0025
I0527 10:13:33.080080 25403 solver.cpp:237] Iteration 200625, loss = 1.18607
I0527 10:13:33.080113 25403 solver.cpp:253]     Train net output #0: loss = 1.18607 (* 1 = 1.18607 loss)
I0527 10:13:33.080129 25403 sgd_solver.cpp:106] Iteration 200625, lr = 0.0025
I0527 10:13:42.994560 25403 solver.cpp:237] Iteration 201000, loss = 1.12356
I0527 10:13:42.994606 25403 solver.cpp:253]     Train net output #0: loss = 1.12356 (* 1 = 1.12356 loss)
I0527 10:13:42.994622 25403 sgd_solver.cpp:106] Iteration 201000, lr = 0.0025
I0527 10:13:52.915592 25403 solver.cpp:237] Iteration 201375, loss = 1.31495
I0527 10:13:52.915627 25403 solver.cpp:253]     Train net output #0: loss = 1.31495 (* 1 = 1.31495 loss)
I0527 10:13:52.915642 25403 sgd_solver.cpp:106] Iteration 201375, lr = 0.0025
I0527 10:14:02.838618 25403 solver.cpp:237] Iteration 201750, loss = 1.08624
I0527 10:14:02.838757 25403 solver.cpp:253]     Train net output #0: loss = 1.08624 (* 1 = 1.08624 loss)
I0527 10:14:02.838771 25403 sgd_solver.cpp:106] Iteration 201750, lr = 0.0025
I0527 10:14:12.760970 25403 solver.cpp:237] Iteration 202125, loss = 1.15672
I0527 10:14:12.761018 25403 solver.cpp:253]     Train net output #0: loss = 1.15673 (* 1 = 1.15673 loss)
I0527 10:14:12.761035 25403 sgd_solver.cpp:106] Iteration 202125, lr = 0.0025
I0527 10:14:22.656219 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_202500.caffemodel
I0527 10:14:22.715432 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_202500.solverstate
I0527 10:14:22.743296 25403 solver.cpp:341] Iteration 202500, Testing net (#0)
I0527 10:15:11.336679 25403 solver.cpp:409]     Test net output #0: accuracy = 0.898625
I0527 10:15:11.336848 25403 solver.cpp:409]     Test net output #1: loss = 0.326855 (* 1 = 0.326855 loss)
I0527 10:15:32.252743 25403 solver.cpp:237] Iteration 202500, loss = 1.13761
I0527 10:15:32.252797 25403 solver.cpp:253]     Train net output #0: loss = 1.13761 (* 1 = 1.13761 loss)
I0527 10:15:32.252812 25403 sgd_solver.cpp:106] Iteration 202500, lr = 0.0025
I0527 10:15:42.049934 25403 solver.cpp:237] Iteration 202875, loss = 0.930804
I0527 10:15:42.050088 25403 solver.cpp:253]     Train net output #0: loss = 0.930805 (* 1 = 0.930805 loss)
I0527 10:15:42.050102 25403 sgd_solver.cpp:106] Iteration 202875, lr = 0.0025
I0527 10:15:51.839725 25403 solver.cpp:237] Iteration 203250, loss = 1.19231
I0527 10:15:51.839768 25403 solver.cpp:253]     Train net output #0: loss = 1.19231 (* 1 = 1.19231 loss)
I0527 10:15:51.839792 25403 sgd_solver.cpp:106] Iteration 203250, lr = 0.0025
I0527 10:16:01.630740 25403 solver.cpp:237] Iteration 203625, loss = 1.2608
I0527 10:16:01.630775 25403 solver.cpp:253]     Train net output #0: loss = 1.2608 (* 1 = 1.2608 loss)
I0527 10:16:01.630789 25403 sgd_solver.cpp:106] Iteration 203625, lr = 0.0025
I0527 10:16:11.419553 25403 solver.cpp:237] Iteration 204000, loss = 1.18033
I0527 10:16:11.419596 25403 solver.cpp:253]     Train net output #0: loss = 1.18033 (* 1 = 1.18033 loss)
I0527 10:16:11.419615 25403 sgd_solver.cpp:106] Iteration 204000, lr = 0.0025
I0527 10:16:21.213676 25403 solver.cpp:237] Iteration 204375, loss = 1.05911
I0527 10:16:21.213834 25403 solver.cpp:253]     Train net output #0: loss = 1.05911 (* 1 = 1.05911 loss)
I0527 10:16:21.213847 25403 sgd_solver.cpp:106] Iteration 204375, lr = 0.0025
I0527 10:16:31.005873 25403 solver.cpp:237] Iteration 204750, loss = 1.31956
I0527 10:16:31.005908 25403 solver.cpp:253]     Train net output #0: loss = 1.31956 (* 1 = 1.31956 loss)
I0527 10:16:31.005923 25403 sgd_solver.cpp:106] Iteration 204750, lr = 0.0025
I0527 10:17:01.687914 25403 solver.cpp:237] Iteration 205125, loss = 1.06023
I0527 10:17:01.688087 25403 solver.cpp:253]     Train net output #0: loss = 1.06023 (* 1 = 1.06023 loss)
I0527 10:17:01.688102 25403 sgd_solver.cpp:106] Iteration 205125, lr = 0.0025
I0527 10:17:11.480566 25403 solver.cpp:237] Iteration 205500, loss = 0.943817
I0527 10:17:11.480600 25403 solver.cpp:253]     Train net output #0: loss = 0.943817 (* 1 = 0.943817 loss)
I0527 10:17:11.480617 25403 sgd_solver.cpp:106] Iteration 205500, lr = 0.0025
I0527 10:17:21.270952 25403 solver.cpp:237] Iteration 205875, loss = 1.49892
I0527 10:17:21.270987 25403 solver.cpp:253]     Train net output #0: loss = 1.49892 (* 1 = 1.49892 loss)
I0527 10:17:21.271003 25403 sgd_solver.cpp:106] Iteration 205875, lr = 0.0025
I0527 10:17:31.034370 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_206250.caffemodel
I0527 10:17:31.090651 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_206250.solverstate
I0527 10:17:31.124150 25403 solver.cpp:237] Iteration 206250, loss = 0.831642
I0527 10:17:31.124196 25403 solver.cpp:253]     Train net output #0: loss = 0.831642 (* 1 = 0.831642 loss)
I0527 10:17:31.124217 25403 sgd_solver.cpp:106] Iteration 206250, lr = 0.0025
I0527 10:17:40.919322 25403 solver.cpp:237] Iteration 206625, loss = 1.31222
I0527 10:17:40.919472 25403 solver.cpp:253]     Train net output #0: loss = 1.31222 (* 1 = 1.31222 loss)
I0527 10:17:40.919486 25403 sgd_solver.cpp:106] Iteration 206625, lr = 0.0025
I0527 10:17:50.710814 25403 solver.cpp:237] Iteration 207000, loss = 0.890536
I0527 10:17:50.710850 25403 solver.cpp:253]     Train net output #0: loss = 0.890536 (* 1 = 0.890536 loss)
I0527 10:17:50.710865 25403 sgd_solver.cpp:106] Iteration 207000, lr = 0.0025
I0527 10:18:00.493813 25403 solver.cpp:237] Iteration 207375, loss = 1.18639
I0527 10:18:00.493860 25403 solver.cpp:253]     Train net output #0: loss = 1.18639 (* 1 = 1.18639 loss)
I0527 10:18:00.493873 25403 sgd_solver.cpp:106] Iteration 207375, lr = 0.0025
I0527 10:18:31.173674 25403 solver.cpp:237] Iteration 207750, loss = 1.03916
I0527 10:18:31.173849 25403 solver.cpp:253]     Train net output #0: loss = 1.03916 (* 1 = 1.03916 loss)
I0527 10:18:31.173866 25403 sgd_solver.cpp:106] Iteration 207750, lr = 0.0025
I0527 10:18:40.960187 25403 solver.cpp:237] Iteration 208125, loss = 0.962677
I0527 10:18:40.960222 25403 solver.cpp:253]     Train net output #0: loss = 0.962677 (* 1 = 0.962677 loss)
I0527 10:18:40.960237 25403 sgd_solver.cpp:106] Iteration 208125, lr = 0.0025
I0527 10:18:50.746815 25403 solver.cpp:237] Iteration 208500, loss = 1.47916
I0527 10:18:50.746855 25403 solver.cpp:253]     Train net output #0: loss = 1.47916 (* 1 = 1.47916 loss)
I0527 10:18:50.746872 25403 sgd_solver.cpp:106] Iteration 208500, lr = 0.0025
I0527 10:19:00.537396 25403 solver.cpp:237] Iteration 208875, loss = 1.10963
I0527 10:19:00.537431 25403 solver.cpp:253]     Train net output #0: loss = 1.10963 (* 1 = 1.10963 loss)
I0527 10:19:00.537446 25403 sgd_solver.cpp:106] Iteration 208875, lr = 0.0025
I0527 10:19:10.325423 25403 solver.cpp:237] Iteration 209250, loss = 0.918511
I0527 10:19:10.325589 25403 solver.cpp:253]     Train net output #0: loss = 0.918512 (* 1 = 0.918512 loss)
I0527 10:19:10.325603 25403 sgd_solver.cpp:106] Iteration 209250, lr = 0.0025
I0527 10:19:20.113641 25403 solver.cpp:237] Iteration 209625, loss = 1.27898
I0527 10:19:20.113675 25403 solver.cpp:253]     Train net output #0: loss = 1.27899 (* 1 = 1.27899 loss)
I0527 10:19:20.113690 25403 sgd_solver.cpp:106] Iteration 209625, lr = 0.0025
I0527 10:19:29.879861 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_210000.caffemodel
I0527 10:19:29.935868 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_210000.solverstate
I0527 10:19:29.961824 25403 solver.cpp:341] Iteration 210000, Testing net (#0)
I0527 10:20:39.424238 25403 solver.cpp:409]     Test net output #0: accuracy = 0.901908
I0527 10:20:39.424422 25403 solver.cpp:409]     Test net output #1: loss = 0.300942 (* 1 = 0.300942 loss)
I0527 10:21:00.349463 25403 solver.cpp:237] Iteration 210000, loss = 1.20918
I0527 10:21:00.349520 25403 solver.cpp:253]     Train net output #0: loss = 1.20918 (* 1 = 1.20918 loss)
I0527 10:21:00.349535 25403 sgd_solver.cpp:106] Iteration 210000, lr = 0.0025
I0527 10:21:10.188916 25403 solver.cpp:237] Iteration 210375, loss = 0.904778
I0527 10:21:10.189086 25403 solver.cpp:253]     Train net output #0: loss = 0.904778 (* 1 = 0.904778 loss)
I0527 10:21:10.189100 25403 sgd_solver.cpp:106] Iteration 210375, lr = 0.0025
I0527 10:21:20.032809 25403 solver.cpp:237] Iteration 210750, loss = 1.12171
I0527 10:21:20.032852 25403 solver.cpp:253]     Train net output #0: loss = 1.12171 (* 1 = 1.12171 loss)
I0527 10:21:20.032866 25403 sgd_solver.cpp:106] Iteration 210750, lr = 0.0025
I0527 10:21:29.884490 25403 solver.cpp:237] Iteration 211125, loss = 1.17124
I0527 10:21:29.884526 25403 solver.cpp:253]     Train net output #0: loss = 1.17124 (* 1 = 1.17124 loss)
I0527 10:21:29.884541 25403 sgd_solver.cpp:106] Iteration 211125, lr = 0.0025
I0527 10:21:39.736943 25403 solver.cpp:237] Iteration 211500, loss = 1.3578
I0527 10:21:39.736985 25403 solver.cpp:253]     Train net output #0: loss = 1.3578 (* 1 = 1.3578 loss)
I0527 10:21:39.737004 25403 sgd_solver.cpp:106] Iteration 211500, lr = 0.0025
I0527 10:21:49.589112 25403 solver.cpp:237] Iteration 211875, loss = 1.37442
I0527 10:21:49.589259 25403 solver.cpp:253]     Train net output #0: loss = 1.37442 (* 1 = 1.37442 loss)
I0527 10:21:49.589272 25403 sgd_solver.cpp:106] Iteration 211875, lr = 0.0025
I0527 10:21:59.438544 25403 solver.cpp:237] Iteration 212250, loss = 1.10425
I0527 10:21:59.438578 25403 solver.cpp:253]     Train net output #0: loss = 1.10425 (* 1 = 1.10425 loss)
I0527 10:21:59.438594 25403 sgd_solver.cpp:106] Iteration 212250, lr = 0.0025
I0527 10:22:30.182574 25403 solver.cpp:237] Iteration 212625, loss = 1.25529
I0527 10:22:30.182747 25403 solver.cpp:253]     Train net output #0: loss = 1.25529 (* 1 = 1.25529 loss)
I0527 10:22:30.182765 25403 sgd_solver.cpp:106] Iteration 212625, lr = 0.0025
I0527 10:22:40.036655 25403 solver.cpp:237] Iteration 213000, loss = 0.936042
I0527 10:22:40.036692 25403 solver.cpp:253]     Train net output #0: loss = 0.936042 (* 1 = 0.936042 loss)
I0527 10:22:40.036706 25403 sgd_solver.cpp:106] Iteration 213000, lr = 0.0025
I0527 10:22:49.882135 25403 solver.cpp:237] Iteration 213375, loss = 1.07267
I0527 10:22:49.882171 25403 solver.cpp:253]     Train net output #0: loss = 1.07267 (* 1 = 1.07267 loss)
I0527 10:22:49.882184 25403 sgd_solver.cpp:106] Iteration 213375, lr = 0.0025
I0527 10:22:59.699609 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_213750.caffemodel
I0527 10:22:59.756427 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_213750.solverstate
I0527 10:22:59.790367 25403 solver.cpp:237] Iteration 213750, loss = 1.14556
I0527 10:22:59.790411 25403 solver.cpp:253]     Train net output #0: loss = 1.14556 (* 1 = 1.14556 loss)
I0527 10:22:59.790431 25403 sgd_solver.cpp:106] Iteration 213750, lr = 0.0025
I0527 10:23:09.643076 25403 solver.cpp:237] Iteration 214125, loss = 1.24363
I0527 10:23:09.643237 25403 solver.cpp:253]     Train net output #0: loss = 1.24363 (* 1 = 1.24363 loss)
I0527 10:23:09.643251 25403 sgd_solver.cpp:106] Iteration 214125, lr = 0.0025
I0527 10:23:19.495239 25403 solver.cpp:237] Iteration 214500, loss = 1.19668
I0527 10:23:19.495293 25403 solver.cpp:253]     Train net output #0: loss = 1.19668 (* 1 = 1.19668 loss)
I0527 10:23:19.495308 25403 sgd_solver.cpp:106] Iteration 214500, lr = 0.0025
I0527 10:23:29.342679 25403 solver.cpp:237] Iteration 214875, loss = 1.47145
I0527 10:23:29.342715 25403 solver.cpp:253]     Train net output #0: loss = 1.47145 (* 1 = 1.47145 loss)
I0527 10:23:29.342728 25403 sgd_solver.cpp:106] Iteration 214875, lr = 0.0025
I0527 10:24:00.114929 25403 solver.cpp:237] Iteration 215250, loss = 1.23259
I0527 10:24:00.115108 25403 solver.cpp:253]     Train net output #0: loss = 1.23259 (* 1 = 1.23259 loss)
I0527 10:24:00.115124 25403 sgd_solver.cpp:106] Iteration 215250, lr = 0.0025
I0527 10:24:09.963735 25403 solver.cpp:237] Iteration 215625, loss = 0.830909
I0527 10:24:09.963781 25403 solver.cpp:253]     Train net output #0: loss = 0.830909 (* 1 = 0.830909 loss)
I0527 10:24:09.963801 25403 sgd_solver.cpp:106] Iteration 215625, lr = 0.0025
I0527 10:24:19.814242 25403 solver.cpp:237] Iteration 216000, loss = 1.06822
I0527 10:24:19.814277 25403 solver.cpp:253]     Train net output #0: loss = 1.06822 (* 1 = 1.06822 loss)
I0527 10:24:19.814292 25403 sgd_solver.cpp:106] Iteration 216000, lr = 0.0025
I0527 10:24:29.667132 25403 solver.cpp:237] Iteration 216375, loss = 0.834705
I0527 10:24:29.667170 25403 solver.cpp:253]     Train net output #0: loss = 0.834705 (* 1 = 0.834705 loss)
I0527 10:24:29.667184 25403 sgd_solver.cpp:106] Iteration 216375, lr = 0.0025
I0527 10:24:39.461176 25403 solver.cpp:237] Iteration 216750, loss = 0.911604
I0527 10:24:39.461359 25403 solver.cpp:253]     Train net output #0: loss = 0.911604 (* 1 = 0.911604 loss)
I0527 10:24:39.461372 25403 sgd_solver.cpp:106] Iteration 216750, lr = 0.0025
I0527 10:24:49.239630 25403 solver.cpp:237] Iteration 217125, loss = 0.820305
I0527 10:24:49.239668 25403 solver.cpp:253]     Train net output #0: loss = 0.820306 (* 1 = 0.820306 loss)
I0527 10:24:49.239682 25403 sgd_solver.cpp:106] Iteration 217125, lr = 0.0025
I0527 10:24:58.990473 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_217500.caffemodel
I0527 10:24:59.047027 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_217500.solverstate
I0527 10:24:59.072746 25403 solver.cpp:341] Iteration 217500, Testing net (#0)
I0527 10:25:47.284678 25403 solver.cpp:409]     Test net output #0: accuracy = 0.899659
I0527 10:25:47.284847 25403 solver.cpp:409]     Test net output #1: loss = 0.314373 (* 1 = 0.314373 loss)
I0527 10:26:08.185637 25403 solver.cpp:237] Iteration 217500, loss = 1.10302
I0527 10:26:08.185693 25403 solver.cpp:253]     Train net output #0: loss = 1.10302 (* 1 = 1.10302 loss)
I0527 10:26:08.185709 25403 sgd_solver.cpp:106] Iteration 217500, lr = 0.0025
I0527 10:26:17.945320 25403 solver.cpp:237] Iteration 217875, loss = 1.28845
I0527 10:26:17.945497 25403 solver.cpp:253]     Train net output #0: loss = 1.28845 (* 1 = 1.28845 loss)
I0527 10:26:17.945511 25403 sgd_solver.cpp:106] Iteration 217875, lr = 0.0025
I0527 10:26:27.700641 25403 solver.cpp:237] Iteration 218250, loss = 1.50032
I0527 10:26:27.700675 25403 solver.cpp:253]     Train net output #0: loss = 1.50032 (* 1 = 1.50032 loss)
I0527 10:26:27.700691 25403 sgd_solver.cpp:106] Iteration 218250, lr = 0.0025
I0527 10:26:37.457406 25403 solver.cpp:237] Iteration 218625, loss = 1.3326
I0527 10:26:37.457450 25403 solver.cpp:253]     Train net output #0: loss = 1.3326 (* 1 = 1.3326 loss)
I0527 10:26:37.457469 25403 sgd_solver.cpp:106] Iteration 218625, lr = 0.0025
I0527 10:26:47.210273 25403 solver.cpp:237] Iteration 219000, loss = 0.99287
I0527 10:26:47.210309 25403 solver.cpp:253]     Train net output #0: loss = 0.99287 (* 1 = 0.99287 loss)
I0527 10:26:47.210322 25403 sgd_solver.cpp:106] Iteration 219000, lr = 0.0025
I0527 10:26:56.961170 25403 solver.cpp:237] Iteration 219375, loss = 1.26621
I0527 10:26:56.961320 25403 solver.cpp:253]     Train net output #0: loss = 1.26621 (* 1 = 1.26621 loss)
I0527 10:26:56.961333 25403 sgd_solver.cpp:106] Iteration 219375, lr = 0.0025
I0527 10:27:06.722432 25403 solver.cpp:237] Iteration 219750, loss = 1.11057
I0527 10:27:06.722479 25403 solver.cpp:253]     Train net output #0: loss = 1.11057 (* 1 = 1.11057 loss)
I0527 10:27:06.722497 25403 sgd_solver.cpp:106] Iteration 219750, lr = 0.0025
I0527 10:27:37.423259 25403 solver.cpp:237] Iteration 220125, loss = 1.12608
I0527 10:27:37.423440 25403 solver.cpp:253]     Train net output #0: loss = 1.12608 (* 1 = 1.12608 loss)
I0527 10:27:37.423455 25403 sgd_solver.cpp:106] Iteration 220125, lr = 0.0025
I0527 10:27:47.176420 25403 solver.cpp:237] Iteration 220500, loss = 0.849098
I0527 10:27:47.176456 25403 solver.cpp:253]     Train net output #0: loss = 0.849098 (* 1 = 0.849098 loss)
I0527 10:27:47.176470 25403 sgd_solver.cpp:106] Iteration 220500, lr = 0.0025
I0527 10:27:56.935128 25403 solver.cpp:237] Iteration 220875, loss = 0.909028
I0527 10:27:56.935179 25403 solver.cpp:253]     Train net output #0: loss = 0.909028 (* 1 = 0.909028 loss)
I0527 10:27:56.935196 25403 sgd_solver.cpp:106] Iteration 220875, lr = 0.0025
I0527 10:28:06.660565 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_221250.caffemodel
I0527 10:28:06.719216 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_221250.solverstate
I0527 10:28:06.755400 25403 solver.cpp:237] Iteration 221250, loss = 1.31911
I0527 10:28:06.755453 25403 solver.cpp:253]     Train net output #0: loss = 1.31911 (* 1 = 1.31911 loss)
I0527 10:28:06.755468 25403 sgd_solver.cpp:106] Iteration 221250, lr = 0.0025
I0527 10:28:16.518230 25403 solver.cpp:237] Iteration 221625, loss = 0.994224
I0527 10:28:16.518401 25403 solver.cpp:253]     Train net output #0: loss = 0.994224 (* 1 = 0.994224 loss)
I0527 10:28:16.518416 25403 sgd_solver.cpp:106] Iteration 221625, lr = 0.0025
I0527 10:28:26.270613 25403 solver.cpp:237] Iteration 222000, loss = 1.62307
I0527 10:28:26.270649 25403 solver.cpp:253]     Train net output #0: loss = 1.62307 (* 1 = 1.62307 loss)
I0527 10:28:26.270664 25403 sgd_solver.cpp:106] Iteration 222000, lr = 0.0025
I0527 10:28:36.032866 25403 solver.cpp:237] Iteration 222375, loss = 1.17377
I0527 10:28:36.032902 25403 solver.cpp:253]     Train net output #0: loss = 1.17377 (* 1 = 1.17377 loss)
I0527 10:28:36.032914 25403 sgd_solver.cpp:106] Iteration 222375, lr = 0.0025
I0527 10:29:06.694795 25403 solver.cpp:237] Iteration 222750, loss = 1.0765
I0527 10:29:06.694974 25403 solver.cpp:253]     Train net output #0: loss = 1.0765 (* 1 = 1.0765 loss)
I0527 10:29:06.694988 25403 sgd_solver.cpp:106] Iteration 222750, lr = 0.0025
I0527 10:29:16.451015 25403 solver.cpp:237] Iteration 223125, loss = 1.24926
I0527 10:29:16.451050 25403 solver.cpp:253]     Train net output #0: loss = 1.24926 (* 1 = 1.24926 loss)
I0527 10:29:16.451066 25403 sgd_solver.cpp:106] Iteration 223125, lr = 0.0025
I0527 10:29:26.204663 25403 solver.cpp:237] Iteration 223500, loss = 1.27459
I0527 10:29:26.204699 25403 solver.cpp:253]     Train net output #0: loss = 1.27459 (* 1 = 1.27459 loss)
I0527 10:29:26.204713 25403 sgd_solver.cpp:106] Iteration 223500, lr = 0.0025
I0527 10:29:35.964697 25403 solver.cpp:237] Iteration 223875, loss = 1.14285
I0527 10:29:35.964746 25403 solver.cpp:253]     Train net output #0: loss = 1.14285 (* 1 = 1.14285 loss)
I0527 10:29:35.964761 25403 sgd_solver.cpp:106] Iteration 223875, lr = 0.0025
I0527 10:29:45.724685 25403 solver.cpp:237] Iteration 224250, loss = 1.06031
I0527 10:29:45.724846 25403 solver.cpp:253]     Train net output #0: loss = 1.06031 (* 1 = 1.06031 loss)
I0527 10:29:45.724860 25403 sgd_solver.cpp:106] Iteration 224250, lr = 0.0025
I0527 10:29:55.484688 25403 solver.cpp:237] Iteration 224625, loss = 0.927606
I0527 10:29:55.484722 25403 solver.cpp:253]     Train net output #0: loss = 0.927606 (* 1 = 0.927606 loss)
I0527 10:29:55.484738 25403 sgd_solver.cpp:106] Iteration 224625, lr = 0.0025
I0527 10:30:05.218127 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_225000.caffemodel
I0527 10:30:05.274341 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_225000.solverstate
I0527 10:30:05.300025 25403 solver.cpp:341] Iteration 225000, Testing net (#0)
I0527 10:31:14.776284 25403 solver.cpp:409]     Test net output #0: accuracy = 0.898966
I0527 10:31:14.776456 25403 solver.cpp:409]     Test net output #1: loss = 0.317259 (* 1 = 0.317259 loss)
I0527 10:31:35.626322 25403 solver.cpp:237] Iteration 225000, loss = 1.00651
I0527 10:31:35.626379 25403 solver.cpp:253]     Train net output #0: loss = 1.00651 (* 1 = 1.00651 loss)
I0527 10:31:35.626394 25403 sgd_solver.cpp:106] Iteration 225000, lr = 0.0025
I0527 10:31:45.530095 25403 solver.cpp:237] Iteration 225375, loss = 1.07728
I0527 10:31:45.530261 25403 solver.cpp:253]     Train net output #0: loss = 1.07728 (* 1 = 1.07728 loss)
I0527 10:31:45.530275 25403 sgd_solver.cpp:106] Iteration 225375, lr = 0.0025
I0527 10:31:55.431665 25403 solver.cpp:237] Iteration 225750, loss = 1.28818
I0527 10:31:55.431700 25403 solver.cpp:253]     Train net output #0: loss = 1.28818 (* 1 = 1.28818 loss)
I0527 10:31:55.431715 25403 sgd_solver.cpp:106] Iteration 225750, lr = 0.0025
I0527 10:32:05.339582 25403 solver.cpp:237] Iteration 226125, loss = 1.41225
I0527 10:32:05.339637 25403 solver.cpp:253]     Train net output #0: loss = 1.41225 (* 1 = 1.41225 loss)
I0527 10:32:05.339651 25403 sgd_solver.cpp:106] Iteration 226125, lr = 0.0025
I0527 10:32:15.248575 25403 solver.cpp:237] Iteration 226500, loss = 1.00512
I0527 10:32:15.248611 25403 solver.cpp:253]     Train net output #0: loss = 1.00512 (* 1 = 1.00512 loss)
I0527 10:32:15.248625 25403 sgd_solver.cpp:106] Iteration 226500, lr = 0.0025
I0527 10:32:25.152776 25403 solver.cpp:237] Iteration 226875, loss = 1.27521
I0527 10:32:25.152930 25403 solver.cpp:253]     Train net output #0: loss = 1.27521 (* 1 = 1.27521 loss)
I0527 10:32:25.152943 25403 sgd_solver.cpp:106] Iteration 226875, lr = 0.0025
I0527 10:32:35.052718 25403 solver.cpp:237] Iteration 227250, loss = 0.967703
I0527 10:32:35.052760 25403 solver.cpp:253]     Train net output #0: loss = 0.967703 (* 1 = 0.967703 loss)
I0527 10:32:35.052779 25403 sgd_solver.cpp:106] Iteration 227250, lr = 0.0025
I0527 10:33:05.810077 25403 solver.cpp:237] Iteration 227625, loss = 1.25513
I0527 10:33:05.810252 25403 solver.cpp:253]     Train net output #0: loss = 1.25513 (* 1 = 1.25513 loss)
I0527 10:33:05.810269 25403 sgd_solver.cpp:106] Iteration 227625, lr = 0.0025
I0527 10:33:15.715116 25403 solver.cpp:237] Iteration 228000, loss = 0.92155
I0527 10:33:15.715152 25403 solver.cpp:253]     Train net output #0: loss = 0.92155 (* 1 = 0.92155 loss)
I0527 10:33:15.715165 25403 sgd_solver.cpp:106] Iteration 228000, lr = 0.0025
I0527 10:33:25.621104 25403 solver.cpp:237] Iteration 228375, loss = 1.17416
I0527 10:33:25.621145 25403 solver.cpp:253]     Train net output #0: loss = 1.17416 (* 1 = 1.17416 loss)
I0527 10:33:25.621163 25403 sgd_solver.cpp:106] Iteration 228375, lr = 0.0025
I0527 10:33:35.507459 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_228750.caffemodel
I0527 10:33:35.564568 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_228750.solverstate
I0527 10:33:35.598568 25403 solver.cpp:237] Iteration 228750, loss = 0.937707
I0527 10:33:35.598613 25403 solver.cpp:253]     Train net output #0: loss = 0.937707 (* 1 = 0.937707 loss)
I0527 10:33:35.598631 25403 sgd_solver.cpp:106] Iteration 228750, lr = 0.0025
I0527 10:33:45.497274 25403 solver.cpp:237] Iteration 229125, loss = 1.22755
I0527 10:33:45.497460 25403 solver.cpp:253]     Train net output #0: loss = 1.22755 (* 1 = 1.22755 loss)
I0527 10:33:45.497475 25403 sgd_solver.cpp:106] Iteration 229125, lr = 0.0025
I0527 10:33:55.411846 25403 solver.cpp:237] Iteration 229500, loss = 1.21531
I0527 10:33:55.411882 25403 solver.cpp:253]     Train net output #0: loss = 1.21531 (* 1 = 1.21531 loss)
I0527 10:33:55.411897 25403 sgd_solver.cpp:106] Iteration 229500, lr = 0.0025
I0527 10:34:05.313105 25403 solver.cpp:237] Iteration 229875, loss = 1.10076
I0527 10:34:05.313140 25403 solver.cpp:253]     Train net output #0: loss = 1.10076 (* 1 = 1.10076 loss)
I0527 10:34:05.313154 25403 sgd_solver.cpp:106] Iteration 229875, lr = 0.0025
I0527 10:34:36.115392 25403 solver.cpp:237] Iteration 230250, loss = 1.05571
I0527 10:34:36.115574 25403 solver.cpp:253]     Train net output #0: loss = 1.05571 (* 1 = 1.05571 loss)
I0527 10:34:36.115591 25403 sgd_solver.cpp:106] Iteration 230250, lr = 0.0025
I0527 10:34:46.027863 25403 solver.cpp:237] Iteration 230625, loss = 1.54211
I0527 10:34:46.027899 25403 solver.cpp:253]     Train net output #0: loss = 1.54211 (* 1 = 1.54211 loss)
I0527 10:34:46.027912 25403 sgd_solver.cpp:106] Iteration 230625, lr = 0.0025
I0527 10:34:55.945860 25403 solver.cpp:237] Iteration 231000, loss = 1.42138
I0527 10:34:55.945895 25403 solver.cpp:253]     Train net output #0: loss = 1.42138 (* 1 = 1.42138 loss)
I0527 10:34:55.945909 25403 sgd_solver.cpp:106] Iteration 231000, lr = 0.0025
I0527 10:35:05.856755 25403 solver.cpp:237] Iteration 231375, loss = 1.65997
I0527 10:35:05.856803 25403 solver.cpp:253]     Train net output #0: loss = 1.65997 (* 1 = 1.65997 loss)
I0527 10:35:05.856817 25403 sgd_solver.cpp:106] Iteration 231375, lr = 0.0025
I0527 10:35:15.768422 25403 solver.cpp:237] Iteration 231750, loss = 1.25077
I0527 10:35:15.768575 25403 solver.cpp:253]     Train net output #0: loss = 1.25077 (* 1 = 1.25077 loss)
I0527 10:35:15.768589 25403 sgd_solver.cpp:106] Iteration 231750, lr = 0.0025
I0527 10:35:25.674955 25403 solver.cpp:237] Iteration 232125, loss = 0.962008
I0527 10:35:25.675001 25403 solver.cpp:253]     Train net output #0: loss = 0.962009 (* 1 = 0.962009 loss)
I0527 10:35:25.675021 25403 sgd_solver.cpp:106] Iteration 232125, lr = 0.0025
I0527 10:35:35.555583 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_232500.caffemodel
I0527 10:35:35.612514 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_232500.solverstate
I0527 10:35:35.638095 25403 solver.cpp:341] Iteration 232500, Testing net (#0)
I0527 10:36:24.197870 25403 solver.cpp:409]     Test net output #0: accuracy = 0.900212
I0527 10:36:24.198055 25403 solver.cpp:409]     Test net output #1: loss = 0.326625 (* 1 = 0.326625 loss)
I0527 10:36:45.052332 25403 solver.cpp:237] Iteration 232500, loss = 1.09474
I0527 10:36:45.052387 25403 solver.cpp:253]     Train net output #0: loss = 1.09474 (* 1 = 1.09474 loss)
I0527 10:36:45.052402 25403 sgd_solver.cpp:106] Iteration 232500, lr = 0.0025
I0527 10:36:54.768080 25403 solver.cpp:237] Iteration 232875, loss = 1.28797
I0527 10:36:54.768244 25403 solver.cpp:253]     Train net output #0: loss = 1.28798 (* 1 = 1.28798 loss)
I0527 10:36:54.768257 25403 sgd_solver.cpp:106] Iteration 232875, lr = 0.0025
I0527 10:37:04.481623 25403 solver.cpp:237] Iteration 233250, loss = 1.16694
I0527 10:37:04.481667 25403 solver.cpp:253]     Train net output #0: loss = 1.16694 (* 1 = 1.16694 loss)
I0527 10:37:04.481683 25403 sgd_solver.cpp:106] Iteration 233250, lr = 0.0025
I0527 10:37:14.198530 25403 solver.cpp:237] Iteration 233625, loss = 1.13867
I0527 10:37:14.198566 25403 solver.cpp:253]     Train net output #0: loss = 1.13867 (* 1 = 1.13867 loss)
I0527 10:37:14.198580 25403 sgd_solver.cpp:106] Iteration 233625, lr = 0.0025
I0527 10:37:23.910380 25403 solver.cpp:237] Iteration 234000, loss = 1.10736
I0527 10:37:23.910415 25403 solver.cpp:253]     Train net output #0: loss = 1.10736 (* 1 = 1.10736 loss)
I0527 10:37:23.910429 25403 sgd_solver.cpp:106] Iteration 234000, lr = 0.0025
I0527 10:37:33.628340 25403 solver.cpp:237] Iteration 234375, loss = 1.23536
I0527 10:37:33.628518 25403 solver.cpp:253]     Train net output #0: loss = 1.23536 (* 1 = 1.23536 loss)
I0527 10:37:33.628532 25403 sgd_solver.cpp:106] Iteration 234375, lr = 0.0025
I0527 10:37:43.341027 25403 solver.cpp:237] Iteration 234750, loss = 0.679591
I0527 10:37:43.341063 25403 solver.cpp:253]     Train net output #0: loss = 0.679591 (* 1 = 0.679591 loss)
I0527 10:37:43.341078 25403 sgd_solver.cpp:106] Iteration 234750, lr = 0.0025
I0527 10:38:13.965121 25403 solver.cpp:237] Iteration 235125, loss = 1.15701
I0527 10:38:13.965302 25403 solver.cpp:253]     Train net output #0: loss = 1.15701 (* 1 = 1.15701 loss)
I0527 10:38:13.965318 25403 sgd_solver.cpp:106] Iteration 235125, lr = 0.0025
I0527 10:38:23.679700 25403 solver.cpp:237] Iteration 235500, loss = 1.18024
I0527 10:38:23.679746 25403 solver.cpp:253]     Train net output #0: loss = 1.18024 (* 1 = 1.18024 loss)
I0527 10:38:23.679762 25403 sgd_solver.cpp:106] Iteration 235500, lr = 0.0025
I0527 10:38:33.393831 25403 solver.cpp:237] Iteration 235875, loss = 1.10518
I0527 10:38:33.393864 25403 solver.cpp:253]     Train net output #0: loss = 1.10518 (* 1 = 1.10518 loss)
I0527 10:38:33.393880 25403 sgd_solver.cpp:106] Iteration 235875, lr = 0.0025
I0527 10:38:43.077396 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_236250.caffemodel
I0527 10:38:43.135747 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_236250.solverstate
I0527 10:38:43.171885 25403 solver.cpp:237] Iteration 236250, loss = 1.64044
I0527 10:38:43.171936 25403 solver.cpp:253]     Train net output #0: loss = 1.64044 (* 1 = 1.64044 loss)
I0527 10:38:43.171952 25403 sgd_solver.cpp:106] Iteration 236250, lr = 0.0025
I0527 10:38:52.883352 25403 solver.cpp:237] Iteration 236625, loss = 0.950446
I0527 10:38:52.883509 25403 solver.cpp:253]     Train net output #0: loss = 0.950446 (* 1 = 0.950446 loss)
I0527 10:38:52.883523 25403 sgd_solver.cpp:106] Iteration 236625, lr = 0.0025
I0527 10:39:02.602258 25403 solver.cpp:237] Iteration 237000, loss = 1.31072
I0527 10:39:02.602293 25403 solver.cpp:253]     Train net output #0: loss = 1.31072 (* 1 = 1.31072 loss)
I0527 10:39:02.602308 25403 sgd_solver.cpp:106] Iteration 237000, lr = 0.0025
I0527 10:39:12.312942 25403 solver.cpp:237] Iteration 237375, loss = 1.03652
I0527 10:39:12.312990 25403 solver.cpp:253]     Train net output #0: loss = 1.03652 (* 1 = 1.03652 loss)
I0527 10:39:12.313007 25403 sgd_solver.cpp:106] Iteration 237375, lr = 0.0025
I0527 10:39:42.897331 25403 solver.cpp:237] Iteration 237750, loss = 1.09416
I0527 10:39:42.897521 25403 solver.cpp:253]     Train net output #0: loss = 1.09416 (* 1 = 1.09416 loss)
I0527 10:39:42.897536 25403 sgd_solver.cpp:106] Iteration 237750, lr = 0.0025
I0527 10:39:52.609956 25403 solver.cpp:237] Iteration 238125, loss = 1.02662
I0527 10:39:52.609992 25403 solver.cpp:253]     Train net output #0: loss = 1.02662 (* 1 = 1.02662 loss)
I0527 10:39:52.610005 25403 sgd_solver.cpp:106] Iteration 238125, lr = 0.0025
I0527 10:40:02.321447 25403 solver.cpp:237] Iteration 238500, loss = 1.36029
I0527 10:40:02.321498 25403 solver.cpp:253]     Train net output #0: loss = 1.3603 (* 1 = 1.3603 loss)
I0527 10:40:02.321512 25403 sgd_solver.cpp:106] Iteration 238500, lr = 0.0025
I0527 10:40:12.038033 25403 solver.cpp:237] Iteration 238875, loss = 1.3087
I0527 10:40:12.038067 25403 solver.cpp:253]     Train net output #0: loss = 1.3087 (* 1 = 1.3087 loss)
I0527 10:40:12.038081 25403 sgd_solver.cpp:106] Iteration 238875, lr = 0.0025
I0527 10:40:21.750488 25403 solver.cpp:237] Iteration 239250, loss = 1.39231
I0527 10:40:21.750661 25403 solver.cpp:253]     Train net output #0: loss = 1.39232 (* 1 = 1.39232 loss)
I0527 10:40:21.750675 25403 sgd_solver.cpp:106] Iteration 239250, lr = 0.0025
I0527 10:40:31.464293 25403 solver.cpp:237] Iteration 239625, loss = 1.13516
I0527 10:40:31.464328 25403 solver.cpp:253]     Train net output #0: loss = 1.13516 (* 1 = 1.13516 loss)
I0527 10:40:31.464344 25403 sgd_solver.cpp:106] Iteration 239625, lr = 0.0025
I0527 10:40:41.151716 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_240000.caffemodel
I0527 10:40:41.219971 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_240000.solverstate
I0527 10:40:41.247650 25403 solver.cpp:341] Iteration 240000, Testing net (#0)
I0527 10:41:50.612357 25403 solver.cpp:409]     Test net output #0: accuracy = 0.902839
I0527 10:41:50.612534 25403 solver.cpp:409]     Test net output #1: loss = 0.320958 (* 1 = 0.320958 loss)
I0527 10:42:11.521755 25403 solver.cpp:237] Iteration 240000, loss = 0.973235
I0527 10:42:11.521811 25403 solver.cpp:253]     Train net output #0: loss = 0.973235 (* 1 = 0.973235 loss)
I0527 10:42:11.521826 25403 sgd_solver.cpp:106] Iteration 240000, lr = 0.0025
I0527 10:42:21.316387 25403 solver.cpp:237] Iteration 240375, loss = 0.98657
I0527 10:42:21.316545 25403 solver.cpp:253]     Train net output #0: loss = 0.98657 (* 1 = 0.98657 loss)
I0527 10:42:21.316560 25403 sgd_solver.cpp:106] Iteration 240375, lr = 0.0025
I0527 10:42:31.109894 25403 solver.cpp:237] Iteration 240750, loss = 1.0389
I0527 10:42:31.109944 25403 solver.cpp:253]     Train net output #0: loss = 1.0389 (* 1 = 1.0389 loss)
I0527 10:42:31.109959 25403 sgd_solver.cpp:106] Iteration 240750, lr = 0.0025
I0527 10:42:40.902878 25403 solver.cpp:237] Iteration 241125, loss = 1.06342
I0527 10:42:40.902912 25403 solver.cpp:253]     Train net output #0: loss = 1.06343 (* 1 = 1.06343 loss)
I0527 10:42:40.902927 25403 sgd_solver.cpp:106] Iteration 241125, lr = 0.0025
I0527 10:42:50.699492 25403 solver.cpp:237] Iteration 241500, loss = 1.18946
I0527 10:42:50.699527 25403 solver.cpp:253]     Train net output #0: loss = 1.18946 (* 1 = 1.18946 loss)
I0527 10:42:50.699542 25403 sgd_solver.cpp:106] Iteration 241500, lr = 0.0025
I0527 10:43:00.502950 25403 solver.cpp:237] Iteration 241875, loss = 0.967507
I0527 10:43:00.503124 25403 solver.cpp:253]     Train net output #0: loss = 0.967507 (* 1 = 0.967507 loss)
I0527 10:43:00.503139 25403 sgd_solver.cpp:106] Iteration 241875, lr = 0.0025
I0527 10:43:10.295107 25403 solver.cpp:237] Iteration 242250, loss = 1.04328
I0527 10:43:10.295141 25403 solver.cpp:253]     Train net output #0: loss = 1.04328 (* 1 = 1.04328 loss)
I0527 10:43:10.295156 25403 sgd_solver.cpp:106] Iteration 242250, lr = 0.0025
I0527 10:43:40.981204 25403 solver.cpp:237] Iteration 242625, loss = 1.38969
I0527 10:43:40.981395 25403 solver.cpp:253]     Train net output #0: loss = 1.38969 (* 1 = 1.38969 loss)
I0527 10:43:40.981411 25403 sgd_solver.cpp:106] Iteration 242625, lr = 0.0025
I0527 10:43:50.779989 25403 solver.cpp:237] Iteration 243000, loss = 1.04202
I0527 10:43:50.780033 25403 solver.cpp:253]     Train net output #0: loss = 1.04202 (* 1 = 1.04202 loss)
I0527 10:43:50.780050 25403 sgd_solver.cpp:106] Iteration 243000, lr = 0.0025
I0527 10:44:00.577222 25403 solver.cpp:237] Iteration 243375, loss = 2.02882
I0527 10:44:00.577257 25403 solver.cpp:253]     Train net output #0: loss = 2.02882 (* 1 = 2.02882 loss)
I0527 10:44:00.577272 25403 sgd_solver.cpp:106] Iteration 243375, lr = 0.0025
I0527 10:44:10.346935 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_243750.caffemodel
I0527 10:44:10.403795 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_243750.solverstate
I0527 10:44:10.437239 25403 solver.cpp:237] Iteration 243750, loss = 1.39461
I0527 10:44:10.437286 25403 solver.cpp:253]     Train net output #0: loss = 1.39461 (* 1 = 1.39461 loss)
I0527 10:44:10.437305 25403 sgd_solver.cpp:106] Iteration 243750, lr = 0.0025
I0527 10:44:20.240057 25403 solver.cpp:237] Iteration 244125, loss = 1.09136
I0527 10:44:20.240217 25403 solver.cpp:253]     Train net output #0: loss = 1.09136 (* 1 = 1.09136 loss)
I0527 10:44:20.240231 25403 sgd_solver.cpp:106] Iteration 244125, lr = 0.0025
I0527 10:44:30.037065 25403 solver.cpp:237] Iteration 244500, loss = 1.01218
I0527 10:44:30.037099 25403 solver.cpp:253]     Train net output #0: loss = 1.01218 (* 1 = 1.01218 loss)
I0527 10:44:30.037114 25403 sgd_solver.cpp:106] Iteration 244500, lr = 0.0025
I0527 10:44:39.829314 25403 solver.cpp:237] Iteration 244875, loss = 1.18685
I0527 10:44:39.829355 25403 solver.cpp:253]     Train net output #0: loss = 1.18685 (* 1 = 1.18685 loss)
I0527 10:44:39.829370 25403 sgd_solver.cpp:106] Iteration 244875, lr = 0.0025
I0527 10:45:10.492919 25403 solver.cpp:237] Iteration 245250, loss = 0.978851
I0527 10:45:10.493098 25403 solver.cpp:253]     Train net output #0: loss = 0.978852 (* 1 = 0.978852 loss)
I0527 10:45:10.493114 25403 sgd_solver.cpp:106] Iteration 245250, lr = 0.0025
I0527 10:45:20.287597 25403 solver.cpp:237] Iteration 245625, loss = 1.28227
I0527 10:45:20.287631 25403 solver.cpp:253]     Train net output #0: loss = 1.28227 (* 1 = 1.28227 loss)
I0527 10:45:20.287647 25403 sgd_solver.cpp:106] Iteration 245625, lr = 0.0025
I0527 10:45:30.083426 25403 solver.cpp:237] Iteration 246000, loss = 1.23581
I0527 10:45:30.083469 25403 solver.cpp:253]     Train net output #0: loss = 1.23581 (* 1 = 1.23581 loss)
I0527 10:45:30.083483 25403 sgd_solver.cpp:106] Iteration 246000, lr = 0.0025
I0527 10:45:39.875149 25403 solver.cpp:237] Iteration 246375, loss = 0.932037
I0527 10:45:39.875185 25403 solver.cpp:253]     Train net output #0: loss = 0.932038 (* 1 = 0.932038 loss)
I0527 10:45:39.875200 25403 sgd_solver.cpp:106] Iteration 246375, lr = 0.0025
I0527 10:45:49.678375 25403 solver.cpp:237] Iteration 246750, loss = 0.895322
I0527 10:45:49.678546 25403 solver.cpp:253]     Train net output #0: loss = 0.895323 (* 1 = 0.895323 loss)
I0527 10:45:49.678560 25403 sgd_solver.cpp:106] Iteration 246750, lr = 0.0025
I0527 10:45:59.474325 25403 solver.cpp:237] Iteration 247125, loss = 1.24673
I0527 10:45:59.474360 25403 solver.cpp:253]     Train net output #0: loss = 1.24673 (* 1 = 1.24673 loss)
I0527 10:45:59.474375 25403 sgd_solver.cpp:106] Iteration 247125, lr = 0.0025
I0527 10:46:09.238353 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_247500.caffemodel
I0527 10:46:09.295557 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_247500.solverstate
I0527 10:46:09.321388 25403 solver.cpp:341] Iteration 247500, Testing net (#0)
I0527 10:46:57.498220 25403 solver.cpp:409]     Test net output #0: accuracy = 0.902978
I0527 10:46:57.498409 25403 solver.cpp:409]     Test net output #1: loss = 0.302298 (* 1 = 0.302298 loss)
I0527 10:47:18.371619 25403 solver.cpp:237] Iteration 247500, loss = 0.922918
I0527 10:47:18.371677 25403 solver.cpp:253]     Train net output #0: loss = 0.922919 (* 1 = 0.922919 loss)
I0527 10:47:18.371695 25403 sgd_solver.cpp:106] Iteration 247500, lr = 0.0025
I0527 10:47:28.118098 25403 solver.cpp:237] Iteration 247875, loss = 1.13528
I0527 10:47:28.118266 25403 solver.cpp:253]     Train net output #0: loss = 1.13528 (* 1 = 1.13528 loss)
I0527 10:47:28.118280 25403 sgd_solver.cpp:106] Iteration 247875, lr = 0.0025
I0527 10:47:37.847954 25403 solver.cpp:237] Iteration 248250, loss = 1.01692
I0527 10:47:37.847990 25403 solver.cpp:253]     Train net output #0: loss = 1.01692 (* 1 = 1.01692 loss)
I0527 10:47:37.848004 25403 sgd_solver.cpp:106] Iteration 248250, lr = 0.0025
I0527 10:47:47.580888 25403 solver.cpp:237] Iteration 248625, loss = 1.03223
I0527 10:47:47.580924 25403 solver.cpp:253]     Train net output #0: loss = 1.03223 (* 1 = 1.03223 loss)
I0527 10:47:47.580941 25403 sgd_solver.cpp:106] Iteration 248625, lr = 0.0025
I0527 10:47:57.316423 25403 solver.cpp:237] Iteration 249000, loss = 1.08526
I0527 10:47:57.316473 25403 solver.cpp:253]     Train net output #0: loss = 1.08526 (* 1 = 1.08526 loss)
I0527 10:47:57.316488 25403 sgd_solver.cpp:106] Iteration 249000, lr = 0.0025
I0527 10:48:07.055768 25403 solver.cpp:237] Iteration 249375, loss = 1.3957
I0527 10:48:07.055932 25403 solver.cpp:253]     Train net output #0: loss = 1.3957 (* 1 = 1.3957 loss)
I0527 10:48:07.055946 25403 sgd_solver.cpp:106] Iteration 249375, lr = 0.0025
I0527 10:48:16.792790 25403 solver.cpp:237] Iteration 249750, loss = 1.07189
I0527 10:48:16.792836 25403 solver.cpp:253]     Train net output #0: loss = 1.07189 (* 1 = 1.07189 loss)
I0527 10:48:16.792851 25403 sgd_solver.cpp:106] Iteration 249750, lr = 0.0025
I0527 10:48:47.428616 25403 solver.cpp:237] Iteration 250125, loss = 0.984614
I0527 10:48:47.428800 25403 solver.cpp:253]     Train net output #0: loss = 0.984614 (* 1 = 0.984614 loss)
I0527 10:48:47.428815 25403 sgd_solver.cpp:106] Iteration 250125, lr = 0.0025
I0527 10:48:57.164729 25403 solver.cpp:237] Iteration 250500, loss = 0.86264
I0527 10:48:57.164764 25403 solver.cpp:253]     Train net output #0: loss = 0.862641 (* 1 = 0.862641 loss)
I0527 10:48:57.164780 25403 sgd_solver.cpp:106] Iteration 250500, lr = 0.0025
I0527 10:49:06.898617 25403 solver.cpp:237] Iteration 250875, loss = 1.27808
I0527 10:49:06.898656 25403 solver.cpp:253]     Train net output #0: loss = 1.27808 (* 1 = 1.27808 loss)
I0527 10:49:06.898674 25403 sgd_solver.cpp:106] Iteration 250875, lr = 0.0025
I0527 10:49:16.609108 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_251250.caffemodel
I0527 10:49:16.665030 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_251250.solverstate
I0527 10:49:16.699336 25403 solver.cpp:237] Iteration 251250, loss = 1.10449
I0527 10:49:16.699378 25403 solver.cpp:253]     Train net output #0: loss = 1.10449 (* 1 = 1.10449 loss)
I0527 10:49:16.699400 25403 sgd_solver.cpp:106] Iteration 251250, lr = 0.0025
I0527 10:49:26.440680 25403 solver.cpp:237] Iteration 251625, loss = 0.915145
I0527 10:49:26.440852 25403 solver.cpp:253]     Train net output #0: loss = 0.915146 (* 1 = 0.915146 loss)
I0527 10:49:26.440867 25403 sgd_solver.cpp:106] Iteration 251625, lr = 0.0025
I0527 10:49:36.181346 25403 solver.cpp:237] Iteration 252000, loss = 1.14739
I0527 10:49:36.181388 25403 solver.cpp:253]     Train net output #0: loss = 1.14739 (* 1 = 1.14739 loss)
I0527 10:49:36.181407 25403 sgd_solver.cpp:106] Iteration 252000, lr = 0.0025
I0527 10:49:45.916435 25403 solver.cpp:237] Iteration 252375, loss = 1.04283
I0527 10:49:45.916471 25403 solver.cpp:253]     Train net output #0: loss = 1.04283 (* 1 = 1.04283 loss)
I0527 10:49:45.916483 25403 sgd_solver.cpp:106] Iteration 252375, lr = 0.0025
I0527 10:50:16.507266 25403 solver.cpp:237] Iteration 252750, loss = 0.855969
I0527 10:50:16.507447 25403 solver.cpp:253]     Train net output #0: loss = 0.85597 (* 1 = 0.85597 loss)
I0527 10:50:16.507463 25403 sgd_solver.cpp:106] Iteration 252750, lr = 0.0025
I0527 10:50:26.253824 25403 solver.cpp:237] Iteration 253125, loss = 1.19935
I0527 10:50:26.253868 25403 solver.cpp:253]     Train net output #0: loss = 1.19935 (* 1 = 1.19935 loss)
I0527 10:50:26.253888 25403 sgd_solver.cpp:106] Iteration 253125, lr = 0.0025
I0527 10:50:35.991606 25403 solver.cpp:237] Iteration 253500, loss = 1.28573
I0527 10:50:35.991642 25403 solver.cpp:253]     Train net output #0: loss = 1.28573 (* 1 = 1.28573 loss)
I0527 10:50:35.991655 25403 sgd_solver.cpp:106] Iteration 253500, lr = 0.0025
I0527 10:50:45.732365 25403 solver.cpp:237] Iteration 253875, loss = 0.983619
I0527 10:50:45.732401 25403 solver.cpp:253]     Train net output #0: loss = 0.983619 (* 1 = 0.983619 loss)
I0527 10:50:45.732414 25403 sgd_solver.cpp:106] Iteration 253875, lr = 0.0025
I0527 10:50:55.467890 25403 solver.cpp:237] Iteration 254250, loss = 1.11339
I0527 10:50:55.468060 25403 solver.cpp:253]     Train net output #0: loss = 1.11339 (* 1 = 1.11339 loss)
I0527 10:50:55.468075 25403 sgd_solver.cpp:106] Iteration 254250, lr = 0.0025
I0527 10:51:05.208565 25403 solver.cpp:237] Iteration 254625, loss = 0.979372
I0527 10:51:05.208600 25403 solver.cpp:253]     Train net output #0: loss = 0.979372 (* 1 = 0.979372 loss)
I0527 10:51:05.208614 25403 sgd_solver.cpp:106] Iteration 254625, lr = 0.0025
I0527 10:51:14.919409 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_255000.caffemodel
I0527 10:51:14.975384 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_255000.solverstate
I0527 10:51:15.001134 25403 solver.cpp:341] Iteration 255000, Testing net (#0)
I0527 10:52:24.403336 25403 solver.cpp:409]     Test net output #0: accuracy = 0.901887
I0527 10:52:24.403518 25403 solver.cpp:409]     Test net output #1: loss = 0.312686 (* 1 = 0.312686 loss)
I0527 10:52:45.277478 25403 solver.cpp:237] Iteration 255000, loss = 1.06391
I0527 10:52:45.277534 25403 solver.cpp:253]     Train net output #0: loss = 1.06391 (* 1 = 1.06391 loss)
I0527 10:52:45.277549 25403 sgd_solver.cpp:106] Iteration 255000, lr = 0.0025
I0527 10:52:55.185171 25403 solver.cpp:237] Iteration 255375, loss = 1.21588
I0527 10:52:55.185339 25403 solver.cpp:253]     Train net output #0: loss = 1.21588 (* 1 = 1.21588 loss)
I0527 10:52:55.185353 25403 sgd_solver.cpp:106] Iteration 255375, lr = 0.0025
I0527 10:53:05.093134 25403 solver.cpp:237] Iteration 255750, loss = 1.30602
I0527 10:53:05.093168 25403 solver.cpp:253]     Train net output #0: loss = 1.30602 (* 1 = 1.30602 loss)
I0527 10:53:05.093183 25403 sgd_solver.cpp:106] Iteration 255750, lr = 0.0025
I0527 10:53:14.995932 25403 solver.cpp:237] Iteration 256125, loss = 1.00884
I0527 10:53:14.995966 25403 solver.cpp:253]     Train net output #0: loss = 1.00884 (* 1 = 1.00884 loss)
I0527 10:53:14.995980 25403 sgd_solver.cpp:106] Iteration 256125, lr = 0.0025
I0527 10:53:24.911098 25403 solver.cpp:237] Iteration 256500, loss = 0.996427
I0527 10:53:24.911136 25403 solver.cpp:253]     Train net output #0: loss = 0.996428 (* 1 = 0.996428 loss)
I0527 10:53:24.911156 25403 sgd_solver.cpp:106] Iteration 256500, lr = 0.0025
I0527 10:53:34.824331 25403 solver.cpp:237] Iteration 256875, loss = 0.867432
I0527 10:53:34.824496 25403 solver.cpp:253]     Train net output #0: loss = 0.867432 (* 1 = 0.867432 loss)
I0527 10:53:34.824511 25403 sgd_solver.cpp:106] Iteration 256875, lr = 0.0025
I0527 10:53:44.732794 25403 solver.cpp:237] Iteration 257250, loss = 1.11329
I0527 10:53:44.732838 25403 solver.cpp:253]     Train net output #0: loss = 1.11329 (* 1 = 1.11329 loss)
I0527 10:53:44.732856 25403 sgd_solver.cpp:106] Iteration 257250, lr = 0.0025
I0527 10:54:15.549660 25403 solver.cpp:237] Iteration 257625, loss = 1.07857
I0527 10:54:15.549849 25403 solver.cpp:253]     Train net output #0: loss = 1.07857 (* 1 = 1.07857 loss)
I0527 10:54:15.549863 25403 sgd_solver.cpp:106] Iteration 257625, lr = 0.0025
I0527 10:54:25.458648 25403 solver.cpp:237] Iteration 258000, loss = 0.953598
I0527 10:54:25.458683 25403 solver.cpp:253]     Train net output #0: loss = 0.953598 (* 1 = 0.953598 loss)
I0527 10:54:25.458700 25403 sgd_solver.cpp:106] Iteration 258000, lr = 0.0025
I0527 10:54:35.370069 25403 solver.cpp:237] Iteration 258375, loss = 1.24057
I0527 10:54:35.370111 25403 solver.cpp:253]     Train net output #0: loss = 1.24057 (* 1 = 1.24057 loss)
I0527 10:54:35.370126 25403 sgd_solver.cpp:106] Iteration 258375, lr = 0.0025
I0527 10:54:45.251349 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_258750.caffemodel
I0527 10:54:45.310492 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_258750.solverstate
I0527 10:54:45.346304 25403 solver.cpp:237] Iteration 258750, loss = 0.906079
I0527 10:54:45.346360 25403 solver.cpp:253]     Train net output #0: loss = 0.906079 (* 1 = 0.906079 loss)
I0527 10:54:45.346374 25403 sgd_solver.cpp:106] Iteration 258750, lr = 0.0025
I0527 10:54:55.247794 25403 solver.cpp:237] Iteration 259125, loss = 1.29359
I0527 10:54:55.247958 25403 solver.cpp:253]     Train net output #0: loss = 1.29359 (* 1 = 1.29359 loss)
I0527 10:54:55.247972 25403 sgd_solver.cpp:106] Iteration 259125, lr = 0.0025
I0527 10:55:05.160785 25403 solver.cpp:237] Iteration 259500, loss = 1.35397
I0527 10:55:05.160825 25403 solver.cpp:253]     Train net output #0: loss = 1.35397 (* 1 = 1.35397 loss)
I0527 10:55:05.160841 25403 sgd_solver.cpp:106] Iteration 259500, lr = 0.0025
I0527 10:55:15.074120 25403 solver.cpp:237] Iteration 259875, loss = 1.03566
I0527 10:55:15.074156 25403 solver.cpp:253]     Train net output #0: loss = 1.03566 (* 1 = 1.03566 loss)
I0527 10:55:15.074172 25403 sgd_solver.cpp:106] Iteration 259875, lr = 0.0025
I0527 10:55:45.861073 25403 solver.cpp:237] Iteration 260250, loss = 0.868449
I0527 10:55:45.861261 25403 solver.cpp:253]     Train net output #0: loss = 0.86845 (* 1 = 0.86845 loss)
I0527 10:55:45.861276 25403 sgd_solver.cpp:106] Iteration 260250, lr = 0.0025
I0527 10:55:55.769508 25403 solver.cpp:237] Iteration 260625, loss = 0.980645
I0527 10:55:55.769546 25403 solver.cpp:253]     Train net output #0: loss = 0.980646 (* 1 = 0.980646 loss)
I0527 10:55:55.769561 25403 sgd_solver.cpp:106] Iteration 260625, lr = 0.0025
I0527 10:56:05.678879 25403 solver.cpp:237] Iteration 261000, loss = 1.2287
I0527 10:56:05.678915 25403 solver.cpp:253]     Train net output #0: loss = 1.2287 (* 1 = 1.2287 loss)
I0527 10:56:05.678927 25403 sgd_solver.cpp:106] Iteration 261000, lr = 0.0025
I0527 10:56:15.590436 25403 solver.cpp:237] Iteration 261375, loss = 1.14982
I0527 10:56:15.590487 25403 solver.cpp:253]     Train net output #0: loss = 1.14983 (* 1 = 1.14983 loss)
I0527 10:56:15.590500 25403 sgd_solver.cpp:106] Iteration 261375, lr = 0.0025
I0527 10:56:25.500318 25403 solver.cpp:237] Iteration 261750, loss = 1.10105
I0527 10:56:25.500490 25403 solver.cpp:253]     Train net output #0: loss = 1.10105 (* 1 = 1.10105 loss)
I0527 10:56:25.500504 25403 sgd_solver.cpp:106] Iteration 261750, lr = 0.0025
I0527 10:56:35.407471 25403 solver.cpp:237] Iteration 262125, loss = 0.911851
I0527 10:56:35.407506 25403 solver.cpp:253]     Train net output #0: loss = 0.911852 (* 1 = 0.911852 loss)
I0527 10:56:35.407521 25403 sgd_solver.cpp:106] Iteration 262125, lr = 0.0025
I0527 10:56:45.290041 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_262500.caffemodel
I0527 10:56:45.346910 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_262500.solverstate
I0527 10:56:45.372776 25403 solver.cpp:341] Iteration 262500, Testing net (#0)
I0527 10:57:33.972738 25403 solver.cpp:409]     Test net output #0: accuracy = 0.902573
I0527 10:57:33.972923 25403 solver.cpp:409]     Test net output #1: loss = 0.300245 (* 1 = 0.300245 loss)
I0527 10:57:54.808974 25403 solver.cpp:237] Iteration 262500, loss = 0.896939
I0527 10:57:54.809031 25403 solver.cpp:253]     Train net output #0: loss = 0.896939 (* 1 = 0.896939 loss)
I0527 10:57:54.809046 25403 sgd_solver.cpp:106] Iteration 262500, lr = 0.0025
I0527 10:58:04.522447 25403 solver.cpp:237] Iteration 262875, loss = 1.37945
I0527 10:58:04.522616 25403 solver.cpp:253]     Train net output #0: loss = 1.37945 (* 1 = 1.37945 loss)
I0527 10:58:04.522630 25403 sgd_solver.cpp:106] Iteration 262875, lr = 0.0025
I0527 10:58:14.233944 25403 solver.cpp:237] Iteration 263250, loss = 1.10663
I0527 10:58:14.233978 25403 solver.cpp:253]     Train net output #0: loss = 1.10663 (* 1 = 1.10663 loss)
I0527 10:58:14.233992 25403 sgd_solver.cpp:106] Iteration 263250, lr = 0.0025
I0527 10:58:23.951967 25403 solver.cpp:237] Iteration 263625, loss = 1.11004
I0527 10:58:23.952013 25403 solver.cpp:253]     Train net output #0: loss = 1.11004 (* 1 = 1.11004 loss)
I0527 10:58:23.952029 25403 sgd_solver.cpp:106] Iteration 263625, lr = 0.0025
I0527 10:58:33.661878 25403 solver.cpp:237] Iteration 264000, loss = 1.12054
I0527 10:58:33.661913 25403 solver.cpp:253]     Train net output #0: loss = 1.12054 (* 1 = 1.12054 loss)
I0527 10:58:33.661929 25403 sgd_solver.cpp:106] Iteration 264000, lr = 0.0025
I0527 10:58:43.376318 25403 solver.cpp:237] Iteration 264375, loss = 1.15548
I0527 10:58:43.376487 25403 solver.cpp:253]     Train net output #0: loss = 1.15548 (* 1 = 1.15548 loss)
I0527 10:58:43.376502 25403 sgd_solver.cpp:106] Iteration 264375, lr = 0.0025
I0527 10:58:53.091505 25403 solver.cpp:237] Iteration 264750, loss = 1.13477
I0527 10:58:53.091538 25403 solver.cpp:253]     Train net output #0: loss = 1.13477 (* 1 = 1.13477 loss)
I0527 10:58:53.091557 25403 sgd_solver.cpp:106] Iteration 264750, lr = 0.0025
I0527 10:59:23.650522 25403 solver.cpp:237] Iteration 265125, loss = 1.3392
I0527 10:59:23.650710 25403 solver.cpp:253]     Train net output #0: loss = 1.3392 (* 1 = 1.3392 loss)
I0527 10:59:23.650727 25403 sgd_solver.cpp:106] Iteration 265125, lr = 0.0025
I0527 10:59:33.364539 25403 solver.cpp:237] Iteration 265500, loss = 0.883498
I0527 10:59:33.364591 25403 solver.cpp:253]     Train net output #0: loss = 0.883499 (* 1 = 0.883499 loss)
I0527 10:59:33.364608 25403 sgd_solver.cpp:106] Iteration 265500, lr = 0.0025
I0527 10:59:43.080662 25403 solver.cpp:237] Iteration 265875, loss = 1.00389
I0527 10:59:43.080698 25403 solver.cpp:253]     Train net output #0: loss = 1.00389 (* 1 = 1.00389 loss)
I0527 10:59:43.080713 25403 sgd_solver.cpp:106] Iteration 265875, lr = 0.0025
I0527 10:59:52.765458 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_266250.caffemodel
I0527 10:59:52.821352 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_266250.solverstate
I0527 10:59:52.855321 25403 solver.cpp:237] Iteration 266250, loss = 1.05044
I0527 10:59:52.855370 25403 solver.cpp:253]     Train net output #0: loss = 1.05044 (* 1 = 1.05044 loss)
I0527 10:59:52.855388 25403 sgd_solver.cpp:106] Iteration 266250, lr = 0.0025
I0527 11:00:02.566824 25403 solver.cpp:237] Iteration 266625, loss = 1.03229
I0527 11:00:02.567015 25403 solver.cpp:253]     Train net output #0: loss = 1.03229 (* 1 = 1.03229 loss)
I0527 11:00:02.567029 25403 sgd_solver.cpp:106] Iteration 266625, lr = 0.0025
I0527 11:00:12.281131 25403 solver.cpp:237] Iteration 267000, loss = 0.99349
I0527 11:00:12.281167 25403 solver.cpp:253]     Train net output #0: loss = 0.993491 (* 1 = 0.993491 loss)
I0527 11:00:12.281179 25403 sgd_solver.cpp:106] Iteration 267000, lr = 0.0025
I0527 11:00:21.989563 25403 solver.cpp:237] Iteration 267375, loss = 1.11365
I0527 11:00:21.989612 25403 solver.cpp:253]     Train net output #0: loss = 1.11365 (* 1 = 1.11365 loss)
I0527 11:00:21.989626 25403 sgd_solver.cpp:106] Iteration 267375, lr = 0.0025
I0527 11:00:52.586881 25403 solver.cpp:237] Iteration 267750, loss = 0.825796
I0527 11:00:52.587072 25403 solver.cpp:253]     Train net output #0: loss = 0.825797 (* 1 = 0.825797 loss)
I0527 11:00:52.587087 25403 sgd_solver.cpp:106] Iteration 267750, lr = 0.0025
I0527 11:01:02.302994 25403 solver.cpp:237] Iteration 268125, loss = 1.1853
I0527 11:01:02.303030 25403 solver.cpp:253]     Train net output #0: loss = 1.1853 (* 1 = 1.1853 loss)
I0527 11:01:02.303042 25403 sgd_solver.cpp:106] Iteration 268125, lr = 0.0025
I0527 11:01:12.018679 25403 solver.cpp:237] Iteration 268500, loss = 1.14881
I0527 11:01:12.018728 25403 solver.cpp:253]     Train net output #0: loss = 1.14881 (* 1 = 1.14881 loss)
I0527 11:01:12.018741 25403 sgd_solver.cpp:106] Iteration 268500, lr = 0.0025
I0527 11:01:21.734709 25403 solver.cpp:237] Iteration 268875, loss = 0.897195
I0527 11:01:21.734745 25403 solver.cpp:253]     Train net output #0: loss = 0.897195 (* 1 = 0.897195 loss)
I0527 11:01:21.734760 25403 sgd_solver.cpp:106] Iteration 268875, lr = 0.0025
I0527 11:01:31.441319 25403 solver.cpp:237] Iteration 269250, loss = 1.19663
I0527 11:01:31.441483 25403 solver.cpp:253]     Train net output #0: loss = 1.19664 (* 1 = 1.19664 loss)
I0527 11:01:31.441496 25403 sgd_solver.cpp:106] Iteration 269250, lr = 0.0025
I0527 11:01:41.155817 25403 solver.cpp:237] Iteration 269625, loss = 1.25311
I0527 11:01:41.155865 25403 solver.cpp:253]     Train net output #0: loss = 1.25311 (* 1 = 1.25311 loss)
I0527 11:01:41.155879 25403 sgd_solver.cpp:106] Iteration 269625, lr = 0.0025
I0527 11:01:50.846053 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_270000.caffemodel
I0527 11:01:50.901571 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_270000.solverstate
I0527 11:01:50.926648 25403 solver.cpp:341] Iteration 270000, Testing net (#0)
I0527 11:03:00.344629 25403 solver.cpp:409]     Test net output #0: accuracy = 0.902886
I0527 11:03:00.344820 25403 solver.cpp:409]     Test net output #1: loss = 0.304058 (* 1 = 0.304058 loss)
I0527 11:03:21.231184 25403 solver.cpp:237] Iteration 270000, loss = 1.05182
I0527 11:03:21.231240 25403 solver.cpp:253]     Train net output #0: loss = 1.05182 (* 1 = 1.05182 loss)
I0527 11:03:21.231256 25403 sgd_solver.cpp:106] Iteration 270000, lr = 0.0025
I0527 11:03:31.027164 25403 solver.cpp:237] Iteration 270375, loss = 1.48322
I0527 11:03:31.027331 25403 solver.cpp:253]     Train net output #0: loss = 1.48322 (* 1 = 1.48322 loss)
I0527 11:03:31.027345 25403 sgd_solver.cpp:106] Iteration 270375, lr = 0.0025
I0527 11:03:40.822952 25403 solver.cpp:237] Iteration 270750, loss = 1.19188
I0527 11:03:40.822998 25403 solver.cpp:253]     Train net output #0: loss = 1.19188 (* 1 = 1.19188 loss)
I0527 11:03:40.823010 25403 sgd_solver.cpp:106] Iteration 270750, lr = 0.0025
I0527 11:03:50.622740 25403 solver.cpp:237] Iteration 271125, loss = 0.87473
I0527 11:03:50.622792 25403 solver.cpp:253]     Train net output #0: loss = 0.874731 (* 1 = 0.874731 loss)
I0527 11:03:50.622810 25403 sgd_solver.cpp:106] Iteration 271125, lr = 0.0025
I0527 11:04:00.424232 25403 solver.cpp:237] Iteration 271500, loss = 0.977262
I0527 11:04:00.424268 25403 solver.cpp:253]     Train net output #0: loss = 0.977262 (* 1 = 0.977262 loss)
I0527 11:04:00.424283 25403 sgd_solver.cpp:106] Iteration 271500, lr = 0.0025
I0527 11:04:10.220753 25403 solver.cpp:237] Iteration 271875, loss = 1.18951
I0527 11:04:10.220942 25403 solver.cpp:253]     Train net output #0: loss = 1.18951 (* 1 = 1.18951 loss)
I0527 11:04:10.220955 25403 sgd_solver.cpp:106] Iteration 271875, lr = 0.0025
I0527 11:04:20.016062 25403 solver.cpp:237] Iteration 272250, loss = 0.937761
I0527 11:04:20.016098 25403 solver.cpp:253]     Train net output #0: loss = 0.937762 (* 1 = 0.937762 loss)
I0527 11:04:20.016111 25403 sgd_solver.cpp:106] Iteration 272250, lr = 0.0025
I0527 11:04:50.664680 25403 solver.cpp:237] Iteration 272625, loss = 1.10949
I0527 11:04:50.664871 25403 solver.cpp:253]     Train net output #0: loss = 1.10949 (* 1 = 1.10949 loss)
I0527 11:04:50.664886 25403 sgd_solver.cpp:106] Iteration 272625, lr = 0.0025
I0527 11:05:00.462798 25403 solver.cpp:237] Iteration 273000, loss = 1.37828
I0527 11:05:00.462846 25403 solver.cpp:253]     Train net output #0: loss = 1.37828 (* 1 = 1.37828 loss)
I0527 11:05:00.462863 25403 sgd_solver.cpp:106] Iteration 273000, lr = 0.0025
I0527 11:05:10.254113 25403 solver.cpp:237] Iteration 273375, loss = 1.29811
I0527 11:05:10.254149 25403 solver.cpp:253]     Train net output #0: loss = 1.29811 (* 1 = 1.29811 loss)
I0527 11:05:10.254163 25403 sgd_solver.cpp:106] Iteration 273375, lr = 0.0025
I0527 11:05:20.015878 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_273750.caffemodel
I0527 11:05:20.074991 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_273750.solverstate
I0527 11:05:20.110914 25403 solver.cpp:237] Iteration 273750, loss = 1.40609
I0527 11:05:20.110967 25403 solver.cpp:253]     Train net output #0: loss = 1.40609 (* 1 = 1.40609 loss)
I0527 11:05:20.110985 25403 sgd_solver.cpp:106] Iteration 273750, lr = 0.0025
I0527 11:05:29.910022 25403 solver.cpp:237] Iteration 274125, loss = 1.14685
I0527 11:05:29.910203 25403 solver.cpp:253]     Train net output #0: loss = 1.14685 (* 1 = 1.14685 loss)
I0527 11:05:29.910218 25403 sgd_solver.cpp:106] Iteration 274125, lr = 0.0025
I0527 11:05:39.704974 25403 solver.cpp:237] Iteration 274500, loss = 1.27142
I0527 11:05:39.705008 25403 solver.cpp:253]     Train net output #0: loss = 1.27142 (* 1 = 1.27142 loss)
I0527 11:05:39.705023 25403 sgd_solver.cpp:106] Iteration 274500, lr = 0.0025
I0527 11:05:49.507874 25403 solver.cpp:237] Iteration 274875, loss = 1.04674
I0527 11:05:49.507925 25403 solver.cpp:253]     Train net output #0: loss = 1.04674 (* 1 = 1.04674 loss)
I0527 11:05:49.507946 25403 sgd_solver.cpp:106] Iteration 274875, lr = 0.0025
I0527 11:06:20.242291 25403 solver.cpp:237] Iteration 275250, loss = 1.029
I0527 11:06:20.242481 25403 solver.cpp:253]     Train net output #0: loss = 1.029 (* 1 = 1.029 loss)
I0527 11:06:20.242496 25403 sgd_solver.cpp:106] Iteration 275250, lr = 0.0025
I0527 11:06:30.031806 25403 solver.cpp:237] Iteration 275625, loss = 1.25177
I0527 11:06:30.031841 25403 solver.cpp:253]     Train net output #0: loss = 1.25177 (* 1 = 1.25177 loss)
I0527 11:06:30.031854 25403 sgd_solver.cpp:106] Iteration 275625, lr = 0.0025
I0527 11:06:39.826700 25403 solver.cpp:237] Iteration 276000, loss = 1.27391
I0527 11:06:39.826747 25403 solver.cpp:253]     Train net output #0: loss = 1.27391 (* 1 = 1.27391 loss)
I0527 11:06:39.826761 25403 sgd_solver.cpp:106] Iteration 276000, lr = 0.0025
I0527 11:06:49.616636 25403 solver.cpp:237] Iteration 276375, loss = 1.24457
I0527 11:06:49.616672 25403 solver.cpp:253]     Train net output #0: loss = 1.24457 (* 1 = 1.24457 loss)
I0527 11:06:49.616689 25403 sgd_solver.cpp:106] Iteration 276375, lr = 0.0025
I0527 11:06:59.410248 25403 solver.cpp:237] Iteration 276750, loss = 1.30466
I0527 11:06:59.410421 25403 solver.cpp:253]     Train net output #0: loss = 1.30466 (* 1 = 1.30466 loss)
I0527 11:06:59.410435 25403 sgd_solver.cpp:106] Iteration 276750, lr = 0.0025
I0527 11:07:09.200578 25403 solver.cpp:237] Iteration 277125, loss = 1.14755
I0527 11:07:09.200621 25403 solver.cpp:253]     Train net output #0: loss = 1.14755 (* 1 = 1.14755 loss)
I0527 11:07:09.200642 25403 sgd_solver.cpp:106] Iteration 277125, lr = 0.0025
I0527 11:07:18.966655 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_277500.caffemodel
I0527 11:07:19.026574 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_277500.solverstate
I0527 11:07:19.054380 25403 solver.cpp:341] Iteration 277500, Testing net (#0)
I0527 11:08:07.232594 25403 solver.cpp:409]     Test net output #0: accuracy = 0.903647
I0527 11:08:07.232785 25403 solver.cpp:409]     Test net output #1: loss = 0.301619 (* 1 = 0.301619 loss)
I0527 11:08:28.116793 25403 solver.cpp:237] Iteration 277500, loss = 1.07229
I0527 11:08:28.116849 25403 solver.cpp:253]     Train net output #0: loss = 1.07229 (* 1 = 1.07229 loss)
I0527 11:08:28.116863 25403 sgd_solver.cpp:106] Iteration 277500, lr = 0.0025
I0527 11:08:37.851501 25403 solver.cpp:237] Iteration 277875, loss = 0.833663
I0527 11:08:37.851672 25403 solver.cpp:253]     Train net output #0: loss = 0.833664 (* 1 = 0.833664 loss)
I0527 11:08:37.851686 25403 sgd_solver.cpp:106] Iteration 277875, lr = 0.0025
I0527 11:08:47.594072 25403 solver.cpp:237] Iteration 278250, loss = 1.19606
I0527 11:08:47.594121 25403 solver.cpp:253]     Train net output #0: loss = 1.19606 (* 1 = 1.19606 loss)
I0527 11:08:47.594140 25403 sgd_solver.cpp:106] Iteration 278250, lr = 0.0025
I0527 11:08:57.337962 25403 solver.cpp:237] Iteration 278625, loss = 1.59423
I0527 11:08:57.337993 25403 solver.cpp:253]     Train net output #0: loss = 1.59423 (* 1 = 1.59423 loss)
I0527 11:08:57.338006 25403 sgd_solver.cpp:106] Iteration 278625, lr = 0.0025
I0527 11:09:07.075040 25403 solver.cpp:237] Iteration 279000, loss = 1.01966
I0527 11:09:07.075093 25403 solver.cpp:253]     Train net output #0: loss = 1.01966 (* 1 = 1.01966 loss)
I0527 11:09:07.075108 25403 sgd_solver.cpp:106] Iteration 279000, lr = 0.0025
I0527 11:09:16.814301 25403 solver.cpp:237] Iteration 279375, loss = 0.930264
I0527 11:09:16.814468 25403 solver.cpp:253]     Train net output #0: loss = 0.930264 (* 1 = 0.930264 loss)
I0527 11:09:16.814482 25403 sgd_solver.cpp:106] Iteration 279375, lr = 0.0025
I0527 11:09:26.545452 25403 solver.cpp:237] Iteration 279750, loss = 1.49347
I0527 11:09:26.545486 25403 solver.cpp:253]     Train net output #0: loss = 1.49347 (* 1 = 1.49347 loss)
I0527 11:09:26.545500 25403 sgd_solver.cpp:106] Iteration 279750, lr = 0.0025
I0527 11:09:57.148499 25403 solver.cpp:237] Iteration 280125, loss = 1.21038
I0527 11:09:57.148687 25403 solver.cpp:253]     Train net output #0: loss = 1.21038 (* 1 = 1.21038 loss)
I0527 11:09:57.148704 25403 sgd_solver.cpp:106] Iteration 280125, lr = 0.0025
I0527 11:10:06.890985 25403 solver.cpp:237] Iteration 280500, loss = 0.963368
I0527 11:10:06.891021 25403 solver.cpp:253]     Train net output #0: loss = 0.963369 (* 1 = 0.963369 loss)
I0527 11:10:06.891034 25403 sgd_solver.cpp:106] Iteration 280500, lr = 0.0025
I0527 11:10:16.626093 25403 solver.cpp:237] Iteration 280875, loss = 1.76546
I0527 11:10:16.626128 25403 solver.cpp:253]     Train net output #0: loss = 1.76546 (* 1 = 1.76546 loss)
I0527 11:10:16.626147 25403 sgd_solver.cpp:106] Iteration 280875, lr = 0.0025
I0527 11:10:26.337759 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_281250.caffemodel
I0527 11:10:26.393487 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_281250.solverstate
I0527 11:10:26.427651 25403 solver.cpp:237] Iteration 281250, loss = 1.00964
I0527 11:10:26.427700 25403 solver.cpp:253]     Train net output #0: loss = 1.00964 (* 1 = 1.00964 loss)
I0527 11:10:26.427717 25403 sgd_solver.cpp:106] Iteration 281250, lr = 0.0025
I0527 11:10:36.165001 25403 solver.cpp:237] Iteration 281625, loss = 1.35286
I0527 11:10:36.165181 25403 solver.cpp:253]     Train net output #0: loss = 1.35287 (* 1 = 1.35287 loss)
I0527 11:10:36.165196 25403 sgd_solver.cpp:106] Iteration 281625, lr = 0.0025
I0527 11:10:45.904052 25403 solver.cpp:237] Iteration 282000, loss = 1.03683
I0527 11:10:45.904088 25403 solver.cpp:253]     Train net output #0: loss = 1.03683 (* 1 = 1.03683 loss)
I0527 11:10:45.904101 25403 sgd_solver.cpp:106] Iteration 282000, lr = 0.0025
I0527 11:10:55.634240 25403 solver.cpp:237] Iteration 282375, loss = 0.980892
I0527 11:10:55.634275 25403 solver.cpp:253]     Train net output #0: loss = 0.980892 (* 1 = 0.980892 loss)
I0527 11:10:55.634297 25403 sgd_solver.cpp:106] Iteration 282375, lr = 0.0025
I0527 11:11:26.256104 25403 solver.cpp:237] Iteration 282750, loss = 0.855648
I0527 11:11:26.256299 25403 solver.cpp:253]     Train net output #0: loss = 0.855648 (* 1 = 0.855648 loss)
I0527 11:11:26.256314 25403 sgd_solver.cpp:106] Iteration 282750, lr = 0.0025
I0527 11:11:36.000196 25403 solver.cpp:237] Iteration 283125, loss = 1.05271
I0527 11:11:36.000232 25403 solver.cpp:253]     Train net output #0: loss = 1.05271 (* 1 = 1.05271 loss)
I0527 11:11:36.000247 25403 sgd_solver.cpp:106] Iteration 283125, lr = 0.0025
I0527 11:11:45.738808 25403 solver.cpp:237] Iteration 283500, loss = 1.17651
I0527 11:11:45.738842 25403 solver.cpp:253]     Train net output #0: loss = 1.17651 (* 1 = 1.17651 loss)
I0527 11:11:45.738863 25403 sgd_solver.cpp:106] Iteration 283500, lr = 0.0025
I0527 11:11:55.466709 25403 solver.cpp:237] Iteration 283875, loss = 1.18645
I0527 11:11:55.466745 25403 solver.cpp:253]     Train net output #0: loss = 1.18645 (* 1 = 1.18645 loss)
I0527 11:11:55.466759 25403 sgd_solver.cpp:106] Iteration 283875, lr = 0.0025
I0527 11:12:05.202611 25403 solver.cpp:237] Iteration 284250, loss = 1.11247
I0527 11:12:05.202795 25403 solver.cpp:253]     Train net output #0: loss = 1.11247 (* 1 = 1.11247 loss)
I0527 11:12:05.202808 25403 sgd_solver.cpp:106] Iteration 284250, lr = 0.0025
I0527 11:12:14.949180 25403 solver.cpp:237] Iteration 284625, loss = 1.16479
I0527 11:12:14.949215 25403 solver.cpp:253]     Train net output #0: loss = 1.16479 (* 1 = 1.16479 loss)
I0527 11:12:14.949229 25403 sgd_solver.cpp:106] Iteration 284625, lr = 0.0025
I0527 11:12:24.657702 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_285000.caffemodel
I0527 11:12:24.713505 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_285000.solverstate
I0527 11:12:24.739166 25403 solver.cpp:341] Iteration 285000, Testing net (#0)
I0527 11:13:34.205636 25403 solver.cpp:409]     Test net output #0: accuracy = 0.903306
I0527 11:13:34.205826 25403 solver.cpp:409]     Test net output #1: loss = 0.307587 (* 1 = 0.307587 loss)
I0527 11:13:55.086604 25403 solver.cpp:237] Iteration 285000, loss = 1.20735
I0527 11:13:55.086660 25403 solver.cpp:253]     Train net output #0: loss = 1.20735 (* 1 = 1.20735 loss)
I0527 11:13:55.086675 25403 sgd_solver.cpp:106] Iteration 285000, lr = 0.0025
I0527 11:14:04.881191 25403 solver.cpp:237] Iteration 285375, loss = 1.40996
I0527 11:14:04.881372 25403 solver.cpp:253]     Train net output #0: loss = 1.40996 (* 1 = 1.40996 loss)
I0527 11:14:04.881386 25403 sgd_solver.cpp:106] Iteration 285375, lr = 0.0025
I0527 11:14:14.693218 25403 solver.cpp:237] Iteration 285750, loss = 0.667225
I0527 11:14:14.693265 25403 solver.cpp:253]     Train net output #0: loss = 0.667226 (* 1 = 0.667226 loss)
I0527 11:14:14.693279 25403 sgd_solver.cpp:106] Iteration 285750, lr = 0.0025
I0527 11:14:24.529448 25403 solver.cpp:237] Iteration 286125, loss = 1.29158
I0527 11:14:24.529484 25403 solver.cpp:253]     Train net output #0: loss = 1.29158 (* 1 = 1.29158 loss)
I0527 11:14:24.529498 25403 sgd_solver.cpp:106] Iteration 286125, lr = 0.0025
I0527 11:14:34.361299 25403 solver.cpp:237] Iteration 286500, loss = 1.11229
I0527 11:14:34.361351 25403 solver.cpp:253]     Train net output #0: loss = 1.11229 (* 1 = 1.11229 loss)
I0527 11:14:34.361366 25403 sgd_solver.cpp:106] Iteration 286500, lr = 0.0025
I0527 11:14:44.194705 25403 solver.cpp:237] Iteration 286875, loss = 1.1998
I0527 11:14:44.194875 25403 solver.cpp:253]     Train net output #0: loss = 1.1998 (* 1 = 1.1998 loss)
I0527 11:14:44.194887 25403 sgd_solver.cpp:106] Iteration 286875, lr = 0.0025
I0527 11:14:54.024757 25403 solver.cpp:237] Iteration 287250, loss = 1.06265
I0527 11:14:54.024793 25403 solver.cpp:253]     Train net output #0: loss = 1.06265 (* 1 = 1.06265 loss)
I0527 11:14:54.024806 25403 sgd_solver.cpp:106] Iteration 287250, lr = 0.0025
I0527 11:15:24.755208 25403 solver.cpp:237] Iteration 287625, loss = 0.968576
I0527 11:15:24.755398 25403 solver.cpp:253]     Train net output #0: loss = 0.968577 (* 1 = 0.968577 loss)
I0527 11:15:24.755414 25403 sgd_solver.cpp:106] Iteration 287625, lr = 0.0025
I0527 11:15:34.585850 25403 solver.cpp:237] Iteration 288000, loss = 0.9141
I0527 11:15:34.585886 25403 solver.cpp:253]     Train net output #0: loss = 0.914101 (* 1 = 0.914101 loss)
I0527 11:15:34.585901 25403 sgd_solver.cpp:106] Iteration 288000, lr = 0.0025
I0527 11:15:44.416290 25403 solver.cpp:237] Iteration 288375, loss = 1.37419
I0527 11:15:44.416324 25403 solver.cpp:253]     Train net output #0: loss = 1.37419 (* 1 = 1.37419 loss)
I0527 11:15:44.416337 25403 sgd_solver.cpp:106] Iteration 288375, lr = 0.0025
I0527 11:15:54.221704 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_288750.caffemodel
I0527 11:15:54.278714 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_288750.solverstate
I0527 11:15:54.312391 25403 solver.cpp:237] Iteration 288750, loss = 1.19465
I0527 11:15:54.312438 25403 solver.cpp:253]     Train net output #0: loss = 1.19465 (* 1 = 1.19465 loss)
I0527 11:15:54.312456 25403 sgd_solver.cpp:106] Iteration 288750, lr = 0.0025
I0527 11:16:04.146826 25403 solver.cpp:237] Iteration 289125, loss = 0.938396
I0527 11:16:04.146997 25403 solver.cpp:253]     Train net output #0: loss = 0.938397 (* 1 = 0.938397 loss)
I0527 11:16:04.147011 25403 sgd_solver.cpp:106] Iteration 289125, lr = 0.0025
I0527 11:16:13.977463 25403 solver.cpp:237] Iteration 289500, loss = 1.18857
I0527 11:16:13.977514 25403 solver.cpp:253]     Train net output #0: loss = 1.18857 (* 1 = 1.18857 loss)
I0527 11:16:13.977530 25403 sgd_solver.cpp:106] Iteration 289500, lr = 0.0025
I0527 11:16:23.800817 25403 solver.cpp:237] Iteration 289875, loss = 0.951325
I0527 11:16:23.800853 25403 solver.cpp:253]     Train net output #0: loss = 0.951326 (* 1 = 0.951326 loss)
I0527 11:16:23.800865 25403 sgd_solver.cpp:106] Iteration 289875, lr = 0.0025
I0527 11:16:54.502996 25403 solver.cpp:237] Iteration 290250, loss = 1.02847
I0527 11:16:54.503201 25403 solver.cpp:253]     Train net output #0: loss = 1.02847 (* 1 = 1.02847 loss)
I0527 11:16:54.503216 25403 sgd_solver.cpp:106] Iteration 290250, lr = 0.0025
I0527 11:17:04.338721 25403 solver.cpp:237] Iteration 290625, loss = 0.923039
I0527 11:17:04.338769 25403 solver.cpp:253]     Train net output #0: loss = 0.923039 (* 1 = 0.923039 loss)
I0527 11:17:04.338788 25403 sgd_solver.cpp:106] Iteration 290625, lr = 0.0025
I0527 11:17:14.169844 25403 solver.cpp:237] Iteration 291000, loss = 0.926324
I0527 11:17:14.169880 25403 solver.cpp:253]     Train net output #0: loss = 0.926324 (* 1 = 0.926324 loss)
I0527 11:17:14.169893 25403 sgd_solver.cpp:106] Iteration 291000, lr = 0.0025
I0527 11:17:24.005847 25403 solver.cpp:237] Iteration 291375, loss = 0.966617
I0527 11:17:24.005883 25403 solver.cpp:253]     Train net output #0: loss = 0.966618 (* 1 = 0.966618 loss)
I0527 11:17:24.005897 25403 sgd_solver.cpp:106] Iteration 291375, lr = 0.0025
I0527 11:17:33.834987 25403 solver.cpp:237] Iteration 291750, loss = 1.13395
I0527 11:17:33.835175 25403 solver.cpp:253]     Train net output #0: loss = 1.13395 (* 1 = 1.13395 loss)
I0527 11:17:33.835189 25403 sgd_solver.cpp:106] Iteration 291750, lr = 0.0025
I0527 11:17:43.663717 25403 solver.cpp:237] Iteration 292125, loss = 0.701598
I0527 11:17:43.663751 25403 solver.cpp:253]     Train net output #0: loss = 0.701599 (* 1 = 0.701599 loss)
I0527 11:17:43.663765 25403 sgd_solver.cpp:106] Iteration 292125, lr = 0.0025
I0527 11:17:53.460263 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_292500.caffemodel
I0527 11:17:53.516561 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_292500.solverstate
I0527 11:17:53.541548 25403 solver.cpp:341] Iteration 292500, Testing net (#0)
I0527 11:18:42.103111 25403 solver.cpp:409]     Test net output #0: accuracy = 0.905619
I0527 11:18:42.103302 25403 solver.cpp:409]     Test net output #1: loss = 0.301887 (* 1 = 0.301887 loss)
I0527 11:19:03.011360 25403 solver.cpp:237] Iteration 292500, loss = 0.920925
I0527 11:19:03.011418 25403 solver.cpp:253]     Train net output #0: loss = 0.920926 (* 1 = 0.920926 loss)
I0527 11:19:03.011433 25403 sgd_solver.cpp:106] Iteration 292500, lr = 0.0025
I0527 11:19:12.721608 25403 solver.cpp:237] Iteration 292875, loss = 0.988109
I0527 11:19:12.721797 25403 solver.cpp:253]     Train net output #0: loss = 0.988109 (* 1 = 0.988109 loss)
I0527 11:19:12.721812 25403 sgd_solver.cpp:106] Iteration 292875, lr = 0.0025
I0527 11:19:22.435808 25403 solver.cpp:237] Iteration 293250, loss = 1.36538
I0527 11:19:22.435842 25403 solver.cpp:253]     Train net output #0: loss = 1.36538 (* 1 = 1.36538 loss)
I0527 11:19:22.435858 25403 sgd_solver.cpp:106] Iteration 293250, lr = 0.0025
I0527 11:19:32.142123 25403 solver.cpp:237] Iteration 293625, loss = 0.890805
I0527 11:19:32.142173 25403 solver.cpp:253]     Train net output #0: loss = 0.890805 (* 1 = 0.890805 loss)
I0527 11:19:32.142189 25403 sgd_solver.cpp:106] Iteration 293625, lr = 0.0025
I0527 11:19:41.843842 25403 solver.cpp:237] Iteration 294000, loss = 1.11614
I0527 11:19:41.843876 25403 solver.cpp:253]     Train net output #0: loss = 1.11614 (* 1 = 1.11614 loss)
I0527 11:19:41.843889 25403 sgd_solver.cpp:106] Iteration 294000, lr = 0.0025
I0527 11:19:51.551360 25403 solver.cpp:237] Iteration 294375, loss = 1.13624
I0527 11:19:51.551532 25403 solver.cpp:253]     Train net output #0: loss = 1.13624 (* 1 = 1.13624 loss)
I0527 11:19:51.551545 25403 sgd_solver.cpp:106] Iteration 294375, lr = 0.0025
I0527 11:20:01.257264 25403 solver.cpp:237] Iteration 294750, loss = 1.52215
I0527 11:20:01.257310 25403 solver.cpp:253]     Train net output #0: loss = 1.52215 (* 1 = 1.52215 loss)
I0527 11:20:01.257328 25403 sgd_solver.cpp:106] Iteration 294750, lr = 0.0025
I0527 11:20:31.855612 25403 solver.cpp:237] Iteration 295125, loss = 0.919015
I0527 11:20:31.855825 25403 solver.cpp:253]     Train net output #0: loss = 0.919016 (* 1 = 0.919016 loss)
I0527 11:20:31.855841 25403 sgd_solver.cpp:106] Iteration 295125, lr = 0.0025
I0527 11:20:41.564435 25403 solver.cpp:237] Iteration 295500, loss = 1.10645
I0527 11:20:41.564484 25403 solver.cpp:253]     Train net output #0: loss = 1.10645 (* 1 = 1.10645 loss)
I0527 11:20:41.564502 25403 sgd_solver.cpp:106] Iteration 295500, lr = 0.0025
I0527 11:20:51.271492 25403 solver.cpp:237] Iteration 295875, loss = 0.997302
I0527 11:20:51.271540 25403 solver.cpp:253]     Train net output #0: loss = 0.997303 (* 1 = 0.997303 loss)
I0527 11:20:51.271558 25403 sgd_solver.cpp:106] Iteration 295875, lr = 0.0025
I0527 11:21:00.960085 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_296250.caffemodel
I0527 11:21:01.021147 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_296250.solverstate
I0527 11:21:01.056713 25403 solver.cpp:237] Iteration 296250, loss = 1.32962
I0527 11:21:01.056763 25403 solver.cpp:253]     Train net output #0: loss = 1.32962 (* 1 = 1.32962 loss)
I0527 11:21:01.056780 25403 sgd_solver.cpp:106] Iteration 296250, lr = 0.0025
I0527 11:21:10.761448 25403 solver.cpp:237] Iteration 296625, loss = 1.28815
I0527 11:21:10.761626 25403 solver.cpp:253]     Train net output #0: loss = 1.28815 (* 1 = 1.28815 loss)
I0527 11:21:10.761641 25403 sgd_solver.cpp:106] Iteration 296625, lr = 0.0025
I0527 11:21:20.474000 25403 solver.cpp:237] Iteration 297000, loss = 1.51452
I0527 11:21:20.474045 25403 solver.cpp:253]     Train net output #0: loss = 1.51452 (* 1 = 1.51452 loss)
I0527 11:21:20.474058 25403 sgd_solver.cpp:106] Iteration 297000, lr = 0.0025
I0527 11:21:30.181479 25403 solver.cpp:237] Iteration 297375, loss = 0.93831
I0527 11:21:30.181515 25403 solver.cpp:253]     Train net output #0: loss = 0.938311 (* 1 = 0.938311 loss)
I0527 11:21:30.181529 25403 sgd_solver.cpp:106] Iteration 297375, lr = 0.0025
I0527 11:22:00.802959 25403 solver.cpp:237] Iteration 297750, loss = 1.1334
I0527 11:22:00.803153 25403 solver.cpp:253]     Train net output #0: loss = 1.1334 (* 1 = 1.1334 loss)
I0527 11:22:00.803169 25403 sgd_solver.cpp:106] Iteration 297750, lr = 0.0025
I0527 11:22:10.512034 25403 solver.cpp:237] Iteration 298125, loss = 0.839572
I0527 11:22:10.512081 25403 solver.cpp:253]     Train net output #0: loss = 0.839573 (* 1 = 0.839573 loss)
I0527 11:22:10.512095 25403 sgd_solver.cpp:106] Iteration 298125, lr = 0.0025
I0527 11:22:20.217087 25403 solver.cpp:237] Iteration 298500, loss = 1.50239
I0527 11:22:20.217120 25403 solver.cpp:253]     Train net output #0: loss = 1.50239 (* 1 = 1.50239 loss)
I0527 11:22:20.217139 25403 sgd_solver.cpp:106] Iteration 298500, lr = 0.0025
I0527 11:22:29.929805 25403 solver.cpp:237] Iteration 298875, loss = 1.48766
I0527 11:22:29.929848 25403 solver.cpp:253]     Train net output #0: loss = 1.48766 (* 1 = 1.48766 loss)
I0527 11:22:29.929865 25403 sgd_solver.cpp:106] Iteration 298875, lr = 0.0025
I0527 11:22:39.635671 25403 solver.cpp:237] Iteration 299250, loss = 1.1543
I0527 11:22:39.635849 25403 solver.cpp:253]     Train net output #0: loss = 1.1543 (* 1 = 1.1543 loss)
I0527 11:22:39.635864 25403 sgd_solver.cpp:106] Iteration 299250, lr = 0.0025
I0527 11:22:49.350057 25403 solver.cpp:237] Iteration 299625, loss = 0.917945
I0527 11:22:49.350093 25403 solver.cpp:253]     Train net output #0: loss = 0.917946 (* 1 = 0.917946 loss)
I0527 11:22:49.350112 25403 sgd_solver.cpp:106] Iteration 299625, lr = 0.0025
I0527 11:22:59.030871 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_300000.caffemodel
I0527 11:22:59.093724 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_300000.solverstate
I0527 11:22:59.125113 25403 solver.cpp:341] Iteration 300000, Testing net (#0)
I0527 11:24:08.507899 25403 solver.cpp:409]     Test net output #0: accuracy = 0.901707
I0527 11:24:08.508101 25403 solver.cpp:409]     Test net output #1: loss = 0.300575 (* 1 = 0.300575 loss)
I0527 11:24:29.368966 25403 solver.cpp:237] Iteration 300000, loss = 1.23597
I0527 11:24:29.369022 25403 solver.cpp:253]     Train net output #0: loss = 1.23598 (* 1 = 1.23598 loss)
I0527 11:24:29.369037 25403 sgd_solver.cpp:106] Iteration 300000, lr = 0.0025
I0527 11:24:39.292711 25403 solver.cpp:237] Iteration 300375, loss = 0.998766
I0527 11:24:39.292902 25403 solver.cpp:253]     Train net output #0: loss = 0.998766 (* 1 = 0.998766 loss)
I0527 11:24:39.292917 25403 sgd_solver.cpp:106] Iteration 300375, lr = 0.0025
I0527 11:24:49.213464 25403 solver.cpp:237] Iteration 300750, loss = 0.989994
I0527 11:24:49.213498 25403 solver.cpp:253]     Train net output #0: loss = 0.989995 (* 1 = 0.989995 loss)
I0527 11:24:49.213512 25403 sgd_solver.cpp:106] Iteration 300750, lr = 0.0025
I0527 11:24:59.132485 25403 solver.cpp:237] Iteration 301125, loss = 1.0484
I0527 11:24:59.132536 25403 solver.cpp:253]     Train net output #0: loss = 1.0484 (* 1 = 1.0484 loss)
I0527 11:24:59.132552 25403 sgd_solver.cpp:106] Iteration 301125, lr = 0.0025
I0527 11:25:09.055905 25403 solver.cpp:237] Iteration 301500, loss = 1.13608
I0527 11:25:09.055939 25403 solver.cpp:253]     Train net output #0: loss = 1.13608 (* 1 = 1.13608 loss)
I0527 11:25:09.055953 25403 sgd_solver.cpp:106] Iteration 301500, lr = 0.0025
I0527 11:25:18.976930 25403 solver.cpp:237] Iteration 301875, loss = 1.34683
I0527 11:25:18.977103 25403 solver.cpp:253]     Train net output #0: loss = 1.34683 (* 1 = 1.34683 loss)
I0527 11:25:18.977116 25403 sgd_solver.cpp:106] Iteration 301875, lr = 0.0025
I0527 11:25:28.897462 25403 solver.cpp:237] Iteration 302250, loss = 1.06979
I0527 11:25:28.897508 25403 solver.cpp:253]     Train net output #0: loss = 1.06979 (* 1 = 1.06979 loss)
I0527 11:25:28.897527 25403 sgd_solver.cpp:106] Iteration 302250, lr = 0.0025
I0527 11:25:59.642087 25403 solver.cpp:237] Iteration 302625, loss = 1.20155
I0527 11:25:59.642284 25403 solver.cpp:253]     Train net output #0: loss = 1.20155 (* 1 = 1.20155 loss)
I0527 11:25:59.642300 25403 sgd_solver.cpp:106] Iteration 302625, lr = 0.0025
I0527 11:26:09.567175 25403 solver.cpp:237] Iteration 303000, loss = 0.952361
I0527 11:26:09.567211 25403 solver.cpp:253]     Train net output #0: loss = 0.952361 (* 1 = 0.952361 loss)
I0527 11:26:09.567225 25403 sgd_solver.cpp:106] Iteration 303000, lr = 0.0025
I0527 11:26:19.493561 25403 solver.cpp:237] Iteration 303375, loss = 1.25426
I0527 11:26:19.493604 25403 solver.cpp:253]     Train net output #0: loss = 1.25426 (* 1 = 1.25426 loss)
I0527 11:26:19.493623 25403 sgd_solver.cpp:106] Iteration 303375, lr = 0.0025
I0527 11:26:29.391162 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_303750.caffemodel
I0527 11:26:29.448649 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_303750.solverstate
I0527 11:26:29.482661 25403 solver.cpp:237] Iteration 303750, loss = 1.00116
I0527 11:26:29.482704 25403 solver.cpp:253]     Train net output #0: loss = 1.00117 (* 1 = 1.00117 loss)
I0527 11:26:29.482724 25403 sgd_solver.cpp:106] Iteration 303750, lr = 0.0025
I0527 11:26:39.416055 25403 solver.cpp:237] Iteration 304125, loss = 0.904939
I0527 11:26:39.416249 25403 solver.cpp:253]     Train net output #0: loss = 0.90494 (* 1 = 0.90494 loss)
I0527 11:26:39.416265 25403 sgd_solver.cpp:106] Iteration 304125, lr = 0.0025
I0527 11:26:49.339470 25403 solver.cpp:237] Iteration 304500, loss = 1.41062
I0527 11:26:49.339505 25403 solver.cpp:253]     Train net output #0: loss = 1.41062 (* 1 = 1.41062 loss)
I0527 11:26:49.339522 25403 sgd_solver.cpp:106] Iteration 304500, lr = 0.0025
I0527 11:26:59.269342 25403 solver.cpp:237] Iteration 304875, loss = 0.845148
I0527 11:26:59.269377 25403 solver.cpp:253]     Train net output #0: loss = 0.845149 (* 1 = 0.845149 loss)
I0527 11:26:59.269393 25403 sgd_solver.cpp:106] Iteration 304875, lr = 0.0025
I0527 11:27:30.033071 25403 solver.cpp:237] Iteration 305250, loss = 1.36301
I0527 11:27:30.033278 25403 solver.cpp:253]     Train net output #0: loss = 1.36301 (* 1 = 1.36301 loss)
I0527 11:27:30.033293 25403 sgd_solver.cpp:106] Iteration 305250, lr = 0.0025
I0527 11:27:39.968540 25403 solver.cpp:237] Iteration 305625, loss = 1.37587
I0527 11:27:39.968576 25403 solver.cpp:253]     Train net output #0: loss = 1.37587 (* 1 = 1.37587 loss)
I0527 11:27:39.968590 25403 sgd_solver.cpp:106] Iteration 305625, lr = 0.0025
I0527 11:27:49.895109 25403 solver.cpp:237] Iteration 306000, loss = 1.16689
I0527 11:27:49.895144 25403 solver.cpp:253]     Train net output #0: loss = 1.16689 (* 1 = 1.16689 loss)
I0527 11:27:49.895158 25403 sgd_solver.cpp:106] Iteration 306000, lr = 0.0025
I0527 11:27:59.817545 25403 solver.cpp:237] Iteration 306375, loss = 1.04772
I0527 11:27:59.817589 25403 solver.cpp:253]     Train net output #0: loss = 1.04772 (* 1 = 1.04772 loss)
I0527 11:27:59.817610 25403 sgd_solver.cpp:106] Iteration 306375, lr = 0.0025
I0527 11:28:09.745832 25403 solver.cpp:237] Iteration 306750, loss = 1.16834
I0527 11:28:09.746002 25403 solver.cpp:253]     Train net output #0: loss = 1.16834 (* 1 = 1.16834 loss)
I0527 11:28:09.746016 25403 sgd_solver.cpp:106] Iteration 306750, lr = 0.0025
I0527 11:28:19.674088 25403 solver.cpp:237] Iteration 307125, loss = 1.00559
I0527 11:28:19.674129 25403 solver.cpp:253]     Train net output #0: loss = 1.00559 (* 1 = 1.00559 loss)
I0527 11:28:19.674149 25403 sgd_solver.cpp:106] Iteration 307125, lr = 0.0025
I0527 11:28:29.568948 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_307500.caffemodel
I0527 11:28:29.627846 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_307500.solverstate
I0527 11:28:29.653012 25403 solver.cpp:341] Iteration 307500, Testing net (#0)
I0527 11:29:17.845640 25403 solver.cpp:409]     Test net output #0: accuracy = 0.903999
I0527 11:29:17.845836 25403 solver.cpp:409]     Test net output #1: loss = 0.312261 (* 1 = 0.312261 loss)
I0527 11:29:38.686269 25403 solver.cpp:237] Iteration 307500, loss = 1.11381
I0527 11:29:38.686324 25403 solver.cpp:253]     Train net output #0: loss = 1.11381 (* 1 = 1.11381 loss)
I0527 11:29:38.686339 25403 sgd_solver.cpp:106] Iteration 307500, lr = 0.0025
I0527 11:29:48.402715 25403 solver.cpp:237] Iteration 307875, loss = 1.13123
I0527 11:29:48.402892 25403 solver.cpp:253]     Train net output #0: loss = 1.13123 (* 1 = 1.13123 loss)
I0527 11:29:48.402906 25403 sgd_solver.cpp:106] Iteration 307875, lr = 0.0025
I0527 11:29:58.122987 25403 solver.cpp:237] Iteration 308250, loss = 1.03119
I0527 11:29:58.123037 25403 solver.cpp:253]     Train net output #0: loss = 1.0312 (* 1 = 1.0312 loss)
I0527 11:29:58.123051 25403 sgd_solver.cpp:106] Iteration 308250, lr = 0.0025
I0527 11:30:07.792687 25403 solver.cpp:237] Iteration 308625, loss = 0.788506
I0527 11:30:07.792723 25403 solver.cpp:253]     Train net output #0: loss = 0.788507 (* 1 = 0.788507 loss)
I0527 11:30:07.792737 25403 sgd_solver.cpp:106] Iteration 308625, lr = 0.0025
I0527 11:30:17.465602 25403 solver.cpp:237] Iteration 309000, loss = 1.16379
I0527 11:30:17.465637 25403 solver.cpp:253]     Train net output #0: loss = 1.16379 (* 1 = 1.16379 loss)
I0527 11:30:17.465651 25403 sgd_solver.cpp:106] Iteration 309000, lr = 0.0025
I0527 11:30:27.136380 25403 solver.cpp:237] Iteration 309375, loss = 0.952423
I0527 11:30:27.136586 25403 solver.cpp:253]     Train net output #0: loss = 0.952423 (* 1 = 0.952423 loss)
I0527 11:30:27.136601 25403 sgd_solver.cpp:106] Iteration 309375, lr = 0.0025
I0527 11:30:36.808944 25403 solver.cpp:237] Iteration 309750, loss = 0.891315
I0527 11:30:36.808979 25403 solver.cpp:253]     Train net output #0: loss = 0.891316 (* 1 = 0.891316 loss)
I0527 11:30:36.808995 25403 sgd_solver.cpp:106] Iteration 309750, lr = 0.0025
I0527 11:31:07.311528 25403 solver.cpp:237] Iteration 310125, loss = 1.19811
I0527 11:31:07.311728 25403 solver.cpp:253]     Train net output #0: loss = 1.19811 (* 1 = 1.19811 loss)
I0527 11:31:07.311743 25403 sgd_solver.cpp:106] Iteration 310125, lr = 0.0025
I0527 11:31:16.987233 25403 solver.cpp:237] Iteration 310500, loss = 1.19991
I0527 11:31:16.987282 25403 solver.cpp:253]     Train net output #0: loss = 1.19991 (* 1 = 1.19991 loss)
I0527 11:31:16.987296 25403 sgd_solver.cpp:106] Iteration 310500, lr = 0.0025
I0527 11:31:26.660924 25403 solver.cpp:237] Iteration 310875, loss = 1.27074
I0527 11:31:26.660959 25403 solver.cpp:253]     Train net output #0: loss = 1.27074 (* 1 = 1.27074 loss)
I0527 11:31:26.660972 25403 sgd_solver.cpp:106] Iteration 310875, lr = 0.0025
I0527 11:31:36.305554 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_311250.caffemodel
I0527 11:31:36.371318 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_311250.solverstate
I0527 11:31:36.404301 25403 solver.cpp:237] Iteration 311250, loss = 1.66807
I0527 11:31:36.404345 25403 solver.cpp:253]     Train net output #0: loss = 1.66807 (* 1 = 1.66807 loss)
I0527 11:31:36.404364 25403 sgd_solver.cpp:106] Iteration 311250, lr = 0.0025
I0527 11:31:46.073746 25403 solver.cpp:237] Iteration 311625, loss = 0.860414
I0527 11:31:46.073923 25403 solver.cpp:253]     Train net output #0: loss = 0.860415 (* 1 = 0.860415 loss)
I0527 11:31:46.073937 25403 sgd_solver.cpp:106] Iteration 311625, lr = 0.0025
I0527 11:31:55.748752 25403 solver.cpp:237] Iteration 312000, loss = 1.36779
I0527 11:31:55.748786 25403 solver.cpp:253]     Train net output #0: loss = 1.36779 (* 1 = 1.36779 loss)
I0527 11:31:55.748805 25403 sgd_solver.cpp:106] Iteration 312000, lr = 0.0025
I0527 11:32:05.414229 25403 solver.cpp:237] Iteration 312375, loss = 1.29406
I0527 11:32:05.414278 25403 solver.cpp:253]     Train net output #0: loss = 1.29406 (* 1 = 1.29406 loss)
I0527 11:32:05.414293 25403 sgd_solver.cpp:106] Iteration 312375, lr = 0.0025
I0527 11:32:35.955265 25403 solver.cpp:237] Iteration 312750, loss = 0.807128
I0527 11:32:35.955466 25403 solver.cpp:253]     Train net output #0: loss = 0.807128 (* 1 = 0.807128 loss)
I0527 11:32:35.955482 25403 sgd_solver.cpp:106] Iteration 312750, lr = 0.0025
I0527 11:32:45.624866 25403 solver.cpp:237] Iteration 313125, loss = 1.20978
I0527 11:32:45.624899 25403 solver.cpp:253]     Train net output #0: loss = 1.20978 (* 1 = 1.20978 loss)
I0527 11:32:45.624917 25403 sgd_solver.cpp:106] Iteration 313125, lr = 0.0025
I0527 11:32:55.299821 25403 solver.cpp:237] Iteration 313500, loss = 1.09422
I0527 11:32:55.299862 25403 solver.cpp:253]     Train net output #0: loss = 1.09422 (* 1 = 1.09422 loss)
I0527 11:32:55.299885 25403 sgd_solver.cpp:106] Iteration 313500, lr = 0.0025
I0527 11:33:04.973554 25403 solver.cpp:237] Iteration 313875, loss = 1.12241
I0527 11:33:04.973588 25403 solver.cpp:253]     Train net output #0: loss = 1.12241 (* 1 = 1.12241 loss)
I0527 11:33:04.973603 25403 sgd_solver.cpp:106] Iteration 313875, lr = 0.0025
I0527 11:33:14.647848 25403 solver.cpp:237] Iteration 314250, loss = 1.47618
I0527 11:33:14.648020 25403 solver.cpp:253]     Train net output #0: loss = 1.47618 (* 1 = 1.47618 loss)
I0527 11:33:14.648033 25403 sgd_solver.cpp:106] Iteration 314250, lr = 0.0025
I0527 11:33:24.323223 25403 solver.cpp:237] Iteration 314625, loss = 1.25275
I0527 11:33:24.323268 25403 solver.cpp:253]     Train net output #0: loss = 1.25275 (* 1 = 1.25275 loss)
I0527 11:33:24.323288 25403 sgd_solver.cpp:106] Iteration 314625, lr = 0.0025
I0527 11:33:33.970144 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_315000.caffemodel
I0527 11:33:34.030652 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_315000.solverstate
I0527 11:33:34.058248 25403 solver.cpp:341] Iteration 315000, Testing net (#0)
I0527 11:34:43.402930 25403 solver.cpp:409]     Test net output #0: accuracy = 0.90224
I0527 11:34:43.403147 25403 solver.cpp:409]     Test net output #1: loss = 0.31283 (* 1 = 0.31283 loss)
I0527 11:35:04.281441 25403 solver.cpp:237] Iteration 315000, loss = 0.862311
I0527 11:35:04.281500 25403 solver.cpp:253]     Train net output #0: loss = 0.862312 (* 1 = 0.862312 loss)
I0527 11:35:04.281515 25403 sgd_solver.cpp:106] Iteration 315000, lr = 0.0025
I0527 11:35:14.138717 25403 solver.cpp:237] Iteration 315375, loss = 1.10117
I0527 11:35:14.138898 25403 solver.cpp:253]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0527 11:35:14.138911 25403 sgd_solver.cpp:106] Iteration 315375, lr = 0.0025
I0527 11:35:23.994916 25403 solver.cpp:237] Iteration 315750, loss = 1.41776
I0527 11:35:23.994962 25403 solver.cpp:253]     Train net output #0: loss = 1.41776 (* 1 = 1.41776 loss)
I0527 11:35:23.994981 25403 sgd_solver.cpp:106] Iteration 315750, lr = 0.0025
I0527 11:35:33.846979 25403 solver.cpp:237] Iteration 316125, loss = 1.08251
I0527 11:35:33.847015 25403 solver.cpp:253]     Train net output #0: loss = 1.08251 (* 1 = 1.08251 loss)
I0527 11:35:33.847028 25403 sgd_solver.cpp:106] Iteration 316125, lr = 0.0025
I0527 11:35:43.701328 25403 solver.cpp:237] Iteration 316500, loss = 0.909963
I0527 11:35:43.701365 25403 solver.cpp:253]     Train net output #0: loss = 0.909963 (* 1 = 0.909963 loss)
I0527 11:35:43.701378 25403 sgd_solver.cpp:106] Iteration 316500, lr = 0.0025
I0527 11:35:53.558773 25403 solver.cpp:237] Iteration 316875, loss = 1.22205
I0527 11:35:53.559032 25403 solver.cpp:253]     Train net output #0: loss = 1.22205 (* 1 = 1.22205 loss)
I0527 11:35:53.559046 25403 sgd_solver.cpp:106] Iteration 316875, lr = 0.0025
I0527 11:36:03.416713 25403 solver.cpp:237] Iteration 317250, loss = 1.18187
I0527 11:36:03.416748 25403 solver.cpp:253]     Train net output #0: loss = 1.18187 (* 1 = 1.18187 loss)
I0527 11:36:03.416764 25403 sgd_solver.cpp:106] Iteration 317250, lr = 0.0025
I0527 11:36:34.142379 25403 solver.cpp:237] Iteration 317625, loss = 1.02665
I0527 11:36:34.142580 25403 solver.cpp:253]     Train net output #0: loss = 1.02665 (* 1 = 1.02665 loss)
I0527 11:36:34.142596 25403 sgd_solver.cpp:106] Iteration 317625, lr = 0.0025
I0527 11:36:43.994845 25403 solver.cpp:237] Iteration 318000, loss = 0.932357
I0527 11:36:43.994885 25403 solver.cpp:253]     Train net output #0: loss = 0.932358 (* 1 = 0.932358 loss)
I0527 11:36:43.994900 25403 sgd_solver.cpp:106] Iteration 318000, lr = 0.0025
I0527 11:36:53.851764 25403 solver.cpp:237] Iteration 318375, loss = 1.60208
I0527 11:36:53.851799 25403 solver.cpp:253]     Train net output #0: loss = 1.60208 (* 1 = 1.60208 loss)
I0527 11:36:53.851815 25403 sgd_solver.cpp:106] Iteration 318375, lr = 0.0025
I0527 11:37:03.687054 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_318750.caffemodel
I0527 11:37:03.743165 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_318750.solverstate
I0527 11:37:03.777017 25403 solver.cpp:237] Iteration 318750, loss = 1.15082
I0527 11:37:03.777062 25403 solver.cpp:253]     Train net output #0: loss = 1.15082 (* 1 = 1.15082 loss)
I0527 11:37:03.777086 25403 sgd_solver.cpp:106] Iteration 318750, lr = 0.0025
I0527 11:37:13.628667 25403 solver.cpp:237] Iteration 319125, loss = 1.06211
I0527 11:37:13.628856 25403 solver.cpp:253]     Train net output #0: loss = 1.06212 (* 1 = 1.06212 loss)
I0527 11:37:13.628870 25403 sgd_solver.cpp:106] Iteration 319125, lr = 0.0025
I0527 11:37:23.479811 25403 solver.cpp:237] Iteration 319500, loss = 0.99763
I0527 11:37:23.479846 25403 solver.cpp:253]     Train net output #0: loss = 0.99763 (* 1 = 0.99763 loss)
I0527 11:37:23.479863 25403 sgd_solver.cpp:106] Iteration 319500, lr = 0.0025
I0527 11:37:33.335868 25403 solver.cpp:237] Iteration 319875, loss = 0.938994
I0527 11:37:33.335918 25403 solver.cpp:253]     Train net output #0: loss = 0.938995 (* 1 = 0.938995 loss)
I0527 11:37:33.335937 25403 sgd_solver.cpp:106] Iteration 319875, lr = 0.0025
I0527 11:38:04.084543 25403 solver.cpp:237] Iteration 320250, loss = 1.21461
I0527 11:38:04.084748 25403 solver.cpp:253]     Train net output #0: loss = 1.21461 (* 1 = 1.21461 loss)
I0527 11:38:04.084763 25403 sgd_solver.cpp:106] Iteration 320250, lr = 0.0025
I0527 11:38:13.939363 25403 solver.cpp:237] Iteration 320625, loss = 0.900623
I0527 11:38:13.939399 25403 solver.cpp:253]     Train net output #0: loss = 0.900623 (* 1 = 0.900623 loss)
I0527 11:38:13.939412 25403 sgd_solver.cpp:106] Iteration 320625, lr = 0.0025
I0527 11:38:23.795627 25403 solver.cpp:237] Iteration 321000, loss = 1.05427
I0527 11:38:23.795681 25403 solver.cpp:253]     Train net output #0: loss = 1.05427 (* 1 = 1.05427 loss)
I0527 11:38:23.795697 25403 sgd_solver.cpp:106] Iteration 321000, lr = 0.0025
I0527 11:38:33.656035 25403 solver.cpp:237] Iteration 321375, loss = 0.990108
I0527 11:38:33.656071 25403 solver.cpp:253]     Train net output #0: loss = 0.990108 (* 1 = 0.990108 loss)
I0527 11:38:33.656085 25403 sgd_solver.cpp:106] Iteration 321375, lr = 0.0025
I0527 11:38:43.508183 25403 solver.cpp:237] Iteration 321750, loss = 1.1266
I0527 11:38:43.508374 25403 solver.cpp:253]     Train net output #0: loss = 1.1266 (* 1 = 1.1266 loss)
I0527 11:38:43.508389 25403 sgd_solver.cpp:106] Iteration 321750, lr = 0.0025
I0527 11:38:53.371866 25403 solver.cpp:237] Iteration 322125, loss = 1.07599
I0527 11:38:53.371901 25403 solver.cpp:253]     Train net output #0: loss = 1.07599 (* 1 = 1.07599 loss)
I0527 11:38:53.371918 25403 sgd_solver.cpp:106] Iteration 322125, lr = 0.0025
I0527 11:39:03.200443 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_322500.caffemodel
I0527 11:39:03.256963 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_322500.solverstate
I0527 11:39:03.281862 25403 solver.cpp:341] Iteration 322500, Testing net (#0)
I0527 11:39:51.791662 25403 solver.cpp:409]     Test net output #0: accuracy = 0.904946
I0527 11:39:51.791877 25403 solver.cpp:409]     Test net output #1: loss = 0.290689 (* 1 = 0.290689 loss)
I0527 11:40:12.643883 25403 solver.cpp:237] Iteration 322500, loss = 1.09697
I0527 11:40:12.643939 25403 solver.cpp:253]     Train net output #0: loss = 1.09698 (* 1 = 1.09698 loss)
I0527 11:40:12.643954 25403 sgd_solver.cpp:106] Iteration 322500, lr = 0.0025
I0527 11:40:22.331226 25403 solver.cpp:237] Iteration 322875, loss = 0.926609
I0527 11:40:22.331423 25403 solver.cpp:253]     Train net output #0: loss = 0.926609 (* 1 = 0.926609 loss)
I0527 11:40:22.331439 25403 sgd_solver.cpp:106] Iteration 322875, lr = 0.0025
I0527 11:40:32.010253 25403 solver.cpp:237] Iteration 323250, loss = 1.03583
I0527 11:40:32.010288 25403 solver.cpp:253]     Train net output #0: loss = 1.03583 (* 1 = 1.03583 loss)
I0527 11:40:32.010303 25403 sgd_solver.cpp:106] Iteration 323250, lr = 0.0025
I0527 11:40:41.701488 25403 solver.cpp:237] Iteration 323625, loss = 1.14112
I0527 11:40:41.701524 25403 solver.cpp:253]     Train net output #0: loss = 1.14112 (* 1 = 1.14112 loss)
I0527 11:40:41.701540 25403 sgd_solver.cpp:106] Iteration 323625, lr = 0.0025
I0527 11:40:51.401496 25403 solver.cpp:237] Iteration 324000, loss = 1.07151
I0527 11:40:51.401543 25403 solver.cpp:253]     Train net output #0: loss = 1.07151 (* 1 = 1.07151 loss)
I0527 11:40:51.401561 25403 sgd_solver.cpp:106] Iteration 324000, lr = 0.0025
I0527 11:41:01.093387 25403 solver.cpp:237] Iteration 324375, loss = 1.19976
I0527 11:41:01.093592 25403 solver.cpp:253]     Train net output #0: loss = 1.19976 (* 1 = 1.19976 loss)
I0527 11:41:01.093606 25403 sgd_solver.cpp:106] Iteration 324375, lr = 0.0025
I0527 11:41:10.793342 25403 solver.cpp:237] Iteration 324750, loss = 1.28226
I0527 11:41:10.793377 25403 solver.cpp:253]     Train net output #0: loss = 1.28226 (* 1 = 1.28226 loss)
I0527 11:41:10.793393 25403 sgd_solver.cpp:106] Iteration 324750, lr = 0.0025
I0527 11:41:41.339967 25403 solver.cpp:237] Iteration 325125, loss = 0.96623
I0527 11:41:41.340163 25403 solver.cpp:253]     Train net output #0: loss = 0.966231 (* 1 = 0.966231 loss)
I0527 11:41:41.340178 25403 sgd_solver.cpp:106] Iteration 325125, lr = 0.0025
I0527 11:41:51.047894 25403 solver.cpp:237] Iteration 325500, loss = 1.21834
I0527 11:41:51.047927 25403 solver.cpp:253]     Train net output #0: loss = 1.21834 (* 1 = 1.21834 loss)
I0527 11:41:51.047945 25403 sgd_solver.cpp:106] Iteration 325500, lr = 0.0025
I0527 11:42:00.752202 25403 solver.cpp:237] Iteration 325875, loss = 1.14676
I0527 11:42:00.752236 25403 solver.cpp:253]     Train net output #0: loss = 1.14676 (* 1 = 1.14676 loss)
I0527 11:42:00.752254 25403 sgd_solver.cpp:106] Iteration 325875, lr = 0.0025
I0527 11:42:10.432339 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_326250.caffemodel
I0527 11:42:10.488359 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_326250.solverstate
I0527 11:42:10.521998 25403 solver.cpp:237] Iteration 326250, loss = 1.04535
I0527 11:42:10.522047 25403 solver.cpp:253]     Train net output #0: loss = 1.04535 (* 1 = 1.04535 loss)
I0527 11:42:10.522064 25403 sgd_solver.cpp:106] Iteration 326250, lr = 0.0025
I0527 11:42:20.228844 25403 solver.cpp:237] Iteration 326625, loss = 1.02012
I0527 11:42:20.229025 25403 solver.cpp:253]     Train net output #0: loss = 1.02012 (* 1 = 1.02012 loss)
I0527 11:42:20.229038 25403 sgd_solver.cpp:106] Iteration 326625, lr = 0.0025
I0527 11:42:29.928727 25403 solver.cpp:237] Iteration 327000, loss = 1.03112
I0527 11:42:29.928769 25403 solver.cpp:253]     Train net output #0: loss = 1.03112 (* 1 = 1.03112 loss)
I0527 11:42:29.928791 25403 sgd_solver.cpp:106] Iteration 327000, lr = 0.0025
I0527 11:42:39.632552 25403 solver.cpp:237] Iteration 327375, loss = 1.0004
I0527 11:42:39.632587 25403 solver.cpp:253]     Train net output #0: loss = 1.0004 (* 1 = 1.0004 loss)
I0527 11:42:39.632601 25403 sgd_solver.cpp:106] Iteration 327375, lr = 0.0025
I0527 11:43:10.228613 25403 solver.cpp:237] Iteration 327750, loss = 1.20765
I0527 11:43:10.228816 25403 solver.cpp:253]     Train net output #0: loss = 1.20765 (* 1 = 1.20765 loss)
I0527 11:43:10.228832 25403 sgd_solver.cpp:106] Iteration 327750, lr = 0.0025
I0527 11:43:19.933578 25403 solver.cpp:237] Iteration 328125, loss = 1.1414
I0527 11:43:19.933629 25403 solver.cpp:253]     Train net output #0: loss = 1.1414 (* 1 = 1.1414 loss)
I0527 11:43:19.933645 25403 sgd_solver.cpp:106] Iteration 328125, lr = 0.0025
I0527 11:43:29.644501 25403 solver.cpp:237] Iteration 328500, loss = 1.23436
I0527 11:43:29.644537 25403 solver.cpp:253]     Train net output #0: loss = 1.23436 (* 1 = 1.23436 loss)
I0527 11:43:29.644553 25403 sgd_solver.cpp:106] Iteration 328500, lr = 0.0025
I0527 11:43:39.350080 25403 solver.cpp:237] Iteration 328875, loss = 1.2675
I0527 11:43:39.350113 25403 solver.cpp:253]     Train net output #0: loss = 1.2675 (* 1 = 1.2675 loss)
I0527 11:43:39.350128 25403 sgd_solver.cpp:106] Iteration 328875, lr = 0.0025
I0527 11:43:49.050380 25403 solver.cpp:237] Iteration 329250, loss = 1.04701
I0527 11:43:49.050587 25403 solver.cpp:253]     Train net output #0: loss = 1.04701 (* 1 = 1.04701 loss)
I0527 11:43:49.050602 25403 sgd_solver.cpp:106] Iteration 329250, lr = 0.0025
I0527 11:43:58.758939 25403 solver.cpp:237] Iteration 329625, loss = 0.986041
I0527 11:43:58.758973 25403 solver.cpp:253]     Train net output #0: loss = 0.986042 (* 1 = 0.986042 loss)
I0527 11:43:58.758987 25403 sgd_solver.cpp:106] Iteration 329625, lr = 0.0025
I0527 11:44:08.437484 25403 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_330000.caffemodel
I0527 11:44:08.493329 25403 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0025_2016-05-20T15.49.02.631491_iter_330000.solverstate
I0527 11:44:08.519073 25403 solver.cpp:341] Iteration 330000, Testing net (#0)
I0527 11:45:17.951511 25403 solver.cpp:409]     Test net output #0: accuracy = 0.904834
I0527 11:45:17.951714 25403 solver.cpp:409]     Test net output #1: loss = 0.305313 (* 1 = 0.305313 loss)
I0527 11:45:38.861877 25403 solver.cpp:237] Iteration 330000, loss = 0.876345
I0527 11:45:38.861935 25403 solver.cpp:253]     Train net output #0: loss = 0.876345 (* 1 = 0.876345 loss)
I0527 11:45:38.861951 25403 sgd_solver.cpp:106] Iteration 330000, lr = 0.0025
I0527 11:45:48.813746 25403 solver.cpp:237] Iteration 330375, loss = 0.986941
I0527 11:45:48.813940 25403 solver.cpp:253]     Train net output #0: loss = 0.986941 (* 1 = 0.986941 loss)
I0527 11:45:48.813953 25403 sgd_solver.cpp:106] Iteration 330375, lr = 0.0025
I0527 11:45:58.771706 25403 solver.cpp:237] Iteration 330750, loss = 1.1266
I0527 11:45:58.771741 25403 solver.cpp:253]     Train net output #0: loss = 1.1266 (* 1 = 1.1266 loss)
I0527 11:45:58.771755 25403 sgd_solver.cpp:106] Iteration 330750, lr = 0.0025
I0527 11:46:08.720499 25403 solver.cpp:237] Iteration 331125, loss = 1.21326
I0527 11:46:08.720535 25403 solver.cpp:253]     Train net output #0: loss = 1.21326 (* 1 = 1.21326 loss)
I0527 11:46:08.720551 25403 sgd_solver.cpp:106] Iteration 331125, lr = 0.0025
I0527 11:46:18.678783 25403 solver.cpp:237] Iteration 331500, loss = 1.09169
I0527 11:46:18.678819 25403 solver.cpp:253]     Train net output #0: loss = 1.09169 (* 1 = 1.09169 loss)
I0527 11:46:18.678840 25403 sgd_solver.cpp:106] Iteration 331500, lr = 0.0025
I0527 11:46:28.631969 25403 solver.cpp:237] Iteration 331875, loss = 0.883938
I0527 11:46:28.632143 25403 solver.cpp:253]     Train net output #0: loss = 0.883939 (* 1 = 0.883939 loss)
I0527 11:46:28.632158 25403 sgd_solver.cpp:106] Iteration 331875, lr = 0.0025
I0527 11:46:38.590448 25403 solver.cpp:237] Iteration 332250, loss = 0.905091
I0527 11:46:38.590489 25403 solver.cpp:253]     Train net output #0: loss = 0.905091 (* 1 = 0.905091 loss)
I0527 11:46:38.590509 25403 sgd_solver.cpp:106] Iteration 332250, lr = 0.0025
I0527 11:47:09.464334 25403 solver.cpp:237] Iteration 332625, loss = 1.20446
I0527 11:47:09.464539 25403 solver.cpp:253]     Train net output #0: loss = 1.20446 (* 1 = 1.20446 loss)
I0527 11:47:09.464553 25403 sgd_solver.cpp:106] Iteration 332625, lr = 0.0025
I0527 11:47:19.422044 25403 solver.cpp:237] Iteration 333000, loss = 1.13383
I0527 11:47:19.422080 25403 solver.cpp:253]     Train net output #0: loss = 1.13383 (* 1 = 1.13383 loss)
I0527 11:47:19.422096 25403 sgd_solver.cpp:106] Iteration 333000, lr = 0.0025
aprun: Apid 11273097: Caught signal Terminated, sending to application
*** Aborted at 1464364044 (unix time) try "date -d @1464364044" if you are using GNU date ***
PC: @     0x2aaab9276640 (unknown)
*** SIGTERM (@0x6338) received by PID 25403 (TID 0x2aaac746f900) from PID 25400; stack trace: ***
=>> PBS: job killed: walltime 7218 exceeded limit 7200
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab9276640 (unknown)
aprun: Apid 11273097: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
aprun: Apid 11273097: Caught signal Terminated, sending to application
    @     0x2aaab928a368 (unknown)
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11273097: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11273097: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x60ee80 caffe::caffe_gpu_memcpy()
aprun: Apid 11273097: Caught signal Terminated, sending to application
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11273097: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11273097: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
aprun: Apid 11273097: Caught signal Terminated, sending to application
