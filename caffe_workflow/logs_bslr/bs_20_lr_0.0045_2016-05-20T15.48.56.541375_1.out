2807174
I0522 04:05:30.635776 12754 caffe.cpp:184] Using GPUs 0
I0522 04:05:31.061800 12754 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0045
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375.prototxt"
I0522 04:05:31.063477 12754 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375.prototxt
I0522 04:05:31.078717 12754 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 04:05:31.078778 12754 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 04:05:31.079124 12754 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 04:05:31.079303 12754 layer_factory.hpp:77] Creating layer data_hdf5
I0522 04:05:31.079327 12754 net.cpp:106] Creating Layer data_hdf5
I0522 04:05:31.079341 12754 net.cpp:411] data_hdf5 -> data
I0522 04:05:31.079375 12754 net.cpp:411] data_hdf5 -> label
I0522 04:05:31.079407 12754 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 04:05:31.080780 12754 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 04:05:31.083047 12754 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 04:05:52.619740 12754 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 04:05:52.625007 12754 net.cpp:150] Setting up data_hdf5
I0522 04:05:52.625047 12754 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 04:05:52.625062 12754 net.cpp:157] Top shape: 20 (20)
I0522 04:05:52.625075 12754 net.cpp:165] Memory required for data: 508080
I0522 04:05:52.625089 12754 layer_factory.hpp:77] Creating layer conv1
I0522 04:05:52.625124 12754 net.cpp:106] Creating Layer conv1
I0522 04:05:52.625135 12754 net.cpp:454] conv1 <- data
I0522 04:05:52.625159 12754 net.cpp:411] conv1 -> conv1
I0522 04:05:52.991439 12754 net.cpp:150] Setting up conv1
I0522 04:05:52.991487 12754 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 04:05:52.991497 12754 net.cpp:165] Memory required for data: 6037680
I0522 04:05:52.991526 12754 layer_factory.hpp:77] Creating layer relu1
I0522 04:05:52.991549 12754 net.cpp:106] Creating Layer relu1
I0522 04:05:52.991559 12754 net.cpp:454] relu1 <- conv1
I0522 04:05:52.991572 12754 net.cpp:397] relu1 -> conv1 (in-place)
I0522 04:05:52.992089 12754 net.cpp:150] Setting up relu1
I0522 04:05:52.992106 12754 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 04:05:52.992116 12754 net.cpp:165] Memory required for data: 11567280
I0522 04:05:52.992127 12754 layer_factory.hpp:77] Creating layer pool1
I0522 04:05:52.992143 12754 net.cpp:106] Creating Layer pool1
I0522 04:05:52.992153 12754 net.cpp:454] pool1 <- conv1
I0522 04:05:52.992166 12754 net.cpp:411] pool1 -> pool1
I0522 04:05:52.992246 12754 net.cpp:150] Setting up pool1
I0522 04:05:52.992260 12754 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 04:05:52.992270 12754 net.cpp:165] Memory required for data: 14332080
I0522 04:05:52.992280 12754 layer_factory.hpp:77] Creating layer conv2
I0522 04:05:52.992302 12754 net.cpp:106] Creating Layer conv2
I0522 04:05:52.992313 12754 net.cpp:454] conv2 <- pool1
I0522 04:05:52.992326 12754 net.cpp:411] conv2 -> conv2
I0522 04:05:52.995041 12754 net.cpp:150] Setting up conv2
I0522 04:05:52.995065 12754 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 04:05:52.995076 12754 net.cpp:165] Memory required for data: 18306480
I0522 04:05:52.995095 12754 layer_factory.hpp:77] Creating layer relu2
I0522 04:05:52.995110 12754 net.cpp:106] Creating Layer relu2
I0522 04:05:52.995121 12754 net.cpp:454] relu2 <- conv2
I0522 04:05:52.995133 12754 net.cpp:397] relu2 -> conv2 (in-place)
I0522 04:05:52.995465 12754 net.cpp:150] Setting up relu2
I0522 04:05:52.995479 12754 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 04:05:52.995489 12754 net.cpp:165] Memory required for data: 22280880
I0522 04:05:52.995499 12754 layer_factory.hpp:77] Creating layer pool2
I0522 04:05:52.995512 12754 net.cpp:106] Creating Layer pool2
I0522 04:05:52.995522 12754 net.cpp:454] pool2 <- conv2
I0522 04:05:52.995534 12754 net.cpp:411] pool2 -> pool2
I0522 04:05:52.995616 12754 net.cpp:150] Setting up pool2
I0522 04:05:52.995630 12754 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 04:05:52.995640 12754 net.cpp:165] Memory required for data: 24268080
I0522 04:05:52.995649 12754 layer_factory.hpp:77] Creating layer conv3
I0522 04:05:52.995669 12754 net.cpp:106] Creating Layer conv3
I0522 04:05:52.995681 12754 net.cpp:454] conv3 <- pool2
I0522 04:05:52.995694 12754 net.cpp:411] conv3 -> conv3
I0522 04:05:52.997651 12754 net.cpp:150] Setting up conv3
I0522 04:05:52.997674 12754 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 04:05:52.997687 12754 net.cpp:165] Memory required for data: 26436400
I0522 04:05:52.997706 12754 layer_factory.hpp:77] Creating layer relu3
I0522 04:05:52.997722 12754 net.cpp:106] Creating Layer relu3
I0522 04:05:52.997732 12754 net.cpp:454] relu3 <- conv3
I0522 04:05:52.997745 12754 net.cpp:397] relu3 -> conv3 (in-place)
I0522 04:05:52.998217 12754 net.cpp:150] Setting up relu3
I0522 04:05:52.998234 12754 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 04:05:52.998245 12754 net.cpp:165] Memory required for data: 28604720
I0522 04:05:52.998256 12754 layer_factory.hpp:77] Creating layer pool3
I0522 04:05:52.998270 12754 net.cpp:106] Creating Layer pool3
I0522 04:05:52.998280 12754 net.cpp:454] pool3 <- conv3
I0522 04:05:52.998292 12754 net.cpp:411] pool3 -> pool3
I0522 04:05:52.998359 12754 net.cpp:150] Setting up pool3
I0522 04:05:52.998373 12754 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 04:05:52.998383 12754 net.cpp:165] Memory required for data: 29688880
I0522 04:05:52.998392 12754 layer_factory.hpp:77] Creating layer conv4
I0522 04:05:52.998412 12754 net.cpp:106] Creating Layer conv4
I0522 04:05:52.998423 12754 net.cpp:454] conv4 <- pool3
I0522 04:05:52.998437 12754 net.cpp:411] conv4 -> conv4
I0522 04:05:53.001157 12754 net.cpp:150] Setting up conv4
I0522 04:05:53.001184 12754 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 04:05:53.001196 12754 net.cpp:165] Memory required for data: 30414640
I0522 04:05:53.001212 12754 layer_factory.hpp:77] Creating layer relu4
I0522 04:05:53.001226 12754 net.cpp:106] Creating Layer relu4
I0522 04:05:53.001236 12754 net.cpp:454] relu4 <- conv4
I0522 04:05:53.001250 12754 net.cpp:397] relu4 -> conv4 (in-place)
I0522 04:05:53.001714 12754 net.cpp:150] Setting up relu4
I0522 04:05:53.001730 12754 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 04:05:53.001741 12754 net.cpp:165] Memory required for data: 31140400
I0522 04:05:53.001751 12754 layer_factory.hpp:77] Creating layer pool4
I0522 04:05:53.001765 12754 net.cpp:106] Creating Layer pool4
I0522 04:05:53.001775 12754 net.cpp:454] pool4 <- conv4
I0522 04:05:53.001788 12754 net.cpp:411] pool4 -> pool4
I0522 04:05:53.001857 12754 net.cpp:150] Setting up pool4
I0522 04:05:53.001870 12754 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 04:05:53.001880 12754 net.cpp:165] Memory required for data: 31503280
I0522 04:05:53.001890 12754 layer_factory.hpp:77] Creating layer ip1
I0522 04:05:53.001909 12754 net.cpp:106] Creating Layer ip1
I0522 04:05:53.001919 12754 net.cpp:454] ip1 <- pool4
I0522 04:05:53.001934 12754 net.cpp:411] ip1 -> ip1
I0522 04:05:53.017331 12754 net.cpp:150] Setting up ip1
I0522 04:05:53.017359 12754 net.cpp:157] Top shape: 20 196 (3920)
I0522 04:05:53.017372 12754 net.cpp:165] Memory required for data: 31518960
I0522 04:05:53.017395 12754 layer_factory.hpp:77] Creating layer relu5
I0522 04:05:53.017410 12754 net.cpp:106] Creating Layer relu5
I0522 04:05:53.017421 12754 net.cpp:454] relu5 <- ip1
I0522 04:05:53.017433 12754 net.cpp:397] relu5 -> ip1 (in-place)
I0522 04:05:53.017774 12754 net.cpp:150] Setting up relu5
I0522 04:05:53.017788 12754 net.cpp:157] Top shape: 20 196 (3920)
I0522 04:05:53.017798 12754 net.cpp:165] Memory required for data: 31534640
I0522 04:05:53.017809 12754 layer_factory.hpp:77] Creating layer drop1
I0522 04:05:53.017830 12754 net.cpp:106] Creating Layer drop1
I0522 04:05:53.017840 12754 net.cpp:454] drop1 <- ip1
I0522 04:05:53.017853 12754 net.cpp:397] drop1 -> ip1 (in-place)
I0522 04:05:53.017911 12754 net.cpp:150] Setting up drop1
I0522 04:05:53.017925 12754 net.cpp:157] Top shape: 20 196 (3920)
I0522 04:05:53.017935 12754 net.cpp:165] Memory required for data: 31550320
I0522 04:05:53.017945 12754 layer_factory.hpp:77] Creating layer ip2
I0522 04:05:53.017963 12754 net.cpp:106] Creating Layer ip2
I0522 04:05:53.017973 12754 net.cpp:454] ip2 <- ip1
I0522 04:05:53.017987 12754 net.cpp:411] ip2 -> ip2
I0522 04:05:53.018447 12754 net.cpp:150] Setting up ip2
I0522 04:05:53.018461 12754 net.cpp:157] Top shape: 20 98 (1960)
I0522 04:05:53.018471 12754 net.cpp:165] Memory required for data: 31558160
I0522 04:05:53.018486 12754 layer_factory.hpp:77] Creating layer relu6
I0522 04:05:53.018498 12754 net.cpp:106] Creating Layer relu6
I0522 04:05:53.018507 12754 net.cpp:454] relu6 <- ip2
I0522 04:05:53.018519 12754 net.cpp:397] relu6 -> ip2 (in-place)
I0522 04:05:53.019040 12754 net.cpp:150] Setting up relu6
I0522 04:05:53.019057 12754 net.cpp:157] Top shape: 20 98 (1960)
I0522 04:05:53.019068 12754 net.cpp:165] Memory required for data: 31566000
I0522 04:05:53.019079 12754 layer_factory.hpp:77] Creating layer drop2
I0522 04:05:53.019093 12754 net.cpp:106] Creating Layer drop2
I0522 04:05:53.019103 12754 net.cpp:454] drop2 <- ip2
I0522 04:05:53.019115 12754 net.cpp:397] drop2 -> ip2 (in-place)
I0522 04:05:53.019157 12754 net.cpp:150] Setting up drop2
I0522 04:05:53.019170 12754 net.cpp:157] Top shape: 20 98 (1960)
I0522 04:05:53.019181 12754 net.cpp:165] Memory required for data: 31573840
I0522 04:05:53.019191 12754 layer_factory.hpp:77] Creating layer ip3
I0522 04:05:53.019204 12754 net.cpp:106] Creating Layer ip3
I0522 04:05:53.019214 12754 net.cpp:454] ip3 <- ip2
I0522 04:05:53.019227 12754 net.cpp:411] ip3 -> ip3
I0522 04:05:53.019438 12754 net.cpp:150] Setting up ip3
I0522 04:05:53.019453 12754 net.cpp:157] Top shape: 20 11 (220)
I0522 04:05:53.019462 12754 net.cpp:165] Memory required for data: 31574720
I0522 04:05:53.019477 12754 layer_factory.hpp:77] Creating layer drop3
I0522 04:05:53.019490 12754 net.cpp:106] Creating Layer drop3
I0522 04:05:53.019500 12754 net.cpp:454] drop3 <- ip3
I0522 04:05:53.019512 12754 net.cpp:397] drop3 -> ip3 (in-place)
I0522 04:05:53.019552 12754 net.cpp:150] Setting up drop3
I0522 04:05:53.019565 12754 net.cpp:157] Top shape: 20 11 (220)
I0522 04:05:53.019575 12754 net.cpp:165] Memory required for data: 31575600
I0522 04:05:53.019585 12754 layer_factory.hpp:77] Creating layer loss
I0522 04:05:53.019605 12754 net.cpp:106] Creating Layer loss
I0522 04:05:53.019615 12754 net.cpp:454] loss <- ip3
I0522 04:05:53.019626 12754 net.cpp:454] loss <- label
I0522 04:05:53.019637 12754 net.cpp:411] loss -> loss
I0522 04:05:53.019654 12754 layer_factory.hpp:77] Creating layer loss
I0522 04:05:53.020345 12754 net.cpp:150] Setting up loss
I0522 04:05:53.020366 12754 net.cpp:157] Top shape: (1)
I0522 04:05:53.020380 12754 net.cpp:160]     with loss weight 1
I0522 04:05:53.020422 12754 net.cpp:165] Memory required for data: 31575604
I0522 04:05:53.020432 12754 net.cpp:226] loss needs backward computation.
I0522 04:05:53.020445 12754 net.cpp:226] drop3 needs backward computation.
I0522 04:05:53.020455 12754 net.cpp:226] ip3 needs backward computation.
I0522 04:05:53.020463 12754 net.cpp:226] drop2 needs backward computation.
I0522 04:05:53.020474 12754 net.cpp:226] relu6 needs backward computation.
I0522 04:05:53.020483 12754 net.cpp:226] ip2 needs backward computation.
I0522 04:05:53.020493 12754 net.cpp:226] drop1 needs backward computation.
I0522 04:05:53.020503 12754 net.cpp:226] relu5 needs backward computation.
I0522 04:05:53.020514 12754 net.cpp:226] ip1 needs backward computation.
I0522 04:05:53.020524 12754 net.cpp:226] pool4 needs backward computation.
I0522 04:05:53.020534 12754 net.cpp:226] relu4 needs backward computation.
I0522 04:05:53.020544 12754 net.cpp:226] conv4 needs backward computation.
I0522 04:05:53.020553 12754 net.cpp:226] pool3 needs backward computation.
I0522 04:05:53.020565 12754 net.cpp:226] relu3 needs backward computation.
I0522 04:05:53.020575 12754 net.cpp:226] conv3 needs backward computation.
I0522 04:05:53.020592 12754 net.cpp:226] pool2 needs backward computation.
I0522 04:05:53.020604 12754 net.cpp:226] relu2 needs backward computation.
I0522 04:05:53.020614 12754 net.cpp:226] conv2 needs backward computation.
I0522 04:05:53.020624 12754 net.cpp:226] pool1 needs backward computation.
I0522 04:05:53.020635 12754 net.cpp:226] relu1 needs backward computation.
I0522 04:05:53.020645 12754 net.cpp:226] conv1 needs backward computation.
I0522 04:05:53.020656 12754 net.cpp:228] data_hdf5 does not need backward computation.
I0522 04:05:53.020666 12754 net.cpp:270] This network produces output loss
I0522 04:05:53.020690 12754 net.cpp:283] Network initialization done.
I0522 04:05:53.022358 12754 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375.prototxt
I0522 04:05:53.022430 12754 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 04:05:53.022788 12754 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 04:05:53.022977 12754 layer_factory.hpp:77] Creating layer data_hdf5
I0522 04:05:53.022992 12754 net.cpp:106] Creating Layer data_hdf5
I0522 04:05:53.023005 12754 net.cpp:411] data_hdf5 -> data
I0522 04:05:53.023021 12754 net.cpp:411] data_hdf5 -> label
I0522 04:05:53.023037 12754 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 04:05:53.024477 12754 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 04:06:14.357235 12754 net.cpp:150] Setting up data_hdf5
I0522 04:06:14.357414 12754 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0522 04:06:14.357429 12754 net.cpp:157] Top shape: 20 (20)
I0522 04:06:14.357439 12754 net.cpp:165] Memory required for data: 508080
I0522 04:06:14.357452 12754 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 04:06:14.357481 12754 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 04:06:14.357492 12754 net.cpp:454] label_data_hdf5_1_split <- label
I0522 04:06:14.357507 12754 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 04:06:14.357529 12754 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 04:06:14.357604 12754 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 04:06:14.357617 12754 net.cpp:157] Top shape: 20 (20)
I0522 04:06:14.357630 12754 net.cpp:157] Top shape: 20 (20)
I0522 04:06:14.357638 12754 net.cpp:165] Memory required for data: 508240
I0522 04:06:14.357648 12754 layer_factory.hpp:77] Creating layer conv1
I0522 04:06:14.357671 12754 net.cpp:106] Creating Layer conv1
I0522 04:06:14.357681 12754 net.cpp:454] conv1 <- data
I0522 04:06:14.357697 12754 net.cpp:411] conv1 -> conv1
I0522 04:06:14.359645 12754 net.cpp:150] Setting up conv1
I0522 04:06:14.359665 12754 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 04:06:14.359679 12754 net.cpp:165] Memory required for data: 6037840
I0522 04:06:14.359701 12754 layer_factory.hpp:77] Creating layer relu1
I0522 04:06:14.359716 12754 net.cpp:106] Creating Layer relu1
I0522 04:06:14.359726 12754 net.cpp:454] relu1 <- conv1
I0522 04:06:14.359740 12754 net.cpp:397] relu1 -> conv1 (in-place)
I0522 04:06:14.360242 12754 net.cpp:150] Setting up relu1
I0522 04:06:14.360258 12754 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0522 04:06:14.360270 12754 net.cpp:165] Memory required for data: 11567440
I0522 04:06:14.360280 12754 layer_factory.hpp:77] Creating layer pool1
I0522 04:06:14.360296 12754 net.cpp:106] Creating Layer pool1
I0522 04:06:14.360306 12754 net.cpp:454] pool1 <- conv1
I0522 04:06:14.360319 12754 net.cpp:411] pool1 -> pool1
I0522 04:06:14.360394 12754 net.cpp:150] Setting up pool1
I0522 04:06:14.360409 12754 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0522 04:06:14.360419 12754 net.cpp:165] Memory required for data: 14332240
I0522 04:06:14.360425 12754 layer_factory.hpp:77] Creating layer conv2
I0522 04:06:14.360443 12754 net.cpp:106] Creating Layer conv2
I0522 04:06:14.360453 12754 net.cpp:454] conv2 <- pool1
I0522 04:06:14.360468 12754 net.cpp:411] conv2 -> conv2
I0522 04:06:14.362421 12754 net.cpp:150] Setting up conv2
I0522 04:06:14.362444 12754 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 04:06:14.362454 12754 net.cpp:165] Memory required for data: 18306640
I0522 04:06:14.362474 12754 layer_factory.hpp:77] Creating layer relu2
I0522 04:06:14.362488 12754 net.cpp:106] Creating Layer relu2
I0522 04:06:14.362498 12754 net.cpp:454] relu2 <- conv2
I0522 04:06:14.362510 12754 net.cpp:397] relu2 -> conv2 (in-place)
I0522 04:06:14.362844 12754 net.cpp:150] Setting up relu2
I0522 04:06:14.362859 12754 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0522 04:06:14.362869 12754 net.cpp:165] Memory required for data: 22281040
I0522 04:06:14.362879 12754 layer_factory.hpp:77] Creating layer pool2
I0522 04:06:14.362892 12754 net.cpp:106] Creating Layer pool2
I0522 04:06:14.362902 12754 net.cpp:454] pool2 <- conv2
I0522 04:06:14.362915 12754 net.cpp:411] pool2 -> pool2
I0522 04:06:14.362987 12754 net.cpp:150] Setting up pool2
I0522 04:06:14.363000 12754 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0522 04:06:14.363010 12754 net.cpp:165] Memory required for data: 24268240
I0522 04:06:14.363020 12754 layer_factory.hpp:77] Creating layer conv3
I0522 04:06:14.363039 12754 net.cpp:106] Creating Layer conv3
I0522 04:06:14.363049 12754 net.cpp:454] conv3 <- pool2
I0522 04:06:14.363062 12754 net.cpp:411] conv3 -> conv3
I0522 04:06:14.365034 12754 net.cpp:150] Setting up conv3
I0522 04:06:14.365056 12754 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 04:06:14.365069 12754 net.cpp:165] Memory required for data: 26436560
I0522 04:06:14.365088 12754 layer_factory.hpp:77] Creating layer relu3
I0522 04:06:14.365114 12754 net.cpp:106] Creating Layer relu3
I0522 04:06:14.365124 12754 net.cpp:454] relu3 <- conv3
I0522 04:06:14.365139 12754 net.cpp:397] relu3 -> conv3 (in-place)
I0522 04:06:14.365612 12754 net.cpp:150] Setting up relu3
I0522 04:06:14.365628 12754 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0522 04:06:14.365638 12754 net.cpp:165] Memory required for data: 28604880
I0522 04:06:14.365648 12754 layer_factory.hpp:77] Creating layer pool3
I0522 04:06:14.365661 12754 net.cpp:106] Creating Layer pool3
I0522 04:06:14.365671 12754 net.cpp:454] pool3 <- conv3
I0522 04:06:14.365684 12754 net.cpp:411] pool3 -> pool3
I0522 04:06:14.365756 12754 net.cpp:150] Setting up pool3
I0522 04:06:14.365769 12754 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0522 04:06:14.365779 12754 net.cpp:165] Memory required for data: 29689040
I0522 04:06:14.365789 12754 layer_factory.hpp:77] Creating layer conv4
I0522 04:06:14.365806 12754 net.cpp:106] Creating Layer conv4
I0522 04:06:14.365818 12754 net.cpp:454] conv4 <- pool3
I0522 04:06:14.365831 12754 net.cpp:411] conv4 -> conv4
I0522 04:06:14.367887 12754 net.cpp:150] Setting up conv4
I0522 04:06:14.367910 12754 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 04:06:14.367923 12754 net.cpp:165] Memory required for data: 30414800
I0522 04:06:14.367938 12754 layer_factory.hpp:77] Creating layer relu4
I0522 04:06:14.367952 12754 net.cpp:106] Creating Layer relu4
I0522 04:06:14.367962 12754 net.cpp:454] relu4 <- conv4
I0522 04:06:14.367975 12754 net.cpp:397] relu4 -> conv4 (in-place)
I0522 04:06:14.368446 12754 net.cpp:150] Setting up relu4
I0522 04:06:14.368463 12754 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0522 04:06:14.368472 12754 net.cpp:165] Memory required for data: 31140560
I0522 04:06:14.368482 12754 layer_factory.hpp:77] Creating layer pool4
I0522 04:06:14.368495 12754 net.cpp:106] Creating Layer pool4
I0522 04:06:14.368505 12754 net.cpp:454] pool4 <- conv4
I0522 04:06:14.368518 12754 net.cpp:411] pool4 -> pool4
I0522 04:06:14.368590 12754 net.cpp:150] Setting up pool4
I0522 04:06:14.368603 12754 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0522 04:06:14.368613 12754 net.cpp:165] Memory required for data: 31503440
I0522 04:06:14.368623 12754 layer_factory.hpp:77] Creating layer ip1
I0522 04:06:14.368636 12754 net.cpp:106] Creating Layer ip1
I0522 04:06:14.368648 12754 net.cpp:454] ip1 <- pool4
I0522 04:06:14.368660 12754 net.cpp:411] ip1 -> ip1
I0522 04:06:14.384151 12754 net.cpp:150] Setting up ip1
I0522 04:06:14.384181 12754 net.cpp:157] Top shape: 20 196 (3920)
I0522 04:06:14.384191 12754 net.cpp:165] Memory required for data: 31519120
I0522 04:06:14.384213 12754 layer_factory.hpp:77] Creating layer relu5
I0522 04:06:14.384228 12754 net.cpp:106] Creating Layer relu5
I0522 04:06:14.384238 12754 net.cpp:454] relu5 <- ip1
I0522 04:06:14.384253 12754 net.cpp:397] relu5 -> ip1 (in-place)
I0522 04:06:14.384598 12754 net.cpp:150] Setting up relu5
I0522 04:06:14.384613 12754 net.cpp:157] Top shape: 20 196 (3920)
I0522 04:06:14.384623 12754 net.cpp:165] Memory required for data: 31534800
I0522 04:06:14.384632 12754 layer_factory.hpp:77] Creating layer drop1
I0522 04:06:14.384650 12754 net.cpp:106] Creating Layer drop1
I0522 04:06:14.384660 12754 net.cpp:454] drop1 <- ip1
I0522 04:06:14.384673 12754 net.cpp:397] drop1 -> ip1 (in-place)
I0522 04:06:14.384719 12754 net.cpp:150] Setting up drop1
I0522 04:06:14.384732 12754 net.cpp:157] Top shape: 20 196 (3920)
I0522 04:06:14.384743 12754 net.cpp:165] Memory required for data: 31550480
I0522 04:06:14.384752 12754 layer_factory.hpp:77] Creating layer ip2
I0522 04:06:14.384768 12754 net.cpp:106] Creating Layer ip2
I0522 04:06:14.384778 12754 net.cpp:454] ip2 <- ip1
I0522 04:06:14.384791 12754 net.cpp:411] ip2 -> ip2
I0522 04:06:14.385277 12754 net.cpp:150] Setting up ip2
I0522 04:06:14.385289 12754 net.cpp:157] Top shape: 20 98 (1960)
I0522 04:06:14.385299 12754 net.cpp:165] Memory required for data: 31558320
I0522 04:06:14.385314 12754 layer_factory.hpp:77] Creating layer relu6
I0522 04:06:14.385340 12754 net.cpp:106] Creating Layer relu6
I0522 04:06:14.385350 12754 net.cpp:454] relu6 <- ip2
I0522 04:06:14.385363 12754 net.cpp:397] relu6 -> ip2 (in-place)
I0522 04:06:14.385896 12754 net.cpp:150] Setting up relu6
I0522 04:06:14.385912 12754 net.cpp:157] Top shape: 20 98 (1960)
I0522 04:06:14.385922 12754 net.cpp:165] Memory required for data: 31566160
I0522 04:06:14.385932 12754 layer_factory.hpp:77] Creating layer drop2
I0522 04:06:14.385946 12754 net.cpp:106] Creating Layer drop2
I0522 04:06:14.385957 12754 net.cpp:454] drop2 <- ip2
I0522 04:06:14.385970 12754 net.cpp:397] drop2 -> ip2 (in-place)
I0522 04:06:14.386014 12754 net.cpp:150] Setting up drop2
I0522 04:06:14.386028 12754 net.cpp:157] Top shape: 20 98 (1960)
I0522 04:06:14.386036 12754 net.cpp:165] Memory required for data: 31574000
I0522 04:06:14.386046 12754 layer_factory.hpp:77] Creating layer ip3
I0522 04:06:14.386060 12754 net.cpp:106] Creating Layer ip3
I0522 04:06:14.386070 12754 net.cpp:454] ip3 <- ip2
I0522 04:06:14.386085 12754 net.cpp:411] ip3 -> ip3
I0522 04:06:14.386307 12754 net.cpp:150] Setting up ip3
I0522 04:06:14.386319 12754 net.cpp:157] Top shape: 20 11 (220)
I0522 04:06:14.386330 12754 net.cpp:165] Memory required for data: 31574880
I0522 04:06:14.386345 12754 layer_factory.hpp:77] Creating layer drop3
I0522 04:06:14.386358 12754 net.cpp:106] Creating Layer drop3
I0522 04:06:14.386368 12754 net.cpp:454] drop3 <- ip3
I0522 04:06:14.386381 12754 net.cpp:397] drop3 -> ip3 (in-place)
I0522 04:06:14.386422 12754 net.cpp:150] Setting up drop3
I0522 04:06:14.386435 12754 net.cpp:157] Top shape: 20 11 (220)
I0522 04:06:14.386445 12754 net.cpp:165] Memory required for data: 31575760
I0522 04:06:14.386456 12754 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 04:06:14.386468 12754 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 04:06:14.386478 12754 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 04:06:14.386492 12754 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 04:06:14.386507 12754 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 04:06:14.386581 12754 net.cpp:150] Setting up ip3_drop3_0_split
I0522 04:06:14.386595 12754 net.cpp:157] Top shape: 20 11 (220)
I0522 04:06:14.386606 12754 net.cpp:157] Top shape: 20 11 (220)
I0522 04:06:14.386616 12754 net.cpp:165] Memory required for data: 31577520
I0522 04:06:14.386626 12754 layer_factory.hpp:77] Creating layer accuracy
I0522 04:06:14.386647 12754 net.cpp:106] Creating Layer accuracy
I0522 04:06:14.386657 12754 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 04:06:14.386668 12754 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 04:06:14.386682 12754 net.cpp:411] accuracy -> accuracy
I0522 04:06:14.386705 12754 net.cpp:150] Setting up accuracy
I0522 04:06:14.386718 12754 net.cpp:157] Top shape: (1)
I0522 04:06:14.386728 12754 net.cpp:165] Memory required for data: 31577524
I0522 04:06:14.386737 12754 layer_factory.hpp:77] Creating layer loss
I0522 04:06:14.386752 12754 net.cpp:106] Creating Layer loss
I0522 04:06:14.386762 12754 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 04:06:14.386773 12754 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 04:06:14.386787 12754 net.cpp:411] loss -> loss
I0522 04:06:14.386804 12754 layer_factory.hpp:77] Creating layer loss
I0522 04:06:14.387284 12754 net.cpp:150] Setting up loss
I0522 04:06:14.387298 12754 net.cpp:157] Top shape: (1)
I0522 04:06:14.387308 12754 net.cpp:160]     with loss weight 1
I0522 04:06:14.387326 12754 net.cpp:165] Memory required for data: 31577528
I0522 04:06:14.387336 12754 net.cpp:226] loss needs backward computation.
I0522 04:06:14.387348 12754 net.cpp:228] accuracy does not need backward computation.
I0522 04:06:14.387359 12754 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 04:06:14.387369 12754 net.cpp:226] drop3 needs backward computation.
I0522 04:06:14.387377 12754 net.cpp:226] ip3 needs backward computation.
I0522 04:06:14.387388 12754 net.cpp:226] drop2 needs backward computation.
I0522 04:06:14.387398 12754 net.cpp:226] relu6 needs backward computation.
I0522 04:06:14.387415 12754 net.cpp:226] ip2 needs backward computation.
I0522 04:06:14.387425 12754 net.cpp:226] drop1 needs backward computation.
I0522 04:06:14.387435 12754 net.cpp:226] relu5 needs backward computation.
I0522 04:06:14.387445 12754 net.cpp:226] ip1 needs backward computation.
I0522 04:06:14.387455 12754 net.cpp:226] pool4 needs backward computation.
I0522 04:06:14.387465 12754 net.cpp:226] relu4 needs backward computation.
I0522 04:06:14.387475 12754 net.cpp:226] conv4 needs backward computation.
I0522 04:06:14.387485 12754 net.cpp:226] pool3 needs backward computation.
I0522 04:06:14.387496 12754 net.cpp:226] relu3 needs backward computation.
I0522 04:06:14.387506 12754 net.cpp:226] conv3 needs backward computation.
I0522 04:06:14.387517 12754 net.cpp:226] pool2 needs backward computation.
I0522 04:06:14.387527 12754 net.cpp:226] relu2 needs backward computation.
I0522 04:06:14.387537 12754 net.cpp:226] conv2 needs backward computation.
I0522 04:06:14.387547 12754 net.cpp:226] pool1 needs backward computation.
I0522 04:06:14.387558 12754 net.cpp:226] relu1 needs backward computation.
I0522 04:06:14.387568 12754 net.cpp:226] conv1 needs backward computation.
I0522 04:06:14.387579 12754 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 04:06:14.387591 12754 net.cpp:228] data_hdf5 does not need backward computation.
I0522 04:06:14.387601 12754 net.cpp:270] This network produces output accuracy
I0522 04:06:14.387612 12754 net.cpp:270] This network produces output loss
I0522 04:06:14.387641 12754 net.cpp:283] Network initialization done.
I0522 04:06:14.387773 12754 solver.cpp:60] Solver scaffolding done.
I0522 04:06:14.388902 12754 caffe.cpp:212] Starting Optimization
I0522 04:06:14.388937 12754 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 04:06:14.388947 12754 solver.cpp:289] Learning Rate Policy: fixed
I0522 04:06:14.390171 12754 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 04:07:07.187501 12754 solver.cpp:409]     Test net output #0: accuracy = 0.0589059
I0522 04:07:07.187660 12754 solver.cpp:409]     Test net output #1: loss = 2.39958 (* 1 = 2.39958 loss)
I0522 04:07:07.206742 12754 solver.cpp:237] Iteration 0, loss = 2.40289
I0522 04:07:07.206778 12754 solver.cpp:253]     Train net output #0: loss = 2.40289 (* 1 = 2.40289 loss)
I0522 04:07:07.206796 12754 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0522 04:07:19.351744 12754 solver.cpp:237] Iteration 750, loss = 1.86592
I0522 04:07:19.351793 12754 solver.cpp:253]     Train net output #0: loss = 1.86592 (* 1 = 1.86592 loss)
I0522 04:07:19.351809 12754 sgd_solver.cpp:106] Iteration 750, lr = 0.0045
I0522 04:07:31.481858 12754 solver.cpp:237] Iteration 1500, loss = 1.93334
I0522 04:07:31.481895 12754 solver.cpp:253]     Train net output #0: loss = 1.93334 (* 1 = 1.93334 loss)
I0522 04:07:31.481911 12754 sgd_solver.cpp:106] Iteration 1500, lr = 0.0045
I0522 04:07:43.610350 12754 solver.cpp:237] Iteration 2250, loss = 1.86114
I0522 04:07:43.610517 12754 solver.cpp:253]     Train net output #0: loss = 1.86114 (* 1 = 1.86114 loss)
I0522 04:07:43.610532 12754 sgd_solver.cpp:106] Iteration 2250, lr = 0.0045
I0522 04:07:55.743438 12754 solver.cpp:237] Iteration 3000, loss = 1.24257
I0522 04:07:55.743476 12754 solver.cpp:253]     Train net output #0: loss = 1.24257 (* 1 = 1.24257 loss)
I0522 04:07:55.743492 12754 sgd_solver.cpp:106] Iteration 3000, lr = 0.0045
I0522 04:08:07.877724 12754 solver.cpp:237] Iteration 3750, loss = 1.26707
I0522 04:08:07.877774 12754 solver.cpp:253]     Train net output #0: loss = 1.26707 (* 1 = 1.26707 loss)
I0522 04:08:07.877787 12754 sgd_solver.cpp:106] Iteration 3750, lr = 0.0045
I0522 04:08:19.994515 12754 solver.cpp:237] Iteration 4500, loss = 1.3797
I0522 04:08:19.994659 12754 solver.cpp:253]     Train net output #0: loss = 1.3797 (* 1 = 1.3797 loss)
I0522 04:08:19.994674 12754 sgd_solver.cpp:106] Iteration 4500, lr = 0.0045
I0522 04:08:54.276541 12754 solver.cpp:237] Iteration 5250, loss = 1.97443
I0522 04:08:54.276705 12754 solver.cpp:253]     Train net output #0: loss = 1.97443 (* 1 = 1.97443 loss)
I0522 04:08:54.276720 12754 sgd_solver.cpp:106] Iteration 5250, lr = 0.0045
I0522 04:09:06.435953 12754 solver.cpp:237] Iteration 6000, loss = 1.22839
I0522 04:09:06.435991 12754 solver.cpp:253]     Train net output #0: loss = 1.22839 (* 1 = 1.22839 loss)
I0522 04:09:06.436007 12754 sgd_solver.cpp:106] Iteration 6000, lr = 0.0045
I0522 04:09:18.630323 12754 solver.cpp:237] Iteration 6750, loss = 1.73785
I0522 04:09:18.630374 12754 solver.cpp:253]     Train net output #0: loss = 1.73785 (* 1 = 1.73785 loss)
I0522 04:09:18.630388 12754 sgd_solver.cpp:106] Iteration 6750, lr = 0.0045
I0522 04:09:30.793766 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_7500.caffemodel
I0522 04:09:30.846715 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_7500.solverstate
I0522 04:09:30.877331 12754 solver.cpp:237] Iteration 7500, loss = 1.40236
I0522 04:09:30.877374 12754 solver.cpp:253]     Train net output #0: loss = 1.40236 (* 1 = 1.40236 loss)
I0522 04:09:30.877391 12754 sgd_solver.cpp:106] Iteration 7500, lr = 0.0045
I0522 04:09:42.997117 12754 solver.cpp:237] Iteration 8250, loss = 1.64632
I0522 04:09:42.997170 12754 solver.cpp:253]     Train net output #0: loss = 1.64632 (* 1 = 1.64632 loss)
I0522 04:09:42.997184 12754 sgd_solver.cpp:106] Iteration 8250, lr = 0.0045
I0522 04:09:55.116761 12754 solver.cpp:237] Iteration 9000, loss = 1.04916
I0522 04:09:55.116797 12754 solver.cpp:253]     Train net output #0: loss = 1.04916 (* 1 = 1.04916 loss)
I0522 04:09:55.116814 12754 sgd_solver.cpp:106] Iteration 9000, lr = 0.0045
I0522 04:10:07.259378 12754 solver.cpp:237] Iteration 9750, loss = 0.814535
I0522 04:10:07.259531 12754 solver.cpp:253]     Train net output #0: loss = 0.814535 (* 1 = 0.814535 loss)
I0522 04:10:07.259546 12754 sgd_solver.cpp:106] Iteration 9750, lr = 0.0045
I0522 04:10:41.499810 12754 solver.cpp:237] Iteration 10500, loss = 1.18476
I0522 04:10:41.499974 12754 solver.cpp:253]     Train net output #0: loss = 1.18476 (* 1 = 1.18476 loss)
I0522 04:10:41.499989 12754 sgd_solver.cpp:106] Iteration 10500, lr = 0.0045
I0522 04:10:53.659000 12754 solver.cpp:237] Iteration 11250, loss = 1.05783
I0522 04:10:53.659037 12754 solver.cpp:253]     Train net output #0: loss = 1.05783 (* 1 = 1.05783 loss)
I0522 04:10:53.659052 12754 sgd_solver.cpp:106] Iteration 11250, lr = 0.0045
I0522 04:11:05.813671 12754 solver.cpp:237] Iteration 12000, loss = 1.73155
I0522 04:11:05.813716 12754 solver.cpp:253]     Train net output #0: loss = 1.73155 (* 1 = 1.73155 loss)
I0522 04:11:05.813732 12754 sgd_solver.cpp:106] Iteration 12000, lr = 0.0045
I0522 04:11:17.947818 12754 solver.cpp:237] Iteration 12750, loss = 1.47418
I0522 04:11:17.947969 12754 solver.cpp:253]     Train net output #0: loss = 1.47418 (* 1 = 1.47418 loss)
I0522 04:11:17.947985 12754 sgd_solver.cpp:106] Iteration 12750, lr = 0.0045
I0522 04:11:30.080796 12754 solver.cpp:237] Iteration 13500, loss = 1.37367
I0522 04:11:30.080840 12754 solver.cpp:253]     Train net output #0: loss = 1.37367 (* 1 = 1.37367 loss)
I0522 04:11:30.080855 12754 sgd_solver.cpp:106] Iteration 13500, lr = 0.0045
I0522 04:11:42.225276 12754 solver.cpp:237] Iteration 14250, loss = 1.37249
I0522 04:11:42.225312 12754 solver.cpp:253]     Train net output #0: loss = 1.37249 (* 1 = 1.37249 loss)
I0522 04:11:42.225328 12754 sgd_solver.cpp:106] Iteration 14250, lr = 0.0045
I0522 04:11:54.355101 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_15000.caffemodel
I0522 04:11:54.415457 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_15000.solverstate
I0522 04:11:54.441076 12754 solver.cpp:341] Iteration 15000, Testing net (#0)
I0522 04:12:46.290729 12754 solver.cpp:409]     Test net output #0: accuracy = 0.849732
I0522 04:12:46.290884 12754 solver.cpp:409]     Test net output #1: loss = 0.515635 (* 1 = 0.515635 loss)
I0522 04:13:08.375967 12754 solver.cpp:237] Iteration 15000, loss = 1.36777
I0522 04:13:08.376019 12754 solver.cpp:253]     Train net output #0: loss = 1.36777 (* 1 = 1.36777 loss)
I0522 04:13:08.376034 12754 sgd_solver.cpp:106] Iteration 15000, lr = 0.0045
I0522 04:13:20.515238 12754 solver.cpp:237] Iteration 15750, loss = 1.25164
I0522 04:13:20.515388 12754 solver.cpp:253]     Train net output #0: loss = 1.25164 (* 1 = 1.25164 loss)
I0522 04:13:20.515401 12754 sgd_solver.cpp:106] Iteration 15750, lr = 0.0045
I0522 04:13:32.671206 12754 solver.cpp:237] Iteration 16500, loss = 1.22598
I0522 04:13:32.671252 12754 solver.cpp:253]     Train net output #0: loss = 1.22598 (* 1 = 1.22598 loss)
I0522 04:13:32.671268 12754 sgd_solver.cpp:106] Iteration 16500, lr = 0.0045
I0522 04:13:44.850412 12754 solver.cpp:237] Iteration 17250, loss = 1.0218
I0522 04:13:44.850448 12754 solver.cpp:253]     Train net output #0: loss = 1.0218 (* 1 = 1.0218 loss)
I0522 04:13:44.850466 12754 sgd_solver.cpp:106] Iteration 17250, lr = 0.0045
I0522 04:13:56.992523 12754 solver.cpp:237] Iteration 18000, loss = 1.01252
I0522 04:13:56.992678 12754 solver.cpp:253]     Train net output #0: loss = 1.01252 (* 1 = 1.01252 loss)
I0522 04:13:56.992692 12754 sgd_solver.cpp:106] Iteration 18000, lr = 0.0045
I0522 04:14:09.060071 12754 solver.cpp:237] Iteration 18750, loss = 1.63222
I0522 04:14:09.060108 12754 solver.cpp:253]     Train net output #0: loss = 1.63222 (* 1 = 1.63222 loss)
I0522 04:14:09.060124 12754 sgd_solver.cpp:106] Iteration 18750, lr = 0.0045
I0522 04:14:21.135781 12754 solver.cpp:237] Iteration 19500, loss = 1.20885
I0522 04:14:21.135824 12754 solver.cpp:253]     Train net output #0: loss = 1.20885 (* 1 = 1.20885 loss)
I0522 04:14:21.135840 12754 sgd_solver.cpp:106] Iteration 19500, lr = 0.0045
I0522 04:14:55.297336 12754 solver.cpp:237] Iteration 20250, loss = 1.20989
I0522 04:14:55.297502 12754 solver.cpp:253]     Train net output #0: loss = 1.20989 (* 1 = 1.20989 loss)
I0522 04:14:55.297515 12754 sgd_solver.cpp:106] Iteration 20250, lr = 0.0045
I0522 04:15:07.390136 12754 solver.cpp:237] Iteration 21000, loss = 1.1045
I0522 04:15:07.390183 12754 solver.cpp:253]     Train net output #0: loss = 1.1045 (* 1 = 1.1045 loss)
I0522 04:15:07.390198 12754 sgd_solver.cpp:106] Iteration 21000, lr = 0.0045
I0522 04:15:19.477399 12754 solver.cpp:237] Iteration 21750, loss = 0.810439
I0522 04:15:19.477437 12754 solver.cpp:253]     Train net output #0: loss = 0.810439 (* 1 = 0.810439 loss)
I0522 04:15:19.477450 12754 sgd_solver.cpp:106] Iteration 21750, lr = 0.0045
I0522 04:15:31.564287 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_22500.caffemodel
I0522 04:15:31.615439 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_22500.solverstate
I0522 04:15:31.649297 12754 solver.cpp:237] Iteration 22500, loss = 1.01169
I0522 04:15:31.649343 12754 solver.cpp:253]     Train net output #0: loss = 1.01169 (* 1 = 1.01169 loss)
I0522 04:15:31.649364 12754 sgd_solver.cpp:106] Iteration 22500, lr = 0.0045
I0522 04:15:43.746026 12754 solver.cpp:237] Iteration 23250, loss = 1.66488
I0522 04:15:43.746062 12754 solver.cpp:253]     Train net output #0: loss = 1.66488 (* 1 = 1.66488 loss)
I0522 04:15:43.746078 12754 sgd_solver.cpp:106] Iteration 23250, lr = 0.0045
I0522 04:15:55.900631 12754 solver.cpp:237] Iteration 24000, loss = 0.888178
I0522 04:15:55.900671 12754 solver.cpp:253]     Train net output #0: loss = 0.888178 (* 1 = 0.888178 loss)
I0522 04:15:55.900689 12754 sgd_solver.cpp:106] Iteration 24000, lr = 0.0045
I0522 04:16:08.061594 12754 solver.cpp:237] Iteration 24750, loss = 1.55065
I0522 04:16:08.061749 12754 solver.cpp:253]     Train net output #0: loss = 1.55065 (* 1 = 1.55065 loss)
I0522 04:16:08.061764 12754 sgd_solver.cpp:106] Iteration 24750, lr = 0.0045
I0522 04:16:42.337072 12754 solver.cpp:237] Iteration 25500, loss = 1.19817
I0522 04:16:42.337236 12754 solver.cpp:253]     Train net output #0: loss = 1.19817 (* 1 = 1.19817 loss)
I0522 04:16:42.337250 12754 sgd_solver.cpp:106] Iteration 25500, lr = 0.0045
I0522 04:16:54.460959 12754 solver.cpp:237] Iteration 26250, loss = 1.33864
I0522 04:16:54.461009 12754 solver.cpp:253]     Train net output #0: loss = 1.33864 (* 1 = 1.33864 loss)
I0522 04:16:54.461024 12754 sgd_solver.cpp:106] Iteration 26250, lr = 0.0045
I0522 04:17:06.621862 12754 solver.cpp:237] Iteration 27000, loss = 1.52988
I0522 04:17:06.621899 12754 solver.cpp:253]     Train net output #0: loss = 1.52988 (* 1 = 1.52988 loss)
I0522 04:17:06.621915 12754 sgd_solver.cpp:106] Iteration 27000, lr = 0.0045
I0522 04:17:18.740286 12754 solver.cpp:237] Iteration 27750, loss = 1.63921
I0522 04:17:18.740439 12754 solver.cpp:253]     Train net output #0: loss = 1.63921 (* 1 = 1.63921 loss)
I0522 04:17:18.740455 12754 sgd_solver.cpp:106] Iteration 27750, lr = 0.0045
I0522 04:17:30.879098 12754 solver.cpp:237] Iteration 28500, loss = 1.51791
I0522 04:17:30.879135 12754 solver.cpp:253]     Train net output #0: loss = 1.51791 (* 1 = 1.51791 loss)
I0522 04:17:30.879153 12754 sgd_solver.cpp:106] Iteration 28500, lr = 0.0045
I0522 04:17:43.020474 12754 solver.cpp:237] Iteration 29250, loss = 0.938962
I0522 04:17:43.020524 12754 solver.cpp:253]     Train net output #0: loss = 0.938962 (* 1 = 0.938962 loss)
I0522 04:17:43.020539 12754 sgd_solver.cpp:106] Iteration 29250, lr = 0.0045
I0522 04:17:55.150492 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_30000.caffemodel
I0522 04:17:55.202419 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_30000.solverstate
I0522 04:17:55.230911 12754 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 04:19:08.065912 12754 solver.cpp:409]     Test net output #0: accuracy = 0.862168
I0522 04:19:08.066082 12754 solver.cpp:409]     Test net output #1: loss = 0.465742 (* 1 = 0.465742 loss)
I0522 04:19:30.145532 12754 solver.cpp:237] Iteration 30000, loss = 0.862601
I0522 04:19:30.145586 12754 solver.cpp:253]     Train net output #0: loss = 0.862601 (* 1 = 0.862601 loss)
I0522 04:19:30.145602 12754 sgd_solver.cpp:106] Iteration 30000, lr = 0.0045
I0522 04:19:42.255184 12754 solver.cpp:237] Iteration 30750, loss = 1.04124
I0522 04:19:42.255348 12754 solver.cpp:253]     Train net output #0: loss = 1.04124 (* 1 = 1.04124 loss)
I0522 04:19:42.255363 12754 sgd_solver.cpp:106] Iteration 30750, lr = 0.0045
I0522 04:19:54.446835 12754 solver.cpp:237] Iteration 31500, loss = 0.964863
I0522 04:19:54.446871 12754 solver.cpp:253]     Train net output #0: loss = 0.964863 (* 1 = 0.964863 loss)
I0522 04:19:54.446887 12754 sgd_solver.cpp:106] Iteration 31500, lr = 0.0045
I0522 04:20:06.622669 12754 solver.cpp:237] Iteration 32250, loss = 1.13269
I0522 04:20:06.622714 12754 solver.cpp:253]     Train net output #0: loss = 1.13269 (* 1 = 1.13269 loss)
I0522 04:20:06.622730 12754 sgd_solver.cpp:106] Iteration 32250, lr = 0.0045
I0522 04:20:18.738590 12754 solver.cpp:237] Iteration 33000, loss = 1.13628
I0522 04:20:18.738730 12754 solver.cpp:253]     Train net output #0: loss = 1.13628 (* 1 = 1.13628 loss)
I0522 04:20:18.738744 12754 sgd_solver.cpp:106] Iteration 33000, lr = 0.0045
I0522 04:20:30.862067 12754 solver.cpp:237] Iteration 33750, loss = 1.08886
I0522 04:20:30.862110 12754 solver.cpp:253]     Train net output #0: loss = 1.08886 (* 1 = 1.08886 loss)
I0522 04:20:30.862129 12754 sgd_solver.cpp:106] Iteration 33750, lr = 0.0045
I0522 04:20:42.960244 12754 solver.cpp:237] Iteration 34500, loss = 1.72227
I0522 04:20:42.960280 12754 solver.cpp:253]     Train net output #0: loss = 1.72227 (* 1 = 1.72227 loss)
I0522 04:20:42.960297 12754 sgd_solver.cpp:106] Iteration 34500, lr = 0.0045
I0522 04:21:17.226369 12754 solver.cpp:237] Iteration 35250, loss = 0.959351
I0522 04:21:17.226538 12754 solver.cpp:253]     Train net output #0: loss = 0.95935 (* 1 = 0.95935 loss)
I0522 04:21:17.226553 12754 sgd_solver.cpp:106] Iteration 35250, lr = 0.0045
I0522 04:21:29.347707 12754 solver.cpp:237] Iteration 36000, loss = 1.22168
I0522 04:21:29.347754 12754 solver.cpp:253]     Train net output #0: loss = 1.22168 (* 1 = 1.22168 loss)
I0522 04:21:29.347770 12754 sgd_solver.cpp:106] Iteration 36000, lr = 0.0045
I0522 04:21:41.460832 12754 solver.cpp:237] Iteration 36750, loss = 1.47966
I0522 04:21:41.460868 12754 solver.cpp:253]     Train net output #0: loss = 1.47966 (* 1 = 1.47966 loss)
I0522 04:21:41.460885 12754 sgd_solver.cpp:106] Iteration 36750, lr = 0.0045
I0522 04:21:53.650585 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_37500.caffemodel
I0522 04:21:53.701809 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_37500.solverstate
I0522 04:21:53.735770 12754 solver.cpp:237] Iteration 37500, loss = 1.16486
I0522 04:21:53.735816 12754 solver.cpp:253]     Train net output #0: loss = 1.16486 (* 1 = 1.16486 loss)
I0522 04:21:53.735833 12754 sgd_solver.cpp:106] Iteration 37500, lr = 0.0045
I0522 04:22:05.942595 12754 solver.cpp:237] Iteration 38250, loss = 1.17553
I0522 04:22:05.942631 12754 solver.cpp:253]     Train net output #0: loss = 1.17553 (* 1 = 1.17553 loss)
I0522 04:22:05.942646 12754 sgd_solver.cpp:106] Iteration 38250, lr = 0.0045
I0522 04:22:18.146414 12754 solver.cpp:237] Iteration 39000, loss = 1.22041
I0522 04:22:18.146463 12754 solver.cpp:253]     Train net output #0: loss = 1.22041 (* 1 = 1.22041 loss)
I0522 04:22:18.146477 12754 sgd_solver.cpp:106] Iteration 39000, lr = 0.0045
I0522 04:22:30.352912 12754 solver.cpp:237] Iteration 39750, loss = 1.07414
I0522 04:22:30.353061 12754 solver.cpp:253]     Train net output #0: loss = 1.07414 (* 1 = 1.07414 loss)
I0522 04:22:30.353075 12754 sgd_solver.cpp:106] Iteration 39750, lr = 0.0045
I0522 04:23:04.667217 12754 solver.cpp:237] Iteration 40500, loss = 0.964457
I0522 04:23:04.667392 12754 solver.cpp:253]     Train net output #0: loss = 0.964456 (* 1 = 0.964456 loss)
I0522 04:23:04.667407 12754 sgd_solver.cpp:106] Iteration 40500, lr = 0.0045
I0522 04:23:16.877393 12754 solver.cpp:237] Iteration 41250, loss = 1.07197
I0522 04:23:16.877429 12754 solver.cpp:253]     Train net output #0: loss = 1.07197 (* 1 = 1.07197 loss)
I0522 04:23:16.877445 12754 sgd_solver.cpp:106] Iteration 41250, lr = 0.0045
I0522 04:23:29.106326 12754 solver.cpp:237] Iteration 42000, loss = 1.31942
I0522 04:23:29.106371 12754 solver.cpp:253]     Train net output #0: loss = 1.31942 (* 1 = 1.31942 loss)
I0522 04:23:29.106387 12754 sgd_solver.cpp:106] Iteration 42000, lr = 0.0045
I0522 04:23:41.294340 12754 solver.cpp:237] Iteration 42750, loss = 0.698336
I0522 04:23:41.294486 12754 solver.cpp:253]     Train net output #0: loss = 0.698334 (* 1 = 0.698334 loss)
I0522 04:23:41.294500 12754 sgd_solver.cpp:106] Iteration 42750, lr = 0.0045
I0522 04:23:53.465083 12754 solver.cpp:237] Iteration 43500, loss = 0.970516
I0522 04:23:53.465133 12754 solver.cpp:253]     Train net output #0: loss = 0.970515 (* 1 = 0.970515 loss)
I0522 04:23:53.465148 12754 sgd_solver.cpp:106] Iteration 43500, lr = 0.0045
I0522 04:24:05.630911 12754 solver.cpp:237] Iteration 44250, loss = 0.616113
I0522 04:24:05.630944 12754 solver.cpp:253]     Train net output #0: loss = 0.616113 (* 1 = 0.616113 loss)
I0522 04:24:05.630957 12754 sgd_solver.cpp:106] Iteration 44250, lr = 0.0045
I0522 04:24:17.785322 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_45000.caffemodel
I0522 04:24:17.836570 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_45000.solverstate
I0522 04:24:17.862748 12754 solver.cpp:341] Iteration 45000, Testing net (#0)
I0522 04:25:09.428233 12754 solver.cpp:409]     Test net output #0: accuracy = 0.870467
I0522 04:25:09.428395 12754 solver.cpp:409]     Test net output #1: loss = 0.420529 (* 1 = 0.420529 loss)
I0522 04:25:31.576481 12754 solver.cpp:237] Iteration 45000, loss = 0.871172
I0522 04:25:31.576535 12754 solver.cpp:253]     Train net output #0: loss = 0.871171 (* 1 = 0.871171 loss)
I0522 04:25:31.576552 12754 sgd_solver.cpp:106] Iteration 45000, lr = 0.0045
I0522 04:25:43.702633 12754 solver.cpp:237] Iteration 45750, loss = 1.20736
I0522 04:25:43.702787 12754 solver.cpp:253]     Train net output #0: loss = 1.20736 (* 1 = 1.20736 loss)
I0522 04:25:43.702801 12754 sgd_solver.cpp:106] Iteration 45750, lr = 0.0045
I0522 04:25:55.824754 12754 solver.cpp:237] Iteration 46500, loss = 1.68483
I0522 04:25:55.824800 12754 solver.cpp:253]     Train net output #0: loss = 1.68483 (* 1 = 1.68483 loss)
I0522 04:25:55.824818 12754 sgd_solver.cpp:106] Iteration 46500, lr = 0.0045
I0522 04:26:07.917269 12754 solver.cpp:237] Iteration 47250, loss = 1.34089
I0522 04:26:07.917300 12754 solver.cpp:253]     Train net output #0: loss = 1.34089 (* 1 = 1.34089 loss)
I0522 04:26:07.917315 12754 sgd_solver.cpp:106] Iteration 47250, lr = 0.0045
I0522 04:26:20.018643 12754 solver.cpp:237] Iteration 48000, loss = 1.21304
I0522 04:26:20.018776 12754 solver.cpp:253]     Train net output #0: loss = 1.21304 (* 1 = 1.21304 loss)
I0522 04:26:20.018791 12754 sgd_solver.cpp:106] Iteration 48000, lr = 0.0045
I0522 04:26:32.138197 12754 solver.cpp:237] Iteration 48750, loss = 1.21576
I0522 04:26:32.138232 12754 solver.cpp:253]     Train net output #0: loss = 1.21576 (* 1 = 1.21576 loss)
I0522 04:26:32.138250 12754 sgd_solver.cpp:106] Iteration 48750, lr = 0.0045
I0522 04:26:44.253820 12754 solver.cpp:237] Iteration 49500, loss = 1.22659
I0522 04:26:44.253857 12754 solver.cpp:253]     Train net output #0: loss = 1.22659 (* 1 = 1.22659 loss)
I0522 04:26:44.253873 12754 sgd_solver.cpp:106] Iteration 49500, lr = 0.0045
I0522 04:27:18.519168 12754 solver.cpp:237] Iteration 50250, loss = 1.23002
I0522 04:27:18.519345 12754 solver.cpp:253]     Train net output #0: loss = 1.23002 (* 1 = 1.23002 loss)
I0522 04:27:18.519359 12754 sgd_solver.cpp:106] Iteration 50250, lr = 0.0045
I0522 04:27:30.613965 12754 solver.cpp:237] Iteration 51000, loss = 1.02453
I0522 04:27:30.614001 12754 solver.cpp:253]     Train net output #0: loss = 1.02453 (* 1 = 1.02453 loss)
I0522 04:27:30.614017 12754 sgd_solver.cpp:106] Iteration 51000, lr = 0.0045
I0522 04:27:42.722275 12754 solver.cpp:237] Iteration 51750, loss = 1.19571
I0522 04:27:42.722321 12754 solver.cpp:253]     Train net output #0: loss = 1.19571 (* 1 = 1.19571 loss)
I0522 04:27:42.722337 12754 sgd_solver.cpp:106] Iteration 51750, lr = 0.0045
I0522 04:27:54.777506 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_52500.caffemodel
I0522 04:27:54.826280 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_52500.solverstate
I0522 04:27:54.857623 12754 solver.cpp:237] Iteration 52500, loss = 1.58542
I0522 04:27:54.857666 12754 solver.cpp:253]     Train net output #0: loss = 1.58542 (* 1 = 1.58542 loss)
I0522 04:27:54.857684 12754 sgd_solver.cpp:106] Iteration 52500, lr = 0.0045
I0522 04:28:07.010785 12754 solver.cpp:237] Iteration 53250, loss = 1.16573
I0522 04:28:07.010831 12754 solver.cpp:253]     Train net output #0: loss = 1.16573 (* 1 = 1.16573 loss)
I0522 04:28:07.010848 12754 sgd_solver.cpp:106] Iteration 53250, lr = 0.0045
I0522 04:28:19.184722 12754 solver.cpp:237] Iteration 54000, loss = 1.16386
I0522 04:28:19.184758 12754 solver.cpp:253]     Train net output #0: loss = 1.16386 (* 1 = 1.16386 loss)
I0522 04:28:19.184775 12754 sgd_solver.cpp:106] Iteration 54000, lr = 0.0045
I0522 04:28:31.343436 12754 solver.cpp:237] Iteration 54750, loss = 1.37835
I0522 04:28:31.343595 12754 solver.cpp:253]     Train net output #0: loss = 1.37835 (* 1 = 1.37835 loss)
I0522 04:28:31.343611 12754 sgd_solver.cpp:106] Iteration 54750, lr = 0.0045
I0522 04:29:05.630471 12754 solver.cpp:237] Iteration 55500, loss = 1.22567
I0522 04:29:05.630642 12754 solver.cpp:253]     Train net output #0: loss = 1.22567 (* 1 = 1.22567 loss)
I0522 04:29:05.630657 12754 sgd_solver.cpp:106] Iteration 55500, lr = 0.0045
I0522 04:29:17.784466 12754 solver.cpp:237] Iteration 56250, loss = 1.71041
I0522 04:29:17.784512 12754 solver.cpp:253]     Train net output #0: loss = 1.71041 (* 1 = 1.71041 loss)
I0522 04:29:17.784528 12754 sgd_solver.cpp:106] Iteration 56250, lr = 0.0045
I0522 04:29:29.927500 12754 solver.cpp:237] Iteration 57000, loss = 1.35995
I0522 04:29:29.927537 12754 solver.cpp:253]     Train net output #0: loss = 1.35995 (* 1 = 1.35995 loss)
I0522 04:29:29.927554 12754 sgd_solver.cpp:106] Iteration 57000, lr = 0.0045
I0522 04:29:42.047900 12754 solver.cpp:237] Iteration 57750, loss = 1.28366
I0522 04:29:42.048053 12754 solver.cpp:253]     Train net output #0: loss = 1.28366 (* 1 = 1.28366 loss)
I0522 04:29:42.048068 12754 sgd_solver.cpp:106] Iteration 57750, lr = 0.0045
I0522 04:29:54.182967 12754 solver.cpp:237] Iteration 58500, loss = 1.13998
I0522 04:29:54.183003 12754 solver.cpp:253]     Train net output #0: loss = 1.13998 (* 1 = 1.13998 loss)
I0522 04:29:54.183019 12754 sgd_solver.cpp:106] Iteration 58500, lr = 0.0045
I0522 04:30:06.315218 12754 solver.cpp:237] Iteration 59250, loss = 1.33171
I0522 04:30:06.315255 12754 solver.cpp:253]     Train net output #0: loss = 1.33171 (* 1 = 1.33171 loss)
I0522 04:30:06.315276 12754 sgd_solver.cpp:106] Iteration 59250, lr = 0.0045
I0522 04:30:18.459496 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_60000.caffemodel
I0522 04:30:18.508913 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_60000.solverstate
I0522 04:30:18.535343 12754 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 04:31:31.367157 12754 solver.cpp:409]     Test net output #0: accuracy = 0.880721
I0522 04:31:31.367331 12754 solver.cpp:409]     Test net output #1: loss = 0.379408 (* 1 = 0.379408 loss)
I0522 04:31:53.554487 12754 solver.cpp:237] Iteration 60000, loss = 1.19791
I0522 04:31:53.554540 12754 solver.cpp:253]     Train net output #0: loss = 1.1979 (* 1 = 1.1979 loss)
I0522 04:31:53.554558 12754 sgd_solver.cpp:106] Iteration 60000, lr = 0.0045
I0522 04:32:05.665019 12754 solver.cpp:237] Iteration 60750, loss = 1.38791
I0522 04:32:05.665174 12754 solver.cpp:253]     Train net output #0: loss = 1.38791 (* 1 = 1.38791 loss)
I0522 04:32:05.665189 12754 sgd_solver.cpp:106] Iteration 60750, lr = 0.0045
I0522 04:32:17.736307 12754 solver.cpp:237] Iteration 61500, loss = 0.821923
I0522 04:32:17.736361 12754 solver.cpp:253]     Train net output #0: loss = 0.821922 (* 1 = 0.821922 loss)
I0522 04:32:17.736376 12754 sgd_solver.cpp:106] Iteration 61500, lr = 0.0045
I0522 04:32:29.807904 12754 solver.cpp:237] Iteration 62250, loss = 0.912542
I0522 04:32:29.807941 12754 solver.cpp:253]     Train net output #0: loss = 0.912541 (* 1 = 0.912541 loss)
I0522 04:32:29.807957 12754 sgd_solver.cpp:106] Iteration 62250, lr = 0.0045
I0522 04:32:41.956110 12754 solver.cpp:237] Iteration 63000, loss = 0.955325
I0522 04:32:41.956270 12754 solver.cpp:253]     Train net output #0: loss = 0.955324 (* 1 = 0.955324 loss)
I0522 04:32:41.956285 12754 sgd_solver.cpp:106] Iteration 63000, lr = 0.0045
I0522 04:32:54.124644 12754 solver.cpp:237] Iteration 63750, loss = 0.949668
I0522 04:32:54.124682 12754 solver.cpp:253]     Train net output #0: loss = 0.949667 (* 1 = 0.949667 loss)
I0522 04:32:54.124698 12754 sgd_solver.cpp:106] Iteration 63750, lr = 0.0045
I0522 04:33:06.300504 12754 solver.cpp:237] Iteration 64500, loss = 1.05082
I0522 04:33:06.300554 12754 solver.cpp:253]     Train net output #0: loss = 1.05082 (* 1 = 1.05082 loss)
I0522 04:33:06.300568 12754 sgd_solver.cpp:106] Iteration 64500, lr = 0.0045
I0522 04:33:40.603654 12754 solver.cpp:237] Iteration 65250, loss = 1.34396
I0522 04:33:40.603824 12754 solver.cpp:253]     Train net output #0: loss = 1.34396 (* 1 = 1.34396 loss)
I0522 04:33:40.603840 12754 sgd_solver.cpp:106] Iteration 65250, lr = 0.0045
I0522 04:33:52.714889 12754 solver.cpp:237] Iteration 66000, loss = 1.19512
I0522 04:33:52.714934 12754 solver.cpp:253]     Train net output #0: loss = 1.19512 (* 1 = 1.19512 loss)
I0522 04:33:52.714951 12754 sgd_solver.cpp:106] Iteration 66000, lr = 0.0045
I0522 04:34:04.857287 12754 solver.cpp:237] Iteration 66750, loss = 0.839777
I0522 04:34:04.857326 12754 solver.cpp:253]     Train net output #0: loss = 0.839776 (* 1 = 0.839776 loss)
I0522 04:34:04.857341 12754 sgd_solver.cpp:106] Iteration 66750, lr = 0.0045
I0522 04:34:16.932368 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_67500.caffemodel
I0522 04:34:16.984283 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_67500.solverstate
I0522 04:34:17.018007 12754 solver.cpp:237] Iteration 67500, loss = 1.86839
I0522 04:34:17.018059 12754 solver.cpp:253]     Train net output #0: loss = 1.86839 (* 1 = 1.86839 loss)
I0522 04:34:17.018074 12754 sgd_solver.cpp:106] Iteration 67500, lr = 0.0045
I0522 04:34:29.104400 12754 solver.cpp:237] Iteration 68250, loss = 1.21064
I0522 04:34:29.104437 12754 solver.cpp:253]     Train net output #0: loss = 1.21064 (* 1 = 1.21064 loss)
I0522 04:34:29.104454 12754 sgd_solver.cpp:106] Iteration 68250, lr = 0.0045
I0522 04:34:41.229632 12754 solver.cpp:237] Iteration 69000, loss = 1.66645
I0522 04:34:41.229676 12754 solver.cpp:253]     Train net output #0: loss = 1.66645 (* 1 = 1.66645 loss)
I0522 04:34:41.229694 12754 sgd_solver.cpp:106] Iteration 69000, lr = 0.0045
I0522 04:34:53.363734 12754 solver.cpp:237] Iteration 69750, loss = 1.32829
I0522 04:34:53.363898 12754 solver.cpp:253]     Train net output #0: loss = 1.32829 (* 1 = 1.32829 loss)
I0522 04:34:53.363911 12754 sgd_solver.cpp:106] Iteration 69750, lr = 0.0045
I0522 04:35:27.694516 12754 solver.cpp:237] Iteration 70500, loss = 1.43246
I0522 04:35:27.694690 12754 solver.cpp:253]     Train net output #0: loss = 1.43246 (* 1 = 1.43246 loss)
I0522 04:35:27.694705 12754 sgd_solver.cpp:106] Iteration 70500, lr = 0.0045
I0522 04:35:39.843102 12754 solver.cpp:237] Iteration 71250, loss = 1.44014
I0522 04:35:39.843147 12754 solver.cpp:253]     Train net output #0: loss = 1.44014 (* 1 = 1.44014 loss)
I0522 04:35:39.843164 12754 sgd_solver.cpp:106] Iteration 71250, lr = 0.0045
I0522 04:35:51.958578 12754 solver.cpp:237] Iteration 72000, loss = 1.016
I0522 04:35:51.958616 12754 solver.cpp:253]     Train net output #0: loss = 1.016 (* 1 = 1.016 loss)
I0522 04:35:51.958632 12754 sgd_solver.cpp:106] Iteration 72000, lr = 0.0045
I0522 04:36:04.115962 12754 solver.cpp:237] Iteration 72750, loss = 1.02974
I0522 04:36:04.116117 12754 solver.cpp:253]     Train net output #0: loss = 1.02974 (* 1 = 1.02974 loss)
I0522 04:36:04.116132 12754 sgd_solver.cpp:106] Iteration 72750, lr = 0.0045
I0522 04:36:16.310598 12754 solver.cpp:237] Iteration 73500, loss = 1.68028
I0522 04:36:16.310633 12754 solver.cpp:253]     Train net output #0: loss = 1.68028 (* 1 = 1.68028 loss)
I0522 04:36:16.310649 12754 sgd_solver.cpp:106] Iteration 73500, lr = 0.0045
I0522 04:36:28.483199 12754 solver.cpp:237] Iteration 74250, loss = 1.12602
I0522 04:36:28.483249 12754 solver.cpp:253]     Train net output #0: loss = 1.12602 (* 1 = 1.12602 loss)
I0522 04:36:28.483263 12754 sgd_solver.cpp:106] Iteration 74250, lr = 0.0045
I0522 04:36:40.631384 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_75000.caffemodel
I0522 04:36:40.685443 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_75000.solverstate
I0522 04:36:40.714169 12754 solver.cpp:341] Iteration 75000, Testing net (#0)
I0522 04:37:32.586640 12754 solver.cpp:409]     Test net output #0: accuracy = 0.87962
I0522 04:37:32.586807 12754 solver.cpp:409]     Test net output #1: loss = 0.374815 (* 1 = 0.374815 loss)
I0522 04:37:53.441117 12754 solver.cpp:237] Iteration 75000, loss = 1.55372
I0522 04:37:53.441169 12754 solver.cpp:253]     Train net output #0: loss = 1.55371 (* 1 = 1.55371 loss)
I0522 04:37:53.441184 12754 sgd_solver.cpp:106] Iteration 75000, lr = 0.0045
I0522 04:38:05.561094 12754 solver.cpp:237] Iteration 75750, loss = 1.03899
I0522 04:38:05.561259 12754 solver.cpp:253]     Train net output #0: loss = 1.03899 (* 1 = 1.03899 loss)
I0522 04:38:05.561275 12754 sgd_solver.cpp:106] Iteration 75750, lr = 0.0045
I0522 04:38:17.664909 12754 solver.cpp:237] Iteration 76500, loss = 1.29509
I0522 04:38:17.664950 12754 solver.cpp:253]     Train net output #0: loss = 1.29509 (* 1 = 1.29509 loss)
I0522 04:38:17.664966 12754 sgd_solver.cpp:106] Iteration 76500, lr = 0.0045
I0522 04:38:29.854789 12754 solver.cpp:237] Iteration 77250, loss = 1.62769
I0522 04:38:29.854835 12754 solver.cpp:253]     Train net output #0: loss = 1.62769 (* 1 = 1.62769 loss)
I0522 04:38:29.854848 12754 sgd_solver.cpp:106] Iteration 77250, lr = 0.0045
I0522 04:38:42.051059 12754 solver.cpp:237] Iteration 78000, loss = 1.38195
I0522 04:38:42.051203 12754 solver.cpp:253]     Train net output #0: loss = 1.38195 (* 1 = 1.38195 loss)
I0522 04:38:42.051218 12754 sgd_solver.cpp:106] Iteration 78000, lr = 0.0045
I0522 04:38:54.263736 12754 solver.cpp:237] Iteration 78750, loss = 1.21985
I0522 04:38:54.263777 12754 solver.cpp:253]     Train net output #0: loss = 1.21985 (* 1 = 1.21985 loss)
I0522 04:38:54.263793 12754 sgd_solver.cpp:106] Iteration 78750, lr = 0.0045
I0522 04:39:06.498700 12754 solver.cpp:237] Iteration 79500, loss = 1.343
I0522 04:39:06.498736 12754 solver.cpp:253]     Train net output #0: loss = 1.343 (* 1 = 1.343 loss)
I0522 04:39:06.498752 12754 sgd_solver.cpp:106] Iteration 79500, lr = 0.0045
I0522 04:39:39.588222 12754 solver.cpp:237] Iteration 80250, loss = 1.71362
I0522 04:39:39.588400 12754 solver.cpp:253]     Train net output #0: loss = 1.71362 (* 1 = 1.71362 loss)
I0522 04:39:39.588415 12754 sgd_solver.cpp:106] Iteration 80250, lr = 0.0045
I0522 04:39:51.767633 12754 solver.cpp:237] Iteration 81000, loss = 1.49401
I0522 04:39:51.767676 12754 solver.cpp:253]     Train net output #0: loss = 1.49401 (* 1 = 1.49401 loss)
I0522 04:39:51.767693 12754 sgd_solver.cpp:106] Iteration 81000, lr = 0.0045
I0522 04:40:03.910683 12754 solver.cpp:237] Iteration 81750, loss = 1.41645
I0522 04:40:03.910719 12754 solver.cpp:253]     Train net output #0: loss = 1.41645 (* 1 = 1.41645 loss)
I0522 04:40:03.910735 12754 sgd_solver.cpp:106] Iteration 81750, lr = 0.0045
I0522 04:40:16.040536 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_82500.caffemodel
I0522 04:40:16.089737 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_82500.solverstate
I0522 04:40:16.121040 12754 solver.cpp:237] Iteration 82500, loss = 1.3128
I0522 04:40:16.121086 12754 solver.cpp:253]     Train net output #0: loss = 1.31279 (* 1 = 1.31279 loss)
I0522 04:40:16.121100 12754 sgd_solver.cpp:106] Iteration 82500, lr = 0.0045
I0522 04:40:28.275969 12754 solver.cpp:237] Iteration 83250, loss = 1.17693
I0522 04:40:28.276005 12754 solver.cpp:253]     Train net output #0: loss = 1.17693 (* 1 = 1.17693 loss)
I0522 04:40:28.276021 12754 sgd_solver.cpp:106] Iteration 83250, lr = 0.0045
I0522 04:40:40.430929 12754 solver.cpp:237] Iteration 84000, loss = 0.80361
I0522 04:40:40.430976 12754 solver.cpp:253]     Train net output #0: loss = 0.803609 (* 1 = 0.803609 loss)
I0522 04:40:40.430992 12754 sgd_solver.cpp:106] Iteration 84000, lr = 0.0045
I0522 04:40:52.572856 12754 solver.cpp:237] Iteration 84750, loss = 1.4065
I0522 04:40:52.573016 12754 solver.cpp:253]     Train net output #0: loss = 1.4065 (* 1 = 1.4065 loss)
I0522 04:40:52.573030 12754 sgd_solver.cpp:106] Iteration 84750, lr = 0.0045
I0522 04:41:25.601316 12754 solver.cpp:237] Iteration 85500, loss = 1.12761
I0522 04:41:25.601485 12754 solver.cpp:253]     Train net output #0: loss = 1.12761 (* 1 = 1.12761 loss)
I0522 04:41:25.601501 12754 sgd_solver.cpp:106] Iteration 85500, lr = 0.0045
I0522 04:41:37.781509 12754 solver.cpp:237] Iteration 86250, loss = 1.10603
I0522 04:41:37.781546 12754 solver.cpp:253]     Train net output #0: loss = 1.10603 (* 1 = 1.10603 loss)
I0522 04:41:37.781564 12754 sgd_solver.cpp:106] Iteration 86250, lr = 0.0045
I0522 04:41:49.969986 12754 solver.cpp:237] Iteration 87000, loss = 1.1482
I0522 04:41:49.970031 12754 solver.cpp:253]     Train net output #0: loss = 1.1482 (* 1 = 1.1482 loss)
I0522 04:41:49.970046 12754 sgd_solver.cpp:106] Iteration 87000, lr = 0.0045
I0522 04:42:02.189927 12754 solver.cpp:237] Iteration 87750, loss = 1.40263
I0522 04:42:02.190073 12754 solver.cpp:253]     Train net output #0: loss = 1.40263 (* 1 = 1.40263 loss)
I0522 04:42:02.190086 12754 sgd_solver.cpp:106] Iteration 87750, lr = 0.0045
I0522 04:42:14.369045 12754 solver.cpp:237] Iteration 88500, loss = 1.51374
I0522 04:42:14.369092 12754 solver.cpp:253]     Train net output #0: loss = 1.51374 (* 1 = 1.51374 loss)
I0522 04:42:14.369107 12754 sgd_solver.cpp:106] Iteration 88500, lr = 0.0045
I0522 04:42:26.517627 12754 solver.cpp:237] Iteration 89250, loss = 1.13287
I0522 04:42:26.517663 12754 solver.cpp:253]     Train net output #0: loss = 1.13287 (* 1 = 1.13287 loss)
I0522 04:42:26.517678 12754 sgd_solver.cpp:106] Iteration 89250, lr = 0.0045
I0522 04:42:38.664651 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_90000.caffemodel
I0522 04:42:38.714082 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_90000.solverstate
I0522 04:42:38.740228 12754 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 04:43:51.551210 12754 solver.cpp:409]     Test net output #0: accuracy = 0.886544
I0522 04:43:51.551384 12754 solver.cpp:409]     Test net output #1: loss = 0.352078 (* 1 = 0.352078 loss)
I0522 04:44:12.392289 12754 solver.cpp:237] Iteration 90000, loss = 1.05189
I0522 04:44:12.392343 12754 solver.cpp:253]     Train net output #0: loss = 1.05189 (* 1 = 1.05189 loss)
I0522 04:44:12.392357 12754 sgd_solver.cpp:106] Iteration 90000, lr = 0.0045
I0522 04:44:24.507153 12754 solver.cpp:237] Iteration 90750, loss = 1.47988
I0522 04:44:24.507319 12754 solver.cpp:253]     Train net output #0: loss = 1.47988 (* 1 = 1.47988 loss)
I0522 04:44:24.507335 12754 sgd_solver.cpp:106] Iteration 90750, lr = 0.0045
I0522 04:44:36.625238 12754 solver.cpp:237] Iteration 91500, loss = 1.00467
I0522 04:44:36.625274 12754 solver.cpp:253]     Train net output #0: loss = 1.00467 (* 1 = 1.00467 loss)
I0522 04:44:36.625290 12754 sgd_solver.cpp:106] Iteration 91500, lr = 0.0045
I0522 04:44:48.769455 12754 solver.cpp:237] Iteration 92250, loss = 1.38839
I0522 04:44:48.769502 12754 solver.cpp:253]     Train net output #0: loss = 1.38839 (* 1 = 1.38839 loss)
I0522 04:44:48.769518 12754 sgd_solver.cpp:106] Iteration 92250, lr = 0.0045
I0522 04:45:00.930018 12754 solver.cpp:237] Iteration 93000, loss = 1.30163
I0522 04:45:00.930167 12754 solver.cpp:253]     Train net output #0: loss = 1.30163 (* 1 = 1.30163 loss)
I0522 04:45:00.930181 12754 sgd_solver.cpp:106] Iteration 93000, lr = 0.0045
I0522 04:45:13.091608 12754 solver.cpp:237] Iteration 93750, loss = 1.54214
I0522 04:45:13.091651 12754 solver.cpp:253]     Train net output #0: loss = 1.54214 (* 1 = 1.54214 loss)
I0522 04:45:13.091666 12754 sgd_solver.cpp:106] Iteration 93750, lr = 0.0045
I0522 04:45:25.198041 12754 solver.cpp:237] Iteration 94500, loss = 1.12205
I0522 04:45:25.198077 12754 solver.cpp:253]     Train net output #0: loss = 1.12205 (* 1 = 1.12205 loss)
I0522 04:45:25.198093 12754 sgd_solver.cpp:106] Iteration 94500, lr = 0.0045
I0522 04:45:58.193645 12754 solver.cpp:237] Iteration 95250, loss = 1.11764
I0522 04:45:58.193814 12754 solver.cpp:253]     Train net output #0: loss = 1.11764 (* 1 = 1.11764 loss)
I0522 04:45:58.193830 12754 sgd_solver.cpp:106] Iteration 95250, lr = 0.0045
I0522 04:46:10.346604 12754 solver.cpp:237] Iteration 96000, loss = 0.949003
I0522 04:46:10.346642 12754 solver.cpp:253]     Train net output #0: loss = 0.949002 (* 1 = 0.949002 loss)
I0522 04:46:10.346657 12754 sgd_solver.cpp:106] Iteration 96000, lr = 0.0045
I0522 04:46:22.501296 12754 solver.cpp:237] Iteration 96750, loss = 1.33506
I0522 04:46:22.501340 12754 solver.cpp:253]     Train net output #0: loss = 1.33506 (* 1 = 1.33506 loss)
I0522 04:46:22.501358 12754 sgd_solver.cpp:106] Iteration 96750, lr = 0.0045
I0522 04:46:34.608283 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_97500.caffemodel
I0522 04:46:34.657244 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_97500.solverstate
I0522 04:46:34.688573 12754 solver.cpp:237] Iteration 97500, loss = 1.04216
I0522 04:46:34.688616 12754 solver.cpp:253]     Train net output #0: loss = 1.04216 (* 1 = 1.04216 loss)
I0522 04:46:34.688634 12754 sgd_solver.cpp:106] Iteration 97500, lr = 0.0045
I0522 04:46:46.793835 12754 solver.cpp:237] Iteration 98250, loss = 1.48185
I0522 04:46:46.793879 12754 solver.cpp:253]     Train net output #0: loss = 1.48185 (* 1 = 1.48185 loss)
I0522 04:46:46.793898 12754 sgd_solver.cpp:106] Iteration 98250, lr = 0.0045
I0522 04:46:58.959489 12754 solver.cpp:237] Iteration 99000, loss = 0.39872
I0522 04:46:58.959527 12754 solver.cpp:253]     Train net output #0: loss = 0.398719 (* 1 = 0.398719 loss)
I0522 04:46:58.959540 12754 sgd_solver.cpp:106] Iteration 99000, lr = 0.0045
I0522 04:47:11.110483 12754 solver.cpp:237] Iteration 99750, loss = 1.3624
I0522 04:47:11.110657 12754 solver.cpp:253]     Train net output #0: loss = 1.3624 (* 1 = 1.3624 loss)
I0522 04:47:11.110672 12754 sgd_solver.cpp:106] Iteration 99750, lr = 0.0045
I0522 04:47:44.117317 12754 solver.cpp:237] Iteration 100500, loss = 1.05487
I0522 04:47:44.117491 12754 solver.cpp:253]     Train net output #0: loss = 1.05487 (* 1 = 1.05487 loss)
I0522 04:47:44.117506 12754 sgd_solver.cpp:106] Iteration 100500, lr = 0.0045
I0522 04:47:56.278002 12754 solver.cpp:237] Iteration 101250, loss = 1.39576
I0522 04:47:56.278038 12754 solver.cpp:253]     Train net output #0: loss = 1.39576 (* 1 = 1.39576 loss)
I0522 04:47:56.278053 12754 sgd_solver.cpp:106] Iteration 101250, lr = 0.0045
I0522 04:48:08.391350 12754 solver.cpp:237] Iteration 102000, loss = 0.84497
I0522 04:48:08.391397 12754 solver.cpp:253]     Train net output #0: loss = 0.844969 (* 1 = 0.844969 loss)
I0522 04:48:08.391412 12754 sgd_solver.cpp:106] Iteration 102000, lr = 0.0045
I0522 04:48:20.496031 12754 solver.cpp:237] Iteration 102750, loss = 1.06248
I0522 04:48:20.496181 12754 solver.cpp:253]     Train net output #0: loss = 1.06248 (* 1 = 1.06248 loss)
I0522 04:48:20.496193 12754 sgd_solver.cpp:106] Iteration 102750, lr = 0.0045
I0522 04:48:32.580430 12754 solver.cpp:237] Iteration 103500, loss = 1.39713
I0522 04:48:32.580476 12754 solver.cpp:253]     Train net output #0: loss = 1.39713 (* 1 = 1.39713 loss)
I0522 04:48:32.580490 12754 sgd_solver.cpp:106] Iteration 103500, lr = 0.0045
I0522 04:48:44.675089 12754 solver.cpp:237] Iteration 104250, loss = 0.830806
I0522 04:48:44.675127 12754 solver.cpp:253]     Train net output #0: loss = 0.830805 (* 1 = 0.830805 loss)
I0522 04:48:44.675140 12754 sgd_solver.cpp:106] Iteration 104250, lr = 0.0045
I0522 04:48:56.770181 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_105000.caffemodel
I0522 04:48:56.820049 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_105000.solverstate
I0522 04:48:56.845273 12754 solver.cpp:341] Iteration 105000, Testing net (#0)
I0522 04:49:48.442133 12754 solver.cpp:409]     Test net output #0: accuracy = 0.885188
I0522 04:49:48.442299 12754 solver.cpp:409]     Test net output #1: loss = 0.392708 (* 1 = 0.392708 loss)
I0522 04:50:09.352229 12754 solver.cpp:237] Iteration 105000, loss = 1.22732
I0522 04:50:09.352283 12754 solver.cpp:253]     Train net output #0: loss = 1.22732 (* 1 = 1.22732 loss)
I0522 04:50:09.352298 12754 sgd_solver.cpp:106] Iteration 105000, lr = 0.0045
I0522 04:50:21.495360 12754 solver.cpp:237] Iteration 105750, loss = 1.15981
I0522 04:50:21.495519 12754 solver.cpp:253]     Train net output #0: loss = 1.15981 (* 1 = 1.15981 loss)
I0522 04:50:21.495533 12754 sgd_solver.cpp:106] Iteration 105750, lr = 0.0045
I0522 04:50:33.665503 12754 solver.cpp:237] Iteration 106500, loss = 0.68677
I0522 04:50:33.665551 12754 solver.cpp:253]     Train net output #0: loss = 0.686769 (* 1 = 0.686769 loss)
I0522 04:50:33.665566 12754 sgd_solver.cpp:106] Iteration 106500, lr = 0.0045
I0522 04:50:45.807101 12754 solver.cpp:237] Iteration 107250, loss = 1.04019
I0522 04:50:45.807137 12754 solver.cpp:253]     Train net output #0: loss = 1.04019 (* 1 = 1.04019 loss)
I0522 04:50:45.807153 12754 sgd_solver.cpp:106] Iteration 107250, lr = 0.0045
I0522 04:50:57.966876 12754 solver.cpp:237] Iteration 108000, loss = 1.46493
I0522 04:50:57.967052 12754 solver.cpp:253]     Train net output #0: loss = 1.46493 (* 1 = 1.46493 loss)
I0522 04:50:57.967069 12754 sgd_solver.cpp:106] Iteration 108000, lr = 0.0045
I0522 04:51:10.189699 12754 solver.cpp:237] Iteration 108750, loss = 1.00426
I0522 04:51:10.189736 12754 solver.cpp:253]     Train net output #0: loss = 1.00426 (* 1 = 1.00426 loss)
I0522 04:51:10.189751 12754 sgd_solver.cpp:106] Iteration 108750, lr = 0.0045
I0522 04:51:22.417930 12754 solver.cpp:237] Iteration 109500, loss = 1.05047
I0522 04:51:22.417980 12754 solver.cpp:253]     Train net output #0: loss = 1.05046 (* 1 = 1.05046 loss)
I0522 04:51:22.417994 12754 sgd_solver.cpp:106] Iteration 109500, lr = 0.0045
I0522 04:51:55.534298 12754 solver.cpp:237] Iteration 110250, loss = 1.62861
I0522 04:51:55.534476 12754 solver.cpp:253]     Train net output #0: loss = 1.62861 (* 1 = 1.62861 loss)
I0522 04:51:55.534492 12754 sgd_solver.cpp:106] Iteration 110250, lr = 0.0045
I0522 04:52:07.713685 12754 solver.cpp:237] Iteration 111000, loss = 1.12284
I0522 04:52:07.713721 12754 solver.cpp:253]     Train net output #0: loss = 1.12284 (* 1 = 1.12284 loss)
I0522 04:52:07.713737 12754 sgd_solver.cpp:106] Iteration 111000, lr = 0.0045
I0522 04:52:19.859030 12754 solver.cpp:237] Iteration 111750, loss = 1.13753
I0522 04:52:19.859079 12754 solver.cpp:253]     Train net output #0: loss = 1.13753 (* 1 = 1.13753 loss)
I0522 04:52:19.859094 12754 sgd_solver.cpp:106] Iteration 111750, lr = 0.0045
I0522 04:52:32.004207 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_112500.caffemodel
I0522 04:52:32.099298 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_112500.solverstate
I0522 04:52:32.132249 12754 solver.cpp:237] Iteration 112500, loss = 1.33055
I0522 04:52:32.132297 12754 solver.cpp:253]     Train net output #0: loss = 1.33055 (* 1 = 1.33055 loss)
I0522 04:52:32.132314 12754 sgd_solver.cpp:106] Iteration 112500, lr = 0.0045
I0522 04:52:44.284250 12754 solver.cpp:237] Iteration 113250, loss = 1.28062
I0522 04:52:44.284294 12754 solver.cpp:253]     Train net output #0: loss = 1.28062 (* 1 = 1.28062 loss)
I0522 04:52:44.284308 12754 sgd_solver.cpp:106] Iteration 113250, lr = 0.0045
I0522 04:52:56.496824 12754 solver.cpp:237] Iteration 114000, loss = 0.823697
I0522 04:52:56.496860 12754 solver.cpp:253]     Train net output #0: loss = 0.823696 (* 1 = 0.823696 loss)
I0522 04:52:56.496875 12754 sgd_solver.cpp:106] Iteration 114000, lr = 0.0045
I0522 04:53:08.722149 12754 solver.cpp:237] Iteration 114750, loss = 1.4303
I0522 04:53:08.722321 12754 solver.cpp:253]     Train net output #0: loss = 1.43029 (* 1 = 1.43029 loss)
I0522 04:53:08.722337 12754 sgd_solver.cpp:106] Iteration 114750, lr = 0.0045
I0522 04:53:41.842581 12754 solver.cpp:237] Iteration 115500, loss = 1.00383
I0522 04:53:41.842752 12754 solver.cpp:253]     Train net output #0: loss = 1.00383 (* 1 = 1.00383 loss)
I0522 04:53:41.842768 12754 sgd_solver.cpp:106] Iteration 115500, lr = 0.0045
I0522 04:53:54.062882 12754 solver.cpp:237] Iteration 116250, loss = 1.11019
I0522 04:53:54.062930 12754 solver.cpp:253]     Train net output #0: loss = 1.11019 (* 1 = 1.11019 loss)
I0522 04:53:54.062947 12754 sgd_solver.cpp:106] Iteration 116250, lr = 0.0045
I0522 04:54:06.274937 12754 solver.cpp:237] Iteration 117000, loss = 1.55636
I0522 04:54:06.274973 12754 solver.cpp:253]     Train net output #0: loss = 1.55636 (* 1 = 1.55636 loss)
I0522 04:54:06.274989 12754 sgd_solver.cpp:106] Iteration 117000, lr = 0.0045
I0522 04:54:18.475394 12754 solver.cpp:237] Iteration 117750, loss = 1.6186
I0522 04:54:18.475556 12754 solver.cpp:253]     Train net output #0: loss = 1.6186 (* 1 = 1.6186 loss)
I0522 04:54:18.475571 12754 sgd_solver.cpp:106] Iteration 117750, lr = 0.0045
I0522 04:54:30.682957 12754 solver.cpp:237] Iteration 118500, loss = 1.19846
I0522 04:54:30.682993 12754 solver.cpp:253]     Train net output #0: loss = 1.19846 (* 1 = 1.19846 loss)
I0522 04:54:30.683010 12754 sgd_solver.cpp:106] Iteration 118500, lr = 0.0045
I0522 04:54:42.870573 12754 solver.cpp:237] Iteration 119250, loss = 0.935211
I0522 04:54:42.870621 12754 solver.cpp:253]     Train net output #0: loss = 0.935209 (* 1 = 0.935209 loss)
I0522 04:54:42.870636 12754 sgd_solver.cpp:106] Iteration 119250, lr = 0.0045
I0522 04:54:55.044781 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_120000.caffemodel
I0522 04:54:55.099778 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_120000.solverstate
I0522 04:54:55.125080 12754 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 04:56:08.005828 12754 solver.cpp:409]     Test net output #0: accuracy = 0.889356
I0522 04:56:08.006002 12754 solver.cpp:409]     Test net output #1: loss = 0.346509 (* 1 = 0.346509 loss)
I0522 04:56:28.903878 12754 solver.cpp:237] Iteration 120000, loss = 1.07947
I0522 04:56:28.903930 12754 solver.cpp:253]     Train net output #0: loss = 1.07947 (* 1 = 1.07947 loss)
I0522 04:56:28.903947 12754 sgd_solver.cpp:106] Iteration 120000, lr = 0.0045
I0522 04:56:41.064749 12754 solver.cpp:237] Iteration 120750, loss = 1.16623
I0522 04:56:41.064905 12754 solver.cpp:253]     Train net output #0: loss = 1.16623 (* 1 = 1.16623 loss)
I0522 04:56:41.064919 12754 sgd_solver.cpp:106] Iteration 120750, lr = 0.0045
I0522 04:56:53.238734 12754 solver.cpp:237] Iteration 121500, loss = 1.13027
I0522 04:56:53.238781 12754 solver.cpp:253]     Train net output #0: loss = 1.13027 (* 1 = 1.13027 loss)
I0522 04:56:53.238795 12754 sgd_solver.cpp:106] Iteration 121500, lr = 0.0045
I0522 04:57:05.381357 12754 solver.cpp:237] Iteration 122250, loss = 1.22805
I0522 04:57:05.381393 12754 solver.cpp:253]     Train net output #0: loss = 1.22805 (* 1 = 1.22805 loss)
I0522 04:57:05.381408 12754 sgd_solver.cpp:106] Iteration 122250, lr = 0.0045
I0522 04:57:17.505630 12754 solver.cpp:237] Iteration 123000, loss = 1.20072
I0522 04:57:17.505798 12754 solver.cpp:253]     Train net output #0: loss = 1.20072 (* 1 = 1.20072 loss)
I0522 04:57:17.505813 12754 sgd_solver.cpp:106] Iteration 123000, lr = 0.0045
I0522 04:57:29.618888 12754 solver.cpp:237] Iteration 123750, loss = 0.609244
I0522 04:57:29.618927 12754 solver.cpp:253]     Train net output #0: loss = 0.609242 (* 1 = 0.609242 loss)
I0522 04:57:29.618940 12754 sgd_solver.cpp:106] Iteration 123750, lr = 0.0045
I0522 04:57:41.735074 12754 solver.cpp:237] Iteration 124500, loss = 1.09386
I0522 04:57:41.735118 12754 solver.cpp:253]     Train net output #0: loss = 1.09386 (* 1 = 1.09386 loss)
I0522 04:57:41.735132 12754 sgd_solver.cpp:106] Iteration 124500, lr = 0.0045
I0522 04:58:14.797093 12754 solver.cpp:237] Iteration 125250, loss = 0.99262
I0522 04:58:14.797268 12754 solver.cpp:253]     Train net output #0: loss = 0.992618 (* 1 = 0.992618 loss)
I0522 04:58:14.797283 12754 sgd_solver.cpp:106] Iteration 125250, lr = 0.0045
I0522 04:58:26.920338 12754 solver.cpp:237] Iteration 126000, loss = 1.02169
I0522 04:58:26.920387 12754 solver.cpp:253]     Train net output #0: loss = 1.02169 (* 1 = 1.02169 loss)
I0522 04:58:26.920403 12754 sgd_solver.cpp:106] Iteration 126000, lr = 0.0045
I0522 04:58:39.011409 12754 solver.cpp:237] Iteration 126750, loss = 1.21063
I0522 04:58:39.011446 12754 solver.cpp:253]     Train net output #0: loss = 1.21063 (* 1 = 1.21063 loss)
I0522 04:58:39.011461 12754 sgd_solver.cpp:106] Iteration 126750, lr = 0.0045
I0522 04:58:51.086580 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_127500.caffemodel
I0522 04:58:51.135965 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_127500.solverstate
I0522 04:58:51.166282 12754 solver.cpp:237] Iteration 127500, loss = 1.13243
I0522 04:58:51.166326 12754 solver.cpp:253]     Train net output #0: loss = 1.13243 (* 1 = 1.13243 loss)
I0522 04:58:51.166343 12754 sgd_solver.cpp:106] Iteration 127500, lr = 0.0045
I0522 04:59:03.314201 12754 solver.cpp:237] Iteration 128250, loss = 1.26721
I0522 04:59:03.314239 12754 solver.cpp:253]     Train net output #0: loss = 1.2672 (* 1 = 1.2672 loss)
I0522 04:59:03.314252 12754 sgd_solver.cpp:106] Iteration 128250, lr = 0.0045
I0522 04:59:15.419080 12754 solver.cpp:237] Iteration 129000, loss = 0.957343
I0522 04:59:15.419119 12754 solver.cpp:253]     Train net output #0: loss = 0.957341 (* 1 = 0.957341 loss)
I0522 04:59:15.419138 12754 sgd_solver.cpp:106] Iteration 129000, lr = 0.0045
I0522 04:59:27.507915 12754 solver.cpp:237] Iteration 129750, loss = 0.569503
I0522 04:59:27.508074 12754 solver.cpp:253]     Train net output #0: loss = 0.569501 (* 1 = 0.569501 loss)
I0522 04:59:27.508087 12754 sgd_solver.cpp:106] Iteration 129750, lr = 0.0045
I0522 05:00:00.529758 12754 solver.cpp:237] Iteration 130500, loss = 1.33466
I0522 05:00:00.529937 12754 solver.cpp:253]     Train net output #0: loss = 1.33466 (* 1 = 1.33466 loss)
I0522 05:00:00.529950 12754 sgd_solver.cpp:106] Iteration 130500, lr = 0.0045
I0522 05:00:12.618357 12754 solver.cpp:237] Iteration 131250, loss = 1.27646
I0522 05:00:12.618407 12754 solver.cpp:253]     Train net output #0: loss = 1.27646 (* 1 = 1.27646 loss)
I0522 05:00:12.618420 12754 sgd_solver.cpp:106] Iteration 131250, lr = 0.0045
I0522 05:00:24.702118 12754 solver.cpp:237] Iteration 132000, loss = 1.39461
I0522 05:00:24.702154 12754 solver.cpp:253]     Train net output #0: loss = 1.3946 (* 1 = 1.3946 loss)
I0522 05:00:24.702168 12754 sgd_solver.cpp:106] Iteration 132000, lr = 0.0045
I0522 05:00:36.840004 12754 solver.cpp:237] Iteration 132750, loss = 1.06417
I0522 05:00:36.840167 12754 solver.cpp:253]     Train net output #0: loss = 1.06417 (* 1 = 1.06417 loss)
I0522 05:00:36.840181 12754 sgd_solver.cpp:106] Iteration 132750, lr = 0.0045
I0522 05:00:49.006906 12754 solver.cpp:237] Iteration 133500, loss = 1.34477
I0522 05:00:49.006942 12754 solver.cpp:253]     Train net output #0: loss = 1.34476 (* 1 = 1.34476 loss)
I0522 05:00:49.006956 12754 sgd_solver.cpp:106] Iteration 133500, lr = 0.0045
I0522 05:01:01.183418 12754 solver.cpp:237] Iteration 134250, loss = 1.0686
I0522 05:01:01.183461 12754 solver.cpp:253]     Train net output #0: loss = 1.0686 (* 1 = 1.0686 loss)
I0522 05:01:01.183475 12754 sgd_solver.cpp:106] Iteration 134250, lr = 0.0045
I0522 05:01:13.300029 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_135000.caffemodel
I0522 05:01:13.350229 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_135000.solverstate
I0522 05:01:13.376157 12754 solver.cpp:341] Iteration 135000, Testing net (#0)
I0522 05:02:05.314492 12754 solver.cpp:409]     Test net output #0: accuracy = 0.885542
I0522 05:02:05.314667 12754 solver.cpp:409]     Test net output #1: loss = 0.357951 (* 1 = 0.357951 loss)
I0522 05:02:26.164391 12754 solver.cpp:237] Iteration 135000, loss = 1.13014
I0522 05:02:26.164445 12754 solver.cpp:253]     Train net output #0: loss = 1.13014 (* 1 = 1.13014 loss)
I0522 05:02:26.164460 12754 sgd_solver.cpp:106] Iteration 135000, lr = 0.0045
I0522 05:02:38.356894 12754 solver.cpp:237] Iteration 135750, loss = 1.39616
I0522 05:02:38.357074 12754 solver.cpp:253]     Train net output #0: loss = 1.39616 (* 1 = 1.39616 loss)
I0522 05:02:38.357089 12754 sgd_solver.cpp:106] Iteration 135750, lr = 0.0045
I0522 05:02:50.547221 12754 solver.cpp:237] Iteration 136500, loss = 1.03719
I0522 05:02:50.547257 12754 solver.cpp:253]     Train net output #0: loss = 1.03718 (* 1 = 1.03718 loss)
I0522 05:02:50.547271 12754 sgd_solver.cpp:106] Iteration 136500, lr = 0.0045
I0522 05:03:02.734964 12754 solver.cpp:237] Iteration 137250, loss = 1.07878
I0522 05:03:02.735011 12754 solver.cpp:253]     Train net output #0: loss = 1.07878 (* 1 = 1.07878 loss)
I0522 05:03:02.735025 12754 sgd_solver.cpp:106] Iteration 137250, lr = 0.0045
I0522 05:03:14.918931 12754 solver.cpp:237] Iteration 138000, loss = 1.31267
I0522 05:03:14.919095 12754 solver.cpp:253]     Train net output #0: loss = 1.31266 (* 1 = 1.31266 loss)
I0522 05:03:14.919109 12754 sgd_solver.cpp:106] Iteration 138000, lr = 0.0045
I0522 05:03:27.108204 12754 solver.cpp:237] Iteration 138750, loss = 1.05048
I0522 05:03:27.108253 12754 solver.cpp:253]     Train net output #0: loss = 1.05048 (* 1 = 1.05048 loss)
I0522 05:03:27.108266 12754 sgd_solver.cpp:106] Iteration 138750, lr = 0.0045
I0522 05:03:39.303572 12754 solver.cpp:237] Iteration 139500, loss = 0.846171
I0522 05:03:39.303609 12754 solver.cpp:253]     Train net output #0: loss = 0.846168 (* 1 = 0.846168 loss)
I0522 05:03:39.303623 12754 sgd_solver.cpp:106] Iteration 139500, lr = 0.0045
I0522 05:04:12.394413 12754 solver.cpp:237] Iteration 140250, loss = 1.20901
I0522 05:04:12.394592 12754 solver.cpp:253]     Train net output #0: loss = 1.20901 (* 1 = 1.20901 loss)
I0522 05:04:12.394608 12754 sgd_solver.cpp:106] Iteration 140250, lr = 0.0045
I0522 05:04:24.552749 12754 solver.cpp:237] Iteration 141000, loss = 1.03896
I0522 05:04:24.552796 12754 solver.cpp:253]     Train net output #0: loss = 1.03896 (* 1 = 1.03896 loss)
I0522 05:04:24.552810 12754 sgd_solver.cpp:106] Iteration 141000, lr = 0.0045
I0522 05:04:36.699921 12754 solver.cpp:237] Iteration 141750, loss = 0.735671
I0522 05:04:36.699959 12754 solver.cpp:253]     Train net output #0: loss = 0.735669 (* 1 = 0.735669 loss)
I0522 05:04:36.699972 12754 sgd_solver.cpp:106] Iteration 141750, lr = 0.0045
I0522 05:04:48.862666 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_142500.caffemodel
I0522 05:04:48.915104 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_142500.solverstate
I0522 05:04:48.948045 12754 solver.cpp:237] Iteration 142500, loss = 1.97637
I0522 05:04:48.948094 12754 solver.cpp:253]     Train net output #0: loss = 1.97637 (* 1 = 1.97637 loss)
I0522 05:04:48.948109 12754 sgd_solver.cpp:106] Iteration 142500, lr = 0.0045
I0522 05:05:01.106596 12754 solver.cpp:237] Iteration 143250, loss = 1.03097
I0522 05:05:01.106632 12754 solver.cpp:253]     Train net output #0: loss = 1.03097 (* 1 = 1.03097 loss)
I0522 05:05:01.106647 12754 sgd_solver.cpp:106] Iteration 143250, lr = 0.0045
I0522 05:05:13.269536 12754 solver.cpp:237] Iteration 144000, loss = 2.18202
I0522 05:05:13.269583 12754 solver.cpp:253]     Train net output #0: loss = 2.18202 (* 1 = 2.18202 loss)
I0522 05:05:13.269598 12754 sgd_solver.cpp:106] Iteration 144000, lr = 0.0045
I0522 05:05:25.455535 12754 solver.cpp:237] Iteration 144750, loss = 1.33774
I0522 05:05:25.455695 12754 solver.cpp:253]     Train net output #0: loss = 1.33774 (* 1 = 1.33774 loss)
I0522 05:05:25.455708 12754 sgd_solver.cpp:106] Iteration 144750, lr = 0.0045
I0522 05:05:58.523656 12754 solver.cpp:237] Iteration 145500, loss = 0.930347
I0522 05:05:58.523838 12754 solver.cpp:253]     Train net output #0: loss = 0.930344 (* 1 = 0.930344 loss)
I0522 05:05:58.523854 12754 sgd_solver.cpp:106] Iteration 145500, lr = 0.0045
I0522 05:06:10.626472 12754 solver.cpp:237] Iteration 146250, loss = 1.26453
I0522 05:06:10.626508 12754 solver.cpp:253]     Train net output #0: loss = 1.26452 (* 1 = 1.26452 loss)
I0522 05:06:10.626523 12754 sgd_solver.cpp:106] Iteration 146250, lr = 0.0045
I0522 05:06:22.757828 12754 solver.cpp:237] Iteration 147000, loss = 1.03324
I0522 05:06:22.757879 12754 solver.cpp:253]     Train net output #0: loss = 1.03324 (* 1 = 1.03324 loss)
I0522 05:06:22.757894 12754 sgd_solver.cpp:106] Iteration 147000, lr = 0.0045
I0522 05:06:34.942673 12754 solver.cpp:237] Iteration 147750, loss = 1.64735
I0522 05:06:34.942840 12754 solver.cpp:253]     Train net output #0: loss = 1.64735 (* 1 = 1.64735 loss)
I0522 05:06:34.942853 12754 sgd_solver.cpp:106] Iteration 147750, lr = 0.0045
I0522 05:06:47.129776 12754 solver.cpp:237] Iteration 148500, loss = 1.04165
I0522 05:06:47.129824 12754 solver.cpp:253]     Train net output #0: loss = 1.04165 (* 1 = 1.04165 loss)
I0522 05:06:47.129838 12754 sgd_solver.cpp:106] Iteration 148500, lr = 0.0045
I0522 05:06:59.340041 12754 solver.cpp:237] Iteration 149250, loss = 1.61341
I0522 05:06:59.340077 12754 solver.cpp:253]     Train net output #0: loss = 1.61341 (* 1 = 1.61341 loss)
I0522 05:06:59.340092 12754 sgd_solver.cpp:106] Iteration 149250, lr = 0.0045
I0522 05:07:11.509097 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_150000.caffemodel
I0522 05:07:11.560634 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_150000.solverstate
I0522 05:07:11.587973 12754 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 05:08:24.493957 12754 solver.cpp:409]     Test net output #0: accuracy = 0.892736
I0522 05:08:24.494133 12754 solver.cpp:409]     Test net output #1: loss = 0.361141 (* 1 = 0.361141 loss)
I0522 05:08:45.372758 12754 solver.cpp:237] Iteration 150000, loss = 1.17887
I0522 05:08:45.372812 12754 solver.cpp:253]     Train net output #0: loss = 1.17886 (* 1 = 1.17886 loss)
I0522 05:08:45.372826 12754 sgd_solver.cpp:106] Iteration 150000, lr = 0.0045
I0522 05:08:57.472827 12754 solver.cpp:237] Iteration 150750, loss = 1.21911
I0522 05:08:57.473006 12754 solver.cpp:253]     Train net output #0: loss = 1.21911 (* 1 = 1.21911 loss)
I0522 05:08:57.473021 12754 sgd_solver.cpp:106] Iteration 150750, lr = 0.0045
I0522 05:09:09.556970 12754 solver.cpp:237] Iteration 151500, loss = 1.00999
I0522 05:09:09.557008 12754 solver.cpp:253]     Train net output #0: loss = 1.00999 (* 1 = 1.00999 loss)
I0522 05:09:09.557023 12754 sgd_solver.cpp:106] Iteration 151500, lr = 0.0045
I0522 05:09:21.658215 12754 solver.cpp:237] Iteration 152250, loss = 0.948456
I0522 05:09:21.658267 12754 solver.cpp:253]     Train net output #0: loss = 0.948453 (* 1 = 0.948453 loss)
I0522 05:09:21.658282 12754 sgd_solver.cpp:106] Iteration 152250, lr = 0.0045
I0522 05:09:33.760349 12754 solver.cpp:237] Iteration 153000, loss = 0.992821
I0522 05:09:33.760509 12754 solver.cpp:253]     Train net output #0: loss = 0.992818 (* 1 = 0.992818 loss)
I0522 05:09:33.760522 12754 sgd_solver.cpp:106] Iteration 153000, lr = 0.0045
I0522 05:09:45.864097 12754 solver.cpp:237] Iteration 153750, loss = 0.978062
I0522 05:09:45.864146 12754 solver.cpp:253]     Train net output #0: loss = 0.978059 (* 1 = 0.978059 loss)
I0522 05:09:45.864161 12754 sgd_solver.cpp:106] Iteration 153750, lr = 0.0045
I0522 05:09:57.964267 12754 solver.cpp:237] Iteration 154500, loss = 1.36452
I0522 05:09:57.964303 12754 solver.cpp:253]     Train net output #0: loss = 1.36451 (* 1 = 1.36451 loss)
I0522 05:09:57.964318 12754 sgd_solver.cpp:106] Iteration 154500, lr = 0.0045
I0522 05:10:30.933809 12754 solver.cpp:237] Iteration 155250, loss = 1.02969
I0522 05:10:30.933987 12754 solver.cpp:253]     Train net output #0: loss = 1.02969 (* 1 = 1.02969 loss)
I0522 05:10:30.934001 12754 sgd_solver.cpp:106] Iteration 155250, lr = 0.0045
I0522 05:10:43.045269 12754 solver.cpp:237] Iteration 156000, loss = 1.11089
I0522 05:10:43.045305 12754 solver.cpp:253]     Train net output #0: loss = 1.11089 (* 1 = 1.11089 loss)
I0522 05:10:43.045320 12754 sgd_solver.cpp:106] Iteration 156000, lr = 0.0045
I0522 05:10:55.156499 12754 solver.cpp:237] Iteration 156750, loss = 1.68281
I0522 05:10:55.156543 12754 solver.cpp:253]     Train net output #0: loss = 1.6828 (* 1 = 1.6828 loss)
I0522 05:10:55.156560 12754 sgd_solver.cpp:106] Iteration 156750, lr = 0.0045
I0522 05:11:07.237301 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_157500.caffemodel
I0522 05:11:07.286613 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_157500.solverstate
I0522 05:11:07.316846 12754 solver.cpp:237] Iteration 157500, loss = 0.888167
I0522 05:11:07.316892 12754 solver.cpp:253]     Train net output #0: loss = 0.888164 (* 1 = 0.888164 loss)
I0522 05:11:07.316907 12754 sgd_solver.cpp:106] Iteration 157500, lr = 0.0045
I0522 05:11:19.403683 12754 solver.cpp:237] Iteration 158250, loss = 1.22879
I0522 05:11:19.403720 12754 solver.cpp:253]     Train net output #0: loss = 1.22878 (* 1 = 1.22878 loss)
I0522 05:11:19.403734 12754 sgd_solver.cpp:106] Iteration 158250, lr = 0.0045
I0522 05:11:31.472316 12754 solver.cpp:237] Iteration 159000, loss = 0.987128
I0522 05:11:31.472355 12754 solver.cpp:253]     Train net output #0: loss = 0.987125 (* 1 = 0.987125 loss)
I0522 05:11:31.472369 12754 sgd_solver.cpp:106] Iteration 159000, lr = 0.0045
I0522 05:11:43.535310 12754 solver.cpp:237] Iteration 159750, loss = 0.977112
I0522 05:11:43.535475 12754 solver.cpp:253]     Train net output #0: loss = 0.977109 (* 1 = 0.977109 loss)
I0522 05:11:43.535490 12754 sgd_solver.cpp:106] Iteration 159750, lr = 0.0045
I0522 05:12:16.514022 12754 solver.cpp:237] Iteration 160500, loss = 0.883949
I0522 05:12:16.514201 12754 solver.cpp:253]     Train net output #0: loss = 0.883946 (* 1 = 0.883946 loss)
I0522 05:12:16.514215 12754 sgd_solver.cpp:106] Iteration 160500, lr = 0.0045
I0522 05:12:28.606358 12754 solver.cpp:237] Iteration 161250, loss = 1.17622
I0522 05:12:28.606395 12754 solver.cpp:253]     Train net output #0: loss = 1.17622 (* 1 = 1.17622 loss)
I0522 05:12:28.606408 12754 sgd_solver.cpp:106] Iteration 161250, lr = 0.0045
I0522 05:12:40.702476 12754 solver.cpp:237] Iteration 162000, loss = 1.21819
I0522 05:12:40.702525 12754 solver.cpp:253]     Train net output #0: loss = 1.21818 (* 1 = 1.21818 loss)
I0522 05:12:40.702539 12754 sgd_solver.cpp:106] Iteration 162000, lr = 0.0045
I0522 05:12:52.799469 12754 solver.cpp:237] Iteration 162750, loss = 1.14916
I0522 05:12:52.799628 12754 solver.cpp:253]     Train net output #0: loss = 1.14916 (* 1 = 1.14916 loss)
I0522 05:12:52.799643 12754 sgd_solver.cpp:106] Iteration 162750, lr = 0.0045
I0522 05:13:04.941015 12754 solver.cpp:237] Iteration 163500, loss = 1.06974
I0522 05:13:04.941059 12754 solver.cpp:253]     Train net output #0: loss = 1.06973 (* 1 = 1.06973 loss)
I0522 05:13:04.941073 12754 sgd_solver.cpp:106] Iteration 163500, lr = 0.0045
I0522 05:13:17.051475 12754 solver.cpp:237] Iteration 164250, loss = 1.26607
I0522 05:13:17.051511 12754 solver.cpp:253]     Train net output #0: loss = 1.26607 (* 1 = 1.26607 loss)
I0522 05:13:17.051525 12754 sgd_solver.cpp:106] Iteration 164250, lr = 0.0045
I0522 05:13:29.102390 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_165000.caffemodel
I0522 05:13:29.151690 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_165000.solverstate
I0522 05:13:29.177481 12754 solver.cpp:341] Iteration 165000, Testing net (#0)
I0522 05:14:20.840872 12754 solver.cpp:409]     Test net output #0: accuracy = 0.895504
I0522 05:14:20.841053 12754 solver.cpp:409]     Test net output #1: loss = 0.322772 (* 1 = 0.322772 loss)
I0522 05:14:41.682494 12754 solver.cpp:237] Iteration 165000, loss = 1.0385
I0522 05:14:41.682548 12754 solver.cpp:253]     Train net output #0: loss = 1.03849 (* 1 = 1.03849 loss)
I0522 05:14:41.682562 12754 sgd_solver.cpp:106] Iteration 165000, lr = 0.0045
I0522 05:14:53.838002 12754 solver.cpp:237] Iteration 165750, loss = 1.31952
I0522 05:14:53.838171 12754 solver.cpp:253]     Train net output #0: loss = 1.31951 (* 1 = 1.31951 loss)
I0522 05:14:53.838186 12754 sgd_solver.cpp:106] Iteration 165750, lr = 0.0045
I0522 05:15:05.990981 12754 solver.cpp:237] Iteration 166500, loss = 1.17213
I0522 05:15:05.991029 12754 solver.cpp:253]     Train net output #0: loss = 1.17213 (* 1 = 1.17213 loss)
I0522 05:15:05.991044 12754 sgd_solver.cpp:106] Iteration 166500, lr = 0.0045
I0522 05:15:18.174414 12754 solver.cpp:237] Iteration 167250, loss = 0.852829
I0522 05:15:18.174451 12754 solver.cpp:253]     Train net output #0: loss = 0.852826 (* 1 = 0.852826 loss)
I0522 05:15:18.174466 12754 sgd_solver.cpp:106] Iteration 167250, lr = 0.0045
I0522 05:15:30.358988 12754 solver.cpp:237] Iteration 168000, loss = 1.07547
I0522 05:15:30.359159 12754 solver.cpp:253]     Train net output #0: loss = 1.07547 (* 1 = 1.07547 loss)
I0522 05:15:30.359174 12754 sgd_solver.cpp:106] Iteration 168000, lr = 0.0045
I0522 05:15:42.504341 12754 solver.cpp:237] Iteration 168750, loss = 1.59597
I0522 05:15:42.504377 12754 solver.cpp:253]     Train net output #0: loss = 1.59597 (* 1 = 1.59597 loss)
I0522 05:15:42.504391 12754 sgd_solver.cpp:106] Iteration 168750, lr = 0.0045
I0522 05:15:54.647821 12754 solver.cpp:237] Iteration 169500, loss = 1.19705
I0522 05:15:54.647857 12754 solver.cpp:253]     Train net output #0: loss = 1.19705 (* 1 = 1.19705 loss)
I0522 05:15:54.647872 12754 sgd_solver.cpp:106] Iteration 169500, lr = 0.0045
I0522 05:16:27.703604 12754 solver.cpp:237] Iteration 170250, loss = 1.2434
I0522 05:16:27.703784 12754 solver.cpp:253]     Train net output #0: loss = 1.2434 (* 1 = 1.2434 loss)
I0522 05:16:27.703799 12754 sgd_solver.cpp:106] Iteration 170250, lr = 0.0045
I0522 05:16:39.819998 12754 solver.cpp:237] Iteration 171000, loss = 1.01807
I0522 05:16:39.820034 12754 solver.cpp:253]     Train net output #0: loss = 1.01806 (* 1 = 1.01806 loss)
I0522 05:16:39.820049 12754 sgd_solver.cpp:106] Iteration 171000, lr = 0.0045
I0522 05:16:51.972384 12754 solver.cpp:237] Iteration 171750, loss = 0.886454
I0522 05:16:51.972432 12754 solver.cpp:253]     Train net output #0: loss = 0.886451 (* 1 = 0.886451 loss)
I0522 05:16:51.972446 12754 sgd_solver.cpp:106] Iteration 171750, lr = 0.0045
I0522 05:17:04.116888 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_172500.caffemodel
I0522 05:17:04.166404 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_172500.solverstate
I0522 05:17:04.197253 12754 solver.cpp:237] Iteration 172500, loss = 0.741806
I0522 05:17:04.197295 12754 solver.cpp:253]     Train net output #0: loss = 0.741804 (* 1 = 0.741804 loss)
I0522 05:17:04.197314 12754 sgd_solver.cpp:106] Iteration 172500, lr = 0.0045
I0522 05:17:16.354748 12754 solver.cpp:237] Iteration 173250, loss = 1.24976
I0522 05:17:16.354797 12754 solver.cpp:253]     Train net output #0: loss = 1.24975 (* 1 = 1.24975 loss)
I0522 05:17:16.354820 12754 sgd_solver.cpp:106] Iteration 173250, lr = 0.0045
I0522 05:17:28.514233 12754 solver.cpp:237] Iteration 174000, loss = 0.832012
I0522 05:17:28.514271 12754 solver.cpp:253]     Train net output #0: loss = 0.832009 (* 1 = 0.832009 loss)
I0522 05:17:28.514284 12754 sgd_solver.cpp:106] Iteration 174000, lr = 0.0045
I0522 05:17:40.672821 12754 solver.cpp:237] Iteration 174750, loss = 1.40423
I0522 05:17:40.673015 12754 solver.cpp:253]     Train net output #0: loss = 1.40422 (* 1 = 1.40422 loss)
I0522 05:17:40.673029 12754 sgd_solver.cpp:106] Iteration 174750, lr = 0.0045
I0522 05:18:13.734556 12754 solver.cpp:237] Iteration 175500, loss = 1.07647
I0522 05:18:13.734750 12754 solver.cpp:253]     Train net output #0: loss = 1.07646 (* 1 = 1.07646 loss)
I0522 05:18:13.734765 12754 sgd_solver.cpp:106] Iteration 175500, lr = 0.0045
I0522 05:18:25.928916 12754 solver.cpp:237] Iteration 176250, loss = 1.38994
I0522 05:18:25.928966 12754 solver.cpp:253]     Train net output #0: loss = 1.38994 (* 1 = 1.38994 loss)
I0522 05:18:25.928983 12754 sgd_solver.cpp:106] Iteration 176250, lr = 0.0045
I0522 05:18:38.044566 12754 solver.cpp:237] Iteration 177000, loss = 1.02785
I0522 05:18:38.044603 12754 solver.cpp:253]     Train net output #0: loss = 1.02785 (* 1 = 1.02785 loss)
I0522 05:18:38.044618 12754 sgd_solver.cpp:106] Iteration 177000, lr = 0.0045
I0522 05:18:50.181685 12754 solver.cpp:237] Iteration 177750, loss = 1.18126
I0522 05:18:50.181849 12754 solver.cpp:253]     Train net output #0: loss = 1.18126 (* 1 = 1.18126 loss)
I0522 05:18:50.181862 12754 sgd_solver.cpp:106] Iteration 177750, lr = 0.0045
I0522 05:19:02.379138 12754 solver.cpp:237] Iteration 178500, loss = 1.09178
I0522 05:19:02.379175 12754 solver.cpp:253]     Train net output #0: loss = 1.09178 (* 1 = 1.09178 loss)
I0522 05:19:02.379190 12754 sgd_solver.cpp:106] Iteration 178500, lr = 0.0045
I0522 05:19:14.484694 12754 solver.cpp:237] Iteration 179250, loss = 0.915422
I0522 05:19:14.484730 12754 solver.cpp:253]     Train net output #0: loss = 0.915419 (* 1 = 0.915419 loss)
I0522 05:19:14.484745 12754 sgd_solver.cpp:106] Iteration 179250, lr = 0.0045
I0522 05:19:26.589575 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_180000.caffemodel
I0522 05:19:26.639122 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_180000.solverstate
I0522 05:19:26.664239 12754 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 05:20:39.635792 12754 solver.cpp:409]     Test net output #0: accuracy = 0.895936
I0522 05:20:39.635969 12754 solver.cpp:409]     Test net output #1: loss = 0.350038 (* 1 = 0.350038 loss)
I0522 05:21:00.532230 12754 solver.cpp:237] Iteration 180000, loss = 0.676045
I0522 05:21:00.532285 12754 solver.cpp:253]     Train net output #0: loss = 0.676042 (* 1 = 0.676042 loss)
I0522 05:21:00.532300 12754 sgd_solver.cpp:106] Iteration 180000, lr = 0.0045
I0522 05:21:12.680670 12754 solver.cpp:237] Iteration 180750, loss = 0.454343
I0522 05:21:12.680851 12754 solver.cpp:253]     Train net output #0: loss = 0.45434 (* 1 = 0.45434 loss)
I0522 05:21:12.680866 12754 sgd_solver.cpp:106] Iteration 180750, lr = 0.0045
I0522 05:21:24.823254 12754 solver.cpp:237] Iteration 181500, loss = 1.06902
I0522 05:21:24.823300 12754 solver.cpp:253]     Train net output #0: loss = 1.06902 (* 1 = 1.06902 loss)
I0522 05:21:24.823315 12754 sgd_solver.cpp:106] Iteration 181500, lr = 0.0045
I0522 05:21:36.945060 12754 solver.cpp:237] Iteration 182250, loss = 1.67142
I0522 05:21:36.945096 12754 solver.cpp:253]     Train net output #0: loss = 1.67142 (* 1 = 1.67142 loss)
I0522 05:21:36.945112 12754 sgd_solver.cpp:106] Iteration 182250, lr = 0.0045
I0522 05:21:49.003279 12754 solver.cpp:237] Iteration 183000, loss = 1.06977
I0522 05:21:49.003448 12754 solver.cpp:253]     Train net output #0: loss = 1.06976 (* 1 = 1.06976 loss)
I0522 05:21:49.003463 12754 sgd_solver.cpp:106] Iteration 183000, lr = 0.0045
I0522 05:22:01.066910 12754 solver.cpp:237] Iteration 183750, loss = 1.1839
I0522 05:22:01.066947 12754 solver.cpp:253]     Train net output #0: loss = 1.1839 (* 1 = 1.1839 loss)
I0522 05:22:01.066962 12754 sgd_solver.cpp:106] Iteration 183750, lr = 0.0045
I0522 05:22:13.190060 12754 solver.cpp:237] Iteration 184500, loss = 1.35473
I0522 05:22:13.190104 12754 solver.cpp:253]     Train net output #0: loss = 1.35472 (* 1 = 1.35472 loss)
I0522 05:22:13.190119 12754 sgd_solver.cpp:106] Iteration 184500, lr = 0.0045
I0522 05:22:46.123391 12754 solver.cpp:237] Iteration 185250, loss = 1.50316
I0522 05:22:46.123582 12754 solver.cpp:253]     Train net output #0: loss = 1.50315 (* 1 = 1.50315 loss)
I0522 05:22:46.123597 12754 sgd_solver.cpp:106] Iteration 185250, lr = 0.0045
I0522 05:22:58.209200 12754 solver.cpp:237] Iteration 186000, loss = 1.17411
I0522 05:22:58.209238 12754 solver.cpp:253]     Train net output #0: loss = 1.17411 (* 1 = 1.17411 loss)
I0522 05:22:58.209251 12754 sgd_solver.cpp:106] Iteration 186000, lr = 0.0045
I0522 05:23:10.291375 12754 solver.cpp:237] Iteration 186750, loss = 1.14593
I0522 05:23:10.291424 12754 solver.cpp:253]     Train net output #0: loss = 1.14593 (* 1 = 1.14593 loss)
I0522 05:23:10.291438 12754 sgd_solver.cpp:106] Iteration 186750, lr = 0.0045
I0522 05:23:22.420820 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_187500.caffemodel
I0522 05:23:22.472889 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_187500.solverstate
I0522 05:23:22.505735 12754 solver.cpp:237] Iteration 187500, loss = 0.77856
I0522 05:23:22.505786 12754 solver.cpp:253]     Train net output #0: loss = 0.778556 (* 1 = 0.778556 loss)
I0522 05:23:22.505801 12754 sgd_solver.cpp:106] Iteration 187500, lr = 0.0045
I0522 05:23:34.622421 12754 solver.cpp:237] Iteration 188250, loss = 1.03398
I0522 05:23:34.622465 12754 solver.cpp:253]     Train net output #0: loss = 1.03398 (* 1 = 1.03398 loss)
I0522 05:23:34.622479 12754 sgd_solver.cpp:106] Iteration 188250, lr = 0.0045
I0522 05:23:46.700181 12754 solver.cpp:237] Iteration 189000, loss = 1.24938
I0522 05:23:46.700217 12754 solver.cpp:253]     Train net output #0: loss = 1.24938 (* 1 = 1.24938 loss)
I0522 05:23:46.700232 12754 sgd_solver.cpp:106] Iteration 189000, lr = 0.0045
I0522 05:23:58.742436 12754 solver.cpp:237] Iteration 189750, loss = 0.989731
I0522 05:23:58.742616 12754 solver.cpp:253]     Train net output #0: loss = 0.989727 (* 1 = 0.989727 loss)
I0522 05:23:58.742631 12754 sgd_solver.cpp:106] Iteration 189750, lr = 0.0045
I0522 05:24:31.640895 12754 solver.cpp:237] Iteration 190500, loss = 1.36795
I0522 05:24:31.641083 12754 solver.cpp:253]     Train net output #0: loss = 1.36795 (* 1 = 1.36795 loss)
I0522 05:24:31.641096 12754 sgd_solver.cpp:106] Iteration 190500, lr = 0.0045
I0522 05:24:43.732447 12754 solver.cpp:237] Iteration 191250, loss = 1.02699
I0522 05:24:43.732494 12754 solver.cpp:253]     Train net output #0: loss = 1.02699 (* 1 = 1.02699 loss)
I0522 05:24:43.732508 12754 sgd_solver.cpp:106] Iteration 191250, lr = 0.0045
I0522 05:24:55.824399 12754 solver.cpp:237] Iteration 192000, loss = 1.56788
I0522 05:24:55.824435 12754 solver.cpp:253]     Train net output #0: loss = 1.56787 (* 1 = 1.56787 loss)
I0522 05:24:55.824450 12754 sgd_solver.cpp:106] Iteration 192000, lr = 0.0045
I0522 05:25:07.867682 12754 solver.cpp:237] Iteration 192750, loss = 1.38397
I0522 05:25:07.867854 12754 solver.cpp:253]     Train net output #0: loss = 1.38397 (* 1 = 1.38397 loss)
I0522 05:25:07.867869 12754 sgd_solver.cpp:106] Iteration 192750, lr = 0.0045
I0522 05:25:19.910449 12754 solver.cpp:237] Iteration 193500, loss = 0.98008
I0522 05:25:19.910486 12754 solver.cpp:253]     Train net output #0: loss = 0.980077 (* 1 = 0.980077 loss)
I0522 05:25:19.910501 12754 sgd_solver.cpp:106] Iteration 193500, lr = 0.0045
I0522 05:25:31.950996 12754 solver.cpp:237] Iteration 194250, loss = 0.95713
I0522 05:25:31.951045 12754 solver.cpp:253]     Train net output #0: loss = 0.957127 (* 1 = 0.957127 loss)
I0522 05:25:31.951061 12754 sgd_solver.cpp:106] Iteration 194250, lr = 0.0045
I0522 05:25:44.034879 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_195000.caffemodel
I0522 05:25:44.084328 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_195000.solverstate
I0522 05:25:44.109484 12754 solver.cpp:341] Iteration 195000, Testing net (#0)
I0522 05:26:35.997056 12754 solver.cpp:409]     Test net output #0: accuracy = 0.891722
I0522 05:26:35.997230 12754 solver.cpp:409]     Test net output #1: loss = 0.373356 (* 1 = 0.373356 loss)
I0522 05:26:56.820255 12754 solver.cpp:237] Iteration 195000, loss = 0.940231
I0522 05:26:56.820307 12754 solver.cpp:253]     Train net output #0: loss = 0.940228 (* 1 = 0.940228 loss)
I0522 05:26:56.820323 12754 sgd_solver.cpp:106] Iteration 195000, lr = 0.0045
I0522 05:27:08.985232 12754 solver.cpp:237] Iteration 195750, loss = 0.794901
I0522 05:27:08.985411 12754 solver.cpp:253]     Train net output #0: loss = 0.794897 (* 1 = 0.794897 loss)
I0522 05:27:08.985426 12754 sgd_solver.cpp:106] Iteration 195750, lr = 0.0045
I0522 05:27:21.073024 12754 solver.cpp:237] Iteration 196500, loss = 1.3222
I0522 05:27:21.073067 12754 solver.cpp:253]     Train net output #0: loss = 1.32219 (* 1 = 1.32219 loss)
I0522 05:27:21.073081 12754 sgd_solver.cpp:106] Iteration 196500, lr = 0.0045
I0522 05:27:33.137034 12754 solver.cpp:237] Iteration 197250, loss = 0.846557
I0522 05:27:33.137071 12754 solver.cpp:253]     Train net output #0: loss = 0.846554 (* 1 = 0.846554 loss)
I0522 05:27:33.137085 12754 sgd_solver.cpp:106] Iteration 197250, lr = 0.0045
I0522 05:27:45.244642 12754 solver.cpp:237] Iteration 198000, loss = 0.793509
I0522 05:27:45.244822 12754 solver.cpp:253]     Train net output #0: loss = 0.793505 (* 1 = 0.793505 loss)
I0522 05:27:45.244837 12754 sgd_solver.cpp:106] Iteration 198000, lr = 0.0045
I0522 05:27:57.386243 12754 solver.cpp:237] Iteration 198750, loss = 1.23401
I0522 05:27:57.386281 12754 solver.cpp:253]     Train net output #0: loss = 1.234 (* 1 = 1.234 loss)
I0522 05:27:57.386294 12754 sgd_solver.cpp:106] Iteration 198750, lr = 0.0045
I0522 05:28:09.468504 12754 solver.cpp:237] Iteration 199500, loss = 1.0394
I0522 05:28:09.468554 12754 solver.cpp:253]     Train net output #0: loss = 1.0394 (* 1 = 1.0394 loss)
I0522 05:28:09.468569 12754 sgd_solver.cpp:106] Iteration 199500, lr = 0.0045
I0522 05:28:42.395311 12754 solver.cpp:237] Iteration 200250, loss = 1.19416
I0522 05:28:42.395495 12754 solver.cpp:253]     Train net output #0: loss = 1.19416 (* 1 = 1.19416 loss)
I0522 05:28:42.395512 12754 sgd_solver.cpp:106] Iteration 200250, lr = 0.0045
I0522 05:28:54.503592 12754 solver.cpp:237] Iteration 201000, loss = 0.799368
I0522 05:28:54.503638 12754 solver.cpp:253]     Train net output #0: loss = 0.799364 (* 1 = 0.799364 loss)
I0522 05:28:54.503653 12754 sgd_solver.cpp:106] Iteration 201000, lr = 0.0045
I0522 05:29:06.621263 12754 solver.cpp:237] Iteration 201750, loss = 1.4604
I0522 05:29:06.621299 12754 solver.cpp:253]     Train net output #0: loss = 1.46039 (* 1 = 1.46039 loss)
I0522 05:29:06.621311 12754 sgd_solver.cpp:106] Iteration 201750, lr = 0.0045
I0522 05:29:18.725136 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_202500.caffemodel
I0522 05:29:18.774803 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_202500.solverstate
I0522 05:29:18.805104 12754 solver.cpp:237] Iteration 202500, loss = 0.980209
I0522 05:29:18.805150 12754 solver.cpp:253]     Train net output #0: loss = 0.980206 (* 1 = 0.980206 loss)
I0522 05:29:18.805165 12754 sgd_solver.cpp:106] Iteration 202500, lr = 0.0045
I0522 05:29:30.946822 12754 solver.cpp:237] Iteration 203250, loss = 0.937716
I0522 05:29:30.946861 12754 solver.cpp:253]     Train net output #0: loss = 0.937712 (* 1 = 0.937712 loss)
I0522 05:29:30.946874 12754 sgd_solver.cpp:106] Iteration 203250, lr = 0.0045
I0522 05:29:43.087116 12754 solver.cpp:237] Iteration 204000, loss = 0.979831
I0522 05:29:43.087162 12754 solver.cpp:253]     Train net output #0: loss = 0.979827 (* 1 = 0.979827 loss)
I0522 05:29:43.087175 12754 sgd_solver.cpp:106] Iteration 204000, lr = 0.0045
I0522 05:29:55.195843 12754 solver.cpp:237] Iteration 204750, loss = 0.743592
I0522 05:29:55.196022 12754 solver.cpp:253]     Train net output #0: loss = 0.743588 (* 1 = 0.743588 loss)
I0522 05:29:55.196036 12754 sgd_solver.cpp:106] Iteration 204750, lr = 0.0045
I0522 05:30:28.146037 12754 solver.cpp:237] Iteration 205500, loss = 1.22252
I0522 05:30:28.146231 12754 solver.cpp:253]     Train net output #0: loss = 1.22252 (* 1 = 1.22252 loss)
I0522 05:30:28.146245 12754 sgd_solver.cpp:106] Iteration 205500, lr = 0.0045
I0522 05:30:40.258287 12754 solver.cpp:237] Iteration 206250, loss = 2.33068
I0522 05:30:40.258328 12754 solver.cpp:253]     Train net output #0: loss = 2.33068 (* 1 = 2.33068 loss)
I0522 05:30:40.258342 12754 sgd_solver.cpp:106] Iteration 206250, lr = 0.0045
I0522 05:30:52.333048 12754 solver.cpp:237] Iteration 207000, loss = 1.38246
I0522 05:30:52.333084 12754 solver.cpp:253]     Train net output #0: loss = 1.38246 (* 1 = 1.38246 loss)
I0522 05:30:52.333098 12754 sgd_solver.cpp:106] Iteration 207000, lr = 0.0045
I0522 05:31:04.389678 12754 solver.cpp:237] Iteration 207750, loss = 0.703629
I0522 05:31:04.389853 12754 solver.cpp:253]     Train net output #0: loss = 0.703625 (* 1 = 0.703625 loss)
I0522 05:31:04.389868 12754 sgd_solver.cpp:106] Iteration 207750, lr = 0.0045
I0522 05:31:16.470036 12754 solver.cpp:237] Iteration 208500, loss = 1.12135
I0522 05:31:16.470072 12754 solver.cpp:253]     Train net output #0: loss = 1.12135 (* 1 = 1.12135 loss)
I0522 05:31:16.470088 12754 sgd_solver.cpp:106] Iteration 208500, lr = 0.0045
I0522 05:31:28.603159 12754 solver.cpp:237] Iteration 209250, loss = 0.824786
I0522 05:31:28.603207 12754 solver.cpp:253]     Train net output #0: loss = 0.824782 (* 1 = 0.824782 loss)
I0522 05:31:28.603222 12754 sgd_solver.cpp:106] Iteration 209250, lr = 0.0045
I0522 05:31:40.724916 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_210000.caffemodel
I0522 05:31:40.774036 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_210000.solverstate
I0522 05:31:40.799341 12754 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 05:32:53.652190 12754 solver.cpp:409]     Test net output #0: accuracy = 0.893211
I0522 05:32:53.652390 12754 solver.cpp:409]     Test net output #1: loss = 0.335402 (* 1 = 0.335402 loss)
I0522 05:33:14.500988 12754 solver.cpp:237] Iteration 210000, loss = 1.06064
I0522 05:33:14.501040 12754 solver.cpp:253]     Train net output #0: loss = 1.06064 (* 1 = 1.06064 loss)
I0522 05:33:14.501055 12754 sgd_solver.cpp:106] Iteration 210000, lr = 0.0045
I0522 05:33:26.673256 12754 solver.cpp:237] Iteration 210750, loss = 1.35103
I0522 05:33:26.673435 12754 solver.cpp:253]     Train net output #0: loss = 1.35103 (* 1 = 1.35103 loss)
I0522 05:33:26.673450 12754 sgd_solver.cpp:106] Iteration 210750, lr = 0.0045
I0522 05:33:38.766064 12754 solver.cpp:237] Iteration 211500, loss = 0.779205
I0522 05:33:38.766101 12754 solver.cpp:253]     Train net output #0: loss = 0.779201 (* 1 = 0.779201 loss)
I0522 05:33:38.766115 12754 sgd_solver.cpp:106] Iteration 211500, lr = 0.0045
I0522 05:33:50.867180 12754 solver.cpp:237] Iteration 212250, loss = 0.855484
I0522 05:33:50.867220 12754 solver.cpp:253]     Train net output #0: loss = 0.855481 (* 1 = 0.855481 loss)
I0522 05:33:50.867241 12754 sgd_solver.cpp:106] Iteration 212250, lr = 0.0045
I0522 05:34:02.960072 12754 solver.cpp:237] Iteration 213000, loss = 0.87651
I0522 05:34:02.960234 12754 solver.cpp:253]     Train net output #0: loss = 0.876507 (* 1 = 0.876507 loss)
I0522 05:34:02.960250 12754 sgd_solver.cpp:106] Iteration 213000, lr = 0.0045
I0522 05:34:15.053632 12754 solver.cpp:237] Iteration 213750, loss = 1.15041
I0522 05:34:15.053681 12754 solver.cpp:253]     Train net output #0: loss = 1.1504 (* 1 = 1.1504 loss)
I0522 05:34:15.053696 12754 sgd_solver.cpp:106] Iteration 213750, lr = 0.0045
I0522 05:34:27.173352 12754 solver.cpp:237] Iteration 214500, loss = 1.08891
I0522 05:34:27.173388 12754 solver.cpp:253]     Train net output #0: loss = 1.0889 (* 1 = 1.0889 loss)
I0522 05:34:27.173401 12754 sgd_solver.cpp:106] Iteration 214500, lr = 0.0045
I0522 05:35:00.133441 12754 solver.cpp:237] Iteration 215250, loss = 1.24069
I0522 05:35:00.133640 12754 solver.cpp:253]     Train net output #0: loss = 1.24068 (* 1 = 1.24068 loss)
I0522 05:35:00.133656 12754 sgd_solver.cpp:106] Iteration 215250, lr = 0.0045
I0522 05:35:12.221144 12754 solver.cpp:237] Iteration 216000, loss = 0.6362
I0522 05:35:12.221190 12754 solver.cpp:253]     Train net output #0: loss = 0.636196 (* 1 = 0.636196 loss)
I0522 05:35:12.221205 12754 sgd_solver.cpp:106] Iteration 216000, lr = 0.0045
I0522 05:35:24.333536 12754 solver.cpp:237] Iteration 216750, loss = 1.12669
I0522 05:35:24.333572 12754 solver.cpp:253]     Train net output #0: loss = 1.12669 (* 1 = 1.12669 loss)
I0522 05:35:24.333587 12754 sgd_solver.cpp:106] Iteration 216750, lr = 0.0045
I0522 05:35:36.455016 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_217500.caffemodel
I0522 05:35:36.506791 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_217500.solverstate
I0522 05:35:36.539825 12754 solver.cpp:237] Iteration 217500, loss = 1.65462
I0522 05:35:36.539875 12754 solver.cpp:253]     Train net output #0: loss = 1.65462 (* 1 = 1.65462 loss)
I0522 05:35:36.539891 12754 sgd_solver.cpp:106] Iteration 217500, lr = 0.0045
I0522 05:35:48.620990 12754 solver.cpp:237] Iteration 218250, loss = 1.1121
I0522 05:35:48.621027 12754 solver.cpp:253]     Train net output #0: loss = 1.1121 (* 1 = 1.1121 loss)
I0522 05:35:48.621040 12754 sgd_solver.cpp:106] Iteration 218250, lr = 0.0045
I0522 05:36:00.717207 12754 solver.cpp:237] Iteration 219000, loss = 1.96405
I0522 05:36:00.717257 12754 solver.cpp:253]     Train net output #0: loss = 1.96404 (* 1 = 1.96404 loss)
I0522 05:36:00.717270 12754 sgd_solver.cpp:106] Iteration 219000, lr = 0.0045
I0522 05:36:12.812414 12754 solver.cpp:237] Iteration 219750, loss = 0.883111
I0522 05:36:12.812582 12754 solver.cpp:253]     Train net output #0: loss = 0.883108 (* 1 = 0.883108 loss)
I0522 05:36:12.812595 12754 sgd_solver.cpp:106] Iteration 219750, lr = 0.0045
I0522 05:36:45.749133 12754 solver.cpp:237] Iteration 220500, loss = 1.25461
I0522 05:36:45.749308 12754 solver.cpp:253]     Train net output #0: loss = 1.25461 (* 1 = 1.25461 loss)
I0522 05:36:45.749323 12754 sgd_solver.cpp:106] Iteration 220500, lr = 0.0045
I0522 05:36:57.842830 12754 solver.cpp:237] Iteration 221250, loss = 1.37981
I0522 05:36:57.842865 12754 solver.cpp:253]     Train net output #0: loss = 1.3798 (* 1 = 1.3798 loss)
I0522 05:36:57.842880 12754 sgd_solver.cpp:106] Iteration 221250, lr = 0.0045
I0522 05:37:09.948541 12754 solver.cpp:237] Iteration 222000, loss = 1.16192
I0522 05:37:09.948586 12754 solver.cpp:253]     Train net output #0: loss = 1.16192 (* 1 = 1.16192 loss)
I0522 05:37:09.948603 12754 sgd_solver.cpp:106] Iteration 222000, lr = 0.0045
I0522 05:37:22.044420 12754 solver.cpp:237] Iteration 222750, loss = 1.04997
I0522 05:37:22.044585 12754 solver.cpp:253]     Train net output #0: loss = 1.04996 (* 1 = 1.04996 loss)
I0522 05:37:22.044600 12754 sgd_solver.cpp:106] Iteration 222750, lr = 0.0045
I0522 05:37:34.147748 12754 solver.cpp:237] Iteration 223500, loss = 1.40574
I0522 05:37:34.147784 12754 solver.cpp:253]     Train net output #0: loss = 1.40573 (* 1 = 1.40573 loss)
I0522 05:37:34.147799 12754 sgd_solver.cpp:106] Iteration 223500, lr = 0.0045
I0522 05:37:46.288282 12754 solver.cpp:237] Iteration 224250, loss = 1.19461
I0522 05:37:46.288323 12754 solver.cpp:253]     Train net output #0: loss = 1.19461 (* 1 = 1.19461 loss)
I0522 05:37:46.288337 12754 sgd_solver.cpp:106] Iteration 224250, lr = 0.0045
I0522 05:37:58.375372 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_225000.caffemodel
I0522 05:37:58.427358 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_225000.solverstate
I0522 05:37:58.455957 12754 solver.cpp:341] Iteration 225000, Testing net (#0)
I0522 05:38:50.110379 12754 solver.cpp:409]     Test net output #0: accuracy = 0.89327
I0522 05:38:50.110566 12754 solver.cpp:409]     Test net output #1: loss = 0.337432 (* 1 = 0.337432 loss)
I0522 05:39:10.963064 12754 solver.cpp:237] Iteration 225000, loss = 1.26692
I0522 05:39:10.963117 12754 solver.cpp:253]     Train net output #0: loss = 1.26692 (* 1 = 1.26692 loss)
I0522 05:39:10.963134 12754 sgd_solver.cpp:106] Iteration 225000, lr = 0.0045
I0522 05:39:23.150293 12754 solver.cpp:237] Iteration 225750, loss = 0.755231
I0522 05:39:23.150476 12754 solver.cpp:253]     Train net output #0: loss = 0.755228 (* 1 = 0.755228 loss)
I0522 05:39:23.150493 12754 sgd_solver.cpp:106] Iteration 225750, lr = 0.0045
I0522 05:39:35.359423 12754 solver.cpp:237] Iteration 226500, loss = 1.17557
I0522 05:39:35.359460 12754 solver.cpp:253]     Train net output #0: loss = 1.17557 (* 1 = 1.17557 loss)
I0522 05:39:35.359473 12754 sgd_solver.cpp:106] Iteration 226500, lr = 0.0045
I0522 05:39:47.493336 12754 solver.cpp:237] Iteration 227250, loss = 1.14843
I0522 05:39:47.493387 12754 solver.cpp:253]     Train net output #0: loss = 1.14842 (* 1 = 1.14842 loss)
I0522 05:39:47.493402 12754 sgd_solver.cpp:106] Iteration 227250, lr = 0.0045
I0522 05:39:59.649327 12754 solver.cpp:237] Iteration 228000, loss = 0.568715
I0522 05:39:59.649494 12754 solver.cpp:253]     Train net output #0: loss = 0.568711 (* 1 = 0.568711 loss)
I0522 05:39:59.649507 12754 sgd_solver.cpp:106] Iteration 228000, lr = 0.0045
I0522 05:40:11.805963 12754 solver.cpp:237] Iteration 228750, loss = 1.28715
I0522 05:40:11.806005 12754 solver.cpp:253]     Train net output #0: loss = 1.28715 (* 1 = 1.28715 loss)
I0522 05:40:11.806020 12754 sgd_solver.cpp:106] Iteration 228750, lr = 0.0045
I0522 05:40:23.975951 12754 solver.cpp:237] Iteration 229500, loss = 1.49711
I0522 05:40:23.975987 12754 solver.cpp:253]     Train net output #0: loss = 1.49711 (* 1 = 1.49711 loss)
I0522 05:40:23.976001 12754 sgd_solver.cpp:106] Iteration 229500, lr = 0.0045
I0522 05:40:57.031628 12754 solver.cpp:237] Iteration 230250, loss = 1.31862
I0522 05:40:57.031815 12754 solver.cpp:253]     Train net output #0: loss = 1.31862 (* 1 = 1.31862 loss)
I0522 05:40:57.031829 12754 sgd_solver.cpp:106] Iteration 230250, lr = 0.0045
I0522 05:41:09.216337 12754 solver.cpp:237] Iteration 231000, loss = 1.12374
I0522 05:41:09.216373 12754 solver.cpp:253]     Train net output #0: loss = 1.12374 (* 1 = 1.12374 loss)
I0522 05:41:09.216387 12754 sgd_solver.cpp:106] Iteration 231000, lr = 0.0045
I0522 05:41:21.381253 12754 solver.cpp:237] Iteration 231750, loss = 1.93759
I0522 05:41:21.381297 12754 solver.cpp:253]     Train net output #0: loss = 1.93759 (* 1 = 1.93759 loss)
I0522 05:41:21.381315 12754 sgd_solver.cpp:106] Iteration 231750, lr = 0.0045
I0522 05:41:33.533171 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_232500.caffemodel
I0522 05:41:33.582238 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_232500.solverstate
I0522 05:41:33.612843 12754 solver.cpp:237] Iteration 232500, loss = 0.777884
I0522 05:41:33.612890 12754 solver.cpp:253]     Train net output #0: loss = 0.777879 (* 1 = 0.777879 loss)
I0522 05:41:33.612905 12754 sgd_solver.cpp:106] Iteration 232500, lr = 0.0045
I0522 05:41:45.794047 12754 solver.cpp:237] Iteration 233250, loss = 1.24102
I0522 05:41:45.794096 12754 solver.cpp:253]     Train net output #0: loss = 1.24102 (* 1 = 1.24102 loss)
I0522 05:41:45.794111 12754 sgd_solver.cpp:106] Iteration 233250, lr = 0.0045
I0522 05:41:58.001148 12754 solver.cpp:237] Iteration 234000, loss = 0.919853
I0522 05:41:58.001186 12754 solver.cpp:253]     Train net output #0: loss = 0.919849 (* 1 = 0.919849 loss)
I0522 05:41:58.001200 12754 sgd_solver.cpp:106] Iteration 234000, lr = 0.0045
I0522 05:42:10.167551 12754 solver.cpp:237] Iteration 234750, loss = 1.17297
I0522 05:42:10.167748 12754 solver.cpp:253]     Train net output #0: loss = 1.17297 (* 1 = 1.17297 loss)
I0522 05:42:10.167762 12754 sgd_solver.cpp:106] Iteration 234750, lr = 0.0045
I0522 05:42:43.161337 12754 solver.cpp:237] Iteration 235500, loss = 1.2253
I0522 05:42:43.161526 12754 solver.cpp:253]     Train net output #0: loss = 1.2253 (* 1 = 1.2253 loss)
I0522 05:42:43.161541 12754 sgd_solver.cpp:106] Iteration 235500, lr = 0.0045
I0522 05:42:55.290119 12754 solver.cpp:237] Iteration 236250, loss = 0.876042
I0522 05:42:55.290156 12754 solver.cpp:253]     Train net output #0: loss = 0.876038 (* 1 = 0.876038 loss)
I0522 05:42:55.290171 12754 sgd_solver.cpp:106] Iteration 236250, lr = 0.0045
I0522 05:43:07.425987 12754 solver.cpp:237] Iteration 237000, loss = 1.20622
I0522 05:43:07.426038 12754 solver.cpp:253]     Train net output #0: loss = 1.20622 (* 1 = 1.20622 loss)
I0522 05:43:07.426051 12754 sgd_solver.cpp:106] Iteration 237000, lr = 0.0045
I0522 05:43:19.579906 12754 solver.cpp:237] Iteration 237750, loss = 1.11029
I0522 05:43:19.580078 12754 solver.cpp:253]     Train net output #0: loss = 1.11028 (* 1 = 1.11028 loss)
I0522 05:43:19.580092 12754 sgd_solver.cpp:106] Iteration 237750, lr = 0.0045
I0522 05:43:31.717226 12754 solver.cpp:237] Iteration 238500, loss = 1.31812
I0522 05:43:31.717272 12754 solver.cpp:253]     Train net output #0: loss = 1.31812 (* 1 = 1.31812 loss)
I0522 05:43:31.717285 12754 sgd_solver.cpp:106] Iteration 238500, lr = 0.0045
I0522 05:43:43.919667 12754 solver.cpp:237] Iteration 239250, loss = 1.48913
I0522 05:43:43.919703 12754 solver.cpp:253]     Train net output #0: loss = 1.48912 (* 1 = 1.48912 loss)
I0522 05:43:43.919718 12754 sgd_solver.cpp:106] Iteration 239250, lr = 0.0045
I0522 05:43:56.112890 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_240000.caffemodel
I0522 05:43:56.162742 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_240000.solverstate
I0522 05:43:56.188117 12754 solver.cpp:341] Iteration 240000, Testing net (#0)
I0522 05:45:08.967694 12754 solver.cpp:409]     Test net output #0: accuracy = 0.896124
I0522 05:45:08.967876 12754 solver.cpp:409]     Test net output #1: loss = 0.319101 (* 1 = 0.319101 loss)
I0522 05:45:29.850765 12754 solver.cpp:237] Iteration 240000, loss = 1.44801
I0522 05:45:29.850819 12754 solver.cpp:253]     Train net output #0: loss = 1.448 (* 1 = 1.448 loss)
I0522 05:45:29.850837 12754 sgd_solver.cpp:106] Iteration 240000, lr = 0.0045
I0522 05:45:42.078722 12754 solver.cpp:237] Iteration 240750, loss = 1.14172
I0522 05:45:42.078893 12754 solver.cpp:253]     Train net output #0: loss = 1.14172 (* 1 = 1.14172 loss)
I0522 05:45:42.078907 12754 sgd_solver.cpp:106] Iteration 240750, lr = 0.0045
I0522 05:45:54.292870 12754 solver.cpp:237] Iteration 241500, loss = 0.835507
I0522 05:45:54.292906 12754 solver.cpp:253]     Train net output #0: loss = 0.835503 (* 1 = 0.835503 loss)
I0522 05:45:54.292927 12754 sgd_solver.cpp:106] Iteration 241500, lr = 0.0045
I0522 05:46:06.512058 12754 solver.cpp:237] Iteration 242250, loss = 1.22556
I0522 05:46:06.512107 12754 solver.cpp:253]     Train net output #0: loss = 1.22556 (* 1 = 1.22556 loss)
I0522 05:46:06.512120 12754 sgd_solver.cpp:106] Iteration 242250, lr = 0.0045
I0522 05:46:18.675976 12754 solver.cpp:237] Iteration 243000, loss = 0.938887
I0522 05:46:18.676156 12754 solver.cpp:253]     Train net output #0: loss = 0.938883 (* 1 = 0.938883 loss)
I0522 05:46:18.676169 12754 sgd_solver.cpp:106] Iteration 243000, lr = 0.0045
I0522 05:46:30.828331 12754 solver.cpp:237] Iteration 243750, loss = 0.967018
I0522 05:46:30.828383 12754 solver.cpp:253]     Train net output #0: loss = 0.967014 (* 1 = 0.967014 loss)
I0522 05:46:30.828398 12754 sgd_solver.cpp:106] Iteration 243750, lr = 0.0045
I0522 05:46:43.035899 12754 solver.cpp:237] Iteration 244500, loss = 1.13176
I0522 05:46:43.035936 12754 solver.cpp:253]     Train net output #0: loss = 1.13175 (* 1 = 1.13175 loss)
I0522 05:46:43.035951 12754 sgd_solver.cpp:106] Iteration 244500, lr = 0.0045
I0522 05:47:16.145777 12754 solver.cpp:237] Iteration 245250, loss = 1.35864
I0522 05:47:16.145963 12754 solver.cpp:253]     Train net output #0: loss = 1.35864 (* 1 = 1.35864 loss)
I0522 05:47:16.145978 12754 sgd_solver.cpp:106] Iteration 245250, lr = 0.0045
I0522 05:47:28.389950 12754 solver.cpp:237] Iteration 246000, loss = 1.16419
I0522 05:47:28.389986 12754 solver.cpp:253]     Train net output #0: loss = 1.16419 (* 1 = 1.16419 loss)
I0522 05:47:28.390000 12754 sgd_solver.cpp:106] Iteration 246000, lr = 0.0045
I0522 05:47:40.612165 12754 solver.cpp:237] Iteration 246750, loss = 1.31899
I0522 05:47:40.612213 12754 solver.cpp:253]     Train net output #0: loss = 1.31899 (* 1 = 1.31899 loss)
I0522 05:47:40.612227 12754 sgd_solver.cpp:106] Iteration 246750, lr = 0.0045
I0522 05:47:52.771205 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_247500.caffemodel
I0522 05:47:52.820487 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_247500.solverstate
I0522 05:47:52.850247 12754 solver.cpp:237] Iteration 247500, loss = 0.958659
I0522 05:47:52.850294 12754 solver.cpp:253]     Train net output #0: loss = 0.958655 (* 1 = 0.958655 loss)
I0522 05:47:52.850311 12754 sgd_solver.cpp:106] Iteration 247500, lr = 0.0045
I0522 05:48:05.036217 12754 solver.cpp:237] Iteration 248250, loss = 0.869722
I0522 05:48:05.036265 12754 solver.cpp:253]     Train net output #0: loss = 0.869718 (* 1 = 0.869718 loss)
I0522 05:48:05.036279 12754 sgd_solver.cpp:106] Iteration 248250, lr = 0.0045
I0522 05:48:17.255612 12754 solver.cpp:237] Iteration 249000, loss = 0.983084
I0522 05:48:17.255650 12754 solver.cpp:253]     Train net output #0: loss = 0.98308 (* 1 = 0.98308 loss)
I0522 05:48:17.255663 12754 sgd_solver.cpp:106] Iteration 249000, lr = 0.0045
I0522 05:48:29.479403 12754 solver.cpp:237] Iteration 249750, loss = 1.452
I0522 05:48:29.479588 12754 solver.cpp:253]     Train net output #0: loss = 1.45199 (* 1 = 1.45199 loss)
I0522 05:48:29.479604 12754 sgd_solver.cpp:106] Iteration 249750, lr = 0.0045
I0522 05:49:02.583003 12754 solver.cpp:237] Iteration 250500, loss = 1.00556
I0522 05:49:02.583192 12754 solver.cpp:253]     Train net output #0: loss = 1.00555 (* 1 = 1.00555 loss)
I0522 05:49:02.583206 12754 sgd_solver.cpp:106] Iteration 250500, lr = 0.0045
I0522 05:49:14.835324 12754 solver.cpp:237] Iteration 251250, loss = 1.84879
I0522 05:49:14.835367 12754 solver.cpp:253]     Train net output #0: loss = 1.84878 (* 1 = 1.84878 loss)
I0522 05:49:14.835384 12754 sgd_solver.cpp:106] Iteration 251250, lr = 0.0045
I0522 05:49:27.034152 12754 solver.cpp:237] Iteration 252000, loss = 1.206
I0522 05:49:27.034188 12754 solver.cpp:253]     Train net output #0: loss = 1.20599 (* 1 = 1.20599 loss)
I0522 05:49:27.034203 12754 sgd_solver.cpp:106] Iteration 252000, lr = 0.0045
I0522 05:49:39.208041 12754 solver.cpp:237] Iteration 252750, loss = 1.10294
I0522 05:49:39.208220 12754 solver.cpp:253]     Train net output #0: loss = 1.10294 (* 1 = 1.10294 loss)
I0522 05:49:39.208235 12754 sgd_solver.cpp:106] Iteration 252750, lr = 0.0045
I0522 05:49:51.379256 12754 solver.cpp:237] Iteration 253500, loss = 1.45991
I0522 05:49:51.379303 12754 solver.cpp:253]     Train net output #0: loss = 1.45991 (* 1 = 1.45991 loss)
I0522 05:49:51.379317 12754 sgd_solver.cpp:106] Iteration 253500, lr = 0.0045
I0522 05:50:03.585000 12754 solver.cpp:237] Iteration 254250, loss = 0.92509
I0522 05:50:03.585036 12754 solver.cpp:253]     Train net output #0: loss = 0.925086 (* 1 = 0.925086 loss)
I0522 05:50:03.585052 12754 sgd_solver.cpp:106] Iteration 254250, lr = 0.0045
I0522 05:50:15.775605 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_255000.caffemodel
I0522 05:50:15.826020 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_255000.solverstate
I0522 05:50:15.851156 12754 solver.cpp:341] Iteration 255000, Testing net (#0)
I0522 05:51:07.878825 12754 solver.cpp:409]     Test net output #0: accuracy = 0.89954
I0522 05:51:07.879012 12754 solver.cpp:409]     Test net output #1: loss = 0.34239 (* 1 = 0.34239 loss)
I0522 05:51:28.771792 12754 solver.cpp:237] Iteration 255000, loss = 0.926029
I0522 05:51:28.771845 12754 solver.cpp:253]     Train net output #0: loss = 0.926025 (* 1 = 0.926025 loss)
I0522 05:51:28.771860 12754 sgd_solver.cpp:106] Iteration 255000, lr = 0.0045
I0522 05:51:41.016537 12754 solver.cpp:237] Iteration 255750, loss = 1.27245
I0522 05:51:41.016710 12754 solver.cpp:253]     Train net output #0: loss = 1.27244 (* 1 = 1.27244 loss)
I0522 05:51:41.016723 12754 sgd_solver.cpp:106] Iteration 255750, lr = 0.0045
I0522 05:51:53.205660 12754 solver.cpp:237] Iteration 256500, loss = 0.644503
I0522 05:51:53.205710 12754 solver.cpp:253]     Train net output #0: loss = 0.644499 (* 1 = 0.644499 loss)
I0522 05:51:53.205724 12754 sgd_solver.cpp:106] Iteration 256500, lr = 0.0045
I0522 05:52:05.385208 12754 solver.cpp:237] Iteration 257250, loss = 1.13377
I0522 05:52:05.385244 12754 solver.cpp:253]     Train net output #0: loss = 1.13376 (* 1 = 1.13376 loss)
I0522 05:52:05.385258 12754 sgd_solver.cpp:106] Iteration 257250, lr = 0.0045
I0522 05:52:17.584898 12754 solver.cpp:237] Iteration 258000, loss = 0.849534
I0522 05:52:17.585089 12754 solver.cpp:253]     Train net output #0: loss = 0.84953 (* 1 = 0.84953 loss)
I0522 05:52:17.585105 12754 sgd_solver.cpp:106] Iteration 258000, lr = 0.0045
I0522 05:52:29.769428 12754 solver.cpp:237] Iteration 258750, loss = 1.23637
I0522 05:52:29.769464 12754 solver.cpp:253]     Train net output #0: loss = 1.23636 (* 1 = 1.23636 loss)
I0522 05:52:29.769479 12754 sgd_solver.cpp:106] Iteration 258750, lr = 0.0045
I0522 05:52:41.973431 12754 solver.cpp:237] Iteration 259500, loss = 0.955076
I0522 05:52:41.973482 12754 solver.cpp:253]     Train net output #0: loss = 0.955072 (* 1 = 0.955072 loss)
I0522 05:52:41.973496 12754 sgd_solver.cpp:106] Iteration 259500, lr = 0.0045
I0522 05:53:15.072173 12754 solver.cpp:237] Iteration 260250, loss = 1.26264
I0522 05:53:15.072363 12754 solver.cpp:253]     Train net output #0: loss = 1.26264 (* 1 = 1.26264 loss)
I0522 05:53:15.072377 12754 sgd_solver.cpp:106] Iteration 260250, lr = 0.0045
I0522 05:53:27.251808 12754 solver.cpp:237] Iteration 261000, loss = 1.30267
I0522 05:53:27.251857 12754 solver.cpp:253]     Train net output #0: loss = 1.30267 (* 1 = 1.30267 loss)
I0522 05:53:27.251873 12754 sgd_solver.cpp:106] Iteration 261000, lr = 0.0045
I0522 05:53:39.389688 12754 solver.cpp:237] Iteration 261750, loss = 1.07703
I0522 05:53:39.389724 12754 solver.cpp:253]     Train net output #0: loss = 1.07703 (* 1 = 1.07703 loss)
I0522 05:53:39.389737 12754 sgd_solver.cpp:106] Iteration 261750, lr = 0.0045
I0522 05:53:51.572762 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_262500.caffemodel
I0522 05:53:51.624042 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_262500.solverstate
I0522 05:53:51.656220 12754 solver.cpp:237] Iteration 262500, loss = 1.1496
I0522 05:53:51.656270 12754 solver.cpp:253]     Train net output #0: loss = 1.1496 (* 1 = 1.1496 loss)
I0522 05:53:51.656286 12754 sgd_solver.cpp:106] Iteration 262500, lr = 0.0045
I0522 05:54:03.829471 12754 solver.cpp:237] Iteration 263250, loss = 1.36196
I0522 05:54:03.829507 12754 solver.cpp:253]     Train net output #0: loss = 1.36196 (* 1 = 1.36196 loss)
I0522 05:54:03.829522 12754 sgd_solver.cpp:106] Iteration 263250, lr = 0.0045
I0522 05:54:15.989198 12754 solver.cpp:237] Iteration 264000, loss = 1.16854
I0522 05:54:15.989245 12754 solver.cpp:253]     Train net output #0: loss = 1.16853 (* 1 = 1.16853 loss)
I0522 05:54:15.989262 12754 sgd_solver.cpp:106] Iteration 264000, lr = 0.0045
I0522 05:54:28.159068 12754 solver.cpp:237] Iteration 264750, loss = 0.900182
I0522 05:54:28.159245 12754 solver.cpp:253]     Train net output #0: loss = 0.900177 (* 1 = 0.900177 loss)
I0522 05:54:28.159258 12754 sgd_solver.cpp:106] Iteration 264750, lr = 0.0045
I0522 05:55:01.206800 12754 solver.cpp:237] Iteration 265500, loss = 1.05942
I0522 05:55:01.206995 12754 solver.cpp:253]     Train net output #0: loss = 1.05941 (* 1 = 1.05941 loss)
I0522 05:55:01.207010 12754 sgd_solver.cpp:106] Iteration 265500, lr = 0.0045
I0522 05:55:13.379966 12754 solver.cpp:237] Iteration 266250, loss = 0.901836
I0522 05:55:13.380013 12754 solver.cpp:253]     Train net output #0: loss = 0.901832 (* 1 = 0.901832 loss)
I0522 05:55:13.380028 12754 sgd_solver.cpp:106] Iteration 266250, lr = 0.0045
I0522 05:55:25.556187 12754 solver.cpp:237] Iteration 267000, loss = 1.69135
I0522 05:55:25.556223 12754 solver.cpp:253]     Train net output #0: loss = 1.69134 (* 1 = 1.69134 loss)
I0522 05:55:25.556238 12754 sgd_solver.cpp:106] Iteration 267000, lr = 0.0045
I0522 05:55:37.738193 12754 solver.cpp:237] Iteration 267750, loss = 1.31309
I0522 05:55:37.738374 12754 solver.cpp:253]     Train net output #0: loss = 1.31309 (* 1 = 1.31309 loss)
I0522 05:55:37.738387 12754 sgd_solver.cpp:106] Iteration 267750, lr = 0.0045
I0522 05:55:49.931345 12754 solver.cpp:237] Iteration 268500, loss = 1.00371
I0522 05:55:49.931381 12754 solver.cpp:253]     Train net output #0: loss = 1.0037 (* 1 = 1.0037 loss)
I0522 05:55:49.931396 12754 sgd_solver.cpp:106] Iteration 268500, lr = 0.0045
I0522 05:56:02.137646 12754 solver.cpp:237] Iteration 269250, loss = 0.832224
I0522 05:56:02.137696 12754 solver.cpp:253]     Train net output #0: loss = 0.83222 (* 1 = 0.83222 loss)
I0522 05:56:02.137711 12754 sgd_solver.cpp:106] Iteration 269250, lr = 0.0045
I0522 05:56:14.338927 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_270000.caffemodel
I0522 05:56:14.390486 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_270000.solverstate
I0522 05:56:14.418748 12754 solver.cpp:341] Iteration 270000, Testing net (#0)
I0522 05:57:27.310299 12754 solver.cpp:409]     Test net output #0: accuracy = 0.896286
I0522 05:57:27.310492 12754 solver.cpp:409]     Test net output #1: loss = 0.341191 (* 1 = 0.341191 loss)
I0522 05:57:48.189404 12754 solver.cpp:237] Iteration 270000, loss = 1.30436
I0522 05:57:48.189456 12754 solver.cpp:253]     Train net output #0: loss = 1.30435 (* 1 = 1.30435 loss)
I0522 05:57:48.189471 12754 sgd_solver.cpp:106] Iteration 270000, lr = 0.0045
I0522 05:58:00.366122 12754 solver.cpp:237] Iteration 270750, loss = 0.952238
I0522 05:58:00.366318 12754 solver.cpp:253]     Train net output #0: loss = 0.952234 (* 1 = 0.952234 loss)
I0522 05:58:00.366333 12754 sgd_solver.cpp:106] Iteration 270750, lr = 0.0045
I0522 05:58:12.519312 12754 solver.cpp:237] Iteration 271500, loss = 1.4452
I0522 05:58:12.519350 12754 solver.cpp:253]     Train net output #0: loss = 1.4452 (* 1 = 1.4452 loss)
I0522 05:58:12.519363 12754 sgd_solver.cpp:106] Iteration 271500, lr = 0.0045
I0522 05:58:24.639850 12754 solver.cpp:237] Iteration 272250, loss = 1.19568
I0522 05:58:24.639886 12754 solver.cpp:253]     Train net output #0: loss = 1.19568 (* 1 = 1.19568 loss)
I0522 05:58:24.639899 12754 sgd_solver.cpp:106] Iteration 272250, lr = 0.0045
I0522 05:58:36.762418 12754 solver.cpp:237] Iteration 273000, loss = 1.18016
I0522 05:58:36.762598 12754 solver.cpp:253]     Train net output #0: loss = 1.18015 (* 1 = 1.18015 loss)
I0522 05:58:36.762611 12754 sgd_solver.cpp:106] Iteration 273000, lr = 0.0045
I0522 05:58:48.878386 12754 solver.cpp:237] Iteration 273750, loss = 0.999507
I0522 05:58:48.878424 12754 solver.cpp:253]     Train net output #0: loss = 0.999504 (* 1 = 0.999504 loss)
I0522 05:58:48.878438 12754 sgd_solver.cpp:106] Iteration 273750, lr = 0.0045
I0522 05:59:01.000324 12754 solver.cpp:237] Iteration 274500, loss = 0.705717
I0522 05:59:01.000368 12754 solver.cpp:253]     Train net output #0: loss = 0.705713 (* 1 = 0.705713 loss)
I0522 05:59:01.000382 12754 sgd_solver.cpp:106] Iteration 274500, lr = 0.0045
I0522 05:59:33.959616 12754 solver.cpp:237] Iteration 275250, loss = 0.767029
I0522 05:59:33.959807 12754 solver.cpp:253]     Train net output #0: loss = 0.767025 (* 1 = 0.767025 loss)
I0522 05:59:33.959821 12754 sgd_solver.cpp:106] Iteration 275250, lr = 0.0045
I0522 05:59:46.044221 12754 solver.cpp:237] Iteration 276000, loss = 1.05894
I0522 05:59:46.044266 12754 solver.cpp:253]     Train net output #0: loss = 1.05894 (* 1 = 1.05894 loss)
I0522 05:59:46.044281 12754 sgd_solver.cpp:106] Iteration 276000, lr = 0.0045
I0522 05:59:58.146280 12754 solver.cpp:237] Iteration 276750, loss = 1.31293
I0522 05:59:58.146317 12754 solver.cpp:253]     Train net output #0: loss = 1.31293 (* 1 = 1.31293 loss)
I0522 05:59:58.146332 12754 sgd_solver.cpp:106] Iteration 276750, lr = 0.0045
I0522 06:00:10.250546 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_277500.caffemodel
I0522 06:00:10.300000 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_277500.solverstate
I0522 06:00:10.330776 12754 solver.cpp:237] Iteration 277500, loss = 0.986492
I0522 06:00:10.330821 12754 solver.cpp:253]     Train net output #0: loss = 0.986489 (* 1 = 0.986489 loss)
I0522 06:00:10.330834 12754 sgd_solver.cpp:106] Iteration 277500, lr = 0.0045
I0522 06:00:22.470530 12754 solver.cpp:237] Iteration 278250, loss = 1.33004
I0522 06:00:22.470566 12754 solver.cpp:253]     Train net output #0: loss = 1.33004 (* 1 = 1.33004 loss)
I0522 06:00:22.470580 12754 sgd_solver.cpp:106] Iteration 278250, lr = 0.0045
I0522 06:00:34.627501 12754 solver.cpp:237] Iteration 279000, loss = 1.30512
I0522 06:00:34.627547 12754 solver.cpp:253]     Train net output #0: loss = 1.30511 (* 1 = 1.30511 loss)
I0522 06:00:34.627562 12754 sgd_solver.cpp:106] Iteration 279000, lr = 0.0045
I0522 06:00:46.788589 12754 solver.cpp:237] Iteration 279750, loss = 1.09795
I0522 06:00:46.788764 12754 solver.cpp:253]     Train net output #0: loss = 1.09794 (* 1 = 1.09794 loss)
I0522 06:00:46.788779 12754 sgd_solver.cpp:106] Iteration 279750, lr = 0.0045
I0522 06:01:19.852494 12754 solver.cpp:237] Iteration 280500, loss = 1.32199
I0522 06:01:19.852686 12754 solver.cpp:253]     Train net output #0: loss = 1.32199 (* 1 = 1.32199 loss)
I0522 06:01:19.852701 12754 sgd_solver.cpp:106] Iteration 280500, lr = 0.0045
I0522 06:01:32.008987 12754 solver.cpp:237] Iteration 281250, loss = 1.60278
I0522 06:01:32.009024 12754 solver.cpp:253]     Train net output #0: loss = 1.60278 (* 1 = 1.60278 loss)
I0522 06:01:32.009040 12754 sgd_solver.cpp:106] Iteration 281250, lr = 0.0045
I0522 06:01:44.163389 12754 solver.cpp:237] Iteration 282000, loss = 0.638671
I0522 06:01:44.163426 12754 solver.cpp:253]     Train net output #0: loss = 0.638668 (* 1 = 0.638668 loss)
I0522 06:01:44.163440 12754 sgd_solver.cpp:106] Iteration 282000, lr = 0.0045
I0522 06:01:56.318084 12754 solver.cpp:237] Iteration 282750, loss = 1.0823
I0522 06:01:56.318279 12754 solver.cpp:253]     Train net output #0: loss = 1.0823 (* 1 = 1.0823 loss)
I0522 06:01:56.318294 12754 sgd_solver.cpp:106] Iteration 282750, lr = 0.0045
I0522 06:02:08.417714 12754 solver.cpp:237] Iteration 283500, loss = 1.06712
I0522 06:02:08.417750 12754 solver.cpp:253]     Train net output #0: loss = 1.06711 (* 1 = 1.06711 loss)
I0522 06:02:08.417764 12754 sgd_solver.cpp:106] Iteration 283500, lr = 0.0045
I0522 06:02:20.521996 12754 solver.cpp:237] Iteration 284250, loss = 1.42114
I0522 06:02:20.522039 12754 solver.cpp:253]     Train net output #0: loss = 1.42113 (* 1 = 1.42113 loss)
I0522 06:02:20.522054 12754 sgd_solver.cpp:106] Iteration 284250, lr = 0.0045
I0522 06:02:32.618674 12754 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_285000.caffemodel
I0522 06:02:32.668642 12754 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0045_2016-05-20T15.48.56.541375_iter_285000.solverstate
I0522 06:02:32.693711 12754 solver.cpp:341] Iteration 285000, Testing net (#0)
I0522 06:03:24.317739 12754 solver.cpp:409]     Test net output #0: accuracy = 0.894729
I0522 06:03:24.317934 12754 solver.cpp:409]     Test net output #1: loss = 0.328699 (* 1 = 0.328699 loss)
I0522 06:03:45.204351 12754 solver.cpp:237] Iteration 285000, loss = 1.26715
I0522 06:03:45.204404 12754 solver.cpp:253]     Train net output #0: loss = 1.26714 (* 1 = 1.26714 loss)
I0522 06:03:45.204421 12754 sgd_solver.cpp:106] Iteration 285000, lr = 0.0045
I0522 06:03:57.365944 12754 solver.cpp:237] Iteration 285750, loss = 1.13478
I0522 06:03:57.366134 12754 solver.cpp:253]     Train net output #0: loss = 1.13477 (* 1 = 1.13477 loss)
I0522 06:03:57.366149 12754 sgd_solver.cpp:106] Iteration 285750, lr = 0.0045
I0522 06:04:09.530410 12754 solver.cpp:237] Iteration 286500, loss = 1.02478
I0522 06:04:09.530446 12754 solver.cpp:253]     Train net output #0: loss = 1.02477 (* 1 = 1.02477 loss)
I0522 06:04:09.530459 12754 sgd_solver.cpp:106] Iteration 286500, lr = 0.0045
I0522 06:04:21.700083 12754 solver.cpp:237] Iteration 287250, loss = 1.31099
I0522 06:04:21.700125 12754 solver.cpp:253]     Train net output #0: loss = 1.31098 (* 1 = 1.31098 loss)
I0522 06:04:21.700139 12754 sgd_solver.cpp:106] Iteration 287250, lr = 0.0045
I0522 06:04:33.881877 12754 solver.cpp:237] Iteration 288000, loss = 1.24241
I0522 06:04:33.882055 12754 solver.cpp:253]     Train net output #0: loss = 1.24241 (* 1 = 1.24241 loss)
I0522 06:04:33.882069 12754 sgd_solver.cpp:106] Iteration 288000, lr = 0.0045
I0522 06:04:46.062440 12754 solver.cpp:237] Iteration 288750, loss = 1.20176
I0522 06:04:46.062481 12754 solver.cpp:253]     Train net output #0: loss = 1.20176 (* 1 = 1.20176 loss)
I0522 06:04:46.062496 12754 sgd_solver.cpp:106] Iteration 288750, lr = 0.0045
I0522 06:04:58.182132 12754 solver.cpp:237] Iteration 289500, loss = 0.760061
I0522 06:04:58.182169 12754 solver.cpp:253]     Train net output #0: loss = 0.760058 (* 1 = 0.760058 loss)
I0522 06:04:58.182183 12754 sgd_solver.cpp:106] Iteration 289500, lr = 0.0045
I0522 06:05:31.130064 12754 solver.cpp:237] Iteration 290250, loss = 0.992839
I0522 06:05:31.130264 12754 solver.cpp:253]     Train net output #0: loss = 0.992836 (* 1 = 0.992836 loss)
I0522 06:05:31.130278 12754 sgd_solver.cpp:106] Iteration 290250, lr = 0.0045
=>> PBS: job killed: walltime 7218 exceeded limit 7200
aprun: Apid 11245357: Caught signal Terminated, sending to application
*** Aborted at 1463911538 (unix time) try "date -d @1463911538" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x31cf) received by PID 12754 (TID 0x2aaac746f900) from PID 12751; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11245357: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11245357: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
aprun: Apid 11245357: Caught signal Terminated, sending to application
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
aprun: Apid 11245357: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02064] [c4-5c0s7n2] [Sun May 22 06:05:40 2016] PE RANK 0 exit signal Terminated
Application 11245357 exit codes: 143
Application 11245357 resources: utime ~6276s, stime ~932s, Rss ~5332236, inblocks ~13318068, outblocks ~592961
