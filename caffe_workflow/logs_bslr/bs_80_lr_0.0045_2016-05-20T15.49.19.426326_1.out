2809826
I0525 00:46:42.005785 19044 caffe.cpp:184] Using GPUs 0
I0525 00:46:42.424176 19044 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1875
test_interval: 3750
base_lr: 0.0045
display: 187
max_iter: 187500
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1875
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326.prototxt"
I0525 00:46:42.426177 19044 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326.prototxt
I0525 00:46:42.442790 19044 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 00:46:42.442849 19044 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 00:46:42.443195 19044 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 80
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 00:46:42.443373 19044 layer_factory.hpp:77] Creating layer data_hdf5
I0525 00:46:42.443397 19044 net.cpp:106] Creating Layer data_hdf5
I0525 00:46:42.443411 19044 net.cpp:411] data_hdf5 -> data
I0525 00:46:42.443444 19044 net.cpp:411] data_hdf5 -> label
I0525 00:46:42.443476 19044 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 00:46:42.445044 19044 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 00:46:42.447373 19044 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 00:47:03.937603 19044 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 00:47:03.942878 19044 net.cpp:150] Setting up data_hdf5
I0525 00:47:03.942920 19044 net.cpp:157] Top shape: 80 1 127 50 (508000)
I0525 00:47:03.942934 19044 net.cpp:157] Top shape: 80 (80)
I0525 00:47:03.942947 19044 net.cpp:165] Memory required for data: 2032320
I0525 00:47:03.942961 19044 layer_factory.hpp:77] Creating layer conv1
I0525 00:47:03.942994 19044 net.cpp:106] Creating Layer conv1
I0525 00:47:03.943006 19044 net.cpp:454] conv1 <- data
I0525 00:47:03.943028 19044 net.cpp:411] conv1 -> conv1
I0525 00:47:04.308418 19044 net.cpp:150] Setting up conv1
I0525 00:47:04.308465 19044 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 00:47:04.308475 19044 net.cpp:165] Memory required for data: 24150720
I0525 00:47:04.308506 19044 layer_factory.hpp:77] Creating layer relu1
I0525 00:47:04.308526 19044 net.cpp:106] Creating Layer relu1
I0525 00:47:04.308537 19044 net.cpp:454] relu1 <- conv1
I0525 00:47:04.308552 19044 net.cpp:397] relu1 -> conv1 (in-place)
I0525 00:47:04.309063 19044 net.cpp:150] Setting up relu1
I0525 00:47:04.309080 19044 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 00:47:04.309092 19044 net.cpp:165] Memory required for data: 46269120
I0525 00:47:04.309103 19044 layer_factory.hpp:77] Creating layer pool1
I0525 00:47:04.309119 19044 net.cpp:106] Creating Layer pool1
I0525 00:47:04.309129 19044 net.cpp:454] pool1 <- conv1
I0525 00:47:04.309144 19044 net.cpp:411] pool1 -> pool1
I0525 00:47:04.309224 19044 net.cpp:150] Setting up pool1
I0525 00:47:04.309238 19044 net.cpp:157] Top shape: 80 12 60 48 (2764800)
I0525 00:47:04.309250 19044 net.cpp:165] Memory required for data: 57328320
I0525 00:47:04.309260 19044 layer_factory.hpp:77] Creating layer conv2
I0525 00:47:04.309283 19044 net.cpp:106] Creating Layer conv2
I0525 00:47:04.309293 19044 net.cpp:454] conv2 <- pool1
I0525 00:47:04.309306 19044 net.cpp:411] conv2 -> conv2
I0525 00:47:04.312039 19044 net.cpp:150] Setting up conv2
I0525 00:47:04.312067 19044 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 00:47:04.312077 19044 net.cpp:165] Memory required for data: 73225920
I0525 00:47:04.312098 19044 layer_factory.hpp:77] Creating layer relu2
I0525 00:47:04.312121 19044 net.cpp:106] Creating Layer relu2
I0525 00:47:04.312132 19044 net.cpp:454] relu2 <- conv2
I0525 00:47:04.312145 19044 net.cpp:397] relu2 -> conv2 (in-place)
I0525 00:47:04.312476 19044 net.cpp:150] Setting up relu2
I0525 00:47:04.312491 19044 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 00:47:04.312501 19044 net.cpp:165] Memory required for data: 89123520
I0525 00:47:04.312512 19044 layer_factory.hpp:77] Creating layer pool2
I0525 00:47:04.312525 19044 net.cpp:106] Creating Layer pool2
I0525 00:47:04.312535 19044 net.cpp:454] pool2 <- conv2
I0525 00:47:04.312547 19044 net.cpp:411] pool2 -> pool2
I0525 00:47:04.312628 19044 net.cpp:150] Setting up pool2
I0525 00:47:04.312641 19044 net.cpp:157] Top shape: 80 20 27 46 (1987200)
I0525 00:47:04.312651 19044 net.cpp:165] Memory required for data: 97072320
I0525 00:47:04.312659 19044 layer_factory.hpp:77] Creating layer conv3
I0525 00:47:04.312679 19044 net.cpp:106] Creating Layer conv3
I0525 00:47:04.312688 19044 net.cpp:454] conv3 <- pool2
I0525 00:47:04.312702 19044 net.cpp:411] conv3 -> conv3
I0525 00:47:04.314615 19044 net.cpp:150] Setting up conv3
I0525 00:47:04.314640 19044 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 00:47:04.314651 19044 net.cpp:165] Memory required for data: 105745600
I0525 00:47:04.314671 19044 layer_factory.hpp:77] Creating layer relu3
I0525 00:47:04.314687 19044 net.cpp:106] Creating Layer relu3
I0525 00:47:04.314697 19044 net.cpp:454] relu3 <- conv3
I0525 00:47:04.314709 19044 net.cpp:397] relu3 -> conv3 (in-place)
I0525 00:47:04.315176 19044 net.cpp:150] Setting up relu3
I0525 00:47:04.315192 19044 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 00:47:04.315202 19044 net.cpp:165] Memory required for data: 114418880
I0525 00:47:04.315213 19044 layer_factory.hpp:77] Creating layer pool3
I0525 00:47:04.315227 19044 net.cpp:106] Creating Layer pool3
I0525 00:47:04.315237 19044 net.cpp:454] pool3 <- conv3
I0525 00:47:04.315251 19044 net.cpp:411] pool3 -> pool3
I0525 00:47:04.315320 19044 net.cpp:150] Setting up pool3
I0525 00:47:04.315332 19044 net.cpp:157] Top shape: 80 28 11 44 (1084160)
I0525 00:47:04.315342 19044 net.cpp:165] Memory required for data: 118755520
I0525 00:47:04.315353 19044 layer_factory.hpp:77] Creating layer conv4
I0525 00:47:04.315371 19044 net.cpp:106] Creating Layer conv4
I0525 00:47:04.315382 19044 net.cpp:454] conv4 <- pool3
I0525 00:47:04.315395 19044 net.cpp:411] conv4 -> conv4
I0525 00:47:04.318369 19044 net.cpp:150] Setting up conv4
I0525 00:47:04.318392 19044 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 00:47:04.318403 19044 net.cpp:165] Memory required for data: 121658560
I0525 00:47:04.318418 19044 layer_factory.hpp:77] Creating layer relu4
I0525 00:47:04.318434 19044 net.cpp:106] Creating Layer relu4
I0525 00:47:04.318444 19044 net.cpp:454] relu4 <- conv4
I0525 00:47:04.318456 19044 net.cpp:397] relu4 -> conv4 (in-place)
I0525 00:47:04.318922 19044 net.cpp:150] Setting up relu4
I0525 00:47:04.318938 19044 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 00:47:04.318948 19044 net.cpp:165] Memory required for data: 124561600
I0525 00:47:04.318959 19044 layer_factory.hpp:77] Creating layer pool4
I0525 00:47:04.318972 19044 net.cpp:106] Creating Layer pool4
I0525 00:47:04.318981 19044 net.cpp:454] pool4 <- conv4
I0525 00:47:04.318995 19044 net.cpp:411] pool4 -> pool4
I0525 00:47:04.319063 19044 net.cpp:150] Setting up pool4
I0525 00:47:04.319077 19044 net.cpp:157] Top shape: 80 36 3 42 (362880)
I0525 00:47:04.319087 19044 net.cpp:165] Memory required for data: 126013120
I0525 00:47:04.319097 19044 layer_factory.hpp:77] Creating layer ip1
I0525 00:47:04.319114 19044 net.cpp:106] Creating Layer ip1
I0525 00:47:04.319125 19044 net.cpp:454] ip1 <- pool4
I0525 00:47:04.319139 19044 net.cpp:411] ip1 -> ip1
I0525 00:47:04.334583 19044 net.cpp:150] Setting up ip1
I0525 00:47:04.334611 19044 net.cpp:157] Top shape: 80 196 (15680)
I0525 00:47:04.334624 19044 net.cpp:165] Memory required for data: 126075840
I0525 00:47:04.334645 19044 layer_factory.hpp:77] Creating layer relu5
I0525 00:47:04.334661 19044 net.cpp:106] Creating Layer relu5
I0525 00:47:04.334671 19044 net.cpp:454] relu5 <- ip1
I0525 00:47:04.334684 19044 net.cpp:397] relu5 -> ip1 (in-place)
I0525 00:47:04.335024 19044 net.cpp:150] Setting up relu5
I0525 00:47:04.335039 19044 net.cpp:157] Top shape: 80 196 (15680)
I0525 00:47:04.335049 19044 net.cpp:165] Memory required for data: 126138560
I0525 00:47:04.335059 19044 layer_factory.hpp:77] Creating layer drop1
I0525 00:47:04.335080 19044 net.cpp:106] Creating Layer drop1
I0525 00:47:04.335091 19044 net.cpp:454] drop1 <- ip1
I0525 00:47:04.335104 19044 net.cpp:397] drop1 -> ip1 (in-place)
I0525 00:47:04.335166 19044 net.cpp:150] Setting up drop1
I0525 00:47:04.335180 19044 net.cpp:157] Top shape: 80 196 (15680)
I0525 00:47:04.335189 19044 net.cpp:165] Memory required for data: 126201280
I0525 00:47:04.335199 19044 layer_factory.hpp:77] Creating layer ip2
I0525 00:47:04.335219 19044 net.cpp:106] Creating Layer ip2
I0525 00:47:04.335229 19044 net.cpp:454] ip2 <- ip1
I0525 00:47:04.335243 19044 net.cpp:411] ip2 -> ip2
I0525 00:47:04.335708 19044 net.cpp:150] Setting up ip2
I0525 00:47:04.335721 19044 net.cpp:157] Top shape: 80 98 (7840)
I0525 00:47:04.335731 19044 net.cpp:165] Memory required for data: 126232640
I0525 00:47:04.335747 19044 layer_factory.hpp:77] Creating layer relu6
I0525 00:47:04.335759 19044 net.cpp:106] Creating Layer relu6
I0525 00:47:04.335769 19044 net.cpp:454] relu6 <- ip2
I0525 00:47:04.335783 19044 net.cpp:397] relu6 -> ip2 (in-place)
I0525 00:47:04.336308 19044 net.cpp:150] Setting up relu6
I0525 00:47:04.336323 19044 net.cpp:157] Top shape: 80 98 (7840)
I0525 00:47:04.336333 19044 net.cpp:165] Memory required for data: 126264000
I0525 00:47:04.336344 19044 layer_factory.hpp:77] Creating layer drop2
I0525 00:47:04.336357 19044 net.cpp:106] Creating Layer drop2
I0525 00:47:04.336367 19044 net.cpp:454] drop2 <- ip2
I0525 00:47:04.336380 19044 net.cpp:397] drop2 -> ip2 (in-place)
I0525 00:47:04.336422 19044 net.cpp:150] Setting up drop2
I0525 00:47:04.336436 19044 net.cpp:157] Top shape: 80 98 (7840)
I0525 00:47:04.336446 19044 net.cpp:165] Memory required for data: 126295360
I0525 00:47:04.336455 19044 layer_factory.hpp:77] Creating layer ip3
I0525 00:47:04.336469 19044 net.cpp:106] Creating Layer ip3
I0525 00:47:04.336479 19044 net.cpp:454] ip3 <- ip2
I0525 00:47:04.336493 19044 net.cpp:411] ip3 -> ip3
I0525 00:47:04.336700 19044 net.cpp:150] Setting up ip3
I0525 00:47:04.336714 19044 net.cpp:157] Top shape: 80 11 (880)
I0525 00:47:04.336724 19044 net.cpp:165] Memory required for data: 126298880
I0525 00:47:04.336738 19044 layer_factory.hpp:77] Creating layer drop3
I0525 00:47:04.336751 19044 net.cpp:106] Creating Layer drop3
I0525 00:47:04.336761 19044 net.cpp:454] drop3 <- ip3
I0525 00:47:04.336773 19044 net.cpp:397] drop3 -> ip3 (in-place)
I0525 00:47:04.336812 19044 net.cpp:150] Setting up drop3
I0525 00:47:04.336825 19044 net.cpp:157] Top shape: 80 11 (880)
I0525 00:47:04.336835 19044 net.cpp:165] Memory required for data: 126302400
I0525 00:47:04.336845 19044 layer_factory.hpp:77] Creating layer loss
I0525 00:47:04.336864 19044 net.cpp:106] Creating Layer loss
I0525 00:47:04.336874 19044 net.cpp:454] loss <- ip3
I0525 00:47:04.336885 19044 net.cpp:454] loss <- label
I0525 00:47:04.336899 19044 net.cpp:411] loss -> loss
I0525 00:47:04.336915 19044 layer_factory.hpp:77] Creating layer loss
I0525 00:47:04.337560 19044 net.cpp:150] Setting up loss
I0525 00:47:04.337581 19044 net.cpp:157] Top shape: (1)
I0525 00:47:04.337595 19044 net.cpp:160]     with loss weight 1
I0525 00:47:04.337636 19044 net.cpp:165] Memory required for data: 126302404
I0525 00:47:04.337646 19044 net.cpp:226] loss needs backward computation.
I0525 00:47:04.337658 19044 net.cpp:226] drop3 needs backward computation.
I0525 00:47:04.337668 19044 net.cpp:226] ip3 needs backward computation.
I0525 00:47:04.337677 19044 net.cpp:226] drop2 needs backward computation.
I0525 00:47:04.337687 19044 net.cpp:226] relu6 needs backward computation.
I0525 00:47:04.337697 19044 net.cpp:226] ip2 needs backward computation.
I0525 00:47:04.337707 19044 net.cpp:226] drop1 needs backward computation.
I0525 00:47:04.337716 19044 net.cpp:226] relu5 needs backward computation.
I0525 00:47:04.337726 19044 net.cpp:226] ip1 needs backward computation.
I0525 00:47:04.337736 19044 net.cpp:226] pool4 needs backward computation.
I0525 00:47:04.337746 19044 net.cpp:226] relu4 needs backward computation.
I0525 00:47:04.337756 19044 net.cpp:226] conv4 needs backward computation.
I0525 00:47:04.337767 19044 net.cpp:226] pool3 needs backward computation.
I0525 00:47:04.337777 19044 net.cpp:226] relu3 needs backward computation.
I0525 00:47:04.337796 19044 net.cpp:226] conv3 needs backward computation.
I0525 00:47:04.337807 19044 net.cpp:226] pool2 needs backward computation.
I0525 00:47:04.337818 19044 net.cpp:226] relu2 needs backward computation.
I0525 00:47:04.337828 19044 net.cpp:226] conv2 needs backward computation.
I0525 00:47:04.337839 19044 net.cpp:226] pool1 needs backward computation.
I0525 00:47:04.337851 19044 net.cpp:226] relu1 needs backward computation.
I0525 00:47:04.337859 19044 net.cpp:226] conv1 needs backward computation.
I0525 00:47:04.337872 19044 net.cpp:228] data_hdf5 does not need backward computation.
I0525 00:47:04.337882 19044 net.cpp:270] This network produces output loss
I0525 00:47:04.337904 19044 net.cpp:283] Network initialization done.
I0525 00:47:04.339704 19044 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326.prototxt
I0525 00:47:04.339777 19044 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 00:47:04.340142 19044 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 80
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 00:47:04.340332 19044 layer_factory.hpp:77] Creating layer data_hdf5
I0525 00:47:04.340348 19044 net.cpp:106] Creating Layer data_hdf5
I0525 00:47:04.340360 19044 net.cpp:411] data_hdf5 -> data
I0525 00:47:04.340378 19044 net.cpp:411] data_hdf5 -> label
I0525 00:47:04.340394 19044 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 00:47:04.341686 19044 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 00:47:25.656018 19044 net.cpp:150] Setting up data_hdf5
I0525 00:47:25.656191 19044 net.cpp:157] Top shape: 80 1 127 50 (508000)
I0525 00:47:25.656205 19044 net.cpp:157] Top shape: 80 (80)
I0525 00:47:25.656215 19044 net.cpp:165] Memory required for data: 2032320
I0525 00:47:25.656229 19044 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 00:47:25.656257 19044 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 00:47:25.656267 19044 net.cpp:454] label_data_hdf5_1_split <- label
I0525 00:47:25.656282 19044 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 00:47:25.656304 19044 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 00:47:25.656378 19044 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 00:47:25.656391 19044 net.cpp:157] Top shape: 80 (80)
I0525 00:47:25.656404 19044 net.cpp:157] Top shape: 80 (80)
I0525 00:47:25.656414 19044 net.cpp:165] Memory required for data: 2032960
I0525 00:47:25.656421 19044 layer_factory.hpp:77] Creating layer conv1
I0525 00:47:25.656445 19044 net.cpp:106] Creating Layer conv1
I0525 00:47:25.656455 19044 net.cpp:454] conv1 <- data
I0525 00:47:25.656471 19044 net.cpp:411] conv1 -> conv1
I0525 00:47:25.658413 19044 net.cpp:150] Setting up conv1
I0525 00:47:25.658432 19044 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 00:47:25.658445 19044 net.cpp:165] Memory required for data: 24151360
I0525 00:47:25.658465 19044 layer_factory.hpp:77] Creating layer relu1
I0525 00:47:25.658480 19044 net.cpp:106] Creating Layer relu1
I0525 00:47:25.658490 19044 net.cpp:454] relu1 <- conv1
I0525 00:47:25.658504 19044 net.cpp:397] relu1 -> conv1 (in-place)
I0525 00:47:25.658998 19044 net.cpp:150] Setting up relu1
I0525 00:47:25.659014 19044 net.cpp:157] Top shape: 80 12 120 48 (5529600)
I0525 00:47:25.659025 19044 net.cpp:165] Memory required for data: 46269760
I0525 00:47:25.659035 19044 layer_factory.hpp:77] Creating layer pool1
I0525 00:47:25.659051 19044 net.cpp:106] Creating Layer pool1
I0525 00:47:25.659061 19044 net.cpp:454] pool1 <- conv1
I0525 00:47:25.659075 19044 net.cpp:411] pool1 -> pool1
I0525 00:47:25.659149 19044 net.cpp:150] Setting up pool1
I0525 00:47:25.659162 19044 net.cpp:157] Top shape: 80 12 60 48 (2764800)
I0525 00:47:25.659173 19044 net.cpp:165] Memory required for data: 57328960
I0525 00:47:25.659183 19044 layer_factory.hpp:77] Creating layer conv2
I0525 00:47:25.659199 19044 net.cpp:106] Creating Layer conv2
I0525 00:47:25.659210 19044 net.cpp:454] conv2 <- pool1
I0525 00:47:25.659224 19044 net.cpp:411] conv2 -> conv2
I0525 00:47:25.661140 19044 net.cpp:150] Setting up conv2
I0525 00:47:25.661164 19044 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 00:47:25.661175 19044 net.cpp:165] Memory required for data: 73226560
I0525 00:47:25.661192 19044 layer_factory.hpp:77] Creating layer relu2
I0525 00:47:25.661206 19044 net.cpp:106] Creating Layer relu2
I0525 00:47:25.661216 19044 net.cpp:454] relu2 <- conv2
I0525 00:47:25.661229 19044 net.cpp:397] relu2 -> conv2 (in-place)
I0525 00:47:25.661562 19044 net.cpp:150] Setting up relu2
I0525 00:47:25.661576 19044 net.cpp:157] Top shape: 80 20 54 46 (3974400)
I0525 00:47:25.661586 19044 net.cpp:165] Memory required for data: 89124160
I0525 00:47:25.661597 19044 layer_factory.hpp:77] Creating layer pool2
I0525 00:47:25.661610 19044 net.cpp:106] Creating Layer pool2
I0525 00:47:25.661620 19044 net.cpp:454] pool2 <- conv2
I0525 00:47:25.661633 19044 net.cpp:411] pool2 -> pool2
I0525 00:47:25.661705 19044 net.cpp:150] Setting up pool2
I0525 00:47:25.661717 19044 net.cpp:157] Top shape: 80 20 27 46 (1987200)
I0525 00:47:25.661727 19044 net.cpp:165] Memory required for data: 97072960
I0525 00:47:25.661737 19044 layer_factory.hpp:77] Creating layer conv3
I0525 00:47:25.661756 19044 net.cpp:106] Creating Layer conv3
I0525 00:47:25.661767 19044 net.cpp:454] conv3 <- pool2
I0525 00:47:25.661782 19044 net.cpp:411] conv3 -> conv3
I0525 00:47:25.663760 19044 net.cpp:150] Setting up conv3
I0525 00:47:25.663784 19044 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 00:47:25.663795 19044 net.cpp:165] Memory required for data: 105746240
I0525 00:47:25.663827 19044 layer_factory.hpp:77] Creating layer relu3
I0525 00:47:25.663841 19044 net.cpp:106] Creating Layer relu3
I0525 00:47:25.663852 19044 net.cpp:454] relu3 <- conv3
I0525 00:47:25.663866 19044 net.cpp:397] relu3 -> conv3 (in-place)
I0525 00:47:25.664340 19044 net.cpp:150] Setting up relu3
I0525 00:47:25.664356 19044 net.cpp:157] Top shape: 80 28 22 44 (2168320)
I0525 00:47:25.664367 19044 net.cpp:165] Memory required for data: 114419520
I0525 00:47:25.664377 19044 layer_factory.hpp:77] Creating layer pool3
I0525 00:47:25.664391 19044 net.cpp:106] Creating Layer pool3
I0525 00:47:25.664400 19044 net.cpp:454] pool3 <- conv3
I0525 00:47:25.664414 19044 net.cpp:411] pool3 -> pool3
I0525 00:47:25.664485 19044 net.cpp:150] Setting up pool3
I0525 00:47:25.664499 19044 net.cpp:157] Top shape: 80 28 11 44 (1084160)
I0525 00:47:25.664508 19044 net.cpp:165] Memory required for data: 118756160
I0525 00:47:25.664517 19044 layer_factory.hpp:77] Creating layer conv4
I0525 00:47:25.664535 19044 net.cpp:106] Creating Layer conv4
I0525 00:47:25.664546 19044 net.cpp:454] conv4 <- pool3
I0525 00:47:25.664561 19044 net.cpp:411] conv4 -> conv4
I0525 00:47:25.666631 19044 net.cpp:150] Setting up conv4
I0525 00:47:25.666653 19044 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 00:47:25.666666 19044 net.cpp:165] Memory required for data: 121659200
I0525 00:47:25.666682 19044 layer_factory.hpp:77] Creating layer relu4
I0525 00:47:25.666695 19044 net.cpp:106] Creating Layer relu4
I0525 00:47:25.666705 19044 net.cpp:454] relu4 <- conv4
I0525 00:47:25.666718 19044 net.cpp:397] relu4 -> conv4 (in-place)
I0525 00:47:25.667194 19044 net.cpp:150] Setting up relu4
I0525 00:47:25.667212 19044 net.cpp:157] Top shape: 80 36 6 42 (725760)
I0525 00:47:25.667222 19044 net.cpp:165] Memory required for data: 124562240
I0525 00:47:25.667232 19044 layer_factory.hpp:77] Creating layer pool4
I0525 00:47:25.667245 19044 net.cpp:106] Creating Layer pool4
I0525 00:47:25.667255 19044 net.cpp:454] pool4 <- conv4
I0525 00:47:25.667268 19044 net.cpp:411] pool4 -> pool4
I0525 00:47:25.667340 19044 net.cpp:150] Setting up pool4
I0525 00:47:25.667353 19044 net.cpp:157] Top shape: 80 36 3 42 (362880)
I0525 00:47:25.667362 19044 net.cpp:165] Memory required for data: 126013760
I0525 00:47:25.667373 19044 layer_factory.hpp:77] Creating layer ip1
I0525 00:47:25.667389 19044 net.cpp:106] Creating Layer ip1
I0525 00:47:25.667400 19044 net.cpp:454] ip1 <- pool4
I0525 00:47:25.667413 19044 net.cpp:411] ip1 -> ip1
I0525 00:47:25.682919 19044 net.cpp:150] Setting up ip1
I0525 00:47:25.682947 19044 net.cpp:157] Top shape: 80 196 (15680)
I0525 00:47:25.682960 19044 net.cpp:165] Memory required for data: 126076480
I0525 00:47:25.682981 19044 layer_factory.hpp:77] Creating layer relu5
I0525 00:47:25.682996 19044 net.cpp:106] Creating Layer relu5
I0525 00:47:25.683007 19044 net.cpp:454] relu5 <- ip1
I0525 00:47:25.683022 19044 net.cpp:397] relu5 -> ip1 (in-place)
I0525 00:47:25.683369 19044 net.cpp:150] Setting up relu5
I0525 00:47:25.683382 19044 net.cpp:157] Top shape: 80 196 (15680)
I0525 00:47:25.683393 19044 net.cpp:165] Memory required for data: 126139200
I0525 00:47:25.683403 19044 layer_factory.hpp:77] Creating layer drop1
I0525 00:47:25.683421 19044 net.cpp:106] Creating Layer drop1
I0525 00:47:25.683431 19044 net.cpp:454] drop1 <- ip1
I0525 00:47:25.683445 19044 net.cpp:397] drop1 -> ip1 (in-place)
I0525 00:47:25.683493 19044 net.cpp:150] Setting up drop1
I0525 00:47:25.683506 19044 net.cpp:157] Top shape: 80 196 (15680)
I0525 00:47:25.683516 19044 net.cpp:165] Memory required for data: 126201920
I0525 00:47:25.683526 19044 layer_factory.hpp:77] Creating layer ip2
I0525 00:47:25.683542 19044 net.cpp:106] Creating Layer ip2
I0525 00:47:25.683552 19044 net.cpp:454] ip2 <- ip1
I0525 00:47:25.683564 19044 net.cpp:411] ip2 -> ip2
I0525 00:47:25.684041 19044 net.cpp:150] Setting up ip2
I0525 00:47:25.684054 19044 net.cpp:157] Top shape: 80 98 (7840)
I0525 00:47:25.684064 19044 net.cpp:165] Memory required for data: 126233280
I0525 00:47:25.684080 19044 layer_factory.hpp:77] Creating layer relu6
I0525 00:47:25.684105 19044 net.cpp:106] Creating Layer relu6
I0525 00:47:25.684123 19044 net.cpp:454] relu6 <- ip2
I0525 00:47:25.684135 19044 net.cpp:397] relu6 -> ip2 (in-place)
I0525 00:47:25.684669 19044 net.cpp:150] Setting up relu6
I0525 00:47:25.684689 19044 net.cpp:157] Top shape: 80 98 (7840)
I0525 00:47:25.684698 19044 net.cpp:165] Memory required for data: 126264640
I0525 00:47:25.684707 19044 layer_factory.hpp:77] Creating layer drop2
I0525 00:47:25.684721 19044 net.cpp:106] Creating Layer drop2
I0525 00:47:25.684732 19044 net.cpp:454] drop2 <- ip2
I0525 00:47:25.684746 19044 net.cpp:397] drop2 -> ip2 (in-place)
I0525 00:47:25.684789 19044 net.cpp:150] Setting up drop2
I0525 00:47:25.684803 19044 net.cpp:157] Top shape: 80 98 (7840)
I0525 00:47:25.684813 19044 net.cpp:165] Memory required for data: 126296000
I0525 00:47:25.684823 19044 layer_factory.hpp:77] Creating layer ip3
I0525 00:47:25.684839 19044 net.cpp:106] Creating Layer ip3
I0525 00:47:25.684849 19044 net.cpp:454] ip3 <- ip2
I0525 00:47:25.684862 19044 net.cpp:411] ip3 -> ip3
I0525 00:47:25.685086 19044 net.cpp:150] Setting up ip3
I0525 00:47:25.685101 19044 net.cpp:157] Top shape: 80 11 (880)
I0525 00:47:25.685111 19044 net.cpp:165] Memory required for data: 126299520
I0525 00:47:25.685127 19044 layer_factory.hpp:77] Creating layer drop3
I0525 00:47:25.685140 19044 net.cpp:106] Creating Layer drop3
I0525 00:47:25.685150 19044 net.cpp:454] drop3 <- ip3
I0525 00:47:25.685163 19044 net.cpp:397] drop3 -> ip3 (in-place)
I0525 00:47:25.685204 19044 net.cpp:150] Setting up drop3
I0525 00:47:25.685217 19044 net.cpp:157] Top shape: 80 11 (880)
I0525 00:47:25.685227 19044 net.cpp:165] Memory required for data: 126303040
I0525 00:47:25.685237 19044 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 00:47:25.685250 19044 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 00:47:25.685261 19044 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 00:47:25.685273 19044 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 00:47:25.685288 19044 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 00:47:25.685362 19044 net.cpp:150] Setting up ip3_drop3_0_split
I0525 00:47:25.685375 19044 net.cpp:157] Top shape: 80 11 (880)
I0525 00:47:25.685389 19044 net.cpp:157] Top shape: 80 11 (880)
I0525 00:47:25.685400 19044 net.cpp:165] Memory required for data: 126310080
I0525 00:47:25.685410 19044 layer_factory.hpp:77] Creating layer accuracy
I0525 00:47:25.685431 19044 net.cpp:106] Creating Layer accuracy
I0525 00:47:25.685441 19044 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 00:47:25.685452 19044 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 00:47:25.685467 19044 net.cpp:411] accuracy -> accuracy
I0525 00:47:25.685492 19044 net.cpp:150] Setting up accuracy
I0525 00:47:25.685503 19044 net.cpp:157] Top shape: (1)
I0525 00:47:25.685513 19044 net.cpp:165] Memory required for data: 126310084
I0525 00:47:25.685523 19044 layer_factory.hpp:77] Creating layer loss
I0525 00:47:25.685536 19044 net.cpp:106] Creating Layer loss
I0525 00:47:25.685546 19044 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 00:47:25.685557 19044 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 00:47:25.685571 19044 net.cpp:411] loss -> loss
I0525 00:47:25.685590 19044 layer_factory.hpp:77] Creating layer loss
I0525 00:47:25.686089 19044 net.cpp:150] Setting up loss
I0525 00:47:25.686102 19044 net.cpp:157] Top shape: (1)
I0525 00:47:25.686112 19044 net.cpp:160]     with loss weight 1
I0525 00:47:25.686131 19044 net.cpp:165] Memory required for data: 126310088
I0525 00:47:25.686141 19044 net.cpp:226] loss needs backward computation.
I0525 00:47:25.686153 19044 net.cpp:228] accuracy does not need backward computation.
I0525 00:47:25.686164 19044 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 00:47:25.686174 19044 net.cpp:226] drop3 needs backward computation.
I0525 00:47:25.686185 19044 net.cpp:226] ip3 needs backward computation.
I0525 00:47:25.686195 19044 net.cpp:226] drop2 needs backward computation.
I0525 00:47:25.686205 19044 net.cpp:226] relu6 needs backward computation.
I0525 00:47:25.686223 19044 net.cpp:226] ip2 needs backward computation.
I0525 00:47:25.686234 19044 net.cpp:226] drop1 needs backward computation.
I0525 00:47:25.686244 19044 net.cpp:226] relu5 needs backward computation.
I0525 00:47:25.686254 19044 net.cpp:226] ip1 needs backward computation.
I0525 00:47:25.686264 19044 net.cpp:226] pool4 needs backward computation.
I0525 00:47:25.686274 19044 net.cpp:226] relu4 needs backward computation.
I0525 00:47:25.686283 19044 net.cpp:226] conv4 needs backward computation.
I0525 00:47:25.686292 19044 net.cpp:226] pool3 needs backward computation.
I0525 00:47:25.686303 19044 net.cpp:226] relu3 needs backward computation.
I0525 00:47:25.686313 19044 net.cpp:226] conv3 needs backward computation.
I0525 00:47:25.686324 19044 net.cpp:226] pool2 needs backward computation.
I0525 00:47:25.686334 19044 net.cpp:226] relu2 needs backward computation.
I0525 00:47:25.686344 19044 net.cpp:226] conv2 needs backward computation.
I0525 00:47:25.686355 19044 net.cpp:226] pool1 needs backward computation.
I0525 00:47:25.686365 19044 net.cpp:226] relu1 needs backward computation.
I0525 00:47:25.686374 19044 net.cpp:226] conv1 needs backward computation.
I0525 00:47:25.686386 19044 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 00:47:25.686398 19044 net.cpp:228] data_hdf5 does not need backward computation.
I0525 00:47:25.686408 19044 net.cpp:270] This network produces output accuracy
I0525 00:47:25.686419 19044 net.cpp:270] This network produces output loss
I0525 00:47:25.686446 19044 net.cpp:283] Network initialization done.
I0525 00:47:25.686579 19044 solver.cpp:60] Solver scaffolding done.
I0525 00:47:25.687714 19044 caffe.cpp:212] Starting Optimization
I0525 00:47:25.687732 19044 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 00:47:25.687747 19044 solver.cpp:289] Learning Rate Policy: fixed
I0525 00:47:25.688817 19044 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 00:48:13.997848 19044 solver.cpp:409]     Test net output #0: accuracy = 0.120813
I0525 00:48:13.998009 19044 solver.cpp:409]     Test net output #1: loss = 2.39612 (* 1 = 2.39612 loss)
I0525 00:48:14.027520 19044 solver.cpp:237] Iteration 0, loss = 2.39434
I0525 00:48:14.027559 19044 solver.cpp:253]     Train net output #0: loss = 2.39434 (* 1 = 2.39434 loss)
I0525 00:48:14.027576 19044 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0525 00:48:22.682397 19044 solver.cpp:237] Iteration 187, loss = 2.21473
I0525 00:48:22.682447 19044 solver.cpp:253]     Train net output #0: loss = 2.21473 (* 1 = 2.21473 loss)
I0525 00:48:22.682461 19044 sgd_solver.cpp:106] Iteration 187, lr = 0.0045
I0525 00:48:31.336712 19044 solver.cpp:237] Iteration 374, loss = 1.96576
I0525 00:48:31.336750 19044 solver.cpp:253]     Train net output #0: loss = 1.96576 (* 1 = 1.96576 loss)
I0525 00:48:31.336766 19044 sgd_solver.cpp:106] Iteration 374, lr = 0.0045
I0525 00:48:39.992791 19044 solver.cpp:237] Iteration 561, loss = 1.86212
I0525 00:48:39.992828 19044 solver.cpp:253]     Train net output #0: loss = 1.86212 (* 1 = 1.86212 loss)
I0525 00:48:39.992842 19044 sgd_solver.cpp:106] Iteration 561, lr = 0.0045
I0525 00:48:48.650796 19044 solver.cpp:237] Iteration 748, loss = 1.87538
I0525 00:48:48.650954 19044 solver.cpp:253]     Train net output #0: loss = 1.87538 (* 1 = 1.87538 loss)
I0525 00:48:48.650969 19044 sgd_solver.cpp:106] Iteration 748, lr = 0.0045
I0525 00:48:57.310055 19044 solver.cpp:237] Iteration 935, loss = 1.90074
I0525 00:48:57.310091 19044 solver.cpp:253]     Train net output #0: loss = 1.90074 (* 1 = 1.90074 loss)
I0525 00:48:57.310108 19044 sgd_solver.cpp:106] Iteration 935, lr = 0.0045
I0525 00:49:05.967849 19044 solver.cpp:237] Iteration 1122, loss = 1.85334
I0525 00:49:05.967886 19044 solver.cpp:253]     Train net output #0: loss = 1.85334 (* 1 = 1.85334 loss)
I0525 00:49:05.967902 19044 sgd_solver.cpp:106] Iteration 1122, lr = 0.0045
I0525 00:49:36.732619 19044 solver.cpp:237] Iteration 1309, loss = 1.74819
I0525 00:49:36.732780 19044 solver.cpp:253]     Train net output #0: loss = 1.74819 (* 1 = 1.74819 loss)
I0525 00:49:36.732796 19044 sgd_solver.cpp:106] Iteration 1309, lr = 0.0045
I0525 00:49:45.394803 19044 solver.cpp:237] Iteration 1496, loss = 1.74866
I0525 00:49:45.394839 19044 solver.cpp:253]     Train net output #0: loss = 1.74866 (* 1 = 1.74866 loss)
I0525 00:49:45.394855 19044 sgd_solver.cpp:106] Iteration 1496, lr = 0.0045
I0525 00:49:54.056345 19044 solver.cpp:237] Iteration 1683, loss = 1.69435
I0525 00:49:54.056375 19044 solver.cpp:253]     Train net output #0: loss = 1.69435 (* 1 = 1.69435 loss)
I0525 00:49:54.056388 19044 sgd_solver.cpp:106] Iteration 1683, lr = 0.0045
I0525 00:50:02.718423 19044 solver.cpp:237] Iteration 1870, loss = 1.65614
I0525 00:50:02.718472 19044 solver.cpp:253]     Train net output #0: loss = 1.65614 (* 1 = 1.65614 loss)
I0525 00:50:02.718487 19044 sgd_solver.cpp:106] Iteration 1870, lr = 0.0045
I0525 00:50:02.903858 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_1875.caffemodel
I0525 00:50:02.977377 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_1875.solverstate
I0525 00:50:11.447666 19044 solver.cpp:237] Iteration 2057, loss = 1.55352
I0525 00:50:11.447818 19044 solver.cpp:253]     Train net output #0: loss = 1.55352 (* 1 = 1.55352 loss)
I0525 00:50:11.447832 19044 sgd_solver.cpp:106] Iteration 2057, lr = 0.0045
I0525 00:50:20.105547 19044 solver.cpp:237] Iteration 2244, loss = 1.72214
I0525 00:50:20.105582 19044 solver.cpp:253]     Train net output #0: loss = 1.72214 (* 1 = 1.72214 loss)
I0525 00:50:20.105599 19044 sgd_solver.cpp:106] Iteration 2244, lr = 0.0045
I0525 00:50:28.760262 19044 solver.cpp:237] Iteration 2431, loss = 1.51923
I0525 00:50:28.760304 19044 solver.cpp:253]     Train net output #0: loss = 1.51923 (* 1 = 1.51923 loss)
I0525 00:50:28.760323 19044 sgd_solver.cpp:106] Iteration 2431, lr = 0.0045
I0525 00:50:59.535975 19044 solver.cpp:237] Iteration 2618, loss = 1.61171
I0525 00:50:59.536133 19044 solver.cpp:253]     Train net output #0: loss = 1.61171 (* 1 = 1.61171 loss)
I0525 00:50:59.536147 19044 sgd_solver.cpp:106] Iteration 2618, lr = 0.0045
I0525 00:51:08.199921 19044 solver.cpp:237] Iteration 2805, loss = 1.48563
I0525 00:51:08.199971 19044 solver.cpp:253]     Train net output #0: loss = 1.48563 (* 1 = 1.48563 loss)
I0525 00:51:08.199985 19044 sgd_solver.cpp:106] Iteration 2805, lr = 0.0045
I0525 00:51:16.861102 19044 solver.cpp:237] Iteration 2992, loss = 1.30787
I0525 00:51:16.861145 19044 solver.cpp:253]     Train net output #0: loss = 1.30787 (* 1 = 1.30787 loss)
I0525 00:51:16.861160 19044 sgd_solver.cpp:106] Iteration 2992, lr = 0.0045
I0525 00:51:25.522580 19044 solver.cpp:237] Iteration 3179, loss = 1.46922
I0525 00:51:25.522616 19044 solver.cpp:253]     Train net output #0: loss = 1.46922 (* 1 = 1.46922 loss)
I0525 00:51:25.522629 19044 sgd_solver.cpp:106] Iteration 3179, lr = 0.0045
I0525 00:51:34.185647 19044 solver.cpp:237] Iteration 3366, loss = 1.39468
I0525 00:51:34.185796 19044 solver.cpp:253]     Train net output #0: loss = 1.39468 (* 1 = 1.39468 loss)
I0525 00:51:34.185808 19044 sgd_solver.cpp:106] Iteration 3366, lr = 0.0045
I0525 00:51:42.847688 19044 solver.cpp:237] Iteration 3553, loss = 1.27186
I0525 00:51:42.847729 19044 solver.cpp:253]     Train net output #0: loss = 1.27186 (* 1 = 1.27186 loss)
I0525 00:51:42.847748 19044 sgd_solver.cpp:106] Iteration 3553, lr = 0.0045
I0525 00:51:51.507772 19044 solver.cpp:237] Iteration 3740, loss = 1.49374
I0525 00:51:51.507807 19044 solver.cpp:253]     Train net output #0: loss = 1.49374 (* 1 = 1.49374 loss)
I0525 00:51:51.507823 19044 sgd_solver.cpp:106] Iteration 3740, lr = 0.0045
I0525 00:51:51.925153 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_3750.caffemodel
I0525 00:51:51.994990 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_3750.solverstate
I0525 00:51:52.023190 19044 solver.cpp:341] Iteration 3750, Testing net (#0)
I0525 00:52:39.391810 19044 solver.cpp:409]     Test net output #0: accuracy = 0.800233
I0525 00:52:39.391968 19044 solver.cpp:409]     Test net output #1: loss = 0.660113 (* 1 = 0.660113 loss)
I0525 00:53:09.721915 19044 solver.cpp:237] Iteration 3927, loss = 1.54641
I0525 00:53:09.722074 19044 solver.cpp:253]     Train net output #0: loss = 1.54641 (* 1 = 1.54641 loss)
I0525 00:53:09.722089 19044 sgd_solver.cpp:106] Iteration 3927, lr = 0.0045
I0525 00:53:18.372215 19044 solver.cpp:237] Iteration 4114, loss = 1.30828
I0525 00:53:18.372258 19044 solver.cpp:253]     Train net output #0: loss = 1.30828 (* 1 = 1.30828 loss)
I0525 00:53:18.372277 19044 sgd_solver.cpp:106] Iteration 4114, lr = 0.0045
I0525 00:53:27.018487 19044 solver.cpp:237] Iteration 4301, loss = 1.28867
I0525 00:53:27.018523 19044 solver.cpp:253]     Train net output #0: loss = 1.28867 (* 1 = 1.28867 loss)
I0525 00:53:27.018540 19044 sgd_solver.cpp:106] Iteration 4301, lr = 0.0045
I0525 00:53:35.672416 19044 solver.cpp:237] Iteration 4488, loss = 1.56339
I0525 00:53:35.672451 19044 solver.cpp:253]     Train net output #0: loss = 1.56339 (* 1 = 1.56339 loss)
I0525 00:53:35.672466 19044 sgd_solver.cpp:106] Iteration 4488, lr = 0.0045
I0525 00:53:44.321204 19044 solver.cpp:237] Iteration 4675, loss = 1.47925
I0525 00:53:44.321355 19044 solver.cpp:253]     Train net output #0: loss = 1.47925 (* 1 = 1.47925 loss)
I0525 00:53:44.321369 19044 sgd_solver.cpp:106] Iteration 4675, lr = 0.0045
I0525 00:53:52.969218 19044 solver.cpp:237] Iteration 4862, loss = 1.27106
I0525 00:53:52.969252 19044 solver.cpp:253]     Train net output #0: loss = 1.27106 (* 1 = 1.27106 loss)
I0525 00:53:52.969270 19044 sgd_solver.cpp:106] Iteration 4862, lr = 0.0045
I0525 00:54:23.774015 19044 solver.cpp:237] Iteration 5049, loss = 1.45679
I0525 00:54:23.774183 19044 solver.cpp:253]     Train net output #0: loss = 1.45679 (* 1 = 1.45679 loss)
I0525 00:54:23.774199 19044 sgd_solver.cpp:106] Iteration 5049, lr = 0.0045
I0525 00:54:32.423738 19044 solver.cpp:237] Iteration 5236, loss = 1.30373
I0525 00:54:32.423774 19044 solver.cpp:253]     Train net output #0: loss = 1.30373 (* 1 = 1.30373 loss)
I0525 00:54:32.423786 19044 sgd_solver.cpp:106] Iteration 5236, lr = 0.0045
I0525 00:54:41.071972 19044 solver.cpp:237] Iteration 5423, loss = 1.25918
I0525 00:54:41.072005 19044 solver.cpp:253]     Train net output #0: loss = 1.25918 (* 1 = 1.25918 loss)
I0525 00:54:41.072027 19044 sgd_solver.cpp:106] Iteration 5423, lr = 0.0045
I0525 00:54:49.721544 19044 solver.cpp:237] Iteration 5610, loss = 1.11817
I0525 00:54:49.721580 19044 solver.cpp:253]     Train net output #0: loss = 1.11817 (* 1 = 1.11817 loss)
I0525 00:54:49.721596 19044 sgd_solver.cpp:106] Iteration 5610, lr = 0.0045
I0525 00:54:50.370093 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_5625.caffemodel
I0525 00:54:50.442343 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_5625.solverstate
I0525 00:54:58.444501 19044 solver.cpp:237] Iteration 5797, loss = 1.29499
I0525 00:54:58.444666 19044 solver.cpp:253]     Train net output #0: loss = 1.29499 (* 1 = 1.29499 loss)
I0525 00:54:58.444681 19044 sgd_solver.cpp:106] Iteration 5797, lr = 0.0045
I0525 00:55:07.091928 19044 solver.cpp:237] Iteration 5984, loss = 1.31479
I0525 00:55:07.091963 19044 solver.cpp:253]     Train net output #0: loss = 1.31479 (* 1 = 1.31479 loss)
I0525 00:55:07.091979 19044 sgd_solver.cpp:106] Iteration 5984, lr = 0.0045
I0525 00:55:15.743777 19044 solver.cpp:237] Iteration 6171, loss = 1.60194
I0525 00:55:15.743811 19044 solver.cpp:253]     Train net output #0: loss = 1.60194 (* 1 = 1.60194 loss)
I0525 00:55:15.743829 19044 sgd_solver.cpp:106] Iteration 6171, lr = 0.0045
I0525 00:55:46.593786 19044 solver.cpp:237] Iteration 6358, loss = 1.20299
I0525 00:55:46.593952 19044 solver.cpp:253]     Train net output #0: loss = 1.20299 (* 1 = 1.20299 loss)
I0525 00:55:46.593968 19044 sgd_solver.cpp:106] Iteration 6358, lr = 0.0045
I0525 00:55:55.245213 19044 solver.cpp:237] Iteration 6545, loss = 1.37647
I0525 00:55:55.245251 19044 solver.cpp:253]     Train net output #0: loss = 1.37647 (* 1 = 1.37647 loss)
I0525 00:55:55.245268 19044 sgd_solver.cpp:106] Iteration 6545, lr = 0.0045
I0525 00:56:03.896980 19044 solver.cpp:237] Iteration 6732, loss = 1.17083
I0525 00:56:03.897016 19044 solver.cpp:253]     Train net output #0: loss = 1.17083 (* 1 = 1.17083 loss)
I0525 00:56:03.897032 19044 sgd_solver.cpp:106] Iteration 6732, lr = 0.0045
I0525 00:56:12.543548 19044 solver.cpp:237] Iteration 6919, loss = 1.21852
I0525 00:56:12.543582 19044 solver.cpp:253]     Train net output #0: loss = 1.21852 (* 1 = 1.21852 loss)
I0525 00:56:12.543601 19044 sgd_solver.cpp:106] Iteration 6919, lr = 0.0045
I0525 00:56:21.193054 19044 solver.cpp:237] Iteration 7106, loss = 1.26021
I0525 00:56:21.193195 19044 solver.cpp:253]     Train net output #0: loss = 1.26021 (* 1 = 1.26021 loss)
I0525 00:56:21.193209 19044 sgd_solver.cpp:106] Iteration 7106, lr = 0.0045
I0525 00:56:29.842715 19044 solver.cpp:237] Iteration 7293, loss = 1.12687
I0525 00:56:29.842749 19044 solver.cpp:253]     Train net output #0: loss = 1.12687 (* 1 = 1.12687 loss)
I0525 00:56:29.842764 19044 sgd_solver.cpp:106] Iteration 7293, lr = 0.0045
I0525 00:56:38.491197 19044 solver.cpp:237] Iteration 7480, loss = 1.49579
I0525 00:56:38.491235 19044 solver.cpp:253]     Train net output #0: loss = 1.49579 (* 1 = 1.49579 loss)
I0525 00:56:38.491256 19044 sgd_solver.cpp:106] Iteration 7480, lr = 0.0045
I0525 00:56:39.370896 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_7500.caffemodel
I0525 00:56:39.442520 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_7500.solverstate
I0525 00:56:39.470093 19044 solver.cpp:341] Iteration 7500, Testing net (#0)
I0525 00:57:47.619212 19044 solver.cpp:409]     Test net output #0: accuracy = 0.842714
I0525 00:57:47.619384 19044 solver.cpp:409]     Test net output #1: loss = 0.56348 (* 1 = 0.56348 loss)
I0525 00:58:17.510706 19044 solver.cpp:237] Iteration 7667, loss = 1.32137
I0525 00:58:17.510757 19044 solver.cpp:253]     Train net output #0: loss = 1.32137 (* 1 = 1.32137 loss)
I0525 00:58:17.510772 19044 sgd_solver.cpp:106] Iteration 7667, lr = 0.0045
I0525 00:58:26.176403 19044 solver.cpp:237] Iteration 7854, loss = 1.27903
I0525 00:58:26.176551 19044 solver.cpp:253]     Train net output #0: loss = 1.27903 (* 1 = 1.27903 loss)
I0525 00:58:26.176565 19044 sgd_solver.cpp:106] Iteration 7854, lr = 0.0045
I0525 00:58:34.837719 19044 solver.cpp:237] Iteration 8041, loss = 1.15951
I0525 00:58:34.837754 19044 solver.cpp:253]     Train net output #0: loss = 1.15951 (* 1 = 1.15951 loss)
I0525 00:58:34.837770 19044 sgd_solver.cpp:106] Iteration 8041, lr = 0.0045
I0525 00:58:43.500069 19044 solver.cpp:237] Iteration 8228, loss = 1.2176
I0525 00:58:43.500126 19044 solver.cpp:253]     Train net output #0: loss = 1.2176 (* 1 = 1.2176 loss)
I0525 00:58:43.500140 19044 sgd_solver.cpp:106] Iteration 8228, lr = 0.0045
I0525 00:58:52.166040 19044 solver.cpp:237] Iteration 8415, loss = 1.28222
I0525 00:58:52.166077 19044 solver.cpp:253]     Train net output #0: loss = 1.28222 (* 1 = 1.28222 loss)
I0525 00:58:52.166095 19044 sgd_solver.cpp:106] Iteration 8415, lr = 0.0045
I0525 00:59:00.829380 19044 solver.cpp:237] Iteration 8602, loss = 1.43498
I0525 00:59:00.829530 19044 solver.cpp:253]     Train net output #0: loss = 1.43498 (* 1 = 1.43498 loss)
I0525 00:59:00.829543 19044 sgd_solver.cpp:106] Iteration 8602, lr = 0.0045
I0525 00:59:31.640910 19044 solver.cpp:237] Iteration 8789, loss = 1.22725
I0525 00:59:31.641078 19044 solver.cpp:253]     Train net output #0: loss = 1.22725 (* 1 = 1.22725 loss)
I0525 00:59:31.641094 19044 sgd_solver.cpp:106] Iteration 8789, lr = 0.0045
I0525 00:59:40.305892 19044 solver.cpp:237] Iteration 8976, loss = 1.43685
I0525 00:59:40.305927 19044 solver.cpp:253]     Train net output #0: loss = 1.43685 (* 1 = 1.43685 loss)
I0525 00:59:40.305948 19044 sgd_solver.cpp:106] Iteration 8976, lr = 0.0045
I0525 00:59:48.968557 19044 solver.cpp:237] Iteration 9163, loss = 1.31413
I0525 00:59:48.968592 19044 solver.cpp:253]     Train net output #0: loss = 1.31413 (* 1 = 1.31413 loss)
I0525 00:59:48.968610 19044 sgd_solver.cpp:106] Iteration 9163, lr = 0.0045
I0525 00:59:57.631119 19044 solver.cpp:237] Iteration 9350, loss = 1.20319
I0525 00:59:57.631155 19044 solver.cpp:253]     Train net output #0: loss = 1.20319 (* 1 = 1.20319 loss)
I0525 00:59:57.631170 19044 sgd_solver.cpp:106] Iteration 9350, lr = 0.0045
I0525 00:59:58.744472 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_9375.caffemodel
I0525 00:59:58.815436 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_9375.solverstate
I0525 01:00:06.361057 19044 solver.cpp:237] Iteration 9537, loss = 1.355
I0525 01:00:06.361218 19044 solver.cpp:253]     Train net output #0: loss = 1.355 (* 1 = 1.355 loss)
I0525 01:00:06.361232 19044 sgd_solver.cpp:106] Iteration 9537, lr = 0.0045
I0525 01:00:15.023636 19044 solver.cpp:237] Iteration 9724, loss = 1.33955
I0525 01:00:15.023670 19044 solver.cpp:253]     Train net output #0: loss = 1.33955 (* 1 = 1.33955 loss)
I0525 01:00:15.023687 19044 sgd_solver.cpp:106] Iteration 9724, lr = 0.0045
I0525 01:00:23.688124 19044 solver.cpp:237] Iteration 9911, loss = 1.36119
I0525 01:00:23.688170 19044 solver.cpp:253]     Train net output #0: loss = 1.36119 (* 1 = 1.36119 loss)
I0525 01:00:23.688187 19044 sgd_solver.cpp:106] Iteration 9911, lr = 0.0045
I0525 01:00:54.513772 19044 solver.cpp:237] Iteration 10098, loss = 1.15178
I0525 01:00:54.513943 19044 solver.cpp:253]     Train net output #0: loss = 1.15178 (* 1 = 1.15178 loss)
I0525 01:00:54.513959 19044 sgd_solver.cpp:106] Iteration 10098, lr = 0.0045
I0525 01:01:03.176853 19044 solver.cpp:237] Iteration 10285, loss = 1.34557
I0525 01:01:03.176888 19044 solver.cpp:253]     Train net output #0: loss = 1.34557 (* 1 = 1.34557 loss)
I0525 01:01:03.176905 19044 sgd_solver.cpp:106] Iteration 10285, lr = 0.0045
I0525 01:01:11.841190 19044 solver.cpp:237] Iteration 10472, loss = 1.2855
I0525 01:01:11.841225 19044 solver.cpp:253]     Train net output #0: loss = 1.2855 (* 1 = 1.2855 loss)
I0525 01:01:11.841243 19044 sgd_solver.cpp:106] Iteration 10472, lr = 0.0045
I0525 01:01:20.501488 19044 solver.cpp:237] Iteration 10659, loss = 1.19202
I0525 01:01:20.501531 19044 solver.cpp:253]     Train net output #0: loss = 1.19202 (* 1 = 1.19202 loss)
I0525 01:01:20.501546 19044 sgd_solver.cpp:106] Iteration 10659, lr = 0.0045
I0525 01:01:29.166570 19044 solver.cpp:237] Iteration 10846, loss = 1.19459
I0525 01:01:29.166714 19044 solver.cpp:253]     Train net output #0: loss = 1.19459 (* 1 = 1.19459 loss)
I0525 01:01:29.166730 19044 sgd_solver.cpp:106] Iteration 10846, lr = 0.0045
I0525 01:01:37.830978 19044 solver.cpp:237] Iteration 11033, loss = 1.30167
I0525 01:01:37.831013 19044 solver.cpp:253]     Train net output #0: loss = 1.30167 (* 1 = 1.30167 loss)
I0525 01:01:37.831027 19044 sgd_solver.cpp:106] Iteration 11033, lr = 0.0045
I0525 01:01:46.495591 19044 solver.cpp:237] Iteration 11220, loss = 1.0907
I0525 01:01:46.495628 19044 solver.cpp:253]     Train net output #0: loss = 1.0907 (* 1 = 1.0907 loss)
I0525 01:01:46.495647 19044 sgd_solver.cpp:106] Iteration 11220, lr = 0.0045
I0525 01:01:47.838431 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_11250.caffemodel
I0525 01:01:47.907677 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_11250.solverstate
I0525 01:01:47.932994 19044 solver.cpp:341] Iteration 11250, Testing net (#0)
I0525 01:02:34.995930 19044 solver.cpp:409]     Test net output #0: accuracy = 0.856866
I0525 01:02:34.996089 19044 solver.cpp:409]     Test net output #1: loss = 0.47012 (* 1 = 0.47012 loss)
I0525 01:03:04.413192 19044 solver.cpp:237] Iteration 11407, loss = 0.937139
I0525 01:03:04.413244 19044 solver.cpp:253]     Train net output #0: loss = 0.937139 (* 1 = 0.937139 loss)
I0525 01:03:04.413259 19044 sgd_solver.cpp:106] Iteration 11407, lr = 0.0045
I0525 01:03:13.071058 19044 solver.cpp:237] Iteration 11594, loss = 1.38977
I0525 01:03:13.071209 19044 solver.cpp:253]     Train net output #0: loss = 1.38977 (* 1 = 1.38977 loss)
I0525 01:03:13.071223 19044 sgd_solver.cpp:106] Iteration 11594, lr = 0.0045
I0525 01:03:21.729576 19044 solver.cpp:237] Iteration 11781, loss = 1.47142
I0525 01:03:21.729621 19044 solver.cpp:253]     Train net output #0: loss = 1.47142 (* 1 = 1.47142 loss)
I0525 01:03:21.729638 19044 sgd_solver.cpp:106] Iteration 11781, lr = 0.0045
I0525 01:03:30.384163 19044 solver.cpp:237] Iteration 11968, loss = 1.00711
I0525 01:03:30.384198 19044 solver.cpp:253]     Train net output #0: loss = 1.00711 (* 1 = 1.00711 loss)
I0525 01:03:30.384214 19044 sgd_solver.cpp:106] Iteration 11968, lr = 0.0045
I0525 01:03:39.039971 19044 solver.cpp:237] Iteration 12155, loss = 1.17276
I0525 01:03:39.040006 19044 solver.cpp:253]     Train net output #0: loss = 1.17276 (* 1 = 1.17276 loss)
I0525 01:03:39.040022 19044 sgd_solver.cpp:106] Iteration 12155, lr = 0.0045
I0525 01:03:47.696677 19044 solver.cpp:237] Iteration 12342, loss = 1.28391
I0525 01:03:47.696825 19044 solver.cpp:253]     Train net output #0: loss = 1.28391 (* 1 = 1.28391 loss)
I0525 01:03:47.696840 19044 sgd_solver.cpp:106] Iteration 12342, lr = 0.0045
I0525 01:04:18.502712 19044 solver.cpp:237] Iteration 12529, loss = 1.08542
I0525 01:04:18.502882 19044 solver.cpp:253]     Train net output #0: loss = 1.08542 (* 1 = 1.08542 loss)
I0525 01:04:18.502897 19044 sgd_solver.cpp:106] Iteration 12529, lr = 0.0045
I0525 01:04:27.158465 19044 solver.cpp:237] Iteration 12716, loss = 1.37981
I0525 01:04:27.158501 19044 solver.cpp:253]     Train net output #0: loss = 1.37981 (* 1 = 1.37981 loss)
I0525 01:04:27.158517 19044 sgd_solver.cpp:106] Iteration 12716, lr = 0.0045
I0525 01:04:35.814924 19044 solver.cpp:237] Iteration 12903, loss = 1.20575
I0525 01:04:35.814972 19044 solver.cpp:253]     Train net output #0: loss = 1.20575 (* 1 = 1.20575 loss)
I0525 01:04:35.814990 19044 sgd_solver.cpp:106] Iteration 12903, lr = 0.0045
I0525 01:04:44.468966 19044 solver.cpp:237] Iteration 13090, loss = 1.20145
I0525 01:04:44.469002 19044 solver.cpp:253]     Train net output #0: loss = 1.20145 (* 1 = 1.20145 loss)
I0525 01:04:44.469018 19044 sgd_solver.cpp:106] Iteration 13090, lr = 0.0045
I0525 01:04:46.044961 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_13125.caffemodel
I0525 01:04:46.114500 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_13125.solverstate
I0525 01:04:53.190989 19044 solver.cpp:237] Iteration 13277, loss = 1.07966
I0525 01:04:53.191149 19044 solver.cpp:253]     Train net output #0: loss = 1.07966 (* 1 = 1.07966 loss)
I0525 01:04:53.191164 19044 sgd_solver.cpp:106] Iteration 13277, lr = 0.0045
I0525 01:05:01.841547 19044 solver.cpp:237] Iteration 13464, loss = 1.34726
I0525 01:05:01.841590 19044 solver.cpp:253]     Train net output #0: loss = 1.34726 (* 1 = 1.34726 loss)
I0525 01:05:01.841604 19044 sgd_solver.cpp:106] Iteration 13464, lr = 0.0045
I0525 01:05:10.500216 19044 solver.cpp:237] Iteration 13651, loss = 1.25081
I0525 01:05:10.500252 19044 solver.cpp:253]     Train net output #0: loss = 1.25081 (* 1 = 1.25081 loss)
I0525 01:05:10.500268 19044 sgd_solver.cpp:106] Iteration 13651, lr = 0.0045
I0525 01:05:41.308202 19044 solver.cpp:237] Iteration 13838, loss = 1.37977
I0525 01:05:41.308367 19044 solver.cpp:253]     Train net output #0: loss = 1.37977 (* 1 = 1.37977 loss)
I0525 01:05:41.308382 19044 sgd_solver.cpp:106] Iteration 13838, lr = 0.0045
I0525 01:05:49.962019 19044 solver.cpp:237] Iteration 14025, loss = 1.31445
I0525 01:05:49.962062 19044 solver.cpp:253]     Train net output #0: loss = 1.31445 (* 1 = 1.31445 loss)
I0525 01:05:49.962081 19044 sgd_solver.cpp:106] Iteration 14025, lr = 0.0045
I0525 01:05:58.614864 19044 solver.cpp:237] Iteration 14212, loss = 1.24705
I0525 01:05:58.614900 19044 solver.cpp:253]     Train net output #0: loss = 1.24705 (* 1 = 1.24705 loss)
I0525 01:05:58.614915 19044 sgd_solver.cpp:106] Iteration 14212, lr = 0.0045
I0525 01:06:07.271143 19044 solver.cpp:237] Iteration 14399, loss = 1.25865
I0525 01:06:07.271179 19044 solver.cpp:253]     Train net output #0: loss = 1.25865 (* 1 = 1.25865 loss)
I0525 01:06:07.271195 19044 sgd_solver.cpp:106] Iteration 14399, lr = 0.0045
I0525 01:06:15.929167 19044 solver.cpp:237] Iteration 14586, loss = 1.39747
I0525 01:06:15.929329 19044 solver.cpp:253]     Train net output #0: loss = 1.39747 (* 1 = 1.39747 loss)
I0525 01:06:15.929344 19044 sgd_solver.cpp:106] Iteration 14586, lr = 0.0045
I0525 01:06:24.585701 19044 solver.cpp:237] Iteration 14773, loss = 1.48221
I0525 01:06:24.585736 19044 solver.cpp:253]     Train net output #0: loss = 1.48221 (* 1 = 1.48221 loss)
I0525 01:06:24.585753 19044 sgd_solver.cpp:106] Iteration 14773, lr = 0.0045
I0525 01:06:33.241511 19044 solver.cpp:237] Iteration 14960, loss = 1.38899
I0525 01:06:33.241546 19044 solver.cpp:253]     Train net output #0: loss = 1.38899 (* 1 = 1.38899 loss)
I0525 01:06:33.241561 19044 sgd_solver.cpp:106] Iteration 14960, lr = 0.0045
I0525 01:06:35.046597 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_15000.caffemodel
I0525 01:06:35.116250 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_15000.solverstate
I0525 01:06:35.141434 19044 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 01:07:43.316386 19044 solver.cpp:409]     Test net output #0: accuracy = 0.862654
I0525 01:07:43.316563 19044 solver.cpp:409]     Test net output #1: loss = 0.441601 (* 1 = 0.441601 loss)
I0525 01:08:12.280557 19044 solver.cpp:237] Iteration 15147, loss = 1.3467
I0525 01:08:12.280608 19044 solver.cpp:253]     Train net output #0: loss = 1.3467 (* 1 = 1.3467 loss)
I0525 01:08:12.280624 19044 sgd_solver.cpp:106] Iteration 15147, lr = 0.0045
I0525 01:08:20.948567 19044 solver.cpp:237] Iteration 15334, loss = 1.24332
I0525 01:08:20.948729 19044 solver.cpp:253]     Train net output #0: loss = 1.24332 (* 1 = 1.24332 loss)
I0525 01:08:20.948742 19044 sgd_solver.cpp:106] Iteration 15334, lr = 0.0045
I0525 01:08:29.609800 19044 solver.cpp:237] Iteration 15521, loss = 1.29773
I0525 01:08:29.609835 19044 solver.cpp:253]     Train net output #0: loss = 1.29773 (* 1 = 1.29773 loss)
I0525 01:08:29.609853 19044 sgd_solver.cpp:106] Iteration 15521, lr = 0.0045
I0525 01:08:38.265785 19044 solver.cpp:237] Iteration 15708, loss = 0.980748
I0525 01:08:38.265822 19044 solver.cpp:253]     Train net output #0: loss = 0.980748 (* 1 = 0.980748 loss)
I0525 01:08:38.265837 19044 sgd_solver.cpp:106] Iteration 15708, lr = 0.0045
I0525 01:08:46.925668 19044 solver.cpp:237] Iteration 15895, loss = 1.22612
I0525 01:08:46.925709 19044 solver.cpp:253]     Train net output #0: loss = 1.22612 (* 1 = 1.22612 loss)
I0525 01:08:46.925730 19044 sgd_solver.cpp:106] Iteration 15895, lr = 0.0045
I0525 01:08:55.585887 19044 solver.cpp:237] Iteration 16082, loss = 1.54913
I0525 01:08:55.586040 19044 solver.cpp:253]     Train net output #0: loss = 1.54913 (* 1 = 1.54913 loss)
I0525 01:08:55.586055 19044 sgd_solver.cpp:106] Iteration 16082, lr = 0.0045
I0525 01:09:26.377249 19044 solver.cpp:237] Iteration 16269, loss = 0.95783
I0525 01:09:26.377421 19044 solver.cpp:253]     Train net output #0: loss = 0.95783 (* 1 = 0.95783 loss)
I0525 01:09:26.377437 19044 sgd_solver.cpp:106] Iteration 16269, lr = 0.0045
I0525 01:09:35.037848 19044 solver.cpp:237] Iteration 16456, loss = 1.29017
I0525 01:09:35.037889 19044 solver.cpp:253]     Train net output #0: loss = 1.29017 (* 1 = 1.29017 loss)
I0525 01:09:35.037906 19044 sgd_solver.cpp:106] Iteration 16456, lr = 0.0045
I0525 01:09:43.697732 19044 solver.cpp:237] Iteration 16643, loss = 1.186
I0525 01:09:43.697767 19044 solver.cpp:253]     Train net output #0: loss = 1.186 (* 1 = 1.186 loss)
I0525 01:09:43.697783 19044 sgd_solver.cpp:106] Iteration 16643, lr = 0.0045
I0525 01:09:52.355985 19044 solver.cpp:237] Iteration 16830, loss = 1.24559
I0525 01:09:52.356021 19044 solver.cpp:253]     Train net output #0: loss = 1.24559 (* 1 = 1.24559 loss)
I0525 01:09:52.356039 19044 sgd_solver.cpp:106] Iteration 16830, lr = 0.0045
I0525 01:09:54.394951 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_16875.caffemodel
I0525 01:09:54.465554 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_16875.solverstate
I0525 01:10:01.088528 19044 solver.cpp:237] Iteration 17017, loss = 1.14015
I0525 01:10:01.088692 19044 solver.cpp:253]     Train net output #0: loss = 1.14015 (* 1 = 1.14015 loss)
I0525 01:10:01.088706 19044 sgd_solver.cpp:106] Iteration 17017, lr = 0.0045
I0525 01:10:09.752120 19044 solver.cpp:237] Iteration 17204, loss = 1.09962
I0525 01:10:09.752154 19044 solver.cpp:253]     Train net output #0: loss = 1.09962 (* 1 = 1.09962 loss)
I0525 01:10:09.752171 19044 sgd_solver.cpp:106] Iteration 17204, lr = 0.0045
I0525 01:10:18.415467 19044 solver.cpp:237] Iteration 17391, loss = 1.10136
I0525 01:10:18.415503 19044 solver.cpp:253]     Train net output #0: loss = 1.10136 (* 1 = 1.10136 loss)
I0525 01:10:18.415518 19044 sgd_solver.cpp:106] Iteration 17391, lr = 0.0045
I0525 01:10:49.199674 19044 solver.cpp:237] Iteration 17578, loss = 1.43127
I0525 01:10:49.199852 19044 solver.cpp:253]     Train net output #0: loss = 1.43127 (* 1 = 1.43127 loss)
I0525 01:10:49.199867 19044 sgd_solver.cpp:106] Iteration 17578, lr = 0.0045
I0525 01:10:57.856782 19044 solver.cpp:237] Iteration 17765, loss = 1.04212
I0525 01:10:57.856817 19044 solver.cpp:253]     Train net output #0: loss = 1.04212 (* 1 = 1.04212 loss)
I0525 01:10:57.856834 19044 sgd_solver.cpp:106] Iteration 17765, lr = 0.0045
I0525 01:11:06.511186 19044 solver.cpp:237] Iteration 17952, loss = 0.973197
I0525 01:11:06.511222 19044 solver.cpp:253]     Train net output #0: loss = 0.973197 (* 1 = 0.973197 loss)
I0525 01:11:06.511236 19044 sgd_solver.cpp:106] Iteration 17952, lr = 0.0045
I0525 01:11:15.170635 19044 solver.cpp:237] Iteration 18139, loss = 1.28338
I0525 01:11:15.170680 19044 solver.cpp:253]     Train net output #0: loss = 1.28338 (* 1 = 1.28338 loss)
I0525 01:11:15.170697 19044 sgd_solver.cpp:106] Iteration 18139, lr = 0.0045
I0525 01:11:23.832900 19044 solver.cpp:237] Iteration 18326, loss = 1.06437
I0525 01:11:23.833055 19044 solver.cpp:253]     Train net output #0: loss = 1.06437 (* 1 = 1.06437 loss)
I0525 01:11:23.833071 19044 sgd_solver.cpp:106] Iteration 18326, lr = 0.0045
I0525 01:11:32.492229 19044 solver.cpp:237] Iteration 18513, loss = 1.35506
I0525 01:11:32.492264 19044 solver.cpp:253]     Train net output #0: loss = 1.35506 (* 1 = 1.35506 loss)
I0525 01:11:32.492279 19044 sgd_solver.cpp:106] Iteration 18513, lr = 0.0045
I0525 01:11:41.154083 19044 solver.cpp:237] Iteration 18700, loss = 1.57883
I0525 01:11:41.154124 19044 solver.cpp:253]     Train net output #0: loss = 1.57883 (* 1 = 1.57883 loss)
I0525 01:11:41.154144 19044 sgd_solver.cpp:106] Iteration 18700, lr = 0.0045
I0525 01:11:43.424603 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_18750.caffemodel
I0525 01:11:43.496342 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_18750.solverstate
I0525 01:11:43.525046 19044 solver.cpp:341] Iteration 18750, Testing net (#0)
I0525 01:12:30.902010 19044 solver.cpp:409]     Test net output #0: accuracy = 0.868573
I0525 01:12:30.902171 19044 solver.cpp:409]     Test net output #1: loss = 0.446483 (* 1 = 0.446483 loss)
I0525 01:12:58.122443 19044 solver.cpp:237] Iteration 18887, loss = 1.15285
I0525 01:12:58.122493 19044 solver.cpp:253]     Train net output #0: loss = 1.15285 (* 1 = 1.15285 loss)
I0525 01:12:58.122509 19044 sgd_solver.cpp:106] Iteration 18887, lr = 0.0045
I0525 01:13:06.774900 19044 solver.cpp:237] Iteration 19074, loss = 1.07194
I0525 01:13:06.775049 19044 solver.cpp:253]     Train net output #0: loss = 1.07194 (* 1 = 1.07194 loss)
I0525 01:13:06.775063 19044 sgd_solver.cpp:106] Iteration 19074, lr = 0.0045
I0525 01:13:15.426553 19044 solver.cpp:237] Iteration 19261, loss = 1.1651
I0525 01:13:15.426587 19044 solver.cpp:253]     Train net output #0: loss = 1.1651 (* 1 = 1.1651 loss)
I0525 01:13:15.426601 19044 sgd_solver.cpp:106] Iteration 19261, lr = 0.0045
I0525 01:13:24.073683 19044 solver.cpp:237] Iteration 19448, loss = 1.35592
I0525 01:13:24.073725 19044 solver.cpp:253]     Train net output #0: loss = 1.35592 (* 1 = 1.35592 loss)
I0525 01:13:24.073740 19044 sgd_solver.cpp:106] Iteration 19448, lr = 0.0045
I0525 01:13:32.719741 19044 solver.cpp:237] Iteration 19635, loss = 1.12067
I0525 01:13:32.719776 19044 solver.cpp:253]     Train net output #0: loss = 1.12067 (* 1 = 1.12067 loss)
I0525 01:13:32.719792 19044 sgd_solver.cpp:106] Iteration 19635, lr = 0.0045
I0525 01:13:41.369660 19044 solver.cpp:237] Iteration 19822, loss = 0.863564
I0525 01:13:41.369819 19044 solver.cpp:253]     Train net output #0: loss = 0.863564 (* 1 = 0.863564 loss)
I0525 01:13:41.369833 19044 sgd_solver.cpp:106] Iteration 19822, lr = 0.0045
I0525 01:14:10.874642 19044 solver.cpp:237] Iteration 20009, loss = 1.24729
I0525 01:14:10.874692 19044 solver.cpp:253]     Train net output #0: loss = 1.24729 (* 1 = 1.24729 loss)
I0525 01:14:10.874711 19044 sgd_solver.cpp:106] Iteration 20009, lr = 0.0045
I0525 01:14:19.520736 19044 solver.cpp:237] Iteration 20196, loss = 1.04509
I0525 01:14:19.520889 19044 solver.cpp:253]     Train net output #0: loss = 1.04509 (* 1 = 1.04509 loss)
I0525 01:14:19.520903 19044 sgd_solver.cpp:106] Iteration 20196, lr = 0.0045
I0525 01:14:28.172579 19044 solver.cpp:237] Iteration 20383, loss = 1.1587
I0525 01:14:28.172612 19044 solver.cpp:253]     Train net output #0: loss = 1.1587 (* 1 = 1.1587 loss)
I0525 01:14:28.172631 19044 sgd_solver.cpp:106] Iteration 20383, lr = 0.0045
I0525 01:14:36.822785 19044 solver.cpp:237] Iteration 20570, loss = 1.29152
I0525 01:14:36.822831 19044 solver.cpp:253]     Train net output #0: loss = 1.29152 (* 1 = 1.29152 loss)
I0525 01:14:36.822849 19044 sgd_solver.cpp:106] Iteration 20570, lr = 0.0045
I0525 01:14:39.320503 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_20625.caffemodel
I0525 01:14:39.390694 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_20625.solverstate
I0525 01:14:45.539409 19044 solver.cpp:237] Iteration 20757, loss = 1.16163
I0525 01:14:45.539455 19044 solver.cpp:253]     Train net output #0: loss = 1.16163 (* 1 = 1.16163 loss)
I0525 01:14:45.539472 19044 sgd_solver.cpp:106] Iteration 20757, lr = 0.0045
I0525 01:14:54.191468 19044 solver.cpp:237] Iteration 20944, loss = 1.40181
I0525 01:14:54.191619 19044 solver.cpp:253]     Train net output #0: loss = 1.40181 (* 1 = 1.40181 loss)
I0525 01:14:54.191635 19044 sgd_solver.cpp:106] Iteration 20944, lr = 0.0045
I0525 01:15:02.842628 19044 solver.cpp:237] Iteration 21131, loss = 1.11283
I0525 01:15:02.842675 19044 solver.cpp:253]     Train net output #0: loss = 1.11283 (* 1 = 1.11283 loss)
I0525 01:15:02.842689 19044 sgd_solver.cpp:106] Iteration 21131, lr = 0.0045
I0525 01:15:32.368975 19044 solver.cpp:237] Iteration 21318, loss = 1.23781
I0525 01:15:32.369155 19044 solver.cpp:253]     Train net output #0: loss = 1.23781 (* 1 = 1.23781 loss)
I0525 01:15:32.369170 19044 sgd_solver.cpp:106] Iteration 21318, lr = 0.0045
I0525 01:15:41.017658 19044 solver.cpp:237] Iteration 21505, loss = 1.25906
I0525 01:15:41.017693 19044 solver.cpp:253]     Train net output #0: loss = 1.25906 (* 1 = 1.25906 loss)
I0525 01:15:41.017710 19044 sgd_solver.cpp:106] Iteration 21505, lr = 0.0045
I0525 01:15:49.666563 19044 solver.cpp:237] Iteration 21692, loss = 1.21777
I0525 01:15:49.666612 19044 solver.cpp:253]     Train net output #0: loss = 1.21777 (* 1 = 1.21777 loss)
I0525 01:15:49.666627 19044 sgd_solver.cpp:106] Iteration 21692, lr = 0.0045
I0525 01:15:58.315866 19044 solver.cpp:237] Iteration 21879, loss = 1.09504
I0525 01:15:58.315902 19044 solver.cpp:253]     Train net output #0: loss = 1.09504 (* 1 = 1.09504 loss)
I0525 01:15:58.315918 19044 sgd_solver.cpp:106] Iteration 21879, lr = 0.0045
I0525 01:16:06.961717 19044 solver.cpp:237] Iteration 22066, loss = 1.35645
I0525 01:16:06.961865 19044 solver.cpp:253]     Train net output #0: loss = 1.35645 (* 1 = 1.35645 loss)
I0525 01:16:06.961880 19044 sgd_solver.cpp:106] Iteration 22066, lr = 0.0045
I0525 01:16:15.610046 19044 solver.cpp:237] Iteration 22253, loss = 1.29472
I0525 01:16:15.610095 19044 solver.cpp:253]     Train net output #0: loss = 1.29472 (* 1 = 1.29472 loss)
I0525 01:16:15.610110 19044 sgd_solver.cpp:106] Iteration 22253, lr = 0.0045
I0525 01:16:24.257556 19044 solver.cpp:237] Iteration 22440, loss = 1.25181
I0525 01:16:24.257591 19044 solver.cpp:253]     Train net output #0: loss = 1.25181 (* 1 = 1.25181 loss)
I0525 01:16:24.257607 19044 sgd_solver.cpp:106] Iteration 22440, lr = 0.0045
I0525 01:16:26.987798 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_22500.caffemodel
I0525 01:16:27.057591 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_22500.solverstate
I0525 01:16:27.083772 19044 solver.cpp:341] Iteration 22500, Testing net (#0)
I0525 01:17:35.257117 19044 solver.cpp:409]     Test net output #0: accuracy = 0.873041
I0525 01:17:35.257292 19044 solver.cpp:409]     Test net output #1: loss = 0.386661 (* 1 = 0.386661 loss)
I0525 01:18:01.976475 19044 solver.cpp:237] Iteration 22627, loss = 1.32509
I0525 01:18:01.976526 19044 solver.cpp:253]     Train net output #0: loss = 1.32509 (* 1 = 1.32509 loss)
I0525 01:18:01.976542 19044 sgd_solver.cpp:106] Iteration 22627, lr = 0.0045
I0525 01:18:10.638562 19044 solver.cpp:237] Iteration 22814, loss = 1.0909
I0525 01:18:10.638712 19044 solver.cpp:253]     Train net output #0: loss = 1.0909 (* 1 = 1.0909 loss)
I0525 01:18:10.638726 19044 sgd_solver.cpp:106] Iteration 22814, lr = 0.0045
I0525 01:18:19.297370 19044 solver.cpp:237] Iteration 23001, loss = 1.27561
I0525 01:18:19.297415 19044 solver.cpp:253]     Train net output #0: loss = 1.27561 (* 1 = 1.27561 loss)
I0525 01:18:19.297431 19044 sgd_solver.cpp:106] Iteration 23001, lr = 0.0045
I0525 01:18:27.961603 19044 solver.cpp:237] Iteration 23188, loss = 1.0304
I0525 01:18:27.961638 19044 solver.cpp:253]     Train net output #0: loss = 1.0304 (* 1 = 1.0304 loss)
I0525 01:18:27.961655 19044 sgd_solver.cpp:106] Iteration 23188, lr = 0.0045
I0525 01:18:36.624816 19044 solver.cpp:237] Iteration 23375, loss = 1.23828
I0525 01:18:36.624851 19044 solver.cpp:253]     Train net output #0: loss = 1.23828 (* 1 = 1.23828 loss)
I0525 01:18:36.624864 19044 sgd_solver.cpp:106] Iteration 23375, lr = 0.0045
I0525 01:18:45.287312 19044 solver.cpp:237] Iteration 23562, loss = 1.12429
I0525 01:18:45.287475 19044 solver.cpp:253]     Train net output #0: loss = 1.12429 (* 1 = 1.12429 loss)
I0525 01:18:45.287490 19044 sgd_solver.cpp:106] Iteration 23562, lr = 0.0045
I0525 01:18:53.946630 19044 solver.cpp:237] Iteration 23749, loss = 1.29341
I0525 01:18:53.946665 19044 solver.cpp:253]     Train net output #0: loss = 1.29341 (* 1 = 1.29341 loss)
I0525 01:18:53.946681 19044 sgd_solver.cpp:106] Iteration 23749, lr = 0.0045
I0525 01:19:23.442319 19044 solver.cpp:237] Iteration 23936, loss = 1.09909
I0525 01:19:23.442489 19044 solver.cpp:253]     Train net output #0: loss = 1.09909 (* 1 = 1.09909 loss)
I0525 01:19:23.442505 19044 sgd_solver.cpp:106] Iteration 23936, lr = 0.0045
I0525 01:19:32.104246 19044 solver.cpp:237] Iteration 24123, loss = 1.38314
I0525 01:19:32.104281 19044 solver.cpp:253]     Train net output #0: loss = 1.38314 (* 1 = 1.38314 loss)
I0525 01:19:32.104298 19044 sgd_solver.cpp:106] Iteration 24123, lr = 0.0045
I0525 01:19:40.765969 19044 solver.cpp:237] Iteration 24310, loss = 1.26637
I0525 01:19:40.766012 19044 solver.cpp:253]     Train net output #0: loss = 1.26637 (* 1 = 1.26637 loss)
I0525 01:19:40.766032 19044 sgd_solver.cpp:106] Iteration 24310, lr = 0.0045
I0525 01:19:43.732326 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_24375.caffemodel
I0525 01:19:43.801944 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_24375.solverstate
I0525 01:19:49.501438 19044 solver.cpp:237] Iteration 24497, loss = 1.25938
I0525 01:19:49.501487 19044 solver.cpp:253]     Train net output #0: loss = 1.25938 (* 1 = 1.25938 loss)
I0525 01:19:49.501502 19044 sgd_solver.cpp:106] Iteration 24497, lr = 0.0045
I0525 01:19:58.165076 19044 solver.cpp:237] Iteration 24684, loss = 1.0242
I0525 01:19:58.165259 19044 solver.cpp:253]     Train net output #0: loss = 1.0242 (* 1 = 1.0242 loss)
I0525 01:19:58.165274 19044 sgd_solver.cpp:106] Iteration 24684, lr = 0.0045
I0525 01:20:06.832608 19044 solver.cpp:237] Iteration 24871, loss = 1.0425
I0525 01:20:06.832643 19044 solver.cpp:253]     Train net output #0: loss = 1.0425 (* 1 = 1.0425 loss)
I0525 01:20:06.832659 19044 sgd_solver.cpp:106] Iteration 24871, lr = 0.0045
I0525 01:20:36.316635 19044 solver.cpp:237] Iteration 25058, loss = 1.11957
I0525 01:20:36.316810 19044 solver.cpp:253]     Train net output #0: loss = 1.11957 (* 1 = 1.11957 loss)
I0525 01:20:36.316826 19044 sgd_solver.cpp:106] Iteration 25058, lr = 0.0045
I0525 01:20:44.981592 19044 solver.cpp:237] Iteration 25245, loss = 1.05145
I0525 01:20:44.981627 19044 solver.cpp:253]     Train net output #0: loss = 1.05145 (* 1 = 1.05145 loss)
I0525 01:20:44.981645 19044 sgd_solver.cpp:106] Iteration 25245, lr = 0.0045
I0525 01:20:53.645480 19044 solver.cpp:237] Iteration 25432, loss = 1.27038
I0525 01:20:53.645526 19044 solver.cpp:253]     Train net output #0: loss = 1.27038 (* 1 = 1.27038 loss)
I0525 01:20:53.645544 19044 sgd_solver.cpp:106] Iteration 25432, lr = 0.0045
I0525 01:21:02.310322 19044 solver.cpp:237] Iteration 25619, loss = 1.07009
I0525 01:21:02.310358 19044 solver.cpp:253]     Train net output #0: loss = 1.07009 (* 1 = 1.07009 loss)
I0525 01:21:02.310374 19044 sgd_solver.cpp:106] Iteration 25619, lr = 0.0045
I0525 01:21:10.973909 19044 solver.cpp:237] Iteration 25806, loss = 1.32737
I0525 01:21:10.974056 19044 solver.cpp:253]     Train net output #0: loss = 1.32737 (* 1 = 1.32737 loss)
I0525 01:21:10.974069 19044 sgd_solver.cpp:106] Iteration 25806, lr = 0.0045
I0525 01:21:19.639691 19044 solver.cpp:237] Iteration 25993, loss = 1.13705
I0525 01:21:19.639732 19044 solver.cpp:253]     Train net output #0: loss = 1.13705 (* 1 = 1.13705 loss)
I0525 01:21:19.639753 19044 sgd_solver.cpp:106] Iteration 25993, lr = 0.0045
I0525 01:21:28.302445 19044 solver.cpp:237] Iteration 26180, loss = 1.25866
I0525 01:21:28.302479 19044 solver.cpp:253]     Train net output #0: loss = 1.25866 (* 1 = 1.25866 loss)
I0525 01:21:28.302496 19044 sgd_solver.cpp:106] Iteration 26180, lr = 0.0045
I0525 01:21:31.500329 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_26250.caffemodel
I0525 01:21:31.571658 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_26250.solverstate
I0525 01:21:31.600004 19044 solver.cpp:341] Iteration 26250, Testing net (#0)
I0525 01:22:18.678690 19044 solver.cpp:409]     Test net output #0: accuracy = 0.877127
I0525 01:22:18.678860 19044 solver.cpp:409]     Test net output #1: loss = 0.406295 (* 1 = 0.406295 loss)
I0525 01:22:44.985242 19044 solver.cpp:237] Iteration 26367, loss = 0.982501
I0525 01:22:44.985294 19044 solver.cpp:253]     Train net output #0: loss = 0.982501 (* 1 = 0.982501 loss)
I0525 01:22:44.985309 19044 sgd_solver.cpp:106] Iteration 26367, lr = 0.0045
I0525 01:22:53.642743 19044 solver.cpp:237] Iteration 26554, loss = 1.28432
I0525 01:22:53.642904 19044 solver.cpp:253]     Train net output #0: loss = 1.28432 (* 1 = 1.28432 loss)
I0525 01:22:53.642917 19044 sgd_solver.cpp:106] Iteration 26554, lr = 0.0045
I0525 01:23:02.300287 19044 solver.cpp:237] Iteration 26741, loss = 1.16599
I0525 01:23:02.300323 19044 solver.cpp:253]     Train net output #0: loss = 1.16599 (* 1 = 1.16599 loss)
I0525 01:23:02.300339 19044 sgd_solver.cpp:106] Iteration 26741, lr = 0.0045
I0525 01:23:10.956022 19044 solver.cpp:237] Iteration 26928, loss = 1.40609
I0525 01:23:10.956058 19044 solver.cpp:253]     Train net output #0: loss = 1.40609 (* 1 = 1.40609 loss)
I0525 01:23:10.956074 19044 sgd_solver.cpp:106] Iteration 26928, lr = 0.0045
I0525 01:23:19.611729 19044 solver.cpp:237] Iteration 27115, loss = 1.48191
I0525 01:23:19.611778 19044 solver.cpp:253]     Train net output #0: loss = 1.48191 (* 1 = 1.48191 loss)
I0525 01:23:19.611791 19044 sgd_solver.cpp:106] Iteration 27115, lr = 0.0045
I0525 01:23:28.262805 19044 solver.cpp:237] Iteration 27302, loss = 1.18165
I0525 01:23:28.262969 19044 solver.cpp:253]     Train net output #0: loss = 1.18165 (* 1 = 1.18165 loss)
I0525 01:23:28.262984 19044 sgd_solver.cpp:106] Iteration 27302, lr = 0.0045
I0525 01:23:36.918486 19044 solver.cpp:237] Iteration 27489, loss = 1.25983
I0525 01:23:36.918521 19044 solver.cpp:253]     Train net output #0: loss = 1.25983 (* 1 = 1.25983 loss)
I0525 01:23:36.918539 19044 sgd_solver.cpp:106] Iteration 27489, lr = 0.0045
I0525 01:24:06.462189 19044 solver.cpp:237] Iteration 27676, loss = 1.06594
I0525 01:24:06.462363 19044 solver.cpp:253]     Train net output #0: loss = 1.06594 (* 1 = 1.06594 loss)
I0525 01:24:06.462378 19044 sgd_solver.cpp:106] Iteration 27676, lr = 0.0045
I0525 01:24:15.118582 19044 solver.cpp:237] Iteration 27863, loss = 1.27665
I0525 01:24:15.118620 19044 solver.cpp:253]     Train net output #0: loss = 1.27665 (* 1 = 1.27665 loss)
I0525 01:24:15.118641 19044 sgd_solver.cpp:106] Iteration 27863, lr = 0.0045
I0525 01:24:23.776355 19044 solver.cpp:237] Iteration 28050, loss = 1.19991
I0525 01:24:23.776391 19044 solver.cpp:253]     Train net output #0: loss = 1.19991 (* 1 = 1.19991 loss)
I0525 01:24:23.776407 19044 sgd_solver.cpp:106] Iteration 28050, lr = 0.0045
I0525 01:24:27.200412 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_28125.caffemodel
I0525 01:24:27.272100 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_28125.solverstate
I0525 01:24:32.503861 19044 solver.cpp:237] Iteration 28237, loss = 1.27816
I0525 01:24:32.503909 19044 solver.cpp:253]     Train net output #0: loss = 1.27816 (* 1 = 1.27816 loss)
I0525 01:24:32.503926 19044 sgd_solver.cpp:106] Iteration 28237, lr = 0.0045
I0525 01:24:41.161799 19044 solver.cpp:237] Iteration 28424, loss = 1.04422
I0525 01:24:41.161967 19044 solver.cpp:253]     Train net output #0: loss = 1.04422 (* 1 = 1.04422 loss)
I0525 01:24:41.161981 19044 sgd_solver.cpp:106] Iteration 28424, lr = 0.0045
I0525 01:24:49.814116 19044 solver.cpp:237] Iteration 28611, loss = 1.055
I0525 01:24:49.814151 19044 solver.cpp:253]     Train net output #0: loss = 1.055 (* 1 = 1.055 loss)
I0525 01:24:49.814168 19044 sgd_solver.cpp:106] Iteration 28611, lr = 0.0045
I0525 01:25:19.338824 19044 solver.cpp:237] Iteration 28798, loss = 1.18842
I0525 01:25:19.338992 19044 solver.cpp:253]     Train net output #0: loss = 1.18842 (* 1 = 1.18842 loss)
I0525 01:25:19.339007 19044 sgd_solver.cpp:106] Iteration 28798, lr = 0.0045
I0525 01:25:27.993463 19044 solver.cpp:237] Iteration 28985, loss = 0.948287
I0525 01:25:27.993512 19044 solver.cpp:253]     Train net output #0: loss = 0.948287 (* 1 = 0.948287 loss)
I0525 01:25:27.993525 19044 sgd_solver.cpp:106] Iteration 28985, lr = 0.0045
I0525 01:25:36.649466 19044 solver.cpp:237] Iteration 29172, loss = 1.24116
I0525 01:25:36.649502 19044 solver.cpp:253]     Train net output #0: loss = 1.24116 (* 1 = 1.24116 loss)
I0525 01:25:36.649518 19044 sgd_solver.cpp:106] Iteration 29172, lr = 0.0045
I0525 01:25:45.305955 19044 solver.cpp:237] Iteration 29359, loss = 1.24708
I0525 01:25:45.305991 19044 solver.cpp:253]     Train net output #0: loss = 1.24708 (* 1 = 1.24708 loss)
I0525 01:25:45.306007 19044 sgd_solver.cpp:106] Iteration 29359, lr = 0.0045
I0525 01:25:53.963178 19044 solver.cpp:237] Iteration 29546, loss = 1.20295
I0525 01:25:53.963353 19044 solver.cpp:253]     Train net output #0: loss = 1.20295 (* 1 = 1.20295 loss)
I0525 01:25:53.963368 19044 sgd_solver.cpp:106] Iteration 29546, lr = 0.0045
I0525 01:26:02.625754 19044 solver.cpp:237] Iteration 29733, loss = 1.34656
I0525 01:26:02.625789 19044 solver.cpp:253]     Train net output #0: loss = 1.34656 (* 1 = 1.34656 loss)
I0525 01:26:02.625807 19044 sgd_solver.cpp:106] Iteration 29733, lr = 0.0045
I0525 01:26:11.283892 19044 solver.cpp:237] Iteration 29920, loss = 1.20432
I0525 01:26:11.283926 19044 solver.cpp:253]     Train net output #0: loss = 1.20432 (* 1 = 1.20432 loss)
I0525 01:26:11.283943 19044 sgd_solver.cpp:106] Iteration 29920, lr = 0.0045
I0525 01:26:14.941320 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_30000.caffemodel
I0525 01:26:15.011453 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_30000.solverstate
I0525 01:26:15.037500 19044 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 01:27:23.269805 19044 solver.cpp:409]     Test net output #0: accuracy = 0.884873
I0525 01:27:23.269979 19044 solver.cpp:409]     Test net output #1: loss = 0.365478 (* 1 = 0.365478 loss)
I0525 01:27:49.122100 19044 solver.cpp:237] Iteration 30107, loss = 0.999149
I0525 01:27:49.122151 19044 solver.cpp:253]     Train net output #0: loss = 0.999149 (* 1 = 0.999149 loss)
I0525 01:27:49.122166 19044 sgd_solver.cpp:106] Iteration 30107, lr = 0.0045
I0525 01:27:57.781369 19044 solver.cpp:237] Iteration 30294, loss = 1.14061
I0525 01:27:57.781535 19044 solver.cpp:253]     Train net output #0: loss = 1.14061 (* 1 = 1.14061 loss)
I0525 01:27:57.781549 19044 sgd_solver.cpp:106] Iteration 30294, lr = 0.0045
I0525 01:28:06.440699 19044 solver.cpp:237] Iteration 30481, loss = 1.03149
I0525 01:28:06.440734 19044 solver.cpp:253]     Train net output #0: loss = 1.03149 (* 1 = 1.03149 loss)
I0525 01:28:06.440752 19044 sgd_solver.cpp:106] Iteration 30481, lr = 0.0045
I0525 01:28:15.102032 19044 solver.cpp:237] Iteration 30668, loss = 1.15816
I0525 01:28:15.102066 19044 solver.cpp:253]     Train net output #0: loss = 1.15816 (* 1 = 1.15816 loss)
I0525 01:28:15.102083 19044 sgd_solver.cpp:106] Iteration 30668, lr = 0.0045
I0525 01:28:23.764372 19044 solver.cpp:237] Iteration 30855, loss = 0.907455
I0525 01:28:23.764412 19044 solver.cpp:253]     Train net output #0: loss = 0.907455 (* 1 = 0.907455 loss)
I0525 01:28:23.764431 19044 sgd_solver.cpp:106] Iteration 30855, lr = 0.0045
I0525 01:28:32.425740 19044 solver.cpp:237] Iteration 31042, loss = 1.25535
I0525 01:28:32.425906 19044 solver.cpp:253]     Train net output #0: loss = 1.25535 (* 1 = 1.25535 loss)
I0525 01:28:32.425920 19044 sgd_solver.cpp:106] Iteration 31042, lr = 0.0045
I0525 01:28:41.086737 19044 solver.cpp:237] Iteration 31229, loss = 1.10311
I0525 01:28:41.086771 19044 solver.cpp:253]     Train net output #0: loss = 1.10311 (* 1 = 1.10311 loss)
I0525 01:28:41.086788 19044 sgd_solver.cpp:106] Iteration 31229, lr = 0.0045
I0525 01:29:10.615597 19044 solver.cpp:237] Iteration 31416, loss = 1.0639
I0525 01:29:10.615772 19044 solver.cpp:253]     Train net output #0: loss = 1.0639 (* 1 = 1.0639 loss)
I0525 01:29:10.615787 19044 sgd_solver.cpp:106] Iteration 31416, lr = 0.0045
I0525 01:29:19.278209 19044 solver.cpp:237] Iteration 31603, loss = 1.07688
I0525 01:29:19.278244 19044 solver.cpp:253]     Train net output #0: loss = 1.07688 (* 1 = 1.07688 loss)
I0525 01:29:19.278259 19044 sgd_solver.cpp:106] Iteration 31603, lr = 0.0045
I0525 01:29:27.936540 19044 solver.cpp:237] Iteration 31790, loss = 1.14893
I0525 01:29:27.936574 19044 solver.cpp:253]     Train net output #0: loss = 1.14893 (* 1 = 1.14893 loss)
I0525 01:29:27.936592 19044 sgd_solver.cpp:106] Iteration 31790, lr = 0.0045
I0525 01:29:31.826560 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_31875.caffemodel
I0525 01:29:31.895975 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_31875.solverstate
I0525 01:29:36.661808 19044 solver.cpp:237] Iteration 31977, loss = 1.05388
I0525 01:29:36.661856 19044 solver.cpp:253]     Train net output #0: loss = 1.05388 (* 1 = 1.05388 loss)
I0525 01:29:36.661875 19044 sgd_solver.cpp:106] Iteration 31977, lr = 0.0045
I0525 01:29:45.320190 19044 solver.cpp:237] Iteration 32164, loss = 1.29204
I0525 01:29:45.320355 19044 solver.cpp:253]     Train net output #0: loss = 1.29204 (* 1 = 1.29204 loss)
I0525 01:29:45.320369 19044 sgd_solver.cpp:106] Iteration 32164, lr = 0.0045
I0525 01:29:53.977283 19044 solver.cpp:237] Iteration 32351, loss = 0.962994
I0525 01:29:53.977319 19044 solver.cpp:253]     Train net output #0: loss = 0.962994 (* 1 = 0.962994 loss)
I0525 01:29:53.977331 19044 sgd_solver.cpp:106] Iteration 32351, lr = 0.0045
I0525 01:30:23.483095 19044 solver.cpp:237] Iteration 32538, loss = 1.2273
I0525 01:30:23.483273 19044 solver.cpp:253]     Train net output #0: loss = 1.2273 (* 1 = 1.2273 loss)
I0525 01:30:23.483286 19044 sgd_solver.cpp:106] Iteration 32538, lr = 0.0045
I0525 01:30:32.142323 19044 solver.cpp:237] Iteration 32725, loss = 0.936534
I0525 01:30:32.142359 19044 solver.cpp:253]     Train net output #0: loss = 0.936534 (* 1 = 0.936534 loss)
I0525 01:30:32.142371 19044 sgd_solver.cpp:106] Iteration 32725, lr = 0.0045
I0525 01:30:40.804877 19044 solver.cpp:237] Iteration 32912, loss = 1.25938
I0525 01:30:40.804913 19044 solver.cpp:253]     Train net output #0: loss = 1.25938 (* 1 = 1.25938 loss)
I0525 01:30:40.804929 19044 sgd_solver.cpp:106] Iteration 32912, lr = 0.0045
I0525 01:30:49.468709 19044 solver.cpp:237] Iteration 33099, loss = 1.23689
I0525 01:30:49.468750 19044 solver.cpp:253]     Train net output #0: loss = 1.23689 (* 1 = 1.23689 loss)
I0525 01:30:49.468767 19044 sgd_solver.cpp:106] Iteration 33099, lr = 0.0045
I0525 01:30:58.129570 19044 solver.cpp:237] Iteration 33286, loss = 1.02398
I0525 01:30:58.129719 19044 solver.cpp:253]     Train net output #0: loss = 1.02398 (* 1 = 1.02398 loss)
I0525 01:30:58.129732 19044 sgd_solver.cpp:106] Iteration 33286, lr = 0.0045
I0525 01:31:06.790657 19044 solver.cpp:237] Iteration 33473, loss = 1.28055
I0525 01:31:06.790691 19044 solver.cpp:253]     Train net output #0: loss = 1.28055 (* 1 = 1.28055 loss)
I0525 01:31:06.790709 19044 sgd_solver.cpp:106] Iteration 33473, lr = 0.0045
I0525 01:31:15.449681 19044 solver.cpp:237] Iteration 33660, loss = 1.03984
I0525 01:31:15.449728 19044 solver.cpp:253]     Train net output #0: loss = 1.03984 (* 1 = 1.03984 loss)
I0525 01:31:15.449744 19044 sgd_solver.cpp:106] Iteration 33660, lr = 0.0045
I0525 01:31:19.571593 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_33750.caffemodel
I0525 01:31:19.641216 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_33750.solverstate
I0525 01:31:19.667644 19044 solver.cpp:341] Iteration 33750, Testing net (#0)
I0525 01:32:07.042820 19044 solver.cpp:409]     Test net output #0: accuracy = 0.886787
I0525 01:32:07.043000 19044 solver.cpp:409]     Test net output #1: loss = 0.354709 (* 1 = 0.354709 loss)
I0525 01:32:32.375247 19044 solver.cpp:237] Iteration 33847, loss = 1.06402
I0525 01:32:32.375294 19044 solver.cpp:253]     Train net output #0: loss = 1.06402 (* 1 = 1.06402 loss)
I0525 01:32:32.375311 19044 sgd_solver.cpp:106] Iteration 33847, lr = 0.0045
I0525 01:32:41.025851 19044 solver.cpp:237] Iteration 34034, loss = 1.19151
I0525 01:32:41.026013 19044 solver.cpp:253]     Train net output #0: loss = 1.19151 (* 1 = 1.19151 loss)
I0525 01:32:41.026027 19044 sgd_solver.cpp:106] Iteration 34034, lr = 0.0045
I0525 01:32:49.675335 19044 solver.cpp:237] Iteration 34221, loss = 1.06877
I0525 01:32:49.675371 19044 solver.cpp:253]     Train net output #0: loss = 1.06877 (* 1 = 1.06877 loss)
I0525 01:32:49.675387 19044 sgd_solver.cpp:106] Iteration 34221, lr = 0.0045
I0525 01:32:58.324635 19044 solver.cpp:237] Iteration 34408, loss = 1.15202
I0525 01:32:58.324683 19044 solver.cpp:253]     Train net output #0: loss = 1.15202 (* 1 = 1.15202 loss)
I0525 01:32:58.324698 19044 sgd_solver.cpp:106] Iteration 34408, lr = 0.0045
I0525 01:33:06.973965 19044 solver.cpp:237] Iteration 34595, loss = 1.23095
I0525 01:33:06.974001 19044 solver.cpp:253]     Train net output #0: loss = 1.23095 (* 1 = 1.23095 loss)
I0525 01:33:06.974017 19044 sgd_solver.cpp:106] Iteration 34595, lr = 0.0045
I0525 01:33:15.624974 19044 solver.cpp:237] Iteration 34782, loss = 1.22649
I0525 01:33:15.625139 19044 solver.cpp:253]     Train net output #0: loss = 1.22649 (* 1 = 1.22649 loss)
I0525 01:33:15.625154 19044 sgd_solver.cpp:106] Iteration 34782, lr = 0.0045
I0525 01:33:24.277885 19044 solver.cpp:237] Iteration 34969, loss = 1.02853
I0525 01:33:24.277932 19044 solver.cpp:253]     Train net output #0: loss = 1.02853 (* 1 = 1.02853 loss)
I0525 01:33:24.277950 19044 sgd_solver.cpp:106] Iteration 34969, lr = 0.0045
I0525 01:33:53.776499 19044 solver.cpp:237] Iteration 35156, loss = 1.14288
I0525 01:33:53.776679 19044 solver.cpp:253]     Train net output #0: loss = 1.14288 (* 1 = 1.14288 loss)
I0525 01:33:53.776695 19044 sgd_solver.cpp:106] Iteration 35156, lr = 0.0045
I0525 01:34:02.422569 19044 solver.cpp:237] Iteration 35343, loss = 1.05365
I0525 01:34:02.422603 19044 solver.cpp:253]     Train net output #0: loss = 1.05365 (* 1 = 1.05365 loss)
I0525 01:34:02.422617 19044 sgd_solver.cpp:106] Iteration 35343, lr = 0.0045
I0525 01:34:11.072541 19044 solver.cpp:237] Iteration 35530, loss = 1.32303
I0525 01:34:11.072576 19044 solver.cpp:253]     Train net output #0: loss = 1.32303 (* 1 = 1.32303 loss)
I0525 01:34:11.072598 19044 sgd_solver.cpp:106] Iteration 35530, lr = 0.0045
I0525 01:34:15.418920 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_35625.caffemodel
I0525 01:34:15.491281 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_35625.solverstate
I0525 01:34:19.789536 19044 solver.cpp:237] Iteration 35717, loss = 1.36757
I0525 01:34:19.789584 19044 solver.cpp:253]     Train net output #0: loss = 1.36757 (* 1 = 1.36757 loss)
I0525 01:34:19.789602 19044 sgd_solver.cpp:106] Iteration 35717, lr = 0.0045
I0525 01:34:28.438199 19044 solver.cpp:237] Iteration 35904, loss = 1.36103
I0525 01:34:28.438359 19044 solver.cpp:253]     Train net output #0: loss = 1.36103 (* 1 = 1.36103 loss)
I0525 01:34:28.438374 19044 sgd_solver.cpp:106] Iteration 35904, lr = 0.0045
I0525 01:34:37.086483 19044 solver.cpp:237] Iteration 36091, loss = 1.38187
I0525 01:34:37.086524 19044 solver.cpp:253]     Train net output #0: loss = 1.38187 (* 1 = 1.38187 loss)
I0525 01:34:37.086544 19044 sgd_solver.cpp:106] Iteration 36091, lr = 0.0045
I0525 01:35:06.603926 19044 solver.cpp:237] Iteration 36278, loss = 1.22501
I0525 01:35:06.604107 19044 solver.cpp:253]     Train net output #0: loss = 1.22501 (* 1 = 1.22501 loss)
I0525 01:35:06.604130 19044 sgd_solver.cpp:106] Iteration 36278, lr = 0.0045
I0525 01:35:15.253648 19044 solver.cpp:237] Iteration 36465, loss = 1.14558
I0525 01:35:15.253684 19044 solver.cpp:253]     Train net output #0: loss = 1.14558 (* 1 = 1.14558 loss)
I0525 01:35:15.253701 19044 sgd_solver.cpp:106] Iteration 36465, lr = 0.0045
I0525 01:35:23.902727 19044 solver.cpp:237] Iteration 36652, loss = 1.14552
I0525 01:35:23.902770 19044 solver.cpp:253]     Train net output #0: loss = 1.14552 (* 1 = 1.14552 loss)
I0525 01:35:23.902791 19044 sgd_solver.cpp:106] Iteration 36652, lr = 0.0045
I0525 01:35:32.554389 19044 solver.cpp:237] Iteration 36839, loss = 1.09034
I0525 01:35:32.554426 19044 solver.cpp:253]     Train net output #0: loss = 1.09034 (* 1 = 1.09034 loss)
I0525 01:35:32.554441 19044 sgd_solver.cpp:106] Iteration 36839, lr = 0.0045
I0525 01:35:41.203898 19044 solver.cpp:237] Iteration 37026, loss = 1.19829
I0525 01:35:41.204061 19044 solver.cpp:253]     Train net output #0: loss = 1.19829 (* 1 = 1.19829 loss)
I0525 01:35:41.204077 19044 sgd_solver.cpp:106] Iteration 37026, lr = 0.0045
I0525 01:35:49.853327 19044 solver.cpp:237] Iteration 37213, loss = 1.18749
I0525 01:35:49.853370 19044 solver.cpp:253]     Train net output #0: loss = 1.18749 (* 1 = 1.18749 loss)
I0525 01:35:49.853385 19044 sgd_solver.cpp:106] Iteration 37213, lr = 0.0045
I0525 01:35:58.506867 19044 solver.cpp:237] Iteration 37400, loss = 1.00046
I0525 01:35:58.506903 19044 solver.cpp:253]     Train net output #0: loss = 1.00046 (* 1 = 1.00046 loss)
I0525 01:35:58.506919 19044 sgd_solver.cpp:106] Iteration 37400, lr = 0.0045
I0525 01:36:03.088484 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_37500.caffemodel
I0525 01:36:03.160766 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_37500.solverstate
I0525 01:36:03.189299 19044 solver.cpp:341] Iteration 37500, Testing net (#0)
I0525 01:37:11.426403 19044 solver.cpp:409]     Test net output #0: accuracy = 0.886952
I0525 01:37:11.426579 19044 solver.cpp:409]     Test net output #1: loss = 0.396888 (* 1 = 0.396888 loss)
I0525 01:37:36.317809 19044 solver.cpp:237] Iteration 37587, loss = 1.22843
I0525 01:37:36.317859 19044 solver.cpp:253]     Train net output #0: loss = 1.22843 (* 1 = 1.22843 loss)
I0525 01:37:36.317875 19044 sgd_solver.cpp:106] Iteration 37587, lr = 0.0045
I0525 01:37:44.981462 19044 solver.cpp:237] Iteration 37774, loss = 1.17707
I0525 01:37:44.981621 19044 solver.cpp:253]     Train net output #0: loss = 1.17707 (* 1 = 1.17707 loss)
I0525 01:37:44.981633 19044 sgd_solver.cpp:106] Iteration 37774, lr = 0.0045
I0525 01:37:53.642254 19044 solver.cpp:237] Iteration 37961, loss = 1.15767
I0525 01:37:53.642303 19044 solver.cpp:253]     Train net output #0: loss = 1.15767 (* 1 = 1.15767 loss)
I0525 01:37:53.642318 19044 sgd_solver.cpp:106] Iteration 37961, lr = 0.0045
I0525 01:38:02.307476 19044 solver.cpp:237] Iteration 38148, loss = 1.19143
I0525 01:38:02.307510 19044 solver.cpp:253]     Train net output #0: loss = 1.19143 (* 1 = 1.19143 loss)
I0525 01:38:02.307528 19044 sgd_solver.cpp:106] Iteration 38148, lr = 0.0045
I0525 01:38:10.976078 19044 solver.cpp:237] Iteration 38335, loss = 1.35621
I0525 01:38:10.976119 19044 solver.cpp:253]     Train net output #0: loss = 1.35621 (* 1 = 1.35621 loss)
I0525 01:38:10.976133 19044 sgd_solver.cpp:106] Iteration 38335, lr = 0.0045
I0525 01:38:19.636647 19044 solver.cpp:237] Iteration 38522, loss = 1.26806
I0525 01:38:19.636813 19044 solver.cpp:253]     Train net output #0: loss = 1.26806 (* 1 = 1.26806 loss)
I0525 01:38:19.636827 19044 sgd_solver.cpp:106] Iteration 38522, lr = 0.0045
I0525 01:38:28.300418 19044 solver.cpp:237] Iteration 38709, loss = 1.24734
I0525 01:38:28.300452 19044 solver.cpp:253]     Train net output #0: loss = 1.24734 (* 1 = 1.24734 loss)
I0525 01:38:28.300469 19044 sgd_solver.cpp:106] Iteration 38709, lr = 0.0045
I0525 01:38:57.782030 19044 solver.cpp:237] Iteration 38896, loss = 1.20562
I0525 01:38:57.782207 19044 solver.cpp:253]     Train net output #0: loss = 1.20562 (* 1 = 1.20562 loss)
I0525 01:38:57.782222 19044 sgd_solver.cpp:106] Iteration 38896, lr = 0.0045
I0525 01:39:06.440981 19044 solver.cpp:237] Iteration 39083, loss = 1.09854
I0525 01:39:06.441015 19044 solver.cpp:253]     Train net output #0: loss = 1.09854 (* 1 = 1.09854 loss)
I0525 01:39:06.441032 19044 sgd_solver.cpp:106] Iteration 39083, lr = 0.0045
I0525 01:39:15.105226 19044 solver.cpp:237] Iteration 39270, loss = 1.25103
I0525 01:39:15.105273 19044 solver.cpp:253]     Train net output #0: loss = 1.25103 (* 1 = 1.25103 loss)
I0525 01:39:15.105288 19044 sgd_solver.cpp:106] Iteration 39270, lr = 0.0045
I0525 01:39:19.924562 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_39375.caffemodel
I0525 01:39:19.995064 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_39375.solverstate
I0525 01:39:23.835114 19044 solver.cpp:237] Iteration 39457, loss = 1.20795
I0525 01:39:23.835156 19044 solver.cpp:253]     Train net output #0: loss = 1.20795 (* 1 = 1.20795 loss)
I0525 01:39:23.835175 19044 sgd_solver.cpp:106] Iteration 39457, lr = 0.0045
I0525 01:39:32.497908 19044 solver.cpp:237] Iteration 39644, loss = 1.24147
I0525 01:39:32.498077 19044 solver.cpp:253]     Train net output #0: loss = 1.24147 (* 1 = 1.24147 loss)
I0525 01:39:32.498092 19044 sgd_solver.cpp:106] Iteration 39644, lr = 0.0045
I0525 01:39:41.164933 19044 solver.cpp:237] Iteration 39831, loss = 1.09555
I0525 01:39:41.164978 19044 solver.cpp:253]     Train net output #0: loss = 1.09555 (* 1 = 1.09555 loss)
I0525 01:39:41.164997 19044 sgd_solver.cpp:106] Iteration 39831, lr = 0.0045
I0525 01:40:10.694778 19044 solver.cpp:237] Iteration 40018, loss = 1.05938
I0525 01:40:10.694959 19044 solver.cpp:253]     Train net output #0: loss = 1.05938 (* 1 = 1.05938 loss)
I0525 01:40:10.694975 19044 sgd_solver.cpp:106] Iteration 40018, lr = 0.0045
I0525 01:40:19.359760 19044 solver.cpp:237] Iteration 40205, loss = 1.18799
I0525 01:40:19.359794 19044 solver.cpp:253]     Train net output #0: loss = 1.18799 (* 1 = 1.18799 loss)
I0525 01:40:19.359812 19044 sgd_solver.cpp:106] Iteration 40205, lr = 0.0045
I0525 01:40:28.020850 19044 solver.cpp:237] Iteration 40392, loss = 1.16105
I0525 01:40:28.020889 19044 solver.cpp:253]     Train net output #0: loss = 1.16105 (* 1 = 1.16105 loss)
I0525 01:40:28.020910 19044 sgd_solver.cpp:106] Iteration 40392, lr = 0.0045
I0525 01:40:36.686365 19044 solver.cpp:237] Iteration 40579, loss = 1.1658
I0525 01:40:36.686400 19044 solver.cpp:253]     Train net output #0: loss = 1.1658 (* 1 = 1.1658 loss)
I0525 01:40:36.686416 19044 sgd_solver.cpp:106] Iteration 40579, lr = 0.0045
I0525 01:40:45.355120 19044 solver.cpp:237] Iteration 40766, loss = 1.00668
I0525 01:40:45.355276 19044 solver.cpp:253]     Train net output #0: loss = 1.00668 (* 1 = 1.00668 loss)
I0525 01:40:45.355289 19044 sgd_solver.cpp:106] Iteration 40766, lr = 0.0045
I0525 01:40:54.021189 19044 solver.cpp:237] Iteration 40953, loss = 1.27927
I0525 01:40:54.021235 19044 solver.cpp:253]     Train net output #0: loss = 1.27927 (* 1 = 1.27927 loss)
I0525 01:40:54.021252 19044 sgd_solver.cpp:106] Iteration 40953, lr = 0.0045
I0525 01:41:02.684296 19044 solver.cpp:237] Iteration 41140, loss = 1.01739
I0525 01:41:02.684332 19044 solver.cpp:253]     Train net output #0: loss = 1.01739 (* 1 = 1.01739 loss)
I0525 01:41:02.684347 19044 sgd_solver.cpp:106] Iteration 41140, lr = 0.0045
I0525 01:41:07.733850 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_41250.caffemodel
I0525 01:41:07.804559 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_41250.solverstate
I0525 01:41:07.830576 19044 solver.cpp:341] Iteration 41250, Testing net (#0)
I0525 01:41:54.923975 19044 solver.cpp:409]     Test net output #0: accuracy = 0.890307
I0525 01:41:54.924167 19044 solver.cpp:409]     Test net output #1: loss = 0.346911 (* 1 = 0.346911 loss)
I0525 01:42:19.384028 19044 solver.cpp:237] Iteration 41327, loss = 1.17857
I0525 01:42:19.384080 19044 solver.cpp:253]     Train net output #0: loss = 1.17857 (* 1 = 1.17857 loss)
I0525 01:42:19.384096 19044 sgd_solver.cpp:106] Iteration 41327, lr = 0.0045
I0525 01:42:28.041110 19044 solver.cpp:237] Iteration 41514, loss = 1.27787
I0525 01:42:28.041280 19044 solver.cpp:253]     Train net output #0: loss = 1.27787 (* 1 = 1.27787 loss)
I0525 01:42:28.041296 19044 sgd_solver.cpp:106] Iteration 41514, lr = 0.0045
I0525 01:42:36.694917 19044 solver.cpp:237] Iteration 41701, loss = 1.20534
I0525 01:42:36.694952 19044 solver.cpp:253]     Train net output #0: loss = 1.20534 (* 1 = 1.20534 loss)
I0525 01:42:36.694968 19044 sgd_solver.cpp:106] Iteration 41701, lr = 0.0045
I0525 01:42:45.353032 19044 solver.cpp:237] Iteration 41888, loss = 1.3683
I0525 01:42:45.353068 19044 solver.cpp:253]     Train net output #0: loss = 1.3683 (* 1 = 1.3683 loss)
I0525 01:42:45.353085 19044 sgd_solver.cpp:106] Iteration 41888, lr = 0.0045
I0525 01:42:54.013591 19044 solver.cpp:237] Iteration 42075, loss = 1.18595
I0525 01:42:54.013634 19044 solver.cpp:253]     Train net output #0: loss = 1.18595 (* 1 = 1.18595 loss)
I0525 01:42:54.013651 19044 sgd_solver.cpp:106] Iteration 42075, lr = 0.0045
I0525 01:43:02.671540 19044 solver.cpp:237] Iteration 42262, loss = 1.16071
I0525 01:43:02.671697 19044 solver.cpp:253]     Train net output #0: loss = 1.16071 (* 1 = 1.16071 loss)
I0525 01:43:02.671711 19044 sgd_solver.cpp:106] Iteration 42262, lr = 0.0045
I0525 01:43:11.325768 19044 solver.cpp:237] Iteration 42449, loss = 1.39696
I0525 01:43:11.325803 19044 solver.cpp:253]     Train net output #0: loss = 1.39696 (* 1 = 1.39696 loss)
I0525 01:43:11.325819 19044 sgd_solver.cpp:106] Iteration 42449, lr = 0.0045
I0525 01:43:40.846706 19044 solver.cpp:237] Iteration 42636, loss = 1.20143
I0525 01:43:40.846884 19044 solver.cpp:253]     Train net output #0: loss = 1.20143 (* 1 = 1.20143 loss)
I0525 01:43:40.846900 19044 sgd_solver.cpp:106] Iteration 42636, lr = 0.0045
I0525 01:43:49.502202 19044 solver.cpp:237] Iteration 42823, loss = 1.10308
I0525 01:43:49.502235 19044 solver.cpp:253]     Train net output #0: loss = 1.10308 (* 1 = 1.10308 loss)
I0525 01:43:49.502257 19044 sgd_solver.cpp:106] Iteration 42823, lr = 0.0045
I0525 01:43:58.155527 19044 solver.cpp:237] Iteration 43010, loss = 1.0077
I0525 01:43:58.155563 19044 solver.cpp:253]     Train net output #0: loss = 1.0077 (* 1 = 1.0077 loss)
I0525 01:43:58.155577 19044 sgd_solver.cpp:106] Iteration 43010, lr = 0.0045
I0525 01:44:03.429837 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_43125.caffemodel
I0525 01:44:03.499486 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_43125.solverstate
I0525 01:44:06.874419 19044 solver.cpp:237] Iteration 43197, loss = 1.31349
I0525 01:44:06.874462 19044 solver.cpp:253]     Train net output #0: loss = 1.31349 (* 1 = 1.31349 loss)
I0525 01:44:06.874482 19044 sgd_solver.cpp:106] Iteration 43197, lr = 0.0045
I0525 01:44:15.530727 19044 solver.cpp:237] Iteration 43384, loss = 1.05976
I0525 01:44:15.530894 19044 solver.cpp:253]     Train net output #0: loss = 1.05976 (* 1 = 1.05976 loss)
I0525 01:44:15.530907 19044 sgd_solver.cpp:106] Iteration 43384, lr = 0.0045
I0525 01:44:24.188104 19044 solver.cpp:237] Iteration 43571, loss = 1.2115
I0525 01:44:24.188143 19044 solver.cpp:253]     Train net output #0: loss = 1.2115 (* 1 = 1.2115 loss)
I0525 01:44:24.188160 19044 sgd_solver.cpp:106] Iteration 43571, lr = 0.0045
I0525 01:44:53.718091 19044 solver.cpp:237] Iteration 43758, loss = 0.983301
I0525 01:44:53.718272 19044 solver.cpp:253]     Train net output #0: loss = 0.983301 (* 1 = 0.983301 loss)
I0525 01:44:53.718289 19044 sgd_solver.cpp:106] Iteration 43758, lr = 0.0045
I0525 01:45:02.378120 19044 solver.cpp:237] Iteration 43945, loss = 1.11872
I0525 01:45:02.378166 19044 solver.cpp:253]     Train net output #0: loss = 1.11872 (* 1 = 1.11872 loss)
I0525 01:45:02.378185 19044 sgd_solver.cpp:106] Iteration 43945, lr = 0.0045
I0525 01:45:11.033221 19044 solver.cpp:237] Iteration 44132, loss = 1.21599
I0525 01:45:11.033257 19044 solver.cpp:253]     Train net output #0: loss = 1.21599 (* 1 = 1.21599 loss)
I0525 01:45:11.033273 19044 sgd_solver.cpp:106] Iteration 44132, lr = 0.0045
I0525 01:45:19.690485 19044 solver.cpp:237] Iteration 44319, loss = 1.18308
I0525 01:45:19.690521 19044 solver.cpp:253]     Train net output #0: loss = 1.18308 (* 1 = 1.18308 loss)
I0525 01:45:19.690534 19044 sgd_solver.cpp:106] Iteration 44319, lr = 0.0045
I0525 01:45:28.347422 19044 solver.cpp:237] Iteration 44506, loss = 1.03131
I0525 01:45:28.347604 19044 solver.cpp:253]     Train net output #0: loss = 1.03131 (* 1 = 1.03131 loss)
I0525 01:45:28.347618 19044 sgd_solver.cpp:106] Iteration 44506, lr = 0.0045
I0525 01:45:37.005225 19044 solver.cpp:237] Iteration 44693, loss = 0.963893
I0525 01:45:37.005262 19044 solver.cpp:253]     Train net output #0: loss = 0.963893 (* 1 = 0.963893 loss)
I0525 01:45:37.005275 19044 sgd_solver.cpp:106] Iteration 44693, lr = 0.0045
I0525 01:45:45.661406 19044 solver.cpp:237] Iteration 44880, loss = 1.07568
I0525 01:45:45.661442 19044 solver.cpp:253]     Train net output #0: loss = 1.07568 (* 1 = 1.07568 loss)
I0525 01:45:45.661458 19044 sgd_solver.cpp:106] Iteration 44880, lr = 0.0045
I0525 01:45:51.168232 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_45000.caffemodel
I0525 01:45:51.240931 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_45000.solverstate
I0525 01:45:51.269527 19044 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 01:46:59.490173 19044 solver.cpp:409]     Test net output #0: accuracy = 0.891007
I0525 01:46:59.490353 19044 solver.cpp:409]     Test net output #1: loss = 0.368175 (* 1 = 0.368175 loss)
I0525 01:47:23.456133 19044 solver.cpp:237] Iteration 45067, loss = 1.38977
I0525 01:47:23.456183 19044 solver.cpp:253]     Train net output #0: loss = 1.38977 (* 1 = 1.38977 loss)
I0525 01:47:23.456199 19044 sgd_solver.cpp:106] Iteration 45067, lr = 0.0045
I0525 01:47:32.113217 19044 solver.cpp:237] Iteration 45254, loss = 1.27916
I0525 01:47:32.113392 19044 solver.cpp:253]     Train net output #0: loss = 1.27916 (* 1 = 1.27916 loss)
I0525 01:47:32.113407 19044 sgd_solver.cpp:106] Iteration 45254, lr = 0.0045
I0525 01:47:40.770087 19044 solver.cpp:237] Iteration 45441, loss = 1.01684
I0525 01:47:40.770122 19044 solver.cpp:253]     Train net output #0: loss = 1.01684 (* 1 = 1.01684 loss)
I0525 01:47:40.770138 19044 sgd_solver.cpp:106] Iteration 45441, lr = 0.0045
I0525 01:47:49.430624 19044 solver.cpp:237] Iteration 45628, loss = 1.02057
I0525 01:47:49.430660 19044 solver.cpp:253]     Train net output #0: loss = 1.02057 (* 1 = 1.02057 loss)
I0525 01:47:49.430676 19044 sgd_solver.cpp:106] Iteration 45628, lr = 0.0045
I0525 01:47:58.095168 19044 solver.cpp:237] Iteration 45815, loss = 1.20408
I0525 01:47:58.095211 19044 solver.cpp:253]     Train net output #0: loss = 1.20408 (* 1 = 1.20408 loss)
I0525 01:47:58.095229 19044 sgd_solver.cpp:106] Iteration 45815, lr = 0.0045
I0525 01:48:06.758750 19044 solver.cpp:237] Iteration 46002, loss = 1.0924
I0525 01:48:06.758910 19044 solver.cpp:253]     Train net output #0: loss = 1.0924 (* 1 = 1.0924 loss)
I0525 01:48:06.758924 19044 sgd_solver.cpp:106] Iteration 46002, lr = 0.0045
I0525 01:48:15.417769 19044 solver.cpp:237] Iteration 46189, loss = 1.17657
I0525 01:48:15.417804 19044 solver.cpp:253]     Train net output #0: loss = 1.17657 (* 1 = 1.17657 loss)
I0525 01:48:15.417821 19044 sgd_solver.cpp:106] Iteration 46189, lr = 0.0045
I0525 01:48:44.940801 19044 solver.cpp:237] Iteration 46376, loss = 1.19827
I0525 01:48:44.940989 19044 solver.cpp:253]     Train net output #0: loss = 1.19827 (* 1 = 1.19827 loss)
I0525 01:48:44.941004 19044 sgd_solver.cpp:106] Iteration 46376, lr = 0.0045
I0525 01:48:53.600298 19044 solver.cpp:237] Iteration 46563, loss = 1.29223
I0525 01:48:53.600333 19044 solver.cpp:253]     Train net output #0: loss = 1.29223 (* 1 = 1.29223 loss)
I0525 01:48:53.600352 19044 sgd_solver.cpp:106] Iteration 46563, lr = 0.0045
I0525 01:49:02.260141 19044 solver.cpp:237] Iteration 46750, loss = 1.166
I0525 01:49:02.260177 19044 solver.cpp:253]     Train net output #0: loss = 1.166 (* 1 = 1.166 loss)
I0525 01:49:02.260192 19044 sgd_solver.cpp:106] Iteration 46750, lr = 0.0045
I0525 01:49:08.002207 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_46875.caffemodel
I0525 01:49:08.073429 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_46875.solverstate
I0525 01:49:10.986274 19044 solver.cpp:237] Iteration 46937, loss = 0.844596
I0525 01:49:10.986320 19044 solver.cpp:253]     Train net output #0: loss = 0.844596 (* 1 = 0.844596 loss)
I0525 01:49:10.986340 19044 sgd_solver.cpp:106] Iteration 46937, lr = 0.0045
I0525 01:49:19.645086 19044 solver.cpp:237] Iteration 47124, loss = 1.0837
I0525 01:49:19.645252 19044 solver.cpp:253]     Train net output #0: loss = 1.0837 (* 1 = 1.0837 loss)
I0525 01:49:19.645267 19044 sgd_solver.cpp:106] Iteration 47124, lr = 0.0045
I0525 01:49:28.302652 19044 solver.cpp:237] Iteration 47311, loss = 1.34762
I0525 01:49:28.302687 19044 solver.cpp:253]     Train net output #0: loss = 1.34762 (* 1 = 1.34762 loss)
I0525 01:49:28.302705 19044 sgd_solver.cpp:106] Iteration 47311, lr = 0.0045
I0525 01:49:36.960984 19044 solver.cpp:237] Iteration 47498, loss = 0.995381
I0525 01:49:36.961025 19044 solver.cpp:253]     Train net output #0: loss = 0.995381 (* 1 = 0.995381 loss)
I0525 01:49:36.961045 19044 sgd_solver.cpp:106] Iteration 47498, lr = 0.0045
I0525 01:50:06.493834 19044 solver.cpp:237] Iteration 47685, loss = 1.19175
I0525 01:50:06.494024 19044 solver.cpp:253]     Train net output #0: loss = 1.19175 (* 1 = 1.19175 loss)
I0525 01:50:06.494038 19044 sgd_solver.cpp:106] Iteration 47685, lr = 0.0045
I0525 01:50:15.152487 19044 solver.cpp:237] Iteration 47872, loss = 1.2709
I0525 01:50:15.152521 19044 solver.cpp:253]     Train net output #0: loss = 1.2709 (* 1 = 1.2709 loss)
I0525 01:50:15.152539 19044 sgd_solver.cpp:106] Iteration 47872, lr = 0.0045
I0525 01:50:23.817129 19044 solver.cpp:237] Iteration 48059, loss = 1.13118
I0525 01:50:23.817178 19044 solver.cpp:253]     Train net output #0: loss = 1.13118 (* 1 = 1.13118 loss)
I0525 01:50:23.817193 19044 sgd_solver.cpp:106] Iteration 48059, lr = 0.0045
I0525 01:50:32.477460 19044 solver.cpp:237] Iteration 48246, loss = 1.33574
I0525 01:50:32.477495 19044 solver.cpp:253]     Train net output #0: loss = 1.33574 (* 1 = 1.33574 loss)
I0525 01:50:32.477512 19044 sgd_solver.cpp:106] Iteration 48246, lr = 0.0045
I0525 01:50:41.136503 19044 solver.cpp:237] Iteration 48433, loss = 1.23063
I0525 01:50:41.136673 19044 solver.cpp:253]     Train net output #0: loss = 1.23063 (* 1 = 1.23063 loss)
I0525 01:50:41.136688 19044 sgd_solver.cpp:106] Iteration 48433, lr = 0.0045
I0525 01:50:49.795923 19044 solver.cpp:237] Iteration 48620, loss = 1.15216
I0525 01:50:49.795964 19044 solver.cpp:253]     Train net output #0: loss = 1.15216 (* 1 = 1.15216 loss)
I0525 01:50:49.795985 19044 sgd_solver.cpp:106] Iteration 48620, lr = 0.0045
I0525 01:50:55.768661 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_48750.caffemodel
I0525 01:50:55.838076 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_48750.solverstate
I0525 01:50:55.864166 19044 solver.cpp:341] Iteration 48750, Testing net (#0)
I0525 01:51:43.221887 19044 solver.cpp:409]     Test net output #0: accuracy = 0.89318
I0525 01:51:43.222074 19044 solver.cpp:409]     Test net output #1: loss = 0.339447 (* 1 = 0.339447 loss)
I0525 01:52:06.716451 19044 solver.cpp:237] Iteration 48807, loss = 1.16175
I0525 01:52:06.716502 19044 solver.cpp:253]     Train net output #0: loss = 1.16175 (* 1 = 1.16175 loss)
I0525 01:52:06.716517 19044 sgd_solver.cpp:106] Iteration 48807, lr = 0.0045
I0525 01:52:15.364414 19044 solver.cpp:237] Iteration 48994, loss = 1.36119
I0525 01:52:15.364581 19044 solver.cpp:253]     Train net output #0: loss = 1.36119 (* 1 = 1.36119 loss)
I0525 01:52:15.364595 19044 sgd_solver.cpp:106] Iteration 48994, lr = 0.0045
I0525 01:52:24.013200 19044 solver.cpp:237] Iteration 49181, loss = 1.22946
I0525 01:52:24.013234 19044 solver.cpp:253]     Train net output #0: loss = 1.22946 (* 1 = 1.22946 loss)
I0525 01:52:24.013252 19044 sgd_solver.cpp:106] Iteration 49181, lr = 0.0045
I0525 01:52:32.659690 19044 solver.cpp:237] Iteration 49368, loss = 1.11936
I0525 01:52:32.659734 19044 solver.cpp:253]     Train net output #0: loss = 1.11936 (* 1 = 1.11936 loss)
I0525 01:52:32.659754 19044 sgd_solver.cpp:106] Iteration 49368, lr = 0.0045
I0525 01:52:41.307840 19044 solver.cpp:237] Iteration 49555, loss = 1.26828
I0525 01:52:41.307874 19044 solver.cpp:253]     Train net output #0: loss = 1.26828 (* 1 = 1.26828 loss)
I0525 01:52:41.307890 19044 sgd_solver.cpp:106] Iteration 49555, lr = 0.0045
I0525 01:52:49.956403 19044 solver.cpp:237] Iteration 49742, loss = 1.07875
I0525 01:52:49.956563 19044 solver.cpp:253]     Train net output #0: loss = 1.07875 (* 1 = 1.07875 loss)
I0525 01:52:49.956578 19044 sgd_solver.cpp:106] Iteration 49742, lr = 0.0045
I0525 01:52:58.604981 19044 solver.cpp:237] Iteration 49929, loss = 1.25167
I0525 01:52:58.605026 19044 solver.cpp:253]     Train net output #0: loss = 1.25167 (* 1 = 1.25167 loss)
I0525 01:52:58.605041 19044 sgd_solver.cpp:106] Iteration 49929, lr = 0.0045
I0525 01:53:28.080389 19044 solver.cpp:237] Iteration 50116, loss = 1.11005
I0525 01:53:28.080566 19044 solver.cpp:253]     Train net output #0: loss = 1.11005 (* 1 = 1.11005 loss)
I0525 01:53:28.080582 19044 sgd_solver.cpp:106] Iteration 50116, lr = 0.0045
I0525 01:53:36.725760 19044 solver.cpp:237] Iteration 50303, loss = 1.00708
I0525 01:53:36.725795 19044 solver.cpp:253]     Train net output #0: loss = 1.00708 (* 1 = 1.00708 loss)
I0525 01:53:36.725812 19044 sgd_solver.cpp:106] Iteration 50303, lr = 0.0045
I0525 01:53:45.374559 19044 solver.cpp:237] Iteration 50490, loss = 1.05072
I0525 01:53:45.374598 19044 solver.cpp:253]     Train net output #0: loss = 1.05072 (* 1 = 1.05072 loss)
I0525 01:53:45.374619 19044 sgd_solver.cpp:106] Iteration 50490, lr = 0.0045
I0525 01:53:51.572788 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_50625.caffemodel
I0525 01:53:51.642632 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_50625.solverstate
I0525 01:53:54.089031 19044 solver.cpp:237] Iteration 50677, loss = 1.22157
I0525 01:53:54.089078 19044 solver.cpp:253]     Train net output #0: loss = 1.22157 (* 1 = 1.22157 loss)
I0525 01:53:54.089094 19044 sgd_solver.cpp:106] Iteration 50677, lr = 0.0045
I0525 01:54:02.738981 19044 solver.cpp:237] Iteration 50864, loss = 1.05033
I0525 01:54:02.739150 19044 solver.cpp:253]     Train net output #0: loss = 1.05033 (* 1 = 1.05033 loss)
I0525 01:54:02.739163 19044 sgd_solver.cpp:106] Iteration 50864, lr = 0.0045
I0525 01:54:11.386883 19044 solver.cpp:237] Iteration 51051, loss = 1.08574
I0525 01:54:11.386925 19044 solver.cpp:253]     Train net output #0: loss = 1.08574 (* 1 = 1.08574 loss)
I0525 01:54:11.386940 19044 sgd_solver.cpp:106] Iteration 51051, lr = 0.0045
I0525 01:54:20.037206 19044 solver.cpp:237] Iteration 51238, loss = 1.15018
I0525 01:54:20.037242 19044 solver.cpp:253]     Train net output #0: loss = 1.15018 (* 1 = 1.15018 loss)
I0525 01:54:20.037259 19044 sgd_solver.cpp:106] Iteration 51238, lr = 0.0045
I0525 01:54:49.529268 19044 solver.cpp:237] Iteration 51425, loss = 1.14591
I0525 01:54:49.529469 19044 solver.cpp:253]     Train net output #0: loss = 1.14591 (* 1 = 1.14591 loss)
I0525 01:54:49.529485 19044 sgd_solver.cpp:106] Iteration 51425, lr = 0.0045
I0525 01:54:58.179270 19044 solver.cpp:237] Iteration 51612, loss = 1.16912
I0525 01:54:58.179311 19044 solver.cpp:253]     Train net output #0: loss = 1.16912 (* 1 = 1.16912 loss)
I0525 01:54:58.179327 19044 sgd_solver.cpp:106] Iteration 51612, lr = 0.0045
I0525 01:55:06.830340 19044 solver.cpp:237] Iteration 51799, loss = 1.10471
I0525 01:55:06.830375 19044 solver.cpp:253]     Train net output #0: loss = 1.10471 (* 1 = 1.10471 loss)
I0525 01:55:06.830389 19044 sgd_solver.cpp:106] Iteration 51799, lr = 0.0045
I0525 01:55:15.478466 19044 solver.cpp:237] Iteration 51986, loss = 1.08524
I0525 01:55:15.478503 19044 solver.cpp:253]     Train net output #0: loss = 1.08524 (* 1 = 1.08524 loss)
I0525 01:55:15.478518 19044 sgd_solver.cpp:106] Iteration 51986, lr = 0.0045
I0525 01:55:24.128275 19044 solver.cpp:237] Iteration 52173, loss = 1.18187
I0525 01:55:24.128448 19044 solver.cpp:253]     Train net output #0: loss = 1.18187 (* 1 = 1.18187 loss)
I0525 01:55:24.128461 19044 sgd_solver.cpp:106] Iteration 52173, lr = 0.0045
I0525 01:55:32.776566 19044 solver.cpp:237] Iteration 52360, loss = 1.1931
I0525 01:55:32.776599 19044 solver.cpp:253]     Train net output #0: loss = 1.1931 (* 1 = 1.1931 loss)
I0525 01:55:32.776617 19044 sgd_solver.cpp:106] Iteration 52360, lr = 0.0045
I0525 01:55:39.205313 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_52500.caffemodel
I0525 01:55:39.274906 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_52500.solverstate
I0525 01:55:39.301384 19044 solver.cpp:341] Iteration 52500, Testing net (#0)
I0525 01:56:47.503063 19044 solver.cpp:409]     Test net output #0: accuracy = 0.892314
I0525 01:56:47.503247 19044 solver.cpp:409]     Test net output #1: loss = 0.339103 (* 1 = 0.339103 loss)
I0525 01:57:10.523947 19044 solver.cpp:237] Iteration 52547, loss = 1.23886
I0525 01:57:10.523999 19044 solver.cpp:253]     Train net output #0: loss = 1.23886 (* 1 = 1.23886 loss)
I0525 01:57:10.524014 19044 sgd_solver.cpp:106] Iteration 52547, lr = 0.0045
I0525 01:57:19.186290 19044 solver.cpp:237] Iteration 52734, loss = 1.05015
I0525 01:57:19.186455 19044 solver.cpp:253]     Train net output #0: loss = 1.05015 (* 1 = 1.05015 loss)
I0525 01:57:19.186470 19044 sgd_solver.cpp:106] Iteration 52734, lr = 0.0045
I0525 01:57:27.846581 19044 solver.cpp:237] Iteration 52921, loss = 1.07691
I0525 01:57:27.846616 19044 solver.cpp:253]     Train net output #0: loss = 1.07691 (* 1 = 1.07691 loss)
I0525 01:57:27.846632 19044 sgd_solver.cpp:106] Iteration 52921, lr = 0.0045
I0525 01:57:36.510910 19044 solver.cpp:237] Iteration 53108, loss = 1.22159
I0525 01:57:36.510941 19044 solver.cpp:253]     Train net output #0: loss = 1.22159 (* 1 = 1.22159 loss)
I0525 01:57:36.510964 19044 sgd_solver.cpp:106] Iteration 53108, lr = 0.0045
I0525 01:57:45.173435 19044 solver.cpp:237] Iteration 53295, loss = 1.03437
I0525 01:57:45.173470 19044 solver.cpp:253]     Train net output #0: loss = 1.03437 (* 1 = 1.03437 loss)
I0525 01:57:45.173486 19044 sgd_solver.cpp:106] Iteration 53295, lr = 0.0045
I0525 01:57:53.829251 19044 solver.cpp:237] Iteration 53482, loss = 1.12968
I0525 01:57:53.829429 19044 solver.cpp:253]     Train net output #0: loss = 1.12968 (* 1 = 1.12968 loss)
I0525 01:57:53.829443 19044 sgd_solver.cpp:106] Iteration 53482, lr = 0.0045
I0525 01:58:02.491178 19044 solver.cpp:237] Iteration 53669, loss = 1.20494
I0525 01:58:02.491212 19044 solver.cpp:253]     Train net output #0: loss = 1.20494 (* 1 = 1.20494 loss)
I0525 01:58:02.491230 19044 sgd_solver.cpp:106] Iteration 53669, lr = 0.0045
I0525 01:58:32.020190 19044 solver.cpp:237] Iteration 53856, loss = 1.25184
I0525 01:58:32.020387 19044 solver.cpp:253]     Train net output #0: loss = 1.25184 (* 1 = 1.25184 loss)
I0525 01:58:32.020402 19044 sgd_solver.cpp:106] Iteration 53856, lr = 0.0045
I0525 01:58:40.683537 19044 solver.cpp:237] Iteration 54043, loss = 1.07489
I0525 01:58:40.683573 19044 solver.cpp:253]     Train net output #0: loss = 1.07489 (* 1 = 1.07489 loss)
I0525 01:58:40.683588 19044 sgd_solver.cpp:106] Iteration 54043, lr = 0.0045
I0525 01:58:49.346832 19044 solver.cpp:237] Iteration 54230, loss = 1.07337
I0525 01:58:49.346873 19044 solver.cpp:253]     Train net output #0: loss = 1.07337 (* 1 = 1.07337 loss)
I0525 01:58:49.346889 19044 sgd_solver.cpp:106] Iteration 54230, lr = 0.0045
I0525 01:58:56.016353 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_54375.caffemodel
I0525 01:58:56.089371 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_54375.solverstate
I0525 01:58:58.078078 19044 solver.cpp:237] Iteration 54417, loss = 1.15558
I0525 01:58:58.078126 19044 solver.cpp:253]     Train net output #0: loss = 1.15558 (* 1 = 1.15558 loss)
I0525 01:58:58.078142 19044 sgd_solver.cpp:106] Iteration 54417, lr = 0.0045
I0525 01:59:06.742460 19044 solver.cpp:237] Iteration 54604, loss = 1.157
I0525 01:59:06.742637 19044 solver.cpp:253]     Train net output #0: loss = 1.157 (* 1 = 1.157 loss)
I0525 01:59:06.742651 19044 sgd_solver.cpp:106] Iteration 54604, lr = 0.0045
I0525 01:59:15.409757 19044 solver.cpp:237] Iteration 54791, loss = 1.21087
I0525 01:59:15.409797 19044 solver.cpp:253]     Train net output #0: loss = 1.21087 (* 1 = 1.21087 loss)
I0525 01:59:15.409818 19044 sgd_solver.cpp:106] Iteration 54791, lr = 0.0045
I0525 01:59:24.069957 19044 solver.cpp:237] Iteration 54978, loss = 1.1794
I0525 01:59:24.069993 19044 solver.cpp:253]     Train net output #0: loss = 1.1794 (* 1 = 1.1794 loss)
I0525 01:59:24.070008 19044 sgd_solver.cpp:106] Iteration 54978, lr = 0.0045
I0525 01:59:53.592831 19044 solver.cpp:237] Iteration 55165, loss = 1.26628
I0525 01:59:53.593016 19044 solver.cpp:253]     Train net output #0: loss = 1.26628 (* 1 = 1.26628 loss)
I0525 01:59:53.593031 19044 sgd_solver.cpp:106] Iteration 55165, lr = 0.0045
I0525 02:00:02.256592 19044 solver.cpp:237] Iteration 55352, loss = 1.12836
I0525 02:00:02.256630 19044 solver.cpp:253]     Train net output #0: loss = 1.12836 (* 1 = 1.12836 loss)
I0525 02:00:02.256654 19044 sgd_solver.cpp:106] Iteration 55352, lr = 0.0045
I0525 02:00:10.915738 19044 solver.cpp:237] Iteration 55539, loss = 1.28172
I0525 02:00:10.915774 19044 solver.cpp:253]     Train net output #0: loss = 1.28172 (* 1 = 1.28172 loss)
I0525 02:00:10.915787 19044 sgd_solver.cpp:106] Iteration 55539, lr = 0.0045
I0525 02:00:19.579360 19044 solver.cpp:237] Iteration 55726, loss = 1.10096
I0525 02:00:19.579396 19044 solver.cpp:253]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0525 02:00:19.579412 19044 sgd_solver.cpp:106] Iteration 55726, lr = 0.0045
I0525 02:00:28.243835 19044 solver.cpp:237] Iteration 55913, loss = 1.27483
I0525 02:00:28.244010 19044 solver.cpp:253]     Train net output #0: loss = 1.27483 (* 1 = 1.27483 loss)
I0525 02:00:28.244024 19044 sgd_solver.cpp:106] Iteration 55913, lr = 0.0045
I0525 02:00:36.907335 19044 solver.cpp:237] Iteration 56100, loss = 1.14092
I0525 02:00:36.907368 19044 solver.cpp:253]     Train net output #0: loss = 1.14092 (* 1 = 1.14092 loss)
I0525 02:00:36.907387 19044 sgd_solver.cpp:106] Iteration 56100, lr = 0.0045
I0525 02:00:43.810433 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_56250.caffemodel
I0525 02:00:43.886670 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_56250.solverstate
I0525 02:00:43.914999 19044 solver.cpp:341] Iteration 56250, Testing net (#0)
I0525 02:01:31.029603 19044 solver.cpp:409]     Test net output #0: accuracy = 0.893927
I0525 02:01:31.029798 19044 solver.cpp:409]     Test net output #1: loss = 0.333188 (* 1 = 0.333188 loss)
I0525 02:01:53.614150 19044 solver.cpp:237] Iteration 56287, loss = 1.10962
I0525 02:01:53.614200 19044 solver.cpp:253]     Train net output #0: loss = 1.10962 (* 1 = 1.10962 loss)
I0525 02:01:53.614214 19044 sgd_solver.cpp:106] Iteration 56287, lr = 0.0045
I0525 02:02:02.270642 19044 solver.cpp:237] Iteration 56474, loss = 1.08278
I0525 02:02:02.270824 19044 solver.cpp:253]     Train net output #0: loss = 1.08278 (* 1 = 1.08278 loss)
I0525 02:02:02.270838 19044 sgd_solver.cpp:106] Iteration 56474, lr = 0.0045
I0525 02:02:10.926111 19044 solver.cpp:237] Iteration 56661, loss = 1.18097
I0525 02:02:10.926151 19044 solver.cpp:253]     Train net output #0: loss = 1.18097 (* 1 = 1.18097 loss)
I0525 02:02:10.926170 19044 sgd_solver.cpp:106] Iteration 56661, lr = 0.0045
I0525 02:02:19.585435 19044 solver.cpp:237] Iteration 56848, loss = 1.18157
I0525 02:02:19.585471 19044 solver.cpp:253]     Train net output #0: loss = 1.18157 (* 1 = 1.18157 loss)
I0525 02:02:19.585487 19044 sgd_solver.cpp:106] Iteration 56848, lr = 0.0045
I0525 02:02:28.240600 19044 solver.cpp:237] Iteration 57035, loss = 1.00146
I0525 02:02:28.240645 19044 solver.cpp:253]     Train net output #0: loss = 1.00146 (* 1 = 1.00146 loss)
I0525 02:02:28.240664 19044 sgd_solver.cpp:106] Iteration 57035, lr = 0.0045
I0525 02:02:36.894791 19044 solver.cpp:237] Iteration 57222, loss = 1.34117
I0525 02:02:36.894968 19044 solver.cpp:253]     Train net output #0: loss = 1.34117 (* 1 = 1.34117 loss)
I0525 02:02:36.894980 19044 sgd_solver.cpp:106] Iteration 57222, lr = 0.0045
I0525 02:02:45.550490 19044 solver.cpp:237] Iteration 57409, loss = 0.968118
I0525 02:02:45.550525 19044 solver.cpp:253]     Train net output #0: loss = 0.968118 (* 1 = 0.968118 loss)
I0525 02:02:45.550542 19044 sgd_solver.cpp:106] Iteration 57409, lr = 0.0045
I0525 02:03:15.050787 19044 solver.cpp:237] Iteration 57596, loss = 1.06148
I0525 02:03:15.050971 19044 solver.cpp:253]     Train net output #0: loss = 1.06148 (* 1 = 1.06148 loss)
I0525 02:03:15.050987 19044 sgd_solver.cpp:106] Iteration 57596, lr = 0.0045
I0525 02:03:23.705395 19044 solver.cpp:237] Iteration 57783, loss = 1.05676
I0525 02:03:23.705432 19044 solver.cpp:253]     Train net output #0: loss = 1.05676 (* 1 = 1.05676 loss)
I0525 02:03:23.705452 19044 sgd_solver.cpp:106] Iteration 57783, lr = 0.0045
I0525 02:03:32.365221 19044 solver.cpp:237] Iteration 57970, loss = 1.31653
I0525 02:03:32.365257 19044 solver.cpp:253]     Train net output #0: loss = 1.31653 (* 1 = 1.31653 loss)
I0525 02:03:32.365273 19044 sgd_solver.cpp:106] Iteration 57970, lr = 0.0045
I0525 02:03:39.494040 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_58125.caffemodel
I0525 02:03:39.563524 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_58125.solverstate
I0525 02:03:41.088358 19044 solver.cpp:237] Iteration 58157, loss = 1.16523
I0525 02:03:41.088403 19044 solver.cpp:253]     Train net output #0: loss = 1.16523 (* 1 = 1.16523 loss)
I0525 02:03:41.088421 19044 sgd_solver.cpp:106] Iteration 58157, lr = 0.0045
I0525 02:03:49.743638 19044 solver.cpp:237] Iteration 58344, loss = 1.16008
I0525 02:03:49.743829 19044 solver.cpp:253]     Train net output #0: loss = 1.16008 (* 1 = 1.16008 loss)
I0525 02:03:49.743844 19044 sgd_solver.cpp:106] Iteration 58344, lr = 0.0045
I0525 02:03:58.399559 19044 solver.cpp:237] Iteration 58531, loss = 1.135
I0525 02:03:58.399595 19044 solver.cpp:253]     Train net output #0: loss = 1.135 (* 1 = 1.135 loss)
I0525 02:03:58.399608 19044 sgd_solver.cpp:106] Iteration 58531, lr = 0.0045
I0525 02:04:07.055588 19044 solver.cpp:237] Iteration 58718, loss = 1.25275
I0525 02:04:07.055624 19044 solver.cpp:253]     Train net output #0: loss = 1.25275 (* 1 = 1.25275 loss)
I0525 02:04:07.055636 19044 sgd_solver.cpp:106] Iteration 58718, lr = 0.0045
I0525 02:04:36.564486 19044 solver.cpp:237] Iteration 58905, loss = 1.04741
I0525 02:04:36.564673 19044 solver.cpp:253]     Train net output #0: loss = 1.04741 (* 1 = 1.04741 loss)
I0525 02:04:36.564688 19044 sgd_solver.cpp:106] Iteration 58905, lr = 0.0045
I0525 02:04:45.219310 19044 solver.cpp:237] Iteration 59092, loss = 1.12343
I0525 02:04:45.219343 19044 solver.cpp:253]     Train net output #0: loss = 1.12343 (* 1 = 1.12343 loss)
I0525 02:04:45.219360 19044 sgd_solver.cpp:106] Iteration 59092, lr = 0.0045
I0525 02:04:53.875937 19044 solver.cpp:237] Iteration 59279, loss = 1.02212
I0525 02:04:53.875973 19044 solver.cpp:253]     Train net output #0: loss = 1.02212 (* 1 = 1.02212 loss)
I0525 02:04:53.875989 19044 sgd_solver.cpp:106] Iteration 59279, lr = 0.0045
I0525 02:05:02.530124 19044 solver.cpp:237] Iteration 59466, loss = 1.00264
I0525 02:05:02.530174 19044 solver.cpp:253]     Train net output #0: loss = 1.00264 (* 1 = 1.00264 loss)
I0525 02:05:02.530189 19044 sgd_solver.cpp:106] Iteration 59466, lr = 0.0045
I0525 02:05:11.181738 19044 solver.cpp:237] Iteration 59653, loss = 1.16299
I0525 02:05:11.181907 19044 solver.cpp:253]     Train net output #0: loss = 1.16299 (* 1 = 1.16299 loss)
I0525 02:05:11.181921 19044 sgd_solver.cpp:106] Iteration 59653, lr = 0.0045
I0525 02:05:19.842056 19044 solver.cpp:237] Iteration 59840, loss = 1.10258
I0525 02:05:19.842090 19044 solver.cpp:253]     Train net output #0: loss = 1.10258 (* 1 = 1.10258 loss)
I0525 02:05:19.842104 19044 sgd_solver.cpp:106] Iteration 59840, lr = 0.0045
I0525 02:05:27.203863 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_60000.caffemodel
I0525 02:05:27.273607 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_60000.solverstate
I0525 02:05:27.300165 19044 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 02:06:35.539285 19044 solver.cpp:409]     Test net output #0: accuracy = 0.895693
I0525 02:06:35.539474 19044 solver.cpp:409]     Test net output #1: loss = 0.341255 (* 1 = 0.341255 loss)
I0525 02:06:57.647660 19044 solver.cpp:237] Iteration 60027, loss = 1.00585
I0525 02:06:57.647711 19044 solver.cpp:253]     Train net output #0: loss = 1.00585 (* 1 = 1.00585 loss)
I0525 02:06:57.647725 19044 sgd_solver.cpp:106] Iteration 60027, lr = 0.0045
I0525 02:07:06.306275 19044 solver.cpp:237] Iteration 60214, loss = 0.921724
I0525 02:07:06.306455 19044 solver.cpp:253]     Train net output #0: loss = 0.921724 (* 1 = 0.921724 loss)
I0525 02:07:06.306470 19044 sgd_solver.cpp:106] Iteration 60214, lr = 0.0045
I0525 02:07:14.968228 19044 solver.cpp:237] Iteration 60401, loss = 1.15366
I0525 02:07:14.968263 19044 solver.cpp:253]     Train net output #0: loss = 1.15366 (* 1 = 1.15366 loss)
I0525 02:07:14.968278 19044 sgd_solver.cpp:106] Iteration 60401, lr = 0.0045
I0525 02:07:23.623464 19044 solver.cpp:237] Iteration 60588, loss = 0.924272
I0525 02:07:23.623502 19044 solver.cpp:253]     Train net output #0: loss = 0.924272 (* 1 = 0.924272 loss)
I0525 02:07:23.623517 19044 sgd_solver.cpp:106] Iteration 60588, lr = 0.0045
I0525 02:07:32.283753 19044 solver.cpp:237] Iteration 60775, loss = 1.19193
I0525 02:07:32.283797 19044 solver.cpp:253]     Train net output #0: loss = 1.19193 (* 1 = 1.19193 loss)
I0525 02:07:32.283815 19044 sgd_solver.cpp:106] Iteration 60775, lr = 0.0045
I0525 02:07:40.945152 19044 solver.cpp:237] Iteration 60962, loss = 1.11905
I0525 02:07:40.945327 19044 solver.cpp:253]     Train net output #0: loss = 1.11905 (* 1 = 1.11905 loss)
I0525 02:07:40.945340 19044 sgd_solver.cpp:106] Iteration 60962, lr = 0.0045
I0525 02:07:49.607427 19044 solver.cpp:237] Iteration 61149, loss = 1.11512
I0525 02:07:49.607462 19044 solver.cpp:253]     Train net output #0: loss = 1.11512 (* 1 = 1.11512 loss)
I0525 02:07:49.607480 19044 sgd_solver.cpp:106] Iteration 61149, lr = 0.0045
I0525 02:08:19.141719 19044 solver.cpp:237] Iteration 61336, loss = 1.3867
I0525 02:08:19.141909 19044 solver.cpp:253]     Train net output #0: loss = 1.3867 (* 1 = 1.3867 loss)
I0525 02:08:19.141923 19044 sgd_solver.cpp:106] Iteration 61336, lr = 0.0045
I0525 02:08:27.807948 19044 solver.cpp:237] Iteration 61523, loss = 1.15785
I0525 02:08:27.807983 19044 solver.cpp:253]     Train net output #0: loss = 1.15785 (* 1 = 1.15785 loss)
I0525 02:08:27.808001 19044 sgd_solver.cpp:106] Iteration 61523, lr = 0.0045
I0525 02:08:36.468559 19044 solver.cpp:237] Iteration 61710, loss = 1.15091
I0525 02:08:36.468595 19044 solver.cpp:253]     Train net output #0: loss = 1.15091 (* 1 = 1.15091 loss)
I0525 02:08:36.468611 19044 sgd_solver.cpp:106] Iteration 61710, lr = 0.0045
I0525 02:08:44.067469 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_61875.caffemodel
I0525 02:08:44.137428 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_61875.solverstate
I0525 02:08:45.200994 19044 solver.cpp:237] Iteration 61897, loss = 1.1484
I0525 02:08:45.201040 19044 solver.cpp:253]     Train net output #0: loss = 1.1484 (* 1 = 1.1484 loss)
I0525 02:08:45.201059 19044 sgd_solver.cpp:106] Iteration 61897, lr = 0.0045
I0525 02:08:53.864322 19044 solver.cpp:237] Iteration 62084, loss = 0.996713
I0525 02:08:53.864492 19044 solver.cpp:253]     Train net output #0: loss = 0.996713 (* 1 = 0.996713 loss)
I0525 02:08:53.864506 19044 sgd_solver.cpp:106] Iteration 62084, lr = 0.0045
I0525 02:09:02.522732 19044 solver.cpp:237] Iteration 62271, loss = 1.23295
I0525 02:09:02.522766 19044 solver.cpp:253]     Train net output #0: loss = 1.23295 (* 1 = 1.23295 loss)
I0525 02:09:02.522783 19044 sgd_solver.cpp:106] Iteration 62271, lr = 0.0045
I0525 02:09:11.184126 19044 solver.cpp:237] Iteration 62458, loss = 1.1654
I0525 02:09:11.184166 19044 solver.cpp:253]     Train net output #0: loss = 1.1654 (* 1 = 1.1654 loss)
I0525 02:09:11.184186 19044 sgd_solver.cpp:106] Iteration 62458, lr = 0.0045
I0525 02:09:40.683264 19044 solver.cpp:237] Iteration 62645, loss = 1.15027
I0525 02:09:40.683455 19044 solver.cpp:253]     Train net output #0: loss = 1.15027 (* 1 = 1.15027 loss)
I0525 02:09:40.683470 19044 sgd_solver.cpp:106] Iteration 62645, lr = 0.0045
I0525 02:09:49.344097 19044 solver.cpp:237] Iteration 62832, loss = 0.990825
I0525 02:09:49.344138 19044 solver.cpp:253]     Train net output #0: loss = 0.990825 (* 1 = 0.990825 loss)
I0525 02:09:49.344154 19044 sgd_solver.cpp:106] Iteration 62832, lr = 0.0045
I0525 02:09:58.003504 19044 solver.cpp:237] Iteration 63019, loss = 1.30924
I0525 02:09:58.003540 19044 solver.cpp:253]     Train net output #0: loss = 1.30924 (* 1 = 1.30924 loss)
I0525 02:09:58.003553 19044 sgd_solver.cpp:106] Iteration 63019, lr = 0.0045
I0525 02:10:06.663861 19044 solver.cpp:237] Iteration 63206, loss = 1.14017
I0525 02:10:06.663898 19044 solver.cpp:253]     Train net output #0: loss = 1.14017 (* 1 = 1.14017 loss)
I0525 02:10:06.663913 19044 sgd_solver.cpp:106] Iteration 63206, lr = 0.0045
I0525 02:10:15.323719 19044 solver.cpp:237] Iteration 63393, loss = 0.974085
I0525 02:10:15.323897 19044 solver.cpp:253]     Train net output #0: loss = 0.974085 (* 1 = 0.974085 loss)
I0525 02:10:15.323911 19044 sgd_solver.cpp:106] Iteration 63393, lr = 0.0045
I0525 02:10:23.982139 19044 solver.cpp:237] Iteration 63580, loss = 1.04244
I0525 02:10:23.982182 19044 solver.cpp:253]     Train net output #0: loss = 1.04244 (* 1 = 1.04244 loss)
I0525 02:10:23.982200 19044 sgd_solver.cpp:106] Iteration 63580, lr = 0.0045
I0525 02:10:31.810360 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_63750.caffemodel
I0525 02:10:31.881294 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_63750.solverstate
I0525 02:10:31.909299 19044 solver.cpp:341] Iteration 63750, Testing net (#0)
I0525 02:11:19.294790 19044 solver.cpp:409]     Test net output #0: accuracy = 0.893834
I0525 02:11:19.294973 19044 solver.cpp:409]     Test net output #1: loss = 0.366755 (* 1 = 0.366755 loss)
I0525 02:11:40.935993 19044 solver.cpp:237] Iteration 63767, loss = 1.04502
I0525 02:11:40.936043 19044 solver.cpp:253]     Train net output #0: loss = 1.04502 (* 1 = 1.04502 loss)
I0525 02:11:40.936058 19044 sgd_solver.cpp:106] Iteration 63767, lr = 0.0045
I0525 02:11:49.584220 19044 solver.cpp:237] Iteration 63954, loss = 1.20526
I0525 02:11:49.584395 19044 solver.cpp:253]     Train net output #0: loss = 1.20526 (* 1 = 1.20526 loss)
I0525 02:11:49.584409 19044 sgd_solver.cpp:106] Iteration 63954, lr = 0.0045
I0525 02:11:58.234545 19044 solver.cpp:237] Iteration 64141, loss = 1.15969
I0525 02:11:58.234580 19044 solver.cpp:253]     Train net output #0: loss = 1.15969 (* 1 = 1.15969 loss)
I0525 02:11:58.234596 19044 sgd_solver.cpp:106] Iteration 64141, lr = 0.0045
I0525 02:12:06.888543 19044 solver.cpp:237] Iteration 64328, loss = 1.18971
I0525 02:12:06.888592 19044 solver.cpp:253]     Train net output #0: loss = 1.18971 (* 1 = 1.18971 loss)
I0525 02:12:06.888607 19044 sgd_solver.cpp:106] Iteration 64328, lr = 0.0045
I0525 02:12:15.536433 19044 solver.cpp:237] Iteration 64515, loss = 1.09074
I0525 02:12:15.536468 19044 solver.cpp:253]     Train net output #0: loss = 1.09074 (* 1 = 1.09074 loss)
I0525 02:12:15.536483 19044 sgd_solver.cpp:106] Iteration 64515, lr = 0.0045
I0525 02:12:24.190043 19044 solver.cpp:237] Iteration 64702, loss = 1.15608
I0525 02:12:24.190213 19044 solver.cpp:253]     Train net output #0: loss = 1.15608 (* 1 = 1.15608 loss)
I0525 02:12:24.190227 19044 sgd_solver.cpp:106] Iteration 64702, lr = 0.0045
I0525 02:12:32.834291 19044 solver.cpp:237] Iteration 64889, loss = 1.27429
I0525 02:12:32.834336 19044 solver.cpp:253]     Train net output #0: loss = 1.27429 (* 1 = 1.27429 loss)
I0525 02:12:32.834352 19044 sgd_solver.cpp:106] Iteration 64889, lr = 0.0045
I0525 02:13:02.321692 19044 solver.cpp:237] Iteration 65076, loss = 1.24949
I0525 02:13:02.321883 19044 solver.cpp:253]     Train net output #0: loss = 1.24949 (* 1 = 1.24949 loss)
I0525 02:13:02.321898 19044 sgd_solver.cpp:106] Iteration 65076, lr = 0.0045
I0525 02:13:10.974412 19044 solver.cpp:237] Iteration 65263, loss = 1.27632
I0525 02:13:10.974447 19044 solver.cpp:253]     Train net output #0: loss = 1.27632 (* 1 = 1.27632 loss)
I0525 02:13:10.974462 19044 sgd_solver.cpp:106] Iteration 65263, lr = 0.0045
I0525 02:13:19.623265 19044 solver.cpp:237] Iteration 65450, loss = 0.943957
I0525 02:13:19.623316 19044 solver.cpp:253]     Train net output #0: loss = 0.943957 (* 1 = 0.943957 loss)
I0525 02:13:19.623329 19044 sgd_solver.cpp:106] Iteration 65450, lr = 0.0045
I0525 02:13:27.667562 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_65625.caffemodel
I0525 02:13:27.738976 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_65625.solverstate
I0525 02:13:28.338562 19044 solver.cpp:237] Iteration 65637, loss = 1.00633
I0525 02:13:28.338613 19044 solver.cpp:253]     Train net output #0: loss = 1.00633 (* 1 = 1.00633 loss)
I0525 02:13:28.338627 19044 sgd_solver.cpp:106] Iteration 65637, lr = 0.0045
I0525 02:13:36.987505 19044 solver.cpp:237] Iteration 65824, loss = 1.06195
I0525 02:13:36.987690 19044 solver.cpp:253]     Train net output #0: loss = 1.06195 (* 1 = 1.06195 loss)
I0525 02:13:36.987704 19044 sgd_solver.cpp:106] Iteration 65824, lr = 0.0045
I0525 02:13:45.638865 19044 solver.cpp:237] Iteration 66011, loss = 1.09409
I0525 02:13:45.638912 19044 solver.cpp:253]     Train net output #0: loss = 1.09409 (* 1 = 1.09409 loss)
I0525 02:13:45.638927 19044 sgd_solver.cpp:106] Iteration 66011, lr = 0.0045
I0525 02:13:54.289026 19044 solver.cpp:237] Iteration 66198, loss = 1.26575
I0525 02:13:54.289062 19044 solver.cpp:253]     Train net output #0: loss = 1.26575 (* 1 = 1.26575 loss)
I0525 02:13:54.289077 19044 sgd_solver.cpp:106] Iteration 66198, lr = 0.0045
I0525 02:14:23.844718 19044 solver.cpp:237] Iteration 66385, loss = 1.06065
I0525 02:14:23.844907 19044 solver.cpp:253]     Train net output #0: loss = 1.06065 (* 1 = 1.06065 loss)
I0525 02:14:23.844923 19044 sgd_solver.cpp:106] Iteration 66385, lr = 0.0045
I0525 02:14:32.492086 19044 solver.cpp:237] Iteration 66572, loss = 1.20548
I0525 02:14:32.492126 19044 solver.cpp:253]     Train net output #0: loss = 1.20548 (* 1 = 1.20548 loss)
I0525 02:14:32.492141 19044 sgd_solver.cpp:106] Iteration 66572, lr = 0.0045
I0525 02:14:41.137379 19044 solver.cpp:237] Iteration 66759, loss = 1.12181
I0525 02:14:41.137421 19044 solver.cpp:253]     Train net output #0: loss = 1.12181 (* 1 = 1.12181 loss)
I0525 02:14:41.137439 19044 sgd_solver.cpp:106] Iteration 66759, lr = 0.0045
I0525 02:14:49.785327 19044 solver.cpp:237] Iteration 66946, loss = 1.09123
I0525 02:14:49.785363 19044 solver.cpp:253]     Train net output #0: loss = 1.09123 (* 1 = 1.09123 loss)
I0525 02:14:49.785377 19044 sgd_solver.cpp:106] Iteration 66946, lr = 0.0045
I0525 02:14:58.434294 19044 solver.cpp:237] Iteration 67133, loss = 1.05553
I0525 02:14:58.434471 19044 solver.cpp:253]     Train net output #0: loss = 1.05553 (* 1 = 1.05553 loss)
I0525 02:14:58.434485 19044 sgd_solver.cpp:106] Iteration 67133, lr = 0.0045
I0525 02:15:07.081802 19044 solver.cpp:237] Iteration 67320, loss = 1.12256
I0525 02:15:07.081837 19044 solver.cpp:253]     Train net output #0: loss = 1.12256 (* 1 = 1.12256 loss)
I0525 02:15:07.081852 19044 sgd_solver.cpp:106] Iteration 67320, lr = 0.0045
I0525 02:15:15.363272 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_67500.caffemodel
I0525 02:15:15.435156 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_67500.solverstate
I0525 02:15:15.463809 19044 solver.cpp:341] Iteration 67500, Testing net (#0)
I0525 02:16:23.802842 19044 solver.cpp:409]     Test net output #0: accuracy = 0.896855
I0525 02:16:23.803032 19044 solver.cpp:409]     Test net output #1: loss = 0.317796 (* 1 = 0.317796 loss)
I0525 02:16:45.028607 19044 solver.cpp:237] Iteration 67507, loss = 1.12171
I0525 02:16:45.028659 19044 solver.cpp:253]     Train net output #0: loss = 1.12171 (* 1 = 1.12171 loss)
I0525 02:16:45.028673 19044 sgd_solver.cpp:106] Iteration 67507, lr = 0.0045
I0525 02:16:53.689810 19044 solver.cpp:237] Iteration 67694, loss = 1.16437
I0525 02:16:53.689846 19044 solver.cpp:253]     Train net output #0: loss = 1.16437 (* 1 = 1.16437 loss)
I0525 02:16:53.689860 19044 sgd_solver.cpp:106] Iteration 67694, lr = 0.0045
I0525 02:17:02.352067 19044 solver.cpp:237] Iteration 67881, loss = 1.15156
I0525 02:17:02.352246 19044 solver.cpp:253]     Train net output #0: loss = 1.15156 (* 1 = 1.15156 loss)
I0525 02:17:02.352260 19044 sgd_solver.cpp:106] Iteration 67881, lr = 0.0045
I0525 02:17:11.011766 19044 solver.cpp:237] Iteration 68068, loss = 1.26926
I0525 02:17:11.011806 19044 solver.cpp:253]     Train net output #0: loss = 1.26926 (* 1 = 1.26926 loss)
I0525 02:17:11.011824 19044 sgd_solver.cpp:106] Iteration 68068, lr = 0.0045
I0525 02:17:19.675869 19044 solver.cpp:237] Iteration 68255, loss = 1.01511
I0525 02:17:19.675906 19044 solver.cpp:253]     Train net output #0: loss = 1.01511 (* 1 = 1.01511 loss)
I0525 02:17:19.675920 19044 sgd_solver.cpp:106] Iteration 68255, lr = 0.0045
I0525 02:17:28.341536 19044 solver.cpp:237] Iteration 68442, loss = 1.13159
I0525 02:17:28.341579 19044 solver.cpp:253]     Train net output #0: loss = 1.13159 (* 1 = 1.13159 loss)
I0525 02:17:28.341596 19044 sgd_solver.cpp:106] Iteration 68442, lr = 0.0045
I0525 02:17:37.006950 19044 solver.cpp:237] Iteration 68629, loss = 1.2374
I0525 02:17:37.007130 19044 solver.cpp:253]     Train net output #0: loss = 1.2374 (* 1 = 1.2374 loss)
I0525 02:17:37.007144 19044 sgd_solver.cpp:106] Iteration 68629, lr = 0.0045
I0525 02:18:06.546473 19044 solver.cpp:237] Iteration 68816, loss = 1.00623
I0525 02:18:06.546525 19044 solver.cpp:253]     Train net output #0: loss = 1.00623 (* 1 = 1.00623 loss)
I0525 02:18:06.546540 19044 sgd_solver.cpp:106] Iteration 68816, lr = 0.0045
I0525 02:18:15.207381 19044 solver.cpp:237] Iteration 69003, loss = 1.0754
I0525 02:18:15.207556 19044 solver.cpp:253]     Train net output #0: loss = 1.0754 (* 1 = 1.0754 loss)
I0525 02:18:15.207569 19044 sgd_solver.cpp:106] Iteration 69003, lr = 0.0045
I0525 02:18:23.875833 19044 solver.cpp:237] Iteration 69190, loss = 1.10118
I0525 02:18:23.875881 19044 solver.cpp:253]     Train net output #0: loss = 1.10118 (* 1 = 1.10118 loss)
I0525 02:18:23.875895 19044 sgd_solver.cpp:106] Iteration 69190, lr = 0.0045
I0525 02:18:32.399740 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_69375.caffemodel
I0525 02:18:32.470186 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_69375.solverstate
I0525 02:18:32.603672 19044 solver.cpp:237] Iteration 69377, loss = 1.16911
I0525 02:18:32.603718 19044 solver.cpp:253]     Train net output #0: loss = 1.16911 (* 1 = 1.16911 loss)
I0525 02:18:32.603731 19044 sgd_solver.cpp:106] Iteration 69377, lr = 0.0045
I0525 02:18:41.268718 19044 solver.cpp:237] Iteration 69564, loss = 1.25762
I0525 02:18:41.268754 19044 solver.cpp:253]     Train net output #0: loss = 1.25762 (* 1 = 1.25762 loss)
I0525 02:18:41.268767 19044 sgd_solver.cpp:106] Iteration 69564, lr = 0.0045
I0525 02:18:49.934211 19044 solver.cpp:237] Iteration 69751, loss = 1.10237
I0525 02:18:49.934396 19044 solver.cpp:253]     Train net output #0: loss = 1.10237 (* 1 = 1.10237 loss)
I0525 02:18:49.934411 19044 sgd_solver.cpp:106] Iteration 69751, lr = 0.0045
I0525 02:18:58.597620 19044 solver.cpp:237] Iteration 69938, loss = 1.14779
I0525 02:18:58.597654 19044 solver.cpp:253]     Train net output #0: loss = 1.14779 (* 1 = 1.14779 loss)
I0525 02:18:58.597669 19044 sgd_solver.cpp:106] Iteration 69938, lr = 0.0045
I0525 02:19:28.111636 19044 solver.cpp:237] Iteration 70125, loss = 1.11977
I0525 02:19:28.111830 19044 solver.cpp:253]     Train net output #0: loss = 1.11977 (* 1 = 1.11977 loss)
I0525 02:19:28.111845 19044 sgd_solver.cpp:106] Iteration 70125, lr = 0.0045
I0525 02:19:36.773677 19044 solver.cpp:237] Iteration 70312, loss = 1.27333
I0525 02:19:36.773720 19044 solver.cpp:253]     Train net output #0: loss = 1.27333 (* 1 = 1.27333 loss)
I0525 02:19:36.773737 19044 sgd_solver.cpp:106] Iteration 70312, lr = 0.0045
I0525 02:19:45.434430 19044 solver.cpp:237] Iteration 70499, loss = 1.0568
I0525 02:19:45.434466 19044 solver.cpp:253]     Train net output #0: loss = 1.0568 (* 1 = 1.0568 loss)
I0525 02:19:45.434483 19044 sgd_solver.cpp:106] Iteration 70499, lr = 0.0045
I0525 02:19:54.097288 19044 solver.cpp:237] Iteration 70686, loss = 1.08281
I0525 02:19:54.097324 19044 solver.cpp:253]     Train net output #0: loss = 1.08281 (* 1 = 1.08281 loss)
I0525 02:19:54.097339 19044 sgd_solver.cpp:106] Iteration 70686, lr = 0.0045
I0525 02:20:02.762410 19044 solver.cpp:237] Iteration 70873, loss = 1.23663
I0525 02:20:02.762608 19044 solver.cpp:253]     Train net output #0: loss = 1.23663 (* 1 = 1.23663 loss)
I0525 02:20:02.762621 19044 sgd_solver.cpp:106] Iteration 70873, lr = 0.0045
I0525 02:20:11.420755 19044 solver.cpp:237] Iteration 71060, loss = 1.02617
I0525 02:20:11.420790 19044 solver.cpp:253]     Train net output #0: loss = 1.02617 (* 1 = 1.02617 loss)
I0525 02:20:11.420806 19044 sgd_solver.cpp:106] Iteration 71060, lr = 0.0045
I0525 02:20:20.083119 19044 solver.cpp:237] Iteration 71247, loss = 1.16373
I0525 02:20:20.083155 19044 solver.cpp:253]     Train net output #0: loss = 1.16373 (* 1 = 1.16373 loss)
I0525 02:20:20.083170 19044 sgd_solver.cpp:106] Iteration 71247, lr = 0.0045
I0525 02:20:20.176723 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_71250.caffemodel
I0525 02:20:20.247004 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_71250.solverstate
I0525 02:20:20.273468 19044 solver.cpp:341] Iteration 71250, Testing net (#0)
I0525 02:21:07.361830 19044 solver.cpp:409]     Test net output #0: accuracy = 0.898641
I0525 02:21:07.362031 19044 solver.cpp:409]     Test net output #1: loss = 0.324199 (* 1 = 0.324199 loss)
I0525 02:21:36.733208 19044 solver.cpp:237] Iteration 71434, loss = 1.1907
I0525 02:21:36.733258 19044 solver.cpp:253]     Train net output #0: loss = 1.1907 (* 1 = 1.1907 loss)
I0525 02:21:36.733273 19044 sgd_solver.cpp:106] Iteration 71434, lr = 0.0045
I0525 02:21:45.390512 19044 solver.cpp:237] Iteration 71621, loss = 1.19768
I0525 02:21:45.390692 19044 solver.cpp:253]     Train net output #0: loss = 1.19768 (* 1 = 1.19768 loss)
I0525 02:21:45.390707 19044 sgd_solver.cpp:106] Iteration 71621, lr = 0.0045
I0525 02:21:54.042106 19044 solver.cpp:237] Iteration 71808, loss = 0.998576
I0525 02:21:54.042143 19044 solver.cpp:253]     Train net output #0: loss = 0.998576 (* 1 = 0.998576 loss)
I0525 02:21:54.042157 19044 sgd_solver.cpp:106] Iteration 71808, lr = 0.0045
I0525 02:22:02.701627 19044 solver.cpp:237] Iteration 71995, loss = 1.10584
I0525 02:22:02.701663 19044 solver.cpp:253]     Train net output #0: loss = 1.10584 (* 1 = 1.10584 loss)
I0525 02:22:02.701675 19044 sgd_solver.cpp:106] Iteration 71995, lr = 0.0045
I0525 02:22:11.356978 19044 solver.cpp:237] Iteration 72182, loss = 1.23925
I0525 02:22:11.357017 19044 solver.cpp:253]     Train net output #0: loss = 1.23925 (* 1 = 1.23925 loss)
I0525 02:22:11.357033 19044 sgd_solver.cpp:106] Iteration 72182, lr = 0.0045
I0525 02:22:20.015290 19044 solver.cpp:237] Iteration 72369, loss = 1.10441
I0525 02:22:20.015462 19044 solver.cpp:253]     Train net output #0: loss = 1.10441 (* 1 = 1.10441 loss)
I0525 02:22:20.015476 19044 sgd_solver.cpp:106] Iteration 72369, lr = 0.0045
I0525 02:22:49.548177 19044 solver.cpp:237] Iteration 72556, loss = 1.15877
I0525 02:22:49.548228 19044 solver.cpp:253]     Train net output #0: loss = 1.15877 (* 1 = 1.15877 loss)
I0525 02:22:49.548243 19044 sgd_solver.cpp:106] Iteration 72556, lr = 0.0045
I0525 02:22:58.200649 19044 solver.cpp:237] Iteration 72743, loss = 0.944447
I0525 02:22:58.200827 19044 solver.cpp:253]     Train net output #0: loss = 0.944447 (* 1 = 0.944447 loss)
I0525 02:22:58.200840 19044 sgd_solver.cpp:106] Iteration 72743, lr = 0.0045
I0525 02:23:06.853581 19044 solver.cpp:237] Iteration 72930, loss = 1.00413
I0525 02:23:06.853616 19044 solver.cpp:253]     Train net output #0: loss = 1.00413 (* 1 = 1.00413 loss)
I0525 02:23:06.853631 19044 sgd_solver.cpp:106] Iteration 72930, lr = 0.0045
I0525 02:23:15.509150 19044 solver.cpp:237] Iteration 73117, loss = 0.979551
I0525 02:23:15.509186 19044 solver.cpp:253]     Train net output #0: loss = 0.979551 (* 1 = 0.979551 loss)
I0525 02:23:15.509201 19044 sgd_solver.cpp:106] Iteration 73117, lr = 0.0045
I0525 02:23:15.833359 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_73125.caffemodel
I0525 02:23:15.905588 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_73125.solverstate
I0525 02:23:24.229392 19044 solver.cpp:237] Iteration 73304, loss = 0.954865
I0525 02:23:24.229440 19044 solver.cpp:253]     Train net output #0: loss = 0.954865 (* 1 = 0.954865 loss)
I0525 02:23:24.229456 19044 sgd_solver.cpp:106] Iteration 73304, lr = 0.0045
I0525 02:23:32.881003 19044 solver.cpp:237] Iteration 73491, loss = 1.15269
I0525 02:23:32.881186 19044 solver.cpp:253]     Train net output #0: loss = 1.15269 (* 1 = 1.15269 loss)
I0525 02:23:32.881201 19044 sgd_solver.cpp:106] Iteration 73491, lr = 0.0045
I0525 02:23:41.541002 19044 solver.cpp:237] Iteration 73678, loss = 0.963435
I0525 02:23:41.541038 19044 solver.cpp:253]     Train net output #0: loss = 0.963435 (* 1 = 0.963435 loss)
I0525 02:23:41.541052 19044 sgd_solver.cpp:106] Iteration 73678, lr = 0.0045
I0525 02:24:11.058946 19044 solver.cpp:237] Iteration 73865, loss = 1.30564
I0525 02:24:11.059137 19044 solver.cpp:253]     Train net output #0: loss = 1.30564 (* 1 = 1.30564 loss)
I0525 02:24:11.059152 19044 sgd_solver.cpp:106] Iteration 73865, lr = 0.0045
I0525 02:24:19.717046 19044 solver.cpp:237] Iteration 74052, loss = 0.986772
I0525 02:24:19.717080 19044 solver.cpp:253]     Train net output #0: loss = 0.986772 (* 1 = 0.986772 loss)
I0525 02:24:19.717094 19044 sgd_solver.cpp:106] Iteration 74052, lr = 0.0045
I0525 02:24:28.375898 19044 solver.cpp:237] Iteration 74239, loss = 1.43337
I0525 02:24:28.375933 19044 solver.cpp:253]     Train net output #0: loss = 1.43337 (* 1 = 1.43337 loss)
I0525 02:24:28.375947 19044 sgd_solver.cpp:106] Iteration 74239, lr = 0.0045
I0525 02:24:37.029762 19044 solver.cpp:237] Iteration 74426, loss = 1.16861
I0525 02:24:37.029809 19044 solver.cpp:253]     Train net output #0: loss = 1.16861 (* 1 = 1.16861 loss)
I0525 02:24:37.029824 19044 sgd_solver.cpp:106] Iteration 74426, lr = 0.0045
I0525 02:24:45.689627 19044 solver.cpp:237] Iteration 74613, loss = 1.01446
I0525 02:24:45.689801 19044 solver.cpp:253]     Train net output #0: loss = 1.01446 (* 1 = 1.01446 loss)
I0525 02:24:45.689815 19044 sgd_solver.cpp:106] Iteration 74613, lr = 0.0045
I0525 02:24:54.346225 19044 solver.cpp:237] Iteration 74800, loss = 0.935243
I0525 02:24:54.346259 19044 solver.cpp:253]     Train net output #0: loss = 0.935243 (* 1 = 0.935243 loss)
I0525 02:24:54.346274 19044 sgd_solver.cpp:106] Iteration 74800, lr = 0.0045
I0525 02:25:03.004815 19044 solver.cpp:237] Iteration 74987, loss = 1.20604
I0525 02:25:03.004864 19044 solver.cpp:253]     Train net output #0: loss = 1.20604 (* 1 = 1.20604 loss)
I0525 02:25:03.004878 19044 sgd_solver.cpp:106] Iteration 74987, lr = 0.0045
I0525 02:25:03.561100 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_75000.caffemodel
I0525 02:25:03.632263 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_75000.solverstate
I0525 02:25:03.661299 19044 solver.cpp:341] Iteration 75000, Testing net (#0)
I0525 02:26:11.933955 19044 solver.cpp:409]     Test net output #0: accuracy = 0.89742
I0525 02:26:11.934147 19044 solver.cpp:409]     Test net output #1: loss = 0.3239 (* 1 = 0.3239 loss)
I0525 02:26:40.842989 19044 solver.cpp:237] Iteration 75174, loss = 1.01734
I0525 02:26:40.843039 19044 solver.cpp:253]     Train net output #0: loss = 1.01734 (* 1 = 1.01734 loss)
I0525 02:26:40.843055 19044 sgd_solver.cpp:106] Iteration 75174, lr = 0.0045
I0525 02:26:49.497730 19044 solver.cpp:237] Iteration 75361, loss = 1.12174
I0525 02:26:49.497927 19044 solver.cpp:253]     Train net output #0: loss = 1.12174 (* 1 = 1.12174 loss)
I0525 02:26:49.497941 19044 sgd_solver.cpp:106] Iteration 75361, lr = 0.0045
I0525 02:26:58.156420 19044 solver.cpp:237] Iteration 75548, loss = 1.31558
I0525 02:26:58.156455 19044 solver.cpp:253]     Train net output #0: loss = 1.31558 (* 1 = 1.31558 loss)
I0525 02:26:58.156471 19044 sgd_solver.cpp:106] Iteration 75548, lr = 0.0045
I0525 02:27:06.819377 19044 solver.cpp:237] Iteration 75735, loss = 1.12222
I0525 02:27:06.819427 19044 solver.cpp:253]     Train net output #0: loss = 1.12222 (* 1 = 1.12222 loss)
I0525 02:27:06.819440 19044 sgd_solver.cpp:106] Iteration 75735, lr = 0.0045
I0525 02:27:15.478911 19044 solver.cpp:237] Iteration 75922, loss = 1.17811
I0525 02:27:15.478946 19044 solver.cpp:253]     Train net output #0: loss = 1.17811 (* 1 = 1.17811 loss)
I0525 02:27:15.478960 19044 sgd_solver.cpp:106] Iteration 75922, lr = 0.0045
I0525 02:27:24.135673 19044 solver.cpp:237] Iteration 76109, loss = 1.31744
I0525 02:27:24.135849 19044 solver.cpp:253]     Train net output #0: loss = 1.31744 (* 1 = 1.31744 loss)
I0525 02:27:24.135862 19044 sgd_solver.cpp:106] Iteration 76109, lr = 0.0045
I0525 02:27:53.631194 19044 solver.cpp:237] Iteration 76296, loss = 1.26631
I0525 02:27:53.631245 19044 solver.cpp:253]     Train net output #0: loss = 1.26631 (* 1 = 1.26631 loss)
I0525 02:27:53.631259 19044 sgd_solver.cpp:106] Iteration 76296, lr = 0.0045
I0525 02:28:02.289932 19044 solver.cpp:237] Iteration 76483, loss = 1.13533
I0525 02:28:02.290108 19044 solver.cpp:253]     Train net output #0: loss = 1.13533 (* 1 = 1.13533 loss)
I0525 02:28:02.290122 19044 sgd_solver.cpp:106] Iteration 76483, lr = 0.0045
I0525 02:28:10.954121 19044 solver.cpp:237] Iteration 76670, loss = 1.19756
I0525 02:28:10.954156 19044 solver.cpp:253]     Train net output #0: loss = 1.19756 (* 1 = 1.19756 loss)
I0525 02:28:10.954171 19044 sgd_solver.cpp:106] Iteration 76670, lr = 0.0045
I0525 02:28:19.615396 19044 solver.cpp:237] Iteration 76857, loss = 1.13113
I0525 02:28:19.615442 19044 solver.cpp:253]     Train net output #0: loss = 1.13113 (* 1 = 1.13113 loss)
I0525 02:28:19.615455 19044 sgd_solver.cpp:106] Iteration 76857, lr = 0.0045
I0525 02:28:20.402650 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_76875.caffemodel
I0525 02:28:20.471854 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_76875.solverstate
I0525 02:28:28.337884 19044 solver.cpp:237] Iteration 77044, loss = 0.890803
I0525 02:28:28.337931 19044 solver.cpp:253]     Train net output #0: loss = 0.890803 (* 1 = 0.890803 loss)
I0525 02:28:28.337945 19044 sgd_solver.cpp:106] Iteration 77044, lr = 0.0045
I0525 02:28:36.994861 19044 solver.cpp:237] Iteration 77231, loss = 1.2652
I0525 02:28:36.995039 19044 solver.cpp:253]     Train net output #0: loss = 1.2652 (* 1 = 1.2652 loss)
I0525 02:28:36.995053 19044 sgd_solver.cpp:106] Iteration 77231, lr = 0.0045
I0525 02:28:45.654662 19044 solver.cpp:237] Iteration 77418, loss = 1.26323
I0525 02:28:45.654705 19044 solver.cpp:253]     Train net output #0: loss = 1.26323 (* 1 = 1.26323 loss)
I0525 02:28:45.654721 19044 sgd_solver.cpp:106] Iteration 77418, lr = 0.0045
I0525 02:29:15.141603 19044 solver.cpp:237] Iteration 77605, loss = 1.20426
I0525 02:29:15.141798 19044 solver.cpp:253]     Train net output #0: loss = 1.20426 (* 1 = 1.20426 loss)
I0525 02:29:15.141813 19044 sgd_solver.cpp:106] Iteration 77605, lr = 0.0045
I0525 02:29:23.800860 19044 solver.cpp:237] Iteration 77792, loss = 1.35454
I0525 02:29:23.800895 19044 solver.cpp:253]     Train net output #0: loss = 1.35454 (* 1 = 1.35454 loss)
I0525 02:29:23.800910 19044 sgd_solver.cpp:106] Iteration 77792, lr = 0.0045
I0525 02:29:32.463182 19044 solver.cpp:237] Iteration 77979, loss = 1.08279
I0525 02:29:32.463218 19044 solver.cpp:253]     Train net output #0: loss = 1.08279 (* 1 = 1.08279 loss)
I0525 02:29:32.463233 19044 sgd_solver.cpp:106] Iteration 77979, lr = 0.0045
I0525 02:29:41.124686 19044 solver.cpp:237] Iteration 78166, loss = 1.21059
I0525 02:29:41.124727 19044 solver.cpp:253]     Train net output #0: loss = 1.21059 (* 1 = 1.21059 loss)
I0525 02:29:41.124745 19044 sgd_solver.cpp:106] Iteration 78166, lr = 0.0045
I0525 02:29:49.782619 19044 solver.cpp:237] Iteration 78353, loss = 1.05317
I0525 02:29:49.782805 19044 solver.cpp:253]     Train net output #0: loss = 1.05317 (* 1 = 1.05317 loss)
I0525 02:29:49.782819 19044 sgd_solver.cpp:106] Iteration 78353, lr = 0.0045
I0525 02:29:58.442805 19044 solver.cpp:237] Iteration 78540, loss = 1.21222
I0525 02:29:58.442849 19044 solver.cpp:253]     Train net output #0: loss = 1.21222 (* 1 = 1.21222 loss)
I0525 02:29:58.442864 19044 sgd_solver.cpp:106] Iteration 78540, lr = 0.0045
I0525 02:30:07.104384 19044 solver.cpp:237] Iteration 78727, loss = 1.21224
I0525 02:30:07.104420 19044 solver.cpp:253]     Train net output #0: loss = 1.21224 (* 1 = 1.21224 loss)
I0525 02:30:07.104435 19044 sgd_solver.cpp:106] Iteration 78727, lr = 0.0045
I0525 02:30:08.124946 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_78750.caffemodel
I0525 02:30:08.194355 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_78750.solverstate
I0525 02:30:08.220803 19044 solver.cpp:341] Iteration 78750, Testing net (#0)
I0525 02:30:55.582589 19044 solver.cpp:409]     Test net output #0: accuracy = 0.89954
I0525 02:30:55.582782 19044 solver.cpp:409]     Test net output #1: loss = 0.318846 (* 1 = 0.318846 loss)
I0525 02:31:24.008010 19044 solver.cpp:237] Iteration 78914, loss = 0.887773
I0525 02:31:24.008064 19044 solver.cpp:253]     Train net output #0: loss = 0.887773 (* 1 = 0.887773 loss)
I0525 02:31:24.008076 19044 sgd_solver.cpp:106] Iteration 78914, lr = 0.0045
I0525 02:31:32.656536 19044 solver.cpp:237] Iteration 79101, loss = 1.15221
I0525 02:31:32.656716 19044 solver.cpp:253]     Train net output #0: loss = 1.15221 (* 1 = 1.15221 loss)
I0525 02:31:32.656729 19044 sgd_solver.cpp:106] Iteration 79101, lr = 0.0045
I0525 02:31:41.305961 19044 solver.cpp:237] Iteration 79288, loss = 1.11653
I0525 02:31:41.306004 19044 solver.cpp:253]     Train net output #0: loss = 1.11653 (* 1 = 1.11653 loss)
I0525 02:31:41.306022 19044 sgd_solver.cpp:106] Iteration 79288, lr = 0.0045
I0525 02:31:49.953063 19044 solver.cpp:237] Iteration 79475, loss = 1.26436
I0525 02:31:49.953099 19044 solver.cpp:253]     Train net output #0: loss = 1.26436 (* 1 = 1.26436 loss)
I0525 02:31:49.953114 19044 sgd_solver.cpp:106] Iteration 79475, lr = 0.0045
I0525 02:31:58.603127 19044 solver.cpp:237] Iteration 79662, loss = 0.980225
I0525 02:31:58.603162 19044 solver.cpp:253]     Train net output #0: loss = 0.980225 (* 1 = 0.980225 loss)
I0525 02:31:58.603176 19044 sgd_solver.cpp:106] Iteration 79662, lr = 0.0045
I0525 02:32:07.248558 19044 solver.cpp:237] Iteration 79849, loss = 1.10887
I0525 02:32:07.248738 19044 solver.cpp:253]     Train net output #0: loss = 1.10887 (* 1 = 1.10887 loss)
I0525 02:32:07.248751 19044 sgd_solver.cpp:106] Iteration 79849, lr = 0.0045
I0525 02:32:36.754935 19044 solver.cpp:237] Iteration 80036, loss = 1.02637
I0525 02:32:36.754983 19044 solver.cpp:253]     Train net output #0: loss = 1.02637 (* 1 = 1.02637 loss)
I0525 02:32:36.754998 19044 sgd_solver.cpp:106] Iteration 80036, lr = 0.0045
I0525 02:32:45.403396 19044 solver.cpp:237] Iteration 80223, loss = 1.12773
I0525 02:32:45.403585 19044 solver.cpp:253]     Train net output #0: loss = 1.12773 (* 1 = 1.12773 loss)
I0525 02:32:45.403599 19044 sgd_solver.cpp:106] Iteration 80223, lr = 0.0045
I0525 02:32:54.053499 19044 solver.cpp:237] Iteration 80410, loss = 1.09326
I0525 02:32:54.053539 19044 solver.cpp:253]     Train net output #0: loss = 1.09326 (* 1 = 1.09326 loss)
I0525 02:32:54.053556 19044 sgd_solver.cpp:106] Iteration 80410, lr = 0.0045
I0525 02:33:02.698627 19044 solver.cpp:237] Iteration 80597, loss = 1.17428
I0525 02:33:02.698662 19044 solver.cpp:253]     Train net output #0: loss = 1.17428 (* 1 = 1.17428 loss)
I0525 02:33:02.698676 19044 sgd_solver.cpp:106] Iteration 80597, lr = 0.0045
I0525 02:33:03.948021 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_80625.caffemodel
I0525 02:33:04.017266 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_80625.solverstate
I0525 02:33:11.413468 19044 solver.cpp:237] Iteration 80784, loss = 1.40489
I0525 02:33:11.413511 19044 solver.cpp:253]     Train net output #0: loss = 1.40489 (* 1 = 1.40489 loss)
I0525 02:33:11.413530 19044 sgd_solver.cpp:106] Iteration 80784, lr = 0.0045
I0525 02:33:20.062739 19044 solver.cpp:237] Iteration 80971, loss = 1.20702
I0525 02:33:20.062930 19044 solver.cpp:253]     Train net output #0: loss = 1.20702 (* 1 = 1.20702 loss)
I0525 02:33:20.062944 19044 sgd_solver.cpp:106] Iteration 80971, lr = 0.0045
I0525 02:33:28.707723 19044 solver.cpp:237] Iteration 81158, loss = 0.991742
I0525 02:33:28.707754 19044 solver.cpp:253]     Train net output #0: loss = 0.991742 (* 1 = 0.991742 loss)
I0525 02:33:28.707773 19044 sgd_solver.cpp:106] Iteration 81158, lr = 0.0045
I0525 02:33:58.190428 19044 solver.cpp:237] Iteration 81345, loss = 1.07192
I0525 02:33:58.190628 19044 solver.cpp:253]     Train net output #0: loss = 1.07192 (* 1 = 1.07192 loss)
I0525 02:33:58.190642 19044 sgd_solver.cpp:106] Iteration 81345, lr = 0.0045
I0525 02:34:06.842517 19044 solver.cpp:237] Iteration 81532, loss = 1.13552
I0525 02:34:06.842552 19044 solver.cpp:253]     Train net output #0: loss = 1.13552 (* 1 = 1.13552 loss)
I0525 02:34:06.842567 19044 sgd_solver.cpp:106] Iteration 81532, lr = 0.0045
I0525 02:34:15.493798 19044 solver.cpp:237] Iteration 81719, loss = 1.10908
I0525 02:34:15.493837 19044 solver.cpp:253]     Train net output #0: loss = 1.10908 (* 1 = 1.10908 loss)
I0525 02:34:15.493856 19044 sgd_solver.cpp:106] Iteration 81719, lr = 0.0045
I0525 02:34:24.143013 19044 solver.cpp:237] Iteration 81906, loss = 1.00756
I0525 02:34:24.143048 19044 solver.cpp:253]     Train net output #0: loss = 1.00756 (* 1 = 1.00756 loss)
I0525 02:34:24.143061 19044 sgd_solver.cpp:106] Iteration 81906, lr = 0.0045
I0525 02:34:32.792886 19044 solver.cpp:237] Iteration 82093, loss = 1.14999
I0525 02:34:32.793061 19044 solver.cpp:253]     Train net output #0: loss = 1.14999 (* 1 = 1.14999 loss)
I0525 02:34:32.793073 19044 sgd_solver.cpp:106] Iteration 82093, lr = 0.0045
I0525 02:34:41.445219 19044 solver.cpp:237] Iteration 82280, loss = 1.17278
I0525 02:34:41.445262 19044 solver.cpp:253]     Train net output #0: loss = 1.17278 (* 1 = 1.17278 loss)
I0525 02:34:41.445277 19044 sgd_solver.cpp:106] Iteration 82280, lr = 0.0045
I0525 02:34:50.094607 19044 solver.cpp:237] Iteration 82467, loss = 1.31628
I0525 02:34:50.094643 19044 solver.cpp:253]     Train net output #0: loss = 1.31628 (* 1 = 1.31628 loss)
I0525 02:34:50.094656 19044 sgd_solver.cpp:106] Iteration 82467, lr = 0.0045
I0525 02:34:51.575997 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_82500.caffemodel
I0525 02:34:51.647171 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_82500.solverstate
I0525 02:34:51.674828 19044 solver.cpp:341] Iteration 82500, Testing net (#0)
I0525 02:35:59.902546 19044 solver.cpp:409]     Test net output #0: accuracy = 0.895507
I0525 02:35:59.902750 19044 solver.cpp:409]     Test net output #1: loss = 0.344415 (* 1 = 0.344415 loss)
I0525 02:36:27.895463 19044 solver.cpp:237] Iteration 82654, loss = 1.06292
I0525 02:36:27.895512 19044 solver.cpp:253]     Train net output #0: loss = 1.06292 (* 1 = 1.06292 loss)
I0525 02:36:27.895527 19044 sgd_solver.cpp:106] Iteration 82654, lr = 0.0045
I0525 02:36:36.558877 19044 solver.cpp:237] Iteration 82841, loss = 1.0453
I0525 02:36:36.559062 19044 solver.cpp:253]     Train net output #0: loss = 1.0453 (* 1 = 1.0453 loss)
I0525 02:36:36.559075 19044 sgd_solver.cpp:106] Iteration 82841, lr = 0.0045
I0525 02:36:45.222398 19044 solver.cpp:237] Iteration 83028, loss = 1.17475
I0525 02:36:45.222434 19044 solver.cpp:253]     Train net output #0: loss = 1.17475 (* 1 = 1.17475 loss)
I0525 02:36:45.222446 19044 sgd_solver.cpp:106] Iteration 83028, lr = 0.0045
I0525 02:36:53.885932 19044 solver.cpp:237] Iteration 83215, loss = 1.32535
I0525 02:36:53.885967 19044 solver.cpp:253]     Train net output #0: loss = 1.32535 (* 1 = 1.32535 loss)
I0525 02:36:53.885982 19044 sgd_solver.cpp:106] Iteration 83215, lr = 0.0045
I0525 02:37:02.548023 19044 solver.cpp:237] Iteration 83402, loss = 1.17845
I0525 02:37:02.548058 19044 solver.cpp:253]     Train net output #0: loss = 1.17845 (* 1 = 1.17845 loss)
I0525 02:37:02.548071 19044 sgd_solver.cpp:106] Iteration 83402, lr = 0.0045
I0525 02:37:11.208418 19044 solver.cpp:237] Iteration 83589, loss = 1.04371
I0525 02:37:11.208611 19044 solver.cpp:253]     Train net output #0: loss = 1.04371 (* 1 = 1.04371 loss)
I0525 02:37:11.208626 19044 sgd_solver.cpp:106] Iteration 83589, lr = 0.0045
I0525 02:37:40.704854 19044 solver.cpp:237] Iteration 83776, loss = 1.05105
I0525 02:37:40.704905 19044 solver.cpp:253]     Train net output #0: loss = 1.05105 (* 1 = 1.05105 loss)
I0525 02:37:40.704919 19044 sgd_solver.cpp:106] Iteration 83776, lr = 0.0045
I0525 02:37:49.365694 19044 solver.cpp:237] Iteration 83963, loss = 1.12783
I0525 02:37:49.365872 19044 solver.cpp:253]     Train net output #0: loss = 1.12783 (* 1 = 1.12783 loss)
I0525 02:37:49.365888 19044 sgd_solver.cpp:106] Iteration 83963, lr = 0.0045
I0525 02:37:58.033381 19044 solver.cpp:237] Iteration 84150, loss = 1.06356
I0525 02:37:58.033419 19044 solver.cpp:253]     Train net output #0: loss = 1.06356 (* 1 = 1.06356 loss)
I0525 02:37:58.033440 19044 sgd_solver.cpp:106] Iteration 84150, lr = 0.0045
I0525 02:38:06.697083 19044 solver.cpp:237] Iteration 84337, loss = 0.962609
I0525 02:38:06.697121 19044 solver.cpp:253]     Train net output #0: loss = 0.962609 (* 1 = 0.962609 loss)
I0525 02:38:06.697135 19044 sgd_solver.cpp:106] Iteration 84337, lr = 0.0045
I0525 02:38:08.412001 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_84375.caffemodel
I0525 02:38:08.483726 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_84375.solverstate
I0525 02:38:15.431890 19044 solver.cpp:237] Iteration 84524, loss = 1.35507
I0525 02:38:15.431941 19044 solver.cpp:253]     Train net output #0: loss = 1.35507 (* 1 = 1.35507 loss)
I0525 02:38:15.431956 19044 sgd_solver.cpp:106] Iteration 84524, lr = 0.0045
I0525 02:38:24.093055 19044 solver.cpp:237] Iteration 84711, loss = 1.1304
I0525 02:38:24.093246 19044 solver.cpp:253]     Train net output #0: loss = 1.1304 (* 1 = 1.1304 loss)
I0525 02:38:24.093261 19044 sgd_solver.cpp:106] Iteration 84711, lr = 0.0045
I0525 02:38:32.756166 19044 solver.cpp:237] Iteration 84898, loss = 0.913585
I0525 02:38:32.756198 19044 solver.cpp:253]     Train net output #0: loss = 0.913585 (* 1 = 0.913585 loss)
I0525 02:38:32.756217 19044 sgd_solver.cpp:106] Iteration 84898, lr = 0.0045
I0525 02:39:02.319262 19044 solver.cpp:237] Iteration 85085, loss = 1.47093
I0525 02:39:02.319473 19044 solver.cpp:253]     Train net output #0: loss = 1.47093 (* 1 = 1.47093 loss)
I0525 02:39:02.319488 19044 sgd_solver.cpp:106] Iteration 85085, lr = 0.0045
I0525 02:39:10.980880 19044 solver.cpp:237] Iteration 85272, loss = 1.57144
I0525 02:39:10.980921 19044 solver.cpp:253]     Train net output #0: loss = 1.57144 (* 1 = 1.57144 loss)
I0525 02:39:10.980938 19044 sgd_solver.cpp:106] Iteration 85272, lr = 0.0045
I0525 02:39:19.646746 19044 solver.cpp:237] Iteration 85459, loss = 1.06822
I0525 02:39:19.646782 19044 solver.cpp:253]     Train net output #0: loss = 1.06822 (* 1 = 1.06822 loss)
I0525 02:39:19.646796 19044 sgd_solver.cpp:106] Iteration 85459, lr = 0.0045
I0525 02:39:28.307616 19044 solver.cpp:237] Iteration 85646, loss = 0.967374
I0525 02:39:28.307652 19044 solver.cpp:253]     Train net output #0: loss = 0.967374 (* 1 = 0.967374 loss)
I0525 02:39:28.307667 19044 sgd_solver.cpp:106] Iteration 85646, lr = 0.0045
I0525 02:39:36.970257 19044 solver.cpp:237] Iteration 85833, loss = 1.2069
I0525 02:39:36.970441 19044 solver.cpp:253]     Train net output #0: loss = 1.2069 (* 1 = 1.2069 loss)
I0525 02:39:36.970455 19044 sgd_solver.cpp:106] Iteration 85833, lr = 0.0045
I0525 02:39:45.633926 19044 solver.cpp:237] Iteration 86020, loss = 1.23626
I0525 02:39:45.633960 19044 solver.cpp:253]     Train net output #0: loss = 1.23626 (* 1 = 1.23626 loss)
I0525 02:39:45.633976 19044 sgd_solver.cpp:106] Iteration 86020, lr = 0.0045
I0525 02:39:54.301347 19044 solver.cpp:237] Iteration 86207, loss = 1.20362
I0525 02:39:54.301383 19044 solver.cpp:253]     Train net output #0: loss = 1.20362 (* 1 = 1.20362 loss)
I0525 02:39:54.301396 19044 sgd_solver.cpp:106] Iteration 86207, lr = 0.0045
I0525 02:39:56.247565 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_86250.caffemodel
I0525 02:39:56.317051 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_86250.solverstate
I0525 02:39:56.343214 19044 solver.cpp:341] Iteration 86250, Testing net (#0)
I0525 02:40:43.429107 19044 solver.cpp:409]     Test net output #0: accuracy = 0.901034
I0525 02:40:43.429306 19044 solver.cpp:409]     Test net output #1: loss = 0.314833 (* 1 = 0.314833 loss)
I0525 02:41:10.967097 19044 solver.cpp:237] Iteration 86394, loss = 1.26584
I0525 02:41:10.967147 19044 solver.cpp:253]     Train net output #0: loss = 1.26584 (* 1 = 1.26584 loss)
I0525 02:41:10.967162 19044 sgd_solver.cpp:106] Iteration 86394, lr = 0.0045
I0525 02:41:19.623292 19044 solver.cpp:237] Iteration 86581, loss = 0.98411
I0525 02:41:19.623484 19044 solver.cpp:253]     Train net output #0: loss = 0.98411 (* 1 = 0.98411 loss)
I0525 02:41:19.623498 19044 sgd_solver.cpp:106] Iteration 86581, lr = 0.0045
I0525 02:41:28.279400 19044 solver.cpp:237] Iteration 86768, loss = 1.27508
I0525 02:41:28.279434 19044 solver.cpp:253]     Train net output #0: loss = 1.27508 (* 1 = 1.27508 loss)
I0525 02:41:28.279450 19044 sgd_solver.cpp:106] Iteration 86768, lr = 0.0045
I0525 02:41:36.941623 19044 solver.cpp:237] Iteration 86955, loss = 1.18958
I0525 02:41:36.941658 19044 solver.cpp:253]     Train net output #0: loss = 1.18958 (* 1 = 1.18958 loss)
I0525 02:41:36.941673 19044 sgd_solver.cpp:106] Iteration 86955, lr = 0.0045
I0525 02:41:45.597995 19044 solver.cpp:237] Iteration 87142, loss = 0.963051
I0525 02:41:45.598040 19044 solver.cpp:253]     Train net output #0: loss = 0.963051 (* 1 = 0.963051 loss)
I0525 02:41:45.598054 19044 sgd_solver.cpp:106] Iteration 87142, lr = 0.0045
I0525 02:41:54.254961 19044 solver.cpp:237] Iteration 87329, loss = 1.02871
I0525 02:41:54.255139 19044 solver.cpp:253]     Train net output #0: loss = 1.02871 (* 1 = 1.02871 loss)
I0525 02:41:54.255152 19044 sgd_solver.cpp:106] Iteration 87329, lr = 0.0045
I0525 02:42:23.744338 19044 solver.cpp:237] Iteration 87516, loss = 1.09097
I0525 02:42:23.744390 19044 solver.cpp:253]     Train net output #0: loss = 1.09097 (* 1 = 1.09097 loss)
I0525 02:42:23.744403 19044 sgd_solver.cpp:106] Iteration 87516, lr = 0.0045
I0525 02:42:32.400331 19044 solver.cpp:237] Iteration 87703, loss = 1.0634
I0525 02:42:32.400547 19044 solver.cpp:253]     Train net output #0: loss = 1.0634 (* 1 = 1.0634 loss)
I0525 02:42:32.400560 19044 sgd_solver.cpp:106] Iteration 87703, lr = 0.0045
I0525 02:42:41.058071 19044 solver.cpp:237] Iteration 87890, loss = 1.06546
I0525 02:42:41.058106 19044 solver.cpp:253]     Train net output #0: loss = 1.06546 (* 1 = 1.06546 loss)
I0525 02:42:41.058120 19044 sgd_solver.cpp:106] Iteration 87890, lr = 0.0045
I0525 02:42:49.715344 19044 solver.cpp:237] Iteration 88077, loss = 1.08471
I0525 02:42:49.715380 19044 solver.cpp:253]     Train net output #0: loss = 1.08471 (* 1 = 1.08471 loss)
I0525 02:42:49.715394 19044 sgd_solver.cpp:106] Iteration 88077, lr = 0.0045
I0525 02:42:51.891279 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_88125.caffemodel
I0525 02:42:51.960526 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_88125.solverstate
I0525 02:42:58.436192 19044 solver.cpp:237] Iteration 88264, loss = 1.1853
I0525 02:42:58.436236 19044 solver.cpp:253]     Train net output #0: loss = 1.1853 (* 1 = 1.1853 loss)
I0525 02:42:58.436256 19044 sgd_solver.cpp:106] Iteration 88264, lr = 0.0045
I0525 02:43:07.090229 19044 solver.cpp:237] Iteration 88451, loss = 1.26199
I0525 02:43:07.090416 19044 solver.cpp:253]     Train net output #0: loss = 1.26199 (* 1 = 1.26199 loss)
I0525 02:43:07.090430 19044 sgd_solver.cpp:106] Iteration 88451, lr = 0.0045
I0525 02:43:15.742151 19044 solver.cpp:237] Iteration 88638, loss = 1.13947
I0525 02:43:15.742185 19044 solver.cpp:253]     Train net output #0: loss = 1.13947 (* 1 = 1.13947 loss)
I0525 02:43:15.742199 19044 sgd_solver.cpp:106] Iteration 88638, lr = 0.0045
I0525 02:43:45.362131 19044 solver.cpp:237] Iteration 88825, loss = 1.20385
I0525 02:43:45.362334 19044 solver.cpp:253]     Train net output #0: loss = 1.20385 (* 1 = 1.20385 loss)
I0525 02:43:45.362347 19044 sgd_solver.cpp:106] Iteration 88825, lr = 0.0045
I0525 02:43:54.017611 19044 solver.cpp:237] Iteration 89012, loss = 1.02384
I0525 02:43:54.017647 19044 solver.cpp:253]     Train net output #0: loss = 1.02384 (* 1 = 1.02384 loss)
I0525 02:43:54.017662 19044 sgd_solver.cpp:106] Iteration 89012, lr = 0.0045
I0525 02:44:02.677068 19044 solver.cpp:237] Iteration 89199, loss = 1.07382
I0525 02:44:02.677104 19044 solver.cpp:253]     Train net output #0: loss = 1.07382 (* 1 = 1.07382 loss)
I0525 02:44:02.677117 19044 sgd_solver.cpp:106] Iteration 89199, lr = 0.0045
I0525 02:44:11.329205 19044 solver.cpp:237] Iteration 89386, loss = 1.16532
I0525 02:44:11.329252 19044 solver.cpp:253]     Train net output #0: loss = 1.16532 (* 1 = 1.16532 loss)
I0525 02:44:11.329267 19044 sgd_solver.cpp:106] Iteration 89386, lr = 0.0045
I0525 02:44:19.982853 19044 solver.cpp:237] Iteration 89573, loss = 1.25496
I0525 02:44:19.983031 19044 solver.cpp:253]     Train net output #0: loss = 1.25496 (* 1 = 1.25496 loss)
I0525 02:44:19.983045 19044 sgd_solver.cpp:106] Iteration 89573, lr = 0.0045
I0525 02:44:28.639335 19044 solver.cpp:237] Iteration 89760, loss = 1.08818
I0525 02:44:28.639370 19044 solver.cpp:253]     Train net output #0: loss = 1.08818 (* 1 = 1.08818 loss)
I0525 02:44:28.639385 19044 sgd_solver.cpp:106] Iteration 89760, lr = 0.0045
I0525 02:44:37.298447 19044 solver.cpp:237] Iteration 89947, loss = 1.17803
I0525 02:44:37.298491 19044 solver.cpp:253]     Train net output #0: loss = 1.17803 (* 1 = 1.17803 loss)
I0525 02:44:37.298506 19044 sgd_solver.cpp:106] Iteration 89947, lr = 0.0045
I0525 02:44:39.707023 19044 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_90000.caffemodel
I0525 02:44:39.776295 19044 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_80_lr_0.0045_2016-05-20T15.49.19.426326_iter_90000.solverstate
I0525 02:44:39.802629 19044 solver.cpp:341] Iteration 90000, Testing net (#0)
I0525 02:45:48.081393 19044 solver.cpp:409]     Test net output #0: accuracy = 0.89894
I0525 02:45:48.081591 19044 solver.cpp:409]     Test net output #1: loss = 0.315229 (* 1 = 0.315229 loss)
I0525 02:46:15.175550 19044 solver.cpp:237] Iteration 90134, loss = 1.24446
I0525 02:46:15.175600 19044 solver.cpp:253]     Train net output #0: loss = 1.24446 (* 1 = 1.24446 loss)
I0525 02:46:15.175616 19044 sgd_solver.cpp:106] Iteration 90134, lr = 0.0045
I0525 02:46:23.836206 19044 solver.cpp:237] Iteration 90321, loss = 0.913792
I0525 02:46:23.836387 19044 solver.cpp:253]     Train net output #0: loss = 0.913792 (* 1 = 0.913792 loss)
I0525 02:46:23.836401 19044 sgd_solver.cpp:106] Iteration 90321, lr = 0.0045
I0525 02:46:32.497203 19044 solver.cpp:237] Iteration 90508, loss = 1.25358
I0525 02:46:32.497238 19044 solver.cpp:253]     Train net output #0: loss = 1.25358 (* 1 = 1.25358 loss)
I0525 02:46:32.497253 19044 sgd_solver.cpp:106] Iteration 90508, lr = 0.0045
aprun: Apid 11262141: Caught signal Terminated, sending to application
*** Aborted at 1464158796 (unix time) try "date -d @1464158796" if you are using GNU date ***
aprun: Apid 11262141: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11262141: Caught signal Terminated, sending to application
*** SIGTERM (@0x4a61) received by PID 19044 (TID 0x2aaac746f900) from PID 19041; stack trace: ***
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
=>> PBS: job killed: walltime 7204 exceeded limit 7200
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11262141: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11262141: Caught signal Terminated, sending to application
