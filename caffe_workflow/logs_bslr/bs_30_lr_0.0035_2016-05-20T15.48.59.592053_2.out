2812971
I0527 03:13:34.618445  7584 caffe.cpp:184] Using GPUs 0
I0527 03:13:35.048216  7584 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.0035
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053.prototxt"
I0527 03:13:35.050473  7584 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053.prototxt
I0527 03:13:35.068436  7584 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0527 03:13:35.068500  7584 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0527 03:13:35.068878  7584 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 03:13:35.069090  7584 layer_factory.hpp:77] Creating layer data_hdf5
I0527 03:13:35.069120  7584 net.cpp:106] Creating Layer data_hdf5
I0527 03:13:35.069144  7584 net.cpp:411] data_hdf5 -> data
I0527 03:13:35.069178  7584 net.cpp:411] data_hdf5 -> label
I0527 03:13:35.069221  7584 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0527 03:13:35.070580  7584 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0527 03:13:35.072978  7584 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0527 03:13:56.654943  7584 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0527 03:13:56.660215  7584 net.cpp:150] Setting up data_hdf5
I0527 03:13:56.660257  7584 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0527 03:13:56.660274  7584 net.cpp:157] Top shape: 30 (30)
I0527 03:13:56.660287  7584 net.cpp:165] Memory required for data: 762120
I0527 03:13:56.660306  7584 layer_factory.hpp:77] Creating layer conv1
I0527 03:13:56.660351  7584 net.cpp:106] Creating Layer conv1
I0527 03:13:56.660365  7584 net.cpp:454] conv1 <- data
I0527 03:13:56.660390  7584 net.cpp:411] conv1 -> conv1
I0527 03:13:57.025745  7584 net.cpp:150] Setting up conv1
I0527 03:13:57.025799  7584 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 03:13:57.025815  7584 net.cpp:165] Memory required for data: 9056520
I0527 03:13:57.025846  7584 layer_factory.hpp:77] Creating layer relu1
I0527 03:13:57.025876  7584 net.cpp:106] Creating Layer relu1
I0527 03:13:57.025908  7584 net.cpp:454] relu1 <- conv1
I0527 03:13:57.025926  7584 net.cpp:397] relu1 -> conv1 (in-place)
I0527 03:13:57.026465  7584 net.cpp:150] Setting up relu1
I0527 03:13:57.026490  7584 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 03:13:57.026504  7584 net.cpp:165] Memory required for data: 17350920
I0527 03:13:57.026520  7584 layer_factory.hpp:77] Creating layer pool1
I0527 03:13:57.026548  7584 net.cpp:106] Creating Layer pool1
I0527 03:13:57.026562  7584 net.cpp:454] pool1 <- conv1
I0527 03:13:57.026578  7584 net.cpp:411] pool1 -> pool1
I0527 03:13:57.026672  7584 net.cpp:150] Setting up pool1
I0527 03:13:57.026690  7584 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0527 03:13:57.026711  7584 net.cpp:165] Memory required for data: 21498120
I0527 03:13:57.026726  7584 layer_factory.hpp:77] Creating layer conv2
I0527 03:13:57.026751  7584 net.cpp:106] Creating Layer conv2
I0527 03:13:57.026764  7584 net.cpp:454] conv2 <- pool1
I0527 03:13:57.026779  7584 net.cpp:411] conv2 -> conv2
I0527 03:13:57.029455  7584 net.cpp:150] Setting up conv2
I0527 03:13:57.029490  7584 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 03:13:57.029505  7584 net.cpp:165] Memory required for data: 27459720
I0527 03:13:57.029532  7584 layer_factory.hpp:77] Creating layer relu2
I0527 03:13:57.029561  7584 net.cpp:106] Creating Layer relu2
I0527 03:13:57.029574  7584 net.cpp:454] relu2 <- conv2
I0527 03:13:57.029590  7584 net.cpp:397] relu2 -> conv2 (in-place)
I0527 03:13:57.029947  7584 net.cpp:150] Setting up relu2
I0527 03:13:57.029966  7584 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 03:13:57.029979  7584 net.cpp:165] Memory required for data: 33421320
I0527 03:13:57.029995  7584 layer_factory.hpp:77] Creating layer pool2
I0527 03:13:57.030019  7584 net.cpp:106] Creating Layer pool2
I0527 03:13:57.030031  7584 net.cpp:454] pool2 <- conv2
I0527 03:13:57.030047  7584 net.cpp:411] pool2 -> pool2
I0527 03:13:57.030144  7584 net.cpp:150] Setting up pool2
I0527 03:13:57.030161  7584 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0527 03:13:57.030182  7584 net.cpp:165] Memory required for data: 36402120
I0527 03:13:57.030197  7584 layer_factory.hpp:77] Creating layer conv3
I0527 03:13:57.030217  7584 net.cpp:106] Creating Layer conv3
I0527 03:13:57.030238  7584 net.cpp:454] conv3 <- pool2
I0527 03:13:57.030257  7584 net.cpp:411] conv3 -> conv3
I0527 03:13:57.032240  7584 net.cpp:150] Setting up conv3
I0527 03:13:57.032266  7584 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 03:13:57.032287  7584 net.cpp:165] Memory required for data: 39654600
I0527 03:13:57.032310  7584 layer_factory.hpp:77] Creating layer relu3
I0527 03:13:57.032342  7584 net.cpp:106] Creating Layer relu3
I0527 03:13:57.032356  7584 net.cpp:454] relu3 <- conv3
I0527 03:13:57.032371  7584 net.cpp:397] relu3 -> conv3 (in-place)
I0527 03:13:57.032860  7584 net.cpp:150] Setting up relu3
I0527 03:13:57.032884  7584 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 03:13:57.032897  7584 net.cpp:165] Memory required for data: 42907080
I0527 03:13:57.032913  7584 layer_factory.hpp:77] Creating layer pool3
I0527 03:13:57.032938  7584 net.cpp:106] Creating Layer pool3
I0527 03:13:57.032951  7584 net.cpp:454] pool3 <- conv3
I0527 03:13:57.032968  7584 net.cpp:411] pool3 -> pool3
I0527 03:13:57.033048  7584 net.cpp:150] Setting up pool3
I0527 03:13:57.033067  7584 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0527 03:13:57.033080  7584 net.cpp:165] Memory required for data: 44533320
I0527 03:13:57.033095  7584 layer_factory.hpp:77] Creating layer conv4
I0527 03:13:57.033123  7584 net.cpp:106] Creating Layer conv4
I0527 03:13:57.033135  7584 net.cpp:454] conv4 <- pool3
I0527 03:13:57.033151  7584 net.cpp:411] conv4 -> conv4
I0527 03:13:57.035887  7584 net.cpp:150] Setting up conv4
I0527 03:13:57.035918  7584 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 03:13:57.035933  7584 net.cpp:165] Memory required for data: 45621960
I0527 03:13:57.035953  7584 layer_factory.hpp:77] Creating layer relu4
I0527 03:13:57.035984  7584 net.cpp:106] Creating Layer relu4
I0527 03:13:57.036000  7584 net.cpp:454] relu4 <- conv4
I0527 03:13:57.036015  7584 net.cpp:397] relu4 -> conv4 (in-place)
I0527 03:13:57.036504  7584 net.cpp:150] Setting up relu4
I0527 03:13:57.036526  7584 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 03:13:57.036540  7584 net.cpp:165] Memory required for data: 46710600
I0527 03:13:57.036556  7584 layer_factory.hpp:77] Creating layer pool4
I0527 03:13:57.036579  7584 net.cpp:106] Creating Layer pool4
I0527 03:13:57.036592  7584 net.cpp:454] pool4 <- conv4
I0527 03:13:57.036608  7584 net.cpp:411] pool4 -> pool4
I0527 03:13:57.036690  7584 net.cpp:150] Setting up pool4
I0527 03:13:57.036713  7584 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0527 03:13:57.036727  7584 net.cpp:165] Memory required for data: 47254920
I0527 03:13:57.036742  7584 layer_factory.hpp:77] Creating layer ip1
I0527 03:13:57.036770  7584 net.cpp:106] Creating Layer ip1
I0527 03:13:57.036784  7584 net.cpp:454] ip1 <- pool4
I0527 03:13:57.036800  7584 net.cpp:411] ip1 -> ip1
I0527 03:13:57.052206  7584 net.cpp:150] Setting up ip1
I0527 03:13:57.052239  7584 net.cpp:157] Top shape: 30 196 (5880)
I0527 03:13:57.052261  7584 net.cpp:165] Memory required for data: 47278440
I0527 03:13:57.052287  7584 layer_factory.hpp:77] Creating layer relu5
I0527 03:13:57.052309  7584 net.cpp:106] Creating Layer relu5
I0527 03:13:57.052333  7584 net.cpp:454] relu5 <- ip1
I0527 03:13:57.052351  7584 net.cpp:397] relu5 -> ip1 (in-place)
I0527 03:13:57.052707  7584 net.cpp:150] Setting up relu5
I0527 03:13:57.052727  7584 net.cpp:157] Top shape: 30 196 (5880)
I0527 03:13:57.052741  7584 net.cpp:165] Memory required for data: 47301960
I0527 03:13:57.052757  7584 layer_factory.hpp:77] Creating layer drop1
I0527 03:13:57.052786  7584 net.cpp:106] Creating Layer drop1
I0527 03:13:57.052800  7584 net.cpp:454] drop1 <- ip1
I0527 03:13:57.052816  7584 net.cpp:397] drop1 -> ip1 (in-place)
I0527 03:13:57.052888  7584 net.cpp:150] Setting up drop1
I0527 03:13:57.052914  7584 net.cpp:157] Top shape: 30 196 (5880)
I0527 03:13:57.052927  7584 net.cpp:165] Memory required for data: 47325480
I0527 03:13:57.052939  7584 layer_factory.hpp:77] Creating layer ip2
I0527 03:13:57.052969  7584 net.cpp:106] Creating Layer ip2
I0527 03:13:57.052983  7584 net.cpp:454] ip2 <- ip1
I0527 03:13:57.052999  7584 net.cpp:411] ip2 -> ip2
I0527 03:13:57.053483  7584 net.cpp:150] Setting up ip2
I0527 03:13:57.053501  7584 net.cpp:157] Top shape: 30 98 (2940)
I0527 03:13:57.053514  7584 net.cpp:165] Memory required for data: 47337240
I0527 03:13:57.053535  7584 layer_factory.hpp:77] Creating layer relu6
I0527 03:13:57.053556  7584 net.cpp:106] Creating Layer relu6
I0527 03:13:57.053570  7584 net.cpp:454] relu6 <- ip2
I0527 03:13:57.053586  7584 net.cpp:397] relu6 -> ip2 (in-place)
I0527 03:13:57.054132  7584 net.cpp:150] Setting up relu6
I0527 03:13:57.054154  7584 net.cpp:157] Top shape: 30 98 (2940)
I0527 03:13:57.054168  7584 net.cpp:165] Memory required for data: 47349000
I0527 03:13:57.054184  7584 layer_factory.hpp:77] Creating layer drop2
I0527 03:13:57.054208  7584 net.cpp:106] Creating Layer drop2
I0527 03:13:57.054227  7584 net.cpp:454] drop2 <- ip2
I0527 03:13:57.054244  7584 net.cpp:397] drop2 -> ip2 (in-place)
I0527 03:13:57.054299  7584 net.cpp:150] Setting up drop2
I0527 03:13:57.054316  7584 net.cpp:157] Top shape: 30 98 (2940)
I0527 03:13:57.054337  7584 net.cpp:165] Memory required for data: 47360760
I0527 03:13:57.054349  7584 layer_factory.hpp:77] Creating layer ip3
I0527 03:13:57.054368  7584 net.cpp:106] Creating Layer ip3
I0527 03:13:57.054380  7584 net.cpp:454] ip3 <- ip2
I0527 03:13:57.054402  7584 net.cpp:411] ip3 -> ip3
I0527 03:13:57.054631  7584 net.cpp:150] Setting up ip3
I0527 03:13:57.054651  7584 net.cpp:157] Top shape: 30 11 (330)
I0527 03:13:57.054662  7584 net.cpp:165] Memory required for data: 47362080
I0527 03:13:57.054683  7584 layer_factory.hpp:77] Creating layer drop3
I0527 03:13:57.054704  7584 net.cpp:106] Creating Layer drop3
I0527 03:13:57.054718  7584 net.cpp:454] drop3 <- ip3
I0527 03:13:57.054733  7584 net.cpp:397] drop3 -> ip3 (in-place)
I0527 03:13:57.054780  7584 net.cpp:150] Setting up drop3
I0527 03:13:57.054801  7584 net.cpp:157] Top shape: 30 11 (330)
I0527 03:13:57.054814  7584 net.cpp:165] Memory required for data: 47363400
I0527 03:13:57.054829  7584 layer_factory.hpp:77] Creating layer loss
I0527 03:13:57.054852  7584 net.cpp:106] Creating Layer loss
I0527 03:13:57.054867  7584 net.cpp:454] loss <- ip3
I0527 03:13:57.054886  7584 net.cpp:454] loss <- label
I0527 03:13:57.054901  7584 net.cpp:411] loss -> loss
I0527 03:13:57.054921  7584 layer_factory.hpp:77] Creating layer loss
I0527 03:13:57.055588  7584 net.cpp:150] Setting up loss
I0527 03:13:57.055610  7584 net.cpp:157] Top shape: (1)
I0527 03:13:57.055627  7584 net.cpp:160]     with loss weight 1
I0527 03:13:57.055687  7584 net.cpp:165] Memory required for data: 47363404
I0527 03:13:57.055701  7584 net.cpp:226] loss needs backward computation.
I0527 03:13:57.055716  7584 net.cpp:226] drop3 needs backward computation.
I0527 03:13:57.055732  7584 net.cpp:226] ip3 needs backward computation.
I0527 03:13:57.055745  7584 net.cpp:226] drop2 needs backward computation.
I0527 03:13:57.055757  7584 net.cpp:226] relu6 needs backward computation.
I0527 03:13:57.055771  7584 net.cpp:226] ip2 needs backward computation.
I0527 03:13:57.055790  7584 net.cpp:226] drop1 needs backward computation.
I0527 03:13:57.055804  7584 net.cpp:226] relu5 needs backward computation.
I0527 03:13:57.055816  7584 net.cpp:226] ip1 needs backward computation.
I0527 03:13:57.055832  7584 net.cpp:226] pool4 needs backward computation.
I0527 03:13:57.055845  7584 net.cpp:226] relu4 needs backward computation.
I0527 03:13:57.055857  7584 net.cpp:226] conv4 needs backward computation.
I0527 03:13:57.055869  7584 net.cpp:226] pool3 needs backward computation.
I0527 03:13:57.055886  7584 net.cpp:226] relu3 needs backward computation.
I0527 03:13:57.055905  7584 net.cpp:226] conv3 needs backward computation.
I0527 03:13:57.055927  7584 net.cpp:226] pool2 needs backward computation.
I0527 03:13:57.055944  7584 net.cpp:226] relu2 needs backward computation.
I0527 03:13:57.055958  7584 net.cpp:226] conv2 needs backward computation.
I0527 03:13:57.055970  7584 net.cpp:226] pool1 needs backward computation.
I0527 03:13:57.055982  7584 net.cpp:226] relu1 needs backward computation.
I0527 03:13:57.055997  7584 net.cpp:226] conv1 needs backward computation.
I0527 03:13:57.056018  7584 net.cpp:228] data_hdf5 does not need backward computation.
I0527 03:13:57.056031  7584 net.cpp:270] This network produces output loss
I0527 03:13:57.056057  7584 net.cpp:283] Network initialization done.
I0527 03:13:57.057831  7584 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053.prototxt
I0527 03:13:57.057910  7584 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0527 03:13:57.058303  7584 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 03:13:57.058524  7584 layer_factory.hpp:77] Creating layer data_hdf5
I0527 03:13:57.058545  7584 net.cpp:106] Creating Layer data_hdf5
I0527 03:13:57.058562  7584 net.cpp:411] data_hdf5 -> data
I0527 03:13:57.058583  7584 net.cpp:411] data_hdf5 -> label
I0527 03:13:57.058603  7584 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0527 03:13:57.060034  7584 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0527 03:14:18.440114  7584 net.cpp:150] Setting up data_hdf5
I0527 03:14:18.440284  7584 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0527 03:14:18.440302  7584 net.cpp:157] Top shape: 30 (30)
I0527 03:14:18.440315  7584 net.cpp:165] Memory required for data: 762120
I0527 03:14:18.440330  7584 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0527 03:14:18.440364  7584 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0527 03:14:18.440397  7584 net.cpp:454] label_data_hdf5_1_split <- label
I0527 03:14:18.440414  7584 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0527 03:14:18.440438  7584 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0527 03:14:18.440523  7584 net.cpp:150] Setting up label_data_hdf5_1_split
I0527 03:14:18.440541  7584 net.cpp:157] Top shape: 30 (30)
I0527 03:14:18.440556  7584 net.cpp:157] Top shape: 30 (30)
I0527 03:14:18.440568  7584 net.cpp:165] Memory required for data: 762360
I0527 03:14:18.440579  7584 layer_factory.hpp:77] Creating layer conv1
I0527 03:14:18.440613  7584 net.cpp:106] Creating Layer conv1
I0527 03:14:18.440625  7584 net.cpp:454] conv1 <- data
I0527 03:14:18.440642  7584 net.cpp:411] conv1 -> conv1
I0527 03:14:18.442641  7584 net.cpp:150] Setting up conv1
I0527 03:14:18.442667  7584 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 03:14:18.442679  7584 net.cpp:165] Memory required for data: 9056760
I0527 03:14:18.442708  7584 layer_factory.hpp:77] Creating layer relu1
I0527 03:14:18.442734  7584 net.cpp:106] Creating Layer relu1
I0527 03:14:18.442747  7584 net.cpp:454] relu1 <- conv1
I0527 03:14:18.442764  7584 net.cpp:397] relu1 -> conv1 (in-place)
I0527 03:14:18.443292  7584 net.cpp:150] Setting up relu1
I0527 03:14:18.443315  7584 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 03:14:18.443328  7584 net.cpp:165] Memory required for data: 17351160
I0527 03:14:18.443344  7584 layer_factory.hpp:77] Creating layer pool1
I0527 03:14:18.443370  7584 net.cpp:106] Creating Layer pool1
I0527 03:14:18.443385  7584 net.cpp:454] pool1 <- conv1
I0527 03:14:18.443402  7584 net.cpp:411] pool1 -> pool1
I0527 03:14:18.443490  7584 net.cpp:150] Setting up pool1
I0527 03:14:18.443507  7584 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0527 03:14:18.443528  7584 net.cpp:165] Memory required for data: 21498360
I0527 03:14:18.443543  7584 layer_factory.hpp:77] Creating layer conv2
I0527 03:14:18.443563  7584 net.cpp:106] Creating Layer conv2
I0527 03:14:18.443584  7584 net.cpp:454] conv2 <- pool1
I0527 03:14:18.443601  7584 net.cpp:411] conv2 -> conv2
I0527 03:14:18.445544  7584 net.cpp:150] Setting up conv2
I0527 03:14:18.445569  7584 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 03:14:18.445588  7584 net.cpp:165] Memory required for data: 27459960
I0527 03:14:18.445611  7584 layer_factory.hpp:77] Creating layer relu2
I0527 03:14:18.445631  7584 net.cpp:106] Creating Layer relu2
I0527 03:14:18.445652  7584 net.cpp:454] relu2 <- conv2
I0527 03:14:18.445667  7584 net.cpp:397] relu2 -> conv2 (in-place)
I0527 03:14:18.446017  7584 net.cpp:150] Setting up relu2
I0527 03:14:18.446036  7584 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 03:14:18.446049  7584 net.cpp:165] Memory required for data: 33421560
I0527 03:14:18.446064  7584 layer_factory.hpp:77] Creating layer pool2
I0527 03:14:18.446087  7584 net.cpp:106] Creating Layer pool2
I0527 03:14:18.446100  7584 net.cpp:454] pool2 <- conv2
I0527 03:14:18.446115  7584 net.cpp:411] pool2 -> pool2
I0527 03:14:18.446204  7584 net.cpp:150] Setting up pool2
I0527 03:14:18.446238  7584 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0527 03:14:18.446252  7584 net.cpp:165] Memory required for data: 36402360
I0527 03:14:18.446267  7584 layer_factory.hpp:77] Creating layer conv3
I0527 03:14:18.446296  7584 net.cpp:106] Creating Layer conv3
I0527 03:14:18.446310  7584 net.cpp:454] conv3 <- pool2
I0527 03:14:18.446336  7584 net.cpp:411] conv3 -> conv3
I0527 03:14:18.448345  7584 net.cpp:150] Setting up conv3
I0527 03:14:18.448371  7584 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 03:14:18.448390  7584 net.cpp:165] Memory required for data: 39654840
I0527 03:14:18.448431  7584 layer_factory.hpp:77] Creating layer relu3
I0527 03:14:18.448456  7584 net.cpp:106] Creating Layer relu3
I0527 03:14:18.448469  7584 net.cpp:454] relu3 <- conv3
I0527 03:14:18.448485  7584 net.cpp:397] relu3 -> conv3 (in-place)
I0527 03:14:18.448984  7584 net.cpp:150] Setting up relu3
I0527 03:14:18.449007  7584 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 03:14:18.449021  7584 net.cpp:165] Memory required for data: 42907320
I0527 03:14:18.449038  7584 layer_factory.hpp:77] Creating layer pool3
I0527 03:14:18.449060  7584 net.cpp:106] Creating Layer pool3
I0527 03:14:18.449074  7584 net.cpp:454] pool3 <- conv3
I0527 03:14:18.449090  7584 net.cpp:411] pool3 -> pool3
I0527 03:14:18.449177  7584 net.cpp:150] Setting up pool3
I0527 03:14:18.449193  7584 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0527 03:14:18.449208  7584 net.cpp:165] Memory required for data: 44533560
I0527 03:14:18.449220  7584 layer_factory.hpp:77] Creating layer conv4
I0527 03:14:18.449247  7584 net.cpp:106] Creating Layer conv4
I0527 03:14:18.449260  7584 net.cpp:454] conv4 <- pool3
I0527 03:14:18.449277  7584 net.cpp:411] conv4 -> conv4
I0527 03:14:18.451373  7584 net.cpp:150] Setting up conv4
I0527 03:14:18.451398  7584 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 03:14:18.451417  7584 net.cpp:165] Memory required for data: 45622200
I0527 03:14:18.451436  7584 layer_factory.hpp:77] Creating layer relu4
I0527 03:14:18.451457  7584 net.cpp:106] Creating Layer relu4
I0527 03:14:18.451478  7584 net.cpp:454] relu4 <- conv4
I0527 03:14:18.451494  7584 net.cpp:397] relu4 -> conv4 (in-place)
I0527 03:14:18.451983  7584 net.cpp:150] Setting up relu4
I0527 03:14:18.452006  7584 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 03:14:18.452019  7584 net.cpp:165] Memory required for data: 46710840
I0527 03:14:18.452031  7584 layer_factory.hpp:77] Creating layer pool4
I0527 03:14:18.452059  7584 net.cpp:106] Creating Layer pool4
I0527 03:14:18.452074  7584 net.cpp:454] pool4 <- conv4
I0527 03:14:18.452090  7584 net.cpp:411] pool4 -> pool4
I0527 03:14:18.452177  7584 net.cpp:150] Setting up pool4
I0527 03:14:18.452194  7584 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0527 03:14:18.452209  7584 net.cpp:165] Memory required for data: 47255160
I0527 03:14:18.452220  7584 layer_factory.hpp:77] Creating layer ip1
I0527 03:14:18.452244  7584 net.cpp:106] Creating Layer ip1
I0527 03:14:18.452257  7584 net.cpp:454] ip1 <- pool4
I0527 03:14:18.452280  7584 net.cpp:411] ip1 -> ip1
I0527 03:14:18.467670  7584 net.cpp:150] Setting up ip1
I0527 03:14:18.467703  7584 net.cpp:157] Top shape: 30 196 (5880)
I0527 03:14:18.467725  7584 net.cpp:165] Memory required for data: 47278680
I0527 03:14:18.467751  7584 layer_factory.hpp:77] Creating layer relu5
I0527 03:14:18.467772  7584 net.cpp:106] Creating Layer relu5
I0527 03:14:18.467797  7584 net.cpp:454] relu5 <- ip1
I0527 03:14:18.467814  7584 net.cpp:397] relu5 -> ip1 (in-place)
I0527 03:14:18.468178  7584 net.cpp:150] Setting up relu5
I0527 03:14:18.468199  7584 net.cpp:157] Top shape: 30 196 (5880)
I0527 03:14:18.468211  7584 net.cpp:165] Memory required for data: 47302200
I0527 03:14:18.468222  7584 layer_factory.hpp:77] Creating layer drop1
I0527 03:14:18.468255  7584 net.cpp:106] Creating Layer drop1
I0527 03:14:18.468269  7584 net.cpp:454] drop1 <- ip1
I0527 03:14:18.468286  7584 net.cpp:397] drop1 -> ip1 (in-place)
I0527 03:14:18.468348  7584 net.cpp:150] Setting up drop1
I0527 03:14:18.468364  7584 net.cpp:157] Top shape: 30 196 (5880)
I0527 03:14:18.468384  7584 net.cpp:165] Memory required for data: 47325720
I0527 03:14:18.468397  7584 layer_factory.hpp:77] Creating layer ip2
I0527 03:14:18.468416  7584 net.cpp:106] Creating Layer ip2
I0527 03:14:18.468428  7584 net.cpp:454] ip2 <- ip1
I0527 03:14:18.468452  7584 net.cpp:411] ip2 -> ip2
I0527 03:14:18.468948  7584 net.cpp:150] Setting up ip2
I0527 03:14:18.468967  7584 net.cpp:157] Top shape: 30 98 (2940)
I0527 03:14:18.468979  7584 net.cpp:165] Memory required for data: 47337480
I0527 03:14:18.469000  7584 layer_factory.hpp:77] Creating layer relu6
I0527 03:14:18.469058  7584 net.cpp:106] Creating Layer relu6
I0527 03:14:18.469074  7584 net.cpp:454] relu6 <- ip2
I0527 03:14:18.469091  7584 net.cpp:397] relu6 -> ip2 (in-place)
I0527 03:14:18.469657  7584 net.cpp:150] Setting up relu6
I0527 03:14:18.469681  7584 net.cpp:157] Top shape: 30 98 (2940)
I0527 03:14:18.469698  7584 net.cpp:165] Memory required for data: 47349240
I0527 03:14:18.469712  7584 layer_factory.hpp:77] Creating layer drop2
I0527 03:14:18.469727  7584 net.cpp:106] Creating Layer drop2
I0527 03:14:18.469743  7584 net.cpp:454] drop2 <- ip2
I0527 03:14:18.469768  7584 net.cpp:397] drop2 -> ip2 (in-place)
I0527 03:14:18.469815  7584 net.cpp:150] Setting up drop2
I0527 03:14:18.469835  7584 net.cpp:157] Top shape: 30 98 (2940)
I0527 03:14:18.469852  7584 net.cpp:165] Memory required for data: 47361000
I0527 03:14:18.469866  7584 layer_factory.hpp:77] Creating layer ip3
I0527 03:14:18.469882  7584 net.cpp:106] Creating Layer ip3
I0527 03:14:18.469895  7584 net.cpp:454] ip3 <- ip2
I0527 03:14:18.469914  7584 net.cpp:411] ip3 -> ip3
I0527 03:14:18.470161  7584 net.cpp:150] Setting up ip3
I0527 03:14:18.470180  7584 net.cpp:157] Top shape: 30 11 (330)
I0527 03:14:18.470193  7584 net.cpp:165] Memory required for data: 47362320
I0527 03:14:18.470214  7584 layer_factory.hpp:77] Creating layer drop3
I0527 03:14:18.470249  7584 net.cpp:106] Creating Layer drop3
I0527 03:14:18.470263  7584 net.cpp:454] drop3 <- ip3
I0527 03:14:18.470278  7584 net.cpp:397] drop3 -> ip3 (in-place)
I0527 03:14:18.470335  7584 net.cpp:150] Setting up drop3
I0527 03:14:18.470350  7584 net.cpp:157] Top shape: 30 11 (330)
I0527 03:14:18.470363  7584 net.cpp:165] Memory required for data: 47363640
I0527 03:14:18.470374  7584 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0527 03:14:18.470393  7584 net.cpp:106] Creating Layer ip3_drop3_0_split
I0527 03:14:18.470413  7584 net.cpp:454] ip3_drop3_0_split <- ip3
I0527 03:14:18.470430  7584 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0527 03:14:18.470458  7584 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0527 03:14:18.470543  7584 net.cpp:150] Setting up ip3_drop3_0_split
I0527 03:14:18.470563  7584 net.cpp:157] Top shape: 30 11 (330)
I0527 03:14:18.470578  7584 net.cpp:157] Top shape: 30 11 (330)
I0527 03:14:18.470590  7584 net.cpp:165] Memory required for data: 47366280
I0527 03:14:18.470605  7584 layer_factory.hpp:77] Creating layer accuracy
I0527 03:14:18.470635  7584 net.cpp:106] Creating Layer accuracy
I0527 03:14:18.470649  7584 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0527 03:14:18.470662  7584 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0527 03:14:18.470679  7584 net.cpp:411] accuracy -> accuracy
I0527 03:14:18.470715  7584 net.cpp:150] Setting up accuracy
I0527 03:14:18.470731  7584 net.cpp:157] Top shape: (1)
I0527 03:14:18.470746  7584 net.cpp:165] Memory required for data: 47366284
I0527 03:14:18.470758  7584 layer_factory.hpp:77] Creating layer loss
I0527 03:14:18.470774  7584 net.cpp:106] Creating Layer loss
I0527 03:14:18.470789  7584 net.cpp:454] loss <- ip3_drop3_0_split_1
I0527 03:14:18.470808  7584 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0527 03:14:18.470825  7584 net.cpp:411] loss -> loss
I0527 03:14:18.470845  7584 layer_factory.hpp:77] Creating layer loss
I0527 03:14:18.471362  7584 net.cpp:150] Setting up loss
I0527 03:14:18.471382  7584 net.cpp:157] Top shape: (1)
I0527 03:14:18.471395  7584 net.cpp:160]     with loss weight 1
I0527 03:14:18.471422  7584 net.cpp:165] Memory required for data: 47366288
I0527 03:14:18.471442  7584 net.cpp:226] loss needs backward computation.
I0527 03:14:18.471458  7584 net.cpp:228] accuracy does not need backward computation.
I0527 03:14:18.471474  7584 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0527 03:14:18.471488  7584 net.cpp:226] drop3 needs backward computation.
I0527 03:14:18.471500  7584 net.cpp:226] ip3 needs backward computation.
I0527 03:14:18.471516  7584 net.cpp:226] drop2 needs backward computation.
I0527 03:14:18.471534  7584 net.cpp:226] relu6 needs backward computation.
I0527 03:14:18.471556  7584 net.cpp:226] ip2 needs backward computation.
I0527 03:14:18.471572  7584 net.cpp:226] drop1 needs backward computation.
I0527 03:14:18.471585  7584 net.cpp:226] relu5 needs backward computation.
I0527 03:14:18.471597  7584 net.cpp:226] ip1 needs backward computation.
I0527 03:14:18.471609  7584 net.cpp:226] pool4 needs backward computation.
I0527 03:14:18.471626  7584 net.cpp:226] relu4 needs backward computation.
I0527 03:14:18.471645  7584 net.cpp:226] conv4 needs backward computation.
I0527 03:14:18.471659  7584 net.cpp:226] pool3 needs backward computation.
I0527 03:14:18.471673  7584 net.cpp:226] relu3 needs backward computation.
I0527 03:14:18.471685  7584 net.cpp:226] conv3 needs backward computation.
I0527 03:14:18.471698  7584 net.cpp:226] pool2 needs backward computation.
I0527 03:14:18.471710  7584 net.cpp:226] relu2 needs backward computation.
I0527 03:14:18.471725  7584 net.cpp:226] conv2 needs backward computation.
I0527 03:14:18.471745  7584 net.cpp:226] pool1 needs backward computation.
I0527 03:14:18.471757  7584 net.cpp:226] relu1 needs backward computation.
I0527 03:14:18.471771  7584 net.cpp:226] conv1 needs backward computation.
I0527 03:14:18.471784  7584 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0527 03:14:18.471798  7584 net.cpp:228] data_hdf5 does not need backward computation.
I0527 03:14:18.471813  7584 net.cpp:270] This network produces output accuracy
I0527 03:14:18.471825  7584 net.cpp:270] This network produces output loss
I0527 03:14:18.471856  7584 net.cpp:283] Network initialization done.
I0527 03:14:18.471992  7584 solver.cpp:60] Solver scaffolding done.
I0527 03:14:18.473150  7584 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_210000.solverstate
I0527 03:14:18.693851  7584 sgd_solver.cpp:318] SGDSolver: restoring history
I0527 03:14:18.699311  7584 caffe.cpp:212] Starting Optimization
I0527 03:14:18.699357  7584 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0527 03:14:18.699373  7584 solver.cpp:289] Learning Rate Policy: fixed
I0527 03:14:18.700773  7584 solver.cpp:341] Iteration 210000, Testing net (#0)
I0527 03:15:09.329999  7584 solver.cpp:409]     Test net output #0: accuracy = 0.898103
I0527 03:15:09.330157  7584 solver.cpp:409]     Test net output #1: loss = 0.320383 (* 1 = 0.320383 loss)
I0527 03:15:09.351030  7584 solver.cpp:237] Iteration 210000, loss = 1.10875
I0527 03:15:09.351069  7584 solver.cpp:253]     Train net output #0: loss = 1.10875 (* 1 = 1.10875 loss)
I0527 03:15:09.351090  7584 sgd_solver.cpp:106] Iteration 210000, lr = 0.0035
I0527 03:15:19.903671  7584 solver.cpp:237] Iteration 210500, loss = 1.16049
I0527 03:15:19.903709  7584 solver.cpp:253]     Train net output #0: loss = 1.16049 (* 1 = 1.16049 loss)
I0527 03:15:19.903726  7584 sgd_solver.cpp:106] Iteration 210500, lr = 0.0035
I0527 03:15:30.421175  7584 solver.cpp:237] Iteration 211000, loss = 1.2845
I0527 03:15:30.421227  7584 solver.cpp:253]     Train net output #0: loss = 1.2845 (* 1 = 1.2845 loss)
I0527 03:15:30.421246  7584 sgd_solver.cpp:106] Iteration 211000, lr = 0.0035
I0527 03:15:40.944782  7584 solver.cpp:237] Iteration 211500, loss = 1.08287
I0527 03:15:40.944933  7584 solver.cpp:253]     Train net output #0: loss = 1.08287 (* 1 = 1.08287 loss)
I0527 03:15:40.944950  7584 sgd_solver.cpp:106] Iteration 211500, lr = 0.0035
I0527 03:15:51.466399  7584 solver.cpp:237] Iteration 212000, loss = 1.19307
I0527 03:15:51.466456  7584 solver.cpp:253]     Train net output #0: loss = 1.19307 (* 1 = 1.19307 loss)
I0527 03:15:51.466475  7584 sgd_solver.cpp:106] Iteration 212000, lr = 0.0035
I0527 03:16:01.994488  7584 solver.cpp:237] Iteration 212500, loss = 0.81918
I0527 03:16:01.994525  7584 solver.cpp:253]     Train net output #0: loss = 0.81918 (* 1 = 0.81918 loss)
I0527 03:16:01.994544  7584 sgd_solver.cpp:106] Iteration 212500, lr = 0.0035
I0527 03:16:12.515461  7584 solver.cpp:237] Iteration 213000, loss = 1.69607
I0527 03:16:12.515617  7584 solver.cpp:253]     Train net output #0: loss = 1.69607 (* 1 = 1.69607 loss)
I0527 03:16:12.515635  7584 sgd_solver.cpp:106] Iteration 213000, lr = 0.0035
I0527 03:16:45.230120  7584 solver.cpp:237] Iteration 213500, loss = 1.13825
I0527 03:16:45.230295  7584 solver.cpp:253]     Train net output #0: loss = 1.13825 (* 1 = 1.13825 loss)
I0527 03:16:45.230314  7584 sgd_solver.cpp:106] Iteration 213500, lr = 0.0035
I0527 03:16:55.793087  7584 solver.cpp:237] Iteration 214000, loss = 1.18408
I0527 03:16:55.793123  7584 solver.cpp:253]     Train net output #0: loss = 1.18408 (* 1 = 1.18408 loss)
I0527 03:16:55.793143  7584 sgd_solver.cpp:106] Iteration 214000, lr = 0.0035
I0527 03:17:06.367254  7584 solver.cpp:237] Iteration 214500, loss = 1.94938
I0527 03:17:06.367311  7584 solver.cpp:253]     Train net output #0: loss = 1.94938 (* 1 = 1.94938 loss)
I0527 03:17:06.367327  7584 sgd_solver.cpp:106] Iteration 214500, lr = 0.0035
I0527 03:17:16.868935  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_215000.caffemodel
I0527 03:17:16.923630  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_215000.solverstate
I0527 03:17:16.957185  7584 solver.cpp:237] Iteration 215000, loss = 1.16285
I0527 03:17:16.957244  7584 solver.cpp:253]     Train net output #0: loss = 1.16285 (* 1 = 1.16285 loss)
I0527 03:17:16.957263  7584 sgd_solver.cpp:106] Iteration 215000, lr = 0.0035
I0527 03:17:27.470844  7584 solver.cpp:237] Iteration 215500, loss = 1.14671
I0527 03:17:27.470901  7584 solver.cpp:253]     Train net output #0: loss = 1.14671 (* 1 = 1.14671 loss)
I0527 03:17:27.470919  7584 sgd_solver.cpp:106] Iteration 215500, lr = 0.0035
I0527 03:17:38.044471  7584 solver.cpp:237] Iteration 216000, loss = 1.10852
I0527 03:17:38.044510  7584 solver.cpp:253]     Train net output #0: loss = 1.10852 (* 1 = 1.10852 loss)
I0527 03:17:38.044528  7584 sgd_solver.cpp:106] Iteration 216000, lr = 0.0035
I0527 03:17:48.618418  7584 solver.cpp:237] Iteration 216500, loss = 1.32143
I0527 03:17:48.618562  7584 solver.cpp:253]     Train net output #0: loss = 1.32143 (* 1 = 1.32143 loss)
I0527 03:17:48.618579  7584 sgd_solver.cpp:106] Iteration 216500, lr = 0.0035
I0527 03:18:21.301941  7584 solver.cpp:237] Iteration 217000, loss = 0.884337
I0527 03:18:21.302122  7584 solver.cpp:253]     Train net output #0: loss = 0.884337 (* 1 = 0.884337 loss)
I0527 03:18:21.302140  7584 sgd_solver.cpp:106] Iteration 217000, lr = 0.0035
I0527 03:18:31.786312  7584 solver.cpp:237] Iteration 217500, loss = 0.983101
I0527 03:18:31.786351  7584 solver.cpp:253]     Train net output #0: loss = 0.983101 (* 1 = 0.983101 loss)
I0527 03:18:31.786370  7584 sgd_solver.cpp:106] Iteration 217500, lr = 0.0035
I0527 03:18:42.293965  7584 solver.cpp:237] Iteration 218000, loss = 1.11267
I0527 03:18:42.294016  7584 solver.cpp:253]     Train net output #0: loss = 1.11267 (* 1 = 1.11267 loss)
I0527 03:18:42.294034  7584 sgd_solver.cpp:106] Iteration 218000, lr = 0.0035
I0527 03:18:52.834074  7584 solver.cpp:237] Iteration 218500, loss = 1.26129
I0527 03:18:52.834233  7584 solver.cpp:253]     Train net output #0: loss = 1.26129 (* 1 = 1.26129 loss)
I0527 03:18:52.834251  7584 sgd_solver.cpp:106] Iteration 218500, lr = 0.0035
I0527 03:19:03.390856  7584 solver.cpp:237] Iteration 219000, loss = 1.17338
I0527 03:19:03.390893  7584 solver.cpp:253]     Train net output #0: loss = 1.17338 (* 1 = 1.17338 loss)
I0527 03:19:03.390913  7584 sgd_solver.cpp:106] Iteration 219000, lr = 0.0035
I0527 03:19:13.944946  7584 solver.cpp:237] Iteration 219500, loss = 1.26713
I0527 03:19:13.944993  7584 solver.cpp:253]     Train net output #0: loss = 1.26713 (* 1 = 1.26713 loss)
I0527 03:19:13.945011  7584 sgd_solver.cpp:106] Iteration 219500, lr = 0.0035
I0527 03:19:24.483151  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_220000.caffemodel
I0527 03:19:24.537456  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_220000.solverstate
I0527 03:19:24.566160  7584 solver.cpp:341] Iteration 220000, Testing net (#0)
I0527 03:20:14.228611  7584 solver.cpp:409]     Test net output #0: accuracy = 0.904151
I0527 03:20:14.228777  7584 solver.cpp:409]     Test net output #1: loss = 0.301875 (* 1 = 0.301875 loss)
I0527 03:20:36.408403  7584 solver.cpp:237] Iteration 220000, loss = 0.890437
I0527 03:20:36.408469  7584 solver.cpp:253]     Train net output #0: loss = 0.890437 (* 1 = 0.890437 loss)
I0527 03:20:36.408498  7584 sgd_solver.cpp:106] Iteration 220000, lr = 0.0035
I0527 03:20:46.947615  7584 solver.cpp:237] Iteration 220500, loss = 1.11719
I0527 03:20:46.947779  7584 solver.cpp:253]     Train net output #0: loss = 1.11719 (* 1 = 1.11719 loss)
I0527 03:20:46.947796  7584 sgd_solver.cpp:106] Iteration 220500, lr = 0.0035
I0527 03:20:57.470271  7584 solver.cpp:237] Iteration 221000, loss = 1.13277
I0527 03:20:57.470309  7584 solver.cpp:253]     Train net output #0: loss = 1.13277 (* 1 = 1.13277 loss)
I0527 03:20:57.470327  7584 sgd_solver.cpp:106] Iteration 221000, lr = 0.0035
I0527 03:21:07.997839  7584 solver.cpp:237] Iteration 221500, loss = 1.50493
I0527 03:21:07.997875  7584 solver.cpp:253]     Train net output #0: loss = 1.50493 (* 1 = 1.50493 loss)
I0527 03:21:07.997895  7584 sgd_solver.cpp:106] Iteration 221500, lr = 0.0035
I0527 03:21:18.513203  7584 solver.cpp:237] Iteration 222000, loss = 1.27787
I0527 03:21:18.513363  7584 solver.cpp:253]     Train net output #0: loss = 1.27787 (* 1 = 1.27787 loss)
I0527 03:21:18.513381  7584 sgd_solver.cpp:106] Iteration 222000, lr = 0.0035
I0527 03:21:29.032125  7584 solver.cpp:237] Iteration 222500, loss = 1.13134
I0527 03:21:29.032161  7584 solver.cpp:253]     Train net output #0: loss = 1.13134 (* 1 = 1.13134 loss)
I0527 03:21:29.032181  7584 sgd_solver.cpp:106] Iteration 222500, lr = 0.0035
I0527 03:21:39.570886  7584 solver.cpp:237] Iteration 223000, loss = 0.938913
I0527 03:21:39.570945  7584 solver.cpp:253]     Train net output #0: loss = 0.938913 (* 1 = 0.938913 loss)
I0527 03:21:39.570962  7584 sgd_solver.cpp:106] Iteration 223000, lr = 0.0035
I0527 03:22:12.334082  7584 solver.cpp:237] Iteration 223500, loss = 1.1597
I0527 03:22:12.334259  7584 solver.cpp:253]     Train net output #0: loss = 1.1597 (* 1 = 1.1597 loss)
I0527 03:22:12.334277  7584 sgd_solver.cpp:106] Iteration 223500, lr = 0.0035
I0527 03:22:22.884753  7584 solver.cpp:237] Iteration 224000, loss = 0.94188
I0527 03:22:22.884794  7584 solver.cpp:253]     Train net output #0: loss = 0.94188 (* 1 = 0.94188 loss)
I0527 03:22:22.884811  7584 sgd_solver.cpp:106] Iteration 224000, lr = 0.0035
I0527 03:22:33.428045  7584 solver.cpp:237] Iteration 224500, loss = 1.37176
I0527 03:22:33.428102  7584 solver.cpp:253]     Train net output #0: loss = 1.37176 (* 1 = 1.37176 loss)
I0527 03:22:33.428119  7584 sgd_solver.cpp:106] Iteration 224500, lr = 0.0035
I0527 03:22:43.940198  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_225000.caffemodel
I0527 03:22:43.994997  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_225000.solverstate
I0527 03:22:44.029428  7584 solver.cpp:237] Iteration 225000, loss = 0.998969
I0527 03:22:44.029489  7584 solver.cpp:253]     Train net output #0: loss = 0.998968 (* 1 = 0.998968 loss)
I0527 03:22:44.029508  7584 sgd_solver.cpp:106] Iteration 225000, lr = 0.0035
I0527 03:22:54.646747  7584 solver.cpp:237] Iteration 225500, loss = 0.889963
I0527 03:22:54.646803  7584 solver.cpp:253]     Train net output #0: loss = 0.889962 (* 1 = 0.889962 loss)
I0527 03:22:54.646821  7584 sgd_solver.cpp:106] Iteration 225500, lr = 0.0035
I0527 03:23:05.256479  7584 solver.cpp:237] Iteration 226000, loss = 0.957451
I0527 03:23:05.256517  7584 solver.cpp:253]     Train net output #0: loss = 0.957451 (* 1 = 0.957451 loss)
I0527 03:23:05.256536  7584 sgd_solver.cpp:106] Iteration 226000, lr = 0.0035
I0527 03:23:15.869922  7584 solver.cpp:237] Iteration 226500, loss = 1.13377
I0527 03:23:15.870085  7584 solver.cpp:253]     Train net output #0: loss = 1.13377 (* 1 = 1.13377 loss)
I0527 03:23:15.870103  7584 sgd_solver.cpp:106] Iteration 226500, lr = 0.0035
I0527 03:23:48.668876  7584 solver.cpp:237] Iteration 227000, loss = 1.31067
I0527 03:23:48.669047  7584 solver.cpp:253]     Train net output #0: loss = 1.31067 (* 1 = 1.31067 loss)
I0527 03:23:48.669064  7584 sgd_solver.cpp:106] Iteration 227000, lr = 0.0035
I0527 03:23:59.290480  7584 solver.cpp:237] Iteration 227500, loss = 1.24048
I0527 03:23:59.290518  7584 solver.cpp:253]     Train net output #0: loss = 1.24048 (* 1 = 1.24048 loss)
I0527 03:23:59.290535  7584 sgd_solver.cpp:106] Iteration 227500, lr = 0.0035
I0527 03:24:09.871809  7584 solver.cpp:237] Iteration 228000, loss = 1.11215
I0527 03:24:09.871862  7584 solver.cpp:253]     Train net output #0: loss = 1.11215 (* 1 = 1.11215 loss)
I0527 03:24:09.871881  7584 sgd_solver.cpp:106] Iteration 228000, lr = 0.0035
I0527 03:24:20.375149  7584 solver.cpp:237] Iteration 228500, loss = 1.03749
I0527 03:24:20.375293  7584 solver.cpp:253]     Train net output #0: loss = 1.03749 (* 1 = 1.03749 loss)
I0527 03:24:20.375309  7584 sgd_solver.cpp:106] Iteration 228500, lr = 0.0035
I0527 03:24:30.878904  7584 solver.cpp:237] Iteration 229000, loss = 1.37713
I0527 03:24:30.878959  7584 solver.cpp:253]     Train net output #0: loss = 1.37713 (* 1 = 1.37713 loss)
I0527 03:24:30.878978  7584 sgd_solver.cpp:106] Iteration 229000, lr = 0.0035
I0527 03:24:41.379444  7584 solver.cpp:237] Iteration 229500, loss = 1.06917
I0527 03:24:41.379482  7584 solver.cpp:253]     Train net output #0: loss = 1.06917 (* 1 = 1.06917 loss)
I0527 03:24:41.379499  7584 sgd_solver.cpp:106] Iteration 229500, lr = 0.0035
I0527 03:24:51.855181  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_230000.caffemodel
I0527 03:24:51.910509  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_230000.solverstate
I0527 03:24:51.938470  7584 solver.cpp:341] Iteration 230000, Testing net (#0)
I0527 03:26:02.468854  7584 solver.cpp:409]     Test net output #0: accuracy = 0.899079
I0527 03:26:02.469025  7584 solver.cpp:409]     Test net output #1: loss = 0.349799 (* 1 = 0.349799 loss)
I0527 03:26:24.684537  7584 solver.cpp:237] Iteration 230000, loss = 1.07211
I0527 03:26:24.684603  7584 solver.cpp:253]     Train net output #0: loss = 1.07211 (* 1 = 1.07211 loss)
I0527 03:26:24.684624  7584 sgd_solver.cpp:106] Iteration 230000, lr = 0.0035
I0527 03:26:35.330688  7584 solver.cpp:237] Iteration 230500, loss = 1.02467
I0527 03:26:35.330837  7584 solver.cpp:253]     Train net output #0: loss = 1.02467 (* 1 = 1.02467 loss)
I0527 03:26:35.330852  7584 sgd_solver.cpp:106] Iteration 230500, lr = 0.0035
I0527 03:26:45.848440  7584 solver.cpp:237] Iteration 231000, loss = 1.48566
I0527 03:26:45.848494  7584 solver.cpp:253]     Train net output #0: loss = 1.48566 (* 1 = 1.48566 loss)
I0527 03:26:45.848511  7584 sgd_solver.cpp:106] Iteration 231000, lr = 0.0035
I0527 03:26:56.375759  7584 solver.cpp:237] Iteration 231500, loss = 1.08144
I0527 03:26:56.375795  7584 solver.cpp:253]     Train net output #0: loss = 1.08144 (* 1 = 1.08144 loss)
I0527 03:26:56.375814  7584 sgd_solver.cpp:106] Iteration 231500, lr = 0.0035
I0527 03:27:06.891919  7584 solver.cpp:237] Iteration 232000, loss = 1.25154
I0527 03:27:06.892093  7584 solver.cpp:253]     Train net output #0: loss = 1.25153 (* 1 = 1.25153 loss)
I0527 03:27:06.892112  7584 sgd_solver.cpp:106] Iteration 232000, lr = 0.0035
I0527 03:27:17.405838  7584 solver.cpp:237] Iteration 232500, loss = 0.940633
I0527 03:27:17.405879  7584 solver.cpp:253]     Train net output #0: loss = 0.940632 (* 1 = 0.940632 loss)
I0527 03:27:17.405895  7584 sgd_solver.cpp:106] Iteration 232500, lr = 0.0035
I0527 03:27:27.919188  7584 solver.cpp:237] Iteration 233000, loss = 1.12379
I0527 03:27:27.919245  7584 solver.cpp:253]     Train net output #0: loss = 1.12379 (* 1 = 1.12379 loss)
I0527 03:27:27.919263  7584 sgd_solver.cpp:106] Iteration 233000, lr = 0.0035
I0527 03:28:00.682588  7584 solver.cpp:237] Iteration 233500, loss = 0.960506
I0527 03:28:00.682763  7584 solver.cpp:253]     Train net output #0: loss = 0.960506 (* 1 = 0.960506 loss)
I0527 03:28:00.682780  7584 sgd_solver.cpp:106] Iteration 233500, lr = 0.0035
I0527 03:28:11.232554  7584 solver.cpp:237] Iteration 234000, loss = 0.999743
I0527 03:28:11.232591  7584 solver.cpp:253]     Train net output #0: loss = 0.999742 (* 1 = 0.999742 loss)
I0527 03:28:11.232609  7584 sgd_solver.cpp:106] Iteration 234000, lr = 0.0035
I0527 03:28:21.786450  7584 solver.cpp:237] Iteration 234500, loss = 0.910987
I0527 03:28:21.786502  7584 solver.cpp:253]     Train net output #0: loss = 0.910986 (* 1 = 0.910986 loss)
I0527 03:28:21.786521  7584 sgd_solver.cpp:106] Iteration 234500, lr = 0.0035
I0527 03:28:32.292315  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_235000.caffemodel
I0527 03:28:32.348408  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_235000.solverstate
I0527 03:28:32.383241  7584 solver.cpp:237] Iteration 235000, loss = 1.21625
I0527 03:28:32.383306  7584 solver.cpp:253]     Train net output #0: loss = 1.21624 (* 1 = 1.21624 loss)
I0527 03:28:32.383324  7584 sgd_solver.cpp:106] Iteration 235000, lr = 0.0035
I0527 03:28:42.920522  7584 solver.cpp:237] Iteration 235500, loss = 0.880754
I0527 03:28:42.920579  7584 solver.cpp:253]     Train net output #0: loss = 0.880753 (* 1 = 0.880753 loss)
I0527 03:28:42.920596  7584 sgd_solver.cpp:106] Iteration 235500, lr = 0.0035
I0527 03:28:53.491097  7584 solver.cpp:237] Iteration 236000, loss = 1.23096
I0527 03:28:53.491135  7584 solver.cpp:253]     Train net output #0: loss = 1.23096 (* 1 = 1.23096 loss)
I0527 03:28:53.491153  7584 sgd_solver.cpp:106] Iteration 236000, lr = 0.0035
I0527 03:29:04.059638  7584 solver.cpp:237] Iteration 236500, loss = 0.995357
I0527 03:29:04.059798  7584 solver.cpp:253]     Train net output #0: loss = 0.995357 (* 1 = 0.995357 loss)
I0527 03:29:04.059815  7584 sgd_solver.cpp:106] Iteration 236500, lr = 0.0035
I0527 03:29:36.851568  7584 solver.cpp:237] Iteration 237000, loss = 1.13301
I0527 03:29:36.851743  7584 solver.cpp:253]     Train net output #0: loss = 1.13301 (* 1 = 1.13301 loss)
I0527 03:29:36.851760  7584 sgd_solver.cpp:106] Iteration 237000, lr = 0.0035
I0527 03:29:47.423058  7584 solver.cpp:237] Iteration 237500, loss = 1.04276
I0527 03:29:47.423096  7584 solver.cpp:253]     Train net output #0: loss = 1.04276 (* 1 = 1.04276 loss)
I0527 03:29:47.423113  7584 sgd_solver.cpp:106] Iteration 237500, lr = 0.0035
I0527 03:29:57.965250  7584 solver.cpp:237] Iteration 238000, loss = 1.02494
I0527 03:29:57.965307  7584 solver.cpp:253]     Train net output #0: loss = 1.02493 (* 1 = 1.02493 loss)
I0527 03:29:57.965325  7584 sgd_solver.cpp:106] Iteration 238000, lr = 0.0035
I0527 03:30:08.479168  7584 solver.cpp:237] Iteration 238500, loss = 1.12124
I0527 03:30:08.479315  7584 solver.cpp:253]     Train net output #0: loss = 1.12124 (* 1 = 1.12124 loss)
I0527 03:30:08.479332  7584 sgd_solver.cpp:106] Iteration 238500, lr = 0.0035
I0527 03:30:18.969343  7584 solver.cpp:237] Iteration 239000, loss = 0.884475
I0527 03:30:18.969383  7584 solver.cpp:253]     Train net output #0: loss = 0.884474 (* 1 = 0.884474 loss)
I0527 03:30:18.969399  7584 sgd_solver.cpp:106] Iteration 239000, lr = 0.0035
I0527 03:30:29.478029  7584 solver.cpp:237] Iteration 239500, loss = 1.21257
I0527 03:30:29.478077  7584 solver.cpp:253]     Train net output #0: loss = 1.21257 (* 1 = 1.21257 loss)
I0527 03:30:29.478096  7584 sgd_solver.cpp:106] Iteration 239500, lr = 0.0035
I0527 03:30:39.962265  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_240000.caffemodel
I0527 03:30:40.014726  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_240000.solverstate
I0527 03:30:40.040303  7584 solver.cpp:341] Iteration 240000, Testing net (#0)
I0527 03:31:29.335335  7584 solver.cpp:409]     Test net output #0: accuracy = 0.901476
I0527 03:31:29.335502  7584 solver.cpp:409]     Test net output #1: loss = 0.303151 (* 1 = 0.303151 loss)
I0527 03:31:51.547014  7584 solver.cpp:237] Iteration 240000, loss = 1.1122
I0527 03:31:51.547081  7584 solver.cpp:253]     Train net output #0: loss = 1.1122 (* 1 = 1.1122 loss)
I0527 03:31:51.547101  7584 sgd_solver.cpp:106] Iteration 240000, lr = 0.0035
I0527 03:32:02.137384  7584 solver.cpp:237] Iteration 240500, loss = 1.17773
I0527 03:32:02.137549  7584 solver.cpp:253]     Train net output #0: loss = 1.17773 (* 1 = 1.17773 loss)
I0527 03:32:02.137567  7584 sgd_solver.cpp:106] Iteration 240500, lr = 0.0035
I0527 03:32:12.739230  7584 solver.cpp:237] Iteration 241000, loss = 1.32519
I0527 03:32:12.739269  7584 solver.cpp:253]     Train net output #0: loss = 1.32519 (* 1 = 1.32519 loss)
I0527 03:32:12.739287  7584 sgd_solver.cpp:106] Iteration 241000, lr = 0.0035
I0527 03:32:23.354043  7584 solver.cpp:237] Iteration 241500, loss = 0.930233
I0527 03:32:23.354084  7584 solver.cpp:253]     Train net output #0: loss = 0.930232 (* 1 = 0.930232 loss)
I0527 03:32:23.354100  7584 sgd_solver.cpp:106] Iteration 241500, lr = 0.0035
I0527 03:32:33.892551  7584 solver.cpp:237] Iteration 242000, loss = 0.99708
I0527 03:32:33.892715  7584 solver.cpp:253]     Train net output #0: loss = 0.997079 (* 1 = 0.997079 loss)
I0527 03:32:33.892732  7584 sgd_solver.cpp:106] Iteration 242000, lr = 0.0035
I0527 03:32:44.451272  7584 solver.cpp:237] Iteration 242500, loss = 1.20798
I0527 03:32:44.451308  7584 solver.cpp:253]     Train net output #0: loss = 1.20798 (* 1 = 1.20798 loss)
I0527 03:32:44.451328  7584 sgd_solver.cpp:106] Iteration 242500, lr = 0.0035
I0527 03:32:55.008380  7584 solver.cpp:237] Iteration 243000, loss = 0.957369
I0527 03:32:55.008435  7584 solver.cpp:253]     Train net output #0: loss = 0.957368 (* 1 = 0.957368 loss)
I0527 03:32:55.008455  7584 sgd_solver.cpp:106] Iteration 243000, lr = 0.0035
I0527 03:33:27.797425  7584 solver.cpp:237] Iteration 243500, loss = 1.21729
I0527 03:33:27.797612  7584 solver.cpp:253]     Train net output #0: loss = 1.21729 (* 1 = 1.21729 loss)
I0527 03:33:27.797631  7584 sgd_solver.cpp:106] Iteration 243500, lr = 0.0035
I0527 03:33:38.393712  7584 solver.cpp:237] Iteration 244000, loss = 1.01755
I0527 03:33:38.393750  7584 solver.cpp:253]     Train net output #0: loss = 1.01755 (* 1 = 1.01755 loss)
I0527 03:33:38.393767  7584 sgd_solver.cpp:106] Iteration 244000, lr = 0.0035
I0527 03:33:48.942134  7584 solver.cpp:237] Iteration 244500, loss = 1.08231
I0527 03:33:48.942183  7584 solver.cpp:253]     Train net output #0: loss = 1.08231 (* 1 = 1.08231 loss)
I0527 03:33:48.942201  7584 sgd_solver.cpp:106] Iteration 244500, lr = 0.0035
I0527 03:33:59.440649  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_245000.caffemodel
I0527 03:33:59.493525  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_245000.solverstate
I0527 03:33:59.526017  7584 solver.cpp:237] Iteration 245000, loss = 1.29984
I0527 03:33:59.526073  7584 solver.cpp:253]     Train net output #0: loss = 1.29984 (* 1 = 1.29984 loss)
I0527 03:33:59.526093  7584 sgd_solver.cpp:106] Iteration 245000, lr = 0.0035
I0527 03:34:10.049073  7584 solver.cpp:237] Iteration 245500, loss = 1.1941
I0527 03:34:10.049124  7584 solver.cpp:253]     Train net output #0: loss = 1.1941 (* 1 = 1.1941 loss)
I0527 03:34:10.049142  7584 sgd_solver.cpp:106] Iteration 245500, lr = 0.0035
I0527 03:34:20.570751  7584 solver.cpp:237] Iteration 246000, loss = 1.3354
I0527 03:34:20.570791  7584 solver.cpp:253]     Train net output #0: loss = 1.33539 (* 1 = 1.33539 loss)
I0527 03:34:20.570807  7584 sgd_solver.cpp:106] Iteration 246000, lr = 0.0035
I0527 03:34:31.094394  7584 solver.cpp:237] Iteration 246500, loss = 1.00979
I0527 03:34:31.094558  7584 solver.cpp:253]     Train net output #0: loss = 1.00978 (* 1 = 1.00978 loss)
I0527 03:34:31.094578  7584 sgd_solver.cpp:106] Iteration 246500, lr = 0.0035
I0527 03:35:03.871129  7584 solver.cpp:237] Iteration 247000, loss = 1.26133
I0527 03:35:03.871316  7584 solver.cpp:253]     Train net output #0: loss = 1.26132 (* 1 = 1.26132 loss)
I0527 03:35:03.871333  7584 sgd_solver.cpp:106] Iteration 247000, lr = 0.0035
I0527 03:35:14.510059  7584 solver.cpp:237] Iteration 247500, loss = 1.47684
I0527 03:35:14.510097  7584 solver.cpp:253]     Train net output #0: loss = 1.47684 (* 1 = 1.47684 loss)
I0527 03:35:14.510114  7584 sgd_solver.cpp:106] Iteration 247500, lr = 0.0035
I0527 03:35:25.116108  7584 solver.cpp:237] Iteration 248000, loss = 1.5313
I0527 03:35:25.116164  7584 solver.cpp:253]     Train net output #0: loss = 1.5313 (* 1 = 1.5313 loss)
I0527 03:35:25.116183  7584 sgd_solver.cpp:106] Iteration 248000, lr = 0.0035
I0527 03:35:35.663166  7584 solver.cpp:237] Iteration 248500, loss = 1.30554
I0527 03:35:35.663311  7584 solver.cpp:253]     Train net output #0: loss = 1.30554 (* 1 = 1.30554 loss)
I0527 03:35:35.663328  7584 sgd_solver.cpp:106] Iteration 248500, lr = 0.0035
I0527 03:35:46.210083  7584 solver.cpp:237] Iteration 249000, loss = 1.6323
I0527 03:35:46.210130  7584 solver.cpp:253]     Train net output #0: loss = 1.6323 (* 1 = 1.6323 loss)
I0527 03:35:46.210147  7584 sgd_solver.cpp:106] Iteration 249000, lr = 0.0035
I0527 03:35:56.759508  7584 solver.cpp:237] Iteration 249500, loss = 1.17897
I0527 03:35:56.759546  7584 solver.cpp:253]     Train net output #0: loss = 1.17897 (* 1 = 1.17897 loss)
I0527 03:35:56.759565  7584 sgd_solver.cpp:106] Iteration 249500, lr = 0.0035
I0527 03:36:07.287678  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_250000.caffemodel
I0527 03:36:07.340451  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_250000.solverstate
I0527 03:36:07.365867  7584 solver.cpp:341] Iteration 250000, Testing net (#0)
I0527 03:37:17.848217  7584 solver.cpp:409]     Test net output #0: accuracy = 0.902863
I0527 03:37:17.848387  7584 solver.cpp:409]     Test net output #1: loss = 0.315385 (* 1 = 0.315385 loss)
I0527 03:37:40.006295  7584 solver.cpp:237] Iteration 250000, loss = 1.29933
I0527 03:37:40.006359  7584 solver.cpp:253]     Train net output #0: loss = 1.29933 (* 1 = 1.29933 loss)
I0527 03:37:40.006386  7584 sgd_solver.cpp:106] Iteration 250000, lr = 0.0035
I0527 03:37:50.562836  7584 solver.cpp:237] Iteration 250500, loss = 1.06892
I0527 03:37:50.562994  7584 solver.cpp:253]     Train net output #0: loss = 1.06892 (* 1 = 1.06892 loss)
I0527 03:37:50.563010  7584 sgd_solver.cpp:106] Iteration 250500, lr = 0.0035
I0527 03:38:01.139413  7584 solver.cpp:237] Iteration 251000, loss = 0.723085
I0527 03:38:01.139470  7584 solver.cpp:253]     Train net output #0: loss = 0.723084 (* 1 = 0.723084 loss)
I0527 03:38:01.139488  7584 sgd_solver.cpp:106] Iteration 251000, lr = 0.0035
I0527 03:38:11.700718  7584 solver.cpp:237] Iteration 251500, loss = 0.754756
I0527 03:38:11.700759  7584 solver.cpp:253]     Train net output #0: loss = 0.754756 (* 1 = 0.754756 loss)
I0527 03:38:11.700776  7584 sgd_solver.cpp:106] Iteration 251500, lr = 0.0035
I0527 03:38:22.245158  7584 solver.cpp:237] Iteration 252000, loss = 0.918469
I0527 03:38:22.245326  7584 solver.cpp:253]     Train net output #0: loss = 0.918468 (* 1 = 0.918468 loss)
I0527 03:38:22.245343  7584 sgd_solver.cpp:106] Iteration 252000, lr = 0.0035
I0527 03:38:32.795030  7584 solver.cpp:237] Iteration 252500, loss = 0.959503
I0527 03:38:32.795073  7584 solver.cpp:253]     Train net output #0: loss = 0.959503 (* 1 = 0.959503 loss)
I0527 03:38:32.795090  7584 sgd_solver.cpp:106] Iteration 252500, lr = 0.0035
I0527 03:38:43.344784  7584 solver.cpp:237] Iteration 253000, loss = 0.827567
I0527 03:38:43.344841  7584 solver.cpp:253]     Train net output #0: loss = 0.827566 (* 1 = 0.827566 loss)
I0527 03:38:43.344858  7584 sgd_solver.cpp:106] Iteration 253000, lr = 0.0035
I0527 03:39:16.072085  7584 solver.cpp:237] Iteration 253500, loss = 1.14447
I0527 03:39:16.072259  7584 solver.cpp:253]     Train net output #0: loss = 1.14447 (* 1 = 1.14447 loss)
I0527 03:39:16.072278  7584 sgd_solver.cpp:106] Iteration 253500, lr = 0.0035
I0527 03:39:26.635644  7584 solver.cpp:237] Iteration 254000, loss = 1.28324
I0527 03:39:26.635681  7584 solver.cpp:253]     Train net output #0: loss = 1.28324 (* 1 = 1.28324 loss)
I0527 03:39:26.635700  7584 sgd_solver.cpp:106] Iteration 254000, lr = 0.0035
I0527 03:39:37.210306  7584 solver.cpp:237] Iteration 254500, loss = 0.966003
I0527 03:39:37.210363  7584 solver.cpp:253]     Train net output #0: loss = 0.966002 (* 1 = 0.966002 loss)
I0527 03:39:37.210381  7584 sgd_solver.cpp:106] Iteration 254500, lr = 0.0035
I0527 03:39:47.765133  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_255000.caffemodel
I0527 03:39:47.821346  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_255000.solverstate
I0527 03:39:47.856068  7584 solver.cpp:237] Iteration 255000, loss = 1.36692
I0527 03:39:47.856133  7584 solver.cpp:253]     Train net output #0: loss = 1.36692 (* 1 = 1.36692 loss)
I0527 03:39:47.856151  7584 sgd_solver.cpp:106] Iteration 255000, lr = 0.0035
I0527 03:39:58.441982  7584 solver.cpp:237] Iteration 255500, loss = 1.01086
I0527 03:39:58.442039  7584 solver.cpp:253]     Train net output #0: loss = 1.01086 (* 1 = 1.01086 loss)
I0527 03:39:58.442056  7584 sgd_solver.cpp:106] Iteration 255500, lr = 0.0035
I0527 03:40:09.054216  7584 solver.cpp:237] Iteration 256000, loss = 1.84608
I0527 03:40:09.054260  7584 solver.cpp:253]     Train net output #0: loss = 1.84608 (* 1 = 1.84608 loss)
I0527 03:40:09.054277  7584 sgd_solver.cpp:106] Iteration 256000, lr = 0.0035
I0527 03:40:19.678014  7584 solver.cpp:237] Iteration 256500, loss = 1.21852
I0527 03:40:19.678179  7584 solver.cpp:253]     Train net output #0: loss = 1.21852 (* 1 = 1.21852 loss)
I0527 03:40:19.678195  7584 sgd_solver.cpp:106] Iteration 256500, lr = 0.0035
I0527 03:40:52.336534  7584 solver.cpp:237] Iteration 257000, loss = 0.793696
I0527 03:40:52.336712  7584 solver.cpp:253]     Train net output #0: loss = 0.793695 (* 1 = 0.793695 loss)
I0527 03:40:52.336730  7584 sgd_solver.cpp:106] Iteration 257000, lr = 0.0035
I0527 03:41:02.836031  7584 solver.cpp:237] Iteration 257500, loss = 1.15906
I0527 03:41:02.836074  7584 solver.cpp:253]     Train net output #0: loss = 1.15906 (* 1 = 1.15906 loss)
I0527 03:41:02.836091  7584 sgd_solver.cpp:106] Iteration 257500, lr = 0.0035
I0527 03:41:13.346292  7584 solver.cpp:237] Iteration 258000, loss = 1.28986
I0527 03:41:13.346345  7584 solver.cpp:253]     Train net output #0: loss = 1.28986 (* 1 = 1.28986 loss)
I0527 03:41:13.346364  7584 sgd_solver.cpp:106] Iteration 258000, lr = 0.0035
I0527 03:41:23.862493  7584 solver.cpp:237] Iteration 258500, loss = 1.28384
I0527 03:41:23.862643  7584 solver.cpp:253]     Train net output #0: loss = 1.28384 (* 1 = 1.28384 loss)
I0527 03:41:23.862660  7584 sgd_solver.cpp:106] Iteration 258500, lr = 0.0035
I0527 03:41:34.372476  7584 solver.cpp:237] Iteration 259000, loss = 1.31692
I0527 03:41:34.372514  7584 solver.cpp:253]     Train net output #0: loss = 1.31692 (* 1 = 1.31692 loss)
I0527 03:41:34.372534  7584 sgd_solver.cpp:106] Iteration 259000, lr = 0.0035
I0527 03:41:44.982048  7584 solver.cpp:237] Iteration 259500, loss = 1.52588
I0527 03:41:44.982100  7584 solver.cpp:253]     Train net output #0: loss = 1.52588 (* 1 = 1.52588 loss)
I0527 03:41:44.982118  7584 sgd_solver.cpp:106] Iteration 259500, lr = 0.0035
I0527 03:41:55.567217  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_260000.caffemodel
I0527 03:41:55.623433  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_260000.solverstate
I0527 03:41:55.651198  7584 solver.cpp:341] Iteration 260000, Testing net (#0)
I0527 03:42:45.323848  7584 solver.cpp:409]     Test net output #0: accuracy = 0.902979
I0527 03:42:45.324018  7584 solver.cpp:409]     Test net output #1: loss = 0.315839 (* 1 = 0.315839 loss)
I0527 03:43:06.248280  7584 solver.cpp:237] Iteration 260000, loss = 1.16194
I0527 03:43:06.248342  7584 solver.cpp:253]     Train net output #0: loss = 1.16194 (* 1 = 1.16194 loss)
I0527 03:43:06.248371  7584 sgd_solver.cpp:106] Iteration 260000, lr = 0.0035
I0527 03:43:16.802909  7584 solver.cpp:237] Iteration 260500, loss = 1.03024
I0527 03:43:16.803078  7584 solver.cpp:253]     Train net output #0: loss = 1.03024 (* 1 = 1.03024 loss)
I0527 03:43:16.803097  7584 sgd_solver.cpp:106] Iteration 260500, lr = 0.0035
I0527 03:43:27.321931  7584 solver.cpp:237] Iteration 261000, loss = 0.998727
I0527 03:43:27.321969  7584 solver.cpp:253]     Train net output #0: loss = 0.998726 (* 1 = 0.998726 loss)
I0527 03:43:27.321988  7584 sgd_solver.cpp:106] Iteration 261000, lr = 0.0035
I0527 03:43:37.828786  7584 solver.cpp:237] Iteration 261500, loss = 1.39979
I0527 03:43:37.828825  7584 solver.cpp:253]     Train net output #0: loss = 1.39979 (* 1 = 1.39979 loss)
I0527 03:43:37.828842  7584 sgd_solver.cpp:106] Iteration 261500, lr = 0.0035
I0527 03:43:48.359671  7584 solver.cpp:237] Iteration 262000, loss = 1.13935
I0527 03:43:48.359851  7584 solver.cpp:253]     Train net output #0: loss = 1.13935 (* 1 = 1.13935 loss)
I0527 03:43:48.359869  7584 sgd_solver.cpp:106] Iteration 262000, lr = 0.0035
I0527 03:43:58.907769  7584 solver.cpp:237] Iteration 262500, loss = 1.15857
I0527 03:43:58.907806  7584 solver.cpp:253]     Train net output #0: loss = 1.15857 (* 1 = 1.15857 loss)
I0527 03:43:58.907825  7584 sgd_solver.cpp:106] Iteration 262500, lr = 0.0035
I0527 03:44:09.462368  7584 solver.cpp:237] Iteration 263000, loss = 1.43255
I0527 03:44:09.462424  7584 solver.cpp:253]     Train net output #0: loss = 1.43254 (* 1 = 1.43254 loss)
I0527 03:44:09.462441  7584 sgd_solver.cpp:106] Iteration 263000, lr = 0.0035
I0527 03:44:40.858362  7584 solver.cpp:237] Iteration 263500, loss = 0.95097
I0527 03:44:40.858541  7584 solver.cpp:253]     Train net output #0: loss = 0.950969 (* 1 = 0.950969 loss)
I0527 03:44:40.858558  7584 sgd_solver.cpp:106] Iteration 263500, lr = 0.0035
I0527 03:44:51.389451  7584 solver.cpp:237] Iteration 264000, loss = 0.939725
I0527 03:44:51.389488  7584 solver.cpp:253]     Train net output #0: loss = 0.939724 (* 1 = 0.939724 loss)
I0527 03:44:51.389508  7584 sgd_solver.cpp:106] Iteration 264000, lr = 0.0035
I0527 03:45:01.933713  7584 solver.cpp:237] Iteration 264500, loss = 1.65182
I0527 03:45:01.933768  7584 solver.cpp:253]     Train net output #0: loss = 1.65182 (* 1 = 1.65182 loss)
I0527 03:45:01.933784  7584 sgd_solver.cpp:106] Iteration 264500, lr = 0.0035
I0527 03:45:12.449144  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_265000.caffemodel
I0527 03:45:12.501528  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_265000.solverstate
I0527 03:45:12.533504  7584 solver.cpp:237] Iteration 265000, loss = 0.948627
I0527 03:45:12.533563  7584 solver.cpp:253]     Train net output #0: loss = 0.948626 (* 1 = 0.948626 loss)
I0527 03:45:12.533582  7584 sgd_solver.cpp:106] Iteration 265000, lr = 0.0035
I0527 03:45:23.064599  7584 solver.cpp:237] Iteration 265500, loss = 1.3526
I0527 03:45:23.064654  7584 solver.cpp:253]     Train net output #0: loss = 1.3526 (* 1 = 1.3526 loss)
I0527 03:45:23.064672  7584 sgd_solver.cpp:106] Iteration 265500, lr = 0.0035
I0527 03:45:33.575352  7584 solver.cpp:237] Iteration 266000, loss = 0.96639
I0527 03:45:33.575392  7584 solver.cpp:253]     Train net output #0: loss = 0.966389 (* 1 = 0.966389 loss)
I0527 03:45:33.575408  7584 sgd_solver.cpp:106] Iteration 266000, lr = 0.0035
I0527 03:45:44.092325  7584 solver.cpp:237] Iteration 266500, loss = 1.16147
I0527 03:45:44.092481  7584 solver.cpp:253]     Train net output #0: loss = 1.16146 (* 1 = 1.16146 loss)
I0527 03:45:44.092499  7584 sgd_solver.cpp:106] Iteration 266500, lr = 0.0035
I0527 03:46:15.507068  7584 solver.cpp:237] Iteration 267000, loss = 1.22415
I0527 03:46:15.507243  7584 solver.cpp:253]     Train net output #0: loss = 1.22415 (* 1 = 1.22415 loss)
I0527 03:46:15.507261  7584 sgd_solver.cpp:106] Iteration 267000, lr = 0.0035
I0527 03:46:26.060164  7584 solver.cpp:237] Iteration 267500, loss = 1.20832
I0527 03:46:26.060201  7584 solver.cpp:253]     Train net output #0: loss = 1.20832 (* 1 = 1.20832 loss)
I0527 03:46:26.060220  7584 sgd_solver.cpp:106] Iteration 267500, lr = 0.0035
I0527 03:46:36.608054  7584 solver.cpp:237] Iteration 268000, loss = 1.05863
I0527 03:46:36.608108  7584 solver.cpp:253]     Train net output #0: loss = 1.05863 (* 1 = 1.05863 loss)
I0527 03:46:36.608125  7584 sgd_solver.cpp:106] Iteration 268000, lr = 0.0035
I0527 03:46:47.201011  7584 solver.cpp:237] Iteration 268500, loss = 1.16545
I0527 03:46:47.201174  7584 solver.cpp:253]     Train net output #0: loss = 1.16545 (* 1 = 1.16545 loss)
I0527 03:46:47.201191  7584 sgd_solver.cpp:106] Iteration 268500, lr = 0.0035
I0527 03:46:57.811691  7584 solver.cpp:237] Iteration 269000, loss = 1.26752
I0527 03:46:57.811730  7584 solver.cpp:253]     Train net output #0: loss = 1.26752 (* 1 = 1.26752 loss)
I0527 03:46:57.811748  7584 sgd_solver.cpp:106] Iteration 269000, lr = 0.0035
I0527 03:47:08.361188  7584 solver.cpp:237] Iteration 269500, loss = 1.08802
I0527 03:47:08.361243  7584 solver.cpp:253]     Train net output #0: loss = 1.08802 (* 1 = 1.08802 loss)
I0527 03:47:08.361260  7584 sgd_solver.cpp:106] Iteration 269500, lr = 0.0035
I0527 03:47:18.849455  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_270000.caffemodel
I0527 03:47:18.903275  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_270000.solverstate
I0527 03:47:18.929033  7584 solver.cpp:341] Iteration 270000, Testing net (#0)
I0527 03:48:29.456722  7584 solver.cpp:409]     Test net output #0: accuracy = 0.901912
I0527 03:48:29.456895  7584 solver.cpp:409]     Test net output #1: loss = 0.301555 (* 1 = 0.301555 loss)
I0527 03:48:50.342736  7584 solver.cpp:237] Iteration 270000, loss = 1.00103
I0527 03:48:50.342798  7584 solver.cpp:253]     Train net output #0: loss = 1.00103 (* 1 = 1.00103 loss)
I0527 03:48:50.342816  7584 sgd_solver.cpp:106] Iteration 270000, lr = 0.0035
I0527 03:49:00.858188  7584 solver.cpp:237] Iteration 270500, loss = 0.927373
I0527 03:49:00.858357  7584 solver.cpp:253]     Train net output #0: loss = 0.927371 (* 1 = 0.927371 loss)
I0527 03:49:00.858374  7584 sgd_solver.cpp:106] Iteration 270500, lr = 0.0035
I0527 03:49:11.365154  7584 solver.cpp:237] Iteration 271000, loss = 1.18869
I0527 03:49:11.365208  7584 solver.cpp:253]     Train net output #0: loss = 1.18869 (* 1 = 1.18869 loss)
I0527 03:49:11.365226  7584 sgd_solver.cpp:106] Iteration 271000, lr = 0.0035
I0527 03:49:21.868376  7584 solver.cpp:237] Iteration 271500, loss = 1.3725
I0527 03:49:21.868413  7584 solver.cpp:253]     Train net output #0: loss = 1.3725 (* 1 = 1.3725 loss)
I0527 03:49:21.868432  7584 sgd_solver.cpp:106] Iteration 271500, lr = 0.0035
I0527 03:49:32.379016  7584 solver.cpp:237] Iteration 272000, loss = 1.14987
I0527 03:49:32.379185  7584 solver.cpp:253]     Train net output #0: loss = 1.14987 (* 1 = 1.14987 loss)
I0527 03:49:32.379204  7584 sgd_solver.cpp:106] Iteration 272000, lr = 0.0035
I0527 03:49:42.914119  7584 solver.cpp:237] Iteration 272500, loss = 1.10406
I0527 03:49:42.914156  7584 solver.cpp:253]     Train net output #0: loss = 1.10405 (* 1 = 1.10405 loss)
I0527 03:49:42.914175  7584 sgd_solver.cpp:106] Iteration 272500, lr = 0.0035
I0527 03:49:53.431500  7584 solver.cpp:237] Iteration 273000, loss = 1.02631
I0527 03:49:53.431538  7584 solver.cpp:253]     Train net output #0: loss = 1.02631 (* 1 = 1.02631 loss)
I0527 03:49:53.431555  7584 sgd_solver.cpp:106] Iteration 273000, lr = 0.0035
I0527 03:50:24.927779  7584 solver.cpp:237] Iteration 273500, loss = 1.2793
I0527 03:50:24.927963  7584 solver.cpp:253]     Train net output #0: loss = 1.2793 (* 1 = 1.2793 loss)
I0527 03:50:24.927980  7584 sgd_solver.cpp:106] Iteration 273500, lr = 0.0035
I0527 03:50:35.527107  7584 solver.cpp:237] Iteration 274000, loss = 1.14622
I0527 03:50:35.527145  7584 solver.cpp:253]     Train net output #0: loss = 1.14622 (* 1 = 1.14622 loss)
I0527 03:50:35.527163  7584 sgd_solver.cpp:106] Iteration 274000, lr = 0.0035
I0527 03:50:46.122377  7584 solver.cpp:237] Iteration 274500, loss = 1.02744
I0527 03:50:46.122434  7584 solver.cpp:253]     Train net output #0: loss = 1.02743 (* 1 = 1.02743 loss)
I0527 03:50:46.122454  7584 sgd_solver.cpp:106] Iteration 274500, lr = 0.0035
I0527 03:50:56.711145  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_275000.caffemodel
I0527 03:50:56.765110  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_275000.solverstate
I0527 03:50:56.801069  7584 solver.cpp:237] Iteration 275000, loss = 1.0467
I0527 03:50:56.801133  7584 solver.cpp:253]     Train net output #0: loss = 1.0467 (* 1 = 1.0467 loss)
I0527 03:50:56.801152  7584 sgd_solver.cpp:106] Iteration 275000, lr = 0.0035
I0527 03:51:07.419029  7584 solver.cpp:237] Iteration 275500, loss = 0.762684
I0527 03:51:07.419070  7584 solver.cpp:253]     Train net output #0: loss = 0.762684 (* 1 = 0.762684 loss)
I0527 03:51:07.419088  7584 sgd_solver.cpp:106] Iteration 275500, lr = 0.0035
I0527 03:51:18.045169  7584 solver.cpp:237] Iteration 276000, loss = 0.778467
I0527 03:51:18.045227  7584 solver.cpp:253]     Train net output #0: loss = 0.778466 (* 1 = 0.778466 loss)
I0527 03:51:18.045308  7584 sgd_solver.cpp:106] Iteration 276000, lr = 0.0035
I0527 03:51:28.650745  7584 solver.cpp:237] Iteration 276500, loss = 1.35625
I0527 03:51:28.650910  7584 solver.cpp:253]     Train net output #0: loss = 1.35625 (* 1 = 1.35625 loss)
I0527 03:51:28.650928  7584 sgd_solver.cpp:106] Iteration 276500, lr = 0.0035
I0527 03:52:00.161620  7584 solver.cpp:237] Iteration 277000, loss = 0.991422
I0527 03:52:00.161800  7584 solver.cpp:253]     Train net output #0: loss = 0.991421 (* 1 = 0.991421 loss)
I0527 03:52:00.161818  7584 sgd_solver.cpp:106] Iteration 277000, lr = 0.0035
I0527 03:52:10.775143  7584 solver.cpp:237] Iteration 277500, loss = 1.16047
I0527 03:52:10.775199  7584 solver.cpp:253]     Train net output #0: loss = 1.16047 (* 1 = 1.16047 loss)
I0527 03:52:10.775216  7584 sgd_solver.cpp:106] Iteration 277500, lr = 0.0035
I0527 03:52:21.396453  7584 solver.cpp:237] Iteration 278000, loss = 1.04975
I0527 03:52:21.396492  7584 solver.cpp:253]     Train net output #0: loss = 1.04975 (* 1 = 1.04975 loss)
I0527 03:52:21.396510  7584 sgd_solver.cpp:106] Iteration 278000, lr = 0.0035
I0527 03:52:31.962049  7584 solver.cpp:237] Iteration 278500, loss = 0.955879
I0527 03:52:31.962229  7584 solver.cpp:253]     Train net output #0: loss = 0.955878 (* 1 = 0.955878 loss)
I0527 03:52:31.962247  7584 sgd_solver.cpp:106] Iteration 278500, lr = 0.0035
I0527 03:52:42.490804  7584 solver.cpp:237] Iteration 279000, loss = 1.34472
I0527 03:52:42.490842  7584 solver.cpp:253]     Train net output #0: loss = 1.34471 (* 1 = 1.34471 loss)
I0527 03:52:42.490859  7584 sgd_solver.cpp:106] Iteration 279000, lr = 0.0035
I0527 03:52:53.009629  7584 solver.cpp:237] Iteration 279500, loss = 1.1846
I0527 03:52:53.009683  7584 solver.cpp:253]     Train net output #0: loss = 1.1846 (* 1 = 1.1846 loss)
I0527 03:52:53.009701  7584 sgd_solver.cpp:106] Iteration 279500, lr = 0.0035
I0527 03:53:03.518460  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_280000.caffemodel
I0527 03:53:03.574190  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_280000.solverstate
I0527 03:53:03.601671  7584 solver.cpp:341] Iteration 280000, Testing net (#0)
I0527 03:53:52.935094  7584 solver.cpp:409]     Test net output #0: accuracy = 0.901317
I0527 03:53:52.935271  7584 solver.cpp:409]     Test net output #1: loss = 0.331499 (* 1 = 0.331499 loss)
I0527 03:54:13.827253  7584 solver.cpp:237] Iteration 280000, loss = 1.19437
I0527 03:54:13.827321  7584 solver.cpp:253]     Train net output #0: loss = 1.19437 (* 1 = 1.19437 loss)
I0527 03:54:13.827342  7584 sgd_solver.cpp:106] Iteration 280000, lr = 0.0035
I0527 03:54:24.371045  7584 solver.cpp:237] Iteration 280500, loss = 0.908532
I0527 03:54:24.371217  7584 solver.cpp:253]     Train net output #0: loss = 0.908531 (* 1 = 0.908531 loss)
I0527 03:54:24.371234  7584 sgd_solver.cpp:106] Iteration 280500, lr = 0.0035
I0527 03:54:34.927474  7584 solver.cpp:237] Iteration 281000, loss = 1.60651
I0527 03:54:34.927532  7584 solver.cpp:253]     Train net output #0: loss = 1.60651 (* 1 = 1.60651 loss)
I0527 03:54:34.927551  7584 sgd_solver.cpp:106] Iteration 281000, lr = 0.0035
I0527 03:54:45.468344  7584 solver.cpp:237] Iteration 281500, loss = 1.05141
I0527 03:54:45.468382  7584 solver.cpp:253]     Train net output #0: loss = 1.05141 (* 1 = 1.05141 loss)
I0527 03:54:45.468400  7584 sgd_solver.cpp:106] Iteration 281500, lr = 0.0035
I0527 03:54:55.984938  7584 solver.cpp:237] Iteration 282000, loss = 1.35695
I0527 03:54:55.985112  7584 solver.cpp:253]     Train net output #0: loss = 1.35695 (* 1 = 1.35695 loss)
I0527 03:54:55.985131  7584 sgd_solver.cpp:106] Iteration 282000, lr = 0.0035
I0527 03:55:06.587218  7584 solver.cpp:237] Iteration 282500, loss = 0.967146
I0527 03:55:06.587256  7584 solver.cpp:253]     Train net output #0: loss = 0.967145 (* 1 = 0.967145 loss)
I0527 03:55:06.587275  7584 sgd_solver.cpp:106] Iteration 282500, lr = 0.0035
I0527 03:55:17.176774  7584 solver.cpp:237] Iteration 283000, loss = 1.06596
I0527 03:55:17.176811  7584 solver.cpp:253]     Train net output #0: loss = 1.06596 (* 1 = 1.06596 loss)
I0527 03:55:17.176831  7584 sgd_solver.cpp:106] Iteration 283000, lr = 0.0035
I0527 03:55:48.636960  7584 solver.cpp:237] Iteration 283500, loss = 1.15293
I0527 03:55:48.637141  7584 solver.cpp:253]     Train net output #0: loss = 1.15292 (* 1 = 1.15292 loss)
I0527 03:55:48.637158  7584 sgd_solver.cpp:106] Iteration 283500, lr = 0.0035
I0527 03:55:59.192260  7584 solver.cpp:237] Iteration 284000, loss = 1.12338
I0527 03:55:59.192296  7584 solver.cpp:253]     Train net output #0: loss = 1.12338 (* 1 = 1.12338 loss)
I0527 03:55:59.192315  7584 sgd_solver.cpp:106] Iteration 284000, lr = 0.0035
I0527 03:56:09.745129  7584 solver.cpp:237] Iteration 284500, loss = 0.931872
I0527 03:56:09.745167  7584 solver.cpp:253]     Train net output #0: loss = 0.931871 (* 1 = 0.931871 loss)
I0527 03:56:09.745183  7584 sgd_solver.cpp:106] Iteration 284500, lr = 0.0035
I0527 03:56:20.327155  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_285000.caffemodel
I0527 03:56:20.383533  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_285000.solverstate
I0527 03:56:20.418175  7584 solver.cpp:237] Iteration 285000, loss = 1.19978
I0527 03:56:20.418246  7584 solver.cpp:253]     Train net output #0: loss = 1.19977 (* 1 = 1.19977 loss)
I0527 03:56:20.418267  7584 sgd_solver.cpp:106] Iteration 285000, lr = 0.0035
I0527 03:56:31.034832  7584 solver.cpp:237] Iteration 285500, loss = 1.08342
I0527 03:56:31.034868  7584 solver.cpp:253]     Train net output #0: loss = 1.08342 (* 1 = 1.08342 loss)
I0527 03:56:31.034888  7584 sgd_solver.cpp:106] Iteration 285500, lr = 0.0035
I0527 03:56:41.618691  7584 solver.cpp:237] Iteration 286000, loss = 0.823678
I0527 03:56:41.618746  7584 solver.cpp:253]     Train net output #0: loss = 0.823677 (* 1 = 0.823677 loss)
I0527 03:56:41.618763  7584 sgd_solver.cpp:106] Iteration 286000, lr = 0.0035
I0527 03:56:52.203909  7584 solver.cpp:237] Iteration 286500, loss = 1.15717
I0527 03:56:52.204071  7584 solver.cpp:253]     Train net output #0: loss = 1.15717 (* 1 = 1.15717 loss)
I0527 03:56:52.204087  7584 sgd_solver.cpp:106] Iteration 286500, lr = 0.0035
I0527 03:57:23.678323  7584 solver.cpp:237] Iteration 287000, loss = 1.27538
I0527 03:57:23.678513  7584 solver.cpp:253]     Train net output #0: loss = 1.27538 (* 1 = 1.27538 loss)
I0527 03:57:23.678530  7584 sgd_solver.cpp:106] Iteration 287000, lr = 0.0035
I0527 03:57:34.243453  7584 solver.cpp:237] Iteration 287500, loss = 1.24982
I0527 03:57:34.243508  7584 solver.cpp:253]     Train net output #0: loss = 1.24981 (* 1 = 1.24981 loss)
I0527 03:57:34.243527  7584 sgd_solver.cpp:106] Iteration 287500, lr = 0.0035
I0527 03:57:44.824903  7584 solver.cpp:237] Iteration 288000, loss = 1.38953
I0527 03:57:44.824941  7584 solver.cpp:253]     Train net output #0: loss = 1.38953 (* 1 = 1.38953 loss)
I0527 03:57:44.824960  7584 sgd_solver.cpp:106] Iteration 288000, lr = 0.0035
I0527 03:57:55.374816  7584 solver.cpp:237] Iteration 288500, loss = 0.817714
I0527 03:57:55.375003  7584 solver.cpp:253]     Train net output #0: loss = 0.817713 (* 1 = 0.817713 loss)
I0527 03:57:55.375021  7584 sgd_solver.cpp:106] Iteration 288500, lr = 0.0035
I0527 03:58:05.943065  7584 solver.cpp:237] Iteration 289000, loss = 1.17286
I0527 03:58:05.943104  7584 solver.cpp:253]     Train net output #0: loss = 1.17286 (* 1 = 1.17286 loss)
I0527 03:58:05.943121  7584 sgd_solver.cpp:106] Iteration 289000, lr = 0.0035
I0527 03:58:16.498319  7584 solver.cpp:237] Iteration 289500, loss = 0.476243
I0527 03:58:16.498376  7584 solver.cpp:253]     Train net output #0: loss = 0.476241 (* 1 = 0.476241 loss)
I0527 03:58:16.498394  7584 sgd_solver.cpp:106] Iteration 289500, lr = 0.0035
I0527 03:58:27.023664  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_290000.caffemodel
I0527 03:58:27.077296  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_290000.solverstate
I0527 03:58:27.103186  7584 solver.cpp:341] Iteration 290000, Testing net (#0)
I0527 03:59:37.620256  7584 solver.cpp:409]     Test net output #0: accuracy = 0.904736
I0527 03:59:37.620434  7584 solver.cpp:409]     Test net output #1: loss = 0.307517 (* 1 = 0.307517 loss)
I0527 03:59:58.509635  7584 solver.cpp:237] Iteration 290000, loss = 0.725552
I0527 03:59:58.509701  7584 solver.cpp:253]     Train net output #0: loss = 0.725551 (* 1 = 0.725551 loss)
I0527 03:59:58.509721  7584 sgd_solver.cpp:106] Iteration 290000, lr = 0.0035
I0527 04:00:09.083914  7584 solver.cpp:237] Iteration 290500, loss = 1.03963
I0527 04:00:09.084076  7584 solver.cpp:253]     Train net output #0: loss = 1.03963 (* 1 = 1.03963 loss)
I0527 04:00:09.084092  7584 sgd_solver.cpp:106] Iteration 290500, lr = 0.0035
I0527 04:00:19.652305  7584 solver.cpp:237] Iteration 291000, loss = 1.07407
I0527 04:00:19.652348  7584 solver.cpp:253]     Train net output #0: loss = 1.07407 (* 1 = 1.07407 loss)
I0527 04:00:19.652364  7584 sgd_solver.cpp:106] Iteration 291000, lr = 0.0035
I0527 04:00:30.284876  7584 solver.cpp:237] Iteration 291500, loss = 0.979196
I0527 04:00:30.284934  7584 solver.cpp:253]     Train net output #0: loss = 0.979195 (* 1 = 0.979195 loss)
I0527 04:00:30.284950  7584 sgd_solver.cpp:106] Iteration 291500, lr = 0.0035
I0527 04:00:40.923342  7584 solver.cpp:237] Iteration 292000, loss = 1.13945
I0527 04:00:40.923508  7584 solver.cpp:253]     Train net output #0: loss = 1.13945 (* 1 = 1.13945 loss)
I0527 04:00:40.923524  7584 sgd_solver.cpp:106] Iteration 292000, lr = 0.0035
I0527 04:00:51.522171  7584 solver.cpp:237] Iteration 292500, loss = 1.08105
I0527 04:00:51.522230  7584 solver.cpp:253]     Train net output #0: loss = 1.08104 (* 1 = 1.08104 loss)
I0527 04:00:51.522248  7584 sgd_solver.cpp:106] Iteration 292500, lr = 0.0035
I0527 04:01:02.085319  7584 solver.cpp:237] Iteration 293000, loss = 1.14524
I0527 04:01:02.085356  7584 solver.cpp:253]     Train net output #0: loss = 1.14524 (* 1 = 1.14524 loss)
I0527 04:01:02.085374  7584 sgd_solver.cpp:106] Iteration 293000, lr = 0.0035
I0527 04:01:33.521176  7584 solver.cpp:237] Iteration 293500, loss = 1.1605
I0527 04:01:33.521360  7584 solver.cpp:253]     Train net output #0: loss = 1.1605 (* 1 = 1.1605 loss)
I0527 04:01:33.521378  7584 sgd_solver.cpp:106] Iteration 293500, lr = 0.0035
I0527 04:01:44.092123  7584 solver.cpp:237] Iteration 294000, loss = 0.859455
I0527 04:01:44.092180  7584 solver.cpp:253]     Train net output #0: loss = 0.859454 (* 1 = 0.859454 loss)
I0527 04:01:44.092197  7584 sgd_solver.cpp:106] Iteration 294000, lr = 0.0035
I0527 04:01:54.667445  7584 solver.cpp:237] Iteration 294500, loss = 0.888966
I0527 04:01:54.667484  7584 solver.cpp:253]     Train net output #0: loss = 0.888965 (* 1 = 0.888965 loss)
I0527 04:01:54.667501  7584 sgd_solver.cpp:106] Iteration 294500, lr = 0.0035
I0527 04:02:05.231334  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_295000.caffemodel
I0527 04:02:05.285308  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_295000.solverstate
I0527 04:02:05.317636  7584 solver.cpp:237] Iteration 295000, loss = 1.01394
I0527 04:02:05.317692  7584 solver.cpp:253]     Train net output #0: loss = 1.01393 (* 1 = 1.01393 loss)
I0527 04:02:05.317718  7584 sgd_solver.cpp:106] Iteration 295000, lr = 0.0035
I0527 04:02:15.917960  7584 solver.cpp:237] Iteration 295500, loss = 1.25429
I0527 04:02:15.917997  7584 solver.cpp:253]     Train net output #0: loss = 1.25429 (* 1 = 1.25429 loss)
I0527 04:02:15.918015  7584 sgd_solver.cpp:106] Iteration 295500, lr = 0.0035
I0527 04:02:26.513965  7584 solver.cpp:237] Iteration 296000, loss = 0.95255
I0527 04:02:26.514024  7584 solver.cpp:253]     Train net output #0: loss = 0.95255 (* 1 = 0.95255 loss)
I0527 04:02:26.514042  7584 sgd_solver.cpp:106] Iteration 296000, lr = 0.0035
I0527 04:02:37.115250  7584 solver.cpp:237] Iteration 296500, loss = 0.786608
I0527 04:02:37.115413  7584 solver.cpp:253]     Train net output #0: loss = 0.786607 (* 1 = 0.786607 loss)
I0527 04:02:37.115430  7584 sgd_solver.cpp:106] Iteration 296500, lr = 0.0035
I0527 04:03:08.573580  7584 solver.cpp:237] Iteration 297000, loss = 1.34805
I0527 04:03:08.573762  7584 solver.cpp:253]     Train net output #0: loss = 1.34804 (* 1 = 1.34804 loss)
I0527 04:03:08.573779  7584 sgd_solver.cpp:106] Iteration 297000, lr = 0.0035
I0527 04:03:19.155395  7584 solver.cpp:237] Iteration 297500, loss = 1.32382
I0527 04:03:19.155447  7584 solver.cpp:253]     Train net output #0: loss = 1.32382 (* 1 = 1.32382 loss)
I0527 04:03:19.155467  7584 sgd_solver.cpp:106] Iteration 297500, lr = 0.0035
I0527 04:03:29.698456  7584 solver.cpp:237] Iteration 298000, loss = 1.05418
I0527 04:03:29.698493  7584 solver.cpp:253]     Train net output #0: loss = 1.05418 (* 1 = 1.05418 loss)
I0527 04:03:29.698510  7584 sgd_solver.cpp:106] Iteration 298000, lr = 0.0035
I0527 04:03:40.244762  7584 solver.cpp:237] Iteration 298500, loss = 1.31307
I0527 04:03:40.244920  7584 solver.cpp:253]     Train net output #0: loss = 1.31307 (* 1 = 1.31307 loss)
I0527 04:03:40.244936  7584 sgd_solver.cpp:106] Iteration 298500, lr = 0.0035
I0527 04:03:50.795114  7584 solver.cpp:237] Iteration 299000, loss = 1.04201
I0527 04:03:50.795168  7584 solver.cpp:253]     Train net output #0: loss = 1.04201 (* 1 = 1.04201 loss)
I0527 04:03:50.795186  7584 sgd_solver.cpp:106] Iteration 299000, lr = 0.0035
I0527 04:04:01.341883  7584 solver.cpp:237] Iteration 299500, loss = 1.26888
I0527 04:04:01.341920  7584 solver.cpp:253]     Train net output #0: loss = 1.26888 (* 1 = 1.26888 loss)
I0527 04:04:01.341939  7584 sgd_solver.cpp:106] Iteration 299500, lr = 0.0035
I0527 04:04:11.863687  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_300000.caffemodel
I0527 04:04:11.916507  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_300000.solverstate
I0527 04:04:11.942507  7584 solver.cpp:341] Iteration 300000, Testing net (#0)
I0527 04:05:01.630543  7584 solver.cpp:409]     Test net output #0: accuracy = 0.902958
I0527 04:05:01.630731  7584 solver.cpp:409]     Test net output #1: loss = 0.306887 (* 1 = 0.306887 loss)
I0527 04:05:22.527730  7584 solver.cpp:237] Iteration 300000, loss = 1.04152
I0527 04:05:22.527794  7584 solver.cpp:253]     Train net output #0: loss = 1.04152 (* 1 = 1.04152 loss)
I0527 04:05:22.527822  7584 sgd_solver.cpp:106] Iteration 300000, lr = 0.0035
I0527 04:05:33.066231  7584 solver.cpp:237] Iteration 300500, loss = 0.762123
I0527 04:05:33.066409  7584 solver.cpp:253]     Train net output #0: loss = 0.762123 (* 1 = 0.762123 loss)
I0527 04:05:33.066427  7584 sgd_solver.cpp:106] Iteration 300500, lr = 0.0035
I0527 04:05:43.619926  7584 solver.cpp:237] Iteration 301000, loss = 1.08522
I0527 04:05:43.619964  7584 solver.cpp:253]     Train net output #0: loss = 1.08522 (* 1 = 1.08522 loss)
I0527 04:05:43.619982  7584 sgd_solver.cpp:106] Iteration 301000, lr = 0.0035
I0527 04:05:54.157042  7584 solver.cpp:237] Iteration 301500, loss = 1.05023
I0527 04:05:54.157102  7584 solver.cpp:253]     Train net output #0: loss = 1.05023 (* 1 = 1.05023 loss)
I0527 04:05:54.157119  7584 sgd_solver.cpp:106] Iteration 301500, lr = 0.0035
I0527 04:06:04.681563  7584 solver.cpp:237] Iteration 302000, loss = 1.17678
I0527 04:06:04.681725  7584 solver.cpp:253]     Train net output #0: loss = 1.17678 (* 1 = 1.17678 loss)
I0527 04:06:04.681741  7584 sgd_solver.cpp:106] Iteration 302000, lr = 0.0035
I0527 04:06:15.224417  7584 solver.cpp:237] Iteration 302500, loss = 1.09459
I0527 04:06:15.224472  7584 solver.cpp:253]     Train net output #0: loss = 1.09459 (* 1 = 1.09459 loss)
I0527 04:06:15.224489  7584 sgd_solver.cpp:106] Iteration 302500, lr = 0.0035
I0527 04:06:25.757364  7584 solver.cpp:237] Iteration 303000, loss = 1.21959
I0527 04:06:25.757403  7584 solver.cpp:253]     Train net output #0: loss = 1.21959 (* 1 = 1.21959 loss)
I0527 04:06:25.757421  7584 sgd_solver.cpp:106] Iteration 303000, lr = 0.0035
I0527 04:06:57.192082  7584 solver.cpp:237] Iteration 303500, loss = 1.07245
I0527 04:06:57.192266  7584 solver.cpp:253]     Train net output #0: loss = 1.07245 (* 1 = 1.07245 loss)
I0527 04:06:57.192283  7584 sgd_solver.cpp:106] Iteration 303500, lr = 0.0035
I0527 04:07:07.759817  7584 solver.cpp:237] Iteration 304000, loss = 1.15922
I0527 04:07:07.759871  7584 solver.cpp:253]     Train net output #0: loss = 1.15922 (* 1 = 1.15922 loss)
I0527 04:07:07.759889  7584 sgd_solver.cpp:106] Iteration 304000, lr = 0.0035
I0527 04:07:18.292969  7584 solver.cpp:237] Iteration 304500, loss = 1.28083
I0527 04:07:18.293007  7584 solver.cpp:253]     Train net output #0: loss = 1.28083 (* 1 = 1.28083 loss)
I0527 04:07:18.293023  7584 sgd_solver.cpp:106] Iteration 304500, lr = 0.0035
I0527 04:07:28.829509  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_305000.caffemodel
I0527 04:07:28.885669  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_305000.solverstate
I0527 04:07:28.920148  7584 solver.cpp:237] Iteration 305000, loss = 1.50621
I0527 04:07:28.920213  7584 solver.cpp:253]     Train net output #0: loss = 1.50621 (* 1 = 1.50621 loss)
I0527 04:07:28.920230  7584 sgd_solver.cpp:106] Iteration 305000, lr = 0.0035
I0527 04:07:39.553091  7584 solver.cpp:237] Iteration 305500, loss = 1.02696
I0527 04:07:39.553128  7584 solver.cpp:253]     Train net output #0: loss = 1.02696 (* 1 = 1.02696 loss)
I0527 04:07:39.553145  7584 sgd_solver.cpp:106] Iteration 305500, lr = 0.0035
I0527 04:07:50.162986  7584 solver.cpp:237] Iteration 306000, loss = 1.38107
I0527 04:07:50.163023  7584 solver.cpp:253]     Train net output #0: loss = 1.38107 (* 1 = 1.38107 loss)
I0527 04:07:50.163040  7584 sgd_solver.cpp:106] Iteration 306000, lr = 0.0035
I0527 04:08:00.797492  7584 solver.cpp:237] Iteration 306500, loss = 1.25755
I0527 04:08:00.797683  7584 solver.cpp:253]     Train net output #0: loss = 1.25755 (* 1 = 1.25755 loss)
I0527 04:08:00.797699  7584 sgd_solver.cpp:106] Iteration 306500, lr = 0.0035
I0527 04:08:32.353781  7584 solver.cpp:237] Iteration 307000, loss = 1.11934
I0527 04:08:32.353962  7584 solver.cpp:253]     Train net output #0: loss = 1.11934 (* 1 = 1.11934 loss)
I0527 04:08:32.353981  7584 sgd_solver.cpp:106] Iteration 307000, lr = 0.0035
I0527 04:08:42.995596  7584 solver.cpp:237] Iteration 307500, loss = 1.26885
I0527 04:08:42.995653  7584 solver.cpp:253]     Train net output #0: loss = 1.26885 (* 1 = 1.26885 loss)
I0527 04:08:42.995671  7584 sgd_solver.cpp:106] Iteration 307500, lr = 0.0035
I0527 04:08:53.613128  7584 solver.cpp:237] Iteration 308000, loss = 1.10495
I0527 04:08:53.613167  7584 solver.cpp:253]     Train net output #0: loss = 1.10495 (* 1 = 1.10495 loss)
I0527 04:08:53.613183  7584 sgd_solver.cpp:106] Iteration 308000, lr = 0.0035
I0527 04:09:04.229900  7584 solver.cpp:237] Iteration 308500, loss = 1.46289
I0527 04:09:04.230060  7584 solver.cpp:253]     Train net output #0: loss = 1.46289 (* 1 = 1.46289 loss)
I0527 04:09:04.230077  7584 sgd_solver.cpp:106] Iteration 308500, lr = 0.0035
I0527 04:09:14.860239  7584 solver.cpp:237] Iteration 309000, loss = 1.05694
I0527 04:09:14.860297  7584 solver.cpp:253]     Train net output #0: loss = 1.05694 (* 1 = 1.05694 loss)
I0527 04:09:14.860316  7584 sgd_solver.cpp:106] Iteration 309000, lr = 0.0035
I0527 04:09:25.495460  7584 solver.cpp:237] Iteration 309500, loss = 1.31141
I0527 04:09:25.495501  7584 solver.cpp:253]     Train net output #0: loss = 1.31141 (* 1 = 1.31141 loss)
I0527 04:09:25.495519  7584 sgd_solver.cpp:106] Iteration 309500, lr = 0.0035
I0527 04:09:36.103354  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_310000.caffemodel
I0527 04:09:36.158519  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_310000.solverstate
I0527 04:09:36.186414  7584 solver.cpp:341] Iteration 310000, Testing net (#0)
I0527 04:10:46.766263  7584 solver.cpp:409]     Test net output #0: accuracy = 0.901285
I0527 04:10:46.766446  7584 solver.cpp:409]     Test net output #1: loss = 0.330566 (* 1 = 0.330566 loss)
I0527 04:11:07.672341  7584 solver.cpp:237] Iteration 310000, loss = 1.13987
I0527 04:11:07.672406  7584 solver.cpp:253]     Train net output #0: loss = 1.13987 (* 1 = 1.13987 loss)
I0527 04:11:07.672426  7584 sgd_solver.cpp:106] Iteration 310000, lr = 0.0035
I0527 04:11:18.285709  7584 solver.cpp:237] Iteration 310500, loss = 1.0953
I0527 04:11:18.285892  7584 solver.cpp:253]     Train net output #0: loss = 1.0953 (* 1 = 1.0953 loss)
I0527 04:11:18.285908  7584 sgd_solver.cpp:106] Iteration 310500, lr = 0.0035
I0527 04:11:28.893292  7584 solver.cpp:237] Iteration 311000, loss = 1.30299
I0527 04:11:28.893331  7584 solver.cpp:253]     Train net output #0: loss = 1.30299 (* 1 = 1.30299 loss)
I0527 04:11:28.893347  7584 sgd_solver.cpp:106] Iteration 311000, lr = 0.0035
I0527 04:11:39.480363  7584 solver.cpp:237] Iteration 311500, loss = 1.06251
I0527 04:11:39.480418  7584 solver.cpp:253]     Train net output #0: loss = 1.06251 (* 1 = 1.06251 loss)
I0527 04:11:39.480437  7584 sgd_solver.cpp:106] Iteration 311500, lr = 0.0035
I0527 04:11:50.041822  7584 solver.cpp:237] Iteration 312000, loss = 1.06299
I0527 04:11:50.041985  7584 solver.cpp:253]     Train net output #0: loss = 1.06299 (* 1 = 1.06299 loss)
I0527 04:11:50.042001  7584 sgd_solver.cpp:106] Iteration 312000, lr = 0.0035
I0527 04:12:00.604173  7584 solver.cpp:237] Iteration 312500, loss = 1.41269
I0527 04:12:00.604210  7584 solver.cpp:253]     Train net output #0: loss = 1.41269 (* 1 = 1.41269 loss)
I0527 04:12:00.604229  7584 sgd_solver.cpp:106] Iteration 312500, lr = 0.0035
I0527 04:12:11.202512  7584 solver.cpp:237] Iteration 313000, loss = 1.09315
I0527 04:12:11.202564  7584 solver.cpp:253]     Train net output #0: loss = 1.09315 (* 1 = 1.09315 loss)
I0527 04:12:11.202580  7584 sgd_solver.cpp:106] Iteration 313000, lr = 0.0035
I0527 04:12:42.705692  7584 solver.cpp:237] Iteration 313500, loss = 1.20469
I0527 04:12:42.705883  7584 solver.cpp:253]     Train net output #0: loss = 1.20469 (* 1 = 1.20469 loss)
I0527 04:12:42.705900  7584 sgd_solver.cpp:106] Iteration 313500, lr = 0.0035
I0527 04:12:53.328699  7584 solver.cpp:237] Iteration 314000, loss = 1.06136
I0527 04:12:53.328755  7584 solver.cpp:253]     Train net output #0: loss = 1.06136 (* 1 = 1.06136 loss)
I0527 04:12:53.328773  7584 sgd_solver.cpp:106] Iteration 314000, lr = 0.0035
I0527 04:13:03.976330  7584 solver.cpp:237] Iteration 314500, loss = 1.22665
I0527 04:13:03.976367  7584 solver.cpp:253]     Train net output #0: loss = 1.22665 (* 1 = 1.22665 loss)
I0527 04:13:03.976385  7584 sgd_solver.cpp:106] Iteration 314500, lr = 0.0035
I0527 04:13:14.602083  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_315000.caffemodel
I0527 04:13:14.654633  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_315000.solverstate
I0527 04:13:14.686935  7584 solver.cpp:237] Iteration 315000, loss = 0.99969
I0527 04:13:14.686995  7584 solver.cpp:253]     Train net output #0: loss = 0.999689 (* 1 = 0.999689 loss)
I0527 04:13:14.687013  7584 sgd_solver.cpp:106] Iteration 315000, lr = 0.0035
I0527 04:13:25.234585  7584 solver.cpp:237] Iteration 315500, loss = 1.13814
I0527 04:13:25.234642  7584 solver.cpp:253]     Train net output #0: loss = 1.13814 (* 1 = 1.13814 loss)
I0527 04:13:25.234659  7584 sgd_solver.cpp:106] Iteration 315500, lr = 0.0035
I0527 04:13:35.770894  7584 solver.cpp:237] Iteration 316000, loss = 0.971806
I0527 04:13:35.770931  7584 solver.cpp:253]     Train net output #0: loss = 0.971805 (* 1 = 0.971805 loss)
I0527 04:13:35.770948  7584 sgd_solver.cpp:106] Iteration 316000, lr = 0.0035
I0527 04:13:46.318828  7584 solver.cpp:237] Iteration 316500, loss = 1.02972
I0527 04:13:46.319011  7584 solver.cpp:253]     Train net output #0: loss = 1.02972 (* 1 = 1.02972 loss)
I0527 04:13:46.319030  7584 sgd_solver.cpp:106] Iteration 316500, lr = 0.0035
I0527 04:14:17.770385  7584 solver.cpp:237] Iteration 317000, loss = 1.07807
I0527 04:14:17.770570  7584 solver.cpp:253]     Train net output #0: loss = 1.07807 (* 1 = 1.07807 loss)
I0527 04:14:17.770586  7584 sgd_solver.cpp:106] Iteration 317000, lr = 0.0035
I0527 04:14:28.326786  7584 solver.cpp:237] Iteration 317500, loss = 0.876586
I0527 04:14:28.326822  7584 solver.cpp:253]     Train net output #0: loss = 0.876585 (* 1 = 0.876585 loss)
I0527 04:14:28.326840  7584 sgd_solver.cpp:106] Iteration 317500, lr = 0.0035
I0527 04:14:38.879094  7584 solver.cpp:237] Iteration 318000, loss = 0.630721
I0527 04:14:38.879151  7584 solver.cpp:253]     Train net output #0: loss = 0.63072 (* 1 = 0.63072 loss)
I0527 04:14:38.879168  7584 sgd_solver.cpp:106] Iteration 318000, lr = 0.0035
I0527 04:14:49.415021  7584 solver.cpp:237] Iteration 318500, loss = 1.0905
I0527 04:14:49.415184  7584 solver.cpp:253]     Train net output #0: loss = 1.0905 (* 1 = 1.0905 loss)
I0527 04:14:49.415200  7584 sgd_solver.cpp:106] Iteration 318500, lr = 0.0035
I0527 04:14:59.967056  7584 solver.cpp:237] Iteration 319000, loss = 0.915648
I0527 04:14:59.967111  7584 solver.cpp:253]     Train net output #0: loss = 0.915647 (* 1 = 0.915647 loss)
I0527 04:14:59.967128  7584 sgd_solver.cpp:106] Iteration 319000, lr = 0.0035
I0527 04:15:10.514694  7584 solver.cpp:237] Iteration 319500, loss = 1.18424
I0527 04:15:10.514731  7584 solver.cpp:253]     Train net output #0: loss = 1.18424 (* 1 = 1.18424 loss)
I0527 04:15:10.514749  7584 sgd_solver.cpp:106] Iteration 319500, lr = 0.0035
I0527 04:15:21.058943  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_320000.caffemodel
I0527 04:15:21.112774  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_320000.solverstate
I0527 04:15:21.138494  7584 solver.cpp:341] Iteration 320000, Testing net (#0)
I0527 04:16:10.502005  7584 solver.cpp:409]     Test net output #0: accuracy = 0.905038
I0527 04:16:10.502189  7584 solver.cpp:409]     Test net output #1: loss = 0.300078 (* 1 = 0.300078 loss)
I0527 04:16:31.383730  7584 solver.cpp:237] Iteration 320000, loss = 1.13242
I0527 04:16:31.383791  7584 solver.cpp:253]     Train net output #0: loss = 1.13242 (* 1 = 1.13242 loss)
I0527 04:16:31.383819  7584 sgd_solver.cpp:106] Iteration 320000, lr = 0.0035
I0527 04:16:41.955967  7584 solver.cpp:237] Iteration 320500, loss = 1.20466
I0527 04:16:41.956154  7584 solver.cpp:253]     Train net output #0: loss = 1.20465 (* 1 = 1.20465 loss)
I0527 04:16:41.956172  7584 sgd_solver.cpp:106] Iteration 320500, lr = 0.0035
I0527 04:16:52.511325  7584 solver.cpp:237] Iteration 321000, loss = 1.60509
I0527 04:16:52.511363  7584 solver.cpp:253]     Train net output #0: loss = 1.60509 (* 1 = 1.60509 loss)
I0527 04:16:52.511380  7584 sgd_solver.cpp:106] Iteration 321000, lr = 0.0035
I0527 04:17:03.070683  7584 solver.cpp:237] Iteration 321500, loss = 1.33444
I0527 04:17:03.070740  7584 solver.cpp:253]     Train net output #0: loss = 1.33444 (* 1 = 1.33444 loss)
I0527 04:17:03.070758  7584 sgd_solver.cpp:106] Iteration 321500, lr = 0.0035
I0527 04:17:13.609225  7584 solver.cpp:237] Iteration 322000, loss = 0.857502
I0527 04:17:13.609392  7584 solver.cpp:253]     Train net output #0: loss = 0.857501 (* 1 = 0.857501 loss)
I0527 04:17:13.609410  7584 sgd_solver.cpp:106] Iteration 322000, lr = 0.0035
I0527 04:17:24.147851  7584 solver.cpp:237] Iteration 322500, loss = 1.35905
I0527 04:17:24.147891  7584 solver.cpp:253]     Train net output #0: loss = 1.35905 (* 1 = 1.35905 loss)
I0527 04:17:24.147907  7584 sgd_solver.cpp:106] Iteration 322500, lr = 0.0035
I0527 04:17:34.663153  7584 solver.cpp:237] Iteration 323000, loss = 1.1522
I0527 04:17:34.663210  7584 solver.cpp:253]     Train net output #0: loss = 1.1522 (* 1 = 1.1522 loss)
I0527 04:17:34.663228  7584 sgd_solver.cpp:106] Iteration 323000, lr = 0.0035
I0527 04:18:06.098217  7584 solver.cpp:237] Iteration 323500, loss = 1.22431
I0527 04:18:06.098426  7584 solver.cpp:253]     Train net output #0: loss = 1.22431 (* 1 = 1.22431 loss)
I0527 04:18:06.098444  7584 sgd_solver.cpp:106] Iteration 323500, lr = 0.0035
I0527 04:18:16.622773  7584 solver.cpp:237] Iteration 324000, loss = 1.13809
I0527 04:18:16.622825  7584 solver.cpp:253]     Train net output #0: loss = 1.13809 (* 1 = 1.13809 loss)
I0527 04:18:16.622844  7584 sgd_solver.cpp:106] Iteration 324000, lr = 0.0035
I0527 04:18:27.145508  7584 solver.cpp:237] Iteration 324500, loss = 1.23344
I0527 04:18:27.145545  7584 solver.cpp:253]     Train net output #0: loss = 1.23344 (* 1 = 1.23344 loss)
I0527 04:18:27.145562  7584 sgd_solver.cpp:106] Iteration 324500, lr = 0.0035
I0527 04:18:37.666426  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_325000.caffemodel
I0527 04:18:37.718791  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_325000.solverstate
I0527 04:18:37.751461  7584 solver.cpp:237] Iteration 325000, loss = 1.41888
I0527 04:18:37.751518  7584 solver.cpp:253]     Train net output #0: loss = 1.41888 (* 1 = 1.41888 loss)
I0527 04:18:37.751543  7584 sgd_solver.cpp:106] Iteration 325000, lr = 0.0035
I0527 04:18:48.340975  7584 solver.cpp:237] Iteration 325500, loss = 1.25357
I0527 04:18:48.341033  7584 solver.cpp:253]     Train net output #0: loss = 1.25357 (* 1 = 1.25357 loss)
I0527 04:18:48.341050  7584 sgd_solver.cpp:106] Iteration 325500, lr = 0.0035
I0527 04:18:58.956029  7584 solver.cpp:237] Iteration 326000, loss = 0.826932
I0527 04:18:58.956068  7584 solver.cpp:253]     Train net output #0: loss = 0.826931 (* 1 = 0.826931 loss)
I0527 04:18:58.956084  7584 sgd_solver.cpp:106] Iteration 326000, lr = 0.0035
I0527 04:19:09.533632  7584 solver.cpp:237] Iteration 326500, loss = 0.906315
I0527 04:19:09.533825  7584 solver.cpp:253]     Train net output #0: loss = 0.906314 (* 1 = 0.906314 loss)
I0527 04:19:09.533843  7584 sgd_solver.cpp:106] Iteration 326500, lr = 0.0035
I0527 04:19:40.949442  7584 solver.cpp:237] Iteration 327000, loss = 0.875628
I0527 04:19:40.949631  7584 solver.cpp:253]     Train net output #0: loss = 0.875628 (* 1 = 0.875628 loss)
I0527 04:19:40.949650  7584 sgd_solver.cpp:106] Iteration 327000, lr = 0.0035
I0527 04:19:51.477618  7584 solver.cpp:237] Iteration 327500, loss = 1.32115
I0527 04:19:51.477658  7584 solver.cpp:253]     Train net output #0: loss = 1.32115 (* 1 = 1.32115 loss)
I0527 04:19:51.477674  7584 sgd_solver.cpp:106] Iteration 327500, lr = 0.0035
I0527 04:20:02.066257  7584 solver.cpp:237] Iteration 328000, loss = 0.876213
I0527 04:20:02.066313  7584 solver.cpp:253]     Train net output #0: loss = 0.876213 (* 1 = 0.876213 loss)
I0527 04:20:02.066331  7584 sgd_solver.cpp:106] Iteration 328000, lr = 0.0035
I0527 04:20:12.698487  7584 solver.cpp:237] Iteration 328500, loss = 0.860374
I0527 04:20:12.698653  7584 solver.cpp:253]     Train net output #0: loss = 0.860373 (* 1 = 0.860373 loss)
I0527 04:20:12.698670  7584 sgd_solver.cpp:106] Iteration 328500, lr = 0.0035
I0527 04:20:23.313495  7584 solver.cpp:237] Iteration 329000, loss = 1.22346
I0527 04:20:23.313551  7584 solver.cpp:253]     Train net output #0: loss = 1.22346 (* 1 = 1.22346 loss)
I0527 04:20:23.313568  7584 sgd_solver.cpp:106] Iteration 329000, lr = 0.0035
I0527 04:20:33.858767  7584 solver.cpp:237] Iteration 329500, loss = 0.904885
I0527 04:20:33.858806  7584 solver.cpp:253]     Train net output #0: loss = 0.904884 (* 1 = 0.904884 loss)
I0527 04:20:33.858824  7584 sgd_solver.cpp:106] Iteration 329500, lr = 0.0035
I0527 04:20:44.378583  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_330000.caffemodel
I0527 04:20:44.434551  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_330000.solverstate
I0527 04:20:44.461904  7584 solver.cpp:341] Iteration 330000, Testing net (#0)
I0527 04:21:54.995028  7584 solver.cpp:409]     Test net output #0: accuracy = 0.905171
I0527 04:21:54.995219  7584 solver.cpp:409]     Test net output #1: loss = 0.302247 (* 1 = 0.302247 loss)
I0527 04:22:15.896031  7584 solver.cpp:237] Iteration 330000, loss = 1.18991
I0527 04:22:15.896096  7584 solver.cpp:253]     Train net output #0: loss = 1.18991 (* 1 = 1.18991 loss)
I0527 04:22:15.896126  7584 sgd_solver.cpp:106] Iteration 330000, lr = 0.0035
I0527 04:22:26.476045  7584 solver.cpp:237] Iteration 330500, loss = 1.30782
I0527 04:22:26.476227  7584 solver.cpp:253]     Train net output #0: loss = 1.30782 (* 1 = 1.30782 loss)
I0527 04:22:26.476244  7584 sgd_solver.cpp:106] Iteration 330500, lr = 0.0035
I0527 04:22:37.111542  7584 solver.cpp:237] Iteration 331000, loss = 1.29505
I0527 04:22:37.111580  7584 solver.cpp:253]     Train net output #0: loss = 1.29505 (* 1 = 1.29505 loss)
I0527 04:22:37.111598  7584 sgd_solver.cpp:106] Iteration 331000, lr = 0.0035
I0527 04:22:47.753980  7584 solver.cpp:237] Iteration 331500, loss = 0.888968
I0527 04:22:47.754019  7584 solver.cpp:253]     Train net output #0: loss = 0.888967 (* 1 = 0.888967 loss)
I0527 04:22:47.754036  7584 sgd_solver.cpp:106] Iteration 331500, lr = 0.0035
I0527 04:22:58.295400  7584 solver.cpp:237] Iteration 332000, loss = 0.940892
I0527 04:22:58.295596  7584 solver.cpp:253]     Train net output #0: loss = 0.940891 (* 1 = 0.940891 loss)
I0527 04:22:58.295614  7584 sgd_solver.cpp:106] Iteration 332000, lr = 0.0035
I0527 04:23:08.826284  7584 solver.cpp:237] Iteration 332500, loss = 1.24905
I0527 04:23:08.826324  7584 solver.cpp:253]     Train net output #0: loss = 1.24905 (* 1 = 1.24905 loss)
I0527 04:23:08.826341  7584 sgd_solver.cpp:106] Iteration 332500, lr = 0.0035
I0527 04:23:19.366531  7584 solver.cpp:237] Iteration 333000, loss = 1.2592
I0527 04:23:19.366586  7584 solver.cpp:253]     Train net output #0: loss = 1.25919 (* 1 = 1.25919 loss)
I0527 04:23:19.366605  7584 sgd_solver.cpp:106] Iteration 333000, lr = 0.0035
I0527 04:23:50.822954  7584 solver.cpp:237] Iteration 333500, loss = 1.22068
I0527 04:23:50.823144  7584 solver.cpp:253]     Train net output #0: loss = 1.22068 (* 1 = 1.22068 loss)
I0527 04:23:50.823163  7584 sgd_solver.cpp:106] Iteration 333500, lr = 0.0035
I0527 04:24:01.390133  7584 solver.cpp:237] Iteration 334000, loss = 0.922732
I0527 04:24:01.390173  7584 solver.cpp:253]     Train net output #0: loss = 0.922731 (* 1 = 0.922731 loss)
I0527 04:24:01.390190  7584 sgd_solver.cpp:106] Iteration 334000, lr = 0.0035
I0527 04:24:11.925566  7584 solver.cpp:237] Iteration 334500, loss = 1.20435
I0527 04:24:11.925621  7584 solver.cpp:253]     Train net output #0: loss = 1.20435 (* 1 = 1.20435 loss)
I0527 04:24:11.925639  7584 sgd_solver.cpp:106] Iteration 334500, lr = 0.0035
I0527 04:24:22.412932  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_335000.caffemodel
I0527 04:24:22.468935  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_335000.solverstate
I0527 04:24:22.503232  7584 solver.cpp:237] Iteration 335000, loss = 1.28649
I0527 04:24:22.503290  7584 solver.cpp:253]     Train net output #0: loss = 1.28649 (* 1 = 1.28649 loss)
I0527 04:24:22.503316  7584 sgd_solver.cpp:106] Iteration 335000, lr = 0.0035
I0527 04:24:33.026235  7584 solver.cpp:237] Iteration 335500, loss = 1.26942
I0527 04:24:33.026291  7584 solver.cpp:253]     Train net output #0: loss = 1.26942 (* 1 = 1.26942 loss)
I0527 04:24:33.026309  7584 sgd_solver.cpp:106] Iteration 335500, lr = 0.0035
I0527 04:24:43.576787  7584 solver.cpp:237] Iteration 336000, loss = 0.929123
I0527 04:24:43.576825  7584 solver.cpp:253]     Train net output #0: loss = 0.929122 (* 1 = 0.929122 loss)
I0527 04:24:43.576843  7584 sgd_solver.cpp:106] Iteration 336000, lr = 0.0035
I0527 04:24:54.129197  7584 solver.cpp:237] Iteration 336500, loss = 1.57838
I0527 04:24:54.129370  7584 solver.cpp:253]     Train net output #0: loss = 1.57838 (* 1 = 1.57838 loss)
I0527 04:24:54.129387  7584 sgd_solver.cpp:106] Iteration 336500, lr = 0.0035
I0527 04:25:25.591348  7584 solver.cpp:237] Iteration 337000, loss = 1.18892
I0527 04:25:25.591534  7584 solver.cpp:253]     Train net output #0: loss = 1.18892 (* 1 = 1.18892 loss)
I0527 04:25:25.591552  7584 sgd_solver.cpp:106] Iteration 337000, lr = 0.0035
I0527 04:25:36.140581  7584 solver.cpp:237] Iteration 337500, loss = 1.04021
I0527 04:25:36.140619  7584 solver.cpp:253]     Train net output #0: loss = 1.04021 (* 1 = 1.04021 loss)
I0527 04:25:36.140636  7584 sgd_solver.cpp:106] Iteration 337500, lr = 0.0035
I0527 04:25:46.683661  7584 solver.cpp:237] Iteration 338000, loss = 1.09704
I0527 04:25:46.683714  7584 solver.cpp:253]     Train net output #0: loss = 1.09704 (* 1 = 1.09704 loss)
I0527 04:25:46.683732  7584 sgd_solver.cpp:106] Iteration 338000, lr = 0.0035
I0527 04:25:57.282254  7584 solver.cpp:237] Iteration 338500, loss = 0.923414
I0527 04:25:57.282421  7584 solver.cpp:253]     Train net output #0: loss = 0.923413 (* 1 = 0.923413 loss)
I0527 04:25:57.282438  7584 sgd_solver.cpp:106] Iteration 338500, lr = 0.0035
I0527 04:26:07.885728  7584 solver.cpp:237] Iteration 339000, loss = 1.05211
I0527 04:26:07.885766  7584 solver.cpp:253]     Train net output #0: loss = 1.05211 (* 1 = 1.05211 loss)
I0527 04:26:07.885783  7584 sgd_solver.cpp:106] Iteration 339000, lr = 0.0035
I0527 04:26:18.414990  7584 solver.cpp:237] Iteration 339500, loss = 1.03846
I0527 04:26:18.415045  7584 solver.cpp:253]     Train net output #0: loss = 1.03846 (* 1 = 1.03846 loss)
I0527 04:26:18.415062  7584 sgd_solver.cpp:106] Iteration 339500, lr = 0.0035
I0527 04:26:28.936482  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_340000.caffemodel
I0527 04:26:28.989092  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_340000.solverstate
I0527 04:26:29.014765  7584 solver.cpp:341] Iteration 340000, Testing net (#0)
I0527 04:27:18.699184  7584 solver.cpp:409]     Test net output #0: accuracy = 0.902239
I0527 04:27:18.699373  7584 solver.cpp:409]     Test net output #1: loss = 0.304581 (* 1 = 0.304581 loss)
I0527 04:27:39.578246  7584 solver.cpp:237] Iteration 340000, loss = 0.659854
I0527 04:27:39.578311  7584 solver.cpp:253]     Train net output #0: loss = 0.659853 (* 1 = 0.659853 loss)
I0527 04:27:39.578331  7584 sgd_solver.cpp:106] Iteration 340000, lr = 0.0035
I0527 04:27:50.097105  7584 solver.cpp:237] Iteration 340500, loss = 0.633947
I0527 04:27:50.097275  7584 solver.cpp:253]     Train net output #0: loss = 0.633947 (* 1 = 0.633947 loss)
I0527 04:27:50.097293  7584 sgd_solver.cpp:106] Iteration 340500, lr = 0.0035
I0527 04:28:00.689020  7584 solver.cpp:237] Iteration 341000, loss = 1.12601
I0527 04:28:00.689077  7584 solver.cpp:253]     Train net output #0: loss = 1.12601 (* 1 = 1.12601 loss)
I0527 04:28:00.689095  7584 sgd_solver.cpp:106] Iteration 341000, lr = 0.0035
I0527 04:28:11.317689  7584 solver.cpp:237] Iteration 341500, loss = 0.934697
I0527 04:28:11.317729  7584 solver.cpp:253]     Train net output #0: loss = 0.934696 (* 1 = 0.934696 loss)
I0527 04:28:11.317746  7584 sgd_solver.cpp:106] Iteration 341500, lr = 0.0035
I0527 04:28:21.894129  7584 solver.cpp:237] Iteration 342000, loss = 0.967326
I0527 04:28:21.894323  7584 solver.cpp:253]     Train net output #0: loss = 0.967326 (* 1 = 0.967326 loss)
I0527 04:28:21.894341  7584 sgd_solver.cpp:106] Iteration 342000, lr = 0.0035
I0527 04:28:32.448274  7584 solver.cpp:237] Iteration 342500, loss = 1.01085
I0527 04:28:32.448312  7584 solver.cpp:253]     Train net output #0: loss = 1.01085 (* 1 = 1.01085 loss)
I0527 04:28:32.448329  7584 sgd_solver.cpp:106] Iteration 342500, lr = 0.0035
I0527 04:28:43.016337  7584 solver.cpp:237] Iteration 343000, loss = 0.915633
I0527 04:28:43.016384  7584 solver.cpp:253]     Train net output #0: loss = 0.915632 (* 1 = 0.915632 loss)
I0527 04:28:43.016402  7584 sgd_solver.cpp:106] Iteration 343000, lr = 0.0035
I0527 04:29:14.539453  7584 solver.cpp:237] Iteration 343500, loss = 1.17852
I0527 04:29:14.539644  7584 solver.cpp:253]     Train net output #0: loss = 1.17852 (* 1 = 1.17852 loss)
I0527 04:29:14.539660  7584 sgd_solver.cpp:106] Iteration 343500, lr = 0.0035
I0527 04:29:25.171838  7584 solver.cpp:237] Iteration 344000, loss = 1.05417
I0527 04:29:25.171876  7584 solver.cpp:253]     Train net output #0: loss = 1.05417 (* 1 = 1.05417 loss)
I0527 04:29:25.171893  7584 sgd_solver.cpp:106] Iteration 344000, lr = 0.0035
I0527 04:29:35.816975  7584 solver.cpp:237] Iteration 344500, loss = 1.07472
I0527 04:29:35.817033  7584 solver.cpp:253]     Train net output #0: loss = 1.07472 (* 1 = 1.07472 loss)
I0527 04:29:35.817050  7584 sgd_solver.cpp:106] Iteration 344500, lr = 0.0035
I0527 04:29:46.432884  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_345000.caffemodel
I0527 04:29:46.487104  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_345000.solverstate
I0527 04:29:46.519291  7584 solver.cpp:237] Iteration 345000, loss = 1.13411
I0527 04:29:46.519348  7584 solver.cpp:253]     Train net output #0: loss = 1.13411 (* 1 = 1.13411 loss)
I0527 04:29:46.519376  7584 sgd_solver.cpp:106] Iteration 345000, lr = 0.0035
I0527 04:29:57.137828  7584 solver.cpp:237] Iteration 345500, loss = 0.83191
I0527 04:29:57.137882  7584 solver.cpp:253]     Train net output #0: loss = 0.83191 (* 1 = 0.83191 loss)
I0527 04:29:57.137900  7584 sgd_solver.cpp:106] Iteration 345500, lr = 0.0035
I0527 04:30:07.676228  7584 solver.cpp:237] Iteration 346000, loss = 1.08515
I0527 04:30:07.676267  7584 solver.cpp:253]     Train net output #0: loss = 1.08515 (* 1 = 1.08515 loss)
I0527 04:30:07.676285  7584 sgd_solver.cpp:106] Iteration 346000, lr = 0.0035
I0527 04:30:18.214721  7584 solver.cpp:237] Iteration 346500, loss = 1.06746
I0527 04:30:18.214893  7584 solver.cpp:253]     Train net output #0: loss = 1.06746 (* 1 = 1.06746 loss)
I0527 04:30:18.214910  7584 sgd_solver.cpp:106] Iteration 346500, lr = 0.0035
I0527 04:30:49.629088  7584 solver.cpp:237] Iteration 347000, loss = 1.06231
I0527 04:30:49.629277  7584 solver.cpp:253]     Train net output #0: loss = 1.06231 (* 1 = 1.06231 loss)
I0527 04:30:49.629295  7584 sgd_solver.cpp:106] Iteration 347000, lr = 0.0035
I0527 04:31:00.198772  7584 solver.cpp:237] Iteration 347500, loss = 1.56702
I0527 04:31:00.198810  7584 solver.cpp:253]     Train net output #0: loss = 1.56702 (* 1 = 1.56702 loss)
I0527 04:31:00.198827  7584 sgd_solver.cpp:106] Iteration 347500, lr = 0.0035
I0527 04:31:10.760998  7584 solver.cpp:237] Iteration 348000, loss = 0.930077
I0527 04:31:10.761055  7584 solver.cpp:253]     Train net output #0: loss = 0.930077 (* 1 = 0.930077 loss)
I0527 04:31:10.761083  7584 sgd_solver.cpp:106] Iteration 348000, lr = 0.0035
I0527 04:31:21.312868  7584 solver.cpp:237] Iteration 348500, loss = 1.29257
I0527 04:31:21.313036  7584 solver.cpp:253]     Train net output #0: loss = 1.29257 (* 1 = 1.29257 loss)
I0527 04:31:21.313053  7584 sgd_solver.cpp:106] Iteration 348500, lr = 0.0035
I0527 04:31:31.869276  7584 solver.cpp:237] Iteration 349000, loss = 1.30059
I0527 04:31:31.869313  7584 solver.cpp:253]     Train net output #0: loss = 1.30059 (* 1 = 1.30059 loss)
I0527 04:31:31.869330  7584 sgd_solver.cpp:106] Iteration 349000, lr = 0.0035
I0527 04:31:42.427695  7584 solver.cpp:237] Iteration 349500, loss = 1.14393
I0527 04:31:42.427749  7584 solver.cpp:253]     Train net output #0: loss = 1.14393 (* 1 = 1.14393 loss)
I0527 04:31:42.427767  7584 sgd_solver.cpp:106] Iteration 349500, lr = 0.0035
I0527 04:31:52.960753  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_350000.caffemodel
I0527 04:31:53.014497  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_350000.solverstate
I0527 04:31:53.040082  7584 solver.cpp:341] Iteration 350000, Testing net (#0)
I0527 04:33:03.572111  7584 solver.cpp:409]     Test net output #0: accuracy = 0.903057
I0527 04:33:03.572302  7584 solver.cpp:409]     Test net output #1: loss = 0.305682 (* 1 = 0.305682 loss)
I0527 04:33:24.458961  7584 solver.cpp:237] Iteration 350000, loss = 1.2791
I0527 04:33:24.459024  7584 solver.cpp:253]     Train net output #0: loss = 1.2791 (* 1 = 1.2791 loss)
I0527 04:33:24.459044  7584 sgd_solver.cpp:106] Iteration 350000, lr = 0.0035
I0527 04:33:35.033854  7584 solver.cpp:237] Iteration 350500, loss = 0.867034
I0527 04:33:35.034026  7584 solver.cpp:253]     Train net output #0: loss = 0.867034 (* 1 = 0.867034 loss)
I0527 04:33:35.034044  7584 sgd_solver.cpp:106] Iteration 350500, lr = 0.0035
I0527 04:33:45.616722  7584 solver.cpp:237] Iteration 351000, loss = 1.2541
I0527 04:33:45.616775  7584 solver.cpp:253]     Train net output #0: loss = 1.2541 (* 1 = 1.2541 loss)
I0527 04:33:45.616793  7584 sgd_solver.cpp:106] Iteration 351000, lr = 0.0035
I0527 04:33:56.232985  7584 solver.cpp:237] Iteration 351500, loss = 0.952879
I0527 04:33:56.233023  7584 solver.cpp:253]     Train net output #0: loss = 0.952879 (* 1 = 0.952879 loss)
I0527 04:33:56.233042  7584 sgd_solver.cpp:106] Iteration 351500, lr = 0.0035
I0527 04:34:06.832207  7584 solver.cpp:237] Iteration 352000, loss = 1.31195
I0527 04:34:06.832404  7584 solver.cpp:253]     Train net output #0: loss = 1.31195 (* 1 = 1.31195 loss)
I0527 04:34:06.832422  7584 sgd_solver.cpp:106] Iteration 352000, lr = 0.0035
I0527 04:34:17.386363  7584 solver.cpp:237] Iteration 352500, loss = 1.2504
I0527 04:34:17.386400  7584 solver.cpp:253]     Train net output #0: loss = 1.2504 (* 1 = 1.2504 loss)
I0527 04:34:17.386417  7584 sgd_solver.cpp:106] Iteration 352500, lr = 0.0035
I0527 04:34:27.941268  7584 solver.cpp:237] Iteration 353000, loss = 0.80254
I0527 04:34:27.941305  7584 solver.cpp:253]     Train net output #0: loss = 0.80254 (* 1 = 0.80254 loss)
I0527 04:34:27.941323  7584 sgd_solver.cpp:106] Iteration 353000, lr = 0.0035
I0527 04:34:59.369451  7584 solver.cpp:237] Iteration 353500, loss = 1.21178
I0527 04:34:59.369644  7584 solver.cpp:253]     Train net output #0: loss = 1.21178 (* 1 = 1.21178 loss)
I0527 04:34:59.369662  7584 sgd_solver.cpp:106] Iteration 353500, lr = 0.0035
I0527 04:35:09.927008  7584 solver.cpp:237] Iteration 354000, loss = 1.14945
I0527 04:35:09.927047  7584 solver.cpp:253]     Train net output #0: loss = 1.14945 (* 1 = 1.14945 loss)
I0527 04:35:09.927064  7584 sgd_solver.cpp:106] Iteration 354000, lr = 0.0035
I0527 04:35:20.452190  7584 solver.cpp:237] Iteration 354500, loss = 1.08438
I0527 04:35:20.452229  7584 solver.cpp:253]     Train net output #0: loss = 1.08438 (* 1 = 1.08438 loss)
I0527 04:35:20.452245  7584 sgd_solver.cpp:106] Iteration 354500, lr = 0.0035
I0527 04:35:30.999866  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_355000.caffemodel
I0527 04:35:31.055833  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_355000.solverstate
I0527 04:35:31.090595  7584 solver.cpp:237] Iteration 355000, loss = 1.56618
I0527 04:35:31.090656  7584 solver.cpp:253]     Train net output #0: loss = 1.56618 (* 1 = 1.56618 loss)
I0527 04:35:31.090672  7584 sgd_solver.cpp:106] Iteration 355000, lr = 0.0035
I0527 04:35:41.649756  7584 solver.cpp:237] Iteration 355500, loss = 1.21167
I0527 04:35:41.649796  7584 solver.cpp:253]     Train net output #0: loss = 1.21167 (* 1 = 1.21167 loss)
I0527 04:35:41.649812  7584 sgd_solver.cpp:106] Iteration 355500, lr = 0.0035
I0527 04:35:52.212929  7584 solver.cpp:237] Iteration 356000, loss = 1.11801
I0527 04:35:52.212985  7584 solver.cpp:253]     Train net output #0: loss = 1.11801 (* 1 = 1.11801 loss)
I0527 04:35:52.213001  7584 sgd_solver.cpp:106] Iteration 356000, lr = 0.0035
I0527 04:36:02.747740  7584 solver.cpp:237] Iteration 356500, loss = 0.997967
I0527 04:36:02.747915  7584 solver.cpp:253]     Train net output #0: loss = 0.997967 (* 1 = 0.997967 loss)
I0527 04:36:02.747932  7584 sgd_solver.cpp:106] Iteration 356500, lr = 0.0035
I0527 04:36:34.188627  7584 solver.cpp:237] Iteration 357000, loss = 0.981158
I0527 04:36:34.188822  7584 solver.cpp:253]     Train net output #0: loss = 0.981158 (* 1 = 0.981158 loss)
I0527 04:36:34.188839  7584 sgd_solver.cpp:106] Iteration 357000, lr = 0.0035
I0527 04:36:44.724633  7584 solver.cpp:237] Iteration 357500, loss = 1.15372
I0527 04:36:44.724684  7584 solver.cpp:253]     Train net output #0: loss = 1.15372 (* 1 = 1.15372 loss)
I0527 04:36:44.724701  7584 sgd_solver.cpp:106] Iteration 357500, lr = 0.0035
I0527 04:36:55.245620  7584 solver.cpp:237] Iteration 358000, loss = 1.29966
I0527 04:36:55.245659  7584 solver.cpp:253]     Train net output #0: loss = 1.29966 (* 1 = 1.29966 loss)
I0527 04:36:55.245676  7584 sgd_solver.cpp:106] Iteration 358000, lr = 0.0035
I0527 04:37:05.773056  7584 solver.cpp:237] Iteration 358500, loss = 1.37804
I0527 04:37:05.773252  7584 solver.cpp:253]     Train net output #0: loss = 1.37804 (* 1 = 1.37804 loss)
I0527 04:37:05.773269  7584 sgd_solver.cpp:106] Iteration 358500, lr = 0.0035
I0527 04:37:16.300740  7584 solver.cpp:237] Iteration 359000, loss = 0.75583
I0527 04:37:16.300777  7584 solver.cpp:253]     Train net output #0: loss = 0.75583 (* 1 = 0.75583 loss)
I0527 04:37:16.300796  7584 sgd_solver.cpp:106] Iteration 359000, lr = 0.0035
I0527 04:37:26.840468  7584 solver.cpp:237] Iteration 359500, loss = 1.2912
I0527 04:37:26.840528  7584 solver.cpp:253]     Train net output #0: loss = 1.2912 (* 1 = 1.2912 loss)
I0527 04:37:26.840545  7584 sgd_solver.cpp:106] Iteration 359500, lr = 0.0035
I0527 04:37:37.366384  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_360000.caffemodel
I0527 04:37:37.422511  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_360000.solverstate
I0527 04:37:37.450263  7584 solver.cpp:341] Iteration 360000, Testing net (#0)
I0527 04:38:26.873258  7584 solver.cpp:409]     Test net output #0: accuracy = 0.903611
I0527 04:38:26.873450  7584 solver.cpp:409]     Test net output #1: loss = 0.305793 (* 1 = 0.305793 loss)
I0527 04:38:47.807581  7584 solver.cpp:237] Iteration 360000, loss = 1.0485
I0527 04:38:47.807644  7584 solver.cpp:253]     Train net output #0: loss = 1.0485 (* 1 = 1.0485 loss)
I0527 04:38:47.807673  7584 sgd_solver.cpp:106] Iteration 360000, lr = 0.0035
I0527 04:38:58.348268  7584 solver.cpp:237] Iteration 360500, loss = 1.17123
I0527 04:38:58.348443  7584 solver.cpp:253]     Train net output #0: loss = 1.17123 (* 1 = 1.17123 loss)
I0527 04:38:58.348459  7584 sgd_solver.cpp:106] Iteration 360500, lr = 0.0035
I0527 04:39:08.900784  7584 solver.cpp:237] Iteration 361000, loss = 1.36454
I0527 04:39:08.900838  7584 solver.cpp:253]     Train net output #0: loss = 1.36454 (* 1 = 1.36454 loss)
I0527 04:39:08.900856  7584 sgd_solver.cpp:106] Iteration 361000, lr = 0.0035
I0527 04:39:19.451037  7584 solver.cpp:237] Iteration 361500, loss = 1.59397
I0527 04:39:19.451073  7584 solver.cpp:253]     Train net output #0: loss = 1.59397 (* 1 = 1.59397 loss)
I0527 04:39:19.451092  7584 sgd_solver.cpp:106] Iteration 361500, lr = 0.0035
I0527 04:39:30.006538  7584 solver.cpp:237] Iteration 362000, loss = 1.16747
I0527 04:39:30.006711  7584 solver.cpp:253]     Train net output #0: loss = 1.16747 (* 1 = 1.16747 loss)
I0527 04:39:30.006728  7584 sgd_solver.cpp:106] Iteration 362000, lr = 0.0035
I0527 04:39:40.547742  7584 solver.cpp:237] Iteration 362500, loss = 1.19712
I0527 04:39:40.547796  7584 solver.cpp:253]     Train net output #0: loss = 1.19712 (* 1 = 1.19712 loss)
I0527 04:39:40.547812  7584 sgd_solver.cpp:106] Iteration 362500, lr = 0.0035
I0527 04:39:51.096107  7584 solver.cpp:237] Iteration 363000, loss = 1.59264
I0527 04:39:51.096144  7584 solver.cpp:253]     Train net output #0: loss = 1.59264 (* 1 = 1.59264 loss)
I0527 04:39:51.096163  7584 sgd_solver.cpp:106] Iteration 363000, lr = 0.0035
I0527 04:40:22.519821  7584 solver.cpp:237] Iteration 363500, loss = 0.803367
I0527 04:40:22.520015  7584 solver.cpp:253]     Train net output #0: loss = 0.803367 (* 1 = 0.803367 loss)
I0527 04:40:22.520031  7584 sgd_solver.cpp:106] Iteration 363500, lr = 0.0035
I0527 04:40:33.069836  7584 solver.cpp:237] Iteration 364000, loss = 0.940567
I0527 04:40:33.069875  7584 solver.cpp:253]     Train net output #0: loss = 0.940567 (* 1 = 0.940567 loss)
I0527 04:40:33.069892  7584 sgd_solver.cpp:106] Iteration 364000, lr = 0.0035
I0527 04:40:43.614948  7584 solver.cpp:237] Iteration 364500, loss = 1.71613
I0527 04:40:43.614985  7584 solver.cpp:253]     Train net output #0: loss = 1.71613 (* 1 = 1.71613 loss)
I0527 04:40:43.615002  7584 sgd_solver.cpp:106] Iteration 364500, lr = 0.0035
I0527 04:40:54.154148  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_365000.caffemodel
I0527 04:40:54.207017  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_365000.solverstate
I0527 04:40:54.239477  7584 solver.cpp:237] Iteration 365000, loss = 1.05046
I0527 04:40:54.239534  7584 solver.cpp:253]     Train net output #0: loss = 1.05046 (* 1 = 1.05046 loss)
I0527 04:40:54.239560  7584 sgd_solver.cpp:106] Iteration 365000, lr = 0.0035
I0527 04:41:04.804857  7584 solver.cpp:237] Iteration 365500, loss = 1.42235
I0527 04:41:04.804895  7584 solver.cpp:253]     Train net output #0: loss = 1.42235 (* 1 = 1.42235 loss)
I0527 04:41:04.804913  7584 sgd_solver.cpp:106] Iteration 365500, lr = 0.0035
I0527 04:41:15.366574  7584 solver.cpp:237] Iteration 366000, loss = 1.14672
I0527 04:41:15.366627  7584 solver.cpp:253]     Train net output #0: loss = 1.14672 (* 1 = 1.14672 loss)
I0527 04:41:15.366644  7584 sgd_solver.cpp:106] Iteration 366000, lr = 0.0035
I0527 04:41:25.945132  7584 solver.cpp:237] Iteration 366500, loss = 1.05562
I0527 04:41:25.945312  7584 solver.cpp:253]     Train net output #0: loss = 1.05562 (* 1 = 1.05562 loss)
I0527 04:41:25.945328  7584 sgd_solver.cpp:106] Iteration 366500, lr = 0.0035
I0527 04:41:57.402504  7584 solver.cpp:237] Iteration 367000, loss = 0.904909
I0527 04:41:57.402710  7584 solver.cpp:253]     Train net output #0: loss = 0.904909 (* 1 = 0.904909 loss)
I0527 04:41:57.402729  7584 sgd_solver.cpp:106] Iteration 367000, lr = 0.0035
I0527 04:42:07.964109  7584 solver.cpp:237] Iteration 367500, loss = 0.812294
I0527 04:42:07.964164  7584 solver.cpp:253]     Train net output #0: loss = 0.812294 (* 1 = 0.812294 loss)
I0527 04:42:07.964181  7584 sgd_solver.cpp:106] Iteration 367500, lr = 0.0035
I0527 04:42:18.500671  7584 solver.cpp:237] Iteration 368000, loss = 1.09832
I0527 04:42:18.500715  7584 solver.cpp:253]     Train net output #0: loss = 1.09832 (* 1 = 1.09832 loss)
I0527 04:42:18.500730  7584 sgd_solver.cpp:106] Iteration 368000, lr = 0.0035
I0527 04:42:29.054620  7584 solver.cpp:237] Iteration 368500, loss = 1.30969
I0527 04:42:29.054808  7584 solver.cpp:253]     Train net output #0: loss = 1.30969 (* 1 = 1.30969 loss)
I0527 04:42:29.054826  7584 sgd_solver.cpp:106] Iteration 368500, lr = 0.0035
I0527 04:42:39.621938  7584 solver.cpp:237] Iteration 369000, loss = 1.01433
I0527 04:42:39.621975  7584 solver.cpp:253]     Train net output #0: loss = 1.01433 (* 1 = 1.01433 loss)
I0527 04:42:39.621994  7584 sgd_solver.cpp:106] Iteration 369000, lr = 0.0035
I0527 04:42:50.200708  7584 solver.cpp:237] Iteration 369500, loss = 1.40383
I0527 04:42:50.200747  7584 solver.cpp:253]     Train net output #0: loss = 1.40383 (* 1 = 1.40383 loss)
I0527 04:42:50.200763  7584 sgd_solver.cpp:106] Iteration 369500, lr = 0.0035
I0527 04:43:00.705210  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_370000.caffemodel
I0527 04:43:00.758424  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_370000.solverstate
I0527 04:43:00.784257  7584 solver.cpp:341] Iteration 370000, Testing net (#0)
I0527 04:44:11.325808  7584 solver.cpp:409]     Test net output #0: accuracy = 0.90635
I0527 04:44:11.326002  7584 solver.cpp:409]     Test net output #1: loss = 0.288583 (* 1 = 0.288583 loss)
I0527 04:44:32.213407  7584 solver.cpp:237] Iteration 370000, loss = 1.09332
I0527 04:44:32.213467  7584 solver.cpp:253]     Train net output #0: loss = 1.09333 (* 1 = 1.09333 loss)
I0527 04:44:32.213493  7584 sgd_solver.cpp:106] Iteration 370000, lr = 0.0035
I0527 04:44:42.732008  7584 solver.cpp:237] Iteration 370500, loss = 1.16037
I0527 04:44:42.732193  7584 solver.cpp:253]     Train net output #0: loss = 1.16037 (* 1 = 1.16037 loss)
I0527 04:44:42.732210  7584 sgd_solver.cpp:106] Iteration 370500, lr = 0.0035
I0527 04:44:53.241672  7584 solver.cpp:237] Iteration 371000, loss = 1.39887
I0527 04:44:53.241710  7584 solver.cpp:253]     Train net output #0: loss = 1.39887 (* 1 = 1.39887 loss)
I0527 04:44:53.241727  7584 sgd_solver.cpp:106] Iteration 371000, lr = 0.0035
I0527 04:45:03.827945  7584 solver.cpp:237] Iteration 371500, loss = 1.49253
I0527 04:45:03.827999  7584 solver.cpp:253]     Train net output #0: loss = 1.49253 (* 1 = 1.49253 loss)
I0527 04:45:03.828016  7584 sgd_solver.cpp:106] Iteration 371500, lr = 0.0035
I0527 04:45:14.425577  7584 solver.cpp:237] Iteration 372000, loss = 0.993608
I0527 04:45:14.425750  7584 solver.cpp:253]     Train net output #0: loss = 0.993608 (* 1 = 0.993608 loss)
I0527 04:45:14.425766  7584 sgd_solver.cpp:106] Iteration 372000, lr = 0.0035
I0527 04:45:25.021811  7584 solver.cpp:237] Iteration 372500, loss = 1.13655
I0527 04:45:25.021865  7584 solver.cpp:253]     Train net output #0: loss = 1.13655 (* 1 = 1.13655 loss)
I0527 04:45:25.021883  7584 sgd_solver.cpp:106] Iteration 372500, lr = 0.0035
I0527 04:45:35.613379  7584 solver.cpp:237] Iteration 373000, loss = 1.17914
I0527 04:45:35.613416  7584 solver.cpp:253]     Train net output #0: loss = 1.17914 (* 1 = 1.17914 loss)
I0527 04:45:35.613435  7584 sgd_solver.cpp:106] Iteration 373000, lr = 0.0035
I0527 04:46:07.125037  7584 solver.cpp:237] Iteration 373500, loss = 0.650493
I0527 04:46:07.125236  7584 solver.cpp:253]     Train net output #0: loss = 0.650493 (* 1 = 0.650493 loss)
I0527 04:46:07.125253  7584 sgd_solver.cpp:106] Iteration 373500, lr = 0.0035
I0527 04:46:17.708863  7584 solver.cpp:237] Iteration 374000, loss = 1.08669
I0527 04:46:17.708919  7584 solver.cpp:253]     Train net output #0: loss = 1.08669 (* 1 = 1.08669 loss)
I0527 04:46:17.708936  7584 sgd_solver.cpp:106] Iteration 374000, lr = 0.0035
I0527 04:46:28.283025  7584 solver.cpp:237] Iteration 374500, loss = 0.993827
I0527 04:46:28.283063  7584 solver.cpp:253]     Train net output #0: loss = 0.993827 (* 1 = 0.993827 loss)
I0527 04:46:28.283080  7584 sgd_solver.cpp:106] Iteration 374500, lr = 0.0035
I0527 04:46:38.845551  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_375000.caffemodel
I0527 04:46:38.899521  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_375000.solverstate
I0527 04:46:38.934540  7584 solver.cpp:237] Iteration 375000, loss = 1.00481
I0527 04:46:38.934607  7584 solver.cpp:253]     Train net output #0: loss = 1.00481 (* 1 = 1.00481 loss)
I0527 04:46:38.934625  7584 sgd_solver.cpp:106] Iteration 375000, lr = 0.0035
I0527 04:46:49.534248  7584 solver.cpp:237] Iteration 375500, loss = 1.15518
I0527 04:46:49.534284  7584 solver.cpp:253]     Train net output #0: loss = 1.15518 (* 1 = 1.15518 loss)
I0527 04:46:49.534303  7584 sgd_solver.cpp:106] Iteration 375500, lr = 0.0035
I0527 04:47:00.105891  7584 solver.cpp:237] Iteration 376000, loss = 1.3374
I0527 04:47:00.105929  7584 solver.cpp:253]     Train net output #0: loss = 1.3374 (* 1 = 1.3374 loss)
I0527 04:47:00.105947  7584 sgd_solver.cpp:106] Iteration 376000, lr = 0.0035
I0527 04:47:10.698534  7584 solver.cpp:237] Iteration 376500, loss = 0.833102
I0527 04:47:10.698726  7584 solver.cpp:253]     Train net output #0: loss = 0.833102 (* 1 = 0.833102 loss)
I0527 04:47:10.698743  7584 sgd_solver.cpp:106] Iteration 376500, lr = 0.0035
I0527 04:47:42.199411  7584 solver.cpp:237] Iteration 377000, loss = 1.17884
I0527 04:47:42.199618  7584 solver.cpp:253]     Train net output #0: loss = 1.17884 (* 1 = 1.17884 loss)
I0527 04:47:42.199636  7584 sgd_solver.cpp:106] Iteration 377000, lr = 0.0035
I0527 04:47:52.797885  7584 solver.cpp:237] Iteration 377500, loss = 1.33296
I0527 04:47:52.797941  7584 solver.cpp:253]     Train net output #0: loss = 1.33296 (* 1 = 1.33296 loss)
I0527 04:47:52.797958  7584 sgd_solver.cpp:106] Iteration 377500, lr = 0.0035
I0527 04:48:03.396725  7584 solver.cpp:237] Iteration 378000, loss = 1.26984
I0527 04:48:03.396764  7584 solver.cpp:253]     Train net output #0: loss = 1.26984 (* 1 = 1.26984 loss)
I0527 04:48:03.396781  7584 sgd_solver.cpp:106] Iteration 378000, lr = 0.0035
I0527 04:48:13.988400  7584 solver.cpp:237] Iteration 378500, loss = 1.22804
I0527 04:48:13.988569  7584 solver.cpp:253]     Train net output #0: loss = 1.22804 (* 1 = 1.22804 loss)
I0527 04:48:13.988586  7584 sgd_solver.cpp:106] Iteration 378500, lr = 0.0035
I0527 04:48:24.547657  7584 solver.cpp:237] Iteration 379000, loss = 0.820177
I0527 04:48:24.547713  7584 solver.cpp:253]     Train net output #0: loss = 0.820177 (* 1 = 0.820177 loss)
I0527 04:48:24.547730  7584 sgd_solver.cpp:106] Iteration 379000, lr = 0.0035
I0527 04:48:35.121664  7584 solver.cpp:237] Iteration 379500, loss = 1.26198
I0527 04:48:35.121701  7584 solver.cpp:253]     Train net output #0: loss = 1.26198 (* 1 = 1.26198 loss)
I0527 04:48:35.121718  7584 sgd_solver.cpp:106] Iteration 379500, lr = 0.0035
I0527 04:48:45.657112  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_380000.caffemodel
I0527 04:48:45.711383  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_380000.solverstate
I0527 04:48:45.738706  7584 solver.cpp:341] Iteration 380000, Testing net (#0)
I0527 04:49:35.425814  7584 solver.cpp:409]     Test net output #0: accuracy = 0.904883
I0527 04:49:35.426012  7584 solver.cpp:409]     Test net output #1: loss = 0.305084 (* 1 = 0.305084 loss)
I0527 04:49:56.261696  7584 solver.cpp:237] Iteration 380000, loss = 1.09793
I0527 04:49:56.261766  7584 solver.cpp:253]     Train net output #0: loss = 1.09793 (* 1 = 1.09793 loss)
I0527 04:49:56.261786  7584 sgd_solver.cpp:106] Iteration 380000, lr = 0.0035
I0527 04:50:06.827865  7584 solver.cpp:237] Iteration 380500, loss = 1.21444
I0527 04:50:06.828047  7584 solver.cpp:253]     Train net output #0: loss = 1.21444 (* 1 = 1.21444 loss)
I0527 04:50:06.828063  7584 sgd_solver.cpp:106] Iteration 380500, lr = 0.0035
I0527 04:50:17.398608  7584 solver.cpp:237] Iteration 381000, loss = 1.21089
I0527 04:50:17.398646  7584 solver.cpp:253]     Train net output #0: loss = 1.21089 (* 1 = 1.21089 loss)
I0527 04:50:17.398663  7584 sgd_solver.cpp:106] Iteration 381000, lr = 0.0035
I0527 04:50:27.959926  7584 solver.cpp:237] Iteration 381500, loss = 1.10875
I0527 04:50:27.959983  7584 solver.cpp:253]     Train net output #0: loss = 1.10875 (* 1 = 1.10875 loss)
I0527 04:50:27.960001  7584 sgd_solver.cpp:106] Iteration 381500, lr = 0.0035
I0527 04:50:38.514161  7584 solver.cpp:237] Iteration 382000, loss = 1.34767
I0527 04:50:38.514339  7584 solver.cpp:253]     Train net output #0: loss = 1.34767 (* 1 = 1.34767 loss)
I0527 04:50:38.514358  7584 sgd_solver.cpp:106] Iteration 382000, lr = 0.0035
I0527 04:50:49.087760  7584 solver.cpp:237] Iteration 382500, loss = 1.03449
I0527 04:50:49.087807  7584 solver.cpp:253]     Train net output #0: loss = 1.03449 (* 1 = 1.03449 loss)
I0527 04:50:49.087826  7584 sgd_solver.cpp:106] Iteration 382500, lr = 0.0035
I0527 04:50:59.656373  7584 solver.cpp:237] Iteration 383000, loss = 1.05594
I0527 04:50:59.656409  7584 solver.cpp:253]     Train net output #0: loss = 1.05594 (* 1 = 1.05594 loss)
I0527 04:50:59.656429  7584 sgd_solver.cpp:106] Iteration 383000, lr = 0.0035
I0527 04:51:31.054852  7584 solver.cpp:237] Iteration 383500, loss = 1.20869
I0527 04:51:31.055059  7584 solver.cpp:253]     Train net output #0: loss = 1.20869 (* 1 = 1.20869 loss)
I0527 04:51:31.055078  7584 sgd_solver.cpp:106] Iteration 383500, lr = 0.0035
I0527 04:51:41.615849  7584 solver.cpp:237] Iteration 384000, loss = 1.16178
I0527 04:51:41.615903  7584 solver.cpp:253]     Train net output #0: loss = 1.16178 (* 1 = 1.16178 loss)
I0527 04:51:41.615921  7584 sgd_solver.cpp:106] Iteration 384000, lr = 0.0035
I0527 04:51:52.177476  7584 solver.cpp:237] Iteration 384500, loss = 1.25589
I0527 04:51:52.177515  7584 solver.cpp:253]     Train net output #0: loss = 1.25589 (* 1 = 1.25589 loss)
I0527 04:51:52.177532  7584 sgd_solver.cpp:106] Iteration 384500, lr = 0.0035
I0527 04:52:02.712481  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_385000.caffemodel
I0527 04:52:02.771173  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_385000.solverstate
I0527 04:52:02.805621  7584 solver.cpp:237] Iteration 385000, loss = 1.41668
I0527 04:52:02.805686  7584 solver.cpp:253]     Train net output #0: loss = 1.41668 (* 1 = 1.41668 loss)
I0527 04:52:02.805703  7584 sgd_solver.cpp:106] Iteration 385000, lr = 0.0035
I0527 04:52:13.332211  7584 solver.cpp:237] Iteration 385500, loss = 1.24481
I0527 04:52:13.332249  7584 solver.cpp:253]     Train net output #0: loss = 1.24481 (* 1 = 1.24481 loss)
I0527 04:52:13.332267  7584 sgd_solver.cpp:106] Iteration 385500, lr = 0.0035
I0527 04:52:23.856495  7584 solver.cpp:237] Iteration 386000, loss = 1.05534
I0527 04:52:23.856534  7584 solver.cpp:253]     Train net output #0: loss = 1.05534 (* 1 = 1.05534 loss)
I0527 04:52:23.856550  7584 sgd_solver.cpp:106] Iteration 386000, lr = 0.0035
I0527 04:52:34.416453  7584 solver.cpp:237] Iteration 386500, loss = 1.09089
I0527 04:52:34.416651  7584 solver.cpp:253]     Train net output #0: loss = 1.09089 (* 1 = 1.09089 loss)
I0527 04:52:34.416667  7584 sgd_solver.cpp:106] Iteration 386500, lr = 0.0035
I0527 04:53:05.895048  7584 solver.cpp:237] Iteration 387000, loss = 1.18965
I0527 04:53:05.895248  7584 solver.cpp:253]     Train net output #0: loss = 1.18965 (* 1 = 1.18965 loss)
I0527 04:53:05.895265  7584 sgd_solver.cpp:106] Iteration 387000, lr = 0.0035
I0527 04:53:16.467576  7584 solver.cpp:237] Iteration 387500, loss = 0.783275
I0527 04:53:16.467634  7584 solver.cpp:253]     Train net output #0: loss = 0.783275 (* 1 = 0.783275 loss)
I0527 04:53:16.467653  7584 sgd_solver.cpp:106] Iteration 387500, lr = 0.0035
I0527 04:53:27.043287  7584 solver.cpp:237] Iteration 388000, loss = 1.36117
I0527 04:53:27.043324  7584 solver.cpp:253]     Train net output #0: loss = 1.36117 (* 1 = 1.36117 loss)
I0527 04:53:27.043342  7584 sgd_solver.cpp:106] Iteration 388000, lr = 0.0035
I0527 04:53:37.619387  7584 solver.cpp:237] Iteration 388500, loss = 0.97846
I0527 04:53:37.619565  7584 solver.cpp:253]     Train net output #0: loss = 0.97846 (* 1 = 0.97846 loss)
I0527 04:53:37.619581  7584 sgd_solver.cpp:106] Iteration 388500, lr = 0.0035
I0527 04:53:48.194602  7584 solver.cpp:237] Iteration 389000, loss = 0.993114
I0527 04:53:48.194660  7584 solver.cpp:253]     Train net output #0: loss = 0.993114 (* 1 = 0.993114 loss)
I0527 04:53:48.194679  7584 sgd_solver.cpp:106] Iteration 389000, lr = 0.0035
I0527 04:53:58.760828  7584 solver.cpp:237] Iteration 389500, loss = 1.30299
I0527 04:53:58.760865  7584 solver.cpp:253]     Train net output #0: loss = 1.30299 (* 1 = 1.30299 loss)
I0527 04:53:58.760884  7584 sgd_solver.cpp:106] Iteration 389500, lr = 0.0035
I0527 04:54:09.317790  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_390000.caffemodel
I0527 04:54:09.377444  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_390000.solverstate
I0527 04:54:09.408926  7584 solver.cpp:341] Iteration 390000, Testing net (#0)
I0527 04:55:19.985579  7584 solver.cpp:409]     Test net output #0: accuracy = 0.904458
I0527 04:55:19.985783  7584 solver.cpp:409]     Test net output #1: loss = 0.306785 (* 1 = 0.306785 loss)
I0527 04:55:40.846586  7584 solver.cpp:237] Iteration 390000, loss = 1.14627
I0527 04:55:40.846649  7584 solver.cpp:253]     Train net output #0: loss = 1.14627 (* 1 = 1.14627 loss)
I0527 04:55:40.846668  7584 sgd_solver.cpp:106] Iteration 390000, lr = 0.0035
I0527 04:55:51.358345  7584 solver.cpp:237] Iteration 390500, loss = 1.16343
I0527 04:55:51.358542  7584 solver.cpp:253]     Train net output #0: loss = 1.16343 (* 1 = 1.16343 loss)
I0527 04:55:51.358559  7584 sgd_solver.cpp:106] Iteration 390500, lr = 0.0035
I0527 04:56:01.852529  7584 solver.cpp:237] Iteration 391000, loss = 1.13529
I0527 04:56:01.852565  7584 solver.cpp:253]     Train net output #0: loss = 1.13529 (* 1 = 1.13529 loss)
I0527 04:56:01.852583  7584 sgd_solver.cpp:106] Iteration 391000, lr = 0.0035
I0527 04:56:12.353579  7584 solver.cpp:237] Iteration 391500, loss = 1.14388
I0527 04:56:12.353632  7584 solver.cpp:253]     Train net output #0: loss = 1.14388 (* 1 = 1.14388 loss)
I0527 04:56:12.353649  7584 sgd_solver.cpp:106] Iteration 391500, lr = 0.0035
I0527 04:56:22.920656  7584 solver.cpp:237] Iteration 392000, loss = 1.20029
I0527 04:56:22.920833  7584 solver.cpp:253]     Train net output #0: loss = 1.20029 (* 1 = 1.20029 loss)
I0527 04:56:22.920850  7584 sgd_solver.cpp:106] Iteration 392000, lr = 0.0035
I0527 04:56:33.501185  7584 solver.cpp:237] Iteration 392500, loss = 0.94004
I0527 04:56:33.501224  7584 solver.cpp:253]     Train net output #0: loss = 0.94004 (* 1 = 0.94004 loss)
I0527 04:56:33.501241  7584 sgd_solver.cpp:106] Iteration 392500, lr = 0.0035
I0527 04:56:44.042333  7584 solver.cpp:237] Iteration 393000, loss = 0.883431
I0527 04:56:44.042382  7584 solver.cpp:253]     Train net output #0: loss = 0.88343 (* 1 = 0.88343 loss)
I0527 04:56:44.042399  7584 sgd_solver.cpp:106] Iteration 393000, lr = 0.0035
I0527 04:57:15.512436  7584 solver.cpp:237] Iteration 393500, loss = 1.08917
I0527 04:57:15.512639  7584 solver.cpp:253]     Train net output #0: loss = 1.08917 (* 1 = 1.08917 loss)
I0527 04:57:15.512655  7584 sgd_solver.cpp:106] Iteration 393500, lr = 0.0035
I0527 04:57:26.042392  7584 solver.cpp:237] Iteration 394000, loss = 0.836372
I0527 04:57:26.042451  7584 solver.cpp:253]     Train net output #0: loss = 0.836372 (* 1 = 0.836372 loss)
I0527 04:57:26.042480  7584 sgd_solver.cpp:106] Iteration 394000, lr = 0.0035
I0527 04:57:36.672271  7584 solver.cpp:237] Iteration 394500, loss = 0.839638
I0527 04:57:36.672310  7584 solver.cpp:253]     Train net output #0: loss = 0.839637 (* 1 = 0.839637 loss)
I0527 04:57:36.672328  7584 sgd_solver.cpp:106] Iteration 394500, lr = 0.0035
I0527 04:57:47.279605  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_395000.caffemodel
I0527 04:57:47.333127  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_395000.solverstate
I0527 04:57:47.365198  7584 solver.cpp:237] Iteration 395000, loss = 1.13828
I0527 04:57:47.365260  7584 solver.cpp:253]     Train net output #0: loss = 1.13828 (* 1 = 1.13828 loss)
I0527 04:57:47.365280  7584 sgd_solver.cpp:106] Iteration 395000, lr = 0.0035
I0527 04:57:58.003340  7584 solver.cpp:237] Iteration 395500, loss = 1.06558
I0527 04:57:58.003393  7584 solver.cpp:253]     Train net output #0: loss = 1.06558 (* 1 = 1.06558 loss)
I0527 04:57:58.003412  7584 sgd_solver.cpp:106] Iteration 395500, lr = 0.0035
I0527 04:58:08.654515  7584 solver.cpp:237] Iteration 396000, loss = 1.22425
I0527 04:58:08.654553  7584 solver.cpp:253]     Train net output #0: loss = 1.22425 (* 1 = 1.22425 loss)
I0527 04:58:08.654570  7584 sgd_solver.cpp:106] Iteration 396000, lr = 0.0035
I0527 04:58:19.283053  7584 solver.cpp:237] Iteration 396500, loss = 0.707574
I0527 04:58:19.283265  7584 solver.cpp:253]     Train net output #0: loss = 0.707573 (* 1 = 0.707573 loss)
I0527 04:58:19.283283  7584 sgd_solver.cpp:106] Iteration 396500, lr = 0.0035
I0527 04:58:50.808001  7584 solver.cpp:237] Iteration 397000, loss = 0.919433
I0527 04:58:50.808214  7584 solver.cpp:253]     Train net output #0: loss = 0.919432 (* 1 = 0.919432 loss)
I0527 04:58:50.808233  7584 sgd_solver.cpp:106] Iteration 397000, lr = 0.0035
I0527 04:59:01.446965  7584 solver.cpp:237] Iteration 397500, loss = 1.31757
I0527 04:59:01.447003  7584 solver.cpp:253]     Train net output #0: loss = 1.31757 (* 1 = 1.31757 loss)
I0527 04:59:01.447021  7584 sgd_solver.cpp:106] Iteration 397500, lr = 0.0035
I0527 04:59:12.027024  7584 solver.cpp:237] Iteration 398000, loss = 0.708265
I0527 04:59:12.027082  7584 solver.cpp:253]     Train net output #0: loss = 0.708264 (* 1 = 0.708264 loss)
I0527 04:59:12.027101  7584 sgd_solver.cpp:106] Iteration 398000, lr = 0.0035
I0527 04:59:22.577628  7584 solver.cpp:237] Iteration 398500, loss = 0.945419
I0527 04:59:22.577807  7584 solver.cpp:253]     Train net output #0: loss = 0.945419 (* 1 = 0.945419 loss)
I0527 04:59:22.577824  7584 sgd_solver.cpp:106] Iteration 398500, lr = 0.0035
I0527 04:59:33.140738  7584 solver.cpp:237] Iteration 399000, loss = 1.11787
I0527 04:59:33.140795  7584 solver.cpp:253]     Train net output #0: loss = 1.11787 (* 1 = 1.11787 loss)
I0527 04:59:33.140813  7584 sgd_solver.cpp:106] Iteration 399000, lr = 0.0035
I0527 04:59:43.694587  7584 solver.cpp:237] Iteration 399500, loss = 1.21364
I0527 04:59:43.694624  7584 solver.cpp:253]     Train net output #0: loss = 1.21364 (* 1 = 1.21364 loss)
I0527 04:59:43.694641  7584 sgd_solver.cpp:106] Iteration 399500, lr = 0.0035
I0527 04:59:54.253783  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_400000.caffemodel
I0527 04:59:54.306720  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_400000.solverstate
I0527 04:59:54.332172  7584 solver.cpp:341] Iteration 400000, Testing net (#0)
I0527 05:00:43.750247  7584 solver.cpp:409]     Test net output #0: accuracy = 0.902691
I0527 05:00:43.750450  7584 solver.cpp:409]     Test net output #1: loss = 0.294796 (* 1 = 0.294796 loss)
I0527 05:01:04.668472  7584 solver.cpp:237] Iteration 400000, loss = 1.16665
I0527 05:01:04.668531  7584 solver.cpp:253]     Train net output #0: loss = 1.16665 (* 1 = 1.16665 loss)
I0527 05:01:04.668550  7584 sgd_solver.cpp:106] Iteration 400000, lr = 0.0035
I0527 05:01:15.224037  7584 solver.cpp:237] Iteration 400500, loss = 0.506231
I0527 05:01:15.224238  7584 solver.cpp:253]     Train net output #0: loss = 0.50623 (* 1 = 0.50623 loss)
I0527 05:01:15.224256  7584 sgd_solver.cpp:106] Iteration 400500, lr = 0.0035
I0527 05:01:25.823331  7584 solver.cpp:237] Iteration 401000, loss = 0.93532
I0527 05:01:25.823369  7584 solver.cpp:253]     Train net output #0: loss = 0.93532 (* 1 = 0.93532 loss)
I0527 05:01:25.823386  7584 sgd_solver.cpp:106] Iteration 401000, lr = 0.0035
I0527 05:01:36.444072  7584 solver.cpp:237] Iteration 401500, loss = 0.983751
I0527 05:01:36.444126  7584 solver.cpp:253]     Train net output #0: loss = 0.98375 (* 1 = 0.98375 loss)
I0527 05:01:36.444144  7584 sgd_solver.cpp:106] Iteration 401500, lr = 0.0035
I0527 05:01:47.065657  7584 solver.cpp:237] Iteration 402000, loss = 1.22018
I0527 05:01:47.065839  7584 solver.cpp:253]     Train net output #0: loss = 1.22018 (* 1 = 1.22018 loss)
I0527 05:01:47.065856  7584 sgd_solver.cpp:106] Iteration 402000, lr = 0.0035
I0527 05:01:57.675182  7584 solver.cpp:237] Iteration 402500, loss = 0.908459
I0527 05:01:57.675220  7584 solver.cpp:253]     Train net output #0: loss = 0.908459 (* 1 = 0.908459 loss)
I0527 05:01:57.675237  7584 sgd_solver.cpp:106] Iteration 402500, lr = 0.0035
I0527 05:02:08.290042  7584 solver.cpp:237] Iteration 403000, loss = 0.926648
I0527 05:02:08.290097  7584 solver.cpp:253]     Train net output #0: loss = 0.926647 (* 1 = 0.926647 loss)
I0527 05:02:08.290115  7584 sgd_solver.cpp:106] Iteration 403000, lr = 0.0035
I0527 05:02:39.814393  7584 solver.cpp:237] Iteration 403500, loss = 0.910068
I0527 05:02:39.814609  7584 solver.cpp:253]     Train net output #0: loss = 0.910067 (* 1 = 0.910067 loss)
I0527 05:02:39.814626  7584 sgd_solver.cpp:106] Iteration 403500, lr = 0.0035
I0527 05:02:50.438009  7584 solver.cpp:237] Iteration 404000, loss = 1.07501
I0527 05:02:50.438047  7584 solver.cpp:253]     Train net output #0: loss = 1.07501 (* 1 = 1.07501 loss)
I0527 05:02:50.438065  7584 sgd_solver.cpp:106] Iteration 404000, lr = 0.0035
I0527 05:03:01.051252  7584 solver.cpp:237] Iteration 404500, loss = 1.0801
I0527 05:03:01.051293  7584 solver.cpp:253]     Train net output #0: loss = 1.0801 (* 1 = 1.0801 loss)
I0527 05:03:01.051313  7584 sgd_solver.cpp:106] Iteration 404500, lr = 0.0035
I0527 05:03:11.640434  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_405000.caffemodel
I0527 05:03:11.694465  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_405000.solverstate
I0527 05:03:11.728374  7584 solver.cpp:237] Iteration 405000, loss = 1.46853
I0527 05:03:11.728440  7584 solver.cpp:253]     Train net output #0: loss = 1.46853 (* 1 = 1.46853 loss)
I0527 05:03:11.728457  7584 sgd_solver.cpp:106] Iteration 405000, lr = 0.0035
I0527 05:03:22.317181  7584 solver.cpp:237] Iteration 405500, loss = 1.07841
I0527 05:03:22.317236  7584 solver.cpp:253]     Train net output #0: loss = 1.07841 (* 1 = 1.07841 loss)
I0527 05:03:22.317255  7584 sgd_solver.cpp:106] Iteration 405500, lr = 0.0035
I0527 05:03:32.879662  7584 solver.cpp:237] Iteration 406000, loss = 1.51085
I0527 05:03:32.879699  7584 solver.cpp:253]     Train net output #0: loss = 1.51085 (* 1 = 1.51085 loss)
I0527 05:03:32.879719  7584 sgd_solver.cpp:106] Iteration 406000, lr = 0.0035
I0527 05:03:43.442106  7584 solver.cpp:237] Iteration 406500, loss = 1.15662
I0527 05:03:43.442317  7584 solver.cpp:253]     Train net output #0: loss = 1.15662 (* 1 = 1.15662 loss)
I0527 05:03:43.442334  7584 sgd_solver.cpp:106] Iteration 406500, lr = 0.0035
I0527 05:04:14.887922  7584 solver.cpp:237] Iteration 407000, loss = 1.12527
I0527 05:04:14.888125  7584 solver.cpp:253]     Train net output #0: loss = 1.12527 (* 1 = 1.12527 loss)
I0527 05:04:14.888142  7584 sgd_solver.cpp:106] Iteration 407000, lr = 0.0035
I0527 05:04:25.439543  7584 solver.cpp:237] Iteration 407500, loss = 1.09353
I0527 05:04:25.439580  7584 solver.cpp:253]     Train net output #0: loss = 1.09353 (* 1 = 1.09353 loss)
I0527 05:04:25.439599  7584 sgd_solver.cpp:106] Iteration 407500, lr = 0.0035
I0527 05:04:35.979425  7584 solver.cpp:237] Iteration 408000, loss = 1.11009
I0527 05:04:35.979480  7584 solver.cpp:253]     Train net output #0: loss = 1.11009 (* 1 = 1.11009 loss)
I0527 05:04:35.979496  7584 sgd_solver.cpp:106] Iteration 408000, lr = 0.0035
I0527 05:04:46.528672  7584 solver.cpp:237] Iteration 408500, loss = 0.948899
I0527 05:04:46.528851  7584 solver.cpp:253]     Train net output #0: loss = 0.948898 (* 1 = 0.948898 loss)
I0527 05:04:46.528867  7584 sgd_solver.cpp:106] Iteration 408500, lr = 0.0035
I0527 05:04:57.079288  7584 solver.cpp:237] Iteration 409000, loss = 1.02898
I0527 05:04:57.079342  7584 solver.cpp:253]     Train net output #0: loss = 1.02898 (* 1 = 1.02898 loss)
I0527 05:04:57.079360  7584 sgd_solver.cpp:106] Iteration 409000, lr = 0.0035
I0527 05:05:07.663404  7584 solver.cpp:237] Iteration 409500, loss = 1.46725
I0527 05:05:07.663442  7584 solver.cpp:253]     Train net output #0: loss = 1.46725 (* 1 = 1.46725 loss)
I0527 05:05:07.663460  7584 sgd_solver.cpp:106] Iteration 409500, lr = 0.0035
I0527 05:05:18.216931  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_410000.caffemodel
I0527 05:05:18.275921  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_410000.solverstate
I0527 05:05:18.303139  7584 solver.cpp:341] Iteration 410000, Testing net (#0)
I0527 05:06:28.932226  7584 solver.cpp:409]     Test net output #0: accuracy = 0.904665
I0527 05:06:28.932431  7584 solver.cpp:409]     Test net output #1: loss = 0.292467 (* 1 = 0.292467 loss)
I0527 05:06:49.827476  7584 solver.cpp:237] Iteration 410000, loss = 0.829376
I0527 05:06:49.827538  7584 solver.cpp:253]     Train net output #0: loss = 0.829376 (* 1 = 0.829376 loss)
I0527 05:06:49.827558  7584 sgd_solver.cpp:106] Iteration 410000, lr = 0.0035
I0527 05:07:00.379839  7584 solver.cpp:237] Iteration 410500, loss = 1.24376
I0527 05:07:00.380024  7584 solver.cpp:253]     Train net output #0: loss = 1.24376 (* 1 = 1.24376 loss)
I0527 05:07:00.380041  7584 sgd_solver.cpp:106] Iteration 410500, lr = 0.0035
I0527 05:07:10.930661  7584 solver.cpp:237] Iteration 411000, loss = 1.1266
I0527 05:07:10.930712  7584 solver.cpp:253]     Train net output #0: loss = 1.1266 (* 1 = 1.1266 loss)
I0527 05:07:10.930732  7584 sgd_solver.cpp:106] Iteration 411000, lr = 0.0035
I0527 05:07:21.485244  7584 solver.cpp:237] Iteration 411500, loss = 1.18415
I0527 05:07:21.485280  7584 solver.cpp:253]     Train net output #0: loss = 1.18415 (* 1 = 1.18415 loss)
I0527 05:07:21.485299  7584 sgd_solver.cpp:106] Iteration 411500, lr = 0.0035
I0527 05:07:32.081794  7584 solver.cpp:237] Iteration 412000, loss = 1.12777
I0527 05:07:32.081990  7584 solver.cpp:253]     Train net output #0: loss = 1.12777 (* 1 = 1.12777 loss)
I0527 05:07:32.082008  7584 sgd_solver.cpp:106] Iteration 412000, lr = 0.0035
I0527 05:07:42.711858  7584 solver.cpp:237] Iteration 412500, loss = 0.874513
I0527 05:07:42.711897  7584 solver.cpp:253]     Train net output #0: loss = 0.874512 (* 1 = 0.874512 loss)
I0527 05:07:42.711913  7584 sgd_solver.cpp:106] Iteration 412500, lr = 0.0035
I0527 05:07:53.329102  7584 solver.cpp:237] Iteration 413000, loss = 1.3559
I0527 05:07:53.329151  7584 solver.cpp:253]     Train net output #0: loss = 1.3559 (* 1 = 1.3559 loss)
I0527 05:07:53.329169  7584 sgd_solver.cpp:106] Iteration 413000, lr = 0.0035
I0527 05:08:24.861439  7584 solver.cpp:237] Iteration 413500, loss = 1.03656
I0527 05:08:24.861641  7584 solver.cpp:253]     Train net output #0: loss = 1.03656 (* 1 = 1.03656 loss)
I0527 05:08:24.861659  7584 sgd_solver.cpp:106] Iteration 413500, lr = 0.0035
I0527 05:08:35.491305  7584 solver.cpp:237] Iteration 414000, loss = 1.12731
I0527 05:08:35.491343  7584 solver.cpp:253]     Train net output #0: loss = 1.12731 (* 1 = 1.12731 loss)
I0527 05:08:35.491360  7584 sgd_solver.cpp:106] Iteration 414000, lr = 0.0035
I0527 05:08:46.090498  7584 solver.cpp:237] Iteration 414500, loss = 1.83441
I0527 05:08:46.090556  7584 solver.cpp:253]     Train net output #0: loss = 1.83441 (* 1 = 1.83441 loss)
I0527 05:08:46.090574  7584 sgd_solver.cpp:106] Iteration 414500, lr = 0.0035
I0527 05:08:56.639267  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_415000.caffemodel
I0527 05:08:56.692039  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_415000.solverstate
I0527 05:08:56.724109  7584 solver.cpp:237] Iteration 415000, loss = 1.06162
I0527 05:08:56.724165  7584 solver.cpp:253]     Train net output #0: loss = 1.06162 (* 1 = 1.06162 loss)
I0527 05:08:56.724191  7584 sgd_solver.cpp:106] Iteration 415000, lr = 0.0035
I0527 05:09:07.296241  7584 solver.cpp:237] Iteration 415500, loss = 1.18737
I0527 05:09:07.296298  7584 solver.cpp:253]     Train net output #0: loss = 1.18737 (* 1 = 1.18737 loss)
I0527 05:09:07.296316  7584 sgd_solver.cpp:106] Iteration 415500, lr = 0.0035
I0527 05:09:17.907603  7584 solver.cpp:237] Iteration 416000, loss = 1.20786
I0527 05:09:17.907640  7584 solver.cpp:253]     Train net output #0: loss = 1.20786 (* 1 = 1.20786 loss)
I0527 05:09:17.907657  7584 sgd_solver.cpp:106] Iteration 416000, lr = 0.0035
I0527 05:09:28.522754  7584 solver.cpp:237] Iteration 416500, loss = 1.17441
I0527 05:09:28.522950  7584 solver.cpp:253]     Train net output #0: loss = 1.17441 (* 1 = 1.17441 loss)
I0527 05:09:28.522967  7584 sgd_solver.cpp:106] Iteration 416500, lr = 0.0035
I0527 05:10:00.056433  7584 solver.cpp:237] Iteration 417000, loss = 1.28804
I0527 05:10:00.056640  7584 solver.cpp:253]     Train net output #0: loss = 1.28804 (* 1 = 1.28804 loss)
I0527 05:10:00.056658  7584 sgd_solver.cpp:106] Iteration 417000, lr = 0.0035
I0527 05:10:10.678855  7584 solver.cpp:237] Iteration 417500, loss = 1.19617
I0527 05:10:10.678891  7584 solver.cpp:253]     Train net output #0: loss = 1.19617 (* 1 = 1.19617 loss)
I0527 05:10:10.678910  7584 sgd_solver.cpp:106] Iteration 417500, lr = 0.0035
I0527 05:10:21.294998  7584 solver.cpp:237] Iteration 418000, loss = 0.868477
I0527 05:10:21.295059  7584 solver.cpp:253]     Train net output #0: loss = 0.868477 (* 1 = 0.868477 loss)
I0527 05:10:21.295078  7584 sgd_solver.cpp:106] Iteration 418000, lr = 0.0035
I0527 05:10:31.854588  7584 solver.cpp:237] Iteration 418500, loss = 0.779975
I0527 05:10:31.854769  7584 solver.cpp:253]     Train net output #0: loss = 0.779975 (* 1 = 0.779975 loss)
I0527 05:10:31.854786  7584 sgd_solver.cpp:106] Iteration 418500, lr = 0.0035
I0527 05:10:42.404851  7584 solver.cpp:237] Iteration 419000, loss = 1.172
I0527 05:10:42.404891  7584 solver.cpp:253]     Train net output #0: loss = 1.172 (* 1 = 1.172 loss)
I0527 05:10:42.404907  7584 sgd_solver.cpp:106] Iteration 419000, lr = 0.0035
I0527 05:10:52.964442  7584 solver.cpp:237] Iteration 419500, loss = 1.03333
I0527 05:10:52.964491  7584 solver.cpp:253]     Train net output #0: loss = 1.03333 (* 1 = 1.03333 loss)
I0527 05:10:52.964509  7584 sgd_solver.cpp:106] Iteration 419500, lr = 0.0035
I0527 05:11:03.500396  7584 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_420000.caffemodel
I0527 05:11:03.556198  7584 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_420000.solverstate
I0527 05:11:03.582037  7584 solver.cpp:341] Iteration 420000, Testing net (#0)
I0527 05:11:53.253288  7584 solver.cpp:409]     Test net output #0: accuracy = 0.905145
I0527 05:11:53.253491  7584 solver.cpp:409]     Test net output #1: loss = 0.287908 (* 1 = 0.287908 loss)
I0527 05:12:14.149083  7584 solver.cpp:237] Iteration 420000, loss = 0.982556
I0527 05:12:14.149147  7584 solver.cpp:253]     Train net output #0: loss = 0.982555 (* 1 = 0.982555 loss)
I0527 05:12:14.149168  7584 sgd_solver.cpp:106] Iteration 420000, lr = 0.0035
I0527 05:12:24.709894  7584 solver.cpp:237] Iteration 420500, loss = 0.913709
I0527 05:12:24.710081  7584 solver.cpp:253]     Train net output #0: loss = 0.913709 (* 1 = 0.913709 loss)
I0527 05:12:24.710098  7584 sgd_solver.cpp:106] Iteration 420500, lr = 0.0035
I0527 05:12:35.264804  7584 solver.cpp:237] Iteration 421000, loss = 1.22686
I0527 05:12:35.264861  7584 solver.cpp:253]     Train net output #0: loss = 1.22686 (* 1 = 1.22686 loss)
I0527 05:12:35.264878  7584 sgd_solver.cpp:106] Iteration 421000, lr = 0.0035
I0527 05:12:45.828651  7584 solver.cpp:237] Iteration 421500, loss = 1.23504
I0527 05:12:45.828691  7584 solver.cpp:253]     Train net output #0: loss = 1.23504 (* 1 = 1.23504 loss)
I0527 05:12:45.828707  7584 sgd_solver.cpp:106] Iteration 421500, lr = 0.0035
I0527 05:12:56.375195  7584 solver.cpp:237] Iteration 422000, loss = 0.995644
I0527 05:12:56.375406  7584 solver.cpp:253]     Train net output #0: loss = 0.995643 (* 1 = 0.995643 loss)
I0527 05:12:56.375423  7584 sgd_solver.cpp:106] Iteration 422000, lr = 0.0035
I0527 05:13:06.912523  7584 solver.cpp:237] Iteration 422500, loss = 1.21515
I0527 05:13:06.912559  7584 solver.cpp:253]     Train net output #0: loss = 1.21515 (* 1 = 1.21515 loss)
I0527 05:13:06.912577  7584 sgd_solver.cpp:106] Iteration 422500, lr = 0.0035
I0527 05:13:17.464012  7584 solver.cpp:237] Iteration 423000, loss = 1.25448
I0527 05:13:17.464069  7584 solver.cpp:253]     Train net output #0: loss = 1.25448 (* 1 = 1.25448 loss)
I0527 05:13:17.464087  7584 sgd_solver.cpp:106] Iteration 423000, lr = 0.0035
I0527 05:13:48.943789  7584 solver.cpp:237] Iteration 423500, loss = 0.946447
I0527 05:13:48.943995  7584 solver.cpp:253]     Train net output #0: loss = 0.946447 (* 1 = 0.946447 loss)
I0527 05:13:48.944012  7584 sgd_solver.cpp:106] Iteration 423500, lr = 0.0035
aprun: Apid 11271488: Caught signal Terminated, sending to application
*** Aborted at 1464340429 (unix time) try "date -d @1464340429" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11271488: Caught signal Terminated, sending to application
*** SIGTERM (@0x1d9d) received by PID 7584 (TID 0x2aaac746f900) from PID 7581; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
=>> PBS: job killed: walltime 7224 exceeded limit 7200
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11271488: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11271488: Caught signal Terminated, sending to application
aprun: Apid 11271488: Caught signal Terminated, sending to application
aprun: Apid 11271488: Caught signal Terminated, sending to application
aprun: Apid 11271488: Caught signal Terminated, sending to application
aprun: Apid 11271488: Caught signal Terminated, sending to application
aprun: Apid 11271488: Caught signal Terminated, sending to application
aprun: Apid 11271488: Caught signal Terminated, sending to application
aprun: Apid 11271488: Caught signal Terminated, sending to application
