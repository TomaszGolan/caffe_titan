2813323
I0527 11:47:57.953408  5565 caffe.cpp:184] Using GPUs 0
I0527 11:47:58.382302  5565 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0035
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033.prototxt"
I0527 11:47:58.386906  5565 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033.prototxt
I0527 11:47:58.408349  5565 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0527 11:47:58.408411  5565 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0527 11:47:58.408792  5565 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 11:47:58.409001  5565 layer_factory.hpp:77] Creating layer data_hdf5
I0527 11:47:58.409031  5565 net.cpp:106] Creating Layer data_hdf5
I0527 11:47:58.409056  5565 net.cpp:411] data_hdf5 -> data
I0527 11:47:58.409090  5565 net.cpp:411] data_hdf5 -> label
I0527 11:47:58.409126  5565 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0527 11:47:58.410701  5565 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0527 11:47:58.413084  5565 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0527 11:48:19.976829  5565 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0527 11:48:19.981989  5565 net.cpp:150] Setting up data_hdf5
I0527 11:48:19.982030  5565 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 11:48:19.982048  5565 net.cpp:157] Top shape: 40 (40)
I0527 11:48:19.982060  5565 net.cpp:165] Memory required for data: 1016160
I0527 11:48:19.982079  5565 layer_factory.hpp:77] Creating layer conv1
I0527 11:48:19.982125  5565 net.cpp:106] Creating Layer conv1
I0527 11:48:19.982139  5565 net.cpp:454] conv1 <- data
I0527 11:48:19.982164  5565 net.cpp:411] conv1 -> conv1
I0527 11:48:20.347314  5565 net.cpp:150] Setting up conv1
I0527 11:48:20.347365  5565 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 11:48:20.347380  5565 net.cpp:165] Memory required for data: 12075360
I0527 11:48:20.347410  5565 layer_factory.hpp:77] Creating layer relu1
I0527 11:48:20.347434  5565 net.cpp:106] Creating Layer relu1
I0527 11:48:20.347453  5565 net.cpp:454] relu1 <- conv1
I0527 11:48:20.347489  5565 net.cpp:397] relu1 -> conv1 (in-place)
I0527 11:48:20.348023  5565 net.cpp:150] Setting up relu1
I0527 11:48:20.348047  5565 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 11:48:20.348060  5565 net.cpp:165] Memory required for data: 23134560
I0527 11:48:20.348076  5565 layer_factory.hpp:77] Creating layer pool1
I0527 11:48:20.348104  5565 net.cpp:106] Creating Layer pool1
I0527 11:48:20.348117  5565 net.cpp:454] pool1 <- conv1
I0527 11:48:20.348134  5565 net.cpp:411] pool1 -> pool1
I0527 11:48:20.348228  5565 net.cpp:150] Setting up pool1
I0527 11:48:20.348247  5565 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 11:48:20.348260  5565 net.cpp:165] Memory required for data: 28664160
I0527 11:48:20.348281  5565 layer_factory.hpp:77] Creating layer conv2
I0527 11:48:20.348305  5565 net.cpp:106] Creating Layer conv2
I0527 11:48:20.348320  5565 net.cpp:454] conv2 <- pool1
I0527 11:48:20.348335  5565 net.cpp:411] conv2 -> conv2
I0527 11:48:20.351027  5565 net.cpp:150] Setting up conv2
I0527 11:48:20.351061  5565 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 11:48:20.351076  5565 net.cpp:165] Memory required for data: 36612960
I0527 11:48:20.351104  5565 layer_factory.hpp:77] Creating layer relu2
I0527 11:48:20.351132  5565 net.cpp:106] Creating Layer relu2
I0527 11:48:20.351146  5565 net.cpp:454] relu2 <- conv2
I0527 11:48:20.351163  5565 net.cpp:397] relu2 -> conv2 (in-place)
I0527 11:48:20.351516  5565 net.cpp:150] Setting up relu2
I0527 11:48:20.351537  5565 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 11:48:20.351550  5565 net.cpp:165] Memory required for data: 44561760
I0527 11:48:20.351562  5565 layer_factory.hpp:77] Creating layer pool2
I0527 11:48:20.351588  5565 net.cpp:106] Creating Layer pool2
I0527 11:48:20.351600  5565 net.cpp:454] pool2 <- conv2
I0527 11:48:20.351616  5565 net.cpp:411] pool2 -> pool2
I0527 11:48:20.351713  5565 net.cpp:150] Setting up pool2
I0527 11:48:20.351730  5565 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 11:48:20.351745  5565 net.cpp:165] Memory required for data: 48536160
I0527 11:48:20.351764  5565 layer_factory.hpp:77] Creating layer conv3
I0527 11:48:20.351784  5565 net.cpp:106] Creating Layer conv3
I0527 11:48:20.351799  5565 net.cpp:454] conv3 <- pool2
I0527 11:48:20.351815  5565 net.cpp:411] conv3 -> conv3
I0527 11:48:20.353806  5565 net.cpp:150] Setting up conv3
I0527 11:48:20.353829  5565 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 11:48:20.353849  5565 net.cpp:165] Memory required for data: 52872800
I0527 11:48:20.353873  5565 layer_factory.hpp:77] Creating layer relu3
I0527 11:48:20.353894  5565 net.cpp:106] Creating Layer relu3
I0527 11:48:20.353917  5565 net.cpp:454] relu3 <- conv3
I0527 11:48:20.353934  5565 net.cpp:397] relu3 -> conv3 (in-place)
I0527 11:48:20.354423  5565 net.cpp:150] Setting up relu3
I0527 11:48:20.354447  5565 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 11:48:20.354460  5565 net.cpp:165] Memory required for data: 57209440
I0527 11:48:20.354476  5565 layer_factory.hpp:77] Creating layer pool3
I0527 11:48:20.354491  5565 net.cpp:106] Creating Layer pool3
I0527 11:48:20.354513  5565 net.cpp:454] pool3 <- conv3
I0527 11:48:20.354529  5565 net.cpp:411] pool3 -> pool3
I0527 11:48:20.354612  5565 net.cpp:150] Setting up pool3
I0527 11:48:20.354635  5565 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 11:48:20.354647  5565 net.cpp:165] Memory required for data: 59377760
I0527 11:48:20.354662  5565 layer_factory.hpp:77] Creating layer conv4
I0527 11:48:20.354688  5565 net.cpp:106] Creating Layer conv4
I0527 11:48:20.354701  5565 net.cpp:454] conv4 <- pool3
I0527 11:48:20.354718  5565 net.cpp:411] conv4 -> conv4
I0527 11:48:20.357497  5565 net.cpp:150] Setting up conv4
I0527 11:48:20.357533  5565 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 11:48:20.357547  5565 net.cpp:165] Memory required for data: 60829280
I0527 11:48:20.357570  5565 layer_factory.hpp:77] Creating layer relu4
I0527 11:48:20.357599  5565 net.cpp:106] Creating Layer relu4
I0527 11:48:20.357612  5565 net.cpp:454] relu4 <- conv4
I0527 11:48:20.357628  5565 net.cpp:397] relu4 -> conv4 (in-place)
I0527 11:48:20.358129  5565 net.cpp:150] Setting up relu4
I0527 11:48:20.358152  5565 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 11:48:20.358165  5565 net.cpp:165] Memory required for data: 62280800
I0527 11:48:20.358181  5565 layer_factory.hpp:77] Creating layer pool4
I0527 11:48:20.358206  5565 net.cpp:106] Creating Layer pool4
I0527 11:48:20.358218  5565 net.cpp:454] pool4 <- conv4
I0527 11:48:20.358234  5565 net.cpp:411] pool4 -> pool4
I0527 11:48:20.358317  5565 net.cpp:150] Setting up pool4
I0527 11:48:20.358340  5565 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 11:48:20.358355  5565 net.cpp:165] Memory required for data: 63006560
I0527 11:48:20.358369  5565 layer_factory.hpp:77] Creating layer ip1
I0527 11:48:20.358397  5565 net.cpp:106] Creating Layer ip1
I0527 11:48:20.358412  5565 net.cpp:454] ip1 <- pool4
I0527 11:48:20.358427  5565 net.cpp:411] ip1 -> ip1
I0527 11:48:20.373908  5565 net.cpp:150] Setting up ip1
I0527 11:48:20.373941  5565 net.cpp:157] Top shape: 40 196 (7840)
I0527 11:48:20.373958  5565 net.cpp:165] Memory required for data: 63037920
I0527 11:48:20.373988  5565 layer_factory.hpp:77] Creating layer relu5
I0527 11:48:20.374017  5565 net.cpp:106] Creating Layer relu5
I0527 11:48:20.374032  5565 net.cpp:454] relu5 <- ip1
I0527 11:48:20.374047  5565 net.cpp:397] relu5 -> ip1 (in-place)
I0527 11:48:20.374411  5565 net.cpp:150] Setting up relu5
I0527 11:48:20.374431  5565 net.cpp:157] Top shape: 40 196 (7840)
I0527 11:48:20.374444  5565 net.cpp:165] Memory required for data: 63069280
I0527 11:48:20.374456  5565 layer_factory.hpp:77] Creating layer drop1
I0527 11:48:20.374491  5565 net.cpp:106] Creating Layer drop1
I0527 11:48:20.374505  5565 net.cpp:454] drop1 <- ip1
I0527 11:48:20.374521  5565 net.cpp:397] drop1 -> ip1 (in-place)
I0527 11:48:20.374593  5565 net.cpp:150] Setting up drop1
I0527 11:48:20.374619  5565 net.cpp:157] Top shape: 40 196 (7840)
I0527 11:48:20.374632  5565 net.cpp:165] Memory required for data: 63100640
I0527 11:48:20.374649  5565 layer_factory.hpp:77] Creating layer ip2
I0527 11:48:20.374676  5565 net.cpp:106] Creating Layer ip2
I0527 11:48:20.374689  5565 net.cpp:454] ip2 <- ip1
I0527 11:48:20.374706  5565 net.cpp:411] ip2 -> ip2
I0527 11:48:20.375195  5565 net.cpp:150] Setting up ip2
I0527 11:48:20.375214  5565 net.cpp:157] Top shape: 40 98 (3920)
I0527 11:48:20.375227  5565 net.cpp:165] Memory required for data: 63116320
I0527 11:48:20.375248  5565 layer_factory.hpp:77] Creating layer relu6
I0527 11:48:20.375270  5565 net.cpp:106] Creating Layer relu6
I0527 11:48:20.375284  5565 net.cpp:454] relu6 <- ip2
I0527 11:48:20.375299  5565 net.cpp:397] relu6 -> ip2 (in-place)
I0527 11:48:20.375851  5565 net.cpp:150] Setting up relu6
I0527 11:48:20.375874  5565 net.cpp:157] Top shape: 40 98 (3920)
I0527 11:48:20.375887  5565 net.cpp:165] Memory required for data: 63132000
I0527 11:48:20.375905  5565 layer_factory.hpp:77] Creating layer drop2
I0527 11:48:20.375919  5565 net.cpp:106] Creating Layer drop2
I0527 11:48:20.375941  5565 net.cpp:454] drop2 <- ip2
I0527 11:48:20.375957  5565 net.cpp:397] drop2 -> ip2 (in-place)
I0527 11:48:20.376006  5565 net.cpp:150] Setting up drop2
I0527 11:48:20.376029  5565 net.cpp:157] Top shape: 40 98 (3920)
I0527 11:48:20.376042  5565 net.cpp:165] Memory required for data: 63147680
I0527 11:48:20.376056  5565 layer_factory.hpp:77] Creating layer ip3
I0527 11:48:20.376072  5565 net.cpp:106] Creating Layer ip3
I0527 11:48:20.376087  5565 net.cpp:454] ip3 <- ip2
I0527 11:48:20.376108  5565 net.cpp:411] ip3 -> ip3
I0527 11:48:20.376337  5565 net.cpp:150] Setting up ip3
I0527 11:48:20.376354  5565 net.cpp:157] Top shape: 40 11 (440)
I0527 11:48:20.376368  5565 net.cpp:165] Memory required for data: 63149440
I0527 11:48:20.376389  5565 layer_factory.hpp:77] Creating layer drop3
I0527 11:48:20.376410  5565 net.cpp:106] Creating Layer drop3
I0527 11:48:20.376423  5565 net.cpp:454] drop3 <- ip3
I0527 11:48:20.376440  5565 net.cpp:397] drop3 -> ip3 (in-place)
I0527 11:48:20.376487  5565 net.cpp:150] Setting up drop3
I0527 11:48:20.376508  5565 net.cpp:157] Top shape: 40 11 (440)
I0527 11:48:20.376520  5565 net.cpp:165] Memory required for data: 63151200
I0527 11:48:20.376539  5565 layer_factory.hpp:77] Creating layer loss
I0527 11:48:20.376560  5565 net.cpp:106] Creating Layer loss
I0527 11:48:20.376575  5565 net.cpp:454] loss <- ip3
I0527 11:48:20.376590  5565 net.cpp:454] loss <- label
I0527 11:48:20.376611  5565 net.cpp:411] loss -> loss
I0527 11:48:20.376631  5565 layer_factory.hpp:77] Creating layer loss
I0527 11:48:20.377300  5565 net.cpp:150] Setting up loss
I0527 11:48:20.377321  5565 net.cpp:157] Top shape: (1)
I0527 11:48:20.377337  5565 net.cpp:160]     with loss weight 1
I0527 11:48:20.377385  5565 net.cpp:165] Memory required for data: 63151204
I0527 11:48:20.377408  5565 net.cpp:226] loss needs backward computation.
I0527 11:48:20.377421  5565 net.cpp:226] drop3 needs backward computation.
I0527 11:48:20.377434  5565 net.cpp:226] ip3 needs backward computation.
I0527 11:48:20.377447  5565 net.cpp:226] drop2 needs backward computation.
I0527 11:48:20.377460  5565 net.cpp:226] relu6 needs backward computation.
I0527 11:48:20.377475  5565 net.cpp:226] ip2 needs backward computation.
I0527 11:48:20.377486  5565 net.cpp:226] drop1 needs backward computation.
I0527 11:48:20.377506  5565 net.cpp:226] relu5 needs backward computation.
I0527 11:48:20.377519  5565 net.cpp:226] ip1 needs backward computation.
I0527 11:48:20.377534  5565 net.cpp:226] pool4 needs backward computation.
I0527 11:48:20.377547  5565 net.cpp:226] relu4 needs backward computation.
I0527 11:48:20.377559  5565 net.cpp:226] conv4 needs backward computation.
I0527 11:48:20.377573  5565 net.cpp:226] pool3 needs backward computation.
I0527 11:48:20.377588  5565 net.cpp:226] relu3 needs backward computation.
I0527 11:48:20.377609  5565 net.cpp:226] conv3 needs backward computation.
I0527 11:48:20.377631  5565 net.cpp:226] pool2 needs backward computation.
I0527 11:48:20.377645  5565 net.cpp:226] relu2 needs backward computation.
I0527 11:48:20.377657  5565 net.cpp:226] conv2 needs backward computation.
I0527 11:48:20.377671  5565 net.cpp:226] pool1 needs backward computation.
I0527 11:48:20.377686  5565 net.cpp:226] relu1 needs backward computation.
I0527 11:48:20.377706  5565 net.cpp:226] conv1 needs backward computation.
I0527 11:48:20.377718  5565 net.cpp:228] data_hdf5 does not need backward computation.
I0527 11:48:20.377732  5565 net.cpp:270] This network produces output loss
I0527 11:48:20.377758  5565 net.cpp:283] Network initialization done.
I0527 11:48:20.379420  5565 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033.prototxt
I0527 11:48:20.379498  5565 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0527 11:48:20.379878  5565 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 11:48:20.380098  5565 layer_factory.hpp:77] Creating layer data_hdf5
I0527 11:48:20.380117  5565 net.cpp:106] Creating Layer data_hdf5
I0527 11:48:20.380138  5565 net.cpp:411] data_hdf5 -> data
I0527 11:48:20.380157  5565 net.cpp:411] data_hdf5 -> label
I0527 11:48:20.380178  5565 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0527 11:48:20.381408  5565 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0527 11:48:41.706939  5565 net.cpp:150] Setting up data_hdf5
I0527 11:48:41.707111  5565 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 11:48:41.707137  5565 net.cpp:157] Top shape: 40 (40)
I0527 11:48:41.707150  5565 net.cpp:165] Memory required for data: 1016160
I0527 11:48:41.707165  5565 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0527 11:48:41.707193  5565 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0527 11:48:41.707206  5565 net.cpp:454] label_data_hdf5_1_split <- label
I0527 11:48:41.707248  5565 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0527 11:48:41.707270  5565 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0527 11:48:41.707347  5565 net.cpp:150] Setting up label_data_hdf5_1_split
I0527 11:48:41.707367  5565 net.cpp:157] Top shape: 40 (40)
I0527 11:48:41.707389  5565 net.cpp:157] Top shape: 40 (40)
I0527 11:48:41.707402  5565 net.cpp:165] Memory required for data: 1016480
I0527 11:48:41.707415  5565 layer_factory.hpp:77] Creating layer conv1
I0527 11:48:41.707442  5565 net.cpp:106] Creating Layer conv1
I0527 11:48:41.707453  5565 net.cpp:454] conv1 <- data
I0527 11:48:41.707480  5565 net.cpp:411] conv1 -> conv1
I0527 11:48:41.709529  5565 net.cpp:150] Setting up conv1
I0527 11:48:41.709555  5565 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 11:48:41.709575  5565 net.cpp:165] Memory required for data: 12075680
I0527 11:48:41.709599  5565 layer_factory.hpp:77] Creating layer relu1
I0527 11:48:41.709620  5565 net.cpp:106] Creating Layer relu1
I0527 11:48:41.709642  5565 net.cpp:454] relu1 <- conv1
I0527 11:48:41.709659  5565 net.cpp:397] relu1 -> conv1 (in-place)
I0527 11:48:41.710173  5565 net.cpp:150] Setting up relu1
I0527 11:48:41.710196  5565 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 11:48:41.710209  5565 net.cpp:165] Memory required for data: 23134880
I0527 11:48:41.710222  5565 layer_factory.hpp:77] Creating layer pool1
I0527 11:48:41.710253  5565 net.cpp:106] Creating Layer pool1
I0527 11:48:41.710266  5565 net.cpp:454] pool1 <- conv1
I0527 11:48:41.710283  5565 net.cpp:411] pool1 -> pool1
I0527 11:48:41.710371  5565 net.cpp:150] Setting up pool1
I0527 11:48:41.710388  5565 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 11:48:41.710403  5565 net.cpp:165] Memory required for data: 28664480
I0527 11:48:41.710422  5565 layer_factory.hpp:77] Creating layer conv2
I0527 11:48:41.710443  5565 net.cpp:106] Creating Layer conv2
I0527 11:48:41.710455  5565 net.cpp:454] conv2 <- pool1
I0527 11:48:41.710472  5565 net.cpp:411] conv2 -> conv2
I0527 11:48:41.712426  5565 net.cpp:150] Setting up conv2
I0527 11:48:41.712451  5565 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 11:48:41.712472  5565 net.cpp:165] Memory required for data: 36613280
I0527 11:48:41.712494  5565 layer_factory.hpp:77] Creating layer relu2
I0527 11:48:41.712514  5565 net.cpp:106] Creating Layer relu2
I0527 11:48:41.712537  5565 net.cpp:454] relu2 <- conv2
I0527 11:48:41.712553  5565 net.cpp:397] relu2 -> conv2 (in-place)
I0527 11:48:41.712901  5565 net.cpp:150] Setting up relu2
I0527 11:48:41.712921  5565 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 11:48:41.712934  5565 net.cpp:165] Memory required for data: 44562080
I0527 11:48:41.712949  5565 layer_factory.hpp:77] Creating layer pool2
I0527 11:48:41.712972  5565 net.cpp:106] Creating Layer pool2
I0527 11:48:41.712985  5565 net.cpp:454] pool2 <- conv2
I0527 11:48:41.713001  5565 net.cpp:411] pool2 -> pool2
I0527 11:48:41.713088  5565 net.cpp:150] Setting up pool2
I0527 11:48:41.713111  5565 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 11:48:41.713124  5565 net.cpp:165] Memory required for data: 48536480
I0527 11:48:41.713138  5565 layer_factory.hpp:77] Creating layer conv3
I0527 11:48:41.713166  5565 net.cpp:106] Creating Layer conv3
I0527 11:48:41.713181  5565 net.cpp:454] conv3 <- pool2
I0527 11:48:41.713196  5565 net.cpp:411] conv3 -> conv3
I0527 11:48:41.715204  5565 net.cpp:150] Setting up conv3
I0527 11:48:41.715229  5565 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 11:48:41.715242  5565 net.cpp:165] Memory required for data: 52873120
I0527 11:48:41.715281  5565 layer_factory.hpp:77] Creating layer relu3
I0527 11:48:41.715308  5565 net.cpp:106] Creating Layer relu3
I0527 11:48:41.715322  5565 net.cpp:454] relu3 <- conv3
I0527 11:48:41.715344  5565 net.cpp:397] relu3 -> conv3 (in-place)
I0527 11:48:41.715845  5565 net.cpp:150] Setting up relu3
I0527 11:48:41.715868  5565 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 11:48:41.715881  5565 net.cpp:165] Memory required for data: 57209760
I0527 11:48:41.715898  5565 layer_factory.hpp:77] Creating layer pool3
I0527 11:48:41.715922  5565 net.cpp:106] Creating Layer pool3
I0527 11:48:41.715936  5565 net.cpp:454] pool3 <- conv3
I0527 11:48:41.715951  5565 net.cpp:411] pool3 -> pool3
I0527 11:48:41.716037  5565 net.cpp:150] Setting up pool3
I0527 11:48:41.716055  5565 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 11:48:41.716070  5565 net.cpp:165] Memory required for data: 59378080
I0527 11:48:41.716083  5565 layer_factory.hpp:77] Creating layer conv4
I0527 11:48:41.716111  5565 net.cpp:106] Creating Layer conv4
I0527 11:48:41.716132  5565 net.cpp:454] conv4 <- pool3
I0527 11:48:41.716150  5565 net.cpp:411] conv4 -> conv4
I0527 11:48:41.718233  5565 net.cpp:150] Setting up conv4
I0527 11:48:41.718257  5565 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 11:48:41.718277  5565 net.cpp:165] Memory required for data: 60829600
I0527 11:48:41.718297  5565 layer_factory.hpp:77] Creating layer relu4
I0527 11:48:41.718317  5565 net.cpp:106] Creating Layer relu4
I0527 11:48:41.718328  5565 net.cpp:454] relu4 <- conv4
I0527 11:48:41.718354  5565 net.cpp:397] relu4 -> conv4 (in-place)
I0527 11:48:41.718848  5565 net.cpp:150] Setting up relu4
I0527 11:48:41.718871  5565 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 11:48:41.718884  5565 net.cpp:165] Memory required for data: 62281120
I0527 11:48:41.718896  5565 layer_factory.hpp:77] Creating layer pool4
I0527 11:48:41.718916  5565 net.cpp:106] Creating Layer pool4
I0527 11:48:41.718930  5565 net.cpp:454] pool4 <- conv4
I0527 11:48:41.718955  5565 net.cpp:411] pool4 -> pool4
I0527 11:48:41.719036  5565 net.cpp:150] Setting up pool4
I0527 11:48:41.719065  5565 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 11:48:41.719079  5565 net.cpp:165] Memory required for data: 63006880
I0527 11:48:41.719094  5565 layer_factory.hpp:77] Creating layer ip1
I0527 11:48:41.719111  5565 net.cpp:106] Creating Layer ip1
I0527 11:48:41.719125  5565 net.cpp:454] ip1 <- pool4
I0527 11:48:41.719148  5565 net.cpp:411] ip1 -> ip1
I0527 11:48:41.734532  5565 net.cpp:150] Setting up ip1
I0527 11:48:41.734565  5565 net.cpp:157] Top shape: 40 196 (7840)
I0527 11:48:41.734586  5565 net.cpp:165] Memory required for data: 63038240
I0527 11:48:41.734612  5565 layer_factory.hpp:77] Creating layer relu5
I0527 11:48:41.734634  5565 net.cpp:106] Creating Layer relu5
I0527 11:48:41.734647  5565 net.cpp:454] relu5 <- ip1
I0527 11:48:41.734676  5565 net.cpp:397] relu5 -> ip1 (in-place)
I0527 11:48:41.735046  5565 net.cpp:150] Setting up relu5
I0527 11:48:41.735067  5565 net.cpp:157] Top shape: 40 196 (7840)
I0527 11:48:41.735081  5565 net.cpp:165] Memory required for data: 63069600
I0527 11:48:41.735096  5565 layer_factory.hpp:77] Creating layer drop1
I0527 11:48:41.735126  5565 net.cpp:106] Creating Layer drop1
I0527 11:48:41.735139  5565 net.cpp:454] drop1 <- ip1
I0527 11:48:41.735155  5565 net.cpp:397] drop1 -> ip1 (in-place)
I0527 11:48:41.735215  5565 net.cpp:150] Setting up drop1
I0527 11:48:41.735230  5565 net.cpp:157] Top shape: 40 196 (7840)
I0527 11:48:41.735244  5565 net.cpp:165] Memory required for data: 63100960
I0527 11:48:41.735255  5565 layer_factory.hpp:77] Creating layer ip2
I0527 11:48:41.735275  5565 net.cpp:106] Creating Layer ip2
I0527 11:48:41.735287  5565 net.cpp:454] ip2 <- ip1
I0527 11:48:41.735311  5565 net.cpp:411] ip2 -> ip2
I0527 11:48:41.735808  5565 net.cpp:150] Setting up ip2
I0527 11:48:41.735828  5565 net.cpp:157] Top shape: 40 98 (3920)
I0527 11:48:41.735841  5565 net.cpp:165] Memory required for data: 63116640
I0527 11:48:41.735862  5565 layer_factory.hpp:77] Creating layer relu6
I0527 11:48:41.735896  5565 net.cpp:106] Creating Layer relu6
I0527 11:48:41.735910  5565 net.cpp:454] relu6 <- ip2
I0527 11:48:41.735926  5565 net.cpp:397] relu6 -> ip2 (in-place)
I0527 11:48:41.736491  5565 net.cpp:150] Setting up relu6
I0527 11:48:41.736515  5565 net.cpp:157] Top shape: 40 98 (3920)
I0527 11:48:41.736527  5565 net.cpp:165] Memory required for data: 63132320
I0527 11:48:41.736539  5565 layer_factory.hpp:77] Creating layer drop2
I0527 11:48:41.736559  5565 net.cpp:106] Creating Layer drop2
I0527 11:48:41.736580  5565 net.cpp:454] drop2 <- ip2
I0527 11:48:41.736598  5565 net.cpp:397] drop2 -> ip2 (in-place)
I0527 11:48:41.736649  5565 net.cpp:150] Setting up drop2
I0527 11:48:41.736671  5565 net.cpp:157] Top shape: 40 98 (3920)
I0527 11:48:41.736685  5565 net.cpp:165] Memory required for data: 63148000
I0527 11:48:41.736698  5565 layer_factory.hpp:77] Creating layer ip3
I0527 11:48:41.736714  5565 net.cpp:106] Creating Layer ip3
I0527 11:48:41.736729  5565 net.cpp:454] ip3 <- ip2
I0527 11:48:41.736752  5565 net.cpp:411] ip3 -> ip3
I0527 11:48:41.736994  5565 net.cpp:150] Setting up ip3
I0527 11:48:41.737012  5565 net.cpp:157] Top shape: 40 11 (440)
I0527 11:48:41.737025  5565 net.cpp:165] Memory required for data: 63149760
I0527 11:48:41.737046  5565 layer_factory.hpp:77] Creating layer drop3
I0527 11:48:41.737068  5565 net.cpp:106] Creating Layer drop3
I0527 11:48:41.737082  5565 net.cpp:454] drop3 <- ip3
I0527 11:48:41.737097  5565 net.cpp:397] drop3 -> ip3 (in-place)
I0527 11:48:41.737152  5565 net.cpp:150] Setting up drop3
I0527 11:48:41.737169  5565 net.cpp:157] Top shape: 40 11 (440)
I0527 11:48:41.737180  5565 net.cpp:165] Memory required for data: 63151520
I0527 11:48:41.737192  5565 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0527 11:48:41.737208  5565 net.cpp:106] Creating Layer ip3_drop3_0_split
I0527 11:48:41.737223  5565 net.cpp:454] ip3_drop3_0_split <- ip3
I0527 11:48:41.737246  5565 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0527 11:48:41.737265  5565 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0527 11:48:41.737355  5565 net.cpp:150] Setting up ip3_drop3_0_split
I0527 11:48:41.737380  5565 net.cpp:157] Top shape: 40 11 (440)
I0527 11:48:41.737396  5565 net.cpp:157] Top shape: 40 11 (440)
I0527 11:48:41.737409  5565 net.cpp:165] Memory required for data: 63155040
I0527 11:48:41.737421  5565 layer_factory.hpp:77] Creating layer accuracy
I0527 11:48:41.737450  5565 net.cpp:106] Creating Layer accuracy
I0527 11:48:41.737464  5565 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0527 11:48:41.737478  5565 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0527 11:48:41.737498  5565 net.cpp:411] accuracy -> accuracy
I0527 11:48:41.737529  5565 net.cpp:150] Setting up accuracy
I0527 11:48:41.737545  5565 net.cpp:157] Top shape: (1)
I0527 11:48:41.737563  5565 net.cpp:165] Memory required for data: 63155044
I0527 11:48:41.737576  5565 layer_factory.hpp:77] Creating layer loss
I0527 11:48:41.737592  5565 net.cpp:106] Creating Layer loss
I0527 11:48:41.737607  5565 net.cpp:454] loss <- ip3_drop3_0_split_1
I0527 11:48:41.737627  5565 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0527 11:48:41.737643  5565 net.cpp:411] loss -> loss
I0527 11:48:41.737665  5565 layer_factory.hpp:77] Creating layer loss
I0527 11:48:41.738183  5565 net.cpp:150] Setting up loss
I0527 11:48:41.738203  5565 net.cpp:157] Top shape: (1)
I0527 11:48:41.738215  5565 net.cpp:160]     with loss weight 1
I0527 11:48:41.738240  5565 net.cpp:165] Memory required for data: 63155048
I0527 11:48:41.738258  5565 net.cpp:226] loss needs backward computation.
I0527 11:48:41.738273  5565 net.cpp:228] accuracy does not need backward computation.
I0527 11:48:41.738287  5565 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0527 11:48:41.738301  5565 net.cpp:226] drop3 needs backward computation.
I0527 11:48:41.738312  5565 net.cpp:226] ip3 needs backward computation.
I0527 11:48:41.738328  5565 net.cpp:226] drop2 needs backward computation.
I0527 11:48:41.738346  5565 net.cpp:226] relu6 needs backward computation.
I0527 11:48:41.738368  5565 net.cpp:226] ip2 needs backward computation.
I0527 11:48:41.738384  5565 net.cpp:226] drop1 needs backward computation.
I0527 11:48:41.738396  5565 net.cpp:226] relu5 needs backward computation.
I0527 11:48:41.738407  5565 net.cpp:226] ip1 needs backward computation.
I0527 11:48:41.738423  5565 net.cpp:226] pool4 needs backward computation.
I0527 11:48:41.738435  5565 net.cpp:226] relu4 needs backward computation.
I0527 11:48:41.738456  5565 net.cpp:226] conv4 needs backward computation.
I0527 11:48:41.738471  5565 net.cpp:226] pool3 needs backward computation.
I0527 11:48:41.738487  5565 net.cpp:226] relu3 needs backward computation.
I0527 11:48:41.738499  5565 net.cpp:226] conv3 needs backward computation.
I0527 11:48:41.738512  5565 net.cpp:226] pool2 needs backward computation.
I0527 11:48:41.738524  5565 net.cpp:226] relu2 needs backward computation.
I0527 11:48:41.738539  5565 net.cpp:226] conv2 needs backward computation.
I0527 11:48:41.738553  5565 net.cpp:226] pool1 needs backward computation.
I0527 11:48:41.738571  5565 net.cpp:226] relu1 needs backward computation.
I0527 11:48:41.738584  5565 net.cpp:226] conv1 needs backward computation.
I0527 11:48:41.738600  5565 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0527 11:48:41.738613  5565 net.cpp:228] data_hdf5 does not need backward computation.
I0527 11:48:41.738625  5565 net.cpp:270] This network produces output accuracy
I0527 11:48:41.738641  5565 net.cpp:270] This network produces output loss
I0527 11:48:41.738670  5565 net.cpp:283] Network initialization done.
I0527 11:48:41.738816  5565 solver.cpp:60] Solver scaffolding done.
I0527 11:48:41.739958  5565 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_165000.solverstate
I0527 11:48:41.962399  5565 sgd_solver.cpp:318] SGDSolver: restoring history
I0527 11:48:41.967928  5565 caffe.cpp:212] Starting Optimization
I0527 11:48:41.967972  5565 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0527 11:48:41.967994  5565 solver.cpp:289] Learning Rate Policy: fixed
I0527 11:48:41.969404  5565 solver.cpp:341] Iteration 165000, Testing net (#0)
I0527 11:49:31.462090  5565 solver.cpp:409]     Test net output #0: accuracy = 0.902412
I0527 11:49:31.462251  5565 solver.cpp:409]     Test net output #1: loss = 0.343674 (* 1 = 0.343674 loss)
I0527 11:49:31.484911  5565 solver.cpp:237] Iteration 165000, loss = 0.987908
I0527 11:49:31.484956  5565 solver.cpp:253]     Train net output #0: loss = 0.987908 (* 1 = 0.987908 loss)
I0527 11:49:31.484978  5565 sgd_solver.cpp:106] Iteration 165000, lr = 0.0035
I0527 11:49:41.346814  5565 solver.cpp:237] Iteration 165375, loss = 1.04343
I0527 11:49:41.346851  5565 solver.cpp:253]     Train net output #0: loss = 1.04343 (* 1 = 1.04343 loss)
I0527 11:49:41.346875  5565 sgd_solver.cpp:106] Iteration 165375, lr = 0.0035
I0527 11:49:51.212966  5565 solver.cpp:237] Iteration 165750, loss = 1.51282
I0527 11:49:51.213003  5565 solver.cpp:253]     Train net output #0: loss = 1.51282 (* 1 = 1.51282 loss)
I0527 11:49:51.213022  5565 sgd_solver.cpp:106] Iteration 165750, lr = 0.0035
I0527 11:50:01.064328  5565 solver.cpp:237] Iteration 166125, loss = 1.17064
I0527 11:50:01.064376  5565 solver.cpp:253]     Train net output #0: loss = 1.17064 (* 1 = 1.17064 loss)
I0527 11:50:01.064393  5565 sgd_solver.cpp:106] Iteration 166125, lr = 0.0035
I0527 11:50:10.900774  5565 solver.cpp:237] Iteration 166500, loss = 1.13229
I0527 11:50:10.900925  5565 solver.cpp:253]     Train net output #0: loss = 1.13229 (* 1 = 1.13229 loss)
I0527 11:50:10.900943  5565 sgd_solver.cpp:106] Iteration 166500, lr = 0.0035
I0527 11:50:20.739964  5565 solver.cpp:237] Iteration 166875, loss = 1.12123
I0527 11:50:20.740001  5565 solver.cpp:253]     Train net output #0: loss = 1.12123 (* 1 = 1.12123 loss)
I0527 11:50:20.740020  5565 sgd_solver.cpp:106] Iteration 166875, lr = 0.0035
I0527 11:50:30.702982  5565 solver.cpp:237] Iteration 167250, loss = 1.21647
I0527 11:50:30.703022  5565 solver.cpp:253]     Train net output #0: loss = 1.21647 (* 1 = 1.21647 loss)
I0527 11:50:30.703040  5565 sgd_solver.cpp:106] Iteration 167250, lr = 0.0035
I0527 11:51:02.767411  5565 solver.cpp:237] Iteration 167625, loss = 1.3547
I0527 11:51:02.767575  5565 solver.cpp:253]     Train net output #0: loss = 1.3547 (* 1 = 1.3547 loss)
I0527 11:51:02.767592  5565 sgd_solver.cpp:106] Iteration 167625, lr = 0.0035
I0527 11:51:12.706364  5565 solver.cpp:237] Iteration 168000, loss = 1.00385
I0527 11:51:12.706415  5565 solver.cpp:253]     Train net output #0: loss = 1.00385 (* 1 = 1.00385 loss)
I0527 11:51:12.706432  5565 sgd_solver.cpp:106] Iteration 168000, lr = 0.0035
I0527 11:51:22.415752  5565 solver.cpp:237] Iteration 168375, loss = 1.4252
I0527 11:51:22.415791  5565 solver.cpp:253]     Train net output #0: loss = 1.4252 (* 1 = 1.4252 loss)
I0527 11:51:22.415814  5565 sgd_solver.cpp:106] Iteration 168375, lr = 0.0035
I0527 11:51:32.089207  5565 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_168750.caffemodel
I0527 11:51:32.147498  5565 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0035_2016-05-20T15.49.03.369033_iter_168750.solverstate
I0527 11:51:32.181735  5565 solver.cpp:237] Iteration 168750, loss = 0.919194
I0527 11:51:32.181789  5565 solver.cpp:253]     Train net output #0: loss = 0.919194 (* 1 = 0.919194 loss)
I0527 11:51:32.181808  5565 sgd_solver.cpp:106] Iteration 168750, lr = 0.0035
I0527 11:51:41.879357  5565 solver.cpp:237] Iteration 169125, loss = 1.41505
I0527 11:51:41.879519  5565 solver.cpp:253]     Train net output #0: loss = 1.41505 (* 1 = 1.41505 loss)
I0527 11:51:41.879537  5565 sgd_solver.cpp:106] Iteration 169125, lr = 0.0035
I0527 11:51:51.574069  5565 solver.cpp:237] Iteration 169500, loss = 1.2654
I0527 11:51:51.574106  5565 solver.cpp:253]     Train net output #0: loss = 1.2654 (* 1 = 1.2654 loss)
I0527 11:51:51.574126  5565 sgd_solver.cpp:106] Iteration 169500, lr = 0.0035
aprun: Apid 11273625: Caught signal Terminated, sending to application
*** Aborted at 1464364313 (unix time) try "date -d @1464364313" if you are using GNU date ***
PC: @     0x2aaab930eb40 (unknown)
*** SIGTERM (@0x15ba) received by PID 5565 (TID 0x2aaac746f900) from PID 5562; stack trace: ***
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11273625: Caught signal Terminated, sending to application
    @     0x2aaab930eb40 (unknown)
aprun: Apid 11273625: Caught signal Terminated, sending to application
    @     0x2aaab928a3b8 (unknown)
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e9877 (unknown)
    @     0x2aaab928eb4e (unknown)
aprun: Apid 11273625: Caught signal Terminated, sending to application
    @     0x2aaab926d6cf (unknown)
    @     0x2aaab9265ac0 (unknown)
    @     0x2aaab92663d3 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11273625: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11273625: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11273625: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
aprun: Apid 11273625: Caught signal Terminated, sending to application
