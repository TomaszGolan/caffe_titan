2813006
I0527 05:14:21.300689  1888 caffe.cpp:184] Using GPUs 0
I0527 05:14:21.725977  1888 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.0045
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182.prototxt"
I0527 05:14:21.728282  1888 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182.prototxt
I0527 05:14:21.746667  1888 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0527 05:14:21.746723  1888 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0527 05:14:21.747071  1888 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 05:14:21.747251  1888 layer_factory.hpp:77] Creating layer data_hdf5
I0527 05:14:21.747274  1888 net.cpp:106] Creating Layer data_hdf5
I0527 05:14:21.747288  1888 net.cpp:411] data_hdf5 -> data
I0527 05:14:21.747323  1888 net.cpp:411] data_hdf5 -> label
I0527 05:14:21.747354  1888 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0527 05:14:21.748821  1888 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0527 05:14:21.751127  1888 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0527 05:14:43.273562  1888 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0527 05:14:43.278775  1888 net.cpp:150] Setting up data_hdf5
I0527 05:14:43.278816  1888 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0527 05:14:43.278831  1888 net.cpp:157] Top shape: 30 (30)
I0527 05:14:43.278841  1888 net.cpp:165] Memory required for data: 762120
I0527 05:14:43.278853  1888 layer_factory.hpp:77] Creating layer conv1
I0527 05:14:43.278887  1888 net.cpp:106] Creating Layer conv1
I0527 05:14:43.278899  1888 net.cpp:454] conv1 <- data
I0527 05:14:43.278923  1888 net.cpp:411] conv1 -> conv1
I0527 05:14:43.746419  1888 net.cpp:150] Setting up conv1
I0527 05:14:43.746464  1888 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 05:14:43.746474  1888 net.cpp:165] Memory required for data: 9056520
I0527 05:14:43.746505  1888 layer_factory.hpp:77] Creating layer relu1
I0527 05:14:43.746527  1888 net.cpp:106] Creating Layer relu1
I0527 05:14:43.746538  1888 net.cpp:454] relu1 <- conv1
I0527 05:14:43.746551  1888 net.cpp:397] relu1 -> conv1 (in-place)
I0527 05:14:43.747068  1888 net.cpp:150] Setting up relu1
I0527 05:14:43.747086  1888 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 05:14:43.747097  1888 net.cpp:165] Memory required for data: 17350920
I0527 05:14:43.747107  1888 layer_factory.hpp:77] Creating layer pool1
I0527 05:14:43.747123  1888 net.cpp:106] Creating Layer pool1
I0527 05:14:43.747133  1888 net.cpp:454] pool1 <- conv1
I0527 05:14:43.747148  1888 net.cpp:411] pool1 -> pool1
I0527 05:14:43.747229  1888 net.cpp:150] Setting up pool1
I0527 05:14:43.747243  1888 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0527 05:14:43.747251  1888 net.cpp:165] Memory required for data: 21498120
I0527 05:14:43.747262  1888 layer_factory.hpp:77] Creating layer conv2
I0527 05:14:43.747285  1888 net.cpp:106] Creating Layer conv2
I0527 05:14:43.747295  1888 net.cpp:454] conv2 <- pool1
I0527 05:14:43.747308  1888 net.cpp:411] conv2 -> conv2
I0527 05:14:43.750003  1888 net.cpp:150] Setting up conv2
I0527 05:14:43.750031  1888 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 05:14:43.750042  1888 net.cpp:165] Memory required for data: 27459720
I0527 05:14:43.750061  1888 layer_factory.hpp:77] Creating layer relu2
I0527 05:14:43.750077  1888 net.cpp:106] Creating Layer relu2
I0527 05:14:43.750087  1888 net.cpp:454] relu2 <- conv2
I0527 05:14:43.750100  1888 net.cpp:397] relu2 -> conv2 (in-place)
I0527 05:14:43.750433  1888 net.cpp:150] Setting up relu2
I0527 05:14:43.750448  1888 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 05:14:43.750458  1888 net.cpp:165] Memory required for data: 33421320
I0527 05:14:43.750468  1888 layer_factory.hpp:77] Creating layer pool2
I0527 05:14:43.750481  1888 net.cpp:106] Creating Layer pool2
I0527 05:14:43.750491  1888 net.cpp:454] pool2 <- conv2
I0527 05:14:43.750504  1888 net.cpp:411] pool2 -> pool2
I0527 05:14:43.750584  1888 net.cpp:150] Setting up pool2
I0527 05:14:43.750598  1888 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0527 05:14:43.750608  1888 net.cpp:165] Memory required for data: 36402120
I0527 05:14:43.750617  1888 layer_factory.hpp:77] Creating layer conv3
I0527 05:14:43.750634  1888 net.cpp:106] Creating Layer conv3
I0527 05:14:43.750644  1888 net.cpp:454] conv3 <- pool2
I0527 05:14:43.750658  1888 net.cpp:411] conv3 -> conv3
I0527 05:14:43.752614  1888 net.cpp:150] Setting up conv3
I0527 05:14:43.752637  1888 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 05:14:43.752650  1888 net.cpp:165] Memory required for data: 39654600
I0527 05:14:43.752667  1888 layer_factory.hpp:77] Creating layer relu3
I0527 05:14:43.752684  1888 net.cpp:106] Creating Layer relu3
I0527 05:14:43.752694  1888 net.cpp:454] relu3 <- conv3
I0527 05:14:43.752707  1888 net.cpp:397] relu3 -> conv3 (in-place)
I0527 05:14:43.753177  1888 net.cpp:150] Setting up relu3
I0527 05:14:43.753195  1888 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 05:14:43.753206  1888 net.cpp:165] Memory required for data: 42907080
I0527 05:14:43.753216  1888 layer_factory.hpp:77] Creating layer pool3
I0527 05:14:43.753228  1888 net.cpp:106] Creating Layer pool3
I0527 05:14:43.753238  1888 net.cpp:454] pool3 <- conv3
I0527 05:14:43.753259  1888 net.cpp:411] pool3 -> pool3
I0527 05:14:43.753329  1888 net.cpp:150] Setting up pool3
I0527 05:14:43.753341  1888 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0527 05:14:43.753353  1888 net.cpp:165] Memory required for data: 44533320
I0527 05:14:43.753363  1888 layer_factory.hpp:77] Creating layer conv4
I0527 05:14:43.753381  1888 net.cpp:106] Creating Layer conv4
I0527 05:14:43.753391  1888 net.cpp:454] conv4 <- pool3
I0527 05:14:43.753406  1888 net.cpp:411] conv4 -> conv4
I0527 05:14:43.756111  1888 net.cpp:150] Setting up conv4
I0527 05:14:43.756139  1888 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 05:14:43.756150  1888 net.cpp:165] Memory required for data: 45621960
I0527 05:14:43.756165  1888 layer_factory.hpp:77] Creating layer relu4
I0527 05:14:43.756181  1888 net.cpp:106] Creating Layer relu4
I0527 05:14:43.756191  1888 net.cpp:454] relu4 <- conv4
I0527 05:14:43.756203  1888 net.cpp:397] relu4 -> conv4 (in-place)
I0527 05:14:43.756674  1888 net.cpp:150] Setting up relu4
I0527 05:14:43.756690  1888 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 05:14:43.756700  1888 net.cpp:165] Memory required for data: 46710600
I0527 05:14:43.756711  1888 layer_factory.hpp:77] Creating layer pool4
I0527 05:14:43.756724  1888 net.cpp:106] Creating Layer pool4
I0527 05:14:43.756734  1888 net.cpp:454] pool4 <- conv4
I0527 05:14:43.756747  1888 net.cpp:411] pool4 -> pool4
I0527 05:14:43.756814  1888 net.cpp:150] Setting up pool4
I0527 05:14:43.756829  1888 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0527 05:14:43.756839  1888 net.cpp:165] Memory required for data: 47254920
I0527 05:14:43.756850  1888 layer_factory.hpp:77] Creating layer ip1
I0527 05:14:43.756870  1888 net.cpp:106] Creating Layer ip1
I0527 05:14:43.756881  1888 net.cpp:454] ip1 <- pool4
I0527 05:14:43.756894  1888 net.cpp:411] ip1 -> ip1
I0527 05:14:43.772380  1888 net.cpp:150] Setting up ip1
I0527 05:14:43.772409  1888 net.cpp:157] Top shape: 30 196 (5880)
I0527 05:14:43.772421  1888 net.cpp:165] Memory required for data: 47278440
I0527 05:14:43.772444  1888 layer_factory.hpp:77] Creating layer relu5
I0527 05:14:43.772459  1888 net.cpp:106] Creating Layer relu5
I0527 05:14:43.772469  1888 net.cpp:454] relu5 <- ip1
I0527 05:14:43.772482  1888 net.cpp:397] relu5 -> ip1 (in-place)
I0527 05:14:43.772824  1888 net.cpp:150] Setting up relu5
I0527 05:14:43.772837  1888 net.cpp:157] Top shape: 30 196 (5880)
I0527 05:14:43.772848  1888 net.cpp:165] Memory required for data: 47301960
I0527 05:14:43.772860  1888 layer_factory.hpp:77] Creating layer drop1
I0527 05:14:43.772881  1888 net.cpp:106] Creating Layer drop1
I0527 05:14:43.772891  1888 net.cpp:454] drop1 <- ip1
I0527 05:14:43.772903  1888 net.cpp:397] drop1 -> ip1 (in-place)
I0527 05:14:43.772964  1888 net.cpp:150] Setting up drop1
I0527 05:14:43.772977  1888 net.cpp:157] Top shape: 30 196 (5880)
I0527 05:14:43.772987  1888 net.cpp:165] Memory required for data: 47325480
I0527 05:14:43.772997  1888 layer_factory.hpp:77] Creating layer ip2
I0527 05:14:43.773016  1888 net.cpp:106] Creating Layer ip2
I0527 05:14:43.773027  1888 net.cpp:454] ip2 <- ip1
I0527 05:14:43.773041  1888 net.cpp:411] ip2 -> ip2
I0527 05:14:43.773509  1888 net.cpp:150] Setting up ip2
I0527 05:14:43.773521  1888 net.cpp:157] Top shape: 30 98 (2940)
I0527 05:14:43.773531  1888 net.cpp:165] Memory required for data: 47337240
I0527 05:14:43.773546  1888 layer_factory.hpp:77] Creating layer relu6
I0527 05:14:43.773561  1888 net.cpp:106] Creating Layer relu6
I0527 05:14:43.773571  1888 net.cpp:454] relu6 <- ip2
I0527 05:14:43.773582  1888 net.cpp:397] relu6 -> ip2 (in-place)
I0527 05:14:43.774103  1888 net.cpp:150] Setting up relu6
I0527 05:14:43.774119  1888 net.cpp:157] Top shape: 30 98 (2940)
I0527 05:14:43.774130  1888 net.cpp:165] Memory required for data: 47349000
I0527 05:14:43.774140  1888 layer_factory.hpp:77] Creating layer drop2
I0527 05:14:43.774153  1888 net.cpp:106] Creating Layer drop2
I0527 05:14:43.774163  1888 net.cpp:454] drop2 <- ip2
I0527 05:14:43.774176  1888 net.cpp:397] drop2 -> ip2 (in-place)
I0527 05:14:43.774219  1888 net.cpp:150] Setting up drop2
I0527 05:14:43.774232  1888 net.cpp:157] Top shape: 30 98 (2940)
I0527 05:14:43.774242  1888 net.cpp:165] Memory required for data: 47360760
I0527 05:14:43.774252  1888 layer_factory.hpp:77] Creating layer ip3
I0527 05:14:43.774266  1888 net.cpp:106] Creating Layer ip3
I0527 05:14:43.774276  1888 net.cpp:454] ip3 <- ip2
I0527 05:14:43.774288  1888 net.cpp:411] ip3 -> ip3
I0527 05:14:43.774503  1888 net.cpp:150] Setting up ip3
I0527 05:14:43.774516  1888 net.cpp:157] Top shape: 30 11 (330)
I0527 05:14:43.774526  1888 net.cpp:165] Memory required for data: 47362080
I0527 05:14:43.774541  1888 layer_factory.hpp:77] Creating layer drop3
I0527 05:14:43.774554  1888 net.cpp:106] Creating Layer drop3
I0527 05:14:43.774564  1888 net.cpp:454] drop3 <- ip3
I0527 05:14:43.774575  1888 net.cpp:397] drop3 -> ip3 (in-place)
I0527 05:14:43.774616  1888 net.cpp:150] Setting up drop3
I0527 05:14:43.774628  1888 net.cpp:157] Top shape: 30 11 (330)
I0527 05:14:43.774637  1888 net.cpp:165] Memory required for data: 47363400
I0527 05:14:43.774647  1888 layer_factory.hpp:77] Creating layer loss
I0527 05:14:43.774667  1888 net.cpp:106] Creating Layer loss
I0527 05:14:43.774677  1888 net.cpp:454] loss <- ip3
I0527 05:14:43.774688  1888 net.cpp:454] loss <- label
I0527 05:14:43.774700  1888 net.cpp:411] loss -> loss
I0527 05:14:43.774718  1888 layer_factory.hpp:77] Creating layer loss
I0527 05:14:43.775358  1888 net.cpp:150] Setting up loss
I0527 05:14:43.775373  1888 net.cpp:157] Top shape: (1)
I0527 05:14:43.775385  1888 net.cpp:160]     with loss weight 1
I0527 05:14:43.775426  1888 net.cpp:165] Memory required for data: 47363404
I0527 05:14:43.775437  1888 net.cpp:226] loss needs backward computation.
I0527 05:14:43.775449  1888 net.cpp:226] drop3 needs backward computation.
I0527 05:14:43.775457  1888 net.cpp:226] ip3 needs backward computation.
I0527 05:14:43.775467  1888 net.cpp:226] drop2 needs backward computation.
I0527 05:14:43.775477  1888 net.cpp:226] relu6 needs backward computation.
I0527 05:14:43.775488  1888 net.cpp:226] ip2 needs backward computation.
I0527 05:14:43.775497  1888 net.cpp:226] drop1 needs backward computation.
I0527 05:14:43.775507  1888 net.cpp:226] relu5 needs backward computation.
I0527 05:14:43.775517  1888 net.cpp:226] ip1 needs backward computation.
I0527 05:14:43.775527  1888 net.cpp:226] pool4 needs backward computation.
I0527 05:14:43.775537  1888 net.cpp:226] relu4 needs backward computation.
I0527 05:14:43.775547  1888 net.cpp:226] conv4 needs backward computation.
I0527 05:14:43.775557  1888 net.cpp:226] pool3 needs backward computation.
I0527 05:14:43.775568  1888 net.cpp:226] relu3 needs backward computation.
I0527 05:14:43.775578  1888 net.cpp:226] conv3 needs backward computation.
I0527 05:14:43.775598  1888 net.cpp:226] pool2 needs backward computation.
I0527 05:14:43.775609  1888 net.cpp:226] relu2 needs backward computation.
I0527 05:14:43.775619  1888 net.cpp:226] conv2 needs backward computation.
I0527 05:14:43.775629  1888 net.cpp:226] pool1 needs backward computation.
I0527 05:14:43.775640  1888 net.cpp:226] relu1 needs backward computation.
I0527 05:14:43.775650  1888 net.cpp:226] conv1 needs backward computation.
I0527 05:14:43.775660  1888 net.cpp:228] data_hdf5 does not need backward computation.
I0527 05:14:43.775671  1888 net.cpp:270] This network produces output loss
I0527 05:14:43.775693  1888 net.cpp:283] Network initialization done.
I0527 05:14:43.777379  1888 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182.prototxt
I0527 05:14:43.777451  1888 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0527 05:14:43.777808  1888 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 05:14:43.778000  1888 layer_factory.hpp:77] Creating layer data_hdf5
I0527 05:14:43.778015  1888 net.cpp:106] Creating Layer data_hdf5
I0527 05:14:43.778028  1888 net.cpp:411] data_hdf5 -> data
I0527 05:14:43.778045  1888 net.cpp:411] data_hdf5 -> label
I0527 05:14:43.778061  1888 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0527 05:14:43.779429  1888 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0527 05:15:05.095986  1888 net.cpp:150] Setting up data_hdf5
I0527 05:15:05.096153  1888 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0527 05:15:05.096168  1888 net.cpp:157] Top shape: 30 (30)
I0527 05:15:05.096180  1888 net.cpp:165] Memory required for data: 762120
I0527 05:15:05.096194  1888 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0527 05:15:05.096221  1888 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0527 05:15:05.096232  1888 net.cpp:454] label_data_hdf5_1_split <- label
I0527 05:15:05.096247  1888 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0527 05:15:05.096269  1888 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0527 05:15:05.096343  1888 net.cpp:150] Setting up label_data_hdf5_1_split
I0527 05:15:05.096355  1888 net.cpp:157] Top shape: 30 (30)
I0527 05:15:05.096367  1888 net.cpp:157] Top shape: 30 (30)
I0527 05:15:05.096377  1888 net.cpp:165] Memory required for data: 762360
I0527 05:15:05.096387  1888 layer_factory.hpp:77] Creating layer conv1
I0527 05:15:05.096407  1888 net.cpp:106] Creating Layer conv1
I0527 05:15:05.096417  1888 net.cpp:454] conv1 <- data
I0527 05:15:05.096431  1888 net.cpp:411] conv1 -> conv1
I0527 05:15:05.098389  1888 net.cpp:150] Setting up conv1
I0527 05:15:05.098414  1888 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 05:15:05.098425  1888 net.cpp:165] Memory required for data: 9056760
I0527 05:15:05.098446  1888 layer_factory.hpp:77] Creating layer relu1
I0527 05:15:05.098461  1888 net.cpp:106] Creating Layer relu1
I0527 05:15:05.098471  1888 net.cpp:454] relu1 <- conv1
I0527 05:15:05.098484  1888 net.cpp:397] relu1 -> conv1 (in-place)
I0527 05:15:05.098980  1888 net.cpp:150] Setting up relu1
I0527 05:15:05.098996  1888 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0527 05:15:05.099006  1888 net.cpp:165] Memory required for data: 17351160
I0527 05:15:05.099017  1888 layer_factory.hpp:77] Creating layer pool1
I0527 05:15:05.099033  1888 net.cpp:106] Creating Layer pool1
I0527 05:15:05.099042  1888 net.cpp:454] pool1 <- conv1
I0527 05:15:05.099057  1888 net.cpp:411] pool1 -> pool1
I0527 05:15:05.099131  1888 net.cpp:150] Setting up pool1
I0527 05:15:05.099145  1888 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0527 05:15:05.099155  1888 net.cpp:165] Memory required for data: 21498360
I0527 05:15:05.099165  1888 layer_factory.hpp:77] Creating layer conv2
I0527 05:15:05.099182  1888 net.cpp:106] Creating Layer conv2
I0527 05:15:05.099194  1888 net.cpp:454] conv2 <- pool1
I0527 05:15:05.099207  1888 net.cpp:411] conv2 -> conv2
I0527 05:15:05.101111  1888 net.cpp:150] Setting up conv2
I0527 05:15:05.101133  1888 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 05:15:05.101145  1888 net.cpp:165] Memory required for data: 27459960
I0527 05:15:05.101163  1888 layer_factory.hpp:77] Creating layer relu2
I0527 05:15:05.101177  1888 net.cpp:106] Creating Layer relu2
I0527 05:15:05.101187  1888 net.cpp:454] relu2 <- conv2
I0527 05:15:05.101200  1888 net.cpp:397] relu2 -> conv2 (in-place)
I0527 05:15:05.101541  1888 net.cpp:150] Setting up relu2
I0527 05:15:05.101555  1888 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0527 05:15:05.101565  1888 net.cpp:165] Memory required for data: 33421560
I0527 05:15:05.101577  1888 layer_factory.hpp:77] Creating layer pool2
I0527 05:15:05.101589  1888 net.cpp:106] Creating Layer pool2
I0527 05:15:05.101599  1888 net.cpp:454] pool2 <- conv2
I0527 05:15:05.101611  1888 net.cpp:411] pool2 -> pool2
I0527 05:15:05.101683  1888 net.cpp:150] Setting up pool2
I0527 05:15:05.101696  1888 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0527 05:15:05.101706  1888 net.cpp:165] Memory required for data: 36402360
I0527 05:15:05.101716  1888 layer_factory.hpp:77] Creating layer conv3
I0527 05:15:05.101737  1888 net.cpp:106] Creating Layer conv3
I0527 05:15:05.101747  1888 net.cpp:454] conv3 <- pool2
I0527 05:15:05.101761  1888 net.cpp:411] conv3 -> conv3
I0527 05:15:05.103729  1888 net.cpp:150] Setting up conv3
I0527 05:15:05.103751  1888 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 05:15:05.103762  1888 net.cpp:165] Memory required for data: 39654840
I0527 05:15:05.103796  1888 layer_factory.hpp:77] Creating layer relu3
I0527 05:15:05.103808  1888 net.cpp:106] Creating Layer relu3
I0527 05:15:05.103819  1888 net.cpp:454] relu3 <- conv3
I0527 05:15:05.103832  1888 net.cpp:397] relu3 -> conv3 (in-place)
I0527 05:15:05.104307  1888 net.cpp:150] Setting up relu3
I0527 05:15:05.104323  1888 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0527 05:15:05.104333  1888 net.cpp:165] Memory required for data: 42907320
I0527 05:15:05.104344  1888 layer_factory.hpp:77] Creating layer pool3
I0527 05:15:05.104357  1888 net.cpp:106] Creating Layer pool3
I0527 05:15:05.104367  1888 net.cpp:454] pool3 <- conv3
I0527 05:15:05.104380  1888 net.cpp:411] pool3 -> pool3
I0527 05:15:05.104452  1888 net.cpp:150] Setting up pool3
I0527 05:15:05.104465  1888 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0527 05:15:05.104475  1888 net.cpp:165] Memory required for data: 44533560
I0527 05:15:05.104486  1888 layer_factory.hpp:77] Creating layer conv4
I0527 05:15:05.104503  1888 net.cpp:106] Creating Layer conv4
I0527 05:15:05.104513  1888 net.cpp:454] conv4 <- pool3
I0527 05:15:05.104527  1888 net.cpp:411] conv4 -> conv4
I0527 05:15:05.106595  1888 net.cpp:150] Setting up conv4
I0527 05:15:05.106617  1888 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 05:15:05.106631  1888 net.cpp:165] Memory required for data: 45622200
I0527 05:15:05.106645  1888 layer_factory.hpp:77] Creating layer relu4
I0527 05:15:05.106658  1888 net.cpp:106] Creating Layer relu4
I0527 05:15:05.106668  1888 net.cpp:454] relu4 <- conv4
I0527 05:15:05.106681  1888 net.cpp:397] relu4 -> conv4 (in-place)
I0527 05:15:05.107152  1888 net.cpp:150] Setting up relu4
I0527 05:15:05.107168  1888 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0527 05:15:05.107178  1888 net.cpp:165] Memory required for data: 46710840
I0527 05:15:05.107188  1888 layer_factory.hpp:77] Creating layer pool4
I0527 05:15:05.107203  1888 net.cpp:106] Creating Layer pool4
I0527 05:15:05.107213  1888 net.cpp:454] pool4 <- conv4
I0527 05:15:05.107225  1888 net.cpp:411] pool4 -> pool4
I0527 05:15:05.107297  1888 net.cpp:150] Setting up pool4
I0527 05:15:05.107311  1888 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0527 05:15:05.107321  1888 net.cpp:165] Memory required for data: 47255160
I0527 05:15:05.107331  1888 layer_factory.hpp:77] Creating layer ip1
I0527 05:15:05.107343  1888 net.cpp:106] Creating Layer ip1
I0527 05:15:05.107354  1888 net.cpp:454] ip1 <- pool4
I0527 05:15:05.107368  1888 net.cpp:411] ip1 -> ip1
I0527 05:15:05.122774  1888 net.cpp:150] Setting up ip1
I0527 05:15:05.122802  1888 net.cpp:157] Top shape: 30 196 (5880)
I0527 05:15:05.122813  1888 net.cpp:165] Memory required for data: 47278680
I0527 05:15:05.122835  1888 layer_factory.hpp:77] Creating layer relu5
I0527 05:15:05.122850  1888 net.cpp:106] Creating Layer relu5
I0527 05:15:05.122861  1888 net.cpp:454] relu5 <- ip1
I0527 05:15:05.122874  1888 net.cpp:397] relu5 -> ip1 (in-place)
I0527 05:15:05.123220  1888 net.cpp:150] Setting up relu5
I0527 05:15:05.123234  1888 net.cpp:157] Top shape: 30 196 (5880)
I0527 05:15:05.123245  1888 net.cpp:165] Memory required for data: 47302200
I0527 05:15:05.123255  1888 layer_factory.hpp:77] Creating layer drop1
I0527 05:15:05.123275  1888 net.cpp:106] Creating Layer drop1
I0527 05:15:05.123284  1888 net.cpp:454] drop1 <- ip1
I0527 05:15:05.123297  1888 net.cpp:397] drop1 -> ip1 (in-place)
I0527 05:15:05.123342  1888 net.cpp:150] Setting up drop1
I0527 05:15:05.123355  1888 net.cpp:157] Top shape: 30 196 (5880)
I0527 05:15:05.123364  1888 net.cpp:165] Memory required for data: 47325720
I0527 05:15:05.123374  1888 layer_factory.hpp:77] Creating layer ip2
I0527 05:15:05.123389  1888 net.cpp:106] Creating Layer ip2
I0527 05:15:05.123399  1888 net.cpp:454] ip2 <- ip1
I0527 05:15:05.123414  1888 net.cpp:411] ip2 -> ip2
I0527 05:15:05.123896  1888 net.cpp:150] Setting up ip2
I0527 05:15:05.123909  1888 net.cpp:157] Top shape: 30 98 (2940)
I0527 05:15:05.123919  1888 net.cpp:165] Memory required for data: 47337480
I0527 05:15:05.123935  1888 layer_factory.hpp:77] Creating layer relu6
I0527 05:15:05.123960  1888 net.cpp:106] Creating Layer relu6
I0527 05:15:05.123970  1888 net.cpp:454] relu6 <- ip2
I0527 05:15:05.123983  1888 net.cpp:397] relu6 -> ip2 (in-place)
I0527 05:15:05.124521  1888 net.cpp:150] Setting up relu6
I0527 05:15:05.124544  1888 net.cpp:157] Top shape: 30 98 (2940)
I0527 05:15:05.124554  1888 net.cpp:165] Memory required for data: 47349240
I0527 05:15:05.124567  1888 layer_factory.hpp:77] Creating layer drop2
I0527 05:15:05.124580  1888 net.cpp:106] Creating Layer drop2
I0527 05:15:05.124590  1888 net.cpp:454] drop2 <- ip2
I0527 05:15:05.124603  1888 net.cpp:397] drop2 -> ip2 (in-place)
I0527 05:15:05.124647  1888 net.cpp:150] Setting up drop2
I0527 05:15:05.124660  1888 net.cpp:157] Top shape: 30 98 (2940)
I0527 05:15:05.124670  1888 net.cpp:165] Memory required for data: 47361000
I0527 05:15:05.124680  1888 layer_factory.hpp:77] Creating layer ip3
I0527 05:15:05.124694  1888 net.cpp:106] Creating Layer ip3
I0527 05:15:05.124704  1888 net.cpp:454] ip3 <- ip2
I0527 05:15:05.124718  1888 net.cpp:411] ip3 -> ip3
I0527 05:15:05.124944  1888 net.cpp:150] Setting up ip3
I0527 05:15:05.124958  1888 net.cpp:157] Top shape: 30 11 (330)
I0527 05:15:05.124968  1888 net.cpp:165] Memory required for data: 47362320
I0527 05:15:05.124984  1888 layer_factory.hpp:77] Creating layer drop3
I0527 05:15:05.124996  1888 net.cpp:106] Creating Layer drop3
I0527 05:15:05.125006  1888 net.cpp:454] drop3 <- ip3
I0527 05:15:05.125018  1888 net.cpp:397] drop3 -> ip3 (in-place)
I0527 05:15:05.125061  1888 net.cpp:150] Setting up drop3
I0527 05:15:05.125073  1888 net.cpp:157] Top shape: 30 11 (330)
I0527 05:15:05.125083  1888 net.cpp:165] Memory required for data: 47363640
I0527 05:15:05.125093  1888 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0527 05:15:05.125107  1888 net.cpp:106] Creating Layer ip3_drop3_0_split
I0527 05:15:05.125116  1888 net.cpp:454] ip3_drop3_0_split <- ip3
I0527 05:15:05.125129  1888 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0527 05:15:05.125144  1888 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0527 05:15:05.125218  1888 net.cpp:150] Setting up ip3_drop3_0_split
I0527 05:15:05.125231  1888 net.cpp:157] Top shape: 30 11 (330)
I0527 05:15:05.125243  1888 net.cpp:157] Top shape: 30 11 (330)
I0527 05:15:05.125262  1888 net.cpp:165] Memory required for data: 47366280
I0527 05:15:05.125272  1888 layer_factory.hpp:77] Creating layer accuracy
I0527 05:15:05.125293  1888 net.cpp:106] Creating Layer accuracy
I0527 05:15:05.125303  1888 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0527 05:15:05.125313  1888 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0527 05:15:05.125327  1888 net.cpp:411] accuracy -> accuracy
I0527 05:15:05.125351  1888 net.cpp:150] Setting up accuracy
I0527 05:15:05.125363  1888 net.cpp:157] Top shape: (1)
I0527 05:15:05.125373  1888 net.cpp:165] Memory required for data: 47366284
I0527 05:15:05.125383  1888 layer_factory.hpp:77] Creating layer loss
I0527 05:15:05.125397  1888 net.cpp:106] Creating Layer loss
I0527 05:15:05.125406  1888 net.cpp:454] loss <- ip3_drop3_0_split_1
I0527 05:15:05.125417  1888 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0527 05:15:05.125430  1888 net.cpp:411] loss -> loss
I0527 05:15:05.125448  1888 layer_factory.hpp:77] Creating layer loss
I0527 05:15:05.125936  1888 net.cpp:150] Setting up loss
I0527 05:15:05.125951  1888 net.cpp:157] Top shape: (1)
I0527 05:15:05.125960  1888 net.cpp:160]     with loss weight 1
I0527 05:15:05.125978  1888 net.cpp:165] Memory required for data: 47366288
I0527 05:15:05.125988  1888 net.cpp:226] loss needs backward computation.
I0527 05:15:05.126000  1888 net.cpp:228] accuracy does not need backward computation.
I0527 05:15:05.126011  1888 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0527 05:15:05.126021  1888 net.cpp:226] drop3 needs backward computation.
I0527 05:15:05.126032  1888 net.cpp:226] ip3 needs backward computation.
I0527 05:15:05.126044  1888 net.cpp:226] drop2 needs backward computation.
I0527 05:15:05.126052  1888 net.cpp:226] relu6 needs backward computation.
I0527 05:15:05.126070  1888 net.cpp:226] ip2 needs backward computation.
I0527 05:15:05.126081  1888 net.cpp:226] drop1 needs backward computation.
I0527 05:15:05.126091  1888 net.cpp:226] relu5 needs backward computation.
I0527 05:15:05.126101  1888 net.cpp:226] ip1 needs backward computation.
I0527 05:15:05.126111  1888 net.cpp:226] pool4 needs backward computation.
I0527 05:15:05.126121  1888 net.cpp:226] relu4 needs backward computation.
I0527 05:15:05.126132  1888 net.cpp:226] conv4 needs backward computation.
I0527 05:15:05.126142  1888 net.cpp:226] pool3 needs backward computation.
I0527 05:15:05.126152  1888 net.cpp:226] relu3 needs backward computation.
I0527 05:15:05.126163  1888 net.cpp:226] conv3 needs backward computation.
I0527 05:15:05.126173  1888 net.cpp:226] pool2 needs backward computation.
I0527 05:15:05.126183  1888 net.cpp:226] relu2 needs backward computation.
I0527 05:15:05.126193  1888 net.cpp:226] conv2 needs backward computation.
I0527 05:15:05.126202  1888 net.cpp:226] pool1 needs backward computation.
I0527 05:15:05.126212  1888 net.cpp:226] relu1 needs backward computation.
I0527 05:15:05.126222  1888 net.cpp:226] conv1 needs backward computation.
I0527 05:15:05.126233  1888 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0527 05:15:05.126245  1888 net.cpp:228] data_hdf5 does not need backward computation.
I0527 05:15:05.126255  1888 net.cpp:270] This network produces output accuracy
I0527 05:15:05.126263  1888 net.cpp:270] This network produces output loss
I0527 05:15:05.126291  1888 net.cpp:283] Network initialization done.
I0527 05:15:05.126423  1888 solver.cpp:60] Solver scaffolding done.
I0527 05:15:05.127565  1888 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_210000.solverstate
I0527 05:15:05.389638  1888 sgd_solver.cpp:318] SGDSolver: restoring history
I0527 05:15:05.395195  1888 caffe.cpp:212] Starting Optimization
I0527 05:15:05.395236  1888 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0527 05:15:05.395247  1888 solver.cpp:289] Learning Rate Policy: fixed
I0527 05:15:05.396626  1888 solver.cpp:341] Iteration 210000, Testing net (#0)
I0527 05:15:56.034718  1888 solver.cpp:409]     Test net output #0: accuracy = 0.899965
I0527 05:15:56.034865  1888 solver.cpp:409]     Test net output #1: loss = 0.321299 (* 1 = 0.321299 loss)
I0527 05:15:56.055831  1888 solver.cpp:237] Iteration 210000, loss = 1.32311
I0527 05:15:56.055866  1888 solver.cpp:253]     Train net output #0: loss = 1.32311 (* 1 = 1.32311 loss)
I0527 05:15:56.055884  1888 sgd_solver.cpp:106] Iteration 210000, lr = 0.0045
I0527 05:16:06.608458  1888 solver.cpp:237] Iteration 210500, loss = 0.964711
I0527 05:16:06.608513  1888 solver.cpp:253]     Train net output #0: loss = 0.964711 (* 1 = 0.964711 loss)
I0527 05:16:06.608527  1888 sgd_solver.cpp:106] Iteration 210500, lr = 0.0045
I0527 05:16:17.160935  1888 solver.cpp:237] Iteration 211000, loss = 1.5062
I0527 05:16:17.160971  1888 solver.cpp:253]     Train net output #0: loss = 1.5062 (* 1 = 1.5062 loss)
I0527 05:16:17.160989  1888 sgd_solver.cpp:106] Iteration 211000, lr = 0.0045
I0527 05:16:27.715126  1888 solver.cpp:237] Iteration 211500, loss = 1.23902
I0527 05:16:27.715276  1888 solver.cpp:253]     Train net output #0: loss = 1.23902 (* 1 = 1.23902 loss)
I0527 05:16:27.715291  1888 sgd_solver.cpp:106] Iteration 211500, lr = 0.0045
I0527 05:16:38.271154  1888 solver.cpp:237] Iteration 212000, loss = 1.3251
I0527 05:16:38.271199  1888 solver.cpp:253]     Train net output #0: loss = 1.3251 (* 1 = 1.3251 loss)
I0527 05:16:38.271212  1888 sgd_solver.cpp:106] Iteration 212000, lr = 0.0045
I0527 05:16:48.834002  1888 solver.cpp:237] Iteration 212500, loss = 1.08008
I0527 05:16:48.834038  1888 solver.cpp:253]     Train net output #0: loss = 1.08008 (* 1 = 1.08008 loss)
I0527 05:16:48.834051  1888 sgd_solver.cpp:106] Iteration 212500, lr = 0.0045
I0527 05:16:59.394525  1888 solver.cpp:237] Iteration 213000, loss = 1.05864
I0527 05:16:59.394676  1888 solver.cpp:253]     Train net output #0: loss = 1.05864 (* 1 = 1.05864 loss)
I0527 05:16:59.394692  1888 sgd_solver.cpp:106] Iteration 213000, lr = 0.0045
I0527 05:17:32.085937  1888 solver.cpp:237] Iteration 213500, loss = 1.21125
I0527 05:17:32.086097  1888 solver.cpp:253]     Train net output #0: loss = 1.21125 (* 1 = 1.21125 loss)
I0527 05:17:32.086112  1888 sgd_solver.cpp:106] Iteration 213500, lr = 0.0045
I0527 05:17:42.648852  1888 solver.cpp:237] Iteration 214000, loss = 1.00843
I0527 05:17:42.648890  1888 solver.cpp:253]     Train net output #0: loss = 1.00843 (* 1 = 1.00843 loss)
I0527 05:17:42.648902  1888 sgd_solver.cpp:106] Iteration 214000, lr = 0.0045
I0527 05:17:53.210007  1888 solver.cpp:237] Iteration 214500, loss = 1.05107
I0527 05:17:53.210053  1888 solver.cpp:253]     Train net output #0: loss = 1.05107 (* 1 = 1.05107 loss)
I0527 05:17:53.210067  1888 sgd_solver.cpp:106] Iteration 214500, lr = 0.0045
I0527 05:18:03.749600  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_215000.caffemodel
I0527 05:18:03.803870  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_215000.solverstate
I0527 05:18:03.837196  1888 solver.cpp:237] Iteration 215000, loss = 0.88835
I0527 05:18:03.837257  1888 solver.cpp:253]     Train net output #0: loss = 0.88835 (* 1 = 0.88835 loss)
I0527 05:18:03.837272  1888 sgd_solver.cpp:106] Iteration 215000, lr = 0.0045
I0527 05:18:14.405412  1888 solver.cpp:237] Iteration 215500, loss = 1.33866
I0527 05:18:14.405453  1888 solver.cpp:253]     Train net output #0: loss = 1.33866 (* 1 = 1.33866 loss)
I0527 05:18:14.405467  1888 sgd_solver.cpp:106] Iteration 215500, lr = 0.0045
I0527 05:18:24.970983  1888 solver.cpp:237] Iteration 216000, loss = 0.89585
I0527 05:18:24.971020  1888 solver.cpp:253]     Train net output #0: loss = 0.89585 (* 1 = 0.89585 loss)
I0527 05:18:24.971035  1888 sgd_solver.cpp:106] Iteration 216000, lr = 0.0045
I0527 05:18:35.520465  1888 solver.cpp:237] Iteration 216500, loss = 0.879454
I0527 05:18:35.520618  1888 solver.cpp:253]     Train net output #0: loss = 0.879454 (* 1 = 0.879454 loss)
I0527 05:18:35.520633  1888 sgd_solver.cpp:106] Iteration 216500, lr = 0.0045
I0527 05:19:08.201304  1888 solver.cpp:237] Iteration 217000, loss = 1.05501
I0527 05:19:08.201478  1888 solver.cpp:253]     Train net output #0: loss = 1.05501 (* 1 = 1.05501 loss)
I0527 05:19:08.201495  1888 sgd_solver.cpp:106] Iteration 217000, lr = 0.0045
I0527 05:19:18.756036  1888 solver.cpp:237] Iteration 217500, loss = 0.958088
I0527 05:19:18.756073  1888 solver.cpp:253]     Train net output #0: loss = 0.958088 (* 1 = 0.958088 loss)
I0527 05:19:18.756088  1888 sgd_solver.cpp:106] Iteration 217500, lr = 0.0045
I0527 05:19:29.326728  1888 solver.cpp:237] Iteration 218000, loss = 1.15088
I0527 05:19:29.326777  1888 solver.cpp:253]     Train net output #0: loss = 1.15088 (* 1 = 1.15088 loss)
I0527 05:19:29.326792  1888 sgd_solver.cpp:106] Iteration 218000, lr = 0.0045
I0527 05:19:39.889564  1888 solver.cpp:237] Iteration 218500, loss = 1.05075
I0527 05:19:39.889703  1888 solver.cpp:253]     Train net output #0: loss = 1.05075 (* 1 = 1.05075 loss)
I0527 05:19:39.889719  1888 sgd_solver.cpp:106] Iteration 218500, lr = 0.0045
I0527 05:19:50.448668  1888 solver.cpp:237] Iteration 219000, loss = 1.0616
I0527 05:19:50.448715  1888 solver.cpp:253]     Train net output #0: loss = 1.0616 (* 1 = 1.0616 loss)
I0527 05:19:50.448729  1888 sgd_solver.cpp:106] Iteration 219000, lr = 0.0045
I0527 05:20:01.015568  1888 solver.cpp:237] Iteration 219500, loss = 1.1391
I0527 05:20:01.015604  1888 solver.cpp:253]     Train net output #0: loss = 1.1391 (* 1 = 1.1391 loss)
I0527 05:20:01.015620  1888 sgd_solver.cpp:106] Iteration 219500, lr = 0.0045
I0527 05:20:11.550160  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_220000.caffemodel
I0527 05:20:11.604233  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_220000.solverstate
I0527 05:20:11.633190  1888 solver.cpp:341] Iteration 220000, Testing net (#0)
I0527 05:21:01.283103  1888 solver.cpp:409]     Test net output #0: accuracy = 0.896919
I0527 05:21:01.283264  1888 solver.cpp:409]     Test net output #1: loss = 0.320793 (* 1 = 0.320793 loss)
I0527 05:21:23.383167  1888 solver.cpp:237] Iteration 220000, loss = 1.0085
I0527 05:21:23.383220  1888 solver.cpp:253]     Train net output #0: loss = 1.0085 (* 1 = 1.0085 loss)
I0527 05:21:23.383237  1888 sgd_solver.cpp:106] Iteration 220000, lr = 0.0045
I0527 05:21:33.913672  1888 solver.cpp:237] Iteration 220500, loss = 1.04217
I0527 05:21:33.913830  1888 solver.cpp:253]     Train net output #0: loss = 1.04217 (* 1 = 1.04217 loss)
I0527 05:21:33.913844  1888 sgd_solver.cpp:106] Iteration 220500, lr = 0.0045
I0527 05:21:44.447204  1888 solver.cpp:237] Iteration 221000, loss = 1.10291
I0527 05:21:44.447240  1888 solver.cpp:253]     Train net output #0: loss = 1.10291 (* 1 = 1.10291 loss)
I0527 05:21:44.447253  1888 sgd_solver.cpp:106] Iteration 221000, lr = 0.0045
I0527 05:21:54.985440  1888 solver.cpp:237] Iteration 221500, loss = 1.05683
I0527 05:21:54.985486  1888 solver.cpp:253]     Train net output #0: loss = 1.05683 (* 1 = 1.05683 loss)
I0527 05:21:54.985504  1888 sgd_solver.cpp:106] Iteration 221500, lr = 0.0045
I0527 05:22:05.521718  1888 solver.cpp:237] Iteration 222000, loss = 0.816467
I0527 05:22:05.521858  1888 solver.cpp:253]     Train net output #0: loss = 0.816467 (* 1 = 0.816467 loss)
I0527 05:22:05.521873  1888 sgd_solver.cpp:106] Iteration 222000, lr = 0.0045
I0527 05:22:16.037058  1888 solver.cpp:237] Iteration 222500, loss = 1.27311
I0527 05:22:16.037094  1888 solver.cpp:253]     Train net output #0: loss = 1.27311 (* 1 = 1.27311 loss)
I0527 05:22:16.037107  1888 sgd_solver.cpp:106] Iteration 222500, lr = 0.0045
I0527 05:22:26.574753  1888 solver.cpp:237] Iteration 223000, loss = 0.950699
I0527 05:22:26.574800  1888 solver.cpp:253]     Train net output #0: loss = 0.950699 (* 1 = 0.950699 loss)
I0527 05:22:26.574815  1888 sgd_solver.cpp:106] Iteration 223000, lr = 0.0045
I0527 05:22:59.240281  1888 solver.cpp:237] Iteration 223500, loss = 1.23991
I0527 05:22:59.240456  1888 solver.cpp:253]     Train net output #0: loss = 1.23991 (* 1 = 1.23991 loss)
I0527 05:22:59.240471  1888 sgd_solver.cpp:106] Iteration 223500, lr = 0.0045
I0527 05:23:09.788141  1888 solver.cpp:237] Iteration 224000, loss = 1.07976
I0527 05:23:09.788177  1888 solver.cpp:253]     Train net output #0: loss = 1.07976 (* 1 = 1.07976 loss)
I0527 05:23:09.788190  1888 sgd_solver.cpp:106] Iteration 224000, lr = 0.0045
I0527 05:23:20.317009  1888 solver.cpp:237] Iteration 224500, loss = 1.20819
I0527 05:23:20.317055  1888 solver.cpp:253]     Train net output #0: loss = 1.20819 (* 1 = 1.20819 loss)
I0527 05:23:20.317070  1888 sgd_solver.cpp:106] Iteration 224500, lr = 0.0045
I0527 05:23:30.836760  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_225000.caffemodel
I0527 05:23:30.892153  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_225000.solverstate
I0527 05:23:30.926400  1888 solver.cpp:237] Iteration 225000, loss = 1.06615
I0527 05:23:30.926446  1888 solver.cpp:253]     Train net output #0: loss = 1.06615 (* 1 = 1.06615 loss)
I0527 05:23:30.926463  1888 sgd_solver.cpp:106] Iteration 225000, lr = 0.0045
I0527 05:23:41.459098  1888 solver.cpp:237] Iteration 225500, loss = 1.44212
I0527 05:23:41.459144  1888 solver.cpp:253]     Train net output #0: loss = 1.44212 (* 1 = 1.44212 loss)
I0527 05:23:41.459158  1888 sgd_solver.cpp:106] Iteration 225500, lr = 0.0045
I0527 05:23:51.988605  1888 solver.cpp:237] Iteration 226000, loss = 1.07693
I0527 05:23:51.988639  1888 solver.cpp:253]     Train net output #0: loss = 1.07693 (* 1 = 1.07693 loss)
I0527 05:23:51.988653  1888 sgd_solver.cpp:106] Iteration 226000, lr = 0.0045
I0527 05:24:02.533536  1888 solver.cpp:237] Iteration 226500, loss = 1.12812
I0527 05:24:02.533695  1888 solver.cpp:253]     Train net output #0: loss = 1.12812 (* 1 = 1.12812 loss)
I0527 05:24:02.533710  1888 sgd_solver.cpp:106] Iteration 226500, lr = 0.0045
I0527 05:24:35.194774  1888 solver.cpp:237] Iteration 227000, loss = 1.14106
I0527 05:24:35.194933  1888 solver.cpp:253]     Train net output #0: loss = 1.14106 (* 1 = 1.14106 loss)
I0527 05:24:35.194949  1888 sgd_solver.cpp:106] Iteration 227000, lr = 0.0045
I0527 05:24:45.727840  1888 solver.cpp:237] Iteration 227500, loss = 1.49843
I0527 05:24:45.727875  1888 solver.cpp:253]     Train net output #0: loss = 1.49843 (* 1 = 1.49843 loss)
I0527 05:24:45.727888  1888 sgd_solver.cpp:106] Iteration 227500, lr = 0.0045
I0527 05:24:56.267447  1888 solver.cpp:237] Iteration 228000, loss = 1.25855
I0527 05:24:56.267494  1888 solver.cpp:253]     Train net output #0: loss = 1.25855 (* 1 = 1.25855 loss)
I0527 05:24:56.267509  1888 sgd_solver.cpp:106] Iteration 228000, lr = 0.0045
I0527 05:25:06.790410  1888 solver.cpp:237] Iteration 228500, loss = 0.811739
I0527 05:25:06.790550  1888 solver.cpp:253]     Train net output #0: loss = 0.811739 (* 1 = 0.811739 loss)
I0527 05:25:06.790565  1888 sgd_solver.cpp:106] Iteration 228500, lr = 0.0045
I0527 05:25:17.333019  1888 solver.cpp:237] Iteration 229000, loss = 1.07646
I0527 05:25:17.333067  1888 solver.cpp:253]     Train net output #0: loss = 1.07646 (* 1 = 1.07646 loss)
I0527 05:25:17.333082  1888 sgd_solver.cpp:106] Iteration 229000, lr = 0.0045
I0527 05:25:27.835494  1888 solver.cpp:237] Iteration 229500, loss = 1.17305
I0527 05:25:27.835530  1888 solver.cpp:253]     Train net output #0: loss = 1.17305 (* 1 = 1.17305 loss)
I0527 05:25:27.835546  1888 sgd_solver.cpp:106] Iteration 229500, lr = 0.0045
I0527 05:25:38.330066  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_230000.caffemodel
I0527 05:25:38.384692  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_230000.solverstate
I0527 05:25:38.412480  1888 solver.cpp:341] Iteration 230000, Testing net (#0)
I0527 05:26:48.735594  1888 solver.cpp:409]     Test net output #0: accuracy = 0.902298
I0527 05:26:48.735756  1888 solver.cpp:409]     Test net output #1: loss = 0.323459 (* 1 = 0.323459 loss)
I0527 05:27:10.832756  1888 solver.cpp:237] Iteration 230000, loss = 0.964245
I0527 05:27:10.832810  1888 solver.cpp:253]     Train net output #0: loss = 0.964245 (* 1 = 0.964245 loss)
I0527 05:27:10.832825  1888 sgd_solver.cpp:106] Iteration 230000, lr = 0.0045
I0527 05:27:21.343463  1888 solver.cpp:237] Iteration 230500, loss = 0.797297
I0527 05:27:21.343622  1888 solver.cpp:253]     Train net output #0: loss = 0.797297 (* 1 = 0.797297 loss)
I0527 05:27:21.343637  1888 sgd_solver.cpp:106] Iteration 230500, lr = 0.0045
I0527 05:27:31.858705  1888 solver.cpp:237] Iteration 231000, loss = 1.33394
I0527 05:27:31.858741  1888 solver.cpp:253]     Train net output #0: loss = 1.33394 (* 1 = 1.33394 loss)
I0527 05:27:31.858753  1888 sgd_solver.cpp:106] Iteration 231000, lr = 0.0045
I0527 05:27:42.381147  1888 solver.cpp:237] Iteration 231500, loss = 1.36384
I0527 05:27:42.381183  1888 solver.cpp:253]     Train net output #0: loss = 1.36384 (* 1 = 1.36384 loss)
I0527 05:27:42.381197  1888 sgd_solver.cpp:106] Iteration 231500, lr = 0.0045
I0527 05:27:52.888905  1888 solver.cpp:237] Iteration 232000, loss = 1.29414
I0527 05:27:52.889050  1888 solver.cpp:253]     Train net output #0: loss = 1.29414 (* 1 = 1.29414 loss)
I0527 05:27:52.889065  1888 sgd_solver.cpp:106] Iteration 232000, lr = 0.0045
I0527 05:28:03.404952  1888 solver.cpp:237] Iteration 232500, loss = 1.20984
I0527 05:28:03.404986  1888 solver.cpp:253]     Train net output #0: loss = 1.20984 (* 1 = 1.20984 loss)
I0527 05:28:03.405000  1888 sgd_solver.cpp:106] Iteration 232500, lr = 0.0045
I0527 05:28:13.924487  1888 solver.cpp:237] Iteration 233000, loss = 1.08794
I0527 05:28:13.924536  1888 solver.cpp:253]     Train net output #0: loss = 1.08794 (* 1 = 1.08794 loss)
I0527 05:28:13.924551  1888 sgd_solver.cpp:106] Iteration 233000, lr = 0.0045
I0527 05:28:46.595875  1888 solver.cpp:237] Iteration 233500, loss = 1.46053
I0527 05:28:46.596037  1888 solver.cpp:253]     Train net output #0: loss = 1.46053 (* 1 = 1.46053 loss)
I0527 05:28:46.596053  1888 sgd_solver.cpp:106] Iteration 233500, lr = 0.0045
I0527 05:28:57.106778  1888 solver.cpp:237] Iteration 234000, loss = 0.827938
I0527 05:28:57.106814  1888 solver.cpp:253]     Train net output #0: loss = 0.827938 (* 1 = 0.827938 loss)
I0527 05:28:57.106830  1888 sgd_solver.cpp:106] Iteration 234000, lr = 0.0045
I0527 05:29:07.655007  1888 solver.cpp:237] Iteration 234500, loss = 0.901096
I0527 05:29:07.655058  1888 solver.cpp:253]     Train net output #0: loss = 0.901096 (* 1 = 0.901096 loss)
I0527 05:29:07.655072  1888 sgd_solver.cpp:106] Iteration 234500, lr = 0.0045
I0527 05:29:18.179389  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_235000.caffemodel
I0527 05:29:18.234323  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_235000.solverstate
I0527 05:29:18.268535  1888 solver.cpp:237] Iteration 235000, loss = 0.934678
I0527 05:29:18.268582  1888 solver.cpp:253]     Train net output #0: loss = 0.934678 (* 1 = 0.934678 loss)
I0527 05:29:18.268600  1888 sgd_solver.cpp:106] Iteration 235000, lr = 0.0045
I0527 05:29:28.823688  1888 solver.cpp:237] Iteration 235500, loss = 1.25599
I0527 05:29:28.823737  1888 solver.cpp:253]     Train net output #0: loss = 1.25599 (* 1 = 1.25599 loss)
I0527 05:29:28.823751  1888 sgd_solver.cpp:106] Iteration 235500, lr = 0.0045
I0527 05:29:39.393355  1888 solver.cpp:237] Iteration 236000, loss = 0.97898
I0527 05:29:39.393393  1888 solver.cpp:253]     Train net output #0: loss = 0.978979 (* 1 = 0.978979 loss)
I0527 05:29:39.393409  1888 sgd_solver.cpp:106] Iteration 236000, lr = 0.0045
I0527 05:29:49.953505  1888 solver.cpp:237] Iteration 236500, loss = 1.1005
I0527 05:29:49.953673  1888 solver.cpp:253]     Train net output #0: loss = 1.1005 (* 1 = 1.1005 loss)
I0527 05:29:49.953687  1888 sgd_solver.cpp:106] Iteration 236500, lr = 0.0045
I0527 05:30:22.702051  1888 solver.cpp:237] Iteration 237000, loss = 1.10499
I0527 05:30:22.702224  1888 solver.cpp:253]     Train net output #0: loss = 1.10499 (* 1 = 1.10499 loss)
I0527 05:30:22.702239  1888 sgd_solver.cpp:106] Iteration 237000, lr = 0.0045
I0527 05:30:33.263298  1888 solver.cpp:237] Iteration 237500, loss = 1.26542
I0527 05:30:33.263334  1888 solver.cpp:253]     Train net output #0: loss = 1.26542 (* 1 = 1.26542 loss)
I0527 05:30:33.263348  1888 sgd_solver.cpp:106] Iteration 237500, lr = 0.0045
I0527 05:30:43.817401  1888 solver.cpp:237] Iteration 238000, loss = 1.25376
I0527 05:30:43.817450  1888 solver.cpp:253]     Train net output #0: loss = 1.25376 (* 1 = 1.25376 loss)
I0527 05:30:43.817463  1888 sgd_solver.cpp:106] Iteration 238000, lr = 0.0045
I0527 05:30:54.377815  1888 solver.cpp:237] Iteration 238500, loss = 0.929286
I0527 05:30:54.377956  1888 solver.cpp:253]     Train net output #0: loss = 0.929286 (* 1 = 0.929286 loss)
I0527 05:30:54.377971  1888 sgd_solver.cpp:106] Iteration 238500, lr = 0.0045
I0527 05:31:04.939358  1888 solver.cpp:237] Iteration 239000, loss = 1.34546
I0527 05:31:04.939398  1888 solver.cpp:253]     Train net output #0: loss = 1.34546 (* 1 = 1.34546 loss)
I0527 05:31:04.939411  1888 sgd_solver.cpp:106] Iteration 239000, lr = 0.0045
I0527 05:31:15.488816  1888 solver.cpp:237] Iteration 239500, loss = 1.02765
I0527 05:31:15.488852  1888 solver.cpp:253]     Train net output #0: loss = 1.02765 (* 1 = 1.02765 loss)
I0527 05:31:15.488864  1888 sgd_solver.cpp:106] Iteration 239500, lr = 0.0045
I0527 05:31:26.023993  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_240000.caffemodel
I0527 05:31:26.076503  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_240000.solverstate
I0527 05:31:26.102124  1888 solver.cpp:341] Iteration 240000, Testing net (#0)
I0527 05:32:15.420770  1888 solver.cpp:409]     Test net output #0: accuracy = 0.900044
I0527 05:32:15.420929  1888 solver.cpp:409]     Test net output #1: loss = 0.317911 (* 1 = 0.317911 loss)
I0527 05:32:37.597363  1888 solver.cpp:237] Iteration 240000, loss = 0.92811
I0527 05:32:37.597414  1888 solver.cpp:253]     Train net output #0: loss = 0.92811 (* 1 = 0.92811 loss)
I0527 05:32:37.597434  1888 sgd_solver.cpp:106] Iteration 240000, lr = 0.0045
I0527 05:32:48.161104  1888 solver.cpp:237] Iteration 240500, loss = 0.850586
I0527 05:32:48.161272  1888 solver.cpp:253]     Train net output #0: loss = 0.850586 (* 1 = 0.850586 loss)
I0527 05:32:48.161286  1888 sgd_solver.cpp:106] Iteration 240500, lr = 0.0045
I0527 05:32:58.725903  1888 solver.cpp:237] Iteration 241000, loss = 1.25221
I0527 05:32:58.725939  1888 solver.cpp:253]     Train net output #0: loss = 1.2522 (* 1 = 1.2522 loss)
I0527 05:32:58.725953  1888 sgd_solver.cpp:106] Iteration 241000, lr = 0.0045
I0527 05:33:09.297725  1888 solver.cpp:237] Iteration 241500, loss = 1.22832
I0527 05:33:09.297761  1888 solver.cpp:253]     Train net output #0: loss = 1.22832 (* 1 = 1.22832 loss)
I0527 05:33:09.297778  1888 sgd_solver.cpp:106] Iteration 241500, lr = 0.0045
I0527 05:33:19.885567  1888 solver.cpp:237] Iteration 242000, loss = 0.983838
I0527 05:33:19.885720  1888 solver.cpp:253]     Train net output #0: loss = 0.983837 (* 1 = 0.983837 loss)
I0527 05:33:19.885735  1888 sgd_solver.cpp:106] Iteration 242000, lr = 0.0045
I0527 05:33:30.480463  1888 solver.cpp:237] Iteration 242500, loss = 1.35572
I0527 05:33:30.480499  1888 solver.cpp:253]     Train net output #0: loss = 1.35572 (* 1 = 1.35572 loss)
I0527 05:33:30.480516  1888 sgd_solver.cpp:106] Iteration 242500, lr = 0.0045
I0527 05:33:41.068878  1888 solver.cpp:237] Iteration 243000, loss = 0.811422
I0527 05:33:41.068923  1888 solver.cpp:253]     Train net output #0: loss = 0.811421 (* 1 = 0.811421 loss)
I0527 05:33:41.068939  1888 sgd_solver.cpp:106] Iteration 243000, lr = 0.0045
I0527 05:34:13.795914  1888 solver.cpp:237] Iteration 243500, loss = 1.00141
I0527 05:34:13.796097  1888 solver.cpp:253]     Train net output #0: loss = 1.00141 (* 1 = 1.00141 loss)
I0527 05:34:13.796113  1888 sgd_solver.cpp:106] Iteration 243500, lr = 0.0045
I0527 05:34:24.361580  1888 solver.cpp:237] Iteration 244000, loss = 0.843591
I0527 05:34:24.361616  1888 solver.cpp:253]     Train net output #0: loss = 0.843591 (* 1 = 0.843591 loss)
I0527 05:34:24.361630  1888 sgd_solver.cpp:106] Iteration 244000, lr = 0.0045
I0527 05:34:34.952111  1888 solver.cpp:237] Iteration 244500, loss = 1.27523
I0527 05:34:34.952154  1888 solver.cpp:253]     Train net output #0: loss = 1.27523 (* 1 = 1.27523 loss)
I0527 05:34:34.952170  1888 sgd_solver.cpp:106] Iteration 244500, lr = 0.0045
I0527 05:34:45.529942  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_245000.caffemodel
I0527 05:34:45.582494  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_245000.solverstate
I0527 05:34:45.615097  1888 solver.cpp:237] Iteration 245000, loss = 1.45821
I0527 05:34:45.615142  1888 solver.cpp:253]     Train net output #0: loss = 1.45821 (* 1 = 1.45821 loss)
I0527 05:34:45.615157  1888 sgd_solver.cpp:106] Iteration 245000, lr = 0.0045
I0527 05:34:56.201840  1888 solver.cpp:237] Iteration 245500, loss = 1.1565
I0527 05:34:56.201886  1888 solver.cpp:253]     Train net output #0: loss = 1.1565 (* 1 = 1.1565 loss)
I0527 05:34:56.201900  1888 sgd_solver.cpp:106] Iteration 245500, lr = 0.0045
I0527 05:35:06.780707  1888 solver.cpp:237] Iteration 246000, loss = 0.671131
I0527 05:35:06.780745  1888 solver.cpp:253]     Train net output #0: loss = 0.671131 (* 1 = 0.671131 loss)
I0527 05:35:06.780761  1888 sgd_solver.cpp:106] Iteration 246000, lr = 0.0045
I0527 05:35:17.358773  1888 solver.cpp:237] Iteration 246500, loss = 1.04069
I0527 05:35:17.358943  1888 solver.cpp:253]     Train net output #0: loss = 1.04069 (* 1 = 1.04069 loss)
I0527 05:35:17.358959  1888 sgd_solver.cpp:106] Iteration 246500, lr = 0.0045
I0527 05:35:50.105037  1888 solver.cpp:237] Iteration 247000, loss = 1.14088
I0527 05:35:50.105207  1888 solver.cpp:253]     Train net output #0: loss = 1.14088 (* 1 = 1.14088 loss)
I0527 05:35:50.105222  1888 sgd_solver.cpp:106] Iteration 247000, lr = 0.0045
I0527 05:36:00.671632  1888 solver.cpp:237] Iteration 247500, loss = 1.35153
I0527 05:36:00.671669  1888 solver.cpp:253]     Train net output #0: loss = 1.35153 (* 1 = 1.35153 loss)
I0527 05:36:00.671681  1888 sgd_solver.cpp:106] Iteration 247500, lr = 0.0045
I0527 05:36:11.216213  1888 solver.cpp:237] Iteration 248000, loss = 1.11269
I0527 05:36:11.216264  1888 solver.cpp:253]     Train net output #0: loss = 1.11269 (* 1 = 1.11269 loss)
I0527 05:36:11.216276  1888 sgd_solver.cpp:106] Iteration 248000, lr = 0.0045
I0527 05:36:21.760313  1888 solver.cpp:237] Iteration 248500, loss = 1.28545
I0527 05:36:21.760457  1888 solver.cpp:253]     Train net output #0: loss = 1.28545 (* 1 = 1.28545 loss)
I0527 05:36:21.760473  1888 sgd_solver.cpp:106] Iteration 248500, lr = 0.0045
I0527 05:36:32.319550  1888 solver.cpp:237] Iteration 249000, loss = 1.24529
I0527 05:36:32.319597  1888 solver.cpp:253]     Train net output #0: loss = 1.24529 (* 1 = 1.24529 loss)
I0527 05:36:32.319612  1888 sgd_solver.cpp:106] Iteration 249000, lr = 0.0045
I0527 05:36:42.871523  1888 solver.cpp:237] Iteration 249500, loss = 1.10813
I0527 05:36:42.871559  1888 solver.cpp:253]     Train net output #0: loss = 1.10813 (* 1 = 1.10813 loss)
I0527 05:36:42.871572  1888 sgd_solver.cpp:106] Iteration 249500, lr = 0.0045
I0527 05:36:53.409610  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_250000.caffemodel
I0527 05:36:53.462086  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_250000.solverstate
I0527 05:36:53.490201  1888 solver.cpp:341] Iteration 250000, Testing net (#0)
I0527 05:38:03.951040  1888 solver.cpp:409]     Test net output #0: accuracy = 0.896385
I0527 05:38:03.951203  1888 solver.cpp:409]     Test net output #1: loss = 0.313506 (* 1 = 0.313506 loss)
I0527 05:38:26.106014  1888 solver.cpp:237] Iteration 250000, loss = 1.24711
I0527 05:38:26.106067  1888 solver.cpp:253]     Train net output #0: loss = 1.24711 (* 1 = 1.24711 loss)
I0527 05:38:26.106082  1888 sgd_solver.cpp:106] Iteration 250000, lr = 0.0045
I0527 05:38:36.636006  1888 solver.cpp:237] Iteration 250500, loss = 0.788036
I0527 05:38:36.636174  1888 solver.cpp:253]     Train net output #0: loss = 0.788035 (* 1 = 0.788035 loss)
I0527 05:38:36.636189  1888 sgd_solver.cpp:106] Iteration 250500, lr = 0.0045
I0527 05:38:47.189327  1888 solver.cpp:237] Iteration 251000, loss = 1.0308
I0527 05:38:47.189363  1888 solver.cpp:253]     Train net output #0: loss = 1.0308 (* 1 = 1.0308 loss)
I0527 05:38:47.189379  1888 sgd_solver.cpp:106] Iteration 251000, lr = 0.0045
I0527 05:38:57.747826  1888 solver.cpp:237] Iteration 251500, loss = 1.12495
I0527 05:38:57.747862  1888 solver.cpp:253]     Train net output #0: loss = 1.12495 (* 1 = 1.12495 loss)
I0527 05:38:57.747875  1888 sgd_solver.cpp:106] Iteration 251500, lr = 0.0045
I0527 05:39:08.314426  1888 solver.cpp:237] Iteration 252000, loss = 1.12549
I0527 05:39:08.314581  1888 solver.cpp:253]     Train net output #0: loss = 1.12549 (* 1 = 1.12549 loss)
I0527 05:39:08.314597  1888 sgd_solver.cpp:106] Iteration 252000, lr = 0.0045
I0527 05:39:18.875743  1888 solver.cpp:237] Iteration 252500, loss = 0.758833
I0527 05:39:18.875782  1888 solver.cpp:253]     Train net output #0: loss = 0.758833 (* 1 = 0.758833 loss)
I0527 05:39:18.875797  1888 sgd_solver.cpp:106] Iteration 252500, lr = 0.0045
I0527 05:39:29.428211  1888 solver.cpp:237] Iteration 253000, loss = 1.1269
I0527 05:39:29.428259  1888 solver.cpp:253]     Train net output #0: loss = 1.1269 (* 1 = 1.1269 loss)
I0527 05:39:29.428272  1888 sgd_solver.cpp:106] Iteration 253000, lr = 0.0045
I0527 05:40:02.165338  1888 solver.cpp:237] Iteration 253500, loss = 1.09284
I0527 05:40:02.165505  1888 solver.cpp:253]     Train net output #0: loss = 1.09284 (* 1 = 1.09284 loss)
I0527 05:40:02.165519  1888 sgd_solver.cpp:106] Iteration 253500, lr = 0.0045
I0527 05:40:12.730998  1888 solver.cpp:237] Iteration 254000, loss = 1.18041
I0527 05:40:12.731034  1888 solver.cpp:253]     Train net output #0: loss = 1.18041 (* 1 = 1.18041 loss)
I0527 05:40:12.731046  1888 sgd_solver.cpp:106] Iteration 254000, lr = 0.0045
I0527 05:40:23.304400  1888 solver.cpp:237] Iteration 254500, loss = 0.919104
I0527 05:40:23.304450  1888 solver.cpp:253]     Train net output #0: loss = 0.919104 (* 1 = 0.919104 loss)
I0527 05:40:23.304463  1888 sgd_solver.cpp:106] Iteration 254500, lr = 0.0045
I0527 05:40:33.838752  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_255000.caffemodel
I0527 05:40:33.893474  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_255000.solverstate
I0527 05:40:33.927628  1888 solver.cpp:237] Iteration 255000, loss = 1.82167
I0527 05:40:33.927678  1888 solver.cpp:253]     Train net output #0: loss = 1.82167 (* 1 = 1.82167 loss)
I0527 05:40:33.927695  1888 sgd_solver.cpp:106] Iteration 255000, lr = 0.0045
I0527 05:40:44.502480  1888 solver.cpp:237] Iteration 255500, loss = 1.06295
I0527 05:40:44.502528  1888 solver.cpp:253]     Train net output #0: loss = 1.06295 (* 1 = 1.06295 loss)
I0527 05:40:44.502542  1888 sgd_solver.cpp:106] Iteration 255500, lr = 0.0045
I0527 05:40:55.063194  1888 solver.cpp:237] Iteration 256000, loss = 1.52678
I0527 05:40:55.063230  1888 solver.cpp:253]     Train net output #0: loss = 1.52678 (* 1 = 1.52678 loss)
I0527 05:40:55.063246  1888 sgd_solver.cpp:106] Iteration 256000, lr = 0.0045
I0527 05:41:05.618804  1888 solver.cpp:237] Iteration 256500, loss = 1.43151
I0527 05:41:05.618979  1888 solver.cpp:253]     Train net output #0: loss = 1.43151 (* 1 = 1.43151 loss)
I0527 05:41:05.618994  1888 sgd_solver.cpp:106] Iteration 256500, lr = 0.0045
I0527 05:41:38.333781  1888 solver.cpp:237] Iteration 257000, loss = 1.24448
I0527 05:41:38.333953  1888 solver.cpp:253]     Train net output #0: loss = 1.24448 (* 1 = 1.24448 loss)
I0527 05:41:38.333969  1888 sgd_solver.cpp:106] Iteration 257000, lr = 0.0045
I0527 05:41:48.893491  1888 solver.cpp:237] Iteration 257500, loss = 1.50585
I0527 05:41:48.893527  1888 solver.cpp:253]     Train net output #0: loss = 1.50585 (* 1 = 1.50585 loss)
I0527 05:41:48.893543  1888 sgd_solver.cpp:106] Iteration 257500, lr = 0.0045
I0527 05:41:59.467126  1888 solver.cpp:237] Iteration 258000, loss = 1.25252
I0527 05:41:59.467178  1888 solver.cpp:253]     Train net output #0: loss = 1.25252 (* 1 = 1.25252 loss)
I0527 05:41:59.467192  1888 sgd_solver.cpp:106] Iteration 258000, lr = 0.0045
I0527 05:42:10.030138  1888 solver.cpp:237] Iteration 258500, loss = 1.24192
I0527 05:42:10.030282  1888 solver.cpp:253]     Train net output #0: loss = 1.24192 (* 1 = 1.24192 loss)
I0527 05:42:10.030297  1888 sgd_solver.cpp:106] Iteration 258500, lr = 0.0045
I0527 05:42:20.595659  1888 solver.cpp:237] Iteration 259000, loss = 1.37785
I0527 05:42:20.595707  1888 solver.cpp:253]     Train net output #0: loss = 1.37785 (* 1 = 1.37785 loss)
I0527 05:42:20.595721  1888 sgd_solver.cpp:106] Iteration 259000, lr = 0.0045
I0527 05:42:31.160980  1888 solver.cpp:237] Iteration 259500, loss = 0.948315
I0527 05:42:31.161017  1888 solver.cpp:253]     Train net output #0: loss = 0.948315 (* 1 = 0.948315 loss)
I0527 05:42:31.161031  1888 sgd_solver.cpp:106] Iteration 259500, lr = 0.0045
I0527 05:42:41.687772  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_260000.caffemodel
I0527 05:42:41.742732  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_260000.solverstate
I0527 05:42:41.770355  1888 solver.cpp:341] Iteration 260000, Testing net (#0)
I0527 05:43:31.401769  1888 solver.cpp:409]     Test net output #0: accuracy = 0.901331
I0527 05:43:31.401935  1888 solver.cpp:409]     Test net output #1: loss = 0.331568 (* 1 = 0.331568 loss)
I0527 05:43:52.270084  1888 solver.cpp:237] Iteration 260000, loss = 0.823882
I0527 05:43:52.270139  1888 solver.cpp:253]     Train net output #0: loss = 0.823882 (* 1 = 0.823882 loss)
I0527 05:43:52.270154  1888 sgd_solver.cpp:106] Iteration 260000, lr = 0.0045
I0527 05:44:02.810109  1888 solver.cpp:237] Iteration 260500, loss = 0.883281
I0527 05:44:02.810276  1888 solver.cpp:253]     Train net output #0: loss = 0.883281 (* 1 = 0.883281 loss)
I0527 05:44:02.810291  1888 sgd_solver.cpp:106] Iteration 260500, lr = 0.0045
I0527 05:44:13.324982  1888 solver.cpp:237] Iteration 261000, loss = 1.47417
I0527 05:44:13.325017  1888 solver.cpp:253]     Train net output #0: loss = 1.47417 (* 1 = 1.47417 loss)
I0527 05:44:13.325034  1888 sgd_solver.cpp:106] Iteration 261000, lr = 0.0045
I0527 05:44:23.863317  1888 solver.cpp:237] Iteration 261500, loss = 1.39921
I0527 05:44:23.863353  1888 solver.cpp:253]     Train net output #0: loss = 1.39921 (* 1 = 1.39921 loss)
I0527 05:44:23.863370  1888 sgd_solver.cpp:106] Iteration 261500, lr = 0.0045
I0527 05:44:34.379402  1888 solver.cpp:237] Iteration 262000, loss = 0.926531
I0527 05:44:34.379577  1888 solver.cpp:253]     Train net output #0: loss = 0.926531 (* 1 = 0.926531 loss)
I0527 05:44:34.379593  1888 sgd_solver.cpp:106] Iteration 262000, lr = 0.0045
I0527 05:44:44.917608  1888 solver.cpp:237] Iteration 262500, loss = 1.34666
I0527 05:44:44.917644  1888 solver.cpp:253]     Train net output #0: loss = 1.34666 (* 1 = 1.34666 loss)
I0527 05:44:44.917657  1888 sgd_solver.cpp:106] Iteration 262500, lr = 0.0045
I0527 05:44:55.450909  1888 solver.cpp:237] Iteration 263000, loss = 1.06812
I0527 05:44:55.450951  1888 solver.cpp:253]     Train net output #0: loss = 1.06812 (* 1 = 1.06812 loss)
I0527 05:44:55.450968  1888 sgd_solver.cpp:106] Iteration 263000, lr = 0.0045
I0527 05:45:26.832481  1888 solver.cpp:237] Iteration 263500, loss = 0.752662
I0527 05:45:26.832650  1888 solver.cpp:253]     Train net output #0: loss = 0.752662 (* 1 = 0.752662 loss)
I0527 05:45:26.832666  1888 sgd_solver.cpp:106] Iteration 263500, lr = 0.0045
I0527 05:45:37.364569  1888 solver.cpp:237] Iteration 264000, loss = 1.16244
I0527 05:45:37.364605  1888 solver.cpp:253]     Train net output #0: loss = 1.16244 (* 1 = 1.16244 loss)
I0527 05:45:37.364621  1888 sgd_solver.cpp:106] Iteration 264000, lr = 0.0045
I0527 05:45:47.873594  1888 solver.cpp:237] Iteration 264500, loss = 1.36523
I0527 05:45:47.873636  1888 solver.cpp:253]     Train net output #0: loss = 1.36523 (* 1 = 1.36523 loss)
I0527 05:45:47.873653  1888 sgd_solver.cpp:106] Iteration 264500, lr = 0.0045
I0527 05:45:58.372274  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_265000.caffemodel
I0527 05:45:58.425107  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_265000.solverstate
I0527 05:45:58.457372  1888 solver.cpp:237] Iteration 265000, loss = 1.04734
I0527 05:45:58.457417  1888 solver.cpp:253]     Train net output #0: loss = 1.04734 (* 1 = 1.04734 loss)
I0527 05:45:58.457430  1888 sgd_solver.cpp:106] Iteration 265000, lr = 0.0045
I0527 05:46:08.977612  1888 solver.cpp:237] Iteration 265500, loss = 1.13448
I0527 05:46:08.977659  1888 solver.cpp:253]     Train net output #0: loss = 1.13448 (* 1 = 1.13448 loss)
I0527 05:46:08.977675  1888 sgd_solver.cpp:106] Iteration 265500, lr = 0.0045
I0527 05:46:19.516826  1888 solver.cpp:237] Iteration 266000, loss = 1.30914
I0527 05:46:19.516862  1888 solver.cpp:253]     Train net output #0: loss = 1.30914 (* 1 = 1.30914 loss)
I0527 05:46:19.516880  1888 sgd_solver.cpp:106] Iteration 266000, lr = 0.0045
I0527 05:46:30.032805  1888 solver.cpp:237] Iteration 266500, loss = 1.01362
I0527 05:46:30.032968  1888 solver.cpp:253]     Train net output #0: loss = 1.01362 (* 1 = 1.01362 loss)
I0527 05:46:30.032981  1888 sgd_solver.cpp:106] Iteration 266500, lr = 0.0045
I0527 05:47:01.381438  1888 solver.cpp:237] Iteration 267000, loss = 1.04104
I0527 05:47:01.381603  1888 solver.cpp:253]     Train net output #0: loss = 1.04104 (* 1 = 1.04104 loss)
I0527 05:47:01.381618  1888 sgd_solver.cpp:106] Iteration 267000, lr = 0.0045
I0527 05:47:11.902874  1888 solver.cpp:237] Iteration 267500, loss = 0.95891
I0527 05:47:11.902911  1888 solver.cpp:253]     Train net output #0: loss = 0.95891 (* 1 = 0.95891 loss)
I0527 05:47:11.902925  1888 sgd_solver.cpp:106] Iteration 267500, lr = 0.0045
I0527 05:47:22.433473  1888 solver.cpp:237] Iteration 268000, loss = 1.10653
I0527 05:47:22.433522  1888 solver.cpp:253]     Train net output #0: loss = 1.10653 (* 1 = 1.10653 loss)
I0527 05:47:22.433537  1888 sgd_solver.cpp:106] Iteration 268000, lr = 0.0045
I0527 05:47:32.977512  1888 solver.cpp:237] Iteration 268500, loss = 1.30661
I0527 05:47:32.977674  1888 solver.cpp:253]     Train net output #0: loss = 1.30661 (* 1 = 1.30661 loss)
I0527 05:47:32.977689  1888 sgd_solver.cpp:106] Iteration 268500, lr = 0.0045
I0527 05:47:43.540530  1888 solver.cpp:237] Iteration 269000, loss = 1.29234
I0527 05:47:43.540566  1888 solver.cpp:253]     Train net output #0: loss = 1.29234 (* 1 = 1.29234 loss)
I0527 05:47:43.540580  1888 sgd_solver.cpp:106] Iteration 269000, lr = 0.0045
I0527 05:47:54.105407  1888 solver.cpp:237] Iteration 269500, loss = 1.11682
I0527 05:47:54.105456  1888 solver.cpp:253]     Train net output #0: loss = 1.11682 (* 1 = 1.11682 loss)
I0527 05:47:54.105469  1888 sgd_solver.cpp:106] Iteration 269500, lr = 0.0045
I0527 05:48:04.631956  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_270000.caffemodel
I0527 05:48:04.685283  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_270000.solverstate
I0527 05:48:04.710494  1888 solver.cpp:341] Iteration 270000, Testing net (#0)
I0527 05:49:15.135478  1888 solver.cpp:409]     Test net output #0: accuracy = 0.902752
I0527 05:49:15.135645  1888 solver.cpp:409]     Test net output #1: loss = 0.306522 (* 1 = 0.306522 loss)
I0527 05:49:36.011353  1888 solver.cpp:237] Iteration 270000, loss = 1.23744
I0527 05:49:36.011405  1888 solver.cpp:253]     Train net output #0: loss = 1.23744 (* 1 = 1.23744 loss)
I0527 05:49:36.011420  1888 sgd_solver.cpp:106] Iteration 270000, lr = 0.0045
I0527 05:49:46.567524  1888 solver.cpp:237] Iteration 270500, loss = 1.13093
I0527 05:49:46.567682  1888 solver.cpp:253]     Train net output #0: loss = 1.13093 (* 1 = 1.13093 loss)
I0527 05:49:46.567697  1888 sgd_solver.cpp:106] Iteration 270500, lr = 0.0045
I0527 05:49:57.120057  1888 solver.cpp:237] Iteration 271000, loss = 1.11211
I0527 05:49:57.120101  1888 solver.cpp:253]     Train net output #0: loss = 1.11211 (* 1 = 1.11211 loss)
I0527 05:49:57.120115  1888 sgd_solver.cpp:106] Iteration 271000, lr = 0.0045
I0527 05:50:07.694751  1888 solver.cpp:237] Iteration 271500, loss = 1.25971
I0527 05:50:07.694785  1888 solver.cpp:253]     Train net output #0: loss = 1.25971 (* 1 = 1.25971 loss)
I0527 05:50:07.694802  1888 sgd_solver.cpp:106] Iteration 271500, lr = 0.0045
I0527 05:50:18.261919  1888 solver.cpp:237] Iteration 272000, loss = 1.00731
I0527 05:50:18.262073  1888 solver.cpp:253]     Train net output #0: loss = 1.00731 (* 1 = 1.00731 loss)
I0527 05:50:18.262089  1888 sgd_solver.cpp:106] Iteration 272000, lr = 0.0045
I0527 05:50:28.835396  1888 solver.cpp:237] Iteration 272500, loss = 1.20892
I0527 05:50:28.835430  1888 solver.cpp:253]     Train net output #0: loss = 1.20892 (* 1 = 1.20892 loss)
I0527 05:50:28.835448  1888 sgd_solver.cpp:106] Iteration 272500, lr = 0.0045
I0527 05:50:39.398896  1888 solver.cpp:237] Iteration 273000, loss = 1.26148
I0527 05:50:39.398931  1888 solver.cpp:253]     Train net output #0: loss = 1.26148 (* 1 = 1.26148 loss)
I0527 05:50:39.398944  1888 sgd_solver.cpp:106] Iteration 273000, lr = 0.0045
I0527 05:51:10.881438  1888 solver.cpp:237] Iteration 273500, loss = 1.12526
I0527 05:51:10.881606  1888 solver.cpp:253]     Train net output #0: loss = 1.12526 (* 1 = 1.12526 loss)
I0527 05:51:10.881621  1888 sgd_solver.cpp:106] Iteration 273500, lr = 0.0045
I0527 05:51:21.441951  1888 solver.cpp:237] Iteration 274000, loss = 1.15507
I0527 05:51:21.441987  1888 solver.cpp:253]     Train net output #0: loss = 1.15507 (* 1 = 1.15507 loss)
I0527 05:51:21.442003  1888 sgd_solver.cpp:106] Iteration 274000, lr = 0.0045
I0527 05:51:32.011904  1888 solver.cpp:237] Iteration 274500, loss = 1.54307
I0527 05:51:32.011948  1888 solver.cpp:253]     Train net output #0: loss = 1.54307 (* 1 = 1.54307 loss)
I0527 05:51:32.011962  1888 sgd_solver.cpp:106] Iteration 274500, lr = 0.0045
I0527 05:51:42.568686  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_275000.caffemodel
I0527 05:51:42.622694  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_275000.solverstate
I0527 05:51:42.656592  1888 solver.cpp:237] Iteration 275000, loss = 1.18158
I0527 05:51:42.656641  1888 solver.cpp:253]     Train net output #0: loss = 1.18158 (* 1 = 1.18158 loss)
I0527 05:51:42.656657  1888 sgd_solver.cpp:106] Iteration 275000, lr = 0.0045
I0527 05:51:53.227970  1888 solver.cpp:237] Iteration 275500, loss = 1.30158
I0527 05:51:53.228006  1888 solver.cpp:253]     Train net output #0: loss = 1.30158 (* 1 = 1.30158 loss)
I0527 05:51:53.228019  1888 sgd_solver.cpp:106] Iteration 275500, lr = 0.0045
I0527 05:52:03.787503  1888 solver.cpp:237] Iteration 276000, loss = 0.752428
I0527 05:52:03.787549  1888 solver.cpp:253]     Train net output #0: loss = 0.752428 (* 1 = 0.752428 loss)
I0527 05:52:03.787564  1888 sgd_solver.cpp:106] Iteration 276000, lr = 0.0045
I0527 05:52:14.345772  1888 solver.cpp:237] Iteration 276500, loss = 1.31654
I0527 05:52:14.345927  1888 solver.cpp:253]     Train net output #0: loss = 1.31654 (* 1 = 1.31654 loss)
I0527 05:52:14.345942  1888 sgd_solver.cpp:106] Iteration 276500, lr = 0.0045
I0527 05:52:45.773358  1888 solver.cpp:237] Iteration 277000, loss = 0.848043
I0527 05:52:45.773529  1888 solver.cpp:253]     Train net output #0: loss = 0.848043 (* 1 = 0.848043 loss)
I0527 05:52:45.773542  1888 sgd_solver.cpp:106] Iteration 277000, lr = 0.0045
I0527 05:52:56.304486  1888 solver.cpp:237] Iteration 277500, loss = 1.28337
I0527 05:52:56.304522  1888 solver.cpp:253]     Train net output #0: loss = 1.28337 (* 1 = 1.28337 loss)
I0527 05:52:56.304535  1888 sgd_solver.cpp:106] Iteration 277500, lr = 0.0045
I0527 05:53:06.856951  1888 solver.cpp:237] Iteration 278000, loss = 0.928598
I0527 05:53:06.856987  1888 solver.cpp:253]     Train net output #0: loss = 0.928598 (* 1 = 0.928598 loss)
I0527 05:53:06.857002  1888 sgd_solver.cpp:106] Iteration 278000, lr = 0.0045
I0527 05:53:17.409692  1888 solver.cpp:237] Iteration 278500, loss = 1.05871
I0527 05:53:17.409857  1888 solver.cpp:253]     Train net output #0: loss = 1.05871 (* 1 = 1.05871 loss)
I0527 05:53:17.409871  1888 sgd_solver.cpp:106] Iteration 278500, lr = 0.0045
I0527 05:53:27.965214  1888 solver.cpp:237] Iteration 279000, loss = 1.222
I0527 05:53:27.965260  1888 solver.cpp:253]     Train net output #0: loss = 1.222 (* 1 = 1.222 loss)
I0527 05:53:27.965276  1888 sgd_solver.cpp:106] Iteration 279000, lr = 0.0045
I0527 05:53:38.509196  1888 solver.cpp:237] Iteration 279500, loss = 0.869108
I0527 05:53:38.509243  1888 solver.cpp:253]     Train net output #0: loss = 0.869108 (* 1 = 0.869108 loss)
I0527 05:53:38.509263  1888 sgd_solver.cpp:106] Iteration 279500, lr = 0.0045
I0527 05:53:49.039333  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_280000.caffemodel
I0527 05:53:49.093597  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_280000.solverstate
I0527 05:53:49.120829  1888 solver.cpp:341] Iteration 280000, Testing net (#0)
I0527 05:54:38.413516  1888 solver.cpp:409]     Test net output #0: accuracy = 0.900085
I0527 05:54:38.413693  1888 solver.cpp:409]     Test net output #1: loss = 0.356123 (* 1 = 0.356123 loss)
I0527 05:54:59.293684  1888 solver.cpp:237] Iteration 280000, loss = 0.942836
I0527 05:54:59.293736  1888 solver.cpp:253]     Train net output #0: loss = 0.942836 (* 1 = 0.942836 loss)
I0527 05:54:59.293753  1888 sgd_solver.cpp:106] Iteration 280000, lr = 0.0045
I0527 05:55:09.840708  1888 solver.cpp:237] Iteration 280500, loss = 0.87074
I0527 05:55:09.840880  1888 solver.cpp:253]     Train net output #0: loss = 0.87074 (* 1 = 0.87074 loss)
I0527 05:55:09.840895  1888 sgd_solver.cpp:106] Iteration 280500, lr = 0.0045
I0527 05:55:20.387346  1888 solver.cpp:237] Iteration 281000, loss = 1.50581
I0527 05:55:20.387392  1888 solver.cpp:253]     Train net output #0: loss = 1.50581 (* 1 = 1.50581 loss)
I0527 05:55:20.387406  1888 sgd_solver.cpp:106] Iteration 281000, lr = 0.0045
I0527 05:55:30.934434  1888 solver.cpp:237] Iteration 281500, loss = 1.17817
I0527 05:55:30.934470  1888 solver.cpp:253]     Train net output #0: loss = 1.17817 (* 1 = 1.17817 loss)
I0527 05:55:30.934484  1888 sgd_solver.cpp:106] Iteration 281500, lr = 0.0045
I0527 05:55:41.483307  1888 solver.cpp:237] Iteration 282000, loss = 1.18072
I0527 05:55:41.483476  1888 solver.cpp:253]     Train net output #0: loss = 1.18072 (* 1 = 1.18072 loss)
I0527 05:55:41.483491  1888 sgd_solver.cpp:106] Iteration 282000, lr = 0.0045
I0527 05:55:52.039685  1888 solver.cpp:237] Iteration 282500, loss = 1.6191
I0527 05:55:52.039721  1888 solver.cpp:253]     Train net output #0: loss = 1.6191 (* 1 = 1.6191 loss)
I0527 05:55:52.039734  1888 sgd_solver.cpp:106] Iteration 282500, lr = 0.0045
I0527 05:56:02.599766  1888 solver.cpp:237] Iteration 283000, loss = 1.4529
I0527 05:56:02.599802  1888 solver.cpp:253]     Train net output #0: loss = 1.4529 (* 1 = 1.4529 loss)
I0527 05:56:02.599815  1888 sgd_solver.cpp:106] Iteration 283000, lr = 0.0045
I0527 05:56:34.014973  1888 solver.cpp:237] Iteration 283500, loss = 1.187
I0527 05:56:34.015148  1888 solver.cpp:253]     Train net output #0: loss = 1.187 (* 1 = 1.187 loss)
I0527 05:56:34.015164  1888 sgd_solver.cpp:106] Iteration 283500, lr = 0.0045
I0527 05:56:44.564648  1888 solver.cpp:237] Iteration 284000, loss = 1.19355
I0527 05:56:44.564683  1888 solver.cpp:253]     Train net output #0: loss = 1.19355 (* 1 = 1.19355 loss)
I0527 05:56:44.564697  1888 sgd_solver.cpp:106] Iteration 284000, lr = 0.0045
I0527 05:56:55.123803  1888 solver.cpp:237] Iteration 284500, loss = 1.12703
I0527 05:56:55.123852  1888 solver.cpp:253]     Train net output #0: loss = 1.12703 (* 1 = 1.12703 loss)
I0527 05:56:55.123867  1888 sgd_solver.cpp:106] Iteration 284500, lr = 0.0045
I0527 05:57:05.662091  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_285000.caffemodel
I0527 05:57:05.717998  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_285000.solverstate
I0527 05:57:05.752276  1888 solver.cpp:237] Iteration 285000, loss = 1.62533
I0527 05:57:05.752326  1888 solver.cpp:253]     Train net output #0: loss = 1.62533 (* 1 = 1.62533 loss)
I0527 05:57:05.752341  1888 sgd_solver.cpp:106] Iteration 285000, lr = 0.0045
I0527 05:57:16.317044  1888 solver.cpp:237] Iteration 285500, loss = 0.978315
I0527 05:57:16.317080  1888 solver.cpp:253]     Train net output #0: loss = 0.978316 (* 1 = 0.978316 loss)
I0527 05:57:16.317095  1888 sgd_solver.cpp:106] Iteration 285500, lr = 0.0045
I0527 05:57:26.867910  1888 solver.cpp:237] Iteration 286000, loss = 1.33725
I0527 05:57:26.867959  1888 solver.cpp:253]     Train net output #0: loss = 1.33725 (* 1 = 1.33725 loss)
I0527 05:57:26.867976  1888 sgd_solver.cpp:106] Iteration 286000, lr = 0.0045
I0527 05:57:37.439384  1888 solver.cpp:237] Iteration 286500, loss = 1.40718
I0527 05:57:37.439541  1888 solver.cpp:253]     Train net output #0: loss = 1.40718 (* 1 = 1.40718 loss)
I0527 05:57:37.439556  1888 sgd_solver.cpp:106] Iteration 286500, lr = 0.0045
I0527 05:58:08.868752  1888 solver.cpp:237] Iteration 287000, loss = 1.09969
I0527 05:58:08.868923  1888 solver.cpp:253]     Train net output #0: loss = 1.09969 (* 1 = 1.09969 loss)
I0527 05:58:08.868939  1888 sgd_solver.cpp:106] Iteration 287000, lr = 0.0045
I0527 05:58:19.438413  1888 solver.cpp:237] Iteration 287500, loss = 1.03241
I0527 05:58:19.438459  1888 solver.cpp:253]     Train net output #0: loss = 1.03241 (* 1 = 1.03241 loss)
I0527 05:58:19.438474  1888 sgd_solver.cpp:106] Iteration 287500, lr = 0.0045
I0527 05:58:29.997824  1888 solver.cpp:237] Iteration 288000, loss = 1.47443
I0527 05:58:29.997860  1888 solver.cpp:253]     Train net output #0: loss = 1.47443 (* 1 = 1.47443 loss)
I0527 05:58:29.997876  1888 sgd_solver.cpp:106] Iteration 288000, lr = 0.0045
I0527 05:58:40.565289  1888 solver.cpp:237] Iteration 288500, loss = 1.02901
I0527 05:58:40.565470  1888 solver.cpp:253]     Train net output #0: loss = 1.02901 (* 1 = 1.02901 loss)
I0527 05:58:40.565485  1888 sgd_solver.cpp:106] Iteration 288500, lr = 0.0045
I0527 05:58:51.115743  1888 solver.cpp:237] Iteration 289000, loss = 1.07801
I0527 05:58:51.115779  1888 solver.cpp:253]     Train net output #0: loss = 1.07801 (* 1 = 1.07801 loss)
I0527 05:58:51.115792  1888 sgd_solver.cpp:106] Iteration 289000, lr = 0.0045
I0527 05:59:01.665999  1888 solver.cpp:237] Iteration 289500, loss = 1.02682
I0527 05:59:01.666048  1888 solver.cpp:253]     Train net output #0: loss = 1.02682 (* 1 = 1.02682 loss)
I0527 05:59:01.666064  1888 sgd_solver.cpp:106] Iteration 289500, lr = 0.0045
I0527 05:59:12.201375  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_290000.caffemodel
I0527 05:59:12.254456  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_290000.solverstate
I0527 05:59:12.280092  1888 solver.cpp:341] Iteration 290000, Testing net (#0)
I0527 06:00:22.782632  1888 solver.cpp:409]     Test net output #0: accuracy = 0.90489
I0527 06:00:22.782809  1888 solver.cpp:409]     Test net output #1: loss = 0.321178 (* 1 = 0.321178 loss)
I0527 06:00:43.653970  1888 solver.cpp:237] Iteration 290000, loss = 1.07026
I0527 06:00:43.654021  1888 solver.cpp:253]     Train net output #0: loss = 1.07026 (* 1 = 1.07026 loss)
I0527 06:00:43.654038  1888 sgd_solver.cpp:106] Iteration 290000, lr = 0.0045
I0527 06:00:54.268070  1888 solver.cpp:237] Iteration 290500, loss = 1.18053
I0527 06:00:54.268226  1888 solver.cpp:253]     Train net output #0: loss = 1.18053 (* 1 = 1.18053 loss)
I0527 06:00:54.268240  1888 sgd_solver.cpp:106] Iteration 290500, lr = 0.0045
I0527 06:01:04.877941  1888 solver.cpp:237] Iteration 291000, loss = 1.4066
I0527 06:01:04.877988  1888 solver.cpp:253]     Train net output #0: loss = 1.4066 (* 1 = 1.4066 loss)
I0527 06:01:04.878011  1888 sgd_solver.cpp:106] Iteration 291000, lr = 0.0045
I0527 06:01:15.492480  1888 solver.cpp:237] Iteration 291500, loss = 1.02164
I0527 06:01:15.492516  1888 solver.cpp:253]     Train net output #0: loss = 1.02164 (* 1 = 1.02164 loss)
I0527 06:01:15.492533  1888 sgd_solver.cpp:106] Iteration 291500, lr = 0.0045
I0527 06:01:26.092285  1888 solver.cpp:237] Iteration 292000, loss = 1.11087
I0527 06:01:26.092438  1888 solver.cpp:253]     Train net output #0: loss = 1.11087 (* 1 = 1.11087 loss)
I0527 06:01:26.092454  1888 sgd_solver.cpp:106] Iteration 292000, lr = 0.0045
I0527 06:01:36.687537  1888 solver.cpp:237] Iteration 292500, loss = 1.15728
I0527 06:01:36.687577  1888 solver.cpp:253]     Train net output #0: loss = 1.15728 (* 1 = 1.15728 loss)
I0527 06:01:36.687590  1888 sgd_solver.cpp:106] Iteration 292500, lr = 0.0045
I0527 06:01:47.292130  1888 solver.cpp:237] Iteration 293000, loss = 0.937024
I0527 06:01:47.292166  1888 solver.cpp:253]     Train net output #0: loss = 0.937024 (* 1 = 0.937024 loss)
I0527 06:01:47.292179  1888 sgd_solver.cpp:106] Iteration 293000, lr = 0.0045
I0527 06:02:18.782126  1888 solver.cpp:237] Iteration 293500, loss = 1.28096
I0527 06:02:18.782300  1888 solver.cpp:253]     Train net output #0: loss = 1.28096 (* 1 = 1.28096 loss)
I0527 06:02:18.782315  1888 sgd_solver.cpp:106] Iteration 293500, lr = 0.0045
I0527 06:02:29.413604  1888 solver.cpp:237] Iteration 294000, loss = 0.967693
I0527 06:02:29.413652  1888 solver.cpp:253]     Train net output #0: loss = 0.967693 (* 1 = 0.967693 loss)
I0527 06:02:29.413666  1888 sgd_solver.cpp:106] Iteration 294000, lr = 0.0045
I0527 06:02:40.016602  1888 solver.cpp:237] Iteration 294500, loss = 1.42104
I0527 06:02:40.016638  1888 solver.cpp:253]     Train net output #0: loss = 1.42104 (* 1 = 1.42104 loss)
I0527 06:02:40.016654  1888 sgd_solver.cpp:106] Iteration 294500, lr = 0.0045
I0527 06:02:50.612800  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_295000.caffemodel
I0527 06:02:50.665011  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_295000.solverstate
I0527 06:02:50.697293  1888 solver.cpp:237] Iteration 295000, loss = 1.20687
I0527 06:02:50.697334  1888 solver.cpp:253]     Train net output #0: loss = 1.20687 (* 1 = 1.20687 loss)
I0527 06:02:50.697356  1888 sgd_solver.cpp:106] Iteration 295000, lr = 0.0045
I0527 06:03:01.315976  1888 solver.cpp:237] Iteration 295500, loss = 0.949307
I0527 06:03:01.316014  1888 solver.cpp:253]     Train net output #0: loss = 0.949307 (* 1 = 0.949307 loss)
I0527 06:03:01.316028  1888 sgd_solver.cpp:106] Iteration 295500, lr = 0.0045
I0527 06:03:11.928722  1888 solver.cpp:237] Iteration 296000, loss = 0.951075
I0527 06:03:11.928768  1888 solver.cpp:253]     Train net output #0: loss = 0.951075 (* 1 = 0.951075 loss)
I0527 06:03:11.928786  1888 sgd_solver.cpp:106] Iteration 296000, lr = 0.0045
I0527 06:03:22.541754  1888 solver.cpp:237] Iteration 296500, loss = 0.599769
I0527 06:03:22.541914  1888 solver.cpp:253]     Train net output #0: loss = 0.599769 (* 1 = 0.599769 loss)
I0527 06:03:22.541929  1888 sgd_solver.cpp:106] Iteration 296500, lr = 0.0045
I0527 06:03:54.048831  1888 solver.cpp:237] Iteration 297000, loss = 1.15974
I0527 06:03:54.049008  1888 solver.cpp:253]     Train net output #0: loss = 1.15974 (* 1 = 1.15974 loss)
I0527 06:03:54.049024  1888 sgd_solver.cpp:106] Iteration 297000, lr = 0.0045
I0527 06:04:04.661778  1888 solver.cpp:237] Iteration 297500, loss = 1.3377
I0527 06:04:04.661826  1888 solver.cpp:253]     Train net output #0: loss = 1.3377 (* 1 = 1.3377 loss)
I0527 06:04:04.661841  1888 sgd_solver.cpp:106] Iteration 297500, lr = 0.0045
I0527 06:04:15.268913  1888 solver.cpp:237] Iteration 298000, loss = 1.19808
I0527 06:04:15.268950  1888 solver.cpp:253]     Train net output #0: loss = 1.19808 (* 1 = 1.19808 loss)
I0527 06:04:15.268964  1888 sgd_solver.cpp:106] Iteration 298000, lr = 0.0045
I0527 06:04:25.867235  1888 solver.cpp:237] Iteration 298500, loss = 0.965788
I0527 06:04:25.867399  1888 solver.cpp:253]     Train net output #0: loss = 0.965789 (* 1 = 0.965789 loss)
I0527 06:04:25.867414  1888 sgd_solver.cpp:106] Iteration 298500, lr = 0.0045
I0527 06:04:36.480680  1888 solver.cpp:237] Iteration 299000, loss = 0.985644
I0527 06:04:36.480717  1888 solver.cpp:253]     Train net output #0: loss = 0.985644 (* 1 = 0.985644 loss)
I0527 06:04:36.480731  1888 sgd_solver.cpp:106] Iteration 299000, lr = 0.0045
I0527 06:04:47.094027  1888 solver.cpp:237] Iteration 299500, loss = 1.50602
I0527 06:04:47.094061  1888 solver.cpp:253]     Train net output #0: loss = 1.50602 (* 1 = 1.50602 loss)
I0527 06:04:47.094079  1888 sgd_solver.cpp:106] Iteration 299500, lr = 0.0045
I0527 06:04:57.696621  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_300000.caffemodel
I0527 06:04:57.752790  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_300000.solverstate
I0527 06:04:57.779909  1888 solver.cpp:341] Iteration 300000, Testing net (#0)
I0527 06:05:47.417651  1888 solver.cpp:409]     Test net output #0: accuracy = 0.904631
I0527 06:05:47.417846  1888 solver.cpp:409]     Test net output #1: loss = 0.306265 (* 1 = 0.306265 loss)
I0527 06:06:08.344542  1888 solver.cpp:237] Iteration 300000, loss = 1.26997
I0527 06:06:08.344596  1888 solver.cpp:253]     Train net output #0: loss = 1.26997 (* 1 = 1.26997 loss)
I0527 06:06:08.344611  1888 sgd_solver.cpp:106] Iteration 300000, lr = 0.0045
I0527 06:06:18.938696  1888 solver.cpp:237] Iteration 300500, loss = 1.19522
I0527 06:06:18.938861  1888 solver.cpp:253]     Train net output #0: loss = 1.19523 (* 1 = 1.19523 loss)
I0527 06:06:18.938876  1888 sgd_solver.cpp:106] Iteration 300500, lr = 0.0045
I0527 06:06:29.545454  1888 solver.cpp:237] Iteration 301000, loss = 1.03302
I0527 06:06:29.545490  1888 solver.cpp:253]     Train net output #0: loss = 1.03302 (* 1 = 1.03302 loss)
I0527 06:06:29.545502  1888 sgd_solver.cpp:106] Iteration 301000, lr = 0.0045
I0527 06:06:40.155223  1888 solver.cpp:237] Iteration 301500, loss = 1.09266
I0527 06:06:40.155270  1888 solver.cpp:253]     Train net output #0: loss = 1.09266 (* 1 = 1.09266 loss)
I0527 06:06:40.155284  1888 sgd_solver.cpp:106] Iteration 301500, lr = 0.0045
I0527 06:06:50.758944  1888 solver.cpp:237] Iteration 302000, loss = 1.2422
I0527 06:06:50.759099  1888 solver.cpp:253]     Train net output #0: loss = 1.2422 (* 1 = 1.2422 loss)
I0527 06:06:50.759115  1888 sgd_solver.cpp:106] Iteration 302000, lr = 0.0045
I0527 06:07:01.355136  1888 solver.cpp:237] Iteration 302500, loss = 1.20752
I0527 06:07:01.355181  1888 solver.cpp:253]     Train net output #0: loss = 1.20752 (* 1 = 1.20752 loss)
I0527 06:07:01.355195  1888 sgd_solver.cpp:106] Iteration 302500, lr = 0.0045
I0527 06:07:11.949352  1888 solver.cpp:237] Iteration 303000, loss = 0.956294
I0527 06:07:11.949388  1888 solver.cpp:253]     Train net output #0: loss = 0.956295 (* 1 = 0.956295 loss)
I0527 06:07:11.949403  1888 sgd_solver.cpp:106] Iteration 303000, lr = 0.0045
I0527 06:07:43.434260  1888 solver.cpp:237] Iteration 303500, loss = 0.837754
I0527 06:07:43.434438  1888 solver.cpp:253]     Train net output #0: loss = 0.837755 (* 1 = 0.837755 loss)
I0527 06:07:43.434453  1888 sgd_solver.cpp:106] Iteration 303500, lr = 0.0045
I0527 06:07:54.033442  1888 solver.cpp:237] Iteration 304000, loss = 1.16102
I0527 06:07:54.033489  1888 solver.cpp:253]     Train net output #0: loss = 1.16102 (* 1 = 1.16102 loss)
I0527 06:07:54.033505  1888 sgd_solver.cpp:106] Iteration 304000, lr = 0.0045
I0527 06:08:04.650106  1888 solver.cpp:237] Iteration 304500, loss = 1.44325
I0527 06:08:04.650143  1888 solver.cpp:253]     Train net output #0: loss = 1.44325 (* 1 = 1.44325 loss)
I0527 06:08:04.650159  1888 sgd_solver.cpp:106] Iteration 304500, lr = 0.0045
I0527 06:08:15.196328  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_305000.caffemodel
I0527 06:08:15.253407  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_305000.solverstate
I0527 06:08:15.287282  1888 solver.cpp:237] Iteration 305000, loss = 1.83534
I0527 06:08:15.287333  1888 solver.cpp:253]     Train net output #0: loss = 1.83534 (* 1 = 1.83534 loss)
I0527 06:08:15.287349  1888 sgd_solver.cpp:106] Iteration 305000, lr = 0.0045
I0527 06:08:25.799868  1888 solver.cpp:237] Iteration 305500, loss = 0.934846
I0527 06:08:25.799906  1888 solver.cpp:253]     Train net output #0: loss = 0.934846 (* 1 = 0.934846 loss)
I0527 06:08:25.799921  1888 sgd_solver.cpp:106] Iteration 305500, lr = 0.0045
I0527 06:08:36.308609  1888 solver.cpp:237] Iteration 306000, loss = 1.22723
I0527 06:08:36.308660  1888 solver.cpp:253]     Train net output #0: loss = 1.22723 (* 1 = 1.22723 loss)
I0527 06:08:36.308676  1888 sgd_solver.cpp:106] Iteration 306000, lr = 0.0045
I0527 06:08:46.819931  1888 solver.cpp:237] Iteration 306500, loss = 1.02494
I0527 06:08:46.820103  1888 solver.cpp:253]     Train net output #0: loss = 1.02494 (* 1 = 1.02494 loss)
I0527 06:08:46.820118  1888 sgd_solver.cpp:106] Iteration 306500, lr = 0.0045
I0527 06:09:18.232204  1888 solver.cpp:237] Iteration 307000, loss = 1.25941
I0527 06:09:18.232388  1888 solver.cpp:253]     Train net output #0: loss = 1.25941 (* 1 = 1.25941 loss)
I0527 06:09:18.232403  1888 sgd_solver.cpp:106] Iteration 307000, lr = 0.0045
I0527 06:09:28.738766  1888 solver.cpp:237] Iteration 307500, loss = 1.23702
I0527 06:09:28.738812  1888 solver.cpp:253]     Train net output #0: loss = 1.23702 (* 1 = 1.23702 loss)
I0527 06:09:28.738826  1888 sgd_solver.cpp:106] Iteration 307500, lr = 0.0045
I0527 06:09:39.242394  1888 solver.cpp:237] Iteration 308000, loss = 1.14437
I0527 06:09:39.242429  1888 solver.cpp:253]     Train net output #0: loss = 1.14437 (* 1 = 1.14437 loss)
I0527 06:09:39.242444  1888 sgd_solver.cpp:106] Iteration 308000, lr = 0.0045
I0527 06:09:49.747093  1888 solver.cpp:237] Iteration 308500, loss = 1.02352
I0527 06:09:49.747251  1888 solver.cpp:253]     Train net output #0: loss = 1.02352 (* 1 = 1.02352 loss)
I0527 06:09:49.747265  1888 sgd_solver.cpp:106] Iteration 308500, lr = 0.0045
I0527 06:10:00.254145  1888 solver.cpp:237] Iteration 309000, loss = 1.05297
I0527 06:10:00.254192  1888 solver.cpp:253]     Train net output #0: loss = 1.05297 (* 1 = 1.05297 loss)
I0527 06:10:00.254207  1888 sgd_solver.cpp:106] Iteration 309000, lr = 0.0045
I0527 06:10:10.764653  1888 solver.cpp:237] Iteration 309500, loss = 1.63406
I0527 06:10:10.764688  1888 solver.cpp:253]     Train net output #0: loss = 1.63406 (* 1 = 1.63406 loss)
I0527 06:10:10.764705  1888 sgd_solver.cpp:106] Iteration 309500, lr = 0.0045
I0527 06:10:21.238029  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_310000.caffemodel
I0527 06:10:21.292845  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_310000.solverstate
I0527 06:10:21.320369  1888 solver.cpp:341] Iteration 310000, Testing net (#0)
I0527 06:11:31.772536  1888 solver.cpp:409]     Test net output #0: accuracy = 0.903324
I0527 06:11:31.772706  1888 solver.cpp:409]     Test net output #1: loss = 0.311305 (* 1 = 0.311305 loss)
I0527 06:11:52.677795  1888 solver.cpp:237] Iteration 310000, loss = 0.961865
I0527 06:11:52.677850  1888 solver.cpp:253]     Train net output #0: loss = 0.961866 (* 1 = 0.961866 loss)
I0527 06:11:52.677865  1888 sgd_solver.cpp:106] Iteration 310000, lr = 0.0045
I0527 06:12:03.199484  1888 solver.cpp:237] Iteration 310500, loss = 0.778377
I0527 06:12:03.199659  1888 solver.cpp:253]     Train net output #0: loss = 0.778378 (* 1 = 0.778378 loss)
I0527 06:12:03.199676  1888 sgd_solver.cpp:106] Iteration 310500, lr = 0.0045
I0527 06:12:13.718994  1888 solver.cpp:237] Iteration 311000, loss = 1.46142
I0527 06:12:13.719029  1888 solver.cpp:253]     Train net output #0: loss = 1.46142 (* 1 = 1.46142 loss)
I0527 06:12:13.719043  1888 sgd_solver.cpp:106] Iteration 311000, lr = 0.0045
I0527 06:12:24.234983  1888 solver.cpp:237] Iteration 311500, loss = 1.11667
I0527 06:12:24.235028  1888 solver.cpp:253]     Train net output #0: loss = 1.11667 (* 1 = 1.11667 loss)
I0527 06:12:24.235040  1888 sgd_solver.cpp:106] Iteration 311500, lr = 0.0045
I0527 06:12:34.750057  1888 solver.cpp:237] Iteration 312000, loss = 1.32674
I0527 06:12:34.750211  1888 solver.cpp:253]     Train net output #0: loss = 1.32674 (* 1 = 1.32674 loss)
I0527 06:12:34.750226  1888 sgd_solver.cpp:106] Iteration 312000, lr = 0.0045
I0527 06:12:45.271730  1888 solver.cpp:237] Iteration 312500, loss = 1.34578
I0527 06:12:45.271778  1888 solver.cpp:253]     Train net output #0: loss = 1.34578 (* 1 = 1.34578 loss)
I0527 06:12:45.271791  1888 sgd_solver.cpp:106] Iteration 312500, lr = 0.0045
I0527 06:12:55.784138  1888 solver.cpp:237] Iteration 313000, loss = 1.56065
I0527 06:12:55.784173  1888 solver.cpp:253]     Train net output #0: loss = 1.56065 (* 1 = 1.56065 loss)
I0527 06:12:55.784188  1888 sgd_solver.cpp:106] Iteration 313000, lr = 0.0045
I0527 06:13:27.155624  1888 solver.cpp:237] Iteration 313500, loss = 1.44133
I0527 06:13:27.155814  1888 solver.cpp:253]     Train net output #0: loss = 1.44134 (* 1 = 1.44134 loss)
I0527 06:13:27.155829  1888 sgd_solver.cpp:106] Iteration 313500, lr = 0.0045
I0527 06:13:37.679826  1888 solver.cpp:237] Iteration 314000, loss = 1.12527
I0527 06:13:37.679872  1888 solver.cpp:253]     Train net output #0: loss = 1.12527 (* 1 = 1.12527 loss)
I0527 06:13:37.679886  1888 sgd_solver.cpp:106] Iteration 314000, lr = 0.0045
I0527 06:13:48.185242  1888 solver.cpp:237] Iteration 314500, loss = 1.42438
I0527 06:13:48.185282  1888 solver.cpp:253]     Train net output #0: loss = 1.42438 (* 1 = 1.42438 loss)
I0527 06:13:48.185295  1888 sgd_solver.cpp:106] Iteration 314500, lr = 0.0045
I0527 06:13:58.672771  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_315000.caffemodel
I0527 06:13:58.725142  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_315000.solverstate
I0527 06:13:58.757146  1888 solver.cpp:237] Iteration 315000, loss = 1.08622
I0527 06:13:58.757197  1888 solver.cpp:253]     Train net output #0: loss = 1.08622 (* 1 = 1.08622 loss)
I0527 06:13:58.757212  1888 sgd_solver.cpp:106] Iteration 315000, lr = 0.0045
I0527 06:14:09.269083  1888 solver.cpp:237] Iteration 315500, loss = 1.07376
I0527 06:14:09.269129  1888 solver.cpp:253]     Train net output #0: loss = 1.07376 (* 1 = 1.07376 loss)
I0527 06:14:09.269142  1888 sgd_solver.cpp:106] Iteration 315500, lr = 0.0045
I0527 06:14:19.780243  1888 solver.cpp:237] Iteration 316000, loss = 0.970438
I0527 06:14:19.780280  1888 solver.cpp:253]     Train net output #0: loss = 0.970438 (* 1 = 0.970438 loss)
I0527 06:14:19.780293  1888 sgd_solver.cpp:106] Iteration 316000, lr = 0.0045
I0527 06:14:30.298612  1888 solver.cpp:237] Iteration 316500, loss = 1.02496
I0527 06:14:30.298787  1888 solver.cpp:253]     Train net output #0: loss = 1.02496 (* 1 = 1.02496 loss)
I0527 06:14:30.298802  1888 sgd_solver.cpp:106] Iteration 316500, lr = 0.0045
I0527 06:15:01.661872  1888 solver.cpp:237] Iteration 317000, loss = 0.823953
I0527 06:15:01.662050  1888 solver.cpp:253]     Train net output #0: loss = 0.823953 (* 1 = 0.823953 loss)
I0527 06:15:01.662065  1888 sgd_solver.cpp:106] Iteration 317000, lr = 0.0045
I0527 06:15:12.156947  1888 solver.cpp:237] Iteration 317500, loss = 1.10117
I0527 06:15:12.156983  1888 solver.cpp:253]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0527 06:15:12.156999  1888 sgd_solver.cpp:106] Iteration 317500, lr = 0.0045
I0527 06:15:22.660290  1888 solver.cpp:237] Iteration 318000, loss = 0.949656
I0527 06:15:22.660338  1888 solver.cpp:253]     Train net output #0: loss = 0.949657 (* 1 = 0.949657 loss)
I0527 06:15:22.660352  1888 sgd_solver.cpp:106] Iteration 318000, lr = 0.0045
I0527 06:15:33.178210  1888 solver.cpp:237] Iteration 318500, loss = 1.09201
I0527 06:15:33.178366  1888 solver.cpp:253]     Train net output #0: loss = 1.09201 (* 1 = 1.09201 loss)
I0527 06:15:33.178380  1888 sgd_solver.cpp:106] Iteration 318500, lr = 0.0045
I0527 06:15:43.698457  1888 solver.cpp:237] Iteration 319000, loss = 1.17112
I0527 06:15:43.698503  1888 solver.cpp:253]     Train net output #0: loss = 1.17112 (* 1 = 1.17112 loss)
I0527 06:15:43.698519  1888 sgd_solver.cpp:106] Iteration 319000, lr = 0.0045
I0527 06:15:54.216838  1888 solver.cpp:237] Iteration 319500, loss = 1.16733
I0527 06:15:54.216874  1888 solver.cpp:253]     Train net output #0: loss = 1.16733 (* 1 = 1.16733 loss)
I0527 06:15:54.216887  1888 sgd_solver.cpp:106] Iteration 319500, lr = 0.0045
I0527 06:16:04.712301  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_320000.caffemodel
I0527 06:16:04.766080  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_320000.solverstate
I0527 06:16:04.791523  1888 solver.cpp:341] Iteration 320000, Testing net (#0)
I0527 06:16:54.089877  1888 solver.cpp:409]     Test net output #0: accuracy = 0.904685
I0527 06:16:54.090054  1888 solver.cpp:409]     Test net output #1: loss = 0.302459 (* 1 = 0.302459 loss)
I0527 06:17:14.915875  1888 solver.cpp:237] Iteration 320000, loss = 1.13617
I0527 06:17:14.915928  1888 solver.cpp:253]     Train net output #0: loss = 1.13617 (* 1 = 1.13617 loss)
I0527 06:17:14.915943  1888 sgd_solver.cpp:106] Iteration 320000, lr = 0.0045
I0527 06:17:25.484004  1888 solver.cpp:237] Iteration 320500, loss = 0.978875
I0527 06:17:25.484184  1888 solver.cpp:253]     Train net output #0: loss = 0.978876 (* 1 = 0.978876 loss)
I0527 06:17:25.484199  1888 sgd_solver.cpp:106] Iteration 320500, lr = 0.0045
I0527 06:17:36.049378  1888 solver.cpp:237] Iteration 321000, loss = 1.10216
I0527 06:17:36.049413  1888 solver.cpp:253]     Train net output #0: loss = 1.10216 (* 1 = 1.10216 loss)
I0527 06:17:36.049427  1888 sgd_solver.cpp:106] Iteration 321000, lr = 0.0045
I0527 06:17:46.631918  1888 solver.cpp:237] Iteration 321500, loss = 1.39847
I0527 06:17:46.631968  1888 solver.cpp:253]     Train net output #0: loss = 1.39847 (* 1 = 1.39847 loss)
I0527 06:17:46.631981  1888 sgd_solver.cpp:106] Iteration 321500, lr = 0.0045
I0527 06:17:57.194566  1888 solver.cpp:237] Iteration 322000, loss = 0.960927
I0527 06:17:57.194723  1888 solver.cpp:253]     Train net output #0: loss = 0.960928 (* 1 = 0.960928 loss)
I0527 06:17:57.194737  1888 sgd_solver.cpp:106] Iteration 322000, lr = 0.0045
I0527 06:18:07.753324  1888 solver.cpp:237] Iteration 322500, loss = 1.39248
I0527 06:18:07.753360  1888 solver.cpp:253]     Train net output #0: loss = 1.39248 (* 1 = 1.39248 loss)
I0527 06:18:07.753373  1888 sgd_solver.cpp:106] Iteration 322500, lr = 0.0045
I0527 06:18:18.320605  1888 solver.cpp:237] Iteration 323000, loss = 0.898563
I0527 06:18:18.320655  1888 solver.cpp:253]     Train net output #0: loss = 0.898564 (* 1 = 0.898564 loss)
I0527 06:18:18.320670  1888 sgd_solver.cpp:106] Iteration 323000, lr = 0.0045
I0527 06:18:49.755523  1888 solver.cpp:237] Iteration 323500, loss = 1.2419
I0527 06:18:49.755715  1888 solver.cpp:253]     Train net output #0: loss = 1.2419 (* 1 = 1.2419 loss)
I0527 06:18:49.755731  1888 sgd_solver.cpp:106] Iteration 323500, lr = 0.0045
I0527 06:19:00.326380  1888 solver.cpp:237] Iteration 324000, loss = 1.34314
I0527 06:19:00.326431  1888 solver.cpp:253]     Train net output #0: loss = 1.34314 (* 1 = 1.34314 loss)
I0527 06:19:00.326447  1888 sgd_solver.cpp:106] Iteration 324000, lr = 0.0045
I0527 06:19:10.886188  1888 solver.cpp:237] Iteration 324500, loss = 1.62247
I0527 06:19:10.886224  1888 solver.cpp:253]     Train net output #0: loss = 1.62247 (* 1 = 1.62247 loss)
I0527 06:19:10.886242  1888 sgd_solver.cpp:106] Iteration 324500, lr = 0.0045
I0527 06:19:21.428637  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_325000.caffemodel
I0527 06:19:21.482396  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_325000.solverstate
I0527 06:19:21.517475  1888 solver.cpp:237] Iteration 325000, loss = 1.18802
I0527 06:19:21.517525  1888 solver.cpp:253]     Train net output #0: loss = 1.18802 (* 1 = 1.18802 loss)
I0527 06:19:21.517542  1888 sgd_solver.cpp:106] Iteration 325000, lr = 0.0045
I0527 06:19:32.088165  1888 solver.cpp:237] Iteration 325500, loss = 1.00238
I0527 06:19:32.088212  1888 solver.cpp:253]     Train net output #0: loss = 1.00238 (* 1 = 1.00238 loss)
I0527 06:19:32.088225  1888 sgd_solver.cpp:106] Iteration 325500, lr = 0.0045
I0527 06:19:42.663911  1888 solver.cpp:237] Iteration 326000, loss = 1.1729
I0527 06:19:42.663947  1888 solver.cpp:253]     Train net output #0: loss = 1.17291 (* 1 = 1.17291 loss)
I0527 06:19:42.663960  1888 sgd_solver.cpp:106] Iteration 326000, lr = 0.0045
I0527 06:19:53.239460  1888 solver.cpp:237] Iteration 326500, loss = 1.26363
I0527 06:19:53.239650  1888 solver.cpp:253]     Train net output #0: loss = 1.26363 (* 1 = 1.26363 loss)
I0527 06:19:53.239665  1888 sgd_solver.cpp:106] Iteration 326500, lr = 0.0045
I0527 06:20:24.694531  1888 solver.cpp:237] Iteration 327000, loss = 1.16455
I0527 06:20:24.694715  1888 solver.cpp:253]     Train net output #0: loss = 1.16455 (* 1 = 1.16455 loss)
I0527 06:20:24.694730  1888 sgd_solver.cpp:106] Iteration 327000, lr = 0.0045
I0527 06:20:35.261852  1888 solver.cpp:237] Iteration 327500, loss = 1.14054
I0527 06:20:35.261888  1888 solver.cpp:253]     Train net output #0: loss = 1.14055 (* 1 = 1.14055 loss)
I0527 06:20:35.261904  1888 sgd_solver.cpp:106] Iteration 327500, lr = 0.0045
I0527 06:20:45.828331  1888 solver.cpp:237] Iteration 328000, loss = 1.30128
I0527 06:20:45.828377  1888 solver.cpp:253]     Train net output #0: loss = 1.30128 (* 1 = 1.30128 loss)
I0527 06:20:45.828392  1888 sgd_solver.cpp:106] Iteration 328000, lr = 0.0045
I0527 06:20:56.390544  1888 solver.cpp:237] Iteration 328500, loss = 0.801409
I0527 06:20:56.390702  1888 solver.cpp:253]     Train net output #0: loss = 0.801409 (* 1 = 0.801409 loss)
I0527 06:20:56.390717  1888 sgd_solver.cpp:106] Iteration 328500, lr = 0.0045
I0527 06:21:06.940476  1888 solver.cpp:237] Iteration 329000, loss = 1.23492
I0527 06:21:06.940522  1888 solver.cpp:253]     Train net output #0: loss = 1.23492 (* 1 = 1.23492 loss)
I0527 06:21:06.940538  1888 sgd_solver.cpp:106] Iteration 329000, lr = 0.0045
I0527 06:21:17.514606  1888 solver.cpp:237] Iteration 329500, loss = 0.721648
I0527 06:21:17.514642  1888 solver.cpp:253]     Train net output #0: loss = 0.721648 (* 1 = 0.721648 loss)
I0527 06:21:17.514659  1888 sgd_solver.cpp:106] Iteration 329500, lr = 0.0045
I0527 06:21:28.056407  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_330000.caffemodel
I0527 06:21:28.110353  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_330000.solverstate
I0527 06:21:28.137388  1888 solver.cpp:341] Iteration 330000, Testing net (#0)
I0527 06:22:38.654444  1888 solver.cpp:409]     Test net output #0: accuracy = 0.903464
I0527 06:22:38.654623  1888 solver.cpp:409]     Test net output #1: loss = 0.321015 (* 1 = 0.321015 loss)
I0527 06:22:59.559594  1888 solver.cpp:237] Iteration 330000, loss = 0.817288
I0527 06:22:59.559649  1888 solver.cpp:253]     Train net output #0: loss = 0.817288 (* 1 = 0.817288 loss)
I0527 06:22:59.559664  1888 sgd_solver.cpp:106] Iteration 330000, lr = 0.0045
I0527 06:23:10.194571  1888 solver.cpp:237] Iteration 330500, loss = 1.23548
I0527 06:23:10.194749  1888 solver.cpp:253]     Train net output #0: loss = 1.23548 (* 1 = 1.23548 loss)
I0527 06:23:10.194763  1888 sgd_solver.cpp:106] Iteration 330500, lr = 0.0045
I0527 06:23:20.837795  1888 solver.cpp:237] Iteration 331000, loss = 1.53877
I0527 06:23:20.837829  1888 solver.cpp:253]     Train net output #0: loss = 1.53877 (* 1 = 1.53877 loss)
I0527 06:23:20.837843  1888 sgd_solver.cpp:106] Iteration 331000, lr = 0.0045
I0527 06:23:31.477493  1888 solver.cpp:237] Iteration 331500, loss = 1.13993
I0527 06:23:31.477529  1888 solver.cpp:253]     Train net output #0: loss = 1.13993 (* 1 = 1.13993 loss)
I0527 06:23:31.477542  1888 sgd_solver.cpp:106] Iteration 331500, lr = 0.0045
I0527 06:23:42.138867  1888 solver.cpp:237] Iteration 332000, loss = 1.07783
I0527 06:23:42.139050  1888 solver.cpp:253]     Train net output #0: loss = 1.07783 (* 1 = 1.07783 loss)
I0527 06:23:42.139065  1888 sgd_solver.cpp:106] Iteration 332000, lr = 0.0045
I0527 06:23:52.779888  1888 solver.cpp:237] Iteration 332500, loss = 1.19332
I0527 06:23:52.779924  1888 solver.cpp:253]     Train net output #0: loss = 1.19332 (* 1 = 1.19332 loss)
I0527 06:23:52.779938  1888 sgd_solver.cpp:106] Iteration 332500, lr = 0.0045
I0527 06:24:03.427335  1888 solver.cpp:237] Iteration 333000, loss = 0.986671
I0527 06:24:03.427386  1888 solver.cpp:253]     Train net output #0: loss = 0.986672 (* 1 = 0.986672 loss)
I0527 06:24:03.427399  1888 sgd_solver.cpp:106] Iteration 333000, lr = 0.0045
I0527 06:24:34.968384  1888 solver.cpp:237] Iteration 333500, loss = 1.48554
I0527 06:24:34.968562  1888 solver.cpp:253]     Train net output #0: loss = 1.48554 (* 1 = 1.48554 loss)
I0527 06:24:34.968580  1888 sgd_solver.cpp:106] Iteration 333500, lr = 0.0045
I0527 06:24:45.609099  1888 solver.cpp:237] Iteration 334000, loss = 1.13714
I0527 06:24:45.609135  1888 solver.cpp:253]     Train net output #0: loss = 1.13714 (* 1 = 1.13714 loss)
I0527 06:24:45.609149  1888 sgd_solver.cpp:106] Iteration 334000, lr = 0.0045
I0527 06:24:56.253152  1888 solver.cpp:237] Iteration 334500, loss = 1.04184
I0527 06:24:56.253198  1888 solver.cpp:253]     Train net output #0: loss = 1.04184 (* 1 = 1.04184 loss)
I0527 06:24:56.253212  1888 sgd_solver.cpp:106] Iteration 334500, lr = 0.0045
I0527 06:25:06.873098  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_335000.caffemodel
I0527 06:25:06.928213  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_335000.solverstate
I0527 06:25:06.962307  1888 solver.cpp:237] Iteration 335000, loss = 0.91388
I0527 06:25:06.962358  1888 solver.cpp:253]     Train net output #0: loss = 0.913881 (* 1 = 0.913881 loss)
I0527 06:25:06.962373  1888 sgd_solver.cpp:106] Iteration 335000, lr = 0.0045
I0527 06:25:17.607290  1888 solver.cpp:237] Iteration 335500, loss = 1.33237
I0527 06:25:17.607339  1888 solver.cpp:253]     Train net output #0: loss = 1.33237 (* 1 = 1.33237 loss)
I0527 06:25:17.607353  1888 sgd_solver.cpp:106] Iteration 335500, lr = 0.0045
I0527 06:25:28.231834  1888 solver.cpp:237] Iteration 336000, loss = 1.03554
I0527 06:25:28.231869  1888 solver.cpp:253]     Train net output #0: loss = 1.03554 (* 1 = 1.03554 loss)
I0527 06:25:28.231884  1888 sgd_solver.cpp:106] Iteration 336000, lr = 0.0045
I0527 06:25:38.857872  1888 solver.cpp:237] Iteration 336500, loss = 1.33205
I0527 06:25:38.858039  1888 solver.cpp:253]     Train net output #0: loss = 1.33205 (* 1 = 1.33205 loss)
I0527 06:25:38.858052  1888 sgd_solver.cpp:106] Iteration 336500, lr = 0.0045
I0527 06:26:10.386402  1888 solver.cpp:237] Iteration 337000, loss = 1.26744
I0527 06:26:10.386585  1888 solver.cpp:253]     Train net output #0: loss = 1.26744 (* 1 = 1.26744 loss)
I0527 06:26:10.386600  1888 sgd_solver.cpp:106] Iteration 337000, lr = 0.0045
I0527 06:26:21.008420  1888 solver.cpp:237] Iteration 337500, loss = 1.11303
I0527 06:26:21.008456  1888 solver.cpp:253]     Train net output #0: loss = 1.11303 (* 1 = 1.11303 loss)
I0527 06:26:21.008471  1888 sgd_solver.cpp:106] Iteration 337500, lr = 0.0045
I0527 06:26:31.510458  1888 solver.cpp:237] Iteration 338000, loss = 1.27836
I0527 06:26:31.510509  1888 solver.cpp:253]     Train net output #0: loss = 1.27836 (* 1 = 1.27836 loss)
I0527 06:26:31.510524  1888 sgd_solver.cpp:106] Iteration 338000, lr = 0.0045
I0527 06:26:42.021708  1888 solver.cpp:237] Iteration 338500, loss = 0.970799
I0527 06:26:42.021869  1888 solver.cpp:253]     Train net output #0: loss = 0.9708 (* 1 = 0.9708 loss)
I0527 06:26:42.021884  1888 sgd_solver.cpp:106] Iteration 338500, lr = 0.0045
I0527 06:26:52.526531  1888 solver.cpp:237] Iteration 339000, loss = 1.00402
I0527 06:26:52.526566  1888 solver.cpp:253]     Train net output #0: loss = 1.00402 (* 1 = 1.00402 loss)
I0527 06:26:52.526582  1888 sgd_solver.cpp:106] Iteration 339000, lr = 0.0045
I0527 06:27:03.039444  1888 solver.cpp:237] Iteration 339500, loss = 1.16674
I0527 06:27:03.039494  1888 solver.cpp:253]     Train net output #0: loss = 1.16674 (* 1 = 1.16674 loss)
I0527 06:27:03.039510  1888 sgd_solver.cpp:106] Iteration 339500, lr = 0.0045
I0527 06:27:13.526895  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_340000.caffemodel
I0527 06:27:13.579638  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_340000.solverstate
I0527 06:27:13.605288  1888 solver.cpp:341] Iteration 340000, Testing net (#0)
I0527 06:28:03.269909  1888 solver.cpp:409]     Test net output #0: accuracy = 0.904031
I0527 06:28:03.270087  1888 solver.cpp:409]     Test net output #1: loss = 0.312309 (* 1 = 0.312309 loss)
I0527 06:28:24.148077  1888 solver.cpp:237] Iteration 340000, loss = 0.802307
I0527 06:28:24.148131  1888 solver.cpp:253]     Train net output #0: loss = 0.802307 (* 1 = 0.802307 loss)
I0527 06:28:24.148147  1888 sgd_solver.cpp:106] Iteration 340000, lr = 0.0045
I0527 06:28:34.660183  1888 solver.cpp:237] Iteration 340500, loss = 0.733877
I0527 06:28:34.660351  1888 solver.cpp:253]     Train net output #0: loss = 0.733877 (* 1 = 0.733877 loss)
I0527 06:28:34.660367  1888 sgd_solver.cpp:106] Iteration 340500, lr = 0.0045
I0527 06:28:45.180886  1888 solver.cpp:237] Iteration 341000, loss = 1.30538
I0527 06:28:45.180929  1888 solver.cpp:253]     Train net output #0: loss = 1.30538 (* 1 = 1.30538 loss)
I0527 06:28:45.180944  1888 sgd_solver.cpp:106] Iteration 341000, lr = 0.0045
I0527 06:28:55.664216  1888 solver.cpp:237] Iteration 341500, loss = 0.986945
I0527 06:28:55.664252  1888 solver.cpp:253]     Train net output #0: loss = 0.986946 (* 1 = 0.986946 loss)
I0527 06:28:55.664266  1888 sgd_solver.cpp:106] Iteration 341500, lr = 0.0045
I0527 06:29:06.174479  1888 solver.cpp:237] Iteration 342000, loss = 0.690997
I0527 06:29:06.174657  1888 solver.cpp:253]     Train net output #0: loss = 0.690998 (* 1 = 0.690998 loss)
I0527 06:29:06.174674  1888 sgd_solver.cpp:106] Iteration 342000, lr = 0.0045
I0527 06:29:16.693450  1888 solver.cpp:237] Iteration 342500, loss = 1.44103
I0527 06:29:16.693486  1888 solver.cpp:253]     Train net output #0: loss = 1.44103 (* 1 = 1.44103 loss)
I0527 06:29:16.693500  1888 sgd_solver.cpp:106] Iteration 342500, lr = 0.0045
I0527 06:29:27.193455  1888 solver.cpp:237] Iteration 343000, loss = 0.856087
I0527 06:29:27.193507  1888 solver.cpp:253]     Train net output #0: loss = 0.856088 (* 1 = 0.856088 loss)
I0527 06:29:27.193521  1888 sgd_solver.cpp:106] Iteration 343000, lr = 0.0045
I0527 06:29:58.561940  1888 solver.cpp:237] Iteration 343500, loss = 0.94832
I0527 06:29:58.562129  1888 solver.cpp:253]     Train net output #0: loss = 0.948321 (* 1 = 0.948321 loss)
I0527 06:29:58.562145  1888 sgd_solver.cpp:106] Iteration 343500, lr = 0.0045
I0527 06:30:09.069283  1888 solver.cpp:237] Iteration 344000, loss = 1.1915
I0527 06:30:09.069317  1888 solver.cpp:253]     Train net output #0: loss = 1.1915 (* 1 = 1.1915 loss)
I0527 06:30:09.069331  1888 sgd_solver.cpp:106] Iteration 344000, lr = 0.0045
I0527 06:30:19.581362  1888 solver.cpp:237] Iteration 344500, loss = 1.24507
I0527 06:30:19.581408  1888 solver.cpp:253]     Train net output #0: loss = 1.24507 (* 1 = 1.24507 loss)
I0527 06:30:19.581421  1888 sgd_solver.cpp:106] Iteration 344500, lr = 0.0045
I0527 06:30:30.063496  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_345000.caffemodel
I0527 06:30:30.116222  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_345000.solverstate
I0527 06:30:30.148694  1888 solver.cpp:237] Iteration 345000, loss = 1.1725
I0527 06:30:30.148736  1888 solver.cpp:253]     Train net output #0: loss = 1.1725 (* 1 = 1.1725 loss)
I0527 06:30:30.148756  1888 sgd_solver.cpp:106] Iteration 345000, lr = 0.0045
I0527 06:30:40.667533  1888 solver.cpp:237] Iteration 345500, loss = 1.35674
I0527 06:30:40.667580  1888 solver.cpp:253]     Train net output #0: loss = 1.35674 (* 1 = 1.35674 loss)
I0527 06:30:40.667594  1888 sgd_solver.cpp:106] Iteration 345500, lr = 0.0045
I0527 06:30:51.166350  1888 solver.cpp:237] Iteration 346000, loss = 1.75368
I0527 06:30:51.166386  1888 solver.cpp:253]     Train net output #0: loss = 1.75368 (* 1 = 1.75368 loss)
I0527 06:30:51.166399  1888 sgd_solver.cpp:106] Iteration 346000, lr = 0.0045
I0527 06:31:01.676905  1888 solver.cpp:237] Iteration 346500, loss = 0.717113
I0527 06:31:01.677086  1888 solver.cpp:253]     Train net output #0: loss = 0.717113 (* 1 = 0.717113 loss)
I0527 06:31:01.677100  1888 sgd_solver.cpp:106] Iteration 346500, lr = 0.0045
I0527 06:31:33.079046  1888 solver.cpp:237] Iteration 347000, loss = 1.35341
I0527 06:31:33.079234  1888 solver.cpp:253]     Train net output #0: loss = 1.35341 (* 1 = 1.35341 loss)
I0527 06:31:33.079249  1888 sgd_solver.cpp:106] Iteration 347000, lr = 0.0045
I0527 06:31:43.583601  1888 solver.cpp:237] Iteration 347500, loss = 1.44989
I0527 06:31:43.583637  1888 solver.cpp:253]     Train net output #0: loss = 1.44989 (* 1 = 1.44989 loss)
I0527 06:31:43.583652  1888 sgd_solver.cpp:106] Iteration 347500, lr = 0.0045
I0527 06:31:54.094764  1888 solver.cpp:237] Iteration 348000, loss = 1.11431
I0527 06:31:54.094800  1888 solver.cpp:253]     Train net output #0: loss = 1.11431 (* 1 = 1.11431 loss)
I0527 06:31:54.094816  1888 sgd_solver.cpp:106] Iteration 348000, lr = 0.0045
I0527 06:32:04.596990  1888 solver.cpp:237] Iteration 348500, loss = 1.06497
I0527 06:32:04.597170  1888 solver.cpp:253]     Train net output #0: loss = 1.06497 (* 1 = 1.06497 loss)
I0527 06:32:04.597185  1888 sgd_solver.cpp:106] Iteration 348500, lr = 0.0045
I0527 06:32:15.104079  1888 solver.cpp:237] Iteration 349000, loss = 1.2916
I0527 06:32:15.104115  1888 solver.cpp:253]     Train net output #0: loss = 1.2916 (* 1 = 1.2916 loss)
I0527 06:32:15.104128  1888 sgd_solver.cpp:106] Iteration 349000, lr = 0.0045
I0527 06:32:25.606669  1888 solver.cpp:237] Iteration 349500, loss = 1.24041
I0527 06:32:25.606717  1888 solver.cpp:253]     Train net output #0: loss = 1.24041 (* 1 = 1.24041 loss)
I0527 06:32:25.606732  1888 sgd_solver.cpp:106] Iteration 349500, lr = 0.0045
I0527 06:32:36.101531  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_350000.caffemodel
I0527 06:32:36.154702  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_350000.solverstate
I0527 06:32:36.184761  1888 solver.cpp:341] Iteration 350000, Testing net (#0)
I0527 06:33:46.716338  1888 solver.cpp:409]     Test net output #0: accuracy = 0.905277
I0527 06:33:46.716522  1888 solver.cpp:409]     Test net output #1: loss = 0.29667 (* 1 = 0.29667 loss)
I0527 06:34:07.632674  1888 solver.cpp:237] Iteration 350000, loss = 1.29582
I0527 06:34:07.632725  1888 solver.cpp:253]     Train net output #0: loss = 1.29582 (* 1 = 1.29582 loss)
I0527 06:34:07.632741  1888 sgd_solver.cpp:106] Iteration 350000, lr = 0.0045
I0527 06:34:18.176048  1888 solver.cpp:237] Iteration 350500, loss = 0.963788
I0527 06:34:18.176220  1888 solver.cpp:253]     Train net output #0: loss = 0.963788 (* 1 = 0.963788 loss)
I0527 06:34:18.176237  1888 sgd_solver.cpp:106] Iteration 350500, lr = 0.0045
I0527 06:34:28.727128  1888 solver.cpp:237] Iteration 351000, loss = 0.833897
I0527 06:34:28.727174  1888 solver.cpp:253]     Train net output #0: loss = 0.833898 (* 1 = 0.833898 loss)
I0527 06:34:28.727190  1888 sgd_solver.cpp:106] Iteration 351000, lr = 0.0045
I0527 06:34:39.258925  1888 solver.cpp:237] Iteration 351500, loss = 1.03066
I0527 06:34:39.258960  1888 solver.cpp:253]     Train net output #0: loss = 1.03066 (* 1 = 1.03066 loss)
I0527 06:34:39.258975  1888 sgd_solver.cpp:106] Iteration 351500, lr = 0.0045
I0527 06:34:49.789418  1888 solver.cpp:237] Iteration 352000, loss = 1.16946
I0527 06:34:49.789594  1888 solver.cpp:253]     Train net output #0: loss = 1.16946 (* 1 = 1.16946 loss)
I0527 06:34:49.789611  1888 sgd_solver.cpp:106] Iteration 352000, lr = 0.0045
I0527 06:35:00.345154  1888 solver.cpp:237] Iteration 352500, loss = 0.954689
I0527 06:35:00.345201  1888 solver.cpp:253]     Train net output #0: loss = 0.954689 (* 1 = 0.954689 loss)
I0527 06:35:00.345216  1888 sgd_solver.cpp:106] Iteration 352500, lr = 0.0045
I0527 06:35:10.896235  1888 solver.cpp:237] Iteration 353000, loss = 1.05077
I0527 06:35:10.896270  1888 solver.cpp:253]     Train net output #0: loss = 1.05077 (* 1 = 1.05077 loss)
I0527 06:35:10.896284  1888 sgd_solver.cpp:106] Iteration 353000, lr = 0.0045
I0527 06:35:42.345779  1888 solver.cpp:237] Iteration 353500, loss = 1.23957
I0527 06:35:42.345965  1888 solver.cpp:253]     Train net output #0: loss = 1.23957 (* 1 = 1.23957 loss)
I0527 06:35:42.345979  1888 sgd_solver.cpp:106] Iteration 353500, lr = 0.0045
I0527 06:35:52.867050  1888 solver.cpp:237] Iteration 354000, loss = 1.03105
I0527 06:35:52.867087  1888 solver.cpp:253]     Train net output #0: loss = 1.03105 (* 1 = 1.03105 loss)
I0527 06:35:52.867102  1888 sgd_solver.cpp:106] Iteration 354000, lr = 0.0045
I0527 06:36:03.391589  1888 solver.cpp:237] Iteration 354500, loss = 1.17571
I0527 06:36:03.391625  1888 solver.cpp:253]     Train net output #0: loss = 1.17571 (* 1 = 1.17571 loss)
I0527 06:36:03.391639  1888 sgd_solver.cpp:106] Iteration 354500, lr = 0.0045
I0527 06:36:13.895539  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_355000.caffemodel
I0527 06:36:13.951720  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_355000.solverstate
I0527 06:36:13.986014  1888 solver.cpp:237] Iteration 355000, loss = 1.50464
I0527 06:36:13.986063  1888 solver.cpp:253]     Train net output #0: loss = 1.50464 (* 1 = 1.50464 loss)
I0527 06:36:13.986079  1888 sgd_solver.cpp:106] Iteration 355000, lr = 0.0045
I0527 06:36:24.509004  1888 solver.cpp:237] Iteration 355500, loss = 1.1939
I0527 06:36:24.509040  1888 solver.cpp:253]     Train net output #0: loss = 1.1939 (* 1 = 1.1939 loss)
I0527 06:36:24.509054  1888 sgd_solver.cpp:106] Iteration 355500, lr = 0.0045
I0527 06:36:35.081151  1888 solver.cpp:237] Iteration 356000, loss = 1.51207
I0527 06:36:35.081203  1888 solver.cpp:253]     Train net output #0: loss = 1.51207 (* 1 = 1.51207 loss)
I0527 06:36:35.081218  1888 sgd_solver.cpp:106] Iteration 356000, lr = 0.0045
I0527 06:36:45.683964  1888 solver.cpp:237] Iteration 356500, loss = 0.843463
I0527 06:36:45.684136  1888 solver.cpp:253]     Train net output #0: loss = 0.843463 (* 1 = 0.843463 loss)
I0527 06:36:45.684150  1888 sgd_solver.cpp:106] Iteration 356500, lr = 0.0045
I0527 06:37:17.188804  1888 solver.cpp:237] Iteration 357000, loss = 1.04276
I0527 06:37:17.188992  1888 solver.cpp:253]     Train net output #0: loss = 1.04276 (* 1 = 1.04276 loss)
I0527 06:37:17.189007  1888 sgd_solver.cpp:106] Iteration 357000, lr = 0.0045
I0527 06:37:27.787223  1888 solver.cpp:237] Iteration 357500, loss = 1.48372
I0527 06:37:27.787271  1888 solver.cpp:253]     Train net output #0: loss = 1.48372 (* 1 = 1.48372 loss)
I0527 06:37:27.787286  1888 sgd_solver.cpp:106] Iteration 357500, lr = 0.0045
I0527 06:37:38.364274  1888 solver.cpp:237] Iteration 358000, loss = 1.30455
I0527 06:37:38.364308  1888 solver.cpp:253]     Train net output #0: loss = 1.30455 (* 1 = 1.30455 loss)
I0527 06:37:38.364323  1888 sgd_solver.cpp:106] Iteration 358000, lr = 0.0045
I0527 06:37:48.947157  1888 solver.cpp:237] Iteration 358500, loss = 0.977563
I0527 06:37:48.947352  1888 solver.cpp:253]     Train net output #0: loss = 0.977564 (* 1 = 0.977564 loss)
I0527 06:37:48.947367  1888 sgd_solver.cpp:106] Iteration 358500, lr = 0.0045
I0527 06:37:59.488306  1888 solver.cpp:237] Iteration 359000, loss = 1.38901
I0527 06:37:59.488343  1888 solver.cpp:253]     Train net output #0: loss = 1.38901 (* 1 = 1.38901 loss)
I0527 06:37:59.488356  1888 sgd_solver.cpp:106] Iteration 359000, lr = 0.0045
I0527 06:38:10.028744  1888 solver.cpp:237] Iteration 359500, loss = 1.53464
I0527 06:38:10.028794  1888 solver.cpp:253]     Train net output #0: loss = 1.53464 (* 1 = 1.53464 loss)
I0527 06:38:10.028807  1888 sgd_solver.cpp:106] Iteration 359500, lr = 0.0045
I0527 06:38:20.550863  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_360000.caffemodel
I0527 06:38:20.615702  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_360000.solverstate
I0527 06:38:20.643265  1888 solver.cpp:341] Iteration 360000, Testing net (#0)
I0527 06:39:10.014899  1888 solver.cpp:409]     Test net output #0: accuracy = 0.904696
I0527 06:39:10.015094  1888 solver.cpp:409]     Test net output #1: loss = 0.288047 (* 1 = 0.288047 loss)
I0527 06:39:30.921669  1888 solver.cpp:237] Iteration 360000, loss = 0.896542
I0527 06:39:30.921723  1888 solver.cpp:253]     Train net output #0: loss = 0.896542 (* 1 = 0.896542 loss)
I0527 06:39:30.921739  1888 sgd_solver.cpp:106] Iteration 360000, lr = 0.0045
I0527 06:39:41.556515  1888 solver.cpp:237] Iteration 360500, loss = 0.94483
I0527 06:39:41.556689  1888 solver.cpp:253]     Train net output #0: loss = 0.94483 (* 1 = 0.94483 loss)
I0527 06:39:41.556705  1888 sgd_solver.cpp:106] Iteration 360500, lr = 0.0045
I0527 06:39:52.207938  1888 solver.cpp:237] Iteration 361000, loss = 1.17902
I0527 06:39:52.207981  1888 solver.cpp:253]     Train net output #0: loss = 1.17902 (* 1 = 1.17902 loss)
I0527 06:39:52.207995  1888 sgd_solver.cpp:106] Iteration 361000, lr = 0.0045
I0527 06:40:02.845170  1888 solver.cpp:237] Iteration 361500, loss = 0.892542
I0527 06:40:02.845206  1888 solver.cpp:253]     Train net output #0: loss = 0.892542 (* 1 = 0.892542 loss)
I0527 06:40:02.845221  1888 sgd_solver.cpp:106] Iteration 361500, lr = 0.0045
I0527 06:40:13.484113  1888 solver.cpp:237] Iteration 362000, loss = 0.698428
I0527 06:40:13.484278  1888 solver.cpp:253]     Train net output #0: loss = 0.698428 (* 1 = 0.698428 loss)
I0527 06:40:13.484295  1888 sgd_solver.cpp:106] Iteration 362000, lr = 0.0045
I0527 06:40:24.133237  1888 solver.cpp:237] Iteration 362500, loss = 0.836737
I0527 06:40:24.133291  1888 solver.cpp:253]     Train net output #0: loss = 0.836738 (* 1 = 0.836738 loss)
I0527 06:40:24.133304  1888 sgd_solver.cpp:106] Iteration 362500, lr = 0.0045
I0527 06:40:34.768092  1888 solver.cpp:237] Iteration 363000, loss = 1.00317
I0527 06:40:34.768127  1888 solver.cpp:253]     Train net output #0: loss = 1.00317 (* 1 = 1.00317 loss)
I0527 06:40:34.768141  1888 sgd_solver.cpp:106] Iteration 363000, lr = 0.0045
I0527 06:41:06.300715  1888 solver.cpp:237] Iteration 363500, loss = 1.30666
I0527 06:41:06.300901  1888 solver.cpp:253]     Train net output #0: loss = 1.30666 (* 1 = 1.30666 loss)
I0527 06:41:06.300915  1888 sgd_solver.cpp:106] Iteration 363500, lr = 0.0045
I0527 06:41:16.939271  1888 solver.cpp:237] Iteration 364000, loss = 1.12286
I0527 06:41:16.939307  1888 solver.cpp:253]     Train net output #0: loss = 1.12286 (* 1 = 1.12286 loss)
I0527 06:41:16.939322  1888 sgd_solver.cpp:106] Iteration 364000, lr = 0.0045
I0527 06:41:27.581297  1888 solver.cpp:237] Iteration 364500, loss = 1.03011
I0527 06:41:27.581332  1888 solver.cpp:253]     Train net output #0: loss = 1.03011 (* 1 = 1.03011 loss)
I0527 06:41:27.581347  1888 sgd_solver.cpp:106] Iteration 364500, lr = 0.0045
I0527 06:41:38.207949  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_365000.caffemodel
I0527 06:41:38.260362  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_365000.solverstate
I0527 06:41:38.292271  1888 solver.cpp:237] Iteration 365000, loss = 1.26404
I0527 06:41:38.292314  1888 solver.cpp:253]     Train net output #0: loss = 1.26404 (* 1 = 1.26404 loss)
I0527 06:41:38.292331  1888 sgd_solver.cpp:106] Iteration 365000, lr = 0.0045
I0527 06:41:48.921423  1888 solver.cpp:237] Iteration 365500, loss = 1.43291
I0527 06:41:48.921459  1888 solver.cpp:253]     Train net output #0: loss = 1.43291 (* 1 = 1.43291 loss)
I0527 06:41:48.921473  1888 sgd_solver.cpp:106] Iteration 365500, lr = 0.0045
I0527 06:41:59.567863  1888 solver.cpp:237] Iteration 366000, loss = 1.1667
I0527 06:41:59.567914  1888 solver.cpp:253]     Train net output #0: loss = 1.1667 (* 1 = 1.1667 loss)
I0527 06:41:59.567927  1888 sgd_solver.cpp:106] Iteration 366000, lr = 0.0045
I0527 06:42:10.194762  1888 solver.cpp:237] Iteration 366500, loss = 0.794525
I0527 06:42:10.194932  1888 solver.cpp:253]     Train net output #0: loss = 0.794525 (* 1 = 0.794525 loss)
I0527 06:42:10.194947  1888 sgd_solver.cpp:106] Iteration 366500, lr = 0.0045
I0527 06:42:41.680472  1888 solver.cpp:237] Iteration 367000, loss = 0.769301
I0527 06:42:41.680660  1888 solver.cpp:253]     Train net output #0: loss = 0.769301 (* 1 = 0.769301 loss)
I0527 06:42:41.680675  1888 sgd_solver.cpp:106] Iteration 367000, lr = 0.0045
I0527 06:42:52.316920  1888 solver.cpp:237] Iteration 367500, loss = 1.35971
I0527 06:42:52.316968  1888 solver.cpp:253]     Train net output #0: loss = 1.35971 (* 1 = 1.35971 loss)
I0527 06:42:52.316982  1888 sgd_solver.cpp:106] Iteration 367500, lr = 0.0045
I0527 06:43:02.953347  1888 solver.cpp:237] Iteration 368000, loss = 0.888434
I0527 06:43:02.953383  1888 solver.cpp:253]     Train net output #0: loss = 0.888434 (* 1 = 0.888434 loss)
I0527 06:43:02.953399  1888 sgd_solver.cpp:106] Iteration 368000, lr = 0.0045
I0527 06:43:13.598240  1888 solver.cpp:237] Iteration 368500, loss = 1.28823
I0527 06:43:13.598422  1888 solver.cpp:253]     Train net output #0: loss = 1.28823 (* 1 = 1.28823 loss)
I0527 06:43:13.598438  1888 sgd_solver.cpp:106] Iteration 368500, lr = 0.0045
I0527 06:43:24.241770  1888 solver.cpp:237] Iteration 369000, loss = 1.30948
I0527 06:43:24.241806  1888 solver.cpp:253]     Train net output #0: loss = 1.30948 (* 1 = 1.30948 loss)
I0527 06:43:24.241821  1888 sgd_solver.cpp:106] Iteration 369000, lr = 0.0045
I0527 06:43:34.882237  1888 solver.cpp:237] Iteration 369500, loss = 1.28419
I0527 06:43:34.882278  1888 solver.cpp:253]     Train net output #0: loss = 1.28419 (* 1 = 1.28419 loss)
I0527 06:43:34.882299  1888 sgd_solver.cpp:106] Iteration 369500, lr = 0.0045
I0527 06:43:45.493933  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_370000.caffemodel
I0527 06:43:45.546828  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_370000.solverstate
I0527 06:43:45.572685  1888 solver.cpp:341] Iteration 370000, Testing net (#0)
I0527 06:44:56.103646  1888 solver.cpp:409]     Test net output #0: accuracy = 0.904851
I0527 06:44:56.103837  1888 solver.cpp:409]     Test net output #1: loss = 0.299942 (* 1 = 0.299942 loss)
I0527 06:45:17.012053  1888 solver.cpp:237] Iteration 370000, loss = 0.930078
I0527 06:45:17.012106  1888 solver.cpp:253]     Train net output #0: loss = 0.930078 (* 1 = 0.930078 loss)
I0527 06:45:17.012122  1888 sgd_solver.cpp:106] Iteration 370000, lr = 0.0045
I0527 06:45:27.574622  1888 solver.cpp:237] Iteration 370500, loss = 1.1949
I0527 06:45:27.574803  1888 solver.cpp:253]     Train net output #0: loss = 1.1949 (* 1 = 1.1949 loss)
I0527 06:45:27.574816  1888 sgd_solver.cpp:106] Iteration 370500, lr = 0.0045
I0527 06:45:38.157001  1888 solver.cpp:237] Iteration 371000, loss = 1.13775
I0527 06:45:38.157037  1888 solver.cpp:253]     Train net output #0: loss = 1.13775 (* 1 = 1.13775 loss)
I0527 06:45:38.157050  1888 sgd_solver.cpp:106] Iteration 371000, lr = 0.0045
I0527 06:45:48.735586  1888 solver.cpp:237] Iteration 371500, loss = 1.23765
I0527 06:45:48.735635  1888 solver.cpp:253]     Train net output #0: loss = 1.23765 (* 1 = 1.23765 loss)
I0527 06:45:48.735648  1888 sgd_solver.cpp:106] Iteration 371500, lr = 0.0045
I0527 06:45:59.325009  1888 solver.cpp:237] Iteration 372000, loss = 0.859482
I0527 06:45:59.325177  1888 solver.cpp:253]     Train net output #0: loss = 0.859482 (* 1 = 0.859482 loss)
I0527 06:45:59.325191  1888 sgd_solver.cpp:106] Iteration 372000, lr = 0.0045
I0527 06:46:09.893853  1888 solver.cpp:237] Iteration 372500, loss = 1.28045
I0527 06:46:09.893899  1888 solver.cpp:253]     Train net output #0: loss = 1.28045 (* 1 = 1.28045 loss)
I0527 06:46:09.893913  1888 sgd_solver.cpp:106] Iteration 372500, lr = 0.0045
I0527 06:46:20.469702  1888 solver.cpp:237] Iteration 373000, loss = 0.981615
I0527 06:46:20.469738  1888 solver.cpp:253]     Train net output #0: loss = 0.981615 (* 1 = 0.981615 loss)
I0527 06:46:20.469753  1888 sgd_solver.cpp:106] Iteration 373000, lr = 0.0045
I0527 06:46:51.906919  1888 solver.cpp:237] Iteration 373500, loss = 0.970266
I0527 06:46:51.907109  1888 solver.cpp:253]     Train net output #0: loss = 0.970266 (* 1 = 0.970266 loss)
I0527 06:46:51.907125  1888 sgd_solver.cpp:106] Iteration 373500, lr = 0.0045
I0527 06:47:02.472540  1888 solver.cpp:237] Iteration 374000, loss = 1.11551
I0527 06:47:02.472586  1888 solver.cpp:253]     Train net output #0: loss = 1.11551 (* 1 = 1.11551 loss)
I0527 06:47:02.472600  1888 sgd_solver.cpp:106] Iteration 374000, lr = 0.0045
I0527 06:47:13.043637  1888 solver.cpp:237] Iteration 374500, loss = 1.1629
I0527 06:47:13.043673  1888 solver.cpp:253]     Train net output #0: loss = 1.1629 (* 1 = 1.1629 loss)
I0527 06:47:13.043687  1888 sgd_solver.cpp:106] Iteration 374500, lr = 0.0045
I0527 06:47:23.590814  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_375000.caffemodel
I0527 06:47:23.644593  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_375000.solverstate
I0527 06:47:23.677953  1888 solver.cpp:237] Iteration 375000, loss = 1.16654
I0527 06:47:23.678000  1888 solver.cpp:253]     Train net output #0: loss = 1.16654 (* 1 = 1.16654 loss)
I0527 06:47:23.678020  1888 sgd_solver.cpp:106] Iteration 375000, lr = 0.0045
I0527 06:47:34.261703  1888 solver.cpp:237] Iteration 375500, loss = 1.23924
I0527 06:47:34.261739  1888 solver.cpp:253]     Train net output #0: loss = 1.23924 (* 1 = 1.23924 loss)
I0527 06:47:34.261754  1888 sgd_solver.cpp:106] Iteration 375500, lr = 0.0045
I0527 06:47:44.842813  1888 solver.cpp:237] Iteration 376000, loss = 1.02214
I0527 06:47:44.842852  1888 solver.cpp:253]     Train net output #0: loss = 1.02214 (* 1 = 1.02214 loss)
I0527 06:47:44.842864  1888 sgd_solver.cpp:106] Iteration 376000, lr = 0.0045
I0527 06:47:55.413380  1888 solver.cpp:237] Iteration 376500, loss = 1.16625
I0527 06:47:55.413557  1888 solver.cpp:253]     Train net output #0: loss = 1.16625 (* 1 = 1.16625 loss)
I0527 06:47:55.413570  1888 sgd_solver.cpp:106] Iteration 376500, lr = 0.0045
I0527 06:48:26.884022  1888 solver.cpp:237] Iteration 377000, loss = 1.5689
I0527 06:48:26.884225  1888 solver.cpp:253]     Train net output #0: loss = 1.5689 (* 1 = 1.5689 loss)
I0527 06:48:26.884243  1888 sgd_solver.cpp:106] Iteration 377000, lr = 0.0045
I0527 06:48:37.455737  1888 solver.cpp:237] Iteration 377500, loss = 1.33353
I0527 06:48:37.455782  1888 solver.cpp:253]     Train net output #0: loss = 1.33353 (* 1 = 1.33353 loss)
I0527 06:48:37.455797  1888 sgd_solver.cpp:106] Iteration 377500, lr = 0.0045
I0527 06:48:48.035192  1888 solver.cpp:237] Iteration 378000, loss = 1.00884
I0527 06:48:48.035228  1888 solver.cpp:253]     Train net output #0: loss = 1.00884 (* 1 = 1.00884 loss)
I0527 06:48:48.035243  1888 sgd_solver.cpp:106] Iteration 378000, lr = 0.0045
I0527 06:48:58.615573  1888 solver.cpp:237] Iteration 378500, loss = 0.935153
I0527 06:48:58.615746  1888 solver.cpp:253]     Train net output #0: loss = 0.935153 (* 1 = 0.935153 loss)
I0527 06:48:58.615761  1888 sgd_solver.cpp:106] Iteration 378500, lr = 0.0045
I0527 06:49:09.186620  1888 solver.cpp:237] Iteration 379000, loss = 0.907844
I0527 06:49:09.186662  1888 solver.cpp:253]     Train net output #0: loss = 0.907844 (* 1 = 0.907844 loss)
I0527 06:49:09.186676  1888 sgd_solver.cpp:106] Iteration 379000, lr = 0.0045
I0527 06:49:19.783785  1888 solver.cpp:237] Iteration 379500, loss = 1.08352
I0527 06:49:19.783820  1888 solver.cpp:253]     Train net output #0: loss = 1.08352 (* 1 = 1.08352 loss)
I0527 06:49:19.783834  1888 sgd_solver.cpp:106] Iteration 379500, lr = 0.0045
I0527 06:49:30.345818  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_380000.caffemodel
I0527 06:49:30.399798  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_380000.solverstate
I0527 06:49:30.426383  1888 solver.cpp:341] Iteration 380000, Testing net (#0)
I0527 06:50:20.144285  1888 solver.cpp:409]     Test net output #0: accuracy = 0.90371
I0527 06:50:20.144471  1888 solver.cpp:409]     Test net output #1: loss = 0.318152 (* 1 = 0.318152 loss)
I0527 06:50:41.027374  1888 solver.cpp:237] Iteration 380000, loss = 1.30319
I0527 06:50:41.027423  1888 solver.cpp:253]     Train net output #0: loss = 1.30319 (* 1 = 1.30319 loss)
I0527 06:50:41.027439  1888 sgd_solver.cpp:106] Iteration 380000, lr = 0.0045
I0527 06:50:51.622489  1888 solver.cpp:237] Iteration 380500, loss = 1.36968
I0527 06:50:51.622664  1888 solver.cpp:253]     Train net output #0: loss = 1.36968 (* 1 = 1.36968 loss)
I0527 06:50:51.622678  1888 sgd_solver.cpp:106] Iteration 380500, lr = 0.0045
I0527 06:51:02.208104  1888 solver.cpp:237] Iteration 381000, loss = 1.25925
I0527 06:51:02.208139  1888 solver.cpp:253]     Train net output #0: loss = 1.25925 (* 1 = 1.25925 loss)
I0527 06:51:02.208154  1888 sgd_solver.cpp:106] Iteration 381000, lr = 0.0045
I0527 06:51:12.810724  1888 solver.cpp:237] Iteration 381500, loss = 1.06613
I0527 06:51:12.810767  1888 solver.cpp:253]     Train net output #0: loss = 1.06613 (* 1 = 1.06613 loss)
I0527 06:51:12.810781  1888 sgd_solver.cpp:106] Iteration 381500, lr = 0.0045
I0527 06:51:23.393586  1888 solver.cpp:237] Iteration 382000, loss = 1.19604
I0527 06:51:23.393754  1888 solver.cpp:253]     Train net output #0: loss = 1.19604 (* 1 = 1.19604 loss)
I0527 06:51:23.393767  1888 sgd_solver.cpp:106] Iteration 382000, lr = 0.0045
I0527 06:51:33.977550  1888 solver.cpp:237] Iteration 382500, loss = 1.42917
I0527 06:51:33.977596  1888 solver.cpp:253]     Train net output #0: loss = 1.42917 (* 1 = 1.42917 loss)
I0527 06:51:33.977610  1888 sgd_solver.cpp:106] Iteration 382500, lr = 0.0045
I0527 06:51:44.566216  1888 solver.cpp:237] Iteration 383000, loss = 1.51676
I0527 06:51:44.566251  1888 solver.cpp:253]     Train net output #0: loss = 1.51676 (* 1 = 1.51676 loss)
I0527 06:51:44.566267  1888 sgd_solver.cpp:106] Iteration 383000, lr = 0.0045
I0527 06:52:16.048048  1888 solver.cpp:237] Iteration 383500, loss = 1.35161
I0527 06:52:16.048250  1888 solver.cpp:253]     Train net output #0: loss = 1.35161 (* 1 = 1.35161 loss)
I0527 06:52:16.048267  1888 sgd_solver.cpp:106] Iteration 383500, lr = 0.0045
I0527 06:52:26.642472  1888 solver.cpp:237] Iteration 384000, loss = 1.02739
I0527 06:52:26.642518  1888 solver.cpp:253]     Train net output #0: loss = 1.02739 (* 1 = 1.02739 loss)
I0527 06:52:26.642532  1888 sgd_solver.cpp:106] Iteration 384000, lr = 0.0045
I0527 06:52:37.230378  1888 solver.cpp:237] Iteration 384500, loss = 1.03827
I0527 06:52:37.230414  1888 solver.cpp:253]     Train net output #0: loss = 1.03827 (* 1 = 1.03827 loss)
I0527 06:52:37.230428  1888 sgd_solver.cpp:106] Iteration 384500, lr = 0.0045
I0527 06:52:47.787364  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_385000.caffemodel
I0527 06:52:47.842219  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_385000.solverstate
I0527 06:52:47.876382  1888 solver.cpp:237] Iteration 385000, loss = 1.05592
I0527 06:52:47.876435  1888 solver.cpp:253]     Train net output #0: loss = 1.05592 (* 1 = 1.05592 loss)
I0527 06:52:47.876448  1888 sgd_solver.cpp:106] Iteration 385000, lr = 0.0045
I0527 06:52:58.468794  1888 solver.cpp:237] Iteration 385500, loss = 1.00933
I0527 06:52:58.468830  1888 solver.cpp:253]     Train net output #0: loss = 1.00933 (* 1 = 1.00933 loss)
I0527 06:52:58.468844  1888 sgd_solver.cpp:106] Iteration 385500, lr = 0.0045
I0527 06:53:09.061442  1888 solver.cpp:237] Iteration 386000, loss = 1.29426
I0527 06:53:09.061478  1888 solver.cpp:253]     Train net output #0: loss = 1.29426 (* 1 = 1.29426 loss)
I0527 06:53:09.061492  1888 sgd_solver.cpp:106] Iteration 386000, lr = 0.0045
I0527 06:53:19.665303  1888 solver.cpp:237] Iteration 386500, loss = 1.29404
I0527 06:53:19.665494  1888 solver.cpp:253]     Train net output #0: loss = 1.29404 (* 1 = 1.29404 loss)
I0527 06:53:19.665510  1888 sgd_solver.cpp:106] Iteration 386500, lr = 0.0045
I0527 06:53:51.192670  1888 solver.cpp:237] Iteration 387000, loss = 1.22429
I0527 06:53:51.192865  1888 solver.cpp:253]     Train net output #0: loss = 1.22429 (* 1 = 1.22429 loss)
I0527 06:53:51.192883  1888 sgd_solver.cpp:106] Iteration 387000, lr = 0.0045
I0527 06:54:01.783262  1888 solver.cpp:237] Iteration 387500, loss = 0.839732
I0527 06:54:01.783310  1888 solver.cpp:253]     Train net output #0: loss = 0.839732 (* 1 = 0.839732 loss)
I0527 06:54:01.783325  1888 sgd_solver.cpp:106] Iteration 387500, lr = 0.0045
I0527 06:54:12.370761  1888 solver.cpp:237] Iteration 388000, loss = 0.879055
I0527 06:54:12.370798  1888 solver.cpp:253]     Train net output #0: loss = 0.879055 (* 1 = 0.879055 loss)
I0527 06:54:12.370812  1888 sgd_solver.cpp:106] Iteration 388000, lr = 0.0045
I0527 06:54:22.956100  1888 solver.cpp:237] Iteration 388500, loss = 1.25158
I0527 06:54:22.956270  1888 solver.cpp:253]     Train net output #0: loss = 1.25158 (* 1 = 1.25158 loss)
I0527 06:54:22.956286  1888 sgd_solver.cpp:106] Iteration 388500, lr = 0.0045
I0527 06:54:33.554808  1888 solver.cpp:237] Iteration 389000, loss = 0.923643
I0527 06:54:33.554857  1888 solver.cpp:253]     Train net output #0: loss = 0.923642 (* 1 = 0.923642 loss)
I0527 06:54:33.554872  1888 sgd_solver.cpp:106] Iteration 389000, lr = 0.0045
I0527 06:54:44.149338  1888 solver.cpp:237] Iteration 389500, loss = 1.05616
I0527 06:54:44.149369  1888 solver.cpp:253]     Train net output #0: loss = 1.05616 (* 1 = 1.05616 loss)
I0527 06:54:44.149382  1888 sgd_solver.cpp:106] Iteration 389500, lr = 0.0045
I0527 06:54:54.732544  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_390000.caffemodel
I0527 06:54:54.790781  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_390000.solverstate
I0527 06:54:54.821434  1888 solver.cpp:341] Iteration 390000, Testing net (#0)
I0527 06:56:05.350711  1888 solver.cpp:409]     Test net output #0: accuracy = 0.906426
I0527 06:56:05.350903  1888 solver.cpp:409]     Test net output #1: loss = 0.29522 (* 1 = 0.29522 loss)
I0527 06:56:26.214534  1888 solver.cpp:237] Iteration 390000, loss = 0.820334
I0527 06:56:26.214588  1888 solver.cpp:253]     Train net output #0: loss = 0.820333 (* 1 = 0.820333 loss)
I0527 06:56:26.214603  1888 sgd_solver.cpp:106] Iteration 390000, lr = 0.0045
I0527 06:56:36.735857  1888 solver.cpp:237] Iteration 390500, loss = 1.11428
I0527 06:56:36.736049  1888 solver.cpp:253]     Train net output #0: loss = 1.11428 (* 1 = 1.11428 loss)
I0527 06:56:36.736064  1888 sgd_solver.cpp:106] Iteration 390500, lr = 0.0045
I0527 06:56:47.256562  1888 solver.cpp:237] Iteration 391000, loss = 1.37783
I0527 06:56:47.256599  1888 solver.cpp:253]     Train net output #0: loss = 1.37783 (* 1 = 1.37783 loss)
I0527 06:56:47.256613  1888 sgd_solver.cpp:106] Iteration 391000, lr = 0.0045
I0527 06:56:57.773169  1888 solver.cpp:237] Iteration 391500, loss = 1.18168
I0527 06:56:57.773216  1888 solver.cpp:253]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0527 06:56:57.773231  1888 sgd_solver.cpp:106] Iteration 391500, lr = 0.0045
I0527 06:57:08.300385  1888 solver.cpp:237] Iteration 392000, loss = 0.753552
I0527 06:57:08.300559  1888 solver.cpp:253]     Train net output #0: loss = 0.753551 (* 1 = 0.753551 loss)
I0527 06:57:08.300573  1888 sgd_solver.cpp:106] Iteration 392000, lr = 0.0045
I0527 06:57:18.807343  1888 solver.cpp:237] Iteration 392500, loss = 1.00524
I0527 06:57:18.807379  1888 solver.cpp:253]     Train net output #0: loss = 1.00523 (* 1 = 1.00523 loss)
I0527 06:57:18.807394  1888 sgd_solver.cpp:106] Iteration 392500, lr = 0.0045
I0527 06:57:29.323577  1888 solver.cpp:237] Iteration 393000, loss = 0.905537
I0527 06:57:29.323627  1888 solver.cpp:253]     Train net output #0: loss = 0.905536 (* 1 = 0.905536 loss)
I0527 06:57:29.323642  1888 sgd_solver.cpp:106] Iteration 393000, lr = 0.0045
I0527 06:58:00.706207  1888 solver.cpp:237] Iteration 393500, loss = 0.895332
I0527 06:58:00.706404  1888 solver.cpp:253]     Train net output #0: loss = 0.895331 (* 1 = 0.895331 loss)
I0527 06:58:00.706420  1888 sgd_solver.cpp:106] Iteration 393500, lr = 0.0045
I0527 06:58:11.227643  1888 solver.cpp:237] Iteration 394000, loss = 0.883717
I0527 06:58:11.227694  1888 solver.cpp:253]     Train net output #0: loss = 0.883716 (* 1 = 0.883716 loss)
I0527 06:58:11.227708  1888 sgd_solver.cpp:106] Iteration 394000, lr = 0.0045
I0527 06:58:21.745576  1888 solver.cpp:237] Iteration 394500, loss = 0.918509
I0527 06:58:21.745614  1888 solver.cpp:253]     Train net output #0: loss = 0.918508 (* 1 = 0.918508 loss)
I0527 06:58:21.745628  1888 sgd_solver.cpp:106] Iteration 394500, lr = 0.0045
I0527 06:58:32.234868  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_395000.caffemodel
I0527 06:58:32.299724  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_395000.solverstate
I0527 06:58:32.331686  1888 solver.cpp:237] Iteration 395000, loss = 1.46372
I0527 06:58:32.331732  1888 solver.cpp:253]     Train net output #0: loss = 1.46372 (* 1 = 1.46372 loss)
I0527 06:58:32.331748  1888 sgd_solver.cpp:106] Iteration 395000, lr = 0.0045
I0527 06:58:42.867599  1888 solver.cpp:237] Iteration 395500, loss = 1.13764
I0527 06:58:42.867645  1888 solver.cpp:253]     Train net output #0: loss = 1.13764 (* 1 = 1.13764 loss)
I0527 06:58:42.867660  1888 sgd_solver.cpp:106] Iteration 395500, lr = 0.0045
I0527 06:58:53.390105  1888 solver.cpp:237] Iteration 396000, loss = 1.32349
I0527 06:58:53.390141  1888 solver.cpp:253]     Train net output #0: loss = 1.32349 (* 1 = 1.32349 loss)
I0527 06:58:53.390156  1888 sgd_solver.cpp:106] Iteration 396000, lr = 0.0045
I0527 06:59:03.919030  1888 solver.cpp:237] Iteration 396500, loss = 1.08824
I0527 06:59:03.919235  1888 solver.cpp:253]     Train net output #0: loss = 1.08824 (* 1 = 1.08824 loss)
I0527 06:59:03.919251  1888 sgd_solver.cpp:106] Iteration 396500, lr = 0.0045
I0527 06:59:35.326748  1888 solver.cpp:237] Iteration 397000, loss = 1.00944
I0527 06:59:35.326948  1888 solver.cpp:253]     Train net output #0: loss = 1.00944 (* 1 = 1.00944 loss)
I0527 06:59:35.326963  1888 sgd_solver.cpp:106] Iteration 397000, lr = 0.0045
I0527 06:59:45.847650  1888 solver.cpp:237] Iteration 397500, loss = 1.43214
I0527 06:59:45.847687  1888 solver.cpp:253]     Train net output #0: loss = 1.43214 (* 1 = 1.43214 loss)
I0527 06:59:45.847700  1888 sgd_solver.cpp:106] Iteration 397500, lr = 0.0045
I0527 06:59:56.373052  1888 solver.cpp:237] Iteration 398000, loss = 1.03557
I0527 06:59:56.373100  1888 solver.cpp:253]     Train net output #0: loss = 1.03557 (* 1 = 1.03557 loss)
I0527 06:59:56.373113  1888 sgd_solver.cpp:106] Iteration 398000, lr = 0.0045
I0527 07:00:06.906658  1888 solver.cpp:237] Iteration 398500, loss = 1.21944
I0527 07:00:06.906831  1888 solver.cpp:253]     Train net output #0: loss = 1.21944 (* 1 = 1.21944 loss)
I0527 07:00:06.906844  1888 sgd_solver.cpp:106] Iteration 398500, lr = 0.0045
I0527 07:00:17.433790  1888 solver.cpp:237] Iteration 399000, loss = 1.08757
I0527 07:00:17.433840  1888 solver.cpp:253]     Train net output #0: loss = 1.08757 (* 1 = 1.08757 loss)
I0527 07:00:17.433854  1888 sgd_solver.cpp:106] Iteration 399000, lr = 0.0045
I0527 07:00:27.968080  1888 solver.cpp:237] Iteration 399500, loss = 1.23326
I0527 07:00:27.968116  1888 solver.cpp:253]     Train net output #0: loss = 1.23326 (* 1 = 1.23326 loss)
I0527 07:00:27.968132  1888 sgd_solver.cpp:106] Iteration 399500, lr = 0.0045
I0527 07:00:38.489362  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_400000.caffemodel
I0527 07:00:38.542038  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_400000.solverstate
I0527 07:00:38.567576  1888 solver.cpp:341] Iteration 400000, Testing net (#0)
I0527 07:01:27.882068  1888 solver.cpp:409]     Test net output #0: accuracy = 0.906417
I0527 07:01:27.882257  1888 solver.cpp:409]     Test net output #1: loss = 0.292321 (* 1 = 0.292321 loss)
I0527 07:01:48.738668  1888 solver.cpp:237] Iteration 400000, loss = 0.950224
I0527 07:01:48.738723  1888 solver.cpp:253]     Train net output #0: loss = 0.950224 (* 1 = 0.950224 loss)
I0527 07:01:48.738739  1888 sgd_solver.cpp:106] Iteration 400000, lr = 0.0045
I0527 07:01:59.252740  1888 solver.cpp:237] Iteration 400500, loss = 0.828708
I0527 07:01:59.252929  1888 solver.cpp:253]     Train net output #0: loss = 0.828707 (* 1 = 0.828707 loss)
I0527 07:01:59.252944  1888 sgd_solver.cpp:106] Iteration 400500, lr = 0.0045
I0527 07:02:09.763798  1888 solver.cpp:237] Iteration 401000, loss = 1.0456
I0527 07:02:09.763834  1888 solver.cpp:253]     Train net output #0: loss = 1.0456 (* 1 = 1.0456 loss)
I0527 07:02:09.763849  1888 sgd_solver.cpp:106] Iteration 401000, lr = 0.0045
I0527 07:02:20.271189  1888 solver.cpp:237] Iteration 401500, loss = 0.999223
I0527 07:02:20.271229  1888 solver.cpp:253]     Train net output #0: loss = 0.999222 (* 1 = 0.999222 loss)
I0527 07:02:20.271244  1888 sgd_solver.cpp:106] Iteration 401500, lr = 0.0045
I0527 07:02:30.776821  1888 solver.cpp:237] Iteration 402000, loss = 1.54818
I0527 07:02:30.776993  1888 solver.cpp:253]     Train net output #0: loss = 1.54818 (* 1 = 1.54818 loss)
I0527 07:02:30.777007  1888 sgd_solver.cpp:106] Iteration 402000, lr = 0.0045
I0527 07:02:41.282678  1888 solver.cpp:237] Iteration 402500, loss = 0.981659
I0527 07:02:41.282714  1888 solver.cpp:253]     Train net output #0: loss = 0.981658 (* 1 = 0.981658 loss)
I0527 07:02:41.282728  1888 sgd_solver.cpp:106] Iteration 402500, lr = 0.0045
I0527 07:02:51.820775  1888 solver.cpp:237] Iteration 403000, loss = 0.881586
I0527 07:02:51.820821  1888 solver.cpp:253]     Train net output #0: loss = 0.881585 (* 1 = 0.881585 loss)
I0527 07:02:51.820834  1888 sgd_solver.cpp:106] Iteration 403000, lr = 0.0045
I0527 07:03:23.176883  1888 solver.cpp:237] Iteration 403500, loss = 1.08674
I0527 07:03:23.177084  1888 solver.cpp:253]     Train net output #0: loss = 1.08674 (* 1 = 1.08674 loss)
I0527 07:03:23.177099  1888 sgd_solver.cpp:106] Iteration 403500, lr = 0.0045
I0527 07:03:33.695861  1888 solver.cpp:237] Iteration 404000, loss = 1.39866
I0527 07:03:33.695897  1888 solver.cpp:253]     Train net output #0: loss = 1.39866 (* 1 = 1.39866 loss)
I0527 07:03:33.695911  1888 sgd_solver.cpp:106] Iteration 404000, lr = 0.0045
I0527 07:03:44.209672  1888 solver.cpp:237] Iteration 404500, loss = 1.31377
I0527 07:03:44.209720  1888 solver.cpp:253]     Train net output #0: loss = 1.31377 (* 1 = 1.31377 loss)
I0527 07:03:44.209734  1888 sgd_solver.cpp:106] Iteration 404500, lr = 0.0045
I0527 07:03:54.705617  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_405000.caffemodel
I0527 07:03:54.760046  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_405000.solverstate
I0527 07:03:54.799562  1888 solver.cpp:237] Iteration 405000, loss = 1.29684
I0527 07:03:54.799612  1888 solver.cpp:253]     Train net output #0: loss = 1.29684 (* 1 = 1.29684 loss)
I0527 07:03:54.799628  1888 sgd_solver.cpp:106] Iteration 405000, lr = 0.0045
I0527 07:04:05.317569  1888 solver.cpp:237] Iteration 405500, loss = 1.30018
I0527 07:04:05.317620  1888 solver.cpp:253]     Train net output #0: loss = 1.30018 (* 1 = 1.30018 loss)
I0527 07:04:05.317633  1888 sgd_solver.cpp:106] Iteration 405500, lr = 0.0045
I0527 07:04:15.841363  1888 solver.cpp:237] Iteration 406000, loss = 1.98205
I0527 07:04:15.841399  1888 solver.cpp:253]     Train net output #0: loss = 1.98205 (* 1 = 1.98205 loss)
I0527 07:04:15.841414  1888 sgd_solver.cpp:106] Iteration 406000, lr = 0.0045
I0527 07:04:26.371136  1888 solver.cpp:237] Iteration 406500, loss = 1.18591
I0527 07:04:26.371328  1888 solver.cpp:253]     Train net output #0: loss = 1.18591 (* 1 = 1.18591 loss)
I0527 07:04:26.371345  1888 sgd_solver.cpp:106] Iteration 406500, lr = 0.0045
I0527 07:04:57.783265  1888 solver.cpp:237] Iteration 407000, loss = 1.12451
I0527 07:04:57.783473  1888 solver.cpp:253]     Train net output #0: loss = 1.12451 (* 1 = 1.12451 loss)
I0527 07:04:57.783489  1888 sgd_solver.cpp:106] Iteration 407000, lr = 0.0045
I0527 07:05:08.307896  1888 solver.cpp:237] Iteration 407500, loss = 1.09281
I0527 07:05:08.307931  1888 solver.cpp:253]     Train net output #0: loss = 1.09281 (* 1 = 1.09281 loss)
I0527 07:05:08.307946  1888 sgd_solver.cpp:106] Iteration 407500, lr = 0.0045
I0527 07:05:18.843910  1888 solver.cpp:237] Iteration 408000, loss = 1.38927
I0527 07:05:18.843955  1888 solver.cpp:253]     Train net output #0: loss = 1.38927 (* 1 = 1.38927 loss)
I0527 07:05:18.843968  1888 sgd_solver.cpp:106] Iteration 408000, lr = 0.0045
I0527 07:05:29.376973  1888 solver.cpp:237] Iteration 408500, loss = 1.18191
I0527 07:05:29.377148  1888 solver.cpp:253]     Train net output #0: loss = 1.18191 (* 1 = 1.18191 loss)
I0527 07:05:29.377162  1888 sgd_solver.cpp:106] Iteration 408500, lr = 0.0045
I0527 07:05:39.911087  1888 solver.cpp:237] Iteration 409000, loss = 1.21564
I0527 07:05:39.911136  1888 solver.cpp:253]     Train net output #0: loss = 1.21564 (* 1 = 1.21564 loss)
I0527 07:05:39.911150  1888 sgd_solver.cpp:106] Iteration 409000, lr = 0.0045
I0527 07:05:50.440333  1888 solver.cpp:237] Iteration 409500, loss = 1.45894
I0527 07:05:50.440369  1888 solver.cpp:253]     Train net output #0: loss = 1.45894 (* 1 = 1.45894 loss)
I0527 07:05:50.440383  1888 sgd_solver.cpp:106] Iteration 409500, lr = 0.0045
I0527 07:06:00.952360  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_410000.caffemodel
I0527 07:06:01.006037  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_410000.solverstate
I0527 07:06:01.034683  1888 solver.cpp:341] Iteration 410000, Testing net (#0)
I0527 07:07:11.499387  1888 solver.cpp:409]     Test net output #0: accuracy = 0.906525
I0527 07:07:11.499585  1888 solver.cpp:409]     Test net output #1: loss = 0.29035 (* 1 = 0.29035 loss)
I0527 07:07:32.382429  1888 solver.cpp:237] Iteration 410000, loss = 0.963322
I0527 07:07:32.382483  1888 solver.cpp:253]     Train net output #0: loss = 0.963322 (* 1 = 0.963322 loss)
I0527 07:07:32.382498  1888 sgd_solver.cpp:106] Iteration 410000, lr = 0.0045
I0527 07:07:42.895915  1888 solver.cpp:237] Iteration 410500, loss = 1.01922
I0527 07:07:42.896095  1888 solver.cpp:253]     Train net output #0: loss = 1.01922 (* 1 = 1.01922 loss)
I0527 07:07:42.896108  1888 sgd_solver.cpp:106] Iteration 410500, lr = 0.0045
I0527 07:07:53.419498  1888 solver.cpp:237] Iteration 411000, loss = 1.45633
I0527 07:07:53.419546  1888 solver.cpp:253]     Train net output #0: loss = 1.45633 (* 1 = 1.45633 loss)
I0527 07:07:53.419560  1888 sgd_solver.cpp:106] Iteration 411000, lr = 0.0045
I0527 07:08:03.940284  1888 solver.cpp:237] Iteration 411500, loss = 1.16891
I0527 07:08:03.940320  1888 solver.cpp:253]     Train net output #0: loss = 1.16891 (* 1 = 1.16891 loss)
I0527 07:08:03.940335  1888 sgd_solver.cpp:106] Iteration 411500, lr = 0.0045
I0527 07:08:14.470073  1888 solver.cpp:237] Iteration 412000, loss = 1.09106
I0527 07:08:14.470263  1888 solver.cpp:253]     Train net output #0: loss = 1.09106 (* 1 = 1.09106 loss)
I0527 07:08:14.470278  1888 sgd_solver.cpp:106] Iteration 412000, lr = 0.0045
I0527 07:08:24.997311  1888 solver.cpp:237] Iteration 412500, loss = 1.06355
I0527 07:08:24.997347  1888 solver.cpp:253]     Train net output #0: loss = 1.06355 (* 1 = 1.06355 loss)
I0527 07:08:24.997362  1888 sgd_solver.cpp:106] Iteration 412500, lr = 0.0045
I0527 07:08:35.515554  1888 solver.cpp:237] Iteration 413000, loss = 1.25708
I0527 07:08:35.515604  1888 solver.cpp:253]     Train net output #0: loss = 1.25708 (* 1 = 1.25708 loss)
I0527 07:08:35.515619  1888 sgd_solver.cpp:106] Iteration 413000, lr = 0.0045
I0527 07:09:06.895107  1888 solver.cpp:237] Iteration 413500, loss = 1.52859
I0527 07:09:06.895305  1888 solver.cpp:253]     Train net output #0: loss = 1.52859 (* 1 = 1.52859 loss)
I0527 07:09:06.895319  1888 sgd_solver.cpp:106] Iteration 413500, lr = 0.0045
I0527 07:09:17.413571  1888 solver.cpp:237] Iteration 414000, loss = 1.10782
I0527 07:09:17.413606  1888 solver.cpp:253]     Train net output #0: loss = 1.10782 (* 1 = 1.10782 loss)
I0527 07:09:17.413621  1888 sgd_solver.cpp:106] Iteration 414000, lr = 0.0045
I0527 07:09:27.930727  1888 solver.cpp:237] Iteration 414500, loss = 1.50446
I0527 07:09:27.930774  1888 solver.cpp:253]     Train net output #0: loss = 1.50446 (* 1 = 1.50446 loss)
I0527 07:09:27.930788  1888 sgd_solver.cpp:106] Iteration 414500, lr = 0.0045
I0527 07:09:38.420402  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_415000.caffemodel
I0527 07:09:38.474066  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_415000.solverstate
I0527 07:09:38.506086  1888 solver.cpp:237] Iteration 415000, loss = 1.10822
I0527 07:09:38.506127  1888 solver.cpp:253]     Train net output #0: loss = 1.10822 (* 1 = 1.10822 loss)
I0527 07:09:38.506150  1888 sgd_solver.cpp:106] Iteration 415000, lr = 0.0045
I0527 07:09:49.074064  1888 solver.cpp:237] Iteration 415500, loss = 1.3645
I0527 07:09:49.074100  1888 solver.cpp:253]     Train net output #0: loss = 1.36449 (* 1 = 1.36449 loss)
I0527 07:09:49.074115  1888 sgd_solver.cpp:106] Iteration 415500, lr = 0.0045
I0527 07:09:59.656899  1888 solver.cpp:237] Iteration 416000, loss = 1.02186
I0527 07:09:59.656946  1888 solver.cpp:253]     Train net output #0: loss = 1.02186 (* 1 = 1.02186 loss)
I0527 07:09:59.656960  1888 sgd_solver.cpp:106] Iteration 416000, lr = 0.0045
I0527 07:10:10.236536  1888 solver.cpp:237] Iteration 416500, loss = 1.13381
I0527 07:10:10.236728  1888 solver.cpp:253]     Train net output #0: loss = 1.13381 (* 1 = 1.13381 loss)
I0527 07:10:10.236742  1888 sgd_solver.cpp:106] Iteration 416500, lr = 0.0045
I0527 07:10:41.659003  1888 solver.cpp:237] Iteration 417000, loss = 0.863055
I0527 07:10:41.659201  1888 solver.cpp:253]     Train net output #0: loss = 0.863055 (* 1 = 0.863055 loss)
I0527 07:10:41.659219  1888 sgd_solver.cpp:106] Iteration 417000, lr = 0.0045
I0527 07:10:52.217826  1888 solver.cpp:237] Iteration 417500, loss = 1.10884
I0527 07:10:52.217861  1888 solver.cpp:253]     Train net output #0: loss = 1.10884 (* 1 = 1.10884 loss)
I0527 07:10:52.217875  1888 sgd_solver.cpp:106] Iteration 417500, lr = 0.0045
I0527 07:11:02.784790  1888 solver.cpp:237] Iteration 418000, loss = 0.848981
I0527 07:11:02.784826  1888 solver.cpp:253]     Train net output #0: loss = 0.84898 (* 1 = 0.84898 loss)
I0527 07:11:02.784839  1888 sgd_solver.cpp:106] Iteration 418000, lr = 0.0045
I0527 07:11:13.365409  1888 solver.cpp:237] Iteration 418500, loss = 1.14194
I0527 07:11:13.365594  1888 solver.cpp:253]     Train net output #0: loss = 1.14194 (* 1 = 1.14194 loss)
I0527 07:11:13.365609  1888 sgd_solver.cpp:106] Iteration 418500, lr = 0.0045
I0527 07:11:23.934588  1888 solver.cpp:237] Iteration 419000, loss = 1.34124
I0527 07:11:23.934623  1888 solver.cpp:253]     Train net output #0: loss = 1.34124 (* 1 = 1.34124 loss)
I0527 07:11:23.934639  1888 sgd_solver.cpp:106] Iteration 419000, lr = 0.0045
I0527 07:11:34.498769  1888 solver.cpp:237] Iteration 419500, loss = 1.6448
I0527 07:11:34.498814  1888 solver.cpp:253]     Train net output #0: loss = 1.6448 (* 1 = 1.6448 loss)
I0527 07:11:34.498829  1888 sgd_solver.cpp:106] Iteration 419500, lr = 0.0045
I0527 07:11:45.049480  1888 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_420000.caffemodel
I0527 07:11:45.103212  1888 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0045_2016-05-20T15.49.00.352182_iter_420000.solverstate
I0527 07:11:45.128566  1888 solver.cpp:341] Iteration 420000, Testing net (#0)
I0527 07:12:34.697806  1888 solver.cpp:409]     Test net output #0: accuracy = 0.905104
I0527 07:12:34.698004  1888 solver.cpp:409]     Test net output #1: loss = 0.299981 (* 1 = 0.299981 loss)
I0527 07:12:55.549031  1888 solver.cpp:237] Iteration 420000, loss = 0.930244
I0527 07:12:55.549084  1888 solver.cpp:253]     Train net output #0: loss = 0.930243 (* 1 = 0.930243 loss)
I0527 07:12:55.549100  1888 sgd_solver.cpp:106] Iteration 420000, lr = 0.0045
I0527 07:13:06.111721  1888 solver.cpp:237] Iteration 420500, loss = 1.07056
I0527 07:13:06.111906  1888 solver.cpp:253]     Train net output #0: loss = 1.07056 (* 1 = 1.07056 loss)
I0527 07:13:06.111919  1888 sgd_solver.cpp:106] Iteration 420500, lr = 0.0045
I0527 07:13:16.662375  1888 solver.cpp:237] Iteration 421000, loss = 1.17555
I0527 07:13:16.662422  1888 solver.cpp:253]     Train net output #0: loss = 1.17555 (* 1 = 1.17555 loss)
I0527 07:13:16.662437  1888 sgd_solver.cpp:106] Iteration 421000, lr = 0.0045
I0527 07:13:27.213764  1888 solver.cpp:237] Iteration 421500, loss = 1.04986
I0527 07:13:27.213800  1888 solver.cpp:253]     Train net output #0: loss = 1.04986 (* 1 = 1.04986 loss)
I0527 07:13:27.213814  1888 sgd_solver.cpp:106] Iteration 421500, lr = 0.0045
I0527 07:13:37.768120  1888 solver.cpp:237] Iteration 422000, loss = 0.910481
I0527 07:13:37.768326  1888 solver.cpp:253]     Train net output #0: loss = 0.91048 (* 1 = 0.91048 loss)
I0527 07:13:37.768340  1888 sgd_solver.cpp:106] Iteration 422000, lr = 0.0045
I0527 07:13:48.332962  1888 solver.cpp:237] Iteration 422500, loss = 1.19028
I0527 07:13:48.332998  1888 solver.cpp:253]     Train net output #0: loss = 1.19028 (* 1 = 1.19028 loss)
I0527 07:13:48.333014  1888 sgd_solver.cpp:106] Iteration 422500, lr = 0.0045
I0527 07:13:58.886507  1888 solver.cpp:237] Iteration 423000, loss = 1.13568
I0527 07:13:58.886541  1888 solver.cpp:253]     Train net output #0: loss = 1.13568 (* 1 = 1.13568 loss)
I0527 07:13:58.886556  1888 sgd_solver.cpp:106] Iteration 423000, lr = 0.0045
=>> PBS: job killed: walltime 7206 exceeded limit 7200
aprun: Apid 11271895: Caught signal Terminated, sending to application
*** Aborted at 1464347656 (unix time) try "date -d @1464347656" if you are using GNU date ***
PC: @     0x2aaac5e9ec19 (unknown)
*** SIGTERM (@0x75d) received by PID 1888 (TID 0x2aaac746f900) from PID 1885; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaac5e9ec19 (unknown)
    @     0x2aaac5e9e77f inflate
    @     0x2aaab1450a9d H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11271895: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11271895: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
aprun: Apid 11271895: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 00819] [c2-1c0s6n1] [Fri May 27 07:14:18 2016] PE RANK 0 exit signal Terminated
Application 11271895 exit codes: 143
Application 11271895 resources: utime ~6245s, stime ~951s, Rss ~5329924, inblocks ~14598943, outblocks ~651982
