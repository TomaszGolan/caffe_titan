2811212
I0526 00:57:58.917853 20937 caffe.cpp:184] Using GPUs 0
I0526 00:57:59.337993 20937 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0015
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706.prototxt"
I0526 00:57:59.341787 20937 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706.prototxt
I0526 00:57:59.357167 20937 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 00:57:59.357229 20937 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 00:57:59.357609 20937 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 00:57:59.357815 20937 layer_factory.hpp:77] Creating layer data_hdf5
I0526 00:57:59.357843 20937 net.cpp:106] Creating Layer data_hdf5
I0526 00:57:59.357868 20937 net.cpp:411] data_hdf5 -> data
I0526 00:57:59.357902 20937 net.cpp:411] data_hdf5 -> label
I0526 00:57:59.357939 20937 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 00:57:59.366875 20937 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 00:57:59.383491 20937 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 00:58:20.959674 20937 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 00:58:20.964949 20937 net.cpp:150] Setting up data_hdf5
I0526 00:58:20.964990 20937 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0526 00:58:20.965008 20937 net.cpp:157] Top shape: 40 (40)
I0526 00:58:20.965020 20937 net.cpp:165] Memory required for data: 1016160
I0526 00:58:20.965052 20937 layer_factory.hpp:77] Creating layer conv1
I0526 00:58:20.965086 20937 net.cpp:106] Creating Layer conv1
I0526 00:58:20.965101 20937 net.cpp:454] conv1 <- data
I0526 00:58:20.965124 20937 net.cpp:411] conv1 -> conv1
I0526 00:58:22.741078 20937 net.cpp:150] Setting up conv1
I0526 00:58:22.741130 20937 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0526 00:58:22.741153 20937 net.cpp:165] Memory required for data: 12075360
I0526 00:58:22.741184 20937 layer_factory.hpp:77] Creating layer relu1
I0526 00:58:22.741206 20937 net.cpp:106] Creating Layer relu1
I0526 00:58:22.741225 20937 net.cpp:454] relu1 <- conv1
I0526 00:58:22.741261 20937 net.cpp:397] relu1 -> conv1 (in-place)
I0526 00:58:22.741794 20937 net.cpp:150] Setting up relu1
I0526 00:58:22.741818 20937 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0526 00:58:22.741832 20937 net.cpp:165] Memory required for data: 23134560
I0526 00:58:22.741848 20937 layer_factory.hpp:77] Creating layer pool1
I0526 00:58:22.741875 20937 net.cpp:106] Creating Layer pool1
I0526 00:58:22.741889 20937 net.cpp:454] pool1 <- conv1
I0526 00:58:22.741905 20937 net.cpp:411] pool1 -> pool1
I0526 00:58:22.741999 20937 net.cpp:150] Setting up pool1
I0526 00:58:22.742020 20937 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0526 00:58:22.742039 20937 net.cpp:165] Memory required for data: 28664160
I0526 00:58:22.742053 20937 layer_factory.hpp:77] Creating layer conv2
I0526 00:58:22.742077 20937 net.cpp:106] Creating Layer conv2
I0526 00:58:22.742091 20937 net.cpp:454] conv2 <- pool1
I0526 00:58:22.742110 20937 net.cpp:411] conv2 -> conv2
I0526 00:58:22.744797 20937 net.cpp:150] Setting up conv2
I0526 00:58:22.744828 20937 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0526 00:58:22.744842 20937 net.cpp:165] Memory required for data: 36612960
I0526 00:58:22.744869 20937 layer_factory.hpp:77] Creating layer relu2
I0526 00:58:22.744899 20937 net.cpp:106] Creating Layer relu2
I0526 00:58:22.744911 20937 net.cpp:454] relu2 <- conv2
I0526 00:58:22.744928 20937 net.cpp:397] relu2 -> conv2 (in-place)
I0526 00:58:22.745285 20937 net.cpp:150] Setting up relu2
I0526 00:58:22.745304 20937 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0526 00:58:22.745317 20937 net.cpp:165] Memory required for data: 44561760
I0526 00:58:22.745331 20937 layer_factory.hpp:77] Creating layer pool2
I0526 00:58:22.745357 20937 net.cpp:106] Creating Layer pool2
I0526 00:58:22.745369 20937 net.cpp:454] pool2 <- conv2
I0526 00:58:22.745385 20937 net.cpp:411] pool2 -> pool2
I0526 00:58:22.745482 20937 net.cpp:150] Setting up pool2
I0526 00:58:22.745502 20937 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0526 00:58:22.745522 20937 net.cpp:165] Memory required for data: 48536160
I0526 00:58:22.745534 20937 layer_factory.hpp:77] Creating layer conv3
I0526 00:58:22.745555 20937 net.cpp:106] Creating Layer conv3
I0526 00:58:22.745568 20937 net.cpp:454] conv3 <- pool2
I0526 00:58:22.745584 20937 net.cpp:411] conv3 -> conv3
I0526 00:58:22.747541 20937 net.cpp:150] Setting up conv3
I0526 00:58:22.747566 20937 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0526 00:58:22.747586 20937 net.cpp:165] Memory required for data: 52872800
I0526 00:58:22.747609 20937 layer_factory.hpp:77] Creating layer relu3
I0526 00:58:22.747632 20937 net.cpp:106] Creating Layer relu3
I0526 00:58:22.747654 20937 net.cpp:454] relu3 <- conv3
I0526 00:58:22.747671 20937 net.cpp:397] relu3 -> conv3 (in-place)
I0526 00:58:22.748162 20937 net.cpp:150] Setting up relu3
I0526 00:58:22.748186 20937 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0526 00:58:22.748199 20937 net.cpp:165] Memory required for data: 57209440
I0526 00:58:22.748215 20937 layer_factory.hpp:77] Creating layer pool3
I0526 00:58:22.748230 20937 net.cpp:106] Creating Layer pool3
I0526 00:58:22.748251 20937 net.cpp:454] pool3 <- conv3
I0526 00:58:22.748267 20937 net.cpp:411] pool3 -> pool3
I0526 00:58:22.748358 20937 net.cpp:150] Setting up pool3
I0526 00:58:22.748374 20937 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0526 00:58:22.748389 20937 net.cpp:165] Memory required for data: 59377760
I0526 00:58:22.748400 20937 layer_factory.hpp:77] Creating layer conv4
I0526 00:58:22.748427 20937 net.cpp:106] Creating Layer conv4
I0526 00:58:22.748447 20937 net.cpp:454] conv4 <- pool3
I0526 00:58:22.748463 20937 net.cpp:411] conv4 -> conv4
I0526 00:58:22.751243 20937 net.cpp:150] Setting up conv4
I0526 00:58:22.751276 20937 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0526 00:58:22.751291 20937 net.cpp:165] Memory required for data: 60829280
I0526 00:58:22.751310 20937 layer_factory.hpp:77] Creating layer relu4
I0526 00:58:22.751332 20937 net.cpp:106] Creating Layer relu4
I0526 00:58:22.751358 20937 net.cpp:454] relu4 <- conv4
I0526 00:58:22.751374 20937 net.cpp:397] relu4 -> conv4 (in-place)
I0526 00:58:22.751869 20937 net.cpp:150] Setting up relu4
I0526 00:58:22.751893 20937 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0526 00:58:22.751906 20937 net.cpp:165] Memory required for data: 62280800
I0526 00:58:22.751922 20937 layer_factory.hpp:77] Creating layer pool4
I0526 00:58:22.751937 20937 net.cpp:106] Creating Layer pool4
I0526 00:58:22.751960 20937 net.cpp:454] pool4 <- conv4
I0526 00:58:22.751976 20937 net.cpp:411] pool4 -> pool4
I0526 00:58:22.752058 20937 net.cpp:150] Setting up pool4
I0526 00:58:22.752081 20937 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0526 00:58:22.752095 20937 net.cpp:165] Memory required for data: 63006560
I0526 00:58:22.752110 20937 layer_factory.hpp:77] Creating layer ip1
I0526 00:58:22.752137 20937 net.cpp:106] Creating Layer ip1
I0526 00:58:22.752151 20937 net.cpp:454] ip1 <- pool4
I0526 00:58:22.752166 20937 net.cpp:411] ip1 -> ip1
I0526 00:58:22.767642 20937 net.cpp:150] Setting up ip1
I0526 00:58:22.767673 20937 net.cpp:157] Top shape: 40 196 (7840)
I0526 00:58:22.767695 20937 net.cpp:165] Memory required for data: 63037920
I0526 00:58:22.767722 20937 layer_factory.hpp:77] Creating layer relu5
I0526 00:58:22.767743 20937 net.cpp:106] Creating Layer relu5
I0526 00:58:22.767768 20937 net.cpp:454] relu5 <- ip1
I0526 00:58:22.767784 20937 net.cpp:397] relu5 -> ip1 (in-place)
I0526 00:58:22.768143 20937 net.cpp:150] Setting up relu5
I0526 00:58:22.768163 20937 net.cpp:157] Top shape: 40 196 (7840)
I0526 00:58:22.768177 20937 net.cpp:165] Memory required for data: 63069280
I0526 00:58:22.768192 20937 layer_factory.hpp:77] Creating layer drop1
I0526 00:58:22.768223 20937 net.cpp:106] Creating Layer drop1
I0526 00:58:22.768236 20937 net.cpp:454] drop1 <- ip1
I0526 00:58:22.768252 20937 net.cpp:397] drop1 -> ip1 (in-place)
I0526 00:58:22.768324 20937 net.cpp:150] Setting up drop1
I0526 00:58:22.768347 20937 net.cpp:157] Top shape: 40 196 (7840)
I0526 00:58:22.768360 20937 net.cpp:165] Memory required for data: 63100640
I0526 00:58:22.768376 20937 layer_factory.hpp:77] Creating layer ip2
I0526 00:58:22.768398 20937 net.cpp:106] Creating Layer ip2
I0526 00:58:22.768416 20937 net.cpp:454] ip2 <- ip1
I0526 00:58:22.768438 20937 net.cpp:411] ip2 -> ip2
I0526 00:58:22.768923 20937 net.cpp:150] Setting up ip2
I0526 00:58:22.768942 20937 net.cpp:157] Top shape: 40 98 (3920)
I0526 00:58:22.768955 20937 net.cpp:165] Memory required for data: 63116320
I0526 00:58:22.768976 20937 layer_factory.hpp:77] Creating layer relu6
I0526 00:58:22.768990 20937 net.cpp:106] Creating Layer relu6
I0526 00:58:22.769011 20937 net.cpp:454] relu6 <- ip2
I0526 00:58:22.769026 20937 net.cpp:397] relu6 -> ip2 (in-place)
I0526 00:58:22.769572 20937 net.cpp:150] Setting up relu6
I0526 00:58:22.769595 20937 net.cpp:157] Top shape: 40 98 (3920)
I0526 00:58:22.769609 20937 net.cpp:165] Memory required for data: 63132000
I0526 00:58:22.769624 20937 layer_factory.hpp:77] Creating layer drop2
I0526 00:58:22.769639 20937 net.cpp:106] Creating Layer drop2
I0526 00:58:22.769660 20937 net.cpp:454] drop2 <- ip2
I0526 00:58:22.769676 20937 net.cpp:397] drop2 -> ip2 (in-place)
I0526 00:58:22.769727 20937 net.cpp:150] Setting up drop2
I0526 00:58:22.769749 20937 net.cpp:157] Top shape: 40 98 (3920)
I0526 00:58:22.769762 20937 net.cpp:165] Memory required for data: 63147680
I0526 00:58:22.769780 20937 layer_factory.hpp:77] Creating layer ip3
I0526 00:58:22.769796 20937 net.cpp:106] Creating Layer ip3
I0526 00:58:22.769811 20937 net.cpp:454] ip3 <- ip2
I0526 00:58:22.769827 20937 net.cpp:411] ip3 -> ip3
I0526 00:58:22.770061 20937 net.cpp:150] Setting up ip3
I0526 00:58:22.770079 20937 net.cpp:157] Top shape: 40 11 (440)
I0526 00:58:22.770092 20937 net.cpp:165] Memory required for data: 63149440
I0526 00:58:22.770112 20937 layer_factory.hpp:77] Creating layer drop3
I0526 00:58:22.770134 20937 net.cpp:106] Creating Layer drop3
I0526 00:58:22.770148 20937 net.cpp:454] drop3 <- ip3
I0526 00:58:22.770162 20937 net.cpp:397] drop3 -> ip3 (in-place)
I0526 00:58:22.770210 20937 net.cpp:150] Setting up drop3
I0526 00:58:22.770231 20937 net.cpp:157] Top shape: 40 11 (440)
I0526 00:58:22.770244 20937 net.cpp:165] Memory required for data: 63151200
I0526 00:58:22.770261 20937 layer_factory.hpp:77] Creating layer loss
I0526 00:58:22.770282 20937 net.cpp:106] Creating Layer loss
I0526 00:58:22.770298 20937 net.cpp:454] loss <- ip3
I0526 00:58:22.770311 20937 net.cpp:454] loss <- label
I0526 00:58:22.770334 20937 net.cpp:411] loss -> loss
I0526 00:58:22.770354 20937 layer_factory.hpp:77] Creating layer loss
I0526 00:58:22.771020 20937 net.cpp:150] Setting up loss
I0526 00:58:22.771042 20937 net.cpp:157] Top shape: (1)
I0526 00:58:22.771059 20937 net.cpp:160]     with loss weight 1
I0526 00:58:22.771111 20937 net.cpp:165] Memory required for data: 63151204
I0526 00:58:22.771133 20937 net.cpp:226] loss needs backward computation.
I0526 00:58:22.771147 20937 net.cpp:226] drop3 needs backward computation.
I0526 00:58:22.771160 20937 net.cpp:226] ip3 needs backward computation.
I0526 00:58:22.771173 20937 net.cpp:226] drop2 needs backward computation.
I0526 00:58:22.771185 20937 net.cpp:226] relu6 needs backward computation.
I0526 00:58:22.771199 20937 net.cpp:226] ip2 needs backward computation.
I0526 00:58:22.771219 20937 net.cpp:226] drop1 needs backward computation.
I0526 00:58:22.771231 20937 net.cpp:226] relu5 needs backward computation.
I0526 00:58:22.771245 20937 net.cpp:226] ip1 needs backward computation.
I0526 00:58:22.771260 20937 net.cpp:226] pool4 needs backward computation.
I0526 00:58:22.771273 20937 net.cpp:226] relu4 needs backward computation.
I0526 00:58:22.771286 20937 net.cpp:226] conv4 needs backward computation.
I0526 00:58:22.771299 20937 net.cpp:226] pool3 needs backward computation.
I0526 00:58:22.771314 20937 net.cpp:226] relu3 needs backward computation.
I0526 00:58:22.771335 20937 net.cpp:226] conv3 needs backward computation.
I0526 00:58:22.771358 20937 net.cpp:226] pool2 needs backward computation.
I0526 00:58:22.771371 20937 net.cpp:226] relu2 needs backward computation.
I0526 00:58:22.771384 20937 net.cpp:226] conv2 needs backward computation.
I0526 00:58:22.771399 20937 net.cpp:226] pool1 needs backward computation.
I0526 00:58:22.771411 20937 net.cpp:226] relu1 needs backward computation.
I0526 00:58:22.771431 20937 net.cpp:226] conv1 needs backward computation.
I0526 00:58:22.771445 20937 net.cpp:228] data_hdf5 does not need backward computation.
I0526 00:58:22.771461 20937 net.cpp:270] This network produces output loss
I0526 00:58:22.771487 20937 net.cpp:283] Network initialization done.
I0526 00:58:22.773350 20937 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706.prototxt
I0526 00:58:22.773429 20937 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 00:58:22.773809 20937 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 00:58:22.774032 20937 layer_factory.hpp:77] Creating layer data_hdf5
I0526 00:58:22.774052 20937 net.cpp:106] Creating Layer data_hdf5
I0526 00:58:22.774067 20937 net.cpp:411] data_hdf5 -> data
I0526 00:58:22.774090 20937 net.cpp:411] data_hdf5 -> label
I0526 00:58:22.774107 20937 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 00:58:22.785403 20937 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 00:58:44.157960 20937 net.cpp:150] Setting up data_hdf5
I0526 00:58:44.158143 20937 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0526 00:58:44.158162 20937 net.cpp:157] Top shape: 40 (40)
I0526 00:58:44.158174 20937 net.cpp:165] Memory required for data: 1016160
I0526 00:58:44.158190 20937 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 00:58:44.158223 20937 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 00:58:44.158237 20937 net.cpp:454] label_data_hdf5_1_split <- label
I0526 00:58:44.158272 20937 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 00:58:44.158295 20937 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 00:58:44.158382 20937 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 00:58:44.158399 20937 net.cpp:157] Top shape: 40 (40)
I0526 00:58:44.158414 20937 net.cpp:157] Top shape: 40 (40)
I0526 00:58:44.158427 20937 net.cpp:165] Memory required for data: 1016480
I0526 00:58:44.158439 20937 layer_factory.hpp:77] Creating layer conv1
I0526 00:58:44.158473 20937 net.cpp:106] Creating Layer conv1
I0526 00:58:44.158485 20937 net.cpp:454] conv1 <- data
I0526 00:58:44.158504 20937 net.cpp:411] conv1 -> conv1
I0526 00:58:44.160459 20937 net.cpp:150] Setting up conv1
I0526 00:58:44.160485 20937 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0526 00:58:44.160506 20937 net.cpp:165] Memory required for data: 12075680
I0526 00:58:44.160531 20937 layer_factory.hpp:77] Creating layer relu1
I0526 00:58:44.160552 20937 net.cpp:106] Creating Layer relu1
I0526 00:58:44.160573 20937 net.cpp:454] relu1 <- conv1
I0526 00:58:44.160590 20937 net.cpp:397] relu1 -> conv1 (in-place)
I0526 00:58:44.161106 20937 net.cpp:150] Setting up relu1
I0526 00:58:44.161129 20937 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0526 00:58:44.161144 20937 net.cpp:165] Memory required for data: 23134880
I0526 00:58:44.161155 20937 layer_factory.hpp:77] Creating layer pool1
I0526 00:58:44.161185 20937 net.cpp:106] Creating Layer pool1
I0526 00:58:44.161200 20937 net.cpp:454] pool1 <- conv1
I0526 00:58:44.161216 20937 net.cpp:411] pool1 -> pool1
I0526 00:58:44.161304 20937 net.cpp:150] Setting up pool1
I0526 00:58:44.161321 20937 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0526 00:58:44.161336 20937 net.cpp:165] Memory required for data: 28664480
I0526 00:58:44.161355 20937 layer_factory.hpp:77] Creating layer conv2
I0526 00:58:44.161376 20937 net.cpp:106] Creating Layer conv2
I0526 00:58:44.161398 20937 net.cpp:454] conv2 <- pool1
I0526 00:58:44.161415 20937 net.cpp:411] conv2 -> conv2
I0526 00:58:44.163357 20937 net.cpp:150] Setting up conv2
I0526 00:58:44.163381 20937 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0526 00:58:44.163401 20937 net.cpp:165] Memory required for data: 36613280
I0526 00:58:44.163424 20937 layer_factory.hpp:77] Creating layer relu2
I0526 00:58:44.163442 20937 net.cpp:106] Creating Layer relu2
I0526 00:58:44.163465 20937 net.cpp:454] relu2 <- conv2
I0526 00:58:44.163480 20937 net.cpp:397] relu2 -> conv2 (in-place)
I0526 00:58:44.163830 20937 net.cpp:150] Setting up relu2
I0526 00:58:44.163849 20937 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0526 00:58:44.163862 20937 net.cpp:165] Memory required for data: 44562080
I0526 00:58:44.163877 20937 layer_factory.hpp:77] Creating layer pool2
I0526 00:58:44.163899 20937 net.cpp:106] Creating Layer pool2
I0526 00:58:44.163913 20937 net.cpp:454] pool2 <- conv2
I0526 00:58:44.163928 20937 net.cpp:411] pool2 -> pool2
I0526 00:58:44.164017 20937 net.cpp:150] Setting up pool2
I0526 00:58:44.164039 20937 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0526 00:58:44.164052 20937 net.cpp:165] Memory required for data: 48536480
I0526 00:58:44.164067 20937 layer_factory.hpp:77] Creating layer conv3
I0526 00:58:44.164095 20937 net.cpp:106] Creating Layer conv3
I0526 00:58:44.164109 20937 net.cpp:454] conv3 <- pool2
I0526 00:58:44.164125 20937 net.cpp:411] conv3 -> conv3
I0526 00:58:44.166129 20937 net.cpp:150] Setting up conv3
I0526 00:58:44.166154 20937 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0526 00:58:44.166174 20937 net.cpp:165] Memory required for data: 52873120
I0526 00:58:44.166213 20937 layer_factory.hpp:77] Creating layer relu3
I0526 00:58:44.166239 20937 net.cpp:106] Creating Layer relu3
I0526 00:58:44.166254 20937 net.cpp:454] relu3 <- conv3
I0526 00:58:44.166270 20937 net.cpp:397] relu3 -> conv3 (in-place)
I0526 00:58:44.166764 20937 net.cpp:150] Setting up relu3
I0526 00:58:44.166787 20937 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0526 00:58:44.166800 20937 net.cpp:165] Memory required for data: 57209760
I0526 00:58:44.166816 20937 layer_factory.hpp:77] Creating layer pool3
I0526 00:58:44.166831 20937 net.cpp:106] Creating Layer pool3
I0526 00:58:44.166853 20937 net.cpp:454] pool3 <- conv3
I0526 00:58:44.166869 20937 net.cpp:411] pool3 -> pool3
I0526 00:58:44.166955 20937 net.cpp:150] Setting up pool3
I0526 00:58:44.166972 20937 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0526 00:58:44.166987 20937 net.cpp:165] Memory required for data: 59378080
I0526 00:58:44.166999 20937 layer_factory.hpp:77] Creating layer conv4
I0526 00:58:44.167027 20937 net.cpp:106] Creating Layer conv4
I0526 00:58:44.167040 20937 net.cpp:454] conv4 <- pool3
I0526 00:58:44.167057 20937 net.cpp:411] conv4 -> conv4
I0526 00:58:44.169155 20937 net.cpp:150] Setting up conv4
I0526 00:58:44.169179 20937 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0526 00:58:44.169199 20937 net.cpp:165] Memory required for data: 60829600
I0526 00:58:44.169219 20937 layer_factory.hpp:77] Creating layer relu4
I0526 00:58:44.169239 20937 net.cpp:106] Creating Layer relu4
I0526 00:58:44.169251 20937 net.cpp:454] relu4 <- conv4
I0526 00:58:44.169277 20937 net.cpp:397] relu4 -> conv4 (in-place)
I0526 00:58:44.169767 20937 net.cpp:150] Setting up relu4
I0526 00:58:44.169790 20937 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0526 00:58:44.169803 20937 net.cpp:165] Memory required for data: 62281120
I0526 00:58:44.169819 20937 layer_factory.hpp:77] Creating layer pool4
I0526 00:58:44.169836 20937 net.cpp:106] Creating Layer pool4
I0526 00:58:44.169857 20937 net.cpp:454] pool4 <- conv4
I0526 00:58:44.169872 20937 net.cpp:411] pool4 -> pool4
I0526 00:58:44.169960 20937 net.cpp:150] Setting up pool4
I0526 00:58:44.169976 20937 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0526 00:58:44.169991 20937 net.cpp:165] Memory required for data: 63006880
I0526 00:58:44.170003 20937 layer_factory.hpp:77] Creating layer ip1
I0526 00:58:44.170022 20937 net.cpp:106] Creating Layer ip1
I0526 00:58:44.170035 20937 net.cpp:454] ip1 <- pool4
I0526 00:58:44.170059 20937 net.cpp:411] ip1 -> ip1
I0526 00:58:44.185523 20937 net.cpp:150] Setting up ip1
I0526 00:58:44.185556 20937 net.cpp:157] Top shape: 40 196 (7840)
I0526 00:58:44.185577 20937 net.cpp:165] Memory required for data: 63038240
I0526 00:58:44.185603 20937 layer_factory.hpp:77] Creating layer relu5
I0526 00:58:44.185626 20937 net.cpp:106] Creating Layer relu5
I0526 00:58:44.185652 20937 net.cpp:454] relu5 <- ip1
I0526 00:58:44.185668 20937 net.cpp:397] relu5 -> ip1 (in-place)
I0526 00:58:44.186034 20937 net.cpp:150] Setting up relu5
I0526 00:58:44.186055 20937 net.cpp:157] Top shape: 40 196 (7840)
I0526 00:58:44.186069 20937 net.cpp:165] Memory required for data: 63069600
I0526 00:58:44.186084 20937 layer_factory.hpp:77] Creating layer drop1
I0526 00:58:44.186113 20937 net.cpp:106] Creating Layer drop1
I0526 00:58:44.186127 20937 net.cpp:454] drop1 <- ip1
I0526 00:58:44.186142 20937 net.cpp:397] drop1 -> ip1 (in-place)
I0526 00:58:44.186203 20937 net.cpp:150] Setting up drop1
I0526 00:58:44.186223 20937 net.cpp:157] Top shape: 40 196 (7840)
I0526 00:58:44.186236 20937 net.cpp:165] Memory required for data: 63100960
I0526 00:58:44.186249 20937 layer_factory.hpp:77] Creating layer ip2
I0526 00:58:44.186269 20937 net.cpp:106] Creating Layer ip2
I0526 00:58:44.186281 20937 net.cpp:454] ip2 <- ip1
I0526 00:58:44.186305 20937 net.cpp:411] ip2 -> ip2
I0526 00:58:44.186805 20937 net.cpp:150] Setting up ip2
I0526 00:58:44.186823 20937 net.cpp:157] Top shape: 40 98 (3920)
I0526 00:58:44.186836 20937 net.cpp:165] Memory required for data: 63116640
I0526 00:58:44.186858 20937 layer_factory.hpp:77] Creating layer relu6
I0526 00:58:44.186893 20937 net.cpp:106] Creating Layer relu6
I0526 00:58:44.186906 20937 net.cpp:454] relu6 <- ip2
I0526 00:58:44.186923 20937 net.cpp:397] relu6 -> ip2 (in-place)
I0526 00:58:44.187479 20937 net.cpp:150] Setting up relu6
I0526 00:58:44.187502 20937 net.cpp:157] Top shape: 40 98 (3920)
I0526 00:58:44.187515 20937 net.cpp:165] Memory required for data: 63132320
I0526 00:58:44.187527 20937 layer_factory.hpp:77] Creating layer drop2
I0526 00:58:44.187547 20937 net.cpp:106] Creating Layer drop2
I0526 00:58:44.187568 20937 net.cpp:454] drop2 <- ip2
I0526 00:58:44.187585 20937 net.cpp:397] drop2 -> ip2 (in-place)
I0526 00:58:44.187638 20937 net.cpp:150] Setting up drop2
I0526 00:58:44.187659 20937 net.cpp:157] Top shape: 40 98 (3920)
I0526 00:58:44.187672 20937 net.cpp:165] Memory required for data: 63148000
I0526 00:58:44.187691 20937 layer_factory.hpp:77] Creating layer ip3
I0526 00:58:44.187708 20937 net.cpp:106] Creating Layer ip3
I0526 00:58:44.187723 20937 net.cpp:454] ip3 <- ip2
I0526 00:58:44.187741 20937 net.cpp:411] ip3 -> ip3
I0526 00:58:44.187984 20937 net.cpp:150] Setting up ip3
I0526 00:58:44.188004 20937 net.cpp:157] Top shape: 40 11 (440)
I0526 00:58:44.188017 20937 net.cpp:165] Memory required for data: 63149760
I0526 00:58:44.188038 20937 layer_factory.hpp:77] Creating layer drop3
I0526 00:58:44.188060 20937 net.cpp:106] Creating Layer drop3
I0526 00:58:44.188074 20937 net.cpp:454] drop3 <- ip3
I0526 00:58:44.188091 20937 net.cpp:397] drop3 -> ip3 (in-place)
I0526 00:58:44.188138 20937 net.cpp:150] Setting up drop3
I0526 00:58:44.188160 20937 net.cpp:157] Top shape: 40 11 (440)
I0526 00:58:44.188174 20937 net.cpp:165] Memory required for data: 63151520
I0526 00:58:44.188187 20937 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 00:58:44.188202 20937 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 00:58:44.188217 20937 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 00:58:44.188232 20937 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 00:58:44.188258 20937 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 00:58:44.188360 20937 net.cpp:150] Setting up ip3_drop3_0_split
I0526 00:58:44.188381 20937 net.cpp:157] Top shape: 40 11 (440)
I0526 00:58:44.188396 20937 net.cpp:157] Top shape: 40 11 (440)
I0526 00:58:44.188411 20937 net.cpp:165] Memory required for data: 63155040
I0526 00:58:44.188423 20937 layer_factory.hpp:77] Creating layer accuracy
I0526 00:58:44.188452 20937 net.cpp:106] Creating Layer accuracy
I0526 00:58:44.188464 20937 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 00:58:44.188479 20937 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 00:58:44.188495 20937 net.cpp:411] accuracy -> accuracy
I0526 00:58:44.188530 20937 net.cpp:150] Setting up accuracy
I0526 00:58:44.188546 20937 net.cpp:157] Top shape: (1)
I0526 00:58:44.188562 20937 net.cpp:165] Memory required for data: 63155044
I0526 00:58:44.188575 20937 layer_factory.hpp:77] Creating layer loss
I0526 00:58:44.188591 20937 net.cpp:106] Creating Layer loss
I0526 00:58:44.188602 20937 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 00:58:44.188621 20937 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 00:58:44.188643 20937 net.cpp:411] loss -> loss
I0526 00:58:44.188663 20937 layer_factory.hpp:77] Creating layer loss
I0526 00:58:44.189179 20937 net.cpp:150] Setting up loss
I0526 00:58:44.189199 20937 net.cpp:157] Top shape: (1)
I0526 00:58:44.189213 20937 net.cpp:160]     with loss weight 1
I0526 00:58:44.189239 20937 net.cpp:165] Memory required for data: 63155048
I0526 00:58:44.189260 20937 net.cpp:226] loss needs backward computation.
I0526 00:58:44.189275 20937 net.cpp:228] accuracy does not need backward computation.
I0526 00:58:44.189292 20937 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 00:58:44.189306 20937 net.cpp:226] drop3 needs backward computation.
I0526 00:58:44.189317 20937 net.cpp:226] ip3 needs backward computation.
I0526 00:58:44.189333 20937 net.cpp:226] drop2 needs backward computation.
I0526 00:58:44.189352 20937 net.cpp:226] relu6 needs backward computation.
I0526 00:58:44.189373 20937 net.cpp:226] ip2 needs backward computation.
I0526 00:58:44.189390 20937 net.cpp:226] drop1 needs backward computation.
I0526 00:58:44.189402 20937 net.cpp:226] relu5 needs backward computation.
I0526 00:58:44.189414 20937 net.cpp:226] ip1 needs backward computation.
I0526 00:58:44.189429 20937 net.cpp:226] pool4 needs backward computation.
I0526 00:58:44.189442 20937 net.cpp:226] relu4 needs backward computation.
I0526 00:58:44.189462 20937 net.cpp:226] conv4 needs backward computation.
I0526 00:58:44.189476 20937 net.cpp:226] pool3 needs backward computation.
I0526 00:58:44.189492 20937 net.cpp:226] relu3 needs backward computation.
I0526 00:58:44.189505 20937 net.cpp:226] conv3 needs backward computation.
I0526 00:58:44.189517 20937 net.cpp:226] pool2 needs backward computation.
I0526 00:58:44.189532 20937 net.cpp:226] relu2 needs backward computation.
I0526 00:58:44.189545 20937 net.cpp:226] conv2 needs backward computation.
I0526 00:58:44.189564 20937 net.cpp:226] pool1 needs backward computation.
I0526 00:58:44.189579 20937 net.cpp:226] relu1 needs backward computation.
I0526 00:58:44.189594 20937 net.cpp:226] conv1 needs backward computation.
I0526 00:58:44.189609 20937 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 00:58:44.189622 20937 net.cpp:228] data_hdf5 does not need backward computation.
I0526 00:58:44.189635 20937 net.cpp:270] This network produces output accuracy
I0526 00:58:44.189649 20937 net.cpp:270] This network produces output loss
I0526 00:58:44.189680 20937 net.cpp:283] Network initialization done.
I0526 00:58:44.189815 20937 solver.cpp:60] Solver scaffolding done.
I0526 00:58:44.190953 20937 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_168750.solverstate
I0526 00:58:44.391876 20937 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 00:58:44.397325 20937 caffe.cpp:212] Starting Optimization
I0526 00:58:44.397367 20937 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 00:58:44.397390 20937 solver.cpp:289] Learning Rate Policy: fixed
I0526 00:58:44.424484 20937 solver.cpp:237] Iteration 168750, loss = 1.08436
I0526 00:58:44.424532 20937 solver.cpp:253]     Train net output #0: loss = 1.08436 (* 1 = 1.08436 loss)
I0526 00:58:44.424554 20937 sgd_solver.cpp:106] Iteration 168750, lr = 0.0015
I0526 00:58:54.168706 20937 solver.cpp:237] Iteration 169125, loss = 0.811321
I0526 00:58:54.168764 20937 solver.cpp:253]     Train net output #0: loss = 0.811321 (* 1 = 0.811321 loss)
I0526 00:58:54.168782 20937 sgd_solver.cpp:106] Iteration 169125, lr = 0.0015
I0526 00:59:03.880400 20937 solver.cpp:237] Iteration 169500, loss = 1.5095
I0526 00:59:03.880439 20937 solver.cpp:253]     Train net output #0: loss = 1.5095 (* 1 = 1.5095 loss)
I0526 00:59:03.880463 20937 sgd_solver.cpp:106] Iteration 169500, lr = 0.0015
I0526 00:59:13.595561 20937 solver.cpp:237] Iteration 169875, loss = 1.08745
I0526 00:59:13.595600 20937 solver.cpp:253]     Train net output #0: loss = 1.08745 (* 1 = 1.08745 loss)
I0526 00:59:13.595618 20937 sgd_solver.cpp:106] Iteration 169875, lr = 0.0015
I0526 00:59:23.427762 20937 solver.cpp:237] Iteration 170250, loss = 1.10429
I0526 00:59:23.427937 20937 solver.cpp:253]     Train net output #0: loss = 1.10429 (* 1 = 1.10429 loss)
I0526 00:59:23.427955 20937 sgd_solver.cpp:106] Iteration 170250, lr = 0.0015
I0526 00:59:33.337728 20937 solver.cpp:237] Iteration 170625, loss = 0.965267
I0526 00:59:33.337766 20937 solver.cpp:253]     Train net output #0: loss = 0.965267 (* 1 = 0.965267 loss)
I0526 00:59:33.337790 20937 sgd_solver.cpp:106] Iteration 170625, lr = 0.0015
I0526 00:59:43.256574 20937 solver.cpp:237] Iteration 171000, loss = 1.37817
I0526 00:59:43.256633 20937 solver.cpp:253]     Train net output #0: loss = 1.37817 (* 1 = 1.37817 loss)
I0526 00:59:43.256660 20937 sgd_solver.cpp:106] Iteration 171000, lr = 0.0015
I0526 01:00:15.256091 20937 solver.cpp:237] Iteration 171375, loss = 0.907792
I0526 01:00:15.256261 20937 solver.cpp:253]     Train net output #0: loss = 0.907792 (* 1 = 0.907792 loss)
I0526 01:00:15.256279 20937 sgd_solver.cpp:106] Iteration 171375, lr = 0.0015
I0526 01:00:25.131042 20937 solver.cpp:237] Iteration 171750, loss = 0.91968
I0526 01:00:25.131083 20937 solver.cpp:253]     Train net output #0: loss = 0.91968 (* 1 = 0.91968 loss)
I0526 01:00:25.131100 20937 sgd_solver.cpp:106] Iteration 171750, lr = 0.0015
I0526 01:00:35.011342 20937 solver.cpp:237] Iteration 172125, loss = 1.40091
I0526 01:00:35.011396 20937 solver.cpp:253]     Train net output #0: loss = 1.40091 (* 1 = 1.40091 loss)
I0526 01:00:35.011415 20937 sgd_solver.cpp:106] Iteration 172125, lr = 0.0015
I0526 01:00:44.891464 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_172500.caffemodel
I0526 01:00:44.948680 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_172500.solverstate
I0526 01:00:44.973939 20937 solver.cpp:341] Iteration 172500, Testing net (#0)
I0526 01:01:34.549872 20937 solver.cpp:409]     Test net output #0: accuracy = 0.89414
I0526 01:01:34.550040 20937 solver.cpp:409]     Test net output #1: loss = 0.321599 (* 1 = 0.321599 loss)
I0526 01:01:34.558143 20937 solver.cpp:237] Iteration 172500, loss = 0.991482
I0526 01:01:34.558173 20937 solver.cpp:253]     Train net output #0: loss = 0.991482 (* 1 = 0.991482 loss)
I0526 01:01:34.558190 20937 sgd_solver.cpp:106] Iteration 172500, lr = 0.0015
I0526 01:01:44.346128 20937 solver.cpp:237] Iteration 172875, loss = 1.09205
I0526 01:01:44.346168 20937 solver.cpp:253]     Train net output #0: loss = 1.09205 (* 1 = 1.09205 loss)
I0526 01:01:44.346186 20937 sgd_solver.cpp:106] Iteration 172875, lr = 0.0015
I0526 01:01:54.171795 20937 solver.cpp:237] Iteration 173250, loss = 1.19487
I0526 01:01:54.171850 20937 solver.cpp:253]     Train net output #0: loss = 1.19487 (* 1 = 1.19487 loss)
I0526 01:01:54.171867 20937 sgd_solver.cpp:106] Iteration 173250, lr = 0.0015
I0526 01:02:04.021401 20937 solver.cpp:237] Iteration 173625, loss = 0.994244
I0526 01:02:04.021441 20937 solver.cpp:253]     Train net output #0: loss = 0.994244 (* 1 = 0.994244 loss)
I0526 01:02:04.021458 20937 sgd_solver.cpp:106] Iteration 173625, lr = 0.0015
I0526 01:02:35.994058 20937 solver.cpp:237] Iteration 174000, loss = 1.18693
I0526 01:02:35.994237 20937 solver.cpp:253]     Train net output #0: loss = 1.18693 (* 1 = 1.18693 loss)
I0526 01:02:35.994254 20937 sgd_solver.cpp:106] Iteration 174000, lr = 0.0015
I0526 01:02:45.827523 20937 solver.cpp:237] Iteration 174375, loss = 1.06734
I0526 01:02:45.827577 20937 solver.cpp:253]     Train net output #0: loss = 1.06734 (* 1 = 1.06734 loss)
I0526 01:02:45.827606 20937 sgd_solver.cpp:106] Iteration 174375, lr = 0.0015
I0526 01:02:55.664266 20937 solver.cpp:237] Iteration 174750, loss = 1.40749
I0526 01:02:55.664304 20937 solver.cpp:253]     Train net output #0: loss = 1.40749 (* 1 = 1.40749 loss)
I0526 01:02:55.664324 20937 sgd_solver.cpp:106] Iteration 174750, lr = 0.0015
I0526 01:03:05.513664 20937 solver.cpp:237] Iteration 175125, loss = 1.12019
I0526 01:03:05.513721 20937 solver.cpp:253]     Train net output #0: loss = 1.12019 (* 1 = 1.12019 loss)
I0526 01:03:05.513748 20937 sgd_solver.cpp:106] Iteration 175125, lr = 0.0015
I0526 01:03:15.408532 20937 solver.cpp:237] Iteration 175500, loss = 0.917616
I0526 01:03:15.408695 20937 solver.cpp:253]     Train net output #0: loss = 0.917616 (* 1 = 0.917616 loss)
I0526 01:03:15.408712 20937 sgd_solver.cpp:106] Iteration 175500, lr = 0.0015
I0526 01:03:25.301851 20937 solver.cpp:237] Iteration 175875, loss = 1.18886
I0526 01:03:25.301887 20937 solver.cpp:253]     Train net output #0: loss = 1.18886 (* 1 = 1.18886 loss)
I0526 01:03:25.301911 20937 sgd_solver.cpp:106] Iteration 175875, lr = 0.0015
I0526 01:03:35.172802 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_176250.caffemodel
I0526 01:03:35.229684 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_176250.solverstate
I0526 01:03:57.367404 20937 solver.cpp:237] Iteration 176250, loss = 0.988831
I0526 01:03:57.367580 20937 solver.cpp:253]     Train net output #0: loss = 0.988831 (* 1 = 0.988831 loss)
I0526 01:03:57.367599 20937 sgd_solver.cpp:106] Iteration 176250, lr = 0.0015
I0526 01:04:07.267618 20937 solver.cpp:237] Iteration 176625, loss = 1.20922
I0526 01:04:07.267657 20937 solver.cpp:253]     Train net output #0: loss = 1.20922 (* 1 = 1.20922 loss)
I0526 01:04:07.267680 20937 sgd_solver.cpp:106] Iteration 176625, lr = 0.0015
I0526 01:04:17.164597 20937 solver.cpp:237] Iteration 177000, loss = 0.96101
I0526 01:04:17.164636 20937 solver.cpp:253]     Train net output #0: loss = 0.961011 (* 1 = 0.961011 loss)
I0526 01:04:17.164655 20937 sgd_solver.cpp:106] Iteration 177000, lr = 0.0015
I0526 01:04:26.884740 20937 solver.cpp:237] Iteration 177375, loss = 1.18098
I0526 01:04:26.884791 20937 solver.cpp:253]     Train net output #0: loss = 1.18098 (* 1 = 1.18098 loss)
I0526 01:04:26.884809 20937 sgd_solver.cpp:106] Iteration 177375, lr = 0.0015
I0526 01:04:36.603219 20937 solver.cpp:237] Iteration 177750, loss = 1.19925
I0526 01:04:36.603361 20937 solver.cpp:253]     Train net output #0: loss = 1.19925 (* 1 = 1.19925 loss)
I0526 01:04:36.603379 20937 sgd_solver.cpp:106] Iteration 177750, lr = 0.0015
I0526 01:04:46.329303 20937 solver.cpp:237] Iteration 178125, loss = 1.1547
I0526 01:04:46.329362 20937 solver.cpp:253]     Train net output #0: loss = 1.1547 (* 1 = 1.1547 loss)
I0526 01:04:46.329387 20937 sgd_solver.cpp:106] Iteration 178125, lr = 0.0015
I0526 01:04:56.048893 20937 solver.cpp:237] Iteration 178500, loss = 1.22123
I0526 01:04:56.048933 20937 solver.cpp:253]     Train net output #0: loss = 1.22123 (* 1 = 1.22123 loss)
I0526 01:04:56.048950 20937 sgd_solver.cpp:106] Iteration 178500, lr = 0.0015
I0526 01:05:27.914788 20937 solver.cpp:237] Iteration 178875, loss = 1.40677
I0526 01:05:27.914958 20937 solver.cpp:253]     Train net output #0: loss = 1.40677 (* 1 = 1.40677 loss)
I0526 01:05:27.914975 20937 sgd_solver.cpp:106] Iteration 178875, lr = 0.0015
I0526 01:05:37.709400 20937 solver.cpp:237] Iteration 179250, loss = 0.760581
I0526 01:05:37.709458 20937 solver.cpp:253]     Train net output #0: loss = 0.760581 (* 1 = 0.760581 loss)
I0526 01:05:37.709486 20937 sgd_solver.cpp:106] Iteration 179250, lr = 0.0015
I0526 01:05:47.559927 20937 solver.cpp:237] Iteration 179625, loss = 1.11742
I0526 01:05:47.559972 20937 solver.cpp:253]     Train net output #0: loss = 1.11742 (* 1 = 1.11742 loss)
I0526 01:05:47.559988 20937 sgd_solver.cpp:106] Iteration 179625, lr = 0.0015
I0526 01:05:57.380762 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_180000.caffemodel
I0526 01:05:57.439970 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_180000.solverstate
I0526 01:05:57.467960 20937 solver.cpp:341] Iteration 180000, Testing net (#0)
I0526 01:06:46.092036 20937 solver.cpp:409]     Test net output #0: accuracy = 0.896257
I0526 01:06:46.092219 20937 solver.cpp:409]     Test net output #1: loss = 0.332954 (* 1 = 0.332954 loss)
I0526 01:06:46.100332 20937 solver.cpp:237] Iteration 180000, loss = 1.14142
I0526 01:06:46.100368 20937 solver.cpp:253]     Train net output #0: loss = 1.14142 (* 1 = 1.14142 loss)
I0526 01:06:46.100384 20937 sgd_solver.cpp:106] Iteration 180000, lr = 0.0015
I0526 01:06:55.866421 20937 solver.cpp:237] Iteration 180375, loss = 1.02774
I0526 01:06:55.866479 20937 solver.cpp:253]     Train net output #0: loss = 1.02774 (* 1 = 1.02774 loss)
I0526 01:06:55.866504 20937 sgd_solver.cpp:106] Iteration 180375, lr = 0.0015
I0526 01:07:05.604243 20937 solver.cpp:237] Iteration 180750, loss = 1.22625
I0526 01:07:05.604281 20937 solver.cpp:253]     Train net output #0: loss = 1.22625 (* 1 = 1.22625 loss)
I0526 01:07:05.604300 20937 sgd_solver.cpp:106] Iteration 180750, lr = 0.0015
I0526 01:07:15.333256 20937 solver.cpp:237] Iteration 181125, loss = 1.13681
I0526 01:07:15.333312 20937 solver.cpp:253]     Train net output #0: loss = 1.13681 (* 1 = 1.13681 loss)
I0526 01:07:15.333329 20937 sgd_solver.cpp:106] Iteration 181125, lr = 0.0015
I0526 01:07:47.247629 20937 solver.cpp:237] Iteration 181500, loss = 1.23082
I0526 01:07:47.247814 20937 solver.cpp:253]     Train net output #0: loss = 1.23082 (* 1 = 1.23082 loss)
I0526 01:07:47.247833 20937 sgd_solver.cpp:106] Iteration 181500, lr = 0.0015
I0526 01:07:56.978309 20937 solver.cpp:237] Iteration 181875, loss = 0.931244
I0526 01:07:56.978348 20937 solver.cpp:253]     Train net output #0: loss = 0.931244 (* 1 = 0.931244 loss)
I0526 01:07:56.978366 20937 sgd_solver.cpp:106] Iteration 181875, lr = 0.0015
I0526 01:08:06.724548 20937 solver.cpp:237] Iteration 182250, loss = 1.09705
I0526 01:08:06.724607 20937 solver.cpp:253]     Train net output #0: loss = 1.09705 (* 1 = 1.09705 loss)
I0526 01:08:06.724628 20937 sgd_solver.cpp:106] Iteration 182250, lr = 0.0015
I0526 01:08:16.497133 20937 solver.cpp:237] Iteration 182625, loss = 1.14262
I0526 01:08:16.497170 20937 solver.cpp:253]     Train net output #0: loss = 1.14262 (* 1 = 1.14262 loss)
I0526 01:08:16.497189 20937 sgd_solver.cpp:106] Iteration 182625, lr = 0.0015
I0526 01:08:26.276123 20937 solver.cpp:237] Iteration 183000, loss = 1.15846
I0526 01:08:26.276267 20937 solver.cpp:253]     Train net output #0: loss = 1.15846 (* 1 = 1.15846 loss)
I0526 01:08:26.276284 20937 sgd_solver.cpp:106] Iteration 183000, lr = 0.0015
I0526 01:08:36.018714 20937 solver.cpp:237] Iteration 183375, loss = 0.813142
I0526 01:08:36.018774 20937 solver.cpp:253]     Train net output #0: loss = 0.813142 (* 1 = 0.813142 loss)
I0526 01:08:36.018798 20937 sgd_solver.cpp:106] Iteration 183375, lr = 0.0015
I0526 01:08:45.725150 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_183750.caffemodel
I0526 01:08:45.783607 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_183750.solverstate
I0526 01:09:08.064671 20937 solver.cpp:237] Iteration 183750, loss = 0.829113
I0526 01:09:08.064857 20937 solver.cpp:253]     Train net output #0: loss = 0.829114 (* 1 = 0.829114 loss)
I0526 01:09:08.064877 20937 sgd_solver.cpp:106] Iteration 183750, lr = 0.0015
I0526 01:09:17.799310 20937 solver.cpp:237] Iteration 184125, loss = 0.886894
I0526 01:09:17.799368 20937 solver.cpp:253]     Train net output #0: loss = 0.886894 (* 1 = 0.886894 loss)
I0526 01:09:17.799386 20937 sgd_solver.cpp:106] Iteration 184125, lr = 0.0015
I0526 01:09:27.546545 20937 solver.cpp:237] Iteration 184500, loss = 1.15416
I0526 01:09:27.546586 20937 solver.cpp:253]     Train net output #0: loss = 1.15416 (* 1 = 1.15416 loss)
I0526 01:09:27.546609 20937 sgd_solver.cpp:106] Iteration 184500, lr = 0.0015
I0526 01:09:37.297845 20937 solver.cpp:237] Iteration 184875, loss = 1.14743
I0526 01:09:37.297883 20937 solver.cpp:253]     Train net output #0: loss = 1.14743 (* 1 = 1.14743 loss)
I0526 01:09:37.297901 20937 sgd_solver.cpp:106] Iteration 184875, lr = 0.0015
I0526 01:09:47.068840 20937 solver.cpp:237] Iteration 185250, loss = 1.40763
I0526 01:09:47.069007 20937 solver.cpp:253]     Train net output #0: loss = 1.40763 (* 1 = 1.40763 loss)
I0526 01:09:47.069025 20937 sgd_solver.cpp:106] Iteration 185250, lr = 0.0015
I0526 01:09:56.860177 20937 solver.cpp:237] Iteration 185625, loss = 1.35374
I0526 01:09:56.860215 20937 solver.cpp:253]     Train net output #0: loss = 1.35374 (* 1 = 1.35374 loss)
I0526 01:09:56.860232 20937 sgd_solver.cpp:106] Iteration 185625, lr = 0.0015
I0526 01:10:06.653571 20937 solver.cpp:237] Iteration 186000, loss = 1.12408
I0526 01:10:06.653609 20937 solver.cpp:253]     Train net output #0: loss = 1.12408 (* 1 = 1.12408 loss)
I0526 01:10:06.653626 20937 sgd_solver.cpp:106] Iteration 186000, lr = 0.0015
I0526 01:10:38.593538 20937 solver.cpp:237] Iteration 186375, loss = 1.124
I0526 01:10:38.593719 20937 solver.cpp:253]     Train net output #0: loss = 1.124 (* 1 = 1.124 loss)
I0526 01:10:38.593736 20937 sgd_solver.cpp:106] Iteration 186375, lr = 0.0015
I0526 01:10:48.312666 20937 solver.cpp:237] Iteration 186750, loss = 1.24651
I0526 01:10:48.312703 20937 solver.cpp:253]     Train net output #0: loss = 1.24651 (* 1 = 1.24651 loss)
I0526 01:10:48.312722 20937 sgd_solver.cpp:106] Iteration 186750, lr = 0.0015
I0526 01:10:58.031769 20937 solver.cpp:237] Iteration 187125, loss = 1.04843
I0526 01:10:58.031826 20937 solver.cpp:253]     Train net output #0: loss = 1.04843 (* 1 = 1.04843 loss)
I0526 01:10:58.031853 20937 sgd_solver.cpp:106] Iteration 187125, lr = 0.0015
I0526 01:11:07.726876 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_187500.caffemodel
I0526 01:11:07.785527 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_187500.solverstate
I0526 01:11:07.813287 20937 solver.cpp:341] Iteration 187500, Testing net (#0)
I0526 01:12:17.248466 20937 solver.cpp:409]     Test net output #0: accuracy = 0.895713
I0526 01:12:17.248634 20937 solver.cpp:409]     Test net output #1: loss = 0.324718 (* 1 = 0.324718 loss)
I0526 01:12:17.256736 20937 solver.cpp:237] Iteration 187500, loss = 1.13114
I0526 01:12:17.256764 20937 solver.cpp:253]     Train net output #0: loss = 1.13114 (* 1 = 1.13114 loss)
I0526 01:12:17.256781 20937 sgd_solver.cpp:106] Iteration 187500, lr = 0.0015
I0526 01:12:26.982600 20937 solver.cpp:237] Iteration 187875, loss = 1.07609
I0526 01:12:26.982638 20937 solver.cpp:253]     Train net output #0: loss = 1.07609 (* 1 = 1.07609 loss)
I0526 01:12:26.982656 20937 sgd_solver.cpp:106] Iteration 187875, lr = 0.0015
I0526 01:12:36.739035 20937 solver.cpp:237] Iteration 188250, loss = 1.22869
I0526 01:12:36.739073 20937 solver.cpp:253]     Train net output #0: loss = 1.22869 (* 1 = 1.22869 loss)
I0526 01:12:36.739097 20937 sgd_solver.cpp:106] Iteration 188250, lr = 0.0015
I0526 01:12:46.469681 20937 solver.cpp:237] Iteration 188625, loss = 1.11338
I0526 01:12:46.469732 20937 solver.cpp:253]     Train net output #0: loss = 1.11338 (* 1 = 1.11338 loss)
I0526 01:12:46.469759 20937 sgd_solver.cpp:106] Iteration 188625, lr = 0.0015
I0526 01:13:18.387434 20937 solver.cpp:237] Iteration 189000, loss = 1.23947
I0526 01:13:18.387614 20937 solver.cpp:253]     Train net output #0: loss = 1.23947 (* 1 = 1.23947 loss)
I0526 01:13:18.387631 20937 sgd_solver.cpp:106] Iteration 189000, lr = 0.0015
I0526 01:13:28.130328 20937 solver.cpp:237] Iteration 189375, loss = 1.04526
I0526 01:13:28.130385 20937 solver.cpp:253]     Train net output #0: loss = 1.04526 (* 1 = 1.04526 loss)
I0526 01:13:28.130414 20937 sgd_solver.cpp:106] Iteration 189375, lr = 0.0015
I0526 01:13:38.089725 20937 solver.cpp:237] Iteration 189750, loss = 1.27819
I0526 01:13:38.089764 20937 solver.cpp:253]     Train net output #0: loss = 1.27819 (* 1 = 1.27819 loss)
I0526 01:13:38.089782 20937 sgd_solver.cpp:106] Iteration 189750, lr = 0.0015
I0526 01:13:48.052224 20937 solver.cpp:237] Iteration 190125, loss = 1.26008
I0526 01:13:48.052264 20937 solver.cpp:253]     Train net output #0: loss = 1.26008 (* 1 = 1.26008 loss)
I0526 01:13:48.052281 20937 sgd_solver.cpp:106] Iteration 190125, lr = 0.0015
I0526 01:13:57.881081 20937 solver.cpp:237] Iteration 190500, loss = 1.2902
I0526 01:13:57.881243 20937 solver.cpp:253]     Train net output #0: loss = 1.2902 (* 1 = 1.2902 loss)
I0526 01:13:57.881261 20937 sgd_solver.cpp:106] Iteration 190500, lr = 0.0015
I0526 01:14:07.597694 20937 solver.cpp:237] Iteration 190875, loss = 0.740314
I0526 01:14:07.597733 20937 solver.cpp:253]     Train net output #0: loss = 0.740314 (* 1 = 0.740314 loss)
I0526 01:14:07.597751 20937 sgd_solver.cpp:106] Iteration 190875, lr = 0.0015
I0526 01:14:17.284114 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_191250.caffemodel
I0526 01:14:17.339982 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_191250.solverstate
I0526 01:14:39.553863 20937 solver.cpp:237] Iteration 191250, loss = 1.17263
I0526 01:14:39.554042 20937 solver.cpp:253]     Train net output #0: loss = 1.17263 (* 1 = 1.17263 loss)
I0526 01:14:39.554061 20937 sgd_solver.cpp:106] Iteration 191250, lr = 0.0015
I0526 01:14:49.273036 20937 solver.cpp:237] Iteration 191625, loss = 0.990834
I0526 01:14:49.273097 20937 solver.cpp:253]     Train net output #0: loss = 0.990834 (* 1 = 0.990834 loss)
I0526 01:14:49.273121 20937 sgd_solver.cpp:106] Iteration 191625, lr = 0.0015
I0526 01:14:58.990964 20937 solver.cpp:237] Iteration 192000, loss = 1.18908
I0526 01:14:58.991003 20937 solver.cpp:253]     Train net output #0: loss = 1.18908 (* 1 = 1.18908 loss)
I0526 01:14:58.991025 20937 sgd_solver.cpp:106] Iteration 192000, lr = 0.0015
I0526 01:15:08.708042 20937 solver.cpp:237] Iteration 192375, loss = 1.45021
I0526 01:15:08.708098 20937 solver.cpp:253]     Train net output #0: loss = 1.45021 (* 1 = 1.45021 loss)
I0526 01:15:08.708125 20937 sgd_solver.cpp:106] Iteration 192375, lr = 0.0015
I0526 01:15:18.439060 20937 solver.cpp:237] Iteration 192750, loss = 1.2483
I0526 01:15:18.439208 20937 solver.cpp:253]     Train net output #0: loss = 1.2483 (* 1 = 1.2483 loss)
I0526 01:15:18.439224 20937 sgd_solver.cpp:106] Iteration 192750, lr = 0.0015
I0526 01:15:28.185293 20937 solver.cpp:237] Iteration 193125, loss = 1.30256
I0526 01:15:28.185330 20937 solver.cpp:253]     Train net output #0: loss = 1.30256 (* 1 = 1.30256 loss)
I0526 01:15:28.185349 20937 sgd_solver.cpp:106] Iteration 193125, lr = 0.0015
I0526 01:15:37.942148 20937 solver.cpp:237] Iteration 193500, loss = 0.864572
I0526 01:15:37.942204 20937 solver.cpp:253]     Train net output #0: loss = 0.864572 (* 1 = 0.864572 loss)
I0526 01:15:37.942224 20937 sgd_solver.cpp:106] Iteration 193500, lr = 0.0015
I0526 01:16:09.893558 20937 solver.cpp:237] Iteration 193875, loss = 0.874186
I0526 01:16:09.893735 20937 solver.cpp:253]     Train net output #0: loss = 0.874187 (* 1 = 0.874187 loss)
I0526 01:16:09.893754 20937 sgd_solver.cpp:106] Iteration 193875, lr = 0.0015
I0526 01:16:19.665143 20937 solver.cpp:237] Iteration 194250, loss = 0.959145
I0526 01:16:19.665181 20937 solver.cpp:253]     Train net output #0: loss = 0.959146 (* 1 = 0.959146 loss)
I0526 01:16:19.665199 20937 sgd_solver.cpp:106] Iteration 194250, lr = 0.0015
I0526 01:16:29.517626 20937 solver.cpp:237] Iteration 194625, loss = 1.1522
I0526 01:16:29.517678 20937 solver.cpp:253]     Train net output #0: loss = 1.1522 (* 1 = 1.1522 loss)
I0526 01:16:29.517698 20937 sgd_solver.cpp:106] Iteration 194625, lr = 0.0015
I0526 01:16:39.377885 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_195000.caffemodel
I0526 01:16:39.434372 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_195000.solverstate
I0526 01:16:39.459940 20937 solver.cpp:341] Iteration 195000, Testing net (#0)
I0526 01:17:27.710093 20937 solver.cpp:409]     Test net output #0: accuracy = 0.896439
I0526 01:17:27.710263 20937 solver.cpp:409]     Test net output #1: loss = 0.32371 (* 1 = 0.32371 loss)
I0526 01:17:27.718423 20937 solver.cpp:237] Iteration 195000, loss = 0.916669
I0526 01:17:27.718453 20937 solver.cpp:253]     Train net output #0: loss = 0.916669 (* 1 = 0.916669 loss)
I0526 01:17:27.718471 20937 sgd_solver.cpp:106] Iteration 195000, lr = 0.0015
I0526 01:17:37.498066 20937 solver.cpp:237] Iteration 195375, loss = 1.24882
I0526 01:17:37.498105 20937 solver.cpp:253]     Train net output #0: loss = 1.24882 (* 1 = 1.24882 loss)
I0526 01:17:37.498123 20937 sgd_solver.cpp:106] Iteration 195375, lr = 0.0015
I0526 01:17:47.272644 20937 solver.cpp:237] Iteration 195750, loss = 0.760529
I0526 01:17:47.272701 20937 solver.cpp:253]     Train net output #0: loss = 0.760529 (* 1 = 0.760529 loss)
I0526 01:17:47.272725 20937 sgd_solver.cpp:106] Iteration 195750, lr = 0.0015
I0526 01:17:57.044064 20937 solver.cpp:237] Iteration 196125, loss = 0.848996
I0526 01:17:57.044105 20937 solver.cpp:253]     Train net output #0: loss = 0.848997 (* 1 = 0.848997 loss)
I0526 01:17:57.044121 20937 sgd_solver.cpp:106] Iteration 196125, lr = 0.0015
I0526 01:18:29.039963 20937 solver.cpp:237] Iteration 196500, loss = 0.930003
I0526 01:18:29.040139 20937 solver.cpp:253]     Train net output #0: loss = 0.930003 (* 1 = 0.930003 loss)
I0526 01:18:29.040158 20937 sgd_solver.cpp:106] Iteration 196500, lr = 0.0015
I0526 01:18:38.795110 20937 solver.cpp:237] Iteration 196875, loss = 1.07461
I0526 01:18:38.795150 20937 solver.cpp:253]     Train net output #0: loss = 1.07461 (* 1 = 1.07461 loss)
I0526 01:18:38.795166 20937 sgd_solver.cpp:106] Iteration 196875, lr = 0.0015
I0526 01:18:48.557662 20937 solver.cpp:237] Iteration 197250, loss = 1.20327
I0526 01:18:48.557699 20937 solver.cpp:253]     Train net output #0: loss = 1.20327 (* 1 = 1.20327 loss)
I0526 01:18:48.557718 20937 sgd_solver.cpp:106] Iteration 197250, lr = 0.0015
I0526 01:18:58.314100 20937 solver.cpp:237] Iteration 197625, loss = 1.12833
I0526 01:18:58.314159 20937 solver.cpp:253]     Train net output #0: loss = 1.12833 (* 1 = 1.12833 loss)
I0526 01:18:58.314183 20937 sgd_solver.cpp:106] Iteration 197625, lr = 0.0015
I0526 01:19:08.062450 20937 solver.cpp:237] Iteration 198000, loss = 1.26879
I0526 01:19:08.062599 20937 solver.cpp:253]     Train net output #0: loss = 1.26879 (* 1 = 1.26879 loss)
I0526 01:19:08.062615 20937 sgd_solver.cpp:106] Iteration 198000, lr = 0.0015
I0526 01:19:17.820091 20937 solver.cpp:237] Iteration 198375, loss = 1.18455
I0526 01:19:17.820147 20937 solver.cpp:253]     Train net output #0: loss = 1.18455 (* 1 = 1.18455 loss)
I0526 01:19:17.820174 20937 sgd_solver.cpp:106] Iteration 198375, lr = 0.0015
I0526 01:19:27.700487 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_198750.caffemodel
I0526 01:19:27.756619 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_198750.solverstate
I0526 01:19:49.962609 20937 solver.cpp:237] Iteration 198750, loss = 0.961133
I0526 01:19:49.962800 20937 solver.cpp:253]     Train net output #0: loss = 0.961133 (* 1 = 0.961133 loss)
I0526 01:19:49.962817 20937 sgd_solver.cpp:106] Iteration 198750, lr = 0.0015
I0526 01:19:59.859925 20937 solver.cpp:237] Iteration 199125, loss = 1.11656
I0526 01:19:59.859964 20937 solver.cpp:253]     Train net output #0: loss = 1.11657 (* 1 = 1.11657 loss)
I0526 01:19:59.859989 20937 sgd_solver.cpp:106] Iteration 199125, lr = 0.0015
I0526 01:20:09.725972 20937 solver.cpp:237] Iteration 199500, loss = 1.24583
I0526 01:20:09.726027 20937 solver.cpp:253]     Train net output #0: loss = 1.24583 (* 1 = 1.24583 loss)
I0526 01:20:09.726045 20937 sgd_solver.cpp:106] Iteration 199500, lr = 0.0015
I0526 01:20:19.489938 20937 solver.cpp:237] Iteration 199875, loss = 0.835616
I0526 01:20:19.489979 20937 solver.cpp:253]     Train net output #0: loss = 0.835616 (* 1 = 0.835616 loss)
I0526 01:20:19.489996 20937 sgd_solver.cpp:106] Iteration 199875, lr = 0.0015
I0526 01:20:29.260220 20937 solver.cpp:237] Iteration 200250, loss = 1.21576
I0526 01:20:29.260375 20937 solver.cpp:253]     Train net output #0: loss = 1.21576 (* 1 = 1.21576 loss)
I0526 01:20:29.260392 20937 sgd_solver.cpp:106] Iteration 200250, lr = 0.0015
I0526 01:20:39.032333 20937 solver.cpp:237] Iteration 200625, loss = 1.01887
I0526 01:20:39.032397 20937 solver.cpp:253]     Train net output #0: loss = 1.01887 (* 1 = 1.01887 loss)
I0526 01:20:39.032421 20937 sgd_solver.cpp:106] Iteration 200625, lr = 0.0015
I0526 01:20:48.795354 20937 solver.cpp:237] Iteration 201000, loss = 1.02257
I0526 01:20:48.795392 20937 solver.cpp:253]     Train net output #0: loss = 1.02257 (* 1 = 1.02257 loss)
I0526 01:20:48.795410 20937 sgd_solver.cpp:106] Iteration 201000, lr = 0.0015
I0526 01:21:20.788480 20937 solver.cpp:237] Iteration 201375, loss = 0.814076
I0526 01:21:20.788655 20937 solver.cpp:253]     Train net output #0: loss = 0.814076 (* 1 = 0.814076 loss)
I0526 01:21:20.788672 20937 sgd_solver.cpp:106] Iteration 201375, lr = 0.0015
I0526 01:21:30.523512 20937 solver.cpp:237] Iteration 201750, loss = 1.08545
I0526 01:21:30.523571 20937 solver.cpp:253]     Train net output #0: loss = 1.08545 (* 1 = 1.08545 loss)
I0526 01:21:30.523596 20937 sgd_solver.cpp:106] Iteration 201750, lr = 0.0015
I0526 01:21:40.257359 20937 solver.cpp:237] Iteration 202125, loss = 1.47751
I0526 01:21:40.257397 20937 solver.cpp:253]     Train net output #0: loss = 1.47751 (* 1 = 1.47751 loss)
I0526 01:21:40.257416 20937 sgd_solver.cpp:106] Iteration 202125, lr = 0.0015
I0526 01:21:49.957550 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_202500.caffemodel
I0526 01:21:50.013368 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_202500.solverstate
I0526 01:21:50.038913 20937 solver.cpp:341] Iteration 202500, Testing net (#0)
I0526 01:22:59.519996 20937 solver.cpp:409]     Test net output #0: accuracy = 0.897408
I0526 01:22:59.520169 20937 solver.cpp:409]     Test net output #1: loss = 0.339523 (* 1 = 0.339523 loss)
I0526 01:22:59.528362 20937 solver.cpp:237] Iteration 202500, loss = 1.49677
I0526 01:22:59.528393 20937 solver.cpp:253]     Train net output #0: loss = 1.49677 (* 1 = 1.49677 loss)
I0526 01:22:59.528409 20937 sgd_solver.cpp:106] Iteration 202500, lr = 0.0015
I0526 01:23:09.334116 20937 solver.cpp:237] Iteration 202875, loss = 1.19643
I0526 01:23:09.334173 20937 solver.cpp:253]     Train net output #0: loss = 1.19643 (* 1 = 1.19643 loss)
I0526 01:23:09.334203 20937 sgd_solver.cpp:106] Iteration 202875, lr = 0.0015
I0526 01:23:19.099516 20937 solver.cpp:237] Iteration 203250, loss = 1.60331
I0526 01:23:19.099555 20937 solver.cpp:253]     Train net output #0: loss = 1.60331 (* 1 = 1.60331 loss)
I0526 01:23:19.099572 20937 sgd_solver.cpp:106] Iteration 203250, lr = 0.0015
I0526 01:23:28.874819 20937 solver.cpp:237] Iteration 203625, loss = 1.0586
I0526 01:23:28.874876 20937 solver.cpp:253]     Train net output #0: loss = 1.0586 (* 1 = 1.0586 loss)
I0526 01:23:28.874904 20937 sgd_solver.cpp:106] Iteration 203625, lr = 0.0015
I0526 01:24:00.913127 20937 solver.cpp:237] Iteration 204000, loss = 1.22653
I0526 01:24:00.913313 20937 solver.cpp:253]     Train net output #0: loss = 1.22653 (* 1 = 1.22653 loss)
I0526 01:24:00.913331 20937 sgd_solver.cpp:106] Iteration 204000, lr = 0.0015
I0526 01:24:10.684044 20937 solver.cpp:237] Iteration 204375, loss = 1.39442
I0526 01:24:10.684082 20937 solver.cpp:253]     Train net output #0: loss = 1.39442 (* 1 = 1.39442 loss)
I0526 01:24:10.684101 20937 sgd_solver.cpp:106] Iteration 204375, lr = 0.0015
I0526 01:24:20.466437 20937 solver.cpp:237] Iteration 204750, loss = 1.13094
I0526 01:24:20.466492 20937 solver.cpp:253]     Train net output #0: loss = 1.13094 (* 1 = 1.13094 loss)
I0526 01:24:20.466522 20937 sgd_solver.cpp:106] Iteration 204750, lr = 0.0015
I0526 01:24:30.235509 20937 solver.cpp:237] Iteration 205125, loss = 1.25052
I0526 01:24:30.235548 20937 solver.cpp:253]     Train net output #0: loss = 1.25052 (* 1 = 1.25052 loss)
I0526 01:24:30.235565 20937 sgd_solver.cpp:106] Iteration 205125, lr = 0.0015
I0526 01:24:40.008628 20937 solver.cpp:237] Iteration 205500, loss = 1.172
I0526 01:24:40.008780 20937 solver.cpp:253]     Train net output #0: loss = 1.172 (* 1 = 1.172 loss)
I0526 01:24:40.008797 20937 sgd_solver.cpp:106] Iteration 205500, lr = 0.0015
I0526 01:24:49.787045 20937 solver.cpp:237] Iteration 205875, loss = 1.35128
I0526 01:24:49.787101 20937 solver.cpp:253]     Train net output #0: loss = 1.35128 (* 1 = 1.35128 loss)
I0526 01:24:49.787127 20937 sgd_solver.cpp:106] Iteration 205875, lr = 0.0015
I0526 01:24:59.540361 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_206250.caffemodel
I0526 01:24:59.598817 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_206250.solverstate
I0526 01:25:20.565876 20937 solver.cpp:237] Iteration 206250, loss = 1.13918
I0526 01:25:20.566062 20937 solver.cpp:253]     Train net output #0: loss = 1.13919 (* 1 = 1.13919 loss)
I0526 01:25:20.566081 20937 sgd_solver.cpp:106] Iteration 206250, lr = 0.0015
I0526 01:25:30.347157 20937 solver.cpp:237] Iteration 206625, loss = 1.07769
I0526 01:25:30.347200 20937 solver.cpp:253]     Train net output #0: loss = 1.07769 (* 1 = 1.07769 loss)
I0526 01:25:30.347219 20937 sgd_solver.cpp:106] Iteration 206625, lr = 0.0015
I0526 01:25:40.110589 20937 solver.cpp:237] Iteration 207000, loss = 1.05998
I0526 01:25:40.110647 20937 solver.cpp:253]     Train net output #0: loss = 1.05998 (* 1 = 1.05998 loss)
I0526 01:25:40.110666 20937 sgd_solver.cpp:106] Iteration 207000, lr = 0.0015
I0526 01:25:49.884037 20937 solver.cpp:237] Iteration 207375, loss = 1.24449
I0526 01:25:49.884074 20937 solver.cpp:253]     Train net output #0: loss = 1.24449 (* 1 = 1.24449 loss)
I0526 01:25:49.884093 20937 sgd_solver.cpp:106] Iteration 207375, lr = 0.0015
I0526 01:25:59.684057 20937 solver.cpp:237] Iteration 207750, loss = 0.918581
I0526 01:25:59.684238 20937 solver.cpp:253]     Train net output #0: loss = 0.918581 (* 1 = 0.918581 loss)
I0526 01:25:59.684257 20937 sgd_solver.cpp:106] Iteration 207750, lr = 0.0015
I0526 01:26:09.608140 20937 solver.cpp:237] Iteration 208125, loss = 1.13585
I0526 01:26:09.608178 20937 solver.cpp:253]     Train net output #0: loss = 1.13585 (* 1 = 1.13585 loss)
I0526 01:26:09.608196 20937 sgd_solver.cpp:106] Iteration 208125, lr = 0.0015
I0526 01:26:19.528833 20937 solver.cpp:237] Iteration 208500, loss = 1.26016
I0526 01:26:19.528872 20937 solver.cpp:253]     Train net output #0: loss = 1.26016 (* 1 = 1.26016 loss)
I0526 01:26:19.528888 20937 sgd_solver.cpp:106] Iteration 208500, lr = 0.0015
I0526 01:26:50.330647 20937 solver.cpp:237] Iteration 208875, loss = 0.923834
I0526 01:26:50.330826 20937 solver.cpp:253]     Train net output #0: loss = 0.923834 (* 1 = 0.923834 loss)
I0526 01:26:50.330843 20937 sgd_solver.cpp:106] Iteration 208875, lr = 0.0015
I0526 01:27:00.251348 20937 solver.cpp:237] Iteration 209250, loss = 0.910439
I0526 01:27:00.251386 20937 solver.cpp:253]     Train net output #0: loss = 0.910439 (* 1 = 0.910439 loss)
I0526 01:27:00.251405 20937 sgd_solver.cpp:106] Iteration 209250, lr = 0.0015
I0526 01:27:10.174288 20937 solver.cpp:237] Iteration 209625, loss = 1.5879
I0526 01:27:10.174327 20937 solver.cpp:253]     Train net output #0: loss = 1.58791 (* 1 = 1.58791 loss)
I0526 01:27:10.174345 20937 sgd_solver.cpp:106] Iteration 209625, lr = 0.0015
I0526 01:27:20.073058 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_210000.caffemodel
I0526 01:27:20.129382 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_210000.solverstate
I0526 01:27:20.155045 20937 solver.cpp:341] Iteration 210000, Testing net (#0)
I0526 01:28:08.752019 20937 solver.cpp:409]     Test net output #0: accuracy = 0.895493
I0526 01:28:08.752193 20937 solver.cpp:409]     Test net output #1: loss = 0.313597 (* 1 = 0.313597 loss)
I0526 01:28:08.760320 20937 solver.cpp:237] Iteration 210000, loss = 1.11772
I0526 01:28:08.760356 20937 solver.cpp:253]     Train net output #0: loss = 1.11772 (* 1 = 1.11772 loss)
I0526 01:28:08.760383 20937 sgd_solver.cpp:106] Iteration 210000, lr = 0.0015
I0526 01:28:18.559864 20937 solver.cpp:237] Iteration 210375, loss = 1.31571
I0526 01:28:18.559903 20937 solver.cpp:253]     Train net output #0: loss = 1.31571 (* 1 = 1.31571 loss)
I0526 01:28:18.559921 20937 sgd_solver.cpp:106] Iteration 210375, lr = 0.0015
I0526 01:28:28.357802 20937 solver.cpp:237] Iteration 210750, loss = 1.19671
I0526 01:28:28.357861 20937 solver.cpp:253]     Train net output #0: loss = 1.19671 (* 1 = 1.19671 loss)
I0526 01:28:28.357887 20937 sgd_solver.cpp:106] Iteration 210750, lr = 0.0015
I0526 01:28:38.142585 20937 solver.cpp:237] Iteration 211125, loss = 1.38525
I0526 01:28:38.142621 20937 solver.cpp:253]     Train net output #0: loss = 1.38525 (* 1 = 1.38525 loss)
I0526 01:28:38.142640 20937 sgd_solver.cpp:106] Iteration 211125, lr = 0.0015
I0526 01:29:08.799247 20937 solver.cpp:237] Iteration 211500, loss = 1.22899
I0526 01:29:08.799425 20937 solver.cpp:253]     Train net output #0: loss = 1.22899 (* 1 = 1.22899 loss)
I0526 01:29:08.799443 20937 sgd_solver.cpp:106] Iteration 211500, lr = 0.0015
I0526 01:29:18.582855 20937 solver.cpp:237] Iteration 211875, loss = 1.05845
I0526 01:29:18.582916 20937 solver.cpp:253]     Train net output #0: loss = 1.05845 (* 1 = 1.05845 loss)
I0526 01:29:18.582940 20937 sgd_solver.cpp:106] Iteration 211875, lr = 0.0015
I0526 01:29:28.337607 20937 solver.cpp:237] Iteration 212250, loss = 1.3903
I0526 01:29:28.337646 20937 solver.cpp:253]     Train net output #0: loss = 1.3903 (* 1 = 1.3903 loss)
I0526 01:29:28.337666 20937 sgd_solver.cpp:106] Iteration 212250, lr = 0.0015
I0526 01:29:38.068653 20937 solver.cpp:237] Iteration 212625, loss = 1.31916
I0526 01:29:38.068691 20937 solver.cpp:253]     Train net output #0: loss = 1.31916 (* 1 = 1.31916 loss)
I0526 01:29:38.068716 20937 sgd_solver.cpp:106] Iteration 212625, lr = 0.0015
I0526 01:29:47.870765 20937 solver.cpp:237] Iteration 213000, loss = 0.889702
I0526 01:29:47.870949 20937 solver.cpp:253]     Train net output #0: loss = 0.889702 (* 1 = 0.889702 loss)
I0526 01:29:47.870967 20937 sgd_solver.cpp:106] Iteration 213000, lr = 0.0015
I0526 01:29:57.730834 20937 solver.cpp:237] Iteration 213375, loss = 0.974227
I0526 01:29:57.730870 20937 solver.cpp:253]     Train net output #0: loss = 0.974227 (* 1 = 0.974227 loss)
I0526 01:29:57.730888 20937 sgd_solver.cpp:106] Iteration 213375, lr = 0.0015
I0526 01:30:07.564764 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_213750.caffemodel
I0526 01:30:07.620744 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_213750.solverstate
I0526 01:30:28.566043 20937 solver.cpp:237] Iteration 213750, loss = 0.943123
I0526 01:30:28.566232 20937 solver.cpp:253]     Train net output #0: loss = 0.943123 (* 1 = 0.943123 loss)
I0526 01:30:28.566251 20937 sgd_solver.cpp:106] Iteration 213750, lr = 0.0015
I0526 01:30:38.465746 20937 solver.cpp:237] Iteration 214125, loss = 1.1238
I0526 01:30:38.465806 20937 solver.cpp:253]     Train net output #0: loss = 1.1238 (* 1 = 1.1238 loss)
I0526 01:30:38.465834 20937 sgd_solver.cpp:106] Iteration 214125, lr = 0.0015
I0526 01:30:48.382268 20937 solver.cpp:237] Iteration 214500, loss = 1.38923
I0526 01:30:48.382308 20937 solver.cpp:253]     Train net output #0: loss = 1.38924 (* 1 = 1.38924 loss)
I0526 01:30:48.382326 20937 sgd_solver.cpp:106] Iteration 214500, lr = 0.0015
I0526 01:30:58.298457 20937 solver.cpp:237] Iteration 214875, loss = 1.49612
I0526 01:30:58.298516 20937 solver.cpp:253]     Train net output #0: loss = 1.49612 (* 1 = 1.49612 loss)
I0526 01:30:58.298543 20937 sgd_solver.cpp:106] Iteration 214875, lr = 0.0015
I0526 01:31:08.176754 20937 solver.cpp:237] Iteration 215250, loss = 1.19705
I0526 01:31:08.176909 20937 solver.cpp:253]     Train net output #0: loss = 1.19705 (* 1 = 1.19705 loss)
I0526 01:31:08.176926 20937 sgd_solver.cpp:106] Iteration 215250, lr = 0.0015
I0526 01:31:18.056659 20937 solver.cpp:237] Iteration 215625, loss = 1.56384
I0526 01:31:18.056696 20937 solver.cpp:253]     Train net output #0: loss = 1.56384 (* 1 = 1.56384 loss)
I0526 01:31:18.056715 20937 sgd_solver.cpp:106] Iteration 215625, lr = 0.0015
I0526 01:31:27.939072 20937 solver.cpp:237] Iteration 216000, loss = 0.964175
I0526 01:31:27.939131 20937 solver.cpp:253]     Train net output #0: loss = 0.964175 (* 1 = 0.964175 loss)
I0526 01:31:27.939157 20937 sgd_solver.cpp:106] Iteration 216000, lr = 0.0015
I0526 01:31:58.718475 20937 solver.cpp:237] Iteration 216375, loss = 1.03797
I0526 01:31:58.718652 20937 solver.cpp:253]     Train net output #0: loss = 1.03797 (* 1 = 1.03797 loss)
I0526 01:31:58.718669 20937 sgd_solver.cpp:106] Iteration 216375, lr = 0.0015
I0526 01:32:08.597813 20937 solver.cpp:237] Iteration 216750, loss = 1.15948
I0526 01:32:08.597851 20937 solver.cpp:253]     Train net output #0: loss = 1.15948 (* 1 = 1.15948 loss)
I0526 01:32:08.597869 20937 sgd_solver.cpp:106] Iteration 216750, lr = 0.0015
I0526 01:32:18.388721 20937 solver.cpp:237] Iteration 217125, loss = 1.03047
I0526 01:32:18.388777 20937 solver.cpp:253]     Train net output #0: loss = 1.03047 (* 1 = 1.03047 loss)
I0526 01:32:18.388805 20937 sgd_solver.cpp:106] Iteration 217125, lr = 0.0015
I0526 01:32:28.076150 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_217500.caffemodel
I0526 01:32:28.132131 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_217500.solverstate
I0526 01:32:28.158103 20937 solver.cpp:341] Iteration 217500, Testing net (#0)
I0526 01:33:37.522799 20937 solver.cpp:409]     Test net output #0: accuracy = 0.899013
I0526 01:33:37.522996 20937 solver.cpp:409]     Test net output #1: loss = 0.326729 (* 1 = 0.326729 loss)
I0526 01:33:37.531132 20937 solver.cpp:237] Iteration 217500, loss = 1.37302
I0526 01:33:37.531162 20937 solver.cpp:253]     Train net output #0: loss = 1.37302 (* 1 = 1.37302 loss)
I0526 01:33:37.531180 20937 sgd_solver.cpp:106] Iteration 217500, lr = 0.0015
I0526 01:33:47.260674 20937 solver.cpp:237] Iteration 217875, loss = 0.775512
I0526 01:33:47.260713 20937 solver.cpp:253]     Train net output #0: loss = 0.775513 (* 1 = 0.775513 loss)
I0526 01:33:47.260736 20937 sgd_solver.cpp:106] Iteration 217875, lr = 0.0015
I0526 01:33:56.990726 20937 solver.cpp:237] Iteration 218250, loss = 1.17338
I0526 01:33:56.990785 20937 solver.cpp:253]     Train net output #0: loss = 1.17338 (* 1 = 1.17338 loss)
I0526 01:33:56.990810 20937 sgd_solver.cpp:106] Iteration 218250, lr = 0.0015
I0526 01:34:06.729290 20937 solver.cpp:237] Iteration 218625, loss = 1.05105
I0526 01:34:06.729328 20937 solver.cpp:253]     Train net output #0: loss = 1.05105 (* 1 = 1.05105 loss)
I0526 01:34:06.729346 20937 sgd_solver.cpp:106] Iteration 218625, lr = 0.0015
I0526 01:34:37.312566 20937 solver.cpp:237] Iteration 219000, loss = 1.13794
I0526 01:34:37.312733 20937 solver.cpp:253]     Train net output #0: loss = 1.13794 (* 1 = 1.13794 loss)
I0526 01:34:37.312752 20937 sgd_solver.cpp:106] Iteration 219000, lr = 0.0015
I0526 01:34:47.094660 20937 solver.cpp:237] Iteration 219375, loss = 1.09922
I0526 01:34:47.094715 20937 solver.cpp:253]     Train net output #0: loss = 1.09922 (* 1 = 1.09922 loss)
I0526 01:34:47.094732 20937 sgd_solver.cpp:106] Iteration 219375, lr = 0.0015
I0526 01:34:56.940047 20937 solver.cpp:237] Iteration 219750, loss = 0.95898
I0526 01:34:56.940098 20937 solver.cpp:253]     Train net output #0: loss = 0.95898 (* 1 = 0.95898 loss)
I0526 01:34:56.940114 20937 sgd_solver.cpp:106] Iteration 219750, lr = 0.0015
I0526 01:35:06.800503 20937 solver.cpp:237] Iteration 220125, loss = 0.801487
I0526 01:35:06.800540 20937 solver.cpp:253]     Train net output #0: loss = 0.801487 (* 1 = 0.801487 loss)
I0526 01:35:06.800559 20937 sgd_solver.cpp:106] Iteration 220125, lr = 0.0015
I0526 01:35:16.589419 20937 solver.cpp:237] Iteration 220500, loss = 1.24499
I0526 01:35:16.589592 20937 solver.cpp:253]     Train net output #0: loss = 1.24499 (* 1 = 1.24499 loss)
I0526 01:35:16.589610 20937 sgd_solver.cpp:106] Iteration 220500, lr = 0.0015
I0526 01:35:26.382766 20937 solver.cpp:237] Iteration 220875, loss = 0.955465
I0526 01:35:26.382804 20937 solver.cpp:253]     Train net output #0: loss = 0.955465 (* 1 = 0.955465 loss)
I0526 01:35:26.382822 20937 sgd_solver.cpp:106] Iteration 220875, lr = 0.0015
I0526 01:35:36.168992 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_221250.caffemodel
I0526 01:35:36.224915 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_221250.solverstate
I0526 01:35:57.116231 20937 solver.cpp:237] Iteration 221250, loss = 0.836338
I0526 01:35:57.116432 20937 solver.cpp:253]     Train net output #0: loss = 0.836339 (* 1 = 0.836339 loss)
I0526 01:35:57.116451 20937 sgd_solver.cpp:106] Iteration 221250, lr = 0.0015
I0526 01:36:06.936038 20937 solver.cpp:237] Iteration 221625, loss = 1.10427
I0526 01:36:06.936089 20937 solver.cpp:253]     Train net output #0: loss = 1.10427 (* 1 = 1.10427 loss)
I0526 01:36:06.936117 20937 sgd_solver.cpp:106] Iteration 221625, lr = 0.0015
I0526 01:36:16.758128 20937 solver.cpp:237] Iteration 222000, loss = 1.23724
I0526 01:36:16.758167 20937 solver.cpp:253]     Train net output #0: loss = 1.23724 (* 1 = 1.23724 loss)
I0526 01:36:16.758190 20937 sgd_solver.cpp:106] Iteration 222000, lr = 0.0015
I0526 01:36:26.582772 20937 solver.cpp:237] Iteration 222375, loss = 1.28432
I0526 01:36:26.582830 20937 solver.cpp:253]     Train net output #0: loss = 1.28432 (* 1 = 1.28432 loss)
I0526 01:36:26.582856 20937 sgd_solver.cpp:106] Iteration 222375, lr = 0.0015
I0526 01:36:36.402469 20937 solver.cpp:237] Iteration 222750, loss = 1.07097
I0526 01:36:36.402636 20937 solver.cpp:253]     Train net output #0: loss = 1.07097 (* 1 = 1.07097 loss)
I0526 01:36:36.402652 20937 sgd_solver.cpp:106] Iteration 222750, lr = 0.0015
I0526 01:36:46.227627 20937 solver.cpp:237] Iteration 223125, loss = 1.05924
I0526 01:36:46.227666 20937 solver.cpp:253]     Train net output #0: loss = 1.05924 (* 1 = 1.05924 loss)
I0526 01:36:46.227684 20937 sgd_solver.cpp:106] Iteration 223125, lr = 0.0015
I0526 01:36:56.060921 20937 solver.cpp:237] Iteration 223500, loss = 1.29547
I0526 01:36:56.060979 20937 solver.cpp:253]     Train net output #0: loss = 1.29547 (* 1 = 1.29547 loss)
I0526 01:36:56.061003 20937 sgd_solver.cpp:106] Iteration 223500, lr = 0.0015
I0526 01:37:26.782382 20937 solver.cpp:237] Iteration 223875, loss = 1.2159
I0526 01:37:26.782562 20937 solver.cpp:253]     Train net output #0: loss = 1.2159 (* 1 = 1.2159 loss)
I0526 01:37:26.782579 20937 sgd_solver.cpp:106] Iteration 223875, lr = 0.0015
I0526 01:37:36.609688 20937 solver.cpp:237] Iteration 224250, loss = 1.13876
I0526 01:37:36.609726 20937 solver.cpp:253]     Train net output #0: loss = 1.13876 (* 1 = 1.13876 loss)
I0526 01:37:36.609745 20937 sgd_solver.cpp:106] Iteration 224250, lr = 0.0015
I0526 01:37:46.442762 20937 solver.cpp:237] Iteration 224625, loss = 0.910031
I0526 01:37:46.442821 20937 solver.cpp:253]     Train net output #0: loss = 0.910031 (* 1 = 0.910031 loss)
I0526 01:37:46.442845 20937 sgd_solver.cpp:106] Iteration 224625, lr = 0.0015
I0526 01:37:56.245424 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_225000.caffemodel
I0526 01:37:56.303516 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_225000.solverstate
I0526 01:37:56.331624 20937 solver.cpp:341] Iteration 225000, Testing net (#0)
I0526 01:38:44.598371 20937 solver.cpp:409]     Test net output #0: accuracy = 0.898074
I0526 01:38:44.598556 20937 solver.cpp:409]     Test net output #1: loss = 0.316753 (* 1 = 0.316753 loss)
I0526 01:38:44.606657 20937 solver.cpp:237] Iteration 225000, loss = 1.04567
I0526 01:38:44.606685 20937 solver.cpp:253]     Train net output #0: loss = 1.04567 (* 1 = 1.04567 loss)
I0526 01:38:44.606704 20937 sgd_solver.cpp:106] Iteration 225000, lr = 0.0015
I0526 01:38:54.417537 20937 solver.cpp:237] Iteration 225375, loss = 1.33745
I0526 01:38:54.417593 20937 solver.cpp:253]     Train net output #0: loss = 1.33745 (* 1 = 1.33745 loss)
I0526 01:38:54.417609 20937 sgd_solver.cpp:106] Iteration 225375, lr = 0.0015
I0526 01:39:04.169196 20937 solver.cpp:237] Iteration 225750, loss = 1.44017
I0526 01:39:04.169235 20937 solver.cpp:253]     Train net output #0: loss = 1.44017 (* 1 = 1.44017 loss)
I0526 01:39:04.169252 20937 sgd_solver.cpp:106] Iteration 225750, lr = 0.0015
I0526 01:39:13.927070 20937 solver.cpp:237] Iteration 226125, loss = 1.37511
I0526 01:39:13.927108 20937 solver.cpp:253]     Train net output #0: loss = 1.37511 (* 1 = 1.37511 loss)
I0526 01:39:13.927126 20937 sgd_solver.cpp:106] Iteration 226125, lr = 0.0015
I0526 01:39:44.594142 20937 solver.cpp:237] Iteration 226500, loss = 1.07735
I0526 01:39:44.594319 20937 solver.cpp:253]     Train net output #0: loss = 1.07735 (* 1 = 1.07735 loss)
I0526 01:39:44.594337 20937 sgd_solver.cpp:106] Iteration 226500, lr = 0.0015
I0526 01:39:54.352336 20937 solver.cpp:237] Iteration 226875, loss = 1.02385
I0526 01:39:54.352382 20937 solver.cpp:253]     Train net output #0: loss = 1.02385 (* 1 = 1.02385 loss)
I0526 01:39:54.352398 20937 sgd_solver.cpp:106] Iteration 226875, lr = 0.0015
I0526 01:40:04.120889 20937 solver.cpp:237] Iteration 227250, loss = 1.43529
I0526 01:40:04.120926 20937 solver.cpp:253]     Train net output #0: loss = 1.43529 (* 1 = 1.43529 loss)
I0526 01:40:04.120944 20937 sgd_solver.cpp:106] Iteration 227250, lr = 0.0015
I0526 01:40:13.880854 20937 solver.cpp:237] Iteration 227625, loss = 1.20468
I0526 01:40:13.880911 20937 solver.cpp:253]     Train net output #0: loss = 1.20468 (* 1 = 1.20468 loss)
I0526 01:40:13.880939 20937 sgd_solver.cpp:106] Iteration 227625, lr = 0.0015
I0526 01:40:23.641129 20937 solver.cpp:237] Iteration 228000, loss = 1.36982
I0526 01:40:23.641294 20937 solver.cpp:253]     Train net output #0: loss = 1.36982 (* 1 = 1.36982 loss)
I0526 01:40:23.641312 20937 sgd_solver.cpp:106] Iteration 228000, lr = 0.0015
I0526 01:40:33.398844 20937 solver.cpp:237] Iteration 228375, loss = 1.17335
I0526 01:40:33.398901 20937 solver.cpp:253]     Train net output #0: loss = 1.17335 (* 1 = 1.17335 loss)
I0526 01:40:33.398926 20937 sgd_solver.cpp:106] Iteration 228375, lr = 0.0015
I0526 01:40:43.104893 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_228750.caffemodel
I0526 01:40:43.161984 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_228750.solverstate
I0526 01:41:04.050011 20937 solver.cpp:237] Iteration 228750, loss = 1.04813
I0526 01:41:04.050199 20937 solver.cpp:253]     Train net output #0: loss = 1.04813 (* 1 = 1.04813 loss)
I0526 01:41:04.050217 20937 sgd_solver.cpp:106] Iteration 228750, lr = 0.0015
I0526 01:41:13.776589 20937 solver.cpp:237] Iteration 229125, loss = 1.13808
I0526 01:41:13.776628 20937 solver.cpp:253]     Train net output #0: loss = 1.13808 (* 1 = 1.13808 loss)
I0526 01:41:13.776650 20937 sgd_solver.cpp:106] Iteration 229125, lr = 0.0015
I0526 01:41:23.506872 20937 solver.cpp:237] Iteration 229500, loss = 1.41858
I0526 01:41:23.506932 20937 solver.cpp:253]     Train net output #0: loss = 1.41858 (* 1 = 1.41858 loss)
I0526 01:41:23.506958 20937 sgd_solver.cpp:106] Iteration 229500, lr = 0.0015
I0526 01:41:33.243615 20937 solver.cpp:237] Iteration 229875, loss = 0.896563
I0526 01:41:33.243656 20937 solver.cpp:253]     Train net output #0: loss = 0.896563 (* 1 = 0.896563 loss)
I0526 01:41:33.243674 20937 sgd_solver.cpp:106] Iteration 229875, lr = 0.0015
I0526 01:41:42.970105 20937 solver.cpp:237] Iteration 230250, loss = 0.966516
I0526 01:41:42.970265 20937 solver.cpp:253]     Train net output #0: loss = 0.966516 (* 1 = 0.966516 loss)
I0526 01:41:42.970283 20937 sgd_solver.cpp:106] Iteration 230250, lr = 0.0015
I0526 01:41:52.698483 20937 solver.cpp:237] Iteration 230625, loss = 1.13375
I0526 01:41:52.698539 20937 solver.cpp:253]     Train net output #0: loss = 1.13375 (* 1 = 1.13375 loss)
I0526 01:41:52.698567 20937 sgd_solver.cpp:106] Iteration 230625, lr = 0.0015
I0526 01:42:02.424564 20937 solver.cpp:237] Iteration 231000, loss = 0.872185
I0526 01:42:02.424602 20937 solver.cpp:253]     Train net output #0: loss = 0.872185 (* 1 = 0.872185 loss)
I0526 01:42:02.424620 20937 sgd_solver.cpp:106] Iteration 231000, lr = 0.0015
I0526 01:42:33.026080 20937 solver.cpp:237] Iteration 231375, loss = 1.14843
I0526 01:42:33.026262 20937 solver.cpp:253]     Train net output #0: loss = 1.14844 (* 1 = 1.14844 loss)
I0526 01:42:33.026280 20937 sgd_solver.cpp:106] Iteration 231375, lr = 0.0015
I0526 01:42:42.785919 20937 solver.cpp:237] Iteration 231750, loss = 1.0908
I0526 01:42:42.785979 20937 solver.cpp:253]     Train net output #0: loss = 1.0908 (* 1 = 1.0908 loss)
I0526 01:42:42.786005 20937 sgd_solver.cpp:106] Iteration 231750, lr = 0.0015
I0526 01:42:52.570847 20937 solver.cpp:237] Iteration 232125, loss = 1.10308
I0526 01:42:52.570884 20937 solver.cpp:253]     Train net output #0: loss = 1.10308 (* 1 = 1.10308 loss)
I0526 01:42:52.570902 20937 sgd_solver.cpp:106] Iteration 232125, lr = 0.0015
I0526 01:43:02.328547 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_232500.caffemodel
I0526 01:43:02.385723 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_232500.solverstate
I0526 01:43:02.410800 20937 solver.cpp:341] Iteration 232500, Testing net (#0)
I0526 01:44:11.850878 20937 solver.cpp:409]     Test net output #0: accuracy = 0.899146
I0526 01:44:11.851070 20937 solver.cpp:409]     Test net output #1: loss = 0.313281 (* 1 = 0.313281 loss)
I0526 01:44:11.859194 20937 solver.cpp:237] Iteration 232500, loss = 1.13509
I0526 01:44:11.859223 20937 solver.cpp:253]     Train net output #0: loss = 1.13509 (* 1 = 1.13509 loss)
I0526 01:44:11.859241 20937 sgd_solver.cpp:106] Iteration 232500, lr = 0.0015
I0526 01:44:21.645282 20937 solver.cpp:237] Iteration 232875, loss = 1.40197
I0526 01:44:21.645341 20937 solver.cpp:253]     Train net output #0: loss = 1.40197 (* 1 = 1.40197 loss)
I0526 01:44:21.645366 20937 sgd_solver.cpp:106] Iteration 232875, lr = 0.0015
I0526 01:44:31.342061 20937 solver.cpp:237] Iteration 233250, loss = 1.02331
I0526 01:44:31.342098 20937 solver.cpp:253]     Train net output #0: loss = 1.02331 (* 1 = 1.02331 loss)
I0526 01:44:31.342118 20937 sgd_solver.cpp:106] Iteration 233250, lr = 0.0015
I0526 01:44:41.042601 20937 solver.cpp:237] Iteration 233625, loss = 1.03374
I0526 01:44:41.042639 20937 solver.cpp:253]     Train net output #0: loss = 1.03374 (* 1 = 1.03374 loss)
I0526 01:44:41.042657 20937 sgd_solver.cpp:106] Iteration 233625, lr = 0.0015
I0526 01:45:11.774591 20937 solver.cpp:237] Iteration 234000, loss = 1.45337
I0526 01:45:11.774777 20937 solver.cpp:253]     Train net output #0: loss = 1.45337 (* 1 = 1.45337 loss)
I0526 01:45:11.774796 20937 sgd_solver.cpp:106] Iteration 234000, lr = 0.0015
I0526 01:45:21.651350 20937 solver.cpp:237] Iteration 234375, loss = 1.30049
I0526 01:45:21.651387 20937 solver.cpp:253]     Train net output #0: loss = 1.30049 (* 1 = 1.30049 loss)
I0526 01:45:21.651406 20937 sgd_solver.cpp:106] Iteration 234375, lr = 0.0015
I0526 01:45:31.529547 20937 solver.cpp:237] Iteration 234750, loss = 1.01868
I0526 01:45:31.529587 20937 solver.cpp:253]     Train net output #0: loss = 1.01868 (* 1 = 1.01868 loss)
I0526 01:45:31.529604 20937 sgd_solver.cpp:106] Iteration 234750, lr = 0.0015
I0526 01:45:41.259336 20937 solver.cpp:237] Iteration 235125, loss = 0.881953
I0526 01:45:41.259392 20937 solver.cpp:253]     Train net output #0: loss = 0.881953 (* 1 = 0.881953 loss)
I0526 01:45:41.259418 20937 sgd_solver.cpp:106] Iteration 235125, lr = 0.0015
I0526 01:45:50.969964 20937 solver.cpp:237] Iteration 235500, loss = 0.99961
I0526 01:45:50.970140 20937 solver.cpp:253]     Train net output #0: loss = 0.99961 (* 1 = 0.99961 loss)
I0526 01:45:50.970158 20937 sgd_solver.cpp:106] Iteration 235500, lr = 0.0015
I0526 01:46:00.714828 20937 solver.cpp:237] Iteration 235875, loss = 1.16661
I0526 01:46:00.714886 20937 solver.cpp:253]     Train net output #0: loss = 1.16661 (* 1 = 1.16661 loss)
I0526 01:46:00.714911 20937 sgd_solver.cpp:106] Iteration 235875, lr = 0.0015
I0526 01:46:10.481451 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_236250.caffemodel
I0526 01:46:10.538154 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_236250.solverstate
I0526 01:46:31.463337 20937 solver.cpp:237] Iteration 236250, loss = 1.12911
I0526 01:46:31.463529 20937 solver.cpp:253]     Train net output #0: loss = 1.12911 (* 1 = 1.12911 loss)
I0526 01:46:31.463547 20937 sgd_solver.cpp:106] Iteration 236250, lr = 0.0015
I0526 01:46:41.261373 20937 solver.cpp:237] Iteration 236625, loss = 1.39202
I0526 01:46:41.261412 20937 solver.cpp:253]     Train net output #0: loss = 1.39202 (* 1 = 1.39202 loss)
I0526 01:46:41.261437 20937 sgd_solver.cpp:106] Iteration 236625, lr = 0.0015
I0526 01:46:51.100635 20937 solver.cpp:237] Iteration 237000, loss = 0.860517
I0526 01:46:51.100693 20937 solver.cpp:253]     Train net output #0: loss = 0.860517 (* 1 = 0.860517 loss)
I0526 01:46:51.100718 20937 sgd_solver.cpp:106] Iteration 237000, lr = 0.0015
I0526 01:47:01.016841 20937 solver.cpp:237] Iteration 237375, loss = 1.1772
I0526 01:47:01.016878 20937 solver.cpp:253]     Train net output #0: loss = 1.1772 (* 1 = 1.1772 loss)
I0526 01:47:01.016897 20937 sgd_solver.cpp:106] Iteration 237375, lr = 0.0015
I0526 01:47:10.935873 20937 solver.cpp:237] Iteration 237750, loss = 0.821018
I0526 01:47:10.936036 20937 solver.cpp:253]     Train net output #0: loss = 0.821019 (* 1 = 0.821019 loss)
I0526 01:47:10.936053 20937 sgd_solver.cpp:106] Iteration 237750, lr = 0.0015
I0526 01:47:20.726977 20937 solver.cpp:237] Iteration 238125, loss = 0.833063
I0526 01:47:20.727032 20937 solver.cpp:253]     Train net output #0: loss = 0.833064 (* 1 = 0.833064 loss)
I0526 01:47:20.727052 20937 sgd_solver.cpp:106] Iteration 238125, lr = 0.0015
I0526 01:47:30.482048 20937 solver.cpp:237] Iteration 238500, loss = 1.13723
I0526 01:47:30.482085 20937 solver.cpp:253]     Train net output #0: loss = 1.13723 (* 1 = 1.13723 loss)
I0526 01:47:30.482105 20937 sgd_solver.cpp:106] Iteration 238500, lr = 0.0015
I0526 01:48:01.060199 20937 solver.cpp:237] Iteration 238875, loss = 0.82233
I0526 01:48:01.060386 20937 solver.cpp:253]     Train net output #0: loss = 0.822331 (* 1 = 0.822331 loss)
I0526 01:48:01.060405 20937 sgd_solver.cpp:106] Iteration 238875, lr = 0.0015
I0526 01:48:10.895967 20937 solver.cpp:237] Iteration 239250, loss = 1.3005
I0526 01:48:10.896023 20937 solver.cpp:253]     Train net output #0: loss = 1.3005 (* 1 = 1.3005 loss)
I0526 01:48:10.896047 20937 sgd_solver.cpp:106] Iteration 239250, lr = 0.0015
I0526 01:48:20.754387 20937 solver.cpp:237] Iteration 239625, loss = 1.52264
I0526 01:48:20.754426 20937 solver.cpp:253]     Train net output #0: loss = 1.52264 (* 1 = 1.52264 loss)
I0526 01:48:20.754442 20937 sgd_solver.cpp:106] Iteration 239625, lr = 0.0015
I0526 01:48:30.548866 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_240000.caffemodel
I0526 01:48:30.605424 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_240000.solverstate
I0526 01:48:30.631131 20937 solver.cpp:341] Iteration 240000, Testing net (#0)
I0526 01:49:19.218116 20937 solver.cpp:409]     Test net output #0: accuracy = 0.899907
I0526 01:49:19.218298 20937 solver.cpp:409]     Test net output #1: loss = 0.313815 (* 1 = 0.313815 loss)
I0526 01:49:19.226384 20937 solver.cpp:237] Iteration 240000, loss = 1.36742
I0526 01:49:19.226413 20937 solver.cpp:253]     Train net output #0: loss = 1.36742 (* 1 = 1.36742 loss)
I0526 01:49:19.226430 20937 sgd_solver.cpp:106] Iteration 240000, lr = 0.0015
I0526 01:49:29.183737 20937 solver.cpp:237] Iteration 240375, loss = 0.980007
I0526 01:49:29.183774 20937 solver.cpp:253]     Train net output #0: loss = 0.980008 (* 1 = 0.980008 loss)
I0526 01:49:29.183792 20937 sgd_solver.cpp:106] Iteration 240375, lr = 0.0015
I0526 01:49:39.135560 20937 solver.cpp:237] Iteration 240750, loss = 1.35264
I0526 01:49:39.135597 20937 solver.cpp:253]     Train net output #0: loss = 1.35264 (* 1 = 1.35264 loss)
I0526 01:49:39.135622 20937 sgd_solver.cpp:106] Iteration 240750, lr = 0.0015
I0526 01:49:49.089088 20937 solver.cpp:237] Iteration 241125, loss = 1.05307
I0526 01:49:49.089146 20937 solver.cpp:253]     Train net output #0: loss = 1.05307 (* 1 = 1.05307 loss)
I0526 01:49:49.089171 20937 sgd_solver.cpp:106] Iteration 241125, lr = 0.0015
I0526 01:50:19.900168 20937 solver.cpp:237] Iteration 241500, loss = 1.07566
I0526 01:50:19.900367 20937 solver.cpp:253]     Train net output #0: loss = 1.07566 (* 1 = 1.07566 loss)
I0526 01:50:19.900385 20937 sgd_solver.cpp:106] Iteration 241500, lr = 0.0015
I0526 01:50:29.857908 20937 solver.cpp:237] Iteration 241875, loss = 1.12761
I0526 01:50:29.857945 20937 solver.cpp:253]     Train net output #0: loss = 1.12761 (* 1 = 1.12761 loss)
I0526 01:50:29.857964 20937 sgd_solver.cpp:106] Iteration 241875, lr = 0.0015
I0526 01:50:39.808210 20937 solver.cpp:237] Iteration 242250, loss = 1.0137
I0526 01:50:39.808267 20937 solver.cpp:253]     Train net output #0: loss = 1.0137 (* 1 = 1.0137 loss)
I0526 01:50:39.808292 20937 sgd_solver.cpp:106] Iteration 242250, lr = 0.0015
I0526 01:50:49.760402 20937 solver.cpp:237] Iteration 242625, loss = 1.29577
I0526 01:50:49.760442 20937 solver.cpp:253]     Train net output #0: loss = 1.29577 (* 1 = 1.29577 loss)
I0526 01:50:49.760458 20937 sgd_solver.cpp:106] Iteration 242625, lr = 0.0015
I0526 01:50:59.682883 20937 solver.cpp:237] Iteration 243000, loss = 1.22924
I0526 01:50:59.683066 20937 solver.cpp:253]     Train net output #0: loss = 1.22924 (* 1 = 1.22924 loss)
I0526 01:50:59.683084 20937 sgd_solver.cpp:106] Iteration 243000, lr = 0.0015
I0526 01:51:09.462677 20937 solver.cpp:237] Iteration 243375, loss = 1.24553
I0526 01:51:09.462716 20937 solver.cpp:253]     Train net output #0: loss = 1.24553 (* 1 = 1.24553 loss)
I0526 01:51:09.462733 20937 sgd_solver.cpp:106] Iteration 243375, lr = 0.0015
I0526 01:51:19.215436 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_243750.caffemodel
I0526 01:51:19.273751 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_243750.solverstate
I0526 01:51:40.180713 20937 solver.cpp:237] Iteration 243750, loss = 0.99882
I0526 01:51:40.180907 20937 solver.cpp:253]     Train net output #0: loss = 0.99882 (* 1 = 0.99882 loss)
I0526 01:51:40.180927 20937 sgd_solver.cpp:106] Iteration 243750, lr = 0.0015
I0526 01:51:49.961416 20937 solver.cpp:237] Iteration 244125, loss = 1.0805
I0526 01:51:49.961472 20937 solver.cpp:253]     Train net output #0: loss = 1.0805 (* 1 = 1.0805 loss)
I0526 01:51:49.961499 20937 sgd_solver.cpp:106] Iteration 244125, lr = 0.0015
I0526 01:51:59.734438 20937 solver.cpp:237] Iteration 244500, loss = 1.27185
I0526 01:51:59.734478 20937 solver.cpp:253]     Train net output #0: loss = 1.27185 (* 1 = 1.27185 loss)
I0526 01:51:59.734498 20937 sgd_solver.cpp:106] Iteration 244500, lr = 0.0015
I0526 01:52:09.511716 20937 solver.cpp:237] Iteration 244875, loss = 0.993364
I0526 01:52:09.511755 20937 solver.cpp:253]     Train net output #0: loss = 0.993365 (* 1 = 0.993365 loss)
I0526 01:52:09.511772 20937 sgd_solver.cpp:106] Iteration 244875, lr = 0.0015
I0526 01:52:19.271234 20937 solver.cpp:237] Iteration 245250, loss = 1.09046
I0526 01:52:19.271414 20937 solver.cpp:253]     Train net output #0: loss = 1.09046 (* 1 = 1.09046 loss)
I0526 01:52:19.271430 20937 sgd_solver.cpp:106] Iteration 245250, lr = 0.0015
I0526 01:52:29.026204 20937 solver.cpp:237] Iteration 245625, loss = 1.23463
I0526 01:52:29.026243 20937 solver.cpp:253]     Train net output #0: loss = 1.23463 (* 1 = 1.23463 loss)
I0526 01:52:29.026260 20937 sgd_solver.cpp:106] Iteration 245625, lr = 0.0015
I0526 01:52:38.780714 20937 solver.cpp:237] Iteration 246000, loss = 0.987821
I0526 01:52:38.780771 20937 solver.cpp:253]     Train net output #0: loss = 0.987821 (* 1 = 0.987821 loss)
I0526 01:52:38.780798 20937 sgd_solver.cpp:106] Iteration 246000, lr = 0.0015
I0526 01:53:09.401981 20937 solver.cpp:237] Iteration 246375, loss = 0.886137
I0526 01:53:09.402175 20937 solver.cpp:253]     Train net output #0: loss = 0.886137 (* 1 = 0.886137 loss)
I0526 01:53:09.402194 20937 sgd_solver.cpp:106] Iteration 246375, lr = 0.0015
I0526 01:53:19.176872 20937 solver.cpp:237] Iteration 246750, loss = 0.99103
I0526 01:53:19.176913 20937 solver.cpp:253]     Train net output #0: loss = 0.99103 (* 1 = 0.99103 loss)
I0526 01:53:19.176928 20937 sgd_solver.cpp:106] Iteration 246750, lr = 0.0015
I0526 01:53:28.961916 20937 solver.cpp:237] Iteration 247125, loss = 1.85656
I0526 01:53:28.961968 20937 solver.cpp:253]     Train net output #0: loss = 1.85656 (* 1 = 1.85656 loss)
I0526 01:53:28.961995 20937 sgd_solver.cpp:106] Iteration 247125, lr = 0.0015
I0526 01:53:38.709060 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_247500.caffemodel
I0526 01:53:38.767158 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_247500.solverstate
I0526 01:53:38.795063 20937 solver.cpp:341] Iteration 247500, Testing net (#0)
I0526 01:54:48.211621 20937 solver.cpp:409]     Test net output #0: accuracy = 0.898726
I0526 01:54:48.211804 20937 solver.cpp:409]     Test net output #1: loss = 0.30685 (* 1 = 0.30685 loss)
I0526 01:54:48.219931 20937 solver.cpp:237] Iteration 247500, loss = 1.12101
I0526 01:54:48.219962 20937 solver.cpp:253]     Train net output #0: loss = 1.12101 (* 1 = 1.12101 loss)
I0526 01:54:48.219980 20937 sgd_solver.cpp:106] Iteration 247500, lr = 0.0015
I0526 01:54:57.938124 20937 solver.cpp:237] Iteration 247875, loss = 1.18329
I0526 01:54:57.938161 20937 solver.cpp:253]     Train net output #0: loss = 1.18329 (* 1 = 1.18329 loss)
I0526 01:54:57.938180 20937 sgd_solver.cpp:106] Iteration 247875, lr = 0.0015
I0526 01:55:07.666211 20937 solver.cpp:237] Iteration 248250, loss = 1.49451
I0526 01:55:07.666271 20937 solver.cpp:253]     Train net output #0: loss = 1.49451 (* 1 = 1.49451 loss)
I0526 01:55:07.666297 20937 sgd_solver.cpp:106] Iteration 248250, lr = 0.0015
I0526 01:55:17.576438 20937 solver.cpp:237] Iteration 248625, loss = 1.01075
I0526 01:55:17.576475 20937 solver.cpp:253]     Train net output #0: loss = 1.01075 (* 1 = 1.01075 loss)
I0526 01:55:17.576493 20937 sgd_solver.cpp:106] Iteration 248625, lr = 0.0015
I0526 01:55:48.367631 20937 solver.cpp:237] Iteration 249000, loss = 0.875627
I0526 01:55:48.367816 20937 solver.cpp:253]     Train net output #0: loss = 0.875628 (* 1 = 0.875628 loss)
I0526 01:55:48.367835 20937 sgd_solver.cpp:106] Iteration 249000, lr = 0.0015
I0526 01:55:58.285601 20937 solver.cpp:237] Iteration 249375, loss = 1.17154
I0526 01:55:58.285660 20937 solver.cpp:253]     Train net output #0: loss = 1.17154 (* 1 = 1.17154 loss)
I0526 01:55:58.285688 20937 sgd_solver.cpp:106] Iteration 249375, lr = 0.0015
I0526 01:56:08.199077 20937 solver.cpp:237] Iteration 249750, loss = 1.06562
I0526 01:56:08.199120 20937 solver.cpp:253]     Train net output #0: loss = 1.06562 (* 1 = 1.06562 loss)
I0526 01:56:08.199137 20937 sgd_solver.cpp:106] Iteration 249750, lr = 0.0015
I0526 01:56:18.118335 20937 solver.cpp:237] Iteration 250125, loss = 1.11378
I0526 01:56:18.118372 20937 solver.cpp:253]     Train net output #0: loss = 1.11378 (* 1 = 1.11378 loss)
I0526 01:56:18.118389 20937 sgd_solver.cpp:106] Iteration 250125, lr = 0.0015
I0526 01:56:28.027657 20937 solver.cpp:237] Iteration 250500, loss = 1.09849
I0526 01:56:28.027838 20937 solver.cpp:253]     Train net output #0: loss = 1.09849 (* 1 = 1.09849 loss)
I0526 01:56:28.027858 20937 sgd_solver.cpp:106] Iteration 250500, lr = 0.0015
I0526 01:56:37.888059 20937 solver.cpp:237] Iteration 250875, loss = 1.26378
I0526 01:56:37.888097 20937 solver.cpp:253]     Train net output #0: loss = 1.26378 (* 1 = 1.26378 loss)
I0526 01:56:37.888121 20937 sgd_solver.cpp:106] Iteration 250875, lr = 0.0015
I0526 01:56:47.727025 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_251250.caffemodel
I0526 01:56:47.783313 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_251250.solverstate
I0526 01:57:08.681658 20937 solver.cpp:237] Iteration 251250, loss = 1.14669
I0526 01:57:08.681851 20937 solver.cpp:253]     Train net output #0: loss = 1.14669 (* 1 = 1.14669 loss)
I0526 01:57:08.681869 20937 sgd_solver.cpp:106] Iteration 251250, lr = 0.0015
I0526 01:57:18.432790 20937 solver.cpp:237] Iteration 251625, loss = 1.25232
I0526 01:57:18.432847 20937 solver.cpp:253]     Train net output #0: loss = 1.25233 (* 1 = 1.25233 loss)
I0526 01:57:18.432873 20937 sgd_solver.cpp:106] Iteration 251625, lr = 0.0015
I0526 01:57:28.182533 20937 solver.cpp:237] Iteration 252000, loss = 1.14965
I0526 01:57:28.182572 20937 solver.cpp:253]     Train net output #0: loss = 1.14965 (* 1 = 1.14965 loss)
I0526 01:57:28.182591 20937 sgd_solver.cpp:106] Iteration 252000, lr = 0.0015
I0526 01:57:37.932530 20937 solver.cpp:237] Iteration 252375, loss = 1.21252
I0526 01:57:37.932585 20937 solver.cpp:253]     Train net output #0: loss = 1.21252 (* 1 = 1.21252 loss)
I0526 01:57:37.932610 20937 sgd_solver.cpp:106] Iteration 252375, lr = 0.0015
I0526 01:57:47.641021 20937 solver.cpp:237] Iteration 252750, loss = 1.01344
I0526 01:57:47.641187 20937 solver.cpp:253]     Train net output #0: loss = 1.01344 (* 1 = 1.01344 loss)
I0526 01:57:47.641204 20937 sgd_solver.cpp:106] Iteration 252750, lr = 0.0015
I0526 01:57:57.349732 20937 solver.cpp:237] Iteration 253125, loss = 1.21006
I0526 01:57:57.349769 20937 solver.cpp:253]     Train net output #0: loss = 1.21006 (* 1 = 1.21006 loss)
I0526 01:57:57.349787 20937 sgd_solver.cpp:106] Iteration 253125, lr = 0.0015
I0526 01:58:07.096447 20937 solver.cpp:237] Iteration 253500, loss = 0.879439
I0526 01:58:07.096500 20937 solver.cpp:253]     Train net output #0: loss = 0.879439 (* 1 = 0.879439 loss)
I0526 01:58:07.096526 20937 sgd_solver.cpp:106] Iteration 253500, lr = 0.0015
I0526 01:58:37.802713 20937 solver.cpp:237] Iteration 253875, loss = 1.05311
I0526 01:58:37.802898 20937 solver.cpp:253]     Train net output #0: loss = 1.05311 (* 1 = 1.05311 loss)
I0526 01:58:37.802917 20937 sgd_solver.cpp:106] Iteration 253875, lr = 0.0015
I0526 01:58:47.590003 20937 solver.cpp:237] Iteration 254250, loss = 1.20091
I0526 01:58:47.590042 20937 solver.cpp:253]     Train net output #0: loss = 1.20091 (* 1 = 1.20091 loss)
I0526 01:58:47.590059 20937 sgd_solver.cpp:106] Iteration 254250, lr = 0.0015
I0526 01:58:57.462491 20937 solver.cpp:237] Iteration 254625, loss = 1.09412
I0526 01:58:57.462548 20937 solver.cpp:253]     Train net output #0: loss = 1.09412 (* 1 = 1.09412 loss)
I0526 01:58:57.462577 20937 sgd_solver.cpp:106] Iteration 254625, lr = 0.0015
I0526 01:59:07.389922 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_255000.caffemodel
I0526 01:59:07.446964 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_255000.solverstate
I0526 01:59:07.472782 20937 solver.cpp:341] Iteration 255000, Testing net (#0)
I0526 01:59:55.710680 20937 solver.cpp:409]     Test net output #0: accuracy = 0.899645
I0526 01:59:55.710862 20937 solver.cpp:409]     Test net output #1: loss = 0.322129 (* 1 = 0.322129 loss)
I0526 01:59:55.718988 20937 solver.cpp:237] Iteration 255000, loss = 1.28518
I0526 01:59:55.719017 20937 solver.cpp:253]     Train net output #0: loss = 1.28518 (* 1 = 1.28518 loss)
I0526 01:59:55.719035 20937 sgd_solver.cpp:106] Iteration 255000, lr = 0.0015
I0526 02:00:05.512006 20937 solver.cpp:237] Iteration 255375, loss = 1.14871
I0526 02:00:05.512045 20937 solver.cpp:253]     Train net output #0: loss = 1.14871 (* 1 = 1.14871 loss)
I0526 02:00:05.512063 20937 sgd_solver.cpp:106] Iteration 255375, lr = 0.0015
I0526 02:00:15.308878 20937 solver.cpp:237] Iteration 255750, loss = 1.23939
I0526 02:00:15.308933 20937 solver.cpp:253]     Train net output #0: loss = 1.23939 (* 1 = 1.23939 loss)
I0526 02:00:15.308959 20937 sgd_solver.cpp:106] Iteration 255750, lr = 0.0015
I0526 02:00:25.116067 20937 solver.cpp:237] Iteration 256125, loss = 0.967698
I0526 02:00:25.116106 20937 solver.cpp:253]     Train net output #0: loss = 0.967698 (* 1 = 0.967698 loss)
I0526 02:00:25.116124 20937 sgd_solver.cpp:106] Iteration 256125, lr = 0.0015
I0526 02:00:55.778637 20937 solver.cpp:237] Iteration 256500, loss = 0.859772
I0526 02:00:55.778834 20937 solver.cpp:253]     Train net output #0: loss = 0.859772 (* 1 = 0.859772 loss)
I0526 02:00:55.778852 20937 sgd_solver.cpp:106] Iteration 256500, lr = 0.0015
I0526 02:01:05.572134 20937 solver.cpp:237] Iteration 256875, loss = 1.16657
I0526 02:01:05.572190 20937 solver.cpp:253]     Train net output #0: loss = 1.16657 (* 1 = 1.16657 loss)
I0526 02:01:05.572207 20937 sgd_solver.cpp:106] Iteration 256875, lr = 0.0015
I0526 02:01:15.378756 20937 solver.cpp:237] Iteration 257250, loss = 1.23141
I0526 02:01:15.378795 20937 solver.cpp:253]     Train net output #0: loss = 1.23141 (* 1 = 1.23141 loss)
I0526 02:01:15.378813 20937 sgd_solver.cpp:106] Iteration 257250, lr = 0.0015
I0526 02:01:25.180928 20937 solver.cpp:237] Iteration 257625, loss = 1.19116
I0526 02:01:25.180987 20937 solver.cpp:253]     Train net output #0: loss = 1.19116 (* 1 = 1.19116 loss)
I0526 02:01:25.181015 20937 sgd_solver.cpp:106] Iteration 257625, lr = 0.0015
I0526 02:01:34.970113 20937 solver.cpp:237] Iteration 258000, loss = 1.08814
I0526 02:01:34.970280 20937 solver.cpp:253]     Train net output #0: loss = 1.08814 (* 1 = 1.08814 loss)
I0526 02:01:34.970296 20937 sgd_solver.cpp:106] Iteration 258000, lr = 0.0015
I0526 02:01:44.755553 20937 solver.cpp:237] Iteration 258375, loss = 1.1182
I0526 02:01:44.755589 20937 solver.cpp:253]     Train net output #0: loss = 1.1182 (* 1 = 1.1182 loss)
I0526 02:01:44.755612 20937 sgd_solver.cpp:106] Iteration 258375, lr = 0.0015
I0526 02:01:54.558708 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_258750.caffemodel
I0526 02:01:54.615442 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_258750.solverstate
I0526 02:02:15.521250 20937 solver.cpp:237] Iteration 258750, loss = 1.12838
I0526 02:02:15.521450 20937 solver.cpp:253]     Train net output #0: loss = 1.12838 (* 1 = 1.12838 loss)
I0526 02:02:15.521467 20937 sgd_solver.cpp:106] Iteration 258750, lr = 0.0015
I0526 02:02:25.372544 20937 solver.cpp:237] Iteration 259125, loss = 1.10511
I0526 02:02:25.372588 20937 solver.cpp:253]     Train net output #0: loss = 1.10511 (* 1 = 1.10511 loss)
I0526 02:02:25.372606 20937 sgd_solver.cpp:106] Iteration 259125, lr = 0.0015
I0526 02:02:35.227661 20937 solver.cpp:237] Iteration 259500, loss = 1.01642
I0526 02:02:35.227700 20937 solver.cpp:253]     Train net output #0: loss = 1.01642 (* 1 = 1.01642 loss)
I0526 02:02:35.227725 20937 sgd_solver.cpp:106] Iteration 259500, lr = 0.0015
I0526 02:02:45.044962 20937 solver.cpp:237] Iteration 259875, loss = 1.15298
I0526 02:02:45.045019 20937 solver.cpp:253]     Train net output #0: loss = 1.15298 (* 1 = 1.15298 loss)
I0526 02:02:45.045047 20937 sgd_solver.cpp:106] Iteration 259875, lr = 0.0015
I0526 02:02:54.863386 20937 solver.cpp:237] Iteration 260250, loss = 1.24034
I0526 02:02:54.863551 20937 solver.cpp:253]     Train net output #0: loss = 1.24035 (* 1 = 1.24035 loss)
I0526 02:02:54.863569 20937 sgd_solver.cpp:106] Iteration 260250, lr = 0.0015
I0526 02:03:04.647421 20937 solver.cpp:237] Iteration 260625, loss = 0.910457
I0526 02:03:04.647481 20937 solver.cpp:253]     Train net output #0: loss = 0.910458 (* 1 = 0.910458 loss)
I0526 02:03:04.647507 20937 sgd_solver.cpp:106] Iteration 260625, lr = 0.0015
I0526 02:03:14.430091 20937 solver.cpp:237] Iteration 261000, loss = 1.12421
I0526 02:03:14.430130 20937 solver.cpp:253]     Train net output #0: loss = 1.12421 (* 1 = 1.12421 loss)
I0526 02:03:14.430150 20937 sgd_solver.cpp:106] Iteration 261000, lr = 0.0015
I0526 02:03:45.069682 20937 solver.cpp:237] Iteration 261375, loss = 1.19964
I0526 02:03:45.069878 20937 solver.cpp:253]     Train net output #0: loss = 1.19964 (* 1 = 1.19964 loss)
I0526 02:03:45.069896 20937 sgd_solver.cpp:106] Iteration 261375, lr = 0.0015
I0526 02:03:54.861330 20937 solver.cpp:237] Iteration 261750, loss = 0.853442
I0526 02:03:54.861392 20937 solver.cpp:253]     Train net output #0: loss = 0.853442 (* 1 = 0.853442 loss)
I0526 02:03:54.861418 20937 sgd_solver.cpp:106] Iteration 261750, lr = 0.0015
I0526 02:04:04.588232 20937 solver.cpp:237] Iteration 262125, loss = 0.953746
I0526 02:04:04.588270 20937 solver.cpp:253]     Train net output #0: loss = 0.953746 (* 1 = 0.953746 loss)
I0526 02:04:04.588289 20937 sgd_solver.cpp:106] Iteration 262125, lr = 0.0015
I0526 02:04:14.288877 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_262500.caffemodel
I0526 02:04:14.349992 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_262500.solverstate
I0526 02:04:14.378661 20937 solver.cpp:341] Iteration 262500, Testing net (#0)
I0526 02:05:23.837606 20937 solver.cpp:409]     Test net output #0: accuracy = 0.89764
I0526 02:05:23.837796 20937 solver.cpp:409]     Test net output #1: loss = 0.312193 (* 1 = 0.312193 loss)
I0526 02:05:23.845916 20937 solver.cpp:237] Iteration 262500, loss = 1.00038
I0526 02:05:23.845944 20937 solver.cpp:253]     Train net output #0: loss = 1.00038 (* 1 = 1.00038 loss)
I0526 02:05:23.845963 20937 sgd_solver.cpp:106] Iteration 262500, lr = 0.0015
I0526 02:05:33.706171 20937 solver.cpp:237] Iteration 262875, loss = 1.05907
I0526 02:05:33.706226 20937 solver.cpp:253]     Train net output #0: loss = 1.05907 (* 1 = 1.05907 loss)
I0526 02:05:33.706243 20937 sgd_solver.cpp:106] Iteration 262875, lr = 0.0015
I0526 02:05:43.510778 20937 solver.cpp:237] Iteration 263250, loss = 1.3506
I0526 02:05:43.510818 20937 solver.cpp:253]     Train net output #0: loss = 1.3506 (* 1 = 1.3506 loss)
I0526 02:05:43.510838 20937 sgd_solver.cpp:106] Iteration 263250, lr = 0.0015
I0526 02:05:53.309882 20937 solver.cpp:237] Iteration 263625, loss = 1.20842
I0526 02:05:53.309922 20937 solver.cpp:253]     Train net output #0: loss = 1.20842 (* 1 = 1.20842 loss)
I0526 02:05:53.309940 20937 sgd_solver.cpp:106] Iteration 263625, lr = 0.0015
I0526 02:06:24.004748 20937 solver.cpp:237] Iteration 264000, loss = 1.07031
I0526 02:06:24.004945 20937 solver.cpp:253]     Train net output #0: loss = 1.07031 (* 1 = 1.07031 loss)
I0526 02:06:24.004962 20937 sgd_solver.cpp:106] Iteration 264000, lr = 0.0015
I0526 02:06:33.904487 20937 solver.cpp:237] Iteration 264375, loss = 1.08575
I0526 02:06:33.904525 20937 solver.cpp:253]     Train net output #0: loss = 1.08575 (* 1 = 1.08575 loss)
I0526 02:06:33.904546 20937 sgd_solver.cpp:106] Iteration 264375, lr = 0.0015
I0526 02:06:43.809227 20937 solver.cpp:237] Iteration 264750, loss = 1.14131
I0526 02:06:43.809267 20937 solver.cpp:253]     Train net output #0: loss = 1.14131 (* 1 = 1.14131 loss)
I0526 02:06:43.809284 20937 sgd_solver.cpp:106] Iteration 264750, lr = 0.0015
I0526 02:06:53.713698 20937 solver.cpp:237] Iteration 265125, loss = 1.15153
I0526 02:06:53.713752 20937 solver.cpp:253]     Train net output #0: loss = 1.15153 (* 1 = 1.15153 loss)
I0526 02:06:53.713769 20937 sgd_solver.cpp:106] Iteration 265125, lr = 0.0015
I0526 02:07:03.617933 20937 solver.cpp:237] Iteration 265500, loss = 1.42358
I0526 02:07:03.618116 20937 solver.cpp:253]     Train net output #0: loss = 1.42358 (* 1 = 1.42358 loss)
I0526 02:07:03.618134 20937 sgd_solver.cpp:106] Iteration 265500, lr = 0.0015
I0526 02:07:13.528944 20937 solver.cpp:237] Iteration 265875, loss = 0.809994
I0526 02:07:13.529003 20937 solver.cpp:253]     Train net output #0: loss = 0.809995 (* 1 = 0.809995 loss)
I0526 02:07:13.529031 20937 sgd_solver.cpp:106] Iteration 265875, lr = 0.0015
I0526 02:07:23.401800 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_266250.caffemodel
I0526 02:07:23.457780 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_266250.solverstate
I0526 02:07:44.360512 20937 solver.cpp:237] Iteration 266250, loss = 0.977704
I0526 02:07:44.360708 20937 solver.cpp:253]     Train net output #0: loss = 0.977704 (* 1 = 0.977704 loss)
I0526 02:07:44.360726 20937 sgd_solver.cpp:106] Iteration 266250, lr = 0.0015
I0526 02:07:54.265081 20937 solver.cpp:237] Iteration 266625, loss = 0.952623
I0526 02:07:54.265122 20937 solver.cpp:253]     Train net output #0: loss = 0.952623 (* 1 = 0.952623 loss)
I0526 02:07:54.265147 20937 sgd_solver.cpp:106] Iteration 266625, lr = 0.0015
I0526 02:08:04.176259 20937 solver.cpp:237] Iteration 267000, loss = 0.879052
I0526 02:08:04.176317 20937 solver.cpp:253]     Train net output #0: loss = 0.879052 (* 1 = 0.879052 loss)
I0526 02:08:04.176334 20937 sgd_solver.cpp:106] Iteration 267000, lr = 0.0015
I0526 02:08:14.083268 20937 solver.cpp:237] Iteration 267375, loss = 1.40908
I0526 02:08:14.083307 20937 solver.cpp:253]     Train net output #0: loss = 1.40908 (* 1 = 1.40908 loss)
I0526 02:08:14.083326 20937 sgd_solver.cpp:106] Iteration 267375, lr = 0.0015
I0526 02:08:23.986790 20937 solver.cpp:237] Iteration 267750, loss = 1.11791
I0526 02:08:23.986970 20937 solver.cpp:253]     Train net output #0: loss = 1.11791 (* 1 = 1.11791 loss)
I0526 02:08:23.986987 20937 sgd_solver.cpp:106] Iteration 267750, lr = 0.0015
I0526 02:08:33.804946 20937 solver.cpp:237] Iteration 268125, loss = 1.15326
I0526 02:08:33.805001 20937 solver.cpp:253]     Train net output #0: loss = 1.15326 (* 1 = 1.15326 loss)
I0526 02:08:33.805017 20937 sgd_solver.cpp:106] Iteration 268125, lr = 0.0015
I0526 02:08:43.572944 20937 solver.cpp:237] Iteration 268500, loss = 1.01229
I0526 02:08:43.572981 20937 solver.cpp:253]     Train net output #0: loss = 1.01229 (* 1 = 1.01229 loss)
I0526 02:08:43.573005 20937 sgd_solver.cpp:106] Iteration 268500, lr = 0.0015
I0526 02:09:14.191754 20937 solver.cpp:237] Iteration 268875, loss = 1.08149
I0526 02:09:14.191946 20937 solver.cpp:253]     Train net output #0: loss = 1.08149 (* 1 = 1.08149 loss)
I0526 02:09:14.191965 20937 sgd_solver.cpp:106] Iteration 268875, lr = 0.0015
I0526 02:09:23.943102 20937 solver.cpp:237] Iteration 269250, loss = 1.07545
I0526 02:09:23.943159 20937 solver.cpp:253]     Train net output #0: loss = 1.07545 (* 1 = 1.07545 loss)
I0526 02:09:23.943186 20937 sgd_solver.cpp:106] Iteration 269250, lr = 0.0015
I0526 02:09:33.673046 20937 solver.cpp:237] Iteration 269625, loss = 1.07722
I0526 02:09:33.673084 20937 solver.cpp:253]     Train net output #0: loss = 1.07722 (* 1 = 1.07722 loss)
I0526 02:09:33.673107 20937 sgd_solver.cpp:106] Iteration 269625, lr = 0.0015
I0526 02:09:43.386365 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_270000.caffemodel
I0526 02:09:43.442919 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_270000.solverstate
I0526 02:09:43.468757 20937 solver.cpp:341] Iteration 270000, Testing net (#0)
I0526 02:10:32.076861 20937 solver.cpp:409]     Test net output #0: accuracy = 0.900547
I0526 02:10:32.077060 20937 solver.cpp:409]     Test net output #1: loss = 0.305788 (* 1 = 0.305788 loss)
I0526 02:10:32.085122 20937 solver.cpp:237] Iteration 270000, loss = 1.12128
I0526 02:10:32.085151 20937 solver.cpp:253]     Train net output #0: loss = 1.12128 (* 1 = 1.12128 loss)
I0526 02:10:32.085168 20937 sgd_solver.cpp:106] Iteration 270000, lr = 0.0015
I0526 02:10:41.961637 20937 solver.cpp:237] Iteration 270375, loss = 1.05988
I0526 02:10:41.961689 20937 solver.cpp:253]     Train net output #0: loss = 1.05988 (* 1 = 1.05988 loss)
I0526 02:10:41.961706 20937 sgd_solver.cpp:106] Iteration 270375, lr = 0.0015
I0526 02:10:51.833639 20937 solver.cpp:237] Iteration 270750, loss = 1.2055
I0526 02:10:51.833678 20937 solver.cpp:253]     Train net output #0: loss = 1.2055 (* 1 = 1.2055 loss)
I0526 02:10:51.833698 20937 sgd_solver.cpp:106] Iteration 270750, lr = 0.0015
I0526 02:11:01.720329 20937 solver.cpp:237] Iteration 271125, loss = 0.969034
I0526 02:11:01.720393 20937 solver.cpp:253]     Train net output #0: loss = 0.969034 (* 1 = 0.969034 loss)
I0526 02:11:01.720418 20937 sgd_solver.cpp:106] Iteration 271125, lr = 0.0015
I0526 02:11:32.493774 20937 solver.cpp:237] Iteration 271500, loss = 0.913605
I0526 02:11:32.493968 20937 solver.cpp:253]     Train net output #0: loss = 0.913605 (* 1 = 0.913605 loss)
I0526 02:11:32.493984 20937 sgd_solver.cpp:106] Iteration 271500, lr = 0.0015
I0526 02:11:42.369810 20937 solver.cpp:237] Iteration 271875, loss = 1.17932
I0526 02:11:42.369848 20937 solver.cpp:253]     Train net output #0: loss = 1.17932 (* 1 = 1.17932 loss)
I0526 02:11:42.369873 20937 sgd_solver.cpp:106] Iteration 271875, lr = 0.0015
I0526 02:11:52.175086 20937 solver.cpp:237] Iteration 272250, loss = 1.30839
I0526 02:11:52.175140 20937 solver.cpp:253]     Train net output #0: loss = 1.30839 (* 1 = 1.30839 loss)
I0526 02:11:52.175158 20937 sgd_solver.cpp:106] Iteration 272250, lr = 0.0015
I0526 02:12:01.905416 20937 solver.cpp:237] Iteration 272625, loss = 1.21568
I0526 02:12:01.905455 20937 solver.cpp:253]     Train net output #0: loss = 1.21568 (* 1 = 1.21568 loss)
I0526 02:12:01.905472 20937 sgd_solver.cpp:106] Iteration 272625, lr = 0.0015
I0526 02:12:11.633605 20937 solver.cpp:237] Iteration 273000, loss = 1.24292
I0526 02:12:11.633775 20937 solver.cpp:253]     Train net output #0: loss = 1.24292 (* 1 = 1.24292 loss)
I0526 02:12:11.633792 20937 sgd_solver.cpp:106] Iteration 273000, lr = 0.0015
I0526 02:12:21.466847 20937 solver.cpp:237] Iteration 273375, loss = 1.05947
I0526 02:12:21.466904 20937 solver.cpp:253]     Train net output #0: loss = 1.05947 (* 1 = 1.05947 loss)
I0526 02:12:21.466929 20937 sgd_solver.cpp:106] Iteration 273375, lr = 0.0015
I0526 02:12:31.284562 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_273750.caffemodel
I0526 02:12:31.341317 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_273750.solverstate
I0526 02:12:52.235802 20937 solver.cpp:237] Iteration 273750, loss = 1.37062
I0526 02:12:52.236001 20937 solver.cpp:253]     Train net output #0: loss = 1.37062 (* 1 = 1.37062 loss)
I0526 02:12:52.236021 20937 sgd_solver.cpp:106] Iteration 273750, lr = 0.0015
I0526 02:13:02.083773 20937 solver.cpp:237] Iteration 274125, loss = 1.09959
I0526 02:13:02.083817 20937 solver.cpp:253]     Train net output #0: loss = 1.09959 (* 1 = 1.09959 loss)
I0526 02:13:02.083834 20937 sgd_solver.cpp:106] Iteration 274125, lr = 0.0015
I0526 02:13:11.954991 20937 solver.cpp:237] Iteration 274500, loss = 1.1318
I0526 02:13:11.955049 20937 solver.cpp:253]     Train net output #0: loss = 1.1318 (* 1 = 1.1318 loss)
I0526 02:13:11.955066 20937 sgd_solver.cpp:106] Iteration 274500, lr = 0.0015
I0526 02:13:21.830695 20937 solver.cpp:237] Iteration 274875, loss = 0.905012
I0526 02:13:21.830734 20937 solver.cpp:253]     Train net output #0: loss = 0.905012 (* 1 = 0.905012 loss)
I0526 02:13:21.830752 20937 sgd_solver.cpp:106] Iteration 274875, lr = 0.0015
I0526 02:13:31.655067 20937 solver.cpp:237] Iteration 275250, loss = 1.10633
I0526 02:13:31.655267 20937 solver.cpp:253]     Train net output #0: loss = 1.10633 (* 1 = 1.10633 loss)
I0526 02:13:31.655287 20937 sgd_solver.cpp:106] Iteration 275250, lr = 0.0015
I0526 02:13:41.419240 20937 solver.cpp:237] Iteration 275625, loss = 0.950927
I0526 02:13:41.419278 20937 solver.cpp:253]     Train net output #0: loss = 0.950927 (* 1 = 0.950927 loss)
I0526 02:13:41.419297 20937 sgd_solver.cpp:106] Iteration 275625, lr = 0.0015
I0526 02:13:51.174895 20937 solver.cpp:237] Iteration 276000, loss = 0.987013
I0526 02:13:51.174933 20937 solver.cpp:253]     Train net output #0: loss = 0.987014 (* 1 = 0.987014 loss)
I0526 02:13:51.174952 20937 sgd_solver.cpp:106] Iteration 276000, lr = 0.0015
I0526 02:14:21.808920 20937 solver.cpp:237] Iteration 276375, loss = 1.1509
I0526 02:14:21.809113 20937 solver.cpp:253]     Train net output #0: loss = 1.1509 (* 1 = 1.1509 loss)
I0526 02:14:21.809131 20937 sgd_solver.cpp:106] Iteration 276375, lr = 0.0015
I0526 02:14:31.565086 20937 solver.cpp:237] Iteration 276750, loss = 0.978856
I0526 02:14:31.565124 20937 solver.cpp:253]     Train net output #0: loss = 0.978856 (* 1 = 0.978856 loss)
I0526 02:14:31.565147 20937 sgd_solver.cpp:106] Iteration 276750, lr = 0.0015
I0526 02:14:41.325793 20937 solver.cpp:237] Iteration 277125, loss = 1.23255
I0526 02:14:41.325829 20937 solver.cpp:253]     Train net output #0: loss = 1.23255 (* 1 = 1.23255 loss)
I0526 02:14:41.325852 20937 sgd_solver.cpp:106] Iteration 277125, lr = 0.0015
I0526 02:14:51.151882 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_277500.caffemodel
I0526 02:14:51.207695 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_277500.solverstate
I0526 02:14:51.233575 20937 solver.cpp:341] Iteration 277500, Testing net (#0)
I0526 02:16:00.725121 20937 solver.cpp:409]     Test net output #0: accuracy = 0.900339
I0526 02:16:00.725311 20937 solver.cpp:409]     Test net output #1: loss = 0.315381 (* 1 = 0.315381 loss)
I0526 02:16:00.733412 20937 solver.cpp:237] Iteration 277500, loss = 1.1843
I0526 02:16:00.733444 20937 solver.cpp:253]     Train net output #0: loss = 1.1843 (* 1 = 1.1843 loss)
I0526 02:16:00.733461 20937 sgd_solver.cpp:106] Iteration 277500, lr = 0.0015
I0526 02:16:10.475417 20937 solver.cpp:237] Iteration 277875, loss = 0.927447
I0526 02:16:10.475456 20937 solver.cpp:253]     Train net output #0: loss = 0.927448 (* 1 = 0.927448 loss)
I0526 02:16:10.475476 20937 sgd_solver.cpp:106] Iteration 277875, lr = 0.0015
I0526 02:16:20.224843 20937 solver.cpp:237] Iteration 278250, loss = 1.58207
I0526 02:16:20.224881 20937 solver.cpp:253]     Train net output #0: loss = 1.58207 (* 1 = 1.58207 loss)
I0526 02:16:20.224900 20937 sgd_solver.cpp:106] Iteration 278250, lr = 0.0015
I0526 02:16:30.046717 20937 solver.cpp:237] Iteration 278625, loss = 1.14295
I0526 02:16:30.046777 20937 solver.cpp:253]     Train net output #0: loss = 1.14295 (* 1 = 1.14295 loss)
I0526 02:16:30.046802 20937 sgd_solver.cpp:106] Iteration 278625, lr = 0.0015
I0526 02:17:00.794757 20937 solver.cpp:237] Iteration 279000, loss = 0.915931
I0526 02:17:00.794950 20937 solver.cpp:253]     Train net output #0: loss = 0.915932 (* 1 = 0.915932 loss)
I0526 02:17:00.794968 20937 sgd_solver.cpp:106] Iteration 279000, lr = 0.0015
I0526 02:17:10.640305 20937 solver.cpp:237] Iteration 279375, loss = 1.35419
I0526 02:17:10.640349 20937 solver.cpp:253]     Train net output #0: loss = 1.35419 (* 1 = 1.35419 loss)
I0526 02:17:10.640367 20937 sgd_solver.cpp:106] Iteration 279375, lr = 0.0015
I0526 02:17:20.509174 20937 solver.cpp:237] Iteration 279750, loss = 1.25793
I0526 02:17:20.509232 20937 solver.cpp:253]     Train net output #0: loss = 1.25793 (* 1 = 1.25793 loss)
I0526 02:17:20.509258 20937 sgd_solver.cpp:106] Iteration 279750, lr = 0.0015
I0526 02:17:30.382334 20937 solver.cpp:237] Iteration 280125, loss = 1.4031
I0526 02:17:30.382374 20937 solver.cpp:253]     Train net output #0: loss = 1.4031 (* 1 = 1.4031 loss)
I0526 02:17:30.382390 20937 sgd_solver.cpp:106] Iteration 280125, lr = 0.0015
I0526 02:17:40.259780 20937 solver.cpp:237] Iteration 280500, loss = 1.23432
I0526 02:17:40.259979 20937 solver.cpp:253]     Train net output #0: loss = 1.23432 (* 1 = 1.23432 loss)
I0526 02:17:40.259999 20937 sgd_solver.cpp:106] Iteration 280500, lr = 0.0015
I0526 02:17:50.133693 20937 solver.cpp:237] Iteration 280875, loss = 1.32069
I0526 02:17:50.133731 20937 solver.cpp:253]     Train net output #0: loss = 1.3207 (* 1 = 1.3207 loss)
I0526 02:17:50.133751 20937 sgd_solver.cpp:106] Iteration 280875, lr = 0.0015
I0526 02:17:59.983273 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_281250.caffemodel
I0526 02:18:00.043005 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_281250.solverstate
I0526 02:18:20.989851 20937 solver.cpp:237] Iteration 281250, loss = 1.18165
I0526 02:18:20.990056 20937 solver.cpp:253]     Train net output #0: loss = 1.18165 (* 1 = 1.18165 loss)
I0526 02:18:20.990074 20937 sgd_solver.cpp:106] Iteration 281250, lr = 0.0015
I0526 02:18:30.805560 20937 solver.cpp:237] Iteration 281625, loss = 1.33421
I0526 02:18:30.805616 20937 solver.cpp:253]     Train net output #0: loss = 1.33421 (* 1 = 1.33421 loss)
I0526 02:18:30.805634 20937 sgd_solver.cpp:106] Iteration 281625, lr = 0.0015
I0526 02:18:40.492569 20937 solver.cpp:237] Iteration 282000, loss = 1.14281
I0526 02:18:40.492609 20937 solver.cpp:253]     Train net output #0: loss = 1.14281 (* 1 = 1.14281 loss)
I0526 02:18:40.492627 20937 sgd_solver.cpp:106] Iteration 282000, lr = 0.0015
I0526 02:18:50.175096 20937 solver.cpp:237] Iteration 282375, loss = 0.967777
I0526 02:18:50.175133 20937 solver.cpp:253]     Train net output #0: loss = 0.967777 (* 1 = 0.967777 loss)
I0526 02:18:50.175153 20937 sgd_solver.cpp:106] Iteration 282375, lr = 0.0015
I0526 02:18:59.854645 20937 solver.cpp:237] Iteration 282750, loss = 0.8331
I0526 02:18:59.854838 20937 solver.cpp:253]     Train net output #0: loss = 0.833101 (* 1 = 0.833101 loss)
I0526 02:18:59.854858 20937 sgd_solver.cpp:106] Iteration 282750, lr = 0.0015
I0526 02:19:09.534664 20937 solver.cpp:237] Iteration 283125, loss = 0.777133
I0526 02:19:09.534703 20937 solver.cpp:253]     Train net output #0: loss = 0.777133 (* 1 = 0.777133 loss)
I0526 02:19:09.534723 20937 sgd_solver.cpp:106] Iteration 283125, lr = 0.0015
I0526 02:19:19.226217 20937 solver.cpp:237] Iteration 283500, loss = 1.34784
I0526 02:19:19.226274 20937 solver.cpp:253]     Train net output #0: loss = 1.34784 (* 1 = 1.34784 loss)
I0526 02:19:19.226290 20937 sgd_solver.cpp:106] Iteration 283500, lr = 0.0015
I0526 02:19:49.786355 20937 solver.cpp:237] Iteration 283875, loss = 1.05468
I0526 02:19:49.786552 20937 solver.cpp:253]     Train net output #0: loss = 1.05468 (* 1 = 1.05468 loss)
I0526 02:19:49.786569 20937 sgd_solver.cpp:106] Iteration 283875, lr = 0.0015
I0526 02:19:59.469591 20937 solver.cpp:237] Iteration 284250, loss = 1.08887
I0526 02:19:59.469629 20937 solver.cpp:253]     Train net output #0: loss = 1.08887 (* 1 = 1.08887 loss)
I0526 02:19:59.469653 20937 sgd_solver.cpp:106] Iteration 284250, lr = 0.0015
I0526 02:20:09.158403 20937 solver.cpp:237] Iteration 284625, loss = 1.77642
I0526 02:20:09.158455 20937 solver.cpp:253]     Train net output #0: loss = 1.77642 (* 1 = 1.77642 loss)
I0526 02:20:09.158473 20937 sgd_solver.cpp:106] Iteration 284625, lr = 0.0015
I0526 02:20:18.857729 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_285000.caffemodel
I0526 02:20:18.914013 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_285000.solverstate
I0526 02:20:18.939709 20937 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 02:21:07.285254 20937 solver.cpp:409]     Test net output #0: accuracy = 0.900485
I0526 02:21:07.285459 20937 solver.cpp:409]     Test net output #1: loss = 0.30704 (* 1 = 0.30704 loss)
I0526 02:21:07.293555 20937 solver.cpp:237] Iteration 285000, loss = 1.27504
I0526 02:21:07.293583 20937 solver.cpp:253]     Train net output #0: loss = 1.27504 (* 1 = 1.27504 loss)
I0526 02:21:07.293601 20937 sgd_solver.cpp:106] Iteration 285000, lr = 0.0015
I0526 02:21:17.075295 20937 solver.cpp:237] Iteration 285375, loss = 1.30862
I0526 02:21:17.075333 20937 solver.cpp:253]     Train net output #0: loss = 1.30862 (* 1 = 1.30862 loss)
I0526 02:21:17.075352 20937 sgd_solver.cpp:106] Iteration 285375, lr = 0.0015
I0526 02:21:26.854001 20937 solver.cpp:237] Iteration 285750, loss = 1.22733
I0526 02:21:26.854055 20937 solver.cpp:253]     Train net output #0: loss = 1.22733 (* 1 = 1.22733 loss)
I0526 02:21:26.854074 20937 sgd_solver.cpp:106] Iteration 285750, lr = 0.0015
I0526 02:21:36.682595 20937 solver.cpp:237] Iteration 286125, loss = 1.03605
I0526 02:21:36.682632 20937 solver.cpp:253]     Train net output #0: loss = 1.03605 (* 1 = 1.03605 loss)
I0526 02:21:36.682657 20937 sgd_solver.cpp:106] Iteration 286125, lr = 0.0015
I0526 02:22:07.415534 20937 solver.cpp:237] Iteration 286500, loss = 1.11216
I0526 02:22:07.415727 20937 solver.cpp:253]     Train net output #0: loss = 1.11216 (* 1 = 1.11216 loss)
I0526 02:22:07.415745 20937 sgd_solver.cpp:106] Iteration 286500, lr = 0.0015
I0526 02:22:17.220677 20937 solver.cpp:237] Iteration 286875, loss = 1.22603
I0526 02:22:17.220736 20937 solver.cpp:253]     Train net output #0: loss = 1.22603 (* 1 = 1.22603 loss)
I0526 02:22:17.220752 20937 sgd_solver.cpp:106] Iteration 286875, lr = 0.0015
I0526 02:22:26.983305 20937 solver.cpp:237] Iteration 287250, loss = 1.18595
I0526 02:22:26.983342 20937 solver.cpp:253]     Train net output #0: loss = 1.18595 (* 1 = 1.18595 loss)
I0526 02:22:26.983366 20937 sgd_solver.cpp:106] Iteration 287250, lr = 0.0015
I0526 02:22:36.751685 20937 solver.cpp:237] Iteration 287625, loss = 1.0205
I0526 02:22:36.751724 20937 solver.cpp:253]     Train net output #0: loss = 1.0205 (* 1 = 1.0205 loss)
I0526 02:22:36.751742 20937 sgd_solver.cpp:106] Iteration 287625, lr = 0.0015
I0526 02:22:46.528234 20937 solver.cpp:237] Iteration 288000, loss = 1.18835
I0526 02:22:46.528434 20937 solver.cpp:253]     Train net output #0: loss = 1.18835 (* 1 = 1.18835 loss)
I0526 02:22:46.528450 20937 sgd_solver.cpp:106] Iteration 288000, lr = 0.0015
I0526 02:22:56.304896 20937 solver.cpp:237] Iteration 288375, loss = 1.34229
I0526 02:22:56.304934 20937 solver.cpp:253]     Train net output #0: loss = 1.34229 (* 1 = 1.34229 loss)
I0526 02:22:56.304952 20937 sgd_solver.cpp:106] Iteration 288375, lr = 0.0015
I0526 02:23:06.036075 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_288750.caffemodel
I0526 02:23:06.092288 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_288750.solverstate
I0526 02:23:27.020094 20937 solver.cpp:237] Iteration 288750, loss = 1.33514
I0526 02:23:27.020297 20937 solver.cpp:253]     Train net output #0: loss = 1.33515 (* 1 = 1.33515 loss)
I0526 02:23:27.020314 20937 sgd_solver.cpp:106] Iteration 288750, lr = 0.0015
I0526 02:23:36.766618 20937 solver.cpp:237] Iteration 289125, loss = 1.01024
I0526 02:23:36.766672 20937 solver.cpp:253]     Train net output #0: loss = 1.01024 (* 1 = 1.01024 loss)
I0526 02:23:36.766690 20937 sgd_solver.cpp:106] Iteration 289125, lr = 0.0015
I0526 02:23:46.504995 20937 solver.cpp:237] Iteration 289500, loss = 1.25618
I0526 02:23:46.505033 20937 solver.cpp:253]     Train net output #0: loss = 1.25618 (* 1 = 1.25618 loss)
I0526 02:23:46.505058 20937 sgd_solver.cpp:106] Iteration 289500, lr = 0.0015
I0526 02:23:56.249411 20937 solver.cpp:237] Iteration 289875, loss = 1.29895
I0526 02:23:56.249464 20937 solver.cpp:253]     Train net output #0: loss = 1.29895 (* 1 = 1.29895 loss)
I0526 02:23:56.249482 20937 sgd_solver.cpp:106] Iteration 289875, lr = 0.0015
I0526 02:24:05.987699 20937 solver.cpp:237] Iteration 290250, loss = 1.25395
I0526 02:24:05.987900 20937 solver.cpp:253]     Train net output #0: loss = 1.25395 (* 1 = 1.25395 loss)
I0526 02:24:05.987917 20937 sgd_solver.cpp:106] Iteration 290250, lr = 0.0015
I0526 02:24:15.726680 20937 solver.cpp:237] Iteration 290625, loss = 1.38076
I0526 02:24:15.726718 20937 solver.cpp:253]     Train net output #0: loss = 1.38076 (* 1 = 1.38076 loss)
I0526 02:24:15.726735 20937 sgd_solver.cpp:106] Iteration 290625, lr = 0.0015
I0526 02:24:25.496073 20937 solver.cpp:237] Iteration 291000, loss = 0.977167
I0526 02:24:25.496129 20937 solver.cpp:253]     Train net output #0: loss = 0.977168 (* 1 = 0.977168 loss)
I0526 02:24:25.496155 20937 sgd_solver.cpp:106] Iteration 291000, lr = 0.0015
I0526 02:24:56.189906 20937 solver.cpp:237] Iteration 291375, loss = 1.35387
I0526 02:24:56.190114 20937 solver.cpp:253]     Train net output #0: loss = 1.35387 (* 1 = 1.35387 loss)
I0526 02:24:56.190131 20937 sgd_solver.cpp:106] Iteration 291375, lr = 0.0015
I0526 02:25:05.972062 20937 solver.cpp:237] Iteration 291750, loss = 1.01688
I0526 02:25:05.972101 20937 solver.cpp:253]     Train net output #0: loss = 1.01688 (* 1 = 1.01688 loss)
I0526 02:25:05.972121 20937 sgd_solver.cpp:106] Iteration 291750, lr = 0.0015
I0526 02:25:15.746091 20937 solver.cpp:237] Iteration 292125, loss = 1.20417
I0526 02:25:15.746145 20937 solver.cpp:253]     Train net output #0: loss = 1.20417 (* 1 = 1.20417 loss)
I0526 02:25:15.746163 20937 sgd_solver.cpp:106] Iteration 292125, lr = 0.0015
I0526 02:25:25.494505 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_292500.caffemodel
I0526 02:25:25.551627 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_292500.solverstate
I0526 02:25:25.577479 20937 solver.cpp:341] Iteration 292500, Testing net (#0)
I0526 02:26:35.092537 20937 solver.cpp:409]     Test net output #0: accuracy = 0.902026
I0526 02:26:35.092735 20937 solver.cpp:409]     Test net output #1: loss = 0.308328 (* 1 = 0.308328 loss)
I0526 02:26:35.100837 20937 solver.cpp:237] Iteration 292500, loss = 1.27558
I0526 02:26:35.100867 20937 solver.cpp:253]     Train net output #0: loss = 1.27558 (* 1 = 1.27558 loss)
I0526 02:26:35.100883 20937 sgd_solver.cpp:106] Iteration 292500, lr = 0.0015
I0526 02:26:44.975853 20937 solver.cpp:237] Iteration 292875, loss = 0.952601
I0526 02:26:44.975893 20937 solver.cpp:253]     Train net output #0: loss = 0.952601 (* 1 = 0.952601 loss)
I0526 02:26:44.975913 20937 sgd_solver.cpp:106] Iteration 292875, lr = 0.0015
I0526 02:26:54.746381 20937 solver.cpp:237] Iteration 293250, loss = 1.12374
I0526 02:26:54.746438 20937 solver.cpp:253]     Train net output #0: loss = 1.12374 (* 1 = 1.12374 loss)
I0526 02:26:54.746467 20937 sgd_solver.cpp:106] Iteration 293250, lr = 0.0015
I0526 02:27:04.475186 20937 solver.cpp:237] Iteration 293625, loss = 1.23301
I0526 02:27:04.475224 20937 solver.cpp:253]     Train net output #0: loss = 1.23301 (* 1 = 1.23301 loss)
I0526 02:27:04.475247 20937 sgd_solver.cpp:106] Iteration 293625, lr = 0.0015
I0526 02:27:35.084273 20937 solver.cpp:237] Iteration 294000, loss = 1.15206
I0526 02:27:35.084488 20937 solver.cpp:253]     Train net output #0: loss = 1.15206 (* 1 = 1.15206 loss)
I0526 02:27:35.084506 20937 sgd_solver.cpp:106] Iteration 294000, lr = 0.0015
I0526 02:27:44.875008 20937 solver.cpp:237] Iteration 294375, loss = 1.08983
I0526 02:27:44.875063 20937 solver.cpp:253]     Train net output #0: loss = 1.08984 (* 1 = 1.08984 loss)
I0526 02:27:44.875082 20937 sgd_solver.cpp:106] Iteration 294375, lr = 0.0015
I0526 02:27:54.678119 20937 solver.cpp:237] Iteration 294750, loss = 1.42514
I0526 02:27:54.678156 20937 solver.cpp:253]     Train net output #0: loss = 1.42514 (* 1 = 1.42514 loss)
I0526 02:27:54.678176 20937 sgd_solver.cpp:106] Iteration 294750, lr = 0.0015
I0526 02:28:04.482213 20937 solver.cpp:237] Iteration 295125, loss = 1.00244
I0526 02:28:04.482270 20937 solver.cpp:253]     Train net output #0: loss = 1.00244 (* 1 = 1.00244 loss)
I0526 02:28:04.482287 20937 sgd_solver.cpp:106] Iteration 295125, lr = 0.0015
I0526 02:28:14.287372 20937 solver.cpp:237] Iteration 295500, loss = 0.983302
I0526 02:28:14.287550 20937 solver.cpp:253]     Train net output #0: loss = 0.983303 (* 1 = 0.983303 loss)
I0526 02:28:14.287567 20937 sgd_solver.cpp:106] Iteration 295500, lr = 0.0015
I0526 02:28:24.108044 20937 solver.cpp:237] Iteration 295875, loss = 1.21086
I0526 02:28:24.108083 20937 solver.cpp:253]     Train net output #0: loss = 1.21086 (* 1 = 1.21086 loss)
I0526 02:28:24.108103 20937 sgd_solver.cpp:106] Iteration 295875, lr = 0.0015
I0526 02:28:33.900517 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_296250.caffemodel
I0526 02:28:33.957409 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_296250.solverstate
I0526 02:28:54.897002 20937 solver.cpp:237] Iteration 296250, loss = 1.00988
I0526 02:28:54.897209 20937 solver.cpp:253]     Train net output #0: loss = 1.00988 (* 1 = 1.00988 loss)
I0526 02:28:54.897228 20937 sgd_solver.cpp:106] Iteration 296250, lr = 0.0015
I0526 02:29:04.695940 20937 solver.cpp:237] Iteration 296625, loss = 1.13272
I0526 02:29:04.695978 20937 solver.cpp:253]     Train net output #0: loss = 1.13272 (* 1 = 1.13272 loss)
I0526 02:29:04.696004 20937 sgd_solver.cpp:106] Iteration 296625, lr = 0.0015
I0526 02:29:14.504894 20937 solver.cpp:237] Iteration 297000, loss = 1.2391
I0526 02:29:14.504932 20937 solver.cpp:253]     Train net output #0: loss = 1.2391 (* 1 = 1.2391 loss)
I0526 02:29:14.504956 20937 sgd_solver.cpp:106] Iteration 297000, lr = 0.0015
I0526 02:29:24.261195 20937 solver.cpp:237] Iteration 297375, loss = 1.1134
I0526 02:29:24.261255 20937 solver.cpp:253]     Train net output #0: loss = 1.1134 (* 1 = 1.1134 loss)
I0526 02:29:24.261281 20937 sgd_solver.cpp:106] Iteration 297375, lr = 0.0015
I0526 02:29:33.988777 20937 solver.cpp:237] Iteration 297750, loss = 1.19011
I0526 02:29:33.988955 20937 solver.cpp:253]     Train net output #0: loss = 1.19011 (* 1 = 1.19011 loss)
I0526 02:29:33.988971 20937 sgd_solver.cpp:106] Iteration 297750, lr = 0.0015
I0526 02:29:43.724159 20937 solver.cpp:237] Iteration 298125, loss = 0.834334
I0526 02:29:43.724216 20937 solver.cpp:253]     Train net output #0: loss = 0.834335 (* 1 = 0.834335 loss)
I0526 02:29:43.724234 20937 sgd_solver.cpp:106] Iteration 298125, lr = 0.0015
I0526 02:29:53.500864 20937 solver.cpp:237] Iteration 298500, loss = 1.15093
I0526 02:29:53.500902 20937 solver.cpp:253]     Train net output #0: loss = 1.15093 (* 1 = 1.15093 loss)
I0526 02:29:53.500926 20937 sgd_solver.cpp:106] Iteration 298500, lr = 0.0015
I0526 02:30:24.156395 20937 solver.cpp:237] Iteration 298875, loss = 1.04088
I0526 02:30:24.156594 20937 solver.cpp:253]     Train net output #0: loss = 1.04088 (* 1 = 1.04088 loss)
I0526 02:30:24.156611 20937 sgd_solver.cpp:106] Iteration 298875, lr = 0.0015
I0526 02:30:33.926553 20937 solver.cpp:237] Iteration 299250, loss = 1.3265
I0526 02:30:33.926612 20937 solver.cpp:253]     Train net output #0: loss = 1.3265 (* 1 = 1.3265 loss)
I0526 02:30:33.926638 20937 sgd_solver.cpp:106] Iteration 299250, lr = 0.0015
I0526 02:30:43.653327 20937 solver.cpp:237] Iteration 299625, loss = 1.12599
I0526 02:30:43.653365 20937 solver.cpp:253]     Train net output #0: loss = 1.12599 (* 1 = 1.12599 loss)
I0526 02:30:43.653384 20937 sgd_solver.cpp:106] Iteration 299625, lr = 0.0015
I0526 02:30:53.362340 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_300000.caffemodel
I0526 02:30:53.420379 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_300000.solverstate
I0526 02:30:53.448818 20937 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 02:31:42.023303 20937 solver.cpp:409]     Test net output #0: accuracy = 0.902006
I0526 02:31:42.023506 20937 solver.cpp:409]     Test net output #1: loss = 0.309747 (* 1 = 0.309747 loss)
I0526 02:31:42.031638 20937 solver.cpp:237] Iteration 300000, loss = 1.34371
I0526 02:31:42.031672 20937 solver.cpp:253]     Train net output #0: loss = 1.34371 (* 1 = 1.34371 loss)
I0526 02:31:42.031689 20937 sgd_solver.cpp:106] Iteration 300000, lr = 0.0015
I0526 02:31:51.849112 20937 solver.cpp:237] Iteration 300375, loss = 1.30985
I0526 02:31:51.849166 20937 solver.cpp:253]     Train net output #0: loss = 1.30985 (* 1 = 1.30985 loss)
I0526 02:31:51.849195 20937 sgd_solver.cpp:106] Iteration 300375, lr = 0.0015
I0526 02:32:01.663300 20937 solver.cpp:237] Iteration 300750, loss = 1.66558
I0526 02:32:01.663339 20937 solver.cpp:253]     Train net output #0: loss = 1.66558 (* 1 = 1.66558 loss)
I0526 02:32:01.663357 20937 sgd_solver.cpp:106] Iteration 300750, lr = 0.0015
I0526 02:32:11.466028 20937 solver.cpp:237] Iteration 301125, loss = 1.18302
I0526 02:32:11.466065 20937 solver.cpp:253]     Train net output #0: loss = 1.18302 (* 1 = 1.18302 loss)
I0526 02:32:11.466084 20937 sgd_solver.cpp:106] Iteration 301125, lr = 0.0015
I0526 02:32:42.059211 20937 solver.cpp:237] Iteration 301500, loss = 0.828652
I0526 02:32:42.059411 20937 solver.cpp:253]     Train net output #0: loss = 0.828652 (* 1 = 0.828652 loss)
I0526 02:32:42.059428 20937 sgd_solver.cpp:106] Iteration 301500, lr = 0.0015
I0526 02:32:51.783965 20937 solver.cpp:237] Iteration 301875, loss = 1.20725
I0526 02:32:51.784003 20937 solver.cpp:253]     Train net output #0: loss = 1.20725 (* 1 = 1.20725 loss)
I0526 02:32:51.784027 20937 sgd_solver.cpp:106] Iteration 301875, lr = 0.0015
I0526 02:33:01.507468 20937 solver.cpp:237] Iteration 302250, loss = 1.21799
I0526 02:33:01.507505 20937 solver.cpp:253]     Train net output #0: loss = 1.21799 (* 1 = 1.21799 loss)
I0526 02:33:01.507529 20937 sgd_solver.cpp:106] Iteration 302250, lr = 0.0015
I0526 02:33:11.275460 20937 solver.cpp:237] Iteration 302625, loss = 1.13748
I0526 02:33:11.275514 20937 solver.cpp:253]     Train net output #0: loss = 1.13748 (* 1 = 1.13748 loss)
I0526 02:33:11.275532 20937 sgd_solver.cpp:106] Iteration 302625, lr = 0.0015
I0526 02:33:21.047214 20937 solver.cpp:237] Iteration 303000, loss = 1.18618
I0526 02:33:21.047389 20937 solver.cpp:253]     Train net output #0: loss = 1.18618 (* 1 = 1.18618 loss)
I0526 02:33:21.047406 20937 sgd_solver.cpp:106] Iteration 303000, lr = 0.0015
I0526 02:33:30.827299 20937 solver.cpp:237] Iteration 303375, loss = 0.850579
I0526 02:33:30.827358 20937 solver.cpp:253]     Train net output #0: loss = 0.850579 (* 1 = 0.850579 loss)
I0526 02:33:30.827384 20937 sgd_solver.cpp:106] Iteration 303375, lr = 0.0015
I0526 02:33:40.581172 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_303750.caffemodel
I0526 02:33:40.642307 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_303750.solverstate
I0526 02:34:01.494206 20937 solver.cpp:237] Iteration 303750, loss = 1.23088
I0526 02:34:01.494421 20937 solver.cpp:253]     Train net output #0: loss = 1.23088 (* 1 = 1.23088 loss)
I0526 02:34:01.494441 20937 sgd_solver.cpp:106] Iteration 303750, lr = 0.0015
I0526 02:34:11.274839 20937 solver.cpp:237] Iteration 304125, loss = 0.973861
I0526 02:34:11.274879 20937 solver.cpp:253]     Train net output #0: loss = 0.973862 (* 1 = 0.973862 loss)
I0526 02:34:11.274902 20937 sgd_solver.cpp:106] Iteration 304125, lr = 0.0015
I0526 02:34:21.049388 20937 solver.cpp:237] Iteration 304500, loss = 1.25789
I0526 02:34:21.049445 20937 solver.cpp:253]     Train net output #0: loss = 1.25789 (* 1 = 1.25789 loss)
I0526 02:34:21.049473 20937 sgd_solver.cpp:106] Iteration 304500, lr = 0.0015
I0526 02:34:30.824618 20937 solver.cpp:237] Iteration 304875, loss = 1.4021
I0526 02:34:30.824656 20937 solver.cpp:253]     Train net output #0: loss = 1.4021 (* 1 = 1.4021 loss)
I0526 02:34:30.824678 20937 sgd_solver.cpp:106] Iteration 304875, lr = 0.0015
I0526 02:34:40.602974 20937 solver.cpp:237] Iteration 305250, loss = 1.03251
I0526 02:34:40.603153 20937 solver.cpp:253]     Train net output #0: loss = 1.03251 (* 1 = 1.03251 loss)
I0526 02:34:40.603170 20937 sgd_solver.cpp:106] Iteration 305250, lr = 0.0015
I0526 02:34:50.407573 20937 solver.cpp:237] Iteration 305625, loss = 1.25057
I0526 02:34:50.407632 20937 solver.cpp:253]     Train net output #0: loss = 1.25057 (* 1 = 1.25057 loss)
I0526 02:34:50.407660 20937 sgd_solver.cpp:106] Iteration 305625, lr = 0.0015
I0526 02:35:00.216199 20937 solver.cpp:237] Iteration 306000, loss = 1.24272
I0526 02:35:00.216238 20937 solver.cpp:253]     Train net output #0: loss = 1.24272 (* 1 = 1.24272 loss)
I0526 02:35:00.216255 20937 sgd_solver.cpp:106] Iteration 306000, lr = 0.0015
I0526 02:35:30.882272 20937 solver.cpp:237] Iteration 306375, loss = 1.2986
I0526 02:35:30.882470 20937 solver.cpp:253]     Train net output #0: loss = 1.2986 (* 1 = 1.2986 loss)
I0526 02:35:30.882488 20937 sgd_solver.cpp:106] Iteration 306375, lr = 0.0015
I0526 02:35:40.613034 20937 solver.cpp:237] Iteration 306750, loss = 1.40952
I0526 02:35:40.613090 20937 solver.cpp:253]     Train net output #0: loss = 1.40952 (* 1 = 1.40952 loss)
I0526 02:35:40.613107 20937 sgd_solver.cpp:106] Iteration 306750, lr = 0.0015
I0526 02:35:50.329929 20937 solver.cpp:237] Iteration 307125, loss = 1.0558
I0526 02:35:50.329967 20937 solver.cpp:253]     Train net output #0: loss = 1.0558 (* 1 = 1.0558 loss)
I0526 02:35:50.329990 20937 sgd_solver.cpp:106] Iteration 307125, lr = 0.0015
I0526 02:36:00.042182 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_307500.caffemodel
I0526 02:36:00.098286 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_307500.solverstate
I0526 02:36:00.124255 20937 solver.cpp:341] Iteration 307500, Testing net (#0)
I0526 02:37:09.521831 20937 solver.cpp:409]     Test net output #0: accuracy = 0.90162
I0526 02:37:09.522033 20937 solver.cpp:409]     Test net output #1: loss = 0.302531 (* 1 = 0.302531 loss)
I0526 02:37:09.530104 20937 solver.cpp:237] Iteration 307500, loss = 1.01143
I0526 02:37:09.530138 20937 solver.cpp:253]     Train net output #0: loss = 1.01143 (* 1 = 1.01143 loss)
I0526 02:37:09.530154 20937 sgd_solver.cpp:106] Iteration 307500, lr = 0.0015
I0526 02:37:19.274382 20937 solver.cpp:237] Iteration 307875, loss = 1.13077
I0526 02:37:19.274435 20937 solver.cpp:253]     Train net output #0: loss = 1.13078 (* 1 = 1.13078 loss)
I0526 02:37:19.274452 20937 sgd_solver.cpp:106] Iteration 307875, lr = 0.0015
I0526 02:37:29.028342 20937 solver.cpp:237] Iteration 308250, loss = 1.16203
I0526 02:37:29.028379 20937 solver.cpp:253]     Train net output #0: loss = 1.16203 (* 1 = 1.16203 loss)
I0526 02:37:29.028403 20937 sgd_solver.cpp:106] Iteration 308250, lr = 0.0015
I0526 02:37:38.773444 20937 solver.cpp:237] Iteration 308625, loss = 1.42446
I0526 02:37:38.773500 20937 solver.cpp:253]     Train net output #0: loss = 1.42446 (* 1 = 1.42446 loss)
I0526 02:37:38.773517 20937 sgd_solver.cpp:106] Iteration 308625, lr = 0.0015
I0526 02:38:09.353188 20937 solver.cpp:237] Iteration 309000, loss = 0.922697
I0526 02:38:09.353401 20937 solver.cpp:253]     Train net output #0: loss = 0.922697 (* 1 = 0.922697 loss)
I0526 02:38:09.353420 20937 sgd_solver.cpp:106] Iteration 309000, lr = 0.0015
I0526 02:38:19.097087 20937 solver.cpp:237] Iteration 309375, loss = 1.49451
I0526 02:38:19.097126 20937 solver.cpp:253]     Train net output #0: loss = 1.49451 (* 1 = 1.49451 loss)
I0526 02:38:19.097144 20937 sgd_solver.cpp:106] Iteration 309375, lr = 0.0015
I0526 02:38:28.865257 20937 solver.cpp:237] Iteration 309750, loss = 0.934711
I0526 02:38:28.865316 20937 solver.cpp:253]     Train net output #0: loss = 0.934711 (* 1 = 0.934711 loss)
I0526 02:38:28.865344 20937 sgd_solver.cpp:106] Iteration 309750, lr = 0.0015
I0526 02:38:38.766295 20937 solver.cpp:237] Iteration 310125, loss = 1.10199
I0526 02:38:38.766338 20937 solver.cpp:253]     Train net output #0: loss = 1.10199 (* 1 = 1.10199 loss)
I0526 02:38:38.766355 20937 sgd_solver.cpp:106] Iteration 310125, lr = 0.0015
I0526 02:38:48.665597 20937 solver.cpp:237] Iteration 310500, loss = 1.06492
I0526 02:38:48.665789 20937 solver.cpp:253]     Train net output #0: loss = 1.06492 (* 1 = 1.06492 loss)
I0526 02:38:48.665807 20937 sgd_solver.cpp:106] Iteration 310500, lr = 0.0015
I0526 02:38:58.570415 20937 solver.cpp:237] Iteration 310875, loss = 1.19154
I0526 02:38:58.570472 20937 solver.cpp:253]     Train net output #0: loss = 1.19154 (* 1 = 1.19154 loss)
I0526 02:38:58.570499 20937 sgd_solver.cpp:106] Iteration 310875, lr = 0.0015
I0526 02:39:08.449337 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_311250.caffemodel
I0526 02:39:08.505810 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_311250.solverstate
I0526 02:39:29.355489 20937 solver.cpp:237] Iteration 311250, loss = 1.24839
I0526 02:39:29.355697 20937 solver.cpp:253]     Train net output #0: loss = 1.24839 (* 1 = 1.24839 loss)
I0526 02:39:29.355716 20937 sgd_solver.cpp:106] Iteration 311250, lr = 0.0015
I0526 02:39:39.261893 20937 solver.cpp:237] Iteration 311625, loss = 1.15637
I0526 02:39:39.261934 20937 solver.cpp:253]     Train net output #0: loss = 1.15637 (* 1 = 1.15637 loss)
I0526 02:39:39.261953 20937 sgd_solver.cpp:106] Iteration 311625, lr = 0.0015
I0526 02:39:49.171759 20937 solver.cpp:237] Iteration 312000, loss = 1.07994
I0526 02:39:49.171816 20937 solver.cpp:253]     Train net output #0: loss = 1.07994 (* 1 = 1.07994 loss)
I0526 02:39:49.171833 20937 sgd_solver.cpp:106] Iteration 312000, lr = 0.0015
I0526 02:39:59.085362 20937 solver.cpp:237] Iteration 312375, loss = 1.00964
I0526 02:39:59.085398 20937 solver.cpp:253]     Train net output #0: loss = 1.00964 (* 1 = 1.00964 loss)
I0526 02:39:59.085422 20937 sgd_solver.cpp:106] Iteration 312375, lr = 0.0015
I0526 02:40:08.977255 20937 solver.cpp:237] Iteration 312750, loss = 1.23306
I0526 02:40:08.977453 20937 solver.cpp:253]     Train net output #0: loss = 1.23306 (* 1 = 1.23306 loss)
I0526 02:40:08.977473 20937 sgd_solver.cpp:106] Iteration 312750, lr = 0.0015
I0526 02:40:18.794565 20937 solver.cpp:237] Iteration 313125, loss = 0.836741
I0526 02:40:18.794605 20937 solver.cpp:253]     Train net output #0: loss = 0.836741 (* 1 = 0.836741 loss)
I0526 02:40:18.794623 20937 sgd_solver.cpp:106] Iteration 313125, lr = 0.0015
I0526 02:40:28.611868 20937 solver.cpp:237] Iteration 313500, loss = 0.834551
I0526 02:40:28.611908 20937 solver.cpp:253]     Train net output #0: loss = 0.834551 (* 1 = 0.834551 loss)
I0526 02:40:28.611925 20937 sgd_solver.cpp:106] Iteration 313500, lr = 0.0015
I0526 02:40:59.244999 20937 solver.cpp:237] Iteration 313875, loss = 0.994552
I0526 02:40:59.245210 20937 solver.cpp:253]     Train net output #0: loss = 0.994552 (* 1 = 0.994552 loss)
I0526 02:40:59.245228 20937 sgd_solver.cpp:106] Iteration 313875, lr = 0.0015
I0526 02:41:08.953073 20937 solver.cpp:237] Iteration 314250, loss = 1.11671
I0526 02:41:08.953112 20937 solver.cpp:253]     Train net output #0: loss = 1.11671 (* 1 = 1.11671 loss)
I0526 02:41:08.953130 20937 sgd_solver.cpp:106] Iteration 314250, lr = 0.0015
I0526 02:41:18.673836 20937 solver.cpp:237] Iteration 314625, loss = 1.11713
I0526 02:41:18.673874 20937 solver.cpp:253]     Train net output #0: loss = 1.11713 (* 1 = 1.11713 loss)
I0526 02:41:18.673893 20937 sgd_solver.cpp:106] Iteration 314625, lr = 0.0015
I0526 02:41:28.363595 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_315000.caffemodel
I0526 02:41:28.419728 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_315000.solverstate
I0526 02:41:28.445647 20937 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 02:42:16.677790 20937 solver.cpp:409]     Test net output #0: accuracy = 0.902107
I0526 02:42:16.677994 20937 solver.cpp:409]     Test net output #1: loss = 0.318455 (* 1 = 0.318455 loss)
I0526 02:42:16.686028 20937 solver.cpp:237] Iteration 315000, loss = 1.1824
I0526 02:42:16.686058 20937 solver.cpp:253]     Train net output #0: loss = 1.1824 (* 1 = 1.1824 loss)
I0526 02:42:16.686075 20937 sgd_solver.cpp:106] Iteration 315000, lr = 0.0015
I0526 02:42:26.443783 20937 solver.cpp:237] Iteration 315375, loss = 1.12778
I0526 02:42:26.443822 20937 solver.cpp:253]     Train net output #0: loss = 1.12778 (* 1 = 1.12778 loss)
I0526 02:42:26.443840 20937 sgd_solver.cpp:106] Iteration 315375, lr = 0.0015
I0526 02:42:36.198825 20937 solver.cpp:237] Iteration 315750, loss = 1.22427
I0526 02:42:36.198863 20937 solver.cpp:253]     Train net output #0: loss = 1.22427 (* 1 = 1.22427 loss)
I0526 02:42:36.198885 20937 sgd_solver.cpp:106] Iteration 315750, lr = 0.0015
I0526 02:42:45.958972 20937 solver.cpp:237] Iteration 316125, loss = 1.15049
I0526 02:42:45.959022 20937 solver.cpp:253]     Train net output #0: loss = 1.15049 (* 1 = 1.15049 loss)
I0526 02:42:45.959038 20937 sgd_solver.cpp:106] Iteration 316125, lr = 0.0015
I0526 02:43:16.590523 20937 solver.cpp:237] Iteration 316500, loss = 0.937479
I0526 02:43:16.590728 20937 solver.cpp:253]     Train net output #0: loss = 0.93748 (* 1 = 0.93748 loss)
I0526 02:43:16.590745 20937 sgd_solver.cpp:106] Iteration 316500, lr = 0.0015
I0526 02:43:26.357956 20937 solver.cpp:237] Iteration 316875, loss = 1.13919
I0526 02:43:26.357993 20937 solver.cpp:253]     Train net output #0: loss = 1.13919 (* 1 = 1.13919 loss)
I0526 02:43:26.358017 20937 sgd_solver.cpp:106] Iteration 316875, lr = 0.0015
I0526 02:43:36.300115 20937 solver.cpp:237] Iteration 317250, loss = 1.18988
I0526 02:43:36.300173 20937 solver.cpp:253]     Train net output #0: loss = 1.18988 (* 1 = 1.18988 loss)
I0526 02:43:36.300197 20937 sgd_solver.cpp:106] Iteration 317250, lr = 0.0015
I0526 02:43:46.262306 20937 solver.cpp:237] Iteration 317625, loss = 1.35689
I0526 02:43:46.262344 20937 solver.cpp:253]     Train net output #0: loss = 1.35689 (* 1 = 1.35689 loss)
I0526 02:43:46.262367 20937 sgd_solver.cpp:106] Iteration 317625, lr = 0.0015
I0526 02:43:56.216850 20937 solver.cpp:237] Iteration 318000, loss = 1.21832
I0526 02:43:56.217051 20937 solver.cpp:253]     Train net output #0: loss = 1.21832 (* 1 = 1.21832 loss)
I0526 02:43:56.217069 20937 sgd_solver.cpp:106] Iteration 318000, lr = 0.0015
I0526 02:44:06.176326 20937 solver.cpp:237] Iteration 318375, loss = 1.38057
I0526 02:44:06.176368 20937 solver.cpp:253]     Train net output #0: loss = 1.38057 (* 1 = 1.38057 loss)
I0526 02:44:06.176388 20937 sgd_solver.cpp:106] Iteration 318375, lr = 0.0015
I0526 02:44:16.105140 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_318750.caffemodel
I0526 02:44:16.162814 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_318750.solverstate
I0526 02:44:37.043470 20937 solver.cpp:237] Iteration 318750, loss = 1.08238
I0526 02:44:37.043695 20937 solver.cpp:253]     Train net output #0: loss = 1.08238 (* 1 = 1.08238 loss)
I0526 02:44:37.043714 20937 sgd_solver.cpp:106] Iteration 318750, lr = 0.0015
I0526 02:44:46.934556 20937 solver.cpp:237] Iteration 319125, loss = 0.936111
I0526 02:44:46.934617 20937 solver.cpp:253]     Train net output #0: loss = 0.936111 (* 1 = 0.936111 loss)
I0526 02:44:46.934643 20937 sgd_solver.cpp:106] Iteration 319125, lr = 0.0015
I0526 02:44:56.732298 20937 solver.cpp:237] Iteration 319500, loss = 0.873709
I0526 02:44:56.732337 20937 solver.cpp:253]     Train net output #0: loss = 0.87371 (* 1 = 0.87371 loss)
I0526 02:44:56.732367 20937 sgd_solver.cpp:106] Iteration 319500, lr = 0.0015
I0526 02:45:06.532909 20937 solver.cpp:237] Iteration 319875, loss = 1.3379
I0526 02:45:06.532948 20937 solver.cpp:253]     Train net output #0: loss = 1.3379 (* 1 = 1.3379 loss)
I0526 02:45:06.532965 20937 sgd_solver.cpp:106] Iteration 319875, lr = 0.0015
I0526 02:45:16.334867 20937 solver.cpp:237] Iteration 320250, loss = 0.97266
I0526 02:45:16.335070 20937 solver.cpp:253]     Train net output #0: loss = 0.97266 (* 1 = 0.97266 loss)
I0526 02:45:16.335088 20937 sgd_solver.cpp:106] Iteration 320250, lr = 0.0015
I0526 02:45:26.126004 20937 solver.cpp:237] Iteration 320625, loss = 1.17482
I0526 02:45:26.126044 20937 solver.cpp:253]     Train net output #0: loss = 1.17482 (* 1 = 1.17482 loss)
I0526 02:45:26.126060 20937 sgd_solver.cpp:106] Iteration 320625, lr = 0.0015
I0526 02:45:35.923967 20937 solver.cpp:237] Iteration 321000, loss = 1.36985
I0526 02:45:35.924023 20937 solver.cpp:253]     Train net output #0: loss = 1.36985 (* 1 = 1.36985 loss)
I0526 02:45:35.924041 20937 sgd_solver.cpp:106] Iteration 321000, lr = 0.0015
I0526 02:46:06.582888 20937 solver.cpp:237] Iteration 321375, loss = 0.797883
I0526 02:46:06.583093 20937 solver.cpp:253]     Train net output #0: loss = 0.797883 (* 1 = 0.797883 loss)
I0526 02:46:06.583112 20937 sgd_solver.cpp:106] Iteration 321375, lr = 0.0015
I0526 02:46:16.379932 20937 solver.cpp:237] Iteration 321750, loss = 1.00527
I0526 02:46:16.379971 20937 solver.cpp:253]     Train net output #0: loss = 1.00527 (* 1 = 1.00527 loss)
I0526 02:46:16.379989 20937 sgd_solver.cpp:106] Iteration 321750, lr = 0.0015
I0526 02:46:26.176237 20937 solver.cpp:237] Iteration 322125, loss = 1.48069
I0526 02:46:26.176295 20937 solver.cpp:253]     Train net output #0: loss = 1.48069 (* 1 = 1.48069 loss)
I0526 02:46:26.176321 20937 sgd_solver.cpp:106] Iteration 322125, lr = 0.0015
I0526 02:46:35.949481 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_322500.caffemodel
I0526 02:46:36.007486 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_322500.solverstate
I0526 02:46:36.034818 20937 solver.cpp:341] Iteration 322500, Testing net (#0)
I0526 02:47:45.442859 20937 solver.cpp:409]     Test net output #0: accuracy = 0.90256
I0526 02:47:45.443064 20937 solver.cpp:409]     Test net output #1: loss = 0.292113 (* 1 = 0.292113 loss)
I0526 02:47:45.451182 20937 solver.cpp:237] Iteration 322500, loss = 0.876199
I0526 02:47:45.451212 20937 solver.cpp:253]     Train net output #0: loss = 0.876199 (* 1 = 0.876199 loss)
I0526 02:47:45.451230 20937 sgd_solver.cpp:106] Iteration 322500, lr = 0.0015
I0526 02:47:55.164170 20937 solver.cpp:237] Iteration 322875, loss = 1.36863
I0526 02:47:55.164207 20937 solver.cpp:253]     Train net output #0: loss = 1.36863 (* 1 = 1.36863 loss)
I0526 02:47:55.164227 20937 sgd_solver.cpp:106] Iteration 322875, lr = 0.0015
I0526 02:48:04.931823 20937 solver.cpp:237] Iteration 323250, loss = 1.18843
I0526 02:48:04.931879 20937 solver.cpp:253]     Train net output #0: loss = 1.18843 (* 1 = 1.18843 loss)
I0526 02:48:04.931907 20937 sgd_solver.cpp:106] Iteration 323250, lr = 0.0015
I0526 02:48:14.842134 20937 solver.cpp:237] Iteration 323625, loss = 0.968069
I0526 02:48:14.842172 20937 solver.cpp:253]     Train net output #0: loss = 0.968069 (* 1 = 0.968069 loss)
I0526 02:48:14.842196 20937 sgd_solver.cpp:106] Iteration 323625, lr = 0.0015
I0526 02:48:45.639848 20937 solver.cpp:237] Iteration 324000, loss = 1.0981
I0526 02:48:45.640056 20937 solver.cpp:253]     Train net output #0: loss = 1.0981 (* 1 = 1.0981 loss)
I0526 02:48:45.640074 20937 sgd_solver.cpp:106] Iteration 324000, lr = 0.0015
I0526 02:48:55.551422 20937 solver.cpp:237] Iteration 324375, loss = 1.00448
I0526 02:48:55.551477 20937 solver.cpp:253]     Train net output #0: loss = 1.00448 (* 1 = 1.00448 loss)
I0526 02:48:55.551496 20937 sgd_solver.cpp:106] Iteration 324375, lr = 0.0015
I0526 02:49:05.452334 20937 solver.cpp:237] Iteration 324750, loss = 1.28596
I0526 02:49:05.452376 20937 solver.cpp:253]     Train net output #0: loss = 1.28596 (* 1 = 1.28596 loss)
I0526 02:49:05.452395 20937 sgd_solver.cpp:106] Iteration 324750, lr = 0.0015
I0526 02:49:15.356180 20937 solver.cpp:237] Iteration 325125, loss = 1.10068
I0526 02:49:15.356218 20937 solver.cpp:253]     Train net output #0: loss = 1.10068 (* 1 = 1.10068 loss)
I0526 02:49:15.356236 20937 sgd_solver.cpp:106] Iteration 325125, lr = 0.0015
I0526 02:49:25.181323 20937 solver.cpp:237] Iteration 325500, loss = 1.28861
I0526 02:49:25.181532 20937 solver.cpp:253]     Train net output #0: loss = 1.28861 (* 1 = 1.28861 loss)
I0526 02:49:25.181550 20937 sgd_solver.cpp:106] Iteration 325500, lr = 0.0015
I0526 02:49:34.975306 20937 solver.cpp:237] Iteration 325875, loss = 1.00697
I0526 02:49:34.975343 20937 solver.cpp:253]     Train net output #0: loss = 1.00697 (* 1 = 1.00697 loss)
I0526 02:49:34.975368 20937 sgd_solver.cpp:106] Iteration 325875, lr = 0.0015
I0526 02:49:44.769259 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_326250.caffemodel
I0526 02:49:44.825912 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_326250.solverstate
I0526 02:50:05.706104 20937 solver.cpp:237] Iteration 326250, loss = 1.157
I0526 02:50:05.706318 20937 solver.cpp:253]     Train net output #0: loss = 1.157 (* 1 = 1.157 loss)
I0526 02:50:05.706336 20937 sgd_solver.cpp:106] Iteration 326250, lr = 0.0015
I0526 02:50:15.585494 20937 solver.cpp:237] Iteration 326625, loss = 1.18352
I0526 02:50:15.585551 20937 solver.cpp:253]     Train net output #0: loss = 1.18352 (* 1 = 1.18352 loss)
I0526 02:50:15.585577 20937 sgd_solver.cpp:106] Iteration 326625, lr = 0.0015
I0526 02:50:25.473300 20937 solver.cpp:237] Iteration 327000, loss = 0.883792
I0526 02:50:25.473340 20937 solver.cpp:253]     Train net output #0: loss = 0.883792 (* 1 = 0.883792 loss)
I0526 02:50:25.473363 20937 sgd_solver.cpp:106] Iteration 327000, lr = 0.0015
I0526 02:50:35.368880 20937 solver.cpp:237] Iteration 327375, loss = 1.21372
I0526 02:50:35.368934 20937 solver.cpp:253]     Train net output #0: loss = 1.21372 (* 1 = 1.21372 loss)
I0526 02:50:35.368952 20937 sgd_solver.cpp:106] Iteration 327375, lr = 0.0015
I0526 02:50:45.264732 20937 solver.cpp:237] Iteration 327750, loss = 0.946055
I0526 02:50:45.264917 20937 solver.cpp:253]     Train net output #0: loss = 0.946055 (* 1 = 0.946055 loss)
I0526 02:50:45.264935 20937 sgd_solver.cpp:106] Iteration 327750, lr = 0.0015
I0526 02:50:55.157817 20937 solver.cpp:237] Iteration 328125, loss = 1.28252
I0526 02:50:55.157855 20937 solver.cpp:253]     Train net output #0: loss = 1.28252 (* 1 = 1.28252 loss)
I0526 02:50:55.157873 20937 sgd_solver.cpp:106] Iteration 328125, lr = 0.0015
I0526 02:51:04.935581 20937 solver.cpp:237] Iteration 328500, loss = 1.14605
I0526 02:51:04.935636 20937 solver.cpp:253]     Train net output #0: loss = 1.14605 (* 1 = 1.14605 loss)
I0526 02:51:04.935663 20937 sgd_solver.cpp:106] Iteration 328500, lr = 0.0015
I0526 02:51:35.532169 20937 solver.cpp:237] Iteration 328875, loss = 1.21419
I0526 02:51:35.532392 20937 solver.cpp:253]     Train net output #0: loss = 1.21419 (* 1 = 1.21419 loss)
I0526 02:51:35.532408 20937 sgd_solver.cpp:106] Iteration 328875, lr = 0.0015
I0526 02:51:45.269665 20937 solver.cpp:237] Iteration 329250, loss = 1.00709
I0526 02:51:45.269703 20937 solver.cpp:253]     Train net output #0: loss = 1.00709 (* 1 = 1.00709 loss)
I0526 02:51:45.269726 20937 sgd_solver.cpp:106] Iteration 329250, lr = 0.0015
I0526 02:51:55.110754 20937 solver.cpp:237] Iteration 329625, loss = 1.24286
I0526 02:51:55.110810 20937 solver.cpp:253]     Train net output #0: loss = 1.24286 (* 1 = 1.24286 loss)
I0526 02:51:55.110837 20937 sgd_solver.cpp:106] Iteration 329625, lr = 0.0015
I0526 02:52:04.961673 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_330000.caffemodel
I0526 02:52:05.019093 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_330000.solverstate
I0526 02:52:05.045068 20937 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 02:52:53.620149 20937 solver.cpp:409]     Test net output #0: accuracy = 0.903285
I0526 02:52:53.620358 20937 solver.cpp:409]     Test net output #1: loss = 0.309233 (* 1 = 0.309233 loss)
I0526 02:52:53.628430 20937 solver.cpp:237] Iteration 330000, loss = 1.09781
I0526 02:52:53.628463 20937 solver.cpp:253]     Train net output #0: loss = 1.09781 (* 1 = 1.09781 loss)
I0526 02:52:53.628479 20937 sgd_solver.cpp:106] Iteration 330000, lr = 0.0015
I0526 02:53:03.415254 20937 solver.cpp:237] Iteration 330375, loss = 1.08901
I0526 02:53:03.415312 20937 solver.cpp:253]     Train net output #0: loss = 1.08901 (* 1 = 1.08901 loss)
I0526 02:53:03.415328 20937 sgd_solver.cpp:106] Iteration 330375, lr = 0.0015
I0526 02:53:13.209666 20937 solver.cpp:237] Iteration 330750, loss = 1.15121
I0526 02:53:13.209707 20937 solver.cpp:253]     Train net output #0: loss = 1.15121 (* 1 = 1.15121 loss)
I0526 02:53:13.209723 20937 sgd_solver.cpp:106] Iteration 330750, lr = 0.0015
I0526 02:53:23.005959 20937 solver.cpp:237] Iteration 331125, loss = 1.2115
I0526 02:53:23.005997 20937 solver.cpp:253]     Train net output #0: loss = 1.2115 (* 1 = 1.2115 loss)
I0526 02:53:23.006014 20937 sgd_solver.cpp:106] Iteration 331125, lr = 0.0015
I0526 02:53:53.637923 20937 solver.cpp:237] Iteration 331500, loss = 0.983785
I0526 02:53:53.638128 20937 solver.cpp:253]     Train net output #0: loss = 0.983786 (* 1 = 0.983786 loss)
I0526 02:53:53.638147 20937 sgd_solver.cpp:106] Iteration 331500, lr = 0.0015
I0526 02:54:03.487929 20937 solver.cpp:237] Iteration 331875, loss = 0.893369
I0526 02:54:03.487967 20937 solver.cpp:253]     Train net output #0: loss = 0.89337 (* 1 = 0.89337 loss)
I0526 02:54:03.487987 20937 sgd_solver.cpp:106] Iteration 331875, lr = 0.0015
I0526 02:54:13.335855 20937 solver.cpp:237] Iteration 332250, loss = 0.968542
I0526 02:54:13.335892 20937 solver.cpp:253]     Train net output #0: loss = 0.968543 (* 1 = 0.968543 loss)
I0526 02:54:13.335911 20937 sgd_solver.cpp:106] Iteration 332250, lr = 0.0015
I0526 02:54:23.214697 20937 solver.cpp:237] Iteration 332625, loss = 1.14215
I0526 02:54:23.214756 20937 solver.cpp:253]     Train net output #0: loss = 1.14215 (* 1 = 1.14215 loss)
I0526 02:54:23.214781 20937 sgd_solver.cpp:106] Iteration 332625, lr = 0.0015
I0526 02:54:33.127604 20937 solver.cpp:237] Iteration 333000, loss = 1.2181
I0526 02:54:33.127795 20937 solver.cpp:253]     Train net output #0: loss = 1.2181 (* 1 = 1.2181 loss)
I0526 02:54:33.127812 20937 sgd_solver.cpp:106] Iteration 333000, lr = 0.0015
I0526 02:54:43.031093 20937 solver.cpp:237] Iteration 333375, loss = 0.907085
I0526 02:54:43.031152 20937 solver.cpp:253]     Train net output #0: loss = 0.907086 (* 1 = 0.907086 loss)
I0526 02:54:43.031177 20937 sgd_solver.cpp:106] Iteration 333375, lr = 0.0015
I0526 02:54:52.909806 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_333750.caffemodel
I0526 02:54:52.965991 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_333750.solverstate
I0526 02:55:13.861804 20937 solver.cpp:237] Iteration 333750, loss = 1.25714
I0526 02:55:13.862017 20937 solver.cpp:253]     Train net output #0: loss = 1.25714 (* 1 = 1.25714 loss)
I0526 02:55:13.862035 20937 sgd_solver.cpp:106] Iteration 333750, lr = 0.0015
I0526 02:55:23.761988 20937 solver.cpp:237] Iteration 334125, loss = 1.10749
I0526 02:55:23.762027 20937 solver.cpp:253]     Train net output #0: loss = 1.10749 (* 1 = 1.10749 loss)
I0526 02:55:23.762051 20937 sgd_solver.cpp:106] Iteration 334125, lr = 0.0015
I0526 02:55:33.667314 20937 solver.cpp:237] Iteration 334500, loss = 1.29633
I0526 02:55:33.667367 20937 solver.cpp:253]     Train net output #0: loss = 1.29634 (* 1 = 1.29634 loss)
I0526 02:55:33.667387 20937 sgd_solver.cpp:106] Iteration 334500, lr = 0.0015
I0526 02:55:43.597985 20937 solver.cpp:237] Iteration 334875, loss = 1.00198
I0526 02:55:43.598024 20937 solver.cpp:253]     Train net output #0: loss = 1.00198 (* 1 = 1.00198 loss)
I0526 02:55:43.598042 20937 sgd_solver.cpp:106] Iteration 334875, lr = 0.0015
I0526 02:55:53.557049 20937 solver.cpp:237] Iteration 335250, loss = 1.2449
I0526 02:55:53.557231 20937 solver.cpp:253]     Train net output #0: loss = 1.2449 (* 1 = 1.2449 loss)
I0526 02:55:53.557248 20937 sgd_solver.cpp:106] Iteration 335250, lr = 0.0015
I0526 02:56:03.399266 20937 solver.cpp:237] Iteration 335625, loss = 1.13428
I0526 02:56:03.399324 20937 solver.cpp:253]     Train net output #0: loss = 1.13428 (* 1 = 1.13428 loss)
I0526 02:56:03.399348 20937 sgd_solver.cpp:106] Iteration 335625, lr = 0.0015
I0526 02:56:13.160308 20937 solver.cpp:237] Iteration 336000, loss = 1.17497
I0526 02:56:13.160351 20937 solver.cpp:253]     Train net output #0: loss = 1.17497 (* 1 = 1.17497 loss)
I0526 02:56:13.160367 20937 sgd_solver.cpp:106] Iteration 336000, lr = 0.0015
I0526 02:56:43.802482 20937 solver.cpp:237] Iteration 336375, loss = 0.903706
I0526 02:56:43.802693 20937 solver.cpp:253]     Train net output #0: loss = 0.903707 (* 1 = 0.903707 loss)
I0526 02:56:43.802711 20937 sgd_solver.cpp:106] Iteration 336375, lr = 0.0015
I0526 02:56:53.594070 20937 solver.cpp:237] Iteration 336750, loss = 1.14766
I0526 02:56:53.594130 20937 solver.cpp:253]     Train net output #0: loss = 1.14767 (* 1 = 1.14767 loss)
I0526 02:56:53.594147 20937 sgd_solver.cpp:106] Iteration 336750, lr = 0.0015
I0526 02:57:03.400946 20937 solver.cpp:237] Iteration 337125, loss = 0.963629
I0526 02:57:03.400985 20937 solver.cpp:253]     Train net output #0: loss = 0.96363 (* 1 = 0.96363 loss)
I0526 02:57:03.401002 20937 sgd_solver.cpp:106] Iteration 337125, lr = 0.0015
I0526 02:57:13.185297 20937 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_337500.caffemodel
I0526 02:57:13.247150 20937 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0015_2016-05-20T15.49.01.878706_iter_337500.solverstate
I0526 02:57:13.274950 20937 solver.cpp:341] Iteration 337500, Testing net (#0)
I0526 02:58:22.752974 20937 solver.cpp:409]     Test net output #0: accuracy = 0.900625
I0526 02:58:22.753188 20937 solver.cpp:409]     Test net output #1: loss = 0.310854 (* 1 = 0.310854 loss)
I0526 02:58:22.761348 20937 solver.cpp:237] Iteration 337500, loss = 1.24846
I0526 02:58:22.761378 20937 solver.cpp:253]     Train net output #0: loss = 1.24846 (* 1 = 1.24846 loss)
I0526 02:58:22.761395 20937 sgd_solver.cpp:106] Iteration 337500, lr = 0.0015
aprun: Apid 11266375: Caught signal Terminated, sending to application
*** Aborted at 1464245904 (unix time) try "date -d @1464245904" if you are using GNU date ***
aprun: Apid 11266375: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11266375: Caught signal Terminated, sending to application
*** SIGTERM (@0x51c6) received by PID 20937 (TID 0x2aaac746f900) from PID 20934; stack trace: ***
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
=>> PBS: job killed: walltime 7237 exceeded limit 7200
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11266375: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11266375: Caught signal Terminated, sending to application
aprun: Apid 11266375: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02136] [c4-3c1s3n0] [Thu May 26 02:58:26 2016] PE RANK 0 exit signal Terminated
Application 11266375 exit codes: 143
Application 11266375 resources: utime ~6255s, stime ~969s, Rss ~5331980, inblocks ~15425368, outblocks ~696239
