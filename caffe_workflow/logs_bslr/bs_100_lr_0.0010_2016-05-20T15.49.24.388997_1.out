2810616
I0525 14:52:34.863014 23215 caffe.cpp:184] Using GPUs 0
I0525 14:52:35.283699 23215 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1500
test_interval: 3000
base_lr: 0.001
display: 150
max_iter: 150000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997.prototxt"
I0525 14:52:35.285884 23215 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997.prototxt
I0525 14:52:35.300251 23215 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 14:52:35.300309 23215 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 14:52:35.300653 23215 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 14:52:35.300832 23215 layer_factory.hpp:77] Creating layer data_hdf5
I0525 14:52:35.300855 23215 net.cpp:106] Creating Layer data_hdf5
I0525 14:52:35.300870 23215 net.cpp:411] data_hdf5 -> data
I0525 14:52:35.300905 23215 net.cpp:411] data_hdf5 -> label
I0525 14:52:35.300937 23215 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 14:52:35.315929 23215 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 14:52:35.328811 23215 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 14:52:56.899451 23215 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 14:52:56.904564 23215 net.cpp:150] Setting up data_hdf5
I0525 14:52:56.904604 23215 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 14:52:56.904618 23215 net.cpp:157] Top shape: 100 (100)
I0525 14:52:56.904630 23215 net.cpp:165] Memory required for data: 2540400
I0525 14:52:56.904644 23215 layer_factory.hpp:77] Creating layer conv1
I0525 14:52:56.904677 23215 net.cpp:106] Creating Layer conv1
I0525 14:52:56.904688 23215 net.cpp:454] conv1 <- data
I0525 14:52:56.904711 23215 net.cpp:411] conv1 -> conv1
I0525 14:52:58.536842 23215 net.cpp:150] Setting up conv1
I0525 14:52:58.536886 23215 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:52:58.536897 23215 net.cpp:165] Memory required for data: 30188400
I0525 14:52:58.536928 23215 layer_factory.hpp:77] Creating layer relu1
I0525 14:52:58.536949 23215 net.cpp:106] Creating Layer relu1
I0525 14:52:58.536960 23215 net.cpp:454] relu1 <- conv1
I0525 14:52:58.536973 23215 net.cpp:397] relu1 -> conv1 (in-place)
I0525 14:52:58.537504 23215 net.cpp:150] Setting up relu1
I0525 14:52:58.537521 23215 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:52:58.537531 23215 net.cpp:165] Memory required for data: 57836400
I0525 14:52:58.537541 23215 layer_factory.hpp:77] Creating layer pool1
I0525 14:52:58.537559 23215 net.cpp:106] Creating Layer pool1
I0525 14:52:58.537569 23215 net.cpp:454] pool1 <- conv1
I0525 14:52:58.537582 23215 net.cpp:411] pool1 -> pool1
I0525 14:52:58.537662 23215 net.cpp:150] Setting up pool1
I0525 14:52:58.537677 23215 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 14:52:58.537686 23215 net.cpp:165] Memory required for data: 71660400
I0525 14:52:58.537698 23215 layer_factory.hpp:77] Creating layer conv2
I0525 14:52:58.537719 23215 net.cpp:106] Creating Layer conv2
I0525 14:52:58.537730 23215 net.cpp:454] conv2 <- pool1
I0525 14:52:58.537744 23215 net.cpp:411] conv2 -> conv2
I0525 14:52:58.540472 23215 net.cpp:150] Setting up conv2
I0525 14:52:58.540500 23215 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:52:58.540511 23215 net.cpp:165] Memory required for data: 91532400
I0525 14:52:58.540529 23215 layer_factory.hpp:77] Creating layer relu2
I0525 14:52:58.540544 23215 net.cpp:106] Creating Layer relu2
I0525 14:52:58.540555 23215 net.cpp:454] relu2 <- conv2
I0525 14:52:58.540567 23215 net.cpp:397] relu2 -> conv2 (in-place)
I0525 14:52:58.540896 23215 net.cpp:150] Setting up relu2
I0525 14:52:58.540911 23215 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:52:58.540921 23215 net.cpp:165] Memory required for data: 111404400
I0525 14:52:58.540932 23215 layer_factory.hpp:77] Creating layer pool2
I0525 14:52:58.540944 23215 net.cpp:106] Creating Layer pool2
I0525 14:52:58.540954 23215 net.cpp:454] pool2 <- conv2
I0525 14:52:58.540966 23215 net.cpp:411] pool2 -> pool2
I0525 14:52:58.541059 23215 net.cpp:150] Setting up pool2
I0525 14:52:58.541071 23215 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 14:52:58.541085 23215 net.cpp:165] Memory required for data: 121340400
I0525 14:52:58.541095 23215 layer_factory.hpp:77] Creating layer conv3
I0525 14:52:58.541112 23215 net.cpp:106] Creating Layer conv3
I0525 14:52:58.541122 23215 net.cpp:454] conv3 <- pool2
I0525 14:52:58.541136 23215 net.cpp:411] conv3 -> conv3
I0525 14:52:58.543056 23215 net.cpp:150] Setting up conv3
I0525 14:52:58.543073 23215 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:52:58.543086 23215 net.cpp:165] Memory required for data: 132182000
I0525 14:52:58.543103 23215 layer_factory.hpp:77] Creating layer relu3
I0525 14:52:58.543119 23215 net.cpp:106] Creating Layer relu3
I0525 14:52:58.543129 23215 net.cpp:454] relu3 <- conv3
I0525 14:52:58.543143 23215 net.cpp:397] relu3 -> conv3 (in-place)
I0525 14:52:58.543613 23215 net.cpp:150] Setting up relu3
I0525 14:52:58.543630 23215 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:52:58.543640 23215 net.cpp:165] Memory required for data: 143023600
I0525 14:52:58.543650 23215 layer_factory.hpp:77] Creating layer pool3
I0525 14:52:58.543663 23215 net.cpp:106] Creating Layer pool3
I0525 14:52:58.543673 23215 net.cpp:454] pool3 <- conv3
I0525 14:52:58.543686 23215 net.cpp:411] pool3 -> pool3
I0525 14:52:58.543753 23215 net.cpp:150] Setting up pool3
I0525 14:52:58.543766 23215 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 14:52:58.543776 23215 net.cpp:165] Memory required for data: 148444400
I0525 14:52:58.543784 23215 layer_factory.hpp:77] Creating layer conv4
I0525 14:52:58.543802 23215 net.cpp:106] Creating Layer conv4
I0525 14:52:58.543812 23215 net.cpp:454] conv4 <- pool3
I0525 14:52:58.543823 23215 net.cpp:411] conv4 -> conv4
I0525 14:52:58.546782 23215 net.cpp:150] Setting up conv4
I0525 14:52:58.546809 23215 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:52:58.546820 23215 net.cpp:165] Memory required for data: 152073200
I0525 14:52:58.546838 23215 layer_factory.hpp:77] Creating layer relu4
I0525 14:52:58.546851 23215 net.cpp:106] Creating Layer relu4
I0525 14:52:58.546862 23215 net.cpp:454] relu4 <- conv4
I0525 14:52:58.546875 23215 net.cpp:397] relu4 -> conv4 (in-place)
I0525 14:52:58.547338 23215 net.cpp:150] Setting up relu4
I0525 14:52:58.547354 23215 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:52:58.547364 23215 net.cpp:165] Memory required for data: 155702000
I0525 14:52:58.547374 23215 layer_factory.hpp:77] Creating layer pool4
I0525 14:52:58.547387 23215 net.cpp:106] Creating Layer pool4
I0525 14:52:58.547397 23215 net.cpp:454] pool4 <- conv4
I0525 14:52:58.547410 23215 net.cpp:411] pool4 -> pool4
I0525 14:52:58.547479 23215 net.cpp:150] Setting up pool4
I0525 14:52:58.547492 23215 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 14:52:58.547502 23215 net.cpp:165] Memory required for data: 157516400
I0525 14:52:58.547513 23215 layer_factory.hpp:77] Creating layer ip1
I0525 14:52:58.547533 23215 net.cpp:106] Creating Layer ip1
I0525 14:52:58.547543 23215 net.cpp:454] ip1 <- pool4
I0525 14:52:58.547554 23215 net.cpp:411] ip1 -> ip1
I0525 14:52:58.563115 23215 net.cpp:150] Setting up ip1
I0525 14:52:58.563138 23215 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:52:58.563153 23215 net.cpp:165] Memory required for data: 157594800
I0525 14:52:58.563179 23215 layer_factory.hpp:77] Creating layer relu5
I0525 14:52:58.563194 23215 net.cpp:106] Creating Layer relu5
I0525 14:52:58.563205 23215 net.cpp:454] relu5 <- ip1
I0525 14:52:58.563218 23215 net.cpp:397] relu5 -> ip1 (in-place)
I0525 14:52:58.563562 23215 net.cpp:150] Setting up relu5
I0525 14:52:58.563576 23215 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:52:58.563586 23215 net.cpp:165] Memory required for data: 157673200
I0525 14:52:58.563596 23215 layer_factory.hpp:77] Creating layer drop1
I0525 14:52:58.563616 23215 net.cpp:106] Creating Layer drop1
I0525 14:52:58.563627 23215 net.cpp:454] drop1 <- ip1
I0525 14:52:58.563639 23215 net.cpp:397] drop1 -> ip1 (in-place)
I0525 14:52:58.563699 23215 net.cpp:150] Setting up drop1
I0525 14:52:58.563711 23215 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:52:58.563721 23215 net.cpp:165] Memory required for data: 157751600
I0525 14:52:58.563731 23215 layer_factory.hpp:77] Creating layer ip2
I0525 14:52:58.563750 23215 net.cpp:106] Creating Layer ip2
I0525 14:52:58.563760 23215 net.cpp:454] ip2 <- ip1
I0525 14:52:58.563773 23215 net.cpp:411] ip2 -> ip2
I0525 14:52:58.564240 23215 net.cpp:150] Setting up ip2
I0525 14:52:58.564254 23215 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:52:58.564263 23215 net.cpp:165] Memory required for data: 157790800
I0525 14:52:58.564278 23215 layer_factory.hpp:77] Creating layer relu6
I0525 14:52:58.564291 23215 net.cpp:106] Creating Layer relu6
I0525 14:52:58.564301 23215 net.cpp:454] relu6 <- ip2
I0525 14:52:58.564311 23215 net.cpp:397] relu6 -> ip2 (in-place)
I0525 14:52:58.564829 23215 net.cpp:150] Setting up relu6
I0525 14:52:58.564846 23215 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:52:58.564856 23215 net.cpp:165] Memory required for data: 157830000
I0525 14:52:58.564865 23215 layer_factory.hpp:77] Creating layer drop2
I0525 14:52:58.564878 23215 net.cpp:106] Creating Layer drop2
I0525 14:52:58.564888 23215 net.cpp:454] drop2 <- ip2
I0525 14:52:58.564900 23215 net.cpp:397] drop2 -> ip2 (in-place)
I0525 14:52:58.564944 23215 net.cpp:150] Setting up drop2
I0525 14:52:58.564955 23215 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:52:58.564965 23215 net.cpp:165] Memory required for data: 157869200
I0525 14:52:58.564975 23215 layer_factory.hpp:77] Creating layer ip3
I0525 14:52:58.564988 23215 net.cpp:106] Creating Layer ip3
I0525 14:52:58.564998 23215 net.cpp:454] ip3 <- ip2
I0525 14:52:58.565011 23215 net.cpp:411] ip3 -> ip3
I0525 14:52:58.565227 23215 net.cpp:150] Setting up ip3
I0525 14:52:58.565240 23215 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:52:58.565250 23215 net.cpp:165] Memory required for data: 157873600
I0525 14:52:58.565265 23215 layer_factory.hpp:77] Creating layer drop3
I0525 14:52:58.565279 23215 net.cpp:106] Creating Layer drop3
I0525 14:52:58.565287 23215 net.cpp:454] drop3 <- ip3
I0525 14:52:58.565300 23215 net.cpp:397] drop3 -> ip3 (in-place)
I0525 14:52:58.565340 23215 net.cpp:150] Setting up drop3
I0525 14:52:58.565352 23215 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:52:58.565361 23215 net.cpp:165] Memory required for data: 157878000
I0525 14:52:58.565372 23215 layer_factory.hpp:77] Creating layer loss
I0525 14:52:58.565392 23215 net.cpp:106] Creating Layer loss
I0525 14:52:58.565402 23215 net.cpp:454] loss <- ip3
I0525 14:52:58.565412 23215 net.cpp:454] loss <- label
I0525 14:52:58.565424 23215 net.cpp:411] loss -> loss
I0525 14:52:58.565441 23215 layer_factory.hpp:77] Creating layer loss
I0525 14:52:58.566079 23215 net.cpp:150] Setting up loss
I0525 14:52:58.566100 23215 net.cpp:157] Top shape: (1)
I0525 14:52:58.566113 23215 net.cpp:160]     with loss weight 1
I0525 14:52:58.566154 23215 net.cpp:165] Memory required for data: 157878004
I0525 14:52:58.566165 23215 net.cpp:226] loss needs backward computation.
I0525 14:52:58.566176 23215 net.cpp:226] drop3 needs backward computation.
I0525 14:52:58.566186 23215 net.cpp:226] ip3 needs backward computation.
I0525 14:52:58.566196 23215 net.cpp:226] drop2 needs backward computation.
I0525 14:52:58.566206 23215 net.cpp:226] relu6 needs backward computation.
I0525 14:52:58.566215 23215 net.cpp:226] ip2 needs backward computation.
I0525 14:52:58.566225 23215 net.cpp:226] drop1 needs backward computation.
I0525 14:52:58.566233 23215 net.cpp:226] relu5 needs backward computation.
I0525 14:52:58.566243 23215 net.cpp:226] ip1 needs backward computation.
I0525 14:52:58.566253 23215 net.cpp:226] pool4 needs backward computation.
I0525 14:52:58.566263 23215 net.cpp:226] relu4 needs backward computation.
I0525 14:52:58.566273 23215 net.cpp:226] conv4 needs backward computation.
I0525 14:52:58.566283 23215 net.cpp:226] pool3 needs backward computation.
I0525 14:52:58.566294 23215 net.cpp:226] relu3 needs backward computation.
I0525 14:52:58.566313 23215 net.cpp:226] conv3 needs backward computation.
I0525 14:52:58.566324 23215 net.cpp:226] pool2 needs backward computation.
I0525 14:52:58.566335 23215 net.cpp:226] relu2 needs backward computation.
I0525 14:52:58.566345 23215 net.cpp:226] conv2 needs backward computation.
I0525 14:52:58.566356 23215 net.cpp:226] pool1 needs backward computation.
I0525 14:52:58.566366 23215 net.cpp:226] relu1 needs backward computation.
I0525 14:52:58.566376 23215 net.cpp:226] conv1 needs backward computation.
I0525 14:52:58.566387 23215 net.cpp:228] data_hdf5 does not need backward computation.
I0525 14:52:58.566396 23215 net.cpp:270] This network produces output loss
I0525 14:52:58.566421 23215 net.cpp:283] Network initialization done.
I0525 14:52:58.568025 23215 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997.prototxt
I0525 14:52:58.568096 23215 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 14:52:58.568450 23215 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 14:52:58.568637 23215 layer_factory.hpp:77] Creating layer data_hdf5
I0525 14:52:58.568652 23215 net.cpp:106] Creating Layer data_hdf5
I0525 14:52:58.568665 23215 net.cpp:411] data_hdf5 -> data
I0525 14:52:58.568681 23215 net.cpp:411] data_hdf5 -> label
I0525 14:52:58.568697 23215 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 14:52:58.585480 23215 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 14:53:19.945935 23215 net.cpp:150] Setting up data_hdf5
I0525 14:53:19.946101 23215 net.cpp:157] Top shape: 100 1 127 50 (635000)
I0525 14:53:19.946116 23215 net.cpp:157] Top shape: 100 (100)
I0525 14:53:19.946128 23215 net.cpp:165] Memory required for data: 2540400
I0525 14:53:19.946142 23215 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 14:53:19.946171 23215 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 14:53:19.946182 23215 net.cpp:454] label_data_hdf5_1_split <- label
I0525 14:53:19.946197 23215 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 14:53:19.946218 23215 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 14:53:19.946290 23215 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 14:53:19.946303 23215 net.cpp:157] Top shape: 100 (100)
I0525 14:53:19.946315 23215 net.cpp:157] Top shape: 100 (100)
I0525 14:53:19.946324 23215 net.cpp:165] Memory required for data: 2541200
I0525 14:53:19.946334 23215 layer_factory.hpp:77] Creating layer conv1
I0525 14:53:19.946354 23215 net.cpp:106] Creating Layer conv1
I0525 14:53:19.946364 23215 net.cpp:454] conv1 <- data
I0525 14:53:19.946379 23215 net.cpp:411] conv1 -> conv1
I0525 14:53:19.948340 23215 net.cpp:150] Setting up conv1
I0525 14:53:19.948365 23215 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:53:19.948376 23215 net.cpp:165] Memory required for data: 30189200
I0525 14:53:19.948397 23215 layer_factory.hpp:77] Creating layer relu1
I0525 14:53:19.948411 23215 net.cpp:106] Creating Layer relu1
I0525 14:53:19.948421 23215 net.cpp:454] relu1 <- conv1
I0525 14:53:19.948433 23215 net.cpp:397] relu1 -> conv1 (in-place)
I0525 14:53:19.948930 23215 net.cpp:150] Setting up relu1
I0525 14:53:19.948947 23215 net.cpp:157] Top shape: 100 12 120 48 (6912000)
I0525 14:53:19.948957 23215 net.cpp:165] Memory required for data: 57837200
I0525 14:53:19.948967 23215 layer_factory.hpp:77] Creating layer pool1
I0525 14:53:19.948983 23215 net.cpp:106] Creating Layer pool1
I0525 14:53:19.948993 23215 net.cpp:454] pool1 <- conv1
I0525 14:53:19.949007 23215 net.cpp:411] pool1 -> pool1
I0525 14:53:19.949092 23215 net.cpp:150] Setting up pool1
I0525 14:53:19.949105 23215 net.cpp:157] Top shape: 100 12 60 48 (3456000)
I0525 14:53:19.949116 23215 net.cpp:165] Memory required for data: 71661200
I0525 14:53:19.949126 23215 layer_factory.hpp:77] Creating layer conv2
I0525 14:53:19.949143 23215 net.cpp:106] Creating Layer conv2
I0525 14:53:19.949153 23215 net.cpp:454] conv2 <- pool1
I0525 14:53:19.949167 23215 net.cpp:411] conv2 -> conv2
I0525 14:53:19.951086 23215 net.cpp:150] Setting up conv2
I0525 14:53:19.951103 23215 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:53:19.951117 23215 net.cpp:165] Memory required for data: 91533200
I0525 14:53:19.951134 23215 layer_factory.hpp:77] Creating layer relu2
I0525 14:53:19.951148 23215 net.cpp:106] Creating Layer relu2
I0525 14:53:19.951158 23215 net.cpp:454] relu2 <- conv2
I0525 14:53:19.951169 23215 net.cpp:397] relu2 -> conv2 (in-place)
I0525 14:53:19.951503 23215 net.cpp:150] Setting up relu2
I0525 14:53:19.951516 23215 net.cpp:157] Top shape: 100 20 54 46 (4968000)
I0525 14:53:19.951527 23215 net.cpp:165] Memory required for data: 111405200
I0525 14:53:19.951537 23215 layer_factory.hpp:77] Creating layer pool2
I0525 14:53:19.951550 23215 net.cpp:106] Creating Layer pool2
I0525 14:53:19.951560 23215 net.cpp:454] pool2 <- conv2
I0525 14:53:19.951572 23215 net.cpp:411] pool2 -> pool2
I0525 14:53:19.951643 23215 net.cpp:150] Setting up pool2
I0525 14:53:19.951658 23215 net.cpp:157] Top shape: 100 20 27 46 (2484000)
I0525 14:53:19.951666 23215 net.cpp:165] Memory required for data: 121341200
I0525 14:53:19.951676 23215 layer_factory.hpp:77] Creating layer conv3
I0525 14:53:19.951696 23215 net.cpp:106] Creating Layer conv3
I0525 14:53:19.951706 23215 net.cpp:454] conv3 <- pool2
I0525 14:53:19.951720 23215 net.cpp:411] conv3 -> conv3
I0525 14:53:19.953716 23215 net.cpp:150] Setting up conv3
I0525 14:53:19.953739 23215 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:53:19.953752 23215 net.cpp:165] Memory required for data: 132182800
I0525 14:53:19.953784 23215 layer_factory.hpp:77] Creating layer relu3
I0525 14:53:19.953799 23215 net.cpp:106] Creating Layer relu3
I0525 14:53:19.953809 23215 net.cpp:454] relu3 <- conv3
I0525 14:53:19.953821 23215 net.cpp:397] relu3 -> conv3 (in-place)
I0525 14:53:19.954289 23215 net.cpp:150] Setting up relu3
I0525 14:53:19.954305 23215 net.cpp:157] Top shape: 100 28 22 44 (2710400)
I0525 14:53:19.954315 23215 net.cpp:165] Memory required for data: 143024400
I0525 14:53:19.954326 23215 layer_factory.hpp:77] Creating layer pool3
I0525 14:53:19.954339 23215 net.cpp:106] Creating Layer pool3
I0525 14:53:19.954349 23215 net.cpp:454] pool3 <- conv3
I0525 14:53:19.954361 23215 net.cpp:411] pool3 -> pool3
I0525 14:53:19.954432 23215 net.cpp:150] Setting up pool3
I0525 14:53:19.954445 23215 net.cpp:157] Top shape: 100 28 11 44 (1355200)
I0525 14:53:19.954454 23215 net.cpp:165] Memory required for data: 148445200
I0525 14:53:19.954465 23215 layer_factory.hpp:77] Creating layer conv4
I0525 14:53:19.954483 23215 net.cpp:106] Creating Layer conv4
I0525 14:53:19.954493 23215 net.cpp:454] conv4 <- pool3
I0525 14:53:19.954507 23215 net.cpp:411] conv4 -> conv4
I0525 14:53:19.956586 23215 net.cpp:150] Setting up conv4
I0525 14:53:19.956609 23215 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:53:19.956621 23215 net.cpp:165] Memory required for data: 152074000
I0525 14:53:19.956636 23215 layer_factory.hpp:77] Creating layer relu4
I0525 14:53:19.956650 23215 net.cpp:106] Creating Layer relu4
I0525 14:53:19.956660 23215 net.cpp:454] relu4 <- conv4
I0525 14:53:19.956672 23215 net.cpp:397] relu4 -> conv4 (in-place)
I0525 14:53:19.957155 23215 net.cpp:150] Setting up relu4
I0525 14:53:19.957171 23215 net.cpp:157] Top shape: 100 36 6 42 (907200)
I0525 14:53:19.957181 23215 net.cpp:165] Memory required for data: 155702800
I0525 14:53:19.957192 23215 layer_factory.hpp:77] Creating layer pool4
I0525 14:53:19.957206 23215 net.cpp:106] Creating Layer pool4
I0525 14:53:19.957216 23215 net.cpp:454] pool4 <- conv4
I0525 14:53:19.957228 23215 net.cpp:411] pool4 -> pool4
I0525 14:53:19.957300 23215 net.cpp:150] Setting up pool4
I0525 14:53:19.957314 23215 net.cpp:157] Top shape: 100 36 3 42 (453600)
I0525 14:53:19.957324 23215 net.cpp:165] Memory required for data: 157517200
I0525 14:53:19.957334 23215 layer_factory.hpp:77] Creating layer ip1
I0525 14:53:19.957350 23215 net.cpp:106] Creating Layer ip1
I0525 14:53:19.957360 23215 net.cpp:454] ip1 <- pool4
I0525 14:53:19.957372 23215 net.cpp:411] ip1 -> ip1
I0525 14:53:19.972826 23215 net.cpp:150] Setting up ip1
I0525 14:53:19.972854 23215 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:53:19.972865 23215 net.cpp:165] Memory required for data: 157595600
I0525 14:53:19.972888 23215 layer_factory.hpp:77] Creating layer relu5
I0525 14:53:19.972903 23215 net.cpp:106] Creating Layer relu5
I0525 14:53:19.972913 23215 net.cpp:454] relu5 <- ip1
I0525 14:53:19.972926 23215 net.cpp:397] relu5 -> ip1 (in-place)
I0525 14:53:19.973283 23215 net.cpp:150] Setting up relu5
I0525 14:53:19.973296 23215 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:53:19.973306 23215 net.cpp:165] Memory required for data: 157674000
I0525 14:53:19.973316 23215 layer_factory.hpp:77] Creating layer drop1
I0525 14:53:19.973335 23215 net.cpp:106] Creating Layer drop1
I0525 14:53:19.973345 23215 net.cpp:454] drop1 <- ip1
I0525 14:53:19.973357 23215 net.cpp:397] drop1 -> ip1 (in-place)
I0525 14:53:19.973402 23215 net.cpp:150] Setting up drop1
I0525 14:53:19.973415 23215 net.cpp:157] Top shape: 100 196 (19600)
I0525 14:53:19.973424 23215 net.cpp:165] Memory required for data: 157752400
I0525 14:53:19.973434 23215 layer_factory.hpp:77] Creating layer ip2
I0525 14:53:19.973448 23215 net.cpp:106] Creating Layer ip2
I0525 14:53:19.973459 23215 net.cpp:454] ip2 <- ip1
I0525 14:53:19.973471 23215 net.cpp:411] ip2 -> ip2
I0525 14:53:19.973953 23215 net.cpp:150] Setting up ip2
I0525 14:53:19.973965 23215 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:53:19.973975 23215 net.cpp:165] Memory required for data: 157791600
I0525 14:53:19.973991 23215 layer_factory.hpp:77] Creating layer relu6
I0525 14:53:19.974016 23215 net.cpp:106] Creating Layer relu6
I0525 14:53:19.974026 23215 net.cpp:454] relu6 <- ip2
I0525 14:53:19.974040 23215 net.cpp:397] relu6 -> ip2 (in-place)
I0525 14:53:19.974576 23215 net.cpp:150] Setting up relu6
I0525 14:53:19.974592 23215 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:53:19.974602 23215 net.cpp:165] Memory required for data: 157830800
I0525 14:53:19.974612 23215 layer_factory.hpp:77] Creating layer drop2
I0525 14:53:19.974625 23215 net.cpp:106] Creating Layer drop2
I0525 14:53:19.974635 23215 net.cpp:454] drop2 <- ip2
I0525 14:53:19.974648 23215 net.cpp:397] drop2 -> ip2 (in-place)
I0525 14:53:19.974692 23215 net.cpp:150] Setting up drop2
I0525 14:53:19.974705 23215 net.cpp:157] Top shape: 100 98 (9800)
I0525 14:53:19.974714 23215 net.cpp:165] Memory required for data: 157870000
I0525 14:53:19.974725 23215 layer_factory.hpp:77] Creating layer ip3
I0525 14:53:19.974738 23215 net.cpp:106] Creating Layer ip3
I0525 14:53:19.974748 23215 net.cpp:454] ip3 <- ip2
I0525 14:53:19.974762 23215 net.cpp:411] ip3 -> ip3
I0525 14:53:19.974985 23215 net.cpp:150] Setting up ip3
I0525 14:53:19.974998 23215 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:53:19.975008 23215 net.cpp:165] Memory required for data: 157874400
I0525 14:53:19.975024 23215 layer_factory.hpp:77] Creating layer drop3
I0525 14:53:19.975036 23215 net.cpp:106] Creating Layer drop3
I0525 14:53:19.975046 23215 net.cpp:454] drop3 <- ip3
I0525 14:53:19.975059 23215 net.cpp:397] drop3 -> ip3 (in-place)
I0525 14:53:19.975100 23215 net.cpp:150] Setting up drop3
I0525 14:53:19.975113 23215 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:53:19.975123 23215 net.cpp:165] Memory required for data: 157878800
I0525 14:53:19.975133 23215 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 14:53:19.975147 23215 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 14:53:19.975155 23215 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 14:53:19.975168 23215 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 14:53:19.975183 23215 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 14:53:19.975256 23215 net.cpp:150] Setting up ip3_drop3_0_split
I0525 14:53:19.975270 23215 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:53:19.975282 23215 net.cpp:157] Top shape: 100 11 (1100)
I0525 14:53:19.975292 23215 net.cpp:165] Memory required for data: 157887600
I0525 14:53:19.975302 23215 layer_factory.hpp:77] Creating layer accuracy
I0525 14:53:19.975324 23215 net.cpp:106] Creating Layer accuracy
I0525 14:53:19.975334 23215 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 14:53:19.975345 23215 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 14:53:19.975358 23215 net.cpp:411] accuracy -> accuracy
I0525 14:53:19.975383 23215 net.cpp:150] Setting up accuracy
I0525 14:53:19.975394 23215 net.cpp:157] Top shape: (1)
I0525 14:53:19.975404 23215 net.cpp:165] Memory required for data: 157887604
I0525 14:53:19.975414 23215 layer_factory.hpp:77] Creating layer loss
I0525 14:53:19.975428 23215 net.cpp:106] Creating Layer loss
I0525 14:53:19.975437 23215 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 14:53:19.975448 23215 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 14:53:19.975461 23215 net.cpp:411] loss -> loss
I0525 14:53:19.975479 23215 layer_factory.hpp:77] Creating layer loss
I0525 14:53:19.975965 23215 net.cpp:150] Setting up loss
I0525 14:53:19.975980 23215 net.cpp:157] Top shape: (1)
I0525 14:53:19.975988 23215 net.cpp:160]     with loss weight 1
I0525 14:53:19.976006 23215 net.cpp:165] Memory required for data: 157887608
I0525 14:53:19.976016 23215 net.cpp:226] loss needs backward computation.
I0525 14:53:19.976028 23215 net.cpp:228] accuracy does not need backward computation.
I0525 14:53:19.976039 23215 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 14:53:19.976049 23215 net.cpp:226] drop3 needs backward computation.
I0525 14:53:19.976059 23215 net.cpp:226] ip3 needs backward computation.
I0525 14:53:19.976068 23215 net.cpp:226] drop2 needs backward computation.
I0525 14:53:19.976086 23215 net.cpp:226] relu6 needs backward computation.
I0525 14:53:19.976096 23215 net.cpp:226] ip2 needs backward computation.
I0525 14:53:19.976107 23215 net.cpp:226] drop1 needs backward computation.
I0525 14:53:19.976116 23215 net.cpp:226] relu5 needs backward computation.
I0525 14:53:19.976125 23215 net.cpp:226] ip1 needs backward computation.
I0525 14:53:19.976135 23215 net.cpp:226] pool4 needs backward computation.
I0525 14:53:19.976145 23215 net.cpp:226] relu4 needs backward computation.
I0525 14:53:19.976155 23215 net.cpp:226] conv4 needs backward computation.
I0525 14:53:19.976166 23215 net.cpp:226] pool3 needs backward computation.
I0525 14:53:19.976176 23215 net.cpp:226] relu3 needs backward computation.
I0525 14:53:19.976186 23215 net.cpp:226] conv3 needs backward computation.
I0525 14:53:19.976197 23215 net.cpp:226] pool2 needs backward computation.
I0525 14:53:19.976207 23215 net.cpp:226] relu2 needs backward computation.
I0525 14:53:19.976217 23215 net.cpp:226] conv2 needs backward computation.
I0525 14:53:19.976227 23215 net.cpp:226] pool1 needs backward computation.
I0525 14:53:19.976238 23215 net.cpp:226] relu1 needs backward computation.
I0525 14:53:19.976248 23215 net.cpp:226] conv1 needs backward computation.
I0525 14:53:19.976258 23215 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 14:53:19.976270 23215 net.cpp:228] data_hdf5 does not need backward computation.
I0525 14:53:19.976279 23215 net.cpp:270] This network produces output accuracy
I0525 14:53:19.976290 23215 net.cpp:270] This network produces output loss
I0525 14:53:19.976317 23215 net.cpp:283] Network initialization done.
I0525 14:53:19.976451 23215 solver.cpp:60] Solver scaffolding done.
I0525 14:53:19.977599 23215 caffe.cpp:212] Starting Optimization
I0525 14:53:19.977617 23215 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 14:53:19.977632 23215 solver.cpp:289] Learning Rate Policy: fixed
I0525 14:53:19.978706 23215 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 14:54:07.840461 23215 solver.cpp:409]     Test net output #0: accuracy = 0.11346
I0525 14:54:07.840622 23215 solver.cpp:409]     Test net output #1: loss = 2.39756 (* 1 = 2.39756 loss)
I0525 14:54:07.873739 23215 solver.cpp:237] Iteration 0, loss = 2.39947
I0525 14:54:07.873774 23215 solver.cpp:253]     Train net output #0: loss = 2.39947 (* 1 = 2.39947 loss)
I0525 14:54:07.873791 23215 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0525 14:54:16.591519 23215 solver.cpp:237] Iteration 150, loss = 2.3195
I0525 14:54:16.591557 23215 solver.cpp:253]     Train net output #0: loss = 2.3195 (* 1 = 2.3195 loss)
I0525 14:54:16.591572 23215 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0525 14:54:25.313899 23215 solver.cpp:237] Iteration 300, loss = 2.32835
I0525 14:54:25.313944 23215 solver.cpp:253]     Train net output #0: loss = 2.32835 (* 1 = 2.32835 loss)
I0525 14:54:25.313959 23215 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0525 14:54:34.030756 23215 solver.cpp:237] Iteration 450, loss = 2.28618
I0525 14:54:34.030792 23215 solver.cpp:253]     Train net output #0: loss = 2.28618 (* 1 = 2.28618 loss)
I0525 14:54:34.030808 23215 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0525 14:54:42.753371 23215 solver.cpp:237] Iteration 600, loss = 2.22306
I0525 14:54:42.753520 23215 solver.cpp:253]     Train net output #0: loss = 2.22306 (* 1 = 2.22306 loss)
I0525 14:54:42.753535 23215 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0525 14:54:51.477691 23215 solver.cpp:237] Iteration 750, loss = 2.19299
I0525 14:54:51.477738 23215 solver.cpp:253]     Train net output #0: loss = 2.19299 (* 1 = 2.19299 loss)
I0525 14:54:51.477754 23215 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0525 14:55:00.200944 23215 solver.cpp:237] Iteration 900, loss = 2.11798
I0525 14:55:00.200980 23215 solver.cpp:253]     Train net output #0: loss = 2.11798 (* 1 = 2.11798 loss)
I0525 14:55:00.200996 23215 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0525 14:55:31.078899 23215 solver.cpp:237] Iteration 1050, loss = 2.02589
I0525 14:55:31.079059 23215 solver.cpp:253]     Train net output #0: loss = 2.02589 (* 1 = 2.02589 loss)
I0525 14:55:31.079076 23215 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0525 14:55:39.804062 23215 solver.cpp:237] Iteration 1200, loss = 1.97021
I0525 14:55:39.804106 23215 solver.cpp:253]     Train net output #0: loss = 1.97021 (* 1 = 1.97021 loss)
I0525 14:55:39.804122 23215 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0525 14:55:48.529351 23215 solver.cpp:237] Iteration 1350, loss = 1.93542
I0525 14:55:48.529386 23215 solver.cpp:253]     Train net output #0: loss = 1.93542 (* 1 = 1.93542 loss)
I0525 14:55:48.529400 23215 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0525 14:55:57.190160 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_1500.caffemodel
I0525 14:55:57.272264 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_1500.solverstate
I0525 14:55:57.317812 23215 solver.cpp:237] Iteration 1500, loss = 1.95964
I0525 14:55:57.317862 23215 solver.cpp:253]     Train net output #0: loss = 1.95964 (* 1 = 1.95964 loss)
I0525 14:55:57.317875 23215 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0525 14:56:06.040782 23215 solver.cpp:237] Iteration 1650, loss = 1.79689
I0525 14:56:06.040935 23215 solver.cpp:253]     Train net output #0: loss = 1.79689 (* 1 = 1.79689 loss)
I0525 14:56:06.040949 23215 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0525 14:56:14.762157 23215 solver.cpp:237] Iteration 1800, loss = 1.75783
I0525 14:56:14.762192 23215 solver.cpp:253]     Train net output #0: loss = 1.75783 (* 1 = 1.75783 loss)
I0525 14:56:14.762209 23215 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0525 14:56:23.486424 23215 solver.cpp:237] Iteration 1950, loss = 1.89445
I0525 14:56:23.486460 23215 solver.cpp:253]     Train net output #0: loss = 1.89445 (* 1 = 1.89445 loss)
I0525 14:56:23.486474 23215 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0525 14:56:54.332001 23215 solver.cpp:237] Iteration 2100, loss = 1.6768
I0525 14:56:54.332154 23215 solver.cpp:253]     Train net output #0: loss = 1.6768 (* 1 = 1.6768 loss)
I0525 14:56:54.332168 23215 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0525 14:57:03.056957 23215 solver.cpp:237] Iteration 2250, loss = 2.00762
I0525 14:57:03.056991 23215 solver.cpp:253]     Train net output #0: loss = 2.00762 (* 1 = 2.00762 loss)
I0525 14:57:03.057008 23215 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I0525 14:57:11.776764 23215 solver.cpp:237] Iteration 2400, loss = 1.98565
I0525 14:57:11.776800 23215 solver.cpp:253]     Train net output #0: loss = 1.98565 (* 1 = 1.98565 loss)
I0525 14:57:11.776816 23215 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0525 14:57:20.499495 23215 solver.cpp:237] Iteration 2550, loss = 1.81626
I0525 14:57:20.499536 23215 solver.cpp:253]     Train net output #0: loss = 1.81626 (* 1 = 1.81626 loss)
I0525 14:57:20.499555 23215 sgd_solver.cpp:106] Iteration 2550, lr = 0.001
I0525 14:57:29.222381 23215 solver.cpp:237] Iteration 2700, loss = 1.82465
I0525 14:57:29.222528 23215 solver.cpp:253]     Train net output #0: loss = 1.82465 (* 1 = 1.82465 loss)
I0525 14:57:29.222542 23215 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0525 14:57:37.945106 23215 solver.cpp:237] Iteration 2850, loss = 1.83341
I0525 14:57:37.945140 23215 solver.cpp:253]     Train net output #0: loss = 1.83341 (* 1 = 1.83341 loss)
I0525 14:57:37.945155 23215 sgd_solver.cpp:106] Iteration 2850, lr = 0.001
I0525 14:57:46.609997 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_3000.caffemodel
I0525 14:57:46.689354 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_3000.solverstate
I0525 14:57:46.715315 23215 solver.cpp:341] Iteration 3000, Testing net (#0)
I0525 14:58:33.515692 23215 solver.cpp:409]     Test net output #0: accuracy = 0.628773
I0525 14:58:33.541124 23215 solver.cpp:409]     Test net output #1: loss = 1.26095 (* 1 = 1.26095 loss)
I0525 14:58:55.748050 23215 solver.cpp:237] Iteration 3000, loss = 1.76409
I0525 14:58:55.748103 23215 solver.cpp:253]     Train net output #0: loss = 1.76409 (* 1 = 1.76409 loss)
I0525 14:58:55.748118 23215 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0525 14:59:04.481181 23215 solver.cpp:237] Iteration 3150, loss = 1.75548
I0525 14:59:04.481334 23215 solver.cpp:253]     Train net output #0: loss = 1.75548 (* 1 = 1.75548 loss)
I0525 14:59:04.481348 23215 sgd_solver.cpp:106] Iteration 3150, lr = 0.001
I0525 14:59:13.222784 23215 solver.cpp:237] Iteration 3300, loss = 1.74754
I0525 14:59:13.222820 23215 solver.cpp:253]     Train net output #0: loss = 1.74754 (* 1 = 1.74754 loss)
I0525 14:59:13.222832 23215 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0525 14:59:21.962272 23215 solver.cpp:237] Iteration 3450, loss = 1.81104
I0525 14:59:21.962308 23215 solver.cpp:253]     Train net output #0: loss = 1.81104 (* 1 = 1.81104 loss)
I0525 14:59:21.962323 23215 sgd_solver.cpp:106] Iteration 3450, lr = 0.001
I0525 14:59:30.700387 23215 solver.cpp:237] Iteration 3600, loss = 1.58837
I0525 14:59:30.700425 23215 solver.cpp:253]     Train net output #0: loss = 1.58837 (* 1 = 1.58837 loss)
I0525 14:59:30.700444 23215 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0525 14:59:39.437938 23215 solver.cpp:237] Iteration 3750, loss = 1.55291
I0525 14:59:39.438091 23215 solver.cpp:253]     Train net output #0: loss = 1.55291 (* 1 = 1.55291 loss)
I0525 14:59:39.438104 23215 sgd_solver.cpp:106] Iteration 3750, lr = 0.001
I0525 14:59:48.177872 23215 solver.cpp:237] Iteration 3900, loss = 1.64674
I0525 14:59:48.177907 23215 solver.cpp:253]     Train net output #0: loss = 1.64674 (* 1 = 1.64674 loss)
I0525 14:59:48.177923 23215 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0525 15:00:19.039021 23215 solver.cpp:237] Iteration 4050, loss = 1.79645
I0525 15:00:19.039192 23215 solver.cpp:253]     Train net output #0: loss = 1.79645 (* 1 = 1.79645 loss)
I0525 15:00:19.039208 23215 sgd_solver.cpp:106] Iteration 4050, lr = 0.001
I0525 15:00:27.777521 23215 solver.cpp:237] Iteration 4200, loss = 1.42511
I0525 15:00:27.777556 23215 solver.cpp:253]     Train net output #0: loss = 1.42511 (* 1 = 1.42511 loss)
I0525 15:00:27.777573 23215 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0525 15:00:36.512320 23215 solver.cpp:237] Iteration 4350, loss = 1.86003
I0525 15:00:36.512356 23215 solver.cpp:253]     Train net output #0: loss = 1.86003 (* 1 = 1.86003 loss)
I0525 15:00:36.512370 23215 sgd_solver.cpp:106] Iteration 4350, lr = 0.001
I0525 15:00:45.188590 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_4500.caffemodel
I0525 15:00:45.267987 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_4500.solverstate
I0525 15:00:45.313366 23215 solver.cpp:237] Iteration 4500, loss = 1.79742
I0525 15:00:45.313416 23215 solver.cpp:253]     Train net output #0: loss = 1.79742 (* 1 = 1.79742 loss)
I0525 15:00:45.313431 23215 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0525 15:00:54.048861 23215 solver.cpp:237] Iteration 4650, loss = 1.72967
I0525 15:00:54.049015 23215 solver.cpp:253]     Train net output #0: loss = 1.72967 (* 1 = 1.72967 loss)
I0525 15:00:54.049029 23215 sgd_solver.cpp:106] Iteration 4650, lr = 0.001
I0525 15:01:02.785375 23215 solver.cpp:237] Iteration 4800, loss = 1.72161
I0525 15:01:02.785409 23215 solver.cpp:253]     Train net output #0: loss = 1.72161 (* 1 = 1.72161 loss)
I0525 15:01:02.785426 23215 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0525 15:01:11.520840 23215 solver.cpp:237] Iteration 4950, loss = 1.59837
I0525 15:01:11.520886 23215 solver.cpp:253]     Train net output #0: loss = 1.59837 (* 1 = 1.59837 loss)
I0525 15:01:11.520903 23215 sgd_solver.cpp:106] Iteration 4950, lr = 0.001
I0525 15:01:42.349405 23215 solver.cpp:237] Iteration 5100, loss = 1.80819
I0525 15:01:42.349568 23215 solver.cpp:253]     Train net output #0: loss = 1.80819 (* 1 = 1.80819 loss)
I0525 15:01:42.349584 23215 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0525 15:01:51.089918 23215 solver.cpp:237] Iteration 5250, loss = 1.58692
I0525 15:01:51.089952 23215 solver.cpp:253]     Train net output #0: loss = 1.58692 (* 1 = 1.58692 loss)
I0525 15:01:51.089970 23215 sgd_solver.cpp:106] Iteration 5250, lr = 0.001
I0525 15:01:59.829720 23215 solver.cpp:237] Iteration 5400, loss = 1.67875
I0525 15:01:59.829761 23215 solver.cpp:253]     Train net output #0: loss = 1.67875 (* 1 = 1.67875 loss)
I0525 15:01:59.829783 23215 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0525 15:02:08.570739 23215 solver.cpp:237] Iteration 5550, loss = 1.64046
I0525 15:02:08.570775 23215 solver.cpp:253]     Train net output #0: loss = 1.64046 (* 1 = 1.64046 loss)
I0525 15:02:08.570791 23215 sgd_solver.cpp:106] Iteration 5550, lr = 0.001
I0525 15:02:17.310701 23215 solver.cpp:237] Iteration 5700, loss = 1.67618
I0525 15:02:17.310838 23215 solver.cpp:253]     Train net output #0: loss = 1.67618 (* 1 = 1.67618 loss)
I0525 15:02:17.310852 23215 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0525 15:02:26.048413 23215 solver.cpp:237] Iteration 5850, loss = 1.48548
I0525 15:02:26.048454 23215 solver.cpp:253]     Train net output #0: loss = 1.48548 (* 1 = 1.48548 loss)
I0525 15:02:26.048471 23215 sgd_solver.cpp:106] Iteration 5850, lr = 0.001
I0525 15:02:34.729733 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_6000.caffemodel
I0525 15:02:34.809449 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_6000.solverstate
I0525 15:02:34.836359 23215 solver.cpp:341] Iteration 6000, Testing net (#0)
I0525 15:03:42.436713 23215 solver.cpp:409]     Test net output #0: accuracy = 0.680119
I0525 15:03:42.436883 23215 solver.cpp:409]     Test net output #1: loss = 1.10853 (* 1 = 1.10853 loss)
I0525 15:04:04.737121 23215 solver.cpp:237] Iteration 6000, loss = 1.75639
I0525 15:04:04.737174 23215 solver.cpp:253]     Train net output #0: loss = 1.75639 (* 1 = 1.75639 loss)
I0525 15:04:04.737188 23215 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0525 15:04:13.460031 23215 solver.cpp:237] Iteration 6150, loss = 1.5731
I0525 15:04:13.460196 23215 solver.cpp:253]     Train net output #0: loss = 1.5731 (* 1 = 1.5731 loss)
I0525 15:04:13.460211 23215 sgd_solver.cpp:106] Iteration 6150, lr = 0.001
I0525 15:04:22.196579 23215 solver.cpp:237] Iteration 6300, loss = 1.74749
I0525 15:04:22.196614 23215 solver.cpp:253]     Train net output #0: loss = 1.74749 (* 1 = 1.74749 loss)
I0525 15:04:22.196631 23215 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I0525 15:04:30.929042 23215 solver.cpp:237] Iteration 6450, loss = 1.7899
I0525 15:04:30.929086 23215 solver.cpp:253]     Train net output #0: loss = 1.7899 (* 1 = 1.7899 loss)
I0525 15:04:30.929101 23215 sgd_solver.cpp:106] Iteration 6450, lr = 0.001
I0525 15:04:39.657294 23215 solver.cpp:237] Iteration 6600, loss = 1.51833
I0525 15:04:39.657330 23215 solver.cpp:253]     Train net output #0: loss = 1.51833 (* 1 = 1.51833 loss)
I0525 15:04:39.657346 23215 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0525 15:04:48.385152 23215 solver.cpp:237] Iteration 6750, loss = 1.53842
I0525 15:04:48.385291 23215 solver.cpp:253]     Train net output #0: loss = 1.53842 (* 1 = 1.53842 loss)
I0525 15:04:48.385305 23215 sgd_solver.cpp:106] Iteration 6750, lr = 0.001
I0525 15:04:57.115489 23215 solver.cpp:237] Iteration 6900, loss = 1.4203
I0525 15:04:57.115526 23215 solver.cpp:253]     Train net output #0: loss = 1.4203 (* 1 = 1.4203 loss)
I0525 15:04:57.115545 23215 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I0525 15:05:28.020874 23215 solver.cpp:237] Iteration 7050, loss = 1.70359
I0525 15:05:28.021040 23215 solver.cpp:253]     Train net output #0: loss = 1.70359 (* 1 = 1.70359 loss)
I0525 15:05:28.021055 23215 sgd_solver.cpp:106] Iteration 7050, lr = 0.001
I0525 15:05:36.751828 23215 solver.cpp:237] Iteration 7200, loss = 1.54423
I0525 15:05:36.751863 23215 solver.cpp:253]     Train net output #0: loss = 1.54423 (* 1 = 1.54423 loss)
I0525 15:05:36.751879 23215 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0525 15:05:45.486045 23215 solver.cpp:237] Iteration 7350, loss = 1.48393
I0525 15:05:45.486090 23215 solver.cpp:253]     Train net output #0: loss = 1.48393 (* 1 = 1.48393 loss)
I0525 15:05:45.486106 23215 sgd_solver.cpp:106] Iteration 7350, lr = 0.001
I0525 15:05:54.161837 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_7500.caffemodel
I0525 15:05:54.241756 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_7500.solverstate
I0525 15:05:54.286842 23215 solver.cpp:237] Iteration 7500, loss = 1.5677
I0525 15:05:54.286891 23215 solver.cpp:253]     Train net output #0: loss = 1.5677 (* 1 = 1.5677 loss)
I0525 15:05:54.286906 23215 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0525 15:06:03.016252 23215 solver.cpp:237] Iteration 7650, loss = 1.61974
I0525 15:06:03.016397 23215 solver.cpp:253]     Train net output #0: loss = 1.61974 (* 1 = 1.61974 loss)
I0525 15:06:03.016410 23215 sgd_solver.cpp:106] Iteration 7650, lr = 0.001
I0525 15:06:11.745992 23215 solver.cpp:237] Iteration 7800, loss = 1.49957
I0525 15:06:11.746032 23215 solver.cpp:253]     Train net output #0: loss = 1.49957 (* 1 = 1.49957 loss)
I0525 15:06:11.746054 23215 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0525 15:06:20.476816 23215 solver.cpp:237] Iteration 7950, loss = 1.54013
I0525 15:06:20.476852 23215 solver.cpp:253]     Train net output #0: loss = 1.54013 (* 1 = 1.54013 loss)
I0525 15:06:20.476866 23215 sgd_solver.cpp:106] Iteration 7950, lr = 0.001
I0525 15:06:51.364570 23215 solver.cpp:237] Iteration 8100, loss = 1.61841
I0525 15:06:51.364737 23215 solver.cpp:253]     Train net output #0: loss = 1.61841 (* 1 = 1.61841 loss)
I0525 15:06:51.364753 23215 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0525 15:07:00.099386 23215 solver.cpp:237] Iteration 8250, loss = 1.54753
I0525 15:07:00.099431 23215 solver.cpp:253]     Train net output #0: loss = 1.54753 (* 1 = 1.54753 loss)
I0525 15:07:00.099449 23215 sgd_solver.cpp:106] Iteration 8250, lr = 0.001
I0525 15:07:08.831627 23215 solver.cpp:237] Iteration 8400, loss = 1.58256
I0525 15:07:08.831661 23215 solver.cpp:253]     Train net output #0: loss = 1.58256 (* 1 = 1.58256 loss)
I0525 15:07:08.831678 23215 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0525 15:07:17.558996 23215 solver.cpp:237] Iteration 8550, loss = 1.60207
I0525 15:07:17.559032 23215 solver.cpp:253]     Train net output #0: loss = 1.60207 (* 1 = 1.60207 loss)
I0525 15:07:17.559046 23215 sgd_solver.cpp:106] Iteration 8550, lr = 0.001
I0525 15:07:26.288705 23215 solver.cpp:237] Iteration 8700, loss = 1.61256
I0525 15:07:26.288856 23215 solver.cpp:253]     Train net output #0: loss = 1.61256 (* 1 = 1.61256 loss)
I0525 15:07:26.288871 23215 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0525 15:07:35.015555 23215 solver.cpp:237] Iteration 8850, loss = 1.39878
I0525 15:07:35.015589 23215 solver.cpp:253]     Train net output #0: loss = 1.39878 (* 1 = 1.39878 loss)
I0525 15:07:35.015606 23215 sgd_solver.cpp:106] Iteration 8850, lr = 0.001
I0525 15:07:43.686044 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_9000.caffemodel
I0525 15:07:43.764574 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_9000.solverstate
I0525 15:07:43.789705 23215 solver.cpp:341] Iteration 9000, Testing net (#0)
I0525 15:08:30.258702 23215 solver.cpp:409]     Test net output #0: accuracy = 0.741214
I0525 15:08:30.258865 23215 solver.cpp:409]     Test net output #1: loss = 0.880426 (* 1 = 0.880426 loss)
I0525 15:08:52.459621 23215 solver.cpp:237] Iteration 9000, loss = 1.34141
I0525 15:08:52.459673 23215 solver.cpp:253]     Train net output #0: loss = 1.34141 (* 1 = 1.34141 loss)
I0525 15:08:52.459689 23215 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0525 15:09:01.195658 23215 solver.cpp:237] Iteration 9150, loss = 1.33244
I0525 15:09:01.195823 23215 solver.cpp:253]     Train net output #0: loss = 1.33244 (* 1 = 1.33244 loss)
I0525 15:09:01.195837 23215 sgd_solver.cpp:106] Iteration 9150, lr = 0.001
I0525 15:09:09.927733 23215 solver.cpp:237] Iteration 9300, loss = 1.5934
I0525 15:09:09.927768 23215 solver.cpp:253]     Train net output #0: loss = 1.5934 (* 1 = 1.5934 loss)
I0525 15:09:09.927785 23215 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0525 15:09:18.658100 23215 solver.cpp:237] Iteration 9450, loss = 1.56893
I0525 15:09:18.658135 23215 solver.cpp:253]     Train net output #0: loss = 1.56893 (* 1 = 1.56893 loss)
I0525 15:09:18.658151 23215 sgd_solver.cpp:106] Iteration 9450, lr = 0.001
I0525 15:09:27.390115 23215 solver.cpp:237] Iteration 9600, loss = 1.56359
I0525 15:09:27.390161 23215 solver.cpp:253]     Train net output #0: loss = 1.56359 (* 1 = 1.56359 loss)
I0525 15:09:27.390178 23215 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0525 15:09:36.122578 23215 solver.cpp:237] Iteration 9750, loss = 1.70004
I0525 15:09:36.122720 23215 solver.cpp:253]     Train net output #0: loss = 1.70004 (* 1 = 1.70004 loss)
I0525 15:09:36.122735 23215 sgd_solver.cpp:106] Iteration 9750, lr = 0.001
I0525 15:09:44.853469 23215 solver.cpp:237] Iteration 9900, loss = 1.38894
I0525 15:09:44.853503 23215 solver.cpp:253]     Train net output #0: loss = 1.38894 (* 1 = 1.38894 loss)
I0525 15:09:44.853520 23215 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0525 15:10:15.778655 23215 solver.cpp:237] Iteration 10050, loss = 1.59959
I0525 15:10:15.778827 23215 solver.cpp:253]     Train net output #0: loss = 1.59959 (* 1 = 1.59959 loss)
I0525 15:10:15.778842 23215 sgd_solver.cpp:106] Iteration 10050, lr = 0.001
I0525 15:10:24.517760 23215 solver.cpp:237] Iteration 10200, loss = 1.38891
I0525 15:10:24.517796 23215 solver.cpp:253]     Train net output #0: loss = 1.38891 (* 1 = 1.38891 loss)
I0525 15:10:24.517809 23215 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0525 15:10:33.251365 23215 solver.cpp:237] Iteration 10350, loss = 1.25338
I0525 15:10:33.251400 23215 solver.cpp:253]     Train net output #0: loss = 1.25338 (* 1 = 1.25338 loss)
I0525 15:10:33.251416 23215 sgd_solver.cpp:106] Iteration 10350, lr = 0.001
I0525 15:10:41.927559 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_10500.caffemodel
I0525 15:10:42.005704 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_10500.solverstate
I0525 15:10:42.049856 23215 solver.cpp:237] Iteration 10500, loss = 1.453
I0525 15:10:42.049901 23215 solver.cpp:253]     Train net output #0: loss = 1.453 (* 1 = 1.453 loss)
I0525 15:10:42.049916 23215 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0525 15:10:50.783359 23215 solver.cpp:237] Iteration 10650, loss = 1.40432
I0525 15:10:50.783506 23215 solver.cpp:253]     Train net output #0: loss = 1.40432 (* 1 = 1.40432 loss)
I0525 15:10:50.783519 23215 sgd_solver.cpp:106] Iteration 10650, lr = 0.001
I0525 15:10:59.520246 23215 solver.cpp:237] Iteration 10800, loss = 1.37096
I0525 15:10:59.520279 23215 solver.cpp:253]     Train net output #0: loss = 1.37096 (* 1 = 1.37096 loss)
I0525 15:10:59.520297 23215 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0525 15:11:08.255736 23215 solver.cpp:237] Iteration 10950, loss = 1.41897
I0525 15:11:08.255779 23215 solver.cpp:253]     Train net output #0: loss = 1.41897 (* 1 = 1.41897 loss)
I0525 15:11:08.255800 23215 sgd_solver.cpp:106] Iteration 10950, lr = 0.001
I0525 15:11:39.155737 23215 solver.cpp:237] Iteration 11100, loss = 1.4177
I0525 15:11:39.155905 23215 solver.cpp:253]     Train net output #0: loss = 1.4177 (* 1 = 1.4177 loss)
I0525 15:11:39.155920 23215 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I0525 15:11:47.885489 23215 solver.cpp:237] Iteration 11250, loss = 1.553
I0525 15:11:47.885524 23215 solver.cpp:253]     Train net output #0: loss = 1.553 (* 1 = 1.553 loss)
I0525 15:11:47.885540 23215 sgd_solver.cpp:106] Iteration 11250, lr = 0.001
I0525 15:11:56.622117 23215 solver.cpp:237] Iteration 11400, loss = 1.47342
I0525 15:11:56.622159 23215 solver.cpp:253]     Train net output #0: loss = 1.47342 (* 1 = 1.47342 loss)
I0525 15:11:56.622179 23215 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0525 15:12:05.349637 23215 solver.cpp:237] Iteration 11550, loss = 1.26245
I0525 15:12:05.349671 23215 solver.cpp:253]     Train net output #0: loss = 1.26245 (* 1 = 1.26245 loss)
I0525 15:12:05.349687 23215 sgd_solver.cpp:106] Iteration 11550, lr = 0.001
I0525 15:12:14.080653 23215 solver.cpp:237] Iteration 11700, loss = 1.57992
I0525 15:12:14.080804 23215 solver.cpp:253]     Train net output #0: loss = 1.57992 (* 1 = 1.57992 loss)
I0525 15:12:14.080818 23215 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I0525 15:12:22.819702 23215 solver.cpp:237] Iteration 11850, loss = 1.33607
I0525 15:12:22.819747 23215 solver.cpp:253]     Train net output #0: loss = 1.33607 (* 1 = 1.33607 loss)
I0525 15:12:22.819763 23215 sgd_solver.cpp:106] Iteration 11850, lr = 0.001
I0525 15:12:31.500538 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_12000.caffemodel
I0525 15:12:31.578646 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_12000.solverstate
I0525 15:12:31.605082 23215 solver.cpp:341] Iteration 12000, Testing net (#0)
I0525 15:13:39.212898 23215 solver.cpp:409]     Test net output #0: accuracy = 0.784648
I0525 15:13:39.213085 23215 solver.cpp:409]     Test net output #1: loss = 0.798534 (* 1 = 0.798534 loss)
I0525 15:14:01.391300 23215 solver.cpp:237] Iteration 12000, loss = 1.3735
I0525 15:14:01.391353 23215 solver.cpp:253]     Train net output #0: loss = 1.3735 (* 1 = 1.3735 loss)
I0525 15:14:01.391368 23215 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0525 15:14:10.113754 23215 solver.cpp:237] Iteration 12150, loss = 1.63031
I0525 15:14:10.113909 23215 solver.cpp:253]     Train net output #0: loss = 1.63031 (* 1 = 1.63031 loss)
I0525 15:14:10.113922 23215 sgd_solver.cpp:106] Iteration 12150, lr = 0.001
I0525 15:14:18.839159 23215 solver.cpp:237] Iteration 12300, loss = 1.30668
I0525 15:14:18.839195 23215 solver.cpp:253]     Train net output #0: loss = 1.30668 (* 1 = 1.30668 loss)
I0525 15:14:18.839211 23215 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I0525 15:14:27.570902 23215 solver.cpp:237] Iteration 12450, loss = 1.28832
I0525 15:14:27.570947 23215 solver.cpp:253]     Train net output #0: loss = 1.28832 (* 1 = 1.28832 loss)
I0525 15:14:27.570966 23215 sgd_solver.cpp:106] Iteration 12450, lr = 0.001
I0525 15:14:36.292464 23215 solver.cpp:237] Iteration 12600, loss = 1.33273
I0525 15:14:36.292500 23215 solver.cpp:253]     Train net output #0: loss = 1.33273 (* 1 = 1.33273 loss)
I0525 15:14:36.292515 23215 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0525 15:14:45.018787 23215 solver.cpp:237] Iteration 12750, loss = 1.58748
I0525 15:14:45.018932 23215 solver.cpp:253]     Train net output #0: loss = 1.58748 (* 1 = 1.58748 loss)
I0525 15:14:45.018946 23215 sgd_solver.cpp:106] Iteration 12750, lr = 0.001
I0525 15:14:53.742821 23215 solver.cpp:237] Iteration 12900, loss = 1.26909
I0525 15:14:53.742858 23215 solver.cpp:253]     Train net output #0: loss = 1.26909 (* 1 = 1.26909 loss)
I0525 15:14:53.742879 23215 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I0525 15:15:24.702736 23215 solver.cpp:237] Iteration 13050, loss = 1.66206
I0525 15:15:24.702909 23215 solver.cpp:253]     Train net output #0: loss = 1.66206 (* 1 = 1.66206 loss)
I0525 15:15:24.702924 23215 sgd_solver.cpp:106] Iteration 13050, lr = 0.001
I0525 15:15:33.425364 23215 solver.cpp:237] Iteration 13200, loss = 1.40516
I0525 15:15:33.425398 23215 solver.cpp:253]     Train net output #0: loss = 1.40516 (* 1 = 1.40516 loss)
I0525 15:15:33.425416 23215 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0525 15:15:42.152876 23215 solver.cpp:237] Iteration 13350, loss = 1.36899
I0525 15:15:42.152918 23215 solver.cpp:253]     Train net output #0: loss = 1.36899 (* 1 = 1.36899 loss)
I0525 15:15:42.152937 23215 sgd_solver.cpp:106] Iteration 13350, lr = 0.001
I0525 15:15:50.815824 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_13500.caffemodel
I0525 15:15:50.896085 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_13500.solverstate
I0525 15:15:50.942492 23215 solver.cpp:237] Iteration 13500, loss = 1.33212
I0525 15:15:50.942541 23215 solver.cpp:253]     Train net output #0: loss = 1.33212 (* 1 = 1.33212 loss)
I0525 15:15:50.942559 23215 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0525 15:15:59.667635 23215 solver.cpp:237] Iteration 13650, loss = 1.5113
I0525 15:15:59.667794 23215 solver.cpp:253]     Train net output #0: loss = 1.5113 (* 1 = 1.5113 loss)
I0525 15:15:59.667809 23215 sgd_solver.cpp:106] Iteration 13650, lr = 0.001
I0525 15:16:08.394255 23215 solver.cpp:237] Iteration 13800, loss = 1.57293
I0525 15:16:08.394304 23215 solver.cpp:253]     Train net output #0: loss = 1.57293 (* 1 = 1.57293 loss)
I0525 15:16:08.394320 23215 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0525 15:16:17.121847 23215 solver.cpp:237] Iteration 13950, loss = 1.50107
I0525 15:16:17.121883 23215 solver.cpp:253]     Train net output #0: loss = 1.50107 (* 1 = 1.50107 loss)
I0525 15:16:17.121899 23215 sgd_solver.cpp:106] Iteration 13950, lr = 0.001
I0525 15:16:48.030052 23215 solver.cpp:237] Iteration 14100, loss = 1.32654
I0525 15:16:48.030236 23215 solver.cpp:253]     Train net output #0: loss = 1.32654 (* 1 = 1.32654 loss)
I0525 15:16:48.030252 23215 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I0525 15:16:56.753676 23215 solver.cpp:237] Iteration 14250, loss = 1.28395
I0525 15:16:56.753722 23215 solver.cpp:253]     Train net output #0: loss = 1.28395 (* 1 = 1.28395 loss)
I0525 15:16:56.753741 23215 sgd_solver.cpp:106] Iteration 14250, lr = 0.001
I0525 15:17:05.474300 23215 solver.cpp:237] Iteration 14400, loss = 1.42348
I0525 15:17:05.474336 23215 solver.cpp:253]     Train net output #0: loss = 1.42348 (* 1 = 1.42348 loss)
I0525 15:17:05.474349 23215 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0525 15:17:14.195746 23215 solver.cpp:237] Iteration 14550, loss = 1.40587
I0525 15:17:14.195782 23215 solver.cpp:253]     Train net output #0: loss = 1.40587 (* 1 = 1.40587 loss)
I0525 15:17:14.195798 23215 sgd_solver.cpp:106] Iteration 14550, lr = 0.001
I0525 15:17:22.918046 23215 solver.cpp:237] Iteration 14700, loss = 1.49397
I0525 15:17:22.918201 23215 solver.cpp:253]     Train net output #0: loss = 1.49397 (* 1 = 1.49397 loss)
I0525 15:17:22.918215 23215 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I0525 15:17:31.640374 23215 solver.cpp:237] Iteration 14850, loss = 1.48338
I0525 15:17:31.640410 23215 solver.cpp:253]     Train net output #0: loss = 1.48338 (* 1 = 1.48338 loss)
I0525 15:17:31.640424 23215 sgd_solver.cpp:106] Iteration 14850, lr = 0.001
I0525 15:17:40.304451 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_15000.caffemodel
I0525 15:17:40.384595 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_15000.solverstate
I0525 15:17:40.412601 23215 solver.cpp:341] Iteration 15000, Testing net (#0)
I0525 15:18:27.222250 23215 solver.cpp:409]     Test net output #0: accuracy = 0.797962
I0525 15:18:27.222414 23215 solver.cpp:409]     Test net output #1: loss = 0.683591 (* 1 = 0.683591 loss)
I0525 15:18:48.157320 23215 solver.cpp:237] Iteration 15000, loss = 1.24669
I0525 15:18:48.157372 23215 solver.cpp:253]     Train net output #0: loss = 1.24669 (* 1 = 1.24669 loss)
I0525 15:18:48.157388 23215 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0525 15:18:56.898252 23215 solver.cpp:237] Iteration 15150, loss = 1.20692
I0525 15:18:56.898286 23215 solver.cpp:253]     Train net output #0: loss = 1.20692 (* 1 = 1.20692 loss)
I0525 15:18:56.898303 23215 sgd_solver.cpp:106] Iteration 15150, lr = 0.001
I0525 15:19:05.635828 23215 solver.cpp:237] Iteration 15300, loss = 1.21034
I0525 15:19:05.635987 23215 solver.cpp:253]     Train net output #0: loss = 1.21034 (* 1 = 1.21034 loss)
I0525 15:19:05.636000 23215 sgd_solver.cpp:106] Iteration 15300, lr = 0.001
I0525 15:19:14.364480 23215 solver.cpp:237] Iteration 15450, loss = 1.4184
I0525 15:19:14.364513 23215 solver.cpp:253]     Train net output #0: loss = 1.4184 (* 1 = 1.4184 loss)
I0525 15:19:14.364531 23215 sgd_solver.cpp:106] Iteration 15450, lr = 0.001
I0525 15:19:23.100863 23215 solver.cpp:237] Iteration 15600, loss = 1.44699
I0525 15:19:23.100899 23215 solver.cpp:253]     Train net output #0: loss = 1.44699 (* 1 = 1.44699 loss)
I0525 15:19:23.100916 23215 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0525 15:19:31.838803 23215 solver.cpp:237] Iteration 15750, loss = 1.5537
I0525 15:19:31.838840 23215 solver.cpp:253]     Train net output #0: loss = 1.5537 (* 1 = 1.5537 loss)
I0525 15:19:31.838860 23215 sgd_solver.cpp:106] Iteration 15750, lr = 0.001
I0525 15:19:40.577373 23215 solver.cpp:237] Iteration 15900, loss = 1.2953
I0525 15:19:40.577525 23215 solver.cpp:253]     Train net output #0: loss = 1.2953 (* 1 = 1.2953 loss)
I0525 15:19:40.577539 23215 sgd_solver.cpp:106] Iteration 15900, lr = 0.001
I0525 15:20:10.209751 23215 solver.cpp:237] Iteration 16050, loss = 1.30644
I0525 15:20:10.209801 23215 solver.cpp:253]     Train net output #0: loss = 1.30644 (* 1 = 1.30644 loss)
I0525 15:20:10.209817 23215 sgd_solver.cpp:106] Iteration 16050, lr = 0.001
I0525 15:20:18.941195 23215 solver.cpp:237] Iteration 16200, loss = 1.29855
I0525 15:20:18.941359 23215 solver.cpp:253]     Train net output #0: loss = 1.29855 (* 1 = 1.29855 loss)
I0525 15:20:18.941373 23215 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0525 15:20:27.680124 23215 solver.cpp:237] Iteration 16350, loss = 1.32296
I0525 15:20:27.680158 23215 solver.cpp:253]     Train net output #0: loss = 1.32296 (* 1 = 1.32296 loss)
I0525 15:20:27.680171 23215 sgd_solver.cpp:106] Iteration 16350, lr = 0.001
I0525 15:20:36.362282 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_16500.caffemodel
I0525 15:20:36.441298 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_16500.solverstate
I0525 15:20:36.484329 23215 solver.cpp:237] Iteration 16500, loss = 1.27432
I0525 15:20:36.484374 23215 solver.cpp:253]     Train net output #0: loss = 1.27432 (* 1 = 1.27432 loss)
I0525 15:20:36.484387 23215 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0525 15:20:45.215968 23215 solver.cpp:237] Iteration 16650, loss = 1.35988
I0525 15:20:45.216002 23215 solver.cpp:253]     Train net output #0: loss = 1.35988 (* 1 = 1.35988 loss)
I0525 15:20:45.216022 23215 sgd_solver.cpp:106] Iteration 16650, lr = 0.001
I0525 15:20:53.954962 23215 solver.cpp:237] Iteration 16800, loss = 1.38606
I0525 15:20:53.955121 23215 solver.cpp:253]     Train net output #0: loss = 1.38606 (* 1 = 1.38606 loss)
I0525 15:20:53.955135 23215 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0525 15:21:02.693783 23215 solver.cpp:237] Iteration 16950, loss = 1.54491
I0525 15:21:02.693819 23215 solver.cpp:253]     Train net output #0: loss = 1.54491 (* 1 = 1.54491 loss)
I0525 15:21:02.693835 23215 sgd_solver.cpp:106] Iteration 16950, lr = 0.001
I0525 15:21:32.293581 23215 solver.cpp:237] Iteration 17100, loss = 1.3291
I0525 15:21:32.293751 23215 solver.cpp:253]     Train net output #0: loss = 1.3291 (* 1 = 1.3291 loss)
I0525 15:21:32.293766 23215 sgd_solver.cpp:106] Iteration 17100, lr = 0.001
I0525 15:21:41.035598 23215 solver.cpp:237] Iteration 17250, loss = 1.2966
I0525 15:21:41.035634 23215 solver.cpp:253]     Train net output #0: loss = 1.2966 (* 1 = 1.2966 loss)
I0525 15:21:41.035651 23215 sgd_solver.cpp:106] Iteration 17250, lr = 0.001
I0525 15:21:49.771067 23215 solver.cpp:237] Iteration 17400, loss = 1.39033
I0525 15:21:49.771103 23215 solver.cpp:253]     Train net output #0: loss = 1.39033 (* 1 = 1.39033 loss)
I0525 15:21:49.771116 23215 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0525 15:21:58.514396 23215 solver.cpp:237] Iteration 17550, loss = 1.26724
I0525 15:21:58.514443 23215 solver.cpp:253]     Train net output #0: loss = 1.26724 (* 1 = 1.26724 loss)
I0525 15:21:58.514459 23215 sgd_solver.cpp:106] Iteration 17550, lr = 0.001
I0525 15:22:07.254305 23215 solver.cpp:237] Iteration 17700, loss = 1.38759
I0525 15:22:07.254452 23215 solver.cpp:253]     Train net output #0: loss = 1.38759 (* 1 = 1.38759 loss)
I0525 15:22:07.254468 23215 sgd_solver.cpp:106] Iteration 17700, lr = 0.001
I0525 15:22:15.990592 23215 solver.cpp:237] Iteration 17850, loss = 1.56728
I0525 15:22:15.990625 23215 solver.cpp:253]     Train net output #0: loss = 1.56728 (* 1 = 1.56728 loss)
I0525 15:22:15.990643 23215 sgd_solver.cpp:106] Iteration 17850, lr = 0.001
I0525 15:22:24.673128 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_18000.caffemodel
I0525 15:22:24.752239 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_18000.solverstate
I0525 15:22:24.777756 23215 solver.cpp:341] Iteration 18000, Testing net (#0)
I0525 15:23:32.433847 23215 solver.cpp:409]     Test net output #0: accuracy = 0.816434
I0525 15:23:32.434020 23215 solver.cpp:409]     Test net output #1: loss = 0.622107 (* 1 = 0.622107 loss)
I0525 15:23:53.278172 23215 solver.cpp:237] Iteration 18000, loss = 1.31782
I0525 15:23:53.278225 23215 solver.cpp:253]     Train net output #0: loss = 1.31782 (* 1 = 1.31782 loss)
I0525 15:23:53.278240 23215 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0525 15:24:02.014596 23215 solver.cpp:237] Iteration 18150, loss = 1.45886
I0525 15:24:02.014641 23215 solver.cpp:253]     Train net output #0: loss = 1.45886 (* 1 = 1.45886 loss)
I0525 15:24:02.014660 23215 sgd_solver.cpp:106] Iteration 18150, lr = 0.001
I0525 15:24:10.744060 23215 solver.cpp:237] Iteration 18300, loss = 1.61635
I0525 15:24:10.744210 23215 solver.cpp:253]     Train net output #0: loss = 1.61635 (* 1 = 1.61635 loss)
I0525 15:24:10.744223 23215 sgd_solver.cpp:106] Iteration 18300, lr = 0.001
I0525 15:24:19.475642 23215 solver.cpp:237] Iteration 18450, loss = 1.29157
I0525 15:24:19.475677 23215 solver.cpp:253]     Train net output #0: loss = 1.29157 (* 1 = 1.29157 loss)
I0525 15:24:19.475694 23215 sgd_solver.cpp:106] Iteration 18450, lr = 0.001
I0525 15:24:28.211686 23215 solver.cpp:237] Iteration 18600, loss = 1.38446
I0525 15:24:28.211732 23215 solver.cpp:253]     Train net output #0: loss = 1.38446 (* 1 = 1.38446 loss)
I0525 15:24:28.211750 23215 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0525 15:24:36.939151 23215 solver.cpp:237] Iteration 18750, loss = 1.38981
I0525 15:24:36.939185 23215 solver.cpp:253]     Train net output #0: loss = 1.38981 (* 1 = 1.38981 loss)
I0525 15:24:36.939199 23215 sgd_solver.cpp:106] Iteration 18750, lr = 0.001
I0525 15:24:45.669747 23215 solver.cpp:237] Iteration 18900, loss = 1.39839
I0525 15:24:45.669895 23215 solver.cpp:253]     Train net output #0: loss = 1.39839 (* 1 = 1.39839 loss)
I0525 15:24:45.669909 23215 sgd_solver.cpp:106] Iteration 18900, lr = 0.001
I0525 15:25:15.275360 23215 solver.cpp:237] Iteration 19050, loss = 1.35462
I0525 15:25:15.275410 23215 solver.cpp:253]     Train net output #0: loss = 1.35462 (* 1 = 1.35462 loss)
I0525 15:25:15.275424 23215 sgd_solver.cpp:106] Iteration 19050, lr = 0.001
I0525 15:25:24.001842 23215 solver.cpp:237] Iteration 19200, loss = 1.20606
I0525 15:25:24.001994 23215 solver.cpp:253]     Train net output #0: loss = 1.20606 (* 1 = 1.20606 loss)
I0525 15:25:24.002008 23215 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0525 15:25:32.736711 23215 solver.cpp:237] Iteration 19350, loss = 1.44948
I0525 15:25:32.736743 23215 solver.cpp:253]     Train net output #0: loss = 1.44948 (* 1 = 1.44948 loss)
I0525 15:25:32.736762 23215 sgd_solver.cpp:106] Iteration 19350, lr = 0.001
I0525 15:25:41.412806 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_19500.caffemodel
I0525 15:25:41.491464 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_19500.solverstate
I0525 15:25:41.536979 23215 solver.cpp:237] Iteration 19500, loss = 1.44549
I0525 15:25:41.537025 23215 solver.cpp:253]     Train net output #0: loss = 1.44549 (* 1 = 1.44549 loss)
I0525 15:25:41.537050 23215 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0525 15:25:50.268744 23215 solver.cpp:237] Iteration 19650, loss = 1.47655
I0525 15:25:50.268779 23215 solver.cpp:253]     Train net output #0: loss = 1.47655 (* 1 = 1.47655 loss)
I0525 15:25:50.268796 23215 sgd_solver.cpp:106] Iteration 19650, lr = 0.001
I0525 15:25:59.000566 23215 solver.cpp:237] Iteration 19800, loss = 1.4391
I0525 15:25:59.000727 23215 solver.cpp:253]     Train net output #0: loss = 1.4391 (* 1 = 1.4391 loss)
I0525 15:25:59.000741 23215 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0525 15:26:07.733156 23215 solver.cpp:237] Iteration 19950, loss = 1.55779
I0525 15:26:07.733206 23215 solver.cpp:253]     Train net output #0: loss = 1.55779 (* 1 = 1.55779 loss)
I0525 15:26:07.733222 23215 sgd_solver.cpp:106] Iteration 19950, lr = 0.001
I0525 15:26:37.333777 23215 solver.cpp:237] Iteration 20100, loss = 1.43717
I0525 15:26:37.333950 23215 solver.cpp:253]     Train net output #0: loss = 1.43717 (* 1 = 1.43717 loss)
I0525 15:26:37.333964 23215 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0525 15:26:46.066696 23215 solver.cpp:237] Iteration 20250, loss = 1.28099
I0525 15:26:46.066730 23215 solver.cpp:253]     Train net output #0: loss = 1.28099 (* 1 = 1.28099 loss)
I0525 15:26:46.066747 23215 sgd_solver.cpp:106] Iteration 20250, lr = 0.001
I0525 15:26:54.797745 23215 solver.cpp:237] Iteration 20400, loss = 1.38783
I0525 15:26:54.797792 23215 solver.cpp:253]     Train net output #0: loss = 1.38783 (* 1 = 1.38783 loss)
I0525 15:26:54.797808 23215 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0525 15:27:03.526198 23215 solver.cpp:237] Iteration 20550, loss = 1.45865
I0525 15:27:03.526234 23215 solver.cpp:253]     Train net output #0: loss = 1.45865 (* 1 = 1.45865 loss)
I0525 15:27:03.526250 23215 sgd_solver.cpp:106] Iteration 20550, lr = 0.001
I0525 15:27:12.255877 23215 solver.cpp:237] Iteration 20700, loss = 1.28169
I0525 15:27:12.256026 23215 solver.cpp:253]     Train net output #0: loss = 1.28169 (* 1 = 1.28169 loss)
I0525 15:27:12.256039 23215 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0525 15:27:20.991058 23215 solver.cpp:237] Iteration 20850, loss = 1.23888
I0525 15:27:20.991104 23215 solver.cpp:253]     Train net output #0: loss = 1.23888 (* 1 = 1.23888 loss)
I0525 15:27:20.991118 23215 sgd_solver.cpp:106] Iteration 20850, lr = 0.001
I0525 15:27:29.664710 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_21000.caffemodel
I0525 15:27:29.744487 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_21000.solverstate
I0525 15:27:29.771127 23215 solver.cpp:341] Iteration 21000, Testing net (#0)
I0525 15:28:16.331137 23215 solver.cpp:409]     Test net output #0: accuracy = 0.825379
I0525 15:28:16.331305 23215 solver.cpp:409]     Test net output #1: loss = 0.597556 (* 1 = 0.597556 loss)
I0525 15:28:37.236129 23215 solver.cpp:237] Iteration 21000, loss = 1.43
I0525 15:28:37.236182 23215 solver.cpp:253]     Train net output #0: loss = 1.43 (* 1 = 1.43 loss)
I0525 15:28:37.236197 23215 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0525 15:28:45.966931 23215 solver.cpp:237] Iteration 21150, loss = 1.36765
I0525 15:28:45.966965 23215 solver.cpp:253]     Train net output #0: loss = 1.36765 (* 1 = 1.36765 loss)
I0525 15:28:45.966982 23215 sgd_solver.cpp:106] Iteration 21150, lr = 0.001
I0525 15:28:54.699784 23215 solver.cpp:237] Iteration 21300, loss = 1.24976
I0525 15:28:54.699942 23215 solver.cpp:253]     Train net output #0: loss = 1.24976 (* 1 = 1.24976 loss)
I0525 15:28:54.699955 23215 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0525 15:29:03.438832 23215 solver.cpp:237] Iteration 21450, loss = 1.50893
I0525 15:29:03.438870 23215 solver.cpp:253]     Train net output #0: loss = 1.50893 (* 1 = 1.50893 loss)
I0525 15:29:03.438892 23215 sgd_solver.cpp:106] Iteration 21450, lr = 0.001
I0525 15:29:12.182574 23215 solver.cpp:237] Iteration 21600, loss = 1.53658
I0525 15:29:12.182608 23215 solver.cpp:253]     Train net output #0: loss = 1.53658 (* 1 = 1.53658 loss)
I0525 15:29:12.182624 23215 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0525 15:29:20.915802 23215 solver.cpp:237] Iteration 21750, loss = 1.21565
I0525 15:29:20.915838 23215 solver.cpp:253]     Train net output #0: loss = 1.21565 (* 1 = 1.21565 loss)
I0525 15:29:20.915853 23215 sgd_solver.cpp:106] Iteration 21750, lr = 0.001
I0525 15:29:29.653095 23215 solver.cpp:237] Iteration 21900, loss = 1.25902
I0525 15:29:29.653267 23215 solver.cpp:253]     Train net output #0: loss = 1.25902 (* 1 = 1.25902 loss)
I0525 15:29:29.653281 23215 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0525 15:29:59.245517 23215 solver.cpp:237] Iteration 22050, loss = 1.39593
I0525 15:29:59.245566 23215 solver.cpp:253]     Train net output #0: loss = 1.39593 (* 1 = 1.39593 loss)
I0525 15:29:59.245580 23215 sgd_solver.cpp:106] Iteration 22050, lr = 0.001
I0525 15:30:07.975031 23215 solver.cpp:237] Iteration 22200, loss = 1.24339
I0525 15:30:07.975193 23215 solver.cpp:253]     Train net output #0: loss = 1.24339 (* 1 = 1.24339 loss)
I0525 15:30:07.975206 23215 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0525 15:30:16.707633 23215 solver.cpp:237] Iteration 22350, loss = 1.56319
I0525 15:30:16.707675 23215 solver.cpp:253]     Train net output #0: loss = 1.56319 (* 1 = 1.56319 loss)
I0525 15:30:16.707695 23215 sgd_solver.cpp:106] Iteration 22350, lr = 0.001
I0525 15:30:25.393055 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_22500.caffemodel
I0525 15:30:25.473232 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_22500.solverstate
I0525 15:30:25.518525 23215 solver.cpp:237] Iteration 22500, loss = 1.5109
I0525 15:30:25.518574 23215 solver.cpp:253]     Train net output #0: loss = 1.5109 (* 1 = 1.5109 loss)
I0525 15:30:25.518590 23215 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0525 15:30:34.256786 23215 solver.cpp:237] Iteration 22650, loss = 1.2401
I0525 15:30:34.256821 23215 solver.cpp:253]     Train net output #0: loss = 1.2401 (* 1 = 1.2401 loss)
I0525 15:30:34.256839 23215 sgd_solver.cpp:106] Iteration 22650, lr = 0.001
I0525 15:30:42.990016 23215 solver.cpp:237] Iteration 22800, loss = 1.26144
I0525 15:30:42.990187 23215 solver.cpp:253]     Train net output #0: loss = 1.26144 (* 1 = 1.26144 loss)
I0525 15:30:42.990202 23215 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0525 15:30:51.727989 23215 solver.cpp:237] Iteration 22950, loss = 1.48821
I0525 15:30:51.728024 23215 solver.cpp:253]     Train net output #0: loss = 1.48821 (* 1 = 1.48821 loss)
I0525 15:30:51.728040 23215 sgd_solver.cpp:106] Iteration 22950, lr = 0.001
I0525 15:31:21.345739 23215 solver.cpp:237] Iteration 23100, loss = 1.34112
I0525 15:31:21.345911 23215 solver.cpp:253]     Train net output #0: loss = 1.34112 (* 1 = 1.34112 loss)
I0525 15:31:21.345926 23215 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0525 15:31:30.076450 23215 solver.cpp:237] Iteration 23250, loss = 1.35465
I0525 15:31:30.076495 23215 solver.cpp:253]     Train net output #0: loss = 1.35465 (* 1 = 1.35465 loss)
I0525 15:31:30.076511 23215 sgd_solver.cpp:106] Iteration 23250, lr = 0.001
I0525 15:31:38.808430 23215 solver.cpp:237] Iteration 23400, loss = 1.34055
I0525 15:31:38.808466 23215 solver.cpp:253]     Train net output #0: loss = 1.34055 (* 1 = 1.34055 loss)
I0525 15:31:38.808482 23215 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0525 15:31:47.538117 23215 solver.cpp:237] Iteration 23550, loss = 1.25407
I0525 15:31:47.538152 23215 solver.cpp:253]     Train net output #0: loss = 1.25407 (* 1 = 1.25407 loss)
I0525 15:31:47.538167 23215 sgd_solver.cpp:106] Iteration 23550, lr = 0.001
I0525 15:31:56.273406 23215 solver.cpp:237] Iteration 23700, loss = 1.54612
I0525 15:31:56.273568 23215 solver.cpp:253]     Train net output #0: loss = 1.54612 (* 1 = 1.54612 loss)
I0525 15:31:56.273582 23215 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0525 15:32:05.004564 23215 solver.cpp:237] Iteration 23850, loss = 0.896346
I0525 15:32:05.004598 23215 solver.cpp:253]     Train net output #0: loss = 0.896346 (* 1 = 0.896346 loss)
I0525 15:32:05.004616 23215 sgd_solver.cpp:106] Iteration 23850, lr = 0.001
I0525 15:32:13.675704 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_24000.caffemodel
I0525 15:32:13.753895 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_24000.solverstate
I0525 15:32:13.779269 23215 solver.cpp:341] Iteration 24000, Testing net (#0)
I0525 15:33:21.517421 23215 solver.cpp:409]     Test net output #0: accuracy = 0.83146
I0525 15:33:21.517601 23215 solver.cpp:409]     Test net output #1: loss = 0.609494 (* 1 = 0.609494 loss)
I0525 15:33:42.417155 23215 solver.cpp:237] Iteration 24000, loss = 1.23307
I0525 15:33:42.417232 23215 solver.cpp:253]     Train net output #0: loss = 1.23307 (* 1 = 1.23307 loss)
I0525 15:33:42.417249 23215 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0525 15:33:51.141757 23215 solver.cpp:237] Iteration 24150, loss = 1.32568
I0525 15:33:51.141793 23215 solver.cpp:253]     Train net output #0: loss = 1.32568 (* 1 = 1.32568 loss)
I0525 15:33:51.141808 23215 sgd_solver.cpp:106] Iteration 24150, lr = 0.001
I0525 15:33:59.862143 23215 solver.cpp:237] Iteration 24300, loss = 1.35568
I0525 15:33:59.862311 23215 solver.cpp:253]     Train net output #0: loss = 1.35568 (* 1 = 1.35568 loss)
I0525 15:33:59.862325 23215 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0525 15:34:08.585981 23215 solver.cpp:237] Iteration 24450, loss = 1.33097
I0525 15:34:08.586017 23215 solver.cpp:253]     Train net output #0: loss = 1.33097 (* 1 = 1.33097 loss)
I0525 15:34:08.586033 23215 sgd_solver.cpp:106] Iteration 24450, lr = 0.001
I0525 15:34:17.306252 23215 solver.cpp:237] Iteration 24600, loss = 1.36028
I0525 15:34:17.306287 23215 solver.cpp:253]     Train net output #0: loss = 1.36028 (* 1 = 1.36028 loss)
I0525 15:34:17.306303 23215 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0525 15:34:26.028832 23215 solver.cpp:237] Iteration 24750, loss = 1.37789
I0525 15:34:26.028872 23215 solver.cpp:253]     Train net output #0: loss = 1.37789 (* 1 = 1.37789 loss)
I0525 15:34:26.028892 23215 sgd_solver.cpp:106] Iteration 24750, lr = 0.001
I0525 15:34:34.752151 23215 solver.cpp:237] Iteration 24900, loss = 1.36056
I0525 15:34:34.752308 23215 solver.cpp:253]     Train net output #0: loss = 1.36056 (* 1 = 1.36056 loss)
I0525 15:34:34.752321 23215 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0525 15:35:04.348601 23215 solver.cpp:237] Iteration 25050, loss = 1.26507
I0525 15:35:04.348652 23215 solver.cpp:253]     Train net output #0: loss = 1.26507 (* 1 = 1.26507 loss)
I0525 15:35:04.348667 23215 sgd_solver.cpp:106] Iteration 25050, lr = 0.001
I0525 15:35:13.077814 23215 solver.cpp:237] Iteration 25200, loss = 1.3723
I0525 15:35:13.077970 23215 solver.cpp:253]     Train net output #0: loss = 1.3723 (* 1 = 1.3723 loss)
I0525 15:35:13.077985 23215 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0525 15:35:21.804709 23215 solver.cpp:237] Iteration 25350, loss = 1.21101
I0525 15:35:21.804751 23215 solver.cpp:253]     Train net output #0: loss = 1.21101 (* 1 = 1.21101 loss)
I0525 15:35:21.804769 23215 sgd_solver.cpp:106] Iteration 25350, lr = 0.001
I0525 15:35:30.472988 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_25500.caffemodel
I0525 15:35:30.555800 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_25500.solverstate
I0525 15:35:30.599292 23215 solver.cpp:237] Iteration 25500, loss = 1.32983
I0525 15:35:30.599339 23215 solver.cpp:253]     Train net output #0: loss = 1.32983 (* 1 = 1.32983 loss)
I0525 15:35:30.599352 23215 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0525 15:35:39.325285 23215 solver.cpp:237] Iteration 25650, loss = 1.24721
I0525 15:35:39.325327 23215 solver.cpp:253]     Train net output #0: loss = 1.24721 (* 1 = 1.24721 loss)
I0525 15:35:39.325345 23215 sgd_solver.cpp:106] Iteration 25650, lr = 0.001
I0525 15:35:48.046406 23215 solver.cpp:237] Iteration 25800, loss = 1.28238
I0525 15:35:48.046586 23215 solver.cpp:253]     Train net output #0: loss = 1.28238 (* 1 = 1.28238 loss)
I0525 15:35:48.046599 23215 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0525 15:35:56.772951 23215 solver.cpp:237] Iteration 25950, loss = 1.29184
I0525 15:35:56.772985 23215 solver.cpp:253]     Train net output #0: loss = 1.29184 (* 1 = 1.29184 loss)
I0525 15:35:56.773002 23215 sgd_solver.cpp:106] Iteration 25950, lr = 0.001
I0525 15:36:26.371260 23215 solver.cpp:237] Iteration 26100, loss = 1.1804
I0525 15:36:26.371434 23215 solver.cpp:253]     Train net output #0: loss = 1.1804 (* 1 = 1.1804 loss)
I0525 15:36:26.371449 23215 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0525 15:36:35.095168 23215 solver.cpp:237] Iteration 26250, loss = 1.43507
I0525 15:36:35.095204 23215 solver.cpp:253]     Train net output #0: loss = 1.43507 (* 1 = 1.43507 loss)
I0525 15:36:35.095226 23215 sgd_solver.cpp:106] Iteration 26250, lr = 0.001
I0525 15:36:43.819447 23215 solver.cpp:237] Iteration 26400, loss = 1.33361
I0525 15:36:43.819483 23215 solver.cpp:253]     Train net output #0: loss = 1.33361 (* 1 = 1.33361 loss)
I0525 15:36:43.819499 23215 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0525 15:36:52.540323 23215 solver.cpp:237] Iteration 26550, loss = 1.43596
I0525 15:36:52.540359 23215 solver.cpp:253]     Train net output #0: loss = 1.43596 (* 1 = 1.43596 loss)
I0525 15:36:52.540371 23215 sgd_solver.cpp:106] Iteration 26550, lr = 0.001
I0525 15:37:01.259675 23215 solver.cpp:237] Iteration 26700, loss = 1.27499
I0525 15:37:01.259832 23215 solver.cpp:253]     Train net output #0: loss = 1.27499 (* 1 = 1.27499 loss)
I0525 15:37:01.259846 23215 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0525 15:37:09.980814 23215 solver.cpp:237] Iteration 26850, loss = 1.28037
I0525 15:37:09.980849 23215 solver.cpp:253]     Train net output #0: loss = 1.28037 (* 1 = 1.28037 loss)
I0525 15:37:09.980866 23215 sgd_solver.cpp:106] Iteration 26850, lr = 0.001
I0525 15:37:18.647500 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_27000.caffemodel
I0525 15:37:18.725996 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_27000.solverstate
I0525 15:37:18.751497 23215 solver.cpp:341] Iteration 27000, Testing net (#0)
I0525 15:38:05.556576 23215 solver.cpp:409]     Test net output #0: accuracy = 0.842479
I0525 15:38:05.556748 23215 solver.cpp:409]     Test net output #1: loss = 0.592939 (* 1 = 0.592939 loss)
I0525 15:38:26.396309 23215 solver.cpp:237] Iteration 27000, loss = 1.26873
I0525 15:38:26.396361 23215 solver.cpp:253]     Train net output #0: loss = 1.26873 (* 1 = 1.26873 loss)
I0525 15:38:26.396376 23215 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0525 15:38:35.133422 23215 solver.cpp:237] Iteration 27150, loss = 1.26959
I0525 15:38:35.133469 23215 solver.cpp:253]     Train net output #0: loss = 1.26959 (* 1 = 1.26959 loss)
I0525 15:38:35.133483 23215 sgd_solver.cpp:106] Iteration 27150, lr = 0.001
I0525 15:38:43.879009 23215 solver.cpp:237] Iteration 27300, loss = 1.26988
I0525 15:38:43.879160 23215 solver.cpp:253]     Train net output #0: loss = 1.26988 (* 1 = 1.26988 loss)
I0525 15:38:43.879174 23215 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0525 15:38:52.616173 23215 solver.cpp:237] Iteration 27450, loss = 1.2954
I0525 15:38:52.616206 23215 solver.cpp:253]     Train net output #0: loss = 1.2954 (* 1 = 1.2954 loss)
I0525 15:38:52.616224 23215 sgd_solver.cpp:106] Iteration 27450, lr = 0.001
I0525 15:39:01.355197 23215 solver.cpp:237] Iteration 27600, loss = 1.33419
I0525 15:39:01.355247 23215 solver.cpp:253]     Train net output #0: loss = 1.33419 (* 1 = 1.33419 loss)
I0525 15:39:01.355259 23215 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0525 15:39:10.089128 23215 solver.cpp:237] Iteration 27750, loss = 1.37945
I0525 15:39:10.089164 23215 solver.cpp:253]     Train net output #0: loss = 1.37945 (* 1 = 1.37945 loss)
I0525 15:39:10.089180 23215 sgd_solver.cpp:106] Iteration 27750, lr = 0.001
I0525 15:39:18.827072 23215 solver.cpp:237] Iteration 27900, loss = 1.17064
I0525 15:39:18.827235 23215 solver.cpp:253]     Train net output #0: loss = 1.17064 (* 1 = 1.17064 loss)
I0525 15:39:18.827249 23215 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0525 15:39:48.447738 23215 solver.cpp:237] Iteration 28050, loss = 1.19403
I0525 15:39:48.447790 23215 solver.cpp:253]     Train net output #0: loss = 1.19403 (* 1 = 1.19403 loss)
I0525 15:39:48.447803 23215 sgd_solver.cpp:106] Iteration 28050, lr = 0.001
I0525 15:39:57.185994 23215 solver.cpp:237] Iteration 28200, loss = 1.47684
I0525 15:39:57.186159 23215 solver.cpp:253]     Train net output #0: loss = 1.47684 (* 1 = 1.47684 loss)
I0525 15:39:57.186172 23215 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0525 15:40:05.924969 23215 solver.cpp:237] Iteration 28350, loss = 1.07226
I0525 15:40:05.925004 23215 solver.cpp:253]     Train net output #0: loss = 1.07226 (* 1 = 1.07226 loss)
I0525 15:40:05.925021 23215 sgd_solver.cpp:106] Iteration 28350, lr = 0.001
I0525 15:40:14.606503 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_28500.caffemodel
I0525 15:40:14.687574 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_28500.solverstate
I0525 15:40:14.732321 23215 solver.cpp:237] Iteration 28500, loss = 1.41419
I0525 15:40:14.732372 23215 solver.cpp:253]     Train net output #0: loss = 1.41419 (* 1 = 1.41419 loss)
I0525 15:40:14.732385 23215 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0525 15:40:23.472374 23215 solver.cpp:237] Iteration 28650, loss = 1.26292
I0525 15:40:23.472409 23215 solver.cpp:253]     Train net output #0: loss = 1.26292 (* 1 = 1.26292 loss)
I0525 15:40:23.472425 23215 sgd_solver.cpp:106] Iteration 28650, lr = 0.001
I0525 15:40:32.211117 23215 solver.cpp:237] Iteration 28800, loss = 1.26402
I0525 15:40:32.211273 23215 solver.cpp:253]     Train net output #0: loss = 1.26402 (* 1 = 1.26402 loss)
I0525 15:40:32.211287 23215 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0525 15:40:40.946022 23215 solver.cpp:237] Iteration 28950, loss = 1.22269
I0525 15:40:40.946070 23215 solver.cpp:253]     Train net output #0: loss = 1.22269 (* 1 = 1.22269 loss)
I0525 15:40:40.946087 23215 sgd_solver.cpp:106] Iteration 28950, lr = 0.001
I0525 15:41:10.526497 23215 solver.cpp:237] Iteration 29100, loss = 1.20353
I0525 15:41:10.526674 23215 solver.cpp:253]     Train net output #0: loss = 1.20353 (* 1 = 1.20353 loss)
I0525 15:41:10.526687 23215 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0525 15:41:19.259606 23215 solver.cpp:237] Iteration 29250, loss = 1.26957
I0525 15:41:19.259640 23215 solver.cpp:253]     Train net output #0: loss = 1.26957 (* 1 = 1.26957 loss)
I0525 15:41:19.259657 23215 sgd_solver.cpp:106] Iteration 29250, lr = 0.001
I0525 15:41:27.999722 23215 solver.cpp:237] Iteration 29400, loss = 1.12117
I0525 15:41:27.999757 23215 solver.cpp:253]     Train net output #0: loss = 1.12117 (* 1 = 1.12117 loss)
I0525 15:41:27.999770 23215 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0525 15:41:36.739264 23215 solver.cpp:237] Iteration 29550, loss = 1.37499
I0525 15:41:36.739308 23215 solver.cpp:253]     Train net output #0: loss = 1.37499 (* 1 = 1.37499 loss)
I0525 15:41:36.739325 23215 sgd_solver.cpp:106] Iteration 29550, lr = 0.001
I0525 15:41:45.472129 23215 solver.cpp:237] Iteration 29700, loss = 1.40504
I0525 15:41:45.472293 23215 solver.cpp:253]     Train net output #0: loss = 1.40504 (* 1 = 1.40504 loss)
I0525 15:41:45.472307 23215 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0525 15:41:54.209579 23215 solver.cpp:237] Iteration 29850, loss = 1.18093
I0525 15:41:54.209630 23215 solver.cpp:253]     Train net output #0: loss = 1.18093 (* 1 = 1.18093 loss)
I0525 15:41:54.209645 23215 sgd_solver.cpp:106] Iteration 29850, lr = 0.001
I0525 15:42:02.887881 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_30000.caffemodel
I0525 15:42:02.968297 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_30000.solverstate
I0525 15:42:02.995692 23215 solver.cpp:341] Iteration 30000, Testing net (#0)
I0525 15:43:10.795358 23215 solver.cpp:409]     Test net output #0: accuracy = 0.840819
I0525 15:43:10.795531 23215 solver.cpp:409]     Test net output #1: loss = 0.498649 (* 1 = 0.498649 loss)
I0525 15:43:31.694154 23215 solver.cpp:237] Iteration 30000, loss = 1.12725
I0525 15:43:31.694205 23215 solver.cpp:253]     Train net output #0: loss = 1.12725 (* 1 = 1.12725 loss)
I0525 15:43:31.694221 23215 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0525 15:43:40.425657 23215 solver.cpp:237] Iteration 30150, loss = 1.19541
I0525 15:43:40.425699 23215 solver.cpp:253]     Train net output #0: loss = 1.19541 (* 1 = 1.19541 loss)
I0525 15:43:40.425717 23215 sgd_solver.cpp:106] Iteration 30150, lr = 0.001
I0525 15:43:49.154029 23215 solver.cpp:237] Iteration 30300, loss = 1.24054
I0525 15:43:49.154187 23215 solver.cpp:253]     Train net output #0: loss = 1.24054 (* 1 = 1.24054 loss)
I0525 15:43:49.154201 23215 sgd_solver.cpp:106] Iteration 30300, lr = 0.001
I0525 15:43:57.882361 23215 solver.cpp:237] Iteration 30450, loss = 1.15735
I0525 15:43:57.882396 23215 solver.cpp:253]     Train net output #0: loss = 1.15735 (* 1 = 1.15735 loss)
I0525 15:43:57.882413 23215 sgd_solver.cpp:106] Iteration 30450, lr = 0.001
I0525 15:44:06.614850 23215 solver.cpp:237] Iteration 30600, loss = 1.05854
I0525 15:44:06.614891 23215 solver.cpp:253]     Train net output #0: loss = 1.05854 (* 1 = 1.05854 loss)
I0525 15:44:06.614910 23215 sgd_solver.cpp:106] Iteration 30600, lr = 0.001
I0525 15:44:15.346052 23215 solver.cpp:237] Iteration 30750, loss = 1.08942
I0525 15:44:15.346087 23215 solver.cpp:253]     Train net output #0: loss = 1.08942 (* 1 = 1.08942 loss)
I0525 15:44:15.346103 23215 sgd_solver.cpp:106] Iteration 30750, lr = 0.001
I0525 15:44:24.079179 23215 solver.cpp:237] Iteration 30900, loss = 1.3379
I0525 15:44:24.079342 23215 solver.cpp:253]     Train net output #0: loss = 1.3379 (* 1 = 1.3379 loss)
I0525 15:44:24.079356 23215 sgd_solver.cpp:106] Iteration 30900, lr = 0.001
I0525 15:44:53.707654 23215 solver.cpp:237] Iteration 31050, loss = 1.40755
I0525 15:44:53.707703 23215 solver.cpp:253]     Train net output #0: loss = 1.40755 (* 1 = 1.40755 loss)
I0525 15:44:53.707720 23215 sgd_solver.cpp:106] Iteration 31050, lr = 0.001
I0525 15:45:02.436221 23215 solver.cpp:237] Iteration 31200, loss = 1.11297
I0525 15:45:02.436379 23215 solver.cpp:253]     Train net output #0: loss = 1.11297 (* 1 = 1.11297 loss)
I0525 15:45:02.436393 23215 sgd_solver.cpp:106] Iteration 31200, lr = 0.001
I0525 15:45:11.165189 23215 solver.cpp:237] Iteration 31350, loss = 1.41452
I0525 15:45:11.165222 23215 solver.cpp:253]     Train net output #0: loss = 1.41452 (* 1 = 1.41452 loss)
I0525 15:45:11.165240 23215 sgd_solver.cpp:106] Iteration 31350, lr = 0.001
I0525 15:45:19.836242 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_31500.caffemodel
I0525 15:45:19.914861 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_31500.solverstate
I0525 15:45:19.958706 23215 solver.cpp:237] Iteration 31500, loss = 1.04881
I0525 15:45:19.958750 23215 solver.cpp:253]     Train net output #0: loss = 1.04881 (* 1 = 1.04881 loss)
I0525 15:45:19.958765 23215 sgd_solver.cpp:106] Iteration 31500, lr = 0.001
I0525 15:45:28.688568 23215 solver.cpp:237] Iteration 31650, loss = 1.15224
I0525 15:45:28.688599 23215 solver.cpp:253]     Train net output #0: loss = 1.15224 (* 1 = 1.15224 loss)
I0525 15:45:28.688621 23215 sgd_solver.cpp:106] Iteration 31650, lr = 0.001
I0525 15:45:37.419518 23215 solver.cpp:237] Iteration 31800, loss = 1.31475
I0525 15:45:37.419684 23215 solver.cpp:253]     Train net output #0: loss = 1.31475 (* 1 = 1.31475 loss)
I0525 15:45:37.419697 23215 sgd_solver.cpp:106] Iteration 31800, lr = 0.001
I0525 15:45:46.153596 23215 solver.cpp:237] Iteration 31950, loss = 1.3027
I0525 15:45:46.153638 23215 solver.cpp:253]     Train net output #0: loss = 1.3027 (* 1 = 1.3027 loss)
I0525 15:45:46.153656 23215 sgd_solver.cpp:106] Iteration 31950, lr = 0.001
I0525 15:46:15.756628 23215 solver.cpp:237] Iteration 32100, loss = 1.18807
I0525 15:46:15.756803 23215 solver.cpp:253]     Train net output #0: loss = 1.18807 (* 1 = 1.18807 loss)
I0525 15:46:15.756819 23215 sgd_solver.cpp:106] Iteration 32100, lr = 0.001
I0525 15:46:24.488189 23215 solver.cpp:237] Iteration 32250, loss = 1.30224
I0525 15:46:24.488224 23215 solver.cpp:253]     Train net output #0: loss = 1.30224 (* 1 = 1.30224 loss)
I0525 15:46:24.488240 23215 sgd_solver.cpp:106] Iteration 32250, lr = 0.001
I0525 15:46:33.215888 23215 solver.cpp:237] Iteration 32400, loss = 1.40002
I0525 15:46:33.215929 23215 solver.cpp:253]     Train net output #0: loss = 1.40002 (* 1 = 1.40002 loss)
I0525 15:46:33.215950 23215 sgd_solver.cpp:106] Iteration 32400, lr = 0.001
I0525 15:46:41.948933 23215 solver.cpp:237] Iteration 32550, loss = 1.16365
I0525 15:46:41.948968 23215 solver.cpp:253]     Train net output #0: loss = 1.16365 (* 1 = 1.16365 loss)
I0525 15:46:41.948983 23215 sgd_solver.cpp:106] Iteration 32550, lr = 0.001
I0525 15:46:50.679883 23215 solver.cpp:237] Iteration 32700, loss = 1.43
I0525 15:46:50.680038 23215 solver.cpp:253]     Train net output #0: loss = 1.43 (* 1 = 1.43 loss)
I0525 15:46:50.680052 23215 sgd_solver.cpp:106] Iteration 32700, lr = 0.001
I0525 15:46:59.409040 23215 solver.cpp:237] Iteration 32850, loss = 1.44276
I0525 15:46:59.409076 23215 solver.cpp:253]     Train net output #0: loss = 1.44276 (* 1 = 1.44276 loss)
I0525 15:46:59.409097 23215 sgd_solver.cpp:106] Iteration 32850, lr = 0.001
I0525 15:47:08.082705 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_33000.caffemodel
I0525 15:47:08.161499 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_33000.solverstate
I0525 15:47:08.186942 23215 solver.cpp:341] Iteration 33000, Testing net (#0)
I0525 15:47:54.726500 23215 solver.cpp:409]     Test net output #0: accuracy = 0.845792
I0525 15:47:54.726673 23215 solver.cpp:409]     Test net output #1: loss = 0.476082 (* 1 = 0.476082 loss)
I0525 15:48:15.628316 23215 solver.cpp:237] Iteration 33000, loss = 1.20194
I0525 15:48:15.628370 23215 solver.cpp:253]     Train net output #0: loss = 1.20194 (* 1 = 1.20194 loss)
I0525 15:48:15.628386 23215 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0525 15:48:24.356753 23215 solver.cpp:237] Iteration 33150, loss = 1.43446
I0525 15:48:24.356789 23215 solver.cpp:253]     Train net output #0: loss = 1.43446 (* 1 = 1.43446 loss)
I0525 15:48:24.356804 23215 sgd_solver.cpp:106] Iteration 33150, lr = 0.001
I0525 15:48:33.087358 23215 solver.cpp:237] Iteration 33300, loss = 1.29925
I0525 15:48:33.087539 23215 solver.cpp:253]     Train net output #0: loss = 1.29925 (* 1 = 1.29925 loss)
I0525 15:48:33.087553 23215 sgd_solver.cpp:106] Iteration 33300, lr = 0.001
I0525 15:48:41.826453 23215 solver.cpp:237] Iteration 33450, loss = 1.46555
I0525 15:48:41.826491 23215 solver.cpp:253]     Train net output #0: loss = 1.46555 (* 1 = 1.46555 loss)
I0525 15:48:41.826509 23215 sgd_solver.cpp:106] Iteration 33450, lr = 0.001
I0525 15:48:50.555341 23215 solver.cpp:237] Iteration 33600, loss = 1.29013
I0525 15:48:50.555376 23215 solver.cpp:253]     Train net output #0: loss = 1.29013 (* 1 = 1.29013 loss)
I0525 15:48:50.555392 23215 sgd_solver.cpp:106] Iteration 33600, lr = 0.001
I0525 15:48:59.288527 23215 solver.cpp:237] Iteration 33750, loss = 1.1683
I0525 15:48:59.288573 23215 solver.cpp:253]     Train net output #0: loss = 1.1683 (* 1 = 1.1683 loss)
I0525 15:48:59.288589 23215 sgd_solver.cpp:106] Iteration 33750, lr = 0.001
I0525 15:49:08.022898 23215 solver.cpp:237] Iteration 33900, loss = 1.30213
I0525 15:49:08.023057 23215 solver.cpp:253]     Train net output #0: loss = 1.30213 (* 1 = 1.30213 loss)
I0525 15:49:08.023072 23215 sgd_solver.cpp:106] Iteration 33900, lr = 0.001
I0525 15:49:37.649081 23215 solver.cpp:237] Iteration 34050, loss = 1.47309
I0525 15:49:37.649132 23215 solver.cpp:253]     Train net output #0: loss = 1.47309 (* 1 = 1.47309 loss)
I0525 15:49:37.649147 23215 sgd_solver.cpp:106] Iteration 34050, lr = 0.001
I0525 15:49:46.389350 23215 solver.cpp:237] Iteration 34200, loss = 1.40953
I0525 15:49:46.389511 23215 solver.cpp:253]     Train net output #0: loss = 1.40953 (* 1 = 1.40953 loss)
I0525 15:49:46.389525 23215 sgd_solver.cpp:106] Iteration 34200, lr = 0.001
I0525 15:49:55.128582 23215 solver.cpp:237] Iteration 34350, loss = 1.31829
I0525 15:49:55.128626 23215 solver.cpp:253]     Train net output #0: loss = 1.31829 (* 1 = 1.31829 loss)
I0525 15:49:55.128643 23215 sgd_solver.cpp:106] Iteration 34350, lr = 0.001
I0525 15:50:03.799916 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_34500.caffemodel
I0525 15:50:03.877809 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_34500.solverstate
I0525 15:50:03.920945 23215 solver.cpp:237] Iteration 34500, loss = 1.23106
I0525 15:50:03.920992 23215 solver.cpp:253]     Train net output #0: loss = 1.23106 (* 1 = 1.23106 loss)
I0525 15:50:03.921006 23215 sgd_solver.cpp:106] Iteration 34500, lr = 0.001
I0525 15:50:12.652268 23215 solver.cpp:237] Iteration 34650, loss = 1.31103
I0525 15:50:12.652303 23215 solver.cpp:253]     Train net output #0: loss = 1.31103 (* 1 = 1.31103 loss)
I0525 15:50:12.652320 23215 sgd_solver.cpp:106] Iteration 34650, lr = 0.001
I0525 15:50:21.377002 23215 solver.cpp:237] Iteration 34800, loss = 1.24312
I0525 15:50:21.377177 23215 solver.cpp:253]     Train net output #0: loss = 1.24312 (* 1 = 1.24312 loss)
I0525 15:50:21.377189 23215 sgd_solver.cpp:106] Iteration 34800, lr = 0.001
I0525 15:50:30.106022 23215 solver.cpp:237] Iteration 34950, loss = 1.60043
I0525 15:50:30.106056 23215 solver.cpp:253]     Train net output #0: loss = 1.60043 (* 1 = 1.60043 loss)
I0525 15:50:30.106073 23215 sgd_solver.cpp:106] Iteration 34950, lr = 0.001
I0525 15:50:59.714651 23215 solver.cpp:237] Iteration 35100, loss = 1.22273
I0525 15:50:59.714830 23215 solver.cpp:253]     Train net output #0: loss = 1.22273 (* 1 = 1.22273 loss)
I0525 15:50:59.714845 23215 sgd_solver.cpp:106] Iteration 35100, lr = 0.001
I0525 15:51:08.448693 23215 solver.cpp:237] Iteration 35250, loss = 1.28186
I0525 15:51:08.448739 23215 solver.cpp:253]     Train net output #0: loss = 1.28186 (* 1 = 1.28186 loss)
I0525 15:51:08.448753 23215 sgd_solver.cpp:106] Iteration 35250, lr = 0.001
I0525 15:51:17.184204 23215 solver.cpp:237] Iteration 35400, loss = 1.17241
I0525 15:51:17.184239 23215 solver.cpp:253]     Train net output #0: loss = 1.17241 (* 1 = 1.17241 loss)
I0525 15:51:17.184255 23215 sgd_solver.cpp:106] Iteration 35400, lr = 0.001
I0525 15:51:25.917382 23215 solver.cpp:237] Iteration 35550, loss = 1.11899
I0525 15:51:25.917417 23215 solver.cpp:253]     Train net output #0: loss = 1.11899 (* 1 = 1.11899 loss)
I0525 15:51:25.917429 23215 sgd_solver.cpp:106] Iteration 35550, lr = 0.001
I0525 15:51:34.654096 23215 solver.cpp:237] Iteration 35700, loss = 1.45955
I0525 15:51:34.654280 23215 solver.cpp:253]     Train net output #0: loss = 1.45955 (* 1 = 1.45955 loss)
I0525 15:51:34.654294 23215 sgd_solver.cpp:106] Iteration 35700, lr = 0.001
I0525 15:51:43.382436 23215 solver.cpp:237] Iteration 35850, loss = 1.1562
I0525 15:51:43.382469 23215 solver.cpp:253]     Train net output #0: loss = 1.1562 (* 1 = 1.1562 loss)
I0525 15:51:43.382485 23215 sgd_solver.cpp:106] Iteration 35850, lr = 0.001
I0525 15:51:52.063241 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_36000.caffemodel
I0525 15:51:52.154124 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_36000.solverstate
I0525 15:51:52.180661 23215 solver.cpp:341] Iteration 36000, Testing net (#0)
I0525 15:52:59.894629 23215 solver.cpp:409]     Test net output #0: accuracy = 0.852532
I0525 15:52:59.894807 23215 solver.cpp:409]     Test net output #1: loss = 0.481975 (* 1 = 0.481975 loss)
I0525 15:53:20.793236 23215 solver.cpp:237] Iteration 36000, loss = 1.25796
I0525 15:53:20.793288 23215 solver.cpp:253]     Train net output #0: loss = 1.25796 (* 1 = 1.25796 loss)
I0525 15:53:20.793304 23215 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0525 15:53:29.518602 23215 solver.cpp:237] Iteration 36150, loss = 1.34669
I0525 15:53:29.518637 23215 solver.cpp:253]     Train net output #0: loss = 1.34669 (* 1 = 1.34669 loss)
I0525 15:53:29.518653 23215 sgd_solver.cpp:106] Iteration 36150, lr = 0.001
I0525 15:53:38.244462 23215 solver.cpp:237] Iteration 36300, loss = 1.17934
I0525 15:53:38.244635 23215 solver.cpp:253]     Train net output #0: loss = 1.17934 (* 1 = 1.17934 loss)
I0525 15:53:38.244649 23215 sgd_solver.cpp:106] Iteration 36300, lr = 0.001
I0525 15:53:46.971247 23215 solver.cpp:237] Iteration 36450, loss = 1.36963
I0525 15:53:46.971282 23215 solver.cpp:253]     Train net output #0: loss = 1.36963 (* 1 = 1.36963 loss)
I0525 15:53:46.971299 23215 sgd_solver.cpp:106] Iteration 36450, lr = 0.001
I0525 15:53:55.691001 23215 solver.cpp:237] Iteration 36600, loss = 1.15655
I0525 15:53:55.691036 23215 solver.cpp:253]     Train net output #0: loss = 1.15655 (* 1 = 1.15655 loss)
I0525 15:53:55.691052 23215 sgd_solver.cpp:106] Iteration 36600, lr = 0.001
I0525 15:54:04.414906 23215 solver.cpp:237] Iteration 36750, loss = 1.35844
I0525 15:54:04.414950 23215 solver.cpp:253]     Train net output #0: loss = 1.35844 (* 1 = 1.35844 loss)
I0525 15:54:04.414968 23215 sgd_solver.cpp:106] Iteration 36750, lr = 0.001
I0525 15:54:13.135993 23215 solver.cpp:237] Iteration 36900, loss = 1.22817
I0525 15:54:13.136152 23215 solver.cpp:253]     Train net output #0: loss = 1.22817 (* 1 = 1.22817 loss)
I0525 15:54:13.136165 23215 sgd_solver.cpp:106] Iteration 36900, lr = 0.001
I0525 15:54:42.733774 23215 solver.cpp:237] Iteration 37050, loss = 1.14805
I0525 15:54:42.733824 23215 solver.cpp:253]     Train net output #0: loss = 1.14805 (* 1 = 1.14805 loss)
I0525 15:54:42.733840 23215 sgd_solver.cpp:106] Iteration 37050, lr = 0.001
I0525 15:54:51.456835 23215 solver.cpp:237] Iteration 37200, loss = 1.21802
I0525 15:54:51.457005 23215 solver.cpp:253]     Train net output #0: loss = 1.21802 (* 1 = 1.21802 loss)
I0525 15:54:51.457018 23215 sgd_solver.cpp:106] Iteration 37200, lr = 0.001
I0525 15:55:00.182186 23215 solver.cpp:237] Iteration 37350, loss = 1.5472
I0525 15:55:00.182220 23215 solver.cpp:253]     Train net output #0: loss = 1.5472 (* 1 = 1.5472 loss)
I0525 15:55:00.182237 23215 sgd_solver.cpp:106] Iteration 37350, lr = 0.001
I0525 15:55:08.850841 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_37500.caffemodel
I0525 15:55:08.931196 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_37500.solverstate
I0525 15:55:08.976374 23215 solver.cpp:237] Iteration 37500, loss = 1.39307
I0525 15:55:08.976424 23215 solver.cpp:253]     Train net output #0: loss = 1.39307 (* 1 = 1.39307 loss)
I0525 15:55:08.976438 23215 sgd_solver.cpp:106] Iteration 37500, lr = 0.001
I0525 15:55:17.697960 23215 solver.cpp:237] Iteration 37650, loss = 1.21161
I0525 15:55:17.698005 23215 solver.cpp:253]     Train net output #0: loss = 1.21161 (* 1 = 1.21161 loss)
I0525 15:55:17.698022 23215 sgd_solver.cpp:106] Iteration 37650, lr = 0.001
I0525 15:55:26.425854 23215 solver.cpp:237] Iteration 37800, loss = 1.36674
I0525 15:55:26.426028 23215 solver.cpp:253]     Train net output #0: loss = 1.36674 (* 1 = 1.36674 loss)
I0525 15:55:26.426041 23215 sgd_solver.cpp:106] Iteration 37800, lr = 0.001
I0525 15:55:35.149448 23215 solver.cpp:237] Iteration 37950, loss = 1.4956
I0525 15:55:35.149482 23215 solver.cpp:253]     Train net output #0: loss = 1.4956 (* 1 = 1.4956 loss)
I0525 15:55:35.149499 23215 sgd_solver.cpp:106] Iteration 37950, lr = 0.001
I0525 15:56:04.743435 23215 solver.cpp:237] Iteration 38100, loss = 1.27739
I0525 15:56:04.743613 23215 solver.cpp:253]     Train net output #0: loss = 1.27739 (* 1 = 1.27739 loss)
I0525 15:56:04.743628 23215 sgd_solver.cpp:106] Iteration 38100, lr = 0.001
I0525 15:56:13.469338 23215 solver.cpp:237] Iteration 38250, loss = 1.32908
I0525 15:56:13.469372 23215 solver.cpp:253]     Train net output #0: loss = 1.32908 (* 1 = 1.32908 loss)
I0525 15:56:13.469390 23215 sgd_solver.cpp:106] Iteration 38250, lr = 0.001
I0525 15:56:22.196262 23215 solver.cpp:237] Iteration 38400, loss = 1.14605
I0525 15:56:22.196297 23215 solver.cpp:253]     Train net output #0: loss = 1.14605 (* 1 = 1.14605 loss)
I0525 15:56:22.196313 23215 sgd_solver.cpp:106] Iteration 38400, lr = 0.001
I0525 15:56:30.921295 23215 solver.cpp:237] Iteration 38550, loss = 1.41214
I0525 15:56:30.921334 23215 solver.cpp:253]     Train net output #0: loss = 1.41214 (* 1 = 1.41214 loss)
I0525 15:56:30.921355 23215 sgd_solver.cpp:106] Iteration 38550, lr = 0.001
I0525 15:56:39.645428 23215 solver.cpp:237] Iteration 38700, loss = 1.40442
I0525 15:56:39.645586 23215 solver.cpp:253]     Train net output #0: loss = 1.40442 (* 1 = 1.40442 loss)
I0525 15:56:39.645598 23215 sgd_solver.cpp:106] Iteration 38700, lr = 0.001
I0525 15:56:48.365474 23215 solver.cpp:237] Iteration 38850, loss = 1.12917
I0525 15:56:48.365509 23215 solver.cpp:253]     Train net output #0: loss = 1.12917 (* 1 = 1.12917 loss)
I0525 15:56:48.365527 23215 sgd_solver.cpp:106] Iteration 38850, lr = 0.001
I0525 15:56:57.032852 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_39000.caffemodel
I0525 15:56:57.110973 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_39000.solverstate
I0525 15:56:57.136636 23215 solver.cpp:341] Iteration 39000, Testing net (#0)
I0525 15:57:43.998214 23215 solver.cpp:409]     Test net output #0: accuracy = 0.851859
I0525 15:57:43.998381 23215 solver.cpp:409]     Test net output #1: loss = 0.487067 (* 1 = 0.487067 loss)
I0525 15:58:04.899147 23215 solver.cpp:237] Iteration 39000, loss = 1.32464
I0525 15:58:04.899200 23215 solver.cpp:253]     Train net output #0: loss = 1.32464 (* 1 = 1.32464 loss)
I0525 15:58:04.899214 23215 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0525 15:58:13.631670 23215 solver.cpp:237] Iteration 39150, loss = 1.02664
I0525 15:58:13.631710 23215 solver.cpp:253]     Train net output #0: loss = 1.02664 (* 1 = 1.02664 loss)
I0525 15:58:13.631731 23215 sgd_solver.cpp:106] Iteration 39150, lr = 0.001
I0525 15:58:22.373606 23215 solver.cpp:237] Iteration 39300, loss = 1.27754
I0525 15:58:22.373783 23215 solver.cpp:253]     Train net output #0: loss = 1.27754 (* 1 = 1.27754 loss)
I0525 15:58:22.373796 23215 sgd_solver.cpp:106] Iteration 39300, lr = 0.001
I0525 15:58:31.115501 23215 solver.cpp:237] Iteration 39450, loss = 1.44521
I0525 15:58:31.115535 23215 solver.cpp:253]     Train net output #0: loss = 1.44521 (* 1 = 1.44521 loss)
I0525 15:58:31.115553 23215 sgd_solver.cpp:106] Iteration 39450, lr = 0.001
I0525 15:58:39.849973 23215 solver.cpp:237] Iteration 39600, loss = 1.35062
I0525 15:58:39.850018 23215 solver.cpp:253]     Train net output #0: loss = 1.35062 (* 1 = 1.35062 loss)
I0525 15:58:39.850036 23215 sgd_solver.cpp:106] Iteration 39600, lr = 0.001
I0525 15:58:48.581013 23215 solver.cpp:237] Iteration 39750, loss = 1.23837
I0525 15:58:48.581054 23215 solver.cpp:253]     Train net output #0: loss = 1.23837 (* 1 = 1.23837 loss)
I0525 15:58:48.581068 23215 sgd_solver.cpp:106] Iteration 39750, lr = 0.001
I0525 15:58:57.314906 23215 solver.cpp:237] Iteration 39900, loss = 1.35048
I0525 15:58:57.315068 23215 solver.cpp:253]     Train net output #0: loss = 1.35048 (* 1 = 1.35048 loss)
I0525 15:58:57.315081 23215 sgd_solver.cpp:106] Iteration 39900, lr = 0.001
I0525 15:59:26.895634 23215 solver.cpp:237] Iteration 40050, loss = 1.38754
I0525 15:59:26.895684 23215 solver.cpp:253]     Train net output #0: loss = 1.38754 (* 1 = 1.38754 loss)
I0525 15:59:26.895701 23215 sgd_solver.cpp:106] Iteration 40050, lr = 0.001
I0525 15:59:35.631716 23215 solver.cpp:237] Iteration 40200, loss = 1.30004
I0525 15:59:35.631881 23215 solver.cpp:253]     Train net output #0: loss = 1.30004 (* 1 = 1.30004 loss)
I0525 15:59:35.631896 23215 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0525 15:59:44.365773 23215 solver.cpp:237] Iteration 40350, loss = 1.20269
I0525 15:59:44.365808 23215 solver.cpp:253]     Train net output #0: loss = 1.20269 (* 1 = 1.20269 loss)
I0525 15:59:44.365825 23215 sgd_solver.cpp:106] Iteration 40350, lr = 0.001
I0525 15:59:53.045464 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_40500.caffemodel
I0525 15:59:53.123700 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_40500.solverstate
I0525 15:59:53.166772 23215 solver.cpp:237] Iteration 40500, loss = 1.23197
I0525 15:59:53.166817 23215 solver.cpp:253]     Train net output #0: loss = 1.23197 (* 1 = 1.23197 loss)
I0525 15:59:53.166831 23215 sgd_solver.cpp:106] Iteration 40500, lr = 0.001
I0525 16:00:01.902067 23215 solver.cpp:237] Iteration 40650, loss = 1.05772
I0525 16:00:01.902103 23215 solver.cpp:253]     Train net output #0: loss = 1.05772 (* 1 = 1.05772 loss)
I0525 16:00:01.902118 23215 sgd_solver.cpp:106] Iteration 40650, lr = 0.001
I0525 16:00:10.640269 23215 solver.cpp:237] Iteration 40800, loss = 1.12917
I0525 16:00:10.640431 23215 solver.cpp:253]     Train net output #0: loss = 1.12917 (* 1 = 1.12917 loss)
I0525 16:00:10.640445 23215 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0525 16:00:19.378310 23215 solver.cpp:237] Iteration 40950, loss = 1.19157
I0525 16:00:19.378355 23215 solver.cpp:253]     Train net output #0: loss = 1.19157 (* 1 = 1.19157 loss)
I0525 16:00:19.378371 23215 sgd_solver.cpp:106] Iteration 40950, lr = 0.001
I0525 16:00:49.001977 23215 solver.cpp:237] Iteration 41100, loss = 1.23606
I0525 16:00:49.002161 23215 solver.cpp:253]     Train net output #0: loss = 1.23606 (* 1 = 1.23606 loss)
I0525 16:00:49.002174 23215 sgd_solver.cpp:106] Iteration 41100, lr = 0.001
I0525 16:00:57.738744 23215 solver.cpp:237] Iteration 41250, loss = 1.4315
I0525 16:00:57.738778 23215 solver.cpp:253]     Train net output #0: loss = 1.4315 (* 1 = 1.4315 loss)
I0525 16:00:57.738795 23215 sgd_solver.cpp:106] Iteration 41250, lr = 0.001
I0525 16:01:06.478922 23215 solver.cpp:237] Iteration 41400, loss = 1.27216
I0525 16:01:06.478966 23215 solver.cpp:253]     Train net output #0: loss = 1.27216 (* 1 = 1.27216 loss)
I0525 16:01:06.478983 23215 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0525 16:01:15.217974 23215 solver.cpp:237] Iteration 41550, loss = 1.34271
I0525 16:01:15.218009 23215 solver.cpp:253]     Train net output #0: loss = 1.34271 (* 1 = 1.34271 loss)
I0525 16:01:15.218027 23215 sgd_solver.cpp:106] Iteration 41550, lr = 0.001
I0525 16:01:23.955289 23215 solver.cpp:237] Iteration 41700, loss = 1.2571
I0525 16:01:23.955461 23215 solver.cpp:253]     Train net output #0: loss = 1.2571 (* 1 = 1.2571 loss)
I0525 16:01:23.955474 23215 sgd_solver.cpp:106] Iteration 41700, lr = 0.001
I0525 16:01:32.695890 23215 solver.cpp:237] Iteration 41850, loss = 1.22462
I0525 16:01:32.695931 23215 solver.cpp:253]     Train net output #0: loss = 1.22462 (* 1 = 1.22462 loss)
I0525 16:01:32.695952 23215 sgd_solver.cpp:106] Iteration 41850, lr = 0.001
I0525 16:01:41.375556 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_42000.caffemodel
I0525 16:01:41.454270 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_42000.solverstate
I0525 16:01:41.479701 23215 solver.cpp:341] Iteration 42000, Testing net (#0)
I0525 16:02:49.218549 23215 solver.cpp:409]     Test net output #0: accuracy = 0.858012
I0525 16:02:49.218730 23215 solver.cpp:409]     Test net output #1: loss = 0.480969 (* 1 = 0.480969 loss)
I0525 16:03:10.090888 23215 solver.cpp:237] Iteration 42000, loss = 1.31535
I0525 16:03:10.090941 23215 solver.cpp:253]     Train net output #0: loss = 1.31535 (* 1 = 1.31535 loss)
I0525 16:03:10.090956 23215 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0525 16:03:18.822741 23215 solver.cpp:237] Iteration 42150, loss = 1.08115
I0525 16:03:18.822774 23215 solver.cpp:253]     Train net output #0: loss = 1.08115 (* 1 = 1.08115 loss)
I0525 16:03:18.822793 23215 sgd_solver.cpp:106] Iteration 42150, lr = 0.001
I0525 16:03:27.550052 23215 solver.cpp:237] Iteration 42300, loss = 1.16236
I0525 16:03:27.550221 23215 solver.cpp:253]     Train net output #0: loss = 1.16236 (* 1 = 1.16236 loss)
I0525 16:03:27.550235 23215 sgd_solver.cpp:106] Iteration 42300, lr = 0.001
I0525 16:03:36.281944 23215 solver.cpp:237] Iteration 42450, loss = 1.42698
I0525 16:03:36.281986 23215 solver.cpp:253]     Train net output #0: loss = 1.42698 (* 1 = 1.42698 loss)
I0525 16:03:36.282001 23215 sgd_solver.cpp:106] Iteration 42450, lr = 0.001
I0525 16:03:45.007935 23215 solver.cpp:237] Iteration 42600, loss = 1.44125
I0525 16:03:45.007969 23215 solver.cpp:253]     Train net output #0: loss = 1.44125 (* 1 = 1.44125 loss)
I0525 16:03:45.007985 23215 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0525 16:03:53.737152 23215 solver.cpp:237] Iteration 42750, loss = 1.17586
I0525 16:03:53.737188 23215 solver.cpp:253]     Train net output #0: loss = 1.17586 (* 1 = 1.17586 loss)
I0525 16:03:53.737203 23215 sgd_solver.cpp:106] Iteration 42750, lr = 0.001
I0525 16:04:02.465354 23215 solver.cpp:237] Iteration 42900, loss = 1.0725
I0525 16:04:02.465530 23215 solver.cpp:253]     Train net output #0: loss = 1.0725 (* 1 = 1.0725 loss)
I0525 16:04:02.465544 23215 sgd_solver.cpp:106] Iteration 42900, lr = 0.001
I0525 16:04:32.103066 23215 solver.cpp:237] Iteration 43050, loss = 1.14599
I0525 16:04:32.103114 23215 solver.cpp:253]     Train net output #0: loss = 1.14599 (* 1 = 1.14599 loss)
I0525 16:04:32.103132 23215 sgd_solver.cpp:106] Iteration 43050, lr = 0.001
I0525 16:04:40.835904 23215 solver.cpp:237] Iteration 43200, loss = 1.37243
I0525 16:04:40.836081 23215 solver.cpp:253]     Train net output #0: loss = 1.37243 (* 1 = 1.37243 loss)
I0525 16:04:40.836096 23215 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0525 16:04:49.566738 23215 solver.cpp:237] Iteration 43350, loss = 1.14376
I0525 16:04:49.566783 23215 solver.cpp:253]     Train net output #0: loss = 1.14376 (* 1 = 1.14376 loss)
I0525 16:04:49.566800 23215 sgd_solver.cpp:106] Iteration 43350, lr = 0.001
I0525 16:04:58.248244 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_43500.caffemodel
I0525 16:04:58.328781 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_43500.solverstate
I0525 16:04:58.373908 23215 solver.cpp:237] Iteration 43500, loss = 1.36227
I0525 16:04:58.373957 23215 solver.cpp:253]     Train net output #0: loss = 1.36227 (* 1 = 1.36227 loss)
I0525 16:04:58.373971 23215 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I0525 16:05:07.106050 23215 solver.cpp:237] Iteration 43650, loss = 1.14927
I0525 16:05:07.106086 23215 solver.cpp:253]     Train net output #0: loss = 1.14927 (* 1 = 1.14927 loss)
I0525 16:05:07.106099 23215 sgd_solver.cpp:106] Iteration 43650, lr = 0.001
I0525 16:05:15.839790 23215 solver.cpp:237] Iteration 43800, loss = 1.46885
I0525 16:05:15.839974 23215 solver.cpp:253]     Train net output #0: loss = 1.46885 (* 1 = 1.46885 loss)
I0525 16:05:15.839988 23215 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0525 16:05:24.571084 23215 solver.cpp:237] Iteration 43950, loss = 1.48314
I0525 16:05:24.571120 23215 solver.cpp:253]     Train net output #0: loss = 1.48314 (* 1 = 1.48314 loss)
I0525 16:05:24.571135 23215 sgd_solver.cpp:106] Iteration 43950, lr = 0.001
I0525 16:05:54.187067 23215 solver.cpp:237] Iteration 44100, loss = 1.12251
I0525 16:05:54.187252 23215 solver.cpp:253]     Train net output #0: loss = 1.12251 (* 1 = 1.12251 loss)
I0525 16:05:54.187266 23215 sgd_solver.cpp:106] Iteration 44100, lr = 0.001
I0525 16:06:02.915055 23215 solver.cpp:237] Iteration 44250, loss = 1.28911
I0525 16:06:02.915091 23215 solver.cpp:253]     Train net output #0: loss = 1.28911 (* 1 = 1.28911 loss)
I0525 16:06:02.915104 23215 sgd_solver.cpp:106] Iteration 44250, lr = 0.001
I0525 16:06:11.648097 23215 solver.cpp:237] Iteration 44400, loss = 1.43167
I0525 16:06:11.648138 23215 solver.cpp:253]     Train net output #0: loss = 1.43167 (* 1 = 1.43167 loss)
I0525 16:06:11.648156 23215 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0525 16:06:20.380723 23215 solver.cpp:237] Iteration 44550, loss = 1.24296
I0525 16:06:20.380759 23215 solver.cpp:253]     Train net output #0: loss = 1.24296 (* 1 = 1.24296 loss)
I0525 16:06:20.380775 23215 sgd_solver.cpp:106] Iteration 44550, lr = 0.001
I0525 16:06:29.107581 23215 solver.cpp:237] Iteration 44700, loss = 1.30633
I0525 16:06:29.107753 23215 solver.cpp:253]     Train net output #0: loss = 1.30633 (* 1 = 1.30633 loss)
I0525 16:06:29.107766 23215 sgd_solver.cpp:106] Iteration 44700, lr = 0.001
I0525 16:06:37.837266 23215 solver.cpp:237] Iteration 44850, loss = 1.24007
I0525 16:06:37.837301 23215 solver.cpp:253]     Train net output #0: loss = 1.24007 (* 1 = 1.24007 loss)
I0525 16:06:37.837318 23215 sgd_solver.cpp:106] Iteration 44850, lr = 0.001
I0525 16:06:46.504933 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_45000.caffemodel
I0525 16:06:46.584986 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_45000.solverstate
I0525 16:06:46.612568 23215 solver.cpp:341] Iteration 45000, Testing net (#0)
I0525 16:07:33.141507 23215 solver.cpp:409]     Test net output #0: accuracy = 0.859892
I0525 16:07:33.141700 23215 solver.cpp:409]     Test net output #1: loss = 0.46096 (* 1 = 0.46096 loss)
I0525 16:07:53.990962 23215 solver.cpp:237] Iteration 45000, loss = 1.36958
I0525 16:07:53.991014 23215 solver.cpp:253]     Train net output #0: loss = 1.36958 (* 1 = 1.36958 loss)
I0525 16:07:53.991030 23215 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0525 16:08:02.726425 23215 solver.cpp:237] Iteration 45150, loss = 1.02176
I0525 16:08:02.726460 23215 solver.cpp:253]     Train net output #0: loss = 1.02176 (* 1 = 1.02176 loss)
I0525 16:08:02.726477 23215 sgd_solver.cpp:106] Iteration 45150, lr = 0.001
I0525 16:08:11.457607 23215 solver.cpp:237] Iteration 45300, loss = 1.14505
I0525 16:08:11.457782 23215 solver.cpp:253]     Train net output #0: loss = 1.14505 (* 1 = 1.14505 loss)
I0525 16:08:11.457795 23215 sgd_solver.cpp:106] Iteration 45300, lr = 0.001
I0525 16:08:20.190893 23215 solver.cpp:237] Iteration 45450, loss = 1.13722
I0525 16:08:20.190927 23215 solver.cpp:253]     Train net output #0: loss = 1.13722 (* 1 = 1.13722 loss)
I0525 16:08:20.190944 23215 sgd_solver.cpp:106] Iteration 45450, lr = 0.001
I0525 16:08:28.920558 23215 solver.cpp:237] Iteration 45600, loss = 1.34094
I0525 16:08:28.920594 23215 solver.cpp:253]     Train net output #0: loss = 1.34094 (* 1 = 1.34094 loss)
I0525 16:08:28.920609 23215 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0525 16:08:37.656119 23215 solver.cpp:237] Iteration 45750, loss = 1.08243
I0525 16:08:37.656159 23215 solver.cpp:253]     Train net output #0: loss = 1.08243 (* 1 = 1.08243 loss)
I0525 16:08:37.656177 23215 sgd_solver.cpp:106] Iteration 45750, lr = 0.001
I0525 16:08:46.385149 23215 solver.cpp:237] Iteration 45900, loss = 1.14415
I0525 16:08:46.385311 23215 solver.cpp:253]     Train net output #0: loss = 1.14415 (* 1 = 1.14415 loss)
I0525 16:08:46.385324 23215 sgd_solver.cpp:106] Iteration 45900, lr = 0.001
I0525 16:09:15.972098 23215 solver.cpp:237] Iteration 46050, loss = 1.31837
I0525 16:09:15.972147 23215 solver.cpp:253]     Train net output #0: loss = 1.31837 (* 1 = 1.31837 loss)
I0525 16:09:15.972164 23215 sgd_solver.cpp:106] Iteration 46050, lr = 0.001
I0525 16:09:24.704504 23215 solver.cpp:237] Iteration 46200, loss = 1.04977
I0525 16:09:24.704684 23215 solver.cpp:253]     Train net output #0: loss = 1.04977 (* 1 = 1.04977 loss)
I0525 16:09:24.704699 23215 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0525 16:09:33.430210 23215 solver.cpp:237] Iteration 46350, loss = 1.47608
I0525 16:09:33.430244 23215 solver.cpp:253]     Train net output #0: loss = 1.47608 (* 1 = 1.47608 loss)
I0525 16:09:33.430261 23215 sgd_solver.cpp:106] Iteration 46350, lr = 0.001
I0525 16:09:42.108084 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_46500.caffemodel
I0525 16:09:42.186123 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_46500.solverstate
I0525 16:09:42.229671 23215 solver.cpp:237] Iteration 46500, loss = 1.09114
I0525 16:09:42.229714 23215 solver.cpp:253]     Train net output #0: loss = 1.09114 (* 1 = 1.09114 loss)
I0525 16:09:42.229732 23215 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I0525 16:09:50.966786 23215 solver.cpp:237] Iteration 46650, loss = 1.16116
I0525 16:09:50.966827 23215 solver.cpp:253]     Train net output #0: loss = 1.16116 (* 1 = 1.16116 loss)
I0525 16:09:50.966845 23215 sgd_solver.cpp:106] Iteration 46650, lr = 0.001
I0525 16:09:59.703850 23215 solver.cpp:237] Iteration 46800, loss = 1.22512
I0525 16:09:59.704018 23215 solver.cpp:253]     Train net output #0: loss = 1.22512 (* 1 = 1.22512 loss)
I0525 16:09:59.704031 23215 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0525 16:10:08.442705 23215 solver.cpp:237] Iteration 46950, loss = 1.34072
I0525 16:10:08.442739 23215 solver.cpp:253]     Train net output #0: loss = 1.34072 (* 1 = 1.34072 loss)
I0525 16:10:08.442756 23215 sgd_solver.cpp:106] Iteration 46950, lr = 0.001
I0525 16:10:37.993109 23215 solver.cpp:237] Iteration 47100, loss = 1.16326
I0525 16:10:37.993306 23215 solver.cpp:253]     Train net output #0: loss = 1.16326 (* 1 = 1.16326 loss)
I0525 16:10:37.993320 23215 sgd_solver.cpp:106] Iteration 47100, lr = 0.001
I0525 16:10:46.728126 23215 solver.cpp:237] Iteration 47250, loss = 1.18161
I0525 16:10:46.728164 23215 solver.cpp:253]     Train net output #0: loss = 1.18161 (* 1 = 1.18161 loss)
I0525 16:10:46.728186 23215 sgd_solver.cpp:106] Iteration 47250, lr = 0.001
I0525 16:10:55.462335 23215 solver.cpp:237] Iteration 47400, loss = 1.18157
I0525 16:10:55.462371 23215 solver.cpp:253]     Train net output #0: loss = 1.18157 (* 1 = 1.18157 loss)
I0525 16:10:55.462386 23215 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0525 16:11:04.195683 23215 solver.cpp:237] Iteration 47550, loss = 1.23854
I0525 16:11:04.195734 23215 solver.cpp:253]     Train net output #0: loss = 1.23854 (* 1 = 1.23854 loss)
I0525 16:11:04.195747 23215 sgd_solver.cpp:106] Iteration 47550, lr = 0.001
I0525 16:11:12.925077 23215 solver.cpp:237] Iteration 47700, loss = 1.20318
I0525 16:11:12.925247 23215 solver.cpp:253]     Train net output #0: loss = 1.20318 (* 1 = 1.20318 loss)
I0525 16:11:12.925261 23215 sgd_solver.cpp:106] Iteration 47700, lr = 0.001
I0525 16:11:21.654362 23215 solver.cpp:237] Iteration 47850, loss = 1.3205
I0525 16:11:21.654397 23215 solver.cpp:253]     Train net output #0: loss = 1.3205 (* 1 = 1.3205 loss)
I0525 16:11:21.654410 23215 sgd_solver.cpp:106] Iteration 47850, lr = 0.001
I0525 16:11:30.327164 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_48000.caffemodel
I0525 16:11:30.406103 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_48000.solverstate
I0525 16:11:30.431860 23215 solver.cpp:341] Iteration 48000, Testing net (#0)
I0525 16:12:38.153661 23215 solver.cpp:409]     Test net output #0: accuracy = 0.859919
I0525 16:12:38.153846 23215 solver.cpp:409]     Test net output #1: loss = 0.449846 (* 1 = 0.449846 loss)
I0525 16:12:59.037245 23215 solver.cpp:237] Iteration 48000, loss = 1.23125
I0525 16:12:59.037297 23215 solver.cpp:253]     Train net output #0: loss = 1.23125 (* 1 = 1.23125 loss)
I0525 16:12:59.037312 23215 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0525 16:13:07.761836 23215 solver.cpp:237] Iteration 48150, loss = 1.298
I0525 16:13:07.761869 23215 solver.cpp:253]     Train net output #0: loss = 1.298 (* 1 = 1.298 loss)
I0525 16:13:07.761888 23215 sgd_solver.cpp:106] Iteration 48150, lr = 0.001
I0525 16:13:16.487735 23215 solver.cpp:237] Iteration 48300, loss = 1.20624
I0525 16:13:16.487918 23215 solver.cpp:253]     Train net output #0: loss = 1.20624 (* 1 = 1.20624 loss)
I0525 16:13:16.487932 23215 sgd_solver.cpp:106] Iteration 48300, lr = 0.001
I0525 16:13:25.214293 23215 solver.cpp:237] Iteration 48450, loss = 1.15199
I0525 16:13:25.214328 23215 solver.cpp:253]     Train net output #0: loss = 1.15199 (* 1 = 1.15199 loss)
I0525 16:13:25.214345 23215 sgd_solver.cpp:106] Iteration 48450, lr = 0.001
I0525 16:13:33.938644 23215 solver.cpp:237] Iteration 48600, loss = 1.30455
I0525 16:13:33.938691 23215 solver.cpp:253]     Train net output #0: loss = 1.30455 (* 1 = 1.30455 loss)
I0525 16:13:33.938705 23215 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0525 16:13:42.663671 23215 solver.cpp:237] Iteration 48750, loss = 1.42868
I0525 16:13:42.663707 23215 solver.cpp:253]     Train net output #0: loss = 1.42868 (* 1 = 1.42868 loss)
I0525 16:13:42.663723 23215 sgd_solver.cpp:106] Iteration 48750, lr = 0.001
I0525 16:13:51.383219 23215 solver.cpp:237] Iteration 48900, loss = 1.42184
I0525 16:13:51.383385 23215 solver.cpp:253]     Train net output #0: loss = 1.42184 (* 1 = 1.42184 loss)
I0525 16:13:51.383399 23215 sgd_solver.cpp:106] Iteration 48900, lr = 0.001
I0525 16:14:20.966519 23215 solver.cpp:237] Iteration 49050, loss = 1.28765
I0525 16:14:20.966569 23215 solver.cpp:253]     Train net output #0: loss = 1.28765 (* 1 = 1.28765 loss)
I0525 16:14:20.966585 23215 sgd_solver.cpp:106] Iteration 49050, lr = 0.001
I0525 16:14:29.692196 23215 solver.cpp:237] Iteration 49200, loss = 1.12417
I0525 16:14:29.692391 23215 solver.cpp:253]     Train net output #0: loss = 1.12417 (* 1 = 1.12417 loss)
I0525 16:14:29.692405 23215 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0525 16:14:38.415446 23215 solver.cpp:237] Iteration 49350, loss = 1.32942
I0525 16:14:38.415480 23215 solver.cpp:253]     Train net output #0: loss = 1.32942 (* 1 = 1.32942 loss)
I0525 16:14:38.415498 23215 sgd_solver.cpp:106] Iteration 49350, lr = 0.001
I0525 16:14:47.083220 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_49500.caffemodel
I0525 16:14:47.162513 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_49500.solverstate
I0525 16:14:47.207418 23215 solver.cpp:237] Iteration 49500, loss = 1.19815
I0525 16:14:47.207468 23215 solver.cpp:253]     Train net output #0: loss = 1.19815 (* 1 = 1.19815 loss)
I0525 16:14:47.207482 23215 sgd_solver.cpp:106] Iteration 49500, lr = 0.001
I0525 16:14:55.936823 23215 solver.cpp:237] Iteration 49650, loss = 1.09502
I0525 16:14:55.936862 23215 solver.cpp:253]     Train net output #0: loss = 1.09502 (* 1 = 1.09502 loss)
I0525 16:14:55.936883 23215 sgd_solver.cpp:106] Iteration 49650, lr = 0.001
I0525 16:15:04.659420 23215 solver.cpp:237] Iteration 49800, loss = 1.38054
I0525 16:15:04.659592 23215 solver.cpp:253]     Train net output #0: loss = 1.38054 (* 1 = 1.38054 loss)
I0525 16:15:04.659606 23215 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0525 16:15:13.384873 23215 solver.cpp:237] Iteration 49950, loss = 1.16508
I0525 16:15:13.384908 23215 solver.cpp:253]     Train net output #0: loss = 1.16508 (* 1 = 1.16508 loss)
I0525 16:15:13.384927 23215 sgd_solver.cpp:106] Iteration 49950, lr = 0.001
I0525 16:15:42.988821 23215 solver.cpp:237] Iteration 50100, loss = 1.17455
I0525 16:15:42.989007 23215 solver.cpp:253]     Train net output #0: loss = 1.17455 (* 1 = 1.17455 loss)
I0525 16:15:42.989022 23215 sgd_solver.cpp:106] Iteration 50100, lr = 0.001
I0525 16:15:51.712888 23215 solver.cpp:237] Iteration 50250, loss = 1.37087
I0525 16:15:51.712923 23215 solver.cpp:253]     Train net output #0: loss = 1.37087 (* 1 = 1.37087 loss)
I0525 16:15:51.712939 23215 sgd_solver.cpp:106] Iteration 50250, lr = 0.001
I0525 16:16:00.444692 23215 solver.cpp:237] Iteration 50400, loss = 1.2461
I0525 16:16:00.444728 23215 solver.cpp:253]     Train net output #0: loss = 1.2461 (* 1 = 1.2461 loss)
I0525 16:16:00.444743 23215 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0525 16:16:09.166944 23215 solver.cpp:237] Iteration 50550, loss = 1.26206
I0525 16:16:09.166990 23215 solver.cpp:253]     Train net output #0: loss = 1.26206 (* 1 = 1.26206 loss)
I0525 16:16:09.167006 23215 sgd_solver.cpp:106] Iteration 50550, lr = 0.001
I0525 16:16:17.894882 23215 solver.cpp:237] Iteration 50700, loss = 1.33977
I0525 16:16:17.895048 23215 solver.cpp:253]     Train net output #0: loss = 1.33977 (* 1 = 1.33977 loss)
I0525 16:16:17.895061 23215 sgd_solver.cpp:106] Iteration 50700, lr = 0.001
I0525 16:16:26.621109 23215 solver.cpp:237] Iteration 50850, loss = 1.23366
I0525 16:16:26.621143 23215 solver.cpp:253]     Train net output #0: loss = 1.23366 (* 1 = 1.23366 loss)
I0525 16:16:26.621160 23215 sgd_solver.cpp:106] Iteration 50850, lr = 0.001
I0525 16:16:35.287459 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_51000.caffemodel
I0525 16:16:35.366487 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_51000.solverstate
I0525 16:16:35.392396 23215 solver.cpp:341] Iteration 51000, Testing net (#0)
I0525 16:17:22.208425 23215 solver.cpp:409]     Test net output #0: accuracy = 0.861606
I0525 16:17:22.208621 23215 solver.cpp:409]     Test net output #1: loss = 0.483371 (* 1 = 0.483371 loss)
I0525 16:17:43.064190 23215 solver.cpp:237] Iteration 51000, loss = 1.24601
I0525 16:17:43.064244 23215 solver.cpp:253]     Train net output #0: loss = 1.24601 (* 1 = 1.24601 loss)
I0525 16:17:43.064260 23215 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0525 16:17:51.802865 23215 solver.cpp:237] Iteration 51150, loss = 1.23074
I0525 16:17:51.802911 23215 solver.cpp:253]     Train net output #0: loss = 1.23074 (* 1 = 1.23074 loss)
I0525 16:17:51.802925 23215 sgd_solver.cpp:106] Iteration 51150, lr = 0.001
I0525 16:18:00.537520 23215 solver.cpp:237] Iteration 51300, loss = 1.30966
I0525 16:18:00.537693 23215 solver.cpp:253]     Train net output #0: loss = 1.30966 (* 1 = 1.30966 loss)
I0525 16:18:00.537708 23215 sgd_solver.cpp:106] Iteration 51300, lr = 0.001
I0525 16:18:09.276073 23215 solver.cpp:237] Iteration 51450, loss = 1.32664
I0525 16:18:09.276124 23215 solver.cpp:253]     Train net output #0: loss = 1.32664 (* 1 = 1.32664 loss)
I0525 16:18:09.276136 23215 sgd_solver.cpp:106] Iteration 51450, lr = 0.001
I0525 16:18:18.010686 23215 solver.cpp:237] Iteration 51600, loss = 1.40378
I0525 16:18:18.010722 23215 solver.cpp:253]     Train net output #0: loss = 1.40378 (* 1 = 1.40378 loss)
I0525 16:18:18.010740 23215 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0525 16:18:26.745085 23215 solver.cpp:237] Iteration 51750, loss = 1.25422
I0525 16:18:26.745120 23215 solver.cpp:253]     Train net output #0: loss = 1.25422 (* 1 = 1.25422 loss)
I0525 16:18:26.745136 23215 sgd_solver.cpp:106] Iteration 51750, lr = 0.001
I0525 16:18:35.486196 23215 solver.cpp:237] Iteration 51900, loss = 1.32722
I0525 16:18:35.486373 23215 solver.cpp:253]     Train net output #0: loss = 1.32722 (* 1 = 1.32722 loss)
I0525 16:18:35.486387 23215 sgd_solver.cpp:106] Iteration 51900, lr = 0.001
I0525 16:19:05.086014 23215 solver.cpp:237] Iteration 52050, loss = 1.19621
I0525 16:19:05.086063 23215 solver.cpp:253]     Train net output #0: loss = 1.19621 (* 1 = 1.19621 loss)
I0525 16:19:05.086081 23215 sgd_solver.cpp:106] Iteration 52050, lr = 0.001
I0525 16:19:13.823441 23215 solver.cpp:237] Iteration 52200, loss = 1.18962
I0525 16:19:13.823612 23215 solver.cpp:253]     Train net output #0: loss = 1.18962 (* 1 = 1.18962 loss)
I0525 16:19:13.823626 23215 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0525 16:19:22.564852 23215 solver.cpp:237] Iteration 52350, loss = 1.24426
I0525 16:19:22.564887 23215 solver.cpp:253]     Train net output #0: loss = 1.24426 (* 1 = 1.24426 loss)
I0525 16:19:22.564903 23215 sgd_solver.cpp:106] Iteration 52350, lr = 0.001
I0525 16:19:31.248035 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_52500.caffemodel
I0525 16:19:31.327771 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_52500.solverstate
I0525 16:19:31.372303 23215 solver.cpp:237] Iteration 52500, loss = 1.24681
I0525 16:19:31.372349 23215 solver.cpp:253]     Train net output #0: loss = 1.24681 (* 1 = 1.24681 loss)
I0525 16:19:31.372364 23215 sgd_solver.cpp:106] Iteration 52500, lr = 0.001
I0525 16:19:40.105525 23215 solver.cpp:237] Iteration 52650, loss = 1.07533
I0525 16:19:40.105559 23215 solver.cpp:253]     Train net output #0: loss = 1.07533 (* 1 = 1.07533 loss)
I0525 16:19:40.105576 23215 sgd_solver.cpp:106] Iteration 52650, lr = 0.001
I0525 16:19:48.838096 23215 solver.cpp:237] Iteration 52800, loss = 1.18095
I0525 16:19:48.838291 23215 solver.cpp:253]     Train net output #0: loss = 1.18095 (* 1 = 1.18095 loss)
I0525 16:19:48.838306 23215 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0525 16:19:57.577800 23215 solver.cpp:237] Iteration 52950, loss = 1.26846
I0525 16:19:57.577834 23215 solver.cpp:253]     Train net output #0: loss = 1.26846 (* 1 = 1.26846 loss)
I0525 16:19:57.577852 23215 sgd_solver.cpp:106] Iteration 52950, lr = 0.001
I0525 16:20:27.168249 23215 solver.cpp:237] Iteration 53100, loss = 1.21674
I0525 16:20:27.168439 23215 solver.cpp:253]     Train net output #0: loss = 1.21674 (* 1 = 1.21674 loss)
I0525 16:20:27.168454 23215 sgd_solver.cpp:106] Iteration 53100, lr = 0.001
I0525 16:20:35.909304 23215 solver.cpp:237] Iteration 53250, loss = 1.1523
I0525 16:20:35.909338 23215 solver.cpp:253]     Train net output #0: loss = 1.1523 (* 1 = 1.1523 loss)
I0525 16:20:35.909355 23215 sgd_solver.cpp:106] Iteration 53250, lr = 0.001
I0525 16:20:44.646726 23215 solver.cpp:237] Iteration 53400, loss = 1.15461
I0525 16:20:44.646770 23215 solver.cpp:253]     Train net output #0: loss = 1.15461 (* 1 = 1.15461 loss)
I0525 16:20:44.646786 23215 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0525 16:20:53.380762 23215 solver.cpp:237] Iteration 53550, loss = 1.39174
I0525 16:20:53.380797 23215 solver.cpp:253]     Train net output #0: loss = 1.39174 (* 1 = 1.39174 loss)
I0525 16:20:53.380810 23215 sgd_solver.cpp:106] Iteration 53550, lr = 0.001
I0525 16:21:02.113708 23215 solver.cpp:237] Iteration 53700, loss = 1.25966
I0525 16:21:02.113873 23215 solver.cpp:253]     Train net output #0: loss = 1.25966 (* 1 = 1.25966 loss)
I0525 16:21:02.113886 23215 sgd_solver.cpp:106] Iteration 53700, lr = 0.001
I0525 16:21:10.850092 23215 solver.cpp:237] Iteration 53850, loss = 0.990354
I0525 16:21:10.850141 23215 solver.cpp:253]     Train net output #0: loss = 0.990354 (* 1 = 0.990354 loss)
I0525 16:21:10.850154 23215 sgd_solver.cpp:106] Iteration 53850, lr = 0.001
I0525 16:21:19.531975 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_54000.caffemodel
I0525 16:21:19.613668 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_54000.solverstate
I0525 16:21:19.641232 23215 solver.cpp:341] Iteration 54000, Testing net (#0)
I0525 16:22:27.378402 23215 solver.cpp:409]     Test net output #0: accuracy = 0.862126
I0525 16:22:27.378602 23215 solver.cpp:409]     Test net output #1: loss = 0.444648 (* 1 = 0.444648 loss)
I0525 16:22:48.245718 23215 solver.cpp:237] Iteration 54000, loss = 1.35665
I0525 16:22:48.245770 23215 solver.cpp:253]     Train net output #0: loss = 1.35665 (* 1 = 1.35665 loss)
I0525 16:22:48.245785 23215 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0525 16:22:56.975184 23215 solver.cpp:237] Iteration 54150, loss = 1.18411
I0525 16:22:56.975219 23215 solver.cpp:253]     Train net output #0: loss = 1.18411 (* 1 = 1.18411 loss)
I0525 16:22:56.975236 23215 sgd_solver.cpp:106] Iteration 54150, lr = 0.001
I0525 16:23:05.705490 23215 solver.cpp:237] Iteration 54300, loss = 1.31251
I0525 16:23:05.705662 23215 solver.cpp:253]     Train net output #0: loss = 1.31251 (* 1 = 1.31251 loss)
I0525 16:23:05.705677 23215 sgd_solver.cpp:106] Iteration 54300, lr = 0.001
I0525 16:23:14.439061 23215 solver.cpp:237] Iteration 54450, loss = 1.25833
I0525 16:23:14.439096 23215 solver.cpp:253]     Train net output #0: loss = 1.25833 (* 1 = 1.25833 loss)
I0525 16:23:14.439118 23215 sgd_solver.cpp:106] Iteration 54450, lr = 0.001
I0525 16:23:23.170894 23215 solver.cpp:237] Iteration 54600, loss = 1.20607
I0525 16:23:23.170929 23215 solver.cpp:253]     Train net output #0: loss = 1.20607 (* 1 = 1.20607 loss)
I0525 16:23:23.170945 23215 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0525 16:23:31.903488 23215 solver.cpp:237] Iteration 54750, loss = 1.39562
I0525 16:23:31.903523 23215 solver.cpp:253]     Train net output #0: loss = 1.39562 (* 1 = 1.39562 loss)
I0525 16:23:31.903539 23215 sgd_solver.cpp:106] Iteration 54750, lr = 0.001
I0525 16:23:40.632653 23215 solver.cpp:237] Iteration 54900, loss = 1.2393
I0525 16:23:40.632843 23215 solver.cpp:253]     Train net output #0: loss = 1.2393 (* 1 = 1.2393 loss)
I0525 16:23:40.632856 23215 sgd_solver.cpp:106] Iteration 54900, lr = 0.001
I0525 16:24:10.201066 23215 solver.cpp:237] Iteration 55050, loss = 1.28385
I0525 16:24:10.201117 23215 solver.cpp:253]     Train net output #0: loss = 1.28385 (* 1 = 1.28385 loss)
I0525 16:24:10.201131 23215 sgd_solver.cpp:106] Iteration 55050, lr = 0.001
I0525 16:24:18.927961 23215 solver.cpp:237] Iteration 55200, loss = 1.30582
I0525 16:24:18.928138 23215 solver.cpp:253]     Train net output #0: loss = 1.30582 (* 1 = 1.30582 loss)
I0525 16:24:18.928150 23215 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0525 16:24:27.656720 23215 solver.cpp:237] Iteration 55350, loss = 1.19186
I0525 16:24:27.656767 23215 solver.cpp:253]     Train net output #0: loss = 1.19186 (* 1 = 1.19186 loss)
I0525 16:24:27.656783 23215 sgd_solver.cpp:106] Iteration 55350, lr = 0.001
I0525 16:24:36.327451 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_55500.caffemodel
I0525 16:24:36.405793 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_55500.solverstate
I0525 16:24:36.449296 23215 solver.cpp:237] Iteration 55500, loss = 1.19998
I0525 16:24:36.449337 23215 solver.cpp:253]     Train net output #0: loss = 1.19998 (* 1 = 1.19998 loss)
I0525 16:24:36.449357 23215 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I0525 16:24:45.175312 23215 solver.cpp:237] Iteration 55650, loss = 1.39434
I0525 16:24:45.175346 23215 solver.cpp:253]     Train net output #0: loss = 1.39434 (* 1 = 1.39434 loss)
I0525 16:24:45.175361 23215 sgd_solver.cpp:106] Iteration 55650, lr = 0.001
I0525 16:24:53.905674 23215 solver.cpp:237] Iteration 55800, loss = 1.22351
I0525 16:24:53.905858 23215 solver.cpp:253]     Train net output #0: loss = 1.22351 (* 1 = 1.22351 loss)
I0525 16:24:53.905872 23215 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0525 16:25:02.637426 23215 solver.cpp:237] Iteration 55950, loss = 1.26843
I0525 16:25:02.637457 23215 solver.cpp:253]     Train net output #0: loss = 1.26843 (* 1 = 1.26843 loss)
I0525 16:25:02.637470 23215 sgd_solver.cpp:106] Iteration 55950, lr = 0.001
I0525 16:25:32.194126 23215 solver.cpp:237] Iteration 56100, loss = 1.17959
I0525 16:25:32.194316 23215 solver.cpp:253]     Train net output #0: loss = 1.17959 (* 1 = 1.17959 loss)
I0525 16:25:32.194330 23215 sgd_solver.cpp:106] Iteration 56100, lr = 0.001
I0525 16:25:40.924101 23215 solver.cpp:237] Iteration 56250, loss = 1.27453
I0525 16:25:40.924136 23215 solver.cpp:253]     Train net output #0: loss = 1.27453 (* 1 = 1.27453 loss)
I0525 16:25:40.924159 23215 sgd_solver.cpp:106] Iteration 56250, lr = 0.001
I0525 16:25:49.656950 23215 solver.cpp:237] Iteration 56400, loss = 1.17252
I0525 16:25:49.656986 23215 solver.cpp:253]     Train net output #0: loss = 1.17252 (* 1 = 1.17252 loss)
I0525 16:25:49.657002 23215 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0525 16:25:58.385840 23215 solver.cpp:237] Iteration 56550, loss = 1.39483
I0525 16:25:58.385875 23215 solver.cpp:253]     Train net output #0: loss = 1.39483 (* 1 = 1.39483 loss)
I0525 16:25:58.385890 23215 sgd_solver.cpp:106] Iteration 56550, lr = 0.001
I0525 16:26:07.111922 23215 solver.cpp:237] Iteration 56700, loss = 1.32061
I0525 16:26:07.112097 23215 solver.cpp:253]     Train net output #0: loss = 1.32061 (* 1 = 1.32061 loss)
I0525 16:26:07.112110 23215 sgd_solver.cpp:106] Iteration 56700, lr = 0.001
I0525 16:26:15.842181 23215 solver.cpp:237] Iteration 56850, loss = 1.20613
I0525 16:26:15.842216 23215 solver.cpp:253]     Train net output #0: loss = 1.20613 (* 1 = 1.20613 loss)
I0525 16:26:15.842232 23215 sgd_solver.cpp:106] Iteration 56850, lr = 0.001
I0525 16:26:24.512501 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_57000.caffemodel
I0525 16:26:24.591416 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_57000.solverstate
I0525 16:26:24.616613 23215 solver.cpp:341] Iteration 57000, Testing net (#0)
I0525 16:27:11.105573 23215 solver.cpp:409]     Test net output #0: accuracy = 0.871747
I0525 16:27:11.105773 23215 solver.cpp:409]     Test net output #1: loss = 0.43921 (* 1 = 0.43921 loss)
I0525 16:27:31.974022 23215 solver.cpp:237] Iteration 57000, loss = 1.08136
I0525 16:27:31.974076 23215 solver.cpp:253]     Train net output #0: loss = 1.08136 (* 1 = 1.08136 loss)
I0525 16:27:31.974089 23215 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0525 16:27:40.703593 23215 solver.cpp:237] Iteration 57150, loss = 1.36276
I0525 16:27:40.703629 23215 solver.cpp:253]     Train net output #0: loss = 1.36276 (* 1 = 1.36276 loss)
I0525 16:27:40.703645 23215 sgd_solver.cpp:106] Iteration 57150, lr = 0.001
I0525 16:27:49.437074 23215 solver.cpp:237] Iteration 57300, loss = 1.26866
I0525 16:27:49.437263 23215 solver.cpp:253]     Train net output #0: loss = 1.26866 (* 1 = 1.26866 loss)
I0525 16:27:49.437278 23215 sgd_solver.cpp:106] Iteration 57300, lr = 0.001
I0525 16:27:58.166456 23215 solver.cpp:237] Iteration 57450, loss = 1.37789
I0525 16:27:58.166491 23215 solver.cpp:253]     Train net output #0: loss = 1.37789 (* 1 = 1.37789 loss)
I0525 16:27:58.166509 23215 sgd_solver.cpp:106] Iteration 57450, lr = 0.001
I0525 16:28:06.898972 23215 solver.cpp:237] Iteration 57600, loss = 1.07851
I0525 16:28:06.899008 23215 solver.cpp:253]     Train net output #0: loss = 1.07851 (* 1 = 1.07851 loss)
I0525 16:28:06.899024 23215 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0525 16:28:15.631247 23215 solver.cpp:237] Iteration 57750, loss = 1.17653
I0525 16:28:15.631286 23215 solver.cpp:253]     Train net output #0: loss = 1.17653 (* 1 = 1.17653 loss)
I0525 16:28:15.631307 23215 sgd_solver.cpp:106] Iteration 57750, lr = 0.001
I0525 16:28:24.359347 23215 solver.cpp:237] Iteration 57900, loss = 1.21552
I0525 16:28:24.359518 23215 solver.cpp:253]     Train net output #0: loss = 1.21552 (* 1 = 1.21552 loss)
I0525 16:28:24.359534 23215 sgd_solver.cpp:106] Iteration 57900, lr = 0.001
I0525 16:28:53.932737 23215 solver.cpp:237] Iteration 58050, loss = 1.42329
I0525 16:28:53.932787 23215 solver.cpp:253]     Train net output #0: loss = 1.42329 (* 1 = 1.42329 loss)
I0525 16:28:53.932803 23215 sgd_solver.cpp:106] Iteration 58050, lr = 0.001
I0525 16:29:02.667749 23215 solver.cpp:237] Iteration 58200, loss = 1.40695
I0525 16:29:02.667932 23215 solver.cpp:253]     Train net output #0: loss = 1.40695 (* 1 = 1.40695 loss)
I0525 16:29:02.667946 23215 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0525 16:29:11.398615 23215 solver.cpp:237] Iteration 58350, loss = 1.15736
I0525 16:29:11.398651 23215 solver.cpp:253]     Train net output #0: loss = 1.15736 (* 1 = 1.15736 loss)
I0525 16:29:11.398666 23215 sgd_solver.cpp:106] Iteration 58350, lr = 0.001
I0525 16:29:20.073194 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_58500.caffemodel
I0525 16:29:20.152892 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_58500.solverstate
I0525 16:29:20.196313 23215 solver.cpp:237] Iteration 58500, loss = 1.31082
I0525 16:29:20.196362 23215 solver.cpp:253]     Train net output #0: loss = 1.31082 (* 1 = 1.31082 loss)
I0525 16:29:20.196378 23215 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I0525 16:29:28.929046 23215 solver.cpp:237] Iteration 58650, loss = 1.21894
I0525 16:29:28.929091 23215 solver.cpp:253]     Train net output #0: loss = 1.21894 (* 1 = 1.21894 loss)
I0525 16:29:28.929108 23215 sgd_solver.cpp:106] Iteration 58650, lr = 0.001
I0525 16:29:37.660435 23215 solver.cpp:237] Iteration 58800, loss = 1.26738
I0525 16:29:37.660630 23215 solver.cpp:253]     Train net output #0: loss = 1.26738 (* 1 = 1.26738 loss)
I0525 16:29:37.660645 23215 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0525 16:29:46.391111 23215 solver.cpp:237] Iteration 58950, loss = 1.28782
I0525 16:29:46.391145 23215 solver.cpp:253]     Train net output #0: loss = 1.28782 (* 1 = 1.28782 loss)
I0525 16:29:46.391162 23215 sgd_solver.cpp:106] Iteration 58950, lr = 0.001
I0525 16:30:15.988662 23215 solver.cpp:237] Iteration 59100, loss = 1.06586
I0525 16:30:15.988853 23215 solver.cpp:253]     Train net output #0: loss = 1.06586 (* 1 = 1.06586 loss)
I0525 16:30:15.988867 23215 sgd_solver.cpp:106] Iteration 59100, lr = 0.001
I0525 16:30:24.721043 23215 solver.cpp:237] Iteration 59250, loss = 1.08524
I0525 16:30:24.721077 23215 solver.cpp:253]     Train net output #0: loss = 1.08524 (* 1 = 1.08524 loss)
I0525 16:30:24.721094 23215 sgd_solver.cpp:106] Iteration 59250, lr = 0.001
I0525 16:30:33.452801 23215 solver.cpp:237] Iteration 59400, loss = 0.99752
I0525 16:30:33.452837 23215 solver.cpp:253]     Train net output #0: loss = 0.99752 (* 1 = 0.99752 loss)
I0525 16:30:33.452852 23215 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0525 16:30:42.188658 23215 solver.cpp:237] Iteration 59550, loss = 1.2184
I0525 16:30:42.188702 23215 solver.cpp:253]     Train net output #0: loss = 1.2184 (* 1 = 1.2184 loss)
I0525 16:30:42.188719 23215 sgd_solver.cpp:106] Iteration 59550, lr = 0.001
I0525 16:30:50.925371 23215 solver.cpp:237] Iteration 59700, loss = 1.08764
I0525 16:30:50.925544 23215 solver.cpp:253]     Train net output #0: loss = 1.08764 (* 1 = 1.08764 loss)
I0525 16:30:50.925557 23215 sgd_solver.cpp:106] Iteration 59700, lr = 0.001
I0525 16:30:59.658875 23215 solver.cpp:237] Iteration 59850, loss = 1.08243
I0525 16:30:59.658910 23215 solver.cpp:253]     Train net output #0: loss = 1.08243 (* 1 = 1.08243 loss)
I0525 16:30:59.658933 23215 sgd_solver.cpp:106] Iteration 59850, lr = 0.001
I0525 16:31:08.331738 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_60000.caffemodel
I0525 16:31:08.415444 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_60000.solverstate
I0525 16:31:08.442852 23215 solver.cpp:341] Iteration 60000, Testing net (#0)
I0525 16:32:16.147718 23215 solver.cpp:409]     Test net output #0: accuracy = 0.867667
I0525 16:32:16.147910 23215 solver.cpp:409]     Test net output #1: loss = 0.411709 (* 1 = 0.411709 loss)
I0525 16:32:37.017660 23215 solver.cpp:237] Iteration 60000, loss = 1.21593
I0525 16:32:37.017714 23215 solver.cpp:253]     Train net output #0: loss = 1.21593 (* 1 = 1.21593 loss)
I0525 16:32:37.017729 23215 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0525 16:32:45.748404 23215 solver.cpp:237] Iteration 60150, loss = 1.17754
I0525 16:32:45.748461 23215 solver.cpp:253]     Train net output #0: loss = 1.17754 (* 1 = 1.17754 loss)
I0525 16:32:45.748473 23215 sgd_solver.cpp:106] Iteration 60150, lr = 0.001
I0525 16:32:54.467931 23215 solver.cpp:237] Iteration 60300, loss = 1.03656
I0525 16:32:54.468108 23215 solver.cpp:253]     Train net output #0: loss = 1.03656 (* 1 = 1.03656 loss)
I0525 16:32:54.468122 23215 sgd_solver.cpp:106] Iteration 60300, lr = 0.001
I0525 16:33:03.199010 23215 solver.cpp:237] Iteration 60450, loss = 1.05898
I0525 16:33:03.199044 23215 solver.cpp:253]     Train net output #0: loss = 1.05898 (* 1 = 1.05898 loss)
I0525 16:33:03.199061 23215 sgd_solver.cpp:106] Iteration 60450, lr = 0.001
I0525 16:33:11.923761 23215 solver.cpp:237] Iteration 60600, loss = 1.11782
I0525 16:33:11.923805 23215 solver.cpp:253]     Train net output #0: loss = 1.11782 (* 1 = 1.11782 loss)
I0525 16:33:11.923822 23215 sgd_solver.cpp:106] Iteration 60600, lr = 0.001
I0525 16:33:20.648862 23215 solver.cpp:237] Iteration 60750, loss = 1.30868
I0525 16:33:20.648898 23215 solver.cpp:253]     Train net output #0: loss = 1.30868 (* 1 = 1.30868 loss)
I0525 16:33:20.648915 23215 sgd_solver.cpp:106] Iteration 60750, lr = 0.001
I0525 16:33:29.375600 23215 solver.cpp:237] Iteration 60900, loss = 1.07187
I0525 16:33:29.375784 23215 solver.cpp:253]     Train net output #0: loss = 1.07187 (* 1 = 1.07187 loss)
I0525 16:33:29.375798 23215 sgd_solver.cpp:106] Iteration 60900, lr = 0.001
I0525 16:33:58.949337 23215 solver.cpp:237] Iteration 61050, loss = 1.32112
I0525 16:33:58.949385 23215 solver.cpp:253]     Train net output #0: loss = 1.32112 (* 1 = 1.32112 loss)
I0525 16:33:58.949403 23215 sgd_solver.cpp:106] Iteration 61050, lr = 0.001
I0525 16:34:07.674496 23215 solver.cpp:237] Iteration 61200, loss = 1.06074
I0525 16:34:07.674674 23215 solver.cpp:253]     Train net output #0: loss = 1.06074 (* 1 = 1.06074 loss)
I0525 16:34:07.674687 23215 sgd_solver.cpp:106] Iteration 61200, lr = 0.001
I0525 16:34:16.393621 23215 solver.cpp:237] Iteration 61350, loss = 1.31907
I0525 16:34:16.393656 23215 solver.cpp:253]     Train net output #0: loss = 1.31907 (* 1 = 1.31907 loss)
I0525 16:34:16.393671 23215 sgd_solver.cpp:106] Iteration 61350, lr = 0.001
I0525 16:34:25.057656 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_61500.caffemodel
I0525 16:34:25.136013 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_61500.solverstate
I0525 16:34:25.180107 23215 solver.cpp:237] Iteration 61500, loss = 1.11249
I0525 16:34:25.180152 23215 solver.cpp:253]     Train net output #0: loss = 1.11249 (* 1 = 1.11249 loss)
I0525 16:34:25.180169 23215 sgd_solver.cpp:106] Iteration 61500, lr = 0.001
I0525 16:34:33.899310 23215 solver.cpp:237] Iteration 61650, loss = 1.39911
I0525 16:34:33.899344 23215 solver.cpp:253]     Train net output #0: loss = 1.39911 (* 1 = 1.39911 loss)
I0525 16:34:33.899358 23215 sgd_solver.cpp:106] Iteration 61650, lr = 0.001
I0525 16:34:42.625777 23215 solver.cpp:237] Iteration 61800, loss = 1.34721
I0525 16:34:42.625952 23215 solver.cpp:253]     Train net output #0: loss = 1.34721 (* 1 = 1.34721 loss)
I0525 16:34:42.625965 23215 sgd_solver.cpp:106] Iteration 61800, lr = 0.001
I0525 16:34:51.346688 23215 solver.cpp:237] Iteration 61950, loss = 1.28057
I0525 16:34:51.346732 23215 solver.cpp:253]     Train net output #0: loss = 1.28057 (* 1 = 1.28057 loss)
I0525 16:34:51.346750 23215 sgd_solver.cpp:106] Iteration 61950, lr = 0.001
I0525 16:35:20.928802 23215 solver.cpp:237] Iteration 62100, loss = 1.06162
I0525 16:35:20.928997 23215 solver.cpp:253]     Train net output #0: loss = 1.06162 (* 1 = 1.06162 loss)
I0525 16:35:20.929011 23215 sgd_solver.cpp:106] Iteration 62100, lr = 0.001
I0525 16:35:29.652845 23215 solver.cpp:237] Iteration 62250, loss = 1.20145
I0525 16:35:29.652880 23215 solver.cpp:253]     Train net output #0: loss = 1.20145 (* 1 = 1.20145 loss)
I0525 16:35:29.652897 23215 sgd_solver.cpp:106] Iteration 62250, lr = 0.001
I0525 16:35:38.377795 23215 solver.cpp:237] Iteration 62400, loss = 1.24376
I0525 16:35:38.377830 23215 solver.cpp:253]     Train net output #0: loss = 1.24376 (* 1 = 1.24376 loss)
I0525 16:35:38.377847 23215 sgd_solver.cpp:106] Iteration 62400, lr = 0.001
I0525 16:35:47.107700 23215 solver.cpp:237] Iteration 62550, loss = 1.23012
I0525 16:35:47.107738 23215 solver.cpp:253]     Train net output #0: loss = 1.23012 (* 1 = 1.23012 loss)
I0525 16:35:47.107758 23215 sgd_solver.cpp:106] Iteration 62550, lr = 0.001
I0525 16:35:55.827136 23215 solver.cpp:237] Iteration 62700, loss = 1.1274
I0525 16:35:55.827317 23215 solver.cpp:253]     Train net output #0: loss = 1.1274 (* 1 = 1.1274 loss)
I0525 16:35:55.827332 23215 sgd_solver.cpp:106] Iteration 62700, lr = 0.001
I0525 16:36:04.556562 23215 solver.cpp:237] Iteration 62850, loss = 1.40203
I0525 16:36:04.556607 23215 solver.cpp:253]     Train net output #0: loss = 1.40203 (* 1 = 1.40203 loss)
I0525 16:36:04.556625 23215 sgd_solver.cpp:106] Iteration 62850, lr = 0.001
I0525 16:36:13.223172 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_63000.caffemodel
I0525 16:36:13.301717 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_63000.solverstate
I0525 16:36:13.327661 23215 solver.cpp:341] Iteration 63000, Testing net (#0)
I0525 16:37:00.171735 23215 solver.cpp:409]     Test net output #0: accuracy = 0.871053
I0525 16:37:00.171927 23215 solver.cpp:409]     Test net output #1: loss = 0.406846 (* 1 = 0.406846 loss)
I0525 16:37:21.040187 23215 solver.cpp:237] Iteration 63000, loss = 1.18718
I0525 16:37:21.040241 23215 solver.cpp:253]     Train net output #0: loss = 1.18718 (* 1 = 1.18718 loss)
I0525 16:37:21.040256 23215 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I0525 16:37:29.777847 23215 solver.cpp:237] Iteration 63150, loss = 1.32328
I0525 16:37:29.777880 23215 solver.cpp:253]     Train net output #0: loss = 1.32328 (* 1 = 1.32328 loss)
I0525 16:37:29.777894 23215 sgd_solver.cpp:106] Iteration 63150, lr = 0.001
I0525 16:37:38.514947 23215 solver.cpp:237] Iteration 63300, loss = 1.26227
I0525 16:37:38.515127 23215 solver.cpp:253]     Train net output #0: loss = 1.26227 (* 1 = 1.26227 loss)
I0525 16:37:38.515141 23215 sgd_solver.cpp:106] Iteration 63300, lr = 0.001
I0525 16:37:47.253175 23215 solver.cpp:237] Iteration 63450, loss = 1.33401
I0525 16:37:47.253222 23215 solver.cpp:253]     Train net output #0: loss = 1.33401 (* 1 = 1.33401 loss)
I0525 16:37:47.253238 23215 sgd_solver.cpp:106] Iteration 63450, lr = 0.001
I0525 16:37:55.986871 23215 solver.cpp:237] Iteration 63600, loss = 1.23521
I0525 16:37:55.986906 23215 solver.cpp:253]     Train net output #0: loss = 1.23521 (* 1 = 1.23521 loss)
I0525 16:37:55.986922 23215 sgd_solver.cpp:106] Iteration 63600, lr = 0.001
I0525 16:38:04.722915 23215 solver.cpp:237] Iteration 63750, loss = 1.28758
I0525 16:38:04.722950 23215 solver.cpp:253]     Train net output #0: loss = 1.28758 (* 1 = 1.28758 loss)
I0525 16:38:04.722966 23215 sgd_solver.cpp:106] Iteration 63750, lr = 0.001
I0525 16:38:13.458770 23215 solver.cpp:237] Iteration 63900, loss = 1.17507
I0525 16:38:13.458956 23215 solver.cpp:253]     Train net output #0: loss = 1.17507 (* 1 = 1.17507 loss)
I0525 16:38:13.458969 23215 sgd_solver.cpp:106] Iteration 63900, lr = 0.001
I0525 16:38:43.034760 23215 solver.cpp:237] Iteration 64050, loss = 1.20619
I0525 16:38:43.034811 23215 solver.cpp:253]     Train net output #0: loss = 1.20619 (* 1 = 1.20619 loss)
I0525 16:38:43.034826 23215 sgd_solver.cpp:106] Iteration 64050, lr = 0.001
I0525 16:38:51.768679 23215 solver.cpp:237] Iteration 64200, loss = 1.22962
I0525 16:38:51.768857 23215 solver.cpp:253]     Train net output #0: loss = 1.22962 (* 1 = 1.22962 loss)
I0525 16:38:51.768872 23215 sgd_solver.cpp:106] Iteration 64200, lr = 0.001
I0525 16:39:00.510363 23215 solver.cpp:237] Iteration 64350, loss = 1.24534
I0525 16:39:00.510406 23215 solver.cpp:253]     Train net output #0: loss = 1.24534 (* 1 = 1.24534 loss)
I0525 16:39:00.510424 23215 sgd_solver.cpp:106] Iteration 64350, lr = 0.001
I0525 16:39:09.189959 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_64500.caffemodel
I0525 16:39:09.268857 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_64500.solverstate
I0525 16:39:09.312088 23215 solver.cpp:237] Iteration 64500, loss = 1.14391
I0525 16:39:09.312129 23215 solver.cpp:253]     Train net output #0: loss = 1.14391 (* 1 = 1.14391 loss)
I0525 16:39:09.312150 23215 sgd_solver.cpp:106] Iteration 64500, lr = 0.001
I0525 16:39:18.052386 23215 solver.cpp:237] Iteration 64650, loss = 1.07656
I0525 16:39:18.052419 23215 solver.cpp:253]     Train net output #0: loss = 1.07656 (* 1 = 1.07656 loss)
I0525 16:39:18.052435 23215 sgd_solver.cpp:106] Iteration 64650, lr = 0.001
I0525 16:39:26.799865 23215 solver.cpp:237] Iteration 64800, loss = 1.20605
I0525 16:39:26.800070 23215 solver.cpp:253]     Train net output #0: loss = 1.20605 (* 1 = 1.20605 loss)
I0525 16:39:26.800083 23215 sgd_solver.cpp:106] Iteration 64800, lr = 0.001
I0525 16:39:35.536562 23215 solver.cpp:237] Iteration 64950, loss = 1.22317
I0525 16:39:35.536597 23215 solver.cpp:253]     Train net output #0: loss = 1.22317 (* 1 = 1.22317 loss)
I0525 16:39:35.536614 23215 sgd_solver.cpp:106] Iteration 64950, lr = 0.001
I0525 16:40:05.167292 23215 solver.cpp:237] Iteration 65100, loss = 1.21524
I0525 16:40:05.167491 23215 solver.cpp:253]     Train net output #0: loss = 1.21524 (* 1 = 1.21524 loss)
I0525 16:40:05.167507 23215 sgd_solver.cpp:106] Iteration 65100, lr = 0.001
I0525 16:40:13.906296 23215 solver.cpp:237] Iteration 65250, loss = 1.28937
I0525 16:40:13.906343 23215 solver.cpp:253]     Train net output #0: loss = 1.28937 (* 1 = 1.28937 loss)
I0525 16:40:13.906360 23215 sgd_solver.cpp:106] Iteration 65250, lr = 0.001
I0525 16:40:22.640377 23215 solver.cpp:237] Iteration 65400, loss = 1.28785
I0525 16:40:22.640413 23215 solver.cpp:253]     Train net output #0: loss = 1.28785 (* 1 = 1.28785 loss)
I0525 16:40:22.640429 23215 sgd_solver.cpp:106] Iteration 65400, lr = 0.001
I0525 16:40:31.377089 23215 solver.cpp:237] Iteration 65550, loss = 1.28761
I0525 16:40:31.377123 23215 solver.cpp:253]     Train net output #0: loss = 1.28761 (* 1 = 1.28761 loss)
I0525 16:40:31.377140 23215 sgd_solver.cpp:106] Iteration 65550, lr = 0.001
I0525 16:40:40.119279 23215 solver.cpp:237] Iteration 65700, loss = 1.25538
I0525 16:40:40.119468 23215 solver.cpp:253]     Train net output #0: loss = 1.25538 (* 1 = 1.25538 loss)
I0525 16:40:40.119482 23215 sgd_solver.cpp:106] Iteration 65700, lr = 0.001
I0525 16:40:48.857414 23215 solver.cpp:237] Iteration 65850, loss = 1.25649
I0525 16:40:48.857447 23215 solver.cpp:253]     Train net output #0: loss = 1.25649 (* 1 = 1.25649 loss)
I0525 16:40:48.857465 23215 sgd_solver.cpp:106] Iteration 65850, lr = 0.001
I0525 16:40:57.536156 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_66000.caffemodel
I0525 16:40:57.616087 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_66000.solverstate
I0525 16:40:57.642688 23215 solver.cpp:341] Iteration 66000, Testing net (#0)
I0525 16:42:05.397621 23215 solver.cpp:409]     Test net output #0: accuracy = 0.872406
I0525 16:42:05.397825 23215 solver.cpp:409]     Test net output #1: loss = 0.424159 (* 1 = 0.424159 loss)
I0525 16:42:26.296893 23215 solver.cpp:237] Iteration 66000, loss = 1.16442
I0525 16:42:26.296946 23215 solver.cpp:253]     Train net output #0: loss = 1.16442 (* 1 = 1.16442 loss)
I0525 16:42:26.296960 23215 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I0525 16:42:35.025534 23215 solver.cpp:237] Iteration 66150, loss = 1.10962
I0525 16:42:35.025570 23215 solver.cpp:253]     Train net output #0: loss = 1.10962 (* 1 = 1.10962 loss)
I0525 16:42:35.025583 23215 sgd_solver.cpp:106] Iteration 66150, lr = 0.001
I0525 16:42:43.766902 23215 solver.cpp:237] Iteration 66300, loss = 1.4739
I0525 16:42:43.767089 23215 solver.cpp:253]     Train net output #0: loss = 1.4739 (* 1 = 1.4739 loss)
I0525 16:42:43.767104 23215 sgd_solver.cpp:106] Iteration 66300, lr = 0.001
I0525 16:42:52.495771 23215 solver.cpp:237] Iteration 66450, loss = 1.32652
I0525 16:42:52.495805 23215 solver.cpp:253]     Train net output #0: loss = 1.32652 (* 1 = 1.32652 loss)
I0525 16:42:52.495823 23215 sgd_solver.cpp:106] Iteration 66450, lr = 0.001
I0525 16:43:01.230406 23215 solver.cpp:237] Iteration 66600, loss = 1.31403
I0525 16:43:01.230442 23215 solver.cpp:253]     Train net output #0: loss = 1.31403 (* 1 = 1.31403 loss)
I0525 16:43:01.230458 23215 sgd_solver.cpp:106] Iteration 66600, lr = 0.001
I0525 16:43:09.961490 23215 solver.cpp:237] Iteration 66750, loss = 1.30288
I0525 16:43:09.961535 23215 solver.cpp:253]     Train net output #0: loss = 1.30288 (* 1 = 1.30288 loss)
I0525 16:43:09.961552 23215 sgd_solver.cpp:106] Iteration 66750, lr = 0.001
I0525 16:43:18.691357 23215 solver.cpp:237] Iteration 66900, loss = 1.12141
I0525 16:43:18.691546 23215 solver.cpp:253]     Train net output #0: loss = 1.12141 (* 1 = 1.12141 loss)
I0525 16:43:18.691560 23215 sgd_solver.cpp:106] Iteration 66900, lr = 0.001
I0525 16:43:48.312237 23215 solver.cpp:237] Iteration 67050, loss = 1.27449
I0525 16:43:48.312286 23215 solver.cpp:253]     Train net output #0: loss = 1.27449 (* 1 = 1.27449 loss)
I0525 16:43:48.312302 23215 sgd_solver.cpp:106] Iteration 67050, lr = 0.001
I0525 16:43:57.041764 23215 solver.cpp:237] Iteration 67200, loss = 1.09346
I0525 16:43:57.041957 23215 solver.cpp:253]     Train net output #0: loss = 1.09346 (* 1 = 1.09346 loss)
I0525 16:43:57.041971 23215 sgd_solver.cpp:106] Iteration 67200, lr = 0.001
I0525 16:44:05.770309 23215 solver.cpp:237] Iteration 67350, loss = 1.26236
I0525 16:44:05.770351 23215 solver.cpp:253]     Train net output #0: loss = 1.26236 (* 1 = 1.26236 loss)
I0525 16:44:05.770370 23215 sgd_solver.cpp:106] Iteration 67350, lr = 0.001
I0525 16:44:14.436779 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_67500.caffemodel
I0525 16:44:14.517596 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_67500.solverstate
I0525 16:44:14.562921 23215 solver.cpp:237] Iteration 67500, loss = 1.36222
I0525 16:44:14.562971 23215 solver.cpp:253]     Train net output #0: loss = 1.36222 (* 1 = 1.36222 loss)
I0525 16:44:14.562986 23215 sgd_solver.cpp:106] Iteration 67500, lr = 0.001
I0525 16:44:23.288264 23215 solver.cpp:237] Iteration 67650, loss = 1.16541
I0525 16:44:23.288298 23215 solver.cpp:253]     Train net output #0: loss = 1.16541 (* 1 = 1.16541 loss)
I0525 16:44:23.288314 23215 sgd_solver.cpp:106] Iteration 67650, lr = 0.001
I0525 16:44:32.010779 23215 solver.cpp:237] Iteration 67800, loss = 1.02778
I0525 16:44:32.010977 23215 solver.cpp:253]     Train net output #0: loss = 1.02778 (* 1 = 1.02778 loss)
I0525 16:44:32.010990 23215 sgd_solver.cpp:106] Iteration 67800, lr = 0.001
I0525 16:44:40.732792 23215 solver.cpp:237] Iteration 67950, loss = 1.19145
I0525 16:44:40.732827 23215 solver.cpp:253]     Train net output #0: loss = 1.19145 (* 1 = 1.19145 loss)
I0525 16:44:40.732844 23215 sgd_solver.cpp:106] Iteration 67950, lr = 0.001
I0525 16:45:10.348031 23215 solver.cpp:237] Iteration 68100, loss = 1.191
I0525 16:45:10.348237 23215 solver.cpp:253]     Train net output #0: loss = 1.191 (* 1 = 1.191 loss)
I0525 16:45:10.348253 23215 sgd_solver.cpp:106] Iteration 68100, lr = 0.001
I0525 16:45:19.076854 23215 solver.cpp:237] Iteration 68250, loss = 1.27146
I0525 16:45:19.076894 23215 solver.cpp:253]     Train net output #0: loss = 1.27146 (* 1 = 1.27146 loss)
I0525 16:45:19.076913 23215 sgd_solver.cpp:106] Iteration 68250, lr = 0.001
I0525 16:45:27.811693 23215 solver.cpp:237] Iteration 68400, loss = 1.25119
I0525 16:45:27.811729 23215 solver.cpp:253]     Train net output #0: loss = 1.25119 (* 1 = 1.25119 loss)
I0525 16:45:27.811743 23215 sgd_solver.cpp:106] Iteration 68400, lr = 0.001
I0525 16:45:36.540277 23215 solver.cpp:237] Iteration 68550, loss = 1.31898
I0525 16:45:36.540313 23215 solver.cpp:253]     Train net output #0: loss = 1.31898 (* 1 = 1.31898 loss)
I0525 16:45:36.540326 23215 sgd_solver.cpp:106] Iteration 68550, lr = 0.001
I0525 16:45:45.272189 23215 solver.cpp:237] Iteration 68700, loss = 1.21938
I0525 16:45:45.272392 23215 solver.cpp:253]     Train net output #0: loss = 1.21938 (* 1 = 1.21938 loss)
I0525 16:45:45.272406 23215 sgd_solver.cpp:106] Iteration 68700, lr = 0.001
I0525 16:45:54.007560 23215 solver.cpp:237] Iteration 68850, loss = 1.11349
I0525 16:45:54.007593 23215 solver.cpp:253]     Train net output #0: loss = 1.11349 (* 1 = 1.11349 loss)
I0525 16:45:54.007611 23215 sgd_solver.cpp:106] Iteration 68850, lr = 0.001
I0525 16:46:02.679469 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_69000.caffemodel
I0525 16:46:02.757969 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_69000.solverstate
I0525 16:46:02.783362 23215 solver.cpp:341] Iteration 69000, Testing net (#0)
I0525 16:46:49.335438 23215 solver.cpp:409]     Test net output #0: accuracy = 0.8734
I0525 16:46:49.335638 23215 solver.cpp:409]     Test net output #1: loss = 0.424682 (* 1 = 0.424682 loss)
I0525 16:47:10.205314 23215 solver.cpp:237] Iteration 69000, loss = 1.14639
I0525 16:47:10.205366 23215 solver.cpp:253]     Train net output #0: loss = 1.14639 (* 1 = 1.14639 loss)
I0525 16:47:10.205380 23215 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I0525 16:47:18.942410 23215 solver.cpp:237] Iteration 69150, loss = 0.971562
I0525 16:47:18.942453 23215 solver.cpp:253]     Train net output #0: loss = 0.971562 (* 1 = 0.971562 loss)
I0525 16:47:18.942471 23215 sgd_solver.cpp:106] Iteration 69150, lr = 0.001
I0525 16:47:27.672302 23215 solver.cpp:237] Iteration 69300, loss = 1.24516
I0525 16:47:27.672487 23215 solver.cpp:253]     Train net output #0: loss = 1.24516 (* 1 = 1.24516 loss)
I0525 16:47:27.672500 23215 sgd_solver.cpp:106] Iteration 69300, lr = 0.001
I0525 16:47:36.402264 23215 solver.cpp:237] Iteration 69450, loss = 1.26849
I0525 16:47:36.402298 23215 solver.cpp:253]     Train net output #0: loss = 1.26849 (* 1 = 1.26849 loss)
I0525 16:47:36.402317 23215 sgd_solver.cpp:106] Iteration 69450, lr = 0.001
I0525 16:47:45.130091 23215 solver.cpp:237] Iteration 69600, loss = 1.2265
I0525 16:47:45.130130 23215 solver.cpp:253]     Train net output #0: loss = 1.2265 (* 1 = 1.2265 loss)
I0525 16:47:45.130151 23215 sgd_solver.cpp:106] Iteration 69600, lr = 0.001
I0525 16:47:53.858238 23215 solver.cpp:237] Iteration 69750, loss = 1.13043
I0525 16:47:53.858273 23215 solver.cpp:253]     Train net output #0: loss = 1.13043 (* 1 = 1.13043 loss)
I0525 16:47:53.858289 23215 sgd_solver.cpp:106] Iteration 69750, lr = 0.001
I0525 16:48:02.590836 23215 solver.cpp:237] Iteration 69900, loss = 1.34361
I0525 16:48:02.591012 23215 solver.cpp:253]     Train net output #0: loss = 1.34361 (* 1 = 1.34361 loss)
I0525 16:48:02.591027 23215 sgd_solver.cpp:106] Iteration 69900, lr = 0.001
I0525 16:48:32.189344 23215 solver.cpp:237] Iteration 70050, loss = 1.37785
I0525 16:48:32.189394 23215 solver.cpp:253]     Train net output #0: loss = 1.37785 (* 1 = 1.37785 loss)
I0525 16:48:32.189410 23215 sgd_solver.cpp:106] Iteration 70050, lr = 0.001
I0525 16:48:40.918689 23215 solver.cpp:237] Iteration 70200, loss = 1.30725
I0525 16:48:40.918872 23215 solver.cpp:253]     Train net output #0: loss = 1.30725 (* 1 = 1.30725 loss)
I0525 16:48:40.918886 23215 sgd_solver.cpp:106] Iteration 70200, lr = 0.001
I0525 16:48:49.647296 23215 solver.cpp:237] Iteration 70350, loss = 1.12081
I0525 16:48:49.647331 23215 solver.cpp:253]     Train net output #0: loss = 1.12081 (* 1 = 1.12081 loss)
I0525 16:48:49.647346 23215 sgd_solver.cpp:106] Iteration 70350, lr = 0.001
I0525 16:48:58.319710 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_70500.caffemodel
I0525 16:48:58.398718 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_70500.solverstate
I0525 16:48:58.442538 23215 solver.cpp:237] Iteration 70500, loss = 1.06759
I0525 16:48:58.442585 23215 solver.cpp:253]     Train net output #0: loss = 1.06759 (* 1 = 1.06759 loss)
I0525 16:48:58.442600 23215 sgd_solver.cpp:106] Iteration 70500, lr = 0.001
I0525 16:49:07.175334 23215 solver.cpp:237] Iteration 70650, loss = 1.10455
I0525 16:49:07.175365 23215 solver.cpp:253]     Train net output #0: loss = 1.10455 (* 1 = 1.10455 loss)
I0525 16:49:07.175384 23215 sgd_solver.cpp:106] Iteration 70650, lr = 0.001
I0525 16:49:15.905369 23215 solver.cpp:237] Iteration 70800, loss = 1.1462
I0525 16:49:15.905561 23215 solver.cpp:253]     Train net output #0: loss = 1.1462 (* 1 = 1.1462 loss)
I0525 16:49:15.905575 23215 sgd_solver.cpp:106] Iteration 70800, lr = 0.001
I0525 16:49:24.637958 23215 solver.cpp:237] Iteration 70950, loss = 1.32804
I0525 16:49:24.638001 23215 solver.cpp:253]     Train net output #0: loss = 1.32804 (* 1 = 1.32804 loss)
I0525 16:49:24.638016 23215 sgd_solver.cpp:106] Iteration 70950, lr = 0.001
I0525 16:49:54.217627 23215 solver.cpp:237] Iteration 71100, loss = 1.27155
I0525 16:49:54.217828 23215 solver.cpp:253]     Train net output #0: loss = 1.27155 (* 1 = 1.27155 loss)
I0525 16:49:54.217841 23215 sgd_solver.cpp:106] Iteration 71100, lr = 0.001
I0525 16:50:02.950268 23215 solver.cpp:237] Iteration 71250, loss = 1.34005
I0525 16:50:02.950302 23215 solver.cpp:253]     Train net output #0: loss = 1.34005 (* 1 = 1.34005 loss)
I0525 16:50:02.950320 23215 sgd_solver.cpp:106] Iteration 71250, lr = 0.001
I0525 16:50:11.679869 23215 solver.cpp:237] Iteration 71400, loss = 1.2291
I0525 16:50:11.679904 23215 solver.cpp:253]     Train net output #0: loss = 1.2291 (* 1 = 1.2291 loss)
I0525 16:50:11.679920 23215 sgd_solver.cpp:106] Iteration 71400, lr = 0.001
I0525 16:50:20.412993 23215 solver.cpp:237] Iteration 71550, loss = 1.47364
I0525 16:50:20.413033 23215 solver.cpp:253]     Train net output #0: loss = 1.47364 (* 1 = 1.47364 loss)
I0525 16:50:20.413058 23215 sgd_solver.cpp:106] Iteration 71550, lr = 0.001
I0525 16:50:29.138768 23215 solver.cpp:237] Iteration 71700, loss = 1.26042
I0525 16:50:29.138955 23215 solver.cpp:253]     Train net output #0: loss = 1.26042 (* 1 = 1.26042 loss)
I0525 16:50:29.138970 23215 sgd_solver.cpp:106] Iteration 71700, lr = 0.001
I0525 16:50:37.867267 23215 solver.cpp:237] Iteration 71850, loss = 1.34258
I0525 16:50:37.867302 23215 solver.cpp:253]     Train net output #0: loss = 1.34258 (* 1 = 1.34258 loss)
I0525 16:50:37.867317 23215 sgd_solver.cpp:106] Iteration 71850, lr = 0.001
I0525 16:50:46.546905 23215 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_72000.caffemodel
I0525 16:50:46.626210 23215 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_100_lr_0.0010_2016-05-20T15.49.24.388997_iter_72000.solverstate
I0525 16:50:46.652148 23215 solver.cpp:341] Iteration 72000, Testing net (#0)
I0525 16:51:54.320452 23215 solver.cpp:409]     Test net output #0: accuracy = 0.876227
I0525 16:51:54.320649 23215 solver.cpp:409]     Test net output #1: loss = 0.398304 (* 1 = 0.398304 loss)
I0525 16:52:15.171861 23215 solver.cpp:237] Iteration 72000, loss = 1.30558
I0525 16:52:15.171914 23215 solver.cpp:253]     Train net output #0: loss = 1.30558 (* 1 = 1.30558 loss)
I0525 16:52:15.171928 23215 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I0525 16:52:23.897356 23215 solver.cpp:237] Iteration 72150, loss = 1.19443
I0525 16:52:23.897398 23215 solver.cpp:253]     Train net output #0: loss = 1.19443 (* 1 = 1.19443 loss)
I0525 16:52:23.897419 23215 sgd_solver.cpp:106] Iteration 72150, lr = 0.001
I0525 16:52:32.620952 23215 solver.cpp:237] Iteration 72300, loss = 1.12525
I0525 16:52:32.621152 23215 solver.cpp:253]     Train net output #0: loss = 1.12525 (* 1 = 1.12525 loss)
I0525 16:52:32.621166 23215 sgd_solver.cpp:106] Iteration 72300, lr = 0.001
I0525 16:52:41.343261 23215 solver.cpp:237] Iteration 72450, loss = 1.2653
I0525 16:52:41.343296 23215 solver.cpp:253]     Train net output #0: loss = 1.2653 (* 1 = 1.2653 loss)
I0525 16:52:41.343313 23215 sgd_solver.cpp:106] Iteration 72450, lr = 0.001
I0525 16:52:50.070601 23215 solver.cpp:237] Iteration 72600, loss = 1.05694
I0525 16:52:50.070646 23215 solver.cpp:253]     Train net output #0: loss = 1.05694 (* 1 = 1.05694 loss)
I0525 16:52:50.070663 23215 sgd_solver.cpp:106] Iteration 72600, lr = 0.001
I0525 16:52:58.796635 23215 solver.cpp:237] Iteration 72750, loss = 1.09016
I0525 16:52:58.796670 23215 solver.cpp:253]     Train net output #0: loss = 1.09016 (* 1 = 1.09016 loss)
I0525 16:52:58.796687 23215 sgd_solver.cpp:106] Iteration 72750, lr = 0.001
aprun: Apid 11264672: Caught signal Terminated, sending to application
*** Aborted at 1464209578 (unix time) try "date -d @1464209578" if you are using GNU date ***
aprun: Apid 11264672: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11264672: Caught signal Terminated, sending to application
*** SIGTERM (@0x5aac) received by PID 23215 (TID 0x2aaac746f900) from PID 23212; stack trace: ***
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
=>> PBS: job killed: walltime 7233 exceeded limit 7200
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11264672: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 03789] [c8-1c0s6n1] [Wed May 25 16:53:00 2016] PE RANK 0 exit signal Terminated
Application 11264672 exit codes: 143
Application 11264672 resources: utime ~6240s, stime ~983s, Rss ~5333168, inblocks ~16605764, outblocks ~740501
