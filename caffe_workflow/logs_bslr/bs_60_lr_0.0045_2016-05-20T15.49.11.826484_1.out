2809008
I0523 20:01:35.035495 14326 caffe.cpp:184] Using GPUs 0
I0523 20:01:35.460904 14326 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.0045
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484.prototxt"
I0523 20:01:35.462841 14326 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484.prototxt
I0523 20:01:35.482484 14326 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 20:01:35.482544 14326 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 20:01:35.482892 14326 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 20:01:35.483072 14326 layer_factory.hpp:77] Creating layer data_hdf5
I0523 20:01:35.483095 14326 net.cpp:106] Creating Layer data_hdf5
I0523 20:01:35.483109 14326 net.cpp:411] data_hdf5 -> data
I0523 20:01:35.483144 14326 net.cpp:411] data_hdf5 -> label
I0523 20:01:35.483176 14326 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 20:01:35.491976 14326 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 20:01:35.508329 14326 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 20:01:57.089300 14326 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 20:01:57.094522 14326 net.cpp:150] Setting up data_hdf5
I0523 20:01:57.094563 14326 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 20:01:57.094576 14326 net.cpp:157] Top shape: 60 (60)
I0523 20:01:57.094588 14326 net.cpp:165] Memory required for data: 1524240
I0523 20:01:57.094600 14326 layer_factory.hpp:77] Creating layer conv1
I0523 20:01:57.094635 14326 net.cpp:106] Creating Layer conv1
I0523 20:01:57.094646 14326 net.cpp:454] conv1 <- data
I0523 20:01:57.094669 14326 net.cpp:411] conv1 -> conv1
I0523 20:02:00.194335 14326 net.cpp:150] Setting up conv1
I0523 20:02:00.194382 14326 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:02:00.194393 14326 net.cpp:165] Memory required for data: 18113040
I0523 20:02:00.194423 14326 layer_factory.hpp:77] Creating layer relu1
I0523 20:02:00.194445 14326 net.cpp:106] Creating Layer relu1
I0523 20:02:00.194456 14326 net.cpp:454] relu1 <- conv1
I0523 20:02:00.194469 14326 net.cpp:397] relu1 -> conv1 (in-place)
I0523 20:02:00.194988 14326 net.cpp:150] Setting up relu1
I0523 20:02:00.195004 14326 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:02:00.195015 14326 net.cpp:165] Memory required for data: 34701840
I0523 20:02:00.195024 14326 layer_factory.hpp:77] Creating layer pool1
I0523 20:02:00.195042 14326 net.cpp:106] Creating Layer pool1
I0523 20:02:00.195051 14326 net.cpp:454] pool1 <- conv1
I0523 20:02:00.195065 14326 net.cpp:411] pool1 -> pool1
I0523 20:02:00.195145 14326 net.cpp:150] Setting up pool1
I0523 20:02:00.195159 14326 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 20:02:00.195169 14326 net.cpp:165] Memory required for data: 42996240
I0523 20:02:00.195180 14326 layer_factory.hpp:77] Creating layer conv2
I0523 20:02:00.195202 14326 net.cpp:106] Creating Layer conv2
I0523 20:02:00.195214 14326 net.cpp:454] conv2 <- pool1
I0523 20:02:00.195227 14326 net.cpp:411] conv2 -> conv2
I0523 20:02:00.197973 14326 net.cpp:150] Setting up conv2
I0523 20:02:00.198001 14326 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:02:00.198012 14326 net.cpp:165] Memory required for data: 54919440
I0523 20:02:00.198031 14326 layer_factory.hpp:77] Creating layer relu2
I0523 20:02:00.198046 14326 net.cpp:106] Creating Layer relu2
I0523 20:02:00.198056 14326 net.cpp:454] relu2 <- conv2
I0523 20:02:00.198068 14326 net.cpp:397] relu2 -> conv2 (in-place)
I0523 20:02:00.198401 14326 net.cpp:150] Setting up relu2
I0523 20:02:00.198416 14326 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:02:00.198426 14326 net.cpp:165] Memory required for data: 66842640
I0523 20:02:00.198436 14326 layer_factory.hpp:77] Creating layer pool2
I0523 20:02:00.198448 14326 net.cpp:106] Creating Layer pool2
I0523 20:02:00.198458 14326 net.cpp:454] pool2 <- conv2
I0523 20:02:00.198472 14326 net.cpp:411] pool2 -> pool2
I0523 20:02:00.198552 14326 net.cpp:150] Setting up pool2
I0523 20:02:00.198565 14326 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 20:02:00.198575 14326 net.cpp:165] Memory required for data: 72804240
I0523 20:02:00.198585 14326 layer_factory.hpp:77] Creating layer conv3
I0523 20:02:00.198601 14326 net.cpp:106] Creating Layer conv3
I0523 20:02:00.198611 14326 net.cpp:454] conv3 <- pool2
I0523 20:02:00.198626 14326 net.cpp:411] conv3 -> conv3
I0523 20:02:00.200558 14326 net.cpp:150] Setting up conv3
I0523 20:02:00.200582 14326 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:02:00.200594 14326 net.cpp:165] Memory required for data: 79309200
I0523 20:02:00.200613 14326 layer_factory.hpp:77] Creating layer relu3
I0523 20:02:00.200628 14326 net.cpp:106] Creating Layer relu3
I0523 20:02:00.200639 14326 net.cpp:454] relu3 <- conv3
I0523 20:02:00.200651 14326 net.cpp:397] relu3 -> conv3 (in-place)
I0523 20:02:00.201133 14326 net.cpp:150] Setting up relu3
I0523 20:02:00.201149 14326 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:02:00.201160 14326 net.cpp:165] Memory required for data: 85814160
I0523 20:02:00.201171 14326 layer_factory.hpp:77] Creating layer pool3
I0523 20:02:00.201184 14326 net.cpp:106] Creating Layer pool3
I0523 20:02:00.201194 14326 net.cpp:454] pool3 <- conv3
I0523 20:02:00.201207 14326 net.cpp:411] pool3 -> pool3
I0523 20:02:00.201274 14326 net.cpp:150] Setting up pool3
I0523 20:02:00.201287 14326 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 20:02:00.201297 14326 net.cpp:165] Memory required for data: 89066640
I0523 20:02:00.201308 14326 layer_factory.hpp:77] Creating layer conv4
I0523 20:02:00.201324 14326 net.cpp:106] Creating Layer conv4
I0523 20:02:00.201335 14326 net.cpp:454] conv4 <- pool3
I0523 20:02:00.201349 14326 net.cpp:411] conv4 -> conv4
I0523 20:02:00.204102 14326 net.cpp:150] Setting up conv4
I0523 20:02:00.204130 14326 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:02:00.204141 14326 net.cpp:165] Memory required for data: 91243920
I0523 20:02:00.204156 14326 layer_factory.hpp:77] Creating layer relu4
I0523 20:02:00.204171 14326 net.cpp:106] Creating Layer relu4
I0523 20:02:00.204181 14326 net.cpp:454] relu4 <- conv4
I0523 20:02:00.204193 14326 net.cpp:397] relu4 -> conv4 (in-place)
I0523 20:02:00.204666 14326 net.cpp:150] Setting up relu4
I0523 20:02:00.204682 14326 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:02:00.204694 14326 net.cpp:165] Memory required for data: 93421200
I0523 20:02:00.204704 14326 layer_factory.hpp:77] Creating layer pool4
I0523 20:02:00.204717 14326 net.cpp:106] Creating Layer pool4
I0523 20:02:00.204726 14326 net.cpp:454] pool4 <- conv4
I0523 20:02:00.204740 14326 net.cpp:411] pool4 -> pool4
I0523 20:02:00.204808 14326 net.cpp:150] Setting up pool4
I0523 20:02:00.204821 14326 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 20:02:00.204833 14326 net.cpp:165] Memory required for data: 94509840
I0523 20:02:00.204843 14326 layer_factory.hpp:77] Creating layer ip1
I0523 20:02:00.204872 14326 net.cpp:106] Creating Layer ip1
I0523 20:02:00.204884 14326 net.cpp:454] ip1 <- pool4
I0523 20:02:00.204896 14326 net.cpp:411] ip1 -> ip1
I0523 20:02:00.220260 14326 net.cpp:150] Setting up ip1
I0523 20:02:00.220289 14326 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:02:00.220301 14326 net.cpp:165] Memory required for data: 94556880
I0523 20:02:00.220324 14326 layer_factory.hpp:77] Creating layer relu5
I0523 20:02:00.220338 14326 net.cpp:106] Creating Layer relu5
I0523 20:02:00.220350 14326 net.cpp:454] relu5 <- ip1
I0523 20:02:00.220362 14326 net.cpp:397] relu5 -> ip1 (in-place)
I0523 20:02:00.220705 14326 net.cpp:150] Setting up relu5
I0523 20:02:00.220720 14326 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:02:00.220729 14326 net.cpp:165] Memory required for data: 94603920
I0523 20:02:00.220741 14326 layer_factory.hpp:77] Creating layer drop1
I0523 20:02:00.220762 14326 net.cpp:106] Creating Layer drop1
I0523 20:02:00.220772 14326 net.cpp:454] drop1 <- ip1
I0523 20:02:00.220783 14326 net.cpp:397] drop1 -> ip1 (in-place)
I0523 20:02:00.220844 14326 net.cpp:150] Setting up drop1
I0523 20:02:00.220863 14326 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:02:00.220873 14326 net.cpp:165] Memory required for data: 94650960
I0523 20:02:00.220883 14326 layer_factory.hpp:77] Creating layer ip2
I0523 20:02:00.220902 14326 net.cpp:106] Creating Layer ip2
I0523 20:02:00.220913 14326 net.cpp:454] ip2 <- ip1
I0523 20:02:00.220927 14326 net.cpp:411] ip2 -> ip2
I0523 20:02:00.221390 14326 net.cpp:150] Setting up ip2
I0523 20:02:00.221402 14326 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:02:00.221412 14326 net.cpp:165] Memory required for data: 94674480
I0523 20:02:00.221427 14326 layer_factory.hpp:77] Creating layer relu6
I0523 20:02:00.221441 14326 net.cpp:106] Creating Layer relu6
I0523 20:02:00.221451 14326 net.cpp:454] relu6 <- ip2
I0523 20:02:00.221462 14326 net.cpp:397] relu6 -> ip2 (in-place)
I0523 20:02:00.221983 14326 net.cpp:150] Setting up relu6
I0523 20:02:00.222000 14326 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:02:00.222012 14326 net.cpp:165] Memory required for data: 94698000
I0523 20:02:00.222021 14326 layer_factory.hpp:77] Creating layer drop2
I0523 20:02:00.222034 14326 net.cpp:106] Creating Layer drop2
I0523 20:02:00.222044 14326 net.cpp:454] drop2 <- ip2
I0523 20:02:00.222056 14326 net.cpp:397] drop2 -> ip2 (in-place)
I0523 20:02:00.222100 14326 net.cpp:150] Setting up drop2
I0523 20:02:00.222112 14326 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:02:00.222123 14326 net.cpp:165] Memory required for data: 94721520
I0523 20:02:00.222132 14326 layer_factory.hpp:77] Creating layer ip3
I0523 20:02:00.222146 14326 net.cpp:106] Creating Layer ip3
I0523 20:02:00.222156 14326 net.cpp:454] ip3 <- ip2
I0523 20:02:00.222168 14326 net.cpp:411] ip3 -> ip3
I0523 20:02:00.222380 14326 net.cpp:150] Setting up ip3
I0523 20:02:00.222393 14326 net.cpp:157] Top shape: 60 11 (660)
I0523 20:02:00.222404 14326 net.cpp:165] Memory required for data: 94724160
I0523 20:02:00.222419 14326 layer_factory.hpp:77] Creating layer drop3
I0523 20:02:00.222431 14326 net.cpp:106] Creating Layer drop3
I0523 20:02:00.222440 14326 net.cpp:454] drop3 <- ip3
I0523 20:02:00.222452 14326 net.cpp:397] drop3 -> ip3 (in-place)
I0523 20:02:00.222493 14326 net.cpp:150] Setting up drop3
I0523 20:02:00.222506 14326 net.cpp:157] Top shape: 60 11 (660)
I0523 20:02:00.222517 14326 net.cpp:165] Memory required for data: 94726800
I0523 20:02:00.222525 14326 layer_factory.hpp:77] Creating layer loss
I0523 20:02:00.222544 14326 net.cpp:106] Creating Layer loss
I0523 20:02:00.222554 14326 net.cpp:454] loss <- ip3
I0523 20:02:00.222565 14326 net.cpp:454] loss <- label
I0523 20:02:00.222578 14326 net.cpp:411] loss -> loss
I0523 20:02:00.222594 14326 layer_factory.hpp:77] Creating layer loss
I0523 20:02:00.223242 14326 net.cpp:150] Setting up loss
I0523 20:02:00.223263 14326 net.cpp:157] Top shape: (1)
I0523 20:02:00.223275 14326 net.cpp:160]     with loss weight 1
I0523 20:02:00.223318 14326 net.cpp:165] Memory required for data: 94726804
I0523 20:02:00.223328 14326 net.cpp:226] loss needs backward computation.
I0523 20:02:00.223340 14326 net.cpp:226] drop3 needs backward computation.
I0523 20:02:00.223350 14326 net.cpp:226] ip3 needs backward computation.
I0523 20:02:00.223357 14326 net.cpp:226] drop2 needs backward computation.
I0523 20:02:00.223367 14326 net.cpp:226] relu6 needs backward computation.
I0523 20:02:00.223377 14326 net.cpp:226] ip2 needs backward computation.
I0523 20:02:00.223387 14326 net.cpp:226] drop1 needs backward computation.
I0523 20:02:00.223398 14326 net.cpp:226] relu5 needs backward computation.
I0523 20:02:00.223407 14326 net.cpp:226] ip1 needs backward computation.
I0523 20:02:00.223418 14326 net.cpp:226] pool4 needs backward computation.
I0523 20:02:00.223428 14326 net.cpp:226] relu4 needs backward computation.
I0523 20:02:00.223438 14326 net.cpp:226] conv4 needs backward computation.
I0523 20:02:00.223448 14326 net.cpp:226] pool3 needs backward computation.
I0523 20:02:00.223459 14326 net.cpp:226] relu3 needs backward computation.
I0523 20:02:00.223467 14326 net.cpp:226] conv3 needs backward computation.
I0523 20:02:00.223486 14326 net.cpp:226] pool2 needs backward computation.
I0523 20:02:00.223497 14326 net.cpp:226] relu2 needs backward computation.
I0523 20:02:00.223508 14326 net.cpp:226] conv2 needs backward computation.
I0523 20:02:00.223518 14326 net.cpp:226] pool1 needs backward computation.
I0523 20:02:00.223528 14326 net.cpp:226] relu1 needs backward computation.
I0523 20:02:00.223538 14326 net.cpp:226] conv1 needs backward computation.
I0523 20:02:00.223549 14326 net.cpp:228] data_hdf5 does not need backward computation.
I0523 20:02:00.223559 14326 net.cpp:270] This network produces output loss
I0523 20:02:00.223583 14326 net.cpp:283] Network initialization done.
I0523 20:02:00.225277 14326 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484.prototxt
I0523 20:02:00.225348 14326 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 20:02:00.225703 14326 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 20:02:00.225893 14326 layer_factory.hpp:77] Creating layer data_hdf5
I0523 20:02:00.225908 14326 net.cpp:106] Creating Layer data_hdf5
I0523 20:02:00.225920 14326 net.cpp:411] data_hdf5 -> data
I0523 20:02:00.225937 14326 net.cpp:411] data_hdf5 -> label
I0523 20:02:00.225953 14326 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 20:02:00.233757 14326 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 20:02:21.663427 14326 net.cpp:150] Setting up data_hdf5
I0523 20:02:21.663594 14326 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 20:02:21.663609 14326 net.cpp:157] Top shape: 60 (60)
I0523 20:02:21.663620 14326 net.cpp:165] Memory required for data: 1524240
I0523 20:02:21.663635 14326 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 20:02:21.663662 14326 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 20:02:21.663674 14326 net.cpp:454] label_data_hdf5_1_split <- label
I0523 20:02:21.663688 14326 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 20:02:21.663710 14326 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 20:02:21.663781 14326 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 20:02:21.663796 14326 net.cpp:157] Top shape: 60 (60)
I0523 20:02:21.663810 14326 net.cpp:157] Top shape: 60 (60)
I0523 20:02:21.663820 14326 net.cpp:165] Memory required for data: 1524720
I0523 20:02:21.663830 14326 layer_factory.hpp:77] Creating layer conv1
I0523 20:02:21.663851 14326 net.cpp:106] Creating Layer conv1
I0523 20:02:21.663861 14326 net.cpp:454] conv1 <- data
I0523 20:02:21.663877 14326 net.cpp:411] conv1 -> conv1
I0523 20:02:21.665804 14326 net.cpp:150] Setting up conv1
I0523 20:02:21.665828 14326 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:02:21.665839 14326 net.cpp:165] Memory required for data: 18113520
I0523 20:02:21.665860 14326 layer_factory.hpp:77] Creating layer relu1
I0523 20:02:21.665875 14326 net.cpp:106] Creating Layer relu1
I0523 20:02:21.665885 14326 net.cpp:454] relu1 <- conv1
I0523 20:02:21.665899 14326 net.cpp:397] relu1 -> conv1 (in-place)
I0523 20:02:21.666401 14326 net.cpp:150] Setting up relu1
I0523 20:02:21.666417 14326 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:02:21.666427 14326 net.cpp:165] Memory required for data: 34702320
I0523 20:02:21.666438 14326 layer_factory.hpp:77] Creating layer pool1
I0523 20:02:21.666455 14326 net.cpp:106] Creating Layer pool1
I0523 20:02:21.666465 14326 net.cpp:454] pool1 <- conv1
I0523 20:02:21.666477 14326 net.cpp:411] pool1 -> pool1
I0523 20:02:21.666551 14326 net.cpp:150] Setting up pool1
I0523 20:02:21.666564 14326 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 20:02:21.666574 14326 net.cpp:165] Memory required for data: 42996720
I0523 20:02:21.666582 14326 layer_factory.hpp:77] Creating layer conv2
I0523 20:02:21.666600 14326 net.cpp:106] Creating Layer conv2
I0523 20:02:21.666611 14326 net.cpp:454] conv2 <- pool1
I0523 20:02:21.666625 14326 net.cpp:411] conv2 -> conv2
I0523 20:02:21.668620 14326 net.cpp:150] Setting up conv2
I0523 20:02:21.668637 14326 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:02:21.668653 14326 net.cpp:165] Memory required for data: 54919920
I0523 20:02:21.668671 14326 layer_factory.hpp:77] Creating layer relu2
I0523 20:02:21.668685 14326 net.cpp:106] Creating Layer relu2
I0523 20:02:21.668695 14326 net.cpp:454] relu2 <- conv2
I0523 20:02:21.668707 14326 net.cpp:397] relu2 -> conv2 (in-place)
I0523 20:02:21.669049 14326 net.cpp:150] Setting up relu2
I0523 20:02:21.669062 14326 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:02:21.669072 14326 net.cpp:165] Memory required for data: 66843120
I0523 20:02:21.669083 14326 layer_factory.hpp:77] Creating layer pool2
I0523 20:02:21.669096 14326 net.cpp:106] Creating Layer pool2
I0523 20:02:21.669106 14326 net.cpp:454] pool2 <- conv2
I0523 20:02:21.669118 14326 net.cpp:411] pool2 -> pool2
I0523 20:02:21.669190 14326 net.cpp:150] Setting up pool2
I0523 20:02:21.669203 14326 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 20:02:21.669214 14326 net.cpp:165] Memory required for data: 72804720
I0523 20:02:21.669224 14326 layer_factory.hpp:77] Creating layer conv3
I0523 20:02:21.669241 14326 net.cpp:106] Creating Layer conv3
I0523 20:02:21.669251 14326 net.cpp:454] conv3 <- pool2
I0523 20:02:21.669265 14326 net.cpp:411] conv3 -> conv3
I0523 20:02:21.671231 14326 net.cpp:150] Setting up conv3
I0523 20:02:21.671254 14326 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:02:21.671267 14326 net.cpp:165] Memory required for data: 79309680
I0523 20:02:21.671299 14326 layer_factory.hpp:77] Creating layer relu3
I0523 20:02:21.671313 14326 net.cpp:106] Creating Layer relu3
I0523 20:02:21.671322 14326 net.cpp:454] relu3 <- conv3
I0523 20:02:21.671335 14326 net.cpp:397] relu3 -> conv3 (in-place)
I0523 20:02:21.671804 14326 net.cpp:150] Setting up relu3
I0523 20:02:21.671820 14326 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:02:21.671830 14326 net.cpp:165] Memory required for data: 85814640
I0523 20:02:21.671840 14326 layer_factory.hpp:77] Creating layer pool3
I0523 20:02:21.671854 14326 net.cpp:106] Creating Layer pool3
I0523 20:02:21.671864 14326 net.cpp:454] pool3 <- conv3
I0523 20:02:21.671876 14326 net.cpp:411] pool3 -> pool3
I0523 20:02:21.671947 14326 net.cpp:150] Setting up pool3
I0523 20:02:21.671960 14326 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 20:02:21.671970 14326 net.cpp:165] Memory required for data: 89067120
I0523 20:02:21.671979 14326 layer_factory.hpp:77] Creating layer conv4
I0523 20:02:21.671998 14326 net.cpp:106] Creating Layer conv4
I0523 20:02:21.672008 14326 net.cpp:454] conv4 <- pool3
I0523 20:02:21.672022 14326 net.cpp:411] conv4 -> conv4
I0523 20:02:21.674084 14326 net.cpp:150] Setting up conv4
I0523 20:02:21.674108 14326 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:02:21.674119 14326 net.cpp:165] Memory required for data: 91244400
I0523 20:02:21.674134 14326 layer_factory.hpp:77] Creating layer relu4
I0523 20:02:21.674149 14326 net.cpp:106] Creating Layer relu4
I0523 20:02:21.674159 14326 net.cpp:454] relu4 <- conv4
I0523 20:02:21.674171 14326 net.cpp:397] relu4 -> conv4 (in-place)
I0523 20:02:21.674643 14326 net.cpp:150] Setting up relu4
I0523 20:02:21.674659 14326 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:02:21.674669 14326 net.cpp:165] Memory required for data: 93421680
I0523 20:02:21.674679 14326 layer_factory.hpp:77] Creating layer pool4
I0523 20:02:21.674692 14326 net.cpp:106] Creating Layer pool4
I0523 20:02:21.674702 14326 net.cpp:454] pool4 <- conv4
I0523 20:02:21.674716 14326 net.cpp:411] pool4 -> pool4
I0523 20:02:21.674787 14326 net.cpp:150] Setting up pool4
I0523 20:02:21.674800 14326 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 20:02:21.674810 14326 net.cpp:165] Memory required for data: 94510320
I0523 20:02:21.674820 14326 layer_factory.hpp:77] Creating layer ip1
I0523 20:02:21.674835 14326 net.cpp:106] Creating Layer ip1
I0523 20:02:21.674846 14326 net.cpp:454] ip1 <- pool4
I0523 20:02:21.674860 14326 net.cpp:411] ip1 -> ip1
I0523 20:02:21.690347 14326 net.cpp:150] Setting up ip1
I0523 20:02:21.690376 14326 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:02:21.690389 14326 net.cpp:165] Memory required for data: 94557360
I0523 20:02:21.690415 14326 layer_factory.hpp:77] Creating layer relu5
I0523 20:02:21.690430 14326 net.cpp:106] Creating Layer relu5
I0523 20:02:21.690441 14326 net.cpp:454] relu5 <- ip1
I0523 20:02:21.690455 14326 net.cpp:397] relu5 -> ip1 (in-place)
I0523 20:02:21.690804 14326 net.cpp:150] Setting up relu5
I0523 20:02:21.690817 14326 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:02:21.690827 14326 net.cpp:165] Memory required for data: 94604400
I0523 20:02:21.690837 14326 layer_factory.hpp:77] Creating layer drop1
I0523 20:02:21.690855 14326 net.cpp:106] Creating Layer drop1
I0523 20:02:21.690865 14326 net.cpp:454] drop1 <- ip1
I0523 20:02:21.690878 14326 net.cpp:397] drop1 -> ip1 (in-place)
I0523 20:02:21.690923 14326 net.cpp:150] Setting up drop1
I0523 20:02:21.690937 14326 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:02:21.690946 14326 net.cpp:165] Memory required for data: 94651440
I0523 20:02:21.690956 14326 layer_factory.hpp:77] Creating layer ip2
I0523 20:02:21.690971 14326 net.cpp:106] Creating Layer ip2
I0523 20:02:21.690981 14326 net.cpp:454] ip2 <- ip1
I0523 20:02:21.690994 14326 net.cpp:411] ip2 -> ip2
I0523 20:02:21.691471 14326 net.cpp:150] Setting up ip2
I0523 20:02:21.691484 14326 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:02:21.691493 14326 net.cpp:165] Memory required for data: 94674960
I0523 20:02:21.691509 14326 layer_factory.hpp:77] Creating layer relu6
I0523 20:02:21.691536 14326 net.cpp:106] Creating Layer relu6
I0523 20:02:21.691547 14326 net.cpp:454] relu6 <- ip2
I0523 20:02:21.691560 14326 net.cpp:397] relu6 -> ip2 (in-place)
I0523 20:02:21.692093 14326 net.cpp:150] Setting up relu6
I0523 20:02:21.692116 14326 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:02:21.692126 14326 net.cpp:165] Memory required for data: 94698480
I0523 20:02:21.692137 14326 layer_factory.hpp:77] Creating layer drop2
I0523 20:02:21.692152 14326 net.cpp:106] Creating Layer drop2
I0523 20:02:21.692162 14326 net.cpp:454] drop2 <- ip2
I0523 20:02:21.692174 14326 net.cpp:397] drop2 -> ip2 (in-place)
I0523 20:02:21.692219 14326 net.cpp:150] Setting up drop2
I0523 20:02:21.692231 14326 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:02:21.692241 14326 net.cpp:165] Memory required for data: 94722000
I0523 20:02:21.692251 14326 layer_factory.hpp:77] Creating layer ip3
I0523 20:02:21.692265 14326 net.cpp:106] Creating Layer ip3
I0523 20:02:21.692276 14326 net.cpp:454] ip3 <- ip2
I0523 20:02:21.692288 14326 net.cpp:411] ip3 -> ip3
I0523 20:02:21.692510 14326 net.cpp:150] Setting up ip3
I0523 20:02:21.692523 14326 net.cpp:157] Top shape: 60 11 (660)
I0523 20:02:21.692533 14326 net.cpp:165] Memory required for data: 94724640
I0523 20:02:21.692548 14326 layer_factory.hpp:77] Creating layer drop3
I0523 20:02:21.692561 14326 net.cpp:106] Creating Layer drop3
I0523 20:02:21.692570 14326 net.cpp:454] drop3 <- ip3
I0523 20:02:21.692584 14326 net.cpp:397] drop3 -> ip3 (in-place)
I0523 20:02:21.692625 14326 net.cpp:150] Setting up drop3
I0523 20:02:21.692636 14326 net.cpp:157] Top shape: 60 11 (660)
I0523 20:02:21.692646 14326 net.cpp:165] Memory required for data: 94727280
I0523 20:02:21.692656 14326 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 20:02:21.692669 14326 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 20:02:21.692679 14326 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 20:02:21.692692 14326 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 20:02:21.692708 14326 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 20:02:21.692781 14326 net.cpp:150] Setting up ip3_drop3_0_split
I0523 20:02:21.692795 14326 net.cpp:157] Top shape: 60 11 (660)
I0523 20:02:21.692807 14326 net.cpp:157] Top shape: 60 11 (660)
I0523 20:02:21.692816 14326 net.cpp:165] Memory required for data: 94732560
I0523 20:02:21.692824 14326 layer_factory.hpp:77] Creating layer accuracy
I0523 20:02:21.692847 14326 net.cpp:106] Creating Layer accuracy
I0523 20:02:21.692862 14326 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 20:02:21.692875 14326 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 20:02:21.692889 14326 net.cpp:411] accuracy -> accuracy
I0523 20:02:21.692912 14326 net.cpp:150] Setting up accuracy
I0523 20:02:21.692925 14326 net.cpp:157] Top shape: (1)
I0523 20:02:21.692935 14326 net.cpp:165] Memory required for data: 94732564
I0523 20:02:21.692945 14326 layer_factory.hpp:77] Creating layer loss
I0523 20:02:21.692960 14326 net.cpp:106] Creating Layer loss
I0523 20:02:21.692970 14326 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 20:02:21.692981 14326 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 20:02:21.692993 14326 net.cpp:411] loss -> loss
I0523 20:02:21.693011 14326 layer_factory.hpp:77] Creating layer loss
I0523 20:02:21.693496 14326 net.cpp:150] Setting up loss
I0523 20:02:21.693509 14326 net.cpp:157] Top shape: (1)
I0523 20:02:21.693519 14326 net.cpp:160]     with loss weight 1
I0523 20:02:21.693537 14326 net.cpp:165] Memory required for data: 94732568
I0523 20:02:21.693548 14326 net.cpp:226] loss needs backward computation.
I0523 20:02:21.693559 14326 net.cpp:228] accuracy does not need backward computation.
I0523 20:02:21.693570 14326 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 20:02:21.693580 14326 net.cpp:226] drop3 needs backward computation.
I0523 20:02:21.693591 14326 net.cpp:226] ip3 needs backward computation.
I0523 20:02:21.693601 14326 net.cpp:226] drop2 needs backward computation.
I0523 20:02:21.693611 14326 net.cpp:226] relu6 needs backward computation.
I0523 20:02:21.693629 14326 net.cpp:226] ip2 needs backward computation.
I0523 20:02:21.693639 14326 net.cpp:226] drop1 needs backward computation.
I0523 20:02:21.693648 14326 net.cpp:226] relu5 needs backward computation.
I0523 20:02:21.693658 14326 net.cpp:226] ip1 needs backward computation.
I0523 20:02:21.693668 14326 net.cpp:226] pool4 needs backward computation.
I0523 20:02:21.693678 14326 net.cpp:226] relu4 needs backward computation.
I0523 20:02:21.693689 14326 net.cpp:226] conv4 needs backward computation.
I0523 20:02:21.693701 14326 net.cpp:226] pool3 needs backward computation.
I0523 20:02:21.693711 14326 net.cpp:226] relu3 needs backward computation.
I0523 20:02:21.693720 14326 net.cpp:226] conv3 needs backward computation.
I0523 20:02:21.693730 14326 net.cpp:226] pool2 needs backward computation.
I0523 20:02:21.693742 14326 net.cpp:226] relu2 needs backward computation.
I0523 20:02:21.693752 14326 net.cpp:226] conv2 needs backward computation.
I0523 20:02:21.693761 14326 net.cpp:226] pool1 needs backward computation.
I0523 20:02:21.693771 14326 net.cpp:226] relu1 needs backward computation.
I0523 20:02:21.693781 14326 net.cpp:226] conv1 needs backward computation.
I0523 20:02:21.693794 14326 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 20:02:21.693804 14326 net.cpp:228] data_hdf5 does not need backward computation.
I0523 20:02:21.693814 14326 net.cpp:270] This network produces output accuracy
I0523 20:02:21.693825 14326 net.cpp:270] This network produces output loss
I0523 20:02:21.693853 14326 net.cpp:283] Network initialization done.
I0523 20:02:21.693986 14326 solver.cpp:60] Solver scaffolding done.
I0523 20:02:21.695117 14326 caffe.cpp:212] Starting Optimization
I0523 20:02:21.695132 14326 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 20:02:21.695143 14326 solver.cpp:289] Learning Rate Policy: fixed
I0523 20:02:21.696367 14326 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 20:03:09.946333 14326 solver.cpp:409]     Test net output #0: accuracy = 0.0885468
I0523 20:03:09.946491 14326 solver.cpp:409]     Test net output #1: loss = 2.39843 (* 1 = 2.39843 loss)
I0523 20:03:09.972489 14326 solver.cpp:237] Iteration 0, loss = 2.39776
I0523 20:03:09.972525 14326 solver.cpp:253]     Train net output #0: loss = 2.39776 (* 1 = 2.39776 loss)
I0523 20:03:09.972543 14326 sgd_solver.cpp:106] Iteration 0, lr = 0.0045
I0523 20:03:19.055219 14326 solver.cpp:237] Iteration 250, loss = 2.03624
I0523 20:03:19.055269 14326 solver.cpp:253]     Train net output #0: loss = 2.03624 (* 1 = 2.03624 loss)
I0523 20:03:19.055282 14326 sgd_solver.cpp:106] Iteration 250, lr = 0.0045
I0523 20:03:28.150296 14326 solver.cpp:237] Iteration 500, loss = 1.80155
I0523 20:03:28.150331 14326 solver.cpp:253]     Train net output #0: loss = 1.80155 (* 1 = 1.80155 loss)
I0523 20:03:28.150347 14326 sgd_solver.cpp:106] Iteration 500, lr = 0.0045
I0523 20:03:37.241361 14326 solver.cpp:237] Iteration 750, loss = 1.98009
I0523 20:03:37.241397 14326 solver.cpp:253]     Train net output #0: loss = 1.98009 (* 1 = 1.98009 loss)
I0523 20:03:37.241412 14326 sgd_solver.cpp:106] Iteration 750, lr = 0.0045
I0523 20:03:46.338014 14326 solver.cpp:237] Iteration 1000, loss = 1.68764
I0523 20:03:46.338171 14326 solver.cpp:253]     Train net output #0: loss = 1.68764 (* 1 = 1.68764 loss)
I0523 20:03:46.338186 14326 sgd_solver.cpp:106] Iteration 1000, lr = 0.0045
I0523 20:03:55.433898 14326 solver.cpp:237] Iteration 1250, loss = 1.6432
I0523 20:03:55.433933 14326 solver.cpp:253]     Train net output #0: loss = 1.6432 (* 1 = 1.6432 loss)
I0523 20:03:55.433948 14326 sgd_solver.cpp:106] Iteration 1250, lr = 0.0045
I0523 20:04:04.519301 14326 solver.cpp:237] Iteration 1500, loss = 1.6073
I0523 20:04:04.519341 14326 solver.cpp:253]     Train net output #0: loss = 1.6073 (* 1 = 1.6073 loss)
I0523 20:04:04.519358 14326 sgd_solver.cpp:106] Iteration 1500, lr = 0.0045
I0523 20:04:35.796484 14326 solver.cpp:237] Iteration 1750, loss = 1.78624
I0523 20:04:35.796646 14326 solver.cpp:253]     Train net output #0: loss = 1.78624 (* 1 = 1.78624 loss)
I0523 20:04:35.796661 14326 sgd_solver.cpp:106] Iteration 1750, lr = 0.0045
I0523 20:04:44.895802 14326 solver.cpp:237] Iteration 2000, loss = 1.21686
I0523 20:04:44.895836 14326 solver.cpp:253]     Train net output #0: loss = 1.21686 (* 1 = 1.21686 loss)
I0523 20:04:44.895854 14326 sgd_solver.cpp:106] Iteration 2000, lr = 0.0045
I0523 20:04:53.994194 14326 solver.cpp:237] Iteration 2250, loss = 1.74041
I0523 20:04:53.994228 14326 solver.cpp:253]     Train net output #0: loss = 1.74041 (* 1 = 1.74041 loss)
I0523 20:04:53.994246 14326 sgd_solver.cpp:106] Iteration 2250, lr = 0.0045
I0523 20:05:03.057910 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_2500.caffemodel
I0523 20:05:03.123606 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_2500.solverstate
I0523 20:05:03.160053 14326 solver.cpp:237] Iteration 2500, loss = 1.42526
I0523 20:05:03.160097 14326 solver.cpp:253]     Train net output #0: loss = 1.42526 (* 1 = 1.42526 loss)
I0523 20:05:03.160111 14326 sgd_solver.cpp:106] Iteration 2500, lr = 0.0045
I0523 20:05:12.259543 14326 solver.cpp:237] Iteration 2750, loss = 1.41083
I0523 20:05:12.259686 14326 solver.cpp:253]     Train net output #0: loss = 1.41083 (* 1 = 1.41083 loss)
I0523 20:05:12.259699 14326 sgd_solver.cpp:106] Iteration 2750, lr = 0.0045
I0523 20:05:21.359639 14326 solver.cpp:237] Iteration 3000, loss = 1.38754
I0523 20:05:21.359683 14326 solver.cpp:253]     Train net output #0: loss = 1.38754 (* 1 = 1.38754 loss)
I0523 20:05:21.359701 14326 sgd_solver.cpp:106] Iteration 3000, lr = 0.0045
I0523 20:05:30.447003 14326 solver.cpp:237] Iteration 3250, loss = 1.3703
I0523 20:05:30.447038 14326 solver.cpp:253]     Train net output #0: loss = 1.3703 (* 1 = 1.3703 loss)
I0523 20:05:30.447055 14326 sgd_solver.cpp:106] Iteration 3250, lr = 0.0045
I0523 20:06:01.743880 14326 solver.cpp:237] Iteration 3500, loss = 1.63479
I0523 20:06:01.744038 14326 solver.cpp:253]     Train net output #0: loss = 1.63479 (* 1 = 1.63479 loss)
I0523 20:06:01.744052 14326 sgd_solver.cpp:106] Iteration 3500, lr = 0.0045
I0523 20:06:10.832957 14326 solver.cpp:237] Iteration 3750, loss = 1.35316
I0523 20:06:10.833003 14326 solver.cpp:253]     Train net output #0: loss = 1.35316 (* 1 = 1.35316 loss)
I0523 20:06:10.833019 14326 sgd_solver.cpp:106] Iteration 3750, lr = 0.0045
I0523 20:06:19.933141 14326 solver.cpp:237] Iteration 4000, loss = 1.41295
I0523 20:06:19.933178 14326 solver.cpp:253]     Train net output #0: loss = 1.41295 (* 1 = 1.41295 loss)
I0523 20:06:19.933192 14326 sgd_solver.cpp:106] Iteration 4000, lr = 0.0045
I0523 20:06:29.029830 14326 solver.cpp:237] Iteration 4250, loss = 1.13458
I0523 20:06:29.029866 14326 solver.cpp:253]     Train net output #0: loss = 1.13458 (* 1 = 1.13458 loss)
I0523 20:06:29.029883 14326 sgd_solver.cpp:106] Iteration 4250, lr = 0.0045
I0523 20:06:38.130412 14326 solver.cpp:237] Iteration 4500, loss = 1.33344
I0523 20:06:38.130574 14326 solver.cpp:253]     Train net output #0: loss = 1.33344 (* 1 = 1.33344 loss)
I0523 20:06:38.130589 14326 sgd_solver.cpp:106] Iteration 4500, lr = 0.0045
I0523 20:06:47.235816 14326 solver.cpp:237] Iteration 4750, loss = 1.59963
I0523 20:06:47.235851 14326 solver.cpp:253]     Train net output #0: loss = 1.59963 (* 1 = 1.59963 loss)
I0523 20:06:47.235868 14326 sgd_solver.cpp:106] Iteration 4750, lr = 0.0045
I0523 20:06:56.295342 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_5000.caffemodel
I0523 20:06:56.359074 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_5000.solverstate
I0523 20:06:56.384318 14326 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 20:07:43.629376 14326 solver.cpp:409]     Test net output #0: accuracy = 0.826729
I0523 20:07:43.629534 14326 solver.cpp:409]     Test net output #1: loss = 0.613109 (* 1 = 0.613109 loss)
I0523 20:08:05.823547 14326 solver.cpp:237] Iteration 5000, loss = 1.47964
I0523 20:08:05.823597 14326 solver.cpp:253]     Train net output #0: loss = 1.47964 (* 1 = 1.47964 loss)
I0523 20:08:05.823614 14326 sgd_solver.cpp:106] Iteration 5000, lr = 0.0045
I0523 20:08:14.893633 14326 solver.cpp:237] Iteration 5250, loss = 1.22409
I0523 20:08:14.893777 14326 solver.cpp:253]     Train net output #0: loss = 1.22409 (* 1 = 1.22409 loss)
I0523 20:08:14.893792 14326 sgd_solver.cpp:106] Iteration 5250, lr = 0.0045
I0523 20:08:23.964843 14326 solver.cpp:237] Iteration 5500, loss = 1.43513
I0523 20:08:23.964881 14326 solver.cpp:253]     Train net output #0: loss = 1.43513 (* 1 = 1.43513 loss)
I0523 20:08:23.964898 14326 sgd_solver.cpp:106] Iteration 5500, lr = 0.0045
I0523 20:08:33.037252 14326 solver.cpp:237] Iteration 5750, loss = 1.26918
I0523 20:08:33.037282 14326 solver.cpp:253]     Train net output #0: loss = 1.26918 (* 1 = 1.26918 loss)
I0523 20:08:33.037295 14326 sgd_solver.cpp:106] Iteration 5750, lr = 0.0045
I0523 20:08:42.110635 14326 solver.cpp:237] Iteration 6000, loss = 1.58789
I0523 20:08:42.110677 14326 solver.cpp:253]     Train net output #0: loss = 1.58789 (* 1 = 1.58789 loss)
I0523 20:08:42.110693 14326 sgd_solver.cpp:106] Iteration 6000, lr = 0.0045
I0523 20:08:51.184612 14326 solver.cpp:237] Iteration 6250, loss = 1.28089
I0523 20:08:51.184749 14326 solver.cpp:253]     Train net output #0: loss = 1.28089 (* 1 = 1.28089 loss)
I0523 20:08:51.184763 14326 sgd_solver.cpp:106] Iteration 6250, lr = 0.0045
I0523 20:09:00.256433 14326 solver.cpp:237] Iteration 6500, loss = 1.3186
I0523 20:09:00.256467 14326 solver.cpp:253]     Train net output #0: loss = 1.3186 (* 1 = 1.3186 loss)
I0523 20:09:00.256484 14326 sgd_solver.cpp:106] Iteration 6500, lr = 0.0045
I0523 20:09:31.555835 14326 solver.cpp:237] Iteration 6750, loss = 1.44774
I0523 20:09:31.555990 14326 solver.cpp:253]     Train net output #0: loss = 1.44774 (* 1 = 1.44774 loss)
I0523 20:09:31.556005 14326 sgd_solver.cpp:106] Iteration 6750, lr = 0.0045
I0523 20:09:40.621909 14326 solver.cpp:237] Iteration 7000, loss = 1.09218
I0523 20:09:40.621944 14326 solver.cpp:253]     Train net output #0: loss = 1.09218 (* 1 = 1.09218 loss)
I0523 20:09:40.621961 14326 sgd_solver.cpp:106] Iteration 7000, lr = 0.0045
I0523 20:09:49.696176 14326 solver.cpp:237] Iteration 7250, loss = 1.38116
I0523 20:09:49.696210 14326 solver.cpp:253]     Train net output #0: loss = 1.38116 (* 1 = 1.38116 loss)
I0523 20:09:49.696226 14326 sgd_solver.cpp:106] Iteration 7250, lr = 0.0045
I0523 20:09:58.727334 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_7500.caffemodel
I0523 20:09:58.792732 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_7500.solverstate
I0523 20:09:58.831198 14326 solver.cpp:237] Iteration 7500, loss = 1.22313
I0523 20:09:58.831248 14326 solver.cpp:253]     Train net output #0: loss = 1.22313 (* 1 = 1.22313 loss)
I0523 20:09:58.831264 14326 sgd_solver.cpp:106] Iteration 7500, lr = 0.0045
I0523 20:10:07.902092 14326 solver.cpp:237] Iteration 7750, loss = 1.3733
I0523 20:10:07.902245 14326 solver.cpp:253]     Train net output #0: loss = 1.3733 (* 1 = 1.3733 loss)
I0523 20:10:07.902259 14326 sgd_solver.cpp:106] Iteration 7750, lr = 0.0045
I0523 20:10:16.975703 14326 solver.cpp:237] Iteration 8000, loss = 1.25632
I0523 20:10:16.975736 14326 solver.cpp:253]     Train net output #0: loss = 1.25632 (* 1 = 1.25632 loss)
I0523 20:10:16.975754 14326 sgd_solver.cpp:106] Iteration 8000, lr = 0.0045
I0523 20:10:26.045541 14326 solver.cpp:237] Iteration 8250, loss = 1.28691
I0523 20:10:26.045589 14326 solver.cpp:253]     Train net output #0: loss = 1.28691 (* 1 = 1.28691 loss)
I0523 20:10:26.045604 14326 sgd_solver.cpp:106] Iteration 8250, lr = 0.0045
I0523 20:10:57.408835 14326 solver.cpp:237] Iteration 8500, loss = 1.15073
I0523 20:10:57.409005 14326 solver.cpp:253]     Train net output #0: loss = 1.15073 (* 1 = 1.15073 loss)
I0523 20:10:57.409020 14326 sgd_solver.cpp:106] Iteration 8500, lr = 0.0045
I0523 20:11:06.484179 14326 solver.cpp:237] Iteration 8750, loss = 1.42121
I0523 20:11:06.484212 14326 solver.cpp:253]     Train net output #0: loss = 1.42121 (* 1 = 1.42121 loss)
I0523 20:11:06.484230 14326 sgd_solver.cpp:106] Iteration 8750, lr = 0.0045
I0523 20:11:15.560844 14326 solver.cpp:237] Iteration 9000, loss = 1.31311
I0523 20:11:15.560890 14326 solver.cpp:253]     Train net output #0: loss = 1.31311 (* 1 = 1.31311 loss)
I0523 20:11:15.560912 14326 sgd_solver.cpp:106] Iteration 9000, lr = 0.0045
I0523 20:11:24.634909 14326 solver.cpp:237] Iteration 9250, loss = 1.07531
I0523 20:11:24.634944 14326 solver.cpp:253]     Train net output #0: loss = 1.07531 (* 1 = 1.07531 loss)
I0523 20:11:24.634958 14326 sgd_solver.cpp:106] Iteration 9250, lr = 0.0045
I0523 20:11:33.710589 14326 solver.cpp:237] Iteration 9500, loss = 1.28283
I0523 20:11:33.710728 14326 solver.cpp:253]     Train net output #0: loss = 1.28283 (* 1 = 1.28283 loss)
I0523 20:11:33.710741 14326 sgd_solver.cpp:106] Iteration 9500, lr = 0.0045
I0523 20:11:42.782243 14326 solver.cpp:237] Iteration 9750, loss = 1.36278
I0523 20:11:42.782280 14326 solver.cpp:253]     Train net output #0: loss = 1.36278 (* 1 = 1.36278 loss)
I0523 20:11:42.782300 14326 sgd_solver.cpp:106] Iteration 9750, lr = 0.0045
I0523 20:11:51.817337 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_10000.caffemodel
I0523 20:11:51.882643 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_10000.solverstate
I0523 20:11:51.910466 14326 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 20:13:00.017074 14326 solver.cpp:409]     Test net output #0: accuracy = 0.845095
I0523 20:13:00.017235 14326 solver.cpp:409]     Test net output #1: loss = 0.503243 (* 1 = 0.503243 loss)
I0523 20:13:22.310350 14326 solver.cpp:237] Iteration 10000, loss = 1.23817
I0523 20:13:22.310405 14326 solver.cpp:253]     Train net output #0: loss = 1.23817 (* 1 = 1.23817 loss)
I0523 20:13:22.310420 14326 sgd_solver.cpp:106] Iteration 10000, lr = 0.0045
I0523 20:13:31.418054 14326 solver.cpp:237] Iteration 10250, loss = 1.15616
I0523 20:13:31.418210 14326 solver.cpp:253]     Train net output #0: loss = 1.15616 (* 1 = 1.15616 loss)
I0523 20:13:31.418225 14326 sgd_solver.cpp:106] Iteration 10250, lr = 0.0045
I0523 20:13:40.538359 14326 solver.cpp:237] Iteration 10500, loss = 1.26518
I0523 20:13:40.538403 14326 solver.cpp:253]     Train net output #0: loss = 1.26518 (* 1 = 1.26518 loss)
I0523 20:13:40.538419 14326 sgd_solver.cpp:106] Iteration 10500, lr = 0.0045
I0523 20:13:49.649672 14326 solver.cpp:237] Iteration 10750, loss = 1.15931
I0523 20:13:49.649708 14326 solver.cpp:253]     Train net output #0: loss = 1.15931 (* 1 = 1.15931 loss)
I0523 20:13:49.649724 14326 sgd_solver.cpp:106] Iteration 10750, lr = 0.0045
I0523 20:13:58.765637 14326 solver.cpp:237] Iteration 11000, loss = 1.08776
I0523 20:13:58.765672 14326 solver.cpp:253]     Train net output #0: loss = 1.08776 (* 1 = 1.08776 loss)
I0523 20:13:58.765689 14326 sgd_solver.cpp:106] Iteration 11000, lr = 0.0045
I0523 20:14:07.886618 14326 solver.cpp:237] Iteration 11250, loss = 1.34574
I0523 20:14:07.886775 14326 solver.cpp:253]     Train net output #0: loss = 1.34574 (* 1 = 1.34574 loss)
I0523 20:14:07.886788 14326 sgd_solver.cpp:106] Iteration 11250, lr = 0.0045
I0523 20:14:16.991664 14326 solver.cpp:237] Iteration 11500, loss = 1.20189
I0523 20:14:16.991698 14326 solver.cpp:253]     Train net output #0: loss = 1.20189 (* 1 = 1.20189 loss)
I0523 20:14:16.991716 14326 sgd_solver.cpp:106] Iteration 11500, lr = 0.0045
I0523 20:14:48.345733 14326 solver.cpp:237] Iteration 11750, loss = 1.14094
I0523 20:14:48.345895 14326 solver.cpp:253]     Train net output #0: loss = 1.14094 (* 1 = 1.14094 loss)
I0523 20:14:48.345909 14326 sgd_solver.cpp:106] Iteration 11750, lr = 0.0045
I0523 20:14:57.452072 14326 solver.cpp:237] Iteration 12000, loss = 1.47091
I0523 20:14:57.452121 14326 solver.cpp:253]     Train net output #0: loss = 1.47091 (* 1 = 1.47091 loss)
I0523 20:14:57.452136 14326 sgd_solver.cpp:106] Iteration 12000, lr = 0.0045
I0523 20:15:06.565995 14326 solver.cpp:237] Iteration 12250, loss = 1.37351
I0523 20:15:06.566031 14326 solver.cpp:253]     Train net output #0: loss = 1.37351 (* 1 = 1.37351 loss)
I0523 20:15:06.566047 14326 sgd_solver.cpp:106] Iteration 12250, lr = 0.0045
I0523 20:15:15.647586 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_12500.caffemodel
I0523 20:15:15.712626 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_12500.solverstate
I0523 20:15:15.754990 14326 solver.cpp:237] Iteration 12500, loss = 1.50642
I0523 20:15:15.755040 14326 solver.cpp:253]     Train net output #0: loss = 1.50642 (* 1 = 1.50642 loss)
I0523 20:15:15.755054 14326 sgd_solver.cpp:106] Iteration 12500, lr = 0.0045
I0523 20:15:24.872913 14326 solver.cpp:237] Iteration 12750, loss = 1.19243
I0523 20:15:24.873070 14326 solver.cpp:253]     Train net output #0: loss = 1.19243 (* 1 = 1.19243 loss)
I0523 20:15:24.873083 14326 sgd_solver.cpp:106] Iteration 12750, lr = 0.0045
I0523 20:15:33.989096 14326 solver.cpp:237] Iteration 13000, loss = 1.09935
I0523 20:15:33.989130 14326 solver.cpp:253]     Train net output #0: loss = 1.09935 (* 1 = 1.09935 loss)
I0523 20:15:33.989147 14326 sgd_solver.cpp:106] Iteration 13000, lr = 0.0045
I0523 20:15:43.099915 14326 solver.cpp:237] Iteration 13250, loss = 1.4135
I0523 20:15:43.099951 14326 solver.cpp:253]     Train net output #0: loss = 1.4135 (* 1 = 1.4135 loss)
I0523 20:15:43.099967 14326 sgd_solver.cpp:106] Iteration 13250, lr = 0.0045
I0523 20:16:14.464637 14326 solver.cpp:237] Iteration 13500, loss = 1.33823
I0523 20:16:14.464813 14326 solver.cpp:253]     Train net output #0: loss = 1.33823 (* 1 = 1.33823 loss)
I0523 20:16:14.464829 14326 sgd_solver.cpp:106] Iteration 13500, lr = 0.0045
I0523 20:16:23.584429 14326 solver.cpp:237] Iteration 13750, loss = 1.28893
I0523 20:16:23.584462 14326 solver.cpp:253]     Train net output #0: loss = 1.28893 (* 1 = 1.28893 loss)
I0523 20:16:23.584481 14326 sgd_solver.cpp:106] Iteration 13750, lr = 0.0045
I0523 20:16:32.698914 14326 solver.cpp:237] Iteration 14000, loss = 1.08692
I0523 20:16:32.698950 14326 solver.cpp:253]     Train net output #0: loss = 1.08692 (* 1 = 1.08692 loss)
I0523 20:16:32.698966 14326 sgd_solver.cpp:106] Iteration 14000, lr = 0.0045
I0523 20:16:41.813282 14326 solver.cpp:237] Iteration 14250, loss = 1.27101
I0523 20:16:41.813323 14326 solver.cpp:253]     Train net output #0: loss = 1.27101 (* 1 = 1.27101 loss)
I0523 20:16:41.813340 14326 sgd_solver.cpp:106] Iteration 14250, lr = 0.0045
I0523 20:16:50.926965 14326 solver.cpp:237] Iteration 14500, loss = 1.14232
I0523 20:16:50.927103 14326 solver.cpp:253]     Train net output #0: loss = 1.14232 (* 1 = 1.14232 loss)
I0523 20:16:50.927116 14326 sgd_solver.cpp:106] Iteration 14500, lr = 0.0045
I0523 20:17:00.041249 14326 solver.cpp:237] Iteration 14750, loss = 1.07216
I0523 20:17:00.041288 14326 solver.cpp:253]     Train net output #0: loss = 1.07216 (* 1 = 1.07216 loss)
I0523 20:17:00.041309 14326 sgd_solver.cpp:106] Iteration 14750, lr = 0.0045
I0523 20:17:09.108326 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_15000.caffemodel
I0523 20:17:09.181648 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_15000.solverstate
I0523 20:17:09.207079 14326 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 20:17:56.155967 14326 solver.cpp:409]     Test net output #0: accuracy = 0.868795
I0523 20:17:56.156126 14326 solver.cpp:409]     Test net output #1: loss = 0.418939 (* 1 = 0.418939 loss)
I0523 20:18:18.394315 14326 solver.cpp:237] Iteration 15000, loss = 0.913768
I0523 20:18:18.394367 14326 solver.cpp:253]     Train net output #0: loss = 0.913768 (* 1 = 0.913768 loss)
I0523 20:18:18.394382 14326 sgd_solver.cpp:106] Iteration 15000, lr = 0.0045
I0523 20:18:27.421095 14326 solver.cpp:237] Iteration 15250, loss = 1.2049
I0523 20:18:27.421248 14326 solver.cpp:253]     Train net output #0: loss = 1.2049 (* 1 = 1.2049 loss)
I0523 20:18:27.421262 14326 sgd_solver.cpp:106] Iteration 15250, lr = 0.0045
I0523 20:18:36.456717 14326 solver.cpp:237] Iteration 15500, loss = 1.2173
I0523 20:18:36.456750 14326 solver.cpp:253]     Train net output #0: loss = 1.2173 (* 1 = 1.2173 loss)
I0523 20:18:36.456770 14326 sgd_solver.cpp:106] Iteration 15500, lr = 0.0045
I0523 20:18:45.492347 14326 solver.cpp:237] Iteration 15750, loss = 1.17735
I0523 20:18:45.492396 14326 solver.cpp:253]     Train net output #0: loss = 1.17735 (* 1 = 1.17735 loss)
I0523 20:18:45.492410 14326 sgd_solver.cpp:106] Iteration 15750, lr = 0.0045
I0523 20:18:54.521235 14326 solver.cpp:237] Iteration 16000, loss = 1.45711
I0523 20:18:54.521271 14326 solver.cpp:253]     Train net output #0: loss = 1.45711 (* 1 = 1.45711 loss)
I0523 20:18:54.521287 14326 sgd_solver.cpp:106] Iteration 16000, lr = 0.0045
I0523 20:19:03.548867 14326 solver.cpp:237] Iteration 16250, loss = 1.24295
I0523 20:19:03.549027 14326 solver.cpp:253]     Train net output #0: loss = 1.24295 (* 1 = 1.24295 loss)
I0523 20:19:03.549041 14326 sgd_solver.cpp:106] Iteration 16250, lr = 0.0045
I0523 20:19:12.578107 14326 solver.cpp:237] Iteration 16500, loss = 1.10502
I0523 20:19:12.578146 14326 solver.cpp:253]     Train net output #0: loss = 1.10502 (* 1 = 1.10502 loss)
I0523 20:19:12.578168 14326 sgd_solver.cpp:106] Iteration 16500, lr = 0.0045
I0523 20:19:43.878577 14326 solver.cpp:237] Iteration 16750, loss = 1.20056
I0523 20:19:43.878754 14326 solver.cpp:253]     Train net output #0: loss = 1.20056 (* 1 = 1.20056 loss)
I0523 20:19:43.878768 14326 sgd_solver.cpp:106] Iteration 16750, lr = 0.0045
I0523 20:19:52.912142 14326 solver.cpp:237] Iteration 17000, loss = 1.28832
I0523 20:19:52.912176 14326 solver.cpp:253]     Train net output #0: loss = 1.28832 (* 1 = 1.28832 loss)
I0523 20:19:52.912194 14326 sgd_solver.cpp:106] Iteration 17000, lr = 0.0045
I0523 20:20:01.946480 14326 solver.cpp:237] Iteration 17250, loss = 1.12037
I0523 20:20:01.946527 14326 solver.cpp:253]     Train net output #0: loss = 1.12037 (* 1 = 1.12037 loss)
I0523 20:20:01.946542 14326 sgd_solver.cpp:106] Iteration 17250, lr = 0.0045
I0523 20:20:10.945088 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_17500.caffemodel
I0523 20:20:11.008143 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_17500.solverstate
I0523 20:20:11.045837 14326 solver.cpp:237] Iteration 17500, loss = 1.16637
I0523 20:20:11.045881 14326 solver.cpp:253]     Train net output #0: loss = 1.16637 (* 1 = 1.16637 loss)
I0523 20:20:11.045898 14326 sgd_solver.cpp:106] Iteration 17500, lr = 0.0045
I0523 20:20:20.072911 14326 solver.cpp:237] Iteration 17750, loss = 1.31621
I0523 20:20:20.073071 14326 solver.cpp:253]     Train net output #0: loss = 1.31621 (* 1 = 1.31621 loss)
I0523 20:20:20.073084 14326 sgd_solver.cpp:106] Iteration 17750, lr = 0.0045
I0523 20:20:29.105300 14326 solver.cpp:237] Iteration 18000, loss = 1.01824
I0523 20:20:29.105336 14326 solver.cpp:253]     Train net output #0: loss = 1.01824 (* 1 = 1.01824 loss)
I0523 20:20:29.105352 14326 sgd_solver.cpp:106] Iteration 18000, lr = 0.0045
I0523 20:20:38.137770 14326 solver.cpp:237] Iteration 18250, loss = 1.24931
I0523 20:20:38.137806 14326 solver.cpp:253]     Train net output #0: loss = 1.24931 (* 1 = 1.24931 loss)
I0523 20:20:38.137820 14326 sgd_solver.cpp:106] Iteration 18250, lr = 0.0045
I0523 20:21:09.397125 14326 solver.cpp:237] Iteration 18500, loss = 1.05487
I0523 20:21:09.397290 14326 solver.cpp:253]     Train net output #0: loss = 1.05487 (* 1 = 1.05487 loss)
I0523 20:21:09.397305 14326 sgd_solver.cpp:106] Iteration 18500, lr = 0.0045
I0523 20:21:18.430732 14326 solver.cpp:237] Iteration 18750, loss = 1.50984
I0523 20:21:18.430766 14326 solver.cpp:253]     Train net output #0: loss = 1.50984 (* 1 = 1.50984 loss)
I0523 20:21:18.430779 14326 sgd_solver.cpp:106] Iteration 18750, lr = 0.0045
I0523 20:21:27.463887 14326 solver.cpp:237] Iteration 19000, loss = 1.16885
I0523 20:21:27.463922 14326 solver.cpp:253]     Train net output #0: loss = 1.16885 (* 1 = 1.16885 loss)
I0523 20:21:27.463940 14326 sgd_solver.cpp:106] Iteration 19000, lr = 0.0045
I0523 20:21:36.494666 14326 solver.cpp:237] Iteration 19250, loss = 1.09795
I0523 20:21:36.494710 14326 solver.cpp:253]     Train net output #0: loss = 1.09795 (* 1 = 1.09795 loss)
I0523 20:21:36.494727 14326 sgd_solver.cpp:106] Iteration 19250, lr = 0.0045
I0523 20:21:45.533262 14326 solver.cpp:237] Iteration 19500, loss = 1.10076
I0523 20:21:45.533421 14326 solver.cpp:253]     Train net output #0: loss = 1.10076 (* 1 = 1.10076 loss)
I0523 20:21:45.533434 14326 sgd_solver.cpp:106] Iteration 19500, lr = 0.0045
I0523 20:21:54.564828 14326 solver.cpp:237] Iteration 19750, loss = 1.18171
I0523 20:21:54.564870 14326 solver.cpp:253]     Train net output #0: loss = 1.18171 (* 1 = 1.18171 loss)
I0523 20:21:54.564884 14326 sgd_solver.cpp:106] Iteration 19750, lr = 0.0045
I0523 20:22:03.561956 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_20000.caffemodel
I0523 20:22:03.624645 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_20000.solverstate
I0523 20:22:03.651062 14326 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 20:23:11.701822 14326 solver.cpp:409]     Test net output #0: accuracy = 0.867914
I0523 20:23:11.701998 14326 solver.cpp:409]     Test net output #1: loss = 0.416617 (* 1 = 0.416617 loss)
I0523 20:23:33.941251 14326 solver.cpp:237] Iteration 20000, loss = 1.15011
I0523 20:23:33.941303 14326 solver.cpp:253]     Train net output #0: loss = 1.15011 (* 1 = 1.15011 loss)
I0523 20:23:33.941318 14326 sgd_solver.cpp:106] Iteration 20000, lr = 0.0045
I0523 20:23:42.996767 14326 solver.cpp:237] Iteration 20250, loss = 1.0542
I0523 20:23:42.996938 14326 solver.cpp:253]     Train net output #0: loss = 1.0542 (* 1 = 1.0542 loss)
I0523 20:23:42.996953 14326 sgd_solver.cpp:106] Iteration 20250, lr = 0.0045
I0523 20:23:52.046741 14326 solver.cpp:237] Iteration 20500, loss = 1.16475
I0523 20:23:52.046772 14326 solver.cpp:253]     Train net output #0: loss = 1.16475 (* 1 = 1.16475 loss)
I0523 20:23:52.046784 14326 sgd_solver.cpp:106] Iteration 20500, lr = 0.0045
I0523 20:24:01.105762 14326 solver.cpp:237] Iteration 20750, loss = 1.31905
I0523 20:24:01.105798 14326 solver.cpp:253]     Train net output #0: loss = 1.31905 (* 1 = 1.31905 loss)
I0523 20:24:01.105813 14326 sgd_solver.cpp:106] Iteration 20750, lr = 0.0045
I0523 20:24:10.155948 14326 solver.cpp:237] Iteration 21000, loss = 1.18722
I0523 20:24:10.155993 14326 solver.cpp:253]     Train net output #0: loss = 1.18722 (* 1 = 1.18722 loss)
I0523 20:24:10.156008 14326 sgd_solver.cpp:106] Iteration 21000, lr = 0.0045
I0523 20:24:19.213361 14326 solver.cpp:237] Iteration 21250, loss = 1.23002
I0523 20:24:19.213505 14326 solver.cpp:253]     Train net output #0: loss = 1.23002 (* 1 = 1.23002 loss)
I0523 20:24:19.213520 14326 sgd_solver.cpp:106] Iteration 21250, lr = 0.0045
I0523 20:24:28.277192 14326 solver.cpp:237] Iteration 21500, loss = 0.918488
I0523 20:24:28.277226 14326 solver.cpp:253]     Train net output #0: loss = 0.918488 (* 1 = 0.918488 loss)
I0523 20:24:28.277245 14326 sgd_solver.cpp:106] Iteration 21500, lr = 0.0045
I0523 20:24:59.494586 14326 solver.cpp:237] Iteration 21750, loss = 1.27842
I0523 20:24:59.494753 14326 solver.cpp:253]     Train net output #0: loss = 1.27842 (* 1 = 1.27842 loss)
I0523 20:24:59.494767 14326 sgd_solver.cpp:106] Iteration 21750, lr = 0.0045
I0523 20:25:08.560291 14326 solver.cpp:237] Iteration 22000, loss = 1.26015
I0523 20:25:08.560324 14326 solver.cpp:253]     Train net output #0: loss = 1.26015 (* 1 = 1.26015 loss)
I0523 20:25:08.560339 14326 sgd_solver.cpp:106] Iteration 22000, lr = 0.0045
I0523 20:25:17.611824 14326 solver.cpp:237] Iteration 22250, loss = 1.33244
I0523 20:25:17.611858 14326 solver.cpp:253]     Train net output #0: loss = 1.33244 (* 1 = 1.33244 loss)
I0523 20:25:17.611876 14326 sgd_solver.cpp:106] Iteration 22250, lr = 0.0045
I0523 20:25:26.614490 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_22500.caffemodel
I0523 20:25:26.678719 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_22500.solverstate
I0523 20:25:26.718109 14326 solver.cpp:237] Iteration 22500, loss = 1.60272
I0523 20:25:26.718159 14326 solver.cpp:253]     Train net output #0: loss = 1.60272 (* 1 = 1.60272 loss)
I0523 20:25:26.718174 14326 sgd_solver.cpp:106] Iteration 22500, lr = 0.0045
I0523 20:25:35.787637 14326 solver.cpp:237] Iteration 22750, loss = 1.23512
I0523 20:25:35.787796 14326 solver.cpp:253]     Train net output #0: loss = 1.23512 (* 1 = 1.23512 loss)
I0523 20:25:35.787811 14326 sgd_solver.cpp:106] Iteration 22750, lr = 0.0045
I0523 20:25:44.840010 14326 solver.cpp:237] Iteration 23000, loss = 1.81166
I0523 20:25:44.840059 14326 solver.cpp:253]     Train net output #0: loss = 1.81166 (* 1 = 1.81166 loss)
I0523 20:25:44.840076 14326 sgd_solver.cpp:106] Iteration 23000, lr = 0.0045
I0523 20:25:53.890110 14326 solver.cpp:237] Iteration 23250, loss = 1.3055
I0523 20:25:53.890144 14326 solver.cpp:253]     Train net output #0: loss = 1.3055 (* 1 = 1.3055 loss)
I0523 20:25:53.890161 14326 sgd_solver.cpp:106] Iteration 23250, lr = 0.0045
I0523 20:26:25.254300 14326 solver.cpp:237] Iteration 23500, loss = 1.02781
I0523 20:26:25.254492 14326 solver.cpp:253]     Train net output #0: loss = 1.02781 (* 1 = 1.02781 loss)
I0523 20:26:25.254508 14326 sgd_solver.cpp:106] Iteration 23500, lr = 0.0045
I0523 20:26:34.312399 14326 solver.cpp:237] Iteration 23750, loss = 1.10884
I0523 20:26:34.312433 14326 solver.cpp:253]     Train net output #0: loss = 1.10884 (* 1 = 1.10884 loss)
I0523 20:26:34.312451 14326 sgd_solver.cpp:106] Iteration 23750, lr = 0.0045
I0523 20:26:43.371712 14326 solver.cpp:237] Iteration 24000, loss = 1.10041
I0523 20:26:43.371748 14326 solver.cpp:253]     Train net output #0: loss = 1.10041 (* 1 = 1.10041 loss)
I0523 20:26:43.371763 14326 sgd_solver.cpp:106] Iteration 24000, lr = 0.0045
I0523 20:26:52.420229 14326 solver.cpp:237] Iteration 24250, loss = 1.20411
I0523 20:26:52.420265 14326 solver.cpp:253]     Train net output #0: loss = 1.20411 (* 1 = 1.20411 loss)
I0523 20:26:52.420281 14326 sgd_solver.cpp:106] Iteration 24250, lr = 0.0045
I0523 20:27:01.473565 14326 solver.cpp:237] Iteration 24500, loss = 1.12261
I0523 20:27:01.473742 14326 solver.cpp:253]     Train net output #0: loss = 1.12261 (* 1 = 1.12261 loss)
I0523 20:27:01.473757 14326 sgd_solver.cpp:106] Iteration 24500, lr = 0.0045
I0523 20:27:10.521893 14326 solver.cpp:237] Iteration 24750, loss = 1.31429
I0523 20:27:10.521927 14326 solver.cpp:253]     Train net output #0: loss = 1.31429 (* 1 = 1.31429 loss)
I0523 20:27:10.521941 14326 sgd_solver.cpp:106] Iteration 24750, lr = 0.0045
I0523 20:27:19.534672 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_25000.caffemodel
I0523 20:27:19.600175 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_25000.solverstate
I0523 20:27:19.628626 14326 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 20:28:06.904379 14326 solver.cpp:409]     Test net output #0: accuracy = 0.880292
I0523 20:28:06.904541 14326 solver.cpp:409]     Test net output #1: loss = 0.38772 (* 1 = 0.38772 loss)
I0523 20:28:27.788849 14326 solver.cpp:237] Iteration 25000, loss = 1.09028
I0523 20:28:27.788907 14326 solver.cpp:253]     Train net output #0: loss = 1.09028 (* 1 = 1.09028 loss)
I0523 20:28:27.788921 14326 sgd_solver.cpp:106] Iteration 25000, lr = 0.0045
I0523 20:28:36.807651 14326 solver.cpp:237] Iteration 25250, loss = 1.0616
I0523 20:28:36.807685 14326 solver.cpp:253]     Train net output #0: loss = 1.0616 (* 1 = 1.0616 loss)
I0523 20:28:36.807703 14326 sgd_solver.cpp:106] Iteration 25250, lr = 0.0045
I0523 20:28:45.825299 14326 solver.cpp:237] Iteration 25500, loss = 1.17722
I0523 20:28:45.825469 14326 solver.cpp:253]     Train net output #0: loss = 1.17722 (* 1 = 1.17722 loss)
I0523 20:28:45.825482 14326 sgd_solver.cpp:106] Iteration 25500, lr = 0.0045
I0523 20:28:54.845405 14326 solver.cpp:237] Iteration 25750, loss = 1.37922
I0523 20:28:54.845438 14326 solver.cpp:253]     Train net output #0: loss = 1.37922 (* 1 = 1.37922 loss)
I0523 20:28:54.845456 14326 sgd_solver.cpp:106] Iteration 25750, lr = 0.0045
I0523 20:29:03.857429 14326 solver.cpp:237] Iteration 26000, loss = 1.13176
I0523 20:29:03.857463 14326 solver.cpp:253]     Train net output #0: loss = 1.13176 (* 1 = 1.13176 loss)
I0523 20:29:03.857476 14326 sgd_solver.cpp:106] Iteration 26000, lr = 0.0045
I0523 20:29:12.875308 14326 solver.cpp:237] Iteration 26250, loss = 1.12724
I0523 20:29:12.875345 14326 solver.cpp:253]     Train net output #0: loss = 1.12724 (* 1 = 1.12724 loss)
I0523 20:29:12.875366 14326 sgd_solver.cpp:106] Iteration 26250, lr = 0.0045
I0523 20:29:21.882936 14326 solver.cpp:237] Iteration 26500, loss = 1.2697
I0523 20:29:21.883093 14326 solver.cpp:253]     Train net output #0: loss = 1.2697 (* 1 = 1.2697 loss)
I0523 20:29:21.883106 14326 sgd_solver.cpp:106] Iteration 26500, lr = 0.0045
I0523 20:29:51.788782 14326 solver.cpp:237] Iteration 26750, loss = 1.28913
I0523 20:29:51.788830 14326 solver.cpp:253]     Train net output #0: loss = 1.28913 (* 1 = 1.28913 loss)
I0523 20:29:51.788851 14326 sgd_solver.cpp:106] Iteration 26750, lr = 0.0045
I0523 20:30:00.808919 14326 solver.cpp:237] Iteration 27000, loss = 0.938919
I0523 20:30:00.809084 14326 solver.cpp:253]     Train net output #0: loss = 0.938919 (* 1 = 0.938919 loss)
I0523 20:30:00.809098 14326 sgd_solver.cpp:106] Iteration 27000, lr = 0.0045
I0523 20:30:09.826439 14326 solver.cpp:237] Iteration 27250, loss = 1.62677
I0523 20:30:09.826474 14326 solver.cpp:253]     Train net output #0: loss = 1.62677 (* 1 = 1.62677 loss)
I0523 20:30:09.826491 14326 sgd_solver.cpp:106] Iteration 27250, lr = 0.0045
I0523 20:30:18.810037 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_27500.caffemodel
I0523 20:30:18.871963 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_27500.solverstate
I0523 20:30:18.909384 14326 solver.cpp:237] Iteration 27500, loss = 1.12449
I0523 20:30:18.909423 14326 solver.cpp:253]     Train net output #0: loss = 1.12449 (* 1 = 1.12449 loss)
I0523 20:30:18.909442 14326 sgd_solver.cpp:106] Iteration 27500, lr = 0.0045
I0523 20:30:27.926069 14326 solver.cpp:237] Iteration 27750, loss = 1.33696
I0523 20:30:27.926107 14326 solver.cpp:253]     Train net output #0: loss = 1.33696 (* 1 = 1.33696 loss)
I0523 20:30:27.926128 14326 sgd_solver.cpp:106] Iteration 27750, lr = 0.0045
I0523 20:30:36.936261 14326 solver.cpp:237] Iteration 28000, loss = 1.33884
I0523 20:30:36.936404 14326 solver.cpp:253]     Train net output #0: loss = 1.33884 (* 1 = 1.33884 loss)
I0523 20:30:36.936419 14326 sgd_solver.cpp:106] Iteration 28000, lr = 0.0045
I0523 20:30:45.949604 14326 solver.cpp:237] Iteration 28250, loss = 1.05904
I0523 20:30:45.949643 14326 solver.cpp:253]     Train net output #0: loss = 1.05904 (* 1 = 1.05904 loss)
I0523 20:30:45.949664 14326 sgd_solver.cpp:106] Iteration 28250, lr = 0.0045
I0523 20:31:15.849979 14326 solver.cpp:237] Iteration 28500, loss = 1.11794
I0523 20:31:15.850160 14326 solver.cpp:253]     Train net output #0: loss = 1.11794 (* 1 = 1.11794 loss)
I0523 20:31:15.850174 14326 sgd_solver.cpp:106] Iteration 28500, lr = 0.0045
I0523 20:31:24.859891 14326 solver.cpp:237] Iteration 28750, loss = 1.15602
I0523 20:31:24.859925 14326 solver.cpp:253]     Train net output #0: loss = 1.15602 (* 1 = 1.15602 loss)
I0523 20:31:24.859942 14326 sgd_solver.cpp:106] Iteration 28750, lr = 0.0045
I0523 20:31:33.871573 14326 solver.cpp:237] Iteration 29000, loss = 1.21386
I0523 20:31:33.871609 14326 solver.cpp:253]     Train net output #0: loss = 1.21386 (* 1 = 1.21386 loss)
I0523 20:31:33.871625 14326 sgd_solver.cpp:106] Iteration 29000, lr = 0.0045
I0523 20:31:42.884344 14326 solver.cpp:237] Iteration 29250, loss = 1.05836
I0523 20:31:42.884392 14326 solver.cpp:253]     Train net output #0: loss = 1.05836 (* 1 = 1.05836 loss)
I0523 20:31:42.884407 14326 sgd_solver.cpp:106] Iteration 29250, lr = 0.0045
I0523 20:31:51.896472 14326 solver.cpp:237] Iteration 29500, loss = 1.12787
I0523 20:31:51.896618 14326 solver.cpp:253]     Train net output #0: loss = 1.12787 (* 1 = 1.12787 loss)
I0523 20:31:51.896632 14326 sgd_solver.cpp:106] Iteration 29500, lr = 0.0045
I0523 20:32:00.905401 14326 solver.cpp:237] Iteration 29750, loss = 1.51497
I0523 20:32:00.905443 14326 solver.cpp:253]     Train net output #0: loss = 1.51497 (* 1 = 1.51497 loss)
I0523 20:32:00.905463 14326 sgd_solver.cpp:106] Iteration 29750, lr = 0.0045
I0523 20:32:09.884143 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_30000.caffemodel
I0523 20:32:09.946908 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_30000.solverstate
I0523 20:32:09.973062 14326 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 20:33:17.998324 14326 solver.cpp:409]     Test net output #0: accuracy = 0.884573
I0523 20:33:17.998498 14326 solver.cpp:409]     Test net output #1: loss = 0.357777 (* 1 = 0.357777 loss)
I0523 20:33:38.904336 14326 solver.cpp:237] Iteration 30000, loss = 1.23931
I0523 20:33:38.904391 14326 solver.cpp:253]     Train net output #0: loss = 1.23931 (* 1 = 1.23931 loss)
I0523 20:33:38.904404 14326 sgd_solver.cpp:106] Iteration 30000, lr = 0.0045
I0523 20:33:47.995280 14326 solver.cpp:237] Iteration 30250, loss = 1.05761
I0523 20:33:47.995323 14326 solver.cpp:253]     Train net output #0: loss = 1.05761 (* 1 = 1.05761 loss)
I0523 20:33:47.995337 14326 sgd_solver.cpp:106] Iteration 30250, lr = 0.0045
I0523 20:33:57.097348 14326 solver.cpp:237] Iteration 30500, loss = 1.17144
I0523 20:33:57.097504 14326 solver.cpp:253]     Train net output #0: loss = 1.17144 (* 1 = 1.17144 loss)
I0523 20:33:57.097518 14326 sgd_solver.cpp:106] Iteration 30500, lr = 0.0045
I0523 20:34:06.200515 14326 solver.cpp:237] Iteration 30750, loss = 1.37198
I0523 20:34:06.200557 14326 solver.cpp:253]     Train net output #0: loss = 1.37198 (* 1 = 1.37198 loss)
I0523 20:34:06.200574 14326 sgd_solver.cpp:106] Iteration 30750, lr = 0.0045
I0523 20:34:15.292474 14326 solver.cpp:237] Iteration 31000, loss = 1.25025
I0523 20:34:15.292510 14326 solver.cpp:253]     Train net output #0: loss = 1.25025 (* 1 = 1.25025 loss)
I0523 20:34:15.292526 14326 sgd_solver.cpp:106] Iteration 31000, lr = 0.0045
I0523 20:34:24.386847 14326 solver.cpp:237] Iteration 31250, loss = 1.31118
I0523 20:34:24.386883 14326 solver.cpp:253]     Train net output #0: loss = 1.31118 (* 1 = 1.31118 loss)
I0523 20:34:24.386898 14326 sgd_solver.cpp:106] Iteration 31250, lr = 0.0045
I0523 20:34:33.481194 14326 solver.cpp:237] Iteration 31500, loss = 1.19245
I0523 20:34:33.481343 14326 solver.cpp:253]     Train net output #0: loss = 1.19245 (* 1 = 1.19245 loss)
I0523 20:34:33.481359 14326 sgd_solver.cpp:106] Iteration 31500, lr = 0.0045
I0523 20:35:03.485335 14326 solver.cpp:237] Iteration 31750, loss = 1.14146
I0523 20:35:03.485504 14326 solver.cpp:253]     Train net output #0: loss = 1.14146 (* 1 = 1.14146 loss)
I0523 20:35:03.485518 14326 sgd_solver.cpp:106] Iteration 31750, lr = 0.0045
I0523 20:35:12.592751 14326 solver.cpp:237] Iteration 32000, loss = 0.950685
I0523 20:35:12.592787 14326 solver.cpp:253]     Train net output #0: loss = 0.950685 (* 1 = 0.950685 loss)
I0523 20:35:12.592802 14326 sgd_solver.cpp:106] Iteration 32000, lr = 0.0045
I0523 20:35:21.688732 14326 solver.cpp:237] Iteration 32250, loss = 1.10729
I0523 20:35:21.688777 14326 solver.cpp:253]     Train net output #0: loss = 1.10729 (* 1 = 1.10729 loss)
I0523 20:35:21.688797 14326 sgd_solver.cpp:106] Iteration 32250, lr = 0.0045
I0523 20:35:30.755982 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_32500.caffemodel
I0523 20:35:30.819098 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_32500.solverstate
I0523 20:35:30.856379 14326 solver.cpp:237] Iteration 32500, loss = 1.28324
I0523 20:35:30.856423 14326 solver.cpp:253]     Train net output #0: loss = 1.28324 (* 1 = 1.28324 loss)
I0523 20:35:30.856438 14326 sgd_solver.cpp:106] Iteration 32500, lr = 0.0045
I0523 20:35:39.952929 14326 solver.cpp:237] Iteration 32750, loss = 1.15892
I0523 20:35:39.953088 14326 solver.cpp:253]     Train net output #0: loss = 1.15892 (* 1 = 1.15892 loss)
I0523 20:35:39.953101 14326 sgd_solver.cpp:106] Iteration 32750, lr = 0.0045
I0523 20:35:49.047927 14326 solver.cpp:237] Iteration 33000, loss = 1.16189
I0523 20:35:49.047967 14326 solver.cpp:253]     Train net output #0: loss = 1.16189 (* 1 = 1.16189 loss)
I0523 20:35:49.047988 14326 sgd_solver.cpp:106] Iteration 33000, lr = 0.0045
I0523 20:35:58.147233 14326 solver.cpp:237] Iteration 33250, loss = 1.06359
I0523 20:35:58.147269 14326 solver.cpp:253]     Train net output #0: loss = 1.06359 (* 1 = 1.06359 loss)
I0523 20:35:58.147282 14326 sgd_solver.cpp:106] Iteration 33250, lr = 0.0045
I0523 20:36:28.118974 14326 solver.cpp:237] Iteration 33500, loss = 1.32948
I0523 20:36:28.119150 14326 solver.cpp:253]     Train net output #0: loss = 1.32948 (* 1 = 1.32948 loss)
I0523 20:36:28.119164 14326 sgd_solver.cpp:106] Iteration 33500, lr = 0.0045
I0523 20:36:37.218972 14326 solver.cpp:237] Iteration 33750, loss = 1.02229
I0523 20:36:37.219017 14326 solver.cpp:253]     Train net output #0: loss = 1.02229 (* 1 = 1.02229 loss)
I0523 20:36:37.219033 14326 sgd_solver.cpp:106] Iteration 33750, lr = 0.0045
I0523 20:36:46.309751 14326 solver.cpp:237] Iteration 34000, loss = 1.10314
I0523 20:36:46.309787 14326 solver.cpp:253]     Train net output #0: loss = 1.10314 (* 1 = 1.10314 loss)
I0523 20:36:46.309803 14326 sgd_solver.cpp:106] Iteration 34000, lr = 0.0045
I0523 20:36:55.405035 14326 solver.cpp:237] Iteration 34250, loss = 1.14367
I0523 20:36:55.405069 14326 solver.cpp:253]     Train net output #0: loss = 1.14367 (* 1 = 1.14367 loss)
I0523 20:36:55.405086 14326 sgd_solver.cpp:106] Iteration 34250, lr = 0.0045
I0523 20:37:04.508505 14326 solver.cpp:237] Iteration 34500, loss = 1.17704
I0523 20:37:04.508663 14326 solver.cpp:253]     Train net output #0: loss = 1.17704 (* 1 = 1.17704 loss)
I0523 20:37:04.508677 14326 sgd_solver.cpp:106] Iteration 34500, lr = 0.0045
I0523 20:37:13.595741 14326 solver.cpp:237] Iteration 34750, loss = 0.853306
I0523 20:37:13.595777 14326 solver.cpp:253]     Train net output #0: loss = 0.853306 (* 1 = 0.853306 loss)
I0523 20:37:13.595790 14326 sgd_solver.cpp:106] Iteration 34750, lr = 0.0045
I0523 20:37:22.669441 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_35000.caffemodel
I0523 20:37:22.743659 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_35000.solverstate
I0523 20:37:22.770036 14326 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 20:38:09.739821 14326 solver.cpp:409]     Test net output #0: accuracy = 0.886574
I0523 20:38:09.739989 14326 solver.cpp:409]     Test net output #1: loss = 0.384472 (* 1 = 0.384472 loss)
I0523 20:38:30.641214 14326 solver.cpp:237] Iteration 35000, loss = 0.969401
I0523 20:38:30.641268 14326 solver.cpp:253]     Train net output #0: loss = 0.969401 (* 1 = 0.969401 loss)
I0523 20:38:30.641284 14326 sgd_solver.cpp:106] Iteration 35000, lr = 0.0045
I0523 20:38:39.712040 14326 solver.cpp:237] Iteration 35250, loss = 1.16539
I0523 20:38:39.712090 14326 solver.cpp:253]     Train net output #0: loss = 1.16539 (* 1 = 1.16539 loss)
I0523 20:38:39.712105 14326 sgd_solver.cpp:106] Iteration 35250, lr = 0.0045
I0523 20:38:48.780549 14326 solver.cpp:237] Iteration 35500, loss = 1.566
I0523 20:38:48.780701 14326 solver.cpp:253]     Train net output #0: loss = 1.566 (* 1 = 1.566 loss)
I0523 20:38:48.780715 14326 sgd_solver.cpp:106] Iteration 35500, lr = 0.0045
I0523 20:38:57.846047 14326 solver.cpp:237] Iteration 35750, loss = 1.26465
I0523 20:38:57.846082 14326 solver.cpp:253]     Train net output #0: loss = 1.26465 (* 1 = 1.26465 loss)
I0523 20:38:57.846099 14326 sgd_solver.cpp:106] Iteration 35750, lr = 0.0045
I0523 20:39:06.914763 14326 solver.cpp:237] Iteration 36000, loss = 1.01116
I0523 20:39:06.914813 14326 solver.cpp:253]     Train net output #0: loss = 1.01116 (* 1 = 1.01116 loss)
I0523 20:39:06.914827 14326 sgd_solver.cpp:106] Iteration 36000, lr = 0.0045
I0523 20:39:15.984952 14326 solver.cpp:237] Iteration 36250, loss = 1.10269
I0523 20:39:15.984987 14326 solver.cpp:253]     Train net output #0: loss = 1.10269 (* 1 = 1.10269 loss)
I0523 20:39:15.985002 14326 sgd_solver.cpp:106] Iteration 36250, lr = 0.0045
I0523 20:39:25.053392 14326 solver.cpp:237] Iteration 36500, loss = 1.03731
I0523 20:39:25.053565 14326 solver.cpp:253]     Train net output #0: loss = 1.03731 (* 1 = 1.03731 loss)
I0523 20:39:25.053578 14326 sgd_solver.cpp:106] Iteration 36500, lr = 0.0045
I0523 20:39:55.035033 14326 solver.cpp:237] Iteration 36750, loss = 1.04506
I0523 20:39:55.035081 14326 solver.cpp:253]     Train net output #0: loss = 1.04506 (* 1 = 1.04506 loss)
I0523 20:39:55.035095 14326 sgd_solver.cpp:106] Iteration 36750, lr = 0.0045
I0523 20:40:04.113435 14326 solver.cpp:237] Iteration 37000, loss = 1.30021
I0523 20:40:04.113590 14326 solver.cpp:253]     Train net output #0: loss = 1.30021 (* 1 = 1.30021 loss)
I0523 20:40:04.113605 14326 sgd_solver.cpp:106] Iteration 37000, lr = 0.0045
I0523 20:40:13.189023 14326 solver.cpp:237] Iteration 37250, loss = 1.13629
I0523 20:40:13.189057 14326 solver.cpp:253]     Train net output #0: loss = 1.13629 (* 1 = 1.13629 loss)
I0523 20:40:13.189074 14326 sgd_solver.cpp:106] Iteration 37250, lr = 0.0045
I0523 20:40:22.225196 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_37500.caffemodel
I0523 20:40:22.290539 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_37500.solverstate
I0523 20:40:22.330149 14326 solver.cpp:237] Iteration 37500, loss = 1.20747
I0523 20:40:22.330200 14326 solver.cpp:253]     Train net output #0: loss = 1.20747 (* 1 = 1.20747 loss)
I0523 20:40:22.330215 14326 sgd_solver.cpp:106] Iteration 37500, lr = 0.0045
I0523 20:40:31.398799 14326 solver.cpp:237] Iteration 37750, loss = 1.07706
I0523 20:40:31.398833 14326 solver.cpp:253]     Train net output #0: loss = 1.07706 (* 1 = 1.07706 loss)
I0523 20:40:31.398850 14326 sgd_solver.cpp:106] Iteration 37750, lr = 0.0045
I0523 20:40:40.470415 14326 solver.cpp:237] Iteration 38000, loss = 0.972763
I0523 20:40:40.470573 14326 solver.cpp:253]     Train net output #0: loss = 0.972763 (* 1 = 0.972763 loss)
I0523 20:40:40.470588 14326 sgd_solver.cpp:106] Iteration 38000, lr = 0.0045
I0523 20:40:49.537772 14326 solver.cpp:237] Iteration 38250, loss = 1.19923
I0523 20:40:49.537820 14326 solver.cpp:253]     Train net output #0: loss = 1.19923 (* 1 = 1.19923 loss)
I0523 20:40:49.537834 14326 sgd_solver.cpp:106] Iteration 38250, lr = 0.0045
I0523 20:41:19.519439 14326 solver.cpp:237] Iteration 38500, loss = 1.05392
I0523 20:41:19.519616 14326 solver.cpp:253]     Train net output #0: loss = 1.05392 (* 1 = 1.05392 loss)
I0523 20:41:19.519630 14326 sgd_solver.cpp:106] Iteration 38500, lr = 0.0045
I0523 20:41:28.597743 14326 solver.cpp:237] Iteration 38750, loss = 1.23847
I0523 20:41:28.597777 14326 solver.cpp:253]     Train net output #0: loss = 1.23847 (* 1 = 1.23847 loss)
I0523 20:41:28.597795 14326 sgd_solver.cpp:106] Iteration 38750, lr = 0.0045
I0523 20:41:37.666918 14326 solver.cpp:237] Iteration 39000, loss = 1.00382
I0523 20:41:37.666955 14326 solver.cpp:253]     Train net output #0: loss = 1.00382 (* 1 = 1.00382 loss)
I0523 20:41:37.666975 14326 sgd_solver.cpp:106] Iteration 39000, lr = 0.0045
I0523 20:41:46.736335 14326 solver.cpp:237] Iteration 39250, loss = 1.13858
I0523 20:41:46.736369 14326 solver.cpp:253]     Train net output #0: loss = 1.13858 (* 1 = 1.13858 loss)
I0523 20:41:46.736385 14326 sgd_solver.cpp:106] Iteration 39250, lr = 0.0045
I0523 20:41:55.811969 14326 solver.cpp:237] Iteration 39500, loss = 0.907229
I0523 20:41:55.812132 14326 solver.cpp:253]     Train net output #0: loss = 0.907229 (* 1 = 0.907229 loss)
I0523 20:41:55.812146 14326 sgd_solver.cpp:106] Iteration 39500, lr = 0.0045
I0523 20:42:04.886273 14326 solver.cpp:237] Iteration 39750, loss = 1.14752
I0523 20:42:04.886318 14326 solver.cpp:253]     Train net output #0: loss = 1.14752 (* 1 = 1.14752 loss)
I0523 20:42:04.886337 14326 sgd_solver.cpp:106] Iteration 39750, lr = 0.0045
I0523 20:42:13.925498 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_40000.caffemodel
I0523 20:42:13.987967 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_40000.solverstate
I0523 20:42:14.014266 14326 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 20:43:22.124028 14326 solver.cpp:409]     Test net output #0: accuracy = 0.886612
I0523 20:43:22.124202 14326 solver.cpp:409]     Test net output #1: loss = 0.352691 (* 1 = 0.352691 loss)
I0523 20:43:43.042158 14326 solver.cpp:237] Iteration 40000, loss = 1.06415
I0523 20:43:43.042212 14326 solver.cpp:253]     Train net output #0: loss = 1.06415 (* 1 = 1.06415 loss)
I0523 20:43:43.042225 14326 sgd_solver.cpp:106] Iteration 40000, lr = 0.0045
I0523 20:43:52.154108 14326 solver.cpp:237] Iteration 40250, loss = 1.06017
I0523 20:43:52.154266 14326 solver.cpp:253]     Train net output #0: loss = 1.06017 (* 1 = 1.06017 loss)
I0523 20:43:52.154279 14326 sgd_solver.cpp:106] Iteration 40250, lr = 0.0045
I0523 20:44:01.269655 14326 solver.cpp:237] Iteration 40500, loss = 1.14861
I0523 20:44:01.269690 14326 solver.cpp:253]     Train net output #0: loss = 1.14861 (* 1 = 1.14861 loss)
I0523 20:44:01.269703 14326 sgd_solver.cpp:106] Iteration 40500, lr = 0.0045
I0523 20:44:10.377296 14326 solver.cpp:237] Iteration 40750, loss = 1.15179
I0523 20:44:10.377338 14326 solver.cpp:253]     Train net output #0: loss = 1.15179 (* 1 = 1.15179 loss)
I0523 20:44:10.377356 14326 sgd_solver.cpp:106] Iteration 40750, lr = 0.0045
I0523 20:44:19.499929 14326 solver.cpp:237] Iteration 41000, loss = 1.23639
I0523 20:44:19.499964 14326 solver.cpp:253]     Train net output #0: loss = 1.23639 (* 1 = 1.23639 loss)
I0523 20:44:19.499981 14326 sgd_solver.cpp:106] Iteration 41000, lr = 0.0045
I0523 20:44:28.616155 14326 solver.cpp:237] Iteration 41250, loss = 1.12916
I0523 20:44:28.616307 14326 solver.cpp:253]     Train net output #0: loss = 1.12916 (* 1 = 1.12916 loss)
I0523 20:44:28.616320 14326 sgd_solver.cpp:106] Iteration 41250, lr = 0.0045
I0523 20:44:37.728757 14326 solver.cpp:237] Iteration 41500, loss = 0.748414
I0523 20:44:37.728792 14326 solver.cpp:253]     Train net output #0: loss = 0.748414 (* 1 = 0.748414 loss)
I0523 20:44:37.728813 14326 sgd_solver.cpp:106] Iteration 41500, lr = 0.0045
I0523 20:45:07.735369 14326 solver.cpp:237] Iteration 41750, loss = 1.18834
I0523 20:45:07.735540 14326 solver.cpp:253]     Train net output #0: loss = 1.18834 (* 1 = 1.18834 loss)
I0523 20:45:07.735554 14326 sgd_solver.cpp:106] Iteration 41750, lr = 0.0045
I0523 20:45:16.852473 14326 solver.cpp:237] Iteration 42000, loss = 1.08326
I0523 20:45:16.852507 14326 solver.cpp:253]     Train net output #0: loss = 1.08326 (* 1 = 1.08326 loss)
I0523 20:45:16.852521 14326 sgd_solver.cpp:106] Iteration 42000, lr = 0.0045
I0523 20:45:25.969614 14326 solver.cpp:237] Iteration 42250, loss = 1.22232
I0523 20:45:25.969653 14326 solver.cpp:253]     Train net output #0: loss = 1.22232 (* 1 = 1.22232 loss)
I0523 20:45:25.969672 14326 sgd_solver.cpp:106] Iteration 42250, lr = 0.0045
I0523 20:45:35.055642 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_42500.caffemodel
I0523 20:45:35.118870 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_42500.solverstate
I0523 20:45:35.156626 14326 solver.cpp:237] Iteration 42500, loss = 0.900609
I0523 20:45:35.156667 14326 solver.cpp:253]     Train net output #0: loss = 0.900609 (* 1 = 0.900609 loss)
I0523 20:45:35.156685 14326 sgd_solver.cpp:106] Iteration 42500, lr = 0.0045
I0523 20:45:44.265537 14326 solver.cpp:237] Iteration 42750, loss = 1.01992
I0523 20:45:44.265703 14326 solver.cpp:253]     Train net output #0: loss = 1.01992 (* 1 = 1.01992 loss)
I0523 20:45:44.265717 14326 sgd_solver.cpp:106] Iteration 42750, lr = 0.0045
I0523 20:45:53.384990 14326 solver.cpp:237] Iteration 43000, loss = 1.04202
I0523 20:45:53.385021 14326 solver.cpp:253]     Train net output #0: loss = 1.04202 (* 1 = 1.04202 loss)
I0523 20:45:53.385040 14326 sgd_solver.cpp:106] Iteration 43000, lr = 0.0045
I0523 20:46:02.499434 14326 solver.cpp:237] Iteration 43250, loss = 1.13818
I0523 20:46:02.499469 14326 solver.cpp:253]     Train net output #0: loss = 1.13818 (* 1 = 1.13818 loss)
I0523 20:46:02.499483 14326 sgd_solver.cpp:106] Iteration 43250, lr = 0.0045
I0523 20:46:32.504725 14326 solver.cpp:237] Iteration 43500, loss = 1.03109
I0523 20:46:32.504920 14326 solver.cpp:253]     Train net output #0: loss = 1.03109 (* 1 = 1.03109 loss)
I0523 20:46:32.504935 14326 sgd_solver.cpp:106] Iteration 43500, lr = 0.0045
I0523 20:46:41.627806 14326 solver.cpp:237] Iteration 43750, loss = 1.44277
I0523 20:46:41.627848 14326 solver.cpp:253]     Train net output #0: loss = 1.44277 (* 1 = 1.44277 loss)
I0523 20:46:41.627867 14326 sgd_solver.cpp:106] Iteration 43750, lr = 0.0045
I0523 20:46:50.741816 14326 solver.cpp:237] Iteration 44000, loss = 1.0196
I0523 20:46:50.741852 14326 solver.cpp:253]     Train net output #0: loss = 1.0196 (* 1 = 1.0196 loss)
I0523 20:46:50.741868 14326 sgd_solver.cpp:106] Iteration 44000, lr = 0.0045
I0523 20:46:59.861709 14326 solver.cpp:237] Iteration 44250, loss = 1.28614
I0523 20:46:59.861757 14326 solver.cpp:253]     Train net output #0: loss = 1.28614 (* 1 = 1.28614 loss)
I0523 20:46:59.861773 14326 sgd_solver.cpp:106] Iteration 44250, lr = 0.0045
I0523 20:47:08.977959 14326 solver.cpp:237] Iteration 44500, loss = 1.03622
I0523 20:47:08.978112 14326 solver.cpp:253]     Train net output #0: loss = 1.03622 (* 1 = 1.03622 loss)
I0523 20:47:08.978127 14326 sgd_solver.cpp:106] Iteration 44500, lr = 0.0045
I0523 20:47:18.088934 14326 solver.cpp:237] Iteration 44750, loss = 1.10736
I0523 20:47:18.088968 14326 solver.cpp:253]     Train net output #0: loss = 1.10736 (* 1 = 1.10736 loss)
I0523 20:47:18.088985 14326 sgd_solver.cpp:106] Iteration 44750, lr = 0.0045
I0523 20:47:27.168297 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_45000.caffemodel
I0523 20:47:27.231952 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_45000.solverstate
I0523 20:47:27.258205 14326 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 20:48:14.499037 14326 solver.cpp:409]     Test net output #0: accuracy = 0.884934
I0523 20:48:14.499204 14326 solver.cpp:409]     Test net output #1: loss = 0.353855 (* 1 = 0.353855 loss)
I0523 20:48:35.399320 14326 solver.cpp:237] Iteration 45000, loss = 1.35101
I0523 20:48:35.399374 14326 solver.cpp:253]     Train net output #0: loss = 1.35101 (* 1 = 1.35101 loss)
I0523 20:48:35.399389 14326 sgd_solver.cpp:106] Iteration 45000, lr = 0.0045
I0523 20:48:44.439659 14326 solver.cpp:237] Iteration 45250, loss = 1.32446
I0523 20:48:44.439698 14326 solver.cpp:253]     Train net output #0: loss = 1.32446 (* 1 = 1.32446 loss)
I0523 20:48:44.439716 14326 sgd_solver.cpp:106] Iteration 45250, lr = 0.0045
I0523 20:48:53.477458 14326 solver.cpp:237] Iteration 45500, loss = 0.910293
I0523 20:48:53.477617 14326 solver.cpp:253]     Train net output #0: loss = 0.910293 (* 1 = 0.910293 loss)
I0523 20:48:53.477633 14326 sgd_solver.cpp:106] Iteration 45500, lr = 0.0045
I0523 20:49:02.517132 14326 solver.cpp:237] Iteration 45750, loss = 1.12406
I0523 20:49:02.517166 14326 solver.cpp:253]     Train net output #0: loss = 1.12406 (* 1 = 1.12406 loss)
I0523 20:49:02.517184 14326 sgd_solver.cpp:106] Iteration 45750, lr = 0.0045
I0523 20:49:11.543292 14326 solver.cpp:237] Iteration 46000, loss = 1.53941
I0523 20:49:11.543336 14326 solver.cpp:253]     Train net output #0: loss = 1.53941 (* 1 = 1.53941 loss)
I0523 20:49:11.543350 14326 sgd_solver.cpp:106] Iteration 46000, lr = 0.0045
I0523 20:49:20.571773 14326 solver.cpp:237] Iteration 46250, loss = 1.09324
I0523 20:49:20.571807 14326 solver.cpp:253]     Train net output #0: loss = 1.09324 (* 1 = 1.09324 loss)
I0523 20:49:20.571825 14326 sgd_solver.cpp:106] Iteration 46250, lr = 0.0045
I0523 20:49:29.601461 14326 solver.cpp:237] Iteration 46500, loss = 1.02619
I0523 20:49:29.601631 14326 solver.cpp:253]     Train net output #0: loss = 1.02619 (* 1 = 1.02619 loss)
I0523 20:49:29.601646 14326 sgd_solver.cpp:106] Iteration 46500, lr = 0.0045
I0523 20:49:59.555191 14326 solver.cpp:237] Iteration 46750, loss = 1.21758
I0523 20:49:59.555243 14326 solver.cpp:253]     Train net output #0: loss = 1.21758 (* 1 = 1.21758 loss)
I0523 20:49:59.555259 14326 sgd_solver.cpp:106] Iteration 46750, lr = 0.0045
I0523 20:50:08.584610 14326 solver.cpp:237] Iteration 47000, loss = 1.48168
I0523 20:50:08.584769 14326 solver.cpp:253]     Train net output #0: loss = 1.48168 (* 1 = 1.48168 loss)
I0523 20:50:08.584784 14326 sgd_solver.cpp:106] Iteration 47000, lr = 0.0045
I0523 20:50:17.612980 14326 solver.cpp:237] Iteration 47250, loss = 1.17396
I0523 20:50:17.613014 14326 solver.cpp:253]     Train net output #0: loss = 1.17396 (* 1 = 1.17396 loss)
I0523 20:50:17.613032 14326 sgd_solver.cpp:106] Iteration 47250, lr = 0.0045
I0523 20:50:26.618613 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_47500.caffemodel
I0523 20:50:26.683454 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_47500.solverstate
I0523 20:50:26.723156 14326 solver.cpp:237] Iteration 47500, loss = 1.37496
I0523 20:50:26.723206 14326 solver.cpp:253]     Train net output #0: loss = 1.37496 (* 1 = 1.37496 loss)
I0523 20:50:26.723220 14326 sgd_solver.cpp:106] Iteration 47500, lr = 0.0045
I0523 20:50:35.757391 14326 solver.cpp:237] Iteration 47750, loss = 1.08942
I0523 20:50:35.757427 14326 solver.cpp:253]     Train net output #0: loss = 1.08942 (* 1 = 1.08942 loss)
I0523 20:50:35.757441 14326 sgd_solver.cpp:106] Iteration 47750, lr = 0.0045
I0523 20:50:44.792181 14326 solver.cpp:237] Iteration 48000, loss = 1.2122
I0523 20:50:44.792356 14326 solver.cpp:253]     Train net output #0: loss = 1.2122 (* 1 = 1.2122 loss)
I0523 20:50:44.792369 14326 sgd_solver.cpp:106] Iteration 48000, lr = 0.0045
I0523 20:50:53.823930 14326 solver.cpp:237] Iteration 48250, loss = 1.13141
I0523 20:50:53.823964 14326 solver.cpp:253]     Train net output #0: loss = 1.13141 (* 1 = 1.13141 loss)
I0523 20:50:53.823981 14326 sgd_solver.cpp:106] Iteration 48250, lr = 0.0045
I0523 20:51:23.764986 14326 solver.cpp:237] Iteration 48500, loss = 1.31636
I0523 20:51:23.765163 14326 solver.cpp:253]     Train net output #0: loss = 1.31636 (* 1 = 1.31636 loss)
I0523 20:51:23.765177 14326 sgd_solver.cpp:106] Iteration 48500, lr = 0.0045
I0523 20:51:32.798094 14326 solver.cpp:237] Iteration 48750, loss = 0.958557
I0523 20:51:32.798128 14326 solver.cpp:253]     Train net output #0: loss = 0.958557 (* 1 = 0.958557 loss)
I0523 20:51:32.798144 14326 sgd_solver.cpp:106] Iteration 48750, lr = 0.0045
I0523 20:51:41.830322 14326 solver.cpp:237] Iteration 49000, loss = 0.943436
I0523 20:51:41.830366 14326 solver.cpp:253]     Train net output #0: loss = 0.943436 (* 1 = 0.943436 loss)
I0523 20:51:41.830380 14326 sgd_solver.cpp:106] Iteration 49000, lr = 0.0045
I0523 20:51:50.865208 14326 solver.cpp:237] Iteration 49250, loss = 1.28515
I0523 20:51:50.865244 14326 solver.cpp:253]     Train net output #0: loss = 1.28515 (* 1 = 1.28515 loss)
I0523 20:51:50.865257 14326 sgd_solver.cpp:106] Iteration 49250, lr = 0.0045
I0523 20:51:59.901749 14326 solver.cpp:237] Iteration 49500, loss = 0.905969
I0523 20:51:59.901927 14326 solver.cpp:253]     Train net output #0: loss = 0.905969 (* 1 = 0.905969 loss)
I0523 20:51:59.901942 14326 sgd_solver.cpp:106] Iteration 49500, lr = 0.0045
I0523 20:52:08.936293 14326 solver.cpp:237] Iteration 49750, loss = 1.16884
I0523 20:52:08.936328 14326 solver.cpp:253]     Train net output #0: loss = 1.16884 (* 1 = 1.16884 loss)
I0523 20:52:08.936344 14326 sgd_solver.cpp:106] Iteration 49750, lr = 0.0045
I0523 20:52:17.935606 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_50000.caffemodel
I0523 20:52:18.001555 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_50000.solverstate
I0523 20:52:18.030073 14326 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 20:53:26.245654 14326 solver.cpp:409]     Test net output #0: accuracy = 0.895246
I0523 20:53:26.245832 14326 solver.cpp:409]     Test net output #1: loss = 0.351684 (* 1 = 0.351684 loss)
I0523 20:53:47.137326 14326 solver.cpp:237] Iteration 50000, loss = 1.25248
I0523 20:53:47.137377 14326 solver.cpp:253]     Train net output #0: loss = 1.25248 (* 1 = 1.25248 loss)
I0523 20:53:47.137393 14326 sgd_solver.cpp:106] Iteration 50000, lr = 0.0045
I0523 20:53:56.197046 14326 solver.cpp:237] Iteration 50250, loss = 1.00203
I0523 20:53:56.197082 14326 solver.cpp:253]     Train net output #0: loss = 1.00203 (* 1 = 1.00203 loss)
I0523 20:53:56.197096 14326 sgd_solver.cpp:106] Iteration 50250, lr = 0.0045
I0523 20:54:05.247089 14326 solver.cpp:237] Iteration 50500, loss = 1.33308
I0523 20:54:05.247258 14326 solver.cpp:253]     Train net output #0: loss = 1.33308 (* 1 = 1.33308 loss)
I0523 20:54:05.247272 14326 sgd_solver.cpp:106] Iteration 50500, lr = 0.0045
I0523 20:54:14.303625 14326 solver.cpp:237] Iteration 50750, loss = 1.31173
I0523 20:54:14.303659 14326 solver.cpp:253]     Train net output #0: loss = 1.31173 (* 1 = 1.31173 loss)
I0523 20:54:14.303675 14326 sgd_solver.cpp:106] Iteration 50750, lr = 0.0045
I0523 20:54:23.372736 14326 solver.cpp:237] Iteration 51000, loss = 1.23616
I0523 20:54:23.372771 14326 solver.cpp:253]     Train net output #0: loss = 1.23616 (* 1 = 1.23616 loss)
I0523 20:54:23.372786 14326 sgd_solver.cpp:106] Iteration 51000, lr = 0.0045
I0523 20:54:32.425303 14326 solver.cpp:237] Iteration 51250, loss = 1.06507
I0523 20:54:32.425343 14326 solver.cpp:253]     Train net output #0: loss = 1.06507 (* 1 = 1.06507 loss)
I0523 20:54:32.425359 14326 sgd_solver.cpp:106] Iteration 51250, lr = 0.0045
I0523 20:54:41.471366 14326 solver.cpp:237] Iteration 51500, loss = 1.34603
I0523 20:54:41.471515 14326 solver.cpp:253]     Train net output #0: loss = 1.34603 (* 1 = 1.34603 loss)
I0523 20:54:41.471529 14326 sgd_solver.cpp:106] Iteration 51500, lr = 0.0045
I0523 20:55:11.434473 14326 solver.cpp:237] Iteration 51750, loss = 1.21487
I0523 20:55:11.434521 14326 solver.cpp:253]     Train net output #0: loss = 1.21487 (* 1 = 1.21487 loss)
I0523 20:55:11.434538 14326 sgd_solver.cpp:106] Iteration 51750, lr = 0.0045
I0523 20:55:20.478519 14326 solver.cpp:237] Iteration 52000, loss = 0.934371
I0523 20:55:20.478696 14326 solver.cpp:253]     Train net output #0: loss = 0.934371 (* 1 = 0.934371 loss)
I0523 20:55:20.478711 14326 sgd_solver.cpp:106] Iteration 52000, lr = 0.0045
I0523 20:55:29.533321 14326 solver.cpp:237] Iteration 52250, loss = 1.48362
I0523 20:55:29.533355 14326 solver.cpp:253]     Train net output #0: loss = 1.48362 (* 1 = 1.48362 loss)
I0523 20:55:29.533372 14326 sgd_solver.cpp:106] Iteration 52250, lr = 0.0045
I0523 20:55:38.551614 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_52500.caffemodel
I0523 20:55:38.616220 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_52500.solverstate
I0523 20:55:38.653895 14326 solver.cpp:237] Iteration 52500, loss = 1.09255
I0523 20:55:38.653939 14326 solver.cpp:253]     Train net output #0: loss = 1.09255 (* 1 = 1.09255 loss)
I0523 20:55:38.653956 14326 sgd_solver.cpp:106] Iteration 52500, lr = 0.0045
I0523 20:55:47.710114 14326 solver.cpp:237] Iteration 52750, loss = 1.26509
I0523 20:55:47.710158 14326 solver.cpp:253]     Train net output #0: loss = 1.26509 (* 1 = 1.26509 loss)
I0523 20:55:47.710172 14326 sgd_solver.cpp:106] Iteration 52750, lr = 0.0045
I0523 20:55:56.762992 14326 solver.cpp:237] Iteration 53000, loss = 1.03645
I0523 20:55:56.763162 14326 solver.cpp:253]     Train net output #0: loss = 1.03645 (* 1 = 1.03645 loss)
I0523 20:55:56.763175 14326 sgd_solver.cpp:106] Iteration 53000, lr = 0.0045
I0523 20:56:05.817881 14326 solver.cpp:237] Iteration 53250, loss = 1.14095
I0523 20:56:05.817915 14326 solver.cpp:253]     Train net output #0: loss = 1.14095 (* 1 = 1.14095 loss)
I0523 20:56:05.817930 14326 sgd_solver.cpp:106] Iteration 53250, lr = 0.0045
I0523 20:56:35.742928 14326 solver.cpp:237] Iteration 53500, loss = 0.873979
I0523 20:56:35.743113 14326 solver.cpp:253]     Train net output #0: loss = 0.873979 (* 1 = 0.873979 loss)
I0523 20:56:35.743129 14326 sgd_solver.cpp:106] Iteration 53500, lr = 0.0045
I0523 20:56:44.801347 14326 solver.cpp:237] Iteration 53750, loss = 0.918006
I0523 20:56:44.801383 14326 solver.cpp:253]     Train net output #0: loss = 0.918006 (* 1 = 0.918006 loss)
I0523 20:56:44.801398 14326 sgd_solver.cpp:106] Iteration 53750, lr = 0.0045
I0523 20:56:53.865572 14326 solver.cpp:237] Iteration 54000, loss = 1.19569
I0523 20:56:53.865607 14326 solver.cpp:253]     Train net output #0: loss = 1.19569 (* 1 = 1.19569 loss)
I0523 20:56:53.865620 14326 sgd_solver.cpp:106] Iteration 54000, lr = 0.0045
I0523 20:57:02.922441 14326 solver.cpp:237] Iteration 54250, loss = 1.02763
I0523 20:57:02.922490 14326 solver.cpp:253]     Train net output #0: loss = 1.02763 (* 1 = 1.02763 loss)
I0523 20:57:02.922504 14326 sgd_solver.cpp:106] Iteration 54250, lr = 0.0045
I0523 20:57:11.974174 14326 solver.cpp:237] Iteration 54500, loss = 1.10515
I0523 20:57:11.974331 14326 solver.cpp:253]     Train net output #0: loss = 1.10515 (* 1 = 1.10515 loss)
I0523 20:57:11.974344 14326 sgd_solver.cpp:106] Iteration 54500, lr = 0.0045
I0523 20:57:21.036991 14326 solver.cpp:237] Iteration 54750, loss = 1.29957
I0523 20:57:21.037022 14326 solver.cpp:253]     Train net output #0: loss = 1.29957 (* 1 = 1.29957 loss)
I0523 20:57:21.037035 14326 sgd_solver.cpp:106] Iteration 54750, lr = 0.0045
I0523 20:57:30.060892 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_55000.caffemodel
I0523 20:57:30.134775 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_55000.solverstate
I0523 20:57:30.161355 14326 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 20:58:17.108341 14326 solver.cpp:409]     Test net output #0: accuracy = 0.891699
I0523 20:58:17.108517 14326 solver.cpp:409]     Test net output #1: loss = 0.343017 (* 1 = 0.343017 loss)
I0523 20:58:38.007557 14326 solver.cpp:237] Iteration 55000, loss = 0.927008
I0523 20:58:38.007611 14326 solver.cpp:253]     Train net output #0: loss = 0.927008 (* 1 = 0.927008 loss)
I0523 20:58:38.007627 14326 sgd_solver.cpp:106] Iteration 55000, lr = 0.0045
I0523 20:58:47.029424 14326 solver.cpp:237] Iteration 55250, loss = 1.17189
I0523 20:58:47.029471 14326 solver.cpp:253]     Train net output #0: loss = 1.17189 (* 1 = 1.17189 loss)
I0523 20:58:47.029485 14326 sgd_solver.cpp:106] Iteration 55250, lr = 0.0045
I0523 20:58:56.051725 14326 solver.cpp:237] Iteration 55500, loss = 1.11379
I0523 20:58:56.051893 14326 solver.cpp:253]     Train net output #0: loss = 1.11379 (* 1 = 1.11379 loss)
I0523 20:58:56.051908 14326 sgd_solver.cpp:106] Iteration 55500, lr = 0.0045
I0523 20:59:05.064808 14326 solver.cpp:237] Iteration 55750, loss = 1.23876
I0523 20:59:05.064864 14326 solver.cpp:253]     Train net output #0: loss = 1.23876 (* 1 = 1.23876 loss)
I0523 20:59:05.064878 14326 sgd_solver.cpp:106] Iteration 55750, lr = 0.0045
I0523 20:59:14.078981 14326 solver.cpp:237] Iteration 56000, loss = 1.18014
I0523 20:59:14.079017 14326 solver.cpp:253]     Train net output #0: loss = 1.18014 (* 1 = 1.18014 loss)
I0523 20:59:14.079031 14326 sgd_solver.cpp:106] Iteration 56000, lr = 0.0045
I0523 20:59:23.088800 14326 solver.cpp:237] Iteration 56250, loss = 1.05825
I0523 20:59:23.088836 14326 solver.cpp:253]     Train net output #0: loss = 1.05825 (* 1 = 1.05825 loss)
I0523 20:59:23.088850 14326 sgd_solver.cpp:106] Iteration 56250, lr = 0.0045
I0523 20:59:32.103998 14326 solver.cpp:237] Iteration 56500, loss = 1.12683
I0523 20:59:32.104179 14326 solver.cpp:253]     Train net output #0: loss = 1.12683 (* 1 = 1.12683 loss)
I0523 20:59:32.104194 14326 sgd_solver.cpp:106] Iteration 56500, lr = 0.0045
I0523 21:00:02.039595 14326 solver.cpp:237] Iteration 56750, loss = 1.18261
I0523 21:00:02.039645 14326 solver.cpp:253]     Train net output #0: loss = 1.18261 (* 1 = 1.18261 loss)
I0523 21:00:02.039659 14326 sgd_solver.cpp:106] Iteration 56750, lr = 0.0045
I0523 21:00:11.049003 14326 solver.cpp:237] Iteration 57000, loss = 1.1584
I0523 21:00:11.049165 14326 solver.cpp:253]     Train net output #0: loss = 1.1584 (* 1 = 1.1584 loss)
I0523 21:00:11.049178 14326 sgd_solver.cpp:106] Iteration 57000, lr = 0.0045
I0523 21:00:20.063513 14326 solver.cpp:237] Iteration 57250, loss = 1.07505
I0523 21:00:20.063563 14326 solver.cpp:253]     Train net output #0: loss = 1.07505 (* 1 = 1.07505 loss)
I0523 21:00:20.063577 14326 sgd_solver.cpp:106] Iteration 57250, lr = 0.0045
I0523 21:00:29.040628 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_57500.caffemodel
I0523 21:00:29.104285 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_57500.solverstate
I0523 21:00:29.141677 14326 solver.cpp:237] Iteration 57500, loss = 1.24377
I0523 21:00:29.141721 14326 solver.cpp:253]     Train net output #0: loss = 1.24377 (* 1 = 1.24377 loss)
I0523 21:00:29.141738 14326 sgd_solver.cpp:106] Iteration 57500, lr = 0.0045
I0523 21:00:38.168237 14326 solver.cpp:237] Iteration 57750, loss = 1.06395
I0523 21:00:38.168273 14326 solver.cpp:253]     Train net output #0: loss = 1.06395 (* 1 = 1.06395 loss)
I0523 21:00:38.168288 14326 sgd_solver.cpp:106] Iteration 57750, lr = 0.0045
I0523 21:00:47.186857 14326 solver.cpp:237] Iteration 58000, loss = 1.09664
I0523 21:00:47.187033 14326 solver.cpp:253]     Train net output #0: loss = 1.09664 (* 1 = 1.09664 loss)
I0523 21:00:47.187047 14326 sgd_solver.cpp:106] Iteration 58000, lr = 0.0045
I0523 21:00:56.197012 14326 solver.cpp:237] Iteration 58250, loss = 1.05647
I0523 21:00:56.197047 14326 solver.cpp:253]     Train net output #0: loss = 1.05647 (* 1 = 1.05647 loss)
I0523 21:00:56.197063 14326 sgd_solver.cpp:106] Iteration 58250, lr = 0.0045
I0523 21:01:26.151620 14326 solver.cpp:237] Iteration 58500, loss = 0.936129
I0523 21:01:26.151799 14326 solver.cpp:253]     Train net output #0: loss = 0.936129 (* 1 = 0.936129 loss)
I0523 21:01:26.151813 14326 sgd_solver.cpp:106] Iteration 58500, lr = 0.0045
I0523 21:01:35.167973 14326 solver.cpp:237] Iteration 58750, loss = 1.0027
I0523 21:01:35.168011 14326 solver.cpp:253]     Train net output #0: loss = 1.0027 (* 1 = 1.0027 loss)
I0523 21:01:35.168031 14326 sgd_solver.cpp:106] Iteration 58750, lr = 0.0045
I0523 21:01:44.181874 14326 solver.cpp:237] Iteration 59000, loss = 1.14948
I0523 21:01:44.181910 14326 solver.cpp:253]     Train net output #0: loss = 1.14948 (* 1 = 1.14948 loss)
I0523 21:01:44.181924 14326 sgd_solver.cpp:106] Iteration 59000, lr = 0.0045
I0523 21:01:53.201127 14326 solver.cpp:237] Iteration 59250, loss = 1.25503
I0523 21:01:53.201160 14326 solver.cpp:253]     Train net output #0: loss = 1.25503 (* 1 = 1.25503 loss)
I0523 21:01:53.201175 14326 sgd_solver.cpp:106] Iteration 59250, lr = 0.0045
I0523 21:02:02.212399 14326 solver.cpp:237] Iteration 59500, loss = 1.21653
I0523 21:02:02.212577 14326 solver.cpp:253]     Train net output #0: loss = 1.21653 (* 1 = 1.21653 loss)
I0523 21:02:02.212591 14326 sgd_solver.cpp:106] Iteration 59500, lr = 0.0045
I0523 21:02:11.225564 14326 solver.cpp:237] Iteration 59750, loss = 0.817261
I0523 21:02:11.225599 14326 solver.cpp:253]     Train net output #0: loss = 0.817261 (* 1 = 0.817261 loss)
I0523 21:02:11.225613 14326 sgd_solver.cpp:106] Iteration 59750, lr = 0.0045
I0523 21:02:20.202360 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_60000.caffemodel
I0523 21:02:20.265539 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_60000.solverstate
I0523 21:02:20.292073 14326 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 21:03:28.421108 14326 solver.cpp:409]     Test net output #0: accuracy = 0.893311
I0523 21:03:28.421286 14326 solver.cpp:409]     Test net output #1: loss = 0.366339 (* 1 = 0.366339 loss)
I0523 21:03:49.328205 14326 solver.cpp:237] Iteration 60000, loss = 0.945969
I0523 21:03:49.328258 14326 solver.cpp:253]     Train net output #0: loss = 0.945969 (* 1 = 0.945969 loss)
I0523 21:03:49.328274 14326 sgd_solver.cpp:106] Iteration 60000, lr = 0.0045
I0523 21:03:58.424914 14326 solver.cpp:237] Iteration 60250, loss = 1.44687
I0523 21:03:58.425081 14326 solver.cpp:253]     Train net output #0: loss = 1.44687 (* 1 = 1.44687 loss)
I0523 21:03:58.425093 14326 sgd_solver.cpp:106] Iteration 60250, lr = 0.0045
I0523 21:04:07.516088 14326 solver.cpp:237] Iteration 60500, loss = 1.1491
I0523 21:04:07.516134 14326 solver.cpp:253]     Train net output #0: loss = 1.1491 (* 1 = 1.1491 loss)
I0523 21:04:07.516150 14326 sgd_solver.cpp:106] Iteration 60500, lr = 0.0045
I0523 21:04:16.610486 14326 solver.cpp:237] Iteration 60750, loss = 1.02087
I0523 21:04:16.610522 14326 solver.cpp:253]     Train net output #0: loss = 1.02087 (* 1 = 1.02087 loss)
I0523 21:04:16.610538 14326 sgd_solver.cpp:106] Iteration 60750, lr = 0.0045
I0523 21:04:25.690711 14326 solver.cpp:237] Iteration 61000, loss = 1.29159
I0523 21:04:25.690745 14326 solver.cpp:253]     Train net output #0: loss = 1.29159 (* 1 = 1.29159 loss)
I0523 21:04:25.690760 14326 sgd_solver.cpp:106] Iteration 61000, lr = 0.0045
I0523 21:04:34.794355 14326 solver.cpp:237] Iteration 61250, loss = 0.884736
I0523 21:04:34.794530 14326 solver.cpp:253]     Train net output #0: loss = 0.884736 (* 1 = 0.884736 loss)
I0523 21:04:34.794544 14326 sgd_solver.cpp:106] Iteration 61250, lr = 0.0045
I0523 21:04:43.874826 14326 solver.cpp:237] Iteration 61500, loss = 1.35682
I0523 21:04:43.874861 14326 solver.cpp:253]     Train net output #0: loss = 1.35682 (* 1 = 1.35682 loss)
I0523 21:04:43.874876 14326 sgd_solver.cpp:106] Iteration 61500, lr = 0.0045
I0523 21:05:13.877648 14326 solver.cpp:237] Iteration 61750, loss = 1.08816
I0523 21:05:13.877827 14326 solver.cpp:253]     Train net output #0: loss = 1.08816 (* 1 = 1.08816 loss)
I0523 21:05:13.877841 14326 sgd_solver.cpp:106] Iteration 61750, lr = 0.0045
I0523 21:05:22.962426 14326 solver.cpp:237] Iteration 62000, loss = 1.17929
I0523 21:05:22.962472 14326 solver.cpp:253]     Train net output #0: loss = 1.17929 (* 1 = 1.17929 loss)
I0523 21:05:22.962488 14326 sgd_solver.cpp:106] Iteration 62000, lr = 0.0045
I0523 21:05:32.066337 14326 solver.cpp:237] Iteration 62250, loss = 1.0006
I0523 21:05:32.066373 14326 solver.cpp:253]     Train net output #0: loss = 1.0006 (* 1 = 1.0006 loss)
I0523 21:05:32.066387 14326 sgd_solver.cpp:106] Iteration 62250, lr = 0.0045
I0523 21:05:41.131026 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_62500.caffemodel
I0523 21:05:41.196295 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_62500.solverstate
I0523 21:05:41.235859 14326 solver.cpp:237] Iteration 62500, loss = 1.02606
I0523 21:05:41.235909 14326 solver.cpp:253]     Train net output #0: loss = 1.02606 (* 1 = 1.02606 loss)
I0523 21:05:41.235924 14326 sgd_solver.cpp:106] Iteration 62500, lr = 0.0045
I0523 21:05:50.333672 14326 solver.cpp:237] Iteration 62750, loss = 1.14083
I0523 21:05:50.333858 14326 solver.cpp:253]     Train net output #0: loss = 1.14083 (* 1 = 1.14083 loss)
I0523 21:05:50.333871 14326 sgd_solver.cpp:106] Iteration 62750, lr = 0.0045
I0523 21:05:59.424075 14326 solver.cpp:237] Iteration 63000, loss = 1.47057
I0523 21:05:59.424110 14326 solver.cpp:253]     Train net output #0: loss = 1.47057 (* 1 = 1.47057 loss)
I0523 21:05:59.424125 14326 sgd_solver.cpp:106] Iteration 63000, lr = 0.0045
I0523 21:06:08.520869 14326 solver.cpp:237] Iteration 63250, loss = 1.21282
I0523 21:06:08.520905 14326 solver.cpp:253]     Train net output #0: loss = 1.21282 (* 1 = 1.21282 loss)
I0523 21:06:08.520920 14326 sgd_solver.cpp:106] Iteration 63250, lr = 0.0045
I0523 21:06:38.531877 14326 solver.cpp:237] Iteration 63500, loss = 1.31298
I0523 21:06:38.532061 14326 solver.cpp:253]     Train net output #0: loss = 1.31298 (* 1 = 1.31298 loss)
I0523 21:06:38.532075 14326 sgd_solver.cpp:106] Iteration 63500, lr = 0.0045
I0523 21:06:47.621973 14326 solver.cpp:237] Iteration 63750, loss = 1.26986
I0523 21:06:47.622007 14326 solver.cpp:253]     Train net output #0: loss = 1.26986 (* 1 = 1.26986 loss)
I0523 21:06:47.622022 14326 sgd_solver.cpp:106] Iteration 63750, lr = 0.0045
I0523 21:06:56.718633 14326 solver.cpp:237] Iteration 64000, loss = 1.0007
I0523 21:06:56.718669 14326 solver.cpp:253]     Train net output #0: loss = 1.0007 (* 1 = 1.0007 loss)
I0523 21:06:56.718683 14326 sgd_solver.cpp:106] Iteration 64000, lr = 0.0045
I0523 21:07:05.816059 14326 solver.cpp:237] Iteration 64250, loss = 1.25355
I0523 21:07:05.816097 14326 solver.cpp:253]     Train net output #0: loss = 1.25355 (* 1 = 1.25355 loss)
I0523 21:07:05.816118 14326 sgd_solver.cpp:106] Iteration 64250, lr = 0.0045
I0523 21:07:14.918892 14326 solver.cpp:237] Iteration 64500, loss = 1.24407
I0523 21:07:14.919052 14326 solver.cpp:253]     Train net output #0: loss = 1.24407 (* 1 = 1.24407 loss)
I0523 21:07:14.919066 14326 sgd_solver.cpp:106] Iteration 64500, lr = 0.0045
I0523 21:07:24.014703 14326 solver.cpp:237] Iteration 64750, loss = 1.09721
I0523 21:07:24.014737 14326 solver.cpp:253]     Train net output #0: loss = 1.09721 (* 1 = 1.09721 loss)
I0523 21:07:24.014752 14326 sgd_solver.cpp:106] Iteration 64750, lr = 0.0045
I0523 21:07:33.082727 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_65000.caffemodel
I0523 21:07:33.146292 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_65000.solverstate
I0523 21:07:33.173025 14326 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 21:08:20.466697 14326 solver.cpp:409]     Test net output #0: accuracy = 0.894285
I0523 21:08:20.466886 14326 solver.cpp:409]     Test net output #1: loss = 0.343033 (* 1 = 0.343033 loss)
I0523 21:08:41.390811 14326 solver.cpp:237] Iteration 65000, loss = 0.993636
I0523 21:08:41.390866 14326 solver.cpp:253]     Train net output #0: loss = 0.993636 (* 1 = 0.993636 loss)
I0523 21:08:41.390880 14326 sgd_solver.cpp:106] Iteration 65000, lr = 0.0045
I0523 21:08:50.462970 14326 solver.cpp:237] Iteration 65250, loss = 1.07512
I0523 21:08:50.463004 14326 solver.cpp:253]     Train net output #0: loss = 1.07512 (* 1 = 1.07512 loss)
I0523 21:08:50.463021 14326 sgd_solver.cpp:106] Iteration 65250, lr = 0.0045
I0523 21:08:59.531666 14326 solver.cpp:237] Iteration 65500, loss = 1.20204
I0523 21:08:59.531833 14326 solver.cpp:253]     Train net output #0: loss = 1.20204 (* 1 = 1.20204 loss)
I0523 21:08:59.531847 14326 sgd_solver.cpp:106] Iteration 65500, lr = 0.0045
I0523 21:09:08.608268 14326 solver.cpp:237] Iteration 65750, loss = 1.08866
I0523 21:09:08.608309 14326 solver.cpp:253]     Train net output #0: loss = 1.08866 (* 1 = 1.08866 loss)
I0523 21:09:08.608328 14326 sgd_solver.cpp:106] Iteration 65750, lr = 0.0045
I0523 21:09:17.678442 14326 solver.cpp:237] Iteration 66000, loss = 1.32808
I0523 21:09:17.678478 14326 solver.cpp:253]     Train net output #0: loss = 1.32808 (* 1 = 1.32808 loss)
I0523 21:09:17.678491 14326 sgd_solver.cpp:106] Iteration 66000, lr = 0.0045
I0523 21:09:26.756425 14326 solver.cpp:237] Iteration 66250, loss = 1.33561
I0523 21:09:26.756460 14326 solver.cpp:253]     Train net output #0: loss = 1.33561 (* 1 = 1.33561 loss)
I0523 21:09:26.756476 14326 sgd_solver.cpp:106] Iteration 66250, lr = 0.0045
I0523 21:09:35.826544 14326 solver.cpp:237] Iteration 66500, loss = 1.08127
I0523 21:09:35.826714 14326 solver.cpp:253]     Train net output #0: loss = 1.08127 (* 1 = 1.08127 loss)
I0523 21:09:35.826727 14326 sgd_solver.cpp:106] Iteration 66500, lr = 0.0045
I0523 21:10:05.857281 14326 solver.cpp:237] Iteration 66750, loss = 1.04123
I0523 21:10:05.857463 14326 solver.cpp:253]     Train net output #0: loss = 1.04123 (* 1 = 1.04123 loss)
I0523 21:10:05.857477 14326 sgd_solver.cpp:106] Iteration 66750, lr = 0.0045
I0523 21:10:14.927479 14326 solver.cpp:237] Iteration 67000, loss = 1.16926
I0523 21:10:14.927512 14326 solver.cpp:253]     Train net output #0: loss = 1.16926 (* 1 = 1.16926 loss)
I0523 21:10:14.927526 14326 sgd_solver.cpp:106] Iteration 67000, lr = 0.0045
I0523 21:10:24.000279 14326 solver.cpp:237] Iteration 67250, loss = 1.55685
I0523 21:10:24.000316 14326 solver.cpp:253]     Train net output #0: loss = 1.55685 (* 1 = 1.55685 loss)
I0523 21:10:24.000329 14326 sgd_solver.cpp:106] Iteration 67250, lr = 0.0045
I0523 21:10:33.038378 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_67500.caffemodel
I0523 21:10:33.101860 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_67500.solverstate
I0523 21:10:33.139225 14326 solver.cpp:237] Iteration 67500, loss = 1.0152
I0523 21:10:33.139269 14326 solver.cpp:253]     Train net output #0: loss = 1.0152 (* 1 = 1.0152 loss)
I0523 21:10:33.139283 14326 sgd_solver.cpp:106] Iteration 67500, lr = 0.0045
I0523 21:10:42.218392 14326 solver.cpp:237] Iteration 67750, loss = 1.15887
I0523 21:10:42.218559 14326 solver.cpp:253]     Train net output #0: loss = 1.15887 (* 1 = 1.15887 loss)
I0523 21:10:42.218572 14326 sgd_solver.cpp:106] Iteration 67750, lr = 0.0045
I0523 21:10:51.290973 14326 solver.cpp:237] Iteration 68000, loss = 1.19596
I0523 21:10:51.291019 14326 solver.cpp:253]     Train net output #0: loss = 1.19596 (* 1 = 1.19596 loss)
I0523 21:10:51.291034 14326 sgd_solver.cpp:106] Iteration 68000, lr = 0.0045
I0523 21:11:00.367893 14326 solver.cpp:237] Iteration 68250, loss = 1.22291
I0523 21:11:00.367929 14326 solver.cpp:253]     Train net output #0: loss = 1.22291 (* 1 = 1.22291 loss)
I0523 21:11:00.367944 14326 sgd_solver.cpp:106] Iteration 68250, lr = 0.0045
I0523 21:11:30.345358 14326 solver.cpp:237] Iteration 68500, loss = 0.996165
I0523 21:11:30.345556 14326 solver.cpp:253]     Train net output #0: loss = 0.996165 (* 1 = 0.996165 loss)
I0523 21:11:30.345569 14326 sgd_solver.cpp:106] Iteration 68500, lr = 0.0045
I0523 21:11:39.415580 14326 solver.cpp:237] Iteration 68750, loss = 1.19363
I0523 21:11:39.415618 14326 solver.cpp:253]     Train net output #0: loss = 1.19363 (* 1 = 1.19363 loss)
I0523 21:11:39.415630 14326 sgd_solver.cpp:106] Iteration 68750, lr = 0.0045
I0523 21:11:48.492286 14326 solver.cpp:237] Iteration 69000, loss = 0.87094
I0523 21:11:48.492323 14326 solver.cpp:253]     Train net output #0: loss = 0.87094 (* 1 = 0.87094 loss)
I0523 21:11:48.492337 14326 sgd_solver.cpp:106] Iteration 69000, lr = 0.0045
I0523 21:11:57.572831 14326 solver.cpp:237] Iteration 69250, loss = 1.09928
I0523 21:11:57.572872 14326 solver.cpp:253]     Train net output #0: loss = 1.09928 (* 1 = 1.09928 loss)
I0523 21:11:57.572885 14326 sgd_solver.cpp:106] Iteration 69250, lr = 0.0045
I0523 21:12:06.647367 14326 solver.cpp:237] Iteration 69500, loss = 1.13906
I0523 21:12:06.647536 14326 solver.cpp:253]     Train net output #0: loss = 1.13906 (* 1 = 1.13906 loss)
I0523 21:12:06.647549 14326 sgd_solver.cpp:106] Iteration 69500, lr = 0.0045
I0523 21:12:15.718279 14326 solver.cpp:237] Iteration 69750, loss = 0.964649
I0523 21:12:15.718314 14326 solver.cpp:253]     Train net output #0: loss = 0.964649 (* 1 = 0.964649 loss)
I0523 21:12:15.718330 14326 sgd_solver.cpp:106] Iteration 69750, lr = 0.0045
I0523 21:12:24.756669 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_70000.caffemodel
I0523 21:12:24.819495 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_70000.solverstate
I0523 21:12:24.845898 14326 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 21:13:32.964467 14326 solver.cpp:409]     Test net output #0: accuracy = 0.897819
I0523 21:13:32.964648 14326 solver.cpp:409]     Test net output #1: loss = 0.333919 (* 1 = 0.333919 loss)
I0523 21:13:53.834724 14326 solver.cpp:237] Iteration 70000, loss = 1.08571
I0523 21:13:53.834776 14326 solver.cpp:253]     Train net output #0: loss = 1.08571 (* 1 = 1.08571 loss)
I0523 21:13:53.834792 14326 sgd_solver.cpp:106] Iteration 70000, lr = 0.0045
I0523 21:14:02.950964 14326 solver.cpp:237] Iteration 70250, loss = 1.06464
I0523 21:14:02.951000 14326 solver.cpp:253]     Train net output #0: loss = 1.06464 (* 1 = 1.06464 loss)
I0523 21:14:02.951014 14326 sgd_solver.cpp:106] Iteration 70250, lr = 0.0045
I0523 21:14:12.063530 14326 solver.cpp:237] Iteration 70500, loss = 1.05997
I0523 21:14:12.063712 14326 solver.cpp:253]     Train net output #0: loss = 1.05997 (* 1 = 1.05997 loss)
I0523 21:14:12.063726 14326 sgd_solver.cpp:106] Iteration 70500, lr = 0.0045
I0523 21:14:21.177944 14326 solver.cpp:237] Iteration 70750, loss = 1.05265
I0523 21:14:21.177979 14326 solver.cpp:253]     Train net output #0: loss = 1.05265 (* 1 = 1.05265 loss)
I0523 21:14:21.177994 14326 sgd_solver.cpp:106] Iteration 70750, lr = 0.0045
I0523 21:14:30.299357 14326 solver.cpp:237] Iteration 71000, loss = 1.01208
I0523 21:14:30.299396 14326 solver.cpp:253]     Train net output #0: loss = 1.01208 (* 1 = 1.01208 loss)
I0523 21:14:30.299414 14326 sgd_solver.cpp:106] Iteration 71000, lr = 0.0045
I0523 21:14:39.412168 14326 solver.cpp:237] Iteration 71250, loss = 0.932104
I0523 21:14:39.412204 14326 solver.cpp:253]     Train net output #0: loss = 0.932104 (* 1 = 0.932104 loss)
I0523 21:14:39.412219 14326 sgd_solver.cpp:106] Iteration 71250, lr = 0.0045
I0523 21:14:48.526696 14326 solver.cpp:237] Iteration 71500, loss = 1.04378
I0523 21:14:48.526856 14326 solver.cpp:253]     Train net output #0: loss = 1.04378 (* 1 = 1.04378 loss)
I0523 21:14:48.526870 14326 sgd_solver.cpp:106] Iteration 71500, lr = 0.0045
I0523 21:15:18.531704 14326 solver.cpp:237] Iteration 71750, loss = 0.982569
I0523 21:15:18.531895 14326 solver.cpp:253]     Train net output #0: loss = 0.982569 (* 1 = 0.982569 loss)
I0523 21:15:18.531913 14326 sgd_solver.cpp:106] Iteration 71750, lr = 0.0045
I0523 21:15:27.644515 14326 solver.cpp:237] Iteration 72000, loss = 1.14456
I0523 21:15:27.644563 14326 solver.cpp:253]     Train net output #0: loss = 1.14456 (* 1 = 1.14456 loss)
I0523 21:15:27.644579 14326 sgd_solver.cpp:106] Iteration 72000, lr = 0.0045
I0523 21:15:36.756642 14326 solver.cpp:237] Iteration 72250, loss = 1.33828
I0523 21:15:36.756678 14326 solver.cpp:253]     Train net output #0: loss = 1.33828 (* 1 = 1.33828 loss)
I0523 21:15:36.756693 14326 sgd_solver.cpp:106] Iteration 72250, lr = 0.0045
I0523 21:15:45.830106 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_72500.caffemodel
I0523 21:15:45.894512 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_72500.solverstate
I0523 21:15:45.934136 14326 solver.cpp:237] Iteration 72500, loss = 1.36622
I0523 21:15:45.934182 14326 solver.cpp:253]     Train net output #0: loss = 1.36622 (* 1 = 1.36622 loss)
I0523 21:15:45.934201 14326 sgd_solver.cpp:106] Iteration 72500, lr = 0.0045
I0523 21:15:55.038771 14326 solver.cpp:237] Iteration 72750, loss = 1.33659
I0523 21:15:55.038938 14326 solver.cpp:253]     Train net output #0: loss = 1.33659 (* 1 = 1.33659 loss)
I0523 21:15:55.038951 14326 sgd_solver.cpp:106] Iteration 72750, lr = 0.0045
I0523 21:16:04.153295 14326 solver.cpp:237] Iteration 73000, loss = 1.41368
I0523 21:16:04.153329 14326 solver.cpp:253]     Train net output #0: loss = 1.41368 (* 1 = 1.41368 loss)
I0523 21:16:04.153343 14326 sgd_solver.cpp:106] Iteration 73000, lr = 0.0045
I0523 21:16:13.271273 14326 solver.cpp:237] Iteration 73250, loss = 1.07946
I0523 21:16:13.271313 14326 solver.cpp:253]     Train net output #0: loss = 1.07946 (* 1 = 1.07946 loss)
I0523 21:16:13.271333 14326 sgd_solver.cpp:106] Iteration 73250, lr = 0.0045
I0523 21:16:43.287565 14326 solver.cpp:237] Iteration 73500, loss = 1.11891
I0523 21:16:43.287752 14326 solver.cpp:253]     Train net output #0: loss = 1.11891 (* 1 = 1.11891 loss)
I0523 21:16:43.287766 14326 sgd_solver.cpp:106] Iteration 73500, lr = 0.0045
I0523 21:16:52.403058 14326 solver.cpp:237] Iteration 73750, loss = 1.19084
I0523 21:16:52.403091 14326 solver.cpp:253]     Train net output #0: loss = 1.19084 (* 1 = 1.19084 loss)
I0523 21:16:52.403107 14326 sgd_solver.cpp:106] Iteration 73750, lr = 0.0045
I0523 21:17:01.520579 14326 solver.cpp:237] Iteration 74000, loss = 1.00502
I0523 21:17:01.520627 14326 solver.cpp:253]     Train net output #0: loss = 1.00502 (* 1 = 1.00502 loss)
I0523 21:17:01.520642 14326 sgd_solver.cpp:106] Iteration 74000, lr = 0.0045
I0523 21:17:10.636860 14326 solver.cpp:237] Iteration 74250, loss = 1.1734
I0523 21:17:10.636895 14326 solver.cpp:253]     Train net output #0: loss = 1.1734 (* 1 = 1.1734 loss)
I0523 21:17:10.636912 14326 sgd_solver.cpp:106] Iteration 74250, lr = 0.0045
I0523 21:17:19.754222 14326 solver.cpp:237] Iteration 74500, loss = 1.1223
I0523 21:17:19.754384 14326 solver.cpp:253]     Train net output #0: loss = 1.1223 (* 1 = 1.1223 loss)
I0523 21:17:19.754397 14326 sgd_solver.cpp:106] Iteration 74500, lr = 0.0045
I0523 21:17:28.858146 14326 solver.cpp:237] Iteration 74750, loss = 1.15747
I0523 21:17:28.858185 14326 solver.cpp:253]     Train net output #0: loss = 1.15747 (* 1 = 1.15747 loss)
I0523 21:17:28.858197 14326 sgd_solver.cpp:106] Iteration 74750, lr = 0.0045
I0523 21:17:37.928915 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_75000.caffemodel
I0523 21:17:38.004871 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_75000.solverstate
I0523 21:17:38.033088 14326 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 21:18:25.056237 14326 solver.cpp:409]     Test net output #0: accuracy = 0.894606
I0523 21:18:25.056442 14326 solver.cpp:409]     Test net output #1: loss = 0.332757 (* 1 = 0.332757 loss)
I0523 21:18:45.980384 14326 solver.cpp:237] Iteration 75000, loss = 1.35535
I0523 21:18:45.980437 14326 solver.cpp:253]     Train net output #0: loss = 1.35535 (* 1 = 1.35535 loss)
I0523 21:18:45.980453 14326 sgd_solver.cpp:106] Iteration 75000, lr = 0.0045
I0523 21:18:55.012383 14326 solver.cpp:237] Iteration 75250, loss = 0.861887
I0523 21:18:55.012420 14326 solver.cpp:253]     Train net output #0: loss = 0.861887 (* 1 = 0.861887 loss)
I0523 21:18:55.012434 14326 sgd_solver.cpp:106] Iteration 75250, lr = 0.0045
I0523 21:19:04.048929 14326 solver.cpp:237] Iteration 75500, loss = 1.49874
I0523 21:19:04.049100 14326 solver.cpp:253]     Train net output #0: loss = 1.49874 (* 1 = 1.49874 loss)
I0523 21:19:04.049114 14326 sgd_solver.cpp:106] Iteration 75500, lr = 0.0045
I0523 21:19:13.082615 14326 solver.cpp:237] Iteration 75750, loss = 1.0002
I0523 21:19:13.082654 14326 solver.cpp:253]     Train net output #0: loss = 1.0002 (* 1 = 1.0002 loss)
I0523 21:19:13.082675 14326 sgd_solver.cpp:106] Iteration 75750, lr = 0.0045
I0523 21:19:22.115995 14326 solver.cpp:237] Iteration 76000, loss = 1.04555
I0523 21:19:22.116029 14326 solver.cpp:253]     Train net output #0: loss = 1.04555 (* 1 = 1.04555 loss)
I0523 21:19:22.116044 14326 sgd_solver.cpp:106] Iteration 76000, lr = 0.0045
I0523 21:19:31.143350 14326 solver.cpp:237] Iteration 76250, loss = 1.24325
I0523 21:19:31.143388 14326 solver.cpp:253]     Train net output #0: loss = 1.24325 (* 1 = 1.24325 loss)
I0523 21:19:31.143406 14326 sgd_solver.cpp:106] Iteration 76250, lr = 0.0045
I0523 21:19:40.175583 14326 solver.cpp:237] Iteration 76500, loss = 1.09917
I0523 21:19:40.175747 14326 solver.cpp:253]     Train net output #0: loss = 1.09917 (* 1 = 1.09917 loss)
I0523 21:19:40.175760 14326 sgd_solver.cpp:106] Iteration 76500, lr = 0.0045
I0523 21:20:10.094257 14326 solver.cpp:237] Iteration 76750, loss = 1.14122
I0523 21:20:10.094307 14326 solver.cpp:253]     Train net output #0: loss = 1.14122 (* 1 = 1.14122 loss)
I0523 21:20:10.094321 14326 sgd_solver.cpp:106] Iteration 76750, lr = 0.0045
I0523 21:20:19.132741 14326 solver.cpp:237] Iteration 77000, loss = 0.960177
I0523 21:20:19.132917 14326 solver.cpp:253]     Train net output #0: loss = 0.960177 (* 1 = 0.960177 loss)
I0523 21:20:19.132931 14326 sgd_solver.cpp:106] Iteration 77000, lr = 0.0045
I0523 21:20:28.163810 14326 solver.cpp:237] Iteration 77250, loss = 1.50789
I0523 21:20:28.163849 14326 solver.cpp:253]     Train net output #0: loss = 1.50789 (* 1 = 1.50789 loss)
I0523 21:20:28.163867 14326 sgd_solver.cpp:106] Iteration 77250, lr = 0.0045
I0523 21:20:37.168853 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_77500.caffemodel
I0523 21:20:37.232910 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_77500.solverstate
I0523 21:20:37.270866 14326 solver.cpp:237] Iteration 77500, loss = 0.740608
I0523 21:20:37.270908 14326 solver.cpp:253]     Train net output #0: loss = 0.740608 (* 1 = 0.740608 loss)
I0523 21:20:37.270923 14326 sgd_solver.cpp:106] Iteration 77500, lr = 0.0045
I0523 21:20:46.307252 14326 solver.cpp:237] Iteration 77750, loss = 1.26272
I0523 21:20:46.307291 14326 solver.cpp:253]     Train net output #0: loss = 1.26272 (* 1 = 1.26272 loss)
I0523 21:20:46.307312 14326 sgd_solver.cpp:106] Iteration 77750, lr = 0.0045
I0523 21:20:55.347004 14326 solver.cpp:237] Iteration 78000, loss = 1.35207
I0523 21:20:55.347183 14326 solver.cpp:253]     Train net output #0: loss = 1.35207 (* 1 = 1.35207 loss)
I0523 21:20:55.347198 14326 sgd_solver.cpp:106] Iteration 78000, lr = 0.0045
I0523 21:21:04.387457 14326 solver.cpp:237] Iteration 78250, loss = 0.984351
I0523 21:21:04.387492 14326 solver.cpp:253]     Train net output #0: loss = 0.984351 (* 1 = 0.984351 loss)
I0523 21:21:04.387507 14326 sgd_solver.cpp:106] Iteration 78250, lr = 0.0045
I0523 21:21:34.288542 14326 solver.cpp:237] Iteration 78500, loss = 1.17438
I0523 21:21:34.288728 14326 solver.cpp:253]     Train net output #0: loss = 1.17438 (* 1 = 1.17438 loss)
I0523 21:21:34.288743 14326 sgd_solver.cpp:106] Iteration 78500, lr = 0.0045
I0523 21:21:43.316941 14326 solver.cpp:237] Iteration 78750, loss = 0.948163
I0523 21:21:43.316978 14326 solver.cpp:253]     Train net output #0: loss = 0.948163 (* 1 = 0.948163 loss)
I0523 21:21:43.316998 14326 sgd_solver.cpp:106] Iteration 78750, lr = 0.0045
I0523 21:21:52.348239 14326 solver.cpp:237] Iteration 79000, loss = 1.35229
I0523 21:21:52.348275 14326 solver.cpp:253]     Train net output #0: loss = 1.35229 (* 1 = 1.35229 loss)
I0523 21:21:52.348289 14326 sgd_solver.cpp:106] Iteration 79000, lr = 0.0045
I0523 21:22:01.380802 14326 solver.cpp:237] Iteration 79250, loss = 1.1086
I0523 21:22:01.380842 14326 solver.cpp:253]     Train net output #0: loss = 1.1086 (* 1 = 1.1086 loss)
I0523 21:22:01.380868 14326 sgd_solver.cpp:106] Iteration 79250, lr = 0.0045
I0523 21:22:10.416335 14326 solver.cpp:237] Iteration 79500, loss = 1.07724
I0523 21:22:10.416501 14326 solver.cpp:253]     Train net output #0: loss = 1.07724 (* 1 = 1.07724 loss)
I0523 21:22:10.416515 14326 sgd_solver.cpp:106] Iteration 79500, lr = 0.0045
I0523 21:22:19.447293 14326 solver.cpp:237] Iteration 79750, loss = 1.13212
I0523 21:22:19.447329 14326 solver.cpp:253]     Train net output #0: loss = 1.13212 (* 1 = 1.13212 loss)
I0523 21:22:19.447345 14326 sgd_solver.cpp:106] Iteration 79750, lr = 0.0045
I0523 21:22:28.442945 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_80000.caffemodel
I0523 21:22:28.505177 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_80000.solverstate
I0523 21:22:28.531463 14326 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 21:23:36.723410 14326 solver.cpp:409]     Test net output #0: accuracy = 0.897086
I0523 21:23:36.723593 14326 solver.cpp:409]     Test net output #1: loss = 0.333288 (* 1 = 0.333288 loss)
I0523 21:23:57.642945 14326 solver.cpp:237] Iteration 80000, loss = 1.10054
I0523 21:23:57.642997 14326 solver.cpp:253]     Train net output #0: loss = 1.10054 (* 1 = 1.10054 loss)
I0523 21:23:57.643013 14326 sgd_solver.cpp:106] Iteration 80000, lr = 0.0045
I0523 21:24:06.689083 14326 solver.cpp:237] Iteration 80250, loss = 1.0149
I0523 21:24:06.689126 14326 solver.cpp:253]     Train net output #0: loss = 1.0149 (* 1 = 1.0149 loss)
I0523 21:24:06.689141 14326 sgd_solver.cpp:106] Iteration 80250, lr = 0.0045
I0523 21:24:15.757658 14326 solver.cpp:237] Iteration 80500, loss = 1.26227
I0523 21:24:15.757828 14326 solver.cpp:253]     Train net output #0: loss = 1.26227 (* 1 = 1.26227 loss)
I0523 21:24:15.757841 14326 sgd_solver.cpp:106] Iteration 80500, lr = 0.0045
I0523 21:24:24.810003 14326 solver.cpp:237] Iteration 80750, loss = 1.05742
I0523 21:24:24.810036 14326 solver.cpp:253]     Train net output #0: loss = 1.05742 (* 1 = 1.05742 loss)
I0523 21:24:24.810050 14326 sgd_solver.cpp:106] Iteration 80750, lr = 0.0045
I0523 21:24:33.861227 14326 solver.cpp:237] Iteration 81000, loss = 1.46631
I0523 21:24:33.861274 14326 solver.cpp:253]     Train net output #0: loss = 1.46631 (* 1 = 1.46631 loss)
I0523 21:24:33.861287 14326 sgd_solver.cpp:106] Iteration 81000, lr = 0.0045
I0523 21:24:42.922446 14326 solver.cpp:237] Iteration 81250, loss = 1.28983
I0523 21:24:42.922482 14326 solver.cpp:253]     Train net output #0: loss = 1.28983 (* 1 = 1.28983 loss)
I0523 21:24:42.922495 14326 sgd_solver.cpp:106] Iteration 81250, lr = 0.0045
I0523 21:24:51.965744 14326 solver.cpp:237] Iteration 81500, loss = 1.13024
I0523 21:24:51.965920 14326 solver.cpp:253]     Train net output #0: loss = 1.13024 (* 1 = 1.13024 loss)
I0523 21:24:51.965934 14326 sgd_solver.cpp:106] Iteration 81500, lr = 0.0045
I0523 21:25:21.940171 14326 solver.cpp:237] Iteration 81750, loss = 0.984587
I0523 21:25:21.940220 14326 solver.cpp:253]     Train net output #0: loss = 0.984587 (* 1 = 0.984587 loss)
I0523 21:25:21.940235 14326 sgd_solver.cpp:106] Iteration 81750, lr = 0.0045
I0523 21:25:30.989380 14326 solver.cpp:237] Iteration 82000, loss = 0.870994
I0523 21:25:30.989552 14326 solver.cpp:253]     Train net output #0: loss = 0.870994 (* 1 = 0.870994 loss)
I0523 21:25:30.989564 14326 sgd_solver.cpp:106] Iteration 82000, lr = 0.0045
I0523 21:25:40.040791 14326 solver.cpp:237] Iteration 82250, loss = 1.14475
I0523 21:25:40.040827 14326 solver.cpp:253]     Train net output #0: loss = 1.14475 (* 1 = 1.14475 loss)
I0523 21:25:40.040840 14326 sgd_solver.cpp:106] Iteration 82250, lr = 0.0045
I0523 21:25:49.066561 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_82500.caffemodel
I0523 21:25:49.130224 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_82500.solverstate
I0523 21:25:49.167790 14326 solver.cpp:237] Iteration 82500, loss = 0.917425
I0523 21:25:49.167831 14326 solver.cpp:253]     Train net output #0: loss = 0.917425 (* 1 = 0.917425 loss)
I0523 21:25:49.167850 14326 sgd_solver.cpp:106] Iteration 82500, lr = 0.0045
I0523 21:25:58.219339 14326 solver.cpp:237] Iteration 82750, loss = 1.1839
I0523 21:25:58.219374 14326 solver.cpp:253]     Train net output #0: loss = 1.1839 (* 1 = 1.1839 loss)
I0523 21:25:58.219389 14326 sgd_solver.cpp:106] Iteration 82750, lr = 0.0045
I0523 21:26:07.277231 14326 solver.cpp:237] Iteration 83000, loss = 1.1339
I0523 21:26:07.277411 14326 solver.cpp:253]     Train net output #0: loss = 1.1339 (* 1 = 1.1339 loss)
I0523 21:26:07.277425 14326 sgd_solver.cpp:106] Iteration 83000, lr = 0.0045
I0523 21:26:16.336529 14326 solver.cpp:237] Iteration 83250, loss = 0.987042
I0523 21:26:16.336570 14326 solver.cpp:253]     Train net output #0: loss = 0.987042 (* 1 = 0.987042 loss)
I0523 21:26:16.336588 14326 sgd_solver.cpp:106] Iteration 83250, lr = 0.0045
I0523 21:26:46.279925 14326 solver.cpp:237] Iteration 83500, loss = 1.14768
I0523 21:26:46.280125 14326 solver.cpp:253]     Train net output #0: loss = 1.14768 (* 1 = 1.14768 loss)
I0523 21:26:46.280140 14326 sgd_solver.cpp:106] Iteration 83500, lr = 0.0045
I0523 21:26:55.328122 14326 solver.cpp:237] Iteration 83750, loss = 1.12813
I0523 21:26:55.328157 14326 solver.cpp:253]     Train net output #0: loss = 1.12813 (* 1 = 1.12813 loss)
I0523 21:26:55.328172 14326 sgd_solver.cpp:106] Iteration 83750, lr = 0.0045
I0523 21:27:04.364899 14326 solver.cpp:237] Iteration 84000, loss = 1.14502
I0523 21:27:04.364944 14326 solver.cpp:253]     Train net output #0: loss = 1.14502 (* 1 = 1.14502 loss)
I0523 21:27:04.364959 14326 sgd_solver.cpp:106] Iteration 84000, lr = 0.0045
I0523 21:27:13.423954 14326 solver.cpp:237] Iteration 84250, loss = 1.10678
I0523 21:27:13.423990 14326 solver.cpp:253]     Train net output #0: loss = 1.10678 (* 1 = 1.10678 loss)
I0523 21:27:13.424003 14326 sgd_solver.cpp:106] Iteration 84250, lr = 0.0045
I0523 21:27:22.471268 14326 solver.cpp:237] Iteration 84500, loss = 1.3565
I0523 21:27:22.471448 14326 solver.cpp:253]     Train net output #0: loss = 1.3565 (* 1 = 1.3565 loss)
I0523 21:27:22.471462 14326 sgd_solver.cpp:106] Iteration 84500, lr = 0.0045
I0523 21:27:31.519630 14326 solver.cpp:237] Iteration 84750, loss = 0.890114
I0523 21:27:31.519673 14326 solver.cpp:253]     Train net output #0: loss = 0.890114 (* 1 = 0.890114 loss)
I0523 21:27:31.519693 14326 sgd_solver.cpp:106] Iteration 84750, lr = 0.0045
I0523 21:27:40.537071 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_85000.caffemodel
I0523 21:27:40.601572 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_85000.solverstate
I0523 21:27:40.628196 14326 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 21:28:27.934149 14326 solver.cpp:409]     Test net output #0: accuracy = 0.898519
I0523 21:28:27.934340 14326 solver.cpp:409]     Test net output #1: loss = 0.340599 (* 1 = 0.340599 loss)
I0523 21:28:48.826236 14326 solver.cpp:237] Iteration 85000, loss = 1.1863
I0523 21:28:48.826292 14326 solver.cpp:253]     Train net output #0: loss = 1.1863 (* 1 = 1.1863 loss)
I0523 21:28:48.826306 14326 sgd_solver.cpp:106] Iteration 85000, lr = 0.0045
I0523 21:28:57.840297 14326 solver.cpp:237] Iteration 85250, loss = 1.44786
I0523 21:28:57.840333 14326 solver.cpp:253]     Train net output #0: loss = 1.44786 (* 1 = 1.44786 loss)
I0523 21:28:57.840348 14326 sgd_solver.cpp:106] Iteration 85250, lr = 0.0045
I0523 21:29:06.850847 14326 solver.cpp:237] Iteration 85500, loss = 1.30259
I0523 21:29:06.851032 14326 solver.cpp:253]     Train net output #0: loss = 1.30259 (* 1 = 1.30259 loss)
I0523 21:29:06.851045 14326 sgd_solver.cpp:106] Iteration 85500, lr = 0.0045
I0523 21:29:15.861980 14326 solver.cpp:237] Iteration 85750, loss = 0.960419
I0523 21:29:15.862016 14326 solver.cpp:253]     Train net output #0: loss = 0.960419 (* 1 = 0.960419 loss)
I0523 21:29:15.862030 14326 sgd_solver.cpp:106] Iteration 85750, lr = 0.0045
I0523 21:29:24.873229 14326 solver.cpp:237] Iteration 86000, loss = 1.05817
I0523 21:29:24.873265 14326 solver.cpp:253]     Train net output #0: loss = 1.05817 (* 1 = 1.05817 loss)
I0523 21:29:24.873278 14326 sgd_solver.cpp:106] Iteration 86000, lr = 0.0045
I0523 21:29:33.892683 14326 solver.cpp:237] Iteration 86250, loss = 1.26227
I0523 21:29:33.892732 14326 solver.cpp:253]     Train net output #0: loss = 1.26227 (* 1 = 1.26227 loss)
I0523 21:29:33.892746 14326 sgd_solver.cpp:106] Iteration 86250, lr = 0.0045
I0523 21:29:42.910176 14326 solver.cpp:237] Iteration 86500, loss = 0.94033
I0523 21:29:42.910344 14326 solver.cpp:253]     Train net output #0: loss = 0.94033 (* 1 = 0.94033 loss)
I0523 21:29:42.910358 14326 sgd_solver.cpp:106] Iteration 86500, lr = 0.0045
I0523 21:30:12.815371 14326 solver.cpp:237] Iteration 86750, loss = 1.01587
I0523 21:30:12.815418 14326 solver.cpp:253]     Train net output #0: loss = 1.01587 (* 1 = 1.01587 loss)
I0523 21:30:12.815433 14326 sgd_solver.cpp:106] Iteration 86750, lr = 0.0045
I0523 21:30:21.832698 14326 solver.cpp:237] Iteration 87000, loss = 0.941924
I0523 21:30:21.832887 14326 solver.cpp:253]     Train net output #0: loss = 0.941924 (* 1 = 0.941924 loss)
I0523 21:30:21.832901 14326 sgd_solver.cpp:106] Iteration 87000, lr = 0.0045
I0523 21:30:30.844432 14326 solver.cpp:237] Iteration 87250, loss = 0.962988
I0523 21:30:30.844467 14326 solver.cpp:253]     Train net output #0: loss = 0.962988 (* 1 = 0.962988 loss)
I0523 21:30:30.844483 14326 sgd_solver.cpp:106] Iteration 87250, lr = 0.0045
I0523 21:30:39.821370 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_87500.caffemodel
I0523 21:30:39.885980 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_87500.solverstate
I0523 21:30:39.925557 14326 solver.cpp:237] Iteration 87500, loss = 1.22796
I0523 21:30:39.925603 14326 solver.cpp:253]     Train net output #0: loss = 1.22796 (* 1 = 1.22796 loss)
I0523 21:30:39.925621 14326 sgd_solver.cpp:106] Iteration 87500, lr = 0.0045
I0523 21:30:48.943064 14326 solver.cpp:237] Iteration 87750, loss = 1.27165
I0523 21:30:48.943104 14326 solver.cpp:253]     Train net output #0: loss = 1.27165 (* 1 = 1.27165 loss)
I0523 21:30:48.943123 14326 sgd_solver.cpp:106] Iteration 87750, lr = 0.0045
I0523 21:30:57.958050 14326 solver.cpp:237] Iteration 88000, loss = 1.44049
I0523 21:30:57.958230 14326 solver.cpp:253]     Train net output #0: loss = 1.44049 (* 1 = 1.44049 loss)
I0523 21:30:57.958242 14326 sgd_solver.cpp:106] Iteration 88000, lr = 0.0045
I0523 21:31:06.974225 14326 solver.cpp:237] Iteration 88250, loss = 1.4007
I0523 21:31:06.974258 14326 solver.cpp:253]     Train net output #0: loss = 1.4007 (* 1 = 1.4007 loss)
I0523 21:31:06.974274 14326 sgd_solver.cpp:106] Iteration 88250, lr = 0.0045
I0523 21:31:36.871512 14326 solver.cpp:237] Iteration 88500, loss = 1.19528
I0523 21:31:36.871701 14326 solver.cpp:253]     Train net output #0: loss = 1.19528 (* 1 = 1.19528 loss)
I0523 21:31:36.871716 14326 sgd_solver.cpp:106] Iteration 88500, lr = 0.0045
I0523 21:31:45.886494 14326 solver.cpp:237] Iteration 88750, loss = 1.08093
I0523 21:31:45.886529 14326 solver.cpp:253]     Train net output #0: loss = 1.08093 (* 1 = 1.08093 loss)
I0523 21:31:45.886545 14326 sgd_solver.cpp:106] Iteration 88750, lr = 0.0045
I0523 21:31:54.901808 14326 solver.cpp:237] Iteration 89000, loss = 1.2115
I0523 21:31:54.901844 14326 solver.cpp:253]     Train net output #0: loss = 1.2115 (* 1 = 1.2115 loss)
I0523 21:31:54.901857 14326 sgd_solver.cpp:106] Iteration 89000, lr = 0.0045
I0523 21:32:03.920450 14326 solver.cpp:237] Iteration 89250, loss = 1.06716
I0523 21:32:03.920495 14326 solver.cpp:253]     Train net output #0: loss = 1.06716 (* 1 = 1.06716 loss)
I0523 21:32:03.920511 14326 sgd_solver.cpp:106] Iteration 89250, lr = 0.0045
I0523 21:32:12.937463 14326 solver.cpp:237] Iteration 89500, loss = 1.06011
I0523 21:32:12.937631 14326 solver.cpp:253]     Train net output #0: loss = 1.06011 (* 1 = 1.06011 loss)
I0523 21:32:12.937645 14326 sgd_solver.cpp:106] Iteration 89500, lr = 0.0045
I0523 21:32:21.948730 14326 solver.cpp:237] Iteration 89750, loss = 1.1828
I0523 21:32:21.948765 14326 solver.cpp:253]     Train net output #0: loss = 1.1828 (* 1 = 1.1828 loss)
I0523 21:32:21.948779 14326 sgd_solver.cpp:106] Iteration 89750, lr = 0.0045
I0523 21:32:30.936408 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_90000.caffemodel
I0523 21:32:31.002532 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_90000.solverstate
I0523 21:32:31.031201 14326 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 21:33:39.227937 14326 solver.cpp:409]     Test net output #0: accuracy = 0.900325
I0523 21:33:39.228127 14326 solver.cpp:409]     Test net output #1: loss = 0.308754 (* 1 = 0.308754 loss)
I0523 21:34:00.118288 14326 solver.cpp:237] Iteration 90000, loss = 1.1178
I0523 21:34:00.118341 14326 solver.cpp:253]     Train net output #0: loss = 1.1178 (* 1 = 1.1178 loss)
I0523 21:34:00.118356 14326 sgd_solver.cpp:106] Iteration 90000, lr = 0.0045
I0523 21:34:09.210161 14326 solver.cpp:237] Iteration 90250, loss = 0.820418
I0523 21:34:09.210208 14326 solver.cpp:253]     Train net output #0: loss = 0.820418 (* 1 = 0.820418 loss)
I0523 21:34:09.210222 14326 sgd_solver.cpp:106] Iteration 90250, lr = 0.0045
I0523 21:34:18.315920 14326 solver.cpp:237] Iteration 90500, loss = 1.32259
I0523 21:34:18.316093 14326 solver.cpp:253]     Train net output #0: loss = 1.32259 (* 1 = 1.32259 loss)
I0523 21:34:18.316107 14326 sgd_solver.cpp:106] Iteration 90500, lr = 0.0045
I0523 21:34:27.417496 14326 solver.cpp:237] Iteration 90750, loss = 1.02132
I0523 21:34:27.417531 14326 solver.cpp:253]     Train net output #0: loss = 1.02132 (* 1 = 1.02132 loss)
I0523 21:34:27.417546 14326 sgd_solver.cpp:106] Iteration 90750, lr = 0.0045
I0523 21:34:36.510908 14326 solver.cpp:237] Iteration 91000, loss = 1.14833
I0523 21:34:36.510958 14326 solver.cpp:253]     Train net output #0: loss = 1.14833 (* 1 = 1.14833 loss)
I0523 21:34:36.510972 14326 sgd_solver.cpp:106] Iteration 91000, lr = 0.0045
I0523 21:34:45.616616 14326 solver.cpp:237] Iteration 91250, loss = 1.10688
I0523 21:34:45.616649 14326 solver.cpp:253]     Train net output #0: loss = 1.10688 (* 1 = 1.10688 loss)
I0523 21:34:45.616665 14326 sgd_solver.cpp:106] Iteration 91250, lr = 0.0045
I0523 21:34:54.700403 14326 solver.cpp:237] Iteration 91500, loss = 0.886769
I0523 21:34:54.700595 14326 solver.cpp:253]     Train net output #0: loss = 0.886769 (* 1 = 0.886769 loss)
I0523 21:34:54.700610 14326 sgd_solver.cpp:106] Iteration 91500, lr = 0.0045
I0523 21:35:24.689749 14326 solver.cpp:237] Iteration 91750, loss = 1.3053
I0523 21:35:24.689800 14326 solver.cpp:253]     Train net output #0: loss = 1.3053 (* 1 = 1.3053 loss)
I0523 21:35:24.689815 14326 sgd_solver.cpp:106] Iteration 91750, lr = 0.0045
I0523 21:35:33.791159 14326 solver.cpp:237] Iteration 92000, loss = 0.909536
I0523 21:35:33.791344 14326 solver.cpp:253]     Train net output #0: loss = 0.909536 (* 1 = 0.909536 loss)
I0523 21:35:33.791358 14326 sgd_solver.cpp:106] Iteration 92000, lr = 0.0045
I0523 21:35:42.894745 14326 solver.cpp:237] Iteration 92250, loss = 1.09083
I0523 21:35:42.894780 14326 solver.cpp:253]     Train net output #0: loss = 1.09083 (* 1 = 1.09083 loss)
I0523 21:35:42.894795 14326 sgd_solver.cpp:106] Iteration 92250, lr = 0.0045
I0523 21:35:51.959645 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_92500.caffemodel
I0523 21:35:52.022333 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_92500.solverstate
I0523 21:35:52.060032 14326 solver.cpp:237] Iteration 92500, loss = 1.05746
I0523 21:35:52.060077 14326 solver.cpp:253]     Train net output #0: loss = 1.05746 (* 1 = 1.05746 loss)
I0523 21:35:52.060093 14326 sgd_solver.cpp:106] Iteration 92500, lr = 0.0045
I0523 21:36:01.171172 14326 solver.cpp:237] Iteration 92750, loss = 1.17079
I0523 21:36:01.171210 14326 solver.cpp:253]     Train net output #0: loss = 1.17079 (* 1 = 1.17079 loss)
I0523 21:36:01.171223 14326 sgd_solver.cpp:106] Iteration 92750, lr = 0.0045
I0523 21:36:10.262766 14326 solver.cpp:237] Iteration 93000, loss = 1.22506
I0523 21:36:10.262954 14326 solver.cpp:253]     Train net output #0: loss = 1.22506 (* 1 = 1.22506 loss)
I0523 21:36:10.262969 14326 sgd_solver.cpp:106] Iteration 93000, lr = 0.0045
I0523 21:36:19.357717 14326 solver.cpp:237] Iteration 93250, loss = 1.10025
I0523 21:36:19.357751 14326 solver.cpp:253]     Train net output #0: loss = 1.10025 (* 1 = 1.10025 loss)
I0523 21:36:19.357766 14326 sgd_solver.cpp:106] Iteration 93250, lr = 0.0045
I0523 21:36:49.349364 14326 solver.cpp:237] Iteration 93500, loss = 1.10324
I0523 21:36:49.349558 14326 solver.cpp:253]     Train net output #0: loss = 1.10324 (* 1 = 1.10324 loss)
I0523 21:36:49.349572 14326 sgd_solver.cpp:106] Iteration 93500, lr = 0.0045
I0523 21:36:58.446579 14326 solver.cpp:237] Iteration 93750, loss = 0.930071
I0523 21:36:58.446616 14326 solver.cpp:253]     Train net output #0: loss = 0.930071 (* 1 = 0.930071 loss)
I0523 21:36:58.446630 14326 sgd_solver.cpp:106] Iteration 93750, lr = 0.0045
I0523 21:37:07.541956 14326 solver.cpp:237] Iteration 94000, loss = 1.31491
I0523 21:37:07.541996 14326 solver.cpp:253]     Train net output #0: loss = 1.31491 (* 1 = 1.31491 loss)
I0523 21:37:07.542013 14326 sgd_solver.cpp:106] Iteration 94000, lr = 0.0045
I0523 21:37:16.642691 14326 solver.cpp:237] Iteration 94250, loss = 0.93923
I0523 21:37:16.642727 14326 solver.cpp:253]     Train net output #0: loss = 0.93923 (* 1 = 0.93923 loss)
I0523 21:37:16.642740 14326 sgd_solver.cpp:106] Iteration 94250, lr = 0.0045
I0523 21:37:25.736433 14326 solver.cpp:237] Iteration 94500, loss = 1.30129
I0523 21:37:25.736629 14326 solver.cpp:253]     Train net output #0: loss = 1.30129 (* 1 = 1.30129 loss)
I0523 21:37:25.736644 14326 sgd_solver.cpp:106] Iteration 94500, lr = 0.0045
I0523 21:37:34.827311 14326 solver.cpp:237] Iteration 94750, loss = 1.02937
I0523 21:37:34.827345 14326 solver.cpp:253]     Train net output #0: loss = 1.02937 (* 1 = 1.02937 loss)
I0523 21:37:34.827360 14326 sgd_solver.cpp:106] Iteration 94750, lr = 0.0045
I0523 21:37:43.875850 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_95000.caffemodel
I0523 21:37:43.950003 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_95000.solverstate
I0523 21:37:43.976637 14326 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 21:38:30.964891 14326 solver.cpp:409]     Test net output #0: accuracy = 0.900898
I0523 21:38:30.965087 14326 solver.cpp:409]     Test net output #1: loss = 0.309117 (* 1 = 0.309117 loss)
I0523 21:38:51.889283 14326 solver.cpp:237] Iteration 95000, loss = 1.24816
I0523 21:38:51.889336 14326 solver.cpp:253]     Train net output #0: loss = 1.24816 (* 1 = 1.24816 loss)
I0523 21:38:51.889351 14326 sgd_solver.cpp:106] Iteration 95000, lr = 0.0045
I0523 21:39:00.955456 14326 solver.cpp:237] Iteration 95250, loss = 1.18421
I0523 21:39:00.955492 14326 solver.cpp:253]     Train net output #0: loss = 1.18421 (* 1 = 1.18421 loss)
I0523 21:39:00.955507 14326 sgd_solver.cpp:106] Iteration 95250, lr = 0.0045
I0523 21:39:10.027876 14326 solver.cpp:237] Iteration 95500, loss = 0.878242
I0523 21:39:10.028062 14326 solver.cpp:253]     Train net output #0: loss = 0.878242 (* 1 = 0.878242 loss)
I0523 21:39:10.028076 14326 sgd_solver.cpp:106] Iteration 95500, lr = 0.0045
I0523 21:39:19.106070 14326 solver.cpp:237] Iteration 95750, loss = 1.00014
I0523 21:39:19.106104 14326 solver.cpp:253]     Train net output #0: loss = 1.00014 (* 1 = 1.00014 loss)
I0523 21:39:19.106118 14326 sgd_solver.cpp:106] Iteration 95750, lr = 0.0045
I0523 21:39:28.178601 14326 solver.cpp:237] Iteration 96000, loss = 0.996216
I0523 21:39:28.178637 14326 solver.cpp:253]     Train net output #0: loss = 0.996216 (* 1 = 0.996216 loss)
I0523 21:39:28.178652 14326 sgd_solver.cpp:106] Iteration 96000, lr = 0.0045
I0523 21:39:37.251152 14326 solver.cpp:237] Iteration 96250, loss = 0.959599
I0523 21:39:37.251190 14326 solver.cpp:253]     Train net output #0: loss = 0.959599 (* 1 = 0.959599 loss)
I0523 21:39:37.251210 14326 sgd_solver.cpp:106] Iteration 96250, lr = 0.0045
I0523 21:39:46.322100 14326 solver.cpp:237] Iteration 96500, loss = 1.1421
I0523 21:39:46.322271 14326 solver.cpp:253]     Train net output #0: loss = 1.1421 (* 1 = 1.1421 loss)
I0523 21:39:46.322284 14326 sgd_solver.cpp:106] Iteration 96500, lr = 0.0045
I0523 21:40:16.306128 14326 solver.cpp:237] Iteration 96750, loss = 0.992481
I0523 21:40:16.306181 14326 solver.cpp:253]     Train net output #0: loss = 0.992481 (* 1 = 0.992481 loss)
I0523 21:40:16.306196 14326 sgd_solver.cpp:106] Iteration 96750, lr = 0.0045
I0523 21:40:25.373486 14326 solver.cpp:237] Iteration 97000, loss = 1.29105
I0523 21:40:25.373669 14326 solver.cpp:253]     Train net output #0: loss = 1.29105 (* 1 = 1.29105 loss)
I0523 21:40:25.373683 14326 sgd_solver.cpp:106] Iteration 97000, lr = 0.0045
I0523 21:40:34.439754 14326 solver.cpp:237] Iteration 97250, loss = 1.11069
I0523 21:40:34.439788 14326 solver.cpp:253]     Train net output #0: loss = 1.11069 (* 1 = 1.11069 loss)
I0523 21:40:34.439805 14326 sgd_solver.cpp:106] Iteration 97250, lr = 0.0045
I0523 21:40:43.477170 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_97500.caffemodel
I0523 21:40:43.540809 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_97500.solverstate
I0523 21:40:43.578222 14326 solver.cpp:237] Iteration 97500, loss = 1.53218
I0523 21:40:43.578263 14326 solver.cpp:253]     Train net output #0: loss = 1.53218 (* 1 = 1.53218 loss)
I0523 21:40:43.578282 14326 sgd_solver.cpp:106] Iteration 97500, lr = 0.0045
I0523 21:40:52.650521 14326 solver.cpp:237] Iteration 97750, loss = 0.91479
I0523 21:40:52.650573 14326 solver.cpp:253]     Train net output #0: loss = 0.91479 (* 1 = 0.91479 loss)
I0523 21:40:52.650586 14326 sgd_solver.cpp:106] Iteration 97750, lr = 0.0045
I0523 21:41:01.726168 14326 solver.cpp:237] Iteration 98000, loss = 1.43547
I0523 21:41:01.726356 14326 solver.cpp:253]     Train net output #0: loss = 1.43547 (* 1 = 1.43547 loss)
I0523 21:41:01.726369 14326 sgd_solver.cpp:106] Iteration 98000, lr = 0.0045
I0523 21:41:10.799522 14326 solver.cpp:237] Iteration 98250, loss = 1.03245
I0523 21:41:10.799569 14326 solver.cpp:253]     Train net output #0: loss = 1.03245 (* 1 = 1.03245 loss)
I0523 21:41:10.799583 14326 sgd_solver.cpp:106] Iteration 98250, lr = 0.0045
I0523 21:41:40.786269 14326 solver.cpp:237] Iteration 98500, loss = 1.10816
I0523 21:41:40.786474 14326 solver.cpp:253]     Train net output #0: loss = 1.10816 (* 1 = 1.10816 loss)
I0523 21:41:40.786489 14326 sgd_solver.cpp:106] Iteration 98500, lr = 0.0045
I0523 21:41:49.862375 14326 solver.cpp:237] Iteration 98750, loss = 1.13508
I0523 21:41:49.862408 14326 solver.cpp:253]     Train net output #0: loss = 1.13508 (* 1 = 1.13508 loss)
I0523 21:41:49.862423 14326 sgd_solver.cpp:106] Iteration 98750, lr = 0.0045
I0523 21:41:58.937085 14326 solver.cpp:237] Iteration 99000, loss = 1.32659
I0523 21:41:58.937121 14326 solver.cpp:253]     Train net output #0: loss = 1.32659 (* 1 = 1.32659 loss)
I0523 21:41:58.937135 14326 sgd_solver.cpp:106] Iteration 99000, lr = 0.0045
I0523 21:42:08.012048 14326 solver.cpp:237] Iteration 99250, loss = 1.40008
I0523 21:42:08.012091 14326 solver.cpp:253]     Train net output #0: loss = 1.40008 (* 1 = 1.40008 loss)
I0523 21:42:08.012105 14326 sgd_solver.cpp:106] Iteration 99250, lr = 0.0045
I0523 21:42:17.078999 14326 solver.cpp:237] Iteration 99500, loss = 0.964774
I0523 21:42:17.079171 14326 solver.cpp:253]     Train net output #0: loss = 0.964774 (* 1 = 0.964774 loss)
I0523 21:42:17.079185 14326 sgd_solver.cpp:106] Iteration 99500, lr = 0.0045
I0523 21:42:26.146828 14326 solver.cpp:237] Iteration 99750, loss = 1.23647
I0523 21:42:26.146868 14326 solver.cpp:253]     Train net output #0: loss = 1.23647 (* 1 = 1.23647 loss)
I0523 21:42:26.146888 14326 sgd_solver.cpp:106] Iteration 99750, lr = 0.0045
I0523 21:42:35.190537 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_100000.caffemodel
I0523 21:42:35.254832 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_100000.solverstate
I0523 21:42:35.281754 14326 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 21:43:43.484046 14326 solver.cpp:409]     Test net output #0: accuracy = 0.900318
I0523 21:43:43.484246 14326 solver.cpp:409]     Test net output #1: loss = 0.319645 (* 1 = 0.319645 loss)
I0523 21:44:04.392716 14326 solver.cpp:237] Iteration 100000, loss = 1.1376
I0523 21:44:04.392768 14326 solver.cpp:253]     Train net output #0: loss = 1.1376 (* 1 = 1.1376 loss)
I0523 21:44:04.392783 14326 sgd_solver.cpp:106] Iteration 100000, lr = 0.0045
I0523 21:44:13.506939 14326 solver.cpp:237] Iteration 100250, loss = 0.89967
I0523 21:44:13.507124 14326 solver.cpp:253]     Train net output #0: loss = 0.89967 (* 1 = 0.89967 loss)
I0523 21:44:13.507138 14326 sgd_solver.cpp:106] Iteration 100250, lr = 0.0045
I0523 21:44:22.624722 14326 solver.cpp:237] Iteration 100500, loss = 1.59059
I0523 21:44:22.624757 14326 solver.cpp:253]     Train net output #0: loss = 1.59059 (* 1 = 1.59059 loss)
I0523 21:44:22.624773 14326 sgd_solver.cpp:106] Iteration 100500, lr = 0.0045
I0523 21:44:31.743185 14326 solver.cpp:237] Iteration 100750, loss = 1.35751
I0523 21:44:31.743226 14326 solver.cpp:253]     Train net output #0: loss = 1.35751 (* 1 = 1.35751 loss)
I0523 21:44:31.743245 14326 sgd_solver.cpp:106] Iteration 100750, lr = 0.0045
I0523 21:44:40.863410 14326 solver.cpp:237] Iteration 101000, loss = 1.03759
I0523 21:44:40.863446 14326 solver.cpp:253]     Train net output #0: loss = 1.03759 (* 1 = 1.03759 loss)
I0523 21:44:40.863461 14326 sgd_solver.cpp:106] Iteration 101000, lr = 0.0045
I0523 21:44:49.979240 14326 solver.cpp:237] Iteration 101250, loss = 1.31905
I0523 21:44:49.979423 14326 solver.cpp:253]     Train net output #0: loss = 1.31905 (* 1 = 1.31905 loss)
I0523 21:44:49.979436 14326 sgd_solver.cpp:106] Iteration 101250, lr = 0.0045
I0523 21:44:59.097354 14326 solver.cpp:237] Iteration 101500, loss = 1.51542
I0523 21:44:59.097393 14326 solver.cpp:253]     Train net output #0: loss = 1.51542 (* 1 = 1.51542 loss)
I0523 21:44:59.097414 14326 sgd_solver.cpp:106] Iteration 101500, lr = 0.0045
I0523 21:45:29.139732 14326 solver.cpp:237] Iteration 101750, loss = 1.13328
I0523 21:45:29.139930 14326 solver.cpp:253]     Train net output #0: loss = 1.13328 (* 1 = 1.13328 loss)
I0523 21:45:29.139945 14326 sgd_solver.cpp:106] Iteration 101750, lr = 0.0045
I0523 21:45:38.254019 14326 solver.cpp:237] Iteration 102000, loss = 1.15452
I0523 21:45:38.254053 14326 solver.cpp:253]     Train net output #0: loss = 1.15452 (* 1 = 1.15452 loss)
I0523 21:45:38.254068 14326 sgd_solver.cpp:106] Iteration 102000, lr = 0.0045
I0523 21:45:47.367900 14326 solver.cpp:237] Iteration 102250, loss = 1.43323
I0523 21:45:47.367946 14326 solver.cpp:253]     Train net output #0: loss = 1.43323 (* 1 = 1.43323 loss)
I0523 21:45:47.367961 14326 sgd_solver.cpp:106] Iteration 102250, lr = 0.0045
I0523 21:45:56.452574 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_102500.caffemodel
I0523 21:45:56.515204 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_102500.solverstate
I0523 21:45:56.552147 14326 solver.cpp:237] Iteration 102500, loss = 0.995024
I0523 21:45:56.552192 14326 solver.cpp:253]     Train net output #0: loss = 0.995024 (* 1 = 0.995024 loss)
I0523 21:45:56.552209 14326 sgd_solver.cpp:106] Iteration 102500, lr = 0.0045
I0523 21:46:05.664942 14326 solver.cpp:237] Iteration 102750, loss = 1.25496
I0523 21:46:05.665122 14326 solver.cpp:253]     Train net output #0: loss = 1.25496 (* 1 = 1.25496 loss)
I0523 21:46:05.665134 14326 sgd_solver.cpp:106] Iteration 102750, lr = 0.0045
I0523 21:46:14.777637 14326 solver.cpp:237] Iteration 103000, loss = 1.20009
I0523 21:46:14.777679 14326 solver.cpp:253]     Train net output #0: loss = 1.20009 (* 1 = 1.20009 loss)
I0523 21:46:14.777695 14326 sgd_solver.cpp:106] Iteration 103000, lr = 0.0045
I0523 21:46:23.896329 14326 solver.cpp:237] Iteration 103250, loss = 1.05715
I0523 21:46:23.896364 14326 solver.cpp:253]     Train net output #0: loss = 1.05715 (* 1 = 1.05715 loss)
I0523 21:46:23.896378 14326 sgd_solver.cpp:106] Iteration 103250, lr = 0.0045
I0523 21:46:53.919862 14326 solver.cpp:237] Iteration 103500, loss = 1.02044
I0523 21:46:53.920054 14326 solver.cpp:253]     Train net output #0: loss = 1.02044 (* 1 = 1.02044 loss)
I0523 21:46:53.920068 14326 sgd_solver.cpp:106] Iteration 103500, lr = 0.0045
I0523 21:47:03.039265 14326 solver.cpp:237] Iteration 103750, loss = 1.007
I0523 21:47:03.039312 14326 solver.cpp:253]     Train net output #0: loss = 1.007 (* 1 = 1.007 loss)
I0523 21:47:03.039325 14326 sgd_solver.cpp:106] Iteration 103750, lr = 0.0045
I0523 21:47:12.147150 14326 solver.cpp:237] Iteration 104000, loss = 1.03963
I0523 21:47:12.147186 14326 solver.cpp:253]     Train net output #0: loss = 1.03963 (* 1 = 1.03963 loss)
I0523 21:47:12.147198 14326 sgd_solver.cpp:106] Iteration 104000, lr = 0.0045
I0523 21:47:21.258467 14326 solver.cpp:237] Iteration 104250, loss = 1.19429
I0523 21:47:21.258503 14326 solver.cpp:253]     Train net output #0: loss = 1.19429 (* 1 = 1.19429 loss)
I0523 21:47:21.258517 14326 sgd_solver.cpp:106] Iteration 104250, lr = 0.0045
I0523 21:47:30.381091 14326 solver.cpp:237] Iteration 104500, loss = 1.16083
I0523 21:47:30.381286 14326 solver.cpp:253]     Train net output #0: loss = 1.16083 (* 1 = 1.16083 loss)
I0523 21:47:30.381300 14326 sgd_solver.cpp:106] Iteration 104500, lr = 0.0045
I0523 21:47:39.488935 14326 solver.cpp:237] Iteration 104750, loss = 1.0916
I0523 21:47:39.488970 14326 solver.cpp:253]     Train net output #0: loss = 1.0916 (* 1 = 1.0916 loss)
I0523 21:47:39.488986 14326 sgd_solver.cpp:106] Iteration 104750, lr = 0.0045
I0523 21:47:48.568106 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_105000.caffemodel
I0523 21:47:48.632333 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_105000.solverstate
I0523 21:47:48.658440 14326 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 21:48:35.948665 14326 solver.cpp:409]     Test net output #0: accuracy = 0.899285
I0523 21:48:35.948865 14326 solver.cpp:409]     Test net output #1: loss = 0.314829 (* 1 = 0.314829 loss)
I0523 21:48:56.883683 14326 solver.cpp:237] Iteration 105000, loss = 1.08761
I0523 21:48:56.883736 14326 solver.cpp:253]     Train net output #0: loss = 1.08761 (* 1 = 1.08761 loss)
I0523 21:48:56.883751 14326 sgd_solver.cpp:106] Iteration 105000, lr = 0.0045
I0523 21:49:05.914078 14326 solver.cpp:237] Iteration 105250, loss = 1.15245
I0523 21:49:05.914120 14326 solver.cpp:253]     Train net output #0: loss = 1.15245 (* 1 = 1.15245 loss)
I0523 21:49:05.914139 14326 sgd_solver.cpp:106] Iteration 105250, lr = 0.0045
I0523 21:49:14.949520 14326 solver.cpp:237] Iteration 105500, loss = 0.932833
I0523 21:49:14.949699 14326 solver.cpp:253]     Train net output #0: loss = 0.932833 (* 1 = 0.932833 loss)
I0523 21:49:14.949714 14326 sgd_solver.cpp:106] Iteration 105500, lr = 0.0045
I0523 21:49:23.984042 14326 solver.cpp:237] Iteration 105750, loss = 1.06745
I0523 21:49:23.984077 14326 solver.cpp:253]     Train net output #0: loss = 1.06745 (* 1 = 1.06745 loss)
I0523 21:49:23.984093 14326 sgd_solver.cpp:106] Iteration 105750, lr = 0.0045
I0523 21:49:33.019914 14326 solver.cpp:237] Iteration 106000, loss = 1.15553
I0523 21:49:33.019961 14326 solver.cpp:253]     Train net output #0: loss = 1.15553 (* 1 = 1.15553 loss)
I0523 21:49:33.019976 14326 sgd_solver.cpp:106] Iteration 106000, lr = 0.0045
I0523 21:49:42.055364 14326 solver.cpp:237] Iteration 106250, loss = 1.03795
I0523 21:49:42.055400 14326 solver.cpp:253]     Train net output #0: loss = 1.03795 (* 1 = 1.03795 loss)
I0523 21:49:42.055413 14326 sgd_solver.cpp:106] Iteration 106250, lr = 0.0045
I0523 21:49:51.088860 14326 solver.cpp:237] Iteration 106500, loss = 1.3284
I0523 21:49:51.089035 14326 solver.cpp:253]     Train net output #0: loss = 1.3284 (* 1 = 1.3284 loss)
I0523 21:49:51.089049 14326 sgd_solver.cpp:106] Iteration 106500, lr = 0.0045
I0523 21:50:21.035663 14326 solver.cpp:237] Iteration 106750, loss = 1.17318
I0523 21:50:21.035713 14326 solver.cpp:253]     Train net output #0: loss = 1.17318 (* 1 = 1.17318 loss)
I0523 21:50:21.035729 14326 sgd_solver.cpp:106] Iteration 106750, lr = 0.0045
I0523 21:50:30.061092 14326 solver.cpp:237] Iteration 107000, loss = 0.97693
I0523 21:50:30.061266 14326 solver.cpp:253]     Train net output #0: loss = 0.97693 (* 1 = 0.97693 loss)
I0523 21:50:30.061280 14326 sgd_solver.cpp:106] Iteration 107000, lr = 0.0045
I0523 21:50:39.091923 14326 solver.cpp:237] Iteration 107250, loss = 1.25285
I0523 21:50:39.091958 14326 solver.cpp:253]     Train net output #0: loss = 1.25285 (* 1 = 1.25285 loss)
I0523 21:50:39.091974 14326 sgd_solver.cpp:106] Iteration 107250, lr = 0.0045
I0523 21:50:48.094239 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_107500.caffemodel
I0523 21:50:48.157414 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_107500.solverstate
I0523 21:50:48.194628 14326 solver.cpp:237] Iteration 107500, loss = 1.02911
I0523 21:50:48.194666 14326 solver.cpp:253]     Train net output #0: loss = 1.02911 (* 1 = 1.02911 loss)
I0523 21:50:48.194681 14326 sgd_solver.cpp:106] Iteration 107500, lr = 0.0045
I0523 21:50:57.230603 14326 solver.cpp:237] Iteration 107750, loss = 1.10373
I0523 21:50:57.230638 14326 solver.cpp:253]     Train net output #0: loss = 1.10373 (* 1 = 1.10373 loss)
I0523 21:50:57.230653 14326 sgd_solver.cpp:106] Iteration 107750, lr = 0.0045
I0523 21:51:06.267789 14326 solver.cpp:237] Iteration 108000, loss = 0.984436
I0523 21:51:06.267979 14326 solver.cpp:253]     Train net output #0: loss = 0.984436 (* 1 = 0.984436 loss)
I0523 21:51:06.267993 14326 sgd_solver.cpp:106] Iteration 108000, lr = 0.0045
I0523 21:51:15.302196 14326 solver.cpp:237] Iteration 108250, loss = 1.33532
I0523 21:51:15.302242 14326 solver.cpp:253]     Train net output #0: loss = 1.33532 (* 1 = 1.33532 loss)
I0523 21:51:15.302258 14326 sgd_solver.cpp:106] Iteration 108250, lr = 0.0045
I0523 21:51:45.230336 14326 solver.cpp:237] Iteration 108500, loss = 1.15547
I0523 21:51:45.230535 14326 solver.cpp:253]     Train net output #0: loss = 1.15547 (* 1 = 1.15547 loss)
I0523 21:51:45.230548 14326 sgd_solver.cpp:106] Iteration 108500, lr = 0.0045
I0523 21:51:54.262171 14326 solver.cpp:237] Iteration 108750, loss = 1.00772
I0523 21:51:54.262207 14326 solver.cpp:253]     Train net output #0: loss = 1.00772 (* 1 = 1.00772 loss)
I0523 21:51:54.262222 14326 sgd_solver.cpp:106] Iteration 108750, lr = 0.0045
I0523 21:52:03.289150 14326 solver.cpp:237] Iteration 109000, loss = 0.976738
I0523 21:52:03.289201 14326 solver.cpp:253]     Train net output #0: loss = 0.976738 (* 1 = 0.976738 loss)
I0523 21:52:03.289217 14326 sgd_solver.cpp:106] Iteration 109000, lr = 0.0045
I0523 21:52:12.319051 14326 solver.cpp:237] Iteration 109250, loss = 1.24559
I0523 21:52:12.319087 14326 solver.cpp:253]     Train net output #0: loss = 1.24559 (* 1 = 1.24559 loss)
I0523 21:52:12.319102 14326 sgd_solver.cpp:106] Iteration 109250, lr = 0.0045
I0523 21:52:21.354027 14326 solver.cpp:237] Iteration 109500, loss = 1.1658
I0523 21:52:21.354207 14326 solver.cpp:253]     Train net output #0: loss = 1.1658 (* 1 = 1.1658 loss)
I0523 21:52:21.354219 14326 sgd_solver.cpp:106] Iteration 109500, lr = 0.0045
I0523 21:52:30.390889 14326 solver.cpp:237] Iteration 109750, loss = 1.22553
I0523 21:52:30.390930 14326 solver.cpp:253]     Train net output #0: loss = 1.22553 (* 1 = 1.22553 loss)
I0523 21:52:30.390949 14326 sgd_solver.cpp:106] Iteration 109750, lr = 0.0045
I0523 21:52:39.396272 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_110000.caffemodel
I0523 21:52:39.465211 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_110000.solverstate
I0523 21:52:39.491098 14326 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 21:53:47.654481 14326 solver.cpp:409]     Test net output #0: accuracy = 0.901292
I0523 21:53:47.654676 14326 solver.cpp:409]     Test net output #1: loss = 0.320037 (* 1 = 0.320037 loss)
I0523 21:54:08.561965 14326 solver.cpp:237] Iteration 110000, loss = 1.19936
I0523 21:54:08.562018 14326 solver.cpp:253]     Train net output #0: loss = 1.19936 (* 1 = 1.19936 loss)
I0523 21:54:08.562033 14326 sgd_solver.cpp:106] Iteration 110000, lr = 0.0045
I0523 21:54:17.611634 14326 solver.cpp:237] Iteration 110250, loss = 1.00557
I0523 21:54:17.611670 14326 solver.cpp:253]     Train net output #0: loss = 1.00557 (* 1 = 1.00557 loss)
I0523 21:54:17.611685 14326 sgd_solver.cpp:106] Iteration 110250, lr = 0.0045
I0523 21:54:26.673048 14326 solver.cpp:237] Iteration 110500, loss = 1.17853
I0523 21:54:26.673238 14326 solver.cpp:253]     Train net output #0: loss = 1.17853 (* 1 = 1.17853 loss)
I0523 21:54:26.673251 14326 sgd_solver.cpp:106] Iteration 110500, lr = 0.0045
I0523 21:54:35.740447 14326 solver.cpp:237] Iteration 110750, loss = 1.07905
I0523 21:54:35.740490 14326 solver.cpp:253]     Train net output #0: loss = 1.07905 (* 1 = 1.07905 loss)
I0523 21:54:35.740509 14326 sgd_solver.cpp:106] Iteration 110750, lr = 0.0045
I0523 21:54:44.784384 14326 solver.cpp:237] Iteration 111000, loss = 1.1067
I0523 21:54:44.784418 14326 solver.cpp:253]     Train net output #0: loss = 1.1067 (* 1 = 1.1067 loss)
I0523 21:54:44.784432 14326 sgd_solver.cpp:106] Iteration 111000, lr = 0.0045
I0523 21:54:53.844717 14326 solver.cpp:237] Iteration 111250, loss = 1.08725
I0523 21:54:53.844750 14326 solver.cpp:253]     Train net output #0: loss = 1.08725 (* 1 = 1.08725 loss)
I0523 21:54:53.844765 14326 sgd_solver.cpp:106] Iteration 111250, lr = 0.0045
I0523 21:55:02.906970 14326 solver.cpp:237] Iteration 111500, loss = 0.935769
I0523 21:55:02.907161 14326 solver.cpp:253]     Train net output #0: loss = 0.935769 (* 1 = 0.935769 loss)
I0523 21:55:02.907176 14326 sgd_solver.cpp:106] Iteration 111500, lr = 0.0045
I0523 21:55:32.864521 14326 solver.cpp:237] Iteration 111750, loss = 0.978934
I0523 21:55:32.864573 14326 solver.cpp:253]     Train net output #0: loss = 0.978934 (* 1 = 0.978934 loss)
I0523 21:55:32.864586 14326 sgd_solver.cpp:106] Iteration 111750, lr = 0.0045
I0523 21:55:41.919529 14326 solver.cpp:237] Iteration 112000, loss = 1.12579
I0523 21:55:41.919713 14326 solver.cpp:253]     Train net output #0: loss = 1.12579 (* 1 = 1.12579 loss)
I0523 21:55:41.919726 14326 sgd_solver.cpp:106] Iteration 112000, lr = 0.0045
I0523 21:55:50.980099 14326 solver.cpp:237] Iteration 112250, loss = 1.02974
I0523 21:55:50.980140 14326 solver.cpp:253]     Train net output #0: loss = 1.02974 (* 1 = 1.02974 loss)
I0523 21:55:50.980154 14326 sgd_solver.cpp:106] Iteration 112250, lr = 0.0045
I0523 21:56:00.001983 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_112500.caffemodel
I0523 21:56:00.067626 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_112500.solverstate
I0523 21:56:00.106014 14326 solver.cpp:237] Iteration 112500, loss = 0.91121
I0523 21:56:00.106066 14326 solver.cpp:253]     Train net output #0: loss = 0.91121 (* 1 = 0.91121 loss)
I0523 21:56:00.106081 14326 sgd_solver.cpp:106] Iteration 112500, lr = 0.0045
I0523 21:56:09.166221 14326 solver.cpp:237] Iteration 112750, loss = 0.89553
I0523 21:56:09.166257 14326 solver.cpp:253]     Train net output #0: loss = 0.89553 (* 1 = 0.89553 loss)
I0523 21:56:09.166271 14326 sgd_solver.cpp:106] Iteration 112750, lr = 0.0045
I0523 21:56:18.218713 14326 solver.cpp:237] Iteration 113000, loss = 1.13571
I0523 21:56:18.218909 14326 solver.cpp:253]     Train net output #0: loss = 1.13571 (* 1 = 1.13571 loss)
I0523 21:56:18.218924 14326 sgd_solver.cpp:106] Iteration 113000, lr = 0.0045
I0523 21:56:27.281704 14326 solver.cpp:237] Iteration 113250, loss = 1.14617
I0523 21:56:27.281738 14326 solver.cpp:253]     Train net output #0: loss = 1.14617 (* 1 = 1.14617 loss)
I0523 21:56:27.281754 14326 sgd_solver.cpp:106] Iteration 113250, lr = 0.0045
I0523 21:56:57.257974 14326 solver.cpp:237] Iteration 113500, loss = 1.25845
I0523 21:56:57.258186 14326 solver.cpp:253]     Train net output #0: loss = 1.25845 (* 1 = 1.25845 loss)
I0523 21:56:57.258200 14326 sgd_solver.cpp:106] Iteration 113500, lr = 0.0045
I0523 21:57:06.318439 14326 solver.cpp:237] Iteration 113750, loss = 1.24035
I0523 21:57:06.318480 14326 solver.cpp:253]     Train net output #0: loss = 1.24035 (* 1 = 1.24035 loss)
I0523 21:57:06.318500 14326 sgd_solver.cpp:106] Iteration 113750, lr = 0.0045
I0523 21:57:15.376847 14326 solver.cpp:237] Iteration 114000, loss = 1.16527
I0523 21:57:15.376886 14326 solver.cpp:253]     Train net output #0: loss = 1.16527 (* 1 = 1.16527 loss)
I0523 21:57:15.376899 14326 sgd_solver.cpp:106] Iteration 114000, lr = 0.0045
I0523 21:57:24.440723 14326 solver.cpp:237] Iteration 114250, loss = 1.3164
I0523 21:57:24.440757 14326 solver.cpp:253]     Train net output #0: loss = 1.3164 (* 1 = 1.3164 loss)
I0523 21:57:24.440770 14326 sgd_solver.cpp:106] Iteration 114250, lr = 0.0045
I0523 21:57:33.495678 14326 solver.cpp:237] Iteration 114500, loss = 1.17012
I0523 21:57:33.495870 14326 solver.cpp:253]     Train net output #0: loss = 1.17012 (* 1 = 1.17012 loss)
I0523 21:57:33.495884 14326 sgd_solver.cpp:106] Iteration 114500, lr = 0.0045
I0523 21:57:42.561367 14326 solver.cpp:237] Iteration 114750, loss = 0.787567
I0523 21:57:42.561401 14326 solver.cpp:253]     Train net output #0: loss = 0.787567 (* 1 = 0.787567 loss)
I0523 21:57:42.561416 14326 sgd_solver.cpp:106] Iteration 114750, lr = 0.0045
I0523 21:57:51.575870 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_115000.caffemodel
I0523 21:57:51.648222 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_115000.solverstate
I0523 21:57:51.673416 14326 solver.cpp:341] Iteration 115000, Testing net (#0)
I0523 21:58:38.667302 14326 solver.cpp:409]     Test net output #0: accuracy = 0.903052
I0523 21:58:38.667501 14326 solver.cpp:409]     Test net output #1: loss = 0.307509 (* 1 = 0.307509 loss)
I0523 21:58:59.553294 14326 solver.cpp:237] Iteration 115000, loss = 0.962172
I0523 21:58:59.553346 14326 solver.cpp:253]     Train net output #0: loss = 0.962172 (* 1 = 0.962172 loss)
I0523 21:58:59.553362 14326 sgd_solver.cpp:106] Iteration 115000, lr = 0.0045
I0523 21:59:08.569771 14326 solver.cpp:237] Iteration 115250, loss = 1.26638
I0523 21:59:08.569815 14326 solver.cpp:253]     Train net output #0: loss = 1.26638 (* 1 = 1.26638 loss)
I0523 21:59:08.569830 14326 sgd_solver.cpp:106] Iteration 115250, lr = 0.0045
I0523 21:59:17.589797 14326 solver.cpp:237] Iteration 115500, loss = 1.23101
I0523 21:59:17.589978 14326 solver.cpp:253]     Train net output #0: loss = 1.23101 (* 1 = 1.23101 loss)
I0523 21:59:17.589993 14326 sgd_solver.cpp:106] Iteration 115500, lr = 0.0045
I0523 21:59:26.612468 14326 solver.cpp:237] Iteration 115750, loss = 1.10417
I0523 21:59:26.612501 14326 solver.cpp:253]     Train net output #0: loss = 1.10417 (* 1 = 1.10417 loss)
I0523 21:59:26.612516 14326 sgd_solver.cpp:106] Iteration 115750, lr = 0.0045
I0523 21:59:35.626101 14326 solver.cpp:237] Iteration 116000, loss = 1.30774
I0523 21:59:35.626137 14326 solver.cpp:253]     Train net output #0: loss = 1.30774 (* 1 = 1.30774 loss)
I0523 21:59:35.626157 14326 sgd_solver.cpp:106] Iteration 116000, lr = 0.0045
I0523 21:59:44.645740 14326 solver.cpp:237] Iteration 116250, loss = 0.997735
I0523 21:59:44.645776 14326 solver.cpp:253]     Train net output #0: loss = 0.997735 (* 1 = 0.997735 loss)
I0523 21:59:44.645790 14326 sgd_solver.cpp:106] Iteration 116250, lr = 0.0045
I0523 21:59:53.656175 14326 solver.cpp:237] Iteration 116500, loss = 0.952801
I0523 21:59:53.656353 14326 solver.cpp:253]     Train net output #0: loss = 0.952801 (* 1 = 0.952801 loss)
I0523 21:59:53.656368 14326 sgd_solver.cpp:106] Iteration 116500, lr = 0.0045
I0523 22:00:23.561468 14326 solver.cpp:237] Iteration 116750, loss = 1.07897
I0523 22:00:23.561519 14326 solver.cpp:253]     Train net output #0: loss = 1.07897 (* 1 = 1.07897 loss)
I0523 22:00:23.561534 14326 sgd_solver.cpp:106] Iteration 116750, lr = 0.0045
I0523 22:00:32.579598 14326 solver.cpp:237] Iteration 117000, loss = 1.06689
I0523 22:00:32.579795 14326 solver.cpp:253]     Train net output #0: loss = 1.06689 (* 1 = 1.06689 loss)
I0523 22:00:32.579808 14326 sgd_solver.cpp:106] Iteration 117000, lr = 0.0045
I0523 22:00:41.593356 14326 solver.cpp:237] Iteration 117250, loss = 1.41301
I0523 22:00:41.593390 14326 solver.cpp:253]     Train net output #0: loss = 1.41301 (* 1 = 1.41301 loss)
I0523 22:00:41.593407 14326 sgd_solver.cpp:106] Iteration 117250, lr = 0.0045
I0523 22:00:50.576565 14326 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_117500.caffemodel
I0523 22:00:50.639488 14326 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0045_2016-05-20T15.49.11.826484_iter_117500.solverstate
I0523 22:00:50.676409 14326 solver.cpp:237] Iteration 117500, loss = 1.32466
I0523 22:00:50.676453 14326 solver.cpp:253]     Train net output #0: loss = 1.32466 (* 1 = 1.32466 loss)
I0523 22:00:50.676470 14326 sgd_solver.cpp:106] Iteration 117500, lr = 0.0045
I0523 22:00:59.694821 14326 solver.cpp:237] Iteration 117750, loss = 0.937159
I0523 22:00:59.694857 14326 solver.cpp:253]     Train net output #0: loss = 0.937159 (* 1 = 0.937159 loss)
I0523 22:00:59.694871 14326 sgd_solver.cpp:106] Iteration 117750, lr = 0.0045
I0523 22:01:08.705986 14326 solver.cpp:237] Iteration 118000, loss = 1.02002
I0523 22:01:08.706171 14326 solver.cpp:253]     Train net output #0: loss = 1.02002 (* 1 = 1.02002 loss)
I0523 22:01:08.706185 14326 sgd_solver.cpp:106] Iteration 118000, lr = 0.0045
I0523 22:01:17.720227 14326 solver.cpp:237] Iteration 118250, loss = 1.18676
I0523 22:01:17.720268 14326 solver.cpp:253]     Train net output #0: loss = 1.18676 (* 1 = 1.18676 loss)
I0523 22:01:17.720288 14326 sgd_solver.cpp:106] Iteration 118250, lr = 0.0045
aprun: Apid 11257967: Caught signal Terminated, sending to application
*** Aborted at 1464055286 (unix time) try "date -d @1464055286" if you are using GNU date ***
PC: @     0x2aaac5e9b800 (unknown)
aprun: Apid 11257967: Caught signal Terminated, sending to application
*** SIGTERM (@0x37f3) received by PID 14326 (TID 0x2aaac746f900) from PID 14323; stack trace: ***
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7203 exceeded limit 7200
aprun: Apid 11257967: Caught signal Terminated, sending to application
    @     0x2aaac5e9b800 (unknown)
    @     0x2aaac5e9c9d5 inflate
aprun: Apid 11257967: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11257967: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11257967: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11257967: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11257967: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11257967: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
aprun: Apid 11257967: Caught signal Terminated, sending to application
