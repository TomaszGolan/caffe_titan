2808201
I0523 07:55:09.243774 24595 caffe.cpp:184] Using GPUs 0
I0523 07:55:09.668431 24595 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3000
test_interval: 6000
base_lr: 0.0035
display: 300
max_iter: 300000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047.prototxt"
I0523 07:55:09.670291 24595 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047.prototxt
I0523 07:55:09.683902 24595 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 07:55:09.683976 24595 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 07:55:09.684324 24595 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 07:55:09.684509 24595 layer_factory.hpp:77] Creating layer data_hdf5
I0523 07:55:09.684532 24595 net.cpp:106] Creating Layer data_hdf5
I0523 07:55:09.684547 24595 net.cpp:411] data_hdf5 -> data
I0523 07:55:09.684579 24595 net.cpp:411] data_hdf5 -> label
I0523 07:55:09.684612 24595 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 07:55:09.685986 24595 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 07:55:09.688360 24595 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 07:55:31.248329 24595 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 07:55:31.253451 24595 net.cpp:150] Setting up data_hdf5
I0523 07:55:31.253491 24595 net.cpp:157] Top shape: 50 1 127 50 (317500)
I0523 07:55:31.253506 24595 net.cpp:157] Top shape: 50 (50)
I0523 07:55:31.253518 24595 net.cpp:165] Memory required for data: 1270200
I0523 07:55:31.253532 24595 layer_factory.hpp:77] Creating layer conv1
I0523 07:55:31.253566 24595 net.cpp:106] Creating Layer conv1
I0523 07:55:31.253576 24595 net.cpp:454] conv1 <- data
I0523 07:55:31.253597 24595 net.cpp:411] conv1 -> conv1
I0523 07:55:32.167441 24595 net.cpp:150] Setting up conv1
I0523 07:55:32.167489 24595 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 07:55:32.167500 24595 net.cpp:165] Memory required for data: 15094200
I0523 07:55:32.167531 24595 layer_factory.hpp:77] Creating layer relu1
I0523 07:55:32.167551 24595 net.cpp:106] Creating Layer relu1
I0523 07:55:32.167562 24595 net.cpp:454] relu1 <- conv1
I0523 07:55:32.167574 24595 net.cpp:397] relu1 -> conv1 (in-place)
I0523 07:55:32.168090 24595 net.cpp:150] Setting up relu1
I0523 07:55:32.168107 24595 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 07:55:32.168118 24595 net.cpp:165] Memory required for data: 28918200
I0523 07:55:32.168126 24595 layer_factory.hpp:77] Creating layer pool1
I0523 07:55:32.168143 24595 net.cpp:106] Creating Layer pool1
I0523 07:55:32.168154 24595 net.cpp:454] pool1 <- conv1
I0523 07:55:32.168167 24595 net.cpp:411] pool1 -> pool1
I0523 07:55:32.168248 24595 net.cpp:150] Setting up pool1
I0523 07:55:32.168262 24595 net.cpp:157] Top shape: 50 12 60 48 (1728000)
I0523 07:55:32.168272 24595 net.cpp:165] Memory required for data: 35830200
I0523 07:55:32.168283 24595 layer_factory.hpp:77] Creating layer conv2
I0523 07:55:32.168306 24595 net.cpp:106] Creating Layer conv2
I0523 07:55:32.168316 24595 net.cpp:454] conv2 <- pool1
I0523 07:55:32.168329 24595 net.cpp:411] conv2 -> conv2
I0523 07:55:32.171003 24595 net.cpp:150] Setting up conv2
I0523 07:55:32.171030 24595 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 07:55:32.171041 24595 net.cpp:165] Memory required for data: 45766200
I0523 07:55:32.171061 24595 layer_factory.hpp:77] Creating layer relu2
I0523 07:55:32.171075 24595 net.cpp:106] Creating Layer relu2
I0523 07:55:32.171085 24595 net.cpp:454] relu2 <- conv2
I0523 07:55:32.171098 24595 net.cpp:397] relu2 -> conv2 (in-place)
I0523 07:55:32.171428 24595 net.cpp:150] Setting up relu2
I0523 07:55:32.171443 24595 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 07:55:32.171453 24595 net.cpp:165] Memory required for data: 55702200
I0523 07:55:32.171463 24595 layer_factory.hpp:77] Creating layer pool2
I0523 07:55:32.171475 24595 net.cpp:106] Creating Layer pool2
I0523 07:55:32.171485 24595 net.cpp:454] pool2 <- conv2
I0523 07:55:32.171499 24595 net.cpp:411] pool2 -> pool2
I0523 07:55:32.171579 24595 net.cpp:150] Setting up pool2
I0523 07:55:32.171593 24595 net.cpp:157] Top shape: 50 20 27 46 (1242000)
I0523 07:55:32.171603 24595 net.cpp:165] Memory required for data: 60670200
I0523 07:55:32.171613 24595 layer_factory.hpp:77] Creating layer conv3
I0523 07:55:32.171632 24595 net.cpp:106] Creating Layer conv3
I0523 07:55:32.171641 24595 net.cpp:454] conv3 <- pool2
I0523 07:55:32.171655 24595 net.cpp:411] conv3 -> conv3
I0523 07:55:32.173594 24595 net.cpp:150] Setting up conv3
I0523 07:55:32.173617 24595 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 07:55:32.173629 24595 net.cpp:165] Memory required for data: 66091000
I0523 07:55:32.173648 24595 layer_factory.hpp:77] Creating layer relu3
I0523 07:55:32.173663 24595 net.cpp:106] Creating Layer relu3
I0523 07:55:32.173673 24595 net.cpp:454] relu3 <- conv3
I0523 07:55:32.173686 24595 net.cpp:397] relu3 -> conv3 (in-place)
I0523 07:55:32.174166 24595 net.cpp:150] Setting up relu3
I0523 07:55:32.174183 24595 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 07:55:32.174195 24595 net.cpp:165] Memory required for data: 71511800
I0523 07:55:32.174204 24595 layer_factory.hpp:77] Creating layer pool3
I0523 07:55:32.174217 24595 net.cpp:106] Creating Layer pool3
I0523 07:55:32.174227 24595 net.cpp:454] pool3 <- conv3
I0523 07:55:32.174240 24595 net.cpp:411] pool3 -> pool3
I0523 07:55:32.174307 24595 net.cpp:150] Setting up pool3
I0523 07:55:32.174321 24595 net.cpp:157] Top shape: 50 28 11 44 (677600)
I0523 07:55:32.174330 24595 net.cpp:165] Memory required for data: 74222200
I0523 07:55:32.174340 24595 layer_factory.hpp:77] Creating layer conv4
I0523 07:55:32.174360 24595 net.cpp:106] Creating Layer conv4
I0523 07:55:32.174371 24595 net.cpp:454] conv4 <- pool3
I0523 07:55:32.174383 24595 net.cpp:411] conv4 -> conv4
I0523 07:55:32.177145 24595 net.cpp:150] Setting up conv4
I0523 07:55:32.177173 24595 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 07:55:32.177186 24595 net.cpp:165] Memory required for data: 76036600
I0523 07:55:32.177201 24595 layer_factory.hpp:77] Creating layer relu4
I0523 07:55:32.177217 24595 net.cpp:106] Creating Layer relu4
I0523 07:55:32.177227 24595 net.cpp:454] relu4 <- conv4
I0523 07:55:32.177239 24595 net.cpp:397] relu4 -> conv4 (in-place)
I0523 07:55:32.177709 24595 net.cpp:150] Setting up relu4
I0523 07:55:32.177726 24595 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 07:55:32.177736 24595 net.cpp:165] Memory required for data: 77851000
I0523 07:55:32.177747 24595 layer_factory.hpp:77] Creating layer pool4
I0523 07:55:32.177760 24595 net.cpp:106] Creating Layer pool4
I0523 07:55:32.177770 24595 net.cpp:454] pool4 <- conv4
I0523 07:55:32.177783 24595 net.cpp:411] pool4 -> pool4
I0523 07:55:32.177852 24595 net.cpp:150] Setting up pool4
I0523 07:55:32.177865 24595 net.cpp:157] Top shape: 50 36 3 42 (226800)
I0523 07:55:32.177876 24595 net.cpp:165] Memory required for data: 78758200
I0523 07:55:32.177886 24595 layer_factory.hpp:77] Creating layer ip1
I0523 07:55:32.177907 24595 net.cpp:106] Creating Layer ip1
I0523 07:55:32.177918 24595 net.cpp:454] ip1 <- pool4
I0523 07:55:32.177932 24595 net.cpp:411] ip1 -> ip1
I0523 07:55:32.193377 24595 net.cpp:150] Setting up ip1
I0523 07:55:32.193404 24595 net.cpp:157] Top shape: 50 196 (9800)
I0523 07:55:32.193416 24595 net.cpp:165] Memory required for data: 78797400
I0523 07:55:32.193439 24595 layer_factory.hpp:77] Creating layer relu5
I0523 07:55:32.193454 24595 net.cpp:106] Creating Layer relu5
I0523 07:55:32.193464 24595 net.cpp:454] relu5 <- ip1
I0523 07:55:32.193478 24595 net.cpp:397] relu5 -> ip1 (in-place)
I0523 07:55:32.193819 24595 net.cpp:150] Setting up relu5
I0523 07:55:32.193832 24595 net.cpp:157] Top shape: 50 196 (9800)
I0523 07:55:32.193842 24595 net.cpp:165] Memory required for data: 78836600
I0523 07:55:32.193853 24595 layer_factory.hpp:77] Creating layer drop1
I0523 07:55:32.193874 24595 net.cpp:106] Creating Layer drop1
I0523 07:55:32.193884 24595 net.cpp:454] drop1 <- ip1
I0523 07:55:32.193897 24595 net.cpp:397] drop1 -> ip1 (in-place)
I0523 07:55:32.193955 24595 net.cpp:150] Setting up drop1
I0523 07:55:32.193969 24595 net.cpp:157] Top shape: 50 196 (9800)
I0523 07:55:32.193979 24595 net.cpp:165] Memory required for data: 78875800
I0523 07:55:32.193989 24595 layer_factory.hpp:77] Creating layer ip2
I0523 07:55:32.194006 24595 net.cpp:106] Creating Layer ip2
I0523 07:55:32.194017 24595 net.cpp:454] ip2 <- ip1
I0523 07:55:32.194030 24595 net.cpp:411] ip2 -> ip2
I0523 07:55:32.194497 24595 net.cpp:150] Setting up ip2
I0523 07:55:32.194510 24595 net.cpp:157] Top shape: 50 98 (4900)
I0523 07:55:32.194520 24595 net.cpp:165] Memory required for data: 78895400
I0523 07:55:32.194535 24595 layer_factory.hpp:77] Creating layer relu6
I0523 07:55:32.194548 24595 net.cpp:106] Creating Layer relu6
I0523 07:55:32.194557 24595 net.cpp:454] relu6 <- ip2
I0523 07:55:32.194569 24595 net.cpp:397] relu6 -> ip2 (in-place)
I0523 07:55:32.195086 24595 net.cpp:150] Setting up relu6
I0523 07:55:32.195102 24595 net.cpp:157] Top shape: 50 98 (4900)
I0523 07:55:32.195112 24595 net.cpp:165] Memory required for data: 78915000
I0523 07:55:32.195122 24595 layer_factory.hpp:77] Creating layer drop2
I0523 07:55:32.195135 24595 net.cpp:106] Creating Layer drop2
I0523 07:55:32.195145 24595 net.cpp:454] drop2 <- ip2
I0523 07:55:32.195158 24595 net.cpp:397] drop2 -> ip2 (in-place)
I0523 07:55:32.195200 24595 net.cpp:150] Setting up drop2
I0523 07:55:32.195214 24595 net.cpp:157] Top shape: 50 98 (4900)
I0523 07:55:32.195225 24595 net.cpp:165] Memory required for data: 78934600
I0523 07:55:32.195235 24595 layer_factory.hpp:77] Creating layer ip3
I0523 07:55:32.195247 24595 net.cpp:106] Creating Layer ip3
I0523 07:55:32.195257 24595 net.cpp:454] ip3 <- ip2
I0523 07:55:32.195271 24595 net.cpp:411] ip3 -> ip3
I0523 07:55:32.195480 24595 net.cpp:150] Setting up ip3
I0523 07:55:32.195493 24595 net.cpp:157] Top shape: 50 11 (550)
I0523 07:55:32.195504 24595 net.cpp:165] Memory required for data: 78936800
I0523 07:55:32.195519 24595 layer_factory.hpp:77] Creating layer drop3
I0523 07:55:32.195531 24595 net.cpp:106] Creating Layer drop3
I0523 07:55:32.195541 24595 net.cpp:454] drop3 <- ip3
I0523 07:55:32.195554 24595 net.cpp:397] drop3 -> ip3 (in-place)
I0523 07:55:32.195592 24595 net.cpp:150] Setting up drop3
I0523 07:55:32.195605 24595 net.cpp:157] Top shape: 50 11 (550)
I0523 07:55:32.195616 24595 net.cpp:165] Memory required for data: 78939000
I0523 07:55:32.195626 24595 layer_factory.hpp:77] Creating layer loss
I0523 07:55:32.195646 24595 net.cpp:106] Creating Layer loss
I0523 07:55:32.195655 24595 net.cpp:454] loss <- ip3
I0523 07:55:32.195667 24595 net.cpp:454] loss <- label
I0523 07:55:32.195679 24595 net.cpp:411] loss -> loss
I0523 07:55:32.195695 24595 layer_factory.hpp:77] Creating layer loss
I0523 07:55:32.196414 24595 net.cpp:150] Setting up loss
I0523 07:55:32.196436 24595 net.cpp:157] Top shape: (1)
I0523 07:55:32.196449 24595 net.cpp:160]     with loss weight 1
I0523 07:55:32.196492 24595 net.cpp:165] Memory required for data: 78939004
I0523 07:55:32.196502 24595 net.cpp:226] loss needs backward computation.
I0523 07:55:32.196513 24595 net.cpp:226] drop3 needs backward computation.
I0523 07:55:32.196523 24595 net.cpp:226] ip3 needs backward computation.
I0523 07:55:32.196533 24595 net.cpp:226] drop2 needs backward computation.
I0523 07:55:32.196544 24595 net.cpp:226] relu6 needs backward computation.
I0523 07:55:32.196553 24595 net.cpp:226] ip2 needs backward computation.
I0523 07:55:32.196564 24595 net.cpp:226] drop1 needs backward computation.
I0523 07:55:32.196573 24595 net.cpp:226] relu5 needs backward computation.
I0523 07:55:32.196583 24595 net.cpp:226] ip1 needs backward computation.
I0523 07:55:32.196593 24595 net.cpp:226] pool4 needs backward computation.
I0523 07:55:32.196604 24595 net.cpp:226] relu4 needs backward computation.
I0523 07:55:32.196614 24595 net.cpp:226] conv4 needs backward computation.
I0523 07:55:32.196624 24595 net.cpp:226] pool3 needs backward computation.
I0523 07:55:32.196635 24595 net.cpp:226] relu3 needs backward computation.
I0523 07:55:32.196645 24595 net.cpp:226] conv3 needs backward computation.
I0523 07:55:32.196666 24595 net.cpp:226] pool2 needs backward computation.
I0523 07:55:32.196676 24595 net.cpp:226] relu2 needs backward computation.
I0523 07:55:32.196686 24595 net.cpp:226] conv2 needs backward computation.
I0523 07:55:32.196697 24595 net.cpp:226] pool1 needs backward computation.
I0523 07:55:32.196707 24595 net.cpp:226] relu1 needs backward computation.
I0523 07:55:32.196717 24595 net.cpp:226] conv1 needs backward computation.
I0523 07:55:32.196728 24595 net.cpp:228] data_hdf5 does not need backward computation.
I0523 07:55:32.196738 24595 net.cpp:270] This network produces output loss
I0523 07:55:32.196761 24595 net.cpp:283] Network initialization done.
I0523 07:55:32.198356 24595 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047.prototxt
I0523 07:55:32.198427 24595 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 07:55:32.198781 24595 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 07:55:32.198971 24595 layer_factory.hpp:77] Creating layer data_hdf5
I0523 07:55:32.198987 24595 net.cpp:106] Creating Layer data_hdf5
I0523 07:55:32.198998 24595 net.cpp:411] data_hdf5 -> data
I0523 07:55:32.199018 24595 net.cpp:411] data_hdf5 -> label
I0523 07:55:32.199033 24595 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 07:55:32.209311 24595 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 07:55:53.546311 24595 net.cpp:150] Setting up data_hdf5
I0523 07:55:53.546476 24595 net.cpp:157] Top shape: 50 1 127 50 (317500)
I0523 07:55:53.546491 24595 net.cpp:157] Top shape: 50 (50)
I0523 07:55:53.546502 24595 net.cpp:165] Memory required for data: 1270200
I0523 07:55:53.546516 24595 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 07:55:53.546545 24595 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 07:55:53.546555 24595 net.cpp:454] label_data_hdf5_1_split <- label
I0523 07:55:53.546571 24595 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 07:55:53.546592 24595 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 07:55:53.546664 24595 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 07:55:53.546679 24595 net.cpp:157] Top shape: 50 (50)
I0523 07:55:53.546690 24595 net.cpp:157] Top shape: 50 (50)
I0523 07:55:53.546700 24595 net.cpp:165] Memory required for data: 1270600
I0523 07:55:53.546710 24595 layer_factory.hpp:77] Creating layer conv1
I0523 07:55:53.546731 24595 net.cpp:106] Creating Layer conv1
I0523 07:55:53.546741 24595 net.cpp:454] conv1 <- data
I0523 07:55:53.546756 24595 net.cpp:411] conv1 -> conv1
I0523 07:55:53.548665 24595 net.cpp:150] Setting up conv1
I0523 07:55:53.548689 24595 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 07:55:53.548701 24595 net.cpp:165] Memory required for data: 15094600
I0523 07:55:53.548722 24595 layer_factory.hpp:77] Creating layer relu1
I0523 07:55:53.548737 24595 net.cpp:106] Creating Layer relu1
I0523 07:55:53.548746 24595 net.cpp:454] relu1 <- conv1
I0523 07:55:53.548759 24595 net.cpp:397] relu1 -> conv1 (in-place)
I0523 07:55:53.549254 24595 net.cpp:150] Setting up relu1
I0523 07:55:53.549271 24595 net.cpp:157] Top shape: 50 12 120 48 (3456000)
I0523 07:55:53.549281 24595 net.cpp:165] Memory required for data: 28918600
I0523 07:55:53.549293 24595 layer_factory.hpp:77] Creating layer pool1
I0523 07:55:53.549309 24595 net.cpp:106] Creating Layer pool1
I0523 07:55:53.549319 24595 net.cpp:454] pool1 <- conv1
I0523 07:55:53.549331 24595 net.cpp:411] pool1 -> pool1
I0523 07:55:53.549406 24595 net.cpp:150] Setting up pool1
I0523 07:55:53.549419 24595 net.cpp:157] Top shape: 50 12 60 48 (1728000)
I0523 07:55:53.549429 24595 net.cpp:165] Memory required for data: 35830600
I0523 07:55:53.549442 24595 layer_factory.hpp:77] Creating layer conv2
I0523 07:55:53.549459 24595 net.cpp:106] Creating Layer conv2
I0523 07:55:53.549469 24595 net.cpp:454] conv2 <- pool1
I0523 07:55:53.549484 24595 net.cpp:411] conv2 -> conv2
I0523 07:55:53.551411 24595 net.cpp:150] Setting up conv2
I0523 07:55:53.551434 24595 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 07:55:53.551446 24595 net.cpp:165] Memory required for data: 45766600
I0523 07:55:53.551465 24595 layer_factory.hpp:77] Creating layer relu2
I0523 07:55:53.551477 24595 net.cpp:106] Creating Layer relu2
I0523 07:55:53.551487 24595 net.cpp:454] relu2 <- conv2
I0523 07:55:53.551501 24595 net.cpp:397] relu2 -> conv2 (in-place)
I0523 07:55:53.551831 24595 net.cpp:150] Setting up relu2
I0523 07:55:53.551843 24595 net.cpp:157] Top shape: 50 20 54 46 (2484000)
I0523 07:55:53.551854 24595 net.cpp:165] Memory required for data: 55702600
I0523 07:55:53.551864 24595 layer_factory.hpp:77] Creating layer pool2
I0523 07:55:53.551877 24595 net.cpp:106] Creating Layer pool2
I0523 07:55:53.551887 24595 net.cpp:454] pool2 <- conv2
I0523 07:55:53.551899 24595 net.cpp:411] pool2 -> pool2
I0523 07:55:53.551977 24595 net.cpp:150] Setting up pool2
I0523 07:55:53.551990 24595 net.cpp:157] Top shape: 50 20 27 46 (1242000)
I0523 07:55:53.552000 24595 net.cpp:165] Memory required for data: 60670600
I0523 07:55:53.552011 24595 layer_factory.hpp:77] Creating layer conv3
I0523 07:55:53.552028 24595 net.cpp:106] Creating Layer conv3
I0523 07:55:53.552038 24595 net.cpp:454] conv3 <- pool2
I0523 07:55:53.552052 24595 net.cpp:411] conv3 -> conv3
I0523 07:55:53.554025 24595 net.cpp:150] Setting up conv3
I0523 07:55:53.554049 24595 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 07:55:53.554067 24595 net.cpp:165] Memory required for data: 66091400
I0523 07:55:53.554100 24595 layer_factory.hpp:77] Creating layer relu3
I0523 07:55:53.554113 24595 net.cpp:106] Creating Layer relu3
I0523 07:55:53.554124 24595 net.cpp:454] relu3 <- conv3
I0523 07:55:53.554134 24595 net.cpp:397] relu3 -> conv3 (in-place)
I0523 07:55:53.554607 24595 net.cpp:150] Setting up relu3
I0523 07:55:53.554623 24595 net.cpp:157] Top shape: 50 28 22 44 (1355200)
I0523 07:55:53.554635 24595 net.cpp:165] Memory required for data: 71512200
I0523 07:55:53.554643 24595 layer_factory.hpp:77] Creating layer pool3
I0523 07:55:53.554656 24595 net.cpp:106] Creating Layer pool3
I0523 07:55:53.554666 24595 net.cpp:454] pool3 <- conv3
I0523 07:55:53.554679 24595 net.cpp:411] pool3 -> pool3
I0523 07:55:53.554751 24595 net.cpp:150] Setting up pool3
I0523 07:55:53.554764 24595 net.cpp:157] Top shape: 50 28 11 44 (677600)
I0523 07:55:53.554774 24595 net.cpp:165] Memory required for data: 74222600
I0523 07:55:53.554783 24595 layer_factory.hpp:77] Creating layer conv4
I0523 07:55:53.554801 24595 net.cpp:106] Creating Layer conv4
I0523 07:55:53.554812 24595 net.cpp:454] conv4 <- pool3
I0523 07:55:53.554826 24595 net.cpp:411] conv4 -> conv4
I0523 07:55:53.556879 24595 net.cpp:150] Setting up conv4
I0523 07:55:53.556900 24595 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 07:55:53.556913 24595 net.cpp:165] Memory required for data: 76037000
I0523 07:55:53.556928 24595 layer_factory.hpp:77] Creating layer relu4
I0523 07:55:53.556942 24595 net.cpp:106] Creating Layer relu4
I0523 07:55:53.556952 24595 net.cpp:454] relu4 <- conv4
I0523 07:55:53.556965 24595 net.cpp:397] relu4 -> conv4 (in-place)
I0523 07:55:53.557436 24595 net.cpp:150] Setting up relu4
I0523 07:55:53.557452 24595 net.cpp:157] Top shape: 50 36 6 42 (453600)
I0523 07:55:53.557462 24595 net.cpp:165] Memory required for data: 77851400
I0523 07:55:53.557472 24595 layer_factory.hpp:77] Creating layer pool4
I0523 07:55:53.557485 24595 net.cpp:106] Creating Layer pool4
I0523 07:55:53.557495 24595 net.cpp:454] pool4 <- conv4
I0523 07:55:53.557508 24595 net.cpp:411] pool4 -> pool4
I0523 07:55:53.557579 24595 net.cpp:150] Setting up pool4
I0523 07:55:53.557592 24595 net.cpp:157] Top shape: 50 36 3 42 (226800)
I0523 07:55:53.557602 24595 net.cpp:165] Memory required for data: 78758600
I0523 07:55:53.557612 24595 layer_factory.hpp:77] Creating layer ip1
I0523 07:55:53.557626 24595 net.cpp:106] Creating Layer ip1
I0523 07:55:53.557636 24595 net.cpp:454] ip1 <- pool4
I0523 07:55:53.557649 24595 net.cpp:411] ip1 -> ip1
I0523 07:55:53.573132 24595 net.cpp:150] Setting up ip1
I0523 07:55:53.573160 24595 net.cpp:157] Top shape: 50 196 (9800)
I0523 07:55:53.573171 24595 net.cpp:165] Memory required for data: 78797800
I0523 07:55:53.573192 24595 layer_factory.hpp:77] Creating layer relu5
I0523 07:55:53.573209 24595 net.cpp:106] Creating Layer relu5
I0523 07:55:53.573220 24595 net.cpp:454] relu5 <- ip1
I0523 07:55:53.573232 24595 net.cpp:397] relu5 -> ip1 (in-place)
I0523 07:55:53.573580 24595 net.cpp:150] Setting up relu5
I0523 07:55:53.573595 24595 net.cpp:157] Top shape: 50 196 (9800)
I0523 07:55:53.573603 24595 net.cpp:165] Memory required for data: 78837000
I0523 07:55:53.573614 24595 layer_factory.hpp:77] Creating layer drop1
I0523 07:55:53.573633 24595 net.cpp:106] Creating Layer drop1
I0523 07:55:53.573643 24595 net.cpp:454] drop1 <- ip1
I0523 07:55:53.573657 24595 net.cpp:397] drop1 -> ip1 (in-place)
I0523 07:55:53.573704 24595 net.cpp:150] Setting up drop1
I0523 07:55:53.573716 24595 net.cpp:157] Top shape: 50 196 (9800)
I0523 07:55:53.573726 24595 net.cpp:165] Memory required for data: 78876200
I0523 07:55:53.573735 24595 layer_factory.hpp:77] Creating layer ip2
I0523 07:55:53.573750 24595 net.cpp:106] Creating Layer ip2
I0523 07:55:53.573760 24595 net.cpp:454] ip2 <- ip1
I0523 07:55:53.573773 24595 net.cpp:411] ip2 -> ip2
I0523 07:55:53.574259 24595 net.cpp:150] Setting up ip2
I0523 07:55:53.574271 24595 net.cpp:157] Top shape: 50 98 (4900)
I0523 07:55:53.574281 24595 net.cpp:165] Memory required for data: 78895800
I0523 07:55:53.574296 24595 layer_factory.hpp:77] Creating layer relu6
I0523 07:55:53.574322 24595 net.cpp:106] Creating Layer relu6
I0523 07:55:53.574332 24595 net.cpp:454] relu6 <- ip2
I0523 07:55:53.574345 24595 net.cpp:397] relu6 -> ip2 (in-place)
I0523 07:55:53.574882 24595 net.cpp:150] Setting up relu6
I0523 07:55:53.574898 24595 net.cpp:157] Top shape: 50 98 (4900)
I0523 07:55:53.574908 24595 net.cpp:165] Memory required for data: 78915400
I0523 07:55:53.574916 24595 layer_factory.hpp:77] Creating layer drop2
I0523 07:55:53.574930 24595 net.cpp:106] Creating Layer drop2
I0523 07:55:53.574940 24595 net.cpp:454] drop2 <- ip2
I0523 07:55:53.574954 24595 net.cpp:397] drop2 -> ip2 (in-place)
I0523 07:55:53.574997 24595 net.cpp:150] Setting up drop2
I0523 07:55:53.575011 24595 net.cpp:157] Top shape: 50 98 (4900)
I0523 07:55:53.575021 24595 net.cpp:165] Memory required for data: 78935000
I0523 07:55:53.575029 24595 layer_factory.hpp:77] Creating layer ip3
I0523 07:55:53.575043 24595 net.cpp:106] Creating Layer ip3
I0523 07:55:53.575053 24595 net.cpp:454] ip3 <- ip2
I0523 07:55:53.575067 24595 net.cpp:411] ip3 -> ip3
I0523 07:55:53.575287 24595 net.cpp:150] Setting up ip3
I0523 07:55:53.575300 24595 net.cpp:157] Top shape: 50 11 (550)
I0523 07:55:53.575310 24595 net.cpp:165] Memory required for data: 78937200
I0523 07:55:53.575325 24595 layer_factory.hpp:77] Creating layer drop3
I0523 07:55:53.575338 24595 net.cpp:106] Creating Layer drop3
I0523 07:55:53.575348 24595 net.cpp:454] drop3 <- ip3
I0523 07:55:53.575361 24595 net.cpp:397] drop3 -> ip3 (in-place)
I0523 07:55:53.575403 24595 net.cpp:150] Setting up drop3
I0523 07:55:53.575417 24595 net.cpp:157] Top shape: 50 11 (550)
I0523 07:55:53.575425 24595 net.cpp:165] Memory required for data: 78939400
I0523 07:55:53.575435 24595 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 07:55:53.575448 24595 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 07:55:53.575459 24595 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 07:55:53.575471 24595 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 07:55:53.575487 24595 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 07:55:53.575559 24595 net.cpp:150] Setting up ip3_drop3_0_split
I0523 07:55:53.575575 24595 net.cpp:157] Top shape: 50 11 (550)
I0523 07:55:53.575587 24595 net.cpp:157] Top shape: 50 11 (550)
I0523 07:55:53.575598 24595 net.cpp:165] Memory required for data: 78943800
I0523 07:55:53.575608 24595 layer_factory.hpp:77] Creating layer accuracy
I0523 07:55:53.575630 24595 net.cpp:106] Creating Layer accuracy
I0523 07:55:53.575640 24595 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 07:55:53.575651 24595 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 07:55:53.575665 24595 net.cpp:411] accuracy -> accuracy
I0523 07:55:53.575690 24595 net.cpp:150] Setting up accuracy
I0523 07:55:53.575701 24595 net.cpp:157] Top shape: (1)
I0523 07:55:53.575711 24595 net.cpp:165] Memory required for data: 78943804
I0523 07:55:53.575721 24595 layer_factory.hpp:77] Creating layer loss
I0523 07:55:53.575734 24595 net.cpp:106] Creating Layer loss
I0523 07:55:53.575744 24595 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 07:55:53.575757 24595 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 07:55:53.575770 24595 net.cpp:411] loss -> loss
I0523 07:55:53.575788 24595 layer_factory.hpp:77] Creating layer loss
I0523 07:55:53.576270 24595 net.cpp:150] Setting up loss
I0523 07:55:53.576284 24595 net.cpp:157] Top shape: (1)
I0523 07:55:53.576294 24595 net.cpp:160]     with loss weight 1
I0523 07:55:53.576313 24595 net.cpp:165] Memory required for data: 78943808
I0523 07:55:53.576323 24595 net.cpp:226] loss needs backward computation.
I0523 07:55:53.576335 24595 net.cpp:228] accuracy does not need backward computation.
I0523 07:55:53.576346 24595 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 07:55:53.576357 24595 net.cpp:226] drop3 needs backward computation.
I0523 07:55:53.576366 24595 net.cpp:226] ip3 needs backward computation.
I0523 07:55:53.576377 24595 net.cpp:226] drop2 needs backward computation.
I0523 07:55:53.576387 24595 net.cpp:226] relu6 needs backward computation.
I0523 07:55:53.576406 24595 net.cpp:226] ip2 needs backward computation.
I0523 07:55:53.576416 24595 net.cpp:226] drop1 needs backward computation.
I0523 07:55:53.576426 24595 net.cpp:226] relu5 needs backward computation.
I0523 07:55:53.576436 24595 net.cpp:226] ip1 needs backward computation.
I0523 07:55:53.576444 24595 net.cpp:226] pool4 needs backward computation.
I0523 07:55:53.576455 24595 net.cpp:226] relu4 needs backward computation.
I0523 07:55:53.576465 24595 net.cpp:226] conv4 needs backward computation.
I0523 07:55:53.576475 24595 net.cpp:226] pool3 needs backward computation.
I0523 07:55:53.576483 24595 net.cpp:226] relu3 needs backward computation.
I0523 07:55:53.576494 24595 net.cpp:226] conv3 needs backward computation.
I0523 07:55:53.576505 24595 net.cpp:226] pool2 needs backward computation.
I0523 07:55:53.576516 24595 net.cpp:226] relu2 needs backward computation.
I0523 07:55:53.576526 24595 net.cpp:226] conv2 needs backward computation.
I0523 07:55:53.576536 24595 net.cpp:226] pool1 needs backward computation.
I0523 07:55:53.576546 24595 net.cpp:226] relu1 needs backward computation.
I0523 07:55:53.576556 24595 net.cpp:226] conv1 needs backward computation.
I0523 07:55:53.576567 24595 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 07:55:53.576580 24595 net.cpp:228] data_hdf5 does not need backward computation.
I0523 07:55:53.576588 24595 net.cpp:270] This network produces output accuracy
I0523 07:55:53.576599 24595 net.cpp:270] This network produces output loss
I0523 07:55:53.576628 24595 net.cpp:283] Network initialization done.
I0523 07:55:53.576761 24595 solver.cpp:60] Solver scaffolding done.
I0523 07:55:53.577893 24595 caffe.cpp:212] Starting Optimization
I0523 07:55:53.577910 24595 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 07:55:53.577924 24595 solver.cpp:289] Learning Rate Policy: fixed
I0523 07:55:53.579156 24595 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 07:56:42.309033 24595 solver.cpp:409]     Test net output #0: accuracy = 0.122547
I0523 07:56:42.309195 24595 solver.cpp:409]     Test net output #1: loss = 2.39787 (* 1 = 2.39787 loss)
I0523 07:56:42.333345 24595 solver.cpp:237] Iteration 0, loss = 2.39848
I0523 07:56:42.333384 24595 solver.cpp:253]     Train net output #0: loss = 2.39848 (* 1 = 2.39848 loss)
I0523 07:56:42.333402 24595 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0523 07:56:51.621592 24595 solver.cpp:237] Iteration 300, loss = 2.18284
I0523 07:56:51.621634 24595 solver.cpp:253]     Train net output #0: loss = 2.18284 (* 1 = 2.18284 loss)
I0523 07:56:51.621656 24595 sgd_solver.cpp:106] Iteration 300, lr = 0.0035
I0523 07:57:00.911747 24595 solver.cpp:237] Iteration 600, loss = 2.14012
I0523 07:57:00.911784 24595 solver.cpp:253]     Train net output #0: loss = 2.14012 (* 1 = 2.14012 loss)
I0523 07:57:00.911799 24595 sgd_solver.cpp:106] Iteration 600, lr = 0.0035
I0523 07:57:10.202008 24595 solver.cpp:237] Iteration 900, loss = 2.05905
I0523 07:57:10.202044 24595 solver.cpp:253]     Train net output #0: loss = 2.05905 (* 1 = 2.05905 loss)
I0523 07:57:10.202066 24595 sgd_solver.cpp:106] Iteration 900, lr = 0.0035
I0523 07:57:19.491394 24595 solver.cpp:237] Iteration 1200, loss = 1.856
I0523 07:57:19.491556 24595 solver.cpp:253]     Train net output #0: loss = 1.856 (* 1 = 1.856 loss)
I0523 07:57:19.491571 24595 sgd_solver.cpp:106] Iteration 1200, lr = 0.0035
I0523 07:57:28.777221 24595 solver.cpp:237] Iteration 1500, loss = 1.89594
I0523 07:57:28.777256 24595 solver.cpp:253]     Train net output #0: loss = 1.89594 (* 1 = 1.89594 loss)
I0523 07:57:28.777274 24595 sgd_solver.cpp:106] Iteration 1500, lr = 0.0035
I0523 07:57:38.066305 24595 solver.cpp:237] Iteration 1800, loss = 1.77718
I0523 07:57:38.066341 24595 solver.cpp:253]     Train net output #0: loss = 1.77718 (* 1 = 1.77718 loss)
I0523 07:57:38.066357 24595 sgd_solver.cpp:106] Iteration 1800, lr = 0.0035
I0523 07:58:09.490262 24595 solver.cpp:237] Iteration 2100, loss = 1.57588
I0523 07:58:09.490422 24595 solver.cpp:253]     Train net output #0: loss = 1.57588 (* 1 = 1.57588 loss)
I0523 07:58:09.490437 24595 sgd_solver.cpp:106] Iteration 2100, lr = 0.0035
I0523 07:58:18.783354 24595 solver.cpp:237] Iteration 2400, loss = 1.384
I0523 07:58:18.783388 24595 solver.cpp:253]     Train net output #0: loss = 1.384 (* 1 = 1.384 loss)
I0523 07:58:18.783407 24595 sgd_solver.cpp:106] Iteration 2400, lr = 0.0035
I0523 07:58:28.076838 24595 solver.cpp:237] Iteration 2700, loss = 2.10752
I0523 07:58:28.076874 24595 solver.cpp:253]     Train net output #0: loss = 2.10752 (* 1 = 2.10752 loss)
I0523 07:58:28.076890 24595 sgd_solver.cpp:106] Iteration 2700, lr = 0.0035
I0523 07:58:37.343305 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_3000.caffemodel
I0523 07:58:37.406556 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_3000.solverstate
I0523 07:58:37.441373 24595 solver.cpp:237] Iteration 3000, loss = 1.82548
I0523 07:58:37.441414 24595 solver.cpp:253]     Train net output #0: loss = 1.82548 (* 1 = 1.82548 loss)
I0523 07:58:37.441431 24595 sgd_solver.cpp:106] Iteration 3000, lr = 0.0035
I0523 07:58:46.734835 24595 solver.cpp:237] Iteration 3300, loss = 1.61954
I0523 07:58:46.734977 24595 solver.cpp:253]     Train net output #0: loss = 1.61954 (* 1 = 1.61954 loss)
I0523 07:58:46.734990 24595 sgd_solver.cpp:106] Iteration 3300, lr = 0.0035
I0523 07:58:56.023170 24595 solver.cpp:237] Iteration 3600, loss = 1.39667
I0523 07:58:56.023205 24595 solver.cpp:253]     Train net output #0: loss = 1.39667 (* 1 = 1.39667 loss)
I0523 07:58:56.023222 24595 sgd_solver.cpp:106] Iteration 3600, lr = 0.0035
I0523 07:59:05.315186 24595 solver.cpp:237] Iteration 3900, loss = 1.42967
I0523 07:59:05.315230 24595 solver.cpp:253]     Train net output #0: loss = 1.42967 (* 1 = 1.42967 loss)
I0523 07:59:05.315246 24595 sgd_solver.cpp:106] Iteration 3900, lr = 0.0035
I0523 07:59:36.726877 24595 solver.cpp:237] Iteration 4200, loss = 1.31806
I0523 07:59:36.727033 24595 solver.cpp:253]     Train net output #0: loss = 1.31806 (* 1 = 1.31806 loss)
I0523 07:59:36.727049 24595 sgd_solver.cpp:106] Iteration 4200, lr = 0.0035
I0523 07:59:46.017936 24595 solver.cpp:237] Iteration 4500, loss = 1.49697
I0523 07:59:46.017971 24595 solver.cpp:253]     Train net output #0: loss = 1.49697 (* 1 = 1.49697 loss)
I0523 07:59:46.017987 24595 sgd_solver.cpp:106] Iteration 4500, lr = 0.0035
I0523 07:59:55.308339 24595 solver.cpp:237] Iteration 4800, loss = 1.54544
I0523 07:59:55.308380 24595 solver.cpp:253]     Train net output #0: loss = 1.54544 (* 1 = 1.54544 loss)
I0523 07:59:55.308398 24595 sgd_solver.cpp:106] Iteration 4800, lr = 0.0035
I0523 08:00:04.600447 24595 solver.cpp:237] Iteration 5100, loss = 1.58299
I0523 08:00:04.600483 24595 solver.cpp:253]     Train net output #0: loss = 1.58299 (* 1 = 1.58299 loss)
I0523 08:00:04.600500 24595 sgd_solver.cpp:106] Iteration 5100, lr = 0.0035
I0523 08:00:13.891890 24595 solver.cpp:237] Iteration 5400, loss = 1.53012
I0523 08:00:13.892046 24595 solver.cpp:253]     Train net output #0: loss = 1.53012 (* 1 = 1.53012 loss)
I0523 08:00:13.892060 24595 sgd_solver.cpp:106] Iteration 5400, lr = 0.0035
I0523 08:00:23.183276 24595 solver.cpp:237] Iteration 5700, loss = 1.19369
I0523 08:00:23.183311 24595 solver.cpp:253]     Train net output #0: loss = 1.19369 (* 1 = 1.19369 loss)
I0523 08:00:23.183328 24595 sgd_solver.cpp:106] Iteration 5700, lr = 0.0035
I0523 08:00:32.448974 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_6000.caffemodel
I0523 08:00:32.508067 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_6000.solverstate
I0523 08:00:32.533349 24595 solver.cpp:341] Iteration 6000, Testing net (#0)
I0523 08:01:20.287497 24595 solver.cpp:409]     Test net output #0: accuracy = 0.805857
I0523 08:01:20.287657 24595 solver.cpp:409]     Test net output #1: loss = 0.632869 (* 1 = 0.632869 loss)
I0523 08:01:42.428387 24595 solver.cpp:237] Iteration 6000, loss = 1.51782
I0523 08:01:42.428442 24595 solver.cpp:253]     Train net output #0: loss = 1.51782 (* 1 = 1.51782 loss)
I0523 08:01:42.428457 24595 sgd_solver.cpp:106] Iteration 6000, lr = 0.0035
I0523 08:01:51.716481 24595 solver.cpp:237] Iteration 6300, loss = 1.31016
I0523 08:01:51.716634 24595 solver.cpp:253]     Train net output #0: loss = 1.31016 (* 1 = 1.31016 loss)
I0523 08:01:51.716647 24595 sgd_solver.cpp:106] Iteration 6300, lr = 0.0035
I0523 08:02:01.003131 24595 solver.cpp:237] Iteration 6600, loss = 1.47308
I0523 08:02:01.003167 24595 solver.cpp:253]     Train net output #0: loss = 1.47308 (* 1 = 1.47308 loss)
I0523 08:02:01.003185 24595 sgd_solver.cpp:106] Iteration 6600, lr = 0.0035
I0523 08:02:10.290900 24595 solver.cpp:237] Iteration 6900, loss = 1.37034
I0523 08:02:10.290935 24595 solver.cpp:253]     Train net output #0: loss = 1.37034 (* 1 = 1.37034 loss)
I0523 08:02:10.290952 24595 sgd_solver.cpp:106] Iteration 6900, lr = 0.0035
I0523 08:02:19.578949 24595 solver.cpp:237] Iteration 7200, loss = 1.40651
I0523 08:02:19.578996 24595 solver.cpp:253]     Train net output #0: loss = 1.40651 (* 1 = 1.40651 loss)
I0523 08:02:19.579015 24595 sgd_solver.cpp:106] Iteration 7200, lr = 0.0035
I0523 08:02:28.863402 24595 solver.cpp:237] Iteration 7500, loss = 1.11743
I0523 08:02:28.863539 24595 solver.cpp:253]     Train net output #0: loss = 1.11743 (* 1 = 1.11743 loss)
I0523 08:02:28.863554 24595 sgd_solver.cpp:106] Iteration 7500, lr = 0.0035
I0523 08:02:38.147958 24595 solver.cpp:237] Iteration 7800, loss = 1.41091
I0523 08:02:38.147992 24595 solver.cpp:253]     Train net output #0: loss = 1.41091 (* 1 = 1.41091 loss)
I0523 08:02:38.148010 24595 sgd_solver.cpp:106] Iteration 7800, lr = 0.0035
I0523 08:03:09.613049 24595 solver.cpp:237] Iteration 8100, loss = 1.48689
I0523 08:03:09.613224 24595 solver.cpp:253]     Train net output #0: loss = 1.48689 (* 1 = 1.48689 loss)
I0523 08:03:09.613240 24595 sgd_solver.cpp:106] Iteration 8100, lr = 0.0035
I0523 08:03:18.897003 24595 solver.cpp:237] Iteration 8400, loss = 1.56809
I0523 08:03:18.897038 24595 solver.cpp:253]     Train net output #0: loss = 1.56809 (* 1 = 1.56809 loss)
I0523 08:03:18.897055 24595 sgd_solver.cpp:106] Iteration 8400, lr = 0.0035
I0523 08:03:28.182232 24595 solver.cpp:237] Iteration 8700, loss = 1.24917
I0523 08:03:28.182268 24595 solver.cpp:253]     Train net output #0: loss = 1.24917 (* 1 = 1.24917 loss)
I0523 08:03:28.182284 24595 sgd_solver.cpp:106] Iteration 8700, lr = 0.0035
I0523 08:03:37.439754 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_9000.caffemodel
I0523 08:03:37.501794 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_9000.solverstate
I0523 08:03:37.538772 24595 solver.cpp:237] Iteration 9000, loss = 1.32485
I0523 08:03:37.538822 24595 solver.cpp:253]     Train net output #0: loss = 1.32485 (* 1 = 1.32485 loss)
I0523 08:03:37.538839 24595 sgd_solver.cpp:106] Iteration 9000, lr = 0.0035
I0523 08:03:46.827822 24595 solver.cpp:237] Iteration 9300, loss = 1.50822
I0523 08:03:46.827975 24595 solver.cpp:253]     Train net output #0: loss = 1.50822 (* 1 = 1.50822 loss)
I0523 08:03:46.827988 24595 sgd_solver.cpp:106] Iteration 9300, lr = 0.0035
I0523 08:03:56.113481 24595 solver.cpp:237] Iteration 9600, loss = 1.55404
I0523 08:03:56.113515 24595 solver.cpp:253]     Train net output #0: loss = 1.55404 (* 1 = 1.55404 loss)
I0523 08:03:56.113531 24595 sgd_solver.cpp:106] Iteration 9600, lr = 0.0035
I0523 08:04:05.400216 24595 solver.cpp:237] Iteration 9900, loss = 1.43167
I0523 08:04:05.400262 24595 solver.cpp:253]     Train net output #0: loss = 1.43167 (* 1 = 1.43167 loss)
I0523 08:04:05.400281 24595 sgd_solver.cpp:106] Iteration 9900, lr = 0.0035
I0523 08:04:36.822959 24595 solver.cpp:237] Iteration 10200, loss = 1.40768
I0523 08:04:36.823122 24595 solver.cpp:253]     Train net output #0: loss = 1.40768 (* 1 = 1.40768 loss)
I0523 08:04:36.823137 24595 sgd_solver.cpp:106] Iteration 10200, lr = 0.0035
I0523 08:04:46.108719 24595 solver.cpp:237] Iteration 10500, loss = 1.41302
I0523 08:04:46.108754 24595 solver.cpp:253]     Train net output #0: loss = 1.41302 (* 1 = 1.41302 loss)
I0523 08:04:46.108772 24595 sgd_solver.cpp:106] Iteration 10500, lr = 0.0035
I0523 08:04:55.392264 24595 solver.cpp:237] Iteration 10800, loss = 1.22568
I0523 08:04:55.392302 24595 solver.cpp:253]     Train net output #0: loss = 1.22568 (* 1 = 1.22568 loss)
I0523 08:04:55.392324 24595 sgd_solver.cpp:106] Iteration 10800, lr = 0.0035
I0523 08:05:04.676004 24595 solver.cpp:237] Iteration 11100, loss = 1.12292
I0523 08:05:04.676039 24595 solver.cpp:253]     Train net output #0: loss = 1.12292 (* 1 = 1.12292 loss)
I0523 08:05:04.676055 24595 sgd_solver.cpp:106] Iteration 11100, lr = 0.0035
I0523 08:05:13.960759 24595 solver.cpp:237] Iteration 11400, loss = 1.38467
I0523 08:05:13.960908 24595 solver.cpp:253]     Train net output #0: loss = 1.38467 (* 1 = 1.38467 loss)
I0523 08:05:13.960923 24595 sgd_solver.cpp:106] Iteration 11400, lr = 0.0035
I0523 08:05:23.249009 24595 solver.cpp:237] Iteration 11700, loss = 1.39704
I0523 08:05:23.249045 24595 solver.cpp:253]     Train net output #0: loss = 1.39704 (* 1 = 1.39704 loss)
I0523 08:05:23.249063 24595 sgd_solver.cpp:106] Iteration 11700, lr = 0.0035
I0523 08:05:32.507944 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_12000.caffemodel
I0523 08:05:32.569515 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_12000.solverstate
I0523 08:05:32.596945 24595 solver.cpp:341] Iteration 12000, Testing net (#0)
I0523 08:06:41.183557 24595 solver.cpp:409]     Test net output #0: accuracy = 0.845515
I0523 08:06:41.183728 24595 solver.cpp:409]     Test net output #1: loss = 0.548812 (* 1 = 0.548812 loss)
I0523 08:07:03.393544 24595 solver.cpp:237] Iteration 12000, loss = 1.34273
I0523 08:07:03.393599 24595 solver.cpp:253]     Train net output #0: loss = 1.34273 (* 1 = 1.34273 loss)
I0523 08:07:03.393613 24595 sgd_solver.cpp:106] Iteration 12000, lr = 0.0035
I0523 08:07:12.695647 24595 solver.cpp:237] Iteration 12300, loss = 1.00108
I0523 08:07:12.695801 24595 solver.cpp:253]     Train net output #0: loss = 1.00108 (* 1 = 1.00108 loss)
I0523 08:07:12.695814 24595 sgd_solver.cpp:106] Iteration 12300, lr = 0.0035
I0523 08:07:21.994446 24595 solver.cpp:237] Iteration 12600, loss = 1.47088
I0523 08:07:21.994493 24595 solver.cpp:253]     Train net output #0: loss = 1.47088 (* 1 = 1.47088 loss)
I0523 08:07:21.994510 24595 sgd_solver.cpp:106] Iteration 12600, lr = 0.0035
I0523 08:07:31.292466 24595 solver.cpp:237] Iteration 12900, loss = 1.27918
I0523 08:07:31.292502 24595 solver.cpp:253]     Train net output #0: loss = 1.27918 (* 1 = 1.27918 loss)
I0523 08:07:31.292518 24595 sgd_solver.cpp:106] Iteration 12900, lr = 0.0035
I0523 08:07:40.591956 24595 solver.cpp:237] Iteration 13200, loss = 1.37911
I0523 08:07:40.591991 24595 solver.cpp:253]     Train net output #0: loss = 1.37911 (* 1 = 1.37911 loss)
I0523 08:07:40.592007 24595 sgd_solver.cpp:106] Iteration 13200, lr = 0.0035
I0523 08:07:49.896371 24595 solver.cpp:237] Iteration 13500, loss = 1.44243
I0523 08:07:49.896524 24595 solver.cpp:253]     Train net output #0: loss = 1.44243 (* 1 = 1.44243 loss)
I0523 08:07:49.896538 24595 sgd_solver.cpp:106] Iteration 13500, lr = 0.0035
I0523 08:07:59.194442 24595 solver.cpp:237] Iteration 13800, loss = 1.07782
I0523 08:07:59.194475 24595 solver.cpp:253]     Train net output #0: loss = 1.07782 (* 1 = 1.07782 loss)
I0523 08:07:59.194494 24595 sgd_solver.cpp:106] Iteration 13800, lr = 0.0035
I0523 08:08:30.693464 24595 solver.cpp:237] Iteration 14100, loss = 1.0319
I0523 08:08:30.693631 24595 solver.cpp:253]     Train net output #0: loss = 1.0319 (* 1 = 1.0319 loss)
I0523 08:08:30.693647 24595 sgd_solver.cpp:106] Iteration 14100, lr = 0.0035
I0523 08:08:39.989276 24595 solver.cpp:237] Iteration 14400, loss = 1.25396
I0523 08:08:39.989322 24595 solver.cpp:253]     Train net output #0: loss = 1.25396 (* 1 = 1.25396 loss)
I0523 08:08:39.989339 24595 sgd_solver.cpp:106] Iteration 14400, lr = 0.0035
I0523 08:08:49.288571 24595 solver.cpp:237] Iteration 14700, loss = 1.08688
I0523 08:08:49.288606 24595 solver.cpp:253]     Train net output #0: loss = 1.08688 (* 1 = 1.08688 loss)
I0523 08:08:49.288620 24595 sgd_solver.cpp:106] Iteration 14700, lr = 0.0035
I0523 08:08:58.559439 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_15000.caffemodel
I0523 08:08:58.621037 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_15000.solverstate
I0523 08:08:58.658440 24595 solver.cpp:237] Iteration 15000, loss = 1.14124
I0523 08:08:58.658485 24595 solver.cpp:253]     Train net output #0: loss = 1.14124 (* 1 = 1.14124 loss)
I0523 08:08:58.658502 24595 sgd_solver.cpp:106] Iteration 15000, lr = 0.0035
I0523 08:09:07.953832 24595 solver.cpp:237] Iteration 15300, loss = 1.35358
I0523 08:09:07.953979 24595 solver.cpp:253]     Train net output #0: loss = 1.35358 (* 1 = 1.35358 loss)
I0523 08:09:07.953994 24595 sgd_solver.cpp:106] Iteration 15300, lr = 0.0035
I0523 08:09:17.254359 24595 solver.cpp:237] Iteration 15600, loss = 1.2364
I0523 08:09:17.254393 24595 solver.cpp:253]     Train net output #0: loss = 1.2364 (* 1 = 1.2364 loss)
I0523 08:09:17.254408 24595 sgd_solver.cpp:106] Iteration 15600, lr = 0.0035
I0523 08:09:26.556097 24595 solver.cpp:237] Iteration 15900, loss = 1.39565
I0523 08:09:26.556144 24595 solver.cpp:253]     Train net output #0: loss = 1.39565 (* 1 = 1.39565 loss)
I0523 08:09:26.556159 24595 sgd_solver.cpp:106] Iteration 15900, lr = 0.0035
I0523 08:09:58.028184 24595 solver.cpp:237] Iteration 16200, loss = 1.20628
I0523 08:09:58.028362 24595 solver.cpp:253]     Train net output #0: loss = 1.20628 (* 1 = 1.20628 loss)
I0523 08:09:58.028376 24595 sgd_solver.cpp:106] Iteration 16200, lr = 0.0035
I0523 08:10:07.328559 24595 solver.cpp:237] Iteration 16500, loss = 1.04449
I0523 08:10:07.328595 24595 solver.cpp:253]     Train net output #0: loss = 1.04449 (* 1 = 1.04449 loss)
I0523 08:10:07.328609 24595 sgd_solver.cpp:106] Iteration 16500, lr = 0.0035
I0523 08:10:16.630944 24595 solver.cpp:237] Iteration 16800, loss = 1.17705
I0523 08:10:16.630991 24595 solver.cpp:253]     Train net output #0: loss = 1.17705 (* 1 = 1.17705 loss)
I0523 08:10:16.631009 24595 sgd_solver.cpp:106] Iteration 16800, lr = 0.0035
I0523 08:10:25.932862 24595 solver.cpp:237] Iteration 17100, loss = 1.40153
I0523 08:10:25.932898 24595 solver.cpp:253]     Train net output #0: loss = 1.40153 (* 1 = 1.40153 loss)
I0523 08:10:25.932915 24595 sgd_solver.cpp:106] Iteration 17100, lr = 0.0035
I0523 08:10:35.234702 24595 solver.cpp:237] Iteration 17400, loss = 1.24644
I0523 08:10:35.234846 24595 solver.cpp:253]     Train net output #0: loss = 1.24644 (* 1 = 1.24644 loss)
I0523 08:10:35.234860 24595 sgd_solver.cpp:106] Iteration 17400, lr = 0.0035
I0523 08:10:44.538619 24595 solver.cpp:237] Iteration 17700, loss = 1.13064
I0523 08:10:44.538666 24595 solver.cpp:253]     Train net output #0: loss = 1.13064 (* 1 = 1.13064 loss)
I0523 08:10:44.538683 24595 sgd_solver.cpp:106] Iteration 17700, lr = 0.0035
I0523 08:10:53.811403 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_18000.caffemodel
I0523 08:10:53.871145 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_18000.solverstate
I0523 08:10:53.897524 24595 solver.cpp:341] Iteration 18000, Testing net (#0)
I0523 08:11:41.404809 24595 solver.cpp:409]     Test net output #0: accuracy = 0.862233
I0523 08:11:41.404980 24595 solver.cpp:409]     Test net output #1: loss = 0.443969 (* 1 = 0.443969 loss)
I0523 08:12:03.531648 24595 solver.cpp:237] Iteration 18000, loss = 1.05723
I0523 08:12:03.531700 24595 solver.cpp:253]     Train net output #0: loss = 1.05723 (* 1 = 1.05723 loss)
I0523 08:12:03.531715 24595 sgd_solver.cpp:106] Iteration 18000, lr = 0.0035
I0523 08:12:12.813971 24595 solver.cpp:237] Iteration 18300, loss = 1.19785
I0523 08:12:12.814138 24595 solver.cpp:253]     Train net output #0: loss = 1.19785 (* 1 = 1.19785 loss)
I0523 08:12:12.814152 24595 sgd_solver.cpp:106] Iteration 18300, lr = 0.0035
I0523 08:12:22.096851 24595 solver.cpp:237] Iteration 18600, loss = 1.19655
I0523 08:12:22.096897 24595 solver.cpp:253]     Train net output #0: loss = 1.19655 (* 1 = 1.19655 loss)
I0523 08:12:22.096911 24595 sgd_solver.cpp:106] Iteration 18600, lr = 0.0035
I0523 08:12:31.382902 24595 solver.cpp:237] Iteration 18900, loss = 1.26127
I0523 08:12:31.382938 24595 solver.cpp:253]     Train net output #0: loss = 1.26127 (* 1 = 1.26127 loss)
I0523 08:12:31.382954 24595 sgd_solver.cpp:106] Iteration 18900, lr = 0.0035
I0523 08:12:40.663643 24595 solver.cpp:237] Iteration 19200, loss = 1.04844
I0523 08:12:40.663679 24595 solver.cpp:253]     Train net output #0: loss = 1.04844 (* 1 = 1.04844 loss)
I0523 08:12:40.663696 24595 sgd_solver.cpp:106] Iteration 19200, lr = 0.0035
I0523 08:12:49.946434 24595 solver.cpp:237] Iteration 19500, loss = 1.3912
I0523 08:12:49.946583 24595 solver.cpp:253]     Train net output #0: loss = 1.3912 (* 1 = 1.3912 loss)
I0523 08:12:49.946597 24595 sgd_solver.cpp:106] Iteration 19500, lr = 0.0035
I0523 08:12:59.226632 24595 solver.cpp:237] Iteration 19800, loss = 1.03676
I0523 08:12:59.226667 24595 solver.cpp:253]     Train net output #0: loss = 1.03676 (* 1 = 1.03676 loss)
I0523 08:12:59.226681 24595 sgd_solver.cpp:106] Iteration 19800, lr = 0.0035
I0523 08:13:30.711724 24595 solver.cpp:237] Iteration 20100, loss = 1.35163
I0523 08:13:30.711895 24595 solver.cpp:253]     Train net output #0: loss = 1.35163 (* 1 = 1.35163 loss)
I0523 08:13:30.711911 24595 sgd_solver.cpp:106] Iteration 20100, lr = 0.0035
I0523 08:13:39.995295 24595 solver.cpp:237] Iteration 20400, loss = 1.37964
I0523 08:13:39.995337 24595 solver.cpp:253]     Train net output #0: loss = 1.37964 (* 1 = 1.37964 loss)
I0523 08:13:39.995355 24595 sgd_solver.cpp:106] Iteration 20400, lr = 0.0035
I0523 08:13:49.280127 24595 solver.cpp:237] Iteration 20700, loss = 1.25848
I0523 08:13:49.280163 24595 solver.cpp:253]     Train net output #0: loss = 1.25848 (* 1 = 1.25848 loss)
I0523 08:13:49.280179 24595 sgd_solver.cpp:106] Iteration 20700, lr = 0.0035
I0523 08:13:58.532335 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_21000.caffemodel
I0523 08:13:58.591940 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_21000.solverstate
I0523 08:13:58.628020 24595 solver.cpp:237] Iteration 21000, loss = 1.12529
I0523 08:13:58.628064 24595 solver.cpp:253]     Train net output #0: loss = 1.12529 (* 1 = 1.12529 loss)
I0523 08:13:58.628083 24595 sgd_solver.cpp:106] Iteration 21000, lr = 0.0035
I0523 08:14:07.911149 24595 solver.cpp:237] Iteration 21300, loss = 1.24151
I0523 08:14:07.911298 24595 solver.cpp:253]     Train net output #0: loss = 1.24151 (* 1 = 1.24151 loss)
I0523 08:14:07.911311 24595 sgd_solver.cpp:106] Iteration 21300, lr = 0.0035
I0523 08:14:17.194149 24595 solver.cpp:237] Iteration 21600, loss = 1.30761
I0523 08:14:17.194182 24595 solver.cpp:253]     Train net output #0: loss = 1.30761 (* 1 = 1.30761 loss)
I0523 08:14:17.194200 24595 sgd_solver.cpp:106] Iteration 21600, lr = 0.0035
I0523 08:14:26.475574 24595 solver.cpp:237] Iteration 21900, loss = 1.13331
I0523 08:14:26.475620 24595 solver.cpp:253]     Train net output #0: loss = 1.13331 (* 1 = 1.13331 loss)
I0523 08:14:26.475633 24595 sgd_solver.cpp:106] Iteration 21900, lr = 0.0035
I0523 08:14:57.979158 24595 solver.cpp:237] Iteration 22200, loss = 1.26059
I0523 08:14:57.979321 24595 solver.cpp:253]     Train net output #0: loss = 1.26059 (* 1 = 1.26059 loss)
I0523 08:14:57.979334 24595 sgd_solver.cpp:106] Iteration 22200, lr = 0.0035
I0523 08:15:07.267299 24595 solver.cpp:237] Iteration 22500, loss = 1.24098
I0523 08:15:07.267333 24595 solver.cpp:253]     Train net output #0: loss = 1.24098 (* 1 = 1.24098 loss)
I0523 08:15:07.267352 24595 sgd_solver.cpp:106] Iteration 22500, lr = 0.0035
I0523 08:15:16.551911 24595 solver.cpp:237] Iteration 22800, loss = 1.15515
I0523 08:15:16.551957 24595 solver.cpp:253]     Train net output #0: loss = 1.15515 (* 1 = 1.15515 loss)
I0523 08:15:16.551975 24595 sgd_solver.cpp:106] Iteration 22800, lr = 0.0035
I0523 08:15:25.836113 24595 solver.cpp:237] Iteration 23100, loss = 1.31035
I0523 08:15:25.836148 24595 solver.cpp:253]     Train net output #0: loss = 1.31035 (* 1 = 1.31035 loss)
I0523 08:15:25.836164 24595 sgd_solver.cpp:106] Iteration 23100, lr = 0.0035
I0523 08:15:35.118522 24595 solver.cpp:237] Iteration 23400, loss = 1.3191
I0523 08:15:35.118666 24595 solver.cpp:253]     Train net output #0: loss = 1.3191 (* 1 = 1.3191 loss)
I0523 08:15:35.118680 24595 sgd_solver.cpp:106] Iteration 23400, lr = 0.0035
I0523 08:15:44.400542 24595 solver.cpp:237] Iteration 23700, loss = 1.2125
I0523 08:15:44.400581 24595 solver.cpp:253]     Train net output #0: loss = 1.2125 (* 1 = 1.2125 loss)
I0523 08:15:44.400604 24595 sgd_solver.cpp:106] Iteration 23700, lr = 0.0035
I0523 08:15:53.651428 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_24000.caffemodel
I0523 08:15:53.716135 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_24000.solverstate
I0523 08:15:53.742385 24595 solver.cpp:341] Iteration 24000, Testing net (#0)
I0523 08:17:02.355542 24595 solver.cpp:409]     Test net output #0: accuracy = 0.872257
I0523 08:17:02.355715 24595 solver.cpp:409]     Test net output #1: loss = 0.403155 (* 1 = 0.403155 loss)
I0523 08:17:24.566998 24595 solver.cpp:237] Iteration 24000, loss = 1.24977
I0523 08:17:24.567049 24595 solver.cpp:253]     Train net output #0: loss = 1.24977 (* 1 = 1.24977 loss)
I0523 08:17:24.567064 24595 sgd_solver.cpp:106] Iteration 24000, lr = 0.0035
I0523 08:17:33.860864 24595 solver.cpp:237] Iteration 24300, loss = 1.22619
I0523 08:17:33.861019 24595 solver.cpp:253]     Train net output #0: loss = 1.22619 (* 1 = 1.22619 loss)
I0523 08:17:33.861033 24595 sgd_solver.cpp:106] Iteration 24300, lr = 0.0035
I0523 08:17:43.154577 24595 solver.cpp:237] Iteration 24600, loss = 1.05002
I0523 08:17:43.154623 24595 solver.cpp:253]     Train net output #0: loss = 1.05002 (* 1 = 1.05002 loss)
I0523 08:17:43.154639 24595 sgd_solver.cpp:106] Iteration 24600, lr = 0.0035
I0523 08:17:52.450422 24595 solver.cpp:237] Iteration 24900, loss = 1.09577
I0523 08:17:52.450458 24595 solver.cpp:253]     Train net output #0: loss = 1.09577 (* 1 = 1.09577 loss)
I0523 08:17:52.450474 24595 sgd_solver.cpp:106] Iteration 24900, lr = 0.0035
I0523 08:18:01.746320 24595 solver.cpp:237] Iteration 25200, loss = 1.19438
I0523 08:18:01.746356 24595 solver.cpp:253]     Train net output #0: loss = 1.19438 (* 1 = 1.19438 loss)
I0523 08:18:01.746368 24595 sgd_solver.cpp:106] Iteration 25200, lr = 0.0035
I0523 08:18:11.044435 24595 solver.cpp:237] Iteration 25500, loss = 1.44527
I0523 08:18:11.044608 24595 solver.cpp:253]     Train net output #0: loss = 1.44527 (* 1 = 1.44527 loss)
I0523 08:18:11.044622 24595 sgd_solver.cpp:106] Iteration 25500, lr = 0.0035
I0523 08:18:20.334241 24595 solver.cpp:237] Iteration 25800, loss = 1.10207
I0523 08:18:20.334275 24595 solver.cpp:253]     Train net output #0: loss = 1.10207 (* 1 = 1.10207 loss)
I0523 08:18:20.334292 24595 sgd_solver.cpp:106] Iteration 25800, lr = 0.0035
I0523 08:18:51.857554 24595 solver.cpp:237] Iteration 26100, loss = 1.28446
I0523 08:18:51.857722 24595 solver.cpp:253]     Train net output #0: loss = 1.28446 (* 1 = 1.28446 loss)
I0523 08:18:51.857736 24595 sgd_solver.cpp:106] Iteration 26100, lr = 0.0035
I0523 08:19:01.148341 24595 solver.cpp:237] Iteration 26400, loss = 1.64136
I0523 08:19:01.148385 24595 solver.cpp:253]     Train net output #0: loss = 1.64136 (* 1 = 1.64136 loss)
I0523 08:19:01.148399 24595 sgd_solver.cpp:106] Iteration 26400, lr = 0.0035
I0523 08:19:10.441612 24595 solver.cpp:237] Iteration 26700, loss = 1.15448
I0523 08:19:10.441648 24595 solver.cpp:253]     Train net output #0: loss = 1.15448 (* 1 = 1.15448 loss)
I0523 08:19:10.441664 24595 sgd_solver.cpp:106] Iteration 26700, lr = 0.0035
I0523 08:19:19.701205 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_27000.caffemodel
I0523 08:19:19.767452 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_27000.solverstate
I0523 08:19:19.805826 24595 solver.cpp:237] Iteration 27000, loss = 1.49349
I0523 08:19:19.805876 24595 solver.cpp:253]     Train net output #0: loss = 1.49349 (* 1 = 1.49349 loss)
I0523 08:19:19.805891 24595 sgd_solver.cpp:106] Iteration 27000, lr = 0.0035
I0523 08:19:29.099097 24595 solver.cpp:237] Iteration 27300, loss = 1.21742
I0523 08:19:29.099258 24595 solver.cpp:253]     Train net output #0: loss = 1.21742 (* 1 = 1.21742 loss)
I0523 08:19:29.099272 24595 sgd_solver.cpp:106] Iteration 27300, lr = 0.0035
I0523 08:19:38.395627 24595 solver.cpp:237] Iteration 27600, loss = 1.20921
I0523 08:19:38.395663 24595 solver.cpp:253]     Train net output #0: loss = 1.20921 (* 1 = 1.20921 loss)
I0523 08:19:38.395679 24595 sgd_solver.cpp:106] Iteration 27600, lr = 0.0035
I0523 08:19:47.691839 24595 solver.cpp:237] Iteration 27900, loss = 1.03082
I0523 08:19:47.691884 24595 solver.cpp:253]     Train net output #0: loss = 1.03082 (* 1 = 1.03082 loss)
I0523 08:19:47.691902 24595 sgd_solver.cpp:106] Iteration 27900, lr = 0.0035
I0523 08:20:19.209810 24595 solver.cpp:237] Iteration 28200, loss = 1.07637
I0523 08:20:19.209985 24595 solver.cpp:253]     Train net output #0: loss = 1.07637 (* 1 = 1.07637 loss)
I0523 08:20:19.210000 24595 sgd_solver.cpp:106] Iteration 28200, lr = 0.0035
I0523 08:20:28.501868 24595 solver.cpp:237] Iteration 28500, loss = 1.22604
I0523 08:20:28.501902 24595 solver.cpp:253]     Train net output #0: loss = 1.22604 (* 1 = 1.22604 loss)
I0523 08:20:28.501919 24595 sgd_solver.cpp:106] Iteration 28500, lr = 0.0035
I0523 08:20:37.793709 24595 solver.cpp:237] Iteration 28800, loss = 1.34352
I0523 08:20:37.793754 24595 solver.cpp:253]     Train net output #0: loss = 1.34352 (* 1 = 1.34352 loss)
I0523 08:20:37.793774 24595 sgd_solver.cpp:106] Iteration 28800, lr = 0.0035
I0523 08:20:47.092092 24595 solver.cpp:237] Iteration 29100, loss = 1.50637
I0523 08:20:47.092128 24595 solver.cpp:253]     Train net output #0: loss = 1.50637 (* 1 = 1.50637 loss)
I0523 08:20:47.092144 24595 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035
I0523 08:20:56.384757 24595 solver.cpp:237] Iteration 29400, loss = 1.21216
I0523 08:20:56.384904 24595 solver.cpp:253]     Train net output #0: loss = 1.21216 (* 1 = 1.21216 loss)
I0523 08:20:56.384917 24595 sgd_solver.cpp:106] Iteration 29400, lr = 0.0035
I0523 08:21:05.678367 24595 solver.cpp:237] Iteration 29700, loss = 1.52822
I0523 08:21:05.678414 24595 solver.cpp:253]     Train net output #0: loss = 1.52822 (* 1 = 1.52822 loss)
I0523 08:21:05.678431 24595 sgd_solver.cpp:106] Iteration 29700, lr = 0.0035
I0523 08:21:14.942312 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_30000.caffemodel
I0523 08:21:15.003854 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_30000.solverstate
I0523 08:21:15.032488 24595 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 08:22:02.778372 24595 solver.cpp:409]     Test net output #0: accuracy = 0.880261
I0523 08:22:02.778533 24595 solver.cpp:409]     Test net output #1: loss = 0.400176 (* 1 = 0.400176 loss)
I0523 08:22:23.687315 24595 solver.cpp:237] Iteration 30000, loss = 1.15619
I0523 08:22:23.687367 24595 solver.cpp:253]     Train net output #0: loss = 1.15619 (* 1 = 1.15619 loss)
I0523 08:22:23.687386 24595 sgd_solver.cpp:106] Iteration 30000, lr = 0.0035
I0523 08:22:32.972820 24595 solver.cpp:237] Iteration 30300, loss = 0.950234
I0523 08:22:32.972975 24595 solver.cpp:253]     Train net output #0: loss = 0.950234 (* 1 = 0.950234 loss)
I0523 08:22:32.972990 24595 sgd_solver.cpp:106] Iteration 30300, lr = 0.0035
I0523 08:22:42.259737 24595 solver.cpp:237] Iteration 30600, loss = 1.07413
I0523 08:22:42.259785 24595 solver.cpp:253]     Train net output #0: loss = 1.07413 (* 1 = 1.07413 loss)
I0523 08:22:42.259799 24595 sgd_solver.cpp:106] Iteration 30600, lr = 0.0035
I0523 08:22:51.558984 24595 solver.cpp:237] Iteration 30900, loss = 1.28798
I0523 08:22:51.559020 24595 solver.cpp:253]     Train net output #0: loss = 1.28798 (* 1 = 1.28798 loss)
I0523 08:22:51.559036 24595 sgd_solver.cpp:106] Iteration 30900, lr = 0.0035
I0523 08:23:00.858602 24595 solver.cpp:237] Iteration 31200, loss = 1.29014
I0523 08:23:00.858638 24595 solver.cpp:253]     Train net output #0: loss = 1.29014 (* 1 = 1.29014 loss)
I0523 08:23:00.858654 24595 sgd_solver.cpp:106] Iteration 31200, lr = 0.0035
I0523 08:23:10.157228 24595 solver.cpp:237] Iteration 31500, loss = 1.07762
I0523 08:23:10.157390 24595 solver.cpp:253]     Train net output #0: loss = 1.07762 (* 1 = 1.07762 loss)
I0523 08:23:10.157404 24595 sgd_solver.cpp:106] Iteration 31500, lr = 0.0035
I0523 08:23:19.457110 24595 solver.cpp:237] Iteration 31800, loss = 1.44569
I0523 08:23:19.457145 24595 solver.cpp:253]     Train net output #0: loss = 1.44569 (* 1 = 1.44569 loss)
I0523 08:23:19.457159 24595 sgd_solver.cpp:106] Iteration 31800, lr = 0.0035
I0523 08:23:49.631337 24595 solver.cpp:237] Iteration 32100, loss = 1.22498
I0523 08:23:49.631516 24595 solver.cpp:253]     Train net output #0: loss = 1.22498 (* 1 = 1.22498 loss)
I0523 08:23:49.631531 24595 sgd_solver.cpp:106] Iteration 32100, lr = 0.0035
I0523 08:23:58.932653 24595 solver.cpp:237] Iteration 32400, loss = 1.23072
I0523 08:23:58.932696 24595 solver.cpp:253]     Train net output #0: loss = 1.23072 (* 1 = 1.23072 loss)
I0523 08:23:58.932716 24595 sgd_solver.cpp:106] Iteration 32400, lr = 0.0035
I0523 08:24:08.228457 24595 solver.cpp:237] Iteration 32700, loss = 1.29388
I0523 08:24:08.228492 24595 solver.cpp:253]     Train net output #0: loss = 1.29388 (* 1 = 1.29388 loss)
I0523 08:24:08.228509 24595 sgd_solver.cpp:106] Iteration 32700, lr = 0.0035
I0523 08:24:17.497927 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_33000.caffemodel
I0523 08:24:17.556967 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_33000.solverstate
I0523 08:24:17.592869 24595 solver.cpp:237] Iteration 33000, loss = 1.27504
I0523 08:24:17.592913 24595 solver.cpp:253]     Train net output #0: loss = 1.27504 (* 1 = 1.27504 loss)
I0523 08:24:17.592928 24595 sgd_solver.cpp:106] Iteration 33000, lr = 0.0035
I0523 08:24:26.893447 24595 solver.cpp:237] Iteration 33300, loss = 1.20093
I0523 08:24:26.893620 24595 solver.cpp:253]     Train net output #0: loss = 1.20093 (* 1 = 1.20093 loss)
I0523 08:24:26.893635 24595 sgd_solver.cpp:106] Iteration 33300, lr = 0.0035
I0523 08:24:36.189937 24595 solver.cpp:237] Iteration 33600, loss = 1.31642
I0523 08:24:36.189972 24595 solver.cpp:253]     Train net output #0: loss = 1.31642 (* 1 = 1.31642 loss)
I0523 08:24:36.189990 24595 sgd_solver.cpp:106] Iteration 33600, lr = 0.0035
I0523 08:24:45.486974 24595 solver.cpp:237] Iteration 33900, loss = 1.03077
I0523 08:24:45.487010 24595 solver.cpp:253]     Train net output #0: loss = 1.03077 (* 1 = 1.03077 loss)
I0523 08:24:45.487025 24595 sgd_solver.cpp:106] Iteration 33900, lr = 0.0035
I0523 08:25:15.664386 24595 solver.cpp:237] Iteration 34200, loss = 1.22107
I0523 08:25:15.664556 24595 solver.cpp:253]     Train net output #0: loss = 1.22107 (* 1 = 1.22107 loss)
I0523 08:25:15.664572 24595 sgd_solver.cpp:106] Iteration 34200, lr = 0.0035
I0523 08:25:24.960023 24595 solver.cpp:237] Iteration 34500, loss = 1.13568
I0523 08:25:24.960058 24595 solver.cpp:253]     Train net output #0: loss = 1.13568 (* 1 = 1.13568 loss)
I0523 08:25:24.960077 24595 sgd_solver.cpp:106] Iteration 34500, lr = 0.0035
I0523 08:25:34.256052 24595 solver.cpp:237] Iteration 34800, loss = 1.42013
I0523 08:25:34.256088 24595 solver.cpp:253]     Train net output #0: loss = 1.42013 (* 1 = 1.42013 loss)
I0523 08:25:34.256101 24595 sgd_solver.cpp:106] Iteration 34800, lr = 0.0035
I0523 08:25:43.560750 24595 solver.cpp:237] Iteration 35100, loss = 1.28806
I0523 08:25:43.560794 24595 solver.cpp:253]     Train net output #0: loss = 1.28806 (* 1 = 1.28806 loss)
I0523 08:25:43.560811 24595 sgd_solver.cpp:106] Iteration 35100, lr = 0.0035
I0523 08:25:52.859589 24595 solver.cpp:237] Iteration 35400, loss = 0.92867
I0523 08:25:52.859733 24595 solver.cpp:253]     Train net output #0: loss = 0.92867 (* 1 = 0.92867 loss)
I0523 08:25:52.859747 24595 sgd_solver.cpp:106] Iteration 35400, lr = 0.0035
I0523 08:26:02.159229 24595 solver.cpp:237] Iteration 35700, loss = 1.17929
I0523 08:26:02.159271 24595 solver.cpp:253]     Train net output #0: loss = 1.17929 (* 1 = 1.17929 loss)
I0523 08:26:02.159289 24595 sgd_solver.cpp:106] Iteration 35700, lr = 0.0035
I0523 08:26:11.426381 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_36000.caffemodel
I0523 08:26:11.485618 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_36000.solverstate
I0523 08:26:11.512258 24595 solver.cpp:341] Iteration 36000, Testing net (#0)
I0523 08:27:20.218688 24595 solver.cpp:409]     Test net output #0: accuracy = 0.879382
I0523 08:27:20.218864 24595 solver.cpp:409]     Test net output #1: loss = 0.37369 (* 1 = 0.37369 loss)
I0523 08:27:41.142276 24595 solver.cpp:237] Iteration 36000, loss = 0.956393
I0523 08:27:41.142328 24595 solver.cpp:253]     Train net output #0: loss = 0.956393 (* 1 = 0.956393 loss)
I0523 08:27:41.142343 24595 sgd_solver.cpp:106] Iteration 36000, lr = 0.0035
I0523 08:27:50.442205 24595 solver.cpp:237] Iteration 36300, loss = 1.16673
I0523 08:27:50.442366 24595 solver.cpp:253]     Train net output #0: loss = 1.16673 (* 1 = 1.16673 loss)
I0523 08:27:50.442380 24595 sgd_solver.cpp:106] Iteration 36300, lr = 0.0035
I0523 08:27:59.740200 24595 solver.cpp:237] Iteration 36600, loss = 1.14998
I0523 08:27:59.740234 24595 solver.cpp:253]     Train net output #0: loss = 1.14998 (* 1 = 1.14998 loss)
I0523 08:27:59.740252 24595 sgd_solver.cpp:106] Iteration 36600, lr = 0.0035
I0523 08:28:09.040246 24595 solver.cpp:237] Iteration 36900, loss = 1.29012
I0523 08:28:09.040292 24595 solver.cpp:253]     Train net output #0: loss = 1.29012 (* 1 = 1.29012 loss)
I0523 08:28:09.040310 24595 sgd_solver.cpp:106] Iteration 36900, lr = 0.0035
I0523 08:28:18.344321 24595 solver.cpp:237] Iteration 37200, loss = 1.18659
I0523 08:28:18.344357 24595 solver.cpp:253]     Train net output #0: loss = 1.18659 (* 1 = 1.18659 loss)
I0523 08:28:18.344372 24595 sgd_solver.cpp:106] Iteration 37200, lr = 0.0035
I0523 08:28:27.642344 24595 solver.cpp:237] Iteration 37500, loss = 1.16453
I0523 08:28:27.642493 24595 solver.cpp:253]     Train net output #0: loss = 1.16453 (* 1 = 1.16453 loss)
I0523 08:28:27.642508 24595 sgd_solver.cpp:106] Iteration 37500, lr = 0.0035
I0523 08:28:36.945379 24595 solver.cpp:237] Iteration 37800, loss = 1.1322
I0523 08:28:36.945418 24595 solver.cpp:253]     Train net output #0: loss = 1.1322 (* 1 = 1.1322 loss)
I0523 08:28:36.945439 24595 sgd_solver.cpp:106] Iteration 37800, lr = 0.0035
I0523 08:29:07.150902 24595 solver.cpp:237] Iteration 38100, loss = 1.38014
I0523 08:29:07.151070 24595 solver.cpp:253]     Train net output #0: loss = 1.38014 (* 1 = 1.38014 loss)
I0523 08:29:07.151087 24595 sgd_solver.cpp:106] Iteration 38100, lr = 0.0035
I0523 08:29:16.448951 24595 solver.cpp:237] Iteration 38400, loss = 1.16959
I0523 08:29:16.448984 24595 solver.cpp:253]     Train net output #0: loss = 1.16959 (* 1 = 1.16959 loss)
I0523 08:29:16.449002 24595 sgd_solver.cpp:106] Iteration 38400, lr = 0.0035
I0523 08:29:25.749287 24595 solver.cpp:237] Iteration 38700, loss = 1.1698
I0523 08:29:25.749333 24595 solver.cpp:253]     Train net output #0: loss = 1.1698 (* 1 = 1.1698 loss)
I0523 08:29:25.749346 24595 sgd_solver.cpp:106] Iteration 38700, lr = 0.0035
I0523 08:29:35.018132 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_39000.caffemodel
I0523 08:29:35.078896 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_39000.solverstate
I0523 08:29:35.115407 24595 solver.cpp:237] Iteration 39000, loss = 1.16131
I0523 08:29:35.115449 24595 solver.cpp:253]     Train net output #0: loss = 1.16131 (* 1 = 1.16131 loss)
I0523 08:29:35.115466 24595 sgd_solver.cpp:106] Iteration 39000, lr = 0.0035
I0523 08:29:44.416044 24595 solver.cpp:237] Iteration 39300, loss = 0.823475
I0523 08:29:44.416208 24595 solver.cpp:253]     Train net output #0: loss = 0.823475 (* 1 = 0.823475 loss)
I0523 08:29:44.416224 24595 sgd_solver.cpp:106] Iteration 39300, lr = 0.0035
I0523 08:29:53.721500 24595 solver.cpp:237] Iteration 39600, loss = 1.01483
I0523 08:29:53.721542 24595 solver.cpp:253]     Train net output #0: loss = 1.01483 (* 1 = 1.01483 loss)
I0523 08:29:53.721563 24595 sgd_solver.cpp:106] Iteration 39600, lr = 0.0035
I0523 08:30:03.023316 24595 solver.cpp:237] Iteration 39900, loss = 1.51107
I0523 08:30:03.023351 24595 solver.cpp:253]     Train net output #0: loss = 1.51107 (* 1 = 1.51107 loss)
I0523 08:30:03.023367 24595 sgd_solver.cpp:106] Iteration 39900, lr = 0.0035
I0523 08:30:33.206502 24595 solver.cpp:237] Iteration 40200, loss = 1.14682
I0523 08:30:33.206676 24595 solver.cpp:253]     Train net output #0: loss = 1.14682 (* 1 = 1.14682 loss)
I0523 08:30:33.206692 24595 sgd_solver.cpp:106] Iteration 40200, lr = 0.0035
I0523 08:30:42.509034 24595 solver.cpp:237] Iteration 40500, loss = 1.32757
I0523 08:30:42.509083 24595 solver.cpp:253]     Train net output #0: loss = 1.32757 (* 1 = 1.32757 loss)
I0523 08:30:42.509099 24595 sgd_solver.cpp:106] Iteration 40500, lr = 0.0035
I0523 08:30:51.805083 24595 solver.cpp:237] Iteration 40800, loss = 1.19139
I0523 08:30:51.805119 24595 solver.cpp:253]     Train net output #0: loss = 1.19139 (* 1 = 1.19139 loss)
I0523 08:30:51.805135 24595 sgd_solver.cpp:106] Iteration 40800, lr = 0.0035
I0523 08:31:01.101564 24595 solver.cpp:237] Iteration 41100, loss = 1.10883
I0523 08:31:01.101598 24595 solver.cpp:253]     Train net output #0: loss = 1.10883 (* 1 = 1.10883 loss)
I0523 08:31:01.101615 24595 sgd_solver.cpp:106] Iteration 41100, lr = 0.0035
I0523 08:31:10.403517 24595 solver.cpp:237] Iteration 41400, loss = 1.2121
I0523 08:31:10.403676 24595 solver.cpp:253]     Train net output #0: loss = 1.2121 (* 1 = 1.2121 loss)
I0523 08:31:10.403689 24595 sgd_solver.cpp:106] Iteration 41400, lr = 0.0035
I0523 08:31:19.701179 24595 solver.cpp:237] Iteration 41700, loss = 0.820086
I0523 08:31:19.701215 24595 solver.cpp:253]     Train net output #0: loss = 0.820085 (* 1 = 0.820085 loss)
I0523 08:31:19.701231 24595 sgd_solver.cpp:106] Iteration 41700, lr = 0.0035
I0523 08:31:28.974931 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_42000.caffemodel
I0523 08:31:29.034117 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_42000.solverstate
I0523 08:31:29.060855 24595 solver.cpp:341] Iteration 42000, Testing net (#0)
I0523 08:32:16.547448 24595 solver.cpp:409]     Test net output #0: accuracy = 0.880787
I0523 08:32:16.561254 24595 solver.cpp:409]     Test net output #1: loss = 0.391334 (* 1 = 0.391334 loss)
I0523 08:32:37.480875 24595 solver.cpp:237] Iteration 42000, loss = 1.05873
I0523 08:32:37.480929 24595 solver.cpp:253]     Train net output #0: loss = 1.05873 (* 1 = 1.05873 loss)
I0523 08:32:37.480943 24595 sgd_solver.cpp:106] Iteration 42000, lr = 0.0035
I0523 08:32:46.771044 24595 solver.cpp:237] Iteration 42300, loss = 0.931955
I0523 08:32:46.771209 24595 solver.cpp:253]     Train net output #0: loss = 0.931955 (* 1 = 0.931955 loss)
I0523 08:32:46.771224 24595 sgd_solver.cpp:106] Iteration 42300, lr = 0.0035
I0523 08:32:56.055630 24595 solver.cpp:237] Iteration 42600, loss = 1.41403
I0523 08:32:56.055665 24595 solver.cpp:253]     Train net output #0: loss = 1.41403 (* 1 = 1.41403 loss)
I0523 08:32:56.055680 24595 sgd_solver.cpp:106] Iteration 42600, lr = 0.0035
I0523 08:33:05.342486 24595 solver.cpp:237] Iteration 42900, loss = 0.994107
I0523 08:33:05.342522 24595 solver.cpp:253]     Train net output #0: loss = 0.994107 (* 1 = 0.994107 loss)
I0523 08:33:05.342536 24595 sgd_solver.cpp:106] Iteration 42900, lr = 0.0035
I0523 08:33:14.630806 24595 solver.cpp:237] Iteration 43200, loss = 0.968769
I0523 08:33:14.630856 24595 solver.cpp:253]     Train net output #0: loss = 0.968769 (* 1 = 0.968769 loss)
I0523 08:33:14.630870 24595 sgd_solver.cpp:106] Iteration 43200, lr = 0.0035
I0523 08:33:23.915249 24595 solver.cpp:237] Iteration 43500, loss = 1.15633
I0523 08:33:23.915412 24595 solver.cpp:253]     Train net output #0: loss = 1.15633 (* 1 = 1.15633 loss)
I0523 08:33:23.915426 24595 sgd_solver.cpp:106] Iteration 43500, lr = 0.0035
I0523 08:33:33.202224 24595 solver.cpp:237] Iteration 43800, loss = 0.98651
I0523 08:33:33.202265 24595 solver.cpp:253]     Train net output #0: loss = 0.98651 (* 1 = 0.98651 loss)
I0523 08:33:33.202282 24595 sgd_solver.cpp:106] Iteration 43800, lr = 0.0035
I0523 08:34:03.390113 24595 solver.cpp:237] Iteration 44100, loss = 1.28262
I0523 08:34:03.390287 24595 solver.cpp:253]     Train net output #0: loss = 1.28262 (* 1 = 1.28262 loss)
I0523 08:34:03.390305 24595 sgd_solver.cpp:106] Iteration 44100, lr = 0.0035
I0523 08:34:12.673202 24595 solver.cpp:237] Iteration 44400, loss = 1.09406
I0523 08:34:12.673236 24595 solver.cpp:253]     Train net output #0: loss = 1.09406 (* 1 = 1.09406 loss)
I0523 08:34:12.673252 24595 sgd_solver.cpp:106] Iteration 44400, lr = 0.0035
I0523 08:34:21.960777 24595 solver.cpp:237] Iteration 44700, loss = 1.10692
I0523 08:34:21.960822 24595 solver.cpp:253]     Train net output #0: loss = 1.10692 (* 1 = 1.10692 loss)
I0523 08:34:21.960839 24595 sgd_solver.cpp:106] Iteration 44700, lr = 0.0035
I0523 08:34:31.213109 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_45000.caffemodel
I0523 08:34:31.274909 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_45000.solverstate
I0523 08:34:31.312923 24595 solver.cpp:237] Iteration 45000, loss = 1.43173
I0523 08:34:31.312973 24595 solver.cpp:253]     Train net output #0: loss = 1.43173 (* 1 = 1.43173 loss)
I0523 08:34:31.312988 24595 sgd_solver.cpp:106] Iteration 45000, lr = 0.0035
I0523 08:34:40.594110 24595 solver.cpp:237] Iteration 45300, loss = 1.1687
I0523 08:34:40.594267 24595 solver.cpp:253]     Train net output #0: loss = 1.1687 (* 1 = 1.1687 loss)
I0523 08:34:40.594281 24595 sgd_solver.cpp:106] Iteration 45300, lr = 0.0035
I0523 08:34:49.874992 24595 solver.cpp:237] Iteration 45600, loss = 1.16621
I0523 08:34:49.875041 24595 solver.cpp:253]     Train net output #0: loss = 1.16621 (* 1 = 1.16621 loss)
I0523 08:34:49.875056 24595 sgd_solver.cpp:106] Iteration 45600, lr = 0.0035
I0523 08:34:59.160176 24595 solver.cpp:237] Iteration 45900, loss = 1.02545
I0523 08:34:59.160212 24595 solver.cpp:253]     Train net output #0: loss = 1.02545 (* 1 = 1.02545 loss)
I0523 08:34:59.160225 24595 sgd_solver.cpp:106] Iteration 45900, lr = 0.0035
I0523 08:35:29.331980 24595 solver.cpp:237] Iteration 46200, loss = 1.37876
I0523 08:35:29.332155 24595 solver.cpp:253]     Train net output #0: loss = 1.37876 (* 1 = 1.37876 loss)
I0523 08:35:29.332172 24595 sgd_solver.cpp:106] Iteration 46200, lr = 0.0035
I0523 08:35:38.615911 24595 solver.cpp:237] Iteration 46500, loss = 1.12039
I0523 08:35:38.615948 24595 solver.cpp:253]     Train net output #0: loss = 1.12039 (* 1 = 1.12039 loss)
I0523 08:35:38.615962 24595 sgd_solver.cpp:106] Iteration 46500, lr = 0.0035
I0523 08:35:47.900274 24595 solver.cpp:237] Iteration 46800, loss = 1.2058
I0523 08:35:47.900310 24595 solver.cpp:253]     Train net output #0: loss = 1.2058 (* 1 = 1.2058 loss)
I0523 08:35:47.900323 24595 sgd_solver.cpp:106] Iteration 46800, lr = 0.0035
I0523 08:35:57.184943 24595 solver.cpp:237] Iteration 47100, loss = 1.03907
I0523 08:35:57.184979 24595 solver.cpp:253]     Train net output #0: loss = 1.03907 (* 1 = 1.03907 loss)
I0523 08:35:57.184993 24595 sgd_solver.cpp:106] Iteration 47100, lr = 0.0035
I0523 08:36:06.468593 24595 solver.cpp:237] Iteration 47400, loss = 1.21076
I0523 08:36:06.468778 24595 solver.cpp:253]     Train net output #0: loss = 1.21076 (* 1 = 1.21076 loss)
I0523 08:36:06.468792 24595 sgd_solver.cpp:106] Iteration 47400, lr = 0.0035
I0523 08:36:15.755102 24595 solver.cpp:237] Iteration 47700, loss = 0.868627
I0523 08:36:15.755137 24595 solver.cpp:253]     Train net output #0: loss = 0.868627 (* 1 = 0.868627 loss)
I0523 08:36:15.755152 24595 sgd_solver.cpp:106] Iteration 47700, lr = 0.0035
I0523 08:36:25.011096 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_48000.caffemodel
I0523 08:36:25.070245 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_48000.solverstate
I0523 08:36:25.096537 24595 solver.cpp:341] Iteration 48000, Testing net (#0)
I0523 08:37:33.744645 24595 solver.cpp:409]     Test net output #0: accuracy = 0.882773
I0523 08:37:33.744817 24595 solver.cpp:409]     Test net output #1: loss = 0.376361 (* 1 = 0.376361 loss)
I0523 08:37:54.639197 24595 solver.cpp:237] Iteration 48000, loss = 1.00763
I0523 08:37:54.639250 24595 solver.cpp:253]     Train net output #0: loss = 1.00763 (* 1 = 1.00763 loss)
I0523 08:37:54.639266 24595 sgd_solver.cpp:106] Iteration 48000, lr = 0.0035
I0523 08:38:03.921816 24595 solver.cpp:237] Iteration 48300, loss = 1.05688
I0523 08:38:03.921982 24595 solver.cpp:253]     Train net output #0: loss = 1.05688 (* 1 = 1.05688 loss)
I0523 08:38:03.921995 24595 sgd_solver.cpp:106] Iteration 48300, lr = 0.0035
I0523 08:38:13.202584 24595 solver.cpp:237] Iteration 48600, loss = 1.2929
I0523 08:38:13.202625 24595 solver.cpp:253]     Train net output #0: loss = 1.2929 (* 1 = 1.2929 loss)
I0523 08:38:13.202641 24595 sgd_solver.cpp:106] Iteration 48600, lr = 0.0035
I0523 08:38:22.486109 24595 solver.cpp:237] Iteration 48900, loss = 1.40476
I0523 08:38:22.486138 24595 solver.cpp:253]     Train net output #0: loss = 1.40476 (* 1 = 1.40476 loss)
I0523 08:38:22.486152 24595 sgd_solver.cpp:106] Iteration 48900, lr = 0.0035
I0523 08:38:31.770678 24595 solver.cpp:237] Iteration 49200, loss = 1.10151
I0523 08:38:31.770720 24595 solver.cpp:253]     Train net output #0: loss = 1.10151 (* 1 = 1.10151 loss)
I0523 08:38:31.770738 24595 sgd_solver.cpp:106] Iteration 49200, lr = 0.0035
I0523 08:38:41.054409 24595 solver.cpp:237] Iteration 49500, loss = 1.21472
I0523 08:38:41.054563 24595 solver.cpp:253]     Train net output #0: loss = 1.21472 (* 1 = 1.21472 loss)
I0523 08:38:41.054575 24595 sgd_solver.cpp:106] Iteration 49500, lr = 0.0035
I0523 08:38:50.335831 24595 solver.cpp:237] Iteration 49800, loss = 1.16568
I0523 08:38:50.335865 24595 solver.cpp:253]     Train net output #0: loss = 1.16568 (* 1 = 1.16568 loss)
I0523 08:38:50.335880 24595 sgd_solver.cpp:106] Iteration 49800, lr = 0.0035
I0523 08:39:20.481648 24595 solver.cpp:237] Iteration 50100, loss = 1.14577
I0523 08:39:20.481823 24595 solver.cpp:253]     Train net output #0: loss = 1.14577 (* 1 = 1.14577 loss)
I0523 08:39:20.481838 24595 sgd_solver.cpp:106] Iteration 50100, lr = 0.0035
I0523 08:39:29.764371 24595 solver.cpp:237] Iteration 50400, loss = 1.10581
I0523 08:39:29.764405 24595 solver.cpp:253]     Train net output #0: loss = 1.10581 (* 1 = 1.10581 loss)
I0523 08:39:29.764418 24595 sgd_solver.cpp:106] Iteration 50400, lr = 0.0035
I0523 08:39:39.043050 24595 solver.cpp:237] Iteration 50700, loss = 1.17006
I0523 08:39:39.043086 24595 solver.cpp:253]     Train net output #0: loss = 1.17006 (* 1 = 1.17006 loss)
I0523 08:39:39.043099 24595 sgd_solver.cpp:106] Iteration 50700, lr = 0.0035
I0523 08:39:48.296800 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_51000.caffemodel
I0523 08:39:48.356761 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_51000.solverstate
I0523 08:39:48.392989 24595 solver.cpp:237] Iteration 51000, loss = 0.980003
I0523 08:39:48.393034 24595 solver.cpp:253]     Train net output #0: loss = 0.980003 (* 1 = 0.980003 loss)
I0523 08:39:48.393050 24595 sgd_solver.cpp:106] Iteration 51000, lr = 0.0035
I0523 08:39:57.671576 24595 solver.cpp:237] Iteration 51300, loss = 1.1201
I0523 08:39:57.671742 24595 solver.cpp:253]     Train net output #0: loss = 1.1201 (* 1 = 1.1201 loss)
I0523 08:39:57.671756 24595 sgd_solver.cpp:106] Iteration 51300, lr = 0.0035
I0523 08:40:06.953845 24595 solver.cpp:237] Iteration 51600, loss = 1.32986
I0523 08:40:06.953879 24595 solver.cpp:253]     Train net output #0: loss = 1.32986 (* 1 = 1.32986 loss)
I0523 08:40:06.953896 24595 sgd_solver.cpp:106] Iteration 51600, lr = 0.0035
I0523 08:40:16.234316 24595 solver.cpp:237] Iteration 51900, loss = 1.18163
I0523 08:40:16.234364 24595 solver.cpp:253]     Train net output #0: loss = 1.18163 (* 1 = 1.18163 loss)
I0523 08:40:16.234378 24595 sgd_solver.cpp:106] Iteration 51900, lr = 0.0035
I0523 08:40:46.390839 24595 solver.cpp:237] Iteration 52200, loss = 1.13581
I0523 08:40:46.391017 24595 solver.cpp:253]     Train net output #0: loss = 1.13581 (* 1 = 1.13581 loss)
I0523 08:40:46.391034 24595 sgd_solver.cpp:106] Iteration 52200, lr = 0.0035
I0523 08:40:55.669500 24595 solver.cpp:237] Iteration 52500, loss = 0.944343
I0523 08:40:55.669536 24595 solver.cpp:253]     Train net output #0: loss = 0.944342 (* 1 = 0.944342 loss)
I0523 08:40:55.669551 24595 sgd_solver.cpp:106] Iteration 52500, lr = 0.0035
I0523 08:41:04.952222 24595 solver.cpp:237] Iteration 52800, loss = 1.22743
I0523 08:41:04.952265 24595 solver.cpp:253]     Train net output #0: loss = 1.22743 (* 1 = 1.22743 loss)
I0523 08:41:04.952281 24595 sgd_solver.cpp:106] Iteration 52800, lr = 0.0035
I0523 08:41:14.233180 24595 solver.cpp:237] Iteration 53100, loss = 1.37504
I0523 08:41:14.233217 24595 solver.cpp:253]     Train net output #0: loss = 1.37504 (* 1 = 1.37504 loss)
I0523 08:41:14.233232 24595 sgd_solver.cpp:106] Iteration 53100, lr = 0.0035
I0523 08:41:23.515326 24595 solver.cpp:237] Iteration 53400, loss = 1.22377
I0523 08:41:23.515489 24595 solver.cpp:253]     Train net output #0: loss = 1.22376 (* 1 = 1.22376 loss)
I0523 08:41:23.515503 24595 sgd_solver.cpp:106] Iteration 53400, lr = 0.0035
I0523 08:41:32.796588 24595 solver.cpp:237] Iteration 53700, loss = 1.21556
I0523 08:41:32.796623 24595 solver.cpp:253]     Train net output #0: loss = 1.21556 (* 1 = 1.21556 loss)
I0523 08:41:32.796636 24595 sgd_solver.cpp:106] Iteration 53700, lr = 0.0035
I0523 08:41:42.044023 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_54000.caffemodel
I0523 08:41:42.103582 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_54000.solverstate
I0523 08:41:42.130074 24595 solver.cpp:341] Iteration 54000, Testing net (#0)
I0523 08:42:29.888696 24595 solver.cpp:409]     Test net output #0: accuracy = 0.887866
I0523 08:42:29.888870 24595 solver.cpp:409]     Test net output #1: loss = 0.370703 (* 1 = 0.370703 loss)
I0523 08:42:50.777544 24595 solver.cpp:237] Iteration 54000, loss = 1.61843
I0523 08:42:50.777596 24595 solver.cpp:253]     Train net output #0: loss = 1.61843 (* 1 = 1.61843 loss)
I0523 08:42:50.777612 24595 sgd_solver.cpp:106] Iteration 54000, lr = 0.0035
I0523 08:43:00.073766 24595 solver.cpp:237] Iteration 54300, loss = 1.27788
I0523 08:43:00.073927 24595 solver.cpp:253]     Train net output #0: loss = 1.27788 (* 1 = 1.27788 loss)
I0523 08:43:00.073941 24595 sgd_solver.cpp:106] Iteration 54300, lr = 0.0035
I0523 08:43:09.365583 24595 solver.cpp:237] Iteration 54600, loss = 1.05855
I0523 08:43:09.365628 24595 solver.cpp:253]     Train net output #0: loss = 1.05855 (* 1 = 1.05855 loss)
I0523 08:43:09.365643 24595 sgd_solver.cpp:106] Iteration 54600, lr = 0.0035
I0523 08:43:18.653071 24595 solver.cpp:237] Iteration 54900, loss = 0.96252
I0523 08:43:18.653108 24595 solver.cpp:253]     Train net output #0: loss = 0.96252 (* 1 = 0.96252 loss)
I0523 08:43:18.653122 24595 sgd_solver.cpp:106] Iteration 54900, lr = 0.0035
I0523 08:43:27.949636 24595 solver.cpp:237] Iteration 55200, loss = 1.28007
I0523 08:43:27.949671 24595 solver.cpp:253]     Train net output #0: loss = 1.28007 (* 1 = 1.28007 loss)
I0523 08:43:27.949687 24595 sgd_solver.cpp:106] Iteration 55200, lr = 0.0035
I0523 08:43:37.241590 24595 solver.cpp:237] Iteration 55500, loss = 1.12427
I0523 08:43:37.241765 24595 solver.cpp:253]     Train net output #0: loss = 1.12427 (* 1 = 1.12427 loss)
I0523 08:43:37.241780 24595 sgd_solver.cpp:106] Iteration 55500, lr = 0.0035
I0523 08:43:46.537451 24595 solver.cpp:237] Iteration 55800, loss = 1.1335
I0523 08:43:46.537487 24595 solver.cpp:253]     Train net output #0: loss = 1.1335 (* 1 = 1.1335 loss)
I0523 08:43:46.537502 24595 sgd_solver.cpp:106] Iteration 55800, lr = 0.0035
I0523 08:44:16.715116 24595 solver.cpp:237] Iteration 56100, loss = 1.41412
I0523 08:44:16.715291 24595 solver.cpp:253]     Train net output #0: loss = 1.41412 (* 1 = 1.41412 loss)
I0523 08:44:16.715307 24595 sgd_solver.cpp:106] Iteration 56100, lr = 0.0035
I0523 08:44:26.007441 24595 solver.cpp:237] Iteration 56400, loss = 1.42279
I0523 08:44:26.007485 24595 solver.cpp:253]     Train net output #0: loss = 1.42279 (* 1 = 1.42279 loss)
I0523 08:44:26.007504 24595 sgd_solver.cpp:106] Iteration 56400, lr = 0.0035
I0523 08:44:35.301851 24595 solver.cpp:237] Iteration 56700, loss = 1.38224
I0523 08:44:35.301887 24595 solver.cpp:253]     Train net output #0: loss = 1.38224 (* 1 = 1.38224 loss)
I0523 08:44:35.301903 24595 sgd_solver.cpp:106] Iteration 56700, lr = 0.0035
I0523 08:44:44.561008 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_57000.caffemodel
I0523 08:44:44.622465 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_57000.solverstate
I0523 08:44:44.660698 24595 solver.cpp:237] Iteration 57000, loss = 1.42355
I0523 08:44:44.660748 24595 solver.cpp:253]     Train net output #0: loss = 1.42355 (* 1 = 1.42355 loss)
I0523 08:44:44.660763 24595 sgd_solver.cpp:106] Iteration 57000, lr = 0.0035
I0523 08:44:53.951455 24595 solver.cpp:237] Iteration 57300, loss = 0.994574
I0523 08:44:53.951629 24595 solver.cpp:253]     Train net output #0: loss = 0.994574 (* 1 = 0.994574 loss)
I0523 08:44:53.951643 24595 sgd_solver.cpp:106] Iteration 57300, lr = 0.0035
I0523 08:45:03.238798 24595 solver.cpp:237] Iteration 57600, loss = 1.08984
I0523 08:45:03.238832 24595 solver.cpp:253]     Train net output #0: loss = 1.08984 (* 1 = 1.08984 loss)
I0523 08:45:03.238850 24595 sgd_solver.cpp:106] Iteration 57600, lr = 0.0035
I0523 08:45:12.527334 24595 solver.cpp:237] Iteration 57900, loss = 1.31858
I0523 08:45:12.527382 24595 solver.cpp:253]     Train net output #0: loss = 1.31858 (* 1 = 1.31858 loss)
I0523 08:45:12.527396 24595 sgd_solver.cpp:106] Iteration 57900, lr = 0.0035
I0523 08:45:42.694780 24595 solver.cpp:237] Iteration 58200, loss = 1.24671
I0523 08:45:42.694957 24595 solver.cpp:253]     Train net output #0: loss = 1.24671 (* 1 = 1.24671 loss)
I0523 08:45:42.694973 24595 sgd_solver.cpp:106] Iteration 58200, lr = 0.0035
I0523 08:45:51.982929 24595 solver.cpp:237] Iteration 58500, loss = 1.32569
I0523 08:45:51.982964 24595 solver.cpp:253]     Train net output #0: loss = 1.32569 (* 1 = 1.32569 loss)
I0523 08:45:51.982981 24595 sgd_solver.cpp:106] Iteration 58500, lr = 0.0035
I0523 08:46:01.270696 24595 solver.cpp:237] Iteration 58800, loss = 1.34743
I0523 08:46:01.270732 24595 solver.cpp:253]     Train net output #0: loss = 1.34743 (* 1 = 1.34743 loss)
I0523 08:46:01.270748 24595 sgd_solver.cpp:106] Iteration 58800, lr = 0.0035
I0523 08:46:10.557291 24595 solver.cpp:237] Iteration 59100, loss = 1.53937
I0523 08:46:10.557327 24595 solver.cpp:253]     Train net output #0: loss = 1.53937 (* 1 = 1.53937 loss)
I0523 08:46:10.557343 24595 sgd_solver.cpp:106] Iteration 59100, lr = 0.0035
I0523 08:46:19.847398 24595 solver.cpp:237] Iteration 59400, loss = 1.23473
I0523 08:46:19.847563 24595 solver.cpp:253]     Train net output #0: loss = 1.23473 (* 1 = 1.23473 loss)
I0523 08:46:19.847575 24595 sgd_solver.cpp:106] Iteration 59400, lr = 0.0035
I0523 08:46:29.136695 24595 solver.cpp:237] Iteration 59700, loss = 1.26648
I0523 08:46:29.136740 24595 solver.cpp:253]     Train net output #0: loss = 1.26648 (* 1 = 1.26648 loss)
I0523 08:46:29.136759 24595 sgd_solver.cpp:106] Iteration 59700, lr = 0.0035
I0523 08:46:38.390929 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_60000.caffemodel
I0523 08:46:38.452563 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_60000.solverstate
I0523 08:46:38.481145 24595 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 08:47:47.191954 24595 solver.cpp:409]     Test net output #0: accuracy = 0.888687
I0523 08:47:47.192127 24595 solver.cpp:409]     Test net output #1: loss = 0.353629 (* 1 = 0.353629 loss)
I0523 08:48:08.140923 24595 solver.cpp:237] Iteration 60000, loss = 1.15027
I0523 08:48:08.140976 24595 solver.cpp:253]     Train net output #0: loss = 1.15027 (* 1 = 1.15027 loss)
I0523 08:48:08.140991 24595 sgd_solver.cpp:106] Iteration 60000, lr = 0.0035
I0523 08:48:17.425277 24595 solver.cpp:237] Iteration 60300, loss = 1.16951
I0523 08:48:17.425438 24595 solver.cpp:253]     Train net output #0: loss = 1.16951 (* 1 = 1.16951 loss)
I0523 08:48:17.425452 24595 sgd_solver.cpp:106] Iteration 60300, lr = 0.0035
I0523 08:48:26.709163 24595 solver.cpp:237] Iteration 60600, loss = 1.30405
I0523 08:48:26.709198 24595 solver.cpp:253]     Train net output #0: loss = 1.30405 (* 1 = 1.30405 loss)
I0523 08:48:26.709216 24595 sgd_solver.cpp:106] Iteration 60600, lr = 0.0035
I0523 08:48:35.990850 24595 solver.cpp:237] Iteration 60900, loss = 1.14538
I0523 08:48:35.990891 24595 solver.cpp:253]     Train net output #0: loss = 1.14538 (* 1 = 1.14538 loss)
I0523 08:48:35.990906 24595 sgd_solver.cpp:106] Iteration 60900, lr = 0.0035
I0523 08:48:45.272320 24595 solver.cpp:237] Iteration 61200, loss = 1.08347
I0523 08:48:45.272354 24595 solver.cpp:253]     Train net output #0: loss = 1.08347 (* 1 = 1.08347 loss)
I0523 08:48:45.272372 24595 sgd_solver.cpp:106] Iteration 61200, lr = 0.0035
I0523 08:48:54.551750 24595 solver.cpp:237] Iteration 61500, loss = 0.963154
I0523 08:48:54.551905 24595 solver.cpp:253]     Train net output #0: loss = 0.963154 (* 1 = 0.963154 loss)
I0523 08:48:54.551919 24595 sgd_solver.cpp:106] Iteration 61500, lr = 0.0035
I0523 08:49:03.831584 24595 solver.cpp:237] Iteration 61800, loss = 1.18338
I0523 08:49:03.831625 24595 solver.cpp:253]     Train net output #0: loss = 1.18338 (* 1 = 1.18338 loss)
I0523 08:49:03.831645 24595 sgd_solver.cpp:106] Iteration 61800, lr = 0.0035
I0523 08:49:34.023653 24595 solver.cpp:237] Iteration 62100, loss = 1.08025
I0523 08:49:34.023833 24595 solver.cpp:253]     Train net output #0: loss = 1.08025 (* 1 = 1.08025 loss)
I0523 08:49:34.023849 24595 sgd_solver.cpp:106] Iteration 62100, lr = 0.0035
I0523 08:49:43.306252 24595 solver.cpp:237] Iteration 62400, loss = 1.16784
I0523 08:49:43.306288 24595 solver.cpp:253]     Train net output #0: loss = 1.16784 (* 1 = 1.16784 loss)
I0523 08:49:43.306304 24595 sgd_solver.cpp:106] Iteration 62400, lr = 0.0035
I0523 08:49:52.587288 24595 solver.cpp:237] Iteration 62700, loss = 1.40501
I0523 08:49:52.587334 24595 solver.cpp:253]     Train net output #0: loss = 1.40501 (* 1 = 1.40501 loss)
I0523 08:49:52.587349 24595 sgd_solver.cpp:106] Iteration 62700, lr = 0.0035
I0523 08:50:01.840553 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_63000.caffemodel
I0523 08:50:01.899951 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_63000.solverstate
I0523 08:50:01.935863 24595 solver.cpp:237] Iteration 63000, loss = 1.19052
I0523 08:50:01.935909 24595 solver.cpp:253]     Train net output #0: loss = 1.19052 (* 1 = 1.19052 loss)
I0523 08:50:01.935923 24595 sgd_solver.cpp:106] Iteration 63000, lr = 0.0035
I0523 08:50:11.219861 24595 solver.cpp:237] Iteration 63300, loss = 1.26237
I0523 08:50:11.220029 24595 solver.cpp:253]     Train net output #0: loss = 1.26237 (* 1 = 1.26237 loss)
I0523 08:50:11.220043 24595 sgd_solver.cpp:106] Iteration 63300, lr = 0.0035
I0523 08:50:20.499544 24595 solver.cpp:237] Iteration 63600, loss = 1.43053
I0523 08:50:20.499577 24595 solver.cpp:253]     Train net output #0: loss = 1.43053 (* 1 = 1.43053 loss)
I0523 08:50:20.499599 24595 sgd_solver.cpp:106] Iteration 63600, lr = 0.0035
I0523 08:50:29.782008 24595 solver.cpp:237] Iteration 63900, loss = 1.10767
I0523 08:50:29.782043 24595 solver.cpp:253]     Train net output #0: loss = 1.10767 (* 1 = 1.10767 loss)
I0523 08:50:29.782066 24595 sgd_solver.cpp:106] Iteration 63900, lr = 0.0035
I0523 08:50:59.955077 24595 solver.cpp:237] Iteration 64200, loss = 1.23156
I0523 08:50:59.955257 24595 solver.cpp:253]     Train net output #0: loss = 1.23156 (* 1 = 1.23156 loss)
I0523 08:50:59.955271 24595 sgd_solver.cpp:106] Iteration 64200, lr = 0.0035
I0523 08:51:09.230556 24595 solver.cpp:237] Iteration 64500, loss = 0.803335
I0523 08:51:09.230599 24595 solver.cpp:253]     Train net output #0: loss = 0.803335 (* 1 = 0.803335 loss)
I0523 08:51:09.230618 24595 sgd_solver.cpp:106] Iteration 64500, lr = 0.0035
I0523 08:51:18.516026 24595 solver.cpp:237] Iteration 64800, loss = 1.33147
I0523 08:51:18.516060 24595 solver.cpp:253]     Train net output #0: loss = 1.33147 (* 1 = 1.33147 loss)
I0523 08:51:18.516077 24595 sgd_solver.cpp:106] Iteration 64800, lr = 0.0035
I0523 08:51:27.795881 24595 solver.cpp:237] Iteration 65100, loss = 1.24775
I0523 08:51:27.795928 24595 solver.cpp:253]     Train net output #0: loss = 1.24775 (* 1 = 1.24775 loss)
I0523 08:51:27.795945 24595 sgd_solver.cpp:106] Iteration 65100, lr = 0.0035
I0523 08:51:37.077307 24595 solver.cpp:237] Iteration 65400, loss = 1.09668
I0523 08:51:37.077466 24595 solver.cpp:253]     Train net output #0: loss = 1.09668 (* 1 = 1.09668 loss)
I0523 08:51:37.077479 24595 sgd_solver.cpp:106] Iteration 65400, lr = 0.0035
I0523 08:51:46.355900 24595 solver.cpp:237] Iteration 65700, loss = 1.06694
I0523 08:51:46.355934 24595 solver.cpp:253]     Train net output #0: loss = 1.06694 (* 1 = 1.06694 loss)
I0523 08:51:46.355952 24595 sgd_solver.cpp:106] Iteration 65700, lr = 0.0035
I0523 08:51:55.605864 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_66000.caffemodel
I0523 08:51:55.664917 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_66000.solverstate
I0523 08:51:55.691278 24595 solver.cpp:341] Iteration 66000, Testing net (#0)
I0523 08:52:43.108752 24595 solver.cpp:409]     Test net output #0: accuracy = 0.890091
I0523 08:52:43.108925 24595 solver.cpp:409]     Test net output #1: loss = 0.351359 (* 1 = 0.351359 loss)
I0523 08:53:04.002050 24595 solver.cpp:237] Iteration 66000, loss = 1.11706
I0523 08:53:04.002112 24595 solver.cpp:253]     Train net output #0: loss = 1.11706 (* 1 = 1.11706 loss)
I0523 08:53:04.002127 24595 sgd_solver.cpp:106] Iteration 66000, lr = 0.0035
I0523 08:53:13.304834 24595 solver.cpp:237] Iteration 66300, loss = 1.22289
I0523 08:53:13.305014 24595 solver.cpp:253]     Train net output #0: loss = 1.22289 (* 1 = 1.22289 loss)
I0523 08:53:13.305028 24595 sgd_solver.cpp:106] Iteration 66300, lr = 0.0035
I0523 08:53:22.609776 24595 solver.cpp:237] Iteration 66600, loss = 0.991484
I0523 08:53:22.609812 24595 solver.cpp:253]     Train net output #0: loss = 0.991484 (* 1 = 0.991484 loss)
I0523 08:53:22.609827 24595 sgd_solver.cpp:106] Iteration 66600, lr = 0.0035
I0523 08:53:31.910914 24595 solver.cpp:237] Iteration 66900, loss = 1.14738
I0523 08:53:31.910958 24595 solver.cpp:253]     Train net output #0: loss = 1.14738 (* 1 = 1.14738 loss)
I0523 08:53:31.910977 24595 sgd_solver.cpp:106] Iteration 66900, lr = 0.0035
I0523 08:53:41.212604 24595 solver.cpp:237] Iteration 67200, loss = 1.14854
I0523 08:53:41.212640 24595 solver.cpp:253]     Train net output #0: loss = 1.14854 (* 1 = 1.14854 loss)
I0523 08:53:41.212656 24595 sgd_solver.cpp:106] Iteration 67200, lr = 0.0035
I0523 08:53:50.516083 24595 solver.cpp:237] Iteration 67500, loss = 1.13948
I0523 08:53:50.516242 24595 solver.cpp:253]     Train net output #0: loss = 1.13948 (* 1 = 1.13948 loss)
I0523 08:53:50.516257 24595 sgd_solver.cpp:106] Iteration 67500, lr = 0.0035
I0523 08:53:59.818923 24595 solver.cpp:237] Iteration 67800, loss = 0.90589
I0523 08:53:59.818961 24595 solver.cpp:253]     Train net output #0: loss = 0.905889 (* 1 = 0.905889 loss)
I0523 08:53:59.818979 24595 sgd_solver.cpp:106] Iteration 67800, lr = 0.0035
I0523 08:54:30.012943 24595 solver.cpp:237] Iteration 68100, loss = 1.41454
I0523 08:54:30.013124 24595 solver.cpp:253]     Train net output #0: loss = 1.41454 (* 1 = 1.41454 loss)
I0523 08:54:30.013141 24595 sgd_solver.cpp:106] Iteration 68100, lr = 0.0035
I0523 08:54:39.317582 24595 solver.cpp:237] Iteration 68400, loss = 1.13437
I0523 08:54:39.317618 24595 solver.cpp:253]     Train net output #0: loss = 1.13437 (* 1 = 1.13437 loss)
I0523 08:54:39.317632 24595 sgd_solver.cpp:106] Iteration 68400, lr = 0.0035
I0523 08:54:48.623668 24595 solver.cpp:237] Iteration 68700, loss = 1.15666
I0523 08:54:48.623714 24595 solver.cpp:253]     Train net output #0: loss = 1.15666 (* 1 = 1.15666 loss)
I0523 08:54:48.623733 24595 sgd_solver.cpp:106] Iteration 68700, lr = 0.0035
I0523 08:54:57.899701 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_69000.caffemodel
I0523 08:54:57.959533 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_69000.solverstate
I0523 08:54:57.995533 24595 solver.cpp:237] Iteration 69000, loss = 1.03802
I0523 08:54:57.995584 24595 solver.cpp:253]     Train net output #0: loss = 1.03802 (* 1 = 1.03802 loss)
I0523 08:54:57.995599 24595 sgd_solver.cpp:106] Iteration 69000, lr = 0.0035
I0523 08:55:07.301515 24595 solver.cpp:237] Iteration 69300, loss = 0.998296
I0523 08:55:07.301679 24595 solver.cpp:253]     Train net output #0: loss = 0.998296 (* 1 = 0.998296 loss)
I0523 08:55:07.301693 24595 sgd_solver.cpp:106] Iteration 69300, lr = 0.0035
I0523 08:55:16.603727 24595 solver.cpp:237] Iteration 69600, loss = 1.05177
I0523 08:55:16.603766 24595 solver.cpp:253]     Train net output #0: loss = 1.05177 (* 1 = 1.05177 loss)
I0523 08:55:16.603785 24595 sgd_solver.cpp:106] Iteration 69600, lr = 0.0035
I0523 08:55:25.907081 24595 solver.cpp:237] Iteration 69900, loss = 1.45835
I0523 08:55:25.907117 24595 solver.cpp:253]     Train net output #0: loss = 1.45835 (* 1 = 1.45835 loss)
I0523 08:55:25.907133 24595 sgd_solver.cpp:106] Iteration 69900, lr = 0.0035
I0523 08:55:56.098794 24595 solver.cpp:237] Iteration 70200, loss = 0.94646
I0523 08:55:56.098975 24595 solver.cpp:253]     Train net output #0: loss = 0.94646 (* 1 = 0.94646 loss)
I0523 08:55:56.098989 24595 sgd_solver.cpp:106] Iteration 70200, lr = 0.0035
I0523 08:56:05.404570 24595 solver.cpp:237] Iteration 70500, loss = 1.12864
I0523 08:56:05.404613 24595 solver.cpp:253]     Train net output #0: loss = 1.12864 (* 1 = 1.12864 loss)
I0523 08:56:05.404631 24595 sgd_solver.cpp:106] Iteration 70500, lr = 0.0035
I0523 08:56:14.707334 24595 solver.cpp:237] Iteration 70800, loss = 1.17816
I0523 08:56:14.707368 24595 solver.cpp:253]     Train net output #0: loss = 1.17816 (* 1 = 1.17816 loss)
I0523 08:56:14.707386 24595 sgd_solver.cpp:106] Iteration 70800, lr = 0.0035
I0523 08:56:24.011694 24595 solver.cpp:237] Iteration 71100, loss = 1.17487
I0523 08:56:24.011730 24595 solver.cpp:253]     Train net output #0: loss = 1.17487 (* 1 = 1.17487 loss)
I0523 08:56:24.011746 24595 sgd_solver.cpp:106] Iteration 71100, lr = 0.0035
I0523 08:56:33.316817 24595 solver.cpp:237] Iteration 71400, loss = 1.15268
I0523 08:56:33.316994 24595 solver.cpp:253]     Train net output #0: loss = 1.15268 (* 1 = 1.15268 loss)
I0523 08:56:33.317008 24595 sgd_solver.cpp:106] Iteration 71400, lr = 0.0035
I0523 08:56:42.621733 24595 solver.cpp:237] Iteration 71700, loss = 1.09289
I0523 08:56:42.621768 24595 solver.cpp:253]     Train net output #0: loss = 1.09289 (* 1 = 1.09289 loss)
I0523 08:56:42.621785 24595 sgd_solver.cpp:106] Iteration 71700, lr = 0.0035
I0523 08:56:51.892055 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_72000.caffemodel
I0523 08:56:51.951833 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_72000.solverstate
I0523 08:56:51.978394 24595 solver.cpp:341] Iteration 72000, Testing net (#0)
I0523 08:58:00.662979 24595 solver.cpp:409]     Test net output #0: accuracy = 0.891459
I0523 08:58:00.663159 24595 solver.cpp:409]     Test net output #1: loss = 0.365306 (* 1 = 0.365306 loss)
I0523 08:58:21.572644 24595 solver.cpp:237] Iteration 72000, loss = 1.05414
I0523 08:58:21.572697 24595 solver.cpp:253]     Train net output #0: loss = 1.05414 (* 1 = 1.05414 loss)
I0523 08:58:21.572712 24595 sgd_solver.cpp:106] Iteration 72000, lr = 0.0035
I0523 08:58:30.861889 24595 solver.cpp:237] Iteration 72300, loss = 0.98376
I0523 08:58:30.862056 24595 solver.cpp:253]     Train net output #0: loss = 0.983759 (* 1 = 0.983759 loss)
I0523 08:58:30.862076 24595 sgd_solver.cpp:106] Iteration 72300, lr = 0.0035
I0523 08:58:40.153334 24595 solver.cpp:237] Iteration 72600, loss = 1.13283
I0523 08:58:40.153380 24595 solver.cpp:253]     Train net output #0: loss = 1.13283 (* 1 = 1.13283 loss)
I0523 08:58:40.153396 24595 sgd_solver.cpp:106] Iteration 72600, lr = 0.0035
I0523 08:58:49.442252 24595 solver.cpp:237] Iteration 72900, loss = 1.14245
I0523 08:58:49.442287 24595 solver.cpp:253]     Train net output #0: loss = 1.14245 (* 1 = 1.14245 loss)
I0523 08:58:49.442304 24595 sgd_solver.cpp:106] Iteration 72900, lr = 0.0035
I0523 08:58:58.733008 24595 solver.cpp:237] Iteration 73200, loss = 1.24217
I0523 08:58:58.733053 24595 solver.cpp:253]     Train net output #0: loss = 1.24217 (* 1 = 1.24217 loss)
I0523 08:58:58.733069 24595 sgd_solver.cpp:106] Iteration 73200, lr = 0.0035
I0523 08:59:08.023762 24595 solver.cpp:237] Iteration 73500, loss = 1.50088
I0523 08:59:08.023923 24595 solver.cpp:253]     Train net output #0: loss = 1.50088 (* 1 = 1.50088 loss)
I0523 08:59:08.023937 24595 sgd_solver.cpp:106] Iteration 73500, lr = 0.0035
I0523 08:59:17.315366 24595 solver.cpp:237] Iteration 73800, loss = 1.22312
I0523 08:59:17.315399 24595 solver.cpp:253]     Train net output #0: loss = 1.22311 (* 1 = 1.22311 loss)
I0523 08:59:17.315417 24595 sgd_solver.cpp:106] Iteration 73800, lr = 0.0035
I0523 08:59:47.526528 24595 solver.cpp:237] Iteration 74100, loss = 0.99969
I0523 08:59:47.526708 24595 solver.cpp:253]     Train net output #0: loss = 0.99969 (* 1 = 0.99969 loss)
I0523 08:59:47.526723 24595 sgd_solver.cpp:106] Iteration 74100, lr = 0.0035
I0523 08:59:56.816925 24595 solver.cpp:237] Iteration 74400, loss = 1.16475
I0523 08:59:56.816959 24595 solver.cpp:253]     Train net output #0: loss = 1.16475 (* 1 = 1.16475 loss)
I0523 08:59:56.816977 24595 sgd_solver.cpp:106] Iteration 74400, lr = 0.0035
I0523 09:00:06.108690 24595 solver.cpp:237] Iteration 74700, loss = 1.16622
I0523 09:00:06.108726 24595 solver.cpp:253]     Train net output #0: loss = 1.16622 (* 1 = 1.16622 loss)
I0523 09:00:06.108741 24595 sgd_solver.cpp:106] Iteration 74700, lr = 0.0035
I0523 09:00:15.361593 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_75000.caffemodel
I0523 09:00:15.423158 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_75000.solverstate
I0523 09:00:15.461237 24595 solver.cpp:237] Iteration 75000, loss = 1.07929
I0523 09:00:15.461282 24595 solver.cpp:253]     Train net output #0: loss = 1.07929 (* 1 = 1.07929 loss)
I0523 09:00:15.461300 24595 sgd_solver.cpp:106] Iteration 75000, lr = 0.0035
I0523 09:00:24.753389 24595 solver.cpp:237] Iteration 75300, loss = 0.993133
I0523 09:00:24.753566 24595 solver.cpp:253]     Train net output #0: loss = 0.993133 (* 1 = 0.993133 loss)
I0523 09:00:24.753579 24595 sgd_solver.cpp:106] Iteration 75300, lr = 0.0035
I0523 09:00:34.043201 24595 solver.cpp:237] Iteration 75600, loss = 1.41106
I0523 09:00:34.043236 24595 solver.cpp:253]     Train net output #0: loss = 1.41106 (* 1 = 1.41106 loss)
I0523 09:00:34.043253 24595 sgd_solver.cpp:106] Iteration 75600, lr = 0.0035
I0523 09:00:43.331138 24595 solver.cpp:237] Iteration 75900, loss = 0.955864
I0523 09:00:43.331189 24595 solver.cpp:253]     Train net output #0: loss = 0.955864 (* 1 = 0.955864 loss)
I0523 09:00:43.331203 24595 sgd_solver.cpp:106] Iteration 75900, lr = 0.0035
I0523 09:01:13.509568 24595 solver.cpp:237] Iteration 76200, loss = 1.04734
I0523 09:01:13.509752 24595 solver.cpp:253]     Train net output #0: loss = 1.04733 (* 1 = 1.04733 loss)
I0523 09:01:13.509766 24595 sgd_solver.cpp:106] Iteration 76200, lr = 0.0035
I0523 09:01:22.800541 24595 solver.cpp:237] Iteration 76500, loss = 0.92251
I0523 09:01:22.800577 24595 solver.cpp:253]     Train net output #0: loss = 0.92251 (* 1 = 0.92251 loss)
I0523 09:01:22.800595 24595 sgd_solver.cpp:106] Iteration 76500, lr = 0.0035
I0523 09:01:32.090823 24595 solver.cpp:237] Iteration 76800, loss = 0.96782
I0523 09:01:32.090867 24595 solver.cpp:253]     Train net output #0: loss = 0.96782 (* 1 = 0.96782 loss)
I0523 09:01:32.090885 24595 sgd_solver.cpp:106] Iteration 76800, lr = 0.0035
I0523 09:01:41.374922 24595 solver.cpp:237] Iteration 77100, loss = 1.09623
I0523 09:01:41.374956 24595 solver.cpp:253]     Train net output #0: loss = 1.09623 (* 1 = 1.09623 loss)
I0523 09:01:41.374974 24595 sgd_solver.cpp:106] Iteration 77100, lr = 0.0035
I0523 09:01:50.661129 24595 solver.cpp:237] Iteration 77400, loss = 1.10032
I0523 09:01:50.661298 24595 solver.cpp:253]     Train net output #0: loss = 1.10032 (* 1 = 1.10032 loss)
I0523 09:01:50.661311 24595 sgd_solver.cpp:106] Iteration 77400, lr = 0.0035
I0523 09:01:59.949683 24595 solver.cpp:237] Iteration 77700, loss = 0.96527
I0523 09:01:59.949731 24595 solver.cpp:253]     Train net output #0: loss = 0.96527 (* 1 = 0.96527 loss)
I0523 09:01:59.949748 24595 sgd_solver.cpp:106] Iteration 77700, lr = 0.0035
I0523 09:02:09.203305 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_78000.caffemodel
I0523 09:02:09.262871 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_78000.solverstate
I0523 09:02:09.289089 24595 solver.cpp:341] Iteration 78000, Testing net (#0)
I0523 09:02:57.088632 24595 solver.cpp:409]     Test net output #0: accuracy = 0.893971
I0523 09:02:57.088821 24595 solver.cpp:409]     Test net output #1: loss = 0.332977 (* 1 = 0.332977 loss)
I0523 09:03:18.004681 24595 solver.cpp:237] Iteration 78000, loss = 0.934408
I0523 09:03:18.004735 24595 solver.cpp:253]     Train net output #0: loss = 0.934407 (* 1 = 0.934407 loss)
I0523 09:03:18.004753 24595 sgd_solver.cpp:106] Iteration 78000, lr = 0.0035
I0523 09:03:27.291883 24595 solver.cpp:237] Iteration 78300, loss = 1.05374
I0523 09:03:27.292053 24595 solver.cpp:253]     Train net output #0: loss = 1.05374 (* 1 = 1.05374 loss)
I0523 09:03:27.292067 24595 sgd_solver.cpp:106] Iteration 78300, lr = 0.0035
I0523 09:03:36.581593 24595 solver.cpp:237] Iteration 78600, loss = 1.08023
I0523 09:03:36.581634 24595 solver.cpp:253]     Train net output #0: loss = 1.08023 (* 1 = 1.08023 loss)
I0523 09:03:36.581655 24595 sgd_solver.cpp:106] Iteration 78600, lr = 0.0035
I0523 09:03:45.870136 24595 solver.cpp:237] Iteration 78900, loss = 1.05627
I0523 09:03:45.870167 24595 solver.cpp:253]     Train net output #0: loss = 1.05627 (* 1 = 1.05627 loss)
I0523 09:03:45.870179 24595 sgd_solver.cpp:106] Iteration 78900, lr = 0.0035
I0523 09:03:55.159302 24595 solver.cpp:237] Iteration 79200, loss = 1.17088
I0523 09:03:55.159338 24595 solver.cpp:253]     Train net output #0: loss = 1.17088 (* 1 = 1.17088 loss)
I0523 09:03:55.159354 24595 sgd_solver.cpp:106] Iteration 79200, lr = 0.0035
I0523 09:04:04.447751 24595 solver.cpp:237] Iteration 79500, loss = 1.24808
I0523 09:04:04.447932 24595 solver.cpp:253]     Train net output #0: loss = 1.24808 (* 1 = 1.24808 loss)
I0523 09:04:04.447947 24595 sgd_solver.cpp:106] Iteration 79500, lr = 0.0035
I0523 09:04:13.736469 24595 solver.cpp:237] Iteration 79800, loss = 0.935481
I0523 09:04:13.736505 24595 solver.cpp:253]     Train net output #0: loss = 0.935481 (* 1 = 0.935481 loss)
I0523 09:04:13.736523 24595 sgd_solver.cpp:106] Iteration 79800, lr = 0.0035
I0523 09:04:43.905647 24595 solver.cpp:237] Iteration 80100, loss = 1.08883
I0523 09:04:43.905833 24595 solver.cpp:253]     Train net output #0: loss = 1.08883 (* 1 = 1.08883 loss)
I0523 09:04:43.905848 24595 sgd_solver.cpp:106] Iteration 80100, lr = 0.0035
I0523 09:04:53.194501 24595 solver.cpp:237] Iteration 80400, loss = 1.00342
I0523 09:04:53.194550 24595 solver.cpp:253]     Train net output #0: loss = 1.00342 (* 1 = 1.00342 loss)
I0523 09:04:53.194567 24595 sgd_solver.cpp:106] Iteration 80400, lr = 0.0035
I0523 09:05:02.480696 24595 solver.cpp:237] Iteration 80700, loss = 1.35376
I0523 09:05:02.480732 24595 solver.cpp:253]     Train net output #0: loss = 1.35376 (* 1 = 1.35376 loss)
I0523 09:05:02.480748 24595 sgd_solver.cpp:106] Iteration 80700, lr = 0.0035
I0523 09:05:11.736846 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_81000.caffemodel
I0523 09:05:11.796653 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_81000.solverstate
I0523 09:05:11.832767 24595 solver.cpp:237] Iteration 81000, loss = 0.937443
I0523 09:05:11.832813 24595 solver.cpp:253]     Train net output #0: loss = 0.937443 (* 1 = 0.937443 loss)
I0523 09:05:11.832828 24595 sgd_solver.cpp:106] Iteration 81000, lr = 0.0035
I0523 09:05:21.121604 24595 solver.cpp:237] Iteration 81300, loss = 1.09516
I0523 09:05:21.121768 24595 solver.cpp:253]     Train net output #0: loss = 1.09516 (* 1 = 1.09516 loss)
I0523 09:05:21.121783 24595 sgd_solver.cpp:106] Iteration 81300, lr = 0.0035
I0523 09:05:30.408534 24595 solver.cpp:237] Iteration 81600, loss = 1.18406
I0523 09:05:30.408568 24595 solver.cpp:253]     Train net output #0: loss = 1.18406 (* 1 = 1.18406 loss)
I0523 09:05:30.408586 24595 sgd_solver.cpp:106] Iteration 81600, lr = 0.0035
I0523 09:05:39.698554 24595 solver.cpp:237] Iteration 81900, loss = 1.12027
I0523 09:05:39.698601 24595 solver.cpp:253]     Train net output #0: loss = 1.12027 (* 1 = 1.12027 loss)
I0523 09:05:39.698619 24595 sgd_solver.cpp:106] Iteration 81900, lr = 0.0035
I0523 09:06:09.874264 24595 solver.cpp:237] Iteration 82200, loss = 0.854187
I0523 09:06:09.874457 24595 solver.cpp:253]     Train net output #0: loss = 0.854187 (* 1 = 0.854187 loss)
I0523 09:06:09.874474 24595 sgd_solver.cpp:106] Iteration 82200, lr = 0.0035
I0523 09:06:19.165609 24595 solver.cpp:237] Iteration 82500, loss = 1.34627
I0523 09:06:19.165644 24595 solver.cpp:253]     Train net output #0: loss = 1.34627 (* 1 = 1.34627 loss)
I0523 09:06:19.165662 24595 sgd_solver.cpp:106] Iteration 82500, lr = 0.0035
I0523 09:06:28.457528 24595 solver.cpp:237] Iteration 82800, loss = 1.3287
I0523 09:06:28.457576 24595 solver.cpp:253]     Train net output #0: loss = 1.3287 (* 1 = 1.3287 loss)
I0523 09:06:28.457593 24595 sgd_solver.cpp:106] Iteration 82800, lr = 0.0035
I0523 09:06:37.747478 24595 solver.cpp:237] Iteration 83100, loss = 1.18333
I0523 09:06:37.747515 24595 solver.cpp:253]     Train net output #0: loss = 1.18333 (* 1 = 1.18333 loss)
I0523 09:06:37.747531 24595 sgd_solver.cpp:106] Iteration 83100, lr = 0.0035
I0523 09:06:47.036393 24595 solver.cpp:237] Iteration 83400, loss = 1.10472
I0523 09:06:47.036558 24595 solver.cpp:253]     Train net output #0: loss = 1.10472 (* 1 = 1.10472 loss)
I0523 09:06:47.036571 24595 sgd_solver.cpp:106] Iteration 83400, lr = 0.0035
I0523 09:06:56.327324 24595 solver.cpp:237] Iteration 83700, loss = 0.984535
I0523 09:06:56.327368 24595 solver.cpp:253]     Train net output #0: loss = 0.984535 (* 1 = 0.984535 loss)
I0523 09:06:56.327388 24595 sgd_solver.cpp:106] Iteration 83700, lr = 0.0035
I0523 09:07:05.586190 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_84000.caffemodel
I0523 09:07:05.646159 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_84000.solverstate
I0523 09:07:05.672701 24595 solver.cpp:341] Iteration 84000, Testing net (#0)
I0523 09:08:14.378633 24595 solver.cpp:409]     Test net output #0: accuracy = 0.89585
I0523 09:08:14.378814 24595 solver.cpp:409]     Test net output #1: loss = 0.343158 (* 1 = 0.343158 loss)
I0523 09:08:35.250185 24595 solver.cpp:237] Iteration 84000, loss = 1.39676
I0523 09:08:35.250236 24595 solver.cpp:253]     Train net output #0: loss = 1.39676 (* 1 = 1.39676 loss)
I0523 09:08:35.250250 24595 sgd_solver.cpp:106] Iteration 84000, lr = 0.0035
I0523 09:08:44.531301 24595 solver.cpp:237] Iteration 84300, loss = 1.23574
I0523 09:08:44.531468 24595 solver.cpp:253]     Train net output #0: loss = 1.23574 (* 1 = 1.23574 loss)
I0523 09:08:44.531481 24595 sgd_solver.cpp:106] Iteration 84300, lr = 0.0035
I0523 09:08:53.813081 24595 solver.cpp:237] Iteration 84600, loss = 1.02846
I0523 09:08:53.813115 24595 solver.cpp:253]     Train net output #0: loss = 1.02846 (* 1 = 1.02846 loss)
I0523 09:08:53.813133 24595 sgd_solver.cpp:106] Iteration 84600, lr = 0.0035
I0523 09:09:03.095940 24595 solver.cpp:237] Iteration 84900, loss = 0.898841
I0523 09:09:03.095984 24595 solver.cpp:253]     Train net output #0: loss = 0.89884 (* 1 = 0.89884 loss)
I0523 09:09:03.096001 24595 sgd_solver.cpp:106] Iteration 84900, lr = 0.0035
I0523 09:09:12.381220 24595 solver.cpp:237] Iteration 85200, loss = 1.0396
I0523 09:09:12.381254 24595 solver.cpp:253]     Train net output #0: loss = 1.0396 (* 1 = 1.0396 loss)
I0523 09:09:12.381271 24595 sgd_solver.cpp:106] Iteration 85200, lr = 0.0035
I0523 09:09:21.663872 24595 solver.cpp:237] Iteration 85500, loss = 0.948361
I0523 09:09:21.664036 24595 solver.cpp:253]     Train net output #0: loss = 0.94836 (* 1 = 0.94836 loss)
I0523 09:09:21.664052 24595 sgd_solver.cpp:106] Iteration 85500, lr = 0.0035
I0523 09:09:30.947257 24595 solver.cpp:237] Iteration 85800, loss = 1.11641
I0523 09:09:30.947291 24595 solver.cpp:253]     Train net output #0: loss = 1.11641 (* 1 = 1.11641 loss)
I0523 09:09:30.947309 24595 sgd_solver.cpp:106] Iteration 85800, lr = 0.0035
I0523 09:10:01.093816 24595 solver.cpp:237] Iteration 86100, loss = 1.28228
I0523 09:10:01.094012 24595 solver.cpp:253]     Train net output #0: loss = 1.28228 (* 1 = 1.28228 loss)
I0523 09:10:01.094027 24595 sgd_solver.cpp:106] Iteration 86100, lr = 0.0035
I0523 09:10:10.378832 24595 solver.cpp:237] Iteration 86400, loss = 1.16274
I0523 09:10:10.378866 24595 solver.cpp:253]     Train net output #0: loss = 1.16274 (* 1 = 1.16274 loss)
I0523 09:10:10.378885 24595 sgd_solver.cpp:106] Iteration 86400, lr = 0.0035
I0523 09:10:19.660969 24595 solver.cpp:237] Iteration 86700, loss = 1.44096
I0523 09:10:19.661015 24595 solver.cpp:253]     Train net output #0: loss = 1.44096 (* 1 = 1.44096 loss)
I0523 09:10:19.661028 24595 sgd_solver.cpp:106] Iteration 86700, lr = 0.0035
I0523 09:10:28.908480 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_87000.caffemodel
I0523 09:10:28.970544 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_87000.solverstate
I0523 09:10:29.008887 24595 solver.cpp:237] Iteration 87000, loss = 1.38104
I0523 09:10:29.008936 24595 solver.cpp:253]     Train net output #0: loss = 1.38104 (* 1 = 1.38104 loss)
I0523 09:10:29.008950 24595 sgd_solver.cpp:106] Iteration 87000, lr = 0.0035
I0523 09:10:38.288475 24595 solver.cpp:237] Iteration 87300, loss = 0.86065
I0523 09:10:38.288661 24595 solver.cpp:253]     Train net output #0: loss = 0.86065 (* 1 = 0.86065 loss)
I0523 09:10:38.288676 24595 sgd_solver.cpp:106] Iteration 87300, lr = 0.0035
I0523 09:10:47.568613 24595 solver.cpp:237] Iteration 87600, loss = 1.2928
I0523 09:10:47.568647 24595 solver.cpp:253]     Train net output #0: loss = 1.2928 (* 1 = 1.2928 loss)
I0523 09:10:47.568665 24595 sgd_solver.cpp:106] Iteration 87600, lr = 0.0035
I0523 09:10:56.852699 24595 solver.cpp:237] Iteration 87900, loss = 1.1585
I0523 09:10:56.852735 24595 solver.cpp:253]     Train net output #0: loss = 1.1585 (* 1 = 1.1585 loss)
I0523 09:10:56.852751 24595 sgd_solver.cpp:106] Iteration 87900, lr = 0.0035
I0523 09:11:27.112558 24595 solver.cpp:237] Iteration 88200, loss = 1.12927
I0523 09:11:27.112743 24595 solver.cpp:253]     Train net output #0: loss = 1.12927 (* 1 = 1.12927 loss)
I0523 09:11:27.112761 24595 sgd_solver.cpp:106] Iteration 88200, lr = 0.0035
I0523 09:11:36.399302 24595 solver.cpp:237] Iteration 88500, loss = 1.09426
I0523 09:11:36.399335 24595 solver.cpp:253]     Train net output #0: loss = 1.09426 (* 1 = 1.09426 loss)
I0523 09:11:36.399354 24595 sgd_solver.cpp:106] Iteration 88500, lr = 0.0035
I0523 09:11:45.680735 24595 solver.cpp:237] Iteration 88800, loss = 0.856271
I0523 09:11:45.680773 24595 solver.cpp:253]     Train net output #0: loss = 0.85627 (* 1 = 0.85627 loss)
I0523 09:11:45.680788 24595 sgd_solver.cpp:106] Iteration 88800, lr = 0.0035
I0523 09:11:54.965337 24595 solver.cpp:237] Iteration 89100, loss = 1.37777
I0523 09:11:54.965378 24595 solver.cpp:253]     Train net output #0: loss = 1.37777 (* 1 = 1.37777 loss)
I0523 09:11:54.965397 24595 sgd_solver.cpp:106] Iteration 89100, lr = 0.0035
I0523 09:12:04.250360 24595 solver.cpp:237] Iteration 89400, loss = 1.0144
I0523 09:12:04.250522 24595 solver.cpp:253]     Train net output #0: loss = 1.0144 (* 1 = 1.0144 loss)
I0523 09:12:04.250535 24595 sgd_solver.cpp:106] Iteration 89400, lr = 0.0035
I0523 09:12:13.532347 24595 solver.cpp:237] Iteration 89700, loss = 1.27165
I0523 09:12:13.532382 24595 solver.cpp:253]     Train net output #0: loss = 1.27165 (* 1 = 1.27165 loss)
I0523 09:12:13.532397 24595 sgd_solver.cpp:106] Iteration 89700, lr = 0.0035
I0523 09:12:22.788029 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_90000.caffemodel
I0523 09:12:22.849674 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_90000.solverstate
I0523 09:12:22.878176 24595 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 09:13:10.372676 24595 solver.cpp:409]     Test net output #0: accuracy = 0.892804
I0523 09:13:10.372876 24595 solver.cpp:409]     Test net output #1: loss = 0.349093 (* 1 = 0.349093 loss)
I0523 09:13:31.337198 24595 solver.cpp:237] Iteration 90000, loss = 1.14665
I0523 09:13:31.337250 24595 solver.cpp:253]     Train net output #0: loss = 1.14665 (* 1 = 1.14665 loss)
I0523 09:13:31.337265 24595 sgd_solver.cpp:106] Iteration 90000, lr = 0.0035
I0523 09:13:40.643198 24595 solver.cpp:237] Iteration 90300, loss = 0.918127
I0523 09:13:40.643381 24595 solver.cpp:253]     Train net output #0: loss = 0.918127 (* 1 = 0.918127 loss)
I0523 09:13:40.643395 24595 sgd_solver.cpp:106] Iteration 90300, lr = 0.0035
I0523 09:13:49.946390 24595 solver.cpp:237] Iteration 90600, loss = 1.31631
I0523 09:13:49.946421 24595 solver.cpp:253]     Train net output #0: loss = 1.31631 (* 1 = 1.31631 loss)
I0523 09:13:49.946435 24595 sgd_solver.cpp:106] Iteration 90600, lr = 0.0035
I0523 09:13:59.250821 24595 solver.cpp:237] Iteration 90900, loss = 1.09037
I0523 09:13:59.250870 24595 solver.cpp:253]     Train net output #0: loss = 1.09037 (* 1 = 1.09037 loss)
I0523 09:13:59.250887 24595 sgd_solver.cpp:106] Iteration 90900, lr = 0.0035
I0523 09:14:08.548069 24595 solver.cpp:237] Iteration 91200, loss = 1.07206
I0523 09:14:08.548104 24595 solver.cpp:253]     Train net output #0: loss = 1.07206 (* 1 = 1.07206 loss)
I0523 09:14:08.548120 24595 sgd_solver.cpp:106] Iteration 91200, lr = 0.0035
I0523 09:14:17.851590 24595 solver.cpp:237] Iteration 91500, loss = 0.789997
I0523 09:14:17.851758 24595 solver.cpp:253]     Train net output #0: loss = 0.789997 (* 1 = 0.789997 loss)
I0523 09:14:17.851773 24595 sgd_solver.cpp:106] Iteration 91500, lr = 0.0035
I0523 09:14:27.154711 24595 solver.cpp:237] Iteration 91800, loss = 1.4045
I0523 09:14:27.154752 24595 solver.cpp:253]     Train net output #0: loss = 1.4045 (* 1 = 1.4045 loss)
I0523 09:14:27.154773 24595 sgd_solver.cpp:106] Iteration 91800, lr = 0.0035
I0523 09:14:57.359529 24595 solver.cpp:237] Iteration 92100, loss = 1.31721
I0523 09:14:57.359714 24595 solver.cpp:253]     Train net output #0: loss = 1.31721 (* 1 = 1.31721 loss)
I0523 09:14:57.359730 24595 sgd_solver.cpp:106] Iteration 92100, lr = 0.0035
I0523 09:15:06.664482 24595 solver.cpp:237] Iteration 92400, loss = 1.12643
I0523 09:15:06.664517 24595 solver.cpp:253]     Train net output #0: loss = 1.12643 (* 1 = 1.12643 loss)
I0523 09:15:06.664535 24595 sgd_solver.cpp:106] Iteration 92400, lr = 0.0035
I0523 09:15:15.969048 24595 solver.cpp:237] Iteration 92700, loss = 1.22564
I0523 09:15:15.969087 24595 solver.cpp:253]     Train net output #0: loss = 1.22564 (* 1 = 1.22564 loss)
I0523 09:15:15.969108 24595 sgd_solver.cpp:106] Iteration 92700, lr = 0.0035
I0523 09:15:25.243001 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_93000.caffemodel
I0523 09:15:25.302505 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_93000.solverstate
I0523 09:15:25.338238 24595 solver.cpp:237] Iteration 93000, loss = 0.828891
I0523 09:15:25.338279 24595 solver.cpp:253]     Train net output #0: loss = 0.828891 (* 1 = 0.828891 loss)
I0523 09:15:25.338297 24595 sgd_solver.cpp:106] Iteration 93000, lr = 0.0035
I0523 09:15:34.643913 24595 solver.cpp:237] Iteration 93300, loss = 1.33734
I0523 09:15:34.644093 24595 solver.cpp:253]     Train net output #0: loss = 1.33734 (* 1 = 1.33734 loss)
I0523 09:15:34.644106 24595 sgd_solver.cpp:106] Iteration 93300, lr = 0.0035
I0523 09:15:43.947283 24595 solver.cpp:237] Iteration 93600, loss = 1.2606
I0523 09:15:43.947325 24595 solver.cpp:253]     Train net output #0: loss = 1.26059 (* 1 = 1.26059 loss)
I0523 09:15:43.947343 24595 sgd_solver.cpp:106] Iteration 93600, lr = 0.0035
I0523 09:15:53.253654 24595 solver.cpp:237] Iteration 93900, loss = 1.02565
I0523 09:15:53.253690 24595 solver.cpp:253]     Train net output #0: loss = 1.02565 (* 1 = 1.02565 loss)
I0523 09:15:53.253706 24595 sgd_solver.cpp:106] Iteration 93900, lr = 0.0035
I0523 09:16:23.518790 24595 solver.cpp:237] Iteration 94200, loss = 1.27727
I0523 09:16:23.518990 24595 solver.cpp:253]     Train net output #0: loss = 1.27727 (* 1 = 1.27727 loss)
I0523 09:16:23.519006 24595 sgd_solver.cpp:106] Iteration 94200, lr = 0.0035
I0523 09:16:32.827587 24595 solver.cpp:237] Iteration 94500, loss = 0.810421
I0523 09:16:32.827638 24595 solver.cpp:253]     Train net output #0: loss = 0.810421 (* 1 = 0.810421 loss)
I0523 09:16:32.827653 24595 sgd_solver.cpp:106] Iteration 94500, lr = 0.0035
I0523 09:16:42.131649 24595 solver.cpp:237] Iteration 94800, loss = 1.33974
I0523 09:16:42.131685 24595 solver.cpp:253]     Train net output #0: loss = 1.33974 (* 1 = 1.33974 loss)
I0523 09:16:42.131701 24595 sgd_solver.cpp:106] Iteration 94800, lr = 0.0035
I0523 09:16:51.440502 24595 solver.cpp:237] Iteration 95100, loss = 1.1516
I0523 09:16:51.440538 24595 solver.cpp:253]     Train net output #0: loss = 1.1516 (* 1 = 1.1516 loss)
I0523 09:16:51.440552 24595 sgd_solver.cpp:106] Iteration 95100, lr = 0.0035
I0523 09:17:00.744422 24595 solver.cpp:237] Iteration 95400, loss = 1.03378
I0523 09:17:00.744606 24595 solver.cpp:253]     Train net output #0: loss = 1.03378 (* 1 = 1.03378 loss)
I0523 09:17:00.744619 24595 sgd_solver.cpp:106] Iteration 95400, lr = 0.0035
I0523 09:17:10.046861 24595 solver.cpp:237] Iteration 95700, loss = 0.902807
I0523 09:17:10.046897 24595 solver.cpp:253]     Train net output #0: loss = 0.902806 (* 1 = 0.902806 loss)
I0523 09:17:10.046914 24595 sgd_solver.cpp:106] Iteration 95700, lr = 0.0035
I0523 09:17:19.321985 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_96000.caffemodel
I0523 09:17:19.381548 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_96000.solverstate
I0523 09:17:19.408048 24595 solver.cpp:341] Iteration 96000, Testing net (#0)
I0523 09:18:28.172462 24595 solver.cpp:409]     Test net output #0: accuracy = 0.894725
I0523 09:18:28.172652 24595 solver.cpp:409]     Test net output #1: loss = 0.332799 (* 1 = 0.332799 loss)
I0523 09:18:49.102454 24595 solver.cpp:237] Iteration 96000, loss = 1.03154
I0523 09:18:49.102507 24595 solver.cpp:253]     Train net output #0: loss = 1.03154 (* 1 = 1.03154 loss)
I0523 09:18:49.102524 24595 sgd_solver.cpp:106] Iteration 96000, lr = 0.0035
I0523 09:18:58.392462 24595 solver.cpp:237] Iteration 96300, loss = 1.02712
I0523 09:18:58.392654 24595 solver.cpp:253]     Train net output #0: loss = 1.02712 (* 1 = 1.02712 loss)
I0523 09:18:58.392669 24595 sgd_solver.cpp:106] Iteration 96300, lr = 0.0035
I0523 09:19:07.685096 24595 solver.cpp:237] Iteration 96600, loss = 1.10378
I0523 09:19:07.685132 24595 solver.cpp:253]     Train net output #0: loss = 1.10378 (* 1 = 1.10378 loss)
I0523 09:19:07.685149 24595 sgd_solver.cpp:106] Iteration 96600, lr = 0.0035
I0523 09:19:16.981781 24595 solver.cpp:237] Iteration 96900, loss = 0.967792
I0523 09:19:16.981817 24595 solver.cpp:253]     Train net output #0: loss = 0.967792 (* 1 = 0.967792 loss)
I0523 09:19:16.981832 24595 sgd_solver.cpp:106] Iteration 96900, lr = 0.0035
I0523 09:19:26.275511 24595 solver.cpp:237] Iteration 97200, loss = 0.80945
I0523 09:19:26.275553 24595 solver.cpp:253]     Train net output #0: loss = 0.80945 (* 1 = 0.80945 loss)
I0523 09:19:26.275570 24595 sgd_solver.cpp:106] Iteration 97200, lr = 0.0035
I0523 09:19:35.566150 24595 solver.cpp:237] Iteration 97500, loss = 1.37526
I0523 09:19:35.566330 24595 solver.cpp:253]     Train net output #0: loss = 1.37526 (* 1 = 1.37526 loss)
I0523 09:19:35.566344 24595 sgd_solver.cpp:106] Iteration 97500, lr = 0.0035
I0523 09:19:44.862074 24595 solver.cpp:237] Iteration 97800, loss = 1.10048
I0523 09:19:44.862109 24595 solver.cpp:253]     Train net output #0: loss = 1.10048 (* 1 = 1.10048 loss)
I0523 09:19:44.862125 24595 sgd_solver.cpp:106] Iteration 97800, lr = 0.0035
I0523 09:20:15.090739 24595 solver.cpp:237] Iteration 98100, loss = 1.23742
I0523 09:20:15.090931 24595 solver.cpp:253]     Train net output #0: loss = 1.23742 (* 1 = 1.23742 loss)
I0523 09:20:15.090947 24595 sgd_solver.cpp:106] Iteration 98100, lr = 0.0035
I0523 09:20:24.382360 24595 solver.cpp:237] Iteration 98400, loss = 1.04191
I0523 09:20:24.382395 24595 solver.cpp:253]     Train net output #0: loss = 1.04191 (* 1 = 1.04191 loss)
I0523 09:20:24.382412 24595 sgd_solver.cpp:106] Iteration 98400, lr = 0.0035
I0523 09:20:33.674408 24595 solver.cpp:237] Iteration 98700, loss = 1.21917
I0523 09:20:33.674439 24595 solver.cpp:253]     Train net output #0: loss = 1.21917 (* 1 = 1.21917 loss)
I0523 09:20:33.674453 24595 sgd_solver.cpp:106] Iteration 98700, lr = 0.0035
I0523 09:20:42.938088 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_99000.caffemodel
I0523 09:20:42.997862 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_99000.solverstate
I0523 09:20:43.034065 24595 solver.cpp:237] Iteration 99000, loss = 1.44311
I0523 09:20:43.034111 24595 solver.cpp:253]     Train net output #0: loss = 1.44311 (* 1 = 1.44311 loss)
I0523 09:20:43.034127 24595 sgd_solver.cpp:106] Iteration 99000, lr = 0.0035
I0523 09:20:52.327129 24595 solver.cpp:237] Iteration 99300, loss = 0.998629
I0523 09:20:52.327313 24595 solver.cpp:253]     Train net output #0: loss = 0.998629 (* 1 = 0.998629 loss)
I0523 09:20:52.327327 24595 sgd_solver.cpp:106] Iteration 99300, lr = 0.0035
I0523 09:21:01.620967 24595 solver.cpp:237] Iteration 99600, loss = 0.840318
I0523 09:21:01.621013 24595 solver.cpp:253]     Train net output #0: loss = 0.840318 (* 1 = 0.840318 loss)
I0523 09:21:01.621028 24595 sgd_solver.cpp:106] Iteration 99600, lr = 0.0035
I0523 09:21:10.908104 24595 solver.cpp:237] Iteration 99900, loss = 1.32184
I0523 09:21:10.908140 24595 solver.cpp:253]     Train net output #0: loss = 1.32184 (* 1 = 1.32184 loss)
I0523 09:21:10.908156 24595 sgd_solver.cpp:106] Iteration 99900, lr = 0.0035
I0523 09:21:41.138353 24595 solver.cpp:237] Iteration 100200, loss = 0.951328
I0523 09:21:41.138545 24595 solver.cpp:253]     Train net output #0: loss = 0.951328 (* 1 = 0.951328 loss)
I0523 09:21:41.138561 24595 sgd_solver.cpp:106] Iteration 100200, lr = 0.0035
I0523 09:21:50.426797 24595 solver.cpp:237] Iteration 100500, loss = 1.0867
I0523 09:21:50.426832 24595 solver.cpp:253]     Train net output #0: loss = 1.0867 (* 1 = 1.0867 loss)
I0523 09:21:50.426851 24595 sgd_solver.cpp:106] Iteration 100500, lr = 0.0035
I0523 09:21:59.720105 24595 solver.cpp:237] Iteration 100800, loss = 1.14616
I0523 09:21:59.720150 24595 solver.cpp:253]     Train net output #0: loss = 1.14616 (* 1 = 1.14616 loss)
I0523 09:21:59.720168 24595 sgd_solver.cpp:106] Iteration 100800, lr = 0.0035
I0523 09:22:09.009169 24595 solver.cpp:237] Iteration 101100, loss = 1.15438
I0523 09:22:09.009205 24595 solver.cpp:253]     Train net output #0: loss = 1.15438 (* 1 = 1.15438 loss)
I0523 09:22:09.009218 24595 sgd_solver.cpp:106] Iteration 101100, lr = 0.0035
I0523 09:22:18.298807 24595 solver.cpp:237] Iteration 101400, loss = 1.15725
I0523 09:22:18.298990 24595 solver.cpp:253]     Train net output #0: loss = 1.15725 (* 1 = 1.15725 loss)
I0523 09:22:18.299005 24595 sgd_solver.cpp:106] Iteration 101400, lr = 0.0035
I0523 09:22:27.588870 24595 solver.cpp:237] Iteration 101700, loss = 0.980815
I0523 09:22:27.588907 24595 solver.cpp:253]     Train net output #0: loss = 0.980815 (* 1 = 0.980815 loss)
I0523 09:22:27.588922 24595 sgd_solver.cpp:106] Iteration 101700, lr = 0.0035
I0523 09:22:36.844830 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_102000.caffemodel
I0523 09:22:36.903937 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_102000.solverstate
I0523 09:22:36.928736 24595 solver.cpp:341] Iteration 102000, Testing net (#0)
I0523 09:23:24.747706 24595 solver.cpp:409]     Test net output #0: accuracy = 0.897278
I0523 09:23:24.747905 24595 solver.cpp:409]     Test net output #1: loss = 0.346711 (* 1 = 0.346711 loss)
I0523 09:23:45.704131 24595 solver.cpp:237] Iteration 102000, loss = 1.03151
I0523 09:23:45.704185 24595 solver.cpp:253]     Train net output #0: loss = 1.03151 (* 1 = 1.03151 loss)
I0523 09:23:45.704200 24595 sgd_solver.cpp:106] Iteration 102000, lr = 0.0035
I0523 09:23:54.992661 24595 solver.cpp:237] Iteration 102300, loss = 1.11481
I0523 09:23:54.992837 24595 solver.cpp:253]     Train net output #0: loss = 1.11481 (* 1 = 1.11481 loss)
I0523 09:23:54.992851 24595 sgd_solver.cpp:106] Iteration 102300, lr = 0.0035
I0523 09:24:04.282321 24595 solver.cpp:237] Iteration 102600, loss = 1.38998
I0523 09:24:04.282361 24595 solver.cpp:253]     Train net output #0: loss = 1.38998 (* 1 = 1.38998 loss)
I0523 09:24:04.282376 24595 sgd_solver.cpp:106] Iteration 102600, lr = 0.0035
I0523 09:24:13.566649 24595 solver.cpp:237] Iteration 102900, loss = 1.25371
I0523 09:24:13.566684 24595 solver.cpp:253]     Train net output #0: loss = 1.25371 (* 1 = 1.25371 loss)
I0523 09:24:13.566700 24595 sgd_solver.cpp:106] Iteration 102900, lr = 0.0035
I0523 09:24:22.854742 24595 solver.cpp:237] Iteration 103200, loss = 1.09341
I0523 09:24:22.854786 24595 solver.cpp:253]     Train net output #0: loss = 1.09341 (* 1 = 1.09341 loss)
I0523 09:24:22.854800 24595 sgd_solver.cpp:106] Iteration 103200, lr = 0.0035
I0523 09:24:32.145259 24595 solver.cpp:237] Iteration 103500, loss = 0.926541
I0523 09:24:32.145431 24595 solver.cpp:253]     Train net output #0: loss = 0.926541 (* 1 = 0.926541 loss)
I0523 09:24:32.145445 24595 sgd_solver.cpp:106] Iteration 103500, lr = 0.0035
I0523 09:24:41.436381 24595 solver.cpp:237] Iteration 103800, loss = 1.32412
I0523 09:24:41.436415 24595 solver.cpp:253]     Train net output #0: loss = 1.32412 (* 1 = 1.32412 loss)
I0523 09:24:41.436434 24595 sgd_solver.cpp:106] Iteration 103800, lr = 0.0035
I0523 09:25:11.639386 24595 solver.cpp:237] Iteration 104100, loss = 1.1762
I0523 09:25:11.639572 24595 solver.cpp:253]     Train net output #0: loss = 1.1762 (* 1 = 1.1762 loss)
I0523 09:25:11.639586 24595 sgd_solver.cpp:106] Iteration 104100, lr = 0.0035
I0523 09:25:20.928592 24595 solver.cpp:237] Iteration 104400, loss = 1.13004
I0523 09:25:20.928628 24595 solver.cpp:253]     Train net output #0: loss = 1.13004 (* 1 = 1.13004 loss)
I0523 09:25:20.928644 24595 sgd_solver.cpp:106] Iteration 104400, lr = 0.0035
I0523 09:25:30.216514 24595 solver.cpp:237] Iteration 104700, loss = 0.958605
I0523 09:25:30.216552 24595 solver.cpp:253]     Train net output #0: loss = 0.958605 (* 1 = 0.958605 loss)
I0523 09:25:30.216567 24595 sgd_solver.cpp:106] Iteration 104700, lr = 0.0035
I0523 09:25:39.470335 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_105000.caffemodel
I0523 09:25:39.531757 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_105000.solverstate
I0523 09:25:39.569226 24595 solver.cpp:237] Iteration 105000, loss = 1.2568
I0523 09:25:39.569278 24595 solver.cpp:253]     Train net output #0: loss = 1.2568 (* 1 = 1.2568 loss)
I0523 09:25:39.569293 24595 sgd_solver.cpp:106] Iteration 105000, lr = 0.0035
I0523 09:25:48.854302 24595 solver.cpp:237] Iteration 105300, loss = 0.937405
I0523 09:25:48.854487 24595 solver.cpp:253]     Train net output #0: loss = 0.937405 (* 1 = 0.937405 loss)
I0523 09:25:48.854502 24595 sgd_solver.cpp:106] Iteration 105300, lr = 0.0035
I0523 09:25:58.143199 24595 solver.cpp:237] Iteration 105600, loss = 1.12865
I0523 09:25:58.143234 24595 solver.cpp:253]     Train net output #0: loss = 1.12865 (* 1 = 1.12865 loss)
I0523 09:25:58.143251 24595 sgd_solver.cpp:106] Iteration 105600, lr = 0.0035
I0523 09:26:07.432410 24595 solver.cpp:237] Iteration 105900, loss = 1.24917
I0523 09:26:07.432452 24595 solver.cpp:253]     Train net output #0: loss = 1.24917 (* 1 = 1.24917 loss)
I0523 09:26:07.432471 24595 sgd_solver.cpp:106] Iteration 105900, lr = 0.0035
I0523 09:26:37.669157 24595 solver.cpp:237] Iteration 106200, loss = 1.2791
I0523 09:26:37.669349 24595 solver.cpp:253]     Train net output #0: loss = 1.2791 (* 1 = 1.2791 loss)
I0523 09:26:37.669365 24595 sgd_solver.cpp:106] Iteration 106200, lr = 0.0035
I0523 09:26:46.956616 24595 solver.cpp:237] Iteration 106500, loss = 1.08095
I0523 09:26:46.956651 24595 solver.cpp:253]     Train net output #0: loss = 1.08095 (* 1 = 1.08095 loss)
I0523 09:26:46.956670 24595 sgd_solver.cpp:106] Iteration 106500, lr = 0.0035
I0523 09:26:56.244482 24595 solver.cpp:237] Iteration 106800, loss = 1.14436
I0523 09:26:56.244530 24595 solver.cpp:253]     Train net output #0: loss = 1.14436 (* 1 = 1.14436 loss)
I0523 09:26:56.244547 24595 sgd_solver.cpp:106] Iteration 106800, lr = 0.0035
I0523 09:27:05.534363 24595 solver.cpp:237] Iteration 107100, loss = 1.25367
I0523 09:27:05.534395 24595 solver.cpp:253]     Train net output #0: loss = 1.25367 (* 1 = 1.25367 loss)
I0523 09:27:05.534409 24595 sgd_solver.cpp:106] Iteration 107100, lr = 0.0035
I0523 09:27:14.824065 24595 solver.cpp:237] Iteration 107400, loss = 1.20353
I0523 09:27:14.824239 24595 solver.cpp:253]     Train net output #0: loss = 1.20353 (* 1 = 1.20353 loss)
I0523 09:27:14.824252 24595 sgd_solver.cpp:106] Iteration 107400, lr = 0.0035
I0523 09:27:24.111923 24595 solver.cpp:237] Iteration 107700, loss = 1.00966
I0523 09:27:24.111968 24595 solver.cpp:253]     Train net output #0: loss = 1.00966 (* 1 = 1.00966 loss)
I0523 09:27:24.111985 24595 sgd_solver.cpp:106] Iteration 107700, lr = 0.0035
I0523 09:27:33.371443 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_108000.caffemodel
I0523 09:27:33.433205 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_108000.solverstate
I0523 09:27:33.460981 24595 solver.cpp:341] Iteration 108000, Testing net (#0)
I0523 09:28:42.246819 24595 solver.cpp:409]     Test net output #0: accuracy = 0.898224
I0523 09:28:42.247012 24595 solver.cpp:409]     Test net output #1: loss = 0.320075 (* 1 = 0.320075 loss)
I0523 09:29:03.153733 24595 solver.cpp:237] Iteration 108000, loss = 0.781874
I0523 09:29:03.153787 24595 solver.cpp:253]     Train net output #0: loss = 0.781874 (* 1 = 0.781874 loss)
I0523 09:29:03.153802 24595 sgd_solver.cpp:106] Iteration 108000, lr = 0.0035
I0523 09:29:12.446702 24595 solver.cpp:237] Iteration 108300, loss = 0.882721
I0523 09:29:12.446879 24595 solver.cpp:253]     Train net output #0: loss = 0.882721 (* 1 = 0.882721 loss)
I0523 09:29:12.446895 24595 sgd_solver.cpp:106] Iteration 108300, lr = 0.0035
I0523 09:29:21.748112 24595 solver.cpp:237] Iteration 108600, loss = 1.13842
I0523 09:29:21.748160 24595 solver.cpp:253]     Train net output #0: loss = 1.13842 (* 1 = 1.13842 loss)
I0523 09:29:21.748178 24595 sgd_solver.cpp:106] Iteration 108600, lr = 0.0035
I0523 09:29:31.045581 24595 solver.cpp:237] Iteration 108900, loss = 1.03277
I0523 09:29:31.045619 24595 solver.cpp:253]     Train net output #0: loss = 1.03277 (* 1 = 1.03277 loss)
I0523 09:29:31.045634 24595 sgd_solver.cpp:106] Iteration 108900, lr = 0.0035
I0523 09:29:40.336410 24595 solver.cpp:237] Iteration 109200, loss = 1.01641
I0523 09:29:40.336447 24595 solver.cpp:253]     Train net output #0: loss = 1.01641 (* 1 = 1.01641 loss)
I0523 09:29:40.336462 24595 sgd_solver.cpp:106] Iteration 109200, lr = 0.0035
I0523 09:29:49.631001 24595 solver.cpp:237] Iteration 109500, loss = 1.24071
I0523 09:29:49.631201 24595 solver.cpp:253]     Train net output #0: loss = 1.24071 (* 1 = 1.24071 loss)
I0523 09:29:49.631216 24595 sgd_solver.cpp:106] Iteration 109500, lr = 0.0035
I0523 09:29:58.923307 24595 solver.cpp:237] Iteration 109800, loss = 0.962655
I0523 09:29:58.923343 24595 solver.cpp:253]     Train net output #0: loss = 0.962655 (* 1 = 0.962655 loss)
I0523 09:29:58.923362 24595 sgd_solver.cpp:106] Iteration 109800, lr = 0.0035
I0523 09:30:29.082430 24595 solver.cpp:237] Iteration 110100, loss = 1.03448
I0523 09:30:29.082624 24595 solver.cpp:253]     Train net output #0: loss = 1.03448 (* 1 = 1.03448 loss)
I0523 09:30:29.082640 24595 sgd_solver.cpp:106] Iteration 110100, lr = 0.0035
I0523 09:30:38.381062 24595 solver.cpp:237] Iteration 110400, loss = 1.09588
I0523 09:30:38.381108 24595 solver.cpp:253]     Train net output #0: loss = 1.09588 (* 1 = 1.09588 loss)
I0523 09:30:38.381125 24595 sgd_solver.cpp:106] Iteration 110400, lr = 0.0035
I0523 09:30:47.673621 24595 solver.cpp:237] Iteration 110700, loss = 1.12676
I0523 09:30:47.673657 24595 solver.cpp:253]     Train net output #0: loss = 1.12676 (* 1 = 1.12676 loss)
I0523 09:30:47.673673 24595 sgd_solver.cpp:106] Iteration 110700, lr = 0.0035
I0523 09:30:56.939944 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_111000.caffemodel
I0523 09:30:56.999447 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_111000.solverstate
I0523 09:30:57.034998 24595 solver.cpp:237] Iteration 111000, loss = 1.17798
I0523 09:30:57.035043 24595 solver.cpp:253]     Train net output #0: loss = 1.17798 (* 1 = 1.17798 loss)
I0523 09:30:57.035061 24595 sgd_solver.cpp:106] Iteration 111000, lr = 0.0035
I0523 09:31:06.329902 24595 solver.cpp:237] Iteration 111300, loss = 0.936338
I0523 09:31:06.330097 24595 solver.cpp:253]     Train net output #0: loss = 0.936338 (* 1 = 0.936338 loss)
I0523 09:31:06.330112 24595 sgd_solver.cpp:106] Iteration 111300, lr = 0.0035
I0523 09:31:15.626471 24595 solver.cpp:237] Iteration 111600, loss = 1.03064
I0523 09:31:15.626505 24595 solver.cpp:253]     Train net output #0: loss = 1.03064 (* 1 = 1.03064 loss)
I0523 09:31:15.626524 24595 sgd_solver.cpp:106] Iteration 111600, lr = 0.0035
I0523 09:31:24.916409 24595 solver.cpp:237] Iteration 111900, loss = 1.05044
I0523 09:31:24.916445 24595 solver.cpp:253]     Train net output #0: loss = 1.05044 (* 1 = 1.05044 loss)
I0523 09:31:24.916460 24595 sgd_solver.cpp:106] Iteration 111900, lr = 0.0035
I0523 09:31:55.109702 24595 solver.cpp:237] Iteration 112200, loss = 1.23072
I0523 09:31:55.109894 24595 solver.cpp:253]     Train net output #0: loss = 1.23072 (* 1 = 1.23072 loss)
I0523 09:31:55.109910 24595 sgd_solver.cpp:106] Iteration 112200, lr = 0.0035
I0523 09:32:04.403478 24595 solver.cpp:237] Iteration 112500, loss = 1.2232
I0523 09:32:04.403513 24595 solver.cpp:253]     Train net output #0: loss = 1.2232 (* 1 = 1.2232 loss)
I0523 09:32:04.403530 24595 sgd_solver.cpp:106] Iteration 112500, lr = 0.0035
I0523 09:32:13.699045 24595 solver.cpp:237] Iteration 112800, loss = 1.21309
I0523 09:32:13.699081 24595 solver.cpp:253]     Train net output #0: loss = 1.21309 (* 1 = 1.21309 loss)
I0523 09:32:13.699098 24595 sgd_solver.cpp:106] Iteration 112800, lr = 0.0035
I0523 09:32:22.995272 24595 solver.cpp:237] Iteration 113100, loss = 1.3897
I0523 09:32:22.995319 24595 solver.cpp:253]     Train net output #0: loss = 1.3897 (* 1 = 1.3897 loss)
I0523 09:32:22.995337 24595 sgd_solver.cpp:106] Iteration 113100, lr = 0.0035
I0523 09:32:32.292104 24595 solver.cpp:237] Iteration 113400, loss = 1.03837
I0523 09:32:32.292289 24595 solver.cpp:253]     Train net output #0: loss = 1.03837 (* 1 = 1.03837 loss)
I0523 09:32:32.292302 24595 sgd_solver.cpp:106] Iteration 113400, lr = 0.0035
I0523 09:32:41.584975 24595 solver.cpp:237] Iteration 113700, loss = 1.30331
I0523 09:32:41.585016 24595 solver.cpp:253]     Train net output #0: loss = 1.30331 (* 1 = 1.30331 loss)
I0523 09:32:41.585036 24595 sgd_solver.cpp:106] Iteration 113700, lr = 0.0035
I0523 09:32:50.849588 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_114000.caffemodel
I0523 09:32:50.908460 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_114000.solverstate
I0523 09:32:50.933732 24595 solver.cpp:341] Iteration 114000, Testing net (#0)
I0523 09:33:38.428694 24595 solver.cpp:409]     Test net output #0: accuracy = 0.89779
I0523 09:33:38.428887 24595 solver.cpp:409]     Test net output #1: loss = 0.321542 (* 1 = 0.321542 loss)
I0523 09:33:59.348476 24595 solver.cpp:237] Iteration 114000, loss = 1.06587
I0523 09:33:59.348529 24595 solver.cpp:253]     Train net output #0: loss = 1.06587 (* 1 = 1.06587 loss)
I0523 09:33:59.348546 24595 sgd_solver.cpp:106] Iteration 114000, lr = 0.0035
I0523 09:34:08.644848 24595 solver.cpp:237] Iteration 114300, loss = 1.32878
I0523 09:34:08.645028 24595 solver.cpp:253]     Train net output #0: loss = 1.32878 (* 1 = 1.32878 loss)
I0523 09:34:08.645042 24595 sgd_solver.cpp:106] Iteration 114300, lr = 0.0035
I0523 09:34:17.942440 24595 solver.cpp:237] Iteration 114600, loss = 1.01958
I0523 09:34:17.942476 24595 solver.cpp:253]     Train net output #0: loss = 1.01958 (* 1 = 1.01958 loss)
I0523 09:34:17.942493 24595 sgd_solver.cpp:106] Iteration 114600, lr = 0.0035
I0523 09:34:27.243239 24595 solver.cpp:237] Iteration 114900, loss = 0.885801
I0523 09:34:27.243274 24595 solver.cpp:253]     Train net output #0: loss = 0.885801 (* 1 = 0.885801 loss)
I0523 09:34:27.243297 24595 sgd_solver.cpp:106] Iteration 114900, lr = 0.0035
I0523 09:34:36.540241 24595 solver.cpp:237] Iteration 115200, loss = 0.963599
I0523 09:34:36.540277 24595 solver.cpp:253]     Train net output #0: loss = 0.963599 (* 1 = 0.963599 loss)
I0523 09:34:36.540293 24595 sgd_solver.cpp:106] Iteration 115200, lr = 0.0035
I0523 09:34:45.834727 24595 solver.cpp:237] Iteration 115500, loss = 1.04715
I0523 09:34:45.834903 24595 solver.cpp:253]     Train net output #0: loss = 1.04715 (* 1 = 1.04715 loss)
I0523 09:34:45.834916 24595 sgd_solver.cpp:106] Iteration 115500, lr = 0.0035
I0523 09:34:55.126569 24595 solver.cpp:237] Iteration 115800, loss = 1.1101
I0523 09:34:55.126605 24595 solver.cpp:253]     Train net output #0: loss = 1.1101 (* 1 = 1.1101 loss)
I0523 09:34:55.126626 24595 sgd_solver.cpp:106] Iteration 115800, lr = 0.0035
I0523 09:35:25.327932 24595 solver.cpp:237] Iteration 116100, loss = 1.32186
I0523 09:35:25.328127 24595 solver.cpp:253]     Train net output #0: loss = 1.32186 (* 1 = 1.32186 loss)
I0523 09:35:25.328142 24595 sgd_solver.cpp:106] Iteration 116100, lr = 0.0035
I0523 09:35:34.622977 24595 solver.cpp:237] Iteration 116400, loss = 1.37516
I0523 09:35:34.623013 24595 solver.cpp:253]     Train net output #0: loss = 1.37516 (* 1 = 1.37516 loss)
I0523 09:35:34.623031 24595 sgd_solver.cpp:106] Iteration 116400, lr = 0.0035
I0523 09:35:43.926250 24595 solver.cpp:237] Iteration 116700, loss = 1.28919
I0523 09:35:43.926298 24595 solver.cpp:253]     Train net output #0: loss = 1.28919 (* 1 = 1.28919 loss)
I0523 09:35:43.926316 24595 sgd_solver.cpp:106] Iteration 116700, lr = 0.0035
I0523 09:35:53.193868 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_117000.caffemodel
I0523 09:35:53.254544 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_117000.solverstate
I0523 09:35:53.289468 24595 solver.cpp:237] Iteration 117000, loss = 1.14172
I0523 09:35:53.289511 24595 solver.cpp:253]     Train net output #0: loss = 1.14172 (* 1 = 1.14172 loss)
I0523 09:35:53.289525 24595 sgd_solver.cpp:106] Iteration 117000, lr = 0.0035
I0523 09:36:02.586796 24595 solver.cpp:237] Iteration 117300, loss = 0.873411
I0523 09:36:02.586997 24595 solver.cpp:253]     Train net output #0: loss = 0.873411 (* 1 = 0.873411 loss)
I0523 09:36:02.587012 24595 sgd_solver.cpp:106] Iteration 117300, lr = 0.0035
I0523 09:36:11.877784 24595 solver.cpp:237] Iteration 117600, loss = 1.28441
I0523 09:36:11.877820 24595 solver.cpp:253]     Train net output #0: loss = 1.28441 (* 1 = 1.28441 loss)
I0523 09:36:11.877835 24595 sgd_solver.cpp:106] Iteration 117600, lr = 0.0035
I0523 09:36:21.170017 24595 solver.cpp:237] Iteration 117900, loss = 1.37263
I0523 09:36:21.170053 24595 solver.cpp:253]     Train net output #0: loss = 1.37263 (* 1 = 1.37263 loss)
I0523 09:36:21.170073 24595 sgd_solver.cpp:106] Iteration 117900, lr = 0.0035
I0523 09:36:51.366220 24595 solver.cpp:237] Iteration 118200, loss = 0.900758
I0523 09:36:51.366416 24595 solver.cpp:253]     Train net output #0: loss = 0.900758 (* 1 = 0.900758 loss)
I0523 09:36:51.366432 24595 sgd_solver.cpp:106] Iteration 118200, lr = 0.0035
I0523 09:37:00.664367 24595 solver.cpp:237] Iteration 118500, loss = 1.02483
I0523 09:37:00.664410 24595 solver.cpp:253]     Train net output #0: loss = 1.02483 (* 1 = 1.02483 loss)
I0523 09:37:00.664427 24595 sgd_solver.cpp:106] Iteration 118500, lr = 0.0035
I0523 09:37:09.961741 24595 solver.cpp:237] Iteration 118800, loss = 1.11524
I0523 09:37:09.961777 24595 solver.cpp:253]     Train net output #0: loss = 1.11524 (* 1 = 1.11524 loss)
I0523 09:37:09.961792 24595 sgd_solver.cpp:106] Iteration 118800, lr = 0.0035
I0523 09:37:19.259677 24595 solver.cpp:237] Iteration 119100, loss = 1.19403
I0523 09:37:19.259723 24595 solver.cpp:253]     Train net output #0: loss = 1.19403 (* 1 = 1.19403 loss)
I0523 09:37:19.259739 24595 sgd_solver.cpp:106] Iteration 119100, lr = 0.0035
I0523 09:37:28.552773 24595 solver.cpp:237] Iteration 119400, loss = 1.05086
I0523 09:37:28.552950 24595 solver.cpp:253]     Train net output #0: loss = 1.05086 (* 1 = 1.05086 loss)
I0523 09:37:28.552963 24595 sgd_solver.cpp:106] Iteration 119400, lr = 0.0035
I0523 09:37:37.850371 24595 solver.cpp:237] Iteration 119700, loss = 1.26786
I0523 09:37:37.850406 24595 solver.cpp:253]     Train net output #0: loss = 1.26786 (* 1 = 1.26786 loss)
I0523 09:37:37.850421 24595 sgd_solver.cpp:106] Iteration 119700, lr = 0.0035
I0523 09:37:47.116482 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_120000.caffemodel
I0523 09:37:47.178699 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_120000.solverstate
I0523 09:37:47.206143 24595 solver.cpp:341] Iteration 120000, Testing net (#0)
I0523 09:38:55.965334 24595 solver.cpp:409]     Test net output #0: accuracy = 0.897857
I0523 09:38:55.965529 24595 solver.cpp:409]     Test net output #1: loss = 0.322084 (* 1 = 0.322084 loss)
I0523 09:39:16.893013 24595 solver.cpp:237] Iteration 120000, loss = 1.23268
I0523 09:39:16.893065 24595 solver.cpp:253]     Train net output #0: loss = 1.23268 (* 1 = 1.23268 loss)
I0523 09:39:16.893080 24595 sgd_solver.cpp:106] Iteration 120000, lr = 0.0035
I0523 09:39:26.173172 24595 solver.cpp:237] Iteration 120300, loss = 0.910736
I0523 09:39:26.173375 24595 solver.cpp:253]     Train net output #0: loss = 0.910736 (* 1 = 0.910736 loss)
I0523 09:39:26.173389 24595 sgd_solver.cpp:106] Iteration 120300, lr = 0.0035
I0523 09:39:35.455695 24595 solver.cpp:237] Iteration 120600, loss = 1.30317
I0523 09:39:35.455730 24595 solver.cpp:253]     Train net output #0: loss = 1.30317 (* 1 = 1.30317 loss)
I0523 09:39:35.455746 24595 sgd_solver.cpp:106] Iteration 120600, lr = 0.0035
I0523 09:39:44.739850 24595 solver.cpp:237] Iteration 120900, loss = 1.3172
I0523 09:39:44.739886 24595 solver.cpp:253]     Train net output #0: loss = 1.3172 (* 1 = 1.3172 loss)
I0523 09:39:44.739902 24595 sgd_solver.cpp:106] Iteration 120900, lr = 0.0035
I0523 09:39:54.020952 24595 solver.cpp:237] Iteration 121200, loss = 1.21888
I0523 09:39:54.020993 24595 solver.cpp:253]     Train net output #0: loss = 1.21888 (* 1 = 1.21888 loss)
I0523 09:39:54.021013 24595 sgd_solver.cpp:106] Iteration 121200, lr = 0.0035
I0523 09:40:03.302940 24595 solver.cpp:237] Iteration 121500, loss = 1.12531
I0523 09:40:03.303128 24595 solver.cpp:253]     Train net output #0: loss = 1.12531 (* 1 = 1.12531 loss)
I0523 09:40:03.303143 24595 sgd_solver.cpp:106] Iteration 121500, lr = 0.0035
I0523 09:40:12.590183 24595 solver.cpp:237] Iteration 121800, loss = 1.27654
I0523 09:40:12.590229 24595 solver.cpp:253]     Train net output #0: loss = 1.27654 (* 1 = 1.27654 loss)
I0523 09:40:12.590243 24595 sgd_solver.cpp:106] Iteration 121800, lr = 0.0035
I0523 09:40:42.771277 24595 solver.cpp:237] Iteration 122100, loss = 0.919999
I0523 09:40:42.771473 24595 solver.cpp:253]     Train net output #0: loss = 0.919999 (* 1 = 0.919999 loss)
I0523 09:40:42.771488 24595 sgd_solver.cpp:106] Iteration 122100, lr = 0.0035
I0523 09:40:52.053944 24595 solver.cpp:237] Iteration 122400, loss = 1.32214
I0523 09:40:52.053979 24595 solver.cpp:253]     Train net output #0: loss = 1.32214 (* 1 = 1.32214 loss)
I0523 09:40:52.053995 24595 sgd_solver.cpp:106] Iteration 122400, lr = 0.0035
I0523 09:41:01.336205 24595 solver.cpp:237] Iteration 122700, loss = 1.56245
I0523 09:41:01.336241 24595 solver.cpp:253]     Train net output #0: loss = 1.56245 (* 1 = 1.56245 loss)
I0523 09:41:01.336256 24595 sgd_solver.cpp:106] Iteration 122700, lr = 0.0035
I0523 09:41:10.587844 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_123000.caffemodel
I0523 09:41:10.647152 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_123000.solverstate
I0523 09:41:10.682006 24595 solver.cpp:237] Iteration 123000, loss = 1.26824
I0523 09:41:10.682047 24595 solver.cpp:253]     Train net output #0: loss = 1.26824 (* 1 = 1.26824 loss)
I0523 09:41:10.682073 24595 sgd_solver.cpp:106] Iteration 123000, lr = 0.0035
I0523 09:41:19.961330 24595 solver.cpp:237] Iteration 123300, loss = 1.22593
I0523 09:41:19.961519 24595 solver.cpp:253]     Train net output #0: loss = 1.22593 (* 1 = 1.22593 loss)
I0523 09:41:19.961534 24595 sgd_solver.cpp:106] Iteration 123300, lr = 0.0035
I0523 09:41:29.241226 24595 solver.cpp:237] Iteration 123600, loss = 1.11067
I0523 09:41:29.241271 24595 solver.cpp:253]     Train net output #0: loss = 1.11067 (* 1 = 1.11067 loss)
I0523 09:41:29.241286 24595 sgd_solver.cpp:106] Iteration 123600, lr = 0.0035
I0523 09:41:38.527081 24595 solver.cpp:237] Iteration 123900, loss = 1.12062
I0523 09:41:38.527115 24595 solver.cpp:253]     Train net output #0: loss = 1.12062 (* 1 = 1.12062 loss)
I0523 09:41:38.527132 24595 sgd_solver.cpp:106] Iteration 123900, lr = 0.0035
I0523 09:42:08.692883 24595 solver.cpp:237] Iteration 124200, loss = 0.999937
I0523 09:42:08.693080 24595 solver.cpp:253]     Train net output #0: loss = 0.999937 (* 1 = 0.999937 loss)
I0523 09:42:08.693097 24595 sgd_solver.cpp:106] Iteration 124200, lr = 0.0035
I0523 09:42:17.976697 24595 solver.cpp:237] Iteration 124500, loss = 1.11545
I0523 09:42:17.976742 24595 solver.cpp:253]     Train net output #0: loss = 1.11545 (* 1 = 1.11545 loss)
I0523 09:42:17.976758 24595 sgd_solver.cpp:106] Iteration 124500, lr = 0.0035
I0523 09:42:27.261274 24595 solver.cpp:237] Iteration 124800, loss = 1.27403
I0523 09:42:27.261309 24595 solver.cpp:253]     Train net output #0: loss = 1.27403 (* 1 = 1.27403 loss)
I0523 09:42:27.261324 24595 sgd_solver.cpp:106] Iteration 124800, lr = 0.0035
I0523 09:42:36.545958 24595 solver.cpp:237] Iteration 125100, loss = 1.34454
I0523 09:42:36.545994 24595 solver.cpp:253]     Train net output #0: loss = 1.34454 (* 1 = 1.34454 loss)
I0523 09:42:36.546008 24595 sgd_solver.cpp:106] Iteration 125100, lr = 0.0035
I0523 09:42:45.822794 24595 solver.cpp:237] Iteration 125400, loss = 0.999626
I0523 09:42:45.822993 24595 solver.cpp:253]     Train net output #0: loss = 0.999626 (* 1 = 0.999626 loss)
I0523 09:42:45.823006 24595 sgd_solver.cpp:106] Iteration 125400, lr = 0.0035
I0523 09:42:55.100162 24595 solver.cpp:237] Iteration 125700, loss = 1.02648
I0523 09:42:55.100196 24595 solver.cpp:253]     Train net output #0: loss = 1.02648 (* 1 = 1.02648 loss)
I0523 09:42:55.100211 24595 sgd_solver.cpp:106] Iteration 125700, lr = 0.0035
I0523 09:43:04.352843 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_126000.caffemodel
I0523 09:43:04.411844 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_126000.solverstate
I0523 09:43:04.436796 24595 solver.cpp:341] Iteration 126000, Testing net (#0)
I0523 09:43:52.242830 24595 solver.cpp:409]     Test net output #0: accuracy = 0.898136
I0523 09:43:52.243026 24595 solver.cpp:409]     Test net output #1: loss = 0.313055 (* 1 = 0.313055 loss)
I0523 09:44:13.148032 24595 solver.cpp:237] Iteration 126000, loss = 0.870152
I0523 09:44:13.148084 24595 solver.cpp:253]     Train net output #0: loss = 0.870152 (* 1 = 0.870152 loss)
I0523 09:44:13.148102 24595 sgd_solver.cpp:106] Iteration 126000, lr = 0.0035
I0523 09:44:22.433497 24595 solver.cpp:237] Iteration 126300, loss = 1.31614
I0523 09:44:22.433691 24595 solver.cpp:253]     Train net output #0: loss = 1.31614 (* 1 = 1.31614 loss)
I0523 09:44:22.433706 24595 sgd_solver.cpp:106] Iteration 126300, lr = 0.0035
I0523 09:44:31.727829 24595 solver.cpp:237] Iteration 126600, loss = 0.915938
I0523 09:44:31.727865 24595 solver.cpp:253]     Train net output #0: loss = 0.915938 (* 1 = 0.915938 loss)
I0523 09:44:31.727881 24595 sgd_solver.cpp:106] Iteration 126600, lr = 0.0035
I0523 09:44:41.020485 24595 solver.cpp:237] Iteration 126900, loss = 1.21957
I0523 09:44:41.020520 24595 solver.cpp:253]     Train net output #0: loss = 1.21957 (* 1 = 1.21957 loss)
I0523 09:44:41.020535 24595 sgd_solver.cpp:106] Iteration 126900, lr = 0.0035
I0523 09:44:50.314738 24595 solver.cpp:237] Iteration 127200, loss = 1.16399
I0523 09:44:50.314776 24595 solver.cpp:253]     Train net output #0: loss = 1.16399 (* 1 = 1.16399 loss)
I0523 09:44:50.314797 24595 sgd_solver.cpp:106] Iteration 127200, lr = 0.0035
I0523 09:44:59.609305 24595 solver.cpp:237] Iteration 127500, loss = 1.24252
I0523 09:44:59.609491 24595 solver.cpp:253]     Train net output #0: loss = 1.24252 (* 1 = 1.24252 loss)
I0523 09:44:59.609504 24595 sgd_solver.cpp:106] Iteration 127500, lr = 0.0035
I0523 09:45:08.910080 24595 solver.cpp:237] Iteration 127800, loss = 1.23252
I0523 09:45:08.910115 24595 solver.cpp:253]     Train net output #0: loss = 1.23252 (* 1 = 1.23252 loss)
I0523 09:45:08.910130 24595 sgd_solver.cpp:106] Iteration 127800, lr = 0.0035
I0523 09:45:39.083046 24595 solver.cpp:237] Iteration 128100, loss = 1.1352
I0523 09:45:39.083245 24595 solver.cpp:253]     Train net output #0: loss = 1.1352 (* 1 = 1.1352 loss)
I0523 09:45:39.083259 24595 sgd_solver.cpp:106] Iteration 128100, lr = 0.0035
I0523 09:45:48.370944 24595 solver.cpp:237] Iteration 128400, loss = 1.09321
I0523 09:45:48.370978 24595 solver.cpp:253]     Train net output #0: loss = 1.09321 (* 1 = 1.09321 loss)
I0523 09:45:48.370993 24595 sgd_solver.cpp:106] Iteration 128400, lr = 0.0035
I0523 09:45:57.663558 24595 solver.cpp:237] Iteration 128700, loss = 1.21363
I0523 09:45:57.663592 24595 solver.cpp:253]     Train net output #0: loss = 1.21363 (* 1 = 1.21363 loss)
I0523 09:45:57.663606 24595 sgd_solver.cpp:106] Iteration 128700, lr = 0.0035
I0523 09:46:06.926105 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_129000.caffemodel
I0523 09:46:06.985800 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_129000.solverstate
I0523 09:46:07.021106 24595 solver.cpp:237] Iteration 129000, loss = 1.16973
I0523 09:46:07.021150 24595 solver.cpp:253]     Train net output #0: loss = 1.16973 (* 1 = 1.16973 loss)
I0523 09:46:07.021167 24595 sgd_solver.cpp:106] Iteration 129000, lr = 0.0035
I0523 09:46:16.314019 24595 solver.cpp:237] Iteration 129300, loss = 1.38912
I0523 09:46:16.314216 24595 solver.cpp:253]     Train net output #0: loss = 1.38912 (* 1 = 1.38912 loss)
I0523 09:46:16.314230 24595 sgd_solver.cpp:106] Iteration 129300, lr = 0.0035
I0523 09:46:25.608639 24595 solver.cpp:237] Iteration 129600, loss = 1.2606
I0523 09:46:25.608675 24595 solver.cpp:253]     Train net output #0: loss = 1.2606 (* 1 = 1.2606 loss)
I0523 09:46:25.608690 24595 sgd_solver.cpp:106] Iteration 129600, lr = 0.0035
I0523 09:46:34.899382 24595 solver.cpp:237] Iteration 129900, loss = 1.23201
I0523 09:46:34.899418 24595 solver.cpp:253]     Train net output #0: loss = 1.23201 (* 1 = 1.23201 loss)
I0523 09:46:34.899437 24595 sgd_solver.cpp:106] Iteration 129900, lr = 0.0035
I0523 09:47:05.074224 24595 solver.cpp:237] Iteration 130200, loss = 1.24385
I0523 09:47:05.074425 24595 solver.cpp:253]     Train net output #0: loss = 1.24385 (* 1 = 1.24385 loss)
I0523 09:47:05.074442 24595 sgd_solver.cpp:106] Iteration 130200, lr = 0.0035
I0523 09:47:14.363713 24595 solver.cpp:237] Iteration 130500, loss = 1.16906
I0523 09:47:14.363746 24595 solver.cpp:253]     Train net output #0: loss = 1.16906 (* 1 = 1.16906 loss)
I0523 09:47:14.363762 24595 sgd_solver.cpp:106] Iteration 130500, lr = 0.0035
I0523 09:47:23.657048 24595 solver.cpp:237] Iteration 130800, loss = 1.1846
I0523 09:47:23.657083 24595 solver.cpp:253]     Train net output #0: loss = 1.1846 (* 1 = 1.1846 loss)
I0523 09:47:23.657095 24595 sgd_solver.cpp:106] Iteration 130800, lr = 0.0035
I0523 09:47:32.954504 24595 solver.cpp:237] Iteration 131100, loss = 1.05816
I0523 09:47:32.954538 24595 solver.cpp:253]     Train net output #0: loss = 1.05816 (* 1 = 1.05816 loss)
I0523 09:47:32.954553 24595 sgd_solver.cpp:106] Iteration 131100, lr = 0.0035
I0523 09:47:42.250959 24595 solver.cpp:237] Iteration 131400, loss = 1.11039
I0523 09:47:42.251139 24595 solver.cpp:253]     Train net output #0: loss = 1.11039 (* 1 = 1.11039 loss)
I0523 09:47:42.251153 24595 sgd_solver.cpp:106] Iteration 131400, lr = 0.0035
I0523 09:47:51.542601 24595 solver.cpp:237] Iteration 131700, loss = 0.952743
I0523 09:47:51.542637 24595 solver.cpp:253]     Train net output #0: loss = 0.952743 (* 1 = 0.952743 loss)
I0523 09:47:51.542651 24595 sgd_solver.cpp:106] Iteration 131700, lr = 0.0035
I0523 09:48:00.805063 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_132000.caffemodel
I0523 09:48:00.874909 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_132000.solverstate
I0523 09:48:00.900728 24595 solver.cpp:341] Iteration 132000, Testing net (#0)
I0523 09:49:09.617007 24595 solver.cpp:409]     Test net output #0: accuracy = 0.898956
I0523 09:49:09.617215 24595 solver.cpp:409]     Test net output #1: loss = 0.343011 (* 1 = 0.343011 loss)
I0523 09:49:30.562568 24595 solver.cpp:237] Iteration 132000, loss = 1.23935
I0523 09:49:30.562621 24595 solver.cpp:253]     Train net output #0: loss = 1.23935 (* 1 = 1.23935 loss)
I0523 09:49:30.562638 24595 sgd_solver.cpp:106] Iteration 132000, lr = 0.0035
I0523 09:49:39.855159 24595 solver.cpp:237] Iteration 132300, loss = 0.857996
I0523 09:49:39.855345 24595 solver.cpp:253]     Train net output #0: loss = 0.857996 (* 1 = 0.857996 loss)
I0523 09:49:39.855360 24595 sgd_solver.cpp:106] Iteration 132300, lr = 0.0035
I0523 09:49:49.144136 24595 solver.cpp:237] Iteration 132600, loss = 1.36732
I0523 09:49:49.144176 24595 solver.cpp:253]     Train net output #0: loss = 1.36732 (* 1 = 1.36732 loss)
I0523 09:49:49.144196 24595 sgd_solver.cpp:106] Iteration 132600, lr = 0.0035
I0523 09:49:58.432930 24595 solver.cpp:237] Iteration 132900, loss = 0.985334
I0523 09:49:58.432967 24595 solver.cpp:253]     Train net output #0: loss = 0.985334 (* 1 = 0.985334 loss)
I0523 09:49:58.432981 24595 sgd_solver.cpp:106] Iteration 132900, lr = 0.0035
I0523 09:50:07.722724 24595 solver.cpp:237] Iteration 133200, loss = 1.40795
I0523 09:50:07.722760 24595 solver.cpp:253]     Train net output #0: loss = 1.40795 (* 1 = 1.40795 loss)
I0523 09:50:07.722775 24595 sgd_solver.cpp:106] Iteration 133200, lr = 0.0035
I0523 09:50:17.012321 24595 solver.cpp:237] Iteration 133500, loss = 1.14672
I0523 09:50:17.012516 24595 solver.cpp:253]     Train net output #0: loss = 1.14672 (* 1 = 1.14672 loss)
I0523 09:50:17.012531 24595 sgd_solver.cpp:106] Iteration 133500, lr = 0.0035
I0523 09:50:26.305102 24595 solver.cpp:237] Iteration 133800, loss = 1.15302
I0523 09:50:26.305136 24595 solver.cpp:253]     Train net output #0: loss = 1.15302 (* 1 = 1.15302 loss)
I0523 09:50:26.305152 24595 sgd_solver.cpp:106] Iteration 133800, lr = 0.0035
I0523 09:50:56.475374 24595 solver.cpp:237] Iteration 134100, loss = 0.974522
I0523 09:50:56.475579 24595 solver.cpp:253]     Train net output #0: loss = 0.974522 (* 1 = 0.974522 loss)
I0523 09:50:56.475595 24595 sgd_solver.cpp:106] Iteration 134100, lr = 0.0035
I0523 09:51:05.766844 24595 solver.cpp:237] Iteration 134400, loss = 1.13139
I0523 09:51:05.766891 24595 solver.cpp:253]     Train net output #0: loss = 1.13139 (* 1 = 1.13139 loss)
I0523 09:51:05.766906 24595 sgd_solver.cpp:106] Iteration 134400, lr = 0.0035
I0523 09:51:15.057921 24595 solver.cpp:237] Iteration 134700, loss = 1.21061
I0523 09:51:15.057957 24595 solver.cpp:253]     Train net output #0: loss = 1.21061 (* 1 = 1.21061 loss)
I0523 09:51:15.057971 24595 sgd_solver.cpp:106] Iteration 134700, lr = 0.0035
I0523 09:51:24.321388 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_135000.caffemodel
I0523 09:51:24.382997 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_135000.solverstate
I0523 09:51:24.420187 24595 solver.cpp:237] Iteration 135000, loss = 0.994257
I0523 09:51:24.420233 24595 solver.cpp:253]     Train net output #0: loss = 0.994257 (* 1 = 0.994257 loss)
I0523 09:51:24.420248 24595 sgd_solver.cpp:106] Iteration 135000, lr = 0.0035
I0523 09:51:33.713227 24595 solver.cpp:237] Iteration 135300, loss = 1.40161
I0523 09:51:33.713426 24595 solver.cpp:253]     Train net output #0: loss = 1.40161 (* 1 = 1.40161 loss)
I0523 09:51:33.713440 24595 sgd_solver.cpp:106] Iteration 135300, lr = 0.0035
I0523 09:51:43.004624 24595 solver.cpp:237] Iteration 135600, loss = 1.26714
I0523 09:51:43.004658 24595 solver.cpp:253]     Train net output #0: loss = 1.26714 (* 1 = 1.26714 loss)
I0523 09:51:43.004674 24595 sgd_solver.cpp:106] Iteration 135600, lr = 0.0035
I0523 09:51:52.294807 24595 solver.cpp:237] Iteration 135900, loss = 0.918002
I0523 09:51:52.294859 24595 solver.cpp:253]     Train net output #0: loss = 0.918002 (* 1 = 0.918002 loss)
I0523 09:51:52.294874 24595 sgd_solver.cpp:106] Iteration 135900, lr = 0.0035
I0523 09:52:22.495827 24595 solver.cpp:237] Iteration 136200, loss = 1.1064
I0523 09:52:22.496037 24595 solver.cpp:253]     Train net output #0: loss = 1.1064 (* 1 = 1.1064 loss)
I0523 09:52:22.496053 24595 sgd_solver.cpp:106] Iteration 136200, lr = 0.0035
I0523 09:52:31.786075 24595 solver.cpp:237] Iteration 136500, loss = 1.16481
I0523 09:52:31.786110 24595 solver.cpp:253]     Train net output #0: loss = 1.16481 (* 1 = 1.16481 loss)
I0523 09:52:31.786126 24595 sgd_solver.cpp:106] Iteration 136500, lr = 0.0035
I0523 09:52:41.077803 24595 solver.cpp:237] Iteration 136800, loss = 1.09578
I0523 09:52:41.077839 24595 solver.cpp:253]     Train net output #0: loss = 1.09578 (* 1 = 1.09578 loss)
I0523 09:52:41.077853 24595 sgd_solver.cpp:106] Iteration 136800, lr = 0.0035
I0523 09:52:50.370095 24595 solver.cpp:237] Iteration 137100, loss = 1.09352
I0523 09:52:50.370138 24595 solver.cpp:253]     Train net output #0: loss = 1.09352 (* 1 = 1.09352 loss)
I0523 09:52:50.370153 24595 sgd_solver.cpp:106] Iteration 137100, lr = 0.0035
I0523 09:52:59.659677 24595 solver.cpp:237] Iteration 137400, loss = 1.16547
I0523 09:52:59.659859 24595 solver.cpp:253]     Train net output #0: loss = 1.16547 (* 1 = 1.16547 loss)
I0523 09:52:59.659873 24595 sgd_solver.cpp:106] Iteration 137400, lr = 0.0035
I0523 09:53:08.951568 24595 solver.cpp:237] Iteration 137700, loss = 1.07288
I0523 09:53:08.951611 24595 solver.cpp:253]     Train net output #0: loss = 1.07288 (* 1 = 1.07288 loss)
I0523 09:53:08.951628 24595 sgd_solver.cpp:106] Iteration 137700, lr = 0.0035
I0523 09:53:18.209583 24595 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_138000.caffemodel
I0523 09:53:18.269018 24595 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_50_lr_0.0035_2016-05-20T15.49.07.290047_iter_138000.solverstate
I0523 09:53:18.294719 24595 solver.cpp:341] Iteration 138000, Testing net (#0)
I0523 09:54:05.769770 24595 solver.cpp:409]     Test net output #0: accuracy = 0.902808
I0523 09:54:05.769968 24595 solver.cpp:409]     Test net output #1: loss = 0.310719 (* 1 = 0.310719 loss)
I0523 09:54:26.677072 24595 solver.cpp:237] Iteration 138000, loss = 1.0278
I0523 09:54:26.677124 24595 solver.cpp:253]     Train net output #0: loss = 1.0278 (* 1 = 1.0278 loss)
I0523 09:54:26.677139 24595 sgd_solver.cpp:106] Iteration 138000, lr = 0.0035
I0523 09:54:35.967367 24595 solver.cpp:237] Iteration 138300, loss = 1.02512
I0523 09:54:35.967553 24595 solver.cpp:253]     Train net output #0: loss = 1.02512 (* 1 = 1.02512 loss)
I0523 09:54:35.967566 24595 sgd_solver.cpp:106] Iteration 138300, lr = 0.0035
I0523 09:54:45.253183 24595 solver.cpp:237] Iteration 138600, loss = 1.13739
I0523 09:54:45.253218 24595 solver.cpp:253]     Train net output #0: loss = 1.13739 (* 1 = 1.13739 loss)
I0523 09:54:45.253233 24595 sgd_solver.cpp:106] Iteration 138600, lr = 0.0035
I0523 09:54:54.539957 24595 solver.cpp:237] Iteration 138900, loss = 1.33856
I0523 09:54:54.540004 24595 solver.cpp:253]     Train net output #0: loss = 1.33856 (* 1 = 1.33856 loss)
I0523 09:54:54.540019 24595 sgd_solver.cpp:106] Iteration 138900, lr = 0.0035
I0523 09:55:03.829485 24595 solver.cpp:237] Iteration 139200, loss = 1.11892
I0523 09:55:03.829520 24595 solver.cpp:253]     Train net output #0: loss = 1.11892 (* 1 = 1.11892 loss)
I0523 09:55:03.829536 24595 sgd_solver.cpp:106] Iteration 139200, lr = 0.0035
I0523 09:55:13.115218 24595 solver.cpp:237] Iteration 139500, loss = 1.0233
I0523 09:55:13.115411 24595 solver.cpp:253]     Train net output #0: loss = 1.0233 (* 1 = 1.0233 loss)
I0523 09:55:13.115427 24595 sgd_solver.cpp:106] Iteration 139500, lr = 0.0035
I0523 09:55:22.402799 24595 solver.cpp:237] Iteration 139800, loss = 1.07731
I0523 09:55:22.402834 24595 solver.cpp:253]     Train net output #0: loss = 1.07731 (* 1 = 1.07731 loss)
I0523 09:55:22.402849 24595 sgd_solver.cpp:106] Iteration 139800, lr = 0.0035
aprun: Apid 11253616: Caught signal Terminated, sending to application
*** Aborted at 1464011737 (unix time) try "date -d @1464011737" if you are using GNU date ***
aprun: Apid 11253616: Caught signal Terminated, sending to application
PC: @     0x2aaac5e965f3 adler32
aprun: Apid 11253616: Caught signal Terminated, sending to application
*** SIGTERM (@0x6010) received by PID 24595 (TID 0x2aaac746f900) from PID 24592; stack trace: ***
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaac5e965f3 adler32
aprun: Apid 11253616: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7240 exceeded limit 7200
    @     0x2aaac5e9e607 inflate
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11253616: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11253616: Caught signal Terminated, sending to application
aprun: Apid 11253616: Caught signal Terminated, sending to application
aprun: Apid 11253616: Caught signal Terminated, sending to application
aprun: Apid 11253616: Caught signal Terminated, sending to application
aprun: Apid 11253616: Caught signal Terminated, sending to application
aprun: Apid 11253616: Caught signal Terminated, sending to application
aprun: Apid 11253616: Caught signal Terminated, sending to application
