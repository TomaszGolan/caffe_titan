2806748
I0521 14:01:06.004592  1271 caffe.cpp:184] Using GPUs 0
I0521 14:01:06.436731  1271 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.002
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054.prototxt"
I0521 14:01:06.438274  1271 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054.prototxt
I0521 14:01:06.455361  1271 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 14:01:06.455421  1271 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 14:01:06.455768  1271 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 14:01:06.455948  1271 layer_factory.hpp:77] Creating layer data_hdf5
I0521 14:01:06.455972  1271 net.cpp:106] Creating Layer data_hdf5
I0521 14:01:06.455987  1271 net.cpp:411] data_hdf5 -> data
I0521 14:01:06.456020  1271 net.cpp:411] data_hdf5 -> label
I0521 14:01:06.456053  1271 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 14:01:06.457299  1271 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 14:01:06.459475  1271 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 14:01:28.002847  1271 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 14:01:28.008070  1271 net.cpp:150] Setting up data_hdf5
I0521 14:01:28.008111  1271 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 14:01:28.008126  1271 net.cpp:157] Top shape: 10 (10)
I0521 14:01:28.008138  1271 net.cpp:165] Memory required for data: 254040
I0521 14:01:28.008153  1271 layer_factory.hpp:77] Creating layer conv1
I0521 14:01:28.008188  1271 net.cpp:106] Creating Layer conv1
I0521 14:01:28.008198  1271 net.cpp:454] conv1 <- data
I0521 14:01:28.008221  1271 net.cpp:411] conv1 -> conv1
I0521 14:01:28.375830  1271 net.cpp:150] Setting up conv1
I0521 14:01:28.375874  1271 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 14:01:28.375885  1271 net.cpp:165] Memory required for data: 3018840
I0521 14:01:28.375913  1271 layer_factory.hpp:77] Creating layer relu1
I0521 14:01:28.375936  1271 net.cpp:106] Creating Layer relu1
I0521 14:01:28.375946  1271 net.cpp:454] relu1 <- conv1
I0521 14:01:28.375959  1271 net.cpp:397] relu1 -> conv1 (in-place)
I0521 14:01:28.376490  1271 net.cpp:150] Setting up relu1
I0521 14:01:28.376507  1271 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 14:01:28.376518  1271 net.cpp:165] Memory required for data: 5783640
I0521 14:01:28.376529  1271 layer_factory.hpp:77] Creating layer pool1
I0521 14:01:28.376546  1271 net.cpp:106] Creating Layer pool1
I0521 14:01:28.376556  1271 net.cpp:454] pool1 <- conv1
I0521 14:01:28.376569  1271 net.cpp:411] pool1 -> pool1
I0521 14:01:28.376651  1271 net.cpp:150] Setting up pool1
I0521 14:01:28.376663  1271 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 14:01:28.376674  1271 net.cpp:165] Memory required for data: 7166040
I0521 14:01:28.376684  1271 layer_factory.hpp:77] Creating layer conv2
I0521 14:01:28.376708  1271 net.cpp:106] Creating Layer conv2
I0521 14:01:28.376718  1271 net.cpp:454] conv2 <- pool1
I0521 14:01:28.376730  1271 net.cpp:411] conv2 -> conv2
I0521 14:01:28.379427  1271 net.cpp:150] Setting up conv2
I0521 14:01:28.379454  1271 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 14:01:28.379465  1271 net.cpp:165] Memory required for data: 9153240
I0521 14:01:28.379484  1271 layer_factory.hpp:77] Creating layer relu2
I0521 14:01:28.379498  1271 net.cpp:106] Creating Layer relu2
I0521 14:01:28.379508  1271 net.cpp:454] relu2 <- conv2
I0521 14:01:28.379520  1271 net.cpp:397] relu2 -> conv2 (in-place)
I0521 14:01:28.379853  1271 net.cpp:150] Setting up relu2
I0521 14:01:28.379868  1271 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 14:01:28.379878  1271 net.cpp:165] Memory required for data: 11140440
I0521 14:01:28.379887  1271 layer_factory.hpp:77] Creating layer pool2
I0521 14:01:28.379899  1271 net.cpp:106] Creating Layer pool2
I0521 14:01:28.379909  1271 net.cpp:454] pool2 <- conv2
I0521 14:01:28.379921  1271 net.cpp:411] pool2 -> pool2
I0521 14:01:28.380002  1271 net.cpp:150] Setting up pool2
I0521 14:01:28.380015  1271 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 14:01:28.380024  1271 net.cpp:165] Memory required for data: 12134040
I0521 14:01:28.380033  1271 layer_factory.hpp:77] Creating layer conv3
I0521 14:01:28.380051  1271 net.cpp:106] Creating Layer conv3
I0521 14:01:28.380071  1271 net.cpp:454] conv3 <- pool2
I0521 14:01:28.380086  1271 net.cpp:411] conv3 -> conv3
I0521 14:01:28.382184  1271 net.cpp:150] Setting up conv3
I0521 14:01:28.382202  1271 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 14:01:28.382213  1271 net.cpp:165] Memory required for data: 13218200
I0521 14:01:28.382231  1271 layer_factory.hpp:77] Creating layer relu3
I0521 14:01:28.382247  1271 net.cpp:106] Creating Layer relu3
I0521 14:01:28.382257  1271 net.cpp:454] relu3 <- conv3
I0521 14:01:28.382271  1271 net.cpp:397] relu3 -> conv3 (in-place)
I0521 14:01:28.382735  1271 net.cpp:150] Setting up relu3
I0521 14:01:28.382753  1271 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 14:01:28.382764  1271 net.cpp:165] Memory required for data: 14302360
I0521 14:01:28.382774  1271 layer_factory.hpp:77] Creating layer pool3
I0521 14:01:28.382788  1271 net.cpp:106] Creating Layer pool3
I0521 14:01:28.382797  1271 net.cpp:454] pool3 <- conv3
I0521 14:01:28.382810  1271 net.cpp:411] pool3 -> pool3
I0521 14:01:28.382877  1271 net.cpp:150] Setting up pool3
I0521 14:01:28.382891  1271 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 14:01:28.382900  1271 net.cpp:165] Memory required for data: 14844440
I0521 14:01:28.382908  1271 layer_factory.hpp:77] Creating layer conv4
I0521 14:01:28.382925  1271 net.cpp:106] Creating Layer conv4
I0521 14:01:28.382936  1271 net.cpp:454] conv4 <- pool3
I0521 14:01:28.382949  1271 net.cpp:411] conv4 -> conv4
I0521 14:01:28.385679  1271 net.cpp:150] Setting up conv4
I0521 14:01:28.385705  1271 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 14:01:28.385716  1271 net.cpp:165] Memory required for data: 15207320
I0521 14:01:28.385733  1271 layer_factory.hpp:77] Creating layer relu4
I0521 14:01:28.385747  1271 net.cpp:106] Creating Layer relu4
I0521 14:01:28.385758  1271 net.cpp:454] relu4 <- conv4
I0521 14:01:28.385771  1271 net.cpp:397] relu4 -> conv4 (in-place)
I0521 14:01:28.386235  1271 net.cpp:150] Setting up relu4
I0521 14:01:28.386251  1271 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 14:01:28.386262  1271 net.cpp:165] Memory required for data: 15570200
I0521 14:01:28.386272  1271 layer_factory.hpp:77] Creating layer pool4
I0521 14:01:28.386286  1271 net.cpp:106] Creating Layer pool4
I0521 14:01:28.386296  1271 net.cpp:454] pool4 <- conv4
I0521 14:01:28.386308  1271 net.cpp:411] pool4 -> pool4
I0521 14:01:28.386375  1271 net.cpp:150] Setting up pool4
I0521 14:01:28.386389  1271 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 14:01:28.386399  1271 net.cpp:165] Memory required for data: 15751640
I0521 14:01:28.386409  1271 layer_factory.hpp:77] Creating layer ip1
I0521 14:01:28.386428  1271 net.cpp:106] Creating Layer ip1
I0521 14:01:28.386440  1271 net.cpp:454] ip1 <- pool4
I0521 14:01:28.386452  1271 net.cpp:411] ip1 -> ip1
I0521 14:01:28.401859  1271 net.cpp:150] Setting up ip1
I0521 14:01:28.401882  1271 net.cpp:157] Top shape: 10 196 (1960)
I0521 14:01:28.401895  1271 net.cpp:165] Memory required for data: 15759480
I0521 14:01:28.401921  1271 layer_factory.hpp:77] Creating layer relu5
I0521 14:01:28.401935  1271 net.cpp:106] Creating Layer relu5
I0521 14:01:28.401947  1271 net.cpp:454] relu5 <- ip1
I0521 14:01:28.401959  1271 net.cpp:397] relu5 -> ip1 (in-place)
I0521 14:01:28.402302  1271 net.cpp:150] Setting up relu5
I0521 14:01:28.402317  1271 net.cpp:157] Top shape: 10 196 (1960)
I0521 14:01:28.402326  1271 net.cpp:165] Memory required for data: 15767320
I0521 14:01:28.402338  1271 layer_factory.hpp:77] Creating layer drop1
I0521 14:01:28.402357  1271 net.cpp:106] Creating Layer drop1
I0521 14:01:28.402367  1271 net.cpp:454] drop1 <- ip1
I0521 14:01:28.402380  1271 net.cpp:397] drop1 -> ip1 (in-place)
I0521 14:01:28.402439  1271 net.cpp:150] Setting up drop1
I0521 14:01:28.402453  1271 net.cpp:157] Top shape: 10 196 (1960)
I0521 14:01:28.402462  1271 net.cpp:165] Memory required for data: 15775160
I0521 14:01:28.402472  1271 layer_factory.hpp:77] Creating layer ip2
I0521 14:01:28.402490  1271 net.cpp:106] Creating Layer ip2
I0521 14:01:28.402501  1271 net.cpp:454] ip2 <- ip1
I0521 14:01:28.402514  1271 net.cpp:411] ip2 -> ip2
I0521 14:01:28.402977  1271 net.cpp:150] Setting up ip2
I0521 14:01:28.402990  1271 net.cpp:157] Top shape: 10 98 (980)
I0521 14:01:28.403000  1271 net.cpp:165] Memory required for data: 15779080
I0521 14:01:28.403015  1271 layer_factory.hpp:77] Creating layer relu6
I0521 14:01:28.403028  1271 net.cpp:106] Creating Layer relu6
I0521 14:01:28.403038  1271 net.cpp:454] relu6 <- ip2
I0521 14:01:28.403049  1271 net.cpp:397] relu6 -> ip2 (in-place)
I0521 14:01:28.403569  1271 net.cpp:150] Setting up relu6
I0521 14:01:28.403585  1271 net.cpp:157] Top shape: 10 98 (980)
I0521 14:01:28.403595  1271 net.cpp:165] Memory required for data: 15783000
I0521 14:01:28.403606  1271 layer_factory.hpp:77] Creating layer drop2
I0521 14:01:28.403620  1271 net.cpp:106] Creating Layer drop2
I0521 14:01:28.403630  1271 net.cpp:454] drop2 <- ip2
I0521 14:01:28.403641  1271 net.cpp:397] drop2 -> ip2 (in-place)
I0521 14:01:28.403684  1271 net.cpp:150] Setting up drop2
I0521 14:01:28.403697  1271 net.cpp:157] Top shape: 10 98 (980)
I0521 14:01:28.403707  1271 net.cpp:165] Memory required for data: 15786920
I0521 14:01:28.403717  1271 layer_factory.hpp:77] Creating layer ip3
I0521 14:01:28.403731  1271 net.cpp:106] Creating Layer ip3
I0521 14:01:28.403740  1271 net.cpp:454] ip3 <- ip2
I0521 14:01:28.403753  1271 net.cpp:411] ip3 -> ip3
I0521 14:01:28.403960  1271 net.cpp:150] Setting up ip3
I0521 14:01:28.403973  1271 net.cpp:157] Top shape: 10 11 (110)
I0521 14:01:28.403983  1271 net.cpp:165] Memory required for data: 15787360
I0521 14:01:28.403998  1271 layer_factory.hpp:77] Creating layer drop3
I0521 14:01:28.404011  1271 net.cpp:106] Creating Layer drop3
I0521 14:01:28.404021  1271 net.cpp:454] drop3 <- ip3
I0521 14:01:28.404033  1271 net.cpp:397] drop3 -> ip3 (in-place)
I0521 14:01:28.404080  1271 net.cpp:150] Setting up drop3
I0521 14:01:28.404094  1271 net.cpp:157] Top shape: 10 11 (110)
I0521 14:01:28.404104  1271 net.cpp:165] Memory required for data: 15787800
I0521 14:01:28.404114  1271 layer_factory.hpp:77] Creating layer loss
I0521 14:01:28.404134  1271 net.cpp:106] Creating Layer loss
I0521 14:01:28.404144  1271 net.cpp:454] loss <- ip3
I0521 14:01:28.404155  1271 net.cpp:454] loss <- label
I0521 14:01:28.404168  1271 net.cpp:411] loss -> loss
I0521 14:01:28.404186  1271 layer_factory.hpp:77] Creating layer loss
I0521 14:01:28.404825  1271 net.cpp:150] Setting up loss
I0521 14:01:28.404847  1271 net.cpp:157] Top shape: (1)
I0521 14:01:28.404860  1271 net.cpp:160]     with loss weight 1
I0521 14:01:28.404901  1271 net.cpp:165] Memory required for data: 15787804
I0521 14:01:28.404912  1271 net.cpp:226] loss needs backward computation.
I0521 14:01:28.404923  1271 net.cpp:226] drop3 needs backward computation.
I0521 14:01:28.404932  1271 net.cpp:226] ip3 needs backward computation.
I0521 14:01:28.404942  1271 net.cpp:226] drop2 needs backward computation.
I0521 14:01:28.404952  1271 net.cpp:226] relu6 needs backward computation.
I0521 14:01:28.404961  1271 net.cpp:226] ip2 needs backward computation.
I0521 14:01:28.404971  1271 net.cpp:226] drop1 needs backward computation.
I0521 14:01:28.404981  1271 net.cpp:226] relu5 needs backward computation.
I0521 14:01:28.404991  1271 net.cpp:226] ip1 needs backward computation.
I0521 14:01:28.405001  1271 net.cpp:226] pool4 needs backward computation.
I0521 14:01:28.405011  1271 net.cpp:226] relu4 needs backward computation.
I0521 14:01:28.405021  1271 net.cpp:226] conv4 needs backward computation.
I0521 14:01:28.405032  1271 net.cpp:226] pool3 needs backward computation.
I0521 14:01:28.405042  1271 net.cpp:226] relu3 needs backward computation.
I0521 14:01:28.405052  1271 net.cpp:226] conv3 needs backward computation.
I0521 14:01:28.405072  1271 net.cpp:226] pool2 needs backward computation.
I0521 14:01:28.405083  1271 net.cpp:226] relu2 needs backward computation.
I0521 14:01:28.405094  1271 net.cpp:226] conv2 needs backward computation.
I0521 14:01:28.405105  1271 net.cpp:226] pool1 needs backward computation.
I0521 14:01:28.405117  1271 net.cpp:226] relu1 needs backward computation.
I0521 14:01:28.405127  1271 net.cpp:226] conv1 needs backward computation.
I0521 14:01:28.405138  1271 net.cpp:228] data_hdf5 does not need backward computation.
I0521 14:01:28.405148  1271 net.cpp:270] This network produces output loss
I0521 14:01:28.405170  1271 net.cpp:283] Network initialization done.
I0521 14:01:28.406826  1271 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054.prototxt
I0521 14:01:28.406898  1271 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 14:01:28.407249  1271 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 14:01:28.407439  1271 layer_factory.hpp:77] Creating layer data_hdf5
I0521 14:01:28.407455  1271 net.cpp:106] Creating Layer data_hdf5
I0521 14:01:28.407469  1271 net.cpp:411] data_hdf5 -> data
I0521 14:01:28.407485  1271 net.cpp:411] data_hdf5 -> label
I0521 14:01:28.407501  1271 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 14:01:28.408886  1271 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 14:01:49.710680  1271 net.cpp:150] Setting up data_hdf5
I0521 14:01:49.710846  1271 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 14:01:49.710860  1271 net.cpp:157] Top shape: 10 (10)
I0521 14:01:49.710871  1271 net.cpp:165] Memory required for data: 254040
I0521 14:01:49.710886  1271 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 14:01:49.710914  1271 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 14:01:49.710925  1271 net.cpp:454] label_data_hdf5_1_split <- label
I0521 14:01:49.710942  1271 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 14:01:49.710963  1271 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 14:01:49.711035  1271 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 14:01:49.711048  1271 net.cpp:157] Top shape: 10 (10)
I0521 14:01:49.711061  1271 net.cpp:157] Top shape: 10 (10)
I0521 14:01:49.711071  1271 net.cpp:165] Memory required for data: 254120
I0521 14:01:49.711081  1271 layer_factory.hpp:77] Creating layer conv1
I0521 14:01:49.711103  1271 net.cpp:106] Creating Layer conv1
I0521 14:01:49.711113  1271 net.cpp:454] conv1 <- data
I0521 14:01:49.711128  1271 net.cpp:411] conv1 -> conv1
I0521 14:01:49.713079  1271 net.cpp:150] Setting up conv1
I0521 14:01:49.713104  1271 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 14:01:49.713116  1271 net.cpp:165] Memory required for data: 3018920
I0521 14:01:49.713136  1271 layer_factory.hpp:77] Creating layer relu1
I0521 14:01:49.713151  1271 net.cpp:106] Creating Layer relu1
I0521 14:01:49.713161  1271 net.cpp:454] relu1 <- conv1
I0521 14:01:49.713174  1271 net.cpp:397] relu1 -> conv1 (in-place)
I0521 14:01:49.713681  1271 net.cpp:150] Setting up relu1
I0521 14:01:49.713698  1271 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 14:01:49.713709  1271 net.cpp:165] Memory required for data: 5783720
I0521 14:01:49.713719  1271 layer_factory.hpp:77] Creating layer pool1
I0521 14:01:49.713735  1271 net.cpp:106] Creating Layer pool1
I0521 14:01:49.713745  1271 net.cpp:454] pool1 <- conv1
I0521 14:01:49.713758  1271 net.cpp:411] pool1 -> pool1
I0521 14:01:49.713832  1271 net.cpp:150] Setting up pool1
I0521 14:01:49.713846  1271 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 14:01:49.713855  1271 net.cpp:165] Memory required for data: 7166120
I0521 14:01:49.713866  1271 layer_factory.hpp:77] Creating layer conv2
I0521 14:01:49.713883  1271 net.cpp:106] Creating Layer conv2
I0521 14:01:49.713894  1271 net.cpp:454] conv2 <- pool1
I0521 14:01:49.713908  1271 net.cpp:411] conv2 -> conv2
I0521 14:01:49.715819  1271 net.cpp:150] Setting up conv2
I0521 14:01:49.715842  1271 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 14:01:49.715854  1271 net.cpp:165] Memory required for data: 9153320
I0521 14:01:49.715873  1271 layer_factory.hpp:77] Creating layer relu2
I0521 14:01:49.715885  1271 net.cpp:106] Creating Layer relu2
I0521 14:01:49.715895  1271 net.cpp:454] relu2 <- conv2
I0521 14:01:49.715909  1271 net.cpp:397] relu2 -> conv2 (in-place)
I0521 14:01:49.716254  1271 net.cpp:150] Setting up relu2
I0521 14:01:49.716269  1271 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 14:01:49.716279  1271 net.cpp:165] Memory required for data: 11140520
I0521 14:01:49.716289  1271 layer_factory.hpp:77] Creating layer pool2
I0521 14:01:49.716303  1271 net.cpp:106] Creating Layer pool2
I0521 14:01:49.716313  1271 net.cpp:454] pool2 <- conv2
I0521 14:01:49.716325  1271 net.cpp:411] pool2 -> pool2
I0521 14:01:49.716398  1271 net.cpp:150] Setting up pool2
I0521 14:01:49.716411  1271 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 14:01:49.716421  1271 net.cpp:165] Memory required for data: 12134120
I0521 14:01:49.716431  1271 layer_factory.hpp:77] Creating layer conv3
I0521 14:01:49.716450  1271 net.cpp:106] Creating Layer conv3
I0521 14:01:49.716461  1271 net.cpp:454] conv3 <- pool2
I0521 14:01:49.716475  1271 net.cpp:411] conv3 -> conv3
I0521 14:01:49.718473  1271 net.cpp:150] Setting up conv3
I0521 14:01:49.718497  1271 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 14:01:49.718509  1271 net.cpp:165] Memory required for data: 13218280
I0521 14:01:49.718528  1271 layer_factory.hpp:77] Creating layer relu3
I0521 14:01:49.718554  1271 net.cpp:106] Creating Layer relu3
I0521 14:01:49.718564  1271 net.cpp:454] relu3 <- conv3
I0521 14:01:49.718577  1271 net.cpp:397] relu3 -> conv3 (in-place)
I0521 14:01:49.719050  1271 net.cpp:150] Setting up relu3
I0521 14:01:49.719066  1271 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 14:01:49.719076  1271 net.cpp:165] Memory required for data: 14302440
I0521 14:01:49.719086  1271 layer_factory.hpp:77] Creating layer pool3
I0521 14:01:49.719099  1271 net.cpp:106] Creating Layer pool3
I0521 14:01:49.719110  1271 net.cpp:454] pool3 <- conv3
I0521 14:01:49.719122  1271 net.cpp:411] pool3 -> pool3
I0521 14:01:49.719193  1271 net.cpp:150] Setting up pool3
I0521 14:01:49.719207  1271 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 14:01:49.719216  1271 net.cpp:165] Memory required for data: 14844520
I0521 14:01:49.719226  1271 layer_factory.hpp:77] Creating layer conv4
I0521 14:01:49.719244  1271 net.cpp:106] Creating Layer conv4
I0521 14:01:49.719254  1271 net.cpp:454] conv4 <- pool3
I0521 14:01:49.719269  1271 net.cpp:411] conv4 -> conv4
I0521 14:01:49.721341  1271 net.cpp:150] Setting up conv4
I0521 14:01:49.721364  1271 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 14:01:49.721376  1271 net.cpp:165] Memory required for data: 15207400
I0521 14:01:49.721391  1271 layer_factory.hpp:77] Creating layer relu4
I0521 14:01:49.721405  1271 net.cpp:106] Creating Layer relu4
I0521 14:01:49.721415  1271 net.cpp:454] relu4 <- conv4
I0521 14:01:49.721428  1271 net.cpp:397] relu4 -> conv4 (in-place)
I0521 14:01:49.721895  1271 net.cpp:150] Setting up relu4
I0521 14:01:49.721911  1271 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 14:01:49.721921  1271 net.cpp:165] Memory required for data: 15570280
I0521 14:01:49.721931  1271 layer_factory.hpp:77] Creating layer pool4
I0521 14:01:49.721942  1271 net.cpp:106] Creating Layer pool4
I0521 14:01:49.721952  1271 net.cpp:454] pool4 <- conv4
I0521 14:01:49.721966  1271 net.cpp:411] pool4 -> pool4
I0521 14:01:49.722038  1271 net.cpp:150] Setting up pool4
I0521 14:01:49.722051  1271 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 14:01:49.722061  1271 net.cpp:165] Memory required for data: 15751720
I0521 14:01:49.722069  1271 layer_factory.hpp:77] Creating layer ip1
I0521 14:01:49.722085  1271 net.cpp:106] Creating Layer ip1
I0521 14:01:49.722096  1271 net.cpp:454] ip1 <- pool4
I0521 14:01:49.722110  1271 net.cpp:411] ip1 -> ip1
I0521 14:01:49.737576  1271 net.cpp:150] Setting up ip1
I0521 14:01:49.737606  1271 net.cpp:157] Top shape: 10 196 (1960)
I0521 14:01:49.737617  1271 net.cpp:165] Memory required for data: 15759560
I0521 14:01:49.737639  1271 layer_factory.hpp:77] Creating layer relu5
I0521 14:01:49.737654  1271 net.cpp:106] Creating Layer relu5
I0521 14:01:49.737664  1271 net.cpp:454] relu5 <- ip1
I0521 14:01:49.737679  1271 net.cpp:397] relu5 -> ip1 (in-place)
I0521 14:01:49.738026  1271 net.cpp:150] Setting up relu5
I0521 14:01:49.738039  1271 net.cpp:157] Top shape: 10 196 (1960)
I0521 14:01:49.738049  1271 net.cpp:165] Memory required for data: 15767400
I0521 14:01:49.738060  1271 layer_factory.hpp:77] Creating layer drop1
I0521 14:01:49.738078  1271 net.cpp:106] Creating Layer drop1
I0521 14:01:49.738088  1271 net.cpp:454] drop1 <- ip1
I0521 14:01:49.738101  1271 net.cpp:397] drop1 -> ip1 (in-place)
I0521 14:01:49.738147  1271 net.cpp:150] Setting up drop1
I0521 14:01:49.738158  1271 net.cpp:157] Top shape: 10 196 (1960)
I0521 14:01:49.738168  1271 net.cpp:165] Memory required for data: 15775240
I0521 14:01:49.738178  1271 layer_factory.hpp:77] Creating layer ip2
I0521 14:01:49.738193  1271 net.cpp:106] Creating Layer ip2
I0521 14:01:49.738203  1271 net.cpp:454] ip2 <- ip1
I0521 14:01:49.738216  1271 net.cpp:411] ip2 -> ip2
I0521 14:01:49.738695  1271 net.cpp:150] Setting up ip2
I0521 14:01:49.738709  1271 net.cpp:157] Top shape: 10 98 (980)
I0521 14:01:49.738718  1271 net.cpp:165] Memory required for data: 15779160
I0521 14:01:49.738734  1271 layer_factory.hpp:77] Creating layer relu6
I0521 14:01:49.738759  1271 net.cpp:106] Creating Layer relu6
I0521 14:01:49.738770  1271 net.cpp:454] relu6 <- ip2
I0521 14:01:49.738783  1271 net.cpp:397] relu6 -> ip2 (in-place)
I0521 14:01:49.739316  1271 net.cpp:150] Setting up relu6
I0521 14:01:49.739332  1271 net.cpp:157] Top shape: 10 98 (980)
I0521 14:01:49.739341  1271 net.cpp:165] Memory required for data: 15783080
I0521 14:01:49.739351  1271 layer_factory.hpp:77] Creating layer drop2
I0521 14:01:49.739365  1271 net.cpp:106] Creating Layer drop2
I0521 14:01:49.739375  1271 net.cpp:454] drop2 <- ip2
I0521 14:01:49.739388  1271 net.cpp:397] drop2 -> ip2 (in-place)
I0521 14:01:49.739434  1271 net.cpp:150] Setting up drop2
I0521 14:01:49.739446  1271 net.cpp:157] Top shape: 10 98 (980)
I0521 14:01:49.739455  1271 net.cpp:165] Memory required for data: 15787000
I0521 14:01:49.739465  1271 layer_factory.hpp:77] Creating layer ip3
I0521 14:01:49.739480  1271 net.cpp:106] Creating Layer ip3
I0521 14:01:49.739490  1271 net.cpp:454] ip3 <- ip2
I0521 14:01:49.739503  1271 net.cpp:411] ip3 -> ip3
I0521 14:01:49.739725  1271 net.cpp:150] Setting up ip3
I0521 14:01:49.739738  1271 net.cpp:157] Top shape: 10 11 (110)
I0521 14:01:49.739748  1271 net.cpp:165] Memory required for data: 15787440
I0521 14:01:49.739764  1271 layer_factory.hpp:77] Creating layer drop3
I0521 14:01:49.739778  1271 net.cpp:106] Creating Layer drop3
I0521 14:01:49.739787  1271 net.cpp:454] drop3 <- ip3
I0521 14:01:49.739800  1271 net.cpp:397] drop3 -> ip3 (in-place)
I0521 14:01:49.739841  1271 net.cpp:150] Setting up drop3
I0521 14:01:49.739855  1271 net.cpp:157] Top shape: 10 11 (110)
I0521 14:01:49.739864  1271 net.cpp:165] Memory required for data: 15787880
I0521 14:01:49.739874  1271 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 14:01:49.739887  1271 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 14:01:49.739897  1271 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 14:01:49.739910  1271 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 14:01:49.739925  1271 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 14:01:49.740000  1271 net.cpp:150] Setting up ip3_drop3_0_split
I0521 14:01:49.740012  1271 net.cpp:157] Top shape: 10 11 (110)
I0521 14:01:49.740025  1271 net.cpp:157] Top shape: 10 11 (110)
I0521 14:01:49.740036  1271 net.cpp:165] Memory required for data: 15788760
I0521 14:01:49.740046  1271 layer_factory.hpp:77] Creating layer accuracy
I0521 14:01:49.740073  1271 net.cpp:106] Creating Layer accuracy
I0521 14:01:49.740084  1271 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 14:01:49.740095  1271 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 14:01:49.740109  1271 net.cpp:411] accuracy -> accuracy
I0521 14:01:49.740134  1271 net.cpp:150] Setting up accuracy
I0521 14:01:49.740146  1271 net.cpp:157] Top shape: (1)
I0521 14:01:49.740156  1271 net.cpp:165] Memory required for data: 15788764
I0521 14:01:49.740165  1271 layer_factory.hpp:77] Creating layer loss
I0521 14:01:49.740180  1271 net.cpp:106] Creating Layer loss
I0521 14:01:49.740190  1271 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 14:01:49.740200  1271 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 14:01:49.740213  1271 net.cpp:411] loss -> loss
I0521 14:01:49.740231  1271 layer_factory.hpp:77] Creating layer loss
I0521 14:01:49.740717  1271 net.cpp:150] Setting up loss
I0521 14:01:49.740731  1271 net.cpp:157] Top shape: (1)
I0521 14:01:49.740741  1271 net.cpp:160]     with loss weight 1
I0521 14:01:49.740759  1271 net.cpp:165] Memory required for data: 15788768
I0521 14:01:49.740769  1271 net.cpp:226] loss needs backward computation.
I0521 14:01:49.740780  1271 net.cpp:228] accuracy does not need backward computation.
I0521 14:01:49.740792  1271 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 14:01:49.740803  1271 net.cpp:226] drop3 needs backward computation.
I0521 14:01:49.740813  1271 net.cpp:226] ip3 needs backward computation.
I0521 14:01:49.740823  1271 net.cpp:226] drop2 needs backward computation.
I0521 14:01:49.740833  1271 net.cpp:226] relu6 needs backward computation.
I0521 14:01:49.740851  1271 net.cpp:226] ip2 needs backward computation.
I0521 14:01:49.740862  1271 net.cpp:226] drop1 needs backward computation.
I0521 14:01:49.740872  1271 net.cpp:226] relu5 needs backward computation.
I0521 14:01:49.740882  1271 net.cpp:226] ip1 needs backward computation.
I0521 14:01:49.740892  1271 net.cpp:226] pool4 needs backward computation.
I0521 14:01:49.740902  1271 net.cpp:226] relu4 needs backward computation.
I0521 14:01:49.740912  1271 net.cpp:226] conv4 needs backward computation.
I0521 14:01:49.740921  1271 net.cpp:226] pool3 needs backward computation.
I0521 14:01:49.740931  1271 net.cpp:226] relu3 needs backward computation.
I0521 14:01:49.740942  1271 net.cpp:226] conv3 needs backward computation.
I0521 14:01:49.740953  1271 net.cpp:226] pool2 needs backward computation.
I0521 14:01:49.740963  1271 net.cpp:226] relu2 needs backward computation.
I0521 14:01:49.740973  1271 net.cpp:226] conv2 needs backward computation.
I0521 14:01:49.740983  1271 net.cpp:226] pool1 needs backward computation.
I0521 14:01:49.740993  1271 net.cpp:226] relu1 needs backward computation.
I0521 14:01:49.741003  1271 net.cpp:226] conv1 needs backward computation.
I0521 14:01:49.741015  1271 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 14:01:49.741027  1271 net.cpp:228] data_hdf5 does not need backward computation.
I0521 14:01:49.741037  1271 net.cpp:270] This network produces output accuracy
I0521 14:01:49.741049  1271 net.cpp:270] This network produces output loss
I0521 14:01:49.741077  1271 net.cpp:283] Network initialization done.
I0521 14:01:49.741210  1271 solver.cpp:60] Solver scaffolding done.
I0521 14:01:49.742352  1271 caffe.cpp:212] Starting Optimization
I0521 14:01:49.742365  1271 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 14:01:49.742378  1271 solver.cpp:289] Learning Rate Policy: fixed
I0521 14:01:49.743443  1271 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 14:02:50.204960  1271 solver.cpp:409]     Test net output #0: accuracy = 0.0947471
I0521 14:02:50.205122  1271 solver.cpp:409]     Test net output #1: loss = 2.39765 (* 1 = 2.39765 loss)
I0521 14:02:50.222851  1271 solver.cpp:237] Iteration 0, loss = 2.40248
I0521 14:02:50.222888  1271 solver.cpp:253]     Train net output #0: loss = 2.40248 (* 1 = 2.40248 loss)
I0521 14:02:50.222906  1271 sgd_solver.cpp:106] Iteration 0, lr = 0.002
I0521 14:03:07.001271  1271 solver.cpp:237] Iteration 1500, loss = 2.18637
I0521 14:03:07.001309  1271 solver.cpp:253]     Train net output #0: loss = 2.18637 (* 1 = 2.18637 loss)
I0521 14:03:07.001325  1271 sgd_solver.cpp:106] Iteration 1500, lr = 0.002
I0521 14:03:23.788749  1271 solver.cpp:237] Iteration 3000, loss = 2.20712
I0521 14:03:23.788911  1271 solver.cpp:253]     Train net output #0: loss = 2.20712 (* 1 = 2.20712 loss)
I0521 14:03:23.788925  1271 sgd_solver.cpp:106] Iteration 3000, lr = 0.002
I0521 14:03:40.579036  1271 solver.cpp:237] Iteration 4500, loss = 2.12204
I0521 14:03:40.579084  1271 solver.cpp:253]     Train net output #0: loss = 2.12204 (* 1 = 2.12204 loss)
I0521 14:03:40.579100  1271 sgd_solver.cpp:106] Iteration 4500, lr = 0.002
I0521 14:03:57.377925  1271 solver.cpp:237] Iteration 6000, loss = 1.52732
I0521 14:03:57.378064  1271 solver.cpp:253]     Train net output #0: loss = 1.52732 (* 1 = 1.52732 loss)
I0521 14:03:57.378078  1271 sgd_solver.cpp:106] Iteration 6000, lr = 0.002
I0521 14:04:14.158365  1271 solver.cpp:237] Iteration 7500, loss = 1.62158
I0521 14:04:14.158412  1271 solver.cpp:253]     Train net output #0: loss = 1.62158 (* 1 = 1.62158 loss)
I0521 14:04:14.158427  1271 sgd_solver.cpp:106] Iteration 7500, lr = 0.002
I0521 14:04:30.921146  1271 solver.cpp:237] Iteration 9000, loss = 1.23227
I0521 14:04:30.921295  1271 solver.cpp:253]     Train net output #0: loss = 1.23227 (* 1 = 1.23227 loss)
I0521 14:04:30.921309  1271 sgd_solver.cpp:106] Iteration 9000, lr = 0.002
I0521 14:05:09.844584  1271 solver.cpp:237] Iteration 10500, loss = 0.783691
I0521 14:05:09.844746  1271 solver.cpp:253]     Train net output #0: loss = 0.783691 (* 1 = 0.783691 loss)
I0521 14:05:09.844761  1271 sgd_solver.cpp:106] Iteration 10500, lr = 0.002
I0521 14:05:26.632957  1271 solver.cpp:237] Iteration 12000, loss = 1.03376
I0521 14:05:26.633007  1271 solver.cpp:253]     Train net output #0: loss = 1.03376 (* 1 = 1.03376 loss)
I0521 14:05:26.633020  1271 sgd_solver.cpp:106] Iteration 12000, lr = 0.002
I0521 14:05:43.426666  1271 solver.cpp:237] Iteration 13500, loss = 1.36652
I0521 14:05:43.426820  1271 solver.cpp:253]     Train net output #0: loss = 1.36652 (* 1 = 1.36652 loss)
I0521 14:05:43.426834  1271 sgd_solver.cpp:106] Iteration 13500, lr = 0.002
I0521 14:06:00.178192  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_15000.caffemodel
I0521 14:06:00.227790  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_15000.solverstate
I0521 14:06:00.256260  1271 solver.cpp:237] Iteration 15000, loss = 1.32335
I0521 14:06:00.256304  1271 solver.cpp:253]     Train net output #0: loss = 1.32335 (* 1 = 1.32335 loss)
I0521 14:06:00.256319  1271 sgd_solver.cpp:106] Iteration 15000, lr = 0.002
I0521 14:06:17.029016  1271 solver.cpp:237] Iteration 16500, loss = 1.2765
I0521 14:06:17.029170  1271 solver.cpp:253]     Train net output #0: loss = 1.2765 (* 1 = 1.2765 loss)
I0521 14:06:17.029186  1271 sgd_solver.cpp:106] Iteration 16500, lr = 0.002
I0521 14:06:33.796735  1271 solver.cpp:237] Iteration 18000, loss = 0.954477
I0521 14:06:33.796778  1271 solver.cpp:253]     Train net output #0: loss = 0.954477 (* 1 = 0.954477 loss)
I0521 14:06:33.796798  1271 sgd_solver.cpp:106] Iteration 18000, lr = 0.002
I0521 14:06:50.576465  1271 solver.cpp:237] Iteration 19500, loss = 1.64909
I0521 14:06:50.576612  1271 solver.cpp:253]     Train net output #0: loss = 1.64909 (* 1 = 1.64909 loss)
I0521 14:06:50.576627  1271 sgd_solver.cpp:106] Iteration 19500, lr = 0.002
I0521 14:07:29.493926  1271 solver.cpp:237] Iteration 21000, loss = 1.28372
I0521 14:07:29.494084  1271 solver.cpp:253]     Train net output #0: loss = 1.28372 (* 1 = 1.28372 loss)
I0521 14:07:29.494099  1271 sgd_solver.cpp:106] Iteration 21000, lr = 0.002
I0521 14:07:46.252017  1271 solver.cpp:237] Iteration 22500, loss = 0.765218
I0521 14:07:46.252054  1271 solver.cpp:253]     Train net output #0: loss = 0.765218 (* 1 = 0.765218 loss)
I0521 14:07:46.252076  1271 sgd_solver.cpp:106] Iteration 22500, lr = 0.002
I0521 14:08:03.049309  1271 solver.cpp:237] Iteration 24000, loss = 1.53089
I0521 14:08:03.049468  1271 solver.cpp:253]     Train net output #0: loss = 1.53089 (* 1 = 1.53089 loss)
I0521 14:08:03.049482  1271 sgd_solver.cpp:106] Iteration 24000, lr = 0.002
I0521 14:08:19.795792  1271 solver.cpp:237] Iteration 25500, loss = 1.79815
I0521 14:08:19.795840  1271 solver.cpp:253]     Train net output #0: loss = 1.79815 (* 1 = 1.79815 loss)
I0521 14:08:19.795855  1271 sgd_solver.cpp:106] Iteration 25500, lr = 0.002
I0521 14:08:36.566645  1271 solver.cpp:237] Iteration 27000, loss = 1.05045
I0521 14:08:36.566787  1271 solver.cpp:253]     Train net output #0: loss = 1.05045 (* 1 = 1.05045 loss)
I0521 14:08:36.566799  1271 sgd_solver.cpp:106] Iteration 27000, lr = 0.002
I0521 14:08:53.338819  1271 solver.cpp:237] Iteration 28500, loss = 1.38647
I0521 14:08:53.338867  1271 solver.cpp:253]     Train net output #0: loss = 1.38647 (* 1 = 1.38647 loss)
I0521 14:08:53.338881  1271 sgd_solver.cpp:106] Iteration 28500, lr = 0.002
I0521 14:09:10.088671  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_30000.caffemodel
I0521 14:09:10.135854  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_30000.solverstate
I0521 14:09:10.162015  1271 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 14:10:09.275885  1271 solver.cpp:409]     Test net output #0: accuracy = 0.849945
I0521 14:10:09.276042  1271 solver.cpp:409]     Test net output #1: loss = 0.515312 (* 1 = 0.515312 loss)
I0521 14:10:31.444880  1271 solver.cpp:237] Iteration 30000, loss = 1.41232
I0521 14:10:31.444932  1271 solver.cpp:253]     Train net output #0: loss = 1.41232 (* 1 = 1.41232 loss)
I0521 14:10:31.444949  1271 sgd_solver.cpp:106] Iteration 30000, lr = 0.002
I0521 14:10:48.375481  1271 solver.cpp:237] Iteration 31500, loss = 1.05537
I0521 14:10:48.375641  1271 solver.cpp:253]     Train net output #0: loss = 1.05537 (* 1 = 1.05537 loss)
I0521 14:10:48.375656  1271 sgd_solver.cpp:106] Iteration 31500, lr = 0.002
I0521 14:11:05.295718  1271 solver.cpp:237] Iteration 33000, loss = 1.20765
I0521 14:11:05.295755  1271 solver.cpp:253]     Train net output #0: loss = 1.20765 (* 1 = 1.20765 loss)
I0521 14:11:05.295771  1271 sgd_solver.cpp:106] Iteration 33000, lr = 0.002
I0521 14:11:22.210783  1271 solver.cpp:237] Iteration 34500, loss = 1.52483
I0521 14:11:22.210939  1271 solver.cpp:253]     Train net output #0: loss = 1.52482 (* 1 = 1.52482 loss)
I0521 14:11:22.210954  1271 sgd_solver.cpp:106] Iteration 34500, lr = 0.002
I0521 14:11:39.072865  1271 solver.cpp:237] Iteration 36000, loss = 0.847514
I0521 14:11:39.072916  1271 solver.cpp:253]     Train net output #0: loss = 0.847512 (* 1 = 0.847512 loss)
I0521 14:11:39.072931  1271 sgd_solver.cpp:106] Iteration 36000, lr = 0.002
I0521 14:11:55.920580  1271 solver.cpp:237] Iteration 37500, loss = 1.3136
I0521 14:11:55.920720  1271 solver.cpp:253]     Train net output #0: loss = 1.3136 (* 1 = 1.3136 loss)
I0521 14:11:55.920733  1271 sgd_solver.cpp:106] Iteration 37500, lr = 0.002
I0521 14:12:12.785305  1271 solver.cpp:237] Iteration 39000, loss = 1.00064
I0521 14:12:12.785352  1271 solver.cpp:253]     Train net output #0: loss = 1.00064 (* 1 = 1.00064 loss)
I0521 14:12:12.785367  1271 sgd_solver.cpp:106] Iteration 39000, lr = 0.002
I0521 14:12:51.892410  1271 solver.cpp:237] Iteration 40500, loss = 1.66063
I0521 14:12:51.892571  1271 solver.cpp:253]     Train net output #0: loss = 1.66063 (* 1 = 1.66063 loss)
I0521 14:12:51.892585  1271 sgd_solver.cpp:106] Iteration 40500, lr = 0.002
I0521 14:13:08.778306  1271 solver.cpp:237] Iteration 42000, loss = 1.09721
I0521 14:13:08.778343  1271 solver.cpp:253]     Train net output #0: loss = 1.09721 (* 1 = 1.09721 loss)
I0521 14:13:08.778357  1271 sgd_solver.cpp:106] Iteration 42000, lr = 0.002
I0521 14:13:25.706107  1271 solver.cpp:237] Iteration 43500, loss = 1.43688
I0521 14:13:25.706269  1271 solver.cpp:253]     Train net output #0: loss = 1.43688 (* 1 = 1.43688 loss)
I0521 14:13:25.706284  1271 sgd_solver.cpp:106] Iteration 43500, lr = 0.002
I0521 14:13:42.631546  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_45000.caffemodel
I0521 14:13:42.679147  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_45000.solverstate
I0521 14:13:42.711067  1271 solver.cpp:237] Iteration 45000, loss = 0.983845
I0521 14:13:42.711117  1271 solver.cpp:253]     Train net output #0: loss = 0.983843 (* 1 = 0.983843 loss)
I0521 14:13:42.711133  1271 sgd_solver.cpp:106] Iteration 45000, lr = 0.002
I0521 14:13:59.555678  1271 solver.cpp:237] Iteration 46500, loss = 1.10936
I0521 14:13:59.555827  1271 solver.cpp:253]     Train net output #0: loss = 1.10936 (* 1 = 1.10936 loss)
I0521 14:13:59.555840  1271 sgd_solver.cpp:106] Iteration 46500, lr = 0.002
I0521 14:14:16.441277  1271 solver.cpp:237] Iteration 48000, loss = 1.33176
I0521 14:14:16.441325  1271 solver.cpp:253]     Train net output #0: loss = 1.33176 (* 1 = 1.33176 loss)
I0521 14:14:16.441341  1271 sgd_solver.cpp:106] Iteration 48000, lr = 0.002
I0521 14:14:33.298530  1271 solver.cpp:237] Iteration 49500, loss = 1.36687
I0521 14:14:33.298686  1271 solver.cpp:253]     Train net output #0: loss = 1.36687 (* 1 = 1.36687 loss)
I0521 14:14:33.298701  1271 sgd_solver.cpp:106] Iteration 49500, lr = 0.002
I0521 14:15:12.275813  1271 solver.cpp:237] Iteration 51000, loss = 1.28171
I0521 14:15:12.275975  1271 solver.cpp:253]     Train net output #0: loss = 1.28171 (* 1 = 1.28171 loss)
I0521 14:15:12.275990  1271 sgd_solver.cpp:106] Iteration 51000, lr = 0.002
I0521 14:15:29.134451  1271 solver.cpp:237] Iteration 52500, loss = 1.16079
I0521 14:15:29.134498  1271 solver.cpp:253]     Train net output #0: loss = 1.16079 (* 1 = 1.16079 loss)
I0521 14:15:29.134513  1271 sgd_solver.cpp:106] Iteration 52500, lr = 0.002
I0521 14:15:45.934636  1271 solver.cpp:237] Iteration 54000, loss = 1.60989
I0521 14:15:45.934792  1271 solver.cpp:253]     Train net output #0: loss = 1.60989 (* 1 = 1.60989 loss)
I0521 14:15:45.934806  1271 sgd_solver.cpp:106] Iteration 54000, lr = 0.002
I0521 14:16:02.825546  1271 solver.cpp:237] Iteration 55500, loss = 1.02162
I0521 14:16:02.825582  1271 solver.cpp:253]     Train net output #0: loss = 1.02162 (* 1 = 1.02162 loss)
I0521 14:16:02.825598  1271 sgd_solver.cpp:106] Iteration 55500, lr = 0.002
I0521 14:16:19.756156  1271 solver.cpp:237] Iteration 57000, loss = 1.76511
I0521 14:16:19.756304  1271 solver.cpp:253]     Train net output #0: loss = 1.76511 (* 1 = 1.76511 loss)
I0521 14:16:19.756319  1271 sgd_solver.cpp:106] Iteration 57000, lr = 0.002
I0521 14:16:36.621873  1271 solver.cpp:237] Iteration 58500, loss = 1.29503
I0521 14:16:36.621918  1271 solver.cpp:253]     Train net output #0: loss = 1.29503 (* 1 = 1.29503 loss)
I0521 14:16:36.621935  1271 sgd_solver.cpp:106] Iteration 58500, lr = 0.002
I0521 14:16:53.456517  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_60000.caffemodel
I0521 14:16:53.505118  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_60000.solverstate
I0521 14:16:53.533638  1271 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 14:18:14.108464  1271 solver.cpp:409]     Test net output #0: accuracy = 0.869852
I0521 14:18:14.108625  1271 solver.cpp:409]     Test net output #1: loss = 0.441531 (* 1 = 0.441531 loss)
I0521 14:18:36.329721  1271 solver.cpp:237] Iteration 60000, loss = 0.883063
I0521 14:18:36.329777  1271 solver.cpp:253]     Train net output #0: loss = 0.883063 (* 1 = 0.883063 loss)
I0521 14:18:36.329792  1271 sgd_solver.cpp:106] Iteration 60000, lr = 0.002
I0521 14:18:53.517895  1271 solver.cpp:237] Iteration 61500, loss = 0.704296
I0521 14:18:53.518079  1271 solver.cpp:253]     Train net output #0: loss = 0.704297 (* 1 = 0.704297 loss)
I0521 14:18:53.518093  1271 sgd_solver.cpp:106] Iteration 61500, lr = 0.002
I0521 14:19:10.652211  1271 solver.cpp:237] Iteration 63000, loss = 1.57589
I0521 14:19:10.652254  1271 solver.cpp:253]     Train net output #0: loss = 1.57589 (* 1 = 1.57589 loss)
I0521 14:19:10.652271  1271 sgd_solver.cpp:106] Iteration 63000, lr = 0.002
I0521 14:19:27.828958  1271 solver.cpp:237] Iteration 64500, loss = 1.54694
I0521 14:19:27.829110  1271 solver.cpp:253]     Train net output #0: loss = 1.54695 (* 1 = 1.54695 loss)
I0521 14:19:27.829124  1271 sgd_solver.cpp:106] Iteration 64500, lr = 0.002
I0521 14:19:45.041735  1271 solver.cpp:237] Iteration 66000, loss = 1.08465
I0521 14:19:45.041785  1271 solver.cpp:253]     Train net output #0: loss = 1.08465 (* 1 = 1.08465 loss)
I0521 14:19:45.041800  1271 sgd_solver.cpp:106] Iteration 66000, lr = 0.002
I0521 14:20:02.227979  1271 solver.cpp:237] Iteration 67500, loss = 1.10057
I0521 14:20:02.228142  1271 solver.cpp:253]     Train net output #0: loss = 1.10058 (* 1 = 1.10058 loss)
I0521 14:20:02.228155  1271 sgd_solver.cpp:106] Iteration 67500, lr = 0.002
I0521 14:20:19.392102  1271 solver.cpp:237] Iteration 69000, loss = 1.07196
I0521 14:20:19.392143  1271 solver.cpp:253]     Train net output #0: loss = 1.07196 (* 1 = 1.07196 loss)
I0521 14:20:19.392160  1271 sgd_solver.cpp:106] Iteration 69000, lr = 0.002
I0521 14:20:58.850005  1271 solver.cpp:237] Iteration 70500, loss = 1.4722
I0521 14:20:58.850170  1271 solver.cpp:253]     Train net output #0: loss = 1.4722 (* 1 = 1.4722 loss)
I0521 14:20:58.850184  1271 sgd_solver.cpp:106] Iteration 70500, lr = 0.002
I0521 14:21:16.049926  1271 solver.cpp:237] Iteration 72000, loss = 0.59572
I0521 14:21:16.049973  1271 solver.cpp:253]     Train net output #0: loss = 0.595723 (* 1 = 0.595723 loss)
I0521 14:21:16.049988  1271 sgd_solver.cpp:106] Iteration 72000, lr = 0.002
I0521 14:21:33.178431  1271 solver.cpp:237] Iteration 73500, loss = 1.12051
I0521 14:21:33.178582  1271 solver.cpp:253]     Train net output #0: loss = 1.12051 (* 1 = 1.12051 loss)
I0521 14:21:33.178596  1271 sgd_solver.cpp:106] Iteration 73500, lr = 0.002
I0521 14:21:50.393836  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_75000.caffemodel
I0521 14:21:50.442581  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_75000.solverstate
I0521 14:21:50.474572  1271 solver.cpp:237] Iteration 75000, loss = 0.521288
I0521 14:21:50.474624  1271 solver.cpp:253]     Train net output #0: loss = 0.521292 (* 1 = 0.521292 loss)
I0521 14:21:50.474642  1271 sgd_solver.cpp:106] Iteration 75000, lr = 0.002
I0521 14:22:07.672253  1271 solver.cpp:237] Iteration 76500, loss = 2.04472
I0521 14:22:07.672407  1271 solver.cpp:253]     Train net output #0: loss = 2.04472 (* 1 = 2.04472 loss)
I0521 14:22:07.672422  1271 sgd_solver.cpp:106] Iteration 76500, lr = 0.002
I0521 14:22:24.827322  1271 solver.cpp:237] Iteration 78000, loss = 1.25205
I0521 14:22:24.827368  1271 solver.cpp:253]     Train net output #0: loss = 1.25205 (* 1 = 1.25205 loss)
I0521 14:22:24.827384  1271 sgd_solver.cpp:106] Iteration 78000, lr = 0.002
I0521 14:22:42.022922  1271 solver.cpp:237] Iteration 79500, loss = 1.69789
I0521 14:22:42.023062  1271 solver.cpp:253]     Train net output #0: loss = 1.6979 (* 1 = 1.6979 loss)
I0521 14:22:42.023077  1271 sgd_solver.cpp:106] Iteration 79500, lr = 0.002
I0521 14:23:21.444768  1271 solver.cpp:237] Iteration 81000, loss = 1.06441
I0521 14:23:21.444939  1271 solver.cpp:253]     Train net output #0: loss = 1.06441 (* 1 = 1.06441 loss)
I0521 14:23:21.444954  1271 sgd_solver.cpp:106] Iteration 81000, lr = 0.002
I0521 14:23:38.631345  1271 solver.cpp:237] Iteration 82500, loss = 1.43425
I0521 14:23:38.631392  1271 solver.cpp:253]     Train net output #0: loss = 1.43425 (* 1 = 1.43425 loss)
I0521 14:23:38.631412  1271 sgd_solver.cpp:106] Iteration 82500, lr = 0.002
I0521 14:23:55.831856  1271 solver.cpp:237] Iteration 84000, loss = 1.41701
I0521 14:23:55.832000  1271 solver.cpp:253]     Train net output #0: loss = 1.41701 (* 1 = 1.41701 loss)
I0521 14:23:55.832015  1271 sgd_solver.cpp:106] Iteration 84000, lr = 0.002
I0521 14:24:13.007668  1271 solver.cpp:237] Iteration 85500, loss = 1.27229
I0521 14:24:13.007714  1271 solver.cpp:253]     Train net output #0: loss = 1.2723 (* 1 = 1.2723 loss)
I0521 14:24:13.007727  1271 sgd_solver.cpp:106] Iteration 85500, lr = 0.002
I0521 14:24:30.109493  1271 solver.cpp:237] Iteration 87000, loss = 1.1777
I0521 14:24:30.109644  1271 solver.cpp:253]     Train net output #0: loss = 1.1777 (* 1 = 1.1777 loss)
I0521 14:24:30.109659  1271 sgd_solver.cpp:106] Iteration 87000, lr = 0.002
I0521 14:24:46.710932  1271 solver.cpp:237] Iteration 88500, loss = 1.14086
I0521 14:24:46.710968  1271 solver.cpp:253]     Train net output #0: loss = 1.14086 (* 1 = 1.14086 loss)
I0521 14:24:46.710985  1271 sgd_solver.cpp:106] Iteration 88500, lr = 0.002
I0521 14:25:03.314160  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_90000.caffemodel
I0521 14:25:03.360023  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_90000.solverstate
I0521 14:25:03.386303  1271 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 14:26:02.666136  1271 solver.cpp:409]     Test net output #0: accuracy = 0.876741
I0521 14:26:02.666296  1271 solver.cpp:409]     Test net output #1: loss = 0.396589 (* 1 = 0.396589 loss)
I0521 14:26:24.888479  1271 solver.cpp:237] Iteration 90000, loss = 1.15021
I0521 14:26:24.888532  1271 solver.cpp:253]     Train net output #0: loss = 1.15022 (* 1 = 1.15022 loss)
I0521 14:26:24.888547  1271 sgd_solver.cpp:106] Iteration 90000, lr = 0.002
I0521 14:26:41.537736  1271 solver.cpp:237] Iteration 91500, loss = 1.06318
I0521 14:26:41.537909  1271 solver.cpp:253]     Train net output #0: loss = 1.06318 (* 1 = 1.06318 loss)
I0521 14:26:41.537924  1271 sgd_solver.cpp:106] Iteration 91500, lr = 0.002
I0521 14:26:58.153332  1271 solver.cpp:237] Iteration 93000, loss = 0.934118
I0521 14:26:58.153369  1271 solver.cpp:253]     Train net output #0: loss = 0.934123 (* 1 = 0.934123 loss)
I0521 14:26:58.153384  1271 sgd_solver.cpp:106] Iteration 93000, lr = 0.002
I0521 14:27:14.809550  1271 solver.cpp:237] Iteration 94500, loss = 1.67973
I0521 14:27:14.809697  1271 solver.cpp:253]     Train net output #0: loss = 1.67973 (* 1 = 1.67973 loss)
I0521 14:27:14.809711  1271 sgd_solver.cpp:106] Iteration 94500, lr = 0.002
I0521 14:27:31.440712  1271 solver.cpp:237] Iteration 96000, loss = 1.32156
I0521 14:27:31.440759  1271 solver.cpp:253]     Train net output #0: loss = 1.32156 (* 1 = 1.32156 loss)
I0521 14:27:31.440775  1271 sgd_solver.cpp:106] Iteration 96000, lr = 0.002
I0521 14:27:48.094759  1271 solver.cpp:237] Iteration 97500, loss = 1.49882
I0521 14:27:48.094902  1271 solver.cpp:253]     Train net output #0: loss = 1.49882 (* 1 = 1.49882 loss)
I0521 14:27:48.094915  1271 sgd_solver.cpp:106] Iteration 97500, lr = 0.002
I0521 14:28:04.703830  1271 solver.cpp:237] Iteration 99000, loss = 0.591434
I0521 14:28:04.703876  1271 solver.cpp:253]     Train net output #0: loss = 0.59144 (* 1 = 0.59144 loss)
I0521 14:28:04.703891  1271 sgd_solver.cpp:106] Iteration 99000, lr = 0.002
I0521 14:28:43.455178  1271 solver.cpp:237] Iteration 100500, loss = 0.986994
I0521 14:28:43.455353  1271 solver.cpp:253]     Train net output #0: loss = 0.987001 (* 1 = 0.987001 loss)
I0521 14:28:43.455366  1271 sgd_solver.cpp:106] Iteration 100500, lr = 0.002
I0521 14:29:00.106511  1271 solver.cpp:237] Iteration 102000, loss = 0.692182
I0521 14:29:00.106549  1271 solver.cpp:253]     Train net output #0: loss = 0.692189 (* 1 = 0.692189 loss)
I0521 14:29:00.106564  1271 sgd_solver.cpp:106] Iteration 102000, lr = 0.002
I0521 14:29:16.751371  1271 solver.cpp:237] Iteration 103500, loss = 1.27539
I0521 14:29:16.751525  1271 solver.cpp:253]     Train net output #0: loss = 1.27539 (* 1 = 1.27539 loss)
I0521 14:29:16.751539  1271 sgd_solver.cpp:106] Iteration 103500, lr = 0.002
I0521 14:29:33.396630  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_105000.caffemodel
I0521 14:29:33.441663  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_105000.solverstate
I0521 14:29:33.470230  1271 solver.cpp:237] Iteration 105000, loss = 0.929248
I0521 14:29:33.470276  1271 solver.cpp:253]     Train net output #0: loss = 0.929257 (* 1 = 0.929257 loss)
I0521 14:29:33.470290  1271 sgd_solver.cpp:106] Iteration 105000, lr = 0.002
I0521 14:29:50.089467  1271 solver.cpp:237] Iteration 106500, loss = 1.19359
I0521 14:29:50.089614  1271 solver.cpp:253]     Train net output #0: loss = 1.1936 (* 1 = 1.1936 loss)
I0521 14:29:50.089628  1271 sgd_solver.cpp:106] Iteration 106500, lr = 0.002
I0521 14:30:06.739291  1271 solver.cpp:237] Iteration 108000, loss = 0.930493
I0521 14:30:06.739341  1271 solver.cpp:253]     Train net output #0: loss = 0.930502 (* 1 = 0.930502 loss)
I0521 14:30:06.739354  1271 sgd_solver.cpp:106] Iteration 108000, lr = 0.002
I0521 14:30:23.354784  1271 solver.cpp:237] Iteration 109500, loss = 0.639949
I0521 14:30:23.354944  1271 solver.cpp:253]     Train net output #0: loss = 0.639958 (* 1 = 0.639958 loss)
I0521 14:30:23.354959  1271 sgd_solver.cpp:106] Iteration 109500, lr = 0.002
I0521 14:31:02.146283  1271 solver.cpp:237] Iteration 111000, loss = 1.1133
I0521 14:31:02.146455  1271 solver.cpp:253]     Train net output #0: loss = 1.11331 (* 1 = 1.11331 loss)
I0521 14:31:02.146468  1271 sgd_solver.cpp:106] Iteration 111000, lr = 0.002
I0521 14:31:18.743458  1271 solver.cpp:237] Iteration 112500, loss = 2.55489
I0521 14:31:18.743508  1271 solver.cpp:253]     Train net output #0: loss = 2.5549 (* 1 = 2.5549 loss)
I0521 14:31:18.743522  1271 sgd_solver.cpp:106] Iteration 112500, lr = 0.002
I0521 14:31:35.350215  1271 solver.cpp:237] Iteration 114000, loss = 0.981499
I0521 14:31:35.350371  1271 solver.cpp:253]     Train net output #0: loss = 0.981507 (* 1 = 0.981507 loss)
I0521 14:31:35.350385  1271 sgd_solver.cpp:106] Iteration 114000, lr = 0.002
I0521 14:31:51.977238  1271 solver.cpp:237] Iteration 115500, loss = 1.31668
I0521 14:31:51.977274  1271 solver.cpp:253]     Train net output #0: loss = 1.31669 (* 1 = 1.31669 loss)
I0521 14:31:51.977290  1271 sgd_solver.cpp:106] Iteration 115500, lr = 0.002
I0521 14:32:08.595870  1271 solver.cpp:237] Iteration 117000, loss = 1.26524
I0521 14:32:08.596025  1271 solver.cpp:253]     Train net output #0: loss = 1.26525 (* 1 = 1.26525 loss)
I0521 14:32:08.596040  1271 sgd_solver.cpp:106] Iteration 117000, lr = 0.002
I0521 14:32:25.188485  1271 solver.cpp:237] Iteration 118500, loss = 0.92349
I0521 14:32:25.188524  1271 solver.cpp:253]     Train net output #0: loss = 0.923498 (* 1 = 0.923498 loss)
I0521 14:32:25.188545  1271 sgd_solver.cpp:106] Iteration 118500, lr = 0.002
I0521 14:32:41.822991  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_120000.caffemodel
I0521 14:32:41.869580  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_120000.solverstate
I0521 14:32:41.895150  1271 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 14:34:02.109699  1271 solver.cpp:409]     Test net output #0: accuracy = 0.87583
I0521 14:34:02.109872  1271 solver.cpp:409]     Test net output #1: loss = 0.395668 (* 1 = 0.395668 loss)
I0521 14:34:24.307159  1271 solver.cpp:237] Iteration 120000, loss = 1.79383
I0521 14:34:24.307212  1271 solver.cpp:253]     Train net output #0: loss = 1.79384 (* 1 = 1.79384 loss)
I0521 14:34:24.307229  1271 sgd_solver.cpp:106] Iteration 120000, lr = 0.002
I0521 14:34:41.339129  1271 solver.cpp:237] Iteration 121500, loss = 1.63262
I0521 14:34:41.339298  1271 solver.cpp:253]     Train net output #0: loss = 1.63263 (* 1 = 1.63263 loss)
I0521 14:34:41.339311  1271 sgd_solver.cpp:106] Iteration 121500, lr = 0.002
I0521 14:34:58.384824  1271 solver.cpp:237] Iteration 123000, loss = 1.19164
I0521 14:34:58.384871  1271 solver.cpp:253]     Train net output #0: loss = 1.19165 (* 1 = 1.19165 loss)
I0521 14:34:58.384887  1271 sgd_solver.cpp:106] Iteration 123000, lr = 0.002
I0521 14:35:15.425523  1271 solver.cpp:237] Iteration 124500, loss = 0.696396
I0521 14:35:15.425669  1271 solver.cpp:253]     Train net output #0: loss = 0.696405 (* 1 = 0.696405 loss)
I0521 14:35:15.425685  1271 sgd_solver.cpp:106] Iteration 124500, lr = 0.002
I0521 14:35:32.473860  1271 solver.cpp:237] Iteration 126000, loss = 1.16589
I0521 14:35:32.473906  1271 solver.cpp:253]     Train net output #0: loss = 1.1659 (* 1 = 1.1659 loss)
I0521 14:35:32.473920  1271 sgd_solver.cpp:106] Iteration 126000, lr = 0.002
I0521 14:35:49.509474  1271 solver.cpp:237] Iteration 127500, loss = 0.958691
I0521 14:35:49.509634  1271 solver.cpp:253]     Train net output #0: loss = 0.9587 (* 1 = 0.9587 loss)
I0521 14:35:49.509647  1271 sgd_solver.cpp:106] Iteration 127500, lr = 0.002
I0521 14:36:06.549501  1271 solver.cpp:237] Iteration 129000, loss = 1.62199
I0521 14:36:06.549537  1271 solver.cpp:253]     Train net output #0: loss = 1.622 (* 1 = 1.622 loss)
I0521 14:36:06.549553  1271 sgd_solver.cpp:106] Iteration 129000, lr = 0.002
I0521 14:36:45.699303  1271 solver.cpp:237] Iteration 130500, loss = 0.751546
I0521 14:36:45.699472  1271 solver.cpp:253]     Train net output #0: loss = 0.751554 (* 1 = 0.751554 loss)
I0521 14:36:45.699487  1271 sgd_solver.cpp:106] Iteration 130500, lr = 0.002
I0521 14:37:02.727960  1271 solver.cpp:237] Iteration 132000, loss = 0.796487
I0521 14:37:02.728009  1271 solver.cpp:253]     Train net output #0: loss = 0.796495 (* 1 = 0.796495 loss)
I0521 14:37:02.728024  1271 sgd_solver.cpp:106] Iteration 132000, lr = 0.002
I0521 14:37:19.744954  1271 solver.cpp:237] Iteration 133500, loss = 0.768785
I0521 14:37:19.745098  1271 solver.cpp:253]     Train net output #0: loss = 0.768793 (* 1 = 0.768793 loss)
I0521 14:37:19.745111  1271 sgd_solver.cpp:106] Iteration 133500, lr = 0.002
I0521 14:37:36.726732  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_135000.caffemodel
I0521 14:37:36.775203  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_135000.solverstate
I0521 14:37:36.806407  1271 solver.cpp:237] Iteration 135000, loss = 2.21426
I0521 14:37:36.806457  1271 solver.cpp:253]     Train net output #0: loss = 2.21427 (* 1 = 2.21427 loss)
I0521 14:37:36.806470  1271 sgd_solver.cpp:106] Iteration 135000, lr = 0.002
I0521 14:37:53.845108  1271 solver.cpp:237] Iteration 136500, loss = 0.911277
I0521 14:37:53.845269  1271 solver.cpp:253]     Train net output #0: loss = 0.911285 (* 1 = 0.911285 loss)
I0521 14:37:53.845283  1271 sgd_solver.cpp:106] Iteration 136500, lr = 0.002
I0521 14:38:10.893821  1271 solver.cpp:237] Iteration 138000, loss = 3.03907
I0521 14:38:10.893857  1271 solver.cpp:253]     Train net output #0: loss = 3.03908 (* 1 = 3.03908 loss)
I0521 14:38:10.893870  1271 sgd_solver.cpp:106] Iteration 138000, lr = 0.002
I0521 14:38:27.897871  1271 solver.cpp:237] Iteration 139500, loss = 1.20243
I0521 14:38:27.898037  1271 solver.cpp:253]     Train net output #0: loss = 1.20243 (* 1 = 1.20243 loss)
I0521 14:38:27.898052  1271 sgd_solver.cpp:106] Iteration 139500, lr = 0.002
I0521 14:39:07.129559  1271 solver.cpp:237] Iteration 141000, loss = 1.48862
I0521 14:39:07.129731  1271 solver.cpp:253]     Train net output #0: loss = 1.48863 (* 1 = 1.48863 loss)
I0521 14:39:07.129745  1271 sgd_solver.cpp:106] Iteration 141000, lr = 0.002
I0521 14:39:24.175581  1271 solver.cpp:237] Iteration 142500, loss = 2.15215
I0521 14:39:24.175618  1271 solver.cpp:253]     Train net output #0: loss = 2.15215 (* 1 = 2.15215 loss)
I0521 14:39:24.175634  1271 sgd_solver.cpp:106] Iteration 142500, lr = 0.002
I0521 14:39:41.200778  1271 solver.cpp:237] Iteration 144000, loss = 0.870724
I0521 14:39:41.200932  1271 solver.cpp:253]     Train net output #0: loss = 0.870732 (* 1 = 0.870732 loss)
I0521 14:39:41.200947  1271 sgd_solver.cpp:106] Iteration 144000, lr = 0.002
I0521 14:39:58.252882  1271 solver.cpp:237] Iteration 145500, loss = 1.41861
I0521 14:39:58.252926  1271 solver.cpp:253]     Train net output #0: loss = 1.41862 (* 1 = 1.41862 loss)
I0521 14:39:58.252945  1271 sgd_solver.cpp:106] Iteration 145500, lr = 0.002
I0521 14:40:15.284847  1271 solver.cpp:237] Iteration 147000, loss = 1.70052
I0521 14:40:15.284997  1271 solver.cpp:253]     Train net output #0: loss = 1.70053 (* 1 = 1.70053 loss)
I0521 14:40:15.285012  1271 sgd_solver.cpp:106] Iteration 147000, lr = 0.002
I0521 14:40:32.299947  1271 solver.cpp:237] Iteration 148500, loss = 1.01069
I0521 14:40:32.299993  1271 solver.cpp:253]     Train net output #0: loss = 1.0107 (* 1 = 1.0107 loss)
I0521 14:40:32.300009  1271 sgd_solver.cpp:106] Iteration 148500, lr = 0.002
I0521 14:40:49.319445  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_150000.caffemodel
I0521 14:40:49.367246  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_150000.solverstate
I0521 14:40:49.395182  1271 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 14:41:49.078464  1271 solver.cpp:409]     Test net output #0: accuracy = 0.884641
I0521 14:41:49.078644  1271 solver.cpp:409]     Test net output #1: loss = 0.365123 (* 1 = 0.365123 loss)
I0521 14:42:10.018371  1271 solver.cpp:237] Iteration 150000, loss = 0.662974
I0521 14:42:10.018424  1271 solver.cpp:253]     Train net output #0: loss = 0.662983 (* 1 = 0.662983 loss)
I0521 14:42:10.018441  1271 sgd_solver.cpp:106] Iteration 150000, lr = 0.002
I0521 14:42:27.211340  1271 solver.cpp:237] Iteration 151500, loss = 1.51122
I0521 14:42:27.211508  1271 solver.cpp:253]     Train net output #0: loss = 1.51123 (* 1 = 1.51123 loss)
I0521 14:42:27.211522  1271 sgd_solver.cpp:106] Iteration 151500, lr = 0.002
I0521 14:42:44.397477  1271 solver.cpp:237] Iteration 153000, loss = 1.92404
I0521 14:42:44.397514  1271 solver.cpp:253]     Train net output #0: loss = 1.92405 (* 1 = 1.92405 loss)
I0521 14:42:44.397531  1271 sgd_solver.cpp:106] Iteration 153000, lr = 0.002
I0521 14:43:01.583317  1271 solver.cpp:237] Iteration 154500, loss = 0.988802
I0521 14:43:01.583480  1271 solver.cpp:253]     Train net output #0: loss = 0.988809 (* 1 = 0.988809 loss)
I0521 14:43:01.583497  1271 sgd_solver.cpp:106] Iteration 154500, lr = 0.002
I0521 14:43:18.777160  1271 solver.cpp:237] Iteration 156000, loss = 1.04741
I0521 14:43:18.777209  1271 solver.cpp:253]     Train net output #0: loss = 1.04742 (* 1 = 1.04742 loss)
I0521 14:43:18.777225  1271 sgd_solver.cpp:106] Iteration 156000, lr = 0.002
I0521 14:43:35.942150  1271 solver.cpp:237] Iteration 157500, loss = 1.40453
I0521 14:43:35.942311  1271 solver.cpp:253]     Train net output #0: loss = 1.40454 (* 1 = 1.40454 loss)
I0521 14:43:35.942324  1271 sgd_solver.cpp:106] Iteration 157500, lr = 0.002
I0521 14:43:53.094568  1271 solver.cpp:237] Iteration 159000, loss = 1.21113
I0521 14:43:53.094619  1271 solver.cpp:253]     Train net output #0: loss = 1.21114 (* 1 = 1.21114 loss)
I0521 14:43:53.094632  1271 sgd_solver.cpp:106] Iteration 159000, lr = 0.002
I0521 14:44:31.162475  1271 solver.cpp:237] Iteration 160500, loss = 0.718826
I0521 14:44:31.162648  1271 solver.cpp:253]     Train net output #0: loss = 0.718834 (* 1 = 0.718834 loss)
I0521 14:44:31.162663  1271 sgd_solver.cpp:106] Iteration 160500, lr = 0.002
I0521 14:44:48.346114  1271 solver.cpp:237] Iteration 162000, loss = 1.09242
I0521 14:44:48.346149  1271 solver.cpp:253]     Train net output #0: loss = 1.09243 (* 1 = 1.09243 loss)
I0521 14:44:48.346166  1271 sgd_solver.cpp:106] Iteration 162000, lr = 0.002
I0521 14:45:05.542888  1271 solver.cpp:237] Iteration 163500, loss = 1.34734
I0521 14:45:05.543053  1271 solver.cpp:253]     Train net output #0: loss = 1.34735 (* 1 = 1.34735 loss)
I0521 14:45:05.543068  1271 sgd_solver.cpp:106] Iteration 163500, lr = 0.002
I0521 14:45:22.723181  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_165000.caffemodel
I0521 14:45:22.769172  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_165000.solverstate
I0521 14:45:22.797689  1271 solver.cpp:237] Iteration 165000, loss = 0.969675
I0521 14:45:22.797735  1271 solver.cpp:253]     Train net output #0: loss = 0.969684 (* 1 = 0.969684 loss)
I0521 14:45:22.797750  1271 sgd_solver.cpp:106] Iteration 165000, lr = 0.002
I0521 14:45:39.934397  1271 solver.cpp:237] Iteration 166500, loss = 0.877559
I0521 14:45:39.934551  1271 solver.cpp:253]     Train net output #0: loss = 0.877567 (* 1 = 0.877567 loss)
I0521 14:45:39.934566  1271 sgd_solver.cpp:106] Iteration 166500, lr = 0.002
I0521 14:45:57.107926  1271 solver.cpp:237] Iteration 168000, loss = 1.31612
I0521 14:45:57.107972  1271 solver.cpp:253]     Train net output #0: loss = 1.31612 (* 1 = 1.31612 loss)
I0521 14:45:57.107987  1271 sgd_solver.cpp:106] Iteration 168000, lr = 0.002
I0521 14:46:14.308662  1271 solver.cpp:237] Iteration 169500, loss = 1.07996
I0521 14:46:14.308823  1271 solver.cpp:253]     Train net output #0: loss = 1.07997 (* 1 = 1.07997 loss)
I0521 14:46:14.308837  1271 sgd_solver.cpp:106] Iteration 169500, lr = 0.002
I0521 14:46:52.349473  1271 solver.cpp:237] Iteration 171000, loss = 0.604826
I0521 14:46:52.349645  1271 solver.cpp:253]     Train net output #0: loss = 0.604833 (* 1 = 0.604833 loss)
I0521 14:46:52.349661  1271 sgd_solver.cpp:106] Iteration 171000, lr = 0.002
I0521 14:47:09.521736  1271 solver.cpp:237] Iteration 172500, loss = 0.80839
I0521 14:47:09.521785  1271 solver.cpp:253]     Train net output #0: loss = 0.808397 (* 1 = 0.808397 loss)
I0521 14:47:09.521800  1271 sgd_solver.cpp:106] Iteration 172500, lr = 0.002
I0521 14:47:26.715490  1271 solver.cpp:237] Iteration 174000, loss = 0.85101
I0521 14:47:26.715652  1271 solver.cpp:253]     Train net output #0: loss = 0.851018 (* 1 = 0.851018 loss)
I0521 14:47:26.715667  1271 sgd_solver.cpp:106] Iteration 174000, lr = 0.002
I0521 14:47:43.895051  1271 solver.cpp:237] Iteration 175500, loss = 0.932396
I0521 14:47:43.895088  1271 solver.cpp:253]     Train net output #0: loss = 0.932403 (* 1 = 0.932403 loss)
I0521 14:47:43.895104  1271 sgd_solver.cpp:106] Iteration 175500, lr = 0.002
I0521 14:48:01.087481  1271 solver.cpp:237] Iteration 177000, loss = 1.49502
I0521 14:48:01.087646  1271 solver.cpp:253]     Train net output #0: loss = 1.49503 (* 1 = 1.49503 loss)
I0521 14:48:01.087661  1271 sgd_solver.cpp:106] Iteration 177000, lr = 0.002
I0521 14:48:18.258046  1271 solver.cpp:237] Iteration 178500, loss = 0.982756
I0521 14:48:18.258092  1271 solver.cpp:253]     Train net output #0: loss = 0.982763 (* 1 = 0.982763 loss)
I0521 14:48:18.258110  1271 sgd_solver.cpp:106] Iteration 178500, lr = 0.002
I0521 14:48:35.430189  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_180000.caffemodel
I0521 14:48:35.475543  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_180000.solverstate
I0521 14:48:35.500798  1271 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 14:49:55.764293  1271 solver.cpp:409]     Test net output #0: accuracy = 0.889262
I0521 14:49:55.764459  1271 solver.cpp:409]     Test net output #1: loss = 0.371155 (* 1 = 0.371155 loss)
I0521 14:50:16.660853  1271 solver.cpp:237] Iteration 180000, loss = 0.719491
I0521 14:50:16.660908  1271 solver.cpp:253]     Train net output #0: loss = 0.719498 (* 1 = 0.719498 loss)
I0521 14:50:16.660923  1271 sgd_solver.cpp:106] Iteration 180000, lr = 0.002
I0521 14:50:33.283040  1271 solver.cpp:237] Iteration 181500, loss = 1.42309
I0521 14:50:33.283203  1271 solver.cpp:253]     Train net output #0: loss = 1.4231 (* 1 = 1.4231 loss)
I0521 14:50:33.283217  1271 sgd_solver.cpp:106] Iteration 181500, lr = 0.002
I0521 14:50:49.924787  1271 solver.cpp:237] Iteration 183000, loss = 1.22131
I0521 14:50:49.924834  1271 solver.cpp:253]     Train net output #0: loss = 1.22132 (* 1 = 1.22132 loss)
I0521 14:50:49.924851  1271 sgd_solver.cpp:106] Iteration 183000, lr = 0.002
I0521 14:51:06.546696  1271 solver.cpp:237] Iteration 184500, loss = 1.59205
I0521 14:51:06.546857  1271 solver.cpp:253]     Train net output #0: loss = 1.59206 (* 1 = 1.59206 loss)
I0521 14:51:06.546872  1271 sgd_solver.cpp:106] Iteration 184500, lr = 0.002
I0521 14:51:23.188473  1271 solver.cpp:237] Iteration 186000, loss = 1.03295
I0521 14:51:23.188519  1271 solver.cpp:253]     Train net output #0: loss = 1.03296 (* 1 = 1.03296 loss)
I0521 14:51:23.188534  1271 sgd_solver.cpp:106] Iteration 186000, lr = 0.002
I0521 14:51:39.777616  1271 solver.cpp:237] Iteration 187500, loss = 0.31452
I0521 14:51:39.777777  1271 solver.cpp:253]     Train net output #0: loss = 0.314528 (* 1 = 0.314528 loss)
I0521 14:51:39.777791  1271 sgd_solver.cpp:106] Iteration 187500, lr = 0.002
I0521 14:51:56.425811  1271 solver.cpp:237] Iteration 189000, loss = 1.01364
I0521 14:51:56.425848  1271 solver.cpp:253]     Train net output #0: loss = 1.01364 (* 1 = 1.01364 loss)
I0521 14:51:56.425860  1271 sgd_solver.cpp:106] Iteration 189000, lr = 0.002
I0521 14:52:33.933375  1271 solver.cpp:237] Iteration 190500, loss = 1.28097
I0521 14:52:33.933544  1271 solver.cpp:253]     Train net output #0: loss = 1.28098 (* 1 = 1.28098 loss)
I0521 14:52:33.933559  1271 sgd_solver.cpp:106] Iteration 190500, lr = 0.002
I0521 14:52:50.567558  1271 solver.cpp:237] Iteration 192000, loss = 0.447028
I0521 14:52:50.567602  1271 solver.cpp:253]     Train net output #0: loss = 0.447036 (* 1 = 0.447036 loss)
I0521 14:52:50.567620  1271 sgd_solver.cpp:106] Iteration 192000, lr = 0.002
I0521 14:53:07.181021  1271 solver.cpp:237] Iteration 193500, loss = 1.93887
I0521 14:53:07.181171  1271 solver.cpp:253]     Train net output #0: loss = 1.93887 (* 1 = 1.93887 loss)
I0521 14:53:07.181185  1271 sgd_solver.cpp:106] Iteration 193500, lr = 0.002
I0521 14:53:23.779362  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_195000.caffemodel
I0521 14:53:23.824631  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_195000.solverstate
I0521 14:53:23.852932  1271 solver.cpp:237] Iteration 195000, loss = 1.09061
I0521 14:53:23.852977  1271 solver.cpp:253]     Train net output #0: loss = 1.09062 (* 1 = 1.09062 loss)
I0521 14:53:23.852994  1271 sgd_solver.cpp:106] Iteration 195000, lr = 0.002
I0521 14:53:40.478409  1271 solver.cpp:237] Iteration 196500, loss = 1.46141
I0521 14:53:40.478595  1271 solver.cpp:253]     Train net output #0: loss = 1.46141 (* 1 = 1.46141 loss)
I0521 14:53:40.478610  1271 sgd_solver.cpp:106] Iteration 196500, lr = 0.002
I0521 14:53:57.131083  1271 solver.cpp:237] Iteration 198000, loss = 0.901515
I0521 14:53:57.131120  1271 solver.cpp:253]     Train net output #0: loss = 0.901524 (* 1 = 0.901524 loss)
I0521 14:53:57.131136  1271 sgd_solver.cpp:106] Iteration 198000, lr = 0.002
I0521 14:54:13.752035  1271 solver.cpp:237] Iteration 199500, loss = 0.415335
I0521 14:54:13.752207  1271 solver.cpp:253]     Train net output #0: loss = 0.415344 (* 1 = 0.415344 loss)
I0521 14:54:13.752223  1271 sgd_solver.cpp:106] Iteration 199500, lr = 0.002
I0521 14:54:51.291285  1271 solver.cpp:237] Iteration 201000, loss = 0.854898
I0521 14:54:51.291460  1271 solver.cpp:253]     Train net output #0: loss = 0.854907 (* 1 = 0.854907 loss)
I0521 14:54:51.291476  1271 sgd_solver.cpp:106] Iteration 201000, lr = 0.002
I0521 14:55:07.900732  1271 solver.cpp:237] Iteration 202500, loss = 1.0375
I0521 14:55:07.900781  1271 solver.cpp:253]     Train net output #0: loss = 1.03751 (* 1 = 1.03751 loss)
I0521 14:55:07.900795  1271 sgd_solver.cpp:106] Iteration 202500, lr = 0.002
I0521 14:55:24.524081  1271 solver.cpp:237] Iteration 204000, loss = 1.47084
I0521 14:55:24.524251  1271 solver.cpp:253]     Train net output #0: loss = 1.47085 (* 1 = 1.47085 loss)
I0521 14:55:24.524266  1271 sgd_solver.cpp:106] Iteration 204000, lr = 0.002
I0521 14:55:41.171043  1271 solver.cpp:237] Iteration 205500, loss = 1.27915
I0521 14:55:41.171080  1271 solver.cpp:253]     Train net output #0: loss = 1.27916 (* 1 = 1.27916 loss)
I0521 14:55:41.171097  1271 sgd_solver.cpp:106] Iteration 205500, lr = 0.002
I0521 14:55:57.781170  1271 solver.cpp:237] Iteration 207000, loss = 1.01082
I0521 14:55:57.781335  1271 solver.cpp:253]     Train net output #0: loss = 1.01082 (* 1 = 1.01082 loss)
I0521 14:55:57.781349  1271 sgd_solver.cpp:106] Iteration 207000, lr = 0.002
I0521 14:56:14.366685  1271 solver.cpp:237] Iteration 208500, loss = 1.22798
I0521 14:56:14.366724  1271 solver.cpp:253]     Train net output #0: loss = 1.22799 (* 1 = 1.22799 loss)
I0521 14:56:14.366744  1271 sgd_solver.cpp:106] Iteration 208500, lr = 0.002
I0521 14:56:30.964586  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_210000.caffemodel
I0521 14:56:31.009997  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_210000.solverstate
I0521 14:56:31.035199  1271 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 14:57:30.351025  1271 solver.cpp:409]     Test net output #0: accuracy = 0.889964
I0521 14:57:30.351194  1271 solver.cpp:409]     Test net output #1: loss = 0.383197 (* 1 = 0.383197 loss)
I0521 14:57:51.321072  1271 solver.cpp:237] Iteration 210000, loss = 1.56029
I0521 14:57:51.321125  1271 solver.cpp:253]     Train net output #0: loss = 1.5603 (* 1 = 1.5603 loss)
I0521 14:57:51.321141  1271 sgd_solver.cpp:106] Iteration 210000, lr = 0.002
I0521 14:58:08.509493  1271 solver.cpp:237] Iteration 211500, loss = 0.673065
I0521 14:58:08.509665  1271 solver.cpp:253]     Train net output #0: loss = 0.673073 (* 1 = 0.673073 loss)
I0521 14:58:08.509680  1271 sgd_solver.cpp:106] Iteration 211500, lr = 0.002
I0521 14:58:25.681555  1271 solver.cpp:237] Iteration 213000, loss = 1.2515
I0521 14:58:25.681602  1271 solver.cpp:253]     Train net output #0: loss = 1.25151 (* 1 = 1.25151 loss)
I0521 14:58:25.681617  1271 sgd_solver.cpp:106] Iteration 213000, lr = 0.002
I0521 14:58:42.859838  1271 solver.cpp:237] Iteration 214500, loss = 1.60599
I0521 14:58:42.860011  1271 solver.cpp:253]     Train net output #0: loss = 1.606 (* 1 = 1.606 loss)
I0521 14:58:42.860026  1271 sgd_solver.cpp:106] Iteration 214500, lr = 0.002
I0521 14:59:00.052186  1271 solver.cpp:237] Iteration 216000, loss = 0.963013
I0521 14:59:00.052222  1271 solver.cpp:253]     Train net output #0: loss = 0.963021 (* 1 = 0.963021 loss)
I0521 14:59:00.052239  1271 sgd_solver.cpp:106] Iteration 216000, lr = 0.002
I0521 14:59:17.245512  1271 solver.cpp:237] Iteration 217500, loss = 0.718652
I0521 14:59:17.245676  1271 solver.cpp:253]     Train net output #0: loss = 0.71866 (* 1 = 0.71866 loss)
I0521 14:59:17.245692  1271 sgd_solver.cpp:106] Iteration 217500, lr = 0.002
I0521 14:59:34.447522  1271 solver.cpp:237] Iteration 219000, loss = 1.65524
I0521 14:59:34.447564  1271 solver.cpp:253]     Train net output #0: loss = 1.65525 (* 1 = 1.65525 loss)
I0521 14:59:34.447585  1271 sgd_solver.cpp:106] Iteration 219000, lr = 0.002
I0521 15:00:12.521883  1271 solver.cpp:237] Iteration 220500, loss = 1.72521
I0521 15:00:12.522055  1271 solver.cpp:253]     Train net output #0: loss = 1.72522 (* 1 = 1.72522 loss)
I0521 15:00:12.522070  1271 sgd_solver.cpp:106] Iteration 220500, lr = 0.002
I0521 15:00:29.679633  1271 solver.cpp:237] Iteration 222000, loss = 1.07852
I0521 15:00:29.679678  1271 solver.cpp:253]     Train net output #0: loss = 1.07853 (* 1 = 1.07853 loss)
I0521 15:00:29.679694  1271 sgd_solver.cpp:106] Iteration 222000, lr = 0.002
I0521 15:00:46.870653  1271 solver.cpp:237] Iteration 223500, loss = 0.988736
I0521 15:00:46.870817  1271 solver.cpp:253]     Train net output #0: loss = 0.988744 (* 1 = 0.988744 loss)
I0521 15:00:46.870831  1271 sgd_solver.cpp:106] Iteration 223500, lr = 0.002
I0521 15:01:04.046308  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_225000.caffemodel
I0521 15:01:04.094607  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_225000.solverstate
I0521 15:01:04.125186  1271 solver.cpp:237] Iteration 225000, loss = 0.636812
I0521 15:01:04.125237  1271 solver.cpp:253]     Train net output #0: loss = 0.636821 (* 1 = 0.636821 loss)
I0521 15:01:04.125252  1271 sgd_solver.cpp:106] Iteration 225000, lr = 0.002
I0521 15:01:21.336707  1271 solver.cpp:237] Iteration 226500, loss = 1.92671
I0521 15:01:21.336874  1271 solver.cpp:253]     Train net output #0: loss = 1.92672 (* 1 = 1.92672 loss)
I0521 15:01:21.336889  1271 sgd_solver.cpp:106] Iteration 226500, lr = 0.002
I0521 15:01:38.545205  1271 solver.cpp:237] Iteration 228000, loss = 1.1426
I0521 15:01:38.545256  1271 solver.cpp:253]     Train net output #0: loss = 1.14261 (* 1 = 1.14261 loss)
I0521 15:01:38.545270  1271 sgd_solver.cpp:106] Iteration 228000, lr = 0.002
I0521 15:01:55.722692  1271 solver.cpp:237] Iteration 229500, loss = 1.50894
I0521 15:01:55.722846  1271 solver.cpp:253]     Train net output #0: loss = 1.50895 (* 1 = 1.50895 loss)
I0521 15:01:55.722861  1271 sgd_solver.cpp:106] Iteration 229500, lr = 0.002
I0521 15:02:33.810896  1271 solver.cpp:237] Iteration 231000, loss = 0.777876
I0521 15:02:33.811067  1271 solver.cpp:253]     Train net output #0: loss = 0.777885 (* 1 = 0.777885 loss)
I0521 15:02:33.811082  1271 sgd_solver.cpp:106] Iteration 231000, lr = 0.002
I0521 15:02:50.989019  1271 solver.cpp:237] Iteration 232500, loss = 0.913151
I0521 15:02:50.989064  1271 solver.cpp:253]     Train net output #0: loss = 0.913161 (* 1 = 0.913161 loss)
I0521 15:02:50.989085  1271 sgd_solver.cpp:106] Iteration 232500, lr = 0.002
I0521 15:03:08.170536  1271 solver.cpp:237] Iteration 234000, loss = 1.2407
I0521 15:03:08.170688  1271 solver.cpp:253]     Train net output #0: loss = 1.24071 (* 1 = 1.24071 loss)
I0521 15:03:08.170702  1271 sgd_solver.cpp:106] Iteration 234000, lr = 0.002
I0521 15:03:25.353163  1271 solver.cpp:237] Iteration 235500, loss = 1.0799
I0521 15:03:25.353211  1271 solver.cpp:253]     Train net output #0: loss = 1.07991 (* 1 = 1.07991 loss)
I0521 15:03:25.353224  1271 sgd_solver.cpp:106] Iteration 235500, lr = 0.002
I0521 15:03:42.563158  1271 solver.cpp:237] Iteration 237000, loss = 1.61582
I0521 15:03:42.563336  1271 solver.cpp:253]     Train net output #0: loss = 1.61583 (* 1 = 1.61583 loss)
I0521 15:03:42.563350  1271 sgd_solver.cpp:106] Iteration 237000, lr = 0.002
I0521 15:03:59.751289  1271 solver.cpp:237] Iteration 238500, loss = 0.989377
I0521 15:03:59.751327  1271 solver.cpp:253]     Train net output #0: loss = 0.989386 (* 1 = 0.989386 loss)
I0521 15:03:59.751343  1271 sgd_solver.cpp:106] Iteration 238500, lr = 0.002
I0521 15:04:16.932600  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_240000.caffemodel
I0521 15:04:16.978330  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_240000.solverstate
I0521 15:04:17.003820  1271 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 15:05:37.263356  1271 solver.cpp:409]     Test net output #0: accuracy = 0.891755
I0521 15:05:37.263530  1271 solver.cpp:409]     Test net output #1: loss = 0.355016 (* 1 = 0.355016 loss)
I0521 15:05:58.159220  1271 solver.cpp:237] Iteration 240000, loss = 1.0803
I0521 15:05:58.159274  1271 solver.cpp:253]     Train net output #0: loss = 1.0803 (* 1 = 1.0803 loss)
I0521 15:05:58.159289  1271 sgd_solver.cpp:106] Iteration 240000, lr = 0.002
I0521 15:06:15.000903  1271 solver.cpp:237] Iteration 241500, loss = 0.710883
I0521 15:06:15.001076  1271 solver.cpp:253]     Train net output #0: loss = 0.710892 (* 1 = 0.710892 loss)
I0521 15:06:15.001091  1271 sgd_solver.cpp:106] Iteration 241500, lr = 0.002
I0521 15:06:31.904806  1271 solver.cpp:237] Iteration 243000, loss = 1.25004
I0521 15:06:31.904842  1271 solver.cpp:253]     Train net output #0: loss = 1.25005 (* 1 = 1.25005 loss)
I0521 15:06:31.904860  1271 sgd_solver.cpp:106] Iteration 243000, lr = 0.002
I0521 15:06:48.769160  1271 solver.cpp:237] Iteration 244500, loss = 1.48794
I0521 15:06:48.769320  1271 solver.cpp:253]     Train net output #0: loss = 1.48794 (* 1 = 1.48794 loss)
I0521 15:06:48.769333  1271 sgd_solver.cpp:106] Iteration 244500, lr = 0.002
I0521 15:07:05.680080  1271 solver.cpp:237] Iteration 246000, loss = 0.748153
I0521 15:07:05.680131  1271 solver.cpp:253]     Train net output #0: loss = 0.748161 (* 1 = 0.748161 loss)
I0521 15:07:05.680145  1271 sgd_solver.cpp:106] Iteration 246000, lr = 0.002
I0521 15:07:22.551882  1271 solver.cpp:237] Iteration 247500, loss = 1.06485
I0521 15:07:22.552038  1271 solver.cpp:253]     Train net output #0: loss = 1.06486 (* 1 = 1.06486 loss)
I0521 15:07:22.552052  1271 sgd_solver.cpp:106] Iteration 247500, lr = 0.002
I0521 15:07:39.373071  1271 solver.cpp:237] Iteration 249000, loss = 1.22652
I0521 15:07:39.373116  1271 solver.cpp:253]     Train net output #0: loss = 1.22653 (* 1 = 1.22653 loss)
I0521 15:07:39.373131  1271 sgd_solver.cpp:106] Iteration 249000, lr = 0.002
I0521 15:08:17.086405  1271 solver.cpp:237] Iteration 250500, loss = 1.18003
I0521 15:08:17.086576  1271 solver.cpp:253]     Train net output #0: loss = 1.18004 (* 1 = 1.18004 loss)
I0521 15:08:17.086591  1271 sgd_solver.cpp:106] Iteration 250500, lr = 0.002
I0521 15:08:33.896667  1271 solver.cpp:237] Iteration 252000, loss = 0.521689
I0521 15:08:33.896704  1271 solver.cpp:253]     Train net output #0: loss = 0.521697 (* 1 = 0.521697 loss)
I0521 15:08:33.896721  1271 sgd_solver.cpp:106] Iteration 252000, lr = 0.002
I0521 15:08:50.753834  1271 solver.cpp:237] Iteration 253500, loss = 0.541983
I0521 15:08:50.753994  1271 solver.cpp:253]     Train net output #0: loss = 0.541992 (* 1 = 0.541992 loss)
I0521 15:08:50.754009  1271 sgd_solver.cpp:106] Iteration 253500, lr = 0.002
I0521 15:09:07.635268  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_255000.caffemodel
I0521 15:09:07.681238  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_255000.solverstate
I0521 15:09:07.709652  1271 solver.cpp:237] Iteration 255000, loss = 1.40691
I0521 15:09:07.709698  1271 solver.cpp:253]     Train net output #0: loss = 1.40691 (* 1 = 1.40691 loss)
I0521 15:09:07.709713  1271 sgd_solver.cpp:106] Iteration 255000, lr = 0.002
I0521 15:09:24.609230  1271 solver.cpp:237] Iteration 256500, loss = 1.16636
I0521 15:09:24.609398  1271 solver.cpp:253]     Train net output #0: loss = 1.16637 (* 1 = 1.16637 loss)
I0521 15:09:24.609413  1271 sgd_solver.cpp:106] Iteration 256500, lr = 0.002
I0521 15:09:41.516067  1271 solver.cpp:237] Iteration 258000, loss = 1.13896
I0521 15:09:41.516110  1271 solver.cpp:253]     Train net output #0: loss = 1.13897 (* 1 = 1.13897 loss)
I0521 15:09:41.516126  1271 sgd_solver.cpp:106] Iteration 258000, lr = 0.002
I0521 15:09:58.433430  1271 solver.cpp:237] Iteration 259500, loss = 0.843169
I0521 15:09:58.433609  1271 solver.cpp:253]     Train net output #0: loss = 0.843178 (* 1 = 0.843178 loss)
I0521 15:09:58.433624  1271 sgd_solver.cpp:106] Iteration 259500, lr = 0.002
I0521 15:10:36.213042  1271 solver.cpp:237] Iteration 261000, loss = 1.14503
I0521 15:10:36.213222  1271 solver.cpp:253]     Train net output #0: loss = 1.14504 (* 1 = 1.14504 loss)
I0521 15:10:36.213235  1271 sgd_solver.cpp:106] Iteration 261000, lr = 0.002
I0521 15:10:53.132272  1271 solver.cpp:237] Iteration 262500, loss = 2.29427
I0521 15:10:53.132321  1271 solver.cpp:253]     Train net output #0: loss = 2.29428 (* 1 = 2.29428 loss)
I0521 15:10:53.132335  1271 sgd_solver.cpp:106] Iteration 262500, lr = 0.002
I0521 15:11:10.061492  1271 solver.cpp:237] Iteration 264000, loss = 1.36185
I0521 15:11:10.061658  1271 solver.cpp:253]     Train net output #0: loss = 1.36186 (* 1 = 1.36186 loss)
I0521 15:11:10.061672  1271 sgd_solver.cpp:106] Iteration 264000, lr = 0.002
I0521 15:11:26.707012  1271 solver.cpp:237] Iteration 265500, loss = 1.11173
I0521 15:11:26.707048  1271 solver.cpp:253]     Train net output #0: loss = 1.11174 (* 1 = 1.11174 loss)
I0521 15:11:26.707065  1271 sgd_solver.cpp:106] Iteration 265500, lr = 0.002
I0521 15:11:43.657862  1271 solver.cpp:237] Iteration 267000, loss = 1.22677
I0521 15:11:43.658031  1271 solver.cpp:253]     Train net output #0: loss = 1.22678 (* 1 = 1.22678 loss)
I0521 15:11:43.658046  1271 sgd_solver.cpp:106] Iteration 267000, lr = 0.002
I0521 15:12:00.846904  1271 solver.cpp:237] Iteration 268500, loss = 0.717564
I0521 15:12:00.846952  1271 solver.cpp:253]     Train net output #0: loss = 0.717574 (* 1 = 0.717574 loss)
I0521 15:12:00.846968  1271 sgd_solver.cpp:106] Iteration 268500, lr = 0.002
I0521 15:12:18.025954  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_270000.caffemodel
I0521 15:12:18.077680  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_270000.solverstate
I0521 15:12:18.103350  1271 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 15:13:17.550451  1271 solver.cpp:409]     Test net output #0: accuracy = 0.890684
I0521 15:13:17.550631  1271 solver.cpp:409]     Test net output #1: loss = 0.353525 (* 1 = 0.353525 loss)
I0521 15:13:38.475612  1271 solver.cpp:237] Iteration 270000, loss = 2.49297
I0521 15:13:38.475663  1271 solver.cpp:253]     Train net output #0: loss = 2.49298 (* 1 = 2.49298 loss)
I0521 15:13:38.475679  1271 sgd_solver.cpp:106] Iteration 270000, lr = 0.002
I0521 15:13:55.424474  1271 solver.cpp:237] Iteration 271500, loss = 1.44467
I0521 15:13:55.424636  1271 solver.cpp:253]     Train net output #0: loss = 1.44468 (* 1 = 1.44468 loss)
I0521 15:13:55.424650  1271 sgd_solver.cpp:106] Iteration 271500, lr = 0.002
I0521 15:14:12.359267  1271 solver.cpp:237] Iteration 273000, loss = 1.48432
I0521 15:14:12.359314  1271 solver.cpp:253]     Train net output #0: loss = 1.48433 (* 1 = 1.48433 loss)
I0521 15:14:12.359329  1271 sgd_solver.cpp:106] Iteration 273000, lr = 0.002
I0521 15:14:29.312521  1271 solver.cpp:237] Iteration 274500, loss = 0.492786
I0521 15:14:29.312700  1271 solver.cpp:253]     Train net output #0: loss = 0.492795 (* 1 = 0.492795 loss)
I0521 15:14:29.312713  1271 sgd_solver.cpp:106] Iteration 274500, lr = 0.002
I0521 15:14:46.265276  1271 solver.cpp:237] Iteration 276000, loss = 0.504054
I0521 15:14:46.265314  1271 solver.cpp:253]     Train net output #0: loss = 0.504063 (* 1 = 0.504063 loss)
I0521 15:14:46.265329  1271 sgd_solver.cpp:106] Iteration 276000, lr = 0.002
I0521 15:15:03.238283  1271 solver.cpp:237] Iteration 277500, loss = 0.90473
I0521 15:15:03.238447  1271 solver.cpp:253]     Train net output #0: loss = 0.904739 (* 1 = 0.904739 loss)
I0521 15:15:03.238461  1271 sgd_solver.cpp:106] Iteration 277500, lr = 0.002
I0521 15:15:20.203285  1271 solver.cpp:237] Iteration 279000, loss = 1.12694
I0521 15:15:20.203331  1271 solver.cpp:253]     Train net output #0: loss = 1.12695 (* 1 = 1.12695 loss)
I0521 15:15:20.203347  1271 sgd_solver.cpp:106] Iteration 279000, lr = 0.002
I0521 15:15:58.063398  1271 solver.cpp:237] Iteration 280500, loss = 0.993681
I0521 15:15:58.063578  1271 solver.cpp:253]     Train net output #0: loss = 0.99369 (* 1 = 0.99369 loss)
I0521 15:15:58.063594  1271 sgd_solver.cpp:106] Iteration 280500, lr = 0.002
I0521 15:16:15.015290  1271 solver.cpp:237] Iteration 282000, loss = 1.49973
I0521 15:16:15.015333  1271 solver.cpp:253]     Train net output #0: loss = 1.49974 (* 1 = 1.49974 loss)
I0521 15:16:15.015352  1271 sgd_solver.cpp:106] Iteration 282000, lr = 0.002
I0521 15:16:32.002979  1271 solver.cpp:237] Iteration 283500, loss = 1.05047
I0521 15:16:32.003134  1271 solver.cpp:253]     Train net output #0: loss = 1.05048 (* 1 = 1.05048 loss)
I0521 15:16:32.003149  1271 sgd_solver.cpp:106] Iteration 283500, lr = 0.002
I0521 15:16:48.792781  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_285000.caffemodel
I0521 15:16:48.843114  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_285000.solverstate
I0521 15:16:48.873678  1271 solver.cpp:237] Iteration 285000, loss = 1.6634
I0521 15:16:48.873729  1271 solver.cpp:253]     Train net output #0: loss = 1.66341 (* 1 = 1.66341 loss)
I0521 15:16:48.873744  1271 sgd_solver.cpp:106] Iteration 285000, lr = 0.002
I0521 15:17:05.490397  1271 solver.cpp:237] Iteration 286500, loss = 1.42132
I0521 15:17:05.490569  1271 solver.cpp:253]     Train net output #0: loss = 1.42133 (* 1 = 1.42133 loss)
I0521 15:17:05.490583  1271 sgd_solver.cpp:106] Iteration 286500, lr = 0.002
I0521 15:17:22.126472  1271 solver.cpp:237] Iteration 288000, loss = 2.15453
I0521 15:17:22.126509  1271 solver.cpp:253]     Train net output #0: loss = 2.15454 (* 1 = 2.15454 loss)
I0521 15:17:22.126525  1271 sgd_solver.cpp:106] Iteration 288000, lr = 0.002
I0521 15:17:39.027241  1271 solver.cpp:237] Iteration 289500, loss = 1.36116
I0521 15:17:39.027412  1271 solver.cpp:253]     Train net output #0: loss = 1.36117 (* 1 = 1.36117 loss)
I0521 15:17:39.027429  1271 sgd_solver.cpp:106] Iteration 289500, lr = 0.002
I0521 15:18:16.889421  1271 solver.cpp:237] Iteration 291000, loss = 1.30447
I0521 15:18:16.889611  1271 solver.cpp:253]     Train net output #0: loss = 1.30448 (* 1 = 1.30448 loss)
I0521 15:18:16.889624  1271 sgd_solver.cpp:106] Iteration 291000, lr = 0.002
I0521 15:18:33.846426  1271 solver.cpp:237] Iteration 292500, loss = 1.2834
I0521 15:18:33.846463  1271 solver.cpp:253]     Train net output #0: loss = 1.2834 (* 1 = 1.2834 loss)
I0521 15:18:33.846479  1271 sgd_solver.cpp:106] Iteration 292500, lr = 0.002
I0521 15:18:50.813365  1271 solver.cpp:237] Iteration 294000, loss = 0.915789
I0521 15:18:50.813547  1271 solver.cpp:253]     Train net output #0: loss = 0.915799 (* 1 = 0.915799 loss)
I0521 15:18:50.813561  1271 sgd_solver.cpp:106] Iteration 294000, lr = 0.002
I0521 15:19:07.782304  1271 solver.cpp:237] Iteration 295500, loss = 1.65466
I0521 15:19:07.782352  1271 solver.cpp:253]     Train net output #0: loss = 1.65467 (* 1 = 1.65467 loss)
I0521 15:19:07.782367  1271 sgd_solver.cpp:106] Iteration 295500, lr = 0.002
I0521 15:19:24.747694  1271 solver.cpp:237] Iteration 297000, loss = 0.922754
I0521 15:19:24.747851  1271 solver.cpp:253]     Train net output #0: loss = 0.922763 (* 1 = 0.922763 loss)
I0521 15:19:24.747866  1271 sgd_solver.cpp:106] Iteration 297000, lr = 0.002
I0521 15:19:41.685405  1271 solver.cpp:237] Iteration 298500, loss = 1.07037
I0521 15:19:41.685453  1271 solver.cpp:253]     Train net output #0: loss = 1.07038 (* 1 = 1.07038 loss)
I0521 15:19:41.685467  1271 sgd_solver.cpp:106] Iteration 298500, lr = 0.002
I0521 15:19:58.641587  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_300000.caffemodel
I0521 15:19:58.689476  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_300000.solverstate
I0521 15:19:58.717099  1271 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 15:21:19.099966  1271 solver.cpp:409]     Test net output #0: accuracy = 0.89705
I0521 15:21:19.100148  1271 solver.cpp:409]     Test net output #1: loss = 0.333803 (* 1 = 0.333803 loss)
I0521 15:21:40.048429  1271 solver.cpp:237] Iteration 300000, loss = 1.48326
I0521 15:21:40.048482  1271 solver.cpp:253]     Train net output #0: loss = 1.48326 (* 1 = 1.48326 loss)
I0521 15:21:40.048497  1271 sgd_solver.cpp:106] Iteration 300000, lr = 0.002
I0521 15:21:56.675930  1271 solver.cpp:237] Iteration 301500, loss = 0.783895
I0521 15:21:56.676110  1271 solver.cpp:253]     Train net output #0: loss = 0.783905 (* 1 = 0.783905 loss)
I0521 15:21:56.676123  1271 sgd_solver.cpp:106] Iteration 301500, lr = 0.002
I0521 15:22:13.276139  1271 solver.cpp:237] Iteration 303000, loss = 1.41975
I0521 15:22:13.276182  1271 solver.cpp:253]     Train net output #0: loss = 1.41976 (* 1 = 1.41976 loss)
I0521 15:22:13.276199  1271 sgd_solver.cpp:106] Iteration 303000, lr = 0.002
I0521 15:22:29.890375  1271 solver.cpp:237] Iteration 304500, loss = 1.5356
I0521 15:22:29.890547  1271 solver.cpp:253]     Train net output #0: loss = 1.53561 (* 1 = 1.53561 loss)
I0521 15:22:29.890560  1271 sgd_solver.cpp:106] Iteration 304500, lr = 0.002
I0521 15:22:46.521545  1271 solver.cpp:237] Iteration 306000, loss = 0.980065
I0521 15:22:46.521582  1271 solver.cpp:253]     Train net output #0: loss = 0.980074 (* 1 = 0.980074 loss)
I0521 15:22:46.521597  1271 sgd_solver.cpp:106] Iteration 306000, lr = 0.002
I0521 15:23:03.158556  1271 solver.cpp:237] Iteration 307500, loss = 1.37084
I0521 15:23:03.158725  1271 solver.cpp:253]     Train net output #0: loss = 1.37085 (* 1 = 1.37085 loss)
I0521 15:23:03.158740  1271 sgd_solver.cpp:106] Iteration 307500, lr = 0.002
I0521 15:23:19.790523  1271 solver.cpp:237] Iteration 309000, loss = 1.18064
I0521 15:23:19.790573  1271 solver.cpp:253]     Train net output #0: loss = 1.18065 (* 1 = 1.18065 loss)
I0521 15:23:19.790587  1271 sgd_solver.cpp:106] Iteration 309000, lr = 0.002
I0521 15:23:57.272995  1271 solver.cpp:237] Iteration 310500, loss = 0.704646
I0521 15:23:57.273175  1271 solver.cpp:253]     Train net output #0: loss = 0.704655 (* 1 = 0.704655 loss)
I0521 15:23:57.273190  1271 sgd_solver.cpp:106] Iteration 310500, lr = 0.002
I0521 15:24:13.878036  1271 solver.cpp:237] Iteration 312000, loss = 1.52006
I0521 15:24:13.878080  1271 solver.cpp:253]     Train net output #0: loss = 1.52007 (* 1 = 1.52007 loss)
I0521 15:24:13.878094  1271 sgd_solver.cpp:106] Iteration 312000, lr = 0.002
I0521 15:24:30.516692  1271 solver.cpp:237] Iteration 313500, loss = 1.13837
I0521 15:24:30.516872  1271 solver.cpp:253]     Train net output #0: loss = 1.13838 (* 1 = 1.13838 loss)
I0521 15:24:30.516885  1271 sgd_solver.cpp:106] Iteration 313500, lr = 0.002
I0521 15:24:47.119881  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_315000.caffemodel
I0521 15:24:47.452581  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_315000.solverstate
I0521 15:24:47.627528  1271 solver.cpp:237] Iteration 315000, loss = 0.584154
I0521 15:24:47.627571  1271 solver.cpp:253]     Train net output #0: loss = 0.584163 (* 1 = 0.584163 loss)
I0521 15:24:47.627588  1271 sgd_solver.cpp:106] Iteration 315000, lr = 0.002
I0521 15:25:04.454567  1271 solver.cpp:237] Iteration 316500, loss = 1.20671
I0521 15:25:04.454744  1271 solver.cpp:253]     Train net output #0: loss = 1.20672 (* 1 = 1.20672 loss)
I0521 15:25:04.454761  1271 sgd_solver.cpp:106] Iteration 316500, lr = 0.002
I0521 15:25:21.267663  1271 solver.cpp:237] Iteration 318000, loss = 1.30671
I0521 15:25:21.267714  1271 solver.cpp:253]     Train net output #0: loss = 1.30672 (* 1 = 1.30672 loss)
I0521 15:25:21.267727  1271 sgd_solver.cpp:106] Iteration 318000, lr = 0.002
I0521 15:25:38.138875  1271 solver.cpp:237] Iteration 319500, loss = 1.746
I0521 15:25:38.139052  1271 solver.cpp:253]     Train net output #0: loss = 1.74601 (* 1 = 1.74601 loss)
I0521 15:25:38.139066  1271 sgd_solver.cpp:106] Iteration 319500, lr = 0.002
I0521 15:26:15.871727  1271 solver.cpp:237] Iteration 321000, loss = 1.72774
I0521 15:26:15.871904  1271 solver.cpp:253]     Train net output #0: loss = 1.72775 (* 1 = 1.72775 loss)
I0521 15:26:15.871919  1271 sgd_solver.cpp:106] Iteration 321000, lr = 0.002
I0521 15:26:32.752490  1271 solver.cpp:237] Iteration 322500, loss = 0.952062
I0521 15:26:32.752528  1271 solver.cpp:253]     Train net output #0: loss = 0.95207 (* 1 = 0.95207 loss)
I0521 15:26:32.752544  1271 sgd_solver.cpp:106] Iteration 322500, lr = 0.002
I0521 15:26:49.634143  1271 solver.cpp:237] Iteration 324000, loss = 0.513641
I0521 15:26:49.634305  1271 solver.cpp:253]     Train net output #0: loss = 0.513649 (* 1 = 0.513649 loss)
I0521 15:26:49.634320  1271 sgd_solver.cpp:106] Iteration 324000, lr = 0.002
I0521 15:27:06.491794  1271 solver.cpp:237] Iteration 325500, loss = 1.1279
I0521 15:27:06.491838  1271 solver.cpp:253]     Train net output #0: loss = 1.12791 (* 1 = 1.12791 loss)
I0521 15:27:06.491854  1271 sgd_solver.cpp:106] Iteration 325500, lr = 0.002
I0521 15:27:23.381619  1271 solver.cpp:237] Iteration 327000, loss = 1.50156
I0521 15:27:23.381777  1271 solver.cpp:253]     Train net output #0: loss = 1.50157 (* 1 = 1.50157 loss)
I0521 15:27:23.381789  1271 sgd_solver.cpp:106] Iteration 327000, lr = 0.002
I0521 15:27:40.253175  1271 solver.cpp:237] Iteration 328500, loss = 1.7564
I0521 15:27:40.253213  1271 solver.cpp:253]     Train net output #0: loss = 1.7564 (* 1 = 1.7564 loss)
I0521 15:27:40.253229  1271 sgd_solver.cpp:106] Iteration 328500, lr = 0.002
I0521 15:27:57.100730  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_330000.caffemodel
I0521 15:27:57.146981  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_330000.solverstate
I0521 15:27:57.172623  1271 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 15:28:56.251132  1271 solver.cpp:409]     Test net output #0: accuracy = 0.897511
I0521 15:28:56.251308  1271 solver.cpp:409]     Test net output #1: loss = 0.322691 (* 1 = 0.322691 loss)
I0521 15:29:17.142925  1271 solver.cpp:237] Iteration 330000, loss = 1.16005
I0521 15:29:17.142977  1271 solver.cpp:253]     Train net output #0: loss = 1.16006 (* 1 = 1.16006 loss)
I0521 15:29:17.142992  1271 sgd_solver.cpp:106] Iteration 330000, lr = 0.002
I0521 15:29:34.100613  1271 solver.cpp:237] Iteration 331500, loss = 1.41898
I0521 15:29:34.100807  1271 solver.cpp:253]     Train net output #0: loss = 1.41898 (* 1 = 1.41898 loss)
I0521 15:29:34.100821  1271 sgd_solver.cpp:106] Iteration 331500, lr = 0.002
I0521 15:29:51.087606  1271 solver.cpp:237] Iteration 333000, loss = 0.914358
I0521 15:29:51.087643  1271 solver.cpp:253]     Train net output #0: loss = 0.914365 (* 1 = 0.914365 loss)
I0521 15:29:51.087659  1271 sgd_solver.cpp:106] Iteration 333000, lr = 0.002
I0521 15:30:08.064041  1271 solver.cpp:237] Iteration 334500, loss = 1.25703
I0521 15:30:08.064223  1271 solver.cpp:253]     Train net output #0: loss = 1.25703 (* 1 = 1.25703 loss)
I0521 15:30:08.064236  1271 sgd_solver.cpp:106] Iteration 334500, lr = 0.002
I0521 15:30:25.022680  1271 solver.cpp:237] Iteration 336000, loss = 1.25173
I0521 15:30:25.022728  1271 solver.cpp:253]     Train net output #0: loss = 1.25174 (* 1 = 1.25174 loss)
I0521 15:30:25.022744  1271 sgd_solver.cpp:106] Iteration 336000, lr = 0.002
I0521 15:30:41.968943  1271 solver.cpp:237] Iteration 337500, loss = 1.14699
I0521 15:30:41.969105  1271 solver.cpp:253]     Train net output #0: loss = 1.14699 (* 1 = 1.14699 loss)
I0521 15:30:41.969118  1271 sgd_solver.cpp:106] Iteration 337500, lr = 0.002
I0521 15:30:58.942399  1271 solver.cpp:237] Iteration 339000, loss = 0.744912
I0521 15:30:58.942446  1271 solver.cpp:253]     Train net output #0: loss = 0.74492 (* 1 = 0.74492 loss)
I0521 15:30:58.942461  1271 sgd_solver.cpp:106] Iteration 339000, lr = 0.002
I0521 15:31:36.829774  1271 solver.cpp:237] Iteration 340500, loss = 1.12636
I0521 15:31:36.829955  1271 solver.cpp:253]     Train net output #0: loss = 1.12637 (* 1 = 1.12637 loss)
I0521 15:31:36.829969  1271 sgd_solver.cpp:106] Iteration 340500, lr = 0.002
I0521 15:31:53.782606  1271 solver.cpp:237] Iteration 342000, loss = 1.21842
I0521 15:31:53.782644  1271 solver.cpp:253]     Train net output #0: loss = 1.21843 (* 1 = 1.21843 loss)
I0521 15:31:53.782660  1271 sgd_solver.cpp:106] Iteration 342000, lr = 0.002
I0521 15:32:10.700791  1271 solver.cpp:237] Iteration 343500, loss = 1.37589
I0521 15:32:10.700966  1271 solver.cpp:253]     Train net output #0: loss = 1.3759 (* 1 = 1.3759 loss)
I0521 15:32:10.700980  1271 sgd_solver.cpp:106] Iteration 343500, lr = 0.002
I0521 15:32:27.637308  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_345000.caffemodel
I0521 15:32:27.683794  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_345000.solverstate
I0521 15:32:27.712695  1271 solver.cpp:237] Iteration 345000, loss = 0.883615
I0521 15:32:27.712741  1271 solver.cpp:253]     Train net output #0: loss = 0.883622 (* 1 = 0.883622 loss)
I0521 15:32:27.712755  1271 sgd_solver.cpp:106] Iteration 345000, lr = 0.002
I0521 15:32:44.663012  1271 solver.cpp:237] Iteration 346500, loss = 1.19312
I0521 15:32:44.663177  1271 solver.cpp:253]     Train net output #0: loss = 1.19313 (* 1 = 1.19313 loss)
I0521 15:32:44.663192  1271 sgd_solver.cpp:106] Iteration 346500, lr = 0.002
I0521 15:33:01.606657  1271 solver.cpp:237] Iteration 348000, loss = 0.860004
I0521 15:33:01.606709  1271 solver.cpp:253]     Train net output #0: loss = 0.860011 (* 1 = 0.860011 loss)
I0521 15:33:01.606722  1271 sgd_solver.cpp:106] Iteration 348000, lr = 0.002
I0521 15:33:18.560715  1271 solver.cpp:237] Iteration 349500, loss = 1.16988
I0521 15:33:18.560892  1271 solver.cpp:253]     Train net output #0: loss = 1.16989 (* 1 = 1.16989 loss)
I0521 15:33:18.560906  1271 sgd_solver.cpp:106] Iteration 349500, lr = 0.002
I0521 15:33:56.450222  1271 solver.cpp:237] Iteration 351000, loss = 1.19772
I0521 15:33:56.450412  1271 solver.cpp:253]     Train net output #0: loss = 1.19773 (* 1 = 1.19773 loss)
I0521 15:33:56.450426  1271 sgd_solver.cpp:106] Iteration 351000, lr = 0.002
I0521 15:34:13.381531  1271 solver.cpp:237] Iteration 352500, loss = 1.23255
I0521 15:34:13.381574  1271 solver.cpp:253]     Train net output #0: loss = 1.23256 (* 1 = 1.23256 loss)
I0521 15:34:13.381590  1271 sgd_solver.cpp:106] Iteration 352500, lr = 0.002
I0521 15:34:30.338362  1271 solver.cpp:237] Iteration 354000, loss = 1.48257
I0521 15:34:30.338538  1271 solver.cpp:253]     Train net output #0: loss = 1.48258 (* 1 = 1.48258 loss)
I0521 15:34:30.338553  1271 sgd_solver.cpp:106] Iteration 354000, lr = 0.002
I0521 15:34:47.284523  1271 solver.cpp:237] Iteration 355500, loss = 0.817382
I0521 15:34:47.284559  1271 solver.cpp:253]     Train net output #0: loss = 0.817389 (* 1 = 0.817389 loss)
I0521 15:34:47.284572  1271 sgd_solver.cpp:106] Iteration 355500, lr = 0.002
I0521 15:35:04.252837  1271 solver.cpp:237] Iteration 357000, loss = 1.77713
I0521 15:35:04.253012  1271 solver.cpp:253]     Train net output #0: loss = 1.77713 (* 1 = 1.77713 loss)
I0521 15:35:04.253026  1271 sgd_solver.cpp:106] Iteration 357000, lr = 0.002
I0521 15:35:21.201845  1271 solver.cpp:237] Iteration 358500, loss = 1.27155
I0521 15:35:21.201885  1271 solver.cpp:253]     Train net output #0: loss = 1.27156 (* 1 = 1.27156 loss)
I0521 15:35:21.201906  1271 sgd_solver.cpp:106] Iteration 358500, lr = 0.002
I0521 15:35:38.151278  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_360000.caffemodel
I0521 15:35:38.197557  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_360000.solverstate
I0521 15:35:38.223062  1271 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 15:36:58.609068  1271 solver.cpp:409]     Test net output #0: accuracy = 0.891458
I0521 15:36:58.609237  1271 solver.cpp:409]     Test net output #1: loss = 0.362548 (* 1 = 0.362548 loss)
I0521 15:37:19.522490  1271 solver.cpp:237] Iteration 360000, loss = 1.55687
I0521 15:37:19.522544  1271 solver.cpp:253]     Train net output #0: loss = 1.55687 (* 1 = 1.55687 loss)
I0521 15:37:19.522559  1271 sgd_solver.cpp:106] Iteration 360000, lr = 0.002
I0521 15:37:36.376426  1271 solver.cpp:237] Iteration 361500, loss = 0.773938
I0521 15:37:36.376602  1271 solver.cpp:253]     Train net output #0: loss = 0.773945 (* 1 = 0.773945 loss)
I0521 15:37:36.376616  1271 sgd_solver.cpp:106] Iteration 361500, lr = 0.002
I0521 15:37:53.208896  1271 solver.cpp:237] Iteration 363000, loss = 0.829701
I0521 15:37:53.208947  1271 solver.cpp:253]     Train net output #0: loss = 0.829708 (* 1 = 0.829708 loss)
I0521 15:37:53.208961  1271 sgd_solver.cpp:106] Iteration 363000, lr = 0.002
I0521 15:38:10.063331  1271 solver.cpp:237] Iteration 364500, loss = 1.37428
I0521 15:38:10.063494  1271 solver.cpp:253]     Train net output #0: loss = 1.37429 (* 1 = 1.37429 loss)
I0521 15:38:10.063508  1271 sgd_solver.cpp:106] Iteration 364500, lr = 0.002
I0521 15:38:26.868425  1271 solver.cpp:237] Iteration 366000, loss = 1.10078
I0521 15:38:26.868474  1271 solver.cpp:253]     Train net output #0: loss = 1.10078 (* 1 = 1.10078 loss)
I0521 15:38:26.868489  1271 sgd_solver.cpp:106] Iteration 366000, lr = 0.002
I0521 15:38:43.738544  1271 solver.cpp:237] Iteration 367500, loss = 1.21643
I0521 15:38:43.738716  1271 solver.cpp:253]     Train net output #0: loss = 1.21644 (* 1 = 1.21644 loss)
I0521 15:38:43.738730  1271 sgd_solver.cpp:106] Iteration 367500, lr = 0.002
I0521 15:39:00.673945  1271 solver.cpp:237] Iteration 369000, loss = 1.24012
I0521 15:39:00.673982  1271 solver.cpp:253]     Train net output #0: loss = 1.24013 (* 1 = 1.24013 loss)
I0521 15:39:00.673996  1271 sgd_solver.cpp:106] Iteration 369000, lr = 0.002
I0521 15:39:38.473042  1271 solver.cpp:237] Iteration 370500, loss = 1.29601
I0521 15:39:38.473237  1271 solver.cpp:253]     Train net output #0: loss = 1.29602 (* 1 = 1.29602 loss)
I0521 15:39:38.473250  1271 sgd_solver.cpp:106] Iteration 370500, lr = 0.002
I0521 15:39:55.303475  1271 solver.cpp:237] Iteration 372000, loss = 0.987085
I0521 15:39:55.303522  1271 solver.cpp:253]     Train net output #0: loss = 0.987094 (* 1 = 0.987094 loss)
I0521 15:39:55.303537  1271 sgd_solver.cpp:106] Iteration 372000, lr = 0.002
I0521 15:40:12.154242  1271 solver.cpp:237] Iteration 373500, loss = 1.6148
I0521 15:40:12.154405  1271 solver.cpp:253]     Train net output #0: loss = 1.6148 (* 1 = 1.6148 loss)
I0521 15:40:12.154419  1271 sgd_solver.cpp:106] Iteration 373500, lr = 0.002
I0521 15:40:28.928511  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_375000.caffemodel
I0521 15:40:28.975997  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_375000.solverstate
I0521 15:40:29.006530  1271 solver.cpp:237] Iteration 375000, loss = 1.00754
I0521 15:40:29.006577  1271 solver.cpp:253]     Train net output #0: loss = 1.00755 (* 1 = 1.00755 loss)
I0521 15:40:29.006592  1271 sgd_solver.cpp:106] Iteration 375000, lr = 0.002
I0521 15:40:45.751091  1271 solver.cpp:237] Iteration 376500, loss = 1.29489
I0521 15:40:45.751269  1271 solver.cpp:253]     Train net output #0: loss = 1.2949 (* 1 = 1.2949 loss)
I0521 15:40:45.751283  1271 sgd_solver.cpp:106] Iteration 376500, lr = 0.002
I0521 15:41:02.550571  1271 solver.cpp:237] Iteration 378000, loss = 0.975703
I0521 15:41:02.550607  1271 solver.cpp:253]     Train net output #0: loss = 0.97571 (* 1 = 0.97571 loss)
I0521 15:41:02.550623  1271 sgd_solver.cpp:106] Iteration 378000, lr = 0.002
I0521 15:41:19.493818  1271 solver.cpp:237] Iteration 379500, loss = 0.610293
I0521 15:41:19.493996  1271 solver.cpp:253]     Train net output #0: loss = 0.610301 (* 1 = 0.610301 loss)
I0521 15:41:19.494014  1271 sgd_solver.cpp:106] Iteration 379500, lr = 0.002
I0521 15:41:57.419325  1271 solver.cpp:237] Iteration 381000, loss = 0.815111
I0521 15:41:57.419507  1271 solver.cpp:253]     Train net output #0: loss = 0.815118 (* 1 = 0.815118 loss)
I0521 15:41:57.419522  1271 sgd_solver.cpp:106] Iteration 381000, lr = 0.002
I0521 15:42:14.484361  1271 solver.cpp:237] Iteration 382500, loss = 1.39796
I0521 15:42:14.484408  1271 solver.cpp:253]     Train net output #0: loss = 1.39797 (* 1 = 1.39797 loss)
I0521 15:42:14.484422  1271 sgd_solver.cpp:106] Iteration 382500, lr = 0.002
I0521 15:42:31.498322  1271 solver.cpp:237] Iteration 384000, loss = 1.35188
I0521 15:42:31.498495  1271 solver.cpp:253]     Train net output #0: loss = 1.35189 (* 1 = 1.35189 loss)
I0521 15:42:31.498509  1271 sgd_solver.cpp:106] Iteration 384000, lr = 0.002
I0521 15:42:48.493574  1271 solver.cpp:237] Iteration 385500, loss = 1.02668
I0521 15:42:48.493625  1271 solver.cpp:253]     Train net output #0: loss = 1.02669 (* 1 = 1.02669 loss)
I0521 15:42:48.493639  1271 sgd_solver.cpp:106] Iteration 385500, lr = 0.002
I0521 15:43:05.505723  1271 solver.cpp:237] Iteration 387000, loss = 0.499251
I0521 15:43:05.505889  1271 solver.cpp:253]     Train net output #0: loss = 0.499259 (* 1 = 0.499259 loss)
I0521 15:43:05.505903  1271 sgd_solver.cpp:106] Iteration 387000, lr = 0.002
I0521 15:43:22.521214  1271 solver.cpp:237] Iteration 388500, loss = 0.455976
I0521 15:43:22.521263  1271 solver.cpp:253]     Train net output #0: loss = 0.455984 (* 1 = 0.455984 loss)
I0521 15:43:22.521277  1271 sgd_solver.cpp:106] Iteration 388500, lr = 0.002
I0521 15:43:39.506575  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_390000.caffemodel
I0521 15:43:39.562819  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_390000.solverstate
I0521 15:43:39.588281  1271 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 15:44:39.304134  1271 solver.cpp:409]     Test net output #0: accuracy = 0.897866
I0521 15:44:39.304316  1271 solver.cpp:409]     Test net output #1: loss = 0.335877 (* 1 = 0.335877 loss)
I0521 15:45:00.186425  1271 solver.cpp:237] Iteration 390000, loss = 0.760298
I0521 15:45:00.186480  1271 solver.cpp:253]     Train net output #0: loss = 0.760305 (* 1 = 0.760305 loss)
I0521 15:45:00.186496  1271 sgd_solver.cpp:106] Iteration 390000, lr = 0.002
I0521 15:45:16.840343  1271 solver.cpp:237] Iteration 391500, loss = 0.538154
I0521 15:45:16.840523  1271 solver.cpp:253]     Train net output #0: loss = 0.538161 (* 1 = 0.538161 loss)
I0521 15:45:16.840535  1271 sgd_solver.cpp:106] Iteration 391500, lr = 0.002
I0521 15:45:33.466334  1271 solver.cpp:237] Iteration 393000, loss = 1.77101
I0521 15:45:33.466380  1271 solver.cpp:253]     Train net output #0: loss = 1.77101 (* 1 = 1.77101 loss)
I0521 15:45:33.466394  1271 sgd_solver.cpp:106] Iteration 393000, lr = 0.002
I0521 15:45:50.080536  1271 solver.cpp:237] Iteration 394500, loss = 1.5398
I0521 15:45:50.080704  1271 solver.cpp:253]     Train net output #0: loss = 1.53981 (* 1 = 1.53981 loss)
I0521 15:45:50.080718  1271 sgd_solver.cpp:106] Iteration 394500, lr = 0.002
I0521 15:46:06.675609  1271 solver.cpp:237] Iteration 396000, loss = 1.23784
I0521 15:46:06.675645  1271 solver.cpp:253]     Train net output #0: loss = 1.23785 (* 1 = 1.23785 loss)
I0521 15:46:06.675659  1271 sgd_solver.cpp:106] Iteration 396000, lr = 0.002
I0521 15:46:23.294430  1271 solver.cpp:237] Iteration 397500, loss = 0.984833
I0521 15:46:23.294601  1271 solver.cpp:253]     Train net output #0: loss = 0.984839 (* 1 = 0.984839 loss)
I0521 15:46:23.294615  1271 sgd_solver.cpp:106] Iteration 397500, lr = 0.002
I0521 15:46:39.928714  1271 solver.cpp:237] Iteration 399000, loss = 0.498283
I0521 15:46:39.928757  1271 solver.cpp:253]     Train net output #0: loss = 0.498289 (* 1 = 0.498289 loss)
I0521 15:46:39.928774  1271 sgd_solver.cpp:106] Iteration 399000, lr = 0.002
I0521 15:47:17.401407  1271 solver.cpp:237] Iteration 400500, loss = 1.17252
I0521 15:47:17.401590  1271 solver.cpp:253]     Train net output #0: loss = 1.17253 (* 1 = 1.17253 loss)
I0521 15:47:17.401604  1271 sgd_solver.cpp:106] Iteration 400500, lr = 0.002
I0521 15:47:34.023545  1271 solver.cpp:237] Iteration 402000, loss = 0.958484
I0521 15:47:34.023591  1271 solver.cpp:253]     Train net output #0: loss = 0.95849 (* 1 = 0.95849 loss)
I0521 15:47:34.023604  1271 sgd_solver.cpp:106] Iteration 402000, lr = 0.002
I0521 15:47:50.618896  1271 solver.cpp:237] Iteration 403500, loss = 0.195484
I0521 15:47:50.619082  1271 solver.cpp:253]     Train net output #0: loss = 0.19549 (* 1 = 0.19549 loss)
I0521 15:47:50.619096  1271 sgd_solver.cpp:106] Iteration 403500, lr = 0.002
I0521 15:48:07.213846  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_405000.caffemodel
I0521 15:48:07.259908  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_405000.solverstate
I0521 15:48:07.288379  1271 solver.cpp:237] Iteration 405000, loss = 0.979349
I0521 15:48:07.288421  1271 solver.cpp:253]     Train net output #0: loss = 0.979355 (* 1 = 0.979355 loss)
I0521 15:48:07.288439  1271 sgd_solver.cpp:106] Iteration 405000, lr = 0.002
I0521 15:48:23.940613  1271 solver.cpp:237] Iteration 406500, loss = 1.26559
I0521 15:48:23.940793  1271 solver.cpp:253]     Train net output #0: loss = 1.26559 (* 1 = 1.26559 loss)
I0521 15:48:23.940807  1271 sgd_solver.cpp:106] Iteration 406500, lr = 0.002
I0521 15:48:40.573714  1271 solver.cpp:237] Iteration 408000, loss = 0.93138
I0521 15:48:40.573763  1271 solver.cpp:253]     Train net output #0: loss = 0.931387 (* 1 = 0.931387 loss)
I0521 15:48:40.573777  1271 sgd_solver.cpp:106] Iteration 408000, lr = 0.002
I0521 15:48:57.185401  1271 solver.cpp:237] Iteration 409500, loss = 0.730595
I0521 15:48:57.185580  1271 solver.cpp:253]     Train net output #0: loss = 0.730602 (* 1 = 0.730602 loss)
I0521 15:48:57.185593  1271 sgd_solver.cpp:106] Iteration 409500, lr = 0.002
I0521 15:49:34.663565  1271 solver.cpp:237] Iteration 411000, loss = 1.59094
I0521 15:49:34.663750  1271 solver.cpp:253]     Train net output #0: loss = 1.59094 (* 1 = 1.59094 loss)
I0521 15:49:34.663764  1271 sgd_solver.cpp:106] Iteration 411000, lr = 0.002
I0521 15:49:51.292785  1271 solver.cpp:237] Iteration 412500, loss = 2.69016
I0521 15:49:51.292821  1271 solver.cpp:253]     Train net output #0: loss = 2.69017 (* 1 = 2.69017 loss)
I0521 15:49:51.292835  1271 sgd_solver.cpp:106] Iteration 412500, lr = 0.002
I0521 15:50:07.910915  1271 solver.cpp:237] Iteration 414000, loss = 1.48769
I0521 15:50:07.911088  1271 solver.cpp:253]     Train net output #0: loss = 1.4877 (* 1 = 1.4877 loss)
I0521 15:50:07.911103  1271 sgd_solver.cpp:106] Iteration 414000, lr = 0.002
I0521 15:50:24.541620  1271 solver.cpp:237] Iteration 415500, loss = 1.18028
I0521 15:50:24.541662  1271 solver.cpp:253]     Train net output #0: loss = 1.18028 (* 1 = 1.18028 loss)
I0521 15:50:24.541682  1271 sgd_solver.cpp:106] Iteration 415500, lr = 0.002
I0521 15:50:41.563743  1271 solver.cpp:237] Iteration 417000, loss = 1.17229
I0521 15:50:41.563904  1271 solver.cpp:253]     Train net output #0: loss = 1.1723 (* 1 = 1.1723 loss)
I0521 15:50:41.563917  1271 sgd_solver.cpp:106] Iteration 417000, lr = 0.002
I0521 15:50:58.574980  1271 solver.cpp:237] Iteration 418500, loss = 1.10031
I0521 15:50:58.575028  1271 solver.cpp:253]     Train net output #0: loss = 1.10031 (* 1 = 1.10031 loss)
I0521 15:50:58.575042  1271 sgd_solver.cpp:106] Iteration 418500, lr = 0.002
I0521 15:51:15.596256  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_420000.caffemodel
I0521 15:51:15.642947  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_420000.solverstate
I0521 15:51:15.667908  1271 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 15:52:36.181082  1271 solver.cpp:409]     Test net output #0: accuracy = 0.898651
I0521 15:52:36.181274  1271 solver.cpp:409]     Test net output #1: loss = 0.322541 (* 1 = 0.322541 loss)
I0521 15:52:57.043431  1271 solver.cpp:237] Iteration 420000, loss = 1.51681
I0521 15:52:57.043480  1271 solver.cpp:253]     Train net output #0: loss = 1.51681 (* 1 = 1.51681 loss)
I0521 15:52:57.043498  1271 sgd_solver.cpp:106] Iteration 420000, lr = 0.002
I0521 15:53:13.668679  1271 solver.cpp:237] Iteration 421500, loss = 1.67611
I0521 15:53:13.668850  1271 solver.cpp:253]     Train net output #0: loss = 1.67611 (* 1 = 1.67611 loss)
I0521 15:53:13.668864  1271 sgd_solver.cpp:106] Iteration 421500, lr = 0.002
I0521 15:53:30.278798  1271 solver.cpp:237] Iteration 423000, loss = 0.590938
I0521 15:53:30.278834  1271 solver.cpp:253]     Train net output #0: loss = 0.590945 (* 1 = 0.590945 loss)
I0521 15:53:30.278849  1271 sgd_solver.cpp:106] Iteration 423000, lr = 0.002
I0521 15:53:46.880812  1271 solver.cpp:237] Iteration 424500, loss = 0.786881
I0521 15:53:46.880987  1271 solver.cpp:253]     Train net output #0: loss = 0.786887 (* 1 = 0.786887 loss)
I0521 15:53:46.881000  1271 sgd_solver.cpp:106] Iteration 424500, lr = 0.002
I0521 15:54:03.482084  1271 solver.cpp:237] Iteration 426000, loss = 1.3183
I0521 15:54:03.482125  1271 solver.cpp:253]     Train net output #0: loss = 1.3183 (* 1 = 1.3183 loss)
I0521 15:54:03.482139  1271 sgd_solver.cpp:106] Iteration 426000, lr = 0.002
I0521 15:54:20.082867  1271 solver.cpp:237] Iteration 427500, loss = 1.05339
I0521 15:54:20.083040  1271 solver.cpp:253]     Train net output #0: loss = 1.0534 (* 1 = 1.0534 loss)
I0521 15:54:20.083055  1271 sgd_solver.cpp:106] Iteration 427500, lr = 0.002
I0521 15:54:36.724575  1271 solver.cpp:237] Iteration 429000, loss = 1.0608
I0521 15:54:36.724618  1271 solver.cpp:253]     Train net output #0: loss = 1.0608 (* 1 = 1.0608 loss)
I0521 15:54:36.724632  1271 sgd_solver.cpp:106] Iteration 429000, lr = 0.002
I0521 15:55:14.183929  1271 solver.cpp:237] Iteration 430500, loss = 0.84223
I0521 15:55:14.184128  1271 solver.cpp:253]     Train net output #0: loss = 0.842237 (* 1 = 0.842237 loss)
I0521 15:55:14.184142  1271 sgd_solver.cpp:106] Iteration 430500, lr = 0.002
I0521 15:55:30.810067  1271 solver.cpp:237] Iteration 432000, loss = 1.4553
I0521 15:55:30.810111  1271 solver.cpp:253]     Train net output #0: loss = 1.45531 (* 1 = 1.45531 loss)
I0521 15:55:30.810124  1271 sgd_solver.cpp:106] Iteration 432000, lr = 0.002
I0521 15:55:47.439226  1271 solver.cpp:237] Iteration 433500, loss = 0.663047
I0521 15:55:47.439399  1271 solver.cpp:253]     Train net output #0: loss = 0.663055 (* 1 = 0.663055 loss)
I0521 15:55:47.439412  1271 sgd_solver.cpp:106] Iteration 433500, lr = 0.002
I0521 15:56:04.028553  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_435000.caffemodel
I0521 15:56:04.076304  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_435000.solverstate
I0521 15:56:04.107034  1271 solver.cpp:237] Iteration 435000, loss = 1.09643
I0521 15:56:04.107084  1271 solver.cpp:253]     Train net output #0: loss = 1.09644 (* 1 = 1.09644 loss)
I0521 15:56:04.107098  1271 sgd_solver.cpp:106] Iteration 435000, lr = 0.002
I0521 15:56:20.733517  1271 solver.cpp:237] Iteration 436500, loss = 1.16616
I0521 15:56:20.733700  1271 solver.cpp:253]     Train net output #0: loss = 1.16617 (* 1 = 1.16617 loss)
I0521 15:56:20.733717  1271 sgd_solver.cpp:106] Iteration 436500, lr = 0.002
I0521 15:56:37.333832  1271 solver.cpp:237] Iteration 438000, loss = 1.76725
I0521 15:56:37.333880  1271 solver.cpp:253]     Train net output #0: loss = 1.76726 (* 1 = 1.76726 loss)
I0521 15:56:37.333895  1271 sgd_solver.cpp:106] Iteration 438000, lr = 0.002
I0521 15:56:53.946470  1271 solver.cpp:237] Iteration 439500, loss = 0.919601
I0521 15:56:53.946636  1271 solver.cpp:253]     Train net output #0: loss = 0.919608 (* 1 = 0.919608 loss)
I0521 15:56:53.946650  1271 sgd_solver.cpp:106] Iteration 439500, lr = 0.002
I0521 15:57:31.418815  1271 solver.cpp:237] Iteration 441000, loss = 1.11447
I0521 15:57:31.418997  1271 solver.cpp:253]     Train net output #0: loss = 1.11447 (* 1 = 1.11447 loss)
I0521 15:57:31.419010  1271 sgd_solver.cpp:106] Iteration 441000, lr = 0.002
I0521 15:57:48.050068  1271 solver.cpp:237] Iteration 442500, loss = 1.68683
I0521 15:57:48.050106  1271 solver.cpp:253]     Train net output #0: loss = 1.68684 (* 1 = 1.68684 loss)
I0521 15:57:48.050119  1271 sgd_solver.cpp:106] Iteration 442500, lr = 0.002
I0521 15:58:04.632426  1271 solver.cpp:237] Iteration 444000, loss = 1.52238
I0521 15:58:04.632594  1271 solver.cpp:253]     Train net output #0: loss = 1.52239 (* 1 = 1.52239 loss)
I0521 15:58:04.632608  1271 sgd_solver.cpp:106] Iteration 444000, lr = 0.002
I0521 15:58:21.284468  1271 solver.cpp:237] Iteration 445500, loss = 1.51647
I0521 15:58:21.284517  1271 solver.cpp:253]     Train net output #0: loss = 1.51648 (* 1 = 1.51648 loss)
I0521 15:58:21.284529  1271 sgd_solver.cpp:106] Iteration 445500, lr = 0.002
I0521 15:58:37.930117  1271 solver.cpp:237] Iteration 447000, loss = 1.53399
I0521 15:58:37.930284  1271 solver.cpp:253]     Train net output #0: loss = 1.534 (* 1 = 1.534 loss)
I0521 15:58:37.930299  1271 sgd_solver.cpp:106] Iteration 447000, lr = 0.002
I0521 15:58:54.535076  1271 solver.cpp:237] Iteration 448500, loss = 1.18586
I0521 15:58:54.535118  1271 solver.cpp:253]     Train net output #0: loss = 1.18587 (* 1 = 1.18587 loss)
I0521 15:58:54.535131  1271 sgd_solver.cpp:106] Iteration 448500, lr = 0.002
I0521 15:59:11.141062  1271 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_450000.caffemodel
I0521 15:59:11.188853  1271 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_450000.solverstate
I0521 15:59:11.216363  1271 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 16:00:10.532928  1271 solver.cpp:409]     Test net output #0: accuracy = 0.893488
I0521 16:00:10.533113  1271 solver.cpp:409]     Test net output #1: loss = 0.384366 (* 1 = 0.384366 loss)
I0521 16:00:31.448743  1271 solver.cpp:237] Iteration 450000, loss = 1.13039
I0521 16:00:31.448796  1271 solver.cpp:253]     Train net output #0: loss = 1.13039 (* 1 = 1.13039 loss)
I0521 16:00:31.448810  1271 sgd_solver.cpp:106] Iteration 450000, lr = 0.002
I0521 16:00:48.242674  1271 solver.cpp:237] Iteration 451500, loss = 1.82594
I0521 16:00:48.242858  1271 solver.cpp:253]     Train net output #0: loss = 1.82595 (* 1 = 1.82595 loss)
I0521 16:00:48.242872  1271 sgd_solver.cpp:106] Iteration 451500, lr = 0.002
I0521 16:01:05.042908  1271 solver.cpp:237] Iteration 453000, loss = 1.16583
I0521 16:01:05.042946  1271 solver.cpp:253]     Train net output #0: loss = 1.16583 (* 1 = 1.16583 loss)
I0521 16:01:05.042959  1271 sgd_solver.cpp:106] Iteration 453000, lr = 0.002
=>> PBS: job killed: walltime 7219 exceeded limit 7200
-bash: line 1:   529 Terminated              /var/spool/torque/mom_priv/jobs/2805414.SC
aprun: Apid 11238771: Caught signal Terminated, sending to application
*** Aborted at 1463860875 (unix time) try "date -d @1463860875" if you are using GNU date ***
PC: @     0x2aaab7c73ae0 (unknown)
*** SIGTERM (@0x4f4) received by PID 1271 (TID 0x2aaac746f900) from PID 1268; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab7c73ae0 (unknown)
    @     0x2aaab926d73b (unknown)
    @     0x2aaab9265ac0 (unknown)
    @     0x2aaab92663d3 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11238771: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11238771: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11238771: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
aprun: Apid 11238771: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 02243] [c4-1c0s1n1] [Sat May 21 16:01:17 2016] PE RANK 0 exit signal Terminated
Application 11238771 exit codes: 143
Application 11238771 resources: utime ~6328s, stime ~882s, Rss ~5332164, inblocks ~10476612, outblocks ~474916
