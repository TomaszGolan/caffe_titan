2811432
I0526 09:05:04.412807 26882 caffe.cpp:184] Using GPUs 0
I0526 09:05:04.844090 26882 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.004
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393.prototxt"
I0526 09:05:04.881767 26882 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393.prototxt
I0526 09:05:04.920742 26882 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 09:05:04.920814 26882 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 09:05:04.921203 26882 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 09:05:04.921413 26882 layer_factory.hpp:77] Creating layer data_hdf5
I0526 09:05:04.921450 26882 net.cpp:106] Creating Layer data_hdf5
I0526 09:05:04.921469 26882 net.cpp:411] data_hdf5 -> data
I0526 09:05:04.921504 26882 net.cpp:411] data_hdf5 -> label
I0526 09:05:04.921546 26882 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 09:05:04.961423 26882 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 09:05:04.994482 26882 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 09:05:26.596474 26882 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 09:05:26.603510 26882 net.cpp:150] Setting up data_hdf5
I0526 09:05:26.603560 26882 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 09:05:26.603577 26882 net.cpp:157] Top shape: 10 (10)
I0526 09:05:26.603590 26882 net.cpp:165] Memory required for data: 254040
I0526 09:05:26.603610 26882 layer_factory.hpp:77] Creating layer conv1
I0526 09:05:26.603657 26882 net.cpp:106] Creating Layer conv1
I0526 09:05:26.603672 26882 net.cpp:454] conv1 <- data
I0526 09:05:26.603708 26882 net.cpp:411] conv1 -> conv1
I0526 09:05:29.568410 26882 net.cpp:150] Setting up conv1
I0526 09:05:29.568462 26882 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 09:05:29.568477 26882 net.cpp:165] Memory required for data: 3018840
I0526 09:05:29.568508 26882 layer_factory.hpp:77] Creating layer relu1
I0526 09:05:29.568531 26882 net.cpp:106] Creating Layer relu1
I0526 09:05:29.568552 26882 net.cpp:454] relu1 <- conv1
I0526 09:05:29.568588 26882 net.cpp:397] relu1 -> conv1 (in-place)
I0526 09:05:29.569123 26882 net.cpp:150] Setting up relu1
I0526 09:05:29.569147 26882 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 09:05:29.569161 26882 net.cpp:165] Memory required for data: 5783640
I0526 09:05:29.569177 26882 layer_factory.hpp:77] Creating layer pool1
I0526 09:05:29.569205 26882 net.cpp:106] Creating Layer pool1
I0526 09:05:29.569219 26882 net.cpp:454] pool1 <- conv1
I0526 09:05:29.569236 26882 net.cpp:411] pool1 -> pool1
I0526 09:05:29.569329 26882 net.cpp:150] Setting up pool1
I0526 09:05:29.569346 26882 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 09:05:29.569361 26882 net.cpp:165] Memory required for data: 7166040
I0526 09:05:29.569381 26882 layer_factory.hpp:77] Creating layer conv2
I0526 09:05:29.569404 26882 net.cpp:106] Creating Layer conv2
I0526 09:05:29.569425 26882 net.cpp:454] conv2 <- pool1
I0526 09:05:29.569442 26882 net.cpp:411] conv2 -> conv2
I0526 09:05:29.572163 26882 net.cpp:150] Setting up conv2
I0526 09:05:29.572194 26882 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 09:05:29.572211 26882 net.cpp:165] Memory required for data: 9153240
I0526 09:05:29.572232 26882 layer_factory.hpp:77] Creating layer relu2
I0526 09:05:29.572265 26882 net.cpp:106] Creating Layer relu2
I0526 09:05:29.572279 26882 net.cpp:454] relu2 <- conv2
I0526 09:05:29.572295 26882 net.cpp:397] relu2 -> conv2 (in-place)
I0526 09:05:29.572654 26882 net.cpp:150] Setting up relu2
I0526 09:05:29.572674 26882 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 09:05:29.572686 26882 net.cpp:165] Memory required for data: 11140440
I0526 09:05:29.572701 26882 layer_factory.hpp:77] Creating layer pool2
I0526 09:05:29.572723 26882 net.cpp:106] Creating Layer pool2
I0526 09:05:29.572737 26882 net.cpp:454] pool2 <- conv2
I0526 09:05:29.572753 26882 net.cpp:411] pool2 -> pool2
I0526 09:05:29.572849 26882 net.cpp:150] Setting up pool2
I0526 09:05:29.572867 26882 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 09:05:29.572881 26882 net.cpp:165] Memory required for data: 12134040
I0526 09:05:29.572902 26882 layer_factory.hpp:77] Creating layer conv3
I0526 09:05:29.572922 26882 net.cpp:106] Creating Layer conv3
I0526 09:05:29.572942 26882 net.cpp:454] conv3 <- pool2
I0526 09:05:29.572958 26882 net.cpp:411] conv3 -> conv3
I0526 09:05:29.575091 26882 net.cpp:150] Setting up conv3
I0526 09:05:29.575120 26882 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 09:05:29.575134 26882 net.cpp:165] Memory required for data: 13218200
I0526 09:05:29.575160 26882 layer_factory.hpp:77] Creating layer relu3
I0526 09:05:29.575188 26882 net.cpp:106] Creating Layer relu3
I0526 09:05:29.575201 26882 net.cpp:454] relu3 <- conv3
I0526 09:05:29.575217 26882 net.cpp:397] relu3 -> conv3 (in-place)
I0526 09:05:29.575712 26882 net.cpp:150] Setting up relu3
I0526 09:05:29.575738 26882 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 09:05:29.575752 26882 net.cpp:165] Memory required for data: 14302360
I0526 09:05:29.575768 26882 layer_factory.hpp:77] Creating layer pool3
I0526 09:05:29.575791 26882 net.cpp:106] Creating Layer pool3
I0526 09:05:29.575805 26882 net.cpp:454] pool3 <- conv3
I0526 09:05:29.575820 26882 net.cpp:411] pool3 -> pool3
I0526 09:05:29.575902 26882 net.cpp:150] Setting up pool3
I0526 09:05:29.575919 26882 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 09:05:29.575933 26882 net.cpp:165] Memory required for data: 14844440
I0526 09:05:29.575947 26882 layer_factory.hpp:77] Creating layer conv4
I0526 09:05:29.575973 26882 net.cpp:106] Creating Layer conv4
I0526 09:05:29.575985 26882 net.cpp:454] conv4 <- pool3
I0526 09:05:29.576002 26882 net.cpp:411] conv4 -> conv4
I0526 09:05:29.578747 26882 net.cpp:150] Setting up conv4
I0526 09:05:29.578778 26882 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 09:05:29.578793 26882 net.cpp:165] Memory required for data: 15207320
I0526 09:05:29.578812 26882 layer_factory.hpp:77] Creating layer relu4
I0526 09:05:29.578833 26882 net.cpp:106] Creating Layer relu4
I0526 09:05:29.578860 26882 net.cpp:454] relu4 <- conv4
I0526 09:05:29.578876 26882 net.cpp:397] relu4 -> conv4 (in-place)
I0526 09:05:29.579371 26882 net.cpp:150] Setting up relu4
I0526 09:05:29.579394 26882 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 09:05:29.579408 26882 net.cpp:165] Memory required for data: 15570200
I0526 09:05:29.579423 26882 layer_factory.hpp:77] Creating layer pool4
I0526 09:05:29.579447 26882 net.cpp:106] Creating Layer pool4
I0526 09:05:29.579462 26882 net.cpp:454] pool4 <- conv4
I0526 09:05:29.579478 26882 net.cpp:411] pool4 -> pool4
I0526 09:05:29.579561 26882 net.cpp:150] Setting up pool4
I0526 09:05:29.579583 26882 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 09:05:29.579596 26882 net.cpp:165] Memory required for data: 15751640
I0526 09:05:29.579612 26882 layer_factory.hpp:77] Creating layer ip1
I0526 09:05:29.579632 26882 net.cpp:106] Creating Layer ip1
I0526 09:05:29.579653 26882 net.cpp:454] ip1 <- pool4
I0526 09:05:29.579668 26882 net.cpp:411] ip1 -> ip1
I0526 09:05:29.595057 26882 net.cpp:150] Setting up ip1
I0526 09:05:29.595089 26882 net.cpp:157] Top shape: 10 196 (1960)
I0526 09:05:29.595110 26882 net.cpp:165] Memory required for data: 15759480
I0526 09:05:29.595136 26882 layer_factory.hpp:77] Creating layer relu5
I0526 09:05:29.595157 26882 net.cpp:106] Creating Layer relu5
I0526 09:05:29.595170 26882 net.cpp:454] relu5 <- ip1
I0526 09:05:29.595197 26882 net.cpp:397] relu5 -> ip1 (in-place)
I0526 09:05:29.595558 26882 net.cpp:150] Setting up relu5
I0526 09:05:29.595578 26882 net.cpp:157] Top shape: 10 196 (1960)
I0526 09:05:29.595592 26882 net.cpp:165] Memory required for data: 15767320
I0526 09:05:29.595607 26882 layer_factory.hpp:77] Creating layer drop1
I0526 09:05:29.595636 26882 net.cpp:106] Creating Layer drop1
I0526 09:05:29.595649 26882 net.cpp:454] drop1 <- ip1
I0526 09:05:29.595665 26882 net.cpp:397] drop1 -> ip1 (in-place)
I0526 09:05:29.595738 26882 net.cpp:150] Setting up drop1
I0526 09:05:29.595755 26882 net.cpp:157] Top shape: 10 196 (1960)
I0526 09:05:29.595767 26882 net.cpp:165] Memory required for data: 15775160
I0526 09:05:29.595782 26882 layer_factory.hpp:77] Creating layer ip2
I0526 09:05:29.595803 26882 net.cpp:106] Creating Layer ip2
I0526 09:05:29.595815 26882 net.cpp:454] ip2 <- ip1
I0526 09:05:29.595839 26882 net.cpp:411] ip2 -> ip2
I0526 09:05:29.596328 26882 net.cpp:150] Setting up ip2
I0526 09:05:29.596348 26882 net.cpp:157] Top shape: 10 98 (980)
I0526 09:05:29.596360 26882 net.cpp:165] Memory required for data: 15779080
I0526 09:05:29.596381 26882 layer_factory.hpp:77] Creating layer relu6
I0526 09:05:29.596403 26882 net.cpp:106] Creating Layer relu6
I0526 09:05:29.596416 26882 net.cpp:454] relu6 <- ip2
I0526 09:05:29.596432 26882 net.cpp:397] relu6 -> ip2 (in-place)
I0526 09:05:29.596984 26882 net.cpp:150] Setting up relu6
I0526 09:05:29.597008 26882 net.cpp:157] Top shape: 10 98 (980)
I0526 09:05:29.597021 26882 net.cpp:165] Memory required for data: 15783000
I0526 09:05:29.597038 26882 layer_factory.hpp:77] Creating layer drop2
I0526 09:05:29.597059 26882 net.cpp:106] Creating Layer drop2
I0526 09:05:29.597074 26882 net.cpp:454] drop2 <- ip2
I0526 09:05:29.597090 26882 net.cpp:397] drop2 -> ip2 (in-place)
I0526 09:05:29.597138 26882 net.cpp:150] Setting up drop2
I0526 09:05:29.597162 26882 net.cpp:157] Top shape: 10 98 (980)
I0526 09:05:29.597174 26882 net.cpp:165] Memory required for data: 15786920
I0526 09:05:29.597187 26882 layer_factory.hpp:77] Creating layer ip3
I0526 09:05:29.597203 26882 net.cpp:106] Creating Layer ip3
I0526 09:05:29.597218 26882 net.cpp:454] ip3 <- ip2
I0526 09:05:29.597240 26882 net.cpp:411] ip3 -> ip3
I0526 09:05:29.597463 26882 net.cpp:150] Setting up ip3
I0526 09:05:29.597482 26882 net.cpp:157] Top shape: 10 11 (110)
I0526 09:05:29.597496 26882 net.cpp:165] Memory required for data: 15787360
I0526 09:05:29.597515 26882 layer_factory.hpp:77] Creating layer drop3
I0526 09:05:29.597538 26882 net.cpp:106] Creating Layer drop3
I0526 09:05:29.597551 26882 net.cpp:454] drop3 <- ip3
I0526 09:05:29.597566 26882 net.cpp:397] drop3 -> ip3 (in-place)
I0526 09:05:29.597636 26882 net.cpp:150] Setting up drop3
I0526 09:05:29.597651 26882 net.cpp:157] Top shape: 10 11 (110)
I0526 09:05:29.597671 26882 net.cpp:165] Memory required for data: 15787800
I0526 09:05:29.597683 26882 layer_factory.hpp:77] Creating layer loss
I0526 09:05:29.597707 26882 net.cpp:106] Creating Layer loss
I0526 09:05:29.597725 26882 net.cpp:454] loss <- ip3
I0526 09:05:29.597740 26882 net.cpp:454] loss <- label
I0526 09:05:29.597755 26882 net.cpp:411] loss -> loss
I0526 09:05:29.597775 26882 layer_factory.hpp:77] Creating layer loss
I0526 09:05:29.598441 26882 net.cpp:150] Setting up loss
I0526 09:05:29.598464 26882 net.cpp:157] Top shape: (1)
I0526 09:05:29.598487 26882 net.cpp:160]     with loss weight 1
I0526 09:05:29.598539 26882 net.cpp:165] Memory required for data: 15787804
I0526 09:05:29.598562 26882 net.cpp:226] loss needs backward computation.
I0526 09:05:29.598577 26882 net.cpp:226] drop3 needs backward computation.
I0526 09:05:29.598589 26882 net.cpp:226] ip3 needs backward computation.
I0526 09:05:29.598603 26882 net.cpp:226] drop2 needs backward computation.
I0526 09:05:29.598615 26882 net.cpp:226] relu6 needs backward computation.
I0526 09:05:29.598629 26882 net.cpp:226] ip2 needs backward computation.
I0526 09:05:29.598649 26882 net.cpp:226] drop1 needs backward computation.
I0526 09:05:29.598662 26882 net.cpp:226] relu5 needs backward computation.
I0526 09:05:29.598675 26882 net.cpp:226] ip1 needs backward computation.
I0526 09:05:29.598690 26882 net.cpp:226] pool4 needs backward computation.
I0526 09:05:29.598704 26882 net.cpp:226] relu4 needs backward computation.
I0526 09:05:29.598716 26882 net.cpp:226] conv4 needs backward computation.
I0526 09:05:29.598731 26882 net.cpp:226] pool3 needs backward computation.
I0526 09:05:29.598743 26882 net.cpp:226] relu3 needs backward computation.
I0526 09:05:29.598765 26882 net.cpp:226] conv3 needs backward computation.
I0526 09:05:29.598793 26882 net.cpp:226] pool2 needs backward computation.
I0526 09:05:29.598806 26882 net.cpp:226] relu2 needs backward computation.
I0526 09:05:29.598819 26882 net.cpp:226] conv2 needs backward computation.
I0526 09:05:29.598834 26882 net.cpp:226] pool1 needs backward computation.
I0526 09:05:29.598847 26882 net.cpp:226] relu1 needs backward computation.
I0526 09:05:29.598860 26882 net.cpp:226] conv1 needs backward computation.
I0526 09:05:29.598881 26882 net.cpp:228] data_hdf5 does not need backward computation.
I0526 09:05:29.598896 26882 net.cpp:270] This network produces output loss
I0526 09:05:29.598923 26882 net.cpp:283] Network initialization done.
I0526 09:05:29.617792 26882 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393.prototxt
I0526 09:05:29.617879 26882 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 09:05:29.618264 26882 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 09:05:29.618494 26882 layer_factory.hpp:77] Creating layer data_hdf5
I0526 09:05:29.618515 26882 net.cpp:106] Creating Layer data_hdf5
I0526 09:05:29.618532 26882 net.cpp:411] data_hdf5 -> data
I0526 09:05:29.618556 26882 net.cpp:411] data_hdf5 -> label
I0526 09:05:29.618573 26882 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 09:05:29.638780 26882 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 09:05:51.089112 26882 net.cpp:150] Setting up data_hdf5
I0526 09:05:51.089285 26882 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 09:05:51.089311 26882 net.cpp:157] Top shape: 10 (10)
I0526 09:05:51.089324 26882 net.cpp:165] Memory required for data: 254040
I0526 09:05:51.089340 26882 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 09:05:51.089368 26882 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 09:05:51.089387 26882 net.cpp:454] label_data_hdf5_1_split <- label
I0526 09:05:51.089423 26882 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 09:05:51.089447 26882 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 09:05:51.089526 26882 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 09:05:51.089550 26882 net.cpp:157] Top shape: 10 (10)
I0526 09:05:51.089565 26882 net.cpp:157] Top shape: 10 (10)
I0526 09:05:51.089578 26882 net.cpp:165] Memory required for data: 254120
I0526 09:05:51.089597 26882 layer_factory.hpp:77] Creating layer conv1
I0526 09:05:51.089632 26882 net.cpp:106] Creating Layer conv1
I0526 09:05:51.089651 26882 net.cpp:454] conv1 <- data
I0526 09:05:51.089671 26882 net.cpp:411] conv1 -> conv1
I0526 09:05:51.091631 26882 net.cpp:150] Setting up conv1
I0526 09:05:51.091657 26882 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 09:05:51.091677 26882 net.cpp:165] Memory required for data: 3018920
I0526 09:05:51.091701 26882 layer_factory.hpp:77] Creating layer relu1
I0526 09:05:51.091722 26882 net.cpp:106] Creating Layer relu1
I0526 09:05:51.091735 26882 net.cpp:454] relu1 <- conv1
I0526 09:05:51.091763 26882 net.cpp:397] relu1 -> conv1 (in-place)
I0526 09:05:51.092288 26882 net.cpp:150] Setting up relu1
I0526 09:05:51.092311 26882 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 09:05:51.092324 26882 net.cpp:165] Memory required for data: 5783720
I0526 09:05:51.092337 26882 layer_factory.hpp:77] Creating layer pool1
I0526 09:05:51.092360 26882 net.cpp:106] Creating Layer pool1
I0526 09:05:51.092381 26882 net.cpp:454] pool1 <- conv1
I0526 09:05:51.092397 26882 net.cpp:411] pool1 -> pool1
I0526 09:05:51.092494 26882 net.cpp:150] Setting up pool1
I0526 09:05:51.092510 26882 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 09:05:51.092524 26882 net.cpp:165] Memory required for data: 7166120
I0526 09:05:51.092538 26882 layer_factory.hpp:77] Creating layer conv2
I0526 09:05:51.092566 26882 net.cpp:106] Creating Layer conv2
I0526 09:05:51.092578 26882 net.cpp:454] conv2 <- pool1
I0526 09:05:51.092595 26882 net.cpp:411] conv2 -> conv2
I0526 09:05:51.094552 26882 net.cpp:150] Setting up conv2
I0526 09:05:51.094576 26882 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 09:05:51.094596 26882 net.cpp:165] Memory required for data: 9153320
I0526 09:05:51.094619 26882 layer_factory.hpp:77] Creating layer relu2
I0526 09:05:51.094638 26882 net.cpp:106] Creating Layer relu2
I0526 09:05:51.094660 26882 net.cpp:454] relu2 <- conv2
I0526 09:05:51.094676 26882 net.cpp:397] relu2 -> conv2 (in-place)
I0526 09:05:51.095027 26882 net.cpp:150] Setting up relu2
I0526 09:05:51.095047 26882 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 09:05:51.095060 26882 net.cpp:165] Memory required for data: 11140520
I0526 09:05:51.095075 26882 layer_factory.hpp:77] Creating layer pool2
I0526 09:05:51.095093 26882 net.cpp:106] Creating Layer pool2
I0526 09:05:51.095106 26882 net.cpp:454] pool2 <- conv2
I0526 09:05:51.095130 26882 net.cpp:411] pool2 -> pool2
I0526 09:05:51.095218 26882 net.cpp:150] Setting up pool2
I0526 09:05:51.095235 26882 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 09:05:51.095249 26882 net.cpp:165] Memory required for data: 12134120
I0526 09:05:51.095268 26882 layer_factory.hpp:77] Creating layer conv3
I0526 09:05:51.095291 26882 net.cpp:106] Creating Layer conv3
I0526 09:05:51.095311 26882 net.cpp:454] conv3 <- pool2
I0526 09:05:51.095329 26882 net.cpp:411] conv3 -> conv3
I0526 09:05:51.097360 26882 net.cpp:150] Setting up conv3
I0526 09:05:51.097386 26882 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 09:05:51.097405 26882 net.cpp:165] Memory required for data: 13218280
I0526 09:05:51.097429 26882 layer_factory.hpp:77] Creating layer relu3
I0526 09:05:51.097460 26882 net.cpp:106] Creating Layer relu3
I0526 09:05:51.097476 26882 net.cpp:454] relu3 <- conv3
I0526 09:05:51.097501 26882 net.cpp:397] relu3 -> conv3 (in-place)
I0526 09:05:51.098009 26882 net.cpp:150] Setting up relu3
I0526 09:05:51.098033 26882 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 09:05:51.098047 26882 net.cpp:165] Memory required for data: 14302440
I0526 09:05:51.098062 26882 layer_factory.hpp:77] Creating layer pool3
I0526 09:05:51.098088 26882 net.cpp:106] Creating Layer pool3
I0526 09:05:51.098100 26882 net.cpp:454] pool3 <- conv3
I0526 09:05:51.098117 26882 net.cpp:411] pool3 -> pool3
I0526 09:05:51.098201 26882 net.cpp:150] Setting up pool3
I0526 09:05:51.098218 26882 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 09:05:51.098233 26882 net.cpp:165] Memory required for data: 14844520
I0526 09:05:51.098245 26882 layer_factory.hpp:77] Creating layer conv4
I0526 09:05:51.098266 26882 net.cpp:106] Creating Layer conv4
I0526 09:05:51.098279 26882 net.cpp:454] conv4 <- pool3
I0526 09:05:51.098306 26882 net.cpp:411] conv4 -> conv4
I0526 09:05:51.100395 26882 net.cpp:150] Setting up conv4
I0526 09:05:51.100419 26882 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 09:05:51.100440 26882 net.cpp:165] Memory required for data: 15207400
I0526 09:05:51.100460 26882 layer_factory.hpp:77] Creating layer relu4
I0526 09:05:51.100479 26882 net.cpp:106] Creating Layer relu4
I0526 09:05:51.100502 26882 net.cpp:454] relu4 <- conv4
I0526 09:05:51.100518 26882 net.cpp:397] relu4 -> conv4 (in-place)
I0526 09:05:51.101006 26882 net.cpp:150] Setting up relu4
I0526 09:05:51.101027 26882 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 09:05:51.101040 26882 net.cpp:165] Memory required for data: 15570280
I0526 09:05:51.101053 26882 layer_factory.hpp:77] Creating layer pool4
I0526 09:05:51.101073 26882 net.cpp:106] Creating Layer pool4
I0526 09:05:51.101095 26882 net.cpp:454] pool4 <- conv4
I0526 09:05:51.101111 26882 net.cpp:411] pool4 -> pool4
I0526 09:05:51.101198 26882 net.cpp:150] Setting up pool4
I0526 09:05:51.101217 26882 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 09:05:51.101233 26882 net.cpp:165] Memory required for data: 15751720
I0526 09:05:51.101245 26882 layer_factory.hpp:77] Creating layer ip1
I0526 09:05:51.101269 26882 net.cpp:106] Creating Layer ip1
I0526 09:05:51.101282 26882 net.cpp:454] ip1 <- pool4
I0526 09:05:51.101300 26882 net.cpp:411] ip1 -> ip1
I0526 09:05:51.116641 26882 net.cpp:150] Setting up ip1
I0526 09:05:51.116674 26882 net.cpp:157] Top shape: 10 196 (1960)
I0526 09:05:51.116695 26882 net.cpp:165] Memory required for data: 15759560
I0526 09:05:51.116722 26882 layer_factory.hpp:77] Creating layer relu5
I0526 09:05:51.116744 26882 net.cpp:106] Creating Layer relu5
I0526 09:05:51.116770 26882 net.cpp:454] relu5 <- ip1
I0526 09:05:51.116786 26882 net.cpp:397] relu5 -> ip1 (in-place)
I0526 09:05:51.117151 26882 net.cpp:150] Setting up relu5
I0526 09:05:51.117172 26882 net.cpp:157] Top shape: 10 196 (1960)
I0526 09:05:51.117184 26882 net.cpp:165] Memory required for data: 15767400
I0526 09:05:51.117199 26882 layer_factory.hpp:77] Creating layer drop1
I0526 09:05:51.117228 26882 net.cpp:106] Creating Layer drop1
I0526 09:05:51.117241 26882 net.cpp:454] drop1 <- ip1
I0526 09:05:51.117257 26882 net.cpp:397] drop1 -> ip1 (in-place)
I0526 09:05:51.117317 26882 net.cpp:150] Setting up drop1
I0526 09:05:51.117333 26882 net.cpp:157] Top shape: 10 196 (1960)
I0526 09:05:51.117347 26882 net.cpp:165] Memory required for data: 15775240
I0526 09:05:51.117358 26882 layer_factory.hpp:77] Creating layer ip2
I0526 09:05:51.117378 26882 net.cpp:106] Creating Layer ip2
I0526 09:05:51.117390 26882 net.cpp:454] ip2 <- ip1
I0526 09:05:51.117414 26882 net.cpp:411] ip2 -> ip2
I0526 09:05:51.117914 26882 net.cpp:150] Setting up ip2
I0526 09:05:51.117933 26882 net.cpp:157] Top shape: 10 98 (980)
I0526 09:05:51.117946 26882 net.cpp:165] Memory required for data: 15779160
I0526 09:05:51.117967 26882 layer_factory.hpp:77] Creating layer relu6
I0526 09:05:51.118002 26882 net.cpp:106] Creating Layer relu6
I0526 09:05:51.118016 26882 net.cpp:454] relu6 <- ip2
I0526 09:05:51.118031 26882 net.cpp:397] relu6 -> ip2 (in-place)
I0526 09:05:51.118602 26882 net.cpp:150] Setting up relu6
I0526 09:05:51.118624 26882 net.cpp:157] Top shape: 10 98 (980)
I0526 09:05:51.118638 26882 net.cpp:165] Memory required for data: 15783080
I0526 09:05:51.118650 26882 layer_factory.hpp:77] Creating layer drop2
I0526 09:05:51.118670 26882 net.cpp:106] Creating Layer drop2
I0526 09:05:51.118691 26882 net.cpp:454] drop2 <- ip2
I0526 09:05:51.118708 26882 net.cpp:397] drop2 -> ip2 (in-place)
I0526 09:05:51.118767 26882 net.cpp:150] Setting up drop2
I0526 09:05:51.118783 26882 net.cpp:157] Top shape: 10 98 (980)
I0526 09:05:51.118796 26882 net.cpp:165] Memory required for data: 15787000
I0526 09:05:51.118808 26882 layer_factory.hpp:77] Creating layer ip3
I0526 09:05:51.118825 26882 net.cpp:106] Creating Layer ip3
I0526 09:05:51.118840 26882 net.cpp:454] ip3 <- ip2
I0526 09:05:51.118863 26882 net.cpp:411] ip3 -> ip3
I0526 09:05:51.119101 26882 net.cpp:150] Setting up ip3
I0526 09:05:51.119119 26882 net.cpp:157] Top shape: 10 11 (110)
I0526 09:05:51.119132 26882 net.cpp:165] Memory required for data: 15787440
I0526 09:05:51.119153 26882 layer_factory.hpp:77] Creating layer drop3
I0526 09:05:51.119175 26882 net.cpp:106] Creating Layer drop3
I0526 09:05:51.119189 26882 net.cpp:454] drop3 <- ip3
I0526 09:05:51.119204 26882 net.cpp:397] drop3 -> ip3 (in-place)
I0526 09:05:51.119253 26882 net.cpp:150] Setting up drop3
I0526 09:05:51.119271 26882 net.cpp:157] Top shape: 10 11 (110)
I0526 09:05:51.119289 26882 net.cpp:165] Memory required for data: 15787880
I0526 09:05:51.119303 26882 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 09:05:51.119318 26882 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 09:05:51.119333 26882 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 09:05:51.119349 26882 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 09:05:51.119374 26882 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 09:05:51.119467 26882 net.cpp:150] Setting up ip3_drop3_0_split
I0526 09:05:51.119484 26882 net.cpp:157] Top shape: 10 11 (110)
I0526 09:05:51.119508 26882 net.cpp:157] Top shape: 10 11 (110)
I0526 09:05:51.119519 26882 net.cpp:165] Memory required for data: 15788760
I0526 09:05:51.119531 26882 layer_factory.hpp:77] Creating layer accuracy
I0526 09:05:51.119562 26882 net.cpp:106] Creating Layer accuracy
I0526 09:05:51.119575 26882 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 09:05:51.119590 26882 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 09:05:51.119609 26882 net.cpp:411] accuracy -> accuracy
I0526 09:05:51.119635 26882 net.cpp:150] Setting up accuracy
I0526 09:05:51.119653 26882 net.cpp:157] Top shape: (1)
I0526 09:05:51.119671 26882 net.cpp:165] Memory required for data: 15788764
I0526 09:05:51.119684 26882 layer_factory.hpp:77] Creating layer loss
I0526 09:05:51.119701 26882 net.cpp:106] Creating Layer loss
I0526 09:05:51.119714 26882 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 09:05:51.119726 26882 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 09:05:51.119745 26882 net.cpp:411] loss -> loss
I0526 09:05:51.119771 26882 layer_factory.hpp:77] Creating layer loss
I0526 09:05:51.120270 26882 net.cpp:150] Setting up loss
I0526 09:05:51.120290 26882 net.cpp:157] Top shape: (1)
I0526 09:05:51.120303 26882 net.cpp:160]     with loss weight 1
I0526 09:05:51.120329 26882 net.cpp:165] Memory required for data: 15788768
I0526 09:05:51.120349 26882 net.cpp:226] loss needs backward computation.
I0526 09:05:51.120364 26882 net.cpp:228] accuracy does not need backward computation.
I0526 09:05:51.120383 26882 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 09:05:51.120395 26882 net.cpp:226] drop3 needs backward computation.
I0526 09:05:51.120407 26882 net.cpp:226] ip3 needs backward computation.
I0526 09:05:51.120422 26882 net.cpp:226] drop2 needs backward computation.
I0526 09:05:51.120435 26882 net.cpp:226] relu6 needs backward computation.
I0526 09:05:51.120456 26882 net.cpp:226] ip2 needs backward computation.
I0526 09:05:51.120470 26882 net.cpp:226] drop1 needs backward computation.
I0526 09:05:51.120481 26882 net.cpp:226] relu5 needs backward computation.
I0526 09:05:51.120501 26882 net.cpp:226] ip1 needs backward computation.
I0526 09:05:51.120515 26882 net.cpp:226] pool4 needs backward computation.
I0526 09:05:51.120527 26882 net.cpp:226] relu4 needs backward computation.
I0526 09:05:51.120540 26882 net.cpp:226] conv4 needs backward computation.
I0526 09:05:51.120554 26882 net.cpp:226] pool3 needs backward computation.
I0526 09:05:51.120570 26882 net.cpp:226] relu3 needs backward computation.
I0526 09:05:51.120589 26882 net.cpp:226] conv3 needs backward computation.
I0526 09:05:51.120601 26882 net.cpp:226] pool2 needs backward computation.
I0526 09:05:51.120617 26882 net.cpp:226] relu2 needs backward computation.
I0526 09:05:51.120630 26882 net.cpp:226] conv2 needs backward computation.
I0526 09:05:51.120642 26882 net.cpp:226] pool1 needs backward computation.
I0526 09:05:51.120656 26882 net.cpp:226] relu1 needs backward computation.
I0526 09:05:51.120678 26882 net.cpp:226] conv1 needs backward computation.
I0526 09:05:51.120693 26882 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 09:05:51.120707 26882 net.cpp:228] data_hdf5 does not need backward computation.
I0526 09:05:51.120721 26882 net.cpp:270] This network produces output accuracy
I0526 09:05:51.120733 26882 net.cpp:270] This network produces output loss
I0526 09:05:51.120765 26882 net.cpp:283] Network initialization done.
I0526 09:05:51.120901 26882 solver.cpp:60] Solver scaffolding done.
I0526 09:05:51.122058 26882 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_450000.solverstate
I0526 09:05:51.364182 26882 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 09:05:51.369582 26882 caffe.cpp:212] Starting Optimization
I0526 09:05:51.369634 26882 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 09:05:51.369657 26882 solver.cpp:289] Learning Rate Policy: fixed
I0526 09:05:51.370893 26882 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 09:06:51.982446 26882 solver.cpp:409]     Test net output #0: accuracy = 0.890224
I0526 09:06:51.982606 26882 solver.cpp:409]     Test net output #1: loss = 0.370248 (* 1 = 0.370248 loss)
I0526 09:06:52.000450 26882 solver.cpp:237] Iteration 450000, loss = 2.01681
I0526 09:06:52.000490 26882 solver.cpp:253]     Train net output #0: loss = 2.01681 (* 1 = 2.01681 loss)
I0526 09:06:52.000511 26882 sgd_solver.cpp:106] Iteration 450000, lr = 0.004
I0526 09:07:08.971761 26882 solver.cpp:237] Iteration 451500, loss = 1.06953
I0526 09:07:08.971820 26882 solver.cpp:253]     Train net output #0: loss = 1.06953 (* 1 = 1.06953 loss)
I0526 09:07:08.971838 26882 sgd_solver.cpp:106] Iteration 451500, lr = 0.004
I0526 09:07:25.913137 26882 solver.cpp:237] Iteration 453000, loss = 1.75273
I0526 09:07:25.913310 26882 solver.cpp:253]     Train net output #0: loss = 1.75273 (* 1 = 1.75273 loss)
I0526 09:07:25.913328 26882 sgd_solver.cpp:106] Iteration 453000, lr = 0.004
I0526 09:07:42.519426 26882 solver.cpp:237] Iteration 454500, loss = 0.61948
I0526 09:07:42.519464 26882 solver.cpp:253]     Train net output #0: loss = 0.61948 (* 1 = 0.61948 loss)
I0526 09:07:42.519489 26882 sgd_solver.cpp:106] Iteration 454500, lr = 0.004
I0526 09:07:59.153605 26882 solver.cpp:237] Iteration 456000, loss = 0.277251
I0526 09:07:59.153764 26882 solver.cpp:253]     Train net output #0: loss = 0.277251 (* 1 = 0.277251 loss)
I0526 09:07:59.153780 26882 sgd_solver.cpp:106] Iteration 456000, lr = 0.004
I0526 09:08:15.866631 26882 solver.cpp:237] Iteration 457500, loss = 0.771601
I0526 09:08:15.866686 26882 solver.cpp:253]     Train net output #0: loss = 0.771601 (* 1 = 0.771601 loss)
I0526 09:08:15.866703 26882 sgd_solver.cpp:106] Iteration 457500, lr = 0.004
I0526 09:08:32.830659 26882 solver.cpp:237] Iteration 459000, loss = 1.46541
I0526 09:08:32.830799 26882 solver.cpp:253]     Train net output #0: loss = 1.46541 (* 1 = 1.46541 loss)
I0526 09:08:32.830816 26882 sgd_solver.cpp:106] Iteration 459000, lr = 0.004
I0526 09:09:12.223209 26882 solver.cpp:237] Iteration 460500, loss = 1.17296
I0526 09:09:12.223377 26882 solver.cpp:253]     Train net output #0: loss = 1.17296 (* 1 = 1.17296 loss)
I0526 09:09:12.223395 26882 sgd_solver.cpp:106] Iteration 460500, lr = 0.004
I0526 09:09:29.414881 26882 solver.cpp:237] Iteration 462000, loss = 0.972284
I0526 09:09:29.414942 26882 solver.cpp:253]     Train net output #0: loss = 0.972285 (* 1 = 0.972285 loss)
I0526 09:09:29.414966 26882 sgd_solver.cpp:106] Iteration 462000, lr = 0.004
I0526 09:09:46.471310 26882 solver.cpp:237] Iteration 463500, loss = 1.66388
I0526 09:09:46.471454 26882 solver.cpp:253]     Train net output #0: loss = 1.66388 (* 1 = 1.66388 loss)
I0526 09:09:46.471472 26882 sgd_solver.cpp:106] Iteration 463500, lr = 0.004
I0526 09:10:03.231154 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_465000.caffemodel
I0526 09:10:03.277590 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_465000.solverstate
I0526 09:10:03.306257 26882 solver.cpp:237] Iteration 465000, loss = 0.801221
I0526 09:10:03.306318 26882 solver.cpp:253]     Train net output #0: loss = 0.801222 (* 1 = 0.801222 loss)
I0526 09:10:03.306337 26882 sgd_solver.cpp:106] Iteration 465000, lr = 0.004
I0526 09:10:19.954041 26882 solver.cpp:237] Iteration 466500, loss = 1.13785
I0526 09:10:19.954206 26882 solver.cpp:253]     Train net output #0: loss = 1.13785 (* 1 = 1.13785 loss)
I0526 09:10:19.954226 26882 sgd_solver.cpp:106] Iteration 466500, lr = 0.004
I0526 09:10:36.616035 26882 solver.cpp:237] Iteration 468000, loss = 1.35071
I0526 09:10:36.616077 26882 solver.cpp:253]     Train net output #0: loss = 1.35071 (* 1 = 1.35071 loss)
I0526 09:10:36.616101 26882 sgd_solver.cpp:106] Iteration 468000, lr = 0.004
I0526 09:10:53.441586 26882 solver.cpp:237] Iteration 469500, loss = 1.02197
I0526 09:10:53.441753 26882 solver.cpp:253]     Train net output #0: loss = 1.02197 (* 1 = 1.02197 loss)
I0526 09:10:53.441771 26882 sgd_solver.cpp:106] Iteration 469500, lr = 0.004
I0526 09:11:32.466053 26882 solver.cpp:237] Iteration 471000, loss = 0.873181
I0526 09:11:32.466234 26882 solver.cpp:253]     Train net output #0: loss = 0.873183 (* 1 = 0.873183 loss)
I0526 09:11:32.466254 26882 sgd_solver.cpp:106] Iteration 471000, lr = 0.004
I0526 09:11:49.115784 26882 solver.cpp:237] Iteration 472500, loss = 1.14031
I0526 09:11:49.115824 26882 solver.cpp:253]     Train net output #0: loss = 1.14031 (* 1 = 1.14031 loss)
I0526 09:11:49.115841 26882 sgd_solver.cpp:106] Iteration 472500, lr = 0.004
I0526 09:12:05.753494 26882 solver.cpp:237] Iteration 474000, loss = 0.732062
I0526 09:12:05.753664 26882 solver.cpp:253]     Train net output #0: loss = 0.732061 (* 1 = 0.732061 loss)
I0526 09:12:05.753680 26882 sgd_solver.cpp:106] Iteration 474000, lr = 0.004
I0526 09:12:22.369078 26882 solver.cpp:237] Iteration 475500, loss = 1.08769
I0526 09:12:22.369132 26882 solver.cpp:253]     Train net output #0: loss = 1.08769 (* 1 = 1.08769 loss)
I0526 09:12:22.369149 26882 sgd_solver.cpp:106] Iteration 475500, lr = 0.004
I0526 09:12:39.263413 26882 solver.cpp:237] Iteration 477000, loss = 1.08397
I0526 09:12:39.263569 26882 solver.cpp:253]     Train net output #0: loss = 1.08397 (* 1 = 1.08397 loss)
I0526 09:12:39.263586 26882 sgd_solver.cpp:106] Iteration 477000, lr = 0.004
I0526 09:12:56.321126 26882 solver.cpp:237] Iteration 478500, loss = 1.18974
I0526 09:12:56.321180 26882 solver.cpp:253]     Train net output #0: loss = 1.18973 (* 1 = 1.18973 loss)
I0526 09:12:56.321200 26882 sgd_solver.cpp:106] Iteration 478500, lr = 0.004
I0526 09:13:13.434224 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_480000.caffemodel
I0526 09:13:13.479753 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_480000.solverstate
I0526 09:13:13.507975 26882 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 09:14:13.133205 26882 solver.cpp:409]     Test net output #0: accuracy = 0.885209
I0526 09:14:13.133371 26882 solver.cpp:409]     Test net output #1: loss = 0.378648 (* 1 = 0.378648 loss)
I0526 09:14:35.347254 26882 solver.cpp:237] Iteration 480000, loss = 1.25279
I0526 09:14:35.347317 26882 solver.cpp:253]     Train net output #0: loss = 1.25279 (* 1 = 1.25279 loss)
I0526 09:14:35.347343 26882 sgd_solver.cpp:106] Iteration 480000, lr = 0.004
I0526 09:14:52.362769 26882 solver.cpp:237] Iteration 481500, loss = 1.00337
I0526 09:14:52.362936 26882 solver.cpp:253]     Train net output #0: loss = 1.00337 (* 1 = 1.00337 loss)
I0526 09:14:52.362954 26882 sgd_solver.cpp:106] Iteration 481500, lr = 0.004
I0526 09:15:08.990268 26882 solver.cpp:237] Iteration 483000, loss = 1.15296
I0526 09:15:08.990308 26882 solver.cpp:253]     Train net output #0: loss = 1.15296 (* 1 = 1.15296 loss)
I0526 09:15:08.990325 26882 sgd_solver.cpp:106] Iteration 483000, lr = 0.004
I0526 09:15:25.745178 26882 solver.cpp:237] Iteration 484500, loss = 1.26043
I0526 09:15:25.745337 26882 solver.cpp:253]     Train net output #0: loss = 1.26043 (* 1 = 1.26043 loss)
I0526 09:15:25.745353 26882 sgd_solver.cpp:106] Iteration 484500, lr = 0.004
I0526 09:15:42.696113 26882 solver.cpp:237] Iteration 486000, loss = 0.484496
I0526 09:15:42.696169 26882 solver.cpp:253]     Train net output #0: loss = 0.484494 (* 1 = 0.484494 loss)
I0526 09:15:42.696187 26882 sgd_solver.cpp:106] Iteration 486000, lr = 0.004
I0526 09:15:59.447026 26882 solver.cpp:237] Iteration 487500, loss = 1.54858
I0526 09:15:59.447170 26882 solver.cpp:253]     Train net output #0: loss = 1.54858 (* 1 = 1.54858 loss)
I0526 09:15:59.447185 26882 sgd_solver.cpp:106] Iteration 487500, lr = 0.004
I0526 09:16:16.149917 26882 solver.cpp:237] Iteration 489000, loss = 0.73221
I0526 09:16:16.149977 26882 solver.cpp:253]     Train net output #0: loss = 0.732209 (* 1 = 0.732209 loss)
I0526 09:16:16.149994 26882 sgd_solver.cpp:106] Iteration 489000, lr = 0.004
I0526 09:16:54.974931 26882 solver.cpp:237] Iteration 490500, loss = 1.35342
I0526 09:16:54.975116 26882 solver.cpp:253]     Train net output #0: loss = 1.35342 (* 1 = 1.35342 loss)
I0526 09:16:54.975134 26882 sgd_solver.cpp:106] Iteration 490500, lr = 0.004
I0526 09:17:12.006150 26882 solver.cpp:237] Iteration 492000, loss = 1.11967
I0526 09:17:12.006203 26882 solver.cpp:253]     Train net output #0: loss = 1.11966 (* 1 = 1.11966 loss)
I0526 09:17:12.006222 26882 sgd_solver.cpp:106] Iteration 492000, lr = 0.004
I0526 09:17:28.859141 26882 solver.cpp:237] Iteration 493500, loss = 1.56712
I0526 09:17:28.859300 26882 solver.cpp:253]     Train net output #0: loss = 1.56712 (* 1 = 1.56712 loss)
I0526 09:17:28.859318 26882 sgd_solver.cpp:106] Iteration 493500, lr = 0.004
I0526 09:17:45.439815 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_495000.caffemodel
I0526 09:17:45.487310 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_495000.solverstate
I0526 09:17:45.518039 26882 solver.cpp:237] Iteration 495000, loss = 0.997065
I0526 09:17:45.518100 26882 solver.cpp:253]     Train net output #0: loss = 0.997063 (* 1 = 0.997063 loss)
I0526 09:17:45.518117 26882 sgd_solver.cpp:106] Iteration 495000, lr = 0.004
I0526 09:18:02.266517 26882 solver.cpp:237] Iteration 496500, loss = 1.25239
I0526 09:18:02.266680 26882 solver.cpp:253]     Train net output #0: loss = 1.25239 (* 1 = 1.25239 loss)
I0526 09:18:02.266696 26882 sgd_solver.cpp:106] Iteration 496500, lr = 0.004
I0526 09:18:19.186141 26882 solver.cpp:237] Iteration 498000, loss = 0.711867
I0526 09:18:19.186200 26882 solver.cpp:253]     Train net output #0: loss = 0.711865 (* 1 = 0.711865 loss)
I0526 09:18:19.186218 26882 sgd_solver.cpp:106] Iteration 498000, lr = 0.004
I0526 09:18:36.243088 26882 solver.cpp:237] Iteration 499500, loss = 0.652995
I0526 09:18:36.243237 26882 solver.cpp:253]     Train net output #0: loss = 0.652993 (* 1 = 0.652993 loss)
I0526 09:18:36.243254 26882 sgd_solver.cpp:106] Iteration 499500, lr = 0.004
I0526 09:19:15.232029 26882 solver.cpp:237] Iteration 501000, loss = 1.73481
I0526 09:19:15.232200 26882 solver.cpp:253]     Train net output #0: loss = 1.73481 (* 1 = 1.73481 loss)
I0526 09:19:15.232218 26882 sgd_solver.cpp:106] Iteration 501000, lr = 0.004
I0526 09:19:32.078512 26882 solver.cpp:237] Iteration 502500, loss = 0.780259
I0526 09:19:32.078570 26882 solver.cpp:253]     Train net output #0: loss = 0.780257 (* 1 = 0.780257 loss)
I0526 09:19:32.078598 26882 sgd_solver.cpp:106] Iteration 502500, lr = 0.004
I0526 09:19:49.036284 26882 solver.cpp:237] Iteration 504000, loss = 1.51753
I0526 09:19:49.036427 26882 solver.cpp:253]     Train net output #0: loss = 1.51753 (* 1 = 1.51753 loss)
I0526 09:19:49.036444 26882 sgd_solver.cpp:106] Iteration 504000, lr = 0.004
I0526 09:20:06.059928 26882 solver.cpp:237] Iteration 505500, loss = 0.821784
I0526 09:20:06.059984 26882 solver.cpp:253]     Train net output #0: loss = 0.821782 (* 1 = 0.821782 loss)
I0526 09:20:06.060003 26882 sgd_solver.cpp:106] Iteration 505500, lr = 0.004
I0526 09:20:23.096900 26882 solver.cpp:237] Iteration 507000, loss = 1.74128
I0526 09:20:23.097067 26882 solver.cpp:253]     Train net output #0: loss = 1.74127 (* 1 = 1.74127 loss)
I0526 09:20:23.097086 26882 sgd_solver.cpp:106] Iteration 507000, lr = 0.004
I0526 09:20:40.035919 26882 solver.cpp:237] Iteration 508500, loss = 0.596439
I0526 09:20:40.035959 26882 solver.cpp:253]     Train net output #0: loss = 0.596435 (* 1 = 0.596435 loss)
I0526 09:20:40.035977 26882 sgd_solver.cpp:106] Iteration 508500, lr = 0.004
I0526 09:20:56.916554 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_510000.caffemodel
I0526 09:20:56.964681 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_510000.solverstate
I0526 09:20:56.992683 26882 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 09:22:17.012984 26882 solver.cpp:409]     Test net output #0: accuracy = 0.889203
I0526 09:22:17.013152 26882 solver.cpp:409]     Test net output #1: loss = 0.369475 (* 1 = 0.369475 loss)
I0526 09:22:39.249126 26882 solver.cpp:237] Iteration 510000, loss = 1.6016
I0526 09:22:39.249192 26882 solver.cpp:253]     Train net output #0: loss = 1.60159 (* 1 = 1.60159 loss)
I0526 09:22:39.249212 26882 sgd_solver.cpp:106] Iteration 510000, lr = 0.004
I0526 09:22:56.017889 26882 solver.cpp:237] Iteration 511500, loss = 1.05816
I0526 09:22:56.018059 26882 solver.cpp:253]     Train net output #0: loss = 1.05816 (* 1 = 1.05816 loss)
I0526 09:22:56.018076 26882 sgd_solver.cpp:106] Iteration 511500, lr = 0.004
I0526 09:23:12.666904 26882 solver.cpp:237] Iteration 513000, loss = 0.938429
I0526 09:23:12.666963 26882 solver.cpp:253]     Train net output #0: loss = 0.938425 (* 1 = 0.938425 loss)
I0526 09:23:12.666980 26882 sgd_solver.cpp:106] Iteration 513000, lr = 0.004
I0526 09:23:29.457164 26882 solver.cpp:237] Iteration 514500, loss = 1.40722
I0526 09:23:29.457309 26882 solver.cpp:253]     Train net output #0: loss = 1.40721 (* 1 = 1.40721 loss)
I0526 09:23:29.457326 26882 sgd_solver.cpp:106] Iteration 514500, lr = 0.004
I0526 09:23:46.502825 26882 solver.cpp:237] Iteration 516000, loss = 0.938826
I0526 09:23:46.502882 26882 solver.cpp:253]     Train net output #0: loss = 0.938821 (* 1 = 0.938821 loss)
I0526 09:23:46.502902 26882 sgd_solver.cpp:106] Iteration 516000, lr = 0.004
I0526 09:24:03.667347 26882 solver.cpp:237] Iteration 517500, loss = 1.12677
I0526 09:24:03.667515 26882 solver.cpp:253]     Train net output #0: loss = 1.12677 (* 1 = 1.12677 loss)
I0526 09:24:03.667534 26882 sgd_solver.cpp:106] Iteration 517500, lr = 0.004
I0526 09:24:20.568225 26882 solver.cpp:237] Iteration 519000, loss = 0.94992
I0526 09:24:20.568265 26882 solver.cpp:253]     Train net output #0: loss = 0.949916 (* 1 = 0.949916 loss)
I0526 09:24:20.568282 26882 sgd_solver.cpp:106] Iteration 519000, lr = 0.004
I0526 09:24:59.740420 26882 solver.cpp:237] Iteration 520500, loss = 2.00068
I0526 09:24:59.740586 26882 solver.cpp:253]     Train net output #0: loss = 2.00067 (* 1 = 2.00067 loss)
I0526 09:24:59.740612 26882 sgd_solver.cpp:106] Iteration 520500, lr = 0.004
I0526 09:25:16.799091 26882 solver.cpp:237] Iteration 522000, loss = 1.46289
I0526 09:25:16.799149 26882 solver.cpp:253]     Train net output #0: loss = 1.46288 (* 1 = 1.46288 loss)
I0526 09:25:16.799176 26882 sgd_solver.cpp:106] Iteration 522000, lr = 0.004
I0526 09:25:33.746142 26882 solver.cpp:237] Iteration 523500, loss = 0.695385
I0526 09:25:33.746289 26882 solver.cpp:253]     Train net output #0: loss = 0.695379 (* 1 = 0.695379 loss)
I0526 09:25:33.746306 26882 sgd_solver.cpp:106] Iteration 523500, lr = 0.004
I0526 09:25:50.781054 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_525000.caffemodel
I0526 09:25:50.829304 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_525000.solverstate
I0526 09:25:50.860200 26882 solver.cpp:237] Iteration 525000, loss = 0.600774
I0526 09:25:50.860267 26882 solver.cpp:253]     Train net output #0: loss = 0.600767 (* 1 = 0.600767 loss)
I0526 09:25:50.860286 26882 sgd_solver.cpp:106] Iteration 525000, lr = 0.004
I0526 09:26:08.042459 26882 solver.cpp:237] Iteration 526500, loss = 1.25159
I0526 09:26:08.042626 26882 solver.cpp:253]     Train net output #0: loss = 1.25159 (* 1 = 1.25159 loss)
I0526 09:26:08.042654 26882 sgd_solver.cpp:106] Iteration 526500, lr = 0.004
I0526 09:26:25.094748 26882 solver.cpp:237] Iteration 528000, loss = 1.05381
I0526 09:26:25.094790 26882 solver.cpp:253]     Train net output #0: loss = 1.05381 (* 1 = 1.05381 loss)
I0526 09:26:25.094815 26882 sgd_solver.cpp:106] Iteration 528000, lr = 0.004
I0526 09:26:41.868612 26882 solver.cpp:237] Iteration 529500, loss = 0.940967
I0526 09:26:41.868787 26882 solver.cpp:253]     Train net output #0: loss = 0.94096 (* 1 = 0.94096 loss)
I0526 09:26:41.868804 26882 sgd_solver.cpp:106] Iteration 529500, lr = 0.004
I0526 09:27:20.730141 26882 solver.cpp:237] Iteration 531000, loss = 1.28118
I0526 09:27:20.730319 26882 solver.cpp:253]     Train net output #0: loss = 1.28118 (* 1 = 1.28118 loss)
I0526 09:27:20.730336 26882 sgd_solver.cpp:106] Iteration 531000, lr = 0.004
I0526 09:27:37.487505 26882 solver.cpp:237] Iteration 532500, loss = 1.03927
I0526 09:27:37.487562 26882 solver.cpp:253]     Train net output #0: loss = 1.03926 (* 1 = 1.03926 loss)
I0526 09:27:37.487581 26882 sgd_solver.cpp:106] Iteration 532500, lr = 0.004
I0526 09:27:54.465862 26882 solver.cpp:237] Iteration 534000, loss = 1.54208
I0526 09:27:54.466023 26882 solver.cpp:253]     Train net output #0: loss = 1.54207 (* 1 = 1.54207 loss)
I0526 09:27:54.466040 26882 sgd_solver.cpp:106] Iteration 534000, lr = 0.004
I0526 09:28:11.698380 26882 solver.cpp:237] Iteration 535500, loss = 1.72821
I0526 09:28:11.698438 26882 solver.cpp:253]     Train net output #0: loss = 1.7282 (* 1 = 1.7282 loss)
I0526 09:28:11.698465 26882 sgd_solver.cpp:106] Iteration 535500, lr = 0.004
I0526 09:28:28.332221 26882 solver.cpp:237] Iteration 537000, loss = 1.16051
I0526 09:28:28.332367 26882 solver.cpp:253]     Train net output #0: loss = 1.1605 (* 1 = 1.1605 loss)
I0526 09:28:28.332384 26882 sgd_solver.cpp:106] Iteration 537000, lr = 0.004
I0526 09:28:45.090701 26882 solver.cpp:237] Iteration 538500, loss = 1.10564
I0526 09:28:45.090759 26882 solver.cpp:253]     Train net output #0: loss = 1.10563 (* 1 = 1.10563 loss)
I0526 09:28:45.090775 26882 sgd_solver.cpp:106] Iteration 538500, lr = 0.004
I0526 09:29:01.887491 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_540000.caffemodel
I0526 09:29:01.934159 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_540000.solverstate
I0526 09:29:01.959753 26882 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 09:30:01.079349 26882 solver.cpp:409]     Test net output #0: accuracy = 0.886006
I0526 09:30:01.079516 26882 solver.cpp:409]     Test net output #1: loss = 0.405724 (* 1 = 0.405724 loss)
I0526 09:30:23.254576 26882 solver.cpp:237] Iteration 540000, loss = 1.34348
I0526 09:30:23.254637 26882 solver.cpp:253]     Train net output #0: loss = 1.34347 (* 1 = 1.34347 loss)
I0526 09:30:23.254657 26882 sgd_solver.cpp:106] Iteration 540000, lr = 0.004
I0526 09:30:40.221681 26882 solver.cpp:237] Iteration 541500, loss = 0.527542
I0526 09:30:40.221843 26882 solver.cpp:253]     Train net output #0: loss = 0.527534 (* 1 = 0.527534 loss)
I0526 09:30:40.221859 26882 sgd_solver.cpp:106] Iteration 541500, lr = 0.004
I0526 09:30:56.842244 26882 solver.cpp:237] Iteration 543000, loss = 0.671945
I0526 09:30:56.842303 26882 solver.cpp:253]     Train net output #0: loss = 0.671937 (* 1 = 0.671937 loss)
I0526 09:30:56.842321 26882 sgd_solver.cpp:106] Iteration 543000, lr = 0.004
I0526 09:31:13.475185 26882 solver.cpp:237] Iteration 544500, loss = 2.14426
I0526 09:31:13.475350 26882 solver.cpp:253]     Train net output #0: loss = 2.14426 (* 1 = 2.14426 loss)
I0526 09:31:13.475368 26882 sgd_solver.cpp:106] Iteration 544500, lr = 0.004
I0526 09:31:30.094887 26882 solver.cpp:237] Iteration 546000, loss = 1.04365
I0526 09:31:30.094926 26882 solver.cpp:253]     Train net output #0: loss = 1.04365 (* 1 = 1.04365 loss)
I0526 09:31:30.094944 26882 sgd_solver.cpp:106] Iteration 546000, lr = 0.004
I0526 09:31:47.204836 26882 solver.cpp:237] Iteration 547500, loss = 1.42663
I0526 09:31:47.205011 26882 solver.cpp:253]     Train net output #0: loss = 1.42662 (* 1 = 1.42662 loss)
I0526 09:31:47.205029 26882 sgd_solver.cpp:106] Iteration 547500, lr = 0.004
I0526 09:32:04.114578 26882 solver.cpp:237] Iteration 549000, loss = 0.852413
I0526 09:32:04.114634 26882 solver.cpp:253]     Train net output #0: loss = 0.852404 (* 1 = 0.852404 loss)
I0526 09:32:04.114650 26882 sgd_solver.cpp:106] Iteration 549000, lr = 0.004
I0526 09:32:42.923265 26882 solver.cpp:237] Iteration 550500, loss = 1.70906
I0526 09:32:42.923444 26882 solver.cpp:253]     Train net output #0: loss = 1.70905 (* 1 = 1.70905 loss)
I0526 09:32:42.923461 26882 sgd_solver.cpp:106] Iteration 550500, lr = 0.004
I0526 09:32:59.783748 26882 solver.cpp:237] Iteration 552000, loss = 0.504678
I0526 09:32:59.783807 26882 solver.cpp:253]     Train net output #0: loss = 0.504669 (* 1 = 0.504669 loss)
I0526 09:32:59.783824 26882 sgd_solver.cpp:106] Iteration 552000, lr = 0.004
I0526 09:33:16.848824 26882 solver.cpp:237] Iteration 553500, loss = 1.61296
I0526 09:33:16.848991 26882 solver.cpp:253]     Train net output #0: loss = 1.61295 (* 1 = 1.61295 loss)
I0526 09:33:16.849010 26882 sgd_solver.cpp:106] Iteration 553500, lr = 0.004
I0526 09:33:34.065490 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_555000.caffemodel
I0526 09:33:34.111868 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_555000.solverstate
I0526 09:33:34.140658 26882 solver.cpp:237] Iteration 555000, loss = 1.51085
I0526 09:33:34.140714 26882 solver.cpp:253]     Train net output #0: loss = 1.51084 (* 1 = 1.51084 loss)
I0526 09:33:34.140739 26882 sgd_solver.cpp:106] Iteration 555000, lr = 0.004
I0526 09:33:50.989131 26882 solver.cpp:237] Iteration 556500, loss = 0.79433
I0526 09:33:50.989302 26882 solver.cpp:253]     Train net output #0: loss = 0.794321 (* 1 = 0.794321 loss)
I0526 09:33:50.989320 26882 sgd_solver.cpp:106] Iteration 556500, lr = 0.004
I0526 09:34:07.801810 26882 solver.cpp:237] Iteration 558000, loss = 1.11102
I0526 09:34:07.801867 26882 solver.cpp:253]     Train net output #0: loss = 1.11101 (* 1 = 1.11101 loss)
I0526 09:34:07.801884 26882 sgd_solver.cpp:106] Iteration 558000, lr = 0.004
I0526 09:34:24.640763 26882 solver.cpp:237] Iteration 559500, loss = 1.23181
I0526 09:34:24.640915 26882 solver.cpp:253]     Train net output #0: loss = 1.2318 (* 1 = 1.2318 loss)
I0526 09:34:24.640933 26882 sgd_solver.cpp:106] Iteration 559500, lr = 0.004
I0526 09:35:03.945915 26882 solver.cpp:237] Iteration 561000, loss = 1.65822
I0526 09:35:03.946084 26882 solver.cpp:253]     Train net output #0: loss = 1.65821 (* 1 = 1.65821 loss)
I0526 09:35:03.946100 26882 sgd_solver.cpp:106] Iteration 561000, lr = 0.004
I0526 09:35:21.076050 26882 solver.cpp:237] Iteration 562500, loss = 1.43131
I0526 09:35:21.076105 26882 solver.cpp:253]     Train net output #0: loss = 1.4313 (* 1 = 1.4313 loss)
I0526 09:35:21.076123 26882 sgd_solver.cpp:106] Iteration 562500, lr = 0.004
I0526 09:35:37.929276 26882 solver.cpp:237] Iteration 564000, loss = 0.9864
I0526 09:35:37.929430 26882 solver.cpp:253]     Train net output #0: loss = 0.98639 (* 1 = 0.98639 loss)
I0526 09:35:37.929446 26882 sgd_solver.cpp:106] Iteration 564000, lr = 0.004
I0526 09:35:54.626319 26882 solver.cpp:237] Iteration 565500, loss = 0.928835
I0526 09:35:54.626379 26882 solver.cpp:253]     Train net output #0: loss = 0.928826 (* 1 = 0.928826 loss)
I0526 09:35:54.626396 26882 sgd_solver.cpp:106] Iteration 565500, lr = 0.004
I0526 09:36:11.259470 26882 solver.cpp:237] Iteration 567000, loss = 1.19624
I0526 09:36:11.259634 26882 solver.cpp:253]     Train net output #0: loss = 1.19624 (* 1 = 1.19624 loss)
I0526 09:36:11.259651 26882 sgd_solver.cpp:106] Iteration 567000, lr = 0.004
I0526 09:36:27.895210 26882 solver.cpp:237] Iteration 568500, loss = 1.13466
I0526 09:36:27.895247 26882 solver.cpp:253]     Train net output #0: loss = 1.13465 (* 1 = 1.13465 loss)
I0526 09:36:27.895264 26882 sgd_solver.cpp:106] Iteration 568500, lr = 0.004
I0526 09:36:44.820499 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_570000.caffemodel
I0526 09:36:44.866518 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_570000.solverstate
I0526 09:36:44.891508 26882 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 09:38:05.258035 26882 solver.cpp:409]     Test net output #0: accuracy = 0.883512
I0526 09:38:05.258210 26882 solver.cpp:409]     Test net output #1: loss = 0.373244 (* 1 = 0.373244 loss)
I0526 09:38:27.419728 26882 solver.cpp:237] Iteration 570000, loss = 2.03378
I0526 09:38:27.419790 26882 solver.cpp:253]     Train net output #0: loss = 2.03377 (* 1 = 2.03377 loss)
I0526 09:38:27.419809 26882 sgd_solver.cpp:106] Iteration 570000, lr = 0.004
I0526 09:38:44.169069 26882 solver.cpp:237] Iteration 571500, loss = 2.00268
I0526 09:38:44.169236 26882 solver.cpp:253]     Train net output #0: loss = 2.00267 (* 1 = 2.00267 loss)
I0526 09:38:44.169255 26882 sgd_solver.cpp:106] Iteration 571500, lr = 0.004
I0526 09:39:01.051571 26882 solver.cpp:237] Iteration 573000, loss = 0.900379
I0526 09:39:01.051609 26882 solver.cpp:253]     Train net output #0: loss = 0.90037 (* 1 = 0.90037 loss)
I0526 09:39:01.051628 26882 sgd_solver.cpp:106] Iteration 573000, lr = 0.004
I0526 09:39:17.703047 26882 solver.cpp:237] Iteration 574500, loss = 1.21137
I0526 09:39:17.703207 26882 solver.cpp:253]     Train net output #0: loss = 1.21136 (* 1 = 1.21136 loss)
I0526 09:39:17.703224 26882 sgd_solver.cpp:106] Iteration 574500, lr = 0.004
I0526 09:39:34.378767 26882 solver.cpp:237] Iteration 576000, loss = 1.04177
I0526 09:39:34.378824 26882 solver.cpp:253]     Train net output #0: loss = 1.04176 (* 1 = 1.04176 loss)
I0526 09:39:34.378842 26882 sgd_solver.cpp:106] Iteration 576000, lr = 0.004
I0526 09:39:51.166713 26882 solver.cpp:237] Iteration 577500, loss = 0.888163
I0526 09:39:51.166864 26882 solver.cpp:253]     Train net output #0: loss = 0.888152 (* 1 = 0.888152 loss)
I0526 09:39:51.166880 26882 sgd_solver.cpp:106] Iteration 577500, lr = 0.004
I0526 09:40:08.209024 26882 solver.cpp:237] Iteration 579000, loss = 1.22635
I0526 09:40:08.209079 26882 solver.cpp:253]     Train net output #0: loss = 1.22634 (* 1 = 1.22634 loss)
I0526 09:40:08.209097 26882 sgd_solver.cpp:106] Iteration 579000, lr = 0.004
I0526 09:40:47.333487 26882 solver.cpp:237] Iteration 580500, loss = 1.34789
I0526 09:40:47.333679 26882 solver.cpp:253]     Train net output #0: loss = 1.34788 (* 1 = 1.34788 loss)
I0526 09:40:47.333698 26882 sgd_solver.cpp:106] Iteration 580500, lr = 0.004
I0526 09:41:04.101866 26882 solver.cpp:237] Iteration 582000, loss = 0.760607
I0526 09:41:04.101904 26882 solver.cpp:253]     Train net output #0: loss = 0.760596 (* 1 = 0.760596 loss)
I0526 09:41:04.101923 26882 sgd_solver.cpp:106] Iteration 582000, lr = 0.004
I0526 09:41:20.985079 26882 solver.cpp:237] Iteration 583500, loss = 0.611793
I0526 09:41:20.985246 26882 solver.cpp:253]     Train net output #0: loss = 0.611782 (* 1 = 0.611782 loss)
I0526 09:41:20.985265 26882 sgd_solver.cpp:106] Iteration 583500, lr = 0.004
I0526 09:41:37.801389 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_585000.caffemodel
I0526 09:41:37.848698 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_585000.solverstate
I0526 09:41:37.879308 26882 solver.cpp:237] Iteration 585000, loss = 2.32273
I0526 09:41:37.879366 26882 solver.cpp:253]     Train net output #0: loss = 2.32272 (* 1 = 2.32272 loss)
I0526 09:41:37.879393 26882 sgd_solver.cpp:106] Iteration 585000, lr = 0.004
I0526 09:41:54.509433 26882 solver.cpp:237] Iteration 586500, loss = 0.310995
I0526 09:41:54.509593 26882 solver.cpp:253]     Train net output #0: loss = 0.310984 (* 1 = 0.310984 loss)
I0526 09:41:54.509616 26882 sgd_solver.cpp:106] Iteration 586500, lr = 0.004
I0526 09:42:11.266618 26882 solver.cpp:237] Iteration 588000, loss = 1.70332
I0526 09:42:11.266670 26882 solver.cpp:253]     Train net output #0: loss = 1.70331 (* 1 = 1.70331 loss)
I0526 09:42:11.266690 26882 sgd_solver.cpp:106] Iteration 588000, lr = 0.004
I0526 09:42:28.086228 26882 solver.cpp:237] Iteration 589500, loss = 0.557779
I0526 09:42:28.086400 26882 solver.cpp:253]     Train net output #0: loss = 0.557768 (* 1 = 0.557768 loss)
I0526 09:42:28.086418 26882 sgd_solver.cpp:106] Iteration 589500, lr = 0.004
I0526 09:43:07.191680 26882 solver.cpp:237] Iteration 591000, loss = 0.523098
I0526 09:43:07.191861 26882 solver.cpp:253]     Train net output #0: loss = 0.523087 (* 1 = 0.523087 loss)
I0526 09:43:07.191879 26882 sgd_solver.cpp:106] Iteration 591000, lr = 0.004
I0526 09:43:24.191606 26882 solver.cpp:237] Iteration 592500, loss = 1.97303
I0526 09:43:24.191663 26882 solver.cpp:253]     Train net output #0: loss = 1.97302 (* 1 = 1.97302 loss)
I0526 09:43:24.191681 26882 sgd_solver.cpp:106] Iteration 592500, lr = 0.004
I0526 09:43:41.178488 26882 solver.cpp:237] Iteration 594000, loss = 1.12294
I0526 09:43:41.178660 26882 solver.cpp:253]     Train net output #0: loss = 1.12293 (* 1 = 1.12293 loss)
I0526 09:43:41.178680 26882 sgd_solver.cpp:106] Iteration 594000, lr = 0.004
I0526 09:43:57.943482 26882 solver.cpp:237] Iteration 595500, loss = 1.34317
I0526 09:43:57.943521 26882 solver.cpp:253]     Train net output #0: loss = 1.34316 (* 1 = 1.34316 loss)
I0526 09:43:57.943538 26882 sgd_solver.cpp:106] Iteration 595500, lr = 0.004
I0526 09:44:15.048280 26882 solver.cpp:237] Iteration 597000, loss = 1.65591
I0526 09:44:15.048446 26882 solver.cpp:253]     Train net output #0: loss = 1.6559 (* 1 = 1.6559 loss)
I0526 09:44:15.048463 26882 sgd_solver.cpp:106] Iteration 597000, lr = 0.004
I0526 09:44:32.195969 26882 solver.cpp:237] Iteration 598500, loss = 0.382792
I0526 09:44:32.196029 26882 solver.cpp:253]     Train net output #0: loss = 0.382782 (* 1 = 0.382782 loss)
I0526 09:44:32.196054 26882 sgd_solver.cpp:106] Iteration 598500, lr = 0.004
I0526 09:44:49.232157 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_600000.caffemodel
I0526 09:44:49.279425 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_600000.solverstate
I0526 09:44:49.308583 26882 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 09:45:48.726548 26882 solver.cpp:409]     Test net output #0: accuracy = 0.891069
I0526 09:45:48.726722 26882 solver.cpp:409]     Test net output #1: loss = 0.36606 (* 1 = 0.36606 loss)
I0526 09:46:09.596652 26882 solver.cpp:237] Iteration 600000, loss = 0.793222
I0526 09:46:09.596715 26882 solver.cpp:253]     Train net output #0: loss = 0.793211 (* 1 = 0.793211 loss)
I0526 09:46:09.596745 26882 sgd_solver.cpp:106] Iteration 600000, lr = 0.004
I0526 09:46:26.547657 26882 solver.cpp:237] Iteration 601500, loss = 0.966487
I0526 09:46:26.547817 26882 solver.cpp:253]     Train net output #0: loss = 0.966477 (* 1 = 0.966477 loss)
I0526 09:46:26.547834 26882 sgd_solver.cpp:106] Iteration 601500, lr = 0.004
I0526 09:46:43.508529 26882 solver.cpp:237] Iteration 603000, loss = 0.996726
I0526 09:46:43.508586 26882 solver.cpp:253]     Train net output #0: loss = 0.996716 (* 1 = 0.996716 loss)
I0526 09:46:43.508605 26882 sgd_solver.cpp:106] Iteration 603000, lr = 0.004
I0526 09:47:00.485865 26882 solver.cpp:237] Iteration 604500, loss = 1.22145
I0526 09:47:00.486048 26882 solver.cpp:253]     Train net output #0: loss = 1.22144 (* 1 = 1.22144 loss)
I0526 09:47:00.486066 26882 sgd_solver.cpp:106] Iteration 604500, lr = 0.004
I0526 09:47:17.148188 26882 solver.cpp:237] Iteration 606000, loss = 0.810278
I0526 09:47:17.148227 26882 solver.cpp:253]     Train net output #0: loss = 0.810269 (* 1 = 0.810269 loss)
I0526 09:47:17.148244 26882 sgd_solver.cpp:106] Iteration 606000, lr = 0.004
I0526 09:47:33.960377 26882 solver.cpp:237] Iteration 607500, loss = 1.4977
I0526 09:47:33.960547 26882 solver.cpp:253]     Train net output #0: loss = 1.4977 (* 1 = 1.4977 loss)
I0526 09:47:33.960564 26882 sgd_solver.cpp:106] Iteration 607500, lr = 0.004
I0526 09:47:50.805943 26882 solver.cpp:237] Iteration 609000, loss = 0.89263
I0526 09:47:50.805999 26882 solver.cpp:253]     Train net output #0: loss = 0.892621 (* 1 = 0.892621 loss)
I0526 09:47:50.806016 26882 sgd_solver.cpp:106] Iteration 609000, lr = 0.004
I0526 09:48:28.449093 26882 solver.cpp:237] Iteration 610500, loss = 1.01748
I0526 09:48:28.449275 26882 solver.cpp:253]     Train net output #0: loss = 1.01748 (* 1 = 1.01748 loss)
I0526 09:48:28.449292 26882 sgd_solver.cpp:106] Iteration 610500, lr = 0.004
I0526 09:48:45.192493 26882 solver.cpp:237] Iteration 612000, loss = 1.20236
I0526 09:48:45.192551 26882 solver.cpp:253]     Train net output #0: loss = 1.20235 (* 1 = 1.20235 loss)
I0526 09:48:45.192569 26882 sgd_solver.cpp:106] Iteration 612000, lr = 0.004
I0526 09:49:01.828618 26882 solver.cpp:237] Iteration 613500, loss = 1.33479
I0526 09:49:01.828789 26882 solver.cpp:253]     Train net output #0: loss = 1.33478 (* 1 = 1.33478 loss)
I0526 09:49:01.828809 26882 sgd_solver.cpp:106] Iteration 613500, lr = 0.004
I0526 09:49:18.605115 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_615000.caffemodel
I0526 09:49:18.650931 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_615000.solverstate
I0526 09:49:18.679846 26882 solver.cpp:237] Iteration 615000, loss = 1.29036
I0526 09:49:18.679903 26882 solver.cpp:253]     Train net output #0: loss = 1.29035 (* 1 = 1.29035 loss)
I0526 09:49:18.679929 26882 sgd_solver.cpp:106] Iteration 615000, lr = 0.004
I0526 09:49:35.598448 26882 solver.cpp:237] Iteration 616500, loss = 1.02294
I0526 09:49:35.598623 26882 solver.cpp:253]     Train net output #0: loss = 1.02293 (* 1 = 1.02293 loss)
I0526 09:49:35.598639 26882 sgd_solver.cpp:106] Iteration 616500, lr = 0.004
I0526 09:49:52.595319 26882 solver.cpp:237] Iteration 618000, loss = 0.787392
I0526 09:49:52.595377 26882 solver.cpp:253]     Train net output #0: loss = 0.787382 (* 1 = 0.787382 loss)
I0526 09:49:52.595404 26882 sgd_solver.cpp:106] Iteration 618000, lr = 0.004
I0526 09:50:09.242569 26882 solver.cpp:237] Iteration 619500, loss = 0.479908
I0526 09:50:09.242724 26882 solver.cpp:253]     Train net output #0: loss = 0.4799 (* 1 = 0.4799 loss)
I0526 09:50:09.242741 26882 sgd_solver.cpp:106] Iteration 619500, lr = 0.004
I0526 09:50:46.803488 26882 solver.cpp:237] Iteration 621000, loss = 0.975845
I0526 09:50:46.803663 26882 solver.cpp:253]     Train net output #0: loss = 0.975836 (* 1 = 0.975836 loss)
I0526 09:50:46.803681 26882 sgd_solver.cpp:106] Iteration 621000, lr = 0.004
I0526 09:51:03.749914 26882 solver.cpp:237] Iteration 622500, loss = 1.14101
I0526 09:51:03.749953 26882 solver.cpp:253]     Train net output #0: loss = 1.141 (* 1 = 1.141 loss)
I0526 09:51:03.749971 26882 sgd_solver.cpp:106] Iteration 622500, lr = 0.004
I0526 09:51:20.621129 26882 solver.cpp:237] Iteration 624000, loss = 0.626925
I0526 09:51:20.621301 26882 solver.cpp:253]     Train net output #0: loss = 0.626916 (* 1 = 0.626916 loss)
I0526 09:51:20.621318 26882 sgd_solver.cpp:106] Iteration 624000, lr = 0.004
I0526 09:51:37.460443 26882 solver.cpp:237] Iteration 625500, loss = 0.902201
I0526 09:51:37.460500 26882 solver.cpp:253]     Train net output #0: loss = 0.902191 (* 1 = 0.902191 loss)
I0526 09:51:37.460516 26882 sgd_solver.cpp:106] Iteration 625500, lr = 0.004
I0526 09:51:54.084480 26882 solver.cpp:237] Iteration 627000, loss = 1.15041
I0526 09:51:54.084641 26882 solver.cpp:253]     Train net output #0: loss = 1.1504 (* 1 = 1.1504 loss)
I0526 09:51:54.084658 26882 sgd_solver.cpp:106] Iteration 627000, lr = 0.004
I0526 09:52:10.836978 26882 solver.cpp:237] Iteration 628500, loss = 1.25632
I0526 09:52:10.837036 26882 solver.cpp:253]     Train net output #0: loss = 1.25631 (* 1 = 1.25631 loss)
I0526 09:52:10.837054 26882 sgd_solver.cpp:106] Iteration 628500, lr = 0.004
I0526 09:52:27.696696 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_630000.caffemodel
I0526 09:52:27.746809 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_630000.solverstate
I0526 09:52:27.771984 26882 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 09:53:48.249085 26882 solver.cpp:409]     Test net output #0: accuracy = 0.887582
I0526 09:53:48.249255 26882 solver.cpp:409]     Test net output #1: loss = 0.365218 (* 1 = 0.365218 loss)
I0526 09:54:09.077164 26882 solver.cpp:237] Iteration 630000, loss = 0.753317
I0526 09:54:09.077230 26882 solver.cpp:253]     Train net output #0: loss = 0.753307 (* 1 = 0.753307 loss)
I0526 09:54:09.077260 26882 sgd_solver.cpp:106] Iteration 630000, lr = 0.004
I0526 09:54:25.738667 26882 solver.cpp:237] Iteration 631500, loss = 1.44655
I0526 09:54:25.738829 26882 solver.cpp:253]     Train net output #0: loss = 1.44654 (* 1 = 1.44654 loss)
I0526 09:54:25.738847 26882 sgd_solver.cpp:106] Iteration 631500, lr = 0.004
I0526 09:54:42.504079 26882 solver.cpp:237] Iteration 633000, loss = 0.710147
I0526 09:54:42.504138 26882 solver.cpp:253]     Train net output #0: loss = 0.710138 (* 1 = 0.710138 loss)
I0526 09:54:42.504156 26882 sgd_solver.cpp:106] Iteration 633000, lr = 0.004
I0526 09:54:59.208505 26882 solver.cpp:237] Iteration 634500, loss = 1.93062
I0526 09:54:59.208680 26882 solver.cpp:253]     Train net output #0: loss = 1.93061 (* 1 = 1.93061 loss)
I0526 09:54:59.208698 26882 sgd_solver.cpp:106] Iteration 634500, lr = 0.004
I0526 09:55:15.822583 26882 solver.cpp:237] Iteration 636000, loss = 1.39638
I0526 09:55:15.822621 26882 solver.cpp:253]     Train net output #0: loss = 1.39637 (* 1 = 1.39637 loss)
I0526 09:55:15.822641 26882 sgd_solver.cpp:106] Iteration 636000, lr = 0.004
I0526 09:55:32.414789 26882 solver.cpp:237] Iteration 637500, loss = 1.28942
I0526 09:55:32.414960 26882 solver.cpp:253]     Train net output #0: loss = 1.28941 (* 1 = 1.28941 loss)
I0526 09:55:32.414978 26882 sgd_solver.cpp:106] Iteration 637500, lr = 0.004
I0526 09:55:49.319466 26882 solver.cpp:237] Iteration 639000, loss = 1.36026
I0526 09:55:49.319521 26882 solver.cpp:253]     Train net output #0: loss = 1.36025 (* 1 = 1.36025 loss)
I0526 09:55:49.319540 26882 sgd_solver.cpp:106] Iteration 639000, lr = 0.004
I0526 09:56:27.439972 26882 solver.cpp:237] Iteration 640500, loss = 2.01848
I0526 09:56:27.440148 26882 solver.cpp:253]     Train net output #0: loss = 2.01847 (* 1 = 2.01847 loss)
I0526 09:56:27.440166 26882 sgd_solver.cpp:106] Iteration 640500, lr = 0.004
I0526 09:56:44.193001 26882 solver.cpp:237] Iteration 642000, loss = 1.17837
I0526 09:56:44.193056 26882 solver.cpp:253]     Train net output #0: loss = 1.17835 (* 1 = 1.17835 loss)
I0526 09:56:44.193073 26882 sgd_solver.cpp:106] Iteration 642000, lr = 0.004
I0526 09:57:00.931615 26882 solver.cpp:237] Iteration 643500, loss = 1.49905
I0526 09:57:00.931787 26882 solver.cpp:253]     Train net output #0: loss = 1.49904 (* 1 = 1.49904 loss)
I0526 09:57:00.931807 26882 sgd_solver.cpp:106] Iteration 643500, lr = 0.004
I0526 09:57:17.954221 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_645000.caffemodel
I0526 09:57:25.033505 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_645000.solverstate
I0526 09:57:25.077000 26882 solver.cpp:237] Iteration 645000, loss = 1.518
I0526 09:57:25.077059 26882 solver.cpp:253]     Train net output #0: loss = 1.51799 (* 1 = 1.51799 loss)
I0526 09:57:25.077086 26882 sgd_solver.cpp:106] Iteration 645000, lr = 0.004
I0526 09:57:42.115000 26882 solver.cpp:237] Iteration 646500, loss = 1.1266
I0526 09:57:42.115170 26882 solver.cpp:253]     Train net output #0: loss = 1.12659 (* 1 = 1.12659 loss)
I0526 09:57:42.115185 26882 sgd_solver.cpp:106] Iteration 646500, lr = 0.004
I0526 09:57:58.859268 26882 solver.cpp:237] Iteration 648000, loss = 1.13904
I0526 09:57:58.859328 26882 solver.cpp:253]     Train net output #0: loss = 1.13903 (* 1 = 1.13903 loss)
I0526 09:57:58.859344 26882 sgd_solver.cpp:106] Iteration 648000, lr = 0.004
I0526 09:58:15.495682 26882 solver.cpp:237] Iteration 649500, loss = 1.03951
I0526 09:58:15.495857 26882 solver.cpp:253]     Train net output #0: loss = 1.0395 (* 1 = 1.0395 loss)
I0526 09:58:15.495875 26882 sgd_solver.cpp:106] Iteration 649500, lr = 0.004
I0526 09:58:53.134100 26882 solver.cpp:237] Iteration 651000, loss = 1.02997
I0526 09:58:53.134284 26882 solver.cpp:253]     Train net output #0: loss = 1.02996 (* 1 = 1.02996 loss)
I0526 09:58:53.134300 26882 sgd_solver.cpp:106] Iteration 651000, lr = 0.004
I0526 09:59:09.997666 26882 solver.cpp:237] Iteration 652500, loss = 1.30159
I0526 09:59:09.997723 26882 solver.cpp:253]     Train net output #0: loss = 1.30158 (* 1 = 1.30158 loss)
I0526 09:59:09.997741 26882 sgd_solver.cpp:106] Iteration 652500, lr = 0.004
I0526 09:59:26.950105 26882 solver.cpp:237] Iteration 654000, loss = 1.29078
I0526 09:59:26.950273 26882 solver.cpp:253]     Train net output #0: loss = 1.29077 (* 1 = 1.29077 loss)
I0526 09:59:26.950290 26882 sgd_solver.cpp:106] Iteration 654000, lr = 0.004
I0526 09:59:43.754755 26882 solver.cpp:237] Iteration 655500, loss = 1.04384
I0526 09:59:43.754794 26882 solver.cpp:253]     Train net output #0: loss = 1.04383 (* 1 = 1.04383 loss)
I0526 09:59:43.754812 26882 sgd_solver.cpp:106] Iteration 655500, lr = 0.004
I0526 10:00:00.596854 26882 solver.cpp:237] Iteration 657000, loss = 0.981888
I0526 10:00:00.597043 26882 solver.cpp:253]     Train net output #0: loss = 0.981877 (* 1 = 0.981877 loss)
I0526 10:00:00.597060 26882 sgd_solver.cpp:106] Iteration 657000, lr = 0.004
I0526 10:00:17.479246 26882 solver.cpp:237] Iteration 658500, loss = 1.16958
I0526 10:00:17.479301 26882 solver.cpp:253]     Train net output #0: loss = 1.16957 (* 1 = 1.16957 loss)
I0526 10:00:17.479322 26882 sgd_solver.cpp:106] Iteration 658500, lr = 0.004
I0526 10:00:34.677872 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_660000.caffemodel
I0526 10:00:34.739621 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_660000.solverstate
I0526 10:00:34.765650 26882 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 10:01:34.030380 26882 solver.cpp:409]     Test net output #0: accuracy = 0.881947
I0526 10:01:34.030556 26882 solver.cpp:409]     Test net output #1: loss = 0.398593 (* 1 = 0.398593 loss)
I0526 10:01:54.933914 26882 solver.cpp:237] Iteration 660000, loss = 0.890454
I0526 10:01:54.933979 26882 solver.cpp:253]     Train net output #0: loss = 0.890443 (* 1 = 0.890443 loss)
I0526 10:01:54.933998 26882 sgd_solver.cpp:106] Iteration 660000, lr = 0.004
I0526 10:02:11.941676 26882 solver.cpp:237] Iteration 661500, loss = 0.868611
I0526 10:02:11.941855 26882 solver.cpp:253]     Train net output #0: loss = 0.868598 (* 1 = 0.868598 loss)
I0526 10:02:11.941872 26882 sgd_solver.cpp:106] Iteration 661500, lr = 0.004
I0526 10:02:28.959004 26882 solver.cpp:237] Iteration 663000, loss = 0.671261
I0526 10:02:28.959062 26882 solver.cpp:253]     Train net output #0: loss = 0.671248 (* 1 = 0.671248 loss)
I0526 10:02:28.959079 26882 sgd_solver.cpp:106] Iteration 663000, lr = 0.004
I0526 10:02:45.916118 26882 solver.cpp:237] Iteration 664500, loss = 1.31866
I0526 10:02:45.916285 26882 solver.cpp:253]     Train net output #0: loss = 1.31865 (* 1 = 1.31865 loss)
I0526 10:02:45.916302 26882 sgd_solver.cpp:106] Iteration 664500, lr = 0.004
I0526 10:03:02.554132 26882 solver.cpp:237] Iteration 666000, loss = 1.11635
I0526 10:03:02.554189 26882 solver.cpp:253]     Train net output #0: loss = 1.11634 (* 1 = 1.11634 loss)
I0526 10:03:02.554208 26882 sgd_solver.cpp:106] Iteration 666000, lr = 0.004
I0526 10:03:19.431114 26882 solver.cpp:237] Iteration 667500, loss = 1.1099
I0526 10:03:19.431288 26882 solver.cpp:253]     Train net output #0: loss = 1.10989 (* 1 = 1.10989 loss)
I0526 10:03:19.431305 26882 sgd_solver.cpp:106] Iteration 667500, lr = 0.004
I0526 10:03:36.634182 26882 solver.cpp:237] Iteration 669000, loss = 1.47252
I0526 10:03:36.634219 26882 solver.cpp:253]     Train net output #0: loss = 1.47251 (* 1 = 1.47251 loss)
I0526 10:03:36.634238 26882 sgd_solver.cpp:106] Iteration 669000, lr = 0.004
I0526 10:04:15.485015 26882 solver.cpp:237] Iteration 670500, loss = 1.62147
I0526 10:04:15.485195 26882 solver.cpp:253]     Train net output #0: loss = 1.62146 (* 1 = 1.62146 loss)
I0526 10:04:15.485213 26882 sgd_solver.cpp:106] Iteration 670500, lr = 0.004
I0526 10:04:32.381091 26882 solver.cpp:237] Iteration 672000, loss = 0.672694
I0526 10:04:32.381146 26882 solver.cpp:253]     Train net output #0: loss = 0.67268 (* 1 = 0.67268 loss)
I0526 10:04:32.381173 26882 sgd_solver.cpp:106] Iteration 672000, lr = 0.004
I0526 10:04:48.996029 26882 solver.cpp:237] Iteration 673500, loss = 1.22969
I0526 10:04:48.996187 26882 solver.cpp:253]     Train net output #0: loss = 1.22967 (* 1 = 1.22967 loss)
I0526 10:04:48.996204 26882 sgd_solver.cpp:106] Iteration 673500, lr = 0.004
I0526 10:05:05.954057 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_675000.caffemodel
I0526 10:05:06.011802 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_675000.solverstate
I0526 10:05:06.044756 26882 solver.cpp:237] Iteration 675000, loss = 1.10196
I0526 10:05:06.044822 26882 solver.cpp:253]     Train net output #0: loss = 1.10195 (* 1 = 1.10195 loss)
I0526 10:05:06.044841 26882 sgd_solver.cpp:106] Iteration 675000, lr = 0.004
I0526 10:05:22.962857 26882 solver.cpp:237] Iteration 676500, loss = 1.48163
I0526 10:05:22.963037 26882 solver.cpp:253]     Train net output #0: loss = 1.48162 (* 1 = 1.48162 loss)
I0526 10:05:22.963057 26882 sgd_solver.cpp:106] Iteration 676500, lr = 0.004
I0526 10:05:39.604322 26882 solver.cpp:237] Iteration 678000, loss = 0.917737
I0526 10:05:39.604364 26882 solver.cpp:253]     Train net output #0: loss = 0.917723 (* 1 = 0.917723 loss)
I0526 10:05:39.604382 26882 sgd_solver.cpp:106] Iteration 678000, lr = 0.004
I0526 10:05:56.506551 26882 solver.cpp:237] Iteration 679500, loss = 1.10294
I0526 10:05:56.506723 26882 solver.cpp:253]     Train net output #0: loss = 1.10293 (* 1 = 1.10293 loss)
I0526 10:05:56.506741 26882 sgd_solver.cpp:106] Iteration 679500, lr = 0.004
I0526 10:06:34.476588 26882 solver.cpp:237] Iteration 681000, loss = 1.30541
I0526 10:06:34.476769 26882 solver.cpp:253]     Train net output #0: loss = 1.3054 (* 1 = 1.3054 loss)
I0526 10:06:34.476789 26882 sgd_solver.cpp:106] Iteration 681000, lr = 0.004
I0526 10:06:51.632263 26882 solver.cpp:237] Iteration 682500, loss = 0.929385
I0526 10:06:51.632302 26882 solver.cpp:253]     Train net output #0: loss = 0.929372 (* 1 = 0.929372 loss)
I0526 10:06:51.632320 26882 sgd_solver.cpp:106] Iteration 682500, lr = 0.004
I0526 10:07:08.660226 26882 solver.cpp:237] Iteration 684000, loss = 1.08067
I0526 10:07:08.660413 26882 solver.cpp:253]     Train net output #0: loss = 1.08065 (* 1 = 1.08065 loss)
I0526 10:07:08.660429 26882 sgd_solver.cpp:106] Iteration 684000, lr = 0.004
I0526 10:07:25.648254 26882 solver.cpp:237] Iteration 685500, loss = 1.05901
I0526 10:07:25.648313 26882 solver.cpp:253]     Train net output #0: loss = 1.059 (* 1 = 1.059 loss)
I0526 10:07:25.648339 26882 sgd_solver.cpp:106] Iteration 685500, lr = 0.004
I0526 10:07:42.699349 26882 solver.cpp:237] Iteration 687000, loss = 1.24119
I0526 10:07:42.699508 26882 solver.cpp:253]     Train net output #0: loss = 1.24118 (* 1 = 1.24118 loss)
I0526 10:07:42.699525 26882 sgd_solver.cpp:106] Iteration 687000, lr = 0.004
I0526 10:07:59.464006 26882 solver.cpp:237] Iteration 688500, loss = 0.75041
I0526 10:07:59.464064 26882 solver.cpp:253]     Train net output #0: loss = 0.750396 (* 1 = 0.750396 loss)
I0526 10:07:59.464082 26882 sgd_solver.cpp:106] Iteration 688500, lr = 0.004
I0526 10:08:16.247545 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_690000.caffemodel
I0526 10:08:16.511037 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_690000.solverstate
I0526 10:08:16.536875 26882 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 10:09:37.952953 26882 solver.cpp:409]     Test net output #0: accuracy = 0.887559
I0526 10:09:37.953130 26882 solver.cpp:409]     Test net output #1: loss = 0.389026 (* 1 = 0.389026 loss)
I0526 10:10:02.343235 26882 solver.cpp:237] Iteration 690000, loss = 1.81588
I0526 10:10:02.343297 26882 solver.cpp:253]     Train net output #0: loss = 1.81587 (* 1 = 1.81587 loss)
I0526 10:10:02.343315 26882 sgd_solver.cpp:106] Iteration 690000, lr = 0.004
I0526 10:10:19.008309 26882 solver.cpp:237] Iteration 691500, loss = 0.638237
I0526 10:10:19.008492 26882 solver.cpp:253]     Train net output #0: loss = 0.638222 (* 1 = 0.638222 loss)
I0526 10:10:19.008510 26882 sgd_solver.cpp:106] Iteration 691500, lr = 0.004
I0526 10:10:35.764623 26882 solver.cpp:237] Iteration 693000, loss = 1.14291
I0526 10:10:35.764663 26882 solver.cpp:253]     Train net output #0: loss = 1.14289 (* 1 = 1.14289 loss)
I0526 10:10:35.764683 26882 sgd_solver.cpp:106] Iteration 693000, lr = 0.004
I0526 10:10:52.746422 26882 solver.cpp:237] Iteration 694500, loss = 0.548697
I0526 10:10:52.746600 26882 solver.cpp:253]     Train net output #0: loss = 0.548685 (* 1 = 0.548685 loss)
I0526 10:10:52.746618 26882 sgd_solver.cpp:106] Iteration 694500, lr = 0.004
I0526 10:11:09.733134 26882 solver.cpp:237] Iteration 696000, loss = 0.745718
I0526 10:11:09.733191 26882 solver.cpp:253]     Train net output #0: loss = 0.745707 (* 1 = 0.745707 loss)
I0526 10:11:09.733211 26882 sgd_solver.cpp:106] Iteration 696000, lr = 0.004
I0526 10:11:26.357218 26882 solver.cpp:237] Iteration 697500, loss = 1.09305
I0526 10:11:26.357374 26882 solver.cpp:253]     Train net output #0: loss = 1.09304 (* 1 = 1.09304 loss)
I0526 10:11:26.357390 26882 sgd_solver.cpp:106] Iteration 697500, lr = 0.004
I0526 10:11:43.135486 26882 solver.cpp:237] Iteration 699000, loss = 0.991826
I0526 10:11:43.135542 26882 solver.cpp:253]     Train net output #0: loss = 0.991814 (* 1 = 0.991814 loss)
I0526 10:11:43.135560 26882 sgd_solver.cpp:106] Iteration 699000, lr = 0.004
I0526 10:12:24.553236 26882 solver.cpp:237] Iteration 700500, loss = 1.34429
I0526 10:12:24.553416 26882 solver.cpp:253]     Train net output #0: loss = 1.34428 (* 1 = 1.34428 loss)
I0526 10:12:24.553432 26882 sgd_solver.cpp:106] Iteration 700500, lr = 0.004
I0526 10:12:41.480587 26882 solver.cpp:237] Iteration 702000, loss = 1.23252
I0526 10:12:41.480625 26882 solver.cpp:253]     Train net output #0: loss = 1.23251 (* 1 = 1.23251 loss)
I0526 10:12:41.480644 26882 sgd_solver.cpp:106] Iteration 702000, lr = 0.004
I0526 10:12:58.411133 26882 solver.cpp:237] Iteration 703500, loss = 0.898357
I0526 10:12:58.411321 26882 solver.cpp:253]     Train net output #0: loss = 0.898345 (* 1 = 0.898345 loss)
I0526 10:12:58.411339 26882 sgd_solver.cpp:106] Iteration 703500, lr = 0.004
I0526 10:13:15.265132 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_705000.caffemodel
I0526 10:13:15.324791 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_705000.solverstate
I0526 10:13:15.359741 26882 solver.cpp:237] Iteration 705000, loss = 2.86392
I0526 10:13:15.359797 26882 solver.cpp:253]     Train net output #0: loss = 2.86391 (* 1 = 2.86391 loss)
I0526 10:13:15.359817 26882 sgd_solver.cpp:106] Iteration 705000, lr = 0.004
I0526 10:13:32.308084 26882 solver.cpp:237] Iteration 706500, loss = 1.43627
I0526 10:13:32.308250 26882 solver.cpp:253]     Train net output #0: loss = 1.43626 (* 1 = 1.43626 loss)
I0526 10:13:32.308267 26882 sgd_solver.cpp:106] Iteration 706500, lr = 0.004
I0526 10:13:49.209156 26882 solver.cpp:237] Iteration 708000, loss = 1.2308
I0526 10:13:49.209213 26882 solver.cpp:253]     Train net output #0: loss = 1.23079 (* 1 = 1.23079 loss)
I0526 10:13:49.209231 26882 sgd_solver.cpp:106] Iteration 708000, lr = 0.004
I0526 10:14:06.106283 26882 solver.cpp:237] Iteration 709500, loss = 1.39442
I0526 10:14:06.106464 26882 solver.cpp:253]     Train net output #0: loss = 1.39441 (* 1 = 1.39441 loss)
I0526 10:14:06.106482 26882 sgd_solver.cpp:106] Iteration 709500, lr = 0.004
I0526 10:14:57.017789 26882 solver.cpp:237] Iteration 711000, loss = 1.85329
I0526 10:14:57.017967 26882 solver.cpp:253]     Train net output #0: loss = 1.85328 (* 1 = 1.85328 loss)
I0526 10:14:57.017984 26882 sgd_solver.cpp:106] Iteration 711000, lr = 0.004
I0526 10:15:13.635318 26882 solver.cpp:237] Iteration 712500, loss = 1.66357
I0526 10:15:13.635356 26882 solver.cpp:253]     Train net output #0: loss = 1.66356 (* 1 = 1.66356 loss)
I0526 10:15:13.635375 26882 sgd_solver.cpp:106] Iteration 712500, lr = 0.004
I0526 10:15:30.517122 26882 solver.cpp:237] Iteration 714000, loss = 1.72318
I0526 10:15:30.517297 26882 solver.cpp:253]     Train net output #0: loss = 1.72317 (* 1 = 1.72317 loss)
I0526 10:15:30.517313 26882 sgd_solver.cpp:106] Iteration 714000, lr = 0.004
I0526 10:15:47.399127 26882 solver.cpp:237] Iteration 715500, loss = 1.04744
I0526 10:15:47.399186 26882 solver.cpp:253]     Train net output #0: loss = 1.04743 (* 1 = 1.04743 loss)
I0526 10:15:47.399212 26882 sgd_solver.cpp:106] Iteration 715500, lr = 0.004
I0526 10:16:04.195458 26882 solver.cpp:237] Iteration 717000, loss = 1.02856
I0526 10:16:04.195618 26882 solver.cpp:253]     Train net output #0: loss = 1.02855 (* 1 = 1.02855 loss)
I0526 10:16:04.195636 26882 sgd_solver.cpp:106] Iteration 717000, lr = 0.004
I0526 10:16:21.018857 26882 solver.cpp:237] Iteration 718500, loss = 1.42434
I0526 10:16:21.018913 26882 solver.cpp:253]     Train net output #0: loss = 1.42433 (* 1 = 1.42433 loss)
I0526 10:16:21.018931 26882 sgd_solver.cpp:106] Iteration 718500, lr = 0.004
I0526 10:16:37.624948 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_720000.caffemodel
I0526 10:16:37.689118 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_720000.solverstate
I0526 10:16:37.722556 26882 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 10:17:41.234928 26882 solver.cpp:409]     Test net output #0: accuracy = 0.887403
I0526 10:17:41.235111 26882 solver.cpp:409]     Test net output #1: loss = 0.346208 (* 1 = 0.346208 loss)
I0526 10:18:02.116314 26882 solver.cpp:237] Iteration 720000, loss = 2.04626
I0526 10:18:02.116375 26882 solver.cpp:253]     Train net output #0: loss = 2.04625 (* 1 = 2.04625 loss)
I0526 10:18:02.116401 26882 sgd_solver.cpp:106] Iteration 720000, lr = 0.004
I0526 10:18:19.177031 26882 solver.cpp:237] Iteration 721500, loss = 1.53504
I0526 10:18:19.177227 26882 solver.cpp:253]     Train net output #0: loss = 1.53503 (* 1 = 1.53503 loss)
I0526 10:18:19.177245 26882 sgd_solver.cpp:106] Iteration 721500, lr = 0.004
I0526 10:18:36.051471 26882 solver.cpp:237] Iteration 723000, loss = 1.12101
I0526 10:18:36.051509 26882 solver.cpp:253]     Train net output #0: loss = 1.121 (* 1 = 1.121 loss)
I0526 10:18:36.051534 26882 sgd_solver.cpp:106] Iteration 723000, lr = 0.004
I0526 10:18:53.240535 26882 solver.cpp:237] Iteration 724500, loss = 0.840184
I0526 10:18:53.240717 26882 solver.cpp:253]     Train net output #0: loss = 0.840172 (* 1 = 0.840172 loss)
I0526 10:18:53.240734 26882 sgd_solver.cpp:106] Iteration 724500, lr = 0.004
I0526 10:19:10.142957 26882 solver.cpp:237] Iteration 726000, loss = 0.94301
I0526 10:19:10.143016 26882 solver.cpp:253]     Train net output #0: loss = 0.942998 (* 1 = 0.942998 loss)
I0526 10:19:10.143034 26882 sgd_solver.cpp:106] Iteration 726000, lr = 0.004
I0526 10:19:26.781671 26882 solver.cpp:237] Iteration 727500, loss = 0.802871
I0526 10:19:26.781848 26882 solver.cpp:253]     Train net output #0: loss = 0.802859 (* 1 = 0.802859 loss)
I0526 10:19:26.781867 26882 sgd_solver.cpp:106] Iteration 727500, lr = 0.004
I0526 10:19:43.562223 26882 solver.cpp:237] Iteration 729000, loss = 1.38349
I0526 10:19:43.562263 26882 solver.cpp:253]     Train net output #0: loss = 1.38347 (* 1 = 1.38347 loss)
I0526 10:19:43.562279 26882 sgd_solver.cpp:106] Iteration 729000, lr = 0.004
I0526 10:20:21.198212 26882 solver.cpp:237] Iteration 730500, loss = 1.309
I0526 10:20:21.198400 26882 solver.cpp:253]     Train net output #0: loss = 1.30898 (* 1 = 1.30898 loss)
I0526 10:20:21.198421 26882 sgd_solver.cpp:106] Iteration 730500, lr = 0.004
I0526 10:20:38.105880 26882 solver.cpp:237] Iteration 732000, loss = 0.95039
I0526 10:20:38.105921 26882 solver.cpp:253]     Train net output #0: loss = 0.950378 (* 1 = 0.950378 loss)
I0526 10:20:38.105937 26882 sgd_solver.cpp:106] Iteration 732000, lr = 0.004
I0526 10:20:54.803884 26882 solver.cpp:237] Iteration 733500, loss = 1.85975
I0526 10:20:54.804061 26882 solver.cpp:253]     Train net output #0: loss = 1.85973 (* 1 = 1.85973 loss)
I0526 10:20:54.804078 26882 sgd_solver.cpp:106] Iteration 733500, lr = 0.004
I0526 10:21:11.563261 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_735000.caffemodel
I0526 10:21:11.698729 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_735000.solverstate
I0526 10:21:11.836676 26882 solver.cpp:237] Iteration 735000, loss = 1.52666
I0526 10:21:11.836735 26882 solver.cpp:253]     Train net output #0: loss = 1.52665 (* 1 = 1.52665 loss)
I0526 10:21:11.836763 26882 sgd_solver.cpp:106] Iteration 735000, lr = 0.004
I0526 10:21:29.053256 26882 solver.cpp:237] Iteration 736500, loss = 0.96239
I0526 10:21:29.053417 26882 solver.cpp:253]     Train net output #0: loss = 0.962379 (* 1 = 0.962379 loss)
I0526 10:21:29.053434 26882 sgd_solver.cpp:106] Iteration 736500, lr = 0.004
I0526 10:21:45.755839 26882 solver.cpp:237] Iteration 738000, loss = 2.84593
I0526 10:21:45.755898 26882 solver.cpp:253]     Train net output #0: loss = 2.84592 (* 1 = 2.84592 loss)
I0526 10:21:45.755915 26882 sgd_solver.cpp:106] Iteration 738000, lr = 0.004
I0526 10:22:02.591275 26882 solver.cpp:237] Iteration 739500, loss = 1.12242
I0526 10:22:02.591451 26882 solver.cpp:253]     Train net output #0: loss = 1.12241 (* 1 = 1.12241 loss)
I0526 10:22:02.591469 26882 sgd_solver.cpp:106] Iteration 739500, lr = 0.004
I0526 10:22:40.771334 26882 solver.cpp:237] Iteration 741000, loss = 0.920318
I0526 10:22:40.771531 26882 solver.cpp:253]     Train net output #0: loss = 0.920306 (* 1 = 0.920306 loss)
I0526 10:22:40.771549 26882 sgd_solver.cpp:106] Iteration 741000, lr = 0.004
I0526 10:22:57.772914 26882 solver.cpp:237] Iteration 742500, loss = 0.878433
I0526 10:22:57.772969 26882 solver.cpp:253]     Train net output #0: loss = 0.878421 (* 1 = 0.878421 loss)
I0526 10:22:57.772986 26882 sgd_solver.cpp:106] Iteration 742500, lr = 0.004
I0526 10:23:14.667207 26882 solver.cpp:237] Iteration 744000, loss = 1.68019
I0526 10:23:14.667387 26882 solver.cpp:253]     Train net output #0: loss = 1.68018 (* 1 = 1.68018 loss)
I0526 10:23:14.667403 26882 sgd_solver.cpp:106] Iteration 744000, lr = 0.004
I0526 10:23:31.450350 26882 solver.cpp:237] Iteration 745500, loss = 1.21731
I0526 10:23:31.450388 26882 solver.cpp:253]     Train net output #0: loss = 1.2173 (* 1 = 1.2173 loss)
I0526 10:23:31.450405 26882 sgd_solver.cpp:106] Iteration 745500, lr = 0.004
I0526 10:23:48.107887 26882 solver.cpp:237] Iteration 747000, loss = 1.60033
I0526 10:23:48.108064 26882 solver.cpp:253]     Train net output #0: loss = 1.60032 (* 1 = 1.60032 loss)
I0526 10:23:48.108081 26882 sgd_solver.cpp:106] Iteration 747000, lr = 0.004
I0526 10:24:04.751021 26882 solver.cpp:237] Iteration 748500, loss = 0.960219
I0526 10:24:04.751081 26882 solver.cpp:253]     Train net output #0: loss = 0.960208 (* 1 = 0.960208 loss)
I0526 10:24:04.751106 26882 sgd_solver.cpp:106] Iteration 748500, lr = 0.004
I0526 10:24:21.497639 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_750000.caffemodel
I0526 10:24:23.612614 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_750000.solverstate
I0526 10:24:23.659540 26882 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 10:26:03.212105 26882 solver.cpp:409]     Test net output #0: accuracy = 0.89262
I0526 10:26:03.212291 26882 solver.cpp:409]     Test net output #1: loss = 0.343854 (* 1 = 0.343854 loss)
I0526 10:26:25.876536 26882 solver.cpp:237] Iteration 750000, loss = 0.819405
I0526 10:26:25.876598 26882 solver.cpp:253]     Train net output #0: loss = 0.819394 (* 1 = 0.819394 loss)
I0526 10:26:25.876618 26882 sgd_solver.cpp:106] Iteration 750000, lr = 0.004
I0526 10:26:42.663965 26882 solver.cpp:237] Iteration 751500, loss = 1.3425
I0526 10:26:42.664144 26882 solver.cpp:253]     Train net output #0: loss = 1.34249 (* 1 = 1.34249 loss)
I0526 10:26:42.664161 26882 sgd_solver.cpp:106] Iteration 751500, lr = 0.004
I0526 10:26:59.349848 26882 solver.cpp:237] Iteration 753000, loss = 1.13825
I0526 10:26:59.349900 26882 solver.cpp:253]     Train net output #0: loss = 1.13824 (* 1 = 1.13824 loss)
I0526 10:26:59.349916 26882 sgd_solver.cpp:106] Iteration 753000, lr = 0.004
I0526 10:27:16.329170 26882 solver.cpp:237] Iteration 754500, loss = 1.38684
I0526 10:27:16.329331 26882 solver.cpp:253]     Train net output #0: loss = 1.38684 (* 1 = 1.38684 loss)
I0526 10:27:16.329349 26882 sgd_solver.cpp:106] Iteration 754500, lr = 0.004
I0526 10:27:33.448201 26882 solver.cpp:237] Iteration 756000, loss = 1.26483
I0526 10:27:33.448254 26882 solver.cpp:253]     Train net output #0: loss = 1.26482 (* 1 = 1.26482 loss)
I0526 10:27:33.448273 26882 sgd_solver.cpp:106] Iteration 756000, lr = 0.004
I0526 10:27:50.628968 26882 solver.cpp:237] Iteration 757500, loss = 0.896261
I0526 10:27:50.629148 26882 solver.cpp:253]     Train net output #0: loss = 0.896252 (* 1 = 0.896252 loss)
I0526 10:27:50.629166 26882 sgd_solver.cpp:106] Iteration 757500, lr = 0.004
I0526 10:28:07.567898 26882 solver.cpp:237] Iteration 759000, loss = 0.783969
I0526 10:28:07.567936 26882 solver.cpp:253]     Train net output #0: loss = 0.78396 (* 1 = 0.78396 loss)
I0526 10:28:07.567955 26882 sgd_solver.cpp:106] Iteration 759000, lr = 0.004
I0526 10:28:45.270421 26882 solver.cpp:237] Iteration 760500, loss = 1.05298
I0526 10:28:45.270620 26882 solver.cpp:253]     Train net output #0: loss = 1.05297 (* 1 = 1.05297 loss)
I0526 10:28:45.270638 26882 sgd_solver.cpp:106] Iteration 760500, lr = 0.004
I0526 10:29:02.053076 26882 solver.cpp:237] Iteration 762000, loss = 1.07527
I0526 10:29:02.053135 26882 solver.cpp:253]     Train net output #0: loss = 1.07526 (* 1 = 1.07526 loss)
I0526 10:29:02.053161 26882 sgd_solver.cpp:106] Iteration 762000, lr = 0.004
I0526 10:29:18.827574 26882 solver.cpp:237] Iteration 763500, loss = 1.03405
I0526 10:29:18.827738 26882 solver.cpp:253]     Train net output #0: loss = 1.03404 (* 1 = 1.03404 loss)
I0526 10:29:18.827754 26882 sgd_solver.cpp:106] Iteration 763500, lr = 0.004
I0526 10:29:35.769779 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_765000.caffemodel
I0526 10:29:35.890529 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_765000.solverstate
I0526 10:29:35.927778 26882 solver.cpp:237] Iteration 765000, loss = 0.417061
I0526 10:29:35.927834 26882 solver.cpp:253]     Train net output #0: loss = 0.417053 (* 1 = 0.417053 loss)
I0526 10:29:35.927855 26882 sgd_solver.cpp:106] Iteration 765000, lr = 0.004
I0526 10:29:52.987442 26882 solver.cpp:237] Iteration 766500, loss = 1.41865
I0526 10:29:52.987625 26882 solver.cpp:253]     Train net output #0: loss = 1.41864 (* 1 = 1.41864 loss)
I0526 10:29:52.987644 26882 sgd_solver.cpp:106] Iteration 766500, lr = 0.004
I0526 10:30:09.761003 26882 solver.cpp:237] Iteration 768000, loss = 0.935775
I0526 10:30:09.761044 26882 solver.cpp:253]     Train net output #0: loss = 0.935768 (* 1 = 0.935768 loss)
I0526 10:30:09.761060 26882 sgd_solver.cpp:106] Iteration 768000, lr = 0.004
I0526 10:30:26.689282 26882 solver.cpp:237] Iteration 769500, loss = 0.908404
I0526 10:30:26.689465 26882 solver.cpp:253]     Train net output #0: loss = 0.908396 (* 1 = 0.908396 loss)
I0526 10:30:26.689483 26882 sgd_solver.cpp:106] Iteration 769500, lr = 0.004
I0526 10:31:09.549823 26882 solver.cpp:237] Iteration 771000, loss = 1.13191
I0526 10:31:09.550005 26882 solver.cpp:253]     Train net output #0: loss = 1.13191 (* 1 = 1.13191 loss)
I0526 10:31:09.550024 26882 sgd_solver.cpp:106] Iteration 771000, lr = 0.004
I0526 10:31:26.318289 26882 solver.cpp:237] Iteration 772500, loss = 0.761695
I0526 10:31:26.318328 26882 solver.cpp:253]     Train net output #0: loss = 0.761686 (* 1 = 0.761686 loss)
I0526 10:31:26.318346 26882 sgd_solver.cpp:106] Iteration 772500, lr = 0.004
I0526 10:31:43.385642 26882 solver.cpp:237] Iteration 774000, loss = 1.2318
I0526 10:31:43.385825 26882 solver.cpp:253]     Train net output #0: loss = 1.23179 (* 1 = 1.23179 loss)
I0526 10:31:43.385843 26882 sgd_solver.cpp:106] Iteration 774000, lr = 0.004
I0526 10:32:00.538231 26882 solver.cpp:237] Iteration 775500, loss = 1.49595
I0526 10:32:00.538285 26882 solver.cpp:253]     Train net output #0: loss = 1.49594 (* 1 = 1.49594 loss)
I0526 10:32:00.538302 26882 sgd_solver.cpp:106] Iteration 775500, lr = 0.004
I0526 10:32:17.486766 26882 solver.cpp:237] Iteration 777000, loss = 1.26604
I0526 10:32:17.486929 26882 solver.cpp:253]     Train net output #0: loss = 1.26603 (* 1 = 1.26603 loss)
I0526 10:32:17.486946 26882 sgd_solver.cpp:106] Iteration 777000, lr = 0.004
I0526 10:32:34.296735 26882 solver.cpp:237] Iteration 778500, loss = 1.10371
I0526 10:32:34.296792 26882 solver.cpp:253]     Train net output #0: loss = 1.1037 (* 1 = 1.1037 loss)
I0526 10:32:34.296808 26882 sgd_solver.cpp:106] Iteration 778500, lr = 0.004
I0526 10:32:51.171818 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_780000.caffemodel
I0526 10:32:51.217965 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_780000.solverstate
I0526 10:32:51.242995 26882 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 10:33:50.471875 26882 solver.cpp:409]     Test net output #0: accuracy = 0.889867
I0526 10:33:50.472065 26882 solver.cpp:409]     Test net output #1: loss = 0.354067 (* 1 = 0.354067 loss)
I0526 10:34:11.310508 26882 solver.cpp:237] Iteration 780000, loss = 1.6621
I0526 10:34:11.310571 26882 solver.cpp:253]     Train net output #0: loss = 1.66209 (* 1 = 1.66209 loss)
I0526 10:34:11.310590 26882 sgd_solver.cpp:106] Iteration 780000, lr = 0.004
I0526 10:34:28.124635 26882 solver.cpp:237] Iteration 781500, loss = 1.16217
I0526 10:34:28.124819 26882 solver.cpp:253]     Train net output #0: loss = 1.16216 (* 1 = 1.16216 loss)
I0526 10:34:28.124837 26882 sgd_solver.cpp:106] Iteration 781500, lr = 0.004
I0526 10:34:44.760124 26882 solver.cpp:237] Iteration 783000, loss = 1.0469
I0526 10:34:44.760169 26882 solver.cpp:253]     Train net output #0: loss = 1.04689 (* 1 = 1.04689 loss)
I0526 10:34:44.760185 26882 sgd_solver.cpp:106] Iteration 783000, lr = 0.004
I0526 10:35:01.612206 26882 solver.cpp:237] Iteration 784500, loss = 1.60755
I0526 10:35:01.612391 26882 solver.cpp:253]     Train net output #0: loss = 1.60754 (* 1 = 1.60754 loss)
I0526 10:35:01.612409 26882 sgd_solver.cpp:106] Iteration 784500, lr = 0.004
I0526 10:35:18.641441 26882 solver.cpp:237] Iteration 786000, loss = 1.30575
I0526 10:35:18.641497 26882 solver.cpp:253]     Train net output #0: loss = 1.30574 (* 1 = 1.30574 loss)
I0526 10:35:18.641515 26882 sgd_solver.cpp:106] Iteration 786000, lr = 0.004
I0526 10:35:35.608834 26882 solver.cpp:237] Iteration 787500, loss = 1.94609
I0526 10:35:35.609001 26882 solver.cpp:253]     Train net output #0: loss = 1.94608 (* 1 = 1.94608 loss)
I0526 10:35:35.609019 26882 sgd_solver.cpp:106] Iteration 787500, lr = 0.004
I0526 10:35:52.569167 26882 solver.cpp:237] Iteration 789000, loss = 0.996645
I0526 10:35:52.569226 26882 solver.cpp:253]     Train net output #0: loss = 0.996633 (* 1 = 0.996633 loss)
I0526 10:35:52.569243 26882 sgd_solver.cpp:106] Iteration 789000, lr = 0.004
I0526 10:36:30.344820 26882 solver.cpp:237] Iteration 790500, loss = 1.15431
I0526 10:36:30.345011 26882 solver.cpp:253]     Train net output #0: loss = 1.1543 (* 1 = 1.1543 loss)
I0526 10:36:30.345029 26882 sgd_solver.cpp:106] Iteration 790500, lr = 0.004
I0526 10:36:47.244854 26882 solver.cpp:237] Iteration 792000, loss = 0.714774
I0526 10:36:47.244910 26882 solver.cpp:253]     Train net output #0: loss = 0.714763 (* 1 = 0.714763 loss)
I0526 10:36:47.244928 26882 sgd_solver.cpp:106] Iteration 792000, lr = 0.004
I0526 10:37:04.142566 26882 solver.cpp:237] Iteration 793500, loss = 1.15441
I0526 10:37:04.142747 26882 solver.cpp:253]     Train net output #0: loss = 1.1544 (* 1 = 1.1544 loss)
I0526 10:37:04.142765 26882 sgd_solver.cpp:106] Iteration 793500, lr = 0.004
I0526 10:37:21.072437 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_795000.caffemodel
I0526 10:37:21.118088 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_795000.solverstate
I0526 10:37:21.147106 26882 solver.cpp:237] Iteration 795000, loss = 0.739696
I0526 10:37:21.147166 26882 solver.cpp:253]     Train net output #0: loss = 0.739685 (* 1 = 0.739685 loss)
I0526 10:37:21.147186 26882 sgd_solver.cpp:106] Iteration 795000, lr = 0.004
I0526 10:37:38.022271 26882 solver.cpp:237] Iteration 796500, loss = 1.02861
I0526 10:37:38.022455 26882 solver.cpp:253]     Train net output #0: loss = 1.0286 (* 1 = 1.0286 loss)
I0526 10:37:38.022474 26882 sgd_solver.cpp:106] Iteration 796500, lr = 0.004
I0526 10:37:54.985333 26882 solver.cpp:237] Iteration 798000, loss = 1.11519
I0526 10:37:54.985391 26882 solver.cpp:253]     Train net output #0: loss = 1.11518 (* 1 = 1.11518 loss)
I0526 10:37:54.985409 26882 sgd_solver.cpp:106] Iteration 798000, lr = 0.004
I0526 10:38:12.029173 26882 solver.cpp:237] Iteration 799500, loss = 1.36681
I0526 10:38:12.029368 26882 solver.cpp:253]     Train net output #0: loss = 1.3668 (* 1 = 1.3668 loss)
I0526 10:38:12.029386 26882 sgd_solver.cpp:106] Iteration 799500, lr = 0.004
I0526 10:38:50.076109 26882 solver.cpp:237] Iteration 801000, loss = 0.971949
I0526 10:38:50.076298 26882 solver.cpp:253]     Train net output #0: loss = 0.971938 (* 1 = 0.971938 loss)
I0526 10:38:50.076316 26882 sgd_solver.cpp:106] Iteration 801000, lr = 0.004
I0526 10:39:07.096587 26882 solver.cpp:237] Iteration 802500, loss = 1.35099
I0526 10:39:07.096647 26882 solver.cpp:253]     Train net output #0: loss = 1.35098 (* 1 = 1.35098 loss)
I0526 10:39:07.096673 26882 sgd_solver.cpp:106] Iteration 802500, lr = 0.004
I0526 10:39:23.790900 26882 solver.cpp:237] Iteration 804000, loss = 1.54795
I0526 10:39:23.791075 26882 solver.cpp:253]     Train net output #0: loss = 1.54794 (* 1 = 1.54794 loss)
I0526 10:39:23.791092 26882 sgd_solver.cpp:106] Iteration 804000, lr = 0.004
I0526 10:39:40.621206 26882 solver.cpp:237] Iteration 805500, loss = 1.30702
I0526 10:39:40.621263 26882 solver.cpp:253]     Train net output #0: loss = 1.30701 (* 1 = 1.30701 loss)
I0526 10:39:40.621281 26882 sgd_solver.cpp:106] Iteration 805500, lr = 0.004
I0526 10:39:57.466946 26882 solver.cpp:237] Iteration 807000, loss = 1.22124
I0526 10:39:57.467131 26882 solver.cpp:253]     Train net output #0: loss = 1.22123 (* 1 = 1.22123 loss)
I0526 10:39:57.467149 26882 sgd_solver.cpp:106] Iteration 807000, lr = 0.004
I0526 10:40:14.414487 26882 solver.cpp:237] Iteration 808500, loss = 1.24987
I0526 10:40:14.414525 26882 solver.cpp:253]     Train net output #0: loss = 1.24986 (* 1 = 1.24986 loss)
I0526 10:40:14.414544 26882 sgd_solver.cpp:106] Iteration 808500, lr = 0.004
I0526 10:40:31.575362 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_810000.caffemodel
I0526 10:40:31.621845 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_810000.solverstate
I0526 10:40:31.647025 26882 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 10:41:52.028193 26882 solver.cpp:409]     Test net output #0: accuracy = 0.893903
I0526 10:41:52.028381 26882 solver.cpp:409]     Test net output #1: loss = 0.36795 (* 1 = 0.36795 loss)
I0526 10:42:12.885449 26882 solver.cpp:237] Iteration 810000, loss = 1.14992
I0526 10:42:12.885507 26882 solver.cpp:253]     Train net output #0: loss = 1.14991 (* 1 = 1.14991 loss)
I0526 10:42:12.885535 26882 sgd_solver.cpp:106] Iteration 810000, lr = 0.004
I0526 10:42:29.880923 26882 solver.cpp:237] Iteration 811500, loss = 0.618196
I0526 10:42:29.881111 26882 solver.cpp:253]     Train net output #0: loss = 0.618184 (* 1 = 0.618184 loss)
I0526 10:42:29.881129 26882 sgd_solver.cpp:106] Iteration 811500, lr = 0.004
I0526 10:42:47.082185 26882 solver.cpp:237] Iteration 813000, loss = 0.862753
I0526 10:42:47.082242 26882 solver.cpp:253]     Train net output #0: loss = 0.862741 (* 1 = 0.862741 loss)
I0526 10:42:47.082262 26882 sgd_solver.cpp:106] Iteration 813000, lr = 0.004
I0526 10:43:03.946128 26882 solver.cpp:237] Iteration 814500, loss = 0.926936
I0526 10:43:03.946296 26882 solver.cpp:253]     Train net output #0: loss = 0.926925 (* 1 = 0.926925 loss)
I0526 10:43:03.946312 26882 sgd_solver.cpp:106] Iteration 814500, lr = 0.004
I0526 10:43:20.876900 26882 solver.cpp:237] Iteration 816000, loss = 0.959218
I0526 10:43:20.876957 26882 solver.cpp:253]     Train net output #0: loss = 0.959205 (* 1 = 0.959205 loss)
I0526 10:43:20.876974 26882 sgd_solver.cpp:106] Iteration 816000, lr = 0.004
I0526 10:43:37.795490 26882 solver.cpp:237] Iteration 817500, loss = 1.76403
I0526 10:43:37.795688 26882 solver.cpp:253]     Train net output #0: loss = 1.76402 (* 1 = 1.76402 loss)
I0526 10:43:37.795706 26882 sgd_solver.cpp:106] Iteration 817500, lr = 0.004
I0526 10:43:54.451148 26882 solver.cpp:237] Iteration 819000, loss = 1.74117
I0526 10:43:54.451186 26882 solver.cpp:253]     Train net output #0: loss = 1.74116 (* 1 = 1.74116 loss)
I0526 10:43:54.451203 26882 sgd_solver.cpp:106] Iteration 819000, lr = 0.004
I0526 10:44:32.191910 26882 solver.cpp:237] Iteration 820500, loss = 0.513363
I0526 10:44:32.192101 26882 solver.cpp:253]     Train net output #0: loss = 0.513351 (* 1 = 0.513351 loss)
I0526 10:44:32.192121 26882 sgd_solver.cpp:106] Iteration 820500, lr = 0.004
I0526 10:44:49.103122 26882 solver.cpp:237] Iteration 822000, loss = 1.76377
I0526 10:44:49.103163 26882 solver.cpp:253]     Train net output #0: loss = 1.76376 (* 1 = 1.76376 loss)
I0526 10:44:49.103179 26882 sgd_solver.cpp:106] Iteration 822000, lr = 0.004
I0526 10:45:05.977246 26882 solver.cpp:237] Iteration 823500, loss = 1.15902
I0526 10:45:05.977432 26882 solver.cpp:253]     Train net output #0: loss = 1.15901 (* 1 = 1.15901 loss)
I0526 10:45:05.977449 26882 sgd_solver.cpp:106] Iteration 823500, lr = 0.004
I0526 10:45:22.947443 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_825000.caffemodel
I0526 10:45:22.995199 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_825000.solverstate
I0526 10:45:23.027523 26882 solver.cpp:237] Iteration 825000, loss = 1.2937
I0526 10:45:23.027588 26882 solver.cpp:253]     Train net output #0: loss = 1.29369 (* 1 = 1.29369 loss)
I0526 10:45:23.027606 26882 sgd_solver.cpp:106] Iteration 825000, lr = 0.004
I0526 10:45:40.102974 26882 solver.cpp:237] Iteration 826500, loss = 1.99801
I0526 10:45:40.103147 26882 solver.cpp:253]     Train net output #0: loss = 1.998 (* 1 = 1.998 loss)
I0526 10:45:40.103164 26882 sgd_solver.cpp:106] Iteration 826500, lr = 0.004
I0526 10:45:56.911686 26882 solver.cpp:237] Iteration 828000, loss = 1.16585
I0526 10:45:56.911741 26882 solver.cpp:253]     Train net output #0: loss = 1.16584 (* 1 = 1.16584 loss)
I0526 10:45:56.911759 26882 sgd_solver.cpp:106] Iteration 828000, lr = 0.004
I0526 10:46:13.589802 26882 solver.cpp:237] Iteration 829500, loss = 1.5781
I0526 10:46:13.589987 26882 solver.cpp:253]     Train net output #0: loss = 1.57809 (* 1 = 1.57809 loss)
I0526 10:46:13.590004 26882 sgd_solver.cpp:106] Iteration 829500, lr = 0.004
I0526 10:46:51.106709 26882 solver.cpp:237] Iteration 831000, loss = 1.04417
I0526 10:46:51.106914 26882 solver.cpp:253]     Train net output #0: loss = 1.04416 (* 1 = 1.04416 loss)
I0526 10:46:51.106931 26882 sgd_solver.cpp:106] Iteration 831000, lr = 0.004
I0526 10:47:08.129632 26882 solver.cpp:237] Iteration 832500, loss = 0.592447
I0526 10:47:08.129691 26882 solver.cpp:253]     Train net output #0: loss = 0.592434 (* 1 = 0.592434 loss)
I0526 10:47:08.129709 26882 sgd_solver.cpp:106] Iteration 832500, lr = 0.004
I0526 10:47:25.252177 26882 solver.cpp:237] Iteration 834000, loss = 1.56717
I0526 10:47:25.252364 26882 solver.cpp:253]     Train net output #0: loss = 1.56716 (* 1 = 1.56716 loss)
I0526 10:47:25.252382 26882 sgd_solver.cpp:106] Iteration 834000, lr = 0.004
I0526 10:47:42.204710 26882 solver.cpp:237] Iteration 835500, loss = 1.25512
I0526 10:47:42.204749 26882 solver.cpp:253]     Train net output #0: loss = 1.25511 (* 1 = 1.25511 loss)
I0526 10:47:42.204766 26882 sgd_solver.cpp:106] Iteration 835500, lr = 0.004
I0526 10:47:59.022248 26882 solver.cpp:237] Iteration 837000, loss = 1.15355
I0526 10:47:59.022434 26882 solver.cpp:253]     Train net output #0: loss = 1.15354 (* 1 = 1.15354 loss)
I0526 10:47:59.022451 26882 sgd_solver.cpp:106] Iteration 837000, lr = 0.004
I0526 10:48:15.787422 26882 solver.cpp:237] Iteration 838500, loss = 0.659016
I0526 10:48:15.787482 26882 solver.cpp:253]     Train net output #0: loss = 0.659003 (* 1 = 0.659003 loss)
I0526 10:48:15.787508 26882 sgd_solver.cpp:106] Iteration 838500, lr = 0.004
I0526 10:48:32.425567 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_840000.caffemodel
I0526 10:48:32.471715 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_840000.solverstate
I0526 10:48:32.497529 26882 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 10:49:32.118363 26882 solver.cpp:409]     Test net output #0: accuracy = 0.879666
I0526 10:49:32.118553 26882 solver.cpp:409]     Test net output #1: loss = 0.40653 (* 1 = 0.40653 loss)
I0526 10:49:53.002797 26882 solver.cpp:237] Iteration 840000, loss = 0.875152
I0526 10:49:53.002861 26882 solver.cpp:253]     Train net output #0: loss = 0.875139 (* 1 = 0.875139 loss)
I0526 10:49:53.002888 26882 sgd_solver.cpp:106] Iteration 840000, lr = 0.004
I0526 10:50:10.075085 26882 solver.cpp:237] Iteration 841500, loss = 1.08232
I0526 10:50:10.075260 26882 solver.cpp:253]     Train net output #0: loss = 1.0823 (* 1 = 1.0823 loss)
I0526 10:50:10.075278 26882 sgd_solver.cpp:106] Iteration 841500, lr = 0.004
I0526 10:50:26.879652 26882 solver.cpp:237] Iteration 843000, loss = 1.93658
I0526 10:50:26.879706 26882 solver.cpp:253]     Train net output #0: loss = 1.93656 (* 1 = 1.93656 loss)
I0526 10:50:26.879725 26882 sgd_solver.cpp:106] Iteration 843000, lr = 0.004
I0526 10:50:43.580914 26882 solver.cpp:237] Iteration 844500, loss = 1.4669
I0526 10:50:43.581104 26882 solver.cpp:253]     Train net output #0: loss = 1.46689 (* 1 = 1.46689 loss)
I0526 10:50:43.581121 26882 sgd_solver.cpp:106] Iteration 844500, lr = 0.004
I0526 10:51:00.594249 26882 solver.cpp:237] Iteration 846000, loss = 0.817179
I0526 10:51:00.594288 26882 solver.cpp:253]     Train net output #0: loss = 0.817168 (* 1 = 0.817168 loss)
I0526 10:51:00.594305 26882 sgd_solver.cpp:106] Iteration 846000, lr = 0.004
I0526 10:51:17.382318 26882 solver.cpp:237] Iteration 847500, loss = 1.46483
I0526 10:51:17.382504 26882 solver.cpp:253]     Train net output #0: loss = 1.46482 (* 1 = 1.46482 loss)
I0526 10:51:17.382521 26882 sgd_solver.cpp:106] Iteration 847500, lr = 0.004
I0526 10:51:34.045198 26882 solver.cpp:237] Iteration 849000, loss = 0.949648
I0526 10:51:34.045258 26882 solver.cpp:253]     Train net output #0: loss = 0.949637 (* 1 = 0.949637 loss)
I0526 10:51:34.045282 26882 sgd_solver.cpp:106] Iteration 849000, lr = 0.004
I0526 10:52:11.661034 26882 solver.cpp:237] Iteration 850500, loss = 0.848756
I0526 10:52:11.661231 26882 solver.cpp:253]     Train net output #0: loss = 0.848744 (* 1 = 0.848744 loss)
I0526 10:52:11.661249 26882 sgd_solver.cpp:106] Iteration 850500, lr = 0.004
I0526 10:52:28.527125 26882 solver.cpp:237] Iteration 852000, loss = 0.777484
I0526 10:52:28.527185 26882 solver.cpp:253]     Train net output #0: loss = 0.777472 (* 1 = 0.777472 loss)
I0526 10:52:28.527205 26882 sgd_solver.cpp:106] Iteration 852000, lr = 0.004
I0526 10:52:45.579840 26882 solver.cpp:237] Iteration 853500, loss = 1.24439
I0526 10:52:45.580010 26882 solver.cpp:253]     Train net output #0: loss = 1.24438 (* 1 = 1.24438 loss)
I0526 10:52:45.580027 26882 sgd_solver.cpp:106] Iteration 853500, lr = 0.004
I0526 10:53:02.209450 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_855000.caffemodel
I0526 10:53:02.254685 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_855000.solverstate
I0526 10:53:02.283298 26882 solver.cpp:237] Iteration 855000, loss = 2.21303
I0526 10:53:02.283356 26882 solver.cpp:253]     Train net output #0: loss = 2.21302 (* 1 = 2.21302 loss)
I0526 10:53:02.283376 26882 sgd_solver.cpp:106] Iteration 855000, lr = 0.004
I0526 10:53:19.031427 26882 solver.cpp:237] Iteration 856500, loss = 1.46877
I0526 10:53:19.031630 26882 solver.cpp:253]     Train net output #0: loss = 1.46876 (* 1 = 1.46876 loss)
I0526 10:53:19.031646 26882 sgd_solver.cpp:106] Iteration 856500, lr = 0.004
I0526 10:53:35.896898 26882 solver.cpp:237] Iteration 858000, loss = 1.23383
I0526 10:53:35.896940 26882 solver.cpp:253]     Train net output #0: loss = 1.23381 (* 1 = 1.23381 loss)
I0526 10:53:35.896958 26882 sgd_solver.cpp:106] Iteration 858000, lr = 0.004
I0526 10:53:52.956990 26882 solver.cpp:237] Iteration 859500, loss = 1.68597
I0526 10:53:52.957177 26882 solver.cpp:253]     Train net output #0: loss = 1.68596 (* 1 = 1.68596 loss)
I0526 10:53:52.957195 26882 sgd_solver.cpp:106] Iteration 859500, lr = 0.004
I0526 10:54:30.892726 26882 solver.cpp:237] Iteration 861000, loss = 0.993874
I0526 10:54:30.892925 26882 solver.cpp:253]     Train net output #0: loss = 0.993863 (* 1 = 0.993863 loss)
I0526 10:54:30.892942 26882 sgd_solver.cpp:106] Iteration 861000, lr = 0.004
I0526 10:54:48.126680 26882 solver.cpp:237] Iteration 862500, loss = 1.65169
I0526 10:54:48.126718 26882 solver.cpp:253]     Train net output #0: loss = 1.65168 (* 1 = 1.65168 loss)
I0526 10:54:48.126737 26882 sgd_solver.cpp:106] Iteration 862500, lr = 0.004
I0526 10:55:04.874678 26882 solver.cpp:237] Iteration 864000, loss = 1.51654
I0526 10:55:04.874866 26882 solver.cpp:253]     Train net output #0: loss = 1.51653 (* 1 = 1.51653 loss)
I0526 10:55:04.874883 26882 sgd_solver.cpp:106] Iteration 864000, lr = 0.004
I0526 10:55:21.579097 26882 solver.cpp:237] Iteration 865500, loss = 1.38504
I0526 10:55:21.579154 26882 solver.cpp:253]     Train net output #0: loss = 1.38503 (* 1 = 1.38503 loss)
I0526 10:55:21.579180 26882 sgd_solver.cpp:106] Iteration 865500, lr = 0.004
I0526 10:55:38.526909 26882 solver.cpp:237] Iteration 867000, loss = 1.09554
I0526 10:55:38.527073 26882 solver.cpp:253]     Train net output #0: loss = 1.09553 (* 1 = 1.09553 loss)
I0526 10:55:38.527091 26882 sgd_solver.cpp:106] Iteration 867000, lr = 0.004
I0526 10:55:55.701181 26882 solver.cpp:237] Iteration 868500, loss = 1.13933
I0526 10:55:55.701241 26882 solver.cpp:253]     Train net output #0: loss = 1.13932 (* 1 = 1.13932 loss)
I0526 10:55:55.701257 26882 sgd_solver.cpp:106] Iteration 868500, lr = 0.004
I0526 10:56:12.836678 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_870000.caffemodel
I0526 10:56:12.883256 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_870000.solverstate
I0526 10:56:12.909571 26882 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 10:57:33.446080 26882 solver.cpp:409]     Test net output #0: accuracy = 0.88991
I0526 10:57:33.446274 26882 solver.cpp:409]     Test net output #1: loss = 0.348548 (* 1 = 0.348548 loss)
I0526 10:57:54.299610 26882 solver.cpp:237] Iteration 870000, loss = 1.68227
I0526 10:57:54.299671 26882 solver.cpp:253]     Train net output #0: loss = 1.68226 (* 1 = 1.68226 loss)
I0526 10:57:54.299701 26882 sgd_solver.cpp:106] Iteration 870000, lr = 0.004
I0526 10:58:10.887542 26882 solver.cpp:237] Iteration 871500, loss = 0.933091
I0526 10:58:10.887714 26882 solver.cpp:253]     Train net output #0: loss = 0.93308 (* 1 = 0.93308 loss)
I0526 10:58:10.887732 26882 sgd_solver.cpp:106] Iteration 871500, lr = 0.004
I0526 10:58:27.823453 26882 solver.cpp:237] Iteration 873000, loss = 0.67926
I0526 10:58:27.823510 26882 solver.cpp:253]     Train net output #0: loss = 0.679248 (* 1 = 0.679248 loss)
I0526 10:58:27.823528 26882 sgd_solver.cpp:106] Iteration 873000, lr = 0.004
I0526 10:58:44.610987 26882 solver.cpp:237] Iteration 874500, loss = 0.970747
I0526 10:58:44.611189 26882 solver.cpp:253]     Train net output #0: loss = 0.970736 (* 1 = 0.970736 loss)
I0526 10:58:44.611207 26882 sgd_solver.cpp:106] Iteration 874500, lr = 0.004
I0526 10:59:01.189590 26882 solver.cpp:237] Iteration 876000, loss = 0.969333
I0526 10:59:01.189633 26882 solver.cpp:253]     Train net output #0: loss = 0.969321 (* 1 = 0.969321 loss)
I0526 10:59:01.189651 26882 sgd_solver.cpp:106] Iteration 876000, lr = 0.004
I0526 10:59:18.098263 26882 solver.cpp:237] Iteration 877500, loss = 1.68926
I0526 10:59:18.098448 26882 solver.cpp:253]     Train net output #0: loss = 1.68925 (* 1 = 1.68925 loss)
I0526 10:59:18.098466 26882 sgd_solver.cpp:106] Iteration 877500, lr = 0.004
I0526 10:59:34.983278 26882 solver.cpp:237] Iteration 879000, loss = 1.32109
I0526 10:59:34.983331 26882 solver.cpp:253]     Train net output #0: loss = 1.32108 (* 1 = 1.32108 loss)
I0526 10:59:34.983351 26882 sgd_solver.cpp:106] Iteration 879000, lr = 0.004
I0526 11:00:12.702244 26882 solver.cpp:237] Iteration 880500, loss = 1.26169
I0526 11:00:12.702440 26882 solver.cpp:253]     Train net output #0: loss = 1.26168 (* 1 = 1.26168 loss)
I0526 11:00:12.702456 26882 sgd_solver.cpp:106] Iteration 880500, lr = 0.004
I0526 11:00:29.446306 26882 solver.cpp:237] Iteration 882000, loss = 0.843673
I0526 11:00:29.446360 26882 solver.cpp:253]     Train net output #0: loss = 0.843661 (* 1 = 0.843661 loss)
I0526 11:00:29.446379 26882 sgd_solver.cpp:106] Iteration 882000, lr = 0.004
I0526 11:00:46.480734 26882 solver.cpp:237] Iteration 883500, loss = 1.25572
I0526 11:00:46.480916 26882 solver.cpp:253]     Train net output #0: loss = 1.25571 (* 1 = 1.25571 loss)
I0526 11:00:46.480934 26882 sgd_solver.cpp:106] Iteration 883500, lr = 0.004
I0526 11:01:03.390161 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_885000.caffemodel
I0526 11:01:03.438231 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_885000.solverstate
I0526 11:01:03.468973 26882 solver.cpp:237] Iteration 885000, loss = 1.64133
I0526 11:01:03.469038 26882 solver.cpp:253]     Train net output #0: loss = 1.64132 (* 1 = 1.64132 loss)
I0526 11:01:03.469055 26882 sgd_solver.cpp:106] Iteration 885000, lr = 0.004
I0526 11:01:20.138167 26882 solver.cpp:237] Iteration 886500, loss = 0.79351
I0526 11:01:20.138360 26882 solver.cpp:253]     Train net output #0: loss = 0.793498 (* 1 = 0.793498 loss)
I0526 11:01:20.138377 26882 sgd_solver.cpp:106] Iteration 886500, lr = 0.004
I0526 11:01:36.868440 26882 solver.cpp:237] Iteration 888000, loss = 2.77559
I0526 11:01:36.868496 26882 solver.cpp:253]     Train net output #0: loss = 2.77558 (* 1 = 2.77558 loss)
I0526 11:01:36.868525 26882 sgd_solver.cpp:106] Iteration 888000, lr = 0.004
I0526 11:01:53.753198 26882 solver.cpp:237] Iteration 889500, loss = 0.983403
I0526 11:01:53.753381 26882 solver.cpp:253]     Train net output #0: loss = 0.983392 (* 1 = 0.983392 loss)
I0526 11:01:53.753399 26882 sgd_solver.cpp:106] Iteration 889500, lr = 0.004
I0526 11:02:31.417641 26882 solver.cpp:237] Iteration 891000, loss = 0.659205
I0526 11:02:31.417834 26882 solver.cpp:253]     Train net output #0: loss = 0.659194 (* 1 = 0.659194 loss)
I0526 11:02:31.417851 26882 sgd_solver.cpp:106] Iteration 891000, lr = 0.004
I0526 11:02:48.231819 26882 solver.cpp:237] Iteration 892500, loss = 1.48045
I0526 11:02:48.231874 26882 solver.cpp:253]     Train net output #0: loss = 1.48044 (* 1 = 1.48044 loss)
I0526 11:02:48.231904 26882 sgd_solver.cpp:106] Iteration 892500, lr = 0.004
I0526 11:03:05.015882 26882 solver.cpp:237] Iteration 894000, loss = 1.40851
I0526 11:03:05.016057 26882 solver.cpp:253]     Train net output #0: loss = 1.4085 (* 1 = 1.4085 loss)
I0526 11:03:05.016072 26882 sgd_solver.cpp:106] Iteration 894000, lr = 0.004
I0526 11:03:21.682601 26882 solver.cpp:237] Iteration 895500, loss = 1.41806
I0526 11:03:21.682658 26882 solver.cpp:253]     Train net output #0: loss = 1.41804 (* 1 = 1.41804 loss)
I0526 11:03:21.682677 26882 sgd_solver.cpp:106] Iteration 895500, lr = 0.004
I0526 11:03:38.284790 26882 solver.cpp:237] Iteration 897000, loss = 1.71248
I0526 11:03:38.284994 26882 solver.cpp:253]     Train net output #0: loss = 1.71246 (* 1 = 1.71246 loss)
I0526 11:03:38.285013 26882 sgd_solver.cpp:106] Iteration 897000, lr = 0.004
I0526 11:03:54.923845 26882 solver.cpp:237] Iteration 898500, loss = 1.16251
I0526 11:03:54.923884 26882 solver.cpp:253]     Train net output #0: loss = 1.16249 (* 1 = 1.16249 loss)
I0526 11:03:54.923902 26882 sgd_solver.cpp:106] Iteration 898500, lr = 0.004
I0526 11:04:11.739955 26882 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_900000.caffemodel
I0526 11:04:11.787778 26882 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0040_2016-05-20T15.48.52.047393_iter_900000.solverstate
I0526 11:04:11.817096 26882 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 11:05:10.889730 26882 solver.cpp:409]     Test net output #0: accuracy = 0.889686
I0526 11:05:10.889919 26882 solver.cpp:409]     Test net output #1: loss = 0.368077 (* 1 = 0.368077 loss)
aprun: Apid 11267632: Caught signal Terminated, sending to application
*** Aborted at 1464275121 (unix time) try "date -d @1464275121" if you are using GNU date ***
PC: @     0x2aaac5e9bb3b (unknown)
aprun: Apid 11267632: Caught signal Terminated, sending to application
*** SIGTERM (@0x68ff) received by PID 26882 (TID 0x2aaac746f900) from PID 26879; stack trace: ***
=>> PBS: job killed: walltime 7230 exceeded limit 7200
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaac5e9bb3b (unknown)
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @     0x2aaac5e9c9d5 inflate
    @     0x2aaab1450a9d H5Z_filter_deflate
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11267632: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
aprun: Apid 11267632: Caught signal Terminated, sending to application
