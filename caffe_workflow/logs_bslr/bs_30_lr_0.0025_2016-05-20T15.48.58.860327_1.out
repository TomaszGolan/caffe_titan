2807296
I0522 10:07:44.896893  9292 caffe.cpp:184] Using GPUs 0
I0522 10:07:45.322296  9292 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.0025
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327.prototxt"
I0522 10:07:45.324057  9292 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327.prototxt
I0522 10:07:45.337774  9292 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 10:07:45.337834  9292 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 10:07:45.338181  9292 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 10:07:45.338359  9292 layer_factory.hpp:77] Creating layer data_hdf5
I0522 10:07:45.338384  9292 net.cpp:106] Creating Layer data_hdf5
I0522 10:07:45.338398  9292 net.cpp:411] data_hdf5 -> data
I0522 10:07:45.338433  9292 net.cpp:411] data_hdf5 -> label
I0522 10:07:45.338465  9292 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 10:07:45.339903  9292 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 10:07:45.342288  9292 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 10:08:06.840625  9292 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 10:08:06.845770  9292 net.cpp:150] Setting up data_hdf5
I0522 10:08:06.845810  9292 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 10:08:06.845825  9292 net.cpp:157] Top shape: 30 (30)
I0522 10:08:06.845837  9292 net.cpp:165] Memory required for data: 762120
I0522 10:08:06.845850  9292 layer_factory.hpp:77] Creating layer conv1
I0522 10:08:06.845885  9292 net.cpp:106] Creating Layer conv1
I0522 10:08:06.845896  9292 net.cpp:454] conv1 <- data
I0522 10:08:06.845917  9292 net.cpp:411] conv1 -> conv1
I0522 10:08:07.226876  9292 net.cpp:150] Setting up conv1
I0522 10:08:07.226922  9292 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 10:08:07.226933  9292 net.cpp:165] Memory required for data: 9056520
I0522 10:08:07.226960  9292 layer_factory.hpp:77] Creating layer relu1
I0522 10:08:07.226981  9292 net.cpp:106] Creating Layer relu1
I0522 10:08:07.226992  9292 net.cpp:454] relu1 <- conv1
I0522 10:08:07.227005  9292 net.cpp:397] relu1 -> conv1 (in-place)
I0522 10:08:07.227536  9292 net.cpp:150] Setting up relu1
I0522 10:08:07.227553  9292 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 10:08:07.227565  9292 net.cpp:165] Memory required for data: 17350920
I0522 10:08:07.227576  9292 layer_factory.hpp:77] Creating layer pool1
I0522 10:08:07.227592  9292 net.cpp:106] Creating Layer pool1
I0522 10:08:07.227602  9292 net.cpp:454] pool1 <- conv1
I0522 10:08:07.227615  9292 net.cpp:411] pool1 -> pool1
I0522 10:08:07.227696  9292 net.cpp:150] Setting up pool1
I0522 10:08:07.227710  9292 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 10:08:07.227720  9292 net.cpp:165] Memory required for data: 21498120
I0522 10:08:07.227730  9292 layer_factory.hpp:77] Creating layer conv2
I0522 10:08:07.227752  9292 net.cpp:106] Creating Layer conv2
I0522 10:08:07.227764  9292 net.cpp:454] conv2 <- pool1
I0522 10:08:07.227777  9292 net.cpp:411] conv2 -> conv2
I0522 10:08:07.230466  9292 net.cpp:150] Setting up conv2
I0522 10:08:07.230494  9292 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 10:08:07.230505  9292 net.cpp:165] Memory required for data: 27459720
I0522 10:08:07.230525  9292 layer_factory.hpp:77] Creating layer relu2
I0522 10:08:07.230540  9292 net.cpp:106] Creating Layer relu2
I0522 10:08:07.230550  9292 net.cpp:454] relu2 <- conv2
I0522 10:08:07.230562  9292 net.cpp:397] relu2 -> conv2 (in-place)
I0522 10:08:07.230893  9292 net.cpp:150] Setting up relu2
I0522 10:08:07.230907  9292 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 10:08:07.230917  9292 net.cpp:165] Memory required for data: 33421320
I0522 10:08:07.230927  9292 layer_factory.hpp:77] Creating layer pool2
I0522 10:08:07.230939  9292 net.cpp:106] Creating Layer pool2
I0522 10:08:07.230949  9292 net.cpp:454] pool2 <- conv2
I0522 10:08:07.230962  9292 net.cpp:411] pool2 -> pool2
I0522 10:08:07.231042  9292 net.cpp:150] Setting up pool2
I0522 10:08:07.231056  9292 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 10:08:07.231066  9292 net.cpp:165] Memory required for data: 36402120
I0522 10:08:07.231076  9292 layer_factory.hpp:77] Creating layer conv3
I0522 10:08:07.231102  9292 net.cpp:106] Creating Layer conv3
I0522 10:08:07.231113  9292 net.cpp:454] conv3 <- pool2
I0522 10:08:07.231127  9292 net.cpp:411] conv3 -> conv3
I0522 10:08:07.233089  9292 net.cpp:150] Setting up conv3
I0522 10:08:07.233108  9292 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 10:08:07.233119  9292 net.cpp:165] Memory required for data: 39654600
I0522 10:08:07.233137  9292 layer_factory.hpp:77] Creating layer relu3
I0522 10:08:07.233153  9292 net.cpp:106] Creating Layer relu3
I0522 10:08:07.233162  9292 net.cpp:454] relu3 <- conv3
I0522 10:08:07.233175  9292 net.cpp:397] relu3 -> conv3 (in-place)
I0522 10:08:07.233644  9292 net.cpp:150] Setting up relu3
I0522 10:08:07.233661  9292 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 10:08:07.233672  9292 net.cpp:165] Memory required for data: 42907080
I0522 10:08:07.233682  9292 layer_factory.hpp:77] Creating layer pool3
I0522 10:08:07.233695  9292 net.cpp:106] Creating Layer pool3
I0522 10:08:07.233705  9292 net.cpp:454] pool3 <- conv3
I0522 10:08:07.233718  9292 net.cpp:411] pool3 -> pool3
I0522 10:08:07.233786  9292 net.cpp:150] Setting up pool3
I0522 10:08:07.233799  9292 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 10:08:07.233809  9292 net.cpp:165] Memory required for data: 44533320
I0522 10:08:07.233819  9292 layer_factory.hpp:77] Creating layer conv4
I0522 10:08:07.233836  9292 net.cpp:106] Creating Layer conv4
I0522 10:08:07.233847  9292 net.cpp:454] conv4 <- pool3
I0522 10:08:07.233860  9292 net.cpp:411] conv4 -> conv4
I0522 10:08:07.236577  9292 net.cpp:150] Setting up conv4
I0522 10:08:07.236608  9292 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 10:08:07.236618  9292 net.cpp:165] Memory required for data: 45621960
I0522 10:08:07.236635  9292 layer_factory.hpp:77] Creating layer relu4
I0522 10:08:07.236649  9292 net.cpp:106] Creating Layer relu4
I0522 10:08:07.236660  9292 net.cpp:454] relu4 <- conv4
I0522 10:08:07.236672  9292 net.cpp:397] relu4 -> conv4 (in-place)
I0522 10:08:07.237135  9292 net.cpp:150] Setting up relu4
I0522 10:08:07.237151  9292 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 10:08:07.237161  9292 net.cpp:165] Memory required for data: 46710600
I0522 10:08:07.237172  9292 layer_factory.hpp:77] Creating layer pool4
I0522 10:08:07.237185  9292 net.cpp:106] Creating Layer pool4
I0522 10:08:07.237195  9292 net.cpp:454] pool4 <- conv4
I0522 10:08:07.237207  9292 net.cpp:411] pool4 -> pool4
I0522 10:08:07.237275  9292 net.cpp:150] Setting up pool4
I0522 10:08:07.237289  9292 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 10:08:07.237299  9292 net.cpp:165] Memory required for data: 47254920
I0522 10:08:07.237309  9292 layer_factory.hpp:77] Creating layer ip1
I0522 10:08:07.237330  9292 net.cpp:106] Creating Layer ip1
I0522 10:08:07.237340  9292 net.cpp:454] ip1 <- pool4
I0522 10:08:07.237437  9292 net.cpp:411] ip1 -> ip1
I0522 10:08:07.252840  9292 net.cpp:150] Setting up ip1
I0522 10:08:07.252868  9292 net.cpp:157] Top shape: 30 196 (5880)
I0522 10:08:07.252881  9292 net.cpp:165] Memory required for data: 47278440
I0522 10:08:07.252905  9292 layer_factory.hpp:77] Creating layer relu5
I0522 10:08:07.252920  9292 net.cpp:106] Creating Layer relu5
I0522 10:08:07.252931  9292 net.cpp:454] relu5 <- ip1
I0522 10:08:07.252944  9292 net.cpp:397] relu5 -> ip1 (in-place)
I0522 10:08:07.253286  9292 net.cpp:150] Setting up relu5
I0522 10:08:07.253299  9292 net.cpp:157] Top shape: 30 196 (5880)
I0522 10:08:07.253310  9292 net.cpp:165] Memory required for data: 47301960
I0522 10:08:07.253320  9292 layer_factory.hpp:77] Creating layer drop1
I0522 10:08:07.253345  9292 net.cpp:106] Creating Layer drop1
I0522 10:08:07.253355  9292 net.cpp:454] drop1 <- ip1
I0522 10:08:07.253366  9292 net.cpp:397] drop1 -> ip1 (in-place)
I0522 10:08:07.253427  9292 net.cpp:150] Setting up drop1
I0522 10:08:07.253440  9292 net.cpp:157] Top shape: 30 196 (5880)
I0522 10:08:07.253450  9292 net.cpp:165] Memory required for data: 47325480
I0522 10:08:07.253460  9292 layer_factory.hpp:77] Creating layer ip2
I0522 10:08:07.253479  9292 net.cpp:106] Creating Layer ip2
I0522 10:08:07.253489  9292 net.cpp:454] ip2 <- ip1
I0522 10:08:07.253501  9292 net.cpp:411] ip2 -> ip2
I0522 10:08:07.253962  9292 net.cpp:150] Setting up ip2
I0522 10:08:07.253975  9292 net.cpp:157] Top shape: 30 98 (2940)
I0522 10:08:07.253985  9292 net.cpp:165] Memory required for data: 47337240
I0522 10:08:07.254000  9292 layer_factory.hpp:77] Creating layer relu6
I0522 10:08:07.254014  9292 net.cpp:106] Creating Layer relu6
I0522 10:08:07.254022  9292 net.cpp:454] relu6 <- ip2
I0522 10:08:07.254034  9292 net.cpp:397] relu6 -> ip2 (in-place)
I0522 10:08:07.254555  9292 net.cpp:150] Setting up relu6
I0522 10:08:07.254571  9292 net.cpp:157] Top shape: 30 98 (2940)
I0522 10:08:07.254582  9292 net.cpp:165] Memory required for data: 47349000
I0522 10:08:07.254592  9292 layer_factory.hpp:77] Creating layer drop2
I0522 10:08:07.254606  9292 net.cpp:106] Creating Layer drop2
I0522 10:08:07.254616  9292 net.cpp:454] drop2 <- ip2
I0522 10:08:07.254627  9292 net.cpp:397] drop2 -> ip2 (in-place)
I0522 10:08:07.254670  9292 net.cpp:150] Setting up drop2
I0522 10:08:07.254683  9292 net.cpp:157] Top shape: 30 98 (2940)
I0522 10:08:07.254694  9292 net.cpp:165] Memory required for data: 47360760
I0522 10:08:07.254705  9292 layer_factory.hpp:77] Creating layer ip3
I0522 10:08:07.254719  9292 net.cpp:106] Creating Layer ip3
I0522 10:08:07.254729  9292 net.cpp:454] ip3 <- ip2
I0522 10:08:07.254740  9292 net.cpp:411] ip3 -> ip3
I0522 10:08:07.254951  9292 net.cpp:150] Setting up ip3
I0522 10:08:07.254964  9292 net.cpp:157] Top shape: 30 11 (330)
I0522 10:08:07.254974  9292 net.cpp:165] Memory required for data: 47362080
I0522 10:08:07.254989  9292 layer_factory.hpp:77] Creating layer drop3
I0522 10:08:07.255002  9292 net.cpp:106] Creating Layer drop3
I0522 10:08:07.255012  9292 net.cpp:454] drop3 <- ip3
I0522 10:08:07.255023  9292 net.cpp:397] drop3 -> ip3 (in-place)
I0522 10:08:07.255064  9292 net.cpp:150] Setting up drop3
I0522 10:08:07.255076  9292 net.cpp:157] Top shape: 30 11 (330)
I0522 10:08:07.255095  9292 net.cpp:165] Memory required for data: 47363400
I0522 10:08:07.255105  9292 layer_factory.hpp:77] Creating layer loss
I0522 10:08:07.255123  9292 net.cpp:106] Creating Layer loss
I0522 10:08:07.255133  9292 net.cpp:454] loss <- ip3
I0522 10:08:07.255144  9292 net.cpp:454] loss <- label
I0522 10:08:07.255157  9292 net.cpp:411] loss -> loss
I0522 10:08:07.255174  9292 layer_factory.hpp:77] Creating layer loss
I0522 10:08:07.255816  9292 net.cpp:150] Setting up loss
I0522 10:08:07.255837  9292 net.cpp:157] Top shape: (1)
I0522 10:08:07.255851  9292 net.cpp:160]     with loss weight 1
I0522 10:08:07.255893  9292 net.cpp:165] Memory required for data: 47363404
I0522 10:08:07.255903  9292 net.cpp:226] loss needs backward computation.
I0522 10:08:07.255914  9292 net.cpp:226] drop3 needs backward computation.
I0522 10:08:07.255924  9292 net.cpp:226] ip3 needs backward computation.
I0522 10:08:07.255933  9292 net.cpp:226] drop2 needs backward computation.
I0522 10:08:07.255942  9292 net.cpp:226] relu6 needs backward computation.
I0522 10:08:07.255952  9292 net.cpp:226] ip2 needs backward computation.
I0522 10:08:07.255962  9292 net.cpp:226] drop1 needs backward computation.
I0522 10:08:07.255972  9292 net.cpp:226] relu5 needs backward computation.
I0522 10:08:07.255982  9292 net.cpp:226] ip1 needs backward computation.
I0522 10:08:07.255992  9292 net.cpp:226] pool4 needs backward computation.
I0522 10:08:07.256002  9292 net.cpp:226] relu4 needs backward computation.
I0522 10:08:07.256012  9292 net.cpp:226] conv4 needs backward computation.
I0522 10:08:07.256022  9292 net.cpp:226] pool3 needs backward computation.
I0522 10:08:07.256033  9292 net.cpp:226] relu3 needs backward computation.
I0522 10:08:07.256042  9292 net.cpp:226] conv3 needs backward computation.
I0522 10:08:07.256062  9292 net.cpp:226] pool2 needs backward computation.
I0522 10:08:07.256072  9292 net.cpp:226] relu2 needs backward computation.
I0522 10:08:07.256083  9292 net.cpp:226] conv2 needs backward computation.
I0522 10:08:07.256094  9292 net.cpp:226] pool1 needs backward computation.
I0522 10:08:07.256104  9292 net.cpp:226] relu1 needs backward computation.
I0522 10:08:07.256114  9292 net.cpp:226] conv1 needs backward computation.
I0522 10:08:07.256125  9292 net.cpp:228] data_hdf5 does not need backward computation.
I0522 10:08:07.256135  9292 net.cpp:270] This network produces output loss
I0522 10:08:07.256160  9292 net.cpp:283] Network initialization done.
I0522 10:08:07.257855  9292 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327.prototxt
I0522 10:08:07.257926  9292 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 10:08:07.258283  9292 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 10:08:07.258471  9292 layer_factory.hpp:77] Creating layer data_hdf5
I0522 10:08:07.258486  9292 net.cpp:106] Creating Layer data_hdf5
I0522 10:08:07.258498  9292 net.cpp:411] data_hdf5 -> data
I0522 10:08:07.258513  9292 net.cpp:411] data_hdf5 -> label
I0522 10:08:07.258529  9292 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 10:08:07.260071  9292 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 10:08:28.570055  9292 net.cpp:150] Setting up data_hdf5
I0522 10:08:28.570219  9292 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 10:08:28.570233  9292 net.cpp:157] Top shape: 30 (30)
I0522 10:08:28.570245  9292 net.cpp:165] Memory required for data: 762120
I0522 10:08:28.570257  9292 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 10:08:28.570286  9292 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 10:08:28.570297  9292 net.cpp:454] label_data_hdf5_1_split <- label
I0522 10:08:28.570312  9292 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 10:08:28.570333  9292 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 10:08:28.570405  9292 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 10:08:28.570420  9292 net.cpp:157] Top shape: 30 (30)
I0522 10:08:28.570431  9292 net.cpp:157] Top shape: 30 (30)
I0522 10:08:28.570441  9292 net.cpp:165] Memory required for data: 762360
I0522 10:08:28.570451  9292 layer_factory.hpp:77] Creating layer conv1
I0522 10:08:28.570472  9292 net.cpp:106] Creating Layer conv1
I0522 10:08:28.570483  9292 net.cpp:454] conv1 <- data
I0522 10:08:28.570498  9292 net.cpp:411] conv1 -> conv1
I0522 10:08:28.572455  9292 net.cpp:150] Setting up conv1
I0522 10:08:28.572479  9292 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 10:08:28.572491  9292 net.cpp:165] Memory required for data: 9056760
I0522 10:08:28.572512  9292 layer_factory.hpp:77] Creating layer relu1
I0522 10:08:28.572527  9292 net.cpp:106] Creating Layer relu1
I0522 10:08:28.572537  9292 net.cpp:454] relu1 <- conv1
I0522 10:08:28.572549  9292 net.cpp:397] relu1 -> conv1 (in-place)
I0522 10:08:28.573045  9292 net.cpp:150] Setting up relu1
I0522 10:08:28.573061  9292 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 10:08:28.573071  9292 net.cpp:165] Memory required for data: 17351160
I0522 10:08:28.573082  9292 layer_factory.hpp:77] Creating layer pool1
I0522 10:08:28.573098  9292 net.cpp:106] Creating Layer pool1
I0522 10:08:28.573108  9292 net.cpp:454] pool1 <- conv1
I0522 10:08:28.573122  9292 net.cpp:411] pool1 -> pool1
I0522 10:08:28.573195  9292 net.cpp:150] Setting up pool1
I0522 10:08:28.573209  9292 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 10:08:28.573218  9292 net.cpp:165] Memory required for data: 21498360
I0522 10:08:28.573226  9292 layer_factory.hpp:77] Creating layer conv2
I0522 10:08:28.573245  9292 net.cpp:106] Creating Layer conv2
I0522 10:08:28.573254  9292 net.cpp:454] conv2 <- pool1
I0522 10:08:28.573268  9292 net.cpp:411] conv2 -> conv2
I0522 10:08:28.575183  9292 net.cpp:150] Setting up conv2
I0522 10:08:28.575206  9292 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 10:08:28.575218  9292 net.cpp:165] Memory required for data: 27459960
I0522 10:08:28.575235  9292 layer_factory.hpp:77] Creating layer relu2
I0522 10:08:28.575249  9292 net.cpp:106] Creating Layer relu2
I0522 10:08:28.575259  9292 net.cpp:454] relu2 <- conv2
I0522 10:08:28.575271  9292 net.cpp:397] relu2 -> conv2 (in-place)
I0522 10:08:28.575601  9292 net.cpp:150] Setting up relu2
I0522 10:08:28.575615  9292 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 10:08:28.575626  9292 net.cpp:165] Memory required for data: 33421560
I0522 10:08:28.575636  9292 layer_factory.hpp:77] Creating layer pool2
I0522 10:08:28.575649  9292 net.cpp:106] Creating Layer pool2
I0522 10:08:28.575659  9292 net.cpp:454] pool2 <- conv2
I0522 10:08:28.575671  9292 net.cpp:411] pool2 -> pool2
I0522 10:08:28.575744  9292 net.cpp:150] Setting up pool2
I0522 10:08:28.575757  9292 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 10:08:28.575767  9292 net.cpp:165] Memory required for data: 36402360
I0522 10:08:28.575776  9292 layer_factory.hpp:77] Creating layer conv3
I0522 10:08:28.575794  9292 net.cpp:106] Creating Layer conv3
I0522 10:08:28.575804  9292 net.cpp:454] conv3 <- pool2
I0522 10:08:28.575819  9292 net.cpp:411] conv3 -> conv3
I0522 10:08:28.577790  9292 net.cpp:150] Setting up conv3
I0522 10:08:28.577812  9292 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 10:08:28.577823  9292 net.cpp:165] Memory required for data: 39654840
I0522 10:08:28.577857  9292 layer_factory.hpp:77] Creating layer relu3
I0522 10:08:28.577870  9292 net.cpp:106] Creating Layer relu3
I0522 10:08:28.577880  9292 net.cpp:454] relu3 <- conv3
I0522 10:08:28.577894  9292 net.cpp:397] relu3 -> conv3 (in-place)
I0522 10:08:28.578373  9292 net.cpp:150] Setting up relu3
I0522 10:08:28.578390  9292 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 10:08:28.578400  9292 net.cpp:165] Memory required for data: 42907320
I0522 10:08:28.578409  9292 layer_factory.hpp:77] Creating layer pool3
I0522 10:08:28.578423  9292 net.cpp:106] Creating Layer pool3
I0522 10:08:28.578433  9292 net.cpp:454] pool3 <- conv3
I0522 10:08:28.578445  9292 net.cpp:411] pool3 -> pool3
I0522 10:08:28.578517  9292 net.cpp:150] Setting up pool3
I0522 10:08:28.578531  9292 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 10:08:28.578539  9292 net.cpp:165] Memory required for data: 44533560
I0522 10:08:28.578549  9292 layer_factory.hpp:77] Creating layer conv4
I0522 10:08:28.578565  9292 net.cpp:106] Creating Layer conv4
I0522 10:08:28.578575  9292 net.cpp:454] conv4 <- pool3
I0522 10:08:28.578589  9292 net.cpp:411] conv4 -> conv4
I0522 10:08:28.580657  9292 net.cpp:150] Setting up conv4
I0522 10:08:28.580679  9292 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 10:08:28.580689  9292 net.cpp:165] Memory required for data: 45622200
I0522 10:08:28.580704  9292 layer_factory.hpp:77] Creating layer relu4
I0522 10:08:28.580718  9292 net.cpp:106] Creating Layer relu4
I0522 10:08:28.580727  9292 net.cpp:454] relu4 <- conv4
I0522 10:08:28.580740  9292 net.cpp:397] relu4 -> conv4 (in-place)
I0522 10:08:28.581210  9292 net.cpp:150] Setting up relu4
I0522 10:08:28.581225  9292 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 10:08:28.581235  9292 net.cpp:165] Memory required for data: 46710840
I0522 10:08:28.581245  9292 layer_factory.hpp:77] Creating layer pool4
I0522 10:08:28.581259  9292 net.cpp:106] Creating Layer pool4
I0522 10:08:28.581269  9292 net.cpp:454] pool4 <- conv4
I0522 10:08:28.581282  9292 net.cpp:411] pool4 -> pool4
I0522 10:08:28.581353  9292 net.cpp:150] Setting up pool4
I0522 10:08:28.581367  9292 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 10:08:28.581377  9292 net.cpp:165] Memory required for data: 47255160
I0522 10:08:28.581387  9292 layer_factory.hpp:77] Creating layer ip1
I0522 10:08:28.581399  9292 net.cpp:106] Creating Layer ip1
I0522 10:08:28.581409  9292 net.cpp:454] ip1 <- pool4
I0522 10:08:28.581423  9292 net.cpp:411] ip1 -> ip1
I0522 10:08:28.596861  9292 net.cpp:150] Setting up ip1
I0522 10:08:28.596889  9292 net.cpp:157] Top shape: 30 196 (5880)
I0522 10:08:28.596900  9292 net.cpp:165] Memory required for data: 47278680
I0522 10:08:28.596922  9292 layer_factory.hpp:77] Creating layer relu5
I0522 10:08:28.596937  9292 net.cpp:106] Creating Layer relu5
I0522 10:08:28.596947  9292 net.cpp:454] relu5 <- ip1
I0522 10:08:28.596966  9292 net.cpp:397] relu5 -> ip1 (in-place)
I0522 10:08:28.597313  9292 net.cpp:150] Setting up relu5
I0522 10:08:28.597327  9292 net.cpp:157] Top shape: 30 196 (5880)
I0522 10:08:28.597337  9292 net.cpp:165] Memory required for data: 47302200
I0522 10:08:28.597347  9292 layer_factory.hpp:77] Creating layer drop1
I0522 10:08:28.597367  9292 net.cpp:106] Creating Layer drop1
I0522 10:08:28.597376  9292 net.cpp:454] drop1 <- ip1
I0522 10:08:28.597389  9292 net.cpp:397] drop1 -> ip1 (in-place)
I0522 10:08:28.597435  9292 net.cpp:150] Setting up drop1
I0522 10:08:28.597448  9292 net.cpp:157] Top shape: 30 196 (5880)
I0522 10:08:28.597458  9292 net.cpp:165] Memory required for data: 47325720
I0522 10:08:28.597467  9292 layer_factory.hpp:77] Creating layer ip2
I0522 10:08:28.597482  9292 net.cpp:106] Creating Layer ip2
I0522 10:08:28.597491  9292 net.cpp:454] ip2 <- ip1
I0522 10:08:28.597506  9292 net.cpp:411] ip2 -> ip2
I0522 10:08:28.597983  9292 net.cpp:150] Setting up ip2
I0522 10:08:28.597996  9292 net.cpp:157] Top shape: 30 98 (2940)
I0522 10:08:28.598006  9292 net.cpp:165] Memory required for data: 47337480
I0522 10:08:28.598022  9292 layer_factory.hpp:77] Creating layer relu6
I0522 10:08:28.598047  9292 net.cpp:106] Creating Layer relu6
I0522 10:08:28.598057  9292 net.cpp:454] relu6 <- ip2
I0522 10:08:28.598069  9292 net.cpp:397] relu6 -> ip2 (in-place)
I0522 10:08:28.598604  9292 net.cpp:150] Setting up relu6
I0522 10:08:28.598621  9292 net.cpp:157] Top shape: 30 98 (2940)
I0522 10:08:28.598634  9292 net.cpp:165] Memory required for data: 47349240
I0522 10:08:28.598644  9292 layer_factory.hpp:77] Creating layer drop2
I0522 10:08:28.598659  9292 net.cpp:106] Creating Layer drop2
I0522 10:08:28.598669  9292 net.cpp:454] drop2 <- ip2
I0522 10:08:28.598681  9292 net.cpp:397] drop2 -> ip2 (in-place)
I0522 10:08:28.598726  9292 net.cpp:150] Setting up drop2
I0522 10:08:28.598738  9292 net.cpp:157] Top shape: 30 98 (2940)
I0522 10:08:28.598748  9292 net.cpp:165] Memory required for data: 47361000
I0522 10:08:28.598757  9292 layer_factory.hpp:77] Creating layer ip3
I0522 10:08:28.598772  9292 net.cpp:106] Creating Layer ip3
I0522 10:08:28.598781  9292 net.cpp:454] ip3 <- ip2
I0522 10:08:28.598795  9292 net.cpp:411] ip3 -> ip3
I0522 10:08:28.599020  9292 net.cpp:150] Setting up ip3
I0522 10:08:28.599032  9292 net.cpp:157] Top shape: 30 11 (330)
I0522 10:08:28.599042  9292 net.cpp:165] Memory required for data: 47362320
I0522 10:08:28.599058  9292 layer_factory.hpp:77] Creating layer drop3
I0522 10:08:28.599071  9292 net.cpp:106] Creating Layer drop3
I0522 10:08:28.599081  9292 net.cpp:454] drop3 <- ip3
I0522 10:08:28.599102  9292 net.cpp:397] drop3 -> ip3 (in-place)
I0522 10:08:28.599144  9292 net.cpp:150] Setting up drop3
I0522 10:08:28.599158  9292 net.cpp:157] Top shape: 30 11 (330)
I0522 10:08:28.599167  9292 net.cpp:165] Memory required for data: 47363640
I0522 10:08:28.599176  9292 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 10:08:28.599190  9292 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 10:08:28.599200  9292 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 10:08:28.599212  9292 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 10:08:28.599227  9292 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 10:08:28.599301  9292 net.cpp:150] Setting up ip3_drop3_0_split
I0522 10:08:28.599314  9292 net.cpp:157] Top shape: 30 11 (330)
I0522 10:08:28.599326  9292 net.cpp:157] Top shape: 30 11 (330)
I0522 10:08:28.599337  9292 net.cpp:165] Memory required for data: 47366280
I0522 10:08:28.599347  9292 layer_factory.hpp:77] Creating layer accuracy
I0522 10:08:28.599367  9292 net.cpp:106] Creating Layer accuracy
I0522 10:08:28.599377  9292 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 10:08:28.599390  9292 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 10:08:28.599402  9292 net.cpp:411] accuracy -> accuracy
I0522 10:08:28.599426  9292 net.cpp:150] Setting up accuracy
I0522 10:08:28.599438  9292 net.cpp:157] Top shape: (1)
I0522 10:08:28.599448  9292 net.cpp:165] Memory required for data: 47366284
I0522 10:08:28.599458  9292 layer_factory.hpp:77] Creating layer loss
I0522 10:08:28.599472  9292 net.cpp:106] Creating Layer loss
I0522 10:08:28.599483  9292 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 10:08:28.599493  9292 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 10:08:28.599506  9292 net.cpp:411] loss -> loss
I0522 10:08:28.599524  9292 layer_factory.hpp:77] Creating layer loss
I0522 10:08:28.600010  9292 net.cpp:150] Setting up loss
I0522 10:08:28.600024  9292 net.cpp:157] Top shape: (1)
I0522 10:08:28.600034  9292 net.cpp:160]     with loss weight 1
I0522 10:08:28.600052  9292 net.cpp:165] Memory required for data: 47366288
I0522 10:08:28.600062  9292 net.cpp:226] loss needs backward computation.
I0522 10:08:28.600075  9292 net.cpp:228] accuracy does not need backward computation.
I0522 10:08:28.600085  9292 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 10:08:28.600095  9292 net.cpp:226] drop3 needs backward computation.
I0522 10:08:28.600105  9292 net.cpp:226] ip3 needs backward computation.
I0522 10:08:28.600114  9292 net.cpp:226] drop2 needs backward computation.
I0522 10:08:28.600124  9292 net.cpp:226] relu6 needs backward computation.
I0522 10:08:28.600142  9292 net.cpp:226] ip2 needs backward computation.
I0522 10:08:28.600152  9292 net.cpp:226] drop1 needs backward computation.
I0522 10:08:28.600162  9292 net.cpp:226] relu5 needs backward computation.
I0522 10:08:28.600172  9292 net.cpp:226] ip1 needs backward computation.
I0522 10:08:28.600181  9292 net.cpp:226] pool4 needs backward computation.
I0522 10:08:28.600191  9292 net.cpp:226] relu4 needs backward computation.
I0522 10:08:28.600201  9292 net.cpp:226] conv4 needs backward computation.
I0522 10:08:28.600213  9292 net.cpp:226] pool3 needs backward computation.
I0522 10:08:28.600222  9292 net.cpp:226] relu3 needs backward computation.
I0522 10:08:28.600232  9292 net.cpp:226] conv3 needs backward computation.
I0522 10:08:28.600244  9292 net.cpp:226] pool2 needs backward computation.
I0522 10:08:28.600253  9292 net.cpp:226] relu2 needs backward computation.
I0522 10:08:28.600263  9292 net.cpp:226] conv2 needs backward computation.
I0522 10:08:28.600273  9292 net.cpp:226] pool1 needs backward computation.
I0522 10:08:28.600283  9292 net.cpp:226] relu1 needs backward computation.
I0522 10:08:28.600293  9292 net.cpp:226] conv1 needs backward computation.
I0522 10:08:28.600306  9292 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 10:08:28.600317  9292 net.cpp:228] data_hdf5 does not need backward computation.
I0522 10:08:28.600327  9292 net.cpp:270] This network produces output accuracy
I0522 10:08:28.600337  9292 net.cpp:270] This network produces output loss
I0522 10:08:28.600365  9292 net.cpp:283] Network initialization done.
I0522 10:08:28.600499  9292 solver.cpp:60] Solver scaffolding done.
I0522 10:08:28.601632  9292 caffe.cpp:212] Starting Optimization
I0522 10:08:28.601651  9292 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 10:08:28.601665  9292 solver.cpp:289] Learning Rate Policy: fixed
I0522 10:08:28.602885  9292 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 10:09:19.112545  9292 solver.cpp:409]     Test net output #0: accuracy = 0.085495
I0522 10:09:19.112704  9292 solver.cpp:409]     Test net output #1: loss = 2.39724 (* 1 = 2.39724 loss)
I0522 10:09:19.133720  9292 solver.cpp:237] Iteration 0, loss = 2.39917
I0522 10:09:19.133756  9292 solver.cpp:253]     Train net output #0: loss = 2.39917 (* 1 = 2.39917 loss)
I0522 10:09:19.133774  9292 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0522 10:09:29.655283  9292 solver.cpp:237] Iteration 500, loss = 1.9175
I0522 10:09:29.655320  9292 solver.cpp:253]     Train net output #0: loss = 1.9175 (* 1 = 1.9175 loss)
I0522 10:09:29.655336  9292 sgd_solver.cpp:106] Iteration 500, lr = 0.0025
I0522 10:09:40.186697  9292 solver.cpp:237] Iteration 1000, loss = 2.04071
I0522 10:09:40.186743  9292 solver.cpp:253]     Train net output #0: loss = 2.04071 (* 1 = 2.04071 loss)
I0522 10:09:40.186758  9292 sgd_solver.cpp:106] Iteration 1000, lr = 0.0025
I0522 10:09:50.718487  9292 solver.cpp:237] Iteration 1500, loss = 1.96442
I0522 10:09:50.718634  9292 solver.cpp:253]     Train net output #0: loss = 1.96442 (* 1 = 1.96442 loss)
I0522 10:09:50.718650  9292 sgd_solver.cpp:106] Iteration 1500, lr = 0.0025
I0522 10:10:01.233856  9292 solver.cpp:237] Iteration 2000, loss = 1.74701
I0522 10:10:01.233891  9292 solver.cpp:253]     Train net output #0: loss = 1.74701 (* 1 = 1.74701 loss)
I0522 10:10:01.233907  9292 sgd_solver.cpp:106] Iteration 2000, lr = 0.0025
I0522 10:10:11.770634  9292 solver.cpp:237] Iteration 2500, loss = 1.88498
I0522 10:10:11.770679  9292 solver.cpp:253]     Train net output #0: loss = 1.88498 (* 1 = 1.88498 loss)
I0522 10:10:11.770694  9292 sgd_solver.cpp:106] Iteration 2500, lr = 0.0025
I0522 10:10:22.300958  9292 solver.cpp:237] Iteration 3000, loss = 1.65448
I0522 10:10:22.301098  9292 solver.cpp:253]     Train net output #0: loss = 1.65448 (* 1 = 1.65448 loss)
I0522 10:10:22.301112  9292 sgd_solver.cpp:106] Iteration 3000, lr = 0.0025
I0522 10:10:54.974887  9292 solver.cpp:237] Iteration 3500, loss = 1.49157
I0522 10:10:54.975049  9292 solver.cpp:253]     Train net output #0: loss = 1.49157 (* 1 = 1.49157 loss)
I0522 10:10:54.975062  9292 sgd_solver.cpp:106] Iteration 3500, lr = 0.0025
I0522 10:11:05.518923  9292 solver.cpp:237] Iteration 4000, loss = 1.36722
I0522 10:11:05.518959  9292 solver.cpp:253]     Train net output #0: loss = 1.36722 (* 1 = 1.36722 loss)
I0522 10:11:05.518975  9292 sgd_solver.cpp:106] Iteration 4000, lr = 0.0025
I0522 10:11:16.064548  9292 solver.cpp:237] Iteration 4500, loss = 1.87055
I0522 10:11:16.064584  9292 solver.cpp:253]     Train net output #0: loss = 1.87055 (* 1 = 1.87055 loss)
I0522 10:11:16.064599  9292 sgd_solver.cpp:106] Iteration 4500, lr = 0.0025
I0522 10:11:26.569221  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_5000.caffemodel
I0522 10:11:26.625051  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_5000.solverstate
I0522 10:11:26.656879  9292 solver.cpp:237] Iteration 5000, loss = 1.13891
I0522 10:11:26.656925  9292 solver.cpp:253]     Train net output #0: loss = 1.13891 (* 1 = 1.13891 loss)
I0522 10:11:26.656939  9292 sgd_solver.cpp:106] Iteration 5000, lr = 0.0025
I0522 10:11:37.196081  9292 solver.cpp:237] Iteration 5500, loss = 1.74004
I0522 10:11:37.196118  9292 solver.cpp:253]     Train net output #0: loss = 1.74004 (* 1 = 1.74004 loss)
I0522 10:11:37.196133  9292 sgd_solver.cpp:106] Iteration 5500, lr = 0.0025
I0522 10:11:47.731048  9292 solver.cpp:237] Iteration 6000, loss = 1.33658
I0522 10:11:47.731104  9292 solver.cpp:253]     Train net output #0: loss = 1.33658 (* 1 = 1.33658 loss)
I0522 10:11:47.731118  9292 sgd_solver.cpp:106] Iteration 6000, lr = 0.0025
I0522 10:11:58.260567  9292 solver.cpp:237] Iteration 6500, loss = 1.58819
I0522 10:11:58.260710  9292 solver.cpp:253]     Train net output #0: loss = 1.58819 (* 1 = 1.58819 loss)
I0522 10:11:58.260722  9292 sgd_solver.cpp:106] Iteration 6500, lr = 0.0025
I0522 10:12:30.930619  9292 solver.cpp:237] Iteration 7000, loss = 1.54507
I0522 10:12:30.930775  9292 solver.cpp:253]     Train net output #0: loss = 1.54507 (* 1 = 1.54507 loss)
I0522 10:12:30.930790  9292 sgd_solver.cpp:106] Iteration 7000, lr = 0.0025
I0522 10:12:41.473309  9292 solver.cpp:237] Iteration 7500, loss = 1.30144
I0522 10:12:41.473351  9292 solver.cpp:253]     Train net output #0: loss = 1.30144 (* 1 = 1.30144 loss)
I0522 10:12:41.473367  9292 sgd_solver.cpp:106] Iteration 7500, lr = 0.0025
I0522 10:12:52.007908  9292 solver.cpp:237] Iteration 8000, loss = 1.27112
I0522 10:12:52.007944  9292 solver.cpp:253]     Train net output #0: loss = 1.27112 (* 1 = 1.27112 loss)
I0522 10:12:52.007957  9292 sgd_solver.cpp:106] Iteration 8000, lr = 0.0025
I0522 10:13:02.555631  9292 solver.cpp:237] Iteration 8500, loss = 1.24788
I0522 10:13:02.555784  9292 solver.cpp:253]     Train net output #0: loss = 1.24788 (* 1 = 1.24788 loss)
I0522 10:13:02.555799  9292 sgd_solver.cpp:106] Iteration 8500, lr = 0.0025
I0522 10:13:13.093338  9292 solver.cpp:237] Iteration 9000, loss = 1.26276
I0522 10:13:13.093374  9292 solver.cpp:253]     Train net output #0: loss = 1.26276 (* 1 = 1.26276 loss)
I0522 10:13:13.093391  9292 sgd_solver.cpp:106] Iteration 9000, lr = 0.0025
I0522 10:13:23.628875  9292 solver.cpp:237] Iteration 9500, loss = 1.29094
I0522 10:13:23.628909  9292 solver.cpp:253]     Train net output #0: loss = 1.29094 (* 1 = 1.29094 loss)
I0522 10:13:23.628926  9292 sgd_solver.cpp:106] Iteration 9500, lr = 0.0025
I0522 10:13:34.144148  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_10000.caffemodel
I0522 10:13:34.196895  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_10000.solverstate
I0522 10:13:34.222621  9292 solver.cpp:341] Iteration 10000, Testing net (#0)
I0522 10:14:23.787577  9292 solver.cpp:409]     Test net output #0: accuracy = 0.833489
I0522 10:14:23.787735  9292 solver.cpp:409]     Test net output #1: loss = 0.578206 (* 1 = 0.578206 loss)
I0522 10:14:45.877449  9292 solver.cpp:237] Iteration 10000, loss = 1.3015
I0522 10:14:45.877501  9292 solver.cpp:253]     Train net output #0: loss = 1.3015 (* 1 = 1.3015 loss)
I0522 10:14:45.877516  9292 sgd_solver.cpp:106] Iteration 10000, lr = 0.0025
I0522 10:14:56.371572  9292 solver.cpp:237] Iteration 10500, loss = 1.05053
I0522 10:14:56.371713  9292 solver.cpp:253]     Train net output #0: loss = 1.05053 (* 1 = 1.05053 loss)
I0522 10:14:56.371728  9292 sgd_solver.cpp:106] Iteration 10500, lr = 0.0025
I0522 10:15:06.870506  9292 solver.cpp:237] Iteration 11000, loss = 1.3314
I0522 10:15:06.870553  9292 solver.cpp:253]     Train net output #0: loss = 1.3314 (* 1 = 1.3314 loss)
I0522 10:15:06.870568  9292 sgd_solver.cpp:106] Iteration 11000, lr = 0.0025
I0522 10:15:17.367137  9292 solver.cpp:237] Iteration 11500, loss = 1.14099
I0522 10:15:17.367173  9292 solver.cpp:253]     Train net output #0: loss = 1.14099 (* 1 = 1.14099 loss)
I0522 10:15:17.367188  9292 sgd_solver.cpp:106] Iteration 11500, lr = 0.0025
I0522 10:15:27.878087  9292 solver.cpp:237] Iteration 12000, loss = 1.38509
I0522 10:15:27.878226  9292 solver.cpp:253]     Train net output #0: loss = 1.38509 (* 1 = 1.38509 loss)
I0522 10:15:27.878242  9292 sgd_solver.cpp:106] Iteration 12000, lr = 0.0025
I0522 10:15:38.379345  9292 solver.cpp:237] Iteration 12500, loss = 1.78609
I0522 10:15:38.379386  9292 solver.cpp:253]     Train net output #0: loss = 1.78609 (* 1 = 1.78609 loss)
I0522 10:15:38.379402  9292 sgd_solver.cpp:106] Iteration 12500, lr = 0.0025
I0522 10:15:48.886109  9292 solver.cpp:237] Iteration 13000, loss = 1.29657
I0522 10:15:48.886144  9292 solver.cpp:253]     Train net output #0: loss = 1.29657 (* 1 = 1.29657 loss)
I0522 10:15:48.886160  9292 sgd_solver.cpp:106] Iteration 13000, lr = 0.0025
I0522 10:16:21.574606  9292 solver.cpp:237] Iteration 13500, loss = 1.24269
I0522 10:16:21.574766  9292 solver.cpp:253]     Train net output #0: loss = 1.24269 (* 1 = 1.24269 loss)
I0522 10:16:21.574780  9292 sgd_solver.cpp:106] Iteration 13500, lr = 0.0025
I0522 10:16:32.056988  9292 solver.cpp:237] Iteration 14000, loss = 1.34423
I0522 10:16:32.057024  9292 solver.cpp:253]     Train net output #0: loss = 1.34423 (* 1 = 1.34423 loss)
I0522 10:16:32.057040  9292 sgd_solver.cpp:106] Iteration 14000, lr = 0.0025
I0522 10:16:42.548022  9292 solver.cpp:237] Iteration 14500, loss = 1.5757
I0522 10:16:42.548058  9292 solver.cpp:253]     Train net output #0: loss = 1.5757 (* 1 = 1.5757 loss)
I0522 10:16:42.548071  9292 sgd_solver.cpp:106] Iteration 14500, lr = 0.0025
I0522 10:16:53.029173  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_15000.caffemodel
I0522 10:16:53.084362  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_15000.solverstate
I0522 10:16:53.118540  9292 solver.cpp:237] Iteration 15000, loss = 1.23448
I0522 10:16:53.118587  9292 solver.cpp:253]     Train net output #0: loss = 1.23448 (* 1 = 1.23448 loss)
I0522 10:16:53.118602  9292 sgd_solver.cpp:106] Iteration 15000, lr = 0.0025
I0522 10:17:03.738252  9292 solver.cpp:237] Iteration 15500, loss = 1.26174
I0522 10:17:03.738288  9292 solver.cpp:253]     Train net output #0: loss = 1.26174 (* 1 = 1.26174 loss)
I0522 10:17:03.738304  9292 sgd_solver.cpp:106] Iteration 15500, lr = 0.0025
I0522 10:17:14.326208  9292 solver.cpp:237] Iteration 16000, loss = 1.02168
I0522 10:17:14.326256  9292 solver.cpp:253]     Train net output #0: loss = 1.02168 (* 1 = 1.02168 loss)
I0522 10:17:14.326272  9292 sgd_solver.cpp:106] Iteration 16000, lr = 0.0025
I0522 10:17:24.851034  9292 solver.cpp:237] Iteration 16500, loss = 0.990193
I0522 10:17:24.851188  9292 solver.cpp:253]     Train net output #0: loss = 0.990194 (* 1 = 0.990194 loss)
I0522 10:17:24.851202  9292 sgd_solver.cpp:106] Iteration 16500, lr = 0.0025
I0522 10:17:57.537420  9292 solver.cpp:237] Iteration 17000, loss = 1.1437
I0522 10:17:57.537583  9292 solver.cpp:253]     Train net output #0: loss = 1.1437 (* 1 = 1.1437 loss)
I0522 10:17:57.537600  9292 sgd_solver.cpp:106] Iteration 17000, lr = 0.0025
I0522 10:18:08.044246  9292 solver.cpp:237] Iteration 17500, loss = 1.43105
I0522 10:18:08.044291  9292 solver.cpp:253]     Train net output #0: loss = 1.43105 (* 1 = 1.43105 loss)
I0522 10:18:08.044307  9292 sgd_solver.cpp:106] Iteration 17500, lr = 0.0025
I0522 10:18:18.546607  9292 solver.cpp:237] Iteration 18000, loss = 1.39697
I0522 10:18:18.546643  9292 solver.cpp:253]     Train net output #0: loss = 1.39697 (* 1 = 1.39697 loss)
I0522 10:18:18.546659  9292 sgd_solver.cpp:106] Iteration 18000, lr = 0.0025
I0522 10:18:29.064785  9292 solver.cpp:237] Iteration 18500, loss = 1.02508
I0522 10:18:29.064939  9292 solver.cpp:253]     Train net output #0: loss = 1.02508 (* 1 = 1.02508 loss)
I0522 10:18:29.064954  9292 sgd_solver.cpp:106] Iteration 18500, lr = 0.0025
I0522 10:18:39.574539  9292 solver.cpp:237] Iteration 19000, loss = 1.76599
I0522 10:18:39.574575  9292 solver.cpp:253]     Train net output #0: loss = 1.76599 (* 1 = 1.76599 loss)
I0522 10:18:39.574591  9292 sgd_solver.cpp:106] Iteration 19000, lr = 0.0025
I0522 10:18:50.089846  9292 solver.cpp:237] Iteration 19500, loss = 0.848594
I0522 10:18:50.089897  9292 solver.cpp:253]     Train net output #0: loss = 0.848595 (* 1 = 0.848595 loss)
I0522 10:18:50.089912  9292 sgd_solver.cpp:106] Iteration 19500, lr = 0.0025
I0522 10:19:00.572530  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_20000.caffemodel
I0522 10:19:00.628253  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_20000.solverstate
I0522 10:19:00.656921  9292 solver.cpp:341] Iteration 20000, Testing net (#0)
I0522 10:20:11.085041  9292 solver.cpp:409]     Test net output #0: accuracy = 0.853647
I0522 10:20:11.085202  9292 solver.cpp:409]     Test net output #1: loss = 0.494681 (* 1 = 0.494681 loss)
I0522 10:20:33.237040  9292 solver.cpp:237] Iteration 20000, loss = 1.10554
I0522 10:20:33.237092  9292 solver.cpp:253]     Train net output #0: loss = 1.10554 (* 1 = 1.10554 loss)
I0522 10:20:33.237107  9292 sgd_solver.cpp:106] Iteration 20000, lr = 0.0025
I0522 10:20:43.782438  9292 solver.cpp:237] Iteration 20500, loss = 0.914421
I0522 10:20:43.782588  9292 solver.cpp:253]     Train net output #0: loss = 0.914422 (* 1 = 0.914422 loss)
I0522 10:20:43.782603  9292 sgd_solver.cpp:106] Iteration 20500, lr = 0.0025
I0522 10:20:54.345136  9292 solver.cpp:237] Iteration 21000, loss = 1.28632
I0522 10:20:54.345181  9292 solver.cpp:253]     Train net output #0: loss = 1.28632 (* 1 = 1.28632 loss)
I0522 10:20:54.345194  9292 sgd_solver.cpp:106] Iteration 21000, lr = 0.0025
I0522 10:21:04.920209  9292 solver.cpp:237] Iteration 21500, loss = 1.38228
I0522 10:21:04.920245  9292 solver.cpp:253]     Train net output #0: loss = 1.38228 (* 1 = 1.38228 loss)
I0522 10:21:04.920258  9292 sgd_solver.cpp:106] Iteration 21500, lr = 0.0025
I0522 10:21:15.526535  9292 solver.cpp:237] Iteration 22000, loss = 1.64591
I0522 10:21:15.526675  9292 solver.cpp:253]     Train net output #0: loss = 1.64591 (* 1 = 1.64591 loss)
I0522 10:21:15.526690  9292 sgd_solver.cpp:106] Iteration 22000, lr = 0.0025
I0522 10:21:26.145804  9292 solver.cpp:237] Iteration 22500, loss = 1.39872
I0522 10:21:26.145848  9292 solver.cpp:253]     Train net output #0: loss = 1.39872 (* 1 = 1.39872 loss)
I0522 10:21:26.145865  9292 sgd_solver.cpp:106] Iteration 22500, lr = 0.0025
I0522 10:21:36.740669  9292 solver.cpp:237] Iteration 23000, loss = 1.42146
I0522 10:21:36.740705  9292 solver.cpp:253]     Train net output #0: loss = 1.42146 (* 1 = 1.42146 loss)
I0522 10:21:36.740720  9292 sgd_solver.cpp:106] Iteration 23000, lr = 0.0025
I0522 10:22:09.436849  9292 solver.cpp:237] Iteration 23500, loss = 1.44537
I0522 10:22:09.436997  9292 solver.cpp:253]     Train net output #0: loss = 1.44537 (* 1 = 1.44537 loss)
I0522 10:22:09.437012  9292 sgd_solver.cpp:106] Iteration 23500, lr = 0.0025
I0522 10:22:20.018882  9292 solver.cpp:237] Iteration 24000, loss = 1.10737
I0522 10:22:20.018918  9292 solver.cpp:253]     Train net output #0: loss = 1.10737 (* 1 = 1.10737 loss)
I0522 10:22:20.018934  9292 sgd_solver.cpp:106] Iteration 24000, lr = 0.0025
I0522 10:22:30.606529  9292 solver.cpp:237] Iteration 24500, loss = 1.17784
I0522 10:22:30.606565  9292 solver.cpp:253]     Train net output #0: loss = 1.17784 (* 1 = 1.17784 loss)
I0522 10:22:30.606581  9292 sgd_solver.cpp:106] Iteration 24500, lr = 0.0025
I0522 10:22:41.181471  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_25000.caffemodel
I0522 10:22:41.236302  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_25000.solverstate
I0522 10:22:41.271567  9292 solver.cpp:237] Iteration 25000, loss = 1.24516
I0522 10:22:41.271616  9292 solver.cpp:253]     Train net output #0: loss = 1.24516 (* 1 = 1.24516 loss)
I0522 10:22:41.271633  9292 sgd_solver.cpp:106] Iteration 25000, lr = 0.0025
I0522 10:22:51.862825  9292 solver.cpp:237] Iteration 25500, loss = 1.20035
I0522 10:22:51.862861  9292 solver.cpp:253]     Train net output #0: loss = 1.20035 (* 1 = 1.20035 loss)
I0522 10:22:51.862876  9292 sgd_solver.cpp:106] Iteration 25500, lr = 0.0025
I0522 10:23:02.456588  9292 solver.cpp:237] Iteration 26000, loss = 1.53492
I0522 10:23:02.456634  9292 solver.cpp:253]     Train net output #0: loss = 1.53493 (* 1 = 1.53493 loss)
I0522 10:23:02.456647  9292 sgd_solver.cpp:106] Iteration 26000, lr = 0.0025
I0522 10:23:13.054821  9292 solver.cpp:237] Iteration 26500, loss = 1.23158
I0522 10:23:13.054966  9292 solver.cpp:253]     Train net output #0: loss = 1.23158 (* 1 = 1.23158 loss)
I0522 10:23:13.054980  9292 sgd_solver.cpp:106] Iteration 26500, lr = 0.0025
I0522 10:23:45.807513  9292 solver.cpp:237] Iteration 27000, loss = 1.1524
I0522 10:23:45.807687  9292 solver.cpp:253]     Train net output #0: loss = 1.1524 (* 1 = 1.1524 loss)
I0522 10:23:45.807703  9292 sgd_solver.cpp:106] Iteration 27000, lr = 0.0025
I0522 10:23:56.417683  9292 solver.cpp:237] Iteration 27500, loss = 0.754313
I0522 10:23:56.417729  9292 solver.cpp:253]     Train net output #0: loss = 0.754314 (* 1 = 0.754314 loss)
I0522 10:23:56.417743  9292 sgd_solver.cpp:106] Iteration 27500, lr = 0.0025
I0522 10:24:07.010042  9292 solver.cpp:237] Iteration 28000, loss = 1.38455
I0522 10:24:07.010078  9292 solver.cpp:253]     Train net output #0: loss = 1.38455 (* 1 = 1.38455 loss)
I0522 10:24:07.010094  9292 sgd_solver.cpp:106] Iteration 28000, lr = 0.0025
I0522 10:24:17.621083  9292 solver.cpp:237] Iteration 28500, loss = 1.28878
I0522 10:24:17.621240  9292 solver.cpp:253]     Train net output #0: loss = 1.28878 (* 1 = 1.28878 loss)
I0522 10:24:17.621256  9292 sgd_solver.cpp:106] Iteration 28500, lr = 0.0025
I0522 10:24:28.220955  9292 solver.cpp:237] Iteration 29000, loss = 1.03176
I0522 10:24:28.220991  9292 solver.cpp:253]     Train net output #0: loss = 1.03176 (* 1 = 1.03176 loss)
I0522 10:24:28.221007  9292 sgd_solver.cpp:106] Iteration 29000, lr = 0.0025
I0522 10:24:38.823307  9292 solver.cpp:237] Iteration 29500, loss = 0.840573
I0522 10:24:38.823343  9292 solver.cpp:253]     Train net output #0: loss = 0.840574 (* 1 = 0.840574 loss)
I0522 10:24:38.823357  9292 sgd_solver.cpp:106] Iteration 29500, lr = 0.0025
I0522 10:24:49.397357  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_30000.caffemodel
I0522 10:24:49.451033  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_30000.solverstate
I0522 10:24:49.477345  9292 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 10:25:38.675659  9292 solver.cpp:409]     Test net output #0: accuracy = 0.86903
I0522 10:25:38.675829  9292 solver.cpp:409]     Test net output #1: loss = 0.448628 (* 1 = 0.448628 loss)
I0522 10:26:00.823055  9292 solver.cpp:237] Iteration 30000, loss = 0.778747
I0522 10:26:00.823113  9292 solver.cpp:253]     Train net output #0: loss = 0.778748 (* 1 = 0.778748 loss)
I0522 10:26:00.823132  9292 sgd_solver.cpp:106] Iteration 30000, lr = 0.0025
I0522 10:26:11.353637  9292 solver.cpp:237] Iteration 30500, loss = 1.40795
I0522 10:26:11.353790  9292 solver.cpp:253]     Train net output #0: loss = 1.40795 (* 1 = 1.40795 loss)
I0522 10:26:11.353804  9292 sgd_solver.cpp:106] Iteration 30500, lr = 0.0025
I0522 10:26:21.891770  9292 solver.cpp:237] Iteration 31000, loss = 1.17041
I0522 10:26:21.891818  9292 solver.cpp:253]     Train net output #0: loss = 1.17041 (* 1 = 1.17041 loss)
I0522 10:26:21.891832  9292 sgd_solver.cpp:106] Iteration 31000, lr = 0.0025
I0522 10:26:32.436303  9292 solver.cpp:237] Iteration 31500, loss = 1.30817
I0522 10:26:32.436341  9292 solver.cpp:253]     Train net output #0: loss = 1.30817 (* 1 = 1.30817 loss)
I0522 10:26:32.436357  9292 sgd_solver.cpp:106] Iteration 31500, lr = 0.0025
I0522 10:26:42.974692  9292 solver.cpp:237] Iteration 32000, loss = 1.0146
I0522 10:26:42.974835  9292 solver.cpp:253]     Train net output #0: loss = 1.01461 (* 1 = 1.01461 loss)
I0522 10:26:42.974849  9292 sgd_solver.cpp:106] Iteration 32000, lr = 0.0025
I0522 10:26:53.503268  9292 solver.cpp:237] Iteration 32500, loss = 1.5156
I0522 10:26:53.503309  9292 solver.cpp:253]     Train net output #0: loss = 1.5156 (* 1 = 1.5156 loss)
I0522 10:26:53.503326  9292 sgd_solver.cpp:106] Iteration 32500, lr = 0.0025
I0522 10:27:04.014767  9292 solver.cpp:237] Iteration 33000, loss = 1.23447
I0522 10:27:04.014803  9292 solver.cpp:253]     Train net output #0: loss = 1.23447 (* 1 = 1.23447 loss)
I0522 10:27:04.014819  9292 sgd_solver.cpp:106] Iteration 33000, lr = 0.0025
I0522 10:27:36.743544  9292 solver.cpp:237] Iteration 33500, loss = 1.35014
I0522 10:27:36.743715  9292 solver.cpp:253]     Train net output #0: loss = 1.35014 (* 1 = 1.35014 loss)
I0522 10:27:36.743729  9292 sgd_solver.cpp:106] Iteration 33500, lr = 0.0025
I0522 10:27:47.269867  9292 solver.cpp:237] Iteration 34000, loss = 0.846178
I0522 10:27:47.269904  9292 solver.cpp:253]     Train net output #0: loss = 0.846179 (* 1 = 0.846179 loss)
I0522 10:27:47.269920  9292 sgd_solver.cpp:106] Iteration 34000, lr = 0.0025
I0522 10:27:57.793648  9292 solver.cpp:237] Iteration 34500, loss = 0.879544
I0522 10:27:57.793684  9292 solver.cpp:253]     Train net output #0: loss = 0.879545 (* 1 = 0.879545 loss)
I0522 10:27:57.793699  9292 sgd_solver.cpp:106] Iteration 34500, lr = 0.0025
I0522 10:28:08.286952  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_35000.caffemodel
I0522 10:28:08.339752  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_35000.solverstate
I0522 10:28:08.372995  9292 solver.cpp:237] Iteration 35000, loss = 0.961953
I0522 10:28:08.373042  9292 solver.cpp:253]     Train net output #0: loss = 0.961954 (* 1 = 0.961954 loss)
I0522 10:28:08.373060  9292 sgd_solver.cpp:106] Iteration 35000, lr = 0.0025
I0522 10:28:18.894321  9292 solver.cpp:237] Iteration 35500, loss = 1.01181
I0522 10:28:18.894358  9292 solver.cpp:253]     Train net output #0: loss = 1.01182 (* 1 = 1.01182 loss)
I0522 10:28:18.894373  9292 sgd_solver.cpp:106] Iteration 35500, lr = 0.0025
I0522 10:28:29.410197  9292 solver.cpp:237] Iteration 36000, loss = 1.32314
I0522 10:28:29.410243  9292 solver.cpp:253]     Train net output #0: loss = 1.32314 (* 1 = 1.32314 loss)
I0522 10:28:29.410256  9292 sgd_solver.cpp:106] Iteration 36000, lr = 0.0025
I0522 10:28:39.923054  9292 solver.cpp:237] Iteration 36500, loss = 1.00617
I0522 10:28:39.923207  9292 solver.cpp:253]     Train net output #0: loss = 1.00617 (* 1 = 1.00617 loss)
I0522 10:28:39.923223  9292 sgd_solver.cpp:106] Iteration 36500, lr = 0.0025
I0522 10:29:12.588949  9292 solver.cpp:237] Iteration 37000, loss = 1.44778
I0522 10:29:12.589118  9292 solver.cpp:253]     Train net output #0: loss = 1.44778 (* 1 = 1.44778 loss)
I0522 10:29:12.589133  9292 sgd_solver.cpp:106] Iteration 37000, lr = 0.0025
I0522 10:29:23.106302  9292 solver.cpp:237] Iteration 37500, loss = 1.26998
I0522 10:29:23.106345  9292 solver.cpp:253]     Train net output #0: loss = 1.26998 (* 1 = 1.26998 loss)
I0522 10:29:23.106359  9292 sgd_solver.cpp:106] Iteration 37500, lr = 0.0025
I0522 10:29:33.633831  9292 solver.cpp:237] Iteration 38000, loss = 1.31508
I0522 10:29:33.633867  9292 solver.cpp:253]     Train net output #0: loss = 1.31508 (* 1 = 1.31508 loss)
I0522 10:29:33.633883  9292 sgd_solver.cpp:106] Iteration 38000, lr = 0.0025
I0522 10:29:44.164293  9292 solver.cpp:237] Iteration 38500, loss = 1.56403
I0522 10:29:44.164511  9292 solver.cpp:253]     Train net output #0: loss = 1.56403 (* 1 = 1.56403 loss)
I0522 10:29:44.164525  9292 sgd_solver.cpp:106] Iteration 38500, lr = 0.0025
I0522 10:29:54.672221  9292 solver.cpp:237] Iteration 39000, loss = 1.18577
I0522 10:29:54.672256  9292 solver.cpp:253]     Train net output #0: loss = 1.18577 (* 1 = 1.18577 loss)
I0522 10:29:54.672272  9292 sgd_solver.cpp:106] Iteration 39000, lr = 0.0025
I0522 10:30:05.189286  9292 solver.cpp:237] Iteration 39500, loss = 0.850927
I0522 10:30:05.189333  9292 solver.cpp:253]     Train net output #0: loss = 0.850928 (* 1 = 0.850928 loss)
I0522 10:30:05.189347  9292 sgd_solver.cpp:106] Iteration 39500, lr = 0.0025
I0522 10:30:15.681828  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_40000.caffemodel
I0522 10:30:15.738786  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_40000.solverstate
I0522 10:30:15.764931  9292 solver.cpp:341] Iteration 40000, Testing net (#0)
I0522 10:31:26.212548  9292 solver.cpp:409]     Test net output #0: accuracy = 0.871503
I0522 10:31:26.212713  9292 solver.cpp:409]     Test net output #1: loss = 0.406941 (* 1 = 0.406941 loss)
I0522 10:31:48.368778  9292 solver.cpp:237] Iteration 40000, loss = 1.3407
I0522 10:31:48.368830  9292 solver.cpp:253]     Train net output #0: loss = 1.3407 (* 1 = 1.3407 loss)
I0522 10:31:48.368845  9292 sgd_solver.cpp:106] Iteration 40000, lr = 0.0025
I0522 10:31:58.860515  9292 solver.cpp:237] Iteration 40500, loss = 0.990094
I0522 10:31:58.860671  9292 solver.cpp:253]     Train net output #0: loss = 0.990095 (* 1 = 0.990095 loss)
I0522 10:31:58.860684  9292 sgd_solver.cpp:106] Iteration 40500, lr = 0.0025
I0522 10:32:09.363858  9292 solver.cpp:237] Iteration 41000, loss = 1.29562
I0522 10:32:09.363906  9292 solver.cpp:253]     Train net output #0: loss = 1.29562 (* 1 = 1.29562 loss)
I0522 10:32:09.363925  9292 sgd_solver.cpp:106] Iteration 41000, lr = 0.0025
I0522 10:32:19.876426  9292 solver.cpp:237] Iteration 41500, loss = 0.951467
I0522 10:32:19.876462  9292 solver.cpp:253]     Train net output #0: loss = 0.951468 (* 1 = 0.951468 loss)
I0522 10:32:19.876477  9292 sgd_solver.cpp:106] Iteration 41500, lr = 0.0025
I0522 10:32:30.387778  9292 solver.cpp:237] Iteration 42000, loss = 1.01723
I0522 10:32:30.387923  9292 solver.cpp:253]     Train net output #0: loss = 1.01724 (* 1 = 1.01724 loss)
I0522 10:32:30.387938  9292 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0522 10:32:40.899169  9292 solver.cpp:237] Iteration 42500, loss = 1.10611
I0522 10:32:40.899207  9292 solver.cpp:253]     Train net output #0: loss = 1.10611 (* 1 = 1.10611 loss)
I0522 10:32:40.899220  9292 sgd_solver.cpp:106] Iteration 42500, lr = 0.0025
I0522 10:32:51.406621  9292 solver.cpp:237] Iteration 43000, loss = 0.908158
I0522 10:32:51.406657  9292 solver.cpp:253]     Train net output #0: loss = 0.908159 (* 1 = 0.908159 loss)
I0522 10:32:51.406672  9292 sgd_solver.cpp:106] Iteration 43000, lr = 0.0025
I0522 10:33:24.077363  9292 solver.cpp:237] Iteration 43500, loss = 1.20128
I0522 10:33:24.087028  9292 solver.cpp:253]     Train net output #0: loss = 1.20128 (* 1 = 1.20128 loss)
I0522 10:33:24.087046  9292 sgd_solver.cpp:106] Iteration 43500, lr = 0.0025
I0522 10:33:34.584664  9292 solver.cpp:237] Iteration 44000, loss = 1.13769
I0522 10:33:34.584700  9292 solver.cpp:253]     Train net output #0: loss = 1.13769 (* 1 = 1.13769 loss)
I0522 10:33:34.584717  9292 sgd_solver.cpp:106] Iteration 44000, lr = 0.0025
I0522 10:33:45.091786  9292 solver.cpp:237] Iteration 44500, loss = 1.2037
I0522 10:33:45.091822  9292 solver.cpp:253]     Train net output #0: loss = 1.20371 (* 1 = 1.20371 loss)
I0522 10:33:45.091841  9292 sgd_solver.cpp:106] Iteration 44500, lr = 0.0025
I0522 10:33:55.574390  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_45000.caffemodel
I0522 10:33:55.632081  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_45000.solverstate
I0522 10:33:55.667093  9292 solver.cpp:237] Iteration 45000, loss = 1.38729
I0522 10:33:55.667142  9292 solver.cpp:253]     Train net output #0: loss = 1.38729 (* 1 = 1.38729 loss)
I0522 10:33:55.667158  9292 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0522 10:34:06.187800  9292 solver.cpp:237] Iteration 45500, loss = 0.794896
I0522 10:34:06.187837  9292 solver.cpp:253]     Train net output #0: loss = 0.794897 (* 1 = 0.794897 loss)
I0522 10:34:06.187852  9292 sgd_solver.cpp:106] Iteration 45500, lr = 0.0025
I0522 10:34:16.702668  9292 solver.cpp:237] Iteration 46000, loss = 1.35931
I0522 10:34:16.702718  9292 solver.cpp:253]     Train net output #0: loss = 1.35931 (* 1 = 1.35931 loss)
I0522 10:34:16.702733  9292 sgd_solver.cpp:106] Iteration 46000, lr = 0.0025
I0522 10:34:27.213708  9292 solver.cpp:237] Iteration 46500, loss = 1.38144
I0522 10:34:27.213872  9292 solver.cpp:253]     Train net output #0: loss = 1.38144 (* 1 = 1.38144 loss)
I0522 10:34:27.213887  9292 sgd_solver.cpp:106] Iteration 46500, lr = 0.0025
I0522 10:34:59.903709  9292 solver.cpp:237] Iteration 47000, loss = 1.003
I0522 10:34:59.903880  9292 solver.cpp:253]     Train net output #0: loss = 1.003 (* 1 = 1.003 loss)
I0522 10:34:59.903895  9292 sgd_solver.cpp:106] Iteration 47000, lr = 0.0025
I0522 10:35:10.447795  9292 solver.cpp:237] Iteration 47500, loss = 1.67204
I0522 10:35:10.447844  9292 solver.cpp:253]     Train net output #0: loss = 1.67204 (* 1 = 1.67204 loss)
I0522 10:35:10.447859  9292 sgd_solver.cpp:106] Iteration 47500, lr = 0.0025
I0522 10:35:21.050940  9292 solver.cpp:237] Iteration 48000, loss = 1.31984
I0522 10:35:21.050976  9292 solver.cpp:253]     Train net output #0: loss = 1.31984 (* 1 = 1.31984 loss)
I0522 10:35:21.050989  9292 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0522 10:35:31.653380  9292 solver.cpp:237] Iteration 48500, loss = 1.09677
I0522 10:35:31.653540  9292 solver.cpp:253]     Train net output #0: loss = 1.09677 (* 1 = 1.09677 loss)
I0522 10:35:31.653556  9292 sgd_solver.cpp:106] Iteration 48500, lr = 0.0025
I0522 10:35:42.247480  9292 solver.cpp:237] Iteration 49000, loss = 1.34609
I0522 10:35:42.247515  9292 solver.cpp:253]     Train net output #0: loss = 1.34609 (* 1 = 1.34609 loss)
I0522 10:35:42.247532  9292 sgd_solver.cpp:106] Iteration 49000, lr = 0.0025
I0522 10:35:52.844985  9292 solver.cpp:237] Iteration 49500, loss = 1.28399
I0522 10:35:52.845021  9292 solver.cpp:253]     Train net output #0: loss = 1.28399 (* 1 = 1.28399 loss)
I0522 10:35:52.845036  9292 sgd_solver.cpp:106] Iteration 49500, lr = 0.0025
I0522 10:36:03.428936  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_50000.caffemodel
I0522 10:36:03.528236  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_50000.solverstate
I0522 10:36:03.556488  9292 solver.cpp:341] Iteration 50000, Testing net (#0)
I0522 10:36:53.093032  9292 solver.cpp:409]     Test net output #0: accuracy = 0.88576
I0522 10:36:53.093194  9292 solver.cpp:409]     Test net output #1: loss = 0.398442 (* 1 = 0.398442 loss)
I0522 10:37:13.987328  9292 solver.cpp:237] Iteration 50000, loss = 1.10734
I0522 10:37:13.987380  9292 solver.cpp:253]     Train net output #0: loss = 1.10734 (* 1 = 1.10734 loss)
I0522 10:37:13.987396  9292 sgd_solver.cpp:106] Iteration 50000, lr = 0.0025
I0522 10:37:24.490844  9292 solver.cpp:237] Iteration 50500, loss = 1.24379
I0522 10:37:24.490998  9292 solver.cpp:253]     Train net output #0: loss = 1.24379 (* 1 = 1.24379 loss)
I0522 10:37:24.491010  9292 sgd_solver.cpp:106] Iteration 50500, lr = 0.0025
I0522 10:37:34.984879  9292 solver.cpp:237] Iteration 51000, loss = 1.38225
I0522 10:37:34.984923  9292 solver.cpp:253]     Train net output #0: loss = 1.38225 (* 1 = 1.38225 loss)
I0522 10:37:34.984937  9292 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0522 10:37:45.484405  9292 solver.cpp:237] Iteration 51500, loss = 1.43622
I0522 10:37:45.484441  9292 solver.cpp:253]     Train net output #0: loss = 1.43622 (* 1 = 1.43622 loss)
I0522 10:37:45.484457  9292 sgd_solver.cpp:106] Iteration 51500, lr = 0.0025
I0522 10:37:55.977614  9292 solver.cpp:237] Iteration 52000, loss = 0.857938
I0522 10:37:55.977762  9292 solver.cpp:253]     Train net output #0: loss = 0.857939 (* 1 = 0.857939 loss)
I0522 10:37:55.977777  9292 sgd_solver.cpp:106] Iteration 52000, lr = 0.0025
I0522 10:38:06.498205  9292 solver.cpp:237] Iteration 52500, loss = 1.34037
I0522 10:38:06.498253  9292 solver.cpp:253]     Train net output #0: loss = 1.34037 (* 1 = 1.34037 loss)
I0522 10:38:06.498268  9292 sgd_solver.cpp:106] Iteration 52500, lr = 0.0025
I0522 10:38:16.990384  9292 solver.cpp:237] Iteration 53000, loss = 1.30096
I0522 10:38:16.990420  9292 solver.cpp:253]     Train net output #0: loss = 1.30096 (* 1 = 1.30096 loss)
I0522 10:38:16.990437  9292 sgd_solver.cpp:106] Iteration 53000, lr = 0.0025
I0522 10:38:48.378432  9292 solver.cpp:237] Iteration 53500, loss = 1.17585
I0522 10:38:48.378608  9292 solver.cpp:253]     Train net output #0: loss = 1.17585 (* 1 = 1.17585 loss)
I0522 10:38:48.378623  9292 sgd_solver.cpp:106] Iteration 53500, lr = 0.0025
I0522 10:38:58.901463  9292 solver.cpp:237] Iteration 54000, loss = 1.06559
I0522 10:38:58.901504  9292 solver.cpp:253]     Train net output #0: loss = 1.06559 (* 1 = 1.06559 loss)
I0522 10:38:58.901516  9292 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0522 10:39:09.407860  9292 solver.cpp:237] Iteration 54500, loss = 1.67169
I0522 10:39:09.407896  9292 solver.cpp:253]     Train net output #0: loss = 1.67169 (* 1 = 1.67169 loss)
I0522 10:39:09.407912  9292 sgd_solver.cpp:106] Iteration 54500, lr = 0.0025
I0522 10:39:19.892091  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_55000.caffemodel
I0522 10:39:19.944370  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_55000.solverstate
I0522 10:39:19.977684  9292 solver.cpp:237] Iteration 55000, loss = 0.973328
I0522 10:39:19.977726  9292 solver.cpp:253]     Train net output #0: loss = 0.97333 (* 1 = 0.97333 loss)
I0522 10:39:19.977748  9292 sgd_solver.cpp:106] Iteration 55000, lr = 0.0025
I0522 10:39:30.492441  9292 solver.cpp:237] Iteration 55500, loss = 0.992374
I0522 10:39:30.492480  9292 solver.cpp:253]     Train net output #0: loss = 0.992375 (* 1 = 0.992375 loss)
I0522 10:39:30.492494  9292 sgd_solver.cpp:106] Iteration 55500, lr = 0.0025
I0522 10:39:41.014286  9292 solver.cpp:237] Iteration 56000, loss = 0.811701
I0522 10:39:41.014335  9292 solver.cpp:253]     Train net output #0: loss = 0.811703 (* 1 = 0.811703 loss)
I0522 10:39:41.014349  9292 sgd_solver.cpp:106] Iteration 56000, lr = 0.0025
I0522 10:39:51.520613  9292 solver.cpp:237] Iteration 56500, loss = 1.53281
I0522 10:39:51.520768  9292 solver.cpp:253]     Train net output #0: loss = 1.53281 (* 1 = 1.53281 loss)
I0522 10:39:51.520781  9292 sgd_solver.cpp:106] Iteration 56500, lr = 0.0025
I0522 10:40:22.856372  9292 solver.cpp:237] Iteration 57000, loss = 1.38673
I0522 10:40:22.856545  9292 solver.cpp:253]     Train net output #0: loss = 1.38673 (* 1 = 1.38673 loss)
I0522 10:40:22.856560  9292 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0522 10:40:33.356459  9292 solver.cpp:237] Iteration 57500, loss = 1.08723
I0522 10:40:33.356503  9292 solver.cpp:253]     Train net output #0: loss = 1.08723 (* 1 = 1.08723 loss)
I0522 10:40:33.356516  9292 sgd_solver.cpp:106] Iteration 57500, lr = 0.0025
I0522 10:40:43.859805  9292 solver.cpp:237] Iteration 58000, loss = 1.03119
I0522 10:40:43.859841  9292 solver.cpp:253]     Train net output #0: loss = 1.03119 (* 1 = 1.03119 loss)
I0522 10:40:43.859856  9292 sgd_solver.cpp:106] Iteration 58000, lr = 0.0025
I0522 10:40:54.363471  9292 solver.cpp:237] Iteration 58500, loss = 1.17682
I0522 10:40:54.363625  9292 solver.cpp:253]     Train net output #0: loss = 1.17682 (* 1 = 1.17682 loss)
I0522 10:40:54.363638  9292 sgd_solver.cpp:106] Iteration 58500, lr = 0.0025
I0522 10:41:04.864660  9292 solver.cpp:237] Iteration 59000, loss = 1.1988
I0522 10:41:04.864696  9292 solver.cpp:253]     Train net output #0: loss = 1.1988 (* 1 = 1.1988 loss)
I0522 10:41:04.864712  9292 sgd_solver.cpp:106] Iteration 59000, lr = 0.0025
I0522 10:41:15.368592  9292 solver.cpp:237] Iteration 59500, loss = 1.25072
I0522 10:41:15.368628  9292 solver.cpp:253]     Train net output #0: loss = 1.25072 (* 1 = 1.25072 loss)
I0522 10:41:15.368641  9292 sgd_solver.cpp:106] Iteration 59500, lr = 0.0025
I0522 10:41:25.858074  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_60000.caffemodel
I0522 10:41:25.910984  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_60000.solverstate
I0522 10:41:25.937500  9292 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 10:42:36.294446  9292 solver.cpp:409]     Test net output #0: accuracy = 0.886334
I0522 10:42:36.294613  9292 solver.cpp:409]     Test net output #1: loss = 0.36374 (* 1 = 0.36374 loss)
I0522 10:42:57.152606  9292 solver.cpp:237] Iteration 60000, loss = 1.03378
I0522 10:42:57.152660  9292 solver.cpp:253]     Train net output #0: loss = 1.03379 (* 1 = 1.03379 loss)
I0522 10:42:57.152675  9292 sgd_solver.cpp:106] Iteration 60000, lr = 0.0025
I0522 10:43:07.743224  9292 solver.cpp:237] Iteration 60500, loss = 1.44673
I0522 10:43:07.743389  9292 solver.cpp:253]     Train net output #0: loss = 1.44673 (* 1 = 1.44673 loss)
I0522 10:43:07.743403  9292 sgd_solver.cpp:106] Iteration 60500, lr = 0.0025
I0522 10:43:18.330226  9292 solver.cpp:237] Iteration 61000, loss = 1.16048
I0522 10:43:18.330262  9292 solver.cpp:253]     Train net output #0: loss = 1.16048 (* 1 = 1.16048 loss)
I0522 10:43:18.330278  9292 sgd_solver.cpp:106] Iteration 61000, lr = 0.0025
I0522 10:43:28.916512  9292 solver.cpp:237] Iteration 61500, loss = 1.50228
I0522 10:43:28.916558  9292 solver.cpp:253]     Train net output #0: loss = 1.50228 (* 1 = 1.50228 loss)
I0522 10:43:28.916573  9292 sgd_solver.cpp:106] Iteration 61500, lr = 0.0025
I0522 10:43:39.506306  9292 solver.cpp:237] Iteration 62000, loss = 1.0822
I0522 10:43:39.506454  9292 solver.cpp:253]     Train net output #0: loss = 1.0822 (* 1 = 1.0822 loss)
I0522 10:43:39.506469  9292 sgd_solver.cpp:106] Iteration 62000, lr = 0.0025
I0522 10:43:50.062410  9292 solver.cpp:237] Iteration 62500, loss = 1.12778
I0522 10:43:50.062458  9292 solver.cpp:253]     Train net output #0: loss = 1.12778 (* 1 = 1.12778 loss)
I0522 10:43:50.062474  9292 sgd_solver.cpp:106] Iteration 62500, lr = 0.0025
I0522 10:44:00.628567  9292 solver.cpp:237] Iteration 63000, loss = 1.18611
I0522 10:44:00.628603  9292 solver.cpp:253]     Train net output #0: loss = 1.18611 (* 1 = 1.18611 loss)
I0522 10:44:00.628619  9292 sgd_solver.cpp:106] Iteration 63000, lr = 0.0025
I0522 10:44:32.038599  9292 solver.cpp:237] Iteration 63500, loss = 1.02099
I0522 10:44:32.038769  9292 solver.cpp:253]     Train net output #0: loss = 1.02099 (* 1 = 1.02099 loss)
I0522 10:44:32.038785  9292 sgd_solver.cpp:106] Iteration 63500, lr = 0.0025
I0522 10:44:42.626137  9292 solver.cpp:237] Iteration 64000, loss = 0.838405
I0522 10:44:42.626185  9292 solver.cpp:253]     Train net output #0: loss = 0.838407 (* 1 = 0.838407 loss)
I0522 10:44:42.626200  9292 sgd_solver.cpp:106] Iteration 64000, lr = 0.0025
I0522 10:44:53.210031  9292 solver.cpp:237] Iteration 64500, loss = 1.48659
I0522 10:44:53.210067  9292 solver.cpp:253]     Train net output #0: loss = 1.48659 (* 1 = 1.48659 loss)
I0522 10:44:53.210083  9292 sgd_solver.cpp:106] Iteration 64500, lr = 0.0025
I0522 10:45:03.757499  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_65000.caffemodel
I0522 10:45:03.809675  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_65000.solverstate
I0522 10:45:03.842417  9292 solver.cpp:237] Iteration 65000, loss = 1.12154
I0522 10:45:03.842463  9292 solver.cpp:253]     Train net output #0: loss = 1.12154 (* 1 = 1.12154 loss)
I0522 10:45:03.842479  9292 sgd_solver.cpp:106] Iteration 65000, lr = 0.0025
I0522 10:45:14.410578  9292 solver.cpp:237] Iteration 65500, loss = 1.09139
I0522 10:45:14.410621  9292 solver.cpp:253]     Train net output #0: loss = 1.09139 (* 1 = 1.09139 loss)
I0522 10:45:14.410636  9292 sgd_solver.cpp:106] Iteration 65500, lr = 0.0025
I0522 10:45:24.987467  9292 solver.cpp:237] Iteration 66000, loss = 1.28373
I0522 10:45:24.987503  9292 solver.cpp:253]     Train net output #0: loss = 1.28373 (* 1 = 1.28373 loss)
I0522 10:45:24.987519  9292 sgd_solver.cpp:106] Iteration 66000, lr = 0.0025
I0522 10:45:35.574321  9292 solver.cpp:237] Iteration 66500, loss = 0.727537
I0522 10:45:35.574498  9292 solver.cpp:253]     Train net output #0: loss = 0.727539 (* 1 = 0.727539 loss)
I0522 10:45:35.574514  9292 sgd_solver.cpp:106] Iteration 66500, lr = 0.0025
I0522 10:46:07.037979  9292 solver.cpp:237] Iteration 67000, loss = 1.49118
I0522 10:46:07.038153  9292 solver.cpp:253]     Train net output #0: loss = 1.49119 (* 1 = 1.49119 loss)
I0522 10:46:07.038169  9292 sgd_solver.cpp:106] Iteration 67000, lr = 0.0025
I0522 10:46:17.605778  9292 solver.cpp:237] Iteration 67500, loss = 1.31988
I0522 10:46:17.605814  9292 solver.cpp:253]     Train net output #0: loss = 1.31988 (* 1 = 1.31988 loss)
I0522 10:46:17.605830  9292 sgd_solver.cpp:106] Iteration 67500, lr = 0.0025
I0522 10:46:28.188680  9292 solver.cpp:237] Iteration 68000, loss = 1.17944
I0522 10:46:28.188724  9292 solver.cpp:253]     Train net output #0: loss = 1.17944 (* 1 = 1.17944 loss)
I0522 10:46:28.188740  9292 sgd_solver.cpp:106] Iteration 68000, lr = 0.0025
I0522 10:46:38.767603  9292 solver.cpp:237] Iteration 68500, loss = 0.946478
I0522 10:46:38.767753  9292 solver.cpp:253]     Train net output #0: loss = 0.946479 (* 1 = 0.946479 loss)
I0522 10:46:38.767768  9292 sgd_solver.cpp:106] Iteration 68500, lr = 0.0025
I0522 10:46:49.348335  9292 solver.cpp:237] Iteration 69000, loss = 1.12396
I0522 10:46:49.348381  9292 solver.cpp:253]     Train net output #0: loss = 1.12396 (* 1 = 1.12396 loss)
I0522 10:46:49.348395  9292 sgd_solver.cpp:106] Iteration 69000, lr = 0.0025
I0522 10:46:59.925735  9292 solver.cpp:237] Iteration 69500, loss = 1.1531
I0522 10:46:59.925771  9292 solver.cpp:253]     Train net output #0: loss = 1.1531 (* 1 = 1.1531 loss)
I0522 10:46:59.925786  9292 sgd_solver.cpp:106] Iteration 69500, lr = 0.0025
I0522 10:47:10.481626  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_70000.caffemodel
I0522 10:47:10.534633  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_70000.solverstate
I0522 10:47:10.560736  9292 solver.cpp:341] Iteration 70000, Testing net (#0)
I0522 10:47:59.772776  9292 solver.cpp:409]     Test net output #0: accuracy = 0.886928
I0522 10:47:59.772929  9292 solver.cpp:409]     Test net output #1: loss = 0.385741 (* 1 = 0.385741 loss)
I0522 10:48:20.599011  9292 solver.cpp:237] Iteration 70000, loss = 1.27425
I0522 10:48:20.599064  9292 solver.cpp:253]     Train net output #0: loss = 1.27425 (* 1 = 1.27425 loss)
I0522 10:48:20.599079  9292 sgd_solver.cpp:106] Iteration 70000, lr = 0.0025
I0522 10:48:31.142213  9292 solver.cpp:237] Iteration 70500, loss = 1.02228
I0522 10:48:31.142385  9292 solver.cpp:253]     Train net output #0: loss = 1.02229 (* 1 = 1.02229 loss)
I0522 10:48:31.142400  9292 sgd_solver.cpp:106] Iteration 70500, lr = 0.0025
I0522 10:48:41.697926  9292 solver.cpp:237] Iteration 71000, loss = 1.52243
I0522 10:48:41.697962  9292 solver.cpp:253]     Train net output #0: loss = 1.52243 (* 1 = 1.52243 loss)
I0522 10:48:41.697975  9292 sgd_solver.cpp:106] Iteration 71000, lr = 0.0025
I0522 10:48:52.251297  9292 solver.cpp:237] Iteration 71500, loss = 1.25906
I0522 10:48:52.251348  9292 solver.cpp:253]     Train net output #0: loss = 1.25906 (* 1 = 1.25906 loss)
I0522 10:48:52.251361  9292 sgd_solver.cpp:106] Iteration 71500, lr = 0.0025
I0522 10:49:02.804522  9292 solver.cpp:237] Iteration 72000, loss = 1.1965
I0522 10:49:02.804684  9292 solver.cpp:253]     Train net output #0: loss = 1.1965 (* 1 = 1.1965 loss)
I0522 10:49:02.804702  9292 sgd_solver.cpp:106] Iteration 72000, lr = 0.0025
I0522 10:49:13.351083  9292 solver.cpp:237] Iteration 72500, loss = 1.1151
I0522 10:49:13.351122  9292 solver.cpp:253]     Train net output #0: loss = 1.1151 (* 1 = 1.1151 loss)
I0522 10:49:13.351136  9292 sgd_solver.cpp:106] Iteration 72500, lr = 0.0025
I0522 10:49:23.905802  9292 solver.cpp:237] Iteration 73000, loss = 1.55752
I0522 10:49:23.905848  9292 solver.cpp:253]     Train net output #0: loss = 1.55752 (* 1 = 1.55752 loss)
I0522 10:49:23.905861  9292 sgd_solver.cpp:106] Iteration 73000, lr = 0.0025
I0522 10:49:55.303316  9292 solver.cpp:237] Iteration 73500, loss = 1.13208
I0522 10:49:55.303494  9292 solver.cpp:253]     Train net output #0: loss = 1.13208 (* 1 = 1.13208 loss)
I0522 10:49:55.303511  9292 sgd_solver.cpp:106] Iteration 73500, lr = 0.0025
I0522 10:50:05.848822  9292 solver.cpp:237] Iteration 74000, loss = 1.32784
I0522 10:50:05.848868  9292 solver.cpp:253]     Train net output #0: loss = 1.32784 (* 1 = 1.32784 loss)
I0522 10:50:05.848882  9292 sgd_solver.cpp:106] Iteration 74000, lr = 0.0025
I0522 10:50:16.387508  9292 solver.cpp:237] Iteration 74500, loss = 1.19703
I0522 10:50:16.387544  9292 solver.cpp:253]     Train net output #0: loss = 1.19703 (* 1 = 1.19703 loss)
I0522 10:50:16.387558  9292 sgd_solver.cpp:106] Iteration 74500, lr = 0.0025
I0522 10:50:26.925760  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_75000.caffemodel
I0522 10:50:26.980289  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_75000.solverstate
I0522 10:50:27.015404  9292 solver.cpp:237] Iteration 75000, loss = 1.11516
I0522 10:50:27.015455  9292 solver.cpp:253]     Train net output #0: loss = 1.11516 (* 1 = 1.11516 loss)
I0522 10:50:27.015470  9292 sgd_solver.cpp:106] Iteration 75000, lr = 0.0025
I0522 10:50:37.566459  9292 solver.cpp:237] Iteration 75500, loss = 0.978195
I0522 10:50:37.566507  9292 solver.cpp:253]     Train net output #0: loss = 0.978197 (* 1 = 0.978197 loss)
I0522 10:50:37.566521  9292 sgd_solver.cpp:106] Iteration 75500, lr = 0.0025
I0522 10:50:48.128310  9292 solver.cpp:237] Iteration 76000, loss = 0.963168
I0522 10:50:48.128347  9292 solver.cpp:253]     Train net output #0: loss = 0.96317 (* 1 = 0.96317 loss)
I0522 10:50:48.128361  9292 sgd_solver.cpp:106] Iteration 76000, lr = 0.0025
I0522 10:50:58.677412  9292 solver.cpp:237] Iteration 76500, loss = 1.14158
I0522 10:50:58.677579  9292 solver.cpp:253]     Train net output #0: loss = 1.14158 (* 1 = 1.14158 loss)
I0522 10:50:58.677593  9292 sgd_solver.cpp:106] Iteration 76500, lr = 0.0025
I0522 10:51:30.124055  9292 solver.cpp:237] Iteration 77000, loss = 0.888064
I0522 10:51:30.124230  9292 solver.cpp:253]     Train net output #0: loss = 0.888066 (* 1 = 0.888066 loss)
I0522 10:51:30.124245  9292 sgd_solver.cpp:106] Iteration 77000, lr = 0.0025
I0522 10:51:40.686660  9292 solver.cpp:237] Iteration 77500, loss = 1.01764
I0522 10:51:40.686694  9292 solver.cpp:253]     Train net output #0: loss = 1.01764 (* 1 = 1.01764 loss)
I0522 10:51:40.686709  9292 sgd_solver.cpp:106] Iteration 77500, lr = 0.0025
I0522 10:51:51.247712  9292 solver.cpp:237] Iteration 78000, loss = 1.42475
I0522 10:51:51.247759  9292 solver.cpp:253]     Train net output #0: loss = 1.42475 (* 1 = 1.42475 loss)
I0522 10:51:51.247773  9292 sgd_solver.cpp:106] Iteration 78000, lr = 0.0025
I0522 10:52:01.798913  9292 solver.cpp:237] Iteration 78500, loss = 1.12729
I0522 10:52:01.799064  9292 solver.cpp:253]     Train net output #0: loss = 1.12729 (* 1 = 1.12729 loss)
I0522 10:52:01.799078  9292 sgd_solver.cpp:106] Iteration 78500, lr = 0.0025
I0522 10:52:12.351207  9292 solver.cpp:237] Iteration 79000, loss = 0.942483
I0522 10:52:12.351254  9292 solver.cpp:253]     Train net output #0: loss = 0.942485 (* 1 = 0.942485 loss)
I0522 10:52:12.351269  9292 sgd_solver.cpp:106] Iteration 79000, lr = 0.0025
I0522 10:52:22.904937  9292 solver.cpp:237] Iteration 79500, loss = 0.975426
I0522 10:52:22.904974  9292 solver.cpp:253]     Train net output #0: loss = 0.975428 (* 1 = 0.975428 loss)
I0522 10:52:22.904989  9292 sgd_solver.cpp:106] Iteration 79500, lr = 0.0025
I0522 10:52:33.449986  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_80000.caffemodel
I0522 10:52:33.502307  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_80000.solverstate
I0522 10:52:33.528461  9292 solver.cpp:341] Iteration 80000, Testing net (#0)
I0522 10:53:43.869454  9292 solver.cpp:409]     Test net output #0: accuracy = 0.888587
I0522 10:53:43.869626  9292 solver.cpp:409]     Test net output #1: loss = 0.367214 (* 1 = 0.367214 loss)
I0522 10:54:04.693531  9292 solver.cpp:237] Iteration 80000, loss = 0.667762
I0522 10:54:04.693583  9292 solver.cpp:253]     Train net output #0: loss = 0.667764 (* 1 = 0.667764 loss)
I0522 10:54:04.693598  9292 sgd_solver.cpp:106] Iteration 80000, lr = 0.0025
I0522 10:54:15.254297  9292 solver.cpp:237] Iteration 80500, loss = 0.742581
I0522 10:54:15.254468  9292 solver.cpp:253]     Train net output #0: loss = 0.742583 (* 1 = 0.742583 loss)
I0522 10:54:15.254484  9292 sgd_solver.cpp:106] Iteration 80500, lr = 0.0025
I0522 10:54:25.773941  9292 solver.cpp:237] Iteration 81000, loss = 1.56334
I0522 10:54:25.773977  9292 solver.cpp:253]     Train net output #0: loss = 1.56334 (* 1 = 1.56334 loss)
I0522 10:54:25.773991  9292 sgd_solver.cpp:106] Iteration 81000, lr = 0.0025
I0522 10:54:36.283793  9292 solver.cpp:237] Iteration 81500, loss = 1.14037
I0522 10:54:36.283829  9292 solver.cpp:253]     Train net output #0: loss = 1.14037 (* 1 = 1.14037 loss)
I0522 10:54:36.283843  9292 sgd_solver.cpp:106] Iteration 81500, lr = 0.0025
I0522 10:54:46.788954  9292 solver.cpp:237] Iteration 82000, loss = 1.28282
I0522 10:54:46.789110  9292 solver.cpp:253]     Train net output #0: loss = 1.28282 (* 1 = 1.28282 loss)
I0522 10:54:46.789124  9292 sgd_solver.cpp:106] Iteration 82000, lr = 0.0025
I0522 10:54:57.301851  9292 solver.cpp:237] Iteration 82500, loss = 1.18652
I0522 10:54:57.301887  9292 solver.cpp:253]     Train net output #0: loss = 1.18653 (* 1 = 1.18653 loss)
I0522 10:54:57.301901  9292 sgd_solver.cpp:106] Iteration 82500, lr = 0.0025
I0522 10:55:07.825381  9292 solver.cpp:237] Iteration 83000, loss = 1.16505
I0522 10:55:07.825424  9292 solver.cpp:253]     Train net output #0: loss = 1.16505 (* 1 = 1.16505 loss)
I0522 10:55:07.825438  9292 sgd_solver.cpp:106] Iteration 83000, lr = 0.0025
I0522 10:55:39.157065  9292 solver.cpp:237] Iteration 83500, loss = 1.56297
I0522 10:55:39.157239  9292 solver.cpp:253]     Train net output #0: loss = 1.56297 (* 1 = 1.56297 loss)
I0522 10:55:39.157254  9292 sgd_solver.cpp:106] Iteration 83500, lr = 0.0025
I0522 10:55:49.675917  9292 solver.cpp:237] Iteration 84000, loss = 1.29203
I0522 10:55:49.675953  9292 solver.cpp:253]     Train net output #0: loss = 1.29203 (* 1 = 1.29203 loss)
I0522 10:55:49.675968  9292 sgd_solver.cpp:106] Iteration 84000, lr = 0.0025
I0522 10:56:00.189229  9292 solver.cpp:237] Iteration 84500, loss = 1.23144
I0522 10:56:00.189276  9292 solver.cpp:253]     Train net output #0: loss = 1.23144 (* 1 = 1.23144 loss)
I0522 10:56:00.189291  9292 sgd_solver.cpp:106] Iteration 84500, lr = 0.0025
I0522 10:56:10.680457  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_85000.caffemodel
I0522 10:56:10.744555  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_85000.solverstate
I0522 10:56:10.777848  9292 solver.cpp:237] Iteration 85000, loss = 1.18083
I0522 10:56:10.777890  9292 solver.cpp:253]     Train net output #0: loss = 1.18083 (* 1 = 1.18083 loss)
I0522 10:56:10.777910  9292 sgd_solver.cpp:106] Iteration 85000, lr = 0.0025
I0522 10:56:21.297374  9292 solver.cpp:237] Iteration 85500, loss = 1.35035
I0522 10:56:21.297420  9292 solver.cpp:253]     Train net output #0: loss = 1.35035 (* 1 = 1.35035 loss)
I0522 10:56:21.297433  9292 sgd_solver.cpp:106] Iteration 85500, lr = 0.0025
I0522 10:56:31.807436  9292 solver.cpp:237] Iteration 86000, loss = 1.289
I0522 10:56:31.807472  9292 solver.cpp:253]     Train net output #0: loss = 1.28901 (* 1 = 1.28901 loss)
I0522 10:56:31.807487  9292 sgd_solver.cpp:106] Iteration 86000, lr = 0.0025
I0522 10:56:42.320844  9292 solver.cpp:237] Iteration 86500, loss = 1.29579
I0522 10:56:42.321003  9292 solver.cpp:253]     Train net output #0: loss = 1.29579 (* 1 = 1.29579 loss)
I0522 10:56:42.321017  9292 sgd_solver.cpp:106] Iteration 86500, lr = 0.0025
I0522 10:57:13.660915  9292 solver.cpp:237] Iteration 87000, loss = 1.41769
I0522 10:57:13.661092  9292 solver.cpp:253]     Train net output #0: loss = 1.41769 (* 1 = 1.41769 loss)
I0522 10:57:13.661106  9292 sgd_solver.cpp:106] Iteration 87000, lr = 0.0025
I0522 10:57:24.175040  9292 solver.cpp:237] Iteration 87500, loss = 1.21904
I0522 10:57:24.175076  9292 solver.cpp:253]     Train net output #0: loss = 1.21904 (* 1 = 1.21904 loss)
I0522 10:57:24.175098  9292 sgd_solver.cpp:106] Iteration 87500, lr = 0.0025
I0522 10:57:34.687340  9292 solver.cpp:237] Iteration 88000, loss = 0.987048
I0522 10:57:34.687391  9292 solver.cpp:253]     Train net output #0: loss = 0.98705 (* 1 = 0.98705 loss)
I0522 10:57:34.687404  9292 sgd_solver.cpp:106] Iteration 88000, lr = 0.0025
I0522 10:57:45.195335  9292 solver.cpp:237] Iteration 88500, loss = 0.967391
I0522 10:57:45.195500  9292 solver.cpp:253]     Train net output #0: loss = 0.967393 (* 1 = 0.967393 loss)
I0522 10:57:45.195514  9292 sgd_solver.cpp:106] Iteration 88500, lr = 0.0025
I0522 10:57:55.697046  9292 solver.cpp:237] Iteration 89000, loss = 0.966949
I0522 10:57:55.697082  9292 solver.cpp:253]     Train net output #0: loss = 0.966952 (* 1 = 0.966952 loss)
I0522 10:57:55.697096  9292 sgd_solver.cpp:106] Iteration 89000, lr = 0.0025
I0522 10:58:06.203972  9292 solver.cpp:237] Iteration 89500, loss = 0.913891
I0522 10:58:06.204016  9292 solver.cpp:253]     Train net output #0: loss = 0.913893 (* 1 = 0.913893 loss)
I0522 10:58:06.204030  9292 sgd_solver.cpp:106] Iteration 89500, lr = 0.0025
I0522 10:58:16.694135  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_90000.caffemodel
I0522 10:58:16.746564  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_90000.solverstate
I0522 10:58:16.772920  9292 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 10:59:06.303560  9292 solver.cpp:409]     Test net output #0: accuracy = 0.892425
I0522 10:59:06.303732  9292 solver.cpp:409]     Test net output #1: loss = 0.359733 (* 1 = 0.359733 loss)
I0522 10:59:27.180425  9292 solver.cpp:237] Iteration 90000, loss = 1.14235
I0522 10:59:27.180479  9292 solver.cpp:253]     Train net output #0: loss = 1.14235 (* 1 = 1.14235 loss)
I0522 10:59:27.180495  9292 sgd_solver.cpp:106] Iteration 90000, lr = 0.0025
I0522 10:59:37.694902  9292 solver.cpp:237] Iteration 90500, loss = 1.00814
I0522 10:59:37.695063  9292 solver.cpp:253]     Train net output #0: loss = 1.00814 (* 1 = 1.00814 loss)
I0522 10:59:37.695077  9292 sgd_solver.cpp:106] Iteration 90500, lr = 0.0025
I0522 10:59:48.212218  9292 solver.cpp:237] Iteration 91000, loss = 1.3994
I0522 10:59:48.212266  9292 solver.cpp:253]     Train net output #0: loss = 1.3994 (* 1 = 1.3994 loss)
I0522 10:59:48.212280  9292 sgd_solver.cpp:106] Iteration 91000, lr = 0.0025
I0522 10:59:58.731907  9292 solver.cpp:237] Iteration 91500, loss = 1.22132
I0522 10:59:58.731943  9292 solver.cpp:253]     Train net output #0: loss = 1.22133 (* 1 = 1.22133 loss)
I0522 10:59:58.731957  9292 sgd_solver.cpp:106] Iteration 91500, lr = 0.0025
I0522 11:00:09.258262  9292 solver.cpp:237] Iteration 92000, loss = 1.34396
I0522 11:00:09.258445  9292 solver.cpp:253]     Train net output #0: loss = 1.34397 (* 1 = 1.34397 loss)
I0522 11:00:09.258460  9292 sgd_solver.cpp:106] Iteration 92000, lr = 0.0025
I0522 11:00:19.794281  9292 solver.cpp:237] Iteration 92500, loss = 1.04314
I0522 11:00:19.794317  9292 solver.cpp:253]     Train net output #0: loss = 1.04314 (* 1 = 1.04314 loss)
I0522 11:00:19.794330  9292 sgd_solver.cpp:106] Iteration 92500, lr = 0.0025
I0522 11:00:30.336710  9292 solver.cpp:237] Iteration 93000, loss = 0.94183
I0522 11:00:30.336756  9292 solver.cpp:253]     Train net output #0: loss = 0.941832 (* 1 = 0.941832 loss)
I0522 11:00:30.336771  9292 sgd_solver.cpp:106] Iteration 93000, lr = 0.0025
I0522 11:01:01.710736  9292 solver.cpp:237] Iteration 93500, loss = 1.11789
I0522 11:01:01.710916  9292 solver.cpp:253]     Train net output #0: loss = 1.11789 (* 1 = 1.11789 loss)
I0522 11:01:01.710930  9292 sgd_solver.cpp:106] Iteration 93500, lr = 0.0025
I0522 11:01:12.261363  9292 solver.cpp:237] Iteration 94000, loss = 1.08712
I0522 11:01:12.261400  9292 solver.cpp:253]     Train net output #0: loss = 1.08712 (* 1 = 1.08712 loss)
I0522 11:01:12.261415  9292 sgd_solver.cpp:106] Iteration 94000, lr = 0.0025
I0522 11:01:22.800897  9292 solver.cpp:237] Iteration 94500, loss = 1.10983
I0522 11:01:22.800943  9292 solver.cpp:253]     Train net output #0: loss = 1.10983 (* 1 = 1.10983 loss)
I0522 11:01:22.800958  9292 sgd_solver.cpp:106] Iteration 94500, lr = 0.0025
I0522 11:01:33.322336  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_95000.caffemodel
I0522 11:01:33.375888  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_95000.solverstate
I0522 11:01:33.410879  9292 solver.cpp:237] Iteration 95000, loss = 1.24011
I0522 11:01:33.410930  9292 solver.cpp:253]     Train net output #0: loss = 1.24011 (* 1 = 1.24011 loss)
I0522 11:01:33.410944  9292 sgd_solver.cpp:106] Iteration 95000, lr = 0.0025
I0522 11:01:43.956663  9292 solver.cpp:237] Iteration 95500, loss = 1.32967
I0522 11:01:43.956699  9292 solver.cpp:253]     Train net output #0: loss = 1.32967 (* 1 = 1.32967 loss)
I0522 11:01:43.956713  9292 sgd_solver.cpp:106] Iteration 95500, lr = 0.0025
I0522 11:01:54.505827  9292 solver.cpp:237] Iteration 96000, loss = 1.75213
I0522 11:01:54.505866  9292 solver.cpp:253]     Train net output #0: loss = 1.75213 (* 1 = 1.75213 loss)
I0522 11:01:54.505880  9292 sgd_solver.cpp:106] Iteration 96000, lr = 0.0025
I0522 11:02:05.035447  9292 solver.cpp:237] Iteration 96500, loss = 1.04967
I0522 11:02:05.035609  9292 solver.cpp:253]     Train net output #0: loss = 1.04967 (* 1 = 1.04967 loss)
I0522 11:02:05.035622  9292 sgd_solver.cpp:106] Iteration 96500, lr = 0.0025
I0522 11:02:36.413168  9292 solver.cpp:237] Iteration 97000, loss = 1.24332
I0522 11:02:36.413349  9292 solver.cpp:253]     Train net output #0: loss = 1.24333 (* 1 = 1.24333 loss)
I0522 11:02:36.413364  9292 sgd_solver.cpp:106] Iteration 97000, lr = 0.0025
I0522 11:02:46.939730  9292 solver.cpp:237] Iteration 97500, loss = 1.08126
I0522 11:02:46.939765  9292 solver.cpp:253]     Train net output #0: loss = 1.08126 (* 1 = 1.08126 loss)
I0522 11:02:46.939779  9292 sgd_solver.cpp:106] Iteration 97500, lr = 0.0025
I0522 11:02:57.469233  9292 solver.cpp:237] Iteration 98000, loss = 0.654094
I0522 11:02:57.469270  9292 solver.cpp:253]     Train net output #0: loss = 0.654096 (* 1 = 0.654096 loss)
I0522 11:02:57.469285  9292 sgd_solver.cpp:106] Iteration 98000, lr = 0.0025
I0522 11:03:08.020539  9292 solver.cpp:237] Iteration 98500, loss = 1.22364
I0522 11:03:08.020716  9292 solver.cpp:253]     Train net output #0: loss = 1.22364 (* 1 = 1.22364 loss)
I0522 11:03:08.020731  9292 sgd_solver.cpp:106] Iteration 98500, lr = 0.0025
I0522 11:03:18.565220  9292 solver.cpp:237] Iteration 99000, loss = 1.79622
I0522 11:03:18.565255  9292 solver.cpp:253]     Train net output #0: loss = 1.79622 (* 1 = 1.79622 loss)
I0522 11:03:18.565270  9292 sgd_solver.cpp:106] Iteration 99000, lr = 0.0025
I0522 11:03:29.110429  9292 solver.cpp:237] Iteration 99500, loss = 1.59712
I0522 11:03:29.110476  9292 solver.cpp:253]     Train net output #0: loss = 1.59712 (* 1 = 1.59712 loss)
I0522 11:03:29.110491  9292 sgd_solver.cpp:106] Iteration 99500, lr = 0.0025
I0522 11:03:39.627216  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_100000.caffemodel
I0522 11:03:39.682250  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_100000.solverstate
I0522 11:03:39.710286  9292 solver.cpp:341] Iteration 100000, Testing net (#0)
I0522 11:04:50.133684  9292 solver.cpp:409]     Test net output #0: accuracy = 0.890054
I0522 11:04:50.133858  9292 solver.cpp:409]     Test net output #1: loss = 0.375672 (* 1 = 0.375672 loss)
I0522 11:05:11.028106  9292 solver.cpp:237] Iteration 100000, loss = 1.00139
I0522 11:05:11.028158  9292 solver.cpp:253]     Train net output #0: loss = 1.00139 (* 1 = 1.00139 loss)
I0522 11:05:11.028173  9292 sgd_solver.cpp:106] Iteration 100000, lr = 0.0025
I0522 11:05:21.584184  9292 solver.cpp:237] Iteration 100500, loss = 1.12408
I0522 11:05:21.584347  9292 solver.cpp:253]     Train net output #0: loss = 1.12408 (* 1 = 1.12408 loss)
I0522 11:05:21.584359  9292 sgd_solver.cpp:106] Iteration 100500, lr = 0.0025
I0522 11:05:32.169734  9292 solver.cpp:237] Iteration 101000, loss = 1.13148
I0522 11:05:32.169782  9292 solver.cpp:253]     Train net output #0: loss = 1.13148 (* 1 = 1.13148 loss)
I0522 11:05:32.169796  9292 sgd_solver.cpp:106] Iteration 101000, lr = 0.0025
I0522 11:05:42.760108  9292 solver.cpp:237] Iteration 101500, loss = 1.06369
I0522 11:05:42.760145  9292 solver.cpp:253]     Train net output #0: loss = 1.06369 (* 1 = 1.06369 loss)
I0522 11:05:42.760159  9292 sgd_solver.cpp:106] Iteration 101500, lr = 0.0025
I0522 11:05:53.333540  9292 solver.cpp:237] Iteration 102000, loss = 1.30938
I0522 11:05:53.333699  9292 solver.cpp:253]     Train net output #0: loss = 1.30938 (* 1 = 1.30938 loss)
I0522 11:05:53.333712  9292 sgd_solver.cpp:106] Iteration 102000, lr = 0.0025
I0522 11:06:03.916395  9292 solver.cpp:237] Iteration 102500, loss = 1.32193
I0522 11:06:03.916436  9292 solver.cpp:253]     Train net output #0: loss = 1.32193 (* 1 = 1.32193 loss)
I0522 11:06:03.916450  9292 sgd_solver.cpp:106] Iteration 102500, lr = 0.0025
I0522 11:06:14.491055  9292 solver.cpp:237] Iteration 103000, loss = 1.66816
I0522 11:06:14.491096  9292 solver.cpp:253]     Train net output #0: loss = 1.66816 (* 1 = 1.66816 loss)
I0522 11:06:14.491109  9292 sgd_solver.cpp:106] Iteration 103000, lr = 0.0025
I0522 11:06:45.944031  9292 solver.cpp:237] Iteration 103500, loss = 1.31628
I0522 11:06:45.944210  9292 solver.cpp:253]     Train net output #0: loss = 1.31628 (* 1 = 1.31628 loss)
I0522 11:06:45.944223  9292 sgd_solver.cpp:106] Iteration 103500, lr = 0.0025
I0522 11:06:56.511373  9292 solver.cpp:237] Iteration 104000, loss = 0.778207
I0522 11:06:56.511409  9292 solver.cpp:253]     Train net output #0: loss = 0.77821 (* 1 = 0.77821 loss)
I0522 11:06:56.511423  9292 sgd_solver.cpp:106] Iteration 104000, lr = 0.0025
I0522 11:07:07.095584  9292 solver.cpp:237] Iteration 104500, loss = 1.5738
I0522 11:07:07.095620  9292 solver.cpp:253]     Train net output #0: loss = 1.57381 (* 1 = 1.57381 loss)
I0522 11:07:07.095633  9292 sgd_solver.cpp:106] Iteration 104500, lr = 0.0025
I0522 11:07:17.666136  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_105000.caffemodel
I0522 11:07:17.718211  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_105000.solverstate
I0522 11:07:17.749892  9292 solver.cpp:237] Iteration 105000, loss = 1.06493
I0522 11:07:17.749938  9292 solver.cpp:253]     Train net output #0: loss = 1.06494 (* 1 = 1.06494 loss)
I0522 11:07:17.749953  9292 sgd_solver.cpp:106] Iteration 105000, lr = 0.0025
I0522 11:07:28.327625  9292 solver.cpp:237] Iteration 105500, loss = 1.40541
I0522 11:07:28.327661  9292 solver.cpp:253]     Train net output #0: loss = 1.40541 (* 1 = 1.40541 loss)
I0522 11:07:28.327674  9292 sgd_solver.cpp:106] Iteration 105500, lr = 0.0025
I0522 11:07:38.894459  9292 solver.cpp:237] Iteration 106000, loss = 1.34107
I0522 11:07:38.894505  9292 solver.cpp:253]     Train net output #0: loss = 1.34107 (* 1 = 1.34107 loss)
I0522 11:07:38.894518  9292 sgd_solver.cpp:106] Iteration 106000, lr = 0.0025
I0522 11:07:49.474571  9292 solver.cpp:237] Iteration 106500, loss = 1.309
I0522 11:07:49.474735  9292 solver.cpp:253]     Train net output #0: loss = 1.309 (* 1 = 1.309 loss)
I0522 11:07:49.474750  9292 sgd_solver.cpp:106] Iteration 106500, lr = 0.0025
I0522 11:08:20.923601  9292 solver.cpp:237] Iteration 107000, loss = 1.12823
I0522 11:08:20.923780  9292 solver.cpp:253]     Train net output #0: loss = 1.12823 (* 1 = 1.12823 loss)
I0522 11:08:20.923794  9292 sgd_solver.cpp:106] Iteration 107000, lr = 0.0025
I0522 11:08:31.504248  9292 solver.cpp:237] Iteration 107500, loss = 0.92925
I0522 11:08:31.504293  9292 solver.cpp:253]     Train net output #0: loss = 0.929252 (* 1 = 0.929252 loss)
I0522 11:08:31.504307  9292 sgd_solver.cpp:106] Iteration 107500, lr = 0.0025
I0522 11:08:42.087646  9292 solver.cpp:237] Iteration 108000, loss = 0.973935
I0522 11:08:42.087682  9292 solver.cpp:253]     Train net output #0: loss = 0.973937 (* 1 = 0.973937 loss)
I0522 11:08:42.087721  9292 sgd_solver.cpp:106] Iteration 108000, lr = 0.0025
I0522 11:08:52.663607  9292 solver.cpp:237] Iteration 108500, loss = 1.3284
I0522 11:08:52.663776  9292 solver.cpp:253]     Train net output #0: loss = 1.3284 (* 1 = 1.3284 loss)
I0522 11:08:52.663790  9292 sgd_solver.cpp:106] Iteration 108500, lr = 0.0025
I0522 11:09:03.224166  9292 solver.cpp:237] Iteration 109000, loss = 1.16259
I0522 11:09:03.224202  9292 solver.cpp:253]     Train net output #0: loss = 1.16259 (* 1 = 1.16259 loss)
I0522 11:09:03.224215  9292 sgd_solver.cpp:106] Iteration 109000, lr = 0.0025
I0522 11:09:13.821724  9292 solver.cpp:237] Iteration 109500, loss = 1.17564
I0522 11:09:13.821760  9292 solver.cpp:253]     Train net output #0: loss = 1.17564 (* 1 = 1.17564 loss)
I0522 11:09:13.821774  9292 sgd_solver.cpp:106] Iteration 109500, lr = 0.0025
I0522 11:09:24.385179  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_110000.caffemodel
I0522 11:09:24.437340  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_110000.solverstate
I0522 11:09:24.462846  9292 solver.cpp:341] Iteration 110000, Testing net (#0)
I0522 11:10:13.730857  9292 solver.cpp:409]     Test net output #0: accuracy = 0.890994
I0522 11:10:13.731031  9292 solver.cpp:409]     Test net output #1: loss = 0.354071 (* 1 = 0.354071 loss)
I0522 11:10:34.580312  9292 solver.cpp:237] Iteration 110000, loss = 0.974973
I0522 11:10:34.580365  9292 solver.cpp:253]     Train net output #0: loss = 0.974976 (* 1 = 0.974976 loss)
I0522 11:10:34.580381  9292 sgd_solver.cpp:106] Iteration 110000, lr = 0.0025
I0522 11:10:45.165156  9292 solver.cpp:237] Iteration 110500, loss = 1.21868
I0522 11:10:45.165328  9292 solver.cpp:253]     Train net output #0: loss = 1.21868 (* 1 = 1.21868 loss)
I0522 11:10:45.165343  9292 sgd_solver.cpp:106] Iteration 110500, lr = 0.0025
I0522 11:10:55.753111  9292 solver.cpp:237] Iteration 111000, loss = 0.815341
I0522 11:10:55.753159  9292 solver.cpp:253]     Train net output #0: loss = 0.815343 (* 1 = 0.815343 loss)
I0522 11:10:55.753172  9292 sgd_solver.cpp:106] Iteration 111000, lr = 0.0025
I0522 11:11:06.341279  9292 solver.cpp:237] Iteration 111500, loss = 1.05842
I0522 11:11:06.341323  9292 solver.cpp:253]     Train net output #0: loss = 1.05842 (* 1 = 1.05842 loss)
I0522 11:11:06.341338  9292 sgd_solver.cpp:106] Iteration 111500, lr = 0.0025
I0522 11:11:16.920429  9292 solver.cpp:237] Iteration 112000, loss = 0.827215
I0522 11:11:16.920593  9292 solver.cpp:253]     Train net output #0: loss = 0.827218 (* 1 = 0.827218 loss)
I0522 11:11:16.920608  9292 sgd_solver.cpp:106] Iteration 112000, lr = 0.0025
I0522 11:11:27.496805  9292 solver.cpp:237] Iteration 112500, loss = 1.37355
I0522 11:11:27.496851  9292 solver.cpp:253]     Train net output #0: loss = 1.37355 (* 1 = 1.37355 loss)
I0522 11:11:27.496865  9292 sgd_solver.cpp:106] Iteration 112500, lr = 0.0025
I0522 11:11:38.076910  9292 solver.cpp:237] Iteration 113000, loss = 1.24663
I0522 11:11:38.076946  9292 solver.cpp:253]     Train net output #0: loss = 1.24664 (* 1 = 1.24664 loss)
I0522 11:11:38.076959  9292 sgd_solver.cpp:106] Iteration 113000, lr = 0.0025
I0522 11:12:09.585052  9292 solver.cpp:237] Iteration 113500, loss = 1.32222
I0522 11:12:09.585232  9292 solver.cpp:253]     Train net output #0: loss = 1.32222 (* 1 = 1.32222 loss)
I0522 11:12:09.585247  9292 sgd_solver.cpp:106] Iteration 113500, lr = 0.0025
I0522 11:12:20.177659  9292 solver.cpp:237] Iteration 114000, loss = 1.41732
I0522 11:12:20.177695  9292 solver.cpp:253]     Train net output #0: loss = 1.41733 (* 1 = 1.41733 loss)
I0522 11:12:20.177708  9292 sgd_solver.cpp:106] Iteration 114000, lr = 0.0025
I0522 11:12:30.767688  9292 solver.cpp:237] Iteration 114500, loss = 1.24624
I0522 11:12:30.767722  9292 solver.cpp:253]     Train net output #0: loss = 1.24625 (* 1 = 1.24625 loss)
I0522 11:12:30.767736  9292 sgd_solver.cpp:106] Iteration 114500, lr = 0.0025
I0522 11:12:41.336277  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_115000.caffemodel
I0522 11:12:41.390408  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_115000.solverstate
I0522 11:12:41.422472  9292 solver.cpp:237] Iteration 115000, loss = 0.957971
I0522 11:12:41.422518  9292 solver.cpp:253]     Train net output #0: loss = 0.957973 (* 1 = 0.957973 loss)
I0522 11:12:41.422531  9292 sgd_solver.cpp:106] Iteration 115000, lr = 0.0025
I0522 11:12:52.033826  9292 solver.cpp:237] Iteration 115500, loss = 1.02104
I0522 11:12:52.033864  9292 solver.cpp:253]     Train net output #0: loss = 1.02104 (* 1 = 1.02104 loss)
I0522 11:12:52.033877  9292 sgd_solver.cpp:106] Iteration 115500, lr = 0.0025
I0522 11:13:02.645449  9292 solver.cpp:237] Iteration 116000, loss = 1.00783
I0522 11:13:02.645498  9292 solver.cpp:253]     Train net output #0: loss = 1.00783 (* 1 = 1.00783 loss)
I0522 11:13:02.645511  9292 sgd_solver.cpp:106] Iteration 116000, lr = 0.0025
I0522 11:13:13.234935  9292 solver.cpp:237] Iteration 116500, loss = 1.21826
I0522 11:13:13.235103  9292 solver.cpp:253]     Train net output #0: loss = 1.21826 (* 1 = 1.21826 loss)
I0522 11:13:13.235117  9292 sgd_solver.cpp:106] Iteration 116500, lr = 0.0025
I0522 11:13:44.696835  9292 solver.cpp:237] Iteration 117000, loss = 1.09534
I0522 11:13:44.697027  9292 solver.cpp:253]     Train net output #0: loss = 1.09534 (* 1 = 1.09534 loss)
I0522 11:13:44.697042  9292 sgd_solver.cpp:106] Iteration 117000, lr = 0.0025
I0522 11:13:55.300962  9292 solver.cpp:237] Iteration 117500, loss = 1.10218
I0522 11:13:55.301007  9292 solver.cpp:253]     Train net output #0: loss = 1.10218 (* 1 = 1.10218 loss)
I0522 11:13:55.301020  9292 sgd_solver.cpp:106] Iteration 117500, lr = 0.0025
I0522 11:14:05.890300  9292 solver.cpp:237] Iteration 118000, loss = 1.19328
I0522 11:14:05.890336  9292 solver.cpp:253]     Train net output #0: loss = 1.19328 (* 1 = 1.19328 loss)
I0522 11:14:05.890352  9292 sgd_solver.cpp:106] Iteration 118000, lr = 0.0025
I0522 11:14:16.493221  9292 solver.cpp:237] Iteration 118500, loss = 1.35935
I0522 11:14:16.493396  9292 solver.cpp:253]     Train net output #0: loss = 1.35935 (* 1 = 1.35935 loss)
I0522 11:14:16.493412  9292 sgd_solver.cpp:106] Iteration 118500, lr = 0.0025
I0522 11:14:27.086801  9292 solver.cpp:237] Iteration 119000, loss = 0.978927
I0522 11:14:27.086838  9292 solver.cpp:253]     Train net output #0: loss = 0.978929 (* 1 = 0.978929 loss)
I0522 11:14:27.086851  9292 sgd_solver.cpp:106] Iteration 119000, lr = 0.0025
I0522 11:14:37.685595  9292 solver.cpp:237] Iteration 119500, loss = 1.18634
I0522 11:14:37.685631  9292 solver.cpp:253]     Train net output #0: loss = 1.18634 (* 1 = 1.18634 loss)
I0522 11:14:37.685643  9292 sgd_solver.cpp:106] Iteration 119500, lr = 0.0025
I0522 11:14:48.249002  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_120000.caffemodel
I0522 11:14:48.302433  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_120000.solverstate
I0522 11:14:48.328064  9292 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 11:15:58.709065  9292 solver.cpp:409]     Test net output #0: accuracy = 0.893092
I0522 11:15:58.709244  9292 solver.cpp:409]     Test net output #1: loss = 0.339827 (* 1 = 0.339827 loss)
I0522 11:16:19.574839  9292 solver.cpp:237] Iteration 120000, loss = 1.0837
I0522 11:16:19.574894  9292 solver.cpp:253]     Train net output #0: loss = 1.0837 (* 1 = 1.0837 loss)
I0522 11:16:19.574909  9292 sgd_solver.cpp:106] Iteration 120000, lr = 0.0025
I0522 11:16:30.138139  9292 solver.cpp:237] Iteration 120500, loss = 0.932769
I0522 11:16:30.138304  9292 solver.cpp:253]     Train net output #0: loss = 0.932771 (* 1 = 0.932771 loss)
I0522 11:16:30.138320  9292 sgd_solver.cpp:106] Iteration 120500, lr = 0.0025
I0522 11:16:40.715710  9292 solver.cpp:237] Iteration 121000, loss = 1.43215
I0522 11:16:40.715745  9292 solver.cpp:253]     Train net output #0: loss = 1.43215 (* 1 = 1.43215 loss)
I0522 11:16:40.715759  9292 sgd_solver.cpp:106] Iteration 121000, lr = 0.0025
I0522 11:16:51.288640  9292 solver.cpp:237] Iteration 121500, loss = 1.14028
I0522 11:16:51.288686  9292 solver.cpp:253]     Train net output #0: loss = 1.14028 (* 1 = 1.14028 loss)
I0522 11:16:51.288700  9292 sgd_solver.cpp:106] Iteration 121500, lr = 0.0025
I0522 11:17:01.850178  9292 solver.cpp:237] Iteration 122000, loss = 1.36721
I0522 11:17:01.850337  9292 solver.cpp:253]     Train net output #0: loss = 1.36721 (* 1 = 1.36721 loss)
I0522 11:17:01.850353  9292 sgd_solver.cpp:106] Iteration 122000, lr = 0.0025
I0522 11:17:12.404448  9292 solver.cpp:237] Iteration 122500, loss = 1.39714
I0522 11:17:12.404498  9292 solver.cpp:253]     Train net output #0: loss = 1.39714 (* 1 = 1.39714 loss)
I0522 11:17:12.404512  9292 sgd_solver.cpp:106] Iteration 122500, lr = 0.0025
I0522 11:17:22.962535  9292 solver.cpp:237] Iteration 123000, loss = 1.15873
I0522 11:17:22.962570  9292 solver.cpp:253]     Train net output #0: loss = 1.15874 (* 1 = 1.15874 loss)
I0522 11:17:22.962584  9292 sgd_solver.cpp:106] Iteration 123000, lr = 0.0025
I0522 11:17:54.386085  9292 solver.cpp:237] Iteration 123500, loss = 1.13733
I0522 11:17:54.386279  9292 solver.cpp:253]     Train net output #0: loss = 1.13733 (* 1 = 1.13733 loss)
I0522 11:17:54.386296  9292 sgd_solver.cpp:106] Iteration 123500, lr = 0.0025
I0522 11:18:04.948457  9292 solver.cpp:237] Iteration 124000, loss = 1.18204
I0522 11:18:04.948505  9292 solver.cpp:253]     Train net output #0: loss = 1.18204 (* 1 = 1.18204 loss)
I0522 11:18:04.948519  9292 sgd_solver.cpp:106] Iteration 124000, lr = 0.0025
I0522 11:18:15.493799  9292 solver.cpp:237] Iteration 124500, loss = 1.36893
I0522 11:18:15.493835  9292 solver.cpp:253]     Train net output #0: loss = 1.36893 (* 1 = 1.36893 loss)
I0522 11:18:15.493849  9292 sgd_solver.cpp:106] Iteration 124500, lr = 0.0025
I0522 11:18:26.022200  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_125000.caffemodel
I0522 11:18:26.075697  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_125000.solverstate
I0522 11:18:26.109195  9292 solver.cpp:237] Iteration 125000, loss = 1.28864
I0522 11:18:26.109242  9292 solver.cpp:253]     Train net output #0: loss = 1.28864 (* 1 = 1.28864 loss)
I0522 11:18:26.109256  9292 sgd_solver.cpp:106] Iteration 125000, lr = 0.0025
I0522 11:18:36.662717  9292 solver.cpp:237] Iteration 125500, loss = 1.1646
I0522 11:18:36.662755  9292 solver.cpp:253]     Train net output #0: loss = 1.1646 (* 1 = 1.1646 loss)
I0522 11:18:36.662767  9292 sgd_solver.cpp:106] Iteration 125500, lr = 0.0025
I0522 11:18:47.219943  9292 solver.cpp:237] Iteration 126000, loss = 1.28836
I0522 11:18:47.219977  9292 solver.cpp:253]     Train net output #0: loss = 1.28836 (* 1 = 1.28836 loss)
I0522 11:18:47.219992  9292 sgd_solver.cpp:106] Iteration 126000, lr = 0.0025
I0522 11:18:57.766119  9292 solver.cpp:237] Iteration 126500, loss = 1.27104
I0522 11:18:57.766301  9292 solver.cpp:253]     Train net output #0: loss = 1.27105 (* 1 = 1.27105 loss)
I0522 11:18:57.766317  9292 sgd_solver.cpp:106] Iteration 126500, lr = 0.0025
I0522 11:19:29.177572  9292 solver.cpp:237] Iteration 127000, loss = 0.988977
I0522 11:19:29.177754  9292 solver.cpp:253]     Train net output #0: loss = 0.988979 (* 1 = 0.988979 loss)
I0522 11:19:29.177772  9292 sgd_solver.cpp:106] Iteration 127000, lr = 0.0025
I0522 11:19:39.728916  9292 solver.cpp:237] Iteration 127500, loss = 1.28741
I0522 11:19:39.728965  9292 solver.cpp:253]     Train net output #0: loss = 1.28741 (* 1 = 1.28741 loss)
I0522 11:19:39.728982  9292 sgd_solver.cpp:106] Iteration 127500, lr = 0.0025
I0522 11:19:50.270920  9292 solver.cpp:237] Iteration 128000, loss = 1.38884
I0522 11:19:50.270956  9292 solver.cpp:253]     Train net output #0: loss = 1.38885 (* 1 = 1.38885 loss)
I0522 11:19:50.270968  9292 sgd_solver.cpp:106] Iteration 128000, lr = 0.0025
I0522 11:20:00.830013  9292 solver.cpp:237] Iteration 128500, loss = 1.15296
I0522 11:20:00.830173  9292 solver.cpp:253]     Train net output #0: loss = 1.15297 (* 1 = 1.15297 loss)
I0522 11:20:00.830189  9292 sgd_solver.cpp:106] Iteration 128500, lr = 0.0025
I0522 11:20:11.387445  9292 solver.cpp:237] Iteration 129000, loss = 0.865529
I0522 11:20:11.387491  9292 solver.cpp:253]     Train net output #0: loss = 0.86553 (* 1 = 0.86553 loss)
I0522 11:20:11.387506  9292 sgd_solver.cpp:106] Iteration 129000, lr = 0.0025
I0522 11:20:21.948184  9292 solver.cpp:237] Iteration 129500, loss = 0.643592
I0522 11:20:21.948220  9292 solver.cpp:253]     Train net output #0: loss = 0.643594 (* 1 = 0.643594 loss)
I0522 11:20:21.948235  9292 sgd_solver.cpp:106] Iteration 129500, lr = 0.0025
I0522 11:20:32.468596  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_130000.caffemodel
I0522 11:20:32.520997  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_130000.solverstate
I0522 11:20:32.546241  9292 solver.cpp:341] Iteration 130000, Testing net (#0)
I0522 11:21:22.106009  9292 solver.cpp:409]     Test net output #0: accuracy = 0.897626
I0522 11:21:22.106207  9292 solver.cpp:409]     Test net output #1: loss = 0.328306 (* 1 = 0.328306 loss)
I0522 11:21:42.913507  9292 solver.cpp:237] Iteration 130000, loss = 0.947872
I0522 11:21:42.913563  9292 solver.cpp:253]     Train net output #0: loss = 0.947874 (* 1 = 0.947874 loss)
I0522 11:21:42.913578  9292 sgd_solver.cpp:106] Iteration 130000, lr = 0.0025
I0522 11:21:53.421746  9292 solver.cpp:237] Iteration 130500, loss = 1.16909
I0522 11:21:53.421921  9292 solver.cpp:253]     Train net output #0: loss = 1.16909 (* 1 = 1.16909 loss)
I0522 11:21:53.421936  9292 sgd_solver.cpp:106] Iteration 130500, lr = 0.0025
I0522 11:22:03.919461  9292 solver.cpp:237] Iteration 131000, loss = 1.08423
I0522 11:22:03.919497  9292 solver.cpp:253]     Train net output #0: loss = 1.08423 (* 1 = 1.08423 loss)
I0522 11:22:03.919510  9292 sgd_solver.cpp:106] Iteration 131000, lr = 0.0025
I0522 11:22:14.431401  9292 solver.cpp:237] Iteration 131500, loss = 1.0434
I0522 11:22:14.431448  9292 solver.cpp:253]     Train net output #0: loss = 1.0434 (* 1 = 1.0434 loss)
I0522 11:22:14.431463  9292 sgd_solver.cpp:106] Iteration 131500, lr = 0.0025
I0522 11:22:24.939353  9292 solver.cpp:237] Iteration 132000, loss = 0.955522
I0522 11:22:24.939517  9292 solver.cpp:253]     Train net output #0: loss = 0.955524 (* 1 = 0.955524 loss)
I0522 11:22:24.939532  9292 sgd_solver.cpp:106] Iteration 132000, lr = 0.0025
I0522 11:22:35.451215  9292 solver.cpp:237] Iteration 132500, loss = 0.872647
I0522 11:22:35.451261  9292 solver.cpp:253]     Train net output #0: loss = 0.872649 (* 1 = 0.872649 loss)
I0522 11:22:35.451275  9292 sgd_solver.cpp:106] Iteration 132500, lr = 0.0025
I0522 11:22:45.962018  9292 solver.cpp:237] Iteration 133000, loss = 0.835355
I0522 11:22:45.962054  9292 solver.cpp:253]     Train net output #0: loss = 0.835357 (* 1 = 0.835357 loss)
I0522 11:22:45.962069  9292 sgd_solver.cpp:106] Iteration 133000, lr = 0.0025
I0522 11:23:17.306159  9292 solver.cpp:237] Iteration 133500, loss = 1.02707
I0522 11:23:17.306341  9292 solver.cpp:253]     Train net output #0: loss = 1.02707 (* 1 = 1.02707 loss)
I0522 11:23:17.306356  9292 sgd_solver.cpp:106] Iteration 133500, lr = 0.0025
I0522 11:23:27.808471  9292 solver.cpp:237] Iteration 134000, loss = 0.920685
I0522 11:23:27.808522  9292 solver.cpp:253]     Train net output #0: loss = 0.920687 (* 1 = 0.920687 loss)
I0522 11:23:27.808537  9292 sgd_solver.cpp:106] Iteration 134000, lr = 0.0025
I0522 11:23:38.312376  9292 solver.cpp:237] Iteration 134500, loss = 1.00416
I0522 11:23:38.312412  9292 solver.cpp:253]     Train net output #0: loss = 1.00416 (* 1 = 1.00416 loss)
I0522 11:23:38.312425  9292 sgd_solver.cpp:106] Iteration 134500, lr = 0.0025
I0522 11:23:48.791973  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_135000.caffemodel
I0522 11:23:48.843786  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_135000.solverstate
I0522 11:23:48.875224  9292 solver.cpp:237] Iteration 135000, loss = 1.10007
I0522 11:23:48.875264  9292 solver.cpp:253]     Train net output #0: loss = 1.10008 (* 1 = 1.10008 loss)
I0522 11:23:48.875282  9292 sgd_solver.cpp:106] Iteration 135000, lr = 0.0025
I0522 11:23:59.381111  9292 solver.cpp:237] Iteration 135500, loss = 0.926758
I0522 11:23:59.381150  9292 solver.cpp:253]     Train net output #0: loss = 0.92676 (* 1 = 0.92676 loss)
I0522 11:23:59.381163  9292 sgd_solver.cpp:106] Iteration 135500, lr = 0.0025
I0522 11:24:09.889699  9292 solver.cpp:237] Iteration 136000, loss = 1.05792
I0522 11:24:09.889735  9292 solver.cpp:253]     Train net output #0: loss = 1.05792 (* 1 = 1.05792 loss)
I0522 11:24:09.889750  9292 sgd_solver.cpp:106] Iteration 136000, lr = 0.0025
I0522 11:24:20.393878  9292 solver.cpp:237] Iteration 136500, loss = 0.671593
I0522 11:24:20.394067  9292 solver.cpp:253]     Train net output #0: loss = 0.671595 (* 1 = 0.671595 loss)
I0522 11:24:20.394083  9292 sgd_solver.cpp:106] Iteration 136500, lr = 0.0025
I0522 11:24:51.731899  9292 solver.cpp:237] Iteration 137000, loss = 1.4031
I0522 11:24:51.732084  9292 solver.cpp:253]     Train net output #0: loss = 1.4031 (* 1 = 1.4031 loss)
I0522 11:24:51.732101  9292 sgd_solver.cpp:106] Iteration 137000, lr = 0.0025
I0522 11:25:02.254848  9292 solver.cpp:237] Iteration 137500, loss = 1.70402
I0522 11:25:02.254884  9292 solver.cpp:253]     Train net output #0: loss = 1.70402 (* 1 = 1.70402 loss)
I0522 11:25:02.254897  9292 sgd_solver.cpp:106] Iteration 137500, lr = 0.0025
I0522 11:25:12.762430  9292 solver.cpp:237] Iteration 138000, loss = 1.05753
I0522 11:25:12.762473  9292 solver.cpp:253]     Train net output #0: loss = 1.05753 (* 1 = 1.05753 loss)
I0522 11:25:12.762488  9292 sgd_solver.cpp:106] Iteration 138000, lr = 0.0025
I0522 11:25:23.267870  9292 solver.cpp:237] Iteration 138500, loss = 1.27131
I0522 11:25:23.268035  9292 solver.cpp:253]     Train net output #0: loss = 1.27131 (* 1 = 1.27131 loss)
I0522 11:25:23.268051  9292 sgd_solver.cpp:106] Iteration 138500, lr = 0.0025
I0522 11:25:33.770310  9292 solver.cpp:237] Iteration 139000, loss = 1.08429
I0522 11:25:33.770359  9292 solver.cpp:253]     Train net output #0: loss = 1.08429 (* 1 = 1.08429 loss)
I0522 11:25:33.770373  9292 sgd_solver.cpp:106] Iteration 139000, lr = 0.0025
I0522 11:25:44.285909  9292 solver.cpp:237] Iteration 139500, loss = 1.21096
I0522 11:25:44.285944  9292 solver.cpp:253]     Train net output #0: loss = 1.21096 (* 1 = 1.21096 loss)
I0522 11:25:44.285959  9292 sgd_solver.cpp:106] Iteration 139500, lr = 0.0025
I0522 11:25:54.774824  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_140000.caffemodel
I0522 11:25:54.826876  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_140000.solverstate
I0522 11:25:54.852123  9292 solver.cpp:341] Iteration 140000, Testing net (#0)
I0522 11:27:05.378968  9292 solver.cpp:409]     Test net output #0: accuracy = 0.896913
I0522 11:27:05.379160  9292 solver.cpp:409]     Test net output #1: loss = 0.345169 (* 1 = 0.345169 loss)
I0522 11:27:26.248679  9292 solver.cpp:237] Iteration 140000, loss = 1.06704
I0522 11:27:26.248731  9292 solver.cpp:253]     Train net output #0: loss = 1.06704 (* 1 = 1.06704 loss)
I0522 11:27:26.248746  9292 sgd_solver.cpp:106] Iteration 140000, lr = 0.0025
I0522 11:27:36.815901  9292 solver.cpp:237] Iteration 140500, loss = 1.08169
I0522 11:27:36.816092  9292 solver.cpp:253]     Train net output #0: loss = 1.08169 (* 1 = 1.08169 loss)
I0522 11:27:36.816105  9292 sgd_solver.cpp:106] Iteration 140500, lr = 0.0025
I0522 11:27:47.397512  9292 solver.cpp:237] Iteration 141000, loss = 1.17963
I0522 11:27:47.397548  9292 solver.cpp:253]     Train net output #0: loss = 1.17963 (* 1 = 1.17963 loss)
I0522 11:27:47.397562  9292 sgd_solver.cpp:106] Iteration 141000, lr = 0.0025
I0522 11:27:57.996855  9292 solver.cpp:237] Iteration 141500, loss = 1.10652
I0522 11:27:57.996891  9292 solver.cpp:253]     Train net output #0: loss = 1.10652 (* 1 = 1.10652 loss)
I0522 11:27:57.996904  9292 sgd_solver.cpp:106] Iteration 141500, lr = 0.0025
I0522 11:28:08.594750  9292 solver.cpp:237] Iteration 142000, loss = 1.14264
I0522 11:28:08.594924  9292 solver.cpp:253]     Train net output #0: loss = 1.14264 (* 1 = 1.14264 loss)
I0522 11:28:08.594939  9292 sgd_solver.cpp:106] Iteration 142000, lr = 0.0025
I0522 11:28:19.181779  9292 solver.cpp:237] Iteration 142500, loss = 1.14449
I0522 11:28:19.181815  9292 solver.cpp:253]     Train net output #0: loss = 1.14449 (* 1 = 1.14449 loss)
I0522 11:28:19.181828  9292 sgd_solver.cpp:106] Iteration 142500, lr = 0.0025
I0522 11:28:29.772156  9292 solver.cpp:237] Iteration 143000, loss = 0.872343
I0522 11:28:29.772199  9292 solver.cpp:253]     Train net output #0: loss = 0.872345 (* 1 = 0.872345 loss)
I0522 11:28:29.772213  9292 sgd_solver.cpp:106] Iteration 143000, lr = 0.0025
I0522 11:29:01.242138  9292 solver.cpp:237] Iteration 143500, loss = 0.889062
I0522 11:29:01.242336  9292 solver.cpp:253]     Train net output #0: loss = 0.889063 (* 1 = 0.889063 loss)
I0522 11:29:01.242352  9292 sgd_solver.cpp:106] Iteration 143500, lr = 0.0025
I0522 11:29:11.840639  9292 solver.cpp:237] Iteration 144000, loss = 1.1606
I0522 11:29:11.840675  9292 solver.cpp:253]     Train net output #0: loss = 1.16061 (* 1 = 1.16061 loss)
I0522 11:29:11.840689  9292 sgd_solver.cpp:106] Iteration 144000, lr = 0.0025
I0522 11:29:22.430338  9292 solver.cpp:237] Iteration 144500, loss = 1.33756
I0522 11:29:22.430383  9292 solver.cpp:253]     Train net output #0: loss = 1.33756 (* 1 = 1.33756 loss)
I0522 11:29:22.430397  9292 sgd_solver.cpp:106] Iteration 144500, lr = 0.0025
I0522 11:29:32.981163  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_145000.caffemodel
I0522 11:29:33.036572  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_145000.solverstate
I0522 11:29:33.070132  9292 solver.cpp:237] Iteration 145000, loss = 1.59863
I0522 11:29:33.070178  9292 solver.cpp:253]     Train net output #0: loss = 1.59864 (* 1 = 1.59864 loss)
I0522 11:29:33.070194  9292 sgd_solver.cpp:106] Iteration 145000, lr = 0.0025
I0522 11:29:43.669713  9292 solver.cpp:237] Iteration 145500, loss = 1.32948
I0522 11:29:43.669762  9292 solver.cpp:253]     Train net output #0: loss = 1.32948 (* 1 = 1.32948 loss)
I0522 11:29:43.669776  9292 sgd_solver.cpp:106] Iteration 145500, lr = 0.0025
I0522 11:29:54.280767  9292 solver.cpp:237] Iteration 146000, loss = 1.43523
I0522 11:29:54.280803  9292 solver.cpp:253]     Train net output #0: loss = 1.43523 (* 1 = 1.43523 loss)
I0522 11:29:54.280817  9292 sgd_solver.cpp:106] Iteration 146000, lr = 0.0025
I0522 11:30:04.908162  9292 solver.cpp:237] Iteration 146500, loss = 1.0659
I0522 11:30:04.908335  9292 solver.cpp:253]     Train net output #0: loss = 1.0659 (* 1 = 1.0659 loss)
I0522 11:30:04.908349  9292 sgd_solver.cpp:106] Iteration 146500, lr = 0.0025
I0522 11:30:36.389130  9292 solver.cpp:237] Iteration 147000, loss = 0.989985
I0522 11:30:36.389317  9292 solver.cpp:253]     Train net output #0: loss = 0.989986 (* 1 = 0.989986 loss)
I0522 11:30:36.389333  9292 sgd_solver.cpp:106] Iteration 147000, lr = 0.0025
I0522 11:30:47.010845  9292 solver.cpp:237] Iteration 147500, loss = 1.11084
I0522 11:30:47.010881  9292 solver.cpp:253]     Train net output #0: loss = 1.11084 (* 1 = 1.11084 loss)
I0522 11:30:47.010895  9292 sgd_solver.cpp:106] Iteration 147500, lr = 0.0025
I0522 11:30:57.624456  9292 solver.cpp:237] Iteration 148000, loss = 1.14027
I0522 11:30:57.624501  9292 solver.cpp:253]     Train net output #0: loss = 1.14027 (* 1 = 1.14027 loss)
I0522 11:30:57.624516  9292 sgd_solver.cpp:106] Iteration 148000, lr = 0.0025
I0522 11:31:08.243314  9292 solver.cpp:237] Iteration 148500, loss = 1.03875
I0522 11:31:08.243474  9292 solver.cpp:253]     Train net output #0: loss = 1.03875 (* 1 = 1.03875 loss)
I0522 11:31:08.243489  9292 sgd_solver.cpp:106] Iteration 148500, lr = 0.0025
I0522 11:31:18.865914  9292 solver.cpp:237] Iteration 149000, loss = 1.06953
I0522 11:31:18.865949  9292 solver.cpp:253]     Train net output #0: loss = 1.06953 (* 1 = 1.06953 loss)
I0522 11:31:18.865963  9292 sgd_solver.cpp:106] Iteration 149000, lr = 0.0025
I0522 11:31:29.430985  9292 solver.cpp:237] Iteration 149500, loss = 1.53396
I0522 11:31:29.431022  9292 solver.cpp:253]     Train net output #0: loss = 1.53397 (* 1 = 1.53397 loss)
I0522 11:31:29.431036  9292 sgd_solver.cpp:106] Iteration 149500, lr = 0.0025
I0522 11:31:39.959780  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_150000.caffemodel
I0522 11:31:40.015543  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_150000.solverstate
I0522 11:31:40.043118  9292 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 11:32:29.221179  9292 solver.cpp:409]     Test net output #0: accuracy = 0.897879
I0522 11:32:29.221366  9292 solver.cpp:409]     Test net output #1: loss = 0.34661 (* 1 = 0.34661 loss)
I0522 11:32:50.098876  9292 solver.cpp:237] Iteration 150000, loss = 1.3378
I0522 11:32:50.098929  9292 solver.cpp:253]     Train net output #0: loss = 1.33781 (* 1 = 1.33781 loss)
I0522 11:32:50.098944  9292 sgd_solver.cpp:106] Iteration 150000, lr = 0.0025
I0522 11:33:00.587471  9292 solver.cpp:237] Iteration 150500, loss = 1.03342
I0522 11:33:00.587649  9292 solver.cpp:253]     Train net output #0: loss = 1.03342 (* 1 = 1.03342 loss)
I0522 11:33:00.587663  9292 sgd_solver.cpp:106] Iteration 150500, lr = 0.0025
I0522 11:33:11.088661  9292 solver.cpp:237] Iteration 151000, loss = 1.21052
I0522 11:33:11.088697  9292 solver.cpp:253]     Train net output #0: loss = 1.21052 (* 1 = 1.21052 loss)
I0522 11:33:11.088732  9292 sgd_solver.cpp:106] Iteration 151000, lr = 0.0025
I0522 11:33:21.586479  9292 solver.cpp:237] Iteration 151500, loss = 1.11606
I0522 11:33:21.586515  9292 solver.cpp:253]     Train net output #0: loss = 1.11607 (* 1 = 1.11607 loss)
I0522 11:33:21.586529  9292 sgd_solver.cpp:106] Iteration 151500, lr = 0.0025
I0522 11:33:32.091966  9292 solver.cpp:237] Iteration 152000, loss = 1.08088
I0522 11:33:32.092146  9292 solver.cpp:253]     Train net output #0: loss = 1.08088 (* 1 = 1.08088 loss)
I0522 11:33:32.092161  9292 sgd_solver.cpp:106] Iteration 152000, lr = 0.0025
I0522 11:33:42.591536  9292 solver.cpp:237] Iteration 152500, loss = 1.05995
I0522 11:33:42.591572  9292 solver.cpp:253]     Train net output #0: loss = 1.05995 (* 1 = 1.05995 loss)
I0522 11:33:42.591586  9292 sgd_solver.cpp:106] Iteration 152500, lr = 0.0025
I0522 11:33:53.105255  9292 solver.cpp:237] Iteration 153000, loss = 1.3801
I0522 11:33:53.105300  9292 solver.cpp:253]     Train net output #0: loss = 1.3801 (* 1 = 1.3801 loss)
I0522 11:33:53.105314  9292 sgd_solver.cpp:106] Iteration 153000, lr = 0.0025
I0522 11:34:24.467074  9292 solver.cpp:237] Iteration 153500, loss = 1.1041
I0522 11:34:24.467267  9292 solver.cpp:253]     Train net output #0: loss = 1.1041 (* 1 = 1.1041 loss)
I0522 11:34:24.467283  9292 sgd_solver.cpp:106] Iteration 153500, lr = 0.0025
I0522 11:34:35.011389  9292 solver.cpp:237] Iteration 154000, loss = 0.973868
I0522 11:34:35.011425  9292 solver.cpp:253]     Train net output #0: loss = 0.97387 (* 1 = 0.97387 loss)
I0522 11:34:35.011440  9292 sgd_solver.cpp:106] Iteration 154000, lr = 0.0025
I0522 11:34:45.542553  9292 solver.cpp:237] Iteration 154500, loss = 1.35542
I0522 11:34:45.542598  9292 solver.cpp:253]     Train net output #0: loss = 1.35542 (* 1 = 1.35542 loss)
I0522 11:34:45.542613  9292 sgd_solver.cpp:106] Iteration 154500, lr = 0.0025
I0522 11:34:56.055630  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_155000.caffemodel
I0522 11:34:56.108866  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_155000.solverstate
I0522 11:34:56.141510  9292 solver.cpp:237] Iteration 155000, loss = 1.00129
I0522 11:34:56.141551  9292 solver.cpp:253]     Train net output #0: loss = 1.0013 (* 1 = 1.0013 loss)
I0522 11:34:56.141571  9292 sgd_solver.cpp:106] Iteration 155000, lr = 0.0025
I0522 11:35:06.677258  9292 solver.cpp:237] Iteration 155500, loss = 1.47289
I0522 11:35:06.677306  9292 solver.cpp:253]     Train net output #0: loss = 1.47289 (* 1 = 1.47289 loss)
I0522 11:35:06.677321  9292 sgd_solver.cpp:106] Iteration 155500, lr = 0.0025
I0522 11:35:17.209337  9292 solver.cpp:237] Iteration 156000, loss = 1.31393
I0522 11:35:17.209373  9292 solver.cpp:253]     Train net output #0: loss = 1.31393 (* 1 = 1.31393 loss)
I0522 11:35:17.209386  9292 sgd_solver.cpp:106] Iteration 156000, lr = 0.0025
I0522 11:35:27.752991  9292 solver.cpp:237] Iteration 156500, loss = 1.02384
I0522 11:35:27.753171  9292 solver.cpp:253]     Train net output #0: loss = 1.02384 (* 1 = 1.02384 loss)
I0522 11:35:27.753186  9292 sgd_solver.cpp:106] Iteration 156500, lr = 0.0025
I0522 11:35:59.118638  9292 solver.cpp:237] Iteration 157000, loss = 1.01262
I0522 11:35:59.118824  9292 solver.cpp:253]     Train net output #0: loss = 1.01263 (* 1 = 1.01263 loss)
I0522 11:35:59.118839  9292 sgd_solver.cpp:106] Iteration 157000, lr = 0.0025
I0522 11:36:09.645005  9292 solver.cpp:237] Iteration 157500, loss = 1.1416
I0522 11:36:09.645040  9292 solver.cpp:253]     Train net output #0: loss = 1.1416 (* 1 = 1.1416 loss)
I0522 11:36:09.645054  9292 sgd_solver.cpp:106] Iteration 157500, lr = 0.0025
I0522 11:36:20.179146  9292 solver.cpp:237] Iteration 158000, loss = 1.27317
I0522 11:36:20.179193  9292 solver.cpp:253]     Train net output #0: loss = 1.27317 (* 1 = 1.27317 loss)
I0522 11:36:20.179208  9292 sgd_solver.cpp:106] Iteration 158000, lr = 0.0025
I0522 11:36:30.716526  9292 solver.cpp:237] Iteration 158500, loss = 1.37386
I0522 11:36:30.716693  9292 solver.cpp:253]     Train net output #0: loss = 1.37386 (* 1 = 1.37386 loss)
I0522 11:36:30.716707  9292 sgd_solver.cpp:106] Iteration 158500, lr = 0.0025
I0522 11:36:41.247313  9292 solver.cpp:237] Iteration 159000, loss = 1.05994
I0522 11:36:41.247346  9292 solver.cpp:253]     Train net output #0: loss = 1.05994 (* 1 = 1.05994 loss)
I0522 11:36:41.247361  9292 sgd_solver.cpp:106] Iteration 159000, lr = 0.0025
I0522 11:36:51.780835  9292 solver.cpp:237] Iteration 159500, loss = 1.38983
I0522 11:36:51.780877  9292 solver.cpp:253]     Train net output #0: loss = 1.38984 (* 1 = 1.38984 loss)
I0522 11:36:51.780890  9292 sgd_solver.cpp:106] Iteration 159500, lr = 0.0025
I0522 11:37:02.300555  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_160000.caffemodel
I0522 11:37:02.353724  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_160000.solverstate
I0522 11:37:02.378810  9292 solver.cpp:341] Iteration 160000, Testing net (#0)
I0522 11:38:12.849930  9292 solver.cpp:409]     Test net output #0: accuracy = 0.898846
I0522 11:38:12.850116  9292 solver.cpp:409]     Test net output #1: loss = 0.327902 (* 1 = 0.327902 loss)
I0522 11:38:33.673787  9292 solver.cpp:237] Iteration 160000, loss = 1.29169
I0522 11:38:33.673840  9292 solver.cpp:253]     Train net output #0: loss = 1.2917 (* 1 = 1.2917 loss)
I0522 11:38:33.673854  9292 sgd_solver.cpp:106] Iteration 160000, lr = 0.0025
I0522 11:38:44.248474  9292 solver.cpp:237] Iteration 160500, loss = 1.01364
I0522 11:38:44.248648  9292 solver.cpp:253]     Train net output #0: loss = 1.01364 (* 1 = 1.01364 loss)
I0522 11:38:44.248662  9292 sgd_solver.cpp:106] Iteration 160500, lr = 0.0025
I0522 11:38:54.836697  9292 solver.cpp:237] Iteration 161000, loss = 0.796285
I0522 11:38:54.836745  9292 solver.cpp:253]     Train net output #0: loss = 0.796287 (* 1 = 0.796287 loss)
I0522 11:38:54.836760  9292 sgd_solver.cpp:106] Iteration 161000, lr = 0.0025
I0522 11:39:05.416218  9292 solver.cpp:237] Iteration 161500, loss = 1.29469
I0522 11:39:05.416254  9292 solver.cpp:253]     Train net output #0: loss = 1.29469 (* 1 = 1.29469 loss)
I0522 11:39:05.416266  9292 sgd_solver.cpp:106] Iteration 161500, lr = 0.0025
I0522 11:39:16.004464  9292 solver.cpp:237] Iteration 162000, loss = 1.322
I0522 11:39:16.004657  9292 solver.cpp:253]     Train net output #0: loss = 1.322 (* 1 = 1.322 loss)
I0522 11:39:16.004672  9292 sgd_solver.cpp:106] Iteration 162000, lr = 0.0025
I0522 11:39:26.584686  9292 solver.cpp:237] Iteration 162500, loss = 1.02174
I0522 11:39:26.584722  9292 solver.cpp:253]     Train net output #0: loss = 1.02175 (* 1 = 1.02175 loss)
I0522 11:39:26.584735  9292 sgd_solver.cpp:106] Iteration 162500, lr = 0.0025
I0522 11:39:37.159406  9292 solver.cpp:237] Iteration 163000, loss = 1.03469
I0522 11:39:37.159442  9292 solver.cpp:253]     Train net output #0: loss = 1.0347 (* 1 = 1.0347 loss)
I0522 11:39:37.159456  9292 sgd_solver.cpp:106] Iteration 163000, lr = 0.0025
I0522 11:40:08.583489  9292 solver.cpp:237] Iteration 163500, loss = 1.02132
I0522 11:40:08.583678  9292 solver.cpp:253]     Train net output #0: loss = 1.02132 (* 1 = 1.02132 loss)
I0522 11:40:08.583693  9292 sgd_solver.cpp:106] Iteration 163500, lr = 0.0025
I0522 11:40:19.164562  9292 solver.cpp:237] Iteration 164000, loss = 0.851406
I0522 11:40:19.164599  9292 solver.cpp:253]     Train net output #0: loss = 0.851408 (* 1 = 0.851408 loss)
I0522 11:40:19.164613  9292 sgd_solver.cpp:106] Iteration 164000, lr = 0.0025
I0522 11:40:29.735222  9292 solver.cpp:237] Iteration 164500, loss = 1.1816
I0522 11:40:29.735266  9292 solver.cpp:253]     Train net output #0: loss = 1.18161 (* 1 = 1.18161 loss)
I0522 11:40:29.735280  9292 sgd_solver.cpp:106] Iteration 164500, lr = 0.0025
I0522 11:40:40.280711  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_165000.caffemodel
I0522 11:40:40.334617  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_165000.solverstate
I0522 11:40:40.366708  9292 solver.cpp:237] Iteration 165000, loss = 0.962139
I0522 11:40:40.366755  9292 solver.cpp:253]     Train net output #0: loss = 0.962141 (* 1 = 0.962141 loss)
I0522 11:40:40.366770  9292 sgd_solver.cpp:106] Iteration 165000, lr = 0.0025
I0522 11:40:50.927122  9292 solver.cpp:237] Iteration 165500, loss = 1.20016
I0522 11:40:50.927158  9292 solver.cpp:253]     Train net output #0: loss = 1.20016 (* 1 = 1.20016 loss)
I0522 11:40:50.927172  9292 sgd_solver.cpp:106] Iteration 165500, lr = 0.0025
I0522 11:41:01.484244  9292 solver.cpp:237] Iteration 166000, loss = 1.0426
I0522 11:41:01.484289  9292 solver.cpp:253]     Train net output #0: loss = 1.0426 (* 1 = 1.0426 loss)
I0522 11:41:01.484303  9292 sgd_solver.cpp:106] Iteration 166000, lr = 0.0025
I0522 11:41:12.048530  9292 solver.cpp:237] Iteration 166500, loss = 1.3848
I0522 11:41:12.048702  9292 solver.cpp:253]     Train net output #0: loss = 1.3848 (* 1 = 1.3848 loss)
I0522 11:41:12.048715  9292 sgd_solver.cpp:106] Iteration 166500, lr = 0.0025
I0522 11:41:43.471649  9292 solver.cpp:237] Iteration 167000, loss = 0.831688
I0522 11:41:43.471839  9292 solver.cpp:253]     Train net output #0: loss = 0.83169 (* 1 = 0.83169 loss)
I0522 11:41:43.471855  9292 sgd_solver.cpp:106] Iteration 167000, lr = 0.0025
I0522 11:41:54.046730  9292 solver.cpp:237] Iteration 167500, loss = 1.2609
I0522 11:41:54.046778  9292 solver.cpp:253]     Train net output #0: loss = 1.2609 (* 1 = 1.2609 loss)
I0522 11:41:54.046792  9292 sgd_solver.cpp:106] Iteration 167500, lr = 0.0025
I0522 11:42:04.611660  9292 solver.cpp:237] Iteration 168000, loss = 1.10806
I0522 11:42:04.611696  9292 solver.cpp:253]     Train net output #0: loss = 1.10806 (* 1 = 1.10806 loss)
I0522 11:42:04.611709  9292 sgd_solver.cpp:106] Iteration 168000, lr = 0.0025
I0522 11:42:15.180318  9292 solver.cpp:237] Iteration 168500, loss = 0.94462
I0522 11:42:15.180500  9292 solver.cpp:253]     Train net output #0: loss = 0.944622 (* 1 = 0.944622 loss)
I0522 11:42:15.180513  9292 sgd_solver.cpp:106] Iteration 168500, lr = 0.0025
I0522 11:42:25.743536  9292 solver.cpp:237] Iteration 169000, loss = 0.936393
I0522 11:42:25.743572  9292 solver.cpp:253]     Train net output #0: loss = 0.936395 (* 1 = 0.936395 loss)
I0522 11:42:25.743587  9292 sgd_solver.cpp:106] Iteration 169000, lr = 0.0025
I0522 11:42:36.317096  9292 solver.cpp:237] Iteration 169500, loss = 1.18902
I0522 11:42:36.317140  9292 solver.cpp:253]     Train net output #0: loss = 1.18902 (* 1 = 1.18902 loss)
I0522 11:42:36.317153  9292 sgd_solver.cpp:106] Iteration 169500, lr = 0.0025
I0522 11:42:46.867297  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_170000.caffemodel
I0522 11:42:46.921039  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_170000.solverstate
I0522 11:42:46.946413  9292 solver.cpp:341] Iteration 170000, Testing net (#0)
I0522 11:43:36.544891  9292 solver.cpp:409]     Test net output #0: accuracy = 0.898504
I0522 11:43:36.545089  9292 solver.cpp:409]     Test net output #1: loss = 0.340496 (* 1 = 0.340496 loss)
I0522 11:43:57.428073  9292 solver.cpp:237] Iteration 170000, loss = 1.12426
I0522 11:43:57.428127  9292 solver.cpp:253]     Train net output #0: loss = 1.12426 (* 1 = 1.12426 loss)
I0522 11:43:57.428141  9292 sgd_solver.cpp:106] Iteration 170000, lr = 0.0025
I0522 11:44:07.975540  9292 solver.cpp:237] Iteration 170500, loss = 0.88982
I0522 11:44:07.975718  9292 solver.cpp:253]     Train net output #0: loss = 0.889822 (* 1 = 0.889822 loss)
I0522 11:44:07.975733  9292 sgd_solver.cpp:106] Iteration 170500, lr = 0.0025
I0522 11:44:18.537274  9292 solver.cpp:237] Iteration 171000, loss = 1.57098
I0522 11:44:18.537323  9292 solver.cpp:253]     Train net output #0: loss = 1.57099 (* 1 = 1.57099 loss)
I0522 11:44:18.537338  9292 sgd_solver.cpp:106] Iteration 171000, lr = 0.0025
I0522 11:44:29.086580  9292 solver.cpp:237] Iteration 171500, loss = 1.13478
I0522 11:44:29.086616  9292 solver.cpp:253]     Train net output #0: loss = 1.13478 (* 1 = 1.13478 loss)
I0522 11:44:29.086629  9292 sgd_solver.cpp:106] Iteration 171500, lr = 0.0025
I0522 11:44:39.644496  9292 solver.cpp:237] Iteration 172000, loss = 1.34246
I0522 11:44:39.644676  9292 solver.cpp:253]     Train net output #0: loss = 1.34247 (* 1 = 1.34247 loss)
I0522 11:44:39.644693  9292 sgd_solver.cpp:106] Iteration 172000, lr = 0.0025
I0522 11:44:50.214347  9292 solver.cpp:237] Iteration 172500, loss = 1.11433
I0522 11:44:50.214383  9292 solver.cpp:253]     Train net output #0: loss = 1.11433 (* 1 = 1.11433 loss)
I0522 11:44:50.214398  9292 sgd_solver.cpp:106] Iteration 172500, lr = 0.0025
I0522 11:45:00.762871  9292 solver.cpp:237] Iteration 173000, loss = 0.584037
I0522 11:45:00.762907  9292 solver.cpp:253]     Train net output #0: loss = 0.584039 (* 1 = 0.584039 loss)
I0522 11:45:00.762922  9292 sgd_solver.cpp:106] Iteration 173000, lr = 0.0025
I0522 11:45:32.195607  9292 solver.cpp:237] Iteration 173500, loss = 1.14698
I0522 11:45:32.195796  9292 solver.cpp:253]     Train net output #0: loss = 1.14698 (* 1 = 1.14698 loss)
I0522 11:45:32.195811  9292 sgd_solver.cpp:106] Iteration 173500, lr = 0.0025
I0522 11:45:42.740161  9292 solver.cpp:237] Iteration 174000, loss = 1.11163
I0522 11:45:42.740196  9292 solver.cpp:253]     Train net output #0: loss = 1.11163 (* 1 = 1.11163 loss)
I0522 11:45:42.740211  9292 sgd_solver.cpp:106] Iteration 174000, lr = 0.0025
I0522 11:45:53.283854  9292 solver.cpp:237] Iteration 174500, loss = 0.832992
I0522 11:45:53.283891  9292 solver.cpp:253]     Train net output #0: loss = 0.832994 (* 1 = 0.832994 loss)
I0522 11:45:53.283905  9292 sgd_solver.cpp:106] Iteration 174500, lr = 0.0025
I0522 11:46:03.809849  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_175000.caffemodel
I0522 11:46:03.866164  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_175000.solverstate
I0522 11:46:03.900436  9292 solver.cpp:237] Iteration 175000, loss = 1.47995
I0522 11:46:03.900488  9292 solver.cpp:253]     Train net output #0: loss = 1.47995 (* 1 = 1.47995 loss)
I0522 11:46:03.900502  9292 sgd_solver.cpp:106] Iteration 175000, lr = 0.0025
I0522 11:46:14.460343  9292 solver.cpp:237] Iteration 175500, loss = 1.41974
I0522 11:46:14.460379  9292 solver.cpp:253]     Train net output #0: loss = 1.41974 (* 1 = 1.41974 loss)
I0522 11:46:14.460393  9292 sgd_solver.cpp:106] Iteration 175500, lr = 0.0025
I0522 11:46:25.036003  9292 solver.cpp:237] Iteration 176000, loss = 1.03179
I0522 11:46:25.036047  9292 solver.cpp:253]     Train net output #0: loss = 1.0318 (* 1 = 1.0318 loss)
I0522 11:46:25.036062  9292 sgd_solver.cpp:106] Iteration 176000, lr = 0.0025
I0522 11:46:35.614598  9292 solver.cpp:237] Iteration 176500, loss = 1.34077
I0522 11:46:35.614773  9292 solver.cpp:253]     Train net output #0: loss = 1.34077 (* 1 = 1.34077 loss)
I0522 11:46:35.614787  9292 sgd_solver.cpp:106] Iteration 176500, lr = 0.0025
I0522 11:47:07.081703  9292 solver.cpp:237] Iteration 177000, loss = 1.04511
I0522 11:47:07.081895  9292 solver.cpp:253]     Train net output #0: loss = 1.04511 (* 1 = 1.04511 loss)
I0522 11:47:07.081912  9292 sgd_solver.cpp:106] Iteration 177000, lr = 0.0025
I0522 11:47:17.666540  9292 solver.cpp:237] Iteration 177500, loss = 0.895993
I0522 11:47:17.666591  9292 solver.cpp:253]     Train net output #0: loss = 0.895995 (* 1 = 0.895995 loss)
I0522 11:47:17.666605  9292 sgd_solver.cpp:106] Iteration 177500, lr = 0.0025
I0522 11:47:28.248821  9292 solver.cpp:237] Iteration 178000, loss = 1.12287
I0522 11:47:28.248857  9292 solver.cpp:253]     Train net output #0: loss = 1.12288 (* 1 = 1.12288 loss)
I0522 11:47:28.248870  9292 sgd_solver.cpp:106] Iteration 178000, lr = 0.0025
I0522 11:47:38.833003  9292 solver.cpp:237] Iteration 178500, loss = 1.26522
I0522 11:47:38.833189  9292 solver.cpp:253]     Train net output #0: loss = 1.26523 (* 1 = 1.26523 loss)
I0522 11:47:38.833204  9292 sgd_solver.cpp:106] Iteration 178500, lr = 0.0025
I0522 11:47:49.407006  9292 solver.cpp:237] Iteration 179000, loss = 1.20116
I0522 11:47:49.407042  9292 solver.cpp:253]     Train net output #0: loss = 1.20116 (* 1 = 1.20116 loss)
I0522 11:47:49.407055  9292 sgd_solver.cpp:106] Iteration 179000, lr = 0.0025
I0522 11:47:59.991258  9292 solver.cpp:237] Iteration 179500, loss = 1.07779
I0522 11:47:59.991307  9292 solver.cpp:253]     Train net output #0: loss = 1.0778 (* 1 = 1.0778 loss)
I0522 11:47:59.991322  9292 sgd_solver.cpp:106] Iteration 179500, lr = 0.0025
I0522 11:48:10.564546  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_180000.caffemodel
I0522 11:48:10.619797  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_180000.solverstate
I0522 11:48:10.650800  9292 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 11:49:21.126121  9292 solver.cpp:409]     Test net output #0: accuracy = 0.900218
I0522 11:49:21.126309  9292 solver.cpp:409]     Test net output #1: loss = 0.320501 (* 1 = 0.320501 loss)
I0522 11:49:42.028519  9292 solver.cpp:237] Iteration 180000, loss = 0.975698
I0522 11:49:42.028573  9292 solver.cpp:253]     Train net output #0: loss = 0.9757 (* 1 = 0.9757 loss)
I0522 11:49:42.028589  9292 sgd_solver.cpp:106] Iteration 180000, lr = 0.0025
I0522 11:49:52.542711  9292 solver.cpp:237] Iteration 180500, loss = 1.05512
I0522 11:49:52.542886  9292 solver.cpp:253]     Train net output #0: loss = 1.05512 (* 1 = 1.05512 loss)
I0522 11:49:52.542898  9292 sgd_solver.cpp:106] Iteration 180500, lr = 0.0025
I0522 11:50:03.063374  9292 solver.cpp:237] Iteration 181000, loss = 1.15382
I0522 11:50:03.063410  9292 solver.cpp:253]     Train net output #0: loss = 1.15382 (* 1 = 1.15382 loss)
I0522 11:50:03.063424  9292 sgd_solver.cpp:106] Iteration 181000, lr = 0.0025
I0522 11:50:13.591497  9292 solver.cpp:237] Iteration 181500, loss = 0.924335
I0522 11:50:13.591542  9292 solver.cpp:253]     Train net output #0: loss = 0.924337 (* 1 = 0.924337 loss)
I0522 11:50:13.591557  9292 sgd_solver.cpp:106] Iteration 181500, lr = 0.0025
I0522 11:50:24.099763  9292 solver.cpp:237] Iteration 182000, loss = 1.02029
I0522 11:50:24.099941  9292 solver.cpp:253]     Train net output #0: loss = 1.0203 (* 1 = 1.0203 loss)
I0522 11:50:24.099954  9292 sgd_solver.cpp:106] Iteration 182000, lr = 0.0025
I0522 11:50:34.625000  9292 solver.cpp:237] Iteration 182500, loss = 1.11319
I0522 11:50:34.625047  9292 solver.cpp:253]     Train net output #0: loss = 1.11319 (* 1 = 1.11319 loss)
I0522 11:50:34.625061  9292 sgd_solver.cpp:106] Iteration 182500, lr = 0.0025
I0522 11:50:45.157902  9292 solver.cpp:237] Iteration 183000, loss = 0.752653
I0522 11:50:45.157939  9292 solver.cpp:253]     Train net output #0: loss = 0.752654 (* 1 = 0.752654 loss)
I0522 11:50:45.157953  9292 sgd_solver.cpp:106] Iteration 183000, lr = 0.0025
I0522 11:51:16.552603  9292 solver.cpp:237] Iteration 183500, loss = 1.22204
I0522 11:51:16.552798  9292 solver.cpp:253]     Train net output #0: loss = 1.22204 (* 1 = 1.22204 loss)
I0522 11:51:16.552811  9292 sgd_solver.cpp:106] Iteration 183500, lr = 0.0025
I0522 11:51:27.063676  9292 solver.cpp:237] Iteration 184000, loss = 0.995052
I0522 11:51:27.063726  9292 solver.cpp:253]     Train net output #0: loss = 0.995053 (* 1 = 0.995053 loss)
I0522 11:51:27.063740  9292 sgd_solver.cpp:106] Iteration 184000, lr = 0.0025
I0522 11:51:37.593296  9292 solver.cpp:237] Iteration 184500, loss = 1.31196
I0522 11:51:37.593332  9292 solver.cpp:253]     Train net output #0: loss = 1.31196 (* 1 = 1.31196 loss)
I0522 11:51:37.593345  9292 sgd_solver.cpp:106] Iteration 184500, lr = 0.0025
I0522 11:51:48.101986  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_185000.caffemodel
I0522 11:51:48.154413  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_185000.solverstate
I0522 11:51:48.187008  9292 solver.cpp:237] Iteration 185000, loss = 1.16474
I0522 11:51:48.187052  9292 solver.cpp:253]     Train net output #0: loss = 1.16475 (* 1 = 1.16475 loss)
I0522 11:51:48.187068  9292 sgd_solver.cpp:106] Iteration 185000, lr = 0.0025
I0522 11:51:58.702729  9292 solver.cpp:237] Iteration 185500, loss = 1.1003
I0522 11:51:58.702765  9292 solver.cpp:253]     Train net output #0: loss = 1.1003 (* 1 = 1.1003 loss)
I0522 11:51:58.702780  9292 sgd_solver.cpp:106] Iteration 185500, lr = 0.0025
I0522 11:52:09.230370  9292 solver.cpp:237] Iteration 186000, loss = 1.15892
I0522 11:52:09.230420  9292 solver.cpp:253]     Train net output #0: loss = 1.15893 (* 1 = 1.15893 loss)
I0522 11:52:09.230434  9292 sgd_solver.cpp:106] Iteration 186000, lr = 0.0025
I0522 11:52:19.792220  9292 solver.cpp:237] Iteration 186500, loss = 1.07605
I0522 11:52:19.792397  9292 solver.cpp:253]     Train net output #0: loss = 1.07605 (* 1 = 1.07605 loss)
I0522 11:52:19.792412  9292 sgd_solver.cpp:106] Iteration 186500, lr = 0.0025
I0522 11:52:51.228970  9292 solver.cpp:237] Iteration 187000, loss = 1.16317
I0522 11:52:51.229161  9292 solver.cpp:253]     Train net output #0: loss = 1.16317 (* 1 = 1.16317 loss)
I0522 11:52:51.229176  9292 sgd_solver.cpp:106] Iteration 187000, lr = 0.0025
I0522 11:53:01.799329  9292 solver.cpp:237] Iteration 187500, loss = 1.26383
I0522 11:53:01.799376  9292 solver.cpp:253]     Train net output #0: loss = 1.26383 (* 1 = 1.26383 loss)
I0522 11:53:01.799391  9292 sgd_solver.cpp:106] Iteration 187500, lr = 0.0025
I0522 11:53:12.358572  9292 solver.cpp:237] Iteration 188000, loss = 1.15861
I0522 11:53:12.358608  9292 solver.cpp:253]     Train net output #0: loss = 1.15861 (* 1 = 1.15861 loss)
I0522 11:53:12.358621  9292 sgd_solver.cpp:106] Iteration 188000, lr = 0.0025
I0522 11:53:22.927700  9292 solver.cpp:237] Iteration 188500, loss = 1.12878
I0522 11:53:22.927881  9292 solver.cpp:253]     Train net output #0: loss = 1.12878 (* 1 = 1.12878 loss)
I0522 11:53:22.927897  9292 sgd_solver.cpp:106] Iteration 188500, lr = 0.0025
I0522 11:53:33.495017  9292 solver.cpp:237] Iteration 189000, loss = 1.14276
I0522 11:53:33.495065  9292 solver.cpp:253]     Train net output #0: loss = 1.14276 (* 1 = 1.14276 loss)
I0522 11:53:33.495079  9292 sgd_solver.cpp:106] Iteration 189000, lr = 0.0025
I0522 11:53:44.047817  9292 solver.cpp:237] Iteration 189500, loss = 1.07231
I0522 11:53:44.047853  9292 solver.cpp:253]     Train net output #0: loss = 1.07231 (* 1 = 1.07231 loss)
I0522 11:53:44.047868  9292 sgd_solver.cpp:106] Iteration 189500, lr = 0.0025
I0522 11:53:54.568691  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_190000.caffemodel
I0522 11:53:54.621475  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_190000.solverstate
I0522 11:53:54.646811  9292 solver.cpp:341] Iteration 190000, Testing net (#0)
I0522 11:54:43.924571  9292 solver.cpp:409]     Test net output #0: accuracy = 0.898598
I0522 11:54:43.924762  9292 solver.cpp:409]     Test net output #1: loss = 0.323082 (* 1 = 0.323082 loss)
I0522 11:55:04.798313  9292 solver.cpp:237] Iteration 190000, loss = 1.14681
I0522 11:55:04.798367  9292 solver.cpp:253]     Train net output #0: loss = 1.14681 (* 1 = 1.14681 loss)
I0522 11:55:04.798382  9292 sgd_solver.cpp:106] Iteration 190000, lr = 0.0025
I0522 11:55:15.320708  9292 solver.cpp:237] Iteration 190500, loss = 1.05264
I0522 11:55:15.320886  9292 solver.cpp:253]     Train net output #0: loss = 1.05264 (* 1 = 1.05264 loss)
I0522 11:55:15.320899  9292 sgd_solver.cpp:106] Iteration 190500, lr = 0.0025
I0522 11:55:25.836887  9292 solver.cpp:237] Iteration 191000, loss = 1.10192
I0522 11:55:25.836922  9292 solver.cpp:253]     Train net output #0: loss = 1.10192 (* 1 = 1.10192 loss)
I0522 11:55:25.836936  9292 sgd_solver.cpp:106] Iteration 191000, lr = 0.0025
I0522 11:55:36.372239  9292 solver.cpp:237] Iteration 191500, loss = 1.02813
I0522 11:55:36.372287  9292 solver.cpp:253]     Train net output #0: loss = 1.02813 (* 1 = 1.02813 loss)
I0522 11:55:36.372301  9292 sgd_solver.cpp:106] Iteration 191500, lr = 0.0025
I0522 11:55:46.892153  9292 solver.cpp:237] Iteration 192000, loss = 1.38837
I0522 11:55:46.892330  9292 solver.cpp:253]     Train net output #0: loss = 1.38837 (* 1 = 1.38837 loss)
I0522 11:55:46.892343  9292 sgd_solver.cpp:106] Iteration 192000, lr = 0.0025
I0522 11:55:57.420845  9292 solver.cpp:237] Iteration 192500, loss = 1.13842
I0522 11:55:57.420889  9292 solver.cpp:253]     Train net output #0: loss = 1.13842 (* 1 = 1.13842 loss)
I0522 11:55:57.420903  9292 sgd_solver.cpp:106] Iteration 192500, lr = 0.0025
I0522 11:56:07.930687  9292 solver.cpp:237] Iteration 193000, loss = 1.10491
I0522 11:56:07.930722  9292 solver.cpp:253]     Train net output #0: loss = 1.10491 (* 1 = 1.10491 loss)
I0522 11:56:07.930737  9292 sgd_solver.cpp:106] Iteration 193000, lr = 0.0025
I0522 11:56:39.320224  9292 solver.cpp:237] Iteration 193500, loss = 1.01368
I0522 11:56:39.320420  9292 solver.cpp:253]     Train net output #0: loss = 1.01368 (* 1 = 1.01368 loss)
I0522 11:56:39.320435  9292 sgd_solver.cpp:106] Iteration 193500, lr = 0.0025
I0522 11:56:49.854224  9292 solver.cpp:237] Iteration 194000, loss = 1.29372
I0522 11:56:49.854269  9292 solver.cpp:253]     Train net output #0: loss = 1.29372 (* 1 = 1.29372 loss)
I0522 11:56:49.854282  9292 sgd_solver.cpp:106] Iteration 194000, lr = 0.0025
I0522 11:57:00.363301  9292 solver.cpp:237] Iteration 194500, loss = 1.38553
I0522 11:57:00.363337  9292 solver.cpp:253]     Train net output #0: loss = 1.38553 (* 1 = 1.38553 loss)
I0522 11:57:00.363351  9292 sgd_solver.cpp:106] Iteration 194500, lr = 0.0025
I0522 11:57:10.846518  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_195000.caffemodel
I0522 11:57:10.899147  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_195000.solverstate
I0522 11:57:10.930820  9292 solver.cpp:237] Iteration 195000, loss = 1.40627
I0522 11:57:10.930861  9292 solver.cpp:253]     Train net output #0: loss = 1.40627 (* 1 = 1.40627 loss)
I0522 11:57:10.930882  9292 sgd_solver.cpp:106] Iteration 195000, lr = 0.0025
I0522 11:57:21.459599  9292 solver.cpp:237] Iteration 195500, loss = 1.21176
I0522 11:57:21.459635  9292 solver.cpp:253]     Train net output #0: loss = 1.21177 (* 1 = 1.21177 loss)
I0522 11:57:21.459648  9292 sgd_solver.cpp:106] Iteration 195500, lr = 0.0025
I0522 11:57:31.982923  9292 solver.cpp:237] Iteration 196000, loss = 1.0069
I0522 11:57:31.982959  9292 solver.cpp:253]     Train net output #0: loss = 1.0069 (* 1 = 1.0069 loss)
I0522 11:57:31.982972  9292 sgd_solver.cpp:106] Iteration 196000, lr = 0.0025
I0522 11:57:42.511492  9292 solver.cpp:237] Iteration 196500, loss = 0.962061
I0522 11:57:42.511682  9292 solver.cpp:253]     Train net output #0: loss = 0.962063 (* 1 = 0.962063 loss)
I0522 11:57:42.511698  9292 sgd_solver.cpp:106] Iteration 196500, lr = 0.0025
I0522 11:58:13.928323  9292 solver.cpp:237] Iteration 197000, loss = 1.26551
I0522 11:58:13.928516  9292 solver.cpp:253]     Train net output #0: loss = 1.26551 (* 1 = 1.26551 loss)
I0522 11:58:13.928532  9292 sgd_solver.cpp:106] Iteration 197000, lr = 0.0025
I0522 11:58:24.455493  9292 solver.cpp:237] Iteration 197500, loss = 1.25887
I0522 11:58:24.455535  9292 solver.cpp:253]     Train net output #0: loss = 1.25887 (* 1 = 1.25887 loss)
I0522 11:58:24.455549  9292 sgd_solver.cpp:106] Iteration 197500, lr = 0.0025
I0522 11:58:34.982648  9292 solver.cpp:237] Iteration 198000, loss = 1.24585
I0522 11:58:34.982684  9292 solver.cpp:253]     Train net output #0: loss = 1.24586 (* 1 = 1.24586 loss)
I0522 11:58:34.982699  9292 sgd_solver.cpp:106] Iteration 198000, lr = 0.0025
I0522 11:58:45.502244  9292 solver.cpp:237] Iteration 198500, loss = 1.29757
I0522 11:58:45.502419  9292 solver.cpp:253]     Train net output #0: loss = 1.29757 (* 1 = 1.29757 loss)
I0522 11:58:45.502435  9292 sgd_solver.cpp:106] Iteration 198500, lr = 0.0025
I0522 11:58:56.029331  9292 solver.cpp:237] Iteration 199000, loss = 1.13623
I0522 11:58:56.029373  9292 solver.cpp:253]     Train net output #0: loss = 1.13624 (* 1 = 1.13624 loss)
I0522 11:58:56.029386  9292 sgd_solver.cpp:106] Iteration 199000, lr = 0.0025
I0522 11:59:06.558398  9292 solver.cpp:237] Iteration 199500, loss = 1.59574
I0522 11:59:06.558432  9292 solver.cpp:253]     Train net output #0: loss = 1.59574 (* 1 = 1.59574 loss)
I0522 11:59:06.558447  9292 sgd_solver.cpp:106] Iteration 199500, lr = 0.0025
I0522 11:59:17.055308  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_200000.caffemodel
I0522 11:59:17.109364  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_200000.solverstate
I0522 11:59:17.136592  9292 solver.cpp:341] Iteration 200000, Testing net (#0)
I0522 12:00:27.589165  9292 solver.cpp:409]     Test net output #0: accuracy = 0.896158
I0522 12:00:27.589361  9292 solver.cpp:409]     Test net output #1: loss = 0.33178 (* 1 = 0.33178 loss)
I0522 12:00:48.512183  9292 solver.cpp:237] Iteration 200000, loss = 1.2858
I0522 12:00:48.512235  9292 solver.cpp:253]     Train net output #0: loss = 1.2858 (* 1 = 1.2858 loss)
I0522 12:00:48.512250  9292 sgd_solver.cpp:106] Iteration 200000, lr = 0.0025
I0522 12:00:59.024508  9292 solver.cpp:237] Iteration 200500, loss = 1.07952
I0522 12:00:59.024709  9292 solver.cpp:253]     Train net output #0: loss = 1.07953 (* 1 = 1.07953 loss)
I0522 12:00:59.024725  9292 sgd_solver.cpp:106] Iteration 200500, lr = 0.0025
I0522 12:01:09.530788  9292 solver.cpp:237] Iteration 201000, loss = 1.62718
I0522 12:01:09.530824  9292 solver.cpp:253]     Train net output #0: loss = 1.62718 (* 1 = 1.62718 loss)
I0522 12:01:09.530838  9292 sgd_solver.cpp:106] Iteration 201000, lr = 0.0025
I0522 12:01:20.043936  9292 solver.cpp:237] Iteration 201500, loss = 1.26524
I0522 12:01:20.043984  9292 solver.cpp:253]     Train net output #0: loss = 1.26524 (* 1 = 1.26524 loss)
I0522 12:01:20.043998  9292 sgd_solver.cpp:106] Iteration 201500, lr = 0.0025
I0522 12:01:30.562036  9292 solver.cpp:237] Iteration 202000, loss = 0.912086
I0522 12:01:30.562216  9292 solver.cpp:253]     Train net output #0: loss = 0.912087 (* 1 = 0.912087 loss)
I0522 12:01:30.562232  9292 sgd_solver.cpp:106] Iteration 202000, lr = 0.0025
I0522 12:01:41.083214  9292 solver.cpp:237] Iteration 202500, loss = 0.991222
I0522 12:01:41.083251  9292 solver.cpp:253]     Train net output #0: loss = 0.991223 (* 1 = 0.991223 loss)
I0522 12:01:41.083266  9292 sgd_solver.cpp:106] Iteration 202500, lr = 0.0025
I0522 12:01:51.600541  9292 solver.cpp:237] Iteration 203000, loss = 1.50181
I0522 12:01:51.600587  9292 solver.cpp:253]     Train net output #0: loss = 1.50182 (* 1 = 1.50182 loss)
I0522 12:01:51.600601  9292 sgd_solver.cpp:106] Iteration 203000, lr = 0.0025
I0522 12:02:22.988399  9292 solver.cpp:237] Iteration 203500, loss = 1.29807
I0522 12:02:22.988597  9292 solver.cpp:253]     Train net output #0: loss = 1.29807 (* 1 = 1.29807 loss)
I0522 12:02:22.988613  9292 sgd_solver.cpp:106] Iteration 203500, lr = 0.0025
I0522 12:02:33.503491  9292 solver.cpp:237] Iteration 204000, loss = 1.13474
I0522 12:02:33.503527  9292 solver.cpp:253]     Train net output #0: loss = 1.13474 (* 1 = 1.13474 loss)
I0522 12:02:33.503541  9292 sgd_solver.cpp:106] Iteration 204000, lr = 0.0025
I0522 12:02:44.017896  9292 solver.cpp:237] Iteration 204500, loss = 1.38734
I0522 12:02:44.017935  9292 solver.cpp:253]     Train net output #0: loss = 1.38734 (* 1 = 1.38734 loss)
I0522 12:02:44.017949  9292 sgd_solver.cpp:106] Iteration 204500, lr = 0.0025
I0522 12:02:54.514638  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_205000.caffemodel
I0522 12:02:54.569548  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_205000.solverstate
I0522 12:02:54.601867  9292 solver.cpp:237] Iteration 205000, loss = 1.03888
I0522 12:02:54.601914  9292 solver.cpp:253]     Train net output #0: loss = 1.03888 (* 1 = 1.03888 loss)
I0522 12:02:54.601930  9292 sgd_solver.cpp:106] Iteration 205000, lr = 0.0025
I0522 12:03:05.109496  9292 solver.cpp:237] Iteration 205500, loss = 1.16444
I0522 12:03:05.109541  9292 solver.cpp:253]     Train net output #0: loss = 1.16444 (* 1 = 1.16444 loss)
I0522 12:03:05.109555  9292 sgd_solver.cpp:106] Iteration 205500, lr = 0.0025
I0522 12:03:15.624948  9292 solver.cpp:237] Iteration 206000, loss = 1.07259
I0522 12:03:15.624984  9292 solver.cpp:253]     Train net output #0: loss = 1.07259 (* 1 = 1.07259 loss)
I0522 12:03:15.624997  9292 sgd_solver.cpp:106] Iteration 206000, lr = 0.0025
I0522 12:03:26.135421  9292 solver.cpp:237] Iteration 206500, loss = 0.902694
I0522 12:03:26.135613  9292 solver.cpp:253]     Train net output #0: loss = 0.902696 (* 1 = 0.902696 loss)
I0522 12:03:26.135629  9292 sgd_solver.cpp:106] Iteration 206500, lr = 0.0025
I0522 12:03:57.497051  9292 solver.cpp:237] Iteration 207000, loss = 1.06241
I0522 12:03:57.497258  9292 solver.cpp:253]     Train net output #0: loss = 1.06241 (* 1 = 1.06241 loss)
I0522 12:03:57.497272  9292 sgd_solver.cpp:106] Iteration 207000, lr = 0.0025
I0522 12:04:08.026834  9292 solver.cpp:237] Iteration 207500, loss = 0.951036
I0522 12:04:08.026870  9292 solver.cpp:253]     Train net output #0: loss = 0.951038 (* 1 = 0.951038 loss)
I0522 12:04:08.026883  9292 sgd_solver.cpp:106] Iteration 207500, lr = 0.0025
I0522 12:04:18.544793  9292 solver.cpp:237] Iteration 208000, loss = 1.05511
I0522 12:04:18.544838  9292 solver.cpp:253]     Train net output #0: loss = 1.05511 (* 1 = 1.05511 loss)
I0522 12:04:18.544852  9292 sgd_solver.cpp:106] Iteration 208000, lr = 0.0025
I0522 12:04:29.075609  9292 solver.cpp:237] Iteration 208500, loss = 1.3713
I0522 12:04:29.075788  9292 solver.cpp:253]     Train net output #0: loss = 1.3713 (* 1 = 1.3713 loss)
I0522 12:04:29.075803  9292 sgd_solver.cpp:106] Iteration 208500, lr = 0.0025
I0522 12:04:39.679821  9292 solver.cpp:237] Iteration 209000, loss = 1.13951
I0522 12:04:39.679867  9292 solver.cpp:253]     Train net output #0: loss = 1.13951 (* 1 = 1.13951 loss)
I0522 12:04:39.679883  9292 sgd_solver.cpp:106] Iteration 209000, lr = 0.0025
I0522 12:04:50.285455  9292 solver.cpp:237] Iteration 209500, loss = 1.10767
I0522 12:04:50.285491  9292 solver.cpp:253]     Train net output #0: loss = 1.10767 (* 1 = 1.10767 loss)
I0522 12:04:50.285507  9292 sgd_solver.cpp:106] Iteration 209500, lr = 0.0025
I0522 12:05:00.859045  9292 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_210000.caffemodel
I0522 12:05:00.914557  9292 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0025_2016-05-20T15.48.58.860327_iter_210000.solverstate
I0522 12:05:00.939834  9292 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 12:05:50.551436  9292 solver.cpp:409]     Test net output #0: accuracy = 0.900972
I0522 12:05:50.551632  9292 solver.cpp:409]     Test net output #1: loss = 0.314849 (* 1 = 0.314849 loss)
I0522 12:06:11.448004  9292 solver.cpp:237] Iteration 210000, loss = 1.26209
I0522 12:06:11.448056  9292 solver.cpp:253]     Train net output #0: loss = 1.26209 (* 1 = 1.26209 loss)
I0522 12:06:11.448071  9292 sgd_solver.cpp:106] Iteration 210000, lr = 0.0025
I0522 12:06:21.971822  9292 solver.cpp:237] Iteration 210500, loss = 0.876106
I0522 12:06:21.972013  9292 solver.cpp:253]     Train net output #0: loss = 0.876108 (* 1 = 0.876108 loss)
I0522 12:06:21.972029  9292 sgd_solver.cpp:106] Iteration 210500, lr = 0.0025
I0522 12:06:32.494596  9292 solver.cpp:237] Iteration 211000, loss = 0.923581
I0522 12:06:32.494632  9292 solver.cpp:253]     Train net output #0: loss = 0.923583 (* 1 = 0.923583 loss)
I0522 12:06:32.494647  9292 sgd_solver.cpp:106] Iteration 211000, lr = 0.0025
I0522 12:06:43.022817  9292 solver.cpp:237] Iteration 211500, loss = 1.16484
I0522 12:06:43.022855  9292 solver.cpp:253]     Train net output #0: loss = 1.16484 (* 1 = 1.16484 loss)
I0522 12:06:43.022868  9292 sgd_solver.cpp:106] Iteration 211500, lr = 0.0025
I0522 12:06:53.551067  9292 solver.cpp:237] Iteration 212000, loss = 0.942016
I0522 12:06:53.551260  9292 solver.cpp:253]     Train net output #0: loss = 0.942018 (* 1 = 0.942018 loss)
I0522 12:06:53.551276  9292 sgd_solver.cpp:106] Iteration 212000, lr = 0.0025
I0522 12:07:04.085825  9292 solver.cpp:237] Iteration 212500, loss = 1.19652
I0522 12:07:04.085861  9292 solver.cpp:253]     Train net output #0: loss = 1.19652 (* 1 = 1.19652 loss)
I0522 12:07:04.085873  9292 sgd_solver.cpp:106] Iteration 212500, lr = 0.0025
I0522 12:07:14.604046  9292 solver.cpp:237] Iteration 213000, loss = 1.14823
I0522 12:07:14.604092  9292 solver.cpp:253]     Train net output #0: loss = 1.14824 (* 1 = 1.14824 loss)
I0522 12:07:14.604106  9292 sgd_solver.cpp:106] Iteration 213000, lr = 0.0025
I0522 12:07:46.080348  9292 solver.cpp:237] Iteration 213500, loss = 1.43791
I0522 12:07:46.080559  9292 solver.cpp:253]     Train net output #0: loss = 1.43791 (* 1 = 1.43791 loss)
I0522 12:07:46.080575  9292 sgd_solver.cpp:106] Iteration 213500, lr = 0.0025
I0522 12:07:56.605299  9292 solver.cpp:237] Iteration 214000, loss = 1.01647
I0522 12:07:56.605335  9292 solver.cpp:253]     Train net output #0: loss = 1.01647 (* 1 = 1.01647 loss)
I0522 12:07:56.605351  9292 sgd_solver.cpp:106] Iteration 214000, lr = 0.0025
aprun: Apid 11247441: Caught signal Terminated, sending to application
*** Aborted at 1463933276 (unix time) try "date -d @1463933276" if you are using GNU date ***
aprun: Apid 11247441: Caught signal Terminated, sending to application
aprun: Apid 11247441: Caught signal Terminated, sending to application
PC: @     0x2aaab9276659 (unknown)
*** SIGTERM (@0x2449) received by PID 9292 (TID 0x2aaac746f900) from PID 9289; stack trace: ***
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab9276659 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
=>> PBS: job killed: walltime 7221 exceeded limit 7200
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab928a408 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
aprun: Apid 11247441: Caught signal Terminated, sending to application
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11247441: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11247441: Caught signal Terminated, sending to application
