2807559
I0522 13:49:06.127526 31742 caffe.cpp:184] Using GPUs 0
I0522 13:49:06.578857 31742 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.004
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399.prototxt"
I0522 13:49:06.580643 31742 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399.prototxt
I0522 13:49:06.598644 31742 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 13:49:06.598704 31742 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 13:49:06.599050 31742 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 13:49:06.599230 31742 layer_factory.hpp:77] Creating layer data_hdf5
I0522 13:49:06.599252 31742 net.cpp:106] Creating Layer data_hdf5
I0522 13:49:06.599267 31742 net.cpp:411] data_hdf5 -> data
I0522 13:49:06.599300 31742 net.cpp:411] data_hdf5 -> label
I0522 13:49:06.599333 31742 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 13:49:06.614796 31742 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 13:49:06.628006 31742 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 13:49:28.212400 31742 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 13:49:28.217552 31742 net.cpp:150] Setting up data_hdf5
I0522 13:49:28.217593 31742 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 13:49:28.217608 31742 net.cpp:157] Top shape: 30 (30)
I0522 13:49:28.217620 31742 net.cpp:165] Memory required for data: 762120
I0522 13:49:28.217633 31742 layer_factory.hpp:77] Creating layer conv1
I0522 13:49:28.217667 31742 net.cpp:106] Creating Layer conv1
I0522 13:49:28.217679 31742 net.cpp:454] conv1 <- data
I0522 13:49:28.217700 31742 net.cpp:411] conv1 -> conv1
I0522 13:49:31.111564 31742 net.cpp:150] Setting up conv1
I0522 13:49:31.111613 31742 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 13:49:31.111624 31742 net.cpp:165] Memory required for data: 9056520
I0522 13:49:31.111654 31742 layer_factory.hpp:77] Creating layer relu1
I0522 13:49:31.111675 31742 net.cpp:106] Creating Layer relu1
I0522 13:49:31.111685 31742 net.cpp:454] relu1 <- conv1
I0522 13:49:31.111699 31742 net.cpp:397] relu1 -> conv1 (in-place)
I0522 13:49:31.112216 31742 net.cpp:150] Setting up relu1
I0522 13:49:31.112233 31742 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 13:49:31.112243 31742 net.cpp:165] Memory required for data: 17350920
I0522 13:49:31.112253 31742 layer_factory.hpp:77] Creating layer pool1
I0522 13:49:31.112272 31742 net.cpp:106] Creating Layer pool1
I0522 13:49:31.112282 31742 net.cpp:454] pool1 <- conv1
I0522 13:49:31.112294 31742 net.cpp:411] pool1 -> pool1
I0522 13:49:31.112375 31742 net.cpp:150] Setting up pool1
I0522 13:49:31.112388 31742 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 13:49:31.112398 31742 net.cpp:165] Memory required for data: 21498120
I0522 13:49:31.112409 31742 layer_factory.hpp:77] Creating layer conv2
I0522 13:49:31.112432 31742 net.cpp:106] Creating Layer conv2
I0522 13:49:31.112442 31742 net.cpp:454] conv2 <- pool1
I0522 13:49:31.112457 31742 net.cpp:411] conv2 -> conv2
I0522 13:49:31.115119 31742 net.cpp:150] Setting up conv2
I0522 13:49:31.115147 31742 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 13:49:31.115157 31742 net.cpp:165] Memory required for data: 27459720
I0522 13:49:31.115176 31742 layer_factory.hpp:77] Creating layer relu2
I0522 13:49:31.115190 31742 net.cpp:106] Creating Layer relu2
I0522 13:49:31.115201 31742 net.cpp:454] relu2 <- conv2
I0522 13:49:31.115213 31742 net.cpp:397] relu2 -> conv2 (in-place)
I0522 13:49:31.115556 31742 net.cpp:150] Setting up relu2
I0522 13:49:31.115569 31742 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 13:49:31.115581 31742 net.cpp:165] Memory required for data: 33421320
I0522 13:49:31.115591 31742 layer_factory.hpp:77] Creating layer pool2
I0522 13:49:31.115602 31742 net.cpp:106] Creating Layer pool2
I0522 13:49:31.115612 31742 net.cpp:454] pool2 <- conv2
I0522 13:49:31.115624 31742 net.cpp:411] pool2 -> pool2
I0522 13:49:31.115707 31742 net.cpp:150] Setting up pool2
I0522 13:49:31.115720 31742 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 13:49:31.115731 31742 net.cpp:165] Memory required for data: 36402120
I0522 13:49:31.115738 31742 layer_factory.hpp:77] Creating layer conv3
I0522 13:49:31.115757 31742 net.cpp:106] Creating Layer conv3
I0522 13:49:31.115767 31742 net.cpp:454] conv3 <- pool2
I0522 13:49:31.115780 31742 net.cpp:411] conv3 -> conv3
I0522 13:49:31.117735 31742 net.cpp:150] Setting up conv3
I0522 13:49:31.117754 31742 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 13:49:31.117769 31742 net.cpp:165] Memory required for data: 39654600
I0522 13:49:31.117787 31742 layer_factory.hpp:77] Creating layer relu3
I0522 13:49:31.117804 31742 net.cpp:106] Creating Layer relu3
I0522 13:49:31.117813 31742 net.cpp:454] relu3 <- conv3
I0522 13:49:31.117825 31742 net.cpp:397] relu3 -> conv3 (in-place)
I0522 13:49:31.118291 31742 net.cpp:150] Setting up relu3
I0522 13:49:31.118309 31742 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 13:49:31.118319 31742 net.cpp:165] Memory required for data: 42907080
I0522 13:49:31.118329 31742 layer_factory.hpp:77] Creating layer pool3
I0522 13:49:31.118341 31742 net.cpp:106] Creating Layer pool3
I0522 13:49:31.118351 31742 net.cpp:454] pool3 <- conv3
I0522 13:49:31.118363 31742 net.cpp:411] pool3 -> pool3
I0522 13:49:31.118432 31742 net.cpp:150] Setting up pool3
I0522 13:49:31.118443 31742 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 13:49:31.118453 31742 net.cpp:165] Memory required for data: 44533320
I0522 13:49:31.118463 31742 layer_factory.hpp:77] Creating layer conv4
I0522 13:49:31.118481 31742 net.cpp:106] Creating Layer conv4
I0522 13:49:31.118491 31742 net.cpp:454] conv4 <- pool3
I0522 13:49:31.118505 31742 net.cpp:411] conv4 -> conv4
I0522 13:49:31.121235 31742 net.cpp:150] Setting up conv4
I0522 13:49:31.121263 31742 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 13:49:31.121274 31742 net.cpp:165] Memory required for data: 45621960
I0522 13:49:31.121290 31742 layer_factory.hpp:77] Creating layer relu4
I0522 13:49:31.121304 31742 net.cpp:106] Creating Layer relu4
I0522 13:49:31.121318 31742 net.cpp:454] relu4 <- conv4
I0522 13:49:31.121331 31742 net.cpp:397] relu4 -> conv4 (in-place)
I0522 13:49:31.121793 31742 net.cpp:150] Setting up relu4
I0522 13:49:31.121809 31742 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 13:49:31.121819 31742 net.cpp:165] Memory required for data: 46710600
I0522 13:49:31.121829 31742 layer_factory.hpp:77] Creating layer pool4
I0522 13:49:31.121842 31742 net.cpp:106] Creating Layer pool4
I0522 13:49:31.121852 31742 net.cpp:454] pool4 <- conv4
I0522 13:49:31.121865 31742 net.cpp:411] pool4 -> pool4
I0522 13:49:31.121933 31742 net.cpp:150] Setting up pool4
I0522 13:49:31.121948 31742 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 13:49:31.121958 31742 net.cpp:165] Memory required for data: 47254920
I0522 13:49:31.121968 31742 layer_factory.hpp:77] Creating layer ip1
I0522 13:49:31.121987 31742 net.cpp:106] Creating Layer ip1
I0522 13:49:31.121999 31742 net.cpp:454] ip1 <- pool4
I0522 13:49:31.122010 31742 net.cpp:411] ip1 -> ip1
I0522 13:49:31.137477 31742 net.cpp:150] Setting up ip1
I0522 13:49:31.137506 31742 net.cpp:157] Top shape: 30 196 (5880)
I0522 13:49:31.137521 31742 net.cpp:165] Memory required for data: 47278440
I0522 13:49:31.137542 31742 layer_factory.hpp:77] Creating layer relu5
I0522 13:49:31.137557 31742 net.cpp:106] Creating Layer relu5
I0522 13:49:31.137567 31742 net.cpp:454] relu5 <- ip1
I0522 13:49:31.137580 31742 net.cpp:397] relu5 -> ip1 (in-place)
I0522 13:49:31.137923 31742 net.cpp:150] Setting up relu5
I0522 13:49:31.137935 31742 net.cpp:157] Top shape: 30 196 (5880)
I0522 13:49:31.137946 31742 net.cpp:165] Memory required for data: 47301960
I0522 13:49:31.137956 31742 layer_factory.hpp:77] Creating layer drop1
I0522 13:49:31.137979 31742 net.cpp:106] Creating Layer drop1
I0522 13:49:31.137989 31742 net.cpp:454] drop1 <- ip1
I0522 13:49:31.138000 31742 net.cpp:397] drop1 -> ip1 (in-place)
I0522 13:49:31.138061 31742 net.cpp:150] Setting up drop1
I0522 13:49:31.138074 31742 net.cpp:157] Top shape: 30 196 (5880)
I0522 13:49:31.138084 31742 net.cpp:165] Memory required for data: 47325480
I0522 13:49:31.138094 31742 layer_factory.hpp:77] Creating layer ip2
I0522 13:49:31.138113 31742 net.cpp:106] Creating Layer ip2
I0522 13:49:31.138123 31742 net.cpp:454] ip2 <- ip1
I0522 13:49:31.138136 31742 net.cpp:411] ip2 -> ip2
I0522 13:49:31.138597 31742 net.cpp:150] Setting up ip2
I0522 13:49:31.138609 31742 net.cpp:157] Top shape: 30 98 (2940)
I0522 13:49:31.138619 31742 net.cpp:165] Memory required for data: 47337240
I0522 13:49:31.138634 31742 layer_factory.hpp:77] Creating layer relu6
I0522 13:49:31.138648 31742 net.cpp:106] Creating Layer relu6
I0522 13:49:31.138656 31742 net.cpp:454] relu6 <- ip2
I0522 13:49:31.138669 31742 net.cpp:397] relu6 -> ip2 (in-place)
I0522 13:49:31.139184 31742 net.cpp:150] Setting up relu6
I0522 13:49:31.139200 31742 net.cpp:157] Top shape: 30 98 (2940)
I0522 13:49:31.139211 31742 net.cpp:165] Memory required for data: 47349000
I0522 13:49:31.139221 31742 layer_factory.hpp:77] Creating layer drop2
I0522 13:49:31.139235 31742 net.cpp:106] Creating Layer drop2
I0522 13:49:31.139245 31742 net.cpp:454] drop2 <- ip2
I0522 13:49:31.139256 31742 net.cpp:397] drop2 -> ip2 (in-place)
I0522 13:49:31.139298 31742 net.cpp:150] Setting up drop2
I0522 13:49:31.139312 31742 net.cpp:157] Top shape: 30 98 (2940)
I0522 13:49:31.139322 31742 net.cpp:165] Memory required for data: 47360760
I0522 13:49:31.139333 31742 layer_factory.hpp:77] Creating layer ip3
I0522 13:49:31.139345 31742 net.cpp:106] Creating Layer ip3
I0522 13:49:31.139355 31742 net.cpp:454] ip3 <- ip2
I0522 13:49:31.139369 31742 net.cpp:411] ip3 -> ip3
I0522 13:49:31.139585 31742 net.cpp:150] Setting up ip3
I0522 13:49:31.139598 31742 net.cpp:157] Top shape: 30 11 (330)
I0522 13:49:31.139608 31742 net.cpp:165] Memory required for data: 47362080
I0522 13:49:31.139624 31742 layer_factory.hpp:77] Creating layer drop3
I0522 13:49:31.139636 31742 net.cpp:106] Creating Layer drop3
I0522 13:49:31.139647 31742 net.cpp:454] drop3 <- ip3
I0522 13:49:31.139658 31742 net.cpp:397] drop3 -> ip3 (in-place)
I0522 13:49:31.139698 31742 net.cpp:150] Setting up drop3
I0522 13:49:31.139710 31742 net.cpp:157] Top shape: 30 11 (330)
I0522 13:49:31.139720 31742 net.cpp:165] Memory required for data: 47363400
I0522 13:49:31.139729 31742 layer_factory.hpp:77] Creating layer loss
I0522 13:49:31.139749 31742 net.cpp:106] Creating Layer loss
I0522 13:49:31.139758 31742 net.cpp:454] loss <- ip3
I0522 13:49:31.139770 31742 net.cpp:454] loss <- label
I0522 13:49:31.139780 31742 net.cpp:411] loss -> loss
I0522 13:49:31.139797 31742 layer_factory.hpp:77] Creating layer loss
I0522 13:49:31.140439 31742 net.cpp:150] Setting up loss
I0522 13:49:31.140458 31742 net.cpp:157] Top shape: (1)
I0522 13:49:31.140472 31742 net.cpp:160]     with loss weight 1
I0522 13:49:31.140514 31742 net.cpp:165] Memory required for data: 47363404
I0522 13:49:31.140524 31742 net.cpp:226] loss needs backward computation.
I0522 13:49:31.140535 31742 net.cpp:226] drop3 needs backward computation.
I0522 13:49:31.140545 31742 net.cpp:226] ip3 needs backward computation.
I0522 13:49:31.140557 31742 net.cpp:226] drop2 needs backward computation.
I0522 13:49:31.140566 31742 net.cpp:226] relu6 needs backward computation.
I0522 13:49:31.140576 31742 net.cpp:226] ip2 needs backward computation.
I0522 13:49:31.140586 31742 net.cpp:226] drop1 needs backward computation.
I0522 13:49:31.140596 31742 net.cpp:226] relu5 needs backward computation.
I0522 13:49:31.140605 31742 net.cpp:226] ip1 needs backward computation.
I0522 13:49:31.140615 31742 net.cpp:226] pool4 needs backward computation.
I0522 13:49:31.140625 31742 net.cpp:226] relu4 needs backward computation.
I0522 13:49:31.140635 31742 net.cpp:226] conv4 needs backward computation.
I0522 13:49:31.140646 31742 net.cpp:226] pool3 needs backward computation.
I0522 13:49:31.140656 31742 net.cpp:226] relu3 needs backward computation.
I0522 13:49:31.140666 31742 net.cpp:226] conv3 needs backward computation.
I0522 13:49:31.140686 31742 net.cpp:226] pool2 needs backward computation.
I0522 13:49:31.140697 31742 net.cpp:226] relu2 needs backward computation.
I0522 13:49:31.140707 31742 net.cpp:226] conv2 needs backward computation.
I0522 13:49:31.140717 31742 net.cpp:226] pool1 needs backward computation.
I0522 13:49:31.140728 31742 net.cpp:226] relu1 needs backward computation.
I0522 13:49:31.140738 31742 net.cpp:226] conv1 needs backward computation.
I0522 13:49:31.140748 31742 net.cpp:228] data_hdf5 does not need backward computation.
I0522 13:49:31.140758 31742 net.cpp:270] This network produces output loss
I0522 13:49:31.140782 31742 net.cpp:283] Network initialization done.
I0522 13:49:31.142413 31742 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399.prototxt
I0522 13:49:31.142485 31742 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 13:49:31.142841 31742 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 13:49:31.143030 31742 layer_factory.hpp:77] Creating layer data_hdf5
I0522 13:49:31.143045 31742 net.cpp:106] Creating Layer data_hdf5
I0522 13:49:31.143057 31742 net.cpp:411] data_hdf5 -> data
I0522 13:49:31.143074 31742 net.cpp:411] data_hdf5 -> label
I0522 13:49:31.143090 31742 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 13:49:31.151823 31742 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 13:49:52.539366 31742 net.cpp:150] Setting up data_hdf5
I0522 13:49:52.539541 31742 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 13:49:52.539556 31742 net.cpp:157] Top shape: 30 (30)
I0522 13:49:52.539569 31742 net.cpp:165] Memory required for data: 762120
I0522 13:49:52.539582 31742 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 13:49:52.539610 31742 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 13:49:52.539621 31742 net.cpp:454] label_data_hdf5_1_split <- label
I0522 13:49:52.539636 31742 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 13:49:52.539657 31742 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 13:49:52.539731 31742 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 13:49:52.539744 31742 net.cpp:157] Top shape: 30 (30)
I0522 13:49:52.539757 31742 net.cpp:157] Top shape: 30 (30)
I0522 13:49:52.539765 31742 net.cpp:165] Memory required for data: 762360
I0522 13:49:52.539775 31742 layer_factory.hpp:77] Creating layer conv1
I0522 13:49:52.539798 31742 net.cpp:106] Creating Layer conv1
I0522 13:49:52.539808 31742 net.cpp:454] conv1 <- data
I0522 13:49:52.539822 31742 net.cpp:411] conv1 -> conv1
I0522 13:49:52.541796 31742 net.cpp:150] Setting up conv1
I0522 13:49:52.541815 31742 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 13:49:52.541831 31742 net.cpp:165] Memory required for data: 9056760
I0522 13:49:52.541851 31742 layer_factory.hpp:77] Creating layer relu1
I0522 13:49:52.541867 31742 net.cpp:106] Creating Layer relu1
I0522 13:49:52.541877 31742 net.cpp:454] relu1 <- conv1
I0522 13:49:52.541889 31742 net.cpp:397] relu1 -> conv1 (in-place)
I0522 13:49:52.542394 31742 net.cpp:150] Setting up relu1
I0522 13:49:52.542410 31742 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 13:49:52.542421 31742 net.cpp:165] Memory required for data: 17351160
I0522 13:49:52.542433 31742 layer_factory.hpp:77] Creating layer pool1
I0522 13:49:52.542448 31742 net.cpp:106] Creating Layer pool1
I0522 13:49:52.542459 31742 net.cpp:454] pool1 <- conv1
I0522 13:49:52.542474 31742 net.cpp:411] pool1 -> pool1
I0522 13:49:52.542547 31742 net.cpp:150] Setting up pool1
I0522 13:49:52.542560 31742 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 13:49:52.542570 31742 net.cpp:165] Memory required for data: 21498360
I0522 13:49:52.542580 31742 layer_factory.hpp:77] Creating layer conv2
I0522 13:49:52.542598 31742 net.cpp:106] Creating Layer conv2
I0522 13:49:52.542608 31742 net.cpp:454] conv2 <- pool1
I0522 13:49:52.542623 31742 net.cpp:411] conv2 -> conv2
I0522 13:49:52.544543 31742 net.cpp:150] Setting up conv2
I0522 13:49:52.544564 31742 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 13:49:52.544577 31742 net.cpp:165] Memory required for data: 27459960
I0522 13:49:52.544595 31742 layer_factory.hpp:77] Creating layer relu2
I0522 13:49:52.544608 31742 net.cpp:106] Creating Layer relu2
I0522 13:49:52.544620 31742 net.cpp:454] relu2 <- conv2
I0522 13:49:52.544631 31742 net.cpp:397] relu2 -> conv2 (in-place)
I0522 13:49:52.544963 31742 net.cpp:150] Setting up relu2
I0522 13:49:52.544977 31742 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 13:49:52.544987 31742 net.cpp:165] Memory required for data: 33421560
I0522 13:49:52.544997 31742 layer_factory.hpp:77] Creating layer pool2
I0522 13:49:52.545011 31742 net.cpp:106] Creating Layer pool2
I0522 13:49:52.545020 31742 net.cpp:454] pool2 <- conv2
I0522 13:49:52.545032 31742 net.cpp:411] pool2 -> pool2
I0522 13:49:52.545104 31742 net.cpp:150] Setting up pool2
I0522 13:49:52.545117 31742 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 13:49:52.545126 31742 net.cpp:165] Memory required for data: 36402360
I0522 13:49:52.545136 31742 layer_factory.hpp:77] Creating layer conv3
I0522 13:49:52.545155 31742 net.cpp:106] Creating Layer conv3
I0522 13:49:52.545166 31742 net.cpp:454] conv3 <- pool2
I0522 13:49:52.545179 31742 net.cpp:411] conv3 -> conv3
I0522 13:49:52.547145 31742 net.cpp:150] Setting up conv3
I0522 13:49:52.547168 31742 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 13:49:52.547180 31742 net.cpp:165] Memory required for data: 39654840
I0522 13:49:52.547212 31742 layer_factory.hpp:77] Creating layer relu3
I0522 13:49:52.547226 31742 net.cpp:106] Creating Layer relu3
I0522 13:49:52.547236 31742 net.cpp:454] relu3 <- conv3
I0522 13:49:52.547248 31742 net.cpp:397] relu3 -> conv3 (in-place)
I0522 13:49:52.547726 31742 net.cpp:150] Setting up relu3
I0522 13:49:52.547742 31742 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 13:49:52.547752 31742 net.cpp:165] Memory required for data: 42907320
I0522 13:49:52.547762 31742 layer_factory.hpp:77] Creating layer pool3
I0522 13:49:52.547776 31742 net.cpp:106] Creating Layer pool3
I0522 13:49:52.547786 31742 net.cpp:454] pool3 <- conv3
I0522 13:49:52.547798 31742 net.cpp:411] pool3 -> pool3
I0522 13:49:52.547870 31742 net.cpp:150] Setting up pool3
I0522 13:49:52.547883 31742 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 13:49:52.547894 31742 net.cpp:165] Memory required for data: 44533560
I0522 13:49:52.547904 31742 layer_factory.hpp:77] Creating layer conv4
I0522 13:49:52.547920 31742 net.cpp:106] Creating Layer conv4
I0522 13:49:52.547930 31742 net.cpp:454] conv4 <- pool3
I0522 13:49:52.547945 31742 net.cpp:411] conv4 -> conv4
I0522 13:49:52.549998 31742 net.cpp:150] Setting up conv4
I0522 13:49:52.550021 31742 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 13:49:52.550034 31742 net.cpp:165] Memory required for data: 45622200
I0522 13:49:52.550048 31742 layer_factory.hpp:77] Creating layer relu4
I0522 13:49:52.550062 31742 net.cpp:106] Creating Layer relu4
I0522 13:49:52.550072 31742 net.cpp:454] relu4 <- conv4
I0522 13:49:52.550086 31742 net.cpp:397] relu4 -> conv4 (in-place)
I0522 13:49:52.550554 31742 net.cpp:150] Setting up relu4
I0522 13:49:52.550570 31742 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 13:49:52.550580 31742 net.cpp:165] Memory required for data: 46710840
I0522 13:49:52.550590 31742 layer_factory.hpp:77] Creating layer pool4
I0522 13:49:52.550602 31742 net.cpp:106] Creating Layer pool4
I0522 13:49:52.550612 31742 net.cpp:454] pool4 <- conv4
I0522 13:49:52.550626 31742 net.cpp:411] pool4 -> pool4
I0522 13:49:52.550696 31742 net.cpp:150] Setting up pool4
I0522 13:49:52.550709 31742 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 13:49:52.550719 31742 net.cpp:165] Memory required for data: 47255160
I0522 13:49:52.550729 31742 layer_factory.hpp:77] Creating layer ip1
I0522 13:49:52.550745 31742 net.cpp:106] Creating Layer ip1
I0522 13:49:52.550755 31742 net.cpp:454] ip1 <- pool4
I0522 13:49:52.550767 31742 net.cpp:411] ip1 -> ip1
I0522 13:49:52.566251 31742 net.cpp:150] Setting up ip1
I0522 13:49:52.566279 31742 net.cpp:157] Top shape: 30 196 (5880)
I0522 13:49:52.566292 31742 net.cpp:165] Memory required for data: 47278680
I0522 13:49:52.566313 31742 layer_factory.hpp:77] Creating layer relu5
I0522 13:49:52.566329 31742 net.cpp:106] Creating Layer relu5
I0522 13:49:52.566339 31742 net.cpp:454] relu5 <- ip1
I0522 13:49:52.566352 31742 net.cpp:397] relu5 -> ip1 (in-place)
I0522 13:49:52.566699 31742 net.cpp:150] Setting up relu5
I0522 13:49:52.566714 31742 net.cpp:157] Top shape: 30 196 (5880)
I0522 13:49:52.566723 31742 net.cpp:165] Memory required for data: 47302200
I0522 13:49:52.566733 31742 layer_factory.hpp:77] Creating layer drop1
I0522 13:49:52.566753 31742 net.cpp:106] Creating Layer drop1
I0522 13:49:52.566763 31742 net.cpp:454] drop1 <- ip1
I0522 13:49:52.566776 31742 net.cpp:397] drop1 -> ip1 (in-place)
I0522 13:49:52.566823 31742 net.cpp:150] Setting up drop1
I0522 13:49:52.566836 31742 net.cpp:157] Top shape: 30 196 (5880)
I0522 13:49:52.566845 31742 net.cpp:165] Memory required for data: 47325720
I0522 13:49:52.566855 31742 layer_factory.hpp:77] Creating layer ip2
I0522 13:49:52.566870 31742 net.cpp:106] Creating Layer ip2
I0522 13:49:52.566879 31742 net.cpp:454] ip2 <- ip1
I0522 13:49:52.566891 31742 net.cpp:411] ip2 -> ip2
I0522 13:49:52.567368 31742 net.cpp:150] Setting up ip2
I0522 13:49:52.567380 31742 net.cpp:157] Top shape: 30 98 (2940)
I0522 13:49:52.567390 31742 net.cpp:165] Memory required for data: 47337480
I0522 13:49:52.567405 31742 layer_factory.hpp:77] Creating layer relu6
I0522 13:49:52.567437 31742 net.cpp:106] Creating Layer relu6
I0522 13:49:52.567447 31742 net.cpp:454] relu6 <- ip2
I0522 13:49:52.567461 31742 net.cpp:397] relu6 -> ip2 (in-place)
I0522 13:49:52.567994 31742 net.cpp:150] Setting up relu6
I0522 13:49:52.568016 31742 net.cpp:157] Top shape: 30 98 (2940)
I0522 13:49:52.568025 31742 net.cpp:165] Memory required for data: 47349240
I0522 13:49:52.568037 31742 layer_factory.hpp:77] Creating layer drop2
I0522 13:49:52.568050 31742 net.cpp:106] Creating Layer drop2
I0522 13:49:52.568060 31742 net.cpp:454] drop2 <- ip2
I0522 13:49:52.568073 31742 net.cpp:397] drop2 -> ip2 (in-place)
I0522 13:49:52.568117 31742 net.cpp:150] Setting up drop2
I0522 13:49:52.568130 31742 net.cpp:157] Top shape: 30 98 (2940)
I0522 13:49:52.568140 31742 net.cpp:165] Memory required for data: 47361000
I0522 13:49:52.568150 31742 layer_factory.hpp:77] Creating layer ip3
I0522 13:49:52.568163 31742 net.cpp:106] Creating Layer ip3
I0522 13:49:52.568173 31742 net.cpp:454] ip3 <- ip2
I0522 13:49:52.568188 31742 net.cpp:411] ip3 -> ip3
I0522 13:49:52.568413 31742 net.cpp:150] Setting up ip3
I0522 13:49:52.568425 31742 net.cpp:157] Top shape: 30 11 (330)
I0522 13:49:52.568435 31742 net.cpp:165] Memory required for data: 47362320
I0522 13:49:52.568451 31742 layer_factory.hpp:77] Creating layer drop3
I0522 13:49:52.568464 31742 net.cpp:106] Creating Layer drop3
I0522 13:49:52.568473 31742 net.cpp:454] drop3 <- ip3
I0522 13:49:52.568485 31742 net.cpp:397] drop3 -> ip3 (in-place)
I0522 13:49:52.568527 31742 net.cpp:150] Setting up drop3
I0522 13:49:52.568541 31742 net.cpp:157] Top shape: 30 11 (330)
I0522 13:49:52.568550 31742 net.cpp:165] Memory required for data: 47363640
I0522 13:49:52.568559 31742 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 13:49:52.568572 31742 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 13:49:52.568583 31742 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 13:49:52.568595 31742 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 13:49:52.568610 31742 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 13:49:52.568684 31742 net.cpp:150] Setting up ip3_drop3_0_split
I0522 13:49:52.568696 31742 net.cpp:157] Top shape: 30 11 (330)
I0522 13:49:52.568709 31742 net.cpp:157] Top shape: 30 11 (330)
I0522 13:49:52.568719 31742 net.cpp:165] Memory required for data: 47366280
I0522 13:49:52.568729 31742 layer_factory.hpp:77] Creating layer accuracy
I0522 13:49:52.568752 31742 net.cpp:106] Creating Layer accuracy
I0522 13:49:52.568761 31742 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 13:49:52.568773 31742 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 13:49:52.568786 31742 net.cpp:411] accuracy -> accuracy
I0522 13:49:52.568810 31742 net.cpp:150] Setting up accuracy
I0522 13:49:52.568822 31742 net.cpp:157] Top shape: (1)
I0522 13:49:52.568832 31742 net.cpp:165] Memory required for data: 47366284
I0522 13:49:52.568842 31742 layer_factory.hpp:77] Creating layer loss
I0522 13:49:52.568856 31742 net.cpp:106] Creating Layer loss
I0522 13:49:52.568866 31742 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 13:49:52.568877 31742 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 13:49:52.568891 31742 net.cpp:411] loss -> loss
I0522 13:49:52.568907 31742 layer_factory.hpp:77] Creating layer loss
I0522 13:49:52.569391 31742 net.cpp:150] Setting up loss
I0522 13:49:52.569406 31742 net.cpp:157] Top shape: (1)
I0522 13:49:52.569416 31742 net.cpp:160]     with loss weight 1
I0522 13:49:52.569433 31742 net.cpp:165] Memory required for data: 47366288
I0522 13:49:52.569443 31742 net.cpp:226] loss needs backward computation.
I0522 13:49:52.569454 31742 net.cpp:228] accuracy does not need backward computation.
I0522 13:49:52.569465 31742 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 13:49:52.569476 31742 net.cpp:226] drop3 needs backward computation.
I0522 13:49:52.569486 31742 net.cpp:226] ip3 needs backward computation.
I0522 13:49:52.569496 31742 net.cpp:226] drop2 needs backward computation.
I0522 13:49:52.569506 31742 net.cpp:226] relu6 needs backward computation.
I0522 13:49:52.569525 31742 net.cpp:226] ip2 needs backward computation.
I0522 13:49:52.569535 31742 net.cpp:226] drop1 needs backward computation.
I0522 13:49:52.569545 31742 net.cpp:226] relu5 needs backward computation.
I0522 13:49:52.569553 31742 net.cpp:226] ip1 needs backward computation.
I0522 13:49:52.569564 31742 net.cpp:226] pool4 needs backward computation.
I0522 13:49:52.569574 31742 net.cpp:226] relu4 needs backward computation.
I0522 13:49:52.569584 31742 net.cpp:226] conv4 needs backward computation.
I0522 13:49:52.569596 31742 net.cpp:226] pool3 needs backward computation.
I0522 13:49:52.569605 31742 net.cpp:226] relu3 needs backward computation.
I0522 13:49:52.569615 31742 net.cpp:226] conv3 needs backward computation.
I0522 13:49:52.569625 31742 net.cpp:226] pool2 needs backward computation.
I0522 13:49:52.569636 31742 net.cpp:226] relu2 needs backward computation.
I0522 13:49:52.569645 31742 net.cpp:226] conv2 needs backward computation.
I0522 13:49:52.569656 31742 net.cpp:226] pool1 needs backward computation.
I0522 13:49:52.569666 31742 net.cpp:226] relu1 needs backward computation.
I0522 13:49:52.569675 31742 net.cpp:226] conv1 needs backward computation.
I0522 13:49:52.569687 31742 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 13:49:52.569699 31742 net.cpp:228] data_hdf5 does not need backward computation.
I0522 13:49:52.569707 31742 net.cpp:270] This network produces output accuracy
I0522 13:49:52.569716 31742 net.cpp:270] This network produces output loss
I0522 13:49:52.569744 31742 net.cpp:283] Network initialization done.
I0522 13:49:52.569876 31742 solver.cpp:60] Solver scaffolding done.
I0522 13:49:52.571012 31742 caffe.cpp:212] Starting Optimization
I0522 13:49:52.571030 31742 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 13:49:52.571043 31742 solver.cpp:289] Learning Rate Policy: fixed
I0522 13:49:52.572289 31742 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 13:50:43.161748 31742 solver.cpp:409]     Test net output #0: accuracy = 0.132582
I0522 13:50:43.161909 31742 solver.cpp:409]     Test net output #1: loss = 2.39571 (* 1 = 2.39571 loss)
I0522 13:50:43.182816 31742 solver.cpp:237] Iteration 0, loss = 2.3967
I0522 13:50:43.182854 31742 solver.cpp:253]     Train net output #0: loss = 2.3967 (* 1 = 2.3967 loss)
I0522 13:50:43.182873 31742 sgd_solver.cpp:106] Iteration 0, lr = 0.004
I0522 13:50:53.718474 31742 solver.cpp:237] Iteration 500, loss = 2.30772
I0522 13:50:53.718530 31742 solver.cpp:253]     Train net output #0: loss = 2.30772 (* 1 = 2.30772 loss)
I0522 13:50:53.718544 31742 sgd_solver.cpp:106] Iteration 500, lr = 0.004
I0522 13:51:04.269750 31742 solver.cpp:237] Iteration 1000, loss = 2.16843
I0522 13:51:04.269788 31742 solver.cpp:253]     Train net output #0: loss = 2.16843 (* 1 = 2.16843 loss)
I0522 13:51:04.269804 31742 sgd_solver.cpp:106] Iteration 1000, lr = 0.004
I0522 13:51:14.805232 31742 solver.cpp:237] Iteration 1500, loss = 1.52909
I0522 13:51:14.805392 31742 solver.cpp:253]     Train net output #0: loss = 1.52909 (* 1 = 1.52909 loss)
I0522 13:51:14.805407 31742 sgd_solver.cpp:106] Iteration 1500, lr = 0.004
I0522 13:51:25.357264 31742 solver.cpp:237] Iteration 2000, loss = 1.33388
I0522 13:51:25.357309 31742 solver.cpp:253]     Train net output #0: loss = 1.33388 (* 1 = 1.33388 loss)
I0522 13:51:25.357328 31742 sgd_solver.cpp:106] Iteration 2000, lr = 0.004
I0522 13:51:35.899008 31742 solver.cpp:237] Iteration 2500, loss = 1.55524
I0522 13:51:35.899044 31742 solver.cpp:253]     Train net output #0: loss = 1.55524 (* 1 = 1.55524 loss)
I0522 13:51:35.899060 31742 sgd_solver.cpp:106] Iteration 2500, lr = 0.004
I0522 13:51:46.439875 31742 solver.cpp:237] Iteration 3000, loss = 1.41405
I0522 13:51:46.440027 31742 solver.cpp:253]     Train net output #0: loss = 1.41405 (* 1 = 1.41405 loss)
I0522 13:51:46.440042 31742 sgd_solver.cpp:106] Iteration 3000, lr = 0.004
I0522 13:52:19.201494 31742 solver.cpp:237] Iteration 3500, loss = 1.46157
I0522 13:52:19.201654 31742 solver.cpp:253]     Train net output #0: loss = 1.46157 (* 1 = 1.46157 loss)
I0522 13:52:19.201669 31742 sgd_solver.cpp:106] Iteration 3500, lr = 0.004
I0522 13:52:29.753832 31742 solver.cpp:237] Iteration 4000, loss = 1.34326
I0522 13:52:29.753867 31742 solver.cpp:253]     Train net output #0: loss = 1.34326 (* 1 = 1.34326 loss)
I0522 13:52:29.753885 31742 sgd_solver.cpp:106] Iteration 4000, lr = 0.004
I0522 13:52:40.285531 31742 solver.cpp:237] Iteration 4500, loss = 1.64275
I0522 13:52:40.285572 31742 solver.cpp:253]     Train net output #0: loss = 1.64275 (* 1 = 1.64275 loss)
I0522 13:52:40.285588 31742 sgd_solver.cpp:106] Iteration 4500, lr = 0.004
I0522 13:52:50.810492 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_5000.caffemodel
I0522 13:52:50.866056 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_5000.solverstate
I0522 13:52:50.897929 31742 solver.cpp:237] Iteration 5000, loss = 1.57361
I0522 13:52:50.897974 31742 solver.cpp:253]     Train net output #0: loss = 1.57361 (* 1 = 1.57361 loss)
I0522 13:52:50.897989 31742 sgd_solver.cpp:106] Iteration 5000, lr = 0.004
I0522 13:53:01.449760 31742 solver.cpp:237] Iteration 5500, loss = 1.47259
I0522 13:53:01.449808 31742 solver.cpp:253]     Train net output #0: loss = 1.47259 (* 1 = 1.47259 loss)
I0522 13:53:01.449822 31742 sgd_solver.cpp:106] Iteration 5500, lr = 0.004
I0522 13:53:11.980875 31742 solver.cpp:237] Iteration 6000, loss = 1.1101
I0522 13:53:11.980911 31742 solver.cpp:253]     Train net output #0: loss = 1.1101 (* 1 = 1.1101 loss)
I0522 13:53:11.980924 31742 sgd_solver.cpp:106] Iteration 6000, lr = 0.004
I0522 13:53:22.517042 31742 solver.cpp:237] Iteration 6500, loss = 1.43851
I0522 13:53:22.517195 31742 solver.cpp:253]     Train net output #0: loss = 1.43851 (* 1 = 1.43851 loss)
I0522 13:53:22.517210 31742 sgd_solver.cpp:106] Iteration 6500, lr = 0.004
I0522 13:53:55.252224 31742 solver.cpp:237] Iteration 7000, loss = 1.41597
I0522 13:53:55.252382 31742 solver.cpp:253]     Train net output #0: loss = 1.41597 (* 1 = 1.41597 loss)
I0522 13:53:55.252396 31742 sgd_solver.cpp:106] Iteration 7000, lr = 0.004
I0522 13:54:05.793956 31742 solver.cpp:237] Iteration 7500, loss = 1.24664
I0522 13:54:05.793992 31742 solver.cpp:253]     Train net output #0: loss = 1.24664 (* 1 = 1.24664 loss)
I0522 13:54:05.794008 31742 sgd_solver.cpp:106] Iteration 7500, lr = 0.004
I0522 13:54:16.351126 31742 solver.cpp:237] Iteration 8000, loss = 1.40585
I0522 13:54:16.351178 31742 solver.cpp:253]     Train net output #0: loss = 1.40585 (* 1 = 1.40585 loss)
I0522 13:54:16.351192 31742 sgd_solver.cpp:106] Iteration 8000, lr = 0.004
I0522 13:54:26.904585 31742 solver.cpp:237] Iteration 8500, loss = 1.63543
I0522 13:54:26.904731 31742 solver.cpp:253]     Train net output #0: loss = 1.63543 (* 1 = 1.63543 loss)
I0522 13:54:26.904745 31742 sgd_solver.cpp:106] Iteration 8500, lr = 0.004
I0522 13:54:37.466424 31742 solver.cpp:237] Iteration 9000, loss = 1.70053
I0522 13:54:37.466473 31742 solver.cpp:253]     Train net output #0: loss = 1.70053 (* 1 = 1.70053 loss)
I0522 13:54:37.466488 31742 sgd_solver.cpp:106] Iteration 9000, lr = 0.004
I0522 13:54:48.025573 31742 solver.cpp:237] Iteration 9500, loss = 1.22854
I0522 13:54:48.025607 31742 solver.cpp:253]     Train net output #0: loss = 1.22854 (* 1 = 1.22854 loss)
I0522 13:54:48.025624 31742 sgd_solver.cpp:106] Iteration 9500, lr = 0.004
I0522 13:54:58.579043 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_10000.caffemodel
I0522 13:54:58.632190 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_10000.solverstate
I0522 13:54:58.657882 31742 solver.cpp:341] Iteration 10000, Testing net (#0)
I0522 13:55:48.207129 31742 solver.cpp:409]     Test net output #0: accuracy = 0.841687
I0522 13:55:48.207286 31742 solver.cpp:409]     Test net output #1: loss = 0.550353 (* 1 = 0.550353 loss)
I0522 13:56:10.402571 31742 solver.cpp:237] Iteration 10000, loss = 1.14553
I0522 13:56:10.402624 31742 solver.cpp:253]     Train net output #0: loss = 1.14553 (* 1 = 1.14553 loss)
I0522 13:56:10.402639 31742 sgd_solver.cpp:106] Iteration 10000, lr = 0.004
I0522 13:56:20.940601 31742 solver.cpp:237] Iteration 10500, loss = 1.32222
I0522 13:56:20.940752 31742 solver.cpp:253]     Train net output #0: loss = 1.32222 (* 1 = 1.32222 loss)
I0522 13:56:20.940768 31742 sgd_solver.cpp:106] Iteration 10500, lr = 0.004
I0522 13:56:31.476244 31742 solver.cpp:237] Iteration 11000, loss = 1.18182
I0522 13:56:31.476280 31742 solver.cpp:253]     Train net output #0: loss = 1.18182 (* 1 = 1.18182 loss)
I0522 13:56:31.476296 31742 sgd_solver.cpp:106] Iteration 11000, lr = 0.004
I0522 13:56:42.037562 31742 solver.cpp:237] Iteration 11500, loss = 1.16857
I0522 13:56:42.037608 31742 solver.cpp:253]     Train net output #0: loss = 1.16857 (* 1 = 1.16857 loss)
I0522 13:56:42.037621 31742 sgd_solver.cpp:106] Iteration 11500, lr = 0.004
I0522 13:56:52.595788 31742 solver.cpp:237] Iteration 12000, loss = 1.22086
I0522 13:56:52.595939 31742 solver.cpp:253]     Train net output #0: loss = 1.22086 (* 1 = 1.22086 loss)
I0522 13:56:52.595953 31742 sgd_solver.cpp:106] Iteration 12000, lr = 0.004
I0522 13:57:03.149330 31742 solver.cpp:237] Iteration 12500, loss = 1.80255
I0522 13:57:03.149366 31742 solver.cpp:253]     Train net output #0: loss = 1.80255 (* 1 = 1.80255 loss)
I0522 13:57:03.149381 31742 sgd_solver.cpp:106] Iteration 12500, lr = 0.004
I0522 13:57:13.708981 31742 solver.cpp:237] Iteration 13000, loss = 1.46855
I0522 13:57:13.709022 31742 solver.cpp:253]     Train net output #0: loss = 1.46855 (* 1 = 1.46855 loss)
I0522 13:57:13.709035 31742 sgd_solver.cpp:106] Iteration 13000, lr = 0.004
I0522 13:57:46.468004 31742 solver.cpp:237] Iteration 13500, loss = 1.1597
I0522 13:57:46.468165 31742 solver.cpp:253]     Train net output #0: loss = 1.1597 (* 1 = 1.1597 loss)
I0522 13:57:46.468179 31742 sgd_solver.cpp:106] Iteration 13500, lr = 0.004
I0522 13:57:57.032258 31742 solver.cpp:237] Iteration 14000, loss = 1.16102
I0522 13:57:57.032300 31742 solver.cpp:253]     Train net output #0: loss = 1.16102 (* 1 = 1.16102 loss)
I0522 13:57:57.032317 31742 sgd_solver.cpp:106] Iteration 14000, lr = 0.004
I0522 13:58:07.578515 31742 solver.cpp:237] Iteration 14500, loss = 1.07564
I0522 13:58:07.578550 31742 solver.cpp:253]     Train net output #0: loss = 1.07564 (* 1 = 1.07564 loss)
I0522 13:58:07.578563 31742 sgd_solver.cpp:106] Iteration 14500, lr = 0.004
I0522 13:58:18.103060 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_15000.caffemodel
I0522 13:58:18.157582 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_15000.solverstate
I0522 13:58:18.191836 31742 solver.cpp:237] Iteration 15000, loss = 1.10942
I0522 13:58:18.191887 31742 solver.cpp:253]     Train net output #0: loss = 1.10942 (* 1 = 1.10942 loss)
I0522 13:58:18.191901 31742 sgd_solver.cpp:106] Iteration 15000, lr = 0.004
I0522 13:58:28.745059 31742 solver.cpp:237] Iteration 15500, loss = 0.899141
I0522 13:58:28.745106 31742 solver.cpp:253]     Train net output #0: loss = 0.899141 (* 1 = 0.899141 loss)
I0522 13:58:28.745121 31742 sgd_solver.cpp:106] Iteration 15500, lr = 0.004
I0522 13:58:39.297729 31742 solver.cpp:237] Iteration 16000, loss = 1.57831
I0522 13:58:39.297765 31742 solver.cpp:253]     Train net output #0: loss = 1.57831 (* 1 = 1.57831 loss)
I0522 13:58:39.297781 31742 sgd_solver.cpp:106] Iteration 16000, lr = 0.004
I0522 13:58:49.835798 31742 solver.cpp:237] Iteration 16500, loss = 1.05384
I0522 13:58:49.835955 31742 solver.cpp:253]     Train net output #0: loss = 1.05384 (* 1 = 1.05384 loss)
I0522 13:58:49.835970 31742 sgd_solver.cpp:106] Iteration 16500, lr = 0.004
I0522 13:59:22.615736 31742 solver.cpp:237] Iteration 17000, loss = 1.39014
I0522 13:59:22.615900 31742 solver.cpp:253]     Train net output #0: loss = 1.39014 (* 1 = 1.39014 loss)
I0522 13:59:22.615916 31742 sgd_solver.cpp:106] Iteration 17000, lr = 0.004
I0522 13:59:33.155066 31742 solver.cpp:237] Iteration 17500, loss = 1.22988
I0522 13:59:33.155102 31742 solver.cpp:253]     Train net output #0: loss = 1.22988 (* 1 = 1.22988 loss)
I0522 13:59:33.155117 31742 sgd_solver.cpp:106] Iteration 17500, lr = 0.004
I0522 13:59:43.713266 31742 solver.cpp:237] Iteration 18000, loss = 1.31985
I0522 13:59:43.713316 31742 solver.cpp:253]     Train net output #0: loss = 1.31985 (* 1 = 1.31985 loss)
I0522 13:59:43.713331 31742 sgd_solver.cpp:106] Iteration 18000, lr = 0.004
I0522 13:59:54.243202 31742 solver.cpp:237] Iteration 18500, loss = 1.00459
I0522 13:59:54.243345 31742 solver.cpp:253]     Train net output #0: loss = 1.00459 (* 1 = 1.00459 loss)
I0522 13:59:54.243358 31742 sgd_solver.cpp:106] Iteration 18500, lr = 0.004
I0522 14:00:04.794222 31742 solver.cpp:237] Iteration 19000, loss = 1.17653
I0522 14:00:04.794267 31742 solver.cpp:253]     Train net output #0: loss = 1.17653 (* 1 = 1.17653 loss)
I0522 14:00:04.794284 31742 sgd_solver.cpp:106] Iteration 19000, lr = 0.004
I0522 14:00:15.335898 31742 solver.cpp:237] Iteration 19500, loss = 1.38702
I0522 14:00:15.335934 31742 solver.cpp:253]     Train net output #0: loss = 1.38702 (* 1 = 1.38702 loss)
I0522 14:00:15.335949 31742 sgd_solver.cpp:106] Iteration 19500, lr = 0.004
I0522 14:00:25.864886 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_20000.caffemodel
I0522 14:00:25.919780 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_20000.solverstate
I0522 14:00:25.948071 31742 solver.cpp:341] Iteration 20000, Testing net (#0)
I0522 14:01:36.349978 31742 solver.cpp:409]     Test net output #0: accuracy = 0.854118
I0522 14:01:36.350136 31742 solver.cpp:409]     Test net output #1: loss = 0.528203 (* 1 = 0.528203 loss)
I0522 14:01:58.586590 31742 solver.cpp:237] Iteration 20000, loss = 1.11119
I0522 14:01:58.586644 31742 solver.cpp:253]     Train net output #0: loss = 1.11119 (* 1 = 1.11119 loss)
I0522 14:01:58.586658 31742 sgd_solver.cpp:106] Iteration 20000, lr = 0.004
I0522 14:02:09.155745 31742 solver.cpp:237] Iteration 20500, loss = 1.14876
I0522 14:02:09.155905 31742 solver.cpp:253]     Train net output #0: loss = 1.14876 (* 1 = 1.14876 loss)
I0522 14:02:09.155920 31742 sgd_solver.cpp:106] Iteration 20500, lr = 0.004
I0522 14:02:19.727962 31742 solver.cpp:237] Iteration 21000, loss = 1.2944
I0522 14:02:19.727999 31742 solver.cpp:253]     Train net output #0: loss = 1.2944 (* 1 = 1.2944 loss)
I0522 14:02:19.728015 31742 sgd_solver.cpp:106] Iteration 21000, lr = 0.004
I0522 14:02:30.284128 31742 solver.cpp:237] Iteration 21500, loss = 1.4222
I0522 14:02:30.284164 31742 solver.cpp:253]     Train net output #0: loss = 1.4222 (* 1 = 1.4222 loss)
I0522 14:02:30.284180 31742 sgd_solver.cpp:106] Iteration 21500, lr = 0.004
I0522 14:02:40.858242 31742 solver.cpp:237] Iteration 22000, loss = 1.38318
I0522 14:02:40.858392 31742 solver.cpp:253]     Train net output #0: loss = 1.38318 (* 1 = 1.38318 loss)
I0522 14:02:40.858407 31742 sgd_solver.cpp:106] Iteration 22000, lr = 0.004
I0522 14:02:51.430913 31742 solver.cpp:237] Iteration 22500, loss = 1.21656
I0522 14:02:51.430949 31742 solver.cpp:253]     Train net output #0: loss = 1.21656 (* 1 = 1.21656 loss)
I0522 14:02:51.430965 31742 sgd_solver.cpp:106] Iteration 22500, lr = 0.004
I0522 14:03:02.006701 31742 solver.cpp:237] Iteration 23000, loss = 1.46563
I0522 14:03:02.006747 31742 solver.cpp:253]     Train net output #0: loss = 1.46563 (* 1 = 1.46563 loss)
I0522 14:03:02.006763 31742 sgd_solver.cpp:106] Iteration 23000, lr = 0.004
I0522 14:03:34.845170 31742 solver.cpp:237] Iteration 23500, loss = 1.44079
I0522 14:03:34.845348 31742 solver.cpp:253]     Train net output #0: loss = 1.44079 (* 1 = 1.44079 loss)
I0522 14:03:34.845362 31742 sgd_solver.cpp:106] Iteration 23500, lr = 0.004
I0522 14:03:45.419383 31742 solver.cpp:237] Iteration 24000, loss = 1.45871
I0522 14:03:45.419419 31742 solver.cpp:253]     Train net output #0: loss = 1.45871 (* 1 = 1.45871 loss)
I0522 14:03:45.419438 31742 sgd_solver.cpp:106] Iteration 24000, lr = 0.004
I0522 14:03:55.996692 31742 solver.cpp:237] Iteration 24500, loss = 1.20066
I0522 14:03:55.996737 31742 solver.cpp:253]     Train net output #0: loss = 1.20066 (* 1 = 1.20066 loss)
I0522 14:03:55.996752 31742 sgd_solver.cpp:106] Iteration 24500, lr = 0.004
I0522 14:04:06.543931 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_25000.caffemodel
I0522 14:04:06.598623 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_25000.solverstate
I0522 14:04:06.633467 31742 solver.cpp:237] Iteration 25000, loss = 1.58857
I0522 14:04:06.633519 31742 solver.cpp:253]     Train net output #0: loss = 1.58857 (* 1 = 1.58857 loss)
I0522 14:04:06.633533 31742 sgd_solver.cpp:106] Iteration 25000, lr = 0.004
I0522 14:04:17.217381 31742 solver.cpp:237] Iteration 25500, loss = 1.37709
I0522 14:04:17.217428 31742 solver.cpp:253]     Train net output #0: loss = 1.37709 (* 1 = 1.37709 loss)
I0522 14:04:17.217443 31742 sgd_solver.cpp:106] Iteration 25500, lr = 0.004
I0522 14:04:27.778079 31742 solver.cpp:237] Iteration 26000, loss = 0.989483
I0522 14:04:27.778115 31742 solver.cpp:253]     Train net output #0: loss = 0.989484 (* 1 = 0.989484 loss)
I0522 14:04:27.778132 31742 sgd_solver.cpp:106] Iteration 26000, lr = 0.004
I0522 14:04:38.348250 31742 solver.cpp:237] Iteration 26500, loss = 1.33704
I0522 14:04:38.348410 31742 solver.cpp:253]     Train net output #0: loss = 1.33705 (* 1 = 1.33705 loss)
I0522 14:04:38.348425 31742 sgd_solver.cpp:106] Iteration 26500, lr = 0.004
I0522 14:05:11.162395 31742 solver.cpp:237] Iteration 27000, loss = 1.18678
I0522 14:05:11.162561 31742 solver.cpp:253]     Train net output #0: loss = 1.18678 (* 1 = 1.18678 loss)
I0522 14:05:11.162575 31742 sgd_solver.cpp:106] Iteration 27000, lr = 0.004
I0522 14:05:21.739449 31742 solver.cpp:237] Iteration 27500, loss = 1.01649
I0522 14:05:21.739485 31742 solver.cpp:253]     Train net output #0: loss = 1.01649 (* 1 = 1.01649 loss)
I0522 14:05:21.739501 31742 sgd_solver.cpp:106] Iteration 27500, lr = 0.004
I0522 14:05:32.304618 31742 solver.cpp:237] Iteration 28000, loss = 1.23157
I0522 14:05:32.304663 31742 solver.cpp:253]     Train net output #0: loss = 1.23157 (* 1 = 1.23157 loss)
I0522 14:05:32.304679 31742 sgd_solver.cpp:106] Iteration 28000, lr = 0.004
I0522 14:05:42.881584 31742 solver.cpp:237] Iteration 28500, loss = 1.19954
I0522 14:05:42.881738 31742 solver.cpp:253]     Train net output #0: loss = 1.19954 (* 1 = 1.19954 loss)
I0522 14:05:42.881752 31742 sgd_solver.cpp:106] Iteration 28500, lr = 0.004
I0522 14:05:53.448315 31742 solver.cpp:237] Iteration 29000, loss = 1.00659
I0522 14:05:53.448361 31742 solver.cpp:253]     Train net output #0: loss = 1.00659 (* 1 = 1.00659 loss)
I0522 14:05:53.448377 31742 sgd_solver.cpp:106] Iteration 29000, lr = 0.004
I0522 14:06:04.020838 31742 solver.cpp:237] Iteration 29500, loss = 0.854968
I0522 14:06:04.020875 31742 solver.cpp:253]     Train net output #0: loss = 0.854969 (* 1 = 0.854969 loss)
I0522 14:06:04.020891 31742 sgd_solver.cpp:106] Iteration 29500, lr = 0.004
I0522 14:06:14.573571 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_30000.caffemodel
I0522 14:06:14.626008 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_30000.solverstate
I0522 14:06:14.652091 31742 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 14:07:03.868927 31742 solver.cpp:409]     Test net output #0: accuracy = 0.870996
I0522 14:07:03.869087 31742 solver.cpp:409]     Test net output #1: loss = 0.454614 (* 1 = 0.454614 loss)
I0522 14:07:26.123340 31742 solver.cpp:237] Iteration 30000, loss = 1.15616
I0522 14:07:26.123395 31742 solver.cpp:253]     Train net output #0: loss = 1.15616 (* 1 = 1.15616 loss)
I0522 14:07:26.123409 31742 sgd_solver.cpp:106] Iteration 30000, lr = 0.004
I0522 14:07:36.671782 31742 solver.cpp:237] Iteration 30500, loss = 1.35603
I0522 14:07:36.671946 31742 solver.cpp:253]     Train net output #0: loss = 1.35603 (* 1 = 1.35603 loss)
I0522 14:07:36.671959 31742 sgd_solver.cpp:106] Iteration 30500, lr = 0.004
I0522 14:07:47.233786 31742 solver.cpp:237] Iteration 31000, loss = 1.36881
I0522 14:07:47.233822 31742 solver.cpp:253]     Train net output #0: loss = 1.36881 (* 1 = 1.36881 loss)
I0522 14:07:47.233835 31742 sgd_solver.cpp:106] Iteration 31000, lr = 0.004
I0522 14:07:57.785231 31742 solver.cpp:237] Iteration 31500, loss = 1.08235
I0522 14:07:57.785279 31742 solver.cpp:253]     Train net output #0: loss = 1.08236 (* 1 = 1.08236 loss)
I0522 14:07:57.785291 31742 sgd_solver.cpp:106] Iteration 31500, lr = 0.004
I0522 14:08:08.334981 31742 solver.cpp:237] Iteration 32000, loss = 0.954008
I0522 14:08:08.335125 31742 solver.cpp:253]     Train net output #0: loss = 0.954009 (* 1 = 0.954009 loss)
I0522 14:08:08.335139 31742 sgd_solver.cpp:106] Iteration 32000, lr = 0.004
I0522 14:08:18.870887 31742 solver.cpp:237] Iteration 32500, loss = 1.10394
I0522 14:08:18.870923 31742 solver.cpp:253]     Train net output #0: loss = 1.10394 (* 1 = 1.10394 loss)
I0522 14:08:18.870936 31742 sgd_solver.cpp:106] Iteration 32500, lr = 0.004
I0522 14:08:29.435627 31742 solver.cpp:237] Iteration 33000, loss = 0.787649
I0522 14:08:29.435678 31742 solver.cpp:253]     Train net output #0: loss = 0.78765 (* 1 = 0.78765 loss)
I0522 14:08:29.435691 31742 sgd_solver.cpp:106] Iteration 33000, lr = 0.004
I0522 14:09:02.254103 31742 solver.cpp:237] Iteration 33500, loss = 1.26801
I0522 14:09:02.254281 31742 solver.cpp:253]     Train net output #0: loss = 1.26801 (* 1 = 1.26801 loss)
I0522 14:09:02.254297 31742 sgd_solver.cpp:106] Iteration 33500, lr = 0.004
I0522 14:09:12.819236 31742 solver.cpp:237] Iteration 34000, loss = 1.02412
I0522 14:09:12.819283 31742 solver.cpp:253]     Train net output #0: loss = 1.02412 (* 1 = 1.02412 loss)
I0522 14:09:12.819299 31742 sgd_solver.cpp:106] Iteration 34000, lr = 0.004
I0522 14:09:23.366118 31742 solver.cpp:237] Iteration 34500, loss = 1.12946
I0522 14:09:23.366154 31742 solver.cpp:253]     Train net output #0: loss = 1.12946 (* 1 = 1.12946 loss)
I0522 14:09:23.366171 31742 sgd_solver.cpp:106] Iteration 34500, lr = 0.004
I0522 14:09:33.894553 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_35000.caffemodel
I0522 14:09:33.948484 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_35000.solverstate
I0522 14:09:33.981921 31742 solver.cpp:237] Iteration 35000, loss = 1.03064
I0522 14:09:33.981969 31742 solver.cpp:253]     Train net output #0: loss = 1.03064 (* 1 = 1.03064 loss)
I0522 14:09:33.981984 31742 sgd_solver.cpp:106] Iteration 35000, lr = 0.004
I0522 14:09:44.539450 31742 solver.cpp:237] Iteration 35500, loss = 1.01874
I0522 14:09:44.539495 31742 solver.cpp:253]     Train net output #0: loss = 1.01874 (* 1 = 1.01874 loss)
I0522 14:09:44.539510 31742 sgd_solver.cpp:106] Iteration 35500, lr = 0.004
I0522 14:09:55.098793 31742 solver.cpp:237] Iteration 36000, loss = 1.11534
I0522 14:09:55.098829 31742 solver.cpp:253]     Train net output #0: loss = 1.11534 (* 1 = 1.11534 loss)
I0522 14:09:55.098845 31742 sgd_solver.cpp:106] Iteration 36000, lr = 0.004
I0522 14:10:05.659060 31742 solver.cpp:237] Iteration 36500, loss = 1.03206
I0522 14:10:05.659216 31742 solver.cpp:253]     Train net output #0: loss = 1.03206 (* 1 = 1.03206 loss)
I0522 14:10:05.659230 31742 sgd_solver.cpp:106] Iteration 36500, lr = 0.004
I0522 14:10:38.424731 31742 solver.cpp:237] Iteration 37000, loss = 1.35054
I0522 14:10:38.424891 31742 solver.cpp:253]     Train net output #0: loss = 1.35054 (* 1 = 1.35054 loss)
I0522 14:10:38.424906 31742 sgd_solver.cpp:106] Iteration 37000, lr = 0.004
I0522 14:10:48.964292 31742 solver.cpp:237] Iteration 37500, loss = 1.28294
I0522 14:10:48.964328 31742 solver.cpp:253]     Train net output #0: loss = 1.28295 (* 1 = 1.28295 loss)
I0522 14:10:48.964340 31742 sgd_solver.cpp:106] Iteration 37500, lr = 0.004
I0522 14:10:59.521589 31742 solver.cpp:237] Iteration 38000, loss = 1.15064
I0522 14:10:59.521631 31742 solver.cpp:253]     Train net output #0: loss = 1.15064 (* 1 = 1.15064 loss)
I0522 14:10:59.521647 31742 sgd_solver.cpp:106] Iteration 38000, lr = 0.004
I0522 14:11:10.080287 31742 solver.cpp:237] Iteration 38500, loss = 1.3174
I0522 14:11:10.080427 31742 solver.cpp:253]     Train net output #0: loss = 1.3174 (* 1 = 1.3174 loss)
I0522 14:11:10.080441 31742 sgd_solver.cpp:106] Iteration 38500, lr = 0.004
I0522 14:11:20.638717 31742 solver.cpp:237] Iteration 39000, loss = 1.16612
I0522 14:11:20.638761 31742 solver.cpp:253]     Train net output #0: loss = 1.16612 (* 1 = 1.16612 loss)
I0522 14:11:20.638774 31742 sgd_solver.cpp:106] Iteration 39000, lr = 0.004
I0522 14:11:31.200348 31742 solver.cpp:237] Iteration 39500, loss = 1.31088
I0522 14:11:31.200383 31742 solver.cpp:253]     Train net output #0: loss = 1.31088 (* 1 = 1.31088 loss)
I0522 14:11:31.200400 31742 sgd_solver.cpp:106] Iteration 39500, lr = 0.004
I0522 14:11:41.720734 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_40000.caffemodel
I0522 14:11:41.773526 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_40000.solverstate
I0522 14:11:41.799813 31742 solver.cpp:341] Iteration 40000, Testing net (#0)
I0522 14:12:52.223994 31742 solver.cpp:409]     Test net output #0: accuracy = 0.873004
I0522 14:12:52.224164 31742 solver.cpp:409]     Test net output #1: loss = 0.403372 (* 1 = 0.403372 loss)
I0522 14:13:14.472690 31742 solver.cpp:237] Iteration 40000, loss = 1.63327
I0522 14:13:14.472743 31742 solver.cpp:253]     Train net output #0: loss = 1.63327 (* 1 = 1.63327 loss)
I0522 14:13:14.472757 31742 sgd_solver.cpp:106] Iteration 40000, lr = 0.004
I0522 14:13:25.088383 31742 solver.cpp:237] Iteration 40500, loss = 1.02895
I0522 14:13:25.088543 31742 solver.cpp:253]     Train net output #0: loss = 1.02895 (* 1 = 1.02895 loss)
I0522 14:13:25.088558 31742 sgd_solver.cpp:106] Iteration 40500, lr = 0.004
I0522 14:13:35.701726 31742 solver.cpp:237] Iteration 41000, loss = 1.17858
I0522 14:13:35.701761 31742 solver.cpp:253]     Train net output #0: loss = 1.17858 (* 1 = 1.17858 loss)
I0522 14:13:35.701778 31742 sgd_solver.cpp:106] Iteration 41000, lr = 0.004
I0522 14:13:46.317209 31742 solver.cpp:237] Iteration 41500, loss = 1.41591
I0522 14:13:46.317253 31742 solver.cpp:253]     Train net output #0: loss = 1.41592 (* 1 = 1.41592 loss)
I0522 14:13:46.317267 31742 sgd_solver.cpp:106] Iteration 41500, lr = 0.004
I0522 14:13:56.939227 31742 solver.cpp:237] Iteration 42000, loss = 1.5681
I0522 14:13:56.939373 31742 solver.cpp:253]     Train net output #0: loss = 1.5681 (* 1 = 1.5681 loss)
I0522 14:13:56.939388 31742 sgd_solver.cpp:106] Iteration 42000, lr = 0.004
I0522 14:14:07.563473 31742 solver.cpp:237] Iteration 42500, loss = 1.09215
I0522 14:14:07.563509 31742 solver.cpp:253]     Train net output #0: loss = 1.09215 (* 1 = 1.09215 loss)
I0522 14:14:07.563525 31742 sgd_solver.cpp:106] Iteration 42500, lr = 0.004
I0522 14:14:18.199515 31742 solver.cpp:237] Iteration 43000, loss = 1.22155
I0522 14:14:18.199558 31742 solver.cpp:253]     Train net output #0: loss = 1.22156 (* 1 = 1.22156 loss)
I0522 14:14:18.199575 31742 sgd_solver.cpp:106] Iteration 43000, lr = 0.004
I0522 14:14:51.037078 31742 solver.cpp:237] Iteration 43500, loss = 1.14702
I0522 14:14:51.037247 31742 solver.cpp:253]     Train net output #0: loss = 1.14702 (* 1 = 1.14702 loss)
I0522 14:14:51.037262 31742 sgd_solver.cpp:106] Iteration 43500, lr = 0.004
I0522 14:15:01.645481 31742 solver.cpp:237] Iteration 44000, loss = 1.27706
I0522 14:15:01.645529 31742 solver.cpp:253]     Train net output #0: loss = 1.27706 (* 1 = 1.27706 loss)
I0522 14:15:01.645545 31742 sgd_solver.cpp:106] Iteration 44000, lr = 0.004
I0522 14:15:12.273099 31742 solver.cpp:237] Iteration 44500, loss = 1.53901
I0522 14:15:12.273134 31742 solver.cpp:253]     Train net output #0: loss = 1.53901 (* 1 = 1.53901 loss)
I0522 14:15:12.273149 31742 sgd_solver.cpp:106] Iteration 44500, lr = 0.004
I0522 14:15:22.871665 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_45000.caffemodel
I0522 14:15:22.927810 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_45000.solverstate
I0522 14:15:22.962927 31742 solver.cpp:237] Iteration 45000, loss = 1.56799
I0522 14:15:22.962977 31742 solver.cpp:253]     Train net output #0: loss = 1.56799 (* 1 = 1.56799 loss)
I0522 14:15:22.962991 31742 sgd_solver.cpp:106] Iteration 45000, lr = 0.004
I0522 14:15:33.586042 31742 solver.cpp:237] Iteration 45500, loss = 1.26191
I0522 14:15:33.586091 31742 solver.cpp:253]     Train net output #0: loss = 1.26191 (* 1 = 1.26191 loss)
I0522 14:15:33.586104 31742 sgd_solver.cpp:106] Iteration 45500, lr = 0.004
I0522 14:15:44.223027 31742 solver.cpp:237] Iteration 46000, loss = 1.51634
I0522 14:15:44.223062 31742 solver.cpp:253]     Train net output #0: loss = 1.51634 (* 1 = 1.51634 loss)
I0522 14:15:44.223078 31742 sgd_solver.cpp:106] Iteration 46000, lr = 0.004
I0522 14:15:54.852982 31742 solver.cpp:237] Iteration 46500, loss = 1.44232
I0522 14:15:54.853152 31742 solver.cpp:253]     Train net output #0: loss = 1.44232 (* 1 = 1.44232 loss)
I0522 14:15:54.853169 31742 sgd_solver.cpp:106] Iteration 46500, lr = 0.004
I0522 14:16:27.747659 31742 solver.cpp:237] Iteration 47000, loss = 0.992128
I0522 14:16:27.747833 31742 solver.cpp:253]     Train net output #0: loss = 0.992129 (* 1 = 0.992129 loss)
I0522 14:16:27.747848 31742 sgd_solver.cpp:106] Iteration 47000, lr = 0.004
I0522 14:16:38.363900 31742 solver.cpp:237] Iteration 47500, loss = 1.28854
I0522 14:16:38.363935 31742 solver.cpp:253]     Train net output #0: loss = 1.28854 (* 1 = 1.28854 loss)
I0522 14:16:38.363952 31742 sgd_solver.cpp:106] Iteration 47500, lr = 0.004
I0522 14:16:48.995354 31742 solver.cpp:237] Iteration 48000, loss = 1.39051
I0522 14:16:48.995399 31742 solver.cpp:253]     Train net output #0: loss = 1.39051 (* 1 = 1.39051 loss)
I0522 14:16:48.995412 31742 sgd_solver.cpp:106] Iteration 48000, lr = 0.004
I0522 14:16:59.614007 31742 solver.cpp:237] Iteration 48500, loss = 0.944609
I0522 14:16:59.614154 31742 solver.cpp:253]     Train net output #0: loss = 0.94461 (* 1 = 0.94461 loss)
I0522 14:16:59.614169 31742 sgd_solver.cpp:106] Iteration 48500, lr = 0.004
I0522 14:17:10.221685 31742 solver.cpp:237] Iteration 49000, loss = 1.33241
I0522 14:17:10.221734 31742 solver.cpp:253]     Train net output #0: loss = 1.33242 (* 1 = 1.33242 loss)
I0522 14:17:10.221748 31742 sgd_solver.cpp:106] Iteration 49000, lr = 0.004
I0522 14:17:20.841930 31742 solver.cpp:237] Iteration 49500, loss = 1.5613
I0522 14:17:20.841966 31742 solver.cpp:253]     Train net output #0: loss = 1.5613 (* 1 = 1.5613 loss)
I0522 14:17:20.841982 31742 sgd_solver.cpp:106] Iteration 49500, lr = 0.004
I0522 14:17:31.426461 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_50000.caffemodel
I0522 14:17:31.481305 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_50000.solverstate
I0522 14:17:31.509824 31742 solver.cpp:341] Iteration 50000, Testing net (#0)
I0522 14:18:21.085552 31742 solver.cpp:409]     Test net output #0: accuracy = 0.881267
I0522 14:18:21.085716 31742 solver.cpp:409]     Test net output #1: loss = 0.396911 (* 1 = 0.396911 loss)
I0522 14:18:41.948424 31742 solver.cpp:237] Iteration 50000, loss = 1.028
I0522 14:18:41.948477 31742 solver.cpp:253]     Train net output #0: loss = 1.028 (* 1 = 1.028 loss)
I0522 14:18:41.948493 31742 sgd_solver.cpp:106] Iteration 50000, lr = 0.004
I0522 14:18:52.450767 31742 solver.cpp:237] Iteration 50500, loss = 1.10531
I0522 14:18:52.450935 31742 solver.cpp:253]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0522 14:18:52.450950 31742 sgd_solver.cpp:106] Iteration 50500, lr = 0.004
I0522 14:19:02.950583 31742 solver.cpp:237] Iteration 51000, loss = 1.36394
I0522 14:19:02.950618 31742 solver.cpp:253]     Train net output #0: loss = 1.36394 (* 1 = 1.36394 loss)
I0522 14:19:02.950635 31742 sgd_solver.cpp:106] Iteration 51000, lr = 0.004
I0522 14:19:13.471298 31742 solver.cpp:237] Iteration 51500, loss = 1.34972
I0522 14:19:13.471344 31742 solver.cpp:253]     Train net output #0: loss = 1.34972 (* 1 = 1.34972 loss)
I0522 14:19:13.471359 31742 sgd_solver.cpp:106] Iteration 51500, lr = 0.004
I0522 14:19:23.984720 31742 solver.cpp:237] Iteration 52000, loss = 1.19878
I0522 14:19:23.984866 31742 solver.cpp:253]     Train net output #0: loss = 1.19878 (* 1 = 1.19878 loss)
I0522 14:19:23.984880 31742 sgd_solver.cpp:106] Iteration 52000, lr = 0.004
I0522 14:19:34.488168 31742 solver.cpp:237] Iteration 52500, loss = 1.16093
I0522 14:19:34.488204 31742 solver.cpp:253]     Train net output #0: loss = 1.16093 (* 1 = 1.16093 loss)
I0522 14:19:34.488219 31742 sgd_solver.cpp:106] Iteration 52500, lr = 0.004
I0522 14:19:44.982667 31742 solver.cpp:237] Iteration 53000, loss = 1.5256
I0522 14:19:44.982710 31742 solver.cpp:253]     Train net output #0: loss = 1.5256 (* 1 = 1.5256 loss)
I0522 14:19:44.982727 31742 sgd_solver.cpp:106] Iteration 53000, lr = 0.004
I0522 14:20:16.353279 31742 solver.cpp:237] Iteration 53500, loss = 1.07121
I0522 14:20:16.353456 31742 solver.cpp:253]     Train net output #0: loss = 1.07121 (* 1 = 1.07121 loss)
I0522 14:20:16.353472 31742 sgd_solver.cpp:106] Iteration 53500, lr = 0.004
I0522 14:20:26.868265 31742 solver.cpp:237] Iteration 54000, loss = 1.10475
I0522 14:20:26.868315 31742 solver.cpp:253]     Train net output #0: loss = 1.10476 (* 1 = 1.10476 loss)
I0522 14:20:26.868330 31742 sgd_solver.cpp:106] Iteration 54000, lr = 0.004
I0522 14:20:37.381521 31742 solver.cpp:237] Iteration 54500, loss = 1.32122
I0522 14:20:37.381558 31742 solver.cpp:253]     Train net output #0: loss = 1.32122 (* 1 = 1.32122 loss)
I0522 14:20:37.381572 31742 sgd_solver.cpp:106] Iteration 54500, lr = 0.004
I0522 14:20:47.861436 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_55000.caffemodel
I0522 14:20:47.913501 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_55000.solverstate
I0522 14:20:47.946879 31742 solver.cpp:237] Iteration 55000, loss = 0.91587
I0522 14:20:47.946923 31742 solver.cpp:253]     Train net output #0: loss = 0.915872 (* 1 = 0.915872 loss)
I0522 14:20:47.946939 31742 sgd_solver.cpp:106] Iteration 55000, lr = 0.004
I0522 14:20:58.468277 31742 solver.cpp:237] Iteration 55500, loss = 1.35565
I0522 14:20:58.468327 31742 solver.cpp:253]     Train net output #0: loss = 1.35565 (* 1 = 1.35565 loss)
I0522 14:20:58.468341 31742 sgd_solver.cpp:106] Iteration 55500, lr = 0.004
I0522 14:21:08.976563 31742 solver.cpp:237] Iteration 56000, loss = 1.21812
I0522 14:21:08.976599 31742 solver.cpp:253]     Train net output #0: loss = 1.21812 (* 1 = 1.21812 loss)
I0522 14:21:08.976613 31742 sgd_solver.cpp:106] Iteration 56000, lr = 0.004
I0522 14:21:19.483096 31742 solver.cpp:237] Iteration 56500, loss = 1.10781
I0522 14:21:19.483260 31742 solver.cpp:253]     Train net output #0: loss = 1.10781 (* 1 = 1.10781 loss)
I0522 14:21:19.483276 31742 sgd_solver.cpp:106] Iteration 56500, lr = 0.004
I0522 14:21:50.860208 31742 solver.cpp:237] Iteration 57000, loss = 1.18769
I0522 14:21:50.860371 31742 solver.cpp:253]     Train net output #0: loss = 1.18769 (* 1 = 1.18769 loss)
I0522 14:21:50.860388 31742 sgd_solver.cpp:106] Iteration 57000, lr = 0.004
I0522 14:22:01.389057 31742 solver.cpp:237] Iteration 57500, loss = 1.25565
I0522 14:22:01.389092 31742 solver.cpp:253]     Train net output #0: loss = 1.25565 (* 1 = 1.25565 loss)
I0522 14:22:01.389108 31742 sgd_solver.cpp:106] Iteration 57500, lr = 0.004
I0522 14:22:11.913208 31742 solver.cpp:237] Iteration 58000, loss = 1.28662
I0522 14:22:11.913256 31742 solver.cpp:253]     Train net output #0: loss = 1.28663 (* 1 = 1.28663 loss)
I0522 14:22:11.913271 31742 sgd_solver.cpp:106] Iteration 58000, lr = 0.004
I0522 14:22:22.426836 31742 solver.cpp:237] Iteration 58500, loss = 1.18423
I0522 14:22:22.426983 31742 solver.cpp:253]     Train net output #0: loss = 1.18423 (* 1 = 1.18423 loss)
I0522 14:22:22.426996 31742 sgd_solver.cpp:106] Iteration 58500, lr = 0.004
I0522 14:22:32.960891 31742 solver.cpp:237] Iteration 59000, loss = 0.971062
I0522 14:22:32.960940 31742 solver.cpp:253]     Train net output #0: loss = 0.971063 (* 1 = 0.971063 loss)
I0522 14:22:32.960954 31742 sgd_solver.cpp:106] Iteration 59000, lr = 0.004
I0522 14:22:43.491014 31742 solver.cpp:237] Iteration 59500, loss = 1.03187
I0522 14:22:43.491050 31742 solver.cpp:253]     Train net output #0: loss = 1.03187 (* 1 = 1.03187 loss)
I0522 14:22:43.491065 31742 sgd_solver.cpp:106] Iteration 59500, lr = 0.004
I0522 14:22:53.995921 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_60000.caffemodel
I0522 14:22:54.048568 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_60000.solverstate
I0522 14:22:54.074844 31742 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 14:24:04.468997 31742 solver.cpp:409]     Test net output #0: accuracy = 0.883381
I0522 14:24:04.469163 31742 solver.cpp:409]     Test net output #1: loss = 0.368851 (* 1 = 0.368851 loss)
I0522 14:24:25.345294 31742 solver.cpp:237] Iteration 60000, loss = 0.780572
I0522 14:24:25.345350 31742 solver.cpp:253]     Train net output #0: loss = 0.780573 (* 1 = 0.780573 loss)
I0522 14:24:25.345365 31742 sgd_solver.cpp:106] Iteration 60000, lr = 0.004
I0522 14:24:35.922511 31742 solver.cpp:237] Iteration 60500, loss = 1.27676
I0522 14:24:35.922668 31742 solver.cpp:253]     Train net output #0: loss = 1.27676 (* 1 = 1.27676 loss)
I0522 14:24:35.922683 31742 sgd_solver.cpp:106] Iteration 60500, lr = 0.004
I0522 14:24:46.553937 31742 solver.cpp:237] Iteration 61000, loss = 1.10427
I0522 14:24:46.553973 31742 solver.cpp:253]     Train net output #0: loss = 1.10427 (* 1 = 1.10427 loss)
I0522 14:24:46.553989 31742 sgd_solver.cpp:106] Iteration 61000, lr = 0.004
I0522 14:24:57.194571 31742 solver.cpp:237] Iteration 61500, loss = 1.27694
I0522 14:24:57.194607 31742 solver.cpp:253]     Train net output #0: loss = 1.27695 (* 1 = 1.27695 loss)
I0522 14:24:57.194619 31742 sgd_solver.cpp:106] Iteration 61500, lr = 0.004
I0522 14:25:07.810665 31742 solver.cpp:237] Iteration 62000, loss = 1.06964
I0522 14:25:07.810827 31742 solver.cpp:253]     Train net output #0: loss = 1.06964 (* 1 = 1.06964 loss)
I0522 14:25:07.810840 31742 sgd_solver.cpp:106] Iteration 62000, lr = 0.004
I0522 14:25:18.446476 31742 solver.cpp:237] Iteration 62500, loss = 1.47473
I0522 14:25:18.446511 31742 solver.cpp:253]     Train net output #0: loss = 1.47474 (* 1 = 1.47474 loss)
I0522 14:25:18.446527 31742 sgd_solver.cpp:106] Iteration 62500, lr = 0.004
I0522 14:25:29.086386 31742 solver.cpp:237] Iteration 63000, loss = 1.1426
I0522 14:25:29.086434 31742 solver.cpp:253]     Train net output #0: loss = 1.14261 (* 1 = 1.14261 loss)
I0522 14:25:29.086448 31742 sgd_solver.cpp:106] Iteration 63000, lr = 0.004
I0522 14:26:00.571082 31742 solver.cpp:237] Iteration 63500, loss = 1.32458
I0522 14:26:00.571252 31742 solver.cpp:253]     Train net output #0: loss = 1.32458 (* 1 = 1.32458 loss)
I0522 14:26:00.571267 31742 sgd_solver.cpp:106] Iteration 63500, lr = 0.004
I0522 14:26:11.220855 31742 solver.cpp:237] Iteration 64000, loss = 1.09127
I0522 14:26:11.220890 31742 solver.cpp:253]     Train net output #0: loss = 1.09127 (* 1 = 1.09127 loss)
I0522 14:26:11.220906 31742 sgd_solver.cpp:106] Iteration 64000, lr = 0.004
I0522 14:26:21.863384 31742 solver.cpp:237] Iteration 64500, loss = 1.11799
I0522 14:26:21.863435 31742 solver.cpp:253]     Train net output #0: loss = 1.11799 (* 1 = 1.11799 loss)
I0522 14:26:21.863450 31742 sgd_solver.cpp:106] Iteration 64500, lr = 0.004
I0522 14:26:32.480695 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_65000.caffemodel
I0522 14:26:32.533202 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_65000.solverstate
I0522 14:26:32.566045 31742 solver.cpp:237] Iteration 65000, loss = 0.999517
I0522 14:26:32.566092 31742 solver.cpp:253]     Train net output #0: loss = 0.999519 (* 1 = 0.999519 loss)
I0522 14:26:32.566107 31742 sgd_solver.cpp:106] Iteration 65000, lr = 0.004
I0522 14:26:43.197998 31742 solver.cpp:237] Iteration 65500, loss = 1.13981
I0522 14:26:43.198046 31742 solver.cpp:253]     Train net output #0: loss = 1.13981 (* 1 = 1.13981 loss)
I0522 14:26:43.198062 31742 sgd_solver.cpp:106] Iteration 65500, lr = 0.004
I0522 14:26:53.831158 31742 solver.cpp:237] Iteration 66000, loss = 1.132
I0522 14:26:53.831193 31742 solver.cpp:253]     Train net output #0: loss = 1.132 (* 1 = 1.132 loss)
I0522 14:26:53.831210 31742 sgd_solver.cpp:106] Iteration 66000, lr = 0.004
I0522 14:27:04.475430 31742 solver.cpp:237] Iteration 66500, loss = 1.22371
I0522 14:27:04.475595 31742 solver.cpp:253]     Train net output #0: loss = 1.22371 (* 1 = 1.22371 loss)
I0522 14:27:04.475611 31742 sgd_solver.cpp:106] Iteration 66500, lr = 0.004
I0522 14:27:36.008177 31742 solver.cpp:237] Iteration 67000, loss = 1.14329
I0522 14:27:36.008352 31742 solver.cpp:253]     Train net output #0: loss = 1.14329 (* 1 = 1.14329 loss)
I0522 14:27:36.008366 31742 sgd_solver.cpp:106] Iteration 67000, lr = 0.004
I0522 14:27:46.653486 31742 solver.cpp:237] Iteration 67500, loss = 1.2403
I0522 14:27:46.653522 31742 solver.cpp:253]     Train net output #0: loss = 1.2403 (* 1 = 1.2403 loss)
I0522 14:27:46.653539 31742 sgd_solver.cpp:106] Iteration 67500, lr = 0.004
I0522 14:27:57.292675 31742 solver.cpp:237] Iteration 68000, loss = 1.28642
I0522 14:27:57.292726 31742 solver.cpp:253]     Train net output #0: loss = 1.28643 (* 1 = 1.28643 loss)
I0522 14:27:57.292739 31742 sgd_solver.cpp:106] Iteration 68000, lr = 0.004
I0522 14:28:07.886715 31742 solver.cpp:237] Iteration 68500, loss = 1.0583
I0522 14:28:07.886878 31742 solver.cpp:253]     Train net output #0: loss = 1.0583 (* 1 = 1.0583 loss)
I0522 14:28:07.886893 31742 sgd_solver.cpp:106] Iteration 68500, lr = 0.004
I0522 14:28:18.448338 31742 solver.cpp:237] Iteration 69000, loss = 1.31467
I0522 14:28:18.448374 31742 solver.cpp:253]     Train net output #0: loss = 1.31467 (* 1 = 1.31467 loss)
I0522 14:28:18.448390 31742 sgd_solver.cpp:106] Iteration 69000, lr = 0.004
I0522 14:28:29.026026 31742 solver.cpp:237] Iteration 69500, loss = 0.838675
I0522 14:28:29.026075 31742 solver.cpp:253]     Train net output #0: loss = 0.838677 (* 1 = 0.838677 loss)
I0522 14:28:29.026089 31742 sgd_solver.cpp:106] Iteration 69500, lr = 0.004
I0522 14:28:39.584550 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_70000.caffemodel
I0522 14:28:39.637100 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_70000.solverstate
I0522 14:28:39.663506 31742 solver.cpp:341] Iteration 70000, Testing net (#0)
I0522 14:29:28.922160 31742 solver.cpp:409]     Test net output #0: accuracy = 0.881861
I0522 14:29:28.922329 31742 solver.cpp:409]     Test net output #1: loss = 0.404946 (* 1 = 0.404946 loss)
I0522 14:29:49.794445 31742 solver.cpp:237] Iteration 70000, loss = 0.96074
I0522 14:29:49.794499 31742 solver.cpp:253]     Train net output #0: loss = 0.960742 (* 1 = 0.960742 loss)
I0522 14:29:49.794514 31742 sgd_solver.cpp:106] Iteration 70000, lr = 0.004
I0522 14:30:00.301345 31742 solver.cpp:237] Iteration 70500, loss = 0.848795
I0522 14:30:00.301498 31742 solver.cpp:253]     Train net output #0: loss = 0.848797 (* 1 = 0.848797 loss)
I0522 14:30:00.301514 31742 sgd_solver.cpp:106] Iteration 70500, lr = 0.004
I0522 14:30:10.793340 31742 solver.cpp:237] Iteration 71000, loss = 1.16195
I0522 14:30:10.793385 31742 solver.cpp:253]     Train net output #0: loss = 1.16195 (* 1 = 1.16195 loss)
I0522 14:30:10.793400 31742 sgd_solver.cpp:106] Iteration 71000, lr = 0.004
I0522 14:30:21.292948 31742 solver.cpp:237] Iteration 71500, loss = 1.19959
I0522 14:30:21.292984 31742 solver.cpp:253]     Train net output #0: loss = 1.1996 (* 1 = 1.1996 loss)
I0522 14:30:21.292997 31742 sgd_solver.cpp:106] Iteration 71500, lr = 0.004
I0522 14:30:31.798523 31742 solver.cpp:237] Iteration 72000, loss = 0.974987
I0522 14:30:31.798696 31742 solver.cpp:253]     Train net output #0: loss = 0.974989 (* 1 = 0.974989 loss)
I0522 14:30:31.798712 31742 sgd_solver.cpp:106] Iteration 72000, lr = 0.004
I0522 14:30:42.285293 31742 solver.cpp:237] Iteration 72500, loss = 1.23847
I0522 14:30:42.285328 31742 solver.cpp:253]     Train net output #0: loss = 1.23848 (* 1 = 1.23848 loss)
I0522 14:30:42.285344 31742 sgd_solver.cpp:106] Iteration 72500, lr = 0.004
I0522 14:30:52.786713 31742 solver.cpp:237] Iteration 73000, loss = 1.17389
I0522 14:30:52.786763 31742 solver.cpp:253]     Train net output #0: loss = 1.1739 (* 1 = 1.1739 loss)
I0522 14:30:52.786777 31742 sgd_solver.cpp:106] Iteration 73000, lr = 0.004
I0522 14:31:24.183183 31742 solver.cpp:237] Iteration 73500, loss = 1.28319
I0522 14:31:24.183356 31742 solver.cpp:253]     Train net output #0: loss = 1.28319 (* 1 = 1.28319 loss)
I0522 14:31:24.183370 31742 sgd_solver.cpp:106] Iteration 73500, lr = 0.004
I0522 14:31:34.682778 31742 solver.cpp:237] Iteration 74000, loss = 1.01164
I0522 14:31:34.682814 31742 solver.cpp:253]     Train net output #0: loss = 1.01164 (* 1 = 1.01164 loss)
I0522 14:31:34.682831 31742 sgd_solver.cpp:106] Iteration 74000, lr = 0.004
I0522 14:31:45.185834 31742 solver.cpp:237] Iteration 74500, loss = 0.790838
I0522 14:31:45.185884 31742 solver.cpp:253]     Train net output #0: loss = 0.790841 (* 1 = 0.790841 loss)
I0522 14:31:45.185897 31742 sgd_solver.cpp:106] Iteration 74500, lr = 0.004
I0522 14:31:55.671221 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_75000.caffemodel
I0522 14:31:55.726308 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_75000.solverstate
I0522 14:31:55.761603 31742 solver.cpp:237] Iteration 75000, loss = 1.40239
I0522 14:31:55.761653 31742 solver.cpp:253]     Train net output #0: loss = 1.40239 (* 1 = 1.40239 loss)
I0522 14:31:55.761669 31742 sgd_solver.cpp:106] Iteration 75000, lr = 0.004
I0522 14:32:06.267879 31742 solver.cpp:237] Iteration 75500, loss = 1.11554
I0522 14:32:06.267935 31742 solver.cpp:253]     Train net output #0: loss = 1.11554 (* 1 = 1.11554 loss)
I0522 14:32:06.267948 31742 sgd_solver.cpp:106] Iteration 75500, lr = 0.004
I0522 14:32:16.772112 31742 solver.cpp:237] Iteration 76000, loss = 1.29456
I0522 14:32:16.772147 31742 solver.cpp:253]     Train net output #0: loss = 1.29456 (* 1 = 1.29456 loss)
I0522 14:32:16.772167 31742 sgd_solver.cpp:106] Iteration 76000, lr = 0.004
I0522 14:32:27.291693 31742 solver.cpp:237] Iteration 76500, loss = 1.19705
I0522 14:32:27.291860 31742 solver.cpp:253]     Train net output #0: loss = 1.19705 (* 1 = 1.19705 loss)
I0522 14:32:27.291874 31742 sgd_solver.cpp:106] Iteration 76500, lr = 0.004
I0522 14:32:58.685282 31742 solver.cpp:237] Iteration 77000, loss = 0.954304
I0522 14:32:58.685456 31742 solver.cpp:253]     Train net output #0: loss = 0.954306 (* 1 = 0.954306 loss)
I0522 14:32:58.685470 31742 sgd_solver.cpp:106] Iteration 77000, lr = 0.004
I0522 14:33:09.184017 31742 solver.cpp:237] Iteration 77500, loss = 0.97614
I0522 14:33:09.184053 31742 solver.cpp:253]     Train net output #0: loss = 0.976142 (* 1 = 0.976142 loss)
I0522 14:33:09.184070 31742 sgd_solver.cpp:106] Iteration 77500, lr = 0.004
I0522 14:33:19.689936 31742 solver.cpp:237] Iteration 78000, loss = 1.63073
I0522 14:33:19.689971 31742 solver.cpp:253]     Train net output #0: loss = 1.63073 (* 1 = 1.63073 loss)
I0522 14:33:19.689988 31742 sgd_solver.cpp:106] Iteration 78000, lr = 0.004
I0522 14:33:30.186266 31742 solver.cpp:237] Iteration 78500, loss = 1.20373
I0522 14:33:30.186419 31742 solver.cpp:253]     Train net output #0: loss = 1.20374 (* 1 = 1.20374 loss)
I0522 14:33:30.186432 31742 sgd_solver.cpp:106] Iteration 78500, lr = 0.004
I0522 14:33:40.693042 31742 solver.cpp:237] Iteration 79000, loss = 1.11924
I0522 14:33:40.693076 31742 solver.cpp:253]     Train net output #0: loss = 1.11924 (* 1 = 1.11924 loss)
I0522 14:33:40.693094 31742 sgd_solver.cpp:106] Iteration 79000, lr = 0.004
I0522 14:33:51.202221 31742 solver.cpp:237] Iteration 79500, loss = 0.919735
I0522 14:33:51.202270 31742 solver.cpp:253]     Train net output #0: loss = 0.919737 (* 1 = 0.919737 loss)
I0522 14:33:51.202285 31742 sgd_solver.cpp:106] Iteration 79500, lr = 0.004
I0522 14:34:01.682121 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_80000.caffemodel
I0522 14:34:01.734848 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_80000.solverstate
I0522 14:34:01.761322 31742 solver.cpp:341] Iteration 80000, Testing net (#0)
I0522 14:35:12.226002 31742 solver.cpp:409]     Test net output #0: accuracy = 0.883741
I0522 14:35:12.226174 31742 solver.cpp:409]     Test net output #1: loss = 0.374157 (* 1 = 0.374157 loss)
I0522 14:35:33.082438 31742 solver.cpp:237] Iteration 80000, loss = 0.951629
I0522 14:35:33.082492 31742 solver.cpp:253]     Train net output #0: loss = 0.951631 (* 1 = 0.951631 loss)
I0522 14:35:33.082510 31742 sgd_solver.cpp:106] Iteration 80000, lr = 0.004
I0522 14:35:43.654019 31742 solver.cpp:237] Iteration 80500, loss = 0.753127
I0522 14:35:43.654173 31742 solver.cpp:253]     Train net output #0: loss = 0.753129 (* 1 = 0.753129 loss)
I0522 14:35:43.654188 31742 sgd_solver.cpp:106] Iteration 80500, lr = 0.004
I0522 14:35:54.229288 31742 solver.cpp:237] Iteration 81000, loss = 1.48303
I0522 14:35:54.229336 31742 solver.cpp:253]     Train net output #0: loss = 1.48303 (* 1 = 1.48303 loss)
I0522 14:35:54.229351 31742 sgd_solver.cpp:106] Iteration 81000, lr = 0.004
I0522 14:36:04.795976 31742 solver.cpp:237] Iteration 81500, loss = 1.15228
I0522 14:36:04.796012 31742 solver.cpp:253]     Train net output #0: loss = 1.15228 (* 1 = 1.15228 loss)
I0522 14:36:04.796030 31742 sgd_solver.cpp:106] Iteration 81500, lr = 0.004
I0522 14:36:15.369762 31742 solver.cpp:237] Iteration 82000, loss = 1.22426
I0522 14:36:15.369913 31742 solver.cpp:253]     Train net output #0: loss = 1.22426 (* 1 = 1.22426 loss)
I0522 14:36:15.369928 31742 sgd_solver.cpp:106] Iteration 82000, lr = 0.004
I0522 14:36:25.932792 31742 solver.cpp:237] Iteration 82500, loss = 1.02621
I0522 14:36:25.932837 31742 solver.cpp:253]     Train net output #0: loss = 1.02622 (* 1 = 1.02622 loss)
I0522 14:36:25.932852 31742 sgd_solver.cpp:106] Iteration 82500, lr = 0.004
I0522 14:36:36.509433 31742 solver.cpp:237] Iteration 83000, loss = 1.06559
I0522 14:36:36.509469 31742 solver.cpp:253]     Train net output #0: loss = 1.06559 (* 1 = 1.06559 loss)
I0522 14:36:36.509485 31742 sgd_solver.cpp:106] Iteration 83000, lr = 0.004
I0522 14:37:07.937748 31742 solver.cpp:237] Iteration 83500, loss = 1.42956
I0522 14:37:07.937922 31742 solver.cpp:253]     Train net output #0: loss = 1.42956 (* 1 = 1.42956 loss)
I0522 14:37:07.937937 31742 sgd_solver.cpp:106] Iteration 83500, lr = 0.004
I0522 14:37:18.521944 31742 solver.cpp:237] Iteration 84000, loss = 0.859962
I0522 14:37:18.521981 31742 solver.cpp:253]     Train net output #0: loss = 0.859964 (* 1 = 0.859964 loss)
I0522 14:37:18.521996 31742 sgd_solver.cpp:106] Iteration 84000, lr = 0.004
I0522 14:37:29.103044 31742 solver.cpp:237] Iteration 84500, loss = 1.0069
I0522 14:37:29.103080 31742 solver.cpp:253]     Train net output #0: loss = 1.0069 (* 1 = 1.0069 loss)
I0522 14:37:29.103093 31742 sgd_solver.cpp:106] Iteration 84500, lr = 0.004
I0522 14:37:39.647325 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_85000.caffemodel
I0522 14:37:39.699957 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_85000.solverstate
I0522 14:37:39.732851 31742 solver.cpp:237] Iteration 85000, loss = 0.970819
I0522 14:37:39.732895 31742 solver.cpp:253]     Train net output #0: loss = 0.970821 (* 1 = 0.970821 loss)
I0522 14:37:39.732916 31742 sgd_solver.cpp:106] Iteration 85000, lr = 0.004
I0522 14:37:50.313092 31742 solver.cpp:237] Iteration 85500, loss = 1.14812
I0522 14:37:50.313128 31742 solver.cpp:253]     Train net output #0: loss = 1.14812 (* 1 = 1.14812 loss)
I0522 14:37:50.313144 31742 sgd_solver.cpp:106] Iteration 85500, lr = 0.004
I0522 14:38:00.902220 31742 solver.cpp:237] Iteration 86000, loss = 1.27673
I0522 14:38:00.902269 31742 solver.cpp:253]     Train net output #0: loss = 1.27673 (* 1 = 1.27673 loss)
I0522 14:38:00.902283 31742 sgd_solver.cpp:106] Iteration 86000, lr = 0.004
I0522 14:38:11.493746 31742 solver.cpp:237] Iteration 86500, loss = 1.22243
I0522 14:38:11.493912 31742 solver.cpp:253]     Train net output #0: loss = 1.22244 (* 1 = 1.22244 loss)
I0522 14:38:11.493927 31742 sgd_solver.cpp:106] Iteration 86500, lr = 0.004
I0522 14:38:43.002795 31742 solver.cpp:237] Iteration 87000, loss = 1.27559
I0522 14:38:43.002969 31742 solver.cpp:253]     Train net output #0: loss = 1.27559 (* 1 = 1.27559 loss)
I0522 14:38:43.002985 31742 sgd_solver.cpp:106] Iteration 87000, lr = 0.004
I0522 14:38:53.599719 31742 solver.cpp:237] Iteration 87500, loss = 1.44076
I0522 14:38:53.599766 31742 solver.cpp:253]     Train net output #0: loss = 1.44076 (* 1 = 1.44076 loss)
I0522 14:38:53.599781 31742 sgd_solver.cpp:106] Iteration 87500, lr = 0.004
I0522 14:39:04.190453 31742 solver.cpp:237] Iteration 88000, loss = 1.04805
I0522 14:39:04.190488 31742 solver.cpp:253]     Train net output #0: loss = 1.04806 (* 1 = 1.04806 loss)
I0522 14:39:04.190505 31742 sgd_solver.cpp:106] Iteration 88000, lr = 0.004
I0522 14:39:14.776592 31742 solver.cpp:237] Iteration 88500, loss = 1.03426
I0522 14:39:14.776758 31742 solver.cpp:253]     Train net output #0: loss = 1.03426 (* 1 = 1.03426 loss)
I0522 14:39:14.776773 31742 sgd_solver.cpp:106] Iteration 88500, lr = 0.004
I0522 14:39:25.337967 31742 solver.cpp:237] Iteration 89000, loss = 1.26998
I0522 14:39:25.338004 31742 solver.cpp:253]     Train net output #0: loss = 1.26998 (* 1 = 1.26998 loss)
I0522 14:39:25.338017 31742 sgd_solver.cpp:106] Iteration 89000, lr = 0.004
I0522 14:39:35.904436 31742 solver.cpp:237] Iteration 89500, loss = 1.31878
I0522 14:39:35.904484 31742 solver.cpp:253]     Train net output #0: loss = 1.31878 (* 1 = 1.31878 loss)
I0522 14:39:35.904505 31742 sgd_solver.cpp:106] Iteration 89500, lr = 0.004
I0522 14:39:46.462954 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_90000.caffemodel
I0522 14:39:46.516753 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_90000.solverstate
I0522 14:39:46.543445 31742 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 14:40:36.114449 31742 solver.cpp:409]     Test net output #0: accuracy = 0.890999
I0522 14:40:36.114616 31742 solver.cpp:409]     Test net output #1: loss = 0.344449 (* 1 = 0.344449 loss)
I0522 14:40:56.973031 31742 solver.cpp:237] Iteration 90000, loss = 1.33646
I0522 14:40:56.973083 31742 solver.cpp:253]     Train net output #0: loss = 1.33646 (* 1 = 1.33646 loss)
I0522 14:40:56.973100 31742 sgd_solver.cpp:106] Iteration 90000, lr = 0.004
I0522 14:41:07.532261 31742 solver.cpp:237] Iteration 90500, loss = 1.04533
I0522 14:41:07.532421 31742 solver.cpp:253]     Train net output #0: loss = 1.04533 (* 1 = 1.04533 loss)
I0522 14:41:07.532434 31742 sgd_solver.cpp:106] Iteration 90500, lr = 0.004
I0522 14:41:18.082877 31742 solver.cpp:237] Iteration 91000, loss = 0.93616
I0522 14:41:18.082928 31742 solver.cpp:253]     Train net output #0: loss = 0.936162 (* 1 = 0.936162 loss)
I0522 14:41:18.082942 31742 sgd_solver.cpp:106] Iteration 91000, lr = 0.004
I0522 14:41:28.649361 31742 solver.cpp:237] Iteration 91500, loss = 1.21211
I0522 14:41:28.649397 31742 solver.cpp:253]     Train net output #0: loss = 1.21211 (* 1 = 1.21211 loss)
I0522 14:41:28.649411 31742 sgd_solver.cpp:106] Iteration 91500, lr = 0.004
I0522 14:41:39.198859 31742 solver.cpp:237] Iteration 92000, loss = 1.34628
I0522 14:41:39.199024 31742 solver.cpp:253]     Train net output #0: loss = 1.34629 (* 1 = 1.34629 loss)
I0522 14:41:39.199038 31742 sgd_solver.cpp:106] Iteration 92000, lr = 0.004
I0522 14:41:49.752982 31742 solver.cpp:237] Iteration 92500, loss = 1.20578
I0522 14:41:49.753029 31742 solver.cpp:253]     Train net output #0: loss = 1.20578 (* 1 = 1.20578 loss)
I0522 14:41:49.753046 31742 sgd_solver.cpp:106] Iteration 92500, lr = 0.004
I0522 14:42:00.316535 31742 solver.cpp:237] Iteration 93000, loss = 0.914207
I0522 14:42:00.316571 31742 solver.cpp:253]     Train net output #0: loss = 0.914209 (* 1 = 0.914209 loss)
I0522 14:42:00.316586 31742 sgd_solver.cpp:106] Iteration 93000, lr = 0.004
I0522 14:42:31.737076 31742 solver.cpp:237] Iteration 93500, loss = 1.41627
I0522 14:42:31.737248 31742 solver.cpp:253]     Train net output #0: loss = 1.41628 (* 1 = 1.41628 loss)
I0522 14:42:31.737262 31742 sgd_solver.cpp:106] Iteration 93500, lr = 0.004
I0522 14:42:42.278956 31742 solver.cpp:237] Iteration 94000, loss = 1.29117
I0522 14:42:42.278991 31742 solver.cpp:253]     Train net output #0: loss = 1.29117 (* 1 = 1.29117 loss)
I0522 14:42:42.279008 31742 sgd_solver.cpp:106] Iteration 94000, lr = 0.004
I0522 14:42:52.834471 31742 solver.cpp:237] Iteration 94500, loss = 1.25673
I0522 14:42:52.834506 31742 solver.cpp:253]     Train net output #0: loss = 1.25673 (* 1 = 1.25673 loss)
I0522 14:42:52.834523 31742 sgd_solver.cpp:106] Iteration 94500, lr = 0.004
I0522 14:43:03.367292 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_95000.caffemodel
I0522 14:43:03.422441 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_95000.solverstate
I0522 14:43:03.457396 31742 solver.cpp:237] Iteration 95000, loss = 1.22805
I0522 14:43:03.457445 31742 solver.cpp:253]     Train net output #0: loss = 1.22805 (* 1 = 1.22805 loss)
I0522 14:43:03.457463 31742 sgd_solver.cpp:106] Iteration 95000, lr = 0.004
I0522 14:43:14.015269 31742 solver.cpp:237] Iteration 95500, loss = 1.55791
I0522 14:43:14.015303 31742 solver.cpp:253]     Train net output #0: loss = 1.55791 (* 1 = 1.55791 loss)
I0522 14:43:14.015319 31742 sgd_solver.cpp:106] Iteration 95500, lr = 0.004
I0522 14:43:24.571151 31742 solver.cpp:237] Iteration 96000, loss = 1.37546
I0522 14:43:24.571200 31742 solver.cpp:253]     Train net output #0: loss = 1.37546 (* 1 = 1.37546 loss)
I0522 14:43:24.571215 31742 sgd_solver.cpp:106] Iteration 96000, lr = 0.004
I0522 14:43:35.130216 31742 solver.cpp:237] Iteration 96500, loss = 1.16916
I0522 14:43:35.130374 31742 solver.cpp:253]     Train net output #0: loss = 1.16916 (* 1 = 1.16916 loss)
I0522 14:43:35.130388 31742 sgd_solver.cpp:106] Iteration 96500, lr = 0.004
I0522 14:44:06.589804 31742 solver.cpp:237] Iteration 97000, loss = 1.10635
I0522 14:44:06.589982 31742 solver.cpp:253]     Train net output #0: loss = 1.10635 (* 1 = 1.10635 loss)
I0522 14:44:06.589996 31742 sgd_solver.cpp:106] Iteration 97000, lr = 0.004
I0522 14:44:17.147344 31742 solver.cpp:237] Iteration 97500, loss = 1.41255
I0522 14:44:17.147384 31742 solver.cpp:253]     Train net output #0: loss = 1.41255 (* 1 = 1.41255 loss)
I0522 14:44:17.147400 31742 sgd_solver.cpp:106] Iteration 97500, lr = 0.004
I0522 14:44:27.697643 31742 solver.cpp:237] Iteration 98000, loss = 1.23237
I0522 14:44:27.697679 31742 solver.cpp:253]     Train net output #0: loss = 1.23237 (* 1 = 1.23237 loss)
I0522 14:44:27.697695 31742 sgd_solver.cpp:106] Iteration 98000, lr = 0.004
I0522 14:44:38.239126 31742 solver.cpp:237] Iteration 98500, loss = 1.28069
I0522 14:44:38.239296 31742 solver.cpp:253]     Train net output #0: loss = 1.28069 (* 1 = 1.28069 loss)
I0522 14:44:38.239310 31742 sgd_solver.cpp:106] Iteration 98500, lr = 0.004
I0522 14:44:48.806769 31742 solver.cpp:237] Iteration 99000, loss = 1.19927
I0522 14:44:48.806804 31742 solver.cpp:253]     Train net output #0: loss = 1.19927 (* 1 = 1.19927 loss)
I0522 14:44:48.806821 31742 sgd_solver.cpp:106] Iteration 99000, lr = 0.004
I0522 14:44:59.361945 31742 solver.cpp:237] Iteration 99500, loss = 1.08768
I0522 14:44:59.361981 31742 solver.cpp:253]     Train net output #0: loss = 1.08768 (* 1 = 1.08768 loss)
I0522 14:44:59.361994 31742 sgd_solver.cpp:106] Iteration 99500, lr = 0.004
I0522 14:45:09.887255 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_100000.caffemodel
I0522 14:45:09.941969 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_100000.solverstate
I0522 14:45:09.969696 31742 solver.cpp:341] Iteration 100000, Testing net (#0)
I0522 14:46:20.356881 31742 solver.cpp:409]     Test net output #0: accuracy = 0.887787
I0522 14:46:20.357056 31742 solver.cpp:409]     Test net output #1: loss = 0.361142 (* 1 = 0.361142 loss)
I0522 14:46:41.243454 31742 solver.cpp:237] Iteration 100000, loss = 1.11565
I0522 14:46:41.243505 31742 solver.cpp:253]     Train net output #0: loss = 1.11565 (* 1 = 1.11565 loss)
I0522 14:46:41.243520 31742 sgd_solver.cpp:106] Iteration 100000, lr = 0.004
I0522 14:46:51.779593 31742 solver.cpp:237] Iteration 100500, loss = 1.0002
I0522 14:46:51.779755 31742 solver.cpp:253]     Train net output #0: loss = 1.0002 (* 1 = 1.0002 loss)
I0522 14:46:51.779768 31742 sgd_solver.cpp:106] Iteration 100500, lr = 0.004
I0522 14:47:02.298831 31742 solver.cpp:237] Iteration 101000, loss = 1.32152
I0522 14:47:02.298867 31742 solver.cpp:253]     Train net output #0: loss = 1.32152 (* 1 = 1.32152 loss)
I0522 14:47:02.298884 31742 sgd_solver.cpp:106] Iteration 101000, lr = 0.004
I0522 14:47:12.817744 31742 solver.cpp:237] Iteration 101500, loss = 1.23159
I0522 14:47:12.817790 31742 solver.cpp:253]     Train net output #0: loss = 1.23159 (* 1 = 1.23159 loss)
I0522 14:47:12.817806 31742 sgd_solver.cpp:106] Iteration 101500, lr = 0.004
I0522 14:47:23.328825 31742 solver.cpp:237] Iteration 102000, loss = 1.2861
I0522 14:47:23.328979 31742 solver.cpp:253]     Train net output #0: loss = 1.28611 (* 1 = 1.28611 loss)
I0522 14:47:23.328994 31742 sgd_solver.cpp:106] Iteration 102000, lr = 0.004
I0522 14:47:33.871881 31742 solver.cpp:237] Iteration 102500, loss = 0.968878
I0522 14:47:33.871927 31742 solver.cpp:253]     Train net output #0: loss = 0.96888 (* 1 = 0.96888 loss)
I0522 14:47:33.871942 31742 sgd_solver.cpp:106] Iteration 102500, lr = 0.004
I0522 14:47:44.397804 31742 solver.cpp:237] Iteration 103000, loss = 1.28907
I0522 14:47:44.397840 31742 solver.cpp:253]     Train net output #0: loss = 1.28908 (* 1 = 1.28908 loss)
I0522 14:47:44.397855 31742 sgd_solver.cpp:106] Iteration 103000, lr = 0.004
I0522 14:48:15.759837 31742 solver.cpp:237] Iteration 103500, loss = 1.00212
I0522 14:48:15.760010 31742 solver.cpp:253]     Train net output #0: loss = 1.00212 (* 1 = 1.00212 loss)
I0522 14:48:15.760025 31742 sgd_solver.cpp:106] Iteration 103500, lr = 0.004
I0522 14:48:26.281766 31742 solver.cpp:237] Iteration 104000, loss = 0.885394
I0522 14:48:26.281811 31742 solver.cpp:253]     Train net output #0: loss = 0.885396 (* 1 = 0.885396 loss)
I0522 14:48:26.281828 31742 sgd_solver.cpp:106] Iteration 104000, lr = 0.004
I0522 14:48:36.830152 31742 solver.cpp:237] Iteration 104500, loss = 1.44639
I0522 14:48:36.830186 31742 solver.cpp:253]     Train net output #0: loss = 1.44639 (* 1 = 1.44639 loss)
I0522 14:48:36.830202 31742 sgd_solver.cpp:106] Iteration 104500, lr = 0.004
I0522 14:48:47.347625 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_105000.caffemodel
I0522 14:48:47.400120 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_105000.solverstate
I0522 14:48:47.432019 31742 solver.cpp:237] Iteration 105000, loss = 0.799553
I0522 14:48:47.432065 31742 solver.cpp:253]     Train net output #0: loss = 0.799555 (* 1 = 0.799555 loss)
I0522 14:48:47.432080 31742 sgd_solver.cpp:106] Iteration 105000, lr = 0.004
I0522 14:48:57.968250 31742 solver.cpp:237] Iteration 105500, loss = 1.23773
I0522 14:48:57.968286 31742 solver.cpp:253]     Train net output #0: loss = 1.23773 (* 1 = 1.23773 loss)
I0522 14:48:57.968300 31742 sgd_solver.cpp:106] Iteration 105500, lr = 0.004
I0522 14:49:08.490635 31742 solver.cpp:237] Iteration 106000, loss = 0.933893
I0522 14:49:08.490671 31742 solver.cpp:253]     Train net output #0: loss = 0.933895 (* 1 = 0.933895 loss)
I0522 14:49:08.490687 31742 sgd_solver.cpp:106] Iteration 106000, lr = 0.004
I0522 14:49:19.013077 31742 solver.cpp:237] Iteration 106500, loss = 1.09308
I0522 14:49:19.013253 31742 solver.cpp:253]     Train net output #0: loss = 1.09308 (* 1 = 1.09308 loss)
I0522 14:49:19.013268 31742 sgd_solver.cpp:106] Iteration 106500, lr = 0.004
I0522 14:49:50.449484 31742 solver.cpp:237] Iteration 107000, loss = 0.903626
I0522 14:49:50.449663 31742 solver.cpp:253]     Train net output #0: loss = 0.903628 (* 1 = 0.903628 loss)
I0522 14:49:50.449678 31742 sgd_solver.cpp:106] Iteration 107000, lr = 0.004
I0522 14:50:00.985630 31742 solver.cpp:237] Iteration 107500, loss = 1.17996
I0522 14:50:00.985677 31742 solver.cpp:253]     Train net output #0: loss = 1.17996 (* 1 = 1.17996 loss)
I0522 14:50:00.985693 31742 sgd_solver.cpp:106] Iteration 107500, lr = 0.004
I0522 14:50:11.515024 31742 solver.cpp:237] Iteration 108000, loss = 1.13116
I0522 14:50:11.515059 31742 solver.cpp:253]     Train net output #0: loss = 1.13116 (* 1 = 1.13116 loss)
I0522 14:50:11.515072 31742 sgd_solver.cpp:106] Iteration 108000, lr = 0.004
I0522 14:50:22.040135 31742 solver.cpp:237] Iteration 108500, loss = 1.29039
I0522 14:50:22.040292 31742 solver.cpp:253]     Train net output #0: loss = 1.29039 (* 1 = 1.29039 loss)
I0522 14:50:22.040307 31742 sgd_solver.cpp:106] Iteration 108500, lr = 0.004
I0522 14:50:32.560015 31742 solver.cpp:237] Iteration 109000, loss = 1.08728
I0522 14:50:32.560060 31742 solver.cpp:253]     Train net output #0: loss = 1.08728 (* 1 = 1.08728 loss)
I0522 14:50:32.560076 31742 sgd_solver.cpp:106] Iteration 109000, lr = 0.004
I0522 14:50:43.092319 31742 solver.cpp:237] Iteration 109500, loss = 1.24841
I0522 14:50:43.092355 31742 solver.cpp:253]     Train net output #0: loss = 1.24841 (* 1 = 1.24841 loss)
I0522 14:50:43.092367 31742 sgd_solver.cpp:106] Iteration 109500, lr = 0.004
I0522 14:50:53.625277 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_110000.caffemodel
I0522 14:50:53.677701 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_110000.solverstate
I0522 14:50:53.703181 31742 solver.cpp:341] Iteration 110000, Testing net (#0)
I0522 14:51:42.951659 31742 solver.cpp:409]     Test net output #0: accuracy = 0.893533
I0522 14:51:42.951835 31742 solver.cpp:409]     Test net output #1: loss = 0.370828 (* 1 = 0.370828 loss)
I0522 14:52:03.808094 31742 solver.cpp:237] Iteration 110000, loss = 0.834137
I0522 14:52:03.808146 31742 solver.cpp:253]     Train net output #0: loss = 0.834139 (* 1 = 0.834139 loss)
I0522 14:52:03.808161 31742 sgd_solver.cpp:106] Iteration 110000, lr = 0.004
I0522 14:52:14.294857 31742 solver.cpp:237] Iteration 110500, loss = 1.04147
I0522 14:52:14.295040 31742 solver.cpp:253]     Train net output #0: loss = 1.04147 (* 1 = 1.04147 loss)
I0522 14:52:14.295055 31742 sgd_solver.cpp:106] Iteration 110500, lr = 0.004
I0522 14:52:24.801662 31742 solver.cpp:237] Iteration 111000, loss = 0.902394
I0522 14:52:24.801698 31742 solver.cpp:253]     Train net output #0: loss = 0.902396 (* 1 = 0.902396 loss)
I0522 14:52:24.801714 31742 sgd_solver.cpp:106] Iteration 111000, lr = 0.004
I0522 14:52:35.300381 31742 solver.cpp:237] Iteration 111500, loss = 1.12075
I0522 14:52:35.300426 31742 solver.cpp:253]     Train net output #0: loss = 1.12075 (* 1 = 1.12075 loss)
I0522 14:52:35.300441 31742 sgd_solver.cpp:106] Iteration 111500, lr = 0.004
I0522 14:52:45.798224 31742 solver.cpp:237] Iteration 112000, loss = 0.895859
I0522 14:52:45.798382 31742 solver.cpp:253]     Train net output #0: loss = 0.895861 (* 1 = 0.895861 loss)
I0522 14:52:45.798396 31742 sgd_solver.cpp:106] Iteration 112000, lr = 0.004
I0522 14:52:56.299021 31742 solver.cpp:237] Iteration 112500, loss = 1.41524
I0522 14:52:56.299063 31742 solver.cpp:253]     Train net output #0: loss = 1.41525 (* 1 = 1.41525 loss)
I0522 14:52:56.299079 31742 sgd_solver.cpp:106] Iteration 112500, lr = 0.004
I0522 14:53:06.809551 31742 solver.cpp:237] Iteration 113000, loss = 1.29086
I0522 14:53:06.809586 31742 solver.cpp:253]     Train net output #0: loss = 1.29086 (* 1 = 1.29086 loss)
I0522 14:53:06.809599 31742 sgd_solver.cpp:106] Iteration 113000, lr = 0.004
I0522 14:53:38.186059 31742 solver.cpp:237] Iteration 113500, loss = 1.47925
I0522 14:53:38.186249 31742 solver.cpp:253]     Train net output #0: loss = 1.47925 (* 1 = 1.47925 loss)
I0522 14:53:38.186264 31742 sgd_solver.cpp:106] Iteration 113500, lr = 0.004
I0522 14:53:48.700093 31742 solver.cpp:237] Iteration 114000, loss = 1.06927
I0522 14:53:48.700141 31742 solver.cpp:253]     Train net output #0: loss = 1.06927 (* 1 = 1.06927 loss)
I0522 14:53:48.700155 31742 sgd_solver.cpp:106] Iteration 114000, lr = 0.004
I0522 14:53:59.210064 31742 solver.cpp:237] Iteration 114500, loss = 1.21425
I0522 14:53:59.210099 31742 solver.cpp:253]     Train net output #0: loss = 1.21426 (* 1 = 1.21426 loss)
I0522 14:53:59.210113 31742 sgd_solver.cpp:106] Iteration 114500, lr = 0.004
I0522 14:54:09.679354 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_115000.caffemodel
I0522 14:54:09.731982 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_115000.solverstate
I0522 14:54:09.763675 31742 solver.cpp:237] Iteration 115000, loss = 1.09854
I0522 14:54:09.763720 31742 solver.cpp:253]     Train net output #0: loss = 1.09854 (* 1 = 1.09854 loss)
I0522 14:54:09.763736 31742 sgd_solver.cpp:106] Iteration 115000, lr = 0.004
I0522 14:54:20.273813 31742 solver.cpp:237] Iteration 115500, loss = 1.32234
I0522 14:54:20.273859 31742 solver.cpp:253]     Train net output #0: loss = 1.32234 (* 1 = 1.32234 loss)
I0522 14:54:20.273874 31742 sgd_solver.cpp:106] Iteration 115500, lr = 0.004
I0522 14:54:30.760464 31742 solver.cpp:237] Iteration 116000, loss = 1.22817
I0522 14:54:30.760500 31742 solver.cpp:253]     Train net output #0: loss = 1.22817 (* 1 = 1.22817 loss)
I0522 14:54:30.760516 31742 sgd_solver.cpp:106] Iteration 116000, lr = 0.004
I0522 14:54:41.253623 31742 solver.cpp:237] Iteration 116500, loss = 1.12987
I0522 14:54:41.253793 31742 solver.cpp:253]     Train net output #0: loss = 1.12987 (* 1 = 1.12987 loss)
I0522 14:54:41.253808 31742 sgd_solver.cpp:106] Iteration 116500, lr = 0.004
I0522 14:55:12.685917 31742 solver.cpp:237] Iteration 117000, loss = 1.5071
I0522 14:55:12.686096 31742 solver.cpp:253]     Train net output #0: loss = 1.5071 (* 1 = 1.5071 loss)
I0522 14:55:12.686112 31742 sgd_solver.cpp:106] Iteration 117000, lr = 0.004
I0522 14:55:23.191692 31742 solver.cpp:237] Iteration 117500, loss = 1.29895
I0522 14:55:23.191728 31742 solver.cpp:253]     Train net output #0: loss = 1.29895 (* 1 = 1.29895 loss)
I0522 14:55:23.191745 31742 sgd_solver.cpp:106] Iteration 117500, lr = 0.004
I0522 14:55:33.691792 31742 solver.cpp:237] Iteration 118000, loss = 1.30611
I0522 14:55:33.691834 31742 solver.cpp:253]     Train net output #0: loss = 1.30612 (* 1 = 1.30612 loss)
I0522 14:55:33.691850 31742 sgd_solver.cpp:106] Iteration 118000, lr = 0.004
I0522 14:55:44.187613 31742 solver.cpp:237] Iteration 118500, loss = 1.05359
I0522 14:55:44.187783 31742 solver.cpp:253]     Train net output #0: loss = 1.0536 (* 1 = 1.0536 loss)
I0522 14:55:44.187798 31742 sgd_solver.cpp:106] Iteration 118500, lr = 0.004
I0522 14:55:54.689759 31742 solver.cpp:237] Iteration 119000, loss = 1.25528
I0522 14:55:54.689805 31742 solver.cpp:253]     Train net output #0: loss = 1.25528 (* 1 = 1.25528 loss)
I0522 14:55:54.689821 31742 sgd_solver.cpp:106] Iteration 119000, lr = 0.004
I0522 14:56:05.199774 31742 solver.cpp:237] Iteration 119500, loss = 0.991467
I0522 14:56:05.199805 31742 solver.cpp:253]     Train net output #0: loss = 0.991469 (* 1 = 0.991469 loss)
I0522 14:56:05.199820 31742 sgd_solver.cpp:106] Iteration 119500, lr = 0.004
I0522 14:56:15.692013 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_120000.caffemodel
I0522 14:56:15.744343 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_120000.solverstate
I0522 14:56:15.769582 31742 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 14:57:26.288666 31742 solver.cpp:409]     Test net output #0: accuracy = 0.892118
I0522 14:57:26.288846 31742 solver.cpp:409]     Test net output #1: loss = 0.378545 (* 1 = 0.378545 loss)
I0522 14:57:47.202821 31742 solver.cpp:237] Iteration 120000, loss = 1.20532
I0522 14:57:47.202875 31742 solver.cpp:253]     Train net output #0: loss = 1.20532 (* 1 = 1.20532 loss)
I0522 14:57:47.202893 31742 sgd_solver.cpp:106] Iteration 120000, lr = 0.004
I0522 14:57:57.780683 31742 solver.cpp:237] Iteration 120500, loss = 0.737298
I0522 14:57:57.780853 31742 solver.cpp:253]     Train net output #0: loss = 0.7373 (* 1 = 0.7373 loss)
I0522 14:57:57.780867 31742 sgd_solver.cpp:106] Iteration 120500, lr = 0.004
I0522 14:58:08.351130 31742 solver.cpp:237] Iteration 121000, loss = 1.52049
I0522 14:58:08.351166 31742 solver.cpp:253]     Train net output #0: loss = 1.52049 (* 1 = 1.52049 loss)
I0522 14:58:08.351181 31742 sgd_solver.cpp:106] Iteration 121000, lr = 0.004
I0522 14:58:18.936172 31742 solver.cpp:237] Iteration 121500, loss = 0.830692
I0522 14:58:18.936208 31742 solver.cpp:253]     Train net output #0: loss = 0.830694 (* 1 = 0.830694 loss)
I0522 14:58:18.936220 31742 sgd_solver.cpp:106] Iteration 121500, lr = 0.004
I0522 14:58:29.511191 31742 solver.cpp:237] Iteration 122000, loss = 1.45118
I0522 14:58:29.511356 31742 solver.cpp:253]     Train net output #0: loss = 1.45119 (* 1 = 1.45119 loss)
I0522 14:58:29.511370 31742 sgd_solver.cpp:106] Iteration 122000, lr = 0.004
I0522 14:58:40.084806 31742 solver.cpp:237] Iteration 122500, loss = 1.1759
I0522 14:58:40.084842 31742 solver.cpp:253]     Train net output #0: loss = 1.1759 (* 1 = 1.1759 loss)
I0522 14:58:40.084859 31742 sgd_solver.cpp:106] Iteration 122500, lr = 0.004
I0522 14:58:50.664224 31742 solver.cpp:237] Iteration 123000, loss = 1.07444
I0522 14:58:50.664264 31742 solver.cpp:253]     Train net output #0: loss = 1.07444 (* 1 = 1.07444 loss)
I0522 14:58:50.664278 31742 sgd_solver.cpp:106] Iteration 123000, lr = 0.004
I0522 14:59:22.147960 31742 solver.cpp:237] Iteration 123500, loss = 0.980483
I0522 14:59:22.148141 31742 solver.cpp:253]     Train net output #0: loss = 0.980485 (* 1 = 0.980485 loss)
I0522 14:59:22.148156 31742 sgd_solver.cpp:106] Iteration 123500, lr = 0.004
I0522 14:59:32.712924 31742 solver.cpp:237] Iteration 124000, loss = 1.14453
I0522 14:59:32.712959 31742 solver.cpp:253]     Train net output #0: loss = 1.14454 (* 1 = 1.14454 loss)
I0522 14:59:32.712972 31742 sgd_solver.cpp:106] Iteration 124000, lr = 0.004
I0522 14:59:43.290792 31742 solver.cpp:237] Iteration 124500, loss = 0.788381
I0522 14:59:43.290835 31742 solver.cpp:253]     Train net output #0: loss = 0.788382 (* 1 = 0.788382 loss)
I0522 14:59:43.290850 31742 sgd_solver.cpp:106] Iteration 124500, lr = 0.004
I0522 14:59:53.840517 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_125000.caffemodel
I0522 14:59:53.900840 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_125000.solverstate
I0522 14:59:53.934983 31742 solver.cpp:237] Iteration 125000, loss = 1.44666
I0522 14:59:53.935032 31742 solver.cpp:253]     Train net output #0: loss = 1.44666 (* 1 = 1.44666 loss)
I0522 14:59:53.935045 31742 sgd_solver.cpp:106] Iteration 125000, lr = 0.004
I0522 15:00:04.509454 31742 solver.cpp:237] Iteration 125500, loss = 1.2052
I0522 15:00:04.509500 31742 solver.cpp:253]     Train net output #0: loss = 1.2052 (* 1 = 1.2052 loss)
I0522 15:00:04.509516 31742 sgd_solver.cpp:106] Iteration 125500, lr = 0.004
I0522 15:00:15.098492 31742 solver.cpp:237] Iteration 126000, loss = 1.39121
I0522 15:00:15.098527 31742 solver.cpp:253]     Train net output #0: loss = 1.39121 (* 1 = 1.39121 loss)
I0522 15:00:15.098544 31742 sgd_solver.cpp:106] Iteration 126000, lr = 0.004
I0522 15:00:25.673740 31742 solver.cpp:237] Iteration 126500, loss = 0.945944
I0522 15:00:25.673921 31742 solver.cpp:253]     Train net output #0: loss = 0.945946 (* 1 = 0.945946 loss)
I0522 15:00:25.673935 31742 sgd_solver.cpp:106] Iteration 126500, lr = 0.004
I0522 15:00:57.159816 31742 solver.cpp:237] Iteration 127000, loss = 0.572462
I0522 15:00:57.159996 31742 solver.cpp:253]     Train net output #0: loss = 0.572464 (* 1 = 0.572464 loss)
I0522 15:00:57.160012 31742 sgd_solver.cpp:106] Iteration 127000, lr = 0.004
I0522 15:01:07.734346 31742 solver.cpp:237] Iteration 127500, loss = 0.953378
I0522 15:01:07.734383 31742 solver.cpp:253]     Train net output #0: loss = 0.953379 (* 1 = 0.953379 loss)
I0522 15:01:07.734400 31742 sgd_solver.cpp:106] Iteration 127500, lr = 0.004
I0522 15:01:18.301832 31742 solver.cpp:237] Iteration 128000, loss = 1.17102
I0522 15:01:18.301879 31742 solver.cpp:253]     Train net output #0: loss = 1.17102 (* 1 = 1.17102 loss)
I0522 15:01:18.301894 31742 sgd_solver.cpp:106] Iteration 128000, lr = 0.004
I0522 15:01:28.880775 31742 solver.cpp:237] Iteration 128500, loss = 1.12499
I0522 15:01:28.880935 31742 solver.cpp:253]     Train net output #0: loss = 1.12499 (* 1 = 1.12499 loss)
I0522 15:01:28.880949 31742 sgd_solver.cpp:106] Iteration 128500, lr = 0.004
I0522 15:01:39.474634 31742 solver.cpp:237] Iteration 129000, loss = 1.24916
I0522 15:01:39.474670 31742 solver.cpp:253]     Train net output #0: loss = 1.24916 (* 1 = 1.24916 loss)
I0522 15:01:39.474686 31742 sgd_solver.cpp:106] Iteration 129000, lr = 0.004
I0522 15:01:50.065361 31742 solver.cpp:237] Iteration 129500, loss = 0.905028
I0522 15:01:50.065407 31742 solver.cpp:253]     Train net output #0: loss = 0.905029 (* 1 = 0.905029 loss)
I0522 15:01:50.065421 31742 sgd_solver.cpp:106] Iteration 129500, lr = 0.004
I0522 15:02:00.618083 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_130000.caffemodel
I0522 15:02:00.670845 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_130000.solverstate
I0522 15:02:00.696385 31742 solver.cpp:341] Iteration 130000, Testing net (#0)
I0522 15:02:50.372448 31742 solver.cpp:409]     Test net output #0: accuracy = 0.892507
I0522 15:02:50.372640 31742 solver.cpp:409]     Test net output #1: loss = 0.334579 (* 1 = 0.334579 loss)
I0522 15:03:11.252043 31742 solver.cpp:237] Iteration 130000, loss = 1.04417
I0522 15:03:11.252094 31742 solver.cpp:253]     Train net output #0: loss = 1.04417 (* 1 = 1.04417 loss)
I0522 15:03:11.252111 31742 sgd_solver.cpp:106] Iteration 130000, lr = 0.004
I0522 15:03:21.818583 31742 solver.cpp:237] Iteration 130500, loss = 0.829447
I0522 15:03:21.818764 31742 solver.cpp:253]     Train net output #0: loss = 0.829449 (* 1 = 0.829449 loss)
I0522 15:03:21.818780 31742 sgd_solver.cpp:106] Iteration 130500, lr = 0.004
I0522 15:03:32.377593 31742 solver.cpp:237] Iteration 131000, loss = 1.26458
I0522 15:03:32.377629 31742 solver.cpp:253]     Train net output #0: loss = 1.26458 (* 1 = 1.26458 loss)
I0522 15:03:32.377645 31742 sgd_solver.cpp:106] Iteration 131000, lr = 0.004
I0522 15:03:42.935350 31742 solver.cpp:237] Iteration 131500, loss = 1.40816
I0522 15:03:42.935386 31742 solver.cpp:253]     Train net output #0: loss = 1.40816 (* 1 = 1.40816 loss)
I0522 15:03:42.935402 31742 sgd_solver.cpp:106] Iteration 131500, lr = 0.004
I0522 15:03:53.499907 31742 solver.cpp:237] Iteration 132000, loss = 1.14049
I0522 15:03:53.500072 31742 solver.cpp:253]     Train net output #0: loss = 1.14049 (* 1 = 1.14049 loss)
I0522 15:03:53.500085 31742 sgd_solver.cpp:106] Iteration 132000, lr = 0.004
I0522 15:04:04.070701 31742 solver.cpp:237] Iteration 132500, loss = 0.868888
I0522 15:04:04.070739 31742 solver.cpp:253]     Train net output #0: loss = 0.86889 (* 1 = 0.86889 loss)
I0522 15:04:04.070755 31742 sgd_solver.cpp:106] Iteration 132500, lr = 0.004
I0522 15:04:14.635120 31742 solver.cpp:237] Iteration 133000, loss = 1.11614
I0522 15:04:14.635167 31742 solver.cpp:253]     Train net output #0: loss = 1.11614 (* 1 = 1.11614 loss)
I0522 15:04:14.635182 31742 sgd_solver.cpp:106] Iteration 133000, lr = 0.004
I0522 15:04:46.086279 31742 solver.cpp:237] Iteration 133500, loss = 1.277
I0522 15:04:46.086473 31742 solver.cpp:253]     Train net output #0: loss = 1.27701 (* 1 = 1.27701 loss)
I0522 15:04:46.086488 31742 sgd_solver.cpp:106] Iteration 133500, lr = 0.004
I0522 15:04:56.639856 31742 solver.cpp:237] Iteration 134000, loss = 0.885874
I0522 15:04:56.639892 31742 solver.cpp:253]     Train net output #0: loss = 0.885875 (* 1 = 0.885875 loss)
I0522 15:04:56.639909 31742 sgd_solver.cpp:106] Iteration 134000, lr = 0.004
I0522 15:05:07.221917 31742 solver.cpp:237] Iteration 134500, loss = 0.944938
I0522 15:05:07.221969 31742 solver.cpp:253]     Train net output #0: loss = 0.944939 (* 1 = 0.944939 loss)
I0522 15:05:07.221983 31742 sgd_solver.cpp:106] Iteration 134500, lr = 0.004
I0522 15:05:17.801501 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_135000.caffemodel
I0522 15:05:17.853617 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_135000.solverstate
I0522 15:05:17.885812 31742 solver.cpp:237] Iteration 135000, loss = 1.05826
I0522 15:05:17.885859 31742 solver.cpp:253]     Train net output #0: loss = 1.05826 (* 1 = 1.05826 loss)
I0522 15:05:17.885877 31742 sgd_solver.cpp:106] Iteration 135000, lr = 0.004
I0522 15:05:28.476943 31742 solver.cpp:237] Iteration 135500, loss = 1.307
I0522 15:05:28.476991 31742 solver.cpp:253]     Train net output #0: loss = 1.307 (* 1 = 1.307 loss)
I0522 15:05:28.477006 31742 sgd_solver.cpp:106] Iteration 135500, lr = 0.004
I0522 15:05:39.067697 31742 solver.cpp:237] Iteration 136000, loss = 0.982899
I0522 15:05:39.067734 31742 solver.cpp:253]     Train net output #0: loss = 0.982901 (* 1 = 0.982901 loss)
I0522 15:05:39.067749 31742 sgd_solver.cpp:106] Iteration 136000, lr = 0.004
I0522 15:05:49.663911 31742 solver.cpp:237] Iteration 136500, loss = 1.06327
I0522 15:05:49.664078 31742 solver.cpp:253]     Train net output #0: loss = 1.06327 (* 1 = 1.06327 loss)
I0522 15:05:49.664091 31742 sgd_solver.cpp:106] Iteration 136500, lr = 0.004
I0522 15:06:21.185669 31742 solver.cpp:237] Iteration 137000, loss = 1.38016
I0522 15:06:21.185861 31742 solver.cpp:253]     Train net output #0: loss = 1.38016 (* 1 = 1.38016 loss)
I0522 15:06:21.185876 31742 sgd_solver.cpp:106] Iteration 137000, lr = 0.004
I0522 15:06:31.783531 31742 solver.cpp:237] Iteration 137500, loss = 1.37693
I0522 15:06:31.783567 31742 solver.cpp:253]     Train net output #0: loss = 1.37693 (* 1 = 1.37693 loss)
I0522 15:06:31.783584 31742 sgd_solver.cpp:106] Iteration 137500, lr = 0.004
I0522 15:06:42.386430 31742 solver.cpp:237] Iteration 138000, loss = 1.18253
I0522 15:06:42.386476 31742 solver.cpp:253]     Train net output #0: loss = 1.18253 (* 1 = 1.18253 loss)
I0522 15:06:42.386492 31742 sgd_solver.cpp:106] Iteration 138000, lr = 0.004
I0522 15:06:52.988131 31742 solver.cpp:237] Iteration 138500, loss = 1.21368
I0522 15:06:52.988296 31742 solver.cpp:253]     Train net output #0: loss = 1.21368 (* 1 = 1.21368 loss)
I0522 15:06:52.988311 31742 sgd_solver.cpp:106] Iteration 138500, lr = 0.004
I0522 15:07:03.571854 31742 solver.cpp:237] Iteration 139000, loss = 1.29445
I0522 15:07:03.571890 31742 solver.cpp:253]     Train net output #0: loss = 1.29446 (* 1 = 1.29446 loss)
I0522 15:07:03.571907 31742 sgd_solver.cpp:106] Iteration 139000, lr = 0.004
I0522 15:07:14.187795 31742 solver.cpp:237] Iteration 139500, loss = 1.04677
I0522 15:07:14.187841 31742 solver.cpp:253]     Train net output #0: loss = 1.04677 (* 1 = 1.04677 loss)
I0522 15:07:14.187857 31742 sgd_solver.cpp:106] Iteration 139500, lr = 0.004
I0522 15:07:24.765084 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_140000.caffemodel
I0522 15:07:24.817647 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_140000.solverstate
I0522 15:07:24.843150 31742 solver.cpp:341] Iteration 140000, Testing net (#0)
I0522 15:08:35.372617 31742 solver.cpp:409]     Test net output #0: accuracy = 0.89192
I0522 15:08:35.372802 31742 solver.cpp:409]     Test net output #1: loss = 0.332124 (* 1 = 0.332124 loss)
I0522 15:08:56.315379 31742 solver.cpp:237] Iteration 140000, loss = 1.25736
I0522 15:08:56.315443 31742 solver.cpp:253]     Train net output #0: loss = 1.25736 (* 1 = 1.25736 loss)
I0522 15:08:56.315460 31742 sgd_solver.cpp:106] Iteration 140000, lr = 0.004
I0522 15:09:06.812655 31742 solver.cpp:237] Iteration 140500, loss = 1.206
I0522 15:09:06.812821 31742 solver.cpp:253]     Train net output #0: loss = 1.206 (* 1 = 1.206 loss)
I0522 15:09:06.812835 31742 sgd_solver.cpp:106] Iteration 140500, lr = 0.004
I0522 15:09:17.316838 31742 solver.cpp:237] Iteration 141000, loss = 1.03925
I0522 15:09:17.316887 31742 solver.cpp:253]     Train net output #0: loss = 1.03925 (* 1 = 1.03925 loss)
I0522 15:09:17.316900 31742 sgd_solver.cpp:106] Iteration 141000, lr = 0.004
I0522 15:09:27.820881 31742 solver.cpp:237] Iteration 141500, loss = 0.830282
I0522 15:09:27.820919 31742 solver.cpp:253]     Train net output #0: loss = 0.830284 (* 1 = 0.830284 loss)
I0522 15:09:27.820933 31742 sgd_solver.cpp:106] Iteration 141500, lr = 0.004
I0522 15:09:38.330716 31742 solver.cpp:237] Iteration 142000, loss = 0.950018
I0522 15:09:38.330899 31742 solver.cpp:253]     Train net output #0: loss = 0.95002 (* 1 = 0.95002 loss)
I0522 15:09:38.330912 31742 sgd_solver.cpp:106] Iteration 142000, lr = 0.004
I0522 15:09:48.842558 31742 solver.cpp:237] Iteration 142500, loss = 1.24229
I0522 15:09:48.842594 31742 solver.cpp:253]     Train net output #0: loss = 1.24229 (* 1 = 1.24229 loss)
I0522 15:09:48.842609 31742 sgd_solver.cpp:106] Iteration 142500, lr = 0.004
I0522 15:09:59.324440 31742 solver.cpp:237] Iteration 143000, loss = 0.88551
I0522 15:09:59.324477 31742 solver.cpp:253]     Train net output #0: loss = 0.885511 (* 1 = 0.885511 loss)
I0522 15:09:59.324493 31742 sgd_solver.cpp:106] Iteration 143000, lr = 0.004
I0522 15:10:30.756474 31742 solver.cpp:237] Iteration 143500, loss = 0.933253
I0522 15:10:30.756681 31742 solver.cpp:253]     Train net output #0: loss = 0.933255 (* 1 = 0.933255 loss)
I0522 15:10:30.756697 31742 sgd_solver.cpp:106] Iteration 143500, lr = 0.004
I0522 15:10:41.239655 31742 solver.cpp:237] Iteration 144000, loss = 1.11487
I0522 15:10:41.239691 31742 solver.cpp:253]     Train net output #0: loss = 1.11487 (* 1 = 1.11487 loss)
I0522 15:10:41.239707 31742 sgd_solver.cpp:106] Iteration 144000, lr = 0.004
I0522 15:10:51.741794 31742 solver.cpp:237] Iteration 144500, loss = 1.19792
I0522 15:10:51.741842 31742 solver.cpp:253]     Train net output #0: loss = 1.19792 (* 1 = 1.19792 loss)
I0522 15:10:51.741855 31742 sgd_solver.cpp:106] Iteration 144500, lr = 0.004
I0522 15:11:02.226343 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_145000.caffemodel
I0522 15:11:02.282088 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_145000.solverstate
I0522 15:11:02.316236 31742 solver.cpp:237] Iteration 145000, loss = 0.992237
I0522 15:11:02.316287 31742 solver.cpp:253]     Train net output #0: loss = 0.992239 (* 1 = 0.992239 loss)
I0522 15:11:02.316303 31742 sgd_solver.cpp:106] Iteration 145000, lr = 0.004
I0522 15:11:12.824580 31742 solver.cpp:237] Iteration 145500, loss = 1.40375
I0522 15:11:12.824617 31742 solver.cpp:253]     Train net output #0: loss = 1.40375 (* 1 = 1.40375 loss)
I0522 15:11:12.824633 31742 sgd_solver.cpp:106] Iteration 145500, lr = 0.004
I0522 15:11:23.328070 31742 solver.cpp:237] Iteration 146000, loss = 1.60402
I0522 15:11:23.328122 31742 solver.cpp:253]     Train net output #0: loss = 1.60402 (* 1 = 1.60402 loss)
I0522 15:11:23.328136 31742 sgd_solver.cpp:106] Iteration 146000, lr = 0.004
I0522 15:11:33.823222 31742 solver.cpp:237] Iteration 146500, loss = 1.11619
I0522 15:11:33.823391 31742 solver.cpp:253]     Train net output #0: loss = 1.11619 (* 1 = 1.11619 loss)
I0522 15:11:33.823406 31742 sgd_solver.cpp:106] Iteration 146500, lr = 0.004
I0522 15:12:05.263476 31742 solver.cpp:237] Iteration 147000, loss = 1.24111
I0522 15:12:05.263662 31742 solver.cpp:253]     Train net output #0: loss = 1.24111 (* 1 = 1.24111 loss)
I0522 15:12:05.263677 31742 sgd_solver.cpp:106] Iteration 147000, lr = 0.004
I0522 15:12:15.779666 31742 solver.cpp:237] Iteration 147500, loss = 1.27282
I0522 15:12:15.779706 31742 solver.cpp:253]     Train net output #0: loss = 1.27282 (* 1 = 1.27282 loss)
I0522 15:12:15.779721 31742 sgd_solver.cpp:106] Iteration 147500, lr = 0.004
I0522 15:12:26.281992 31742 solver.cpp:237] Iteration 148000, loss = 1.19198
I0522 15:12:26.282028 31742 solver.cpp:253]     Train net output #0: loss = 1.19198 (* 1 = 1.19198 loss)
I0522 15:12:26.282044 31742 sgd_solver.cpp:106] Iteration 148000, lr = 0.004
I0522 15:12:36.783344 31742 solver.cpp:237] Iteration 148500, loss = 1.49006
I0522 15:12:36.783534 31742 solver.cpp:253]     Train net output #0: loss = 1.49006 (* 1 = 1.49006 loss)
I0522 15:12:36.783550 31742 sgd_solver.cpp:106] Iteration 148500, lr = 0.004
I0522 15:12:47.291421 31742 solver.cpp:237] Iteration 149000, loss = 0.787018
I0522 15:12:47.291462 31742 solver.cpp:253]     Train net output #0: loss = 0.78702 (* 1 = 0.78702 loss)
I0522 15:12:47.291478 31742 sgd_solver.cpp:106] Iteration 149000, lr = 0.004
I0522 15:12:57.794922 31742 solver.cpp:237] Iteration 149500, loss = 1.4491
I0522 15:12:57.794971 31742 solver.cpp:253]     Train net output #0: loss = 1.4491 (* 1 = 1.4491 loss)
I0522 15:12:57.794986 31742 sgd_solver.cpp:106] Iteration 149500, lr = 0.004
I0522 15:13:08.275823 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_150000.caffemodel
I0522 15:13:08.330763 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_150000.solverstate
I0522 15:13:08.358402 31742 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 15:13:57.657258 31742 solver.cpp:409]     Test net output #0: accuracy = 0.891954
I0522 15:13:57.657444 31742 solver.cpp:409]     Test net output #1: loss = 0.366544 (* 1 = 0.366544 loss)
I0522 15:14:18.573184 31742 solver.cpp:237] Iteration 150000, loss = 0.925505
I0522 15:14:18.573236 31742 solver.cpp:253]     Train net output #0: loss = 0.925506 (* 1 = 0.925506 loss)
I0522 15:14:18.573251 31742 sgd_solver.cpp:106] Iteration 150000, lr = 0.004
I0522 15:14:29.158982 31742 solver.cpp:237] Iteration 150500, loss = 1.17915
I0522 15:14:29.159154 31742 solver.cpp:253]     Train net output #0: loss = 1.17915 (* 1 = 1.17915 loss)
I0522 15:14:29.159168 31742 sgd_solver.cpp:106] Iteration 150500, lr = 0.004
I0522 15:14:39.743530 31742 solver.cpp:237] Iteration 151000, loss = 1.46961
I0522 15:14:39.743576 31742 solver.cpp:253]     Train net output #0: loss = 1.46961 (* 1 = 1.46961 loss)
I0522 15:14:39.743592 31742 sgd_solver.cpp:106] Iteration 151000, lr = 0.004
I0522 15:14:50.329175 31742 solver.cpp:237] Iteration 151500, loss = 1.09013
I0522 15:14:50.329212 31742 solver.cpp:253]     Train net output #0: loss = 1.09013 (* 1 = 1.09013 loss)
I0522 15:14:50.329226 31742 sgd_solver.cpp:106] Iteration 151500, lr = 0.004
I0522 15:15:00.931417 31742 solver.cpp:237] Iteration 152000, loss = 0.999117
I0522 15:15:00.931607 31742 solver.cpp:253]     Train net output #0: loss = 0.999119 (* 1 = 0.999119 loss)
I0522 15:15:00.931622 31742 sgd_solver.cpp:106] Iteration 152000, lr = 0.004
I0522 15:15:11.526760 31742 solver.cpp:237] Iteration 152500, loss = 1.17767
I0522 15:15:11.526795 31742 solver.cpp:253]     Train net output #0: loss = 1.17767 (* 1 = 1.17767 loss)
I0522 15:15:11.526809 31742 sgd_solver.cpp:106] Iteration 152500, lr = 0.004
I0522 15:15:22.116942 31742 solver.cpp:237] Iteration 153000, loss = 1.07401
I0522 15:15:22.116978 31742 solver.cpp:253]     Train net output #0: loss = 1.07401 (* 1 = 1.07401 loss)
I0522 15:15:22.116994 31742 sgd_solver.cpp:106] Iteration 153000, lr = 0.004
I0522 15:15:53.605057 31742 solver.cpp:237] Iteration 153500, loss = 1.23189
I0522 15:15:53.605244 31742 solver.cpp:253]     Train net output #0: loss = 1.23189 (* 1 = 1.23189 loss)
I0522 15:15:53.605259 31742 sgd_solver.cpp:106] Iteration 153500, lr = 0.004
I0522 15:16:04.206596 31742 solver.cpp:237] Iteration 154000, loss = 1.0228
I0522 15:16:04.206631 31742 solver.cpp:253]     Train net output #0: loss = 1.02281 (* 1 = 1.02281 loss)
I0522 15:16:04.206648 31742 sgd_solver.cpp:106] Iteration 154000, lr = 0.004
I0522 15:16:14.801643 31742 solver.cpp:237] Iteration 154500, loss = 1.1467
I0522 15:16:14.801678 31742 solver.cpp:253]     Train net output #0: loss = 1.1467 (* 1 = 1.1467 loss)
I0522 15:16:14.801697 31742 sgd_solver.cpp:106] Iteration 154500, lr = 0.004
I0522 15:16:25.373932 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_155000.caffemodel
I0522 15:16:25.426542 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_155000.solverstate
I0522 15:16:25.458978 31742 solver.cpp:237] Iteration 155000, loss = 0.86996
I0522 15:16:25.459020 31742 solver.cpp:253]     Train net output #0: loss = 0.869962 (* 1 = 0.869962 loss)
I0522 15:16:25.459043 31742 sgd_solver.cpp:106] Iteration 155000, lr = 0.004
I0522 15:16:36.057045 31742 solver.cpp:237] Iteration 155500, loss = 0.991991
I0522 15:16:36.057082 31742 solver.cpp:253]     Train net output #0: loss = 0.991993 (* 1 = 0.991993 loss)
I0522 15:16:36.057097 31742 sgd_solver.cpp:106] Iteration 155500, lr = 0.004
I0522 15:16:46.621867 31742 solver.cpp:237] Iteration 156000, loss = 1.26437
I0522 15:16:46.621915 31742 solver.cpp:253]     Train net output #0: loss = 1.26437 (* 1 = 1.26437 loss)
I0522 15:16:46.621932 31742 sgd_solver.cpp:106] Iteration 156000, lr = 0.004
I0522 15:16:57.149952 31742 solver.cpp:237] Iteration 156500, loss = 0.745632
I0522 15:16:57.150133 31742 solver.cpp:253]     Train net output #0: loss = 0.745634 (* 1 = 0.745634 loss)
I0522 15:16:57.150147 31742 sgd_solver.cpp:106] Iteration 156500, lr = 0.004
I0522 15:17:28.560508 31742 solver.cpp:237] Iteration 157000, loss = 1.04717
I0522 15:17:28.560699 31742 solver.cpp:253]     Train net output #0: loss = 1.04717 (* 1 = 1.04717 loss)
I0522 15:17:28.560715 31742 sgd_solver.cpp:106] Iteration 157000, lr = 0.004
I0522 15:17:39.156952 31742 solver.cpp:237] Iteration 157500, loss = 1.34119
I0522 15:17:39.157002 31742 solver.cpp:253]     Train net output #0: loss = 1.3412 (* 1 = 1.3412 loss)
I0522 15:17:39.157016 31742 sgd_solver.cpp:106] Iteration 157500, lr = 0.004
I0522 15:17:49.778978 31742 solver.cpp:237] Iteration 158000, loss = 1.11917
I0522 15:17:49.779014 31742 solver.cpp:253]     Train net output #0: loss = 1.11917 (* 1 = 1.11917 loss)
I0522 15:17:49.779031 31742 sgd_solver.cpp:106] Iteration 158000, lr = 0.004
I0522 15:18:00.379963 31742 solver.cpp:237] Iteration 158500, loss = 1.11832
I0522 15:18:00.380146 31742 solver.cpp:253]     Train net output #0: loss = 1.11832 (* 1 = 1.11832 loss)
I0522 15:18:00.380162 31742 sgd_solver.cpp:106] Iteration 158500, lr = 0.004
I0522 15:18:10.931846 31742 solver.cpp:237] Iteration 159000, loss = 1.17956
I0522 15:18:10.931884 31742 solver.cpp:253]     Train net output #0: loss = 1.17956 (* 1 = 1.17956 loss)
I0522 15:18:10.931896 31742 sgd_solver.cpp:106] Iteration 159000, lr = 0.004
I0522 15:18:21.491164 31742 solver.cpp:237] Iteration 159500, loss = 0.959994
I0522 15:18:21.491214 31742 solver.cpp:253]     Train net output #0: loss = 0.959995 (* 1 = 0.959995 loss)
I0522 15:18:21.491228 31742 sgd_solver.cpp:106] Iteration 159500, lr = 0.004
I0522 15:18:32.036144 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_160000.caffemodel
I0522 15:18:32.098114 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_160000.solverstate
I0522 15:18:32.123422 31742 solver.cpp:341] Iteration 160000, Testing net (#0)
I0522 15:19:42.646997 31742 solver.cpp:409]     Test net output #0: accuracy = 0.897079
I0522 15:19:42.647188 31742 solver.cpp:409]     Test net output #1: loss = 0.333182 (* 1 = 0.333182 loss)
I0522 15:20:03.553254 31742 solver.cpp:237] Iteration 160000, loss = 0.875015
I0522 15:20:03.553308 31742 solver.cpp:253]     Train net output #0: loss = 0.875017 (* 1 = 0.875017 loss)
I0522 15:20:03.553323 31742 sgd_solver.cpp:106] Iteration 160000, lr = 0.004
I0522 15:20:14.085124 31742 solver.cpp:237] Iteration 160500, loss = 1.25546
I0522 15:20:14.085299 31742 solver.cpp:253]     Train net output #0: loss = 1.25546 (* 1 = 1.25546 loss)
I0522 15:20:14.085314 31742 sgd_solver.cpp:106] Iteration 160500, lr = 0.004
I0522 15:20:24.600489 31742 solver.cpp:237] Iteration 161000, loss = 1.21283
I0522 15:20:24.600524 31742 solver.cpp:253]     Train net output #0: loss = 1.21283 (* 1 = 1.21283 loss)
I0522 15:20:24.600541 31742 sgd_solver.cpp:106] Iteration 161000, lr = 0.004
I0522 15:20:35.113898 31742 solver.cpp:237] Iteration 161500, loss = 1.23136
I0522 15:20:35.113947 31742 solver.cpp:253]     Train net output #0: loss = 1.23136 (* 1 = 1.23136 loss)
I0522 15:20:35.113962 31742 sgd_solver.cpp:106] Iteration 161500, lr = 0.004
I0522 15:20:45.643772 31742 solver.cpp:237] Iteration 162000, loss = 1.03957
I0522 15:20:45.643941 31742 solver.cpp:253]     Train net output #0: loss = 1.03957 (* 1 = 1.03957 loss)
I0522 15:20:45.643956 31742 sgd_solver.cpp:106] Iteration 162000, lr = 0.004
I0522 15:20:56.160111 31742 solver.cpp:237] Iteration 162500, loss = 1.24511
I0522 15:20:56.160162 31742 solver.cpp:253]     Train net output #0: loss = 1.24512 (* 1 = 1.24512 loss)
I0522 15:20:56.160176 31742 sgd_solver.cpp:106] Iteration 162500, lr = 0.004
I0522 15:21:06.669095 31742 solver.cpp:237] Iteration 163000, loss = 1.04224
I0522 15:21:06.669131 31742 solver.cpp:253]     Train net output #0: loss = 1.04224 (* 1 = 1.04224 loss)
I0522 15:21:06.669148 31742 sgd_solver.cpp:106] Iteration 163000, lr = 0.004
I0522 15:21:38.109748 31742 solver.cpp:237] Iteration 163500, loss = 1.37311
I0522 15:21:38.109948 31742 solver.cpp:253]     Train net output #0: loss = 1.37311 (* 1 = 1.37311 loss)
I0522 15:21:38.109963 31742 sgd_solver.cpp:106] Iteration 163500, lr = 0.004
I0522 15:21:48.630528 31742 solver.cpp:237] Iteration 164000, loss = 1.03185
I0522 15:21:48.630576 31742 solver.cpp:253]     Train net output #0: loss = 1.03186 (* 1 = 1.03186 loss)
I0522 15:21:48.630590 31742 sgd_solver.cpp:106] Iteration 164000, lr = 0.004
I0522 15:21:59.152979 31742 solver.cpp:237] Iteration 164500, loss = 1.08095
I0522 15:21:59.153017 31742 solver.cpp:253]     Train net output #0: loss = 1.08095 (* 1 = 1.08095 loss)
I0522 15:21:59.153031 31742 sgd_solver.cpp:106] Iteration 164500, lr = 0.004
I0522 15:22:09.673583 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_165000.caffemodel
I0522 15:22:09.727365 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_165000.solverstate
I0522 15:22:09.759351 31742 solver.cpp:237] Iteration 165000, loss = 0.989637
I0522 15:22:09.759397 31742 solver.cpp:253]     Train net output #0: loss = 0.989639 (* 1 = 0.989639 loss)
I0522 15:22:09.759412 31742 sgd_solver.cpp:106] Iteration 165000, lr = 0.004
I0522 15:22:20.272801 31742 solver.cpp:237] Iteration 165500, loss = 1.11219
I0522 15:22:20.272837 31742 solver.cpp:253]     Train net output #0: loss = 1.11219 (* 1 = 1.11219 loss)
I0522 15:22:20.272853 31742 sgd_solver.cpp:106] Iteration 165500, lr = 0.004
I0522 15:22:30.785936 31742 solver.cpp:237] Iteration 166000, loss = 1.21362
I0522 15:22:30.785984 31742 solver.cpp:253]     Train net output #0: loss = 1.21362 (* 1 = 1.21362 loss)
I0522 15:22:30.785998 31742 sgd_solver.cpp:106] Iteration 166000, lr = 0.004
I0522 15:22:41.295321 31742 solver.cpp:237] Iteration 166500, loss = 1.11708
I0522 15:22:41.295514 31742 solver.cpp:253]     Train net output #0: loss = 1.11709 (* 1 = 1.11709 loss)
I0522 15:22:41.295529 31742 sgd_solver.cpp:106] Iteration 166500, lr = 0.004
I0522 15:23:12.708681 31742 solver.cpp:237] Iteration 167000, loss = 1.04219
I0522 15:23:12.708873 31742 solver.cpp:253]     Train net output #0: loss = 1.0422 (* 1 = 1.0422 loss)
I0522 15:23:12.708889 31742 sgd_solver.cpp:106] Iteration 167000, lr = 0.004
I0522 15:23:23.218302 31742 solver.cpp:237] Iteration 167500, loss = 1.03536
I0522 15:23:23.218350 31742 solver.cpp:253]     Train net output #0: loss = 1.03537 (* 1 = 1.03537 loss)
I0522 15:23:23.218364 31742 sgd_solver.cpp:106] Iteration 167500, lr = 0.004
I0522 15:23:33.726022 31742 solver.cpp:237] Iteration 168000, loss = 1.32079
I0522 15:23:33.726058 31742 solver.cpp:253]     Train net output #0: loss = 1.32079 (* 1 = 1.32079 loss)
I0522 15:23:33.726070 31742 sgd_solver.cpp:106] Iteration 168000, lr = 0.004
I0522 15:23:44.251113 31742 solver.cpp:237] Iteration 168500, loss = 0.747371
I0522 15:23:44.251282 31742 solver.cpp:253]     Train net output #0: loss = 0.747372 (* 1 = 0.747372 loss)
I0522 15:23:44.251297 31742 sgd_solver.cpp:106] Iteration 168500, lr = 0.004
I0522 15:23:54.757421 31742 solver.cpp:237] Iteration 169000, loss = 1.21396
I0522 15:23:54.757468 31742 solver.cpp:253]     Train net output #0: loss = 1.21396 (* 1 = 1.21396 loss)
I0522 15:23:54.757484 31742 sgd_solver.cpp:106] Iteration 169000, lr = 0.004
I0522 15:24:05.269434 31742 solver.cpp:237] Iteration 169500, loss = 1.2474
I0522 15:24:05.269470 31742 solver.cpp:253]     Train net output #0: loss = 1.2474 (* 1 = 1.2474 loss)
I0522 15:24:05.269486 31742 sgd_solver.cpp:106] Iteration 169500, lr = 0.004
I0522 15:24:15.751329 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_170000.caffemodel
I0522 15:24:15.803779 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_170000.solverstate
I0522 15:24:15.829246 31742 solver.cpp:341] Iteration 170000, Testing net (#0)
I0522 15:25:05.433166 31742 solver.cpp:409]     Test net output #0: accuracy = 0.893373
I0522 15:25:05.433352 31742 solver.cpp:409]     Test net output #1: loss = 0.377316 (* 1 = 0.377316 loss)
I0522 15:25:26.333192 31742 solver.cpp:237] Iteration 170000, loss = 0.974071
I0522 15:25:26.333243 31742 solver.cpp:253]     Train net output #0: loss = 0.974073 (* 1 = 0.974073 loss)
I0522 15:25:26.333258 31742 sgd_solver.cpp:106] Iteration 170000, lr = 0.004
I0522 15:25:36.855381 31742 solver.cpp:237] Iteration 170500, loss = 1.03881
I0522 15:25:36.855557 31742 solver.cpp:253]     Train net output #0: loss = 1.03882 (* 1 = 1.03882 loss)
I0522 15:25:36.855571 31742 sgd_solver.cpp:106] Iteration 170500, lr = 0.004
I0522 15:25:47.368851 31742 solver.cpp:237] Iteration 171000, loss = 0.793529
I0522 15:25:47.368887 31742 solver.cpp:253]     Train net output #0: loss = 0.79353 (* 1 = 0.79353 loss)
I0522 15:25:47.368904 31742 sgd_solver.cpp:106] Iteration 171000, lr = 0.004
I0522 15:25:57.884837 31742 solver.cpp:237] Iteration 171500, loss = 1.11981
I0522 15:25:57.884886 31742 solver.cpp:253]     Train net output #0: loss = 1.11981 (* 1 = 1.11981 loss)
I0522 15:25:57.884899 31742 sgd_solver.cpp:106] Iteration 171500, lr = 0.004
I0522 15:26:08.402353 31742 solver.cpp:237] Iteration 172000, loss = 1.2883
I0522 15:26:08.402520 31742 solver.cpp:253]     Train net output #0: loss = 1.2883 (* 1 = 1.2883 loss)
I0522 15:26:08.402534 31742 sgd_solver.cpp:106] Iteration 172000, lr = 0.004
I0522 15:26:18.919961 31742 solver.cpp:237] Iteration 172500, loss = 1.13155
I0522 15:26:18.920007 31742 solver.cpp:253]     Train net output #0: loss = 1.13155 (* 1 = 1.13155 loss)
I0522 15:26:18.920022 31742 sgd_solver.cpp:106] Iteration 172500, lr = 0.004
I0522 15:26:29.435554 31742 solver.cpp:237] Iteration 173000, loss = 1.18995
I0522 15:26:29.435590 31742 solver.cpp:253]     Train net output #0: loss = 1.18995 (* 1 = 1.18995 loss)
I0522 15:26:29.435606 31742 sgd_solver.cpp:106] Iteration 173000, lr = 0.004
I0522 15:27:00.888649 31742 solver.cpp:237] Iteration 173500, loss = 1.051
I0522 15:27:00.888838 31742 solver.cpp:253]     Train net output #0: loss = 1.051 (* 1 = 1.051 loss)
I0522 15:27:00.888852 31742 sgd_solver.cpp:106] Iteration 173500, lr = 0.004
I0522 15:27:11.438153 31742 solver.cpp:237] Iteration 174000, loss = 1.06129
I0522 15:27:11.438201 31742 solver.cpp:253]     Train net output #0: loss = 1.06129 (* 1 = 1.06129 loss)
I0522 15:27:11.438217 31742 sgd_solver.cpp:106] Iteration 174000, lr = 0.004
I0522 15:27:21.966648 31742 solver.cpp:237] Iteration 174500, loss = 0.926529
I0522 15:27:21.966684 31742 solver.cpp:253]     Train net output #0: loss = 0.926531 (* 1 = 0.926531 loss)
I0522 15:27:21.966697 31742 sgd_solver.cpp:106] Iteration 174500, lr = 0.004
I0522 15:27:32.492168 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_175000.caffemodel
I0522 15:27:32.546627 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_175000.solverstate
I0522 15:27:32.580401 31742 solver.cpp:237] Iteration 175000, loss = 1.21052
I0522 15:27:32.580452 31742 solver.cpp:253]     Train net output #0: loss = 1.21052 (* 1 = 1.21052 loss)
I0522 15:27:32.580466 31742 sgd_solver.cpp:106] Iteration 175000, lr = 0.004
I0522 15:27:43.125605 31742 solver.cpp:237] Iteration 175500, loss = 1.18558
I0522 15:27:43.125641 31742 solver.cpp:253]     Train net output #0: loss = 1.18559 (* 1 = 1.18559 loss)
I0522 15:27:43.125658 31742 sgd_solver.cpp:106] Iteration 175500, lr = 0.004
I0522 15:27:53.662874 31742 solver.cpp:237] Iteration 176000, loss = 1.20977
I0522 15:27:53.662909 31742 solver.cpp:253]     Train net output #0: loss = 1.20977 (* 1 = 1.20977 loss)
I0522 15:27:53.662925 31742 sgd_solver.cpp:106] Iteration 176000, lr = 0.004
I0522 15:28:04.212291 31742 solver.cpp:237] Iteration 176500, loss = 1.2599
I0522 15:28:04.212496 31742 solver.cpp:253]     Train net output #0: loss = 1.2599 (* 1 = 1.2599 loss)
I0522 15:28:04.212510 31742 sgd_solver.cpp:106] Iteration 176500, lr = 0.004
I0522 15:28:35.644628 31742 solver.cpp:237] Iteration 177000, loss = 1.39735
I0522 15:28:35.644819 31742 solver.cpp:253]     Train net output #0: loss = 1.39735 (* 1 = 1.39735 loss)
I0522 15:28:35.644835 31742 sgd_solver.cpp:106] Iteration 177000, lr = 0.004
I0522 15:28:46.184978 31742 solver.cpp:237] Iteration 177500, loss = 1.05805
I0522 15:28:46.185022 31742 solver.cpp:253]     Train net output #0: loss = 1.05805 (* 1 = 1.05805 loss)
I0522 15:28:46.185039 31742 sgd_solver.cpp:106] Iteration 177500, lr = 0.004
I0522 15:28:56.744338 31742 solver.cpp:237] Iteration 178000, loss = 1.07627
I0522 15:28:56.744374 31742 solver.cpp:253]     Train net output #0: loss = 1.07627 (* 1 = 1.07627 loss)
I0522 15:28:56.744392 31742 sgd_solver.cpp:106] Iteration 178000, lr = 0.004
I0522 15:29:07.279992 31742 solver.cpp:237] Iteration 178500, loss = 1.05865
I0522 15:29:07.280159 31742 solver.cpp:253]     Train net output #0: loss = 1.05866 (* 1 = 1.05866 loss)
I0522 15:29:07.280174 31742 sgd_solver.cpp:106] Iteration 178500, lr = 0.004
I0522 15:29:17.821528 31742 solver.cpp:237] Iteration 179000, loss = 1.02779
I0522 15:29:17.821575 31742 solver.cpp:253]     Train net output #0: loss = 1.02779 (* 1 = 1.02779 loss)
I0522 15:29:17.821591 31742 sgd_solver.cpp:106] Iteration 179000, lr = 0.004
I0522 15:29:28.355576 31742 solver.cpp:237] Iteration 179500, loss = 0.889173
I0522 15:29:28.355612 31742 solver.cpp:253]     Train net output #0: loss = 0.889174 (* 1 = 0.889174 loss)
I0522 15:29:28.355629 31742 sgd_solver.cpp:106] Iteration 179500, lr = 0.004
I0522 15:29:38.878376 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_180000.caffemodel
I0522 15:29:38.932857 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_180000.solverstate
I0522 15:29:38.960693 31742 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 15:30:49.437433 31742 solver.cpp:409]     Test net output #0: accuracy = 0.895312
I0522 15:30:49.437621 31742 solver.cpp:409]     Test net output #1: loss = 0.323069 (* 1 = 0.323069 loss)
I0522 15:31:10.305248 31742 solver.cpp:237] Iteration 180000, loss = 1.06919
I0522 15:31:10.305300 31742 solver.cpp:253]     Train net output #0: loss = 1.06919 (* 1 = 1.06919 loss)
I0522 15:31:10.305320 31742 sgd_solver.cpp:106] Iteration 180000, lr = 0.004
I0522 15:31:20.887099 31742 solver.cpp:237] Iteration 180500, loss = 1.33255
I0522 15:31:20.887286 31742 solver.cpp:253]     Train net output #0: loss = 1.33256 (* 1 = 1.33256 loss)
I0522 15:31:20.887302 31742 sgd_solver.cpp:106] Iteration 180500, lr = 0.004
I0522 15:31:31.466032 31742 solver.cpp:237] Iteration 181000, loss = 1.33732
I0522 15:31:31.466066 31742 solver.cpp:253]     Train net output #0: loss = 1.33732 (* 1 = 1.33732 loss)
I0522 15:31:31.466083 31742 sgd_solver.cpp:106] Iteration 181000, lr = 0.004
I0522 15:31:42.052971 31742 solver.cpp:237] Iteration 181500, loss = 1.14546
I0522 15:31:42.053020 31742 solver.cpp:253]     Train net output #0: loss = 1.14546 (* 1 = 1.14546 loss)
I0522 15:31:42.053035 31742 sgd_solver.cpp:106] Iteration 181500, lr = 0.004
I0522 15:31:52.618460 31742 solver.cpp:237] Iteration 182000, loss = 1.15525
I0522 15:31:52.618643 31742 solver.cpp:253]     Train net output #0: loss = 1.15525 (* 1 = 1.15525 loss)
I0522 15:31:52.618659 31742 sgd_solver.cpp:106] Iteration 182000, lr = 0.004
I0522 15:32:03.198611 31742 solver.cpp:237] Iteration 182500, loss = 1.05238
I0522 15:32:03.198647 31742 solver.cpp:253]     Train net output #0: loss = 1.05239 (* 1 = 1.05239 loss)
I0522 15:32:03.198662 31742 sgd_solver.cpp:106] Iteration 182500, lr = 0.004
I0522 15:32:13.764175 31742 solver.cpp:237] Iteration 183000, loss = 1.15266
I0522 15:32:13.764216 31742 solver.cpp:253]     Train net output #0: loss = 1.15266 (* 1 = 1.15266 loss)
I0522 15:32:13.764230 31742 sgd_solver.cpp:106] Iteration 183000, lr = 0.004
I0522 15:32:45.200323 31742 solver.cpp:237] Iteration 183500, loss = 1.24431
I0522 15:32:45.200517 31742 solver.cpp:253]     Train net output #0: loss = 1.24431 (* 1 = 1.24431 loss)
I0522 15:32:45.200531 31742 sgd_solver.cpp:106] Iteration 183500, lr = 0.004
I0522 15:32:55.773419 31742 solver.cpp:237] Iteration 184000, loss = 1.17744
I0522 15:32:55.773463 31742 solver.cpp:253]     Train net output #0: loss = 1.17744 (* 1 = 1.17744 loss)
I0522 15:32:55.773478 31742 sgd_solver.cpp:106] Iteration 184000, lr = 0.004
I0522 15:33:06.346678 31742 solver.cpp:237] Iteration 184500, loss = 1.10371
I0522 15:33:06.346715 31742 solver.cpp:253]     Train net output #0: loss = 1.10371 (* 1 = 1.10371 loss)
I0522 15:33:06.346730 31742 sgd_solver.cpp:106] Iteration 184500, lr = 0.004
I0522 15:33:16.921308 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_185000.caffemodel
I0522 15:33:16.974164 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_185000.solverstate
I0522 15:33:17.006224 31742 solver.cpp:237] Iteration 185000, loss = 0.989639
I0522 15:33:17.006265 31742 solver.cpp:253]     Train net output #0: loss = 0.989641 (* 1 = 0.989641 loss)
I0522 15:33:17.006286 31742 sgd_solver.cpp:106] Iteration 185000, lr = 0.004
I0522 15:33:27.586833 31742 solver.cpp:237] Iteration 185500, loss = 0.951461
I0522 15:33:27.586881 31742 solver.cpp:253]     Train net output #0: loss = 0.951463 (* 1 = 0.951463 loss)
I0522 15:33:27.586895 31742 sgd_solver.cpp:106] Iteration 185500, lr = 0.004
I0522 15:33:38.151069 31742 solver.cpp:237] Iteration 186000, loss = 1.06059
I0522 15:33:38.151105 31742 solver.cpp:253]     Train net output #0: loss = 1.06059 (* 1 = 1.06059 loss)
I0522 15:33:38.151119 31742 sgd_solver.cpp:106] Iteration 186000, lr = 0.004
I0522 15:33:48.739083 31742 solver.cpp:237] Iteration 186500, loss = 1.14756
I0522 15:33:48.739271 31742 solver.cpp:253]     Train net output #0: loss = 1.14756 (* 1 = 1.14756 loss)
I0522 15:33:48.739289 31742 sgd_solver.cpp:106] Iteration 186500, lr = 0.004
I0522 15:34:20.180611 31742 solver.cpp:237] Iteration 187000, loss = 1.33219
I0522 15:34:20.180804 31742 solver.cpp:253]     Train net output #0: loss = 1.33219 (* 1 = 1.33219 loss)
I0522 15:34:20.180817 31742 sgd_solver.cpp:106] Iteration 187000, lr = 0.004
I0522 15:34:30.768540 31742 solver.cpp:237] Iteration 187500, loss = 1.58562
I0522 15:34:30.768576 31742 solver.cpp:253]     Train net output #0: loss = 1.58563 (* 1 = 1.58563 loss)
I0522 15:34:30.768591 31742 sgd_solver.cpp:106] Iteration 187500, lr = 0.004
I0522 15:34:41.356714 31742 solver.cpp:237] Iteration 188000, loss = 1.17005
I0522 15:34:41.356760 31742 solver.cpp:253]     Train net output #0: loss = 1.17006 (* 1 = 1.17006 loss)
I0522 15:34:41.356773 31742 sgd_solver.cpp:106] Iteration 188000, lr = 0.004
I0522 15:34:51.935794 31742 solver.cpp:237] Iteration 188500, loss = 1.08957
I0522 15:34:51.935977 31742 solver.cpp:253]     Train net output #0: loss = 1.08957 (* 1 = 1.08957 loss)
I0522 15:34:51.935992 31742 sgd_solver.cpp:106] Iteration 188500, lr = 0.004
I0522 15:35:02.510828 31742 solver.cpp:237] Iteration 189000, loss = 1.06379
I0522 15:35:02.510876 31742 solver.cpp:253]     Train net output #0: loss = 1.06379 (* 1 = 1.06379 loss)
I0522 15:35:02.510890 31742 sgd_solver.cpp:106] Iteration 189000, lr = 0.004
I0522 15:35:13.089509 31742 solver.cpp:237] Iteration 189500, loss = 1.28538
I0522 15:35:13.089545 31742 solver.cpp:253]     Train net output #0: loss = 1.28538 (* 1 = 1.28538 loss)
I0522 15:35:13.089558 31742 sgd_solver.cpp:106] Iteration 189500, lr = 0.004
I0522 15:35:23.645678 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_190000.caffemodel
I0522 15:35:23.697929 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_190000.solverstate
I0522 15:35:23.723100 31742 solver.cpp:341] Iteration 190000, Testing net (#0)
I0522 15:36:12.957063 31742 solver.cpp:409]     Test net output #0: accuracy = 0.898771
I0522 15:36:12.957254 31742 solver.cpp:409]     Test net output #1: loss = 0.321465 (* 1 = 0.321465 loss)
I0522 15:36:33.810302 31742 solver.cpp:237] Iteration 190000, loss = 1.01242
I0522 15:36:33.810354 31742 solver.cpp:253]     Train net output #0: loss = 1.01242 (* 1 = 1.01242 loss)
I0522 15:36:33.810369 31742 sgd_solver.cpp:106] Iteration 190000, lr = 0.004
I0522 15:36:44.333096 31742 solver.cpp:237] Iteration 190500, loss = 0.789609
I0522 15:36:44.333281 31742 solver.cpp:253]     Train net output #0: loss = 0.789611 (* 1 = 0.789611 loss)
I0522 15:36:44.333295 31742 sgd_solver.cpp:106] Iteration 190500, lr = 0.004
I0522 15:36:54.833485 31742 solver.cpp:237] Iteration 191000, loss = 0.866657
I0522 15:36:54.833521 31742 solver.cpp:253]     Train net output #0: loss = 0.866659 (* 1 = 0.866659 loss)
I0522 15:36:54.833536 31742 sgd_solver.cpp:106] Iteration 191000, lr = 0.004
I0522 15:37:05.353428 31742 solver.cpp:237] Iteration 191500, loss = 1.02753
I0522 15:37:05.353464 31742 solver.cpp:253]     Train net output #0: loss = 1.02753 (* 1 = 1.02753 loss)
I0522 15:37:05.353479 31742 sgd_solver.cpp:106] Iteration 191500, lr = 0.004
I0522 15:37:15.870714 31742 solver.cpp:237] Iteration 192000, loss = 1.14604
I0522 15:37:15.870898 31742 solver.cpp:253]     Train net output #0: loss = 1.14604 (* 1 = 1.14604 loss)
I0522 15:37:15.870911 31742 sgd_solver.cpp:106] Iteration 192000, lr = 0.004
I0522 15:37:26.386955 31742 solver.cpp:237] Iteration 192500, loss = 1.1503
I0522 15:37:26.386991 31742 solver.cpp:253]     Train net output #0: loss = 1.1503 (* 1 = 1.1503 loss)
I0522 15:37:26.387006 31742 sgd_solver.cpp:106] Iteration 192500, lr = 0.004
I0522 15:37:36.911378 31742 solver.cpp:237] Iteration 193000, loss = 1.14401
I0522 15:37:36.911429 31742 solver.cpp:253]     Train net output #0: loss = 1.14401 (* 1 = 1.14401 loss)
I0522 15:37:36.911443 31742 sgd_solver.cpp:106] Iteration 193000, lr = 0.004
I0522 15:38:08.266671 31742 solver.cpp:237] Iteration 193500, loss = 1.05043
I0522 15:38:08.266868 31742 solver.cpp:253]     Train net output #0: loss = 1.05044 (* 1 = 1.05044 loss)
I0522 15:38:08.266886 31742 sgd_solver.cpp:106] Iteration 193500, lr = 0.004
I0522 15:38:18.788802 31742 solver.cpp:237] Iteration 194000, loss = 0.976047
I0522 15:38:18.788839 31742 solver.cpp:253]     Train net output #0: loss = 0.976048 (* 1 = 0.976048 loss)
I0522 15:38:18.788854 31742 sgd_solver.cpp:106] Iteration 194000, lr = 0.004
I0522 15:38:29.296489 31742 solver.cpp:237] Iteration 194500, loss = 1.13262
I0522 15:38:29.296535 31742 solver.cpp:253]     Train net output #0: loss = 1.13262 (* 1 = 1.13262 loss)
I0522 15:38:29.296550 31742 sgd_solver.cpp:106] Iteration 194500, lr = 0.004
I0522 15:38:39.795199 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_195000.caffemodel
I0522 15:38:39.847096 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_195000.solverstate
I0522 15:38:39.878950 31742 solver.cpp:237] Iteration 195000, loss = 1.27325
I0522 15:38:39.878995 31742 solver.cpp:253]     Train net output #0: loss = 1.27325 (* 1 = 1.27325 loss)
I0522 15:38:39.879011 31742 sgd_solver.cpp:106] Iteration 195000, lr = 0.004
I0522 15:38:50.389387 31742 solver.cpp:237] Iteration 195500, loss = 1.42857
I0522 15:38:50.389436 31742 solver.cpp:253]     Train net output #0: loss = 1.42857 (* 1 = 1.42857 loss)
I0522 15:38:50.389449 31742 sgd_solver.cpp:106] Iteration 195500, lr = 0.004
I0522 15:39:00.901264 31742 solver.cpp:237] Iteration 196000, loss = 1.94916
I0522 15:39:00.901300 31742 solver.cpp:253]     Train net output #0: loss = 1.94916 (* 1 = 1.94916 loss)
I0522 15:39:00.901312 31742 sgd_solver.cpp:106] Iteration 196000, lr = 0.004
I0522 15:39:11.411344 31742 solver.cpp:237] Iteration 196500, loss = 1.05887
I0522 15:39:11.411530 31742 solver.cpp:253]     Train net output #0: loss = 1.05887 (* 1 = 1.05887 loss)
I0522 15:39:11.411545 31742 sgd_solver.cpp:106] Iteration 196500, lr = 0.004
I0522 15:39:42.801337 31742 solver.cpp:237] Iteration 197000, loss = 1.12311
I0522 15:39:42.801528 31742 solver.cpp:253]     Train net output #0: loss = 1.12311 (* 1 = 1.12311 loss)
I0522 15:39:42.801542 31742 sgd_solver.cpp:106] Iteration 197000, lr = 0.004
I0522 15:39:53.325930 31742 solver.cpp:237] Iteration 197500, loss = 1.20305
I0522 15:39:53.325965 31742 solver.cpp:253]     Train net output #0: loss = 1.20305 (* 1 = 1.20305 loss)
I0522 15:39:53.325979 31742 sgd_solver.cpp:106] Iteration 197500, lr = 0.004
I0522 15:40:03.846071 31742 solver.cpp:237] Iteration 198000, loss = 1.30151
I0522 15:40:03.846117 31742 solver.cpp:253]     Train net output #0: loss = 1.30151 (* 1 = 1.30151 loss)
I0522 15:40:03.846132 31742 sgd_solver.cpp:106] Iteration 198000, lr = 0.004
I0522 15:40:14.361937 31742 solver.cpp:237] Iteration 198500, loss = 1.23846
I0522 15:40:14.362121 31742 solver.cpp:253]     Train net output #0: loss = 1.23847 (* 1 = 1.23847 loss)
I0522 15:40:14.362134 31742 sgd_solver.cpp:106] Iteration 198500, lr = 0.004
I0522 15:40:24.879797 31742 solver.cpp:237] Iteration 199000, loss = 1.273
I0522 15:40:24.879833 31742 solver.cpp:253]     Train net output #0: loss = 1.27301 (* 1 = 1.27301 loss)
I0522 15:40:24.879848 31742 sgd_solver.cpp:106] Iteration 199000, lr = 0.004
I0522 15:40:35.393062 31742 solver.cpp:237] Iteration 199500, loss = 1.35015
I0522 15:40:35.393101 31742 solver.cpp:253]     Train net output #0: loss = 1.35015 (* 1 = 1.35015 loss)
I0522 15:40:35.393115 31742 sgd_solver.cpp:106] Iteration 199500, lr = 0.004
I0522 15:40:45.886425 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_200000.caffemodel
I0522 15:40:45.940948 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_200000.solverstate
I0522 15:40:45.968425 31742 solver.cpp:341] Iteration 200000, Testing net (#0)
I0522 15:41:56.370234 31742 solver.cpp:409]     Test net output #0: accuracy = 0.900618
I0522 15:41:56.370430 31742 solver.cpp:409]     Test net output #1: loss = 0.327632 (* 1 = 0.327632 loss)
I0522 15:42:17.254811 31742 solver.cpp:237] Iteration 200000, loss = 1.12186
I0522 15:42:17.254863 31742 solver.cpp:253]     Train net output #0: loss = 1.12187 (* 1 = 1.12187 loss)
I0522 15:42:17.254878 31742 sgd_solver.cpp:106] Iteration 200000, lr = 0.004
I0522 15:42:27.774339 31742 solver.cpp:237] Iteration 200500, loss = 1.03428
I0522 15:42:27.774535 31742 solver.cpp:253]     Train net output #0: loss = 1.03428 (* 1 = 1.03428 loss)
I0522 15:42:27.774549 31742 sgd_solver.cpp:106] Iteration 200500, lr = 0.004
I0522 15:42:38.285445 31742 solver.cpp:237] Iteration 201000, loss = 0.945164
I0522 15:42:38.285496 31742 solver.cpp:253]     Train net output #0: loss = 0.945165 (* 1 = 0.945165 loss)
I0522 15:42:38.285511 31742 sgd_solver.cpp:106] Iteration 201000, lr = 0.004
I0522 15:42:48.805704 31742 solver.cpp:237] Iteration 201500, loss = 1.14879
I0522 15:42:48.805740 31742 solver.cpp:253]     Train net output #0: loss = 1.14879 (* 1 = 1.14879 loss)
I0522 15:42:48.805755 31742 sgd_solver.cpp:106] Iteration 201500, lr = 0.004
I0522 15:42:59.342281 31742 solver.cpp:237] Iteration 202000, loss = 0.96731
I0522 15:42:59.342468 31742 solver.cpp:253]     Train net output #0: loss = 0.967312 (* 1 = 0.967312 loss)
I0522 15:42:59.342483 31742 sgd_solver.cpp:106] Iteration 202000, lr = 0.004
I0522 15:43:09.876111 31742 solver.cpp:237] Iteration 202500, loss = 1.2612
I0522 15:43:09.876147 31742 solver.cpp:253]     Train net output #0: loss = 1.2612 (* 1 = 1.2612 loss)
I0522 15:43:09.876163 31742 sgd_solver.cpp:106] Iteration 202500, lr = 0.004
I0522 15:43:20.403882 31742 solver.cpp:237] Iteration 203000, loss = 1.40363
I0522 15:43:20.403918 31742 solver.cpp:253]     Train net output #0: loss = 1.40363 (* 1 = 1.40363 loss)
I0522 15:43:20.403933 31742 sgd_solver.cpp:106] Iteration 203000, lr = 0.004
I0522 15:43:51.826153 31742 solver.cpp:237] Iteration 203500, loss = 1.13954
I0522 15:43:51.826354 31742 solver.cpp:253]     Train net output #0: loss = 1.13954 (* 1 = 1.13954 loss)
I0522 15:43:51.826367 31742 sgd_solver.cpp:106] Iteration 203500, lr = 0.004
I0522 15:44:02.352090 31742 solver.cpp:237] Iteration 204000, loss = 1.04675
I0522 15:44:02.352126 31742 solver.cpp:253]     Train net output #0: loss = 1.04675 (* 1 = 1.04675 loss)
I0522 15:44:02.352140 31742 sgd_solver.cpp:106] Iteration 204000, lr = 0.004
I0522 15:44:12.870414 31742 solver.cpp:237] Iteration 204500, loss = 1.56963
I0522 15:44:12.870457 31742 solver.cpp:253]     Train net output #0: loss = 1.56963 (* 1 = 1.56963 loss)
I0522 15:44:12.870472 31742 sgd_solver.cpp:106] Iteration 204500, lr = 0.004
I0522 15:44:23.385056 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_205000.caffemodel
I0522 15:44:23.439294 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_205000.solverstate
I0522 15:44:23.471263 31742 solver.cpp:237] Iteration 205000, loss = 1.14266
I0522 15:44:23.471308 31742 solver.cpp:253]     Train net output #0: loss = 1.14266 (* 1 = 1.14266 loss)
I0522 15:44:23.471326 31742 sgd_solver.cpp:106] Iteration 205000, lr = 0.004
I0522 15:44:33.999342 31742 solver.cpp:237] Iteration 205500, loss = 1.27797
I0522 15:44:33.999378 31742 solver.cpp:253]     Train net output #0: loss = 1.27797 (* 1 = 1.27797 loss)
I0522 15:44:33.999392 31742 sgd_solver.cpp:106] Iteration 205500, lr = 0.004
I0522 15:44:44.518952 31742 solver.cpp:237] Iteration 206000, loss = 0.867908
I0522 15:44:44.518996 31742 solver.cpp:253]     Train net output #0: loss = 0.86791 (* 1 = 0.86791 loss)
I0522 15:44:44.519009 31742 sgd_solver.cpp:106] Iteration 206000, lr = 0.004
I0522 15:44:55.046298 31742 solver.cpp:237] Iteration 206500, loss = 1.02802
I0522 15:44:55.046474 31742 solver.cpp:253]     Train net output #0: loss = 1.02802 (* 1 = 1.02802 loss)
I0522 15:44:55.046489 31742 sgd_solver.cpp:106] Iteration 206500, lr = 0.004
I0522 15:45:26.431282 31742 solver.cpp:237] Iteration 207000, loss = 1.24077
I0522 15:45:26.431495 31742 solver.cpp:253]     Train net output #0: loss = 1.24077 (* 1 = 1.24077 loss)
I0522 15:45:26.431509 31742 sgd_solver.cpp:106] Iteration 207000, lr = 0.004
I0522 15:45:36.963018 31742 solver.cpp:237] Iteration 207500, loss = 0.891325
I0522 15:45:36.963053 31742 solver.cpp:253]     Train net output #0: loss = 0.891327 (* 1 = 0.891327 loss)
I0522 15:45:36.963068 31742 sgd_solver.cpp:106] Iteration 207500, lr = 0.004
I0522 15:45:47.494663 31742 solver.cpp:237] Iteration 208000, loss = 1.09167
I0522 15:45:47.494699 31742 solver.cpp:253]     Train net output #0: loss = 1.09167 (* 1 = 1.09167 loss)
I0522 15:45:47.494714 31742 sgd_solver.cpp:106] Iteration 208000, lr = 0.004
I0522 15:45:58.021811 31742 solver.cpp:237] Iteration 208500, loss = 1.21166
I0522 15:45:58.022007 31742 solver.cpp:253]     Train net output #0: loss = 1.21166 (* 1 = 1.21166 loss)
I0522 15:45:58.022022 31742 sgd_solver.cpp:106] Iteration 208500, lr = 0.004
I0522 15:46:08.540995 31742 solver.cpp:237] Iteration 209000, loss = 1.51726
I0522 15:46:08.541031 31742 solver.cpp:253]     Train net output #0: loss = 1.51727 (* 1 = 1.51727 loss)
I0522 15:46:08.541046 31742 sgd_solver.cpp:106] Iteration 209000, lr = 0.004
I0522 15:46:19.054430 31742 solver.cpp:237] Iteration 209500, loss = 1.12239
I0522 15:46:19.054473 31742 solver.cpp:253]     Train net output #0: loss = 1.12239 (* 1 = 1.12239 loss)
I0522 15:46:19.054487 31742 sgd_solver.cpp:106] Iteration 209500, lr = 0.004
I0522 15:46:29.555379 31742 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_210000.caffemodel
I0522 15:46:29.607996 31742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0040_2016-05-20T15.48.59.949399_iter_210000.solverstate
I0522 15:46:29.633616 31742 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 15:47:19.203974 31742 solver.cpp:409]     Test net output #0: accuracy = 0.896418
I0522 15:47:19.204166 31742 solver.cpp:409]     Test net output #1: loss = 0.318206 (* 1 = 0.318206 loss)
I0522 15:47:40.100687 31742 solver.cpp:237] Iteration 210000, loss = 0.963876
I0522 15:47:40.100741 31742 solver.cpp:253]     Train net output #0: loss = 0.963878 (* 1 = 0.963878 loss)
I0522 15:47:40.100756 31742 sgd_solver.cpp:106] Iteration 210000, lr = 0.004
I0522 15:47:50.686198 31742 solver.cpp:237] Iteration 210500, loss = 0.574135
I0522 15:47:50.686380 31742 solver.cpp:253]     Train net output #0: loss = 0.574137 (* 1 = 0.574137 loss)
I0522 15:47:50.686395 31742 sgd_solver.cpp:106] Iteration 210500, lr = 0.004
I0522 15:48:01.279431 31742 solver.cpp:237] Iteration 211000, loss = 1.43226
I0522 15:48:01.279479 31742 solver.cpp:253]     Train net output #0: loss = 1.43226 (* 1 = 1.43226 loss)
I0522 15:48:01.279495 31742 sgd_solver.cpp:106] Iteration 211000, lr = 0.004
I0522 15:48:11.838287 31742 solver.cpp:237] Iteration 211500, loss = 1.39452
I0522 15:48:11.838325 31742 solver.cpp:253]     Train net output #0: loss = 1.39452 (* 1 = 1.39452 loss)
I0522 15:48:11.838340 31742 sgd_solver.cpp:106] Iteration 211500, lr = 0.004
I0522 15:48:22.422209 31742 solver.cpp:237] Iteration 212000, loss = 1.11576
I0522 15:48:22.422399 31742 solver.cpp:253]     Train net output #0: loss = 1.11576 (* 1 = 1.11576 loss)
I0522 15:48:22.422413 31742 sgd_solver.cpp:106] Iteration 212000, lr = 0.004
I0522 15:48:33.002712 31742 solver.cpp:237] Iteration 212500, loss = 1.25906
I0522 15:48:33.002748 31742 solver.cpp:253]     Train net output #0: loss = 1.25906 (* 1 = 1.25906 loss)
I0522 15:48:33.002763 31742 sgd_solver.cpp:106] Iteration 212500, lr = 0.004
I0522 15:48:43.577198 31742 solver.cpp:237] Iteration 213000, loss = 1.11861
I0522 15:48:43.577232 31742 solver.cpp:253]     Train net output #0: loss = 1.11862 (* 1 = 1.11862 loss)
I0522 15:48:43.577246 31742 sgd_solver.cpp:106] Iteration 213000, lr = 0.004
I0522 15:49:15.048861 31742 solver.cpp:237] Iteration 213500, loss = 0.85885
I0522 15:49:15.049059 31742 solver.cpp:253]     Train net output #0: loss = 0.858852 (* 1 = 0.858852 loss)
I0522 15:49:15.049077 31742 sgd_solver.cpp:106] Iteration 213500, lr = 0.004
aprun: Apid 11248494: Caught signal Terminated, sending to application
*** Aborted at 1463946562 (unix time) try "date -d @1463946562" if you are using GNU date ***
=>> PBS: job killed: walltime 7228 exceeded limit 7200
PC: @     0x2aaab9276640 (unknown)
*** SIGTERM (@0x7bfb) received by PID 31742 (TID 0x2aaac746f900) from PID 31739; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab9276640 (unknown)
aprun: Apid 11248494: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
aprun: Apid 11248494: Caught signal Terminated, sending to application
    @     0x2aaab928a368 (unknown)
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11248494: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11248494: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11248494: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11248494: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
aprun: Apid 11248494: Caught signal Terminated, sending to application
