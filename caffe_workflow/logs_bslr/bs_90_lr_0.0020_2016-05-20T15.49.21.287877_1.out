2810018
I0525 06:49:34.226577 19224 caffe.cpp:184] Using GPUs 0
I0525 06:49:34.645002 19224 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1666
test_interval: 3333
base_lr: 0.002
display: 166
max_iter: 166660
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1666
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877.prototxt"
I0525 06:49:34.646574 19224 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877.prototxt
I0525 06:49:34.660679 19224 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 06:49:34.660738 19224 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 06:49:34.661099 19224 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 06:49:34.661280 19224 layer_factory.hpp:77] Creating layer data_hdf5
I0525 06:49:34.661303 19224 net.cpp:106] Creating Layer data_hdf5
I0525 06:49:34.661319 19224 net.cpp:411] data_hdf5 -> data
I0525 06:49:34.661352 19224 net.cpp:411] data_hdf5 -> label
I0525 06:49:34.661384 19224 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 06:49:34.662710 19224 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 06:49:34.664924 19224 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 06:49:56.248131 19224 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 06:49:56.253324 19224 net.cpp:150] Setting up data_hdf5
I0525 06:49:56.253363 19224 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 06:49:56.253378 19224 net.cpp:157] Top shape: 90 (90)
I0525 06:49:56.253392 19224 net.cpp:165] Memory required for data: 2286360
I0525 06:49:56.253406 19224 layer_factory.hpp:77] Creating layer conv1
I0525 06:49:56.253439 19224 net.cpp:106] Creating Layer conv1
I0525 06:49:56.253450 19224 net.cpp:454] conv1 <- data
I0525 06:49:56.253471 19224 net.cpp:411] conv1 -> conv1
I0525 06:49:57.316020 19224 net.cpp:150] Setting up conv1
I0525 06:49:57.316067 19224 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:49:57.316078 19224 net.cpp:165] Memory required for data: 27169560
I0525 06:49:57.316108 19224 layer_factory.hpp:77] Creating layer relu1
I0525 06:49:57.316129 19224 net.cpp:106] Creating Layer relu1
I0525 06:49:57.316140 19224 net.cpp:454] relu1 <- conv1
I0525 06:49:57.316154 19224 net.cpp:397] relu1 -> conv1 (in-place)
I0525 06:49:57.316665 19224 net.cpp:150] Setting up relu1
I0525 06:49:57.316681 19224 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:49:57.316692 19224 net.cpp:165] Memory required for data: 52052760
I0525 06:49:57.316702 19224 layer_factory.hpp:77] Creating layer pool1
I0525 06:49:57.316720 19224 net.cpp:106] Creating Layer pool1
I0525 06:49:57.316730 19224 net.cpp:454] pool1 <- conv1
I0525 06:49:57.316742 19224 net.cpp:411] pool1 -> pool1
I0525 06:49:57.316823 19224 net.cpp:150] Setting up pool1
I0525 06:49:57.316836 19224 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 06:49:57.316846 19224 net.cpp:165] Memory required for data: 64494360
I0525 06:49:57.316856 19224 layer_factory.hpp:77] Creating layer conv2
I0525 06:49:57.316879 19224 net.cpp:106] Creating Layer conv2
I0525 06:49:57.316890 19224 net.cpp:454] conv2 <- pool1
I0525 06:49:57.316902 19224 net.cpp:411] conv2 -> conv2
I0525 06:49:57.319631 19224 net.cpp:150] Setting up conv2
I0525 06:49:57.319658 19224 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:49:57.319669 19224 net.cpp:165] Memory required for data: 82379160
I0525 06:49:57.319689 19224 layer_factory.hpp:77] Creating layer relu2
I0525 06:49:57.319702 19224 net.cpp:106] Creating Layer relu2
I0525 06:49:57.319712 19224 net.cpp:454] relu2 <- conv2
I0525 06:49:57.319725 19224 net.cpp:397] relu2 -> conv2 (in-place)
I0525 06:49:57.320055 19224 net.cpp:150] Setting up relu2
I0525 06:49:57.320070 19224 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:49:57.320080 19224 net.cpp:165] Memory required for data: 100263960
I0525 06:49:57.320091 19224 layer_factory.hpp:77] Creating layer pool2
I0525 06:49:57.320102 19224 net.cpp:106] Creating Layer pool2
I0525 06:49:57.320112 19224 net.cpp:454] pool2 <- conv2
I0525 06:49:57.320124 19224 net.cpp:411] pool2 -> pool2
I0525 06:49:57.320205 19224 net.cpp:150] Setting up pool2
I0525 06:49:57.320219 19224 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 06:49:57.320228 19224 net.cpp:165] Memory required for data: 109206360
I0525 06:49:57.320238 19224 layer_factory.hpp:77] Creating layer conv3
I0525 06:49:57.320257 19224 net.cpp:106] Creating Layer conv3
I0525 06:49:57.320267 19224 net.cpp:454] conv3 <- pool2
I0525 06:49:57.320281 19224 net.cpp:411] conv3 -> conv3
I0525 06:49:57.322228 19224 net.cpp:150] Setting up conv3
I0525 06:49:57.322252 19224 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:49:57.322264 19224 net.cpp:165] Memory required for data: 118963800
I0525 06:49:57.322283 19224 layer_factory.hpp:77] Creating layer relu3
I0525 06:49:57.322299 19224 net.cpp:106] Creating Layer relu3
I0525 06:49:57.322309 19224 net.cpp:454] relu3 <- conv3
I0525 06:49:57.322321 19224 net.cpp:397] relu3 -> conv3 (in-place)
I0525 06:49:57.322787 19224 net.cpp:150] Setting up relu3
I0525 06:49:57.322803 19224 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:49:57.322813 19224 net.cpp:165] Memory required for data: 128721240
I0525 06:49:57.322824 19224 layer_factory.hpp:77] Creating layer pool3
I0525 06:49:57.322836 19224 net.cpp:106] Creating Layer pool3
I0525 06:49:57.322846 19224 net.cpp:454] pool3 <- conv3
I0525 06:49:57.322860 19224 net.cpp:411] pool3 -> pool3
I0525 06:49:57.322926 19224 net.cpp:150] Setting up pool3
I0525 06:49:57.322939 19224 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 06:49:57.322949 19224 net.cpp:165] Memory required for data: 133599960
I0525 06:49:57.322959 19224 layer_factory.hpp:77] Creating layer conv4
I0525 06:49:57.322978 19224 net.cpp:106] Creating Layer conv4
I0525 06:49:57.322988 19224 net.cpp:454] conv4 <- pool3
I0525 06:49:57.323002 19224 net.cpp:411] conv4 -> conv4
I0525 06:49:57.325938 19224 net.cpp:150] Setting up conv4
I0525 06:49:57.325968 19224 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:49:57.325978 19224 net.cpp:165] Memory required for data: 136865880
I0525 06:49:57.325994 19224 layer_factory.hpp:77] Creating layer relu4
I0525 06:49:57.326007 19224 net.cpp:106] Creating Layer relu4
I0525 06:49:57.326019 19224 net.cpp:454] relu4 <- conv4
I0525 06:49:57.326031 19224 net.cpp:397] relu4 -> conv4 (in-place)
I0525 06:49:57.326490 19224 net.cpp:150] Setting up relu4
I0525 06:49:57.326506 19224 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:49:57.326516 19224 net.cpp:165] Memory required for data: 140131800
I0525 06:49:57.326527 19224 layer_factory.hpp:77] Creating layer pool4
I0525 06:49:57.326542 19224 net.cpp:106] Creating Layer pool4
I0525 06:49:57.326555 19224 net.cpp:454] pool4 <- conv4
I0525 06:49:57.326570 19224 net.cpp:411] pool4 -> pool4
I0525 06:49:57.326642 19224 net.cpp:150] Setting up pool4
I0525 06:49:57.326654 19224 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 06:49:57.326664 19224 net.cpp:165] Memory required for data: 141764760
I0525 06:49:57.326673 19224 layer_factory.hpp:77] Creating layer ip1
I0525 06:49:57.326694 19224 net.cpp:106] Creating Layer ip1
I0525 06:49:57.326704 19224 net.cpp:454] ip1 <- pool4
I0525 06:49:57.326716 19224 net.cpp:411] ip1 -> ip1
I0525 06:49:57.342082 19224 net.cpp:150] Setting up ip1
I0525 06:49:57.342109 19224 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:49:57.342121 19224 net.cpp:165] Memory required for data: 141835320
I0525 06:49:57.342144 19224 layer_factory.hpp:77] Creating layer relu5
I0525 06:49:57.342159 19224 net.cpp:106] Creating Layer relu5
I0525 06:49:57.342169 19224 net.cpp:454] relu5 <- ip1
I0525 06:49:57.342182 19224 net.cpp:397] relu5 -> ip1 (in-place)
I0525 06:49:57.342524 19224 net.cpp:150] Setting up relu5
I0525 06:49:57.342537 19224 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:49:57.342547 19224 net.cpp:165] Memory required for data: 141905880
I0525 06:49:57.342557 19224 layer_factory.hpp:77] Creating layer drop1
I0525 06:49:57.342578 19224 net.cpp:106] Creating Layer drop1
I0525 06:49:57.342588 19224 net.cpp:454] drop1 <- ip1
I0525 06:49:57.342602 19224 net.cpp:397] drop1 -> ip1 (in-place)
I0525 06:49:57.342663 19224 net.cpp:150] Setting up drop1
I0525 06:49:57.342675 19224 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:49:57.342684 19224 net.cpp:165] Memory required for data: 141976440
I0525 06:49:57.342694 19224 layer_factory.hpp:77] Creating layer ip2
I0525 06:49:57.342713 19224 net.cpp:106] Creating Layer ip2
I0525 06:49:57.342723 19224 net.cpp:454] ip2 <- ip1
I0525 06:49:57.342737 19224 net.cpp:411] ip2 -> ip2
I0525 06:49:57.343202 19224 net.cpp:150] Setting up ip2
I0525 06:49:57.343215 19224 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:49:57.343225 19224 net.cpp:165] Memory required for data: 142011720
I0525 06:49:57.343241 19224 layer_factory.hpp:77] Creating layer relu6
I0525 06:49:57.343253 19224 net.cpp:106] Creating Layer relu6
I0525 06:49:57.343263 19224 net.cpp:454] relu6 <- ip2
I0525 06:49:57.343276 19224 net.cpp:397] relu6 -> ip2 (in-place)
I0525 06:49:57.343791 19224 net.cpp:150] Setting up relu6
I0525 06:49:57.343807 19224 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:49:57.343817 19224 net.cpp:165] Memory required for data: 142047000
I0525 06:49:57.343827 19224 layer_factory.hpp:77] Creating layer drop2
I0525 06:49:57.343840 19224 net.cpp:106] Creating Layer drop2
I0525 06:49:57.343850 19224 net.cpp:454] drop2 <- ip2
I0525 06:49:57.343863 19224 net.cpp:397] drop2 -> ip2 (in-place)
I0525 06:49:57.343904 19224 net.cpp:150] Setting up drop2
I0525 06:49:57.343917 19224 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:49:57.343927 19224 net.cpp:165] Memory required for data: 142082280
I0525 06:49:57.343937 19224 layer_factory.hpp:77] Creating layer ip3
I0525 06:49:57.343950 19224 net.cpp:106] Creating Layer ip3
I0525 06:49:57.343961 19224 net.cpp:454] ip3 <- ip2
I0525 06:49:57.343972 19224 net.cpp:411] ip3 -> ip3
I0525 06:49:57.344180 19224 net.cpp:150] Setting up ip3
I0525 06:49:57.344193 19224 net.cpp:157] Top shape: 90 11 (990)
I0525 06:49:57.344203 19224 net.cpp:165] Memory required for data: 142086240
I0525 06:49:57.344218 19224 layer_factory.hpp:77] Creating layer drop3
I0525 06:49:57.344231 19224 net.cpp:106] Creating Layer drop3
I0525 06:49:57.344240 19224 net.cpp:454] drop3 <- ip3
I0525 06:49:57.344252 19224 net.cpp:397] drop3 -> ip3 (in-place)
I0525 06:49:57.344291 19224 net.cpp:150] Setting up drop3
I0525 06:49:57.344305 19224 net.cpp:157] Top shape: 90 11 (990)
I0525 06:49:57.344315 19224 net.cpp:165] Memory required for data: 142090200
I0525 06:49:57.344324 19224 layer_factory.hpp:77] Creating layer loss
I0525 06:49:57.344342 19224 net.cpp:106] Creating Layer loss
I0525 06:49:57.344352 19224 net.cpp:454] loss <- ip3
I0525 06:49:57.344363 19224 net.cpp:454] loss <- label
I0525 06:49:57.344377 19224 net.cpp:411] loss -> loss
I0525 06:49:57.344393 19224 layer_factory.hpp:77] Creating layer loss
I0525 06:49:57.345032 19224 net.cpp:150] Setting up loss
I0525 06:49:57.345053 19224 net.cpp:157] Top shape: (1)
I0525 06:49:57.345067 19224 net.cpp:160]     with loss weight 1
I0525 06:49:57.345110 19224 net.cpp:165] Memory required for data: 142090204
I0525 06:49:57.345121 19224 net.cpp:226] loss needs backward computation.
I0525 06:49:57.345132 19224 net.cpp:226] drop3 needs backward computation.
I0525 06:49:57.345142 19224 net.cpp:226] ip3 needs backward computation.
I0525 06:49:57.345152 19224 net.cpp:226] drop2 needs backward computation.
I0525 06:49:57.345161 19224 net.cpp:226] relu6 needs backward computation.
I0525 06:49:57.345171 19224 net.cpp:226] ip2 needs backward computation.
I0525 06:49:57.345181 19224 net.cpp:226] drop1 needs backward computation.
I0525 06:49:57.345191 19224 net.cpp:226] relu5 needs backward computation.
I0525 06:49:57.345201 19224 net.cpp:226] ip1 needs backward computation.
I0525 06:49:57.345209 19224 net.cpp:226] pool4 needs backward computation.
I0525 06:49:57.345221 19224 net.cpp:226] relu4 needs backward computation.
I0525 06:49:57.345229 19224 net.cpp:226] conv4 needs backward computation.
I0525 06:49:57.345240 19224 net.cpp:226] pool3 needs backward computation.
I0525 06:49:57.345250 19224 net.cpp:226] relu3 needs backward computation.
I0525 06:49:57.345271 19224 net.cpp:226] conv3 needs backward computation.
I0525 06:49:57.345283 19224 net.cpp:226] pool2 needs backward computation.
I0525 06:49:57.345293 19224 net.cpp:226] relu2 needs backward computation.
I0525 06:49:57.345304 19224 net.cpp:226] conv2 needs backward computation.
I0525 06:49:57.345314 19224 net.cpp:226] pool1 needs backward computation.
I0525 06:49:57.345325 19224 net.cpp:226] relu1 needs backward computation.
I0525 06:49:57.345335 19224 net.cpp:226] conv1 needs backward computation.
I0525 06:49:57.345346 19224 net.cpp:228] data_hdf5 does not need backward computation.
I0525 06:49:57.345356 19224 net.cpp:270] This network produces output loss
I0525 06:49:57.345379 19224 net.cpp:283] Network initialization done.
I0525 06:49:57.347307 19224 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877.prototxt
I0525 06:49:57.347378 19224 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 06:49:57.347731 19224 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 06:49:57.347918 19224 layer_factory.hpp:77] Creating layer data_hdf5
I0525 06:49:57.347934 19224 net.cpp:106] Creating Layer data_hdf5
I0525 06:49:57.347946 19224 net.cpp:411] data_hdf5 -> data
I0525 06:49:57.347964 19224 net.cpp:411] data_hdf5 -> label
I0525 06:49:57.347980 19224 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 06:49:57.349500 19224 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 06:50:18.652110 19224 net.cpp:150] Setting up data_hdf5
I0525 06:50:18.652277 19224 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 06:50:18.652292 19224 net.cpp:157] Top shape: 90 (90)
I0525 06:50:18.652304 19224 net.cpp:165] Memory required for data: 2286360
I0525 06:50:18.652318 19224 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 06:50:18.652345 19224 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 06:50:18.652356 19224 net.cpp:454] label_data_hdf5_1_split <- label
I0525 06:50:18.652372 19224 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 06:50:18.652393 19224 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 06:50:18.652467 19224 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 06:50:18.652482 19224 net.cpp:157] Top shape: 90 (90)
I0525 06:50:18.652493 19224 net.cpp:157] Top shape: 90 (90)
I0525 06:50:18.652503 19224 net.cpp:165] Memory required for data: 2287080
I0525 06:50:18.652513 19224 layer_factory.hpp:77] Creating layer conv1
I0525 06:50:18.652534 19224 net.cpp:106] Creating Layer conv1
I0525 06:50:18.652544 19224 net.cpp:454] conv1 <- data
I0525 06:50:18.652559 19224 net.cpp:411] conv1 -> conv1
I0525 06:50:18.654520 19224 net.cpp:150] Setting up conv1
I0525 06:50:18.654544 19224 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:50:18.654557 19224 net.cpp:165] Memory required for data: 27170280
I0525 06:50:18.654578 19224 layer_factory.hpp:77] Creating layer relu1
I0525 06:50:18.654592 19224 net.cpp:106] Creating Layer relu1
I0525 06:50:18.654603 19224 net.cpp:454] relu1 <- conv1
I0525 06:50:18.654615 19224 net.cpp:397] relu1 -> conv1 (in-place)
I0525 06:50:18.655107 19224 net.cpp:150] Setting up relu1
I0525 06:50:18.655123 19224 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 06:50:18.655134 19224 net.cpp:165] Memory required for data: 52053480
I0525 06:50:18.655144 19224 layer_factory.hpp:77] Creating layer pool1
I0525 06:50:18.655160 19224 net.cpp:106] Creating Layer pool1
I0525 06:50:18.655170 19224 net.cpp:454] pool1 <- conv1
I0525 06:50:18.655184 19224 net.cpp:411] pool1 -> pool1
I0525 06:50:18.655258 19224 net.cpp:150] Setting up pool1
I0525 06:50:18.655272 19224 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 06:50:18.655282 19224 net.cpp:165] Memory required for data: 64495080
I0525 06:50:18.655292 19224 layer_factory.hpp:77] Creating layer conv2
I0525 06:50:18.655310 19224 net.cpp:106] Creating Layer conv2
I0525 06:50:18.655320 19224 net.cpp:454] conv2 <- pool1
I0525 06:50:18.655335 19224 net.cpp:411] conv2 -> conv2
I0525 06:50:18.657248 19224 net.cpp:150] Setting up conv2
I0525 06:50:18.657270 19224 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:50:18.657286 19224 net.cpp:165] Memory required for data: 82379880
I0525 06:50:18.657306 19224 layer_factory.hpp:77] Creating layer relu2
I0525 06:50:18.657320 19224 net.cpp:106] Creating Layer relu2
I0525 06:50:18.657330 19224 net.cpp:454] relu2 <- conv2
I0525 06:50:18.657342 19224 net.cpp:397] relu2 -> conv2 (in-place)
I0525 06:50:18.657677 19224 net.cpp:150] Setting up relu2
I0525 06:50:18.657691 19224 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 06:50:18.657701 19224 net.cpp:165] Memory required for data: 100264680
I0525 06:50:18.657712 19224 layer_factory.hpp:77] Creating layer pool2
I0525 06:50:18.657726 19224 net.cpp:106] Creating Layer pool2
I0525 06:50:18.657734 19224 net.cpp:454] pool2 <- conv2
I0525 06:50:18.657747 19224 net.cpp:411] pool2 -> pool2
I0525 06:50:18.657819 19224 net.cpp:150] Setting up pool2
I0525 06:50:18.657832 19224 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 06:50:18.657841 19224 net.cpp:165] Memory required for data: 109207080
I0525 06:50:18.657851 19224 layer_factory.hpp:77] Creating layer conv3
I0525 06:50:18.657871 19224 net.cpp:106] Creating Layer conv3
I0525 06:50:18.657882 19224 net.cpp:454] conv3 <- pool2
I0525 06:50:18.657896 19224 net.cpp:411] conv3 -> conv3
I0525 06:50:18.659909 19224 net.cpp:150] Setting up conv3
I0525 06:50:18.659932 19224 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:50:18.659943 19224 net.cpp:165] Memory required for data: 118964520
I0525 06:50:18.659976 19224 layer_factory.hpp:77] Creating layer relu3
I0525 06:50:18.659991 19224 net.cpp:106] Creating Layer relu3
I0525 06:50:18.660001 19224 net.cpp:454] relu3 <- conv3
I0525 06:50:18.660013 19224 net.cpp:397] relu3 -> conv3 (in-place)
I0525 06:50:18.660480 19224 net.cpp:150] Setting up relu3
I0525 06:50:18.660496 19224 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 06:50:18.660507 19224 net.cpp:165] Memory required for data: 128721960
I0525 06:50:18.660516 19224 layer_factory.hpp:77] Creating layer pool3
I0525 06:50:18.660529 19224 net.cpp:106] Creating Layer pool3
I0525 06:50:18.660539 19224 net.cpp:454] pool3 <- conv3
I0525 06:50:18.660553 19224 net.cpp:411] pool3 -> pool3
I0525 06:50:18.660624 19224 net.cpp:150] Setting up pool3
I0525 06:50:18.660637 19224 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 06:50:18.660647 19224 net.cpp:165] Memory required for data: 133600680
I0525 06:50:18.660656 19224 layer_factory.hpp:77] Creating layer conv4
I0525 06:50:18.660675 19224 net.cpp:106] Creating Layer conv4
I0525 06:50:18.660686 19224 net.cpp:454] conv4 <- pool3
I0525 06:50:18.660699 19224 net.cpp:411] conv4 -> conv4
I0525 06:50:18.662777 19224 net.cpp:150] Setting up conv4
I0525 06:50:18.662801 19224 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:50:18.662809 19224 net.cpp:165] Memory required for data: 136866600
I0525 06:50:18.662827 19224 layer_factory.hpp:77] Creating layer relu4
I0525 06:50:18.662839 19224 net.cpp:106] Creating Layer relu4
I0525 06:50:18.662849 19224 net.cpp:454] relu4 <- conv4
I0525 06:50:18.662863 19224 net.cpp:397] relu4 -> conv4 (in-place)
I0525 06:50:18.663332 19224 net.cpp:150] Setting up relu4
I0525 06:50:18.663348 19224 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 06:50:18.663358 19224 net.cpp:165] Memory required for data: 140132520
I0525 06:50:18.663368 19224 layer_factory.hpp:77] Creating layer pool4
I0525 06:50:18.663381 19224 net.cpp:106] Creating Layer pool4
I0525 06:50:18.663391 19224 net.cpp:454] pool4 <- conv4
I0525 06:50:18.663404 19224 net.cpp:411] pool4 -> pool4
I0525 06:50:18.663475 19224 net.cpp:150] Setting up pool4
I0525 06:50:18.663489 19224 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 06:50:18.663498 19224 net.cpp:165] Memory required for data: 141765480
I0525 06:50:18.663507 19224 layer_factory.hpp:77] Creating layer ip1
I0525 06:50:18.663522 19224 net.cpp:106] Creating Layer ip1
I0525 06:50:18.663532 19224 net.cpp:454] ip1 <- pool4
I0525 06:50:18.663545 19224 net.cpp:411] ip1 -> ip1
I0525 06:50:18.678910 19224 net.cpp:150] Setting up ip1
I0525 06:50:18.678933 19224 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:50:18.678946 19224 net.cpp:165] Memory required for data: 141836040
I0525 06:50:18.678967 19224 layer_factory.hpp:77] Creating layer relu5
I0525 06:50:18.678982 19224 net.cpp:106] Creating Layer relu5
I0525 06:50:18.678993 19224 net.cpp:454] relu5 <- ip1
I0525 06:50:18.679011 19224 net.cpp:397] relu5 -> ip1 (in-place)
I0525 06:50:18.679358 19224 net.cpp:150] Setting up relu5
I0525 06:50:18.679373 19224 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:50:18.679381 19224 net.cpp:165] Memory required for data: 141906600
I0525 06:50:18.679391 19224 layer_factory.hpp:77] Creating layer drop1
I0525 06:50:18.679410 19224 net.cpp:106] Creating Layer drop1
I0525 06:50:18.679420 19224 net.cpp:454] drop1 <- ip1
I0525 06:50:18.679433 19224 net.cpp:397] drop1 -> ip1 (in-place)
I0525 06:50:18.679481 19224 net.cpp:150] Setting up drop1
I0525 06:50:18.679493 19224 net.cpp:157] Top shape: 90 196 (17640)
I0525 06:50:18.679503 19224 net.cpp:165] Memory required for data: 141977160
I0525 06:50:18.679513 19224 layer_factory.hpp:77] Creating layer ip2
I0525 06:50:18.679527 19224 net.cpp:106] Creating Layer ip2
I0525 06:50:18.679538 19224 net.cpp:454] ip2 <- ip1
I0525 06:50:18.679551 19224 net.cpp:411] ip2 -> ip2
I0525 06:50:18.680029 19224 net.cpp:150] Setting up ip2
I0525 06:50:18.680042 19224 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:50:18.680052 19224 net.cpp:165] Memory required for data: 142012440
I0525 06:50:18.680068 19224 layer_factory.hpp:77] Creating layer relu6
I0525 06:50:18.680094 19224 net.cpp:106] Creating Layer relu6
I0525 06:50:18.680104 19224 net.cpp:454] relu6 <- ip2
I0525 06:50:18.680116 19224 net.cpp:397] relu6 -> ip2 (in-place)
I0525 06:50:18.680647 19224 net.cpp:150] Setting up relu6
I0525 06:50:18.680662 19224 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:50:18.680671 19224 net.cpp:165] Memory required for data: 142047720
I0525 06:50:18.680681 19224 layer_factory.hpp:77] Creating layer drop2
I0525 06:50:18.680696 19224 net.cpp:106] Creating Layer drop2
I0525 06:50:18.680706 19224 net.cpp:454] drop2 <- ip2
I0525 06:50:18.680717 19224 net.cpp:397] drop2 -> ip2 (in-place)
I0525 06:50:18.680762 19224 net.cpp:150] Setting up drop2
I0525 06:50:18.680774 19224 net.cpp:157] Top shape: 90 98 (8820)
I0525 06:50:18.680784 19224 net.cpp:165] Memory required for data: 142083000
I0525 06:50:18.680794 19224 layer_factory.hpp:77] Creating layer ip3
I0525 06:50:18.680807 19224 net.cpp:106] Creating Layer ip3
I0525 06:50:18.680817 19224 net.cpp:454] ip3 <- ip2
I0525 06:50:18.680831 19224 net.cpp:411] ip3 -> ip3
I0525 06:50:18.681061 19224 net.cpp:150] Setting up ip3
I0525 06:50:18.681074 19224 net.cpp:157] Top shape: 90 11 (990)
I0525 06:50:18.681084 19224 net.cpp:165] Memory required for data: 142086960
I0525 06:50:18.681099 19224 layer_factory.hpp:77] Creating layer drop3
I0525 06:50:18.681113 19224 net.cpp:106] Creating Layer drop3
I0525 06:50:18.681123 19224 net.cpp:454] drop3 <- ip3
I0525 06:50:18.681135 19224 net.cpp:397] drop3 -> ip3 (in-place)
I0525 06:50:18.681176 19224 net.cpp:150] Setting up drop3
I0525 06:50:18.681190 19224 net.cpp:157] Top shape: 90 11 (990)
I0525 06:50:18.681198 19224 net.cpp:165] Memory required for data: 142090920
I0525 06:50:18.681208 19224 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 06:50:18.681221 19224 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 06:50:18.681231 19224 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 06:50:18.681243 19224 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 06:50:18.681258 19224 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 06:50:18.681332 19224 net.cpp:150] Setting up ip3_drop3_0_split
I0525 06:50:18.681344 19224 net.cpp:157] Top shape: 90 11 (990)
I0525 06:50:18.681357 19224 net.cpp:157] Top shape: 90 11 (990)
I0525 06:50:18.681367 19224 net.cpp:165] Memory required for data: 142098840
I0525 06:50:18.681377 19224 layer_factory.hpp:77] Creating layer accuracy
I0525 06:50:18.681398 19224 net.cpp:106] Creating Layer accuracy
I0525 06:50:18.681407 19224 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 06:50:18.681419 19224 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 06:50:18.681432 19224 net.cpp:411] accuracy -> accuracy
I0525 06:50:18.681457 19224 net.cpp:150] Setting up accuracy
I0525 06:50:18.681468 19224 net.cpp:157] Top shape: (1)
I0525 06:50:18.681478 19224 net.cpp:165] Memory required for data: 142098844
I0525 06:50:18.681486 19224 layer_factory.hpp:77] Creating layer loss
I0525 06:50:18.681499 19224 net.cpp:106] Creating Layer loss
I0525 06:50:18.681509 19224 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 06:50:18.681519 19224 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 06:50:18.681534 19224 net.cpp:411] loss -> loss
I0525 06:50:18.681550 19224 layer_factory.hpp:77] Creating layer loss
I0525 06:50:18.682039 19224 net.cpp:150] Setting up loss
I0525 06:50:18.682052 19224 net.cpp:157] Top shape: (1)
I0525 06:50:18.682062 19224 net.cpp:160]     with loss weight 1
I0525 06:50:18.682082 19224 net.cpp:165] Memory required for data: 142098848
I0525 06:50:18.682092 19224 net.cpp:226] loss needs backward computation.
I0525 06:50:18.682104 19224 net.cpp:228] accuracy does not need backward computation.
I0525 06:50:18.682116 19224 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 06:50:18.682126 19224 net.cpp:226] drop3 needs backward computation.
I0525 06:50:18.682137 19224 net.cpp:226] ip3 needs backward computation.
I0525 06:50:18.682147 19224 net.cpp:226] drop2 needs backward computation.
I0525 06:50:18.682157 19224 net.cpp:226] relu6 needs backward computation.
I0525 06:50:18.682175 19224 net.cpp:226] ip2 needs backward computation.
I0525 06:50:18.682185 19224 net.cpp:226] drop1 needs backward computation.
I0525 06:50:18.682194 19224 net.cpp:226] relu5 needs backward computation.
I0525 06:50:18.682204 19224 net.cpp:226] ip1 needs backward computation.
I0525 06:50:18.682214 19224 net.cpp:226] pool4 needs backward computation.
I0525 06:50:18.682224 19224 net.cpp:226] relu4 needs backward computation.
I0525 06:50:18.682234 19224 net.cpp:226] conv4 needs backward computation.
I0525 06:50:18.682242 19224 net.cpp:226] pool3 needs backward computation.
I0525 06:50:18.682252 19224 net.cpp:226] relu3 needs backward computation.
I0525 06:50:18.682262 19224 net.cpp:226] conv3 needs backward computation.
I0525 06:50:18.682273 19224 net.cpp:226] pool2 needs backward computation.
I0525 06:50:18.682283 19224 net.cpp:226] relu2 needs backward computation.
I0525 06:50:18.682293 19224 net.cpp:226] conv2 needs backward computation.
I0525 06:50:18.682303 19224 net.cpp:226] pool1 needs backward computation.
I0525 06:50:18.682313 19224 net.cpp:226] relu1 needs backward computation.
I0525 06:50:18.682323 19224 net.cpp:226] conv1 needs backward computation.
I0525 06:50:18.682334 19224 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 06:50:18.682346 19224 net.cpp:228] data_hdf5 does not need backward computation.
I0525 06:50:18.682356 19224 net.cpp:270] This network produces output accuracy
I0525 06:50:18.682368 19224 net.cpp:270] This network produces output loss
I0525 06:50:18.682394 19224 net.cpp:283] Network initialization done.
I0525 06:50:18.682528 19224 solver.cpp:60] Solver scaffolding done.
I0525 06:50:18.683666 19224 caffe.cpp:212] Starting Optimization
I0525 06:50:18.683684 19224 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 06:50:18.683697 19224 solver.cpp:289] Learning Rate Policy: fixed
I0525 06:50:18.684757 19224 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 06:51:06.749449 19224 solver.cpp:409]     Test net output #0: accuracy = 0.0765371
I0525 06:51:06.749614 19224 solver.cpp:409]     Test net output #1: loss = 2.39791 (* 1 = 2.39791 loss)
I0525 06:51:06.780756 19224 solver.cpp:237] Iteration 0, loss = 2.40026
I0525 06:51:06.780792 19224 solver.cpp:253]     Train net output #0: loss = 2.40026 (* 1 = 2.40026 loss)
I0525 06:51:06.780810 19224 sgd_solver.cpp:106] Iteration 0, lr = 0.002
I0525 06:51:15.612957 19224 solver.cpp:237] Iteration 166, loss = 2.31932
I0525 06:51:15.612993 19224 solver.cpp:253]     Train net output #0: loss = 2.31932 (* 1 = 2.31932 loss)
I0525 06:51:15.613006 19224 sgd_solver.cpp:106] Iteration 166, lr = 0.002
I0525 06:51:24.443455 19224 solver.cpp:237] Iteration 332, loss = 2.18573
I0525 06:51:24.443491 19224 solver.cpp:253]     Train net output #0: loss = 2.18573 (* 1 = 2.18573 loss)
I0525 06:51:24.443507 19224 sgd_solver.cpp:106] Iteration 332, lr = 0.002
I0525 06:51:33.273618 19224 solver.cpp:237] Iteration 498, loss = 2.1066
I0525 06:51:33.273660 19224 solver.cpp:253]     Train net output #0: loss = 2.1066 (* 1 = 2.1066 loss)
I0525 06:51:33.273679 19224 sgd_solver.cpp:106] Iteration 498, lr = 0.002
I0525 06:51:42.101784 19224 solver.cpp:237] Iteration 664, loss = 2.06842
I0525 06:51:42.101932 19224 solver.cpp:253]     Train net output #0: loss = 2.06842 (* 1 = 2.06842 loss)
I0525 06:51:42.101945 19224 sgd_solver.cpp:106] Iteration 664, lr = 0.002
I0525 06:51:50.935151 19224 solver.cpp:237] Iteration 830, loss = 1.85908
I0525 06:51:50.935185 19224 solver.cpp:253]     Train net output #0: loss = 1.85908 (* 1 = 1.85908 loss)
I0525 06:51:50.935204 19224 sgd_solver.cpp:106] Iteration 830, lr = 0.002
I0525 06:51:59.760440 19224 solver.cpp:237] Iteration 996, loss = 1.8525
I0525 06:51:59.760479 19224 solver.cpp:253]     Train net output #0: loss = 1.8525 (* 1 = 1.8525 loss)
I0525 06:51:59.760500 19224 sgd_solver.cpp:106] Iteration 996, lr = 0.002
I0525 06:52:30.754663 19224 solver.cpp:237] Iteration 1162, loss = 1.91983
I0525 06:52:30.754827 19224 solver.cpp:253]     Train net output #0: loss = 1.91983 (* 1 = 1.91983 loss)
I0525 06:52:30.754840 19224 sgd_solver.cpp:106] Iteration 1162, lr = 0.002
I0525 06:52:39.588989 19224 solver.cpp:237] Iteration 1328, loss = 1.86162
I0525 06:52:39.589022 19224 solver.cpp:253]     Train net output #0: loss = 1.86162 (* 1 = 1.86162 loss)
I0525 06:52:39.589046 19224 sgd_solver.cpp:106] Iteration 1328, lr = 0.002
I0525 06:52:48.426790 19224 solver.cpp:237] Iteration 1494, loss = 1.70445
I0525 06:52:48.426833 19224 solver.cpp:253]     Train net output #0: loss = 1.70445 (* 1 = 1.70445 loss)
I0525 06:52:48.426854 19224 sgd_solver.cpp:106] Iteration 1494, lr = 0.002
I0525 06:52:57.250555 19224 solver.cpp:237] Iteration 1660, loss = 1.72689
I0525 06:52:57.250591 19224 solver.cpp:253]     Train net output #0: loss = 1.72689 (* 1 = 1.72689 loss)
I0525 06:52:57.250604 19224 sgd_solver.cpp:106] Iteration 1660, lr = 0.002
I0525 06:52:57.517802 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_1666.caffemodel
I0525 06:52:57.596675 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_1666.solverstate
I0525 06:53:06.156021 19224 solver.cpp:237] Iteration 1826, loss = 1.62879
I0525 06:53:06.156177 19224 solver.cpp:253]     Train net output #0: loss = 1.62879 (* 1 = 1.62879 loss)
I0525 06:53:06.156193 19224 sgd_solver.cpp:106] Iteration 1826, lr = 0.002
I0525 06:53:14.995375 19224 solver.cpp:237] Iteration 1992, loss = 1.72504
I0525 06:53:14.995417 19224 solver.cpp:253]     Train net output #0: loss = 1.72504 (* 1 = 1.72504 loss)
I0525 06:53:14.995439 19224 sgd_solver.cpp:106] Iteration 1992, lr = 0.002
I0525 06:53:23.830159 19224 solver.cpp:237] Iteration 2158, loss = 1.75508
I0525 06:53:23.830195 19224 solver.cpp:253]     Train net output #0: loss = 1.75508 (* 1 = 1.75508 loss)
I0525 06:53:23.830211 19224 sgd_solver.cpp:106] Iteration 2158, lr = 0.002
I0525 06:53:54.814882 19224 solver.cpp:237] Iteration 2324, loss = 1.78537
I0525 06:53:54.815043 19224 solver.cpp:253]     Train net output #0: loss = 1.78537 (* 1 = 1.78537 loss)
I0525 06:53:54.815058 19224 sgd_solver.cpp:106] Iteration 2324, lr = 0.002
I0525 06:54:03.648107 19224 solver.cpp:237] Iteration 2490, loss = 1.93153
I0525 06:54:03.648150 19224 solver.cpp:253]     Train net output #0: loss = 1.93153 (* 1 = 1.93153 loss)
I0525 06:54:03.648171 19224 sgd_solver.cpp:106] Iteration 2490, lr = 0.002
I0525 06:54:12.477367 19224 solver.cpp:237] Iteration 2656, loss = 1.61283
I0525 06:54:12.477403 19224 solver.cpp:253]     Train net output #0: loss = 1.61283 (* 1 = 1.61283 loss)
I0525 06:54:12.477417 19224 sgd_solver.cpp:106] Iteration 2656, lr = 0.002
I0525 06:54:21.306730 19224 solver.cpp:237] Iteration 2822, loss = 1.6891
I0525 06:54:21.306766 19224 solver.cpp:253]     Train net output #0: loss = 1.6891 (* 1 = 1.6891 loss)
I0525 06:54:21.306779 19224 sgd_solver.cpp:106] Iteration 2822, lr = 0.002
I0525 06:54:30.136879 19224 solver.cpp:237] Iteration 2988, loss = 1.74333
I0525 06:54:30.137047 19224 solver.cpp:253]     Train net output #0: loss = 1.74333 (* 1 = 1.74333 loss)
I0525 06:54:30.137059 19224 sgd_solver.cpp:106] Iteration 2988, lr = 0.002
I0525 06:54:38.964429 19224 solver.cpp:237] Iteration 3154, loss = 1.58934
I0525 06:54:38.964463 19224 solver.cpp:253]     Train net output #0: loss = 1.58934 (* 1 = 1.58934 loss)
I0525 06:54:38.964480 19224 sgd_solver.cpp:106] Iteration 3154, lr = 0.002
I0525 06:54:47.792677 19224 solver.cpp:237] Iteration 3320, loss = 1.50892
I0525 06:54:47.792711 19224 solver.cpp:253]     Train net output #0: loss = 1.50892 (* 1 = 1.50892 loss)
I0525 06:54:47.792727 19224 sgd_solver.cpp:106] Iteration 3320, lr = 0.002
I0525 06:54:48.377835 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_3332.caffemodel
I0525 06:54:48.452184 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_3332.solverstate
I0525 06:54:48.496420 19224 solver.cpp:341] Iteration 3333, Testing net (#0)
I0525 06:55:35.682342 19224 solver.cpp:409]     Test net output #0: accuracy = 0.683201
I0525 06:55:35.682505 19224 solver.cpp:409]     Test net output #1: loss = 1.08102 (* 1 = 1.08102 loss)
I0525 06:56:06.014425 19224 solver.cpp:237] Iteration 3486, loss = 1.47812
I0525 06:56:06.014586 19224 solver.cpp:253]     Train net output #0: loss = 1.47812 (* 1 = 1.47812 loss)
I0525 06:56:06.014602 19224 sgd_solver.cpp:106] Iteration 3486, lr = 0.002
I0525 06:56:14.832772 19224 solver.cpp:237] Iteration 3652, loss = 1.81208
I0525 06:56:14.832806 19224 solver.cpp:253]     Train net output #0: loss = 1.81208 (* 1 = 1.81208 loss)
I0525 06:56:14.832823 19224 sgd_solver.cpp:106] Iteration 3652, lr = 0.002
I0525 06:56:23.653918 19224 solver.cpp:237] Iteration 3818, loss = 1.45245
I0525 06:56:23.653954 19224 solver.cpp:253]     Train net output #0: loss = 1.45245 (* 1 = 1.45245 loss)
I0525 06:56:23.653967 19224 sgd_solver.cpp:106] Iteration 3818, lr = 0.002
I0525 06:56:32.476693 19224 solver.cpp:237] Iteration 3984, loss = 1.54997
I0525 06:56:32.476735 19224 solver.cpp:253]     Train net output #0: loss = 1.54997 (* 1 = 1.54997 loss)
I0525 06:56:32.476757 19224 sgd_solver.cpp:106] Iteration 3984, lr = 0.002
I0525 06:56:41.297197 19224 solver.cpp:237] Iteration 4150, loss = 1.4983
I0525 06:56:41.297333 19224 solver.cpp:253]     Train net output #0: loss = 1.4983 (* 1 = 1.4983 loss)
I0525 06:56:41.297348 19224 sgd_solver.cpp:106] Iteration 4150, lr = 0.002
I0525 06:56:50.122931 19224 solver.cpp:237] Iteration 4316, loss = 1.52084
I0525 06:56:50.122966 19224 solver.cpp:253]     Train net output #0: loss = 1.52084 (* 1 = 1.52084 loss)
I0525 06:56:50.122982 19224 sgd_solver.cpp:106] Iteration 4316, lr = 0.002
I0525 06:57:21.086140 19224 solver.cpp:237] Iteration 4482, loss = 1.48355
I0525 06:57:21.086307 19224 solver.cpp:253]     Train net output #0: loss = 1.48355 (* 1 = 1.48355 loss)
I0525 06:57:21.086323 19224 sgd_solver.cpp:106] Iteration 4482, lr = 0.002
I0525 06:57:29.909869 19224 solver.cpp:237] Iteration 4648, loss = 1.61137
I0525 06:57:29.909904 19224 solver.cpp:253]     Train net output #0: loss = 1.61137 (* 1 = 1.61137 loss)
I0525 06:57:29.909920 19224 sgd_solver.cpp:106] Iteration 4648, lr = 0.002
I0525 06:57:38.739807 19224 solver.cpp:237] Iteration 4814, loss = 1.38895
I0525 06:57:38.739843 19224 solver.cpp:253]     Train net output #0: loss = 1.38895 (* 1 = 1.38895 loss)
I0525 06:57:38.739858 19224 sgd_solver.cpp:106] Iteration 4814, lr = 0.002
I0525 06:57:47.556289 19224 solver.cpp:237] Iteration 4980, loss = 1.50105
I0525 06:57:47.556344 19224 solver.cpp:253]     Train net output #0: loss = 1.50105 (* 1 = 1.50105 loss)
I0525 06:57:47.556357 19224 sgd_solver.cpp:106] Iteration 4980, lr = 0.002
I0525 06:57:48.462568 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_4998.caffemodel
I0525 06:57:48.539701 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_4998.solverstate
I0525 06:57:56.446557 19224 solver.cpp:237] Iteration 5146, loss = 1.67078
I0525 06:57:56.446729 19224 solver.cpp:253]     Train net output #0: loss = 1.67078 (* 1 = 1.67078 loss)
I0525 06:57:56.446743 19224 sgd_solver.cpp:106] Iteration 5146, lr = 0.002
I0525 06:58:05.267704 19224 solver.cpp:237] Iteration 5312, loss = 1.38995
I0525 06:58:05.267738 19224 solver.cpp:253]     Train net output #0: loss = 1.38995 (* 1 = 1.38995 loss)
I0525 06:58:05.267755 19224 sgd_solver.cpp:106] Iteration 5312, lr = 0.002
I0525 06:58:14.084983 19224 solver.cpp:237] Iteration 5478, loss = 1.50219
I0525 06:58:14.085026 19224 solver.cpp:253]     Train net output #0: loss = 1.50219 (* 1 = 1.50219 loss)
I0525 06:58:14.085049 19224 sgd_solver.cpp:106] Iteration 5478, lr = 0.002
I0525 06:58:45.082854 19224 solver.cpp:237] Iteration 5644, loss = 1.41936
I0525 06:58:45.083030 19224 solver.cpp:253]     Train net output #0: loss = 1.41936 (* 1 = 1.41936 loss)
I0525 06:58:45.083046 19224 sgd_solver.cpp:106] Iteration 5644, lr = 0.002
I0525 06:58:53.904011 19224 solver.cpp:237] Iteration 5810, loss = 1.69489
I0525 06:58:53.904047 19224 solver.cpp:253]     Train net output #0: loss = 1.69489 (* 1 = 1.69489 loss)
I0525 06:58:53.904063 19224 sgd_solver.cpp:106] Iteration 5810, lr = 0.002
I0525 06:59:02.733638 19224 solver.cpp:237] Iteration 5976, loss = 1.43319
I0525 06:59:02.733685 19224 solver.cpp:253]     Train net output #0: loss = 1.43319 (* 1 = 1.43319 loss)
I0525 06:59:02.733701 19224 sgd_solver.cpp:106] Iteration 5976, lr = 0.002
I0525 06:59:11.555160 19224 solver.cpp:237] Iteration 6142, loss = 1.54325
I0525 06:59:11.555197 19224 solver.cpp:253]     Train net output #0: loss = 1.54325 (* 1 = 1.54325 loss)
I0525 06:59:11.555213 19224 sgd_solver.cpp:106] Iteration 6142, lr = 0.002
I0525 06:59:20.379976 19224 solver.cpp:237] Iteration 6308, loss = 1.49869
I0525 06:59:20.380113 19224 solver.cpp:253]     Train net output #0: loss = 1.49869 (* 1 = 1.49869 loss)
I0525 06:59:20.380127 19224 sgd_solver.cpp:106] Iteration 6308, lr = 0.002
I0525 06:59:29.207692 19224 solver.cpp:237] Iteration 6474, loss = 1.41782
I0525 06:59:29.207743 19224 solver.cpp:253]     Train net output #0: loss = 1.41782 (* 1 = 1.41782 loss)
I0525 06:59:29.207761 19224 sgd_solver.cpp:106] Iteration 6474, lr = 0.002
I0525 06:59:38.014796 19224 solver.cpp:237] Iteration 6640, loss = 1.41755
I0525 06:59:38.014832 19224 solver.cpp:253]     Train net output #0: loss = 1.41755 (* 1 = 1.41755 loss)
I0525 06:59:38.014848 19224 sgd_solver.cpp:106] Iteration 6640, lr = 0.002
I0525 06:59:39.239215 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_6664.caffemodel
I0525 06:59:39.315129 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_6664.solverstate
I0525 06:59:39.412562 19224 solver.cpp:341] Iteration 6666, Testing net (#0)
I0525 07:00:47.423809 19224 solver.cpp:409]     Test net output #0: accuracy = 0.781822
I0525 07:00:47.423984 19224 solver.cpp:409]     Test net output #1: loss = 0.808639 (* 1 = 0.808639 loss)
I0525 07:01:17.064530 19224 solver.cpp:237] Iteration 6806, loss = 1.42148
I0525 07:01:17.064585 19224 solver.cpp:253]     Train net output #0: loss = 1.42148 (* 1 = 1.42148 loss)
I0525 07:01:17.064599 19224 sgd_solver.cpp:106] Iteration 6806, lr = 0.002
I0525 07:01:25.894018 19224 solver.cpp:237] Iteration 6972, loss = 1.42038
I0525 07:01:25.894168 19224 solver.cpp:253]     Train net output #0: loss = 1.42038 (* 1 = 1.42038 loss)
I0525 07:01:25.894183 19224 sgd_solver.cpp:106] Iteration 6972, lr = 0.002
I0525 07:01:34.709522 19224 solver.cpp:237] Iteration 7138, loss = 1.33226
I0525 07:01:34.709568 19224 solver.cpp:253]     Train net output #0: loss = 1.33226 (* 1 = 1.33226 loss)
I0525 07:01:34.709586 19224 sgd_solver.cpp:106] Iteration 7138, lr = 0.002
I0525 07:01:43.529408 19224 solver.cpp:237] Iteration 7304, loss = 1.39732
I0525 07:01:43.529443 19224 solver.cpp:253]     Train net output #0: loss = 1.39732 (* 1 = 1.39732 loss)
I0525 07:01:43.529459 19224 sgd_solver.cpp:106] Iteration 7304, lr = 0.002
I0525 07:01:52.354477 19224 solver.cpp:237] Iteration 7470, loss = 1.44649
I0525 07:01:52.354512 19224 solver.cpp:253]     Train net output #0: loss = 1.44649 (* 1 = 1.44649 loss)
I0525 07:01:52.354528 19224 sgd_solver.cpp:106] Iteration 7470, lr = 0.002
I0525 07:02:01.177675 19224 solver.cpp:237] Iteration 7636, loss = 1.37426
I0525 07:02:01.177829 19224 solver.cpp:253]     Train net output #0: loss = 1.37426 (* 1 = 1.37426 loss)
I0525 07:02:01.177842 19224 sgd_solver.cpp:106] Iteration 7636, lr = 0.002
I0525 07:02:32.190384 19224 solver.cpp:237] Iteration 7802, loss = 1.38552
I0525 07:02:32.190553 19224 solver.cpp:253]     Train net output #0: loss = 1.38552 (* 1 = 1.38552 loss)
I0525 07:02:32.190569 19224 sgd_solver.cpp:106] Iteration 7802, lr = 0.002
I0525 07:02:41.016029 19224 solver.cpp:237] Iteration 7968, loss = 1.38562
I0525 07:02:41.016065 19224 solver.cpp:253]     Train net output #0: loss = 1.38562 (* 1 = 1.38562 loss)
I0525 07:02:41.016083 19224 sgd_solver.cpp:106] Iteration 7968, lr = 0.002
I0525 07:02:49.849347 19224 solver.cpp:237] Iteration 8134, loss = 1.42483
I0525 07:02:49.849395 19224 solver.cpp:253]     Train net output #0: loss = 1.42483 (* 1 = 1.42483 loss)
I0525 07:02:49.849411 19224 sgd_solver.cpp:106] Iteration 8134, lr = 0.002
I0525 07:02:58.679031 19224 solver.cpp:237] Iteration 8300, loss = 1.24927
I0525 07:02:58.679069 19224 solver.cpp:253]     Train net output #0: loss = 1.24927 (* 1 = 1.24927 loss)
I0525 07:02:58.679085 19224 sgd_solver.cpp:106] Iteration 8300, lr = 0.002
I0525 07:03:00.219030 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_8330.caffemodel
I0525 07:03:00.295944 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_8330.solverstate
I0525 07:03:07.563706 19224 solver.cpp:237] Iteration 8466, loss = 1.46962
I0525 07:03:07.563871 19224 solver.cpp:253]     Train net output #0: loss = 1.46962 (* 1 = 1.46962 loss)
I0525 07:03:07.563887 19224 sgd_solver.cpp:106] Iteration 8466, lr = 0.002
I0525 07:03:16.389026 19224 solver.cpp:237] Iteration 8632, loss = 1.27791
I0525 07:03:16.389067 19224 solver.cpp:253]     Train net output #0: loss = 1.27791 (* 1 = 1.27791 loss)
I0525 07:03:16.389086 19224 sgd_solver.cpp:106] Iteration 8632, lr = 0.002
I0525 07:03:25.213462 19224 solver.cpp:237] Iteration 8798, loss = 1.32059
I0525 07:03:25.213500 19224 solver.cpp:253]     Train net output #0: loss = 1.32059 (* 1 = 1.32059 loss)
I0525 07:03:25.213513 19224 sgd_solver.cpp:106] Iteration 8798, lr = 0.002
I0525 07:03:56.236846 19224 solver.cpp:237] Iteration 8964, loss = 1.51974
I0525 07:03:56.237023 19224 solver.cpp:253]     Train net output #0: loss = 1.51974 (* 1 = 1.51974 loss)
I0525 07:03:56.237046 19224 sgd_solver.cpp:106] Iteration 8964, lr = 0.002
I0525 07:04:05.064007 19224 solver.cpp:237] Iteration 9130, loss = 1.5262
I0525 07:04:05.064048 19224 solver.cpp:253]     Train net output #0: loss = 1.5262 (* 1 = 1.5262 loss)
I0525 07:04:05.064069 19224 sgd_solver.cpp:106] Iteration 9130, lr = 0.002
I0525 07:04:13.886075 19224 solver.cpp:237] Iteration 9296, loss = 1.31188
I0525 07:04:13.886109 19224 solver.cpp:253]     Train net output #0: loss = 1.31188 (* 1 = 1.31188 loss)
I0525 07:04:13.886126 19224 sgd_solver.cpp:106] Iteration 9296, lr = 0.002
I0525 07:04:22.710929 19224 solver.cpp:237] Iteration 9462, loss = 1.40004
I0525 07:04:22.710965 19224 solver.cpp:253]     Train net output #0: loss = 1.40004 (* 1 = 1.40004 loss)
I0525 07:04:22.710983 19224 sgd_solver.cpp:106] Iteration 9462, lr = 0.002
I0525 07:04:31.546999 19224 solver.cpp:237] Iteration 9628, loss = 1.24563
I0525 07:04:31.547154 19224 solver.cpp:253]     Train net output #0: loss = 1.24563 (* 1 = 1.24563 loss)
I0525 07:04:31.547168 19224 sgd_solver.cpp:106] Iteration 9628, lr = 0.002
I0525 07:04:40.375970 19224 solver.cpp:237] Iteration 9794, loss = 1.3683
I0525 07:04:40.376005 19224 solver.cpp:253]     Train net output #0: loss = 1.3683 (* 1 = 1.3683 loss)
I0525 07:04:40.376022 19224 sgd_solver.cpp:106] Iteration 9794, lr = 0.002
I0525 07:04:49.200376 19224 solver.cpp:237] Iteration 9960, loss = 1.30047
I0525 07:04:49.200424 19224 solver.cpp:253]     Train net output #0: loss = 1.30047 (* 1 = 1.30047 loss)
I0525 07:04:49.200440 19224 sgd_solver.cpp:106] Iteration 9960, lr = 0.002
I0525 07:04:51.064254 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_9996.caffemodel
I0525 07:04:51.138044 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_9996.solverstate
I0525 07:04:51.287005 19224 solver.cpp:341] Iteration 9999, Testing net (#0)
I0525 07:05:38.087524 19224 solver.cpp:409]     Test net output #0: accuracy = 0.821647
I0525 07:05:38.087690 19224 solver.cpp:409]     Test net output #1: loss = 0.617589 (* 1 = 0.617589 loss)
I0525 07:06:07.048341 19224 solver.cpp:237] Iteration 10126, loss = 1.34238
I0525 07:06:07.048395 19224 solver.cpp:253]     Train net output #0: loss = 1.34238 (* 1 = 1.34238 loss)
I0525 07:06:07.048413 19224 sgd_solver.cpp:106] Iteration 10126, lr = 0.002
I0525 07:06:15.866165 19224 solver.cpp:237] Iteration 10292, loss = 1.59071
I0525 07:06:15.866331 19224 solver.cpp:253]     Train net output #0: loss = 1.59071 (* 1 = 1.59071 loss)
I0525 07:06:15.866345 19224 sgd_solver.cpp:106] Iteration 10292, lr = 0.002
I0525 07:06:24.682103 19224 solver.cpp:237] Iteration 10458, loss = 1.17568
I0525 07:06:24.682138 19224 solver.cpp:253]     Train net output #0: loss = 1.17568 (* 1 = 1.17568 loss)
I0525 07:06:24.682155 19224 sgd_solver.cpp:106] Iteration 10458, lr = 0.002
I0525 07:06:33.506559 19224 solver.cpp:237] Iteration 10624, loss = 1.17079
I0525 07:06:33.506613 19224 solver.cpp:253]     Train net output #0: loss = 1.17079 (* 1 = 1.17079 loss)
I0525 07:06:33.506628 19224 sgd_solver.cpp:106] Iteration 10624, lr = 0.002
I0525 07:06:42.328181 19224 solver.cpp:237] Iteration 10790, loss = 1.23572
I0525 07:06:42.328214 19224 solver.cpp:253]     Train net output #0: loss = 1.23572 (* 1 = 1.23572 loss)
I0525 07:06:42.328232 19224 sgd_solver.cpp:106] Iteration 10790, lr = 0.002
I0525 07:06:51.151599 19224 solver.cpp:237] Iteration 10956, loss = 1.15125
I0525 07:06:51.151741 19224 solver.cpp:253]     Train net output #0: loss = 1.15125 (* 1 = 1.15125 loss)
I0525 07:06:51.151754 19224 sgd_solver.cpp:106] Iteration 10956, lr = 0.002
I0525 07:07:22.173776 19224 solver.cpp:237] Iteration 11122, loss = 1.36594
I0525 07:07:22.173954 19224 solver.cpp:253]     Train net output #0: loss = 1.36594 (* 1 = 1.36594 loss)
I0525 07:07:22.173969 19224 sgd_solver.cpp:106] Iteration 11122, lr = 0.002
I0525 07:07:30.992586 19224 solver.cpp:237] Iteration 11288, loss = 1.31461
I0525 07:07:30.992621 19224 solver.cpp:253]     Train net output #0: loss = 1.31461 (* 1 = 1.31461 loss)
I0525 07:07:30.992638 19224 sgd_solver.cpp:106] Iteration 11288, lr = 0.002
I0525 07:07:39.815253 19224 solver.cpp:237] Iteration 11454, loss = 1.51713
I0525 07:07:39.815287 19224 solver.cpp:253]     Train net output #0: loss = 1.51713 (* 1 = 1.51713 loss)
I0525 07:07:39.815304 19224 sgd_solver.cpp:106] Iteration 11454, lr = 0.002
I0525 07:07:48.646859 19224 solver.cpp:237] Iteration 11620, loss = 1.43589
I0525 07:07:48.646906 19224 solver.cpp:253]     Train net output #0: loss = 1.43589 (* 1 = 1.43589 loss)
I0525 07:07:48.646922 19224 sgd_solver.cpp:106] Iteration 11620, lr = 0.002
I0525 07:07:50.826108 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_11662.caffemodel
I0525 07:07:50.901729 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_11662.solverstate
I0525 07:07:57.527508 19224 solver.cpp:237] Iteration 11786, loss = 1.32957
I0525 07:07:57.527670 19224 solver.cpp:253]     Train net output #0: loss = 1.32957 (* 1 = 1.32957 loss)
I0525 07:07:57.527684 19224 sgd_solver.cpp:106] Iteration 11786, lr = 0.002
I0525 07:08:06.349762 19224 solver.cpp:237] Iteration 11952, loss = 1.50368
I0525 07:08:06.349797 19224 solver.cpp:253]     Train net output #0: loss = 1.50368 (* 1 = 1.50368 loss)
I0525 07:08:06.349813 19224 sgd_solver.cpp:106] Iteration 11952, lr = 0.002
I0525 07:08:15.163537 19224 solver.cpp:237] Iteration 12118, loss = 1.46695
I0525 07:08:15.163589 19224 solver.cpp:253]     Train net output #0: loss = 1.46695 (* 1 = 1.46695 loss)
I0525 07:08:15.163604 19224 sgd_solver.cpp:106] Iteration 12118, lr = 0.002
I0525 07:08:46.123674 19224 solver.cpp:237] Iteration 12284, loss = 1.31879
I0525 07:08:46.123843 19224 solver.cpp:253]     Train net output #0: loss = 1.31879 (* 1 = 1.31879 loss)
I0525 07:08:46.123859 19224 sgd_solver.cpp:106] Iteration 12284, lr = 0.002
I0525 07:08:54.948041 19224 solver.cpp:237] Iteration 12450, loss = 1.32944
I0525 07:08:54.948076 19224 solver.cpp:253]     Train net output #0: loss = 1.32944 (* 1 = 1.32944 loss)
I0525 07:08:54.948091 19224 sgd_solver.cpp:106] Iteration 12450, lr = 0.002
I0525 07:09:03.767834 19224 solver.cpp:237] Iteration 12616, loss = 1.45389
I0525 07:09:03.767875 19224 solver.cpp:253]     Train net output #0: loss = 1.45389 (* 1 = 1.45389 loss)
I0525 07:09:03.767894 19224 sgd_solver.cpp:106] Iteration 12616, lr = 0.002
I0525 07:09:12.586266 19224 solver.cpp:237] Iteration 12782, loss = 1.33636
I0525 07:09:12.586302 19224 solver.cpp:253]     Train net output #0: loss = 1.33636 (* 1 = 1.33636 loss)
I0525 07:09:12.586318 19224 sgd_solver.cpp:106] Iteration 12782, lr = 0.002
I0525 07:09:21.402707 19224 solver.cpp:237] Iteration 12948, loss = 1.44885
I0525 07:09:21.402848 19224 solver.cpp:253]     Train net output #0: loss = 1.44885 (* 1 = 1.44885 loss)
I0525 07:09:21.402861 19224 sgd_solver.cpp:106] Iteration 12948, lr = 0.002
I0525 07:09:30.227609 19224 solver.cpp:237] Iteration 13114, loss = 1.34737
I0525 07:09:30.227654 19224 solver.cpp:253]     Train net output #0: loss = 1.34737 (* 1 = 1.34737 loss)
I0525 07:09:30.227669 19224 sgd_solver.cpp:106] Iteration 13114, lr = 0.002
I0525 07:09:39.048055 19224 solver.cpp:237] Iteration 13280, loss = 1.37084
I0525 07:09:39.048089 19224 solver.cpp:253]     Train net output #0: loss = 1.37084 (* 1 = 1.37084 loss)
I0525 07:09:39.048106 19224 sgd_solver.cpp:106] Iteration 13280, lr = 0.002
I0525 07:09:41.545317 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_13328.caffemodel
I0525 07:09:41.620697 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_13328.solverstate
I0525 07:09:41.820979 19224 solver.cpp:341] Iteration 13332, Testing net (#0)
I0525 07:10:49.771409 19224 solver.cpp:409]     Test net output #0: accuracy = 0.836088
I0525 07:10:49.771597 19224 solver.cpp:409]     Test net output #1: loss = 0.554093 (* 1 = 0.554093 loss)
I0525 07:11:18.029511 19224 solver.cpp:237] Iteration 13446, loss = 1.54741
I0525 07:11:18.029566 19224 solver.cpp:253]     Train net output #0: loss = 1.54741 (* 1 = 1.54741 loss)
I0525 07:11:18.029580 19224 sgd_solver.cpp:106] Iteration 13446, lr = 0.002
I0525 07:11:26.861717 19224 solver.cpp:237] Iteration 13612, loss = 1.35248
I0525 07:11:26.861871 19224 solver.cpp:253]     Train net output #0: loss = 1.35248 (* 1 = 1.35248 loss)
I0525 07:11:26.861884 19224 sgd_solver.cpp:106] Iteration 13612, lr = 0.002
I0525 07:11:35.701370 19224 solver.cpp:237] Iteration 13778, loss = 1.42911
I0525 07:11:35.701416 19224 solver.cpp:253]     Train net output #0: loss = 1.42911 (* 1 = 1.42911 loss)
I0525 07:11:35.701433 19224 sgd_solver.cpp:106] Iteration 13778, lr = 0.002
I0525 07:11:44.529294 19224 solver.cpp:237] Iteration 13944, loss = 1.4578
I0525 07:11:44.529325 19224 solver.cpp:253]     Train net output #0: loss = 1.4578 (* 1 = 1.4578 loss)
I0525 07:11:44.529336 19224 sgd_solver.cpp:106] Iteration 13944, lr = 0.002
I0525 07:11:53.361023 19224 solver.cpp:237] Iteration 14110, loss = 1.13446
I0525 07:11:53.361063 19224 solver.cpp:253]     Train net output #0: loss = 1.13446 (* 1 = 1.13446 loss)
I0525 07:11:53.361079 19224 sgd_solver.cpp:106] Iteration 14110, lr = 0.002
I0525 07:12:02.195071 19224 solver.cpp:237] Iteration 14276, loss = 1.20005
I0525 07:12:02.195224 19224 solver.cpp:253]     Train net output #0: loss = 1.20005 (* 1 = 1.20005 loss)
I0525 07:12:02.195236 19224 sgd_solver.cpp:106] Iteration 14276, lr = 0.002
I0525 07:12:11.028520 19224 solver.cpp:237] Iteration 14442, loss = 1.27797
I0525 07:12:11.028554 19224 solver.cpp:253]     Train net output #0: loss = 1.27797 (* 1 = 1.27797 loss)
I0525 07:12:11.028571 19224 sgd_solver.cpp:106] Iteration 14442, lr = 0.002
I0525 07:12:42.105201 19224 solver.cpp:237] Iteration 14608, loss = 1.30081
I0525 07:12:42.105368 19224 solver.cpp:253]     Train net output #0: loss = 1.30081 (* 1 = 1.30081 loss)
I0525 07:12:42.105383 19224 sgd_solver.cpp:106] Iteration 14608, lr = 0.002
I0525 07:12:50.945327 19224 solver.cpp:237] Iteration 14774, loss = 1.35703
I0525 07:12:50.945376 19224 solver.cpp:253]     Train net output #0: loss = 1.35703 (* 1 = 1.35703 loss)
I0525 07:12:50.945390 19224 sgd_solver.cpp:106] Iteration 14774, lr = 0.002
I0525 07:12:59.774792 19224 solver.cpp:237] Iteration 14940, loss = 1.25416
I0525 07:12:59.774828 19224 solver.cpp:253]     Train net output #0: loss = 1.25416 (* 1 = 1.25416 loss)
I0525 07:12:59.774842 19224 sgd_solver.cpp:106] Iteration 14940, lr = 0.002
I0525 07:13:02.591213 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_14994.caffemodel
I0525 07:13:02.666857 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_14994.solverstate
I0525 07:13:08.673190 19224 solver.cpp:237] Iteration 15106, loss = 1.42503
I0525 07:13:08.673243 19224 solver.cpp:253]     Train net output #0: loss = 1.42503 (* 1 = 1.42503 loss)
I0525 07:13:08.673261 19224 sgd_solver.cpp:106] Iteration 15106, lr = 0.002
I0525 07:13:17.507175 19224 solver.cpp:237] Iteration 15272, loss = 1.39017
I0525 07:13:17.507316 19224 solver.cpp:253]     Train net output #0: loss = 1.39017 (* 1 = 1.39017 loss)
I0525 07:13:17.507331 19224 sgd_solver.cpp:106] Iteration 15272, lr = 0.002
I0525 07:13:26.340574 19224 solver.cpp:237] Iteration 15438, loss = 1.59522
I0525 07:13:26.340607 19224 solver.cpp:253]     Train net output #0: loss = 1.59522 (* 1 = 1.59522 loss)
I0525 07:13:26.340625 19224 sgd_solver.cpp:106] Iteration 15438, lr = 0.002
I0525 07:13:57.417933 19224 solver.cpp:237] Iteration 15604, loss = 1.56487
I0525 07:13:57.418115 19224 solver.cpp:253]     Train net output #0: loss = 1.56487 (* 1 = 1.56487 loss)
I0525 07:13:57.418133 19224 sgd_solver.cpp:106] Iteration 15604, lr = 0.002
I0525 07:14:06.243710 19224 solver.cpp:237] Iteration 15770, loss = 1.38296
I0525 07:14:06.243746 19224 solver.cpp:253]     Train net output #0: loss = 1.38296 (* 1 = 1.38296 loss)
I0525 07:14:06.243767 19224 sgd_solver.cpp:106] Iteration 15770, lr = 0.002
I0525 07:14:15.084193 19224 solver.cpp:237] Iteration 15936, loss = 1.10482
I0525 07:14:15.084229 19224 solver.cpp:253]     Train net output #0: loss = 1.10482 (* 1 = 1.10482 loss)
I0525 07:14:15.084245 19224 sgd_solver.cpp:106] Iteration 15936, lr = 0.002
I0525 07:14:23.923506 19224 solver.cpp:237] Iteration 16102, loss = 1.27946
I0525 07:14:23.923557 19224 solver.cpp:253]     Train net output #0: loss = 1.27946 (* 1 = 1.27946 loss)
I0525 07:14:23.923573 19224 sgd_solver.cpp:106] Iteration 16102, lr = 0.002
I0525 07:14:32.758611 19224 solver.cpp:237] Iteration 16268, loss = 1.19049
I0525 07:14:32.758759 19224 solver.cpp:253]     Train net output #0: loss = 1.19049 (* 1 = 1.19049 loss)
I0525 07:14:32.758772 19224 sgd_solver.cpp:106] Iteration 16268, lr = 0.002
I0525 07:14:41.589087 19224 solver.cpp:237] Iteration 16434, loss = 1.2368
I0525 07:14:41.589121 19224 solver.cpp:253]     Train net output #0: loss = 1.2368 (* 1 = 1.2368 loss)
I0525 07:14:41.589134 19224 sgd_solver.cpp:106] Iteration 16434, lr = 0.002
I0525 07:14:50.431813 19224 solver.cpp:237] Iteration 16600, loss = 1.145
I0525 07:14:50.431857 19224 solver.cpp:253]     Train net output #0: loss = 1.145 (* 1 = 1.145 loss)
I0525 07:14:50.431876 19224 sgd_solver.cpp:106] Iteration 16600, lr = 0.002
I0525 07:14:53.573063 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_16660.caffemodel
I0525 07:14:53.648813 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_16660.solverstate
I0525 07:14:53.906244 19224 solver.cpp:341] Iteration 16665, Testing net (#0)
I0525 07:15:41.135913 19224 solver.cpp:409]     Test net output #0: accuracy = 0.850021
I0525 07:15:41.136085 19224 solver.cpp:409]     Test net output #1: loss = 0.540945 (* 1 = 0.540945 loss)
I0525 07:16:07.396234 19224 solver.cpp:237] Iteration 16766, loss = 1.22793
I0525 07:16:07.396289 19224 solver.cpp:253]     Train net output #0: loss = 1.22793 (* 1 = 1.22793 loss)
I0525 07:16:07.396306 19224 sgd_solver.cpp:106] Iteration 16766, lr = 0.002
I0525 07:16:16.216117 19224 solver.cpp:237] Iteration 16932, loss = 1.19471
I0525 07:16:16.216265 19224 solver.cpp:253]     Train net output #0: loss = 1.19471 (* 1 = 1.19471 loss)
I0525 07:16:16.216279 19224 sgd_solver.cpp:106] Iteration 16932, lr = 0.002
I0525 07:16:25.046907 19224 solver.cpp:237] Iteration 17098, loss = 1.26284
I0525 07:16:25.046942 19224 solver.cpp:253]     Train net output #0: loss = 1.26284 (* 1 = 1.26284 loss)
I0525 07:16:25.046960 19224 sgd_solver.cpp:106] Iteration 17098, lr = 0.002
I0525 07:16:33.864616 19224 solver.cpp:237] Iteration 17264, loss = 1.2912
I0525 07:16:33.864658 19224 solver.cpp:253]     Train net output #0: loss = 1.2912 (* 1 = 1.2912 loss)
I0525 07:16:33.864678 19224 sgd_solver.cpp:106] Iteration 17264, lr = 0.002
I0525 07:16:42.694294 19224 solver.cpp:237] Iteration 17430, loss = 1.41841
I0525 07:16:42.694329 19224 solver.cpp:253]     Train net output #0: loss = 1.41841 (* 1 = 1.41841 loss)
I0525 07:16:42.694345 19224 sgd_solver.cpp:106] Iteration 17430, lr = 0.002
I0525 07:16:51.523532 19224 solver.cpp:237] Iteration 17596, loss = 1.39257
I0525 07:16:51.523697 19224 solver.cpp:253]     Train net output #0: loss = 1.39257 (* 1 = 1.39257 loss)
I0525 07:16:51.523711 19224 sgd_solver.cpp:106] Iteration 17596, lr = 0.002
I0525 07:17:00.348270 19224 solver.cpp:237] Iteration 17762, loss = 1.22846
I0525 07:17:00.348318 19224 solver.cpp:253]     Train net output #0: loss = 1.22846 (* 1 = 1.22846 loss)
I0525 07:17:00.348335 19224 sgd_solver.cpp:106] Iteration 17762, lr = 0.002
I0525 07:17:30.028885 19224 solver.cpp:237] Iteration 17928, loss = 1.38245
I0525 07:17:30.029073 19224 solver.cpp:253]     Train net output #0: loss = 1.38245 (* 1 = 1.38245 loss)
I0525 07:17:30.029088 19224 sgd_solver.cpp:106] Iteration 17928, lr = 0.002
I0525 07:17:38.852732 19224 solver.cpp:237] Iteration 18094, loss = 1.36248
I0525 07:17:38.852766 19224 solver.cpp:253]     Train net output #0: loss = 1.36248 (* 1 = 1.36248 loss)
I0525 07:17:38.852782 19224 sgd_solver.cpp:106] Iteration 18094, lr = 0.002
I0525 07:17:47.684478 19224 solver.cpp:237] Iteration 18260, loss = 1.23063
I0525 07:17:47.684523 19224 solver.cpp:253]     Train net output #0: loss = 1.23063 (* 1 = 1.23063 loss)
I0525 07:17:47.684543 19224 sgd_solver.cpp:106] Iteration 18260, lr = 0.002
I0525 07:17:51.133714 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_18326.caffemodel
I0525 07:17:51.213095 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_18326.solverstate
I0525 07:17:56.571876 19224 solver.cpp:237] Iteration 18426, loss = 1.25933
I0525 07:17:56.571921 19224 solver.cpp:253]     Train net output #0: loss = 1.25933 (* 1 = 1.25933 loss)
I0525 07:17:56.571943 19224 sgd_solver.cpp:106] Iteration 18426, lr = 0.002
I0525 07:18:05.395051 19224 solver.cpp:237] Iteration 18592, loss = 1.34076
I0525 07:18:05.395201 19224 solver.cpp:253]     Train net output #0: loss = 1.34076 (* 1 = 1.34076 loss)
I0525 07:18:05.395216 19224 sgd_solver.cpp:106] Iteration 18592, lr = 0.002
I0525 07:18:14.215817 19224 solver.cpp:237] Iteration 18758, loss = 1.18583
I0525 07:18:14.215868 19224 solver.cpp:253]     Train net output #0: loss = 1.18583 (* 1 = 1.18583 loss)
I0525 07:18:14.215883 19224 sgd_solver.cpp:106] Iteration 18758, lr = 0.002
I0525 07:18:43.923872 19224 solver.cpp:237] Iteration 18924, loss = 1.24982
I0525 07:18:43.924055 19224 solver.cpp:253]     Train net output #0: loss = 1.24982 (* 1 = 1.24982 loss)
I0525 07:18:43.924070 19224 sgd_solver.cpp:106] Iteration 18924, lr = 0.002
I0525 07:18:52.742832 19224 solver.cpp:237] Iteration 19090, loss = 1.36276
I0525 07:18:52.742867 19224 solver.cpp:253]     Train net output #0: loss = 1.36276 (* 1 = 1.36276 loss)
I0525 07:18:52.742884 19224 sgd_solver.cpp:106] Iteration 19090, lr = 0.002
I0525 07:19:01.563859 19224 solver.cpp:237] Iteration 19256, loss = 1.15628
I0525 07:19:01.563910 19224 solver.cpp:253]     Train net output #0: loss = 1.15628 (* 1 = 1.15628 loss)
I0525 07:19:01.563927 19224 sgd_solver.cpp:106] Iteration 19256, lr = 0.002
I0525 07:19:10.388795 19224 solver.cpp:237] Iteration 19422, loss = 1.33567
I0525 07:19:10.388831 19224 solver.cpp:253]     Train net output #0: loss = 1.33567 (* 1 = 1.33567 loss)
I0525 07:19:10.388849 19224 sgd_solver.cpp:106] Iteration 19422, lr = 0.002
I0525 07:19:19.206162 19224 solver.cpp:237] Iteration 19588, loss = 1.30114
I0525 07:19:19.206320 19224 solver.cpp:253]     Train net output #0: loss = 1.30114 (* 1 = 1.30114 loss)
I0525 07:19:19.206334 19224 sgd_solver.cpp:106] Iteration 19588, lr = 0.002
I0525 07:19:28.039865 19224 solver.cpp:237] Iteration 19754, loss = 1.31226
I0525 07:19:28.039913 19224 solver.cpp:253]     Train net output #0: loss = 1.31226 (* 1 = 1.31226 loss)
I0525 07:19:28.039932 19224 sgd_solver.cpp:106] Iteration 19754, lr = 0.002
I0525 07:19:36.862572 19224 solver.cpp:237] Iteration 19920, loss = 1.3832
I0525 07:19:36.862607 19224 solver.cpp:253]     Train net output #0: loss = 1.3832 (* 1 = 1.3832 loss)
I0525 07:19:36.862623 19224 sgd_solver.cpp:106] Iteration 19920, lr = 0.002
I0525 07:19:40.646066 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_19992.caffemodel
I0525 07:19:40.720058 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_19992.solverstate
I0525 07:19:41.030604 19224 solver.cpp:341] Iteration 19998, Testing net (#0)
I0525 07:20:49.088315 19224 solver.cpp:409]     Test net output #0: accuracy = 0.85379
I0525 07:20:49.088490 19224 solver.cpp:409]     Test net output #1: loss = 0.463298 (* 1 = 0.463298 loss)
I0525 07:21:14.642318 19224 solver.cpp:237] Iteration 20086, loss = 1.30543
I0525 07:21:14.642371 19224 solver.cpp:253]     Train net output #0: loss = 1.30543 (* 1 = 1.30543 loss)
I0525 07:21:14.642388 19224 sgd_solver.cpp:106] Iteration 20086, lr = 0.002
I0525 07:21:23.461648 19224 solver.cpp:237] Iteration 20252, loss = 1.10759
I0525 07:21:23.461805 19224 solver.cpp:253]     Train net output #0: loss = 1.10759 (* 1 = 1.10759 loss)
I0525 07:21:23.461818 19224 sgd_solver.cpp:106] Iteration 20252, lr = 0.002
I0525 07:21:32.283377 19224 solver.cpp:237] Iteration 20418, loss = 1.27437
I0525 07:21:32.283419 19224 solver.cpp:253]     Train net output #0: loss = 1.27437 (* 1 = 1.27437 loss)
I0525 07:21:32.283440 19224 sgd_solver.cpp:106] Iteration 20418, lr = 0.002
I0525 07:21:41.106878 19224 solver.cpp:237] Iteration 20584, loss = 1.29058
I0525 07:21:41.106912 19224 solver.cpp:253]     Train net output #0: loss = 1.29058 (* 1 = 1.29058 loss)
I0525 07:21:41.106930 19224 sgd_solver.cpp:106] Iteration 20584, lr = 0.002
I0525 07:21:49.935793 19224 solver.cpp:237] Iteration 20750, loss = 1.11294
I0525 07:21:49.935828 19224 solver.cpp:253]     Train net output #0: loss = 1.11294 (* 1 = 1.11294 loss)
I0525 07:21:49.935842 19224 sgd_solver.cpp:106] Iteration 20750, lr = 0.002
I0525 07:21:58.764089 19224 solver.cpp:237] Iteration 20916, loss = 1.36231
I0525 07:21:58.764251 19224 solver.cpp:253]     Train net output #0: loss = 1.36231 (* 1 = 1.36231 loss)
I0525 07:21:58.764266 19224 sgd_solver.cpp:106] Iteration 20916, lr = 0.002
I0525 07:22:07.589040 19224 solver.cpp:237] Iteration 21082, loss = 1.28095
I0525 07:22:07.589076 19224 solver.cpp:253]     Train net output #0: loss = 1.28095 (* 1 = 1.28095 loss)
I0525 07:22:07.589092 19224 sgd_solver.cpp:106] Iteration 21082, lr = 0.002
I0525 07:22:37.283298 19224 solver.cpp:237] Iteration 21248, loss = 1.28519
I0525 07:22:37.283473 19224 solver.cpp:253]     Train net output #0: loss = 1.28519 (* 1 = 1.28519 loss)
I0525 07:22:37.283488 19224 sgd_solver.cpp:106] Iteration 21248, lr = 0.002
I0525 07:22:46.111346 19224 solver.cpp:237] Iteration 21414, loss = 1.10249
I0525 07:22:46.111388 19224 solver.cpp:253]     Train net output #0: loss = 1.10249 (* 1 = 1.10249 loss)
I0525 07:22:46.111407 19224 sgd_solver.cpp:106] Iteration 21414, lr = 0.002
I0525 07:22:54.933060 19224 solver.cpp:237] Iteration 21580, loss = 1.30679
I0525 07:22:54.933096 19224 solver.cpp:253]     Train net output #0: loss = 1.30679 (* 1 = 1.30679 loss)
I0525 07:22:54.933114 19224 sgd_solver.cpp:106] Iteration 21580, lr = 0.002
I0525 07:22:59.027500 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_21658.caffemodel
I0525 07:22:59.101529 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_21658.solverstate
I0525 07:23:03.825242 19224 solver.cpp:237] Iteration 21746, loss = 1.15909
I0525 07:23:03.825294 19224 solver.cpp:253]     Train net output #0: loss = 1.15909 (* 1 = 1.15909 loss)
I0525 07:23:03.825310 19224 sgd_solver.cpp:106] Iteration 21746, lr = 0.002
I0525 07:23:12.649660 19224 solver.cpp:237] Iteration 21912, loss = 1.16524
I0525 07:23:12.649835 19224 solver.cpp:253]     Train net output #0: loss = 1.16524 (* 1 = 1.16524 loss)
I0525 07:23:12.649849 19224 sgd_solver.cpp:106] Iteration 21912, lr = 0.002
I0525 07:23:21.473706 19224 solver.cpp:237] Iteration 22078, loss = 1.37152
I0525 07:23:21.473742 19224 solver.cpp:253]     Train net output #0: loss = 1.37152 (* 1 = 1.37152 loss)
I0525 07:23:21.473758 19224 sgd_solver.cpp:106] Iteration 22078, lr = 0.002
I0525 07:23:51.179930 19224 solver.cpp:237] Iteration 22244, loss = 1.2011
I0525 07:23:51.180107 19224 solver.cpp:253]     Train net output #0: loss = 1.2011 (* 1 = 1.2011 loss)
I0525 07:23:51.180122 19224 sgd_solver.cpp:106] Iteration 22244, lr = 0.002
I0525 07:24:00.008669 19224 solver.cpp:237] Iteration 22410, loss = 1.3503
I0525 07:24:00.008718 19224 solver.cpp:253]     Train net output #0: loss = 1.3503 (* 1 = 1.3503 loss)
I0525 07:24:00.008734 19224 sgd_solver.cpp:106] Iteration 22410, lr = 0.002
I0525 07:24:08.840560 19224 solver.cpp:237] Iteration 22576, loss = 1.32827
I0525 07:24:08.840595 19224 solver.cpp:253]     Train net output #0: loss = 1.32827 (* 1 = 1.32827 loss)
I0525 07:24:08.840611 19224 sgd_solver.cpp:106] Iteration 22576, lr = 0.002
I0525 07:24:17.667263 19224 solver.cpp:237] Iteration 22742, loss = 1.15221
I0525 07:24:17.667299 19224 solver.cpp:253]     Train net output #0: loss = 1.15221 (* 1 = 1.15221 loss)
I0525 07:24:17.667315 19224 sgd_solver.cpp:106] Iteration 22742, lr = 0.002
I0525 07:24:26.496459 19224 solver.cpp:237] Iteration 22908, loss = 1.13689
I0525 07:24:26.496620 19224 solver.cpp:253]     Train net output #0: loss = 1.13689 (* 1 = 1.13689 loss)
I0525 07:24:26.496634 19224 sgd_solver.cpp:106] Iteration 22908, lr = 0.002
I0525 07:24:35.327792 19224 solver.cpp:237] Iteration 23074, loss = 1.09895
I0525 07:24:35.327827 19224 solver.cpp:253]     Train net output #0: loss = 1.09895 (* 1 = 1.09895 loss)
I0525 07:24:35.327844 19224 sgd_solver.cpp:106] Iteration 23074, lr = 0.002
I0525 07:24:44.159751 19224 solver.cpp:237] Iteration 23240, loss = 1.16977
I0525 07:24:44.159786 19224 solver.cpp:253]     Train net output #0: loss = 1.16977 (* 1 = 1.16977 loss)
I0525 07:24:44.159802 19224 sgd_solver.cpp:106] Iteration 23240, lr = 0.002
I0525 07:24:48.572393 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_23324.caffemodel
I0525 07:24:48.647308 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_23324.solverstate
I0525 07:24:49.009827 19224 solver.cpp:341] Iteration 23331, Testing net (#0)
I0525 07:25:35.831909 19224 solver.cpp:409]     Test net output #0: accuracy = 0.861814
I0525 07:25:35.832085 19224 solver.cpp:409]     Test net output #1: loss = 0.464178 (* 1 = 0.464178 loss)
I0525 07:26:00.727278 19224 solver.cpp:237] Iteration 23406, loss = 1.12141
I0525 07:26:00.727332 19224 solver.cpp:253]     Train net output #0: loss = 1.12141 (* 1 = 1.12141 loss)
I0525 07:26:00.727349 19224 sgd_solver.cpp:106] Iteration 23406, lr = 0.002
I0525 07:26:09.568588 19224 solver.cpp:237] Iteration 23572, loss = 1.27241
I0525 07:26:09.568758 19224 solver.cpp:253]     Train net output #0: loss = 1.27241 (* 1 = 1.27241 loss)
I0525 07:26:09.568773 19224 sgd_solver.cpp:106] Iteration 23572, lr = 0.002
I0525 07:26:18.410879 19224 solver.cpp:237] Iteration 23738, loss = 1.14231
I0525 07:26:18.410914 19224 solver.cpp:253]     Train net output #0: loss = 1.14231 (* 1 = 1.14231 loss)
I0525 07:26:18.410931 19224 sgd_solver.cpp:106] Iteration 23738, lr = 0.002
I0525 07:26:27.244307 19224 solver.cpp:237] Iteration 23904, loss = 0.920519
I0525 07:26:27.244341 19224 solver.cpp:253]     Train net output #0: loss = 0.920519 (* 1 = 0.920519 loss)
I0525 07:26:27.244357 19224 sgd_solver.cpp:106] Iteration 23904, lr = 0.002
I0525 07:26:36.071388 19224 solver.cpp:237] Iteration 24070, loss = 1.45129
I0525 07:26:36.071425 19224 solver.cpp:253]     Train net output #0: loss = 1.45129 (* 1 = 1.45129 loss)
I0525 07:26:36.071444 19224 sgd_solver.cpp:106] Iteration 24070, lr = 0.002
I0525 07:26:44.902930 19224 solver.cpp:237] Iteration 24236, loss = 1.20526
I0525 07:26:44.903090 19224 solver.cpp:253]     Train net output #0: loss = 1.20526 (* 1 = 1.20526 loss)
I0525 07:26:44.903103 19224 sgd_solver.cpp:106] Iteration 24236, lr = 0.002
I0525 07:26:53.735370 19224 solver.cpp:237] Iteration 24402, loss = 1.15876
I0525 07:26:53.735424 19224 solver.cpp:253]     Train net output #0: loss = 1.15876 (* 1 = 1.15876 loss)
I0525 07:26:53.735440 19224 sgd_solver.cpp:106] Iteration 24402, lr = 0.002
I0525 07:27:23.531008 19224 solver.cpp:237] Iteration 24568, loss = 1.25983
I0525 07:27:23.531186 19224 solver.cpp:253]     Train net output #0: loss = 1.25983 (* 1 = 1.25983 loss)
I0525 07:27:23.531200 19224 sgd_solver.cpp:106] Iteration 24568, lr = 0.002
I0525 07:27:32.352299 19224 solver.cpp:237] Iteration 24734, loss = 1.35041
I0525 07:27:32.352334 19224 solver.cpp:253]     Train net output #0: loss = 1.35041 (* 1 = 1.35041 loss)
I0525 07:27:32.352351 19224 sgd_solver.cpp:106] Iteration 24734, lr = 0.002
I0525 07:27:41.183081 19224 solver.cpp:237] Iteration 24900, loss = 1.29817
I0525 07:27:41.183117 19224 solver.cpp:253]     Train net output #0: loss = 1.29817 (* 1 = 1.29817 loss)
I0525 07:27:41.183133 19224 sgd_solver.cpp:106] Iteration 24900, lr = 0.002
I0525 07:27:45.918550 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_24990.caffemodel
I0525 07:27:45.994472 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_24990.solverstate
I0525 07:27:50.078876 19224 solver.cpp:237] Iteration 25066, loss = 1.34662
I0525 07:27:50.078929 19224 solver.cpp:253]     Train net output #0: loss = 1.34662 (* 1 = 1.34662 loss)
I0525 07:27:50.078943 19224 sgd_solver.cpp:106] Iteration 25066, lr = 0.002
I0525 07:27:58.913389 19224 solver.cpp:237] Iteration 25232, loss = 1.2901
I0525 07:27:58.913553 19224 solver.cpp:253]     Train net output #0: loss = 1.2901 (* 1 = 1.2901 loss)
I0525 07:27:58.913568 19224 sgd_solver.cpp:106] Iteration 25232, lr = 0.002
I0525 07:28:07.747697 19224 solver.cpp:237] Iteration 25398, loss = 1.26186
I0525 07:28:07.747731 19224 solver.cpp:253]     Train net output #0: loss = 1.26186 (* 1 = 1.26186 loss)
I0525 07:28:07.747750 19224 sgd_solver.cpp:106] Iteration 25398, lr = 0.002
I0525 07:28:37.467630 19224 solver.cpp:237] Iteration 25564, loss = 1.08336
I0525 07:28:37.467823 19224 solver.cpp:253]     Train net output #0: loss = 1.08336 (* 1 = 1.08336 loss)
I0525 07:28:37.467836 19224 sgd_solver.cpp:106] Iteration 25564, lr = 0.002
I0525 07:28:46.299079 19224 solver.cpp:237] Iteration 25730, loss = 1.41022
I0525 07:28:46.299113 19224 solver.cpp:253]     Train net output #0: loss = 1.41022 (* 1 = 1.41022 loss)
I0525 07:28:46.299130 19224 sgd_solver.cpp:106] Iteration 25730, lr = 0.002
I0525 07:28:55.123162 19224 solver.cpp:237] Iteration 25896, loss = 1.2397
I0525 07:28:55.123196 19224 solver.cpp:253]     Train net output #0: loss = 1.2397 (* 1 = 1.2397 loss)
I0525 07:28:55.123213 19224 sgd_solver.cpp:106] Iteration 25896, lr = 0.002
I0525 07:29:03.964820 19224 solver.cpp:237] Iteration 26062, loss = 1.55031
I0525 07:29:03.964861 19224 solver.cpp:253]     Train net output #0: loss = 1.55031 (* 1 = 1.55031 loss)
I0525 07:29:03.964882 19224 sgd_solver.cpp:106] Iteration 26062, lr = 0.002
I0525 07:29:12.791837 19224 solver.cpp:237] Iteration 26228, loss = 1.38519
I0525 07:29:12.791986 19224 solver.cpp:253]     Train net output #0: loss = 1.38519 (* 1 = 1.38519 loss)
I0525 07:29:12.791999 19224 sgd_solver.cpp:106] Iteration 26228, lr = 0.002
I0525 07:29:21.629106 19224 solver.cpp:237] Iteration 26394, loss = 1.32395
I0525 07:29:21.629139 19224 solver.cpp:253]     Train net output #0: loss = 1.32395 (* 1 = 1.32395 loss)
I0525 07:29:21.629155 19224 sgd_solver.cpp:106] Iteration 26394, lr = 0.002
I0525 07:29:30.464184 19224 solver.cpp:237] Iteration 26560, loss = 1.24334
I0525 07:29:30.464228 19224 solver.cpp:253]     Train net output #0: loss = 1.24334 (* 1 = 1.24334 loss)
I0525 07:29:30.464244 19224 sgd_solver.cpp:106] Iteration 26560, lr = 0.002
I0525 07:29:35.520439 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_26656.caffemodel
I0525 07:29:35.594766 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_26656.solverstate
I0525 07:29:36.008442 19224 solver.cpp:341] Iteration 26664, Testing net (#0)
I0525 07:30:44.005121 19224 solver.cpp:409]     Test net output #0: accuracy = 0.859426
I0525 07:30:44.005307 19224 solver.cpp:409]     Test net output #1: loss = 0.459305 (* 1 = 0.459305 loss)
I0525 07:31:08.137361 19224 solver.cpp:237] Iteration 26726, loss = 1.13478
I0525 07:31:08.137413 19224 solver.cpp:253]     Train net output #0: loss = 1.13478 (* 1 = 1.13478 loss)
I0525 07:31:08.137430 19224 sgd_solver.cpp:106] Iteration 26726, lr = 0.002
I0525 07:31:16.958557 19224 solver.cpp:237] Iteration 26892, loss = 1.15947
I0525 07:31:16.958714 19224 solver.cpp:253]     Train net output #0: loss = 1.15947 (* 1 = 1.15947 loss)
I0525 07:31:16.958729 19224 sgd_solver.cpp:106] Iteration 26892, lr = 0.002
I0525 07:31:25.783013 19224 solver.cpp:237] Iteration 27058, loss = 1.20434
I0525 07:31:25.783048 19224 solver.cpp:253]     Train net output #0: loss = 1.20434 (* 1 = 1.20434 loss)
I0525 07:31:25.783066 19224 sgd_solver.cpp:106] Iteration 27058, lr = 0.002
I0525 07:31:34.601357 19224 solver.cpp:237] Iteration 27224, loss = 1.32446
I0525 07:31:34.601403 19224 solver.cpp:253]     Train net output #0: loss = 1.32446 (* 1 = 1.32446 loss)
I0525 07:31:34.601421 19224 sgd_solver.cpp:106] Iteration 27224, lr = 0.002
I0525 07:31:43.430627 19224 solver.cpp:237] Iteration 27390, loss = 1.18179
I0525 07:31:43.430662 19224 solver.cpp:253]     Train net output #0: loss = 1.18179 (* 1 = 1.18179 loss)
I0525 07:31:43.430678 19224 sgd_solver.cpp:106] Iteration 27390, lr = 0.002
I0525 07:31:52.255956 19224 solver.cpp:237] Iteration 27556, loss = 1.25752
I0525 07:31:52.256106 19224 solver.cpp:253]     Train net output #0: loss = 1.25752 (* 1 = 1.25752 loss)
I0525 07:31:52.256120 19224 sgd_solver.cpp:106] Iteration 27556, lr = 0.002
I0525 07:32:01.075696 19224 solver.cpp:237] Iteration 27722, loss = 1.11223
I0525 07:32:01.075744 19224 solver.cpp:253]     Train net output #0: loss = 1.11223 (* 1 = 1.11223 loss)
I0525 07:32:01.075760 19224 sgd_solver.cpp:106] Iteration 27722, lr = 0.002
I0525 07:32:30.732666 19224 solver.cpp:237] Iteration 27888, loss = 1.20636
I0525 07:32:30.732841 19224 solver.cpp:253]     Train net output #0: loss = 1.20636 (* 1 = 1.20636 loss)
I0525 07:32:30.732854 19224 sgd_solver.cpp:106] Iteration 27888, lr = 0.002
I0525 07:32:39.553426 19224 solver.cpp:237] Iteration 28054, loss = 1.32281
I0525 07:32:39.553462 19224 solver.cpp:253]     Train net output #0: loss = 1.32281 (* 1 = 1.32281 loss)
I0525 07:32:39.553475 19224 sgd_solver.cpp:106] Iteration 28054, lr = 0.002
I0525 07:32:48.370019 19224 solver.cpp:237] Iteration 28220, loss = 1.1208
I0525 07:32:48.370066 19224 solver.cpp:253]     Train net output #0: loss = 1.1208 (* 1 = 1.1208 loss)
I0525 07:32:48.370086 19224 sgd_solver.cpp:106] Iteration 28220, lr = 0.002
I0525 07:32:53.741854 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_28322.caffemodel
I0525 07:32:53.819283 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_28322.solverstate
I0525 07:32:57.258442 19224 solver.cpp:237] Iteration 28386, loss = 1.29877
I0525 07:32:57.258489 19224 solver.cpp:253]     Train net output #0: loss = 1.29877 (* 1 = 1.29877 loss)
I0525 07:32:57.258507 19224 sgd_solver.cpp:106] Iteration 28386, lr = 0.002
I0525 07:33:06.079068 19224 solver.cpp:237] Iteration 28552, loss = 1.37162
I0525 07:33:06.079234 19224 solver.cpp:253]     Train net output #0: loss = 1.37162 (* 1 = 1.37162 loss)
I0525 07:33:06.079248 19224 sgd_solver.cpp:106] Iteration 28552, lr = 0.002
I0525 07:33:14.898052 19224 solver.cpp:237] Iteration 28718, loss = 1.24768
I0525 07:33:14.898095 19224 solver.cpp:253]     Train net output #0: loss = 1.24768 (* 1 = 1.24768 loss)
I0525 07:33:14.898115 19224 sgd_solver.cpp:106] Iteration 28718, lr = 0.002
I0525 07:33:23.714229 19224 solver.cpp:237] Iteration 28884, loss = 1.24293
I0525 07:33:23.714264 19224 solver.cpp:253]     Train net output #0: loss = 1.24293 (* 1 = 1.24293 loss)
I0525 07:33:23.714280 19224 sgd_solver.cpp:106] Iteration 28884, lr = 0.002
I0525 07:33:53.399147 19224 solver.cpp:237] Iteration 29050, loss = 1.46981
I0525 07:33:53.399327 19224 solver.cpp:253]     Train net output #0: loss = 1.46981 (* 1 = 1.46981 loss)
I0525 07:33:53.399341 19224 sgd_solver.cpp:106] Iteration 29050, lr = 0.002
I0525 07:34:02.212972 19224 solver.cpp:237] Iteration 29216, loss = 0.890701
I0525 07:34:02.213012 19224 solver.cpp:253]     Train net output #0: loss = 0.890701 (* 1 = 0.890701 loss)
I0525 07:34:02.213029 19224 sgd_solver.cpp:106] Iteration 29216, lr = 0.002
I0525 07:34:11.038656 19224 solver.cpp:237] Iteration 29382, loss = 1.07311
I0525 07:34:11.038691 19224 solver.cpp:253]     Train net output #0: loss = 1.07311 (* 1 = 1.07311 loss)
I0525 07:34:11.038708 19224 sgd_solver.cpp:106] Iteration 29382, lr = 0.002
I0525 07:34:19.858460 19224 solver.cpp:237] Iteration 29548, loss = 1.2099
I0525 07:34:19.858496 19224 solver.cpp:253]     Train net output #0: loss = 1.2099 (* 1 = 1.2099 loss)
I0525 07:34:19.858510 19224 sgd_solver.cpp:106] Iteration 29548, lr = 0.002
I0525 07:34:28.671082 19224 solver.cpp:237] Iteration 29714, loss = 1.03801
I0525 07:34:28.671252 19224 solver.cpp:253]     Train net output #0: loss = 1.03801 (* 1 = 1.03801 loss)
I0525 07:34:28.671265 19224 sgd_solver.cpp:106] Iteration 29714, lr = 0.002
I0525 07:34:37.496860 19224 solver.cpp:237] Iteration 29880, loss = 1.16348
I0525 07:34:37.496894 19224 solver.cpp:253]     Train net output #0: loss = 1.16348 (* 1 = 1.16348 loss)
I0525 07:34:37.496912 19224 sgd_solver.cpp:106] Iteration 29880, lr = 0.002
I0525 07:34:43.179966 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_29988.caffemodel
I0525 07:34:43.254477 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_29988.solverstate
I0525 07:34:43.722832 19224 solver.cpp:341] Iteration 29997, Testing net (#0)
I0525 07:35:30.832583 19224 solver.cpp:409]     Test net output #0: accuracy = 0.865389
I0525 07:35:30.832762 19224 solver.cpp:409]     Test net output #1: loss = 0.438714 (* 1 = 0.438714 loss)
I0525 07:35:54.318203 19224 solver.cpp:237] Iteration 30046, loss = 1.26868
I0525 07:35:54.318259 19224 solver.cpp:253]     Train net output #0: loss = 1.26868 (* 1 = 1.26868 loss)
I0525 07:35:54.318274 19224 sgd_solver.cpp:106] Iteration 30046, lr = 0.002
I0525 07:36:03.148110 19224 solver.cpp:237] Iteration 30212, loss = 1.29487
I0525 07:36:03.148268 19224 solver.cpp:253]     Train net output #0: loss = 1.29487 (* 1 = 1.29487 loss)
I0525 07:36:03.148283 19224 sgd_solver.cpp:106] Iteration 30212, lr = 0.002
I0525 07:36:11.976665 19224 solver.cpp:237] Iteration 30378, loss = 1.37677
I0525 07:36:11.976703 19224 solver.cpp:253]     Train net output #0: loss = 1.37677 (* 1 = 1.37677 loss)
I0525 07:36:11.976724 19224 sgd_solver.cpp:106] Iteration 30378, lr = 0.002
I0525 07:36:20.806288 19224 solver.cpp:237] Iteration 30544, loss = 1.1929
I0525 07:36:20.806324 19224 solver.cpp:253]     Train net output #0: loss = 1.1929 (* 1 = 1.1929 loss)
I0525 07:36:20.806339 19224 sgd_solver.cpp:106] Iteration 30544, lr = 0.002
I0525 07:36:29.634241 19224 solver.cpp:237] Iteration 30710, loss = 1.30899
I0525 07:36:29.634289 19224 solver.cpp:253]     Train net output #0: loss = 1.30899 (* 1 = 1.30899 loss)
I0525 07:36:29.634305 19224 sgd_solver.cpp:106] Iteration 30710, lr = 0.002
I0525 07:36:38.460686 19224 solver.cpp:237] Iteration 30876, loss = 1.10113
I0525 07:36:38.460855 19224 solver.cpp:253]     Train net output #0: loss = 1.10113 (* 1 = 1.10113 loss)
I0525 07:36:38.460870 19224 sgd_solver.cpp:106] Iteration 30876, lr = 0.002
I0525 07:36:47.283470 19224 solver.cpp:237] Iteration 31042, loss = 1.19566
I0525 07:36:47.283504 19224 solver.cpp:253]     Train net output #0: loss = 1.19566 (* 1 = 1.19566 loss)
I0525 07:36:47.283521 19224 sgd_solver.cpp:106] Iteration 31042, lr = 0.002
I0525 07:37:16.992228 19224 solver.cpp:237] Iteration 31208, loss = 1.0494
I0525 07:37:16.992410 19224 solver.cpp:253]     Train net output #0: loss = 1.0494 (* 1 = 1.0494 loss)
I0525 07:37:16.992426 19224 sgd_solver.cpp:106] Iteration 31208, lr = 0.002
I0525 07:37:25.817276 19224 solver.cpp:237] Iteration 31374, loss = 1.2887
I0525 07:37:25.817320 19224 solver.cpp:253]     Train net output #0: loss = 1.2887 (* 1 = 1.2887 loss)
I0525 07:37:25.817340 19224 sgd_solver.cpp:106] Iteration 31374, lr = 0.002
I0525 07:37:34.643474 19224 solver.cpp:237] Iteration 31540, loss = 1.15501
I0525 07:37:34.643510 19224 solver.cpp:253]     Train net output #0: loss = 1.15501 (* 1 = 1.15501 loss)
I0525 07:37:34.643527 19224 sgd_solver.cpp:106] Iteration 31540, lr = 0.002
I0525 07:37:40.648710 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_31654.caffemodel
I0525 07:37:40.727267 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_31654.solverstate
I0525 07:37:43.536805 19224 solver.cpp:237] Iteration 31706, loss = 1.07506
I0525 07:37:43.536864 19224 solver.cpp:253]     Train net output #0: loss = 1.07506 (* 1 = 1.07506 loss)
I0525 07:37:43.536877 19224 sgd_solver.cpp:106] Iteration 31706, lr = 0.002
I0525 07:37:52.370393 19224 solver.cpp:237] Iteration 31872, loss = 1.33589
I0525 07:37:52.370553 19224 solver.cpp:253]     Train net output #0: loss = 1.33589 (* 1 = 1.33589 loss)
I0525 07:37:52.370566 19224 sgd_solver.cpp:106] Iteration 31872, lr = 0.002
I0525 07:38:01.203547 19224 solver.cpp:237] Iteration 32038, loss = 1.46553
I0525 07:38:01.203583 19224 solver.cpp:253]     Train net output #0: loss = 1.46553 (* 1 = 1.46553 loss)
I0525 07:38:01.203598 19224 sgd_solver.cpp:106] Iteration 32038, lr = 0.002
I0525 07:38:10.034111 19224 solver.cpp:237] Iteration 32204, loss = 1.35852
I0525 07:38:10.034164 19224 solver.cpp:253]     Train net output #0: loss = 1.35852 (* 1 = 1.35852 loss)
I0525 07:38:10.034179 19224 sgd_solver.cpp:106] Iteration 32204, lr = 0.002
I0525 07:38:39.756105 19224 solver.cpp:237] Iteration 32370, loss = 1.08528
I0525 07:38:39.756288 19224 solver.cpp:253]     Train net output #0: loss = 1.08528 (* 1 = 1.08528 loss)
I0525 07:38:39.756302 19224 sgd_solver.cpp:106] Iteration 32370, lr = 0.002
I0525 07:38:48.578555 19224 solver.cpp:237] Iteration 32536, loss = 1.44509
I0525 07:38:48.578589 19224 solver.cpp:253]     Train net output #0: loss = 1.44509 (* 1 = 1.44509 loss)
I0525 07:38:48.578608 19224 sgd_solver.cpp:106] Iteration 32536, lr = 0.002
I0525 07:38:57.400732 19224 solver.cpp:237] Iteration 32702, loss = 1.02874
I0525 07:38:57.400766 19224 solver.cpp:253]     Train net output #0: loss = 1.02874 (* 1 = 1.02874 loss)
I0525 07:38:57.400780 19224 sgd_solver.cpp:106] Iteration 32702, lr = 0.002
I0525 07:39:06.224407 19224 solver.cpp:237] Iteration 32868, loss = 1.34273
I0525 07:39:06.224458 19224 solver.cpp:253]     Train net output #0: loss = 1.34273 (* 1 = 1.34273 loss)
I0525 07:39:06.224472 19224 sgd_solver.cpp:106] Iteration 32868, lr = 0.002
I0525 07:39:15.045517 19224 solver.cpp:237] Iteration 33034, loss = 1.40441
I0525 07:39:15.045681 19224 solver.cpp:253]     Train net output #0: loss = 1.40441 (* 1 = 1.40441 loss)
I0525 07:39:15.045696 19224 sgd_solver.cpp:106] Iteration 33034, lr = 0.002
I0525 07:39:23.871829 19224 solver.cpp:237] Iteration 33200, loss = 1.33681
I0525 07:39:23.871877 19224 solver.cpp:253]     Train net output #0: loss = 1.33681 (* 1 = 1.33681 loss)
I0525 07:39:23.871896 19224 sgd_solver.cpp:106] Iteration 33200, lr = 0.002
I0525 07:39:30.200014 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_33320.caffemodel
I0525 07:39:30.277101 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_33320.solverstate
I0525 07:39:30.802289 19224 solver.cpp:341] Iteration 33330, Testing net (#0)
I0525 07:40:38.869479 19224 solver.cpp:409]     Test net output #0: accuracy = 0.872605
I0525 07:40:38.869649 19224 solver.cpp:409]     Test net output #1: loss = 0.42891 (* 1 = 0.42891 loss)
I0525 07:41:01.701642 19224 solver.cpp:237] Iteration 33366, loss = 1.25238
I0525 07:41:01.701692 19224 solver.cpp:253]     Train net output #0: loss = 1.25238 (* 1 = 1.25238 loss)
I0525 07:41:01.701711 19224 sgd_solver.cpp:106] Iteration 33366, lr = 0.002
I0525 07:41:10.519816 19224 solver.cpp:237] Iteration 33532, loss = 1.19939
I0525 07:41:10.519984 19224 solver.cpp:253]     Train net output #0: loss = 1.19939 (* 1 = 1.19939 loss)
I0525 07:41:10.519997 19224 sgd_solver.cpp:106] Iteration 33532, lr = 0.002
I0525 07:41:19.339654 19224 solver.cpp:237] Iteration 33698, loss = 1.12598
I0525 07:41:19.339689 19224 solver.cpp:253]     Train net output #0: loss = 1.12598 (* 1 = 1.12598 loss)
I0525 07:41:19.339706 19224 sgd_solver.cpp:106] Iteration 33698, lr = 0.002
I0525 07:41:28.164054 19224 solver.cpp:237] Iteration 33864, loss = 1.19599
I0525 07:41:28.164089 19224 solver.cpp:253]     Train net output #0: loss = 1.19599 (* 1 = 1.19599 loss)
I0525 07:41:28.164105 19224 sgd_solver.cpp:106] Iteration 33864, lr = 0.002
I0525 07:41:36.982903 19224 solver.cpp:237] Iteration 34030, loss = 1.30224
I0525 07:41:36.982935 19224 solver.cpp:253]     Train net output #0: loss = 1.30224 (* 1 = 1.30224 loss)
I0525 07:41:36.982957 19224 sgd_solver.cpp:106] Iteration 34030, lr = 0.002
I0525 07:41:45.803390 19224 solver.cpp:237] Iteration 34196, loss = 1.12876
I0525 07:41:45.803545 19224 solver.cpp:253]     Train net output #0: loss = 1.12876 (* 1 = 1.12876 loss)
I0525 07:41:45.803560 19224 sgd_solver.cpp:106] Iteration 34196, lr = 0.002
I0525 07:41:54.628578 19224 solver.cpp:237] Iteration 34362, loss = 1.31542
I0525 07:41:54.628619 19224 solver.cpp:253]     Train net output #0: loss = 1.31542 (* 1 = 1.31542 loss)
I0525 07:41:54.628633 19224 sgd_solver.cpp:106] Iteration 34362, lr = 0.002
I0525 07:42:24.326088 19224 solver.cpp:237] Iteration 34528, loss = 1.16763
I0525 07:42:24.326269 19224 solver.cpp:253]     Train net output #0: loss = 1.16763 (* 1 = 1.16763 loss)
I0525 07:42:24.326283 19224 sgd_solver.cpp:106] Iteration 34528, lr = 0.002
I0525 07:42:33.148066 19224 solver.cpp:237] Iteration 34694, loss = 1.29207
I0525 07:42:33.148100 19224 solver.cpp:253]     Train net output #0: loss = 1.29207 (* 1 = 1.29207 loss)
I0525 07:42:33.148118 19224 sgd_solver.cpp:106] Iteration 34694, lr = 0.002
I0525 07:42:41.972291 19224 solver.cpp:237] Iteration 34860, loss = 1.19151
I0525 07:42:41.972327 19224 solver.cpp:253]     Train net output #0: loss = 1.19151 (* 1 = 1.19151 loss)
I0525 07:42:41.972343 19224 sgd_solver.cpp:106] Iteration 34860, lr = 0.002
I0525 07:42:48.615728 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_34986.caffemodel
I0525 07:42:48.690106 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_34986.solverstate
I0525 07:42:50.862653 19224 solver.cpp:237] Iteration 35026, loss = 1.15766
I0525 07:42:50.862699 19224 solver.cpp:253]     Train net output #0: loss = 1.15766 (* 1 = 1.15766 loss)
I0525 07:42:50.862716 19224 sgd_solver.cpp:106] Iteration 35026, lr = 0.002
I0525 07:42:59.690261 19224 solver.cpp:237] Iteration 35192, loss = 1.15526
I0525 07:42:59.690430 19224 solver.cpp:253]     Train net output #0: loss = 1.15526 (* 1 = 1.15526 loss)
I0525 07:42:59.690443 19224 sgd_solver.cpp:106] Iteration 35192, lr = 0.002
I0525 07:43:08.507621 19224 solver.cpp:237] Iteration 35358, loss = 1.24954
I0525 07:43:08.507655 19224 solver.cpp:253]     Train net output #0: loss = 1.24954 (* 1 = 1.24954 loss)
I0525 07:43:08.507669 19224 sgd_solver.cpp:106] Iteration 35358, lr = 0.002
I0525 07:43:17.329471 19224 solver.cpp:237] Iteration 35524, loss = 1.1977
I0525 07:43:17.329510 19224 solver.cpp:253]     Train net output #0: loss = 1.1977 (* 1 = 1.1977 loss)
I0525 07:43:17.329529 19224 sgd_solver.cpp:106] Iteration 35524, lr = 0.002
I0525 07:43:47.006386 19224 solver.cpp:237] Iteration 35690, loss = 1.01867
I0525 07:43:47.006570 19224 solver.cpp:253]     Train net output #0: loss = 1.01867 (* 1 = 1.01867 loss)
I0525 07:43:47.006587 19224 sgd_solver.cpp:106] Iteration 35690, lr = 0.002
I0525 07:43:55.834520 19224 solver.cpp:237] Iteration 35856, loss = 1.0385
I0525 07:43:55.834554 19224 solver.cpp:253]     Train net output #0: loss = 1.0385 (* 1 = 1.0385 loss)
I0525 07:43:55.834571 19224 sgd_solver.cpp:106] Iteration 35856, lr = 0.002
I0525 07:44:04.661670 19224 solver.cpp:237] Iteration 36022, loss = 1.23298
I0525 07:44:04.661715 19224 solver.cpp:253]     Train net output #0: loss = 1.23298 (* 1 = 1.23298 loss)
I0525 07:44:04.661736 19224 sgd_solver.cpp:106] Iteration 36022, lr = 0.002
I0525 07:44:13.475230 19224 solver.cpp:237] Iteration 36188, loss = 1.15046
I0525 07:44:13.475266 19224 solver.cpp:253]     Train net output #0: loss = 1.15046 (* 1 = 1.15046 loss)
I0525 07:44:13.475282 19224 sgd_solver.cpp:106] Iteration 36188, lr = 0.002
I0525 07:44:22.297412 19224 solver.cpp:237] Iteration 36354, loss = 1.2804
I0525 07:44:22.297567 19224 solver.cpp:253]     Train net output #0: loss = 1.2804 (* 1 = 1.2804 loss)
I0525 07:44:22.297580 19224 sgd_solver.cpp:106] Iteration 36354, lr = 0.002
I0525 07:44:31.118963 19224 solver.cpp:237] Iteration 36520, loss = 1.08353
I0525 07:44:31.119004 19224 solver.cpp:253]     Train net output #0: loss = 1.08353 (* 1 = 1.08353 loss)
I0525 07:44:31.119022 19224 sgd_solver.cpp:106] Iteration 36520, lr = 0.002
I0525 07:44:38.085289 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_36652.caffemodel
I0525 07:44:38.159821 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_36652.solverstate
I0525 07:44:38.737303 19224 solver.cpp:341] Iteration 36663, Testing net (#0)
I0525 07:45:25.628443 19224 solver.cpp:409]     Test net output #0: accuracy = 0.872725
I0525 07:45:25.628633 19224 solver.cpp:409]     Test net output #1: loss = 0.410031 (* 1 = 0.410031 loss)
I0525 07:45:47.748376 19224 solver.cpp:237] Iteration 36686, loss = 1.28492
I0525 07:45:47.748430 19224 solver.cpp:253]     Train net output #0: loss = 1.28492 (* 1 = 1.28492 loss)
I0525 07:45:47.748446 19224 sgd_solver.cpp:106] Iteration 36686, lr = 0.002
I0525 07:45:56.591753 19224 solver.cpp:237] Iteration 36852, loss = 1.20923
I0525 07:45:56.591927 19224 solver.cpp:253]     Train net output #0: loss = 1.20923 (* 1 = 1.20923 loss)
I0525 07:45:56.591940 19224 sgd_solver.cpp:106] Iteration 36852, lr = 0.002
I0525 07:46:05.421613 19224 solver.cpp:237] Iteration 37018, loss = 1.09865
I0525 07:46:05.421661 19224 solver.cpp:253]     Train net output #0: loss = 1.09865 (* 1 = 1.09865 loss)
I0525 07:46:05.421679 19224 sgd_solver.cpp:106] Iteration 37018, lr = 0.002
I0525 07:46:14.248759 19224 solver.cpp:237] Iteration 37184, loss = 1.01111
I0525 07:46:14.248795 19224 solver.cpp:253]     Train net output #0: loss = 1.01111 (* 1 = 1.01111 loss)
I0525 07:46:14.248811 19224 sgd_solver.cpp:106] Iteration 37184, lr = 0.002
I0525 07:46:23.088680 19224 solver.cpp:237] Iteration 37350, loss = 1.12292
I0525 07:46:23.088716 19224 solver.cpp:253]     Train net output #0: loss = 1.12292 (* 1 = 1.12292 loss)
I0525 07:46:23.088732 19224 sgd_solver.cpp:106] Iteration 37350, lr = 0.002
I0525 07:46:31.918200 19224 solver.cpp:237] Iteration 37516, loss = 1.25
I0525 07:46:31.918360 19224 solver.cpp:253]     Train net output #0: loss = 1.25 (* 1 = 1.25 loss)
I0525 07:46:31.918375 19224 sgd_solver.cpp:106] Iteration 37516, lr = 0.002
I0525 07:46:40.756047 19224 solver.cpp:237] Iteration 37682, loss = 1.08593
I0525 07:46:40.756080 19224 solver.cpp:253]     Train net output #0: loss = 1.08593 (* 1 = 1.08593 loss)
I0525 07:46:40.756098 19224 sgd_solver.cpp:106] Iteration 37682, lr = 0.002
I0525 07:47:10.485407 19224 solver.cpp:237] Iteration 37848, loss = 1.22797
I0525 07:47:10.485589 19224 solver.cpp:253]     Train net output #0: loss = 1.22797 (* 1 = 1.22797 loss)
I0525 07:47:10.485605 19224 sgd_solver.cpp:106] Iteration 37848, lr = 0.002
I0525 07:47:19.318437 19224 solver.cpp:237] Iteration 38014, loss = 1.06724
I0525 07:47:19.318485 19224 solver.cpp:253]     Train net output #0: loss = 1.06724 (* 1 = 1.06724 loss)
I0525 07:47:19.318503 19224 sgd_solver.cpp:106] Iteration 38014, lr = 0.002
I0525 07:47:28.155979 19224 solver.cpp:237] Iteration 38180, loss = 1.12842
I0525 07:47:28.156015 19224 solver.cpp:253]     Train net output #0: loss = 1.12842 (* 1 = 1.12842 loss)
I0525 07:47:28.156031 19224 sgd_solver.cpp:106] Iteration 38180, lr = 0.002
I0525 07:47:35.446321 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_38318.caffemodel
I0525 07:47:35.531790 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_38318.solverstate
I0525 07:47:37.067101 19224 solver.cpp:237] Iteration 38346, loss = 1.43371
I0525 07:47:37.067147 19224 solver.cpp:253]     Train net output #0: loss = 1.43371 (* 1 = 1.43371 loss)
I0525 07:47:37.067167 19224 sgd_solver.cpp:106] Iteration 38346, lr = 0.002
I0525 07:47:45.906385 19224 solver.cpp:237] Iteration 38512, loss = 1.40025
I0525 07:47:45.906556 19224 solver.cpp:253]     Train net output #0: loss = 1.40025 (* 1 = 1.40025 loss)
I0525 07:47:45.906570 19224 sgd_solver.cpp:106] Iteration 38512, lr = 0.002
I0525 07:47:54.739138 19224 solver.cpp:237] Iteration 38678, loss = 1.15333
I0525 07:47:54.739172 19224 solver.cpp:253]     Train net output #0: loss = 1.15333 (* 1 = 1.15333 loss)
I0525 07:47:54.739187 19224 sgd_solver.cpp:106] Iteration 38678, lr = 0.002
I0525 07:48:03.573580 19224 solver.cpp:237] Iteration 38844, loss = 1.10782
I0525 07:48:03.573616 19224 solver.cpp:253]     Train net output #0: loss = 1.10782 (* 1 = 1.10782 loss)
I0525 07:48:03.573633 19224 sgd_solver.cpp:106] Iteration 38844, lr = 0.002
I0525 07:48:33.260844 19224 solver.cpp:237] Iteration 39010, loss = 1.48472
I0525 07:48:33.261029 19224 solver.cpp:253]     Train net output #0: loss = 1.48472 (* 1 = 1.48472 loss)
I0525 07:48:33.261050 19224 sgd_solver.cpp:106] Iteration 39010, lr = 0.002
I0525 07:48:42.094941 19224 solver.cpp:237] Iteration 39176, loss = 1.27356
I0525 07:48:42.094975 19224 solver.cpp:253]     Train net output #0: loss = 1.27356 (* 1 = 1.27356 loss)
I0525 07:48:42.094997 19224 sgd_solver.cpp:106] Iteration 39176, lr = 0.002
I0525 07:48:50.939740 19224 solver.cpp:237] Iteration 39342, loss = 1.43552
I0525 07:48:50.939776 19224 solver.cpp:253]     Train net output #0: loss = 1.43552 (* 1 = 1.43552 loss)
I0525 07:48:50.939793 19224 sgd_solver.cpp:106] Iteration 39342, lr = 0.002
I0525 07:48:59.779099 19224 solver.cpp:237] Iteration 39508, loss = 1.46106
I0525 07:48:59.779145 19224 solver.cpp:253]     Train net output #0: loss = 1.46106 (* 1 = 1.46106 loss)
I0525 07:48:59.779165 19224 sgd_solver.cpp:106] Iteration 39508, lr = 0.002
I0525 07:49:08.622225 19224 solver.cpp:237] Iteration 39674, loss = 1.22737
I0525 07:49:08.622393 19224 solver.cpp:253]     Train net output #0: loss = 1.22737 (* 1 = 1.22737 loss)
I0525 07:49:08.622407 19224 sgd_solver.cpp:106] Iteration 39674, lr = 0.002
I0525 07:49:17.464200 19224 solver.cpp:237] Iteration 39840, loss = 1.20727
I0525 07:49:17.464233 19224 solver.cpp:253]     Train net output #0: loss = 1.20727 (* 1 = 1.20727 loss)
I0525 07:49:17.464251 19224 sgd_solver.cpp:106] Iteration 39840, lr = 0.002
I0525 07:49:25.077102 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_39984.caffemodel
I0525 07:49:25.154096 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_39984.solverstate
I0525 07:49:25.782574 19224 solver.cpp:341] Iteration 39996, Testing net (#0)
I0525 07:50:33.840378 19224 solver.cpp:409]     Test net output #0: accuracy = 0.876741
I0525 07:50:33.840562 19224 solver.cpp:409]     Test net output #1: loss = 0.412454 (* 1 = 0.412454 loss)
I0525 07:50:55.289332 19224 solver.cpp:237] Iteration 40006, loss = 1.28019
I0525 07:50:55.289388 19224 solver.cpp:253]     Train net output #0: loss = 1.28019 (* 1 = 1.28019 loss)
I0525 07:50:55.289403 19224 sgd_solver.cpp:106] Iteration 40006, lr = 0.002
I0525 07:51:04.112650 19224 solver.cpp:237] Iteration 40172, loss = 1.22698
I0525 07:51:04.112823 19224 solver.cpp:253]     Train net output #0: loss = 1.22698 (* 1 = 1.22698 loss)
I0525 07:51:04.112836 19224 sgd_solver.cpp:106] Iteration 40172, lr = 0.002
I0525 07:51:12.940070 19224 solver.cpp:237] Iteration 40338, loss = 1.38156
I0525 07:51:12.940105 19224 solver.cpp:253]     Train net output #0: loss = 1.38156 (* 1 = 1.38156 loss)
I0525 07:51:12.940120 19224 sgd_solver.cpp:106] Iteration 40338, lr = 0.002
I0525 07:51:21.767647 19224 solver.cpp:237] Iteration 40504, loss = 1.05511
I0525 07:51:21.767683 19224 solver.cpp:253]     Train net output #0: loss = 1.05511 (* 1 = 1.05511 loss)
I0525 07:51:21.767699 19224 sgd_solver.cpp:106] Iteration 40504, lr = 0.002
I0525 07:51:30.593349 19224 solver.cpp:237] Iteration 40670, loss = 1.1328
I0525 07:51:30.593403 19224 solver.cpp:253]     Train net output #0: loss = 1.1328 (* 1 = 1.1328 loss)
I0525 07:51:30.593418 19224 sgd_solver.cpp:106] Iteration 40670, lr = 0.002
I0525 07:51:39.415853 19224 solver.cpp:237] Iteration 40836, loss = 1.04188
I0525 07:51:39.416013 19224 solver.cpp:253]     Train net output #0: loss = 1.04188 (* 1 = 1.04188 loss)
I0525 07:51:39.416028 19224 sgd_solver.cpp:106] Iteration 40836, lr = 0.002
I0525 07:51:48.232208 19224 solver.cpp:237] Iteration 41002, loss = 1.45519
I0525 07:51:48.232242 19224 solver.cpp:253]     Train net output #0: loss = 1.45519 (* 1 = 1.45519 loss)
I0525 07:51:48.232260 19224 sgd_solver.cpp:106] Iteration 41002, lr = 0.002
I0525 07:52:17.963742 19224 solver.cpp:237] Iteration 41168, loss = 1.27917
I0525 07:52:17.963925 19224 solver.cpp:253]     Train net output #0: loss = 1.27917 (* 1 = 1.27917 loss)
I0525 07:52:17.963942 19224 sgd_solver.cpp:106] Iteration 41168, lr = 0.002
I0525 07:52:26.782429 19224 solver.cpp:237] Iteration 41334, loss = 1.12365
I0525 07:52:26.782474 19224 solver.cpp:253]     Train net output #0: loss = 1.12365 (* 1 = 1.12365 loss)
I0525 07:52:26.782493 19224 sgd_solver.cpp:106] Iteration 41334, lr = 0.002
I0525 07:52:35.605654 19224 solver.cpp:237] Iteration 41500, loss = 1.06999
I0525 07:52:35.605690 19224 solver.cpp:253]     Train net output #0: loss = 1.06999 (* 1 = 1.06999 loss)
I0525 07:52:35.605702 19224 sgd_solver.cpp:106] Iteration 41500, lr = 0.002
I0525 07:52:43.529458 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_41650.caffemodel
I0525 07:52:43.604957 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_41650.solverstate
I0525 07:52:44.500741 19224 solver.cpp:237] Iteration 41666, loss = 1.26521
I0525 07:52:44.500792 19224 solver.cpp:253]     Train net output #0: loss = 1.26521 (* 1 = 1.26521 loss)
I0525 07:52:44.500808 19224 sgd_solver.cpp:106] Iteration 41666, lr = 0.002
I0525 07:52:53.335413 19224 solver.cpp:237] Iteration 41832, loss = 1.30227
I0525 07:52:53.335587 19224 solver.cpp:253]     Train net output #0: loss = 1.30227 (* 1 = 1.30227 loss)
I0525 07:52:53.335602 19224 sgd_solver.cpp:106] Iteration 41832, lr = 0.002
I0525 07:53:02.165283 19224 solver.cpp:237] Iteration 41998, loss = 1.05958
I0525 07:53:02.165318 19224 solver.cpp:253]     Train net output #0: loss = 1.05958 (* 1 = 1.05958 loss)
I0525 07:53:02.165334 19224 sgd_solver.cpp:106] Iteration 41998, lr = 0.002
I0525 07:53:11.000347 19224 solver.cpp:237] Iteration 42164, loss = 1.11079
I0525 07:53:11.000401 19224 solver.cpp:253]     Train net output #0: loss = 1.11079 (* 1 = 1.11079 loss)
I0525 07:53:11.000416 19224 sgd_solver.cpp:106] Iteration 42164, lr = 0.002
I0525 07:53:40.728030 19224 solver.cpp:237] Iteration 42330, loss = 1.13218
I0525 07:53:40.728217 19224 solver.cpp:253]     Train net output #0: loss = 1.13218 (* 1 = 1.13218 loss)
I0525 07:53:40.728231 19224 sgd_solver.cpp:106] Iteration 42330, lr = 0.002
I0525 07:53:49.549315 19224 solver.cpp:237] Iteration 42496, loss = 1.31921
I0525 07:53:49.549350 19224 solver.cpp:253]     Train net output #0: loss = 1.31921 (* 1 = 1.31921 loss)
I0525 07:53:49.549368 19224 sgd_solver.cpp:106] Iteration 42496, lr = 0.002
I0525 07:53:58.366925 19224 solver.cpp:237] Iteration 42662, loss = 1.3111
I0525 07:53:58.366960 19224 solver.cpp:253]     Train net output #0: loss = 1.3111 (* 1 = 1.3111 loss)
I0525 07:53:58.366976 19224 sgd_solver.cpp:106] Iteration 42662, lr = 0.002
I0525 07:54:07.193032 19224 solver.cpp:237] Iteration 42828, loss = 0.994339
I0525 07:54:07.193092 19224 solver.cpp:253]     Train net output #0: loss = 0.994339 (* 1 = 0.994339 loss)
I0525 07:54:07.193106 19224 sgd_solver.cpp:106] Iteration 42828, lr = 0.002
I0525 07:54:16.015141 19224 solver.cpp:237] Iteration 42994, loss = 1.36762
I0525 07:54:16.015300 19224 solver.cpp:253]     Train net output #0: loss = 1.36762 (* 1 = 1.36762 loss)
I0525 07:54:16.015316 19224 sgd_solver.cpp:106] Iteration 42994, lr = 0.002
I0525 07:54:24.837932 19224 solver.cpp:237] Iteration 43160, loss = 1.21642
I0525 07:54:24.837977 19224 solver.cpp:253]     Train net output #0: loss = 1.21642 (* 1 = 1.21642 loss)
I0525 07:54:24.837997 19224 sgd_solver.cpp:106] Iteration 43160, lr = 0.002
I0525 07:54:33.080765 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_43316.caffemodel
I0525 07:54:33.156327 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_43316.solverstate
I0525 07:54:33.730835 19224 solver.cpp:237] Iteration 43326, loss = 1.12418
I0525 07:54:33.730882 19224 solver.cpp:253]     Train net output #0: loss = 1.12418 (* 1 = 1.12418 loss)
I0525 07:54:33.730902 19224 sgd_solver.cpp:106] Iteration 43326, lr = 0.002
I0525 07:54:33.838062 19224 solver.cpp:341] Iteration 43329, Testing net (#0)
I0525 07:55:21.013741 19224 solver.cpp:409]     Test net output #0: accuracy = 0.871258
I0525 07:55:21.013936 19224 solver.cpp:409]     Test net output #1: loss = 0.402642 (* 1 = 0.402642 loss)
I0525 07:55:50.554986 19224 solver.cpp:237] Iteration 43492, loss = 1.10218
I0525 07:55:50.555040 19224 solver.cpp:253]     Train net output #0: loss = 1.10218 (* 1 = 1.10218 loss)
I0525 07:55:50.555057 19224 sgd_solver.cpp:106] Iteration 43492, lr = 0.002
I0525 07:55:59.377290 19224 solver.cpp:237] Iteration 43658, loss = 1.19395
I0525 07:55:59.377457 19224 solver.cpp:253]     Train net output #0: loss = 1.19395 (* 1 = 1.19395 loss)
I0525 07:55:59.377471 19224 sgd_solver.cpp:106] Iteration 43658, lr = 0.002
I0525 07:56:08.205898 19224 solver.cpp:237] Iteration 43824, loss = 1.07742
I0525 07:56:08.205940 19224 solver.cpp:253]     Train net output #0: loss = 1.07742 (* 1 = 1.07742 loss)
I0525 07:56:08.205960 19224 sgd_solver.cpp:106] Iteration 43824, lr = 0.002
I0525 07:56:17.024850 19224 solver.cpp:237] Iteration 43990, loss = 1.23609
I0525 07:56:17.024886 19224 solver.cpp:253]     Train net output #0: loss = 1.23609 (* 1 = 1.23609 loss)
I0525 07:56:17.024902 19224 sgd_solver.cpp:106] Iteration 43990, lr = 0.002
I0525 07:56:25.859174 19224 solver.cpp:237] Iteration 44156, loss = 1.12806
I0525 07:56:25.859210 19224 solver.cpp:253]     Train net output #0: loss = 1.12806 (* 1 = 1.12806 loss)
I0525 07:56:25.859225 19224 sgd_solver.cpp:106] Iteration 44156, lr = 0.002
I0525 07:56:34.689221 19224 solver.cpp:237] Iteration 44322, loss = 0.992534
I0525 07:56:34.689404 19224 solver.cpp:253]     Train net output #0: loss = 0.992534 (* 1 = 0.992534 loss)
I0525 07:56:34.689419 19224 sgd_solver.cpp:106] Iteration 44322, lr = 0.002
I0525 07:57:04.384238 19224 solver.cpp:237] Iteration 44488, loss = 1.23979
I0525 07:57:04.384289 19224 solver.cpp:253]     Train net output #0: loss = 1.23979 (* 1 = 1.23979 loss)
I0525 07:57:04.384307 19224 sgd_solver.cpp:106] Iteration 44488, lr = 0.002
I0525 07:57:13.220428 19224 solver.cpp:237] Iteration 44654, loss = 1.27203
I0525 07:57:13.220604 19224 solver.cpp:253]     Train net output #0: loss = 1.27203 (* 1 = 1.27203 loss)
I0525 07:57:13.220618 19224 sgd_solver.cpp:106] Iteration 44654, lr = 0.002
I0525 07:57:22.043967 19224 solver.cpp:237] Iteration 44820, loss = 0.986249
I0525 07:57:22.044021 19224 solver.cpp:253]     Train net output #0: loss = 0.986249 (* 1 = 0.986249 loss)
I0525 07:57:22.044035 19224 sgd_solver.cpp:106] Iteration 44820, lr = 0.002
I0525 07:57:30.610393 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_44982.caffemodel
I0525 07:57:30.684325 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_44982.solverstate
I0525 07:57:30.939684 19224 solver.cpp:237] Iteration 44986, loss = 1.14023
I0525 07:57:30.939729 19224 solver.cpp:253]     Train net output #0: loss = 1.14023 (* 1 = 1.14023 loss)
I0525 07:57:30.939750 19224 sgd_solver.cpp:106] Iteration 44986, lr = 0.002
I0525 07:57:39.768597 19224 solver.cpp:237] Iteration 45152, loss = 1.166
I0525 07:57:39.768633 19224 solver.cpp:253]     Train net output #0: loss = 1.166 (* 1 = 1.166 loss)
I0525 07:57:39.768648 19224 sgd_solver.cpp:106] Iteration 45152, lr = 0.002
I0525 07:57:48.598152 19224 solver.cpp:237] Iteration 45318, loss = 1.07094
I0525 07:57:48.598345 19224 solver.cpp:253]     Train net output #0: loss = 1.07094 (* 1 = 1.07094 loss)
I0525 07:57:48.598359 19224 sgd_solver.cpp:106] Iteration 45318, lr = 0.002
I0525 07:57:57.416894 19224 solver.cpp:237] Iteration 45484, loss = 1.33395
I0525 07:57:57.416929 19224 solver.cpp:253]     Train net output #0: loss = 1.33395 (* 1 = 1.33395 loss)
I0525 07:57:57.416946 19224 sgd_solver.cpp:106] Iteration 45484, lr = 0.002
I0525 07:58:27.103307 19224 solver.cpp:237] Iteration 45650, loss = 1.09922
I0525 07:58:27.103505 19224 solver.cpp:253]     Train net output #0: loss = 1.09922 (* 1 = 1.09922 loss)
I0525 07:58:27.103520 19224 sgd_solver.cpp:106] Iteration 45650, lr = 0.002
I0525 07:58:35.932709 19224 solver.cpp:237] Iteration 45816, loss = 1.28977
I0525 07:58:35.932762 19224 solver.cpp:253]     Train net output #0: loss = 1.28977 (* 1 = 1.28977 loss)
I0525 07:58:35.932780 19224 sgd_solver.cpp:106] Iteration 45816, lr = 0.002
I0525 07:58:44.751376 19224 solver.cpp:237] Iteration 45982, loss = 1.20473
I0525 07:58:44.751411 19224 solver.cpp:253]     Train net output #0: loss = 1.20473 (* 1 = 1.20473 loss)
I0525 07:58:44.751428 19224 sgd_solver.cpp:106] Iteration 45982, lr = 0.002
I0525 07:58:53.577566 19224 solver.cpp:237] Iteration 46148, loss = 1.29951
I0525 07:58:53.577601 19224 solver.cpp:253]     Train net output #0: loss = 1.29951 (* 1 = 1.29951 loss)
I0525 07:58:53.577618 19224 sgd_solver.cpp:106] Iteration 46148, lr = 0.002
I0525 07:59:02.407097 19224 solver.cpp:237] Iteration 46314, loss = 1.16342
I0525 07:59:02.407290 19224 solver.cpp:253]     Train net output #0: loss = 1.16342 (* 1 = 1.16342 loss)
I0525 07:59:02.407305 19224 sgd_solver.cpp:106] Iteration 46314, lr = 0.002
I0525 07:59:11.229038 19224 solver.cpp:237] Iteration 46480, loss = 1.4088
I0525 07:59:11.229073 19224 solver.cpp:253]     Train net output #0: loss = 1.4088 (* 1 = 1.4088 loss)
I0525 07:59:11.229087 19224 sgd_solver.cpp:106] Iteration 46480, lr = 0.002
I0525 07:59:20.053004 19224 solver.cpp:237] Iteration 46646, loss = 1.31321
I0525 07:59:20.053045 19224 solver.cpp:253]     Train net output #0: loss = 1.31321 (* 1 = 1.31321 loss)
I0525 07:59:20.053057 19224 sgd_solver.cpp:106] Iteration 46646, lr = 0.002
I0525 07:59:20.106211 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_46648.caffemodel
I0525 07:59:20.181339 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_46648.solverstate
I0525 07:59:20.918470 19224 solver.cpp:341] Iteration 46662, Testing net (#0)
I0525 08:00:28.979842 19224 solver.cpp:409]     Test net output #0: accuracy = 0.879962
I0525 08:00:28.980031 19224 solver.cpp:409]     Test net output #1: loss = 0.385439 (* 1 = 0.385439 loss)
I0525 08:00:57.836915 19224 solver.cpp:237] Iteration 46812, loss = 1.14847
I0525 08:00:57.836971 19224 solver.cpp:253]     Train net output #0: loss = 1.14847 (* 1 = 1.14847 loss)
I0525 08:00:57.836987 19224 sgd_solver.cpp:106] Iteration 46812, lr = 0.002
I0525 08:01:06.668515 19224 solver.cpp:237] Iteration 46978, loss = 1.00081
I0525 08:01:06.668697 19224 solver.cpp:253]     Train net output #0: loss = 1.00081 (* 1 = 1.00081 loss)
I0525 08:01:06.668711 19224 sgd_solver.cpp:106] Iteration 46978, lr = 0.002
I0525 08:01:15.503765 19224 solver.cpp:237] Iteration 47144, loss = 1.18664
I0525 08:01:15.503799 19224 solver.cpp:253]     Train net output #0: loss = 1.18664 (* 1 = 1.18664 loss)
I0525 08:01:15.503813 19224 sgd_solver.cpp:106] Iteration 47144, lr = 0.002
I0525 08:01:24.337815 19224 solver.cpp:237] Iteration 47310, loss = 1.11115
I0525 08:01:24.337851 19224 solver.cpp:253]     Train net output #0: loss = 1.11115 (* 1 = 1.11115 loss)
I0525 08:01:24.337867 19224 sgd_solver.cpp:106] Iteration 47310, lr = 0.002
I0525 08:01:33.169031 19224 solver.cpp:237] Iteration 47476, loss = 1.32337
I0525 08:01:33.169078 19224 solver.cpp:253]     Train net output #0: loss = 1.32337 (* 1 = 1.32337 loss)
I0525 08:01:33.169100 19224 sgd_solver.cpp:106] Iteration 47476, lr = 0.002
I0525 08:01:42.002928 19224 solver.cpp:237] Iteration 47642, loss = 1.43031
I0525 08:01:42.003098 19224 solver.cpp:253]     Train net output #0: loss = 1.43031 (* 1 = 1.43031 loss)
I0525 08:01:42.003113 19224 sgd_solver.cpp:106] Iteration 47642, lr = 0.002
I0525 08:02:11.714673 19224 solver.cpp:237] Iteration 47808, loss = 1.2396
I0525 08:02:11.714725 19224 solver.cpp:253]     Train net output #0: loss = 1.2396 (* 1 = 1.2396 loss)
I0525 08:02:11.714740 19224 sgd_solver.cpp:106] Iteration 47808, lr = 0.002
I0525 08:02:20.554168 19224 solver.cpp:237] Iteration 47974, loss = 1.24759
I0525 08:02:20.554359 19224 solver.cpp:253]     Train net output #0: loss = 1.24759 (* 1 = 1.24759 loss)
I0525 08:02:20.554373 19224 sgd_solver.cpp:106] Iteration 47974, lr = 0.002
I0525 08:02:29.382036 19224 solver.cpp:237] Iteration 48140, loss = 1.17125
I0525 08:02:29.382071 19224 solver.cpp:253]     Train net output #0: loss = 1.17125 (* 1 = 1.17125 loss)
I0525 08:02:29.382089 19224 sgd_solver.cpp:106] Iteration 48140, lr = 0.002
I0525 08:02:38.216965 19224 solver.cpp:237] Iteration 48306, loss = 1.15019
I0525 08:02:38.217000 19224 solver.cpp:253]     Train net output #0: loss = 1.15019 (* 1 = 1.15019 loss)
I0525 08:02:38.217013 19224 sgd_solver.cpp:106] Iteration 48306, lr = 0.002
I0525 08:02:38.588306 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_48314.caffemodel
I0525 08:02:38.666280 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_48314.solverstate
I0525 08:02:47.112831 19224 solver.cpp:237] Iteration 48472, loss = 1.17453
I0525 08:02:47.112884 19224 solver.cpp:253]     Train net output #0: loss = 1.17453 (* 1 = 1.17453 loss)
I0525 08:02:47.112901 19224 sgd_solver.cpp:106] Iteration 48472, lr = 0.002
I0525 08:02:55.948263 19224 solver.cpp:237] Iteration 48638, loss = 1.16445
I0525 08:02:55.948433 19224 solver.cpp:253]     Train net output #0: loss = 1.16445 (* 1 = 1.16445 loss)
I0525 08:02:55.948447 19224 sgd_solver.cpp:106] Iteration 48638, lr = 0.002
I0525 08:03:04.786474 19224 solver.cpp:237] Iteration 48804, loss = 1.3775
I0525 08:03:04.786509 19224 solver.cpp:253]     Train net output #0: loss = 1.3775 (* 1 = 1.3775 loss)
I0525 08:03:04.786525 19224 sgd_solver.cpp:106] Iteration 48804, lr = 0.002
I0525 08:03:34.494860 19224 solver.cpp:237] Iteration 48970, loss = 1.1234
I0525 08:03:34.495038 19224 solver.cpp:253]     Train net output #0: loss = 1.1234 (* 1 = 1.1234 loss)
I0525 08:03:34.495054 19224 sgd_solver.cpp:106] Iteration 48970, lr = 0.002
I0525 08:03:43.325587 19224 solver.cpp:237] Iteration 49136, loss = 1.27419
I0525 08:03:43.325621 19224 solver.cpp:253]     Train net output #0: loss = 1.27419 (* 1 = 1.27419 loss)
I0525 08:03:43.325635 19224 sgd_solver.cpp:106] Iteration 49136, lr = 0.002
I0525 08:03:52.163581 19224 solver.cpp:237] Iteration 49302, loss = 1.11432
I0525 08:03:52.163616 19224 solver.cpp:253]     Train net output #0: loss = 1.11432 (* 1 = 1.11432 loss)
I0525 08:03:52.163635 19224 sgd_solver.cpp:106] Iteration 49302, lr = 0.002
I0525 08:04:00.995198 19224 solver.cpp:237] Iteration 49468, loss = 1.16777
I0525 08:04:00.995249 19224 solver.cpp:253]     Train net output #0: loss = 1.16777 (* 1 = 1.16777 loss)
I0525 08:04:00.995263 19224 sgd_solver.cpp:106] Iteration 49468, lr = 0.002
I0525 08:04:09.822331 19224 solver.cpp:237] Iteration 49634, loss = 1.22406
I0525 08:04:09.822496 19224 solver.cpp:253]     Train net output #0: loss = 1.22406 (* 1 = 1.22406 loss)
I0525 08:04:09.822510 19224 sgd_solver.cpp:106] Iteration 49634, lr = 0.002
I0525 08:04:18.650480 19224 solver.cpp:237] Iteration 49800, loss = 1.00653
I0525 08:04:18.650513 19224 solver.cpp:253]     Train net output #0: loss = 1.00653 (* 1 = 1.00653 loss)
I0525 08:04:18.650529 19224 sgd_solver.cpp:106] Iteration 49800, lr = 0.002
I0525 08:04:27.487509 19224 solver.cpp:237] Iteration 49966, loss = 1.18741
I0525 08:04:27.487548 19224 solver.cpp:253]     Train net output #0: loss = 1.18741 (* 1 = 1.18741 loss)
I0525 08:04:27.487568 19224 sgd_solver.cpp:106] Iteration 49966, lr = 0.002
I0525 08:04:28.180855 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_49980.caffemodel
I0525 08:04:28.257623 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_49980.solverstate
I0525 08:04:29.047864 19224 solver.cpp:341] Iteration 49995, Testing net (#0)
I0525 08:05:15.871716 19224 solver.cpp:409]     Test net output #0: accuracy = 0.874279
I0525 08:05:15.871913 19224 solver.cpp:409]     Test net output #1: loss = 0.414531 (* 1 = 0.414531 loss)
I0525 08:05:44.015072 19224 solver.cpp:237] Iteration 50132, loss = 1.02682
I0525 08:05:44.015127 19224 solver.cpp:253]     Train net output #0: loss = 1.02682 (* 1 = 1.02682 loss)
I0525 08:05:44.015142 19224 sgd_solver.cpp:106] Iteration 50132, lr = 0.002
I0525 08:05:52.843930 19224 solver.cpp:237] Iteration 50298, loss = 1.07619
I0525 08:05:52.844099 19224 solver.cpp:253]     Train net output #0: loss = 1.07619 (* 1 = 1.07619 loss)
I0525 08:05:52.844113 19224 sgd_solver.cpp:106] Iteration 50298, lr = 0.002
I0525 08:06:01.668449 19224 solver.cpp:237] Iteration 50464, loss = 1.22025
I0525 08:06:01.668484 19224 solver.cpp:253]     Train net output #0: loss = 1.22025 (* 1 = 1.22025 loss)
I0525 08:06:01.668500 19224 sgd_solver.cpp:106] Iteration 50464, lr = 0.002
I0525 08:06:10.487828 19224 solver.cpp:237] Iteration 50630, loss = 1.21209
I0525 08:06:10.487867 19224 solver.cpp:253]     Train net output #0: loss = 1.21209 (* 1 = 1.21209 loss)
I0525 08:06:10.487889 19224 sgd_solver.cpp:106] Iteration 50630, lr = 0.002
I0525 08:06:19.311034 19224 solver.cpp:237] Iteration 50796, loss = 1.24983
I0525 08:06:19.311069 19224 solver.cpp:253]     Train net output #0: loss = 1.24983 (* 1 = 1.24983 loss)
I0525 08:06:19.311084 19224 sgd_solver.cpp:106] Iteration 50796, lr = 0.002
I0525 08:06:28.140445 19224 solver.cpp:237] Iteration 50962, loss = 1.12527
I0525 08:06:28.140620 19224 solver.cpp:253]     Train net output #0: loss = 1.12527 (* 1 = 1.12527 loss)
I0525 08:06:28.140635 19224 sgd_solver.cpp:106] Iteration 50962, lr = 0.002
I0525 08:06:57.817631 19224 solver.cpp:237] Iteration 51128, loss = 1.18423
I0525 08:06:57.817684 19224 solver.cpp:253]     Train net output #0: loss = 1.18423 (* 1 = 1.18423 loss)
I0525 08:06:57.817699 19224 sgd_solver.cpp:106] Iteration 51128, lr = 0.002
I0525 08:07:06.642972 19224 solver.cpp:237] Iteration 51294, loss = 1.0919
I0525 08:07:06.643137 19224 solver.cpp:253]     Train net output #0: loss = 1.0919 (* 1 = 1.0919 loss)
I0525 08:07:06.643151 19224 sgd_solver.cpp:106] Iteration 51294, lr = 0.002
I0525 08:07:15.464786 19224 solver.cpp:237] Iteration 51460, loss = 1.24541
I0525 08:07:15.464820 19224 solver.cpp:253]     Train net output #0: loss = 1.24541 (* 1 = 1.24541 loss)
I0525 08:07:15.464838 19224 sgd_solver.cpp:106] Iteration 51460, lr = 0.002
I0525 08:07:24.283113 19224 solver.cpp:237] Iteration 51626, loss = 0.982348
I0525 08:07:24.283160 19224 solver.cpp:253]     Train net output #0: loss = 0.982348 (* 1 = 0.982348 loss)
I0525 08:07:24.283176 19224 sgd_solver.cpp:106] Iteration 51626, lr = 0.002
I0525 08:07:25.294700 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_51646.caffemodel
I0525 08:07:25.370010 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_51646.solverstate
I0525 08:07:33.166050 19224 solver.cpp:237] Iteration 51792, loss = 1.29699
I0525 08:07:33.166097 19224 solver.cpp:253]     Train net output #0: loss = 1.29699 (* 1 = 1.29699 loss)
I0525 08:07:33.166116 19224 sgd_solver.cpp:106] Iteration 51792, lr = 0.002
I0525 08:07:41.987182 19224 solver.cpp:237] Iteration 51958, loss = 1.20727
I0525 08:07:41.987349 19224 solver.cpp:253]     Train net output #0: loss = 1.20727 (* 1 = 1.20727 loss)
I0525 08:07:41.987362 19224 sgd_solver.cpp:106] Iteration 51958, lr = 0.002
I0525 08:07:50.818207 19224 solver.cpp:237] Iteration 52124, loss = 1.12184
I0525 08:07:50.818246 19224 solver.cpp:253]     Train net output #0: loss = 1.12184 (* 1 = 1.12184 loss)
I0525 08:07:50.818264 19224 sgd_solver.cpp:106] Iteration 52124, lr = 0.002
I0525 08:08:20.542438 19224 solver.cpp:237] Iteration 52290, loss = 1.01205
I0525 08:08:20.542636 19224 solver.cpp:253]     Train net output #0: loss = 1.01205 (* 1 = 1.01205 loss)
I0525 08:08:20.542651 19224 sgd_solver.cpp:106] Iteration 52290, lr = 0.002
I0525 08:08:29.366652 19224 solver.cpp:237] Iteration 52456, loss = 1.00382
I0525 08:08:29.366688 19224 solver.cpp:253]     Train net output #0: loss = 1.00382 (* 1 = 1.00382 loss)
I0525 08:08:29.366704 19224 sgd_solver.cpp:106] Iteration 52456, lr = 0.002
I0525 08:08:38.187376 19224 solver.cpp:237] Iteration 52622, loss = 1.22004
I0525 08:08:38.187419 19224 solver.cpp:253]     Train net output #0: loss = 1.22004 (* 1 = 1.22004 loss)
I0525 08:08:38.187440 19224 sgd_solver.cpp:106] Iteration 52622, lr = 0.002
I0525 08:08:47.001696 19224 solver.cpp:237] Iteration 52788, loss = 1.23006
I0525 08:08:47.001732 19224 solver.cpp:253]     Train net output #0: loss = 1.23006 (* 1 = 1.23006 loss)
I0525 08:08:47.001749 19224 sgd_solver.cpp:106] Iteration 52788, lr = 0.002
I0525 08:08:55.821981 19224 solver.cpp:237] Iteration 52954, loss = 1.26921
I0525 08:08:55.822149 19224 solver.cpp:253]     Train net output #0: loss = 1.26921 (* 1 = 1.26921 loss)
I0525 08:08:55.822161 19224 sgd_solver.cpp:106] Iteration 52954, lr = 0.002
I0525 08:09:04.638993 19224 solver.cpp:237] Iteration 53120, loss = 1.14651
I0525 08:09:04.639035 19224 solver.cpp:253]     Train net output #0: loss = 1.14651 (* 1 = 1.14651 loss)
I0525 08:09:04.639056 19224 sgd_solver.cpp:106] Iteration 53120, lr = 0.002
I0525 08:09:13.454674 19224 solver.cpp:237] Iteration 53286, loss = 1.25385
I0525 08:09:13.454710 19224 solver.cpp:253]     Train net output #0: loss = 1.25385 (* 1 = 1.25385 loss)
I0525 08:09:13.454725 19224 sgd_solver.cpp:106] Iteration 53286, lr = 0.002
I0525 08:09:14.785802 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_53312.caffemodel
I0525 08:09:14.861384 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_53312.solverstate
I0525 08:09:15.701375 19224 solver.cpp:341] Iteration 53328, Testing net (#0)
I0525 08:10:23.749176 19224 solver.cpp:409]     Test net output #0: accuracy = 0.883244
I0525 08:10:23.749378 19224 solver.cpp:409]     Test net output #1: loss = 0.37674 (* 1 = 0.37674 loss)
I0525 08:10:51.213982 19224 solver.cpp:237] Iteration 53452, loss = 1.08354
I0525 08:10:51.214038 19224 solver.cpp:253]     Train net output #0: loss = 1.08354 (* 1 = 1.08354 loss)
I0525 08:10:51.214052 19224 sgd_solver.cpp:106] Iteration 53452, lr = 0.002
I0525 08:11:00.034966 19224 solver.cpp:237] Iteration 53618, loss = 1.13639
I0525 08:11:00.035137 19224 solver.cpp:253]     Train net output #0: loss = 1.13639 (* 1 = 1.13639 loss)
I0525 08:11:00.035151 19224 sgd_solver.cpp:106] Iteration 53618, lr = 0.002
I0525 08:11:08.862355 19224 solver.cpp:237] Iteration 53784, loss = 1.18262
I0525 08:11:08.862395 19224 solver.cpp:253]     Train net output #0: loss = 1.18262 (* 1 = 1.18262 loss)
I0525 08:11:08.862416 19224 sgd_solver.cpp:106] Iteration 53784, lr = 0.002
I0525 08:11:17.694443 19224 solver.cpp:237] Iteration 53950, loss = 0.991226
I0525 08:11:17.694478 19224 solver.cpp:253]     Train net output #0: loss = 0.991226 (* 1 = 0.991226 loss)
I0525 08:11:17.694495 19224 sgd_solver.cpp:106] Iteration 53950, lr = 0.002
I0525 08:11:26.518642 19224 solver.cpp:237] Iteration 54116, loss = 1.18132
I0525 08:11:26.518677 19224 solver.cpp:253]     Train net output #0: loss = 1.18132 (* 1 = 1.18132 loss)
I0525 08:11:26.518692 19224 sgd_solver.cpp:106] Iteration 54116, lr = 0.002
I0525 08:11:35.344254 19224 solver.cpp:237] Iteration 54282, loss = 1.10776
I0525 08:11:35.344435 19224 solver.cpp:253]     Train net output #0: loss = 1.10776 (* 1 = 1.10776 loss)
I0525 08:11:35.344449 19224 sgd_solver.cpp:106] Iteration 54282, lr = 0.002
I0525 08:12:05.040693 19224 solver.cpp:237] Iteration 54448, loss = 1.17089
I0525 08:12:05.040747 19224 solver.cpp:253]     Train net output #0: loss = 1.17089 (* 1 = 1.17089 loss)
I0525 08:12:05.040762 19224 sgd_solver.cpp:106] Iteration 54448, lr = 0.002
I0525 08:12:13.870290 19224 solver.cpp:237] Iteration 54614, loss = 1.20248
I0525 08:12:13.870462 19224 solver.cpp:253]     Train net output #0: loss = 1.20248 (* 1 = 1.20248 loss)
I0525 08:12:13.870476 19224 sgd_solver.cpp:106] Iteration 54614, lr = 0.002
I0525 08:12:22.692525 19224 solver.cpp:237] Iteration 54780, loss = 1.26785
I0525 08:12:22.692569 19224 solver.cpp:253]     Train net output #0: loss = 1.26785 (* 1 = 1.26785 loss)
I0525 08:12:22.692589 19224 sgd_solver.cpp:106] Iteration 54780, lr = 0.002
I0525 08:12:31.524554 19224 solver.cpp:237] Iteration 54946, loss = 1.0186
I0525 08:12:31.524588 19224 solver.cpp:253]     Train net output #0: loss = 1.0186 (* 1 = 1.0186 loss)
I0525 08:12:31.524605 19224 sgd_solver.cpp:106] Iteration 54946, lr = 0.002
I0525 08:12:33.175686 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_54978.caffemodel
I0525 08:12:33.250005 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_54978.solverstate
I0525 08:12:40.417549 19224 solver.cpp:237] Iteration 55112, loss = 1.09381
I0525 08:12:40.417599 19224 solver.cpp:253]     Train net output #0: loss = 1.09381 (* 1 = 1.09381 loss)
I0525 08:12:40.417619 19224 sgd_solver.cpp:106] Iteration 55112, lr = 0.002
I0525 08:12:49.249568 19224 solver.cpp:237] Iteration 55278, loss = 1.05634
I0525 08:12:49.249748 19224 solver.cpp:253]     Train net output #0: loss = 1.05634 (* 1 = 1.05634 loss)
I0525 08:12:49.249763 19224 sgd_solver.cpp:106] Iteration 55278, lr = 0.002
I0525 08:12:58.073317 19224 solver.cpp:237] Iteration 55444, loss = 1.17349
I0525 08:12:58.073351 19224 solver.cpp:253]     Train net output #0: loss = 1.17349 (* 1 = 1.17349 loss)
I0525 08:12:58.073369 19224 sgd_solver.cpp:106] Iteration 55444, lr = 0.002
I0525 08:13:27.763371 19224 solver.cpp:237] Iteration 55610, loss = 1.32334
I0525 08:13:27.763562 19224 solver.cpp:253]     Train net output #0: loss = 1.32334 (* 1 = 1.32334 loss)
I0525 08:13:27.763577 19224 sgd_solver.cpp:106] Iteration 55610, lr = 0.002
I0525 08:13:36.595686 19224 solver.cpp:237] Iteration 55776, loss = 1.19857
I0525 08:13:36.595741 19224 solver.cpp:253]     Train net output #0: loss = 1.19857 (* 1 = 1.19857 loss)
I0525 08:13:36.595755 19224 sgd_solver.cpp:106] Iteration 55776, lr = 0.002
I0525 08:13:45.416704 19224 solver.cpp:237] Iteration 55942, loss = 1.03011
I0525 08:13:45.416739 19224 solver.cpp:253]     Train net output #0: loss = 1.03011 (* 1 = 1.03011 loss)
I0525 08:13:45.416754 19224 sgd_solver.cpp:106] Iteration 55942, lr = 0.002
I0525 08:13:54.240927 19224 solver.cpp:237] Iteration 56108, loss = 1.07535
I0525 08:13:54.240963 19224 solver.cpp:253]     Train net output #0: loss = 1.07535 (* 1 = 1.07535 loss)
I0525 08:13:54.240978 19224 sgd_solver.cpp:106] Iteration 56108, lr = 0.002
I0525 08:14:03.063642 19224 solver.cpp:237] Iteration 56274, loss = 1.14117
I0525 08:14:03.063820 19224 solver.cpp:253]     Train net output #0: loss = 1.14117 (* 1 = 1.14117 loss)
I0525 08:14:03.063833 19224 sgd_solver.cpp:106] Iteration 56274, lr = 0.002
I0525 08:14:11.887493 19224 solver.cpp:237] Iteration 56440, loss = 1.09544
I0525 08:14:11.887527 19224 solver.cpp:253]     Train net output #0: loss = 1.09544 (* 1 = 1.09544 loss)
I0525 08:14:11.887545 19224 sgd_solver.cpp:106] Iteration 56440, lr = 0.002
I0525 08:14:20.709192 19224 solver.cpp:237] Iteration 56606, loss = 1.42271
I0525 08:14:20.709225 19224 solver.cpp:253]     Train net output #0: loss = 1.42271 (* 1 = 1.42271 loss)
I0525 08:14:20.709239 19224 sgd_solver.cpp:106] Iteration 56606, lr = 0.002
I0525 08:14:22.675398 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_56644.caffemodel
I0525 08:14:22.750972 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_56644.solverstate
I0525 08:14:23.646669 19224 solver.cpp:341] Iteration 56661, Testing net (#0)
I0525 08:15:10.797662 19224 solver.cpp:409]     Test net output #0: accuracy = 0.885532
I0525 08:15:10.797866 19224 solver.cpp:409]     Test net output #1: loss = 0.397152 (* 1 = 0.397152 loss)
I0525 08:15:37.550038 19224 solver.cpp:237] Iteration 56772, loss = 1.05658
I0525 08:15:37.550092 19224 solver.cpp:253]     Train net output #0: loss = 1.05658 (* 1 = 1.05658 loss)
I0525 08:15:37.550108 19224 sgd_solver.cpp:106] Iteration 56772, lr = 0.002
I0525 08:15:46.372666 19224 solver.cpp:237] Iteration 56938, loss = 1.27055
I0525 08:15:46.372856 19224 solver.cpp:253]     Train net output #0: loss = 1.27055 (* 1 = 1.27055 loss)
I0525 08:15:46.372869 19224 sgd_solver.cpp:106] Iteration 56938, lr = 0.002
I0525 08:15:55.194766 19224 solver.cpp:237] Iteration 57104, loss = 1.10896
I0525 08:15:55.194800 19224 solver.cpp:253]     Train net output #0: loss = 1.10896 (* 1 = 1.10896 loss)
I0525 08:15:55.194815 19224 sgd_solver.cpp:106] Iteration 57104, lr = 0.002
I0525 08:16:04.003232 19224 solver.cpp:237] Iteration 57270, loss = 1.09976
I0525 08:16:04.003284 19224 solver.cpp:253]     Train net output #0: loss = 1.09976 (* 1 = 1.09976 loss)
I0525 08:16:04.003298 19224 sgd_solver.cpp:106] Iteration 57270, lr = 0.002
I0525 08:16:12.826759 19224 solver.cpp:237] Iteration 57436, loss = 1.11327
I0525 08:16:12.826795 19224 solver.cpp:253]     Train net output #0: loss = 1.11327 (* 1 = 1.11327 loss)
I0525 08:16:12.826808 19224 sgd_solver.cpp:106] Iteration 57436, lr = 0.002
I0525 08:16:21.652938 19224 solver.cpp:237] Iteration 57602, loss = 1.50126
I0525 08:16:21.653115 19224 solver.cpp:253]     Train net output #0: loss = 1.50126 (* 1 = 1.50126 loss)
I0525 08:16:21.653128 19224 sgd_solver.cpp:106] Iteration 57602, lr = 0.002
I0525 08:16:30.471333 19224 solver.cpp:237] Iteration 57768, loss = 1.31948
I0525 08:16:30.471382 19224 solver.cpp:253]     Train net output #0: loss = 1.31948 (* 1 = 1.31948 loss)
I0525 08:16:30.471400 19224 sgd_solver.cpp:106] Iteration 57768, lr = 0.002
I0525 08:17:00.113538 19224 solver.cpp:237] Iteration 57934, loss = 1.07039
I0525 08:17:00.113730 19224 solver.cpp:253]     Train net output #0: loss = 1.07039 (* 1 = 1.07039 loss)
I0525 08:17:00.113745 19224 sgd_solver.cpp:106] Iteration 57934, lr = 0.002
I0525 08:17:08.931068 19224 solver.cpp:237] Iteration 58100, loss = 1.27785
I0525 08:17:08.931102 19224 solver.cpp:253]     Train net output #0: loss = 1.27785 (* 1 = 1.27785 loss)
I0525 08:17:08.931116 19224 sgd_solver.cpp:106] Iteration 58100, lr = 0.002
I0525 08:17:17.756181 19224 solver.cpp:237] Iteration 58266, loss = 1.27674
I0525 08:17:17.756216 19224 solver.cpp:253]     Train net output #0: loss = 1.27674 (* 1 = 1.27674 loss)
I0525 08:17:17.756232 19224 sgd_solver.cpp:106] Iteration 58266, lr = 0.002
I0525 08:17:20.038955 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_58310.caffemodel
I0525 08:17:20.114931 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_58310.solverstate
I0525 08:17:26.637177 19224 solver.cpp:237] Iteration 58432, loss = 1.18264
I0525 08:17:26.637226 19224 solver.cpp:253]     Train net output #0: loss = 1.18264 (* 1 = 1.18264 loss)
I0525 08:17:26.637246 19224 sgd_solver.cpp:106] Iteration 58432, lr = 0.002
I0525 08:17:35.455307 19224 solver.cpp:237] Iteration 58598, loss = 1.39559
I0525 08:17:35.455492 19224 solver.cpp:253]     Train net output #0: loss = 1.39559 (* 1 = 1.39559 loss)
I0525 08:17:35.455507 19224 sgd_solver.cpp:106] Iteration 58598, lr = 0.002
I0525 08:17:44.270195 19224 solver.cpp:237] Iteration 58764, loss = 1.11847
I0525 08:17:44.270246 19224 solver.cpp:253]     Train net output #0: loss = 1.11847 (* 1 = 1.11847 loss)
I0525 08:17:44.270262 19224 sgd_solver.cpp:106] Iteration 58764, lr = 0.002
I0525 08:18:13.941572 19224 solver.cpp:237] Iteration 58930, loss = 1.29258
I0525 08:18:13.941767 19224 solver.cpp:253]     Train net output #0: loss = 1.29258 (* 1 = 1.29258 loss)
I0525 08:18:13.941782 19224 sgd_solver.cpp:106] Iteration 58930, lr = 0.002
I0525 08:18:22.759845 19224 solver.cpp:237] Iteration 59096, loss = 1.10209
I0525 08:18:22.759881 19224 solver.cpp:253]     Train net output #0: loss = 1.10209 (* 1 = 1.10209 loss)
I0525 08:18:22.759897 19224 sgd_solver.cpp:106] Iteration 59096, lr = 0.002
I0525 08:18:31.581521 19224 solver.cpp:237] Iteration 59262, loss = 1.26477
I0525 08:18:31.581553 19224 solver.cpp:253]     Train net output #0: loss = 1.26477 (* 1 = 1.26477 loss)
I0525 08:18:31.581567 19224 sgd_solver.cpp:106] Iteration 59262, lr = 0.002
I0525 08:18:40.407815 19224 solver.cpp:237] Iteration 59428, loss = 1.18543
I0525 08:18:40.407860 19224 solver.cpp:253]     Train net output #0: loss = 1.18543 (* 1 = 1.18543 loss)
I0525 08:18:40.407878 19224 sgd_solver.cpp:106] Iteration 59428, lr = 0.002
I0525 08:18:49.229385 19224 solver.cpp:237] Iteration 59594, loss = 1.15797
I0525 08:18:49.229553 19224 solver.cpp:253]     Train net output #0: loss = 1.15797 (* 1 = 1.15797 loss)
I0525 08:18:49.229568 19224 sgd_solver.cpp:106] Iteration 59594, lr = 0.002
I0525 08:18:58.049314 19224 solver.cpp:237] Iteration 59760, loss = 1.46892
I0525 08:18:58.049348 19224 solver.cpp:253]     Train net output #0: loss = 1.46892 (* 1 = 1.46892 loss)
I0525 08:18:58.049365 19224 sgd_solver.cpp:106] Iteration 59760, lr = 0.002
I0525 08:19:06.874105 19224 solver.cpp:237] Iteration 59926, loss = 1.28273
I0525 08:19:06.874135 19224 solver.cpp:253]     Train net output #0: loss = 1.28273 (* 1 = 1.28273 loss)
I0525 08:19:06.874161 19224 sgd_solver.cpp:106] Iteration 59926, lr = 0.002
I0525 08:19:09.474062 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_59976.caffemodel
I0525 08:19:09.551266 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_59976.solverstate
I0525 08:19:10.498152 19224 solver.cpp:341] Iteration 59994, Testing net (#0)
I0525 08:20:18.477946 19224 solver.cpp:409]     Test net output #0: accuracy = 0.887359
I0525 08:20:18.478137 19224 solver.cpp:409]     Test net output #1: loss = 0.358441 (* 1 = 0.358441 loss)
I0525 08:20:44.543323 19224 solver.cpp:237] Iteration 60092, loss = 1.07684
I0525 08:20:44.543375 19224 solver.cpp:253]     Train net output #0: loss = 1.07684 (* 1 = 1.07684 loss)
I0525 08:20:44.543390 19224 sgd_solver.cpp:106] Iteration 60092, lr = 0.002
I0525 08:20:53.378262 19224 solver.cpp:237] Iteration 60258, loss = 0.88523
I0525 08:20:53.378437 19224 solver.cpp:253]     Train net output #0: loss = 0.88523 (* 1 = 0.88523 loss)
I0525 08:20:53.378450 19224 sgd_solver.cpp:106] Iteration 60258, lr = 0.002
I0525 08:21:02.211675 19224 solver.cpp:237] Iteration 60424, loss = 1.10362
I0525 08:21:02.211710 19224 solver.cpp:253]     Train net output #0: loss = 1.10362 (* 1 = 1.10362 loss)
I0525 08:21:02.211727 19224 sgd_solver.cpp:106] Iteration 60424, lr = 0.002
I0525 08:21:11.046494 19224 solver.cpp:237] Iteration 60590, loss = 1.09848
I0525 08:21:11.046540 19224 solver.cpp:253]     Train net output #0: loss = 1.09848 (* 1 = 1.09848 loss)
I0525 08:21:11.046561 19224 sgd_solver.cpp:106] Iteration 60590, lr = 0.002
I0525 08:21:19.873188 19224 solver.cpp:237] Iteration 60756, loss = 1.14699
I0525 08:21:19.873222 19224 solver.cpp:253]     Train net output #0: loss = 1.14699 (* 1 = 1.14699 loss)
I0525 08:21:19.873237 19224 sgd_solver.cpp:106] Iteration 60756, lr = 0.002
I0525 08:21:28.714854 19224 solver.cpp:237] Iteration 60922, loss = 1.33792
I0525 08:21:28.715039 19224 solver.cpp:253]     Train net output #0: loss = 1.33792 (* 1 = 1.33792 loss)
I0525 08:21:28.715054 19224 sgd_solver.cpp:106] Iteration 60922, lr = 0.002
I0525 08:21:37.549588 19224 solver.cpp:237] Iteration 61088, loss = 1.22958
I0525 08:21:37.549623 19224 solver.cpp:253]     Train net output #0: loss = 1.22958 (* 1 = 1.22958 loss)
I0525 08:21:37.549639 19224 sgd_solver.cpp:106] Iteration 61088, lr = 0.002
I0525 08:22:07.244736 19224 solver.cpp:237] Iteration 61254, loss = 1.01072
I0525 08:22:07.244935 19224 solver.cpp:253]     Train net output #0: loss = 1.01072 (* 1 = 1.01072 loss)
I0525 08:22:07.244949 19224 sgd_solver.cpp:106] Iteration 61254, lr = 0.002
I0525 08:22:16.086470 19224 solver.cpp:237] Iteration 61420, loss = 1.20367
I0525 08:22:16.086504 19224 solver.cpp:253]     Train net output #0: loss = 1.20367 (* 1 = 1.20367 loss)
I0525 08:22:16.086519 19224 sgd_solver.cpp:106] Iteration 61420, lr = 0.002
I0525 08:22:24.932405 19224 solver.cpp:237] Iteration 61586, loss = 1.20204
I0525 08:22:24.932440 19224 solver.cpp:253]     Train net output #0: loss = 1.20204 (* 1 = 1.20204 loss)
I0525 08:22:24.932462 19224 sgd_solver.cpp:106] Iteration 61586, lr = 0.002
I0525 08:22:27.857231 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_61642.caffemodel
I0525 08:22:27.933078 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_61642.solverstate
I0525 08:22:33.827081 19224 solver.cpp:237] Iteration 61752, loss = 1.17916
I0525 08:22:33.827127 19224 solver.cpp:253]     Train net output #0: loss = 1.17916 (* 1 = 1.17916 loss)
I0525 08:22:33.827148 19224 sgd_solver.cpp:106] Iteration 61752, lr = 0.002
I0525 08:22:42.651479 19224 solver.cpp:237] Iteration 61918, loss = 1.12226
I0525 08:22:42.651654 19224 solver.cpp:253]     Train net output #0: loss = 1.12226 (* 1 = 1.12226 loss)
I0525 08:22:42.651669 19224 sgd_solver.cpp:106] Iteration 61918, lr = 0.002
I0525 08:22:51.485203 19224 solver.cpp:237] Iteration 62084, loss = 1.17247
I0525 08:22:51.485246 19224 solver.cpp:253]     Train net output #0: loss = 1.17247 (* 1 = 1.17247 loss)
I0525 08:22:51.485267 19224 sgd_solver.cpp:106] Iteration 62084, lr = 0.002
I0525 08:23:21.189492 19224 solver.cpp:237] Iteration 62250, loss = 1.26424
I0525 08:23:21.189689 19224 solver.cpp:253]     Train net output #0: loss = 1.26424 (* 1 = 1.26424 loss)
I0525 08:23:21.189703 19224 sgd_solver.cpp:106] Iteration 62250, lr = 0.002
I0525 08:23:30.022825 19224 solver.cpp:237] Iteration 62416, loss = 1.03985
I0525 08:23:30.022860 19224 solver.cpp:253]     Train net output #0: loss = 1.03985 (* 1 = 1.03985 loss)
I0525 08:23:30.022877 19224 sgd_solver.cpp:106] Iteration 62416, lr = 0.002
I0525 08:23:38.860386 19224 solver.cpp:237] Iteration 62582, loss = 1.21778
I0525 08:23:38.860436 19224 solver.cpp:253]     Train net output #0: loss = 1.21778 (* 1 = 1.21778 loss)
I0525 08:23:38.860455 19224 sgd_solver.cpp:106] Iteration 62582, lr = 0.002
I0525 08:23:47.698796 19224 solver.cpp:237] Iteration 62748, loss = 1.25108
I0525 08:23:47.698832 19224 solver.cpp:253]     Train net output #0: loss = 1.25108 (* 1 = 1.25108 loss)
I0525 08:23:47.698848 19224 sgd_solver.cpp:106] Iteration 62748, lr = 0.002
I0525 08:23:56.529882 19224 solver.cpp:237] Iteration 62914, loss = 1.09341
I0525 08:23:56.530052 19224 solver.cpp:253]     Train net output #0: loss = 1.09341 (* 1 = 1.09341 loss)
I0525 08:23:56.530066 19224 sgd_solver.cpp:106] Iteration 62914, lr = 0.002
I0525 08:24:05.370112 19224 solver.cpp:237] Iteration 63080, loss = 1.38568
I0525 08:24:05.370159 19224 solver.cpp:253]     Train net output #0: loss = 1.38568 (* 1 = 1.38568 loss)
I0525 08:24:05.370178 19224 sgd_solver.cpp:106] Iteration 63080, lr = 0.002
I0525 08:24:14.201279 19224 solver.cpp:237] Iteration 63246, loss = 1.17905
I0525 08:24:14.201309 19224 solver.cpp:253]     Train net output #0: loss = 1.17905 (* 1 = 1.17905 loss)
I0525 08:24:14.201323 19224 sgd_solver.cpp:106] Iteration 63246, lr = 0.002
I0525 08:24:17.454097 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_63308.caffemodel
I0525 08:24:17.528900 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_63308.solverstate
I0525 08:24:18.528553 19224 solver.cpp:341] Iteration 63327, Testing net (#0)
I0525 08:25:05.391250 19224 solver.cpp:409]     Test net output #0: accuracy = 0.887193
I0525 08:25:05.391458 19224 solver.cpp:409]     Test net output #1: loss = 0.364391 (* 1 = 0.364391 loss)
I0525 08:25:30.767668 19224 solver.cpp:237] Iteration 63412, loss = 1.05516
I0525 08:25:30.767722 19224 solver.cpp:253]     Train net output #0: loss = 1.05516 (* 1 = 1.05516 loss)
I0525 08:25:30.767735 19224 sgd_solver.cpp:106] Iteration 63412, lr = 0.002
I0525 08:25:39.594581 19224 solver.cpp:237] Iteration 63578, loss = 1.27091
I0525 08:25:39.594771 19224 solver.cpp:253]     Train net output #0: loss = 1.27091 (* 1 = 1.27091 loss)
I0525 08:25:39.594785 19224 sgd_solver.cpp:106] Iteration 63578, lr = 0.002
I0525 08:25:48.429674 19224 solver.cpp:237] Iteration 63744, loss = 1.19453
I0525 08:25:48.429708 19224 solver.cpp:253]     Train net output #0: loss = 1.19453 (* 1 = 1.19453 loss)
I0525 08:25:48.429725 19224 sgd_solver.cpp:106] Iteration 63744, lr = 0.002
I0525 08:25:57.251230 19224 solver.cpp:237] Iteration 63910, loss = 1.48222
I0525 08:25:57.251265 19224 solver.cpp:253]     Train net output #0: loss = 1.48222 (* 1 = 1.48222 loss)
I0525 08:25:57.251281 19224 sgd_solver.cpp:106] Iteration 63910, lr = 0.002
I0525 08:26:06.080631 19224 solver.cpp:237] Iteration 64076, loss = 1.4287
I0525 08:26:06.080672 19224 solver.cpp:253]     Train net output #0: loss = 1.4287 (* 1 = 1.4287 loss)
I0525 08:26:06.080693 19224 sgd_solver.cpp:106] Iteration 64076, lr = 0.002
I0525 08:26:14.904688 19224 solver.cpp:237] Iteration 64242, loss = 1.02957
I0525 08:26:14.904858 19224 solver.cpp:253]     Train net output #0: loss = 1.02957 (* 1 = 1.02957 loss)
I0525 08:26:14.904872 19224 sgd_solver.cpp:106] Iteration 64242, lr = 0.002
I0525 08:26:23.734239 19224 solver.cpp:237] Iteration 64408, loss = 1.23187
I0525 08:26:23.734274 19224 solver.cpp:253]     Train net output #0: loss = 1.23187 (* 1 = 1.23187 loss)
I0525 08:26:23.734292 19224 sgd_solver.cpp:106] Iteration 64408, lr = 0.002
I0525 08:26:53.423508 19224 solver.cpp:237] Iteration 64574, loss = 1.07896
I0525 08:26:53.423707 19224 solver.cpp:253]     Train net output #0: loss = 1.07896 (* 1 = 1.07896 loss)
I0525 08:26:53.423722 19224 sgd_solver.cpp:106] Iteration 64574, lr = 0.002
I0525 08:27:02.251729 19224 solver.cpp:237] Iteration 64740, loss = 1.24353
I0525 08:27:02.251768 19224 solver.cpp:253]     Train net output #0: loss = 1.24353 (* 1 = 1.24353 loss)
I0525 08:27:02.251790 19224 sgd_solver.cpp:106] Iteration 64740, lr = 0.002
I0525 08:27:11.076244 19224 solver.cpp:237] Iteration 64906, loss = 1.2006
I0525 08:27:11.076279 19224 solver.cpp:253]     Train net output #0: loss = 1.2006 (* 1 = 1.2006 loss)
I0525 08:27:11.076292 19224 sgd_solver.cpp:106] Iteration 64906, lr = 0.002
I0525 08:27:14.645408 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_64974.caffemodel
I0525 08:27:14.721551 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_64974.solverstate
I0525 08:27:19.977010 19224 solver.cpp:237] Iteration 65072, loss = 1.08576
I0525 08:27:19.977064 19224 solver.cpp:253]     Train net output #0: loss = 1.08576 (* 1 = 1.08576 loss)
I0525 08:27:19.977084 19224 sgd_solver.cpp:106] Iteration 65072, lr = 0.002
I0525 08:27:28.798771 19224 solver.cpp:237] Iteration 65238, loss = 1.10036
I0525 08:27:28.798969 19224 solver.cpp:253]     Train net output #0: loss = 1.10036 (* 1 = 1.10036 loss)
I0525 08:27:28.798984 19224 sgd_solver.cpp:106] Iteration 65238, lr = 0.002
I0525 08:27:37.618576 19224 solver.cpp:237] Iteration 65404, loss = 1.20596
I0525 08:27:37.618609 19224 solver.cpp:253]     Train net output #0: loss = 1.20596 (* 1 = 1.20596 loss)
I0525 08:27:37.618624 19224 sgd_solver.cpp:106] Iteration 65404, lr = 0.002
I0525 08:28:07.356585 19224 solver.cpp:237] Iteration 65570, loss = 1.03321
I0525 08:28:07.356784 19224 solver.cpp:253]     Train net output #0: loss = 1.03321 (* 1 = 1.03321 loss)
I0525 08:28:07.356801 19224 sgd_solver.cpp:106] Iteration 65570, lr = 0.002
I0525 08:28:16.187157 19224 solver.cpp:237] Iteration 65736, loss = 1.27851
I0525 08:28:16.187194 19224 solver.cpp:253]     Train net output #0: loss = 1.27851 (* 1 = 1.27851 loss)
I0525 08:28:16.187211 19224 sgd_solver.cpp:106] Iteration 65736, lr = 0.002
I0525 08:28:25.011158 19224 solver.cpp:237] Iteration 65902, loss = 1.30574
I0525 08:28:25.011193 19224 solver.cpp:253]     Train net output #0: loss = 1.30574 (* 1 = 1.30574 loss)
I0525 08:28:25.011209 19224 sgd_solver.cpp:106] Iteration 65902, lr = 0.002
I0525 08:28:33.837304 19224 solver.cpp:237] Iteration 66068, loss = 1.33301
I0525 08:28:33.837349 19224 solver.cpp:253]     Train net output #0: loss = 1.33301 (* 1 = 1.33301 loss)
I0525 08:28:33.837368 19224 sgd_solver.cpp:106] Iteration 66068, lr = 0.002
I0525 08:28:42.660847 19224 solver.cpp:237] Iteration 66234, loss = 1.11467
I0525 08:28:42.661031 19224 solver.cpp:253]     Train net output #0: loss = 1.11467 (* 1 = 1.11467 loss)
I0525 08:28:42.661051 19224 sgd_solver.cpp:106] Iteration 66234, lr = 0.002
I0525 08:28:51.477960 19224 solver.cpp:237] Iteration 66400, loss = 1.21022
I0525 08:28:51.477994 19224 solver.cpp:253]     Train net output #0: loss = 1.21022 (* 1 = 1.21022 loss)
I0525 08:28:51.478013 19224 sgd_solver.cpp:106] Iteration 66400, lr = 0.002
I0525 08:29:00.292989 19224 solver.cpp:237] Iteration 66566, loss = 1.16857
I0525 08:29:00.293045 19224 solver.cpp:253]     Train net output #0: loss = 1.16857 (* 1 = 1.16857 loss)
I0525 08:29:00.293059 19224 sgd_solver.cpp:106] Iteration 66566, lr = 0.002
I0525 08:29:04.169499 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_66640.caffemodel
I0525 08:29:04.245625 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_66640.solverstate
I0525 08:29:05.302220 19224 solver.cpp:341] Iteration 66660, Testing net (#0)
I0525 08:30:13.405596 19224 solver.cpp:409]     Test net output #0: accuracy = 0.890561
I0525 08:30:13.405796 19224 solver.cpp:409]     Test net output #1: loss = 0.360523 (* 1 = 0.360523 loss)
I0525 08:30:38.134500 19224 solver.cpp:237] Iteration 66732, loss = 1.15735
I0525 08:30:38.134555 19224 solver.cpp:253]     Train net output #0: loss = 1.15735 (* 1 = 1.15735 loss)
I0525 08:30:38.134570 19224 sgd_solver.cpp:106] Iteration 66732, lr = 0.002
I0525 08:30:46.961179 19224 solver.cpp:237] Iteration 66898, loss = 1.11787
I0525 08:30:46.961365 19224 solver.cpp:253]     Train net output #0: loss = 1.11787 (* 1 = 1.11787 loss)
I0525 08:30:46.961380 19224 sgd_solver.cpp:106] Iteration 66898, lr = 0.002
I0525 08:30:55.789867 19224 solver.cpp:237] Iteration 67064, loss = 1.1398
I0525 08:30:55.789903 19224 solver.cpp:253]     Train net output #0: loss = 1.1398 (* 1 = 1.1398 loss)
I0525 08:30:55.789918 19224 sgd_solver.cpp:106] Iteration 67064, lr = 0.002
I0525 08:31:04.623684 19224 solver.cpp:237] Iteration 67230, loss = 1.25081
I0525 08:31:04.623734 19224 solver.cpp:253]     Train net output #0: loss = 1.25081 (* 1 = 1.25081 loss)
I0525 08:31:04.623754 19224 sgd_solver.cpp:106] Iteration 67230, lr = 0.002
I0525 08:31:13.449254 19224 solver.cpp:237] Iteration 67396, loss = 1.25351
I0525 08:31:13.449288 19224 solver.cpp:253]     Train net output #0: loss = 1.25351 (* 1 = 1.25351 loss)
I0525 08:31:13.449306 19224 sgd_solver.cpp:106] Iteration 67396, lr = 0.002
I0525 08:31:22.283805 19224 solver.cpp:237] Iteration 67562, loss = 1.12343
I0525 08:31:22.283992 19224 solver.cpp:253]     Train net output #0: loss = 1.12343 (* 1 = 1.12343 loss)
I0525 08:31:22.284005 19224 sgd_solver.cpp:106] Iteration 67562, lr = 0.002
I0525 08:31:31.104648 19224 solver.cpp:237] Iteration 67728, loss = 0.928358
I0525 08:31:31.104699 19224 solver.cpp:253]     Train net output #0: loss = 0.928358 (* 1 = 0.928358 loss)
I0525 08:31:31.104717 19224 sgd_solver.cpp:106] Iteration 67728, lr = 0.002
I0525 08:32:00.823765 19224 solver.cpp:237] Iteration 67894, loss = 0.98273
I0525 08:32:00.823969 19224 solver.cpp:253]     Train net output #0: loss = 0.98273 (* 1 = 0.98273 loss)
I0525 08:32:00.823984 19224 sgd_solver.cpp:106] Iteration 67894, lr = 0.002
I0525 08:32:09.651584 19224 solver.cpp:237] Iteration 68060, loss = 1.14338
I0525 08:32:09.651619 19224 solver.cpp:253]     Train net output #0: loss = 1.14338 (* 1 = 1.14338 loss)
I0525 08:32:09.651636 19224 sgd_solver.cpp:106] Iteration 68060, lr = 0.002
I0525 08:32:18.484262 19224 solver.cpp:237] Iteration 68226, loss = 1.05156
I0525 08:32:18.484298 19224 solver.cpp:253]     Train net output #0: loss = 1.05156 (* 1 = 1.05156 loss)
I0525 08:32:18.484313 19224 sgd_solver.cpp:106] Iteration 68226, lr = 0.002
I0525 08:32:22.682937 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_68306.caffemodel
I0525 08:32:22.758632 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_68306.solverstate
I0525 08:32:27.372668 19224 solver.cpp:237] Iteration 68392, loss = 1.29522
I0525 08:32:27.372719 19224 solver.cpp:253]     Train net output #0: loss = 1.29522 (* 1 = 1.29522 loss)
I0525 08:32:27.372735 19224 sgd_solver.cpp:106] Iteration 68392, lr = 0.002
I0525 08:32:36.208168 19224 solver.cpp:237] Iteration 68558, loss = 1.07788
I0525 08:32:36.208345 19224 solver.cpp:253]     Train net output #0: loss = 1.07788 (* 1 = 1.07788 loss)
I0525 08:32:36.208359 19224 sgd_solver.cpp:106] Iteration 68558, lr = 0.002
I0525 08:32:45.040071 19224 solver.cpp:237] Iteration 68724, loss = 1.23159
I0525 08:32:45.040118 19224 solver.cpp:253]     Train net output #0: loss = 1.23159 (* 1 = 1.23159 loss)
I0525 08:32:45.040134 19224 sgd_solver.cpp:106] Iteration 68724, lr = 0.002
I0525 08:33:14.721563 19224 solver.cpp:237] Iteration 68890, loss = 1.16769
I0525 08:33:14.721767 19224 solver.cpp:253]     Train net output #0: loss = 1.16769 (* 1 = 1.16769 loss)
I0525 08:33:14.721781 19224 sgd_solver.cpp:106] Iteration 68890, lr = 0.002
I0525 08:33:23.549226 19224 solver.cpp:237] Iteration 69056, loss = 1.06966
I0525 08:33:23.549259 19224 solver.cpp:253]     Train net output #0: loss = 1.06966 (* 1 = 1.06966 loss)
I0525 08:33:23.549278 19224 sgd_solver.cpp:106] Iteration 69056, lr = 0.002
I0525 08:33:32.373245 19224 solver.cpp:237] Iteration 69222, loss = 1.18316
I0525 08:33:32.373278 19224 solver.cpp:253]     Train net output #0: loss = 1.18316 (* 1 = 1.18316 loss)
I0525 08:33:32.373294 19224 sgd_solver.cpp:106] Iteration 69222, lr = 0.002
I0525 08:33:41.202903 19224 solver.cpp:237] Iteration 69388, loss = 1.23741
I0525 08:33:41.202950 19224 solver.cpp:253]     Train net output #0: loss = 1.23741 (* 1 = 1.23741 loss)
I0525 08:33:41.202966 19224 sgd_solver.cpp:106] Iteration 69388, lr = 0.002
I0525 08:33:50.021286 19224 solver.cpp:237] Iteration 69554, loss = 1.33628
I0525 08:33:50.021471 19224 solver.cpp:253]     Train net output #0: loss = 1.33628 (* 1 = 1.33628 loss)
I0525 08:33:50.021486 19224 sgd_solver.cpp:106] Iteration 69554, lr = 0.002
I0525 08:33:58.851198 19224 solver.cpp:237] Iteration 69720, loss = 1.18066
I0525 08:33:58.851244 19224 solver.cpp:253]     Train net output #0: loss = 1.18066 (* 1 = 1.18066 loss)
I0525 08:33:58.851263 19224 sgd_solver.cpp:106] Iteration 69720, lr = 0.002
I0525 08:34:07.676234 19224 solver.cpp:237] Iteration 69886, loss = 1.1818
I0525 08:34:07.676268 19224 solver.cpp:253]     Train net output #0: loss = 1.1818 (* 1 = 1.1818 loss)
I0525 08:34:07.676285 19224 sgd_solver.cpp:106] Iteration 69886, lr = 0.002
I0525 08:34:12.197892 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_69972.caffemodel
I0525 08:34:12.275754 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_69972.solverstate
I0525 08:34:13.382851 19224 solver.cpp:341] Iteration 69993, Testing net (#0)
I0525 08:35:00.560673 19224 solver.cpp:409]     Test net output #0: accuracy = 0.888667
I0525 08:35:00.560884 19224 solver.cpp:409]     Test net output #1: loss = 0.365375 (* 1 = 0.365375 loss)
I0525 08:35:24.593235 19224 solver.cpp:237] Iteration 70052, loss = 1.24235
I0525 08:35:24.593291 19224 solver.cpp:253]     Train net output #0: loss = 1.24235 (* 1 = 1.24235 loss)
I0525 08:35:24.593307 19224 sgd_solver.cpp:106] Iteration 70052, lr = 0.002
I0525 08:35:33.426151 19224 solver.cpp:237] Iteration 70218, loss = 1.08492
I0525 08:35:33.426331 19224 solver.cpp:253]     Train net output #0: loss = 1.08492 (* 1 = 1.08492 loss)
I0525 08:35:33.426344 19224 sgd_solver.cpp:106] Iteration 70218, lr = 0.002
I0525 08:35:42.262035 19224 solver.cpp:237] Iteration 70384, loss = 1.19151
I0525 08:35:42.262079 19224 solver.cpp:253]     Train net output #0: loss = 1.19151 (* 1 = 1.19151 loss)
I0525 08:35:42.262100 19224 sgd_solver.cpp:106] Iteration 70384, lr = 0.002
I0525 08:35:51.089198 19224 solver.cpp:237] Iteration 70550, loss = 1.09551
I0525 08:35:51.089234 19224 solver.cpp:253]     Train net output #0: loss = 1.09551 (* 1 = 1.09551 loss)
I0525 08:35:51.089247 19224 sgd_solver.cpp:106] Iteration 70550, lr = 0.002
I0525 08:35:59.915467 19224 solver.cpp:237] Iteration 70716, loss = 1.25559
I0525 08:35:59.915501 19224 solver.cpp:253]     Train net output #0: loss = 1.25559 (* 1 = 1.25559 loss)
I0525 08:35:59.915518 19224 sgd_solver.cpp:106] Iteration 70716, lr = 0.002
I0525 08:36:08.744467 19224 solver.cpp:237] Iteration 70882, loss = 1.18764
I0525 08:36:08.744657 19224 solver.cpp:253]     Train net output #0: loss = 1.18764 (* 1 = 1.18764 loss)
I0525 08:36:08.744671 19224 sgd_solver.cpp:106] Iteration 70882, lr = 0.002
I0525 08:36:17.578250 19224 solver.cpp:237] Iteration 71048, loss = 1.1764
I0525 08:36:17.578284 19224 solver.cpp:253]     Train net output #0: loss = 1.1764 (* 1 = 1.1764 loss)
I0525 08:36:17.578299 19224 sgd_solver.cpp:106] Iteration 71048, lr = 0.002
I0525 08:36:47.289396 19224 solver.cpp:237] Iteration 71214, loss = 1.14988
I0525 08:36:47.289597 19224 solver.cpp:253]     Train net output #0: loss = 1.14988 (* 1 = 1.14988 loss)
I0525 08:36:47.289611 19224 sgd_solver.cpp:106] Iteration 71214, lr = 0.002
I0525 08:36:56.121781 19224 solver.cpp:237] Iteration 71380, loss = 1.21535
I0525 08:36:56.121831 19224 solver.cpp:253]     Train net output #0: loss = 1.21535 (* 1 = 1.21535 loss)
I0525 08:36:56.121848 19224 sgd_solver.cpp:106] Iteration 71380, lr = 0.002
I0525 08:37:04.952170 19224 solver.cpp:237] Iteration 71546, loss = 0.930234
I0525 08:37:04.952208 19224 solver.cpp:253]     Train net output #0: loss = 0.930234 (* 1 = 0.930234 loss)
I0525 08:37:04.952224 19224 sgd_solver.cpp:106] Iteration 71546, lr = 0.002
I0525 08:37:09.801147 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_71638.caffemodel
I0525 08:37:09.875481 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_71638.solverstate
I0525 08:37:13.856276 19224 solver.cpp:237] Iteration 71712, loss = 1.38432
I0525 08:37:13.856325 19224 solver.cpp:253]     Train net output #0: loss = 1.38432 (* 1 = 1.38432 loss)
I0525 08:37:13.856339 19224 sgd_solver.cpp:106] Iteration 71712, lr = 0.002
I0525 08:37:22.696938 19224 solver.cpp:237] Iteration 71878, loss = 0.999124
I0525 08:37:22.697154 19224 solver.cpp:253]     Train net output #0: loss = 0.999124 (* 1 = 0.999124 loss)
I0525 08:37:22.697170 19224 sgd_solver.cpp:106] Iteration 71878, lr = 0.002
I0525 08:37:31.530562 19224 solver.cpp:237] Iteration 72044, loss = 1.11665
I0525 08:37:31.530597 19224 solver.cpp:253]     Train net output #0: loss = 1.11665 (* 1 = 1.11665 loss)
I0525 08:37:31.530613 19224 sgd_solver.cpp:106] Iteration 72044, lr = 0.002
I0525 08:37:40.364923 19224 solver.cpp:237] Iteration 72210, loss = 0.908868
I0525 08:37:40.364959 19224 solver.cpp:253]     Train net output #0: loss = 0.908868 (* 1 = 0.908868 loss)
I0525 08:37:40.364975 19224 sgd_solver.cpp:106] Iteration 72210, lr = 0.002
I0525 08:38:10.072300 19224 solver.cpp:237] Iteration 72376, loss = 1.36206
I0525 08:38:10.072502 19224 solver.cpp:253]     Train net output #0: loss = 1.36206 (* 1 = 1.36206 loss)
I0525 08:38:10.072516 19224 sgd_solver.cpp:106] Iteration 72376, lr = 0.002
I0525 08:38:18.906452 19224 solver.cpp:237] Iteration 72542, loss = 1.06246
I0525 08:38:18.906487 19224 solver.cpp:253]     Train net output #0: loss = 1.06246 (* 1 = 1.06246 loss)
I0525 08:38:18.906503 19224 sgd_solver.cpp:106] Iteration 72542, lr = 0.002
I0525 08:38:27.746922 19224 solver.cpp:237] Iteration 72708, loss = 1.04071
I0525 08:38:27.746958 19224 solver.cpp:253]     Train net output #0: loss = 1.04071 (* 1 = 1.04071 loss)
I0525 08:38:27.746976 19224 sgd_solver.cpp:106] Iteration 72708, lr = 0.002
I0525 08:38:36.580739 19224 solver.cpp:237] Iteration 72874, loss = 0.939289
I0525 08:38:36.580795 19224 solver.cpp:253]     Train net output #0: loss = 0.939289 (* 1 = 0.939289 loss)
I0525 08:38:36.580809 19224 sgd_solver.cpp:106] Iteration 72874, lr = 0.002
I0525 08:38:45.409919 19224 solver.cpp:237] Iteration 73040, loss = 1.35726
I0525 08:38:45.410107 19224 solver.cpp:253]     Train net output #0: loss = 1.35726 (* 1 = 1.35726 loss)
I0525 08:38:45.410120 19224 sgd_solver.cpp:106] Iteration 73040, lr = 0.002
I0525 08:38:54.239925 19224 solver.cpp:237] Iteration 73206, loss = 1.04339
I0525 08:38:54.239959 19224 solver.cpp:253]     Train net output #0: loss = 1.04339 (* 1 = 1.04339 loss)
I0525 08:38:54.239976 19224 sgd_solver.cpp:106] Iteration 73206, lr = 0.002
I0525 08:38:59.404706 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_73304.caffemodel
I0525 08:38:59.480978 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_73304.solverstate
I0525 08:39:00.640805 19224 solver.cpp:341] Iteration 73326, Testing net (#0)
I0525 08:40:08.697794 19224 solver.cpp:409]     Test net output #0: accuracy = 0.888907
I0525 08:40:08.697993 19224 solver.cpp:409]     Test net output #1: loss = 0.387444 (* 1 = 0.387444 loss)
I0525 08:40:32.038470 19224 solver.cpp:237] Iteration 73372, loss = 1.14154
I0525 08:40:32.038524 19224 solver.cpp:253]     Train net output #0: loss = 1.14154 (* 1 = 1.14154 loss)
I0525 08:40:32.038540 19224 sgd_solver.cpp:106] Iteration 73372, lr = 0.002
I0525 08:40:40.862040 19224 solver.cpp:237] Iteration 73538, loss = 1.11566
I0525 08:40:40.862251 19224 solver.cpp:253]     Train net output #0: loss = 1.11566 (* 1 = 1.11566 loss)
I0525 08:40:40.862265 19224 sgd_solver.cpp:106] Iteration 73538, lr = 0.002
I0525 08:40:49.682168 19224 solver.cpp:237] Iteration 73704, loss = 1.03474
I0525 08:40:49.682202 19224 solver.cpp:253]     Train net output #0: loss = 1.03474 (* 1 = 1.03474 loss)
I0525 08:40:49.682219 19224 sgd_solver.cpp:106] Iteration 73704, lr = 0.002
I0525 08:40:58.505929 19224 solver.cpp:237] Iteration 73870, loss = 1.13696
I0525 08:40:58.505965 19224 solver.cpp:253]     Train net output #0: loss = 1.13696 (* 1 = 1.13696 loss)
I0525 08:40:58.505980 19224 sgd_solver.cpp:106] Iteration 73870, lr = 0.002
I0525 08:41:07.320871 19224 solver.cpp:237] Iteration 74036, loss = 1.24398
I0525 08:41:07.320916 19224 solver.cpp:253]     Train net output #0: loss = 1.24398 (* 1 = 1.24398 loss)
I0525 08:41:07.320936 19224 sgd_solver.cpp:106] Iteration 74036, lr = 0.002
I0525 08:41:16.135833 19224 solver.cpp:237] Iteration 74202, loss = 1.15847
I0525 08:41:16.136011 19224 solver.cpp:253]     Train net output #0: loss = 1.15847 (* 1 = 1.15847 loss)
I0525 08:41:16.136024 19224 sgd_solver.cpp:106] Iteration 74202, lr = 0.002
I0525 08:41:24.969137 19224 solver.cpp:237] Iteration 74368, loss = 1.06365
I0525 08:41:24.969172 19224 solver.cpp:253]     Train net output #0: loss = 1.06365 (* 1 = 1.06365 loss)
I0525 08:41:24.969188 19224 sgd_solver.cpp:106] Iteration 74368, lr = 0.002
I0525 08:41:54.637213 19224 solver.cpp:237] Iteration 74534, loss = 1.20415
I0525 08:41:54.637418 19224 solver.cpp:253]     Train net output #0: loss = 1.20415 (* 1 = 1.20415 loss)
I0525 08:41:54.637431 19224 sgd_solver.cpp:106] Iteration 74534, lr = 0.002
I0525 08:42:03.460875 19224 solver.cpp:237] Iteration 74700, loss = 1.0157
I0525 08:42:03.460911 19224 solver.cpp:253]     Train net output #0: loss = 1.0157 (* 1 = 1.0157 loss)
I0525 08:42:03.460928 19224 sgd_solver.cpp:106] Iteration 74700, lr = 0.002
I0525 08:42:12.284873 19224 solver.cpp:237] Iteration 74866, loss = 1.00862
I0525 08:42:12.284909 19224 solver.cpp:253]     Train net output #0: loss = 1.00862 (* 1 = 1.00862 loss)
I0525 08:42:12.284924 19224 sgd_solver.cpp:106] Iteration 74866, lr = 0.002
I0525 08:42:17.761235 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_74970.caffemodel
I0525 08:42:17.838220 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_74970.solverstate
I0525 08:42:21.176357 19224 solver.cpp:237] Iteration 75032, loss = 1.02759
I0525 08:42:21.176411 19224 solver.cpp:253]     Train net output #0: loss = 1.02759 (* 1 = 1.02759 loss)
I0525 08:42:21.176427 19224 sgd_solver.cpp:106] Iteration 75032, lr = 0.002
I0525 08:42:29.999918 19224 solver.cpp:237] Iteration 75198, loss = 1.31637
I0525 08:42:30.000111 19224 solver.cpp:253]     Train net output #0: loss = 1.31637 (* 1 = 1.31637 loss)
I0525 08:42:30.000125 19224 sgd_solver.cpp:106] Iteration 75198, lr = 0.002
I0525 08:42:38.829668 19224 solver.cpp:237] Iteration 75364, loss = 1.12449
I0525 08:42:38.829704 19224 solver.cpp:253]     Train net output #0: loss = 1.12449 (* 1 = 1.12449 loss)
I0525 08:42:38.829720 19224 sgd_solver.cpp:106] Iteration 75364, lr = 0.002
I0525 08:42:47.658123 19224 solver.cpp:237] Iteration 75530, loss = 1.17286
I0525 08:42:47.658175 19224 solver.cpp:253]     Train net output #0: loss = 1.17286 (* 1 = 1.17286 loss)
I0525 08:42:47.658190 19224 sgd_solver.cpp:106] Iteration 75530, lr = 0.002
I0525 08:43:17.361438 19224 solver.cpp:237] Iteration 75696, loss = 1.26825
I0525 08:43:17.361639 19224 solver.cpp:253]     Train net output #0: loss = 1.26825 (* 1 = 1.26825 loss)
I0525 08:43:17.361654 19224 sgd_solver.cpp:106] Iteration 75696, lr = 0.002
I0525 08:43:26.184294 19224 solver.cpp:237] Iteration 75862, loss = 1.15389
I0525 08:43:26.184329 19224 solver.cpp:253]     Train net output #0: loss = 1.15389 (* 1 = 1.15389 loss)
I0525 08:43:26.184346 19224 sgd_solver.cpp:106] Iteration 75862, lr = 0.002
I0525 08:43:35.002583 19224 solver.cpp:237] Iteration 76028, loss = 1.17767
I0525 08:43:35.002629 19224 solver.cpp:253]     Train net output #0: loss = 1.17767 (* 1 = 1.17767 loss)
I0525 08:43:35.002650 19224 sgd_solver.cpp:106] Iteration 76028, lr = 0.002
I0525 08:43:43.824738 19224 solver.cpp:237] Iteration 76194, loss = 1.05782
I0525 08:43:43.824774 19224 solver.cpp:253]     Train net output #0: loss = 1.05782 (* 1 = 1.05782 loss)
I0525 08:43:43.824790 19224 sgd_solver.cpp:106] Iteration 76194, lr = 0.002
I0525 08:43:52.649013 19224 solver.cpp:237] Iteration 76360, loss = 1.31832
I0525 08:43:52.649209 19224 solver.cpp:253]     Train net output #0: loss = 1.31832 (* 1 = 1.31832 loss)
I0525 08:43:52.649222 19224 sgd_solver.cpp:106] Iteration 76360, lr = 0.002
I0525 08:44:01.472628 19224 solver.cpp:237] Iteration 76526, loss = 1.13693
I0525 08:44:01.472683 19224 solver.cpp:253]     Train net output #0: loss = 1.13693 (* 1 = 1.13693 loss)
I0525 08:44:01.472698 19224 sgd_solver.cpp:106] Iteration 76526, lr = 0.002
I0525 08:44:07.265377 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_76636.caffemodel
I0525 08:44:07.340091 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_76636.solverstate
I0525 08:44:08.554122 19224 solver.cpp:341] Iteration 76659, Testing net (#0)
I0525 08:44:55.324059 19224 solver.cpp:409]     Test net output #0: accuracy = 0.889981
I0525 08:44:55.324267 19224 solver.cpp:409]     Test net output #1: loss = 0.366019 (* 1 = 0.366019 loss)
I0525 08:45:17.957490 19224 solver.cpp:237] Iteration 76692, loss = 1.11233
I0525 08:45:17.957543 19224 solver.cpp:253]     Train net output #0: loss = 1.11233 (* 1 = 1.11233 loss)
I0525 08:45:17.957559 19224 sgd_solver.cpp:106] Iteration 76692, lr = 0.002
I0525 08:45:26.782125 19224 solver.cpp:237] Iteration 76858, loss = 1.01253
I0525 08:45:26.782312 19224 solver.cpp:253]     Train net output #0: loss = 1.01253 (* 1 = 1.01253 loss)
I0525 08:45:26.782326 19224 sgd_solver.cpp:106] Iteration 76858, lr = 0.002
I0525 08:45:35.606735 19224 solver.cpp:237] Iteration 77024, loss = 1.23408
I0525 08:45:35.606771 19224 solver.cpp:253]     Train net output #0: loss = 1.23408 (* 1 = 1.23408 loss)
I0525 08:45:35.606788 19224 sgd_solver.cpp:106] Iteration 77024, lr = 0.002
I0525 08:45:44.429203 19224 solver.cpp:237] Iteration 77190, loss = 0.975314
I0525 08:45:44.429257 19224 solver.cpp:253]     Train net output #0: loss = 0.975314 (* 1 = 0.975314 loss)
I0525 08:45:44.429270 19224 sgd_solver.cpp:106] Iteration 77190, lr = 0.002
I0525 08:45:53.250360 19224 solver.cpp:237] Iteration 77356, loss = 1.26492
I0525 08:45:53.250394 19224 solver.cpp:253]     Train net output #0: loss = 1.26492 (* 1 = 1.26492 loss)
I0525 08:45:53.250408 19224 sgd_solver.cpp:106] Iteration 77356, lr = 0.002
I0525 08:46:02.064947 19224 solver.cpp:237] Iteration 77522, loss = 1.29044
I0525 08:46:02.065135 19224 solver.cpp:253]     Train net output #0: loss = 1.29044 (* 1 = 1.29044 loss)
I0525 08:46:02.065148 19224 sgd_solver.cpp:106] Iteration 77522, lr = 0.002
I0525 08:46:10.887905 19224 solver.cpp:237] Iteration 77688, loss = 1.24305
I0525 08:46:10.887946 19224 solver.cpp:253]     Train net output #0: loss = 1.24305 (* 1 = 1.24305 loss)
I0525 08:46:10.887967 19224 sgd_solver.cpp:106] Iteration 77688, lr = 0.002
I0525 08:46:40.603438 19224 solver.cpp:237] Iteration 77854, loss = 1.01535
I0525 08:46:40.603644 19224 solver.cpp:253]     Train net output #0: loss = 1.01535 (* 1 = 1.01535 loss)
I0525 08:46:40.603658 19224 sgd_solver.cpp:106] Iteration 77854, lr = 0.002
I0525 08:46:49.423267 19224 solver.cpp:237] Iteration 78020, loss = 1.0614
I0525 08:46:49.423301 19224 solver.cpp:253]     Train net output #0: loss = 1.0614 (* 1 = 1.0614 loss)
I0525 08:46:49.423318 19224 sgd_solver.cpp:106] Iteration 78020, lr = 0.002
I0525 08:46:58.243340 19224 solver.cpp:237] Iteration 78186, loss = 1.15161
I0525 08:46:58.243386 19224 solver.cpp:253]     Train net output #0: loss = 1.15161 (* 1 = 1.15161 loss)
I0525 08:46:58.243405 19224 sgd_solver.cpp:106] Iteration 78186, lr = 0.002
I0525 08:47:04.359592 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_78302.caffemodel
I0525 08:47:04.434953 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_78302.solverstate
I0525 08:47:07.133728 19224 solver.cpp:237] Iteration 78352, loss = 1.31225
I0525 08:47:07.133777 19224 solver.cpp:253]     Train net output #0: loss = 1.31225 (* 1 = 1.31225 loss)
I0525 08:47:07.133795 19224 sgd_solver.cpp:106] Iteration 78352, lr = 0.002
I0525 08:47:15.961354 19224 solver.cpp:237] Iteration 78518, loss = 1.08796
I0525 08:47:15.961549 19224 solver.cpp:253]     Train net output #0: loss = 1.08796 (* 1 = 1.08796 loss)
I0525 08:47:15.961562 19224 sgd_solver.cpp:106] Iteration 78518, lr = 0.002
I0525 08:47:24.784924 19224 solver.cpp:237] Iteration 78684, loss = 1.21027
I0525 08:47:24.784970 19224 solver.cpp:253]     Train net output #0: loss = 1.21027 (* 1 = 1.21027 loss)
I0525 08:47:24.784991 19224 sgd_solver.cpp:106] Iteration 78684, lr = 0.002
I0525 08:47:33.607959 19224 solver.cpp:237] Iteration 78850, loss = 1.28986
I0525 08:47:33.607995 19224 solver.cpp:253]     Train net output #0: loss = 1.28986 (* 1 = 1.28986 loss)
I0525 08:47:33.608012 19224 sgd_solver.cpp:106] Iteration 78850, lr = 0.002
I0525 08:48:03.321266 19224 solver.cpp:237] Iteration 79016, loss = 1.04317
I0525 08:48:03.321472 19224 solver.cpp:253]     Train net output #0: loss = 1.04317 (* 1 = 1.04317 loss)
I0525 08:48:03.321486 19224 sgd_solver.cpp:106] Iteration 79016, lr = 0.002
I0525 08:48:12.155019 19224 solver.cpp:237] Iteration 79182, loss = 1.24935
I0525 08:48:12.155068 19224 solver.cpp:253]     Train net output #0: loss = 1.24935 (* 1 = 1.24935 loss)
I0525 08:48:12.155086 19224 sgd_solver.cpp:106] Iteration 79182, lr = 0.002
I0525 08:48:20.981516 19224 solver.cpp:237] Iteration 79348, loss = 1.09764
I0525 08:48:20.981552 19224 solver.cpp:253]     Train net output #0: loss = 1.09764 (* 1 = 1.09764 loss)
I0525 08:48:20.981569 19224 sgd_solver.cpp:106] Iteration 79348, lr = 0.002
I0525 08:48:29.808405 19224 solver.cpp:237] Iteration 79514, loss = 1.02969
I0525 08:48:29.808440 19224 solver.cpp:253]     Train net output #0: loss = 1.02969 (* 1 = 1.02969 loss)
I0525 08:48:29.808456 19224 sgd_solver.cpp:106] Iteration 79514, lr = 0.002
I0525 08:48:38.623625 19224 solver.cpp:237] Iteration 79680, loss = 1.06953
I0525 08:48:38.623824 19224 solver.cpp:253]     Train net output #0: loss = 1.06953 (* 1 = 1.06953 loss)
I0525 08:48:38.623839 19224 sgd_solver.cpp:106] Iteration 79680, lr = 0.002
I0525 08:48:47.442273 19224 solver.cpp:237] Iteration 79846, loss = 1.01646
I0525 08:48:47.442308 19224 solver.cpp:253]     Train net output #0: loss = 1.01646 (* 1 = 1.01646 loss)
I0525 08:48:47.442325 19224 sgd_solver.cpp:106] Iteration 79846, lr = 0.002
I0525 08:48:53.871636 19224 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_79968.caffemodel
I0525 08:48:53.947490 19224 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0020_2016-05-20T15.49.21.287877_iter_79968.solverstate
I0525 08:48:55.213299 19224 solver.cpp:341] Iteration 79992, Testing net (#0)
aprun: Apid 11262843: Caught signal Terminated, sending to application
aprun: Apid 11262843: Caught signal Terminated, sending to application
*** Aborted at 1464180583 (unix time) try "date -d @1464180583" if you are using GNU date ***
aprun: Apid 11262843: Caught signal Terminated, sending to application
aprun: Apid 11262843: Caught signal Terminated, sending to application
PC: @     0x2aaac5e9bb37 (unknown)
aprun: Apid 11262843: Caught signal Terminated, sending to application
*** SIGTERM (@0x4b15) received by PID 19224 (TID 0x2aaac746f900) from PID 19221; stack trace: ***
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaac5e9bb37 (unknown)
aprun: Apid 11262843: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7220 exceeded limit 7200
    @     0x2aaac5e9c9d5 inflate
aprun: Apid 11262843: Caught signal Terminated, sending to application
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11262843: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
_pmiu_daemon(SIGCHLD): [NID 03789] [c8-1c0s6n1] [Wed May 25 08:49:44 2016] PE RANK 0 exit signal Terminated
Application 11262843 exit codes: 143
Application 11262843 resources: utime ~6228s, stime ~980s, Rss ~5332656, inblocks ~16324445, outblocks ~740496
