2809019
I0523 20:22:09.701879  3749 caffe.cpp:184] Using GPUs 0
I0523 20:22:10.132139  3749 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2500
test_interval: 5000
base_lr: 0.005
display: 250
max_iter: 250000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131.prototxt"
I0523 20:22:10.134104  3749 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131.prototxt
I0523 20:22:10.157938  3749 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 20:22:10.157997  3749 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 20:22:10.158344  3749 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 20:22:10.158525  3749 layer_factory.hpp:77] Creating layer data_hdf5
I0523 20:22:10.158550  3749 net.cpp:106] Creating Layer data_hdf5
I0523 20:22:10.158565  3749 net.cpp:411] data_hdf5 -> data
I0523 20:22:10.158597  3749 net.cpp:411] data_hdf5 -> label
I0523 20:22:10.158630  3749 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 20:22:10.159952  3749 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 20:22:10.162156  3749 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 20:22:31.665035  3749 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 20:22:31.670194  3749 net.cpp:150] Setting up data_hdf5
I0523 20:22:31.670235  3749 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 20:22:31.670250  3749 net.cpp:157] Top shape: 60 (60)
I0523 20:22:31.670263  3749 net.cpp:165] Memory required for data: 1524240
I0523 20:22:31.670275  3749 layer_factory.hpp:77] Creating layer conv1
I0523 20:22:31.670310  3749 net.cpp:106] Creating Layer conv1
I0523 20:22:31.670320  3749 net.cpp:454] conv1 <- data
I0523 20:22:31.670342  3749 net.cpp:411] conv1 -> conv1
I0523 20:22:32.034838  3749 net.cpp:150] Setting up conv1
I0523 20:22:32.034885  3749 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:22:32.034896  3749 net.cpp:165] Memory required for data: 18113040
I0523 20:22:32.034925  3749 layer_factory.hpp:77] Creating layer relu1
I0523 20:22:32.034946  3749 net.cpp:106] Creating Layer relu1
I0523 20:22:32.034957  3749 net.cpp:454] relu1 <- conv1
I0523 20:22:32.034970  3749 net.cpp:397] relu1 -> conv1 (in-place)
I0523 20:22:32.035495  3749 net.cpp:150] Setting up relu1
I0523 20:22:32.035512  3749 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:22:32.035522  3749 net.cpp:165] Memory required for data: 34701840
I0523 20:22:32.035533  3749 layer_factory.hpp:77] Creating layer pool1
I0523 20:22:32.035549  3749 net.cpp:106] Creating Layer pool1
I0523 20:22:32.035559  3749 net.cpp:454] pool1 <- conv1
I0523 20:22:32.035573  3749 net.cpp:411] pool1 -> pool1
I0523 20:22:32.035652  3749 net.cpp:150] Setting up pool1
I0523 20:22:32.035666  3749 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 20:22:32.035676  3749 net.cpp:165] Memory required for data: 42996240
I0523 20:22:32.035686  3749 layer_factory.hpp:77] Creating layer conv2
I0523 20:22:32.035709  3749 net.cpp:106] Creating Layer conv2
I0523 20:22:32.035719  3749 net.cpp:454] conv2 <- pool1
I0523 20:22:32.035733  3749 net.cpp:411] conv2 -> conv2
I0523 20:22:32.038442  3749 net.cpp:150] Setting up conv2
I0523 20:22:32.038471  3749 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:22:32.038481  3749 net.cpp:165] Memory required for data: 54919440
I0523 20:22:32.038501  3749 layer_factory.hpp:77] Creating layer relu2
I0523 20:22:32.038514  3749 net.cpp:106] Creating Layer relu2
I0523 20:22:32.038524  3749 net.cpp:454] relu2 <- conv2
I0523 20:22:32.038537  3749 net.cpp:397] relu2 -> conv2 (in-place)
I0523 20:22:32.038868  3749 net.cpp:150] Setting up relu2
I0523 20:22:32.038883  3749 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:22:32.038893  3749 net.cpp:165] Memory required for data: 66842640
I0523 20:22:32.038903  3749 layer_factory.hpp:77] Creating layer pool2
I0523 20:22:32.038915  3749 net.cpp:106] Creating Layer pool2
I0523 20:22:32.038925  3749 net.cpp:454] pool2 <- conv2
I0523 20:22:32.038938  3749 net.cpp:411] pool2 -> pool2
I0523 20:22:32.039021  3749 net.cpp:150] Setting up pool2
I0523 20:22:32.039033  3749 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 20:22:32.039043  3749 net.cpp:165] Memory required for data: 72804240
I0523 20:22:32.039052  3749 layer_factory.hpp:77] Creating layer conv3
I0523 20:22:32.039070  3749 net.cpp:106] Creating Layer conv3
I0523 20:22:32.039080  3749 net.cpp:454] conv3 <- pool2
I0523 20:22:32.039094  3749 net.cpp:411] conv3 -> conv3
I0523 20:22:32.041041  3749 net.cpp:150] Setting up conv3
I0523 20:22:32.041065  3749 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:22:32.041074  3749 net.cpp:165] Memory required for data: 79309200
I0523 20:22:32.041093  3749 layer_factory.hpp:77] Creating layer relu3
I0523 20:22:32.041110  3749 net.cpp:106] Creating Layer relu3
I0523 20:22:32.041121  3749 net.cpp:454] relu3 <- conv3
I0523 20:22:32.041133  3749 net.cpp:397] relu3 -> conv3 (in-place)
I0523 20:22:32.041604  3749 net.cpp:150] Setting up relu3
I0523 20:22:32.041620  3749 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:22:32.041630  3749 net.cpp:165] Memory required for data: 85814160
I0523 20:22:32.041640  3749 layer_factory.hpp:77] Creating layer pool3
I0523 20:22:32.041653  3749 net.cpp:106] Creating Layer pool3
I0523 20:22:32.041663  3749 net.cpp:454] pool3 <- conv3
I0523 20:22:32.041676  3749 net.cpp:411] pool3 -> pool3
I0523 20:22:32.041744  3749 net.cpp:150] Setting up pool3
I0523 20:22:32.041757  3749 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 20:22:32.041766  3749 net.cpp:165] Memory required for data: 89066640
I0523 20:22:32.041776  3749 layer_factory.hpp:77] Creating layer conv4
I0523 20:22:32.041795  3749 net.cpp:106] Creating Layer conv4
I0523 20:22:32.041805  3749 net.cpp:454] conv4 <- pool3
I0523 20:22:32.041817  3749 net.cpp:411] conv4 -> conv4
I0523 20:22:32.044571  3749 net.cpp:150] Setting up conv4
I0523 20:22:32.044600  3749 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:22:32.044611  3749 net.cpp:165] Memory required for data: 91243920
I0523 20:22:32.044627  3749 layer_factory.hpp:77] Creating layer relu4
I0523 20:22:32.044641  3749 net.cpp:106] Creating Layer relu4
I0523 20:22:32.044651  3749 net.cpp:454] relu4 <- conv4
I0523 20:22:32.044664  3749 net.cpp:397] relu4 -> conv4 (in-place)
I0523 20:22:32.045140  3749 net.cpp:150] Setting up relu4
I0523 20:22:32.045156  3749 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:22:32.045166  3749 net.cpp:165] Memory required for data: 93421200
I0523 20:22:32.045176  3749 layer_factory.hpp:77] Creating layer pool4
I0523 20:22:32.045189  3749 net.cpp:106] Creating Layer pool4
I0523 20:22:32.045199  3749 net.cpp:454] pool4 <- conv4
I0523 20:22:32.045212  3749 net.cpp:411] pool4 -> pool4
I0523 20:22:32.045281  3749 net.cpp:150] Setting up pool4
I0523 20:22:32.045295  3749 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 20:22:32.045305  3749 net.cpp:165] Memory required for data: 94509840
I0523 20:22:32.045315  3749 layer_factory.hpp:77] Creating layer ip1
I0523 20:22:32.045333  3749 net.cpp:106] Creating Layer ip1
I0523 20:22:32.045344  3749 net.cpp:454] ip1 <- pool4
I0523 20:22:32.045357  3749 net.cpp:411] ip1 -> ip1
I0523 20:22:32.060744  3749 net.cpp:150] Setting up ip1
I0523 20:22:32.060772  3749 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:22:32.060786  3749 net.cpp:165] Memory required for data: 94556880
I0523 20:22:32.060808  3749 layer_factory.hpp:77] Creating layer relu5
I0523 20:22:32.060823  3749 net.cpp:106] Creating Layer relu5
I0523 20:22:32.060834  3749 net.cpp:454] relu5 <- ip1
I0523 20:22:32.060847  3749 net.cpp:397] relu5 -> ip1 (in-place)
I0523 20:22:32.061189  3749 net.cpp:150] Setting up relu5
I0523 20:22:32.061203  3749 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:22:32.061214  3749 net.cpp:165] Memory required for data: 94603920
I0523 20:22:32.061224  3749 layer_factory.hpp:77] Creating layer drop1
I0523 20:22:32.061246  3749 net.cpp:106] Creating Layer drop1
I0523 20:22:32.061256  3749 net.cpp:454] drop1 <- ip1
I0523 20:22:32.061269  3749 net.cpp:397] drop1 -> ip1 (in-place)
I0523 20:22:32.061327  3749 net.cpp:150] Setting up drop1
I0523 20:22:32.061341  3749 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:22:32.061350  3749 net.cpp:165] Memory required for data: 94650960
I0523 20:22:32.061362  3749 layer_factory.hpp:77] Creating layer ip2
I0523 20:22:32.061379  3749 net.cpp:106] Creating Layer ip2
I0523 20:22:32.061389  3749 net.cpp:454] ip2 <- ip1
I0523 20:22:32.061403  3749 net.cpp:411] ip2 -> ip2
I0523 20:22:32.061863  3749 net.cpp:150] Setting up ip2
I0523 20:22:32.061877  3749 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:22:32.061887  3749 net.cpp:165] Memory required for data: 94674480
I0523 20:22:32.061902  3749 layer_factory.hpp:77] Creating layer relu6
I0523 20:22:32.061914  3749 net.cpp:106] Creating Layer relu6
I0523 20:22:32.061924  3749 net.cpp:454] relu6 <- ip2
I0523 20:22:32.061936  3749 net.cpp:397] relu6 -> ip2 (in-place)
I0523 20:22:32.062453  3749 net.cpp:150] Setting up relu6
I0523 20:22:32.062469  3749 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:22:32.062480  3749 net.cpp:165] Memory required for data: 94698000
I0523 20:22:32.062491  3749 layer_factory.hpp:77] Creating layer drop2
I0523 20:22:32.062505  3749 net.cpp:106] Creating Layer drop2
I0523 20:22:32.062515  3749 net.cpp:454] drop2 <- ip2
I0523 20:22:32.062527  3749 net.cpp:397] drop2 -> ip2 (in-place)
I0523 20:22:32.062568  3749 net.cpp:150] Setting up drop2
I0523 20:22:32.062582  3749 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:22:32.062592  3749 net.cpp:165] Memory required for data: 94721520
I0523 20:22:32.062602  3749 layer_factory.hpp:77] Creating layer ip3
I0523 20:22:32.062615  3749 net.cpp:106] Creating Layer ip3
I0523 20:22:32.062625  3749 net.cpp:454] ip3 <- ip2
I0523 20:22:32.062638  3749 net.cpp:411] ip3 -> ip3
I0523 20:22:32.062849  3749 net.cpp:150] Setting up ip3
I0523 20:22:32.062861  3749 net.cpp:157] Top shape: 60 11 (660)
I0523 20:22:32.062871  3749 net.cpp:165] Memory required for data: 94724160
I0523 20:22:32.062886  3749 layer_factory.hpp:77] Creating layer drop3
I0523 20:22:32.062898  3749 net.cpp:106] Creating Layer drop3
I0523 20:22:32.062908  3749 net.cpp:454] drop3 <- ip3
I0523 20:22:32.062919  3749 net.cpp:397] drop3 -> ip3 (in-place)
I0523 20:22:32.062959  3749 net.cpp:150] Setting up drop3
I0523 20:22:32.062973  3749 net.cpp:157] Top shape: 60 11 (660)
I0523 20:22:32.062983  3749 net.cpp:165] Memory required for data: 94726800
I0523 20:22:32.062993  3749 layer_factory.hpp:77] Creating layer loss
I0523 20:22:32.063011  3749 net.cpp:106] Creating Layer loss
I0523 20:22:32.063021  3749 net.cpp:454] loss <- ip3
I0523 20:22:32.063032  3749 net.cpp:454] loss <- label
I0523 20:22:32.063043  3749 net.cpp:411] loss -> loss
I0523 20:22:32.063061  3749 layer_factory.hpp:77] Creating layer loss
I0523 20:22:32.063712  3749 net.cpp:150] Setting up loss
I0523 20:22:32.063729  3749 net.cpp:157] Top shape: (1)
I0523 20:22:32.063737  3749 net.cpp:160]     with loss weight 1
I0523 20:22:32.063779  3749 net.cpp:165] Memory required for data: 94726804
I0523 20:22:32.063791  3749 net.cpp:226] loss needs backward computation.
I0523 20:22:32.063802  3749 net.cpp:226] drop3 needs backward computation.
I0523 20:22:32.063812  3749 net.cpp:226] ip3 needs backward computation.
I0523 20:22:32.063819  3749 net.cpp:226] drop2 needs backward computation.
I0523 20:22:32.063829  3749 net.cpp:226] relu6 needs backward computation.
I0523 20:22:32.063838  3749 net.cpp:226] ip2 needs backward computation.
I0523 20:22:32.063848  3749 net.cpp:226] drop1 needs backward computation.
I0523 20:22:32.063858  3749 net.cpp:226] relu5 needs backward computation.
I0523 20:22:32.063868  3749 net.cpp:226] ip1 needs backward computation.
I0523 20:22:32.063879  3749 net.cpp:226] pool4 needs backward computation.
I0523 20:22:32.063889  3749 net.cpp:226] relu4 needs backward computation.
I0523 20:22:32.063899  3749 net.cpp:226] conv4 needs backward computation.
I0523 20:22:32.063908  3749 net.cpp:226] pool3 needs backward computation.
I0523 20:22:32.063920  3749 net.cpp:226] relu3 needs backward computation.
I0523 20:22:32.063930  3749 net.cpp:226] conv3 needs backward computation.
I0523 20:22:32.063947  3749 net.cpp:226] pool2 needs backward computation.
I0523 20:22:32.063959  3749 net.cpp:226] relu2 needs backward computation.
I0523 20:22:32.063969  3749 net.cpp:226] conv2 needs backward computation.
I0523 20:22:32.063980  3749 net.cpp:226] pool1 needs backward computation.
I0523 20:22:32.063990  3749 net.cpp:226] relu1 needs backward computation.
I0523 20:22:32.064002  3749 net.cpp:226] conv1 needs backward computation.
I0523 20:22:32.064013  3749 net.cpp:228] data_hdf5 does not need backward computation.
I0523 20:22:32.064021  3749 net.cpp:270] This network produces output loss
I0523 20:22:32.064046  3749 net.cpp:283] Network initialization done.
I0523 20:22:32.065778  3749 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131.prototxt
I0523 20:22:32.065848  3749 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 20:22:32.066205  3749 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 60
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 20:22:32.066392  3749 layer_factory.hpp:77] Creating layer data_hdf5
I0523 20:22:32.066408  3749 net.cpp:106] Creating Layer data_hdf5
I0523 20:22:32.066421  3749 net.cpp:411] data_hdf5 -> data
I0523 20:22:32.066437  3749 net.cpp:411] data_hdf5 -> label
I0523 20:22:32.066452  3749 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 20:22:32.067755  3749 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 20:22:53.377832  3749 net.cpp:150] Setting up data_hdf5
I0523 20:22:53.377995  3749 net.cpp:157] Top shape: 60 1 127 50 (381000)
I0523 20:22:53.378010  3749 net.cpp:157] Top shape: 60 (60)
I0523 20:22:53.378021  3749 net.cpp:165] Memory required for data: 1524240
I0523 20:22:53.378033  3749 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 20:22:53.378062  3749 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 20:22:53.378073  3749 net.cpp:454] label_data_hdf5_1_split <- label
I0523 20:22:53.378088  3749 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 20:22:53.378110  3749 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 20:22:53.378181  3749 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 20:22:53.378196  3749 net.cpp:157] Top shape: 60 (60)
I0523 20:22:53.378207  3749 net.cpp:157] Top shape: 60 (60)
I0523 20:22:53.378216  3749 net.cpp:165] Memory required for data: 1524720
I0523 20:22:53.378226  3749 layer_factory.hpp:77] Creating layer conv1
I0523 20:22:53.378248  3749 net.cpp:106] Creating Layer conv1
I0523 20:22:53.378259  3749 net.cpp:454] conv1 <- data
I0523 20:22:53.378273  3749 net.cpp:411] conv1 -> conv1
I0523 20:22:53.380228  3749 net.cpp:150] Setting up conv1
I0523 20:22:53.380252  3749 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:22:53.380264  3749 net.cpp:165] Memory required for data: 18113520
I0523 20:22:53.380285  3749 layer_factory.hpp:77] Creating layer relu1
I0523 20:22:53.380300  3749 net.cpp:106] Creating Layer relu1
I0523 20:22:53.380311  3749 net.cpp:454] relu1 <- conv1
I0523 20:22:53.380323  3749 net.cpp:397] relu1 -> conv1 (in-place)
I0523 20:22:53.380817  3749 net.cpp:150] Setting up relu1
I0523 20:22:53.380834  3749 net.cpp:157] Top shape: 60 12 120 48 (4147200)
I0523 20:22:53.380844  3749 net.cpp:165] Memory required for data: 34702320
I0523 20:22:53.380854  3749 layer_factory.hpp:77] Creating layer pool1
I0523 20:22:53.380870  3749 net.cpp:106] Creating Layer pool1
I0523 20:22:53.380880  3749 net.cpp:454] pool1 <- conv1
I0523 20:22:53.380894  3749 net.cpp:411] pool1 -> pool1
I0523 20:22:53.380969  3749 net.cpp:150] Setting up pool1
I0523 20:22:53.380981  3749 net.cpp:157] Top shape: 60 12 60 48 (2073600)
I0523 20:22:53.380990  3749 net.cpp:165] Memory required for data: 42996720
I0523 20:22:53.380998  3749 layer_factory.hpp:77] Creating layer conv2
I0523 20:22:53.381017  3749 net.cpp:106] Creating Layer conv2
I0523 20:22:53.381027  3749 net.cpp:454] conv2 <- pool1
I0523 20:22:53.381042  3749 net.cpp:411] conv2 -> conv2
I0523 20:22:53.382942  3749 net.cpp:150] Setting up conv2
I0523 20:22:53.382964  3749 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:22:53.382977  3749 net.cpp:165] Memory required for data: 54919920
I0523 20:22:53.382994  3749 layer_factory.hpp:77] Creating layer relu2
I0523 20:22:53.383008  3749 net.cpp:106] Creating Layer relu2
I0523 20:22:53.383018  3749 net.cpp:454] relu2 <- conv2
I0523 20:22:53.383029  3749 net.cpp:397] relu2 -> conv2 (in-place)
I0523 20:22:53.383368  3749 net.cpp:150] Setting up relu2
I0523 20:22:53.383383  3749 net.cpp:157] Top shape: 60 20 54 46 (2980800)
I0523 20:22:53.383393  3749 net.cpp:165] Memory required for data: 66843120
I0523 20:22:53.383402  3749 layer_factory.hpp:77] Creating layer pool2
I0523 20:22:53.383414  3749 net.cpp:106] Creating Layer pool2
I0523 20:22:53.383425  3749 net.cpp:454] pool2 <- conv2
I0523 20:22:53.383437  3749 net.cpp:411] pool2 -> pool2
I0523 20:22:53.383508  3749 net.cpp:150] Setting up pool2
I0523 20:22:53.383522  3749 net.cpp:157] Top shape: 60 20 27 46 (1490400)
I0523 20:22:53.383532  3749 net.cpp:165] Memory required for data: 72804720
I0523 20:22:53.383541  3749 layer_factory.hpp:77] Creating layer conv3
I0523 20:22:53.383560  3749 net.cpp:106] Creating Layer conv3
I0523 20:22:53.383571  3749 net.cpp:454] conv3 <- pool2
I0523 20:22:53.383585  3749 net.cpp:411] conv3 -> conv3
I0523 20:22:53.385550  3749 net.cpp:150] Setting up conv3
I0523 20:22:53.385573  3749 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:22:53.385584  3749 net.cpp:165] Memory required for data: 79309680
I0523 20:22:53.385617  3749 layer_factory.hpp:77] Creating layer relu3
I0523 20:22:53.385630  3749 net.cpp:106] Creating Layer relu3
I0523 20:22:53.385642  3749 net.cpp:454] relu3 <- conv3
I0523 20:22:53.385654  3749 net.cpp:397] relu3 -> conv3 (in-place)
I0523 20:22:53.386122  3749 net.cpp:150] Setting up relu3
I0523 20:22:53.386138  3749 net.cpp:157] Top shape: 60 28 22 44 (1626240)
I0523 20:22:53.386148  3749 net.cpp:165] Memory required for data: 85814640
I0523 20:22:53.386158  3749 layer_factory.hpp:77] Creating layer pool3
I0523 20:22:53.386173  3749 net.cpp:106] Creating Layer pool3
I0523 20:22:53.386181  3749 net.cpp:454] pool3 <- conv3
I0523 20:22:53.386194  3749 net.cpp:411] pool3 -> pool3
I0523 20:22:53.386266  3749 net.cpp:150] Setting up pool3
I0523 20:22:53.386279  3749 net.cpp:157] Top shape: 60 28 11 44 (813120)
I0523 20:22:53.386289  3749 net.cpp:165] Memory required for data: 89067120
I0523 20:22:53.386298  3749 layer_factory.hpp:77] Creating layer conv4
I0523 20:22:53.386317  3749 net.cpp:106] Creating Layer conv4
I0523 20:22:53.386327  3749 net.cpp:454] conv4 <- pool3
I0523 20:22:53.386342  3749 net.cpp:411] conv4 -> conv4
I0523 20:22:53.388404  3749 net.cpp:150] Setting up conv4
I0523 20:22:53.388425  3749 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:22:53.388439  3749 net.cpp:165] Memory required for data: 91244400
I0523 20:22:53.388454  3749 layer_factory.hpp:77] Creating layer relu4
I0523 20:22:53.388468  3749 net.cpp:106] Creating Layer relu4
I0523 20:22:53.388478  3749 net.cpp:454] relu4 <- conv4
I0523 20:22:53.388490  3749 net.cpp:397] relu4 -> conv4 (in-place)
I0523 20:22:53.388958  3749 net.cpp:150] Setting up relu4
I0523 20:22:53.388975  3749 net.cpp:157] Top shape: 60 36 6 42 (544320)
I0523 20:22:53.388985  3749 net.cpp:165] Memory required for data: 93421680
I0523 20:22:53.388995  3749 layer_factory.hpp:77] Creating layer pool4
I0523 20:22:53.389009  3749 net.cpp:106] Creating Layer pool4
I0523 20:22:53.389019  3749 net.cpp:454] pool4 <- conv4
I0523 20:22:53.389031  3749 net.cpp:411] pool4 -> pool4
I0523 20:22:53.389103  3749 net.cpp:150] Setting up pool4
I0523 20:22:53.389117  3749 net.cpp:157] Top shape: 60 36 3 42 (272160)
I0523 20:22:53.389125  3749 net.cpp:165] Memory required for data: 94510320
I0523 20:22:53.389135  3749 layer_factory.hpp:77] Creating layer ip1
I0523 20:22:53.389150  3749 net.cpp:106] Creating Layer ip1
I0523 20:22:53.389161  3749 net.cpp:454] ip1 <- pool4
I0523 20:22:53.389174  3749 net.cpp:411] ip1 -> ip1
I0523 20:22:53.404599  3749 net.cpp:150] Setting up ip1
I0523 20:22:53.404628  3749 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:22:53.404644  3749 net.cpp:165] Memory required for data: 94557360
I0523 20:22:53.404671  3749 layer_factory.hpp:77] Creating layer relu5
I0523 20:22:53.404686  3749 net.cpp:106] Creating Layer relu5
I0523 20:22:53.404697  3749 net.cpp:454] relu5 <- ip1
I0523 20:22:53.404711  3749 net.cpp:397] relu5 -> ip1 (in-place)
I0523 20:22:53.405058  3749 net.cpp:150] Setting up relu5
I0523 20:22:53.405072  3749 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:22:53.405082  3749 net.cpp:165] Memory required for data: 94604400
I0523 20:22:53.405092  3749 layer_factory.hpp:77] Creating layer drop1
I0523 20:22:53.405110  3749 net.cpp:106] Creating Layer drop1
I0523 20:22:53.405120  3749 net.cpp:454] drop1 <- ip1
I0523 20:22:53.405133  3749 net.cpp:397] drop1 -> ip1 (in-place)
I0523 20:22:53.405179  3749 net.cpp:150] Setting up drop1
I0523 20:22:53.405191  3749 net.cpp:157] Top shape: 60 196 (11760)
I0523 20:22:53.405201  3749 net.cpp:165] Memory required for data: 94651440
I0523 20:22:53.405210  3749 layer_factory.hpp:77] Creating layer ip2
I0523 20:22:53.405225  3749 net.cpp:106] Creating Layer ip2
I0523 20:22:53.405235  3749 net.cpp:454] ip2 <- ip1
I0523 20:22:53.405248  3749 net.cpp:411] ip2 -> ip2
I0523 20:22:53.405726  3749 net.cpp:150] Setting up ip2
I0523 20:22:53.405740  3749 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:22:53.405750  3749 net.cpp:165] Memory required for data: 94674960
I0523 20:22:53.405766  3749 layer_factory.hpp:77] Creating layer relu6
I0523 20:22:53.405791  3749 net.cpp:106] Creating Layer relu6
I0523 20:22:53.405800  3749 net.cpp:454] relu6 <- ip2
I0523 20:22:53.405813  3749 net.cpp:397] relu6 -> ip2 (in-place)
I0523 20:22:53.406350  3749 net.cpp:150] Setting up relu6
I0523 20:22:53.406373  3749 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:22:53.406381  3749 net.cpp:165] Memory required for data: 94698480
I0523 20:22:53.406393  3749 layer_factory.hpp:77] Creating layer drop2
I0523 20:22:53.406405  3749 net.cpp:106] Creating Layer drop2
I0523 20:22:53.406415  3749 net.cpp:454] drop2 <- ip2
I0523 20:22:53.406429  3749 net.cpp:397] drop2 -> ip2 (in-place)
I0523 20:22:53.406472  3749 net.cpp:150] Setting up drop2
I0523 20:22:53.406486  3749 net.cpp:157] Top shape: 60 98 (5880)
I0523 20:22:53.406496  3749 net.cpp:165] Memory required for data: 94722000
I0523 20:22:53.406505  3749 layer_factory.hpp:77] Creating layer ip3
I0523 20:22:53.406518  3749 net.cpp:106] Creating Layer ip3
I0523 20:22:53.406528  3749 net.cpp:454] ip3 <- ip2
I0523 20:22:53.406543  3749 net.cpp:411] ip3 -> ip3
I0523 20:22:53.406764  3749 net.cpp:150] Setting up ip3
I0523 20:22:53.406777  3749 net.cpp:157] Top shape: 60 11 (660)
I0523 20:22:53.406786  3749 net.cpp:165] Memory required for data: 94724640
I0523 20:22:53.406801  3749 layer_factory.hpp:77] Creating layer drop3
I0523 20:22:53.406815  3749 net.cpp:106] Creating Layer drop3
I0523 20:22:53.406824  3749 net.cpp:454] drop3 <- ip3
I0523 20:22:53.406837  3749 net.cpp:397] drop3 -> ip3 (in-place)
I0523 20:22:53.406879  3749 net.cpp:150] Setting up drop3
I0523 20:22:53.406891  3749 net.cpp:157] Top shape: 60 11 (660)
I0523 20:22:53.406901  3749 net.cpp:165] Memory required for data: 94727280
I0523 20:22:53.406911  3749 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 20:22:53.406924  3749 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 20:22:53.406934  3749 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 20:22:53.406946  3749 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 20:22:53.406961  3749 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 20:22:53.407035  3749 net.cpp:150] Setting up ip3_drop3_0_split
I0523 20:22:53.407049  3749 net.cpp:157] Top shape: 60 11 (660)
I0523 20:22:53.407061  3749 net.cpp:157] Top shape: 60 11 (660)
I0523 20:22:53.407071  3749 net.cpp:165] Memory required for data: 94732560
I0523 20:22:53.407081  3749 layer_factory.hpp:77] Creating layer accuracy
I0523 20:22:53.407102  3749 net.cpp:106] Creating Layer accuracy
I0523 20:22:53.407112  3749 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 20:22:53.407124  3749 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 20:22:53.407137  3749 net.cpp:411] accuracy -> accuracy
I0523 20:22:53.407161  3749 net.cpp:150] Setting up accuracy
I0523 20:22:53.407173  3749 net.cpp:157] Top shape: (1)
I0523 20:22:53.407191  3749 net.cpp:165] Memory required for data: 94732564
I0523 20:22:53.407202  3749 layer_factory.hpp:77] Creating layer loss
I0523 20:22:53.407217  3749 net.cpp:106] Creating Layer loss
I0523 20:22:53.407227  3749 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 20:22:53.407237  3749 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 20:22:53.407250  3749 net.cpp:411] loss -> loss
I0523 20:22:53.407269  3749 layer_factory.hpp:77] Creating layer loss
I0523 20:22:53.407757  3749 net.cpp:150] Setting up loss
I0523 20:22:53.407770  3749 net.cpp:157] Top shape: (1)
I0523 20:22:53.407779  3749 net.cpp:160]     with loss weight 1
I0523 20:22:53.407799  3749 net.cpp:165] Memory required for data: 94732568
I0523 20:22:53.407809  3749 net.cpp:226] loss needs backward computation.
I0523 20:22:53.407819  3749 net.cpp:228] accuracy does not need backward computation.
I0523 20:22:53.407830  3749 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 20:22:53.407841  3749 net.cpp:226] drop3 needs backward computation.
I0523 20:22:53.407850  3749 net.cpp:226] ip3 needs backward computation.
I0523 20:22:53.407860  3749 net.cpp:226] drop2 needs backward computation.
I0523 20:22:53.407871  3749 net.cpp:226] relu6 needs backward computation.
I0523 20:22:53.407888  3749 net.cpp:226] ip2 needs backward computation.
I0523 20:22:53.407898  3749 net.cpp:226] drop1 needs backward computation.
I0523 20:22:53.407908  3749 net.cpp:226] relu5 needs backward computation.
I0523 20:22:53.407918  3749 net.cpp:226] ip1 needs backward computation.
I0523 20:22:53.407928  3749 net.cpp:226] pool4 needs backward computation.
I0523 20:22:53.407938  3749 net.cpp:226] relu4 needs backward computation.
I0523 20:22:53.407949  3749 net.cpp:226] conv4 needs backward computation.
I0523 20:22:53.407959  3749 net.cpp:226] pool3 needs backward computation.
I0523 20:22:53.407970  3749 net.cpp:226] relu3 needs backward computation.
I0523 20:22:53.407980  3749 net.cpp:226] conv3 needs backward computation.
I0523 20:22:53.407990  3749 net.cpp:226] pool2 needs backward computation.
I0523 20:22:53.408001  3749 net.cpp:226] relu2 needs backward computation.
I0523 20:22:53.408010  3749 net.cpp:226] conv2 needs backward computation.
I0523 20:22:53.408020  3749 net.cpp:226] pool1 needs backward computation.
I0523 20:22:53.408031  3749 net.cpp:226] relu1 needs backward computation.
I0523 20:22:53.408041  3749 net.cpp:226] conv1 needs backward computation.
I0523 20:22:53.408053  3749 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 20:22:53.408064  3749 net.cpp:228] data_hdf5 does not need backward computation.
I0523 20:22:53.408076  3749 net.cpp:270] This network produces output accuracy
I0523 20:22:53.408085  3749 net.cpp:270] This network produces output loss
I0523 20:22:53.408114  3749 net.cpp:283] Network initialization done.
I0523 20:22:53.408248  3749 solver.cpp:60] Solver scaffolding done.
I0523 20:22:53.409378  3749 caffe.cpp:212] Starting Optimization
I0523 20:22:53.409390  3749 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 20:22:53.409404  3749 solver.cpp:289] Learning Rate Policy: fixed
I0523 20:22:53.410621  3749 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 20:23:41.541892  3749 solver.cpp:409]     Test net output #0: accuracy = 0.106867
I0523 20:23:41.542052  3749 solver.cpp:409]     Test net output #1: loss = 2.39699 (* 1 = 2.39699 loss)
I0523 20:23:41.567981  3749 solver.cpp:237] Iteration 0, loss = 2.39873
I0523 20:23:41.568017  3749 solver.cpp:253]     Train net output #0: loss = 2.39873 (* 1 = 2.39873 loss)
I0523 20:23:41.568037  3749 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0523 20:23:50.663301  3749 solver.cpp:237] Iteration 250, loss = 2.02878
I0523 20:23:50.663348  3749 solver.cpp:253]     Train net output #0: loss = 2.02878 (* 1 = 2.02878 loss)
I0523 20:23:50.663367  3749 sgd_solver.cpp:106] Iteration 250, lr = 0.005
I0523 20:23:59.753111  3749 solver.cpp:237] Iteration 500, loss = 2.1186
I0523 20:23:59.753147  3749 solver.cpp:253]     Train net output #0: loss = 2.1186 (* 1 = 2.1186 loss)
I0523 20:23:59.753163  3749 sgd_solver.cpp:106] Iteration 500, lr = 0.005
I0523 20:24:08.846211  3749 solver.cpp:237] Iteration 750, loss = 2.01388
I0523 20:24:08.846247  3749 solver.cpp:253]     Train net output #0: loss = 2.01388 (* 1 = 2.01388 loss)
I0523 20:24:08.846261  3749 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0523 20:24:17.943114  3749 solver.cpp:237] Iteration 1000, loss = 1.74759
I0523 20:24:17.943279  3749 solver.cpp:253]     Train net output #0: loss = 1.74759 (* 1 = 1.74759 loss)
I0523 20:24:17.943295  3749 sgd_solver.cpp:106] Iteration 1000, lr = 0.005
I0523 20:24:27.037361  3749 solver.cpp:237] Iteration 1250, loss = 1.85604
I0523 20:24:27.037396  3749 solver.cpp:253]     Train net output #0: loss = 1.85604 (* 1 = 1.85604 loss)
I0523 20:24:27.037413  3749 sgd_solver.cpp:106] Iteration 1250, lr = 0.005
I0523 20:24:36.131098  3749 solver.cpp:237] Iteration 1500, loss = 1.65466
I0523 20:24:36.131146  3749 solver.cpp:253]     Train net output #0: loss = 1.65466 (* 1 = 1.65466 loss)
I0523 20:24:36.131161  3749 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0523 20:25:07.272881  3749 solver.cpp:237] Iteration 1750, loss = 1.66591
I0523 20:25:07.273041  3749 solver.cpp:253]     Train net output #0: loss = 1.66591 (* 1 = 1.66591 loss)
I0523 20:25:07.273056  3749 sgd_solver.cpp:106] Iteration 1750, lr = 0.005
I0523 20:25:16.369716  3749 solver.cpp:237] Iteration 2000, loss = 1.3714
I0523 20:25:16.369751  3749 solver.cpp:253]     Train net output #0: loss = 1.3714 (* 1 = 1.3714 loss)
I0523 20:25:16.369768  3749 sgd_solver.cpp:106] Iteration 2000, lr = 0.005
I0523 20:25:25.469656  3749 solver.cpp:237] Iteration 2250, loss = 1.73783
I0523 20:25:25.469707  3749 solver.cpp:253]     Train net output #0: loss = 1.73783 (* 1 = 1.73783 loss)
I0523 20:25:25.469723  3749 sgd_solver.cpp:106] Iteration 2250, lr = 0.005
I0523 20:25:34.534396  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_2500.caffemodel
I0523 20:25:34.600591  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_2500.solverstate
I0523 20:25:34.636989  3749 solver.cpp:237] Iteration 2500, loss = 1.49756
I0523 20:25:34.637034  3749 solver.cpp:253]     Train net output #0: loss = 1.49756 (* 1 = 1.49756 loss)
I0523 20:25:34.637048  3749 sgd_solver.cpp:106] Iteration 2500, lr = 0.005
I0523 20:25:43.737642  3749 solver.cpp:237] Iteration 2750, loss = 1.66915
I0523 20:25:43.737783  3749 solver.cpp:253]     Train net output #0: loss = 1.66915 (* 1 = 1.66915 loss)
I0523 20:25:43.737797  3749 sgd_solver.cpp:106] Iteration 2750, lr = 0.005
I0523 20:25:52.842682  3749 solver.cpp:237] Iteration 3000, loss = 1.37419
I0523 20:25:52.842730  3749 solver.cpp:253]     Train net output #0: loss = 1.37419 (* 1 = 1.37419 loss)
I0523 20:25:52.842746  3749 sgd_solver.cpp:106] Iteration 3000, lr = 0.005
I0523 20:26:01.948415  3749 solver.cpp:237] Iteration 3250, loss = 1.5753
I0523 20:26:01.948451  3749 solver.cpp:253]     Train net output #0: loss = 1.5753 (* 1 = 1.5753 loss)
I0523 20:26:01.948467  3749 sgd_solver.cpp:106] Iteration 3250, lr = 0.005
I0523 20:26:33.114392  3749 solver.cpp:237] Iteration 3500, loss = 1.44575
I0523 20:26:33.114548  3749 solver.cpp:253]     Train net output #0: loss = 1.44575 (* 1 = 1.44575 loss)
I0523 20:26:33.114562  3749 sgd_solver.cpp:106] Iteration 3500, lr = 0.005
I0523 20:26:42.221595  3749 solver.cpp:237] Iteration 3750, loss = 1.29533
I0523 20:26:42.221642  3749 solver.cpp:253]     Train net output #0: loss = 1.29533 (* 1 = 1.29533 loss)
I0523 20:26:42.221659  3749 sgd_solver.cpp:106] Iteration 3750, lr = 0.005
I0523 20:26:51.323693  3749 solver.cpp:237] Iteration 4000, loss = 1.72745
I0523 20:26:51.323729  3749 solver.cpp:253]     Train net output #0: loss = 1.72745 (* 1 = 1.72745 loss)
I0523 20:26:51.323745  3749 sgd_solver.cpp:106] Iteration 4000, lr = 0.005
I0523 20:27:00.426991  3749 solver.cpp:237] Iteration 4250, loss = 1.20396
I0523 20:27:00.427028  3749 solver.cpp:253]     Train net output #0: loss = 1.20396 (* 1 = 1.20396 loss)
I0523 20:27:00.427044  3749 sgd_solver.cpp:106] Iteration 4250, lr = 0.005
I0523 20:27:09.521770  3749 solver.cpp:237] Iteration 4500, loss = 1.27767
I0523 20:27:09.521924  3749 solver.cpp:253]     Train net output #0: loss = 1.27767 (* 1 = 1.27767 loss)
I0523 20:27:09.521937  3749 sgd_solver.cpp:106] Iteration 4500, lr = 0.005
I0523 20:27:18.615931  3749 solver.cpp:237] Iteration 4750, loss = 1.36904
I0523 20:27:18.615965  3749 solver.cpp:253]     Train net output #0: loss = 1.36904 (* 1 = 1.36904 loss)
I0523 20:27:18.615983  3749 sgd_solver.cpp:106] Iteration 4750, lr = 0.005
I0523 20:27:27.676920  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_5000.caffemodel
I0523 20:27:27.740187  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_5000.solverstate
I0523 20:27:27.765532  3749 solver.cpp:341] Iteration 5000, Testing net (#0)
I0523 20:28:14.957967  3749 solver.cpp:409]     Test net output #0: accuracy = 0.817183
I0523 20:28:14.958127  3749 solver.cpp:409]     Test net output #1: loss = 0.621691 (* 1 = 0.621691 loss)
I0523 20:28:37.005410  3749 solver.cpp:237] Iteration 5000, loss = 1.22765
I0523 20:28:37.005465  3749 solver.cpp:253]     Train net output #0: loss = 1.22765 (* 1 = 1.22765 loss)
I0523 20:28:37.005481  3749 sgd_solver.cpp:106] Iteration 5000, lr = 0.005
I0523 20:28:46.080912  3749 solver.cpp:237] Iteration 5250, loss = 1.24404
I0523 20:28:46.081063  3749 solver.cpp:253]     Train net output #0: loss = 1.24404 (* 1 = 1.24404 loss)
I0523 20:28:46.081075  3749 sgd_solver.cpp:106] Iteration 5250, lr = 0.005
I0523 20:28:55.158133  3749 solver.cpp:237] Iteration 5500, loss = 1.60366
I0523 20:28:55.158167  3749 solver.cpp:253]     Train net output #0: loss = 1.60366 (* 1 = 1.60366 loss)
I0523 20:28:55.158184  3749 sgd_solver.cpp:106] Iteration 5500, lr = 0.005
I0523 20:29:04.229936  3749 solver.cpp:237] Iteration 5750, loss = 1.42304
I0523 20:29:04.229971  3749 solver.cpp:253]     Train net output #0: loss = 1.42304 (* 1 = 1.42304 loss)
I0523 20:29:04.229987  3749 sgd_solver.cpp:106] Iteration 5750, lr = 0.005
I0523 20:29:13.305354  3749 solver.cpp:237] Iteration 6000, loss = 1.09507
I0523 20:29:13.305392  3749 solver.cpp:253]     Train net output #0: loss = 1.09507 (* 1 = 1.09507 loss)
I0523 20:29:13.305418  3749 sgd_solver.cpp:106] Iteration 6000, lr = 0.005
I0523 20:29:22.380492  3749 solver.cpp:237] Iteration 6250, loss = 1.41905
I0523 20:29:22.380623  3749 solver.cpp:253]     Train net output #0: loss = 1.41905 (* 1 = 1.41905 loss)
I0523 20:29:22.380637  3749 sgd_solver.cpp:106] Iteration 6250, lr = 0.005
I0523 20:29:31.451372  3749 solver.cpp:237] Iteration 6500, loss = 1.29786
I0523 20:29:31.451407  3749 solver.cpp:253]     Train net output #0: loss = 1.29786 (* 1 = 1.29786 loss)
I0523 20:29:31.451424  3749 sgd_solver.cpp:106] Iteration 6500, lr = 0.005
I0523 20:30:02.590796  3749 solver.cpp:237] Iteration 6750, loss = 1.55997
I0523 20:30:02.590953  3749 solver.cpp:253]     Train net output #0: loss = 1.55997 (* 1 = 1.55997 loss)
I0523 20:30:02.590968  3749 sgd_solver.cpp:106] Iteration 6750, lr = 0.005
I0523 20:30:11.662984  3749 solver.cpp:237] Iteration 7000, loss = 1.14938
I0523 20:30:11.663019  3749 solver.cpp:253]     Train net output #0: loss = 1.14938 (* 1 = 1.14938 loss)
I0523 20:30:11.663038  3749 sgd_solver.cpp:106] Iteration 7000, lr = 0.005
I0523 20:30:20.738922  3749 solver.cpp:237] Iteration 7250, loss = 1.24919
I0523 20:30:20.738958  3749 solver.cpp:253]     Train net output #0: loss = 1.24919 (* 1 = 1.24919 loss)
I0523 20:30:20.738971  3749 sgd_solver.cpp:106] Iteration 7250, lr = 0.005
I0523 20:30:29.774845  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_7500.caffemodel
I0523 20:30:29.840811  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_7500.solverstate
I0523 20:30:29.879928  3749 solver.cpp:237] Iteration 7500, loss = 1.26824
I0523 20:30:29.879977  3749 solver.cpp:253]     Train net output #0: loss = 1.26824 (* 1 = 1.26824 loss)
I0523 20:30:29.879992  3749 sgd_solver.cpp:106] Iteration 7500, lr = 0.005
I0523 20:30:38.957180  3749 solver.cpp:237] Iteration 7750, loss = 1.1491
I0523 20:30:38.957330  3749 solver.cpp:253]     Train net output #0: loss = 1.1491 (* 1 = 1.1491 loss)
I0523 20:30:38.957343  3749 sgd_solver.cpp:106] Iteration 7750, lr = 0.005
I0523 20:30:48.036288  3749 solver.cpp:237] Iteration 8000, loss = 1.38646
I0523 20:30:48.036322  3749 solver.cpp:253]     Train net output #0: loss = 1.38646 (* 1 = 1.38646 loss)
I0523 20:30:48.036339  3749 sgd_solver.cpp:106] Iteration 8000, lr = 0.005
I0523 20:30:57.106246  3749 solver.cpp:237] Iteration 8250, loss = 1.23986
I0523 20:30:57.106294  3749 solver.cpp:253]     Train net output #0: loss = 1.23986 (* 1 = 1.23986 loss)
I0523 20:30:57.106312  3749 sgd_solver.cpp:106] Iteration 8250, lr = 0.005
I0523 20:31:28.244336  3749 solver.cpp:237] Iteration 8500, loss = 1.44887
I0523 20:31:28.244493  3749 solver.cpp:253]     Train net output #0: loss = 1.44887 (* 1 = 1.44887 loss)
I0523 20:31:28.244508  3749 sgd_solver.cpp:106] Iteration 8500, lr = 0.005
I0523 20:31:37.315785  3749 solver.cpp:237] Iteration 8750, loss = 1.23676
I0523 20:31:37.315820  3749 solver.cpp:253]     Train net output #0: loss = 1.23676 (* 1 = 1.23676 loss)
I0523 20:31:37.315834  3749 sgd_solver.cpp:106] Iteration 8750, lr = 0.005
I0523 20:31:46.396050  3749 solver.cpp:237] Iteration 9000, loss = 1.16706
I0523 20:31:46.396090  3749 solver.cpp:253]     Train net output #0: loss = 1.16706 (* 1 = 1.16706 loss)
I0523 20:31:46.396107  3749 sgd_solver.cpp:106] Iteration 9000, lr = 0.005
I0523 20:31:55.462505  3749 solver.cpp:237] Iteration 9250, loss = 1.20912
I0523 20:31:55.462540  3749 solver.cpp:253]     Train net output #0: loss = 1.20912 (* 1 = 1.20912 loss)
I0523 20:31:55.462558  3749 sgd_solver.cpp:106] Iteration 9250, lr = 0.005
I0523 20:32:04.539408  3749 solver.cpp:237] Iteration 9500, loss = 1.3807
I0523 20:32:04.539553  3749 solver.cpp:253]     Train net output #0: loss = 1.3807 (* 1 = 1.3807 loss)
I0523 20:32:04.539566  3749 sgd_solver.cpp:106] Iteration 9500, lr = 0.005
I0523 20:32:13.620825  3749 solver.cpp:237] Iteration 9750, loss = 1.2153
I0523 20:32:13.620859  3749 solver.cpp:253]     Train net output #0: loss = 1.2153 (* 1 = 1.2153 loss)
I0523 20:32:13.620879  3749 sgd_solver.cpp:106] Iteration 9750, lr = 0.005
I0523 20:32:22.656704  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_10000.caffemodel
I0523 20:32:22.721593  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_10000.solverstate
I0523 20:32:22.749171  3749 solver.cpp:341] Iteration 10000, Testing net (#0)
I0523 20:33:30.686226  3749 solver.cpp:409]     Test net output #0: accuracy = 0.834188
I0523 20:33:30.686383  3749 solver.cpp:409]     Test net output #1: loss = 0.551591 (* 1 = 0.551591 loss)
I0523 20:33:52.819243  3749 solver.cpp:237] Iteration 10000, loss = 1.24701
I0523 20:33:52.819294  3749 solver.cpp:253]     Train net output #0: loss = 1.24701 (* 1 = 1.24701 loss)
I0523 20:33:52.819313  3749 sgd_solver.cpp:106] Iteration 10000, lr = 0.005
I0523 20:34:01.926589  3749 solver.cpp:237] Iteration 10250, loss = 1.1192
I0523 20:34:01.926740  3749 solver.cpp:253]     Train net output #0: loss = 1.1192 (* 1 = 1.1192 loss)
I0523 20:34:01.926754  3749 sgd_solver.cpp:106] Iteration 10250, lr = 0.005
I0523 20:34:11.035667  3749 solver.cpp:237] Iteration 10500, loss = 1.50451
I0523 20:34:11.035717  3749 solver.cpp:253]     Train net output #0: loss = 1.50451 (* 1 = 1.50451 loss)
I0523 20:34:11.035732  3749 sgd_solver.cpp:106] Iteration 10500, lr = 0.005
I0523 20:34:20.152007  3749 solver.cpp:237] Iteration 10750, loss = 1.29402
I0523 20:34:20.152042  3749 solver.cpp:253]     Train net output #0: loss = 1.29402 (* 1 = 1.29402 loss)
I0523 20:34:20.152060  3749 sgd_solver.cpp:106] Iteration 10750, lr = 0.005
I0523 20:34:29.268820  3749 solver.cpp:237] Iteration 11000, loss = 1.37783
I0523 20:34:29.268854  3749 solver.cpp:253]     Train net output #0: loss = 1.37783 (* 1 = 1.37783 loss)
I0523 20:34:29.268870  3749 sgd_solver.cpp:106] Iteration 11000, lr = 0.005
I0523 20:34:38.379026  3749 solver.cpp:237] Iteration 11250, loss = 1.44795
I0523 20:34:38.379175  3749 solver.cpp:253]     Train net output #0: loss = 1.44795 (* 1 = 1.44795 loss)
I0523 20:34:38.379195  3749 sgd_solver.cpp:106] Iteration 11250, lr = 0.005
I0523 20:34:47.487646  3749 solver.cpp:237] Iteration 11500, loss = 1.32985
I0523 20:34:47.487681  3749 solver.cpp:253]     Train net output #0: loss = 1.32985 (* 1 = 1.32985 loss)
I0523 20:34:47.487695  3749 sgd_solver.cpp:106] Iteration 11500, lr = 0.005
I0523 20:35:18.756225  3749 solver.cpp:237] Iteration 11750, loss = 1.03063
I0523 20:35:18.756386  3749 solver.cpp:253]     Train net output #0: loss = 1.03063 (* 1 = 1.03063 loss)
I0523 20:35:18.756400  3749 sgd_solver.cpp:106] Iteration 11750, lr = 0.005
I0523 20:35:27.881556  3749 solver.cpp:237] Iteration 12000, loss = 1.26613
I0523 20:35:27.881600  3749 solver.cpp:253]     Train net output #0: loss = 1.26613 (* 1 = 1.26613 loss)
I0523 20:35:27.881618  3749 sgd_solver.cpp:106] Iteration 12000, lr = 0.005
I0523 20:35:37.005458  3749 solver.cpp:237] Iteration 12250, loss = 1.19477
I0523 20:35:37.005496  3749 solver.cpp:253]     Train net output #0: loss = 1.19477 (* 1 = 1.19477 loss)
I0523 20:35:37.005511  3749 sgd_solver.cpp:106] Iteration 12250, lr = 0.005
I0523 20:35:46.078441  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_12500.caffemodel
I0523 20:35:46.143780  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_12500.solverstate
I0523 20:35:46.182680  3749 solver.cpp:237] Iteration 12500, loss = 1.22095
I0523 20:35:46.182731  3749 solver.cpp:253]     Train net output #0: loss = 1.22095 (* 1 = 1.22095 loss)
I0523 20:35:46.182746  3749 sgd_solver.cpp:106] Iteration 12500, lr = 0.005
I0523 20:35:55.302369  3749 solver.cpp:237] Iteration 12750, loss = 1.13211
I0523 20:35:55.302533  3749 solver.cpp:253]     Train net output #0: loss = 1.13211 (* 1 = 1.13211 loss)
I0523 20:35:55.302548  3749 sgd_solver.cpp:106] Iteration 12750, lr = 0.005
I0523 20:36:04.410760  3749 solver.cpp:237] Iteration 13000, loss = 1.1016
I0523 20:36:04.410796  3749 solver.cpp:253]     Train net output #0: loss = 1.1016 (* 1 = 1.1016 loss)
I0523 20:36:04.410811  3749 sgd_solver.cpp:106] Iteration 13000, lr = 0.005
I0523 20:36:13.528118  3749 solver.cpp:237] Iteration 13250, loss = 1.41676
I0523 20:36:13.528154  3749 solver.cpp:253]     Train net output #0: loss = 1.41676 (* 1 = 1.41676 loss)
I0523 20:36:13.528170  3749 sgd_solver.cpp:106] Iteration 13250, lr = 0.005
I0523 20:36:44.766551  3749 solver.cpp:237] Iteration 13500, loss = 1.29906
I0523 20:36:44.766726  3749 solver.cpp:253]     Train net output #0: loss = 1.29906 (* 1 = 1.29906 loss)
I0523 20:36:44.766741  3749 sgd_solver.cpp:106] Iteration 13500, lr = 0.005
I0523 20:36:53.871791  3749 solver.cpp:237] Iteration 13750, loss = 1.24769
I0523 20:36:53.871825  3749 solver.cpp:253]     Train net output #0: loss = 1.24769 (* 1 = 1.24769 loss)
I0523 20:36:53.871842  3749 sgd_solver.cpp:106] Iteration 13750, lr = 0.005
I0523 20:37:02.987870  3749 solver.cpp:237] Iteration 14000, loss = 1.35617
I0523 20:37:02.987905  3749 solver.cpp:253]     Train net output #0: loss = 1.35617 (* 1 = 1.35617 loss)
I0523 20:37:02.987923  3749 sgd_solver.cpp:106] Iteration 14000, lr = 0.005
I0523 20:37:12.104213  3749 solver.cpp:237] Iteration 14250, loss = 1.43625
I0523 20:37:12.104257  3749 solver.cpp:253]     Train net output #0: loss = 1.43625 (* 1 = 1.43625 loss)
I0523 20:37:12.104274  3749 sgd_solver.cpp:106] Iteration 14250, lr = 0.005
I0523 20:37:21.211457  3749 solver.cpp:237] Iteration 14500, loss = 1.48303
I0523 20:37:21.211604  3749 solver.cpp:253]     Train net output #0: loss = 1.48303 (* 1 = 1.48303 loss)
I0523 20:37:21.211618  3749 sgd_solver.cpp:106] Iteration 14500, lr = 0.005
I0523 20:37:30.328447  3749 solver.cpp:237] Iteration 14750, loss = 1.14854
I0523 20:37:30.328481  3749 solver.cpp:253]     Train net output #0: loss = 1.14854 (* 1 = 1.14854 loss)
I0523 20:37:30.328500  3749 sgd_solver.cpp:106] Iteration 14750, lr = 0.005
I0523 20:37:39.407088  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_15000.caffemodel
I0523 20:37:39.471223  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_15000.solverstate
I0523 20:37:39.496708  3749 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 20:38:26.393990  3749 solver.cpp:409]     Test net output #0: accuracy = 0.860501
I0523 20:38:26.394145  3749 solver.cpp:409]     Test net output #1: loss = 0.446621 (* 1 = 0.446621 loss)
I0523 20:38:48.474217  3749 solver.cpp:237] Iteration 15000, loss = 1.14128
I0523 20:38:48.474270  3749 solver.cpp:253]     Train net output #0: loss = 1.14128 (* 1 = 1.14128 loss)
I0523 20:38:48.474287  3749 sgd_solver.cpp:106] Iteration 15000, lr = 0.005
I0523 20:38:57.504297  3749 solver.cpp:237] Iteration 15250, loss = 1.10616
I0523 20:38:57.504446  3749 solver.cpp:253]     Train net output #0: loss = 1.10616 (* 1 = 1.10616 loss)
I0523 20:38:57.504459  3749 sgd_solver.cpp:106] Iteration 15250, lr = 0.005
I0523 20:39:06.534957  3749 solver.cpp:237] Iteration 15500, loss = 1.33539
I0523 20:39:06.534992  3749 solver.cpp:253]     Train net output #0: loss = 1.33539 (* 1 = 1.33539 loss)
I0523 20:39:06.535008  3749 sgd_solver.cpp:106] Iteration 15500, lr = 0.005
I0523 20:39:15.568672  3749 solver.cpp:237] Iteration 15750, loss = 1.35303
I0523 20:39:15.568718  3749 solver.cpp:253]     Train net output #0: loss = 1.35303 (* 1 = 1.35303 loss)
I0523 20:39:15.568735  3749 sgd_solver.cpp:106] Iteration 15750, lr = 0.005
I0523 20:39:24.593348  3749 solver.cpp:237] Iteration 16000, loss = 1.27187
I0523 20:39:24.593384  3749 solver.cpp:253]     Train net output #0: loss = 1.27187 (* 1 = 1.27187 loss)
I0523 20:39:24.593400  3749 sgd_solver.cpp:106] Iteration 16000, lr = 0.005
I0523 20:39:33.621506  3749 solver.cpp:237] Iteration 16250, loss = 1.34724
I0523 20:39:33.621647  3749 solver.cpp:253]     Train net output #0: loss = 1.34724 (* 1 = 1.34724 loss)
I0523 20:39:33.621661  3749 sgd_solver.cpp:106] Iteration 16250, lr = 0.005
I0523 20:39:42.648552  3749 solver.cpp:237] Iteration 16500, loss = 0.991624
I0523 20:39:42.648594  3749 solver.cpp:253]     Train net output #0: loss = 0.991624 (* 1 = 0.991624 loss)
I0523 20:39:42.648613  3749 sgd_solver.cpp:106] Iteration 16500, lr = 0.005
I0523 20:40:13.778518  3749 solver.cpp:237] Iteration 16750, loss = 1.12926
I0523 20:40:13.778693  3749 solver.cpp:253]     Train net output #0: loss = 1.12926 (* 1 = 1.12926 loss)
I0523 20:40:13.778707  3749 sgd_solver.cpp:106] Iteration 16750, lr = 0.005
I0523 20:40:22.802530  3749 solver.cpp:237] Iteration 17000, loss = 1.08108
I0523 20:40:22.802564  3749 solver.cpp:253]     Train net output #0: loss = 1.08108 (* 1 = 1.08108 loss)
I0523 20:40:22.802582  3749 sgd_solver.cpp:106] Iteration 17000, lr = 0.005
I0523 20:40:31.837568  3749 solver.cpp:237] Iteration 17250, loss = 1.33463
I0523 20:40:31.837611  3749 solver.cpp:253]     Train net output #0: loss = 1.33463 (* 1 = 1.33463 loss)
I0523 20:40:31.837630  3749 sgd_solver.cpp:106] Iteration 17250, lr = 0.005
I0523 20:40:40.827507  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_17500.caffemodel
I0523 20:40:40.890560  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_17500.solverstate
I0523 20:40:40.928199  3749 solver.cpp:237] Iteration 17500, loss = 1.03927
I0523 20:40:40.928242  3749 solver.cpp:253]     Train net output #0: loss = 1.03927 (* 1 = 1.03927 loss)
I0523 20:40:40.928257  3749 sgd_solver.cpp:106] Iteration 17500, lr = 0.005
I0523 20:40:49.955111  3749 solver.cpp:237] Iteration 17750, loss = 1.27969
I0523 20:40:49.955262  3749 solver.cpp:253]     Train net output #0: loss = 1.27969 (* 1 = 1.27969 loss)
I0523 20:40:49.955276  3749 sgd_solver.cpp:106] Iteration 17750, lr = 0.005
I0523 20:40:58.986876  3749 solver.cpp:237] Iteration 18000, loss = 1.46634
I0523 20:40:58.986919  3749 solver.cpp:253]     Train net output #0: loss = 1.46634 (* 1 = 1.46634 loss)
I0523 20:40:58.986937  3749 sgd_solver.cpp:106] Iteration 18000, lr = 0.005
I0523 20:41:08.020658  3749 solver.cpp:237] Iteration 18250, loss = 1.20168
I0523 20:41:08.020694  3749 solver.cpp:253]     Train net output #0: loss = 1.20168 (* 1 = 1.20168 loss)
I0523 20:41:08.020710  3749 sgd_solver.cpp:106] Iteration 18250, lr = 0.005
I0523 20:41:39.160866  3749 solver.cpp:237] Iteration 18500, loss = 1.15426
I0523 20:41:39.161032  3749 solver.cpp:253]     Train net output #0: loss = 1.15426 (* 1 = 1.15426 loss)
I0523 20:41:39.161047  3749 sgd_solver.cpp:106] Iteration 18500, lr = 0.005
I0523 20:41:48.193497  3749 solver.cpp:237] Iteration 18750, loss = 1.20834
I0523 20:41:48.193543  3749 solver.cpp:253]     Train net output #0: loss = 1.20834 (* 1 = 1.20834 loss)
I0523 20:41:48.193562  3749 sgd_solver.cpp:106] Iteration 18750, lr = 0.005
I0523 20:41:57.224864  3749 solver.cpp:237] Iteration 19000, loss = 1.30026
I0523 20:41:57.224900  3749 solver.cpp:253]     Train net output #0: loss = 1.30026 (* 1 = 1.30026 loss)
I0523 20:41:57.224916  3749 sgd_solver.cpp:106] Iteration 19000, lr = 0.005
I0523 20:42:06.249850  3749 solver.cpp:237] Iteration 19250, loss = 1.31447
I0523 20:42:06.249896  3749 solver.cpp:253]     Train net output #0: loss = 1.31447 (* 1 = 1.31447 loss)
I0523 20:42:06.249913  3749 sgd_solver.cpp:106] Iteration 19250, lr = 0.005
I0523 20:42:15.281716  3749 solver.cpp:237] Iteration 19500, loss = 1.16889
I0523 20:42:15.281859  3749 solver.cpp:253]     Train net output #0: loss = 1.16889 (* 1 = 1.16889 loss)
I0523 20:42:15.281873  3749 sgd_solver.cpp:106] Iteration 19500, lr = 0.005
I0523 20:42:24.314086  3749 solver.cpp:237] Iteration 19750, loss = 1.1896
I0523 20:42:24.314121  3749 solver.cpp:253]     Train net output #0: loss = 1.1896 (* 1 = 1.1896 loss)
I0523 20:42:24.314138  3749 sgd_solver.cpp:106] Iteration 19750, lr = 0.005
I0523 20:42:33.302076  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_20000.caffemodel
I0523 20:42:33.364356  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_20000.solverstate
I0523 20:42:33.390509  3749 solver.cpp:341] Iteration 20000, Testing net (#0)
I0523 20:43:41.391907  3749 solver.cpp:409]     Test net output #0: accuracy = 0.86912
I0523 20:43:41.392076  3749 solver.cpp:409]     Test net output #1: loss = 0.408839 (* 1 = 0.408839 loss)
I0523 20:44:03.519711  3749 solver.cpp:237] Iteration 20000, loss = 1.10296
I0523 20:44:03.519762  3749 solver.cpp:253]     Train net output #0: loss = 1.10296 (* 1 = 1.10296 loss)
I0523 20:44:03.519778  3749 sgd_solver.cpp:106] Iteration 20000, lr = 0.005
I0523 20:44:12.574547  3749 solver.cpp:237] Iteration 20250, loss = 1.35426
I0523 20:44:12.574707  3749 solver.cpp:253]     Train net output #0: loss = 1.35426 (* 1 = 1.35426 loss)
I0523 20:44:12.574722  3749 sgd_solver.cpp:106] Iteration 20250, lr = 0.005
I0523 20:44:21.632452  3749 solver.cpp:237] Iteration 20500, loss = 1.18212
I0523 20:44:21.632488  3749 solver.cpp:253]     Train net output #0: loss = 1.18212 (* 1 = 1.18212 loss)
I0523 20:44:21.632505  3749 sgd_solver.cpp:106] Iteration 20500, lr = 0.005
I0523 20:44:30.705788  3749 solver.cpp:237] Iteration 20750, loss = 1.04014
I0523 20:44:30.705823  3749 solver.cpp:253]     Train net output #0: loss = 1.04014 (* 1 = 1.04014 loss)
I0523 20:44:30.705839  3749 sgd_solver.cpp:106] Iteration 20750, lr = 0.005
I0523 20:44:39.764637  3749 solver.cpp:237] Iteration 21000, loss = 1.17392
I0523 20:44:39.764688  3749 solver.cpp:253]     Train net output #0: loss = 1.17392 (* 1 = 1.17392 loss)
I0523 20:44:39.764701  3749 sgd_solver.cpp:106] Iteration 21000, lr = 0.005
I0523 20:44:48.813956  3749 solver.cpp:237] Iteration 21250, loss = 1.2912
I0523 20:44:48.814097  3749 solver.cpp:253]     Train net output #0: loss = 1.2912 (* 1 = 1.2912 loss)
I0523 20:44:48.814111  3749 sgd_solver.cpp:106] Iteration 21250, lr = 0.005
I0523 20:44:57.873785  3749 solver.cpp:237] Iteration 21500, loss = 1.18992
I0523 20:44:57.873818  3749 solver.cpp:253]     Train net output #0: loss = 1.18992 (* 1 = 1.18992 loss)
I0523 20:44:57.873836  3749 sgd_solver.cpp:106] Iteration 21500, lr = 0.005
I0523 20:45:29.016875  3749 solver.cpp:237] Iteration 21750, loss = 1.44853
I0523 20:45:29.017040  3749 solver.cpp:253]     Train net output #0: loss = 1.44853 (* 1 = 1.44853 loss)
I0523 20:45:29.017055  3749 sgd_solver.cpp:106] Iteration 21750, lr = 0.005
I0523 20:45:38.068760  3749 solver.cpp:237] Iteration 22000, loss = 1.08116
I0523 20:45:38.068795  3749 solver.cpp:253]     Train net output #0: loss = 1.08116 (* 1 = 1.08116 loss)
I0523 20:45:38.068812  3749 sgd_solver.cpp:106] Iteration 22000, lr = 0.005
I0523 20:45:47.120039  3749 solver.cpp:237] Iteration 22250, loss = 1.09903
I0523 20:45:47.120076  3749 solver.cpp:253]     Train net output #0: loss = 1.09903 (* 1 = 1.09903 loss)
I0523 20:45:47.120092  3749 sgd_solver.cpp:106] Iteration 22250, lr = 0.005
I0523 20:45:56.140580  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_22500.caffemodel
I0523 20:45:56.206115  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_22500.solverstate
I0523 20:45:56.245921  3749 solver.cpp:237] Iteration 22500, loss = 1.36051
I0523 20:45:56.245966  3749 solver.cpp:253]     Train net output #0: loss = 1.36051 (* 1 = 1.36051 loss)
I0523 20:45:56.245987  3749 sgd_solver.cpp:106] Iteration 22500, lr = 0.005
I0523 20:46:05.308234  3749 solver.cpp:237] Iteration 22750, loss = 1.33321
I0523 20:46:05.308384  3749 solver.cpp:253]     Train net output #0: loss = 1.33321 (* 1 = 1.33321 loss)
I0523 20:46:05.308398  3749 sgd_solver.cpp:106] Iteration 22750, lr = 0.005
I0523 20:46:14.355581  3749 solver.cpp:237] Iteration 23000, loss = 1.37229
I0523 20:46:14.355615  3749 solver.cpp:253]     Train net output #0: loss = 1.37229 (* 1 = 1.37229 loss)
I0523 20:46:14.355633  3749 sgd_solver.cpp:106] Iteration 23000, lr = 0.005
I0523 20:46:23.413839  3749 solver.cpp:237] Iteration 23250, loss = 1.25444
I0523 20:46:23.413887  3749 solver.cpp:253]     Train net output #0: loss = 1.25444 (* 1 = 1.25444 loss)
I0523 20:46:23.413903  3749 sgd_solver.cpp:106] Iteration 23250, lr = 0.005
I0523 20:46:54.560773  3749 solver.cpp:237] Iteration 23500, loss = 1.2774
I0523 20:46:54.560951  3749 solver.cpp:253]     Train net output #0: loss = 1.2774 (* 1 = 1.2774 loss)
I0523 20:46:54.560966  3749 sgd_solver.cpp:106] Iteration 23500, lr = 0.005
I0523 20:47:03.611475  3749 solver.cpp:237] Iteration 23750, loss = 1.25551
I0523 20:47:03.611510  3749 solver.cpp:253]     Train net output #0: loss = 1.25551 (* 1 = 1.25551 loss)
I0523 20:47:03.611524  3749 sgd_solver.cpp:106] Iteration 23750, lr = 0.005
I0523 20:47:12.666652  3749 solver.cpp:237] Iteration 24000, loss = 1.18335
I0523 20:47:12.666694  3749 solver.cpp:253]     Train net output #0: loss = 1.18335 (* 1 = 1.18335 loss)
I0523 20:47:12.666714  3749 sgd_solver.cpp:106] Iteration 24000, lr = 0.005
I0523 20:47:21.712047  3749 solver.cpp:237] Iteration 24250, loss = 1.27543
I0523 20:47:21.712083  3749 solver.cpp:253]     Train net output #0: loss = 1.27543 (* 1 = 1.27543 loss)
I0523 20:47:21.712100  3749 sgd_solver.cpp:106] Iteration 24250, lr = 0.005
I0523 20:47:30.773226  3749 solver.cpp:237] Iteration 24500, loss = 1.07928
I0523 20:47:30.773375  3749 solver.cpp:253]     Train net output #0: loss = 1.07928 (* 1 = 1.07928 loss)
I0523 20:47:30.773389  3749 sgd_solver.cpp:106] Iteration 24500, lr = 0.005
I0523 20:47:39.825861  3749 solver.cpp:237] Iteration 24750, loss = 1.34942
I0523 20:47:39.825896  3749 solver.cpp:253]     Train net output #0: loss = 1.34942 (* 1 = 1.34942 loss)
I0523 20:47:39.825913  3749 sgd_solver.cpp:106] Iteration 24750, lr = 0.005
I0523 20:47:48.845855  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_25000.caffemodel
I0523 20:47:48.911093  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_25000.solverstate
I0523 20:47:48.939859  3749 solver.cpp:341] Iteration 25000, Testing net (#0)
I0523 20:48:36.194663  3749 solver.cpp:409]     Test net output #0: accuracy = 0.873146
I0523 20:48:36.194825  3749 solver.cpp:409]     Test net output #1: loss = 0.393114 (* 1 = 0.393114 loss)
I0523 20:48:57.020879  3749 solver.cpp:237] Iteration 25000, loss = 1.22218
I0523 20:48:57.020932  3749 solver.cpp:253]     Train net output #0: loss = 1.22218 (* 1 = 1.22218 loss)
I0523 20:48:57.020947  3749 sgd_solver.cpp:106] Iteration 25000, lr = 0.005
I0523 20:49:06.033571  3749 solver.cpp:237] Iteration 25250, loss = 1.10692
I0523 20:49:06.033607  3749 solver.cpp:253]     Train net output #0: loss = 1.10692 (* 1 = 1.10692 loss)
I0523 20:49:06.033623  3749 sgd_solver.cpp:106] Iteration 25250, lr = 0.005
I0523 20:49:15.039904  3749 solver.cpp:237] Iteration 25500, loss = 1.19792
I0523 20:49:15.040078  3749 solver.cpp:253]     Train net output #0: loss = 1.19792 (* 1 = 1.19792 loss)
I0523 20:49:15.040092  3749 sgd_solver.cpp:106] Iteration 25500, lr = 0.005
I0523 20:49:24.045001  3749 solver.cpp:237] Iteration 25750, loss = 1.25277
I0523 20:49:24.045035  3749 solver.cpp:253]     Train net output #0: loss = 1.25277 (* 1 = 1.25277 loss)
I0523 20:49:24.045053  3749 sgd_solver.cpp:106] Iteration 25750, lr = 0.005
I0523 20:49:33.054944  3749 solver.cpp:237] Iteration 26000, loss = 1.25939
I0523 20:49:33.054980  3749 solver.cpp:253]     Train net output #0: loss = 1.25939 (* 1 = 1.25939 loss)
I0523 20:49:33.054994  3749 sgd_solver.cpp:106] Iteration 26000, lr = 0.005
I0523 20:49:42.065104  3749 solver.cpp:237] Iteration 26250, loss = 1.18294
I0523 20:49:42.065146  3749 solver.cpp:253]     Train net output #0: loss = 1.18294 (* 1 = 1.18294 loss)
I0523 20:49:42.065166  3749 sgd_solver.cpp:106] Iteration 26250, lr = 0.005
I0523 20:49:51.074465  3749 solver.cpp:237] Iteration 26500, loss = 1.3277
I0523 20:49:51.074620  3749 solver.cpp:253]     Train net output #0: loss = 1.3277 (* 1 = 1.3277 loss)
I0523 20:49:51.074635  3749 sgd_solver.cpp:106] Iteration 26500, lr = 0.005
I0523 20:50:20.924877  3749 solver.cpp:237] Iteration 26750, loss = 1.30599
I0523 20:50:20.924928  3749 solver.cpp:253]     Train net output #0: loss = 1.30599 (* 1 = 1.30599 loss)
I0523 20:50:20.924943  3749 sgd_solver.cpp:106] Iteration 26750, lr = 0.005
I0523 20:50:29.935506  3749 solver.cpp:237] Iteration 27000, loss = 1.20664
I0523 20:50:29.935672  3749 solver.cpp:253]     Train net output #0: loss = 1.20664 (* 1 = 1.20664 loss)
I0523 20:50:29.935685  3749 sgd_solver.cpp:106] Iteration 27000, lr = 0.005
I0523 20:50:38.944744  3749 solver.cpp:237] Iteration 27250, loss = 1.16856
I0523 20:50:38.944778  3749 solver.cpp:253]     Train net output #0: loss = 1.16856 (* 1 = 1.16856 loss)
I0523 20:50:38.944795  3749 sgd_solver.cpp:106] Iteration 27250, lr = 0.005
I0523 20:50:47.913219  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_27500.caffemodel
I0523 20:50:47.975460  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_27500.solverstate
I0523 20:50:48.013077  3749 solver.cpp:237] Iteration 27500, loss = 1.0387
I0523 20:50:48.013123  3749 solver.cpp:253]     Train net output #0: loss = 1.0387 (* 1 = 1.0387 loss)
I0523 20:50:48.013136  3749 sgd_solver.cpp:106] Iteration 27500, lr = 0.005
I0523 20:50:57.025560  3749 solver.cpp:237] Iteration 27750, loss = 1.29645
I0523 20:50:57.025601  3749 solver.cpp:253]     Train net output #0: loss = 1.29645 (* 1 = 1.29645 loss)
I0523 20:50:57.025621  3749 sgd_solver.cpp:106] Iteration 27750, lr = 0.005
I0523 20:51:06.036557  3749 solver.cpp:237] Iteration 28000, loss = 1.33011
I0523 20:51:06.036717  3749 solver.cpp:253]     Train net output #0: loss = 1.33011 (* 1 = 1.33011 loss)
I0523 20:51:06.036732  3749 sgd_solver.cpp:106] Iteration 28000, lr = 0.005
I0523 20:51:15.035097  3749 solver.cpp:237] Iteration 28250, loss = 1.14425
I0523 20:51:15.035132  3749 solver.cpp:253]     Train net output #0: loss = 1.14425 (* 1 = 1.14425 loss)
I0523 20:51:15.035147  3749 sgd_solver.cpp:106] Iteration 28250, lr = 0.005
I0523 20:51:44.912652  3749 solver.cpp:237] Iteration 28500, loss = 1.18185
I0523 20:51:44.912820  3749 solver.cpp:253]     Train net output #0: loss = 1.18185 (* 1 = 1.18185 loss)
I0523 20:51:44.912835  3749 sgd_solver.cpp:106] Iteration 28500, lr = 0.005
I0523 20:51:53.921802  3749 solver.cpp:237] Iteration 28750, loss = 1.10425
I0523 20:51:53.921835  3749 solver.cpp:253]     Train net output #0: loss = 1.10425 (* 1 = 1.10425 loss)
I0523 20:51:53.921852  3749 sgd_solver.cpp:106] Iteration 28750, lr = 0.005
I0523 20:52:02.936208  3749 solver.cpp:237] Iteration 29000, loss = 1.33467
I0523 20:52:02.936244  3749 solver.cpp:253]     Train net output #0: loss = 1.33467 (* 1 = 1.33467 loss)
I0523 20:52:02.936260  3749 sgd_solver.cpp:106] Iteration 29000, lr = 0.005
I0523 20:52:11.950959  3749 solver.cpp:237] Iteration 29250, loss = 1.26737
I0523 20:52:11.951009  3749 solver.cpp:253]     Train net output #0: loss = 1.26737 (* 1 = 1.26737 loss)
I0523 20:52:11.951025  3749 sgd_solver.cpp:106] Iteration 29250, lr = 0.005
I0523 20:52:20.963510  3749 solver.cpp:237] Iteration 29500, loss = 1.22881
I0523 20:52:20.963657  3749 solver.cpp:253]     Train net output #0: loss = 1.22881 (* 1 = 1.22881 loss)
I0523 20:52:20.963670  3749 sgd_solver.cpp:106] Iteration 29500, lr = 0.005
I0523 20:52:29.978020  3749 solver.cpp:237] Iteration 29750, loss = 1.29212
I0523 20:52:29.978055  3749 solver.cpp:253]     Train net output #0: loss = 1.29212 (* 1 = 1.29212 loss)
I0523 20:52:29.978071  3749 sgd_solver.cpp:106] Iteration 29750, lr = 0.005
I0523 20:52:38.947572  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_30000.caffemodel
I0523 20:52:39.009963  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_30000.solverstate
I0523 20:52:39.035964  3749 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 20:53:47.049772  3749 solver.cpp:409]     Test net output #0: accuracy = 0.878907
I0523 20:53:47.049947  3749 solver.cpp:409]     Test net output #1: loss = 0.385862 (* 1 = 0.385862 loss)
I0523 20:54:07.927646  3749 solver.cpp:237] Iteration 30000, loss = 0.905289
I0523 20:54:07.927700  3749 solver.cpp:253]     Train net output #0: loss = 0.905289 (* 1 = 0.905289 loss)
I0523 20:54:07.927714  3749 sgd_solver.cpp:106] Iteration 30000, lr = 0.005
I0523 20:54:17.032376  3749 solver.cpp:237] Iteration 30250, loss = 1.02848
I0523 20:54:17.032419  3749 solver.cpp:253]     Train net output #0: loss = 1.02848 (* 1 = 1.02848 loss)
I0523 20:54:17.032436  3749 sgd_solver.cpp:106] Iteration 30250, lr = 0.005
I0523 20:54:26.134037  3749 solver.cpp:237] Iteration 30500, loss = 1.11
I0523 20:54:26.134193  3749 solver.cpp:253]     Train net output #0: loss = 1.11 (* 1 = 1.11 loss)
I0523 20:54:26.134207  3749 sgd_solver.cpp:106] Iteration 30500, lr = 0.005
I0523 20:54:35.246790  3749 solver.cpp:237] Iteration 30750, loss = 1.3921
I0523 20:54:35.246824  3749 solver.cpp:253]     Train net output #0: loss = 1.3921 (* 1 = 1.3921 loss)
I0523 20:54:35.246841  3749 sgd_solver.cpp:106] Iteration 30750, lr = 0.005
I0523 20:54:44.360817  3749 solver.cpp:237] Iteration 31000, loss = 1.09065
I0523 20:54:44.360860  3749 solver.cpp:253]     Train net output #0: loss = 1.09065 (* 1 = 1.09065 loss)
I0523 20:54:44.360877  3749 sgd_solver.cpp:106] Iteration 31000, lr = 0.005
I0523 20:54:53.456400  3749 solver.cpp:237] Iteration 31250, loss = 0.973485
I0523 20:54:53.456437  3749 solver.cpp:253]     Train net output #0: loss = 0.973485 (* 1 = 0.973485 loss)
I0523 20:54:53.456454  3749 sgd_solver.cpp:106] Iteration 31250, lr = 0.005
I0523 20:55:02.561687  3749 solver.cpp:237] Iteration 31500, loss = 1.32231
I0523 20:55:02.561847  3749 solver.cpp:253]     Train net output #0: loss = 1.32231 (* 1 = 1.32231 loss)
I0523 20:55:02.561862  3749 sgd_solver.cpp:106] Iteration 31500, lr = 0.005
I0523 20:55:32.526036  3749 solver.cpp:237] Iteration 31750, loss = 1.21299
I0523 20:55:32.526084  3749 solver.cpp:253]     Train net output #0: loss = 1.21299 (* 1 = 1.21299 loss)
I0523 20:55:32.526103  3749 sgd_solver.cpp:106] Iteration 31750, lr = 0.005
I0523 20:55:41.632666  3749 solver.cpp:237] Iteration 32000, loss = 1.03148
I0523 20:55:41.632825  3749 solver.cpp:253]     Train net output #0: loss = 1.03148 (* 1 = 1.03148 loss)
I0523 20:55:41.632839  3749 sgd_solver.cpp:106] Iteration 32000, lr = 0.005
I0523 20:55:50.735157  3749 solver.cpp:237] Iteration 32250, loss = 1.20189
I0523 20:55:50.735209  3749 solver.cpp:253]     Train net output #0: loss = 1.20189 (* 1 = 1.20189 loss)
I0523 20:55:50.735224  3749 sgd_solver.cpp:106] Iteration 32250, lr = 0.005
I0523 20:55:59.802919  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_32500.caffemodel
I0523 20:55:59.865612  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_32500.solverstate
I0523 20:55:59.902997  3749 solver.cpp:237] Iteration 32500, loss = 1.12587
I0523 20:55:59.903040  3749 solver.cpp:253]     Train net output #0: loss = 1.12587 (* 1 = 1.12587 loss)
I0523 20:55:59.903055  3749 sgd_solver.cpp:106] Iteration 32500, lr = 0.005
I0523 20:56:09.000859  3749 solver.cpp:237] Iteration 32750, loss = 1.24463
I0523 20:56:09.000895  3749 solver.cpp:253]     Train net output #0: loss = 1.24463 (* 1 = 1.24463 loss)
I0523 20:56:09.000911  3749 sgd_solver.cpp:106] Iteration 32750, lr = 0.005
I0523 20:56:18.123782  3749 solver.cpp:237] Iteration 33000, loss = 1.28544
I0523 20:56:18.123960  3749 solver.cpp:253]     Train net output #0: loss = 1.28544 (* 1 = 1.28544 loss)
I0523 20:56:18.123973  3749 sgd_solver.cpp:106] Iteration 33000, lr = 0.005
I0523 20:56:27.231851  3749 solver.cpp:237] Iteration 33250, loss = 1.08762
I0523 20:56:27.231886  3749 solver.cpp:253]     Train net output #0: loss = 1.08762 (* 1 = 1.08762 loss)
I0523 20:56:27.231904  3749 sgd_solver.cpp:106] Iteration 33250, lr = 0.005
I0523 20:56:57.166954  3749 solver.cpp:237] Iteration 33500, loss = 1.16899
I0523 20:56:57.167127  3749 solver.cpp:253]     Train net output #0: loss = 1.16899 (* 1 = 1.16899 loss)
I0523 20:56:57.167142  3749 sgd_solver.cpp:106] Iteration 33500, lr = 0.005
I0523 20:57:06.267477  3749 solver.cpp:237] Iteration 33750, loss = 1.1408
I0523 20:57:06.267523  3749 solver.cpp:253]     Train net output #0: loss = 1.1408 (* 1 = 1.1408 loss)
I0523 20:57:06.267541  3749 sgd_solver.cpp:106] Iteration 33750, lr = 0.005
I0523 20:57:15.372153  3749 solver.cpp:237] Iteration 34000, loss = 1.23279
I0523 20:57:15.372189  3749 solver.cpp:253]     Train net output #0: loss = 1.23279 (* 1 = 1.23279 loss)
I0523 20:57:15.372205  3749 sgd_solver.cpp:106] Iteration 34000, lr = 0.005
I0523 20:57:24.468247  3749 solver.cpp:237] Iteration 34250, loss = 1.24963
I0523 20:57:24.468283  3749 solver.cpp:253]     Train net output #0: loss = 1.24963 (* 1 = 1.24963 loss)
I0523 20:57:24.468302  3749 sgd_solver.cpp:106] Iteration 34250, lr = 0.005
I0523 20:57:33.575948  3749 solver.cpp:237] Iteration 34500, loss = 1.49742
I0523 20:57:33.576120  3749 solver.cpp:253]     Train net output #0: loss = 1.49742 (* 1 = 1.49742 loss)
I0523 20:57:33.576134  3749 sgd_solver.cpp:106] Iteration 34500, lr = 0.005
I0523 20:57:42.677731  3749 solver.cpp:237] Iteration 34750, loss = 1.09982
I0523 20:57:42.677767  3749 solver.cpp:253]     Train net output #0: loss = 1.09982 (* 1 = 1.09982 loss)
I0523 20:57:42.677781  3749 sgd_solver.cpp:106] Iteration 34750, lr = 0.005
I0523 20:57:51.754212  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_35000.caffemodel
I0523 20:57:51.817399  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_35000.solverstate
I0523 20:57:51.843672  3749 solver.cpp:341] Iteration 35000, Testing net (#0)
I0523 20:58:38.731863  3749 solver.cpp:409]     Test net output #0: accuracy = 0.8798
I0523 20:58:38.732030  3749 solver.cpp:409]     Test net output #1: loss = 0.422897 (* 1 = 0.422897 loss)
I0523 20:58:59.545049  3749 solver.cpp:237] Iteration 35000, loss = 1.13092
I0523 20:58:59.545104  3749 solver.cpp:253]     Train net output #0: loss = 1.13092 (* 1 = 1.13092 loss)
I0523 20:58:59.545120  3749 sgd_solver.cpp:106] Iteration 35000, lr = 0.005
I0523 20:59:08.618525  3749 solver.cpp:237] Iteration 35250, loss = 1.12522
I0523 20:59:08.618561  3749 solver.cpp:253]     Train net output #0: loss = 1.12522 (* 1 = 1.12522 loss)
I0523 20:59:08.618577  3749 sgd_solver.cpp:106] Iteration 35250, lr = 0.005
I0523 20:59:17.693850  3749 solver.cpp:237] Iteration 35500, loss = 1.19923
I0523 20:59:17.694013  3749 solver.cpp:253]     Train net output #0: loss = 1.19923 (* 1 = 1.19923 loss)
I0523 20:59:17.694027  3749 sgd_solver.cpp:106] Iteration 35500, lr = 0.005
I0523 20:59:26.765290  3749 solver.cpp:237] Iteration 35750, loss = 1.35411
I0523 20:59:26.765326  3749 solver.cpp:253]     Train net output #0: loss = 1.35411 (* 1 = 1.35411 loss)
I0523 20:59:26.765342  3749 sgd_solver.cpp:106] Iteration 35750, lr = 0.005
I0523 20:59:35.830932  3749 solver.cpp:237] Iteration 36000, loss = 1.20365
I0523 20:59:35.830977  3749 solver.cpp:253]     Train net output #0: loss = 1.20365 (* 1 = 1.20365 loss)
I0523 20:59:35.830994  3749 sgd_solver.cpp:106] Iteration 36000, lr = 0.005
I0523 20:59:44.905732  3749 solver.cpp:237] Iteration 36250, loss = 1.02719
I0523 20:59:44.905768  3749 solver.cpp:253]     Train net output #0: loss = 1.02719 (* 1 = 1.02719 loss)
I0523 20:59:44.905784  3749 sgd_solver.cpp:106] Iteration 36250, lr = 0.005
I0523 20:59:53.980588  3749 solver.cpp:237] Iteration 36500, loss = 1.1425
I0523 20:59:53.980762  3749 solver.cpp:253]     Train net output #0: loss = 1.1425 (* 1 = 1.1425 loss)
I0523 20:59:53.980777  3749 sgd_solver.cpp:106] Iteration 36500, lr = 0.005
I0523 21:00:23.871857  3749 solver.cpp:237] Iteration 36750, loss = 1.14318
I0523 21:00:23.871908  3749 solver.cpp:253]     Train net output #0: loss = 1.14318 (* 1 = 1.14318 loss)
I0523 21:00:23.871925  3749 sgd_solver.cpp:106] Iteration 36750, lr = 0.005
I0523 21:00:32.939360  3749 solver.cpp:237] Iteration 37000, loss = 1.16638
I0523 21:00:32.939522  3749 solver.cpp:253]     Train net output #0: loss = 1.16638 (* 1 = 1.16638 loss)
I0523 21:00:32.939538  3749 sgd_solver.cpp:106] Iteration 37000, lr = 0.005
I0523 21:00:42.015566  3749 solver.cpp:237] Iteration 37250, loss = 1.02544
I0523 21:00:42.015600  3749 solver.cpp:253]     Train net output #0: loss = 1.02544 (* 1 = 1.02544 loss)
I0523 21:00:42.015619  3749 sgd_solver.cpp:106] Iteration 37250, lr = 0.005
I0523 21:00:51.061120  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_37500.caffemodel
I0523 21:00:51.126199  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_37500.solverstate
I0523 21:00:51.165659  3749 solver.cpp:237] Iteration 37500, loss = 1.27066
I0523 21:00:51.165706  3749 solver.cpp:253]     Train net output #0: loss = 1.27066 (* 1 = 1.27066 loss)
I0523 21:00:51.165722  3749 sgd_solver.cpp:106] Iteration 37500, lr = 0.005
I0523 21:01:00.227465  3749 solver.cpp:237] Iteration 37750, loss = 1.27469
I0523 21:01:00.227502  3749 solver.cpp:253]     Train net output #0: loss = 1.27469 (* 1 = 1.27469 loss)
I0523 21:01:00.227519  3749 sgd_solver.cpp:106] Iteration 37750, lr = 0.005
I0523 21:01:09.300480  3749 solver.cpp:237] Iteration 38000, loss = 1.04119
I0523 21:01:09.300645  3749 solver.cpp:253]     Train net output #0: loss = 1.04119 (* 1 = 1.04119 loss)
I0523 21:01:09.300662  3749 sgd_solver.cpp:106] Iteration 38000, lr = 0.005
I0523 21:01:18.370929  3749 solver.cpp:237] Iteration 38250, loss = 1.21448
I0523 21:01:18.370978  3749 solver.cpp:253]     Train net output #0: loss = 1.21448 (* 1 = 1.21448 loss)
I0523 21:01:18.370997  3749 sgd_solver.cpp:106] Iteration 38250, lr = 0.005
I0523 21:01:48.246389  3749 solver.cpp:237] Iteration 38500, loss = 1.2417
I0523 21:01:48.246563  3749 solver.cpp:253]     Train net output #0: loss = 1.2417 (* 1 = 1.2417 loss)
I0523 21:01:48.246577  3749 sgd_solver.cpp:106] Iteration 38500, lr = 0.005
I0523 21:01:57.320173  3749 solver.cpp:237] Iteration 38750, loss = 1.12928
I0523 21:01:57.320207  3749 solver.cpp:253]     Train net output #0: loss = 1.12928 (* 1 = 1.12928 loss)
I0523 21:01:57.320225  3749 sgd_solver.cpp:106] Iteration 38750, lr = 0.005
I0523 21:02:06.394788  3749 solver.cpp:237] Iteration 39000, loss = 1.32883
I0523 21:02:06.394832  3749 solver.cpp:253]     Train net output #0: loss = 1.32883 (* 1 = 1.32883 loss)
I0523 21:02:06.394853  3749 sgd_solver.cpp:106] Iteration 39000, lr = 0.005
I0523 21:02:15.473594  3749 solver.cpp:237] Iteration 39250, loss = 1.13761
I0523 21:02:15.473630  3749 solver.cpp:253]     Train net output #0: loss = 1.13761 (* 1 = 1.13761 loss)
I0523 21:02:15.473647  3749 sgd_solver.cpp:106] Iteration 39250, lr = 0.005
I0523 21:02:24.547169  3749 solver.cpp:237] Iteration 39500, loss = 1.4022
I0523 21:02:24.547322  3749 solver.cpp:253]     Train net output #0: loss = 1.40221 (* 1 = 1.40221 loss)
I0523 21:02:24.547336  3749 sgd_solver.cpp:106] Iteration 39500, lr = 0.005
I0523 21:02:33.624040  3749 solver.cpp:237] Iteration 39750, loss = 1.10099
I0523 21:02:33.624079  3749 solver.cpp:253]     Train net output #0: loss = 1.10099 (* 1 = 1.10099 loss)
I0523 21:02:33.624100  3749 sgd_solver.cpp:106] Iteration 39750, lr = 0.005
I0523 21:02:42.656147  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_40000.caffemodel
I0523 21:02:42.718554  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_40000.solverstate
I0523 21:02:42.745389  3749 solver.cpp:341] Iteration 40000, Testing net (#0)
I0523 21:03:50.701331  3749 solver.cpp:409]     Test net output #0: accuracy = 0.884321
I0523 21:03:50.701504  3749 solver.cpp:409]     Test net output #1: loss = 0.396439 (* 1 = 0.396439 loss)
I0523 21:04:11.502260  3749 solver.cpp:237] Iteration 40000, loss = 0.996897
I0523 21:04:11.502315  3749 solver.cpp:253]     Train net output #0: loss = 0.996897 (* 1 = 0.996897 loss)
I0523 21:04:11.502329  3749 sgd_solver.cpp:106] Iteration 40000, lr = 0.005
I0523 21:04:20.614943  3749 solver.cpp:237] Iteration 40250, loss = 1.04407
I0523 21:04:20.614979  3749 solver.cpp:253]     Train net output #0: loss = 1.04407 (* 1 = 1.04407 loss)
I0523 21:04:20.614996  3749 sgd_solver.cpp:106] Iteration 40250, lr = 0.005
I0523 21:04:29.718359  3749 solver.cpp:237] Iteration 40500, loss = 1.36795
I0523 21:04:29.718513  3749 solver.cpp:253]     Train net output #0: loss = 1.36795 (* 1 = 1.36795 loss)
I0523 21:04:29.718528  3749 sgd_solver.cpp:106] Iteration 40500, lr = 0.005
I0523 21:04:38.832011  3749 solver.cpp:237] Iteration 40750, loss = 1.20144
I0523 21:04:38.832059  3749 solver.cpp:253]     Train net output #0: loss = 1.20144 (* 1 = 1.20144 loss)
I0523 21:04:38.832075  3749 sgd_solver.cpp:106] Iteration 40750, lr = 0.005
I0523 21:04:47.952450  3749 solver.cpp:237] Iteration 41000, loss = 1.50544
I0523 21:04:47.952486  3749 solver.cpp:253]     Train net output #0: loss = 1.50544 (* 1 = 1.50544 loss)
I0523 21:04:47.952502  3749 sgd_solver.cpp:106] Iteration 41000, lr = 0.005
I0523 21:04:57.070586  3749 solver.cpp:237] Iteration 41250, loss = 1.18077
I0523 21:04:57.070622  3749 solver.cpp:253]     Train net output #0: loss = 1.18077 (* 1 = 1.18077 loss)
I0523 21:04:57.070638  3749 sgd_solver.cpp:106] Iteration 41250, lr = 0.005
I0523 21:05:06.180709  3749 solver.cpp:237] Iteration 41500, loss = 1.04722
I0523 21:05:06.180873  3749 solver.cpp:253]     Train net output #0: loss = 1.04722 (* 1 = 1.04722 loss)
I0523 21:05:06.180888  3749 sgd_solver.cpp:106] Iteration 41500, lr = 0.005
I0523 21:05:36.110231  3749 solver.cpp:237] Iteration 41750, loss = 1.22024
I0523 21:05:36.110283  3749 solver.cpp:253]     Train net output #0: loss = 1.22024 (* 1 = 1.22024 loss)
I0523 21:05:36.110298  3749 sgd_solver.cpp:106] Iteration 41750, lr = 0.005
I0523 21:05:45.219847  3749 solver.cpp:237] Iteration 42000, loss = 1.3465
I0523 21:05:45.220001  3749 solver.cpp:253]     Train net output #0: loss = 1.3465 (* 1 = 1.3465 loss)
I0523 21:05:45.220015  3749 sgd_solver.cpp:106] Iteration 42000, lr = 0.005
I0523 21:05:54.335131  3749 solver.cpp:237] Iteration 42250, loss = 1.18004
I0523 21:05:54.335175  3749 solver.cpp:253]     Train net output #0: loss = 1.18004 (* 1 = 1.18004 loss)
I0523 21:05:54.335196  3749 sgd_solver.cpp:106] Iteration 42250, lr = 0.005
I0523 21:06:03.414625  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_42500.caffemodel
I0523 21:06:03.477802  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_42500.solverstate
I0523 21:06:03.515453  3749 solver.cpp:237] Iteration 42500, loss = 1.01539
I0523 21:06:03.515501  3749 solver.cpp:253]     Train net output #0: loss = 1.01539 (* 1 = 1.01539 loss)
I0523 21:06:03.515517  3749 sgd_solver.cpp:106] Iteration 42500, lr = 0.005
I0523 21:06:12.632464  3749 solver.cpp:237] Iteration 42750, loss = 1.27303
I0523 21:06:12.632499  3749 solver.cpp:253]     Train net output #0: loss = 1.27303 (* 1 = 1.27303 loss)
I0523 21:06:12.632515  3749 sgd_solver.cpp:106] Iteration 42750, lr = 0.005
I0523 21:06:21.744580  3749 solver.cpp:237] Iteration 43000, loss = 1.17747
I0523 21:06:21.744757  3749 solver.cpp:253]     Train net output #0: loss = 1.17747 (* 1 = 1.17747 loss)
I0523 21:06:21.744771  3749 sgd_solver.cpp:106] Iteration 43000, lr = 0.005
I0523 21:06:30.857610  3749 solver.cpp:237] Iteration 43250, loss = 0.918405
I0523 21:06:30.857646  3749 solver.cpp:253]     Train net output #0: loss = 0.918405 (* 1 = 0.918405 loss)
I0523 21:06:30.857663  3749 sgd_solver.cpp:106] Iteration 43250, lr = 0.005
I0523 21:07:00.754559  3749 solver.cpp:237] Iteration 43500, loss = 1.18481
I0523 21:07:00.754745  3749 solver.cpp:253]     Train net output #0: loss = 1.18481 (* 1 = 1.18481 loss)
I0523 21:07:00.754761  3749 sgd_solver.cpp:106] Iteration 43500, lr = 0.005
I0523 21:07:09.860247  3749 solver.cpp:237] Iteration 43750, loss = 1.36546
I0523 21:07:09.860291  3749 solver.cpp:253]     Train net output #0: loss = 1.36546 (* 1 = 1.36546 loss)
I0523 21:07:09.860307  3749 sgd_solver.cpp:106] Iteration 43750, lr = 0.005
I0523 21:07:18.980463  3749 solver.cpp:237] Iteration 44000, loss = 1.02997
I0523 21:07:18.980499  3749 solver.cpp:253]     Train net output #0: loss = 1.02997 (* 1 = 1.02997 loss)
I0523 21:07:18.980515  3749 sgd_solver.cpp:106] Iteration 44000, lr = 0.005
I0523 21:07:28.094804  3749 solver.cpp:237] Iteration 44250, loss = 1.23362
I0523 21:07:28.094838  3749 solver.cpp:253]     Train net output #0: loss = 1.23362 (* 1 = 1.23362 loss)
I0523 21:07:28.094856  3749 sgd_solver.cpp:106] Iteration 44250, lr = 0.005
I0523 21:07:37.210310  3749 solver.cpp:237] Iteration 44500, loss = 1.40201
I0523 21:07:37.210474  3749 solver.cpp:253]     Train net output #0: loss = 1.40201 (* 1 = 1.40201 loss)
I0523 21:07:37.210487  3749 sgd_solver.cpp:106] Iteration 44500, lr = 0.005
I0523 21:07:46.324322  3749 solver.cpp:237] Iteration 44750, loss = 1.12831
I0523 21:07:46.324357  3749 solver.cpp:253]     Train net output #0: loss = 1.12831 (* 1 = 1.12831 loss)
I0523 21:07:46.324374  3749 sgd_solver.cpp:106] Iteration 44750, lr = 0.005
I0523 21:07:55.407297  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_45000.caffemodel
I0523 21:07:55.470999  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_45000.solverstate
I0523 21:07:55.497241  3749 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 21:08:42.688073  3749 solver.cpp:409]     Test net output #0: accuracy = 0.883972
I0523 21:08:42.688244  3749 solver.cpp:409]     Test net output #1: loss = 0.365594 (* 1 = 0.365594 loss)
I0523 21:09:03.470559  3749 solver.cpp:237] Iteration 45000, loss = 1.11247
I0523 21:09:03.470612  3749 solver.cpp:253]     Train net output #0: loss = 1.11247 (* 1 = 1.11247 loss)
I0523 21:09:03.470628  3749 sgd_solver.cpp:106] Iteration 45000, lr = 0.005
I0523 21:09:12.498736  3749 solver.cpp:237] Iteration 45250, loss = 1.11411
I0523 21:09:12.498775  3749 solver.cpp:253]     Train net output #0: loss = 1.11411 (* 1 = 1.11411 loss)
I0523 21:09:12.498795  3749 sgd_solver.cpp:106] Iteration 45250, lr = 0.005
I0523 21:09:21.528520  3749 solver.cpp:237] Iteration 45500, loss = 1.0028
I0523 21:09:21.528678  3749 solver.cpp:253]     Train net output #0: loss = 1.0028 (* 1 = 1.0028 loss)
I0523 21:09:21.528692  3749 sgd_solver.cpp:106] Iteration 45500, lr = 0.005
I0523 21:09:30.551599  3749 solver.cpp:237] Iteration 45750, loss = 0.837105
I0523 21:09:30.551633  3749 solver.cpp:253]     Train net output #0: loss = 0.837105 (* 1 = 0.837105 loss)
I0523 21:09:30.551651  3749 sgd_solver.cpp:106] Iteration 45750, lr = 0.005
I0523 21:09:39.574708  3749 solver.cpp:237] Iteration 46000, loss = 1.0333
I0523 21:09:39.574754  3749 solver.cpp:253]     Train net output #0: loss = 1.0333 (* 1 = 1.0333 loss)
I0523 21:09:39.574770  3749 sgd_solver.cpp:106] Iteration 46000, lr = 0.005
I0523 21:09:48.602732  3749 solver.cpp:237] Iteration 46250, loss = 1.00386
I0523 21:09:48.602768  3749 solver.cpp:253]     Train net output #0: loss = 1.00386 (* 1 = 1.00386 loss)
I0523 21:09:48.602784  3749 sgd_solver.cpp:106] Iteration 46250, lr = 0.005
I0523 21:09:57.631407  3749 solver.cpp:237] Iteration 46500, loss = 1.04903
I0523 21:09:57.631567  3749 solver.cpp:253]     Train net output #0: loss = 1.04903 (* 1 = 1.04903 loss)
I0523 21:09:57.631582  3749 sgd_solver.cpp:106] Iteration 46500, lr = 0.005
I0523 21:10:27.456084  3749 solver.cpp:237] Iteration 46750, loss = 1.41594
I0523 21:10:27.456135  3749 solver.cpp:253]     Train net output #0: loss = 1.41594 (* 1 = 1.41594 loss)
I0523 21:10:27.456151  3749 sgd_solver.cpp:106] Iteration 46750, lr = 0.005
I0523 21:10:36.484730  3749 solver.cpp:237] Iteration 47000, loss = 1.15616
I0523 21:10:36.484889  3749 solver.cpp:253]     Train net output #0: loss = 1.15616 (* 1 = 1.15616 loss)
I0523 21:10:36.484905  3749 sgd_solver.cpp:106] Iteration 47000, lr = 0.005
I0523 21:10:45.512727  3749 solver.cpp:237] Iteration 47250, loss = 1.15556
I0523 21:10:45.512760  3749 solver.cpp:253]     Train net output #0: loss = 1.15556 (* 1 = 1.15556 loss)
I0523 21:10:45.512778  3749 sgd_solver.cpp:106] Iteration 47250, lr = 0.005
I0523 21:10:54.501174  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_47500.caffemodel
I0523 21:10:54.565994  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_47500.solverstate
I0523 21:10:54.605701  3749 solver.cpp:237] Iteration 47500, loss = 1.37044
I0523 21:10:54.605749  3749 solver.cpp:253]     Train net output #0: loss = 1.37044 (* 1 = 1.37044 loss)
I0523 21:10:54.605763  3749 sgd_solver.cpp:106] Iteration 47500, lr = 0.005
I0523 21:11:03.634215  3749 solver.cpp:237] Iteration 47750, loss = 0.972604
I0523 21:11:03.634253  3749 solver.cpp:253]     Train net output #0: loss = 0.972604 (* 1 = 0.972604 loss)
I0523 21:11:03.634268  3749 sgd_solver.cpp:106] Iteration 47750, lr = 0.005
I0523 21:11:12.664118  3749 solver.cpp:237] Iteration 48000, loss = 1.76531
I0523 21:11:12.664281  3749 solver.cpp:253]     Train net output #0: loss = 1.76531 (* 1 = 1.76531 loss)
I0523 21:11:12.664295  3749 sgd_solver.cpp:106] Iteration 48000, lr = 0.005
I0523 21:11:21.700371  3749 solver.cpp:237] Iteration 48250, loss = 1.05394
I0523 21:11:21.700417  3749 solver.cpp:253]     Train net output #0: loss = 1.05394 (* 1 = 1.05394 loss)
I0523 21:11:21.700434  3749 sgd_solver.cpp:106] Iteration 48250, lr = 0.005
I0523 21:11:51.513212  3749 solver.cpp:237] Iteration 48500, loss = 1.24507
I0523 21:11:51.513388  3749 solver.cpp:253]     Train net output #0: loss = 1.24507 (* 1 = 1.24507 loss)
I0523 21:11:51.513403  3749 sgd_solver.cpp:106] Iteration 48500, lr = 0.005
I0523 21:12:00.542187  3749 solver.cpp:237] Iteration 48750, loss = 1.05503
I0523 21:12:00.542222  3749 solver.cpp:253]     Train net output #0: loss = 1.05503 (* 1 = 1.05503 loss)
I0523 21:12:00.542237  3749 sgd_solver.cpp:106] Iteration 48750, lr = 0.005
I0523 21:12:09.572104  3749 solver.cpp:237] Iteration 49000, loss = 1.15656
I0523 21:12:09.572149  3749 solver.cpp:253]     Train net output #0: loss = 1.15656 (* 1 = 1.15656 loss)
I0523 21:12:09.572166  3749 sgd_solver.cpp:106] Iteration 49000, lr = 0.005
I0523 21:12:18.609099  3749 solver.cpp:237] Iteration 49250, loss = 1.13962
I0523 21:12:18.609136  3749 solver.cpp:253]     Train net output #0: loss = 1.13962 (* 1 = 1.13962 loss)
I0523 21:12:18.609149  3749 sgd_solver.cpp:106] Iteration 49250, lr = 0.005
I0523 21:12:27.640058  3749 solver.cpp:237] Iteration 49500, loss = 1.24909
I0523 21:12:27.640220  3749 solver.cpp:253]     Train net output #0: loss = 1.24909 (* 1 = 1.24909 loss)
I0523 21:12:27.640234  3749 sgd_solver.cpp:106] Iteration 49500, lr = 0.005
I0523 21:12:36.675402  3749 solver.cpp:237] Iteration 49750, loss = 1.38018
I0523 21:12:36.675449  3749 solver.cpp:253]     Train net output #0: loss = 1.38018 (* 1 = 1.38018 loss)
I0523 21:12:36.675465  3749 sgd_solver.cpp:106] Iteration 49750, lr = 0.005
I0523 21:12:45.678696  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_50000.caffemodel
I0523 21:12:45.744190  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_50000.solverstate
I0523 21:12:45.772614  3749 solver.cpp:341] Iteration 50000, Testing net (#0)
I0523 21:13:53.754868  3749 solver.cpp:409]     Test net output #0: accuracy = 0.888866
I0523 21:13:53.755044  3749 solver.cpp:409]     Test net output #1: loss = 0.365862 (* 1 = 0.365862 loss)
I0523 21:14:14.538561  3749 solver.cpp:237] Iteration 50000, loss = 1.13907
I0523 21:14:14.538614  3749 solver.cpp:253]     Train net output #0: loss = 1.13907 (* 1 = 1.13907 loss)
I0523 21:14:14.538630  3749 sgd_solver.cpp:106] Iteration 50000, lr = 0.005
I0523 21:14:23.589509  3749 solver.cpp:237] Iteration 50250, loss = 1.01189
I0523 21:14:23.589545  3749 solver.cpp:253]     Train net output #0: loss = 1.01189 (* 1 = 1.01189 loss)
I0523 21:14:23.589562  3749 sgd_solver.cpp:106] Iteration 50250, lr = 0.005
I0523 21:14:32.647088  3749 solver.cpp:237] Iteration 50500, loss = 1.09693
I0523 21:14:32.647263  3749 solver.cpp:253]     Train net output #0: loss = 1.09693 (* 1 = 1.09693 loss)
I0523 21:14:32.647276  3749 sgd_solver.cpp:106] Iteration 50500, lr = 0.005
I0523 21:14:41.713068  3749 solver.cpp:237] Iteration 50750, loss = 0.927009
I0523 21:14:41.713114  3749 solver.cpp:253]     Train net output #0: loss = 0.927009 (* 1 = 0.927009 loss)
I0523 21:14:41.713134  3749 sgd_solver.cpp:106] Iteration 50750, lr = 0.005
I0523 21:14:50.773365  3749 solver.cpp:237] Iteration 51000, loss = 1.17156
I0523 21:14:50.773401  3749 solver.cpp:253]     Train net output #0: loss = 1.17156 (* 1 = 1.17156 loss)
I0523 21:14:50.773416  3749 sgd_solver.cpp:106] Iteration 51000, lr = 0.005
I0523 21:14:59.829082  3749 solver.cpp:237] Iteration 51250, loss = 1.15574
I0523 21:14:59.829118  3749 solver.cpp:253]     Train net output #0: loss = 1.15574 (* 1 = 1.15574 loss)
I0523 21:14:59.829134  3749 sgd_solver.cpp:106] Iteration 51250, lr = 0.005
I0523 21:15:08.879956  3749 solver.cpp:237] Iteration 51500, loss = 1.43786
I0523 21:15:08.880123  3749 solver.cpp:253]     Train net output #0: loss = 1.43786 (* 1 = 1.43786 loss)
I0523 21:15:08.880138  3749 sgd_solver.cpp:106] Iteration 51500, lr = 0.005
I0523 21:15:38.720005  3749 solver.cpp:237] Iteration 51750, loss = 1.28918
I0523 21:15:38.720055  3749 solver.cpp:253]     Train net output #0: loss = 1.28918 (* 1 = 1.28918 loss)
I0523 21:15:38.720072  3749 sgd_solver.cpp:106] Iteration 51750, lr = 0.005
I0523 21:15:47.766688  3749 solver.cpp:237] Iteration 52000, loss = 0.859629
I0523 21:15:47.766847  3749 solver.cpp:253]     Train net output #0: loss = 0.859629 (* 1 = 0.859629 loss)
I0523 21:15:47.766862  3749 sgd_solver.cpp:106] Iteration 52000, lr = 0.005
I0523 21:15:56.818579  3749 solver.cpp:237] Iteration 52250, loss = 1.54406
I0523 21:15:56.818621  3749 solver.cpp:253]     Train net output #0: loss = 1.54406 (* 1 = 1.54406 loss)
I0523 21:15:56.818639  3749 sgd_solver.cpp:106] Iteration 52250, lr = 0.005
I0523 21:16:05.845826  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_52500.caffemodel
I0523 21:16:05.909622  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_52500.solverstate
I0523 21:16:05.947160  3749 solver.cpp:237] Iteration 52500, loss = 1.04026
I0523 21:16:05.947208  3749 solver.cpp:253]     Train net output #0: loss = 1.04026 (* 1 = 1.04026 loss)
I0523 21:16:05.947226  3749 sgd_solver.cpp:106] Iteration 52500, lr = 0.005
I0523 21:16:15.013092  3749 solver.cpp:237] Iteration 52750, loss = 1.10988
I0523 21:16:15.013126  3749 solver.cpp:253]     Train net output #0: loss = 1.10988 (* 1 = 1.10988 loss)
I0523 21:16:15.013144  3749 sgd_solver.cpp:106] Iteration 52750, lr = 0.005
I0523 21:16:24.055510  3749 solver.cpp:237] Iteration 53000, loss = 1.04688
I0523 21:16:24.055690  3749 solver.cpp:253]     Train net output #0: loss = 1.04688 (* 1 = 1.04688 loss)
I0523 21:16:24.055703  3749 sgd_solver.cpp:106] Iteration 53000, lr = 0.005
I0523 21:16:33.126085  3749 solver.cpp:237] Iteration 53250, loss = 0.928799
I0523 21:16:33.126121  3749 solver.cpp:253]     Train net output #0: loss = 0.928799 (* 1 = 0.928799 loss)
I0523 21:16:33.126138  3749 sgd_solver.cpp:106] Iteration 53250, lr = 0.005
I0523 21:17:02.970036  3749 solver.cpp:237] Iteration 53500, loss = 1.17142
I0523 21:17:02.970211  3749 solver.cpp:253]     Train net output #0: loss = 1.17142 (* 1 = 1.17142 loss)
I0523 21:17:02.970224  3749 sgd_solver.cpp:106] Iteration 53500, lr = 0.005
I0523 21:17:12.028677  3749 solver.cpp:237] Iteration 53750, loss = 1.29282
I0523 21:17:12.028720  3749 solver.cpp:253]     Train net output #0: loss = 1.29283 (* 1 = 1.29283 loss)
I0523 21:17:12.028738  3749 sgd_solver.cpp:106] Iteration 53750, lr = 0.005
I0523 21:17:21.088963  3749 solver.cpp:237] Iteration 54000, loss = 1.17697
I0523 21:17:21.088997  3749 solver.cpp:253]     Train net output #0: loss = 1.17697 (* 1 = 1.17697 loss)
I0523 21:17:21.089015  3749 sgd_solver.cpp:106] Iteration 54000, lr = 0.005
I0523 21:17:30.147939  3749 solver.cpp:237] Iteration 54250, loss = 1.03366
I0523 21:17:30.147975  3749 solver.cpp:253]     Train net output #0: loss = 1.03366 (* 1 = 1.03366 loss)
I0523 21:17:30.147991  3749 sgd_solver.cpp:106] Iteration 54250, lr = 0.005
I0523 21:17:39.211050  3749 solver.cpp:237] Iteration 54500, loss = 1.06862
I0523 21:17:39.211216  3749 solver.cpp:253]     Train net output #0: loss = 1.06862 (* 1 = 1.06862 loss)
I0523 21:17:39.211230  3749 sgd_solver.cpp:106] Iteration 54500, lr = 0.005
I0523 21:17:48.277019  3749 solver.cpp:237] Iteration 54750, loss = 1.25346
I0523 21:17:48.277053  3749 solver.cpp:253]     Train net output #0: loss = 1.25346 (* 1 = 1.25346 loss)
I0523 21:17:48.277071  3749 sgd_solver.cpp:106] Iteration 54750, lr = 0.005
I0523 21:17:57.304208  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_55000.caffemodel
I0523 21:17:57.366530  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_55000.solverstate
I0523 21:17:57.392506  3749 solver.cpp:341] Iteration 55000, Testing net (#0)
I0523 21:18:44.259465  3749 solver.cpp:409]     Test net output #0: accuracy = 0.889927
I0523 21:18:44.259650  3749 solver.cpp:409]     Test net output #1: loss = 0.349526 (* 1 = 0.349526 loss)
I0523 21:19:05.028784  3749 solver.cpp:237] Iteration 55000, loss = 1.22878
I0523 21:19:05.028834  3749 solver.cpp:253]     Train net output #0: loss = 1.22878 (* 1 = 1.22878 loss)
I0523 21:19:05.028853  3749 sgd_solver.cpp:106] Iteration 55000, lr = 0.005
I0523 21:19:14.032887  3749 solver.cpp:237] Iteration 55250, loss = 1.0866
I0523 21:19:14.032929  3749 solver.cpp:253]     Train net output #0: loss = 1.0866 (* 1 = 1.0866 loss)
I0523 21:19:14.032950  3749 sgd_solver.cpp:106] Iteration 55250, lr = 0.005
I0523 21:19:23.048635  3749 solver.cpp:237] Iteration 55500, loss = 1.07721
I0523 21:19:23.048804  3749 solver.cpp:253]     Train net output #0: loss = 1.07721 (* 1 = 1.07721 loss)
I0523 21:19:23.048817  3749 sgd_solver.cpp:106] Iteration 55500, lr = 0.005
I0523 21:19:32.059823  3749 solver.cpp:237] Iteration 55750, loss = 1.06955
I0523 21:19:32.059859  3749 solver.cpp:253]     Train net output #0: loss = 1.06955 (* 1 = 1.06955 loss)
I0523 21:19:32.059875  3749 sgd_solver.cpp:106] Iteration 55750, lr = 0.005
I0523 21:19:41.065240  3749 solver.cpp:237] Iteration 56000, loss = 0.990441
I0523 21:19:41.065284  3749 solver.cpp:253]     Train net output #0: loss = 0.990441 (* 1 = 0.990441 loss)
I0523 21:19:41.065302  3749 sgd_solver.cpp:106] Iteration 56000, lr = 0.005
I0523 21:19:50.073943  3749 solver.cpp:237] Iteration 56250, loss = 1.29604
I0523 21:19:50.073979  3749 solver.cpp:253]     Train net output #0: loss = 1.29604 (* 1 = 1.29604 loss)
I0523 21:19:50.073995  3749 sgd_solver.cpp:106] Iteration 56250, lr = 0.005
I0523 21:19:59.082962  3749 solver.cpp:237] Iteration 56500, loss = 1.02003
I0523 21:19:59.083120  3749 solver.cpp:253]     Train net output #0: loss = 1.02003 (* 1 = 1.02003 loss)
I0523 21:19:59.083133  3749 sgd_solver.cpp:106] Iteration 56500, lr = 0.005
I0523 21:20:28.907127  3749 solver.cpp:237] Iteration 56750, loss = 1.29321
I0523 21:20:28.907176  3749 solver.cpp:253]     Train net output #0: loss = 1.29321 (* 1 = 1.29321 loss)
I0523 21:20:28.907197  3749 sgd_solver.cpp:106] Iteration 56750, lr = 0.005
I0523 21:20:37.920830  3749 solver.cpp:237] Iteration 57000, loss = 1.12492
I0523 21:20:37.920994  3749 solver.cpp:253]     Train net output #0: loss = 1.12492 (* 1 = 1.12492 loss)
I0523 21:20:37.921008  3749 sgd_solver.cpp:106] Iteration 57000, lr = 0.005
I0523 21:20:46.931304  3749 solver.cpp:237] Iteration 57250, loss = 1.13015
I0523 21:20:46.931339  3749 solver.cpp:253]     Train net output #0: loss = 1.13015 (* 1 = 1.13015 loss)
I0523 21:20:46.931356  3749 sgd_solver.cpp:106] Iteration 57250, lr = 0.005
I0523 21:20:55.905252  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_57500.caffemodel
I0523 21:20:55.968605  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_57500.solverstate
I0523 21:20:56.005911  3749 solver.cpp:237] Iteration 57500, loss = 1.03486
I0523 21:20:56.005957  3749 solver.cpp:253]     Train net output #0: loss = 1.03486 (* 1 = 1.03486 loss)
I0523 21:20:56.005973  3749 sgd_solver.cpp:106] Iteration 57500, lr = 0.005
I0523 21:21:05.016124  3749 solver.cpp:237] Iteration 57750, loss = 1.09364
I0523 21:21:05.016160  3749 solver.cpp:253]     Train net output #0: loss = 1.09364 (* 1 = 1.09364 loss)
I0523 21:21:05.016175  3749 sgd_solver.cpp:106] Iteration 57750, lr = 0.005
I0523 21:21:14.023797  3749 solver.cpp:237] Iteration 58000, loss = 1.10068
I0523 21:21:14.023958  3749 solver.cpp:253]     Train net output #0: loss = 1.10068 (* 1 = 1.10068 loss)
I0523 21:21:14.023972  3749 sgd_solver.cpp:106] Iteration 58000, lr = 0.005
I0523 21:21:23.028897  3749 solver.cpp:237] Iteration 58250, loss = 1.25825
I0523 21:21:23.028939  3749 solver.cpp:253]     Train net output #0: loss = 1.25825 (* 1 = 1.25825 loss)
I0523 21:21:23.028959  3749 sgd_solver.cpp:106] Iteration 58250, lr = 0.005
I0523 21:21:52.849822  3749 solver.cpp:237] Iteration 58500, loss = 1.32813
I0523 21:21:52.849999  3749 solver.cpp:253]     Train net output #0: loss = 1.32813 (* 1 = 1.32813 loss)
I0523 21:21:52.850013  3749 sgd_solver.cpp:106] Iteration 58500, lr = 0.005
I0523 21:22:01.854743  3749 solver.cpp:237] Iteration 58750, loss = 1.17288
I0523 21:22:01.854778  3749 solver.cpp:253]     Train net output #0: loss = 1.17288 (* 1 = 1.17288 loss)
I0523 21:22:01.854795  3749 sgd_solver.cpp:106] Iteration 58750, lr = 0.005
I0523 21:22:10.864871  3749 solver.cpp:237] Iteration 59000, loss = 1.3014
I0523 21:22:10.864917  3749 solver.cpp:253]     Train net output #0: loss = 1.3014 (* 1 = 1.3014 loss)
I0523 21:22:10.864935  3749 sgd_solver.cpp:106] Iteration 59000, lr = 0.005
I0523 21:22:19.873278  3749 solver.cpp:237] Iteration 59250, loss = 1.28052
I0523 21:22:19.873314  3749 solver.cpp:253]     Train net output #0: loss = 1.28052 (* 1 = 1.28052 loss)
I0523 21:22:19.873330  3749 sgd_solver.cpp:106] Iteration 59250, lr = 0.005
I0523 21:22:28.885289  3749 solver.cpp:237] Iteration 59500, loss = 1.67378
I0523 21:22:28.885457  3749 solver.cpp:253]     Train net output #0: loss = 1.67378 (* 1 = 1.67378 loss)
I0523 21:22:28.885471  3749 sgd_solver.cpp:106] Iteration 59500, lr = 0.005
I0523 21:22:37.900369  3749 solver.cpp:237] Iteration 59750, loss = 0.99255
I0523 21:22:37.900415  3749 solver.cpp:253]     Train net output #0: loss = 0.99255 (* 1 = 0.99255 loss)
I0523 21:22:37.900432  3749 sgd_solver.cpp:106] Iteration 59750, lr = 0.005
I0523 21:22:46.878882  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_60000.caffemodel
I0523 21:22:46.942271  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_60000.solverstate
I0523 21:22:46.968621  3749 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 21:23:54.903903  3749 solver.cpp:409]     Test net output #0: accuracy = 0.891359
I0523 21:23:54.904079  3749 solver.cpp:409]     Test net output #1: loss = 0.37307 (* 1 = 0.37307 loss)
I0523 21:24:15.692003  3749 solver.cpp:237] Iteration 60000, loss = 1.16539
I0523 21:24:15.692057  3749 solver.cpp:253]     Train net output #0: loss = 1.16539 (* 1 = 1.16539 loss)
I0523 21:24:15.692073  3749 sgd_solver.cpp:106] Iteration 60000, lr = 0.005
I0523 21:24:24.780314  3749 solver.cpp:237] Iteration 60250, loss = 1.11502
I0523 21:24:24.780349  3749 solver.cpp:253]     Train net output #0: loss = 1.11502 (* 1 = 1.11502 loss)
I0523 21:24:24.780366  3749 sgd_solver.cpp:106] Iteration 60250, lr = 0.005
I0523 21:24:33.888200  3749 solver.cpp:237] Iteration 60500, loss = 1.0104
I0523 21:24:33.888372  3749 solver.cpp:253]     Train net output #0: loss = 1.0104 (* 1 = 1.0104 loss)
I0523 21:24:33.888386  3749 sgd_solver.cpp:106] Iteration 60500, lr = 0.005
I0523 21:24:42.994247  3749 solver.cpp:237] Iteration 60750, loss = 0.884803
I0523 21:24:42.994288  3749 solver.cpp:253]     Train net output #0: loss = 0.884803 (* 1 = 0.884803 loss)
I0523 21:24:42.994307  3749 sgd_solver.cpp:106] Iteration 60750, lr = 0.005
I0523 21:24:52.097838  3749 solver.cpp:237] Iteration 61000, loss = 1.0093
I0523 21:24:52.097874  3749 solver.cpp:253]     Train net output #0: loss = 1.0093 (* 1 = 1.0093 loss)
I0523 21:24:52.097890  3749 sgd_solver.cpp:106] Iteration 61000, lr = 0.005
I0523 21:25:01.205191  3749 solver.cpp:237] Iteration 61250, loss = 1.11198
I0523 21:25:01.205242  3749 solver.cpp:253]     Train net output #0: loss = 1.11198 (* 1 = 1.11198 loss)
I0523 21:25:01.205257  3749 sgd_solver.cpp:106] Iteration 61250, lr = 0.005
I0523 21:25:10.314841  3749 solver.cpp:237] Iteration 61500, loss = 1.09413
I0523 21:25:10.314996  3749 solver.cpp:253]     Train net output #0: loss = 1.09413 (* 1 = 1.09413 loss)
I0523 21:25:10.315011  3749 sgd_solver.cpp:106] Iteration 61500, lr = 0.005
I0523 21:25:40.213569  3749 solver.cpp:237] Iteration 61750, loss = 1.00248
I0523 21:25:40.213619  3749 solver.cpp:253]     Train net output #0: loss = 1.00248 (* 1 = 1.00248 loss)
I0523 21:25:40.213636  3749 sgd_solver.cpp:106] Iteration 61750, lr = 0.005
I0523 21:25:49.308457  3749 solver.cpp:237] Iteration 62000, loss = 0.995734
I0523 21:25:49.308620  3749 solver.cpp:253]     Train net output #0: loss = 0.995734 (* 1 = 0.995734 loss)
I0523 21:25:49.308634  3749 sgd_solver.cpp:106] Iteration 62000, lr = 0.005
I0523 21:25:58.414125  3749 solver.cpp:237] Iteration 62250, loss = 1.21206
I0523 21:25:58.414166  3749 solver.cpp:253]     Train net output #0: loss = 1.21206 (* 1 = 1.21206 loss)
I0523 21:25:58.414182  3749 sgd_solver.cpp:106] Iteration 62250, lr = 0.005
I0523 21:26:07.487222  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_62500.caffemodel
I0523 21:26:07.552544  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_62500.solverstate
I0523 21:26:07.592378  3749 solver.cpp:237] Iteration 62500, loss = 1.09729
I0523 21:26:07.592429  3749 solver.cpp:253]     Train net output #0: loss = 1.09729 (* 1 = 1.09729 loss)
I0523 21:26:07.592447  3749 sgd_solver.cpp:106] Iteration 62500, lr = 0.005
I0523 21:26:16.688513  3749 solver.cpp:237] Iteration 62750, loss = 1.27355
I0523 21:26:16.688557  3749 solver.cpp:253]     Train net output #0: loss = 1.27355 (* 1 = 1.27355 loss)
I0523 21:26:16.688572  3749 sgd_solver.cpp:106] Iteration 62750, lr = 0.005
I0523 21:26:25.803663  3749 solver.cpp:237] Iteration 63000, loss = 1.03278
I0523 21:26:25.803844  3749 solver.cpp:253]     Train net output #0: loss = 1.03278 (* 1 = 1.03278 loss)
I0523 21:26:25.803858  3749 sgd_solver.cpp:106] Iteration 63000, lr = 0.005
I0523 21:26:34.894811  3749 solver.cpp:237] Iteration 63250, loss = 1.05644
I0523 21:26:34.894846  3749 solver.cpp:253]     Train net output #0: loss = 1.05644 (* 1 = 1.05644 loss)
I0523 21:26:34.894863  3749 sgd_solver.cpp:106] Iteration 63250, lr = 0.005
I0523 21:27:04.788337  3749 solver.cpp:237] Iteration 63500, loss = 0.961771
I0523 21:27:04.788521  3749 solver.cpp:253]     Train net output #0: loss = 0.961772 (* 1 = 0.961772 loss)
I0523 21:27:04.788537  3749 sgd_solver.cpp:106] Iteration 63500, lr = 0.005
I0523 21:27:13.887567  3749 solver.cpp:237] Iteration 63750, loss = 1.13266
I0523 21:27:13.887599  3749 solver.cpp:253]     Train net output #0: loss = 1.13266 (* 1 = 1.13266 loss)
I0523 21:27:13.887620  3749 sgd_solver.cpp:106] Iteration 63750, lr = 0.005
I0523 21:27:22.993574  3749 solver.cpp:237] Iteration 64000, loss = 1.11575
I0523 21:27:22.993609  3749 solver.cpp:253]     Train net output #0: loss = 1.11575 (* 1 = 1.11575 loss)
I0523 21:27:22.993626  3749 sgd_solver.cpp:106] Iteration 64000, lr = 0.005
I0523 21:27:32.097378  3749 solver.cpp:237] Iteration 64250, loss = 1.05734
I0523 21:27:32.097422  3749 solver.cpp:253]     Train net output #0: loss = 1.05734 (* 1 = 1.05734 loss)
I0523 21:27:32.097437  3749 sgd_solver.cpp:106] Iteration 64250, lr = 0.005
I0523 21:27:41.199004  3749 solver.cpp:237] Iteration 64500, loss = 1.10148
I0523 21:27:41.199165  3749 solver.cpp:253]     Train net output #0: loss = 1.10148 (* 1 = 1.10148 loss)
I0523 21:27:41.199178  3749 sgd_solver.cpp:106] Iteration 64500, lr = 0.005
I0523 21:27:50.300876  3749 solver.cpp:237] Iteration 64750, loss = 0.946679
I0523 21:27:50.300911  3749 solver.cpp:253]     Train net output #0: loss = 0.946679 (* 1 = 0.946679 loss)
I0523 21:27:50.300928  3749 sgd_solver.cpp:106] Iteration 64750, lr = 0.005
I0523 21:27:59.362519  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_65000.caffemodel
I0523 21:27:59.425894  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_65000.solverstate
I0523 21:27:59.452038  3749 solver.cpp:341] Iteration 65000, Testing net (#0)
I0523 21:28:46.629813  3749 solver.cpp:409]     Test net output #0: accuracy = 0.891752
I0523 21:28:46.629989  3749 solver.cpp:409]     Test net output #1: loss = 0.33498 (* 1 = 0.33498 loss)
I0523 21:29:07.446025  3749 solver.cpp:237] Iteration 65000, loss = 0.919807
I0523 21:29:07.446079  3749 solver.cpp:253]     Train net output #0: loss = 0.919807 (* 1 = 0.919807 loss)
I0523 21:29:07.446094  3749 sgd_solver.cpp:106] Iteration 65000, lr = 0.005
I0523 21:29:16.517897  3749 solver.cpp:237] Iteration 65250, loss = 0.946458
I0523 21:29:16.517940  3749 solver.cpp:253]     Train net output #0: loss = 0.946458 (* 1 = 0.946458 loss)
I0523 21:29:16.517957  3749 sgd_solver.cpp:106] Iteration 65250, lr = 0.005
I0523 21:29:25.591825  3749 solver.cpp:237] Iteration 65500, loss = 1.17432
I0523 21:29:25.591996  3749 solver.cpp:253]     Train net output #0: loss = 1.17432 (* 1 = 1.17432 loss)
I0523 21:29:25.592010  3749 sgd_solver.cpp:106] Iteration 65500, lr = 0.005
I0523 21:29:34.669070  3749 solver.cpp:237] Iteration 65750, loss = 1.02093
I0523 21:29:34.669105  3749 solver.cpp:253]     Train net output #0: loss = 1.02093 (* 1 = 1.02093 loss)
I0523 21:29:34.669121  3749 sgd_solver.cpp:106] Iteration 65750, lr = 0.005
I0523 21:29:43.733230  3749 solver.cpp:237] Iteration 66000, loss = 1.27833
I0523 21:29:43.733265  3749 solver.cpp:253]     Train net output #0: loss = 1.27833 (* 1 = 1.27833 loss)
I0523 21:29:43.733285  3749 sgd_solver.cpp:106] Iteration 66000, lr = 0.005
I0523 21:29:52.805676  3749 solver.cpp:237] Iteration 66250, loss = 1.26781
I0523 21:29:52.805711  3749 solver.cpp:253]     Train net output #0: loss = 1.26781 (* 1 = 1.26781 loss)
I0523 21:29:52.805727  3749 sgd_solver.cpp:106] Iteration 66250, lr = 0.005
I0523 21:30:01.885643  3749 solver.cpp:237] Iteration 66500, loss = 0.998487
I0523 21:30:01.885814  3749 solver.cpp:253]     Train net output #0: loss = 0.998488 (* 1 = 0.998488 loss)
I0523 21:30:01.885828  3749 sgd_solver.cpp:106] Iteration 66500, lr = 0.005
I0523 21:30:31.806501  3749 solver.cpp:237] Iteration 66750, loss = 1.13301
I0523 21:30:31.806551  3749 solver.cpp:253]     Train net output #0: loss = 1.13301 (* 1 = 1.13301 loss)
I0523 21:30:31.806569  3749 sgd_solver.cpp:106] Iteration 66750, lr = 0.005
I0523 21:30:40.880947  3749 solver.cpp:237] Iteration 67000, loss = 0.873036
I0523 21:30:40.881117  3749 solver.cpp:253]     Train net output #0: loss = 0.873036 (* 1 = 0.873036 loss)
I0523 21:30:40.881132  3749 sgd_solver.cpp:106] Iteration 67000, lr = 0.005
I0523 21:30:49.946645  3749 solver.cpp:237] Iteration 67250, loss = 1.03639
I0523 21:30:49.946679  3749 solver.cpp:253]     Train net output #0: loss = 1.03639 (* 1 = 1.03639 loss)
I0523 21:30:49.946696  3749 sgd_solver.cpp:106] Iteration 67250, lr = 0.005
I0523 21:30:58.987790  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_67500.caffemodel
I0523 21:30:59.051112  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_67500.solverstate
I0523 21:30:59.088804  3749 solver.cpp:237] Iteration 67500, loss = 0.920711
I0523 21:30:59.088850  3749 solver.cpp:253]     Train net output #0: loss = 0.920711 (* 1 = 0.920711 loss)
I0523 21:30:59.088865  3749 sgd_solver.cpp:106] Iteration 67500, lr = 0.005
I0523 21:31:08.163441  3749 solver.cpp:237] Iteration 67750, loss = 1.02906
I0523 21:31:08.163475  3749 solver.cpp:253]     Train net output #0: loss = 1.02906 (* 1 = 1.02906 loss)
I0523 21:31:08.163493  3749 sgd_solver.cpp:106] Iteration 67750, lr = 0.005
I0523 21:31:17.239751  3749 solver.cpp:237] Iteration 68000, loss = 0.948352
I0523 21:31:17.239933  3749 solver.cpp:253]     Train net output #0: loss = 0.948352 (* 1 = 0.948352 loss)
I0523 21:31:17.239948  3749 sgd_solver.cpp:106] Iteration 68000, lr = 0.005
I0523 21:31:26.316159  3749 solver.cpp:237] Iteration 68250, loss = 0.94722
I0523 21:31:26.316193  3749 solver.cpp:253]     Train net output #0: loss = 0.94722 (* 1 = 0.94722 loss)
I0523 21:31:26.316210  3749 sgd_solver.cpp:106] Iteration 68250, lr = 0.005
I0523 21:31:56.187111  3749 solver.cpp:237] Iteration 68500, loss = 1.09641
I0523 21:31:56.187300  3749 solver.cpp:253]     Train net output #0: loss = 1.09641 (* 1 = 1.09641 loss)
I0523 21:31:56.187315  3749 sgd_solver.cpp:106] Iteration 68500, lr = 0.005
I0523 21:32:05.254060  3749 solver.cpp:237] Iteration 68750, loss = 1.34333
I0523 21:32:05.254096  3749 solver.cpp:253]     Train net output #0: loss = 1.34333 (* 1 = 1.34333 loss)
I0523 21:32:05.254112  3749 sgd_solver.cpp:106] Iteration 68750, lr = 0.005
I0523 21:32:14.322288  3749 solver.cpp:237] Iteration 69000, loss = 0.949017
I0523 21:32:14.322330  3749 solver.cpp:253]     Train net output #0: loss = 0.949017 (* 1 = 0.949017 loss)
I0523 21:32:14.322350  3749 sgd_solver.cpp:106] Iteration 69000, lr = 0.005
I0523 21:32:23.405453  3749 solver.cpp:237] Iteration 69250, loss = 1.49401
I0523 21:32:23.405488  3749 solver.cpp:253]     Train net output #0: loss = 1.49401 (* 1 = 1.49401 loss)
I0523 21:32:23.405504  3749 sgd_solver.cpp:106] Iteration 69250, lr = 0.005
I0523 21:32:32.482051  3749 solver.cpp:237] Iteration 69500, loss = 1.15001
I0523 21:32:32.482239  3749 solver.cpp:253]     Train net output #0: loss = 1.15001 (* 1 = 1.15001 loss)
I0523 21:32:32.482254  3749 sgd_solver.cpp:106] Iteration 69500, lr = 0.005
I0523 21:32:41.568852  3749 solver.cpp:237] Iteration 69750, loss = 1.39125
I0523 21:32:41.568887  3749 solver.cpp:253]     Train net output #0: loss = 1.39125 (* 1 = 1.39125 loss)
I0523 21:32:41.568903  3749 sgd_solver.cpp:106] Iteration 69750, lr = 0.005
I0523 21:32:50.608728  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_70000.caffemodel
I0523 21:32:50.671071  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_70000.solverstate
I0523 21:32:50.697474  3749 solver.cpp:341] Iteration 70000, Testing net (#0)
I0523 21:33:58.659294  3749 solver.cpp:409]     Test net output #0: accuracy = 0.895099
I0523 21:33:58.659476  3749 solver.cpp:409]     Test net output #1: loss = 0.340298 (* 1 = 0.340298 loss)
I0523 21:34:19.415504  3749 solver.cpp:237] Iteration 70000, loss = 1.21821
I0523 21:34:19.415556  3749 solver.cpp:253]     Train net output #0: loss = 1.21821 (* 1 = 1.21821 loss)
I0523 21:34:19.415573  3749 sgd_solver.cpp:106] Iteration 70000, lr = 0.005
I0523 21:34:28.528188  3749 solver.cpp:237] Iteration 70250, loss = 1.29129
I0523 21:34:28.528225  3749 solver.cpp:253]     Train net output #0: loss = 1.29129 (* 1 = 1.29129 loss)
I0523 21:34:28.528241  3749 sgd_solver.cpp:106] Iteration 70250, lr = 0.005
I0523 21:34:37.644562  3749 solver.cpp:237] Iteration 70500, loss = 1.22634
I0523 21:34:37.644742  3749 solver.cpp:253]     Train net output #0: loss = 1.22634 (* 1 = 1.22634 loss)
I0523 21:34:37.644755  3749 sgd_solver.cpp:106] Iteration 70500, lr = 0.005
I0523 21:34:46.764252  3749 solver.cpp:237] Iteration 70750, loss = 1.00934
I0523 21:34:46.764287  3749 solver.cpp:253]     Train net output #0: loss = 1.00934 (* 1 = 1.00934 loss)
I0523 21:34:46.764304  3749 sgd_solver.cpp:106] Iteration 70750, lr = 0.005
I0523 21:34:55.871220  3749 solver.cpp:237] Iteration 71000, loss = 1.30662
I0523 21:34:55.871256  3749 solver.cpp:253]     Train net output #0: loss = 1.30662 (* 1 = 1.30662 loss)
I0523 21:34:55.871273  3749 sgd_solver.cpp:106] Iteration 71000, lr = 0.005
I0523 21:35:04.991657  3749 solver.cpp:237] Iteration 71250, loss = 1.0258
I0523 21:35:04.991706  3749 solver.cpp:253]     Train net output #0: loss = 1.0258 (* 1 = 1.0258 loss)
I0523 21:35:04.991720  3749 sgd_solver.cpp:106] Iteration 71250, lr = 0.005
I0523 21:35:14.111055  3749 solver.cpp:237] Iteration 71500, loss = 1.19675
I0523 21:35:14.111223  3749 solver.cpp:253]     Train net output #0: loss = 1.19675 (* 1 = 1.19675 loss)
I0523 21:35:14.111238  3749 sgd_solver.cpp:106] Iteration 71500, lr = 0.005
I0523 21:35:44.033174  3749 solver.cpp:237] Iteration 71750, loss = 1.02165
I0523 21:35:44.033226  3749 solver.cpp:253]     Train net output #0: loss = 1.02165 (* 1 = 1.02165 loss)
I0523 21:35:44.033241  3749 sgd_solver.cpp:106] Iteration 71750, lr = 0.005
I0523 21:35:53.149734  3749 solver.cpp:237] Iteration 72000, loss = 1.3746
I0523 21:35:53.149919  3749 solver.cpp:253]     Train net output #0: loss = 1.3746 (* 1 = 1.3746 loss)
I0523 21:35:53.149932  3749 sgd_solver.cpp:106] Iteration 72000, lr = 0.005
I0523 21:36:02.265625  3749 solver.cpp:237] Iteration 72250, loss = 1.43484
I0523 21:36:02.265661  3749 solver.cpp:253]     Train net output #0: loss = 1.43484 (* 1 = 1.43484 loss)
I0523 21:36:02.265677  3749 sgd_solver.cpp:106] Iteration 72250, lr = 0.005
I0523 21:36:11.349808  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_72500.caffemodel
I0523 21:36:11.431062  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_72500.solverstate
I0523 21:36:11.474730  3749 solver.cpp:237] Iteration 72500, loss = 1.28235
I0523 21:36:11.474781  3749 solver.cpp:253]     Train net output #0: loss = 1.28235 (* 1 = 1.28235 loss)
I0523 21:36:11.474797  3749 sgd_solver.cpp:106] Iteration 72500, lr = 0.005
I0523 21:36:20.588613  3749 solver.cpp:237] Iteration 72750, loss = 1.14355
I0523 21:36:20.588659  3749 solver.cpp:253]     Train net output #0: loss = 1.14355 (* 1 = 1.14355 loss)
I0523 21:36:20.588675  3749 sgd_solver.cpp:106] Iteration 72750, lr = 0.005
I0523 21:36:29.699856  3749 solver.cpp:237] Iteration 73000, loss = 1.39104
I0523 21:36:29.700023  3749 solver.cpp:253]     Train net output #0: loss = 1.39104 (* 1 = 1.39104 loss)
I0523 21:36:29.700038  3749 sgd_solver.cpp:106] Iteration 73000, lr = 0.005
I0523 21:36:38.818150  3749 solver.cpp:237] Iteration 73250, loss = 1.24957
I0523 21:36:38.818184  3749 solver.cpp:253]     Train net output #0: loss = 1.24957 (* 1 = 1.24957 loss)
I0523 21:36:38.818203  3749 sgd_solver.cpp:106] Iteration 73250, lr = 0.005
I0523 21:37:08.813362  3749 solver.cpp:237] Iteration 73500, loss = 1.08345
I0523 21:37:08.813546  3749 solver.cpp:253]     Train net output #0: loss = 1.08345 (* 1 = 1.08345 loss)
I0523 21:37:08.813561  3749 sgd_solver.cpp:106] Iteration 73500, lr = 0.005
I0523 21:37:17.930608  3749 solver.cpp:237] Iteration 73750, loss = 1.1757
I0523 21:37:17.930644  3749 solver.cpp:253]     Train net output #0: loss = 1.1757 (* 1 = 1.1757 loss)
I0523 21:37:17.930660  3749 sgd_solver.cpp:106] Iteration 73750, lr = 0.005
I0523 21:37:27.049962  3749 solver.cpp:237] Iteration 74000, loss = 1.2433
I0523 21:37:27.049998  3749 solver.cpp:253]     Train net output #0: loss = 1.2433 (* 1 = 1.2433 loss)
I0523 21:37:27.050012  3749 sgd_solver.cpp:106] Iteration 74000, lr = 0.005
I0523 21:37:36.164726  3749 solver.cpp:237] Iteration 74250, loss = 1.42059
I0523 21:37:36.164773  3749 solver.cpp:253]     Train net output #0: loss = 1.42059 (* 1 = 1.42059 loss)
I0523 21:37:36.164790  3749 sgd_solver.cpp:106] Iteration 74250, lr = 0.005
I0523 21:37:45.276195  3749 solver.cpp:237] Iteration 74500, loss = 1.25381
I0523 21:37:45.276360  3749 solver.cpp:253]     Train net output #0: loss = 1.25381 (* 1 = 1.25381 loss)
I0523 21:37:45.276374  3749 sgd_solver.cpp:106] Iteration 74500, lr = 0.005
I0523 21:37:54.385964  3749 solver.cpp:237] Iteration 74750, loss = 1.06216
I0523 21:37:54.385999  3749 solver.cpp:253]     Train net output #0: loss = 1.06216 (* 1 = 1.06216 loss)
I0523 21:37:54.386016  3749 sgd_solver.cpp:106] Iteration 74750, lr = 0.005
I0523 21:38:03.470150  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_75000.caffemodel
I0523 21:38:03.535876  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_75000.solverstate
I0523 21:38:03.564465  3749 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 21:38:50.522923  3749 solver.cpp:409]     Test net output #0: accuracy = 0.895179
I0523 21:38:50.523113  3749 solver.cpp:409]     Test net output #1: loss = 0.339144 (* 1 = 0.339144 loss)
I0523 21:39:11.368551  3749 solver.cpp:237] Iteration 75000, loss = 1.31668
I0523 21:39:11.368604  3749 solver.cpp:253]     Train net output #0: loss = 1.31668 (* 1 = 1.31668 loss)
I0523 21:39:11.368619  3749 sgd_solver.cpp:106] Iteration 75000, lr = 0.005
I0523 21:39:20.394330  3749 solver.cpp:237] Iteration 75250, loss = 0.905
I0523 21:39:20.394367  3749 solver.cpp:253]     Train net output #0: loss = 0.905 (* 1 = 0.905 loss)
I0523 21:39:20.394383  3749 sgd_solver.cpp:106] Iteration 75250, lr = 0.005
I0523 21:39:29.423257  3749 solver.cpp:237] Iteration 75500, loss = 0.893089
I0523 21:39:29.423429  3749 solver.cpp:253]     Train net output #0: loss = 0.893089 (* 1 = 0.893089 loss)
I0523 21:39:29.423442  3749 sgd_solver.cpp:106] Iteration 75500, lr = 0.005
I0523 21:39:38.457295  3749 solver.cpp:237] Iteration 75750, loss = 1.12661
I0523 21:39:38.457339  3749 solver.cpp:253]     Train net output #0: loss = 1.12661 (* 1 = 1.12661 loss)
I0523 21:39:38.457358  3749 sgd_solver.cpp:106] Iteration 75750, lr = 0.005
I0523 21:39:47.489629  3749 solver.cpp:237] Iteration 76000, loss = 1.04988
I0523 21:39:47.489663  3749 solver.cpp:253]     Train net output #0: loss = 1.04988 (* 1 = 1.04988 loss)
I0523 21:39:47.489678  3749 sgd_solver.cpp:106] Iteration 76000, lr = 0.005
I0523 21:39:56.519582  3749 solver.cpp:237] Iteration 76250, loss = 1.20572
I0523 21:39:56.519618  3749 solver.cpp:253]     Train net output #0: loss = 1.20572 (* 1 = 1.20572 loss)
I0523 21:39:56.519634  3749 sgd_solver.cpp:106] Iteration 76250, lr = 0.005
I0523 21:40:05.555797  3749 solver.cpp:237] Iteration 76500, loss = 1.36774
I0523 21:40:05.555969  3749 solver.cpp:253]     Train net output #0: loss = 1.36774 (* 1 = 1.36774 loss)
I0523 21:40:05.555984  3749 sgd_solver.cpp:106] Iteration 76500, lr = 0.005
I0523 21:40:35.404397  3749 solver.cpp:237] Iteration 76750, loss = 1.07685
I0523 21:40:35.404448  3749 solver.cpp:253]     Train net output #0: loss = 1.07685 (* 1 = 1.07685 loss)
I0523 21:40:35.404464  3749 sgd_solver.cpp:106] Iteration 76750, lr = 0.005
I0523 21:40:44.440879  3749 solver.cpp:237] Iteration 77000, loss = 0.966077
I0523 21:40:44.441046  3749 solver.cpp:253]     Train net output #0: loss = 0.966077 (* 1 = 0.966077 loss)
I0523 21:40:44.441061  3749 sgd_solver.cpp:106] Iteration 77000, lr = 0.005
I0523 21:40:53.474840  3749 solver.cpp:237] Iteration 77250, loss = 1.52845
I0523 21:40:53.474884  3749 solver.cpp:253]     Train net output #0: loss = 1.52845 (* 1 = 1.52845 loss)
I0523 21:40:53.474901  3749 sgd_solver.cpp:106] Iteration 77250, lr = 0.005
I0523 21:41:02.469283  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_77500.caffemodel
I0523 21:41:02.532510  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_77500.solverstate
I0523 21:41:02.569932  3749 solver.cpp:237] Iteration 77500, loss = 0.976091
I0523 21:41:02.569975  3749 solver.cpp:253]     Train net output #0: loss = 0.976091 (* 1 = 0.976091 loss)
I0523 21:41:02.569993  3749 sgd_solver.cpp:106] Iteration 77500, lr = 0.005
I0523 21:41:11.601474  3749 solver.cpp:237] Iteration 77750, loss = 1.19712
I0523 21:41:11.601508  3749 solver.cpp:253]     Train net output #0: loss = 1.19712 (* 1 = 1.19712 loss)
I0523 21:41:11.601526  3749 sgd_solver.cpp:106] Iteration 77750, lr = 0.005
I0523 21:41:20.630797  3749 solver.cpp:237] Iteration 78000, loss = 1.12256
I0523 21:41:20.630975  3749 solver.cpp:253]     Train net output #0: loss = 1.12256 (* 1 = 1.12256 loss)
I0523 21:41:20.630988  3749 sgd_solver.cpp:106] Iteration 78000, lr = 0.005
I0523 21:41:29.659040  3749 solver.cpp:237] Iteration 78250, loss = 1.02276
I0523 21:41:29.659075  3749 solver.cpp:253]     Train net output #0: loss = 1.02276 (* 1 = 1.02276 loss)
I0523 21:41:29.659091  3749 sgd_solver.cpp:106] Iteration 78250, lr = 0.005
I0523 21:41:59.482189  3749 solver.cpp:237] Iteration 78500, loss = 0.771945
I0523 21:41:59.482383  3749 solver.cpp:253]     Train net output #0: loss = 0.771945 (* 1 = 0.771945 loss)
I0523 21:41:59.482398  3749 sgd_solver.cpp:106] Iteration 78500, lr = 0.005
I0523 21:42:08.515697  3749 solver.cpp:237] Iteration 78750, loss = 0.913634
I0523 21:42:08.515743  3749 solver.cpp:253]     Train net output #0: loss = 0.913634 (* 1 = 0.913634 loss)
I0523 21:42:08.515758  3749 sgd_solver.cpp:106] Iteration 78750, lr = 0.005
I0523 21:42:17.549204  3749 solver.cpp:237] Iteration 79000, loss = 1.17148
I0523 21:42:17.549238  3749 solver.cpp:253]     Train net output #0: loss = 1.17148 (* 1 = 1.17148 loss)
I0523 21:42:17.549257  3749 sgd_solver.cpp:106] Iteration 79000, lr = 0.005
I0523 21:42:26.577963  3749 solver.cpp:237] Iteration 79250, loss = 1.06921
I0523 21:42:26.577998  3749 solver.cpp:253]     Train net output #0: loss = 1.06921 (* 1 = 1.06921 loss)
I0523 21:42:26.578014  3749 sgd_solver.cpp:106] Iteration 79250, lr = 0.005
I0523 21:42:35.604261  3749 solver.cpp:237] Iteration 79500, loss = 1.13363
I0523 21:42:35.604440  3749 solver.cpp:253]     Train net output #0: loss = 1.13363 (* 1 = 1.13363 loss)
I0523 21:42:35.604454  3749 sgd_solver.cpp:106] Iteration 79500, lr = 0.005
I0523 21:42:44.634536  3749 solver.cpp:237] Iteration 79750, loss = 1.32628
I0523 21:42:44.634572  3749 solver.cpp:253]     Train net output #0: loss = 1.32628 (* 1 = 1.32628 loss)
I0523 21:42:44.634588  3749 sgd_solver.cpp:106] Iteration 79750, lr = 0.005
I0523 21:42:53.635068  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_80000.caffemodel
I0523 21:42:53.696913  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_80000.solverstate
I0523 21:42:53.723274  3749 solver.cpp:341] Iteration 80000, Testing net (#0)
I0523 21:44:01.734016  3749 solver.cpp:409]     Test net output #0: accuracy = 0.895205
I0523 21:44:01.734202  3749 solver.cpp:409]     Test net output #1: loss = 0.326491 (* 1 = 0.326491 loss)
I0523 21:44:22.581151  3749 solver.cpp:237] Iteration 80000, loss = 1.03873
I0523 21:44:22.581202  3749 solver.cpp:253]     Train net output #0: loss = 1.03873 (* 1 = 1.03873 loss)
I0523 21:44:22.581219  3749 sgd_solver.cpp:106] Iteration 80000, lr = 0.005
I0523 21:44:31.638159  3749 solver.cpp:237] Iteration 80250, loss = 1.14661
I0523 21:44:31.638193  3749 solver.cpp:253]     Train net output #0: loss = 1.14661 (* 1 = 1.14661 loss)
I0523 21:44:31.638211  3749 sgd_solver.cpp:106] Iteration 80250, lr = 0.005
I0523 21:44:40.702457  3749 solver.cpp:237] Iteration 80500, loss = 1.19148
I0523 21:44:40.702639  3749 solver.cpp:253]     Train net output #0: loss = 1.19148 (* 1 = 1.19148 loss)
I0523 21:44:40.702653  3749 sgd_solver.cpp:106] Iteration 80500, lr = 0.005
I0523 21:44:49.752820  3749 solver.cpp:237] Iteration 80750, loss = 1.14469
I0523 21:44:49.752854  3749 solver.cpp:253]     Train net output #0: loss = 1.14469 (* 1 = 1.14469 loss)
I0523 21:44:49.752869  3749 sgd_solver.cpp:106] Iteration 80750, lr = 0.005
I0523 21:44:58.806226  3749 solver.cpp:237] Iteration 81000, loss = 1.08593
I0523 21:44:58.806262  3749 solver.cpp:253]     Train net output #0: loss = 1.08593 (* 1 = 1.08593 loss)
I0523 21:44:58.806278  3749 sgd_solver.cpp:106] Iteration 81000, lr = 0.005
I0523 21:45:07.864500  3749 solver.cpp:237] Iteration 81250, loss = 1.17353
I0523 21:45:07.864545  3749 solver.cpp:253]     Train net output #0: loss = 1.17353 (* 1 = 1.17353 loss)
I0523 21:45:07.864563  3749 sgd_solver.cpp:106] Iteration 81250, lr = 0.005
I0523 21:45:16.922160  3749 solver.cpp:237] Iteration 81500, loss = 0.913412
I0523 21:45:16.922348  3749 solver.cpp:253]     Train net output #0: loss = 0.913412 (* 1 = 0.913412 loss)
I0523 21:45:16.922363  3749 sgd_solver.cpp:106] Iteration 81500, lr = 0.005
I0523 21:45:46.817155  3749 solver.cpp:237] Iteration 81750, loss = 1.33496
I0523 21:45:46.817208  3749 solver.cpp:253]     Train net output #0: loss = 1.33496 (* 1 = 1.33496 loss)
I0523 21:45:46.817220  3749 sgd_solver.cpp:106] Iteration 81750, lr = 0.005
I0523 21:45:55.872339  3749 solver.cpp:237] Iteration 82000, loss = 1.04691
I0523 21:45:55.872516  3749 solver.cpp:253]     Train net output #0: loss = 1.04691 (* 1 = 1.04691 loss)
I0523 21:45:55.872531  3749 sgd_solver.cpp:106] Iteration 82000, lr = 0.005
I0523 21:46:04.929512  3749 solver.cpp:237] Iteration 82250, loss = 1.53777
I0523 21:46:04.929548  3749 solver.cpp:253]     Train net output #0: loss = 1.53777 (* 1 = 1.53777 loss)
I0523 21:46:04.929565  3749 sgd_solver.cpp:106] Iteration 82250, lr = 0.005
I0523 21:46:13.951982  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_82500.caffemodel
I0523 21:46:14.015424  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_82500.solverstate
I0523 21:46:14.052796  3749 solver.cpp:237] Iteration 82500, loss = 1.22037
I0523 21:46:14.052842  3749 solver.cpp:253]     Train net output #0: loss = 1.22037 (* 1 = 1.22037 loss)
I0523 21:46:14.052856  3749 sgd_solver.cpp:106] Iteration 82500, lr = 0.005
I0523 21:46:23.108160  3749 solver.cpp:237] Iteration 82750, loss = 1.01916
I0523 21:46:23.108197  3749 solver.cpp:253]     Train net output #0: loss = 1.01916 (* 1 = 1.01916 loss)
I0523 21:46:23.108218  3749 sgd_solver.cpp:106] Iteration 82750, lr = 0.005
I0523 21:46:32.175525  3749 solver.cpp:237] Iteration 83000, loss = 0.821225
I0523 21:46:32.175680  3749 solver.cpp:253]     Train net output #0: loss = 0.821225 (* 1 = 0.821225 loss)
I0523 21:46:32.175694  3749 sgd_solver.cpp:106] Iteration 83000, lr = 0.005
I0523 21:46:41.241550  3749 solver.cpp:237] Iteration 83250, loss = 1.2079
I0523 21:46:41.241595  3749 solver.cpp:253]     Train net output #0: loss = 1.2079 (* 1 = 1.2079 loss)
I0523 21:46:41.241613  3749 sgd_solver.cpp:106] Iteration 83250, lr = 0.005
I0523 21:47:11.093322  3749 solver.cpp:237] Iteration 83500, loss = 1.21998
I0523 21:47:11.093511  3749 solver.cpp:253]     Train net output #0: loss = 1.21998 (* 1 = 1.21998 loss)
I0523 21:47:11.093525  3749 sgd_solver.cpp:106] Iteration 83500, lr = 0.005
I0523 21:47:20.161435  3749 solver.cpp:237] Iteration 83750, loss = 1.20459
I0523 21:47:20.161470  3749 solver.cpp:253]     Train net output #0: loss = 1.20459 (* 1 = 1.20459 loss)
I0523 21:47:20.161487  3749 sgd_solver.cpp:106] Iteration 83750, lr = 0.005
I0523 21:47:29.225824  3749 solver.cpp:237] Iteration 84000, loss = 1.0619
I0523 21:47:29.225858  3749 solver.cpp:253]     Train net output #0: loss = 1.0619 (* 1 = 1.0619 loss)
I0523 21:47:29.225878  3749 sgd_solver.cpp:106] Iteration 84000, lr = 0.005
I0523 21:47:38.281484  3749 solver.cpp:237] Iteration 84250, loss = 1.10978
I0523 21:47:38.281519  3749 solver.cpp:253]     Train net output #0: loss = 1.10978 (* 1 = 1.10978 loss)
I0523 21:47:38.281538  3749 sgd_solver.cpp:106] Iteration 84250, lr = 0.005
I0523 21:47:47.339692  3749 solver.cpp:237] Iteration 84500, loss = 0.928509
I0523 21:47:47.339861  3749 solver.cpp:253]     Train net output #0: loss = 0.928509 (* 1 = 0.928509 loss)
I0523 21:47:47.339875  3749 sgd_solver.cpp:106] Iteration 84500, lr = 0.005
I0523 21:47:56.405288  3749 solver.cpp:237] Iteration 84750, loss = 0.821154
I0523 21:47:56.405328  3749 solver.cpp:253]     Train net output #0: loss = 0.821154 (* 1 = 0.821154 loss)
I0523 21:47:56.405349  3749 sgd_solver.cpp:106] Iteration 84750, lr = 0.005
I0523 21:48:05.432176  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_85000.caffemodel
I0523 21:48:05.495380  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_85000.solverstate
I0523 21:48:05.521759  3749 solver.cpp:341] Iteration 85000, Testing net (#0)
I0523 21:48:52.801023  3749 solver.cpp:409]     Test net output #0: accuracy = 0.894379
I0523 21:48:52.801223  3749 solver.cpp:409]     Test net output #1: loss = 0.354439 (* 1 = 0.354439 loss)
I0523 21:49:13.633263  3749 solver.cpp:237] Iteration 85000, loss = 0.999882
I0523 21:49:13.633318  3749 solver.cpp:253]     Train net output #0: loss = 0.999882 (* 1 = 0.999882 loss)
I0523 21:49:13.633335  3749 sgd_solver.cpp:106] Iteration 85000, lr = 0.005
I0523 21:49:22.638130  3749 solver.cpp:237] Iteration 85250, loss = 1.1046
I0523 21:49:22.638164  3749 solver.cpp:253]     Train net output #0: loss = 1.1046 (* 1 = 1.1046 loss)
I0523 21:49:22.638178  3749 sgd_solver.cpp:106] Iteration 85250, lr = 0.005
I0523 21:49:31.643893  3749 solver.cpp:237] Iteration 85500, loss = 1.27523
I0523 21:49:31.644068  3749 solver.cpp:253]     Train net output #0: loss = 1.27523 (* 1 = 1.27523 loss)
I0523 21:49:31.644081  3749 sgd_solver.cpp:106] Iteration 85500, lr = 0.005
I0523 21:49:40.658993  3749 solver.cpp:237] Iteration 85750, loss = 1.01774
I0523 21:49:40.659032  3749 solver.cpp:253]     Train net output #0: loss = 1.01774 (* 1 = 1.01774 loss)
I0523 21:49:40.659052  3749 sgd_solver.cpp:106] Iteration 85750, lr = 0.005
I0523 21:49:49.666666  3749 solver.cpp:237] Iteration 86000, loss = 1.11336
I0523 21:49:49.666702  3749 solver.cpp:253]     Train net output #0: loss = 1.11336 (* 1 = 1.11336 loss)
I0523 21:49:49.666719  3749 sgd_solver.cpp:106] Iteration 86000, lr = 0.005
I0523 21:49:58.684234  3749 solver.cpp:237] Iteration 86250, loss = 1.04575
I0523 21:49:58.684270  3749 solver.cpp:253]     Train net output #0: loss = 1.04575 (* 1 = 1.04575 loss)
I0523 21:49:58.684285  3749 sgd_solver.cpp:106] Iteration 86250, lr = 0.005
I0523 21:50:07.695569  3749 solver.cpp:237] Iteration 86500, loss = 0.951182
I0523 21:50:07.695787  3749 solver.cpp:253]     Train net output #0: loss = 0.951182 (* 1 = 0.951182 loss)
I0523 21:50:07.695801  3749 sgd_solver.cpp:106] Iteration 86500, lr = 0.005
I0523 21:50:37.559186  3749 solver.cpp:237] Iteration 86750, loss = 1.10538
I0523 21:50:37.559242  3749 solver.cpp:253]     Train net output #0: loss = 1.10538 (* 1 = 1.10538 loss)
I0523 21:50:37.559257  3749 sgd_solver.cpp:106] Iteration 86750, lr = 0.005
I0523 21:50:46.569744  3749 solver.cpp:237] Iteration 87000, loss = 1.22878
I0523 21:50:46.569918  3749 solver.cpp:253]     Train net output #0: loss = 1.22878 (* 1 = 1.22878 loss)
I0523 21:50:46.569931  3749 sgd_solver.cpp:106] Iteration 87000, lr = 0.005
I0523 21:50:55.576503  3749 solver.cpp:237] Iteration 87250, loss = 1.08586
I0523 21:50:55.576550  3749 solver.cpp:253]     Train net output #0: loss = 1.08586 (* 1 = 1.08586 loss)
I0523 21:50:55.576566  3749 sgd_solver.cpp:106] Iteration 87250, lr = 0.005
I0523 21:51:04.547822  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_87500.caffemodel
I0523 21:51:04.612653  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_87500.solverstate
I0523 21:51:04.652638  3749 solver.cpp:237] Iteration 87500, loss = 1.02156
I0523 21:51:04.652684  3749 solver.cpp:253]     Train net output #0: loss = 1.02156 (* 1 = 1.02156 loss)
I0523 21:51:04.652698  3749 sgd_solver.cpp:106] Iteration 87500, lr = 0.005
I0523 21:51:13.660397  3749 solver.cpp:237] Iteration 87750, loss = 1.03381
I0523 21:51:13.660432  3749 solver.cpp:253]     Train net output #0: loss = 1.03381 (* 1 = 1.03381 loss)
I0523 21:51:13.660449  3749 sgd_solver.cpp:106] Iteration 87750, lr = 0.005
I0523 21:51:22.677578  3749 solver.cpp:237] Iteration 88000, loss = 1.12691
I0523 21:51:22.677770  3749 solver.cpp:253]     Train net output #0: loss = 1.12691 (* 1 = 1.12691 loss)
I0523 21:51:22.677784  3749 sgd_solver.cpp:106] Iteration 88000, lr = 0.005
I0523 21:51:31.689735  3749 solver.cpp:237] Iteration 88250, loss = 1.31308
I0523 21:51:31.689771  3749 solver.cpp:253]     Train net output #0: loss = 1.31308 (* 1 = 1.31308 loss)
I0523 21:51:31.689787  3749 sgd_solver.cpp:106] Iteration 88250, lr = 0.005
I0523 21:52:01.531796  3749 solver.cpp:237] Iteration 88500, loss = 1.10664
I0523 21:52:01.531986  3749 solver.cpp:253]     Train net output #0: loss = 1.10664 (* 1 = 1.10664 loss)
I0523 21:52:01.532002  3749 sgd_solver.cpp:106] Iteration 88500, lr = 0.005
I0523 21:52:10.543985  3749 solver.cpp:237] Iteration 88750, loss = 1.20232
I0523 21:52:10.544034  3749 solver.cpp:253]     Train net output #0: loss = 1.20232 (* 1 = 1.20232 loss)
I0523 21:52:10.544049  3749 sgd_solver.cpp:106] Iteration 88750, lr = 0.005
I0523 21:52:19.555377  3749 solver.cpp:237] Iteration 89000, loss = 1.09071
I0523 21:52:19.555413  3749 solver.cpp:253]     Train net output #0: loss = 1.09071 (* 1 = 1.09071 loss)
I0523 21:52:19.555426  3749 sgd_solver.cpp:106] Iteration 89000, lr = 0.005
I0523 21:52:28.567396  3749 solver.cpp:237] Iteration 89250, loss = 1.12537
I0523 21:52:28.567432  3749 solver.cpp:253]     Train net output #0: loss = 1.12537 (* 1 = 1.12537 loss)
I0523 21:52:28.567448  3749 sgd_solver.cpp:106] Iteration 89250, lr = 0.005
I0523 21:52:37.577661  3749 solver.cpp:237] Iteration 89500, loss = 1.22129
I0523 21:52:37.577844  3749 solver.cpp:253]     Train net output #0: loss = 1.22129 (* 1 = 1.22129 loss)
I0523 21:52:37.577859  3749 sgd_solver.cpp:106] Iteration 89500, lr = 0.005
I0523 21:52:46.594733  3749 solver.cpp:237] Iteration 89750, loss = 0.853317
I0523 21:52:46.594769  3749 solver.cpp:253]     Train net output #0: loss = 0.853317 (* 1 = 0.853317 loss)
I0523 21:52:46.594785  3749 sgd_solver.cpp:106] Iteration 89750, lr = 0.005
I0523 21:52:55.571135  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_90000.caffemodel
I0523 21:52:55.637258  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_90000.solverstate
I0523 21:52:55.669440  3749 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 21:54:03.692390  3749 solver.cpp:409]     Test net output #0: accuracy = 0.897691
I0523 21:54:03.692589  3749 solver.cpp:409]     Test net output #1: loss = 0.312982 (* 1 = 0.312982 loss)
I0523 21:54:24.479460  3749 solver.cpp:237] Iteration 90000, loss = 1.12865
I0523 21:54:24.479513  3749 solver.cpp:253]     Train net output #0: loss = 1.12865 (* 1 = 1.12865 loss)
I0523 21:54:24.479528  3749 sgd_solver.cpp:106] Iteration 90000, lr = 0.005
I0523 21:54:33.581147  3749 solver.cpp:237] Iteration 90250, loss = 0.981257
I0523 21:54:33.581182  3749 solver.cpp:253]     Train net output #0: loss = 0.981257 (* 1 = 0.981257 loss)
I0523 21:54:33.581199  3749 sgd_solver.cpp:106] Iteration 90250, lr = 0.005
I0523 21:54:42.690402  3749 solver.cpp:237] Iteration 90500, loss = 1.28553
I0523 21:54:42.690587  3749 solver.cpp:253]     Train net output #0: loss = 1.28553 (* 1 = 1.28553 loss)
I0523 21:54:42.690601  3749 sgd_solver.cpp:106] Iteration 90500, lr = 0.005
I0523 21:54:51.790037  3749 solver.cpp:237] Iteration 90750, loss = 1.10422
I0523 21:54:51.790072  3749 solver.cpp:253]     Train net output #0: loss = 1.10422 (* 1 = 1.10422 loss)
I0523 21:54:51.790091  3749 sgd_solver.cpp:106] Iteration 90750, lr = 0.005
I0523 21:55:00.892523  3749 solver.cpp:237] Iteration 91000, loss = 1.37669
I0523 21:55:00.892560  3749 solver.cpp:253]     Train net output #0: loss = 1.37669 (* 1 = 1.37669 loss)
I0523 21:55:00.892573  3749 sgd_solver.cpp:106] Iteration 91000, lr = 0.005
I0523 21:55:09.995545  3749 solver.cpp:237] Iteration 91250, loss = 1.0674
I0523 21:55:09.995581  3749 solver.cpp:253]     Train net output #0: loss = 1.0674 (* 1 = 1.0674 loss)
I0523 21:55:09.995597  3749 sgd_solver.cpp:106] Iteration 91250, lr = 0.005
I0523 21:55:19.093989  3749 solver.cpp:237] Iteration 91500, loss = 0.905758
I0523 21:55:19.094169  3749 solver.cpp:253]     Train net output #0: loss = 0.905759 (* 1 = 0.905759 loss)
I0523 21:55:19.094183  3749 sgd_solver.cpp:106] Iteration 91500, lr = 0.005
I0523 21:55:49.019747  3749 solver.cpp:237] Iteration 91750, loss = 1.12922
I0523 21:55:49.019798  3749 solver.cpp:253]     Train net output #0: loss = 1.12922 (* 1 = 1.12922 loss)
I0523 21:55:49.019814  3749 sgd_solver.cpp:106] Iteration 91750, lr = 0.005
I0523 21:55:58.129382  3749 solver.cpp:237] Iteration 92000, loss = 1.13819
I0523 21:55:58.129565  3749 solver.cpp:253]     Train net output #0: loss = 1.13819 (* 1 = 1.13819 loss)
I0523 21:55:58.129580  3749 sgd_solver.cpp:106] Iteration 92000, lr = 0.005
I0523 21:56:07.235955  3749 solver.cpp:237] Iteration 92250, loss = 1.0714
I0523 21:56:07.235991  3749 solver.cpp:253]     Train net output #0: loss = 1.0714 (* 1 = 1.0714 loss)
I0523 21:56:07.236007  3749 sgd_solver.cpp:106] Iteration 92250, lr = 0.005
I0523 21:56:16.294637  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_92500.caffemodel
I0523 21:56:16.357450  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_92500.solverstate
I0523 21:56:16.394996  3749 solver.cpp:237] Iteration 92500, loss = 1.2519
I0523 21:56:16.395037  3749 solver.cpp:253]     Train net output #0: loss = 1.2519 (* 1 = 1.2519 loss)
I0523 21:56:16.395056  3749 sgd_solver.cpp:106] Iteration 92500, lr = 0.005
I0523 21:56:25.504050  3749 solver.cpp:237] Iteration 92750, loss = 0.968316
I0523 21:56:25.504086  3749 solver.cpp:253]     Train net output #0: loss = 0.968316 (* 1 = 0.968316 loss)
I0523 21:56:25.504102  3749 sgd_solver.cpp:106] Iteration 92750, lr = 0.005
I0523 21:56:34.601493  3749 solver.cpp:237] Iteration 93000, loss = 1.13782
I0523 21:56:34.601665  3749 solver.cpp:253]     Train net output #0: loss = 1.13782 (* 1 = 1.13782 loss)
I0523 21:56:34.601678  3749 sgd_solver.cpp:106] Iteration 93000, lr = 0.005
I0523 21:56:43.702818  3749 solver.cpp:237] Iteration 93250, loss = 1.28807
I0523 21:56:43.702862  3749 solver.cpp:253]     Train net output #0: loss = 1.28807 (* 1 = 1.28807 loss)
I0523 21:56:43.702882  3749 sgd_solver.cpp:106] Iteration 93250, lr = 0.005
I0523 21:57:13.631860  3749 solver.cpp:237] Iteration 93500, loss = 1.019
I0523 21:57:13.632052  3749 solver.cpp:253]     Train net output #0: loss = 1.019 (* 1 = 1.019 loss)
I0523 21:57:13.632066  3749 sgd_solver.cpp:106] Iteration 93500, lr = 0.005
I0523 21:57:22.737437  3749 solver.cpp:237] Iteration 93750, loss = 1.37394
I0523 21:57:22.737471  3749 solver.cpp:253]     Train net output #0: loss = 1.37394 (* 1 = 1.37394 loss)
I0523 21:57:22.737490  3749 sgd_solver.cpp:106] Iteration 93750, lr = 0.005
I0523 21:57:31.836690  3749 solver.cpp:237] Iteration 94000, loss = 0.94209
I0523 21:57:31.836740  3749 solver.cpp:253]     Train net output #0: loss = 0.94209 (* 1 = 0.94209 loss)
I0523 21:57:31.836755  3749 sgd_solver.cpp:106] Iteration 94000, lr = 0.005
I0523 21:57:40.932723  3749 solver.cpp:237] Iteration 94250, loss = 0.992192
I0523 21:57:40.932760  3749 solver.cpp:253]     Train net output #0: loss = 0.992193 (* 1 = 0.992193 loss)
I0523 21:57:40.932775  3749 sgd_solver.cpp:106] Iteration 94250, lr = 0.005
I0523 21:57:50.041976  3749 solver.cpp:237] Iteration 94500, loss = 1.0143
I0523 21:57:50.042150  3749 solver.cpp:253]     Train net output #0: loss = 1.0143 (* 1 = 1.0143 loss)
I0523 21:57:50.042163  3749 sgd_solver.cpp:106] Iteration 94500, lr = 0.005
I0523 21:57:59.148054  3749 solver.cpp:237] Iteration 94750, loss = 1.23435
I0523 21:57:59.148097  3749 solver.cpp:253]     Train net output #0: loss = 1.23435 (* 1 = 1.23435 loss)
I0523 21:57:59.148118  3749 sgd_solver.cpp:106] Iteration 94750, lr = 0.005
I0523 21:58:08.209141  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_95000.caffemodel
I0523 21:58:08.272658  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_95000.solverstate
I0523 21:58:08.299150  3749 solver.cpp:341] Iteration 95000, Testing net (#0)
I0523 21:58:55.175897  3749 solver.cpp:409]     Test net output #0: accuracy = 0.898638
I0523 21:58:55.176096  3749 solver.cpp:409]     Test net output #1: loss = 0.32564 (* 1 = 0.32564 loss)
I0523 21:59:15.981902  3749 solver.cpp:237] Iteration 95000, loss = 1.38843
I0523 21:59:15.981955  3749 solver.cpp:253]     Train net output #0: loss = 1.38843 (* 1 = 1.38843 loss)
I0523 21:59:15.981971  3749 sgd_solver.cpp:106] Iteration 95000, lr = 0.005
I0523 21:59:25.057431  3749 solver.cpp:237] Iteration 95250, loss = 1.18402
I0523 21:59:25.057467  3749 solver.cpp:253]     Train net output #0: loss = 1.18402 (* 1 = 1.18402 loss)
I0523 21:59:25.057483  3749 sgd_solver.cpp:106] Iteration 95250, lr = 0.005
I0523 21:59:34.137049  3749 solver.cpp:237] Iteration 95500, loss = 1.23426
I0523 21:59:34.137225  3749 solver.cpp:253]     Train net output #0: loss = 1.23426 (* 1 = 1.23426 loss)
I0523 21:59:34.137239  3749 sgd_solver.cpp:106] Iteration 95500, lr = 0.005
I0523 21:59:43.208731  3749 solver.cpp:237] Iteration 95750, loss = 0.817243
I0523 21:59:43.208768  3749 solver.cpp:253]     Train net output #0: loss = 0.817244 (* 1 = 0.817244 loss)
I0523 21:59:43.208791  3749 sgd_solver.cpp:106] Iteration 95750, lr = 0.005
I0523 21:59:52.276401  3749 solver.cpp:237] Iteration 96000, loss = 0.947334
I0523 21:59:52.276437  3749 solver.cpp:253]     Train net output #0: loss = 0.947334 (* 1 = 0.947334 loss)
I0523 21:59:52.276453  3749 sgd_solver.cpp:106] Iteration 96000, lr = 0.005
I0523 22:00:01.350142  3749 solver.cpp:237] Iteration 96250, loss = 1.09869
I0523 22:00:01.350183  3749 solver.cpp:253]     Train net output #0: loss = 1.09869 (* 1 = 1.09869 loss)
I0523 22:00:01.350200  3749 sgd_solver.cpp:106] Iteration 96250, lr = 0.005
I0523 22:00:10.428658  3749 solver.cpp:237] Iteration 96500, loss = 0.977127
I0523 22:00:10.428834  3749 solver.cpp:253]     Train net output #0: loss = 0.977127 (* 1 = 0.977127 loss)
I0523 22:00:10.428848  3749 sgd_solver.cpp:106] Iteration 96500, lr = 0.005
I0523 22:00:40.243239  3749 solver.cpp:237] Iteration 96750, loss = 1.0418
I0523 22:00:40.243289  3749 solver.cpp:253]     Train net output #0: loss = 1.0418 (* 1 = 1.0418 loss)
I0523 22:00:40.243307  3749 sgd_solver.cpp:106] Iteration 96750, lr = 0.005
I0523 22:00:49.313194  3749 solver.cpp:237] Iteration 97000, loss = 1.06994
I0523 22:00:49.313372  3749 solver.cpp:253]     Train net output #0: loss = 1.06994 (* 1 = 1.06994 loss)
I0523 22:00:49.313386  3749 sgd_solver.cpp:106] Iteration 97000, lr = 0.005
I0523 22:00:58.392678  3749 solver.cpp:237] Iteration 97250, loss = 1.25409
I0523 22:00:58.392714  3749 solver.cpp:253]     Train net output #0: loss = 1.25409 (* 1 = 1.25409 loss)
I0523 22:00:58.392737  3749 sgd_solver.cpp:106] Iteration 97250, lr = 0.005
I0523 22:01:07.432915  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_97500.caffemodel
I0523 22:01:07.496459  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_97500.solverstate
I0523 22:01:07.533985  3749 solver.cpp:237] Iteration 97500, loss = 1.54756
I0523 22:01:07.534031  3749 solver.cpp:253]     Train net output #0: loss = 1.54756 (* 1 = 1.54756 loss)
I0523 22:01:07.534045  3749 sgd_solver.cpp:106] Iteration 97500, lr = 0.005
I0523 22:01:16.609813  3749 solver.cpp:237] Iteration 97750, loss = 1.38379
I0523 22:01:16.609858  3749 solver.cpp:253]     Train net output #0: loss = 1.38379 (* 1 = 1.38379 loss)
I0523 22:01:16.609876  3749 sgd_solver.cpp:106] Iteration 97750, lr = 0.005
I0523 22:01:25.678576  3749 solver.cpp:237] Iteration 98000, loss = 1.5988
I0523 22:01:25.678762  3749 solver.cpp:253]     Train net output #0: loss = 1.5988 (* 1 = 1.5988 loss)
I0523 22:01:25.678778  3749 sgd_solver.cpp:106] Iteration 98000, lr = 0.005
I0523 22:01:34.751476  3749 solver.cpp:237] Iteration 98250, loss = 1.18066
I0523 22:01:34.751509  3749 solver.cpp:253]     Train net output #0: loss = 1.18066 (* 1 = 1.18066 loss)
I0523 22:01:34.751523  3749 sgd_solver.cpp:106] Iteration 98250, lr = 0.005
I0523 22:02:04.611371  3749 solver.cpp:237] Iteration 98500, loss = 1.18228
I0523 22:02:04.611565  3749 solver.cpp:253]     Train net output #0: loss = 1.18228 (* 1 = 1.18228 loss)
I0523 22:02:04.611580  3749 sgd_solver.cpp:106] Iteration 98500, lr = 0.005
I0523 22:02:13.685313  3749 solver.cpp:237] Iteration 98750, loss = 1.22142
I0523 22:02:13.685353  3749 solver.cpp:253]     Train net output #0: loss = 1.22142 (* 1 = 1.22142 loss)
I0523 22:02:13.685372  3749 sgd_solver.cpp:106] Iteration 98750, lr = 0.005
I0523 22:02:22.759702  3749 solver.cpp:237] Iteration 99000, loss = 1.16591
I0523 22:02:22.759738  3749 solver.cpp:253]     Train net output #0: loss = 1.16591 (* 1 = 1.16591 loss)
I0523 22:02:22.759754  3749 sgd_solver.cpp:106] Iteration 99000, lr = 0.005
I0523 22:02:31.836539  3749 solver.cpp:237] Iteration 99250, loss = 1.55489
I0523 22:02:31.836580  3749 solver.cpp:253]     Train net output #0: loss = 1.55489 (* 1 = 1.55489 loss)
I0523 22:02:31.836599  3749 sgd_solver.cpp:106] Iteration 99250, lr = 0.005
I0523 22:02:40.908264  3749 solver.cpp:237] Iteration 99500, loss = 0.971318
I0523 22:02:40.908509  3749 solver.cpp:253]     Train net output #0: loss = 0.971318 (* 1 = 0.971318 loss)
I0523 22:02:40.908524  3749 sgd_solver.cpp:106] Iteration 99500, lr = 0.005
I0523 22:02:49.978297  3749 solver.cpp:237] Iteration 99750, loss = 1.1256
I0523 22:02:49.978332  3749 solver.cpp:253]     Train net output #0: loss = 1.1256 (* 1 = 1.1256 loss)
I0523 22:02:49.978349  3749 sgd_solver.cpp:106] Iteration 99750, lr = 0.005
I0523 22:02:59.018965  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_100000.caffemodel
I0523 22:02:59.086591  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_100000.solverstate
I0523 22:02:59.113922  3749 solver.cpp:341] Iteration 100000, Testing net (#0)
I0523 22:04:07.105242  3749 solver.cpp:409]     Test net output #0: accuracy = 0.898678
I0523 22:04:07.105432  3749 solver.cpp:409]     Test net output #1: loss = 0.328827 (* 1 = 0.328827 loss)
I0523 22:04:27.902549  3749 solver.cpp:237] Iteration 100000, loss = 1.36289
I0523 22:04:27.902602  3749 solver.cpp:253]     Train net output #0: loss = 1.36289 (* 1 = 1.36289 loss)
I0523 22:04:27.902618  3749 sgd_solver.cpp:106] Iteration 100000, lr = 0.005
I0523 22:04:37.015780  3749 solver.cpp:237] Iteration 100250, loss = 0.997525
I0523 22:04:37.015823  3749 solver.cpp:253]     Train net output #0: loss = 0.997525 (* 1 = 0.997525 loss)
I0523 22:04:37.015841  3749 sgd_solver.cpp:106] Iteration 100250, lr = 0.005
I0523 22:04:46.128343  3749 solver.cpp:237] Iteration 100500, loss = 1.44335
I0523 22:04:46.128522  3749 solver.cpp:253]     Train net output #0: loss = 1.44335 (* 1 = 1.44335 loss)
I0523 22:04:46.128536  3749 sgd_solver.cpp:106] Iteration 100500, lr = 0.005
I0523 22:04:55.242431  3749 solver.cpp:237] Iteration 100750, loss = 1.26565
I0523 22:04:55.242465  3749 solver.cpp:253]     Train net output #0: loss = 1.26565 (* 1 = 1.26565 loss)
I0523 22:04:55.242485  3749 sgd_solver.cpp:106] Iteration 100750, lr = 0.005
I0523 22:05:04.354141  3749 solver.cpp:237] Iteration 101000, loss = 1.21219
I0523 22:05:04.354188  3749 solver.cpp:253]     Train net output #0: loss = 1.21219 (* 1 = 1.21219 loss)
I0523 22:05:04.354205  3749 sgd_solver.cpp:106] Iteration 101000, lr = 0.005
I0523 22:05:13.470970  3749 solver.cpp:237] Iteration 101250, loss = 1.13233
I0523 22:05:13.471006  3749 solver.cpp:253]     Train net output #0: loss = 1.13233 (* 1 = 1.13233 loss)
I0523 22:05:13.471024  3749 sgd_solver.cpp:106] Iteration 101250, lr = 0.005
I0523 22:05:22.585932  3749 solver.cpp:237] Iteration 101500, loss = 1.27501
I0523 22:05:22.586117  3749 solver.cpp:253]     Train net output #0: loss = 1.27501 (* 1 = 1.27501 loss)
I0523 22:05:22.586132  3749 sgd_solver.cpp:106] Iteration 101500, lr = 0.005
I0523 22:05:52.495546  3749 solver.cpp:237] Iteration 101750, loss = 1.18739
I0523 22:05:52.495595  3749 solver.cpp:253]     Train net output #0: loss = 1.18739 (* 1 = 1.18739 loss)
I0523 22:05:52.495612  3749 sgd_solver.cpp:106] Iteration 101750, lr = 0.005
I0523 22:06:01.603657  3749 solver.cpp:237] Iteration 102000, loss = 1.04233
I0523 22:06:01.603834  3749 solver.cpp:253]     Train net output #0: loss = 1.04233 (* 1 = 1.04233 loss)
I0523 22:06:01.603847  3749 sgd_solver.cpp:106] Iteration 102000, lr = 0.005
I0523 22:06:10.720630  3749 solver.cpp:237] Iteration 102250, loss = 1.74273
I0523 22:06:10.720665  3749 solver.cpp:253]     Train net output #0: loss = 1.74273 (* 1 = 1.74273 loss)
I0523 22:06:10.720681  3749 sgd_solver.cpp:106] Iteration 102250, lr = 0.005
I0523 22:06:19.798740  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_102500.caffemodel
I0523 22:06:19.860877  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_102500.solverstate
I0523 22:06:19.897080  3749 solver.cpp:237] Iteration 102500, loss = 1.29868
I0523 22:06:19.897126  3749 solver.cpp:253]     Train net output #0: loss = 1.29868 (* 1 = 1.29868 loss)
I0523 22:06:19.897140  3749 sgd_solver.cpp:106] Iteration 102500, lr = 0.005
I0523 22:06:29.014920  3749 solver.cpp:237] Iteration 102750, loss = 1.06781
I0523 22:06:29.014955  3749 solver.cpp:253]     Train net output #0: loss = 1.06781 (* 1 = 1.06781 loss)
I0523 22:06:29.014973  3749 sgd_solver.cpp:106] Iteration 102750, lr = 0.005
I0523 22:06:38.128036  3749 solver.cpp:237] Iteration 103000, loss = 1.11119
I0523 22:06:38.128212  3749 solver.cpp:253]     Train net output #0: loss = 1.11119 (* 1 = 1.11119 loss)
I0523 22:06:38.128226  3749 sgd_solver.cpp:106] Iteration 103000, lr = 0.005
I0523 22:06:47.241643  3749 solver.cpp:237] Iteration 103250, loss = 1.06843
I0523 22:06:47.241686  3749 solver.cpp:253]     Train net output #0: loss = 1.06843 (* 1 = 1.06843 loss)
I0523 22:06:47.241704  3749 sgd_solver.cpp:106] Iteration 103250, lr = 0.005
I0523 22:07:17.197029  3749 solver.cpp:237] Iteration 103500, loss = 1.11596
I0523 22:07:17.197218  3749 solver.cpp:253]     Train net output #0: loss = 1.11596 (* 1 = 1.11596 loss)
I0523 22:07:17.197232  3749 sgd_solver.cpp:106] Iteration 103500, lr = 0.005
I0523 22:07:26.300990  3749 solver.cpp:237] Iteration 103750, loss = 0.969184
I0523 22:07:26.301025  3749 solver.cpp:253]     Train net output #0: loss = 0.969184 (* 1 = 0.969184 loss)
I0523 22:07:26.301043  3749 sgd_solver.cpp:106] Iteration 103750, lr = 0.005
I0523 22:07:35.417783  3749 solver.cpp:237] Iteration 104000, loss = 1.39714
I0523 22:07:35.417829  3749 solver.cpp:253]     Train net output #0: loss = 1.39714 (* 1 = 1.39714 loss)
I0523 22:07:35.417842  3749 sgd_solver.cpp:106] Iteration 104000, lr = 0.005
I0523 22:07:44.537428  3749 solver.cpp:237] Iteration 104250, loss = 0.94313
I0523 22:07:44.537466  3749 solver.cpp:253]     Train net output #0: loss = 0.94313 (* 1 = 0.94313 loss)
I0523 22:07:44.537480  3749 sgd_solver.cpp:106] Iteration 104250, lr = 0.005
I0523 22:07:53.656177  3749 solver.cpp:237] Iteration 104500, loss = 1.2439
I0523 22:07:53.656359  3749 solver.cpp:253]     Train net output #0: loss = 1.2439 (* 1 = 1.2439 loss)
I0523 22:07:53.656373  3749 sgd_solver.cpp:106] Iteration 104500, lr = 0.005
I0523 22:08:02.767765  3749 solver.cpp:237] Iteration 104750, loss = 1.26299
I0523 22:08:02.767801  3749 solver.cpp:253]     Train net output #0: loss = 1.26299 (* 1 = 1.26299 loss)
I0523 22:08:02.767822  3749 sgd_solver.cpp:106] Iteration 104750, lr = 0.005
I0523 22:08:11.840107  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_105000.caffemodel
I0523 22:08:11.904337  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_105000.solverstate
I0523 22:08:11.930511  3749 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 22:08:59.128128  3749 solver.cpp:409]     Test net output #0: accuracy = 0.898544
I0523 22:08:59.128324  3749 solver.cpp:409]     Test net output #1: loss = 0.309418 (* 1 = 0.309418 loss)
I0523 22:09:19.937922  3749 solver.cpp:237] Iteration 105000, loss = 1.02771
I0523 22:09:19.937975  3749 solver.cpp:253]     Train net output #0: loss = 1.02771 (* 1 = 1.02771 loss)
I0523 22:09:19.937990  3749 sgd_solver.cpp:106] Iteration 105000, lr = 0.005
I0523 22:09:28.962707  3749 solver.cpp:237] Iteration 105250, loss = 1.27218
I0523 22:09:28.962743  3749 solver.cpp:253]     Train net output #0: loss = 1.27218 (* 1 = 1.27218 loss)
I0523 22:09:28.962760  3749 sgd_solver.cpp:106] Iteration 105250, lr = 0.005
I0523 22:09:37.991938  3749 solver.cpp:237] Iteration 105500, loss = 1.00818
I0523 22:09:37.992131  3749 solver.cpp:253]     Train net output #0: loss = 1.00818 (* 1 = 1.00818 loss)
I0523 22:09:37.992146  3749 sgd_solver.cpp:106] Iteration 105500, lr = 0.005
I0523 22:09:47.020649  3749 solver.cpp:237] Iteration 105750, loss = 1.21084
I0523 22:09:47.020685  3749 solver.cpp:253]     Train net output #0: loss = 1.21084 (* 1 = 1.21084 loss)
I0523 22:09:47.020699  3749 sgd_solver.cpp:106] Iteration 105750, lr = 0.005
I0523 22:09:56.049140  3749 solver.cpp:237] Iteration 106000, loss = 1.0417
I0523 22:09:56.049175  3749 solver.cpp:253]     Train net output #0: loss = 1.0417 (* 1 = 1.0417 loss)
I0523 22:09:56.049191  3749 sgd_solver.cpp:106] Iteration 106000, lr = 0.005
I0523 22:10:05.085166  3749 solver.cpp:237] Iteration 106250, loss = 1.05776
I0523 22:10:05.085206  3749 solver.cpp:253]     Train net output #0: loss = 1.05776 (* 1 = 1.05776 loss)
I0523 22:10:05.085227  3749 sgd_solver.cpp:106] Iteration 106250, lr = 0.005
I0523 22:10:14.111985  3749 solver.cpp:237] Iteration 106500, loss = 1.11761
I0523 22:10:14.112160  3749 solver.cpp:253]     Train net output #0: loss = 1.11761 (* 1 = 1.11761 loss)
I0523 22:10:14.112174  3749 sgd_solver.cpp:106] Iteration 106500, lr = 0.005
I0523 22:10:43.993564  3749 solver.cpp:237] Iteration 106750, loss = 1.07127
I0523 22:10:43.993615  3749 solver.cpp:253]     Train net output #0: loss = 1.07127 (* 1 = 1.07127 loss)
I0523 22:10:43.993631  3749 sgd_solver.cpp:106] Iteration 106750, lr = 0.005
I0523 22:10:53.026478  3749 solver.cpp:237] Iteration 107000, loss = 0.920111
I0523 22:10:53.026681  3749 solver.cpp:253]     Train net output #0: loss = 0.920111 (* 1 = 0.920111 loss)
I0523 22:10:53.026696  3749 sgd_solver.cpp:106] Iteration 107000, lr = 0.005
I0523 22:11:02.052724  3749 solver.cpp:237] Iteration 107250, loss = 1.0151
I0523 22:11:02.052760  3749 solver.cpp:253]     Train net output #0: loss = 1.0151 (* 1 = 1.0151 loss)
I0523 22:11:02.052777  3749 sgd_solver.cpp:106] Iteration 107250, lr = 0.005
I0523 22:11:11.048636  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_107500.caffemodel
I0523 22:11:11.111325  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_107500.solverstate
I0523 22:11:11.147753  3749 solver.cpp:237] Iteration 107500, loss = 1.06754
I0523 22:11:11.147799  3749 solver.cpp:253]     Train net output #0: loss = 1.06754 (* 1 = 1.06754 loss)
I0523 22:11:11.147812  3749 sgd_solver.cpp:106] Iteration 107500, lr = 0.005
I0523 22:11:20.179600  3749 solver.cpp:237] Iteration 107750, loss = 1.19324
I0523 22:11:20.179648  3749 solver.cpp:253]     Train net output #0: loss = 1.19324 (* 1 = 1.19324 loss)
I0523 22:11:20.179666  3749 sgd_solver.cpp:106] Iteration 107750, lr = 0.005
I0523 22:11:29.211879  3749 solver.cpp:237] Iteration 108000, loss = 1.11162
I0523 22:11:29.212067  3749 solver.cpp:253]     Train net output #0: loss = 1.11162 (* 1 = 1.11162 loss)
I0523 22:11:29.212080  3749 sgd_solver.cpp:106] Iteration 108000, lr = 0.005
I0523 22:11:38.244920  3749 solver.cpp:237] Iteration 108250, loss = 1.04899
I0523 22:11:38.244956  3749 solver.cpp:253]     Train net output #0: loss = 1.04899 (* 1 = 1.04899 loss)
I0523 22:11:38.244972  3749 sgd_solver.cpp:106] Iteration 108250, lr = 0.005
I0523 22:12:08.058389  3749 solver.cpp:237] Iteration 108500, loss = 1.25713
I0523 22:12:08.058586  3749 solver.cpp:253]     Train net output #0: loss = 1.25713 (* 1 = 1.25713 loss)
I0523 22:12:08.058601  3749 sgd_solver.cpp:106] Iteration 108500, lr = 0.005
I0523 22:12:17.081248  3749 solver.cpp:237] Iteration 108750, loss = 1.20735
I0523 22:12:17.081284  3749 solver.cpp:253]     Train net output #0: loss = 1.20735 (* 1 = 1.20735 loss)
I0523 22:12:17.081301  3749 sgd_solver.cpp:106] Iteration 108750, lr = 0.005
I0523 22:12:26.104290  3749 solver.cpp:237] Iteration 109000, loss = 1.12758
I0523 22:12:26.104326  3749 solver.cpp:253]     Train net output #0: loss = 1.12758 (* 1 = 1.12758 loss)
I0523 22:12:26.104342  3749 sgd_solver.cpp:106] Iteration 109000, lr = 0.005
I0523 22:12:35.133523  3749 solver.cpp:237] Iteration 109250, loss = 0.932519
I0523 22:12:35.133574  3749 solver.cpp:253]     Train net output #0: loss = 0.932519 (* 1 = 0.932519 loss)
I0523 22:12:35.133589  3749 sgd_solver.cpp:106] Iteration 109250, lr = 0.005
I0523 22:12:44.174474  3749 solver.cpp:237] Iteration 109500, loss = 1.36929
I0523 22:12:44.174651  3749 solver.cpp:253]     Train net output #0: loss = 1.36929 (* 1 = 1.36929 loss)
I0523 22:12:44.174666  3749 sgd_solver.cpp:106] Iteration 109500, lr = 0.005
I0523 22:12:53.204365  3749 solver.cpp:237] Iteration 109750, loss = 1.28457
I0523 22:12:53.204399  3749 solver.cpp:253]     Train net output #0: loss = 1.28457 (* 1 = 1.28457 loss)
I0523 22:12:53.204417  3749 sgd_solver.cpp:106] Iteration 109750, lr = 0.005
I0523 22:13:02.196141  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_110000.caffemodel
I0523 22:13:02.265148  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_110000.solverstate
I0523 22:13:02.290827  3749 solver.cpp:341] Iteration 110000, Testing net (#0)
I0523 22:14:10.385675  3749 solver.cpp:409]     Test net output #0: accuracy = 0.899087
I0523 22:14:10.385874  3749 solver.cpp:409]     Test net output #1: loss = 0.342001 (* 1 = 0.342001 loss)
I0523 22:14:31.273121  3749 solver.cpp:237] Iteration 110000, loss = 1.02013
I0523 22:14:31.273175  3749 solver.cpp:253]     Train net output #0: loss = 1.02013 (* 1 = 1.02013 loss)
I0523 22:14:31.273190  3749 sgd_solver.cpp:106] Iteration 110000, lr = 0.005
I0523 22:14:40.336307  3749 solver.cpp:237] Iteration 110250, loss = 0.840009
I0523 22:14:40.336349  3749 solver.cpp:253]     Train net output #0: loss = 0.840009 (* 1 = 0.840009 loss)
I0523 22:14:40.336369  3749 sgd_solver.cpp:106] Iteration 110250, lr = 0.005
I0523 22:14:49.393589  3749 solver.cpp:237] Iteration 110500, loss = 1.11877
I0523 22:14:49.393784  3749 solver.cpp:253]     Train net output #0: loss = 1.11877 (* 1 = 1.11877 loss)
I0523 22:14:49.393800  3749 sgd_solver.cpp:106] Iteration 110500, lr = 0.005
I0523 22:14:58.454105  3749 solver.cpp:237] Iteration 110750, loss = 1.1088
I0523 22:14:58.454139  3749 solver.cpp:253]     Train net output #0: loss = 1.1088 (* 1 = 1.1088 loss)
I0523 22:14:58.454159  3749 sgd_solver.cpp:106] Iteration 110750, lr = 0.005
I0523 22:15:07.515058  3749 solver.cpp:237] Iteration 111000, loss = 1.24896
I0523 22:15:07.515097  3749 solver.cpp:253]     Train net output #0: loss = 1.24896 (* 1 = 1.24896 loss)
I0523 22:15:07.515117  3749 sgd_solver.cpp:106] Iteration 111000, lr = 0.005
I0523 22:15:16.579762  3749 solver.cpp:237] Iteration 111250, loss = 1.11297
I0523 22:15:16.579798  3749 solver.cpp:253]     Train net output #0: loss = 1.11298 (* 1 = 1.11298 loss)
I0523 22:15:16.579815  3749 sgd_solver.cpp:106] Iteration 111250, lr = 0.005
I0523 22:15:25.634788  3749 solver.cpp:237] Iteration 111500, loss = 0.942476
I0523 22:15:25.634984  3749 solver.cpp:253]     Train net output #0: loss = 0.942477 (* 1 = 0.942477 loss)
I0523 22:15:25.634999  3749 sgd_solver.cpp:106] Iteration 111500, lr = 0.005
I0523 22:15:55.528931  3749 solver.cpp:237] Iteration 111750, loss = 1.06004
I0523 22:15:55.528983  3749 solver.cpp:253]     Train net output #0: loss = 1.06004 (* 1 = 1.06004 loss)
I0523 22:15:55.529000  3749 sgd_solver.cpp:106] Iteration 111750, lr = 0.005
I0523 22:16:04.591086  3749 solver.cpp:237] Iteration 112000, loss = 1.07687
I0523 22:16:04.591284  3749 solver.cpp:253]     Train net output #0: loss = 1.07687 (* 1 = 1.07687 loss)
I0523 22:16:04.591298  3749 sgd_solver.cpp:106] Iteration 112000, lr = 0.005
I0523 22:16:13.643391  3749 solver.cpp:237] Iteration 112250, loss = 1.01407
I0523 22:16:13.643426  3749 solver.cpp:253]     Train net output #0: loss = 1.01407 (* 1 = 1.01407 loss)
I0523 22:16:13.643443  3749 sgd_solver.cpp:106] Iteration 112250, lr = 0.005
I0523 22:16:22.676695  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_112500.caffemodel
I0523 22:16:22.742328  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_112500.solverstate
I0523 22:16:22.782579  3749 solver.cpp:237] Iteration 112500, loss = 0.973284
I0523 22:16:22.782629  3749 solver.cpp:253]     Train net output #0: loss = 0.973284 (* 1 = 0.973284 loss)
I0523 22:16:22.782645  3749 sgd_solver.cpp:106] Iteration 112500, lr = 0.005
I0523 22:16:31.841820  3749 solver.cpp:237] Iteration 112750, loss = 1.11251
I0523 22:16:31.841856  3749 solver.cpp:253]     Train net output #0: loss = 1.11251 (* 1 = 1.11251 loss)
I0523 22:16:31.841871  3749 sgd_solver.cpp:106] Iteration 112750, lr = 0.005
I0523 22:16:40.915884  3749 solver.cpp:237] Iteration 113000, loss = 1.20228
I0523 22:16:40.916074  3749 solver.cpp:253]     Train net output #0: loss = 1.20228 (* 1 = 1.20228 loss)
I0523 22:16:40.916087  3749 sgd_solver.cpp:106] Iteration 113000, lr = 0.005
I0523 22:16:49.959930  3749 solver.cpp:237] Iteration 113250, loss = 1.17184
I0523 22:16:49.959964  3749 solver.cpp:253]     Train net output #0: loss = 1.17184 (* 1 = 1.17184 loss)
I0523 22:16:49.959982  3749 sgd_solver.cpp:106] Iteration 113250, lr = 0.005
I0523 22:17:19.862186  3749 solver.cpp:237] Iteration 113500, loss = 1.06531
I0523 22:17:19.862385  3749 solver.cpp:253]     Train net output #0: loss = 1.06531 (* 1 = 1.06531 loss)
I0523 22:17:19.862398  3749 sgd_solver.cpp:106] Iteration 113500, lr = 0.005
I0523 22:17:28.906236  3749 solver.cpp:237] Iteration 113750, loss = 1.15538
I0523 22:17:28.906270  3749 solver.cpp:253]     Train net output #0: loss = 1.15538 (* 1 = 1.15538 loss)
I0523 22:17:28.906288  3749 sgd_solver.cpp:106] Iteration 113750, lr = 0.005
I0523 22:17:37.958436  3749 solver.cpp:237] Iteration 114000, loss = 1.03581
I0523 22:17:37.958479  3749 solver.cpp:253]     Train net output #0: loss = 1.03581 (* 1 = 1.03581 loss)
I0523 22:17:37.958498  3749 sgd_solver.cpp:106] Iteration 114000, lr = 0.005
I0523 22:17:47.017601  3749 solver.cpp:237] Iteration 114250, loss = 1.04929
I0523 22:17:47.017637  3749 solver.cpp:253]     Train net output #0: loss = 1.04929 (* 1 = 1.04929 loss)
I0523 22:17:47.017652  3749 sgd_solver.cpp:106] Iteration 114250, lr = 0.005
I0523 22:17:56.079530  3749 solver.cpp:237] Iteration 114500, loss = 1.30637
I0523 22:17:56.079731  3749 solver.cpp:253]     Train net output #0: loss = 1.30637 (* 1 = 1.30637 loss)
I0523 22:17:56.079746  3749 sgd_solver.cpp:106] Iteration 114500, lr = 0.005
I0523 22:18:05.142483  3749 solver.cpp:237] Iteration 114750, loss = 1.10797
I0523 22:18:05.142518  3749 solver.cpp:253]     Train net output #0: loss = 1.10797 (* 1 = 1.10797 loss)
I0523 22:18:05.142534  3749 sgd_solver.cpp:106] Iteration 114750, lr = 0.005
I0523 22:18:14.163661  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_115000.caffemodel
I0523 22:18:14.226106  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_115000.solverstate
I0523 22:18:14.250948  3749 solver.cpp:341] Iteration 115000, Testing net (#0)
I0523 22:19:01.186524  3749 solver.cpp:409]     Test net output #0: accuracy = 0.902018
I0523 22:19:01.186723  3749 solver.cpp:409]     Test net output #1: loss = 0.303091 (* 1 = 0.303091 loss)
I0523 22:19:22.009665  3749 solver.cpp:237] Iteration 115000, loss = 0.876449
I0523 22:19:22.009719  3749 solver.cpp:253]     Train net output #0: loss = 0.876449 (* 1 = 0.876449 loss)
I0523 22:19:22.009734  3749 sgd_solver.cpp:106] Iteration 115000, lr = 0.005
I0523 22:19:31.021864  3749 solver.cpp:237] Iteration 115250, loss = 1.10586
I0523 22:19:31.021899  3749 solver.cpp:253]     Train net output #0: loss = 1.10586 (* 1 = 1.10586 loss)
I0523 22:19:31.021917  3749 sgd_solver.cpp:106] Iteration 115250, lr = 0.005
I0523 22:19:40.030953  3749 solver.cpp:237] Iteration 115500, loss = 1.24802
I0523 22:19:40.031147  3749 solver.cpp:253]     Train net output #0: loss = 1.24802 (* 1 = 1.24802 loss)
I0523 22:19:40.031162  3749 sgd_solver.cpp:106] Iteration 115500, lr = 0.005
I0523 22:19:49.037402  3749 solver.cpp:237] Iteration 115750, loss = 1.32949
I0523 22:19:49.037437  3749 solver.cpp:253]     Train net output #0: loss = 1.32949 (* 1 = 1.32949 loss)
I0523 22:19:49.037454  3749 sgd_solver.cpp:106] Iteration 115750, lr = 0.005
I0523 22:19:58.047211  3749 solver.cpp:237] Iteration 116000, loss = 1.06011
I0523 22:19:58.047246  3749 solver.cpp:253]     Train net output #0: loss = 1.06011 (* 1 = 1.06011 loss)
I0523 22:19:58.047263  3749 sgd_solver.cpp:106] Iteration 116000, lr = 0.005
I0523 22:20:07.062104  3749 solver.cpp:237] Iteration 116250, loss = 1.29683
I0523 22:20:07.062144  3749 solver.cpp:253]     Train net output #0: loss = 1.29684 (* 1 = 1.29684 loss)
I0523 22:20:07.062165  3749 sgd_solver.cpp:106] Iteration 116250, lr = 0.005
I0523 22:20:16.076367  3749 solver.cpp:237] Iteration 116500, loss = 0.851732
I0523 22:20:16.076546  3749 solver.cpp:253]     Train net output #0: loss = 0.851732 (* 1 = 0.851732 loss)
I0523 22:20:16.076561  3749 sgd_solver.cpp:106] Iteration 116500, lr = 0.005
I0523 22:20:45.885171  3749 solver.cpp:237] Iteration 116750, loss = 1.34608
I0523 22:20:45.885223  3749 solver.cpp:253]     Train net output #0: loss = 1.34608 (* 1 = 1.34608 loss)
I0523 22:20:45.885241  3749 sgd_solver.cpp:106] Iteration 116750, lr = 0.005
I0523 22:20:54.891614  3749 solver.cpp:237] Iteration 117000, loss = 1.19219
I0523 22:20:54.891811  3749 solver.cpp:253]     Train net output #0: loss = 1.19219 (* 1 = 1.19219 loss)
I0523 22:20:54.891825  3749 sgd_solver.cpp:106] Iteration 117000, lr = 0.005
I0523 22:21:03.902186  3749 solver.cpp:237] Iteration 117250, loss = 1.29866
I0523 22:21:03.902221  3749 solver.cpp:253]     Train net output #0: loss = 1.29866 (* 1 = 1.29866 loss)
I0523 22:21:03.902240  3749 sgd_solver.cpp:106] Iteration 117250, lr = 0.005
I0523 22:21:12.873944  3749 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_117500.caffemodel
I0523 22:21:12.936950  3749 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_60_lr_0.0050_2016-05-20T15.49.12.235131_iter_117500.solverstate
I0523 22:21:12.973855  3749 solver.cpp:237] Iteration 117500, loss = 1.0419
I0523 22:21:12.973901  3749 solver.cpp:253]     Train net output #0: loss = 1.0419 (* 1 = 1.0419 loss)
I0523 22:21:12.973915  3749 sgd_solver.cpp:106] Iteration 117500, lr = 0.005
I0523 22:21:21.983479  3749 solver.cpp:237] Iteration 117750, loss = 1.36955
I0523 22:21:21.983523  3749 solver.cpp:253]     Train net output #0: loss = 1.36955 (* 1 = 1.36955 loss)
I0523 22:21:21.983541  3749 sgd_solver.cpp:106] Iteration 117750, lr = 0.005
I0523 22:21:30.989928  3749 solver.cpp:237] Iteration 118000, loss = 1.25265
I0523 22:21:30.990123  3749 solver.cpp:253]     Train net output #0: loss = 1.25265 (* 1 = 1.25265 loss)
I0523 22:21:30.990136  3749 sgd_solver.cpp:106] Iteration 118000, lr = 0.005
I0523 22:21:39.999371  3749 solver.cpp:237] Iteration 118250, loss = 0.906319
I0523 22:21:39.999406  3749 solver.cpp:253]     Train net output #0: loss = 0.906319 (* 1 = 0.906319 loss)
I0523 22:21:39.999423  3749 sgd_solver.cpp:106] Iteration 118250, lr = 0.005
I0523 22:22:09.779292  3749 solver.cpp:237] Iteration 118500, loss = 0.983224
I0523 22:22:09.779494  3749 solver.cpp:253]     Train net output #0: loss = 0.983224 (* 1 = 0.983224 loss)
I0523 22:22:09.779507  3749 sgd_solver.cpp:106] Iteration 118500, lr = 0.005
I0523 22:22:18.788744  3749 solver.cpp:237] Iteration 118750, loss = 1.25933
I0523 22:22:18.788779  3749 solver.cpp:253]     Train net output #0: loss = 1.25933 (* 1 = 1.25933 loss)
I0523 22:22:18.788794  3749 sgd_solver.cpp:106] Iteration 118750, lr = 0.005
I0523 22:22:27.797400  3749 solver.cpp:237] Iteration 119000, loss = 1.12236
I0523 22:22:27.797436  3749 solver.cpp:253]     Train net output #0: loss = 1.12236 (* 1 = 1.12236 loss)
I0523 22:22:27.797451  3749 sgd_solver.cpp:106] Iteration 119000, lr = 0.005
aprun: Apid 11258028: Caught signal Terminated, sending to application
*** Aborted at 1464056553 (unix time) try "date -d @1464056553" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11258028: Caught signal Terminated, sending to application
*** SIGTERM (@0xea2) received by PID 3749 (TID 0x2aaac746f900) from PID 3746; stack trace: ***
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
=>> PBS: job killed: walltime 7234 exceeded limit 7200
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11258028: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11258028: Caught signal Terminated, sending to application
aprun: Apid 11258028: Caught signal Terminated, sending to application
aprun: Apid 11258028: Caught signal Terminated, sending to application
aprun: Apid 11258028: Caught signal Terminated, sending to application
aprun: Apid 11258028: Caught signal Terminated, sending to application
aprun: Apid 11258028: Caught signal Terminated, sending to application
aprun: Apid 11258028: Caught signal Terminated, sending to application
