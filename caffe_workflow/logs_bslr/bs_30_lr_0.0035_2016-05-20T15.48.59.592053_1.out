2807490
I0522 12:08:25.555244 19035 caffe.cpp:184] Using GPUs 0
I0522 12:08:25.982506 19035 solver.cpp:48] Initializing solver from parameters: 
test_iter: 5000
test_interval: 10000
base_lr: 0.0035
display: 500
max_iter: 500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053.prototxt"
I0522 12:08:25.984439 19035 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053.prototxt
I0522 12:08:26.007376 19035 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0522 12:08:26.007436 19035 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0522 12:08:26.007781 19035 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 12:08:26.007961 19035 layer_factory.hpp:77] Creating layer data_hdf5
I0522 12:08:26.007984 19035 net.cpp:106] Creating Layer data_hdf5
I0522 12:08:26.007999 19035 net.cpp:411] data_hdf5 -> data
I0522 12:08:26.008033 19035 net.cpp:411] data_hdf5 -> label
I0522 12:08:26.008064 19035 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0522 12:08:26.010376 19035 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0522 12:08:26.012617 19035 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0522 12:08:47.553283 19035 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0522 12:08:47.558517 19035 net.cpp:150] Setting up data_hdf5
I0522 12:08:47.558571 19035 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 12:08:47.558585 19035 net.cpp:157] Top shape: 30 (30)
I0522 12:08:47.558596 19035 net.cpp:165] Memory required for data: 762120
I0522 12:08:47.558609 19035 layer_factory.hpp:77] Creating layer conv1
I0522 12:08:47.558643 19035 net.cpp:106] Creating Layer conv1
I0522 12:08:47.558655 19035 net.cpp:454] conv1 <- data
I0522 12:08:47.558678 19035 net.cpp:411] conv1 -> conv1
I0522 12:08:47.926493 19035 net.cpp:150] Setting up conv1
I0522 12:08:47.926551 19035 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 12:08:47.926563 19035 net.cpp:165] Memory required for data: 9056520
I0522 12:08:47.926594 19035 layer_factory.hpp:77] Creating layer relu1
I0522 12:08:47.926615 19035 net.cpp:106] Creating Layer relu1
I0522 12:08:47.926626 19035 net.cpp:454] relu1 <- conv1
I0522 12:08:47.926640 19035 net.cpp:397] relu1 -> conv1 (in-place)
I0522 12:08:47.927156 19035 net.cpp:150] Setting up relu1
I0522 12:08:47.927173 19035 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 12:08:47.927184 19035 net.cpp:165] Memory required for data: 17350920
I0522 12:08:47.927196 19035 layer_factory.hpp:77] Creating layer pool1
I0522 12:08:47.927212 19035 net.cpp:106] Creating Layer pool1
I0522 12:08:47.927222 19035 net.cpp:454] pool1 <- conv1
I0522 12:08:47.927235 19035 net.cpp:411] pool1 -> pool1
I0522 12:08:47.927316 19035 net.cpp:150] Setting up pool1
I0522 12:08:47.927330 19035 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 12:08:47.927340 19035 net.cpp:165] Memory required for data: 21498120
I0522 12:08:47.927350 19035 layer_factory.hpp:77] Creating layer conv2
I0522 12:08:47.927371 19035 net.cpp:106] Creating Layer conv2
I0522 12:08:47.927382 19035 net.cpp:454] conv2 <- pool1
I0522 12:08:47.927397 19035 net.cpp:411] conv2 -> conv2
I0522 12:08:47.930063 19035 net.cpp:150] Setting up conv2
I0522 12:08:47.930090 19035 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 12:08:47.930101 19035 net.cpp:165] Memory required for data: 27459720
I0522 12:08:47.930120 19035 layer_factory.hpp:77] Creating layer relu2
I0522 12:08:47.930135 19035 net.cpp:106] Creating Layer relu2
I0522 12:08:47.930145 19035 net.cpp:454] relu2 <- conv2
I0522 12:08:47.930157 19035 net.cpp:397] relu2 -> conv2 (in-place)
I0522 12:08:47.930487 19035 net.cpp:150] Setting up relu2
I0522 12:08:47.930501 19035 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 12:08:47.930511 19035 net.cpp:165] Memory required for data: 33421320
I0522 12:08:47.930521 19035 layer_factory.hpp:77] Creating layer pool2
I0522 12:08:47.930534 19035 net.cpp:106] Creating Layer pool2
I0522 12:08:47.930553 19035 net.cpp:454] pool2 <- conv2
I0522 12:08:47.930567 19035 net.cpp:411] pool2 -> pool2
I0522 12:08:47.930649 19035 net.cpp:150] Setting up pool2
I0522 12:08:47.930662 19035 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 12:08:47.930672 19035 net.cpp:165] Memory required for data: 36402120
I0522 12:08:47.930680 19035 layer_factory.hpp:77] Creating layer conv3
I0522 12:08:47.930698 19035 net.cpp:106] Creating Layer conv3
I0522 12:08:47.930708 19035 net.cpp:454] conv3 <- pool2
I0522 12:08:47.930722 19035 net.cpp:411] conv3 -> conv3
I0522 12:08:47.932677 19035 net.cpp:150] Setting up conv3
I0522 12:08:47.932695 19035 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 12:08:47.932706 19035 net.cpp:165] Memory required for data: 39654600
I0522 12:08:47.932724 19035 layer_factory.hpp:77] Creating layer relu3
I0522 12:08:47.932740 19035 net.cpp:106] Creating Layer relu3
I0522 12:08:47.932750 19035 net.cpp:454] relu3 <- conv3
I0522 12:08:47.932763 19035 net.cpp:397] relu3 -> conv3 (in-place)
I0522 12:08:47.933230 19035 net.cpp:150] Setting up relu3
I0522 12:08:47.933248 19035 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 12:08:47.933257 19035 net.cpp:165] Memory required for data: 42907080
I0522 12:08:47.933267 19035 layer_factory.hpp:77] Creating layer pool3
I0522 12:08:47.933280 19035 net.cpp:106] Creating Layer pool3
I0522 12:08:47.933290 19035 net.cpp:454] pool3 <- conv3
I0522 12:08:47.933303 19035 net.cpp:411] pool3 -> pool3
I0522 12:08:47.933370 19035 net.cpp:150] Setting up pool3
I0522 12:08:47.933384 19035 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 12:08:47.933393 19035 net.cpp:165] Memory required for data: 44533320
I0522 12:08:47.933403 19035 layer_factory.hpp:77] Creating layer conv4
I0522 12:08:47.933418 19035 net.cpp:106] Creating Layer conv4
I0522 12:08:47.933429 19035 net.cpp:454] conv4 <- pool3
I0522 12:08:47.933442 19035 net.cpp:411] conv4 -> conv4
I0522 12:08:47.936163 19035 net.cpp:150] Setting up conv4
I0522 12:08:47.936192 19035 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 12:08:47.936203 19035 net.cpp:165] Memory required for data: 45621960
I0522 12:08:47.936218 19035 layer_factory.hpp:77] Creating layer relu4
I0522 12:08:47.936233 19035 net.cpp:106] Creating Layer relu4
I0522 12:08:47.936242 19035 net.cpp:454] relu4 <- conv4
I0522 12:08:47.936255 19035 net.cpp:397] relu4 -> conv4 (in-place)
I0522 12:08:47.936718 19035 net.cpp:150] Setting up relu4
I0522 12:08:47.936734 19035 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 12:08:47.936744 19035 net.cpp:165] Memory required for data: 46710600
I0522 12:08:47.936754 19035 layer_factory.hpp:77] Creating layer pool4
I0522 12:08:47.936767 19035 net.cpp:106] Creating Layer pool4
I0522 12:08:47.936777 19035 net.cpp:454] pool4 <- conv4
I0522 12:08:47.936790 19035 net.cpp:411] pool4 -> pool4
I0522 12:08:47.936858 19035 net.cpp:150] Setting up pool4
I0522 12:08:47.936872 19035 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 12:08:47.936882 19035 net.cpp:165] Memory required for data: 47254920
I0522 12:08:47.936893 19035 layer_factory.hpp:77] Creating layer ip1
I0522 12:08:47.936914 19035 net.cpp:106] Creating Layer ip1
I0522 12:08:47.936924 19035 net.cpp:454] ip1 <- pool4
I0522 12:08:47.936938 19035 net.cpp:411] ip1 -> ip1
I0522 12:08:47.952368 19035 net.cpp:150] Setting up ip1
I0522 12:08:47.952396 19035 net.cpp:157] Top shape: 30 196 (5880)
I0522 12:08:47.952409 19035 net.cpp:165] Memory required for data: 47278440
I0522 12:08:47.952436 19035 layer_factory.hpp:77] Creating layer relu5
I0522 12:08:47.952451 19035 net.cpp:106] Creating Layer relu5
I0522 12:08:47.952461 19035 net.cpp:454] relu5 <- ip1
I0522 12:08:47.952476 19035 net.cpp:397] relu5 -> ip1 (in-place)
I0522 12:08:47.952817 19035 net.cpp:150] Setting up relu5
I0522 12:08:47.952831 19035 net.cpp:157] Top shape: 30 196 (5880)
I0522 12:08:47.952842 19035 net.cpp:165] Memory required for data: 47301960
I0522 12:08:47.952852 19035 layer_factory.hpp:77] Creating layer drop1
I0522 12:08:47.952877 19035 net.cpp:106] Creating Layer drop1
I0522 12:08:47.952886 19035 net.cpp:454] drop1 <- ip1
I0522 12:08:47.952898 19035 net.cpp:397] drop1 -> ip1 (in-place)
I0522 12:08:47.952956 19035 net.cpp:150] Setting up drop1
I0522 12:08:47.952970 19035 net.cpp:157] Top shape: 30 196 (5880)
I0522 12:08:47.952980 19035 net.cpp:165] Memory required for data: 47325480
I0522 12:08:47.952991 19035 layer_factory.hpp:77] Creating layer ip2
I0522 12:08:47.953008 19035 net.cpp:106] Creating Layer ip2
I0522 12:08:47.953019 19035 net.cpp:454] ip2 <- ip1
I0522 12:08:47.953032 19035 net.cpp:411] ip2 -> ip2
I0522 12:08:47.953493 19035 net.cpp:150] Setting up ip2
I0522 12:08:47.953506 19035 net.cpp:157] Top shape: 30 98 (2940)
I0522 12:08:47.953516 19035 net.cpp:165] Memory required for data: 47337240
I0522 12:08:47.953532 19035 layer_factory.hpp:77] Creating layer relu6
I0522 12:08:47.953546 19035 net.cpp:106] Creating Layer relu6
I0522 12:08:47.953555 19035 net.cpp:454] relu6 <- ip2
I0522 12:08:47.953567 19035 net.cpp:397] relu6 -> ip2 (in-place)
I0522 12:08:47.954082 19035 net.cpp:150] Setting up relu6
I0522 12:08:47.954097 19035 net.cpp:157] Top shape: 30 98 (2940)
I0522 12:08:47.954108 19035 net.cpp:165] Memory required for data: 47349000
I0522 12:08:47.954119 19035 layer_factory.hpp:77] Creating layer drop2
I0522 12:08:47.954133 19035 net.cpp:106] Creating Layer drop2
I0522 12:08:47.954143 19035 net.cpp:454] drop2 <- ip2
I0522 12:08:47.954154 19035 net.cpp:397] drop2 -> ip2 (in-place)
I0522 12:08:47.954197 19035 net.cpp:150] Setting up drop2
I0522 12:08:47.954210 19035 net.cpp:157] Top shape: 30 98 (2940)
I0522 12:08:47.954221 19035 net.cpp:165] Memory required for data: 47360760
I0522 12:08:47.954231 19035 layer_factory.hpp:77] Creating layer ip3
I0522 12:08:47.954244 19035 net.cpp:106] Creating Layer ip3
I0522 12:08:47.954253 19035 net.cpp:454] ip3 <- ip2
I0522 12:08:47.954265 19035 net.cpp:411] ip3 -> ip3
I0522 12:08:47.954475 19035 net.cpp:150] Setting up ip3
I0522 12:08:47.954488 19035 net.cpp:157] Top shape: 30 11 (330)
I0522 12:08:47.954499 19035 net.cpp:165] Memory required for data: 47362080
I0522 12:08:47.954514 19035 layer_factory.hpp:77] Creating layer drop3
I0522 12:08:47.954526 19035 net.cpp:106] Creating Layer drop3
I0522 12:08:47.954535 19035 net.cpp:454] drop3 <- ip3
I0522 12:08:47.954555 19035 net.cpp:397] drop3 -> ip3 (in-place)
I0522 12:08:47.954596 19035 net.cpp:150] Setting up drop3
I0522 12:08:47.954608 19035 net.cpp:157] Top shape: 30 11 (330)
I0522 12:08:47.954618 19035 net.cpp:165] Memory required for data: 47363400
I0522 12:08:47.954627 19035 layer_factory.hpp:77] Creating layer loss
I0522 12:08:47.954646 19035 net.cpp:106] Creating Layer loss
I0522 12:08:47.954656 19035 net.cpp:454] loss <- ip3
I0522 12:08:47.954668 19035 net.cpp:454] loss <- label
I0522 12:08:47.954679 19035 net.cpp:411] loss -> loss
I0522 12:08:47.954696 19035 layer_factory.hpp:77] Creating layer loss
I0522 12:08:47.955341 19035 net.cpp:150] Setting up loss
I0522 12:08:47.955363 19035 net.cpp:157] Top shape: (1)
I0522 12:08:47.955375 19035 net.cpp:160]     with loss weight 1
I0522 12:08:47.955420 19035 net.cpp:165] Memory required for data: 47363404
I0522 12:08:47.955430 19035 net.cpp:226] loss needs backward computation.
I0522 12:08:47.955441 19035 net.cpp:226] drop3 needs backward computation.
I0522 12:08:47.955451 19035 net.cpp:226] ip3 needs backward computation.
I0522 12:08:47.955461 19035 net.cpp:226] drop2 needs backward computation.
I0522 12:08:47.955471 19035 net.cpp:226] relu6 needs backward computation.
I0522 12:08:47.955481 19035 net.cpp:226] ip2 needs backward computation.
I0522 12:08:47.955490 19035 net.cpp:226] drop1 needs backward computation.
I0522 12:08:47.955499 19035 net.cpp:226] relu5 needs backward computation.
I0522 12:08:47.955509 19035 net.cpp:226] ip1 needs backward computation.
I0522 12:08:47.955519 19035 net.cpp:226] pool4 needs backward computation.
I0522 12:08:47.955529 19035 net.cpp:226] relu4 needs backward computation.
I0522 12:08:47.955539 19035 net.cpp:226] conv4 needs backward computation.
I0522 12:08:47.955550 19035 net.cpp:226] pool3 needs backward computation.
I0522 12:08:47.955560 19035 net.cpp:226] relu3 needs backward computation.
I0522 12:08:47.955570 19035 net.cpp:226] conv3 needs backward computation.
I0522 12:08:47.955590 19035 net.cpp:226] pool2 needs backward computation.
I0522 12:08:47.955601 19035 net.cpp:226] relu2 needs backward computation.
I0522 12:08:47.955611 19035 net.cpp:226] conv2 needs backward computation.
I0522 12:08:47.955621 19035 net.cpp:226] pool1 needs backward computation.
I0522 12:08:47.955632 19035 net.cpp:226] relu1 needs backward computation.
I0522 12:08:47.955642 19035 net.cpp:226] conv1 needs backward computation.
I0522 12:08:47.955653 19035 net.cpp:228] data_hdf5 does not need backward computation.
I0522 12:08:47.955663 19035 net.cpp:270] This network produces output loss
I0522 12:08:47.955687 19035 net.cpp:283] Network initialization done.
I0522 12:08:47.958923 19035 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053.prototxt
I0522 12:08:47.958998 19035 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0522 12:08:47.959357 19035 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 30
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0522 12:08:47.959548 19035 layer_factory.hpp:77] Creating layer data_hdf5
I0522 12:08:47.959564 19035 net.cpp:106] Creating Layer data_hdf5
I0522 12:08:47.959576 19035 net.cpp:411] data_hdf5 -> data
I0522 12:08:47.959595 19035 net.cpp:411] data_hdf5 -> label
I0522 12:08:47.959611 19035 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0522 12:08:47.963824 19035 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0522 12:09:09.280892 19035 net.cpp:150] Setting up data_hdf5
I0522 12:09:09.281059 19035 net.cpp:157] Top shape: 30 1 127 50 (190500)
I0522 12:09:09.281074 19035 net.cpp:157] Top shape: 30 (30)
I0522 12:09:09.281086 19035 net.cpp:165] Memory required for data: 762120
I0522 12:09:09.281100 19035 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0522 12:09:09.281128 19035 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0522 12:09:09.281139 19035 net.cpp:454] label_data_hdf5_1_split <- label
I0522 12:09:09.281154 19035 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0522 12:09:09.281177 19035 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0522 12:09:09.281249 19035 net.cpp:150] Setting up label_data_hdf5_1_split
I0522 12:09:09.281262 19035 net.cpp:157] Top shape: 30 (30)
I0522 12:09:09.281275 19035 net.cpp:157] Top shape: 30 (30)
I0522 12:09:09.281285 19035 net.cpp:165] Memory required for data: 762360
I0522 12:09:09.281294 19035 layer_factory.hpp:77] Creating layer conv1
I0522 12:09:09.281316 19035 net.cpp:106] Creating Layer conv1
I0522 12:09:09.281327 19035 net.cpp:454] conv1 <- data
I0522 12:09:09.281340 19035 net.cpp:411] conv1 -> conv1
I0522 12:09:09.283263 19035 net.cpp:150] Setting up conv1
I0522 12:09:09.283288 19035 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 12:09:09.283298 19035 net.cpp:165] Memory required for data: 9056760
I0522 12:09:09.283319 19035 layer_factory.hpp:77] Creating layer relu1
I0522 12:09:09.283334 19035 net.cpp:106] Creating Layer relu1
I0522 12:09:09.283344 19035 net.cpp:454] relu1 <- conv1
I0522 12:09:09.283356 19035 net.cpp:397] relu1 -> conv1 (in-place)
I0522 12:09:09.283857 19035 net.cpp:150] Setting up relu1
I0522 12:09:09.283874 19035 net.cpp:157] Top shape: 30 12 120 48 (2073600)
I0522 12:09:09.283885 19035 net.cpp:165] Memory required for data: 17351160
I0522 12:09:09.283895 19035 layer_factory.hpp:77] Creating layer pool1
I0522 12:09:09.283910 19035 net.cpp:106] Creating Layer pool1
I0522 12:09:09.283921 19035 net.cpp:454] pool1 <- conv1
I0522 12:09:09.283932 19035 net.cpp:411] pool1 -> pool1
I0522 12:09:09.284008 19035 net.cpp:150] Setting up pool1
I0522 12:09:09.284020 19035 net.cpp:157] Top shape: 30 12 60 48 (1036800)
I0522 12:09:09.284030 19035 net.cpp:165] Memory required for data: 21498360
I0522 12:09:09.284039 19035 layer_factory.hpp:77] Creating layer conv2
I0522 12:09:09.284056 19035 net.cpp:106] Creating Layer conv2
I0522 12:09:09.284066 19035 net.cpp:454] conv2 <- pool1
I0522 12:09:09.284081 19035 net.cpp:411] conv2 -> conv2
I0522 12:09:09.285989 19035 net.cpp:150] Setting up conv2
I0522 12:09:09.286010 19035 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 12:09:09.286023 19035 net.cpp:165] Memory required for data: 27459960
I0522 12:09:09.286041 19035 layer_factory.hpp:77] Creating layer relu2
I0522 12:09:09.286054 19035 net.cpp:106] Creating Layer relu2
I0522 12:09:09.286064 19035 net.cpp:454] relu2 <- conv2
I0522 12:09:09.286077 19035 net.cpp:397] relu2 -> conv2 (in-place)
I0522 12:09:09.286408 19035 net.cpp:150] Setting up relu2
I0522 12:09:09.286422 19035 net.cpp:157] Top shape: 30 20 54 46 (1490400)
I0522 12:09:09.286432 19035 net.cpp:165] Memory required for data: 33421560
I0522 12:09:09.286442 19035 layer_factory.hpp:77] Creating layer pool2
I0522 12:09:09.286455 19035 net.cpp:106] Creating Layer pool2
I0522 12:09:09.286465 19035 net.cpp:454] pool2 <- conv2
I0522 12:09:09.286478 19035 net.cpp:411] pool2 -> pool2
I0522 12:09:09.286559 19035 net.cpp:150] Setting up pool2
I0522 12:09:09.286572 19035 net.cpp:157] Top shape: 30 20 27 46 (745200)
I0522 12:09:09.286582 19035 net.cpp:165] Memory required for data: 36402360
I0522 12:09:09.286592 19035 layer_factory.hpp:77] Creating layer conv3
I0522 12:09:09.286612 19035 net.cpp:106] Creating Layer conv3
I0522 12:09:09.286623 19035 net.cpp:454] conv3 <- pool2
I0522 12:09:09.286636 19035 net.cpp:411] conv3 -> conv3
I0522 12:09:09.288610 19035 net.cpp:150] Setting up conv3
I0522 12:09:09.288628 19035 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 12:09:09.288638 19035 net.cpp:165] Memory required for data: 39654840
I0522 12:09:09.288672 19035 layer_factory.hpp:77] Creating layer relu3
I0522 12:09:09.288686 19035 net.cpp:106] Creating Layer relu3
I0522 12:09:09.288696 19035 net.cpp:454] relu3 <- conv3
I0522 12:09:09.288708 19035 net.cpp:397] relu3 -> conv3 (in-place)
I0522 12:09:09.289181 19035 net.cpp:150] Setting up relu3
I0522 12:09:09.289197 19035 net.cpp:157] Top shape: 30 28 22 44 (813120)
I0522 12:09:09.289207 19035 net.cpp:165] Memory required for data: 42907320
I0522 12:09:09.289217 19035 layer_factory.hpp:77] Creating layer pool3
I0522 12:09:09.289230 19035 net.cpp:106] Creating Layer pool3
I0522 12:09:09.289240 19035 net.cpp:454] pool3 <- conv3
I0522 12:09:09.289253 19035 net.cpp:411] pool3 -> pool3
I0522 12:09:09.289324 19035 net.cpp:150] Setting up pool3
I0522 12:09:09.289337 19035 net.cpp:157] Top shape: 30 28 11 44 (406560)
I0522 12:09:09.289347 19035 net.cpp:165] Memory required for data: 44533560
I0522 12:09:09.289356 19035 layer_factory.hpp:77] Creating layer conv4
I0522 12:09:09.289373 19035 net.cpp:106] Creating Layer conv4
I0522 12:09:09.289383 19035 net.cpp:454] conv4 <- pool3
I0522 12:09:09.289397 19035 net.cpp:411] conv4 -> conv4
I0522 12:09:09.291456 19035 net.cpp:150] Setting up conv4
I0522 12:09:09.291477 19035 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 12:09:09.291491 19035 net.cpp:165] Memory required for data: 45622200
I0522 12:09:09.291507 19035 layer_factory.hpp:77] Creating layer relu4
I0522 12:09:09.291519 19035 net.cpp:106] Creating Layer relu4
I0522 12:09:09.291529 19035 net.cpp:454] relu4 <- conv4
I0522 12:09:09.291543 19035 net.cpp:397] relu4 -> conv4 (in-place)
I0522 12:09:09.292014 19035 net.cpp:150] Setting up relu4
I0522 12:09:09.292031 19035 net.cpp:157] Top shape: 30 36 6 42 (272160)
I0522 12:09:09.292040 19035 net.cpp:165] Memory required for data: 46710840
I0522 12:09:09.292052 19035 layer_factory.hpp:77] Creating layer pool4
I0522 12:09:09.292068 19035 net.cpp:106] Creating Layer pool4
I0522 12:09:09.292080 19035 net.cpp:454] pool4 <- conv4
I0522 12:09:09.292095 19035 net.cpp:411] pool4 -> pool4
I0522 12:09:09.292168 19035 net.cpp:150] Setting up pool4
I0522 12:09:09.292182 19035 net.cpp:157] Top shape: 30 36 3 42 (136080)
I0522 12:09:09.292191 19035 net.cpp:165] Memory required for data: 47255160
I0522 12:09:09.292201 19035 layer_factory.hpp:77] Creating layer ip1
I0522 12:09:09.292217 19035 net.cpp:106] Creating Layer ip1
I0522 12:09:09.292227 19035 net.cpp:454] ip1 <- pool4
I0522 12:09:09.292239 19035 net.cpp:411] ip1 -> ip1
I0522 12:09:09.307763 19035 net.cpp:150] Setting up ip1
I0522 12:09:09.307791 19035 net.cpp:157] Top shape: 30 196 (5880)
I0522 12:09:09.307807 19035 net.cpp:165] Memory required for data: 47278680
I0522 12:09:09.307829 19035 layer_factory.hpp:77] Creating layer relu5
I0522 12:09:09.307845 19035 net.cpp:106] Creating Layer relu5
I0522 12:09:09.307855 19035 net.cpp:454] relu5 <- ip1
I0522 12:09:09.307868 19035 net.cpp:397] relu5 -> ip1 (in-place)
I0522 12:09:09.308217 19035 net.cpp:150] Setting up relu5
I0522 12:09:09.308230 19035 net.cpp:157] Top shape: 30 196 (5880)
I0522 12:09:09.308240 19035 net.cpp:165] Memory required for data: 47302200
I0522 12:09:09.308250 19035 layer_factory.hpp:77] Creating layer drop1
I0522 12:09:09.308270 19035 net.cpp:106] Creating Layer drop1
I0522 12:09:09.308280 19035 net.cpp:454] drop1 <- ip1
I0522 12:09:09.308293 19035 net.cpp:397] drop1 -> ip1 (in-place)
I0522 12:09:09.308339 19035 net.cpp:150] Setting up drop1
I0522 12:09:09.308352 19035 net.cpp:157] Top shape: 30 196 (5880)
I0522 12:09:09.308362 19035 net.cpp:165] Memory required for data: 47325720
I0522 12:09:09.308372 19035 layer_factory.hpp:77] Creating layer ip2
I0522 12:09:09.308387 19035 net.cpp:106] Creating Layer ip2
I0522 12:09:09.308396 19035 net.cpp:454] ip2 <- ip1
I0522 12:09:09.308410 19035 net.cpp:411] ip2 -> ip2
I0522 12:09:09.308889 19035 net.cpp:150] Setting up ip2
I0522 12:09:09.308902 19035 net.cpp:157] Top shape: 30 98 (2940)
I0522 12:09:09.308913 19035 net.cpp:165] Memory required for data: 47337480
I0522 12:09:09.308928 19035 layer_factory.hpp:77] Creating layer relu6
I0522 12:09:09.308954 19035 net.cpp:106] Creating Layer relu6
I0522 12:09:09.308964 19035 net.cpp:454] relu6 <- ip2
I0522 12:09:09.308977 19035 net.cpp:397] relu6 -> ip2 (in-place)
I0522 12:09:09.309510 19035 net.cpp:150] Setting up relu6
I0522 12:09:09.309526 19035 net.cpp:157] Top shape: 30 98 (2940)
I0522 12:09:09.309535 19035 net.cpp:165] Memory required for data: 47349240
I0522 12:09:09.309546 19035 layer_factory.hpp:77] Creating layer drop2
I0522 12:09:09.309559 19035 net.cpp:106] Creating Layer drop2
I0522 12:09:09.309571 19035 net.cpp:454] drop2 <- ip2
I0522 12:09:09.309583 19035 net.cpp:397] drop2 -> ip2 (in-place)
I0522 12:09:09.309628 19035 net.cpp:150] Setting up drop2
I0522 12:09:09.309640 19035 net.cpp:157] Top shape: 30 98 (2940)
I0522 12:09:09.309650 19035 net.cpp:165] Memory required for data: 47361000
I0522 12:09:09.309660 19035 layer_factory.hpp:77] Creating layer ip3
I0522 12:09:09.309674 19035 net.cpp:106] Creating Layer ip3
I0522 12:09:09.309684 19035 net.cpp:454] ip3 <- ip2
I0522 12:09:09.309698 19035 net.cpp:411] ip3 -> ip3
I0522 12:09:09.309921 19035 net.cpp:150] Setting up ip3
I0522 12:09:09.309933 19035 net.cpp:157] Top shape: 30 11 (330)
I0522 12:09:09.309943 19035 net.cpp:165] Memory required for data: 47362320
I0522 12:09:09.309958 19035 layer_factory.hpp:77] Creating layer drop3
I0522 12:09:09.309972 19035 net.cpp:106] Creating Layer drop3
I0522 12:09:09.309980 19035 net.cpp:454] drop3 <- ip3
I0522 12:09:09.309993 19035 net.cpp:397] drop3 -> ip3 (in-place)
I0522 12:09:09.310034 19035 net.cpp:150] Setting up drop3
I0522 12:09:09.310047 19035 net.cpp:157] Top shape: 30 11 (330)
I0522 12:09:09.310056 19035 net.cpp:165] Memory required for data: 47363640
I0522 12:09:09.310066 19035 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0522 12:09:09.310080 19035 net.cpp:106] Creating Layer ip3_drop3_0_split
I0522 12:09:09.310088 19035 net.cpp:454] ip3_drop3_0_split <- ip3
I0522 12:09:09.310101 19035 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0522 12:09:09.310117 19035 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0522 12:09:09.310190 19035 net.cpp:150] Setting up ip3_drop3_0_split
I0522 12:09:09.310204 19035 net.cpp:157] Top shape: 30 11 (330)
I0522 12:09:09.310216 19035 net.cpp:157] Top shape: 30 11 (330)
I0522 12:09:09.310226 19035 net.cpp:165] Memory required for data: 47366280
I0522 12:09:09.310235 19035 layer_factory.hpp:77] Creating layer accuracy
I0522 12:09:09.310256 19035 net.cpp:106] Creating Layer accuracy
I0522 12:09:09.310266 19035 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0522 12:09:09.310277 19035 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0522 12:09:09.310292 19035 net.cpp:411] accuracy -> accuracy
I0522 12:09:09.310314 19035 net.cpp:150] Setting up accuracy
I0522 12:09:09.310326 19035 net.cpp:157] Top shape: (1)
I0522 12:09:09.310336 19035 net.cpp:165] Memory required for data: 47366284
I0522 12:09:09.310346 19035 layer_factory.hpp:77] Creating layer loss
I0522 12:09:09.310359 19035 net.cpp:106] Creating Layer loss
I0522 12:09:09.310369 19035 net.cpp:454] loss <- ip3_drop3_0_split_1
I0522 12:09:09.310380 19035 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0522 12:09:09.310392 19035 net.cpp:411] loss -> loss
I0522 12:09:09.310410 19035 layer_factory.hpp:77] Creating layer loss
I0522 12:09:09.310904 19035 net.cpp:150] Setting up loss
I0522 12:09:09.310917 19035 net.cpp:157] Top shape: (1)
I0522 12:09:09.310927 19035 net.cpp:160]     with loss weight 1
I0522 12:09:09.310948 19035 net.cpp:165] Memory required for data: 47366288
I0522 12:09:09.310958 19035 net.cpp:226] loss needs backward computation.
I0522 12:09:09.310969 19035 net.cpp:228] accuracy does not need backward computation.
I0522 12:09:09.310981 19035 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0522 12:09:09.310992 19035 net.cpp:226] drop3 needs backward computation.
I0522 12:09:09.311002 19035 net.cpp:226] ip3 needs backward computation.
I0522 12:09:09.311013 19035 net.cpp:226] drop2 needs backward computation.
I0522 12:09:09.311022 19035 net.cpp:226] relu6 needs backward computation.
I0522 12:09:09.311040 19035 net.cpp:226] ip2 needs backward computation.
I0522 12:09:09.311051 19035 net.cpp:226] drop1 needs backward computation.
I0522 12:09:09.311060 19035 net.cpp:226] relu5 needs backward computation.
I0522 12:09:09.311070 19035 net.cpp:226] ip1 needs backward computation.
I0522 12:09:09.311079 19035 net.cpp:226] pool4 needs backward computation.
I0522 12:09:09.311089 19035 net.cpp:226] relu4 needs backward computation.
I0522 12:09:09.311100 19035 net.cpp:226] conv4 needs backward computation.
I0522 12:09:09.311110 19035 net.cpp:226] pool3 needs backward computation.
I0522 12:09:09.311120 19035 net.cpp:226] relu3 needs backward computation.
I0522 12:09:09.311130 19035 net.cpp:226] conv3 needs backward computation.
I0522 12:09:09.311139 19035 net.cpp:226] pool2 needs backward computation.
I0522 12:09:09.311151 19035 net.cpp:226] relu2 needs backward computation.
I0522 12:09:09.311161 19035 net.cpp:226] conv2 needs backward computation.
I0522 12:09:09.311170 19035 net.cpp:226] pool1 needs backward computation.
I0522 12:09:09.311180 19035 net.cpp:226] relu1 needs backward computation.
I0522 12:09:09.311190 19035 net.cpp:226] conv1 needs backward computation.
I0522 12:09:09.311202 19035 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0522 12:09:09.311213 19035 net.cpp:228] data_hdf5 does not need backward computation.
I0522 12:09:09.311223 19035 net.cpp:270] This network produces output accuracy
I0522 12:09:09.311233 19035 net.cpp:270] This network produces output loss
I0522 12:09:09.311260 19035 net.cpp:283] Network initialization done.
I0522 12:09:09.311395 19035 solver.cpp:60] Solver scaffolding done.
I0522 12:09:09.312528 19035 caffe.cpp:212] Starting Optimization
I0522 12:09:09.312541 19035 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0522 12:09:09.312553 19035 solver.cpp:289] Learning Rate Policy: fixed
I0522 12:09:09.313758 19035 solver.cpp:341] Iteration 0, Testing net (#0)
I0522 12:09:59.824216 19035 solver.cpp:409]     Test net output #0: accuracy = 0.122341
I0522 12:09:59.824399 19035 solver.cpp:409]     Test net output #1: loss = 2.39841 (* 1 = 2.39841 loss)
I0522 12:09:59.845291 19035 solver.cpp:237] Iteration 0, loss = 2.39858
I0522 12:09:59.845327 19035 solver.cpp:253]     Train net output #0: loss = 2.39858 (* 1 = 2.39858 loss)
I0522 12:09:59.845346 19035 sgd_solver.cpp:106] Iteration 0, lr = 0.0035
I0522 12:10:10.383332 19035 solver.cpp:237] Iteration 500, loss = 2.25758
I0522 12:10:10.383368 19035 solver.cpp:253]     Train net output #0: loss = 2.25758 (* 1 = 2.25758 loss)
I0522 12:10:10.383385 19035 sgd_solver.cpp:106] Iteration 500, lr = 0.0035
I0522 12:10:20.941553 19035 solver.cpp:237] Iteration 1000, loss = 2.10739
I0522 12:10:20.941604 19035 solver.cpp:253]     Train net output #0: loss = 2.10739 (* 1 = 2.10739 loss)
I0522 12:10:20.941619 19035 sgd_solver.cpp:106] Iteration 1000, lr = 0.0035
I0522 12:10:31.478258 19035 solver.cpp:237] Iteration 1500, loss = 1.97091
I0522 12:10:31.478399 19035 solver.cpp:253]     Train net output #0: loss = 1.97091 (* 1 = 1.97091 loss)
I0522 12:10:31.478413 19035 sgd_solver.cpp:106] Iteration 1500, lr = 0.0035
I0522 12:10:42.025252 19035 solver.cpp:237] Iteration 2000, loss = 1.40331
I0522 12:10:42.025301 19035 solver.cpp:253]     Train net output #0: loss = 1.40331 (* 1 = 1.40331 loss)
I0522 12:10:42.025315 19035 sgd_solver.cpp:106] Iteration 2000, lr = 0.0035
I0522 12:10:52.572679 19035 solver.cpp:237] Iteration 2500, loss = 1.62648
I0522 12:10:52.572713 19035 solver.cpp:253]     Train net output #0: loss = 1.62648 (* 1 = 1.62648 loss)
I0522 12:10:52.572727 19035 sgd_solver.cpp:106] Iteration 2500, lr = 0.0035
I0522 12:11:03.118194 19035 solver.cpp:237] Iteration 3000, loss = 1.77022
I0522 12:11:03.118341 19035 solver.cpp:253]     Train net output #0: loss = 1.77022 (* 1 = 1.77022 loss)
I0522 12:11:03.118356 19035 sgd_solver.cpp:106] Iteration 3000, lr = 0.0035
I0522 12:11:35.733510 19035 solver.cpp:237] Iteration 3500, loss = 1.70344
I0522 12:11:35.733676 19035 solver.cpp:253]     Train net output #0: loss = 1.70344 (* 1 = 1.70344 loss)
I0522 12:11:35.733691 19035 sgd_solver.cpp:106] Iteration 3500, lr = 0.0035
I0522 12:11:46.286649 19035 solver.cpp:237] Iteration 4000, loss = 1.29477
I0522 12:11:46.286685 19035 solver.cpp:253]     Train net output #0: loss = 1.29477 (* 1 = 1.29477 loss)
I0522 12:11:46.286700 19035 sgd_solver.cpp:106] Iteration 4000, lr = 0.0035
I0522 12:11:56.824638 19035 solver.cpp:237] Iteration 4500, loss = 1.31082
I0522 12:11:56.824684 19035 solver.cpp:253]     Train net output #0: loss = 1.31082 (* 1 = 1.31082 loss)
I0522 12:11:56.824699 19035 sgd_solver.cpp:106] Iteration 4500, lr = 0.0035
I0522 12:12:07.315812 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_5000.caffemodel
I0522 12:12:07.372298 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_5000.solverstate
I0522 12:12:07.403899 19035 solver.cpp:237] Iteration 5000, loss = 1.45208
I0522 12:12:07.403947 19035 solver.cpp:253]     Train net output #0: loss = 1.45208 (* 1 = 1.45208 loss)
I0522 12:12:07.403964 19035 sgd_solver.cpp:106] Iteration 5000, lr = 0.0035
I0522 12:12:17.928511 19035 solver.cpp:237] Iteration 5500, loss = 1.31891
I0522 12:12:17.928560 19035 solver.cpp:253]     Train net output #0: loss = 1.31891 (* 1 = 1.31891 loss)
I0522 12:12:17.928575 19035 sgd_solver.cpp:106] Iteration 5500, lr = 0.0035
I0522 12:12:28.459933 19035 solver.cpp:237] Iteration 6000, loss = 1.43334
I0522 12:12:28.459969 19035 solver.cpp:253]     Train net output #0: loss = 1.43334 (* 1 = 1.43334 loss)
I0522 12:12:28.459982 19035 sgd_solver.cpp:106] Iteration 6000, lr = 0.0035
I0522 12:12:38.981156 19035 solver.cpp:237] Iteration 6500, loss = 1.45969
I0522 12:12:38.981297 19035 solver.cpp:253]     Train net output #0: loss = 1.45969 (* 1 = 1.45969 loss)
I0522 12:12:38.981312 19035 sgd_solver.cpp:106] Iteration 6500, lr = 0.0035
I0522 12:13:11.649477 19035 solver.cpp:237] Iteration 7000, loss = 1.08123
I0522 12:13:11.649637 19035 solver.cpp:253]     Train net output #0: loss = 1.08123 (* 1 = 1.08123 loss)
I0522 12:13:11.649652 19035 sgd_solver.cpp:106] Iteration 7000, lr = 0.0035
I0522 12:13:22.168378 19035 solver.cpp:237] Iteration 7500, loss = 1.18201
I0522 12:13:22.168414 19035 solver.cpp:253]     Train net output #0: loss = 1.18201 (* 1 = 1.18201 loss)
I0522 12:13:22.168431 19035 sgd_solver.cpp:106] Iteration 7500, lr = 0.0035
I0522 12:13:32.688096 19035 solver.cpp:237] Iteration 8000, loss = 1.25307
I0522 12:13:32.688148 19035 solver.cpp:253]     Train net output #0: loss = 1.25307 (* 1 = 1.25307 loss)
I0522 12:13:32.688160 19035 sgd_solver.cpp:106] Iteration 8000, lr = 0.0035
I0522 12:13:43.216689 19035 solver.cpp:237] Iteration 8500, loss = 1.21727
I0522 12:13:43.216840 19035 solver.cpp:253]     Train net output #0: loss = 1.21727 (* 1 = 1.21727 loss)
I0522 12:13:43.216853 19035 sgd_solver.cpp:106] Iteration 8500, lr = 0.0035
I0522 12:13:53.739408 19035 solver.cpp:237] Iteration 9000, loss = 1.29473
I0522 12:13:53.739444 19035 solver.cpp:253]     Train net output #0: loss = 1.29473 (* 1 = 1.29473 loss)
I0522 12:13:53.739456 19035 sgd_solver.cpp:106] Iteration 9000, lr = 0.0035
I0522 12:14:04.273386 19035 solver.cpp:237] Iteration 9500, loss = 1.32842
I0522 12:14:04.273442 19035 solver.cpp:253]     Train net output #0: loss = 1.32842 (* 1 = 1.32842 loss)
I0522 12:14:04.273455 19035 sgd_solver.cpp:106] Iteration 9500, lr = 0.0035
I0522 12:14:14.773097 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_10000.caffemodel
I0522 12:14:14.826432 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_10000.solverstate
I0522 12:14:14.851913 19035 solver.cpp:341] Iteration 10000, Testing net (#0)
I0522 12:15:04.393741 19035 solver.cpp:409]     Test net output #0: accuracy = 0.832616
I0522 12:15:04.393903 19035 solver.cpp:409]     Test net output #1: loss = 0.60918 (* 1 = 0.60918 loss)
I0522 12:15:26.518479 19035 solver.cpp:237] Iteration 10000, loss = 1.14515
I0522 12:15:26.518537 19035 solver.cpp:253]     Train net output #0: loss = 1.14515 (* 1 = 1.14515 loss)
I0522 12:15:26.518558 19035 sgd_solver.cpp:106] Iteration 10000, lr = 0.0035
I0522 12:15:37.023097 19035 solver.cpp:237] Iteration 10500, loss = 1.42508
I0522 12:15:37.023249 19035 solver.cpp:253]     Train net output #0: loss = 1.42508 (* 1 = 1.42508 loss)
I0522 12:15:37.023263 19035 sgd_solver.cpp:106] Iteration 10500, lr = 0.0035
I0522 12:15:47.507419 19035 solver.cpp:237] Iteration 11000, loss = 1.62878
I0522 12:15:47.507455 19035 solver.cpp:253]     Train net output #0: loss = 1.62878 (* 1 = 1.62878 loss)
I0522 12:15:47.507468 19035 sgd_solver.cpp:106] Iteration 11000, lr = 0.0035
I0522 12:15:58.018507 19035 solver.cpp:237] Iteration 11500, loss = 1.58864
I0522 12:15:58.018554 19035 solver.cpp:253]     Train net output #0: loss = 1.58864 (* 1 = 1.58864 loss)
I0522 12:15:58.018569 19035 sgd_solver.cpp:106] Iteration 11500, lr = 0.0035
I0522 12:16:08.516651 19035 solver.cpp:237] Iteration 12000, loss = 1.35915
I0522 12:16:08.516803 19035 solver.cpp:253]     Train net output #0: loss = 1.35915 (* 1 = 1.35915 loss)
I0522 12:16:08.516818 19035 sgd_solver.cpp:106] Iteration 12000, lr = 0.0035
I0522 12:16:19.024667 19035 solver.cpp:237] Iteration 12500, loss = 1.39755
I0522 12:16:19.024703 19035 solver.cpp:253]     Train net output #0: loss = 1.39755 (* 1 = 1.39755 loss)
I0522 12:16:19.024719 19035 sgd_solver.cpp:106] Iteration 12500, lr = 0.0035
I0522 12:16:29.527788 19035 solver.cpp:237] Iteration 13000, loss = 0.992466
I0522 12:16:29.527838 19035 solver.cpp:253]     Train net output #0: loss = 0.992466 (* 1 = 0.992466 loss)
I0522 12:16:29.527853 19035 sgd_solver.cpp:106] Iteration 13000, lr = 0.0035
I0522 12:17:02.180740 19035 solver.cpp:237] Iteration 13500, loss = 1.308
I0522 12:17:02.180924 19035 solver.cpp:253]     Train net output #0: loss = 1.308 (* 1 = 1.308 loss)
I0522 12:17:02.180938 19035 sgd_solver.cpp:106] Iteration 13500, lr = 0.0035
I0522 12:17:12.683146 19035 solver.cpp:237] Iteration 14000, loss = 1.21399
I0522 12:17:12.683182 19035 solver.cpp:253]     Train net output #0: loss = 1.21399 (* 1 = 1.21399 loss)
I0522 12:17:12.683197 19035 sgd_solver.cpp:106] Iteration 14000, lr = 0.0035
I0522 12:17:23.181427 19035 solver.cpp:237] Iteration 14500, loss = 1.11066
I0522 12:17:23.181476 19035 solver.cpp:253]     Train net output #0: loss = 1.11066 (* 1 = 1.11066 loss)
I0522 12:17:23.181491 19035 sgd_solver.cpp:106] Iteration 14500, lr = 0.0035
I0522 12:17:33.653281 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_15000.caffemodel
I0522 12:17:33.709931 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_15000.solverstate
I0522 12:17:33.744339 19035 solver.cpp:237] Iteration 15000, loss = 1.47918
I0522 12:17:33.744393 19035 solver.cpp:253]     Train net output #0: loss = 1.47918 (* 1 = 1.47918 loss)
I0522 12:17:33.744407 19035 sgd_solver.cpp:106] Iteration 15000, lr = 0.0035
I0522 12:17:44.237572 19035 solver.cpp:237] Iteration 15500, loss = 1.39281
I0522 12:17:44.237629 19035 solver.cpp:253]     Train net output #0: loss = 1.39281 (* 1 = 1.39281 loss)
I0522 12:17:44.237643 19035 sgd_solver.cpp:106] Iteration 15500, lr = 0.0035
I0522 12:17:54.735749 19035 solver.cpp:237] Iteration 16000, loss = 1.54517
I0522 12:17:54.735785 19035 solver.cpp:253]     Train net output #0: loss = 1.54517 (* 1 = 1.54517 loss)
I0522 12:17:54.735798 19035 sgd_solver.cpp:106] Iteration 16000, lr = 0.0035
I0522 12:18:05.229909 19035 solver.cpp:237] Iteration 16500, loss = 1.6198
I0522 12:18:05.230057 19035 solver.cpp:253]     Train net output #0: loss = 1.6198 (* 1 = 1.6198 loss)
I0522 12:18:05.230069 19035 sgd_solver.cpp:106] Iteration 16500, lr = 0.0035
I0522 12:18:37.888988 19035 solver.cpp:237] Iteration 17000, loss = 1.1554
I0522 12:18:37.889153 19035 solver.cpp:253]     Train net output #0: loss = 1.1554 (* 1 = 1.1554 loss)
I0522 12:18:37.889168 19035 sgd_solver.cpp:106] Iteration 17000, lr = 0.0035
I0522 12:18:48.382125 19035 solver.cpp:237] Iteration 17500, loss = 1.23585
I0522 12:18:48.382161 19035 solver.cpp:253]     Train net output #0: loss = 1.23585 (* 1 = 1.23585 loss)
I0522 12:18:48.382175 19035 sgd_solver.cpp:106] Iteration 17500, lr = 0.0035
I0522 12:18:58.890286 19035 solver.cpp:237] Iteration 18000, loss = 1.20288
I0522 12:18:58.890341 19035 solver.cpp:253]     Train net output #0: loss = 1.20288 (* 1 = 1.20288 loss)
I0522 12:18:58.890354 19035 sgd_solver.cpp:106] Iteration 18000, lr = 0.0035
I0522 12:19:09.390008 19035 solver.cpp:237] Iteration 18500, loss = 1.49812
I0522 12:19:09.390142 19035 solver.cpp:253]     Train net output #0: loss = 1.49812 (* 1 = 1.49812 loss)
I0522 12:19:09.390156 19035 sgd_solver.cpp:106] Iteration 18500, lr = 0.0035
I0522 12:19:19.885296 19035 solver.cpp:237] Iteration 19000, loss = 0.99207
I0522 12:19:19.885332 19035 solver.cpp:253]     Train net output #0: loss = 0.99207 (* 1 = 0.99207 loss)
I0522 12:19:19.885349 19035 sgd_solver.cpp:106] Iteration 19000, lr = 0.0035
I0522 12:19:30.391510 19035 solver.cpp:237] Iteration 19500, loss = 1.32766
I0522 12:19:30.391558 19035 solver.cpp:253]     Train net output #0: loss = 1.32766 (* 1 = 1.32766 loss)
I0522 12:19:30.391574 19035 sgd_solver.cpp:106] Iteration 19500, lr = 0.0035
I0522 12:19:40.866448 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_20000.caffemodel
I0522 12:19:40.921138 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_20000.solverstate
I0522 12:19:40.949808 19035 solver.cpp:341] Iteration 20000, Testing net (#0)
I0522 12:20:51.420359 19035 solver.cpp:409]     Test net output #0: accuracy = 0.856425
I0522 12:20:51.420531 19035 solver.cpp:409]     Test net output #1: loss = 0.496357 (* 1 = 0.496357 loss)
I0522 12:21:13.597250 19035 solver.cpp:237] Iteration 20000, loss = 1.2563
I0522 12:21:13.597308 19035 solver.cpp:253]     Train net output #0: loss = 1.2563 (* 1 = 1.2563 loss)
I0522 12:21:13.597324 19035 sgd_solver.cpp:106] Iteration 20000, lr = 0.0035
I0522 12:21:24.188774 19035 solver.cpp:237] Iteration 20500, loss = 1.02008
I0522 12:21:24.188926 19035 solver.cpp:253]     Train net output #0: loss = 1.02008 (* 1 = 1.02008 loss)
I0522 12:21:24.188941 19035 sgd_solver.cpp:106] Iteration 20500, lr = 0.0035
I0522 12:21:34.764842 19035 solver.cpp:237] Iteration 21000, loss = 1.31142
I0522 12:21:34.764895 19035 solver.cpp:253]     Train net output #0: loss = 1.31142 (* 1 = 1.31142 loss)
I0522 12:21:34.764909 19035 sgd_solver.cpp:106] Iteration 21000, lr = 0.0035
I0522 12:21:45.344985 19035 solver.cpp:237] Iteration 21500, loss = 1.26821
I0522 12:21:45.345022 19035 solver.cpp:253]     Train net output #0: loss = 1.26821 (* 1 = 1.26821 loss)
I0522 12:21:45.345037 19035 sgd_solver.cpp:106] Iteration 21500, lr = 0.0035
I0522 12:21:55.928791 19035 solver.cpp:237] Iteration 22000, loss = 1.449
I0522 12:21:55.928943 19035 solver.cpp:253]     Train net output #0: loss = 1.449 (* 1 = 1.449 loss)
I0522 12:21:55.928958 19035 sgd_solver.cpp:106] Iteration 22000, lr = 0.0035
I0522 12:22:06.502095 19035 solver.cpp:237] Iteration 22500, loss = 1.04404
I0522 12:22:06.502131 19035 solver.cpp:253]     Train net output #0: loss = 1.04404 (* 1 = 1.04404 loss)
I0522 12:22:06.502147 19035 sgd_solver.cpp:106] Iteration 22500, lr = 0.0035
I0522 12:22:17.073034 19035 solver.cpp:237] Iteration 23000, loss = 1.14338
I0522 12:22:17.073088 19035 solver.cpp:253]     Train net output #0: loss = 1.14338 (* 1 = 1.14338 loss)
I0522 12:22:17.073102 19035 sgd_solver.cpp:106] Iteration 23000, lr = 0.0035
I0522 12:22:49.815636 19035 solver.cpp:237] Iteration 23500, loss = 1.18746
I0522 12:22:49.815805 19035 solver.cpp:253]     Train net output #0: loss = 1.18746 (* 1 = 1.18746 loss)
I0522 12:22:49.815822 19035 sgd_solver.cpp:106] Iteration 23500, lr = 0.0035
I0522 12:23:00.429219 19035 solver.cpp:237] Iteration 24000, loss = 1.18051
I0522 12:23:00.429255 19035 solver.cpp:253]     Train net output #0: loss = 1.18051 (* 1 = 1.18051 loss)
I0522 12:23:00.429271 19035 sgd_solver.cpp:106] Iteration 24000, lr = 0.0035
I0522 12:23:11.048156 19035 solver.cpp:237] Iteration 24500, loss = 0.964813
I0522 12:23:11.048207 19035 solver.cpp:253]     Train net output #0: loss = 0.964813 (* 1 = 0.964813 loss)
I0522 12:23:11.048221 19035 sgd_solver.cpp:106] Iteration 24500, lr = 0.0035
I0522 12:23:21.620323 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_25000.caffemodel
I0522 12:23:21.677598 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_25000.solverstate
I0522 12:23:21.712633 19035 solver.cpp:237] Iteration 25000, loss = 1.42288
I0522 12:23:21.712689 19035 solver.cpp:253]     Train net output #0: loss = 1.42288 (* 1 = 1.42288 loss)
I0522 12:23:21.712703 19035 sgd_solver.cpp:106] Iteration 25000, lr = 0.0035
I0522 12:23:32.303295 19035 solver.cpp:237] Iteration 25500, loss = 1.38882
I0522 12:23:32.303349 19035 solver.cpp:253]     Train net output #0: loss = 1.38882 (* 1 = 1.38882 loss)
I0522 12:23:32.303364 19035 sgd_solver.cpp:106] Iteration 25500, lr = 0.0035
I0522 12:23:42.922014 19035 solver.cpp:237] Iteration 26000, loss = 1.19809
I0522 12:23:42.922050 19035 solver.cpp:253]     Train net output #0: loss = 1.19809 (* 1 = 1.19809 loss)
I0522 12:23:42.922066 19035 sgd_solver.cpp:106] Iteration 26000, lr = 0.0035
I0522 12:23:53.521435 19035 solver.cpp:237] Iteration 26500, loss = 1.53318
I0522 12:23:53.521580 19035 solver.cpp:253]     Train net output #0: loss = 1.53318 (* 1 = 1.53318 loss)
I0522 12:23:53.521596 19035 sgd_solver.cpp:106] Iteration 26500, lr = 0.0035
I0522 12:24:26.265476 19035 solver.cpp:237] Iteration 27000, loss = 1.04679
I0522 12:24:26.265656 19035 solver.cpp:253]     Train net output #0: loss = 1.04679 (* 1 = 1.04679 loss)
I0522 12:24:26.265672 19035 sgd_solver.cpp:106] Iteration 27000, lr = 0.0035
I0522 12:24:36.865507 19035 solver.cpp:237] Iteration 27500, loss = 1.34074
I0522 12:24:36.865542 19035 solver.cpp:253]     Train net output #0: loss = 1.34074 (* 1 = 1.34074 loss)
I0522 12:24:36.865559 19035 sgd_solver.cpp:106] Iteration 27500, lr = 0.0035
I0522 12:24:47.477583 19035 solver.cpp:237] Iteration 28000, loss = 1.10097
I0522 12:24:47.477634 19035 solver.cpp:253]     Train net output #0: loss = 1.10097 (* 1 = 1.10097 loss)
I0522 12:24:47.477650 19035 sgd_solver.cpp:106] Iteration 28000, lr = 0.0035
I0522 12:24:58.092109 19035 solver.cpp:237] Iteration 28500, loss = 0.772244
I0522 12:24:58.092253 19035 solver.cpp:253]     Train net output #0: loss = 0.772244 (* 1 = 0.772244 loss)
I0522 12:24:58.092268 19035 sgd_solver.cpp:106] Iteration 28500, lr = 0.0035
I0522 12:25:08.707353 19035 solver.cpp:237] Iteration 29000, loss = 1.36047
I0522 12:25:08.707388 19035 solver.cpp:253]     Train net output #0: loss = 1.36047 (* 1 = 1.36047 loss)
I0522 12:25:08.707402 19035 sgd_solver.cpp:106] Iteration 29000, lr = 0.0035
I0522 12:25:19.342290 19035 solver.cpp:237] Iteration 29500, loss = 1.06357
I0522 12:25:19.342339 19035 solver.cpp:253]     Train net output #0: loss = 1.06357 (* 1 = 1.06357 loss)
I0522 12:25:19.342352 19035 sgd_solver.cpp:106] Iteration 29500, lr = 0.0035
I0522 12:25:29.913794 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_30000.caffemodel
I0522 12:25:29.966413 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_30000.solverstate
I0522 12:25:29.992622 19035 solver.cpp:341] Iteration 30000, Testing net (#0)
I0522 12:26:19.279525 19035 solver.cpp:409]     Test net output #0: accuracy = 0.862912
I0522 12:26:19.279690 19035 solver.cpp:409]     Test net output #1: loss = 0.430376 (* 1 = 0.430376 loss)
I0522 12:26:41.418344 19035 solver.cpp:237] Iteration 30000, loss = 0.641331
I0522 12:26:41.418402 19035 solver.cpp:253]     Train net output #0: loss = 0.641331 (* 1 = 0.641331 loss)
I0522 12:26:41.418421 19035 sgd_solver.cpp:106] Iteration 30000, lr = 0.0035
I0522 12:26:51.959967 19035 solver.cpp:237] Iteration 30500, loss = 0.925992
I0522 12:26:51.960135 19035 solver.cpp:253]     Train net output #0: loss = 0.925992 (* 1 = 0.925992 loss)
I0522 12:26:51.960150 19035 sgd_solver.cpp:106] Iteration 30500, lr = 0.0035
I0522 12:27:02.502933 19035 solver.cpp:237] Iteration 31000, loss = 1.17159
I0522 12:27:02.502969 19035 solver.cpp:253]     Train net output #0: loss = 1.17159 (* 1 = 1.17159 loss)
I0522 12:27:02.502982 19035 sgd_solver.cpp:106] Iteration 31000, lr = 0.0035
I0522 12:27:13.028460 19035 solver.cpp:237] Iteration 31500, loss = 1.49185
I0522 12:27:13.028496 19035 solver.cpp:253]     Train net output #0: loss = 1.49185 (* 1 = 1.49185 loss)
I0522 12:27:13.028512 19035 sgd_solver.cpp:106] Iteration 31500, lr = 0.0035
I0522 12:27:23.559878 19035 solver.cpp:237] Iteration 32000, loss = 1.31003
I0522 12:27:23.560039 19035 solver.cpp:253]     Train net output #0: loss = 1.31003 (* 1 = 1.31003 loss)
I0522 12:27:23.560053 19035 sgd_solver.cpp:106] Iteration 32000, lr = 0.0035
I0522 12:27:34.077005 19035 solver.cpp:237] Iteration 32500, loss = 1.39032
I0522 12:27:34.077041 19035 solver.cpp:253]     Train net output #0: loss = 1.39032 (* 1 = 1.39032 loss)
I0522 12:27:34.077057 19035 sgd_solver.cpp:106] Iteration 32500, lr = 0.0035
I0522 12:27:44.603308 19035 solver.cpp:237] Iteration 33000, loss = 1.26647
I0522 12:27:44.603363 19035 solver.cpp:253]     Train net output #0: loss = 1.26647 (* 1 = 1.26647 loss)
I0522 12:27:44.603376 19035 sgd_solver.cpp:106] Iteration 33000, lr = 0.0035
I0522 12:28:17.272943 19035 solver.cpp:237] Iteration 33500, loss = 0.992682
I0522 12:28:17.273123 19035 solver.cpp:253]     Train net output #0: loss = 0.992682 (* 1 = 0.992682 loss)
I0522 12:28:17.273138 19035 sgd_solver.cpp:106] Iteration 33500, lr = 0.0035
I0522 12:28:27.811609 19035 solver.cpp:237] Iteration 34000, loss = 1.05412
I0522 12:28:27.811645 19035 solver.cpp:253]     Train net output #0: loss = 1.05412 (* 1 = 1.05412 loss)
I0522 12:28:27.811661 19035 sgd_solver.cpp:106] Iteration 34000, lr = 0.0035
I0522 12:28:38.343608 19035 solver.cpp:237] Iteration 34500, loss = 1.41911
I0522 12:28:38.343659 19035 solver.cpp:253]     Train net output #0: loss = 1.41911 (* 1 = 1.41911 loss)
I0522 12:28:38.343674 19035 sgd_solver.cpp:106] Iteration 34500, lr = 0.0035
I0522 12:28:48.851611 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_35000.caffemodel
I0522 12:28:48.904022 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_35000.solverstate
I0522 12:28:48.937093 19035 solver.cpp:237] Iteration 35000, loss = 1.13546
I0522 12:28:48.937142 19035 solver.cpp:253]     Train net output #0: loss = 1.13546 (* 1 = 1.13546 loss)
I0522 12:28:48.937156 19035 sgd_solver.cpp:106] Iteration 35000, lr = 0.0035
I0522 12:28:59.484755 19035 solver.cpp:237] Iteration 35500, loss = 1.37115
I0522 12:28:59.484805 19035 solver.cpp:253]     Train net output #0: loss = 1.37115 (* 1 = 1.37115 loss)
I0522 12:28:59.484819 19035 sgd_solver.cpp:106] Iteration 35500, lr = 0.0035
I0522 12:29:10.017839 19035 solver.cpp:237] Iteration 36000, loss = 0.924443
I0522 12:29:10.017875 19035 solver.cpp:253]     Train net output #0: loss = 0.924443 (* 1 = 0.924443 loss)
I0522 12:29:10.017892 19035 sgd_solver.cpp:106] Iteration 36000, lr = 0.0035
I0522 12:29:20.554814 19035 solver.cpp:237] Iteration 36500, loss = 1.175
I0522 12:29:20.554956 19035 solver.cpp:253]     Train net output #0: loss = 1.175 (* 1 = 1.175 loss)
I0522 12:29:20.554970 19035 sgd_solver.cpp:106] Iteration 36500, lr = 0.0035
I0522 12:29:53.281064 19035 solver.cpp:237] Iteration 37000, loss = 1.06082
I0522 12:29:53.281237 19035 solver.cpp:253]     Train net output #0: loss = 1.06082 (* 1 = 1.06082 loss)
I0522 12:29:53.281252 19035 sgd_solver.cpp:106] Iteration 37000, lr = 0.0035
I0522 12:30:03.828512 19035 solver.cpp:237] Iteration 37500, loss = 1.31649
I0522 12:30:03.828548 19035 solver.cpp:253]     Train net output #0: loss = 1.31648 (* 1 = 1.31648 loss)
I0522 12:30:03.828567 19035 sgd_solver.cpp:106] Iteration 37500, lr = 0.0035
I0522 12:30:14.369295 19035 solver.cpp:237] Iteration 38000, loss = 1.08643
I0522 12:30:14.369348 19035 solver.cpp:253]     Train net output #0: loss = 1.08643 (* 1 = 1.08643 loss)
I0522 12:30:14.369362 19035 sgd_solver.cpp:106] Iteration 38000, lr = 0.0035
I0522 12:30:24.891115 19035 solver.cpp:237] Iteration 38500, loss = 1.26556
I0522 12:30:24.891260 19035 solver.cpp:253]     Train net output #0: loss = 1.26556 (* 1 = 1.26556 loss)
I0522 12:30:24.891276 19035 sgd_solver.cpp:106] Iteration 38500, lr = 0.0035
I0522 12:30:35.414968 19035 solver.cpp:237] Iteration 39000, loss = 1.09104
I0522 12:30:35.415002 19035 solver.cpp:253]     Train net output #0: loss = 1.09104 (* 1 = 1.09104 loss)
I0522 12:30:35.415017 19035 sgd_solver.cpp:106] Iteration 39000, lr = 0.0035
I0522 12:30:45.914233 19035 solver.cpp:237] Iteration 39500, loss = 1.26355
I0522 12:30:45.914276 19035 solver.cpp:253]     Train net output #0: loss = 1.26355 (* 1 = 1.26355 loss)
I0522 12:30:45.914293 19035 sgd_solver.cpp:106] Iteration 39500, lr = 0.0035
I0522 12:30:56.399745 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_40000.caffemodel
I0522 12:30:56.452718 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_40000.solverstate
I0522 12:30:56.479255 19035 solver.cpp:341] Iteration 40000, Testing net (#0)
I0522 12:32:06.966522 19035 solver.cpp:409]     Test net output #0: accuracy = 0.874044
I0522 12:32:06.966697 19035 solver.cpp:409]     Test net output #1: loss = 0.401007 (* 1 = 0.401007 loss)
I0522 12:32:29.090986 19035 solver.cpp:237] Iteration 40000, loss = 1.36462
I0522 12:32:29.091042 19035 solver.cpp:253]     Train net output #0: loss = 1.36462 (* 1 = 1.36462 loss)
I0522 12:32:29.091056 19035 sgd_solver.cpp:106] Iteration 40000, lr = 0.0035
I0522 12:32:39.616504 19035 solver.cpp:237] Iteration 40500, loss = 1.3558
I0522 12:32:39.616662 19035 solver.cpp:253]     Train net output #0: loss = 1.3558 (* 1 = 1.3558 loss)
I0522 12:32:39.616674 19035 sgd_solver.cpp:106] Iteration 40500, lr = 0.0035
I0522 12:32:50.140041 19035 solver.cpp:237] Iteration 41000, loss = 1.33762
I0522 12:32:50.140092 19035 solver.cpp:253]     Train net output #0: loss = 1.33762 (* 1 = 1.33762 loss)
I0522 12:32:50.140106 19035 sgd_solver.cpp:106] Iteration 41000, lr = 0.0035
I0522 12:33:00.671809 19035 solver.cpp:237] Iteration 41500, loss = 0.675421
I0522 12:33:00.671846 19035 solver.cpp:253]     Train net output #0: loss = 0.675421 (* 1 = 0.675421 loss)
I0522 12:33:00.671861 19035 sgd_solver.cpp:106] Iteration 41500, lr = 0.0035
I0522 12:33:11.244153 19035 solver.cpp:237] Iteration 42000, loss = 1.28729
I0522 12:33:11.244320 19035 solver.cpp:253]     Train net output #0: loss = 1.28729 (* 1 = 1.28729 loss)
I0522 12:33:11.244334 19035 sgd_solver.cpp:106] Iteration 42000, lr = 0.0035
I0522 12:33:21.859830 19035 solver.cpp:237] Iteration 42500, loss = 0.948058
I0522 12:33:21.859866 19035 solver.cpp:253]     Train net output #0: loss = 0.948058 (* 1 = 0.948058 loss)
I0522 12:33:21.859882 19035 sgd_solver.cpp:106] Iteration 42500, lr = 0.0035
I0522 12:33:32.488003 19035 solver.cpp:237] Iteration 43000, loss = 0.95018
I0522 12:33:32.488052 19035 solver.cpp:253]     Train net output #0: loss = 0.95018 (* 1 = 0.95018 loss)
I0522 12:33:32.488068 19035 sgd_solver.cpp:106] Iteration 43000, lr = 0.0035
I0522 12:34:05.223748 19035 solver.cpp:237] Iteration 43500, loss = 1.07894
I0522 12:34:05.223925 19035 solver.cpp:253]     Train net output #0: loss = 1.07894 (* 1 = 1.07894 loss)
I0522 12:34:05.223940 19035 sgd_solver.cpp:106] Iteration 43500, lr = 0.0035
I0522 12:34:15.828464 19035 solver.cpp:237] Iteration 44000, loss = 1.60351
I0522 12:34:15.828500 19035 solver.cpp:253]     Train net output #0: loss = 1.60351 (* 1 = 1.60351 loss)
I0522 12:34:15.828512 19035 sgd_solver.cpp:106] Iteration 44000, lr = 0.0035
I0522 12:34:26.424412 19035 solver.cpp:237] Iteration 44500, loss = 1.38775
I0522 12:34:26.424458 19035 solver.cpp:253]     Train net output #0: loss = 1.38775 (* 1 = 1.38775 loss)
I0522 12:34:26.424475 19035 sgd_solver.cpp:106] Iteration 44500, lr = 0.0035
I0522 12:34:37.011924 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_45000.caffemodel
I0522 12:34:37.066354 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_45000.solverstate
I0522 12:34:37.100963 19035 solver.cpp:237] Iteration 45000, loss = 1.26547
I0522 12:34:37.101016 19035 solver.cpp:253]     Train net output #0: loss = 1.26548 (* 1 = 1.26548 loss)
I0522 12:34:37.101030 19035 sgd_solver.cpp:106] Iteration 45000, lr = 0.0035
I0522 12:34:47.688127 19035 solver.cpp:237] Iteration 45500, loss = 1.30736
I0522 12:34:47.688180 19035 solver.cpp:253]     Train net output #0: loss = 1.30736 (* 1 = 1.30736 loss)
I0522 12:34:47.688194 19035 sgd_solver.cpp:106] Iteration 45500, lr = 0.0035
I0522 12:34:58.200367 19035 solver.cpp:237] Iteration 46000, loss = 1.6892
I0522 12:34:58.200402 19035 solver.cpp:253]     Train net output #0: loss = 1.6892 (* 1 = 1.6892 loss)
I0522 12:34:58.200419 19035 sgd_solver.cpp:106] Iteration 46000, lr = 0.0035
I0522 12:35:08.696647 19035 solver.cpp:237] Iteration 46500, loss = 1.33074
I0522 12:35:08.696807 19035 solver.cpp:253]     Train net output #0: loss = 1.33074 (* 1 = 1.33074 loss)
I0522 12:35:08.696821 19035 sgd_solver.cpp:106] Iteration 46500, lr = 0.0035
I0522 12:35:41.286207 19035 solver.cpp:237] Iteration 47000, loss = 1.25068
I0522 12:35:41.286380 19035 solver.cpp:253]     Train net output #0: loss = 1.25068 (* 1 = 1.25068 loss)
I0522 12:35:41.286396 19035 sgd_solver.cpp:106] Iteration 47000, lr = 0.0035
I0522 12:35:51.802244 19035 solver.cpp:237] Iteration 47500, loss = 1.68023
I0522 12:35:51.802280 19035 solver.cpp:253]     Train net output #0: loss = 1.68023 (* 1 = 1.68023 loss)
I0522 12:35:51.802294 19035 sgd_solver.cpp:106] Iteration 47500, lr = 0.0035
I0522 12:36:02.316517 19035 solver.cpp:237] Iteration 48000, loss = 1.26275
I0522 12:36:02.316571 19035 solver.cpp:253]     Train net output #0: loss = 1.26275 (* 1 = 1.26275 loss)
I0522 12:36:02.316586 19035 sgd_solver.cpp:106] Iteration 48000, lr = 0.0035
I0522 12:36:12.829998 19035 solver.cpp:237] Iteration 48500, loss = 1.54284
I0522 12:36:12.830145 19035 solver.cpp:253]     Train net output #0: loss = 1.54284 (* 1 = 1.54284 loss)
I0522 12:36:12.830162 19035 sgd_solver.cpp:106] Iteration 48500, lr = 0.0035
I0522 12:36:23.343004 19035 solver.cpp:237] Iteration 49000, loss = 1.26096
I0522 12:36:23.343040 19035 solver.cpp:253]     Train net output #0: loss = 1.26096 (* 1 = 1.26096 loss)
I0522 12:36:23.343056 19035 sgd_solver.cpp:106] Iteration 49000, lr = 0.0035
I0522 12:36:33.860162 19035 solver.cpp:237] Iteration 49500, loss = 1.54969
I0522 12:36:33.860211 19035 solver.cpp:253]     Train net output #0: loss = 1.54969 (* 1 = 1.54969 loss)
I0522 12:36:33.860226 19035 sgd_solver.cpp:106] Iteration 49500, lr = 0.0035
I0522 12:36:44.347992 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_50000.caffemodel
I0522 12:36:44.404110 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_50000.solverstate
I0522 12:36:44.432667 19035 solver.cpp:341] Iteration 50000, Testing net (#0)
I0522 12:37:34.030524 19035 solver.cpp:409]     Test net output #0: accuracy = 0.879801
I0522 12:37:34.030699 19035 solver.cpp:409]     Test net output #1: loss = 0.399649 (* 1 = 0.399649 loss)
I0522 12:37:54.919699 19035 solver.cpp:237] Iteration 50000, loss = 0.781136
I0522 12:37:54.919757 19035 solver.cpp:253]     Train net output #0: loss = 0.781136 (* 1 = 0.781136 loss)
I0522 12:37:54.919772 19035 sgd_solver.cpp:106] Iteration 50000, lr = 0.0035
I0522 12:38:05.464304 19035 solver.cpp:237] Iteration 50500, loss = 1.16529
I0522 12:38:05.464457 19035 solver.cpp:253]     Train net output #0: loss = 1.16529 (* 1 = 1.16529 loss)
I0522 12:38:05.464471 19035 sgd_solver.cpp:106] Iteration 50500, lr = 0.0035
I0522 12:38:15.991333 19035 solver.cpp:237] Iteration 51000, loss = 1.4384
I0522 12:38:15.991372 19035 solver.cpp:253]     Train net output #0: loss = 1.4384 (* 1 = 1.4384 loss)
I0522 12:38:15.991385 19035 sgd_solver.cpp:106] Iteration 51000, lr = 0.0035
I0522 12:38:26.522625 19035 solver.cpp:237] Iteration 51500, loss = 1.16447
I0522 12:38:26.522657 19035 solver.cpp:253]     Train net output #0: loss = 1.16447 (* 1 = 1.16447 loss)
I0522 12:38:26.522670 19035 sgd_solver.cpp:106] Iteration 51500, lr = 0.0035
I0522 12:38:37.057387 19035 solver.cpp:237] Iteration 52000, loss = 0.941844
I0522 12:38:37.057539 19035 solver.cpp:253]     Train net output #0: loss = 0.941844 (* 1 = 0.941844 loss)
I0522 12:38:37.057554 19035 sgd_solver.cpp:106] Iteration 52000, lr = 0.0035
I0522 12:38:47.583011 19035 solver.cpp:237] Iteration 52500, loss = 1.1143
I0522 12:38:47.583047 19035 solver.cpp:253]     Train net output #0: loss = 1.1143 (* 1 = 1.1143 loss)
I0522 12:38:47.583063 19035 sgd_solver.cpp:106] Iteration 52500, lr = 0.0035
I0522 12:38:58.124202 19035 solver.cpp:237] Iteration 53000, loss = 0.914626
I0522 12:38:58.124248 19035 solver.cpp:253]     Train net output #0: loss = 0.914627 (* 1 = 0.914627 loss)
I0522 12:38:58.124264 19035 sgd_solver.cpp:106] Iteration 53000, lr = 0.0035
I0522 12:39:29.539983 19035 solver.cpp:237] Iteration 53500, loss = 1.13381
I0522 12:39:29.540168 19035 solver.cpp:253]     Train net output #0: loss = 1.13381 (* 1 = 1.13381 loss)
I0522 12:39:29.540182 19035 sgd_solver.cpp:106] Iteration 53500, lr = 0.0035
I0522 12:39:40.072612 19035 solver.cpp:237] Iteration 54000, loss = 1.28564
I0522 12:39:40.072648 19035 solver.cpp:253]     Train net output #0: loss = 1.28564 (* 1 = 1.28564 loss)
I0522 12:39:40.072662 19035 sgd_solver.cpp:106] Iteration 54000, lr = 0.0035
I0522 12:39:50.594605 19035 solver.cpp:237] Iteration 54500, loss = 1.21307
I0522 12:39:50.594648 19035 solver.cpp:253]     Train net output #0: loss = 1.21307 (* 1 = 1.21307 loss)
I0522 12:39:50.594662 19035 sgd_solver.cpp:106] Iteration 54500, lr = 0.0035
I0522 12:40:01.109124 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_55000.caffemodel
I0522 12:40:01.162788 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_55000.solverstate
I0522 12:40:01.195822 19035 solver.cpp:237] Iteration 55000, loss = 0.936322
I0522 12:40:01.195873 19035 solver.cpp:253]     Train net output #0: loss = 0.936322 (* 1 = 0.936322 loss)
I0522 12:40:01.195888 19035 sgd_solver.cpp:106] Iteration 55000, lr = 0.0035
I0522 12:40:11.721767 19035 solver.cpp:237] Iteration 55500, loss = 1.57991
I0522 12:40:11.721820 19035 solver.cpp:253]     Train net output #0: loss = 1.57991 (* 1 = 1.57991 loss)
I0522 12:40:11.721837 19035 sgd_solver.cpp:106] Iteration 55500, lr = 0.0035
I0522 12:40:22.249680 19035 solver.cpp:237] Iteration 56000, loss = 1.4136
I0522 12:40:22.249716 19035 solver.cpp:253]     Train net output #0: loss = 1.4136 (* 1 = 1.4136 loss)
I0522 12:40:22.249732 19035 sgd_solver.cpp:106] Iteration 56000, lr = 0.0035
I0522 12:40:32.801357 19035 solver.cpp:237] Iteration 56500, loss = 1.03307
I0522 12:40:32.801509 19035 solver.cpp:253]     Train net output #0: loss = 1.03307 (* 1 = 1.03307 loss)
I0522 12:40:32.801523 19035 sgd_solver.cpp:106] Iteration 56500, lr = 0.0035
I0522 12:41:04.200305 19035 solver.cpp:237] Iteration 57000, loss = 1.49493
I0522 12:41:04.200477 19035 solver.cpp:253]     Train net output #0: loss = 1.49493 (* 1 = 1.49493 loss)
I0522 12:41:04.200492 19035 sgd_solver.cpp:106] Iteration 57000, lr = 0.0035
I0522 12:41:14.731848 19035 solver.cpp:237] Iteration 57500, loss = 1.24017
I0522 12:41:14.731884 19035 solver.cpp:253]     Train net output #0: loss = 1.24017 (* 1 = 1.24017 loss)
I0522 12:41:14.731900 19035 sgd_solver.cpp:106] Iteration 57500, lr = 0.0035
I0522 12:41:25.270486 19035 solver.cpp:237] Iteration 58000, loss = 1.30241
I0522 12:41:25.270522 19035 solver.cpp:253]     Train net output #0: loss = 1.30241 (* 1 = 1.30241 loss)
I0522 12:41:25.270537 19035 sgd_solver.cpp:106] Iteration 58000, lr = 0.0035
I0522 12:41:35.799556 19035 solver.cpp:237] Iteration 58500, loss = 1.13965
I0522 12:41:35.799708 19035 solver.cpp:253]     Train net output #0: loss = 1.13965 (* 1 = 1.13965 loss)
I0522 12:41:35.799722 19035 sgd_solver.cpp:106] Iteration 58500, lr = 0.0035
I0522 12:41:46.342279 19035 solver.cpp:237] Iteration 59000, loss = 1.38425
I0522 12:41:46.342315 19035 solver.cpp:253]     Train net output #0: loss = 1.38425 (* 1 = 1.38425 loss)
I0522 12:41:46.342329 19035 sgd_solver.cpp:106] Iteration 59000, lr = 0.0035
I0522 12:41:56.856941 19035 solver.cpp:237] Iteration 59500, loss = 1.49402
I0522 12:41:56.856992 19035 solver.cpp:253]     Train net output #0: loss = 1.49402 (* 1 = 1.49402 loss)
I0522 12:41:56.857007 19035 sgd_solver.cpp:106] Iteration 59500, lr = 0.0035
I0522 12:42:07.368643 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_60000.caffemodel
I0522 12:42:07.420931 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_60000.solverstate
I0522 12:42:07.447566 19035 solver.cpp:341] Iteration 60000, Testing net (#0)
I0522 12:43:17.846501 19035 solver.cpp:409]     Test net output #0: accuracy = 0.883014
I0522 12:43:17.846679 19035 solver.cpp:409]     Test net output #1: loss = 0.366096 (* 1 = 0.366096 loss)
I0522 12:43:38.687433 19035 solver.cpp:237] Iteration 60000, loss = 0.914948
I0522 12:43:38.687490 19035 solver.cpp:253]     Train net output #0: loss = 0.914948 (* 1 = 0.914948 loss)
I0522 12:43:38.687505 19035 sgd_solver.cpp:106] Iteration 60000, lr = 0.0035
I0522 12:43:49.282891 19035 solver.cpp:237] Iteration 60500, loss = 0.891004
I0522 12:43:49.283042 19035 solver.cpp:253]     Train net output #0: loss = 0.891004 (* 1 = 0.891004 loss)
I0522 12:43:49.283057 19035 sgd_solver.cpp:106] Iteration 60500, lr = 0.0035
I0522 12:43:59.874284 19035 solver.cpp:237] Iteration 61000, loss = 1.04709
I0522 12:43:59.874336 19035 solver.cpp:253]     Train net output #0: loss = 1.04709 (* 1 = 1.04709 loss)
I0522 12:43:59.874349 19035 sgd_solver.cpp:106] Iteration 61000, lr = 0.0035
I0522 12:44:10.497108 19035 solver.cpp:237] Iteration 61500, loss = 1.14374
I0522 12:44:10.497144 19035 solver.cpp:253]     Train net output #0: loss = 1.14374 (* 1 = 1.14374 loss)
I0522 12:44:10.497158 19035 sgd_solver.cpp:106] Iteration 61500, lr = 0.0035
I0522 12:44:21.104171 19035 solver.cpp:237] Iteration 62000, loss = 1.08295
I0522 12:44:21.104337 19035 solver.cpp:253]     Train net output #0: loss = 1.08295 (* 1 = 1.08295 loss)
I0522 12:44:21.104352 19035 sgd_solver.cpp:106] Iteration 62000, lr = 0.0035
I0522 12:44:31.722134 19035 solver.cpp:237] Iteration 62500, loss = 1.44697
I0522 12:44:31.722170 19035 solver.cpp:253]     Train net output #0: loss = 1.44697 (* 1 = 1.44697 loss)
I0522 12:44:31.722187 19035 sgd_solver.cpp:106] Iteration 62500, lr = 0.0035
I0522 12:44:42.343693 19035 solver.cpp:237] Iteration 63000, loss = 1.07021
I0522 12:44:42.343727 19035 solver.cpp:253]     Train net output #0: loss = 1.07021 (* 1 = 1.07021 loss)
I0522 12:44:42.343744 19035 sgd_solver.cpp:106] Iteration 63000, lr = 0.0035
I0522 12:45:13.834647 19035 solver.cpp:237] Iteration 63500, loss = 1.07867
I0522 12:45:13.834820 19035 solver.cpp:253]     Train net output #0: loss = 1.07867 (* 1 = 1.07867 loss)
I0522 12:45:13.834836 19035 sgd_solver.cpp:106] Iteration 63500, lr = 0.0035
I0522 12:45:24.431303 19035 solver.cpp:237] Iteration 64000, loss = 0.986818
I0522 12:45:24.431339 19035 solver.cpp:253]     Train net output #0: loss = 0.986818 (* 1 = 0.986818 loss)
I0522 12:45:24.431354 19035 sgd_solver.cpp:106] Iteration 64000, lr = 0.0035
I0522 12:45:35.038089 19035 solver.cpp:237] Iteration 64500, loss = 1.17883
I0522 12:45:35.038125 19035 solver.cpp:253]     Train net output #0: loss = 1.17883 (* 1 = 1.17883 loss)
I0522 12:45:35.038141 19035 sgd_solver.cpp:106] Iteration 64500, lr = 0.0035
I0522 12:45:45.622936 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_65000.caffemodel
I0522 12:45:45.675374 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_65000.solverstate
I0522 12:45:45.708027 19035 solver.cpp:237] Iteration 65000, loss = 1.20365
I0522 12:45:45.708076 19035 solver.cpp:253]     Train net output #0: loss = 1.20365 (* 1 = 1.20365 loss)
I0522 12:45:45.708091 19035 sgd_solver.cpp:106] Iteration 65000, lr = 0.0035
I0522 12:45:56.311427 19035 solver.cpp:237] Iteration 65500, loss = 1.1693
I0522 12:45:56.311463 19035 solver.cpp:253]     Train net output #0: loss = 1.1693 (* 1 = 1.1693 loss)
I0522 12:45:56.311476 19035 sgd_solver.cpp:106] Iteration 65500, lr = 0.0035
I0522 12:46:06.902120 19035 solver.cpp:237] Iteration 66000, loss = 1.13465
I0522 12:46:06.902166 19035 solver.cpp:253]     Train net output #0: loss = 1.13465 (* 1 = 1.13465 loss)
I0522 12:46:06.902182 19035 sgd_solver.cpp:106] Iteration 66000, lr = 0.0035
I0522 12:46:17.507967 19035 solver.cpp:237] Iteration 66500, loss = 1.33919
I0522 12:46:17.508131 19035 solver.cpp:253]     Train net output #0: loss = 1.33919 (* 1 = 1.33919 loss)
I0522 12:46:17.508143 19035 sgd_solver.cpp:106] Iteration 66500, lr = 0.0035
I0522 12:46:48.995728 19035 solver.cpp:237] Iteration 67000, loss = 1.16262
I0522 12:46:48.995908 19035 solver.cpp:253]     Train net output #0: loss = 1.16262 (* 1 = 1.16262 loss)
I0522 12:46:48.995923 19035 sgd_solver.cpp:106] Iteration 67000, lr = 0.0035
I0522 12:46:59.615489 19035 solver.cpp:237] Iteration 67500, loss = 1.72662
I0522 12:46:59.615532 19035 solver.cpp:253]     Train net output #0: loss = 1.72662 (* 1 = 1.72662 loss)
I0522 12:46:59.615547 19035 sgd_solver.cpp:106] Iteration 67500, lr = 0.0035
I0522 12:47:10.221278 19035 solver.cpp:237] Iteration 68000, loss = 1.04504
I0522 12:47:10.221314 19035 solver.cpp:253]     Train net output #0: loss = 1.04504 (* 1 = 1.04504 loss)
I0522 12:47:10.221393 19035 sgd_solver.cpp:106] Iteration 68000, lr = 0.0035
I0522 12:47:20.826999 19035 solver.cpp:237] Iteration 68500, loss = 0.869544
I0522 12:47:20.827167 19035 solver.cpp:253]     Train net output #0: loss = 0.869544 (* 1 = 0.869544 loss)
I0522 12:47:20.827183 19035 sgd_solver.cpp:106] Iteration 68500, lr = 0.0035
I0522 12:47:31.434231 19035 solver.cpp:237] Iteration 69000, loss = 0.999425
I0522 12:47:31.434267 19035 solver.cpp:253]     Train net output #0: loss = 0.999425 (* 1 = 0.999425 loss)
I0522 12:47:31.434283 19035 sgd_solver.cpp:106] Iteration 69000, lr = 0.0035
I0522 12:47:42.037752 19035 solver.cpp:237] Iteration 69500, loss = 1.02722
I0522 12:47:42.037803 19035 solver.cpp:253]     Train net output #0: loss = 1.02722 (* 1 = 1.02722 loss)
I0522 12:47:42.037818 19035 sgd_solver.cpp:106] Iteration 69500, lr = 0.0035
I0522 12:47:52.626996 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_70000.caffemodel
I0522 12:47:52.679229 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_70000.solverstate
I0522 12:47:52.705561 19035 solver.cpp:341] Iteration 70000, Testing net (#0)
I0522 12:48:41.940935 19035 solver.cpp:409]     Test net output #0: accuracy = 0.886082
I0522 12:48:41.941109 19035 solver.cpp:409]     Test net output #1: loss = 0.383917 (* 1 = 0.383917 loss)
I0522 12:49:02.827286 19035 solver.cpp:237] Iteration 70000, loss = 0.816433
I0522 12:49:02.827344 19035 solver.cpp:253]     Train net output #0: loss = 0.816433 (* 1 = 0.816433 loss)
I0522 12:49:02.827359 19035 sgd_solver.cpp:106] Iteration 70000, lr = 0.0035
I0522 12:49:13.449836 19035 solver.cpp:237] Iteration 70500, loss = 1.07728
I0522 12:49:13.449992 19035 solver.cpp:253]     Train net output #0: loss = 1.07728 (* 1 = 1.07728 loss)
I0522 12:49:13.450006 19035 sgd_solver.cpp:106] Iteration 70500, lr = 0.0035
I0522 12:49:24.052929 19035 solver.cpp:237] Iteration 71000, loss = 1.22916
I0522 12:49:24.052974 19035 solver.cpp:253]     Train net output #0: loss = 1.22916 (* 1 = 1.22916 loss)
I0522 12:49:24.052991 19035 sgd_solver.cpp:106] Iteration 71000, lr = 0.0035
I0522 12:49:34.672410 19035 solver.cpp:237] Iteration 71500, loss = 1.15437
I0522 12:49:34.672447 19035 solver.cpp:253]     Train net output #0: loss = 1.15437 (* 1 = 1.15437 loss)
I0522 12:49:34.672462 19035 sgd_solver.cpp:106] Iteration 71500, lr = 0.0035
I0522 12:49:45.287909 19035 solver.cpp:237] Iteration 72000, loss = 1.15052
I0522 12:49:45.288067 19035 solver.cpp:253]     Train net output #0: loss = 1.15052 (* 1 = 1.15052 loss)
I0522 12:49:45.288082 19035 sgd_solver.cpp:106] Iteration 72000, lr = 0.0035
I0522 12:49:55.917680 19035 solver.cpp:237] Iteration 72500, loss = 1.01507
I0522 12:49:55.917726 19035 solver.cpp:253]     Train net output #0: loss = 1.01507 (* 1 = 1.01507 loss)
I0522 12:49:55.917742 19035 sgd_solver.cpp:106] Iteration 72500, lr = 0.0035
I0522 12:50:06.540325 19035 solver.cpp:237] Iteration 73000, loss = 0.866338
I0522 12:50:06.540361 19035 solver.cpp:253]     Train net output #0: loss = 0.866339 (* 1 = 0.866339 loss)
I0522 12:50:06.540375 19035 sgd_solver.cpp:106] Iteration 73000, lr = 0.0035
I0522 12:50:38.053421 19035 solver.cpp:237] Iteration 73500, loss = 0.97665
I0522 12:50:38.053602 19035 solver.cpp:253]     Train net output #0: loss = 0.97665 (* 1 = 0.97665 loss)
I0522 12:50:38.053617 19035 sgd_solver.cpp:106] Iteration 73500, lr = 0.0035
I0522 12:50:48.657043 19035 solver.cpp:237] Iteration 74000, loss = 1.12046
I0522 12:50:48.657079 19035 solver.cpp:253]     Train net output #0: loss = 1.12046 (* 1 = 1.12046 loss)
I0522 12:50:48.657094 19035 sgd_solver.cpp:106] Iteration 74000, lr = 0.0035
I0522 12:50:59.282682 19035 solver.cpp:237] Iteration 74500, loss = 1.05012
I0522 12:50:59.282718 19035 solver.cpp:253]     Train net output #0: loss = 1.05012 (* 1 = 1.05012 loss)
I0522 12:50:59.282733 19035 sgd_solver.cpp:106] Iteration 74500, lr = 0.0035
I0522 12:51:09.861639 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_75000.caffemodel
I0522 12:51:09.916541 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_75000.solverstate
I0522 12:51:09.953184 19035 solver.cpp:237] Iteration 75000, loss = 1.39488
I0522 12:51:09.953233 19035 solver.cpp:253]     Train net output #0: loss = 1.39488 (* 1 = 1.39488 loss)
I0522 12:51:09.953250 19035 sgd_solver.cpp:106] Iteration 75000, lr = 0.0035
I0522 12:51:20.563285 19035 solver.cpp:237] Iteration 75500, loss = 1.18504
I0522 12:51:20.563321 19035 solver.cpp:253]     Train net output #0: loss = 1.18504 (* 1 = 1.18504 loss)
I0522 12:51:20.563336 19035 sgd_solver.cpp:106] Iteration 75500, lr = 0.0035
I0522 12:51:31.185451 19035 solver.cpp:237] Iteration 76000, loss = 1.32818
I0522 12:51:31.185499 19035 solver.cpp:253]     Train net output #0: loss = 1.32818 (* 1 = 1.32818 loss)
I0522 12:51:31.185515 19035 sgd_solver.cpp:106] Iteration 76000, lr = 0.0035
I0522 12:51:41.801690 19035 solver.cpp:237] Iteration 76500, loss = 1.19399
I0522 12:51:41.801846 19035 solver.cpp:253]     Train net output #0: loss = 1.19399 (* 1 = 1.19399 loss)
I0522 12:51:41.801862 19035 sgd_solver.cpp:106] Iteration 76500, lr = 0.0035
I0522 12:52:13.320395 19035 solver.cpp:237] Iteration 77000, loss = 1.15079
I0522 12:52:13.320570 19035 solver.cpp:253]     Train net output #0: loss = 1.1508 (* 1 = 1.1508 loss)
I0522 12:52:13.320586 19035 sgd_solver.cpp:106] Iteration 77000, lr = 0.0035
I0522 12:52:23.941054 19035 solver.cpp:237] Iteration 77500, loss = 1.08549
I0522 12:52:23.941097 19035 solver.cpp:253]     Train net output #0: loss = 1.08549 (* 1 = 1.08549 loss)
I0522 12:52:23.941112 19035 sgd_solver.cpp:106] Iteration 77500, lr = 0.0035
I0522 12:52:34.543629 19035 solver.cpp:237] Iteration 78000, loss = 1.34135
I0522 12:52:34.543664 19035 solver.cpp:253]     Train net output #0: loss = 1.34135 (* 1 = 1.34135 loss)
I0522 12:52:34.543678 19035 sgd_solver.cpp:106] Iteration 78000, lr = 0.0035
I0522 12:52:45.154881 19035 solver.cpp:237] Iteration 78500, loss = 1.14904
I0522 12:52:45.155051 19035 solver.cpp:253]     Train net output #0: loss = 1.14904 (* 1 = 1.14904 loss)
I0522 12:52:45.155066 19035 sgd_solver.cpp:106] Iteration 78500, lr = 0.0035
I0522 12:52:55.760682 19035 solver.cpp:237] Iteration 79000, loss = 1.22712
I0522 12:52:55.760718 19035 solver.cpp:253]     Train net output #0: loss = 1.22712 (* 1 = 1.22712 loss)
I0522 12:52:55.760735 19035 sgd_solver.cpp:106] Iteration 79000, lr = 0.0035
I0522 12:53:06.391458 19035 solver.cpp:237] Iteration 79500, loss = 0.842208
I0522 12:53:06.391508 19035 solver.cpp:253]     Train net output #0: loss = 0.842208 (* 1 = 0.842208 loss)
I0522 12:53:06.391525 19035 sgd_solver.cpp:106] Iteration 79500, lr = 0.0035
I0522 12:53:16.982825 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_80000.caffemodel
I0522 12:53:17.035843 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_80000.solverstate
I0522 12:53:17.062201 19035 solver.cpp:341] Iteration 80000, Testing net (#0)
I0522 12:54:27.481312 19035 solver.cpp:409]     Test net output #0: accuracy = 0.885709
I0522 12:54:27.481489 19035 solver.cpp:409]     Test net output #1: loss = 0.364661 (* 1 = 0.364661 loss)
I0522 12:54:48.374641 19035 solver.cpp:237] Iteration 80000, loss = 1.18984
I0522 12:54:48.374697 19035 solver.cpp:253]     Train net output #0: loss = 1.18984 (* 1 = 1.18984 loss)
I0522 12:54:48.374714 19035 sgd_solver.cpp:106] Iteration 80000, lr = 0.0035
I0522 12:54:58.963326 19035 solver.cpp:237] Iteration 80500, loss = 1.16151
I0522 12:54:58.963486 19035 solver.cpp:253]     Train net output #0: loss = 1.16151 (* 1 = 1.16151 loss)
I0522 12:54:58.963501 19035 sgd_solver.cpp:106] Iteration 80500, lr = 0.0035
I0522 12:55:09.559125 19035 solver.cpp:237] Iteration 81000, loss = 1.27256
I0522 12:55:09.559160 19035 solver.cpp:253]     Train net output #0: loss = 1.27256 (* 1 = 1.27256 loss)
I0522 12:55:09.559176 19035 sgd_solver.cpp:106] Iteration 81000, lr = 0.0035
I0522 12:55:20.147397 19035 solver.cpp:237] Iteration 81500, loss = 1.38051
I0522 12:55:20.147446 19035 solver.cpp:253]     Train net output #0: loss = 1.38051 (* 1 = 1.38051 loss)
I0522 12:55:20.147461 19035 sgd_solver.cpp:106] Iteration 81500, lr = 0.0035
I0522 12:55:30.736847 19035 solver.cpp:237] Iteration 82000, loss = 0.946365
I0522 12:55:30.737000 19035 solver.cpp:253]     Train net output #0: loss = 0.946365 (* 1 = 0.946365 loss)
I0522 12:55:30.737015 19035 sgd_solver.cpp:106] Iteration 82000, lr = 0.0035
I0522 12:55:41.322576 19035 solver.cpp:237] Iteration 82500, loss = 1.18654
I0522 12:55:41.322625 19035 solver.cpp:253]     Train net output #0: loss = 1.18654 (* 1 = 1.18654 loss)
I0522 12:55:41.322640 19035 sgd_solver.cpp:106] Iteration 82500, lr = 0.0035
I0522 12:55:51.919610 19035 solver.cpp:237] Iteration 83000, loss = 0.966296
I0522 12:55:51.919646 19035 solver.cpp:253]     Train net output #0: loss = 0.966296 (* 1 = 0.966296 loss)
I0522 12:55:51.919661 19035 sgd_solver.cpp:106] Iteration 83000, lr = 0.0035
I0522 12:56:23.450899 19035 solver.cpp:237] Iteration 83500, loss = 1.28235
I0522 12:56:23.451073 19035 solver.cpp:253]     Train net output #0: loss = 1.28235 (* 1 = 1.28235 loss)
I0522 12:56:23.451089 19035 sgd_solver.cpp:106] Iteration 83500, lr = 0.0035
I0522 12:56:34.039149 19035 solver.cpp:237] Iteration 84000, loss = 0.873178
I0522 12:56:34.039202 19035 solver.cpp:253]     Train net output #0: loss = 0.873178 (* 1 = 0.873178 loss)
I0522 12:56:34.039217 19035 sgd_solver.cpp:106] Iteration 84000, lr = 0.0035
I0522 12:56:44.618868 19035 solver.cpp:237] Iteration 84500, loss = 1.07503
I0522 12:56:44.618904 19035 solver.cpp:253]     Train net output #0: loss = 1.07503 (* 1 = 1.07503 loss)
I0522 12:56:44.618921 19035 sgd_solver.cpp:106] Iteration 84500, lr = 0.0035
I0522 12:56:55.183261 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_85000.caffemodel
I0522 12:56:55.246933 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_85000.solverstate
I0522 12:56:55.280164 19035 solver.cpp:237] Iteration 85000, loss = 0.978788
I0522 12:56:55.280216 19035 solver.cpp:253]     Train net output #0: loss = 0.978788 (* 1 = 0.978788 loss)
I0522 12:56:55.280231 19035 sgd_solver.cpp:106] Iteration 85000, lr = 0.0035
I0522 12:57:05.880327 19035 solver.cpp:237] Iteration 85500, loss = 0.927274
I0522 12:57:05.880364 19035 solver.cpp:253]     Train net output #0: loss = 0.927274 (* 1 = 0.927274 loss)
I0522 12:57:05.880379 19035 sgd_solver.cpp:106] Iteration 85500, lr = 0.0035
I0522 12:57:16.460008 19035 solver.cpp:237] Iteration 86000, loss = 0.962945
I0522 12:57:16.460052 19035 solver.cpp:253]     Train net output #0: loss = 0.962945 (* 1 = 0.962945 loss)
I0522 12:57:16.460073 19035 sgd_solver.cpp:106] Iteration 86000, lr = 0.0035
I0522 12:57:27.037721 19035 solver.cpp:237] Iteration 86500, loss = 1.10736
I0522 12:57:27.037890 19035 solver.cpp:253]     Train net output #0: loss = 1.10736 (* 1 = 1.10736 loss)
I0522 12:57:27.037905 19035 sgd_solver.cpp:106] Iteration 86500, lr = 0.0035
I0522 12:57:58.471469 19035 solver.cpp:237] Iteration 87000, loss = 1.20997
I0522 12:57:58.471643 19035 solver.cpp:253]     Train net output #0: loss = 1.20997 (* 1 = 1.20997 loss)
I0522 12:57:58.471658 19035 sgd_solver.cpp:106] Iteration 87000, lr = 0.0035
I0522 12:58:09.061499 19035 solver.cpp:237] Iteration 87500, loss = 1.55734
I0522 12:58:09.061553 19035 solver.cpp:253]     Train net output #0: loss = 1.55734 (* 1 = 1.55734 loss)
I0522 12:58:09.061568 19035 sgd_solver.cpp:106] Iteration 87500, lr = 0.0035
I0522 12:58:19.652076 19035 solver.cpp:237] Iteration 88000, loss = 1.52001
I0522 12:58:19.652112 19035 solver.cpp:253]     Train net output #0: loss = 1.52001 (* 1 = 1.52001 loss)
I0522 12:58:19.652127 19035 sgd_solver.cpp:106] Iteration 88000, lr = 0.0035
I0522 12:58:30.235889 19035 solver.cpp:237] Iteration 88500, loss = 1.13423
I0522 12:58:30.236047 19035 solver.cpp:253]     Train net output #0: loss = 1.13423 (* 1 = 1.13423 loss)
I0522 12:58:30.236062 19035 sgd_solver.cpp:106] Iteration 88500, lr = 0.0035
I0522 12:58:40.821116 19035 solver.cpp:237] Iteration 89000, loss = 1.09361
I0522 12:58:40.821163 19035 solver.cpp:253]     Train net output #0: loss = 1.09361 (* 1 = 1.09361 loss)
I0522 12:58:40.821178 19035 sgd_solver.cpp:106] Iteration 89000, lr = 0.0035
I0522 12:58:51.399857 19035 solver.cpp:237] Iteration 89500, loss = 0.975384
I0522 12:58:51.399893 19035 solver.cpp:253]     Train net output #0: loss = 0.975384 (* 1 = 0.975384 loss)
I0522 12:58:51.399909 19035 sgd_solver.cpp:106] Iteration 89500, lr = 0.0035
I0522 12:59:01.958936 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_90000.caffemodel
I0522 12:59:02.011926 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_90000.solverstate
I0522 12:59:02.038519 19035 solver.cpp:341] Iteration 90000, Testing net (#0)
I0522 12:59:51.674017 19035 solver.cpp:409]     Test net output #0: accuracy = 0.890126
I0522 12:59:51.674195 19035 solver.cpp:409]     Test net output #1: loss = 0.351751 (* 1 = 0.351751 loss)
I0522 13:00:12.560542 19035 solver.cpp:237] Iteration 90000, loss = 1.20098
I0522 13:00:12.560595 19035 solver.cpp:253]     Train net output #0: loss = 1.20098 (* 1 = 1.20098 loss)
I0522 13:00:12.560616 19035 sgd_solver.cpp:106] Iteration 90000, lr = 0.0035
I0522 13:00:23.061559 19035 solver.cpp:237] Iteration 90500, loss = 0.812206
I0522 13:00:23.061717 19035 solver.cpp:253]     Train net output #0: loss = 0.812206 (* 1 = 0.812206 loss)
I0522 13:00:23.061733 19035 sgd_solver.cpp:106] Iteration 90500, lr = 0.0035
I0522 13:00:33.550657 19035 solver.cpp:237] Iteration 91000, loss = 0.900434
I0522 13:00:33.550693 19035 solver.cpp:253]     Train net output #0: loss = 0.900434 (* 1 = 0.900434 loss)
I0522 13:00:33.550709 19035 sgd_solver.cpp:106] Iteration 91000, lr = 0.0035
I0522 13:00:44.044764 19035 solver.cpp:237] Iteration 91500, loss = 0.721233
I0522 13:00:44.044821 19035 solver.cpp:253]     Train net output #0: loss = 0.721233 (* 1 = 0.721233 loss)
I0522 13:00:44.044834 19035 sgd_solver.cpp:106] Iteration 91500, lr = 0.0035
I0522 13:00:54.540122 19035 solver.cpp:237] Iteration 92000, loss = 1.31075
I0522 13:00:54.540288 19035 solver.cpp:253]     Train net output #0: loss = 1.31076 (* 1 = 1.31076 loss)
I0522 13:00:54.540303 19035 sgd_solver.cpp:106] Iteration 92000, lr = 0.0035
I0522 13:01:05.032111 19035 solver.cpp:237] Iteration 92500, loss = 0.993756
I0522 13:01:05.032162 19035 solver.cpp:253]     Train net output #0: loss = 0.993757 (* 1 = 0.993757 loss)
I0522 13:01:05.032178 19035 sgd_solver.cpp:106] Iteration 92500, lr = 0.0035
I0522 13:01:15.535312 19035 solver.cpp:237] Iteration 93000, loss = 1.09577
I0522 13:01:15.535348 19035 solver.cpp:253]     Train net output #0: loss = 1.09577 (* 1 = 1.09577 loss)
I0522 13:01:15.535365 19035 sgd_solver.cpp:106] Iteration 93000, lr = 0.0035
I0522 13:01:46.927556 19035 solver.cpp:237] Iteration 93500, loss = 1.37872
I0522 13:01:46.927741 19035 solver.cpp:253]     Train net output #0: loss = 1.37872 (* 1 = 1.37872 loss)
I0522 13:01:46.927757 19035 sgd_solver.cpp:106] Iteration 93500, lr = 0.0035
I0522 13:01:57.430172 19035 solver.cpp:237] Iteration 94000, loss = 1.16856
I0522 13:01:57.430220 19035 solver.cpp:253]     Train net output #0: loss = 1.16856 (* 1 = 1.16856 loss)
I0522 13:01:57.430234 19035 sgd_solver.cpp:106] Iteration 94000, lr = 0.0035
I0522 13:02:07.944808 19035 solver.cpp:237] Iteration 94500, loss = 1.15593
I0522 13:02:07.944844 19035 solver.cpp:253]     Train net output #0: loss = 1.15593 (* 1 = 1.15593 loss)
I0522 13:02:07.944856 19035 sgd_solver.cpp:106] Iteration 94500, lr = 0.0035
I0522 13:02:18.443348 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_95000.caffemodel
I0522 13:02:18.498790 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_95000.solverstate
I0522 13:02:18.533677 19035 solver.cpp:237] Iteration 95000, loss = 1.39786
I0522 13:02:18.533730 19035 solver.cpp:253]     Train net output #0: loss = 1.39787 (* 1 = 1.39787 loss)
I0522 13:02:18.533746 19035 sgd_solver.cpp:106] Iteration 95000, lr = 0.0035
I0522 13:02:29.063515 19035 solver.cpp:237] Iteration 95500, loss = 1.00261
I0522 13:02:29.063551 19035 solver.cpp:253]     Train net output #0: loss = 1.00261 (* 1 = 1.00261 loss)
I0522 13:02:29.063565 19035 sgd_solver.cpp:106] Iteration 95500, lr = 0.0035
I0522 13:02:39.605440 19035 solver.cpp:237] Iteration 96000, loss = 1.36814
I0522 13:02:39.605476 19035 solver.cpp:253]     Train net output #0: loss = 1.36814 (* 1 = 1.36814 loss)
I0522 13:02:39.605492 19035 sgd_solver.cpp:106] Iteration 96000, lr = 0.0035
I0522 13:02:50.142685 19035 solver.cpp:237] Iteration 96500, loss = 1.27977
I0522 13:02:50.142860 19035 solver.cpp:253]     Train net output #0: loss = 1.27977 (* 1 = 1.27977 loss)
I0522 13:02:50.142876 19035 sgd_solver.cpp:106] Iteration 96500, lr = 0.0035
I0522 13:03:21.523932 19035 solver.cpp:237] Iteration 97000, loss = 0.89933
I0522 13:03:21.524112 19035 solver.cpp:253]     Train net output #0: loss = 0.89933 (* 1 = 0.89933 loss)
I0522 13:03:21.524128 19035 sgd_solver.cpp:106] Iteration 97000, lr = 0.0035
I0522 13:03:32.064725 19035 solver.cpp:237] Iteration 97500, loss = 1.55066
I0522 13:03:32.064770 19035 solver.cpp:253]     Train net output #0: loss = 1.55067 (* 1 = 1.55067 loss)
I0522 13:03:32.064786 19035 sgd_solver.cpp:106] Iteration 97500, lr = 0.0035
I0522 13:03:42.595239 19035 solver.cpp:237] Iteration 98000, loss = 1.20876
I0522 13:03:42.595275 19035 solver.cpp:253]     Train net output #0: loss = 1.20876 (* 1 = 1.20876 loss)
I0522 13:03:42.595291 19035 sgd_solver.cpp:106] Iteration 98000, lr = 0.0035
I0522 13:03:53.117574 19035 solver.cpp:237] Iteration 98500, loss = 1.31003
I0522 13:03:53.117738 19035 solver.cpp:253]     Train net output #0: loss = 1.31004 (* 1 = 1.31004 loss)
I0522 13:03:53.117753 19035 sgd_solver.cpp:106] Iteration 98500, lr = 0.0035
I0522 13:04:03.660043 19035 solver.cpp:237] Iteration 99000, loss = 1.36494
I0522 13:04:03.660094 19035 solver.cpp:253]     Train net output #0: loss = 1.36494 (* 1 = 1.36494 loss)
I0522 13:04:03.660109 19035 sgd_solver.cpp:106] Iteration 99000, lr = 0.0035
I0522 13:04:14.196130 19035 solver.cpp:237] Iteration 99500, loss = 1.914
I0522 13:04:14.196166 19035 solver.cpp:253]     Train net output #0: loss = 1.914 (* 1 = 1.914 loss)
I0522 13:04:14.196182 19035 sgd_solver.cpp:106] Iteration 99500, lr = 0.0035
I0522 13:04:24.711743 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_100000.caffemodel
I0522 13:04:24.767184 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_100000.solverstate
I0522 13:04:24.794112 19035 solver.cpp:341] Iteration 100000, Testing net (#0)
I0522 13:05:35.183476 19035 solver.cpp:409]     Test net output #0: accuracy = 0.892599
I0522 13:05:35.183671 19035 solver.cpp:409]     Test net output #1: loss = 0.343942 (* 1 = 0.343942 loss)
I0522 13:05:56.043951 19035 solver.cpp:237] Iteration 100000, loss = 1.22601
I0522 13:05:56.044008 19035 solver.cpp:253]     Train net output #0: loss = 1.22601 (* 1 = 1.22601 loss)
I0522 13:05:56.044023 19035 sgd_solver.cpp:106] Iteration 100000, lr = 0.0035
I0522 13:06:06.651193 19035 solver.cpp:237] Iteration 100500, loss = 1.08711
I0522 13:06:06.651365 19035 solver.cpp:253]     Train net output #0: loss = 1.08711 (* 1 = 1.08711 loss)
I0522 13:06:06.651379 19035 sgd_solver.cpp:106] Iteration 100500, lr = 0.0035
I0522 13:06:17.264679 19035 solver.cpp:237] Iteration 101000, loss = 1.34844
I0522 13:06:17.264714 19035 solver.cpp:253]     Train net output #0: loss = 1.34844 (* 1 = 1.34844 loss)
I0522 13:06:17.264730 19035 sgd_solver.cpp:106] Iteration 101000, lr = 0.0035
I0522 13:06:27.888155 19035 solver.cpp:237] Iteration 101500, loss = 1.60807
I0522 13:06:27.888211 19035 solver.cpp:253]     Train net output #0: loss = 1.60807 (* 1 = 1.60807 loss)
I0522 13:06:27.888224 19035 sgd_solver.cpp:106] Iteration 101500, lr = 0.0035
I0522 13:06:38.499261 19035 solver.cpp:237] Iteration 102000, loss = 0.835136
I0522 13:06:38.499418 19035 solver.cpp:253]     Train net output #0: loss = 0.835136 (* 1 = 0.835136 loss)
I0522 13:06:38.499433 19035 sgd_solver.cpp:106] Iteration 102000, lr = 0.0035
I0522 13:06:49.120818 19035 solver.cpp:237] Iteration 102500, loss = 1.2339
I0522 13:06:49.120853 19035 solver.cpp:253]     Train net output #0: loss = 1.2339 (* 1 = 1.2339 loss)
I0522 13:06:49.120869 19035 sgd_solver.cpp:106] Iteration 102500, lr = 0.0035
I0522 13:06:59.745141 19035 solver.cpp:237] Iteration 103000, loss = 1.13081
I0522 13:06:59.745193 19035 solver.cpp:253]     Train net output #0: loss = 1.13081 (* 1 = 1.13081 loss)
I0522 13:06:59.745206 19035 sgd_solver.cpp:106] Iteration 103000, lr = 0.0035
I0522 13:07:31.192729 19035 solver.cpp:237] Iteration 103500, loss = 0.923601
I0522 13:07:31.192914 19035 solver.cpp:253]     Train net output #0: loss = 0.923602 (* 1 = 0.923602 loss)
I0522 13:07:31.192930 19035 sgd_solver.cpp:106] Iteration 103500, lr = 0.0035
I0522 13:07:41.802908 19035 solver.cpp:237] Iteration 104000, loss = 1.16262
I0522 13:07:41.802963 19035 solver.cpp:253]     Train net output #0: loss = 1.16262 (* 1 = 1.16262 loss)
I0522 13:07:41.802976 19035 sgd_solver.cpp:106] Iteration 104000, lr = 0.0035
I0522 13:07:52.424243 19035 solver.cpp:237] Iteration 104500, loss = 1.44093
I0522 13:07:52.424279 19035 solver.cpp:253]     Train net output #0: loss = 1.44093 (* 1 = 1.44093 loss)
I0522 13:07:52.424295 19035 sgd_solver.cpp:106] Iteration 104500, lr = 0.0035
I0522 13:08:03.025415 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_105000.caffemodel
I0522 13:08:03.078615 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_105000.solverstate
I0522 13:08:03.110679 19035 solver.cpp:237] Iteration 105000, loss = 1.38079
I0522 13:08:03.110724 19035 solver.cpp:253]     Train net output #0: loss = 1.38079 (* 1 = 1.38079 loss)
I0522 13:08:03.110746 19035 sgd_solver.cpp:106] Iteration 105000, lr = 0.0035
I0522 13:08:13.719342 19035 solver.cpp:237] Iteration 105500, loss = 1.5524
I0522 13:08:13.719394 19035 solver.cpp:253]     Train net output #0: loss = 1.5524 (* 1 = 1.5524 loss)
I0522 13:08:13.719408 19035 sgd_solver.cpp:106] Iteration 105500, lr = 0.0035
I0522 13:08:24.329308 19035 solver.cpp:237] Iteration 106000, loss = 0.963848
I0522 13:08:24.329345 19035 solver.cpp:253]     Train net output #0: loss = 0.963849 (* 1 = 0.963849 loss)
I0522 13:08:24.329360 19035 sgd_solver.cpp:106] Iteration 106000, lr = 0.0035
I0522 13:08:34.941896 19035 solver.cpp:237] Iteration 106500, loss = 1.21505
I0522 13:08:34.942073 19035 solver.cpp:253]     Train net output #0: loss = 1.21505 (* 1 = 1.21505 loss)
I0522 13:08:34.942088 19035 sgd_solver.cpp:106] Iteration 106500, lr = 0.0035
I0522 13:09:06.456601 19035 solver.cpp:237] Iteration 107000, loss = 1.14803
I0522 13:09:06.456784 19035 solver.cpp:253]     Train net output #0: loss = 1.14803 (* 1 = 1.14803 loss)
I0522 13:09:06.456799 19035 sgd_solver.cpp:106] Iteration 107000, lr = 0.0035
I0522 13:09:17.075790 19035 solver.cpp:237] Iteration 107500, loss = 1.17779
I0522 13:09:17.075826 19035 solver.cpp:253]     Train net output #0: loss = 1.1778 (* 1 = 1.1778 loss)
I0522 13:09:17.075842 19035 sgd_solver.cpp:106] Iteration 107500, lr = 0.0035
I0522 13:09:27.701889 19035 solver.cpp:237] Iteration 108000, loss = 1.08339
I0522 13:09:27.701943 19035 solver.cpp:253]     Train net output #0: loss = 1.08339 (* 1 = 1.08339 loss)
I0522 13:09:27.701957 19035 sgd_solver.cpp:106] Iteration 108000, lr = 0.0035
I0522 13:09:38.321146 19035 solver.cpp:237] Iteration 108500, loss = 1.17123
I0522 13:09:38.321302 19035 solver.cpp:253]     Train net output #0: loss = 1.17123 (* 1 = 1.17123 loss)
I0522 13:09:38.321317 19035 sgd_solver.cpp:106] Iteration 108500, lr = 0.0035
I0522 13:09:48.947013 19035 solver.cpp:237] Iteration 109000, loss = 1.13423
I0522 13:09:48.947062 19035 solver.cpp:253]     Train net output #0: loss = 1.13423 (* 1 = 1.13423 loss)
I0522 13:09:48.947075 19035 sgd_solver.cpp:106] Iteration 109000, lr = 0.0035
I0522 13:09:59.559358 19035 solver.cpp:237] Iteration 109500, loss = 1.43115
I0522 13:09:59.559393 19035 solver.cpp:253]     Train net output #0: loss = 1.43115 (* 1 = 1.43115 loss)
I0522 13:09:59.559407 19035 sgd_solver.cpp:106] Iteration 109500, lr = 0.0035
I0522 13:10:10.157538 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_110000.caffemodel
I0522 13:10:10.210084 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_110000.solverstate
I0522 13:10:10.235396 19035 solver.cpp:341] Iteration 110000, Testing net (#0)
I0522 13:10:59.527640 19035 solver.cpp:409]     Test net output #0: accuracy = 0.893
I0522 13:10:59.527818 19035 solver.cpp:409]     Test net output #1: loss = 0.33084 (* 1 = 0.33084 loss)
I0522 13:11:20.371794 19035 solver.cpp:237] Iteration 110000, loss = 1.30381
I0522 13:11:20.371850 19035 solver.cpp:253]     Train net output #0: loss = 1.30381 (* 1 = 1.30381 loss)
I0522 13:11:20.371865 19035 sgd_solver.cpp:106] Iteration 110000, lr = 0.0035
I0522 13:11:30.985224 19035 solver.cpp:237] Iteration 110500, loss = 1.2842
I0522 13:11:30.985412 19035 solver.cpp:253]     Train net output #0: loss = 1.2842 (* 1 = 1.2842 loss)
I0522 13:11:30.985427 19035 sgd_solver.cpp:106] Iteration 110500, lr = 0.0035
I0522 13:11:41.576905 19035 solver.cpp:237] Iteration 111000, loss = 1.00583
I0522 13:11:41.576941 19035 solver.cpp:253]     Train net output #0: loss = 1.00583 (* 1 = 1.00583 loss)
I0522 13:11:41.576957 19035 sgd_solver.cpp:106] Iteration 111000, lr = 0.0035
I0522 13:11:52.192358 19035 solver.cpp:237] Iteration 111500, loss = 1.30392
I0522 13:11:52.192409 19035 solver.cpp:253]     Train net output #0: loss = 1.30392 (* 1 = 1.30392 loss)
I0522 13:11:52.192425 19035 sgd_solver.cpp:106] Iteration 111500, lr = 0.0035
I0522 13:12:02.788646 19035 solver.cpp:237] Iteration 112000, loss = 0.803213
I0522 13:12:02.788806 19035 solver.cpp:253]     Train net output #0: loss = 0.803214 (* 1 = 0.803214 loss)
I0522 13:12:02.788821 19035 sgd_solver.cpp:106] Iteration 112000, lr = 0.0035
I0522 13:12:13.389793 19035 solver.cpp:237] Iteration 112500, loss = 1.4302
I0522 13:12:13.389829 19035 solver.cpp:253]     Train net output #0: loss = 1.4302 (* 1 = 1.4302 loss)
I0522 13:12:13.389847 19035 sgd_solver.cpp:106] Iteration 112500, lr = 0.0035
I0522 13:12:23.988859 19035 solver.cpp:237] Iteration 113000, loss = 0.645939
I0522 13:12:23.988910 19035 solver.cpp:253]     Train net output #0: loss = 0.645939 (* 1 = 0.645939 loss)
I0522 13:12:23.988925 19035 sgd_solver.cpp:106] Iteration 113000, lr = 0.0035
I0522 13:12:55.484424 19035 solver.cpp:237] Iteration 113500, loss = 1.06961
I0522 13:12:55.484608 19035 solver.cpp:253]     Train net output #0: loss = 1.06961 (* 1 = 1.06961 loss)
I0522 13:12:55.484624 19035 sgd_solver.cpp:106] Iteration 113500, lr = 0.0035
I0522 13:13:06.081856 19035 solver.cpp:237] Iteration 114000, loss = 0.961978
I0522 13:13:06.081904 19035 solver.cpp:253]     Train net output #0: loss = 0.961978 (* 1 = 0.961978 loss)
I0522 13:13:06.081920 19035 sgd_solver.cpp:106] Iteration 114000, lr = 0.0035
I0522 13:13:16.682844 19035 solver.cpp:237] Iteration 114500, loss = 1.39777
I0522 13:13:16.682880 19035 solver.cpp:253]     Train net output #0: loss = 1.39777 (* 1 = 1.39777 loss)
I0522 13:13:16.682898 19035 sgd_solver.cpp:106] Iteration 114500, lr = 0.0035
I0522 13:13:27.268096 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_115000.caffemodel
I0522 13:13:27.320405 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_115000.solverstate
I0522 13:13:27.352844 19035 solver.cpp:237] Iteration 115000, loss = 1.06583
I0522 13:13:27.352893 19035 solver.cpp:253]     Train net output #0: loss = 1.06583 (* 1 = 1.06583 loss)
I0522 13:13:27.352907 19035 sgd_solver.cpp:106] Iteration 115000, lr = 0.0035
I0522 13:13:37.947659 19035 solver.cpp:237] Iteration 115500, loss = 1.11818
I0522 13:13:37.947710 19035 solver.cpp:253]     Train net output #0: loss = 1.11818 (* 1 = 1.11818 loss)
I0522 13:13:37.947724 19035 sgd_solver.cpp:106] Iteration 115500, lr = 0.0035
I0522 13:13:48.543087 19035 solver.cpp:237] Iteration 116000, loss = 1.37408
I0522 13:13:48.543123 19035 solver.cpp:253]     Train net output #0: loss = 1.37408 (* 1 = 1.37408 loss)
I0522 13:13:48.543140 19035 sgd_solver.cpp:106] Iteration 116000, lr = 0.0035
I0522 13:13:59.136607 19035 solver.cpp:237] Iteration 116500, loss = 1.17834
I0522 13:13:59.136782 19035 solver.cpp:253]     Train net output #0: loss = 1.17834 (* 1 = 1.17834 loss)
I0522 13:13:59.136796 19035 sgd_solver.cpp:106] Iteration 116500, lr = 0.0035
I0522 13:14:30.604583 19035 solver.cpp:237] Iteration 117000, loss = 1.00958
I0522 13:14:30.604780 19035 solver.cpp:253]     Train net output #0: loss = 1.00958 (* 1 = 1.00958 loss)
I0522 13:14:30.604796 19035 sgd_solver.cpp:106] Iteration 117000, lr = 0.0035
I0522 13:14:41.202296 19035 solver.cpp:237] Iteration 117500, loss = 1.181
I0522 13:14:41.202332 19035 solver.cpp:253]     Train net output #0: loss = 1.181 (* 1 = 1.181 loss)
I0522 13:14:41.202347 19035 sgd_solver.cpp:106] Iteration 117500, lr = 0.0035
I0522 13:14:51.804594 19035 solver.cpp:237] Iteration 118000, loss = 0.968253
I0522 13:14:51.804642 19035 solver.cpp:253]     Train net output #0: loss = 0.968254 (* 1 = 0.968254 loss)
I0522 13:14:51.804659 19035 sgd_solver.cpp:106] Iteration 118000, lr = 0.0035
I0522 13:15:02.429740 19035 solver.cpp:237] Iteration 118500, loss = 1.00831
I0522 13:15:02.429895 19035 solver.cpp:253]     Train net output #0: loss = 1.00831 (* 1 = 1.00831 loss)
I0522 13:15:02.429910 19035 sgd_solver.cpp:106] Iteration 118500, lr = 0.0035
I0522 13:15:13.062890 19035 solver.cpp:237] Iteration 119000, loss = 1.08899
I0522 13:15:13.062937 19035 solver.cpp:253]     Train net output #0: loss = 1.08899 (* 1 = 1.08899 loss)
I0522 13:15:13.062953 19035 sgd_solver.cpp:106] Iteration 119000, lr = 0.0035
I0522 13:15:23.695987 19035 solver.cpp:237] Iteration 119500, loss = 1.22438
I0522 13:15:23.696024 19035 solver.cpp:253]     Train net output #0: loss = 1.22438 (* 1 = 1.22438 loss)
I0522 13:15:23.696040 19035 sgd_solver.cpp:106] Iteration 119500, lr = 0.0035
I0522 13:15:34.299475 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_120000.caffemodel
I0522 13:15:34.351707 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_120000.solverstate
I0522 13:15:34.377305 19035 solver.cpp:341] Iteration 120000, Testing net (#0)
I0522 13:16:44.813427 19035 solver.cpp:409]     Test net output #0: accuracy = 0.890573
I0522 13:16:44.813611 19035 solver.cpp:409]     Test net output #1: loss = 0.35423 (* 1 = 0.35423 loss)
I0522 13:17:05.686969 19035 solver.cpp:237] Iteration 120000, loss = 1.04222
I0522 13:17:05.687026 19035 solver.cpp:253]     Train net output #0: loss = 1.04222 (* 1 = 1.04222 loss)
I0522 13:17:05.687041 19035 sgd_solver.cpp:106] Iteration 120000, lr = 0.0035
I0522 13:17:16.208003 19035 solver.cpp:237] Iteration 120500, loss = 1.06485
I0522 13:17:16.208181 19035 solver.cpp:253]     Train net output #0: loss = 1.06485 (* 1 = 1.06485 loss)
I0522 13:17:16.208196 19035 sgd_solver.cpp:106] Iteration 120500, lr = 0.0035
I0522 13:17:26.719012 19035 solver.cpp:237] Iteration 121000, loss = 1.30087
I0522 13:17:26.719048 19035 solver.cpp:253]     Train net output #0: loss = 1.30087 (* 1 = 1.30087 loss)
I0522 13:17:26.719061 19035 sgd_solver.cpp:106] Iteration 121000, lr = 0.0035
I0522 13:17:37.263018 19035 solver.cpp:237] Iteration 121500, loss = 1.22465
I0522 13:17:37.263054 19035 solver.cpp:253]     Train net output #0: loss = 1.22465 (* 1 = 1.22465 loss)
I0522 13:17:37.263067 19035 sgd_solver.cpp:106] Iteration 121500, lr = 0.0035
I0522 13:17:47.784220 19035 solver.cpp:237] Iteration 122000, loss = 1.19279
I0522 13:17:47.784387 19035 solver.cpp:253]     Train net output #0: loss = 1.19279 (* 1 = 1.19279 loss)
I0522 13:17:47.784404 19035 sgd_solver.cpp:106] Iteration 122000, lr = 0.0035
I0522 13:17:58.322111 19035 solver.cpp:237] Iteration 122500, loss = 1.25319
I0522 13:17:58.322149 19035 solver.cpp:253]     Train net output #0: loss = 1.25319 (* 1 = 1.25319 loss)
I0522 13:17:58.322165 19035 sgd_solver.cpp:106] Iteration 122500, lr = 0.0035
I0522 13:18:08.854665 19035 solver.cpp:237] Iteration 123000, loss = 1.1375
I0522 13:18:08.854713 19035 solver.cpp:253]     Train net output #0: loss = 1.1375 (* 1 = 1.1375 loss)
I0522 13:18:08.854728 19035 sgd_solver.cpp:106] Iteration 123000, lr = 0.0035
I0522 13:18:40.240470 19035 solver.cpp:237] Iteration 123500, loss = 1.0672
I0522 13:18:40.240658 19035 solver.cpp:253]     Train net output #0: loss = 1.0672 (* 1 = 1.0672 loss)
I0522 13:18:40.240671 19035 sgd_solver.cpp:106] Iteration 123500, lr = 0.0035
I0522 13:18:50.793648 19035 solver.cpp:237] Iteration 124000, loss = 1.17286
I0522 13:18:50.793684 19035 solver.cpp:253]     Train net output #0: loss = 1.17286 (* 1 = 1.17286 loss)
I0522 13:18:50.793697 19035 sgd_solver.cpp:106] Iteration 124000, lr = 0.0035
I0522 13:19:01.305891 19035 solver.cpp:237] Iteration 124500, loss = 1.12826
I0522 13:19:01.305939 19035 solver.cpp:253]     Train net output #0: loss = 1.12826 (* 1 = 1.12826 loss)
I0522 13:19:01.305954 19035 sgd_solver.cpp:106] Iteration 124500, lr = 0.0035
I0522 13:19:11.818780 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_125000.caffemodel
I0522 13:19:11.872669 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_125000.solverstate
I0522 13:19:11.906497 19035 solver.cpp:237] Iteration 125000, loss = 1.51436
I0522 13:19:11.906556 19035 solver.cpp:253]     Train net output #0: loss = 1.51436 (* 1 = 1.51436 loss)
I0522 13:19:11.906570 19035 sgd_solver.cpp:106] Iteration 125000, lr = 0.0035
I0522 13:19:22.434730 19035 solver.cpp:237] Iteration 125500, loss = 1.17454
I0522 13:19:22.434783 19035 solver.cpp:253]     Train net output #0: loss = 1.17454 (* 1 = 1.17454 loss)
I0522 13:19:22.434798 19035 sgd_solver.cpp:106] Iteration 125500, lr = 0.0035
I0522 13:19:32.950119 19035 solver.cpp:237] Iteration 126000, loss = 1.07878
I0522 13:19:32.950155 19035 solver.cpp:253]     Train net output #0: loss = 1.07878 (* 1 = 1.07878 loss)
I0522 13:19:32.950170 19035 sgd_solver.cpp:106] Iteration 126000, lr = 0.0035
I0522 13:19:43.474656 19035 solver.cpp:237] Iteration 126500, loss = 1.21604
I0522 13:19:43.474822 19035 solver.cpp:253]     Train net output #0: loss = 1.21604 (* 1 = 1.21604 loss)
I0522 13:19:43.474834 19035 sgd_solver.cpp:106] Iteration 126500, lr = 0.0035
I0522 13:20:14.868360 19035 solver.cpp:237] Iteration 127000, loss = 0.917761
I0522 13:20:14.868548 19035 solver.cpp:253]     Train net output #0: loss = 0.917761 (* 1 = 0.917761 loss)
I0522 13:20:14.868563 19035 sgd_solver.cpp:106] Iteration 127000, lr = 0.0035
I0522 13:20:25.403045 19035 solver.cpp:237] Iteration 127500, loss = 0.856066
I0522 13:20:25.403081 19035 solver.cpp:253]     Train net output #0: loss = 0.856066 (* 1 = 0.856066 loss)
I0522 13:20:25.403097 19035 sgd_solver.cpp:106] Iteration 127500, lr = 0.0035
I0522 13:20:35.930501 19035 solver.cpp:237] Iteration 128000, loss = 1.23675
I0522 13:20:35.930536 19035 solver.cpp:253]     Train net output #0: loss = 1.23675 (* 1 = 1.23675 loss)
I0522 13:20:35.930557 19035 sgd_solver.cpp:106] Iteration 128000, lr = 0.0035
I0522 13:20:46.449553 19035 solver.cpp:237] Iteration 128500, loss = 0.976456
I0522 13:20:46.449723 19035 solver.cpp:253]     Train net output #0: loss = 0.976456 (* 1 = 0.976456 loss)
I0522 13:20:46.449738 19035 sgd_solver.cpp:106] Iteration 128500, lr = 0.0035
I0522 13:20:56.976902 19035 solver.cpp:237] Iteration 129000, loss = 1.33672
I0522 13:20:56.976938 19035 solver.cpp:253]     Train net output #0: loss = 1.33672 (* 1 = 1.33672 loss)
I0522 13:20:56.976951 19035 sgd_solver.cpp:106] Iteration 129000, lr = 0.0035
I0522 13:21:07.512409 19035 solver.cpp:237] Iteration 129500, loss = 0.850394
I0522 13:21:07.512460 19035 solver.cpp:253]     Train net output #0: loss = 0.850394 (* 1 = 0.850394 loss)
I0522 13:21:07.512475 19035 sgd_solver.cpp:106] Iteration 129500, lr = 0.0035
I0522 13:21:18.003965 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_130000.caffemodel
I0522 13:21:18.056095 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_130000.solverstate
I0522 13:21:18.081689 19035 solver.cpp:341] Iteration 130000, Testing net (#0)
I0522 13:22:07.635918 19035 solver.cpp:409]     Test net output #0: accuracy = 0.894913
I0522 13:22:07.636111 19035 solver.cpp:409]     Test net output #1: loss = 0.352144 (* 1 = 0.352144 loss)
I0522 13:22:28.456753 19035 solver.cpp:237] Iteration 130000, loss = 1.18279
I0522 13:22:28.456805 19035 solver.cpp:253]     Train net output #0: loss = 1.18279 (* 1 = 1.18279 loss)
I0522 13:22:28.456823 19035 sgd_solver.cpp:106] Iteration 130000, lr = 0.0035
I0522 13:22:39.010983 19035 solver.cpp:237] Iteration 130500, loss = 0.991653
I0522 13:22:39.011147 19035 solver.cpp:253]     Train net output #0: loss = 0.991653 (* 1 = 0.991653 loss)
I0522 13:22:39.011162 19035 sgd_solver.cpp:106] Iteration 130500, lr = 0.0035
I0522 13:22:49.556821 19035 solver.cpp:237] Iteration 131000, loss = 1.57077
I0522 13:22:49.556865 19035 solver.cpp:253]     Train net output #0: loss = 1.57077 (* 1 = 1.57077 loss)
I0522 13:22:49.556879 19035 sgd_solver.cpp:106] Iteration 131000, lr = 0.0035
I0522 13:23:00.107846 19035 solver.cpp:237] Iteration 131500, loss = 1.43131
I0522 13:23:00.107883 19035 solver.cpp:253]     Train net output #0: loss = 1.43131 (* 1 = 1.43131 loss)
I0522 13:23:00.107898 19035 sgd_solver.cpp:106] Iteration 131500, lr = 0.0035
I0522 13:23:10.675151 19035 solver.cpp:237] Iteration 132000, loss = 0.958366
I0522 13:23:10.675325 19035 solver.cpp:253]     Train net output #0: loss = 0.958366 (* 1 = 0.958366 loss)
I0522 13:23:10.675341 19035 sgd_solver.cpp:106] Iteration 132000, lr = 0.0035
I0522 13:23:21.237221 19035 solver.cpp:237] Iteration 132500, loss = 1.21826
I0522 13:23:21.237258 19035 solver.cpp:253]     Train net output #0: loss = 1.21826 (* 1 = 1.21826 loss)
I0522 13:23:21.237273 19035 sgd_solver.cpp:106] Iteration 132500, lr = 0.0035
I0522 13:23:31.798017 19035 solver.cpp:237] Iteration 133000, loss = 0.732541
I0522 13:23:31.798066 19035 solver.cpp:253]     Train net output #0: loss = 0.732541 (* 1 = 0.732541 loss)
I0522 13:23:31.798081 19035 sgd_solver.cpp:106] Iteration 133000, lr = 0.0035
I0522 13:24:03.243336 19035 solver.cpp:237] Iteration 133500, loss = 1.0386
I0522 13:24:03.243525 19035 solver.cpp:253]     Train net output #0: loss = 1.0386 (* 1 = 1.0386 loss)
I0522 13:24:03.243541 19035 sgd_solver.cpp:106] Iteration 133500, lr = 0.0035
I0522 13:24:13.811070 19035 solver.cpp:237] Iteration 134000, loss = 1.10286
I0522 13:24:13.811106 19035 solver.cpp:253]     Train net output #0: loss = 1.10286 (* 1 = 1.10286 loss)
I0522 13:24:13.811121 19035 sgd_solver.cpp:106] Iteration 134000, lr = 0.0035
I0522 13:24:24.375744 19035 solver.cpp:237] Iteration 134500, loss = 0.79989
I0522 13:24:24.375793 19035 solver.cpp:253]     Train net output #0: loss = 0.79989 (* 1 = 0.79989 loss)
I0522 13:24:24.375808 19035 sgd_solver.cpp:106] Iteration 134500, lr = 0.0035
I0522 13:24:34.904403 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_135000.caffemodel
I0522 13:24:34.961067 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_135000.solverstate
I0522 13:24:34.993453 19035 solver.cpp:237] Iteration 135000, loss = 1.01751
I0522 13:24:34.993501 19035 solver.cpp:253]     Train net output #0: loss = 1.01751 (* 1 = 1.01751 loss)
I0522 13:24:34.993516 19035 sgd_solver.cpp:106] Iteration 135000, lr = 0.0035
I0522 13:24:45.538631 19035 solver.cpp:237] Iteration 135500, loss = 0.836362
I0522 13:24:45.538669 19035 solver.cpp:253]     Train net output #0: loss = 0.836362 (* 1 = 0.836362 loss)
I0522 13:24:45.538684 19035 sgd_solver.cpp:106] Iteration 135500, lr = 0.0035
I0522 13:24:56.098739 19035 solver.cpp:237] Iteration 136000, loss = 1.07809
I0522 13:24:56.098788 19035 solver.cpp:253]     Train net output #0: loss = 1.07809 (* 1 = 1.07809 loss)
I0522 13:24:56.098804 19035 sgd_solver.cpp:106] Iteration 136000, lr = 0.0035
I0522 13:25:06.662379 19035 solver.cpp:237] Iteration 136500, loss = 1.12015
I0522 13:25:06.662562 19035 solver.cpp:253]     Train net output #0: loss = 1.12015 (* 1 = 1.12015 loss)
I0522 13:25:06.662578 19035 sgd_solver.cpp:106] Iteration 136500, lr = 0.0035
I0522 13:25:38.107347 19035 solver.cpp:237] Iteration 137000, loss = 1.36113
I0522 13:25:38.107532 19035 solver.cpp:253]     Train net output #0: loss = 1.36113 (* 1 = 1.36113 loss)
I0522 13:25:38.107547 19035 sgd_solver.cpp:106] Iteration 137000, lr = 0.0035
I0522 13:25:48.663689 19035 solver.cpp:237] Iteration 137500, loss = 1.50981
I0522 13:25:48.663724 19035 solver.cpp:253]     Train net output #0: loss = 1.50981 (* 1 = 1.50981 loss)
I0522 13:25:48.663738 19035 sgd_solver.cpp:106] Iteration 137500, lr = 0.0035
I0522 13:25:59.227820 19035 solver.cpp:237] Iteration 138000, loss = 1.19862
I0522 13:25:59.227856 19035 solver.cpp:253]     Train net output #0: loss = 1.19862 (* 1 = 1.19862 loss)
I0522 13:25:59.227871 19035 sgd_solver.cpp:106] Iteration 138000, lr = 0.0035
I0522 13:26:09.783532 19035 solver.cpp:237] Iteration 138500, loss = 1.10747
I0522 13:26:09.783715 19035 solver.cpp:253]     Train net output #0: loss = 1.10747 (* 1 = 1.10747 loss)
I0522 13:26:09.783730 19035 sgd_solver.cpp:106] Iteration 138500, lr = 0.0035
I0522 13:26:20.330920 19035 solver.cpp:237] Iteration 139000, loss = 1.15924
I0522 13:26:20.330956 19035 solver.cpp:253]     Train net output #0: loss = 1.15924 (* 1 = 1.15924 loss)
I0522 13:26:20.330972 19035 sgd_solver.cpp:106] Iteration 139000, lr = 0.0035
I0522 13:26:30.867739 19035 solver.cpp:237] Iteration 139500, loss = 1.23828
I0522 13:26:30.867792 19035 solver.cpp:253]     Train net output #0: loss = 1.23828 (* 1 = 1.23828 loss)
I0522 13:26:30.867806 19035 sgd_solver.cpp:106] Iteration 139500, lr = 0.0035
I0522 13:26:41.379102 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_140000.caffemodel
I0522 13:26:41.431648 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_140000.solverstate
I0522 13:26:41.457154 19035 solver.cpp:341] Iteration 140000, Testing net (#0)
I0522 13:27:51.939244 19035 solver.cpp:409]     Test net output #0: accuracy = 0.896245
I0522 13:27:51.939429 19035 solver.cpp:409]     Test net output #1: loss = 0.335567 (* 1 = 0.335567 loss)
I0522 13:28:12.827646 19035 solver.cpp:237] Iteration 140000, loss = 1.13503
I0522 13:28:12.827702 19035 solver.cpp:253]     Train net output #0: loss = 1.13503 (* 1 = 1.13503 loss)
I0522 13:28:12.827719 19035 sgd_solver.cpp:106] Iteration 140000, lr = 0.0035
I0522 13:28:23.350057 19035 solver.cpp:237] Iteration 140500, loss = 0.96592
I0522 13:28:23.350226 19035 solver.cpp:253]     Train net output #0: loss = 0.96592 (* 1 = 0.96592 loss)
I0522 13:28:23.350240 19035 sgd_solver.cpp:106] Iteration 140500, lr = 0.0035
I0522 13:28:33.874899 19035 solver.cpp:237] Iteration 141000, loss = 1.25049
I0522 13:28:33.874948 19035 solver.cpp:253]     Train net output #0: loss = 1.25049 (* 1 = 1.25049 loss)
I0522 13:28:33.874963 19035 sgd_solver.cpp:106] Iteration 141000, lr = 0.0035
I0522 13:28:44.394196 19035 solver.cpp:237] Iteration 141500, loss = 1.05729
I0522 13:28:44.394232 19035 solver.cpp:253]     Train net output #0: loss = 1.05729 (* 1 = 1.05729 loss)
I0522 13:28:44.394251 19035 sgd_solver.cpp:106] Iteration 141500, lr = 0.0035
I0522 13:28:54.914427 19035 solver.cpp:237] Iteration 142000, loss = 0.99004
I0522 13:28:54.914597 19035 solver.cpp:253]     Train net output #0: loss = 0.990039 (* 1 = 0.990039 loss)
I0522 13:28:54.914611 19035 sgd_solver.cpp:106] Iteration 142000, lr = 0.0035
I0522 13:29:05.437352 19035 solver.cpp:237] Iteration 142500, loss = 0.930785
I0522 13:29:05.437405 19035 solver.cpp:253]     Train net output #0: loss = 0.930785 (* 1 = 0.930785 loss)
I0522 13:29:05.437419 19035 sgd_solver.cpp:106] Iteration 142500, lr = 0.0035
I0522 13:29:15.961181 19035 solver.cpp:237] Iteration 143000, loss = 1.21989
I0522 13:29:15.961217 19035 solver.cpp:253]     Train net output #0: loss = 1.21989 (* 1 = 1.21989 loss)
I0522 13:29:15.961232 19035 sgd_solver.cpp:106] Iteration 143000, lr = 0.0035
I0522 13:29:47.369726 19035 solver.cpp:237] Iteration 143500, loss = 1.19054
I0522 13:29:47.369923 19035 solver.cpp:253]     Train net output #0: loss = 1.19054 (* 1 = 1.19054 loss)
I0522 13:29:47.369938 19035 sgd_solver.cpp:106] Iteration 143500, lr = 0.0035
I0522 13:29:57.908591 19035 solver.cpp:237] Iteration 144000, loss = 1.26791
I0522 13:29:57.908627 19035 solver.cpp:253]     Train net output #0: loss = 1.26791 (* 1 = 1.26791 loss)
I0522 13:29:57.908640 19035 sgd_solver.cpp:106] Iteration 144000, lr = 0.0035
I0522 13:30:08.427494 19035 solver.cpp:237] Iteration 144500, loss = 1.17813
I0522 13:30:08.427530 19035 solver.cpp:253]     Train net output #0: loss = 1.17813 (* 1 = 1.17813 loss)
I0522 13:30:08.427546 19035 sgd_solver.cpp:106] Iteration 144500, lr = 0.0035
I0522 13:30:18.925591 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_145000.caffemodel
I0522 13:30:18.984457 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_145000.solverstate
I0522 13:30:19.017539 19035 solver.cpp:237] Iteration 145000, loss = 1.71455
I0522 13:30:19.017593 19035 solver.cpp:253]     Train net output #0: loss = 1.71455 (* 1 = 1.71455 loss)
I0522 13:30:19.017607 19035 sgd_solver.cpp:106] Iteration 145000, lr = 0.0035
I0522 13:30:29.525383 19035 solver.cpp:237] Iteration 145500, loss = 1.10858
I0522 13:30:29.525419 19035 solver.cpp:253]     Train net output #0: loss = 1.10858 (* 1 = 1.10858 loss)
I0522 13:30:29.525436 19035 sgd_solver.cpp:106] Iteration 145500, lr = 0.0035
I0522 13:30:40.025575 19035 solver.cpp:237] Iteration 146000, loss = 1.96009
I0522 13:30:40.025627 19035 solver.cpp:253]     Train net output #0: loss = 1.96009 (* 1 = 1.96009 loss)
I0522 13:30:40.025641 19035 sgd_solver.cpp:106] Iteration 146000, lr = 0.0035
I0522 13:30:50.545706 19035 solver.cpp:237] Iteration 146500, loss = 1.00324
I0522 13:30:50.545877 19035 solver.cpp:253]     Train net output #0: loss = 1.00323 (* 1 = 1.00323 loss)
I0522 13:30:50.545891 19035 sgd_solver.cpp:106] Iteration 146500, lr = 0.0035
I0522 13:31:21.952404 19035 solver.cpp:237] Iteration 147000, loss = 1.24841
I0522 13:31:21.952596 19035 solver.cpp:253]     Train net output #0: loss = 1.24841 (* 1 = 1.24841 loss)
I0522 13:31:21.952611 19035 sgd_solver.cpp:106] Iteration 147000, lr = 0.0035
I0522 13:31:32.476291 19035 solver.cpp:237] Iteration 147500, loss = 1.38761
I0522 13:31:32.476341 19035 solver.cpp:253]     Train net output #0: loss = 1.38761 (* 1 = 1.38761 loss)
I0522 13:31:32.476358 19035 sgd_solver.cpp:106] Iteration 147500, lr = 0.0035
I0522 13:31:42.992946 19035 solver.cpp:237] Iteration 148000, loss = 1.20452
I0522 13:31:42.992983 19035 solver.cpp:253]     Train net output #0: loss = 1.20452 (* 1 = 1.20452 loss)
I0522 13:31:42.992996 19035 sgd_solver.cpp:106] Iteration 148000, lr = 0.0035
I0522 13:31:53.508142 19035 solver.cpp:237] Iteration 148500, loss = 1.30981
I0522 13:31:53.508322 19035 solver.cpp:253]     Train net output #0: loss = 1.30981 (* 1 = 1.30981 loss)
I0522 13:31:53.508335 19035 sgd_solver.cpp:106] Iteration 148500, lr = 0.0035
I0522 13:32:04.035476 19035 solver.cpp:237] Iteration 149000, loss = 0.989944
I0522 13:32:04.035514 19035 solver.cpp:253]     Train net output #0: loss = 0.989944 (* 1 = 0.989944 loss)
I0522 13:32:04.035527 19035 sgd_solver.cpp:106] Iteration 149000, lr = 0.0035
I0522 13:32:14.557215 19035 solver.cpp:237] Iteration 149500, loss = 1.32212
I0522 13:32:14.557252 19035 solver.cpp:253]     Train net output #0: loss = 1.32212 (* 1 = 1.32212 loss)
I0522 13:32:14.557265 19035 sgd_solver.cpp:106] Iteration 149500, lr = 0.0035
I0522 13:32:25.045048 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_150000.caffemodel
I0522 13:32:25.100194 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_150000.solverstate
I0522 13:32:25.128940 19035 solver.cpp:341] Iteration 150000, Testing net (#0)
I0522 13:33:14.425252 19035 solver.cpp:409]     Test net output #0: accuracy = 0.897724
I0522 13:33:14.425436 19035 solver.cpp:409]     Test net output #1: loss = 0.32895 (* 1 = 0.32895 loss)
I0522 13:33:35.357529 19035 solver.cpp:237] Iteration 150000, loss = 1.28724
I0522 13:33:35.357586 19035 solver.cpp:253]     Train net output #0: loss = 1.28724 (* 1 = 1.28724 loss)
I0522 13:33:35.357604 19035 sgd_solver.cpp:106] Iteration 150000, lr = 0.0035
I0522 13:33:45.947481 19035 solver.cpp:237] Iteration 150500, loss = 1.13048
I0522 13:33:45.947654 19035 solver.cpp:253]     Train net output #0: loss = 1.13048 (* 1 = 1.13048 loss)
I0522 13:33:45.947669 19035 sgd_solver.cpp:106] Iteration 150500, lr = 0.0035
I0522 13:33:56.538048 19035 solver.cpp:237] Iteration 151000, loss = 0.744649
I0522 13:33:56.538100 19035 solver.cpp:253]     Train net output #0: loss = 0.744649 (* 1 = 0.744649 loss)
I0522 13:33:56.538115 19035 sgd_solver.cpp:106] Iteration 151000, lr = 0.0035
I0522 13:34:07.078300 19035 solver.cpp:237] Iteration 151500, loss = 1.09662
I0522 13:34:07.078337 19035 solver.cpp:253]     Train net output #0: loss = 1.09662 (* 1 = 1.09662 loss)
I0522 13:34:07.078353 19035 sgd_solver.cpp:106] Iteration 151500, lr = 0.0035
I0522 13:34:17.628291 19035 solver.cpp:237] Iteration 152000, loss = 1.14596
I0522 13:34:17.628468 19035 solver.cpp:253]     Train net output #0: loss = 1.14596 (* 1 = 1.14596 loss)
I0522 13:34:17.628482 19035 sgd_solver.cpp:106] Iteration 152000, lr = 0.0035
I0522 13:34:28.157178 19035 solver.cpp:237] Iteration 152500, loss = 1.031
I0522 13:34:28.157228 19035 solver.cpp:253]     Train net output #0: loss = 1.031 (* 1 = 1.031 loss)
I0522 13:34:28.157243 19035 sgd_solver.cpp:106] Iteration 152500, lr = 0.0035
I0522 13:34:38.710417 19035 solver.cpp:237] Iteration 153000, loss = 1.38212
I0522 13:34:38.710453 19035 solver.cpp:253]     Train net output #0: loss = 1.38212 (* 1 = 1.38212 loss)
I0522 13:34:38.710469 19035 sgd_solver.cpp:106] Iteration 153000, lr = 0.0035
I0522 13:35:10.147199 19035 solver.cpp:237] Iteration 153500, loss = 0.957633
I0522 13:35:10.147390 19035 solver.cpp:253]     Train net output #0: loss = 0.957633 (* 1 = 0.957633 loss)
I0522 13:35:10.147405 19035 sgd_solver.cpp:106] Iteration 153500, lr = 0.0035
I0522 13:35:20.686928 19035 solver.cpp:237] Iteration 154000, loss = 1.27387
I0522 13:35:20.686980 19035 solver.cpp:253]     Train net output #0: loss = 1.27387 (* 1 = 1.27387 loss)
I0522 13:35:20.686995 19035 sgd_solver.cpp:106] Iteration 154000, lr = 0.0035
I0522 13:35:31.225213 19035 solver.cpp:237] Iteration 154500, loss = 1.47942
I0522 13:35:31.225247 19035 solver.cpp:253]     Train net output #0: loss = 1.47942 (* 1 = 1.47942 loss)
I0522 13:35:31.225263 19035 sgd_solver.cpp:106] Iteration 154500, lr = 0.0035
I0522 13:35:41.748348 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_155000.caffemodel
I0522 13:35:41.800914 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_155000.solverstate
I0522 13:35:41.833289 19035 solver.cpp:237] Iteration 155000, loss = 0.979295
I0522 13:35:41.833340 19035 solver.cpp:253]     Train net output #0: loss = 0.979295 (* 1 = 0.979295 loss)
I0522 13:35:41.833355 19035 sgd_solver.cpp:106] Iteration 155000, lr = 0.0035
I0522 13:35:52.377599 19035 solver.cpp:237] Iteration 155500, loss = 1.30899
I0522 13:35:52.377634 19035 solver.cpp:253]     Train net output #0: loss = 1.30899 (* 1 = 1.30899 loss)
I0522 13:35:52.377650 19035 sgd_solver.cpp:106] Iteration 155500, lr = 0.0035
I0522 13:36:02.925165 19035 solver.cpp:237] Iteration 156000, loss = 0.896237
I0522 13:36:02.925215 19035 solver.cpp:253]     Train net output #0: loss = 0.896237 (* 1 = 0.896237 loss)
I0522 13:36:02.925230 19035 sgd_solver.cpp:106] Iteration 156000, lr = 0.0035
I0522 13:36:13.493167 19035 solver.cpp:237] Iteration 156500, loss = 1.25729
I0522 13:36:13.493346 19035 solver.cpp:253]     Train net output #0: loss = 1.25729 (* 1 = 1.25729 loss)
I0522 13:36:13.493360 19035 sgd_solver.cpp:106] Iteration 156500, lr = 0.0035
I0522 13:36:44.986600 19035 solver.cpp:237] Iteration 157000, loss = 1.03001
I0522 13:36:44.986780 19035 solver.cpp:253]     Train net output #0: loss = 1.03001 (* 1 = 1.03001 loss)
I0522 13:36:44.986795 19035 sgd_solver.cpp:106] Iteration 157000, lr = 0.0035
I0522 13:36:55.595738 19035 solver.cpp:237] Iteration 157500, loss = 1.47612
I0522 13:36:55.595793 19035 solver.cpp:253]     Train net output #0: loss = 1.47612 (* 1 = 1.47612 loss)
I0522 13:36:55.595806 19035 sgd_solver.cpp:106] Iteration 157500, lr = 0.0035
I0522 13:37:06.211642 19035 solver.cpp:237] Iteration 158000, loss = 1.44508
I0522 13:37:06.211678 19035 solver.cpp:253]     Train net output #0: loss = 1.44508 (* 1 = 1.44508 loss)
I0522 13:37:06.211694 19035 sgd_solver.cpp:106] Iteration 158000, lr = 0.0035
I0522 13:37:16.820650 19035 solver.cpp:237] Iteration 158500, loss = 1.10111
I0522 13:37:16.820837 19035 solver.cpp:253]     Train net output #0: loss = 1.10111 (* 1 = 1.10111 loss)
I0522 13:37:16.820852 19035 sgd_solver.cpp:106] Iteration 158500, lr = 0.0035
I0522 13:37:27.423729 19035 solver.cpp:237] Iteration 159000, loss = 1.35663
I0522 13:37:27.423765 19035 solver.cpp:253]     Train net output #0: loss = 1.35663 (* 1 = 1.35663 loss)
I0522 13:37:27.423779 19035 sgd_solver.cpp:106] Iteration 159000, lr = 0.0035
I0522 13:37:38.032883 19035 solver.cpp:237] Iteration 159500, loss = 1.29706
I0522 13:37:38.032919 19035 solver.cpp:253]     Train net output #0: loss = 1.29706 (* 1 = 1.29706 loss)
I0522 13:37:38.032932 19035 sgd_solver.cpp:106] Iteration 159500, lr = 0.0035
I0522 13:37:48.629616 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_160000.caffemodel
I0522 13:37:48.682375 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_160000.solverstate
I0522 13:37:48.707789 19035 solver.cpp:341] Iteration 160000, Testing net (#0)
I0522 13:38:59.227388 19035 solver.cpp:409]     Test net output #0: accuracy = 0.897679
I0522 13:38:59.227579 19035 solver.cpp:409]     Test net output #1: loss = 0.314566 (* 1 = 0.314566 loss)
I0522 13:39:20.117511 19035 solver.cpp:237] Iteration 160000, loss = 1.29172
I0522 13:39:20.117566 19035 solver.cpp:253]     Train net output #0: loss = 1.29172 (* 1 = 1.29172 loss)
I0522 13:39:20.117583 19035 sgd_solver.cpp:106] Iteration 160000, lr = 0.0035
I0522 13:39:30.649302 19035 solver.cpp:237] Iteration 160500, loss = 1.2023
I0522 13:39:30.649490 19035 solver.cpp:253]     Train net output #0: loss = 1.2023 (* 1 = 1.2023 loss)
I0522 13:39:30.649505 19035 sgd_solver.cpp:106] Iteration 160500, lr = 0.0035
I0522 13:39:41.153118 19035 solver.cpp:237] Iteration 161000, loss = 1.0191
I0522 13:39:41.153153 19035 solver.cpp:253]     Train net output #0: loss = 1.0191 (* 1 = 1.0191 loss)
I0522 13:39:41.153170 19035 sgd_solver.cpp:106] Iteration 161000, lr = 0.0035
I0522 13:39:51.755537 19035 solver.cpp:237] Iteration 161500, loss = 1.08071
I0522 13:39:51.755585 19035 solver.cpp:253]     Train net output #0: loss = 1.08071 (* 1 = 1.08071 loss)
I0522 13:39:51.755601 19035 sgd_solver.cpp:106] Iteration 161500, lr = 0.0035
I0522 13:40:02.371125 19035 solver.cpp:237] Iteration 162000, loss = 1.12293
I0522 13:40:02.371307 19035 solver.cpp:253]     Train net output #0: loss = 1.12293 (* 1 = 1.12293 loss)
I0522 13:40:02.371321 19035 sgd_solver.cpp:106] Iteration 162000, lr = 0.0035
I0522 13:40:12.981966 19035 solver.cpp:237] Iteration 162500, loss = 1.13296
I0522 13:40:12.982018 19035 solver.cpp:253]     Train net output #0: loss = 1.13296 (* 1 = 1.13296 loss)
I0522 13:40:12.982033 19035 sgd_solver.cpp:106] Iteration 162500, lr = 0.0035
I0522 13:40:23.591671 19035 solver.cpp:237] Iteration 163000, loss = 0.947004
I0522 13:40:23.591708 19035 solver.cpp:253]     Train net output #0: loss = 0.947004 (* 1 = 0.947004 loss)
I0522 13:40:23.591724 19035 sgd_solver.cpp:106] Iteration 163000, lr = 0.0035
I0522 13:40:55.061264 19035 solver.cpp:237] Iteration 163500, loss = 1.2351
I0522 13:40:55.061460 19035 solver.cpp:253]     Train net output #0: loss = 1.2351 (* 1 = 1.2351 loss)
I0522 13:40:55.061476 19035 sgd_solver.cpp:106] Iteration 163500, lr = 0.0035
I0522 13:41:05.649453 19035 solver.cpp:237] Iteration 164000, loss = 0.991787
I0522 13:41:05.649507 19035 solver.cpp:253]     Train net output #0: loss = 0.991787 (* 1 = 0.991787 loss)
I0522 13:41:05.649523 19035 sgd_solver.cpp:106] Iteration 164000, lr = 0.0035
I0522 13:41:16.236191 19035 solver.cpp:237] Iteration 164500, loss = 1.25362
I0522 13:41:16.236227 19035 solver.cpp:253]     Train net output #0: loss = 1.25362 (* 1 = 1.25362 loss)
I0522 13:41:16.236241 19035 sgd_solver.cpp:106] Iteration 164500, lr = 0.0035
I0522 13:41:26.803288 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_165000.caffemodel
I0522 13:41:26.856454 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_165000.solverstate
I0522 13:41:26.888859 19035 solver.cpp:237] Iteration 165000, loss = 1.04031
I0522 13:41:26.888906 19035 solver.cpp:253]     Train net output #0: loss = 1.04031 (* 1 = 1.04031 loss)
I0522 13:41:26.888921 19035 sgd_solver.cpp:106] Iteration 165000, lr = 0.0035
I0522 13:41:37.496207 19035 solver.cpp:237] Iteration 165500, loss = 0.914157
I0522 13:41:37.496244 19035 solver.cpp:253]     Train net output #0: loss = 0.914157 (* 1 = 0.914157 loss)
I0522 13:41:37.496258 19035 sgd_solver.cpp:106] Iteration 165500, lr = 0.0035
I0522 13:41:48.100406 19035 solver.cpp:237] Iteration 166000, loss = 1.06753
I0522 13:41:48.100442 19035 solver.cpp:253]     Train net output #0: loss = 1.06753 (* 1 = 1.06753 loss)
I0522 13:41:48.100458 19035 sgd_solver.cpp:106] Iteration 166000, lr = 0.0035
I0522 13:41:58.698915 19035 solver.cpp:237] Iteration 166500, loss = 1.18517
I0522 13:41:58.699101 19035 solver.cpp:253]     Train net output #0: loss = 1.18517 (* 1 = 1.18517 loss)
I0522 13:41:58.699116 19035 sgd_solver.cpp:106] Iteration 166500, lr = 0.0035
I0522 13:42:30.184931 19035 solver.cpp:237] Iteration 167000, loss = 0.644835
I0522 13:42:30.185127 19035 solver.cpp:253]     Train net output #0: loss = 0.644835 (* 1 = 0.644835 loss)
I0522 13:42:30.185142 19035 sgd_solver.cpp:106] Iteration 167000, lr = 0.0035
I0522 13:42:40.793550 19035 solver.cpp:237] Iteration 167500, loss = 1.13235
I0522 13:42:40.793586 19035 solver.cpp:253]     Train net output #0: loss = 1.13235 (* 1 = 1.13235 loss)
I0522 13:42:40.793601 19035 sgd_solver.cpp:106] Iteration 167500, lr = 0.0035
I0522 13:42:51.382628 19035 solver.cpp:237] Iteration 168000, loss = 1.23597
I0522 13:42:51.382664 19035 solver.cpp:253]     Train net output #0: loss = 1.23597 (* 1 = 1.23597 loss)
I0522 13:42:51.382679 19035 sgd_solver.cpp:106] Iteration 168000, lr = 0.0035
I0522 13:43:01.969890 19035 solver.cpp:237] Iteration 168500, loss = 1.14583
I0522 13:43:01.970057 19035 solver.cpp:253]     Train net output #0: loss = 1.14583 (* 1 = 1.14583 loss)
I0522 13:43:01.970070 19035 sgd_solver.cpp:106] Iteration 168500, lr = 0.0035
I0522 13:43:12.563403 19035 solver.cpp:237] Iteration 169000, loss = 1.0131
I0522 13:43:12.563446 19035 solver.cpp:253]     Train net output #0: loss = 1.0131 (* 1 = 1.0131 loss)
I0522 13:43:12.563462 19035 sgd_solver.cpp:106] Iteration 169000, lr = 0.0035
I0522 13:43:23.167289 19035 solver.cpp:237] Iteration 169500, loss = 0.927532
I0522 13:43:23.167325 19035 solver.cpp:253]     Train net output #0: loss = 0.927532 (* 1 = 0.927532 loss)
I0522 13:43:23.167338 19035 sgd_solver.cpp:106] Iteration 169500, lr = 0.0035
I0522 13:43:33.743950 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_170000.caffemodel
I0522 13:43:33.797133 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_170000.solverstate
I0522 13:43:33.822798 19035 solver.cpp:341] Iteration 170000, Testing net (#0)
I0522 13:44:23.461720 19035 solver.cpp:409]     Test net output #0: accuracy = 0.896932
I0522 13:44:23.461907 19035 solver.cpp:409]     Test net output #1: loss = 0.356074 (* 1 = 0.356074 loss)
I0522 13:44:44.389933 19035 solver.cpp:237] Iteration 170000, loss = 1.2164
I0522 13:44:44.389991 19035 solver.cpp:253]     Train net output #0: loss = 1.2164 (* 1 = 1.2164 loss)
I0522 13:44:44.390005 19035 sgd_solver.cpp:106] Iteration 170000, lr = 0.0035
I0522 13:44:54.894964 19035 solver.cpp:237] Iteration 170500, loss = 0.875009
I0522 13:44:54.895155 19035 solver.cpp:253]     Train net output #0: loss = 0.875009 (* 1 = 0.875009 loss)
I0522 13:44:54.895170 19035 sgd_solver.cpp:106] Iteration 170500, lr = 0.0035
I0522 13:45:05.383962 19035 solver.cpp:237] Iteration 171000, loss = 1.21068
I0522 13:45:05.383997 19035 solver.cpp:253]     Train net output #0: loss = 1.21068 (* 1 = 1.21068 loss)
I0522 13:45:05.384014 19035 sgd_solver.cpp:106] Iteration 171000, lr = 0.0035
I0522 13:45:15.896603 19035 solver.cpp:237] Iteration 171500, loss = 0.893559
I0522 13:45:15.896656 19035 solver.cpp:253]     Train net output #0: loss = 0.893559 (* 1 = 0.893559 loss)
I0522 13:45:15.896670 19035 sgd_solver.cpp:106] Iteration 171500, lr = 0.0035
I0522 13:45:26.398941 19035 solver.cpp:237] Iteration 172000, loss = 1.13883
I0522 13:45:26.399108 19035 solver.cpp:253]     Train net output #0: loss = 1.13883 (* 1 = 1.13883 loss)
I0522 13:45:26.399123 19035 sgd_solver.cpp:106] Iteration 172000, lr = 0.0035
I0522 13:45:36.898211 19035 solver.cpp:237] Iteration 172500, loss = 1.05473
I0522 13:45:36.898258 19035 solver.cpp:253]     Train net output #0: loss = 1.05473 (* 1 = 1.05473 loss)
I0522 13:45:36.898274 19035 sgd_solver.cpp:106] Iteration 172500, lr = 0.0035
I0522 13:45:47.394011 19035 solver.cpp:237] Iteration 173000, loss = 1.18277
I0522 13:45:47.394047 19035 solver.cpp:253]     Train net output #0: loss = 1.18277 (* 1 = 1.18277 loss)
I0522 13:45:47.394059 19035 sgd_solver.cpp:106] Iteration 173000, lr = 0.0035
I0522 13:46:18.774986 19035 solver.cpp:237] Iteration 173500, loss = 1.48452
I0522 13:46:18.775182 19035 solver.cpp:253]     Train net output #0: loss = 1.48452 (* 1 = 1.48452 loss)
I0522 13:46:18.775197 19035 sgd_solver.cpp:106] Iteration 173500, lr = 0.0035
I0522 13:46:29.281185 19035 solver.cpp:237] Iteration 174000, loss = 1.16559
I0522 13:46:29.281237 19035 solver.cpp:253]     Train net output #0: loss = 1.16559 (* 1 = 1.16559 loss)
I0522 13:46:29.281250 19035 sgd_solver.cpp:106] Iteration 174000, lr = 0.0035
I0522 13:46:39.785688 19035 solver.cpp:237] Iteration 174500, loss = 1.12967
I0522 13:46:39.785724 19035 solver.cpp:253]     Train net output #0: loss = 1.12967 (* 1 = 1.12967 loss)
I0522 13:46:39.785737 19035 sgd_solver.cpp:106] Iteration 174500, lr = 0.0035
I0522 13:46:50.275723 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_175000.caffemodel
I0522 13:46:50.329401 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_175000.solverstate
I0522 13:46:50.364913 19035 solver.cpp:237] Iteration 175000, loss = 0.744961
I0522 13:46:50.364969 19035 solver.cpp:253]     Train net output #0: loss = 0.744961 (* 1 = 0.744961 loss)
I0522 13:46:50.364984 19035 sgd_solver.cpp:106] Iteration 175000, lr = 0.0035
I0522 13:47:00.857216 19035 solver.cpp:237] Iteration 175500, loss = 1.26289
I0522 13:47:00.857270 19035 solver.cpp:253]     Train net output #0: loss = 1.26289 (* 1 = 1.26289 loss)
I0522 13:47:00.857285 19035 sgd_solver.cpp:106] Iteration 175500, lr = 0.0035
I0522 13:47:11.356884 19035 solver.cpp:237] Iteration 176000, loss = 0.9831
I0522 13:47:11.356921 19035 solver.cpp:253]     Train net output #0: loss = 0.9831 (* 1 = 0.9831 loss)
I0522 13:47:11.356936 19035 sgd_solver.cpp:106] Iteration 176000, lr = 0.0035
I0522 13:47:21.842156 19035 solver.cpp:237] Iteration 176500, loss = 1.09514
I0522 13:47:21.842347 19035 solver.cpp:253]     Train net output #0: loss = 1.09514 (* 1 = 1.09514 loss)
I0522 13:47:21.842363 19035 sgd_solver.cpp:106] Iteration 176500, lr = 0.0035
I0522 13:47:53.251540 19035 solver.cpp:237] Iteration 177000, loss = 1.10394
I0522 13:47:53.251737 19035 solver.cpp:253]     Train net output #0: loss = 1.10394 (* 1 = 1.10394 loss)
I0522 13:47:53.251752 19035 sgd_solver.cpp:106] Iteration 177000, lr = 0.0035
I0522 13:48:03.756913 19035 solver.cpp:237] Iteration 177500, loss = 0.822208
I0522 13:48:03.756949 19035 solver.cpp:253]     Train net output #0: loss = 0.822207 (* 1 = 0.822207 loss)
I0522 13:48:03.756963 19035 sgd_solver.cpp:106] Iteration 177500, lr = 0.0035
I0522 13:48:14.265888 19035 solver.cpp:237] Iteration 178000, loss = 1.40902
I0522 13:48:14.265943 19035 solver.cpp:253]     Train net output #0: loss = 1.40902 (* 1 = 1.40902 loss)
I0522 13:48:14.265956 19035 sgd_solver.cpp:106] Iteration 178000, lr = 0.0035
I0522 13:48:24.776762 19035 solver.cpp:237] Iteration 178500, loss = 0.988585
I0522 13:48:24.776934 19035 solver.cpp:253]     Train net output #0: loss = 0.988584 (* 1 = 0.988584 loss)
I0522 13:48:24.776948 19035 sgd_solver.cpp:106] Iteration 178500, lr = 0.0035
I0522 13:48:35.298446 19035 solver.cpp:237] Iteration 179000, loss = 1.03999
I0522 13:48:35.298497 19035 solver.cpp:253]     Train net output #0: loss = 1.03999 (* 1 = 1.03999 loss)
I0522 13:48:35.298512 19035 sgd_solver.cpp:106] Iteration 179000, lr = 0.0035
I0522 13:48:45.812476 19035 solver.cpp:237] Iteration 179500, loss = 0.882238
I0522 13:48:45.812512 19035 solver.cpp:253]     Train net output #0: loss = 0.882237 (* 1 = 0.882237 loss)
I0522 13:48:45.812528 19035 sgd_solver.cpp:106] Iteration 179500, lr = 0.0035
I0522 13:48:56.308325 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_180000.caffemodel
I0522 13:48:56.362617 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_180000.solverstate
I0522 13:48:56.390445 19035 solver.cpp:341] Iteration 180000, Testing net (#0)
I0522 13:50:06.884474 19035 solver.cpp:409]     Test net output #0: accuracy = 0.898486
I0522 13:50:06.884667 19035 solver.cpp:409]     Test net output #1: loss = 0.314839 (* 1 = 0.314839 loss)
I0522 13:50:27.797392 19035 solver.cpp:237] Iteration 180000, loss = 1.02749
I0522 13:50:27.797447 19035 solver.cpp:253]     Train net output #0: loss = 1.02749 (* 1 = 1.02749 loss)
I0522 13:50:27.797464 19035 sgd_solver.cpp:106] Iteration 180000, lr = 0.0035
I0522 13:50:38.308578 19035 solver.cpp:237] Iteration 180500, loss = 1.08899
I0522 13:50:38.308765 19035 solver.cpp:253]     Train net output #0: loss = 1.08899 (* 1 = 1.08899 loss)
I0522 13:50:38.308780 19035 sgd_solver.cpp:106] Iteration 180500, lr = 0.0035
I0522 13:50:48.818119 19035 solver.cpp:237] Iteration 181000, loss = 1.1587
I0522 13:50:48.818153 19035 solver.cpp:253]     Train net output #0: loss = 1.1587 (* 1 = 1.1587 loss)
I0522 13:50:48.818171 19035 sgd_solver.cpp:106] Iteration 181000, lr = 0.0035
I0522 13:50:59.324815 19035 solver.cpp:237] Iteration 181500, loss = 1.47923
I0522 13:50:59.324851 19035 solver.cpp:253]     Train net output #0: loss = 1.47923 (* 1 = 1.47923 loss)
I0522 13:50:59.324865 19035 sgd_solver.cpp:106] Iteration 181500, lr = 0.0035
I0522 13:51:09.835397 19035 solver.cpp:237] Iteration 182000, loss = 1.02899
I0522 13:51:09.835597 19035 solver.cpp:253]     Train net output #0: loss = 1.02899 (* 1 = 1.02899 loss)
I0522 13:51:09.835611 19035 sgd_solver.cpp:106] Iteration 182000, lr = 0.0035
I0522 13:51:20.338604 19035 solver.cpp:237] Iteration 182500, loss = 1.08468
I0522 13:51:20.338640 19035 solver.cpp:253]     Train net output #0: loss = 1.08468 (* 1 = 1.08468 loss)
I0522 13:51:20.338656 19035 sgd_solver.cpp:106] Iteration 182500, lr = 0.0035
I0522 13:51:30.851076 19035 solver.cpp:237] Iteration 183000, loss = 1.0341
I0522 13:51:30.851125 19035 solver.cpp:253]     Train net output #0: loss = 1.0341 (* 1 = 1.0341 loss)
I0522 13:51:30.851141 19035 sgd_solver.cpp:106] Iteration 183000, lr = 0.0035
I0522 13:52:02.203852 19035 solver.cpp:237] Iteration 183500, loss = 0.736312
I0522 13:52:02.204053 19035 solver.cpp:253]     Train net output #0: loss = 0.736311 (* 1 = 0.736311 loss)
I0522 13:52:02.204069 19035 sgd_solver.cpp:106] Iteration 183500, lr = 0.0035
I0522 13:52:12.718969 19035 solver.cpp:237] Iteration 184000, loss = 0.967736
I0522 13:52:12.719005 19035 solver.cpp:253]     Train net output #0: loss = 0.967736 (* 1 = 0.967736 loss)
I0522 13:52:12.719022 19035 sgd_solver.cpp:106] Iteration 184000, lr = 0.0035
I0522 13:52:23.220387 19035 solver.cpp:237] Iteration 184500, loss = 1.18494
I0522 13:52:23.220434 19035 solver.cpp:253]     Train net output #0: loss = 1.18494 (* 1 = 1.18494 loss)
I0522 13:52:23.220449 19035 sgd_solver.cpp:106] Iteration 184500, lr = 0.0035
I0522 13:52:33.683125 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_185000.caffemodel
I0522 13:52:33.735519 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_185000.solverstate
I0522 13:52:33.767694 19035 solver.cpp:237] Iteration 185000, loss = 1.3063
I0522 13:52:33.767743 19035 solver.cpp:253]     Train net output #0: loss = 1.3063 (* 1 = 1.3063 loss)
I0522 13:52:33.767761 19035 sgd_solver.cpp:106] Iteration 185000, lr = 0.0035
I0522 13:52:44.273653 19035 solver.cpp:237] Iteration 185500, loss = 0.846553
I0522 13:52:44.273710 19035 solver.cpp:253]     Train net output #0: loss = 0.846552 (* 1 = 0.846552 loss)
I0522 13:52:44.273723 19035 sgd_solver.cpp:106] Iteration 185500, lr = 0.0035
I0522 13:52:54.792526 19035 solver.cpp:237] Iteration 186000, loss = 1.03746
I0522 13:52:54.792562 19035 solver.cpp:253]     Train net output #0: loss = 1.03746 (* 1 = 1.03746 loss)
I0522 13:52:54.792577 19035 sgd_solver.cpp:106] Iteration 186000, lr = 0.0035
I0522 13:53:05.291906 19035 solver.cpp:237] Iteration 186500, loss = 0.984696
I0522 13:53:05.292095 19035 solver.cpp:253]     Train net output #0: loss = 0.984695 (* 1 = 0.984695 loss)
I0522 13:53:05.292111 19035 sgd_solver.cpp:106] Iteration 186500, lr = 0.0035
I0522 13:53:36.724059 19035 solver.cpp:237] Iteration 187000, loss = 1.33369
I0522 13:53:36.724253 19035 solver.cpp:253]     Train net output #0: loss = 1.33369 (* 1 = 1.33369 loss)
I0522 13:53:36.724268 19035 sgd_solver.cpp:106] Iteration 187000, lr = 0.0035
I0522 13:53:47.232262 19035 solver.cpp:237] Iteration 187500, loss = 1.23165
I0522 13:53:47.232298 19035 solver.cpp:253]     Train net output #0: loss = 1.23165 (* 1 = 1.23165 loss)
I0522 13:53:47.232312 19035 sgd_solver.cpp:106] Iteration 187500, lr = 0.0035
I0522 13:53:57.765147 19035 solver.cpp:237] Iteration 188000, loss = 1.05887
I0522 13:53:57.765199 19035 solver.cpp:253]     Train net output #0: loss = 1.05887 (* 1 = 1.05887 loss)
I0522 13:53:57.765213 19035 sgd_solver.cpp:106] Iteration 188000, lr = 0.0035
I0522 13:54:08.274773 19035 solver.cpp:237] Iteration 188500, loss = 0.931365
I0522 13:54:08.274955 19035 solver.cpp:253]     Train net output #0: loss = 0.931364 (* 1 = 0.931364 loss)
I0522 13:54:08.274969 19035 sgd_solver.cpp:106] Iteration 188500, lr = 0.0035
I0522 13:54:18.799108 19035 solver.cpp:237] Iteration 189000, loss = 1.24814
I0522 13:54:18.799144 19035 solver.cpp:253]     Train net output #0: loss = 1.24814 (* 1 = 1.24814 loss)
I0522 13:54:18.799156 19035 sgd_solver.cpp:106] Iteration 189000, lr = 0.0035
I0522 13:54:29.317919 19035 solver.cpp:237] Iteration 189500, loss = 0.986458
I0522 13:54:29.317971 19035 solver.cpp:253]     Train net output #0: loss = 0.986457 (* 1 = 0.986457 loss)
I0522 13:54:29.317986 19035 sgd_solver.cpp:106] Iteration 189500, lr = 0.0035
I0522 13:54:39.802690 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_190000.caffemodel
I0522 13:54:39.871598 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_190000.solverstate
I0522 13:54:39.896818 19035 solver.cpp:341] Iteration 190000, Testing net (#0)
I0522 13:55:29.184412 19035 solver.cpp:409]     Test net output #0: accuracy = 0.896706
I0522 13:55:29.184604 19035 solver.cpp:409]     Test net output #1: loss = 0.318554 (* 1 = 0.318554 loss)
I0522 13:55:49.993484 19035 solver.cpp:237] Iteration 190000, loss = 1.24832
I0522 13:55:49.993543 19035 solver.cpp:253]     Train net output #0: loss = 1.24832 (* 1 = 1.24832 loss)
I0522 13:55:49.993557 19035 sgd_solver.cpp:106] Iteration 190000, lr = 0.0035
I0522 13:56:00.519804 19035 solver.cpp:237] Iteration 190500, loss = 0.959915
I0522 13:56:00.519978 19035 solver.cpp:253]     Train net output #0: loss = 0.959914 (* 1 = 0.959914 loss)
I0522 13:56:00.519991 19035 sgd_solver.cpp:106] Iteration 190500, lr = 0.0035
I0522 13:56:11.055878 19035 solver.cpp:237] Iteration 191000, loss = 1.01834
I0522 13:56:11.055924 19035 solver.cpp:253]     Train net output #0: loss = 1.01834 (* 1 = 1.01834 loss)
I0522 13:56:11.055940 19035 sgd_solver.cpp:106] Iteration 191000, lr = 0.0035
I0522 13:56:21.593879 19035 solver.cpp:237] Iteration 191500, loss = 0.793636
I0522 13:56:21.593916 19035 solver.cpp:253]     Train net output #0: loss = 0.793635 (* 1 = 0.793635 loss)
I0522 13:56:21.593931 19035 sgd_solver.cpp:106] Iteration 191500, lr = 0.0035
I0522 13:56:32.160466 19035 solver.cpp:237] Iteration 192000, loss = 1.6253
I0522 13:56:32.160655 19035 solver.cpp:253]     Train net output #0: loss = 1.6253 (* 1 = 1.6253 loss)
I0522 13:56:32.160671 19035 sgd_solver.cpp:106] Iteration 192000, lr = 0.0035
I0522 13:56:42.721755 19035 solver.cpp:237] Iteration 192500, loss = 0.839915
I0522 13:56:42.721792 19035 solver.cpp:253]     Train net output #0: loss = 0.839914 (* 1 = 0.839914 loss)
I0522 13:56:42.721807 19035 sgd_solver.cpp:106] Iteration 192500, lr = 0.0035
I0522 13:56:53.293478 19035 solver.cpp:237] Iteration 193000, loss = 1.20253
I0522 13:56:53.293529 19035 solver.cpp:253]     Train net output #0: loss = 1.20253 (* 1 = 1.20253 loss)
I0522 13:56:53.293542 19035 sgd_solver.cpp:106] Iteration 193000, lr = 0.0035
I0522 13:57:24.724972 19035 solver.cpp:237] Iteration 193500, loss = 1.04592
I0522 13:57:24.725169 19035 solver.cpp:253]     Train net output #0: loss = 1.04591 (* 1 = 1.04591 loss)
I0522 13:57:24.725184 19035 sgd_solver.cpp:106] Iteration 193500, lr = 0.0035
I0522 13:57:35.300464 19035 solver.cpp:237] Iteration 194000, loss = 1.18243
I0522 13:57:35.300500 19035 solver.cpp:253]     Train net output #0: loss = 1.18243 (* 1 = 1.18243 loss)
I0522 13:57:35.300516 19035 sgd_solver.cpp:106] Iteration 194000, lr = 0.0035
I0522 13:57:45.868712 19035 solver.cpp:237] Iteration 194500, loss = 1.28932
I0522 13:57:45.868765 19035 solver.cpp:253]     Train net output #0: loss = 1.28932 (* 1 = 1.28932 loss)
I0522 13:57:45.868779 19035 sgd_solver.cpp:106] Iteration 194500, lr = 0.0035
I0522 13:57:56.413189 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_195000.caffemodel
I0522 13:57:56.465433 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_195000.solverstate
I0522 13:57:56.497311 19035 solver.cpp:237] Iteration 195000, loss = 1.30629
I0522 13:57:56.497359 19035 solver.cpp:253]     Train net output #0: loss = 1.30629 (* 1 = 1.30629 loss)
I0522 13:57:56.497375 19035 sgd_solver.cpp:106] Iteration 195000, lr = 0.0035
I0522 13:58:07.074867 19035 solver.cpp:237] Iteration 195500, loss = 1.43208
I0522 13:58:07.074914 19035 solver.cpp:253]     Train net output #0: loss = 1.43208 (* 1 = 1.43208 loss)
I0522 13:58:07.074928 19035 sgd_solver.cpp:106] Iteration 195500, lr = 0.0035
I0522 13:58:17.635500 19035 solver.cpp:237] Iteration 196000, loss = 1.495
I0522 13:58:17.635535 19035 solver.cpp:253]     Train net output #0: loss = 1.495 (* 1 = 1.495 loss)
I0522 13:58:17.635551 19035 sgd_solver.cpp:106] Iteration 196000, lr = 0.0035
I0522 13:58:28.197777 19035 solver.cpp:237] Iteration 196500, loss = 1.17668
I0522 13:58:28.197955 19035 solver.cpp:253]     Train net output #0: loss = 1.17667 (* 1 = 1.17667 loss)
I0522 13:58:28.197971 19035 sgd_solver.cpp:106] Iteration 196500, lr = 0.0035
I0522 13:58:59.626902 19035 solver.cpp:237] Iteration 197000, loss = 1.40604
I0522 13:58:59.627099 19035 solver.cpp:253]     Train net output #0: loss = 1.40604 (* 1 = 1.40604 loss)
I0522 13:58:59.627115 19035 sgd_solver.cpp:106] Iteration 197000, lr = 0.0035
I0522 13:59:10.199378 19035 solver.cpp:237] Iteration 197500, loss = 1.29467
I0522 13:59:10.199414 19035 solver.cpp:253]     Train net output #0: loss = 1.29467 (* 1 = 1.29467 loss)
I0522 13:59:10.199430 19035 sgd_solver.cpp:106] Iteration 197500, lr = 0.0035
I0522 13:59:20.771456 19035 solver.cpp:237] Iteration 198000, loss = 0.934238
I0522 13:59:20.771493 19035 solver.cpp:253]     Train net output #0: loss = 0.934237 (* 1 = 0.934237 loss)
I0522 13:59:20.771509 19035 sgd_solver.cpp:106] Iteration 198000, lr = 0.0035
I0522 13:59:31.325255 19035 solver.cpp:237] Iteration 198500, loss = 1.03788
I0522 13:59:31.325448 19035 solver.cpp:253]     Train net output #0: loss = 1.03788 (* 1 = 1.03788 loss)
I0522 13:59:31.325462 19035 sgd_solver.cpp:106] Iteration 198500, lr = 0.0035
I0522 13:59:41.860255 19035 solver.cpp:237] Iteration 199000, loss = 1.29248
I0522 13:59:41.860291 19035 solver.cpp:253]     Train net output #0: loss = 1.29248 (* 1 = 1.29248 loss)
I0522 13:59:41.860307 19035 sgd_solver.cpp:106] Iteration 199000, lr = 0.0035
I0522 13:59:52.407722 19035 solver.cpp:237] Iteration 199500, loss = 1.03034
I0522 13:59:52.407776 19035 solver.cpp:253]     Train net output #0: loss = 1.03034 (* 1 = 1.03034 loss)
I0522 13:59:52.407789 19035 sgd_solver.cpp:106] Iteration 199500, lr = 0.0035
I0522 14:00:02.970373 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_200000.caffemodel
I0522 14:00:03.025691 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_200000.solverstate
I0522 14:00:03.052901 19035 solver.cpp:341] Iteration 200000, Testing net (#0)
I0522 14:01:13.525240 19035 solver.cpp:409]     Test net output #0: accuracy = 0.898399
I0522 14:01:13.525439 19035 solver.cpp:409]     Test net output #1: loss = 0.336523 (* 1 = 0.336523 loss)
I0522 14:01:34.383991 19035 solver.cpp:237] Iteration 200000, loss = 1.20584
I0522 14:01:34.384047 19035 solver.cpp:253]     Train net output #0: loss = 1.20584 (* 1 = 1.20584 loss)
I0522 14:01:34.384062 19035 sgd_solver.cpp:106] Iteration 200000, lr = 0.0035
I0522 14:01:44.938249 19035 solver.cpp:237] Iteration 200500, loss = 1.23584
I0522 14:01:44.938439 19035 solver.cpp:253]     Train net output #0: loss = 1.23584 (* 1 = 1.23584 loss)
I0522 14:01:44.938454 19035 sgd_solver.cpp:106] Iteration 200500, lr = 0.0035
I0522 14:01:55.448645 19035 solver.cpp:237] Iteration 201000, loss = 1.23029
I0522 14:01:55.448699 19035 solver.cpp:253]     Train net output #0: loss = 1.23029 (* 1 = 1.23029 loss)
I0522 14:01:55.448714 19035 sgd_solver.cpp:106] Iteration 201000, lr = 0.0035
I0522 14:02:05.975891 19035 solver.cpp:237] Iteration 201500, loss = 1.3509
I0522 14:02:05.975929 19035 solver.cpp:253]     Train net output #0: loss = 1.3509 (* 1 = 1.3509 loss)
I0522 14:02:05.975942 19035 sgd_solver.cpp:106] Iteration 201500, lr = 0.0035
I0522 14:02:16.517276 19035 solver.cpp:237] Iteration 202000, loss = 1.08067
I0522 14:02:16.517472 19035 solver.cpp:253]     Train net output #0: loss = 1.08067 (* 1 = 1.08067 loss)
I0522 14:02:16.517487 19035 sgd_solver.cpp:106] Iteration 202000, lr = 0.0035
I0522 14:02:27.051000 19035 solver.cpp:237] Iteration 202500, loss = 1.04618
I0522 14:02:27.051036 19035 solver.cpp:253]     Train net output #0: loss = 1.04618 (* 1 = 1.04618 loss)
I0522 14:02:27.051050 19035 sgd_solver.cpp:106] Iteration 202500, lr = 0.0035
I0522 14:02:37.588047 19035 solver.cpp:237] Iteration 203000, loss = 1.38033
I0522 14:02:37.588081 19035 solver.cpp:253]     Train net output #0: loss = 1.38033 (* 1 = 1.38033 loss)
I0522 14:02:37.588098 19035 sgd_solver.cpp:106] Iteration 203000, lr = 0.0035
I0522 14:03:08.991238 19035 solver.cpp:237] Iteration 203500, loss = 1.27041
I0522 14:03:08.991437 19035 solver.cpp:253]     Train net output #0: loss = 1.27041 (* 1 = 1.27041 loss)
I0522 14:03:08.991452 19035 sgd_solver.cpp:106] Iteration 203500, lr = 0.0035
I0522 14:03:19.539690 19035 solver.cpp:237] Iteration 204000, loss = 0.922665
I0522 14:03:19.539726 19035 solver.cpp:253]     Train net output #0: loss = 0.922664 (* 1 = 0.922664 loss)
I0522 14:03:19.539742 19035 sgd_solver.cpp:106] Iteration 204000, lr = 0.0035
I0522 14:03:30.063516 19035 solver.cpp:237] Iteration 204500, loss = 1.65645
I0522 14:03:30.063552 19035 solver.cpp:253]     Train net output #0: loss = 1.65645 (* 1 = 1.65645 loss)
I0522 14:03:30.063568 19035 sgd_solver.cpp:106] Iteration 204500, lr = 0.0035
I0522 14:03:40.581054 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_205000.caffemodel
I0522 14:03:40.633347 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_205000.solverstate
I0522 14:03:40.665109 19035 solver.cpp:237] Iteration 205000, loss = 0.826635
I0522 14:03:40.665158 19035 solver.cpp:253]     Train net output #0: loss = 0.826634 (* 1 = 0.826634 loss)
I0522 14:03:40.665172 19035 sgd_solver.cpp:106] Iteration 205000, lr = 0.0035
I0522 14:03:51.193434 19035 solver.cpp:237] Iteration 205500, loss = 1.31016
I0522 14:03:51.193471 19035 solver.cpp:253]     Train net output #0: loss = 1.31016 (* 1 = 1.31016 loss)
I0522 14:03:51.193485 19035 sgd_solver.cpp:106] Iteration 205500, lr = 0.0035
I0522 14:04:01.725729 19035 solver.cpp:237] Iteration 206000, loss = 0.98584
I0522 14:04:01.725785 19035 solver.cpp:253]     Train net output #0: loss = 0.985839 (* 1 = 0.985839 loss)
I0522 14:04:01.725800 19035 sgd_solver.cpp:106] Iteration 206000, lr = 0.0035
I0522 14:04:12.259670 19035 solver.cpp:237] Iteration 206500, loss = 1.38142
I0522 14:04:12.259850 19035 solver.cpp:253]     Train net output #0: loss = 1.38142 (* 1 = 1.38142 loss)
I0522 14:04:12.259865 19035 sgd_solver.cpp:106] Iteration 206500, lr = 0.0035
I0522 14:04:43.670016 19035 solver.cpp:237] Iteration 207000, loss = 0.936175
I0522 14:04:43.670228 19035 solver.cpp:253]     Train net output #0: loss = 0.936174 (* 1 = 0.936174 loss)
I0522 14:04:43.670243 19035 sgd_solver.cpp:106] Iteration 207000, lr = 0.0035
I0522 14:04:54.197275 19035 solver.cpp:237] Iteration 207500, loss = 0.991306
I0522 14:04:54.197326 19035 solver.cpp:253]     Train net output #0: loss = 0.991305 (* 1 = 0.991305 loss)
I0522 14:04:54.197340 19035 sgd_solver.cpp:106] Iteration 207500, lr = 0.0035
I0522 14:05:04.717301 19035 solver.cpp:237] Iteration 208000, loss = 1.14967
I0522 14:05:04.717337 19035 solver.cpp:253]     Train net output #0: loss = 1.14967 (* 1 = 1.14967 loss)
I0522 14:05:04.717353 19035 sgd_solver.cpp:106] Iteration 208000, lr = 0.0035
I0522 14:05:15.260781 19035 solver.cpp:237] Iteration 208500, loss = 1.37888
I0522 14:05:15.260978 19035 solver.cpp:253]     Train net output #0: loss = 1.37888 (* 1 = 1.37888 loss)
I0522 14:05:15.260993 19035 sgd_solver.cpp:106] Iteration 208500, lr = 0.0035
I0522 14:05:25.806846 19035 solver.cpp:237] Iteration 209000, loss = 1.09304
I0522 14:05:25.806882 19035 solver.cpp:253]     Train net output #0: loss = 1.09304 (* 1 = 1.09304 loss)
I0522 14:05:25.806898 19035 sgd_solver.cpp:106] Iteration 209000, lr = 0.0035
I0522 14:05:36.363123 19035 solver.cpp:237] Iteration 209500, loss = 0.969261
I0522 14:05:36.363173 19035 solver.cpp:253]     Train net output #0: loss = 0.96926 (* 1 = 0.96926 loss)
I0522 14:05:36.363188 19035 sgd_solver.cpp:106] Iteration 209500, lr = 0.0035
I0522 14:05:46.905133 19035 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_210000.caffemodel
I0522 14:05:46.957801 19035 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_30_lr_0.0035_2016-05-20T15.48.59.592053_iter_210000.solverstate
I0522 14:05:46.984493 19035 solver.cpp:341] Iteration 210000, Testing net (#0)
I0522 14:06:36.637526 19035 solver.cpp:409]     Test net output #0: accuracy = 0.898819
I0522 14:06:36.637724 19035 solver.cpp:409]     Test net output #1: loss = 0.319555 (* 1 = 0.319555 loss)
I0522 14:06:57.482661 19035 solver.cpp:237] Iteration 210000, loss = 0.94542
I0522 14:06:57.482719 19035 solver.cpp:253]     Train net output #0: loss = 0.945419 (* 1 = 0.945419 loss)
I0522 14:06:57.482734 19035 sgd_solver.cpp:106] Iteration 210000, lr = 0.0035
I0522 14:07:07.998054 19035 solver.cpp:237] Iteration 210500, loss = 1.08279
I0522 14:07:07.998239 19035 solver.cpp:253]     Train net output #0: loss = 1.08279 (* 1 = 1.08279 loss)
I0522 14:07:07.998253 19035 sgd_solver.cpp:106] Iteration 210500, lr = 0.0035
I0522 14:07:18.515686 19035 solver.cpp:237] Iteration 211000, loss = 1.22086
I0522 14:07:18.515735 19035 solver.cpp:253]     Train net output #0: loss = 1.22086 (* 1 = 1.22086 loss)
I0522 14:07:18.515750 19035 sgd_solver.cpp:106] Iteration 211000, lr = 0.0035
I0522 14:07:29.016610 19035 solver.cpp:237] Iteration 211500, loss = 1.19723
I0522 14:07:29.016646 19035 solver.cpp:253]     Train net output #0: loss = 1.19723 (* 1 = 1.19723 loss)
I0522 14:07:29.016659 19035 sgd_solver.cpp:106] Iteration 211500, lr = 0.0035
I0522 14:07:39.524888 19035 solver.cpp:237] Iteration 212000, loss = 1.00496
I0522 14:07:39.525074 19035 solver.cpp:253]     Train net output #0: loss = 1.00496 (* 1 = 1.00496 loss)
I0522 14:07:39.525087 19035 sgd_solver.cpp:106] Iteration 212000, lr = 0.0035
I0522 14:07:50.041399 19035 solver.cpp:237] Iteration 212500, loss = 1.21609
I0522 14:07:50.041446 19035 solver.cpp:253]     Train net output #0: loss = 1.21609 (* 1 = 1.21609 loss)
I0522 14:07:50.041463 19035 sgd_solver.cpp:106] Iteration 212500, lr = 0.0035
I0522 14:08:00.560420 19035 solver.cpp:237] Iteration 213000, loss = 0.869638
I0522 14:08:00.560456 19035 solver.cpp:253]     Train net output #0: loss = 0.869637 (* 1 = 0.869637 loss)
I0522 14:08:00.560472 19035 sgd_solver.cpp:106] Iteration 213000, lr = 0.0035
I0522 14:08:31.962800 19035 solver.cpp:237] Iteration 213500, loss = 1.29016
I0522 14:08:31.963013 19035 solver.cpp:253]     Train net output #0: loss = 1.29016 (* 1 = 1.29016 loss)
I0522 14:08:31.963027 19035 sgd_solver.cpp:106] Iteration 213500, lr = 0.0035
I0522 14:08:42.478502 19035 solver.cpp:237] Iteration 214000, loss = 1.04692
I0522 14:08:42.478538 19035 solver.cpp:253]     Train net output #0: loss = 1.04692 (* 1 = 1.04692 loss)
I0522 14:08:42.478559 19035 sgd_solver.cpp:106] Iteration 214000, lr = 0.0035
aprun: Apid 11248018: Caught signal Terminated, sending to application
*** Aborted at 1463940527 (unix time) try "date -d @1463940527" if you are using GNU date ***
aprun: Apid 11248018: Caught signal Terminated, sending to application
PC: @     0x2aaab9276640 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
*** SIGTERM (@0x4a58) received by PID 19035 (TID 0x2aaac746f900) from PID 19032; stack trace: ***
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab9276640 (unknown)
    @     0x2aaab930eb7d (unknown)
=>> PBS: job killed: walltime 7231 exceeded limit 7200
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab928a368 (unknown)
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @           0x43020c main
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11248018: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11248018: Caught signal Terminated, sending to application
aprun: Apid 11248018: Caught signal Terminated, sending to application
