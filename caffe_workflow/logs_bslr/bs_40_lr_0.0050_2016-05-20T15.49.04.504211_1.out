2807983
I0523 00:14:06.145579 13206 caffe.cpp:184] Using GPUs 0
I0523 00:14:06.570338 13206 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.005
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211.prototxt"
I0523 00:14:06.571884 13206 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211.prototxt
I0523 00:14:06.583196 13206 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0523 00:14:06.583261 13206 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0523 00:14:06.583608 13206 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 00:14:06.583787 13206 layer_factory.hpp:77] Creating layer data_hdf5
I0523 00:14:06.583811 13206 net.cpp:106] Creating Layer data_hdf5
I0523 00:14:06.583827 13206 net.cpp:411] data_hdf5 -> data
I0523 00:14:06.583859 13206 net.cpp:411] data_hdf5 -> label
I0523 00:14:06.583892 13206 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0523 00:14:06.585096 13206 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0523 00:14:06.587317 13206 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0523 00:14:28.140751 13206 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0523 00:14:28.145932 13206 net.cpp:150] Setting up data_hdf5
I0523 00:14:28.145973 13206 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0523 00:14:28.145987 13206 net.cpp:157] Top shape: 40 (40)
I0523 00:14:28.145997 13206 net.cpp:165] Memory required for data: 1016160
I0523 00:14:28.146008 13206 layer_factory.hpp:77] Creating layer conv1
I0523 00:14:28.146040 13206 net.cpp:106] Creating Layer conv1
I0523 00:14:28.146054 13206 net.cpp:454] conv1 <- data
I0523 00:14:28.146076 13206 net.cpp:411] conv1 -> conv1
I0523 00:14:28.509466 13206 net.cpp:150] Setting up conv1
I0523 00:14:28.509516 13206 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0523 00:14:28.509526 13206 net.cpp:165] Memory required for data: 12075360
I0523 00:14:28.509555 13206 layer_factory.hpp:77] Creating layer relu1
I0523 00:14:28.509577 13206 net.cpp:106] Creating Layer relu1
I0523 00:14:28.509588 13206 net.cpp:454] relu1 <- conv1
I0523 00:14:28.509600 13206 net.cpp:397] relu1 -> conv1 (in-place)
I0523 00:14:28.510131 13206 net.cpp:150] Setting up relu1
I0523 00:14:28.510149 13206 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0523 00:14:28.510159 13206 net.cpp:165] Memory required for data: 23134560
I0523 00:14:28.510169 13206 layer_factory.hpp:77] Creating layer pool1
I0523 00:14:28.510185 13206 net.cpp:106] Creating Layer pool1
I0523 00:14:28.510195 13206 net.cpp:454] pool1 <- conv1
I0523 00:14:28.510208 13206 net.cpp:411] pool1 -> pool1
I0523 00:14:28.510290 13206 net.cpp:150] Setting up pool1
I0523 00:14:28.510303 13206 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0523 00:14:28.510313 13206 net.cpp:165] Memory required for data: 28664160
I0523 00:14:28.510324 13206 layer_factory.hpp:77] Creating layer conv2
I0523 00:14:28.510347 13206 net.cpp:106] Creating Layer conv2
I0523 00:14:28.510357 13206 net.cpp:454] conv2 <- pool1
I0523 00:14:28.510372 13206 net.cpp:411] conv2 -> conv2
I0523 00:14:28.513046 13206 net.cpp:150] Setting up conv2
I0523 00:14:28.513074 13206 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0523 00:14:28.513085 13206 net.cpp:165] Memory required for data: 36612960
I0523 00:14:28.513104 13206 layer_factory.hpp:77] Creating layer relu2
I0523 00:14:28.513118 13206 net.cpp:106] Creating Layer relu2
I0523 00:14:28.513128 13206 net.cpp:454] relu2 <- conv2
I0523 00:14:28.513141 13206 net.cpp:397] relu2 -> conv2 (in-place)
I0523 00:14:28.513473 13206 net.cpp:150] Setting up relu2
I0523 00:14:28.513487 13206 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0523 00:14:28.513497 13206 net.cpp:165] Memory required for data: 44561760
I0523 00:14:28.513509 13206 layer_factory.hpp:77] Creating layer pool2
I0523 00:14:28.513520 13206 net.cpp:106] Creating Layer pool2
I0523 00:14:28.513531 13206 net.cpp:454] pool2 <- conv2
I0523 00:14:28.513543 13206 net.cpp:411] pool2 -> pool2
I0523 00:14:28.513624 13206 net.cpp:150] Setting up pool2
I0523 00:14:28.513638 13206 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0523 00:14:28.513648 13206 net.cpp:165] Memory required for data: 48536160
I0523 00:14:28.513658 13206 layer_factory.hpp:77] Creating layer conv3
I0523 00:14:28.513676 13206 net.cpp:106] Creating Layer conv3
I0523 00:14:28.513686 13206 net.cpp:454] conv3 <- pool2
I0523 00:14:28.513700 13206 net.cpp:411] conv3 -> conv3
I0523 00:14:28.515651 13206 net.cpp:150] Setting up conv3
I0523 00:14:28.515671 13206 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0523 00:14:28.515682 13206 net.cpp:165] Memory required for data: 52872800
I0523 00:14:28.515702 13206 layer_factory.hpp:77] Creating layer relu3
I0523 00:14:28.515717 13206 net.cpp:106] Creating Layer relu3
I0523 00:14:28.515727 13206 net.cpp:454] relu3 <- conv3
I0523 00:14:28.515739 13206 net.cpp:397] relu3 -> conv3 (in-place)
I0523 00:14:28.516211 13206 net.cpp:150] Setting up relu3
I0523 00:14:28.516227 13206 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0523 00:14:28.516237 13206 net.cpp:165] Memory required for data: 57209440
I0523 00:14:28.516248 13206 layer_factory.hpp:77] Creating layer pool3
I0523 00:14:28.516261 13206 net.cpp:106] Creating Layer pool3
I0523 00:14:28.516270 13206 net.cpp:454] pool3 <- conv3
I0523 00:14:28.516283 13206 net.cpp:411] pool3 -> pool3
I0523 00:14:28.516351 13206 net.cpp:150] Setting up pool3
I0523 00:14:28.516366 13206 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0523 00:14:28.516374 13206 net.cpp:165] Memory required for data: 59377760
I0523 00:14:28.516384 13206 layer_factory.hpp:77] Creating layer conv4
I0523 00:14:28.516402 13206 net.cpp:106] Creating Layer conv4
I0523 00:14:28.516413 13206 net.cpp:454] conv4 <- pool3
I0523 00:14:28.516427 13206 net.cpp:411] conv4 -> conv4
I0523 00:14:28.519201 13206 net.cpp:150] Setting up conv4
I0523 00:14:28.519229 13206 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0523 00:14:28.519240 13206 net.cpp:165] Memory required for data: 60829280
I0523 00:14:28.519258 13206 layer_factory.hpp:77] Creating layer relu4
I0523 00:14:28.519271 13206 net.cpp:106] Creating Layer relu4
I0523 00:14:28.519281 13206 net.cpp:454] relu4 <- conv4
I0523 00:14:28.519294 13206 net.cpp:397] relu4 -> conv4 (in-place)
I0523 00:14:28.519769 13206 net.cpp:150] Setting up relu4
I0523 00:14:28.519785 13206 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0523 00:14:28.519796 13206 net.cpp:165] Memory required for data: 62280800
I0523 00:14:28.519807 13206 layer_factory.hpp:77] Creating layer pool4
I0523 00:14:28.519820 13206 net.cpp:106] Creating Layer pool4
I0523 00:14:28.519829 13206 net.cpp:454] pool4 <- conv4
I0523 00:14:28.519842 13206 net.cpp:411] pool4 -> pool4
I0523 00:14:28.519911 13206 net.cpp:150] Setting up pool4
I0523 00:14:28.519924 13206 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0523 00:14:28.519934 13206 net.cpp:165] Memory required for data: 63006560
I0523 00:14:28.519944 13206 layer_factory.hpp:77] Creating layer ip1
I0523 00:14:28.519964 13206 net.cpp:106] Creating Layer ip1
I0523 00:14:28.519975 13206 net.cpp:454] ip1 <- pool4
I0523 00:14:28.519989 13206 net.cpp:411] ip1 -> ip1
I0523 00:14:28.535398 13206 net.cpp:150] Setting up ip1
I0523 00:14:28.535426 13206 net.cpp:157] Top shape: 40 196 (7840)
I0523 00:14:28.535439 13206 net.cpp:165] Memory required for data: 63037920
I0523 00:14:28.535464 13206 layer_factory.hpp:77] Creating layer relu5
I0523 00:14:28.535477 13206 net.cpp:106] Creating Layer relu5
I0523 00:14:28.535488 13206 net.cpp:454] relu5 <- ip1
I0523 00:14:28.535501 13206 net.cpp:397] relu5 -> ip1 (in-place)
I0523 00:14:28.535843 13206 net.cpp:150] Setting up relu5
I0523 00:14:28.535857 13206 net.cpp:157] Top shape: 40 196 (7840)
I0523 00:14:28.535867 13206 net.cpp:165] Memory required for data: 63069280
I0523 00:14:28.535878 13206 layer_factory.hpp:77] Creating layer drop1
I0523 00:14:28.535902 13206 net.cpp:106] Creating Layer drop1
I0523 00:14:28.535912 13206 net.cpp:454] drop1 <- ip1
I0523 00:14:28.535923 13206 net.cpp:397] drop1 -> ip1 (in-place)
I0523 00:14:28.535984 13206 net.cpp:150] Setting up drop1
I0523 00:14:28.535996 13206 net.cpp:157] Top shape: 40 196 (7840)
I0523 00:14:28.536006 13206 net.cpp:165] Memory required for data: 63100640
I0523 00:14:28.536016 13206 layer_factory.hpp:77] Creating layer ip2
I0523 00:14:28.536034 13206 net.cpp:106] Creating Layer ip2
I0523 00:14:28.536044 13206 net.cpp:454] ip2 <- ip1
I0523 00:14:28.536057 13206 net.cpp:411] ip2 -> ip2
I0523 00:14:28.536519 13206 net.cpp:150] Setting up ip2
I0523 00:14:28.536531 13206 net.cpp:157] Top shape: 40 98 (3920)
I0523 00:14:28.536541 13206 net.cpp:165] Memory required for data: 63116320
I0523 00:14:28.536556 13206 layer_factory.hpp:77] Creating layer relu6
I0523 00:14:28.536569 13206 net.cpp:106] Creating Layer relu6
I0523 00:14:28.536578 13206 net.cpp:454] relu6 <- ip2
I0523 00:14:28.536590 13206 net.cpp:397] relu6 -> ip2 (in-place)
I0523 00:14:28.537112 13206 net.cpp:150] Setting up relu6
I0523 00:14:28.537128 13206 net.cpp:157] Top shape: 40 98 (3920)
I0523 00:14:28.537138 13206 net.cpp:165] Memory required for data: 63132000
I0523 00:14:28.537149 13206 layer_factory.hpp:77] Creating layer drop2
I0523 00:14:28.537163 13206 net.cpp:106] Creating Layer drop2
I0523 00:14:28.537173 13206 net.cpp:454] drop2 <- ip2
I0523 00:14:28.537184 13206 net.cpp:397] drop2 -> ip2 (in-place)
I0523 00:14:28.537227 13206 net.cpp:150] Setting up drop2
I0523 00:14:28.537240 13206 net.cpp:157] Top shape: 40 98 (3920)
I0523 00:14:28.537250 13206 net.cpp:165] Memory required for data: 63147680
I0523 00:14:28.537261 13206 layer_factory.hpp:77] Creating layer ip3
I0523 00:14:28.537274 13206 net.cpp:106] Creating Layer ip3
I0523 00:14:28.537283 13206 net.cpp:454] ip3 <- ip2
I0523 00:14:28.537297 13206 net.cpp:411] ip3 -> ip3
I0523 00:14:28.537505 13206 net.cpp:150] Setting up ip3
I0523 00:14:28.537518 13206 net.cpp:157] Top shape: 40 11 (440)
I0523 00:14:28.537528 13206 net.cpp:165] Memory required for data: 63149440
I0523 00:14:28.537544 13206 layer_factory.hpp:77] Creating layer drop3
I0523 00:14:28.537556 13206 net.cpp:106] Creating Layer drop3
I0523 00:14:28.537566 13206 net.cpp:454] drop3 <- ip3
I0523 00:14:28.537578 13206 net.cpp:397] drop3 -> ip3 (in-place)
I0523 00:14:28.537617 13206 net.cpp:150] Setting up drop3
I0523 00:14:28.537631 13206 net.cpp:157] Top shape: 40 11 (440)
I0523 00:14:28.537641 13206 net.cpp:165] Memory required for data: 63151200
I0523 00:14:28.537650 13206 layer_factory.hpp:77] Creating layer loss
I0523 00:14:28.537669 13206 net.cpp:106] Creating Layer loss
I0523 00:14:28.537679 13206 net.cpp:454] loss <- ip3
I0523 00:14:28.537690 13206 net.cpp:454] loss <- label
I0523 00:14:28.537703 13206 net.cpp:411] loss -> loss
I0523 00:14:28.537726 13206 layer_factory.hpp:77] Creating layer loss
I0523 00:14:28.538370 13206 net.cpp:150] Setting up loss
I0523 00:14:28.538391 13206 net.cpp:157] Top shape: (1)
I0523 00:14:28.538404 13206 net.cpp:160]     with loss weight 1
I0523 00:14:28.538450 13206 net.cpp:165] Memory required for data: 63151204
I0523 00:14:28.538460 13206 net.cpp:226] loss needs backward computation.
I0523 00:14:28.538471 13206 net.cpp:226] drop3 needs backward computation.
I0523 00:14:28.538481 13206 net.cpp:226] ip3 needs backward computation.
I0523 00:14:28.538489 13206 net.cpp:226] drop2 needs backward computation.
I0523 00:14:28.538499 13206 net.cpp:226] relu6 needs backward computation.
I0523 00:14:28.538511 13206 net.cpp:226] ip2 needs backward computation.
I0523 00:14:28.538521 13206 net.cpp:226] drop1 needs backward computation.
I0523 00:14:28.538532 13206 net.cpp:226] relu5 needs backward computation.
I0523 00:14:28.538542 13206 net.cpp:226] ip1 needs backward computation.
I0523 00:14:28.538552 13206 net.cpp:226] pool4 needs backward computation.
I0523 00:14:28.538561 13206 net.cpp:226] relu4 needs backward computation.
I0523 00:14:28.538571 13206 net.cpp:226] conv4 needs backward computation.
I0523 00:14:28.538583 13206 net.cpp:226] pool3 needs backward computation.
I0523 00:14:28.538594 13206 net.cpp:226] relu3 needs backward computation.
I0523 00:14:28.538601 13206 net.cpp:226] conv3 needs backward computation.
I0523 00:14:28.538620 13206 net.cpp:226] pool2 needs backward computation.
I0523 00:14:28.538631 13206 net.cpp:226] relu2 needs backward computation.
I0523 00:14:28.538641 13206 net.cpp:226] conv2 needs backward computation.
I0523 00:14:28.538651 13206 net.cpp:226] pool1 needs backward computation.
I0523 00:14:28.538662 13206 net.cpp:226] relu1 needs backward computation.
I0523 00:14:28.538672 13206 net.cpp:226] conv1 needs backward computation.
I0523 00:14:28.538683 13206 net.cpp:228] data_hdf5 does not need backward computation.
I0523 00:14:28.538693 13206 net.cpp:270] This network produces output loss
I0523 00:14:28.538717 13206 net.cpp:283] Network initialization done.
I0523 00:14:28.540331 13206 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211.prototxt
I0523 00:14:28.540401 13206 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0523 00:14:28.540758 13206 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0523 00:14:28.540947 13206 layer_factory.hpp:77] Creating layer data_hdf5
I0523 00:14:28.540963 13206 net.cpp:106] Creating Layer data_hdf5
I0523 00:14:28.540976 13206 net.cpp:411] data_hdf5 -> data
I0523 00:14:28.540989 13206 net.cpp:411] data_hdf5 -> label
I0523 00:14:28.541005 13206 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0523 00:14:28.542171 13206 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0523 00:14:49.862331 13206 net.cpp:150] Setting up data_hdf5
I0523 00:14:49.862503 13206 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0523 00:14:49.862517 13206 net.cpp:157] Top shape: 40 (40)
I0523 00:14:49.862529 13206 net.cpp:165] Memory required for data: 1016160
I0523 00:14:49.862541 13206 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0523 00:14:49.862571 13206 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0523 00:14:49.862581 13206 net.cpp:454] label_data_hdf5_1_split <- label
I0523 00:14:49.862596 13206 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0523 00:14:49.862618 13206 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0523 00:14:49.862690 13206 net.cpp:150] Setting up label_data_hdf5_1_split
I0523 00:14:49.862704 13206 net.cpp:157] Top shape: 40 (40)
I0523 00:14:49.862715 13206 net.cpp:157] Top shape: 40 (40)
I0523 00:14:49.862725 13206 net.cpp:165] Memory required for data: 1016480
I0523 00:14:49.862735 13206 layer_factory.hpp:77] Creating layer conv1
I0523 00:14:49.862756 13206 net.cpp:106] Creating Layer conv1
I0523 00:14:49.862767 13206 net.cpp:454] conv1 <- data
I0523 00:14:49.862782 13206 net.cpp:411] conv1 -> conv1
I0523 00:14:49.864737 13206 net.cpp:150] Setting up conv1
I0523 00:14:49.864761 13206 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0523 00:14:49.864773 13206 net.cpp:165] Memory required for data: 12075680
I0523 00:14:49.864794 13206 layer_factory.hpp:77] Creating layer relu1
I0523 00:14:49.864809 13206 net.cpp:106] Creating Layer relu1
I0523 00:14:49.864819 13206 net.cpp:454] relu1 <- conv1
I0523 00:14:49.864831 13206 net.cpp:397] relu1 -> conv1 (in-place)
I0523 00:14:49.865327 13206 net.cpp:150] Setting up relu1
I0523 00:14:49.865344 13206 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0523 00:14:49.865353 13206 net.cpp:165] Memory required for data: 23134880
I0523 00:14:49.865363 13206 layer_factory.hpp:77] Creating layer pool1
I0523 00:14:49.865381 13206 net.cpp:106] Creating Layer pool1
I0523 00:14:49.865391 13206 net.cpp:454] pool1 <- conv1
I0523 00:14:49.865402 13206 net.cpp:411] pool1 -> pool1
I0523 00:14:49.865478 13206 net.cpp:150] Setting up pool1
I0523 00:14:49.865490 13206 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0523 00:14:49.865500 13206 net.cpp:165] Memory required for data: 28664480
I0523 00:14:49.865509 13206 layer_factory.hpp:77] Creating layer conv2
I0523 00:14:49.865525 13206 net.cpp:106] Creating Layer conv2
I0523 00:14:49.865536 13206 net.cpp:454] conv2 <- pool1
I0523 00:14:49.865550 13206 net.cpp:411] conv2 -> conv2
I0523 00:14:49.867478 13206 net.cpp:150] Setting up conv2
I0523 00:14:49.867501 13206 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0523 00:14:49.867511 13206 net.cpp:165] Memory required for data: 36613280
I0523 00:14:49.867528 13206 layer_factory.hpp:77] Creating layer relu2
I0523 00:14:49.867542 13206 net.cpp:106] Creating Layer relu2
I0523 00:14:49.867552 13206 net.cpp:454] relu2 <- conv2
I0523 00:14:49.867563 13206 net.cpp:397] relu2 -> conv2 (in-place)
I0523 00:14:49.867894 13206 net.cpp:150] Setting up relu2
I0523 00:14:49.867908 13206 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0523 00:14:49.867918 13206 net.cpp:165] Memory required for data: 44562080
I0523 00:14:49.867928 13206 layer_factory.hpp:77] Creating layer pool2
I0523 00:14:49.867941 13206 net.cpp:106] Creating Layer pool2
I0523 00:14:49.867951 13206 net.cpp:454] pool2 <- conv2
I0523 00:14:49.867964 13206 net.cpp:411] pool2 -> pool2
I0523 00:14:49.868036 13206 net.cpp:150] Setting up pool2
I0523 00:14:49.868048 13206 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0523 00:14:49.868058 13206 net.cpp:165] Memory required for data: 48536480
I0523 00:14:49.868068 13206 layer_factory.hpp:77] Creating layer conv3
I0523 00:14:49.868085 13206 net.cpp:106] Creating Layer conv3
I0523 00:14:49.868096 13206 net.cpp:454] conv3 <- pool2
I0523 00:14:49.868110 13206 net.cpp:411] conv3 -> conv3
I0523 00:14:49.870079 13206 net.cpp:150] Setting up conv3
I0523 00:14:49.870100 13206 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0523 00:14:49.870113 13206 net.cpp:165] Memory required for data: 52873120
I0523 00:14:49.870146 13206 layer_factory.hpp:77] Creating layer relu3
I0523 00:14:49.870160 13206 net.cpp:106] Creating Layer relu3
I0523 00:14:49.870170 13206 net.cpp:454] relu3 <- conv3
I0523 00:14:49.870183 13206 net.cpp:397] relu3 -> conv3 (in-place)
I0523 00:14:49.870656 13206 net.cpp:150] Setting up relu3
I0523 00:14:49.870673 13206 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0523 00:14:49.870683 13206 net.cpp:165] Memory required for data: 57209760
I0523 00:14:49.870693 13206 layer_factory.hpp:77] Creating layer pool3
I0523 00:14:49.870707 13206 net.cpp:106] Creating Layer pool3
I0523 00:14:49.870715 13206 net.cpp:454] pool3 <- conv3
I0523 00:14:49.870728 13206 net.cpp:411] pool3 -> pool3
I0523 00:14:49.870800 13206 net.cpp:150] Setting up pool3
I0523 00:14:49.870813 13206 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0523 00:14:49.870823 13206 net.cpp:165] Memory required for data: 59378080
I0523 00:14:49.870832 13206 layer_factory.hpp:77] Creating layer conv4
I0523 00:14:49.870848 13206 net.cpp:106] Creating Layer conv4
I0523 00:14:49.870859 13206 net.cpp:454] conv4 <- pool3
I0523 00:14:49.870873 13206 net.cpp:411] conv4 -> conv4
I0523 00:14:49.872954 13206 net.cpp:150] Setting up conv4
I0523 00:14:49.872977 13206 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0523 00:14:49.872989 13206 net.cpp:165] Memory required for data: 60829600
I0523 00:14:49.873004 13206 layer_factory.hpp:77] Creating layer relu4
I0523 00:14:49.873018 13206 net.cpp:106] Creating Layer relu4
I0523 00:14:49.873028 13206 net.cpp:454] relu4 <- conv4
I0523 00:14:49.873041 13206 net.cpp:397] relu4 -> conv4 (in-place)
I0523 00:14:49.873512 13206 net.cpp:150] Setting up relu4
I0523 00:14:49.873528 13206 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0523 00:14:49.873538 13206 net.cpp:165] Memory required for data: 62281120
I0523 00:14:49.873548 13206 layer_factory.hpp:77] Creating layer pool4
I0523 00:14:49.873560 13206 net.cpp:106] Creating Layer pool4
I0523 00:14:49.873570 13206 net.cpp:454] pool4 <- conv4
I0523 00:14:49.873584 13206 net.cpp:411] pool4 -> pool4
I0523 00:14:49.873656 13206 net.cpp:150] Setting up pool4
I0523 00:14:49.873668 13206 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0523 00:14:49.873678 13206 net.cpp:165] Memory required for data: 63006880
I0523 00:14:49.873688 13206 layer_factory.hpp:77] Creating layer ip1
I0523 00:14:49.873716 13206 net.cpp:106] Creating Layer ip1
I0523 00:14:49.873728 13206 net.cpp:454] ip1 <- pool4
I0523 00:14:49.873740 13206 net.cpp:411] ip1 -> ip1
I0523 00:14:49.889317 13206 net.cpp:150] Setting up ip1
I0523 00:14:49.889345 13206 net.cpp:157] Top shape: 40 196 (7840)
I0523 00:14:49.889361 13206 net.cpp:165] Memory required for data: 63038240
I0523 00:14:49.889384 13206 layer_factory.hpp:77] Creating layer relu5
I0523 00:14:49.889399 13206 net.cpp:106] Creating Layer relu5
I0523 00:14:49.889408 13206 net.cpp:454] relu5 <- ip1
I0523 00:14:49.889422 13206 net.cpp:397] relu5 -> ip1 (in-place)
I0523 00:14:49.889776 13206 net.cpp:150] Setting up relu5
I0523 00:14:49.889791 13206 net.cpp:157] Top shape: 40 196 (7840)
I0523 00:14:49.889801 13206 net.cpp:165] Memory required for data: 63069600
I0523 00:14:49.889811 13206 layer_factory.hpp:77] Creating layer drop1
I0523 00:14:49.889829 13206 net.cpp:106] Creating Layer drop1
I0523 00:14:49.889839 13206 net.cpp:454] drop1 <- ip1
I0523 00:14:49.889853 13206 net.cpp:397] drop1 -> ip1 (in-place)
I0523 00:14:49.889897 13206 net.cpp:150] Setting up drop1
I0523 00:14:49.889911 13206 net.cpp:157] Top shape: 40 196 (7840)
I0523 00:14:49.889922 13206 net.cpp:165] Memory required for data: 63100960
I0523 00:14:49.889931 13206 layer_factory.hpp:77] Creating layer ip2
I0523 00:14:49.889945 13206 net.cpp:106] Creating Layer ip2
I0523 00:14:49.889955 13206 net.cpp:454] ip2 <- ip1
I0523 00:14:49.889969 13206 net.cpp:411] ip2 -> ip2
I0523 00:14:49.890445 13206 net.cpp:150] Setting up ip2
I0523 00:14:49.890458 13206 net.cpp:157] Top shape: 40 98 (3920)
I0523 00:14:49.890468 13206 net.cpp:165] Memory required for data: 63116640
I0523 00:14:49.890485 13206 layer_factory.hpp:77] Creating layer relu6
I0523 00:14:49.890509 13206 net.cpp:106] Creating Layer relu6
I0523 00:14:49.890519 13206 net.cpp:454] relu6 <- ip2
I0523 00:14:49.890532 13206 net.cpp:397] relu6 -> ip2 (in-place)
I0523 00:14:49.891067 13206 net.cpp:150] Setting up relu6
I0523 00:14:49.891083 13206 net.cpp:157] Top shape: 40 98 (3920)
I0523 00:14:49.891093 13206 net.cpp:165] Memory required for data: 63132320
I0523 00:14:49.891103 13206 layer_factory.hpp:77] Creating layer drop2
I0523 00:14:49.891115 13206 net.cpp:106] Creating Layer drop2
I0523 00:14:49.891125 13206 net.cpp:454] drop2 <- ip2
I0523 00:14:49.891139 13206 net.cpp:397] drop2 -> ip2 (in-place)
I0523 00:14:49.891183 13206 net.cpp:150] Setting up drop2
I0523 00:14:49.891196 13206 net.cpp:157] Top shape: 40 98 (3920)
I0523 00:14:49.891206 13206 net.cpp:165] Memory required for data: 63148000
I0523 00:14:49.891214 13206 layer_factory.hpp:77] Creating layer ip3
I0523 00:14:49.891228 13206 net.cpp:106] Creating Layer ip3
I0523 00:14:49.891238 13206 net.cpp:454] ip3 <- ip2
I0523 00:14:49.891252 13206 net.cpp:411] ip3 -> ip3
I0523 00:14:49.891475 13206 net.cpp:150] Setting up ip3
I0523 00:14:49.891489 13206 net.cpp:157] Top shape: 40 11 (440)
I0523 00:14:49.891499 13206 net.cpp:165] Memory required for data: 63149760
I0523 00:14:49.891515 13206 layer_factory.hpp:77] Creating layer drop3
I0523 00:14:49.891527 13206 net.cpp:106] Creating Layer drop3
I0523 00:14:49.891536 13206 net.cpp:454] drop3 <- ip3
I0523 00:14:49.891549 13206 net.cpp:397] drop3 -> ip3 (in-place)
I0523 00:14:49.891590 13206 net.cpp:150] Setting up drop3
I0523 00:14:49.891603 13206 net.cpp:157] Top shape: 40 11 (440)
I0523 00:14:49.891613 13206 net.cpp:165] Memory required for data: 63151520
I0523 00:14:49.891621 13206 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0523 00:14:49.891634 13206 net.cpp:106] Creating Layer ip3_drop3_0_split
I0523 00:14:49.891644 13206 net.cpp:454] ip3_drop3_0_split <- ip3
I0523 00:14:49.891657 13206 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0523 00:14:49.891671 13206 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0523 00:14:49.891744 13206 net.cpp:150] Setting up ip3_drop3_0_split
I0523 00:14:49.891758 13206 net.cpp:157] Top shape: 40 11 (440)
I0523 00:14:49.891770 13206 net.cpp:157] Top shape: 40 11 (440)
I0523 00:14:49.891780 13206 net.cpp:165] Memory required for data: 63155040
I0523 00:14:49.891788 13206 layer_factory.hpp:77] Creating layer accuracy
I0523 00:14:49.891810 13206 net.cpp:106] Creating Layer accuracy
I0523 00:14:49.891820 13206 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0523 00:14:49.891832 13206 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0523 00:14:49.891845 13206 net.cpp:411] accuracy -> accuracy
I0523 00:14:49.891870 13206 net.cpp:150] Setting up accuracy
I0523 00:14:49.891881 13206 net.cpp:157] Top shape: (1)
I0523 00:14:49.891891 13206 net.cpp:165] Memory required for data: 63155044
I0523 00:14:49.891901 13206 layer_factory.hpp:77] Creating layer loss
I0523 00:14:49.891914 13206 net.cpp:106] Creating Layer loss
I0523 00:14:49.891924 13206 net.cpp:454] loss <- ip3_drop3_0_split_1
I0523 00:14:49.891934 13206 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0523 00:14:49.891947 13206 net.cpp:411] loss -> loss
I0523 00:14:49.891964 13206 layer_factory.hpp:77] Creating layer loss
I0523 00:14:49.892448 13206 net.cpp:150] Setting up loss
I0523 00:14:49.892462 13206 net.cpp:157] Top shape: (1)
I0523 00:14:49.892472 13206 net.cpp:160]     with loss weight 1
I0523 00:14:49.892493 13206 net.cpp:165] Memory required for data: 63155048
I0523 00:14:49.892503 13206 net.cpp:226] loss needs backward computation.
I0523 00:14:49.892514 13206 net.cpp:228] accuracy does not need backward computation.
I0523 00:14:49.892525 13206 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0523 00:14:49.892535 13206 net.cpp:226] drop3 needs backward computation.
I0523 00:14:49.892545 13206 net.cpp:226] ip3 needs backward computation.
I0523 00:14:49.892556 13206 net.cpp:226] drop2 needs backward computation.
I0523 00:14:49.892565 13206 net.cpp:226] relu6 needs backward computation.
I0523 00:14:49.892583 13206 net.cpp:226] ip2 needs backward computation.
I0523 00:14:49.892595 13206 net.cpp:226] drop1 needs backward computation.
I0523 00:14:49.892603 13206 net.cpp:226] relu5 needs backward computation.
I0523 00:14:49.892612 13206 net.cpp:226] ip1 needs backward computation.
I0523 00:14:49.892622 13206 net.cpp:226] pool4 needs backward computation.
I0523 00:14:49.892633 13206 net.cpp:226] relu4 needs backward computation.
I0523 00:14:49.892642 13206 net.cpp:226] conv4 needs backward computation.
I0523 00:14:49.892653 13206 net.cpp:226] pool3 needs backward computation.
I0523 00:14:49.892664 13206 net.cpp:226] relu3 needs backward computation.
I0523 00:14:49.892674 13206 net.cpp:226] conv3 needs backward computation.
I0523 00:14:49.892684 13206 net.cpp:226] pool2 needs backward computation.
I0523 00:14:49.892694 13206 net.cpp:226] relu2 needs backward computation.
I0523 00:14:49.892704 13206 net.cpp:226] conv2 needs backward computation.
I0523 00:14:49.892714 13206 net.cpp:226] pool1 needs backward computation.
I0523 00:14:49.892724 13206 net.cpp:226] relu1 needs backward computation.
I0523 00:14:49.892735 13206 net.cpp:226] conv1 needs backward computation.
I0523 00:14:49.892745 13206 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0523 00:14:49.892756 13206 net.cpp:228] data_hdf5 does not need backward computation.
I0523 00:14:49.892765 13206 net.cpp:270] This network produces output accuracy
I0523 00:14:49.892776 13206 net.cpp:270] This network produces output loss
I0523 00:14:49.892804 13206 net.cpp:283] Network initialization done.
I0523 00:14:49.892938 13206 solver.cpp:60] Solver scaffolding done.
I0523 00:14:49.894078 13206 caffe.cpp:212] Starting Optimization
I0523 00:14:49.894096 13206 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0523 00:14:49.894109 13206 solver.cpp:289] Learning Rate Policy: fixed
I0523 00:14:49.895337 13206 solver.cpp:341] Iteration 0, Testing net (#0)
I0523 00:15:39.336421 13206 solver.cpp:409]     Test net output #0: accuracy = 0.06864
I0523 00:15:39.336585 13206 solver.cpp:409]     Test net output #1: loss = 2.39905 (* 1 = 2.39905 loss)
I0523 00:15:39.359125 13206 solver.cpp:237] Iteration 0, loss = 2.39756
I0523 00:15:39.359163 13206 solver.cpp:253]     Train net output #0: loss = 2.39756 (* 1 = 2.39756 loss)
I0523 00:15:39.359181 13206 sgd_solver.cpp:106] Iteration 0, lr = 0.005
I0523 00:15:49.206868 13206 solver.cpp:237] Iteration 375, loss = 1.93101
I0523 00:15:49.206915 13206 solver.cpp:253]     Train net output #0: loss = 1.93101 (* 1 = 1.93101 loss)
I0523 00:15:49.206935 13206 sgd_solver.cpp:106] Iteration 375, lr = 0.005
I0523 00:15:59.065940 13206 solver.cpp:237] Iteration 750, loss = 1.99885
I0523 00:15:59.065978 13206 solver.cpp:253]     Train net output #0: loss = 1.99885 (* 1 = 1.99885 loss)
I0523 00:15:59.065991 13206 sgd_solver.cpp:106] Iteration 750, lr = 0.005
I0523 00:16:08.917121 13206 solver.cpp:237] Iteration 1125, loss = 2.05172
I0523 00:16:08.917155 13206 solver.cpp:253]     Train net output #0: loss = 2.05172 (* 1 = 2.05172 loss)
I0523 00:16:08.917173 13206 sgd_solver.cpp:106] Iteration 1125, lr = 0.005
I0523 00:16:18.760280 13206 solver.cpp:237] Iteration 1500, loss = 1.65007
I0523 00:16:18.760447 13206 solver.cpp:253]     Train net output #0: loss = 1.65007 (* 1 = 1.65007 loss)
I0523 00:16:18.760462 13206 sgd_solver.cpp:106] Iteration 1500, lr = 0.005
I0523 00:16:28.585176 13206 solver.cpp:237] Iteration 1875, loss = 1.44099
I0523 00:16:28.585211 13206 solver.cpp:253]     Train net output #0: loss = 1.44099 (* 1 = 1.44099 loss)
I0523 00:16:28.585228 13206 sgd_solver.cpp:106] Iteration 1875, lr = 0.005
I0523 00:16:38.420284 13206 solver.cpp:237] Iteration 2250, loss = 1.52948
I0523 00:16:38.420320 13206 solver.cpp:253]     Train net output #0: loss = 1.52948 (* 1 = 1.52948 loss)
I0523 00:16:38.420336 13206 sgd_solver.cpp:106] Iteration 2250, lr = 0.005
I0523 00:17:10.356745 13206 solver.cpp:237] Iteration 2625, loss = 1.68043
I0523 00:17:10.356921 13206 solver.cpp:253]     Train net output #0: loss = 1.68043 (* 1 = 1.68043 loss)
I0523 00:17:10.356936 13206 sgd_solver.cpp:106] Iteration 2625, lr = 0.005
I0523 00:17:20.185828 13206 solver.cpp:237] Iteration 3000, loss = 1.40357
I0523 00:17:20.185863 13206 solver.cpp:253]     Train net output #0: loss = 1.40357 (* 1 = 1.40357 loss)
I0523 00:17:20.185880 13206 sgd_solver.cpp:106] Iteration 3000, lr = 0.005
I0523 00:17:30.015802 13206 solver.cpp:237] Iteration 3375, loss = 1.6538
I0523 00:17:30.015848 13206 solver.cpp:253]     Train net output #0: loss = 1.6538 (* 1 = 1.6538 loss)
I0523 00:17:30.015866 13206 sgd_solver.cpp:106] Iteration 3375, lr = 0.005
I0523 00:17:39.817641 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_3750.caffemodel
I0523 00:17:39.877156 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_3750.solverstate
I0523 00:17:39.910248 13206 solver.cpp:237] Iteration 3750, loss = 1.27939
I0523 00:17:39.910295 13206 solver.cpp:253]     Train net output #0: loss = 1.27939 (* 1 = 1.27939 loss)
I0523 00:17:39.910307 13206 sgd_solver.cpp:106] Iteration 3750, lr = 0.005
I0523 00:17:49.746896 13206 solver.cpp:237] Iteration 4125, loss = 1.61637
I0523 00:17:49.747038 13206 solver.cpp:253]     Train net output #0: loss = 1.61637 (* 1 = 1.61637 loss)
I0523 00:17:49.747052 13206 sgd_solver.cpp:106] Iteration 4125, lr = 0.005
I0523 00:17:59.580427 13206 solver.cpp:237] Iteration 4500, loss = 1.35899
I0523 00:17:59.580472 13206 solver.cpp:253]     Train net output #0: loss = 1.35899 (* 1 = 1.35899 loss)
I0523 00:17:59.580490 13206 sgd_solver.cpp:106] Iteration 4500, lr = 0.005
I0523 00:18:09.403095 13206 solver.cpp:237] Iteration 4875, loss = 1.63497
I0523 00:18:09.403131 13206 solver.cpp:253]     Train net output #0: loss = 1.63497 (* 1 = 1.63497 loss)
I0523 00:18:09.403147 13206 sgd_solver.cpp:106] Iteration 4875, lr = 0.005
I0523 00:18:41.363639 13206 solver.cpp:237] Iteration 5250, loss = 1.29434
I0523 00:18:41.363801 13206 solver.cpp:253]     Train net output #0: loss = 1.29434 (* 1 = 1.29434 loss)
I0523 00:18:41.363816 13206 sgd_solver.cpp:106] Iteration 5250, lr = 0.005
I0523 00:18:51.195446 13206 solver.cpp:237] Iteration 5625, loss = 1.25294
I0523 00:18:51.195492 13206 solver.cpp:253]     Train net output #0: loss = 1.25294 (* 1 = 1.25294 loss)
I0523 00:18:51.195505 13206 sgd_solver.cpp:106] Iteration 5625, lr = 0.005
I0523 00:19:01.028781 13206 solver.cpp:237] Iteration 6000, loss = 1.28869
I0523 00:19:01.028817 13206 solver.cpp:253]     Train net output #0: loss = 1.28869 (* 1 = 1.28869 loss)
I0523 00:19:01.028831 13206 sgd_solver.cpp:106] Iteration 6000, lr = 0.005
I0523 00:19:10.859683 13206 solver.cpp:237] Iteration 6375, loss = 1.43551
I0523 00:19:10.859732 13206 solver.cpp:253]     Train net output #0: loss = 1.43551 (* 1 = 1.43551 loss)
I0523 00:19:10.859745 13206 sgd_solver.cpp:106] Iteration 6375, lr = 0.005
I0523 00:19:20.683421 13206 solver.cpp:237] Iteration 6750, loss = 1.32261
I0523 00:19:20.683573 13206 solver.cpp:253]     Train net output #0: loss = 1.32261 (* 1 = 1.32261 loss)
I0523 00:19:20.683586 13206 sgd_solver.cpp:106] Iteration 6750, lr = 0.005
I0523 00:19:30.516077 13206 solver.cpp:237] Iteration 7125, loss = 1.13727
I0523 00:19:30.516110 13206 solver.cpp:253]     Train net output #0: loss = 1.13727 (* 1 = 1.13727 loss)
I0523 00:19:30.516129 13206 sgd_solver.cpp:106] Iteration 7125, lr = 0.005
I0523 00:19:40.323251 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_7500.caffemodel
I0523 00:19:40.379642 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_7500.solverstate
I0523 00:19:40.405086 13206 solver.cpp:341] Iteration 7500, Testing net (#0)
I0523 00:20:28.971614 13206 solver.cpp:409]     Test net output #0: accuracy = 0.838253
I0523 00:20:28.971781 13206 solver.cpp:409]     Test net output #1: loss = 0.553589 (* 1 = 0.553589 loss)
I0523 00:20:51.080770 13206 solver.cpp:237] Iteration 7500, loss = 1.1861
I0523 00:20:51.080826 13206 solver.cpp:253]     Train net output #0: loss = 1.1861 (* 1 = 1.1861 loss)
I0523 00:20:51.080843 13206 sgd_solver.cpp:106] Iteration 7500, lr = 0.005
I0523 00:21:00.982077 13206 solver.cpp:237] Iteration 7875, loss = 1.21048
I0523 00:21:00.982228 13206 solver.cpp:253]     Train net output #0: loss = 1.21048 (* 1 = 1.21048 loss)
I0523 00:21:00.982241 13206 sgd_solver.cpp:106] Iteration 7875, lr = 0.005
I0523 00:21:10.882077 13206 solver.cpp:237] Iteration 8250, loss = 1.27932
I0523 00:21:10.882112 13206 solver.cpp:253]     Train net output #0: loss = 1.27932 (* 1 = 1.27932 loss)
I0523 00:21:10.882129 13206 sgd_solver.cpp:106] Iteration 8250, lr = 0.005
I0523 00:21:20.773458 13206 solver.cpp:237] Iteration 8625, loss = 1.43668
I0523 00:21:20.773507 13206 solver.cpp:253]     Train net output #0: loss = 1.43668 (* 1 = 1.43668 loss)
I0523 00:21:20.773522 13206 sgd_solver.cpp:106] Iteration 8625, lr = 0.005
I0523 00:21:30.673212 13206 solver.cpp:237] Iteration 9000, loss = 1.08294
I0523 00:21:30.673246 13206 solver.cpp:253]     Train net output #0: loss = 1.08294 (* 1 = 1.08294 loss)
I0523 00:21:30.673262 13206 sgd_solver.cpp:106] Iteration 9000, lr = 0.005
I0523 00:21:40.587640 13206 solver.cpp:237] Iteration 9375, loss = 1.33479
I0523 00:21:40.587795 13206 solver.cpp:253]     Train net output #0: loss = 1.33479 (* 1 = 1.33479 loss)
I0523 00:21:40.587810 13206 sgd_solver.cpp:106] Iteration 9375, lr = 0.005
I0523 00:21:50.498149 13206 solver.cpp:237] Iteration 9750, loss = 1.25466
I0523 00:21:50.498184 13206 solver.cpp:253]     Train net output #0: loss = 1.25466 (* 1 = 1.25466 loss)
I0523 00:21:50.498203 13206 sgd_solver.cpp:106] Iteration 9750, lr = 0.005
I0523 00:22:22.512099 13206 solver.cpp:237] Iteration 10125, loss = 1.6515
I0523 00:22:22.512262 13206 solver.cpp:253]     Train net output #0: loss = 1.6515 (* 1 = 1.6515 loss)
I0523 00:22:22.512279 13206 sgd_solver.cpp:106] Iteration 10125, lr = 0.005
I0523 00:22:32.412044 13206 solver.cpp:237] Iteration 10500, loss = 1.28697
I0523 00:22:32.412096 13206 solver.cpp:253]     Train net output #0: loss = 1.28697 (* 1 = 1.28697 loss)
I0523 00:22:32.412111 13206 sgd_solver.cpp:106] Iteration 10500, lr = 0.005
I0523 00:22:42.319818 13206 solver.cpp:237] Iteration 10875, loss = 1.25369
I0523 00:22:42.319854 13206 solver.cpp:253]     Train net output #0: loss = 1.25369 (* 1 = 1.25369 loss)
I0523 00:22:42.319871 13206 sgd_solver.cpp:106] Iteration 10875, lr = 0.005
I0523 00:22:52.191601 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_11250.caffemodel
I0523 00:22:52.252043 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_11250.solverstate
I0523 00:22:52.287197 13206 solver.cpp:237] Iteration 11250, loss = 1.14948
I0523 00:22:52.287252 13206 solver.cpp:253]     Train net output #0: loss = 1.14948 (* 1 = 1.14948 loss)
I0523 00:22:52.287266 13206 sgd_solver.cpp:106] Iteration 11250, lr = 0.005
I0523 00:23:02.190146 13206 solver.cpp:237] Iteration 11625, loss = 1.29161
I0523 00:23:02.190316 13206 solver.cpp:253]     Train net output #0: loss = 1.29161 (* 1 = 1.29161 loss)
I0523 00:23:02.190330 13206 sgd_solver.cpp:106] Iteration 11625, lr = 0.005
I0523 00:23:12.095028 13206 solver.cpp:237] Iteration 12000, loss = 1.11118
I0523 00:23:12.095063 13206 solver.cpp:253]     Train net output #0: loss = 1.11118 (* 1 = 1.11118 loss)
I0523 00:23:12.095082 13206 sgd_solver.cpp:106] Iteration 12000, lr = 0.005
I0523 00:23:22.003226 13206 solver.cpp:237] Iteration 12375, loss = 1.23987
I0523 00:23:22.003278 13206 solver.cpp:253]     Train net output #0: loss = 1.23987 (* 1 = 1.23987 loss)
I0523 00:23:22.003295 13206 sgd_solver.cpp:106] Iteration 12375, lr = 0.005
I0523 00:23:54.063596 13206 solver.cpp:237] Iteration 12750, loss = 1.29225
I0523 00:23:54.063766 13206 solver.cpp:253]     Train net output #0: loss = 1.29225 (* 1 = 1.29225 loss)
I0523 00:23:54.063781 13206 sgd_solver.cpp:106] Iteration 12750, lr = 0.005
I0523 00:24:03.972643 13206 solver.cpp:237] Iteration 13125, loss = 1.29034
I0523 00:24:03.972678 13206 solver.cpp:253]     Train net output #0: loss = 1.29034 (* 1 = 1.29034 loss)
I0523 00:24:03.972694 13206 sgd_solver.cpp:106] Iteration 13125, lr = 0.005
I0523 00:24:13.875567 13206 solver.cpp:237] Iteration 13500, loss = 1.39597
I0523 00:24:13.875612 13206 solver.cpp:253]     Train net output #0: loss = 1.39597 (* 1 = 1.39597 loss)
I0523 00:24:13.875630 13206 sgd_solver.cpp:106] Iteration 13500, lr = 0.005
I0523 00:24:23.775156 13206 solver.cpp:237] Iteration 13875, loss = 1.23957
I0523 00:24:23.775192 13206 solver.cpp:253]     Train net output #0: loss = 1.23957 (* 1 = 1.23957 loss)
I0523 00:24:23.775209 13206 sgd_solver.cpp:106] Iteration 13875, lr = 0.005
I0523 00:24:33.669384 13206 solver.cpp:237] Iteration 14250, loss = 1.46655
I0523 00:24:33.669523 13206 solver.cpp:253]     Train net output #0: loss = 1.46655 (* 1 = 1.46655 loss)
I0523 00:24:33.669535 13206 sgd_solver.cpp:106] Iteration 14250, lr = 0.005
I0523 00:24:43.582780 13206 solver.cpp:237] Iteration 14625, loss = 1.21208
I0523 00:24:43.582823 13206 solver.cpp:253]     Train net output #0: loss = 1.21208 (* 1 = 1.21208 loss)
I0523 00:24:43.582842 13206 sgd_solver.cpp:106] Iteration 14625, lr = 0.005
I0523 00:24:53.460736 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_15000.caffemodel
I0523 00:24:53.519106 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_15000.solverstate
I0523 00:24:53.546705 13206 solver.cpp:341] Iteration 15000, Testing net (#0)
I0523 00:26:02.884456 13206 solver.cpp:409]     Test net output #0: accuracy = 0.85736
I0523 00:26:02.884620 13206 solver.cpp:409]     Test net output #1: loss = 0.469764 (* 1 = 0.469764 loss)
I0523 00:26:25.021296 13206 solver.cpp:237] Iteration 15000, loss = 1.17969
I0523 00:26:25.021353 13206 solver.cpp:253]     Train net output #0: loss = 1.17969 (* 1 = 1.17969 loss)
I0523 00:26:25.021368 13206 sgd_solver.cpp:106] Iteration 15000, lr = 0.005
I0523 00:26:34.764235 13206 solver.cpp:237] Iteration 15375, loss = 0.873223
I0523 00:26:34.764408 13206 solver.cpp:253]     Train net output #0: loss = 0.873223 (* 1 = 0.873223 loss)
I0523 00:26:34.764423 13206 sgd_solver.cpp:106] Iteration 15375, lr = 0.005
I0523 00:26:44.508757 13206 solver.cpp:237] Iteration 15750, loss = 1.40579
I0523 00:26:44.508805 13206 solver.cpp:253]     Train net output #0: loss = 1.4058 (* 1 = 1.4058 loss)
I0523 00:26:44.508821 13206 sgd_solver.cpp:106] Iteration 15750, lr = 0.005
I0523 00:26:54.249172 13206 solver.cpp:237] Iteration 16125, loss = 1.42774
I0523 00:26:54.249208 13206 solver.cpp:253]     Train net output #0: loss = 1.42774 (* 1 = 1.42774 loss)
I0523 00:26:54.249224 13206 sgd_solver.cpp:106] Iteration 16125, lr = 0.005
I0523 00:27:03.993041 13206 solver.cpp:237] Iteration 16500, loss = 1.79466
I0523 00:27:03.993078 13206 solver.cpp:253]     Train net output #0: loss = 1.79466 (* 1 = 1.79466 loss)
I0523 00:27:03.993095 13206 sgd_solver.cpp:106] Iteration 16500, lr = 0.005
I0523 00:27:13.741288 13206 solver.cpp:237] Iteration 16875, loss = 1.02168
I0523 00:27:13.741433 13206 solver.cpp:253]     Train net output #0: loss = 1.02168 (* 1 = 1.02168 loss)
I0523 00:27:13.741446 13206 sgd_solver.cpp:106] Iteration 16875, lr = 0.005
I0523 00:27:23.480991 13206 solver.cpp:237] Iteration 17250, loss = 0.934267
I0523 00:27:23.481027 13206 solver.cpp:253]     Train net output #0: loss = 0.934267 (* 1 = 0.934267 loss)
I0523 00:27:23.481043 13206 sgd_solver.cpp:106] Iteration 17250, lr = 0.005
I0523 00:27:55.357889 13206 solver.cpp:237] Iteration 17625, loss = 1.29544
I0523 00:27:55.358074 13206 solver.cpp:253]     Train net output #0: loss = 1.29544 (* 1 = 1.29544 loss)
I0523 00:27:55.358089 13206 sgd_solver.cpp:106] Iteration 17625, lr = 0.005
I0523 00:28:05.091884 13206 solver.cpp:237] Iteration 18000, loss = 1.01769
I0523 00:28:05.091918 13206 solver.cpp:253]     Train net output #0: loss = 1.01769 (* 1 = 1.01769 loss)
I0523 00:28:05.091936 13206 sgd_solver.cpp:106] Iteration 18000, lr = 0.005
I0523 00:28:14.829555 13206 solver.cpp:237] Iteration 18375, loss = 1.30452
I0523 00:28:14.829591 13206 solver.cpp:253]     Train net output #0: loss = 1.30452 (* 1 = 1.30452 loss)
I0523 00:28:14.829607 13206 sgd_solver.cpp:106] Iteration 18375, lr = 0.005
I0523 00:28:24.545754 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_18750.caffemodel
I0523 00:28:24.603128 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_18750.solverstate
I0523 00:28:24.639569 13206 solver.cpp:237] Iteration 18750, loss = 1.19838
I0523 00:28:24.639623 13206 solver.cpp:253]     Train net output #0: loss = 1.19838 (* 1 = 1.19838 loss)
I0523 00:28:24.639638 13206 sgd_solver.cpp:106] Iteration 18750, lr = 0.005
I0523 00:28:34.379216 13206 solver.cpp:237] Iteration 19125, loss = 0.959203
I0523 00:28:34.379364 13206 solver.cpp:253]     Train net output #0: loss = 0.959203 (* 1 = 0.959203 loss)
I0523 00:28:34.379379 13206 sgd_solver.cpp:106] Iteration 19125, lr = 0.005
I0523 00:28:44.117858 13206 solver.cpp:237] Iteration 19500, loss = 1.34197
I0523 00:28:44.117892 13206 solver.cpp:253]     Train net output #0: loss = 1.34197 (* 1 = 1.34197 loss)
I0523 00:28:44.117908 13206 sgd_solver.cpp:106] Iteration 19500, lr = 0.005
I0523 00:28:53.860930 13206 solver.cpp:237] Iteration 19875, loss = 1.21643
I0523 00:28:53.860966 13206 solver.cpp:253]     Train net output #0: loss = 1.21643 (* 1 = 1.21643 loss)
I0523 00:28:53.860985 13206 sgd_solver.cpp:106] Iteration 19875, lr = 0.005
I0523 00:29:25.792889 13206 solver.cpp:237] Iteration 20250, loss = 1.14971
I0523 00:29:25.793064 13206 solver.cpp:253]     Train net output #0: loss = 1.14971 (* 1 = 1.14971 loss)
I0523 00:29:25.793079 13206 sgd_solver.cpp:106] Iteration 20250, lr = 0.005
I0523 00:29:35.532385 13206 solver.cpp:237] Iteration 20625, loss = 1.19897
I0523 00:29:35.532439 13206 solver.cpp:253]     Train net output #0: loss = 1.19897 (* 1 = 1.19897 loss)
I0523 00:29:35.532455 13206 sgd_solver.cpp:106] Iteration 20625, lr = 0.005
I0523 00:29:45.272969 13206 solver.cpp:237] Iteration 21000, loss = 1.0182
I0523 00:29:45.273005 13206 solver.cpp:253]     Train net output #0: loss = 1.0182 (* 1 = 1.0182 loss)
I0523 00:29:45.273022 13206 sgd_solver.cpp:106] Iteration 21000, lr = 0.005
I0523 00:29:55.009806 13206 solver.cpp:237] Iteration 21375, loss = 1.57155
I0523 00:29:55.009842 13206 solver.cpp:253]     Train net output #0: loss = 1.57155 (* 1 = 1.57155 loss)
I0523 00:29:55.009856 13206 sgd_solver.cpp:106] Iteration 21375, lr = 0.005
I0523 00:30:04.750917 13206 solver.cpp:237] Iteration 21750, loss = 1.29703
I0523 00:30:04.751076 13206 solver.cpp:253]     Train net output #0: loss = 1.29703 (* 1 = 1.29703 loss)
I0523 00:30:04.751091 13206 sgd_solver.cpp:106] Iteration 21750, lr = 0.005
I0523 00:30:14.497833 13206 solver.cpp:237] Iteration 22125, loss = 0.781711
I0523 00:30:14.497867 13206 solver.cpp:253]     Train net output #0: loss = 0.781712 (* 1 = 0.781712 loss)
I0523 00:30:14.497884 13206 sgd_solver.cpp:106] Iteration 22125, lr = 0.005
I0523 00:30:24.209450 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_22500.caffemodel
I0523 00:30:24.266046 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_22500.solverstate
I0523 00:30:24.292171 13206 solver.cpp:341] Iteration 22500, Testing net (#0)
I0523 00:31:12.503703 13206 solver.cpp:409]     Test net output #0: accuracy = 0.870015
I0523 00:31:12.503882 13206 solver.cpp:409]     Test net output #1: loss = 0.407789 (* 1 = 0.407789 loss)
I0523 00:31:34.701128 13206 solver.cpp:237] Iteration 22500, loss = 1.1092
I0523 00:31:34.701179 13206 solver.cpp:253]     Train net output #0: loss = 1.1092 (* 1 = 1.1092 loss)
I0523 00:31:34.701196 13206 sgd_solver.cpp:106] Iteration 22500, lr = 0.005
I0523 00:31:44.502599 13206 solver.cpp:237] Iteration 22875, loss = 1.09624
I0523 00:31:44.502784 13206 solver.cpp:253]     Train net output #0: loss = 1.09624 (* 1 = 1.09624 loss)
I0523 00:31:44.502799 13206 sgd_solver.cpp:106] Iteration 22875, lr = 0.005
I0523 00:31:54.308509 13206 solver.cpp:237] Iteration 23250, loss = 1.33
I0523 00:31:54.308545 13206 solver.cpp:253]     Train net output #0: loss = 1.33 (* 1 = 1.33 loss)
I0523 00:31:54.308564 13206 sgd_solver.cpp:106] Iteration 23250, lr = 0.005
I0523 00:32:04.111448 13206 solver.cpp:237] Iteration 23625, loss = 1.27163
I0523 00:32:04.111484 13206 solver.cpp:253]     Train net output #0: loss = 1.27163 (* 1 = 1.27163 loss)
I0523 00:32:04.111500 13206 sgd_solver.cpp:106] Iteration 23625, lr = 0.005
I0523 00:32:13.918385 13206 solver.cpp:237] Iteration 24000, loss = 1.41081
I0523 00:32:13.918431 13206 solver.cpp:253]     Train net output #0: loss = 1.41081 (* 1 = 1.41081 loss)
I0523 00:32:13.918447 13206 sgd_solver.cpp:106] Iteration 24000, lr = 0.005
I0523 00:32:23.730680 13206 solver.cpp:237] Iteration 24375, loss = 1.25331
I0523 00:32:23.730824 13206 solver.cpp:253]     Train net output #0: loss = 1.25331 (* 1 = 1.25331 loss)
I0523 00:32:23.730839 13206 sgd_solver.cpp:106] Iteration 24375, lr = 0.005
I0523 00:32:33.539450 13206 solver.cpp:237] Iteration 24750, loss = 0.89165
I0523 00:32:33.539502 13206 solver.cpp:253]     Train net output #0: loss = 0.891651 (* 1 = 0.891651 loss)
I0523 00:32:33.539520 13206 sgd_solver.cpp:106] Iteration 24750, lr = 0.005
I0523 00:33:05.562151 13206 solver.cpp:237] Iteration 25125, loss = 0.983015
I0523 00:33:05.562335 13206 solver.cpp:253]     Train net output #0: loss = 0.983015 (* 1 = 0.983015 loss)
I0523 00:33:05.562350 13206 sgd_solver.cpp:106] Iteration 25125, lr = 0.005
I0523 00:33:15.369753 13206 solver.cpp:237] Iteration 25500, loss = 0.974433
I0523 00:33:15.369789 13206 solver.cpp:253]     Train net output #0: loss = 0.974433 (* 1 = 0.974433 loss)
I0523 00:33:15.369807 13206 sgd_solver.cpp:106] Iteration 25500, lr = 0.005
I0523 00:33:25.178210 13206 solver.cpp:237] Iteration 25875, loss = 1.44598
I0523 00:33:25.178259 13206 solver.cpp:253]     Train net output #0: loss = 1.44598 (* 1 = 1.44598 loss)
I0523 00:33:25.178282 13206 sgd_solver.cpp:106] Iteration 25875, lr = 0.005
I0523 00:33:34.954931 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_26250.caffemodel
I0523 00:33:35.015009 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_26250.solverstate
I0523 00:33:35.049708 13206 solver.cpp:237] Iteration 26250, loss = 0.880614
I0523 00:33:35.049762 13206 solver.cpp:253]     Train net output #0: loss = 0.880614 (* 1 = 0.880614 loss)
I0523 00:33:35.049777 13206 sgd_solver.cpp:106] Iteration 26250, lr = 0.005
I0523 00:33:44.853837 13206 solver.cpp:237] Iteration 26625, loss = 1.13242
I0523 00:33:44.854001 13206 solver.cpp:253]     Train net output #0: loss = 1.13242 (* 1 = 1.13242 loss)
I0523 00:33:44.854015 13206 sgd_solver.cpp:106] Iteration 26625, lr = 0.005
I0523 00:33:54.655269 13206 solver.cpp:237] Iteration 27000, loss = 1.11347
I0523 00:33:54.655304 13206 solver.cpp:253]     Train net output #0: loss = 1.11347 (* 1 = 1.11347 loss)
I0523 00:33:54.655321 13206 sgd_solver.cpp:106] Iteration 27000, lr = 0.005
I0523 00:34:04.453114 13206 solver.cpp:237] Iteration 27375, loss = 0.932234
I0523 00:34:04.453150 13206 solver.cpp:253]     Train net output #0: loss = 0.932234 (* 1 = 0.932234 loss)
I0523 00:34:04.453166 13206 sgd_solver.cpp:106] Iteration 27375, lr = 0.005
I0523 00:34:36.425086 13206 solver.cpp:237] Iteration 27750, loss = 1.2069
I0523 00:34:36.425253 13206 solver.cpp:253]     Train net output #0: loss = 1.2069 (* 1 = 1.2069 loss)
I0523 00:34:36.425267 13206 sgd_solver.cpp:106] Iteration 27750, lr = 0.005
I0523 00:34:46.227073 13206 solver.cpp:237] Iteration 28125, loss = 1.15339
I0523 00:34:46.227108 13206 solver.cpp:253]     Train net output #0: loss = 1.1534 (* 1 = 1.1534 loss)
I0523 00:34:46.227126 13206 sgd_solver.cpp:106] Iteration 28125, lr = 0.005
I0523 00:34:56.033265 13206 solver.cpp:237] Iteration 28500, loss = 1.04329
I0523 00:34:56.033301 13206 solver.cpp:253]     Train net output #0: loss = 1.04329 (* 1 = 1.04329 loss)
I0523 00:34:56.033318 13206 sgd_solver.cpp:106] Iteration 28500, lr = 0.005
I0523 00:35:05.846204 13206 solver.cpp:237] Iteration 28875, loss = 1.29044
I0523 00:35:05.846246 13206 solver.cpp:253]     Train net output #0: loss = 1.29045 (* 1 = 1.29045 loss)
I0523 00:35:05.846267 13206 sgd_solver.cpp:106] Iteration 28875, lr = 0.005
I0523 00:35:15.651402 13206 solver.cpp:237] Iteration 29250, loss = 1.22609
I0523 00:35:15.651561 13206 solver.cpp:253]     Train net output #0: loss = 1.22609 (* 1 = 1.22609 loss)
I0523 00:35:15.651576 13206 sgd_solver.cpp:106] Iteration 29250, lr = 0.005
I0523 00:35:25.458748 13206 solver.cpp:237] Iteration 29625, loss = 1.05027
I0523 00:35:25.458796 13206 solver.cpp:253]     Train net output #0: loss = 1.05027 (* 1 = 1.05027 loss)
I0523 00:35:25.458816 13206 sgd_solver.cpp:106] Iteration 29625, lr = 0.005
I0523 00:35:35.238447 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_30000.caffemodel
I0523 00:35:35.294453 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_30000.solverstate
I0523 00:35:35.320716 13206 solver.cpp:341] Iteration 30000, Testing net (#0)
I0523 00:36:44.764355 13206 solver.cpp:409]     Test net output #0: accuracy = 0.876307
I0523 00:36:44.764533 13206 solver.cpp:409]     Test net output #1: loss = 0.400886 (* 1 = 0.400886 loss)
I0523 00:37:06.997740 13206 solver.cpp:237] Iteration 30000, loss = 1.47881
I0523 00:37:06.997797 13206 solver.cpp:253]     Train net output #0: loss = 1.47881 (* 1 = 1.47881 loss)
I0523 00:37:06.997812 13206 sgd_solver.cpp:106] Iteration 30000, lr = 0.005
I0523 00:37:16.912366 13206 solver.cpp:237] Iteration 30375, loss = 1.0171
I0523 00:37:16.912538 13206 solver.cpp:253]     Train net output #0: loss = 1.0171 (* 1 = 1.0171 loss)
I0523 00:37:16.912550 13206 sgd_solver.cpp:106] Iteration 30375, lr = 0.005
I0523 00:37:26.831785 13206 solver.cpp:237] Iteration 30750, loss = 1.09902
I0523 00:37:26.831820 13206 solver.cpp:253]     Train net output #0: loss = 1.09902 (* 1 = 1.09902 loss)
I0523 00:37:26.831837 13206 sgd_solver.cpp:106] Iteration 30750, lr = 0.005
I0523 00:37:36.749413 13206 solver.cpp:237] Iteration 31125, loss = 1.01562
I0523 00:37:36.749457 13206 solver.cpp:253]     Train net output #0: loss = 1.01562 (* 1 = 1.01562 loss)
I0523 00:37:36.749476 13206 sgd_solver.cpp:106] Iteration 31125, lr = 0.005
I0523 00:37:46.664948 13206 solver.cpp:237] Iteration 31500, loss = 1.01499
I0523 00:37:46.664984 13206 solver.cpp:253]     Train net output #0: loss = 1.01499 (* 1 = 1.01499 loss)
I0523 00:37:46.665000 13206 sgd_solver.cpp:106] Iteration 31500, lr = 0.005
I0523 00:37:56.586258 13206 solver.cpp:237] Iteration 31875, loss = 1.13912
I0523 00:37:56.586419 13206 solver.cpp:253]     Train net output #0: loss = 1.13912 (* 1 = 1.13912 loss)
I0523 00:37:56.586433 13206 sgd_solver.cpp:106] Iteration 31875, lr = 0.005
I0523 00:38:06.511274 13206 solver.cpp:237] Iteration 32250, loss = 1.02433
I0523 00:38:06.511309 13206 solver.cpp:253]     Train net output #0: loss = 1.02433 (* 1 = 1.02433 loss)
I0523 00:38:06.511327 13206 sgd_solver.cpp:106] Iteration 32250, lr = 0.005
I0523 00:38:41.082679 13206 solver.cpp:237] Iteration 32625, loss = 0.843934
I0523 00:38:41.082855 13206 solver.cpp:253]     Train net output #0: loss = 0.843934 (* 1 = 0.843934 loss)
I0523 00:38:41.082871 13206 sgd_solver.cpp:106] Iteration 32625, lr = 0.005
I0523 00:38:50.994216 13206 solver.cpp:237] Iteration 33000, loss = 1.48158
I0523 00:38:50.994264 13206 solver.cpp:253]     Train net output #0: loss = 1.48158 (* 1 = 1.48158 loss)
I0523 00:38:50.994280 13206 sgd_solver.cpp:106] Iteration 33000, lr = 0.005
I0523 00:39:00.906267 13206 solver.cpp:237] Iteration 33375, loss = 1.22104
I0523 00:39:00.906304 13206 solver.cpp:253]     Train net output #0: loss = 1.22104 (* 1 = 1.22104 loss)
I0523 00:39:00.906319 13206 sgd_solver.cpp:106] Iteration 33375, lr = 0.005
I0523 00:39:10.803706 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_33750.caffemodel
I0523 00:39:10.863392 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_33750.solverstate
I0523 00:39:10.899984 13206 solver.cpp:237] Iteration 33750, loss = 1.59486
I0523 00:39:10.900039 13206 solver.cpp:253]     Train net output #0: loss = 1.59486 (* 1 = 1.59486 loss)
I0523 00:39:10.900053 13206 sgd_solver.cpp:106] Iteration 33750, lr = 0.005
I0523 00:39:20.813347 13206 solver.cpp:237] Iteration 34125, loss = 1.16124
I0523 00:39:20.813501 13206 solver.cpp:253]     Train net output #0: loss = 1.16125 (* 1 = 1.16125 loss)
I0523 00:39:20.813515 13206 sgd_solver.cpp:106] Iteration 34125, lr = 0.005
I0523 00:39:30.723795 13206 solver.cpp:237] Iteration 34500, loss = 1.2092
I0523 00:39:30.723829 13206 solver.cpp:253]     Train net output #0: loss = 1.2092 (* 1 = 1.2092 loss)
I0523 00:39:30.723847 13206 sgd_solver.cpp:106] Iteration 34500, lr = 0.005
I0523 00:39:40.637250 13206 solver.cpp:237] Iteration 34875, loss = 1.44362
I0523 00:39:40.637293 13206 solver.cpp:253]     Train net output #0: loss = 1.44362 (* 1 = 1.44362 loss)
I0523 00:39:40.637315 13206 sgd_solver.cpp:106] Iteration 34875, lr = 0.005
I0523 00:40:12.773847 13206 solver.cpp:237] Iteration 35250, loss = 0.940403
I0523 00:40:12.774032 13206 solver.cpp:253]     Train net output #0: loss = 0.940403 (* 1 = 0.940403 loss)
I0523 00:40:12.774047 13206 sgd_solver.cpp:106] Iteration 35250, lr = 0.005
I0523 00:40:22.687726 13206 solver.cpp:237] Iteration 35625, loss = 1.46508
I0523 00:40:22.687762 13206 solver.cpp:253]     Train net output #0: loss = 1.46508 (* 1 = 1.46508 loss)
I0523 00:40:22.687775 13206 sgd_solver.cpp:106] Iteration 35625, lr = 0.005
I0523 00:40:32.602591 13206 solver.cpp:237] Iteration 36000, loss = 1.24159
I0523 00:40:32.602635 13206 solver.cpp:253]     Train net output #0: loss = 1.24159 (* 1 = 1.24159 loss)
I0523 00:40:32.602653 13206 sgd_solver.cpp:106] Iteration 36000, lr = 0.005
I0523 00:40:42.515781 13206 solver.cpp:237] Iteration 36375, loss = 1.34906
I0523 00:40:42.515817 13206 solver.cpp:253]     Train net output #0: loss = 1.34906 (* 1 = 1.34906 loss)
I0523 00:40:42.515830 13206 sgd_solver.cpp:106] Iteration 36375, lr = 0.005
I0523 00:40:52.434619 13206 solver.cpp:237] Iteration 36750, loss = 1.43111
I0523 00:40:52.434784 13206 solver.cpp:253]     Train net output #0: loss = 1.43111 (* 1 = 1.43111 loss)
I0523 00:40:52.434798 13206 sgd_solver.cpp:106] Iteration 36750, lr = 0.005
I0523 00:41:02.346843 13206 solver.cpp:237] Iteration 37125, loss = 1.53208
I0523 00:41:02.346879 13206 solver.cpp:253]     Train net output #0: loss = 1.53209 (* 1 = 1.53209 loss)
I0523 00:41:02.346895 13206 sgd_solver.cpp:106] Iteration 37125, lr = 0.005
I0523 00:41:12.242622 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_37500.caffemodel
I0523 00:41:12.301024 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_37500.solverstate
I0523 00:41:12.329479 13206 solver.cpp:341] Iteration 37500, Testing net (#0)
I0523 00:42:00.950597 13206 solver.cpp:409]     Test net output #0: accuracy = 0.880294
I0523 00:42:00.950770 13206 solver.cpp:409]     Test net output #1: loss = 0.389258 (* 1 = 0.389258 loss)
I0523 00:42:21.862898 13206 solver.cpp:237] Iteration 37500, loss = 1.05276
I0523 00:42:21.862956 13206 solver.cpp:253]     Train net output #0: loss = 1.05276 (* 1 = 1.05276 loss)
I0523 00:42:21.862970 13206 sgd_solver.cpp:106] Iteration 37500, lr = 0.005
I0523 00:42:31.812258 13206 solver.cpp:237] Iteration 37875, loss = 1.09597
I0523 00:42:31.812423 13206 solver.cpp:253]     Train net output #0: loss = 1.09597 (* 1 = 1.09597 loss)
I0523 00:42:31.812438 13206 sgd_solver.cpp:106] Iteration 37875, lr = 0.005
I0523 00:42:41.758694 13206 solver.cpp:237] Iteration 38250, loss = 1.1789
I0523 00:42:41.758729 13206 solver.cpp:253]     Train net output #0: loss = 1.1789 (* 1 = 1.1789 loss)
I0523 00:42:41.758746 13206 sgd_solver.cpp:106] Iteration 38250, lr = 0.005
I0523 00:42:51.703433 13206 solver.cpp:237] Iteration 38625, loss = 1.08035
I0523 00:42:51.703469 13206 solver.cpp:253]     Train net output #0: loss = 1.08035 (* 1 = 1.08035 loss)
I0523 00:42:51.703487 13206 sgd_solver.cpp:106] Iteration 38625, lr = 0.005
I0523 00:43:01.655656 13206 solver.cpp:237] Iteration 39000, loss = 1.2134
I0523 00:43:01.655699 13206 solver.cpp:253]     Train net output #0: loss = 1.2134 (* 1 = 1.2134 loss)
I0523 00:43:01.655716 13206 sgd_solver.cpp:106] Iteration 39000, lr = 0.005
I0523 00:43:11.608994 13206 solver.cpp:237] Iteration 39375, loss = 1.54711
I0523 00:43:11.609144 13206 solver.cpp:253]     Train net output #0: loss = 1.54711 (* 1 = 1.54711 loss)
I0523 00:43:11.609158 13206 sgd_solver.cpp:106] Iteration 39375, lr = 0.005
I0523 00:43:21.560148 13206 solver.cpp:237] Iteration 39750, loss = 1.24266
I0523 00:43:21.560195 13206 solver.cpp:253]     Train net output #0: loss = 1.24266 (* 1 = 1.24266 loss)
I0523 00:43:21.560214 13206 sgd_solver.cpp:106] Iteration 39750, lr = 0.005
I0523 00:43:52.394062 13206 solver.cpp:237] Iteration 40125, loss = 1.37664
I0523 00:43:52.394248 13206 solver.cpp:253]     Train net output #0: loss = 1.37664 (* 1 = 1.37664 loss)
I0523 00:43:52.394264 13206 sgd_solver.cpp:106] Iteration 40125, lr = 0.005
I0523 00:44:02.342103 13206 solver.cpp:237] Iteration 40500, loss = 1.11952
I0523 00:44:02.342133 13206 solver.cpp:253]     Train net output #0: loss = 1.11952 (* 1 = 1.11952 loss)
I0523 00:44:02.342149 13206 sgd_solver.cpp:106] Iteration 40500, lr = 0.005
I0523 00:44:12.292469 13206 solver.cpp:237] Iteration 40875, loss = 1.48658
I0523 00:44:12.292517 13206 solver.cpp:253]     Train net output #0: loss = 1.48658 (* 1 = 1.48658 loss)
I0523 00:44:12.292537 13206 sgd_solver.cpp:106] Iteration 40875, lr = 0.005
I0523 00:44:22.214340 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_41250.caffemodel
I0523 00:44:22.271445 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_41250.solverstate
I0523 00:44:22.306010 13206 solver.cpp:237] Iteration 41250, loss = 1.15372
I0523 00:44:22.306054 13206 solver.cpp:253]     Train net output #0: loss = 1.15372 (* 1 = 1.15372 loss)
I0523 00:44:22.306072 13206 sgd_solver.cpp:106] Iteration 41250, lr = 0.005
I0523 00:44:32.258867 13206 solver.cpp:237] Iteration 41625, loss = 1.23634
I0523 00:44:32.259021 13206 solver.cpp:253]     Train net output #0: loss = 1.23634 (* 1 = 1.23634 loss)
I0523 00:44:32.259034 13206 sgd_solver.cpp:106] Iteration 41625, lr = 0.005
I0523 00:44:42.214730 13206 solver.cpp:237] Iteration 42000, loss = 1.11164
I0523 00:44:42.214774 13206 solver.cpp:253]     Train net output #0: loss = 1.11164 (* 1 = 1.11164 loss)
I0523 00:44:42.214795 13206 sgd_solver.cpp:106] Iteration 42000, lr = 0.005
I0523 00:44:52.167757 13206 solver.cpp:237] Iteration 42375, loss = 1.31863
I0523 00:44:52.167793 13206 solver.cpp:253]     Train net output #0: loss = 1.31863 (* 1 = 1.31863 loss)
I0523 00:44:52.167809 13206 sgd_solver.cpp:106] Iteration 42375, lr = 0.005
I0523 00:45:22.993897 13206 solver.cpp:237] Iteration 42750, loss = 1.09119
I0523 00:45:22.994073 13206 solver.cpp:253]     Train net output #0: loss = 1.09119 (* 1 = 1.09119 loss)
I0523 00:45:22.994088 13206 sgd_solver.cpp:106] Iteration 42750, lr = 0.005
I0523 00:45:32.941540 13206 solver.cpp:237] Iteration 43125, loss = 1.12133
I0523 00:45:32.941584 13206 solver.cpp:253]     Train net output #0: loss = 1.12133 (* 1 = 1.12133 loss)
I0523 00:45:32.941606 13206 sgd_solver.cpp:106] Iteration 43125, lr = 0.005
I0523 00:45:42.884686 13206 solver.cpp:237] Iteration 43500, loss = 1.38356
I0523 00:45:42.884722 13206 solver.cpp:253]     Train net output #0: loss = 1.38356 (* 1 = 1.38356 loss)
I0523 00:45:42.884738 13206 sgd_solver.cpp:106] Iteration 43500, lr = 0.005
I0523 00:45:52.833905 13206 solver.cpp:237] Iteration 43875, loss = 1.40803
I0523 00:45:52.833956 13206 solver.cpp:253]     Train net output #0: loss = 1.40803 (* 1 = 1.40803 loss)
I0523 00:45:52.833973 13206 sgd_solver.cpp:106] Iteration 43875, lr = 0.005
I0523 00:46:02.782243 13206 solver.cpp:237] Iteration 44250, loss = 1.09273
I0523 00:46:02.782392 13206 solver.cpp:253]     Train net output #0: loss = 1.09273 (* 1 = 1.09273 loss)
I0523 00:46:02.782407 13206 sgd_solver.cpp:106] Iteration 44250, lr = 0.005
I0523 00:46:12.730198 13206 solver.cpp:237] Iteration 44625, loss = 1.40949
I0523 00:46:12.730233 13206 solver.cpp:253]     Train net output #0: loss = 1.40949 (* 1 = 1.40949 loss)
I0523 00:46:12.730252 13206 sgd_solver.cpp:106] Iteration 44625, lr = 0.005
I0523 00:46:22.652993 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_45000.caffemodel
I0523 00:46:22.708009 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_45000.solverstate
I0523 00:46:22.734733 13206 solver.cpp:341] Iteration 45000, Testing net (#0)
I0523 00:47:32.087381 13206 solver.cpp:409]     Test net output #0: accuracy = 0.882226
I0523 00:47:32.087563 13206 solver.cpp:409]     Test net output #1: loss = 0.367375 (* 1 = 0.367375 loss)
I0523 00:47:52.941939 13206 solver.cpp:237] Iteration 45000, loss = 1.07591
I0523 00:47:52.941998 13206 solver.cpp:253]     Train net output #0: loss = 1.07591 (* 1 = 1.07591 loss)
I0523 00:47:52.942013 13206 sgd_solver.cpp:106] Iteration 45000, lr = 0.005
I0523 00:48:02.642108 13206 solver.cpp:237] Iteration 45375, loss = 1.24448
I0523 00:48:02.642292 13206 solver.cpp:253]     Train net output #0: loss = 1.24448 (* 1 = 1.24448 loss)
I0523 00:48:02.642307 13206 sgd_solver.cpp:106] Iteration 45375, lr = 0.005
I0523 00:48:12.343530 13206 solver.cpp:237] Iteration 45750, loss = 1.41645
I0523 00:48:12.343565 13206 solver.cpp:253]     Train net output #0: loss = 1.41645 (* 1 = 1.41645 loss)
I0523 00:48:12.343582 13206 sgd_solver.cpp:106] Iteration 45750, lr = 0.005
I0523 00:48:22.036866 13206 solver.cpp:237] Iteration 46125, loss = 1.28006
I0523 00:48:22.036909 13206 solver.cpp:253]     Train net output #0: loss = 1.28006 (* 1 = 1.28006 loss)
I0523 00:48:22.036926 13206 sgd_solver.cpp:106] Iteration 46125, lr = 0.005
I0523 00:48:31.734521 13206 solver.cpp:237] Iteration 46500, loss = 0.808296
I0523 00:48:31.734557 13206 solver.cpp:253]     Train net output #0: loss = 0.808296 (* 1 = 0.808296 loss)
I0523 00:48:31.734570 13206 sgd_solver.cpp:106] Iteration 46500, lr = 0.005
I0523 00:48:41.438189 13206 solver.cpp:237] Iteration 46875, loss = 1.46996
I0523 00:48:41.438336 13206 solver.cpp:253]     Train net output #0: loss = 1.46996 (* 1 = 1.46996 loss)
I0523 00:48:41.438349 13206 sgd_solver.cpp:106] Iteration 46875, lr = 0.005
I0523 00:48:51.147958 13206 solver.cpp:237] Iteration 47250, loss = 1.27876
I0523 00:48:51.148010 13206 solver.cpp:253]     Train net output #0: loss = 1.27876 (* 1 = 1.27876 loss)
I0523 00:48:51.148023 13206 sgd_solver.cpp:106] Iteration 47250, lr = 0.005
I0523 00:49:21.718809 13206 solver.cpp:237] Iteration 47625, loss = 1.15181
I0523 00:49:21.718986 13206 solver.cpp:253]     Train net output #0: loss = 1.15181 (* 1 = 1.15181 loss)
I0523 00:49:21.719000 13206 sgd_solver.cpp:106] Iteration 47625, lr = 0.005
I0523 00:49:31.421094 13206 solver.cpp:237] Iteration 48000, loss = 1.02397
I0523 00:49:31.421129 13206 solver.cpp:253]     Train net output #0: loss = 1.02398 (* 1 = 1.02398 loss)
I0523 00:49:31.421146 13206 sgd_solver.cpp:106] Iteration 48000, lr = 0.005
I0523 00:49:41.120895 13206 solver.cpp:237] Iteration 48375, loss = 1.29097
I0523 00:49:41.120944 13206 solver.cpp:253]     Train net output #0: loss = 1.29097 (* 1 = 1.29097 loss)
I0523 00:49:41.120960 13206 sgd_solver.cpp:106] Iteration 48375, lr = 0.005
I0523 00:49:50.799834 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_48750.caffemodel
I0523 00:49:50.856039 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_48750.solverstate
I0523 00:49:50.890820 13206 solver.cpp:237] Iteration 48750, loss = 1.31047
I0523 00:49:50.890869 13206 solver.cpp:253]     Train net output #0: loss = 1.31047 (* 1 = 1.31047 loss)
I0523 00:49:50.890883 13206 sgd_solver.cpp:106] Iteration 48750, lr = 0.005
I0523 00:50:00.588856 13206 solver.cpp:237] Iteration 49125, loss = 1.24791
I0523 00:50:00.589032 13206 solver.cpp:253]     Train net output #0: loss = 1.24791 (* 1 = 1.24791 loss)
I0523 00:50:00.589046 13206 sgd_solver.cpp:106] Iteration 49125, lr = 0.005
I0523 00:50:10.289769 13206 solver.cpp:237] Iteration 49500, loss = 1.0015
I0523 00:50:10.289804 13206 solver.cpp:253]     Train net output #0: loss = 1.0015 (* 1 = 1.0015 loss)
I0523 00:50:10.289820 13206 sgd_solver.cpp:106] Iteration 49500, lr = 0.005
I0523 00:50:19.993438 13206 solver.cpp:237] Iteration 49875, loss = 1.35542
I0523 00:50:19.993474 13206 solver.cpp:253]     Train net output #0: loss = 1.35542 (* 1 = 1.35542 loss)
I0523 00:50:19.993489 13206 sgd_solver.cpp:106] Iteration 49875, lr = 0.005
I0523 00:50:50.552722 13206 solver.cpp:237] Iteration 50250, loss = 0.975957
I0523 00:50:50.552903 13206 solver.cpp:253]     Train net output #0: loss = 0.975957 (* 1 = 0.975957 loss)
I0523 00:50:50.552918 13206 sgd_solver.cpp:106] Iteration 50250, lr = 0.005
I0523 00:51:00.250675 13206 solver.cpp:237] Iteration 50625, loss = 1.14859
I0523 00:51:00.250710 13206 solver.cpp:253]     Train net output #0: loss = 1.14859 (* 1 = 1.14859 loss)
I0523 00:51:00.250727 13206 sgd_solver.cpp:106] Iteration 50625, lr = 0.005
I0523 00:51:09.949385 13206 solver.cpp:237] Iteration 51000, loss = 1.20073
I0523 00:51:09.949421 13206 solver.cpp:253]     Train net output #0: loss = 1.20073 (* 1 = 1.20073 loss)
I0523 00:51:09.949437 13206 sgd_solver.cpp:106] Iteration 51000, lr = 0.005
I0523 00:51:19.651110 13206 solver.cpp:237] Iteration 51375, loss = 1.1788
I0523 00:51:19.651151 13206 solver.cpp:253]     Train net output #0: loss = 1.1788 (* 1 = 1.1788 loss)
I0523 00:51:19.651173 13206 sgd_solver.cpp:106] Iteration 51375, lr = 0.005
I0523 00:51:29.354197 13206 solver.cpp:237] Iteration 51750, loss = 1.0762
I0523 00:51:29.354352 13206 solver.cpp:253]     Train net output #0: loss = 1.0762 (* 1 = 1.0762 loss)
I0523 00:51:29.354367 13206 sgd_solver.cpp:106] Iteration 51750, lr = 0.005
I0523 00:51:39.055841 13206 solver.cpp:237] Iteration 52125, loss = 1.01872
I0523 00:51:39.055876 13206 solver.cpp:253]     Train net output #0: loss = 1.01872 (* 1 = 1.01872 loss)
I0523 00:51:39.055892 13206 sgd_solver.cpp:106] Iteration 52125, lr = 0.005
I0523 00:51:48.732067 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_52500.caffemodel
I0523 00:51:48.788712 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_52500.solverstate
I0523 00:51:48.814930 13206 solver.cpp:341] Iteration 52500, Testing net (#0)
I0523 00:52:37.026221 13206 solver.cpp:409]     Test net output #0: accuracy = 0.884193
I0523 00:52:37.026392 13206 solver.cpp:409]     Test net output #1: loss = 0.370763 (* 1 = 0.370763 loss)
I0523 00:52:57.902056 13206 solver.cpp:237] Iteration 52500, loss = 1.06478
I0523 00:52:57.902114 13206 solver.cpp:253]     Train net output #0: loss = 1.06478 (* 1 = 1.06478 loss)
I0523 00:52:57.902130 13206 sgd_solver.cpp:106] Iteration 52500, lr = 0.005
I0523 00:53:07.708727 13206 solver.cpp:237] Iteration 52875, loss = 1.18862
I0523 00:53:07.708884 13206 solver.cpp:253]     Train net output #0: loss = 1.18862 (* 1 = 1.18862 loss)
I0523 00:53:07.708899 13206 sgd_solver.cpp:106] Iteration 52875, lr = 0.005
I0523 00:53:17.511365 13206 solver.cpp:237] Iteration 53250, loss = 1.40155
I0523 00:53:17.511400 13206 solver.cpp:253]     Train net output #0: loss = 1.40155 (* 1 = 1.40155 loss)
I0523 00:53:17.511416 13206 sgd_solver.cpp:106] Iteration 53250, lr = 0.005
I0523 00:53:27.318117 13206 solver.cpp:237] Iteration 53625, loss = 1.40771
I0523 00:53:27.318163 13206 solver.cpp:253]     Train net output #0: loss = 1.40771 (* 1 = 1.40771 loss)
I0523 00:53:27.318181 13206 sgd_solver.cpp:106] Iteration 53625, lr = 0.005
I0523 00:53:37.125535 13206 solver.cpp:237] Iteration 54000, loss = 1.07214
I0523 00:53:37.125569 13206 solver.cpp:253]     Train net output #0: loss = 1.07214 (* 1 = 1.07214 loss)
I0523 00:53:37.125582 13206 sgd_solver.cpp:106] Iteration 54000, lr = 0.005
I0523 00:53:46.929796 13206 solver.cpp:237] Iteration 54375, loss = 1.09394
I0523 00:53:46.929978 13206 solver.cpp:253]     Train net output #0: loss = 1.09394 (* 1 = 1.09394 loss)
I0523 00:53:46.929992 13206 sgd_solver.cpp:106] Iteration 54375, lr = 0.005
I0523 00:53:56.734462 13206 solver.cpp:237] Iteration 54750, loss = 1.17874
I0523 00:53:56.734496 13206 solver.cpp:253]     Train net output #0: loss = 1.17874 (* 1 = 1.17874 loss)
I0523 00:53:56.734513 13206 sgd_solver.cpp:106] Iteration 54750, lr = 0.005
I0523 00:54:27.392443 13206 solver.cpp:237] Iteration 55125, loss = 1.26782
I0523 00:54:27.392627 13206 solver.cpp:253]     Train net output #0: loss = 1.26782 (* 1 = 1.26782 loss)
I0523 00:54:27.392642 13206 sgd_solver.cpp:106] Iteration 55125, lr = 0.005
I0523 00:54:37.201525 13206 solver.cpp:237] Iteration 55500, loss = 1.33938
I0523 00:54:37.201575 13206 solver.cpp:253]     Train net output #0: loss = 1.33938 (* 1 = 1.33938 loss)
I0523 00:54:37.201592 13206 sgd_solver.cpp:106] Iteration 55500, lr = 0.005
I0523 00:54:47.009690 13206 solver.cpp:237] Iteration 55875, loss = 0.986667
I0523 00:54:47.009732 13206 solver.cpp:253]     Train net output #0: loss = 0.986667 (* 1 = 0.986667 loss)
I0523 00:54:47.009748 13206 sgd_solver.cpp:106] Iteration 55875, lr = 0.005
I0523 00:54:56.791836 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_56250.caffemodel
I0523 00:54:56.849983 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_56250.solverstate
I0523 00:54:56.886456 13206 solver.cpp:237] Iteration 56250, loss = 1.04082
I0523 00:54:56.886507 13206 solver.cpp:253]     Train net output #0: loss = 1.04082 (* 1 = 1.04082 loss)
I0523 00:54:56.886526 13206 sgd_solver.cpp:106] Iteration 56250, lr = 0.005
I0523 00:55:06.694258 13206 solver.cpp:237] Iteration 56625, loss = 1.06261
I0523 00:55:06.694432 13206 solver.cpp:253]     Train net output #0: loss = 1.06261 (* 1 = 1.06261 loss)
I0523 00:55:06.694445 13206 sgd_solver.cpp:106] Iteration 56625, lr = 0.005
I0523 00:55:16.502364 13206 solver.cpp:237] Iteration 57000, loss = 1.21272
I0523 00:55:16.502399 13206 solver.cpp:253]     Train net output #0: loss = 1.21272 (* 1 = 1.21272 loss)
I0523 00:55:16.502418 13206 sgd_solver.cpp:106] Iteration 57000, lr = 0.005
I0523 00:55:26.304570 13206 solver.cpp:237] Iteration 57375, loss = 1.44875
I0523 00:55:26.304618 13206 solver.cpp:253]     Train net output #0: loss = 1.44875 (* 1 = 1.44875 loss)
I0523 00:55:26.304635 13206 sgd_solver.cpp:106] Iteration 57375, lr = 0.005
I0523 00:55:57.027333 13206 solver.cpp:237] Iteration 57750, loss = 1.12448
I0523 00:55:57.027514 13206 solver.cpp:253]     Train net output #0: loss = 1.12448 (* 1 = 1.12448 loss)
I0523 00:55:57.027529 13206 sgd_solver.cpp:106] Iteration 57750, lr = 0.005
I0523 00:56:06.825206 13206 solver.cpp:237] Iteration 58125, loss = 0.850525
I0523 00:56:06.825242 13206 solver.cpp:253]     Train net output #0: loss = 0.850526 (* 1 = 0.850526 loss)
I0523 00:56:06.825258 13206 sgd_solver.cpp:106] Iteration 58125, lr = 0.005
I0523 00:56:16.626158 13206 solver.cpp:237] Iteration 58500, loss = 1.03393
I0523 00:56:16.626210 13206 solver.cpp:253]     Train net output #0: loss = 1.03393 (* 1 = 1.03393 loss)
I0523 00:56:16.626227 13206 sgd_solver.cpp:106] Iteration 58500, lr = 0.005
I0523 00:56:26.428272 13206 solver.cpp:237] Iteration 58875, loss = 1.25278
I0523 00:56:26.428308 13206 solver.cpp:253]     Train net output #0: loss = 1.25278 (* 1 = 1.25278 loss)
I0523 00:56:26.428325 13206 sgd_solver.cpp:106] Iteration 58875, lr = 0.005
I0523 00:56:36.235641 13206 solver.cpp:237] Iteration 59250, loss = 1.14318
I0523 00:56:36.235793 13206 solver.cpp:253]     Train net output #0: loss = 1.14318 (* 1 = 1.14318 loss)
I0523 00:56:36.235806 13206 sgd_solver.cpp:106] Iteration 59250, lr = 0.005
I0523 00:56:46.042091 13206 solver.cpp:237] Iteration 59625, loss = 0.771314
I0523 00:56:46.042140 13206 solver.cpp:253]     Train net output #0: loss = 0.771315 (* 1 = 0.771315 loss)
I0523 00:56:46.042153 13206 sgd_solver.cpp:106] Iteration 59625, lr = 0.005
I0523 00:56:55.815273 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_60000.caffemodel
I0523 00:56:55.872484 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_60000.solverstate
I0523 00:56:55.898743 13206 solver.cpp:341] Iteration 60000, Testing net (#0)
I0523 00:58:05.226083 13206 solver.cpp:409]     Test net output #0: accuracy = 0.889293
I0523 00:58:05.226279 13206 solver.cpp:409]     Test net output #1: loss = 0.352058 (* 1 = 0.352058 loss)
I0523 00:58:26.104600 13206 solver.cpp:237] Iteration 60000, loss = 1.14219
I0523 00:58:26.104657 13206 solver.cpp:253]     Train net output #0: loss = 1.14219 (* 1 = 1.14219 loss)
I0523 00:58:26.104672 13206 sgd_solver.cpp:106] Iteration 60000, lr = 0.005
I0523 00:58:35.975381 13206 solver.cpp:237] Iteration 60375, loss = 1.1352
I0523 00:58:35.975540 13206 solver.cpp:253]     Train net output #0: loss = 1.1352 (* 1 = 1.1352 loss)
I0523 00:58:35.975554 13206 sgd_solver.cpp:106] Iteration 60375, lr = 0.005
I0523 00:58:45.841902 13206 solver.cpp:237] Iteration 60750, loss = 1.14517
I0523 00:58:45.841949 13206 solver.cpp:253]     Train net output #0: loss = 1.14517 (* 1 = 1.14517 loss)
I0523 00:58:45.841967 13206 sgd_solver.cpp:106] Iteration 60750, lr = 0.005
I0523 00:58:55.711323 13206 solver.cpp:237] Iteration 61125, loss = 1.05196
I0523 00:58:55.711357 13206 solver.cpp:253]     Train net output #0: loss = 1.05196 (* 1 = 1.05196 loss)
I0523 00:58:55.711374 13206 sgd_solver.cpp:106] Iteration 61125, lr = 0.005
I0523 00:59:05.579360 13206 solver.cpp:237] Iteration 61500, loss = 1.39328
I0523 00:59:05.579396 13206 solver.cpp:253]     Train net output #0: loss = 1.39328 (* 1 = 1.39328 loss)
I0523 00:59:05.579412 13206 sgd_solver.cpp:106] Iteration 61500, lr = 0.005
I0523 00:59:15.454537 13206 solver.cpp:237] Iteration 61875, loss = 1.13613
I0523 00:59:15.454704 13206 solver.cpp:253]     Train net output #0: loss = 1.13613 (* 1 = 1.13613 loss)
I0523 00:59:15.454716 13206 sgd_solver.cpp:106] Iteration 61875, lr = 0.005
I0523 00:59:25.326215 13206 solver.cpp:237] Iteration 62250, loss = 1.09988
I0523 00:59:25.326249 13206 solver.cpp:253]     Train net output #0: loss = 1.09988 (* 1 = 1.09988 loss)
I0523 00:59:25.326267 13206 sgd_solver.cpp:106] Iteration 62250, lr = 0.005
I0523 00:59:56.098098 13206 solver.cpp:237] Iteration 62625, loss = 1.31899
I0523 00:59:56.098278 13206 solver.cpp:253]     Train net output #0: loss = 1.31899 (* 1 = 1.31899 loss)
I0523 00:59:56.098294 13206 sgd_solver.cpp:106] Iteration 62625, lr = 0.005
I0523 01:00:05.979560 13206 solver.cpp:237] Iteration 63000, loss = 1.15688
I0523 01:00:05.979605 13206 solver.cpp:253]     Train net output #0: loss = 1.15688 (* 1 = 1.15688 loss)
I0523 01:00:05.979627 13206 sgd_solver.cpp:106] Iteration 63000, lr = 0.005
I0523 01:00:15.850677 13206 solver.cpp:237] Iteration 63375, loss = 1.22458
I0523 01:00:15.850713 13206 solver.cpp:253]     Train net output #0: loss = 1.22458 (* 1 = 1.22458 loss)
I0523 01:00:15.850731 13206 sgd_solver.cpp:106] Iteration 63375, lr = 0.005
I0523 01:00:25.701299 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_63750.caffemodel
I0523 01:00:25.758055 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_63750.solverstate
I0523 01:00:25.793459 13206 solver.cpp:237] Iteration 63750, loss = 1.07423
I0523 01:00:25.793505 13206 solver.cpp:253]     Train net output #0: loss = 1.07423 (* 1 = 1.07423 loss)
I0523 01:00:25.793522 13206 sgd_solver.cpp:106] Iteration 63750, lr = 0.005
I0523 01:00:35.667955 13206 solver.cpp:237] Iteration 64125, loss = 1.19314
I0523 01:00:35.668133 13206 solver.cpp:253]     Train net output #0: loss = 1.19314 (* 1 = 1.19314 loss)
I0523 01:00:35.668146 13206 sgd_solver.cpp:106] Iteration 64125, lr = 0.005
I0523 01:00:45.539147 13206 solver.cpp:237] Iteration 64500, loss = 1.10052
I0523 01:00:45.539182 13206 solver.cpp:253]     Train net output #0: loss = 1.10052 (* 1 = 1.10052 loss)
I0523 01:00:45.539199 13206 sgd_solver.cpp:106] Iteration 64500, lr = 0.005
I0523 01:00:55.413883 13206 solver.cpp:237] Iteration 64875, loss = 1.20434
I0523 01:00:55.413926 13206 solver.cpp:253]     Train net output #0: loss = 1.20434 (* 1 = 1.20434 loss)
I0523 01:00:55.413947 13206 sgd_solver.cpp:106] Iteration 64875, lr = 0.005
I0523 01:01:26.241160 13206 solver.cpp:237] Iteration 65250, loss = 1.04892
I0523 01:01:26.241343 13206 solver.cpp:253]     Train net output #0: loss = 1.04892 (* 1 = 1.04892 loss)
I0523 01:01:26.241358 13206 sgd_solver.cpp:106] Iteration 65250, lr = 0.005
I0523 01:01:36.107869 13206 solver.cpp:237] Iteration 65625, loss = 1.58626
I0523 01:01:36.107905 13206 solver.cpp:253]     Train net output #0: loss = 1.58626 (* 1 = 1.58626 loss)
I0523 01:01:36.107923 13206 sgd_solver.cpp:106] Iteration 65625, lr = 0.005
I0523 01:01:45.977375 13206 solver.cpp:237] Iteration 66000, loss = 1.35392
I0523 01:01:45.977427 13206 solver.cpp:253]     Train net output #0: loss = 1.35392 (* 1 = 1.35392 loss)
I0523 01:01:45.977444 13206 sgd_solver.cpp:106] Iteration 66000, lr = 0.005
I0523 01:01:55.848384 13206 solver.cpp:237] Iteration 66375, loss = 1.33855
I0523 01:01:55.848422 13206 solver.cpp:253]     Train net output #0: loss = 1.33855 (* 1 = 1.33855 loss)
I0523 01:01:55.848438 13206 sgd_solver.cpp:106] Iteration 66375, lr = 0.005
I0523 01:02:05.723836 13206 solver.cpp:237] Iteration 66750, loss = 0.855274
I0523 01:02:05.724010 13206 solver.cpp:253]     Train net output #0: loss = 0.855275 (* 1 = 0.855275 loss)
I0523 01:02:05.724025 13206 sgd_solver.cpp:106] Iteration 66750, lr = 0.005
I0523 01:02:15.600538 13206 solver.cpp:237] Iteration 67125, loss = 1.24688
I0523 01:02:15.600574 13206 solver.cpp:253]     Train net output #0: loss = 1.24688 (* 1 = 1.24688 loss)
I0523 01:02:15.600590 13206 sgd_solver.cpp:106] Iteration 67125, lr = 0.005
I0523 01:02:25.450884 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_67500.caffemodel
I0523 01:02:25.507365 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_67500.solverstate
I0523 01:02:25.533592 13206 solver.cpp:341] Iteration 67500, Testing net (#0)
I0523 01:03:14.083575 13206 solver.cpp:409]     Test net output #0: accuracy = 0.890487
I0523 01:03:14.083752 13206 solver.cpp:409]     Test net output #1: loss = 0.348098 (* 1 = 0.348098 loss)
I0523 01:03:34.947542 13206 solver.cpp:237] Iteration 67500, loss = 1.12734
I0523 01:03:34.947599 13206 solver.cpp:253]     Train net output #0: loss = 1.12734 (* 1 = 1.12734 loss)
I0523 01:03:34.947614 13206 sgd_solver.cpp:106] Iteration 67500, lr = 0.005
I0523 01:03:44.672436 13206 solver.cpp:237] Iteration 67875, loss = 1.24213
I0523 01:03:44.672613 13206 solver.cpp:253]     Train net output #0: loss = 1.24213 (* 1 = 1.24213 loss)
I0523 01:03:44.672627 13206 sgd_solver.cpp:106] Iteration 67875, lr = 0.005
I0523 01:03:54.405071 13206 solver.cpp:237] Iteration 68250, loss = 1.0239
I0523 01:03:54.405107 13206 solver.cpp:253]     Train net output #0: loss = 1.0239 (* 1 = 1.0239 loss)
I0523 01:03:54.405123 13206 sgd_solver.cpp:106] Iteration 68250, lr = 0.005
I0523 01:04:04.140585 13206 solver.cpp:237] Iteration 68625, loss = 0.917624
I0523 01:04:04.140621 13206 solver.cpp:253]     Train net output #0: loss = 0.917624 (* 1 = 0.917624 loss)
I0523 01:04:04.140637 13206 sgd_solver.cpp:106] Iteration 68625, lr = 0.005
I0523 01:04:13.873667 13206 solver.cpp:237] Iteration 69000, loss = 1.1297
I0523 01:04:13.873725 13206 solver.cpp:253]     Train net output #0: loss = 1.1297 (* 1 = 1.1297 loss)
I0523 01:04:13.873739 13206 sgd_solver.cpp:106] Iteration 69000, lr = 0.005
I0523 01:04:23.610708 13206 solver.cpp:237] Iteration 69375, loss = 1.04999
I0523 01:04:23.610877 13206 solver.cpp:253]     Train net output #0: loss = 1.04999 (* 1 = 1.04999 loss)
I0523 01:04:23.610891 13206 sgd_solver.cpp:106] Iteration 69375, lr = 0.005
I0523 01:04:33.341687 13206 solver.cpp:237] Iteration 69750, loss = 0.934278
I0523 01:04:33.341728 13206 solver.cpp:253]     Train net output #0: loss = 0.934278 (* 1 = 0.934278 loss)
I0523 01:04:33.341744 13206 sgd_solver.cpp:106] Iteration 69750, lr = 0.005
I0523 01:05:03.949395 13206 solver.cpp:237] Iteration 70125, loss = 1.31151
I0523 01:05:03.949584 13206 solver.cpp:253]     Train net output #0: loss = 1.31151 (* 1 = 1.31151 loss)
I0523 01:05:03.949599 13206 sgd_solver.cpp:106] Iteration 70125, lr = 0.005
I0523 01:05:13.679190 13206 solver.cpp:237] Iteration 70500, loss = 1.0547
I0523 01:05:13.679225 13206 solver.cpp:253]     Train net output #0: loss = 1.0547 (* 1 = 1.0547 loss)
I0523 01:05:13.679242 13206 sgd_solver.cpp:106] Iteration 70500, lr = 0.005
I0523 01:05:23.410845 13206 solver.cpp:237] Iteration 70875, loss = 1.26249
I0523 01:05:23.410879 13206 solver.cpp:253]     Train net output #0: loss = 1.26249 (* 1 = 1.26249 loss)
I0523 01:05:23.410895 13206 sgd_solver.cpp:106] Iteration 70875, lr = 0.005
I0523 01:05:33.111587 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_71250.caffemodel
I0523 01:05:33.169505 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_71250.solverstate
I0523 01:05:33.205922 13206 solver.cpp:237] Iteration 71250, loss = 1.08635
I0523 01:05:33.205972 13206 solver.cpp:253]     Train net output #0: loss = 1.08635 (* 1 = 1.08635 loss)
I0523 01:05:33.205991 13206 sgd_solver.cpp:106] Iteration 71250, lr = 0.005
I0523 01:05:42.934027 13206 solver.cpp:237] Iteration 71625, loss = 1.10467
I0523 01:05:42.934190 13206 solver.cpp:253]     Train net output #0: loss = 1.10467 (* 1 = 1.10467 loss)
I0523 01:05:42.934203 13206 sgd_solver.cpp:106] Iteration 71625, lr = 0.005
I0523 01:05:52.668644 13206 solver.cpp:237] Iteration 72000, loss = 1.43015
I0523 01:05:52.668700 13206 solver.cpp:253]     Train net output #0: loss = 1.43015 (* 1 = 1.43015 loss)
I0523 01:05:52.668718 13206 sgd_solver.cpp:106] Iteration 72000, lr = 0.005
I0523 01:06:02.395833 13206 solver.cpp:237] Iteration 72375, loss = 1.06046
I0523 01:06:02.395869 13206 solver.cpp:253]     Train net output #0: loss = 1.06046 (* 1 = 1.06046 loss)
I0523 01:06:02.395884 13206 sgd_solver.cpp:106] Iteration 72375, lr = 0.005
I0523 01:06:33.065883 13206 solver.cpp:237] Iteration 72750, loss = 1.00928
I0523 01:06:33.066071 13206 solver.cpp:253]     Train net output #0: loss = 1.00928 (* 1 = 1.00928 loss)
I0523 01:06:33.066087 13206 sgd_solver.cpp:106] Iteration 72750, lr = 0.005
I0523 01:06:42.789446 13206 solver.cpp:237] Iteration 73125, loss = 1.57131
I0523 01:06:42.789494 13206 solver.cpp:253]     Train net output #0: loss = 1.57131 (* 1 = 1.57131 loss)
I0523 01:06:42.789512 13206 sgd_solver.cpp:106] Iteration 73125, lr = 0.005
I0523 01:06:52.519193 13206 solver.cpp:237] Iteration 73500, loss = 1.49584
I0523 01:06:52.519229 13206 solver.cpp:253]     Train net output #0: loss = 1.49584 (* 1 = 1.49584 loss)
I0523 01:06:52.519245 13206 sgd_solver.cpp:106] Iteration 73500, lr = 0.005
I0523 01:07:02.241246 13206 solver.cpp:237] Iteration 73875, loss = 1.29287
I0523 01:07:02.241282 13206 solver.cpp:253]     Train net output #0: loss = 1.29287 (* 1 = 1.29287 loss)
I0523 01:07:02.241298 13206 sgd_solver.cpp:106] Iteration 73875, lr = 0.005
I0523 01:07:11.972494 13206 solver.cpp:237] Iteration 74250, loss = 1.02143
I0523 01:07:11.972678 13206 solver.cpp:253]     Train net output #0: loss = 1.02143 (* 1 = 1.02143 loss)
I0523 01:07:11.972692 13206 sgd_solver.cpp:106] Iteration 74250, lr = 0.005
I0523 01:07:21.697556 13206 solver.cpp:237] Iteration 74625, loss = 1.54588
I0523 01:07:21.697590 13206 solver.cpp:253]     Train net output #0: loss = 1.54588 (* 1 = 1.54588 loss)
I0523 01:07:21.697608 13206 sgd_solver.cpp:106] Iteration 74625, lr = 0.005
I0523 01:07:31.403163 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_75000.caffemodel
I0523 01:07:31.461235 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_75000.solverstate
I0523 01:07:31.489564 13206 solver.cpp:341] Iteration 75000, Testing net (#0)
I0523 01:08:40.903342 13206 solver.cpp:409]     Test net output #0: accuracy = 0.894307
I0523 01:08:40.903525 13206 solver.cpp:409]     Test net output #1: loss = 0.356962 (* 1 = 0.356962 loss)
I0523 01:09:01.817308 13206 solver.cpp:237] Iteration 75000, loss = 0.759905
I0523 01:09:01.817368 13206 solver.cpp:253]     Train net output #0: loss = 0.759905 (* 1 = 0.759905 loss)
I0523 01:09:01.817383 13206 sgd_solver.cpp:106] Iteration 75000, lr = 0.005
I0523 01:09:11.518690 13206 solver.cpp:237] Iteration 75375, loss = 1.17096
I0523 01:09:11.518863 13206 solver.cpp:253]     Train net output #0: loss = 1.17096 (* 1 = 1.17096 loss)
I0523 01:09:11.518877 13206 sgd_solver.cpp:106] Iteration 75375, lr = 0.005
I0523 01:09:21.216074 13206 solver.cpp:237] Iteration 75750, loss = 1.20478
I0523 01:09:21.216110 13206 solver.cpp:253]     Train net output #0: loss = 1.20478 (* 1 = 1.20478 loss)
I0523 01:09:21.216128 13206 sgd_solver.cpp:106] Iteration 75750, lr = 0.005
I0523 01:09:30.913693 13206 solver.cpp:237] Iteration 76125, loss = 1.17441
I0523 01:09:30.913734 13206 solver.cpp:253]     Train net output #0: loss = 1.17441 (* 1 = 1.17441 loss)
I0523 01:09:30.913750 13206 sgd_solver.cpp:106] Iteration 76125, lr = 0.005
I0523 01:09:40.618240 13206 solver.cpp:237] Iteration 76500, loss = 1.15253
I0523 01:09:40.618288 13206 solver.cpp:253]     Train net output #0: loss = 1.15253 (* 1 = 1.15253 loss)
I0523 01:09:40.618304 13206 sgd_solver.cpp:106] Iteration 76500, lr = 0.005
I0523 01:09:50.319370 13206 solver.cpp:237] Iteration 76875, loss = 1.07075
I0523 01:09:50.319526 13206 solver.cpp:253]     Train net output #0: loss = 1.07075 (* 1 = 1.07075 loss)
I0523 01:09:50.319540 13206 sgd_solver.cpp:106] Iteration 76875, lr = 0.005
I0523 01:10:00.017422 13206 solver.cpp:237] Iteration 77250, loss = 1.56928
I0523 01:10:00.017472 13206 solver.cpp:253]     Train net output #0: loss = 1.56928 (* 1 = 1.56928 loss)
I0523 01:10:00.017488 13206 sgd_solver.cpp:106] Iteration 77250, lr = 0.005
I0523 01:10:30.621755 13206 solver.cpp:237] Iteration 77625, loss = 1.21759
I0523 01:10:30.621935 13206 solver.cpp:253]     Train net output #0: loss = 1.21759 (* 1 = 1.21759 loss)
I0523 01:10:30.621950 13206 sgd_solver.cpp:106] Iteration 77625, lr = 0.005
I0523 01:10:40.316560 13206 solver.cpp:237] Iteration 78000, loss = 1.06656
I0523 01:10:40.316594 13206 solver.cpp:253]     Train net output #0: loss = 1.06656 (* 1 = 1.06656 loss)
I0523 01:10:40.316613 13206 sgd_solver.cpp:106] Iteration 78000, lr = 0.005
I0523 01:10:50.019038 13206 solver.cpp:237] Iteration 78375, loss = 1.38159
I0523 01:10:50.019083 13206 solver.cpp:253]     Train net output #0: loss = 1.38159 (* 1 = 1.38159 loss)
I0523 01:10:50.019099 13206 sgd_solver.cpp:106] Iteration 78375, lr = 0.005
I0523 01:10:59.692777 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_78750.caffemodel
I0523 01:10:59.749096 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_78750.solverstate
I0523 01:10:59.783346 13206 solver.cpp:237] Iteration 78750, loss = 0.864597
I0523 01:10:59.783396 13206 solver.cpp:253]     Train net output #0: loss = 0.864597 (* 1 = 0.864597 loss)
I0523 01:10:59.783411 13206 sgd_solver.cpp:106] Iteration 78750, lr = 0.005
I0523 01:11:09.481103 13206 solver.cpp:237] Iteration 79125, loss = 1.19254
I0523 01:11:09.481276 13206 solver.cpp:253]     Train net output #0: loss = 1.19254 (* 1 = 1.19254 loss)
I0523 01:11:09.481289 13206 sgd_solver.cpp:106] Iteration 79125, lr = 0.005
I0523 01:11:19.182431 13206 solver.cpp:237] Iteration 79500, loss = 1.0005
I0523 01:11:19.182481 13206 solver.cpp:253]     Train net output #0: loss = 1.0005 (* 1 = 1.0005 loss)
I0523 01:11:19.182497 13206 sgd_solver.cpp:106] Iteration 79500, lr = 0.005
I0523 01:11:28.881268 13206 solver.cpp:237] Iteration 79875, loss = 1.34896
I0523 01:11:28.881304 13206 solver.cpp:253]     Train net output #0: loss = 1.34896 (* 1 = 1.34896 loss)
I0523 01:11:28.881319 13206 sgd_solver.cpp:106] Iteration 79875, lr = 0.005
I0523 01:11:59.475111 13206 solver.cpp:237] Iteration 80250, loss = 1.25969
I0523 01:11:59.475296 13206 solver.cpp:253]     Train net output #0: loss = 1.25969 (* 1 = 1.25969 loss)
I0523 01:11:59.475311 13206 sgd_solver.cpp:106] Iteration 80250, lr = 0.005
I0523 01:12:09.172629 13206 solver.cpp:237] Iteration 80625, loss = 0.929479
I0523 01:12:09.172675 13206 solver.cpp:253]     Train net output #0: loss = 0.929479 (* 1 = 0.929479 loss)
I0523 01:12:09.172693 13206 sgd_solver.cpp:106] Iteration 80625, lr = 0.005
I0523 01:12:18.872251 13206 solver.cpp:237] Iteration 81000, loss = 1.48621
I0523 01:12:18.872287 13206 solver.cpp:253]     Train net output #0: loss = 1.48621 (* 1 = 1.48621 loss)
I0523 01:12:18.872304 13206 sgd_solver.cpp:106] Iteration 81000, lr = 0.005
I0523 01:12:28.575392 13206 solver.cpp:237] Iteration 81375, loss = 1.07704
I0523 01:12:28.575428 13206 solver.cpp:253]     Train net output #0: loss = 1.07704 (* 1 = 1.07704 loss)
I0523 01:12:28.575441 13206 sgd_solver.cpp:106] Iteration 81375, lr = 0.005
I0523 01:12:38.279592 13206 solver.cpp:237] Iteration 81750, loss = 1.09404
I0523 01:12:38.279750 13206 solver.cpp:253]     Train net output #0: loss = 1.09404 (* 1 = 1.09404 loss)
I0523 01:12:38.279764 13206 sgd_solver.cpp:106] Iteration 81750, lr = 0.005
I0523 01:12:47.970594 13206 solver.cpp:237] Iteration 82125, loss = 1.12806
I0523 01:12:47.970629 13206 solver.cpp:253]     Train net output #0: loss = 1.12806 (* 1 = 1.12806 loss)
I0523 01:12:47.970648 13206 sgd_solver.cpp:106] Iteration 82125, lr = 0.005
I0523 01:12:57.646452 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_82500.caffemodel
I0523 01:12:57.702942 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_82500.solverstate
I0523 01:12:57.729409 13206 solver.cpp:341] Iteration 82500, Testing net (#0)
I0523 01:13:45.963305 13206 solver.cpp:409]     Test net output #0: accuracy = 0.893227
I0523 01:13:45.963486 13206 solver.cpp:409]     Test net output #1: loss = 0.331881 (* 1 = 0.331881 loss)
I0523 01:14:06.873765 13206 solver.cpp:237] Iteration 82500, loss = 1.05805
I0523 01:14:06.873821 13206 solver.cpp:253]     Train net output #0: loss = 1.05805 (* 1 = 1.05805 loss)
I0523 01:14:06.873836 13206 sgd_solver.cpp:106] Iteration 82500, lr = 0.005
I0523 01:14:16.678568 13206 solver.cpp:237] Iteration 82875, loss = 0.856793
I0523 01:14:16.678741 13206 solver.cpp:253]     Train net output #0: loss = 0.856793 (* 1 = 0.856793 loss)
I0523 01:14:16.678755 13206 sgd_solver.cpp:106] Iteration 82875, lr = 0.005
I0523 01:14:26.486208 13206 solver.cpp:237] Iteration 83250, loss = 1.31232
I0523 01:14:26.486243 13206 solver.cpp:253]     Train net output #0: loss = 1.31232 (* 1 = 1.31232 loss)
I0523 01:14:26.486260 13206 sgd_solver.cpp:106] Iteration 83250, lr = 0.005
I0523 01:14:36.294633 13206 solver.cpp:237] Iteration 83625, loss = 1.54466
I0523 01:14:36.294682 13206 solver.cpp:253]     Train net output #0: loss = 1.54466 (* 1 = 1.54466 loss)
I0523 01:14:36.294701 13206 sgd_solver.cpp:106] Iteration 83625, lr = 0.005
I0523 01:14:46.108356 13206 solver.cpp:237] Iteration 84000, loss = 1.29525
I0523 01:14:46.108392 13206 solver.cpp:253]     Train net output #0: loss = 1.29525 (* 1 = 1.29525 loss)
I0523 01:14:46.108409 13206 sgd_solver.cpp:106] Iteration 84000, lr = 0.005
I0523 01:14:55.916471 13206 solver.cpp:237] Iteration 84375, loss = 1.19889
I0523 01:14:55.916640 13206 solver.cpp:253]     Train net output #0: loss = 1.19889 (* 1 = 1.19889 loss)
I0523 01:14:55.916653 13206 sgd_solver.cpp:106] Iteration 84375, lr = 0.005
I0523 01:15:05.724923 13206 solver.cpp:237] Iteration 84750, loss = 1.12019
I0523 01:15:05.724962 13206 solver.cpp:253]     Train net output #0: loss = 1.12019 (* 1 = 1.12019 loss)
I0523 01:15:05.724983 13206 sgd_solver.cpp:106] Iteration 84750, lr = 0.005
I0523 01:15:36.430949 13206 solver.cpp:237] Iteration 85125, loss = 1.10604
I0523 01:15:36.431136 13206 solver.cpp:253]     Train net output #0: loss = 1.10605 (* 1 = 1.10605 loss)
I0523 01:15:36.431151 13206 sgd_solver.cpp:106] Iteration 85125, lr = 0.005
I0523 01:15:46.241323 13206 solver.cpp:237] Iteration 85500, loss = 0.932626
I0523 01:15:46.241359 13206 solver.cpp:253]     Train net output #0: loss = 0.932627 (* 1 = 0.932627 loss)
I0523 01:15:46.241377 13206 sgd_solver.cpp:106] Iteration 85500, lr = 0.005
I0523 01:15:56.043112 13206 solver.cpp:237] Iteration 85875, loss = 1.04588
I0523 01:15:56.043151 13206 solver.cpp:253]     Train net output #0: loss = 1.04588 (* 1 = 1.04588 loss)
I0523 01:15:56.043171 13206 sgd_solver.cpp:106] Iteration 85875, lr = 0.005
I0523 01:16:05.823294 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_86250.caffemodel
I0523 01:16:05.879796 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_86250.solverstate
I0523 01:16:05.912832 13206 solver.cpp:237] Iteration 86250, loss = 1.22354
I0523 01:16:05.912874 13206 solver.cpp:253]     Train net output #0: loss = 1.22354 (* 1 = 1.22354 loss)
I0523 01:16:05.912892 13206 sgd_solver.cpp:106] Iteration 86250, lr = 0.005
I0523 01:16:15.723347 13206 solver.cpp:237] Iteration 86625, loss = 1.1127
I0523 01:16:15.723522 13206 solver.cpp:253]     Train net output #0: loss = 1.1127 (* 1 = 1.1127 loss)
I0523 01:16:15.723536 13206 sgd_solver.cpp:106] Iteration 86625, lr = 0.005
I0523 01:16:25.526530 13206 solver.cpp:237] Iteration 87000, loss = 0.998379
I0523 01:16:25.526566 13206 solver.cpp:253]     Train net output #0: loss = 0.99838 (* 1 = 0.99838 loss)
I0523 01:16:25.526582 13206 sgd_solver.cpp:106] Iteration 87000, lr = 0.005
I0523 01:16:35.337378 13206 solver.cpp:237] Iteration 87375, loss = 1.19669
I0523 01:16:35.337412 13206 solver.cpp:253]     Train net output #0: loss = 1.19669 (* 1 = 1.19669 loss)
I0523 01:16:35.337430 13206 sgd_solver.cpp:106] Iteration 87375, lr = 0.005
I0523 01:17:06.016108 13206 solver.cpp:237] Iteration 87750, loss = 1.22329
I0523 01:17:06.016291 13206 solver.cpp:253]     Train net output #0: loss = 1.22329 (* 1 = 1.22329 loss)
I0523 01:17:06.016307 13206 sgd_solver.cpp:106] Iteration 87750, lr = 0.005
I0523 01:17:15.827164 13206 solver.cpp:237] Iteration 88125, loss = 1.32985
I0523 01:17:15.827199 13206 solver.cpp:253]     Train net output #0: loss = 1.32985 (* 1 = 1.32985 loss)
I0523 01:17:15.827217 13206 sgd_solver.cpp:106] Iteration 88125, lr = 0.005
I0523 01:17:25.633024 13206 solver.cpp:237] Iteration 88500, loss = 1.23257
I0523 01:17:25.633060 13206 solver.cpp:253]     Train net output #0: loss = 1.23258 (* 1 = 1.23258 loss)
I0523 01:17:25.633076 13206 sgd_solver.cpp:106] Iteration 88500, lr = 0.005
I0523 01:17:35.443416 13206 solver.cpp:237] Iteration 88875, loss = 1.33439
I0523 01:17:35.443465 13206 solver.cpp:253]     Train net output #0: loss = 1.33439 (* 1 = 1.33439 loss)
I0523 01:17:35.443485 13206 sgd_solver.cpp:106] Iteration 88875, lr = 0.005
I0523 01:17:45.253100 13206 solver.cpp:237] Iteration 89250, loss = 1.13987
I0523 01:17:45.253268 13206 solver.cpp:253]     Train net output #0: loss = 1.13987 (* 1 = 1.13987 loss)
I0523 01:17:45.253281 13206 sgd_solver.cpp:106] Iteration 89250, lr = 0.005
I0523 01:17:55.063897 13206 solver.cpp:237] Iteration 89625, loss = 1.37809
I0523 01:17:55.063952 13206 solver.cpp:253]     Train net output #0: loss = 1.37809 (* 1 = 1.37809 loss)
I0523 01:17:55.063967 13206 sgd_solver.cpp:106] Iteration 89625, lr = 0.005
I0523 01:18:04.843597 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_90000.caffemodel
I0523 01:18:04.900490 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_90000.solverstate
I0523 01:18:04.926754 13206 solver.cpp:341] Iteration 90000, Testing net (#0)
I0523 01:19:14.326248 13206 solver.cpp:409]     Test net output #0: accuracy = 0.892793
I0523 01:19:14.326432 13206 solver.cpp:409]     Test net output #1: loss = 0.380121 (* 1 = 0.380121 loss)
I0523 01:19:35.205072 13206 solver.cpp:237] Iteration 90000, loss = 1.04616
I0523 01:19:35.205129 13206 solver.cpp:253]     Train net output #0: loss = 1.04616 (* 1 = 1.04616 loss)
I0523 01:19:35.205144 13206 sgd_solver.cpp:106] Iteration 90000, lr = 0.005
I0523 01:19:45.079911 13206 solver.cpp:237] Iteration 90375, loss = 0.960914
I0523 01:19:45.080077 13206 solver.cpp:253]     Train net output #0: loss = 0.960914 (* 1 = 0.960914 loss)
I0523 01:19:45.080092 13206 sgd_solver.cpp:106] Iteration 90375, lr = 0.005
I0523 01:19:54.950687 13206 solver.cpp:237] Iteration 90750, loss = 1.02094
I0523 01:19:54.950722 13206 solver.cpp:253]     Train net output #0: loss = 1.02094 (* 1 = 1.02094 loss)
I0523 01:19:54.950736 13206 sgd_solver.cpp:106] Iteration 90750, lr = 0.005
I0523 01:20:04.823827 13206 solver.cpp:237] Iteration 91125, loss = 0.991789
I0523 01:20:04.823874 13206 solver.cpp:253]     Train net output #0: loss = 0.991789 (* 1 = 0.991789 loss)
I0523 01:20:04.823890 13206 sgd_solver.cpp:106] Iteration 91125, lr = 0.005
I0523 01:20:14.698710 13206 solver.cpp:237] Iteration 91500, loss = 1.09191
I0523 01:20:14.698746 13206 solver.cpp:253]     Train net output #0: loss = 1.09191 (* 1 = 1.09191 loss)
I0523 01:20:14.698762 13206 sgd_solver.cpp:106] Iteration 91500, lr = 0.005
I0523 01:20:24.565716 13206 solver.cpp:237] Iteration 91875, loss = 1.20123
I0523 01:20:24.565891 13206 solver.cpp:253]     Train net output #0: loss = 1.20124 (* 1 = 1.20124 loss)
I0523 01:20:24.565906 13206 sgd_solver.cpp:106] Iteration 91875, lr = 0.005
I0523 01:20:34.436102 13206 solver.cpp:237] Iteration 92250, loss = 1.02466
I0523 01:20:34.436137 13206 solver.cpp:253]     Train net output #0: loss = 1.02466 (* 1 = 1.02466 loss)
I0523 01:20:34.436154 13206 sgd_solver.cpp:106] Iteration 92250, lr = 0.005
I0523 01:21:05.185335 13206 solver.cpp:237] Iteration 92625, loss = 1.27972
I0523 01:21:05.185523 13206 solver.cpp:253]     Train net output #0: loss = 1.27972 (* 1 = 1.27972 loss)
I0523 01:21:05.185539 13206 sgd_solver.cpp:106] Iteration 92625, lr = 0.005
I0523 01:21:15.054872 13206 solver.cpp:237] Iteration 93000, loss = 1.07928
I0523 01:21:15.054913 13206 solver.cpp:253]     Train net output #0: loss = 1.07928 (* 1 = 1.07928 loss)
I0523 01:21:15.054934 13206 sgd_solver.cpp:106] Iteration 93000, lr = 0.005
I0523 01:21:24.927908 13206 solver.cpp:237] Iteration 93375, loss = 1.17486
I0523 01:21:24.927947 13206 solver.cpp:253]     Train net output #0: loss = 1.17486 (* 1 = 1.17486 loss)
I0523 01:21:24.927963 13206 sgd_solver.cpp:106] Iteration 93375, lr = 0.005
I0523 01:21:34.779101 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_93750.caffemodel
I0523 01:21:34.837455 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_93750.solverstate
I0523 01:21:34.872776 13206 solver.cpp:237] Iteration 93750, loss = 1.17241
I0523 01:21:34.872830 13206 solver.cpp:253]     Train net output #0: loss = 1.17241 (* 1 = 1.17241 loss)
I0523 01:21:34.872844 13206 sgd_solver.cpp:106] Iteration 93750, lr = 0.005
I0523 01:21:44.740097 13206 solver.cpp:237] Iteration 94125, loss = 0.955779
I0523 01:21:44.740290 13206 solver.cpp:253]     Train net output #0: loss = 0.955779 (* 1 = 0.955779 loss)
I0523 01:21:44.740304 13206 sgd_solver.cpp:106] Iteration 94125, lr = 0.005
I0523 01:21:54.605326 13206 solver.cpp:237] Iteration 94500, loss = 1.15956
I0523 01:21:54.605362 13206 solver.cpp:253]     Train net output #0: loss = 1.15956 (* 1 = 1.15956 loss)
I0523 01:21:54.605378 13206 sgd_solver.cpp:106] Iteration 94500, lr = 0.005
I0523 01:22:04.471689 13206 solver.cpp:237] Iteration 94875, loss = 1.34615
I0523 01:22:04.471727 13206 solver.cpp:253]     Train net output #0: loss = 1.34615 (* 1 = 1.34615 loss)
I0523 01:22:04.471741 13206 sgd_solver.cpp:106] Iteration 94875, lr = 0.005
I0523 01:22:35.226842 13206 solver.cpp:237] Iteration 95250, loss = 1.32472
I0523 01:22:35.227030 13206 solver.cpp:253]     Train net output #0: loss = 1.32472 (* 1 = 1.32472 loss)
I0523 01:22:35.227046 13206 sgd_solver.cpp:106] Iteration 95250, lr = 0.005
I0523 01:22:45.104166 13206 solver.cpp:237] Iteration 95625, loss = 1.41477
I0523 01:22:45.104200 13206 solver.cpp:253]     Train net output #0: loss = 1.41477 (* 1 = 1.41477 loss)
I0523 01:22:45.104215 13206 sgd_solver.cpp:106] Iteration 95625, lr = 0.005
I0523 01:22:54.976279 13206 solver.cpp:237] Iteration 96000, loss = 1.13918
I0523 01:22:54.976328 13206 solver.cpp:253]     Train net output #0: loss = 1.13918 (* 1 = 1.13918 loss)
I0523 01:22:54.976347 13206 sgd_solver.cpp:106] Iteration 96000, lr = 0.005
I0523 01:23:04.851449 13206 solver.cpp:237] Iteration 96375, loss = 1.01973
I0523 01:23:04.851485 13206 solver.cpp:253]     Train net output #0: loss = 1.01973 (* 1 = 1.01973 loss)
I0523 01:23:04.851500 13206 sgd_solver.cpp:106] Iteration 96375, lr = 0.005
I0523 01:23:14.723368 13206 solver.cpp:237] Iteration 96750, loss = 1.39758
I0523 01:23:14.723529 13206 solver.cpp:253]     Train net output #0: loss = 1.39758 (* 1 = 1.39758 loss)
I0523 01:23:14.723542 13206 sgd_solver.cpp:106] Iteration 96750, lr = 0.005
I0523 01:23:24.600435 13206 solver.cpp:237] Iteration 97125, loss = 0.909018
I0523 01:23:24.600476 13206 solver.cpp:253]     Train net output #0: loss = 0.909019 (* 1 = 0.909019 loss)
I0523 01:23:24.600494 13206 sgd_solver.cpp:106] Iteration 97125, lr = 0.005
I0523 01:23:34.448110 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_97500.caffemodel
I0523 01:23:34.514315 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_97500.solverstate
I0523 01:23:34.540668 13206 solver.cpp:341] Iteration 97500, Testing net (#0)
I0523 01:24:23.069167 13206 solver.cpp:409]     Test net output #0: accuracy = 0.8944
I0523 01:24:23.069350 13206 solver.cpp:409]     Test net output #1: loss = 0.341301 (* 1 = 0.341301 loss)
I0523 01:24:43.957411 13206 solver.cpp:237] Iteration 97500, loss = 1.06876
I0523 01:24:43.957469 13206 solver.cpp:253]     Train net output #0: loss = 1.06876 (* 1 = 1.06876 loss)
I0523 01:24:43.957484 13206 sgd_solver.cpp:106] Iteration 97500, lr = 0.005
I0523 01:24:53.681892 13206 solver.cpp:237] Iteration 97875, loss = 1.20093
I0523 01:24:53.682071 13206 solver.cpp:253]     Train net output #0: loss = 1.20093 (* 1 = 1.20093 loss)
I0523 01:24:53.682085 13206 sgd_solver.cpp:106] Iteration 97875, lr = 0.005
I0523 01:25:03.406596 13206 solver.cpp:237] Iteration 98250, loss = 1.53698
I0523 01:25:03.406641 13206 solver.cpp:253]     Train net output #0: loss = 1.53698 (* 1 = 1.53698 loss)
I0523 01:25:03.406661 13206 sgd_solver.cpp:106] Iteration 98250, lr = 0.005
I0523 01:25:13.128648 13206 solver.cpp:237] Iteration 98625, loss = 1.28986
I0523 01:25:13.128684 13206 solver.cpp:253]     Train net output #0: loss = 1.28986 (* 1 = 1.28986 loss)
I0523 01:25:13.128700 13206 sgd_solver.cpp:106] Iteration 98625, lr = 0.005
I0523 01:25:22.844321 13206 solver.cpp:237] Iteration 99000, loss = 1.15768
I0523 01:25:22.844357 13206 solver.cpp:253]     Train net output #0: loss = 1.15768 (* 1 = 1.15768 loss)
I0523 01:25:22.844372 13206 sgd_solver.cpp:106] Iteration 99000, lr = 0.005
I0523 01:25:32.571985 13206 solver.cpp:237] Iteration 99375, loss = 1.26055
I0523 01:25:32.572160 13206 solver.cpp:253]     Train net output #0: loss = 1.26055 (* 1 = 1.26055 loss)
I0523 01:25:32.572173 13206 sgd_solver.cpp:106] Iteration 99375, lr = 0.005
I0523 01:25:42.295727 13206 solver.cpp:237] Iteration 99750, loss = 1.06182
I0523 01:25:42.295761 13206 solver.cpp:253]     Train net output #0: loss = 1.06182 (* 1 = 1.06182 loss)
I0523 01:25:42.295778 13206 sgd_solver.cpp:106] Iteration 99750, lr = 0.005
I0523 01:26:12.890964 13206 solver.cpp:237] Iteration 100125, loss = 0.994275
I0523 01:26:12.891155 13206 solver.cpp:253]     Train net output #0: loss = 0.994275 (* 1 = 0.994275 loss)
I0523 01:26:12.891170 13206 sgd_solver.cpp:106] Iteration 100125, lr = 0.005
I0523 01:26:22.619065 13206 solver.cpp:237] Iteration 100500, loss = 1.04188
I0523 01:26:22.619115 13206 solver.cpp:253]     Train net output #0: loss = 1.04188 (* 1 = 1.04188 loss)
I0523 01:26:22.619133 13206 sgd_solver.cpp:106] Iteration 100500, lr = 0.005
I0523 01:26:32.343732 13206 solver.cpp:237] Iteration 100875, loss = 1.13005
I0523 01:26:32.343770 13206 solver.cpp:253]     Train net output #0: loss = 1.13005 (* 1 = 1.13005 loss)
I0523 01:26:32.343783 13206 sgd_solver.cpp:106] Iteration 100875, lr = 0.005
I0523 01:26:42.053812 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_101250.caffemodel
I0523 01:26:42.109851 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_101250.solverstate
I0523 01:26:42.143692 13206 solver.cpp:237] Iteration 101250, loss = 1.06353
I0523 01:26:42.143743 13206 solver.cpp:253]     Train net output #0: loss = 1.06353 (* 1 = 1.06353 loss)
I0523 01:26:42.143756 13206 sgd_solver.cpp:106] Iteration 101250, lr = 0.005
I0523 01:26:51.866372 13206 solver.cpp:237] Iteration 101625, loss = 0.952404
I0523 01:26:51.866541 13206 solver.cpp:253]     Train net output #0: loss = 0.952404 (* 1 = 0.952404 loss)
I0523 01:26:51.866555 13206 sgd_solver.cpp:106] Iteration 101625, lr = 0.005
I0523 01:27:01.591078 13206 solver.cpp:237] Iteration 102000, loss = 1.12532
I0523 01:27:01.591114 13206 solver.cpp:253]     Train net output #0: loss = 1.12532 (* 1 = 1.12532 loss)
I0523 01:27:01.591131 13206 sgd_solver.cpp:106] Iteration 102000, lr = 0.005
I0523 01:27:11.319504 13206 solver.cpp:237] Iteration 102375, loss = 1.0626
I0523 01:27:11.319547 13206 solver.cpp:253]     Train net output #0: loss = 1.0626 (* 1 = 1.0626 loss)
I0523 01:27:11.319566 13206 sgd_solver.cpp:106] Iteration 102375, lr = 0.005
I0523 01:27:41.944972 13206 solver.cpp:237] Iteration 102750, loss = 0.910106
I0523 01:27:41.945171 13206 solver.cpp:253]     Train net output #0: loss = 0.910107 (* 1 = 0.910107 loss)
I0523 01:27:41.945188 13206 sgd_solver.cpp:106] Iteration 102750, lr = 0.005
I0523 01:27:51.665377 13206 solver.cpp:237] Iteration 103125, loss = 1.33117
I0523 01:27:51.665412 13206 solver.cpp:253]     Train net output #0: loss = 1.33117 (* 1 = 1.33117 loss)
I0523 01:27:51.665431 13206 sgd_solver.cpp:106] Iteration 103125, lr = 0.005
I0523 01:28:01.395511 13206 solver.cpp:237] Iteration 103500, loss = 1.03521
I0523 01:28:01.395553 13206 solver.cpp:253]     Train net output #0: loss = 1.03521 (* 1 = 1.03521 loss)
I0523 01:28:01.395575 13206 sgd_solver.cpp:106] Iteration 103500, lr = 0.005
I0523 01:28:11.120225 13206 solver.cpp:237] Iteration 103875, loss = 1.03256
I0523 01:28:11.120261 13206 solver.cpp:253]     Train net output #0: loss = 1.03256 (* 1 = 1.03256 loss)
I0523 01:28:11.120278 13206 sgd_solver.cpp:106] Iteration 103875, lr = 0.005
I0523 01:28:20.843291 13206 solver.cpp:237] Iteration 104250, loss = 1.0087
I0523 01:28:20.843477 13206 solver.cpp:253]     Train net output #0: loss = 1.0087 (* 1 = 1.0087 loss)
I0523 01:28:20.843492 13206 sgd_solver.cpp:106] Iteration 104250, lr = 0.005
I0523 01:28:30.572387 13206 solver.cpp:237] Iteration 104625, loss = 0.968911
I0523 01:28:30.572422 13206 solver.cpp:253]     Train net output #0: loss = 0.968911 (* 1 = 0.968911 loss)
I0523 01:28:30.572438 13206 sgd_solver.cpp:106] Iteration 104625, lr = 0.005
I0523 01:28:40.274780 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_105000.caffemodel
I0523 01:28:40.330564 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_105000.solverstate
I0523 01:28:40.355614 13206 solver.cpp:341] Iteration 105000, Testing net (#0)
I0523 01:29:49.757608 13206 solver.cpp:409]     Test net output #0: accuracy = 0.895053
I0523 01:29:49.757805 13206 solver.cpp:409]     Test net output #1: loss = 0.325878 (* 1 = 0.325878 loss)
I0523 01:30:10.658388 13206 solver.cpp:237] Iteration 105000, loss = 1.44474
I0523 01:30:10.658445 13206 solver.cpp:253]     Train net output #0: loss = 1.44474 (* 1 = 1.44474 loss)
I0523 01:30:10.658460 13206 sgd_solver.cpp:106] Iteration 105000, lr = 0.005
I0523 01:30:20.358309 13206 solver.cpp:237] Iteration 105375, loss = 1.24674
I0523 01:30:20.358479 13206 solver.cpp:253]     Train net output #0: loss = 1.24674 (* 1 = 1.24674 loss)
I0523 01:30:20.358492 13206 sgd_solver.cpp:106] Iteration 105375, lr = 0.005
I0523 01:30:30.058869 13206 solver.cpp:237] Iteration 105750, loss = 0.999775
I0523 01:30:30.058912 13206 solver.cpp:253]     Train net output #0: loss = 0.999776 (* 1 = 0.999776 loss)
I0523 01:30:30.058933 13206 sgd_solver.cpp:106] Iteration 105750, lr = 0.005
I0523 01:30:39.755096 13206 solver.cpp:237] Iteration 106125, loss = 0.959138
I0523 01:30:39.755133 13206 solver.cpp:253]     Train net output #0: loss = 0.959138 (* 1 = 0.959138 loss)
I0523 01:30:39.755148 13206 sgd_solver.cpp:106] Iteration 106125, lr = 0.005
I0523 01:30:49.459350 13206 solver.cpp:237] Iteration 106500, loss = 1.15805
I0523 01:30:49.459396 13206 solver.cpp:253]     Train net output #0: loss = 1.15805 (* 1 = 1.15805 loss)
I0523 01:30:49.459410 13206 sgd_solver.cpp:106] Iteration 106500, lr = 0.005
I0523 01:30:59.164258 13206 solver.cpp:237] Iteration 106875, loss = 1.00271
I0523 01:30:59.164422 13206 solver.cpp:253]     Train net output #0: loss = 1.00271 (* 1 = 1.00271 loss)
I0523 01:30:59.164436 13206 sgd_solver.cpp:106] Iteration 106875, lr = 0.005
I0523 01:31:08.857738 13206 solver.cpp:237] Iteration 107250, loss = 0.770264
I0523 01:31:08.857774 13206 solver.cpp:253]     Train net output #0: loss = 0.770265 (* 1 = 0.770265 loss)
I0523 01:31:08.857791 13206 sgd_solver.cpp:106] Iteration 107250, lr = 0.005
I0523 01:31:39.435047 13206 solver.cpp:237] Iteration 107625, loss = 0.799737
I0523 01:31:39.435241 13206 solver.cpp:253]     Train net output #0: loss = 0.799737 (* 1 = 0.799737 loss)
I0523 01:31:39.435256 13206 sgd_solver.cpp:106] Iteration 107625, lr = 0.005
I0523 01:31:49.139009 13206 solver.cpp:237] Iteration 108000, loss = 1.53708
I0523 01:31:49.139045 13206 solver.cpp:253]     Train net output #0: loss = 1.53708 (* 1 = 1.53708 loss)
I0523 01:31:49.139063 13206 sgd_solver.cpp:106] Iteration 108000, lr = 0.005
I0523 01:31:58.837435 13206 solver.cpp:237] Iteration 108375, loss = 1.22141
I0523 01:31:58.837472 13206 solver.cpp:253]     Train net output #0: loss = 1.22141 (* 1 = 1.22141 loss)
I0523 01:31:58.837488 13206 sgd_solver.cpp:106] Iteration 108375, lr = 0.005
I0523 01:32:08.508132 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_108750.caffemodel
I0523 01:32:08.566485 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_108750.solverstate
I0523 01:32:08.601940 13206 solver.cpp:237] Iteration 108750, loss = 1.201
I0523 01:32:08.601990 13206 solver.cpp:253]     Train net output #0: loss = 1.201 (* 1 = 1.201 loss)
I0523 01:32:08.602007 13206 sgd_solver.cpp:106] Iteration 108750, lr = 0.005
I0523 01:32:18.302175 13206 solver.cpp:237] Iteration 109125, loss = 1.0949
I0523 01:32:18.302345 13206 solver.cpp:253]     Train net output #0: loss = 1.0949 (* 1 = 1.0949 loss)
I0523 01:32:18.302358 13206 sgd_solver.cpp:106] Iteration 109125, lr = 0.005
I0523 01:32:28.004303 13206 solver.cpp:237] Iteration 109500, loss = 1.57359
I0523 01:32:28.004339 13206 solver.cpp:253]     Train net output #0: loss = 1.57359 (* 1 = 1.57359 loss)
I0523 01:32:28.004355 13206 sgd_solver.cpp:106] Iteration 109500, lr = 0.005
I0523 01:32:37.703307 13206 solver.cpp:237] Iteration 109875, loss = 1.04075
I0523 01:32:37.703357 13206 solver.cpp:253]     Train net output #0: loss = 1.04075 (* 1 = 1.04075 loss)
I0523 01:32:37.703375 13206 sgd_solver.cpp:106] Iteration 109875, lr = 0.005
I0523 01:33:08.295342 13206 solver.cpp:237] Iteration 110250, loss = 0.980022
I0523 01:33:08.295533 13206 solver.cpp:253]     Train net output #0: loss = 0.980022 (* 1 = 0.980022 loss)
I0523 01:33:08.295548 13206 sgd_solver.cpp:106] Iteration 110250, lr = 0.005
I0523 01:33:17.995873 13206 solver.cpp:237] Iteration 110625, loss = 1.73386
I0523 01:33:17.995908 13206 solver.cpp:253]     Train net output #0: loss = 1.73386 (* 1 = 1.73386 loss)
I0523 01:33:17.995925 13206 sgd_solver.cpp:106] Iteration 110625, lr = 0.005
I0523 01:33:27.695785 13206 solver.cpp:237] Iteration 111000, loss = 1.11653
I0523 01:33:27.695832 13206 solver.cpp:253]     Train net output #0: loss = 1.11653 (* 1 = 1.11653 loss)
I0523 01:33:27.695850 13206 sgd_solver.cpp:106] Iteration 111000, lr = 0.005
I0523 01:33:37.397320 13206 solver.cpp:237] Iteration 111375, loss = 1.18236
I0523 01:33:37.397356 13206 solver.cpp:253]     Train net output #0: loss = 1.18237 (* 1 = 1.18237 loss)
I0523 01:33:37.397372 13206 sgd_solver.cpp:106] Iteration 111375, lr = 0.005
I0523 01:33:47.098222 13206 solver.cpp:237] Iteration 111750, loss = 1.43139
I0523 01:33:47.098402 13206 solver.cpp:253]     Train net output #0: loss = 1.43139 (* 1 = 1.43139 loss)
I0523 01:33:47.098414 13206 sgd_solver.cpp:106] Iteration 111750, lr = 0.005
I0523 01:33:56.797034 13206 solver.cpp:237] Iteration 112125, loss = 1.36644
I0523 01:33:56.797068 13206 solver.cpp:253]     Train net output #0: loss = 1.36644 (* 1 = 1.36644 loss)
I0523 01:33:56.797085 13206 sgd_solver.cpp:106] Iteration 112125, lr = 0.005
I0523 01:34:06.473513 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_112500.caffemodel
I0523 01:34:06.532047 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_112500.solverstate
I0523 01:34:06.559298 13206 solver.cpp:341] Iteration 112500, Testing net (#0)
I0523 01:34:54.745353 13206 solver.cpp:409]     Test net output #0: accuracy = 0.896932
I0523 01:34:54.745555 13206 solver.cpp:409]     Test net output #1: loss = 0.354406 (* 1 = 0.354406 loss)
I0523 01:35:15.642293 13206 solver.cpp:237] Iteration 112500, loss = 1.2163
I0523 01:35:15.642345 13206 solver.cpp:253]     Train net output #0: loss = 1.2163 (* 1 = 1.2163 loss)
I0523 01:35:15.642361 13206 sgd_solver.cpp:106] Iteration 112500, lr = 0.005
I0523 01:35:25.440433 13206 solver.cpp:237] Iteration 112875, loss = 1.1107
I0523 01:35:25.440613 13206 solver.cpp:253]     Train net output #0: loss = 1.1107 (* 1 = 1.1107 loss)
I0523 01:35:25.440628 13206 sgd_solver.cpp:106] Iteration 112875, lr = 0.005
I0523 01:35:35.239035 13206 solver.cpp:237] Iteration 113250, loss = 1.36472
I0523 01:35:35.239069 13206 solver.cpp:253]     Train net output #0: loss = 1.36472 (* 1 = 1.36472 loss)
I0523 01:35:35.239089 13206 sgd_solver.cpp:106] Iteration 113250, lr = 0.005
I0523 01:35:45.048895 13206 solver.cpp:237] Iteration 113625, loss = 1.2116
I0523 01:35:45.048930 13206 solver.cpp:253]     Train net output #0: loss = 1.2116 (* 1 = 1.2116 loss)
I0523 01:35:45.048946 13206 sgd_solver.cpp:106] Iteration 113625, lr = 0.005
I0523 01:35:54.848630 13206 solver.cpp:237] Iteration 114000, loss = 1.21023
I0523 01:35:54.848675 13206 solver.cpp:253]     Train net output #0: loss = 1.21023 (* 1 = 1.21023 loss)
I0523 01:35:54.848695 13206 sgd_solver.cpp:106] Iteration 114000, lr = 0.005
I0523 01:36:04.654407 13206 solver.cpp:237] Iteration 114375, loss = 1.02982
I0523 01:36:04.654574 13206 solver.cpp:253]     Train net output #0: loss = 1.02982 (* 1 = 1.02982 loss)
I0523 01:36:04.654588 13206 sgd_solver.cpp:106] Iteration 114375, lr = 0.005
I0523 01:36:14.459378 13206 solver.cpp:237] Iteration 114750, loss = 1.19706
I0523 01:36:14.459429 13206 solver.cpp:253]     Train net output #0: loss = 1.19706 (* 1 = 1.19706 loss)
I0523 01:36:14.459441 13206 sgd_solver.cpp:106] Iteration 114750, lr = 0.005
I0523 01:36:45.145710 13206 solver.cpp:237] Iteration 115125, loss = 1.11732
I0523 01:36:45.146018 13206 solver.cpp:253]     Train net output #0: loss = 1.11732 (* 1 = 1.11732 loss)
I0523 01:36:45.146034 13206 sgd_solver.cpp:106] Iteration 115125, lr = 0.005
I0523 01:36:54.949520 13206 solver.cpp:237] Iteration 115500, loss = 0.780624
I0523 01:36:54.949558 13206 solver.cpp:253]     Train net output #0: loss = 0.780624 (* 1 = 0.780624 loss)
I0523 01:36:54.949573 13206 sgd_solver.cpp:106] Iteration 115500, lr = 0.005
I0523 01:37:04.750960 13206 solver.cpp:237] Iteration 115875, loss = 1.67884
I0523 01:37:04.751013 13206 solver.cpp:253]     Train net output #0: loss = 1.67884 (* 1 = 1.67884 loss)
I0523 01:37:04.751031 13206 sgd_solver.cpp:106] Iteration 115875, lr = 0.005
I0523 01:37:14.528187 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_116250.caffemodel
I0523 01:37:14.583582 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_116250.solverstate
I0523 01:37:14.616914 13206 solver.cpp:237] Iteration 116250, loss = 1.29802
I0523 01:37:14.616958 13206 solver.cpp:253]     Train net output #0: loss = 1.29802 (* 1 = 1.29802 loss)
I0523 01:37:14.616973 13206 sgd_solver.cpp:106] Iteration 116250, lr = 0.005
I0523 01:37:24.413103 13206 solver.cpp:237] Iteration 116625, loss = 1.08833
I0523 01:37:24.413275 13206 solver.cpp:253]     Train net output #0: loss = 1.08833 (* 1 = 1.08833 loss)
I0523 01:37:24.413288 13206 sgd_solver.cpp:106] Iteration 116625, lr = 0.005
I0523 01:37:34.212182 13206 solver.cpp:237] Iteration 117000, loss = 1.33359
I0523 01:37:34.212227 13206 solver.cpp:253]     Train net output #0: loss = 1.33359 (* 1 = 1.33359 loss)
I0523 01:37:34.212247 13206 sgd_solver.cpp:106] Iteration 117000, lr = 0.005
I0523 01:37:44.017091 13206 solver.cpp:237] Iteration 117375, loss = 1.11251
I0523 01:37:44.017127 13206 solver.cpp:253]     Train net output #0: loss = 1.11251 (* 1 = 1.11251 loss)
I0523 01:37:44.017143 13206 sgd_solver.cpp:106] Iteration 117375, lr = 0.005
I0523 01:38:14.675328 13206 solver.cpp:237] Iteration 117750, loss = 0.961255
I0523 01:38:14.675532 13206 solver.cpp:253]     Train net output #0: loss = 0.961255 (* 1 = 0.961255 loss)
I0523 01:38:14.675547 13206 sgd_solver.cpp:106] Iteration 117750, lr = 0.005
I0523 01:38:24.478431 13206 solver.cpp:237] Iteration 118125, loss = 0.968659
I0523 01:38:24.478476 13206 solver.cpp:253]     Train net output #0: loss = 0.968659 (* 1 = 0.968659 loss)
I0523 01:38:24.478495 13206 sgd_solver.cpp:106] Iteration 118125, lr = 0.005
I0523 01:38:34.282593 13206 solver.cpp:237] Iteration 118500, loss = 1.09065
I0523 01:38:34.282629 13206 solver.cpp:253]     Train net output #0: loss = 1.09065 (* 1 = 1.09065 loss)
I0523 01:38:34.282646 13206 sgd_solver.cpp:106] Iteration 118500, lr = 0.005
I0523 01:38:44.084878 13206 solver.cpp:237] Iteration 118875, loss = 1.16579
I0523 01:38:44.084914 13206 solver.cpp:253]     Train net output #0: loss = 1.16579 (* 1 = 1.16579 loss)
I0523 01:38:44.084930 13206 sgd_solver.cpp:106] Iteration 118875, lr = 0.005
I0523 01:38:53.891496 13206 solver.cpp:237] Iteration 119250, loss = 0.933731
I0523 01:38:53.891675 13206 solver.cpp:253]     Train net output #0: loss = 0.933731 (* 1 = 0.933731 loss)
I0523 01:38:53.891690 13206 sgd_solver.cpp:106] Iteration 119250, lr = 0.005
I0523 01:39:03.691539 13206 solver.cpp:237] Iteration 119625, loss = 1.3079
I0523 01:39:03.691573 13206 solver.cpp:253]     Train net output #0: loss = 1.3079 (* 1 = 1.3079 loss)
I0523 01:39:03.691589 13206 sgd_solver.cpp:106] Iteration 119625, lr = 0.005
I0523 01:39:13.467574 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_120000.caffemodel
I0523 01:39:13.523036 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_120000.solverstate
I0523 01:39:13.547976 13206 solver.cpp:341] Iteration 120000, Testing net (#0)
I0523 01:40:22.989006 13206 solver.cpp:409]     Test net output #0: accuracy = 0.89738
I0523 01:40:22.989199 13206 solver.cpp:409]     Test net output #1: loss = 0.330661 (* 1 = 0.330661 loss)
I0523 01:40:43.888254 13206 solver.cpp:237] Iteration 120000, loss = 1.18014
I0523 01:40:43.888310 13206 solver.cpp:253]     Train net output #0: loss = 1.18014 (* 1 = 1.18014 loss)
I0523 01:40:43.888327 13206 sgd_solver.cpp:106] Iteration 120000, lr = 0.005
I0523 01:40:53.758245 13206 solver.cpp:237] Iteration 120375, loss = 1.16901
I0523 01:40:53.758425 13206 solver.cpp:253]     Train net output #0: loss = 1.16901 (* 1 = 1.16901 loss)
I0523 01:40:53.758440 13206 sgd_solver.cpp:106] Iteration 120375, lr = 0.005
I0523 01:41:03.625782 13206 solver.cpp:237] Iteration 120750, loss = 1.06071
I0523 01:41:03.625818 13206 solver.cpp:253]     Train net output #0: loss = 1.06071 (* 1 = 1.06071 loss)
I0523 01:41:03.625835 13206 sgd_solver.cpp:106] Iteration 120750, lr = 0.005
I0523 01:41:13.490381 13206 solver.cpp:237] Iteration 121125, loss = 1.34776
I0523 01:41:13.490417 13206 solver.cpp:253]     Train net output #0: loss = 1.34776 (* 1 = 1.34776 loss)
I0523 01:41:13.490433 13206 sgd_solver.cpp:106] Iteration 121125, lr = 0.005
I0523 01:41:23.357846 13206 solver.cpp:237] Iteration 121500, loss = 1.14617
I0523 01:41:23.357885 13206 solver.cpp:253]     Train net output #0: loss = 1.14617 (* 1 = 1.14617 loss)
I0523 01:41:23.357909 13206 sgd_solver.cpp:106] Iteration 121500, lr = 0.005
I0523 01:41:33.227805 13206 solver.cpp:237] Iteration 121875, loss = 1.20175
I0523 01:41:33.227970 13206 solver.cpp:253]     Train net output #0: loss = 1.20175 (* 1 = 1.20175 loss)
I0523 01:41:33.227983 13206 sgd_solver.cpp:106] Iteration 121875, lr = 0.005
I0523 01:41:43.087307 13206 solver.cpp:237] Iteration 122250, loss = 1.3276
I0523 01:41:43.087352 13206 solver.cpp:253]     Train net output #0: loss = 1.3276 (* 1 = 1.3276 loss)
I0523 01:41:43.087373 13206 sgd_solver.cpp:106] Iteration 122250, lr = 0.005
I0523 01:42:13.837312 13206 solver.cpp:237] Iteration 122625, loss = 1.16266
I0523 01:42:13.837517 13206 solver.cpp:253]     Train net output #0: loss = 1.16266 (* 1 = 1.16266 loss)
I0523 01:42:13.837532 13206 sgd_solver.cpp:106] Iteration 122625, lr = 0.005
I0523 01:42:23.697295 13206 solver.cpp:237] Iteration 123000, loss = 1.02789
I0523 01:42:23.697330 13206 solver.cpp:253]     Train net output #0: loss = 1.02789 (* 1 = 1.02789 loss)
I0523 01:42:23.697348 13206 sgd_solver.cpp:106] Iteration 123000, lr = 0.005
I0523 01:42:33.559530 13206 solver.cpp:237] Iteration 123375, loss = 1.10419
I0523 01:42:33.559583 13206 solver.cpp:253]     Train net output #0: loss = 1.10419 (* 1 = 1.10419 loss)
I0523 01:42:33.559602 13206 sgd_solver.cpp:106] Iteration 123375, lr = 0.005
I0523 01:42:43.400892 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_123750.caffemodel
I0523 01:42:43.457576 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_123750.solverstate
I0523 01:42:43.491421 13206 solver.cpp:237] Iteration 123750, loss = 1.1972
I0523 01:42:43.491468 13206 solver.cpp:253]     Train net output #0: loss = 1.1972 (* 1 = 1.1972 loss)
I0523 01:42:43.491482 13206 sgd_solver.cpp:106] Iteration 123750, lr = 0.005
I0523 01:42:53.362201 13206 solver.cpp:237] Iteration 124125, loss = 0.950064
I0523 01:42:53.362376 13206 solver.cpp:253]     Train net output #0: loss = 0.950064 (* 1 = 0.950064 loss)
I0523 01:42:53.362390 13206 sgd_solver.cpp:106] Iteration 124125, lr = 0.005
I0523 01:43:03.228714 13206 solver.cpp:237] Iteration 124500, loss = 1.04448
I0523 01:43:03.228757 13206 solver.cpp:253]     Train net output #0: loss = 1.04448 (* 1 = 1.04448 loss)
I0523 01:43:03.228775 13206 sgd_solver.cpp:106] Iteration 124500, lr = 0.005
I0523 01:43:13.094945 13206 solver.cpp:237] Iteration 124875, loss = 1.23136
I0523 01:43:13.094981 13206 solver.cpp:253]     Train net output #0: loss = 1.23136 (* 1 = 1.23136 loss)
I0523 01:43:13.094997 13206 sgd_solver.cpp:106] Iteration 124875, lr = 0.005
I0523 01:43:43.868008 13206 solver.cpp:237] Iteration 125250, loss = 1.05176
I0523 01:43:43.868206 13206 solver.cpp:253]     Train net output #0: loss = 1.05176 (* 1 = 1.05176 loss)
I0523 01:43:43.868221 13206 sgd_solver.cpp:106] Iteration 125250, lr = 0.005
I0523 01:43:53.730695 13206 solver.cpp:237] Iteration 125625, loss = 1.07242
I0523 01:43:53.730728 13206 solver.cpp:253]     Train net output #0: loss = 1.07242 (* 1 = 1.07242 loss)
I0523 01:43:53.730746 13206 sgd_solver.cpp:106] Iteration 125625, lr = 0.005
I0523 01:44:03.595594 13206 solver.cpp:237] Iteration 126000, loss = 1.27699
I0523 01:44:03.595630 13206 solver.cpp:253]     Train net output #0: loss = 1.27699 (* 1 = 1.27699 loss)
I0523 01:44:03.595649 13206 sgd_solver.cpp:106] Iteration 126000, lr = 0.005
I0523 01:44:13.461189 13206 solver.cpp:237] Iteration 126375, loss = 0.96225
I0523 01:44:13.461233 13206 solver.cpp:253]     Train net output #0: loss = 0.96225 (* 1 = 0.96225 loss)
I0523 01:44:13.461253 13206 sgd_solver.cpp:106] Iteration 126375, lr = 0.005
I0523 01:44:23.331492 13206 solver.cpp:237] Iteration 126750, loss = 1.21708
I0523 01:44:23.331660 13206 solver.cpp:253]     Train net output #0: loss = 1.21708 (* 1 = 1.21708 loss)
I0523 01:44:23.331673 13206 sgd_solver.cpp:106] Iteration 126750, lr = 0.005
I0523 01:44:33.195847 13206 solver.cpp:237] Iteration 127125, loss = 1.28639
I0523 01:44:33.195878 13206 solver.cpp:253]     Train net output #0: loss = 1.28639 (* 1 = 1.28639 loss)
I0523 01:44:33.195891 13206 sgd_solver.cpp:106] Iteration 127125, lr = 0.005
I0523 01:44:43.045685 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_127500.caffemodel
I0523 01:44:43.102922 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_127500.solverstate
I0523 01:44:43.128046 13206 solver.cpp:341] Iteration 127500, Testing net (#0)
I0523 01:45:31.678887 13206 solver.cpp:409]     Test net output #0: accuracy = 0.896987
I0523 01:45:31.679090 13206 solver.cpp:409]     Test net output #1: loss = 0.352825 (* 1 = 0.352825 loss)
I0523 01:45:52.545076 13206 solver.cpp:237] Iteration 127500, loss = 1.29507
I0523 01:45:52.545133 13206 solver.cpp:253]     Train net output #0: loss = 1.29507 (* 1 = 1.29507 loss)
I0523 01:45:52.545148 13206 sgd_solver.cpp:106] Iteration 127500, lr = 0.005
I0523 01:46:02.265002 13206 solver.cpp:237] Iteration 127875, loss = 1.07494
I0523 01:46:02.265188 13206 solver.cpp:253]     Train net output #0: loss = 1.07494 (* 1 = 1.07494 loss)
I0523 01:46:02.265202 13206 sgd_solver.cpp:106] Iteration 127875, lr = 0.005
I0523 01:46:11.992117 13206 solver.cpp:237] Iteration 128250, loss = 1.16368
I0523 01:46:11.992151 13206 solver.cpp:253]     Train net output #0: loss = 1.16368 (* 1 = 1.16368 loss)
I0523 01:46:11.992166 13206 sgd_solver.cpp:106] Iteration 128250, lr = 0.005
I0523 01:46:21.717670 13206 solver.cpp:237] Iteration 128625, loss = 0.9281
I0523 01:46:21.717725 13206 solver.cpp:253]     Train net output #0: loss = 0.9281 (* 1 = 0.9281 loss)
I0523 01:46:21.717738 13206 sgd_solver.cpp:106] Iteration 128625, lr = 0.005
I0523 01:46:31.430927 13206 solver.cpp:237] Iteration 129000, loss = 1.30314
I0523 01:46:31.430961 13206 solver.cpp:253]     Train net output #0: loss = 1.30314 (* 1 = 1.30314 loss)
I0523 01:46:31.430979 13206 sgd_solver.cpp:106] Iteration 129000, lr = 0.005
I0523 01:46:41.155017 13206 solver.cpp:237] Iteration 129375, loss = 0.817446
I0523 01:46:41.155208 13206 solver.cpp:253]     Train net output #0: loss = 0.817446 (* 1 = 0.817446 loss)
I0523 01:46:41.155222 13206 sgd_solver.cpp:106] Iteration 129375, lr = 0.005
I0523 01:46:50.871796 13206 solver.cpp:237] Iteration 129750, loss = 1.30779
I0523 01:46:50.871827 13206 solver.cpp:253]     Train net output #0: loss = 1.30779 (* 1 = 1.30779 loss)
I0523 01:46:50.871852 13206 sgd_solver.cpp:106] Iteration 129750, lr = 0.005
I0523 01:47:21.432358 13206 solver.cpp:237] Iteration 130125, loss = 1.04762
I0523 01:47:21.432551 13206 solver.cpp:253]     Train net output #0: loss = 1.04762 (* 1 = 1.04762 loss)
I0523 01:47:21.432566 13206 sgd_solver.cpp:106] Iteration 130125, lr = 0.005
I0523 01:47:31.150488 13206 solver.cpp:237] Iteration 130500, loss = 0.98707
I0523 01:47:31.150534 13206 solver.cpp:253]     Train net output #0: loss = 0.98707 (* 1 = 0.98707 loss)
I0523 01:47:31.150550 13206 sgd_solver.cpp:106] Iteration 130500, lr = 0.005
I0523 01:47:40.873764 13206 solver.cpp:237] Iteration 130875, loss = 0.881214
I0523 01:47:40.873800 13206 solver.cpp:253]     Train net output #0: loss = 0.881214 (* 1 = 0.881214 loss)
I0523 01:47:40.873816 13206 sgd_solver.cpp:106] Iteration 130875, lr = 0.005
I0523 01:47:50.573034 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_131250.caffemodel
I0523 01:47:50.631508 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_131250.solverstate
I0523 01:47:50.667057 13206 solver.cpp:237] Iteration 131250, loss = 1.11698
I0523 01:47:50.667110 13206 solver.cpp:253]     Train net output #0: loss = 1.11698 (* 1 = 1.11698 loss)
I0523 01:47:50.667125 13206 sgd_solver.cpp:106] Iteration 131250, lr = 0.005
I0523 01:48:00.388790 13206 solver.cpp:237] Iteration 131625, loss = 1.08484
I0523 01:48:00.388993 13206 solver.cpp:253]     Train net output #0: loss = 1.08484 (* 1 = 1.08484 loss)
I0523 01:48:00.389006 13206 sgd_solver.cpp:106] Iteration 131625, lr = 0.005
I0523 01:48:10.110544 13206 solver.cpp:237] Iteration 132000, loss = 1.21388
I0523 01:48:10.110580 13206 solver.cpp:253]     Train net output #0: loss = 1.21388 (* 1 = 1.21388 loss)
I0523 01:48:10.110596 13206 sgd_solver.cpp:106] Iteration 132000, lr = 0.005
I0523 01:48:19.834034 13206 solver.cpp:237] Iteration 132375, loss = 0.771145
I0523 01:48:19.834074 13206 solver.cpp:253]     Train net output #0: loss = 0.771145 (* 1 = 0.771145 loss)
I0523 01:48:19.834092 13206 sgd_solver.cpp:106] Iteration 132375, lr = 0.005
I0523 01:48:50.465677 13206 solver.cpp:237] Iteration 132750, loss = 1.1598
I0523 01:48:50.465880 13206 solver.cpp:253]     Train net output #0: loss = 1.1598 (* 1 = 1.1598 loss)
I0523 01:48:50.465895 13206 sgd_solver.cpp:106] Iteration 132750, lr = 0.005
I0523 01:49:00.190177 13206 solver.cpp:237] Iteration 133125, loss = 1.17419
I0523 01:49:00.190212 13206 solver.cpp:253]     Train net output #0: loss = 1.17419 (* 1 = 1.17419 loss)
I0523 01:49:00.190230 13206 sgd_solver.cpp:106] Iteration 133125, lr = 0.005
I0523 01:49:09.913646 13206 solver.cpp:237] Iteration 133500, loss = 1.69537
I0523 01:49:09.913691 13206 solver.cpp:253]     Train net output #0: loss = 1.69537 (* 1 = 1.69537 loss)
I0523 01:49:09.913717 13206 sgd_solver.cpp:106] Iteration 133500, lr = 0.005
I0523 01:49:19.637982 13206 solver.cpp:237] Iteration 133875, loss = 1.07826
I0523 01:49:19.638018 13206 solver.cpp:253]     Train net output #0: loss = 1.07826 (* 1 = 1.07826 loss)
I0523 01:49:19.638036 13206 sgd_solver.cpp:106] Iteration 133875, lr = 0.005
I0523 01:49:29.364706 13206 solver.cpp:237] Iteration 134250, loss = 0.915496
I0523 01:49:29.364886 13206 solver.cpp:253]     Train net output #0: loss = 0.915496 (* 1 = 0.915496 loss)
I0523 01:49:29.364899 13206 sgd_solver.cpp:106] Iteration 134250, lr = 0.005
I0523 01:49:39.093325 13206 solver.cpp:237] Iteration 134625, loss = 0.591672
I0523 01:49:39.093367 13206 solver.cpp:253]     Train net output #0: loss = 0.591672 (* 1 = 0.591672 loss)
I0523 01:49:39.093389 13206 sgd_solver.cpp:106] Iteration 134625, lr = 0.005
I0523 01:49:48.791028 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_135000.caffemodel
I0523 01:49:48.849263 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_135000.solverstate
I0523 01:49:48.882702 13206 solver.cpp:341] Iteration 135000, Testing net (#0)
I0523 01:50:58.279850 13206 solver.cpp:409]     Test net output #0: accuracy = 0.898352
I0523 01:50:58.280047 13206 solver.cpp:409]     Test net output #1: loss = 0.335385 (* 1 = 0.335385 loss)
I0523 01:51:19.161689 13206 solver.cpp:237] Iteration 135000, loss = 0.929917
I0523 01:51:19.161753 13206 solver.cpp:253]     Train net output #0: loss = 0.929917 (* 1 = 0.929917 loss)
I0523 01:51:19.161768 13206 sgd_solver.cpp:106] Iteration 135000, lr = 0.005
I0523 01:51:29.091048 13206 solver.cpp:237] Iteration 135375, loss = 0.846665
I0523 01:51:29.091228 13206 solver.cpp:253]     Train net output #0: loss = 0.846665 (* 1 = 0.846665 loss)
I0523 01:51:29.091241 13206 sgd_solver.cpp:106] Iteration 135375, lr = 0.005
I0523 01:51:39.023092 13206 solver.cpp:237] Iteration 135750, loss = 1.34911
I0523 01:51:39.023126 13206 solver.cpp:253]     Train net output #0: loss = 1.34911 (* 1 = 1.34911 loss)
I0523 01:51:39.023144 13206 sgd_solver.cpp:106] Iteration 135750, lr = 0.005
I0523 01:51:48.950637 13206 solver.cpp:237] Iteration 136125, loss = 1.35634
I0523 01:51:48.950680 13206 solver.cpp:253]     Train net output #0: loss = 1.35634 (* 1 = 1.35634 loss)
I0523 01:51:48.950695 13206 sgd_solver.cpp:106] Iteration 136125, lr = 0.005
I0523 01:51:58.871268 13206 solver.cpp:237] Iteration 136500, loss = 1.44062
I0523 01:51:58.871304 13206 solver.cpp:253]     Train net output #0: loss = 1.44062 (* 1 = 1.44062 loss)
I0523 01:51:58.871320 13206 sgd_solver.cpp:106] Iteration 136500, lr = 0.005
I0523 01:52:08.800895 13206 solver.cpp:237] Iteration 136875, loss = 1.06413
I0523 01:52:08.801098 13206 solver.cpp:253]     Train net output #0: loss = 1.06413 (* 1 = 1.06413 loss)
I0523 01:52:08.801112 13206 sgd_solver.cpp:106] Iteration 136875, lr = 0.005
I0523 01:52:18.723690 13206 solver.cpp:237] Iteration 137250, loss = 1.046
I0523 01:52:18.723724 13206 solver.cpp:253]     Train net output #0: loss = 1.046 (* 1 = 1.046 loss)
I0523 01:52:18.723742 13206 sgd_solver.cpp:106] Iteration 137250, lr = 0.005
I0523 01:52:49.572304 13206 solver.cpp:237] Iteration 137625, loss = 1.06751
I0523 01:52:49.572500 13206 solver.cpp:253]     Train net output #0: loss = 1.06751 (* 1 = 1.06751 loss)
I0523 01:52:49.572515 13206 sgd_solver.cpp:106] Iteration 137625, lr = 0.005
I0523 01:52:59.493911 13206 solver.cpp:237] Iteration 138000, loss = 0.965757
I0523 01:52:59.493965 13206 solver.cpp:253]     Train net output #0: loss = 0.965757 (* 1 = 0.965757 loss)
I0523 01:52:59.493981 13206 sgd_solver.cpp:106] Iteration 138000, lr = 0.005
I0523 01:53:09.410212 13206 solver.cpp:237] Iteration 138375, loss = 1.05418
I0523 01:53:09.410248 13206 solver.cpp:253]     Train net output #0: loss = 1.05418 (* 1 = 1.05418 loss)
I0523 01:53:09.410264 13206 sgd_solver.cpp:106] Iteration 138375, lr = 0.005
I0523 01:53:19.304703 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_138750.caffemodel
I0523 01:53:19.361680 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_138750.solverstate
I0523 01:53:19.395393 13206 solver.cpp:237] Iteration 138750, loss = 1.1678
I0523 01:53:19.395442 13206 solver.cpp:253]     Train net output #0: loss = 1.1678 (* 1 = 1.1678 loss)
I0523 01:53:19.395455 13206 sgd_solver.cpp:106] Iteration 138750, lr = 0.005
I0523 01:53:29.312047 13206 solver.cpp:237] Iteration 139125, loss = 0.933721
I0523 01:53:29.312225 13206 solver.cpp:253]     Train net output #0: loss = 0.933721 (* 1 = 0.933721 loss)
I0523 01:53:29.312239 13206 sgd_solver.cpp:106] Iteration 139125, lr = 0.005
I0523 01:53:39.236007 13206 solver.cpp:237] Iteration 139500, loss = 1.12471
I0523 01:53:39.236042 13206 solver.cpp:253]     Train net output #0: loss = 1.12471 (* 1 = 1.12471 loss)
I0523 01:53:39.236057 13206 sgd_solver.cpp:106] Iteration 139500, lr = 0.005
I0523 01:53:49.161414 13206 solver.cpp:237] Iteration 139875, loss = 0.966402
I0523 01:53:49.161465 13206 solver.cpp:253]     Train net output #0: loss = 0.966402 (* 1 = 0.966402 loss)
I0523 01:53:49.161483 13206 sgd_solver.cpp:106] Iteration 139875, lr = 0.005
I0523 01:54:19.991358 13206 solver.cpp:237] Iteration 140250, loss = 0.91493
I0523 01:54:19.991557 13206 solver.cpp:253]     Train net output #0: loss = 0.91493 (* 1 = 0.91493 loss)
I0523 01:54:19.991574 13206 sgd_solver.cpp:106] Iteration 140250, lr = 0.005
I0523 01:54:29.918571 13206 solver.cpp:237] Iteration 140625, loss = 1.70776
I0523 01:54:29.918607 13206 solver.cpp:253]     Train net output #0: loss = 1.70776 (* 1 = 1.70776 loss)
I0523 01:54:29.918624 13206 sgd_solver.cpp:106] Iteration 140625, lr = 0.005
I0523 01:54:39.841614 13206 solver.cpp:237] Iteration 141000, loss = 1.38095
I0523 01:54:39.841665 13206 solver.cpp:253]     Train net output #0: loss = 1.38095 (* 1 = 1.38095 loss)
I0523 01:54:39.841681 13206 sgd_solver.cpp:106] Iteration 141000, lr = 0.005
I0523 01:54:49.761049 13206 solver.cpp:237] Iteration 141375, loss = 1.28484
I0523 01:54:49.761085 13206 solver.cpp:253]     Train net output #0: loss = 1.28484 (* 1 = 1.28484 loss)
I0523 01:54:49.761101 13206 sgd_solver.cpp:106] Iteration 141375, lr = 0.005
I0523 01:54:59.685523 13206 solver.cpp:237] Iteration 141750, loss = 0.968665
I0523 01:54:59.685734 13206 solver.cpp:253]     Train net output #0: loss = 0.968665 (* 1 = 0.968665 loss)
I0523 01:54:59.685748 13206 sgd_solver.cpp:106] Iteration 141750, lr = 0.005
I0523 01:55:09.614112 13206 solver.cpp:237] Iteration 142125, loss = 1.09929
I0523 01:55:09.614148 13206 solver.cpp:253]     Train net output #0: loss = 1.09929 (* 1 = 1.09929 loss)
I0523 01:55:09.614166 13206 sgd_solver.cpp:106] Iteration 142125, lr = 0.005
I0523 01:55:19.507371 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_142500.caffemodel
I0523 01:55:19.564374 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_142500.solverstate
I0523 01:55:19.589740 13206 solver.cpp:341] Iteration 142500, Testing net (#0)
I0523 01:56:07.804639 13206 solver.cpp:409]     Test net output #0: accuracy = 0.899614
I0523 01:56:07.804838 13206 solver.cpp:409]     Test net output #1: loss = 0.329074 (* 1 = 0.329074 loss)
I0523 01:56:28.717069 13206 solver.cpp:237] Iteration 142500, loss = 0.948387
I0523 01:56:28.717128 13206 solver.cpp:253]     Train net output #0: loss = 0.948387 (* 1 = 0.948387 loss)
I0523 01:56:28.717144 13206 sgd_solver.cpp:106] Iteration 142500, lr = 0.005
I0523 01:56:38.522567 13206 solver.cpp:237] Iteration 142875, loss = 0.995715
I0523 01:56:38.522747 13206 solver.cpp:253]     Train net output #0: loss = 0.995715 (* 1 = 0.995715 loss)
I0523 01:56:38.522760 13206 sgd_solver.cpp:106] Iteration 142875, lr = 0.005
I0523 01:56:48.326073 13206 solver.cpp:237] Iteration 143250, loss = 1.09312
I0523 01:56:48.326118 13206 solver.cpp:253]     Train net output #0: loss = 1.09312 (* 1 = 1.09312 loss)
I0523 01:56:48.326140 13206 sgd_solver.cpp:106] Iteration 143250, lr = 0.005
I0523 01:56:58.129369 13206 solver.cpp:237] Iteration 143625, loss = 1.06418
I0523 01:56:58.129405 13206 solver.cpp:253]     Train net output #0: loss = 1.06418 (* 1 = 1.06418 loss)
I0523 01:56:58.129421 13206 sgd_solver.cpp:106] Iteration 143625, lr = 0.005
I0523 01:57:07.940191 13206 solver.cpp:237] Iteration 144000, loss = 0.929626
I0523 01:57:07.940238 13206 solver.cpp:253]     Train net output #0: loss = 0.929626 (* 1 = 0.929626 loss)
I0523 01:57:07.940254 13206 sgd_solver.cpp:106] Iteration 144000, lr = 0.005
I0523 01:57:17.739965 13206 solver.cpp:237] Iteration 144375, loss = 1.02364
I0523 01:57:17.740137 13206 solver.cpp:253]     Train net output #0: loss = 1.02364 (* 1 = 1.02364 loss)
I0523 01:57:17.740150 13206 sgd_solver.cpp:106] Iteration 144375, lr = 0.005
I0523 01:57:27.542812 13206 solver.cpp:237] Iteration 144750, loss = 1.10057
I0523 01:57:27.542847 13206 solver.cpp:253]     Train net output #0: loss = 1.10057 (* 1 = 1.10057 loss)
I0523 01:57:27.542865 13206 sgd_solver.cpp:106] Iteration 144750, lr = 0.005
I0523 01:57:58.234967 13206 solver.cpp:237] Iteration 145125, loss = 0.949934
I0523 01:57:58.235172 13206 solver.cpp:253]     Train net output #0: loss = 0.949934 (* 1 = 0.949934 loss)
I0523 01:57:58.235186 13206 sgd_solver.cpp:106] Iteration 145125, lr = 0.005
I0523 01:58:08.039049 13206 solver.cpp:237] Iteration 145500, loss = 1.28946
I0523 01:58:08.039086 13206 solver.cpp:253]     Train net output #0: loss = 1.28946 (* 1 = 1.28946 loss)
I0523 01:58:08.039101 13206 sgd_solver.cpp:106] Iteration 145500, lr = 0.005
I0523 01:58:17.844673 13206 solver.cpp:237] Iteration 145875, loss = 1.21632
I0523 01:58:17.844709 13206 solver.cpp:253]     Train net output #0: loss = 1.21632 (* 1 = 1.21632 loss)
I0523 01:58:17.844725 13206 sgd_solver.cpp:106] Iteration 145875, lr = 0.005
I0523 01:58:27.624295 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_146250.caffemodel
I0523 01:58:27.679803 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_146250.solverstate
I0523 01:58:27.713289 13206 solver.cpp:237] Iteration 146250, loss = 1.23771
I0523 01:58:27.713336 13206 solver.cpp:253]     Train net output #0: loss = 1.23771 (* 1 = 1.23771 loss)
I0523 01:58:27.713353 13206 sgd_solver.cpp:106] Iteration 146250, lr = 0.005
I0523 01:58:37.516355 13206 solver.cpp:237] Iteration 146625, loss = 0.994498
I0523 01:58:37.516553 13206 solver.cpp:253]     Train net output #0: loss = 0.994498 (* 1 = 0.994498 loss)
I0523 01:58:37.516568 13206 sgd_solver.cpp:106] Iteration 146625, lr = 0.005
I0523 01:58:47.321099 13206 solver.cpp:237] Iteration 147000, loss = 1.58736
I0523 01:58:47.321141 13206 solver.cpp:253]     Train net output #0: loss = 1.58736 (* 1 = 1.58736 loss)
I0523 01:58:47.321163 13206 sgd_solver.cpp:106] Iteration 147000, lr = 0.005
I0523 01:58:57.122779 13206 solver.cpp:237] Iteration 147375, loss = 1.276
I0523 01:58:57.122814 13206 solver.cpp:253]     Train net output #0: loss = 1.276 (* 1 = 1.276 loss)
I0523 01:58:57.122831 13206 sgd_solver.cpp:106] Iteration 147375, lr = 0.005
I0523 01:59:27.858197 13206 solver.cpp:237] Iteration 147750, loss = 1.08994
I0523 01:59:27.858400 13206 solver.cpp:253]     Train net output #0: loss = 1.08994 (* 1 = 1.08994 loss)
I0523 01:59:27.858417 13206 sgd_solver.cpp:106] Iteration 147750, lr = 0.005
I0523 01:59:37.662009 13206 solver.cpp:237] Iteration 148125, loss = 1.24095
I0523 01:59:37.662060 13206 solver.cpp:253]     Train net output #0: loss = 1.24095 (* 1 = 1.24095 loss)
I0523 01:59:37.662076 13206 sgd_solver.cpp:106] Iteration 148125, lr = 0.005
I0523 01:59:47.471323 13206 solver.cpp:237] Iteration 148500, loss = 1.09288
I0523 01:59:47.471359 13206 solver.cpp:253]     Train net output #0: loss = 1.09288 (* 1 = 1.09288 loss)
I0523 01:59:47.471375 13206 sgd_solver.cpp:106] Iteration 148500, lr = 0.005
I0523 01:59:57.275254 13206 solver.cpp:237] Iteration 148875, loss = 1.53681
I0523 01:59:57.275290 13206 solver.cpp:253]     Train net output #0: loss = 1.53681 (* 1 = 1.53681 loss)
I0523 01:59:57.275307 13206 sgd_solver.cpp:106] Iteration 148875, lr = 0.005
I0523 02:00:07.081259 13206 solver.cpp:237] Iteration 149250, loss = 1.34827
I0523 02:00:07.081454 13206 solver.cpp:253]     Train net output #0: loss = 1.34827 (* 1 = 1.34827 loss)
I0523 02:00:07.081470 13206 sgd_solver.cpp:106] Iteration 149250, lr = 0.005
I0523 02:00:16.885490 13206 solver.cpp:237] Iteration 149625, loss = 1.50076
I0523 02:00:16.885525 13206 solver.cpp:253]     Train net output #0: loss = 1.50076 (* 1 = 1.50076 loss)
I0523 02:00:16.885540 13206 sgd_solver.cpp:106] Iteration 149625, lr = 0.005
I0523 02:00:26.665562 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_150000.caffemodel
I0523 02:00:26.723721 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_150000.solverstate
I0523 02:00:26.751621 13206 solver.cpp:341] Iteration 150000, Testing net (#0)
I0523 02:01:36.180228 13206 solver.cpp:409]     Test net output #0: accuracy = 0.895927
I0523 02:01:36.180429 13206 solver.cpp:409]     Test net output #1: loss = 0.338819 (* 1 = 0.338819 loss)
I0523 02:01:57.093509 13206 solver.cpp:237] Iteration 150000, loss = 1.18165
I0523 02:01:57.093565 13206 solver.cpp:253]     Train net output #0: loss = 1.18165 (* 1 = 1.18165 loss)
I0523 02:01:57.093580 13206 sgd_solver.cpp:106] Iteration 150000, lr = 0.005
I0523 02:02:06.958394 13206 solver.cpp:237] Iteration 150375, loss = 1.26192
I0523 02:02:06.958592 13206 solver.cpp:253]     Train net output #0: loss = 1.26192 (* 1 = 1.26192 loss)
I0523 02:02:06.958607 13206 sgd_solver.cpp:106] Iteration 150375, lr = 0.005
I0523 02:02:16.824939 13206 solver.cpp:237] Iteration 150750, loss = 1.32875
I0523 02:02:16.824973 13206 solver.cpp:253]     Train net output #0: loss = 1.32875 (* 1 = 1.32875 loss)
I0523 02:02:16.824990 13206 sgd_solver.cpp:106] Iteration 150750, lr = 0.005
I0523 02:02:26.688701 13206 solver.cpp:237] Iteration 151125, loss = 1.0608
I0523 02:02:26.688736 13206 solver.cpp:253]     Train net output #0: loss = 1.0608 (* 1 = 1.0608 loss)
I0523 02:02:26.688753 13206 sgd_solver.cpp:106] Iteration 151125, lr = 0.005
I0523 02:02:36.552557 13206 solver.cpp:237] Iteration 151500, loss = 1.06773
I0523 02:02:36.552608 13206 solver.cpp:253]     Train net output #0: loss = 1.06773 (* 1 = 1.06773 loss)
I0523 02:02:36.552623 13206 sgd_solver.cpp:106] Iteration 151500, lr = 0.005
I0523 02:02:46.420120 13206 solver.cpp:237] Iteration 151875, loss = 0.930409
I0523 02:02:46.420310 13206 solver.cpp:253]     Train net output #0: loss = 0.930409 (* 1 = 0.930409 loss)
I0523 02:02:46.420323 13206 sgd_solver.cpp:106] Iteration 151875, lr = 0.005
I0523 02:02:56.293282 13206 solver.cpp:237] Iteration 152250, loss = 0.999886
I0523 02:02:56.293326 13206 solver.cpp:253]     Train net output #0: loss = 0.999886 (* 1 = 0.999886 loss)
I0523 02:02:56.293344 13206 sgd_solver.cpp:106] Iteration 152250, lr = 0.005
I0523 02:03:27.044579 13206 solver.cpp:237] Iteration 152625, loss = 1.03612
I0523 02:03:27.044783 13206 solver.cpp:253]     Train net output #0: loss = 1.03612 (* 1 = 1.03612 loss)
I0523 02:03:27.044798 13206 sgd_solver.cpp:106] Iteration 152625, lr = 0.005
I0523 02:03:36.903775 13206 solver.cpp:237] Iteration 153000, loss = 0.833363
I0523 02:03:36.903810 13206 solver.cpp:253]     Train net output #0: loss = 0.833363 (* 1 = 0.833363 loss)
I0523 02:03:36.903825 13206 sgd_solver.cpp:106] Iteration 153000, lr = 0.005
I0523 02:03:46.765312 13206 solver.cpp:237] Iteration 153375, loss = 1.47368
I0523 02:03:46.765357 13206 solver.cpp:253]     Train net output #0: loss = 1.47368 (* 1 = 1.47368 loss)
I0523 02:03:46.765377 13206 sgd_solver.cpp:106] Iteration 153375, lr = 0.005
I0523 02:03:56.600818 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_153750.caffemodel
I0523 02:03:56.657281 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_153750.solverstate
I0523 02:03:56.691153 13206 solver.cpp:237] Iteration 153750, loss = 1.18433
I0523 02:03:56.691200 13206 solver.cpp:253]     Train net output #0: loss = 1.18433 (* 1 = 1.18433 loss)
I0523 02:03:56.691217 13206 sgd_solver.cpp:106] Iteration 153750, lr = 0.005
I0523 02:04:06.555547 13206 solver.cpp:237] Iteration 154125, loss = 1.31298
I0523 02:04:06.555727 13206 solver.cpp:253]     Train net output #0: loss = 1.31298 (* 1 = 1.31298 loss)
I0523 02:04:06.555742 13206 sgd_solver.cpp:106] Iteration 154125, lr = 0.005
I0523 02:04:16.424481 13206 solver.cpp:237] Iteration 154500, loss = 1.15352
I0523 02:04:16.424532 13206 solver.cpp:253]     Train net output #0: loss = 1.15352 (* 1 = 1.15352 loss)
I0523 02:04:16.424548 13206 sgd_solver.cpp:106] Iteration 154500, lr = 0.005
I0523 02:04:26.293222 13206 solver.cpp:237] Iteration 154875, loss = 1.08961
I0523 02:04:26.293258 13206 solver.cpp:253]     Train net output #0: loss = 1.08961 (* 1 = 1.08961 loss)
I0523 02:04:26.293272 13206 sgd_solver.cpp:106] Iteration 154875, lr = 0.005
I0523 02:04:57.011159 13206 solver.cpp:237] Iteration 155250, loss = 0.895419
I0523 02:04:57.011364 13206 solver.cpp:253]     Train net output #0: loss = 0.895419 (* 1 = 0.895419 loss)
I0523 02:04:57.011379 13206 sgd_solver.cpp:106] Iteration 155250, lr = 0.005
I0523 02:05:06.869098 13206 solver.cpp:237] Iteration 155625, loss = 1.12771
I0523 02:05:06.869140 13206 solver.cpp:253]     Train net output #0: loss = 1.12771 (* 1 = 1.12771 loss)
I0523 02:05:06.869161 13206 sgd_solver.cpp:106] Iteration 155625, lr = 0.005
I0523 02:05:16.740135 13206 solver.cpp:237] Iteration 156000, loss = 1.13635
I0523 02:05:16.740170 13206 solver.cpp:253]     Train net output #0: loss = 1.13635 (* 1 = 1.13635 loss)
I0523 02:05:16.740187 13206 sgd_solver.cpp:106] Iteration 156000, lr = 0.005
I0523 02:05:26.600659 13206 solver.cpp:237] Iteration 156375, loss = 1.15885
I0523 02:05:26.600708 13206 solver.cpp:253]     Train net output #0: loss = 1.15885 (* 1 = 1.15885 loss)
I0523 02:05:26.600723 13206 sgd_solver.cpp:106] Iteration 156375, lr = 0.005
I0523 02:05:36.460270 13206 solver.cpp:237] Iteration 156750, loss = 1.05394
I0523 02:05:36.460458 13206 solver.cpp:253]     Train net output #0: loss = 1.05394 (* 1 = 1.05394 loss)
I0523 02:05:36.460472 13206 sgd_solver.cpp:106] Iteration 156750, lr = 0.005
I0523 02:05:46.325481 13206 solver.cpp:237] Iteration 157125, loss = 1.07101
I0523 02:05:46.325515 13206 solver.cpp:253]     Train net output #0: loss = 1.07101 (* 1 = 1.07101 loss)
I0523 02:05:46.325530 13206 sgd_solver.cpp:106] Iteration 157125, lr = 0.005
I0523 02:05:56.169805 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_157500.caffemodel
I0523 02:05:56.226721 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_157500.solverstate
I0523 02:05:56.252156 13206 solver.cpp:341] Iteration 157500, Testing net (#0)
I0523 02:06:44.828191 13206 solver.cpp:409]     Test net output #0: accuracy = 0.90026
I0523 02:06:44.828392 13206 solver.cpp:409]     Test net output #1: loss = 0.321836 (* 1 = 0.321836 loss)
I0523 02:07:05.731734 13206 solver.cpp:237] Iteration 157500, loss = 0.969421
I0523 02:07:05.731791 13206 solver.cpp:253]     Train net output #0: loss = 0.969421 (* 1 = 0.969421 loss)
I0523 02:07:05.731807 13206 sgd_solver.cpp:106] Iteration 157500, lr = 0.005
I0523 02:07:15.463855 13206 solver.cpp:237] Iteration 157875, loss = 1.14853
I0523 02:07:15.464035 13206 solver.cpp:253]     Train net output #0: loss = 1.14853 (* 1 = 1.14853 loss)
I0523 02:07:15.464048 13206 sgd_solver.cpp:106] Iteration 157875, lr = 0.005
I0523 02:07:25.190902 13206 solver.cpp:237] Iteration 158250, loss = 0.771269
I0523 02:07:25.190938 13206 solver.cpp:253]     Train net output #0: loss = 0.771269 (* 1 = 0.771269 loss)
I0523 02:07:25.190954 13206 sgd_solver.cpp:106] Iteration 158250, lr = 0.005
I0523 02:07:34.915560 13206 solver.cpp:237] Iteration 158625, loss = 1.04756
I0523 02:07:34.915608 13206 solver.cpp:253]     Train net output #0: loss = 1.04756 (* 1 = 1.04756 loss)
I0523 02:07:34.915627 13206 sgd_solver.cpp:106] Iteration 158625, lr = 0.005
I0523 02:07:44.633622 13206 solver.cpp:237] Iteration 159000, loss = 1.12856
I0523 02:07:44.633658 13206 solver.cpp:253]     Train net output #0: loss = 1.12856 (* 1 = 1.12856 loss)
I0523 02:07:44.633674 13206 sgd_solver.cpp:106] Iteration 159000, lr = 0.005
I0523 02:07:54.357075 13206 solver.cpp:237] Iteration 159375, loss = 1.2402
I0523 02:07:54.357273 13206 solver.cpp:253]     Train net output #0: loss = 1.2402 (* 1 = 1.2402 loss)
I0523 02:07:54.357287 13206 sgd_solver.cpp:106] Iteration 159375, lr = 0.005
I0523 02:08:04.078824 13206 solver.cpp:237] Iteration 159750, loss = 1.16272
I0523 02:08:04.078855 13206 solver.cpp:253]     Train net output #0: loss = 1.16272 (* 1 = 1.16272 loss)
I0523 02:08:04.078876 13206 sgd_solver.cpp:106] Iteration 159750, lr = 0.005
I0523 02:08:34.688427 13206 solver.cpp:237] Iteration 160125, loss = 1.24212
I0523 02:08:34.688632 13206 solver.cpp:253]     Train net output #0: loss = 1.24212 (* 1 = 1.24212 loss)
I0523 02:08:34.688648 13206 sgd_solver.cpp:106] Iteration 160125, lr = 0.005
I0523 02:08:44.412327 13206 solver.cpp:237] Iteration 160500, loss = 1.17381
I0523 02:08:44.412379 13206 solver.cpp:253]     Train net output #0: loss = 1.17381 (* 1 = 1.17381 loss)
I0523 02:08:44.412396 13206 sgd_solver.cpp:106] Iteration 160500, lr = 0.005
I0523 02:08:54.135256 13206 solver.cpp:237] Iteration 160875, loss = 1.17966
I0523 02:08:54.135291 13206 solver.cpp:253]     Train net output #0: loss = 1.17966 (* 1 = 1.17966 loss)
I0523 02:08:54.135308 13206 sgd_solver.cpp:106] Iteration 160875, lr = 0.005
I0523 02:09:03.834759 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_161250.caffemodel
I0523 02:09:03.891366 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_161250.solverstate
I0523 02:09:04.455256 13206 solver.cpp:237] Iteration 161250, loss = 1.10009
I0523 02:09:04.455305 13206 solver.cpp:253]     Train net output #0: loss = 1.10009 (* 1 = 1.10009 loss)
I0523 02:09:04.455319 13206 sgd_solver.cpp:106] Iteration 161250, lr = 0.005
I0523 02:09:14.180510 13206 solver.cpp:237] Iteration 161625, loss = 1.0326
I0523 02:09:14.180714 13206 solver.cpp:253]     Train net output #0: loss = 1.0326 (* 1 = 1.0326 loss)
I0523 02:09:14.180728 13206 sgd_solver.cpp:106] Iteration 161625, lr = 0.005
I0523 02:09:23.902889 13206 solver.cpp:237] Iteration 162000, loss = 1.04369
I0523 02:09:23.902925 13206 solver.cpp:253]     Train net output #0: loss = 1.04369 (* 1 = 1.04369 loss)
I0523 02:09:23.902940 13206 sgd_solver.cpp:106] Iteration 162000, lr = 0.005
I0523 02:09:33.624761 13206 solver.cpp:237] Iteration 162375, loss = 0.960816
I0523 02:09:33.624796 13206 solver.cpp:253]     Train net output #0: loss = 0.960816 (* 1 = 0.960816 loss)
I0523 02:09:33.624814 13206 sgd_solver.cpp:106] Iteration 162375, lr = 0.005
I0523 02:10:04.221370 13206 solver.cpp:237] Iteration 162750, loss = 1.09069
I0523 02:10:04.221575 13206 solver.cpp:253]     Train net output #0: loss = 1.09069 (* 1 = 1.09069 loss)
I0523 02:10:04.221590 13206 sgd_solver.cpp:106] Iteration 162750, lr = 0.005
I0523 02:10:13.943450 13206 solver.cpp:237] Iteration 163125, loss = 1.1343
I0523 02:10:13.943485 13206 solver.cpp:253]     Train net output #0: loss = 1.1343 (* 1 = 1.1343 loss)
I0523 02:10:13.943503 13206 sgd_solver.cpp:106] Iteration 163125, lr = 0.005
I0523 02:10:23.670243 13206 solver.cpp:237] Iteration 163500, loss = 0.984949
I0523 02:10:23.670280 13206 solver.cpp:253]     Train net output #0: loss = 0.98495 (* 1 = 0.98495 loss)
I0523 02:10:23.670296 13206 sgd_solver.cpp:106] Iteration 163500, lr = 0.005
I0523 02:10:33.393868 13206 solver.cpp:237] Iteration 163875, loss = 0.927552
I0523 02:10:33.393916 13206 solver.cpp:253]     Train net output #0: loss = 0.927552 (* 1 = 0.927552 loss)
I0523 02:10:33.393936 13206 sgd_solver.cpp:106] Iteration 163875, lr = 0.005
I0523 02:10:43.114903 13206 solver.cpp:237] Iteration 164250, loss = 1.42744
I0523 02:10:43.115082 13206 solver.cpp:253]     Train net output #0: loss = 1.42744 (* 1 = 1.42744 loss)
I0523 02:10:43.115094 13206 sgd_solver.cpp:106] Iteration 164250, lr = 0.005
I0523 02:10:52.844259 13206 solver.cpp:237] Iteration 164625, loss = 0.719621
I0523 02:10:52.844308 13206 solver.cpp:253]     Train net output #0: loss = 0.719621 (* 1 = 0.719621 loss)
I0523 02:10:52.844326 13206 sgd_solver.cpp:106] Iteration 164625, lr = 0.005
I0523 02:11:02.537662 13206 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_165000.caffemodel
I0523 02:11:02.593720 13206 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0050_2016-05-20T15.49.04.504211_iter_165000.solverstate
I0523 02:11:02.619588 13206 solver.cpp:341] Iteration 165000, Testing net (#0)
I0523 02:12:12.006249 13206 solver.cpp:409]     Test net output #0: accuracy = 0.896019
I0523 02:12:12.006463 13206 solver.cpp:409]     Test net output #1: loss = 0.344839 (* 1 = 0.344839 loss)
I0523 02:12:32.879693 13206 solver.cpp:237] Iteration 165000, loss = 1.25164
I0523 02:12:32.879752 13206 solver.cpp:253]     Train net output #0: loss = 1.25164 (* 1 = 1.25164 loss)
I0523 02:12:32.879767 13206 sgd_solver.cpp:106] Iteration 165000, lr = 0.005
I0523 02:12:42.809614 13206 solver.cpp:237] Iteration 165375, loss = 1.00085
I0523 02:12:42.809833 13206 solver.cpp:253]     Train net output #0: loss = 1.00085 (* 1 = 1.00085 loss)
I0523 02:12:42.809847 13206 sgd_solver.cpp:106] Iteration 165375, lr = 0.005
I0523 02:12:52.736841 13206 solver.cpp:237] Iteration 165750, loss = 0.966183
I0523 02:12:52.736877 13206 solver.cpp:253]     Train net output #0: loss = 0.966183 (* 1 = 0.966183 loss)
I0523 02:12:52.736894 13206 sgd_solver.cpp:106] Iteration 165750, lr = 0.005
I0523 02:13:02.660068 13206 solver.cpp:237] Iteration 166125, loss = 0.977958
I0523 02:13:02.660110 13206 solver.cpp:253]     Train net output #0: loss = 0.977958 (* 1 = 0.977958 loss)
I0523 02:13:02.660130 13206 sgd_solver.cpp:106] Iteration 166125, lr = 0.005
I0523 02:13:12.580591 13206 solver.cpp:237] Iteration 166500, loss = 1.2631
I0523 02:13:12.580626 13206 solver.cpp:253]     Train net output #0: loss = 1.2631 (* 1 = 1.2631 loss)
I0523 02:13:12.580639 13206 sgd_solver.cpp:106] Iteration 166500, lr = 0.005
I0523 02:13:22.506148 13206 solver.cpp:237] Iteration 166875, loss = 0.888512
I0523 02:13:22.506350 13206 solver.cpp:253]     Train net output #0: loss = 0.888512 (* 1 = 0.888512 loss)
I0523 02:13:22.506363 13206 sgd_solver.cpp:106] Iteration 166875, lr = 0.005
I0523 02:13:32.433568 13206 solver.cpp:237] Iteration 167250, loss = 1.18223
I0523 02:13:32.433601 13206 solver.cpp:253]     Train net output #0: loss = 1.18223 (* 1 = 1.18223 loss)
I0523 02:13:32.433619 13206 sgd_solver.cpp:106] Iteration 167250, lr = 0.005
I0523 02:14:03.195946 13206 solver.cpp:237] Iteration 167625, loss = 1.35279
I0523 02:14:03.196153 13206 solver.cpp:253]     Train net output #0: loss = 1.35279 (* 1 = 1.35279 loss)
I0523 02:14:03.196167 13206 sgd_solver.cpp:106] Iteration 167625, lr = 0.005
=>> PBS: job killed: walltime 7212 exceeded limit 7200
aprun: Apid 11252040: Caught signal Terminated, sending to application
*** Aborted at 1463984048 (unix time) try "date -d @1463984048" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x3393) received by PID 13206 (TID 0x2aaac746f900) from PID 13203; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11252040: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11252040: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11252040: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
aprun: Apid 11252040: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03788] [c8-1c0s6n0] [Mon May 23 02:14:10 2016] PE RANK 0 exit signal Terminated
Application 11252040 exit codes: 143
Application 11252040 resources: utime ~6246s, stime ~953s, Rss ~5332912, inblocks ~15410626, outblocks ~681486
