2811285
I0526 03:30:25.439205 26891 caffe.cpp:184] Using GPUs 0
I0526 03:30:25.860472 26891 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.001
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316.prototxt"
I0526 03:30:25.862179 26891 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316.prototxt
I0526 03:30:25.880683 26891 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 03:30:25.880741 26891 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 03:30:25.881099 26891 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 03:30:25.881278 26891 layer_factory.hpp:77] Creating layer data_hdf5
I0526 03:30:25.881304 26891 net.cpp:106] Creating Layer data_hdf5
I0526 03:30:25.881317 26891 net.cpp:411] data_hdf5 -> data
I0526 03:30:25.881351 26891 net.cpp:411] data_hdf5 -> label
I0526 03:30:25.881384 26891 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 03:30:25.882690 26891 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 03:30:25.884934 26891 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 03:30:47.452800 26891 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 03:30:47.457909 26891 net.cpp:150] Setting up data_hdf5
I0526 03:30:47.457953 26891 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 03:30:47.457968 26891 net.cpp:157] Top shape: 10 (10)
I0526 03:30:47.457978 26891 net.cpp:165] Memory required for data: 254040
I0526 03:30:47.457991 26891 layer_factory.hpp:77] Creating layer conv1
I0526 03:30:47.458024 26891 net.cpp:106] Creating Layer conv1
I0526 03:30:47.458037 26891 net.cpp:454] conv1 <- data
I0526 03:30:47.458060 26891 net.cpp:411] conv1 -> conv1
I0526 03:30:48.848695 26891 net.cpp:150] Setting up conv1
I0526 03:30:48.848742 26891 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 03:30:48.848752 26891 net.cpp:165] Memory required for data: 3018840
I0526 03:30:48.848780 26891 layer_factory.hpp:77] Creating layer relu1
I0526 03:30:48.848801 26891 net.cpp:106] Creating Layer relu1
I0526 03:30:48.848812 26891 net.cpp:454] relu1 <- conv1
I0526 03:30:48.848826 26891 net.cpp:397] relu1 -> conv1 (in-place)
I0526 03:30:48.849354 26891 net.cpp:150] Setting up relu1
I0526 03:30:48.849371 26891 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 03:30:48.849382 26891 net.cpp:165] Memory required for data: 5783640
I0526 03:30:48.849392 26891 layer_factory.hpp:77] Creating layer pool1
I0526 03:30:48.849409 26891 net.cpp:106] Creating Layer pool1
I0526 03:30:48.849419 26891 net.cpp:454] pool1 <- conv1
I0526 03:30:48.849432 26891 net.cpp:411] pool1 -> pool1
I0526 03:30:48.849512 26891 net.cpp:150] Setting up pool1
I0526 03:30:48.849526 26891 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 03:30:48.849535 26891 net.cpp:165] Memory required for data: 7166040
I0526 03:30:48.849545 26891 layer_factory.hpp:77] Creating layer conv2
I0526 03:30:48.849565 26891 net.cpp:106] Creating Layer conv2
I0526 03:30:48.849575 26891 net.cpp:454] conv2 <- pool1
I0526 03:30:48.849588 26891 net.cpp:411] conv2 -> conv2
I0526 03:30:48.852267 26891 net.cpp:150] Setting up conv2
I0526 03:30:48.852294 26891 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 03:30:48.852304 26891 net.cpp:165] Memory required for data: 9153240
I0526 03:30:48.852324 26891 layer_factory.hpp:77] Creating layer relu2
I0526 03:30:48.852337 26891 net.cpp:106] Creating Layer relu2
I0526 03:30:48.852347 26891 net.cpp:454] relu2 <- conv2
I0526 03:30:48.852360 26891 net.cpp:397] relu2 -> conv2 (in-place)
I0526 03:30:48.852692 26891 net.cpp:150] Setting up relu2
I0526 03:30:48.852707 26891 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 03:30:48.852717 26891 net.cpp:165] Memory required for data: 11140440
I0526 03:30:48.852727 26891 layer_factory.hpp:77] Creating layer pool2
I0526 03:30:48.852740 26891 net.cpp:106] Creating Layer pool2
I0526 03:30:48.852749 26891 net.cpp:454] pool2 <- conv2
I0526 03:30:48.852762 26891 net.cpp:411] pool2 -> pool2
I0526 03:30:48.852843 26891 net.cpp:150] Setting up pool2
I0526 03:30:48.852856 26891 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 03:30:48.852865 26891 net.cpp:165] Memory required for data: 12134040
I0526 03:30:48.852875 26891 layer_factory.hpp:77] Creating layer conv3
I0526 03:30:48.852893 26891 net.cpp:106] Creating Layer conv3
I0526 03:30:48.852903 26891 net.cpp:454] conv3 <- pool2
I0526 03:30:48.852917 26891 net.cpp:411] conv3 -> conv3
I0526 03:30:48.855023 26891 net.cpp:150] Setting up conv3
I0526 03:30:48.855042 26891 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 03:30:48.855053 26891 net.cpp:165] Memory required for data: 13218200
I0526 03:30:48.855072 26891 layer_factory.hpp:77] Creating layer relu3
I0526 03:30:48.855087 26891 net.cpp:106] Creating Layer relu3
I0526 03:30:48.855098 26891 net.cpp:454] relu3 <- conv3
I0526 03:30:48.855110 26891 net.cpp:397] relu3 -> conv3 (in-place)
I0526 03:30:48.855571 26891 net.cpp:150] Setting up relu3
I0526 03:30:48.855588 26891 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 03:30:48.855598 26891 net.cpp:165] Memory required for data: 14302360
I0526 03:30:48.855608 26891 layer_factory.hpp:77] Creating layer pool3
I0526 03:30:48.855621 26891 net.cpp:106] Creating Layer pool3
I0526 03:30:48.855630 26891 net.cpp:454] pool3 <- conv3
I0526 03:30:48.855643 26891 net.cpp:411] pool3 -> pool3
I0526 03:30:48.855711 26891 net.cpp:150] Setting up pool3
I0526 03:30:48.855725 26891 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 03:30:48.855734 26891 net.cpp:165] Memory required for data: 14844440
I0526 03:30:48.855744 26891 layer_factory.hpp:77] Creating layer conv4
I0526 03:30:48.855762 26891 net.cpp:106] Creating Layer conv4
I0526 03:30:48.855772 26891 net.cpp:454] conv4 <- pool3
I0526 03:30:48.855785 26891 net.cpp:411] conv4 -> conv4
I0526 03:30:48.858500 26891 net.cpp:150] Setting up conv4
I0526 03:30:48.858526 26891 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 03:30:48.858537 26891 net.cpp:165] Memory required for data: 15207320
I0526 03:30:48.858556 26891 layer_factory.hpp:77] Creating layer relu4
I0526 03:30:48.858569 26891 net.cpp:106] Creating Layer relu4
I0526 03:30:48.858579 26891 net.cpp:454] relu4 <- conv4
I0526 03:30:48.858593 26891 net.cpp:397] relu4 -> conv4 (in-place)
I0526 03:30:48.859061 26891 net.cpp:150] Setting up relu4
I0526 03:30:48.859077 26891 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 03:30:48.859087 26891 net.cpp:165] Memory required for data: 15570200
I0526 03:30:48.859097 26891 layer_factory.hpp:77] Creating layer pool4
I0526 03:30:48.859110 26891 net.cpp:106] Creating Layer pool4
I0526 03:30:48.859120 26891 net.cpp:454] pool4 <- conv4
I0526 03:30:48.859134 26891 net.cpp:411] pool4 -> pool4
I0526 03:30:48.859203 26891 net.cpp:150] Setting up pool4
I0526 03:30:48.859216 26891 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 03:30:48.859226 26891 net.cpp:165] Memory required for data: 15751640
I0526 03:30:48.859236 26891 layer_factory.hpp:77] Creating layer ip1
I0526 03:30:48.859254 26891 net.cpp:106] Creating Layer ip1
I0526 03:30:48.859264 26891 net.cpp:454] ip1 <- pool4
I0526 03:30:48.859277 26891 net.cpp:411] ip1 -> ip1
I0526 03:30:48.874603 26891 net.cpp:150] Setting up ip1
I0526 03:30:48.874631 26891 net.cpp:157] Top shape: 10 196 (1960)
I0526 03:30:48.874642 26891 net.cpp:165] Memory required for data: 15759480
I0526 03:30:48.874667 26891 layer_factory.hpp:77] Creating layer relu5
I0526 03:30:48.874682 26891 net.cpp:106] Creating Layer relu5
I0526 03:30:48.874692 26891 net.cpp:454] relu5 <- ip1
I0526 03:30:48.874706 26891 net.cpp:397] relu5 -> ip1 (in-place)
I0526 03:30:48.875049 26891 net.cpp:150] Setting up relu5
I0526 03:30:48.875063 26891 net.cpp:157] Top shape: 10 196 (1960)
I0526 03:30:48.875073 26891 net.cpp:165] Memory required for data: 15767320
I0526 03:30:48.875083 26891 layer_factory.hpp:77] Creating layer drop1
I0526 03:30:48.875104 26891 net.cpp:106] Creating Layer drop1
I0526 03:30:48.875114 26891 net.cpp:454] drop1 <- ip1
I0526 03:30:48.875126 26891 net.cpp:397] drop1 -> ip1 (in-place)
I0526 03:30:48.875185 26891 net.cpp:150] Setting up drop1
I0526 03:30:48.875200 26891 net.cpp:157] Top shape: 10 196 (1960)
I0526 03:30:48.875208 26891 net.cpp:165] Memory required for data: 15775160
I0526 03:30:48.875218 26891 layer_factory.hpp:77] Creating layer ip2
I0526 03:30:48.875236 26891 net.cpp:106] Creating Layer ip2
I0526 03:30:48.875247 26891 net.cpp:454] ip2 <- ip1
I0526 03:30:48.875260 26891 net.cpp:411] ip2 -> ip2
I0526 03:30:48.875725 26891 net.cpp:150] Setting up ip2
I0526 03:30:48.875738 26891 net.cpp:157] Top shape: 10 98 (980)
I0526 03:30:48.875748 26891 net.cpp:165] Memory required for data: 15779080
I0526 03:30:48.875763 26891 layer_factory.hpp:77] Creating layer relu6
I0526 03:30:48.875777 26891 net.cpp:106] Creating Layer relu6
I0526 03:30:48.875785 26891 net.cpp:454] relu6 <- ip2
I0526 03:30:48.875797 26891 net.cpp:397] relu6 -> ip2 (in-place)
I0526 03:30:48.876315 26891 net.cpp:150] Setting up relu6
I0526 03:30:48.876332 26891 net.cpp:157] Top shape: 10 98 (980)
I0526 03:30:48.876343 26891 net.cpp:165] Memory required for data: 15783000
I0526 03:30:48.876353 26891 layer_factory.hpp:77] Creating layer drop2
I0526 03:30:48.876365 26891 net.cpp:106] Creating Layer drop2
I0526 03:30:48.876374 26891 net.cpp:454] drop2 <- ip2
I0526 03:30:48.876387 26891 net.cpp:397] drop2 -> ip2 (in-place)
I0526 03:30:48.876430 26891 net.cpp:150] Setting up drop2
I0526 03:30:48.876443 26891 net.cpp:157] Top shape: 10 98 (980)
I0526 03:30:48.876453 26891 net.cpp:165] Memory required for data: 15786920
I0526 03:30:48.876463 26891 layer_factory.hpp:77] Creating layer ip3
I0526 03:30:48.876477 26891 net.cpp:106] Creating Layer ip3
I0526 03:30:48.876487 26891 net.cpp:454] ip3 <- ip2
I0526 03:30:48.876499 26891 net.cpp:411] ip3 -> ip3
I0526 03:30:48.876709 26891 net.cpp:150] Setting up ip3
I0526 03:30:48.876723 26891 net.cpp:157] Top shape: 10 11 (110)
I0526 03:30:48.876732 26891 net.cpp:165] Memory required for data: 15787360
I0526 03:30:48.876747 26891 layer_factory.hpp:77] Creating layer drop3
I0526 03:30:48.876760 26891 net.cpp:106] Creating Layer drop3
I0526 03:30:48.876770 26891 net.cpp:454] drop3 <- ip3
I0526 03:30:48.876782 26891 net.cpp:397] drop3 -> ip3 (in-place)
I0526 03:30:48.876821 26891 net.cpp:150] Setting up drop3
I0526 03:30:48.876834 26891 net.cpp:157] Top shape: 10 11 (110)
I0526 03:30:48.876844 26891 net.cpp:165] Memory required for data: 15787800
I0526 03:30:48.876853 26891 layer_factory.hpp:77] Creating layer loss
I0526 03:30:48.876873 26891 net.cpp:106] Creating Layer loss
I0526 03:30:48.876883 26891 net.cpp:454] loss <- ip3
I0526 03:30:48.876894 26891 net.cpp:454] loss <- label
I0526 03:30:48.876906 26891 net.cpp:411] loss -> loss
I0526 03:30:48.876924 26891 layer_factory.hpp:77] Creating layer loss
I0526 03:30:48.877571 26891 net.cpp:150] Setting up loss
I0526 03:30:48.877593 26891 net.cpp:157] Top shape: (1)
I0526 03:30:48.877605 26891 net.cpp:160]     with loss weight 1
I0526 03:30:48.877650 26891 net.cpp:165] Memory required for data: 15787804
I0526 03:30:48.877660 26891 net.cpp:226] loss needs backward computation.
I0526 03:30:48.877672 26891 net.cpp:226] drop3 needs backward computation.
I0526 03:30:48.877681 26891 net.cpp:226] ip3 needs backward computation.
I0526 03:30:48.877692 26891 net.cpp:226] drop2 needs backward computation.
I0526 03:30:48.877701 26891 net.cpp:226] relu6 needs backward computation.
I0526 03:30:48.877712 26891 net.cpp:226] ip2 needs backward computation.
I0526 03:30:48.877722 26891 net.cpp:226] drop1 needs backward computation.
I0526 03:30:48.877732 26891 net.cpp:226] relu5 needs backward computation.
I0526 03:30:48.877742 26891 net.cpp:226] ip1 needs backward computation.
I0526 03:30:48.877751 26891 net.cpp:226] pool4 needs backward computation.
I0526 03:30:48.877763 26891 net.cpp:226] relu4 needs backward computation.
I0526 03:30:48.877771 26891 net.cpp:226] conv4 needs backward computation.
I0526 03:30:48.877782 26891 net.cpp:226] pool3 needs backward computation.
I0526 03:30:48.877794 26891 net.cpp:226] relu3 needs backward computation.
I0526 03:30:48.877804 26891 net.cpp:226] conv3 needs backward computation.
I0526 03:30:48.877822 26891 net.cpp:226] pool2 needs backward computation.
I0526 03:30:48.877835 26891 net.cpp:226] relu2 needs backward computation.
I0526 03:30:48.877845 26891 net.cpp:226] conv2 needs backward computation.
I0526 03:30:48.877856 26891 net.cpp:226] pool1 needs backward computation.
I0526 03:30:48.877866 26891 net.cpp:226] relu1 needs backward computation.
I0526 03:30:48.877876 26891 net.cpp:226] conv1 needs backward computation.
I0526 03:30:48.877887 26891 net.cpp:228] data_hdf5 does not need backward computation.
I0526 03:30:48.877897 26891 net.cpp:270] This network produces output loss
I0526 03:30:48.877920 26891 net.cpp:283] Network initialization done.
I0526 03:30:48.879534 26891 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316.prototxt
I0526 03:30:48.879604 26891 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 03:30:48.879987 26891 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 03:30:48.880177 26891 layer_factory.hpp:77] Creating layer data_hdf5
I0526 03:30:48.880192 26891 net.cpp:106] Creating Layer data_hdf5
I0526 03:30:48.880204 26891 net.cpp:411] data_hdf5 -> data
I0526 03:30:48.880221 26891 net.cpp:411] data_hdf5 -> label
I0526 03:30:48.880237 26891 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 03:30:48.881434 26891 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 03:31:10.202589 26891 net.cpp:150] Setting up data_hdf5
I0526 03:31:10.202757 26891 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 03:31:10.202772 26891 net.cpp:157] Top shape: 10 (10)
I0526 03:31:10.202782 26891 net.cpp:165] Memory required for data: 254040
I0526 03:31:10.202795 26891 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 03:31:10.202824 26891 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 03:31:10.202836 26891 net.cpp:454] label_data_hdf5_1_split <- label
I0526 03:31:10.202850 26891 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 03:31:10.202872 26891 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 03:31:10.202945 26891 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 03:31:10.202960 26891 net.cpp:157] Top shape: 10 (10)
I0526 03:31:10.202971 26891 net.cpp:157] Top shape: 10 (10)
I0526 03:31:10.202980 26891 net.cpp:165] Memory required for data: 254120
I0526 03:31:10.202991 26891 layer_factory.hpp:77] Creating layer conv1
I0526 03:31:10.203011 26891 net.cpp:106] Creating Layer conv1
I0526 03:31:10.203022 26891 net.cpp:454] conv1 <- data
I0526 03:31:10.203037 26891 net.cpp:411] conv1 -> conv1
I0526 03:31:10.204998 26891 net.cpp:150] Setting up conv1
I0526 03:31:10.205023 26891 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 03:31:10.205042 26891 net.cpp:165] Memory required for data: 3018920
I0526 03:31:10.205065 26891 layer_factory.hpp:77] Creating layer relu1
I0526 03:31:10.205080 26891 net.cpp:106] Creating Layer relu1
I0526 03:31:10.205090 26891 net.cpp:454] relu1 <- conv1
I0526 03:31:10.205103 26891 net.cpp:397] relu1 -> conv1 (in-place)
I0526 03:31:10.205608 26891 net.cpp:150] Setting up relu1
I0526 03:31:10.205624 26891 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 03:31:10.205636 26891 net.cpp:165] Memory required for data: 5783720
I0526 03:31:10.205646 26891 layer_factory.hpp:77] Creating layer pool1
I0526 03:31:10.205662 26891 net.cpp:106] Creating Layer pool1
I0526 03:31:10.205672 26891 net.cpp:454] pool1 <- conv1
I0526 03:31:10.205685 26891 net.cpp:411] pool1 -> pool1
I0526 03:31:10.205760 26891 net.cpp:150] Setting up pool1
I0526 03:31:10.205773 26891 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 03:31:10.205783 26891 net.cpp:165] Memory required for data: 7166120
I0526 03:31:10.205793 26891 layer_factory.hpp:77] Creating layer conv2
I0526 03:31:10.205811 26891 net.cpp:106] Creating Layer conv2
I0526 03:31:10.205821 26891 net.cpp:454] conv2 <- pool1
I0526 03:31:10.205835 26891 net.cpp:411] conv2 -> conv2
I0526 03:31:10.207746 26891 net.cpp:150] Setting up conv2
I0526 03:31:10.207768 26891 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 03:31:10.207782 26891 net.cpp:165] Memory required for data: 9153320
I0526 03:31:10.207799 26891 layer_factory.hpp:77] Creating layer relu2
I0526 03:31:10.207813 26891 net.cpp:106] Creating Layer relu2
I0526 03:31:10.207823 26891 net.cpp:454] relu2 <- conv2
I0526 03:31:10.207835 26891 net.cpp:397] relu2 -> conv2 (in-place)
I0526 03:31:10.208170 26891 net.cpp:150] Setting up relu2
I0526 03:31:10.208184 26891 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 03:31:10.208195 26891 net.cpp:165] Memory required for data: 11140520
I0526 03:31:10.208205 26891 layer_factory.hpp:77] Creating layer pool2
I0526 03:31:10.208220 26891 net.cpp:106] Creating Layer pool2
I0526 03:31:10.208230 26891 net.cpp:454] pool2 <- conv2
I0526 03:31:10.208241 26891 net.cpp:411] pool2 -> pool2
I0526 03:31:10.208315 26891 net.cpp:150] Setting up pool2
I0526 03:31:10.208328 26891 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 03:31:10.208338 26891 net.cpp:165] Memory required for data: 12134120
I0526 03:31:10.208348 26891 layer_factory.hpp:77] Creating layer conv3
I0526 03:31:10.208367 26891 net.cpp:106] Creating Layer conv3
I0526 03:31:10.208379 26891 net.cpp:454] conv3 <- pool2
I0526 03:31:10.208392 26891 net.cpp:411] conv3 -> conv3
I0526 03:31:10.210394 26891 net.cpp:150] Setting up conv3
I0526 03:31:10.210418 26891 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 03:31:10.210429 26891 net.cpp:165] Memory required for data: 13218280
I0526 03:31:10.210448 26891 layer_factory.hpp:77] Creating layer relu3
I0526 03:31:10.210475 26891 net.cpp:106] Creating Layer relu3
I0526 03:31:10.210485 26891 net.cpp:454] relu3 <- conv3
I0526 03:31:10.210499 26891 net.cpp:397] relu3 -> conv3 (in-place)
I0526 03:31:10.210973 26891 net.cpp:150] Setting up relu3
I0526 03:31:10.210989 26891 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 03:31:10.210999 26891 net.cpp:165] Memory required for data: 14302440
I0526 03:31:10.211009 26891 layer_factory.hpp:77] Creating layer pool3
I0526 03:31:10.211024 26891 net.cpp:106] Creating Layer pool3
I0526 03:31:10.211033 26891 net.cpp:454] pool3 <- conv3
I0526 03:31:10.211046 26891 net.cpp:411] pool3 -> pool3
I0526 03:31:10.211117 26891 net.cpp:150] Setting up pool3
I0526 03:31:10.211130 26891 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 03:31:10.211140 26891 net.cpp:165] Memory required for data: 14844520
I0526 03:31:10.211150 26891 layer_factory.hpp:77] Creating layer conv4
I0526 03:31:10.211169 26891 net.cpp:106] Creating Layer conv4
I0526 03:31:10.211179 26891 net.cpp:454] conv4 <- pool3
I0526 03:31:10.211194 26891 net.cpp:411] conv4 -> conv4
I0526 03:31:10.213254 26891 net.cpp:150] Setting up conv4
I0526 03:31:10.213277 26891 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 03:31:10.213289 26891 net.cpp:165] Memory required for data: 15207400
I0526 03:31:10.213307 26891 layer_factory.hpp:77] Creating layer relu4
I0526 03:31:10.213320 26891 net.cpp:106] Creating Layer relu4
I0526 03:31:10.213330 26891 net.cpp:454] relu4 <- conv4
I0526 03:31:10.213343 26891 net.cpp:397] relu4 -> conv4 (in-place)
I0526 03:31:10.213814 26891 net.cpp:150] Setting up relu4
I0526 03:31:10.213830 26891 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 03:31:10.213840 26891 net.cpp:165] Memory required for data: 15570280
I0526 03:31:10.213850 26891 layer_factory.hpp:77] Creating layer pool4
I0526 03:31:10.213863 26891 net.cpp:106] Creating Layer pool4
I0526 03:31:10.213873 26891 net.cpp:454] pool4 <- conv4
I0526 03:31:10.213887 26891 net.cpp:411] pool4 -> pool4
I0526 03:31:10.213958 26891 net.cpp:150] Setting up pool4
I0526 03:31:10.213973 26891 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 03:31:10.213981 26891 net.cpp:165] Memory required for data: 15751720
I0526 03:31:10.213990 26891 layer_factory.hpp:77] Creating layer ip1
I0526 03:31:10.214005 26891 net.cpp:106] Creating Layer ip1
I0526 03:31:10.214016 26891 net.cpp:454] ip1 <- pool4
I0526 03:31:10.214031 26891 net.cpp:411] ip1 -> ip1
I0526 03:31:10.229305 26891 net.cpp:150] Setting up ip1
I0526 03:31:10.229333 26891 net.cpp:157] Top shape: 10 196 (1960)
I0526 03:31:10.229344 26891 net.cpp:165] Memory required for data: 15759560
I0526 03:31:10.229367 26891 layer_factory.hpp:77] Creating layer relu5
I0526 03:31:10.229382 26891 net.cpp:106] Creating Layer relu5
I0526 03:31:10.229393 26891 net.cpp:454] relu5 <- ip1
I0526 03:31:10.229408 26891 net.cpp:397] relu5 -> ip1 (in-place)
I0526 03:31:10.229753 26891 net.cpp:150] Setting up relu5
I0526 03:31:10.229766 26891 net.cpp:157] Top shape: 10 196 (1960)
I0526 03:31:10.229776 26891 net.cpp:165] Memory required for data: 15767400
I0526 03:31:10.229786 26891 layer_factory.hpp:77] Creating layer drop1
I0526 03:31:10.229805 26891 net.cpp:106] Creating Layer drop1
I0526 03:31:10.229815 26891 net.cpp:454] drop1 <- ip1
I0526 03:31:10.229827 26891 net.cpp:397] drop1 -> ip1 (in-place)
I0526 03:31:10.229873 26891 net.cpp:150] Setting up drop1
I0526 03:31:10.229887 26891 net.cpp:157] Top shape: 10 196 (1960)
I0526 03:31:10.229897 26891 net.cpp:165] Memory required for data: 15775240
I0526 03:31:10.229905 26891 layer_factory.hpp:77] Creating layer ip2
I0526 03:31:10.229919 26891 net.cpp:106] Creating Layer ip2
I0526 03:31:10.229929 26891 net.cpp:454] ip2 <- ip1
I0526 03:31:10.229943 26891 net.cpp:411] ip2 -> ip2
I0526 03:31:10.230424 26891 net.cpp:150] Setting up ip2
I0526 03:31:10.230438 26891 net.cpp:157] Top shape: 10 98 (980)
I0526 03:31:10.230448 26891 net.cpp:165] Memory required for data: 15779160
I0526 03:31:10.230463 26891 layer_factory.hpp:77] Creating layer relu6
I0526 03:31:10.230489 26891 net.cpp:106] Creating Layer relu6
I0526 03:31:10.230500 26891 net.cpp:454] relu6 <- ip2
I0526 03:31:10.230512 26891 net.cpp:397] relu6 -> ip2 (in-place)
I0526 03:31:10.231058 26891 net.cpp:150] Setting up relu6
I0526 03:31:10.231076 26891 net.cpp:157] Top shape: 10 98 (980)
I0526 03:31:10.231086 26891 net.cpp:165] Memory required for data: 15783080
I0526 03:31:10.231096 26891 layer_factory.hpp:77] Creating layer drop2
I0526 03:31:10.231108 26891 net.cpp:106] Creating Layer drop2
I0526 03:31:10.231118 26891 net.cpp:454] drop2 <- ip2
I0526 03:31:10.231132 26891 net.cpp:397] drop2 -> ip2 (in-place)
I0526 03:31:10.231176 26891 net.cpp:150] Setting up drop2
I0526 03:31:10.231189 26891 net.cpp:157] Top shape: 10 98 (980)
I0526 03:31:10.231199 26891 net.cpp:165] Memory required for data: 15787000
I0526 03:31:10.231209 26891 layer_factory.hpp:77] Creating layer ip3
I0526 03:31:10.231223 26891 net.cpp:106] Creating Layer ip3
I0526 03:31:10.231233 26891 net.cpp:454] ip3 <- ip2
I0526 03:31:10.231247 26891 net.cpp:411] ip3 -> ip3
I0526 03:31:10.231467 26891 net.cpp:150] Setting up ip3
I0526 03:31:10.231480 26891 net.cpp:157] Top shape: 10 11 (110)
I0526 03:31:10.231490 26891 net.cpp:165] Memory required for data: 15787440
I0526 03:31:10.231505 26891 layer_factory.hpp:77] Creating layer drop3
I0526 03:31:10.231518 26891 net.cpp:106] Creating Layer drop3
I0526 03:31:10.231528 26891 net.cpp:454] drop3 <- ip3
I0526 03:31:10.231541 26891 net.cpp:397] drop3 -> ip3 (in-place)
I0526 03:31:10.231582 26891 net.cpp:150] Setting up drop3
I0526 03:31:10.231595 26891 net.cpp:157] Top shape: 10 11 (110)
I0526 03:31:10.231606 26891 net.cpp:165] Memory required for data: 15787880
I0526 03:31:10.231614 26891 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 03:31:10.231627 26891 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 03:31:10.231637 26891 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 03:31:10.231652 26891 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 03:31:10.231667 26891 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 03:31:10.231740 26891 net.cpp:150] Setting up ip3_drop3_0_split
I0526 03:31:10.231753 26891 net.cpp:157] Top shape: 10 11 (110)
I0526 03:31:10.231765 26891 net.cpp:157] Top shape: 10 11 (110)
I0526 03:31:10.231775 26891 net.cpp:165] Memory required for data: 15788760
I0526 03:31:10.231786 26891 layer_factory.hpp:77] Creating layer accuracy
I0526 03:31:10.231807 26891 net.cpp:106] Creating Layer accuracy
I0526 03:31:10.231817 26891 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 03:31:10.231828 26891 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 03:31:10.231842 26891 net.cpp:411] accuracy -> accuracy
I0526 03:31:10.231866 26891 net.cpp:150] Setting up accuracy
I0526 03:31:10.231878 26891 net.cpp:157] Top shape: (1)
I0526 03:31:10.231889 26891 net.cpp:165] Memory required for data: 15788764
I0526 03:31:10.231899 26891 layer_factory.hpp:77] Creating layer loss
I0526 03:31:10.231914 26891 net.cpp:106] Creating Layer loss
I0526 03:31:10.231923 26891 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 03:31:10.231933 26891 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 03:31:10.231946 26891 net.cpp:411] loss -> loss
I0526 03:31:10.231964 26891 layer_factory.hpp:77] Creating layer loss
I0526 03:31:10.232445 26891 net.cpp:150] Setting up loss
I0526 03:31:10.232458 26891 net.cpp:157] Top shape: (1)
I0526 03:31:10.232467 26891 net.cpp:160]     with loss weight 1
I0526 03:31:10.232488 26891 net.cpp:165] Memory required for data: 15788768
I0526 03:31:10.232498 26891 net.cpp:226] loss needs backward computation.
I0526 03:31:10.232511 26891 net.cpp:228] accuracy does not need backward computation.
I0526 03:31:10.232522 26891 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 03:31:10.232533 26891 net.cpp:226] drop3 needs backward computation.
I0526 03:31:10.232543 26891 net.cpp:226] ip3 needs backward computation.
I0526 03:31:10.232554 26891 net.cpp:226] drop2 needs backward computation.
I0526 03:31:10.232564 26891 net.cpp:226] relu6 needs backward computation.
I0526 03:31:10.232583 26891 net.cpp:226] ip2 needs backward computation.
I0526 03:31:10.232592 26891 net.cpp:226] drop1 needs backward computation.
I0526 03:31:10.232602 26891 net.cpp:226] relu5 needs backward computation.
I0526 03:31:10.232611 26891 net.cpp:226] ip1 needs backward computation.
I0526 03:31:10.232622 26891 net.cpp:226] pool4 needs backward computation.
I0526 03:31:10.232632 26891 net.cpp:226] relu4 needs backward computation.
I0526 03:31:10.232642 26891 net.cpp:226] conv4 needs backward computation.
I0526 03:31:10.232653 26891 net.cpp:226] pool3 needs backward computation.
I0526 03:31:10.232663 26891 net.cpp:226] relu3 needs backward computation.
I0526 03:31:10.232674 26891 net.cpp:226] conv3 needs backward computation.
I0526 03:31:10.232684 26891 net.cpp:226] pool2 needs backward computation.
I0526 03:31:10.232695 26891 net.cpp:226] relu2 needs backward computation.
I0526 03:31:10.232705 26891 net.cpp:226] conv2 needs backward computation.
I0526 03:31:10.232715 26891 net.cpp:226] pool1 needs backward computation.
I0526 03:31:10.232727 26891 net.cpp:226] relu1 needs backward computation.
I0526 03:31:10.232736 26891 net.cpp:226] conv1 needs backward computation.
I0526 03:31:10.232748 26891 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 03:31:10.232759 26891 net.cpp:228] data_hdf5 does not need backward computation.
I0526 03:31:10.232770 26891 net.cpp:270] This network produces output accuracy
I0526 03:31:10.232781 26891 net.cpp:270] This network produces output loss
I0526 03:31:10.232810 26891 net.cpp:283] Network initialization done.
I0526 03:31:10.232944 26891 solver.cpp:60] Solver scaffolding done.
I0526 03:31:10.234108 26891 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_450000.solverstate
I0526 03:31:10.464706 26891 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 03:31:10.470140 26891 caffe.cpp:212] Starting Optimization
I0526 03:31:10.470180 26891 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 03:31:10.470191 26891 solver.cpp:289] Learning Rate Policy: fixed
I0526 03:31:10.471410 26891 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 03:32:11.037246 26891 solver.cpp:409]     Test net output #0: accuracy = 0.895838
I0526 03:32:11.037405 26891 solver.cpp:409]     Test net output #1: loss = 0.321801 (* 1 = 0.321801 loss)
I0526 03:32:11.055021 26891 solver.cpp:237] Iteration 450000, loss = 1.12194
I0526 03:32:11.055057 26891 solver.cpp:253]     Train net output #0: loss = 1.12194 (* 1 = 1.12194 loss)
I0526 03:32:11.055074 26891 sgd_solver.cpp:106] Iteration 450000, lr = 0.001
I0526 03:32:27.840921 26891 solver.cpp:237] Iteration 451500, loss = 1.27226
I0526 03:32:27.840973 26891 solver.cpp:253]     Train net output #0: loss = 1.27226 (* 1 = 1.27226 loss)
I0526 03:32:27.840989 26891 sgd_solver.cpp:106] Iteration 451500, lr = 0.001
I0526 03:32:44.637639 26891 solver.cpp:237] Iteration 453000, loss = 0.968514
I0526 03:32:44.637800 26891 solver.cpp:253]     Train net output #0: loss = 0.968514 (* 1 = 0.968514 loss)
I0526 03:32:44.637814 26891 sgd_solver.cpp:106] Iteration 453000, lr = 0.001
I0526 03:33:01.435519 26891 solver.cpp:237] Iteration 454500, loss = 1.95611
I0526 03:33:01.435555 26891 solver.cpp:253]     Train net output #0: loss = 1.95611 (* 1 = 1.95611 loss)
I0526 03:33:01.435573 26891 sgd_solver.cpp:106] Iteration 454500, lr = 0.001
I0526 03:33:18.228799 26891 solver.cpp:237] Iteration 456000, loss = 1.23307
I0526 03:33:18.228957 26891 solver.cpp:253]     Train net output #0: loss = 1.23307 (* 1 = 1.23307 loss)
I0526 03:33:18.228972 26891 sgd_solver.cpp:106] Iteration 456000, lr = 0.001
I0526 03:33:35.035195 26891 solver.cpp:237] Iteration 457500, loss = 1.27813
I0526 03:33:35.035246 26891 solver.cpp:253]     Train net output #0: loss = 1.27813 (* 1 = 1.27813 loss)
I0526 03:33:35.035260 26891 sgd_solver.cpp:106] Iteration 457500, lr = 0.001
I0526 03:33:51.806143 26891 solver.cpp:237] Iteration 459000, loss = 0.814319
I0526 03:33:51.806282 26891 solver.cpp:253]     Train net output #0: loss = 0.814318 (* 1 = 0.814318 loss)
I0526 03:33:51.806295 26891 sgd_solver.cpp:106] Iteration 459000, lr = 0.001
I0526 03:34:30.737825 26891 solver.cpp:237] Iteration 460500, loss = 1.06394
I0526 03:34:30.737993 26891 solver.cpp:253]     Train net output #0: loss = 1.06394 (* 1 = 1.06394 loss)
I0526 03:34:30.738008 26891 sgd_solver.cpp:106] Iteration 460500, lr = 0.001
I0526 03:34:47.544409 26891 solver.cpp:237] Iteration 462000, loss = 1.45089
I0526 03:34:47.544445 26891 solver.cpp:253]     Train net output #0: loss = 1.45089 (* 1 = 1.45089 loss)
I0526 03:34:47.544461 26891 sgd_solver.cpp:106] Iteration 462000, lr = 0.001
I0526 03:35:04.339906 26891 solver.cpp:237] Iteration 463500, loss = 1.21876
I0526 03:35:04.340059 26891 solver.cpp:253]     Train net output #0: loss = 1.21876 (* 1 = 1.21876 loss)
I0526 03:35:04.340075 26891 sgd_solver.cpp:106] Iteration 463500, lr = 0.001
I0526 03:35:21.126605 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_465000.caffemodel
I0526 03:35:21.173519 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_465000.solverstate
I0526 03:35:21.203282 26891 solver.cpp:237] Iteration 465000, loss = 1.17462
I0526 03:35:21.203336 26891 solver.cpp:253]     Train net output #0: loss = 1.17461 (* 1 = 1.17461 loss)
I0526 03:35:21.203349 26891 sgd_solver.cpp:106] Iteration 465000, lr = 0.001
I0526 03:35:38.016074 26891 solver.cpp:237] Iteration 466500, loss = 1.39983
I0526 03:35:38.016217 26891 solver.cpp:253]     Train net output #0: loss = 1.39983 (* 1 = 1.39983 loss)
I0526 03:35:38.016233 26891 sgd_solver.cpp:106] Iteration 466500, lr = 0.001
I0526 03:35:54.896528 26891 solver.cpp:237] Iteration 468000, loss = 0.679776
I0526 03:35:54.896580 26891 solver.cpp:253]     Train net output #0: loss = 0.679774 (* 1 = 0.679774 loss)
I0526 03:35:54.896595 26891 sgd_solver.cpp:106] Iteration 468000, lr = 0.001
I0526 03:36:11.638036 26891 solver.cpp:237] Iteration 469500, loss = 1.56343
I0526 03:36:11.638188 26891 solver.cpp:253]     Train net output #0: loss = 1.56343 (* 1 = 1.56343 loss)
I0526 03:36:11.638205 26891 sgd_solver.cpp:106] Iteration 469500, lr = 0.001
I0526 03:36:50.434221 26891 solver.cpp:237] Iteration 471000, loss = 1.05181
I0526 03:36:50.434401 26891 solver.cpp:253]     Train net output #0: loss = 1.05181 (* 1 = 1.05181 loss)
I0526 03:36:50.434415 26891 sgd_solver.cpp:106] Iteration 471000, lr = 0.001
I0526 03:37:07.049146 26891 solver.cpp:237] Iteration 472500, loss = 0.447396
I0526 03:37:07.049197 26891 solver.cpp:253]     Train net output #0: loss = 0.447394 (* 1 = 0.447394 loss)
I0526 03:37:07.049211 26891 sgd_solver.cpp:106] Iteration 472500, lr = 0.001
I0526 03:37:23.660012 26891 solver.cpp:237] Iteration 474000, loss = 1.11882
I0526 03:37:23.660163 26891 solver.cpp:253]     Train net output #0: loss = 1.11882 (* 1 = 1.11882 loss)
I0526 03:37:23.660177 26891 sgd_solver.cpp:106] Iteration 474000, lr = 0.001
I0526 03:37:40.312330 26891 solver.cpp:237] Iteration 475500, loss = 1.22323
I0526 03:37:40.312367 26891 solver.cpp:253]     Train net output #0: loss = 1.22323 (* 1 = 1.22323 loss)
I0526 03:37:40.312381 26891 sgd_solver.cpp:106] Iteration 475500, lr = 0.001
I0526 03:37:56.947612 26891 solver.cpp:237] Iteration 477000, loss = 0.880583
I0526 03:37:56.947762 26891 solver.cpp:253]     Train net output #0: loss = 0.880581 (* 1 = 0.880581 loss)
I0526 03:37:56.947777 26891 sgd_solver.cpp:106] Iteration 477000, lr = 0.001
I0526 03:38:13.595474 26891 solver.cpp:237] Iteration 478500, loss = 1.23615
I0526 03:38:13.595525 26891 solver.cpp:253]     Train net output #0: loss = 1.23614 (* 1 = 1.23614 loss)
I0526 03:38:13.595543 26891 sgd_solver.cpp:106] Iteration 478500, lr = 0.001
I0526 03:38:30.209802 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_480000.caffemodel
I0526 03:38:30.293401 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_480000.solverstate
I0526 03:38:30.319378 26891 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 03:39:29.812242 26891 solver.cpp:409]     Test net output #0: accuracy = 0.899898
I0526 03:39:29.812403 26891 solver.cpp:409]     Test net output #1: loss = 0.3117 (* 1 = 0.3117 loss)
I0526 03:39:51.977485 26891 solver.cpp:237] Iteration 480000, loss = 0.549555
I0526 03:39:51.977545 26891 solver.cpp:253]     Train net output #0: loss = 0.549552 (* 1 = 0.549552 loss)
I0526 03:39:51.977558 26891 sgd_solver.cpp:106] Iteration 480000, lr = 0.001
I0526 03:40:08.833087 26891 solver.cpp:237] Iteration 481500, loss = 0.987625
I0526 03:40:08.833240 26891 solver.cpp:253]     Train net output #0: loss = 0.987622 (* 1 = 0.987622 loss)
I0526 03:40:08.833256 26891 sgd_solver.cpp:106] Iteration 481500, lr = 0.001
I0526 03:40:25.684554 26891 solver.cpp:237] Iteration 483000, loss = 0.551054
I0526 03:40:25.684608 26891 solver.cpp:253]     Train net output #0: loss = 0.55105 (* 1 = 0.55105 loss)
I0526 03:40:25.684626 26891 sgd_solver.cpp:106] Iteration 483000, lr = 0.001
I0526 03:40:42.612898 26891 solver.cpp:237] Iteration 484500, loss = 1.16862
I0526 03:40:42.613059 26891 solver.cpp:253]     Train net output #0: loss = 1.16861 (* 1 = 1.16861 loss)
I0526 03:40:42.613075 26891 sgd_solver.cpp:106] Iteration 484500, lr = 0.001
I0526 03:40:59.449887 26891 solver.cpp:237] Iteration 486000, loss = 1.5493
I0526 03:40:59.449924 26891 solver.cpp:253]     Train net output #0: loss = 1.5493 (* 1 = 1.5493 loss)
I0526 03:40:59.449937 26891 sgd_solver.cpp:106] Iteration 486000, lr = 0.001
I0526 03:41:16.354562 26891 solver.cpp:237] Iteration 487500, loss = 1.19748
I0526 03:41:16.354712 26891 solver.cpp:253]     Train net output #0: loss = 1.19748 (* 1 = 1.19748 loss)
I0526 03:41:16.354728 26891 sgd_solver.cpp:106] Iteration 487500, lr = 0.001
I0526 03:41:33.185698 26891 solver.cpp:237] Iteration 489000, loss = 1.07073
I0526 03:41:33.185748 26891 solver.cpp:253]     Train net output #0: loss = 1.07073 (* 1 = 1.07073 loss)
I0526 03:41:33.185762 26891 sgd_solver.cpp:106] Iteration 489000, lr = 0.001
I0526 03:42:12.296365 26891 solver.cpp:237] Iteration 490500, loss = 1.54227
I0526 03:42:12.296543 26891 solver.cpp:253]     Train net output #0: loss = 1.54226 (* 1 = 1.54226 loss)
I0526 03:42:12.296557 26891 sgd_solver.cpp:106] Iteration 490500, lr = 0.001
I0526 03:42:29.139117 26891 solver.cpp:237] Iteration 492000, loss = 1.13844
I0526 03:42:29.139164 26891 solver.cpp:253]     Train net output #0: loss = 1.13843 (* 1 = 1.13843 loss)
I0526 03:42:29.139181 26891 sgd_solver.cpp:106] Iteration 492000, lr = 0.001
I0526 03:42:46.031127 26891 solver.cpp:237] Iteration 493500, loss = 1.3989
I0526 03:42:46.031280 26891 solver.cpp:253]     Train net output #0: loss = 1.3989 (* 1 = 1.3989 loss)
I0526 03:42:46.031293 26891 sgd_solver.cpp:106] Iteration 493500, lr = 0.001
I0526 03:43:03.078238 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_495000.caffemodel
I0526 03:43:03.126312 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_495000.solverstate
I0526 03:43:03.157315 26891 solver.cpp:237] Iteration 495000, loss = 1.42367
I0526 03:43:03.157368 26891 solver.cpp:253]     Train net output #0: loss = 1.42366 (* 1 = 1.42366 loss)
I0526 03:43:03.157384 26891 sgd_solver.cpp:106] Iteration 495000, lr = 0.001
I0526 03:43:19.796128 26891 solver.cpp:237] Iteration 496500, loss = 0.60914
I0526 03:43:19.796290 26891 solver.cpp:253]     Train net output #0: loss = 0.609133 (* 1 = 0.609133 loss)
I0526 03:43:19.796305 26891 sgd_solver.cpp:106] Iteration 496500, lr = 0.001
I0526 03:43:36.452183 26891 solver.cpp:237] Iteration 498000, loss = 1.05799
I0526 03:43:36.452234 26891 solver.cpp:253]     Train net output #0: loss = 1.05799 (* 1 = 1.05799 loss)
I0526 03:43:36.452250 26891 sgd_solver.cpp:106] Iteration 498000, lr = 0.001
I0526 03:43:53.081492 26891 solver.cpp:237] Iteration 499500, loss = 1.31193
I0526 03:43:53.081635 26891 solver.cpp:253]     Train net output #0: loss = 1.31193 (* 1 = 1.31193 loss)
I0526 03:43:53.081650 26891 sgd_solver.cpp:106] Iteration 499500, lr = 0.001
I0526 03:44:31.894083 26891 solver.cpp:237] Iteration 501000, loss = 0.774347
I0526 03:44:31.894249 26891 solver.cpp:253]     Train net output #0: loss = 0.77434 (* 1 = 0.77434 loss)
I0526 03:44:31.894264 26891 sgd_solver.cpp:106] Iteration 501000, lr = 0.001
I0526 03:44:48.544143 26891 solver.cpp:237] Iteration 502500, loss = 0.795737
I0526 03:44:48.544178 26891 solver.cpp:253]     Train net output #0: loss = 0.795731 (* 1 = 0.795731 loss)
I0526 03:44:48.544193 26891 sgd_solver.cpp:106] Iteration 502500, lr = 0.001
I0526 03:45:05.179494 26891 solver.cpp:237] Iteration 504000, loss = 0.538697
I0526 03:45:05.179636 26891 solver.cpp:253]     Train net output #0: loss = 0.538691 (* 1 = 0.538691 loss)
I0526 03:45:05.179651 26891 sgd_solver.cpp:106] Iteration 504000, lr = 0.001
I0526 03:45:21.786730 26891 solver.cpp:237] Iteration 505500, loss = 0.918992
I0526 03:45:21.786778 26891 solver.cpp:253]     Train net output #0: loss = 0.918984 (* 1 = 0.918984 loss)
I0526 03:45:21.786792 26891 sgd_solver.cpp:106] Iteration 505500, lr = 0.001
I0526 03:45:38.409124 26891 solver.cpp:237] Iteration 507000, loss = 1.06526
I0526 03:45:38.409262 26891 solver.cpp:253]     Train net output #0: loss = 1.06526 (* 1 = 1.06526 loss)
I0526 03:45:38.409276 26891 sgd_solver.cpp:106] Iteration 507000, lr = 0.001
I0526 03:45:55.058784 26891 solver.cpp:237] Iteration 508500, loss = 0.892052
I0526 03:45:55.058835 26891 solver.cpp:253]     Train net output #0: loss = 0.892045 (* 1 = 0.892045 loss)
I0526 03:45:55.058848 26891 sgd_solver.cpp:106] Iteration 508500, lr = 0.001
I0526 03:46:11.671625 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_510000.caffemodel
I0526 03:46:11.719970 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_510000.solverstate
I0526 03:46:11.747192 26891 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 03:47:31.784404 26891 solver.cpp:409]     Test net output #0: accuracy = 0.899807
I0526 03:47:31.784575 26891 solver.cpp:409]     Test net output #1: loss = 0.330967 (* 1 = 0.330967 loss)
I0526 03:47:53.996783 26891 solver.cpp:237] Iteration 510000, loss = 0.687579
I0526 03:47:53.996840 26891 solver.cpp:253]     Train net output #0: loss = 0.687572 (* 1 = 0.687572 loss)
I0526 03:47:53.996855 26891 sgd_solver.cpp:106] Iteration 510000, lr = 0.001
I0526 03:48:10.963753 26891 solver.cpp:237] Iteration 511500, loss = 0.827471
I0526 03:48:10.963932 26891 solver.cpp:253]     Train net output #0: loss = 0.827464 (* 1 = 0.827464 loss)
I0526 03:48:10.963946 26891 sgd_solver.cpp:106] Iteration 511500, lr = 0.001
I0526 03:48:27.893316 26891 solver.cpp:237] Iteration 513000, loss = 1.07577
I0526 03:48:27.893352 26891 solver.cpp:253]     Train net output #0: loss = 1.07576 (* 1 = 1.07576 loss)
I0526 03:48:27.893367 26891 sgd_solver.cpp:106] Iteration 513000, lr = 0.001
I0526 03:48:44.858098 26891 solver.cpp:237] Iteration 514500, loss = 0.833377
I0526 03:48:44.858264 26891 solver.cpp:253]     Train net output #0: loss = 0.833369 (* 1 = 0.833369 loss)
I0526 03:48:44.858279 26891 sgd_solver.cpp:106] Iteration 514500, lr = 0.001
I0526 03:49:01.801352 26891 solver.cpp:237] Iteration 516000, loss = 0.570718
I0526 03:49:01.801406 26891 solver.cpp:253]     Train net output #0: loss = 0.57071 (* 1 = 0.57071 loss)
I0526 03:49:01.801420 26891 sgd_solver.cpp:106] Iteration 516000, lr = 0.001
I0526 03:49:18.432826 26891 solver.cpp:237] Iteration 517500, loss = 1.04102
I0526 03:49:18.432971 26891 solver.cpp:253]     Train net output #0: loss = 1.04102 (* 1 = 1.04102 loss)
I0526 03:49:18.432986 26891 sgd_solver.cpp:106] Iteration 517500, lr = 0.001
I0526 03:49:35.090795 26891 solver.cpp:237] Iteration 519000, loss = 2.11041
I0526 03:49:35.090847 26891 solver.cpp:253]     Train net output #0: loss = 2.1104 (* 1 = 2.1104 loss)
I0526 03:49:35.090862 26891 sgd_solver.cpp:106] Iteration 519000, lr = 0.001
I0526 03:50:13.883446 26891 solver.cpp:237] Iteration 520500, loss = 2.08492
I0526 03:50:13.883615 26891 solver.cpp:253]     Train net output #0: loss = 2.08491 (* 1 = 2.08491 loss)
I0526 03:50:13.883630 26891 sgd_solver.cpp:106] Iteration 520500, lr = 0.001
I0526 03:50:30.546298 26891 solver.cpp:237] Iteration 522000, loss = 0.945367
I0526 03:50:30.546336 26891 solver.cpp:253]     Train net output #0: loss = 0.945361 (* 1 = 0.945361 loss)
I0526 03:50:30.546350 26891 sgd_solver.cpp:106] Iteration 522000, lr = 0.001
I0526 03:50:47.163326 26891 solver.cpp:237] Iteration 523500, loss = 1.04467
I0526 03:50:47.163480 26891 solver.cpp:253]     Train net output #0: loss = 1.04467 (* 1 = 1.04467 loss)
I0526 03:50:47.163494 26891 sgd_solver.cpp:106] Iteration 523500, lr = 0.001
I0526 03:51:03.770692 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_525000.caffemodel
I0526 03:51:03.817922 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_525000.solverstate
I0526 03:51:03.848512 26891 solver.cpp:237] Iteration 525000, loss = 1.2059
I0526 03:51:03.848570 26891 solver.cpp:253]     Train net output #0: loss = 1.20589 (* 1 = 1.20589 loss)
I0526 03:51:03.848584 26891 sgd_solver.cpp:106] Iteration 525000, lr = 0.001
I0526 03:51:20.504829 26891 solver.cpp:237] Iteration 526500, loss = 1.39586
I0526 03:51:20.504976 26891 solver.cpp:253]     Train net output #0: loss = 1.39585 (* 1 = 1.39585 loss)
I0526 03:51:20.504992 26891 sgd_solver.cpp:106] Iteration 526500, lr = 0.001
I0526 03:51:37.144944 26891 solver.cpp:237] Iteration 528000, loss = 1.26908
I0526 03:51:37.145000 26891 solver.cpp:253]     Train net output #0: loss = 1.26907 (* 1 = 1.26907 loss)
I0526 03:51:37.145014 26891 sgd_solver.cpp:106] Iteration 528000, lr = 0.001
I0526 03:51:53.719873 26891 solver.cpp:237] Iteration 529500, loss = 0.919152
I0526 03:51:53.720043 26891 solver.cpp:253]     Train net output #0: loss = 0.919147 (* 1 = 0.919147 loss)
I0526 03:51:53.720057 26891 sgd_solver.cpp:106] Iteration 529500, lr = 0.001
I0526 03:52:32.552927 26891 solver.cpp:237] Iteration 531000, loss = 0.917306
I0526 03:52:32.553110 26891 solver.cpp:253]     Train net output #0: loss = 0.917301 (* 1 = 0.917301 loss)
I0526 03:52:32.553128 26891 sgd_solver.cpp:106] Iteration 531000, lr = 0.001
I0526 03:52:49.162107 26891 solver.cpp:237] Iteration 532500, loss = 0.703981
I0526 03:52:49.162163 26891 solver.cpp:253]     Train net output #0: loss = 0.703976 (* 1 = 0.703976 loss)
I0526 03:52:49.162176 26891 sgd_solver.cpp:106] Iteration 532500, lr = 0.001
I0526 03:53:06.143570 26891 solver.cpp:237] Iteration 534000, loss = 1.07635
I0526 03:53:06.143713 26891 solver.cpp:253]     Train net output #0: loss = 1.07635 (* 1 = 1.07635 loss)
I0526 03:53:06.143728 26891 sgd_solver.cpp:106] Iteration 534000, lr = 0.001
I0526 03:53:23.132652 26891 solver.cpp:237] Iteration 535500, loss = 0.79477
I0526 03:53:23.132699 26891 solver.cpp:253]     Train net output #0: loss = 0.794765 (* 1 = 0.794765 loss)
I0526 03:53:23.132714 26891 sgd_solver.cpp:106] Iteration 535500, lr = 0.001
I0526 03:53:40.109192 26891 solver.cpp:237] Iteration 537000, loss = 1.39151
I0526 03:53:40.109352 26891 solver.cpp:253]     Train net output #0: loss = 1.3915 (* 1 = 1.3915 loss)
I0526 03:53:40.109366 26891 sgd_solver.cpp:106] Iteration 537000, lr = 0.001
I0526 03:53:57.081173 26891 solver.cpp:237] Iteration 538500, loss = 0.40407
I0526 03:53:57.081210 26891 solver.cpp:253]     Train net output #0: loss = 0.404066 (* 1 = 0.404066 loss)
I0526 03:53:57.081224 26891 sgd_solver.cpp:106] Iteration 538500, lr = 0.001
I0526 03:54:14.036185 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_540000.caffemodel
I0526 03:54:14.083150 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_540000.solverstate
I0526 03:54:14.108676 26891 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 03:55:13.161981 26891 solver.cpp:409]     Test net output #0: accuracy = 0.900744
I0526 03:55:13.162148 26891 solver.cpp:409]     Test net output #1: loss = 0.311893 (* 1 = 0.311893 loss)
I0526 03:55:35.299532 26891 solver.cpp:237] Iteration 540000, loss = 1.2193
I0526 03:55:35.299588 26891 solver.cpp:253]     Train net output #0: loss = 1.21929 (* 1 = 1.21929 loss)
I0526 03:55:35.299603 26891 sgd_solver.cpp:106] Iteration 540000, lr = 0.001
I0526 03:55:52.337571 26891 solver.cpp:237] Iteration 541500, loss = 0.611077
I0526 03:55:52.337746 26891 solver.cpp:253]     Train net output #0: loss = 0.611072 (* 1 = 0.611072 loss)
I0526 03:55:52.337760 26891 sgd_solver.cpp:106] Iteration 541500, lr = 0.001
I0526 03:56:09.395126 26891 solver.cpp:237] Iteration 543000, loss = 1.69179
I0526 03:56:09.395179 26891 solver.cpp:253]     Train net output #0: loss = 1.69178 (* 1 = 1.69178 loss)
I0526 03:56:09.395193 26891 sgd_solver.cpp:106] Iteration 543000, lr = 0.001
I0526 03:56:26.437983 26891 solver.cpp:237] Iteration 544500, loss = 1.5117
I0526 03:56:26.438127 26891 solver.cpp:253]     Train net output #0: loss = 1.5117 (* 1 = 1.5117 loss)
I0526 03:56:26.438141 26891 sgd_solver.cpp:106] Iteration 544500, lr = 0.001
I0526 03:56:43.478967 26891 solver.cpp:237] Iteration 546000, loss = 1.0244
I0526 03:56:43.479014 26891 solver.cpp:253]     Train net output #0: loss = 1.02439 (* 1 = 1.02439 loss)
I0526 03:56:43.479028 26891 sgd_solver.cpp:106] Iteration 546000, lr = 0.001
I0526 03:57:00.528193 26891 solver.cpp:237] Iteration 547500, loss = 1.46575
I0526 03:57:00.528360 26891 solver.cpp:253]     Train net output #0: loss = 1.46574 (* 1 = 1.46574 loss)
I0526 03:57:00.528374 26891 sgd_solver.cpp:106] Iteration 547500, lr = 0.001
I0526 03:57:17.578822 26891 solver.cpp:237] Iteration 549000, loss = 1.14826
I0526 03:57:17.578860 26891 solver.cpp:253]     Train net output #0: loss = 1.14826 (* 1 = 1.14826 loss)
I0526 03:57:17.578872 26891 sgd_solver.cpp:106] Iteration 549000, lr = 0.001
I0526 03:57:56.800314 26891 solver.cpp:237] Iteration 550500, loss = 1.05911
I0526 03:57:56.800487 26891 solver.cpp:253]     Train net output #0: loss = 1.0591 (* 1 = 1.0591 loss)
I0526 03:57:56.800501 26891 sgd_solver.cpp:106] Iteration 550500, lr = 0.001
I0526 03:58:13.853379 26891 solver.cpp:237] Iteration 552000, loss = 0.761892
I0526 03:58:13.853428 26891 solver.cpp:253]     Train net output #0: loss = 0.761887 (* 1 = 0.761887 loss)
I0526 03:58:13.853442 26891 sgd_solver.cpp:106] Iteration 552000, lr = 0.001
I0526 03:58:30.899330 26891 solver.cpp:237] Iteration 553500, loss = 0.556543
I0526 03:58:30.899484 26891 solver.cpp:253]     Train net output #0: loss = 0.556538 (* 1 = 0.556538 loss)
I0526 03:58:30.899498 26891 sgd_solver.cpp:106] Iteration 553500, lr = 0.001
I0526 03:58:47.937767 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_555000.caffemodel
I0526 03:58:47.992998 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_555000.solverstate
I0526 03:58:48.022111 26891 solver.cpp:237] Iteration 555000, loss = 0.582918
I0526 03:58:48.022161 26891 solver.cpp:253]     Train net output #0: loss = 0.582913 (* 1 = 0.582913 loss)
I0526 03:58:48.022174 26891 sgd_solver.cpp:106] Iteration 555000, lr = 0.001
I0526 03:59:05.080040 26891 solver.cpp:237] Iteration 556500, loss = 1.31562
I0526 03:59:05.080207 26891 solver.cpp:253]     Train net output #0: loss = 1.31561 (* 1 = 1.31561 loss)
I0526 03:59:05.080221 26891 sgd_solver.cpp:106] Iteration 556500, lr = 0.001
I0526 03:59:22.159008 26891 solver.cpp:237] Iteration 558000, loss = 0.424032
I0526 03:59:22.159045 26891 solver.cpp:253]     Train net output #0: loss = 0.424028 (* 1 = 0.424028 loss)
I0526 03:59:22.159059 26891 sgd_solver.cpp:106] Iteration 558000, lr = 0.001
I0526 03:59:39.215214 26891 solver.cpp:237] Iteration 559500, loss = 0.688882
I0526 03:59:39.215376 26891 solver.cpp:253]     Train net output #0: loss = 0.688876 (* 1 = 0.688876 loss)
I0526 03:59:39.215391 26891 sgd_solver.cpp:106] Iteration 559500, lr = 0.001
I0526 04:00:18.487172 26891 solver.cpp:237] Iteration 561000, loss = 1.19878
I0526 04:00:18.487344 26891 solver.cpp:253]     Train net output #0: loss = 1.19877 (* 1 = 1.19877 loss)
I0526 04:00:18.487360 26891 sgd_solver.cpp:106] Iteration 561000, lr = 0.001
I0526 04:00:35.536790 26891 solver.cpp:237] Iteration 562500, loss = 1.86218
I0526 04:00:35.536828 26891 solver.cpp:253]     Train net output #0: loss = 1.86218 (* 1 = 1.86218 loss)
I0526 04:00:35.536840 26891 sgd_solver.cpp:106] Iteration 562500, lr = 0.001
I0526 04:00:52.581620 26891 solver.cpp:237] Iteration 564000, loss = 1.34522
I0526 04:00:52.581779 26891 solver.cpp:253]     Train net output #0: loss = 1.34522 (* 1 = 1.34522 loss)
I0526 04:00:52.581794 26891 sgd_solver.cpp:106] Iteration 564000, lr = 0.001
I0526 04:01:09.657948 26891 solver.cpp:237] Iteration 565500, loss = 1.24951
I0526 04:01:09.657997 26891 solver.cpp:253]     Train net output #0: loss = 1.24951 (* 1 = 1.24951 loss)
I0526 04:01:09.658011 26891 sgd_solver.cpp:106] Iteration 565500, lr = 0.001
I0526 04:01:26.726879 26891 solver.cpp:237] Iteration 567000, loss = 0.752329
I0526 04:01:26.727022 26891 solver.cpp:253]     Train net output #0: loss = 0.752325 (* 1 = 0.752325 loss)
I0526 04:01:26.727035 26891 sgd_solver.cpp:106] Iteration 567000, lr = 0.001
I0526 04:01:43.768138 26891 solver.cpp:237] Iteration 568500, loss = 1.21431
I0526 04:01:43.768189 26891 solver.cpp:253]     Train net output #0: loss = 1.2143 (* 1 = 1.2143 loss)
I0526 04:01:43.768203 26891 sgd_solver.cpp:106] Iteration 568500, lr = 0.001
I0526 04:02:00.821097 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_570000.caffemodel
I0526 04:02:00.867784 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_570000.solverstate
I0526 04:02:00.893625 26891 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 04:03:21.374299 26891 solver.cpp:409]     Test net output #0: accuracy = 0.899546
I0526 04:03:21.374470 26891 solver.cpp:409]     Test net output #1: loss = 0.326717 (* 1 = 0.326717 loss)
I0526 04:03:43.523495 26891 solver.cpp:237] Iteration 570000, loss = 1.70836
I0526 04:03:43.523552 26891 solver.cpp:253]     Train net output #0: loss = 1.70836 (* 1 = 1.70836 loss)
I0526 04:03:43.523567 26891 sgd_solver.cpp:106] Iteration 570000, lr = 0.001
I0526 04:04:00.722440 26891 solver.cpp:237] Iteration 571500, loss = 1.59854
I0526 04:04:00.722611 26891 solver.cpp:253]     Train net output #0: loss = 1.59853 (* 1 = 1.59853 loss)
I0526 04:04:00.722625 26891 sgd_solver.cpp:106] Iteration 571500, lr = 0.001
I0526 04:04:17.960572 26891 solver.cpp:237] Iteration 573000, loss = 0.773381
I0526 04:04:17.960608 26891 solver.cpp:253]     Train net output #0: loss = 0.773377 (* 1 = 0.773377 loss)
I0526 04:04:17.960623 26891 sgd_solver.cpp:106] Iteration 573000, lr = 0.001
I0526 04:04:35.175601 26891 solver.cpp:237] Iteration 574500, loss = 1.50248
I0526 04:04:35.175758 26891 solver.cpp:253]     Train net output #0: loss = 1.50248 (* 1 = 1.50248 loss)
I0526 04:04:35.175773 26891 sgd_solver.cpp:106] Iteration 574500, lr = 0.001
I0526 04:04:52.381592 26891 solver.cpp:237] Iteration 576000, loss = 1.20367
I0526 04:04:52.381646 26891 solver.cpp:253]     Train net output #0: loss = 1.20367 (* 1 = 1.20367 loss)
I0526 04:04:52.381661 26891 sgd_solver.cpp:106] Iteration 576000, lr = 0.001
I0526 04:05:09.554618 26891 solver.cpp:237] Iteration 577500, loss = 1.34094
I0526 04:05:09.554766 26891 solver.cpp:253]     Train net output #0: loss = 1.34093 (* 1 = 1.34093 loss)
I0526 04:05:09.554780 26891 sgd_solver.cpp:106] Iteration 577500, lr = 0.001
I0526 04:05:26.698858 26891 solver.cpp:237] Iteration 579000, loss = 1.09848
I0526 04:05:26.698912 26891 solver.cpp:253]     Train net output #0: loss = 1.09847 (* 1 = 1.09847 loss)
I0526 04:05:26.698932 26891 sgd_solver.cpp:106] Iteration 579000, lr = 0.001
I0526 04:06:06.108360 26891 solver.cpp:237] Iteration 580500, loss = 1.09621
I0526 04:06:06.108528 26891 solver.cpp:253]     Train net output #0: loss = 1.0962 (* 1 = 1.0962 loss)
I0526 04:06:06.108543 26891 sgd_solver.cpp:106] Iteration 580500, lr = 0.001
I0526 04:06:23.314426 26891 solver.cpp:237] Iteration 582000, loss = 0.806342
I0526 04:06:23.314462 26891 solver.cpp:253]     Train net output #0: loss = 0.806338 (* 1 = 0.806338 loss)
I0526 04:06:23.314476 26891 sgd_solver.cpp:106] Iteration 582000, lr = 0.001
I0526 04:06:40.558598 26891 solver.cpp:237] Iteration 583500, loss = 1.23106
I0526 04:06:40.558758 26891 solver.cpp:253]     Train net output #0: loss = 1.23106 (* 1 = 1.23106 loss)
I0526 04:06:40.558771 26891 sgd_solver.cpp:106] Iteration 583500, lr = 0.001
I0526 04:06:57.754415 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_585000.caffemodel
I0526 04:06:57.802031 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_585000.solverstate
I0526 04:06:57.832478 26891 solver.cpp:237] Iteration 585000, loss = 1.49724
I0526 04:06:57.832530 26891 solver.cpp:253]     Train net output #0: loss = 1.49723 (* 1 = 1.49723 loss)
I0526 04:06:57.832545 26891 sgd_solver.cpp:106] Iteration 585000, lr = 0.001
I0526 04:07:15.032577 26891 solver.cpp:237] Iteration 586500, loss = 0.999072
I0526 04:07:15.032742 26891 solver.cpp:253]     Train net output #0: loss = 0.999069 (* 1 = 0.999069 loss)
I0526 04:07:15.032757 26891 sgd_solver.cpp:106] Iteration 586500, lr = 0.001
I0526 04:07:32.257326 26891 solver.cpp:237] Iteration 588000, loss = 3.49724
I0526 04:07:32.257381 26891 solver.cpp:253]     Train net output #0: loss = 3.49724 (* 1 = 3.49724 loss)
I0526 04:07:32.257395 26891 sgd_solver.cpp:106] Iteration 588000, lr = 0.001
I0526 04:07:49.440446 26891 solver.cpp:237] Iteration 589500, loss = 1.67627
I0526 04:07:49.440611 26891 solver.cpp:253]     Train net output #0: loss = 1.67627 (* 1 = 1.67627 loss)
I0526 04:07:49.440625 26891 sgd_solver.cpp:106] Iteration 589500, lr = 0.001
I0526 04:08:28.840767 26891 solver.cpp:237] Iteration 591000, loss = 0.738433
I0526 04:08:28.840946 26891 solver.cpp:253]     Train net output #0: loss = 0.738432 (* 1 = 0.738432 loss)
I0526 04:08:28.840961 26891 sgd_solver.cpp:106] Iteration 591000, lr = 0.001
I0526 04:08:46.071410 26891 solver.cpp:237] Iteration 592500, loss = 1.39449
I0526 04:08:46.071461 26891 solver.cpp:253]     Train net output #0: loss = 1.39449 (* 1 = 1.39449 loss)
I0526 04:08:46.071480 26891 sgd_solver.cpp:106] Iteration 592500, lr = 0.001
I0526 04:09:03.279541 26891 solver.cpp:237] Iteration 594000, loss = 1.2202
I0526 04:09:03.279706 26891 solver.cpp:253]     Train net output #0: loss = 1.22019 (* 1 = 1.22019 loss)
I0526 04:09:03.279721 26891 sgd_solver.cpp:106] Iteration 594000, lr = 0.001
I0526 04:09:20.470525 26891 solver.cpp:237] Iteration 595500, loss = 1.38592
I0526 04:09:20.470561 26891 solver.cpp:253]     Train net output #0: loss = 1.38592 (* 1 = 1.38592 loss)
I0526 04:09:20.470574 26891 sgd_solver.cpp:106] Iteration 595500, lr = 0.001
I0526 04:09:37.680845 26891 solver.cpp:237] Iteration 597000, loss = 1.37933
I0526 04:09:37.681004 26891 solver.cpp:253]     Train net output #0: loss = 1.37932 (* 1 = 1.37932 loss)
I0526 04:09:37.681017 26891 sgd_solver.cpp:106] Iteration 597000, lr = 0.001
I0526 04:09:54.891345 26891 solver.cpp:237] Iteration 598500, loss = 1.1653
I0526 04:09:54.891397 26891 solver.cpp:253]     Train net output #0: loss = 1.1653 (* 1 = 1.1653 loss)
I0526 04:09:54.891412 26891 sgd_solver.cpp:106] Iteration 598500, lr = 0.001
I0526 04:10:12.059882 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_600000.caffemodel
I0526 04:10:12.107950 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_600000.solverstate
I0526 04:10:12.135363 26891 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 04:11:11.779507 26891 solver.cpp:409]     Test net output #0: accuracy = 0.899539
I0526 04:11:11.779677 26891 solver.cpp:409]     Test net output #1: loss = 0.308998 (* 1 = 0.308998 loss)
I0526 04:11:32.706351 26891 solver.cpp:237] Iteration 600000, loss = 1.69383
I0526 04:11:32.706408 26891 solver.cpp:253]     Train net output #0: loss = 1.69383 (* 1 = 1.69383 loss)
I0526 04:11:32.706425 26891 sgd_solver.cpp:106] Iteration 600000, lr = 0.001
I0526 04:11:49.605322 26891 solver.cpp:237] Iteration 601500, loss = 1.13462
I0526 04:11:49.605479 26891 solver.cpp:253]     Train net output #0: loss = 1.13463 (* 1 = 1.13463 loss)
I0526 04:11:49.605494 26891 sgd_solver.cpp:106] Iteration 601500, lr = 0.001
I0526 04:12:06.291661 26891 solver.cpp:237] Iteration 603000, loss = 1.28098
I0526 04:12:06.291707 26891 solver.cpp:253]     Train net output #0: loss = 1.28098 (* 1 = 1.28098 loss)
I0526 04:12:06.291720 26891 sgd_solver.cpp:106] Iteration 603000, lr = 0.001
I0526 04:12:22.928757 26891 solver.cpp:237] Iteration 604500, loss = 1.58882
I0526 04:12:22.928925 26891 solver.cpp:253]     Train net output #0: loss = 1.58882 (* 1 = 1.58882 loss)
I0526 04:12:22.928941 26891 sgd_solver.cpp:106] Iteration 604500, lr = 0.001
I0526 04:12:39.571595 26891 solver.cpp:237] Iteration 606000, loss = 1.34182
I0526 04:12:39.571631 26891 solver.cpp:253]     Train net output #0: loss = 1.34182 (* 1 = 1.34182 loss)
I0526 04:12:39.571645 26891 sgd_solver.cpp:106] Iteration 606000, lr = 0.001
I0526 04:12:56.183333 26891 solver.cpp:237] Iteration 607500, loss = 1.22788
I0526 04:12:56.183495 26891 solver.cpp:253]     Train net output #0: loss = 1.22788 (* 1 = 1.22788 loss)
I0526 04:12:56.183509 26891 sgd_solver.cpp:106] Iteration 607500, lr = 0.001
I0526 04:13:12.824290 26891 solver.cpp:237] Iteration 609000, loss = 1.04378
I0526 04:13:12.824331 26891 solver.cpp:253]     Train net output #0: loss = 1.04379 (* 1 = 1.04379 loss)
I0526 04:13:12.824349 26891 sgd_solver.cpp:106] Iteration 609000, lr = 0.001
I0526 04:13:50.311686 26891 solver.cpp:237] Iteration 610500, loss = 1.12596
I0526 04:13:50.311863 26891 solver.cpp:253]     Train net output #0: loss = 1.12596 (* 1 = 1.12596 loss)
I0526 04:13:50.311877 26891 sgd_solver.cpp:106] Iteration 610500, lr = 0.001
I0526 04:14:06.957495 26891 solver.cpp:237] Iteration 612000, loss = 1.32209
I0526 04:14:06.957545 26891 solver.cpp:253]     Train net output #0: loss = 1.32209 (* 1 = 1.32209 loss)
I0526 04:14:06.957559 26891 sgd_solver.cpp:106] Iteration 612000, lr = 0.001
I0526 04:14:23.592002 26891 solver.cpp:237] Iteration 613500, loss = 0.826824
I0526 04:14:23.592167 26891 solver.cpp:253]     Train net output #0: loss = 0.826824 (* 1 = 0.826824 loss)
I0526 04:14:23.592182 26891 sgd_solver.cpp:106] Iteration 613500, lr = 0.001
I0526 04:14:40.218631 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_615000.caffemodel
I0526 04:14:40.264483 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_615000.solverstate
I0526 04:14:40.293138 26891 solver.cpp:237] Iteration 615000, loss = 1.04601
I0526 04:14:40.293185 26891 solver.cpp:253]     Train net output #0: loss = 1.04601 (* 1 = 1.04601 loss)
I0526 04:14:40.293200 26891 sgd_solver.cpp:106] Iteration 615000, lr = 0.001
I0526 04:14:57.085793 26891 solver.cpp:237] Iteration 616500, loss = 0.889024
I0526 04:14:57.085959 26891 solver.cpp:253]     Train net output #0: loss = 0.889025 (* 1 = 0.889025 loss)
I0526 04:14:57.085974 26891 sgd_solver.cpp:106] Iteration 616500, lr = 0.001
I0526 04:15:14.290138 26891 solver.cpp:237] Iteration 618000, loss = 1.15443
I0526 04:15:14.290191 26891 solver.cpp:253]     Train net output #0: loss = 1.15442 (* 1 = 1.15442 loss)
I0526 04:15:14.290205 26891 sgd_solver.cpp:106] Iteration 618000, lr = 0.001
I0526 04:15:31.502277 26891 solver.cpp:237] Iteration 619500, loss = 1.47639
I0526 04:15:31.502429 26891 solver.cpp:253]     Train net output #0: loss = 1.47639 (* 1 = 1.47639 loss)
I0526 04:15:31.502441 26891 sgd_solver.cpp:106] Iteration 619500, lr = 0.001
I0526 04:16:09.607211 26891 solver.cpp:237] Iteration 621000, loss = 0.523561
I0526 04:16:09.607386 26891 solver.cpp:253]     Train net output #0: loss = 0.523562 (* 1 = 0.523562 loss)
I0526 04:16:09.607401 26891 sgd_solver.cpp:106] Iteration 621000, lr = 0.001
I0526 04:16:26.783809 26891 solver.cpp:237] Iteration 622500, loss = 1.23298
I0526 04:16:26.783845 26891 solver.cpp:253]     Train net output #0: loss = 1.23298 (* 1 = 1.23298 loss)
I0526 04:16:26.783859 26891 sgd_solver.cpp:106] Iteration 622500, lr = 0.001
I0526 04:16:43.999150 26891 solver.cpp:237] Iteration 624000, loss = 1.19612
I0526 04:16:43.999312 26891 solver.cpp:253]     Train net output #0: loss = 1.19612 (* 1 = 1.19612 loss)
I0526 04:16:43.999326 26891 sgd_solver.cpp:106] Iteration 624000, lr = 0.001
I0526 04:17:01.217643 26891 solver.cpp:237] Iteration 625500, loss = 1.37549
I0526 04:17:01.217695 26891 solver.cpp:253]     Train net output #0: loss = 1.37549 (* 1 = 1.37549 loss)
I0526 04:17:01.217708 26891 sgd_solver.cpp:106] Iteration 625500, lr = 0.001
I0526 04:17:18.421495 26891 solver.cpp:237] Iteration 627000, loss = 1.56456
I0526 04:17:18.421654 26891 solver.cpp:253]     Train net output #0: loss = 1.56456 (* 1 = 1.56456 loss)
I0526 04:17:18.421669 26891 sgd_solver.cpp:106] Iteration 627000, lr = 0.001
I0526 04:17:35.241647 26891 solver.cpp:237] Iteration 628500, loss = 1.71023
I0526 04:17:35.241685 26891 solver.cpp:253]     Train net output #0: loss = 1.71023 (* 1 = 1.71023 loss)
I0526 04:17:35.241698 26891 sgd_solver.cpp:106] Iteration 628500, lr = 0.001
I0526 04:17:52.019960 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_630000.caffemodel
I0526 04:17:52.066072 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_630000.solverstate
I0526 04:17:52.091572 26891 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 04:19:12.374631 26891 solver.cpp:409]     Test net output #0: accuracy = 0.901159
I0526 04:19:12.374806 26891 solver.cpp:409]     Test net output #1: loss = 0.317859 (* 1 = 0.317859 loss)
I0526 04:19:33.230782 26891 solver.cpp:237] Iteration 630000, loss = 1.08455
I0526 04:19:33.230839 26891 solver.cpp:253]     Train net output #0: loss = 1.08455 (* 1 = 1.08455 loss)
I0526 04:19:33.230854 26891 sgd_solver.cpp:106] Iteration 630000, lr = 0.001
I0526 04:19:50.128340 26891 solver.cpp:237] Iteration 631500, loss = 1.39588
I0526 04:19:50.128515 26891 solver.cpp:253]     Train net output #0: loss = 1.39588 (* 1 = 1.39588 loss)
I0526 04:19:50.128530 26891 sgd_solver.cpp:106] Iteration 631500, lr = 0.001
I0526 04:20:07.049767 26891 solver.cpp:237] Iteration 633000, loss = 1.49606
I0526 04:20:07.049803 26891 solver.cpp:253]     Train net output #0: loss = 1.49606 (* 1 = 1.49606 loss)
I0526 04:20:07.049818 26891 sgd_solver.cpp:106] Iteration 633000, lr = 0.001
I0526 04:20:23.871716 26891 solver.cpp:237] Iteration 634500, loss = 1.21865
I0526 04:20:23.871886 26891 solver.cpp:253]     Train net output #0: loss = 1.21865 (* 1 = 1.21865 loss)
I0526 04:20:23.871899 26891 sgd_solver.cpp:106] Iteration 634500, lr = 0.001
I0526 04:20:40.808475 26891 solver.cpp:237] Iteration 636000, loss = 1.28018
I0526 04:20:40.808523 26891 solver.cpp:253]     Train net output #0: loss = 1.28019 (* 1 = 1.28019 loss)
I0526 04:20:40.808537 26891 sgd_solver.cpp:106] Iteration 636000, lr = 0.001
I0526 04:20:57.718137 26891 solver.cpp:237] Iteration 637500, loss = 1.06905
I0526 04:20:57.718286 26891 solver.cpp:253]     Train net output #0: loss = 1.06905 (* 1 = 1.06905 loss)
I0526 04:20:57.718300 26891 sgd_solver.cpp:106] Iteration 637500, lr = 0.001
I0526 04:21:14.587769 26891 solver.cpp:237] Iteration 639000, loss = 0.895574
I0526 04:21:14.587824 26891 solver.cpp:253]     Train net output #0: loss = 0.895575 (* 1 = 0.895575 loss)
I0526 04:21:14.587839 26891 sgd_solver.cpp:106] Iteration 639000, lr = 0.001
I0526 04:21:52.303138 26891 solver.cpp:237] Iteration 640500, loss = 1.06799
I0526 04:21:52.303313 26891 solver.cpp:253]     Train net output #0: loss = 1.06799 (* 1 = 1.06799 loss)
I0526 04:21:52.303326 26891 sgd_solver.cpp:106] Iteration 640500, lr = 0.001
I0526 04:22:08.995834 26891 solver.cpp:237] Iteration 642000, loss = 0.968724
I0526 04:22:08.995888 26891 solver.cpp:253]     Train net output #0: loss = 0.968725 (* 1 = 0.968725 loss)
I0526 04:22:08.995904 26891 sgd_solver.cpp:106] Iteration 642000, lr = 0.001
I0526 04:22:25.664594 26891 solver.cpp:237] Iteration 643500, loss = 1.27935
I0526 04:22:25.664759 26891 solver.cpp:253]     Train net output #0: loss = 1.27935 (* 1 = 1.27935 loss)
I0526 04:22:25.664773 26891 sgd_solver.cpp:106] Iteration 643500, lr = 0.001
I0526 04:22:42.435382 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_645000.caffemodel
I0526 04:22:42.482043 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_645000.solverstate
I0526 04:22:42.513559 26891 solver.cpp:237] Iteration 645000, loss = 0.864554
I0526 04:22:42.513613 26891 solver.cpp:253]     Train net output #0: loss = 0.864554 (* 1 = 0.864554 loss)
I0526 04:22:42.513628 26891 sgd_solver.cpp:106] Iteration 645000, lr = 0.001
I0526 04:22:59.704282 26891 solver.cpp:237] Iteration 646500, loss = 1.39732
I0526 04:22:59.704460 26891 solver.cpp:253]     Train net output #0: loss = 1.39732 (* 1 = 1.39732 loss)
I0526 04:22:59.704474 26891 sgd_solver.cpp:106] Iteration 646500, lr = 0.001
I0526 04:23:16.901296 26891 solver.cpp:237] Iteration 648000, loss = 1.40342
I0526 04:23:16.901345 26891 solver.cpp:253]     Train net output #0: loss = 1.40341 (* 1 = 1.40341 loss)
I0526 04:23:16.901357 26891 sgd_solver.cpp:106] Iteration 648000, lr = 0.001
I0526 04:23:34.137369 26891 solver.cpp:237] Iteration 649500, loss = 1.07489
I0526 04:23:34.137547 26891 solver.cpp:253]     Train net output #0: loss = 1.07489 (* 1 = 1.07489 loss)
I0526 04:23:34.137562 26891 sgd_solver.cpp:106] Iteration 649500, lr = 0.001
I0526 04:24:12.192651 26891 solver.cpp:237] Iteration 651000, loss = 0.841248
I0526 04:24:12.192831 26891 solver.cpp:253]     Train net output #0: loss = 0.841248 (* 1 = 0.841248 loss)
I0526 04:24:12.192848 26891 sgd_solver.cpp:106] Iteration 651000, lr = 0.001
I0526 04:24:29.362820 26891 solver.cpp:237] Iteration 652500, loss = 1.27164
I0526 04:24:29.362867 26891 solver.cpp:253]     Train net output #0: loss = 1.27164 (* 1 = 1.27164 loss)
I0526 04:24:29.362884 26891 sgd_solver.cpp:106] Iteration 652500, lr = 0.001
I0526 04:24:46.571615 26891 solver.cpp:237] Iteration 654000, loss = 1.50009
I0526 04:24:46.571764 26891 solver.cpp:253]     Train net output #0: loss = 1.50009 (* 1 = 1.50009 loss)
I0526 04:24:46.571779 26891 sgd_solver.cpp:106] Iteration 654000, lr = 0.001
I0526 04:25:03.789142 26891 solver.cpp:237] Iteration 655500, loss = 1.31538
I0526 04:25:03.789196 26891 solver.cpp:253]     Train net output #0: loss = 1.31538 (* 1 = 1.31538 loss)
I0526 04:25:03.789211 26891 sgd_solver.cpp:106] Iteration 655500, lr = 0.001
I0526 04:25:20.991760 26891 solver.cpp:237] Iteration 657000, loss = 1.51053
I0526 04:25:20.991920 26891 solver.cpp:253]     Train net output #0: loss = 1.51053 (* 1 = 1.51053 loss)
I0526 04:25:20.991935 26891 sgd_solver.cpp:106] Iteration 657000, lr = 0.001
I0526 04:25:38.208698 26891 solver.cpp:237] Iteration 658500, loss = 1.00715
I0526 04:25:38.208734 26891 solver.cpp:253]     Train net output #0: loss = 1.00715 (* 1 = 1.00715 loss)
I0526 04:25:38.208747 26891 sgd_solver.cpp:106] Iteration 658500, lr = 0.001
I0526 04:25:55.403008 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_660000.caffemodel
I0526 04:25:55.450423 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_660000.solverstate
I0526 04:25:55.476964 26891 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 04:26:54.416350 26891 solver.cpp:409]     Test net output #0: accuracy = 0.898825
I0526 04:26:54.416522 26891 solver.cpp:409]     Test net output #1: loss = 0.316308 (* 1 = 0.316308 loss)
I0526 04:27:15.267361 26891 solver.cpp:237] Iteration 660000, loss = 0.731269
I0526 04:27:15.267421 26891 solver.cpp:253]     Train net output #0: loss = 0.731269 (* 1 = 0.731269 loss)
I0526 04:27:15.267436 26891 sgd_solver.cpp:106] Iteration 660000, lr = 0.001
I0526 04:27:32.052614 26891 solver.cpp:237] Iteration 661500, loss = 0.678181
I0526 04:27:32.052783 26891 solver.cpp:253]     Train net output #0: loss = 0.678181 (* 1 = 0.678181 loss)
I0526 04:27:32.052798 26891 sgd_solver.cpp:106] Iteration 661500, lr = 0.001
I0526 04:27:48.848536 26891 solver.cpp:237] Iteration 663000, loss = 0.99594
I0526 04:27:48.848582 26891 solver.cpp:253]     Train net output #0: loss = 0.995941 (* 1 = 0.995941 loss)
I0526 04:27:48.848595 26891 sgd_solver.cpp:106] Iteration 663000, lr = 0.001
I0526 04:28:05.609146 26891 solver.cpp:237] Iteration 664500, loss = 1.10613
I0526 04:28:05.609308 26891 solver.cpp:253]     Train net output #0: loss = 1.10613 (* 1 = 1.10613 loss)
I0526 04:28:05.609321 26891 sgd_solver.cpp:106] Iteration 664500, lr = 0.001
I0526 04:28:22.393074 26891 solver.cpp:237] Iteration 666000, loss = 1.08896
I0526 04:28:22.393129 26891 solver.cpp:253]     Train net output #0: loss = 1.08896 (* 1 = 1.08896 loss)
I0526 04:28:22.393143 26891 sgd_solver.cpp:106] Iteration 666000, lr = 0.001
I0526 04:28:39.162338 26891 solver.cpp:237] Iteration 667500, loss = 1.51755
I0526 04:28:39.162504 26891 solver.cpp:253]     Train net output #0: loss = 1.51755 (* 1 = 1.51755 loss)
I0526 04:28:39.162518 26891 sgd_solver.cpp:106] Iteration 667500, lr = 0.001
I0526 04:28:55.942780 26891 solver.cpp:237] Iteration 669000, loss = 0.852192
I0526 04:28:55.942817 26891 solver.cpp:253]     Train net output #0: loss = 0.852193 (* 1 = 0.852193 loss)
I0526 04:28:55.942831 26891 sgd_solver.cpp:106] Iteration 669000, lr = 0.001
I0526 04:29:33.403719 26891 solver.cpp:237] Iteration 670500, loss = 1.11013
I0526 04:29:33.403899 26891 solver.cpp:253]     Train net output #0: loss = 1.11013 (* 1 = 1.11013 loss)
I0526 04:29:33.403913 26891 sgd_solver.cpp:106] Iteration 670500, lr = 0.001
I0526 04:29:50.026103 26891 solver.cpp:237] Iteration 672000, loss = 1.09542
I0526 04:29:50.026154 26891 solver.cpp:253]     Train net output #0: loss = 1.09543 (* 1 = 1.09543 loss)
I0526 04:29:50.026168 26891 sgd_solver.cpp:106] Iteration 672000, lr = 0.001
I0526 04:30:06.678439 26891 solver.cpp:237] Iteration 673500, loss = 0.780172
I0526 04:30:06.678594 26891 solver.cpp:253]     Train net output #0: loss = 0.780173 (* 1 = 0.780173 loss)
I0526 04:30:06.678608 26891 sgd_solver.cpp:106] Iteration 673500, lr = 0.001
I0526 04:30:23.293805 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_675000.caffemodel
I0526 04:30:23.340500 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_675000.solverstate
I0526 04:30:23.370893 26891 solver.cpp:237] Iteration 675000, loss = 1.33606
I0526 04:30:23.370944 26891 solver.cpp:253]     Train net output #0: loss = 1.33606 (* 1 = 1.33606 loss)
I0526 04:30:23.370959 26891 sgd_solver.cpp:106] Iteration 675000, lr = 0.001
I0526 04:30:40.002985 26891 solver.cpp:237] Iteration 676500, loss = 0.996564
I0526 04:30:40.003166 26891 solver.cpp:253]     Train net output #0: loss = 0.996566 (* 1 = 0.996566 loss)
I0526 04:30:40.003181 26891 sgd_solver.cpp:106] Iteration 676500, lr = 0.001
I0526 04:30:56.618443 26891 solver.cpp:237] Iteration 678000, loss = 1.18729
I0526 04:30:56.618479 26891 solver.cpp:253]     Train net output #0: loss = 1.18729 (* 1 = 1.18729 loss)
I0526 04:30:56.618492 26891 sgd_solver.cpp:106] Iteration 678000, lr = 0.001
I0526 04:31:13.263463 26891 solver.cpp:237] Iteration 679500, loss = 1.26833
I0526 04:31:13.263643 26891 solver.cpp:253]     Train net output #0: loss = 1.26833 (* 1 = 1.26833 loss)
I0526 04:31:13.263658 26891 sgd_solver.cpp:106] Iteration 679500, lr = 0.001
I0526 04:31:50.801676 26891 solver.cpp:237] Iteration 681000, loss = 0.787096
I0526 04:31:50.801858 26891 solver.cpp:253]     Train net output #0: loss = 0.787098 (* 1 = 0.787098 loss)
I0526 04:31:50.801873 26891 sgd_solver.cpp:106] Iteration 681000, lr = 0.001
I0526 04:32:07.409067 26891 solver.cpp:237] Iteration 682500, loss = 0.585771
I0526 04:32:07.409119 26891 solver.cpp:253]     Train net output #0: loss = 0.585772 (* 1 = 0.585772 loss)
I0526 04:32:07.409133 26891 sgd_solver.cpp:106] Iteration 682500, lr = 0.001
I0526 04:32:24.019346 26891 solver.cpp:237] Iteration 684000, loss = 0.902974
I0526 04:32:24.019526 26891 solver.cpp:253]     Train net output #0: loss = 0.902976 (* 1 = 0.902976 loss)
I0526 04:32:24.019541 26891 sgd_solver.cpp:106] Iteration 684000, lr = 0.001
I0526 04:32:40.655910 26891 solver.cpp:237] Iteration 685500, loss = 1.59805
I0526 04:32:40.655947 26891 solver.cpp:253]     Train net output #0: loss = 1.59806 (* 1 = 1.59806 loss)
I0526 04:32:40.655961 26891 sgd_solver.cpp:106] Iteration 685500, lr = 0.001
I0526 04:32:57.281504 26891 solver.cpp:237] Iteration 687000, loss = 1.00479
I0526 04:32:57.281668 26891 solver.cpp:253]     Train net output #0: loss = 1.00479 (* 1 = 1.00479 loss)
I0526 04:32:57.281682 26891 sgd_solver.cpp:106] Iteration 687000, lr = 0.001
I0526 04:33:13.897505 26891 solver.cpp:237] Iteration 688500, loss = 1.4657
I0526 04:33:13.897552 26891 solver.cpp:253]     Train net output #0: loss = 1.4657 (* 1 = 1.4657 loss)
I0526 04:33:13.897568 26891 sgd_solver.cpp:106] Iteration 688500, lr = 0.001
I0526 04:33:30.526662 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_690000.caffemodel
I0526 04:33:30.571957 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_690000.solverstate
I0526 04:33:30.597646 26891 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 04:34:50.900084 26891 solver.cpp:409]     Test net output #0: accuracy = 0.901725
I0526 04:34:50.900269 26891 solver.cpp:409]     Test net output #1: loss = 0.317639 (* 1 = 0.317639 loss)
I0526 04:35:11.732056 26891 solver.cpp:237] Iteration 690000, loss = 0.735453
I0526 04:35:11.732115 26891 solver.cpp:253]     Train net output #0: loss = 0.735455 (* 1 = 0.735455 loss)
I0526 04:35:11.732130 26891 sgd_solver.cpp:106] Iteration 690000, lr = 0.001
I0526 04:35:28.350626 26891 solver.cpp:237] Iteration 691500, loss = 0.509646
I0526 04:35:28.350801 26891 solver.cpp:253]     Train net output #0: loss = 0.509647 (* 1 = 0.509647 loss)
I0526 04:35:28.350816 26891 sgd_solver.cpp:106] Iteration 691500, lr = 0.001
I0526 04:35:44.973681 26891 solver.cpp:237] Iteration 693000, loss = 1.33455
I0526 04:35:44.973727 26891 solver.cpp:253]     Train net output #0: loss = 1.33455 (* 1 = 1.33455 loss)
I0526 04:35:44.973745 26891 sgd_solver.cpp:106] Iteration 693000, lr = 0.001
I0526 04:36:01.611243 26891 solver.cpp:237] Iteration 694500, loss = 1.16119
I0526 04:36:01.611395 26891 solver.cpp:253]     Train net output #0: loss = 1.16119 (* 1 = 1.16119 loss)
I0526 04:36:01.611409 26891 sgd_solver.cpp:106] Iteration 694500, lr = 0.001
I0526 04:36:18.244006 26891 solver.cpp:237] Iteration 696000, loss = 1.08591
I0526 04:36:18.244060 26891 solver.cpp:253]     Train net output #0: loss = 1.08591 (* 1 = 1.08591 loss)
I0526 04:36:18.244074 26891 sgd_solver.cpp:106] Iteration 696000, lr = 0.001
I0526 04:36:34.860448 26891 solver.cpp:237] Iteration 697500, loss = 1.38814
I0526 04:36:34.860622 26891 solver.cpp:253]     Train net output #0: loss = 1.38814 (* 1 = 1.38814 loss)
I0526 04:36:34.860636 26891 sgd_solver.cpp:106] Iteration 697500, lr = 0.001
I0526 04:36:51.515059 26891 solver.cpp:237] Iteration 699000, loss = 0.556554
I0526 04:36:51.515096 26891 solver.cpp:253]     Train net output #0: loss = 0.556554 (* 1 = 0.556554 loss)
I0526 04:36:51.515110 26891 sgd_solver.cpp:106] Iteration 699000, lr = 0.001
I0526 04:37:28.969066 26891 solver.cpp:237] Iteration 700500, loss = 0.934889
I0526 04:37:28.969251 26891 solver.cpp:253]     Train net output #0: loss = 0.934888 (* 1 = 0.934888 loss)
I0526 04:37:28.969265 26891 sgd_solver.cpp:106] Iteration 700500, lr = 0.001
I0526 04:37:45.619248 26891 solver.cpp:237] Iteration 702000, loss = 0.545105
I0526 04:37:45.619302 26891 solver.cpp:253]     Train net output #0: loss = 0.545104 (* 1 = 0.545104 loss)
I0526 04:37:45.619315 26891 sgd_solver.cpp:106] Iteration 702000, lr = 0.001
I0526 04:38:02.379892 26891 solver.cpp:237] Iteration 703500, loss = 0.2095
I0526 04:38:02.380058 26891 solver.cpp:253]     Train net output #0: loss = 0.2095 (* 1 = 0.2095 loss)
I0526 04:38:02.380071 26891 sgd_solver.cpp:106] Iteration 703500, lr = 0.001
I0526 04:38:19.143465 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_705000.caffemodel
I0526 04:38:19.189285 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_705000.solverstate
I0526 04:38:19.218083 26891 solver.cpp:237] Iteration 705000, loss = 1.45641
I0526 04:38:19.218127 26891 solver.cpp:253]     Train net output #0: loss = 1.45641 (* 1 = 1.45641 loss)
I0526 04:38:19.218147 26891 sgd_solver.cpp:106] Iteration 705000, lr = 0.001
I0526 04:38:35.985796 26891 solver.cpp:237] Iteration 706500, loss = 1.11189
I0526 04:38:35.985975 26891 solver.cpp:253]     Train net output #0: loss = 1.11189 (* 1 = 1.11189 loss)
I0526 04:38:35.985988 26891 sgd_solver.cpp:106] Iteration 706500, lr = 0.001
I0526 04:38:52.803419 26891 solver.cpp:237] Iteration 708000, loss = 0.468585
I0526 04:38:52.803455 26891 solver.cpp:253]     Train net output #0: loss = 0.468584 (* 1 = 0.468584 loss)
I0526 04:38:52.803470 26891 sgd_solver.cpp:106] Iteration 708000, lr = 0.001
I0526 04:39:09.587802 26891 solver.cpp:237] Iteration 709500, loss = 1.36466
I0526 04:39:09.587975 26891 solver.cpp:253]     Train net output #0: loss = 1.36466 (* 1 = 1.36466 loss)
I0526 04:39:09.587990 26891 sgd_solver.cpp:106] Iteration 709500, lr = 0.001
I0526 04:39:47.184140 26891 solver.cpp:237] Iteration 711000, loss = 1.81704
I0526 04:39:47.184319 26891 solver.cpp:253]     Train net output #0: loss = 1.81704 (* 1 = 1.81704 loss)
I0526 04:39:47.184334 26891 sgd_solver.cpp:106] Iteration 711000, lr = 0.001
I0526 04:40:03.970350 26891 solver.cpp:237] Iteration 712500, loss = 1.56389
I0526 04:40:03.970403 26891 solver.cpp:253]     Train net output #0: loss = 1.56389 (* 1 = 1.56389 loss)
I0526 04:40:03.970417 26891 sgd_solver.cpp:106] Iteration 712500, lr = 0.001
I0526 04:40:20.747582 26891 solver.cpp:237] Iteration 714000, loss = 1.1661
I0526 04:40:20.747757 26891 solver.cpp:253]     Train net output #0: loss = 1.1661 (* 1 = 1.1661 loss)
I0526 04:40:20.747774 26891 sgd_solver.cpp:106] Iteration 714000, lr = 0.001
I0526 04:40:37.554560 26891 solver.cpp:237] Iteration 715500, loss = 1.36169
I0526 04:40:37.554597 26891 solver.cpp:253]     Train net output #0: loss = 1.36169 (* 1 = 1.36169 loss)
I0526 04:40:37.554613 26891 sgd_solver.cpp:106] Iteration 715500, lr = 0.001
I0526 04:40:54.394681 26891 solver.cpp:237] Iteration 717000, loss = 0.736709
I0526 04:40:54.394856 26891 solver.cpp:253]     Train net output #0: loss = 0.736708 (* 1 = 0.736708 loss)
I0526 04:40:54.394871 26891 sgd_solver.cpp:106] Iteration 717000, lr = 0.001
I0526 04:41:11.350775 26891 solver.cpp:237] Iteration 718500, loss = 1.09203
I0526 04:41:11.350826 26891 solver.cpp:253]     Train net output #0: loss = 1.09203 (* 1 = 1.09203 loss)
I0526 04:41:11.350839 26891 sgd_solver.cpp:106] Iteration 718500, lr = 0.001
I0526 04:41:28.176987 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_720000.caffemodel
I0526 04:41:28.222445 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_720000.solverstate
I0526 04:41:28.247725 26891 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 04:42:27.757220 26891 solver.cpp:409]     Test net output #0: accuracy = 0.90124
I0526 04:42:27.757400 26891 solver.cpp:409]     Test net output #1: loss = 0.30325 (* 1 = 0.30325 loss)
I0526 04:42:48.595592 26891 solver.cpp:237] Iteration 720000, loss = 1.23743
I0526 04:42:48.595648 26891 solver.cpp:253]     Train net output #0: loss = 1.23743 (* 1 = 1.23743 loss)
I0526 04:42:48.595662 26891 sgd_solver.cpp:106] Iteration 720000, lr = 0.001
I0526 04:43:05.787384 26891 solver.cpp:237] Iteration 721500, loss = 1.41664
I0526 04:43:05.787561 26891 solver.cpp:253]     Train net output #0: loss = 1.41663 (* 1 = 1.41663 loss)
I0526 04:43:05.787575 26891 sgd_solver.cpp:106] Iteration 721500, lr = 0.001
I0526 04:43:22.964800 26891 solver.cpp:237] Iteration 723000, loss = 0.504168
I0526 04:43:22.964851 26891 solver.cpp:253]     Train net output #0: loss = 0.504166 (* 1 = 0.504166 loss)
I0526 04:43:22.964865 26891 sgd_solver.cpp:106] Iteration 723000, lr = 0.001
I0526 04:43:40.159831 26891 solver.cpp:237] Iteration 724500, loss = 1.08909
I0526 04:43:40.160002 26891 solver.cpp:253]     Train net output #0: loss = 1.08909 (* 1 = 1.08909 loss)
I0526 04:43:40.160017 26891 sgd_solver.cpp:106] Iteration 724500, lr = 0.001
I0526 04:43:57.425623 26891 solver.cpp:237] Iteration 726000, loss = 1.16769
I0526 04:43:57.425659 26891 solver.cpp:253]     Train net output #0: loss = 1.16769 (* 1 = 1.16769 loss)
I0526 04:43:57.425674 26891 sgd_solver.cpp:106] Iteration 726000, lr = 0.001
I0526 04:44:14.650676 26891 solver.cpp:237] Iteration 727500, loss = 1.23838
I0526 04:44:14.650846 26891 solver.cpp:253]     Train net output #0: loss = 1.23838 (* 1 = 1.23838 loss)
I0526 04:44:14.650859 26891 sgd_solver.cpp:106] Iteration 727500, lr = 0.001
I0526 04:44:31.848426 26891 solver.cpp:237] Iteration 729000, loss = 1.20995
I0526 04:44:31.848474 26891 solver.cpp:253]     Train net output #0: loss = 1.20995 (* 1 = 1.20995 loss)
I0526 04:44:31.848489 26891 sgd_solver.cpp:106] Iteration 729000, lr = 0.001
I0526 04:45:09.885211 26891 solver.cpp:237] Iteration 730500, loss = 0.811442
I0526 04:45:09.885396 26891 solver.cpp:253]     Train net output #0: loss = 0.811439 (* 1 = 0.811439 loss)
I0526 04:45:09.885413 26891 sgd_solver.cpp:106] Iteration 730500, lr = 0.001
I0526 04:45:27.107475 26891 solver.cpp:237] Iteration 732000, loss = 1.37368
I0526 04:45:27.107522 26891 solver.cpp:253]     Train net output #0: loss = 1.37368 (* 1 = 1.37368 loss)
I0526 04:45:27.107537 26891 sgd_solver.cpp:106] Iteration 732000, lr = 0.001
I0526 04:45:44.336300 26891 solver.cpp:237] Iteration 733500, loss = 1.17034
I0526 04:45:44.336468 26891 solver.cpp:253]     Train net output #0: loss = 1.17034 (* 1 = 1.17034 loss)
I0526 04:45:44.336483 26891 sgd_solver.cpp:106] Iteration 733500, lr = 0.001
I0526 04:46:01.546901 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_735000.caffemodel
I0526 04:46:01.595410 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_735000.solverstate
I0526 04:46:01.625593 26891 solver.cpp:237] Iteration 735000, loss = 1.93155
I0526 04:46:01.625648 26891 solver.cpp:253]     Train net output #0: loss = 1.93155 (* 1 = 1.93155 loss)
I0526 04:46:01.625663 26891 sgd_solver.cpp:106] Iteration 735000, lr = 0.001
I0526 04:46:18.811857 26891 solver.cpp:237] Iteration 736500, loss = 0.65487
I0526 04:46:18.812033 26891 solver.cpp:253]     Train net output #0: loss = 0.654867 (* 1 = 0.654867 loss)
I0526 04:46:18.812048 26891 sgd_solver.cpp:106] Iteration 736500, lr = 0.001
I0526 04:46:36.016396 26891 solver.cpp:237] Iteration 738000, loss = 1.95102
I0526 04:46:36.016445 26891 solver.cpp:253]     Train net output #0: loss = 1.95101 (* 1 = 1.95101 loss)
I0526 04:46:36.016459 26891 sgd_solver.cpp:106] Iteration 738000, lr = 0.001
I0526 04:46:53.227665 26891 solver.cpp:237] Iteration 739500, loss = 1.24769
I0526 04:46:53.227819 26891 solver.cpp:253]     Train net output #0: loss = 1.24768 (* 1 = 1.24768 loss)
I0526 04:46:53.227833 26891 sgd_solver.cpp:106] Iteration 739500, lr = 0.001
I0526 04:47:31.319684 26891 solver.cpp:237] Iteration 741000, loss = 1.41552
I0526 04:47:31.319880 26891 solver.cpp:253]     Train net output #0: loss = 1.41552 (* 1 = 1.41552 loss)
I0526 04:47:31.319895 26891 sgd_solver.cpp:106] Iteration 741000, lr = 0.001
I0526 04:47:48.544244 26891 solver.cpp:237] Iteration 742500, loss = 1.36648
I0526 04:47:48.544294 26891 solver.cpp:253]     Train net output #0: loss = 1.36648 (* 1 = 1.36648 loss)
I0526 04:47:48.544307 26891 sgd_solver.cpp:106] Iteration 742500, lr = 0.001
I0526 04:48:05.747488 26891 solver.cpp:237] Iteration 744000, loss = 1.54663
I0526 04:48:05.747643 26891 solver.cpp:253]     Train net output #0: loss = 1.54663 (* 1 = 1.54663 loss)
I0526 04:48:05.747658 26891 sgd_solver.cpp:106] Iteration 744000, lr = 0.001
I0526 04:48:22.954246 26891 solver.cpp:237] Iteration 745500, loss = 1.60521
I0526 04:48:22.954295 26891 solver.cpp:253]     Train net output #0: loss = 1.60521 (* 1 = 1.60521 loss)
I0526 04:48:22.954309 26891 sgd_solver.cpp:106] Iteration 745500, lr = 0.001
I0526 04:48:40.174949 26891 solver.cpp:237] Iteration 747000, loss = 1.6594
I0526 04:48:40.175124 26891 solver.cpp:253]     Train net output #0: loss = 1.65939 (* 1 = 1.65939 loss)
I0526 04:48:40.175138 26891 sgd_solver.cpp:106] Iteration 747000, lr = 0.001
I0526 04:48:57.370558 26891 solver.cpp:237] Iteration 748500, loss = 0.785599
I0526 04:48:57.370595 26891 solver.cpp:253]     Train net output #0: loss = 0.785597 (* 1 = 0.785597 loss)
I0526 04:48:57.370609 26891 sgd_solver.cpp:106] Iteration 748500, lr = 0.001
I0526 04:49:14.575923 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_750000.caffemodel
I0526 04:49:14.624274 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_750000.solverstate
I0526 04:49:14.651620 26891 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 04:50:34.847463 26891 solver.cpp:409]     Test net output #0: accuracy = 0.902432
I0526 04:50:34.847646 26891 solver.cpp:409]     Test net output #1: loss = 0.300471 (* 1 = 0.300471 loss)
I0526 04:50:55.733937 26891 solver.cpp:237] Iteration 750000, loss = 0.86288
I0526 04:50:55.733990 26891 solver.cpp:253]     Train net output #0: loss = 0.862878 (* 1 = 0.862878 loss)
I0526 04:50:55.734009 26891 sgd_solver.cpp:106] Iteration 750000, lr = 0.001
I0526 04:51:12.697674 26891 solver.cpp:237] Iteration 751500, loss = 1.28363
I0526 04:51:12.697845 26891 solver.cpp:253]     Train net output #0: loss = 1.28363 (* 1 = 1.28363 loss)
I0526 04:51:12.697860 26891 sgd_solver.cpp:106] Iteration 751500, lr = 0.001
I0526 04:51:29.672008 26891 solver.cpp:237] Iteration 753000, loss = 1.55014
I0526 04:51:29.672060 26891 solver.cpp:253]     Train net output #0: loss = 1.55014 (* 1 = 1.55014 loss)
I0526 04:51:29.672075 26891 sgd_solver.cpp:106] Iteration 753000, lr = 0.001
I0526 04:51:46.654757 26891 solver.cpp:237] Iteration 754500, loss = 1.41916
I0526 04:51:46.654917 26891 solver.cpp:253]     Train net output #0: loss = 1.41916 (* 1 = 1.41916 loss)
I0526 04:51:46.654930 26891 sgd_solver.cpp:106] Iteration 754500, lr = 0.001
I0526 04:52:03.619861 26891 solver.cpp:237] Iteration 756000, loss = 1.18098
I0526 04:52:03.619910 26891 solver.cpp:253]     Train net output #0: loss = 1.18098 (* 1 = 1.18098 loss)
I0526 04:52:03.619925 26891 sgd_solver.cpp:106] Iteration 756000, lr = 0.001
I0526 04:52:20.609943 26891 solver.cpp:237] Iteration 757500, loss = 0.940532
I0526 04:52:20.610118 26891 solver.cpp:253]     Train net output #0: loss = 0.940531 (* 1 = 0.940531 loss)
I0526 04:52:20.610133 26891 sgd_solver.cpp:106] Iteration 757500, lr = 0.001
I0526 04:52:37.591544 26891 solver.cpp:237] Iteration 759000, loss = 1.36701
I0526 04:52:37.591581 26891 solver.cpp:253]     Train net output #0: loss = 1.36701 (* 1 = 1.36701 loss)
I0526 04:52:37.591595 26891 sgd_solver.cpp:106] Iteration 759000, lr = 0.001
I0526 04:53:15.411728 26891 solver.cpp:237] Iteration 760500, loss = 1.38846
I0526 04:53:15.411926 26891 solver.cpp:253]     Train net output #0: loss = 1.38846 (* 1 = 1.38846 loss)
I0526 04:53:15.411942 26891 sgd_solver.cpp:106] Iteration 760500, lr = 0.001
I0526 04:53:32.381520 26891 solver.cpp:237] Iteration 762000, loss = 0.762432
I0526 04:53:32.381556 26891 solver.cpp:253]     Train net output #0: loss = 0.762431 (* 1 = 0.762431 loss)
I0526 04:53:32.381570 26891 sgd_solver.cpp:106] Iteration 762000, lr = 0.001
I0526 04:53:49.336135 26891 solver.cpp:237] Iteration 763500, loss = 0.762518
I0526 04:53:49.336320 26891 solver.cpp:253]     Train net output #0: loss = 0.762517 (* 1 = 0.762517 loss)
I0526 04:53:49.336338 26891 sgd_solver.cpp:106] Iteration 763500, lr = 0.001
I0526 04:54:06.278367 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_765000.caffemodel
I0526 04:54:06.325460 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_765000.solverstate
I0526 04:54:06.354337 26891 solver.cpp:237] Iteration 765000, loss = 0.590008
I0526 04:54:06.354384 26891 solver.cpp:253]     Train net output #0: loss = 0.590008 (* 1 = 0.590008 loss)
I0526 04:54:06.354401 26891 sgd_solver.cpp:106] Iteration 765000, lr = 0.001
I0526 04:54:23.324975 26891 solver.cpp:237] Iteration 766500, loss = 0.752234
I0526 04:54:23.325148 26891 solver.cpp:253]     Train net output #0: loss = 0.752233 (* 1 = 0.752233 loss)
I0526 04:54:23.325165 26891 sgd_solver.cpp:106] Iteration 766500, lr = 0.001
I0526 04:54:40.300454 26891 solver.cpp:237] Iteration 768000, loss = 1.23725
I0526 04:54:40.300503 26891 solver.cpp:253]     Train net output #0: loss = 1.23725 (* 1 = 1.23725 loss)
I0526 04:54:40.300518 26891 sgd_solver.cpp:106] Iteration 768000, lr = 0.001
I0526 04:54:57.280753 26891 solver.cpp:237] Iteration 769500, loss = 1.37631
I0526 04:54:57.280932 26891 solver.cpp:253]     Train net output #0: loss = 1.37631 (* 1 = 1.37631 loss)
I0526 04:54:57.280951 26891 sgd_solver.cpp:106] Iteration 769500, lr = 0.001
I0526 04:55:35.107175 26891 solver.cpp:237] Iteration 771000, loss = 1.42396
I0526 04:55:35.107362 26891 solver.cpp:253]     Train net output #0: loss = 1.42395 (* 1 = 1.42395 loss)
I0526 04:55:35.107378 26891 sgd_solver.cpp:106] Iteration 771000, lr = 0.001
I0526 04:55:52.067438 26891 solver.cpp:237] Iteration 772500, loss = 1.37146
I0526 04:55:52.067492 26891 solver.cpp:253]     Train net output #0: loss = 1.37146 (* 1 = 1.37146 loss)
I0526 04:55:52.067507 26891 sgd_solver.cpp:106] Iteration 772500, lr = 0.001
I0526 04:56:09.040606 26891 solver.cpp:237] Iteration 774000, loss = 1.34684
I0526 04:56:09.040781 26891 solver.cpp:253]     Train net output #0: loss = 1.34684 (* 1 = 1.34684 loss)
I0526 04:56:09.040796 26891 sgd_solver.cpp:106] Iteration 774000, lr = 0.001
I0526 04:56:26.028054 26891 solver.cpp:237] Iteration 775500, loss = 0.879139
I0526 04:56:26.028092 26891 solver.cpp:253]     Train net output #0: loss = 0.879137 (* 1 = 0.879137 loss)
I0526 04:56:26.028106 26891 sgd_solver.cpp:106] Iteration 775500, lr = 0.001
I0526 04:56:42.984500 26891 solver.cpp:237] Iteration 777000, loss = 1.13277
I0526 04:56:42.984678 26891 solver.cpp:253]     Train net output #0: loss = 1.13276 (* 1 = 1.13276 loss)
I0526 04:56:42.984691 26891 sgd_solver.cpp:106] Iteration 777000, lr = 0.001
I0526 04:56:59.980376 26891 solver.cpp:237] Iteration 778500, loss = 1.45395
I0526 04:56:59.980423 26891 solver.cpp:253]     Train net output #0: loss = 1.45395 (* 1 = 1.45395 loss)
I0526 04:56:59.980442 26891 sgd_solver.cpp:106] Iteration 778500, lr = 0.001
I0526 04:57:16.921564 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_780000.caffemodel
I0526 04:57:16.968204 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_780000.solverstate
I0526 04:57:16.993932 26891 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 04:58:15.985854 26891 solver.cpp:409]     Test net output #0: accuracy = 0.903353
I0526 04:58:15.986037 26891 solver.cpp:409]     Test net output #1: loss = 0.306573 (* 1 = 0.306573 loss)
I0526 04:58:36.829753 26891 solver.cpp:237] Iteration 780000, loss = 1.13054
I0526 04:58:36.829808 26891 solver.cpp:253]     Train net output #0: loss = 1.13054 (* 1 = 1.13054 loss)
I0526 04:58:36.829823 26891 sgd_solver.cpp:106] Iteration 780000, lr = 0.001
I0526 04:58:54.054462 26891 solver.cpp:237] Iteration 781500, loss = 1.88162
I0526 04:58:54.054628 26891 solver.cpp:253]     Train net output #0: loss = 1.88161 (* 1 = 1.88161 loss)
I0526 04:58:54.054642 26891 sgd_solver.cpp:106] Iteration 781500, lr = 0.001
I0526 04:59:11.242946 26891 solver.cpp:237] Iteration 783000, loss = 1.03371
I0526 04:59:11.242992 26891 solver.cpp:253]     Train net output #0: loss = 1.03371 (* 1 = 1.03371 loss)
I0526 04:59:11.243006 26891 sgd_solver.cpp:106] Iteration 783000, lr = 0.001
I0526 04:59:28.457042 26891 solver.cpp:237] Iteration 784500, loss = 0.975778
I0526 04:59:28.457214 26891 solver.cpp:253]     Train net output #0: loss = 0.975775 (* 1 = 0.975775 loss)
I0526 04:59:28.457228 26891 sgd_solver.cpp:106] Iteration 784500, lr = 0.001
I0526 04:59:45.673411 26891 solver.cpp:237] Iteration 786000, loss = 1.0386
I0526 04:59:45.673447 26891 solver.cpp:253]     Train net output #0: loss = 1.0386 (* 1 = 1.0386 loss)
I0526 04:59:45.673460 26891 sgd_solver.cpp:106] Iteration 786000, lr = 0.001
I0526 05:00:02.900635 26891 solver.cpp:237] Iteration 787500, loss = 1.27842
I0526 05:00:02.900807 26891 solver.cpp:253]     Train net output #0: loss = 1.27842 (* 1 = 1.27842 loss)
I0526 05:00:02.900821 26891 sgd_solver.cpp:106] Iteration 787500, lr = 0.001
I0526 05:00:20.113613 26891 solver.cpp:237] Iteration 789000, loss = 0.41413
I0526 05:00:20.113668 26891 solver.cpp:253]     Train net output #0: loss = 0.414126 (* 1 = 0.414126 loss)
I0526 05:00:20.113683 26891 sgd_solver.cpp:106] Iteration 789000, lr = 0.001
I0526 05:00:58.254173 26891 solver.cpp:237] Iteration 790500, loss = 1.62212
I0526 05:00:58.254357 26891 solver.cpp:253]     Train net output #0: loss = 1.62212 (* 1 = 1.62212 loss)
I0526 05:00:58.254375 26891 sgd_solver.cpp:106] Iteration 790500, lr = 0.001
I0526 05:01:15.446910 26891 solver.cpp:237] Iteration 792000, loss = 0.433036
I0526 05:01:15.446960 26891 solver.cpp:253]     Train net output #0: loss = 0.433032 (* 1 = 0.433032 loss)
I0526 05:01:15.446975 26891 sgd_solver.cpp:106] Iteration 792000, lr = 0.001
I0526 05:01:32.647235 26891 solver.cpp:237] Iteration 793500, loss = 1.12402
I0526 05:01:32.647418 26891 solver.cpp:253]     Train net output #0: loss = 1.12402 (* 1 = 1.12402 loss)
I0526 05:01:32.647431 26891 sgd_solver.cpp:106] Iteration 793500, lr = 0.001
I0526 05:01:49.820004 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_795000.caffemodel
I0526 05:01:49.866418 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_795000.solverstate
I0526 05:01:49.894803 26891 solver.cpp:237] Iteration 795000, loss = 1.25618
I0526 05:01:49.894845 26891 solver.cpp:253]     Train net output #0: loss = 1.25617 (* 1 = 1.25617 loss)
I0526 05:01:49.894860 26891 sgd_solver.cpp:106] Iteration 795000, lr = 0.001
I0526 05:02:07.100445 26891 solver.cpp:237] Iteration 796500, loss = 0.939571
I0526 05:02:07.100623 26891 solver.cpp:253]     Train net output #0: loss = 0.939566 (* 1 = 0.939566 loss)
I0526 05:02:07.100637 26891 sgd_solver.cpp:106] Iteration 796500, lr = 0.001
I0526 05:02:24.344210 26891 solver.cpp:237] Iteration 798000, loss = 0.734518
I0526 05:02:24.344264 26891 solver.cpp:253]     Train net output #0: loss = 0.734513 (* 1 = 0.734513 loss)
I0526 05:02:24.344279 26891 sgd_solver.cpp:106] Iteration 798000, lr = 0.001
I0526 05:02:41.558512 26891 solver.cpp:237] Iteration 799500, loss = 1.06503
I0526 05:02:41.558684 26891 solver.cpp:253]     Train net output #0: loss = 1.06502 (* 1 = 1.06502 loss)
I0526 05:02:41.558698 26891 sgd_solver.cpp:106] Iteration 799500, lr = 0.001
I0526 05:03:19.607532 26891 solver.cpp:237] Iteration 801000, loss = 0.86698
I0526 05:03:19.607719 26891 solver.cpp:253]     Train net output #0: loss = 0.866974 (* 1 = 0.866974 loss)
I0526 05:03:19.607733 26891 sgd_solver.cpp:106] Iteration 801000, lr = 0.001
I0526 05:03:36.853581 26891 solver.cpp:237] Iteration 802500, loss = 0.810635
I0526 05:03:36.853624 26891 solver.cpp:253]     Train net output #0: loss = 0.810629 (* 1 = 0.810629 loss)
I0526 05:03:36.853641 26891 sgd_solver.cpp:106] Iteration 802500, lr = 0.001
I0526 05:03:54.073717 26891 solver.cpp:237] Iteration 804000, loss = 1.26296
I0526 05:03:54.073874 26891 solver.cpp:253]     Train net output #0: loss = 1.26296 (* 1 = 1.26296 loss)
I0526 05:03:54.073887 26891 sgd_solver.cpp:106] Iteration 804000, lr = 0.001
I0526 05:04:11.308850 26891 solver.cpp:237] Iteration 805500, loss = 1.11734
I0526 05:04:11.308900 26891 solver.cpp:253]     Train net output #0: loss = 1.11733 (* 1 = 1.11733 loss)
I0526 05:04:11.308914 26891 sgd_solver.cpp:106] Iteration 805500, lr = 0.001
I0526 05:04:28.568403 26891 solver.cpp:237] Iteration 807000, loss = 1.43215
I0526 05:04:28.568583 26891 solver.cpp:253]     Train net output #0: loss = 1.43215 (* 1 = 1.43215 loss)
I0526 05:04:28.568596 26891 sgd_solver.cpp:106] Iteration 807000, lr = 0.001
I0526 05:04:45.779620 26891 solver.cpp:237] Iteration 808500, loss = 1.39038
I0526 05:04:45.779657 26891 solver.cpp:253]     Train net output #0: loss = 1.39037 (* 1 = 1.39037 loss)
I0526 05:04:45.779671 26891 sgd_solver.cpp:106] Iteration 808500, lr = 0.001
I0526 05:05:02.982038 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_810000.caffemodel
I0526 05:05:03.030000 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_810000.solverstate
I0526 05:05:03.056354 26891 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 05:06:23.208073 26891 solver.cpp:409]     Test net output #0: accuracy = 0.90352
I0526 05:06:23.208258 26891 solver.cpp:409]     Test net output #1: loss = 0.318371 (* 1 = 0.318371 loss)
I0526 05:06:44.098749 26891 solver.cpp:237] Iteration 810000, loss = 1.44183
I0526 05:06:44.098805 26891 solver.cpp:253]     Train net output #0: loss = 1.44182 (* 1 = 1.44182 loss)
I0526 05:06:44.098820 26891 sgd_solver.cpp:106] Iteration 810000, lr = 0.001
I0526 05:07:01.078512 26891 solver.cpp:237] Iteration 811500, loss = 0.956581
I0526 05:07:01.078697 26891 solver.cpp:253]     Train net output #0: loss = 0.956574 (* 1 = 0.956574 loss)
I0526 05:07:01.078714 26891 sgd_solver.cpp:106] Iteration 811500, lr = 0.001
I0526 05:07:18.052485 26891 solver.cpp:237] Iteration 813000, loss = 1.00703
I0526 05:07:18.052521 26891 solver.cpp:253]     Train net output #0: loss = 1.00702 (* 1 = 1.00702 loss)
I0526 05:07:18.052536 26891 sgd_solver.cpp:106] Iteration 813000, lr = 0.001
I0526 05:07:35.036463 26891 solver.cpp:237] Iteration 814500, loss = 1.29674
I0526 05:07:35.036638 26891 solver.cpp:253]     Train net output #0: loss = 1.29674 (* 1 = 1.29674 loss)
I0526 05:07:35.036653 26891 sgd_solver.cpp:106] Iteration 814500, lr = 0.001
I0526 05:07:52.011555 26891 solver.cpp:237] Iteration 816000, loss = 0.532082
I0526 05:07:52.011601 26891 solver.cpp:253]     Train net output #0: loss = 0.532075 (* 1 = 0.532075 loss)
I0526 05:07:52.011615 26891 sgd_solver.cpp:106] Iteration 816000, lr = 0.001
I0526 05:08:08.953191 26891 solver.cpp:237] Iteration 817500, loss = 0.984849
I0526 05:08:08.953372 26891 solver.cpp:253]     Train net output #0: loss = 0.984841 (* 1 = 0.984841 loss)
I0526 05:08:08.953387 26891 sgd_solver.cpp:106] Iteration 817500, lr = 0.001
I0526 05:08:25.930151 26891 solver.cpp:237] Iteration 819000, loss = 0.824488
I0526 05:08:25.930187 26891 solver.cpp:253]     Train net output #0: loss = 0.82448 (* 1 = 0.82448 loss)
I0526 05:08:25.930202 26891 sgd_solver.cpp:106] Iteration 819000, lr = 0.001
I0526 05:09:03.753505 26891 solver.cpp:237] Iteration 820500, loss = 2.25518
I0526 05:09:03.753690 26891 solver.cpp:253]     Train net output #0: loss = 2.25517 (* 1 = 2.25517 loss)
I0526 05:09:03.753705 26891 sgd_solver.cpp:106] Iteration 820500, lr = 0.001
I0526 05:09:20.671012 26891 solver.cpp:237] Iteration 822000, loss = 0.983957
I0526 05:09:20.671048 26891 solver.cpp:253]     Train net output #0: loss = 0.983949 (* 1 = 0.983949 loss)
I0526 05:09:20.671062 26891 sgd_solver.cpp:106] Iteration 822000, lr = 0.001
I0526 05:09:37.578642 26891 solver.cpp:237] Iteration 823500, loss = 0.482323
I0526 05:09:37.578816 26891 solver.cpp:253]     Train net output #0: loss = 0.482315 (* 1 = 0.482315 loss)
I0526 05:09:37.578831 26891 sgd_solver.cpp:106] Iteration 823500, lr = 0.001
I0526 05:09:54.421547 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_825000.caffemodel
I0526 05:09:54.470002 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_825000.solverstate
I0526 05:09:54.500721 26891 solver.cpp:237] Iteration 825000, loss = 1.10716
I0526 05:09:54.500773 26891 solver.cpp:253]     Train net output #0: loss = 1.10715 (* 1 = 1.10715 loss)
I0526 05:09:54.500792 26891 sgd_solver.cpp:106] Iteration 825000, lr = 0.001
I0526 05:10:11.412989 26891 solver.cpp:237] Iteration 826500, loss = 1.31789
I0526 05:10:11.413163 26891 solver.cpp:253]     Train net output #0: loss = 1.31789 (* 1 = 1.31789 loss)
I0526 05:10:11.413177 26891 sgd_solver.cpp:106] Iteration 826500, lr = 0.001
I0526 05:10:28.301923 26891 solver.cpp:237] Iteration 828000, loss = 1.18697
I0526 05:10:28.301977 26891 solver.cpp:253]     Train net output #0: loss = 1.18696 (* 1 = 1.18696 loss)
I0526 05:10:28.301991 26891 sgd_solver.cpp:106] Iteration 828000, lr = 0.001
I0526 05:10:45.165307 26891 solver.cpp:237] Iteration 829500, loss = 1.05106
I0526 05:10:45.165484 26891 solver.cpp:253]     Train net output #0: loss = 1.05106 (* 1 = 1.05106 loss)
I0526 05:10:45.165499 26891 sgd_solver.cpp:106] Iteration 829500, lr = 0.001
I0526 05:11:22.954818 26891 solver.cpp:237] Iteration 831000, loss = 1.16535
I0526 05:11:22.955006 26891 solver.cpp:253]     Train net output #0: loss = 1.16534 (* 1 = 1.16534 loss)
I0526 05:11:22.955020 26891 sgd_solver.cpp:106] Iteration 831000, lr = 0.001
I0526 05:11:39.838990 26891 solver.cpp:237] Iteration 832500, loss = 0.779015
I0526 05:11:39.839041 26891 solver.cpp:253]     Train net output #0: loss = 0.779008 (* 1 = 0.779008 loss)
I0526 05:11:39.839056 26891 sgd_solver.cpp:106] Iteration 832500, lr = 0.001
I0526 05:11:56.707728 26891 solver.cpp:237] Iteration 834000, loss = 1.20286
I0526 05:11:56.707903 26891 solver.cpp:253]     Train net output #0: loss = 1.20285 (* 1 = 1.20285 loss)
I0526 05:11:56.707917 26891 sgd_solver.cpp:106] Iteration 834000, lr = 0.001
I0526 05:12:13.589483 26891 solver.cpp:237] Iteration 835500, loss = 1.04716
I0526 05:12:13.589519 26891 solver.cpp:253]     Train net output #0: loss = 1.04715 (* 1 = 1.04715 loss)
I0526 05:12:13.589534 26891 sgd_solver.cpp:106] Iteration 835500, lr = 0.001
I0526 05:12:30.466156 26891 solver.cpp:237] Iteration 837000, loss = 1.4173
I0526 05:12:30.466331 26891 solver.cpp:253]     Train net output #0: loss = 1.41729 (* 1 = 1.41729 loss)
I0526 05:12:30.466344 26891 sgd_solver.cpp:106] Iteration 837000, lr = 0.001
I0526 05:12:47.363531 26891 solver.cpp:237] Iteration 838500, loss = 1.15401
I0526 05:12:47.363574 26891 solver.cpp:253]     Train net output #0: loss = 1.154 (* 1 = 1.154 loss)
I0526 05:12:47.363592 26891 sgd_solver.cpp:106] Iteration 838500, lr = 0.001
I0526 05:13:04.222098 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_840000.caffemodel
I0526 05:13:04.268597 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_840000.solverstate
I0526 05:13:04.293933 26891 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 05:14:03.532441 26891 solver.cpp:409]     Test net output #0: accuracy = 0.903426
I0526 05:14:03.532629 26891 solver.cpp:409]     Test net output #1: loss = 0.303929 (* 1 = 0.303929 loss)
I0526 05:14:24.422658 26891 solver.cpp:237] Iteration 840000, loss = 0.988021
I0526 05:14:24.422718 26891 solver.cpp:253]     Train net output #0: loss = 0.988014 (* 1 = 0.988014 loss)
I0526 05:14:24.422732 26891 sgd_solver.cpp:106] Iteration 840000, lr = 0.001
I0526 05:14:41.056010 26891 solver.cpp:237] Iteration 841500, loss = 1.31016
I0526 05:14:41.056179 26891 solver.cpp:253]     Train net output #0: loss = 1.31015 (* 1 = 1.31015 loss)
I0526 05:14:41.056191 26891 sgd_solver.cpp:106] Iteration 841500, lr = 0.001
I0526 05:14:57.703819 26891 solver.cpp:237] Iteration 843000, loss = 1.76225
I0526 05:14:57.703871 26891 solver.cpp:253]     Train net output #0: loss = 1.76225 (* 1 = 1.76225 loss)
I0526 05:14:57.703884 26891 sgd_solver.cpp:106] Iteration 843000, lr = 0.001
I0526 05:15:14.712131 26891 solver.cpp:237] Iteration 844500, loss = 1.33421
I0526 05:15:14.712314 26891 solver.cpp:253]     Train net output #0: loss = 1.3342 (* 1 = 1.3342 loss)
I0526 05:15:14.712328 26891 sgd_solver.cpp:106] Iteration 844500, lr = 0.001
I0526 05:15:31.779865 26891 solver.cpp:237] Iteration 846000, loss = 1.02215
I0526 05:15:31.779902 26891 solver.cpp:253]     Train net output #0: loss = 1.02214 (* 1 = 1.02214 loss)
I0526 05:15:31.779917 26891 sgd_solver.cpp:106] Iteration 846000, lr = 0.001
I0526 05:15:48.832945 26891 solver.cpp:237] Iteration 847500, loss = 1.0219
I0526 05:15:48.833135 26891 solver.cpp:253]     Train net output #0: loss = 1.0219 (* 1 = 1.0219 loss)
I0526 05:15:48.833149 26891 sgd_solver.cpp:106] Iteration 847500, lr = 0.001
I0526 05:16:05.900475 26891 solver.cpp:237] Iteration 849000, loss = 1.24663
I0526 05:16:05.900526 26891 solver.cpp:253]     Train net output #0: loss = 1.24662 (* 1 = 1.24662 loss)
I0526 05:16:05.900542 26891 sgd_solver.cpp:106] Iteration 849000, lr = 0.001
I0526 05:16:43.845983 26891 solver.cpp:237] Iteration 850500, loss = 1.33008
I0526 05:16:43.846173 26891 solver.cpp:253]     Train net output #0: loss = 1.33007 (* 1 = 1.33007 loss)
I0526 05:16:43.846187 26891 sgd_solver.cpp:106] Iteration 850500, lr = 0.001
I0526 05:17:00.886515 26891 solver.cpp:237] Iteration 852000, loss = 0.570758
I0526 05:17:00.886570 26891 solver.cpp:253]     Train net output #0: loss = 0.570753 (* 1 = 0.570753 loss)
I0526 05:17:00.886584 26891 sgd_solver.cpp:106] Iteration 852000, lr = 0.001
I0526 05:17:17.948951 26891 solver.cpp:237] Iteration 853500, loss = 0.737501
I0526 05:17:17.949123 26891 solver.cpp:253]     Train net output #0: loss = 0.737495 (* 1 = 0.737495 loss)
I0526 05:17:17.949137 26891 sgd_solver.cpp:106] Iteration 853500, lr = 0.001
I0526 05:17:34.970728 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_855000.caffemodel
I0526 05:17:35.015879 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_855000.solverstate
I0526 05:17:35.044579 26891 solver.cpp:237] Iteration 855000, loss = 0.880378
I0526 05:17:35.044628 26891 solver.cpp:253]     Train net output #0: loss = 0.880373 (* 1 = 0.880373 loss)
I0526 05:17:35.044643 26891 sgd_solver.cpp:106] Iteration 855000, lr = 0.001
I0526 05:17:52.099009 26891 solver.cpp:237] Iteration 856500, loss = 0.829706
I0526 05:17:52.099207 26891 solver.cpp:253]     Train net output #0: loss = 0.8297 (* 1 = 0.8297 loss)
I0526 05:17:52.099225 26891 sgd_solver.cpp:106] Iteration 856500, lr = 0.001
I0526 05:18:09.162902 26891 solver.cpp:237] Iteration 858000, loss = 1.08464
I0526 05:18:09.162952 26891 solver.cpp:253]     Train net output #0: loss = 1.08464 (* 1 = 1.08464 loss)
I0526 05:18:09.162966 26891 sgd_solver.cpp:106] Iteration 858000, lr = 0.001
I0526 05:18:26.205095 26891 solver.cpp:237] Iteration 859500, loss = 0.515539
I0526 05:18:26.205260 26891 solver.cpp:253]     Train net output #0: loss = 0.515533 (* 1 = 0.515533 loss)
I0526 05:18:26.205273 26891 sgd_solver.cpp:106] Iteration 859500, lr = 0.001
I0526 05:19:04.136782 26891 solver.cpp:237] Iteration 861000, loss = 1.38381
I0526 05:19:04.136970 26891 solver.cpp:253]     Train net output #0: loss = 1.38381 (* 1 = 1.38381 loss)
I0526 05:19:04.136983 26891 sgd_solver.cpp:106] Iteration 861000, lr = 0.001
I0526 05:19:21.188094 26891 solver.cpp:237] Iteration 862500, loss = 2.16371
I0526 05:19:21.188132 26891 solver.cpp:253]     Train net output #0: loss = 2.16371 (* 1 = 2.16371 loss)
I0526 05:19:21.188145 26891 sgd_solver.cpp:106] Iteration 862500, lr = 0.001
I0526 05:19:38.235234 26891 solver.cpp:237] Iteration 864000, loss = 1.44614
I0526 05:19:38.235407 26891 solver.cpp:253]     Train net output #0: loss = 1.44613 (* 1 = 1.44613 loss)
I0526 05:19:38.235421 26891 sgd_solver.cpp:106] Iteration 864000, lr = 0.001
I0526 05:19:55.266459 26891 solver.cpp:237] Iteration 865500, loss = 1.34291
I0526 05:19:55.266505 26891 solver.cpp:253]     Train net output #0: loss = 1.34291 (* 1 = 1.34291 loss)
I0526 05:19:55.266523 26891 sgd_solver.cpp:106] Iteration 865500, lr = 0.001
I0526 05:20:12.300791 26891 solver.cpp:237] Iteration 867000, loss = 1.12301
I0526 05:20:12.300956 26891 solver.cpp:253]     Train net output #0: loss = 1.12301 (* 1 = 1.12301 loss)
I0526 05:20:12.300968 26891 sgd_solver.cpp:106] Iteration 867000, lr = 0.001
I0526 05:20:29.385778 26891 solver.cpp:237] Iteration 868500, loss = 1.8185
I0526 05:20:29.385828 26891 solver.cpp:253]     Train net output #0: loss = 1.81849 (* 1 = 1.81849 loss)
I0526 05:20:29.385843 26891 sgd_solver.cpp:106] Iteration 868500, lr = 0.001
I0526 05:20:46.427824 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_870000.caffemodel
I0526 05:20:46.474139 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_870000.solverstate
I0526 05:20:46.499619 26891 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 05:22:06.622417 26891 solver.cpp:409]     Test net output #0: accuracy = 0.90021
I0526 05:22:06.622608 26891 solver.cpp:409]     Test net output #1: loss = 0.317052 (* 1 = 0.317052 loss)
I0526 05:22:27.495632 26891 solver.cpp:237] Iteration 870000, loss = 2.19947
I0526 05:22:27.495690 26891 solver.cpp:253]     Train net output #0: loss = 2.19947 (* 1 = 2.19947 loss)
I0526 05:22:27.495707 26891 sgd_solver.cpp:106] Iteration 870000, lr = 0.001
I0526 05:22:44.342005 26891 solver.cpp:237] Iteration 871500, loss = 0.597416
I0526 05:22:44.342175 26891 solver.cpp:253]     Train net output #0: loss = 0.597408 (* 1 = 0.597408 loss)
I0526 05:22:44.342190 26891 sgd_solver.cpp:106] Iteration 871500, lr = 0.001
I0526 05:23:01.207427 26891 solver.cpp:237] Iteration 873000, loss = 0.985418
I0526 05:23:01.207464 26891 solver.cpp:253]     Train net output #0: loss = 0.985411 (* 1 = 0.985411 loss)
I0526 05:23:01.207479 26891 sgd_solver.cpp:106] Iteration 873000, lr = 0.001
I0526 05:23:18.081459 26891 solver.cpp:237] Iteration 874500, loss = 0.819848
I0526 05:23:18.081650 26891 solver.cpp:253]     Train net output #0: loss = 0.81984 (* 1 = 0.81984 loss)
I0526 05:23:18.081663 26891 sgd_solver.cpp:106] Iteration 874500, lr = 0.001
I0526 05:23:34.940347 26891 solver.cpp:237] Iteration 876000, loss = 0.766464
I0526 05:23:34.940399 26891 solver.cpp:253]     Train net output #0: loss = 0.766456 (* 1 = 0.766456 loss)
I0526 05:23:34.940414 26891 sgd_solver.cpp:106] Iteration 876000, lr = 0.001
I0526 05:23:51.848006 26891 solver.cpp:237] Iteration 877500, loss = 1.25004
I0526 05:23:51.848172 26891 solver.cpp:253]     Train net output #0: loss = 1.25003 (* 1 = 1.25003 loss)
I0526 05:23:51.848186 26891 sgd_solver.cpp:106] Iteration 877500, lr = 0.001
I0526 05:24:08.656731 26891 solver.cpp:237] Iteration 879000, loss = 1.377
I0526 05:24:08.656780 26891 solver.cpp:253]     Train net output #0: loss = 1.37699 (* 1 = 1.37699 loss)
I0526 05:24:08.656795 26891 sgd_solver.cpp:106] Iteration 879000, lr = 0.001
I0526 05:24:46.433507 26891 solver.cpp:237] Iteration 880500, loss = 1.24496
I0526 05:24:46.433696 26891 solver.cpp:253]     Train net output #0: loss = 1.24495 (* 1 = 1.24495 loss)
I0526 05:24:46.433712 26891 sgd_solver.cpp:106] Iteration 880500, lr = 0.001
I0526 05:25:03.279063 26891 solver.cpp:237] Iteration 882000, loss = 0.675663
I0526 05:25:03.279119 26891 solver.cpp:253]     Train net output #0: loss = 0.675655 (* 1 = 0.675655 loss)
I0526 05:25:03.279134 26891 sgd_solver.cpp:106] Iteration 882000, lr = 0.001
I0526 05:25:20.138962 26891 solver.cpp:237] Iteration 883500, loss = 1.06754
I0526 05:25:20.139145 26891 solver.cpp:253]     Train net output #0: loss = 1.06753 (* 1 = 1.06753 loss)
I0526 05:25:20.139159 26891 sgd_solver.cpp:106] Iteration 883500, lr = 0.001
I0526 05:25:36.976246 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_885000.caffemodel
I0526 05:25:37.023680 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_885000.solverstate
I0526 05:25:37.054478 26891 solver.cpp:237] Iteration 885000, loss = 1.54374
I0526 05:25:37.054533 26891 solver.cpp:253]     Train net output #0: loss = 1.54373 (* 1 = 1.54373 loss)
I0526 05:25:37.054548 26891 sgd_solver.cpp:106] Iteration 885000, lr = 0.001
I0526 05:25:53.942100 26891 solver.cpp:237] Iteration 886500, loss = 1.12643
I0526 05:25:53.942286 26891 solver.cpp:253]     Train net output #0: loss = 1.12642 (* 1 = 1.12642 loss)
I0526 05:25:53.942303 26891 sgd_solver.cpp:106] Iteration 886500, lr = 0.001
I0526 05:26:10.840648 26891 solver.cpp:237] Iteration 888000, loss = 2.06465
I0526 05:26:10.840704 26891 solver.cpp:253]     Train net output #0: loss = 2.06464 (* 1 = 2.06464 loss)
I0526 05:26:10.840719 26891 sgd_solver.cpp:106] Iteration 888000, lr = 0.001
I0526 05:26:27.727350 26891 solver.cpp:237] Iteration 889500, loss = 0.944897
I0526 05:26:27.727519 26891 solver.cpp:253]     Train net output #0: loss = 0.944889 (* 1 = 0.944889 loss)
I0526 05:26:27.727535 26891 sgd_solver.cpp:106] Iteration 889500, lr = 0.001
I0526 05:27:05.559860 26891 solver.cpp:237] Iteration 891000, loss = 1.49521
I0526 05:27:05.560051 26891 solver.cpp:253]     Train net output #0: loss = 1.4952 (* 1 = 1.4952 loss)
I0526 05:27:05.560065 26891 sgd_solver.cpp:106] Iteration 891000, lr = 0.001
I0526 05:27:22.443722 26891 solver.cpp:237] Iteration 892500, loss = 1.46572
I0526 05:27:22.443773 26891 solver.cpp:253]     Train net output #0: loss = 1.46572 (* 1 = 1.46572 loss)
I0526 05:27:22.443786 26891 sgd_solver.cpp:106] Iteration 892500, lr = 0.001
I0526 05:27:39.304270 26891 solver.cpp:237] Iteration 894000, loss = 0.955889
I0526 05:27:39.304436 26891 solver.cpp:253]     Train net output #0: loss = 0.955882 (* 1 = 0.955882 loss)
I0526 05:27:39.304450 26891 sgd_solver.cpp:106] Iteration 894000, lr = 0.001
I0526 05:27:56.182327 26891 solver.cpp:237] Iteration 895500, loss = 1.48287
I0526 05:27:56.182371 26891 solver.cpp:253]     Train net output #0: loss = 1.48287 (* 1 = 1.48287 loss)
I0526 05:27:56.182385 26891 sgd_solver.cpp:106] Iteration 895500, lr = 0.001
I0526 05:28:13.019752 26891 solver.cpp:237] Iteration 897000, loss = 1.26326
I0526 05:28:13.019942 26891 solver.cpp:253]     Train net output #0: loss = 1.26325 (* 1 = 1.26325 loss)
I0526 05:28:13.019955 26891 sgd_solver.cpp:106] Iteration 897000, lr = 0.001
I0526 05:28:29.898193 26891 solver.cpp:237] Iteration 898500, loss = 0.705454
I0526 05:28:29.898231 26891 solver.cpp:253]     Train net output #0: loss = 0.705447 (* 1 = 0.705447 loss)
I0526 05:28:29.898244 26891 sgd_solver.cpp:106] Iteration 898500, lr = 0.001
I0526 05:28:46.826936 26891 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_900000.caffemodel
I0526 05:28:46.875473 26891 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0010_2016-05-20T15.48.49.668316_iter_900000.solverstate
I0526 05:28:46.902521 26891 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 05:29:46.280048 26891 solver.cpp:409]     Test net output #0: accuracy = 0.904413
I0526 05:29:46.280241 26891 solver.cpp:409]     Test net output #1: loss = 0.301667 (* 1 = 0.301667 loss)
I0526 05:30:07.177626 26891 solver.cpp:237] Iteration 900000, loss = 1.01042
I0526 05:30:07.177681 26891 solver.cpp:253]     Train net output #0: loss = 1.01041 (* 1 = 1.01041 loss)
I0526 05:30:07.177697 26891 sgd_solver.cpp:106] Iteration 900000, lr = 0.001
I0526 05:30:23.813048 26891 solver.cpp:237] Iteration 901500, loss = 0.753732
I0526 05:30:23.813238 26891 solver.cpp:253]     Train net output #0: loss = 0.753725 (* 1 = 0.753725 loss)
I0526 05:30:23.813253 26891 sgd_solver.cpp:106] Iteration 901500, lr = 0.001
aprun: Apid 11266733: Caught signal Terminated, sending to application
*** Aborted at 1464255030 (unix time) try "date -d @1464255030" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x6908) received by PID 26891 (TID 0x2aaac746f900) from PID 26888; stack trace: ***
=>> PBS: job killed: walltime 7215 exceeded limit 7200
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11266733: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11266733: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11266733: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11266733: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11266733: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
aprun: Apid 11266733: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03789] [c8-1c0s6n1] [Thu May 26 05:30:32 2016] PE RANK 0 exit signal Terminated
Application 11266733 exit codes: 143
Application 11266733 resources: utime ~6312s, stime ~892s, Rss ~5329936, inblocks ~10491400, outblocks ~474918
