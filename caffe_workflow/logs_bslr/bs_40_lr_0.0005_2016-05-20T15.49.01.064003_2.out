2813048
I0527 07:14:55.410156  2100 caffe.cpp:184] Using GPUs 0
I0527 07:14:55.836647  2100 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.0005
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003.prototxt"
I0527 07:14:55.838531  2100 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003.prototxt
I0527 07:14:55.855399  2100 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0527 07:14:55.855456  2100 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0527 07:14:55.855803  2100 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 07:14:55.855986  2100 layer_factory.hpp:77] Creating layer data_hdf5
I0527 07:14:55.856010  2100 net.cpp:106] Creating Layer data_hdf5
I0527 07:14:55.856024  2100 net.cpp:411] data_hdf5 -> data
I0527 07:14:55.856058  2100 net.cpp:411] data_hdf5 -> label
I0527 07:14:55.856091  2100 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0527 07:14:55.857491  2100 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0527 07:14:55.869813  2100 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0527 07:15:17.415628  2100 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0527 07:15:17.420727  2100 net.cpp:150] Setting up data_hdf5
I0527 07:15:17.420766  2100 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 07:15:17.420781  2100 net.cpp:157] Top shape: 40 (40)
I0527 07:15:17.420794  2100 net.cpp:165] Memory required for data: 1016160
I0527 07:15:17.420806  2100 layer_factory.hpp:77] Creating layer conv1
I0527 07:15:17.420840  2100 net.cpp:106] Creating Layer conv1
I0527 07:15:17.420851  2100 net.cpp:454] conv1 <- data
I0527 07:15:17.420871  2100 net.cpp:411] conv1 -> conv1
I0527 07:15:18.263165  2100 net.cpp:150] Setting up conv1
I0527 07:15:18.263207  2100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:15:18.263218  2100 net.cpp:165] Memory required for data: 12075360
I0527 07:15:18.263247  2100 layer_factory.hpp:77] Creating layer relu1
I0527 07:15:18.263268  2100 net.cpp:106] Creating Layer relu1
I0527 07:15:18.263279  2100 net.cpp:454] relu1 <- conv1
I0527 07:15:18.263293  2100 net.cpp:397] relu1 -> conv1 (in-place)
I0527 07:15:18.263815  2100 net.cpp:150] Setting up relu1
I0527 07:15:18.263839  2100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:15:18.263851  2100 net.cpp:165] Memory required for data: 23134560
I0527 07:15:18.263861  2100 layer_factory.hpp:77] Creating layer pool1
I0527 07:15:18.263878  2100 net.cpp:106] Creating Layer pool1
I0527 07:15:18.263888  2100 net.cpp:454] pool1 <- conv1
I0527 07:15:18.263901  2100 net.cpp:411] pool1 -> pool1
I0527 07:15:18.263983  2100 net.cpp:150] Setting up pool1
I0527 07:15:18.263996  2100 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 07:15:18.264005  2100 net.cpp:165] Memory required for data: 28664160
I0527 07:15:18.264016  2100 layer_factory.hpp:77] Creating layer conv2
I0527 07:15:18.264039  2100 net.cpp:106] Creating Layer conv2
I0527 07:15:18.264050  2100 net.cpp:454] conv2 <- pool1
I0527 07:15:18.264062  2100 net.cpp:411] conv2 -> conv2
I0527 07:15:18.266760  2100 net.cpp:150] Setting up conv2
I0527 07:15:18.266788  2100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:15:18.266799  2100 net.cpp:165] Memory required for data: 36612960
I0527 07:15:18.266819  2100 layer_factory.hpp:77] Creating layer relu2
I0527 07:15:18.266834  2100 net.cpp:106] Creating Layer relu2
I0527 07:15:18.266844  2100 net.cpp:454] relu2 <- conv2
I0527 07:15:18.266857  2100 net.cpp:397] relu2 -> conv2 (in-place)
I0527 07:15:18.267187  2100 net.cpp:150] Setting up relu2
I0527 07:15:18.267202  2100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:15:18.267212  2100 net.cpp:165] Memory required for data: 44561760
I0527 07:15:18.267222  2100 layer_factory.hpp:77] Creating layer pool2
I0527 07:15:18.267235  2100 net.cpp:106] Creating Layer pool2
I0527 07:15:18.267246  2100 net.cpp:454] pool2 <- conv2
I0527 07:15:18.267257  2100 net.cpp:411] pool2 -> pool2
I0527 07:15:18.267339  2100 net.cpp:150] Setting up pool2
I0527 07:15:18.267352  2100 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 07:15:18.267362  2100 net.cpp:165] Memory required for data: 48536160
I0527 07:15:18.267372  2100 layer_factory.hpp:77] Creating layer conv3
I0527 07:15:18.267390  2100 net.cpp:106] Creating Layer conv3
I0527 07:15:18.267401  2100 net.cpp:454] conv3 <- pool2
I0527 07:15:18.267415  2100 net.cpp:411] conv3 -> conv3
I0527 07:15:18.269363  2100 net.cpp:150] Setting up conv3
I0527 07:15:18.269387  2100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:15:18.269399  2100 net.cpp:165] Memory required for data: 52872800
I0527 07:15:18.269418  2100 layer_factory.hpp:77] Creating layer relu3
I0527 07:15:18.269433  2100 net.cpp:106] Creating Layer relu3
I0527 07:15:18.269443  2100 net.cpp:454] relu3 <- conv3
I0527 07:15:18.269456  2100 net.cpp:397] relu3 -> conv3 (in-place)
I0527 07:15:18.269930  2100 net.cpp:150] Setting up relu3
I0527 07:15:18.269948  2100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:15:18.269958  2100 net.cpp:165] Memory required for data: 57209440
I0527 07:15:18.269970  2100 layer_factory.hpp:77] Creating layer pool3
I0527 07:15:18.269982  2100 net.cpp:106] Creating Layer pool3
I0527 07:15:18.269992  2100 net.cpp:454] pool3 <- conv3
I0527 07:15:18.270005  2100 net.cpp:411] pool3 -> pool3
I0527 07:15:18.270073  2100 net.cpp:150] Setting up pool3
I0527 07:15:18.270087  2100 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 07:15:18.270097  2100 net.cpp:165] Memory required for data: 59377760
I0527 07:15:18.270107  2100 layer_factory.hpp:77] Creating layer conv4
I0527 07:15:18.270123  2100 net.cpp:106] Creating Layer conv4
I0527 07:15:18.270134  2100 net.cpp:454] conv4 <- pool3
I0527 07:15:18.270148  2100 net.cpp:411] conv4 -> conv4
I0527 07:15:18.272899  2100 net.cpp:150] Setting up conv4
I0527 07:15:18.272928  2100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:15:18.272938  2100 net.cpp:165] Memory required for data: 60829280
I0527 07:15:18.272953  2100 layer_factory.hpp:77] Creating layer relu4
I0527 07:15:18.272969  2100 net.cpp:106] Creating Layer relu4
I0527 07:15:18.272979  2100 net.cpp:454] relu4 <- conv4
I0527 07:15:18.272991  2100 net.cpp:397] relu4 -> conv4 (in-place)
I0527 07:15:18.273474  2100 net.cpp:150] Setting up relu4
I0527 07:15:18.273491  2100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:15:18.273502  2100 net.cpp:165] Memory required for data: 62280800
I0527 07:15:18.273512  2100 layer_factory.hpp:77] Creating layer pool4
I0527 07:15:18.273525  2100 net.cpp:106] Creating Layer pool4
I0527 07:15:18.273535  2100 net.cpp:454] pool4 <- conv4
I0527 07:15:18.273548  2100 net.cpp:411] pool4 -> pool4
I0527 07:15:18.273617  2100 net.cpp:150] Setting up pool4
I0527 07:15:18.273630  2100 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 07:15:18.273638  2100 net.cpp:165] Memory required for data: 63006560
I0527 07:15:18.273649  2100 layer_factory.hpp:77] Creating layer ip1
I0527 07:15:18.273669  2100 net.cpp:106] Creating Layer ip1
I0527 07:15:18.273679  2100 net.cpp:454] ip1 <- pool4
I0527 07:15:18.273692  2100 net.cpp:411] ip1 -> ip1
I0527 07:15:18.289131  2100 net.cpp:150] Setting up ip1
I0527 07:15:18.289160  2100 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:15:18.289172  2100 net.cpp:165] Memory required for data: 63037920
I0527 07:15:18.289194  2100 layer_factory.hpp:77] Creating layer relu5
I0527 07:15:18.289209  2100 net.cpp:106] Creating Layer relu5
I0527 07:15:18.289219  2100 net.cpp:454] relu5 <- ip1
I0527 07:15:18.289232  2100 net.cpp:397] relu5 -> ip1 (in-place)
I0527 07:15:18.289582  2100 net.cpp:150] Setting up relu5
I0527 07:15:18.289595  2100 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:15:18.289607  2100 net.cpp:165] Memory required for data: 63069280
I0527 07:15:18.289616  2100 layer_factory.hpp:77] Creating layer drop1
I0527 07:15:18.289638  2100 net.cpp:106] Creating Layer drop1
I0527 07:15:18.289649  2100 net.cpp:454] drop1 <- ip1
I0527 07:15:18.289660  2100 net.cpp:397] drop1 -> ip1 (in-place)
I0527 07:15:18.289721  2100 net.cpp:150] Setting up drop1
I0527 07:15:18.289734  2100 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:15:18.289744  2100 net.cpp:165] Memory required for data: 63100640
I0527 07:15:18.289753  2100 layer_factory.hpp:77] Creating layer ip2
I0527 07:15:18.289772  2100 net.cpp:106] Creating Layer ip2
I0527 07:15:18.289783  2100 net.cpp:454] ip2 <- ip1
I0527 07:15:18.289795  2100 net.cpp:411] ip2 -> ip2
I0527 07:15:18.290257  2100 net.cpp:150] Setting up ip2
I0527 07:15:18.290271  2100 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:15:18.290280  2100 net.cpp:165] Memory required for data: 63116320
I0527 07:15:18.290295  2100 layer_factory.hpp:77] Creating layer relu6
I0527 07:15:18.290309  2100 net.cpp:106] Creating Layer relu6
I0527 07:15:18.290318  2100 net.cpp:454] relu6 <- ip2
I0527 07:15:18.290331  2100 net.cpp:397] relu6 -> ip2 (in-place)
I0527 07:15:18.290851  2100 net.cpp:150] Setting up relu6
I0527 07:15:18.290868  2100 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:15:18.290879  2100 net.cpp:165] Memory required for data: 63132000
I0527 07:15:18.290889  2100 layer_factory.hpp:77] Creating layer drop2
I0527 07:15:18.290902  2100 net.cpp:106] Creating Layer drop2
I0527 07:15:18.290912  2100 net.cpp:454] drop2 <- ip2
I0527 07:15:18.290925  2100 net.cpp:397] drop2 -> ip2 (in-place)
I0527 07:15:18.290968  2100 net.cpp:150] Setting up drop2
I0527 07:15:18.290982  2100 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:15:18.290992  2100 net.cpp:165] Memory required for data: 63147680
I0527 07:15:18.291002  2100 layer_factory.hpp:77] Creating layer ip3
I0527 07:15:18.291015  2100 net.cpp:106] Creating Layer ip3
I0527 07:15:18.291025  2100 net.cpp:454] ip3 <- ip2
I0527 07:15:18.291038  2100 net.cpp:411] ip3 -> ip3
I0527 07:15:18.291250  2100 net.cpp:150] Setting up ip3
I0527 07:15:18.291263  2100 net.cpp:157] Top shape: 40 11 (440)
I0527 07:15:18.291273  2100 net.cpp:165] Memory required for data: 63149440
I0527 07:15:18.291290  2100 layer_factory.hpp:77] Creating layer drop3
I0527 07:15:18.291302  2100 net.cpp:106] Creating Layer drop3
I0527 07:15:18.291311  2100 net.cpp:454] drop3 <- ip3
I0527 07:15:18.291323  2100 net.cpp:397] drop3 -> ip3 (in-place)
I0527 07:15:18.291363  2100 net.cpp:150] Setting up drop3
I0527 07:15:18.291376  2100 net.cpp:157] Top shape: 40 11 (440)
I0527 07:15:18.291385  2100 net.cpp:165] Memory required for data: 63151200
I0527 07:15:18.291395  2100 layer_factory.hpp:77] Creating layer loss
I0527 07:15:18.291414  2100 net.cpp:106] Creating Layer loss
I0527 07:15:18.291424  2100 net.cpp:454] loss <- ip3
I0527 07:15:18.291434  2100 net.cpp:454] loss <- label
I0527 07:15:18.291446  2100 net.cpp:411] loss -> loss
I0527 07:15:18.291463  2100 layer_factory.hpp:77] Creating layer loss
I0527 07:15:18.292106  2100 net.cpp:150] Setting up loss
I0527 07:15:18.292126  2100 net.cpp:157] Top shape: (1)
I0527 07:15:18.292140  2100 net.cpp:160]     with loss weight 1
I0527 07:15:18.292182  2100 net.cpp:165] Memory required for data: 63151204
I0527 07:15:18.292192  2100 net.cpp:226] loss needs backward computation.
I0527 07:15:18.292203  2100 net.cpp:226] drop3 needs backward computation.
I0527 07:15:18.292212  2100 net.cpp:226] ip3 needs backward computation.
I0527 07:15:18.292223  2100 net.cpp:226] drop2 needs backward computation.
I0527 07:15:18.292232  2100 net.cpp:226] relu6 needs backward computation.
I0527 07:15:18.292242  2100 net.cpp:226] ip2 needs backward computation.
I0527 07:15:18.292251  2100 net.cpp:226] drop1 needs backward computation.
I0527 07:15:18.292261  2100 net.cpp:226] relu5 needs backward computation.
I0527 07:15:18.292270  2100 net.cpp:226] ip1 needs backward computation.
I0527 07:15:18.292281  2100 net.cpp:226] pool4 needs backward computation.
I0527 07:15:18.292291  2100 net.cpp:226] relu4 needs backward computation.
I0527 07:15:18.292301  2100 net.cpp:226] conv4 needs backward computation.
I0527 07:15:18.292312  2100 net.cpp:226] pool3 needs backward computation.
I0527 07:15:18.292322  2100 net.cpp:226] relu3 needs backward computation.
I0527 07:15:18.292332  2100 net.cpp:226] conv3 needs backward computation.
I0527 07:15:18.292351  2100 net.cpp:226] pool2 needs backward computation.
I0527 07:15:18.292362  2100 net.cpp:226] relu2 needs backward computation.
I0527 07:15:18.292372  2100 net.cpp:226] conv2 needs backward computation.
I0527 07:15:18.292384  2100 net.cpp:226] pool1 needs backward computation.
I0527 07:15:18.292394  2100 net.cpp:226] relu1 needs backward computation.
I0527 07:15:18.292404  2100 net.cpp:226] conv1 needs backward computation.
I0527 07:15:18.292415  2100 net.cpp:228] data_hdf5 does not need backward computation.
I0527 07:15:18.292425  2100 net.cpp:270] This network produces output loss
I0527 07:15:18.292449  2100 net.cpp:283] Network initialization done.
I0527 07:15:18.294435  2100 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003.prototxt
I0527 07:15:18.294508  2100 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0527 07:15:18.294864  2100 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 07:15:18.295055  2100 layer_factory.hpp:77] Creating layer data_hdf5
I0527 07:15:18.295070  2100 net.cpp:106] Creating Layer data_hdf5
I0527 07:15:18.295083  2100 net.cpp:411] data_hdf5 -> data
I0527 07:15:18.295100  2100 net.cpp:411] data_hdf5 -> label
I0527 07:15:18.295116  2100 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0527 07:15:18.305600  2100 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0527 07:15:39.649798  2100 net.cpp:150] Setting up data_hdf5
I0527 07:15:39.649965  2100 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 07:15:39.649978  2100 net.cpp:157] Top shape: 40 (40)
I0527 07:15:39.649989  2100 net.cpp:165] Memory required for data: 1016160
I0527 07:15:39.650003  2100 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0527 07:15:39.650032  2100 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0527 07:15:39.650043  2100 net.cpp:454] label_data_hdf5_1_split <- label
I0527 07:15:39.650058  2100 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0527 07:15:39.650079  2100 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0527 07:15:39.650152  2100 net.cpp:150] Setting up label_data_hdf5_1_split
I0527 07:15:39.650166  2100 net.cpp:157] Top shape: 40 (40)
I0527 07:15:39.650178  2100 net.cpp:157] Top shape: 40 (40)
I0527 07:15:39.650188  2100 net.cpp:165] Memory required for data: 1016480
I0527 07:15:39.650198  2100 layer_factory.hpp:77] Creating layer conv1
I0527 07:15:39.650219  2100 net.cpp:106] Creating Layer conv1
I0527 07:15:39.650229  2100 net.cpp:454] conv1 <- data
I0527 07:15:39.650244  2100 net.cpp:411] conv1 -> conv1
I0527 07:15:39.652186  2100 net.cpp:150] Setting up conv1
I0527 07:15:39.652211  2100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:15:39.652222  2100 net.cpp:165] Memory required for data: 12075680
I0527 07:15:39.652243  2100 layer_factory.hpp:77] Creating layer relu1
I0527 07:15:39.652258  2100 net.cpp:106] Creating Layer relu1
I0527 07:15:39.652268  2100 net.cpp:454] relu1 <- conv1
I0527 07:15:39.652281  2100 net.cpp:397] relu1 -> conv1 (in-place)
I0527 07:15:39.652778  2100 net.cpp:150] Setting up relu1
I0527 07:15:39.652796  2100 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:15:39.652806  2100 net.cpp:165] Memory required for data: 23134880
I0527 07:15:39.652815  2100 layer_factory.hpp:77] Creating layer pool1
I0527 07:15:39.652832  2100 net.cpp:106] Creating Layer pool1
I0527 07:15:39.652842  2100 net.cpp:454] pool1 <- conv1
I0527 07:15:39.652854  2100 net.cpp:411] pool1 -> pool1
I0527 07:15:39.652930  2100 net.cpp:150] Setting up pool1
I0527 07:15:39.652943  2100 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 07:15:39.652953  2100 net.cpp:165] Memory required for data: 28664480
I0527 07:15:39.652963  2100 layer_factory.hpp:77] Creating layer conv2
I0527 07:15:39.652981  2100 net.cpp:106] Creating Layer conv2
I0527 07:15:39.652992  2100 net.cpp:454] conv2 <- pool1
I0527 07:15:39.653007  2100 net.cpp:411] conv2 -> conv2
I0527 07:15:39.654947  2100 net.cpp:150] Setting up conv2
I0527 07:15:39.654969  2100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:15:39.654979  2100 net.cpp:165] Memory required for data: 36613280
I0527 07:15:39.654997  2100 layer_factory.hpp:77] Creating layer relu2
I0527 07:15:39.655011  2100 net.cpp:106] Creating Layer relu2
I0527 07:15:39.655021  2100 net.cpp:454] relu2 <- conv2
I0527 07:15:39.655035  2100 net.cpp:397] relu2 -> conv2 (in-place)
I0527 07:15:39.655369  2100 net.cpp:150] Setting up relu2
I0527 07:15:39.655383  2100 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:15:39.655393  2100 net.cpp:165] Memory required for data: 44562080
I0527 07:15:39.655403  2100 layer_factory.hpp:77] Creating layer pool2
I0527 07:15:39.655416  2100 net.cpp:106] Creating Layer pool2
I0527 07:15:39.655426  2100 net.cpp:454] pool2 <- conv2
I0527 07:15:39.655439  2100 net.cpp:411] pool2 -> pool2
I0527 07:15:39.655510  2100 net.cpp:150] Setting up pool2
I0527 07:15:39.655524  2100 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 07:15:39.655534  2100 net.cpp:165] Memory required for data: 48536480
I0527 07:15:39.655544  2100 layer_factory.hpp:77] Creating layer conv3
I0527 07:15:39.655563  2100 net.cpp:106] Creating Layer conv3
I0527 07:15:39.655575  2100 net.cpp:454] conv3 <- pool2
I0527 07:15:39.655587  2100 net.cpp:411] conv3 -> conv3
I0527 07:15:39.657567  2100 net.cpp:150] Setting up conv3
I0527 07:15:39.657590  2100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:15:39.657603  2100 net.cpp:165] Memory required for data: 52873120
I0527 07:15:39.657635  2100 layer_factory.hpp:77] Creating layer relu3
I0527 07:15:39.657649  2100 net.cpp:106] Creating Layer relu3
I0527 07:15:39.657660  2100 net.cpp:454] relu3 <- conv3
I0527 07:15:39.657671  2100 net.cpp:397] relu3 -> conv3 (in-place)
I0527 07:15:39.658149  2100 net.cpp:150] Setting up relu3
I0527 07:15:39.658166  2100 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:15:39.658176  2100 net.cpp:165] Memory required for data: 57209760
I0527 07:15:39.658186  2100 layer_factory.hpp:77] Creating layer pool3
I0527 07:15:39.658200  2100 net.cpp:106] Creating Layer pool3
I0527 07:15:39.658210  2100 net.cpp:454] pool3 <- conv3
I0527 07:15:39.658222  2100 net.cpp:411] pool3 -> pool3
I0527 07:15:39.658295  2100 net.cpp:150] Setting up pool3
I0527 07:15:39.658308  2100 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 07:15:39.658318  2100 net.cpp:165] Memory required for data: 59378080
I0527 07:15:39.658327  2100 layer_factory.hpp:77] Creating layer conv4
I0527 07:15:39.658344  2100 net.cpp:106] Creating Layer conv4
I0527 07:15:39.658355  2100 net.cpp:454] conv4 <- pool3
I0527 07:15:39.658368  2100 net.cpp:411] conv4 -> conv4
I0527 07:15:39.660420  2100 net.cpp:150] Setting up conv4
I0527 07:15:39.660444  2100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:15:39.660456  2100 net.cpp:165] Memory required for data: 60829600
I0527 07:15:39.660471  2100 layer_factory.hpp:77] Creating layer relu4
I0527 07:15:39.660485  2100 net.cpp:106] Creating Layer relu4
I0527 07:15:39.660495  2100 net.cpp:454] relu4 <- conv4
I0527 07:15:39.660508  2100 net.cpp:397] relu4 -> conv4 (in-place)
I0527 07:15:39.660981  2100 net.cpp:150] Setting up relu4
I0527 07:15:39.660997  2100 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:15:39.661007  2100 net.cpp:165] Memory required for data: 62281120
I0527 07:15:39.661017  2100 layer_factory.hpp:77] Creating layer pool4
I0527 07:15:39.661031  2100 net.cpp:106] Creating Layer pool4
I0527 07:15:39.661041  2100 net.cpp:454] pool4 <- conv4
I0527 07:15:39.661054  2100 net.cpp:411] pool4 -> pool4
I0527 07:15:39.661125  2100 net.cpp:150] Setting up pool4
I0527 07:15:39.661139  2100 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 07:15:39.661149  2100 net.cpp:165] Memory required for data: 63006880
I0527 07:15:39.661160  2100 layer_factory.hpp:77] Creating layer ip1
I0527 07:15:39.661175  2100 net.cpp:106] Creating Layer ip1
I0527 07:15:39.661185  2100 net.cpp:454] ip1 <- pool4
I0527 07:15:39.661201  2100 net.cpp:411] ip1 -> ip1
I0527 07:15:39.676590  2100 net.cpp:150] Setting up ip1
I0527 07:15:39.676619  2100 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:15:39.676630  2100 net.cpp:165] Memory required for data: 63038240
I0527 07:15:39.676651  2100 layer_factory.hpp:77] Creating layer relu5
I0527 07:15:39.676666  2100 net.cpp:106] Creating Layer relu5
I0527 07:15:39.676677  2100 net.cpp:454] relu5 <- ip1
I0527 07:15:39.676692  2100 net.cpp:397] relu5 -> ip1 (in-place)
I0527 07:15:39.677038  2100 net.cpp:150] Setting up relu5
I0527 07:15:39.677053  2100 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:15:39.677064  2100 net.cpp:165] Memory required for data: 63069600
I0527 07:15:39.677074  2100 layer_factory.hpp:77] Creating layer drop1
I0527 07:15:39.677094  2100 net.cpp:106] Creating Layer drop1
I0527 07:15:39.677104  2100 net.cpp:454] drop1 <- ip1
I0527 07:15:39.677117  2100 net.cpp:397] drop1 -> ip1 (in-place)
I0527 07:15:39.677163  2100 net.cpp:150] Setting up drop1
I0527 07:15:39.677176  2100 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:15:39.677186  2100 net.cpp:165] Memory required for data: 63100960
I0527 07:15:39.677196  2100 layer_factory.hpp:77] Creating layer ip2
I0527 07:15:39.677211  2100 net.cpp:106] Creating Layer ip2
I0527 07:15:39.677222  2100 net.cpp:454] ip2 <- ip1
I0527 07:15:39.677233  2100 net.cpp:411] ip2 -> ip2
I0527 07:15:39.677722  2100 net.cpp:150] Setting up ip2
I0527 07:15:39.677736  2100 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:15:39.677747  2100 net.cpp:165] Memory required for data: 63116640
I0527 07:15:39.677762  2100 layer_factory.hpp:77] Creating layer relu6
I0527 07:15:39.677788  2100 net.cpp:106] Creating Layer relu6
I0527 07:15:39.677798  2100 net.cpp:454] relu6 <- ip2
I0527 07:15:39.677811  2100 net.cpp:397] relu6 -> ip2 (in-place)
I0527 07:15:39.678349  2100 net.cpp:150] Setting up relu6
I0527 07:15:39.678371  2100 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:15:39.678382  2100 net.cpp:165] Memory required for data: 63132320
I0527 07:15:39.678392  2100 layer_factory.hpp:77] Creating layer drop2
I0527 07:15:39.678406  2100 net.cpp:106] Creating Layer drop2
I0527 07:15:39.678416  2100 net.cpp:454] drop2 <- ip2
I0527 07:15:39.678428  2100 net.cpp:397] drop2 -> ip2 (in-place)
I0527 07:15:39.678473  2100 net.cpp:150] Setting up drop2
I0527 07:15:39.678486  2100 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:15:39.678496  2100 net.cpp:165] Memory required for data: 63148000
I0527 07:15:39.678505  2100 layer_factory.hpp:77] Creating layer ip3
I0527 07:15:39.678520  2100 net.cpp:106] Creating Layer ip3
I0527 07:15:39.678529  2100 net.cpp:454] ip3 <- ip2
I0527 07:15:39.678544  2100 net.cpp:411] ip3 -> ip3
I0527 07:15:39.678768  2100 net.cpp:150] Setting up ip3
I0527 07:15:39.678782  2100 net.cpp:157] Top shape: 40 11 (440)
I0527 07:15:39.678792  2100 net.cpp:165] Memory required for data: 63149760
I0527 07:15:39.678807  2100 layer_factory.hpp:77] Creating layer drop3
I0527 07:15:39.678820  2100 net.cpp:106] Creating Layer drop3
I0527 07:15:39.678830  2100 net.cpp:454] drop3 <- ip3
I0527 07:15:39.678843  2100 net.cpp:397] drop3 -> ip3 (in-place)
I0527 07:15:39.678884  2100 net.cpp:150] Setting up drop3
I0527 07:15:39.678897  2100 net.cpp:157] Top shape: 40 11 (440)
I0527 07:15:39.678907  2100 net.cpp:165] Memory required for data: 63151520
I0527 07:15:39.678917  2100 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0527 07:15:39.678930  2100 net.cpp:106] Creating Layer ip3_drop3_0_split
I0527 07:15:39.678941  2100 net.cpp:454] ip3_drop3_0_split <- ip3
I0527 07:15:39.678953  2100 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0527 07:15:39.678968  2100 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0527 07:15:39.679044  2100 net.cpp:150] Setting up ip3_drop3_0_split
I0527 07:15:39.679056  2100 net.cpp:157] Top shape: 40 11 (440)
I0527 07:15:39.679069  2100 net.cpp:157] Top shape: 40 11 (440)
I0527 07:15:39.679078  2100 net.cpp:165] Memory required for data: 63155040
I0527 07:15:39.679090  2100 layer_factory.hpp:77] Creating layer accuracy
I0527 07:15:39.679111  2100 net.cpp:106] Creating Layer accuracy
I0527 07:15:39.679121  2100 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0527 07:15:39.679131  2100 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0527 07:15:39.679146  2100 net.cpp:411] accuracy -> accuracy
I0527 07:15:39.679169  2100 net.cpp:150] Setting up accuracy
I0527 07:15:39.679183  2100 net.cpp:157] Top shape: (1)
I0527 07:15:39.679193  2100 net.cpp:165] Memory required for data: 63155044
I0527 07:15:39.679203  2100 layer_factory.hpp:77] Creating layer loss
I0527 07:15:39.679216  2100 net.cpp:106] Creating Layer loss
I0527 07:15:39.679226  2100 net.cpp:454] loss <- ip3_drop3_0_split_1
I0527 07:15:39.679237  2100 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0527 07:15:39.679250  2100 net.cpp:411] loss -> loss
I0527 07:15:39.679268  2100 layer_factory.hpp:77] Creating layer loss
I0527 07:15:39.679755  2100 net.cpp:150] Setting up loss
I0527 07:15:39.679769  2100 net.cpp:157] Top shape: (1)
I0527 07:15:39.679780  2100 net.cpp:160]     with loss weight 1
I0527 07:15:39.679797  2100 net.cpp:165] Memory required for data: 63155048
I0527 07:15:39.679808  2100 net.cpp:226] loss needs backward computation.
I0527 07:15:39.679819  2100 net.cpp:228] accuracy does not need backward computation.
I0527 07:15:39.679831  2100 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0527 07:15:39.679841  2100 net.cpp:226] drop3 needs backward computation.
I0527 07:15:39.679852  2100 net.cpp:226] ip3 needs backward computation.
I0527 07:15:39.679862  2100 net.cpp:226] drop2 needs backward computation.
I0527 07:15:39.679872  2100 net.cpp:226] relu6 needs backward computation.
I0527 07:15:39.679889  2100 net.cpp:226] ip2 needs backward computation.
I0527 07:15:39.679899  2100 net.cpp:226] drop1 needs backward computation.
I0527 07:15:39.679909  2100 net.cpp:226] relu5 needs backward computation.
I0527 07:15:39.679919  2100 net.cpp:226] ip1 needs backward computation.
I0527 07:15:39.679929  2100 net.cpp:226] pool4 needs backward computation.
I0527 07:15:39.679939  2100 net.cpp:226] relu4 needs backward computation.
I0527 07:15:39.679949  2100 net.cpp:226] conv4 needs backward computation.
I0527 07:15:39.679960  2100 net.cpp:226] pool3 needs backward computation.
I0527 07:15:39.679970  2100 net.cpp:226] relu3 needs backward computation.
I0527 07:15:39.679981  2100 net.cpp:226] conv3 needs backward computation.
I0527 07:15:39.679991  2100 net.cpp:226] pool2 needs backward computation.
I0527 07:15:39.680001  2100 net.cpp:226] relu2 needs backward computation.
I0527 07:15:39.680011  2100 net.cpp:226] conv2 needs backward computation.
I0527 07:15:39.680022  2100 net.cpp:226] pool1 needs backward computation.
I0527 07:15:39.680032  2100 net.cpp:226] relu1 needs backward computation.
I0527 07:15:39.680042  2100 net.cpp:226] conv1 needs backward computation.
I0527 07:15:39.680053  2100 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0527 07:15:39.680065  2100 net.cpp:228] data_hdf5 does not need backward computation.
I0527 07:15:39.680075  2100 net.cpp:270] This network produces output accuracy
I0527 07:15:39.680085  2100 net.cpp:270] This network produces output loss
I0527 07:15:39.680114  2100 net.cpp:283] Network initialization done.
I0527 07:15:39.680248  2100 solver.cpp:60] Solver scaffolding done.
I0527 07:15:39.681402  2100 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_168750.solverstate
I0527 07:15:39.928145  2100 sgd_solver.cpp:318] SGDSolver: restoring history
I0527 07:15:39.933789  2100 caffe.cpp:212] Starting Optimization
I0527 07:15:39.933826  2100 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0527 07:15:39.933838  2100 solver.cpp:289] Learning Rate Policy: fixed
I0527 07:15:39.960886  2100 solver.cpp:237] Iteration 168750, loss = 1.18008
I0527 07:15:39.960930  2100 solver.cpp:253]     Train net output #0: loss = 1.18008 (* 1 = 1.18008 loss)
I0527 07:15:39.960948  2100 sgd_solver.cpp:106] Iteration 168750, lr = 0.0005
I0527 07:15:49.698606  2100 solver.cpp:237] Iteration 169125, loss = 1.01471
I0527 07:15:49.698643  2100 solver.cpp:253]     Train net output #0: loss = 1.01471 (* 1 = 1.01471 loss)
I0527 07:15:49.698657  2100 sgd_solver.cpp:106] Iteration 169125, lr = 0.0005
I0527 07:15:59.419405  2100 solver.cpp:237] Iteration 169500, loss = 1.26074
I0527 07:15:59.419442  2100 solver.cpp:253]     Train net output #0: loss = 1.26074 (* 1 = 1.26074 loss)
I0527 07:15:59.419456  2100 sgd_solver.cpp:106] Iteration 169500, lr = 0.0005
I0527 07:16:09.121281  2100 solver.cpp:237] Iteration 169875, loss = 1.13841
I0527 07:16:09.121325  2100 solver.cpp:253]     Train net output #0: loss = 1.13841 (* 1 = 1.13841 loss)
I0527 07:16:09.121340  2100 sgd_solver.cpp:106] Iteration 169875, lr = 0.0005
I0527 07:16:18.828280  2100 solver.cpp:237] Iteration 170250, loss = 1.19204
I0527 07:16:18.828431  2100 solver.cpp:253]     Train net output #0: loss = 1.19204 (* 1 = 1.19204 loss)
I0527 07:16:18.828445  2100 sgd_solver.cpp:106] Iteration 170250, lr = 0.0005
I0527 07:16:28.539958  2100 solver.cpp:237] Iteration 170625, loss = 1.14427
I0527 07:16:28.539993  2100 solver.cpp:253]     Train net output #0: loss = 1.14427 (* 1 = 1.14427 loss)
I0527 07:16:28.540005  2100 sgd_solver.cpp:106] Iteration 170625, lr = 0.0005
I0527 07:16:38.244078  2100 solver.cpp:237] Iteration 171000, loss = 1.18812
I0527 07:16:38.244127  2100 solver.cpp:253]     Train net output #0: loss = 1.18812 (* 1 = 1.18812 loss)
I0527 07:16:38.244141  2100 sgd_solver.cpp:106] Iteration 171000, lr = 0.0005
I0527 07:17:10.144858  2100 solver.cpp:237] Iteration 171375, loss = 0.889773
I0527 07:17:10.145023  2100 solver.cpp:253]     Train net output #0: loss = 0.889773 (* 1 = 0.889773 loss)
I0527 07:17:10.145040  2100 sgd_solver.cpp:106] Iteration 171375, lr = 0.0005
I0527 07:17:19.863484  2100 solver.cpp:237] Iteration 171750, loss = 1.03651
I0527 07:17:19.863528  2100 solver.cpp:253]     Train net output #0: loss = 1.03651 (* 1 = 1.03651 loss)
I0527 07:17:19.863543  2100 sgd_solver.cpp:106] Iteration 171750, lr = 0.0005
I0527 07:17:29.580322  2100 solver.cpp:237] Iteration 172125, loss = 1.47404
I0527 07:17:29.580358  2100 solver.cpp:253]     Train net output #0: loss = 1.47404 (* 1 = 1.47404 loss)
I0527 07:17:29.580371  2100 sgd_solver.cpp:106] Iteration 172125, lr = 0.0005
I0527 07:17:39.270345  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_172500.caffemodel
I0527 07:17:39.328176  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_172500.solverstate
I0527 07:17:39.354990  2100 solver.cpp:341] Iteration 172500, Testing net (#0)
I0527 07:18:28.846051  2100 solver.cpp:409]     Test net output #0: accuracy = 0.878319
I0527 07:18:28.846213  2100 solver.cpp:409]     Test net output #1: loss = 0.375816 (* 1 = 0.375816 loss)
I0527 07:18:28.854280  2100 solver.cpp:237] Iteration 172500, loss = 1.04899
I0527 07:18:28.854308  2100 solver.cpp:253]     Train net output #0: loss = 1.04899 (* 1 = 1.04899 loss)
I0527 07:18:28.854322  2100 sgd_solver.cpp:106] Iteration 172500, lr = 0.0005
I0527 07:18:38.587163  2100 solver.cpp:237] Iteration 172875, loss = 1.40469
I0527 07:18:38.587210  2100 solver.cpp:253]     Train net output #0: loss = 1.40469 (* 1 = 1.40469 loss)
I0527 07:18:38.587224  2100 sgd_solver.cpp:106] Iteration 172875, lr = 0.0005
I0527 07:18:48.326447  2100 solver.cpp:237] Iteration 173250, loss = 1.02838
I0527 07:18:48.326480  2100 solver.cpp:253]     Train net output #0: loss = 1.02838 (* 1 = 1.02838 loss)
I0527 07:18:48.326494  2100 sgd_solver.cpp:106] Iteration 173250, lr = 0.0005
I0527 07:18:58.052117  2100 solver.cpp:237] Iteration 173625, loss = 1.03506
I0527 07:18:58.052152  2100 solver.cpp:253]     Train net output #0: loss = 1.03506 (* 1 = 1.03506 loss)
I0527 07:18:58.052166  2100 sgd_solver.cpp:106] Iteration 173625, lr = 0.0005
I0527 07:19:29.931941  2100 solver.cpp:237] Iteration 174000, loss = 1.14611
I0527 07:19:29.932121  2100 solver.cpp:253]     Train net output #0: loss = 1.14611 (* 1 = 1.14611 loss)
I0527 07:19:29.932137  2100 sgd_solver.cpp:106] Iteration 174000, lr = 0.0005
I0527 07:19:39.665074  2100 solver.cpp:237] Iteration 174375, loss = 0.924057
I0527 07:19:39.665110  2100 solver.cpp:253]     Train net output #0: loss = 0.924057 (* 1 = 0.924057 loss)
I0527 07:19:39.665124  2100 sgd_solver.cpp:106] Iteration 174375, lr = 0.0005
I0527 07:19:49.399296  2100 solver.cpp:237] Iteration 174750, loss = 1.1963
I0527 07:19:49.399330  2100 solver.cpp:253]     Train net output #0: loss = 1.1963 (* 1 = 1.1963 loss)
I0527 07:19:49.399344  2100 sgd_solver.cpp:106] Iteration 174750, lr = 0.0005
I0527 07:19:59.133002  2100 solver.cpp:237] Iteration 175125, loss = 1.04777
I0527 07:19:59.133043  2100 solver.cpp:253]     Train net output #0: loss = 1.04777 (* 1 = 1.04777 loss)
I0527 07:19:59.133060  2100 sgd_solver.cpp:106] Iteration 175125, lr = 0.0005
I0527 07:20:08.873025  2100 solver.cpp:237] Iteration 175500, loss = 1.05666
I0527 07:20:08.873164  2100 solver.cpp:253]     Train net output #0: loss = 1.05666 (* 1 = 1.05666 loss)
I0527 07:20:08.873178  2100 sgd_solver.cpp:106] Iteration 175500, lr = 0.0005
I0527 07:20:18.612483  2100 solver.cpp:237] Iteration 175875, loss = 0.973102
I0527 07:20:18.612526  2100 solver.cpp:253]     Train net output #0: loss = 0.973102 (* 1 = 0.973102 loss)
I0527 07:20:18.612541  2100 sgd_solver.cpp:106] Iteration 175875, lr = 0.0005
I0527 07:20:28.319421  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_176250.caffemodel
I0527 07:20:28.377460  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_176250.solverstate
I0527 07:20:50.534719  2100 solver.cpp:237] Iteration 176250, loss = 1.01219
I0527 07:20:50.534888  2100 solver.cpp:253]     Train net output #0: loss = 1.01219 (* 1 = 1.01219 loss)
I0527 07:20:50.534904  2100 sgd_solver.cpp:106] Iteration 176250, lr = 0.0005
I0527 07:21:00.267709  2100 solver.cpp:237] Iteration 176625, loss = 1.13641
I0527 07:21:00.267745  2100 solver.cpp:253]     Train net output #0: loss = 1.13641 (* 1 = 1.13641 loss)
I0527 07:21:00.267758  2100 sgd_solver.cpp:106] Iteration 176625, lr = 0.0005
I0527 07:21:10.003500  2100 solver.cpp:237] Iteration 177000, loss = 1.08866
I0527 07:21:10.003548  2100 solver.cpp:253]     Train net output #0: loss = 1.08866 (* 1 = 1.08866 loss)
I0527 07:21:10.003562  2100 sgd_solver.cpp:106] Iteration 177000, lr = 0.0005
I0527 07:21:19.743119  2100 solver.cpp:237] Iteration 177375, loss = 1.31023
I0527 07:21:19.743154  2100 solver.cpp:253]     Train net output #0: loss = 1.31023 (* 1 = 1.31023 loss)
I0527 07:21:19.743167  2100 sgd_solver.cpp:106] Iteration 177375, lr = 0.0005
I0527 07:21:29.477519  2100 solver.cpp:237] Iteration 177750, loss = 1.22032
I0527 07:21:29.477656  2100 solver.cpp:253]     Train net output #0: loss = 1.22032 (* 1 = 1.22032 loss)
I0527 07:21:29.477670  2100 sgd_solver.cpp:106] Iteration 177750, lr = 0.0005
I0527 07:21:39.223587  2100 solver.cpp:237] Iteration 178125, loss = 1.1933
I0527 07:21:39.223634  2100 solver.cpp:253]     Train net output #0: loss = 1.1933 (* 1 = 1.1933 loss)
I0527 07:21:39.223651  2100 sgd_solver.cpp:106] Iteration 178125, lr = 0.0005
I0527 07:21:48.964447  2100 solver.cpp:237] Iteration 178500, loss = 1.14487
I0527 07:21:48.964483  2100 solver.cpp:253]     Train net output #0: loss = 1.14487 (* 1 = 1.14487 loss)
I0527 07:21:48.964495  2100 sgd_solver.cpp:106] Iteration 178500, lr = 0.0005
I0527 07:22:20.863472  2100 solver.cpp:237] Iteration 178875, loss = 1.43653
I0527 07:22:20.863636  2100 solver.cpp:253]     Train net output #0: loss = 1.43653 (* 1 = 1.43653 loss)
I0527 07:22:20.863651  2100 sgd_solver.cpp:106] Iteration 178875, lr = 0.0005
I0527 07:22:30.612390  2100 solver.cpp:237] Iteration 179250, loss = 1.17979
I0527 07:22:30.612426  2100 solver.cpp:253]     Train net output #0: loss = 1.17979 (* 1 = 1.17979 loss)
I0527 07:22:30.612442  2100 sgd_solver.cpp:106] Iteration 179250, lr = 0.0005
I0527 07:22:40.365661  2100 solver.cpp:237] Iteration 179625, loss = 1.08738
I0527 07:22:40.365697  2100 solver.cpp:253]     Train net output #0: loss = 1.08738 (* 1 = 1.08738 loss)
I0527 07:22:40.365715  2100 sgd_solver.cpp:106] Iteration 179625, lr = 0.0005
I0527 07:22:50.089814  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_180000.caffemodel
I0527 07:22:50.148164  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_180000.solverstate
I0527 07:22:50.175683  2100 solver.cpp:341] Iteration 180000, Testing net (#0)
I0527 07:23:38.769906  2100 solver.cpp:409]     Test net output #0: accuracy = 0.882895
I0527 07:23:38.770074  2100 solver.cpp:409]     Test net output #1: loss = 0.371871 (* 1 = 0.371871 loss)
I0527 07:23:38.778131  2100 solver.cpp:237] Iteration 180000, loss = 0.870296
I0527 07:23:38.778159  2100 solver.cpp:253]     Train net output #0: loss = 0.870296 (* 1 = 0.870296 loss)
I0527 07:23:38.778173  2100 sgd_solver.cpp:106] Iteration 180000, lr = 0.0005
I0527 07:23:48.491245  2100 solver.cpp:237] Iteration 180375, loss = 1.05745
I0527 07:23:48.491279  2100 solver.cpp:253]     Train net output #0: loss = 1.05745 (* 1 = 1.05745 loss)
I0527 07:23:48.491297  2100 sgd_solver.cpp:106] Iteration 180375, lr = 0.0005
I0527 07:23:58.210589  2100 solver.cpp:237] Iteration 180750, loss = 1.02149
I0527 07:23:58.210625  2100 solver.cpp:253]     Train net output #0: loss = 1.02149 (* 1 = 1.02149 loss)
I0527 07:23:58.210642  2100 sgd_solver.cpp:106] Iteration 180750, lr = 0.0005
I0527 07:24:07.928007  2100 solver.cpp:237] Iteration 181125, loss = 0.949075
I0527 07:24:07.928053  2100 solver.cpp:253]     Train net output #0: loss = 0.949075 (* 1 = 0.949075 loss)
I0527 07:24:07.928068  2100 sgd_solver.cpp:106] Iteration 181125, lr = 0.0005
I0527 07:24:39.772827  2100 solver.cpp:237] Iteration 181500, loss = 1.10617
I0527 07:24:39.773000  2100 solver.cpp:253]     Train net output #0: loss = 1.10617 (* 1 = 1.10617 loss)
I0527 07:24:39.773016  2100 sgd_solver.cpp:106] Iteration 181500, lr = 0.0005
I0527 07:24:49.487854  2100 solver.cpp:237] Iteration 181875, loss = 1.32382
I0527 07:24:49.487890  2100 solver.cpp:253]     Train net output #0: loss = 1.32382 (* 1 = 1.32382 loss)
I0527 07:24:49.487907  2100 sgd_solver.cpp:106] Iteration 181875, lr = 0.0005
I0527 07:24:59.200767  2100 solver.cpp:237] Iteration 182250, loss = 1.12848
I0527 07:24:59.200805  2100 solver.cpp:253]     Train net output #0: loss = 1.12848 (* 1 = 1.12848 loss)
I0527 07:24:59.200827  2100 sgd_solver.cpp:106] Iteration 182250, lr = 0.0005
I0527 07:25:08.916039  2100 solver.cpp:237] Iteration 182625, loss = 0.95174
I0527 07:25:08.916076  2100 solver.cpp:253]     Train net output #0: loss = 0.95174 (* 1 = 0.95174 loss)
I0527 07:25:08.916092  2100 sgd_solver.cpp:106] Iteration 182625, lr = 0.0005
I0527 07:25:18.629063  2100 solver.cpp:237] Iteration 183000, loss = 1.15936
I0527 07:25:18.629218  2100 solver.cpp:253]     Train net output #0: loss = 1.15936 (* 1 = 1.15936 loss)
I0527 07:25:18.629233  2100 sgd_solver.cpp:106] Iteration 183000, lr = 0.0005
I0527 07:25:28.335331  2100 solver.cpp:237] Iteration 183375, loss = 1.13035
I0527 07:25:28.335366  2100 solver.cpp:253]     Train net output #0: loss = 1.13035 (* 1 = 1.13035 loss)
I0527 07:25:28.335381  2100 sgd_solver.cpp:106] Iteration 183375, lr = 0.0005
I0527 07:25:38.027444  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_183750.caffemodel
I0527 07:25:38.086324  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_183750.solverstate
I0527 07:26:00.263052  2100 solver.cpp:237] Iteration 183750, loss = 1.09684
I0527 07:26:00.263231  2100 solver.cpp:253]     Train net output #0: loss = 1.09684 (* 1 = 1.09684 loss)
I0527 07:26:00.263247  2100 sgd_solver.cpp:106] Iteration 183750, lr = 0.0005
I0527 07:26:09.975401  2100 solver.cpp:237] Iteration 184125, loss = 0.823201
I0527 07:26:09.975443  2100 solver.cpp:253]     Train net output #0: loss = 0.823201 (* 1 = 0.823201 loss)
I0527 07:26:09.975464  2100 sgd_solver.cpp:106] Iteration 184125, lr = 0.0005
I0527 07:26:19.689254  2100 solver.cpp:237] Iteration 184500, loss = 1.1844
I0527 07:26:19.689291  2100 solver.cpp:253]     Train net output #0: loss = 1.1844 (* 1 = 1.1844 loss)
I0527 07:26:19.689304  2100 sgd_solver.cpp:106] Iteration 184500, lr = 0.0005
I0527 07:26:29.407027  2100 solver.cpp:237] Iteration 184875, loss = 1.13631
I0527 07:26:29.407063  2100 solver.cpp:253]     Train net output #0: loss = 1.13631 (* 1 = 1.13631 loss)
I0527 07:26:29.407078  2100 sgd_solver.cpp:106] Iteration 184875, lr = 0.0005
I0527 07:26:39.120194  2100 solver.cpp:237] Iteration 185250, loss = 1.30601
I0527 07:26:39.120357  2100 solver.cpp:253]     Train net output #0: loss = 1.30601 (* 1 = 1.30601 loss)
I0527 07:26:39.120370  2100 sgd_solver.cpp:106] Iteration 185250, lr = 0.0005
I0527 07:26:48.834223  2100 solver.cpp:237] Iteration 185625, loss = 0.999469
I0527 07:26:48.834257  2100 solver.cpp:253]     Train net output #0: loss = 0.999469 (* 1 = 0.999469 loss)
I0527 07:26:48.834271  2100 sgd_solver.cpp:106] Iteration 185625, lr = 0.0005
I0527 07:26:58.561327  2100 solver.cpp:237] Iteration 186000, loss = 1.38097
I0527 07:26:58.561363  2100 solver.cpp:253]     Train net output #0: loss = 1.38097 (* 1 = 1.38097 loss)
I0527 07:26:58.561381  2100 sgd_solver.cpp:106] Iteration 186000, lr = 0.0005
I0527 07:27:30.398991  2100 solver.cpp:237] Iteration 186375, loss = 1.07688
I0527 07:27:30.399158  2100 solver.cpp:253]     Train net output #0: loss = 1.07688 (* 1 = 1.07688 loss)
I0527 07:27:30.399173  2100 sgd_solver.cpp:106] Iteration 186375, lr = 0.0005
I0527 07:27:40.117499  2100 solver.cpp:237] Iteration 186750, loss = 1.27025
I0527 07:27:40.117534  2100 solver.cpp:253]     Train net output #0: loss = 1.27025 (* 1 = 1.27025 loss)
I0527 07:27:40.117547  2100 sgd_solver.cpp:106] Iteration 186750, lr = 0.0005
I0527 07:27:49.829761  2100 solver.cpp:237] Iteration 187125, loss = 1.27974
I0527 07:27:49.829799  2100 solver.cpp:253]     Train net output #0: loss = 1.27974 (* 1 = 1.27974 loss)
I0527 07:27:49.829816  2100 sgd_solver.cpp:106] Iteration 187125, lr = 0.0005
I0527 07:27:59.515046  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_187500.caffemodel
I0527 07:27:59.573428  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_187500.solverstate
I0527 07:27:59.601043  2100 solver.cpp:341] Iteration 187500, Testing net (#0)
I0527 07:29:09.023393  2100 solver.cpp:409]     Test net output #0: accuracy = 0.882613
I0527 07:29:09.023552  2100 solver.cpp:409]     Test net output #1: loss = 0.381078 (* 1 = 0.381078 loss)
I0527 07:29:09.031625  2100 solver.cpp:237] Iteration 187500, loss = 1.46045
I0527 07:29:09.031653  2100 solver.cpp:253]     Train net output #0: loss = 1.46045 (* 1 = 1.46045 loss)
I0527 07:29:09.031667  2100 sgd_solver.cpp:106] Iteration 187500, lr = 0.0005
I0527 07:29:18.901334  2100 solver.cpp:237] Iteration 187875, loss = 1.2681
I0527 07:29:18.901368  2100 solver.cpp:253]     Train net output #0: loss = 1.2681 (* 1 = 1.2681 loss)
I0527 07:29:18.901386  2100 sgd_solver.cpp:106] Iteration 187875, lr = 0.0005
I0527 07:29:28.771930  2100 solver.cpp:237] Iteration 188250, loss = 1.57353
I0527 07:29:28.771978  2100 solver.cpp:253]     Train net output #0: loss = 1.57353 (* 1 = 1.57353 loss)
I0527 07:29:28.771992  2100 sgd_solver.cpp:106] Iteration 188250, lr = 0.0005
I0527 07:29:38.650496  2100 solver.cpp:237] Iteration 188625, loss = 1.18532
I0527 07:29:38.650532  2100 solver.cpp:253]     Train net output #0: loss = 1.18532 (* 1 = 1.18532 loss)
I0527 07:29:38.650547  2100 sgd_solver.cpp:106] Iteration 188625, lr = 0.0005
I0527 07:30:10.692173  2100 solver.cpp:237] Iteration 189000, loss = 1.36931
I0527 07:30:10.692351  2100 solver.cpp:253]     Train net output #0: loss = 1.36931 (* 1 = 1.36931 loss)
I0527 07:30:10.692368  2100 sgd_solver.cpp:106] Iteration 189000, lr = 0.0005
I0527 07:30:20.569200  2100 solver.cpp:237] Iteration 189375, loss = 1.01656
I0527 07:30:20.569241  2100 solver.cpp:253]     Train net output #0: loss = 1.01656 (* 1 = 1.01656 loss)
I0527 07:30:20.569265  2100 sgd_solver.cpp:106] Iteration 189375, lr = 0.0005
I0527 07:30:30.445817  2100 solver.cpp:237] Iteration 189750, loss = 0.837116
I0527 07:30:30.445853  2100 solver.cpp:253]     Train net output #0: loss = 0.837116 (* 1 = 0.837116 loss)
I0527 07:30:30.445868  2100 sgd_solver.cpp:106] Iteration 189750, lr = 0.0005
I0527 07:30:40.317432  2100 solver.cpp:237] Iteration 190125, loss = 1.34024
I0527 07:30:40.317477  2100 solver.cpp:253]     Train net output #0: loss = 1.34024 (* 1 = 1.34024 loss)
I0527 07:30:40.317492  2100 sgd_solver.cpp:106] Iteration 190125, lr = 0.0005
I0527 07:30:50.197414  2100 solver.cpp:237] Iteration 190500, loss = 1.18301
I0527 07:30:50.197558  2100 solver.cpp:253]     Train net output #0: loss = 1.18301 (* 1 = 1.18301 loss)
I0527 07:30:50.197574  2100 sgd_solver.cpp:106] Iteration 190500, lr = 0.0005
I0527 07:31:00.065682  2100 solver.cpp:237] Iteration 190875, loss = 0.903695
I0527 07:31:00.065717  2100 solver.cpp:253]     Train net output #0: loss = 0.903695 (* 1 = 0.903695 loss)
I0527 07:31:00.065732  2100 sgd_solver.cpp:106] Iteration 190875, lr = 0.0005
I0527 07:31:09.913254  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_191250.caffemodel
I0527 07:31:09.970149  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_191250.solverstate
I0527 07:31:32.125998  2100 solver.cpp:237] Iteration 191250, loss = 0.906028
I0527 07:31:32.126166  2100 solver.cpp:253]     Train net output #0: loss = 0.906028 (* 1 = 0.906028 loss)
I0527 07:31:32.126183  2100 sgd_solver.cpp:106] Iteration 191250, lr = 0.0005
I0527 07:31:42.001467  2100 solver.cpp:237] Iteration 191625, loss = 1.51211
I0527 07:31:42.001502  2100 solver.cpp:253]     Train net output #0: loss = 1.51211 (* 1 = 1.51211 loss)
I0527 07:31:42.001516  2100 sgd_solver.cpp:106] Iteration 191625, lr = 0.0005
I0527 07:31:51.871532  2100 solver.cpp:237] Iteration 192000, loss = 1.28016
I0527 07:31:51.871568  2100 solver.cpp:253]     Train net output #0: loss = 1.28016 (* 1 = 1.28016 loss)
I0527 07:31:51.871582  2100 sgd_solver.cpp:106] Iteration 192000, lr = 0.0005
I0527 07:32:01.743685  2100 solver.cpp:237] Iteration 192375, loss = 1.43981
I0527 07:32:01.743724  2100 solver.cpp:253]     Train net output #0: loss = 1.43981 (* 1 = 1.43981 loss)
I0527 07:32:01.743741  2100 sgd_solver.cpp:106] Iteration 192375, lr = 0.0005
I0527 07:32:11.618654  2100 solver.cpp:237] Iteration 192750, loss = 1.18578
I0527 07:32:11.618806  2100 solver.cpp:253]     Train net output #0: loss = 1.18578 (* 1 = 1.18578 loss)
I0527 07:32:11.618821  2100 sgd_solver.cpp:106] Iteration 192750, lr = 0.0005
I0527 07:32:21.485128  2100 solver.cpp:237] Iteration 193125, loss = 1.32677
I0527 07:32:21.485170  2100 solver.cpp:253]     Train net output #0: loss = 1.32677 (* 1 = 1.32677 loss)
I0527 07:32:21.485186  2100 sgd_solver.cpp:106] Iteration 193125, lr = 0.0005
I0527 07:32:31.356022  2100 solver.cpp:237] Iteration 193500, loss = 1.00059
I0527 07:32:31.356056  2100 solver.cpp:253]     Train net output #0: loss = 1.00059 (* 1 = 1.00059 loss)
I0527 07:32:31.356073  2100 sgd_solver.cpp:106] Iteration 193500, lr = 0.0005
I0527 07:33:03.365824  2100 solver.cpp:237] Iteration 193875, loss = 1.29505
I0527 07:33:03.365999  2100 solver.cpp:253]     Train net output #0: loss = 1.29505 (* 1 = 1.29505 loss)
I0527 07:33:03.366015  2100 sgd_solver.cpp:106] Iteration 193875, lr = 0.0005
I0527 07:33:13.228756  2100 solver.cpp:237] Iteration 194250, loss = 0.934087
I0527 07:33:13.228801  2100 solver.cpp:253]     Train net output #0: loss = 0.934087 (* 1 = 0.934087 loss)
I0527 07:33:13.228817  2100 sgd_solver.cpp:106] Iteration 194250, lr = 0.0005
I0527 07:33:23.102380  2100 solver.cpp:237] Iteration 194625, loss = 1.00359
I0527 07:33:23.102416  2100 solver.cpp:253]     Train net output #0: loss = 1.00359 (* 1 = 1.00359 loss)
I0527 07:33:23.102429  2100 sgd_solver.cpp:106] Iteration 194625, lr = 0.0005
I0527 07:33:32.946666  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_195000.caffemodel
I0527 07:33:33.003157  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_195000.solverstate
I0527 07:33:33.028576  2100 solver.cpp:341] Iteration 195000, Testing net (#0)
I0527 07:34:21.260851  2100 solver.cpp:409]     Test net output #0: accuracy = 0.882912
I0527 07:34:21.261010  2100 solver.cpp:409]     Test net output #1: loss = 0.391189 (* 1 = 0.391189 loss)
I0527 07:34:21.269055  2100 solver.cpp:237] Iteration 195000, loss = 1.28671
I0527 07:34:21.269083  2100 solver.cpp:253]     Train net output #0: loss = 1.28671 (* 1 = 1.28671 loss)
I0527 07:34:21.269096  2100 sgd_solver.cpp:106] Iteration 195000, lr = 0.0005
I0527 07:34:31.106029  2100 solver.cpp:237] Iteration 195375, loss = 1.09956
I0527 07:34:31.106070  2100 solver.cpp:253]     Train net output #0: loss = 1.09956 (* 1 = 1.09956 loss)
I0527 07:34:31.106087  2100 sgd_solver.cpp:106] Iteration 195375, lr = 0.0005
I0527 07:34:40.935418  2100 solver.cpp:237] Iteration 195750, loss = 1.0851
I0527 07:34:40.935453  2100 solver.cpp:253]     Train net output #0: loss = 1.0851 (* 1 = 1.0851 loss)
I0527 07:34:40.935467  2100 sgd_solver.cpp:106] Iteration 195750, lr = 0.0005
I0527 07:34:50.772850  2100 solver.cpp:237] Iteration 196125, loss = 1.38786
I0527 07:34:50.772896  2100 solver.cpp:253]     Train net output #0: loss = 1.38786 (* 1 = 1.38786 loss)
I0527 07:34:50.772908  2100 sgd_solver.cpp:106] Iteration 196125, lr = 0.0005
I0527 07:35:22.734206  2100 solver.cpp:237] Iteration 196500, loss = 0.77931
I0527 07:35:22.734369  2100 solver.cpp:253]     Train net output #0: loss = 0.77931 (* 1 = 0.77931 loss)
I0527 07:35:22.734385  2100 sgd_solver.cpp:106] Iteration 196500, lr = 0.0005
I0527 07:35:32.564374  2100 solver.cpp:237] Iteration 196875, loss = 1.41632
I0527 07:35:32.564409  2100 solver.cpp:253]     Train net output #0: loss = 1.41632 (* 1 = 1.41632 loss)
I0527 07:35:32.564426  2100 sgd_solver.cpp:106] Iteration 196875, lr = 0.0005
I0527 07:35:42.392457  2100 solver.cpp:237] Iteration 197250, loss = 1.24593
I0527 07:35:42.392506  2100 solver.cpp:253]     Train net output #0: loss = 1.24593 (* 1 = 1.24593 loss)
I0527 07:35:42.392521  2100 sgd_solver.cpp:106] Iteration 197250, lr = 0.0005
I0527 07:35:52.227252  2100 solver.cpp:237] Iteration 197625, loss = 1.11368
I0527 07:35:52.227286  2100 solver.cpp:253]     Train net output #0: loss = 1.11368 (* 1 = 1.11368 loss)
I0527 07:35:52.227300  2100 sgd_solver.cpp:106] Iteration 197625, lr = 0.0005
I0527 07:36:02.062788  2100 solver.cpp:237] Iteration 198000, loss = 1.37444
I0527 07:36:02.062932  2100 solver.cpp:253]     Train net output #0: loss = 1.37444 (* 1 = 1.37444 loss)
I0527 07:36:02.062947  2100 sgd_solver.cpp:106] Iteration 198000, lr = 0.0005
I0527 07:36:11.899628  2100 solver.cpp:237] Iteration 198375, loss = 1.17907
I0527 07:36:11.899672  2100 solver.cpp:253]     Train net output #0: loss = 1.17907 (* 1 = 1.17907 loss)
I0527 07:36:11.899691  2100 sgd_solver.cpp:106] Iteration 198375, lr = 0.0005
I0527 07:36:21.709147  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_198750.caffemodel
I0527 07:36:21.765202  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_198750.solverstate
I0527 07:36:43.957106  2100 solver.cpp:237] Iteration 198750, loss = 1.38708
I0527 07:36:43.957305  2100 solver.cpp:253]     Train net output #0: loss = 1.38708 (* 1 = 1.38708 loss)
I0527 07:36:43.957321  2100 sgd_solver.cpp:106] Iteration 198750, lr = 0.0005
I0527 07:36:53.783932  2100 solver.cpp:237] Iteration 199125, loss = 1.16656
I0527 07:36:53.783967  2100 solver.cpp:253]     Train net output #0: loss = 1.16656 (* 1 = 1.16656 loss)
I0527 07:36:53.783982  2100 sgd_solver.cpp:106] Iteration 199125, lr = 0.0005
I0527 07:37:03.619259  2100 solver.cpp:237] Iteration 199500, loss = 0.857005
I0527 07:37:03.619297  2100 solver.cpp:253]     Train net output #0: loss = 0.857005 (* 1 = 0.857005 loss)
I0527 07:37:03.619315  2100 sgd_solver.cpp:106] Iteration 199500, lr = 0.0005
I0527 07:37:13.434048  2100 solver.cpp:237] Iteration 199875, loss = 1.3496
I0527 07:37:13.434084  2100 solver.cpp:253]     Train net output #0: loss = 1.3496 (* 1 = 1.3496 loss)
I0527 07:37:13.434101  2100 sgd_solver.cpp:106] Iteration 199875, lr = 0.0005
I0527 07:37:23.178448  2100 solver.cpp:237] Iteration 200250, loss = 1.00513
I0527 07:37:23.178604  2100 solver.cpp:253]     Train net output #0: loss = 1.00513 (* 1 = 1.00513 loss)
I0527 07:37:23.178618  2100 sgd_solver.cpp:106] Iteration 200250, lr = 0.0005
I0527 07:37:32.927804  2100 solver.cpp:237] Iteration 200625, loss = 1.05881
I0527 07:37:32.927839  2100 solver.cpp:253]     Train net output #0: loss = 1.05881 (* 1 = 1.05881 loss)
I0527 07:37:32.927857  2100 sgd_solver.cpp:106] Iteration 200625, lr = 0.0005
I0527 07:37:42.672921  2100 solver.cpp:237] Iteration 201000, loss = 1.11872
I0527 07:37:42.672957  2100 solver.cpp:253]     Train net output #0: loss = 1.11872 (* 1 = 1.11872 loss)
I0527 07:37:42.672971  2100 sgd_solver.cpp:106] Iteration 201000, lr = 0.0005
I0527 07:38:14.612473  2100 solver.cpp:237] Iteration 201375, loss = 1.09005
I0527 07:38:14.612649  2100 solver.cpp:253]     Train net output #0: loss = 1.09005 (* 1 = 1.09005 loss)
I0527 07:38:14.612664  2100 sgd_solver.cpp:106] Iteration 201375, lr = 0.0005
I0527 07:38:24.356019  2100 solver.cpp:237] Iteration 201750, loss = 1.42268
I0527 07:38:24.356055  2100 solver.cpp:253]     Train net output #0: loss = 1.42268 (* 1 = 1.42268 loss)
I0527 07:38:24.356068  2100 sgd_solver.cpp:106] Iteration 201750, lr = 0.0005
I0527 07:38:34.106642  2100 solver.cpp:237] Iteration 202125, loss = 1.48268
I0527 07:38:34.106678  2100 solver.cpp:253]     Train net output #0: loss = 1.48268 (* 1 = 1.48268 loss)
I0527 07:38:34.106691  2100 sgd_solver.cpp:106] Iteration 202125, lr = 0.0005
I0527 07:38:43.822782  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_202500.caffemodel
I0527 07:38:43.880277  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_202500.solverstate
I0527 07:38:43.907052  2100 solver.cpp:341] Iteration 202500, Testing net (#0)
I0527 07:39:53.303782  2100 solver.cpp:409]     Test net output #0: accuracy = 0.882041
I0527 07:39:53.303943  2100 solver.cpp:409]     Test net output #1: loss = 0.389742 (* 1 = 0.389742 loss)
I0527 07:39:53.312001  2100 solver.cpp:237] Iteration 202500, loss = 1.18908
I0527 07:39:53.312029  2100 solver.cpp:253]     Train net output #0: loss = 1.18908 (* 1 = 1.18908 loss)
I0527 07:39:53.312043  2100 sgd_solver.cpp:106] Iteration 202500, lr = 0.0005
I0527 07:40:03.087635  2100 solver.cpp:237] Iteration 202875, loss = 1.13396
I0527 07:40:03.087669  2100 solver.cpp:253]     Train net output #0: loss = 1.13396 (* 1 = 1.13396 loss)
I0527 07:40:03.087683  2100 sgd_solver.cpp:106] Iteration 202875, lr = 0.0005
I0527 07:40:12.855630  2100 solver.cpp:237] Iteration 203250, loss = 1.3363
I0527 07:40:12.855666  2100 solver.cpp:253]     Train net output #0: loss = 1.3363 (* 1 = 1.3363 loss)
I0527 07:40:12.855679  2100 sgd_solver.cpp:106] Iteration 203250, lr = 0.0005
I0527 07:40:22.628931  2100 solver.cpp:237] Iteration 203625, loss = 1.42614
I0527 07:40:22.628978  2100 solver.cpp:253]     Train net output #0: loss = 1.42614 (* 1 = 1.42614 loss)
I0527 07:40:22.628993  2100 sgd_solver.cpp:106] Iteration 203625, lr = 0.0005
I0527 07:40:54.591006  2100 solver.cpp:237] Iteration 204000, loss = 1.19414
I0527 07:40:54.591188  2100 solver.cpp:253]     Train net output #0: loss = 1.19414 (* 1 = 1.19414 loss)
I0527 07:40:54.591204  2100 sgd_solver.cpp:106] Iteration 204000, lr = 0.0005
I0527 07:41:04.364956  2100 solver.cpp:237] Iteration 204375, loss = 1.16871
I0527 07:41:04.364991  2100 solver.cpp:253]     Train net output #0: loss = 1.16871 (* 1 = 1.16871 loss)
I0527 07:41:04.365010  2100 sgd_solver.cpp:106] Iteration 204375, lr = 0.0005
I0527 07:41:14.134737  2100 solver.cpp:237] Iteration 204750, loss = 1.22908
I0527 07:41:14.134773  2100 solver.cpp:253]     Train net output #0: loss = 1.22908 (* 1 = 1.22908 loss)
I0527 07:41:14.134790  2100 sgd_solver.cpp:106] Iteration 204750, lr = 0.0005
I0527 07:41:23.899510  2100 solver.cpp:237] Iteration 205125, loss = 1.5264
I0527 07:41:23.899546  2100 solver.cpp:253]     Train net output #0: loss = 1.5264 (* 1 = 1.5264 loss)
I0527 07:41:23.899559  2100 sgd_solver.cpp:106] Iteration 205125, lr = 0.0005
I0527 07:41:33.665390  2100 solver.cpp:237] Iteration 205500, loss = 1.26151
I0527 07:41:33.665549  2100 solver.cpp:253]     Train net output #0: loss = 1.26151 (* 1 = 1.26151 loss)
I0527 07:41:33.665563  2100 sgd_solver.cpp:106] Iteration 205500, lr = 0.0005
I0527 07:41:43.432742  2100 solver.cpp:237] Iteration 205875, loss = 1.59231
I0527 07:41:43.432777  2100 solver.cpp:253]     Train net output #0: loss = 1.59231 (* 1 = 1.59231 loss)
I0527 07:41:43.432795  2100 sgd_solver.cpp:106] Iteration 205875, lr = 0.0005
I0527 07:41:53.172049  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_206250.caffemodel
I0527 07:41:53.230367  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_206250.solverstate
I0527 07:42:14.184016  2100 solver.cpp:237] Iteration 206250, loss = 1.10761
I0527 07:42:14.184201  2100 solver.cpp:253]     Train net output #0: loss = 1.10761 (* 1 = 1.10761 loss)
I0527 07:42:14.184217  2100 sgd_solver.cpp:106] Iteration 206250, lr = 0.0005
I0527 07:42:23.950378  2100 solver.cpp:237] Iteration 206625, loss = 0.887193
I0527 07:42:23.950426  2100 solver.cpp:253]     Train net output #0: loss = 0.887193 (* 1 = 0.887193 loss)
I0527 07:42:23.950441  2100 sgd_solver.cpp:106] Iteration 206625, lr = 0.0005
I0527 07:42:33.718582  2100 solver.cpp:237] Iteration 207000, loss = 1.35282
I0527 07:42:33.718618  2100 solver.cpp:253]     Train net output #0: loss = 1.35282 (* 1 = 1.35282 loss)
I0527 07:42:33.718632  2100 sgd_solver.cpp:106] Iteration 207000, lr = 0.0005
I0527 07:42:43.489146  2100 solver.cpp:237] Iteration 207375, loss = 1.0333
I0527 07:42:43.489181  2100 solver.cpp:253]     Train net output #0: loss = 1.0333 (* 1 = 1.0333 loss)
I0527 07:42:43.489197  2100 sgd_solver.cpp:106] Iteration 207375, lr = 0.0005
I0527 07:42:53.261131  2100 solver.cpp:237] Iteration 207750, loss = 0.874765
I0527 07:42:53.261317  2100 solver.cpp:253]     Train net output #0: loss = 0.874765 (* 1 = 0.874765 loss)
I0527 07:42:53.261332  2100 sgd_solver.cpp:106] Iteration 207750, lr = 0.0005
I0527 07:43:03.021860  2100 solver.cpp:237] Iteration 208125, loss = 1.29198
I0527 07:43:03.021894  2100 solver.cpp:253]     Train net output #0: loss = 1.29198 (* 1 = 1.29198 loss)
I0527 07:43:03.021914  2100 sgd_solver.cpp:106] Iteration 208125, lr = 0.0005
I0527 07:43:12.788421  2100 solver.cpp:237] Iteration 208500, loss = 1.38845
I0527 07:43:12.788465  2100 solver.cpp:253]     Train net output #0: loss = 1.38845 (* 1 = 1.38845 loss)
I0527 07:43:12.788480  2100 sgd_solver.cpp:106] Iteration 208500, lr = 0.0005
I0527 07:43:43.456779  2100 solver.cpp:237] Iteration 208875, loss = 1.13112
I0527 07:43:43.456948  2100 solver.cpp:253]     Train net output #0: loss = 1.13112 (* 1 = 1.13112 loss)
I0527 07:43:43.456964  2100 sgd_solver.cpp:106] Iteration 208875, lr = 0.0005
I0527 07:43:53.217346  2100 solver.cpp:237] Iteration 209250, loss = 1.14656
I0527 07:43:53.217381  2100 solver.cpp:253]     Train net output #0: loss = 1.14656 (* 1 = 1.14656 loss)
I0527 07:43:53.217396  2100 sgd_solver.cpp:106] Iteration 209250, lr = 0.0005
I0527 07:44:02.997787  2100 solver.cpp:237] Iteration 209625, loss = 1.7187
I0527 07:44:02.997833  2100 solver.cpp:253]     Train net output #0: loss = 1.7187 (* 1 = 1.7187 loss)
I0527 07:44:02.997853  2100 sgd_solver.cpp:106] Iteration 209625, lr = 0.0005
I0527 07:44:12.768903  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_210000.caffemodel
I0527 07:44:12.824882  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_210000.solverstate
I0527 07:44:12.850802  2100 solver.cpp:341] Iteration 210000, Testing net (#0)
I0527 07:45:01.402154  2100 solver.cpp:409]     Test net output #0: accuracy = 0.886467
I0527 07:45:01.402320  2100 solver.cpp:409]     Test net output #1: loss = 0.353288 (* 1 = 0.353288 loss)
I0527 07:45:01.410398  2100 solver.cpp:237] Iteration 210000, loss = 0.954235
I0527 07:45:01.410425  2100 solver.cpp:253]     Train net output #0: loss = 0.954235 (* 1 = 0.954235 loss)
I0527 07:45:01.410439  2100 sgd_solver.cpp:106] Iteration 210000, lr = 0.0005
I0527 07:45:11.125494  2100 solver.cpp:237] Iteration 210375, loss = 1.31755
I0527 07:45:11.125529  2100 solver.cpp:253]     Train net output #0: loss = 1.31755 (* 1 = 1.31755 loss)
I0527 07:45:11.125548  2100 sgd_solver.cpp:106] Iteration 210375, lr = 0.0005
I0527 07:45:20.830123  2100 solver.cpp:237] Iteration 210750, loss = 1.0256
I0527 07:45:20.830170  2100 solver.cpp:253]     Train net output #0: loss = 1.0256 (* 1 = 1.0256 loss)
I0527 07:45:20.830184  2100 sgd_solver.cpp:106] Iteration 210750, lr = 0.0005
I0527 07:45:30.535068  2100 solver.cpp:237] Iteration 211125, loss = 1.01028
I0527 07:45:30.535104  2100 solver.cpp:253]     Train net output #0: loss = 1.01028 (* 1 = 1.01028 loss)
I0527 07:45:30.535120  2100 sgd_solver.cpp:106] Iteration 211125, lr = 0.0005
I0527 07:46:01.132561  2100 solver.cpp:237] Iteration 211500, loss = 0.969718
I0527 07:46:01.132735  2100 solver.cpp:253]     Train net output #0: loss = 0.969718 (* 1 = 0.969718 loss)
I0527 07:46:01.132750  2100 sgd_solver.cpp:106] Iteration 211500, lr = 0.0005
I0527 07:46:10.842402  2100 solver.cpp:237] Iteration 211875, loss = 1.00742
I0527 07:46:10.842449  2100 solver.cpp:253]     Train net output #0: loss = 1.00742 (* 1 = 1.00742 loss)
I0527 07:46:10.842464  2100 sgd_solver.cpp:106] Iteration 211875, lr = 0.0005
I0527 07:46:20.545797  2100 solver.cpp:237] Iteration 212250, loss = 1.7563
I0527 07:46:20.545833  2100 solver.cpp:253]     Train net output #0: loss = 1.7563 (* 1 = 1.7563 loss)
I0527 07:46:20.545846  2100 sgd_solver.cpp:106] Iteration 212250, lr = 0.0005
I0527 07:46:30.258316  2100 solver.cpp:237] Iteration 212625, loss = 1.17736
I0527 07:46:30.258359  2100 solver.cpp:253]     Train net output #0: loss = 1.17736 (* 1 = 1.17736 loss)
I0527 07:46:30.258375  2100 sgd_solver.cpp:106] Iteration 212625, lr = 0.0005
I0527 07:46:39.965452  2100 solver.cpp:237] Iteration 213000, loss = 1.20807
I0527 07:46:39.965608  2100 solver.cpp:253]     Train net output #0: loss = 1.20807 (* 1 = 1.20807 loss)
I0527 07:46:39.965622  2100 sgd_solver.cpp:106] Iteration 213000, lr = 0.0005
I0527 07:46:49.677976  2100 solver.cpp:237] Iteration 213375, loss = 1.3081
I0527 07:46:49.678010  2100 solver.cpp:253]     Train net output #0: loss = 1.3081 (* 1 = 1.3081 loss)
I0527 07:46:49.678025  2100 sgd_solver.cpp:106] Iteration 213375, lr = 0.0005
I0527 07:46:59.359613  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_213750.caffemodel
I0527 07:46:59.415354  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_213750.solverstate
I0527 07:47:20.344288  2100 solver.cpp:237] Iteration 213750, loss = 1.04511
I0527 07:47:20.344465  2100 solver.cpp:253]     Train net output #0: loss = 1.04511 (* 1 = 1.04511 loss)
I0527 07:47:20.344481  2100 sgd_solver.cpp:106] Iteration 213750, lr = 0.0005
I0527 07:47:30.059510  2100 solver.cpp:237] Iteration 214125, loss = 0.73529
I0527 07:47:30.059546  2100 solver.cpp:253]     Train net output #0: loss = 0.73529 (* 1 = 0.73529 loss)
I0527 07:47:30.059561  2100 sgd_solver.cpp:106] Iteration 214125, lr = 0.0005
I0527 07:47:39.762614  2100 solver.cpp:237] Iteration 214500, loss = 0.850854
I0527 07:47:39.762650  2100 solver.cpp:253]     Train net output #0: loss = 0.850854 (* 1 = 0.850854 loss)
I0527 07:47:39.762663  2100 sgd_solver.cpp:106] Iteration 214500, lr = 0.0005
I0527 07:47:49.468487  2100 solver.cpp:237] Iteration 214875, loss = 1.08081
I0527 07:47:49.468530  2100 solver.cpp:253]     Train net output #0: loss = 1.08081 (* 1 = 1.08081 loss)
I0527 07:47:49.468544  2100 sgd_solver.cpp:106] Iteration 214875, lr = 0.0005
I0527 07:47:59.181633  2100 solver.cpp:237] Iteration 215250, loss = 0.995721
I0527 07:47:59.181782  2100 solver.cpp:253]     Train net output #0: loss = 0.995721 (* 1 = 0.995721 loss)
I0527 07:47:59.181797  2100 sgd_solver.cpp:106] Iteration 215250, lr = 0.0005
I0527 07:48:08.890442  2100 solver.cpp:237] Iteration 215625, loss = 1.28288
I0527 07:48:08.890477  2100 solver.cpp:253]     Train net output #0: loss = 1.28288 (* 1 = 1.28288 loss)
I0527 07:48:08.890491  2100 sgd_solver.cpp:106] Iteration 215625, lr = 0.0005
I0527 07:48:18.600124  2100 solver.cpp:237] Iteration 216000, loss = 1.00311
I0527 07:48:18.600172  2100 solver.cpp:253]     Train net output #0: loss = 1.00311 (* 1 = 1.00311 loss)
I0527 07:48:18.600186  2100 sgd_solver.cpp:106] Iteration 216000, lr = 0.0005
I0527 07:48:49.174911  2100 solver.cpp:237] Iteration 216375, loss = 1.26067
I0527 07:48:49.175081  2100 solver.cpp:253]     Train net output #0: loss = 1.26067 (* 1 = 1.26067 loss)
I0527 07:48:49.175097  2100 sgd_solver.cpp:106] Iteration 216375, lr = 0.0005
I0527 07:48:58.877554  2100 solver.cpp:237] Iteration 216750, loss = 1.09421
I0527 07:48:58.877589  2100 solver.cpp:253]     Train net output #0: loss = 1.09421 (* 1 = 1.09421 loss)
I0527 07:48:58.877607  2100 sgd_solver.cpp:106] Iteration 216750, lr = 0.0005
I0527 07:49:08.582162  2100 solver.cpp:237] Iteration 217125, loss = 1.57944
I0527 07:49:08.582211  2100 solver.cpp:253]     Train net output #0: loss = 1.57944 (* 1 = 1.57944 loss)
I0527 07:49:08.582226  2100 sgd_solver.cpp:106] Iteration 217125, lr = 0.0005
I0527 07:49:18.265033  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_217500.caffemodel
I0527 07:49:18.320754  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_217500.solverstate
I0527 07:49:18.348906  2100 solver.cpp:341] Iteration 217500, Testing net (#0)
I0527 07:50:27.747493  2100 solver.cpp:409]     Test net output #0: accuracy = 0.88168
I0527 07:50:27.747678  2100 solver.cpp:409]     Test net output #1: loss = 0.377444 (* 1 = 0.377444 loss)
I0527 07:50:27.755746  2100 solver.cpp:237] Iteration 217500, loss = 1.23508
I0527 07:50:27.755774  2100 solver.cpp:253]     Train net output #0: loss = 1.23508 (* 1 = 1.23508 loss)
I0527 07:50:27.755787  2100 sgd_solver.cpp:106] Iteration 217500, lr = 0.0005
I0527 07:50:37.470692  2100 solver.cpp:237] Iteration 217875, loss = 0.792057
I0527 07:50:37.470727  2100 solver.cpp:253]     Train net output #0: loss = 0.792057 (* 1 = 0.792057 loss)
I0527 07:50:37.470744  2100 sgd_solver.cpp:106] Iteration 217875, lr = 0.0005
I0527 07:50:47.170398  2100 solver.cpp:237] Iteration 218250, loss = 0.983283
I0527 07:50:47.170440  2100 solver.cpp:253]     Train net output #0: loss = 0.983283 (* 1 = 0.983283 loss)
I0527 07:50:47.170456  2100 sgd_solver.cpp:106] Iteration 218250, lr = 0.0005
I0527 07:50:56.868149  2100 solver.cpp:237] Iteration 218625, loss = 1.24647
I0527 07:50:56.868185  2100 solver.cpp:253]     Train net output #0: loss = 1.24647 (* 1 = 1.24647 loss)
I0527 07:50:56.868198  2100 sgd_solver.cpp:106] Iteration 218625, lr = 0.0005
I0527 07:51:27.442912  2100 solver.cpp:237] Iteration 219000, loss = 1.26944
I0527 07:51:27.443095  2100 solver.cpp:253]     Train net output #0: loss = 1.26944 (* 1 = 1.26944 loss)
I0527 07:51:27.443111  2100 sgd_solver.cpp:106] Iteration 219000, lr = 0.0005
I0527 07:51:37.145140  2100 solver.cpp:237] Iteration 219375, loss = 1.07765
I0527 07:51:37.145187  2100 solver.cpp:253]     Train net output #0: loss = 1.07765 (* 1 = 1.07765 loss)
I0527 07:51:37.145201  2100 sgd_solver.cpp:106] Iteration 219375, lr = 0.0005
I0527 07:51:46.851651  2100 solver.cpp:237] Iteration 219750, loss = 0.89438
I0527 07:51:46.851688  2100 solver.cpp:253]     Train net output #0: loss = 0.894379 (* 1 = 0.894379 loss)
I0527 07:51:46.851701  2100 sgd_solver.cpp:106] Iteration 219750, lr = 0.0005
I0527 07:51:56.560719  2100 solver.cpp:237] Iteration 220125, loss = 0.917326
I0527 07:51:56.560761  2100 solver.cpp:253]     Train net output #0: loss = 0.917326 (* 1 = 0.917326 loss)
I0527 07:51:56.560778  2100 sgd_solver.cpp:106] Iteration 220125, lr = 0.0005
I0527 07:52:06.263031  2100 solver.cpp:237] Iteration 220500, loss = 1.29291
I0527 07:52:06.263180  2100 solver.cpp:253]     Train net output #0: loss = 1.29291 (* 1 = 1.29291 loss)
I0527 07:52:06.263193  2100 sgd_solver.cpp:106] Iteration 220500, lr = 0.0005
I0527 07:52:15.975775  2100 solver.cpp:237] Iteration 220875, loss = 1.09052
I0527 07:52:15.975811  2100 solver.cpp:253]     Train net output #0: loss = 1.09052 (* 1 = 1.09052 loss)
I0527 07:52:15.975829  2100 sgd_solver.cpp:106] Iteration 220875, lr = 0.0005
I0527 07:52:25.649363  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_221250.caffemodel
I0527 07:52:25.706388  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_221250.solverstate
I0527 07:52:46.623998  2100 solver.cpp:237] Iteration 221250, loss = 1.32059
I0527 07:52:46.624184  2100 solver.cpp:253]     Train net output #0: loss = 1.32059 (* 1 = 1.32059 loss)
I0527 07:52:46.624200  2100 sgd_solver.cpp:106] Iteration 221250, lr = 0.0005
I0527 07:52:56.338610  2100 solver.cpp:237] Iteration 221625, loss = 0.768037
I0527 07:52:56.338646  2100 solver.cpp:253]     Train net output #0: loss = 0.768037 (* 1 = 0.768037 loss)
I0527 07:52:56.338663  2100 sgd_solver.cpp:106] Iteration 221625, lr = 0.0005
I0527 07:53:06.048907  2100 solver.cpp:237] Iteration 222000, loss = 1.09321
I0527 07:53:06.048943  2100 solver.cpp:253]     Train net output #0: loss = 1.09321 (* 1 = 1.09321 loss)
I0527 07:53:06.048956  2100 sgd_solver.cpp:106] Iteration 222000, lr = 0.0005
I0527 07:53:15.753461  2100 solver.cpp:237] Iteration 222375, loss = 1.4153
I0527 07:53:15.753500  2100 solver.cpp:253]     Train net output #0: loss = 1.4153 (* 1 = 1.4153 loss)
I0527 07:53:15.753517  2100 sgd_solver.cpp:106] Iteration 222375, lr = 0.0005
I0527 07:53:25.462205  2100 solver.cpp:237] Iteration 222750, loss = 1.48799
I0527 07:53:25.462366  2100 solver.cpp:253]     Train net output #0: loss = 1.48799 (* 1 = 1.48799 loss)
I0527 07:53:25.462379  2100 sgd_solver.cpp:106] Iteration 222750, lr = 0.0005
I0527 07:53:35.160012  2100 solver.cpp:237] Iteration 223125, loss = 1.30225
I0527 07:53:35.160058  2100 solver.cpp:253]     Train net output #0: loss = 1.30225 (* 1 = 1.30225 loss)
I0527 07:53:35.160073  2100 sgd_solver.cpp:106] Iteration 223125, lr = 0.0005
I0527 07:53:44.861115  2100 solver.cpp:237] Iteration 223500, loss = 1.36747
I0527 07:53:44.861151  2100 solver.cpp:253]     Train net output #0: loss = 1.36747 (* 1 = 1.36747 loss)
I0527 07:53:44.861166  2100 sgd_solver.cpp:106] Iteration 223500, lr = 0.0005
I0527 07:54:15.451709  2100 solver.cpp:237] Iteration 223875, loss = 1.34411
I0527 07:54:15.451885  2100 solver.cpp:253]     Train net output #0: loss = 1.34411 (* 1 = 1.34411 loss)
I0527 07:54:15.451901  2100 sgd_solver.cpp:106] Iteration 223875, lr = 0.0005
I0527 07:54:25.153460  2100 solver.cpp:237] Iteration 224250, loss = 1.00124
I0527 07:54:25.153507  2100 solver.cpp:253]     Train net output #0: loss = 1.00124 (* 1 = 1.00124 loss)
I0527 07:54:25.153524  2100 sgd_solver.cpp:106] Iteration 224250, lr = 0.0005
I0527 07:54:34.855379  2100 solver.cpp:237] Iteration 224625, loss = 1.22677
I0527 07:54:34.855409  2100 solver.cpp:253]     Train net output #0: loss = 1.22677 (* 1 = 1.22677 loss)
I0527 07:54:34.855423  2100 sgd_solver.cpp:106] Iteration 224625, lr = 0.0005
I0527 07:54:44.536672  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_225000.caffemodel
I0527 07:54:44.594658  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_225000.solverstate
I0527 07:54:44.622370  2100 solver.cpp:341] Iteration 225000, Testing net (#0)
I0527 07:55:32.846150  2100 solver.cpp:409]     Test net output #0: accuracy = 0.886599
I0527 07:55:32.846326  2100 solver.cpp:409]     Test net output #1: loss = 0.369895 (* 1 = 0.369895 loss)
I0527 07:55:32.854354  2100 solver.cpp:237] Iteration 225000, loss = 1.08611
I0527 07:55:32.854382  2100 solver.cpp:253]     Train net output #0: loss = 1.08611 (* 1 = 1.08611 loss)
I0527 07:55:32.854395  2100 sgd_solver.cpp:106] Iteration 225000, lr = 0.0005
I0527 07:55:42.695006  2100 solver.cpp:237] Iteration 225375, loss = 0.918667
I0527 07:55:42.695050  2100 solver.cpp:253]     Train net output #0: loss = 0.918667 (* 1 = 0.918667 loss)
I0527 07:55:42.695070  2100 sgd_solver.cpp:106] Iteration 225375, lr = 0.0005
I0527 07:55:52.529011  2100 solver.cpp:237] Iteration 225750, loss = 1.26416
I0527 07:55:52.529045  2100 solver.cpp:253]     Train net output #0: loss = 1.26416 (* 1 = 1.26416 loss)
I0527 07:55:52.529060  2100 sgd_solver.cpp:106] Iteration 225750, lr = 0.0005
I0527 07:56:02.371145  2100 solver.cpp:237] Iteration 226125, loss = 1.31002
I0527 07:56:02.371181  2100 solver.cpp:253]     Train net output #0: loss = 1.31002 (* 1 = 1.31002 loss)
I0527 07:56:02.371194  2100 sgd_solver.cpp:106] Iteration 226125, lr = 0.0005
I0527 07:56:33.123234  2100 solver.cpp:237] Iteration 226500, loss = 1.07756
I0527 07:56:33.123404  2100 solver.cpp:253]     Train net output #0: loss = 1.07756 (* 1 = 1.07756 loss)
I0527 07:56:33.123420  2100 sgd_solver.cpp:106] Iteration 226500, lr = 0.0005
I0527 07:56:42.958168  2100 solver.cpp:237] Iteration 226875, loss = 1.18198
I0527 07:56:42.958202  2100 solver.cpp:253]     Train net output #0: loss = 1.18198 (* 1 = 1.18198 loss)
I0527 07:56:42.958217  2100 sgd_solver.cpp:106] Iteration 226875, lr = 0.0005
I0527 07:56:52.791596  2100 solver.cpp:237] Iteration 227250, loss = 0.907349
I0527 07:56:52.791632  2100 solver.cpp:253]     Train net output #0: loss = 0.907349 (* 1 = 0.907349 loss)
I0527 07:56:52.791646  2100 sgd_solver.cpp:106] Iteration 227250, lr = 0.0005
I0527 07:57:02.620101  2100 solver.cpp:237] Iteration 227625, loss = 1.19456
I0527 07:57:02.620146  2100 solver.cpp:253]     Train net output #0: loss = 1.19456 (* 1 = 1.19456 loss)
I0527 07:57:02.620162  2100 sgd_solver.cpp:106] Iteration 227625, lr = 0.0005
I0527 07:57:12.460402  2100 solver.cpp:237] Iteration 228000, loss = 1.56453
I0527 07:57:12.460561  2100 solver.cpp:253]     Train net output #0: loss = 1.56453 (* 1 = 1.56453 loss)
I0527 07:57:12.460575  2100 sgd_solver.cpp:106] Iteration 228000, lr = 0.0005
I0527 07:57:22.299772  2100 solver.cpp:237] Iteration 228375, loss = 0.75129
I0527 07:57:22.299815  2100 solver.cpp:253]     Train net output #0: loss = 0.75129 (* 1 = 0.75129 loss)
I0527 07:57:22.299830  2100 sgd_solver.cpp:106] Iteration 228375, lr = 0.0005
I0527 07:57:32.111227  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_228750.caffemodel
I0527 07:57:32.167587  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_228750.solverstate
I0527 07:57:53.104367  2100 solver.cpp:237] Iteration 228750, loss = 1.20418
I0527 07:57:53.104552  2100 solver.cpp:253]     Train net output #0: loss = 1.20418 (* 1 = 1.20418 loss)
I0527 07:57:53.104568  2100 sgd_solver.cpp:106] Iteration 228750, lr = 0.0005
I0527 07:58:02.945492  2100 solver.cpp:237] Iteration 229125, loss = 1.17012
I0527 07:58:02.945526  2100 solver.cpp:253]     Train net output #0: loss = 1.17012 (* 1 = 1.17012 loss)
I0527 07:58:02.945544  2100 sgd_solver.cpp:106] Iteration 229125, lr = 0.0005
I0527 07:58:12.788543  2100 solver.cpp:237] Iteration 229500, loss = 0.96794
I0527 07:58:12.788594  2100 solver.cpp:253]     Train net output #0: loss = 0.96794 (* 1 = 0.96794 loss)
I0527 07:58:12.788607  2100 sgd_solver.cpp:106] Iteration 229500, lr = 0.0005
I0527 07:58:22.630475  2100 solver.cpp:237] Iteration 229875, loss = 1.22834
I0527 07:58:22.630511  2100 solver.cpp:253]     Train net output #0: loss = 1.22834 (* 1 = 1.22834 loss)
I0527 07:58:22.630524  2100 sgd_solver.cpp:106] Iteration 229875, lr = 0.0005
I0527 07:58:32.470352  2100 solver.cpp:237] Iteration 230250, loss = 1.18794
I0527 07:58:32.470515  2100 solver.cpp:253]     Train net output #0: loss = 1.18794 (* 1 = 1.18794 loss)
I0527 07:58:32.470530  2100 sgd_solver.cpp:106] Iteration 230250, lr = 0.0005
I0527 07:58:42.312897  2100 solver.cpp:237] Iteration 230625, loss = 1.06293
I0527 07:58:42.312942  2100 solver.cpp:253]     Train net output #0: loss = 1.06293 (* 1 = 1.06293 loss)
I0527 07:58:42.312957  2100 sgd_solver.cpp:106] Iteration 230625, lr = 0.0005
I0527 07:58:52.152485  2100 solver.cpp:237] Iteration 231000, loss = 1.1098
I0527 07:58:52.152521  2100 solver.cpp:253]     Train net output #0: loss = 1.1098 (* 1 = 1.1098 loss)
I0527 07:58:52.152535  2100 sgd_solver.cpp:106] Iteration 231000, lr = 0.0005
I0527 07:59:22.924712  2100 solver.cpp:237] Iteration 231375, loss = 1.13175
I0527 07:59:22.924888  2100 solver.cpp:253]     Train net output #0: loss = 1.13175 (* 1 = 1.13175 loss)
I0527 07:59:22.924903  2100 sgd_solver.cpp:106] Iteration 231375, lr = 0.0005
I0527 07:59:32.767391  2100 solver.cpp:237] Iteration 231750, loss = 0.903283
I0527 07:59:32.767438  2100 solver.cpp:253]     Train net output #0: loss = 0.903283 (* 1 = 0.903283 loss)
I0527 07:59:32.767453  2100 sgd_solver.cpp:106] Iteration 231750, lr = 0.0005
I0527 07:59:42.602535  2100 solver.cpp:237] Iteration 232125, loss = 0.946801
I0527 07:59:42.602572  2100 solver.cpp:253]     Train net output #0: loss = 0.946801 (* 1 = 0.946801 loss)
I0527 07:59:42.602586  2100 sgd_solver.cpp:106] Iteration 232125, lr = 0.0005
I0527 07:59:52.407784  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_232500.caffemodel
I0527 07:59:52.464349  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_232500.solverstate
I0527 07:59:52.489578  2100 solver.cpp:341] Iteration 232500, Testing net (#0)
I0527 08:01:01.945087  2100 solver.cpp:409]     Test net output #0: accuracy = 0.888119
I0527 08:01:01.945283  2100 solver.cpp:409]     Test net output #1: loss = 0.35488 (* 1 = 0.35488 loss)
I0527 08:01:01.953320  2100 solver.cpp:237] Iteration 232500, loss = 1.02421
I0527 08:01:01.953347  2100 solver.cpp:253]     Train net output #0: loss = 1.02421 (* 1 = 1.02421 loss)
I0527 08:01:01.953361  2100 sgd_solver.cpp:106] Iteration 232500, lr = 0.0005
I0527 08:01:11.737646  2100 solver.cpp:237] Iteration 232875, loss = 1.26554
I0527 08:01:11.737692  2100 solver.cpp:253]     Train net output #0: loss = 1.26554 (* 1 = 1.26554 loss)
I0527 08:01:11.737709  2100 sgd_solver.cpp:106] Iteration 232875, lr = 0.0005
I0527 08:01:21.526273  2100 solver.cpp:237] Iteration 233250, loss = 1.16424
I0527 08:01:21.526309  2100 solver.cpp:253]     Train net output #0: loss = 1.16424 (* 1 = 1.16424 loss)
I0527 08:01:21.526322  2100 sgd_solver.cpp:106] Iteration 233250, lr = 0.0005
I0527 08:01:31.314491  2100 solver.cpp:237] Iteration 233625, loss = 0.841053
I0527 08:01:31.314534  2100 solver.cpp:253]     Train net output #0: loss = 0.841053 (* 1 = 0.841053 loss)
I0527 08:01:31.314551  2100 sgd_solver.cpp:106] Iteration 233625, lr = 0.0005
I0527 08:02:02.006161  2100 solver.cpp:237] Iteration 234000, loss = 0.864291
I0527 08:02:02.006343  2100 solver.cpp:253]     Train net output #0: loss = 0.864291 (* 1 = 0.864291 loss)
I0527 08:02:02.006359  2100 sgd_solver.cpp:106] Iteration 234000, lr = 0.0005
I0527 08:02:11.795819  2100 solver.cpp:237] Iteration 234375, loss = 1.54252
I0527 08:02:11.795853  2100 solver.cpp:253]     Train net output #0: loss = 1.54252 (* 1 = 1.54252 loss)
I0527 08:02:11.795867  2100 sgd_solver.cpp:106] Iteration 234375, lr = 0.0005
I0527 08:02:21.582690  2100 solver.cpp:237] Iteration 234750, loss = 1.11626
I0527 08:02:21.582732  2100 solver.cpp:253]     Train net output #0: loss = 1.11626 (* 1 = 1.11626 loss)
I0527 08:02:21.582751  2100 sgd_solver.cpp:106] Iteration 234750, lr = 0.0005
I0527 08:02:31.369082  2100 solver.cpp:237] Iteration 235125, loss = 1.19304
I0527 08:02:31.369118  2100 solver.cpp:253]     Train net output #0: loss = 1.19304 (* 1 = 1.19304 loss)
I0527 08:02:31.369132  2100 sgd_solver.cpp:106] Iteration 235125, lr = 0.0005
I0527 08:02:41.152470  2100 solver.cpp:237] Iteration 235500, loss = 1.56746
I0527 08:02:41.152621  2100 solver.cpp:253]     Train net output #0: loss = 1.56746 (* 1 = 1.56746 loss)
I0527 08:02:41.152636  2100 sgd_solver.cpp:106] Iteration 235500, lr = 0.0005
I0527 08:02:50.941715  2100 solver.cpp:237] Iteration 235875, loss = 1.18243
I0527 08:02:50.941758  2100 solver.cpp:253]     Train net output #0: loss = 1.18243 (* 1 = 1.18243 loss)
I0527 08:02:50.941774  2100 sgd_solver.cpp:106] Iteration 235875, lr = 0.0005
I0527 08:03:00.701055  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_236250.caffemodel
I0527 08:03:00.759583  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_236250.solverstate
I0527 08:03:21.690466  2100 solver.cpp:237] Iteration 236250, loss = 1.46016
I0527 08:03:21.690660  2100 solver.cpp:253]     Train net output #0: loss = 1.46016 (* 1 = 1.46016 loss)
I0527 08:03:21.690677  2100 sgd_solver.cpp:106] Iteration 236250, lr = 0.0005
I0527 08:03:31.479712  2100 solver.cpp:237] Iteration 236625, loss = 1.14737
I0527 08:03:31.479744  2100 solver.cpp:253]     Train net output #0: loss = 1.14737 (* 1 = 1.14737 loss)
I0527 08:03:31.479765  2100 sgd_solver.cpp:106] Iteration 236625, lr = 0.0005
I0527 08:03:41.263619  2100 solver.cpp:237] Iteration 237000, loss = 0.895933
I0527 08:03:41.263660  2100 solver.cpp:253]     Train net output #0: loss = 0.895933 (* 1 = 0.895933 loss)
I0527 08:03:41.263679  2100 sgd_solver.cpp:106] Iteration 237000, lr = 0.0005
I0527 08:03:51.052139  2100 solver.cpp:237] Iteration 237375, loss = 0.914155
I0527 08:03:51.052176  2100 solver.cpp:253]     Train net output #0: loss = 0.914155 (* 1 = 0.914155 loss)
I0527 08:03:51.052189  2100 sgd_solver.cpp:106] Iteration 237375, lr = 0.0005
I0527 08:04:00.836272  2100 solver.cpp:237] Iteration 237750, loss = 0.809348
I0527 08:04:00.836452  2100 solver.cpp:253]     Train net output #0: loss = 0.809348 (* 1 = 0.809348 loss)
I0527 08:04:00.836467  2100 sgd_solver.cpp:106] Iteration 237750, lr = 0.0005
I0527 08:04:10.625530  2100 solver.cpp:237] Iteration 238125, loss = 1.09602
I0527 08:04:10.625563  2100 solver.cpp:253]     Train net output #0: loss = 1.09602 (* 1 = 1.09602 loss)
I0527 08:04:10.625577  2100 sgd_solver.cpp:106] Iteration 238125, lr = 0.0005
I0527 08:04:20.407646  2100 solver.cpp:237] Iteration 238500, loss = 1.02416
I0527 08:04:20.407681  2100 solver.cpp:253]     Train net output #0: loss = 1.02416 (* 1 = 1.02416 loss)
I0527 08:04:20.407694  2100 sgd_solver.cpp:106] Iteration 238500, lr = 0.0005
I0527 08:04:51.119218  2100 solver.cpp:237] Iteration 238875, loss = 1.1769
I0527 08:04:51.119484  2100 solver.cpp:253]     Train net output #0: loss = 1.1769 (* 1 = 1.1769 loss)
I0527 08:04:51.119500  2100 sgd_solver.cpp:106] Iteration 238875, lr = 0.0005
I0527 08:05:00.903146  2100 solver.cpp:237] Iteration 239250, loss = 1.34558
I0527 08:05:00.903182  2100 solver.cpp:253]     Train net output #0: loss = 1.34558 (* 1 = 1.34558 loss)
I0527 08:05:00.903199  2100 sgd_solver.cpp:106] Iteration 239250, lr = 0.0005
I0527 08:05:10.686199  2100 solver.cpp:237] Iteration 239625, loss = 1.11098
I0527 08:05:10.686234  2100 solver.cpp:253]     Train net output #0: loss = 1.11098 (* 1 = 1.11098 loss)
I0527 08:05:10.686250  2100 sgd_solver.cpp:106] Iteration 239625, lr = 0.0005
I0527 08:05:20.445441  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_240000.caffemodel
I0527 08:05:20.502667  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_240000.solverstate
I0527 08:05:20.529613  2100 solver.cpp:341] Iteration 240000, Testing net (#0)
I0527 08:06:09.141460  2100 solver.cpp:409]     Test net output #0: accuracy = 0.888093
I0527 08:06:09.141630  2100 solver.cpp:409]     Test net output #1: loss = 0.362522 (* 1 = 0.362522 loss)
I0527 08:06:09.149737  2100 solver.cpp:237] Iteration 240000, loss = 1.46646
I0527 08:06:09.149765  2100 solver.cpp:253]     Train net output #0: loss = 1.46646 (* 1 = 1.46646 loss)
I0527 08:06:09.149782  2100 sgd_solver.cpp:106] Iteration 240000, lr = 0.0005
I0527 08:06:18.878345  2100 solver.cpp:237] Iteration 240375, loss = 1.27605
I0527 08:06:18.878381  2100 solver.cpp:253]     Train net output #0: loss = 1.27605 (* 1 = 1.27605 loss)
I0527 08:06:18.878394  2100 sgd_solver.cpp:106] Iteration 240375, lr = 0.0005
I0527 08:06:28.615516  2100 solver.cpp:237] Iteration 240750, loss = 1.12711
I0527 08:06:28.615552  2100 solver.cpp:253]     Train net output #0: loss = 1.12711 (* 1 = 1.12711 loss)
I0527 08:06:28.615566  2100 sgd_solver.cpp:106] Iteration 240750, lr = 0.0005
I0527 08:06:38.353498  2100 solver.cpp:237] Iteration 241125, loss = 1.14947
I0527 08:06:38.353533  2100 solver.cpp:253]     Train net output #0: loss = 1.14947 (* 1 = 1.14947 loss)
I0527 08:06:38.353552  2100 sgd_solver.cpp:106] Iteration 241125, lr = 0.0005
I0527 08:07:08.998703  2100 solver.cpp:237] Iteration 241500, loss = 1.01563
I0527 08:07:08.998903  2100 solver.cpp:253]     Train net output #0: loss = 1.01563 (* 1 = 1.01563 loss)
I0527 08:07:08.998919  2100 sgd_solver.cpp:106] Iteration 241500, lr = 0.0005
I0527 08:07:18.735306  2100 solver.cpp:237] Iteration 241875, loss = 1.36955
I0527 08:07:18.735339  2100 solver.cpp:253]     Train net output #0: loss = 1.36955 (* 1 = 1.36955 loss)
I0527 08:07:18.735357  2100 sgd_solver.cpp:106] Iteration 241875, lr = 0.0005
I0527 08:07:28.465591  2100 solver.cpp:237] Iteration 242250, loss = 1.29273
I0527 08:07:28.465634  2100 solver.cpp:253]     Train net output #0: loss = 1.29273 (* 1 = 1.29273 loss)
I0527 08:07:28.465649  2100 sgd_solver.cpp:106] Iteration 242250, lr = 0.0005
I0527 08:07:38.198498  2100 solver.cpp:237] Iteration 242625, loss = 1.18624
I0527 08:07:38.198535  2100 solver.cpp:253]     Train net output #0: loss = 1.18624 (* 1 = 1.18624 loss)
I0527 08:07:38.198549  2100 sgd_solver.cpp:106] Iteration 242625, lr = 0.0005
I0527 08:07:47.931574  2100 solver.cpp:237] Iteration 243000, loss = 1.13654
I0527 08:07:47.931741  2100 solver.cpp:253]     Train net output #0: loss = 1.13654 (* 1 = 1.13654 loss)
I0527 08:07:47.931756  2100 sgd_solver.cpp:106] Iteration 243000, lr = 0.0005
I0527 08:07:57.664500  2100 solver.cpp:237] Iteration 243375, loss = 1.44519
I0527 08:07:57.664535  2100 solver.cpp:253]     Train net output #0: loss = 1.44519 (* 1 = 1.44519 loss)
I0527 08:07:57.664549  2100 sgd_solver.cpp:106] Iteration 243375, lr = 0.0005
I0527 08:08:07.367650  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_243750.caffemodel
I0527 08:08:07.425201  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_243750.solverstate
I0527 08:08:28.375958  2100 solver.cpp:237] Iteration 243750, loss = 1.04348
I0527 08:08:28.376149  2100 solver.cpp:253]     Train net output #0: loss = 1.04348 (* 1 = 1.04348 loss)
I0527 08:08:28.376166  2100 sgd_solver.cpp:106] Iteration 243750, lr = 0.0005
I0527 08:08:38.110618  2100 solver.cpp:237] Iteration 244125, loss = 0.940865
I0527 08:08:38.110661  2100 solver.cpp:253]     Train net output #0: loss = 0.940865 (* 1 = 0.940865 loss)
I0527 08:08:38.110679  2100 sgd_solver.cpp:106] Iteration 244125, lr = 0.0005
I0527 08:08:47.835665  2100 solver.cpp:237] Iteration 244500, loss = 1.1799
I0527 08:08:47.835701  2100 solver.cpp:253]     Train net output #0: loss = 1.1799 (* 1 = 1.1799 loss)
I0527 08:08:47.835717  2100 sgd_solver.cpp:106] Iteration 244500, lr = 0.0005
I0527 08:08:57.572898  2100 solver.cpp:237] Iteration 244875, loss = 1.13167
I0527 08:08:57.572933  2100 solver.cpp:253]     Train net output #0: loss = 1.13167 (* 1 = 1.13167 loss)
I0527 08:08:57.572950  2100 sgd_solver.cpp:106] Iteration 244875, lr = 0.0005
I0527 08:09:07.312589  2100 solver.cpp:237] Iteration 245250, loss = 1.17608
I0527 08:09:07.312759  2100 solver.cpp:253]     Train net output #0: loss = 1.17608 (* 1 = 1.17608 loss)
I0527 08:09:07.312774  2100 sgd_solver.cpp:106] Iteration 245250, lr = 0.0005
I0527 08:09:17.042767  2100 solver.cpp:237] Iteration 245625, loss = 1.39104
I0527 08:09:17.042801  2100 solver.cpp:253]     Train net output #0: loss = 1.39104 (* 1 = 1.39104 loss)
I0527 08:09:17.042815  2100 sgd_solver.cpp:106] Iteration 245625, lr = 0.0005
I0527 08:09:26.778806  2100 solver.cpp:237] Iteration 246000, loss = 1.13636
I0527 08:09:26.778854  2100 solver.cpp:253]     Train net output #0: loss = 1.13636 (* 1 = 1.13636 loss)
I0527 08:09:26.778868  2100 sgd_solver.cpp:106] Iteration 246000, lr = 0.0005
I0527 08:09:57.398422  2100 solver.cpp:237] Iteration 246375, loss = 1.23349
I0527 08:09:57.398609  2100 solver.cpp:253]     Train net output #0: loss = 1.23349 (* 1 = 1.23349 loss)
I0527 08:09:57.398624  2100 sgd_solver.cpp:106] Iteration 246375, lr = 0.0005
I0527 08:10:07.133056  2100 solver.cpp:237] Iteration 246750, loss = 1.04416
I0527 08:10:07.133090  2100 solver.cpp:253]     Train net output #0: loss = 1.04416 (* 1 = 1.04416 loss)
I0527 08:10:07.133105  2100 sgd_solver.cpp:106] Iteration 246750, lr = 0.0005
I0527 08:10:16.868237  2100 solver.cpp:237] Iteration 247125, loss = 1.96599
I0527 08:10:16.868281  2100 solver.cpp:253]     Train net output #0: loss = 1.96599 (* 1 = 1.96599 loss)
I0527 08:10:16.868296  2100 sgd_solver.cpp:106] Iteration 247125, lr = 0.0005
I0527 08:10:26.574336  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_247500.caffemodel
I0527 08:10:26.632521  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_247500.solverstate
I0527 08:10:26.660043  2100 solver.cpp:341] Iteration 247500, Testing net (#0)
I0527 08:11:36.144095  2100 solver.cpp:409]     Test net output #0: accuracy = 0.889633
I0527 08:11:36.144273  2100 solver.cpp:409]     Test net output #1: loss = 0.343266 (* 1 = 0.343266 loss)
I0527 08:11:36.152341  2100 solver.cpp:237] Iteration 247500, loss = 1.05451
I0527 08:11:36.152369  2100 solver.cpp:253]     Train net output #0: loss = 1.05451 (* 1 = 1.05451 loss)
I0527 08:11:36.152384  2100 sgd_solver.cpp:106] Iteration 247500, lr = 0.0005
I0527 08:11:45.878999  2100 solver.cpp:237] Iteration 247875, loss = 1.31182
I0527 08:11:45.879034  2100 solver.cpp:253]     Train net output #0: loss = 1.31182 (* 1 = 1.31182 loss)
I0527 08:11:45.879052  2100 sgd_solver.cpp:106] Iteration 247875, lr = 0.0005
I0527 08:11:55.610205  2100 solver.cpp:237] Iteration 248250, loss = 1.35108
I0527 08:11:55.610255  2100 solver.cpp:253]     Train net output #0: loss = 1.35108 (* 1 = 1.35108 loss)
I0527 08:11:55.610268  2100 sgd_solver.cpp:106] Iteration 248250, lr = 0.0005
I0527 08:12:05.340651  2100 solver.cpp:237] Iteration 248625, loss = 0.890564
I0527 08:12:05.340687  2100 solver.cpp:253]     Train net output #0: loss = 0.890564 (* 1 = 0.890564 loss)
I0527 08:12:05.340700  2100 sgd_solver.cpp:106] Iteration 248625, lr = 0.0005
I0527 08:12:35.987057  2100 solver.cpp:237] Iteration 249000, loss = 1.02332
I0527 08:12:35.987233  2100 solver.cpp:253]     Train net output #0: loss = 1.02332 (* 1 = 1.02332 loss)
I0527 08:12:35.987249  2100 sgd_solver.cpp:106] Iteration 249000, lr = 0.0005
I0527 08:12:45.723572  2100 solver.cpp:237] Iteration 249375, loss = 1.21208
I0527 08:12:45.723618  2100 solver.cpp:253]     Train net output #0: loss = 1.21208 (* 1 = 1.21208 loss)
I0527 08:12:45.723631  2100 sgd_solver.cpp:106] Iteration 249375, lr = 0.0005
I0527 08:12:55.455792  2100 solver.cpp:237] Iteration 249750, loss = 1.36447
I0527 08:12:55.455827  2100 solver.cpp:253]     Train net output #0: loss = 1.36447 (* 1 = 1.36447 loss)
I0527 08:12:55.455843  2100 sgd_solver.cpp:106] Iteration 249750, lr = 0.0005
I0527 08:13:05.197270  2100 solver.cpp:237] Iteration 250125, loss = 1.04798
I0527 08:13:05.197305  2100 solver.cpp:253]     Train net output #0: loss = 1.04798 (* 1 = 1.04798 loss)
I0527 08:13:05.197319  2100 sgd_solver.cpp:106] Iteration 250125, lr = 0.0005
I0527 08:13:14.937021  2100 solver.cpp:237] Iteration 250500, loss = 1.27889
I0527 08:13:14.937193  2100 solver.cpp:253]     Train net output #0: loss = 1.27889 (* 1 = 1.27889 loss)
I0527 08:13:14.937207  2100 sgd_solver.cpp:106] Iteration 250500, lr = 0.0005
I0527 08:13:24.665238  2100 solver.cpp:237] Iteration 250875, loss = 1.10816
I0527 08:13:24.665277  2100 solver.cpp:253]     Train net output #0: loss = 1.10816 (* 1 = 1.10816 loss)
I0527 08:13:24.665294  2100 sgd_solver.cpp:106] Iteration 250875, lr = 0.0005
I0527 08:13:34.374819  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_251250.caffemodel
I0527 08:13:34.430924  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_251250.solverstate
I0527 08:13:55.321518  2100 solver.cpp:237] Iteration 251250, loss = 1.12458
I0527 08:13:55.321717  2100 solver.cpp:253]     Train net output #0: loss = 1.12458 (* 1 = 1.12458 loss)
I0527 08:13:55.321733  2100 sgd_solver.cpp:106] Iteration 251250, lr = 0.0005
I0527 08:14:05.055768  2100 solver.cpp:237] Iteration 251625, loss = 1.25114
I0527 08:14:05.055810  2100 solver.cpp:253]     Train net output #0: loss = 1.25114 (* 1 = 1.25114 loss)
I0527 08:14:05.055825  2100 sgd_solver.cpp:106] Iteration 251625, lr = 0.0005
I0527 08:14:14.791008  2100 solver.cpp:237] Iteration 252000, loss = 1.06614
I0527 08:14:14.791044  2100 solver.cpp:253]     Train net output #0: loss = 1.06614 (* 1 = 1.06614 loss)
I0527 08:14:14.791059  2100 sgd_solver.cpp:106] Iteration 252000, lr = 0.0005
I0527 08:14:24.522894  2100 solver.cpp:237] Iteration 252375, loss = 0.95245
I0527 08:14:24.522932  2100 solver.cpp:253]     Train net output #0: loss = 0.95245 (* 1 = 0.95245 loss)
I0527 08:14:24.522948  2100 sgd_solver.cpp:106] Iteration 252375, lr = 0.0005
I0527 08:14:34.253680  2100 solver.cpp:237] Iteration 252750, loss = 1.24226
I0527 08:14:34.253854  2100 solver.cpp:253]     Train net output #0: loss = 1.24226 (* 1 = 1.24226 loss)
I0527 08:14:34.253867  2100 sgd_solver.cpp:106] Iteration 252750, lr = 0.0005
I0527 08:14:43.992812  2100 solver.cpp:237] Iteration 253125, loss = 1.26827
I0527 08:14:43.992847  2100 solver.cpp:253]     Train net output #0: loss = 1.26827 (* 1 = 1.26827 loss)
I0527 08:14:43.992861  2100 sgd_solver.cpp:106] Iteration 253125, lr = 0.0005
I0527 08:14:53.727251  2100 solver.cpp:237] Iteration 253500, loss = 1.14185
I0527 08:14:53.727291  2100 solver.cpp:253]     Train net output #0: loss = 1.14185 (* 1 = 1.14185 loss)
I0527 08:14:53.727304  2100 sgd_solver.cpp:106] Iteration 253500, lr = 0.0005
I0527 08:15:24.337999  2100 solver.cpp:237] Iteration 253875, loss = 1.379
I0527 08:15:24.338178  2100 solver.cpp:253]     Train net output #0: loss = 1.379 (* 1 = 1.379 loss)
I0527 08:15:24.338193  2100 sgd_solver.cpp:106] Iteration 253875, lr = 0.0005
I0527 08:15:34.065991  2100 solver.cpp:237] Iteration 254250, loss = 0.795659
I0527 08:15:34.066027  2100 solver.cpp:253]     Train net output #0: loss = 0.795659 (* 1 = 0.795659 loss)
I0527 08:15:34.066040  2100 sgd_solver.cpp:106] Iteration 254250, lr = 0.0005
I0527 08:15:43.807601  2100 solver.cpp:237] Iteration 254625, loss = 1.20259
I0527 08:15:43.807647  2100 solver.cpp:253]     Train net output #0: loss = 1.20259 (* 1 = 1.20259 loss)
I0527 08:15:43.807662  2100 sgd_solver.cpp:106] Iteration 254625, lr = 0.0005
I0527 08:15:53.519140  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_255000.caffemodel
I0527 08:15:53.575469  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_255000.solverstate
I0527 08:15:53.601469  2100 solver.cpp:341] Iteration 255000, Testing net (#0)
I0527 08:16:41.840217  2100 solver.cpp:409]     Test net output #0: accuracy = 0.889966
I0527 08:16:41.840394  2100 solver.cpp:409]     Test net output #1: loss = 0.35924 (* 1 = 0.35924 loss)
I0527 08:16:41.848484  2100 solver.cpp:237] Iteration 255000, loss = 1.07224
I0527 08:16:41.848511  2100 solver.cpp:253]     Train net output #0: loss = 1.07224 (* 1 = 1.07224 loss)
I0527 08:16:41.848526  2100 sgd_solver.cpp:106] Iteration 255000, lr = 0.0005
I0527 08:16:51.680631  2100 solver.cpp:237] Iteration 255375, loss = 0.984991
I0527 08:16:51.680668  2100 solver.cpp:253]     Train net output #0: loss = 0.984991 (* 1 = 0.984991 loss)
I0527 08:16:51.680682  2100 sgd_solver.cpp:106] Iteration 255375, lr = 0.0005
I0527 08:17:01.514989  2100 solver.cpp:237] Iteration 255750, loss = 1.21336
I0527 08:17:01.515031  2100 solver.cpp:253]     Train net output #0: loss = 1.21336 (* 1 = 1.21336 loss)
I0527 08:17:01.515051  2100 sgd_solver.cpp:106] Iteration 255750, lr = 0.0005
I0527 08:17:11.351096  2100 solver.cpp:237] Iteration 256125, loss = 1.22802
I0527 08:17:11.351131  2100 solver.cpp:253]     Train net output #0: loss = 1.22802 (* 1 = 1.22802 loss)
I0527 08:17:11.351145  2100 sgd_solver.cpp:106] Iteration 256125, lr = 0.0005
I0527 08:17:42.040304  2100 solver.cpp:237] Iteration 256500, loss = 1.47548
I0527 08:17:42.040493  2100 solver.cpp:253]     Train net output #0: loss = 1.47548 (* 1 = 1.47548 loss)
I0527 08:17:42.040508  2100 sgd_solver.cpp:106] Iteration 256500, lr = 0.0005
I0527 08:17:51.868382  2100 solver.cpp:237] Iteration 256875, loss = 1.31504
I0527 08:17:51.868424  2100 solver.cpp:253]     Train net output #0: loss = 1.31504 (* 1 = 1.31504 loss)
I0527 08:17:51.868446  2100 sgd_solver.cpp:106] Iteration 256875, lr = 0.0005
I0527 08:18:01.699985  2100 solver.cpp:237] Iteration 257250, loss = 1.0611
I0527 08:18:01.700019  2100 solver.cpp:253]     Train net output #0: loss = 1.0611 (* 1 = 1.0611 loss)
I0527 08:18:01.700037  2100 sgd_solver.cpp:106] Iteration 257250, lr = 0.0005
I0527 08:18:11.543838  2100 solver.cpp:237] Iteration 257625, loss = 1.08604
I0527 08:18:11.543879  2100 solver.cpp:253]     Train net output #0: loss = 1.08604 (* 1 = 1.08604 loss)
I0527 08:18:11.543896  2100 sgd_solver.cpp:106] Iteration 257625, lr = 0.0005
I0527 08:18:21.383462  2100 solver.cpp:237] Iteration 258000, loss = 1.2453
I0527 08:18:21.383631  2100 solver.cpp:253]     Train net output #0: loss = 1.2453 (* 1 = 1.2453 loss)
I0527 08:18:21.383646  2100 sgd_solver.cpp:106] Iteration 258000, lr = 0.0005
I0527 08:18:31.223697  2100 solver.cpp:237] Iteration 258375, loss = 0.898454
I0527 08:18:31.223733  2100 solver.cpp:253]     Train net output #0: loss = 0.898454 (* 1 = 0.898454 loss)
I0527 08:18:31.223747  2100 sgd_solver.cpp:106] Iteration 258375, lr = 0.0005
I0527 08:18:41.040521  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_258750.caffemodel
I0527 08:18:41.098523  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_258750.solverstate
I0527 08:19:02.014904  2100 solver.cpp:237] Iteration 258750, loss = 1.44482
I0527 08:19:02.015096  2100 solver.cpp:253]     Train net output #0: loss = 1.44482 (* 1 = 1.44482 loss)
I0527 08:19:02.015113  2100 sgd_solver.cpp:106] Iteration 258750, lr = 0.0005
I0527 08:19:11.847761  2100 solver.cpp:237] Iteration 259125, loss = 1.30665
I0527 08:19:11.847796  2100 solver.cpp:253]     Train net output #0: loss = 1.30665 (* 1 = 1.30665 loss)
I0527 08:19:11.847815  2100 sgd_solver.cpp:106] Iteration 259125, lr = 0.0005
I0527 08:19:21.691589  2100 solver.cpp:237] Iteration 259500, loss = 1.43376
I0527 08:19:21.691624  2100 solver.cpp:253]     Train net output #0: loss = 1.43376 (* 1 = 1.43376 loss)
I0527 08:19:21.691642  2100 sgd_solver.cpp:106] Iteration 259500, lr = 0.0005
I0527 08:19:31.526222  2100 solver.cpp:237] Iteration 259875, loss = 1.30935
I0527 08:19:31.526262  2100 solver.cpp:253]     Train net output #0: loss = 1.30935 (* 1 = 1.30935 loss)
I0527 08:19:31.526284  2100 sgd_solver.cpp:106] Iteration 259875, lr = 0.0005
I0527 08:19:41.361480  2100 solver.cpp:237] Iteration 260250, loss = 1.37387
I0527 08:19:41.361637  2100 solver.cpp:253]     Train net output #0: loss = 1.37387 (* 1 = 1.37387 loss)
I0527 08:19:41.361651  2100 sgd_solver.cpp:106] Iteration 260250, lr = 0.0005
I0527 08:19:51.202018  2100 solver.cpp:237] Iteration 260625, loss = 0.987026
I0527 08:19:51.202057  2100 solver.cpp:253]     Train net output #0: loss = 0.987026 (* 1 = 0.987026 loss)
I0527 08:19:51.202077  2100 sgd_solver.cpp:106] Iteration 260625, lr = 0.0005
I0527 08:20:01.041817  2100 solver.cpp:237] Iteration 261000, loss = 1.02178
I0527 08:20:01.041852  2100 solver.cpp:253]     Train net output #0: loss = 1.02178 (* 1 = 1.02178 loss)
I0527 08:20:01.041869  2100 sgd_solver.cpp:106] Iteration 261000, lr = 0.0005
I0527 08:20:31.733667  2100 solver.cpp:237] Iteration 261375, loss = 1.18553
I0527 08:20:31.733858  2100 solver.cpp:253]     Train net output #0: loss = 1.18553 (* 1 = 1.18553 loss)
I0527 08:20:31.733875  2100 sgd_solver.cpp:106] Iteration 261375, lr = 0.0005
I0527 08:20:41.575235  2100 solver.cpp:237] Iteration 261750, loss = 1.26479
I0527 08:20:41.575278  2100 solver.cpp:253]     Train net output #0: loss = 1.26479 (* 1 = 1.26479 loss)
I0527 08:20:41.575299  2100 sgd_solver.cpp:106] Iteration 261750, lr = 0.0005
I0527 08:20:51.416357  2100 solver.cpp:237] Iteration 262125, loss = 1.06621
I0527 08:20:51.416391  2100 solver.cpp:253]     Train net output #0: loss = 1.06621 (* 1 = 1.06621 loss)
I0527 08:20:51.416406  2100 sgd_solver.cpp:106] Iteration 262125, lr = 0.0005
I0527 08:21:01.232710  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_262500.caffemodel
I0527 08:21:01.290400  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_262500.solverstate
I0527 08:21:01.319618  2100 solver.cpp:341] Iteration 262500, Testing net (#0)
I0527 08:22:10.826411  2100 solver.cpp:409]     Test net output #0: accuracy = 0.890173
I0527 08:22:10.826596  2100 solver.cpp:409]     Test net output #1: loss = 0.350711 (* 1 = 0.350711 loss)
I0527 08:22:10.834692  2100 solver.cpp:237] Iteration 262500, loss = 0.944636
I0527 08:22:10.834719  2100 solver.cpp:253]     Train net output #0: loss = 0.944636 (* 1 = 0.944636 loss)
I0527 08:22:10.834734  2100 sgd_solver.cpp:106] Iteration 262500, lr = 0.0005
I0527 08:22:20.702478  2100 solver.cpp:237] Iteration 262875, loss = 1.18289
I0527 08:22:20.702527  2100 solver.cpp:253]     Train net output #0: loss = 1.18289 (* 1 = 1.18289 loss)
I0527 08:22:20.702543  2100 sgd_solver.cpp:106] Iteration 262875, lr = 0.0005
I0527 08:22:30.551681  2100 solver.cpp:237] Iteration 263250, loss = 1.00136
I0527 08:22:30.551715  2100 solver.cpp:253]     Train net output #0: loss = 1.00136 (* 1 = 1.00136 loss)
I0527 08:22:30.551729  2100 sgd_solver.cpp:106] Iteration 263250, lr = 0.0005
I0527 08:22:40.403535  2100 solver.cpp:237] Iteration 263625, loss = 1.21609
I0527 08:22:40.403569  2100 solver.cpp:253]     Train net output #0: loss = 1.21609 (* 1 = 1.21609 loss)
I0527 08:22:40.403584  2100 sgd_solver.cpp:106] Iteration 263625, lr = 0.0005
I0527 08:23:11.182891  2100 solver.cpp:237] Iteration 264000, loss = 1.10531
I0527 08:23:11.183068  2100 solver.cpp:253]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0527 08:23:11.183084  2100 sgd_solver.cpp:106] Iteration 264000, lr = 0.0005
I0527 08:23:21.031350  2100 solver.cpp:237] Iteration 264375, loss = 1.10907
I0527 08:23:21.031385  2100 solver.cpp:253]     Train net output #0: loss = 1.10907 (* 1 = 1.10907 loss)
I0527 08:23:21.031399  2100 sgd_solver.cpp:106] Iteration 264375, lr = 0.0005
I0527 08:23:30.883294  2100 solver.cpp:237] Iteration 264750, loss = 1.18073
I0527 08:23:30.883330  2100 solver.cpp:253]     Train net output #0: loss = 1.18073 (* 1 = 1.18073 loss)
I0527 08:23:30.883347  2100 sgd_solver.cpp:106] Iteration 264750, lr = 0.0005
I0527 08:23:40.733355  2100 solver.cpp:237] Iteration 265125, loss = 1.12711
I0527 08:23:40.733402  2100 solver.cpp:253]     Train net output #0: loss = 1.12711 (* 1 = 1.12711 loss)
I0527 08:23:40.733418  2100 sgd_solver.cpp:106] Iteration 265125, lr = 0.0005
I0527 08:23:50.596879  2100 solver.cpp:237] Iteration 265500, loss = 1.02574
I0527 08:23:50.597069  2100 solver.cpp:253]     Train net output #0: loss = 1.02574 (* 1 = 1.02574 loss)
I0527 08:23:50.597084  2100 sgd_solver.cpp:106] Iteration 265500, lr = 0.0005
I0527 08:24:00.445880  2100 solver.cpp:237] Iteration 265875, loss = 1.04276
I0527 08:24:00.445924  2100 solver.cpp:253]     Train net output #0: loss = 1.04276 (* 1 = 1.04276 loss)
I0527 08:24:00.445937  2100 sgd_solver.cpp:106] Iteration 265875, lr = 0.0005
I0527 08:24:10.278442  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_266250.caffemodel
I0527 08:24:10.335139  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_266250.solverstate
I0527 08:24:31.280087  2100 solver.cpp:237] Iteration 266250, loss = 1.05156
I0527 08:24:31.280282  2100 solver.cpp:253]     Train net output #0: loss = 1.05156 (* 1 = 1.05156 loss)
I0527 08:24:31.280298  2100 sgd_solver.cpp:106] Iteration 266250, lr = 0.0005
I0527 08:24:41.134119  2100 solver.cpp:237] Iteration 266625, loss = 1.23643
I0527 08:24:41.134148  2100 solver.cpp:253]     Train net output #0: loss = 1.23643 (* 1 = 1.23643 loss)
I0527 08:24:41.134171  2100 sgd_solver.cpp:106] Iteration 266625, lr = 0.0005
I0527 08:24:50.987676  2100 solver.cpp:237] Iteration 267000, loss = 0.961486
I0527 08:24:50.987725  2100 solver.cpp:253]     Train net output #0: loss = 0.961486 (* 1 = 0.961486 loss)
I0527 08:24:50.987742  2100 sgd_solver.cpp:106] Iteration 267000, lr = 0.0005
I0527 08:25:00.844303  2100 solver.cpp:237] Iteration 267375, loss = 1.17232
I0527 08:25:00.844339  2100 solver.cpp:253]     Train net output #0: loss = 1.17232 (* 1 = 1.17232 loss)
I0527 08:25:00.844352  2100 sgd_solver.cpp:106] Iteration 267375, lr = 0.0005
I0527 08:25:10.703049  2100 solver.cpp:237] Iteration 267750, loss = 0.950167
I0527 08:25:10.703213  2100 solver.cpp:253]     Train net output #0: loss = 0.950167 (* 1 = 0.950167 loss)
I0527 08:25:10.703229  2100 sgd_solver.cpp:106] Iteration 267750, lr = 0.0005
I0527 08:25:20.567852  2100 solver.cpp:237] Iteration 268125, loss = 1.1987
I0527 08:25:20.567899  2100 solver.cpp:253]     Train net output #0: loss = 1.1987 (* 1 = 1.1987 loss)
I0527 08:25:20.567914  2100 sgd_solver.cpp:106] Iteration 268125, lr = 0.0005
I0527 08:25:30.423424  2100 solver.cpp:237] Iteration 268500, loss = 1.07163
I0527 08:25:30.423460  2100 solver.cpp:253]     Train net output #0: loss = 1.07163 (* 1 = 1.07163 loss)
I0527 08:25:30.423473  2100 sgd_solver.cpp:106] Iteration 268500, lr = 0.0005
I0527 08:26:01.162195  2100 solver.cpp:237] Iteration 268875, loss = 1.31895
I0527 08:26:01.162381  2100 solver.cpp:253]     Train net output #0: loss = 1.31895 (* 1 = 1.31895 loss)
I0527 08:26:01.162397  2100 sgd_solver.cpp:106] Iteration 268875, lr = 0.0005
I0527 08:26:11.024070  2100 solver.cpp:237] Iteration 269250, loss = 1.05393
I0527 08:26:11.024106  2100 solver.cpp:253]     Train net output #0: loss = 1.05393 (* 1 = 1.05393 loss)
I0527 08:26:11.024130  2100 sgd_solver.cpp:106] Iteration 269250, lr = 0.0005
I0527 08:26:20.867988  2100 solver.cpp:237] Iteration 269625, loss = 1.12806
I0527 08:26:20.868024  2100 solver.cpp:253]     Train net output #0: loss = 1.12806 (* 1 = 1.12806 loss)
I0527 08:26:20.868037  2100 sgd_solver.cpp:106] Iteration 269625, lr = 0.0005
I0527 08:26:30.698660  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_270000.caffemodel
I0527 08:26:30.755009  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_270000.solverstate
I0527 08:26:30.780189  2100 solver.cpp:341] Iteration 270000, Testing net (#0)
I0527 08:27:19.391589  2100 solver.cpp:409]     Test net output #0: accuracy = 0.891347
I0527 08:27:19.391777  2100 solver.cpp:409]     Test net output #1: loss = 0.348924 (* 1 = 0.348924 loss)
I0527 08:27:19.399853  2100 solver.cpp:237] Iteration 270000, loss = 1.13574
I0527 08:27:19.399881  2100 solver.cpp:253]     Train net output #0: loss = 1.13574 (* 1 = 1.13574 loss)
I0527 08:27:19.399895  2100 sgd_solver.cpp:106] Iteration 270000, lr = 0.0005
I0527 08:27:29.140678  2100 solver.cpp:237] Iteration 270375, loss = 1.06655
I0527 08:27:29.140712  2100 solver.cpp:253]     Train net output #0: loss = 1.06655 (* 1 = 1.06655 loss)
I0527 08:27:29.140729  2100 sgd_solver.cpp:106] Iteration 270375, lr = 0.0005
I0527 08:27:38.872025  2100 solver.cpp:237] Iteration 270750, loss = 1.20425
I0527 08:27:38.872061  2100 solver.cpp:253]     Train net output #0: loss = 1.20425 (* 1 = 1.20425 loss)
I0527 08:27:38.872074  2100 sgd_solver.cpp:106] Iteration 270750, lr = 0.0005
I0527 08:27:48.609674  2100 solver.cpp:237] Iteration 271125, loss = 1.05262
I0527 08:27:48.609719  2100 solver.cpp:253]     Train net output #0: loss = 1.05262 (* 1 = 1.05262 loss)
I0527 08:27:48.609735  2100 sgd_solver.cpp:106] Iteration 271125, lr = 0.0005
I0527 08:28:19.249040  2100 solver.cpp:237] Iteration 271500, loss = 1.21373
I0527 08:28:19.249224  2100 solver.cpp:253]     Train net output #0: loss = 1.21373 (* 1 = 1.21373 loss)
I0527 08:28:19.249239  2100 sgd_solver.cpp:106] Iteration 271500, lr = 0.0005
I0527 08:28:28.986506  2100 solver.cpp:237] Iteration 271875, loss = 1.02822
I0527 08:28:28.986541  2100 solver.cpp:253]     Train net output #0: loss = 1.02822 (* 1 = 1.02822 loss)
I0527 08:28:28.986559  2100 sgd_solver.cpp:106] Iteration 271875, lr = 0.0005
I0527 08:28:38.722565  2100 solver.cpp:237] Iteration 272250, loss = 1.18685
I0527 08:28:38.722614  2100 solver.cpp:253]     Train net output #0: loss = 1.18685 (* 1 = 1.18685 loss)
I0527 08:28:38.722627  2100 sgd_solver.cpp:106] Iteration 272250, lr = 0.0005
I0527 08:28:48.463822  2100 solver.cpp:237] Iteration 272625, loss = 1.05355
I0527 08:28:48.463858  2100 solver.cpp:253]     Train net output #0: loss = 1.05355 (* 1 = 1.05355 loss)
I0527 08:28:48.463872  2100 sgd_solver.cpp:106] Iteration 272625, lr = 0.0005
I0527 08:28:58.204747  2100 solver.cpp:237] Iteration 273000, loss = 1.06307
I0527 08:28:58.204910  2100 solver.cpp:253]     Train net output #0: loss = 1.06307 (* 1 = 1.06307 loss)
I0527 08:28:58.204924  2100 sgd_solver.cpp:106] Iteration 273000, lr = 0.0005
I0527 08:29:07.934779  2100 solver.cpp:237] Iteration 273375, loss = 1.18156
I0527 08:29:07.934818  2100 solver.cpp:253]     Train net output #0: loss = 1.18156 (* 1 = 1.18156 loss)
I0527 08:29:07.934835  2100 sgd_solver.cpp:106] Iteration 273375, lr = 0.0005
I0527 08:29:17.646210  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_273750.caffemodel
I0527 08:29:17.705087  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_273750.solverstate
I0527 08:29:38.628401  2100 solver.cpp:237] Iteration 273750, loss = 1.23951
I0527 08:29:38.628594  2100 solver.cpp:253]     Train net output #0: loss = 1.23951 (* 1 = 1.23951 loss)
I0527 08:29:38.628612  2100 sgd_solver.cpp:106] Iteration 273750, lr = 0.0005
I0527 08:29:48.365257  2100 solver.cpp:237] Iteration 274125, loss = 0.994792
I0527 08:29:48.365293  2100 solver.cpp:253]     Train net output #0: loss = 0.994792 (* 1 = 0.994792 loss)
I0527 08:29:48.365308  2100 sgd_solver.cpp:106] Iteration 274125, lr = 0.0005
I0527 08:29:58.107782  2100 solver.cpp:237] Iteration 274500, loss = 1.0631
I0527 08:29:58.107820  2100 solver.cpp:253]     Train net output #0: loss = 1.0631 (* 1 = 1.0631 loss)
I0527 08:29:58.107841  2100 sgd_solver.cpp:106] Iteration 274500, lr = 0.0005
I0527 08:30:07.848096  2100 solver.cpp:237] Iteration 274875, loss = 1.08153
I0527 08:30:07.848131  2100 solver.cpp:253]     Train net output #0: loss = 1.08153 (* 1 = 1.08153 loss)
I0527 08:30:07.848145  2100 sgd_solver.cpp:106] Iteration 274875, lr = 0.0005
I0527 08:30:17.580976  2100 solver.cpp:237] Iteration 275250, loss = 0.982785
I0527 08:30:17.581164  2100 solver.cpp:253]     Train net output #0: loss = 0.982785 (* 1 = 0.982785 loss)
I0527 08:30:17.581178  2100 sgd_solver.cpp:106] Iteration 275250, lr = 0.0005
I0527 08:30:27.315011  2100 solver.cpp:237] Iteration 275625, loss = 1.11312
I0527 08:30:27.315045  2100 solver.cpp:253]     Train net output #0: loss = 1.11312 (* 1 = 1.11312 loss)
I0527 08:30:27.315062  2100 sgd_solver.cpp:106] Iteration 275625, lr = 0.0005
I0527 08:30:37.054409  2100 solver.cpp:237] Iteration 276000, loss = 1.19593
I0527 08:30:37.054445  2100 solver.cpp:253]     Train net output #0: loss = 1.19593 (* 1 = 1.19593 loss)
I0527 08:30:37.054458  2100 sgd_solver.cpp:106] Iteration 276000, lr = 0.0005
I0527 08:31:07.672492  2100 solver.cpp:237] Iteration 276375, loss = 0.972099
I0527 08:31:07.672675  2100 solver.cpp:253]     Train net output #0: loss = 0.972099 (* 1 = 0.972099 loss)
I0527 08:31:07.672691  2100 sgd_solver.cpp:106] Iteration 276375, lr = 0.0005
I0527 08:31:17.409126  2100 solver.cpp:237] Iteration 276750, loss = 1.33049
I0527 08:31:17.409160  2100 solver.cpp:253]     Train net output #0: loss = 1.33049 (* 1 = 1.33049 loss)
I0527 08:31:17.409175  2100 sgd_solver.cpp:106] Iteration 276750, lr = 0.0005
I0527 08:31:27.145933  2100 solver.cpp:237] Iteration 277125, loss = 1.34801
I0527 08:31:27.145968  2100 solver.cpp:253]     Train net output #0: loss = 1.34801 (* 1 = 1.34801 loss)
I0527 08:31:27.145984  2100 sgd_solver.cpp:106] Iteration 277125, lr = 0.0005
I0527 08:31:36.862149  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_277500.caffemodel
I0527 08:31:36.919709  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_277500.solverstate
I0527 08:31:36.946218  2100 solver.cpp:341] Iteration 277500, Testing net (#0)
I0527 08:32:46.435467  2100 solver.cpp:409]     Test net output #0: accuracy = 0.891546
I0527 08:32:46.435659  2100 solver.cpp:409]     Test net output #1: loss = 0.357942 (* 1 = 0.357942 loss)
I0527 08:32:46.443763  2100 solver.cpp:237] Iteration 277500, loss = 1.1317
I0527 08:32:46.443789  2100 solver.cpp:253]     Train net output #0: loss = 1.1317 (* 1 = 1.1317 loss)
I0527 08:32:46.443804  2100 sgd_solver.cpp:106] Iteration 277500, lr = 0.0005
I0527 08:32:56.180874  2100 solver.cpp:237] Iteration 277875, loss = 1.03746
I0527 08:32:56.180909  2100 solver.cpp:253]     Train net output #0: loss = 1.03746 (* 1 = 1.03746 loss)
I0527 08:32:56.180923  2100 sgd_solver.cpp:106] Iteration 277875, lr = 0.0005
I0527 08:33:05.917309  2100 solver.cpp:237] Iteration 278250, loss = 1.57892
I0527 08:33:05.917345  2100 solver.cpp:253]     Train net output #0: loss = 1.57892 (* 1 = 1.57892 loss)
I0527 08:33:05.917358  2100 sgd_solver.cpp:106] Iteration 278250, lr = 0.0005
I0527 08:33:15.659186  2100 solver.cpp:237] Iteration 278625, loss = 1.38199
I0527 08:33:15.659229  2100 solver.cpp:253]     Train net output #0: loss = 1.38199 (* 1 = 1.38199 loss)
I0527 08:33:15.659250  2100 sgd_solver.cpp:106] Iteration 278625, lr = 0.0005
I0527 08:33:46.311022  2100 solver.cpp:237] Iteration 279000, loss = 1.06584
I0527 08:33:46.311208  2100 solver.cpp:253]     Train net output #0: loss = 1.06584 (* 1 = 1.06584 loss)
I0527 08:33:46.311224  2100 sgd_solver.cpp:106] Iteration 279000, lr = 0.0005
I0527 08:33:56.048882  2100 solver.cpp:237] Iteration 279375, loss = 1.30783
I0527 08:33:56.048916  2100 solver.cpp:253]     Train net output #0: loss = 1.30783 (* 1 = 1.30783 loss)
I0527 08:33:56.048931  2100 sgd_solver.cpp:106] Iteration 279375, lr = 0.0005
I0527 08:34:05.783133  2100 solver.cpp:237] Iteration 279750, loss = 1.16384
I0527 08:34:05.783179  2100 solver.cpp:253]     Train net output #0: loss = 1.16384 (* 1 = 1.16384 loss)
I0527 08:34:05.783193  2100 sgd_solver.cpp:106] Iteration 279750, lr = 0.0005
I0527 08:34:15.524930  2100 solver.cpp:237] Iteration 280125, loss = 1.21801
I0527 08:34:15.524966  2100 solver.cpp:253]     Train net output #0: loss = 1.21801 (* 1 = 1.21801 loss)
I0527 08:34:15.524979  2100 sgd_solver.cpp:106] Iteration 280125, lr = 0.0005
I0527 08:34:25.256291  2100 solver.cpp:237] Iteration 280500, loss = 1.27791
I0527 08:34:25.256484  2100 solver.cpp:253]     Train net output #0: loss = 1.27791 (* 1 = 1.27791 loss)
I0527 08:34:25.256497  2100 sgd_solver.cpp:106] Iteration 280500, lr = 0.0005
I0527 08:34:34.989992  2100 solver.cpp:237] Iteration 280875, loss = 1.36275
I0527 08:34:34.990027  2100 solver.cpp:253]     Train net output #0: loss = 1.36275 (* 1 = 1.36275 loss)
I0527 08:34:34.990042  2100 sgd_solver.cpp:106] Iteration 280875, lr = 0.0005
I0527 08:34:44.692421  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_281250.caffemodel
I0527 08:34:44.751219  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_281250.solverstate
I0527 08:35:05.695077  2100 solver.cpp:237] Iteration 281250, loss = 1.03134
I0527 08:35:05.695276  2100 solver.cpp:253]     Train net output #0: loss = 1.03134 (* 1 = 1.03134 loss)
I0527 08:35:05.695291  2100 sgd_solver.cpp:106] Iteration 281250, lr = 0.0005
I0527 08:35:15.424326  2100 solver.cpp:237] Iteration 281625, loss = 0.864998
I0527 08:35:15.424376  2100 solver.cpp:253]     Train net output #0: loss = 0.864998 (* 1 = 0.864998 loss)
I0527 08:35:15.424389  2100 sgd_solver.cpp:106] Iteration 281625, lr = 0.0005
I0527 08:35:25.160199  2100 solver.cpp:237] Iteration 282000, loss = 1.14251
I0527 08:35:25.160235  2100 solver.cpp:253]     Train net output #0: loss = 1.14251 (* 1 = 1.14251 loss)
I0527 08:35:25.160248  2100 sgd_solver.cpp:106] Iteration 282000, lr = 0.0005
I0527 08:35:34.892725  2100 solver.cpp:237] Iteration 282375, loss = 1.12761
I0527 08:35:34.892760  2100 solver.cpp:253]     Train net output #0: loss = 1.12761 (* 1 = 1.12761 loss)
I0527 08:35:34.892774  2100 sgd_solver.cpp:106] Iteration 282375, lr = 0.0005
I0527 08:35:44.620532  2100 solver.cpp:237] Iteration 282750, loss = 1.12674
I0527 08:35:44.620708  2100 solver.cpp:253]     Train net output #0: loss = 1.12674 (* 1 = 1.12674 loss)
I0527 08:35:44.620723  2100 sgd_solver.cpp:106] Iteration 282750, lr = 0.0005
I0527 08:35:54.357758  2100 solver.cpp:237] Iteration 283125, loss = 1.1644
I0527 08:35:54.357791  2100 solver.cpp:253]     Train net output #0: loss = 1.1644 (* 1 = 1.1644 loss)
I0527 08:35:54.357808  2100 sgd_solver.cpp:106] Iteration 283125, lr = 0.0005
I0527 08:36:04.091056  2100 solver.cpp:237] Iteration 283500, loss = 1.37463
I0527 08:36:04.091091  2100 solver.cpp:253]     Train net output #0: loss = 1.37463 (* 1 = 1.37463 loss)
I0527 08:36:04.091106  2100 sgd_solver.cpp:106] Iteration 283500, lr = 0.0005
I0527 08:36:34.714390  2100 solver.cpp:237] Iteration 283875, loss = 1.29578
I0527 08:36:34.714577  2100 solver.cpp:253]     Train net output #0: loss = 1.29578 (* 1 = 1.29578 loss)
I0527 08:36:34.714593  2100 sgd_solver.cpp:106] Iteration 283875, lr = 0.0005
I0527 08:36:44.445488  2100 solver.cpp:237] Iteration 284250, loss = 1.09838
I0527 08:36:44.445523  2100 solver.cpp:253]     Train net output #0: loss = 1.09838 (* 1 = 1.09838 loss)
I0527 08:36:44.445538  2100 sgd_solver.cpp:106] Iteration 284250, lr = 0.0005
I0527 08:36:54.182809  2100 solver.cpp:237] Iteration 284625, loss = 1.35619
I0527 08:36:54.182845  2100 solver.cpp:253]     Train net output #0: loss = 1.35619 (* 1 = 1.35619 loss)
I0527 08:36:54.182858  2100 sgd_solver.cpp:106] Iteration 284625, lr = 0.0005
I0527 08:37:03.888871  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_285000.caffemodel
I0527 08:37:03.945843  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_285000.solverstate
I0527 08:37:03.971675  2100 solver.cpp:341] Iteration 285000, Testing net (#0)
I0527 08:37:52.249310  2100 solver.cpp:409]     Test net output #0: accuracy = 0.890073
I0527 08:37:52.249505  2100 solver.cpp:409]     Test net output #1: loss = 0.333635 (* 1 = 0.333635 loss)
I0527 08:37:52.257591  2100 solver.cpp:237] Iteration 285000, loss = 1.19262
I0527 08:37:52.257618  2100 solver.cpp:253]     Train net output #0: loss = 1.19262 (* 1 = 1.19262 loss)
I0527 08:37:52.257633  2100 sgd_solver.cpp:106] Iteration 285000, lr = 0.0005
I0527 08:38:01.976655  2100 solver.cpp:237] Iteration 285375, loss = 1.13993
I0527 08:38:01.976689  2100 solver.cpp:253]     Train net output #0: loss = 1.13993 (* 1 = 1.13993 loss)
I0527 08:38:01.976707  2100 sgd_solver.cpp:106] Iteration 285375, lr = 0.0005
I0527 08:38:11.704126  2100 solver.cpp:237] Iteration 285750, loss = 1.02323
I0527 08:38:11.704167  2100 solver.cpp:253]     Train net output #0: loss = 1.02323 (* 1 = 1.02323 loss)
I0527 08:38:11.704185  2100 sgd_solver.cpp:106] Iteration 285750, lr = 0.0005
I0527 08:38:21.431203  2100 solver.cpp:237] Iteration 286125, loss = 1.13252
I0527 08:38:21.431239  2100 solver.cpp:253]     Train net output #0: loss = 1.13252 (* 1 = 1.13252 loss)
I0527 08:38:21.431255  2100 sgd_solver.cpp:106] Iteration 286125, lr = 0.0005
I0527 08:38:52.019157  2100 solver.cpp:237] Iteration 286500, loss = 0.97921
I0527 08:38:52.019348  2100 solver.cpp:253]     Train net output #0: loss = 0.979209 (* 1 = 0.979209 loss)
I0527 08:38:52.019363  2100 sgd_solver.cpp:106] Iteration 286500, lr = 0.0005
I0527 08:39:01.749053  2100 solver.cpp:237] Iteration 286875, loss = 0.982328
I0527 08:39:01.749095  2100 solver.cpp:253]     Train net output #0: loss = 0.982327 (* 1 = 0.982327 loss)
I0527 08:39:01.749114  2100 sgd_solver.cpp:106] Iteration 286875, lr = 0.0005
I0527 08:39:11.483691  2100 solver.cpp:237] Iteration 287250, loss = 1.08753
I0527 08:39:11.483726  2100 solver.cpp:253]     Train net output #0: loss = 1.08753 (* 1 = 1.08753 loss)
I0527 08:39:11.483742  2100 sgd_solver.cpp:106] Iteration 287250, lr = 0.0005
I0527 08:39:21.221649  2100 solver.cpp:237] Iteration 287625, loss = 0.907592
I0527 08:39:21.221685  2100 solver.cpp:253]     Train net output #0: loss = 0.907591 (* 1 = 0.907591 loss)
I0527 08:39:21.221701  2100 sgd_solver.cpp:106] Iteration 287625, lr = 0.0005
I0527 08:39:30.950062  2100 solver.cpp:237] Iteration 288000, loss = 1.22943
I0527 08:39:30.950240  2100 solver.cpp:253]     Train net output #0: loss = 1.22943 (* 1 = 1.22943 loss)
I0527 08:39:30.950254  2100 sgd_solver.cpp:106] Iteration 288000, lr = 0.0005
I0527 08:39:40.684954  2100 solver.cpp:237] Iteration 288375, loss = 1.08501
I0527 08:39:40.684989  2100 solver.cpp:253]     Train net output #0: loss = 1.08501 (* 1 = 1.08501 loss)
I0527 08:39:40.685003  2100 sgd_solver.cpp:106] Iteration 288375, lr = 0.0005
I0527 08:39:50.389001  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_288750.caffemodel
I0527 08:39:50.453017  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_288750.solverstate
I0527 08:40:11.365419  2100 solver.cpp:237] Iteration 288750, loss = 1.09786
I0527 08:40:11.365612  2100 solver.cpp:253]     Train net output #0: loss = 1.09786 (* 1 = 1.09786 loss)
I0527 08:40:11.365628  2100 sgd_solver.cpp:106] Iteration 288750, lr = 0.0005
I0527 08:40:21.082914  2100 solver.cpp:237] Iteration 289125, loss = 0.934393
I0527 08:40:21.082954  2100 solver.cpp:253]     Train net output #0: loss = 0.934393 (* 1 = 0.934393 loss)
I0527 08:40:21.082972  2100 sgd_solver.cpp:106] Iteration 289125, lr = 0.0005
I0527 08:40:30.811686  2100 solver.cpp:237] Iteration 289500, loss = 0.929051
I0527 08:40:30.811722  2100 solver.cpp:253]     Train net output #0: loss = 0.92905 (* 1 = 0.92905 loss)
I0527 08:40:30.811735  2100 sgd_solver.cpp:106] Iteration 289500, lr = 0.0005
I0527 08:40:40.538053  2100 solver.cpp:237] Iteration 289875, loss = 1.33856
I0527 08:40:40.538099  2100 solver.cpp:253]     Train net output #0: loss = 1.33856 (* 1 = 1.33856 loss)
I0527 08:40:40.538112  2100 sgd_solver.cpp:106] Iteration 289875, lr = 0.0005
I0527 08:40:50.254567  2100 solver.cpp:237] Iteration 290250, loss = 1.21977
I0527 08:40:50.254746  2100 solver.cpp:253]     Train net output #0: loss = 1.21977 (* 1 = 1.21977 loss)
I0527 08:40:50.254760  2100 sgd_solver.cpp:106] Iteration 290250, lr = 0.0005
I0527 08:40:59.968284  2100 solver.cpp:237] Iteration 290625, loss = 1.60159
I0527 08:40:59.968319  2100 solver.cpp:253]     Train net output #0: loss = 1.60159 (* 1 = 1.60159 loss)
I0527 08:40:59.968336  2100 sgd_solver.cpp:106] Iteration 290625, lr = 0.0005
I0527 08:41:09.680615  2100 solver.cpp:237] Iteration 291000, loss = 1.09312
I0527 08:41:09.680662  2100 solver.cpp:253]     Train net output #0: loss = 1.09312 (* 1 = 1.09312 loss)
I0527 08:41:09.680676  2100 sgd_solver.cpp:106] Iteration 291000, lr = 0.0005
I0527 08:41:40.316963  2100 solver.cpp:237] Iteration 291375, loss = 1.22107
I0527 08:41:40.317153  2100 solver.cpp:253]     Train net output #0: loss = 1.22107 (* 1 = 1.22107 loss)
I0527 08:41:40.317169  2100 sgd_solver.cpp:106] Iteration 291375, lr = 0.0005
I0527 08:41:50.033069  2100 solver.cpp:237] Iteration 291750, loss = 0.725455
I0527 08:41:50.033105  2100 solver.cpp:253]     Train net output #0: loss = 0.725455 (* 1 = 0.725455 loss)
I0527 08:41:50.033118  2100 sgd_solver.cpp:106] Iteration 291750, lr = 0.0005
I0527 08:41:59.757025  2100 solver.cpp:237] Iteration 292125, loss = 1.15157
I0527 08:41:59.757071  2100 solver.cpp:253]     Train net output #0: loss = 1.15157 (* 1 = 1.15157 loss)
I0527 08:41:59.757086  2100 sgd_solver.cpp:106] Iteration 292125, lr = 0.0005
I0527 08:42:09.451750  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_292500.caffemodel
I0527 08:42:09.508111  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_292500.solverstate
I0527 08:42:09.533797  2100 solver.cpp:341] Iteration 292500, Testing net (#0)
I0527 08:43:18.930238  2100 solver.cpp:409]     Test net output #0: accuracy = 0.889514
I0527 08:43:18.930433  2100 solver.cpp:409]     Test net output #1: loss = 0.355431 (* 1 = 0.355431 loss)
I0527 08:43:18.938447  2100 solver.cpp:237] Iteration 292500, loss = 1.08974
I0527 08:43:18.938475  2100 solver.cpp:253]     Train net output #0: loss = 1.08974 (* 1 = 1.08974 loss)
I0527 08:43:18.938490  2100 sgd_solver.cpp:106] Iteration 292500, lr = 0.0005
I0527 08:43:28.788518  2100 solver.cpp:237] Iteration 292875, loss = 1.03729
I0527 08:43:28.788552  2100 solver.cpp:253]     Train net output #0: loss = 1.03729 (* 1 = 1.03729 loss)
I0527 08:43:28.788570  2100 sgd_solver.cpp:106] Iteration 292875, lr = 0.0005
I0527 08:43:38.638650  2100 solver.cpp:237] Iteration 293250, loss = 1.02792
I0527 08:43:38.638695  2100 solver.cpp:253]     Train net output #0: loss = 1.02792 (* 1 = 1.02792 loss)
I0527 08:43:38.638710  2100 sgd_solver.cpp:106] Iteration 293250, lr = 0.0005
I0527 08:43:48.494773  2100 solver.cpp:237] Iteration 293625, loss = 0.906995
I0527 08:43:48.494810  2100 solver.cpp:253]     Train net output #0: loss = 0.906995 (* 1 = 0.906995 loss)
I0527 08:43:48.494827  2100 sgd_solver.cpp:106] Iteration 293625, lr = 0.0005
I0527 08:44:19.212417  2100 solver.cpp:237] Iteration 294000, loss = 1.05883
I0527 08:44:19.212604  2100 solver.cpp:253]     Train net output #0: loss = 1.05883 (* 1 = 1.05883 loss)
I0527 08:44:19.212618  2100 sgd_solver.cpp:106] Iteration 294000, lr = 0.0005
I0527 08:44:29.062633  2100 solver.cpp:237] Iteration 294375, loss = 1.31346
I0527 08:44:29.062679  2100 solver.cpp:253]     Train net output #0: loss = 1.31346 (* 1 = 1.31346 loss)
I0527 08:44:29.062693  2100 sgd_solver.cpp:106] Iteration 294375, lr = 0.0005
I0527 08:44:38.917922  2100 solver.cpp:237] Iteration 294750, loss = 1.10316
I0527 08:44:38.917958  2100 solver.cpp:253]     Train net output #0: loss = 1.10316 (* 1 = 1.10316 loss)
I0527 08:44:38.917973  2100 sgd_solver.cpp:106] Iteration 294750, lr = 0.0005
I0527 08:44:48.771973  2100 solver.cpp:237] Iteration 295125, loss = 1.0996
I0527 08:44:48.772009  2100 solver.cpp:253]     Train net output #0: loss = 1.0996 (* 1 = 1.0996 loss)
I0527 08:44:48.772024  2100 sgd_solver.cpp:106] Iteration 295125, lr = 0.0005
I0527 08:44:58.628499  2100 solver.cpp:237] Iteration 295500, loss = 1.40959
I0527 08:44:58.628684  2100 solver.cpp:253]     Train net output #0: loss = 1.40959 (* 1 = 1.40959 loss)
I0527 08:44:58.628700  2100 sgd_solver.cpp:106] Iteration 295500, lr = 0.0005
I0527 08:45:08.488235  2100 solver.cpp:237] Iteration 295875, loss = 1.06176
I0527 08:45:08.488270  2100 solver.cpp:253]     Train net output #0: loss = 1.06176 (* 1 = 1.06176 loss)
I0527 08:45:08.488288  2100 sgd_solver.cpp:106] Iteration 295875, lr = 0.0005
I0527 08:45:18.310492  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_296250.caffemodel
I0527 08:45:18.367419  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_296250.solverstate
I0527 08:45:39.312085  2100 solver.cpp:237] Iteration 296250, loss = 1.35208
I0527 08:45:39.312284  2100 solver.cpp:253]     Train net output #0: loss = 1.35208 (* 1 = 1.35208 loss)
I0527 08:45:39.312301  2100 sgd_solver.cpp:106] Iteration 296250, lr = 0.0005
I0527 08:45:49.169586  2100 solver.cpp:237] Iteration 296625, loss = 0.92893
I0527 08:45:49.169622  2100 solver.cpp:253]     Train net output #0: loss = 0.92893 (* 1 = 0.92893 loss)
I0527 08:45:49.169642  2100 sgd_solver.cpp:106] Iteration 296625, lr = 0.0005
I0527 08:45:59.018803  2100 solver.cpp:237] Iteration 297000, loss = 1.30695
I0527 08:45:59.018839  2100 solver.cpp:253]     Train net output #0: loss = 1.30695 (* 1 = 1.30695 loss)
I0527 08:45:59.018856  2100 sgd_solver.cpp:106] Iteration 297000, lr = 0.0005
I0527 08:46:08.867471  2100 solver.cpp:237] Iteration 297375, loss = 1.30368
I0527 08:46:08.867519  2100 solver.cpp:253]     Train net output #0: loss = 1.30368 (* 1 = 1.30368 loss)
I0527 08:46:08.867533  2100 sgd_solver.cpp:106] Iteration 297375, lr = 0.0005
I0527 08:46:18.715351  2100 solver.cpp:237] Iteration 297750, loss = 1.11179
I0527 08:46:18.715523  2100 solver.cpp:253]     Train net output #0: loss = 1.11179 (* 1 = 1.11179 loss)
I0527 08:46:18.715538  2100 sgd_solver.cpp:106] Iteration 297750, lr = 0.0005
I0527 08:46:28.566059  2100 solver.cpp:237] Iteration 298125, loss = 1.04373
I0527 08:46:28.566094  2100 solver.cpp:253]     Train net output #0: loss = 1.04373 (* 1 = 1.04373 loss)
I0527 08:46:28.566110  2100 sgd_solver.cpp:106] Iteration 298125, lr = 0.0005
I0527 08:46:38.419313  2100 solver.cpp:237] Iteration 298500, loss = 0.826024
I0527 08:46:38.419356  2100 solver.cpp:253]     Train net output #0: loss = 0.826024 (* 1 = 0.826024 loss)
I0527 08:46:38.419373  2100 sgd_solver.cpp:106] Iteration 298500, lr = 0.0005
I0527 08:47:09.119561  2100 solver.cpp:237] Iteration 298875, loss = 1.34679
I0527 08:47:09.119750  2100 solver.cpp:253]     Train net output #0: loss = 1.34679 (* 1 = 1.34679 loss)
I0527 08:47:09.119767  2100 sgd_solver.cpp:106] Iteration 298875, lr = 0.0005
I0527 08:47:18.966449  2100 solver.cpp:237] Iteration 299250, loss = 1.11332
I0527 08:47:18.966483  2100 solver.cpp:253]     Train net output #0: loss = 1.11332 (* 1 = 1.11332 loss)
I0527 08:47:18.966498  2100 sgd_solver.cpp:106] Iteration 299250, lr = 0.0005
I0527 08:47:28.821147  2100 solver.cpp:237] Iteration 299625, loss = 1.17539
I0527 08:47:28.821190  2100 solver.cpp:253]     Train net output #0: loss = 1.17539 (* 1 = 1.17539 loss)
I0527 08:47:28.821208  2100 sgd_solver.cpp:106] Iteration 299625, lr = 0.0005
I0527 08:47:38.642632  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_300000.caffemodel
I0527 08:47:38.704031  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_300000.solverstate
I0527 08:47:38.732496  2100 solver.cpp:341] Iteration 300000, Testing net (#0)
I0527 08:48:27.323956  2100 solver.cpp:409]     Test net output #0: accuracy = 0.89262
I0527 08:48:27.324152  2100 solver.cpp:409]     Test net output #1: loss = 0.340366 (* 1 = 0.340366 loss)
I0527 08:48:27.332162  2100 solver.cpp:237] Iteration 300000, loss = 1.36657
I0527 08:48:27.332190  2100 solver.cpp:253]     Train net output #0: loss = 1.36657 (* 1 = 1.36657 loss)
I0527 08:48:27.332204  2100 sgd_solver.cpp:106] Iteration 300000, lr = 0.0005
I0527 08:48:37.071732  2100 solver.cpp:237] Iteration 300375, loss = 1.17907
I0527 08:48:37.071774  2100 solver.cpp:253]     Train net output #0: loss = 1.17907 (* 1 = 1.17907 loss)
I0527 08:48:37.071791  2100 sgd_solver.cpp:106] Iteration 300375, lr = 0.0005
I0527 08:48:46.808825  2100 solver.cpp:237] Iteration 300750, loss = 1.31804
I0527 08:48:46.808859  2100 solver.cpp:253]     Train net output #0: loss = 1.31804 (* 1 = 1.31804 loss)
I0527 08:48:46.808873  2100 sgd_solver.cpp:106] Iteration 300750, lr = 0.0005
I0527 08:48:56.550714  2100 solver.cpp:237] Iteration 301125, loss = 1.02068
I0527 08:48:56.550748  2100 solver.cpp:253]     Train net output #0: loss = 1.02068 (* 1 = 1.02068 loss)
I0527 08:48:56.550761  2100 sgd_solver.cpp:106] Iteration 301125, lr = 0.0005
I0527 08:49:27.198582  2100 solver.cpp:237] Iteration 301500, loss = 1.06404
I0527 08:49:27.198772  2100 solver.cpp:253]     Train net output #0: loss = 1.06404 (* 1 = 1.06404 loss)
I0527 08:49:27.198788  2100 sgd_solver.cpp:106] Iteration 301500, lr = 0.0005
I0527 08:49:36.948577  2100 solver.cpp:237] Iteration 301875, loss = 1.03077
I0527 08:49:36.948612  2100 solver.cpp:253]     Train net output #0: loss = 1.03077 (* 1 = 1.03077 loss)
I0527 08:49:36.948627  2100 sgd_solver.cpp:106] Iteration 301875, lr = 0.0005
I0527 08:49:46.684741  2100 solver.cpp:237] Iteration 302250, loss = 1.16237
I0527 08:49:46.684777  2100 solver.cpp:253]     Train net output #0: loss = 1.16237 (* 1 = 1.16237 loss)
I0527 08:49:46.684793  2100 sgd_solver.cpp:106] Iteration 302250, lr = 0.0005
I0527 08:49:56.431272  2100 solver.cpp:237] Iteration 302625, loss = 1.27511
I0527 08:49:56.431318  2100 solver.cpp:253]     Train net output #0: loss = 1.27511 (* 1 = 1.27511 loss)
I0527 08:49:56.431331  2100 sgd_solver.cpp:106] Iteration 302625, lr = 0.0005
I0527 08:50:06.180564  2100 solver.cpp:237] Iteration 303000, loss = 1.04502
I0527 08:50:06.180732  2100 solver.cpp:253]     Train net output #0: loss = 1.04502 (* 1 = 1.04502 loss)
I0527 08:50:06.180747  2100 sgd_solver.cpp:106] Iteration 303000, lr = 0.0005
I0527 08:50:15.927460  2100 solver.cpp:237] Iteration 303375, loss = 0.763411
I0527 08:50:15.927511  2100 solver.cpp:253]     Train net output #0: loss = 0.763411 (* 1 = 0.763411 loss)
I0527 08:50:15.927525  2100 sgd_solver.cpp:106] Iteration 303375, lr = 0.0005
I0527 08:50:25.652140  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_303750.caffemodel
I0527 08:50:25.714680  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_303750.solverstate
I0527 08:50:46.655856  2100 solver.cpp:237] Iteration 303750, loss = 1.03717
I0527 08:50:46.656064  2100 solver.cpp:253]     Train net output #0: loss = 1.03717 (* 1 = 1.03717 loss)
I0527 08:50:46.656081  2100 sgd_solver.cpp:106] Iteration 303750, lr = 0.0005
I0527 08:50:56.401628  2100 solver.cpp:237] Iteration 304125, loss = 0.770995
I0527 08:50:56.401661  2100 solver.cpp:253]     Train net output #0: loss = 0.770994 (* 1 = 0.770994 loss)
I0527 08:50:56.401677  2100 sgd_solver.cpp:106] Iteration 304125, lr = 0.0005
I0527 08:51:06.146558  2100 solver.cpp:237] Iteration 304500, loss = 1.39449
I0527 08:51:06.146600  2100 solver.cpp:253]     Train net output #0: loss = 1.39449 (* 1 = 1.39449 loss)
I0527 08:51:06.146617  2100 sgd_solver.cpp:106] Iteration 304500, lr = 0.0005
I0527 08:51:15.886510  2100 solver.cpp:237] Iteration 304875, loss = 1.33008
I0527 08:51:15.886546  2100 solver.cpp:253]     Train net output #0: loss = 1.33008 (* 1 = 1.33008 loss)
I0527 08:51:15.886560  2100 sgd_solver.cpp:106] Iteration 304875, lr = 0.0005
I0527 08:51:25.638123  2100 solver.cpp:237] Iteration 305250, loss = 0.853499
I0527 08:51:25.638306  2100 solver.cpp:253]     Train net output #0: loss = 0.853498 (* 1 = 0.853498 loss)
I0527 08:51:25.638320  2100 sgd_solver.cpp:106] Iteration 305250, lr = 0.0005
I0527 08:51:35.382141  2100 solver.cpp:237] Iteration 305625, loss = 1.10113
I0527 08:51:35.382187  2100 solver.cpp:253]     Train net output #0: loss = 1.10113 (* 1 = 1.10113 loss)
I0527 08:51:35.382203  2100 sgd_solver.cpp:106] Iteration 305625, lr = 0.0005
I0527 08:51:45.122936  2100 solver.cpp:237] Iteration 306000, loss = 0.934372
I0527 08:51:45.122972  2100 solver.cpp:253]     Train net output #0: loss = 0.934371 (* 1 = 0.934371 loss)
I0527 08:51:45.122989  2100 sgd_solver.cpp:106] Iteration 306000, lr = 0.0005
I0527 08:52:15.780030  2100 solver.cpp:237] Iteration 306375, loss = 1.06165
I0527 08:52:15.780225  2100 solver.cpp:253]     Train net output #0: loss = 1.06165 (* 1 = 1.06165 loss)
I0527 08:52:15.780241  2100 sgd_solver.cpp:106] Iteration 306375, lr = 0.0005
I0527 08:52:25.523380  2100 solver.cpp:237] Iteration 306750, loss = 1.16265
I0527 08:52:25.523428  2100 solver.cpp:253]     Train net output #0: loss = 1.16265 (* 1 = 1.16265 loss)
I0527 08:52:25.523442  2100 sgd_solver.cpp:106] Iteration 306750, lr = 0.0005
I0527 08:52:35.267526  2100 solver.cpp:237] Iteration 307125, loss = 0.864213
I0527 08:52:35.267563  2100 solver.cpp:253]     Train net output #0: loss = 0.864213 (* 1 = 0.864213 loss)
I0527 08:52:35.267577  2100 sgd_solver.cpp:106] Iteration 307125, lr = 0.0005
I0527 08:52:44.990190  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_307500.caffemodel
I0527 08:52:45.045905  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_307500.solverstate
I0527 08:52:45.071483  2100 solver.cpp:341] Iteration 307500, Testing net (#0)
I0527 08:53:54.560184  2100 solver.cpp:409]     Test net output #0: accuracy = 0.893439
I0527 08:53:54.560375  2100 solver.cpp:409]     Test net output #1: loss = 0.33316 (* 1 = 0.33316 loss)
I0527 08:53:54.568461  2100 solver.cpp:237] Iteration 307500, loss = 0.936869
I0527 08:53:54.568490  2100 solver.cpp:253]     Train net output #0: loss = 0.936869 (* 1 = 0.936869 loss)
I0527 08:53:54.568505  2100 sgd_solver.cpp:106] Iteration 307500, lr = 0.0005
I0527 08:54:04.311097  2100 solver.cpp:237] Iteration 307875, loss = 1.2134
I0527 08:54:04.311141  2100 solver.cpp:253]     Train net output #0: loss = 1.2134 (* 1 = 1.2134 loss)
I0527 08:54:04.311156  2100 sgd_solver.cpp:106] Iteration 307875, lr = 0.0005
I0527 08:54:14.053663  2100 solver.cpp:237] Iteration 308250, loss = 1.3032
I0527 08:54:14.053697  2100 solver.cpp:253]     Train net output #0: loss = 1.3032 (* 1 = 1.3032 loss)
I0527 08:54:14.053711  2100 sgd_solver.cpp:106] Iteration 308250, lr = 0.0005
I0527 08:54:23.789273  2100 solver.cpp:237] Iteration 308625, loss = 0.990758
I0527 08:54:23.789309  2100 solver.cpp:253]     Train net output #0: loss = 0.990757 (* 1 = 0.990757 loss)
I0527 08:54:23.789325  2100 sgd_solver.cpp:106] Iteration 308625, lr = 0.0005
I0527 08:54:54.460239  2100 solver.cpp:237] Iteration 309000, loss = 1.23287
I0527 08:54:54.460443  2100 solver.cpp:253]     Train net output #0: loss = 1.23287 (* 1 = 1.23287 loss)
I0527 08:54:54.460458  2100 sgd_solver.cpp:106] Iteration 309000, lr = 0.0005
I0527 08:55:04.200757  2100 solver.cpp:237] Iteration 309375, loss = 1.58649
I0527 08:55:04.200791  2100 solver.cpp:253]     Train net output #0: loss = 1.58649 (* 1 = 1.58649 loss)
I0527 08:55:04.200809  2100 sgd_solver.cpp:106] Iteration 309375, lr = 0.0005
I0527 08:55:13.940054  2100 solver.cpp:237] Iteration 309750, loss = 1.03846
I0527 08:55:13.940090  2100 solver.cpp:253]     Train net output #0: loss = 1.03846 (* 1 = 1.03846 loss)
I0527 08:55:13.940104  2100 sgd_solver.cpp:106] Iteration 309750, lr = 0.0005
I0527 08:55:23.695881  2100 solver.cpp:237] Iteration 310125, loss = 1.25467
I0527 08:55:23.695921  2100 solver.cpp:253]     Train net output #0: loss = 1.25467 (* 1 = 1.25467 loss)
I0527 08:55:23.695942  2100 sgd_solver.cpp:106] Iteration 310125, lr = 0.0005
I0527 08:55:33.448310  2100 solver.cpp:237] Iteration 310500, loss = 1.04795
I0527 08:55:33.448482  2100 solver.cpp:253]     Train net output #0: loss = 1.04795 (* 1 = 1.04795 loss)
I0527 08:55:33.448494  2100 sgd_solver.cpp:106] Iteration 310500, lr = 0.0005
I0527 08:55:43.197517  2100 solver.cpp:237] Iteration 310875, loss = 1.14984
I0527 08:55:43.197561  2100 solver.cpp:253]     Train net output #0: loss = 1.14984 (* 1 = 1.14984 loss)
I0527 08:55:43.197581  2100 sgd_solver.cpp:106] Iteration 310875, lr = 0.0005
I0527 08:55:52.924720  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_311250.caffemodel
I0527 08:55:52.981070  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_311250.solverstate
I0527 08:56:13.911443  2100 solver.cpp:237] Iteration 311250, loss = 1.37073
I0527 08:56:13.911644  2100 solver.cpp:253]     Train net output #0: loss = 1.37073 (* 1 = 1.37073 loss)
I0527 08:56:13.911661  2100 sgd_solver.cpp:106] Iteration 311250, lr = 0.0005
I0527 08:56:23.659871  2100 solver.cpp:237] Iteration 311625, loss = 0.826719
I0527 08:56:23.659909  2100 solver.cpp:253]     Train net output #0: loss = 0.826719 (* 1 = 0.826719 loss)
I0527 08:56:23.659924  2100 sgd_solver.cpp:106] Iteration 311625, lr = 0.0005
I0527 08:56:33.407413  2100 solver.cpp:237] Iteration 312000, loss = 1.09586
I0527 08:56:33.407452  2100 solver.cpp:253]     Train net output #0: loss = 1.09586 (* 1 = 1.09586 loss)
I0527 08:56:33.407472  2100 sgd_solver.cpp:106] Iteration 312000, lr = 0.0005
I0527 08:56:43.153620  2100 solver.cpp:237] Iteration 312375, loss = 1.17079
I0527 08:56:43.153653  2100 solver.cpp:253]     Train net output #0: loss = 1.17079 (* 1 = 1.17079 loss)
I0527 08:56:43.153671  2100 sgd_solver.cpp:106] Iteration 312375, lr = 0.0005
I0527 08:56:52.904353  2100 solver.cpp:237] Iteration 312750, loss = 1.31765
I0527 08:56:52.904525  2100 solver.cpp:253]     Train net output #0: loss = 1.31765 (* 1 = 1.31765 loss)
I0527 08:56:52.904538  2100 sgd_solver.cpp:106] Iteration 312750, lr = 0.0005
I0527 08:57:02.658393  2100 solver.cpp:237] Iteration 313125, loss = 1.11735
I0527 08:57:02.658432  2100 solver.cpp:253]     Train net output #0: loss = 1.11735 (* 1 = 1.11735 loss)
I0527 08:57:02.658449  2100 sgd_solver.cpp:106] Iteration 313125, lr = 0.0005
I0527 08:57:12.401021  2100 solver.cpp:237] Iteration 313500, loss = 0.837877
I0527 08:57:12.401056  2100 solver.cpp:253]     Train net output #0: loss = 0.837876 (* 1 = 0.837876 loss)
I0527 08:57:12.401069  2100 sgd_solver.cpp:106] Iteration 313500, lr = 0.0005
I0527 08:57:43.069708  2100 solver.cpp:237] Iteration 313875, loss = 1.10358
I0527 08:57:43.069911  2100 solver.cpp:253]     Train net output #0: loss = 1.10357 (* 1 = 1.10357 loss)
I0527 08:57:43.069927  2100 sgd_solver.cpp:106] Iteration 313875, lr = 0.0005
I0527 08:57:52.814507  2100 solver.cpp:237] Iteration 314250, loss = 1.51109
I0527 08:57:52.814553  2100 solver.cpp:253]     Train net output #0: loss = 1.51109 (* 1 = 1.51109 loss)
I0527 08:57:52.814568  2100 sgd_solver.cpp:106] Iteration 314250, lr = 0.0005
I0527 08:58:02.563897  2100 solver.cpp:237] Iteration 314625, loss = 0.859539
I0527 08:58:02.563933  2100 solver.cpp:253]     Train net output #0: loss = 0.859539 (* 1 = 0.859539 loss)
I0527 08:58:02.563947  2100 sgd_solver.cpp:106] Iteration 314625, lr = 0.0005
I0527 08:58:12.304307  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_315000.caffemodel
I0527 08:58:12.361030  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_315000.solverstate
I0527 08:58:12.387825  2100 solver.cpp:341] Iteration 315000, Testing net (#0)
I0527 08:59:00.651810  2100 solver.cpp:409]     Test net output #0: accuracy = 0.893993
I0527 08:59:00.652014  2100 solver.cpp:409]     Test net output #1: loss = 0.33762 (* 1 = 0.33762 loss)
I0527 08:59:00.660101  2100 solver.cpp:237] Iteration 315000, loss = 1.03564
I0527 08:59:00.660130  2100 solver.cpp:253]     Train net output #0: loss = 1.03564 (* 1 = 1.03564 loss)
I0527 08:59:00.660145  2100 sgd_solver.cpp:106] Iteration 315000, lr = 0.0005
I0527 08:59:10.418540  2100 solver.cpp:237] Iteration 315375, loss = 1.04573
I0527 08:59:10.418576  2100 solver.cpp:253]     Train net output #0: loss = 1.04573 (* 1 = 1.04573 loss)
I0527 08:59:10.418589  2100 sgd_solver.cpp:106] Iteration 315375, lr = 0.0005
I0527 08:59:20.164029  2100 solver.cpp:237] Iteration 315750, loss = 1.45832
I0527 08:59:20.164065  2100 solver.cpp:253]     Train net output #0: loss = 1.45832 (* 1 = 1.45832 loss)
I0527 08:59:20.164078  2100 sgd_solver.cpp:106] Iteration 315750, lr = 0.0005
I0527 08:59:29.917860  2100 solver.cpp:237] Iteration 316125, loss = 1.18901
I0527 08:59:29.917904  2100 solver.cpp:253]     Train net output #0: loss = 1.18901 (* 1 = 1.18901 loss)
I0527 08:59:29.917920  2100 sgd_solver.cpp:106] Iteration 316125, lr = 0.0005
I0527 09:00:00.559089  2100 solver.cpp:237] Iteration 316500, loss = 1.1533
I0527 09:00:00.559288  2100 solver.cpp:253]     Train net output #0: loss = 1.1533 (* 1 = 1.1533 loss)
I0527 09:00:00.559303  2100 sgd_solver.cpp:106] Iteration 316500, lr = 0.0005
I0527 09:00:10.322477  2100 solver.cpp:237] Iteration 316875, loss = 1.17951
I0527 09:00:10.322511  2100 solver.cpp:253]     Train net output #0: loss = 1.17951 (* 1 = 1.17951 loss)
I0527 09:00:10.322530  2100 sgd_solver.cpp:106] Iteration 316875, lr = 0.0005
I0527 09:00:20.086391  2100 solver.cpp:237] Iteration 317250, loss = 0.989925
I0527 09:00:20.086442  2100 solver.cpp:253]     Train net output #0: loss = 0.989925 (* 1 = 0.989925 loss)
I0527 09:00:20.086457  2100 sgd_solver.cpp:106] Iteration 317250, lr = 0.0005
I0527 09:00:29.839220  2100 solver.cpp:237] Iteration 317625, loss = 1.16884
I0527 09:00:29.839251  2100 solver.cpp:253]     Train net output #0: loss = 1.16884 (* 1 = 1.16884 loss)
I0527 09:00:29.839264  2100 sgd_solver.cpp:106] Iteration 317625, lr = 0.0005
I0527 09:00:39.593677  2100 solver.cpp:237] Iteration 318000, loss = 1.44046
I0527 09:00:39.593853  2100 solver.cpp:253]     Train net output #0: loss = 1.44046 (* 1 = 1.44046 loss)
I0527 09:00:39.593868  2100 sgd_solver.cpp:106] Iteration 318000, lr = 0.0005
I0527 09:00:49.358254  2100 solver.cpp:237] Iteration 318375, loss = 1.47822
I0527 09:00:49.358296  2100 solver.cpp:253]     Train net output #0: loss = 1.47822 (* 1 = 1.47822 loss)
I0527 09:00:49.358314  2100 sgd_solver.cpp:106] Iteration 318375, lr = 0.0005
I0527 09:00:59.092864  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_318750.caffemodel
I0527 09:00:59.151231  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_318750.solverstate
I0527 09:01:20.084214  2100 solver.cpp:237] Iteration 318750, loss = 1.01893
I0527 09:01:20.084434  2100 solver.cpp:253]     Train net output #0: loss = 1.01892 (* 1 = 1.01892 loss)
I0527 09:01:20.084451  2100 sgd_solver.cpp:106] Iteration 318750, lr = 0.0005
I0527 09:01:29.838474  2100 solver.cpp:237] Iteration 319125, loss = 0.875353
I0527 09:01:29.838513  2100 solver.cpp:253]     Train net output #0: loss = 0.875353 (* 1 = 0.875353 loss)
I0527 09:01:29.838529  2100 sgd_solver.cpp:106] Iteration 319125, lr = 0.0005
I0527 09:01:39.592628  2100 solver.cpp:237] Iteration 319500, loss = 1.44732
I0527 09:01:39.592667  2100 solver.cpp:253]     Train net output #0: loss = 1.44732 (* 1 = 1.44732 loss)
I0527 09:01:39.592681  2100 sgd_solver.cpp:106] Iteration 319500, lr = 0.0005
I0527 09:01:49.343708  2100 solver.cpp:237] Iteration 319875, loss = 1.28603
I0527 09:01:49.343744  2100 solver.cpp:253]     Train net output #0: loss = 1.28603 (* 1 = 1.28603 loss)
I0527 09:01:49.343757  2100 sgd_solver.cpp:106] Iteration 319875, lr = 0.0005
I0527 09:01:59.110380  2100 solver.cpp:237] Iteration 320250, loss = 1.17689
I0527 09:01:59.110584  2100 solver.cpp:253]     Train net output #0: loss = 1.17689 (* 1 = 1.17689 loss)
I0527 09:01:59.110599  2100 sgd_solver.cpp:106] Iteration 320250, lr = 0.0005
I0527 09:02:08.875444  2100 solver.cpp:237] Iteration 320625, loss = 1.22241
I0527 09:02:08.875479  2100 solver.cpp:253]     Train net output #0: loss = 1.22241 (* 1 = 1.22241 loss)
I0527 09:02:08.875494  2100 sgd_solver.cpp:106] Iteration 320625, lr = 0.0005
I0527 09:02:18.629348  2100 solver.cpp:237] Iteration 321000, loss = 1.13896
I0527 09:02:18.629384  2100 solver.cpp:253]     Train net output #0: loss = 1.13896 (* 1 = 1.13896 loss)
I0527 09:02:18.629396  2100 sgd_solver.cpp:106] Iteration 321000, lr = 0.0005
I0527 09:02:49.276481  2100 solver.cpp:237] Iteration 321375, loss = 1.04972
I0527 09:02:49.276674  2100 solver.cpp:253]     Train net output #0: loss = 1.04972 (* 1 = 1.04972 loss)
I0527 09:02:49.276690  2100 sgd_solver.cpp:106] Iteration 321375, lr = 0.0005
I0527 09:02:59.030993  2100 solver.cpp:237] Iteration 321750, loss = 1.09743
I0527 09:02:59.031028  2100 solver.cpp:253]     Train net output #0: loss = 1.09743 (* 1 = 1.09743 loss)
I0527 09:02:59.031046  2100 sgd_solver.cpp:106] Iteration 321750, lr = 0.0005
I0527 09:03:08.792523  2100 solver.cpp:237] Iteration 322125, loss = 1.85791
I0527 09:03:08.792558  2100 solver.cpp:253]     Train net output #0: loss = 1.85791 (* 1 = 1.85791 loss)
I0527 09:03:08.792572  2100 sgd_solver.cpp:106] Iteration 322125, lr = 0.0005
I0527 09:03:18.509799  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_322500.caffemodel
I0527 09:03:18.569666  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_322500.solverstate
I0527 09:03:18.598003  2100 solver.cpp:341] Iteration 322500, Testing net (#0)
I0527 09:04:28.014777  2100 solver.cpp:409]     Test net output #0: accuracy = 0.8936
I0527 09:04:28.014971  2100 solver.cpp:409]     Test net output #1: loss = 0.32263 (* 1 = 0.32263 loss)
I0527 09:04:28.023057  2100 solver.cpp:237] Iteration 322500, loss = 1.08277
I0527 09:04:28.023085  2100 solver.cpp:253]     Train net output #0: loss = 1.08277 (* 1 = 1.08277 loss)
I0527 09:04:28.023098  2100 sgd_solver.cpp:106] Iteration 322500, lr = 0.0005
I0527 09:04:37.722693  2100 solver.cpp:237] Iteration 322875, loss = 1.05745
I0527 09:04:37.722728  2100 solver.cpp:253]     Train net output #0: loss = 1.05745 (* 1 = 1.05745 loss)
I0527 09:04:37.722746  2100 sgd_solver.cpp:106] Iteration 322875, lr = 0.0005
I0527 09:04:47.417197  2100 solver.cpp:237] Iteration 323250, loss = 1.02078
I0527 09:04:47.417233  2100 solver.cpp:253]     Train net output #0: loss = 1.02078 (* 1 = 1.02078 loss)
I0527 09:04:47.417253  2100 sgd_solver.cpp:106] Iteration 323250, lr = 0.0005
I0527 09:04:57.114946  2100 solver.cpp:237] Iteration 323625, loss = 1.03458
I0527 09:04:57.114995  2100 solver.cpp:253]     Train net output #0: loss = 1.03458 (* 1 = 1.03458 loss)
I0527 09:04:57.115008  2100 sgd_solver.cpp:106] Iteration 323625, lr = 0.0005
I0527 09:05:27.672497  2100 solver.cpp:237] Iteration 324000, loss = 1.09913
I0527 09:05:27.672701  2100 solver.cpp:253]     Train net output #0: loss = 1.09913 (* 1 = 1.09913 loss)
I0527 09:05:27.672718  2100 sgd_solver.cpp:106] Iteration 324000, lr = 0.0005
I0527 09:05:37.378023  2100 solver.cpp:237] Iteration 324375, loss = 1.12301
I0527 09:05:37.378057  2100 solver.cpp:253]     Train net output #0: loss = 1.12301 (* 1 = 1.12301 loss)
I0527 09:05:37.378072  2100 sgd_solver.cpp:106] Iteration 324375, lr = 0.0005
I0527 09:05:47.086617  2100 solver.cpp:237] Iteration 324750, loss = 1.21977
I0527 09:05:47.086666  2100 solver.cpp:253]     Train net output #0: loss = 1.21977 (* 1 = 1.21977 loss)
I0527 09:05:47.086683  2100 sgd_solver.cpp:106] Iteration 324750, lr = 0.0005
I0527 09:05:56.779248  2100 solver.cpp:237] Iteration 325125, loss = 1.21844
I0527 09:05:56.779284  2100 solver.cpp:253]     Train net output #0: loss = 1.21844 (* 1 = 1.21844 loss)
I0527 09:05:56.779299  2100 sgd_solver.cpp:106] Iteration 325125, lr = 0.0005
I0527 09:06:06.476609  2100 solver.cpp:237] Iteration 325500, loss = 1.10717
I0527 09:06:06.476801  2100 solver.cpp:253]     Train net output #0: loss = 1.10717 (* 1 = 1.10717 loss)
I0527 09:06:06.476816  2100 sgd_solver.cpp:106] Iteration 325500, lr = 0.0005
I0527 09:06:16.182332  2100 solver.cpp:237] Iteration 325875, loss = 0.989156
I0527 09:06:16.182366  2100 solver.cpp:253]     Train net output #0: loss = 0.989156 (* 1 = 0.989156 loss)
I0527 09:06:16.182384  2100 sgd_solver.cpp:106] Iteration 325875, lr = 0.0005
I0527 09:06:25.848309  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_326250.caffemodel
I0527 09:06:25.904440  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_326250.solverstate
I0527 09:06:46.796463  2100 solver.cpp:237] Iteration 326250, loss = 1.03746
I0527 09:06:46.796671  2100 solver.cpp:253]     Train net output #0: loss = 1.03746 (* 1 = 1.03746 loss)
I0527 09:06:46.796689  2100 sgd_solver.cpp:106] Iteration 326250, lr = 0.0005
I0527 09:06:56.491315  2100 solver.cpp:237] Iteration 326625, loss = 0.662332
I0527 09:06:56.491365  2100 solver.cpp:253]     Train net output #0: loss = 0.662332 (* 1 = 0.662332 loss)
I0527 09:06:56.491379  2100 sgd_solver.cpp:106] Iteration 326625, lr = 0.0005
I0527 09:07:06.188827  2100 solver.cpp:237] Iteration 327000, loss = 1.25742
I0527 09:07:06.188863  2100 solver.cpp:253]     Train net output #0: loss = 1.25742 (* 1 = 1.25742 loss)
I0527 09:07:06.188877  2100 sgd_solver.cpp:106] Iteration 327000, lr = 0.0005
I0527 09:07:15.879850  2100 solver.cpp:237] Iteration 327375, loss = 0.954634
I0527 09:07:15.879887  2100 solver.cpp:253]     Train net output #0: loss = 0.954634 (* 1 = 0.954634 loss)
I0527 09:07:15.879904  2100 sgd_solver.cpp:106] Iteration 327375, lr = 0.0005
I0527 09:07:25.581710  2100 solver.cpp:237] Iteration 327750, loss = 1.1097
I0527 09:07:25.581902  2100 solver.cpp:253]     Train net output #0: loss = 1.1097 (* 1 = 1.1097 loss)
I0527 09:07:25.581917  2100 sgd_solver.cpp:106] Iteration 327750, lr = 0.0005
I0527 09:07:35.281442  2100 solver.cpp:237] Iteration 328125, loss = 1.08979
I0527 09:07:35.281476  2100 solver.cpp:253]     Train net output #0: loss = 1.08979 (* 1 = 1.08979 loss)
I0527 09:07:35.281491  2100 sgd_solver.cpp:106] Iteration 328125, lr = 0.0005
I0527 09:07:44.981101  2100 solver.cpp:237] Iteration 328500, loss = 0.859091
I0527 09:07:44.981149  2100 solver.cpp:253]     Train net output #0: loss = 0.859091 (* 1 = 0.859091 loss)
I0527 09:07:44.981163  2100 sgd_solver.cpp:106] Iteration 328500, lr = 0.0005
I0527 09:08:15.551784  2100 solver.cpp:237] Iteration 328875, loss = 1.20027
I0527 09:08:15.551990  2100 solver.cpp:253]     Train net output #0: loss = 1.20027 (* 1 = 1.20027 loss)
I0527 09:08:15.552006  2100 sgd_solver.cpp:106] Iteration 328875, lr = 0.0005
I0527 09:08:25.252267  2100 solver.cpp:237] Iteration 329250, loss = 0.79744
I0527 09:08:25.252303  2100 solver.cpp:253]     Train net output #0: loss = 0.79744 (* 1 = 0.79744 loss)
I0527 09:08:25.252321  2100 sgd_solver.cpp:106] Iteration 329250, lr = 0.0005
I0527 09:08:34.950230  2100 solver.cpp:237] Iteration 329625, loss = 1.04377
I0527 09:08:34.950278  2100 solver.cpp:253]     Train net output #0: loss = 1.04377 (* 1 = 1.04377 loss)
I0527 09:08:34.950294  2100 sgd_solver.cpp:106] Iteration 329625, lr = 0.0005
I0527 09:08:44.626595  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_330000.caffemodel
I0527 09:08:44.698493  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_330000.solverstate
I0527 09:08:44.723846  2100 solver.cpp:341] Iteration 330000, Testing net (#0)
I0527 09:09:33.313328  2100 solver.cpp:409]     Test net output #0: accuracy = 0.893126
I0527 09:09:33.313524  2100 solver.cpp:409]     Test net output #1: loss = 0.345192 (* 1 = 0.345192 loss)
I0527 09:09:33.321589  2100 solver.cpp:237] Iteration 330000, loss = 1.2563
I0527 09:09:33.321616  2100 solver.cpp:253]     Train net output #0: loss = 1.2563 (* 1 = 1.2563 loss)
I0527 09:09:33.321631  2100 sgd_solver.cpp:106] Iteration 330000, lr = 0.0005
I0527 09:09:43.217767  2100 solver.cpp:237] Iteration 330375, loss = 0.80154
I0527 09:09:43.217802  2100 solver.cpp:253]     Train net output #0: loss = 0.80154 (* 1 = 0.80154 loss)
I0527 09:09:43.217818  2100 sgd_solver.cpp:106] Iteration 330375, lr = 0.0005
I0527 09:09:53.115983  2100 solver.cpp:237] Iteration 330750, loss = 1.19658
I0527 09:09:53.116030  2100 solver.cpp:253]     Train net output #0: loss = 1.19658 (* 1 = 1.19658 loss)
I0527 09:09:53.116044  2100 sgd_solver.cpp:106] Iteration 330750, lr = 0.0005
I0527 09:10:03.013530  2100 solver.cpp:237] Iteration 331125, loss = 1.04564
I0527 09:10:03.013566  2100 solver.cpp:253]     Train net output #0: loss = 1.04564 (* 1 = 1.04564 loss)
I0527 09:10:03.013579  2100 sgd_solver.cpp:106] Iteration 331125, lr = 0.0005
I0527 09:10:33.792160  2100 solver.cpp:237] Iteration 331500, loss = 1.48447
I0527 09:10:33.792356  2100 solver.cpp:253]     Train net output #0: loss = 1.48447 (* 1 = 1.48447 loss)
I0527 09:10:33.792371  2100 sgd_solver.cpp:106] Iteration 331500, lr = 0.0005
I0527 09:10:43.682006  2100 solver.cpp:237] Iteration 331875, loss = 0.995768
I0527 09:10:43.682054  2100 solver.cpp:253]     Train net output #0: loss = 0.995768 (* 1 = 0.995768 loss)
I0527 09:10:43.682067  2100 sgd_solver.cpp:106] Iteration 331875, lr = 0.0005
I0527 09:10:53.580768  2100 solver.cpp:237] Iteration 332250, loss = 1.29058
I0527 09:10:53.580803  2100 solver.cpp:253]     Train net output #0: loss = 1.29058 (* 1 = 1.29058 loss)
I0527 09:10:53.580817  2100 sgd_solver.cpp:106] Iteration 332250, lr = 0.0005
I0527 09:11:03.473616  2100 solver.cpp:237] Iteration 332625, loss = 1.00447
I0527 09:11:03.473652  2100 solver.cpp:253]     Train net output #0: loss = 1.00447 (* 1 = 1.00447 loss)
I0527 09:11:03.473666  2100 sgd_solver.cpp:106] Iteration 332625, lr = 0.0005
I0527 09:11:13.369968  2100 solver.cpp:237] Iteration 333000, loss = 1.32567
I0527 09:11:13.370164  2100 solver.cpp:253]     Train net output #0: loss = 1.32567 (* 1 = 1.32567 loss)
I0527 09:11:13.370178  2100 sgd_solver.cpp:106] Iteration 333000, lr = 0.0005
I0527 09:11:23.260021  2100 solver.cpp:237] Iteration 333375, loss = 1.1575
I0527 09:11:23.260056  2100 solver.cpp:253]     Train net output #0: loss = 1.1575 (* 1 = 1.1575 loss)
I0527 09:11:23.260071  2100 sgd_solver.cpp:106] Iteration 333375, lr = 0.0005
I0527 09:11:33.126382  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_333750.caffemodel
I0527 09:11:33.184463  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_333750.solverstate
I0527 09:11:54.104785  2100 solver.cpp:237] Iteration 333750, loss = 1.09329
I0527 09:11:54.104996  2100 solver.cpp:253]     Train net output #0: loss = 1.09329 (* 1 = 1.09329 loss)
I0527 09:11:54.105012  2100 sgd_solver.cpp:106] Iteration 333750, lr = 0.0005
I0527 09:12:04.001243  2100 solver.cpp:237] Iteration 334125, loss = 1.02475
I0527 09:12:04.001287  2100 solver.cpp:253]     Train net output #0: loss = 1.02475 (* 1 = 1.02475 loss)
I0527 09:12:04.001305  2100 sgd_solver.cpp:106] Iteration 334125, lr = 0.0005
I0527 09:12:13.901659  2100 solver.cpp:237] Iteration 334500, loss = 1.53743
I0527 09:12:13.901695  2100 solver.cpp:253]     Train net output #0: loss = 1.53743 (* 1 = 1.53743 loss)
I0527 09:12:13.901708  2100 sgd_solver.cpp:106] Iteration 334500, lr = 0.0005
I0527 09:12:23.802706  2100 solver.cpp:237] Iteration 334875, loss = 1.17064
I0527 09:12:23.802749  2100 solver.cpp:253]     Train net output #0: loss = 1.17064 (* 1 = 1.17064 loss)
I0527 09:12:23.802764  2100 sgd_solver.cpp:106] Iteration 334875, lr = 0.0005
I0527 09:12:33.702105  2100 solver.cpp:237] Iteration 335250, loss = 1.13788
I0527 09:12:33.702283  2100 solver.cpp:253]     Train net output #0: loss = 1.13788 (* 1 = 1.13788 loss)
I0527 09:12:33.702296  2100 sgd_solver.cpp:106] Iteration 335250, lr = 0.0005
I0527 09:12:43.589599  2100 solver.cpp:237] Iteration 335625, loss = 1.42854
I0527 09:12:43.589634  2100 solver.cpp:253]     Train net output #0: loss = 1.42854 (* 1 = 1.42854 loss)
I0527 09:12:43.589648  2100 sgd_solver.cpp:106] Iteration 335625, lr = 0.0005
I0527 09:12:53.484964  2100 solver.cpp:237] Iteration 336000, loss = 1.36635
I0527 09:12:53.485002  2100 solver.cpp:253]     Train net output #0: loss = 1.36635 (* 1 = 1.36635 loss)
I0527 09:12:53.485016  2100 sgd_solver.cpp:106] Iteration 336000, lr = 0.0005
I0527 09:13:24.224016  2100 solver.cpp:237] Iteration 336375, loss = 1.05089
I0527 09:13:24.224217  2100 solver.cpp:253]     Train net output #0: loss = 1.05089 (* 1 = 1.05089 loss)
I0527 09:13:24.224232  2100 sgd_solver.cpp:106] Iteration 336375, lr = 0.0005
I0527 09:13:34.126507  2100 solver.cpp:237] Iteration 336750, loss = 1.26717
I0527 09:13:34.126540  2100 solver.cpp:253]     Train net output #0: loss = 1.26717 (* 1 = 1.26717 loss)
I0527 09:13:34.126555  2100 sgd_solver.cpp:106] Iteration 336750, lr = 0.0005
I0527 09:13:44.024626  2100 solver.cpp:237] Iteration 337125, loss = 1.02838
I0527 09:13:44.024664  2100 solver.cpp:253]     Train net output #0: loss = 1.02838 (* 1 = 1.02838 loss)
I0527 09:13:44.024683  2100 sgd_solver.cpp:106] Iteration 337125, lr = 0.0005
I0527 09:13:53.894739  2100 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_337500.caffemodel
I0527 09:13:53.954673  2100 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0005_2016-05-20T15.49.01.064003_iter_337500.solverstate
I0527 09:13:53.982059  2100 solver.cpp:341] Iteration 337500, Testing net (#0)
I0527 09:15:03.477023  2100 solver.cpp:409]     Test net output #0: accuracy = 0.893733
I0527 09:15:03.477231  2100 solver.cpp:409]     Test net output #1: loss = 0.336565 (* 1 = 0.336565 loss)
I0527 09:15:03.485318  2100 solver.cpp:237] Iteration 337500, loss = 1.45713
I0527 09:15:03.485345  2100 solver.cpp:253]     Train net output #0: loss = 1.45713 (* 1 = 1.45713 loss)
I0527 09:15:03.485359  2100 sgd_solver.cpp:106] Iteration 337500, lr = 0.0005
I0527 09:15:13.232909  2100 solver.cpp:237] Iteration 337875, loss = 1.02454
I0527 09:15:13.232944  2100 solver.cpp:253]     Train net output #0: loss = 1.02454 (* 1 = 1.02454 loss)
I0527 09:15:13.232959  2100 sgd_solver.cpp:106] Iteration 337875, lr = 0.0005
aprun: Apid 11272396: Caught signal Terminated, sending to application
*** Aborted at 1464354917 (unix time) try "date -d @1464354917" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x831) received by PID 2100 (TID 0x2aaac746f900) from PID 2097; stack trace: ***
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7232 exceeded limit 7200
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11272396: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
aprun: Apid 11272396: Caught signal Terminated, sending to application
