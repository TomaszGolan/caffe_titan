2812202
I0526 15:35:07.952677 19470 caffe.cpp:184] Using GPUs 0
I0526 15:35:08.379551 19470 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7500
test_interval: 15000
base_lr: 0.0025
display: 750
max_iter: 750000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 7500
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804.prototxt"
I0526 15:35:08.381059 19470 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804.prototxt
I0526 15:35:08.399855 19470 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 15:35:08.399911 19470 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 15:35:08.400260 19470 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 15:35:08.400440 19470 layer_factory.hpp:77] Creating layer data_hdf5
I0526 15:35:08.400465 19470 net.cpp:106] Creating Layer data_hdf5
I0526 15:35:08.400480 19470 net.cpp:411] data_hdf5 -> data
I0526 15:35:08.400512 19470 net.cpp:411] data_hdf5 -> label
I0526 15:35:08.400544 19470 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 15:35:08.417768 19470 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 15:35:08.426853 19470 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 15:35:29.987537 19470 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 15:35:29.992614 19470 net.cpp:150] Setting up data_hdf5
I0526 15:35:29.992655 19470 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 15:35:29.992668 19470 net.cpp:157] Top shape: 20 (20)
I0526 15:35:29.992681 19470 net.cpp:165] Memory required for data: 508080
I0526 15:35:29.992694 19470 layer_factory.hpp:77] Creating layer conv1
I0526 15:35:29.992728 19470 net.cpp:106] Creating Layer conv1
I0526 15:35:29.992738 19470 net.cpp:454] conv1 <- data
I0526 15:35:29.992759 19470 net.cpp:411] conv1 -> conv1
I0526 15:35:33.009121 19470 net.cpp:150] Setting up conv1
I0526 15:35:33.009166 19470 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:35:33.009181 19470 net.cpp:165] Memory required for data: 6037680
I0526 15:35:33.009209 19470 layer_factory.hpp:77] Creating layer relu1
I0526 15:35:33.009232 19470 net.cpp:106] Creating Layer relu1
I0526 15:35:33.009243 19470 net.cpp:454] relu1 <- conv1
I0526 15:35:33.009256 19470 net.cpp:397] relu1 -> conv1 (in-place)
I0526 15:35:33.009773 19470 net.cpp:150] Setting up relu1
I0526 15:35:33.009790 19470 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:35:33.009800 19470 net.cpp:165] Memory required for data: 11567280
I0526 15:35:33.009811 19470 layer_factory.hpp:77] Creating layer pool1
I0526 15:35:33.009827 19470 net.cpp:106] Creating Layer pool1
I0526 15:35:33.009837 19470 net.cpp:454] pool1 <- conv1
I0526 15:35:33.009850 19470 net.cpp:411] pool1 -> pool1
I0526 15:35:33.009930 19470 net.cpp:150] Setting up pool1
I0526 15:35:33.009944 19470 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 15:35:33.009954 19470 net.cpp:165] Memory required for data: 14332080
I0526 15:35:33.009963 19470 layer_factory.hpp:77] Creating layer conv2
I0526 15:35:33.009985 19470 net.cpp:106] Creating Layer conv2
I0526 15:35:33.009996 19470 net.cpp:454] conv2 <- pool1
I0526 15:35:33.010010 19470 net.cpp:411] conv2 -> conv2
I0526 15:35:33.012698 19470 net.cpp:150] Setting up conv2
I0526 15:35:33.012727 19470 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:35:33.012737 19470 net.cpp:165] Memory required for data: 18306480
I0526 15:35:33.012756 19470 layer_factory.hpp:77] Creating layer relu2
I0526 15:35:33.012770 19470 net.cpp:106] Creating Layer relu2
I0526 15:35:33.012780 19470 net.cpp:454] relu2 <- conv2
I0526 15:35:33.012794 19470 net.cpp:397] relu2 -> conv2 (in-place)
I0526 15:35:33.013135 19470 net.cpp:150] Setting up relu2
I0526 15:35:33.013149 19470 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:35:33.013159 19470 net.cpp:165] Memory required for data: 22280880
I0526 15:35:33.013170 19470 layer_factory.hpp:77] Creating layer pool2
I0526 15:35:33.013183 19470 net.cpp:106] Creating Layer pool2
I0526 15:35:33.013193 19470 net.cpp:454] pool2 <- conv2
I0526 15:35:33.013206 19470 net.cpp:411] pool2 -> pool2
I0526 15:35:33.013288 19470 net.cpp:150] Setting up pool2
I0526 15:35:33.013301 19470 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 15:35:33.013311 19470 net.cpp:165] Memory required for data: 24268080
I0526 15:35:33.013321 19470 layer_factory.hpp:77] Creating layer conv3
I0526 15:35:33.013339 19470 net.cpp:106] Creating Layer conv3
I0526 15:35:33.013350 19470 net.cpp:454] conv3 <- pool2
I0526 15:35:33.013363 19470 net.cpp:411] conv3 -> conv3
I0526 15:35:33.015305 19470 net.cpp:150] Setting up conv3
I0526 15:35:33.015328 19470 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:35:33.015341 19470 net.cpp:165] Memory required for data: 26436400
I0526 15:35:33.015359 19470 layer_factory.hpp:77] Creating layer relu3
I0526 15:35:33.015377 19470 net.cpp:106] Creating Layer relu3
I0526 15:35:33.015385 19470 net.cpp:454] relu3 <- conv3
I0526 15:35:33.015398 19470 net.cpp:397] relu3 -> conv3 (in-place)
I0526 15:35:33.015866 19470 net.cpp:150] Setting up relu3
I0526 15:35:33.015883 19470 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:35:33.015894 19470 net.cpp:165] Memory required for data: 28604720
I0526 15:35:33.015904 19470 layer_factory.hpp:77] Creating layer pool3
I0526 15:35:33.015918 19470 net.cpp:106] Creating Layer pool3
I0526 15:35:33.015926 19470 net.cpp:454] pool3 <- conv3
I0526 15:35:33.015939 19470 net.cpp:411] pool3 -> pool3
I0526 15:35:33.016007 19470 net.cpp:150] Setting up pool3
I0526 15:35:33.016021 19470 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 15:35:33.016031 19470 net.cpp:165] Memory required for data: 29688880
I0526 15:35:33.016038 19470 layer_factory.hpp:77] Creating layer conv4
I0526 15:35:33.016055 19470 net.cpp:106] Creating Layer conv4
I0526 15:35:33.016067 19470 net.cpp:454] conv4 <- pool3
I0526 15:35:33.016080 19470 net.cpp:411] conv4 -> conv4
I0526 15:35:33.018811 19470 net.cpp:150] Setting up conv4
I0526 15:35:33.018834 19470 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:35:33.018844 19470 net.cpp:165] Memory required for data: 30414640
I0526 15:35:33.018860 19470 layer_factory.hpp:77] Creating layer relu4
I0526 15:35:33.018874 19470 net.cpp:106] Creating Layer relu4
I0526 15:35:33.018884 19470 net.cpp:454] relu4 <- conv4
I0526 15:35:33.018898 19470 net.cpp:397] relu4 -> conv4 (in-place)
I0526 15:35:33.019366 19470 net.cpp:150] Setting up relu4
I0526 15:35:33.019383 19470 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:35:33.019394 19470 net.cpp:165] Memory required for data: 31140400
I0526 15:35:33.019404 19470 layer_factory.hpp:77] Creating layer pool4
I0526 15:35:33.019418 19470 net.cpp:106] Creating Layer pool4
I0526 15:35:33.019428 19470 net.cpp:454] pool4 <- conv4
I0526 15:35:33.019439 19470 net.cpp:411] pool4 -> pool4
I0526 15:35:33.019507 19470 net.cpp:150] Setting up pool4
I0526 15:35:33.019520 19470 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 15:35:33.019531 19470 net.cpp:165] Memory required for data: 31503280
I0526 15:35:33.019541 19470 layer_factory.hpp:77] Creating layer ip1
I0526 15:35:33.019562 19470 net.cpp:106] Creating Layer ip1
I0526 15:35:33.019572 19470 net.cpp:454] ip1 <- pool4
I0526 15:35:33.019587 19470 net.cpp:411] ip1 -> ip1
I0526 15:35:33.035034 19470 net.cpp:150] Setting up ip1
I0526 15:35:33.035063 19470 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:35:33.035079 19470 net.cpp:165] Memory required for data: 31518960
I0526 15:35:33.035100 19470 layer_factory.hpp:77] Creating layer relu5
I0526 15:35:33.035115 19470 net.cpp:106] Creating Layer relu5
I0526 15:35:33.035125 19470 net.cpp:454] relu5 <- ip1
I0526 15:35:33.035138 19470 net.cpp:397] relu5 -> ip1 (in-place)
I0526 15:35:33.035480 19470 net.cpp:150] Setting up relu5
I0526 15:35:33.035495 19470 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:35:33.035504 19470 net.cpp:165] Memory required for data: 31534640
I0526 15:35:33.035516 19470 layer_factory.hpp:77] Creating layer drop1
I0526 15:35:33.035537 19470 net.cpp:106] Creating Layer drop1
I0526 15:35:33.035547 19470 net.cpp:454] drop1 <- ip1
I0526 15:35:33.035559 19470 net.cpp:397] drop1 -> ip1 (in-place)
I0526 15:35:33.035617 19470 net.cpp:150] Setting up drop1
I0526 15:35:33.035631 19470 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:35:33.035641 19470 net.cpp:165] Memory required for data: 31550320
I0526 15:35:33.035651 19470 layer_factory.hpp:77] Creating layer ip2
I0526 15:35:33.035670 19470 net.cpp:106] Creating Layer ip2
I0526 15:35:33.035681 19470 net.cpp:454] ip2 <- ip1
I0526 15:35:33.035693 19470 net.cpp:411] ip2 -> ip2
I0526 15:35:33.036156 19470 net.cpp:150] Setting up ip2
I0526 15:35:33.036170 19470 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:35:33.036180 19470 net.cpp:165] Memory required for data: 31558160
I0526 15:35:33.036195 19470 layer_factory.hpp:77] Creating layer relu6
I0526 15:35:33.036207 19470 net.cpp:106] Creating Layer relu6
I0526 15:35:33.036216 19470 net.cpp:454] relu6 <- ip2
I0526 15:35:33.036228 19470 net.cpp:397] relu6 -> ip2 (in-place)
I0526 15:35:33.036744 19470 net.cpp:150] Setting up relu6
I0526 15:35:33.036761 19470 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:35:33.036772 19470 net.cpp:165] Memory required for data: 31566000
I0526 15:35:33.036782 19470 layer_factory.hpp:77] Creating layer drop2
I0526 15:35:33.036795 19470 net.cpp:106] Creating Layer drop2
I0526 15:35:33.036804 19470 net.cpp:454] drop2 <- ip2
I0526 15:35:33.036818 19470 net.cpp:397] drop2 -> ip2 (in-place)
I0526 15:35:33.036867 19470 net.cpp:150] Setting up drop2
I0526 15:35:33.036880 19470 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:35:33.036890 19470 net.cpp:165] Memory required for data: 31573840
I0526 15:35:33.036901 19470 layer_factory.hpp:77] Creating layer ip3
I0526 15:35:33.036914 19470 net.cpp:106] Creating Layer ip3
I0526 15:35:33.036924 19470 net.cpp:454] ip3 <- ip2
I0526 15:35:33.036936 19470 net.cpp:411] ip3 -> ip3
I0526 15:35:33.037149 19470 net.cpp:150] Setting up ip3
I0526 15:35:33.037163 19470 net.cpp:157] Top shape: 20 11 (220)
I0526 15:35:33.037173 19470 net.cpp:165] Memory required for data: 31574720
I0526 15:35:33.037189 19470 layer_factory.hpp:77] Creating layer drop3
I0526 15:35:33.037200 19470 net.cpp:106] Creating Layer drop3
I0526 15:35:33.037210 19470 net.cpp:454] drop3 <- ip3
I0526 15:35:33.037222 19470 net.cpp:397] drop3 -> ip3 (in-place)
I0526 15:35:33.037262 19470 net.cpp:150] Setting up drop3
I0526 15:35:33.037276 19470 net.cpp:157] Top shape: 20 11 (220)
I0526 15:35:33.037286 19470 net.cpp:165] Memory required for data: 31575600
I0526 15:35:33.037297 19470 layer_factory.hpp:77] Creating layer loss
I0526 15:35:33.037315 19470 net.cpp:106] Creating Layer loss
I0526 15:35:33.037325 19470 net.cpp:454] loss <- ip3
I0526 15:35:33.037334 19470 net.cpp:454] loss <- label
I0526 15:35:33.037348 19470 net.cpp:411] loss -> loss
I0526 15:35:33.037364 19470 layer_factory.hpp:77] Creating layer loss
I0526 15:35:33.038003 19470 net.cpp:150] Setting up loss
I0526 15:35:33.038025 19470 net.cpp:157] Top shape: (1)
I0526 15:35:33.038038 19470 net.cpp:160]     with loss weight 1
I0526 15:35:33.038080 19470 net.cpp:165] Memory required for data: 31575604
I0526 15:35:33.038091 19470 net.cpp:226] loss needs backward computation.
I0526 15:35:33.038102 19470 net.cpp:226] drop3 needs backward computation.
I0526 15:35:33.038112 19470 net.cpp:226] ip3 needs backward computation.
I0526 15:35:33.038122 19470 net.cpp:226] drop2 needs backward computation.
I0526 15:35:33.038131 19470 net.cpp:226] relu6 needs backward computation.
I0526 15:35:33.038141 19470 net.cpp:226] ip2 needs backward computation.
I0526 15:35:33.038151 19470 net.cpp:226] drop1 needs backward computation.
I0526 15:35:33.038161 19470 net.cpp:226] relu5 needs backward computation.
I0526 15:35:33.038171 19470 net.cpp:226] ip1 needs backward computation.
I0526 15:35:33.038182 19470 net.cpp:226] pool4 needs backward computation.
I0526 15:35:33.038192 19470 net.cpp:226] relu4 needs backward computation.
I0526 15:35:33.038200 19470 net.cpp:226] conv4 needs backward computation.
I0526 15:35:33.038211 19470 net.cpp:226] pool3 needs backward computation.
I0526 15:35:33.038221 19470 net.cpp:226] relu3 needs backward computation.
I0526 15:35:33.038231 19470 net.cpp:226] conv3 needs backward computation.
I0526 15:35:33.038251 19470 net.cpp:226] pool2 needs backward computation.
I0526 15:35:33.038262 19470 net.cpp:226] relu2 needs backward computation.
I0526 15:35:33.038274 19470 net.cpp:226] conv2 needs backward computation.
I0526 15:35:33.038283 19470 net.cpp:226] pool1 needs backward computation.
I0526 15:35:33.038293 19470 net.cpp:226] relu1 needs backward computation.
I0526 15:35:33.038303 19470 net.cpp:226] conv1 needs backward computation.
I0526 15:35:33.038314 19470 net.cpp:228] data_hdf5 does not need backward computation.
I0526 15:35:33.038323 19470 net.cpp:270] This network produces output loss
I0526 15:35:33.038347 19470 net.cpp:283] Network initialization done.
I0526 15:35:33.039916 19470 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804.prototxt
I0526 15:35:33.039988 19470 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 15:35:33.040343 19470 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 15:35:33.040532 19470 layer_factory.hpp:77] Creating layer data_hdf5
I0526 15:35:33.040549 19470 net.cpp:106] Creating Layer data_hdf5
I0526 15:35:33.040560 19470 net.cpp:411] data_hdf5 -> data
I0526 15:35:33.040577 19470 net.cpp:411] data_hdf5 -> label
I0526 15:35:33.040593 19470 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 15:35:33.052307 19470 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 15:35:54.436115 19470 net.cpp:150] Setting up data_hdf5
I0526 15:35:54.436278 19470 net.cpp:157] Top shape: 20 1 127 50 (127000)
I0526 15:35:54.436292 19470 net.cpp:157] Top shape: 20 (20)
I0526 15:35:54.436305 19470 net.cpp:165] Memory required for data: 508080
I0526 15:35:54.436318 19470 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 15:35:54.436347 19470 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 15:35:54.436357 19470 net.cpp:454] label_data_hdf5_1_split <- label
I0526 15:35:54.436372 19470 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 15:35:54.436393 19470 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 15:35:54.436466 19470 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 15:35:54.436480 19470 net.cpp:157] Top shape: 20 (20)
I0526 15:35:54.436491 19470 net.cpp:157] Top shape: 20 (20)
I0526 15:35:54.436501 19470 net.cpp:165] Memory required for data: 508240
I0526 15:35:54.436511 19470 layer_factory.hpp:77] Creating layer conv1
I0526 15:35:54.436533 19470 net.cpp:106] Creating Layer conv1
I0526 15:35:54.436544 19470 net.cpp:454] conv1 <- data
I0526 15:35:54.436558 19470 net.cpp:411] conv1 -> conv1
I0526 15:35:54.438485 19470 net.cpp:150] Setting up conv1
I0526 15:35:54.438510 19470 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:35:54.438520 19470 net.cpp:165] Memory required for data: 6037840
I0526 15:35:54.438544 19470 layer_factory.hpp:77] Creating layer relu1
I0526 15:35:54.438558 19470 net.cpp:106] Creating Layer relu1
I0526 15:35:54.438567 19470 net.cpp:454] relu1 <- conv1
I0526 15:35:54.438580 19470 net.cpp:397] relu1 -> conv1 (in-place)
I0526 15:35:54.439075 19470 net.cpp:150] Setting up relu1
I0526 15:35:54.439091 19470 net.cpp:157] Top shape: 20 12 120 48 (1382400)
I0526 15:35:54.439102 19470 net.cpp:165] Memory required for data: 11567440
I0526 15:35:54.439112 19470 layer_factory.hpp:77] Creating layer pool1
I0526 15:35:54.439128 19470 net.cpp:106] Creating Layer pool1
I0526 15:35:54.439138 19470 net.cpp:454] pool1 <- conv1
I0526 15:35:54.439152 19470 net.cpp:411] pool1 -> pool1
I0526 15:35:54.439227 19470 net.cpp:150] Setting up pool1
I0526 15:35:54.439241 19470 net.cpp:157] Top shape: 20 12 60 48 (691200)
I0526 15:35:54.439252 19470 net.cpp:165] Memory required for data: 14332240
I0526 15:35:54.439262 19470 layer_factory.hpp:77] Creating layer conv2
I0526 15:35:54.439280 19470 net.cpp:106] Creating Layer conv2
I0526 15:35:54.439291 19470 net.cpp:454] conv2 <- pool1
I0526 15:35:54.439306 19470 net.cpp:411] conv2 -> conv2
I0526 15:35:54.441220 19470 net.cpp:150] Setting up conv2
I0526 15:35:54.441242 19470 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:35:54.441256 19470 net.cpp:165] Memory required for data: 18306640
I0526 15:35:54.441272 19470 layer_factory.hpp:77] Creating layer relu2
I0526 15:35:54.441287 19470 net.cpp:106] Creating Layer relu2
I0526 15:35:54.441296 19470 net.cpp:454] relu2 <- conv2
I0526 15:35:54.441308 19470 net.cpp:397] relu2 -> conv2 (in-place)
I0526 15:35:54.441639 19470 net.cpp:150] Setting up relu2
I0526 15:35:54.441653 19470 net.cpp:157] Top shape: 20 20 54 46 (993600)
I0526 15:35:54.441663 19470 net.cpp:165] Memory required for data: 22281040
I0526 15:35:54.441673 19470 layer_factory.hpp:77] Creating layer pool2
I0526 15:35:54.441686 19470 net.cpp:106] Creating Layer pool2
I0526 15:35:54.441696 19470 net.cpp:454] pool2 <- conv2
I0526 15:35:54.441709 19470 net.cpp:411] pool2 -> pool2
I0526 15:35:54.441779 19470 net.cpp:150] Setting up pool2
I0526 15:35:54.441793 19470 net.cpp:157] Top shape: 20 20 27 46 (496800)
I0526 15:35:54.441802 19470 net.cpp:165] Memory required for data: 24268240
I0526 15:35:54.441812 19470 layer_factory.hpp:77] Creating layer conv3
I0526 15:35:54.441829 19470 net.cpp:106] Creating Layer conv3
I0526 15:35:54.441840 19470 net.cpp:454] conv3 <- pool2
I0526 15:35:54.441854 19470 net.cpp:411] conv3 -> conv3
I0526 15:35:54.443819 19470 net.cpp:150] Setting up conv3
I0526 15:35:54.443843 19470 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:35:54.443855 19470 net.cpp:165] Memory required for data: 26436560
I0526 15:35:54.443872 19470 layer_factory.hpp:77] Creating layer relu3
I0526 15:35:54.443898 19470 net.cpp:106] Creating Layer relu3
I0526 15:35:54.443908 19470 net.cpp:454] relu3 <- conv3
I0526 15:35:54.443923 19470 net.cpp:397] relu3 -> conv3 (in-place)
I0526 15:35:54.444398 19470 net.cpp:150] Setting up relu3
I0526 15:35:54.444414 19470 net.cpp:157] Top shape: 20 28 22 44 (542080)
I0526 15:35:54.444424 19470 net.cpp:165] Memory required for data: 28604880
I0526 15:35:54.444434 19470 layer_factory.hpp:77] Creating layer pool3
I0526 15:35:54.444447 19470 net.cpp:106] Creating Layer pool3
I0526 15:35:54.444458 19470 net.cpp:454] pool3 <- conv3
I0526 15:35:54.444470 19470 net.cpp:411] pool3 -> pool3
I0526 15:35:54.444541 19470 net.cpp:150] Setting up pool3
I0526 15:35:54.444555 19470 net.cpp:157] Top shape: 20 28 11 44 (271040)
I0526 15:35:54.444566 19470 net.cpp:165] Memory required for data: 29689040
I0526 15:35:54.444574 19470 layer_factory.hpp:77] Creating layer conv4
I0526 15:35:54.444593 19470 net.cpp:106] Creating Layer conv4
I0526 15:35:54.444603 19470 net.cpp:454] conv4 <- pool3
I0526 15:35:54.444618 19470 net.cpp:411] conv4 -> conv4
I0526 15:35:54.446681 19470 net.cpp:150] Setting up conv4
I0526 15:35:54.446703 19470 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:35:54.446713 19470 net.cpp:165] Memory required for data: 30414800
I0526 15:35:54.446729 19470 layer_factory.hpp:77] Creating layer relu4
I0526 15:35:54.446743 19470 net.cpp:106] Creating Layer relu4
I0526 15:35:54.446753 19470 net.cpp:454] relu4 <- conv4
I0526 15:35:54.446766 19470 net.cpp:397] relu4 -> conv4 (in-place)
I0526 15:35:54.447234 19470 net.cpp:150] Setting up relu4
I0526 15:35:54.447249 19470 net.cpp:157] Top shape: 20 36 6 42 (181440)
I0526 15:35:54.447259 19470 net.cpp:165] Memory required for data: 31140560
I0526 15:35:54.447269 19470 layer_factory.hpp:77] Creating layer pool4
I0526 15:35:54.447283 19470 net.cpp:106] Creating Layer pool4
I0526 15:35:54.447293 19470 net.cpp:454] pool4 <- conv4
I0526 15:35:54.447307 19470 net.cpp:411] pool4 -> pool4
I0526 15:35:54.447381 19470 net.cpp:150] Setting up pool4
I0526 15:35:54.447393 19470 net.cpp:157] Top shape: 20 36 3 42 (90720)
I0526 15:35:54.447403 19470 net.cpp:165] Memory required for data: 31503440
I0526 15:35:54.447412 19470 layer_factory.hpp:77] Creating layer ip1
I0526 15:35:54.447427 19470 net.cpp:106] Creating Layer ip1
I0526 15:35:54.447438 19470 net.cpp:454] ip1 <- pool4
I0526 15:35:54.447451 19470 net.cpp:411] ip1 -> ip1
I0526 15:35:54.462847 19470 net.cpp:150] Setting up ip1
I0526 15:35:54.462872 19470 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:35:54.462882 19470 net.cpp:165] Memory required for data: 31519120
I0526 15:35:54.462905 19470 layer_factory.hpp:77] Creating layer relu5
I0526 15:35:54.462920 19470 net.cpp:106] Creating Layer relu5
I0526 15:35:54.462930 19470 net.cpp:454] relu5 <- ip1
I0526 15:35:54.462944 19470 net.cpp:397] relu5 -> ip1 (in-place)
I0526 15:35:54.463292 19470 net.cpp:150] Setting up relu5
I0526 15:35:54.463306 19470 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:35:54.463315 19470 net.cpp:165] Memory required for data: 31534800
I0526 15:35:54.463326 19470 layer_factory.hpp:77] Creating layer drop1
I0526 15:35:54.463346 19470 net.cpp:106] Creating Layer drop1
I0526 15:35:54.463356 19470 net.cpp:454] drop1 <- ip1
I0526 15:35:54.463368 19470 net.cpp:397] drop1 -> ip1 (in-place)
I0526 15:35:54.463415 19470 net.cpp:150] Setting up drop1
I0526 15:35:54.463428 19470 net.cpp:157] Top shape: 20 196 (3920)
I0526 15:35:54.463438 19470 net.cpp:165] Memory required for data: 31550480
I0526 15:35:54.463449 19470 layer_factory.hpp:77] Creating layer ip2
I0526 15:35:54.463464 19470 net.cpp:106] Creating Layer ip2
I0526 15:35:54.463472 19470 net.cpp:454] ip2 <- ip1
I0526 15:35:54.463485 19470 net.cpp:411] ip2 -> ip2
I0526 15:35:54.463968 19470 net.cpp:150] Setting up ip2
I0526 15:35:54.463980 19470 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:35:54.463990 19470 net.cpp:165] Memory required for data: 31558320
I0526 15:35:54.464005 19470 layer_factory.hpp:77] Creating layer relu6
I0526 15:35:54.464030 19470 net.cpp:106] Creating Layer relu6
I0526 15:35:54.464040 19470 net.cpp:454] relu6 <- ip2
I0526 15:35:54.464053 19470 net.cpp:397] relu6 -> ip2 (in-place)
I0526 15:35:54.464584 19470 net.cpp:150] Setting up relu6
I0526 15:35:54.464607 19470 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:35:54.464617 19470 net.cpp:165] Memory required for data: 31566160
I0526 15:35:54.464627 19470 layer_factory.hpp:77] Creating layer drop2
I0526 15:35:54.464642 19470 net.cpp:106] Creating Layer drop2
I0526 15:35:54.464651 19470 net.cpp:454] drop2 <- ip2
I0526 15:35:54.464664 19470 net.cpp:397] drop2 -> ip2 (in-place)
I0526 15:35:54.464709 19470 net.cpp:150] Setting up drop2
I0526 15:35:54.464721 19470 net.cpp:157] Top shape: 20 98 (1960)
I0526 15:35:54.464731 19470 net.cpp:165] Memory required for data: 31574000
I0526 15:35:54.464740 19470 layer_factory.hpp:77] Creating layer ip3
I0526 15:35:54.464754 19470 net.cpp:106] Creating Layer ip3
I0526 15:35:54.464766 19470 net.cpp:454] ip3 <- ip2
I0526 15:35:54.464778 19470 net.cpp:411] ip3 -> ip3
I0526 15:35:54.465010 19470 net.cpp:150] Setting up ip3
I0526 15:35:54.465023 19470 net.cpp:157] Top shape: 20 11 (220)
I0526 15:35:54.465034 19470 net.cpp:165] Memory required for data: 31574880
I0526 15:35:54.465049 19470 layer_factory.hpp:77] Creating layer drop3
I0526 15:35:54.465062 19470 net.cpp:106] Creating Layer drop3
I0526 15:35:54.465072 19470 net.cpp:454] drop3 <- ip3
I0526 15:35:54.465085 19470 net.cpp:397] drop3 -> ip3 (in-place)
I0526 15:35:54.465126 19470 net.cpp:150] Setting up drop3
I0526 15:35:54.465138 19470 net.cpp:157] Top shape: 20 11 (220)
I0526 15:35:54.465148 19470 net.cpp:165] Memory required for data: 31575760
I0526 15:35:54.465158 19470 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 15:35:54.465172 19470 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 15:35:54.465181 19470 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 15:35:54.465195 19470 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 15:35:54.465210 19470 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 15:35:54.465283 19470 net.cpp:150] Setting up ip3_drop3_0_split
I0526 15:35:54.465296 19470 net.cpp:157] Top shape: 20 11 (220)
I0526 15:35:54.465308 19470 net.cpp:157] Top shape: 20 11 (220)
I0526 15:35:54.465319 19470 net.cpp:165] Memory required for data: 31577520
I0526 15:35:54.465328 19470 layer_factory.hpp:77] Creating layer accuracy
I0526 15:35:54.465350 19470 net.cpp:106] Creating Layer accuracy
I0526 15:35:54.465360 19470 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 15:35:54.465371 19470 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 15:35:54.465385 19470 net.cpp:411] accuracy -> accuracy
I0526 15:35:54.465410 19470 net.cpp:150] Setting up accuracy
I0526 15:35:54.465423 19470 net.cpp:157] Top shape: (1)
I0526 15:35:54.465433 19470 net.cpp:165] Memory required for data: 31577524
I0526 15:35:54.465441 19470 layer_factory.hpp:77] Creating layer loss
I0526 15:35:54.465456 19470 net.cpp:106] Creating Layer loss
I0526 15:35:54.465466 19470 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 15:35:54.465477 19470 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 15:35:54.465490 19470 net.cpp:411] loss -> loss
I0526 15:35:54.465508 19470 layer_factory.hpp:77] Creating layer loss
I0526 15:35:54.465992 19470 net.cpp:150] Setting up loss
I0526 15:35:54.466006 19470 net.cpp:157] Top shape: (1)
I0526 15:35:54.466015 19470 net.cpp:160]     with loss weight 1
I0526 15:35:54.466033 19470 net.cpp:165] Memory required for data: 31577528
I0526 15:35:54.466043 19470 net.cpp:226] loss needs backward computation.
I0526 15:35:54.466054 19470 net.cpp:228] accuracy does not need backward computation.
I0526 15:35:54.466065 19470 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 15:35:54.466076 19470 net.cpp:226] drop3 needs backward computation.
I0526 15:35:54.466086 19470 net.cpp:226] ip3 needs backward computation.
I0526 15:35:54.466097 19470 net.cpp:226] drop2 needs backward computation.
I0526 15:35:54.466107 19470 net.cpp:226] relu6 needs backward computation.
I0526 15:35:54.466126 19470 net.cpp:226] ip2 needs backward computation.
I0526 15:35:54.466136 19470 net.cpp:226] drop1 needs backward computation.
I0526 15:35:54.466146 19470 net.cpp:226] relu5 needs backward computation.
I0526 15:35:54.466156 19470 net.cpp:226] ip1 needs backward computation.
I0526 15:35:54.466166 19470 net.cpp:226] pool4 needs backward computation.
I0526 15:35:54.466176 19470 net.cpp:226] relu4 needs backward computation.
I0526 15:35:54.466187 19470 net.cpp:226] conv4 needs backward computation.
I0526 15:35:54.466197 19470 net.cpp:226] pool3 needs backward computation.
I0526 15:35:54.466208 19470 net.cpp:226] relu3 needs backward computation.
I0526 15:35:54.466218 19470 net.cpp:226] conv3 needs backward computation.
I0526 15:35:54.466228 19470 net.cpp:226] pool2 needs backward computation.
I0526 15:35:54.466239 19470 net.cpp:226] relu2 needs backward computation.
I0526 15:35:54.466249 19470 net.cpp:226] conv2 needs backward computation.
I0526 15:35:54.466259 19470 net.cpp:226] pool1 needs backward computation.
I0526 15:35:54.466269 19470 net.cpp:226] relu1 needs backward computation.
I0526 15:35:54.466279 19470 net.cpp:226] conv1 needs backward computation.
I0526 15:35:54.466290 19470 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 15:35:54.466302 19470 net.cpp:228] data_hdf5 does not need backward computation.
I0526 15:35:54.466312 19470 net.cpp:270] This network produces output accuracy
I0526 15:35:54.466322 19470 net.cpp:270] This network produces output loss
I0526 15:35:54.466349 19470 net.cpp:283] Network initialization done.
I0526 15:35:54.466483 19470 solver.cpp:60] Solver scaffolding done.
I0526 15:35:54.467622 19470 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_285000.solverstate
I0526 15:35:54.686029 19470 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 15:35:54.691582 19470 caffe.cpp:212] Starting Optimization
I0526 15:35:54.691627 19470 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 15:35:54.691637 19470 solver.cpp:289] Learning Rate Policy: fixed
I0526 15:35:54.692997 19470 solver.cpp:341] Iteration 285000, Testing net (#0)
I0526 15:36:47.595780 19470 solver.cpp:409]     Test net output #0: accuracy = 0.900543
I0526 15:36:47.595942 19470 solver.cpp:409]     Test net output #1: loss = 0.31189 (* 1 = 0.31189 loss)
I0526 15:36:47.615012 19470 solver.cpp:237] Iteration 285000, loss = 1.16419
I0526 15:36:47.615043 19470 solver.cpp:253]     Train net output #0: loss = 1.16419 (* 1 = 1.16419 loss)
I0526 15:36:47.615064 19470 sgd_solver.cpp:106] Iteration 285000, lr = 0.0025
I0526 15:36:59.761000 19470 solver.cpp:237] Iteration 285750, loss = 1.29336
I0526 15:36:59.761036 19470 solver.cpp:253]     Train net output #0: loss = 1.29336 (* 1 = 1.29336 loss)
I0526 15:36:59.761050 19470 sgd_solver.cpp:106] Iteration 285750, lr = 0.0025
I0526 15:37:11.910894 19470 solver.cpp:237] Iteration 286500, loss = 1.27082
I0526 15:37:11.910939 19470 solver.cpp:253]     Train net output #0: loss = 1.27082 (* 1 = 1.27082 loss)
I0526 15:37:11.910953 19470 sgd_solver.cpp:106] Iteration 286500, lr = 0.0025
I0526 15:37:24.073668 19470 solver.cpp:237] Iteration 287250, loss = 1.27333
I0526 15:37:24.073814 19470 solver.cpp:253]     Train net output #0: loss = 1.27333 (* 1 = 1.27333 loss)
I0526 15:37:24.073828 19470 sgd_solver.cpp:106] Iteration 287250, lr = 0.0025
I0526 15:37:36.257659 19470 solver.cpp:237] Iteration 288000, loss = 0.725698
I0526 15:37:36.257701 19470 solver.cpp:253]     Train net output #0: loss = 0.725698 (* 1 = 0.725698 loss)
I0526 15:37:36.257715 19470 sgd_solver.cpp:106] Iteration 288000, lr = 0.0025
I0526 15:37:48.413473 19470 solver.cpp:237] Iteration 288750, loss = 1.36402
I0526 15:37:48.413509 19470 solver.cpp:253]     Train net output #0: loss = 1.36402 (* 1 = 1.36402 loss)
I0526 15:37:48.413523 19470 sgd_solver.cpp:106] Iteration 288750, lr = 0.0025
I0526 15:38:00.589795 19470 solver.cpp:237] Iteration 289500, loss = 1.34771
I0526 15:38:00.589934 19470 solver.cpp:253]     Train net output #0: loss = 1.34771 (* 1 = 1.34771 loss)
I0526 15:38:00.589947 19470 sgd_solver.cpp:106] Iteration 289500, lr = 0.0025
I0526 15:38:34.903158 19470 solver.cpp:237] Iteration 290250, loss = 1.7547
I0526 15:38:34.903321 19470 solver.cpp:253]     Train net output #0: loss = 1.7547 (* 1 = 1.7547 loss)
I0526 15:38:34.903334 19470 sgd_solver.cpp:106] Iteration 290250, lr = 0.0025
I0526 15:38:47.040128 19470 solver.cpp:237] Iteration 291000, loss = 1.03025
I0526 15:38:47.040175 19470 solver.cpp:253]     Train net output #0: loss = 1.03025 (* 1 = 1.03025 loss)
I0526 15:38:47.040189 19470 sgd_solver.cpp:106] Iteration 291000, lr = 0.0025
I0526 15:38:59.170260 19470 solver.cpp:237] Iteration 291750, loss = 1.96845
I0526 15:38:59.170295 19470 solver.cpp:253]     Train net output #0: loss = 1.96845 (* 1 = 1.96845 loss)
I0526 15:38:59.170310 19470 sgd_solver.cpp:106] Iteration 291750, lr = 0.0025
I0526 15:39:11.322331 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_292500.caffemodel
I0526 15:39:11.373649 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_292500.solverstate
I0526 15:39:11.405604 19470 solver.cpp:237] Iteration 292500, loss = 0.89292
I0526 15:39:11.405654 19470 solver.cpp:253]     Train net output #0: loss = 0.89292 (* 1 = 0.89292 loss)
I0526 15:39:11.405669 19470 sgd_solver.cpp:106] Iteration 292500, lr = 0.0025
I0526 15:39:23.586202 19470 solver.cpp:237] Iteration 293250, loss = 1.29387
I0526 15:39:23.586241 19470 solver.cpp:253]     Train net output #0: loss = 1.29387 (* 1 = 1.29387 loss)
I0526 15:39:23.586254 19470 sgd_solver.cpp:106] Iteration 293250, lr = 0.0025
I0526 15:39:35.757855 19470 solver.cpp:237] Iteration 294000, loss = 0.853284
I0526 15:39:35.757905 19470 solver.cpp:253]     Train net output #0: loss = 0.853284 (* 1 = 0.853284 loss)
I0526 15:39:35.757921 19470 sgd_solver.cpp:106] Iteration 294000, lr = 0.0025
I0526 15:39:47.973932 19470 solver.cpp:237] Iteration 294750, loss = 1.05037
I0526 15:39:47.974076 19470 solver.cpp:253]     Train net output #0: loss = 1.05037 (* 1 = 1.05037 loss)
I0526 15:39:47.974089 19470 sgd_solver.cpp:106] Iteration 294750, lr = 0.0025
I0526 15:40:22.276767 19470 solver.cpp:237] Iteration 295500, loss = 0.801437
I0526 15:40:22.276947 19470 solver.cpp:253]     Train net output #0: loss = 0.801437 (* 1 = 0.801437 loss)
I0526 15:40:22.276962 19470 sgd_solver.cpp:106] Iteration 295500, lr = 0.0025
I0526 15:40:34.416213 19470 solver.cpp:237] Iteration 296250, loss = 0.605652
I0526 15:40:34.416260 19470 solver.cpp:253]     Train net output #0: loss = 0.605651 (* 1 = 0.605651 loss)
I0526 15:40:34.416275 19470 sgd_solver.cpp:106] Iteration 296250, lr = 0.0025
I0526 15:40:46.566392 19470 solver.cpp:237] Iteration 297000, loss = 1.20625
I0526 15:40:46.566428 19470 solver.cpp:253]     Train net output #0: loss = 1.20625 (* 1 = 1.20625 loss)
I0526 15:40:46.566444 19470 sgd_solver.cpp:106] Iteration 297000, lr = 0.0025
I0526 15:40:58.724148 19470 solver.cpp:237] Iteration 297750, loss = 0.971621
I0526 15:40:58.724298 19470 solver.cpp:253]     Train net output #0: loss = 0.97162 (* 1 = 0.97162 loss)
I0526 15:40:58.724313 19470 sgd_solver.cpp:106] Iteration 297750, lr = 0.0025
I0526 15:41:10.892331 19470 solver.cpp:237] Iteration 298500, loss = 1.30422
I0526 15:41:10.892367 19470 solver.cpp:253]     Train net output #0: loss = 1.30422 (* 1 = 1.30422 loss)
I0526 15:41:10.892382 19470 sgd_solver.cpp:106] Iteration 298500, lr = 0.0025
I0526 15:41:23.064980 19470 solver.cpp:237] Iteration 299250, loss = 1.18877
I0526 15:41:23.065026 19470 solver.cpp:253]     Train net output #0: loss = 1.18877 (* 1 = 1.18877 loss)
I0526 15:41:23.065039 19470 sgd_solver.cpp:106] Iteration 299250, lr = 0.0025
I0526 15:41:35.214447 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_300000.caffemodel
I0526 15:41:35.265260 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_300000.solverstate
I0526 15:41:35.291950 19470 solver.cpp:341] Iteration 300000, Testing net (#0)
I0526 15:42:27.213480 19470 solver.cpp:409]     Test net output #0: accuracy = 0.902292
I0526 15:42:27.213636 19470 solver.cpp:409]     Test net output #1: loss = 0.305319 (* 1 = 0.305319 loss)
I0526 15:42:49.336796 19470 solver.cpp:237] Iteration 300000, loss = 0.957727
I0526 15:42:49.336850 19470 solver.cpp:253]     Train net output #0: loss = 0.957727 (* 1 = 0.957727 loss)
I0526 15:42:49.336872 19470 sgd_solver.cpp:106] Iteration 300000, lr = 0.0025
I0526 15:43:01.474266 19470 solver.cpp:237] Iteration 300750, loss = 1.10185
I0526 15:43:01.474419 19470 solver.cpp:253]     Train net output #0: loss = 1.10185 (* 1 = 1.10185 loss)
I0526 15:43:01.474433 19470 sgd_solver.cpp:106] Iteration 300750, lr = 0.0025
I0526 15:43:13.616582 19470 solver.cpp:237] Iteration 301500, loss = 1.01661
I0526 15:43:13.616618 19470 solver.cpp:253]     Train net output #0: loss = 1.01661 (* 1 = 1.01661 loss)
I0526 15:43:13.616634 19470 sgd_solver.cpp:106] Iteration 301500, lr = 0.0025
I0526 15:43:25.807543 19470 solver.cpp:237] Iteration 302250, loss = 1.24593
I0526 15:43:25.807593 19470 solver.cpp:253]     Train net output #0: loss = 1.24593 (* 1 = 1.24593 loss)
I0526 15:43:25.807607 19470 sgd_solver.cpp:106] Iteration 302250, lr = 0.0025
I0526 15:43:38.017889 19470 solver.cpp:237] Iteration 303000, loss = 0.946758
I0526 15:43:38.018028 19470 solver.cpp:253]     Train net output #0: loss = 0.946759 (* 1 = 0.946759 loss)
I0526 15:43:38.018045 19470 sgd_solver.cpp:106] Iteration 303000, lr = 0.0025
I0526 15:43:50.199620 19470 solver.cpp:237] Iteration 303750, loss = 1.67446
I0526 15:43:50.199664 19470 solver.cpp:253]     Train net output #0: loss = 1.67446 (* 1 = 1.67446 loss)
I0526 15:43:50.199678 19470 sgd_solver.cpp:106] Iteration 303750, lr = 0.0025
I0526 15:44:02.365161 19470 solver.cpp:237] Iteration 304500, loss = 1.38157
I0526 15:44:02.365196 19470 solver.cpp:253]     Train net output #0: loss = 1.38157 (* 1 = 1.38157 loss)
I0526 15:44:02.365211 19470 sgd_solver.cpp:106] Iteration 304500, lr = 0.0025
I0526 15:44:36.692368 19470 solver.cpp:237] Iteration 305250, loss = 1.26567
I0526 15:44:36.692538 19470 solver.cpp:253]     Train net output #0: loss = 1.26567 (* 1 = 1.26567 loss)
I0526 15:44:36.692553 19470 sgd_solver.cpp:106] Iteration 305250, lr = 0.0025
I0526 15:44:48.844014 19470 solver.cpp:237] Iteration 306000, loss = 1.08087
I0526 15:44:48.844051 19470 solver.cpp:253]     Train net output #0: loss = 1.08087 (* 1 = 1.08087 loss)
I0526 15:44:48.844065 19470 sgd_solver.cpp:106] Iteration 306000, lr = 0.0025
I0526 15:45:01.060883 19470 solver.cpp:237] Iteration 306750, loss = 0.886734
I0526 15:45:01.060931 19470 solver.cpp:253]     Train net output #0: loss = 0.886735 (* 1 = 0.886735 loss)
I0526 15:45:01.060945 19470 sgd_solver.cpp:106] Iteration 306750, lr = 0.0025
I0526 15:45:13.276103 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_307500.caffemodel
I0526 15:45:13.327813 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_307500.solverstate
I0526 15:45:13.360397 19470 solver.cpp:237] Iteration 307500, loss = 1.46637
I0526 15:45:13.360443 19470 solver.cpp:253]     Train net output #0: loss = 1.46637 (* 1 = 1.46637 loss)
I0526 15:45:13.360462 19470 sgd_solver.cpp:106] Iteration 307500, lr = 0.0025
I0526 15:45:25.568776 19470 solver.cpp:237] Iteration 308250, loss = 1.13186
I0526 15:45:25.568824 19470 solver.cpp:253]     Train net output #0: loss = 1.13186 (* 1 = 1.13186 loss)
I0526 15:45:25.568840 19470 sgd_solver.cpp:106] Iteration 308250, lr = 0.0025
I0526 15:45:37.746294 19470 solver.cpp:237] Iteration 309000, loss = 0.872132
I0526 15:45:37.746331 19470 solver.cpp:253]     Train net output #0: loss = 0.872133 (* 1 = 0.872133 loss)
I0526 15:45:37.746346 19470 sgd_solver.cpp:106] Iteration 309000, lr = 0.0025
I0526 15:45:49.912281 19470 solver.cpp:237] Iteration 309750, loss = 1.38719
I0526 15:45:49.912434 19470 solver.cpp:253]     Train net output #0: loss = 1.38719 (* 1 = 1.38719 loss)
I0526 15:45:49.912448 19470 sgd_solver.cpp:106] Iteration 309750, lr = 0.0025
I0526 15:46:24.244768 19470 solver.cpp:237] Iteration 310500, loss = 1.01799
I0526 15:46:24.244941 19470 solver.cpp:253]     Train net output #0: loss = 1.01799 (* 1 = 1.01799 loss)
I0526 15:46:24.244956 19470 sgd_solver.cpp:106] Iteration 310500, lr = 0.0025
I0526 15:46:36.433166 19470 solver.cpp:237] Iteration 311250, loss = 1.71636
I0526 15:46:36.433202 19470 solver.cpp:253]     Train net output #0: loss = 1.71636 (* 1 = 1.71636 loss)
I0526 15:46:36.433217 19470 sgd_solver.cpp:106] Iteration 311250, lr = 0.0025
I0526 15:46:48.599433 19470 solver.cpp:237] Iteration 312000, loss = 0.766414
I0526 15:46:48.599485 19470 solver.cpp:253]     Train net output #0: loss = 0.766415 (* 1 = 0.766415 loss)
I0526 15:46:48.599499 19470 sgd_solver.cpp:106] Iteration 312000, lr = 0.0025
I0526 15:47:00.755774 19470 solver.cpp:237] Iteration 312750, loss = 1.45958
I0526 15:47:00.755915 19470 solver.cpp:253]     Train net output #0: loss = 1.45958 (* 1 = 1.45958 loss)
I0526 15:47:00.755928 19470 sgd_solver.cpp:106] Iteration 312750, lr = 0.0025
I0526 15:47:12.886721 19470 solver.cpp:237] Iteration 313500, loss = 1.16854
I0526 15:47:12.886768 19470 solver.cpp:253]     Train net output #0: loss = 1.16854 (* 1 = 1.16854 loss)
I0526 15:47:12.886782 19470 sgd_solver.cpp:106] Iteration 313500, lr = 0.0025
I0526 15:47:24.957073 19470 solver.cpp:237] Iteration 314250, loss = 0.777485
I0526 15:47:24.957110 19470 solver.cpp:253]     Train net output #0: loss = 0.777485 (* 1 = 0.777485 loss)
I0526 15:47:24.957124 19470 sgd_solver.cpp:106] Iteration 314250, lr = 0.0025
I0526 15:47:37.081122 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_315000.caffemodel
I0526 15:47:37.132508 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_315000.solverstate
I0526 15:47:37.159977 19470 solver.cpp:341] Iteration 315000, Testing net (#0)
I0526 15:48:50.039127 19470 solver.cpp:409]     Test net output #0: accuracy = 0.898664
I0526 15:48:50.039283 19470 solver.cpp:409]     Test net output #1: loss = 0.330968 (* 1 = 0.330968 loss)
I0526 15:49:12.202527 19470 solver.cpp:237] Iteration 315000, loss = 1.27466
I0526 15:49:12.202580 19470 solver.cpp:253]     Train net output #0: loss = 1.27466 (* 1 = 1.27466 loss)
I0526 15:49:12.202595 19470 sgd_solver.cpp:106] Iteration 315000, lr = 0.0025
I0526 15:49:24.414494 19470 solver.cpp:237] Iteration 315750, loss = 0.820025
I0526 15:49:24.414654 19470 solver.cpp:253]     Train net output #0: loss = 0.820026 (* 1 = 0.820026 loss)
I0526 15:49:24.414669 19470 sgd_solver.cpp:106] Iteration 315750, lr = 0.0025
I0526 15:49:36.605918 19470 solver.cpp:237] Iteration 316500, loss = 1.01717
I0526 15:49:36.605957 19470 solver.cpp:253]     Train net output #0: loss = 1.01717 (* 1 = 1.01717 loss)
I0526 15:49:36.605976 19470 sgd_solver.cpp:106] Iteration 316500, lr = 0.0025
I0526 15:49:48.777698 19470 solver.cpp:237] Iteration 317250, loss = 1.40134
I0526 15:49:48.777734 19470 solver.cpp:253]     Train net output #0: loss = 1.40134 (* 1 = 1.40134 loss)
I0526 15:49:48.777750 19470 sgd_solver.cpp:106] Iteration 317250, lr = 0.0025
I0526 15:50:00.941908 19470 solver.cpp:237] Iteration 318000, loss = 1.31983
I0526 15:50:00.942057 19470 solver.cpp:253]     Train net output #0: loss = 1.31983 (* 1 = 1.31983 loss)
I0526 15:50:00.942071 19470 sgd_solver.cpp:106] Iteration 318000, lr = 0.0025
I0526 15:50:13.096385 19470 solver.cpp:237] Iteration 318750, loss = 1.07821
I0526 15:50:13.096421 19470 solver.cpp:253]     Train net output #0: loss = 1.07821 (* 1 = 1.07821 loss)
I0526 15:50:13.096434 19470 sgd_solver.cpp:106] Iteration 318750, lr = 0.0025
I0526 15:50:25.285759 19470 solver.cpp:237] Iteration 319500, loss = 1.20212
I0526 15:50:25.285799 19470 solver.cpp:253]     Train net output #0: loss = 1.20212 (* 1 = 1.20212 loss)
I0526 15:50:25.285818 19470 sgd_solver.cpp:106] Iteration 319500, lr = 0.0025
I0526 15:50:59.593998 19470 solver.cpp:237] Iteration 320250, loss = 1.36681
I0526 15:50:59.594166 19470 solver.cpp:253]     Train net output #0: loss = 1.36681 (* 1 = 1.36681 loss)
I0526 15:50:59.594182 19470 sgd_solver.cpp:106] Iteration 320250, lr = 0.0025
I0526 15:51:11.778967 19470 solver.cpp:237] Iteration 321000, loss = 0.96517
I0526 15:51:11.779003 19470 solver.cpp:253]     Train net output #0: loss = 0.96517 (* 1 = 0.96517 loss)
I0526 15:51:11.779018 19470 sgd_solver.cpp:106] Iteration 321000, lr = 0.0025
I0526 15:51:24.017570 19470 solver.cpp:237] Iteration 321750, loss = 1.46998
I0526 15:51:24.017616 19470 solver.cpp:253]     Train net output #0: loss = 1.46998 (* 1 = 1.46998 loss)
I0526 15:51:24.017630 19470 sgd_solver.cpp:106] Iteration 321750, lr = 0.0025
I0526 15:51:36.220495 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_322500.caffemodel
I0526 15:51:36.272377 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_322500.solverstate
I0526 15:51:36.305022 19470 solver.cpp:237] Iteration 322500, loss = 1.14091
I0526 15:51:36.305068 19470 solver.cpp:253]     Train net output #0: loss = 1.14091 (* 1 = 1.14091 loss)
I0526 15:51:36.305088 19470 sgd_solver.cpp:106] Iteration 322500, lr = 0.0025
I0526 15:51:48.434012 19470 solver.cpp:237] Iteration 323250, loss = 1.36483
I0526 15:51:48.434062 19470 solver.cpp:253]     Train net output #0: loss = 1.36483 (* 1 = 1.36483 loss)
I0526 15:51:48.434077 19470 sgd_solver.cpp:106] Iteration 323250, lr = 0.0025
I0526 15:52:00.574584 19470 solver.cpp:237] Iteration 324000, loss = 0.6908
I0526 15:52:00.574620 19470 solver.cpp:253]     Train net output #0: loss = 0.6908 (* 1 = 0.6908 loss)
I0526 15:52:00.574635 19470 sgd_solver.cpp:106] Iteration 324000, lr = 0.0025
I0526 15:52:12.743604 19470 solver.cpp:237] Iteration 324750, loss = 1.11049
I0526 15:52:12.743773 19470 solver.cpp:253]     Train net output #0: loss = 1.11049 (* 1 = 1.11049 loss)
I0526 15:52:12.743788 19470 sgd_solver.cpp:106] Iteration 324750, lr = 0.0025
I0526 15:52:47.075362 19470 solver.cpp:237] Iteration 325500, loss = 0.93442
I0526 15:52:47.075534 19470 solver.cpp:253]     Train net output #0: loss = 0.93442 (* 1 = 0.93442 loss)
I0526 15:52:47.075549 19470 sgd_solver.cpp:106] Iteration 325500, lr = 0.0025
I0526 15:52:59.236630 19470 solver.cpp:237] Iteration 326250, loss = 1.03138
I0526 15:52:59.236677 19470 solver.cpp:253]     Train net output #0: loss = 1.03138 (* 1 = 1.03138 loss)
I0526 15:52:59.236692 19470 sgd_solver.cpp:106] Iteration 326250, lr = 0.0025
I0526 15:53:11.378487 19470 solver.cpp:237] Iteration 327000, loss = 1.57543
I0526 15:53:11.378523 19470 solver.cpp:253]     Train net output #0: loss = 1.57543 (* 1 = 1.57543 loss)
I0526 15:53:11.378538 19470 sgd_solver.cpp:106] Iteration 327000, lr = 0.0025
I0526 15:53:23.515125 19470 solver.cpp:237] Iteration 327750, loss = 1.25013
I0526 15:53:23.515277 19470 solver.cpp:253]     Train net output #0: loss = 1.25013 (* 1 = 1.25013 loss)
I0526 15:53:23.515291 19470 sgd_solver.cpp:106] Iteration 327750, lr = 0.0025
I0526 15:53:35.672008 19470 solver.cpp:237] Iteration 328500, loss = 0.999459
I0526 15:53:35.672045 19470 solver.cpp:253]     Train net output #0: loss = 0.999459 (* 1 = 0.999459 loss)
I0526 15:53:35.672060 19470 sgd_solver.cpp:106] Iteration 328500, lr = 0.0025
I0526 15:53:47.859252 19470 solver.cpp:237] Iteration 329250, loss = 0.988823
I0526 15:53:47.859298 19470 solver.cpp:253]     Train net output #0: loss = 0.988823 (* 1 = 0.988823 loss)
I0526 15:53:47.859313 19470 sgd_solver.cpp:106] Iteration 329250, lr = 0.0025
I0526 15:54:00.019255 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_330000.caffemodel
I0526 15:54:00.081487 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_330000.solverstate
I0526 15:54:00.106904 19470 solver.cpp:341] Iteration 330000, Testing net (#0)
I0526 15:54:51.705080 19470 solver.cpp:409]     Test net output #0: accuracy = 0.903039
I0526 15:54:51.705248 19470 solver.cpp:409]     Test net output #1: loss = 0.309557 (* 1 = 0.309557 loss)
I0526 15:55:13.843288 19470 solver.cpp:237] Iteration 330000, loss = 0.830319
I0526 15:55:13.843341 19470 solver.cpp:253]     Train net output #0: loss = 0.830318 (* 1 = 0.830318 loss)
I0526 15:55:13.843358 19470 sgd_solver.cpp:106] Iteration 330000, lr = 0.0025
I0526 15:55:26.033866 19470 solver.cpp:237] Iteration 330750, loss = 1.07775
I0526 15:55:26.034018 19470 solver.cpp:253]     Train net output #0: loss = 1.07775 (* 1 = 1.07775 loss)
I0526 15:55:26.034034 19470 sgd_solver.cpp:106] Iteration 330750, lr = 0.0025
I0526 15:55:38.211611 19470 solver.cpp:237] Iteration 331500, loss = 1.43832
I0526 15:55:38.211647 19470 solver.cpp:253]     Train net output #0: loss = 1.43832 (* 1 = 1.43832 loss)
I0526 15:55:38.211660 19470 sgd_solver.cpp:106] Iteration 331500, lr = 0.0025
I0526 15:55:50.381626 19470 solver.cpp:237] Iteration 332250, loss = 1.2601
I0526 15:55:50.381675 19470 solver.cpp:253]     Train net output #0: loss = 1.2601 (* 1 = 1.2601 loss)
I0526 15:55:50.381688 19470 sgd_solver.cpp:106] Iteration 332250, lr = 0.0025
I0526 15:56:02.556133 19470 solver.cpp:237] Iteration 333000, loss = 0.852238
I0526 15:56:02.556278 19470 solver.cpp:253]     Train net output #0: loss = 0.852237 (* 1 = 0.852237 loss)
I0526 15:56:02.556293 19470 sgd_solver.cpp:106] Iteration 333000, lr = 0.0025
I0526 15:56:14.692422 19470 solver.cpp:237] Iteration 333750, loss = 1.45163
I0526 15:56:14.692471 19470 solver.cpp:253]     Train net output #0: loss = 1.45163 (* 1 = 1.45163 loss)
I0526 15:56:14.692484 19470 sgd_solver.cpp:106] Iteration 333750, lr = 0.0025
I0526 15:56:26.824026 19470 solver.cpp:237] Iteration 334500, loss = 0.66568
I0526 15:56:26.824064 19470 solver.cpp:253]     Train net output #0: loss = 0.665679 (* 1 = 0.665679 loss)
I0526 15:56:26.824077 19470 sgd_solver.cpp:106] Iteration 334500, lr = 0.0025
I0526 15:57:01.150775 19470 solver.cpp:237] Iteration 335250, loss = 0.999234
I0526 15:57:01.150938 19470 solver.cpp:253]     Train net output #0: loss = 0.999233 (* 1 = 0.999233 loss)
I0526 15:57:01.150954 19470 sgd_solver.cpp:106] Iteration 335250, lr = 0.0025
I0526 15:57:13.292685 19470 solver.cpp:237] Iteration 336000, loss = 1.00969
I0526 15:57:13.292728 19470 solver.cpp:253]     Train net output #0: loss = 1.00969 (* 1 = 1.00969 loss)
I0526 15:57:13.292742 19470 sgd_solver.cpp:106] Iteration 336000, lr = 0.0025
I0526 15:57:25.452018 19470 solver.cpp:237] Iteration 336750, loss = 1.30545
I0526 15:57:25.452054 19470 solver.cpp:253]     Train net output #0: loss = 1.30545 (* 1 = 1.30545 loss)
I0526 15:57:25.452069 19470 sgd_solver.cpp:106] Iteration 336750, lr = 0.0025
I0526 15:57:37.596098 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_337500.caffemodel
I0526 15:57:37.645294 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_337500.solverstate
I0526 15:57:37.675165 19470 solver.cpp:237] Iteration 337500, loss = 1.31661
I0526 15:57:37.675209 19470 solver.cpp:253]     Train net output #0: loss = 1.31661 (* 1 = 1.31661 loss)
I0526 15:57:37.675225 19470 sgd_solver.cpp:106] Iteration 337500, lr = 0.0025
I0526 15:57:49.850004 19470 solver.cpp:237] Iteration 338250, loss = 0.936794
I0526 15:57:49.850041 19470 solver.cpp:253]     Train net output #0: loss = 0.936794 (* 1 = 0.936794 loss)
I0526 15:57:49.850055 19470 sgd_solver.cpp:106] Iteration 338250, lr = 0.0025
I0526 15:58:02.020823 19470 solver.cpp:237] Iteration 339000, loss = 1.03873
I0526 15:58:02.020874 19470 solver.cpp:253]     Train net output #0: loss = 1.03873 (* 1 = 1.03873 loss)
I0526 15:58:02.020889 19470 sgd_solver.cpp:106] Iteration 339000, lr = 0.0025
I0526 15:58:14.190351 19470 solver.cpp:237] Iteration 339750, loss = 1.43198
I0526 15:58:14.190500 19470 solver.cpp:253]     Train net output #0: loss = 1.43198 (* 1 = 1.43198 loss)
I0526 15:58:14.190512 19470 sgd_solver.cpp:106] Iteration 339750, lr = 0.0025
I0526 15:58:48.501231 19470 solver.cpp:237] Iteration 340500, loss = 1.44018
I0526 15:58:48.501399 19470 solver.cpp:253]     Train net output #0: loss = 1.44018 (* 1 = 1.44018 loss)
I0526 15:58:48.501413 19470 sgd_solver.cpp:106] Iteration 340500, lr = 0.0025
I0526 15:59:00.678344 19470 solver.cpp:237] Iteration 341250, loss = 1.78116
I0526 15:59:00.678381 19470 solver.cpp:253]     Train net output #0: loss = 1.78115 (* 1 = 1.78115 loss)
I0526 15:59:00.678395 19470 sgd_solver.cpp:106] Iteration 341250, lr = 0.0025
I0526 15:59:12.841076 19470 solver.cpp:237] Iteration 342000, loss = 1.01993
I0526 15:59:12.841122 19470 solver.cpp:253]     Train net output #0: loss = 1.01993 (* 1 = 1.01993 loss)
I0526 15:59:12.841137 19470 sgd_solver.cpp:106] Iteration 342000, lr = 0.0025
I0526 15:59:25.023598 19470 solver.cpp:237] Iteration 342750, loss = 1.43563
I0526 15:59:25.023741 19470 solver.cpp:253]     Train net output #0: loss = 1.43563 (* 1 = 1.43563 loss)
I0526 15:59:25.023757 19470 sgd_solver.cpp:106] Iteration 342750, lr = 0.0025
I0526 15:59:37.164917 19470 solver.cpp:237] Iteration 343500, loss = 1.04915
I0526 15:59:37.164963 19470 solver.cpp:253]     Train net output #0: loss = 1.04915 (* 1 = 1.04915 loss)
I0526 15:59:37.164978 19470 sgd_solver.cpp:106] Iteration 343500, lr = 0.0025
I0526 15:59:49.343595 19470 solver.cpp:237] Iteration 344250, loss = 1.19282
I0526 15:59:49.343631 19470 solver.cpp:253]     Train net output #0: loss = 1.19282 (* 1 = 1.19282 loss)
I0526 15:59:49.343646 19470 sgd_solver.cpp:106] Iteration 344250, lr = 0.0025
I0526 16:00:01.480681 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_345000.caffemodel
I0526 16:00:01.529662 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_345000.solverstate
I0526 16:00:01.555207 19470 solver.cpp:341] Iteration 345000, Testing net (#0)
I0526 16:01:14.368084 19470 solver.cpp:409]     Test net output #0: accuracy = 0.898891
I0526 16:01:14.368248 19470 solver.cpp:409]     Test net output #1: loss = 0.301777 (* 1 = 0.301777 loss)
I0526 16:01:36.492384 19470 solver.cpp:237] Iteration 345000, loss = 1.24574
I0526 16:01:36.492437 19470 solver.cpp:253]     Train net output #0: loss = 1.24574 (* 1 = 1.24574 loss)
I0526 16:01:36.492452 19470 sgd_solver.cpp:106] Iteration 345000, lr = 0.0025
I0526 16:01:48.720801 19470 solver.cpp:237] Iteration 345750, loss = 1.15301
I0526 16:01:48.720963 19470 solver.cpp:253]     Train net output #0: loss = 1.15301 (* 1 = 1.15301 loss)
I0526 16:01:48.720976 19470 sgd_solver.cpp:106] Iteration 345750, lr = 0.0025
I0526 16:02:00.912832 19470 solver.cpp:237] Iteration 346500, loss = 1.00369
I0526 16:02:00.912873 19470 solver.cpp:253]     Train net output #0: loss = 1.00369 (* 1 = 1.00369 loss)
I0526 16:02:00.912889 19470 sgd_solver.cpp:106] Iteration 346500, lr = 0.0025
I0526 16:02:13.112495 19470 solver.cpp:237] Iteration 347250, loss = 1.29628
I0526 16:02:13.112538 19470 solver.cpp:253]     Train net output #0: loss = 1.29628 (* 1 = 1.29628 loss)
I0526 16:02:13.112553 19470 sgd_solver.cpp:106] Iteration 347250, lr = 0.0025
I0526 16:02:25.309741 19470 solver.cpp:237] Iteration 348000, loss = 1.10984
I0526 16:02:25.309885 19470 solver.cpp:253]     Train net output #0: loss = 1.10984 (* 1 = 1.10984 loss)
I0526 16:02:25.309898 19470 sgd_solver.cpp:106] Iteration 348000, lr = 0.0025
I0526 16:02:37.502348 19470 solver.cpp:237] Iteration 348750, loss = 1.1563
I0526 16:02:37.502396 19470 solver.cpp:253]     Train net output #0: loss = 1.1563 (* 1 = 1.1563 loss)
I0526 16:02:37.502410 19470 sgd_solver.cpp:106] Iteration 348750, lr = 0.0025
I0526 16:02:49.702574 19470 solver.cpp:237] Iteration 349500, loss = 1.06268
I0526 16:02:49.702610 19470 solver.cpp:253]     Train net output #0: loss = 1.06268 (* 1 = 1.06268 loss)
I0526 16:02:49.702625 19470 sgd_solver.cpp:106] Iteration 349500, lr = 0.0025
I0526 16:03:24.021483 19470 solver.cpp:237] Iteration 350250, loss = 1.0758
I0526 16:03:24.021649 19470 solver.cpp:253]     Train net output #0: loss = 1.0758 (* 1 = 1.0758 loss)
I0526 16:03:24.021663 19470 sgd_solver.cpp:106] Iteration 350250, lr = 0.0025
I0526 16:03:36.171416 19470 solver.cpp:237] Iteration 351000, loss = 1.39294
I0526 16:03:36.171452 19470 solver.cpp:253]     Train net output #0: loss = 1.39294 (* 1 = 1.39294 loss)
I0526 16:03:36.171465 19470 sgd_solver.cpp:106] Iteration 351000, lr = 0.0025
I0526 16:03:48.335278 19470 solver.cpp:237] Iteration 351750, loss = 0.903
I0526 16:03:48.335324 19470 solver.cpp:253]     Train net output #0: loss = 0.902999 (* 1 = 0.902999 loss)
I0526 16:03:48.335336 19470 sgd_solver.cpp:106] Iteration 351750, lr = 0.0025
I0526 16:04:00.500583 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_352500.caffemodel
I0526 16:04:00.552336 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_352500.solverstate
I0526 16:04:00.585129 19470 solver.cpp:237] Iteration 352500, loss = 1.78544
I0526 16:04:00.585178 19470 solver.cpp:253]     Train net output #0: loss = 1.78544 (* 1 = 1.78544 loss)
I0526 16:04:00.585194 19470 sgd_solver.cpp:106] Iteration 352500, lr = 0.0025
I0526 16:04:12.756078 19470 solver.cpp:237] Iteration 353250, loss = 1.19722
I0526 16:04:12.756129 19470 solver.cpp:253]     Train net output #0: loss = 1.19722 (* 1 = 1.19722 loss)
I0526 16:04:12.756142 19470 sgd_solver.cpp:106] Iteration 353250, lr = 0.0025
I0526 16:04:24.942317 19470 solver.cpp:237] Iteration 354000, loss = 1.80446
I0526 16:04:24.942353 19470 solver.cpp:253]     Train net output #0: loss = 1.80446 (* 1 = 1.80446 loss)
I0526 16:04:24.942368 19470 sgd_solver.cpp:106] Iteration 354000, lr = 0.0025
I0526 16:04:37.140372 19470 solver.cpp:237] Iteration 354750, loss = 1.02776
I0526 16:04:37.140544 19470 solver.cpp:253]     Train net output #0: loss = 1.02776 (* 1 = 1.02776 loss)
I0526 16:04:37.140558 19470 sgd_solver.cpp:106] Iteration 354750, lr = 0.0025
I0526 16:05:11.528740 19470 solver.cpp:237] Iteration 355500, loss = 1.18474
I0526 16:05:11.528923 19470 solver.cpp:253]     Train net output #0: loss = 1.18474 (* 1 = 1.18474 loss)
I0526 16:05:11.528937 19470 sgd_solver.cpp:106] Iteration 355500, lr = 0.0025
I0526 16:05:23.735878 19470 solver.cpp:237] Iteration 356250, loss = 1.19746
I0526 16:05:23.735914 19470 solver.cpp:253]     Train net output #0: loss = 1.19746 (* 1 = 1.19746 loss)
I0526 16:05:23.735929 19470 sgd_solver.cpp:106] Iteration 356250, lr = 0.0025
I0526 16:05:35.991257 19470 solver.cpp:237] Iteration 357000, loss = 1.11081
I0526 16:05:35.991305 19470 solver.cpp:253]     Train net output #0: loss = 1.11081 (* 1 = 1.11081 loss)
I0526 16:05:35.991319 19470 sgd_solver.cpp:106] Iteration 357000, lr = 0.0025
I0526 16:05:48.246711 19470 solver.cpp:237] Iteration 357750, loss = 1.48222
I0526 16:05:48.246860 19470 solver.cpp:253]     Train net output #0: loss = 1.48222 (* 1 = 1.48222 loss)
I0526 16:05:48.246872 19470 sgd_solver.cpp:106] Iteration 357750, lr = 0.0025
I0526 16:06:00.425917 19470 solver.cpp:237] Iteration 358500, loss = 1.51953
I0526 16:06:00.425967 19470 solver.cpp:253]     Train net output #0: loss = 1.51953 (* 1 = 1.51953 loss)
I0526 16:06:00.425981 19470 sgd_solver.cpp:106] Iteration 358500, lr = 0.0025
I0526 16:06:12.595875 19470 solver.cpp:237] Iteration 359250, loss = 1.66758
I0526 16:06:12.595911 19470 solver.cpp:253]     Train net output #0: loss = 1.66758 (* 1 = 1.66758 loss)
I0526 16:06:12.595924 19470 sgd_solver.cpp:106] Iteration 359250, lr = 0.0025
I0526 16:06:24.742863 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_360000.caffemodel
I0526 16:06:24.794536 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_360000.solverstate
I0526 16:06:24.822243 19470 solver.cpp:341] Iteration 360000, Testing net (#0)
I0526 16:07:16.827494 19470 solver.cpp:409]     Test net output #0: accuracy = 0.90237
I0526 16:07:16.827656 19470 solver.cpp:409]     Test net output #1: loss = 0.301928 (* 1 = 0.301928 loss)
I0526 16:07:37.707797 19470 solver.cpp:237] Iteration 360000, loss = 1.63106
I0526 16:07:37.707847 19470 solver.cpp:253]     Train net output #0: loss = 1.63106 (* 1 = 1.63106 loss)
I0526 16:07:37.707864 19470 sgd_solver.cpp:106] Iteration 360000, lr = 0.0025
I0526 16:07:49.830818 19470 solver.cpp:237] Iteration 360750, loss = 0.924727
I0526 16:07:49.830967 19470 solver.cpp:253]     Train net output #0: loss = 0.924726 (* 1 = 0.924726 loss)
I0526 16:07:49.830983 19470 sgd_solver.cpp:106] Iteration 360750, lr = 0.0025
I0526 16:08:01.956027 19470 solver.cpp:237] Iteration 361500, loss = 0.793798
I0526 16:08:01.956069 19470 solver.cpp:253]     Train net output #0: loss = 0.793797 (* 1 = 0.793797 loss)
I0526 16:08:01.956084 19470 sgd_solver.cpp:106] Iteration 361500, lr = 0.0025
I0526 16:08:14.082267 19470 solver.cpp:237] Iteration 362250, loss = 1.33495
I0526 16:08:14.082304 19470 solver.cpp:253]     Train net output #0: loss = 1.33495 (* 1 = 1.33495 loss)
I0526 16:08:14.082317 19470 sgd_solver.cpp:106] Iteration 362250, lr = 0.0025
I0526 16:08:26.236510 19470 solver.cpp:237] Iteration 363000, loss = 1.14307
I0526 16:08:26.236675 19470 solver.cpp:253]     Train net output #0: loss = 1.14307 (* 1 = 1.14307 loss)
I0526 16:08:26.236690 19470 sgd_solver.cpp:106] Iteration 363000, lr = 0.0025
I0526 16:08:38.396482 19470 solver.cpp:237] Iteration 363750, loss = 1.51118
I0526 16:08:38.396518 19470 solver.cpp:253]     Train net output #0: loss = 1.51118 (* 1 = 1.51118 loss)
I0526 16:08:38.396533 19470 sgd_solver.cpp:106] Iteration 363750, lr = 0.0025
I0526 16:08:50.581341 19470 solver.cpp:237] Iteration 364500, loss = 1.34803
I0526 16:08:50.581384 19470 solver.cpp:253]     Train net output #0: loss = 1.34802 (* 1 = 1.34802 loss)
I0526 16:08:50.581399 19470 sgd_solver.cpp:106] Iteration 364500, lr = 0.0025
I0526 16:09:23.645006 19470 solver.cpp:237] Iteration 365250, loss = 1.13639
I0526 16:09:23.645174 19470 solver.cpp:253]     Train net output #0: loss = 1.13639 (* 1 = 1.13639 loss)
I0526 16:09:23.645189 19470 sgd_solver.cpp:106] Iteration 365250, lr = 0.0025
I0526 16:09:35.815976 19470 solver.cpp:237] Iteration 366000, loss = 0.957945
I0526 16:09:35.816023 19470 solver.cpp:253]     Train net output #0: loss = 0.957944 (* 1 = 0.957944 loss)
I0526 16:09:35.816040 19470 sgd_solver.cpp:106] Iteration 366000, lr = 0.0025
I0526 16:09:48.025580 19470 solver.cpp:237] Iteration 366750, loss = 1.54737
I0526 16:09:48.025617 19470 solver.cpp:253]     Train net output #0: loss = 1.54737 (* 1 = 1.54737 loss)
I0526 16:09:48.025630 19470 sgd_solver.cpp:106] Iteration 366750, lr = 0.0025
I0526 16:10:00.165231 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_367500.caffemodel
I0526 16:10:01.107885 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_367500.solverstate
I0526 16:10:01.139796 19470 solver.cpp:237] Iteration 367500, loss = 0.98728
I0526 16:10:01.139843 19470 solver.cpp:253]     Train net output #0: loss = 0.987279 (* 1 = 0.987279 loss)
I0526 16:10:01.139859 19470 sgd_solver.cpp:106] Iteration 367500, lr = 0.0025
I0526 16:10:13.289513 19470 solver.cpp:237] Iteration 368250, loss = 1.38574
I0526 16:10:13.289549 19470 solver.cpp:253]     Train net output #0: loss = 1.38574 (* 1 = 1.38574 loss)
I0526 16:10:13.289564 19470 sgd_solver.cpp:106] Iteration 368250, lr = 0.0025
I0526 16:10:25.440196 19470 solver.cpp:237] Iteration 369000, loss = 1.03769
I0526 16:10:25.440240 19470 solver.cpp:253]     Train net output #0: loss = 1.03769 (* 1 = 1.03769 loss)
I0526 16:10:25.440255 19470 sgd_solver.cpp:106] Iteration 369000, lr = 0.0025
I0526 16:10:37.585283 19470 solver.cpp:237] Iteration 369750, loss = 1.09544
I0526 16:10:37.585435 19470 solver.cpp:253]     Train net output #0: loss = 1.09544 (* 1 = 1.09544 loss)
I0526 16:10:37.585448 19470 sgd_solver.cpp:106] Iteration 369750, lr = 0.0025
I0526 16:11:10.644246 19470 solver.cpp:237] Iteration 370500, loss = 1.03518
I0526 16:11:10.644418 19470 solver.cpp:253]     Train net output #0: loss = 1.03517 (* 1 = 1.03517 loss)
I0526 16:11:10.644431 19470 sgd_solver.cpp:106] Iteration 370500, lr = 0.0025
I0526 16:11:22.843530 19470 solver.cpp:237] Iteration 371250, loss = 1.01316
I0526 16:11:22.843577 19470 solver.cpp:253]     Train net output #0: loss = 1.01316 (* 1 = 1.01316 loss)
I0526 16:11:22.843591 19470 sgd_solver.cpp:106] Iteration 371250, lr = 0.0025
I0526 16:11:35.010439 19470 solver.cpp:237] Iteration 372000, loss = 0.631124
I0526 16:11:35.010476 19470 solver.cpp:253]     Train net output #0: loss = 0.631122 (* 1 = 0.631122 loss)
I0526 16:11:35.010490 19470 sgd_solver.cpp:106] Iteration 372000, lr = 0.0025
I0526 16:11:47.184618 19470 solver.cpp:237] Iteration 372750, loss = 1.07827
I0526 16:11:47.184789 19470 solver.cpp:253]     Train net output #0: loss = 1.07827 (* 1 = 1.07827 loss)
I0526 16:11:47.184803 19470 sgd_solver.cpp:106] Iteration 372750, lr = 0.0025
I0526 16:11:59.338512 19470 solver.cpp:237] Iteration 373500, loss = 1.38379
I0526 16:11:59.338549 19470 solver.cpp:253]     Train net output #0: loss = 1.38378 (* 1 = 1.38378 loss)
I0526 16:11:59.338563 19470 sgd_solver.cpp:106] Iteration 373500, lr = 0.0025
I0526 16:12:11.476461 19470 solver.cpp:237] Iteration 374250, loss = 1.43244
I0526 16:12:11.476511 19470 solver.cpp:253]     Train net output #0: loss = 1.43244 (* 1 = 1.43244 loss)
I0526 16:12:11.476523 19470 sgd_solver.cpp:106] Iteration 374250, lr = 0.0025
I0526 16:12:23.595296 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_375000.caffemodel
I0526 16:12:23.674327 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_375000.solverstate
I0526 16:12:23.719061 19470 solver.cpp:341] Iteration 375000, Testing net (#0)
I0526 16:13:36.579916 19470 solver.cpp:409]     Test net output #0: accuracy = 0.903685
I0526 16:13:36.580083 19470 solver.cpp:409]     Test net output #1: loss = 0.299471 (* 1 = 0.299471 loss)
I0526 16:13:57.441488 19470 solver.cpp:237] Iteration 375000, loss = 1.33875
I0526 16:13:57.441539 19470 solver.cpp:253]     Train net output #0: loss = 1.33875 (* 1 = 1.33875 loss)
I0526 16:13:57.441553 19470 sgd_solver.cpp:106] Iteration 375000, lr = 0.0025
I0526 16:14:09.666813 19470 solver.cpp:237] Iteration 375750, loss = 1.07083
I0526 16:14:09.666962 19470 solver.cpp:253]     Train net output #0: loss = 1.07083 (* 1 = 1.07083 loss)
I0526 16:14:09.666976 19470 sgd_solver.cpp:106] Iteration 375750, lr = 0.0025
I0526 16:14:21.880638 19470 solver.cpp:237] Iteration 376500, loss = 1.11462
I0526 16:14:21.880673 19470 solver.cpp:253]     Train net output #0: loss = 1.11462 (* 1 = 1.11462 loss)
I0526 16:14:21.880689 19470 sgd_solver.cpp:106] Iteration 376500, lr = 0.0025
I0526 16:14:34.078857 19470 solver.cpp:237] Iteration 377250, loss = 1.40666
I0526 16:14:34.078893 19470 solver.cpp:253]     Train net output #0: loss = 1.40666 (* 1 = 1.40666 loss)
I0526 16:14:34.078908 19470 sgd_solver.cpp:106] Iteration 377250, lr = 0.0025
I0526 16:14:46.274281 19470 solver.cpp:237] Iteration 378000, loss = 1.08801
I0526 16:14:46.274444 19470 solver.cpp:253]     Train net output #0: loss = 1.088 (* 1 = 1.088 loss)
I0526 16:14:46.274458 19470 sgd_solver.cpp:106] Iteration 378000, lr = 0.0025
I0526 16:14:58.467695 19470 solver.cpp:237] Iteration 378750, loss = 1.0635
I0526 16:14:58.467730 19470 solver.cpp:253]     Train net output #0: loss = 1.0635 (* 1 = 1.0635 loss)
I0526 16:14:58.467746 19470 sgd_solver.cpp:106] Iteration 378750, lr = 0.0025
I0526 16:15:10.648517 19470 solver.cpp:237] Iteration 379500, loss = 0.882366
I0526 16:15:10.648566 19470 solver.cpp:253]     Train net output #0: loss = 0.882365 (* 1 = 0.882365 loss)
I0526 16:15:10.648578 19470 sgd_solver.cpp:106] Iteration 379500, lr = 0.0025
I0526 16:15:43.787988 19470 solver.cpp:237] Iteration 380250, loss = 1.32707
I0526 16:15:43.788157 19470 solver.cpp:253]     Train net output #0: loss = 1.32707 (* 1 = 1.32707 loss)
I0526 16:15:43.788174 19470 sgd_solver.cpp:106] Iteration 380250, lr = 0.0025
I0526 16:15:55.995910 19470 solver.cpp:237] Iteration 381000, loss = 1.04436
I0526 16:15:55.995957 19470 solver.cpp:253]     Train net output #0: loss = 1.04435 (* 1 = 1.04435 loss)
I0526 16:15:55.995972 19470 sgd_solver.cpp:106] Iteration 381000, lr = 0.0025
I0526 16:16:08.235451 19470 solver.cpp:237] Iteration 381750, loss = 1.48363
I0526 16:16:08.235487 19470 solver.cpp:253]     Train net output #0: loss = 1.48363 (* 1 = 1.48363 loss)
I0526 16:16:08.235502 19470 sgd_solver.cpp:106] Iteration 381750, lr = 0.0025
I0526 16:16:20.433567 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_382500.caffemodel
I0526 16:16:20.502336 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_382500.solverstate
I0526 16:16:20.563837 19470 solver.cpp:237] Iteration 382500, loss = 0.932678
I0526 16:16:20.563882 19470 solver.cpp:253]     Train net output #0: loss = 0.932677 (* 1 = 0.932677 loss)
I0526 16:16:20.563900 19470 sgd_solver.cpp:106] Iteration 382500, lr = 0.0025
I0526 16:16:32.764336 19470 solver.cpp:237] Iteration 383250, loss = 1.14736
I0526 16:16:32.764374 19470 solver.cpp:253]     Train net output #0: loss = 1.14735 (* 1 = 1.14735 loss)
I0526 16:16:32.764387 19470 sgd_solver.cpp:106] Iteration 383250, lr = 0.0025
I0526 16:16:44.968456 19470 solver.cpp:237] Iteration 384000, loss = 1.0125
I0526 16:16:44.968502 19470 solver.cpp:253]     Train net output #0: loss = 1.0125 (* 1 = 1.0125 loss)
I0526 16:16:44.968516 19470 sgd_solver.cpp:106] Iteration 384000, lr = 0.0025
I0526 16:16:57.191769 19470 solver.cpp:237] Iteration 384750, loss = 1.13058
I0526 16:16:57.191926 19470 solver.cpp:253]     Train net output #0: loss = 1.13058 (* 1 = 1.13058 loss)
I0526 16:16:57.191939 19470 sgd_solver.cpp:106] Iteration 384750, lr = 0.0025
I0526 16:17:30.845686 19470 solver.cpp:237] Iteration 385500, loss = 0.707993
I0526 16:17:30.845861 19470 solver.cpp:253]     Train net output #0: loss = 0.707991 (* 1 = 0.707991 loss)
I0526 16:17:30.845875 19470 sgd_solver.cpp:106] Iteration 385500, lr = 0.0025
I0526 16:17:43.048894 19470 solver.cpp:237] Iteration 386250, loss = 1.36332
I0526 16:17:43.048929 19470 solver.cpp:253]     Train net output #0: loss = 1.36332 (* 1 = 1.36332 loss)
I0526 16:17:43.048944 19470 sgd_solver.cpp:106] Iteration 386250, lr = 0.0025
I0526 16:17:55.253794 19470 solver.cpp:237] Iteration 387000, loss = 1.26102
I0526 16:17:55.253839 19470 solver.cpp:253]     Train net output #0: loss = 1.26102 (* 1 = 1.26102 loss)
I0526 16:17:55.253855 19470 sgd_solver.cpp:106] Iteration 387000, lr = 0.0025
I0526 16:18:07.470194 19470 solver.cpp:237] Iteration 387750, loss = 0.960732
I0526 16:18:07.470343 19470 solver.cpp:253]     Train net output #0: loss = 0.960731 (* 1 = 0.960731 loss)
I0526 16:18:07.470357 19470 sgd_solver.cpp:106] Iteration 387750, lr = 0.0025
I0526 16:18:19.662714 19470 solver.cpp:237] Iteration 388500, loss = 0.693733
I0526 16:18:19.662765 19470 solver.cpp:253]     Train net output #0: loss = 0.693731 (* 1 = 0.693731 loss)
I0526 16:18:19.662778 19470 sgd_solver.cpp:106] Iteration 388500, lr = 0.0025
I0526 16:18:31.854338 19470 solver.cpp:237] Iteration 389250, loss = 1.11653
I0526 16:18:31.854374 19470 solver.cpp:253]     Train net output #0: loss = 1.11653 (* 1 = 1.11653 loss)
I0526 16:18:31.854387 19470 sgd_solver.cpp:106] Iteration 389250, lr = 0.0025
I0526 16:18:44.035970 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_390000.caffemodel
I0526 16:18:44.146780 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_390000.solverstate
I0526 16:18:44.195610 19470 solver.cpp:341] Iteration 390000, Testing net (#0)
I0526 16:19:35.806506 19470 solver.cpp:409]     Test net output #0: accuracy = 0.902946
I0526 16:19:35.806673 19470 solver.cpp:409]     Test net output #1: loss = 0.312471 (* 1 = 0.312471 loss)
I0526 16:20:00.435478 19470 solver.cpp:237] Iteration 390000, loss = 0.9661
I0526 16:20:00.435530 19470 solver.cpp:253]     Train net output #0: loss = 0.966098 (* 1 = 0.966098 loss)
I0526 16:20:00.435550 19470 sgd_solver.cpp:106] Iteration 390000, lr = 0.0025
I0526 16:20:12.584925 19470 solver.cpp:237] Iteration 390750, loss = 0.899238
I0526 16:20:12.585091 19470 solver.cpp:253]     Train net output #0: loss = 0.899237 (* 1 = 0.899237 loss)
I0526 16:20:12.585105 19470 sgd_solver.cpp:106] Iteration 390750, lr = 0.0025
I0526 16:20:24.727197 19470 solver.cpp:237] Iteration 391500, loss = 0.669025
I0526 16:20:24.727244 19470 solver.cpp:253]     Train net output #0: loss = 0.669023 (* 1 = 0.669023 loss)
I0526 16:20:24.727257 19470 sgd_solver.cpp:106] Iteration 391500, lr = 0.0025
I0526 16:20:36.838238 19470 solver.cpp:237] Iteration 392250, loss = 1.34157
I0526 16:20:36.838275 19470 solver.cpp:253]     Train net output #0: loss = 1.34157 (* 1 = 1.34157 loss)
I0526 16:20:36.838289 19470 sgd_solver.cpp:106] Iteration 392250, lr = 0.0025
I0526 16:20:48.950759 19470 solver.cpp:237] Iteration 393000, loss = 1.00415
I0526 16:20:48.950911 19470 solver.cpp:253]     Train net output #0: loss = 1.00415 (* 1 = 1.00415 loss)
I0526 16:20:48.950924 19470 sgd_solver.cpp:106] Iteration 393000, lr = 0.0025
I0526 16:21:01.058989 19470 solver.cpp:237] Iteration 393750, loss = 0.76364
I0526 16:21:01.059031 19470 solver.cpp:253]     Train net output #0: loss = 0.763639 (* 1 = 0.763639 loss)
I0526 16:21:01.059046 19470 sgd_solver.cpp:106] Iteration 393750, lr = 0.0025
I0526 16:21:13.127681 19470 solver.cpp:237] Iteration 394500, loss = 1.26605
I0526 16:21:13.127717 19470 solver.cpp:253]     Train net output #0: loss = 1.26605 (* 1 = 1.26605 loss)
I0526 16:21:13.127730 19470 sgd_solver.cpp:106] Iteration 394500, lr = 0.0025
I0526 16:21:46.202874 19470 solver.cpp:237] Iteration 395250, loss = 1.11672
I0526 16:21:46.203045 19470 solver.cpp:253]     Train net output #0: loss = 1.11672 (* 1 = 1.11672 loss)
I0526 16:21:46.203061 19470 sgd_solver.cpp:106] Iteration 395250, lr = 0.0025
I0526 16:21:58.382009 19470 solver.cpp:237] Iteration 396000, loss = 0.932723
I0526 16:21:58.382045 19470 solver.cpp:253]     Train net output #0: loss = 0.932722 (* 1 = 0.932722 loss)
I0526 16:21:58.382060 19470 sgd_solver.cpp:106] Iteration 396000, lr = 0.0025
I0526 16:22:10.538717 19470 solver.cpp:237] Iteration 396750, loss = 1.14912
I0526 16:22:10.538763 19470 solver.cpp:253]     Train net output #0: loss = 1.14912 (* 1 = 1.14912 loss)
I0526 16:22:10.538777 19470 sgd_solver.cpp:106] Iteration 396750, lr = 0.0025
I0526 16:22:22.694162 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_397500.caffemodel
I0526 16:22:22.803405 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_397500.solverstate
I0526 16:22:22.866916 19470 solver.cpp:237] Iteration 397500, loss = 0.990902
I0526 16:22:22.866966 19470 solver.cpp:253]     Train net output #0: loss = 0.990901 (* 1 = 0.990901 loss)
I0526 16:22:22.866981 19470 sgd_solver.cpp:106] Iteration 397500, lr = 0.0025
I0526 16:22:34.994660 19470 solver.cpp:237] Iteration 398250, loss = 1.22667
I0526 16:22:34.994709 19470 solver.cpp:253]     Train net output #0: loss = 1.22667 (* 1 = 1.22667 loss)
I0526 16:22:34.994722 19470 sgd_solver.cpp:106] Iteration 398250, lr = 0.0025
I0526 16:22:47.144747 19470 solver.cpp:237] Iteration 399000, loss = 0.979107
I0526 16:22:47.144783 19470 solver.cpp:253]     Train net output #0: loss = 0.979105 (* 1 = 0.979105 loss)
I0526 16:22:47.144799 19470 sgd_solver.cpp:106] Iteration 399000, lr = 0.0025
I0526 16:22:59.275301 19470 solver.cpp:237] Iteration 399750, loss = 1.22992
I0526 16:22:59.275473 19470 solver.cpp:253]     Train net output #0: loss = 1.22992 (* 1 = 1.22992 loss)
I0526 16:22:59.275490 19470 sgd_solver.cpp:106] Iteration 399750, lr = 0.0025
I0526 16:23:32.356295 19470 solver.cpp:237] Iteration 400500, loss = 0.865588
I0526 16:23:32.356464 19470 solver.cpp:253]     Train net output #0: loss = 0.865586 (* 1 = 0.865586 loss)
I0526 16:23:32.356479 19470 sgd_solver.cpp:106] Iteration 400500, lr = 0.0025
I0526 16:23:44.465977 19470 solver.cpp:237] Iteration 401250, loss = 0.881562
I0526 16:23:44.466015 19470 solver.cpp:253]     Train net output #0: loss = 0.88156 (* 1 = 0.88156 loss)
I0526 16:23:44.466028 19470 sgd_solver.cpp:106] Iteration 401250, lr = 0.0025
I0526 16:23:56.569005 19470 solver.cpp:237] Iteration 402000, loss = 1.56743
I0526 16:23:56.569046 19470 solver.cpp:253]     Train net output #0: loss = 1.56743 (* 1 = 1.56743 loss)
I0526 16:23:56.569062 19470 sgd_solver.cpp:106] Iteration 402000, lr = 0.0025
I0526 16:24:08.660172 19470 solver.cpp:237] Iteration 402750, loss = 1.04734
I0526 16:24:08.660333 19470 solver.cpp:253]     Train net output #0: loss = 1.04734 (* 1 = 1.04734 loss)
I0526 16:24:08.660348 19470 sgd_solver.cpp:106] Iteration 402750, lr = 0.0025
I0526 16:24:20.825374 19470 solver.cpp:237] Iteration 403500, loss = 1.18028
I0526 16:24:20.825418 19470 solver.cpp:253]     Train net output #0: loss = 1.18027 (* 1 = 1.18027 loss)
I0526 16:24:20.825431 19470 sgd_solver.cpp:106] Iteration 403500, lr = 0.0025
I0526 16:24:32.991928 19470 solver.cpp:237] Iteration 404250, loss = 1.05115
I0526 16:24:32.991964 19470 solver.cpp:253]     Train net output #0: loss = 1.05115 (* 1 = 1.05115 loss)
I0526 16:24:32.991978 19470 sgd_solver.cpp:106] Iteration 404250, lr = 0.0025
I0526 16:24:45.142278 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_405000.caffemodel
I0526 16:24:45.780668 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_405000.solverstate
I0526 16:24:46.523885 19470 solver.cpp:341] Iteration 405000, Testing net (#0)
I0526 16:25:59.790297 19470 solver.cpp:409]     Test net output #0: accuracy = 0.904972
I0526 16:25:59.790465 19470 solver.cpp:409]     Test net output #1: loss = 0.304493 (* 1 = 0.304493 loss)
I0526 16:26:20.666337 19470 solver.cpp:237] Iteration 405000, loss = 0.949798
I0526 16:26:20.666388 19470 solver.cpp:253]     Train net output #0: loss = 0.949795 (* 1 = 0.949795 loss)
I0526 16:26:20.666404 19470 sgd_solver.cpp:106] Iteration 405000, lr = 0.0025
I0526 16:26:32.823187 19470 solver.cpp:237] Iteration 405750, loss = 0.606645
I0526 16:26:32.823349 19470 solver.cpp:253]     Train net output #0: loss = 0.606643 (* 1 = 0.606643 loss)
I0526 16:26:32.823365 19470 sgd_solver.cpp:106] Iteration 405750, lr = 0.0025
I0526 16:26:44.973203 19470 solver.cpp:237] Iteration 406500, loss = 1.32992
I0526 16:26:44.973248 19470 solver.cpp:253]     Train net output #0: loss = 1.32992 (* 1 = 1.32992 loss)
I0526 16:26:44.973261 19470 sgd_solver.cpp:106] Iteration 406500, lr = 0.0025
I0526 16:26:57.128353 19470 solver.cpp:237] Iteration 407250, loss = 1.23108
I0526 16:26:57.128389 19470 solver.cpp:253]     Train net output #0: loss = 1.23107 (* 1 = 1.23107 loss)
I0526 16:26:57.128402 19470 sgd_solver.cpp:106] Iteration 407250, lr = 0.0025
I0526 16:27:09.253016 19470 solver.cpp:237] Iteration 408000, loss = 0.926374
I0526 16:27:09.253176 19470 solver.cpp:253]     Train net output #0: loss = 0.926372 (* 1 = 0.926372 loss)
I0526 16:27:09.253191 19470 sgd_solver.cpp:106] Iteration 408000, lr = 0.0025
I0526 16:27:21.299579 19470 solver.cpp:237] Iteration 408750, loss = 1.18815
I0526 16:27:21.299614 19470 solver.cpp:253]     Train net output #0: loss = 1.18815 (* 1 = 1.18815 loss)
I0526 16:27:21.299628 19470 sgd_solver.cpp:106] Iteration 408750, lr = 0.0025
I0526 16:27:33.378547 19470 solver.cpp:237] Iteration 409500, loss = 1.08185
I0526 16:27:33.378593 19470 solver.cpp:253]     Train net output #0: loss = 1.08185 (* 1 = 1.08185 loss)
I0526 16:27:33.378607 19470 sgd_solver.cpp:106] Iteration 409500, lr = 0.0025
I0526 16:28:06.373004 19470 solver.cpp:237] Iteration 410250, loss = 1.14528
I0526 16:28:06.373179 19470 solver.cpp:253]     Train net output #0: loss = 1.14528 (* 1 = 1.14528 loss)
I0526 16:28:06.373193 19470 sgd_solver.cpp:106] Iteration 410250, lr = 0.0025
I0526 16:28:18.538182 19470 solver.cpp:237] Iteration 411000, loss = 1.06734
I0526 16:28:18.538218 19470 solver.cpp:253]     Train net output #0: loss = 1.06734 (* 1 = 1.06734 loss)
I0526 16:28:18.538235 19470 sgd_solver.cpp:106] Iteration 411000, lr = 0.0025
I0526 16:28:30.736161 19470 solver.cpp:237] Iteration 411750, loss = 1.51093
I0526 16:28:30.736212 19470 solver.cpp:253]     Train net output #0: loss = 1.51093 (* 1 = 1.51093 loss)
I0526 16:28:30.736224 19470 sgd_solver.cpp:106] Iteration 411750, lr = 0.0025
I0526 16:28:42.940083 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_412500.caffemodel
I0526 16:28:42.989573 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_412500.solverstate
I0526 16:28:43.020211 19470 solver.cpp:237] Iteration 412500, loss = 0.854225
I0526 16:28:43.020252 19470 solver.cpp:253]     Train net output #0: loss = 0.854223 (* 1 = 0.854223 loss)
I0526 16:28:43.020269 19470 sgd_solver.cpp:106] Iteration 412500, lr = 0.0025
I0526 16:28:55.233103 19470 solver.cpp:237] Iteration 413250, loss = 0.534837
I0526 16:28:55.233150 19470 solver.cpp:253]     Train net output #0: loss = 0.534835 (* 1 = 0.534835 loss)
I0526 16:28:55.233165 19470 sgd_solver.cpp:106] Iteration 413250, lr = 0.0025
I0526 16:29:07.418097 19470 solver.cpp:237] Iteration 414000, loss = 1.2536
I0526 16:29:07.418134 19470 solver.cpp:253]     Train net output #0: loss = 1.2536 (* 1 = 1.2536 loss)
I0526 16:29:07.418150 19470 sgd_solver.cpp:106] Iteration 414000, lr = 0.0025
I0526 16:29:19.627724 19470 solver.cpp:237] Iteration 414750, loss = 0.930288
I0526 16:29:19.627894 19470 solver.cpp:253]     Train net output #0: loss = 0.930286 (* 1 = 0.930286 loss)
I0526 16:29:19.627908 19470 sgd_solver.cpp:106] Iteration 414750, lr = 0.0025
I0526 16:29:52.662840 19470 solver.cpp:237] Iteration 415500, loss = 1.25253
I0526 16:29:52.663012 19470 solver.cpp:253]     Train net output #0: loss = 1.25252 (* 1 = 1.25252 loss)
I0526 16:29:52.663028 19470 sgd_solver.cpp:106] Iteration 415500, lr = 0.0025
I0526 16:30:04.874533 19470 solver.cpp:237] Iteration 416250, loss = 1.01022
I0526 16:30:04.874580 19470 solver.cpp:253]     Train net output #0: loss = 1.01022 (* 1 = 1.01022 loss)
I0526 16:30:04.874595 19470 sgd_solver.cpp:106] Iteration 416250, lr = 0.0025
I0526 16:30:17.065629 19470 solver.cpp:237] Iteration 417000, loss = 1.52945
I0526 16:30:17.065665 19470 solver.cpp:253]     Train net output #0: loss = 1.52945 (* 1 = 1.52945 loss)
I0526 16:30:17.065681 19470 sgd_solver.cpp:106] Iteration 417000, lr = 0.0025
I0526 16:30:29.251955 19470 solver.cpp:237] Iteration 417750, loss = 1.19308
I0526 16:30:29.252121 19470 solver.cpp:253]     Train net output #0: loss = 1.19308 (* 1 = 1.19308 loss)
I0526 16:30:29.252136 19470 sgd_solver.cpp:106] Iteration 417750, lr = 0.0025
I0526 16:30:41.406692 19470 solver.cpp:237] Iteration 418500, loss = 1.17112
I0526 16:30:41.406728 19470 solver.cpp:253]     Train net output #0: loss = 1.17112 (* 1 = 1.17112 loss)
I0526 16:30:41.406744 19470 sgd_solver.cpp:106] Iteration 418500, lr = 0.0025
I0526 16:30:53.630331 19470 solver.cpp:237] Iteration 419250, loss = 1.48274
I0526 16:30:53.630378 19470 solver.cpp:253]     Train net output #0: loss = 1.48273 (* 1 = 1.48273 loss)
I0526 16:30:53.630394 19470 sgd_solver.cpp:106] Iteration 419250, lr = 0.0025
I0526 16:31:05.821552 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_420000.caffemodel
I0526 16:31:05.871529 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_420000.solverstate
I0526 16:31:05.897300 19470 solver.cpp:341] Iteration 420000, Testing net (#0)
I0526 16:31:57.827365 19470 solver.cpp:409]     Test net output #0: accuracy = 0.903146
I0526 16:31:57.827548 19470 solver.cpp:409]     Test net output #1: loss = 0.305682 (* 1 = 0.305682 loss)
I0526 16:32:18.679708 19470 solver.cpp:237] Iteration 420000, loss = 1.41031
I0526 16:32:18.679761 19470 solver.cpp:253]     Train net output #0: loss = 1.41031 (* 1 = 1.41031 loss)
I0526 16:32:18.679780 19470 sgd_solver.cpp:106] Iteration 420000, lr = 0.0025
I0526 16:32:30.921299 19470 solver.cpp:237] Iteration 420750, loss = 0.500439
I0526 16:32:30.921470 19470 solver.cpp:253]     Train net output #0: loss = 0.500437 (* 1 = 0.500437 loss)
I0526 16:32:30.921484 19470 sgd_solver.cpp:106] Iteration 420750, lr = 0.0025
I0526 16:32:43.130234 19470 solver.cpp:237] Iteration 421500, loss = 0.999631
I0526 16:32:43.130271 19470 solver.cpp:253]     Train net output #0: loss = 0.999629 (* 1 = 0.999629 loss)
I0526 16:32:43.130285 19470 sgd_solver.cpp:106] Iteration 421500, lr = 0.0025
I0526 16:32:55.346830 19470 solver.cpp:237] Iteration 422250, loss = 0.884358
I0526 16:32:55.346868 19470 solver.cpp:253]     Train net output #0: loss = 0.884356 (* 1 = 0.884356 loss)
I0526 16:32:55.346880 19470 sgd_solver.cpp:106] Iteration 422250, lr = 0.0025
I0526 16:33:07.586051 19470 solver.cpp:237] Iteration 423000, loss = 1.07243
I0526 16:33:07.586205 19470 solver.cpp:253]     Train net output #0: loss = 1.07243 (* 1 = 1.07243 loss)
I0526 16:33:07.586220 19470 sgd_solver.cpp:106] Iteration 423000, lr = 0.0025
I0526 16:33:19.806433 19470 solver.cpp:237] Iteration 423750, loss = 0.794308
I0526 16:33:19.806479 19470 solver.cpp:253]     Train net output #0: loss = 0.794306 (* 1 = 0.794306 loss)
I0526 16:33:19.806493 19470 sgd_solver.cpp:106] Iteration 423750, lr = 0.0025
I0526 16:33:31.956091 19470 solver.cpp:237] Iteration 424500, loss = 1.15646
I0526 16:33:31.956127 19470 solver.cpp:253]     Train net output #0: loss = 1.15646 (* 1 = 1.15646 loss)
I0526 16:33:31.956140 19470 sgd_solver.cpp:106] Iteration 424500, lr = 0.0025
I0526 16:34:04.975942 19470 solver.cpp:237] Iteration 425250, loss = 1.07297
I0526 16:34:04.976119 19470 solver.cpp:253]     Train net output #0: loss = 1.07296 (* 1 = 1.07296 loss)
I0526 16:34:04.976133 19470 sgd_solver.cpp:106] Iteration 425250, lr = 0.0025
I0526 16:34:17.126612 19470 solver.cpp:237] Iteration 426000, loss = 1.41202
I0526 16:34:17.126657 19470 solver.cpp:253]     Train net output #0: loss = 1.41202 (* 1 = 1.41202 loss)
I0526 16:34:17.126673 19470 sgd_solver.cpp:106] Iteration 426000, lr = 0.0025
I0526 16:34:29.282603 19470 solver.cpp:237] Iteration 426750, loss = 0.589743
I0526 16:34:29.282639 19470 solver.cpp:253]     Train net output #0: loss = 0.589742 (* 1 = 0.589742 loss)
I0526 16:34:29.282654 19470 sgd_solver.cpp:106] Iteration 426750, lr = 0.0025
I0526 16:34:41.420078 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_427500.caffemodel
I0526 16:34:41.473284 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_427500.solverstate
I0526 16:34:41.506050 19470 solver.cpp:237] Iteration 427500, loss = 1.77431
I0526 16:34:41.506098 19470 solver.cpp:253]     Train net output #0: loss = 1.7743 (* 1 = 1.7743 loss)
I0526 16:34:41.506114 19470 sgd_solver.cpp:106] Iteration 427500, lr = 0.0025
I0526 16:34:53.661697 19470 solver.cpp:237] Iteration 428250, loss = 0.890657
I0526 16:34:53.661736 19470 solver.cpp:253]     Train net output #0: loss = 0.890656 (* 1 = 0.890656 loss)
I0526 16:34:53.661749 19470 sgd_solver.cpp:106] Iteration 428250, lr = 0.0025
I0526 16:35:05.812719 19470 solver.cpp:237] Iteration 429000, loss = 2.2915
I0526 16:35:05.812769 19470 solver.cpp:253]     Train net output #0: loss = 2.2915 (* 1 = 2.2915 loss)
I0526 16:35:05.812785 19470 sgd_solver.cpp:106] Iteration 429000, lr = 0.0025
I0526 16:35:17.987596 19470 solver.cpp:237] Iteration 429750, loss = 1.16902
I0526 16:35:17.987767 19470 solver.cpp:253]     Train net output #0: loss = 1.16901 (* 1 = 1.16901 loss)
I0526 16:35:17.987782 19470 sgd_solver.cpp:106] Iteration 429750, lr = 0.0025
I0526 16:35:51.089911 19470 solver.cpp:237] Iteration 430500, loss = 0.911218
I0526 16:35:51.090088 19470 solver.cpp:253]     Train net output #0: loss = 0.911217 (* 1 = 0.911217 loss)
I0526 16:35:51.090102 19470 sgd_solver.cpp:106] Iteration 430500, lr = 0.0025
I0526 16:36:03.302748 19470 solver.cpp:237] Iteration 431250, loss = 1.39566
I0526 16:36:03.302783 19470 solver.cpp:253]     Train net output #0: loss = 1.39566 (* 1 = 1.39566 loss)
I0526 16:36:03.302798 19470 sgd_solver.cpp:106] Iteration 431250, lr = 0.0025
I0526 16:36:15.499246 19470 solver.cpp:237] Iteration 432000, loss = 1.46921
I0526 16:36:15.499284 19470 solver.cpp:253]     Train net output #0: loss = 1.46921 (* 1 = 1.46921 loss)
I0526 16:36:15.499302 19470 sgd_solver.cpp:106] Iteration 432000, lr = 0.0025
I0526 16:36:27.713467 19470 solver.cpp:237] Iteration 432750, loss = 1.05883
I0526 16:36:27.713620 19470 solver.cpp:253]     Train net output #0: loss = 1.05883 (* 1 = 1.05883 loss)
I0526 16:36:27.713634 19470 sgd_solver.cpp:106] Iteration 432750, lr = 0.0025
I0526 16:36:39.931517 19470 solver.cpp:237] Iteration 433500, loss = 0.783145
I0526 16:36:39.931567 19470 solver.cpp:253]     Train net output #0: loss = 0.783144 (* 1 = 0.783144 loss)
I0526 16:36:39.931581 19470 sgd_solver.cpp:106] Iteration 433500, lr = 0.0025
I0526 16:36:52.126485 19470 solver.cpp:237] Iteration 434250, loss = 1.11363
I0526 16:36:52.126521 19470 solver.cpp:253]     Train net output #0: loss = 1.11363 (* 1 = 1.11363 loss)
I0526 16:36:52.126538 19470 sgd_solver.cpp:106] Iteration 434250, lr = 0.0025
I0526 16:37:04.261472 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_435000.caffemodel
I0526 16:37:04.313588 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_435000.solverstate
I0526 16:37:04.341364 19470 solver.cpp:341] Iteration 435000, Testing net (#0)
I0526 16:38:17.093981 19470 solver.cpp:409]     Test net output #0: accuracy = 0.905759
I0526 16:38:17.094168 19470 solver.cpp:409]     Test net output #1: loss = 0.293403 (* 1 = 0.293403 loss)
I0526 16:38:37.932744 19470 solver.cpp:237] Iteration 435000, loss = 1.09653
I0526 16:38:37.932796 19470 solver.cpp:253]     Train net output #0: loss = 1.09652 (* 1 = 1.09652 loss)
I0526 16:38:37.932813 19470 sgd_solver.cpp:106] Iteration 435000, lr = 0.0025
I0526 16:38:50.149631 19470 solver.cpp:237] Iteration 435750, loss = 1.02709
I0526 16:38:50.149801 19470 solver.cpp:253]     Train net output #0: loss = 1.02709 (* 1 = 1.02709 loss)
I0526 16:38:50.149816 19470 sgd_solver.cpp:106] Iteration 435750, lr = 0.0025
I0526 16:39:02.355803 19470 solver.cpp:237] Iteration 436500, loss = 0.905742
I0526 16:39:02.355839 19470 solver.cpp:253]     Train net output #0: loss = 0.905741 (* 1 = 0.905741 loss)
I0526 16:39:02.355852 19470 sgd_solver.cpp:106] Iteration 436500, lr = 0.0025
I0526 16:39:14.564818 19470 solver.cpp:237] Iteration 437250, loss = 1.49053
I0526 16:39:14.564877 19470 solver.cpp:253]     Train net output #0: loss = 1.49053 (* 1 = 1.49053 loss)
I0526 16:39:14.564891 19470 sgd_solver.cpp:106] Iteration 437250, lr = 0.0025
I0526 16:39:26.783831 19470 solver.cpp:237] Iteration 438000, loss = 1.01432
I0526 16:39:26.783988 19470 solver.cpp:253]     Train net output #0: loss = 1.01432 (* 1 = 1.01432 loss)
I0526 16:39:26.784003 19470 sgd_solver.cpp:106] Iteration 438000, lr = 0.0025
I0526 16:39:38.975885 19470 solver.cpp:237] Iteration 438750, loss = 1.11422
I0526 16:39:38.975935 19470 solver.cpp:253]     Train net output #0: loss = 1.11422 (* 1 = 1.11422 loss)
I0526 16:39:38.975950 19470 sgd_solver.cpp:106] Iteration 438750, lr = 0.0025
I0526 16:39:51.189281 19470 solver.cpp:237] Iteration 439500, loss = 1.01139
I0526 16:39:51.189317 19470 solver.cpp:253]     Train net output #0: loss = 1.01139 (* 1 = 1.01139 loss)
I0526 16:39:51.189330 19470 sgd_solver.cpp:106] Iteration 439500, lr = 0.0025
I0526 16:40:24.261559 19470 solver.cpp:237] Iteration 440250, loss = 1.14288
I0526 16:40:24.261744 19470 solver.cpp:253]     Train net output #0: loss = 1.14287 (* 1 = 1.14287 loss)
I0526 16:40:24.261759 19470 sgd_solver.cpp:106] Iteration 440250, lr = 0.0025
I0526 16:40:36.472297 19470 solver.cpp:237] Iteration 441000, loss = 0.989506
I0526 16:40:36.472347 19470 solver.cpp:253]     Train net output #0: loss = 0.989505 (* 1 = 0.989505 loss)
I0526 16:40:36.472360 19470 sgd_solver.cpp:106] Iteration 441000, lr = 0.0025
I0526 16:40:48.665763 19470 solver.cpp:237] Iteration 441750, loss = 2.3571
I0526 16:40:48.665801 19470 solver.cpp:253]     Train net output #0: loss = 2.3571 (* 1 = 2.3571 loss)
I0526 16:40:48.665813 19470 sgd_solver.cpp:106] Iteration 441750, lr = 0.0025
I0526 16:41:00.805236 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_442500.caffemodel
I0526 16:41:00.855207 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_442500.solverstate
I0526 16:41:00.885980 19470 solver.cpp:237] Iteration 442500, loss = 0.915788
I0526 16:41:00.886028 19470 solver.cpp:253]     Train net output #0: loss = 0.915787 (* 1 = 0.915787 loss)
I0526 16:41:00.886044 19470 sgd_solver.cpp:106] Iteration 442500, lr = 0.0025
I0526 16:41:13.041556 19470 solver.cpp:237] Iteration 443250, loss = 1.04838
I0526 16:41:13.041594 19470 solver.cpp:253]     Train net output #0: loss = 1.04837 (* 1 = 1.04837 loss)
I0526 16:41:13.041610 19470 sgd_solver.cpp:106] Iteration 443250, lr = 0.0025
I0526 16:41:25.225739 19470 solver.cpp:237] Iteration 444000, loss = 0.887404
I0526 16:41:25.225790 19470 solver.cpp:253]     Train net output #0: loss = 0.887403 (* 1 = 0.887403 loss)
I0526 16:41:25.225805 19470 sgd_solver.cpp:106] Iteration 444000, lr = 0.0025
I0526 16:41:37.418934 19470 solver.cpp:237] Iteration 444750, loss = 0.881546
I0526 16:41:37.419097 19470 solver.cpp:253]     Train net output #0: loss = 0.881544 (* 1 = 0.881544 loss)
I0526 16:41:37.419112 19470 sgd_solver.cpp:106] Iteration 444750, lr = 0.0025
I0526 16:42:10.562661 19470 solver.cpp:237] Iteration 445500, loss = 1.18864
I0526 16:42:10.562836 19470 solver.cpp:253]     Train net output #0: loss = 1.18864 (* 1 = 1.18864 loss)
I0526 16:42:10.562851 19470 sgd_solver.cpp:106] Iteration 445500, lr = 0.0025
I0526 16:42:22.789270 19470 solver.cpp:237] Iteration 446250, loss = 1.20698
I0526 16:42:22.789305 19470 solver.cpp:253]     Train net output #0: loss = 1.20698 (* 1 = 1.20698 loss)
I0526 16:42:22.789319 19470 sgd_solver.cpp:106] Iteration 446250, lr = 0.0025
I0526 16:42:34.987337 19470 solver.cpp:237] Iteration 447000, loss = 1.07816
I0526 16:42:34.987375 19470 solver.cpp:253]     Train net output #0: loss = 1.07816 (* 1 = 1.07816 loss)
I0526 16:42:34.987388 19470 sgd_solver.cpp:106] Iteration 447000, lr = 0.0025
I0526 16:42:47.186368 19470 solver.cpp:237] Iteration 447750, loss = 0.963677
I0526 16:42:47.186534 19470 solver.cpp:253]     Train net output #0: loss = 0.963675 (* 1 = 0.963675 loss)
I0526 16:42:47.186548 19470 sgd_solver.cpp:106] Iteration 447750, lr = 0.0025
I0526 16:42:59.384769 19470 solver.cpp:237] Iteration 448500, loss = 1.06582
I0526 16:42:59.384814 19470 solver.cpp:253]     Train net output #0: loss = 1.06581 (* 1 = 1.06581 loss)
I0526 16:42:59.384827 19470 sgd_solver.cpp:106] Iteration 448500, lr = 0.0025
I0526 16:43:11.585216 19470 solver.cpp:237] Iteration 449250, loss = 1.09615
I0526 16:43:11.585252 19470 solver.cpp:253]     Train net output #0: loss = 1.09615 (* 1 = 1.09615 loss)
I0526 16:43:11.585264 19470 sgd_solver.cpp:106] Iteration 449250, lr = 0.0025
I0526 16:43:23.775741 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_450000.caffemodel
I0526 16:43:23.876013 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_450000.solverstate
I0526 16:43:23.909674 19470 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 16:44:15.574786 19470 solver.cpp:409]     Test net output #0: accuracy = 0.906345
I0526 16:44:15.574980 19470 solver.cpp:409]     Test net output #1: loss = 0.28985 (* 1 = 0.28985 loss)
I0526 16:44:36.404949 19470 solver.cpp:237] Iteration 450000, loss = 1.32115
I0526 16:44:36.405000 19470 solver.cpp:253]     Train net output #0: loss = 1.32115 (* 1 = 1.32115 loss)
I0526 16:44:36.405015 19470 sgd_solver.cpp:106] Iteration 450000, lr = 0.0025
I0526 16:44:48.477692 19470 solver.cpp:237] Iteration 450750, loss = 1.01946
I0526 16:44:48.477859 19470 solver.cpp:253]     Train net output #0: loss = 1.01946 (* 1 = 1.01946 loss)
I0526 16:44:48.477874 19470 sgd_solver.cpp:106] Iteration 450750, lr = 0.0025
I0526 16:45:00.578671 19470 solver.cpp:237] Iteration 451500, loss = 1.35928
I0526 16:45:00.578713 19470 solver.cpp:253]     Train net output #0: loss = 1.35928 (* 1 = 1.35928 loss)
I0526 16:45:00.578734 19470 sgd_solver.cpp:106] Iteration 451500, lr = 0.0025
I0526 16:45:12.743737 19470 solver.cpp:237] Iteration 452250, loss = 1.21129
I0526 16:45:12.743773 19470 solver.cpp:253]     Train net output #0: loss = 1.21129 (* 1 = 1.21129 loss)
I0526 16:45:12.743788 19470 sgd_solver.cpp:106] Iteration 452250, lr = 0.0025
I0526 16:45:24.896771 19470 solver.cpp:237] Iteration 453000, loss = 1.05576
I0526 16:45:24.896951 19470 solver.cpp:253]     Train net output #0: loss = 1.05576 (* 1 = 1.05576 loss)
I0526 16:45:24.896966 19470 sgd_solver.cpp:106] Iteration 453000, lr = 0.0025
I0526 16:45:37.122418 19470 solver.cpp:237] Iteration 453750, loss = 1.51539
I0526 16:45:37.122454 19470 solver.cpp:253]     Train net output #0: loss = 1.51539 (* 1 = 1.51539 loss)
I0526 16:45:37.122467 19470 sgd_solver.cpp:106] Iteration 453750, lr = 0.0025
I0526 16:45:49.322993 19470 solver.cpp:237] Iteration 454500, loss = 1.05427
I0526 16:45:49.323029 19470 solver.cpp:253]     Train net output #0: loss = 1.05426 (* 1 = 1.05426 loss)
I0526 16:45:49.323045 19470 sgd_solver.cpp:106] Iteration 454500, lr = 0.0025
I0526 16:46:22.456061 19470 solver.cpp:237] Iteration 455250, loss = 0.914318
I0526 16:46:22.456240 19470 solver.cpp:253]     Train net output #0: loss = 0.914317 (* 1 = 0.914317 loss)
I0526 16:46:22.456256 19470 sgd_solver.cpp:106] Iteration 455250, lr = 0.0025
I0526 16:46:34.663563 19470 solver.cpp:237] Iteration 456000, loss = 1.16773
I0526 16:46:34.663599 19470 solver.cpp:253]     Train net output #0: loss = 1.16773 (* 1 = 1.16773 loss)
I0526 16:46:34.663614 19470 sgd_solver.cpp:106] Iteration 456000, lr = 0.0025
I0526 16:46:46.862427 19470 solver.cpp:237] Iteration 456750, loss = 1.11549
I0526 16:46:46.862476 19470 solver.cpp:253]     Train net output #0: loss = 1.11549 (* 1 = 1.11549 loss)
I0526 16:46:46.862489 19470 sgd_solver.cpp:106] Iteration 456750, lr = 0.0025
I0526 16:46:59.014849 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_457500.caffemodel
I0526 16:46:59.087759 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_457500.solverstate
I0526 16:46:59.149512 19470 solver.cpp:237] Iteration 457500, loss = 1.1235
I0526 16:46:59.149559 19470 solver.cpp:253]     Train net output #0: loss = 1.1235 (* 1 = 1.1235 loss)
I0526 16:46:59.149572 19470 sgd_solver.cpp:106] Iteration 457500, lr = 0.0025
I0526 16:47:11.340242 19470 solver.cpp:237] Iteration 458250, loss = 1.08671
I0526 16:47:11.340292 19470 solver.cpp:253]     Train net output #0: loss = 1.08671 (* 1 = 1.08671 loss)
I0526 16:47:11.340306 19470 sgd_solver.cpp:106] Iteration 458250, lr = 0.0025
I0526 16:47:23.530597 19470 solver.cpp:237] Iteration 459000, loss = 1.13803
I0526 16:47:23.530634 19470 solver.cpp:253]     Train net output #0: loss = 1.13803 (* 1 = 1.13803 loss)
I0526 16:47:23.530650 19470 sgd_solver.cpp:106] Iteration 459000, lr = 0.0025
I0526 16:47:35.691390 19470 solver.cpp:237] Iteration 459750, loss = 1.3278
I0526 16:47:35.691577 19470 solver.cpp:253]     Train net output #0: loss = 1.3278 (* 1 = 1.3278 loss)
I0526 16:47:35.691593 19470 sgd_solver.cpp:106] Iteration 459750, lr = 0.0025
I0526 16:48:08.759883 19470 solver.cpp:237] Iteration 460500, loss = 0.812678
I0526 16:48:08.760066 19470 solver.cpp:253]     Train net output #0: loss = 0.812677 (* 1 = 0.812677 loss)
I0526 16:48:08.760082 19470 sgd_solver.cpp:106] Iteration 460500, lr = 0.0025
I0526 16:48:20.952980 19470 solver.cpp:237] Iteration 461250, loss = 1.20945
I0526 16:48:20.953021 19470 solver.cpp:253]     Train net output #0: loss = 1.20945 (* 1 = 1.20945 loss)
I0526 16:48:20.953033 19470 sgd_solver.cpp:106] Iteration 461250, lr = 0.0025
I0526 16:48:33.165935 19470 solver.cpp:237] Iteration 462000, loss = 1.22984
I0526 16:48:33.165971 19470 solver.cpp:253]     Train net output #0: loss = 1.22984 (* 1 = 1.22984 loss)
I0526 16:48:33.165983 19470 sgd_solver.cpp:106] Iteration 462000, lr = 0.0025
I0526 16:48:45.357436 19470 solver.cpp:237] Iteration 462750, loss = 1.11416
I0526 16:48:45.357610 19470 solver.cpp:253]     Train net output #0: loss = 1.11416 (* 1 = 1.11416 loss)
I0526 16:48:45.357625 19470 sgd_solver.cpp:106] Iteration 462750, lr = 0.0025
I0526 16:48:57.512567 19470 solver.cpp:237] Iteration 463500, loss = 1.06902
I0526 16:48:57.512603 19470 solver.cpp:253]     Train net output #0: loss = 1.06902 (* 1 = 1.06902 loss)
I0526 16:48:57.512617 19470 sgd_solver.cpp:106] Iteration 463500, lr = 0.0025
I0526 16:49:09.689621 19470 solver.cpp:237] Iteration 464250, loss = 1.14487
I0526 16:49:09.689666 19470 solver.cpp:253]     Train net output #0: loss = 1.14487 (* 1 = 1.14487 loss)
I0526 16:49:09.689680 19470 sgd_solver.cpp:106] Iteration 464250, lr = 0.0025
I0526 16:49:21.865087 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_465000.caffemodel
I0526 16:49:21.928463 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_465000.solverstate
I0526 16:49:21.955685 19470 solver.cpp:341] Iteration 465000, Testing net (#0)
I0526 16:50:34.793922 19470 solver.cpp:409]     Test net output #0: accuracy = 0.905586
I0526 16:50:34.794102 19470 solver.cpp:409]     Test net output #1: loss = 0.30135 (* 1 = 0.30135 loss)
I0526 16:50:55.689538 19470 solver.cpp:237] Iteration 465000, loss = 0.790376
I0526 16:50:55.689592 19470 solver.cpp:253]     Train net output #0: loss = 0.790374 (* 1 = 0.790374 loss)
I0526 16:50:55.689607 19470 sgd_solver.cpp:106] Iteration 465000, lr = 0.0025
I0526 16:51:07.888759 19470 solver.cpp:237] Iteration 465750, loss = 0.768994
I0526 16:51:07.888931 19470 solver.cpp:253]     Train net output #0: loss = 0.768992 (* 1 = 0.768992 loss)
I0526 16:51:07.888947 19470 sgd_solver.cpp:106] Iteration 465750, lr = 0.0025
I0526 16:51:20.078022 19470 solver.cpp:237] Iteration 466500, loss = 1.14875
I0526 16:51:20.078070 19470 solver.cpp:253]     Train net output #0: loss = 1.14874 (* 1 = 1.14874 loss)
I0526 16:51:20.078086 19470 sgd_solver.cpp:106] Iteration 466500, lr = 0.0025
I0526 16:51:32.244959 19470 solver.cpp:237] Iteration 467250, loss = 1.45492
I0526 16:51:32.244995 19470 solver.cpp:253]     Train net output #0: loss = 1.45492 (* 1 = 1.45492 loss)
I0526 16:51:32.245008 19470 sgd_solver.cpp:106] Iteration 467250, lr = 0.0025
I0526 16:51:44.384757 19470 solver.cpp:237] Iteration 468000, loss = 1.33742
I0526 16:51:44.384945 19470 solver.cpp:253]     Train net output #0: loss = 1.33741 (* 1 = 1.33741 loss)
I0526 16:51:44.384960 19470 sgd_solver.cpp:106] Iteration 468000, lr = 0.0025
I0526 16:51:56.506645 19470 solver.cpp:237] Iteration 468750, loss = 1.50538
I0526 16:51:56.506681 19470 solver.cpp:253]     Train net output #0: loss = 1.50538 (* 1 = 1.50538 loss)
I0526 16:51:56.506695 19470 sgd_solver.cpp:106] Iteration 468750, lr = 0.0025
I0526 16:52:21.194553 19470 solver.cpp:237] Iteration 469500, loss = 1.2013
I0526 16:52:21.194722 19470 solver.cpp:253]     Train net output #0: loss = 1.2013 (* 1 = 1.2013 loss)
I0526 16:52:21.194736 19470 sgd_solver.cpp:106] Iteration 469500, lr = 0.0025
I0526 16:52:54.261814 19470 solver.cpp:237] Iteration 470250, loss = 1.13494
I0526 16:52:54.261996 19470 solver.cpp:253]     Train net output #0: loss = 1.13493 (* 1 = 1.13493 loss)
I0526 16:52:54.262011 19470 sgd_solver.cpp:106] Iteration 470250, lr = 0.0025
I0526 16:53:06.448181 19470 solver.cpp:237] Iteration 471000, loss = 1.03676
I0526 16:53:06.448225 19470 solver.cpp:253]     Train net output #0: loss = 1.03676 (* 1 = 1.03676 loss)
I0526 16:53:06.448238 19470 sgd_solver.cpp:106] Iteration 471000, lr = 0.0025
I0526 16:53:18.555331 19470 solver.cpp:237] Iteration 471750, loss = 1.19154
I0526 16:53:18.555367 19470 solver.cpp:253]     Train net output #0: loss = 1.19154 (* 1 = 1.19154 loss)
I0526 16:53:18.555382 19470 sgd_solver.cpp:106] Iteration 471750, lr = 0.0025
I0526 16:53:30.686096 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_472500.caffemodel
I0526 16:53:30.738121 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_472500.solverstate
I0526 16:53:30.771589 19470 solver.cpp:237] Iteration 472500, loss = 1.36974
I0526 16:53:30.771637 19470 solver.cpp:253]     Train net output #0: loss = 1.36974 (* 1 = 1.36974 loss)
I0526 16:53:30.771651 19470 sgd_solver.cpp:106] Iteration 472500, lr = 0.0025
I0526 16:53:42.911221 19470 solver.cpp:237] Iteration 473250, loss = 1.01325
I0526 16:53:42.911257 19470 solver.cpp:253]     Train net output #0: loss = 1.01325 (* 1 = 1.01325 loss)
I0526 16:53:42.911274 19470 sgd_solver.cpp:106] Iteration 473250, lr = 0.0025
I0526 16:53:55.042326 19470 solver.cpp:237] Iteration 474000, loss = 1.1002
I0526 16:53:55.042372 19470 solver.cpp:253]     Train net output #0: loss = 1.1002 (* 1 = 1.1002 loss)
I0526 16:53:55.042387 19470 sgd_solver.cpp:106] Iteration 474000, lr = 0.0025
I0526 16:54:07.187249 19470 solver.cpp:237] Iteration 474750, loss = 1.41894
I0526 16:54:07.187415 19470 solver.cpp:253]     Train net output #0: loss = 1.41893 (* 1 = 1.41893 loss)
I0526 16:54:07.187429 19470 sgd_solver.cpp:106] Iteration 474750, lr = 0.0025
I0526 16:54:40.204450 19470 solver.cpp:237] Iteration 475500, loss = 0.793365
I0526 16:54:40.204633 19470 solver.cpp:253]     Train net output #0: loss = 0.793364 (* 1 = 0.793364 loss)
I0526 16:54:40.204649 19470 sgd_solver.cpp:106] Iteration 475500, lr = 0.0025
I0526 16:54:52.318374 19470 solver.cpp:237] Iteration 476250, loss = 1.26042
I0526 16:54:52.318410 19470 solver.cpp:253]     Train net output #0: loss = 1.26042 (* 1 = 1.26042 loss)
I0526 16:54:52.318426 19470 sgd_solver.cpp:106] Iteration 476250, lr = 0.0025
I0526 16:55:04.435775 19470 solver.cpp:237] Iteration 477000, loss = 1.37626
I0526 16:55:04.435820 19470 solver.cpp:253]     Train net output #0: loss = 1.37625 (* 1 = 1.37625 loss)
I0526 16:55:04.435833 19470 sgd_solver.cpp:106] Iteration 477000, lr = 0.0025
I0526 16:55:16.549360 19470 solver.cpp:237] Iteration 477750, loss = 1.03389
I0526 16:55:16.549520 19470 solver.cpp:253]     Train net output #0: loss = 1.03389 (* 1 = 1.03389 loss)
I0526 16:55:16.549535 19470 sgd_solver.cpp:106] Iteration 477750, lr = 0.0025
I0526 16:55:28.682549 19470 solver.cpp:237] Iteration 478500, loss = 1.32928
I0526 16:55:28.682600 19470 solver.cpp:253]     Train net output #0: loss = 1.32928 (* 1 = 1.32928 loss)
I0526 16:55:28.682615 19470 sgd_solver.cpp:106] Iteration 478500, lr = 0.0025
I0526 16:55:40.812808 19470 solver.cpp:237] Iteration 479250, loss = 1.20268
I0526 16:55:40.812844 19470 solver.cpp:253]     Train net output #0: loss = 1.20268 (* 1 = 1.20268 loss)
I0526 16:55:40.812858 19470 sgd_solver.cpp:106] Iteration 479250, lr = 0.0025
I0526 16:55:52.927218 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_480000.caffemodel
I0526 16:55:52.977960 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_480000.solverstate
I0526 16:55:53.058363 19470 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 16:56:45.030285 19470 solver.cpp:409]     Test net output #0: accuracy = 0.902499
I0526 16:56:45.030480 19470 solver.cpp:409]     Test net output #1: loss = 0.325044 (* 1 = 0.325044 loss)
I0526 16:57:05.910295 19470 solver.cpp:237] Iteration 480000, loss = 1.03866
I0526 16:57:05.910349 19470 solver.cpp:253]     Train net output #0: loss = 1.03865 (* 1 = 1.03865 loss)
I0526 16:57:05.910367 19470 sgd_solver.cpp:106] Iteration 480000, lr = 0.0025
I0526 16:57:18.051538 19470 solver.cpp:237] Iteration 480750, loss = 0.777943
I0526 16:57:18.051707 19470 solver.cpp:253]     Train net output #0: loss = 0.777941 (* 1 = 0.777941 loss)
I0526 16:57:18.051722 19470 sgd_solver.cpp:106] Iteration 480750, lr = 0.0025
I0526 16:57:30.194212 19470 solver.cpp:237] Iteration 481500, loss = 1.40344
I0526 16:57:30.194258 19470 solver.cpp:253]     Train net output #0: loss = 1.40344 (* 1 = 1.40344 loss)
I0526 16:57:30.194272 19470 sgd_solver.cpp:106] Iteration 481500, lr = 0.0025
I0526 16:57:42.341258 19470 solver.cpp:237] Iteration 482250, loss = 1.1859
I0526 16:57:42.341295 19470 solver.cpp:253]     Train net output #0: loss = 1.18589 (* 1 = 1.18589 loss)
I0526 16:57:42.341307 19470 sgd_solver.cpp:106] Iteration 482250, lr = 0.0025
I0526 16:57:54.498708 19470 solver.cpp:237] Iteration 483000, loss = 1.01552
I0526 16:57:54.498872 19470 solver.cpp:253]     Train net output #0: loss = 1.01551 (* 1 = 1.01551 loss)
I0526 16:57:54.498886 19470 sgd_solver.cpp:106] Iteration 483000, lr = 0.0025
I0526 16:58:06.641551 19470 solver.cpp:237] Iteration 483750, loss = 1.15536
I0526 16:58:06.641588 19470 solver.cpp:253]     Train net output #0: loss = 1.15536 (* 1 = 1.15536 loss)
I0526 16:58:06.641602 19470 sgd_solver.cpp:106] Iteration 483750, lr = 0.0025
I0526 16:58:18.774437 19470 solver.cpp:237] Iteration 484500, loss = 0.787456
I0526 16:58:18.774473 19470 solver.cpp:253]     Train net output #0: loss = 0.787454 (* 1 = 0.787454 loss)
I0526 16:58:18.774489 19470 sgd_solver.cpp:106] Iteration 484500, lr = 0.0025
I0526 16:58:51.773684 19470 solver.cpp:237] Iteration 485250, loss = 0.918492
I0526 16:58:51.773867 19470 solver.cpp:253]     Train net output #0: loss = 0.91849 (* 1 = 0.91849 loss)
I0526 16:58:51.773883 19470 sgd_solver.cpp:106] Iteration 485250, lr = 0.0025
I0526 16:59:03.934016 19470 solver.cpp:237] Iteration 486000, loss = 0.633553
I0526 16:59:03.934053 19470 solver.cpp:253]     Train net output #0: loss = 0.633552 (* 1 = 0.633552 loss)
I0526 16:59:03.934067 19470 sgd_solver.cpp:106] Iteration 486000, lr = 0.0025
I0526 16:59:16.061689 19470 solver.cpp:237] Iteration 486750, loss = 1.21715
I0526 16:59:16.061738 19470 solver.cpp:253]     Train net output #0: loss = 1.21715 (* 1 = 1.21715 loss)
I0526 16:59:16.061751 19470 sgd_solver.cpp:106] Iteration 486750, lr = 0.0025
I0526 16:59:28.188045 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_487500.caffemodel
I0526 16:59:28.237532 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_487500.solverstate
I0526 16:59:28.268162 19470 solver.cpp:237] Iteration 487500, loss = 1.09863
I0526 16:59:28.268208 19470 solver.cpp:253]     Train net output #0: loss = 1.09863 (* 1 = 1.09863 loss)
I0526 16:59:28.268223 19470 sgd_solver.cpp:106] Iteration 487500, lr = 0.0025
I0526 16:59:40.435922 19470 solver.cpp:237] Iteration 488250, loss = 1.15926
I0526 16:59:40.435971 19470 solver.cpp:253]     Train net output #0: loss = 1.15926 (* 1 = 1.15926 loss)
I0526 16:59:40.435984 19470 sgd_solver.cpp:106] Iteration 488250, lr = 0.0025
I0526 16:59:52.608664 19470 solver.cpp:237] Iteration 489000, loss = 0.79018
I0526 16:59:52.608701 19470 solver.cpp:253]     Train net output #0: loss = 0.790179 (* 1 = 0.790179 loss)
I0526 16:59:52.608714 19470 sgd_solver.cpp:106] Iteration 489000, lr = 0.0025
I0526 17:00:04.823148 19470 solver.cpp:237] Iteration 489750, loss = 0.770024
I0526 17:00:04.823338 19470 solver.cpp:253]     Train net output #0: loss = 0.770023 (* 1 = 0.770023 loss)
I0526 17:00:04.823354 19470 sgd_solver.cpp:106] Iteration 489750, lr = 0.0025
I0526 17:00:37.875589 19470 solver.cpp:237] Iteration 490500, loss = 0.701782
I0526 17:00:37.875776 19470 solver.cpp:253]     Train net output #0: loss = 0.701781 (* 1 = 0.701781 loss)
I0526 17:00:37.875792 19470 sgd_solver.cpp:106] Iteration 490500, lr = 0.0025
I0526 17:00:50.053470 19470 solver.cpp:237] Iteration 491250, loss = 1.19677
I0526 17:00:50.053515 19470 solver.cpp:253]     Train net output #0: loss = 1.19677 (* 1 = 1.19677 loss)
I0526 17:00:50.053529 19470 sgd_solver.cpp:106] Iteration 491250, lr = 0.0025
I0526 17:01:02.214462 19470 solver.cpp:237] Iteration 492000, loss = 1.1463
I0526 17:01:02.214498 19470 solver.cpp:253]     Train net output #0: loss = 1.1463 (* 1 = 1.1463 loss)
I0526 17:01:02.214512 19470 sgd_solver.cpp:106] Iteration 492000, lr = 0.0025
I0526 17:01:14.376201 19470 solver.cpp:237] Iteration 492750, loss = 0.598281
I0526 17:01:14.376366 19470 solver.cpp:253]     Train net output #0: loss = 0.59828 (* 1 = 0.59828 loss)
I0526 17:01:14.376381 19470 sgd_solver.cpp:106] Iteration 492750, lr = 0.0025
I0526 17:01:26.574705 19470 solver.cpp:237] Iteration 493500, loss = 1.22043
I0526 17:01:26.574746 19470 solver.cpp:253]     Train net output #0: loss = 1.22043 (* 1 = 1.22043 loss)
I0526 17:01:26.574759 19470 sgd_solver.cpp:106] Iteration 493500, lr = 0.0025
I0526 17:01:38.765465 19470 solver.cpp:237] Iteration 494250, loss = 1.06087
I0526 17:01:38.765501 19470 solver.cpp:253]     Train net output #0: loss = 1.06087 (* 1 = 1.06087 loss)
I0526 17:01:38.765516 19470 sgd_solver.cpp:106] Iteration 494250, lr = 0.0025
I0526 17:01:50.921068 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_495000.caffemodel
I0526 17:01:50.971344 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_495000.solverstate
I0526 17:01:50.997516 19470 solver.cpp:341] Iteration 495000, Testing net (#0)
I0526 17:03:03.897013 19470 solver.cpp:409]     Test net output #0: accuracy = 0.902386
I0526 17:03:03.897199 19470 solver.cpp:409]     Test net output #1: loss = 0.299825 (* 1 = 0.299825 loss)
I0526 17:03:24.701134 19470 solver.cpp:237] Iteration 495000, loss = 1.01532
I0526 17:03:24.701187 19470 solver.cpp:253]     Train net output #0: loss = 1.01532 (* 1 = 1.01532 loss)
I0526 17:03:24.701202 19470 sgd_solver.cpp:106] Iteration 495000, lr = 0.0025
I0526 17:03:36.831135 19470 solver.cpp:237] Iteration 495750, loss = 1.07903
I0526 17:03:36.831306 19470 solver.cpp:253]     Train net output #0: loss = 1.07903 (* 1 = 1.07903 loss)
I0526 17:03:36.831321 19470 sgd_solver.cpp:106] Iteration 495750, lr = 0.0025
I0526 17:03:48.921079 19470 solver.cpp:237] Iteration 496500, loss = 0.929031
I0526 17:03:48.921125 19470 solver.cpp:253]     Train net output #0: loss = 0.929029 (* 1 = 0.929029 loss)
I0526 17:03:48.921139 19470 sgd_solver.cpp:106] Iteration 496500, lr = 0.0025
I0526 17:04:01.054021 19470 solver.cpp:237] Iteration 497250, loss = 1.00125
I0526 17:04:01.054059 19470 solver.cpp:253]     Train net output #0: loss = 1.00125 (* 1 = 1.00125 loss)
I0526 17:04:01.054071 19470 sgd_solver.cpp:106] Iteration 497250, lr = 0.0025
I0526 17:04:13.175323 19470 solver.cpp:237] Iteration 498000, loss = 1.39606
I0526 17:04:13.175508 19470 solver.cpp:253]     Train net output #0: loss = 1.39606 (* 1 = 1.39606 loss)
I0526 17:04:13.175523 19470 sgd_solver.cpp:106] Iteration 498000, lr = 0.0025
I0526 17:04:25.270700 19470 solver.cpp:237] Iteration 498750, loss = 1.37867
I0526 17:04:25.270736 19470 solver.cpp:253]     Train net output #0: loss = 1.37867 (* 1 = 1.37867 loss)
I0526 17:04:25.270755 19470 sgd_solver.cpp:106] Iteration 498750, lr = 0.0025
I0526 17:04:37.383370 19470 solver.cpp:237] Iteration 499500, loss = 0.859589
I0526 17:04:37.383415 19470 solver.cpp:253]     Train net output #0: loss = 0.859588 (* 1 = 0.859588 loss)
I0526 17:04:37.383430 19470 sgd_solver.cpp:106] Iteration 499500, lr = 0.0025
I0526 17:05:10.287801 19470 solver.cpp:237] Iteration 500250, loss = 1.06168
I0526 17:05:10.287988 19470 solver.cpp:253]     Train net output #0: loss = 1.06168 (* 1 = 1.06168 loss)
I0526 17:05:10.288003 19470 sgd_solver.cpp:106] Iteration 500250, lr = 0.0025
I0526 17:05:22.321522 19470 solver.cpp:237] Iteration 501000, loss = 0.452617
I0526 17:05:22.321559 19470 solver.cpp:253]     Train net output #0: loss = 0.452617 (* 1 = 0.452617 loss)
I0526 17:05:22.321575 19470 sgd_solver.cpp:106] Iteration 501000, lr = 0.0025
I0526 17:05:34.384412 19470 solver.cpp:237] Iteration 501750, loss = 1.36317
I0526 17:05:34.384459 19470 solver.cpp:253]     Train net output #0: loss = 1.36317 (* 1 = 1.36317 loss)
I0526 17:05:34.384472 19470 sgd_solver.cpp:106] Iteration 501750, lr = 0.0025
I0526 17:05:46.424166 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_502500.caffemodel
I0526 17:05:46.475328 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_502500.solverstate
I0526 17:05:46.508246 19470 solver.cpp:237] Iteration 502500, loss = 1.68375
I0526 17:05:46.508293 19470 solver.cpp:253]     Train net output #0: loss = 1.68375 (* 1 = 1.68375 loss)
I0526 17:05:46.508308 19470 sgd_solver.cpp:106] Iteration 502500, lr = 0.0025
I0526 17:05:58.585255 19470 solver.cpp:237] Iteration 503250, loss = 1.02774
I0526 17:05:58.585306 19470 solver.cpp:253]     Train net output #0: loss = 1.02774 (* 1 = 1.02774 loss)
I0526 17:05:58.585320 19470 sgd_solver.cpp:106] Iteration 503250, lr = 0.0025
I0526 17:06:10.718966 19470 solver.cpp:237] Iteration 504000, loss = 1.37768
I0526 17:06:10.719002 19470 solver.cpp:253]     Train net output #0: loss = 1.37768 (* 1 = 1.37768 loss)
I0526 17:06:10.719014 19470 sgd_solver.cpp:106] Iteration 504000, lr = 0.0025
I0526 17:06:22.801542 19470 solver.cpp:237] Iteration 504750, loss = 0.943839
I0526 17:06:22.801730 19470 solver.cpp:253]     Train net output #0: loss = 0.943839 (* 1 = 0.943839 loss)
I0526 17:06:22.801745 19470 sgd_solver.cpp:106] Iteration 504750, lr = 0.0025
I0526 17:06:55.792639 19470 solver.cpp:237] Iteration 505500, loss = 1.0723
I0526 17:06:55.792837 19470 solver.cpp:253]     Train net output #0: loss = 1.0723 (* 1 = 1.0723 loss)
I0526 17:06:55.792855 19470 sgd_solver.cpp:106] Iteration 505500, lr = 0.0025
I0526 17:07:07.957753 19470 solver.cpp:237] Iteration 506250, loss = 1.16183
I0526 17:07:07.957801 19470 solver.cpp:253]     Train net output #0: loss = 1.16183 (* 1 = 1.16183 loss)
I0526 17:07:07.957818 19470 sgd_solver.cpp:106] Iteration 506250, lr = 0.0025
I0526 17:07:20.102581 19470 solver.cpp:237] Iteration 507000, loss = 1.27487
I0526 17:07:20.102617 19470 solver.cpp:253]     Train net output #0: loss = 1.27487 (* 1 = 1.27487 loss)
I0526 17:07:20.102632 19470 sgd_solver.cpp:106] Iteration 507000, lr = 0.0025
I0526 17:07:32.253270 19470 solver.cpp:237] Iteration 507750, loss = 0.937956
I0526 17:07:32.253458 19470 solver.cpp:253]     Train net output #0: loss = 0.937956 (* 1 = 0.937956 loss)
I0526 17:07:32.253473 19470 sgd_solver.cpp:106] Iteration 507750, lr = 0.0025
I0526 17:07:44.382601 19470 solver.cpp:237] Iteration 508500, loss = 1.10409
I0526 17:07:44.382638 19470 solver.cpp:253]     Train net output #0: loss = 1.10409 (* 1 = 1.10409 loss)
I0526 17:07:44.382654 19470 sgd_solver.cpp:106] Iteration 508500, lr = 0.0025
I0526 17:07:56.516173 19470 solver.cpp:237] Iteration 509250, loss = 1.07844
I0526 17:07:56.516218 19470 solver.cpp:253]     Train net output #0: loss = 1.07844 (* 1 = 1.07844 loss)
I0526 17:07:56.516237 19470 sgd_solver.cpp:106] Iteration 509250, lr = 0.0025
I0526 17:08:08.636909 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_510000.caffemodel
I0526 17:08:08.689241 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_510000.solverstate
I0526 17:08:08.717289 19470 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 17:09:00.337082 19470 solver.cpp:409]     Test net output #0: accuracy = 0.908586
I0526 17:09:00.337267 19470 solver.cpp:409]     Test net output #1: loss = 0.286312 (* 1 = 0.286312 loss)
I0526 17:09:21.228796 19470 solver.cpp:237] Iteration 510000, loss = 0.999815
I0526 17:09:21.228848 19470 solver.cpp:253]     Train net output #0: loss = 0.999814 (* 1 = 0.999814 loss)
I0526 17:09:21.228870 19470 sgd_solver.cpp:106] Iteration 510000, lr = 0.0025
I0526 17:09:33.372272 19470 solver.cpp:237] Iteration 510750, loss = 1.16341
I0526 17:09:33.372447 19470 solver.cpp:253]     Train net output #0: loss = 1.16341 (* 1 = 1.16341 loss)
I0526 17:09:33.372462 19470 sgd_solver.cpp:106] Iteration 510750, lr = 0.0025
I0526 17:09:45.486096 19470 solver.cpp:237] Iteration 511500, loss = 1.01311
I0526 17:09:45.486143 19470 solver.cpp:253]     Train net output #0: loss = 1.01311 (* 1 = 1.01311 loss)
I0526 17:09:45.486156 19470 sgd_solver.cpp:106] Iteration 511500, lr = 0.0025
I0526 17:09:57.594707 19470 solver.cpp:237] Iteration 512250, loss = 0.902611
I0526 17:09:57.594743 19470 solver.cpp:253]     Train net output #0: loss = 0.902611 (* 1 = 0.902611 loss)
I0526 17:09:57.594756 19470 sgd_solver.cpp:106] Iteration 512250, lr = 0.0025
I0526 17:10:09.787845 19470 solver.cpp:237] Iteration 513000, loss = 0.947596
I0526 17:10:09.788022 19470 solver.cpp:253]     Train net output #0: loss = 0.947596 (* 1 = 0.947596 loss)
I0526 17:10:09.788038 19470 sgd_solver.cpp:106] Iteration 513000, lr = 0.0025
I0526 17:10:21.962224 19470 solver.cpp:237] Iteration 513750, loss = 1.12418
I0526 17:10:21.962260 19470 solver.cpp:253]     Train net output #0: loss = 1.12418 (* 1 = 1.12418 loss)
I0526 17:10:21.962272 19470 sgd_solver.cpp:106] Iteration 513750, lr = 0.0025
I0526 17:10:34.142387 19470 solver.cpp:237] Iteration 514500, loss = 0.904178
I0526 17:10:34.142429 19470 solver.cpp:253]     Train net output #0: loss = 0.904178 (* 1 = 0.904178 loss)
I0526 17:10:34.142447 19470 sgd_solver.cpp:106] Iteration 514500, lr = 0.0025
I0526 17:11:07.173418 19470 solver.cpp:237] Iteration 515250, loss = 0.954946
I0526 17:11:07.173606 19470 solver.cpp:253]     Train net output #0: loss = 0.954946 (* 1 = 0.954946 loss)
I0526 17:11:07.173622 19470 sgd_solver.cpp:106] Iteration 515250, lr = 0.0025
I0526 17:11:19.330957 19470 solver.cpp:237] Iteration 516000, loss = 1.22751
I0526 17:11:19.331006 19470 solver.cpp:253]     Train net output #0: loss = 1.22751 (* 1 = 1.22751 loss)
I0526 17:11:19.331019 19470 sgd_solver.cpp:106] Iteration 516000, lr = 0.0025
I0526 17:11:31.483930 19470 solver.cpp:237] Iteration 516750, loss = 1.37632
I0526 17:11:31.483966 19470 solver.cpp:253]     Train net output #0: loss = 1.37632 (* 1 = 1.37632 loss)
I0526 17:11:31.483979 19470 sgd_solver.cpp:106] Iteration 516750, lr = 0.0025
I0526 17:11:43.619299 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_517500.caffemodel
I0526 17:11:43.669775 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_517500.solverstate
I0526 17:11:43.700292 19470 solver.cpp:237] Iteration 517500, loss = 1.18981
I0526 17:11:43.700340 19470 solver.cpp:253]     Train net output #0: loss = 1.18981 (* 1 = 1.18981 loss)
I0526 17:11:43.700353 19470 sgd_solver.cpp:106] Iteration 517500, lr = 0.0025
I0526 17:11:55.831560 19470 solver.cpp:237] Iteration 518250, loss = 1.01887
I0526 17:11:55.831596 19470 solver.cpp:253]     Train net output #0: loss = 1.01887 (* 1 = 1.01887 loss)
I0526 17:11:55.831610 19470 sgd_solver.cpp:106] Iteration 518250, lr = 0.0025
I0526 17:12:07.944656 19470 solver.cpp:237] Iteration 519000, loss = 0.714808
I0526 17:12:07.944705 19470 solver.cpp:253]     Train net output #0: loss = 0.714808 (* 1 = 0.714808 loss)
I0526 17:12:07.944720 19470 sgd_solver.cpp:106] Iteration 519000, lr = 0.0025
I0526 17:12:20.102030 19470 solver.cpp:237] Iteration 519750, loss = 0.751869
I0526 17:12:20.102202 19470 solver.cpp:253]     Train net output #0: loss = 0.751869 (* 1 = 0.751869 loss)
I0526 17:12:20.102218 19470 sgd_solver.cpp:106] Iteration 519750, lr = 0.0025
I0526 17:12:53.158578 19470 solver.cpp:237] Iteration 520500, loss = 0.910247
I0526 17:12:53.158769 19470 solver.cpp:253]     Train net output #0: loss = 0.910247 (* 1 = 0.910247 loss)
I0526 17:12:53.158785 19470 sgd_solver.cpp:106] Iteration 520500, lr = 0.0025
I0526 17:13:05.333981 19470 solver.cpp:237] Iteration 521250, loss = 1.14038
I0526 17:13:05.334030 19470 solver.cpp:253]     Train net output #0: loss = 1.14038 (* 1 = 1.14038 loss)
I0526 17:13:05.334044 19470 sgd_solver.cpp:106] Iteration 521250, lr = 0.0025
I0526 17:13:17.474498 19470 solver.cpp:237] Iteration 522000, loss = 0.832416
I0526 17:13:17.474534 19470 solver.cpp:253]     Train net output #0: loss = 0.832416 (* 1 = 0.832416 loss)
I0526 17:13:17.474548 19470 sgd_solver.cpp:106] Iteration 522000, lr = 0.0025
I0526 17:13:29.617678 19470 solver.cpp:237] Iteration 522750, loss = 1.36
I0526 17:13:29.617856 19470 solver.cpp:253]     Train net output #0: loss = 1.36 (* 1 = 1.36 loss)
I0526 17:13:29.617871 19470 sgd_solver.cpp:106] Iteration 522750, lr = 0.0025
I0526 17:13:41.756572 19470 solver.cpp:237] Iteration 523500, loss = 1.34756
I0526 17:13:41.756608 19470 solver.cpp:253]     Train net output #0: loss = 1.34756 (* 1 = 1.34756 loss)
I0526 17:13:41.756628 19470 sgd_solver.cpp:106] Iteration 523500, lr = 0.0025
I0526 17:13:53.903023 19470 solver.cpp:237] Iteration 524250, loss = 1.33598
I0526 17:13:53.903074 19470 solver.cpp:253]     Train net output #0: loss = 1.33598 (* 1 = 1.33598 loss)
I0526 17:13:53.903086 19470 sgd_solver.cpp:106] Iteration 524250, lr = 0.0025
I0526 17:14:05.999007 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_525000.caffemodel
I0526 17:14:06.048974 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_525000.solverstate
I0526 17:14:06.074471 19470 solver.cpp:341] Iteration 525000, Testing net (#0)
I0526 17:15:19.023110 19470 solver.cpp:409]     Test net output #0: accuracy = 0.903097
I0526 17:15:19.023299 19470 solver.cpp:409]     Test net output #1: loss = 0.306973 (* 1 = 0.306973 loss)
I0526 17:15:39.890816 19470 solver.cpp:237] Iteration 525000, loss = 1.06418
I0526 17:15:39.890866 19470 solver.cpp:253]     Train net output #0: loss = 1.06418 (* 1 = 1.06418 loss)
I0526 17:15:39.890884 19470 sgd_solver.cpp:106] Iteration 525000, lr = 0.0025
I0526 17:15:52.021121 19470 solver.cpp:237] Iteration 525750, loss = 1.20983
I0526 17:15:52.021320 19470 solver.cpp:253]     Train net output #0: loss = 1.20983 (* 1 = 1.20983 loss)
I0526 17:15:52.021335 19470 sgd_solver.cpp:106] Iteration 525750, lr = 0.0025
I0526 17:16:04.196318 19470 solver.cpp:237] Iteration 526500, loss = 0.630625
I0526 17:16:04.196355 19470 solver.cpp:253]     Train net output #0: loss = 0.630624 (* 1 = 0.630624 loss)
I0526 17:16:04.196369 19470 sgd_solver.cpp:106] Iteration 526500, lr = 0.0025
I0526 17:16:16.354498 19470 solver.cpp:237] Iteration 527250, loss = 0.910019
I0526 17:16:16.354542 19470 solver.cpp:253]     Train net output #0: loss = 0.910019 (* 1 = 0.910019 loss)
I0526 17:16:16.354558 19470 sgd_solver.cpp:106] Iteration 527250, lr = 0.0025
I0526 17:16:28.482895 19470 solver.cpp:237] Iteration 528000, loss = 0.646564
I0526 17:16:28.483067 19470 solver.cpp:253]     Train net output #0: loss = 0.646564 (* 1 = 0.646564 loss)
I0526 17:16:28.483083 19470 sgd_solver.cpp:106] Iteration 528000, lr = 0.0025
I0526 17:16:40.631844 19470 solver.cpp:237] Iteration 528750, loss = 1.40113
I0526 17:16:40.631892 19470 solver.cpp:253]     Train net output #0: loss = 1.40113 (* 1 = 1.40113 loss)
I0526 17:16:40.631906 19470 sgd_solver.cpp:106] Iteration 528750, lr = 0.0025
I0526 17:16:52.809173 19470 solver.cpp:237] Iteration 529500, loss = 1.06301
I0526 17:16:52.809209 19470 solver.cpp:253]     Train net output #0: loss = 1.06301 (* 1 = 1.06301 loss)
I0526 17:16:52.809223 19470 sgd_solver.cpp:106] Iteration 529500, lr = 0.0025
I0526 17:17:25.842448 19470 solver.cpp:237] Iteration 530250, loss = 1.25883
I0526 17:17:25.842643 19470 solver.cpp:253]     Train net output #0: loss = 1.25883 (* 1 = 1.25883 loss)
I0526 17:17:25.842659 19470 sgd_solver.cpp:106] Iteration 530250, lr = 0.0025
I0526 17:17:37.999238 19470 solver.cpp:237] Iteration 531000, loss = 0.864526
I0526 17:17:37.999286 19470 solver.cpp:253]     Train net output #0: loss = 0.864526 (* 1 = 0.864526 loss)
I0526 17:17:37.999300 19470 sgd_solver.cpp:106] Iteration 531000, lr = 0.0025
I0526 17:17:50.128538 19470 solver.cpp:237] Iteration 531750, loss = 1.48215
I0526 17:17:50.128574 19470 solver.cpp:253]     Train net output #0: loss = 1.48215 (* 1 = 1.48215 loss)
I0526 17:17:50.128587 19470 sgd_solver.cpp:106] Iteration 531750, lr = 0.0025
I0526 17:18:02.244634 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_532500.caffemodel
I0526 17:18:02.294384 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_532500.solverstate
I0526 17:18:02.328856 19470 solver.cpp:237] Iteration 532500, loss = 1.45309
I0526 17:18:02.328912 19470 solver.cpp:253]     Train net output #0: loss = 1.45309 (* 1 = 1.45309 loss)
I0526 17:18:02.328928 19470 sgd_solver.cpp:106] Iteration 532500, lr = 0.0025
I0526 17:18:14.458917 19470 solver.cpp:237] Iteration 533250, loss = 1.12341
I0526 17:18:14.458953 19470 solver.cpp:253]     Train net output #0: loss = 1.12341 (* 1 = 1.12341 loss)
I0526 17:18:14.458967 19470 sgd_solver.cpp:106] Iteration 533250, lr = 0.0025
I0526 17:18:26.620714 19470 solver.cpp:237] Iteration 534000, loss = 1.21866
I0526 17:18:26.620762 19470 solver.cpp:253]     Train net output #0: loss = 1.21866 (* 1 = 1.21866 loss)
I0526 17:18:26.620776 19470 sgd_solver.cpp:106] Iteration 534000, lr = 0.0025
I0526 17:18:38.771534 19470 solver.cpp:237] Iteration 534750, loss = 1.34183
I0526 17:18:38.771709 19470 solver.cpp:253]     Train net output #0: loss = 1.34183 (* 1 = 1.34183 loss)
I0526 17:18:38.771723 19470 sgd_solver.cpp:106] Iteration 534750, lr = 0.0025
I0526 17:19:11.780220 19470 solver.cpp:237] Iteration 535500, loss = 0.952887
I0526 17:19:11.780431 19470 solver.cpp:253]     Train net output #0: loss = 0.952887 (* 1 = 0.952887 loss)
I0526 17:19:11.780446 19470 sgd_solver.cpp:106] Iteration 535500, lr = 0.0025
I0526 17:19:23.897809 19470 solver.cpp:237] Iteration 536250, loss = 0.947934
I0526 17:19:23.897845 19470 solver.cpp:253]     Train net output #0: loss = 0.947934 (* 1 = 0.947934 loss)
I0526 17:19:23.897860 19470 sgd_solver.cpp:106] Iteration 536250, lr = 0.0025
I0526 17:19:36.084345 19470 solver.cpp:237] Iteration 537000, loss = 0.794797
I0526 17:19:36.084396 19470 solver.cpp:253]     Train net output #0: loss = 0.794797 (* 1 = 0.794797 loss)
I0526 17:19:36.084410 19470 sgd_solver.cpp:106] Iteration 537000, lr = 0.0025
I0526 17:19:48.231729 19470 solver.cpp:237] Iteration 537750, loss = 1.04082
I0526 17:19:48.231901 19470 solver.cpp:253]     Train net output #0: loss = 1.04082 (* 1 = 1.04082 loss)
I0526 17:19:48.231916 19470 sgd_solver.cpp:106] Iteration 537750, lr = 0.0025
I0526 17:20:00.384902 19470 solver.cpp:237] Iteration 538500, loss = 1.0541
I0526 17:20:00.384943 19470 solver.cpp:253]     Train net output #0: loss = 1.0541 (* 1 = 1.0541 loss)
I0526 17:20:00.384958 19470 sgd_solver.cpp:106] Iteration 538500, lr = 0.0025
I0526 17:20:12.534258 19470 solver.cpp:237] Iteration 539250, loss = 0.806923
I0526 17:20:12.534296 19470 solver.cpp:253]     Train net output #0: loss = 0.806923 (* 1 = 0.806923 loss)
I0526 17:20:12.534308 19470 sgd_solver.cpp:106] Iteration 539250, lr = 0.0025
I0526 17:20:24.622259 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_540000.caffemodel
I0526 17:20:24.673177 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_540000.solverstate
I0526 17:20:24.699975 19470 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 17:21:16.670490 19470 solver.cpp:409]     Test net output #0: accuracy = 0.903692
I0526 17:21:16.670678 19470 solver.cpp:409]     Test net output #1: loss = 0.294996 (* 1 = 0.294996 loss)
I0526 17:21:37.549873 19470 solver.cpp:237] Iteration 540000, loss = 1.43222
I0526 17:21:37.549926 19470 solver.cpp:253]     Train net output #0: loss = 1.43222 (* 1 = 1.43222 loss)
I0526 17:21:37.549942 19470 sgd_solver.cpp:106] Iteration 540000, lr = 0.0025
I0526 17:21:49.757943 19470 solver.cpp:237] Iteration 540750, loss = 1.0351
I0526 17:21:49.758127 19470 solver.cpp:253]     Train net output #0: loss = 1.0351 (* 1 = 1.0351 loss)
I0526 17:21:49.758141 19470 sgd_solver.cpp:106] Iteration 540750, lr = 0.0025
I0526 17:22:01.931342 19470 solver.cpp:237] Iteration 541500, loss = 0.796831
I0526 17:22:01.931380 19470 solver.cpp:253]     Train net output #0: loss = 0.796831 (* 1 = 0.796831 loss)
I0526 17:22:01.931393 19470 sgd_solver.cpp:106] Iteration 541500, lr = 0.0025
I0526 17:22:14.102352 19470 solver.cpp:237] Iteration 542250, loss = 1.17985
I0526 17:22:14.102401 19470 solver.cpp:253]     Train net output #0: loss = 1.17985 (* 1 = 1.17985 loss)
I0526 17:22:14.102416 19470 sgd_solver.cpp:106] Iteration 542250, lr = 0.0025
I0526 17:22:26.271947 19470 solver.cpp:237] Iteration 543000, loss = 1.31804
I0526 17:22:26.272119 19470 solver.cpp:253]     Train net output #0: loss = 1.31804 (* 1 = 1.31804 loss)
I0526 17:22:26.272135 19470 sgd_solver.cpp:106] Iteration 543000, lr = 0.0025
I0526 17:22:38.474129 19470 solver.cpp:237] Iteration 543750, loss = 1.31853
I0526 17:22:38.474174 19470 solver.cpp:253]     Train net output #0: loss = 1.31853 (* 1 = 1.31853 loss)
I0526 17:22:38.474190 19470 sgd_solver.cpp:106] Iteration 543750, lr = 0.0025
I0526 17:22:50.658370 19470 solver.cpp:237] Iteration 544500, loss = 1.30284
I0526 17:22:50.658406 19470 solver.cpp:253]     Train net output #0: loss = 1.30284 (* 1 = 1.30284 loss)
I0526 17:22:50.658423 19470 sgd_solver.cpp:106] Iteration 544500, lr = 0.0025
I0526 17:23:23.738863 19470 solver.cpp:237] Iteration 545250, loss = 1.58712
I0526 17:23:23.739063 19470 solver.cpp:253]     Train net output #0: loss = 1.58712 (* 1 = 1.58712 loss)
I0526 17:23:23.739078 19470 sgd_solver.cpp:106] Iteration 545250, lr = 0.0025
I0526 17:23:35.951161 19470 solver.cpp:237] Iteration 546000, loss = 1.32663
I0526 17:23:35.951195 19470 solver.cpp:253]     Train net output #0: loss = 1.32663 (* 1 = 1.32663 loss)
I0526 17:23:35.951210 19470 sgd_solver.cpp:106] Iteration 546000, lr = 0.0025
I0526 17:23:48.156008 19470 solver.cpp:237] Iteration 546750, loss = 1.12642
I0526 17:23:48.156052 19470 solver.cpp:253]     Train net output #0: loss = 1.12642 (* 1 = 1.12642 loss)
I0526 17:23:48.156065 19470 sgd_solver.cpp:106] Iteration 546750, lr = 0.0025
I0526 17:24:00.351737 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_547500.caffemodel
I0526 17:24:00.403080 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_547500.solverstate
I0526 17:24:00.435590 19470 solver.cpp:237] Iteration 547500, loss = 1.54001
I0526 17:24:00.435639 19470 solver.cpp:253]     Train net output #0: loss = 1.54001 (* 1 = 1.54001 loss)
I0526 17:24:00.435653 19470 sgd_solver.cpp:106] Iteration 547500, lr = 0.0025
I0526 17:24:12.597340 19470 solver.cpp:237] Iteration 548250, loss = 1.15609
I0526 17:24:12.597390 19470 solver.cpp:253]     Train net output #0: loss = 1.15609 (* 1 = 1.15609 loss)
I0526 17:24:12.597404 19470 sgd_solver.cpp:106] Iteration 548250, lr = 0.0025
I0526 17:24:24.723354 19470 solver.cpp:237] Iteration 549000, loss = 1.06095
I0526 17:24:24.723390 19470 solver.cpp:253]     Train net output #0: loss = 1.06095 (* 1 = 1.06095 loss)
I0526 17:24:24.723403 19470 sgd_solver.cpp:106] Iteration 549000, lr = 0.0025
I0526 17:24:36.848569 19470 solver.cpp:237] Iteration 549750, loss = 1.18414
I0526 17:24:36.848760 19470 solver.cpp:253]     Train net output #0: loss = 1.18414 (* 1 = 1.18414 loss)
I0526 17:24:36.848776 19470 sgd_solver.cpp:106] Iteration 549750, lr = 0.0025
I0526 17:25:09.922207 19470 solver.cpp:237] Iteration 550500, loss = 1.12832
I0526 17:25:09.922400 19470 solver.cpp:253]     Train net output #0: loss = 1.12832 (* 1 = 1.12832 loss)
I0526 17:25:09.922415 19470 sgd_solver.cpp:106] Iteration 550500, lr = 0.0025
I0526 17:25:22.165031 19470 solver.cpp:237] Iteration 551250, loss = 0.690001
I0526 17:25:22.165067 19470 solver.cpp:253]     Train net output #0: loss = 0.690001 (* 1 = 0.690001 loss)
I0526 17:25:22.165086 19470 sgd_solver.cpp:106] Iteration 551250, lr = 0.0025
I0526 17:25:34.359302 19470 solver.cpp:237] Iteration 552000, loss = 0.812297
I0526 17:25:34.359349 19470 solver.cpp:253]     Train net output #0: loss = 0.812297 (* 1 = 0.812297 loss)
I0526 17:25:34.359362 19470 sgd_solver.cpp:106] Iteration 552000, lr = 0.0025
I0526 17:25:46.582991 19470 solver.cpp:237] Iteration 552750, loss = 1.04161
I0526 17:25:46.583160 19470 solver.cpp:253]     Train net output #0: loss = 1.04161 (* 1 = 1.04161 loss)
I0526 17:25:46.583175 19470 sgd_solver.cpp:106] Iteration 552750, lr = 0.0025
I0526 17:25:58.816723 19470 solver.cpp:237] Iteration 553500, loss = 0.800169
I0526 17:25:58.816769 19470 solver.cpp:253]     Train net output #0: loss = 0.800169 (* 1 = 0.800169 loss)
I0526 17:25:58.816783 19470 sgd_solver.cpp:106] Iteration 553500, lr = 0.0025
I0526 17:26:11.067246 19470 solver.cpp:237] Iteration 554250, loss = 0.904002
I0526 17:26:11.067283 19470 solver.cpp:253]     Train net output #0: loss = 0.904001 (* 1 = 0.904001 loss)
I0526 17:26:11.067296 19470 sgd_solver.cpp:106] Iteration 554250, lr = 0.0025
I0526 17:26:23.234235 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_555000.caffemodel
I0526 17:26:23.289491 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_555000.solverstate
I0526 17:26:23.321164 19470 solver.cpp:341] Iteration 555000, Testing net (#0)
I0526 17:27:36.349906 19470 solver.cpp:409]     Test net output #0: accuracy = 0.901949
I0526 17:27:36.350112 19470 solver.cpp:409]     Test net output #1: loss = 0.307611 (* 1 = 0.307611 loss)
I0526 17:27:57.236291 19470 solver.cpp:237] Iteration 555000, loss = 1.10565
I0526 17:27:57.236338 19470 solver.cpp:253]     Train net output #0: loss = 1.10565 (* 1 = 1.10565 loss)
I0526 17:27:57.236356 19470 sgd_solver.cpp:106] Iteration 555000, lr = 0.0025
I0526 17:28:09.402220 19470 solver.cpp:237] Iteration 555750, loss = 1.09362
I0526 17:28:09.402400 19470 solver.cpp:253]     Train net output #0: loss = 1.09362 (* 1 = 1.09362 loss)
I0526 17:28:09.402413 19470 sgd_solver.cpp:106] Iteration 555750, lr = 0.0025
I0526 17:28:21.555290 19470 solver.cpp:237] Iteration 556500, loss = 1.05586
I0526 17:28:21.555338 19470 solver.cpp:253]     Train net output #0: loss = 1.05586 (* 1 = 1.05586 loss)
I0526 17:28:21.555352 19470 sgd_solver.cpp:106] Iteration 556500, lr = 0.0025
I0526 17:28:33.677937 19470 solver.cpp:237] Iteration 557250, loss = 1.30915
I0526 17:28:33.677973 19470 solver.cpp:253]     Train net output #0: loss = 1.30915 (* 1 = 1.30915 loss)
I0526 17:28:33.677986 19470 sgd_solver.cpp:106] Iteration 557250, lr = 0.0025
I0526 17:28:45.811951 19470 solver.cpp:237] Iteration 558000, loss = 0.885591
I0526 17:28:45.812135 19470 solver.cpp:253]     Train net output #0: loss = 0.88559 (* 1 = 0.88559 loss)
I0526 17:28:45.812150 19470 sgd_solver.cpp:106] Iteration 558000, lr = 0.0025
I0526 17:28:57.940628 19470 solver.cpp:237] Iteration 558750, loss = 1.16751
I0526 17:28:57.940663 19470 solver.cpp:253]     Train net output #0: loss = 1.1675 (* 1 = 1.1675 loss)
I0526 17:28:57.940676 19470 sgd_solver.cpp:106] Iteration 558750, lr = 0.0025
I0526 17:29:10.059911 19470 solver.cpp:237] Iteration 559500, loss = 1.05317
I0526 17:29:10.059953 19470 solver.cpp:253]     Train net output #0: loss = 1.05317 (* 1 = 1.05317 loss)
I0526 17:29:10.059972 19470 sgd_solver.cpp:106] Iteration 559500, lr = 0.0025
I0526 17:29:43.051883 19470 solver.cpp:237] Iteration 560250, loss = 1.41854
I0526 17:29:43.052078 19470 solver.cpp:253]     Train net output #0: loss = 1.41854 (* 1 = 1.41854 loss)
I0526 17:29:43.052093 19470 sgd_solver.cpp:106] Iteration 560250, lr = 0.0025
I0526 17:29:55.230885 19470 solver.cpp:237] Iteration 561000, loss = 1.00587
I0526 17:29:55.230921 19470 solver.cpp:253]     Train net output #0: loss = 1.00587 (* 1 = 1.00587 loss)
I0526 17:29:55.230934 19470 sgd_solver.cpp:106] Iteration 561000, lr = 0.0025
I0526 17:30:07.413980 19470 solver.cpp:237] Iteration 561750, loss = 0.988259
I0526 17:30:07.414028 19470 solver.cpp:253]     Train net output #0: loss = 0.988258 (* 1 = 0.988258 loss)
I0526 17:30:07.414041 19470 sgd_solver.cpp:106] Iteration 561750, lr = 0.0025
I0526 17:30:19.527207 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_562500.caffemodel
I0526 17:30:19.576493 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_562500.solverstate
I0526 17:30:19.612496 19470 solver.cpp:237] Iteration 562500, loss = 0.796214
I0526 17:30:19.612540 19470 solver.cpp:253]     Train net output #0: loss = 0.796213 (* 1 = 0.796213 loss)
I0526 17:30:19.612555 19470 sgd_solver.cpp:106] Iteration 562500, lr = 0.0025
I0526 17:30:31.766041 19470 solver.cpp:237] Iteration 563250, loss = 1.13169
I0526 17:30:31.766088 19470 solver.cpp:253]     Train net output #0: loss = 1.13169 (* 1 = 1.13169 loss)
I0526 17:30:31.766100 19470 sgd_solver.cpp:106] Iteration 563250, lr = 0.0025
I0526 17:30:43.929014 19470 solver.cpp:237] Iteration 564000, loss = 1.41263
I0526 17:30:43.929049 19470 solver.cpp:253]     Train net output #0: loss = 1.41262 (* 1 = 1.41262 loss)
I0526 17:30:43.929064 19470 sgd_solver.cpp:106] Iteration 564000, lr = 0.0025
I0526 17:30:56.063832 19470 solver.cpp:237] Iteration 564750, loss = 1.14661
I0526 17:30:56.064024 19470 solver.cpp:253]     Train net output #0: loss = 1.14661 (* 1 = 1.14661 loss)
I0526 17:30:56.064038 19470 sgd_solver.cpp:106] Iteration 564750, lr = 0.0025
I0526 17:31:29.018746 19470 solver.cpp:237] Iteration 565500, loss = 0.827348
I0526 17:31:29.018942 19470 solver.cpp:253]     Train net output #0: loss = 0.827347 (* 1 = 0.827347 loss)
I0526 17:31:29.018959 19470 sgd_solver.cpp:106] Iteration 565500, lr = 0.0025
I0526 17:31:41.095876 19470 solver.cpp:237] Iteration 566250, loss = 1.26192
I0526 17:31:41.095917 19470 solver.cpp:253]     Train net output #0: loss = 1.26191 (* 1 = 1.26191 loss)
I0526 17:31:41.095932 19470 sgd_solver.cpp:106] Iteration 566250, lr = 0.0025
I0526 17:31:53.172150 19470 solver.cpp:237] Iteration 567000, loss = 1.40173
I0526 17:31:53.172186 19470 solver.cpp:253]     Train net output #0: loss = 1.40173 (* 1 = 1.40173 loss)
I0526 17:31:53.172204 19470 sgd_solver.cpp:106] Iteration 567000, lr = 0.0025
I0526 17:32:05.287212 19470 solver.cpp:237] Iteration 567750, loss = 1.04612
I0526 17:32:05.287397 19470 solver.cpp:253]     Train net output #0: loss = 1.04611 (* 1 = 1.04611 loss)
I0526 17:32:05.287412 19470 sgd_solver.cpp:106] Iteration 567750, lr = 0.0025
I0526 17:32:17.484200 19470 solver.cpp:237] Iteration 568500, loss = 0.96465
I0526 17:32:17.484236 19470 solver.cpp:253]     Train net output #0: loss = 0.964648 (* 1 = 0.964648 loss)
I0526 17:32:17.484249 19470 sgd_solver.cpp:106] Iteration 568500, lr = 0.0025
I0526 17:32:29.628751 19470 solver.cpp:237] Iteration 569250, loss = 1.43266
I0526 17:32:29.628793 19470 solver.cpp:253]     Train net output #0: loss = 1.43266 (* 1 = 1.43266 loss)
I0526 17:32:29.628809 19470 sgd_solver.cpp:106] Iteration 569250, lr = 0.0025
I0526 17:32:41.791462 19470 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_570000.caffemodel
I0526 17:32:41.841470 19470 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_20_lr_0.0025_2016-05-20T15.48.54.995804_iter_570000.solverstate
I0526 17:32:41.866911 19470 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 17:33:33.453290 19470 solver.cpp:409]     Test net output #0: accuracy = 0.906633
I0526 17:33:33.453480 19470 solver.cpp:409]     Test net output #1: loss = 0.297377 (* 1 = 0.297377 loss)
I0526 17:33:54.320269 19470 solver.cpp:237] Iteration 570000, loss = 1.45166
I0526 17:33:54.320322 19470 solver.cpp:253]     Train net output #0: loss = 1.45166 (* 1 = 1.45166 loss)
I0526 17:33:54.320338 19470 sgd_solver.cpp:106] Iteration 570000, lr = 0.0025
I0526 17:34:06.477715 19470 solver.cpp:237] Iteration 570750, loss = 0.789208
I0526 17:34:06.477895 19470 solver.cpp:253]     Train net output #0: loss = 0.789207 (* 1 = 0.789207 loss)
I0526 17:34:06.477910 19470 sgd_solver.cpp:106] Iteration 570750, lr = 0.0025
I0526 17:34:18.679262 19470 solver.cpp:237] Iteration 571500, loss = 1.21104
I0526 17:34:18.679311 19470 solver.cpp:253]     Train net output #0: loss = 1.21104 (* 1 = 1.21104 loss)
I0526 17:34:18.679325 19470 sgd_solver.cpp:106] Iteration 571500, lr = 0.0025
I0526 17:34:30.840654 19470 solver.cpp:237] Iteration 572250, loss = 1.21231
I0526 17:34:30.840690 19470 solver.cpp:253]     Train net output #0: loss = 1.2123 (* 1 = 1.2123 loss)
I0526 17:34:30.840704 19470 sgd_solver.cpp:106] Iteration 572250, lr = 0.0025
I0526 17:34:43.070194 19470 solver.cpp:237] Iteration 573000, loss = 0.656758
I0526 17:34:43.070380 19470 solver.cpp:253]     Train net output #0: loss = 0.656757 (* 1 = 0.656757 loss)
I0526 17:34:43.070395 19470 sgd_solver.cpp:106] Iteration 573000, lr = 0.0025
I0526 17:34:55.280872 19470 solver.cpp:237] Iteration 573750, loss = 0.647393
I0526 17:34:55.280910 19470 solver.cpp:253]     Train net output #0: loss = 0.647392 (* 1 = 0.647392 loss)
I0526 17:34:55.280922 19470 sgd_solver.cpp:106] Iteration 573750, lr = 0.0025
I0526 17:35:07.451290 19470 solver.cpp:237] Iteration 574500, loss = 0.897433
I0526 17:35:07.451334 19470 solver.cpp:253]     Train net output #0: loss = 0.897432 (* 1 = 0.897432 loss)
I0526 17:35:07.451349 19470 sgd_solver.cpp:106] Iteration 574500, lr = 0.0025
aprun: Apid 11269601: Caught signal Terminated, sending to application
*** Aborted at 1464298529 (unix time) try "date -d @1464298529" if you are using GNU date ***
aprun: Apid 11269601: Caught signal Terminated, sending to application
aprun: Apid 11269601: Caught signal Terminated, sending to application
PC: @     0x2aaac5e9b80a (unknown)
*** SIGTERM (@0x4c0b) received by PID 19470 (TID 0x2aaac746f900) from PID 19467; stack trace: ***
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaac5e9b80a (unknown)
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaac5e9c9d5 inflate
aprun: Apid 11269601: Caught signal Terminated, sending to application
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaab1450a9d H5Z_filter_deflate
=>> PBS: job killed: walltime 7233 exceeded limit 7200
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaab128be08 H5D__chunk_read
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaab129e5ec H5D__read
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaab129ec5c H5Dread
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x43b3b8 train()
aprun: Apid 11269601: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
