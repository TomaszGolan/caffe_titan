2809168
I0524 00:23:51.713182  8498 caffe.cpp:184] Using GPUs 0
I0524 00:23:52.139181  8498 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2142
test_interval: 4285
base_lr: 0.002
display: 214
max_iter: 214280
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2142
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876.prototxt"
I0524 00:23:52.141098  8498 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876.prototxt
I0524 00:23:52.159027  8498 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0524 00:23:52.159086  8498 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0524 00:23:52.159435  8498 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 00:23:52.159615  8498 layer_factory.hpp:77] Creating layer data_hdf5
I0524 00:23:52.159637  8498 net.cpp:106] Creating Layer data_hdf5
I0524 00:23:52.159652  8498 net.cpp:411] data_hdf5 -> data
I0524 00:23:52.159684  8498 net.cpp:411] data_hdf5 -> label
I0524 00:23:52.159716  8498 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0524 00:23:52.160890  8498 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0524 00:23:52.163084  8498 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0524 00:24:13.687458  8498 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0524 00:24:13.692602  8498 net.cpp:150] Setting up data_hdf5
I0524 00:24:13.692642  8498 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0524 00:24:13.692656  8498 net.cpp:157] Top shape: 70 (70)
I0524 00:24:13.692668  8498 net.cpp:165] Memory required for data: 1778280
I0524 00:24:13.692682  8498 layer_factory.hpp:77] Creating layer conv1
I0524 00:24:13.692718  8498 net.cpp:106] Creating Layer conv1
I0524 00:24:13.692728  8498 net.cpp:454] conv1 <- data
I0524 00:24:13.692750  8498 net.cpp:411] conv1 -> conv1
I0524 00:24:14.052958  8498 net.cpp:150] Setting up conv1
I0524 00:24:14.053006  8498 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 00:24:14.053017  8498 net.cpp:165] Memory required for data: 21131880
I0524 00:24:14.053045  8498 layer_factory.hpp:77] Creating layer relu1
I0524 00:24:14.053066  8498 net.cpp:106] Creating Layer relu1
I0524 00:24:14.053077  8498 net.cpp:454] relu1 <- conv1
I0524 00:24:14.053092  8498 net.cpp:397] relu1 -> conv1 (in-place)
I0524 00:24:14.053601  8498 net.cpp:150] Setting up relu1
I0524 00:24:14.053618  8498 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 00:24:14.053628  8498 net.cpp:165] Memory required for data: 40485480
I0524 00:24:14.053639  8498 layer_factory.hpp:77] Creating layer pool1
I0524 00:24:14.053664  8498 net.cpp:106] Creating Layer pool1
I0524 00:24:14.053674  8498 net.cpp:454] pool1 <- conv1
I0524 00:24:14.053689  8498 net.cpp:411] pool1 -> pool1
I0524 00:24:14.053768  8498 net.cpp:150] Setting up pool1
I0524 00:24:14.053782  8498 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0524 00:24:14.053792  8498 net.cpp:165] Memory required for data: 50162280
I0524 00:24:14.053803  8498 layer_factory.hpp:77] Creating layer conv2
I0524 00:24:14.053825  8498 net.cpp:106] Creating Layer conv2
I0524 00:24:14.053838  8498 net.cpp:454] conv2 <- pool1
I0524 00:24:14.053850  8498 net.cpp:411] conv2 -> conv2
I0524 00:24:14.056589  8498 net.cpp:150] Setting up conv2
I0524 00:24:14.056617  8498 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 00:24:14.056627  8498 net.cpp:165] Memory required for data: 64072680
I0524 00:24:14.056648  8498 layer_factory.hpp:77] Creating layer relu2
I0524 00:24:14.056663  8498 net.cpp:106] Creating Layer relu2
I0524 00:24:14.056673  8498 net.cpp:454] relu2 <- conv2
I0524 00:24:14.056685  8498 net.cpp:397] relu2 -> conv2 (in-place)
I0524 00:24:14.057014  8498 net.cpp:150] Setting up relu2
I0524 00:24:14.057029  8498 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 00:24:14.057039  8498 net.cpp:165] Memory required for data: 77983080
I0524 00:24:14.057049  8498 layer_factory.hpp:77] Creating layer pool2
I0524 00:24:14.057061  8498 net.cpp:106] Creating Layer pool2
I0524 00:24:14.057071  8498 net.cpp:454] pool2 <- conv2
I0524 00:24:14.057085  8498 net.cpp:411] pool2 -> pool2
I0524 00:24:14.057165  8498 net.cpp:150] Setting up pool2
I0524 00:24:14.057179  8498 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0524 00:24:14.057189  8498 net.cpp:165] Memory required for data: 84938280
I0524 00:24:14.057198  8498 layer_factory.hpp:77] Creating layer conv3
I0524 00:24:14.057215  8498 net.cpp:106] Creating Layer conv3
I0524 00:24:14.057226  8498 net.cpp:454] conv3 <- pool2
I0524 00:24:14.057240  8498 net.cpp:411] conv3 -> conv3
I0524 00:24:14.059161  8498 net.cpp:150] Setting up conv3
I0524 00:24:14.059185  8498 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 00:24:14.059196  8498 net.cpp:165] Memory required for data: 92527400
I0524 00:24:14.059216  8498 layer_factory.hpp:77] Creating layer relu3
I0524 00:24:14.059231  8498 net.cpp:106] Creating Layer relu3
I0524 00:24:14.059242  8498 net.cpp:454] relu3 <- conv3
I0524 00:24:14.059254  8498 net.cpp:397] relu3 -> conv3 (in-place)
I0524 00:24:14.059721  8498 net.cpp:150] Setting up relu3
I0524 00:24:14.059738  8498 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 00:24:14.059748  8498 net.cpp:165] Memory required for data: 100116520
I0524 00:24:14.059758  8498 layer_factory.hpp:77] Creating layer pool3
I0524 00:24:14.059772  8498 net.cpp:106] Creating Layer pool3
I0524 00:24:14.059780  8498 net.cpp:454] pool3 <- conv3
I0524 00:24:14.059793  8498 net.cpp:411] pool3 -> pool3
I0524 00:24:14.059860  8498 net.cpp:150] Setting up pool3
I0524 00:24:14.059875  8498 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0524 00:24:14.059883  8498 net.cpp:165] Memory required for data: 103911080
I0524 00:24:14.059891  8498 layer_factory.hpp:77] Creating layer conv4
I0524 00:24:14.059909  8498 net.cpp:106] Creating Layer conv4
I0524 00:24:14.059921  8498 net.cpp:454] conv4 <- pool3
I0524 00:24:14.059933  8498 net.cpp:411] conv4 -> conv4
I0524 00:24:14.062721  8498 net.cpp:150] Setting up conv4
I0524 00:24:14.062750  8498 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 00:24:14.062762  8498 net.cpp:165] Memory required for data: 106451240
I0524 00:24:14.062777  8498 layer_factory.hpp:77] Creating layer relu4
I0524 00:24:14.062791  8498 net.cpp:106] Creating Layer relu4
I0524 00:24:14.062801  8498 net.cpp:454] relu4 <- conv4
I0524 00:24:14.062814  8498 net.cpp:397] relu4 -> conv4 (in-place)
I0524 00:24:14.063290  8498 net.cpp:150] Setting up relu4
I0524 00:24:14.063308  8498 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 00:24:14.063318  8498 net.cpp:165] Memory required for data: 108991400
I0524 00:24:14.063328  8498 layer_factory.hpp:77] Creating layer pool4
I0524 00:24:14.063340  8498 net.cpp:106] Creating Layer pool4
I0524 00:24:14.063350  8498 net.cpp:454] pool4 <- conv4
I0524 00:24:14.063364  8498 net.cpp:411] pool4 -> pool4
I0524 00:24:14.063431  8498 net.cpp:150] Setting up pool4
I0524 00:24:14.063444  8498 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0524 00:24:14.063455  8498 net.cpp:165] Memory required for data: 110261480
I0524 00:24:14.063465  8498 layer_factory.hpp:77] Creating layer ip1
I0524 00:24:14.063485  8498 net.cpp:106] Creating Layer ip1
I0524 00:24:14.063496  8498 net.cpp:454] ip1 <- pool4
I0524 00:24:14.063508  8498 net.cpp:411] ip1 -> ip1
I0524 00:24:14.078999  8498 net.cpp:150] Setting up ip1
I0524 00:24:14.079026  8498 net.cpp:157] Top shape: 70 196 (13720)
I0524 00:24:14.079040  8498 net.cpp:165] Memory required for data: 110316360
I0524 00:24:14.079061  8498 layer_factory.hpp:77] Creating layer relu5
I0524 00:24:14.079077  8498 net.cpp:106] Creating Layer relu5
I0524 00:24:14.079087  8498 net.cpp:454] relu5 <- ip1
I0524 00:24:14.079100  8498 net.cpp:397] relu5 -> ip1 (in-place)
I0524 00:24:14.079442  8498 net.cpp:150] Setting up relu5
I0524 00:24:14.079457  8498 net.cpp:157] Top shape: 70 196 (13720)
I0524 00:24:14.079468  8498 net.cpp:165] Memory required for data: 110371240
I0524 00:24:14.079478  8498 layer_factory.hpp:77] Creating layer drop1
I0524 00:24:14.079499  8498 net.cpp:106] Creating Layer drop1
I0524 00:24:14.079510  8498 net.cpp:454] drop1 <- ip1
I0524 00:24:14.079522  8498 net.cpp:397] drop1 -> ip1 (in-place)
I0524 00:24:14.079583  8498 net.cpp:150] Setting up drop1
I0524 00:24:14.079597  8498 net.cpp:157] Top shape: 70 196 (13720)
I0524 00:24:14.079607  8498 net.cpp:165] Memory required for data: 110426120
I0524 00:24:14.079617  8498 layer_factory.hpp:77] Creating layer ip2
I0524 00:24:14.079635  8498 net.cpp:106] Creating Layer ip2
I0524 00:24:14.079646  8498 net.cpp:454] ip2 <- ip1
I0524 00:24:14.079659  8498 net.cpp:411] ip2 -> ip2
I0524 00:24:14.080121  8498 net.cpp:150] Setting up ip2
I0524 00:24:14.080133  8498 net.cpp:157] Top shape: 70 98 (6860)
I0524 00:24:14.080143  8498 net.cpp:165] Memory required for data: 110453560
I0524 00:24:14.080158  8498 layer_factory.hpp:77] Creating layer relu6
I0524 00:24:14.080170  8498 net.cpp:106] Creating Layer relu6
I0524 00:24:14.080180  8498 net.cpp:454] relu6 <- ip2
I0524 00:24:14.080193  8498 net.cpp:397] relu6 -> ip2 (in-place)
I0524 00:24:14.080704  8498 net.cpp:150] Setting up relu6
I0524 00:24:14.080721  8498 net.cpp:157] Top shape: 70 98 (6860)
I0524 00:24:14.080731  8498 net.cpp:165] Memory required for data: 110481000
I0524 00:24:14.080744  8498 layer_factory.hpp:77] Creating layer drop2
I0524 00:24:14.080756  8498 net.cpp:106] Creating Layer drop2
I0524 00:24:14.080766  8498 net.cpp:454] drop2 <- ip2
I0524 00:24:14.080780  8498 net.cpp:397] drop2 -> ip2 (in-place)
I0524 00:24:14.080821  8498 net.cpp:150] Setting up drop2
I0524 00:24:14.080835  8498 net.cpp:157] Top shape: 70 98 (6860)
I0524 00:24:14.080845  8498 net.cpp:165] Memory required for data: 110508440
I0524 00:24:14.080855  8498 layer_factory.hpp:77] Creating layer ip3
I0524 00:24:14.080868  8498 net.cpp:106] Creating Layer ip3
I0524 00:24:14.080878  8498 net.cpp:454] ip3 <- ip2
I0524 00:24:14.080889  8498 net.cpp:411] ip3 -> ip3
I0524 00:24:14.081099  8498 net.cpp:150] Setting up ip3
I0524 00:24:14.081111  8498 net.cpp:157] Top shape: 70 11 (770)
I0524 00:24:14.081121  8498 net.cpp:165] Memory required for data: 110511520
I0524 00:24:14.081136  8498 layer_factory.hpp:77] Creating layer drop3
I0524 00:24:14.081149  8498 net.cpp:106] Creating Layer drop3
I0524 00:24:14.081159  8498 net.cpp:454] drop3 <- ip3
I0524 00:24:14.081171  8498 net.cpp:397] drop3 -> ip3 (in-place)
I0524 00:24:14.081210  8498 net.cpp:150] Setting up drop3
I0524 00:24:14.081223  8498 net.cpp:157] Top shape: 70 11 (770)
I0524 00:24:14.081233  8498 net.cpp:165] Memory required for data: 110514600
I0524 00:24:14.081243  8498 layer_factory.hpp:77] Creating layer loss
I0524 00:24:14.081262  8498 net.cpp:106] Creating Layer loss
I0524 00:24:14.081272  8498 net.cpp:454] loss <- ip3
I0524 00:24:14.081281  8498 net.cpp:454] loss <- label
I0524 00:24:14.081295  8498 net.cpp:411] loss -> loss
I0524 00:24:14.081312  8498 layer_factory.hpp:77] Creating layer loss
I0524 00:24:14.081961  8498 net.cpp:150] Setting up loss
I0524 00:24:14.081982  8498 net.cpp:157] Top shape: (1)
I0524 00:24:14.081996  8498 net.cpp:160]     with loss weight 1
I0524 00:24:14.082038  8498 net.cpp:165] Memory required for data: 110514604
I0524 00:24:14.082049  8498 net.cpp:226] loss needs backward computation.
I0524 00:24:14.082061  8498 net.cpp:226] drop3 needs backward computation.
I0524 00:24:14.082068  8498 net.cpp:226] ip3 needs backward computation.
I0524 00:24:14.082079  8498 net.cpp:226] drop2 needs backward computation.
I0524 00:24:14.082089  8498 net.cpp:226] relu6 needs backward computation.
I0524 00:24:14.082099  8498 net.cpp:226] ip2 needs backward computation.
I0524 00:24:14.082109  8498 net.cpp:226] drop1 needs backward computation.
I0524 00:24:14.082119  8498 net.cpp:226] relu5 needs backward computation.
I0524 00:24:14.082129  8498 net.cpp:226] ip1 needs backward computation.
I0524 00:24:14.082139  8498 net.cpp:226] pool4 needs backward computation.
I0524 00:24:14.082149  8498 net.cpp:226] relu4 needs backward computation.
I0524 00:24:14.082159  8498 net.cpp:226] conv4 needs backward computation.
I0524 00:24:14.082170  8498 net.cpp:226] pool3 needs backward computation.
I0524 00:24:14.082180  8498 net.cpp:226] relu3 needs backward computation.
I0524 00:24:14.082198  8498 net.cpp:226] conv3 needs backward computation.
I0524 00:24:14.082209  8498 net.cpp:226] pool2 needs backward computation.
I0524 00:24:14.082221  8498 net.cpp:226] relu2 needs backward computation.
I0524 00:24:14.082231  8498 net.cpp:226] conv2 needs backward computation.
I0524 00:24:14.082242  8498 net.cpp:226] pool1 needs backward computation.
I0524 00:24:14.082252  8498 net.cpp:226] relu1 needs backward computation.
I0524 00:24:14.082262  8498 net.cpp:226] conv1 needs backward computation.
I0524 00:24:14.082273  8498 net.cpp:228] data_hdf5 does not need backward computation.
I0524 00:24:14.082283  8498 net.cpp:270] This network produces output loss
I0524 00:24:14.082306  8498 net.cpp:283] Network initialization done.
I0524 00:24:14.083926  8498 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876.prototxt
I0524 00:24:14.083997  8498 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0524 00:24:14.084354  8498 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0524 00:24:14.084543  8498 layer_factory.hpp:77] Creating layer data_hdf5
I0524 00:24:14.084558  8498 net.cpp:106] Creating Layer data_hdf5
I0524 00:24:14.084571  8498 net.cpp:411] data_hdf5 -> data
I0524 00:24:14.084588  8498 net.cpp:411] data_hdf5 -> label
I0524 00:24:14.084604  8498 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0524 00:24:14.085742  8498 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0524 00:24:35.421710  8498 net.cpp:150] Setting up data_hdf5
I0524 00:24:35.421878  8498 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0524 00:24:35.421893  8498 net.cpp:157] Top shape: 70 (70)
I0524 00:24:35.421905  8498 net.cpp:165] Memory required for data: 1778280
I0524 00:24:35.421919  8498 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0524 00:24:35.421947  8498 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0524 00:24:35.421957  8498 net.cpp:454] label_data_hdf5_1_split <- label
I0524 00:24:35.421973  8498 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0524 00:24:35.421994  8498 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0524 00:24:35.422067  8498 net.cpp:150] Setting up label_data_hdf5_1_split
I0524 00:24:35.422081  8498 net.cpp:157] Top shape: 70 (70)
I0524 00:24:35.422092  8498 net.cpp:157] Top shape: 70 (70)
I0524 00:24:35.422102  8498 net.cpp:165] Memory required for data: 1778840
I0524 00:24:35.422112  8498 layer_factory.hpp:77] Creating layer conv1
I0524 00:24:35.422134  8498 net.cpp:106] Creating Layer conv1
I0524 00:24:35.422145  8498 net.cpp:454] conv1 <- data
I0524 00:24:35.422159  8498 net.cpp:411] conv1 -> conv1
I0524 00:24:35.424067  8498 net.cpp:150] Setting up conv1
I0524 00:24:35.424091  8498 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 00:24:35.424103  8498 net.cpp:165] Memory required for data: 21132440
I0524 00:24:35.424124  8498 layer_factory.hpp:77] Creating layer relu1
I0524 00:24:35.424139  8498 net.cpp:106] Creating Layer relu1
I0524 00:24:35.424149  8498 net.cpp:454] relu1 <- conv1
I0524 00:24:35.424161  8498 net.cpp:397] relu1 -> conv1 (in-place)
I0524 00:24:35.424654  8498 net.cpp:150] Setting up relu1
I0524 00:24:35.424671  8498 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0524 00:24:35.424681  8498 net.cpp:165] Memory required for data: 40486040
I0524 00:24:35.424692  8498 layer_factory.hpp:77] Creating layer pool1
I0524 00:24:35.424708  8498 net.cpp:106] Creating Layer pool1
I0524 00:24:35.424718  8498 net.cpp:454] pool1 <- conv1
I0524 00:24:35.424731  8498 net.cpp:411] pool1 -> pool1
I0524 00:24:35.424805  8498 net.cpp:150] Setting up pool1
I0524 00:24:35.424818  8498 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0524 00:24:35.424829  8498 net.cpp:165] Memory required for data: 50162840
I0524 00:24:35.424840  8498 layer_factory.hpp:77] Creating layer conv2
I0524 00:24:35.424859  8498 net.cpp:106] Creating Layer conv2
I0524 00:24:35.424868  8498 net.cpp:454] conv2 <- pool1
I0524 00:24:35.424881  8498 net.cpp:411] conv2 -> conv2
I0524 00:24:35.426803  8498 net.cpp:150] Setting up conv2
I0524 00:24:35.426826  8498 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 00:24:35.426838  8498 net.cpp:165] Memory required for data: 64073240
I0524 00:24:35.426856  8498 layer_factory.hpp:77] Creating layer relu2
I0524 00:24:35.426870  8498 net.cpp:106] Creating Layer relu2
I0524 00:24:35.426880  8498 net.cpp:454] relu2 <- conv2
I0524 00:24:35.426893  8498 net.cpp:397] relu2 -> conv2 (in-place)
I0524 00:24:35.427225  8498 net.cpp:150] Setting up relu2
I0524 00:24:35.427239  8498 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0524 00:24:35.427250  8498 net.cpp:165] Memory required for data: 77983640
I0524 00:24:35.427260  8498 layer_factory.hpp:77] Creating layer pool2
I0524 00:24:35.427273  8498 net.cpp:106] Creating Layer pool2
I0524 00:24:35.427284  8498 net.cpp:454] pool2 <- conv2
I0524 00:24:35.427296  8498 net.cpp:411] pool2 -> pool2
I0524 00:24:35.427368  8498 net.cpp:150] Setting up pool2
I0524 00:24:35.427381  8498 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0524 00:24:35.427392  8498 net.cpp:165] Memory required for data: 84938840
I0524 00:24:35.427400  8498 layer_factory.hpp:77] Creating layer conv3
I0524 00:24:35.427420  8498 net.cpp:106] Creating Layer conv3
I0524 00:24:35.427431  8498 net.cpp:454] conv3 <- pool2
I0524 00:24:35.427446  8498 net.cpp:411] conv3 -> conv3
I0524 00:24:35.429411  8498 net.cpp:150] Setting up conv3
I0524 00:24:35.429435  8498 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 00:24:35.429446  8498 net.cpp:165] Memory required for data: 92527960
I0524 00:24:35.429481  8498 layer_factory.hpp:77] Creating layer relu3
I0524 00:24:35.429493  8498 net.cpp:106] Creating Layer relu3
I0524 00:24:35.429504  8498 net.cpp:454] relu3 <- conv3
I0524 00:24:35.429517  8498 net.cpp:397] relu3 -> conv3 (in-place)
I0524 00:24:35.429996  8498 net.cpp:150] Setting up relu3
I0524 00:24:35.430011  8498 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0524 00:24:35.430022  8498 net.cpp:165] Memory required for data: 100117080
I0524 00:24:35.430032  8498 layer_factory.hpp:77] Creating layer pool3
I0524 00:24:35.430044  8498 net.cpp:106] Creating Layer pool3
I0524 00:24:35.430055  8498 net.cpp:454] pool3 <- conv3
I0524 00:24:35.430068  8498 net.cpp:411] pool3 -> pool3
I0524 00:24:35.430140  8498 net.cpp:150] Setting up pool3
I0524 00:24:35.430153  8498 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0524 00:24:35.430162  8498 net.cpp:165] Memory required for data: 103911640
I0524 00:24:35.430172  8498 layer_factory.hpp:77] Creating layer conv4
I0524 00:24:35.430191  8498 net.cpp:106] Creating Layer conv4
I0524 00:24:35.430202  8498 net.cpp:454] conv4 <- pool3
I0524 00:24:35.430214  8498 net.cpp:411] conv4 -> conv4
I0524 00:24:35.432260  8498 net.cpp:150] Setting up conv4
I0524 00:24:35.432282  8498 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 00:24:35.432293  8498 net.cpp:165] Memory required for data: 106451800
I0524 00:24:35.432309  8498 layer_factory.hpp:77] Creating layer relu4
I0524 00:24:35.432323  8498 net.cpp:106] Creating Layer relu4
I0524 00:24:35.432333  8498 net.cpp:454] relu4 <- conv4
I0524 00:24:35.432345  8498 net.cpp:397] relu4 -> conv4 (in-place)
I0524 00:24:35.432813  8498 net.cpp:150] Setting up relu4
I0524 00:24:35.432834  8498 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0524 00:24:35.432844  8498 net.cpp:165] Memory required for data: 108991960
I0524 00:24:35.432852  8498 layer_factory.hpp:77] Creating layer pool4
I0524 00:24:35.432863  8498 net.cpp:106] Creating Layer pool4
I0524 00:24:35.432873  8498 net.cpp:454] pool4 <- conv4
I0524 00:24:35.432884  8498 net.cpp:411] pool4 -> pool4
I0524 00:24:35.432957  8498 net.cpp:150] Setting up pool4
I0524 00:24:35.432971  8498 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0524 00:24:35.432981  8498 net.cpp:165] Memory required for data: 110262040
I0524 00:24:35.432991  8498 layer_factory.hpp:77] Creating layer ip1
I0524 00:24:35.433006  8498 net.cpp:106] Creating Layer ip1
I0524 00:24:35.433015  8498 net.cpp:454] ip1 <- pool4
I0524 00:24:35.433029  8498 net.cpp:411] ip1 -> ip1
I0524 00:24:35.448539  8498 net.cpp:150] Setting up ip1
I0524 00:24:35.448566  8498 net.cpp:157] Top shape: 70 196 (13720)
I0524 00:24:35.448577  8498 net.cpp:165] Memory required for data: 110316920
I0524 00:24:35.448599  8498 layer_factory.hpp:77] Creating layer relu5
I0524 00:24:35.448616  8498 net.cpp:106] Creating Layer relu5
I0524 00:24:35.448626  8498 net.cpp:454] relu5 <- ip1
I0524 00:24:35.448639  8498 net.cpp:397] relu5 -> ip1 (in-place)
I0524 00:24:35.448983  8498 net.cpp:150] Setting up relu5
I0524 00:24:35.448998  8498 net.cpp:157] Top shape: 70 196 (13720)
I0524 00:24:35.449008  8498 net.cpp:165] Memory required for data: 110371800
I0524 00:24:35.449018  8498 layer_factory.hpp:77] Creating layer drop1
I0524 00:24:35.449038  8498 net.cpp:106] Creating Layer drop1
I0524 00:24:35.449048  8498 net.cpp:454] drop1 <- ip1
I0524 00:24:35.449060  8498 net.cpp:397] drop1 -> ip1 (in-place)
I0524 00:24:35.449107  8498 net.cpp:150] Setting up drop1
I0524 00:24:35.449120  8498 net.cpp:157] Top shape: 70 196 (13720)
I0524 00:24:35.449131  8498 net.cpp:165] Memory required for data: 110426680
I0524 00:24:35.449141  8498 layer_factory.hpp:77] Creating layer ip2
I0524 00:24:35.449156  8498 net.cpp:106] Creating Layer ip2
I0524 00:24:35.449165  8498 net.cpp:454] ip2 <- ip1
I0524 00:24:35.449179  8498 net.cpp:411] ip2 -> ip2
I0524 00:24:35.449669  8498 net.cpp:150] Setting up ip2
I0524 00:24:35.449682  8498 net.cpp:157] Top shape: 70 98 (6860)
I0524 00:24:35.449692  8498 net.cpp:165] Memory required for data: 110454120
I0524 00:24:35.449707  8498 layer_factory.hpp:77] Creating layer relu6
I0524 00:24:35.449733  8498 net.cpp:106] Creating Layer relu6
I0524 00:24:35.449743  8498 net.cpp:454] relu6 <- ip2
I0524 00:24:35.449755  8498 net.cpp:397] relu6 -> ip2 (in-place)
I0524 00:24:35.450289  8498 net.cpp:150] Setting up relu6
I0524 00:24:35.450310  8498 net.cpp:157] Top shape: 70 98 (6860)
I0524 00:24:35.450320  8498 net.cpp:165] Memory required for data: 110481560
I0524 00:24:35.450330  8498 layer_factory.hpp:77] Creating layer drop2
I0524 00:24:35.450345  8498 net.cpp:106] Creating Layer drop2
I0524 00:24:35.450355  8498 net.cpp:454] drop2 <- ip2
I0524 00:24:35.450367  8498 net.cpp:397] drop2 -> ip2 (in-place)
I0524 00:24:35.450412  8498 net.cpp:150] Setting up drop2
I0524 00:24:35.450424  8498 net.cpp:157] Top shape: 70 98 (6860)
I0524 00:24:35.450434  8498 net.cpp:165] Memory required for data: 110509000
I0524 00:24:35.450444  8498 layer_factory.hpp:77] Creating layer ip3
I0524 00:24:35.450459  8498 net.cpp:106] Creating Layer ip3
I0524 00:24:35.450469  8498 net.cpp:454] ip3 <- ip2
I0524 00:24:35.450482  8498 net.cpp:411] ip3 -> ip3
I0524 00:24:35.450705  8498 net.cpp:150] Setting up ip3
I0524 00:24:35.450717  8498 net.cpp:157] Top shape: 70 11 (770)
I0524 00:24:35.450726  8498 net.cpp:165] Memory required for data: 110512080
I0524 00:24:35.450742  8498 layer_factory.hpp:77] Creating layer drop3
I0524 00:24:35.450755  8498 net.cpp:106] Creating Layer drop3
I0524 00:24:35.450765  8498 net.cpp:454] drop3 <- ip3
I0524 00:24:35.450778  8498 net.cpp:397] drop3 -> ip3 (in-place)
I0524 00:24:35.450819  8498 net.cpp:150] Setting up drop3
I0524 00:24:35.450834  8498 net.cpp:157] Top shape: 70 11 (770)
I0524 00:24:35.450842  8498 net.cpp:165] Memory required for data: 110515160
I0524 00:24:35.450852  8498 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0524 00:24:35.450865  8498 net.cpp:106] Creating Layer ip3_drop3_0_split
I0524 00:24:35.450875  8498 net.cpp:454] ip3_drop3_0_split <- ip3
I0524 00:24:35.450888  8498 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0524 00:24:35.450904  8498 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0524 00:24:35.450978  8498 net.cpp:150] Setting up ip3_drop3_0_split
I0524 00:24:35.450991  8498 net.cpp:157] Top shape: 70 11 (770)
I0524 00:24:35.451004  8498 net.cpp:157] Top shape: 70 11 (770)
I0524 00:24:35.451014  8498 net.cpp:165] Memory required for data: 110521320
I0524 00:24:35.451025  8498 layer_factory.hpp:77] Creating layer accuracy
I0524 00:24:35.451045  8498 net.cpp:106] Creating Layer accuracy
I0524 00:24:35.451056  8498 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0524 00:24:35.451066  8498 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0524 00:24:35.451081  8498 net.cpp:411] accuracy -> accuracy
I0524 00:24:35.451104  8498 net.cpp:150] Setting up accuracy
I0524 00:24:35.451117  8498 net.cpp:157] Top shape: (1)
I0524 00:24:35.451127  8498 net.cpp:165] Memory required for data: 110521324
I0524 00:24:35.451136  8498 layer_factory.hpp:77] Creating layer loss
I0524 00:24:35.451149  8498 net.cpp:106] Creating Layer loss
I0524 00:24:35.451159  8498 net.cpp:454] loss <- ip3_drop3_0_split_1
I0524 00:24:35.451170  8498 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0524 00:24:35.451184  8498 net.cpp:411] loss -> loss
I0524 00:24:35.451200  8498 layer_factory.hpp:77] Creating layer loss
I0524 00:24:35.451689  8498 net.cpp:150] Setting up loss
I0524 00:24:35.451701  8498 net.cpp:157] Top shape: (1)
I0524 00:24:35.451711  8498 net.cpp:160]     with loss weight 1
I0524 00:24:35.451730  8498 net.cpp:165] Memory required for data: 110521328
I0524 00:24:35.451740  8498 net.cpp:226] loss needs backward computation.
I0524 00:24:35.451751  8498 net.cpp:228] accuracy does not need backward computation.
I0524 00:24:35.451762  8498 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0524 00:24:35.451773  8498 net.cpp:226] drop3 needs backward computation.
I0524 00:24:35.451784  8498 net.cpp:226] ip3 needs backward computation.
I0524 00:24:35.451794  8498 net.cpp:226] drop2 needs backward computation.
I0524 00:24:35.451804  8498 net.cpp:226] relu6 needs backward computation.
I0524 00:24:35.451822  8498 net.cpp:226] ip2 needs backward computation.
I0524 00:24:35.451833  8498 net.cpp:226] drop1 needs backward computation.
I0524 00:24:35.451843  8498 net.cpp:226] relu5 needs backward computation.
I0524 00:24:35.451851  8498 net.cpp:226] ip1 needs backward computation.
I0524 00:24:35.451861  8498 net.cpp:226] pool4 needs backward computation.
I0524 00:24:35.451871  8498 net.cpp:226] relu4 needs backward computation.
I0524 00:24:35.451881  8498 net.cpp:226] conv4 needs backward computation.
I0524 00:24:35.451891  8498 net.cpp:226] pool3 needs backward computation.
I0524 00:24:35.451902  8498 net.cpp:226] relu3 needs backward computation.
I0524 00:24:35.451912  8498 net.cpp:226] conv3 needs backward computation.
I0524 00:24:35.451923  8498 net.cpp:226] pool2 needs backward computation.
I0524 00:24:35.451933  8498 net.cpp:226] relu2 needs backward computation.
I0524 00:24:35.451943  8498 net.cpp:226] conv2 needs backward computation.
I0524 00:24:35.451954  8498 net.cpp:226] pool1 needs backward computation.
I0524 00:24:35.451964  8498 net.cpp:226] relu1 needs backward computation.
I0524 00:24:35.451974  8498 net.cpp:226] conv1 needs backward computation.
I0524 00:24:35.451985  8498 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0524 00:24:35.451997  8498 net.cpp:228] data_hdf5 does not need backward computation.
I0524 00:24:35.452008  8498 net.cpp:270] This network produces output accuracy
I0524 00:24:35.452018  8498 net.cpp:270] This network produces output loss
I0524 00:24:35.452046  8498 net.cpp:283] Network initialization done.
I0524 00:24:35.452180  8498 solver.cpp:60] Solver scaffolding done.
I0524 00:24:35.453310  8498 caffe.cpp:212] Starting Optimization
I0524 00:24:35.453327  8498 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0524 00:24:35.453341  8498 solver.cpp:289] Learning Rate Policy: fixed
I0524 00:24:35.454566  8498 solver.cpp:341] Iteration 0, Testing net (#0)
I0524 00:25:24.318959  8498 solver.cpp:409]     Test net output #0: accuracy = 0.101741
I0524 00:25:24.319121  8498 solver.cpp:409]     Test net output #1: loss = 2.39758 (* 1 = 2.39758 loss)
I0524 00:25:24.347010  8498 solver.cpp:237] Iteration 0, loss = 2.3944
I0524 00:25:24.347046  8498 solver.cpp:253]     Train net output #0: loss = 2.3944 (* 1 = 2.3944 loss)
I0524 00:25:24.347064  8498 sgd_solver.cpp:106] Iteration 0, lr = 0.002
I0524 00:25:33.230515  8498 solver.cpp:237] Iteration 214, loss = 2.24612
I0524 00:25:33.230551  8498 solver.cpp:253]     Train net output #0: loss = 2.24612 (* 1 = 2.24612 loss)
I0524 00:25:33.230567  8498 sgd_solver.cpp:106] Iteration 214, lr = 0.002
I0524 00:25:42.111419  8498 solver.cpp:237] Iteration 428, loss = 2.15746
I0524 00:25:42.111466  8498 solver.cpp:253]     Train net output #0: loss = 2.15746 (* 1 = 2.15746 loss)
I0524 00:25:42.111481  8498 sgd_solver.cpp:106] Iteration 428, lr = 0.002
I0524 00:25:50.995697  8498 solver.cpp:237] Iteration 642, loss = 2.07679
I0524 00:25:50.995733  8498 solver.cpp:253]     Train net output #0: loss = 2.07679 (* 1 = 2.07679 loss)
I0524 00:25:50.995745  8498 sgd_solver.cpp:106] Iteration 642, lr = 0.002
I0524 00:25:59.879922  8498 solver.cpp:237] Iteration 856, loss = 1.89335
I0524 00:25:59.880080  8498 solver.cpp:253]     Train net output #0: loss = 1.89335 (* 1 = 1.89335 loss)
I0524 00:25:59.880095  8498 sgd_solver.cpp:106] Iteration 856, lr = 0.002
I0524 00:26:08.762192  8498 solver.cpp:237] Iteration 1070, loss = 1.89197
I0524 00:26:08.762226  8498 solver.cpp:253]     Train net output #0: loss = 1.89197 (* 1 = 1.89197 loss)
I0524 00:26:08.762243  8498 sgd_solver.cpp:106] Iteration 1070, lr = 0.002
I0524 00:26:17.641530  8498 solver.cpp:237] Iteration 1284, loss = 2.01337
I0524 00:26:17.641564  8498 solver.cpp:253]     Train net output #0: loss = 2.01337 (* 1 = 2.01337 loss)
I0524 00:26:17.641582  8498 sgd_solver.cpp:106] Iteration 1284, lr = 0.002
I0524 00:26:48.656541  8498 solver.cpp:237] Iteration 1498, loss = 1.86076
I0524 00:26:48.656704  8498 solver.cpp:253]     Train net output #0: loss = 1.86076 (* 1 = 1.86076 loss)
I0524 00:26:48.656719  8498 sgd_solver.cpp:106] Iteration 1498, lr = 0.002
I0524 00:26:57.545735  8498 solver.cpp:237] Iteration 1712, loss = 1.66283
I0524 00:26:57.545770  8498 solver.cpp:253]     Train net output #0: loss = 1.66283 (* 1 = 1.66283 loss)
I0524 00:26:57.545788  8498 sgd_solver.cpp:106] Iteration 1712, lr = 0.002
I0524 00:27:06.423578  8498 solver.cpp:237] Iteration 1926, loss = 1.63307
I0524 00:27:06.423614  8498 solver.cpp:253]     Train net output #0: loss = 1.63307 (* 1 = 1.63307 loss)
I0524 00:27:06.423629  8498 sgd_solver.cpp:106] Iteration 1926, lr = 0.002
I0524 00:27:15.310659  8498 solver.cpp:237] Iteration 2140, loss = 2.15351
I0524 00:27:15.310699  8498 solver.cpp:253]     Train net output #0: loss = 2.15351 (* 1 = 2.15351 loss)
I0524 00:27:15.310719  8498 sgd_solver.cpp:106] Iteration 2140, lr = 0.002
I0524 00:27:15.352980  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_2142.caffemodel
I0524 00:27:15.423214  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_2142.solverstate
I0524 00:27:24.263087  8498 solver.cpp:237] Iteration 2354, loss = 1.6781
I0524 00:27:24.263242  8498 solver.cpp:253]     Train net output #0: loss = 1.6781 (* 1 = 1.6781 loss)
I0524 00:27:24.263257  8498 sgd_solver.cpp:106] Iteration 2354, lr = 0.002
I0524 00:27:33.159302  8498 solver.cpp:237] Iteration 2568, loss = 1.68433
I0524 00:27:33.159337  8498 solver.cpp:253]     Train net output #0: loss = 1.68433 (* 1 = 1.68433 loss)
I0524 00:27:33.159353  8498 sgd_solver.cpp:106] Iteration 2568, lr = 0.002
I0524 00:27:42.039433  8498 solver.cpp:237] Iteration 2782, loss = 1.71082
I0524 00:27:42.039477  8498 solver.cpp:253]     Train net output #0: loss = 1.71082 (* 1 = 1.71082 loss)
I0524 00:27:42.039495  8498 sgd_solver.cpp:106] Iteration 2782, lr = 0.002
I0524 00:28:13.078697  8498 solver.cpp:237] Iteration 2996, loss = 1.49035
I0524 00:28:13.078855  8498 solver.cpp:253]     Train net output #0: loss = 1.49035 (* 1 = 1.49035 loss)
I0524 00:28:13.078869  8498 sgd_solver.cpp:106] Iteration 2996, lr = 0.002
I0524 00:28:21.960402  8498 solver.cpp:237] Iteration 3210, loss = 1.76529
I0524 00:28:21.960438  8498 solver.cpp:253]     Train net output #0: loss = 1.76529 (* 1 = 1.76529 loss)
I0524 00:28:21.960453  8498 sgd_solver.cpp:106] Iteration 3210, lr = 0.002
I0524 00:28:30.840114  8498 solver.cpp:237] Iteration 3424, loss = 1.37092
I0524 00:28:30.840153  8498 solver.cpp:253]     Train net output #0: loss = 1.37092 (* 1 = 1.37092 loss)
I0524 00:28:30.840175  8498 sgd_solver.cpp:106] Iteration 3424, lr = 0.002
I0524 00:28:39.730269  8498 solver.cpp:237] Iteration 3638, loss = 1.5902
I0524 00:28:39.730304  8498 solver.cpp:253]     Train net output #0: loss = 1.5902 (* 1 = 1.5902 loss)
I0524 00:28:39.730320  8498 sgd_solver.cpp:106] Iteration 3638, lr = 0.002
I0524 00:28:48.612105  8498 solver.cpp:237] Iteration 3852, loss = 1.43911
I0524 00:28:48.612252  8498 solver.cpp:253]     Train net output #0: loss = 1.43911 (* 1 = 1.43911 loss)
I0524 00:28:48.612267  8498 sgd_solver.cpp:106] Iteration 3852, lr = 0.002
I0524 00:28:57.495772  8498 solver.cpp:237] Iteration 4066, loss = 1.68124
I0524 00:28:57.495806  8498 solver.cpp:253]     Train net output #0: loss = 1.68124 (* 1 = 1.68124 loss)
I0524 00:28:57.495827  8498 sgd_solver.cpp:106] Iteration 4066, lr = 0.002
I0524 00:29:06.381876  8498 solver.cpp:237] Iteration 4280, loss = 1.57034
I0524 00:29:06.381911  8498 solver.cpp:253]     Train net output #0: loss = 1.57034 (* 1 = 1.57034 loss)
I0524 00:29:06.381924  8498 sgd_solver.cpp:106] Iteration 4280, lr = 0.002
I0524 00:29:06.506744  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_4284.caffemodel
I0524 00:29:06.573041  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_4284.solverstate
I0524 00:29:06.612473  8498 solver.cpp:341] Iteration 4285, Testing net (#0)
I0524 00:29:54.530205  8498 solver.cpp:409]     Test net output #0: accuracy = 0.758212
I0524 00:29:54.530375  8498 solver.cpp:409]     Test net output #1: loss = 0.856235 (* 1 = 0.856235 loss)
I0524 00:30:25.364871  8498 solver.cpp:237] Iteration 4494, loss = 1.37761
I0524 00:30:25.365030  8498 solver.cpp:253]     Train net output #0: loss = 1.37761 (* 1 = 1.37761 loss)
I0524 00:30:25.365044  8498 sgd_solver.cpp:106] Iteration 4494, lr = 0.002
I0524 00:30:34.229693  8498 solver.cpp:237] Iteration 4708, loss = 1.58215
I0524 00:30:34.229738  8498 solver.cpp:253]     Train net output #0: loss = 1.58215 (* 1 = 1.58215 loss)
I0524 00:30:34.229756  8498 sgd_solver.cpp:106] Iteration 4708, lr = 0.002
I0524 00:30:43.098045  8498 solver.cpp:237] Iteration 4922, loss = 1.85834
I0524 00:30:43.098080  8498 solver.cpp:253]     Train net output #0: loss = 1.85834 (* 1 = 1.85834 loss)
I0524 00:30:43.098096  8498 sgd_solver.cpp:106] Iteration 4922, lr = 0.002
I0524 00:30:51.972249  8498 solver.cpp:237] Iteration 5136, loss = 1.52634
I0524 00:30:51.972283  8498 solver.cpp:253]     Train net output #0: loss = 1.52634 (* 1 = 1.52634 loss)
I0524 00:30:51.972301  8498 sgd_solver.cpp:106] Iteration 5136, lr = 0.002
I0524 00:31:00.843029  8498 solver.cpp:237] Iteration 5350, loss = 1.496
I0524 00:31:00.843178  8498 solver.cpp:253]     Train net output #0: loss = 1.496 (* 1 = 1.496 loss)
I0524 00:31:00.843192  8498 sgd_solver.cpp:106] Iteration 5350, lr = 0.002
I0524 00:31:09.715900  8498 solver.cpp:237] Iteration 5564, loss = 1.19603
I0524 00:31:09.715935  8498 solver.cpp:253]     Train net output #0: loss = 1.19603 (* 1 = 1.19603 loss)
I0524 00:31:09.715948  8498 sgd_solver.cpp:106] Iteration 5564, lr = 0.002
I0524 00:31:40.783773  8498 solver.cpp:237] Iteration 5778, loss = 1.50281
I0524 00:31:40.783939  8498 solver.cpp:253]     Train net output #0: loss = 1.50281 (* 1 = 1.50281 loss)
I0524 00:31:40.783956  8498 sgd_solver.cpp:106] Iteration 5778, lr = 0.002
I0524 00:31:49.650616  8498 solver.cpp:237] Iteration 5992, loss = 1.38927
I0524 00:31:49.650662  8498 solver.cpp:253]     Train net output #0: loss = 1.38927 (* 1 = 1.38927 loss)
I0524 00:31:49.650681  8498 sgd_solver.cpp:106] Iteration 5992, lr = 0.002
I0524 00:31:58.518726  8498 solver.cpp:237] Iteration 6206, loss = 1.59867
I0524 00:31:58.518762  8498 solver.cpp:253]     Train net output #0: loss = 1.59867 (* 1 = 1.59867 loss)
I0524 00:31:58.518779  8498 sgd_solver.cpp:106] Iteration 6206, lr = 0.002
I0524 00:32:07.387796  8498 solver.cpp:237] Iteration 6420, loss = 1.27062
I0524 00:32:07.387832  8498 solver.cpp:253]     Train net output #0: loss = 1.27062 (* 1 = 1.27062 loss)
I0524 00:32:07.387845  8498 sgd_solver.cpp:106] Iteration 6420, lr = 0.002
I0524 00:32:07.595161  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_6426.caffemodel
I0524 00:32:07.674011  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_6426.solverstate
I0524 00:32:16.342176  8498 solver.cpp:237] Iteration 6634, loss = 1.38437
I0524 00:32:16.342344  8498 solver.cpp:253]     Train net output #0: loss = 1.38437 (* 1 = 1.38437 loss)
I0524 00:32:16.342358  8498 sgd_solver.cpp:106] Iteration 6634, lr = 0.002
I0524 00:32:25.210250  8498 solver.cpp:237] Iteration 6848, loss = 1.43294
I0524 00:32:25.210285  8498 solver.cpp:253]     Train net output #0: loss = 1.43294 (* 1 = 1.43294 loss)
I0524 00:32:25.210302  8498 sgd_solver.cpp:106] Iteration 6848, lr = 0.002
I0524 00:32:34.077143  8498 solver.cpp:237] Iteration 7062, loss = 1.46541
I0524 00:32:34.077179  8498 solver.cpp:253]     Train net output #0: loss = 1.46541 (* 1 = 1.46541 loss)
I0524 00:32:34.077193  8498 sgd_solver.cpp:106] Iteration 7062, lr = 0.002
I0524 00:33:05.162866  8498 solver.cpp:237] Iteration 7276, loss = 1.62962
I0524 00:33:05.163030  8498 solver.cpp:253]     Train net output #0: loss = 1.62962 (* 1 = 1.62962 loss)
I0524 00:33:05.163046  8498 sgd_solver.cpp:106] Iteration 7276, lr = 0.002
I0524 00:33:14.028764  8498 solver.cpp:237] Iteration 7490, loss = 1.37907
I0524 00:33:14.028798  8498 solver.cpp:253]     Train net output #0: loss = 1.37907 (* 1 = 1.37907 loss)
I0524 00:33:14.028815  8498 sgd_solver.cpp:106] Iteration 7490, lr = 0.002
I0524 00:33:22.897330  8498 solver.cpp:237] Iteration 7704, loss = 1.40848
I0524 00:33:22.897363  8498 solver.cpp:253]     Train net output #0: loss = 1.40848 (* 1 = 1.40848 loss)
I0524 00:33:22.897382  8498 sgd_solver.cpp:106] Iteration 7704, lr = 0.002
I0524 00:33:31.764957  8498 solver.cpp:237] Iteration 7918, loss = 1.21448
I0524 00:33:31.764997  8498 solver.cpp:253]     Train net output #0: loss = 1.21448 (* 1 = 1.21448 loss)
I0524 00:33:31.765014  8498 sgd_solver.cpp:106] Iteration 7918, lr = 0.002
I0524 00:33:40.627748  8498 solver.cpp:237] Iteration 8132, loss = 1.28782
I0524 00:33:40.627881  8498 solver.cpp:253]     Train net output #0: loss = 1.28782 (* 1 = 1.28782 loss)
I0524 00:33:40.627893  8498 sgd_solver.cpp:106] Iteration 8132, lr = 0.002
I0524 00:33:49.497578  8498 solver.cpp:237] Iteration 8346, loss = 1.4462
I0524 00:33:49.497613  8498 solver.cpp:253]     Train net output #0: loss = 1.4462 (* 1 = 1.4462 loss)
I0524 00:33:49.497629  8498 sgd_solver.cpp:106] Iteration 8346, lr = 0.002
I0524 00:33:58.362444  8498 solver.cpp:237] Iteration 8560, loss = 1.40653
I0524 00:33:58.362483  8498 solver.cpp:253]     Train net output #0: loss = 1.40653 (* 1 = 1.40653 loss)
I0524 00:33:58.362504  8498 sgd_solver.cpp:106] Iteration 8560, lr = 0.002
I0524 00:33:58.652847  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_8568.caffemodel
I0524 00:33:58.730468  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_8568.solverstate
I0524 00:33:58.819764  8498 solver.cpp:341] Iteration 8570, Testing net (#0)
I0524 00:35:07.582902  8498 solver.cpp:409]     Test net output #0: accuracy = 0.814845
I0524 00:35:07.583072  8498 solver.cpp:409]     Test net output #1: loss = 0.699232 (* 1 = 0.699232 loss)
I0524 00:35:38.224195  8498 solver.cpp:237] Iteration 8774, loss = 1.20726
I0524 00:35:38.224357  8498 solver.cpp:253]     Train net output #0: loss = 1.20726 (* 1 = 1.20726 loss)
I0524 00:35:38.224372  8498 sgd_solver.cpp:106] Iteration 8774, lr = 0.002
I0524 00:35:47.126664  8498 solver.cpp:237] Iteration 8988, loss = 1.45019
I0524 00:35:47.126698  8498 solver.cpp:253]     Train net output #0: loss = 1.45019 (* 1 = 1.45019 loss)
I0524 00:35:47.126713  8498 sgd_solver.cpp:106] Iteration 8988, lr = 0.002
I0524 00:35:56.029495  8498 solver.cpp:237] Iteration 9202, loss = 1.10293
I0524 00:35:56.029530  8498 solver.cpp:253]     Train net output #0: loss = 1.10293 (* 1 = 1.10293 loss)
I0524 00:35:56.029546  8498 sgd_solver.cpp:106] Iteration 9202, lr = 0.002
I0524 00:36:04.930611  8498 solver.cpp:237] Iteration 9416, loss = 1.49071
I0524 00:36:04.930655  8498 solver.cpp:253]     Train net output #0: loss = 1.49071 (* 1 = 1.49071 loss)
I0524 00:36:04.930675  8498 sgd_solver.cpp:106] Iteration 9416, lr = 0.002
I0524 00:36:13.828034  8498 solver.cpp:237] Iteration 9630, loss = 1.44288
I0524 00:36:13.828174  8498 solver.cpp:253]     Train net output #0: loss = 1.44288 (* 1 = 1.44288 loss)
I0524 00:36:13.828187  8498 sgd_solver.cpp:106] Iteration 9630, lr = 0.002
I0524 00:36:22.730686  8498 solver.cpp:237] Iteration 9844, loss = 1.40835
I0524 00:36:22.730720  8498 solver.cpp:253]     Train net output #0: loss = 1.40835 (* 1 = 1.40835 loss)
I0524 00:36:22.730737  8498 sgd_solver.cpp:106] Iteration 9844, lr = 0.002
I0524 00:36:53.803184  8498 solver.cpp:237] Iteration 10058, loss = 1.42614
I0524 00:36:53.803350  8498 solver.cpp:253]     Train net output #0: loss = 1.42614 (* 1 = 1.42614 loss)
I0524 00:36:53.803365  8498 sgd_solver.cpp:106] Iteration 10058, lr = 0.002
I0524 00:37:02.702926  8498 solver.cpp:237] Iteration 10272, loss = 1.24297
I0524 00:37:02.702960  8498 solver.cpp:253]     Train net output #0: loss = 1.24297 (* 1 = 1.24297 loss)
I0524 00:37:02.702980  8498 sgd_solver.cpp:106] Iteration 10272, lr = 0.002
I0524 00:37:11.605322  8498 solver.cpp:237] Iteration 10486, loss = 1.35763
I0524 00:37:11.605357  8498 solver.cpp:253]     Train net output #0: loss = 1.35763 (* 1 = 1.35763 loss)
I0524 00:37:11.605373  8498 sgd_solver.cpp:106] Iteration 10486, lr = 0.002
I0524 00:37:20.506260  8498 solver.cpp:237] Iteration 10700, loss = 1.67524
I0524 00:37:20.506299  8498 solver.cpp:253]     Train net output #0: loss = 1.67524 (* 1 = 1.67524 loss)
I0524 00:37:20.506320  8498 sgd_solver.cpp:106] Iteration 10700, lr = 0.002
I0524 00:37:20.882328  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_10710.caffemodel
I0524 00:37:20.963770  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_10710.solverstate
I0524 00:37:29.501557  8498 solver.cpp:237] Iteration 10914, loss = 1.57843
I0524 00:37:29.501729  8498 solver.cpp:253]     Train net output #0: loss = 1.57843 (* 1 = 1.57843 loss)
I0524 00:37:29.501744  8498 sgd_solver.cpp:106] Iteration 10914, lr = 0.002
I0524 00:37:38.403275  8498 solver.cpp:237] Iteration 11128, loss = 1.33995
I0524 00:37:38.403309  8498 solver.cpp:253]     Train net output #0: loss = 1.33995 (* 1 = 1.33995 loss)
I0524 00:37:38.403326  8498 sgd_solver.cpp:106] Iteration 11128, lr = 0.002
I0524 00:37:47.305057  8498 solver.cpp:237] Iteration 11342, loss = 1.35936
I0524 00:37:47.305099  8498 solver.cpp:253]     Train net output #0: loss = 1.35936 (* 1 = 1.35936 loss)
I0524 00:37:47.305117  8498 sgd_solver.cpp:106] Iteration 11342, lr = 0.002
I0524 00:38:18.457864  8498 solver.cpp:237] Iteration 11556, loss = 1.33652
I0524 00:38:18.458039  8498 solver.cpp:253]     Train net output #0: loss = 1.33652 (* 1 = 1.33652 loss)
I0524 00:38:18.458055  8498 sgd_solver.cpp:106] Iteration 11556, lr = 0.002
I0524 00:38:27.361809  8498 solver.cpp:237] Iteration 11770, loss = 1.32617
I0524 00:38:27.361843  8498 solver.cpp:253]     Train net output #0: loss = 1.32617 (* 1 = 1.32617 loss)
I0524 00:38:27.361861  8498 sgd_solver.cpp:106] Iteration 11770, lr = 0.002
I0524 00:38:36.261404  8498 solver.cpp:237] Iteration 11984, loss = 1.30006
I0524 00:38:36.261440  8498 solver.cpp:253]     Train net output #0: loss = 1.30006 (* 1 = 1.30006 loss)
I0524 00:38:36.261461  8498 sgd_solver.cpp:106] Iteration 11984, lr = 0.002
I0524 00:38:45.161353  8498 solver.cpp:237] Iteration 12198, loss = 1.24199
I0524 00:38:45.161387  8498 solver.cpp:253]     Train net output #0: loss = 1.24199 (* 1 = 1.24199 loss)
I0524 00:38:45.161404  8498 sgd_solver.cpp:106] Iteration 12198, lr = 0.002
I0524 00:38:54.066030  8498 solver.cpp:237] Iteration 12412, loss = 1.2627
I0524 00:38:54.066175  8498 solver.cpp:253]     Train net output #0: loss = 1.2627 (* 1 = 1.2627 loss)
I0524 00:38:54.066190  8498 sgd_solver.cpp:106] Iteration 12412, lr = 0.002
I0524 00:39:02.964411  8498 solver.cpp:237] Iteration 12626, loss = 1.4168
I0524 00:39:02.964445  8498 solver.cpp:253]     Train net output #0: loss = 1.4168 (* 1 = 1.4168 loss)
I0524 00:39:02.964462  8498 sgd_solver.cpp:106] Iteration 12626, lr = 0.002
I0524 00:39:11.866142  8498 solver.cpp:237] Iteration 12840, loss = 1.42606
I0524 00:39:11.866178  8498 solver.cpp:253]     Train net output #0: loss = 1.42606 (* 1 = 1.42606 loss)
I0524 00:39:11.866194  8498 sgd_solver.cpp:106] Iteration 12840, lr = 0.002
I0524 00:39:12.324213  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_12852.caffemodel
I0524 00:39:12.399420  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_12852.solverstate
I0524 00:39:12.532301  8498 solver.cpp:341] Iteration 12855, Testing net (#0)
I0524 00:40:00.136135  8498 solver.cpp:409]     Test net output #0: accuracy = 0.826516
I0524 00:40:00.136297  8498 solver.cpp:409]     Test net output #1: loss = 0.59411 (* 1 = 0.59411 loss)
I0524 00:40:30.647756  8498 solver.cpp:237] Iteration 13054, loss = 1.50129
I0524 00:40:30.647917  8498 solver.cpp:253]     Train net output #0: loss = 1.50129 (* 1 = 1.50129 loss)
I0524 00:40:30.647932  8498 sgd_solver.cpp:106] Iteration 13054, lr = 0.002
I0524 00:40:39.525270  8498 solver.cpp:237] Iteration 13268, loss = 1.41308
I0524 00:40:39.525312  8498 solver.cpp:253]     Train net output #0: loss = 1.41308 (* 1 = 1.41308 loss)
I0524 00:40:39.525332  8498 sgd_solver.cpp:106] Iteration 13268, lr = 0.002
I0524 00:40:48.401136  8498 solver.cpp:237] Iteration 13482, loss = 1.23137
I0524 00:40:48.401172  8498 solver.cpp:253]     Train net output #0: loss = 1.23137 (* 1 = 1.23137 loss)
I0524 00:40:48.401188  8498 sgd_solver.cpp:106] Iteration 13482, lr = 0.002
I0524 00:40:57.279391  8498 solver.cpp:237] Iteration 13696, loss = 1.56499
I0524 00:40:57.279427  8498 solver.cpp:253]     Train net output #0: loss = 1.56499 (* 1 = 1.56499 loss)
I0524 00:40:57.279443  8498 sgd_solver.cpp:106] Iteration 13696, lr = 0.002
I0524 00:41:06.151535  8498 solver.cpp:237] Iteration 13910, loss = 1.39802
I0524 00:41:06.151684  8498 solver.cpp:253]     Train net output #0: loss = 1.39802 (* 1 = 1.39802 loss)
I0524 00:41:06.151698  8498 sgd_solver.cpp:106] Iteration 13910, lr = 0.002
I0524 00:41:15.031869  8498 solver.cpp:237] Iteration 14124, loss = 1.21032
I0524 00:41:15.031903  8498 solver.cpp:253]     Train net output #0: loss = 1.21032 (* 1 = 1.21032 loss)
I0524 00:41:15.031921  8498 sgd_solver.cpp:106] Iteration 14124, lr = 0.002
I0524 00:41:46.115002  8498 solver.cpp:237] Iteration 14338, loss = 1.19192
I0524 00:41:46.115175  8498 solver.cpp:253]     Train net output #0: loss = 1.19192 (* 1 = 1.19192 loss)
I0524 00:41:46.115191  8498 sgd_solver.cpp:106] Iteration 14338, lr = 0.002
I0524 00:41:54.991477  8498 solver.cpp:237] Iteration 14552, loss = 1.08824
I0524 00:41:54.991523  8498 solver.cpp:253]     Train net output #0: loss = 1.08824 (* 1 = 1.08824 loss)
I0524 00:41:54.991540  8498 sgd_solver.cpp:106] Iteration 14552, lr = 0.002
I0524 00:42:03.863957  8498 solver.cpp:237] Iteration 14766, loss = 1.41894
I0524 00:42:03.863992  8498 solver.cpp:253]     Train net output #0: loss = 1.41894 (* 1 = 1.41894 loss)
I0524 00:42:03.864008  8498 sgd_solver.cpp:106] Iteration 14766, lr = 0.002
I0524 00:42:12.738757  8498 solver.cpp:237] Iteration 14980, loss = 1.19466
I0524 00:42:12.738792  8498 solver.cpp:253]     Train net output #0: loss = 1.19466 (* 1 = 1.19466 loss)
I0524 00:42:12.738806  8498 sgd_solver.cpp:106] Iteration 14980, lr = 0.002
I0524 00:42:13.279587  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_14994.caffemodel
I0524 00:42:13.361510  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_14994.solverstate
I0524 00:42:21.712033  8498 solver.cpp:237] Iteration 15194, loss = 1.35742
I0524 00:42:21.712194  8498 solver.cpp:253]     Train net output #0: loss = 1.35742 (* 1 = 1.35742 loss)
I0524 00:42:21.712208  8498 sgd_solver.cpp:106] Iteration 15194, lr = 0.002
I0524 00:42:30.592108  8498 solver.cpp:237] Iteration 15408, loss = 1.35696
I0524 00:42:30.592141  8498 solver.cpp:253]     Train net output #0: loss = 1.35696 (* 1 = 1.35696 loss)
I0524 00:42:30.592159  8498 sgd_solver.cpp:106] Iteration 15408, lr = 0.002
I0524 00:42:39.465289  8498 solver.cpp:237] Iteration 15622, loss = 1.18449
I0524 00:42:39.465332  8498 solver.cpp:253]     Train net output #0: loss = 1.18449 (* 1 = 1.18449 loss)
I0524 00:42:39.465351  8498 sgd_solver.cpp:106] Iteration 15622, lr = 0.002
I0524 00:43:10.531294  8498 solver.cpp:237] Iteration 15836, loss = 1.34095
I0524 00:43:10.531461  8498 solver.cpp:253]     Train net output #0: loss = 1.34095 (* 1 = 1.34095 loss)
I0524 00:43:10.531476  8498 sgd_solver.cpp:106] Iteration 15836, lr = 0.002
I0524 00:43:19.414557  8498 solver.cpp:237] Iteration 16050, loss = 1.22395
I0524 00:43:19.414592  8498 solver.cpp:253]     Train net output #0: loss = 1.22395 (* 1 = 1.22395 loss)
I0524 00:43:19.414608  8498 sgd_solver.cpp:106] Iteration 16050, lr = 0.002
I0524 00:43:28.288087  8498 solver.cpp:237] Iteration 16264, loss = 1.07524
I0524 00:43:28.288121  8498 solver.cpp:253]     Train net output #0: loss = 1.07524 (* 1 = 1.07524 loss)
I0524 00:43:28.288136  8498 sgd_solver.cpp:106] Iteration 16264, lr = 0.002
I0524 00:43:37.166028  8498 solver.cpp:237] Iteration 16478, loss = 1.32468
I0524 00:43:37.166057  8498 solver.cpp:253]     Train net output #0: loss = 1.32468 (* 1 = 1.32468 loss)
I0524 00:43:37.166075  8498 sgd_solver.cpp:106] Iteration 16478, lr = 0.002
I0524 00:43:46.043069  8498 solver.cpp:237] Iteration 16692, loss = 1.23392
I0524 00:43:46.043225  8498 solver.cpp:253]     Train net output #0: loss = 1.23392 (* 1 = 1.23392 loss)
I0524 00:43:46.043238  8498 sgd_solver.cpp:106] Iteration 16692, lr = 0.002
I0524 00:43:54.908568  8498 solver.cpp:237] Iteration 16906, loss = 1.2944
I0524 00:43:54.908607  8498 solver.cpp:253]     Train net output #0: loss = 1.2944 (* 1 = 1.2944 loss)
I0524 00:43:54.908628  8498 sgd_solver.cpp:106] Iteration 16906, lr = 0.002
I0524 00:44:03.780730  8498 solver.cpp:237] Iteration 17120, loss = 1.19059
I0524 00:44:03.780764  8498 solver.cpp:253]     Train net output #0: loss = 1.19059 (* 1 = 1.19059 loss)
I0524 00:44:03.780779  8498 sgd_solver.cpp:106] Iteration 17120, lr = 0.002
I0524 00:44:04.403208  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_17136.caffemodel
I0524 00:44:04.479601  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_17136.solverstate
I0524 00:44:04.654335  8498 solver.cpp:341] Iteration 17140, Testing net (#0)
I0524 00:45:13.452052  8498 solver.cpp:409]     Test net output #0: accuracy = 0.847265
I0524 00:45:13.452221  8498 solver.cpp:409]     Test net output #1: loss = 0.51437 (* 1 = 0.51437 loss)
I0524 00:45:43.707805  8498 solver.cpp:237] Iteration 17334, loss = 1.48813
I0524 00:45:43.707985  8498 solver.cpp:253]     Train net output #0: loss = 1.48813 (* 1 = 1.48813 loss)
I0524 00:45:43.708001  8498 sgd_solver.cpp:106] Iteration 17334, lr = 0.002
I0524 00:45:52.588084  8498 solver.cpp:237] Iteration 17548, loss = 1.02489
I0524 00:45:52.588119  8498 solver.cpp:253]     Train net output #0: loss = 1.02489 (* 1 = 1.02489 loss)
I0524 00:45:52.588136  8498 sgd_solver.cpp:106] Iteration 17548, lr = 0.002
I0524 00:46:01.466327  8498 solver.cpp:237] Iteration 17762, loss = 1.2315
I0524 00:46:01.466372  8498 solver.cpp:253]     Train net output #0: loss = 1.2315 (* 1 = 1.2315 loss)
I0524 00:46:01.466387  8498 sgd_solver.cpp:106] Iteration 17762, lr = 0.002
I0524 00:46:10.346410  8498 solver.cpp:237] Iteration 17976, loss = 1.37635
I0524 00:46:10.346444  8498 solver.cpp:253]     Train net output #0: loss = 1.37635 (* 1 = 1.37635 loss)
I0524 00:46:10.346457  8498 sgd_solver.cpp:106] Iteration 17976, lr = 0.002
I0524 00:46:19.220119  8498 solver.cpp:237] Iteration 18190, loss = 1.30771
I0524 00:46:19.220263  8498 solver.cpp:253]     Train net output #0: loss = 1.30771 (* 1 = 1.30771 loss)
I0524 00:46:19.220276  8498 sgd_solver.cpp:106] Iteration 18190, lr = 0.002
I0524 00:46:28.102325  8498 solver.cpp:237] Iteration 18404, loss = 1.10434
I0524 00:46:28.102360  8498 solver.cpp:253]     Train net output #0: loss = 1.10434 (* 1 = 1.10434 loss)
I0524 00:46:28.102381  8498 sgd_solver.cpp:106] Iteration 18404, lr = 0.002
I0524 00:46:59.205154  8498 solver.cpp:237] Iteration 18618, loss = 1.44211
I0524 00:46:59.205341  8498 solver.cpp:253]     Train net output #0: loss = 1.44211 (* 1 = 1.44211 loss)
I0524 00:46:59.205358  8498 sgd_solver.cpp:106] Iteration 18618, lr = 0.002
I0524 00:47:08.085721  8498 solver.cpp:237] Iteration 18832, loss = 1.20793
I0524 00:47:08.085755  8498 solver.cpp:253]     Train net output #0: loss = 1.20793 (* 1 = 1.20793 loss)
I0524 00:47:08.085772  8498 sgd_solver.cpp:106] Iteration 18832, lr = 0.002
I0524 00:47:16.970226  8498 solver.cpp:237] Iteration 19046, loss = 1.09856
I0524 00:47:16.970263  8498 solver.cpp:253]     Train net output #0: loss = 1.09856 (* 1 = 1.09856 loss)
I0524 00:47:16.970281  8498 sgd_solver.cpp:106] Iteration 19046, lr = 0.002
I0524 00:47:25.854594  8498 solver.cpp:237] Iteration 19260, loss = 1.37993
I0524 00:47:25.854629  8498 solver.cpp:253]     Train net output #0: loss = 1.37993 (* 1 = 1.37993 loss)
I0524 00:47:25.854645  8498 sgd_solver.cpp:106] Iteration 19260, lr = 0.002
I0524 00:47:26.560588  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_19278.caffemodel
I0524 00:47:26.638533  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_19278.solverstate
I0524 00:47:34.819041  8498 solver.cpp:237] Iteration 19474, loss = 1.45579
I0524 00:47:34.819205  8498 solver.cpp:253]     Train net output #0: loss = 1.45579 (* 1 = 1.45579 loss)
I0524 00:47:34.819219  8498 sgd_solver.cpp:106] Iteration 19474, lr = 0.002
I0524 00:47:43.699982  8498 solver.cpp:237] Iteration 19688, loss = 1.28131
I0524 00:47:43.700026  8498 solver.cpp:253]     Train net output #0: loss = 1.28131 (* 1 = 1.28131 loss)
I0524 00:47:43.700045  8498 sgd_solver.cpp:106] Iteration 19688, lr = 0.002
I0524 00:47:52.576318  8498 solver.cpp:237] Iteration 19902, loss = 1.15585
I0524 00:47:52.576352  8498 solver.cpp:253]     Train net output #0: loss = 1.15585 (* 1 = 1.15585 loss)
I0524 00:47:52.576369  8498 sgd_solver.cpp:106] Iteration 19902, lr = 0.002
I0524 00:48:23.660946  8498 solver.cpp:237] Iteration 20116, loss = 1.05475
I0524 00:48:23.661123  8498 solver.cpp:253]     Train net output #0: loss = 1.05475 (* 1 = 1.05475 loss)
I0524 00:48:23.661139  8498 sgd_solver.cpp:106] Iteration 20116, lr = 0.002
I0524 00:48:32.542621  8498 solver.cpp:237] Iteration 20330, loss = 1.31632
I0524 00:48:32.542664  8498 solver.cpp:253]     Train net output #0: loss = 1.31632 (* 1 = 1.31632 loss)
I0524 00:48:32.542685  8498 sgd_solver.cpp:106] Iteration 20330, lr = 0.002
I0524 00:48:41.426553  8498 solver.cpp:237] Iteration 20544, loss = 1.34408
I0524 00:48:41.426589  8498 solver.cpp:253]     Train net output #0: loss = 1.34408 (* 1 = 1.34408 loss)
I0524 00:48:41.426604  8498 sgd_solver.cpp:106] Iteration 20544, lr = 0.002
I0524 00:48:50.314776  8498 solver.cpp:237] Iteration 20758, loss = 1.36115
I0524 00:48:50.314812  8498 solver.cpp:253]     Train net output #0: loss = 1.36115 (* 1 = 1.36115 loss)
I0524 00:48:50.314828  8498 sgd_solver.cpp:106] Iteration 20758, lr = 0.002
I0524 00:48:59.192162  8498 solver.cpp:237] Iteration 20972, loss = 1.34367
I0524 00:48:59.192322  8498 solver.cpp:253]     Train net output #0: loss = 1.34367 (* 1 = 1.34367 loss)
I0524 00:48:59.192337  8498 sgd_solver.cpp:106] Iteration 20972, lr = 0.002
I0524 00:49:08.072469  8498 solver.cpp:237] Iteration 21186, loss = 1.08357
I0524 00:49:08.072504  8498 solver.cpp:253]     Train net output #0: loss = 1.08357 (* 1 = 1.08357 loss)
I0524 00:49:08.072520  8498 sgd_solver.cpp:106] Iteration 21186, lr = 0.002
I0524 00:49:16.954627  8498 solver.cpp:237] Iteration 21400, loss = 1.19991
I0524 00:49:16.954663  8498 solver.cpp:253]     Train net output #0: loss = 1.19991 (* 1 = 1.19991 loss)
I0524 00:49:16.954677  8498 sgd_solver.cpp:106] Iteration 21400, lr = 0.002
I0524 00:49:17.742158  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_21420.caffemodel
I0524 00:49:17.818999  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_21420.solverstate
I0524 00:49:18.039137  8498 solver.cpp:341] Iteration 21425, Testing net (#0)
I0524 00:50:06.022747  8498 solver.cpp:409]     Test net output #0: accuracy = 0.852981
I0524 00:50:06.022913  8498 solver.cpp:409]     Test net output #1: loss = 0.490202 (* 1 = 0.490202 loss)
I0524 00:50:34.797147  8498 solver.cpp:237] Iteration 21614, loss = 1.44926
I0524 00:50:34.797196  8498 solver.cpp:253]     Train net output #0: loss = 1.44926 (* 1 = 1.44926 loss)
I0524 00:50:34.797214  8498 sgd_solver.cpp:106] Iteration 21614, lr = 0.002
I0524 00:50:43.676453  8498 solver.cpp:237] Iteration 21828, loss = 1.53695
I0524 00:50:43.676607  8498 solver.cpp:253]     Train net output #0: loss = 1.53695 (* 1 = 1.53695 loss)
I0524 00:50:43.676621  8498 sgd_solver.cpp:106] Iteration 21828, lr = 0.002
I0524 00:50:52.552886  8498 solver.cpp:237] Iteration 22042, loss = 1.21728
I0524 00:50:52.552919  8498 solver.cpp:253]     Train net output #0: loss = 1.21728 (* 1 = 1.21728 loss)
I0524 00:50:52.552937  8498 sgd_solver.cpp:106] Iteration 22042, lr = 0.002
I0524 00:51:01.425740  8498 solver.cpp:237] Iteration 22256, loss = 1.55493
I0524 00:51:01.425778  8498 solver.cpp:253]     Train net output #0: loss = 1.55493 (* 1 = 1.55493 loss)
I0524 00:51:01.425799  8498 sgd_solver.cpp:106] Iteration 22256, lr = 0.002
I0524 00:51:10.307466  8498 solver.cpp:237] Iteration 22470, loss = 0.996324
I0524 00:51:10.307500  8498 solver.cpp:253]     Train net output #0: loss = 0.996324 (* 1 = 0.996324 loss)
I0524 00:51:10.307517  8498 sgd_solver.cpp:106] Iteration 22470, lr = 0.002
I0524 00:51:19.194938  8498 solver.cpp:237] Iteration 22684, loss = 1.07461
I0524 00:51:19.195092  8498 solver.cpp:253]     Train net output #0: loss = 1.07461 (* 1 = 1.07461 loss)
I0524 00:51:19.195106  8498 sgd_solver.cpp:106] Iteration 22684, lr = 0.002
I0524 00:51:48.929989  8498 solver.cpp:237] Iteration 22898, loss = 1.28216
I0524 00:51:48.930042  8498 solver.cpp:253]     Train net output #0: loss = 1.28216 (* 1 = 1.28216 loss)
I0524 00:51:48.930055  8498 sgd_solver.cpp:106] Iteration 22898, lr = 0.002
I0524 00:51:57.814925  8498 solver.cpp:237] Iteration 23112, loss = 1.32056
I0524 00:51:57.815078  8498 solver.cpp:253]     Train net output #0: loss = 1.32056 (* 1 = 1.32056 loss)
I0524 00:51:57.815093  8498 sgd_solver.cpp:106] Iteration 23112, lr = 0.002
I0524 00:52:06.697185  8498 solver.cpp:237] Iteration 23326, loss = 1.19194
I0524 00:52:06.697218  8498 solver.cpp:253]     Train net output #0: loss = 1.19194 (* 1 = 1.19194 loss)
I0524 00:52:06.697237  8498 sgd_solver.cpp:106] Iteration 23326, lr = 0.002
I0524 00:52:15.579789  8498 solver.cpp:237] Iteration 23540, loss = 1.26355
I0524 00:52:15.579831  8498 solver.cpp:253]     Train net output #0: loss = 1.26355 (* 1 = 1.26355 loss)
I0524 00:52:15.579851  8498 sgd_solver.cpp:106] Iteration 23540, lr = 0.002
I0524 00:52:16.451159  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_23562.caffemodel
I0524 00:52:16.524493  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_23562.solverstate
I0524 00:52:24.531213  8498 solver.cpp:237] Iteration 23754, loss = 1.32252
I0524 00:52:24.531260  8498 solver.cpp:253]     Train net output #0: loss = 1.32252 (* 1 = 1.32252 loss)
I0524 00:52:24.531273  8498 sgd_solver.cpp:106] Iteration 23754, lr = 0.002
I0524 00:52:33.406224  8498 solver.cpp:237] Iteration 23968, loss = 1.02245
I0524 00:52:33.406373  8498 solver.cpp:253]     Train net output #0: loss = 1.02245 (* 1 = 1.02245 loss)
I0524 00:52:33.406388  8498 sgd_solver.cpp:106] Iteration 23968, lr = 0.002
I0524 00:52:42.284149  8498 solver.cpp:237] Iteration 24182, loss = 1.4658
I0524 00:52:42.284190  8498 solver.cpp:253]     Train net output #0: loss = 1.4658 (* 1 = 1.4658 loss)
I0524 00:52:42.284211  8498 sgd_solver.cpp:106] Iteration 24182, lr = 0.002
I0524 00:53:12.007525  8498 solver.cpp:237] Iteration 24396, loss = 1.1155
I0524 00:53:12.007690  8498 solver.cpp:253]     Train net output #0: loss = 1.1155 (* 1 = 1.1155 loss)
I0524 00:53:12.007705  8498 sgd_solver.cpp:106] Iteration 24396, lr = 0.002
I0524 00:53:20.884620  8498 solver.cpp:237] Iteration 24610, loss = 1.33731
I0524 00:53:20.884654  8498 solver.cpp:253]     Train net output #0: loss = 1.33731 (* 1 = 1.33731 loss)
I0524 00:53:20.884671  8498 sgd_solver.cpp:106] Iteration 24610, lr = 0.002
I0524 00:53:29.760910  8498 solver.cpp:237] Iteration 24824, loss = 1.04476
I0524 00:53:29.760951  8498 solver.cpp:253]     Train net output #0: loss = 1.04476 (* 1 = 1.04476 loss)
I0524 00:53:29.760972  8498 sgd_solver.cpp:106] Iteration 24824, lr = 0.002
I0524 00:53:38.631180  8498 solver.cpp:237] Iteration 25038, loss = 1.28116
I0524 00:53:38.631216  8498 solver.cpp:253]     Train net output #0: loss = 1.28116 (* 1 = 1.28116 loss)
I0524 00:53:38.631230  8498 sgd_solver.cpp:106] Iteration 25038, lr = 0.002
I0524 00:53:47.504271  8498 solver.cpp:237] Iteration 25252, loss = 1.35072
I0524 00:53:47.504418  8498 solver.cpp:253]     Train net output #0: loss = 1.35072 (* 1 = 1.35072 loss)
I0524 00:53:47.504432  8498 sgd_solver.cpp:106] Iteration 25252, lr = 0.002
I0524 00:53:56.379082  8498 solver.cpp:237] Iteration 25466, loss = 1.22618
I0524 00:53:56.379118  8498 solver.cpp:253]     Train net output #0: loss = 1.22618 (* 1 = 1.22618 loss)
I0524 00:53:56.379139  8498 sgd_solver.cpp:106] Iteration 25466, lr = 0.002
I0524 00:54:05.255237  8498 solver.cpp:237] Iteration 25680, loss = 1.26558
I0524 00:54:05.255273  8498 solver.cpp:253]     Train net output #0: loss = 1.26558 (* 1 = 1.26558 loss)
I0524 00:54:05.255290  8498 sgd_solver.cpp:106] Iteration 25680, lr = 0.002
I0524 00:54:06.208619  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_25704.caffemodel
I0524 00:54:06.283625  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_25704.solverstate
I0524 00:54:06.539660  8498 solver.cpp:341] Iteration 25710, Testing net (#0)
I0524 00:55:15.379559  8498 solver.cpp:409]     Test net output #0: accuracy = 0.859196
I0524 00:55:15.379750  8498 solver.cpp:409]     Test net output #1: loss = 0.426789 (* 1 = 0.426789 loss)
I0524 00:55:43.900596  8498 solver.cpp:237] Iteration 25894, loss = 1.48321
I0524 00:55:43.900646  8498 solver.cpp:253]     Train net output #0: loss = 1.48321 (* 1 = 1.48321 loss)
I0524 00:55:43.900662  8498 sgd_solver.cpp:106] Iteration 25894, lr = 0.002
I0524 00:55:52.768326  8498 solver.cpp:237] Iteration 26108, loss = 1.14564
I0524 00:55:52.768476  8498 solver.cpp:253]     Train net output #0: loss = 1.14564 (* 1 = 1.14564 loss)
I0524 00:55:52.768491  8498 sgd_solver.cpp:106] Iteration 26108, lr = 0.002
I0524 00:56:01.634376  8498 solver.cpp:237] Iteration 26322, loss = 1.11679
I0524 00:56:01.634413  8498 solver.cpp:253]     Train net output #0: loss = 1.11679 (* 1 = 1.11679 loss)
I0524 00:56:01.634435  8498 sgd_solver.cpp:106] Iteration 26322, lr = 0.002
I0524 00:56:10.509641  8498 solver.cpp:237] Iteration 26536, loss = 1.28504
I0524 00:56:10.509681  8498 solver.cpp:253]     Train net output #0: loss = 1.28504 (* 1 = 1.28504 loss)
I0524 00:56:10.509697  8498 sgd_solver.cpp:106] Iteration 26536, lr = 0.002
I0524 00:56:19.376440  8498 solver.cpp:237] Iteration 26750, loss = 1.11472
I0524 00:56:19.376474  8498 solver.cpp:253]     Train net output #0: loss = 1.11472 (* 1 = 1.11472 loss)
I0524 00:56:19.376490  8498 sgd_solver.cpp:106] Iteration 26750, lr = 0.002
I0524 00:56:28.247802  8498 solver.cpp:237] Iteration 26964, loss = 1.28
I0524 00:56:28.247958  8498 solver.cpp:253]     Train net output #0: loss = 1.28 (* 1 = 1.28 loss)
I0524 00:56:28.247972  8498 sgd_solver.cpp:106] Iteration 26964, lr = 0.002
I0524 00:56:57.969393  8498 solver.cpp:237] Iteration 27178, loss = 1.20875
I0524 00:56:57.969442  8498 solver.cpp:253]     Train net output #0: loss = 1.20875 (* 1 = 1.20875 loss)
I0524 00:56:57.969460  8498 sgd_solver.cpp:106] Iteration 27178, lr = 0.002
I0524 00:57:06.839687  8498 solver.cpp:237] Iteration 27392, loss = 1.12178
I0524 00:57:06.839841  8498 solver.cpp:253]     Train net output #0: loss = 1.12178 (* 1 = 1.12178 loss)
I0524 00:57:06.839854  8498 sgd_solver.cpp:106] Iteration 27392, lr = 0.002
I0524 00:57:15.702798  8498 solver.cpp:237] Iteration 27606, loss = 1.00094
I0524 00:57:15.702833  8498 solver.cpp:253]     Train net output #0: loss = 1.00094 (* 1 = 1.00094 loss)
I0524 00:57:15.702850  8498 sgd_solver.cpp:106] Iteration 27606, lr = 0.002
I0524 00:57:24.574095  8498 solver.cpp:237] Iteration 27820, loss = 1.3189
I0524 00:57:24.574131  8498 solver.cpp:253]     Train net output #0: loss = 1.3189 (* 1 = 1.3189 loss)
I0524 00:57:24.574146  8498 sgd_solver.cpp:106] Iteration 27820, lr = 0.002
I0524 00:57:25.612187  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_27846.caffemodel
I0524 00:57:25.687213  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_27846.solverstate
I0524 00:57:33.525295  8498 solver.cpp:237] Iteration 28034, loss = 1.09986
I0524 00:57:33.525341  8498 solver.cpp:253]     Train net output #0: loss = 1.09986 (* 1 = 1.09986 loss)
I0524 00:57:33.525354  8498 sgd_solver.cpp:106] Iteration 28034, lr = 0.002
I0524 00:57:42.393796  8498 solver.cpp:237] Iteration 28248, loss = 1.15364
I0524 00:57:42.393970  8498 solver.cpp:253]     Train net output #0: loss = 1.15364 (* 1 = 1.15364 loss)
I0524 00:57:42.393985  8498 sgd_solver.cpp:106] Iteration 28248, lr = 0.002
I0524 00:57:51.259395  8498 solver.cpp:237] Iteration 28462, loss = 1.31867
I0524 00:57:51.259429  8498 solver.cpp:253]     Train net output #0: loss = 1.31867 (* 1 = 1.31867 loss)
I0524 00:57:51.259448  8498 sgd_solver.cpp:106] Iteration 28462, lr = 0.002
I0524 00:58:21.029698  8498 solver.cpp:237] Iteration 28676, loss = 1.15927
I0524 00:58:21.029877  8498 solver.cpp:253]     Train net output #0: loss = 1.15927 (* 1 = 1.15927 loss)
I0524 00:58:21.029892  8498 sgd_solver.cpp:106] Iteration 28676, lr = 0.002
I0524 00:58:29.895143  8498 solver.cpp:237] Iteration 28890, loss = 1.35633
I0524 00:58:29.895184  8498 solver.cpp:253]     Train net output #0: loss = 1.35633 (* 1 = 1.35633 loss)
I0524 00:58:29.895203  8498 sgd_solver.cpp:106] Iteration 28890, lr = 0.002
I0524 00:58:38.760499  8498 solver.cpp:237] Iteration 29104, loss = 1.40921
I0524 00:58:38.760535  8498 solver.cpp:253]     Train net output #0: loss = 1.40921 (* 1 = 1.40921 loss)
I0524 00:58:38.760548  8498 sgd_solver.cpp:106] Iteration 29104, lr = 0.002
I0524 00:58:47.626492  8498 solver.cpp:237] Iteration 29318, loss = 1.40711
I0524 00:58:47.626528  8498 solver.cpp:253]     Train net output #0: loss = 1.40711 (* 1 = 1.40711 loss)
I0524 00:58:47.626541  8498 sgd_solver.cpp:106] Iteration 29318, lr = 0.002
I0524 00:58:56.498275  8498 solver.cpp:237] Iteration 29532, loss = 1.22977
I0524 00:58:56.498440  8498 solver.cpp:253]     Train net output #0: loss = 1.22977 (* 1 = 1.22977 loss)
I0524 00:58:56.498453  8498 sgd_solver.cpp:106] Iteration 29532, lr = 0.002
I0524 00:59:05.367774  8498 solver.cpp:237] Iteration 29746, loss = 1.23108
I0524 00:59:05.367807  8498 solver.cpp:253]     Train net output #0: loss = 1.23108 (* 1 = 1.23108 loss)
I0524 00:59:05.367825  8498 sgd_solver.cpp:106] Iteration 29746, lr = 0.002
I0524 00:59:14.240118  8498 solver.cpp:237] Iteration 29960, loss = 1.29938
I0524 00:59:14.240154  8498 solver.cpp:253]     Train net output #0: loss = 1.29938 (* 1 = 1.29938 loss)
I0524 00:59:14.240170  8498 sgd_solver.cpp:106] Iteration 29960, lr = 0.002
I0524 00:59:15.361798  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_29988.caffemodel
I0524 00:59:15.437047  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_29988.solverstate
I0524 00:59:15.733742  8498 solver.cpp:341] Iteration 29995, Testing net (#0)
I0524 01:00:03.306998  8498 solver.cpp:409]     Test net output #0: accuracy = 0.867347
I0524 01:00:03.307165  8498 solver.cpp:409]     Test net output #1: loss = 0.448883 (* 1 = 0.448883 loss)
I0524 01:00:31.643309  8498 solver.cpp:237] Iteration 30174, loss = 1.14088
I0524 01:00:31.643359  8498 solver.cpp:253]     Train net output #0: loss = 1.14088 (* 1 = 1.14088 loss)
I0524 01:00:31.643376  8498 sgd_solver.cpp:106] Iteration 30174, lr = 0.002
I0524 01:00:40.529383  8498 solver.cpp:237] Iteration 30388, loss = 1.04085
I0524 01:00:40.529551  8498 solver.cpp:253]     Train net output #0: loss = 1.04085 (* 1 = 1.04085 loss)
I0524 01:00:40.529566  8498 sgd_solver.cpp:106] Iteration 30388, lr = 0.002
I0524 01:00:49.415506  8498 solver.cpp:237] Iteration 30602, loss = 1.10342
I0524 01:00:49.415542  8498 solver.cpp:253]     Train net output #0: loss = 1.10342 (* 1 = 1.10342 loss)
I0524 01:00:49.415561  8498 sgd_solver.cpp:106] Iteration 30602, lr = 0.002
I0524 01:00:58.299269  8498 solver.cpp:237] Iteration 30816, loss = 1.05368
I0524 01:00:58.299304  8498 solver.cpp:253]     Train net output #0: loss = 1.05368 (* 1 = 1.05368 loss)
I0524 01:00:58.299320  8498 sgd_solver.cpp:106] Iteration 30816, lr = 0.002
I0524 01:01:07.191298  8498 solver.cpp:237] Iteration 31030, loss = 1.06167
I0524 01:01:07.191340  8498 solver.cpp:253]     Train net output #0: loss = 1.06167 (* 1 = 1.06167 loss)
I0524 01:01:07.191356  8498 sgd_solver.cpp:106] Iteration 31030, lr = 0.002
I0524 01:01:16.069262  8498 solver.cpp:237] Iteration 31244, loss = 1.13209
I0524 01:01:16.069423  8498 solver.cpp:253]     Train net output #0: loss = 1.13209 (* 1 = 1.13209 loss)
I0524 01:01:16.069437  8498 sgd_solver.cpp:106] Iteration 31244, lr = 0.002
I0524 01:01:45.870283  8498 solver.cpp:237] Iteration 31458, loss = 1.32886
I0524 01:01:45.870334  8498 solver.cpp:253]     Train net output #0: loss = 1.32886 (* 1 = 1.32886 loss)
I0524 01:01:45.870349  8498 sgd_solver.cpp:106] Iteration 31458, lr = 0.002
I0524 01:01:54.759986  8498 solver.cpp:237] Iteration 31672, loss = 0.985026
I0524 01:01:54.760155  8498 solver.cpp:253]     Train net output #0: loss = 0.985026 (* 1 = 0.985026 loss)
I0524 01:01:54.760169  8498 sgd_solver.cpp:106] Iteration 31672, lr = 0.002
I0524 01:02:03.638867  8498 solver.cpp:237] Iteration 31886, loss = 1.24237
I0524 01:02:03.638901  8498 solver.cpp:253]     Train net output #0: loss = 1.24237 (* 1 = 1.24237 loss)
I0524 01:02:03.638919  8498 sgd_solver.cpp:106] Iteration 31886, lr = 0.002
I0524 01:02:12.522009  8498 solver.cpp:237] Iteration 32100, loss = 1.17225
I0524 01:02:12.522044  8498 solver.cpp:253]     Train net output #0: loss = 1.17225 (* 1 = 1.17225 loss)
I0524 01:02:12.522061  8498 sgd_solver.cpp:106] Iteration 32100, lr = 0.002
I0524 01:02:13.727355  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_32130.caffemodel
I0524 01:02:13.807754  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_32130.solverstate
I0524 01:02:21.499894  8498 solver.cpp:237] Iteration 32314, loss = 1.34508
I0524 01:02:21.499941  8498 solver.cpp:253]     Train net output #0: loss = 1.34508 (* 1 = 1.34508 loss)
I0524 01:02:21.499958  8498 sgd_solver.cpp:106] Iteration 32314, lr = 0.002
I0524 01:02:30.382027  8498 solver.cpp:237] Iteration 32528, loss = 1.00984
I0524 01:02:30.382185  8498 solver.cpp:253]     Train net output #0: loss = 1.00984 (* 1 = 1.00984 loss)
I0524 01:02:30.382200  8498 sgd_solver.cpp:106] Iteration 32528, lr = 0.002
I0524 01:02:39.267976  8498 solver.cpp:237] Iteration 32742, loss = 1.16013
I0524 01:02:39.268024  8498 solver.cpp:253]     Train net output #0: loss = 1.16013 (* 1 = 1.16013 loss)
I0524 01:02:39.268041  8498 sgd_solver.cpp:106] Iteration 32742, lr = 0.002
I0524 01:03:09.055696  8498 solver.cpp:237] Iteration 32956, loss = 1.23399
I0524 01:03:09.055871  8498 solver.cpp:253]     Train net output #0: loss = 1.23399 (* 1 = 1.23399 loss)
I0524 01:03:09.055886  8498 sgd_solver.cpp:106] Iteration 32956, lr = 0.002
I0524 01:03:17.941154  8498 solver.cpp:237] Iteration 33170, loss = 1.24517
I0524 01:03:17.941189  8498 solver.cpp:253]     Train net output #0: loss = 1.24517 (* 1 = 1.24517 loss)
I0524 01:03:17.941205  8498 sgd_solver.cpp:106] Iteration 33170, lr = 0.002
I0524 01:03:26.825783  8498 solver.cpp:237] Iteration 33384, loss = 1.29271
I0524 01:03:26.825816  8498 solver.cpp:253]     Train net output #0: loss = 1.29271 (* 1 = 1.29271 loss)
I0524 01:03:26.825834  8498 sgd_solver.cpp:106] Iteration 33384, lr = 0.002
I0524 01:03:35.709100  8498 solver.cpp:237] Iteration 33598, loss = 0.985128
I0524 01:03:35.709146  8498 solver.cpp:253]     Train net output #0: loss = 0.985128 (* 1 = 0.985128 loss)
I0524 01:03:35.709159  8498 sgd_solver.cpp:106] Iteration 33598, lr = 0.002
I0524 01:03:44.590579  8498 solver.cpp:237] Iteration 33812, loss = 1.40896
I0524 01:03:44.590728  8498 solver.cpp:253]     Train net output #0: loss = 1.40896 (* 1 = 1.40896 loss)
I0524 01:03:44.590742  8498 sgd_solver.cpp:106] Iteration 33812, lr = 0.002
I0524 01:03:53.469645  8498 solver.cpp:237] Iteration 34026, loss = 1.36048
I0524 01:03:53.469684  8498 solver.cpp:253]     Train net output #0: loss = 1.36048 (* 1 = 1.36048 loss)
I0524 01:03:53.469702  8498 sgd_solver.cpp:106] Iteration 34026, lr = 0.002
I0524 01:04:02.356222  8498 solver.cpp:237] Iteration 34240, loss = 1.23007
I0524 01:04:02.356268  8498 solver.cpp:253]     Train net output #0: loss = 1.23007 (* 1 = 1.23007 loss)
I0524 01:04:02.356284  8498 sgd_solver.cpp:106] Iteration 34240, lr = 0.002
I0524 01:04:03.643846  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_34272.caffemodel
I0524 01:04:03.717505  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_34272.solverstate
I0524 01:04:04.056247  8498 solver.cpp:341] Iteration 34280, Testing net (#0)
I0524 01:05:12.909334  8498 solver.cpp:409]     Test net output #0: accuracy = 0.869361
I0524 01:05:12.909515  8498 solver.cpp:409]     Test net output #1: loss = 0.403568 (* 1 = 0.403568 loss)
I0524 01:05:41.045328  8498 solver.cpp:237] Iteration 34454, loss = 1.17717
I0524 01:05:41.045378  8498 solver.cpp:253]     Train net output #0: loss = 1.17717 (* 1 = 1.17717 loss)
I0524 01:05:41.045392  8498 sgd_solver.cpp:106] Iteration 34454, lr = 0.002
I0524 01:05:49.915082  8498 solver.cpp:237] Iteration 34668, loss = 1.00575
I0524 01:05:49.915240  8498 solver.cpp:253]     Train net output #0: loss = 1.00575 (* 1 = 1.00575 loss)
I0524 01:05:49.915253  8498 sgd_solver.cpp:106] Iteration 34668, lr = 0.002
I0524 01:05:58.790575  8498 solver.cpp:237] Iteration 34882, loss = 1.16646
I0524 01:05:58.790624  8498 solver.cpp:253]     Train net output #0: loss = 1.16646 (* 1 = 1.16646 loss)
I0524 01:05:58.790639  8498 sgd_solver.cpp:106] Iteration 34882, lr = 0.002
I0524 01:06:07.659137  8498 solver.cpp:237] Iteration 35096, loss = 1.06375
I0524 01:06:07.659173  8498 solver.cpp:253]     Train net output #0: loss = 1.06375 (* 1 = 1.06375 loss)
I0524 01:06:07.659190  8498 sgd_solver.cpp:106] Iteration 35096, lr = 0.002
I0524 01:06:16.525794  8498 solver.cpp:237] Iteration 35310, loss = 1.18313
I0524 01:06:16.525830  8498 solver.cpp:253]     Train net output #0: loss = 1.18313 (* 1 = 1.18313 loss)
I0524 01:06:16.525846  8498 sgd_solver.cpp:106] Iteration 35310, lr = 0.002
I0524 01:06:25.390758  8498 solver.cpp:237] Iteration 35524, loss = 1.12044
I0524 01:06:25.390923  8498 solver.cpp:253]     Train net output #0: loss = 1.12044 (* 1 = 1.12044 loss)
I0524 01:06:25.390938  8498 sgd_solver.cpp:106] Iteration 35524, lr = 0.002
I0524 01:06:55.129673  8498 solver.cpp:237] Iteration 35738, loss = 1.33655
I0524 01:06:55.129722  8498 solver.cpp:253]     Train net output #0: loss = 1.33655 (* 1 = 1.33655 loss)
I0524 01:06:55.129739  8498 sgd_solver.cpp:106] Iteration 35738, lr = 0.002
I0524 01:07:03.993938  8498 solver.cpp:237] Iteration 35952, loss = 1.42297
I0524 01:07:03.994096  8498 solver.cpp:253]     Train net output #0: loss = 1.42297 (* 1 = 1.42297 loss)
I0524 01:07:03.994110  8498 sgd_solver.cpp:106] Iteration 35952, lr = 0.002
I0524 01:07:12.859179  8498 solver.cpp:237] Iteration 36166, loss = 1.19129
I0524 01:07:12.859213  8498 solver.cpp:253]     Train net output #0: loss = 1.19129 (* 1 = 1.19129 loss)
I0524 01:07:12.859227  8498 sgd_solver.cpp:106] Iteration 36166, lr = 0.002
I0524 01:07:21.731056  8498 solver.cpp:237] Iteration 36380, loss = 1.22666
I0524 01:07:21.731098  8498 solver.cpp:253]     Train net output #0: loss = 1.22666 (* 1 = 1.22666 loss)
I0524 01:07:21.731114  8498 sgd_solver.cpp:106] Iteration 36380, lr = 0.002
I0524 01:07:23.098861  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_36414.caffemodel
I0524 01:07:23.174650  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_36414.solverstate
I0524 01:07:30.681231  8498 solver.cpp:237] Iteration 36594, loss = 1.00781
I0524 01:07:30.681275  8498 solver.cpp:253]     Train net output #0: loss = 1.00781 (* 1 = 1.00781 loss)
I0524 01:07:30.681293  8498 sgd_solver.cpp:106] Iteration 36594, lr = 0.002
I0524 01:07:39.553153  8498 solver.cpp:237] Iteration 36808, loss = 1.07266
I0524 01:07:39.553334  8498 solver.cpp:253]     Train net output #0: loss = 1.07266 (* 1 = 1.07266 loss)
I0524 01:07:39.553349  8498 sgd_solver.cpp:106] Iteration 36808, lr = 0.002
I0524 01:07:48.423514  8498 solver.cpp:237] Iteration 37022, loss = 1.09016
I0524 01:07:48.423548  8498 solver.cpp:253]     Train net output #0: loss = 1.09016 (* 1 = 1.09016 loss)
I0524 01:07:48.423566  8498 sgd_solver.cpp:106] Iteration 37022, lr = 0.002
I0524 01:08:18.168881  8498 solver.cpp:237] Iteration 37236, loss = 1.21371
I0524 01:08:18.169059  8498 solver.cpp:253]     Train net output #0: loss = 1.21371 (* 1 = 1.21371 loss)
I0524 01:08:18.169075  8498 sgd_solver.cpp:106] Iteration 37236, lr = 0.002
I0524 01:08:27.035773  8498 solver.cpp:237] Iteration 37450, loss = 1.25906
I0524 01:08:27.035807  8498 solver.cpp:253]     Train net output #0: loss = 1.25906 (* 1 = 1.25906 loss)
I0524 01:08:27.035825  8498 sgd_solver.cpp:106] Iteration 37450, lr = 0.002
I0524 01:08:35.897105  8498 solver.cpp:237] Iteration 37664, loss = 1.14567
I0524 01:08:35.897145  8498 solver.cpp:253]     Train net output #0: loss = 1.14567 (* 1 = 1.14567 loss)
I0524 01:08:35.897166  8498 sgd_solver.cpp:106] Iteration 37664, lr = 0.002
I0524 01:08:44.757570  8498 solver.cpp:237] Iteration 37878, loss = 1.19884
I0524 01:08:44.757606  8498 solver.cpp:253]     Train net output #0: loss = 1.19884 (* 1 = 1.19884 loss)
I0524 01:08:44.757622  8498 sgd_solver.cpp:106] Iteration 37878, lr = 0.002
I0524 01:08:53.621165  8498 solver.cpp:237] Iteration 38092, loss = 1.23328
I0524 01:08:53.632657  8498 solver.cpp:253]     Train net output #0: loss = 1.23328 (* 1 = 1.23328 loss)
I0524 01:08:53.632673  8498 sgd_solver.cpp:106] Iteration 38092, lr = 0.002
I0524 01:09:02.488576  8498 solver.cpp:237] Iteration 38306, loss = 1.04223
I0524 01:09:02.488612  8498 solver.cpp:253]     Train net output #0: loss = 1.04223 (* 1 = 1.04223 loss)
I0524 01:09:02.488628  8498 sgd_solver.cpp:106] Iteration 38306, lr = 0.002
I0524 01:09:11.354121  8498 solver.cpp:237] Iteration 38520, loss = 1.44723
I0524 01:09:11.354156  8498 solver.cpp:253]     Train net output #0: loss = 1.44723 (* 1 = 1.44723 loss)
I0524 01:09:11.354174  8498 sgd_solver.cpp:106] Iteration 38520, lr = 0.002
I0524 01:09:12.803531  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_38556.caffemodel
I0524 01:09:12.877866  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_38556.solverstate
I0524 01:09:13.256955  8498 solver.cpp:341] Iteration 38565, Testing net (#0)
I0524 01:10:01.182621  8498 solver.cpp:409]     Test net output #0: accuracy = 0.873096
I0524 01:10:01.182793  8498 solver.cpp:409]     Test net output #1: loss = 0.409721 (* 1 = 0.409721 loss)
I0524 01:10:29.104677  8498 solver.cpp:237] Iteration 38734, loss = 1.06291
I0524 01:10:29.104729  8498 solver.cpp:253]     Train net output #0: loss = 1.06291 (* 1 = 1.06291 loss)
I0524 01:10:29.104743  8498 sgd_solver.cpp:106] Iteration 38734, lr = 0.002
I0524 01:10:37.998642  8498 solver.cpp:237] Iteration 38948, loss = 1.31506
I0524 01:10:37.998813  8498 solver.cpp:253]     Train net output #0: loss = 1.31506 (* 1 = 1.31506 loss)
I0524 01:10:37.998828  8498 sgd_solver.cpp:106] Iteration 38948, lr = 0.002
I0524 01:10:46.899052  8498 solver.cpp:237] Iteration 39162, loss = 0.971119
I0524 01:10:46.899087  8498 solver.cpp:253]     Train net output #0: loss = 0.971119 (* 1 = 0.971119 loss)
I0524 01:10:46.899103  8498 sgd_solver.cpp:106] Iteration 39162, lr = 0.002
I0524 01:10:55.796794  8498 solver.cpp:237] Iteration 39376, loss = 1.09321
I0524 01:10:55.796828  8498 solver.cpp:253]     Train net output #0: loss = 1.09321 (* 1 = 1.09321 loss)
I0524 01:10:55.796845  8498 sgd_solver.cpp:106] Iteration 39376, lr = 0.002
I0524 01:11:04.695986  8498 solver.cpp:237] Iteration 39590, loss = 0.985227
I0524 01:11:04.696022  8498 solver.cpp:253]     Train net output #0: loss = 0.985227 (* 1 = 0.985227 loss)
I0524 01:11:04.696043  8498 sgd_solver.cpp:106] Iteration 39590, lr = 0.002
I0524 01:11:13.594035  8498 solver.cpp:237] Iteration 39804, loss = 1.09917
I0524 01:11:13.594194  8498 solver.cpp:253]     Train net output #0: loss = 1.09917 (* 1 = 1.09917 loss)
I0524 01:11:13.594208  8498 sgd_solver.cpp:106] Iteration 39804, lr = 0.002
I0524 01:11:43.354156  8498 solver.cpp:237] Iteration 40018, loss = 1.31007
I0524 01:11:43.354205  8498 solver.cpp:253]     Train net output #0: loss = 1.31007 (* 1 = 1.31007 loss)
I0524 01:11:43.354221  8498 sgd_solver.cpp:106] Iteration 40018, lr = 0.002
I0524 01:11:52.257936  8498 solver.cpp:237] Iteration 40232, loss = 1.19801
I0524 01:11:52.258105  8498 solver.cpp:253]     Train net output #0: loss = 1.19801 (* 1 = 1.19801 loss)
I0524 01:11:52.258118  8498 sgd_solver.cpp:106] Iteration 40232, lr = 0.002
I0524 01:12:01.160650  8498 solver.cpp:237] Iteration 40446, loss = 1.42114
I0524 01:12:01.160686  8498 solver.cpp:253]     Train net output #0: loss = 1.42114 (* 1 = 1.42114 loss)
I0524 01:12:01.160701  8498 sgd_solver.cpp:106] Iteration 40446, lr = 0.002
I0524 01:12:10.063128  8498 solver.cpp:237] Iteration 40660, loss = 1.14945
I0524 01:12:10.063164  8498 solver.cpp:253]     Train net output #0: loss = 1.14945 (* 1 = 1.14945 loss)
I0524 01:12:10.063179  8498 sgd_solver.cpp:106] Iteration 40660, lr = 0.002
I0524 01:12:11.600991  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_40698.caffemodel
I0524 01:12:11.682487  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_40698.solverstate
I0524 01:12:19.065227  8498 solver.cpp:237] Iteration 40874, loss = 1.0589
I0524 01:12:19.065275  8498 solver.cpp:253]     Train net output #0: loss = 1.0589 (* 1 = 1.0589 loss)
I0524 01:12:19.065291  8498 sgd_solver.cpp:106] Iteration 40874, lr = 0.002
I0524 01:12:27.962347  8498 solver.cpp:237] Iteration 41088, loss = 0.918477
I0524 01:12:27.962507  8498 solver.cpp:253]     Train net output #0: loss = 0.918477 (* 1 = 0.918477 loss)
I0524 01:12:27.962522  8498 sgd_solver.cpp:106] Iteration 41088, lr = 0.002
I0524 01:12:36.861603  8498 solver.cpp:237] Iteration 41302, loss = 1.20043
I0524 01:12:36.861637  8498 solver.cpp:253]     Train net output #0: loss = 1.20043 (* 1 = 1.20043 loss)
I0524 01:12:36.861659  8498 sgd_solver.cpp:106] Iteration 41302, lr = 0.002
I0524 01:13:06.666388  8498 solver.cpp:237] Iteration 41516, loss = 1.2119
I0524 01:13:06.666568  8498 solver.cpp:253]     Train net output #0: loss = 1.2119 (* 1 = 1.2119 loss)
I0524 01:13:06.666581  8498 sgd_solver.cpp:106] Iteration 41516, lr = 0.002
I0524 01:13:15.566121  8498 solver.cpp:237] Iteration 41730, loss = 1.32262
I0524 01:13:15.566155  8498 solver.cpp:253]     Train net output #0: loss = 1.32262 (* 1 = 1.32262 loss)
I0524 01:13:15.566171  8498 sgd_solver.cpp:106] Iteration 41730, lr = 0.002
I0524 01:13:24.463891  8498 solver.cpp:237] Iteration 41944, loss = 1.26601
I0524 01:13:24.463925  8498 solver.cpp:253]     Train net output #0: loss = 1.26601 (* 1 = 1.26601 loss)
I0524 01:13:24.463939  8498 sgd_solver.cpp:106] Iteration 41944, lr = 0.002
I0524 01:13:33.367285  8498 solver.cpp:237] Iteration 42158, loss = 1.06502
I0524 01:13:33.367328  8498 solver.cpp:253]     Train net output #0: loss = 1.06502 (* 1 = 1.06502 loss)
I0524 01:13:33.367344  8498 sgd_solver.cpp:106] Iteration 42158, lr = 0.002
I0524 01:13:42.265763  8498 solver.cpp:237] Iteration 42372, loss = 1.16174
I0524 01:13:42.265926  8498 solver.cpp:253]     Train net output #0: loss = 1.16174 (* 1 = 1.16174 loss)
I0524 01:13:42.265940  8498 sgd_solver.cpp:106] Iteration 42372, lr = 0.002
I0524 01:13:51.159494  8498 solver.cpp:237] Iteration 42586, loss = 1.19112
I0524 01:13:51.159528  8498 solver.cpp:253]     Train net output #0: loss = 1.19112 (* 1 = 1.19112 loss)
I0524 01:13:51.159550  8498 sgd_solver.cpp:106] Iteration 42586, lr = 0.002
I0524 01:14:00.055526  8498 solver.cpp:237] Iteration 42800, loss = 1.39475
I0524 01:14:00.055569  8498 solver.cpp:253]     Train net output #0: loss = 1.39475 (* 1 = 1.39475 loss)
I0524 01:14:00.055586  8498 sgd_solver.cpp:106] Iteration 42800, lr = 0.002
I0524 01:14:01.677803  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_42840.caffemodel
I0524 01:14:01.759521  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_42840.solverstate
I0524 01:14:02.189337  8498 solver.cpp:341] Iteration 42850, Testing net (#0)
I0524 01:15:10.993685  8498 solver.cpp:409]     Test net output #0: accuracy = 0.875377
I0524 01:15:10.993863  8498 solver.cpp:409]     Test net output #1: loss = 0.423421 (* 1 = 0.423421 loss)
I0524 01:15:38.711400  8498 solver.cpp:237] Iteration 43014, loss = 1.14553
I0524 01:15:38.711448  8498 solver.cpp:253]     Train net output #0: loss = 1.14553 (* 1 = 1.14553 loss)
I0524 01:15:38.711465  8498 sgd_solver.cpp:106] Iteration 43014, lr = 0.002
I0524 01:15:47.589571  8498 solver.cpp:237] Iteration 43228, loss = 1.06516
I0524 01:15:47.589740  8498 solver.cpp:253]     Train net output #0: loss = 1.06516 (* 1 = 1.06516 loss)
I0524 01:15:47.589753  8498 sgd_solver.cpp:106] Iteration 43228, lr = 0.002
I0524 01:15:56.472383  8498 solver.cpp:237] Iteration 43442, loss = 1.01587
I0524 01:15:56.472417  8498 solver.cpp:253]     Train net output #0: loss = 1.01587 (* 1 = 1.01587 loss)
I0524 01:15:56.472434  8498 sgd_solver.cpp:106] Iteration 43442, lr = 0.002
I0524 01:16:05.343137  8498 solver.cpp:237] Iteration 43656, loss = 1.1593
I0524 01:16:05.343184  8498 solver.cpp:253]     Train net output #0: loss = 1.1593 (* 1 = 1.1593 loss)
I0524 01:16:05.343199  8498 sgd_solver.cpp:106] Iteration 43656, lr = 0.002
I0524 01:16:14.215291  8498 solver.cpp:237] Iteration 43870, loss = 1.1724
I0524 01:16:14.215325  8498 solver.cpp:253]     Train net output #0: loss = 1.1724 (* 1 = 1.1724 loss)
I0524 01:16:14.215339  8498 sgd_solver.cpp:106] Iteration 43870, lr = 0.002
I0524 01:16:23.088891  8498 solver.cpp:237] Iteration 44084, loss = 1.18077
I0524 01:16:23.089064  8498 solver.cpp:253]     Train net output #0: loss = 1.18077 (* 1 = 1.18077 loss)
I0524 01:16:23.089078  8498 sgd_solver.cpp:106] Iteration 44084, lr = 0.002
I0524 01:16:52.846141  8498 solver.cpp:237] Iteration 44298, loss = 1.21826
I0524 01:16:52.846190  8498 solver.cpp:253]     Train net output #0: loss = 1.21826 (* 1 = 1.21826 loss)
I0524 01:16:52.846205  8498 sgd_solver.cpp:106] Iteration 44298, lr = 0.002
I0524 01:17:01.723567  8498 solver.cpp:237] Iteration 44512, loss = 1.43878
I0524 01:17:01.723740  8498 solver.cpp:253]     Train net output #0: loss = 1.43878 (* 1 = 1.43878 loss)
I0524 01:17:01.723754  8498 sgd_solver.cpp:106] Iteration 44512, lr = 0.002
I0524 01:17:10.606014  8498 solver.cpp:237] Iteration 44726, loss = 1.06344
I0524 01:17:10.606047  8498 solver.cpp:253]     Train net output #0: loss = 1.06344 (* 1 = 1.06344 loss)
I0524 01:17:10.606063  8498 sgd_solver.cpp:106] Iteration 44726, lr = 0.002
I0524 01:17:19.487098  8498 solver.cpp:237] Iteration 44940, loss = 1.19952
I0524 01:17:19.487141  8498 solver.cpp:253]     Train net output #0: loss = 1.19952 (* 1 = 1.19952 loss)
I0524 01:17:19.487159  8498 sgd_solver.cpp:106] Iteration 44940, lr = 0.002
I0524 01:17:21.186615  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_44982.caffemodel
I0524 01:17:21.261803  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_44982.solverstate
I0524 01:17:28.438549  8498 solver.cpp:237] Iteration 45154, loss = 1.25412
I0524 01:17:28.438597  8498 solver.cpp:253]     Train net output #0: loss = 1.25412 (* 1 = 1.25412 loss)
I0524 01:17:28.438611  8498 sgd_solver.cpp:106] Iteration 45154, lr = 0.002
I0524 01:17:37.307510  8498 solver.cpp:237] Iteration 45368, loss = 0.987176
I0524 01:17:37.307695  8498 solver.cpp:253]     Train net output #0: loss = 0.987176 (* 1 = 0.987176 loss)
I0524 01:17:37.307713  8498 sgd_solver.cpp:106] Iteration 45368, lr = 0.002
I0524 01:17:46.189496  8498 solver.cpp:237] Iteration 45582, loss = 1.32349
I0524 01:17:46.189541  8498 solver.cpp:253]     Train net output #0: loss = 1.32349 (* 1 = 1.32349 loss)
I0524 01:17:46.189555  8498 sgd_solver.cpp:106] Iteration 45582, lr = 0.002
I0524 01:18:15.948806  8498 solver.cpp:237] Iteration 45796, loss = 1.04674
I0524 01:18:15.949000  8498 solver.cpp:253]     Train net output #0: loss = 1.04674 (* 1 = 1.04674 loss)
I0524 01:18:15.949014  8498 sgd_solver.cpp:106] Iteration 45796, lr = 0.002
I0524 01:18:24.820765  8498 solver.cpp:237] Iteration 46010, loss = 1.25654
I0524 01:18:24.820799  8498 solver.cpp:253]     Train net output #0: loss = 1.25654 (* 1 = 1.25654 loss)
I0524 01:18:24.820814  8498 sgd_solver.cpp:106] Iteration 46010, lr = 0.002
I0524 01:18:33.703234  8498 solver.cpp:237] Iteration 46224, loss = 1.04623
I0524 01:18:33.703281  8498 solver.cpp:253]     Train net output #0: loss = 1.04623 (* 1 = 1.04623 loss)
I0524 01:18:33.703295  8498 sgd_solver.cpp:106] Iteration 46224, lr = 0.002
I0524 01:18:42.584307  8498 solver.cpp:237] Iteration 46438, loss = 1.35605
I0524 01:18:42.584342  8498 solver.cpp:253]     Train net output #0: loss = 1.35605 (* 1 = 1.35605 loss)
I0524 01:18:42.584357  8498 sgd_solver.cpp:106] Iteration 46438, lr = 0.002
I0524 01:18:51.464221  8498 solver.cpp:237] Iteration 46652, loss = 1.01151
I0524 01:18:51.464375  8498 solver.cpp:253]     Train net output #0: loss = 1.01151 (* 1 = 1.01151 loss)
I0524 01:18:51.464390  8498 sgd_solver.cpp:106] Iteration 46652, lr = 0.002
I0524 01:19:00.341547  8498 solver.cpp:237] Iteration 46866, loss = 1.19383
I0524 01:19:00.341590  8498 solver.cpp:253]     Train net output #0: loss = 1.19383 (* 1 = 1.19383 loss)
I0524 01:19:00.341606  8498 sgd_solver.cpp:106] Iteration 46866, lr = 0.002
I0524 01:19:09.219267  8498 solver.cpp:237] Iteration 47080, loss = 1.22718
I0524 01:19:09.219301  8498 solver.cpp:253]     Train net output #0: loss = 1.22718 (* 1 = 1.22718 loss)
I0524 01:19:09.219316  8498 sgd_solver.cpp:106] Iteration 47080, lr = 0.002
I0524 01:19:11.001713  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_47124.caffemodel
I0524 01:19:11.093266  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_47124.solverstate
I0524 01:19:11.565163  8498 solver.cpp:341] Iteration 47135, Testing net (#0)
I0524 01:19:59.223546  8498 solver.cpp:409]     Test net output #0: accuracy = 0.879305
I0524 01:19:59.223719  8498 solver.cpp:409]     Test net output #1: loss = 0.404438 (* 1 = 0.404438 loss)
I0524 01:20:26.708405  8498 solver.cpp:237] Iteration 47294, loss = 1.12511
I0524 01:20:26.708456  8498 solver.cpp:253]     Train net output #0: loss = 1.12511 (* 1 = 1.12511 loss)
I0524 01:20:26.708470  8498 sgd_solver.cpp:106] Iteration 47294, lr = 0.002
I0524 01:20:35.591814  8498 solver.cpp:237] Iteration 47508, loss = 1.28526
I0524 01:20:35.591997  8498 solver.cpp:253]     Train net output #0: loss = 1.28526 (* 1 = 1.28526 loss)
I0524 01:20:35.592012  8498 sgd_solver.cpp:106] Iteration 47508, lr = 0.002
I0524 01:20:44.465874  8498 solver.cpp:237] Iteration 47722, loss = 0.959244
I0524 01:20:44.465909  8498 solver.cpp:253]     Train net output #0: loss = 0.959244 (* 1 = 0.959244 loss)
I0524 01:20:44.465924  8498 sgd_solver.cpp:106] Iteration 47722, lr = 0.002
I0524 01:20:53.349408  8498 solver.cpp:237] Iteration 47936, loss = 1.13747
I0524 01:20:53.349444  8498 solver.cpp:253]     Train net output #0: loss = 1.13747 (* 1 = 1.13747 loss)
I0524 01:20:53.349457  8498 sgd_solver.cpp:106] Iteration 47936, lr = 0.002
I0524 01:21:02.222503  8498 solver.cpp:237] Iteration 48150, loss = 1.30195
I0524 01:21:02.222543  8498 solver.cpp:253]     Train net output #0: loss = 1.30195 (* 1 = 1.30195 loss)
I0524 01:21:02.222561  8498 sgd_solver.cpp:106] Iteration 48150, lr = 0.002
I0524 01:21:11.101501  8498 solver.cpp:237] Iteration 48364, loss = 1.00898
I0524 01:21:11.101661  8498 solver.cpp:253]     Train net output #0: loss = 1.00898 (* 1 = 1.00898 loss)
I0524 01:21:11.101675  8498 sgd_solver.cpp:106] Iteration 48364, lr = 0.002
I0524 01:21:40.879288  8498 solver.cpp:237] Iteration 48578, loss = 1.42457
I0524 01:21:40.879338  8498 solver.cpp:253]     Train net output #0: loss = 1.42457 (* 1 = 1.42457 loss)
I0524 01:21:40.879354  8498 sgd_solver.cpp:106] Iteration 48578, lr = 0.002
I0524 01:21:49.754653  8498 solver.cpp:237] Iteration 48792, loss = 1.02047
I0524 01:21:49.754840  8498 solver.cpp:253]     Train net output #0: loss = 1.02047 (* 1 = 1.02047 loss)
I0524 01:21:49.754855  8498 sgd_solver.cpp:106] Iteration 48792, lr = 0.002
I0524 01:21:58.638173  8498 solver.cpp:237] Iteration 49006, loss = 1.1309
I0524 01:21:58.638206  8498 solver.cpp:253]     Train net output #0: loss = 1.1309 (* 1 = 1.1309 loss)
I0524 01:21:58.638223  8498 sgd_solver.cpp:106] Iteration 49006, lr = 0.002
I0524 01:22:07.517494  8498 solver.cpp:237] Iteration 49220, loss = 1.15397
I0524 01:22:07.517529  8498 solver.cpp:253]     Train net output #0: loss = 1.15397 (* 1 = 1.15397 loss)
I0524 01:22:07.517544  8498 sgd_solver.cpp:106] Iteration 49220, lr = 0.002
I0524 01:22:09.387161  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_49266.caffemodel
I0524 01:22:09.452900  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_49266.solverstate
I0524 01:22:16.464027  8498 solver.cpp:237] Iteration 49434, loss = 1.27897
I0524 01:22:16.464072  8498 solver.cpp:253]     Train net output #0: loss = 1.27897 (* 1 = 1.27897 loss)
I0524 01:22:16.464089  8498 sgd_solver.cpp:106] Iteration 49434, lr = 0.002
I0524 01:22:25.342232  8498 solver.cpp:237] Iteration 49648, loss = 1.36042
I0524 01:22:25.342392  8498 solver.cpp:253]     Train net output #0: loss = 1.36042 (* 1 = 1.36042 loss)
I0524 01:22:25.342406  8498 sgd_solver.cpp:106] Iteration 49648, lr = 0.002
I0524 01:22:34.219023  8498 solver.cpp:237] Iteration 49862, loss = 1.2391
I0524 01:22:34.219058  8498 solver.cpp:253]     Train net output #0: loss = 1.2391 (* 1 = 1.2391 loss)
I0524 01:22:34.219072  8498 sgd_solver.cpp:106] Iteration 49862, lr = 0.002
I0524 01:23:03.945448  8498 solver.cpp:237] Iteration 50076, loss = 1.12263
I0524 01:23:03.945624  8498 solver.cpp:253]     Train net output #0: loss = 1.12263 (* 1 = 1.12263 loss)
I0524 01:23:03.945638  8498 sgd_solver.cpp:106] Iteration 50076, lr = 0.002
I0524 01:23:12.827042  8498 solver.cpp:237] Iteration 50290, loss = 0.939961
I0524 01:23:12.827078  8498 solver.cpp:253]     Train net output #0: loss = 0.939961 (* 1 = 0.939961 loss)
I0524 01:23:12.827092  8498 sgd_solver.cpp:106] Iteration 50290, lr = 0.002
I0524 01:23:21.706292  8498 solver.cpp:237] Iteration 50504, loss = 1.1041
I0524 01:23:21.706328  8498 solver.cpp:253]     Train net output #0: loss = 1.1041 (* 1 = 1.1041 loss)
I0524 01:23:21.706341  8498 sgd_solver.cpp:106] Iteration 50504, lr = 0.002
I0524 01:23:30.586536  8498 solver.cpp:237] Iteration 50718, loss = 1.15586
I0524 01:23:30.586576  8498 solver.cpp:253]     Train net output #0: loss = 1.15586 (* 1 = 1.15586 loss)
I0524 01:23:30.586596  8498 sgd_solver.cpp:106] Iteration 50718, lr = 0.002
I0524 01:23:39.461457  8498 solver.cpp:237] Iteration 50932, loss = 1.18345
I0524 01:23:39.461623  8498 solver.cpp:253]     Train net output #0: loss = 1.18345 (* 1 = 1.18345 loss)
I0524 01:23:39.461637  8498 sgd_solver.cpp:106] Iteration 50932, lr = 0.002
I0524 01:23:48.342634  8498 solver.cpp:237] Iteration 51146, loss = 1.29955
I0524 01:23:48.342669  8498 solver.cpp:253]     Train net output #0: loss = 1.29955 (* 1 = 1.29955 loss)
I0524 01:23:48.342684  8498 sgd_solver.cpp:106] Iteration 51146, lr = 0.002
I0524 01:23:57.224907  8498 solver.cpp:237] Iteration 51360, loss = 0.962331
I0524 01:23:57.224946  8498 solver.cpp:253]     Train net output #0: loss = 0.962331 (* 1 = 0.962331 loss)
I0524 01:23:57.224964  8498 sgd_solver.cpp:106] Iteration 51360, lr = 0.002
I0524 01:23:59.175647  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_51408.caffemodel
I0524 01:23:59.241370  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_51408.solverstate
I0524 01:23:59.737982  8498 solver.cpp:341] Iteration 51420, Testing net (#0)
I0524 01:25:08.496418  8498 solver.cpp:409]     Test net output #0: accuracy = 0.8832
I0524 01:25:08.496595  8498 solver.cpp:409]     Test net output #1: loss = 0.394273 (* 1 = 0.394273 loss)
I0524 01:25:35.725462  8498 solver.cpp:237] Iteration 51574, loss = 1.34731
I0524 01:25:35.725512  8498 solver.cpp:253]     Train net output #0: loss = 1.34731 (* 1 = 1.34731 loss)
I0524 01:25:35.725525  8498 sgd_solver.cpp:106] Iteration 51574, lr = 0.002
I0524 01:25:44.604269  8498 solver.cpp:237] Iteration 51788, loss = 1.31866
I0524 01:25:44.604442  8498 solver.cpp:253]     Train net output #0: loss = 1.31866 (* 1 = 1.31866 loss)
I0524 01:25:44.604455  8498 sgd_solver.cpp:106] Iteration 51788, lr = 0.002
I0524 01:25:53.486855  8498 solver.cpp:237] Iteration 52002, loss = 1.09261
I0524 01:25:53.486889  8498 solver.cpp:253]     Train net output #0: loss = 1.09261 (* 1 = 1.09261 loss)
I0524 01:25:53.486904  8498 sgd_solver.cpp:106] Iteration 52002, lr = 0.002
I0524 01:26:02.363461  8498 solver.cpp:237] Iteration 52216, loss = 1.08591
I0524 01:26:02.363502  8498 solver.cpp:253]     Train net output #0: loss = 1.08591 (* 1 = 1.08591 loss)
I0524 01:26:02.363522  8498 sgd_solver.cpp:106] Iteration 52216, lr = 0.002
I0524 01:26:11.243769  8498 solver.cpp:237] Iteration 52430, loss = 1.0507
I0524 01:26:11.243804  8498 solver.cpp:253]     Train net output #0: loss = 1.0507 (* 1 = 1.0507 loss)
I0524 01:26:11.243818  8498 sgd_solver.cpp:106] Iteration 52430, lr = 0.002
I0524 01:26:20.120065  8498 solver.cpp:237] Iteration 52644, loss = 1.13792
I0524 01:26:20.120225  8498 solver.cpp:253]     Train net output #0: loss = 1.13792 (* 1 = 1.13792 loss)
I0524 01:26:20.120239  8498 sgd_solver.cpp:106] Iteration 52644, lr = 0.002
I0524 01:26:49.852030  8498 solver.cpp:237] Iteration 52858, loss = 0.958911
I0524 01:26:49.852082  8498 solver.cpp:253]     Train net output #0: loss = 0.958911 (* 1 = 0.958911 loss)
I0524 01:26:49.852097  8498 sgd_solver.cpp:106] Iteration 52858, lr = 0.002
I0524 01:26:58.735056  8498 solver.cpp:237] Iteration 53072, loss = 1.31227
I0524 01:26:58.735220  8498 solver.cpp:253]     Train net output #0: loss = 1.31227 (* 1 = 1.31227 loss)
I0524 01:26:58.735234  8498 sgd_solver.cpp:106] Iteration 53072, lr = 0.002
I0524 01:27:07.611241  8498 solver.cpp:237] Iteration 53286, loss = 1.03146
I0524 01:27:07.611275  8498 solver.cpp:253]     Train net output #0: loss = 1.03146 (* 1 = 1.03146 loss)
I0524 01:27:07.611290  8498 sgd_solver.cpp:106] Iteration 53286, lr = 0.002
I0524 01:27:16.486996  8498 solver.cpp:237] Iteration 53500, loss = 1.27792
I0524 01:27:16.487040  8498 solver.cpp:253]     Train net output #0: loss = 1.27792 (* 1 = 1.27792 loss)
I0524 01:27:16.487056  8498 sgd_solver.cpp:106] Iteration 53500, lr = 0.002
I0524 01:27:18.519719  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_53550.caffemodel
I0524 01:27:18.587324  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_53550.solverstate
I0524 01:27:25.428922  8498 solver.cpp:237] Iteration 53714, loss = 1.1982
I0524 01:27:25.428971  8498 solver.cpp:253]     Train net output #0: loss = 1.1982 (* 1 = 1.1982 loss)
I0524 01:27:25.428984  8498 sgd_solver.cpp:106] Iteration 53714, lr = 0.002
I0524 01:27:34.303544  8498 solver.cpp:237] Iteration 53928, loss = 1.17488
I0524 01:27:34.303716  8498 solver.cpp:253]     Train net output #0: loss = 1.17488 (* 1 = 1.17488 loss)
I0524 01:27:34.303730  8498 sgd_solver.cpp:106] Iteration 53928, lr = 0.002
I0524 01:27:43.182335  8498 solver.cpp:237] Iteration 54142, loss = 1.16415
I0524 01:27:43.182379  8498 solver.cpp:253]     Train net output #0: loss = 1.16415 (* 1 = 1.16415 loss)
I0524 01:27:43.182399  8498 sgd_solver.cpp:106] Iteration 54142, lr = 0.002
I0524 01:28:12.918198  8498 solver.cpp:237] Iteration 54356, loss = 1.23058
I0524 01:28:12.918382  8498 solver.cpp:253]     Train net output #0: loss = 1.23058 (* 1 = 1.23058 loss)
I0524 01:28:12.918396  8498 sgd_solver.cpp:106] Iteration 54356, lr = 0.002
I0524 01:28:21.793614  8498 solver.cpp:237] Iteration 54570, loss = 0.974831
I0524 01:28:21.793649  8498 solver.cpp:253]     Train net output #0: loss = 0.974831 (* 1 = 0.974831 loss)
I0524 01:28:21.793669  8498 sgd_solver.cpp:106] Iteration 54570, lr = 0.002
I0524 01:28:30.667506  8498 solver.cpp:237] Iteration 54784, loss = 1.17201
I0524 01:28:30.667548  8498 solver.cpp:253]     Train net output #0: loss = 1.17201 (* 1 = 1.17201 loss)
I0524 01:28:30.667567  8498 sgd_solver.cpp:106] Iteration 54784, lr = 0.002
I0524 01:28:39.541215  8498 solver.cpp:237] Iteration 54998, loss = 1.49385
I0524 01:28:39.541251  8498 solver.cpp:253]     Train net output #0: loss = 1.49385 (* 1 = 1.49385 loss)
I0524 01:28:39.541265  8498 sgd_solver.cpp:106] Iteration 54998, lr = 0.002
I0524 01:28:48.423944  8498 solver.cpp:237] Iteration 55212, loss = 1.19484
I0524 01:28:48.424106  8498 solver.cpp:253]     Train net output #0: loss = 1.19484 (* 1 = 1.19484 loss)
I0524 01:28:48.424120  8498 sgd_solver.cpp:106] Iteration 55212, lr = 0.002
I0524 01:28:57.305214  8498 solver.cpp:237] Iteration 55426, loss = 1.1503
I0524 01:28:57.305256  8498 solver.cpp:253]     Train net output #0: loss = 1.1503 (* 1 = 1.1503 loss)
I0524 01:28:57.305275  8498 sgd_solver.cpp:106] Iteration 55426, lr = 0.002
I0524 01:29:06.188134  8498 solver.cpp:237] Iteration 55640, loss = 1.0491
I0524 01:29:06.188169  8498 solver.cpp:253]     Train net output #0: loss = 1.0491 (* 1 = 1.0491 loss)
I0524 01:29:06.188182  8498 sgd_solver.cpp:106] Iteration 55640, lr = 0.002
I0524 01:29:08.301405  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_55692.caffemodel
I0524 01:29:08.367502  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_55692.solverstate
I0524 01:29:08.903952  8498 solver.cpp:341] Iteration 55705, Testing net (#0)
I0524 01:29:56.860334  8498 solver.cpp:409]     Test net output #0: accuracy = 0.880106
I0524 01:29:56.860527  8498 solver.cpp:409]     Test net output #1: loss = 0.401085 (* 1 = 0.401085 loss)
I0524 01:30:23.869114  8498 solver.cpp:237] Iteration 55854, loss = 0.774214
I0524 01:30:23.869166  8498 solver.cpp:253]     Train net output #0: loss = 0.774214 (* 1 = 0.774214 loss)
I0524 01:30:23.869180  8498 sgd_solver.cpp:106] Iteration 55854, lr = 0.002
I0524 01:30:32.734632  8498 solver.cpp:237] Iteration 56068, loss = 1.33262
I0524 01:30:32.734798  8498 solver.cpp:253]     Train net output #0: loss = 1.33262 (* 1 = 1.33262 loss)
I0524 01:30:32.734812  8498 sgd_solver.cpp:106] Iteration 56068, lr = 0.002
I0524 01:30:41.604562  8498 solver.cpp:237] Iteration 56282, loss = 1.13996
I0524 01:30:41.604604  8498 solver.cpp:253]     Train net output #0: loss = 1.13996 (* 1 = 1.13996 loss)
I0524 01:30:41.604621  8498 sgd_solver.cpp:106] Iteration 56282, lr = 0.002
I0524 01:30:50.470365  8498 solver.cpp:237] Iteration 56496, loss = 1.3792
I0524 01:30:50.470399  8498 solver.cpp:253]     Train net output #0: loss = 1.3792 (* 1 = 1.3792 loss)
I0524 01:30:50.470412  8498 sgd_solver.cpp:106] Iteration 56496, lr = 0.002
I0524 01:30:59.336907  8498 solver.cpp:237] Iteration 56710, loss = 1.24401
I0524 01:30:59.336946  8498 solver.cpp:253]     Train net output #0: loss = 1.24401 (* 1 = 1.24401 loss)
I0524 01:30:59.336966  8498 sgd_solver.cpp:106] Iteration 56710, lr = 0.002
I0524 01:31:08.202019  8498 solver.cpp:237] Iteration 56924, loss = 1.25563
I0524 01:31:08.202183  8498 solver.cpp:253]     Train net output #0: loss = 1.25563 (* 1 = 1.25563 loss)
I0524 01:31:08.202196  8498 sgd_solver.cpp:106] Iteration 56924, lr = 0.002
I0524 01:31:17.074625  8498 solver.cpp:237] Iteration 57138, loss = 1.23202
I0524 01:31:17.074658  8498 solver.cpp:253]     Train net output #0: loss = 1.23202 (* 1 = 1.23202 loss)
I0524 01:31:17.074673  8498 sgd_solver.cpp:106] Iteration 57138, lr = 0.002
I0524 01:31:46.772289  8498 solver.cpp:237] Iteration 57352, loss = 1.32361
I0524 01:31:46.772474  8498 solver.cpp:253]     Train net output #0: loss = 1.32361 (* 1 = 1.32361 loss)
I0524 01:31:46.772487  8498 sgd_solver.cpp:106] Iteration 57352, lr = 0.002
I0524 01:31:55.645025  8498 solver.cpp:237] Iteration 57566, loss = 1.24737
I0524 01:31:55.645068  8498 solver.cpp:253]     Train net output #0: loss = 1.24737 (* 1 = 1.24737 loss)
I0524 01:31:55.645087  8498 sgd_solver.cpp:106] Iteration 57566, lr = 0.002
I0524 01:32:04.517225  8498 solver.cpp:237] Iteration 57780, loss = 1.19673
I0524 01:32:04.517261  8498 solver.cpp:253]     Train net output #0: loss = 1.19673 (* 1 = 1.19673 loss)
I0524 01:32:04.517274  8498 sgd_solver.cpp:106] Iteration 57780, lr = 0.002
I0524 01:32:06.710852  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_57834.caffemodel
I0524 01:32:06.777079  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_57834.solverstate
I0524 01:32:13.448377  8498 solver.cpp:237] Iteration 57994, loss = 1.15736
I0524 01:32:13.448423  8498 solver.cpp:253]     Train net output #0: loss = 1.15736 (* 1 = 1.15736 loss)
I0524 01:32:13.448437  8498 sgd_solver.cpp:106] Iteration 57994, lr = 0.002
I0524 01:32:22.320207  8498 solver.cpp:237] Iteration 58208, loss = 1.63283
I0524 01:32:22.320379  8498 solver.cpp:253]     Train net output #0: loss = 1.63283 (* 1 = 1.63283 loss)
I0524 01:32:22.320394  8498 sgd_solver.cpp:106] Iteration 58208, lr = 0.002
I0524 01:32:31.187136  8498 solver.cpp:237] Iteration 58422, loss = 1.24825
I0524 01:32:31.187171  8498 solver.cpp:253]     Train net output #0: loss = 1.24825 (* 1 = 1.24825 loss)
I0524 01:32:31.187185  8498 sgd_solver.cpp:106] Iteration 58422, lr = 0.002
I0524 01:33:00.934460  8498 solver.cpp:237] Iteration 58636, loss = 1.18118
I0524 01:33:00.934645  8498 solver.cpp:253]     Train net output #0: loss = 1.18118 (* 1 = 1.18118 loss)
I0524 01:33:00.934660  8498 sgd_solver.cpp:106] Iteration 58636, lr = 0.002
I0524 01:33:09.808185  8498 solver.cpp:237] Iteration 58850, loss = 1.03971
I0524 01:33:09.808229  8498 solver.cpp:253]     Train net output #0: loss = 1.03971 (* 1 = 1.03971 loss)
I0524 01:33:09.808245  8498 sgd_solver.cpp:106] Iteration 58850, lr = 0.002
I0524 01:33:18.676319  8498 solver.cpp:237] Iteration 59064, loss = 1.00186
I0524 01:33:18.676355  8498 solver.cpp:253]     Train net output #0: loss = 1.00186 (* 1 = 1.00186 loss)
I0524 01:33:18.676369  8498 sgd_solver.cpp:106] Iteration 59064, lr = 0.002
I0524 01:33:27.545735  8498 solver.cpp:237] Iteration 59278, loss = 1.18339
I0524 01:33:27.545771  8498 solver.cpp:253]     Train net output #0: loss = 1.18339 (* 1 = 1.18339 loss)
I0524 01:33:27.545785  8498 sgd_solver.cpp:106] Iteration 59278, lr = 0.002
I0524 01:33:36.417742  8498 solver.cpp:237] Iteration 59492, loss = 1.21431
I0524 01:33:36.417928  8498 solver.cpp:253]     Train net output #0: loss = 1.21431 (* 1 = 1.21431 loss)
I0524 01:33:36.417943  8498 sgd_solver.cpp:106] Iteration 59492, lr = 0.002
I0524 01:33:45.283284  8498 solver.cpp:237] Iteration 59706, loss = 1.19721
I0524 01:33:45.283319  8498 solver.cpp:253]     Train net output #0: loss = 1.19721 (* 1 = 1.19721 loss)
I0524 01:33:45.283334  8498 sgd_solver.cpp:106] Iteration 59706, lr = 0.002
I0524 01:33:54.150485  8498 solver.cpp:237] Iteration 59920, loss = 1.02742
I0524 01:33:54.150530  8498 solver.cpp:253]     Train net output #0: loss = 1.02742 (* 1 = 1.02742 loss)
I0524 01:33:54.150544  8498 sgd_solver.cpp:106] Iteration 59920, lr = 0.002
I0524 01:33:56.430297  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_59976.caffemodel
I0524 01:33:56.496435  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_59976.solverstate
I0524 01:33:57.074977  8498 solver.cpp:341] Iteration 59990, Testing net (#0)
I0524 01:35:05.816170  8498 solver.cpp:409]     Test net output #0: accuracy = 0.883794
I0524 01:35:05.816354  8498 solver.cpp:409]     Test net output #1: loss = 0.395765 (* 1 = 0.395765 loss)
I0524 01:35:32.625522  8498 solver.cpp:237] Iteration 60134, loss = 1.20343
I0524 01:35:32.625573  8498 solver.cpp:253]     Train net output #0: loss = 1.20343 (* 1 = 1.20343 loss)
I0524 01:35:32.625587  8498 sgd_solver.cpp:106] Iteration 60134, lr = 0.002
I0524 01:35:41.507407  8498 solver.cpp:237] Iteration 60348, loss = 1.1256
I0524 01:35:41.507586  8498 solver.cpp:253]     Train net output #0: loss = 1.1256 (* 1 = 1.1256 loss)
I0524 01:35:41.507601  8498 sgd_solver.cpp:106] Iteration 60348, lr = 0.002
I0524 01:35:50.389473  8498 solver.cpp:237] Iteration 60562, loss = 1.35244
I0524 01:35:50.389508  8498 solver.cpp:253]     Train net output #0: loss = 1.35244 (* 1 = 1.35244 loss)
I0524 01:35:50.389523  8498 sgd_solver.cpp:106] Iteration 60562, lr = 0.002
I0524 01:35:59.273044  8498 solver.cpp:237] Iteration 60776, loss = 1.16145
I0524 01:35:59.273092  8498 solver.cpp:253]     Train net output #0: loss = 1.16145 (* 1 = 1.16145 loss)
I0524 01:35:59.273107  8498 sgd_solver.cpp:106] Iteration 60776, lr = 0.002
I0524 01:36:08.151310  8498 solver.cpp:237] Iteration 60990, loss = 1.12017
I0524 01:36:08.151345  8498 solver.cpp:253]     Train net output #0: loss = 1.12017 (* 1 = 1.12017 loss)
I0524 01:36:08.151360  8498 sgd_solver.cpp:106] Iteration 60990, lr = 0.002
I0524 01:36:17.034734  8498 solver.cpp:237] Iteration 61204, loss = 1.0038
I0524 01:36:17.034905  8498 solver.cpp:253]     Train net output #0: loss = 1.0038 (* 1 = 1.0038 loss)
I0524 01:36:17.034919  8498 sgd_solver.cpp:106] Iteration 61204, lr = 0.002
I0524 01:36:25.918447  8498 solver.cpp:237] Iteration 61418, loss = 1.20436
I0524 01:36:25.918486  8498 solver.cpp:253]     Train net output #0: loss = 1.20436 (* 1 = 1.20436 loss)
I0524 01:36:25.918505  8498 sgd_solver.cpp:106] Iteration 61418, lr = 0.002
I0524 01:36:55.664877  8498 solver.cpp:237] Iteration 61632, loss = 1.14022
I0524 01:36:55.665071  8498 solver.cpp:253]     Train net output #0: loss = 1.14022 (* 1 = 1.14022 loss)
I0524 01:36:55.665086  8498 sgd_solver.cpp:106] Iteration 61632, lr = 0.002
I0524 01:37:04.554029  8498 solver.cpp:237] Iteration 61846, loss = 1.34633
I0524 01:37:04.554064  8498 solver.cpp:253]     Train net output #0: loss = 1.34633 (* 1 = 1.34633 loss)
I0524 01:37:04.554078  8498 sgd_solver.cpp:106] Iteration 61846, lr = 0.002
I0524 01:37:13.445216  8498 solver.cpp:237] Iteration 62060, loss = 1.14884
I0524 01:37:13.445251  8498 solver.cpp:253]     Train net output #0: loss = 1.14884 (* 1 = 1.14884 loss)
I0524 01:37:13.445266  8498 sgd_solver.cpp:106] Iteration 62060, lr = 0.002
I0524 01:37:15.810847  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_62118.caffemodel
I0524 01:37:15.878805  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_62118.solverstate
I0524 01:37:22.393201  8498 solver.cpp:237] Iteration 62274, loss = 1.24741
I0524 01:37:22.393249  8498 solver.cpp:253]     Train net output #0: loss = 1.24741 (* 1 = 1.24741 loss)
I0524 01:37:22.393265  8498 sgd_solver.cpp:106] Iteration 62274, lr = 0.002
I0524 01:37:31.273075  8498 solver.cpp:237] Iteration 62488, loss = 1.27485
I0524 01:37:31.273246  8498 solver.cpp:253]     Train net output #0: loss = 1.27485 (* 1 = 1.27485 loss)
I0524 01:37:31.273259  8498 sgd_solver.cpp:106] Iteration 62488, lr = 0.002
I0524 01:37:40.156293  8498 solver.cpp:237] Iteration 62702, loss = 1.31074
I0524 01:37:40.156333  8498 solver.cpp:253]     Train net output #0: loss = 1.31074 (* 1 = 1.31074 loss)
I0524 01:37:40.156347  8498 sgd_solver.cpp:106] Iteration 62702, lr = 0.002
I0524 01:38:09.905254  8498 solver.cpp:237] Iteration 62916, loss = 1.19887
I0524 01:38:09.905437  8498 solver.cpp:253]     Train net output #0: loss = 1.19887 (* 1 = 1.19887 loss)
I0524 01:38:09.905452  8498 sgd_solver.cpp:106] Iteration 62916, lr = 0.002
I0524 01:38:18.799437  8498 solver.cpp:237] Iteration 63130, loss = 1.30283
I0524 01:38:18.799471  8498 solver.cpp:253]     Train net output #0: loss = 1.30283 (* 1 = 1.30283 loss)
I0524 01:38:18.799487  8498 sgd_solver.cpp:106] Iteration 63130, lr = 0.002
I0524 01:38:27.683665  8498 solver.cpp:237] Iteration 63344, loss = 1.17011
I0524 01:38:27.683699  8498 solver.cpp:253]     Train net output #0: loss = 1.17011 (* 1 = 1.17011 loss)
I0524 01:38:27.683714  8498 sgd_solver.cpp:106] Iteration 63344, lr = 0.002
I0524 01:38:36.575057  8498 solver.cpp:237] Iteration 63558, loss = 1.11544
I0524 01:38:36.575105  8498 solver.cpp:253]     Train net output #0: loss = 1.11544 (* 1 = 1.11544 loss)
I0524 01:38:36.575119  8498 sgd_solver.cpp:106] Iteration 63558, lr = 0.002
I0524 01:38:45.458878  8498 solver.cpp:237] Iteration 63772, loss = 1.10946
I0524 01:38:45.459043  8498 solver.cpp:253]     Train net output #0: loss = 1.10946 (* 1 = 1.10946 loss)
I0524 01:38:45.459056  8498 sgd_solver.cpp:106] Iteration 63772, lr = 0.002
I0524 01:38:54.345530  8498 solver.cpp:237] Iteration 63986, loss = 1.12355
I0524 01:38:54.345574  8498 solver.cpp:253]     Train net output #0: loss = 1.12355 (* 1 = 1.12355 loss)
I0524 01:38:54.345592  8498 sgd_solver.cpp:106] Iteration 63986, lr = 0.002
I0524 01:39:03.225400  8498 solver.cpp:237] Iteration 64200, loss = 1.25312
I0524 01:39:03.225435  8498 solver.cpp:253]     Train net output #0: loss = 1.25312 (* 1 = 1.25312 loss)
I0524 01:39:03.225448  8498 sgd_solver.cpp:106] Iteration 64200, lr = 0.002
I0524 01:39:05.673387  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_64260.caffemodel
I0524 01:39:05.742130  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_64260.solverstate
I0524 01:39:06.364187  8498 solver.cpp:341] Iteration 64275, Testing net (#0)
I0524 01:39:54.024232  8498 solver.cpp:409]     Test net output #0: accuracy = 0.887935
I0524 01:39:54.024425  8498 solver.cpp:409]     Test net output #1: loss = 0.360237 (* 1 = 0.360237 loss)
I0524 01:40:20.722964  8498 solver.cpp:237] Iteration 64414, loss = 1.02975
I0524 01:40:20.723016  8498 solver.cpp:253]     Train net output #0: loss = 1.02975 (* 1 = 1.02975 loss)
I0524 01:40:20.723031  8498 sgd_solver.cpp:106] Iteration 64414, lr = 0.002
I0524 01:40:29.595479  8498 solver.cpp:237] Iteration 64628, loss = 1.12415
I0524 01:40:29.595649  8498 solver.cpp:253]     Train net output #0: loss = 1.12415 (* 1 = 1.12415 loss)
I0524 01:40:29.595662  8498 sgd_solver.cpp:106] Iteration 64628, lr = 0.002
I0524 01:40:38.458919  8498 solver.cpp:237] Iteration 64842, loss = 1.18556
I0524 01:40:38.458958  8498 solver.cpp:253]     Train net output #0: loss = 1.18556 (* 1 = 1.18556 loss)
I0524 01:40:38.458978  8498 sgd_solver.cpp:106] Iteration 64842, lr = 0.002
I0524 01:40:47.321641  8498 solver.cpp:237] Iteration 65056, loss = 1.17133
I0524 01:40:47.321681  8498 solver.cpp:253]     Train net output #0: loss = 1.17133 (* 1 = 1.17133 loss)
I0524 01:40:47.321696  8498 sgd_solver.cpp:106] Iteration 65056, lr = 0.002
I0524 01:40:56.193202  8498 solver.cpp:237] Iteration 65270, loss = 1.31707
I0524 01:40:56.193238  8498 solver.cpp:253]     Train net output #0: loss = 1.31707 (* 1 = 1.31707 loss)
I0524 01:40:56.193250  8498 sgd_solver.cpp:106] Iteration 65270, lr = 0.002
I0524 01:41:05.056618  8498 solver.cpp:237] Iteration 65484, loss = 1.15448
I0524 01:41:05.056797  8498 solver.cpp:253]     Train net output #0: loss = 1.15448 (* 1 = 1.15448 loss)
I0524 01:41:05.056812  8498 sgd_solver.cpp:106] Iteration 65484, lr = 0.002
I0524 01:41:13.930951  8498 solver.cpp:237] Iteration 65698, loss = 1.41102
I0524 01:41:13.930985  8498 solver.cpp:253]     Train net output #0: loss = 1.41102 (* 1 = 1.41102 loss)
I0524 01:41:13.931000  8498 sgd_solver.cpp:106] Iteration 65698, lr = 0.002
I0524 01:41:43.705348  8498 solver.cpp:237] Iteration 65912, loss = 0.994245
I0524 01:41:43.705535  8498 solver.cpp:253]     Train net output #0: loss = 0.994245 (* 1 = 0.994245 loss)
I0524 01:41:43.705552  8498 sgd_solver.cpp:106] Iteration 65912, lr = 0.002
I0524 01:41:52.572341  8498 solver.cpp:237] Iteration 66126, loss = 1.10977
I0524 01:41:52.572386  8498 solver.cpp:253]     Train net output #0: loss = 1.10977 (* 1 = 1.10977 loss)
I0524 01:41:52.572402  8498 sgd_solver.cpp:106] Iteration 66126, lr = 0.002
I0524 01:42:01.439256  8498 solver.cpp:237] Iteration 66340, loss = 1.21774
I0524 01:42:01.439292  8498 solver.cpp:253]     Train net output #0: loss = 1.21774 (* 1 = 1.21774 loss)
I0524 01:42:01.439306  8498 sgd_solver.cpp:106] Iteration 66340, lr = 0.002
I0524 01:42:03.967653  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_66402.caffemodel
I0524 01:42:04.033500  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_66402.solverstate
I0524 01:42:10.376549  8498 solver.cpp:237] Iteration 66554, loss = 1.07796
I0524 01:42:10.376590  8498 solver.cpp:253]     Train net output #0: loss = 1.07796 (* 1 = 1.07796 loss)
I0524 01:42:10.376610  8498 sgd_solver.cpp:106] Iteration 66554, lr = 0.002
I0524 01:42:19.249469  8498 solver.cpp:237] Iteration 66768, loss = 1.09511
I0524 01:42:19.249647  8498 solver.cpp:253]     Train net output #0: loss = 1.09511 (* 1 = 1.09511 loss)
I0524 01:42:19.249667  8498 sgd_solver.cpp:106] Iteration 66768, lr = 0.002
I0524 01:42:28.113282  8498 solver.cpp:237] Iteration 66982, loss = 1.16341
I0524 01:42:28.113317  8498 solver.cpp:253]     Train net output #0: loss = 1.16341 (* 1 = 1.16341 loss)
I0524 01:42:28.113332  8498 sgd_solver.cpp:106] Iteration 66982, lr = 0.002
I0524 01:42:57.858793  8498 solver.cpp:237] Iteration 67196, loss = 1.23
I0524 01:42:57.858991  8498 solver.cpp:253]     Train net output #0: loss = 1.23 (* 1 = 1.23 loss)
I0524 01:42:57.859006  8498 sgd_solver.cpp:106] Iteration 67196, lr = 0.002
I0524 01:43:06.728924  8498 solver.cpp:237] Iteration 67410, loss = 1.28
I0524 01:43:06.728963  8498 solver.cpp:253]     Train net output #0: loss = 1.28 (* 1 = 1.28 loss)
I0524 01:43:06.728982  8498 sgd_solver.cpp:106] Iteration 67410, lr = 0.002
I0524 01:43:15.592277  8498 solver.cpp:237] Iteration 67624, loss = 1.35232
I0524 01:43:15.592311  8498 solver.cpp:253]     Train net output #0: loss = 1.35232 (* 1 = 1.35232 loss)
I0524 01:43:15.592325  8498 sgd_solver.cpp:106] Iteration 67624, lr = 0.002
I0524 01:43:24.457196  8498 solver.cpp:237] Iteration 67838, loss = 1.00906
I0524 01:43:24.457232  8498 solver.cpp:253]     Train net output #0: loss = 1.00906 (* 1 = 1.00906 loss)
I0524 01:43:24.457247  8498 sgd_solver.cpp:106] Iteration 67838, lr = 0.002
I0524 01:43:33.325263  8498 solver.cpp:237] Iteration 68052, loss = 1.16055
I0524 01:43:33.325438  8498 solver.cpp:253]     Train net output #0: loss = 1.16055 (* 1 = 1.16055 loss)
I0524 01:43:33.325451  8498 sgd_solver.cpp:106] Iteration 68052, lr = 0.002
I0524 01:43:42.198840  8498 solver.cpp:237] Iteration 68266, loss = 0.828978
I0524 01:43:42.198875  8498 solver.cpp:253]     Train net output #0: loss = 0.828978 (* 1 = 0.828978 loss)
I0524 01:43:42.198889  8498 sgd_solver.cpp:106] Iteration 68266, lr = 0.002
I0524 01:43:51.070335  8498 solver.cpp:237] Iteration 68480, loss = 1.17109
I0524 01:43:51.070370  8498 solver.cpp:253]     Train net output #0: loss = 1.17109 (* 1 = 1.17109 loss)
I0524 01:43:51.070384  8498 sgd_solver.cpp:106] Iteration 68480, lr = 0.002
I0524 01:43:53.681159  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_68544.caffemodel
I0524 01:43:53.746840  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_68544.solverstate
I0524 01:43:54.408337  8498 solver.cpp:341] Iteration 68560, Testing net (#0)
I0524 01:45:03.261667  8498 solver.cpp:409]     Test net output #0: accuracy = 0.887528
I0524 01:45:03.261857  8498 solver.cpp:409]     Test net output #1: loss = 0.383299 (* 1 = 0.383299 loss)
I0524 01:45:29.717955  8498 solver.cpp:237] Iteration 68694, loss = 1.30613
I0524 01:45:29.718006  8498 solver.cpp:253]     Train net output #0: loss = 1.30613 (* 1 = 1.30613 loss)
I0524 01:45:29.718020  8498 sgd_solver.cpp:106] Iteration 68694, lr = 0.002
I0524 01:45:38.623605  8498 solver.cpp:237] Iteration 68908, loss = 1.15802
I0524 01:45:38.623783  8498 solver.cpp:253]     Train net output #0: loss = 1.15802 (* 1 = 1.15802 loss)
I0524 01:45:38.623796  8498 sgd_solver.cpp:106] Iteration 68908, lr = 0.002
I0524 01:45:47.520493  8498 solver.cpp:237] Iteration 69122, loss = 1.08125
I0524 01:45:47.520527  8498 solver.cpp:253]     Train net output #0: loss = 1.08125 (* 1 = 1.08125 loss)
I0524 01:45:47.520544  8498 sgd_solver.cpp:106] Iteration 69122, lr = 0.002
I0524 01:45:56.415195  8498 solver.cpp:237] Iteration 69336, loss = 1.13528
I0524 01:45:56.415231  8498 solver.cpp:253]     Train net output #0: loss = 1.13528 (* 1 = 1.13528 loss)
I0524 01:45:56.415244  8498 sgd_solver.cpp:106] Iteration 69336, lr = 0.002
I0524 01:46:05.314586  8498 solver.cpp:237] Iteration 69550, loss = 1.49131
I0524 01:46:05.314630  8498 solver.cpp:253]     Train net output #0: loss = 1.49131 (* 1 = 1.49131 loss)
I0524 01:46:05.314648  8498 sgd_solver.cpp:106] Iteration 69550, lr = 0.002
I0524 01:46:14.213874  8498 solver.cpp:237] Iteration 69764, loss = 1.28926
I0524 01:46:14.214040  8498 solver.cpp:253]     Train net output #0: loss = 1.28926 (* 1 = 1.28926 loss)
I0524 01:46:14.214053  8498 sgd_solver.cpp:106] Iteration 69764, lr = 0.002
I0524 01:46:23.115320  8498 solver.cpp:237] Iteration 69978, loss = 1.40569
I0524 01:46:23.115355  8498 solver.cpp:253]     Train net output #0: loss = 1.40569 (* 1 = 1.40569 loss)
I0524 01:46:23.115368  8498 sgd_solver.cpp:106] Iteration 69978, lr = 0.002
I0524 01:46:52.909505  8498 solver.cpp:237] Iteration 70192, loss = 1.00365
I0524 01:46:52.909714  8498 solver.cpp:253]     Train net output #0: loss = 1.00365 (* 1 = 1.00365 loss)
I0524 01:46:52.909729  8498 sgd_solver.cpp:106] Iteration 70192, lr = 0.002
I0524 01:47:01.806345  8498 solver.cpp:237] Iteration 70406, loss = 0.995173
I0524 01:47:01.806380  8498 solver.cpp:253]     Train net output #0: loss = 0.995173 (* 1 = 0.995173 loss)
I0524 01:47:01.806394  8498 sgd_solver.cpp:106] Iteration 70406, lr = 0.002
I0524 01:47:10.706166  8498 solver.cpp:237] Iteration 70620, loss = 1.26398
I0524 01:47:10.706200  8498 solver.cpp:253]     Train net output #0: loss = 1.26398 (* 1 = 1.26398 loss)
I0524 01:47:10.706213  8498 sgd_solver.cpp:106] Iteration 70620, lr = 0.002
I0524 01:47:13.409299  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_70686.caffemodel
I0524 01:47:13.475961  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_70686.solverstate
I0524 01:47:19.673893  8498 solver.cpp:237] Iteration 70834, loss = 1.32948
I0524 01:47:19.673939  8498 solver.cpp:253]     Train net output #0: loss = 1.32948 (* 1 = 1.32948 loss)
I0524 01:47:19.673959  8498 sgd_solver.cpp:106] Iteration 70834, lr = 0.002
I0524 01:47:28.573904  8498 solver.cpp:237] Iteration 71048, loss = 1.01503
I0524 01:47:28.574079  8498 solver.cpp:253]     Train net output #0: loss = 1.01503 (* 1 = 1.01503 loss)
I0524 01:47:28.574092  8498 sgd_solver.cpp:106] Iteration 71048, lr = 0.002
I0524 01:47:37.477484  8498 solver.cpp:237] Iteration 71262, loss = 1.11004
I0524 01:47:37.477519  8498 solver.cpp:253]     Train net output #0: loss = 1.11004 (* 1 = 1.11004 loss)
I0524 01:47:37.477535  8498 sgd_solver.cpp:106] Iteration 71262, lr = 0.002
I0524 01:48:07.315346  8498 solver.cpp:237] Iteration 71476, loss = 1.2303
I0524 01:48:07.315534  8498 solver.cpp:253]     Train net output #0: loss = 1.2303 (* 1 = 1.2303 loss)
I0524 01:48:07.315548  8498 sgd_solver.cpp:106] Iteration 71476, lr = 0.002
I0524 01:48:16.216799  8498 solver.cpp:237] Iteration 71690, loss = 1.27384
I0524 01:48:16.216833  8498 solver.cpp:253]     Train net output #0: loss = 1.27384 (* 1 = 1.27384 loss)
I0524 01:48:16.216848  8498 sgd_solver.cpp:106] Iteration 71690, lr = 0.002
I0524 01:48:25.121780  8498 solver.cpp:237] Iteration 71904, loss = 1.34672
I0524 01:48:25.121815  8498 solver.cpp:253]     Train net output #0: loss = 1.34672 (* 1 = 1.34672 loss)
I0524 01:48:25.121829  8498 sgd_solver.cpp:106] Iteration 71904, lr = 0.002
I0524 01:48:34.023622  8498 solver.cpp:237] Iteration 72118, loss = 1.10833
I0524 01:48:34.023670  8498 solver.cpp:253]     Train net output #0: loss = 1.10833 (* 1 = 1.10833 loss)
I0524 01:48:34.023684  8498 sgd_solver.cpp:106] Iteration 72118, lr = 0.002
I0524 01:48:42.919456  8498 solver.cpp:237] Iteration 72332, loss = 1.0779
I0524 01:48:42.919636  8498 solver.cpp:253]     Train net output #0: loss = 1.0779 (* 1 = 1.0779 loss)
I0524 01:48:42.919649  8498 sgd_solver.cpp:106] Iteration 72332, lr = 0.002
I0524 01:48:51.823832  8498 solver.cpp:237] Iteration 72546, loss = 0.993546
I0524 01:48:51.823868  8498 solver.cpp:253]     Train net output #0: loss = 0.993546 (* 1 = 0.993546 loss)
I0524 01:48:51.823882  8498 sgd_solver.cpp:106] Iteration 72546, lr = 0.002
I0524 01:49:00.724992  8498 solver.cpp:237] Iteration 72760, loss = 1.33079
I0524 01:49:00.725031  8498 solver.cpp:253]     Train net output #0: loss = 1.33079 (* 1 = 1.33079 loss)
I0524 01:49:00.725051  8498 sgd_solver.cpp:106] Iteration 72760, lr = 0.002
I0524 01:49:03.512837  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_72828.caffemodel
I0524 01:49:03.578454  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_72828.solverstate
I0524 01:49:04.282454  8498 solver.cpp:341] Iteration 72845, Testing net (#0)
I0524 01:49:52.278661  8498 solver.cpp:409]     Test net output #0: accuracy = 0.889696
I0524 01:49:52.278856  8498 solver.cpp:409]     Test net output #1: loss = 0.374873 (* 1 = 0.374873 loss)
I0524 01:50:18.514454  8498 solver.cpp:237] Iteration 72974, loss = 1.11692
I0524 01:50:18.514504  8498 solver.cpp:253]     Train net output #0: loss = 1.11692 (* 1 = 1.11692 loss)
I0524 01:50:18.514518  8498 sgd_solver.cpp:106] Iteration 72974, lr = 0.002
I0524 01:50:27.391876  8498 solver.cpp:237] Iteration 73188, loss = 1.23
I0524 01:50:27.392051  8498 solver.cpp:253]     Train net output #0: loss = 1.23 (* 1 = 1.23 loss)
I0524 01:50:27.392066  8498 sgd_solver.cpp:106] Iteration 73188, lr = 0.002
I0524 01:50:36.266566  8498 solver.cpp:237] Iteration 73402, loss = 1.25068
I0524 01:50:36.266607  8498 solver.cpp:253]     Train net output #0: loss = 1.25068 (* 1 = 1.25068 loss)
I0524 01:50:36.266625  8498 sgd_solver.cpp:106] Iteration 73402, lr = 0.002
I0524 01:50:45.134362  8498 solver.cpp:237] Iteration 73616, loss = 1.34324
I0524 01:50:45.134398  8498 solver.cpp:253]     Train net output #0: loss = 1.34324 (* 1 = 1.34324 loss)
I0524 01:50:45.134413  8498 sgd_solver.cpp:106] Iteration 73616, lr = 0.002
I0524 01:50:54.010769  8498 solver.cpp:237] Iteration 73830, loss = 1.12585
I0524 01:50:54.010804  8498 solver.cpp:253]     Train net output #0: loss = 1.12585 (* 1 = 1.12585 loss)
I0524 01:50:54.010818  8498 sgd_solver.cpp:106] Iteration 73830, lr = 0.002
I0524 01:51:02.880803  8498 solver.cpp:237] Iteration 74044, loss = 1.14354
I0524 01:51:02.880982  8498 solver.cpp:253]     Train net output #0: loss = 1.14354 (* 1 = 1.14354 loss)
I0524 01:51:02.880997  8498 sgd_solver.cpp:106] Iteration 74044, lr = 0.002
I0524 01:51:11.747616  8498 solver.cpp:237] Iteration 74258, loss = 0.919721
I0524 01:51:11.747650  8498 solver.cpp:253]     Train net output #0: loss = 0.919721 (* 1 = 0.919721 loss)
I0524 01:51:11.747664  8498 sgd_solver.cpp:106] Iteration 74258, lr = 0.002
I0524 01:51:41.497915  8498 solver.cpp:237] Iteration 74472, loss = 1.15156
I0524 01:51:41.498103  8498 solver.cpp:253]     Train net output #0: loss = 1.15156 (* 1 = 1.15156 loss)
I0524 01:51:41.498117  8498 sgd_solver.cpp:106] Iteration 74472, lr = 0.002
I0524 01:51:50.374800  8498 solver.cpp:237] Iteration 74686, loss = 0.918921
I0524 01:51:50.374841  8498 solver.cpp:253]     Train net output #0: loss = 0.918921 (* 1 = 0.918921 loss)
I0524 01:51:50.374861  8498 sgd_solver.cpp:106] Iteration 74686, lr = 0.002
I0524 01:51:59.250658  8498 solver.cpp:237] Iteration 74900, loss = 0.928006
I0524 01:51:59.250695  8498 solver.cpp:253]     Train net output #0: loss = 0.928006 (* 1 = 0.928006 loss)
I0524 01:51:59.250710  8498 sgd_solver.cpp:106] Iteration 74900, lr = 0.002
I0524 01:52:02.112943  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_74970.caffemodel
I0524 01:52:02.181859  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_74970.solverstate
I0524 01:52:08.198171  8498 solver.cpp:237] Iteration 75114, loss = 1.37043
I0524 01:52:08.198220  8498 solver.cpp:253]     Train net output #0: loss = 1.37043 (* 1 = 1.37043 loss)
I0524 01:52:08.198236  8498 sgd_solver.cpp:106] Iteration 75114, lr = 0.002
I0524 01:52:17.073611  8498 solver.cpp:237] Iteration 75328, loss = 1.14454
I0524 01:52:17.073817  8498 solver.cpp:253]     Train net output #0: loss = 1.14454 (* 1 = 1.14454 loss)
I0524 01:52:17.073832  8498 sgd_solver.cpp:106] Iteration 75328, lr = 0.002
I0524 01:52:25.949264  8498 solver.cpp:237] Iteration 75542, loss = 1.09223
I0524 01:52:25.949297  8498 solver.cpp:253]     Train net output #0: loss = 1.09223 (* 1 = 1.09223 loss)
I0524 01:52:25.949313  8498 sgd_solver.cpp:106] Iteration 75542, lr = 0.002
I0524 01:52:55.715042  8498 solver.cpp:237] Iteration 75756, loss = 1.19132
I0524 01:52:55.715235  8498 solver.cpp:253]     Train net output #0: loss = 1.19132 (* 1 = 1.19132 loss)
I0524 01:52:55.715250  8498 sgd_solver.cpp:106] Iteration 75756, lr = 0.002
I0524 01:53:04.595309  8498 solver.cpp:237] Iteration 75970, loss = 0.919028
I0524 01:53:04.595352  8498 solver.cpp:253]     Train net output #0: loss = 0.919028 (* 1 = 0.919028 loss)
I0524 01:53:04.595371  8498 sgd_solver.cpp:106] Iteration 75970, lr = 0.002
I0524 01:53:13.476547  8498 solver.cpp:237] Iteration 76184, loss = 1.24882
I0524 01:53:13.476583  8498 solver.cpp:253]     Train net output #0: loss = 1.24882 (* 1 = 1.24882 loss)
I0524 01:53:13.476596  8498 sgd_solver.cpp:106] Iteration 76184, lr = 0.002
I0524 01:53:22.361110  8498 solver.cpp:237] Iteration 76398, loss = 1.33207
I0524 01:53:22.361145  8498 solver.cpp:253]     Train net output #0: loss = 1.33207 (* 1 = 1.33207 loss)
I0524 01:53:22.361160  8498 sgd_solver.cpp:106] Iteration 76398, lr = 0.002
I0524 01:53:31.238654  8498 solver.cpp:237] Iteration 76612, loss = 1.24358
I0524 01:53:31.238839  8498 solver.cpp:253]     Train net output #0: loss = 1.24358 (* 1 = 1.24358 loss)
I0524 01:53:31.238853  8498 sgd_solver.cpp:106] Iteration 76612, lr = 0.002
I0524 01:53:40.112968  8498 solver.cpp:237] Iteration 76826, loss = 1.17281
I0524 01:53:40.113003  8498 solver.cpp:253]     Train net output #0: loss = 1.17281 (* 1 = 1.17281 loss)
I0524 01:53:40.113018  8498 sgd_solver.cpp:106] Iteration 76826, lr = 0.002
I0524 01:53:48.987387  8498 solver.cpp:237] Iteration 77040, loss = 1.21172
I0524 01:53:48.987423  8498 solver.cpp:253]     Train net output #0: loss = 1.21172 (* 1 = 1.21172 loss)
I0524 01:53:48.987437  8498 sgd_solver.cpp:106] Iteration 77040, lr = 0.002
I0524 01:53:51.931430  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_77112.caffemodel
I0524 01:53:51.999518  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_77112.solverstate
I0524 01:53:52.752115  8498 solver.cpp:341] Iteration 77130, Testing net (#0)
I0524 01:55:01.654475  8498 solver.cpp:409]     Test net output #0: accuracy = 0.891983
I0524 01:55:01.654667  8498 solver.cpp:409]     Test net output #1: loss = 0.358166 (* 1 = 0.358166 loss)
I0524 01:55:27.709102  8498 solver.cpp:237] Iteration 77254, loss = 1.44725
I0524 01:55:27.709153  8498 solver.cpp:253]     Train net output #0: loss = 1.44725 (* 1 = 1.44725 loss)
I0524 01:55:27.709167  8498 sgd_solver.cpp:106] Iteration 77254, lr = 0.002
I0524 01:55:36.592957  8498 solver.cpp:237] Iteration 77468, loss = 1.01308
I0524 01:55:36.593138  8498 solver.cpp:253]     Train net output #0: loss = 1.01308 (* 1 = 1.01308 loss)
I0524 01:55:36.593152  8498 sgd_solver.cpp:106] Iteration 77468, lr = 0.002
I0524 01:55:45.474009  8498 solver.cpp:237] Iteration 77682, loss = 1.06803
I0524 01:55:45.474043  8498 solver.cpp:253]     Train net output #0: loss = 1.06803 (* 1 = 1.06803 loss)
I0524 01:55:45.474058  8498 sgd_solver.cpp:106] Iteration 77682, lr = 0.002
I0524 01:55:54.353430  8498 solver.cpp:237] Iteration 77896, loss = 1.23193
I0524 01:55:54.353466  8498 solver.cpp:253]     Train net output #0: loss = 1.23193 (* 1 = 1.23193 loss)
I0524 01:55:54.353478  8498 sgd_solver.cpp:106] Iteration 77896, lr = 0.002
I0524 01:56:03.232578  8498 solver.cpp:237] Iteration 78110, loss = 1.00626
I0524 01:56:03.232623  8498 solver.cpp:253]     Train net output #0: loss = 1.00626 (* 1 = 1.00626 loss)
I0524 01:56:03.232638  8498 sgd_solver.cpp:106] Iteration 78110, lr = 0.002
I0524 01:56:12.115226  8498 solver.cpp:237] Iteration 78324, loss = 1.17067
I0524 01:56:12.115408  8498 solver.cpp:253]     Train net output #0: loss = 1.17067 (* 1 = 1.17067 loss)
I0524 01:56:12.115422  8498 sgd_solver.cpp:106] Iteration 78324, lr = 0.002
I0524 01:56:20.988522  8498 solver.cpp:237] Iteration 78538, loss = 1.15115
I0524 01:56:20.988556  8498 solver.cpp:253]     Train net output #0: loss = 1.15115 (* 1 = 1.15115 loss)
I0524 01:56:20.988571  8498 sgd_solver.cpp:106] Iteration 78538, lr = 0.002
I0524 01:56:50.752004  8498 solver.cpp:237] Iteration 78752, loss = 1.16749
I0524 01:56:50.752197  8498 solver.cpp:253]     Train net output #0: loss = 1.16749 (* 1 = 1.16749 loss)
I0524 01:56:50.752213  8498 sgd_solver.cpp:106] Iteration 78752, lr = 0.002
I0524 01:56:59.629154  8498 solver.cpp:237] Iteration 78966, loss = 1.33528
I0524 01:56:59.629189  8498 solver.cpp:253]     Train net output #0: loss = 1.33528 (* 1 = 1.33528 loss)
I0524 01:56:59.629204  8498 sgd_solver.cpp:106] Iteration 78966, lr = 0.002
I0524 01:57:08.511461  8498 solver.cpp:237] Iteration 79180, loss = 1.12061
I0524 01:57:08.511497  8498 solver.cpp:253]     Train net output #0: loss = 1.12061 (* 1 = 1.12061 loss)
I0524 01:57:08.511510  8498 sgd_solver.cpp:106] Iteration 79180, lr = 0.002
I0524 01:57:11.540738  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_79254.caffemodel
I0524 01:57:11.606693  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_79254.solverstate
I0524 01:57:17.455459  8498 solver.cpp:237] Iteration 79394, loss = 1.27818
I0524 01:57:17.455504  8498 solver.cpp:253]     Train net output #0: loss = 1.27818 (* 1 = 1.27818 loss)
I0524 01:57:17.455524  8498 sgd_solver.cpp:106] Iteration 79394, lr = 0.002
I0524 01:57:26.340533  8498 solver.cpp:237] Iteration 79608, loss = 1.23157
I0524 01:57:26.340705  8498 solver.cpp:253]     Train net output #0: loss = 1.23157 (* 1 = 1.23157 loss)
I0524 01:57:26.340719  8498 sgd_solver.cpp:106] Iteration 79608, lr = 0.002
I0524 01:57:35.225805  8498 solver.cpp:237] Iteration 79822, loss = 1.09761
I0524 01:57:35.225839  8498 solver.cpp:253]     Train net output #0: loss = 1.09761 (* 1 = 1.09761 loss)
I0524 01:57:35.225854  8498 sgd_solver.cpp:106] Iteration 79822, lr = 0.002
I0524 01:58:05.023088  8498 solver.cpp:237] Iteration 80036, loss = 1.08535
I0524 01:58:05.023282  8498 solver.cpp:253]     Train net output #0: loss = 1.08535 (* 1 = 1.08535 loss)
I0524 01:58:05.023295  8498 sgd_solver.cpp:106] Iteration 80036, lr = 0.002
I0524 01:58:13.906091  8498 solver.cpp:237] Iteration 80250, loss = 1.29989
I0524 01:58:13.906126  8498 solver.cpp:253]     Train net output #0: loss = 1.29989 (* 1 = 1.29989 loss)
I0524 01:58:13.906141  8498 sgd_solver.cpp:106] Iteration 80250, lr = 0.002
I0524 01:58:22.780506  8498 solver.cpp:237] Iteration 80464, loss = 1.06975
I0524 01:58:22.780540  8498 solver.cpp:253]     Train net output #0: loss = 1.06975 (* 1 = 1.06975 loss)
I0524 01:58:22.780555  8498 sgd_solver.cpp:106] Iteration 80464, lr = 0.002
I0524 01:58:31.661368  8498 solver.cpp:237] Iteration 80678, loss = 1.1672
I0524 01:58:31.661415  8498 solver.cpp:253]     Train net output #0: loss = 1.1672 (* 1 = 1.1672 loss)
I0524 01:58:31.661430  8498 sgd_solver.cpp:106] Iteration 80678, lr = 0.002
I0524 01:58:40.538746  8498 solver.cpp:237] Iteration 80892, loss = 1.2729
I0524 01:58:40.538918  8498 solver.cpp:253]     Train net output #0: loss = 1.2729 (* 1 = 1.2729 loss)
I0524 01:58:40.538931  8498 sgd_solver.cpp:106] Iteration 80892, lr = 0.002
I0524 01:58:49.420534  8498 solver.cpp:237] Iteration 81106, loss = 1.104
I0524 01:58:49.420568  8498 solver.cpp:253]     Train net output #0: loss = 1.104 (* 1 = 1.104 loss)
I0524 01:58:49.420583  8498 sgd_solver.cpp:106] Iteration 81106, lr = 0.002
I0524 01:58:58.300659  8498 solver.cpp:237] Iteration 81320, loss = 0.812663
I0524 01:58:58.300706  8498 solver.cpp:253]     Train net output #0: loss = 0.812663 (* 1 = 0.812663 loss)
I0524 01:58:58.300719  8498 sgd_solver.cpp:106] Iteration 81320, lr = 0.002
I0524 01:59:01.415282  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_81396.caffemodel
I0524 01:59:01.480820  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_81396.solverstate
I0524 01:59:02.269019  8498 solver.cpp:341] Iteration 81415, Testing net (#0)
I0524 01:59:49.898185  8498 solver.cpp:409]     Test net output #0: accuracy = 0.891811
I0524 01:59:49.898385  8498 solver.cpp:409]     Test net output #1: loss = 0.342181 (* 1 = 0.342181 loss)
I0524 02:00:15.738180  8498 solver.cpp:237] Iteration 81534, loss = 1.03385
I0524 02:00:15.738230  8498 solver.cpp:253]     Train net output #0: loss = 1.03385 (* 1 = 1.03385 loss)
I0524 02:00:15.738245  8498 sgd_solver.cpp:106] Iteration 81534, lr = 0.002
I0524 02:00:24.619385  8498 solver.cpp:237] Iteration 81748, loss = 1.22883
I0524 02:00:24.619563  8498 solver.cpp:253]     Train net output #0: loss = 1.22883 (* 1 = 1.22883 loss)
I0524 02:00:24.619577  8498 sgd_solver.cpp:106] Iteration 81748, lr = 0.002
I0524 02:00:33.501103  8498 solver.cpp:237] Iteration 81962, loss = 1.00887
I0524 02:00:33.501137  8498 solver.cpp:253]     Train net output #0: loss = 1.00887 (* 1 = 1.00887 loss)
I0524 02:00:33.501152  8498 sgd_solver.cpp:106] Iteration 81962, lr = 0.002
I0524 02:00:42.384660  8498 solver.cpp:237] Iteration 82176, loss = 1.13596
I0524 02:00:42.384699  8498 solver.cpp:253]     Train net output #0: loss = 1.13596 (* 1 = 1.13596 loss)
I0524 02:00:42.384718  8498 sgd_solver.cpp:106] Iteration 82176, lr = 0.002
I0524 02:00:51.261790  8498 solver.cpp:237] Iteration 82390, loss = 1.19457
I0524 02:00:51.261824  8498 solver.cpp:253]     Train net output #0: loss = 1.19457 (* 1 = 1.19457 loss)
I0524 02:00:51.261837  8498 sgd_solver.cpp:106] Iteration 82390, lr = 0.002
I0524 02:01:00.142231  8498 solver.cpp:237] Iteration 82604, loss = 1.17313
I0524 02:01:00.142421  8498 solver.cpp:253]     Train net output #0: loss = 1.17313 (* 1 = 1.17313 loss)
I0524 02:01:00.142436  8498 sgd_solver.cpp:106] Iteration 82604, lr = 0.002
I0524 02:01:09.025135  8498 solver.cpp:237] Iteration 82818, loss = 1.1554
I0524 02:01:09.025168  8498 solver.cpp:253]     Train net output #0: loss = 1.1554 (* 1 = 1.1554 loss)
I0524 02:01:09.025183  8498 sgd_solver.cpp:106] Iteration 82818, lr = 0.002
I0524 02:01:38.750576  8498 solver.cpp:237] Iteration 83032, loss = 1.0892
I0524 02:01:38.750772  8498 solver.cpp:253]     Train net output #0: loss = 1.0892 (* 1 = 1.0892 loss)
I0524 02:01:38.750787  8498 sgd_solver.cpp:106] Iteration 83032, lr = 0.002
I0524 02:01:47.627545  8498 solver.cpp:237] Iteration 83246, loss = 1.13811
I0524 02:01:47.627579  8498 solver.cpp:253]     Train net output #0: loss = 1.13811 (* 1 = 1.13811 loss)
I0524 02:01:47.627594  8498 sgd_solver.cpp:106] Iteration 83246, lr = 0.002
I0524 02:01:56.510635  8498 solver.cpp:237] Iteration 83460, loss = 0.895254
I0524 02:01:56.510679  8498 solver.cpp:253]     Train net output #0: loss = 0.895254 (* 1 = 0.895254 loss)
I0524 02:01:56.510696  8498 sgd_solver.cpp:106] Iteration 83460, lr = 0.002
I0524 02:01:59.704680  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_83538.caffemodel
I0524 02:01:59.770556  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_83538.solverstate
I0524 02:02:05.451040  8498 solver.cpp:237] Iteration 83674, loss = 1.0828
I0524 02:02:05.451086  8498 solver.cpp:253]     Train net output #0: loss = 1.0828 (* 1 = 1.0828 loss)
I0524 02:02:05.451100  8498 sgd_solver.cpp:106] Iteration 83674, lr = 0.002
I0524 02:02:14.333576  8498 solver.cpp:237] Iteration 83888, loss = 1.17037
I0524 02:02:14.333780  8498 solver.cpp:253]     Train net output #0: loss = 1.17037 (* 1 = 1.17037 loss)
I0524 02:02:14.333793  8498 sgd_solver.cpp:106] Iteration 83888, lr = 0.002
I0524 02:02:23.212304  8498 solver.cpp:237] Iteration 84102, loss = 1.12398
I0524 02:02:23.212339  8498 solver.cpp:253]     Train net output #0: loss = 1.12398 (* 1 = 1.12398 loss)
I0524 02:02:23.212353  8498 sgd_solver.cpp:106] Iteration 84102, lr = 0.002
I0524 02:02:52.962554  8498 solver.cpp:237] Iteration 84316, loss = 0.786311
I0524 02:02:52.962754  8498 solver.cpp:253]     Train net output #0: loss = 0.786311 (* 1 = 0.786311 loss)
I0524 02:02:52.962769  8498 sgd_solver.cpp:106] Iteration 84316, lr = 0.002
I0524 02:03:01.831779  8498 solver.cpp:237] Iteration 84530, loss = 0.971727
I0524 02:03:01.831814  8498 solver.cpp:253]     Train net output #0: loss = 0.971727 (* 1 = 0.971727 loss)
I0524 02:03:01.831828  8498 sgd_solver.cpp:106] Iteration 84530, lr = 0.002
I0524 02:03:10.700989  8498 solver.cpp:237] Iteration 84744, loss = 1.07673
I0524 02:03:10.701030  8498 solver.cpp:253]     Train net output #0: loss = 1.07673 (* 1 = 1.07673 loss)
I0524 02:03:10.701050  8498 sgd_solver.cpp:106] Iteration 84744, lr = 0.002
I0524 02:03:19.582909  8498 solver.cpp:237] Iteration 84958, loss = 0.959955
I0524 02:03:19.582944  8498 solver.cpp:253]     Train net output #0: loss = 0.959955 (* 1 = 0.959955 loss)
I0524 02:03:19.582959  8498 sgd_solver.cpp:106] Iteration 84958, lr = 0.002
I0524 02:03:28.464040  8498 solver.cpp:237] Iteration 85172, loss = 1.20025
I0524 02:03:28.464213  8498 solver.cpp:253]     Train net output #0: loss = 1.20025 (* 1 = 1.20025 loss)
I0524 02:03:28.464227  8498 sgd_solver.cpp:106] Iteration 85172, lr = 0.002
I0524 02:03:37.343909  8498 solver.cpp:237] Iteration 85386, loss = 1.15639
I0524 02:03:37.343946  8498 solver.cpp:253]     Train net output #0: loss = 1.15639 (* 1 = 1.15639 loss)
I0524 02:03:37.343966  8498 sgd_solver.cpp:106] Iteration 85386, lr = 0.002
I0524 02:03:46.220947  8498 solver.cpp:237] Iteration 85600, loss = 1.23147
I0524 02:03:46.220981  8498 solver.cpp:253]     Train net output #0: loss = 1.23147 (* 1 = 1.23147 loss)
I0524 02:03:46.220996  8498 sgd_solver.cpp:106] Iteration 85600, lr = 0.002
I0524 02:03:49.497666  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_85680.caffemodel
I0524 02:03:49.568069  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_85680.solverstate
I0524 02:03:50.397763  8498 solver.cpp:341] Iteration 85700, Testing net (#0)
I0524 02:04:59.240080  8498 solver.cpp:409]     Test net output #0: accuracy = 0.894018
I0524 02:04:59.240272  8498 solver.cpp:409]     Test net output #1: loss = 0.347576 (* 1 = 0.347576 loss)
I0524 02:05:24.838614  8498 solver.cpp:237] Iteration 85814, loss = 1.1045
I0524 02:05:24.838665  8498 solver.cpp:253]     Train net output #0: loss = 1.1045 (* 1 = 1.1045 loss)
I0524 02:05:24.838680  8498 sgd_solver.cpp:106] Iteration 85814, lr = 0.002
I0524 02:05:33.705032  8498 solver.cpp:237] Iteration 86028, loss = 1.05771
I0524 02:05:33.705219  8498 solver.cpp:253]     Train net output #0: loss = 1.05771 (* 1 = 1.05771 loss)
I0524 02:05:33.705234  8498 sgd_solver.cpp:106] Iteration 86028, lr = 0.002
I0524 02:05:42.568624  8498 solver.cpp:237] Iteration 86242, loss = 1.25938
I0524 02:05:42.568660  8498 solver.cpp:253]     Train net output #0: loss = 1.25938 (* 1 = 1.25938 loss)
I0524 02:05:42.568675  8498 sgd_solver.cpp:106] Iteration 86242, lr = 0.002
I0524 02:05:51.434701  8498 solver.cpp:237] Iteration 86456, loss = 1.40663
I0524 02:05:51.434736  8498 solver.cpp:253]     Train net output #0: loss = 1.40663 (* 1 = 1.40663 loss)
I0524 02:05:51.434751  8498 sgd_solver.cpp:106] Iteration 86456, lr = 0.002
I0524 02:06:00.299469  8498 solver.cpp:237] Iteration 86670, loss = 1.18113
I0524 02:06:00.299512  8498 solver.cpp:253]     Train net output #0: loss = 1.18113 (* 1 = 1.18113 loss)
I0524 02:06:00.299530  8498 sgd_solver.cpp:106] Iteration 86670, lr = 0.002
I0524 02:06:09.161139  8498 solver.cpp:237] Iteration 86884, loss = 1.16026
I0524 02:06:09.161331  8498 solver.cpp:253]     Train net output #0: loss = 1.16026 (* 1 = 1.16026 loss)
I0524 02:06:09.161346  8498 sgd_solver.cpp:106] Iteration 86884, lr = 0.002
I0524 02:06:18.030836  8498 solver.cpp:237] Iteration 87098, loss = 0.989362
I0524 02:06:18.030871  8498 solver.cpp:253]     Train net output #0: loss = 0.989362 (* 1 = 0.989362 loss)
I0524 02:06:18.030886  8498 sgd_solver.cpp:106] Iteration 87098, lr = 0.002
I0524 02:06:47.736691  8498 solver.cpp:237] Iteration 87312, loss = 0.966206
I0524 02:06:47.736887  8498 solver.cpp:253]     Train net output #0: loss = 0.966206 (* 1 = 0.966206 loss)
I0524 02:06:47.736904  8498 sgd_solver.cpp:106] Iteration 87312, lr = 0.002
I0524 02:06:56.602427  8498 solver.cpp:237] Iteration 87526, loss = 1.09739
I0524 02:06:56.602463  8498 solver.cpp:253]     Train net output #0: loss = 1.09739 (* 1 = 1.09739 loss)
I0524 02:06:56.602483  8498 sgd_solver.cpp:106] Iteration 87526, lr = 0.002
I0524 02:07:05.462939  8498 solver.cpp:237] Iteration 87740, loss = 1.16488
I0524 02:07:05.462972  8498 solver.cpp:253]     Train net output #0: loss = 1.16488 (* 1 = 1.16488 loss)
I0524 02:07:05.462987  8498 sgd_solver.cpp:106] Iteration 87740, lr = 0.002
I0524 02:07:08.819546  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_87822.caffemodel
I0524 02:07:08.885536  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_87822.solverstate
I0524 02:07:14.391984  8498 solver.cpp:237] Iteration 87954, loss = 1.35221
I0524 02:07:14.392032  8498 solver.cpp:253]     Train net output #0: loss = 1.35221 (* 1 = 1.35221 loss)
I0524 02:07:14.392048  8498 sgd_solver.cpp:106] Iteration 87954, lr = 0.002
I0524 02:07:23.256110  8498 solver.cpp:237] Iteration 88168, loss = 1.35585
I0524 02:07:23.256301  8498 solver.cpp:253]     Train net output #0: loss = 1.35585 (* 1 = 1.35585 loss)
I0524 02:07:23.256315  8498 sgd_solver.cpp:106] Iteration 88168, lr = 0.002
I0524 02:07:32.125582  8498 solver.cpp:237] Iteration 88382, loss = 1.06745
I0524 02:07:32.125617  8498 solver.cpp:253]     Train net output #0: loss = 1.06745 (* 1 = 1.06745 loss)
I0524 02:07:32.125633  8498 sgd_solver.cpp:106] Iteration 88382, lr = 0.002
I0524 02:08:01.834775  8498 solver.cpp:237] Iteration 88596, loss = 1.01099
I0524 02:08:01.834974  8498 solver.cpp:253]     Train net output #0: loss = 1.01099 (* 1 = 1.01099 loss)
I0524 02:08:01.834987  8498 sgd_solver.cpp:106] Iteration 88596, lr = 0.002
I0524 02:08:10.700045  8498 solver.cpp:237] Iteration 88810, loss = 1.22258
I0524 02:08:10.700088  8498 solver.cpp:253]     Train net output #0: loss = 1.22258 (* 1 = 1.22258 loss)
I0524 02:08:10.700108  8498 sgd_solver.cpp:106] Iteration 88810, lr = 0.002
I0524 02:08:19.569249  8498 solver.cpp:237] Iteration 89024, loss = 1.38162
I0524 02:08:19.569284  8498 solver.cpp:253]     Train net output #0: loss = 1.38162 (* 1 = 1.38162 loss)
I0524 02:08:19.569298  8498 sgd_solver.cpp:106] Iteration 89024, lr = 0.002
I0524 02:08:28.432533  8498 solver.cpp:237] Iteration 89238, loss = 1.19006
I0524 02:08:28.432569  8498 solver.cpp:253]     Train net output #0: loss = 1.19006 (* 1 = 1.19006 loss)
I0524 02:08:28.432582  8498 sgd_solver.cpp:106] Iteration 89238, lr = 0.002
I0524 02:08:37.299448  8498 solver.cpp:237] Iteration 89452, loss = 1.17203
I0524 02:08:37.299648  8498 solver.cpp:253]     Train net output #0: loss = 1.17203 (* 1 = 1.17203 loss)
I0524 02:08:37.299660  8498 sgd_solver.cpp:106] Iteration 89452, lr = 0.002
I0524 02:08:46.166013  8498 solver.cpp:237] Iteration 89666, loss = 1.31183
I0524 02:08:46.166049  8498 solver.cpp:253]     Train net output #0: loss = 1.31183 (* 1 = 1.31183 loss)
I0524 02:08:46.166064  8498 sgd_solver.cpp:106] Iteration 89666, lr = 0.002
I0524 02:08:55.033700  8498 solver.cpp:237] Iteration 89880, loss = 1.18482
I0524 02:08:55.033740  8498 solver.cpp:253]     Train net output #0: loss = 1.18482 (* 1 = 1.18482 loss)
I0524 02:08:55.033758  8498 sgd_solver.cpp:106] Iteration 89880, lr = 0.002
I0524 02:08:58.472183  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_89964.caffemodel
I0524 02:08:58.538333  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_89964.solverstate
I0524 02:08:59.406770  8498 solver.cpp:341] Iteration 89985, Testing net (#0)
I0524 02:09:47.342209  8498 solver.cpp:409]     Test net output #0: accuracy = 0.894171
I0524 02:09:47.342413  8498 solver.cpp:409]     Test net output #1: loss = 0.345923 (* 1 = 0.345923 loss)
I0524 02:10:12.737562  8498 solver.cpp:237] Iteration 90094, loss = 1.01288
I0524 02:10:12.737612  8498 solver.cpp:253]     Train net output #0: loss = 1.01288 (* 1 = 1.01288 loss)
I0524 02:10:12.737627  8498 sgd_solver.cpp:106] Iteration 90094, lr = 0.002
I0524 02:10:21.623661  8498 solver.cpp:237] Iteration 90308, loss = 1.27117
I0524 02:10:21.623842  8498 solver.cpp:253]     Train net output #0: loss = 1.27117 (* 1 = 1.27117 loss)
I0524 02:10:21.623855  8498 sgd_solver.cpp:106] Iteration 90308, lr = 0.002
I0524 02:10:30.501947  8498 solver.cpp:237] Iteration 90522, loss = 1.19411
I0524 02:10:30.501981  8498 solver.cpp:253]     Train net output #0: loss = 1.19411 (* 1 = 1.19411 loss)
I0524 02:10:30.501997  8498 sgd_solver.cpp:106] Iteration 90522, lr = 0.002
I0524 02:10:39.391665  8498 solver.cpp:237] Iteration 90736, loss = 1.18754
I0524 02:10:39.391710  8498 solver.cpp:253]     Train net output #0: loss = 1.18754 (* 1 = 1.18754 loss)
I0524 02:10:39.391726  8498 sgd_solver.cpp:106] Iteration 90736, lr = 0.002
I0524 02:10:48.278395  8498 solver.cpp:237] Iteration 90950, loss = 1.41161
I0524 02:10:48.278431  8498 solver.cpp:253]     Train net output #0: loss = 1.41161 (* 1 = 1.41161 loss)
I0524 02:10:48.278445  8498 sgd_solver.cpp:106] Iteration 90950, lr = 0.002
I0524 02:10:57.165197  8498 solver.cpp:237] Iteration 91164, loss = 1.41137
I0524 02:10:57.165375  8498 solver.cpp:253]     Train net output #0: loss = 1.41137 (* 1 = 1.41137 loss)
I0524 02:10:57.165388  8498 sgd_solver.cpp:106] Iteration 91164, lr = 0.002
I0524 02:11:06.055899  8498 solver.cpp:237] Iteration 91378, loss = 1.10893
I0524 02:11:06.055944  8498 solver.cpp:253]     Train net output #0: loss = 1.10893 (* 1 = 1.10893 loss)
I0524 02:11:06.055961  8498 sgd_solver.cpp:106] Iteration 91378, lr = 0.002
I0524 02:11:35.782588  8498 solver.cpp:237] Iteration 91592, loss = 1.19791
I0524 02:11:35.782793  8498 solver.cpp:253]     Train net output #0: loss = 1.19791 (* 1 = 1.19791 loss)
I0524 02:11:35.782807  8498 sgd_solver.cpp:106] Iteration 91592, lr = 0.002
I0524 02:11:44.673743  8498 solver.cpp:237] Iteration 91806, loss = 1.24317
I0524 02:11:44.673777  8498 solver.cpp:253]     Train net output #0: loss = 1.24317 (* 1 = 1.24317 loss)
I0524 02:11:44.673792  8498 sgd_solver.cpp:106] Iteration 91806, lr = 0.002
I0524 02:11:53.561194  8498 solver.cpp:237] Iteration 92020, loss = 1.15886
I0524 02:11:53.561236  8498 solver.cpp:253]     Train net output #0: loss = 1.15886 (* 1 = 1.15886 loss)
I0524 02:11:53.561254  8498 sgd_solver.cpp:106] Iteration 92020, lr = 0.002
I0524 02:11:57.089285  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_92106.caffemodel
I0524 02:11:57.154767  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_92106.solverstate
I0524 02:12:02.508411  8498 solver.cpp:237] Iteration 92234, loss = 1.25504
I0524 02:12:02.508458  8498 solver.cpp:253]     Train net output #0: loss = 1.25504 (* 1 = 1.25504 loss)
I0524 02:12:02.508472  8498 sgd_solver.cpp:106] Iteration 92234, lr = 0.002
I0524 02:12:11.387238  8498 solver.cpp:237] Iteration 92448, loss = 1.21714
I0524 02:12:11.387428  8498 solver.cpp:253]     Train net output #0: loss = 1.21714 (* 1 = 1.21714 loss)
I0524 02:12:11.387441  8498 sgd_solver.cpp:106] Iteration 92448, lr = 0.002
I0524 02:12:20.277633  8498 solver.cpp:237] Iteration 92662, loss = 1.15581
I0524 02:12:20.277681  8498 solver.cpp:253]     Train net output #0: loss = 1.15581 (* 1 = 1.15581 loss)
I0524 02:12:20.277700  8498 sgd_solver.cpp:106] Iteration 92662, lr = 0.002
I0524 02:12:50.005206  8498 solver.cpp:237] Iteration 92876, loss = 1.0319
I0524 02:12:50.005406  8498 solver.cpp:253]     Train net output #0: loss = 1.0319 (* 1 = 1.0319 loss)
I0524 02:12:50.005420  8498 sgd_solver.cpp:106] Iteration 92876, lr = 0.002
I0524 02:12:58.892112  8498 solver.cpp:237] Iteration 93090, loss = 1.1728
I0524 02:12:58.892146  8498 solver.cpp:253]     Train net output #0: loss = 1.1728 (* 1 = 1.1728 loss)
I0524 02:12:58.892163  8498 sgd_solver.cpp:106] Iteration 93090, lr = 0.002
I0524 02:13:07.775843  8498 solver.cpp:237] Iteration 93304, loss = 0.986274
I0524 02:13:07.775885  8498 solver.cpp:253]     Train net output #0: loss = 0.986274 (* 1 = 0.986274 loss)
I0524 02:13:07.775904  8498 sgd_solver.cpp:106] Iteration 93304, lr = 0.002
I0524 02:13:16.651285  8498 solver.cpp:237] Iteration 93518, loss = 1.28319
I0524 02:13:16.651321  8498 solver.cpp:253]     Train net output #0: loss = 1.28319 (* 1 = 1.28319 loss)
I0524 02:13:16.651335  8498 sgd_solver.cpp:106] Iteration 93518, lr = 0.002
I0524 02:13:25.543601  8498 solver.cpp:237] Iteration 93732, loss = 1.09624
I0524 02:13:25.543777  8498 solver.cpp:253]     Train net output #0: loss = 1.09624 (* 1 = 1.09624 loss)
I0524 02:13:25.543794  8498 sgd_solver.cpp:106] Iteration 93732, lr = 0.002
I0524 02:13:34.430191  8498 solver.cpp:237] Iteration 93946, loss = 1.02372
I0524 02:13:34.430235  8498 solver.cpp:253]     Train net output #0: loss = 1.02372 (* 1 = 1.02372 loss)
I0524 02:13:34.430253  8498 sgd_solver.cpp:106] Iteration 93946, lr = 0.002
I0524 02:13:43.312111  8498 solver.cpp:237] Iteration 94160, loss = 0.966642
I0524 02:13:43.312147  8498 solver.cpp:253]     Train net output #0: loss = 0.966642 (* 1 = 0.966642 loss)
I0524 02:13:43.312161  8498 sgd_solver.cpp:106] Iteration 94160, lr = 0.002
I0524 02:13:46.926066  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_94248.caffemodel
I0524 02:13:46.992087  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_94248.solverstate
I0524 02:13:47.905881  8498 solver.cpp:341] Iteration 94270, Testing net (#0)
I0524 02:14:56.735538  8498 solver.cpp:409]     Test net output #0: accuracy = 0.893658
I0524 02:14:56.735730  8498 solver.cpp:409]     Test net output #1: loss = 0.355948 (* 1 = 0.355948 loss)
I0524 02:15:21.950832  8498 solver.cpp:237] Iteration 94374, loss = 1.10117
I0524 02:15:21.950883  8498 solver.cpp:253]     Train net output #0: loss = 1.10117 (* 1 = 1.10117 loss)
I0524 02:15:21.950898  8498 sgd_solver.cpp:106] Iteration 94374, lr = 0.002
I0524 02:15:30.816310  8498 solver.cpp:237] Iteration 94588, loss = 1.42671
I0524 02:15:30.816506  8498 solver.cpp:253]     Train net output #0: loss = 1.42671 (* 1 = 1.42671 loss)
I0524 02:15:30.816519  8498 sgd_solver.cpp:106] Iteration 94588, lr = 0.002
I0524 02:15:39.677417  8498 solver.cpp:237] Iteration 94802, loss = 1.1779
I0524 02:15:39.677453  8498 solver.cpp:253]     Train net output #0: loss = 1.1779 (* 1 = 1.1779 loss)
I0524 02:15:39.677465  8498 sgd_solver.cpp:106] Iteration 94802, lr = 0.002
I0524 02:15:48.540024  8498 solver.cpp:237] Iteration 95016, loss = 0.935015
I0524 02:15:48.540058  8498 solver.cpp:253]     Train net output #0: loss = 0.935015 (* 1 = 0.935015 loss)
I0524 02:15:48.540072  8498 sgd_solver.cpp:106] Iteration 95016, lr = 0.002
I0524 02:15:57.409710  8498 solver.cpp:237] Iteration 95230, loss = 1.22071
I0524 02:15:57.409745  8498 solver.cpp:253]     Train net output #0: loss = 1.22071 (* 1 = 1.22071 loss)
I0524 02:15:57.409760  8498 sgd_solver.cpp:106] Iteration 95230, lr = 0.002
I0524 02:16:06.283649  8498 solver.cpp:237] Iteration 95444, loss = 1.12106
I0524 02:16:06.283830  8498 solver.cpp:253]     Train net output #0: loss = 1.12106 (* 1 = 1.12106 loss)
I0524 02:16:06.283844  8498 sgd_solver.cpp:106] Iteration 95444, lr = 0.002
I0524 02:16:15.144631  8498 solver.cpp:237] Iteration 95658, loss = 1.20745
I0524 02:16:15.144665  8498 solver.cpp:253]     Train net output #0: loss = 1.20745 (* 1 = 1.20745 loss)
I0524 02:16:15.144681  8498 sgd_solver.cpp:106] Iteration 95658, lr = 0.002
I0524 02:16:44.959079  8498 solver.cpp:237] Iteration 95872, loss = 1.16689
I0524 02:16:44.959276  8498 solver.cpp:253]     Train net output #0: loss = 1.16689 (* 1 = 1.16689 loss)
I0524 02:16:44.959293  8498 sgd_solver.cpp:106] Iteration 95872, lr = 0.002
I0524 02:16:53.827993  8498 solver.cpp:237] Iteration 96086, loss = 1.37726
I0524 02:16:53.828033  8498 solver.cpp:253]     Train net output #0: loss = 1.37726 (* 1 = 1.37726 loss)
I0524 02:16:53.828052  8498 sgd_solver.cpp:106] Iteration 96086, lr = 0.002
I0524 02:17:02.692966  8498 solver.cpp:237] Iteration 96300, loss = 1.05681
I0524 02:17:02.693001  8498 solver.cpp:253]     Train net output #0: loss = 1.05681 (* 1 = 1.05681 loss)
I0524 02:17:02.693016  8498 sgd_solver.cpp:106] Iteration 96300, lr = 0.002
I0524 02:17:06.383889  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_96390.caffemodel
I0524 02:17:06.469060  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_96390.solverstate
I0524 02:17:11.651021  8498 solver.cpp:237] Iteration 96514, loss = 1.22961
I0524 02:17:11.651072  8498 solver.cpp:253]     Train net output #0: loss = 1.22961 (* 1 = 1.22961 loss)
I0524 02:17:11.651085  8498 sgd_solver.cpp:106] Iteration 96514, lr = 0.002
I0524 02:17:20.518882  8498 solver.cpp:237] Iteration 96728, loss = 1.14363
I0524 02:17:20.519068  8498 solver.cpp:253]     Train net output #0: loss = 1.14363 (* 1 = 1.14363 loss)
I0524 02:17:20.519083  8498 sgd_solver.cpp:106] Iteration 96728, lr = 0.002
I0524 02:17:29.384827  8498 solver.cpp:237] Iteration 96942, loss = 1.1874
I0524 02:17:29.384861  8498 solver.cpp:253]     Train net output #0: loss = 1.1874 (* 1 = 1.1874 loss)
I0524 02:17:29.384876  8498 sgd_solver.cpp:106] Iteration 96942, lr = 0.002
I0524 02:17:59.224207  8498 solver.cpp:237] Iteration 97156, loss = 0.940282
I0524 02:17:59.224407  8498 solver.cpp:253]     Train net output #0: loss = 0.940282 (* 1 = 0.940282 loss)
I0524 02:17:59.224422  8498 sgd_solver.cpp:106] Iteration 97156, lr = 0.002
I0524 02:18:08.094002  8498 solver.cpp:237] Iteration 97370, loss = 1.16719
I0524 02:18:08.094043  8498 solver.cpp:253]     Train net output #0: loss = 1.16719 (* 1 = 1.16719 loss)
I0524 02:18:08.094061  8498 sgd_solver.cpp:106] Iteration 97370, lr = 0.002
I0524 02:18:16.962700  8498 solver.cpp:237] Iteration 97584, loss = 0.995402
I0524 02:18:16.962735  8498 solver.cpp:253]     Train net output #0: loss = 0.995402 (* 1 = 0.995402 loss)
I0524 02:18:16.962749  8498 sgd_solver.cpp:106] Iteration 97584, lr = 0.002
I0524 02:18:25.829987  8498 solver.cpp:237] Iteration 97798, loss = 1.09821
I0524 02:18:25.830021  8498 solver.cpp:253]     Train net output #0: loss = 1.09821 (* 1 = 1.09821 loss)
I0524 02:18:25.830036  8498 sgd_solver.cpp:106] Iteration 97798, lr = 0.002
I0524 02:18:34.694644  8498 solver.cpp:237] Iteration 98012, loss = 1.15183
I0524 02:18:34.694841  8498 solver.cpp:253]     Train net output #0: loss = 1.15183 (* 1 = 1.15183 loss)
I0524 02:18:34.694855  8498 sgd_solver.cpp:106] Iteration 98012, lr = 0.002
I0524 02:18:43.555852  8498 solver.cpp:237] Iteration 98226, loss = 0.998483
I0524 02:18:43.555887  8498 solver.cpp:253]     Train net output #0: loss = 0.998483 (* 1 = 0.998483 loss)
I0524 02:18:43.555902  8498 sgd_solver.cpp:106] Iteration 98226, lr = 0.002
I0524 02:18:52.424032  8498 solver.cpp:237] Iteration 98440, loss = 1.02541
I0524 02:18:52.424068  8498 solver.cpp:253]     Train net output #0: loss = 1.02541 (* 1 = 1.02541 loss)
I0524 02:18:52.424082  8498 sgd_solver.cpp:106] Iteration 98440, lr = 0.002
I0524 02:18:56.198503  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_98532.caffemodel
I0524 02:18:56.439817  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_98532.solverstate
I0524 02:18:57.460284  8498 solver.cpp:341] Iteration 98555, Testing net (#0)
I0524 02:19:45.118969  8498 solver.cpp:409]     Test net output #0: accuracy = 0.895845
I0524 02:19:45.119168  8498 solver.cpp:409]     Test net output #1: loss = 0.345247 (* 1 = 0.345247 loss)
I0524 02:20:10.155998  8498 solver.cpp:237] Iteration 98654, loss = 1.30668
I0524 02:20:10.156049  8498 solver.cpp:253]     Train net output #0: loss = 1.30668 (* 1 = 1.30668 loss)
I0524 02:20:10.156064  8498 sgd_solver.cpp:106] Iteration 98654, lr = 0.002
I0524 02:20:19.060052  8498 solver.cpp:237] Iteration 98868, loss = 0.984658
I0524 02:20:19.060238  8498 solver.cpp:253]     Train net output #0: loss = 0.984658 (* 1 = 0.984658 loss)
I0524 02:20:19.060252  8498 sgd_solver.cpp:106] Iteration 98868, lr = 0.002
I0524 02:20:27.964319  8498 solver.cpp:237] Iteration 99082, loss = 1.21002
I0524 02:20:27.964354  8498 solver.cpp:253]     Train net output #0: loss = 1.21002 (* 1 = 1.21002 loss)
I0524 02:20:27.964370  8498 sgd_solver.cpp:106] Iteration 99082, lr = 0.002
I0524 02:20:36.864028  8498 solver.cpp:237] Iteration 99296, loss = 1.30417
I0524 02:20:36.864069  8498 solver.cpp:253]     Train net output #0: loss = 1.30417 (* 1 = 1.30417 loss)
I0524 02:20:36.864089  8498 sgd_solver.cpp:106] Iteration 99296, lr = 0.002
I0524 02:20:45.765784  8498 solver.cpp:237] Iteration 99510, loss = 1.21349
I0524 02:20:45.765817  8498 solver.cpp:253]     Train net output #0: loss = 1.21349 (* 1 = 1.21349 loss)
I0524 02:20:45.765833  8498 sgd_solver.cpp:106] Iteration 99510, lr = 0.002
I0524 02:20:54.663074  8498 solver.cpp:237] Iteration 99724, loss = 1.29507
I0524 02:20:54.663252  8498 solver.cpp:253]     Train net output #0: loss = 1.29507 (* 1 = 1.29507 loss)
I0524 02:20:54.663265  8498 sgd_solver.cpp:106] Iteration 99724, lr = 0.002
I0524 02:21:03.561650  8498 solver.cpp:237] Iteration 99938, loss = 1.08535
I0524 02:21:03.561692  8498 solver.cpp:253]     Train net output #0: loss = 1.08535 (* 1 = 1.08535 loss)
I0524 02:21:03.561712  8498 sgd_solver.cpp:106] Iteration 99938, lr = 0.002
I0524 02:21:33.348130  8498 solver.cpp:237] Iteration 100152, loss = 1.24961
I0524 02:21:33.348332  8498 solver.cpp:253]     Train net output #0: loss = 1.24961 (* 1 = 1.24961 loss)
I0524 02:21:33.348345  8498 sgd_solver.cpp:106] Iteration 100152, lr = 0.002
I0524 02:21:42.240255  8498 solver.cpp:237] Iteration 100366, loss = 1.37249
I0524 02:21:42.240289  8498 solver.cpp:253]     Train net output #0: loss = 1.37249 (* 1 = 1.37249 loss)
I0524 02:21:42.240305  8498 sgd_solver.cpp:106] Iteration 100366, lr = 0.002
I0524 02:21:51.141407  8498 solver.cpp:237] Iteration 100580, loss = 1.11023
I0524 02:21:51.141445  8498 solver.cpp:253]     Train net output #0: loss = 1.11023 (* 1 = 1.11023 loss)
I0524 02:21:51.141458  8498 sgd_solver.cpp:106] Iteration 100580, lr = 0.002
I0524 02:21:55.008878  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_100674.caffemodel
I0524 02:21:55.078678  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_100674.solverstate
I0524 02:22:00.152479  8498 solver.cpp:237] Iteration 100794, loss = 1.16031
I0524 02:22:00.152523  8498 solver.cpp:253]     Train net output #0: loss = 1.16031 (* 1 = 1.16031 loss)
I0524 02:22:00.152540  8498 sgd_solver.cpp:106] Iteration 100794, lr = 0.002
I0524 02:22:09.053681  8498 solver.cpp:237] Iteration 101008, loss = 1.16425
I0524 02:22:09.053874  8498 solver.cpp:253]     Train net output #0: loss = 1.16425 (* 1 = 1.16425 loss)
I0524 02:22:09.053889  8498 sgd_solver.cpp:106] Iteration 101008, lr = 0.002
I0524 02:22:17.949892  8498 solver.cpp:237] Iteration 101222, loss = 1.24753
I0524 02:22:17.949934  8498 solver.cpp:253]     Train net output #0: loss = 1.24753 (* 1 = 1.24753 loss)
I0524 02:22:17.949952  8498 sgd_solver.cpp:106] Iteration 101222, lr = 0.002
I0524 02:22:47.753870  8498 solver.cpp:237] Iteration 101436, loss = 1.25513
I0524 02:22:47.754076  8498 solver.cpp:253]     Train net output #0: loss = 1.25513 (* 1 = 1.25513 loss)
I0524 02:22:47.754089  8498 sgd_solver.cpp:106] Iteration 101436, lr = 0.002
I0524 02:22:56.653611  8498 solver.cpp:237] Iteration 101650, loss = 1.14285
I0524 02:22:56.653645  8498 solver.cpp:253]     Train net output #0: loss = 1.14285 (* 1 = 1.14285 loss)
I0524 02:22:56.653666  8498 sgd_solver.cpp:106] Iteration 101650, lr = 0.002
I0524 02:23:05.555927  8498 solver.cpp:237] Iteration 101864, loss = 1.315
I0524 02:23:05.555976  8498 solver.cpp:253]     Train net output #0: loss = 1.315 (* 1 = 1.315 loss)
I0524 02:23:05.555991  8498 sgd_solver.cpp:106] Iteration 101864, lr = 0.002
I0524 02:23:14.461783  8498 solver.cpp:237] Iteration 102078, loss = 1.04539
I0524 02:23:14.461819  8498 solver.cpp:253]     Train net output #0: loss = 1.04539 (* 1 = 1.04539 loss)
I0524 02:23:14.461834  8498 sgd_solver.cpp:106] Iteration 102078, lr = 0.002
I0524 02:23:23.362066  8498 solver.cpp:237] Iteration 102292, loss = 1.06363
I0524 02:23:23.362265  8498 solver.cpp:253]     Train net output #0: loss = 1.06363 (* 1 = 1.06363 loss)
I0524 02:23:23.362282  8498 sgd_solver.cpp:106] Iteration 102292, lr = 0.002
I0524 02:23:32.265658  8498 solver.cpp:237] Iteration 102506, loss = 1.08525
I0524 02:23:32.265702  8498 solver.cpp:253]     Train net output #0: loss = 1.08525 (* 1 = 1.08525 loss)
I0524 02:23:32.265722  8498 sgd_solver.cpp:106] Iteration 102506, lr = 0.002
I0524 02:23:41.160516  8498 solver.cpp:237] Iteration 102720, loss = 1.35267
I0524 02:23:41.160552  8498 solver.cpp:253]     Train net output #0: loss = 1.35267 (* 1 = 1.35267 loss)
I0524 02:23:41.160567  8498 sgd_solver.cpp:106] Iteration 102720, lr = 0.002
I0524 02:23:45.112300  8498 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_102816.caffemodel
I0524 02:23:45.202961  8498 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0020_2016-05-20T15.49.13.759876_iter_102816.solverstate
I0524 02:23:46.198999  8498 solver.cpp:341] Iteration 102840, Testing net (#0)
aprun: Apid 11259129: Caught signal Terminated, sending to application
*** Aborted at 1464071056 (unix time) try "date -d @1464071056" if you are using GNU date ***
PC: @     0x2aaab930eb63 (unknown)
aprun: Apid 11259129: Caught signal Terminated, sending to application
*** SIGTERM (@0x212f) received by PID 8498 (TID 0x2aaac746f900) from PID 8495; stack trace: ***
=>> PBS: job killed: walltime 7234 exceeded limit 7200
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab930eb63 (unknown)
    @     0x2aaab928a408 (unknown)
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
    @     0x2aaab91e98af (unknown)
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @           0x5ca001 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11259129: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
aprun: Apid 11259129: Caught signal Terminated, sending to application
