2809972
I0525 04:48:53.579145 22762 caffe.cpp:184] Using GPUs 0
I0525 04:48:54.003952 22762 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1666
test_interval: 3333
base_lr: 0.001
display: 166
max_iter: 166660
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 1666
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439.prototxt"
I0525 04:48:54.006650 22762 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439.prototxt
I0525 04:48:54.020519 22762 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0525 04:48:54.020584 22762 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0525 04:48:54.020963 22762 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 04:48:54.021163 22762 layer_factory.hpp:77] Creating layer data_hdf5
I0525 04:48:54.021189 22762 net.cpp:106] Creating Layer data_hdf5
I0525 04:48:54.021205 22762 net.cpp:411] data_hdf5 -> data
I0525 04:48:54.021258 22762 net.cpp:411] data_hdf5 -> label
I0525 04:48:54.021293 22762 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0525 04:48:54.022868 22762 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0525 04:48:54.025213 22762 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 04:49:15.537080 22762 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0525 04:49:15.542307 22762 net.cpp:150] Setting up data_hdf5
I0525 04:49:15.542347 22762 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 04:49:15.542364 22762 net.cpp:157] Top shape: 90 (90)
I0525 04:49:15.542377 22762 net.cpp:165] Memory required for data: 2286360
I0525 04:49:15.542397 22762 layer_factory.hpp:77] Creating layer conv1
I0525 04:49:15.542429 22762 net.cpp:106] Creating Layer conv1
I0525 04:49:15.542457 22762 net.cpp:454] conv1 <- data
I0525 04:49:15.542482 22762 net.cpp:411] conv1 -> conv1
I0525 04:49:16.490108 22762 net.cpp:150] Setting up conv1
I0525 04:49:16.490162 22762 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:49:16.490190 22762 net.cpp:165] Memory required for data: 27169560
I0525 04:49:16.490221 22762 layer_factory.hpp:77] Creating layer relu1
I0525 04:49:16.490244 22762 net.cpp:106] Creating Layer relu1
I0525 04:49:16.490264 22762 net.cpp:454] relu1 <- conv1
I0525 04:49:16.490300 22762 net.cpp:397] relu1 -> conv1 (in-place)
I0525 04:49:16.490828 22762 net.cpp:150] Setting up relu1
I0525 04:49:16.490851 22762 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:49:16.490864 22762 net.cpp:165] Memory required for data: 52052760
I0525 04:49:16.490880 22762 layer_factory.hpp:77] Creating layer pool1
I0525 04:49:16.490907 22762 net.cpp:106] Creating Layer pool1
I0525 04:49:16.490921 22762 net.cpp:454] pool1 <- conv1
I0525 04:49:16.490937 22762 net.cpp:411] pool1 -> pool1
I0525 04:49:16.491022 22762 net.cpp:150] Setting up pool1
I0525 04:49:16.491040 22762 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 04:49:16.491052 22762 net.cpp:165] Memory required for data: 64494360
I0525 04:49:16.491065 22762 layer_factory.hpp:77] Creating layer conv2
I0525 04:49:16.491089 22762 net.cpp:106] Creating Layer conv2
I0525 04:49:16.491102 22762 net.cpp:454] conv2 <- pool1
I0525 04:49:16.491118 22762 net.cpp:411] conv2 -> conv2
I0525 04:49:16.493892 22762 net.cpp:150] Setting up conv2
I0525 04:49:16.493923 22762 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:49:16.493938 22762 net.cpp:165] Memory required for data: 82379160
I0525 04:49:16.493966 22762 layer_factory.hpp:77] Creating layer relu2
I0525 04:49:16.493994 22762 net.cpp:106] Creating Layer relu2
I0525 04:49:16.494009 22762 net.cpp:454] relu2 <- conv2
I0525 04:49:16.494024 22762 net.cpp:397] relu2 -> conv2 (in-place)
I0525 04:49:16.494382 22762 net.cpp:150] Setting up relu2
I0525 04:49:16.494402 22762 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:49:16.494415 22762 net.cpp:165] Memory required for data: 100263960
I0525 04:49:16.494427 22762 layer_factory.hpp:77] Creating layer pool2
I0525 04:49:16.494452 22762 net.cpp:106] Creating Layer pool2
I0525 04:49:16.494467 22762 net.cpp:454] pool2 <- conv2
I0525 04:49:16.494482 22762 net.cpp:411] pool2 -> pool2
I0525 04:49:16.494571 22762 net.cpp:150] Setting up pool2
I0525 04:49:16.494587 22762 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 04:49:16.494599 22762 net.cpp:165] Memory required for data: 109206360
I0525 04:49:16.494611 22762 layer_factory.hpp:77] Creating layer conv3
I0525 04:49:16.494648 22762 net.cpp:106] Creating Layer conv3
I0525 04:49:16.494663 22762 net.cpp:454] conv3 <- pool2
I0525 04:49:16.494679 22762 net.cpp:411] conv3 -> conv3
I0525 04:49:16.496646 22762 net.cpp:150] Setting up conv3
I0525 04:49:16.496672 22762 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:49:16.496685 22762 net.cpp:165] Memory required for data: 118963800
I0525 04:49:16.496711 22762 layer_factory.hpp:77] Creating layer relu3
I0525 04:49:16.496731 22762 net.cpp:106] Creating Layer relu3
I0525 04:49:16.496753 22762 net.cpp:454] relu3 <- conv3
I0525 04:49:16.496769 22762 net.cpp:397] relu3 -> conv3 (in-place)
I0525 04:49:16.497265 22762 net.cpp:150] Setting up relu3
I0525 04:49:16.497289 22762 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:49:16.497303 22762 net.cpp:165] Memory required for data: 128721240
I0525 04:49:16.497318 22762 layer_factory.hpp:77] Creating layer pool3
I0525 04:49:16.497342 22762 net.cpp:106] Creating Layer pool3
I0525 04:49:16.497355 22762 net.cpp:454] pool3 <- conv3
I0525 04:49:16.497371 22762 net.cpp:411] pool3 -> pool3
I0525 04:49:16.497447 22762 net.cpp:150] Setting up pool3
I0525 04:49:16.497473 22762 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 04:49:16.497485 22762 net.cpp:165] Memory required for data: 133599960
I0525 04:49:16.497498 22762 layer_factory.hpp:77] Creating layer conv4
I0525 04:49:16.497531 22762 net.cpp:106] Creating Layer conv4
I0525 04:49:16.497545 22762 net.cpp:454] conv4 <- pool3
I0525 04:49:16.497568 22762 net.cpp:411] conv4 -> conv4
I0525 04:49:16.500576 22762 net.cpp:150] Setting up conv4
I0525 04:49:16.500609 22762 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:49:16.500622 22762 net.cpp:165] Memory required for data: 136865880
I0525 04:49:16.500648 22762 layer_factory.hpp:77] Creating layer relu4
I0525 04:49:16.500675 22762 net.cpp:106] Creating Layer relu4
I0525 04:49:16.500689 22762 net.cpp:454] relu4 <- conv4
I0525 04:49:16.500705 22762 net.cpp:397] relu4 -> conv4 (in-place)
I0525 04:49:16.501201 22762 net.cpp:150] Setting up relu4
I0525 04:49:16.501224 22762 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:49:16.501238 22762 net.cpp:165] Memory required for data: 140131800
I0525 04:49:16.501253 22762 layer_factory.hpp:77] Creating layer pool4
I0525 04:49:16.501269 22762 net.cpp:106] Creating Layer pool4
I0525 04:49:16.501283 22762 net.cpp:454] pool4 <- conv4
I0525 04:49:16.501307 22762 net.cpp:411] pool4 -> pool4
I0525 04:49:16.501382 22762 net.cpp:150] Setting up pool4
I0525 04:49:16.501410 22762 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 04:49:16.501422 22762 net.cpp:165] Memory required for data: 141764760
I0525 04:49:16.501437 22762 layer_factory.hpp:77] Creating layer ip1
I0525 04:49:16.501459 22762 net.cpp:106] Creating Layer ip1
I0525 04:49:16.501472 22762 net.cpp:454] ip1 <- pool4
I0525 04:49:16.501494 22762 net.cpp:411] ip1 -> ip1
I0525 04:49:16.516996 22762 net.cpp:150] Setting up ip1
I0525 04:49:16.517027 22762 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:49:16.517048 22762 net.cpp:165] Memory required for data: 141835320
I0525 04:49:16.517076 22762 layer_factory.hpp:77] Creating layer relu5
I0525 04:49:16.517097 22762 net.cpp:106] Creating Layer relu5
I0525 04:49:16.517109 22762 net.cpp:454] relu5 <- ip1
I0525 04:49:16.517138 22762 net.cpp:397] relu5 -> ip1 (in-place)
I0525 04:49:16.517495 22762 net.cpp:150] Setting up relu5
I0525 04:49:16.517515 22762 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:49:16.517527 22762 net.cpp:165] Memory required for data: 141905880
I0525 04:49:16.517540 22762 layer_factory.hpp:77] Creating layer drop1
I0525 04:49:16.517566 22762 net.cpp:106] Creating Layer drop1
I0525 04:49:16.517580 22762 net.cpp:454] drop1 <- ip1
I0525 04:49:16.517596 22762 net.cpp:397] drop1 -> ip1 (in-place)
I0525 04:49:16.517669 22762 net.cpp:150] Setting up drop1
I0525 04:49:16.517686 22762 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:49:16.517699 22762 net.cpp:165] Memory required for data: 141976440
I0525 04:49:16.517710 22762 layer_factory.hpp:77] Creating layer ip2
I0525 04:49:16.517732 22762 net.cpp:106] Creating Layer ip2
I0525 04:49:16.517761 22762 net.cpp:454] ip2 <- ip1
I0525 04:49:16.517779 22762 net.cpp:411] ip2 -> ip2
I0525 04:49:16.518277 22762 net.cpp:150] Setting up ip2
I0525 04:49:16.518297 22762 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:49:16.518311 22762 net.cpp:165] Memory required for data: 142011720
I0525 04:49:16.518332 22762 layer_factory.hpp:77] Creating layer relu6
I0525 04:49:16.518347 22762 net.cpp:106] Creating Layer relu6
I0525 04:49:16.518359 22762 net.cpp:454] relu6 <- ip2
I0525 04:49:16.518375 22762 net.cpp:397] relu6 -> ip2 (in-place)
I0525 04:49:16.518934 22762 net.cpp:150] Setting up relu6
I0525 04:49:16.518955 22762 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:49:16.518980 22762 net.cpp:165] Memory required for data: 142047000
I0525 04:49:16.518992 22762 layer_factory.hpp:77] Creating layer drop2
I0525 04:49:16.519007 22762 net.cpp:106] Creating Layer drop2
I0525 04:49:16.519023 22762 net.cpp:454] drop2 <- ip2
I0525 04:49:16.519047 22762 net.cpp:397] drop2 -> ip2 (in-place)
I0525 04:49:16.519093 22762 net.cpp:150] Setting up drop2
I0525 04:49:16.519112 22762 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:49:16.519124 22762 net.cpp:165] Memory required for data: 142082280
I0525 04:49:16.519143 22762 layer_factory.hpp:77] Creating layer ip3
I0525 04:49:16.519160 22762 net.cpp:106] Creating Layer ip3
I0525 04:49:16.519175 22762 net.cpp:454] ip3 <- ip2
I0525 04:49:16.519189 22762 net.cpp:411] ip3 -> ip3
I0525 04:49:16.519423 22762 net.cpp:150] Setting up ip3
I0525 04:49:16.519443 22762 net.cpp:157] Top shape: 90 11 (990)
I0525 04:49:16.519454 22762 net.cpp:165] Memory required for data: 142086240
I0525 04:49:16.519475 22762 layer_factory.hpp:77] Creating layer drop3
I0525 04:49:16.519496 22762 net.cpp:106] Creating Layer drop3
I0525 04:49:16.519510 22762 net.cpp:454] drop3 <- ip3
I0525 04:49:16.519526 22762 net.cpp:397] drop3 -> ip3 (in-place)
I0525 04:49:16.519572 22762 net.cpp:150] Setting up drop3
I0525 04:49:16.519587 22762 net.cpp:157] Top shape: 90 11 (990)
I0525 04:49:16.519606 22762 net.cpp:165] Memory required for data: 142090200
I0525 04:49:16.519621 22762 layer_factory.hpp:77] Creating layer loss
I0525 04:49:16.519644 22762 net.cpp:106] Creating Layer loss
I0525 04:49:16.519659 22762 net.cpp:454] loss <- ip3
I0525 04:49:16.519680 22762 net.cpp:454] loss <- label
I0525 04:49:16.519695 22762 net.cpp:411] loss -> loss
I0525 04:49:16.519714 22762 layer_factory.hpp:77] Creating layer loss
I0525 04:49:16.520395 22762 net.cpp:150] Setting up loss
I0525 04:49:16.520416 22762 net.cpp:157] Top shape: (1)
I0525 04:49:16.520433 22762 net.cpp:160]     with loss weight 1
I0525 04:49:16.520484 22762 net.cpp:165] Memory required for data: 142090204
I0525 04:49:16.520508 22762 net.cpp:226] loss needs backward computation.
I0525 04:49:16.520521 22762 net.cpp:226] drop3 needs backward computation.
I0525 04:49:16.520535 22762 net.cpp:226] ip3 needs backward computation.
I0525 04:49:16.520551 22762 net.cpp:226] drop2 needs backward computation.
I0525 04:49:16.520565 22762 net.cpp:226] relu6 needs backward computation.
I0525 04:49:16.520576 22762 net.cpp:226] ip2 needs backward computation.
I0525 04:49:16.520591 22762 net.cpp:226] drop1 needs backward computation.
I0525 04:49:16.520603 22762 net.cpp:226] relu5 needs backward computation.
I0525 04:49:16.520622 22762 net.cpp:226] ip1 needs backward computation.
I0525 04:49:16.520635 22762 net.cpp:226] pool4 needs backward computation.
I0525 04:49:16.520649 22762 net.cpp:226] relu4 needs backward computation.
I0525 04:49:16.520663 22762 net.cpp:226] conv4 needs backward computation.
I0525 04:49:16.520675 22762 net.cpp:226] pool3 needs backward computation.
I0525 04:49:16.520690 22762 net.cpp:226] relu3 needs backward computation.
I0525 04:49:16.520720 22762 net.cpp:226] conv3 needs backward computation.
I0525 04:49:16.520735 22762 net.cpp:226] pool2 needs backward computation.
I0525 04:49:16.520751 22762 net.cpp:226] relu2 needs backward computation.
I0525 04:49:16.520764 22762 net.cpp:226] conv2 needs backward computation.
I0525 04:49:16.520777 22762 net.cpp:226] pool1 needs backward computation.
I0525 04:49:16.520793 22762 net.cpp:226] relu1 needs backward computation.
I0525 04:49:16.520805 22762 net.cpp:226] conv1 needs backward computation.
I0525 04:49:16.520819 22762 net.cpp:228] data_hdf5 does not need backward computation.
I0525 04:49:16.520833 22762 net.cpp:270] This network produces output loss
I0525 04:49:16.520859 22762 net.cpp:283] Network initialization done.
I0525 04:49:16.522603 22762 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439.prototxt
I0525 04:49:16.522682 22762 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0525 04:49:16.523059 22762 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 90
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 04:49:16.523275 22762 layer_factory.hpp:77] Creating layer data_hdf5
I0525 04:49:16.523301 22762 net.cpp:106] Creating Layer data_hdf5
I0525 04:49:16.523320 22762 net.cpp:411] data_hdf5 -> data
I0525 04:49:16.523340 22762 net.cpp:411] data_hdf5 -> label
I0525 04:49:16.523361 22762 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0525 04:49:16.524706 22762 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0525 04:49:37.816859 22762 net.cpp:150] Setting up data_hdf5
I0525 04:49:37.817028 22762 net.cpp:157] Top shape: 90 1 127 50 (571500)
I0525 04:49:37.817046 22762 net.cpp:157] Top shape: 90 (90)
I0525 04:49:37.817059 22762 net.cpp:165] Memory required for data: 2286360
I0525 04:49:37.817073 22762 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0525 04:49:37.817107 22762 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0525 04:49:37.817121 22762 net.cpp:454] label_data_hdf5_1_split <- label
I0525 04:49:37.817137 22762 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0525 04:49:37.817159 22762 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0525 04:49:37.817235 22762 net.cpp:150] Setting up label_data_hdf5_1_split
I0525 04:49:37.817252 22762 net.cpp:157] Top shape: 90 (90)
I0525 04:49:37.817267 22762 net.cpp:157] Top shape: 90 (90)
I0525 04:49:37.817281 22762 net.cpp:165] Memory required for data: 2287080
I0525 04:49:37.817325 22762 layer_factory.hpp:77] Creating layer conv1
I0525 04:49:37.817360 22762 net.cpp:106] Creating Layer conv1
I0525 04:49:37.817374 22762 net.cpp:454] conv1 <- data
I0525 04:49:37.817401 22762 net.cpp:411] conv1 -> conv1
I0525 04:49:37.819387 22762 net.cpp:150] Setting up conv1
I0525 04:49:37.819412 22762 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:49:37.819432 22762 net.cpp:165] Memory required for data: 27170280
I0525 04:49:37.819455 22762 layer_factory.hpp:77] Creating layer relu1
I0525 04:49:37.819476 22762 net.cpp:106] Creating Layer relu1
I0525 04:49:37.819489 22762 net.cpp:454] relu1 <- conv1
I0525 04:49:37.819506 22762 net.cpp:397] relu1 -> conv1 (in-place)
I0525 04:49:37.820032 22762 net.cpp:150] Setting up relu1
I0525 04:49:37.820056 22762 net.cpp:157] Top shape: 90 12 120 48 (6220800)
I0525 04:49:37.820070 22762 net.cpp:165] Memory required for data: 52053480
I0525 04:49:37.820081 22762 layer_factory.hpp:77] Creating layer pool1
I0525 04:49:37.820103 22762 net.cpp:106] Creating Layer pool1
I0525 04:49:37.820117 22762 net.cpp:454] pool1 <- conv1
I0525 04:49:37.820133 22762 net.cpp:411] pool1 -> pool1
I0525 04:49:37.820233 22762 net.cpp:150] Setting up pool1
I0525 04:49:37.820257 22762 net.cpp:157] Top shape: 90 12 60 48 (3110400)
I0525 04:49:37.820281 22762 net.cpp:165] Memory required for data: 64495080
I0525 04:49:37.820292 22762 layer_factory.hpp:77] Creating layer conv2
I0525 04:49:37.820314 22762 net.cpp:106] Creating Layer conv2
I0525 04:49:37.820327 22762 net.cpp:454] conv2 <- pool1
I0525 04:49:37.820349 22762 net.cpp:411] conv2 -> conv2
I0525 04:49:37.822304 22762 net.cpp:150] Setting up conv2
I0525 04:49:37.822329 22762 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:49:37.822350 22762 net.cpp:165] Memory required for data: 82379880
I0525 04:49:37.822371 22762 layer_factory.hpp:77] Creating layer relu2
I0525 04:49:37.822391 22762 net.cpp:106] Creating Layer relu2
I0525 04:49:37.822403 22762 net.cpp:454] relu2 <- conv2
I0525 04:49:37.822418 22762 net.cpp:397] relu2 -> conv2 (in-place)
I0525 04:49:37.822777 22762 net.cpp:150] Setting up relu2
I0525 04:49:37.822796 22762 net.cpp:157] Top shape: 90 20 54 46 (4471200)
I0525 04:49:37.822808 22762 net.cpp:165] Memory required for data: 100264680
I0525 04:49:37.822824 22762 layer_factory.hpp:77] Creating layer pool2
I0525 04:49:37.822846 22762 net.cpp:106] Creating Layer pool2
I0525 04:49:37.822860 22762 net.cpp:454] pool2 <- conv2
I0525 04:49:37.822875 22762 net.cpp:411] pool2 -> pool2
I0525 04:49:37.822964 22762 net.cpp:150] Setting up pool2
I0525 04:49:37.822986 22762 net.cpp:157] Top shape: 90 20 27 46 (2235600)
I0525 04:49:37.822999 22762 net.cpp:165] Memory required for data: 109207080
I0525 04:49:37.823014 22762 layer_factory.hpp:77] Creating layer conv3
I0525 04:49:37.823035 22762 net.cpp:106] Creating Layer conv3
I0525 04:49:37.823048 22762 net.cpp:454] conv3 <- pool2
I0525 04:49:37.823072 22762 net.cpp:411] conv3 -> conv3
I0525 04:49:37.825101 22762 net.cpp:150] Setting up conv3
I0525 04:49:37.825126 22762 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:49:37.825145 22762 net.cpp:165] Memory required for data: 118964520
I0525 04:49:37.825186 22762 layer_factory.hpp:77] Creating layer relu3
I0525 04:49:37.825212 22762 net.cpp:106] Creating Layer relu3
I0525 04:49:37.825224 22762 net.cpp:454] relu3 <- conv3
I0525 04:49:37.825240 22762 net.cpp:397] relu3 -> conv3 (in-place)
I0525 04:49:37.825736 22762 net.cpp:150] Setting up relu3
I0525 04:49:37.825758 22762 net.cpp:157] Top shape: 90 28 22 44 (2439360)
I0525 04:49:37.825772 22762 net.cpp:165] Memory required for data: 128721960
I0525 04:49:37.825788 22762 layer_factory.hpp:77] Creating layer pool3
I0525 04:49:37.825803 22762 net.cpp:106] Creating Layer pool3
I0525 04:49:37.825824 22762 net.cpp:454] pool3 <- conv3
I0525 04:49:37.825841 22762 net.cpp:411] pool3 -> pool3
I0525 04:49:37.825920 22762 net.cpp:150] Setting up pool3
I0525 04:49:37.825937 22762 net.cpp:157] Top shape: 90 28 11 44 (1219680)
I0525 04:49:37.825956 22762 net.cpp:165] Memory required for data: 133600680
I0525 04:49:37.825971 22762 layer_factory.hpp:77] Creating layer conv4
I0525 04:49:37.825991 22762 net.cpp:106] Creating Layer conv4
I0525 04:49:37.826005 22762 net.cpp:454] conv4 <- pool3
I0525 04:49:37.826021 22762 net.cpp:411] conv4 -> conv4
I0525 04:49:37.828174 22762 net.cpp:150] Setting up conv4
I0525 04:49:37.828198 22762 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:49:37.828218 22762 net.cpp:165] Memory required for data: 136866600
I0525 04:49:37.828238 22762 layer_factory.hpp:77] Creating layer relu4
I0525 04:49:37.828258 22762 net.cpp:106] Creating Layer relu4
I0525 04:49:37.828285 22762 net.cpp:454] relu4 <- conv4
I0525 04:49:37.828302 22762 net.cpp:397] relu4 -> conv4 (in-place)
I0525 04:49:37.828794 22762 net.cpp:150] Setting up relu4
I0525 04:49:37.828817 22762 net.cpp:157] Top shape: 90 36 6 42 (816480)
I0525 04:49:37.828830 22762 net.cpp:165] Memory required for data: 140132520
I0525 04:49:37.828846 22762 layer_factory.hpp:77] Creating layer pool4
I0525 04:49:37.828862 22762 net.cpp:106] Creating Layer pool4
I0525 04:49:37.828877 22762 net.cpp:454] pool4 <- conv4
I0525 04:49:37.828902 22762 net.cpp:411] pool4 -> pool4
I0525 04:49:37.828989 22762 net.cpp:150] Setting up pool4
I0525 04:49:37.829006 22762 net.cpp:157] Top shape: 90 36 3 42 (408240)
I0525 04:49:37.829020 22762 net.cpp:165] Memory required for data: 141765480
I0525 04:49:37.829032 22762 layer_factory.hpp:77] Creating layer ip1
I0525 04:49:37.829051 22762 net.cpp:106] Creating Layer ip1
I0525 04:49:37.829069 22762 net.cpp:454] ip1 <- pool4
I0525 04:49:37.829092 22762 net.cpp:411] ip1 -> ip1
I0525 04:49:37.844602 22762 net.cpp:150] Setting up ip1
I0525 04:49:37.844636 22762 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:49:37.844650 22762 net.cpp:165] Memory required for data: 141836040
I0525 04:49:37.844681 22762 layer_factory.hpp:77] Creating layer relu5
I0525 04:49:37.844708 22762 net.cpp:106] Creating Layer relu5
I0525 04:49:37.844722 22762 net.cpp:454] relu5 <- ip1
I0525 04:49:37.844739 22762 net.cpp:397] relu5 -> ip1 (in-place)
I0525 04:49:37.845118 22762 net.cpp:150] Setting up relu5
I0525 04:49:37.845139 22762 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:49:37.845152 22762 net.cpp:165] Memory required for data: 141906600
I0525 04:49:37.845167 22762 layer_factory.hpp:77] Creating layer drop1
I0525 04:49:37.845188 22762 net.cpp:106] Creating Layer drop1
I0525 04:49:37.845201 22762 net.cpp:454] drop1 <- ip1
I0525 04:49:37.845217 22762 net.cpp:397] drop1 -> ip1 (in-place)
I0525 04:49:37.845268 22762 net.cpp:150] Setting up drop1
I0525 04:49:37.845284 22762 net.cpp:157] Top shape: 90 196 (17640)
I0525 04:49:37.845298 22762 net.cpp:165] Memory required for data: 141977160
I0525 04:49:37.845332 22762 layer_factory.hpp:77] Creating layer ip2
I0525 04:49:37.845350 22762 net.cpp:106] Creating Layer ip2
I0525 04:49:37.845376 22762 net.cpp:454] ip2 <- ip1
I0525 04:49:37.845392 22762 net.cpp:411] ip2 -> ip2
I0525 04:49:37.845887 22762 net.cpp:150] Setting up ip2
I0525 04:49:37.845906 22762 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:49:37.845919 22762 net.cpp:165] Memory required for data: 142012440
I0525 04:49:37.845937 22762 layer_factory.hpp:77] Creating layer relu6
I0525 04:49:37.845966 22762 net.cpp:106] Creating Layer relu6
I0525 04:49:37.845979 22762 net.cpp:454] relu6 <- ip2
I0525 04:49:37.845995 22762 net.cpp:397] relu6 -> ip2 (in-place)
I0525 04:49:37.846573 22762 net.cpp:150] Setting up relu6
I0525 04:49:37.846596 22762 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:49:37.846611 22762 net.cpp:165] Memory required for data: 142047720
I0525 04:49:37.846623 22762 layer_factory.hpp:77] Creating layer drop2
I0525 04:49:37.846642 22762 net.cpp:106] Creating Layer drop2
I0525 04:49:37.846657 22762 net.cpp:454] drop2 <- ip2
I0525 04:49:37.846673 22762 net.cpp:397] drop2 -> ip2 (in-place)
I0525 04:49:37.846720 22762 net.cpp:150] Setting up drop2
I0525 04:49:37.846750 22762 net.cpp:157] Top shape: 90 98 (8820)
I0525 04:49:37.846765 22762 net.cpp:165] Memory required for data: 142083000
I0525 04:49:37.846776 22762 layer_factory.hpp:77] Creating layer ip3
I0525 04:49:37.846793 22762 net.cpp:106] Creating Layer ip3
I0525 04:49:37.846806 22762 net.cpp:454] ip3 <- ip2
I0525 04:49:37.846822 22762 net.cpp:411] ip3 -> ip3
I0525 04:49:37.847079 22762 net.cpp:150] Setting up ip3
I0525 04:49:37.847100 22762 net.cpp:157] Top shape: 90 11 (990)
I0525 04:49:37.847112 22762 net.cpp:165] Memory required for data: 142086960
I0525 04:49:37.847133 22762 layer_factory.hpp:77] Creating layer drop3
I0525 04:49:37.847157 22762 net.cpp:106] Creating Layer drop3
I0525 04:49:37.847169 22762 net.cpp:454] drop3 <- ip3
I0525 04:49:37.847185 22762 net.cpp:397] drop3 -> ip3 (in-place)
I0525 04:49:37.847234 22762 net.cpp:150] Setting up drop3
I0525 04:49:37.847256 22762 net.cpp:157] Top shape: 90 11 (990)
I0525 04:49:37.847268 22762 net.cpp:165] Memory required for data: 142090920
I0525 04:49:37.847287 22762 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0525 04:49:37.847303 22762 net.cpp:106] Creating Layer ip3_drop3_0_split
I0525 04:49:37.847316 22762 net.cpp:454] ip3_drop3_0_split <- ip3
I0525 04:49:37.847333 22762 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0525 04:49:37.847358 22762 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0525 04:49:37.847445 22762 net.cpp:150] Setting up ip3_drop3_0_split
I0525 04:49:37.847462 22762 net.cpp:157] Top shape: 90 11 (990)
I0525 04:49:37.847477 22762 net.cpp:157] Top shape: 90 11 (990)
I0525 04:49:37.847492 22762 net.cpp:165] Memory required for data: 142098840
I0525 04:49:37.847504 22762 layer_factory.hpp:77] Creating layer accuracy
I0525 04:49:37.847533 22762 net.cpp:106] Creating Layer accuracy
I0525 04:49:37.847556 22762 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0525 04:49:37.847570 22762 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0525 04:49:37.847586 22762 net.cpp:411] accuracy -> accuracy
I0525 04:49:37.847620 22762 net.cpp:150] Setting up accuracy
I0525 04:49:37.847636 22762 net.cpp:157] Top shape: (1)
I0525 04:49:37.847648 22762 net.cpp:165] Memory required for data: 142098844
I0525 04:49:37.847661 22762 layer_factory.hpp:77] Creating layer loss
I0525 04:49:37.847676 22762 net.cpp:106] Creating Layer loss
I0525 04:49:37.847692 22762 net.cpp:454] loss <- ip3_drop3_0_split_1
I0525 04:49:37.847705 22762 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0525 04:49:37.847728 22762 net.cpp:411] loss -> loss
I0525 04:49:37.847754 22762 layer_factory.hpp:77] Creating layer loss
I0525 04:49:37.848284 22762 net.cpp:150] Setting up loss
I0525 04:49:37.848304 22762 net.cpp:157] Top shape: (1)
I0525 04:49:37.848316 22762 net.cpp:160]     with loss weight 1
I0525 04:49:37.848343 22762 net.cpp:165] Memory required for data: 142098848
I0525 04:49:37.848363 22762 net.cpp:226] loss needs backward computation.
I0525 04:49:37.848378 22762 net.cpp:228] accuracy does not need backward computation.
I0525 04:49:37.848397 22762 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0525 04:49:37.848409 22762 net.cpp:226] drop3 needs backward computation.
I0525 04:49:37.848422 22762 net.cpp:226] ip3 needs backward computation.
I0525 04:49:37.848436 22762 net.cpp:226] drop2 needs backward computation.
I0525 04:49:37.848448 22762 net.cpp:226] relu6 needs backward computation.
I0525 04:49:37.848479 22762 net.cpp:226] ip2 needs backward computation.
I0525 04:49:37.848495 22762 net.cpp:226] drop1 needs backward computation.
I0525 04:49:37.848507 22762 net.cpp:226] relu5 needs backward computation.
I0525 04:49:37.848520 22762 net.cpp:226] ip1 needs backward computation.
I0525 04:49:37.848531 22762 net.cpp:226] pool4 needs backward computation.
I0525 04:49:37.848547 22762 net.cpp:226] relu4 needs backward computation.
I0525 04:49:37.848567 22762 net.cpp:226] conv4 needs backward computation.
I0525 04:49:37.848580 22762 net.cpp:226] pool3 needs backward computation.
I0525 04:49:37.848593 22762 net.cpp:226] relu3 needs backward computation.
I0525 04:49:37.848606 22762 net.cpp:226] conv3 needs backward computation.
I0525 04:49:37.848618 22762 net.cpp:226] pool2 needs backward computation.
I0525 04:49:37.848630 22762 net.cpp:226] relu2 needs backward computation.
I0525 04:49:37.848645 22762 net.cpp:226] conv2 needs backward computation.
I0525 04:49:37.848665 22762 net.cpp:226] pool1 needs backward computation.
I0525 04:49:37.848680 22762 net.cpp:226] relu1 needs backward computation.
I0525 04:49:37.848692 22762 net.cpp:226] conv1 needs backward computation.
I0525 04:49:37.848706 22762 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0525 04:49:37.848721 22762 net.cpp:228] data_hdf5 does not need backward computation.
I0525 04:49:37.848734 22762 net.cpp:270] This network produces output accuracy
I0525 04:49:37.848747 22762 net.cpp:270] This network produces output loss
I0525 04:49:37.848778 22762 net.cpp:283] Network initialization done.
I0525 04:49:37.848914 22762 solver.cpp:60] Solver scaffolding done.
I0525 04:49:37.850054 22762 caffe.cpp:212] Starting Optimization
I0525 04:49:37.850070 22762 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0525 04:49:37.850085 22762 solver.cpp:289] Learning Rate Policy: fixed
I0525 04:49:37.851167 22762 solver.cpp:341] Iteration 0, Testing net (#0)
I0525 04:50:25.933023 22762 solver.cpp:409]     Test net output #0: accuracy = 0.0391156
I0525 04:50:25.933192 22762 solver.cpp:409]     Test net output #1: loss = 2.39896 (* 1 = 2.39896 loss)
I0525 04:50:25.964413 22762 solver.cpp:237] Iteration 0, loss = 2.40291
I0525 04:50:25.964452 22762 solver.cpp:253]     Train net output #0: loss = 2.40291 (* 1 = 2.40291 loss)
I0525 04:50:25.964473 22762 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0525 04:50:34.817776 22762 solver.cpp:237] Iteration 166, loss = 2.31905
I0525 04:50:34.817829 22762 solver.cpp:253]     Train net output #0: loss = 2.31905 (* 1 = 2.31905 loss)
I0525 04:50:34.817847 22762 sgd_solver.cpp:106] Iteration 166, lr = 0.001
I0525 04:50:43.666120 22762 solver.cpp:237] Iteration 332, loss = 2.28089
I0525 04:50:43.666157 22762 solver.cpp:253]     Train net output #0: loss = 2.28089 (* 1 = 2.28089 loss)
I0525 04:50:43.666180 22762 sgd_solver.cpp:106] Iteration 332, lr = 0.001
I0525 04:50:52.513178 22762 solver.cpp:237] Iteration 498, loss = 2.27395
I0525 04:50:52.513216 22762 solver.cpp:253]     Train net output #0: loss = 2.27395 (* 1 = 2.27395 loss)
I0525 04:50:52.513233 22762 sgd_solver.cpp:106] Iteration 498, lr = 0.001
I0525 04:51:01.368901 22762 solver.cpp:237] Iteration 664, loss = 2.29302
I0525 04:51:01.369072 22762 solver.cpp:253]     Train net output #0: loss = 2.29302 (* 1 = 2.29302 loss)
I0525 04:51:01.369091 22762 sgd_solver.cpp:106] Iteration 664, lr = 0.001
I0525 04:51:10.212774 22762 solver.cpp:237] Iteration 830, loss = 2.0963
I0525 04:51:10.212811 22762 solver.cpp:253]     Train net output #0: loss = 2.0963 (* 1 = 2.0963 loss)
I0525 04:51:10.212831 22762 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0525 04:51:19.056505 22762 solver.cpp:237] Iteration 996, loss = 2.1424
I0525 04:51:19.056563 22762 solver.cpp:253]     Train net output #0: loss = 2.1424 (* 1 = 2.1424 loss)
I0525 04:51:19.056591 22762 sgd_solver.cpp:106] Iteration 996, lr = 0.001
I0525 04:51:50.002005 22762 solver.cpp:237] Iteration 1162, loss = 1.89499
I0525 04:51:50.002184 22762 solver.cpp:253]     Train net output #0: loss = 1.89499 (* 1 = 1.89499 loss)
I0525 04:51:50.002202 22762 sgd_solver.cpp:106] Iteration 1162, lr = 0.001
I0525 04:51:58.849066 22762 solver.cpp:237] Iteration 1328, loss = 1.95902
I0525 04:51:58.849102 22762 solver.cpp:253]     Train net output #0: loss = 1.95902 (* 1 = 1.95902 loss)
I0525 04:51:58.849126 22762 sgd_solver.cpp:106] Iteration 1328, lr = 0.001
I0525 04:52:07.701417 22762 solver.cpp:237] Iteration 1494, loss = 1.97473
I0525 04:52:07.701454 22762 solver.cpp:253]     Train net output #0: loss = 1.97473 (* 1 = 1.97473 loss)
I0525 04:52:07.701478 22762 sgd_solver.cpp:106] Iteration 1494, lr = 0.001
I0525 04:52:16.555876 22762 solver.cpp:237] Iteration 1660, loss = 1.91693
I0525 04:52:16.555919 22762 solver.cpp:253]     Train net output #0: loss = 1.91693 (* 1 = 1.91693 loss)
I0525 04:52:16.555938 22762 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0525 04:52:16.822890 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_1666.caffemodel
I0525 04:52:16.901713 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_1666.solverstate
I0525 04:52:25.476410 22762 solver.cpp:237] Iteration 1826, loss = 1.76576
I0525 04:52:25.476572 22762 solver.cpp:253]     Train net output #0: loss = 1.76576 (* 1 = 1.76576 loss)
I0525 04:52:25.476589 22762 sgd_solver.cpp:106] Iteration 1826, lr = 0.001
I0525 04:52:34.328090 22762 solver.cpp:237] Iteration 1992, loss = 1.87844
I0525 04:52:34.328145 22762 solver.cpp:253]     Train net output #0: loss = 1.87844 (* 1 = 1.87844 loss)
I0525 04:52:34.328171 22762 sgd_solver.cpp:106] Iteration 1992, lr = 0.001
I0525 04:52:43.176332 22762 solver.cpp:237] Iteration 2158, loss = 1.77997
I0525 04:52:43.176368 22762 solver.cpp:253]     Train net output #0: loss = 1.77997 (* 1 = 1.77997 loss)
I0525 04:52:43.176393 22762 sgd_solver.cpp:106] Iteration 2158, lr = 0.001
I0525 04:53:14.163395 22762 solver.cpp:237] Iteration 2324, loss = 1.65609
I0525 04:53:14.163559 22762 solver.cpp:253]     Train net output #0: loss = 1.65609 (* 1 = 1.65609 loss)
I0525 04:53:14.163578 22762 sgd_solver.cpp:106] Iteration 2324, lr = 0.001
I0525 04:53:23.011359 22762 solver.cpp:237] Iteration 2490, loss = 2.01301
I0525 04:53:23.011396 22762 solver.cpp:253]     Train net output #0: loss = 2.01301 (* 1 = 2.01301 loss)
I0525 04:53:23.011415 22762 sgd_solver.cpp:106] Iteration 2490, lr = 0.001
I0525 04:53:31.872268 22762 solver.cpp:237] Iteration 2656, loss = 1.70813
I0525 04:53:31.872310 22762 solver.cpp:253]     Train net output #0: loss = 1.70813 (* 1 = 1.70813 loss)
I0525 04:53:31.872328 22762 sgd_solver.cpp:106] Iteration 2656, lr = 0.001
I0525 04:53:40.737233 22762 solver.cpp:237] Iteration 2822, loss = 1.6439
I0525 04:53:40.737269 22762 solver.cpp:253]     Train net output #0: loss = 1.6439 (* 1 = 1.6439 loss)
I0525 04:53:40.737293 22762 sgd_solver.cpp:106] Iteration 2822, lr = 0.001
I0525 04:53:49.598578 22762 solver.cpp:237] Iteration 2988, loss = 1.92747
I0525 04:53:49.598747 22762 solver.cpp:253]     Train net output #0: loss = 1.92747 (* 1 = 1.92747 loss)
I0525 04:53:49.598765 22762 sgd_solver.cpp:106] Iteration 2988, lr = 0.001
I0525 04:53:58.441511 22762 solver.cpp:237] Iteration 3154, loss = 1.59972
I0525 04:53:58.441548 22762 solver.cpp:253]     Train net output #0: loss = 1.59972 (* 1 = 1.59972 loss)
I0525 04:53:58.441570 22762 sgd_solver.cpp:106] Iteration 3154, lr = 0.001
I0525 04:54:07.295389 22762 solver.cpp:237] Iteration 3320, loss = 1.66942
I0525 04:54:07.295425 22762 solver.cpp:253]     Train net output #0: loss = 1.66942 (* 1 = 1.66942 loss)
I0525 04:54:07.295444 22762 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0525 04:54:07.882205 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_3332.caffemodel
I0525 04:54:07.957885 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_3332.solverstate
I0525 04:54:08.000360 22762 solver.cpp:341] Iteration 3333, Testing net (#0)
I0525 04:54:55.223292 22762 solver.cpp:409]     Test net output #0: accuracy = 0.652521
I0525 04:54:55.223460 22762 solver.cpp:409]     Test net output #1: loss = 1.19473 (* 1 = 1.19473 loss)
I0525 04:55:25.479306 22762 solver.cpp:237] Iteration 3486, loss = 1.81587
I0525 04:55:25.479470 22762 solver.cpp:253]     Train net output #0: loss = 1.81587 (* 1 = 1.81587 loss)
I0525 04:55:25.479487 22762 sgd_solver.cpp:106] Iteration 3486, lr = 0.001
I0525 04:55:34.327208 22762 solver.cpp:237] Iteration 3652, loss = 2.00297
I0525 04:55:34.327265 22762 solver.cpp:253]     Train net output #0: loss = 2.00297 (* 1 = 2.00297 loss)
I0525 04:55:34.327289 22762 sgd_solver.cpp:106] Iteration 3652, lr = 0.001
I0525 04:55:43.176363 22762 solver.cpp:237] Iteration 3818, loss = 1.58944
I0525 04:55:43.176400 22762 solver.cpp:253]     Train net output #0: loss = 1.58944 (* 1 = 1.58944 loss)
I0525 04:55:43.176419 22762 sgd_solver.cpp:106] Iteration 3818, lr = 0.001
I0525 04:55:52.021765 22762 solver.cpp:237] Iteration 3984, loss = 1.66901
I0525 04:55:52.021801 22762 solver.cpp:253]     Train net output #0: loss = 1.66901 (* 1 = 1.66901 loss)
I0525 04:55:52.021819 22762 sgd_solver.cpp:106] Iteration 3984, lr = 0.001
I0525 04:56:00.857545 22762 solver.cpp:237] Iteration 4150, loss = 1.66657
I0525 04:56:00.857712 22762 solver.cpp:253]     Train net output #0: loss = 1.66657 (* 1 = 1.66657 loss)
I0525 04:56:00.857735 22762 sgd_solver.cpp:106] Iteration 4150, lr = 0.001
I0525 04:56:09.696861 22762 solver.cpp:237] Iteration 4316, loss = 1.69326
I0525 04:56:09.696897 22762 solver.cpp:253]     Train net output #0: loss = 1.69326 (* 1 = 1.69326 loss)
I0525 04:56:09.696915 22762 sgd_solver.cpp:106] Iteration 4316, lr = 0.001
I0525 04:56:40.748877 22762 solver.cpp:237] Iteration 4482, loss = 1.99102
I0525 04:56:40.749048 22762 solver.cpp:253]     Train net output #0: loss = 1.99102 (* 1 = 1.99102 loss)
I0525 04:56:40.749065 22762 sgd_solver.cpp:106] Iteration 4482, lr = 0.001
I0525 04:56:49.612920 22762 solver.cpp:237] Iteration 4648, loss = 1.62009
I0525 04:56:49.612975 22762 solver.cpp:253]     Train net output #0: loss = 1.62009 (* 1 = 1.62009 loss)
I0525 04:56:49.612993 22762 sgd_solver.cpp:106] Iteration 4648, lr = 0.001
I0525 04:56:58.460254 22762 solver.cpp:237] Iteration 4814, loss = 1.67057
I0525 04:56:58.460295 22762 solver.cpp:253]     Train net output #0: loss = 1.67057 (* 1 = 1.67057 loss)
I0525 04:56:58.460320 22762 sgd_solver.cpp:106] Iteration 4814, lr = 0.001
I0525 04:57:07.309883 22762 solver.cpp:237] Iteration 4980, loss = 1.63723
I0525 04:57:07.309921 22762 solver.cpp:253]     Train net output #0: loss = 1.63723 (* 1 = 1.63723 loss)
I0525 04:57:07.309939 22762 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0525 04:57:08.216421 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_4998.caffemodel
I0525 04:57:08.293627 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_4998.solverstate
I0525 04:57:16.225827 22762 solver.cpp:237] Iteration 5146, loss = 1.70899
I0525 04:57:16.226006 22762 solver.cpp:253]     Train net output #0: loss = 1.70899 (* 1 = 1.70899 loss)
I0525 04:57:16.226022 22762 sgd_solver.cpp:106] Iteration 5146, lr = 0.001
I0525 04:57:25.076913 22762 solver.cpp:237] Iteration 5312, loss = 1.61979
I0525 04:57:25.076949 22762 solver.cpp:253]     Train net output #0: loss = 1.61979 (* 1 = 1.61979 loss)
I0525 04:57:25.076968 22762 sgd_solver.cpp:106] Iteration 5312, lr = 0.001
I0525 04:57:33.929469 22762 solver.cpp:237] Iteration 5478, loss = 1.63315
I0525 04:57:33.929527 22762 solver.cpp:253]     Train net output #0: loss = 1.63315 (* 1 = 1.63315 loss)
I0525 04:57:33.929543 22762 sgd_solver.cpp:106] Iteration 5478, lr = 0.001
I0525 04:58:04.870658 22762 solver.cpp:237] Iteration 5644, loss = 1.58825
I0525 04:58:04.870826 22762 solver.cpp:253]     Train net output #0: loss = 1.58825 (* 1 = 1.58825 loss)
I0525 04:58:04.870843 22762 sgd_solver.cpp:106] Iteration 5644, lr = 0.001
I0525 04:58:13.730114 22762 solver.cpp:237] Iteration 5810, loss = 1.58478
I0525 04:58:13.730154 22762 solver.cpp:253]     Train net output #0: loss = 1.58478 (* 1 = 1.58478 loss)
I0525 04:58:13.730171 22762 sgd_solver.cpp:106] Iteration 5810, lr = 0.001
I0525 04:58:22.580723 22762 solver.cpp:237] Iteration 5976, loss = 1.6444
I0525 04:58:22.580760 22762 solver.cpp:253]     Train net output #0: loss = 1.6444 (* 1 = 1.6444 loss)
I0525 04:58:22.580777 22762 sgd_solver.cpp:106] Iteration 5976, lr = 0.001
I0525 04:58:31.436141 22762 solver.cpp:237] Iteration 6142, loss = 1.54925
I0525 04:58:31.436185 22762 solver.cpp:253]     Train net output #0: loss = 1.54925 (* 1 = 1.54925 loss)
I0525 04:58:31.436203 22762 sgd_solver.cpp:106] Iteration 6142, lr = 0.001
I0525 04:58:40.291153 22762 solver.cpp:237] Iteration 6308, loss = 1.76876
I0525 04:58:40.291297 22762 solver.cpp:253]     Train net output #0: loss = 1.76876 (* 1 = 1.76876 loss)
I0525 04:58:40.291314 22762 sgd_solver.cpp:106] Iteration 6308, lr = 0.001
I0525 04:58:49.140588 22762 solver.cpp:237] Iteration 6474, loss = 1.58991
I0525 04:58:49.140638 22762 solver.cpp:253]     Train net output #0: loss = 1.58991 (* 1 = 1.58991 loss)
I0525 04:58:49.140657 22762 sgd_solver.cpp:106] Iteration 6474, lr = 0.001
I0525 04:58:57.992625 22762 solver.cpp:237] Iteration 6640, loss = 1.57291
I0525 04:58:57.992666 22762 solver.cpp:253]     Train net output #0: loss = 1.57291 (* 1 = 1.57291 loss)
I0525 04:58:57.992683 22762 sgd_solver.cpp:106] Iteration 6640, lr = 0.001
I0525 04:58:59.218482 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_6664.caffemodel
I0525 04:58:59.294796 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_6664.solverstate
I0525 04:58:59.392101 22762 solver.cpp:341] Iteration 6666, Testing net (#0)
I0525 05:00:07.428609 22762 solver.cpp:409]     Test net output #0: accuracy = 0.705976
I0525 05:00:07.428784 22762 solver.cpp:409]     Test net output #1: loss = 1.0606 (* 1 = 1.0606 loss)
I0525 05:00:37.036164 22762 solver.cpp:237] Iteration 6806, loss = 1.63012
I0525 05:00:37.036221 22762 solver.cpp:253]     Train net output #0: loss = 1.63012 (* 1 = 1.63012 loss)
I0525 05:00:37.036239 22762 sgd_solver.cpp:106] Iteration 6806, lr = 0.001
I0525 05:00:45.880429 22762 solver.cpp:237] Iteration 6972, loss = 1.40645
I0525 05:00:45.880578 22762 solver.cpp:253]     Train net output #0: loss = 1.40645 (* 1 = 1.40645 loss)
I0525 05:00:45.880594 22762 sgd_solver.cpp:106] Iteration 6972, lr = 0.001
I0525 05:00:54.732355 22762 solver.cpp:237] Iteration 7138, loss = 1.51382
I0525 05:00:54.732409 22762 solver.cpp:253]     Train net output #0: loss = 1.51382 (* 1 = 1.51382 loss)
I0525 05:00:54.732437 22762 sgd_solver.cpp:106] Iteration 7138, lr = 0.001
I0525 05:01:03.574532 22762 solver.cpp:237] Iteration 7304, loss = 1.34621
I0525 05:01:03.574568 22762 solver.cpp:253]     Train net output #0: loss = 1.34621 (* 1 = 1.34621 loss)
I0525 05:01:03.574592 22762 sgd_solver.cpp:106] Iteration 7304, lr = 0.001
I0525 05:01:12.433519 22762 solver.cpp:237] Iteration 7470, loss = 1.5781
I0525 05:01:12.433555 22762 solver.cpp:253]     Train net output #0: loss = 1.5781 (* 1 = 1.5781 loss)
I0525 05:01:12.433574 22762 sgd_solver.cpp:106] Iteration 7470, lr = 0.001
I0525 05:01:21.279781 22762 solver.cpp:237] Iteration 7636, loss = 1.48135
I0525 05:01:21.279947 22762 solver.cpp:253]     Train net output #0: loss = 1.48135 (* 1 = 1.48135 loss)
I0525 05:01:21.279965 22762 sgd_solver.cpp:106] Iteration 7636, lr = 0.001
I0525 05:01:52.252498 22762 solver.cpp:237] Iteration 7802, loss = 1.62912
I0525 05:01:52.252671 22762 solver.cpp:253]     Train net output #0: loss = 1.62912 (* 1 = 1.62912 loss)
I0525 05:01:52.252691 22762 sgd_solver.cpp:106] Iteration 7802, lr = 0.001
I0525 05:02:01.103623 22762 solver.cpp:237] Iteration 7968, loss = 1.64626
I0525 05:02:01.103662 22762 solver.cpp:253]     Train net output #0: loss = 1.64626 (* 1 = 1.64626 loss)
I0525 05:02:01.103680 22762 sgd_solver.cpp:106] Iteration 7968, lr = 0.001
I0525 05:02:09.956161 22762 solver.cpp:237] Iteration 8134, loss = 1.52067
I0525 05:02:09.956218 22762 solver.cpp:253]     Train net output #0: loss = 1.52067 (* 1 = 1.52067 loss)
I0525 05:02:09.956244 22762 sgd_solver.cpp:106] Iteration 8134, lr = 0.001
I0525 05:02:18.804080 22762 solver.cpp:237] Iteration 8300, loss = 1.30684
I0525 05:02:18.804118 22762 solver.cpp:253]     Train net output #0: loss = 1.30684 (* 1 = 1.30684 loss)
I0525 05:02:18.804136 22762 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0525 05:02:20.354838 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_8330.caffemodel
I0525 05:02:20.431166 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_8330.solverstate
I0525 05:02:27.714983 22762 solver.cpp:237] Iteration 8466, loss = 1.66505
I0525 05:02:27.715150 22762 solver.cpp:253]     Train net output #0: loss = 1.66505 (* 1 = 1.66505 loss)
I0525 05:02:27.715168 22762 sgd_solver.cpp:106] Iteration 8466, lr = 0.001
I0525 05:02:36.567231 22762 solver.cpp:237] Iteration 8632, loss = 1.57759
I0525 05:02:36.567287 22762 solver.cpp:253]     Train net output #0: loss = 1.57759 (* 1 = 1.57759 loss)
I0525 05:02:36.567315 22762 sgd_solver.cpp:106] Iteration 8632, lr = 0.001
I0525 05:02:45.426066 22762 solver.cpp:237] Iteration 8798, loss = 1.44879
I0525 05:02:45.426105 22762 solver.cpp:253]     Train net output #0: loss = 1.44879 (* 1 = 1.44879 loss)
I0525 05:02:45.426123 22762 sgd_solver.cpp:106] Iteration 8798, lr = 0.001
I0525 05:03:16.452015 22762 solver.cpp:237] Iteration 8964, loss = 1.58421
I0525 05:03:16.452194 22762 solver.cpp:253]     Train net output #0: loss = 1.58421 (* 1 = 1.58421 loss)
I0525 05:03:16.452213 22762 sgd_solver.cpp:106] Iteration 8964, lr = 0.001
I0525 05:03:25.298231 22762 solver.cpp:237] Iteration 9130, loss = 1.64667
I0525 05:03:25.298290 22762 solver.cpp:253]     Train net output #0: loss = 1.64667 (* 1 = 1.64667 loss)
I0525 05:03:25.298317 22762 sgd_solver.cpp:106] Iteration 9130, lr = 0.001
I0525 05:03:34.152113 22762 solver.cpp:237] Iteration 9296, loss = 1.45976
I0525 05:03:34.152153 22762 solver.cpp:253]     Train net output #0: loss = 1.45976 (* 1 = 1.45976 loss)
I0525 05:03:34.152169 22762 sgd_solver.cpp:106] Iteration 9296, lr = 0.001
I0525 05:03:43.006256 22762 solver.cpp:237] Iteration 9462, loss = 1.54196
I0525 05:03:43.006294 22762 solver.cpp:253]     Train net output #0: loss = 1.54196 (* 1 = 1.54196 loss)
I0525 05:03:43.006311 22762 sgd_solver.cpp:106] Iteration 9462, lr = 0.001
I0525 05:03:51.857998 22762 solver.cpp:237] Iteration 9628, loss = 1.35711
I0525 05:03:51.858168 22762 solver.cpp:253]     Train net output #0: loss = 1.35711 (* 1 = 1.35711 loss)
I0525 05:03:51.858189 22762 sgd_solver.cpp:106] Iteration 9628, lr = 0.001
I0525 05:04:00.710736 22762 solver.cpp:237] Iteration 9794, loss = 1.57827
I0525 05:04:00.710772 22762 solver.cpp:253]     Train net output #0: loss = 1.57827 (* 1 = 1.57827 loss)
I0525 05:04:00.710795 22762 sgd_solver.cpp:106] Iteration 9794, lr = 0.001
I0525 05:04:09.564342 22762 solver.cpp:237] Iteration 9960, loss = 1.42831
I0525 05:04:09.564378 22762 solver.cpp:253]     Train net output #0: loss = 1.42831 (* 1 = 1.42831 loss)
I0525 05:04:09.564396 22762 sgd_solver.cpp:106] Iteration 9960, lr = 0.001
I0525 05:04:11.434715 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_9996.caffemodel
I0525 05:04:11.510948 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_9996.solverstate
I0525 05:04:11.659454 22762 solver.cpp:341] Iteration 9999, Testing net (#0)
I0525 05:04:58.508291 22762 solver.cpp:409]     Test net output #0: accuracy = 0.7608
I0525 05:04:58.508462 22762 solver.cpp:409]     Test net output #1: loss = 0.890694 (* 1 = 0.890694 loss)
I0525 05:05:27.473464 22762 solver.cpp:237] Iteration 10126, loss = 1.36721
I0525 05:05:27.473526 22762 solver.cpp:253]     Train net output #0: loss = 1.36721 (* 1 = 1.36721 loss)
I0525 05:05:27.473551 22762 sgd_solver.cpp:106] Iteration 10126, lr = 0.001
I0525 05:05:36.324712 22762 solver.cpp:237] Iteration 10292, loss = 1.56397
I0525 05:05:36.324883 22762 solver.cpp:253]     Train net output #0: loss = 1.56397 (* 1 = 1.56397 loss)
I0525 05:05:36.324900 22762 sgd_solver.cpp:106] Iteration 10292, lr = 0.001
I0525 05:05:45.186187 22762 solver.cpp:237] Iteration 10458, loss = 1.20654
I0525 05:05:45.186224 22762 solver.cpp:253]     Train net output #0: loss = 1.20654 (* 1 = 1.20654 loss)
I0525 05:05:45.186244 22762 sgd_solver.cpp:106] Iteration 10458, lr = 0.001
I0525 05:05:54.044154 22762 solver.cpp:237] Iteration 10624, loss = 1.49418
I0525 05:05:54.044214 22762 solver.cpp:253]     Train net output #0: loss = 1.49418 (* 1 = 1.49418 loss)
I0525 05:05:54.044242 22762 sgd_solver.cpp:106] Iteration 10624, lr = 0.001
I0525 05:06:02.896611 22762 solver.cpp:237] Iteration 10790, loss = 1.32
I0525 05:06:02.896649 22762 solver.cpp:253]     Train net output #0: loss = 1.32 (* 1 = 1.32 loss)
I0525 05:06:02.896667 22762 sgd_solver.cpp:106] Iteration 10790, lr = 0.001
I0525 05:06:11.744959 22762 solver.cpp:237] Iteration 10956, loss = 1.60758
I0525 05:06:11.745105 22762 solver.cpp:253]     Train net output #0: loss = 1.60758 (* 1 = 1.60758 loss)
I0525 05:06:11.745121 22762 sgd_solver.cpp:106] Iteration 10956, lr = 0.001
I0525 05:06:42.750164 22762 solver.cpp:237] Iteration 11122, loss = 1.52147
I0525 05:06:42.750360 22762 solver.cpp:253]     Train net output #0: loss = 1.52147 (* 1 = 1.52147 loss)
I0525 05:06:42.750376 22762 sgd_solver.cpp:106] Iteration 11122, lr = 0.001
I0525 05:06:51.597234 22762 solver.cpp:237] Iteration 11288, loss = 1.35879
I0525 05:06:51.597287 22762 solver.cpp:253]     Train net output #0: loss = 1.35879 (* 1 = 1.35879 loss)
I0525 05:06:51.597314 22762 sgd_solver.cpp:106] Iteration 11288, lr = 0.001
I0525 05:07:00.457545 22762 solver.cpp:237] Iteration 11454, loss = 1.33657
I0525 05:07:00.457581 22762 solver.cpp:253]     Train net output #0: loss = 1.33657 (* 1 = 1.33657 loss)
I0525 05:07:00.457599 22762 sgd_solver.cpp:106] Iteration 11454, lr = 0.001
I0525 05:07:09.300645 22762 solver.cpp:237] Iteration 11620, loss = 1.36239
I0525 05:07:09.300699 22762 solver.cpp:253]     Train net output #0: loss = 1.36239 (* 1 = 1.36239 loss)
I0525 05:07:09.300719 22762 sgd_solver.cpp:106] Iteration 11620, lr = 0.001
I0525 05:07:11.490031 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_11662.caffemodel
I0525 05:07:11.565917 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_11662.solverstate
I0525 05:07:18.221006 22762 solver.cpp:237] Iteration 11786, loss = 1.47826
I0525 05:07:18.221176 22762 solver.cpp:253]     Train net output #0: loss = 1.47826 (* 1 = 1.47826 loss)
I0525 05:07:18.221194 22762 sgd_solver.cpp:106] Iteration 11786, lr = 0.001
I0525 05:07:27.074584 22762 solver.cpp:237] Iteration 11952, loss = 1.50413
I0525 05:07:27.074621 22762 solver.cpp:253]     Train net output #0: loss = 1.50413 (* 1 = 1.50413 loss)
I0525 05:07:27.074640 22762 sgd_solver.cpp:106] Iteration 11952, lr = 0.001
I0525 05:07:35.925408 22762 solver.cpp:237] Iteration 12118, loss = 1.25842
I0525 05:07:35.925463 22762 solver.cpp:253]     Train net output #0: loss = 1.25842 (* 1 = 1.25842 loss)
I0525 05:07:35.925489 22762 sgd_solver.cpp:106] Iteration 12118, lr = 0.001
I0525 05:08:06.915006 22762 solver.cpp:237] Iteration 12284, loss = 1.38775
I0525 05:08:06.915181 22762 solver.cpp:253]     Train net output #0: loss = 1.38775 (* 1 = 1.38775 loss)
I0525 05:08:06.915199 22762 sgd_solver.cpp:106] Iteration 12284, lr = 0.001
I0525 05:08:15.761690 22762 solver.cpp:237] Iteration 12450, loss = 1.60077
I0525 05:08:15.761728 22762 solver.cpp:253]     Train net output #0: loss = 1.60077 (* 1 = 1.60077 loss)
I0525 05:08:15.761746 22762 sgd_solver.cpp:106] Iteration 12450, lr = 0.001
I0525 05:08:24.608795 22762 solver.cpp:237] Iteration 12616, loss = 1.39152
I0525 05:08:24.608850 22762 solver.cpp:253]     Train net output #0: loss = 1.39152 (* 1 = 1.39152 loss)
I0525 05:08:24.608868 22762 sgd_solver.cpp:106] Iteration 12616, lr = 0.001
I0525 05:08:33.465479 22762 solver.cpp:237] Iteration 12782, loss = 1.55137
I0525 05:08:33.465517 22762 solver.cpp:253]     Train net output #0: loss = 1.55137 (* 1 = 1.55137 loss)
I0525 05:08:33.465535 22762 sgd_solver.cpp:106] Iteration 12782, lr = 0.001
I0525 05:08:42.314523 22762 solver.cpp:237] Iteration 12948, loss = 1.65287
I0525 05:08:42.314671 22762 solver.cpp:253]     Train net output #0: loss = 1.65287 (* 1 = 1.65287 loss)
I0525 05:08:42.314688 22762 sgd_solver.cpp:106] Iteration 12948, lr = 0.001
I0525 05:08:51.163208 22762 solver.cpp:237] Iteration 13114, loss = 1.46737
I0525 05:08:51.163260 22762 solver.cpp:253]     Train net output #0: loss = 1.46737 (* 1 = 1.46737 loss)
I0525 05:08:51.163277 22762 sgd_solver.cpp:106] Iteration 13114, lr = 0.001
I0525 05:09:00.018334 22762 solver.cpp:237] Iteration 13280, loss = 1.36174
I0525 05:09:00.018371 22762 solver.cpp:253]     Train net output #0: loss = 1.36174 (* 1 = 1.36174 loss)
I0525 05:09:00.018395 22762 sgd_solver.cpp:106] Iteration 13280, lr = 0.001
I0525 05:09:02.525450 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_13328.caffemodel
I0525 05:09:02.600015 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_13328.solverstate
I0525 05:09:02.802836 22762 solver.cpp:341] Iteration 13332, Testing net (#0)
I0525 05:10:10.862687 22762 solver.cpp:409]     Test net output #0: accuracy = 0.801457
I0525 05:10:10.862864 22762 solver.cpp:409]     Test net output #1: loss = 0.714475 (* 1 = 0.714475 loss)
I0525 05:10:39.132480 22762 solver.cpp:237] Iteration 13446, loss = 1.62254
I0525 05:10:39.132541 22762 solver.cpp:253]     Train net output #0: loss = 1.62254 (* 1 = 1.62254 loss)
I0525 05:10:39.132560 22762 sgd_solver.cpp:106] Iteration 13446, lr = 0.001
I0525 05:10:47.993237 22762 solver.cpp:237] Iteration 13612, loss = 1.30666
I0525 05:10:47.993392 22762 solver.cpp:253]     Train net output #0: loss = 1.30666 (* 1 = 1.30666 loss)
I0525 05:10:47.993408 22762 sgd_solver.cpp:106] Iteration 13612, lr = 0.001
I0525 05:10:56.859015 22762 solver.cpp:237] Iteration 13778, loss = 1.43218
I0525 05:10:56.859069 22762 solver.cpp:253]     Train net output #0: loss = 1.43218 (* 1 = 1.43218 loss)
I0525 05:10:56.859096 22762 sgd_solver.cpp:106] Iteration 13778, lr = 0.001
I0525 05:11:05.721444 22762 solver.cpp:237] Iteration 13944, loss = 1.46434
I0525 05:11:05.721482 22762 solver.cpp:253]     Train net output #0: loss = 1.46434 (* 1 = 1.46434 loss)
I0525 05:11:05.721505 22762 sgd_solver.cpp:106] Iteration 13944, lr = 0.001
I0525 05:11:14.579167 22762 solver.cpp:237] Iteration 14110, loss = 1.40643
I0525 05:11:14.579205 22762 solver.cpp:253]     Train net output #0: loss = 1.40643 (* 1 = 1.40643 loss)
I0525 05:11:14.579223 22762 sgd_solver.cpp:106] Iteration 14110, lr = 0.001
I0525 05:11:23.445308 22762 solver.cpp:237] Iteration 14276, loss = 1.21483
I0525 05:11:23.445471 22762 solver.cpp:253]     Train net output #0: loss = 1.21483 (* 1 = 1.21483 loss)
I0525 05:11:23.445488 22762 sgd_solver.cpp:106] Iteration 14276, lr = 0.001
I0525 05:11:32.294970 22762 solver.cpp:237] Iteration 14442, loss = 1.52018
I0525 05:11:32.295006 22762 solver.cpp:253]     Train net output #0: loss = 1.52018 (* 1 = 1.52018 loss)
I0525 05:11:32.295025 22762 sgd_solver.cpp:106] Iteration 14442, lr = 0.001
I0525 05:12:03.360208 22762 solver.cpp:237] Iteration 14608, loss = 1.20496
I0525 05:12:03.360391 22762 solver.cpp:253]     Train net output #0: loss = 1.20496 (* 1 = 1.20496 loss)
I0525 05:12:03.360409 22762 sgd_solver.cpp:106] Iteration 14608, lr = 0.001
I0525 05:12:12.225555 22762 solver.cpp:237] Iteration 14774, loss = 1.29589
I0525 05:12:12.225612 22762 solver.cpp:253]     Train net output #0: loss = 1.29589 (* 1 = 1.29589 loss)
I0525 05:12:12.225637 22762 sgd_solver.cpp:106] Iteration 14774, lr = 0.001
I0525 05:12:21.090165 22762 solver.cpp:237] Iteration 14940, loss = 1.19435
I0525 05:12:21.090203 22762 solver.cpp:253]     Train net output #0: loss = 1.19435 (* 1 = 1.19435 loss)
I0525 05:12:21.090221 22762 sgd_solver.cpp:106] Iteration 14940, lr = 0.001
I0525 05:12:23.922518 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_14994.caffemodel
I0525 05:12:23.997408 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_14994.solverstate
I0525 05:12:30.020375 22762 solver.cpp:237] Iteration 15106, loss = 1.52329
I0525 05:12:30.020434 22762 solver.cpp:253]     Train net output #0: loss = 1.52329 (* 1 = 1.52329 loss)
I0525 05:12:30.020459 22762 sgd_solver.cpp:106] Iteration 15106, lr = 0.001
I0525 05:12:38.885431 22762 solver.cpp:237] Iteration 15272, loss = 1.53631
I0525 05:12:38.885602 22762 solver.cpp:253]     Train net output #0: loss = 1.53631 (* 1 = 1.53631 loss)
I0525 05:12:38.885622 22762 sgd_solver.cpp:106] Iteration 15272, lr = 0.001
I0525 05:12:47.731389 22762 solver.cpp:237] Iteration 15438, loss = 1.3925
I0525 05:12:47.731426 22762 solver.cpp:253]     Train net output #0: loss = 1.3925 (* 1 = 1.3925 loss)
I0525 05:12:47.731444 22762 sgd_solver.cpp:106] Iteration 15438, lr = 0.001
I0525 05:13:18.754122 22762 solver.cpp:237] Iteration 15604, loss = 1.30258
I0525 05:13:18.754309 22762 solver.cpp:253]     Train net output #0: loss = 1.30258 (* 1 = 1.30258 loss)
I0525 05:13:18.754328 22762 sgd_solver.cpp:106] Iteration 15604, lr = 0.001
I0525 05:13:27.613736 22762 solver.cpp:237] Iteration 15770, loss = 1.30042
I0525 05:13:27.613787 22762 solver.cpp:253]     Train net output #0: loss = 1.30042 (* 1 = 1.30042 loss)
I0525 05:13:27.613804 22762 sgd_solver.cpp:106] Iteration 15770, lr = 0.001
I0525 05:13:36.472728 22762 solver.cpp:237] Iteration 15936, loss = 1.36831
I0525 05:13:36.472765 22762 solver.cpp:253]     Train net output #0: loss = 1.36831 (* 1 = 1.36831 loss)
I0525 05:13:36.472784 22762 sgd_solver.cpp:106] Iteration 15936, lr = 0.001
I0525 05:13:45.336544 22762 solver.cpp:237] Iteration 16102, loss = 1.2854
I0525 05:13:45.336580 22762 solver.cpp:253]     Train net output #0: loss = 1.2854 (* 1 = 1.2854 loss)
I0525 05:13:45.336604 22762 sgd_solver.cpp:106] Iteration 16102, lr = 0.001
I0525 05:13:54.194366 22762 solver.cpp:237] Iteration 16268, loss = 1.29242
I0525 05:13:54.194540 22762 solver.cpp:253]     Train net output #0: loss = 1.29242 (* 1 = 1.29242 loss)
I0525 05:13:54.194557 22762 sgd_solver.cpp:106] Iteration 16268, lr = 0.001
I0525 05:14:03.048287 22762 solver.cpp:237] Iteration 16434, loss = 1.29737
I0525 05:14:03.048324 22762 solver.cpp:253]     Train net output #0: loss = 1.29737 (* 1 = 1.29737 loss)
I0525 05:14:03.048342 22762 sgd_solver.cpp:106] Iteration 16434, lr = 0.001
I0525 05:14:11.903992 22762 solver.cpp:237] Iteration 16600, loss = 1.33557
I0525 05:14:11.904029 22762 solver.cpp:253]     Train net output #0: loss = 1.33557 (* 1 = 1.33557 loss)
I0525 05:14:11.904047 22762 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0525 05:14:15.049270 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_16660.caffemodel
I0525 05:14:15.126330 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_16660.solverstate
I0525 05:14:15.385010 22762 solver.cpp:341] Iteration 16665, Testing net (#0)
I0525 05:15:02.627881 22762 solver.cpp:409]     Test net output #0: accuracy = 0.813723
I0525 05:15:02.628053 22762 solver.cpp:409]     Test net output #1: loss = 0.630269 (* 1 = 0.630269 loss)
I0525 05:15:28.945057 22762 solver.cpp:237] Iteration 16766, loss = 1.25719
I0525 05:15:28.945117 22762 solver.cpp:253]     Train net output #0: loss = 1.25719 (* 1 = 1.25719 loss)
I0525 05:15:28.945135 22762 sgd_solver.cpp:106] Iteration 16766, lr = 0.001
I0525 05:15:37.785348 22762 solver.cpp:237] Iteration 16932, loss = 1.4982
I0525 05:15:37.785503 22762 solver.cpp:253]     Train net output #0: loss = 1.4982 (* 1 = 1.4982 loss)
I0525 05:15:37.785521 22762 sgd_solver.cpp:106] Iteration 16932, lr = 0.001
I0525 05:15:46.630866 22762 solver.cpp:237] Iteration 17098, loss = 1.23842
I0525 05:15:46.630902 22762 solver.cpp:253]     Train net output #0: loss = 1.23842 (* 1 = 1.23842 loss)
I0525 05:15:46.630920 22762 sgd_solver.cpp:106] Iteration 17098, lr = 0.001
I0525 05:15:55.481266 22762 solver.cpp:237] Iteration 17264, loss = 1.3973
I0525 05:15:55.481326 22762 solver.cpp:253]     Train net output #0: loss = 1.3973 (* 1 = 1.3973 loss)
I0525 05:15:55.481351 22762 sgd_solver.cpp:106] Iteration 17264, lr = 0.001
I0525 05:16:04.327110 22762 solver.cpp:237] Iteration 17430, loss = 1.28231
I0525 05:16:04.327145 22762 solver.cpp:253]     Train net output #0: loss = 1.28231 (* 1 = 1.28231 loss)
I0525 05:16:04.327164 22762 sgd_solver.cpp:106] Iteration 17430, lr = 0.001
I0525 05:16:13.179560 22762 solver.cpp:237] Iteration 17596, loss = 1.39441
I0525 05:16:13.179723 22762 solver.cpp:253]     Train net output #0: loss = 1.39441 (* 1 = 1.39441 loss)
I0525 05:16:13.179739 22762 sgd_solver.cpp:106] Iteration 17596, lr = 0.001
I0525 05:16:22.025892 22762 solver.cpp:237] Iteration 17762, loss = 1.38036
I0525 05:16:22.025951 22762 solver.cpp:253]     Train net output #0: loss = 1.38036 (* 1 = 1.38036 loss)
I0525 05:16:22.025979 22762 sgd_solver.cpp:106] Iteration 17762, lr = 0.001
I0525 05:16:51.759711 22762 solver.cpp:237] Iteration 17928, loss = 1.42375
I0525 05:16:51.759891 22762 solver.cpp:253]     Train net output #0: loss = 1.42375 (* 1 = 1.42375 loss)
I0525 05:16:51.759910 22762 sgd_solver.cpp:106] Iteration 17928, lr = 0.001
I0525 05:17:00.604182 22762 solver.cpp:237] Iteration 18094, loss = 1.40515
I0525 05:17:00.604219 22762 solver.cpp:253]     Train net output #0: loss = 1.40515 (* 1 = 1.40515 loss)
I0525 05:17:00.604238 22762 sgd_solver.cpp:106] Iteration 18094, lr = 0.001
I0525 05:17:09.451941 22762 solver.cpp:237] Iteration 18260, loss = 1.20117
I0525 05:17:09.451997 22762 solver.cpp:253]     Train net output #0: loss = 1.20117 (* 1 = 1.20117 loss)
I0525 05:17:09.452015 22762 sgd_solver.cpp:106] Iteration 18260, lr = 0.001
I0525 05:17:12.919385 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_18326.caffemodel
I0525 05:17:12.994824 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_18326.solverstate
I0525 05:17:18.357908 22762 solver.cpp:237] Iteration 18426, loss = 1.55218
I0525 05:17:18.357964 22762 solver.cpp:253]     Train net output #0: loss = 1.55218 (* 1 = 1.55218 loss)
I0525 05:17:18.357981 22762 sgd_solver.cpp:106] Iteration 18426, lr = 0.001
I0525 05:17:27.201441 22762 solver.cpp:237] Iteration 18592, loss = 1.61071
I0525 05:17:27.201596 22762 solver.cpp:253]     Train net output #0: loss = 1.61071 (* 1 = 1.61071 loss)
I0525 05:17:27.201612 22762 sgd_solver.cpp:106] Iteration 18592, lr = 0.001
I0525 05:17:36.057512 22762 solver.cpp:237] Iteration 18758, loss = 1.40078
I0525 05:17:36.057566 22762 solver.cpp:253]     Train net output #0: loss = 1.40078 (* 1 = 1.40078 loss)
I0525 05:17:36.057585 22762 sgd_solver.cpp:106] Iteration 18758, lr = 0.001
I0525 05:18:05.803352 22762 solver.cpp:237] Iteration 18924, loss = 1.22892
I0525 05:18:05.803530 22762 solver.cpp:253]     Train net output #0: loss = 1.22892 (* 1 = 1.22892 loss)
I0525 05:18:05.803550 22762 sgd_solver.cpp:106] Iteration 18924, lr = 0.001
I0525 05:18:14.643040 22762 solver.cpp:237] Iteration 19090, loss = 1.51027
I0525 05:18:14.643077 22762 solver.cpp:253]     Train net output #0: loss = 1.51027 (* 1 = 1.51027 loss)
I0525 05:18:14.643095 22762 sgd_solver.cpp:106] Iteration 19090, lr = 0.001
I0525 05:18:23.498641 22762 solver.cpp:237] Iteration 19256, loss = 1.2739
I0525 05:18:23.498677 22762 solver.cpp:253]     Train net output #0: loss = 1.2739 (* 1 = 1.2739 loss)
I0525 05:18:23.498694 22762 sgd_solver.cpp:106] Iteration 19256, lr = 0.001
I0525 05:18:32.343713 22762 solver.cpp:237] Iteration 19422, loss = 1.50601
I0525 05:18:32.343767 22762 solver.cpp:253]     Train net output #0: loss = 1.50601 (* 1 = 1.50601 loss)
I0525 05:18:32.343792 22762 sgd_solver.cpp:106] Iteration 19422, lr = 0.001
I0525 05:18:41.189888 22762 solver.cpp:237] Iteration 19588, loss = 1.38912
I0525 05:18:41.190052 22762 solver.cpp:253]     Train net output #0: loss = 1.38912 (* 1 = 1.38912 loss)
I0525 05:18:41.190069 22762 sgd_solver.cpp:106] Iteration 19588, lr = 0.001
I0525 05:18:50.036532 22762 solver.cpp:237] Iteration 19754, loss = 1.4401
I0525 05:18:50.036593 22762 solver.cpp:253]     Train net output #0: loss = 1.4401 (* 1 = 1.4401 loss)
I0525 05:18:50.036612 22762 sgd_solver.cpp:106] Iteration 19754, lr = 0.001
I0525 05:18:58.883790 22762 solver.cpp:237] Iteration 19920, loss = 1.49837
I0525 05:18:58.883832 22762 solver.cpp:253]     Train net output #0: loss = 1.49837 (* 1 = 1.49837 loss)
I0525 05:18:58.883849 22762 sgd_solver.cpp:106] Iteration 19920, lr = 0.001
I0525 05:19:02.665004 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_19992.caffemodel
I0525 05:19:02.740113 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_19992.solverstate
I0525 05:19:03.050168 22762 solver.cpp:341] Iteration 19998, Testing net (#0)
I0525 05:20:11.170049 22762 solver.cpp:409]     Test net output #0: accuracy = 0.821314
I0525 05:20:11.170236 22762 solver.cpp:409]     Test net output #1: loss = 0.585509 (* 1 = 0.585509 loss)
I0525 05:20:36.729364 22762 solver.cpp:237] Iteration 20086, loss = 1.34301
I0525 05:20:36.729421 22762 solver.cpp:253]     Train net output #0: loss = 1.34301 (* 1 = 1.34301 loss)
I0525 05:20:36.729446 22762 sgd_solver.cpp:106] Iteration 20086, lr = 0.001
I0525 05:20:45.585253 22762 solver.cpp:237] Iteration 20252, loss = 1.28225
I0525 05:20:45.585412 22762 solver.cpp:253]     Train net output #0: loss = 1.28225 (* 1 = 1.28225 loss)
I0525 05:20:45.585428 22762 sgd_solver.cpp:106] Iteration 20252, lr = 0.001
I0525 05:20:54.428633 22762 solver.cpp:237] Iteration 20418, loss = 1.32233
I0525 05:20:54.428686 22762 solver.cpp:253]     Train net output #0: loss = 1.32233 (* 1 = 1.32233 loss)
I0525 05:20:54.428704 22762 sgd_solver.cpp:106] Iteration 20418, lr = 0.001
I0525 05:21:03.274025 22762 solver.cpp:237] Iteration 20584, loss = 1.29849
I0525 05:21:03.274061 22762 solver.cpp:253]     Train net output #0: loss = 1.29849 (* 1 = 1.29849 loss)
I0525 05:21:03.274080 22762 sgd_solver.cpp:106] Iteration 20584, lr = 0.001
I0525 05:21:12.132133 22762 solver.cpp:237] Iteration 20750, loss = 1.38572
I0525 05:21:12.132170 22762 solver.cpp:253]     Train net output #0: loss = 1.38572 (* 1 = 1.38572 loss)
I0525 05:21:12.132187 22762 sgd_solver.cpp:106] Iteration 20750, lr = 0.001
I0525 05:21:20.970705 22762 solver.cpp:237] Iteration 20916, loss = 1.22743
I0525 05:21:20.970878 22762 solver.cpp:253]     Train net output #0: loss = 1.22743 (* 1 = 1.22743 loss)
I0525 05:21:20.970896 22762 sgd_solver.cpp:106] Iteration 20916, lr = 0.001
I0525 05:21:29.819356 22762 solver.cpp:237] Iteration 21082, loss = 1.29171
I0525 05:21:29.819393 22762 solver.cpp:253]     Train net output #0: loss = 1.29171 (* 1 = 1.29171 loss)
I0525 05:21:29.819411 22762 sgd_solver.cpp:106] Iteration 21082, lr = 0.001
I0525 05:21:59.594449 22762 solver.cpp:237] Iteration 21248, loss = 1.5353
I0525 05:21:59.594630 22762 solver.cpp:253]     Train net output #0: loss = 1.5353 (* 1 = 1.5353 loss)
I0525 05:21:59.594648 22762 sgd_solver.cpp:106] Iteration 21248, lr = 0.001
I0525 05:22:08.442181 22762 solver.cpp:237] Iteration 21414, loss = 1.38044
I0525 05:22:08.442219 22762 solver.cpp:253]     Train net output #0: loss = 1.38044 (* 1 = 1.38044 loss)
I0525 05:22:08.442237 22762 sgd_solver.cpp:106] Iteration 21414, lr = 0.001
I0525 05:22:17.291018 22762 solver.cpp:237] Iteration 21580, loss = 1.41667
I0525 05:22:17.291069 22762 solver.cpp:253]     Train net output #0: loss = 1.41667 (* 1 = 1.41667 loss)
I0525 05:22:17.291096 22762 sgd_solver.cpp:106] Iteration 21580, lr = 0.001
I0525 05:22:21.400969 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_21658.caffemodel
I0525 05:22:21.476452 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_21658.solverstate
I0525 05:22:26.210685 22762 solver.cpp:237] Iteration 21746, loss = 1.34675
I0525 05:22:26.210741 22762 solver.cpp:253]     Train net output #0: loss = 1.34675 (* 1 = 1.34675 loss)
I0525 05:22:26.210767 22762 sgd_solver.cpp:106] Iteration 21746, lr = 0.001
I0525 05:22:35.060734 22762 solver.cpp:237] Iteration 21912, loss = 1.31626
I0525 05:22:35.060920 22762 solver.cpp:253]     Train net output #0: loss = 1.31626 (* 1 = 1.31626 loss)
I0525 05:22:35.060937 22762 sgd_solver.cpp:106] Iteration 21912, lr = 0.001
I0525 05:22:43.916018 22762 solver.cpp:237] Iteration 22078, loss = 1.14668
I0525 05:22:43.916055 22762 solver.cpp:253]     Train net output #0: loss = 1.14668 (* 1 = 1.14668 loss)
I0525 05:22:43.916074 22762 sgd_solver.cpp:106] Iteration 22078, lr = 0.001
I0525 05:23:13.620600 22762 solver.cpp:237] Iteration 22244, loss = 1.25952
I0525 05:23:13.620781 22762 solver.cpp:253]     Train net output #0: loss = 1.25952 (* 1 = 1.25952 loss)
I0525 05:23:13.620798 22762 sgd_solver.cpp:106] Iteration 22244, lr = 0.001
I0525 05:23:22.464917 22762 solver.cpp:237] Iteration 22410, loss = 1.46625
I0525 05:23:22.464954 22762 solver.cpp:253]     Train net output #0: loss = 1.46625 (* 1 = 1.46625 loss)
I0525 05:23:22.464972 22762 sgd_solver.cpp:106] Iteration 22410, lr = 0.001
I0525 05:23:31.313465 22762 solver.cpp:237] Iteration 22576, loss = 1.2371
I0525 05:23:31.313519 22762 solver.cpp:253]     Train net output #0: loss = 1.2371 (* 1 = 1.2371 loss)
I0525 05:23:31.313547 22762 sgd_solver.cpp:106] Iteration 22576, lr = 0.001
I0525 05:23:40.163652 22762 solver.cpp:237] Iteration 22742, loss = 1.36316
I0525 05:23:40.163689 22762 solver.cpp:253]     Train net output #0: loss = 1.36316 (* 1 = 1.36316 loss)
I0525 05:23:40.163707 22762 sgd_solver.cpp:106] Iteration 22742, lr = 0.001
I0525 05:23:49.008255 22762 solver.cpp:237] Iteration 22908, loss = 1.20611
I0525 05:23:49.008437 22762 solver.cpp:253]     Train net output #0: loss = 1.20611 (* 1 = 1.20611 loss)
I0525 05:23:49.008455 22762 sgd_solver.cpp:106] Iteration 22908, lr = 0.001
I0525 05:23:57.859814 22762 solver.cpp:237] Iteration 23074, loss = 1.49467
I0525 05:23:57.859853 22762 solver.cpp:253]     Train net output #0: loss = 1.49467 (* 1 = 1.49467 loss)
I0525 05:23:57.859869 22762 sgd_solver.cpp:106] Iteration 23074, lr = 0.001
I0525 05:24:06.713040 22762 solver.cpp:237] Iteration 23240, loss = 1.27678
I0525 05:24:06.713078 22762 solver.cpp:253]     Train net output #0: loss = 1.27678 (* 1 = 1.27678 loss)
I0525 05:24:06.713095 22762 sgd_solver.cpp:106] Iteration 23240, lr = 0.001
I0525 05:24:11.142662 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_23324.caffemodel
I0525 05:24:11.217497 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_23324.solverstate
I0525 05:24:11.580911 22762 solver.cpp:341] Iteration 23331, Testing net (#0)
I0525 05:24:58.437599 22762 solver.cpp:409]     Test net output #0: accuracy = 0.827997
I0525 05:24:58.437773 22762 solver.cpp:409]     Test net output #1: loss = 0.584302 (* 1 = 0.584302 loss)
I0525 05:25:23.302043 22762 solver.cpp:237] Iteration 23406, loss = 1.1802
I0525 05:25:23.302099 22762 solver.cpp:253]     Train net output #0: loss = 1.1802 (* 1 = 1.1802 loss)
I0525 05:25:23.302124 22762 sgd_solver.cpp:106] Iteration 23406, lr = 0.001
I0525 05:25:32.149199 22762 solver.cpp:237] Iteration 23572, loss = 1.50374
I0525 05:25:32.149372 22762 solver.cpp:253]     Train net output #0: loss = 1.50374 (* 1 = 1.50374 loss)
I0525 05:25:32.149390 22762 sgd_solver.cpp:106] Iteration 23572, lr = 0.001
I0525 05:25:40.988452 22762 solver.cpp:237] Iteration 23738, loss = 1.46257
I0525 05:25:40.988490 22762 solver.cpp:253]     Train net output #0: loss = 1.46257 (* 1 = 1.46257 loss)
I0525 05:25:40.988509 22762 sgd_solver.cpp:106] Iteration 23738, lr = 0.001
I0525 05:25:49.844506 22762 solver.cpp:237] Iteration 23904, loss = 1.02333
I0525 05:25:49.844542 22762 solver.cpp:253]     Train net output #0: loss = 1.02333 (* 1 = 1.02333 loss)
I0525 05:25:49.844560 22762 sgd_solver.cpp:106] Iteration 23904, lr = 0.001
I0525 05:25:58.693138 22762 solver.cpp:237] Iteration 24070, loss = 1.34817
I0525 05:25:58.693197 22762 solver.cpp:253]     Train net output #0: loss = 1.34817 (* 1 = 1.34817 loss)
I0525 05:25:58.693222 22762 sgd_solver.cpp:106] Iteration 24070, lr = 0.001
I0525 05:26:07.550659 22762 solver.cpp:237] Iteration 24236, loss = 1.52214
I0525 05:26:07.550823 22762 solver.cpp:253]     Train net output #0: loss = 1.52214 (* 1 = 1.52214 loss)
I0525 05:26:07.550840 22762 sgd_solver.cpp:106] Iteration 24236, lr = 0.001
I0525 05:26:16.396684 22762 solver.cpp:237] Iteration 24402, loss = 1.3166
I0525 05:26:16.396721 22762 solver.cpp:253]     Train net output #0: loss = 1.3166 (* 1 = 1.3166 loss)
I0525 05:26:16.396739 22762 sgd_solver.cpp:106] Iteration 24402, lr = 0.001
I0525 05:26:46.114841 22762 solver.cpp:237] Iteration 24568, loss = 1.17122
I0525 05:26:46.115039 22762 solver.cpp:253]     Train net output #0: loss = 1.17122 (* 1 = 1.17122 loss)
I0525 05:26:46.115057 22762 sgd_solver.cpp:106] Iteration 24568, lr = 0.001
I0525 05:26:54.966744 22762 solver.cpp:237] Iteration 24734, loss = 1.43697
I0525 05:26:54.966781 22762 solver.cpp:253]     Train net output #0: loss = 1.43697 (* 1 = 1.43697 loss)
I0525 05:26:54.966800 22762 sgd_solver.cpp:106] Iteration 24734, lr = 0.001
I0525 05:27:03.819638 22762 solver.cpp:237] Iteration 24900, loss = 1.11793
I0525 05:27:03.819674 22762 solver.cpp:253]     Train net output #0: loss = 1.11793 (* 1 = 1.11793 loss)
I0525 05:27:03.819692 22762 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0525 05:27:08.565502 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_24990.caffemodel
I0525 05:27:08.641434 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_24990.solverstate
I0525 05:27:12.742295 22762 solver.cpp:237] Iteration 25066, loss = 1.31614
I0525 05:27:12.742354 22762 solver.cpp:253]     Train net output #0: loss = 1.31614 (* 1 = 1.31614 loss)
I0525 05:27:12.742382 22762 sgd_solver.cpp:106] Iteration 25066, lr = 0.001
I0525 05:27:21.602583 22762 solver.cpp:237] Iteration 25232, loss = 1.24312
I0525 05:27:21.602741 22762 solver.cpp:253]     Train net output #0: loss = 1.24312 (* 1 = 1.24312 loss)
I0525 05:27:21.602757 22762 sgd_solver.cpp:106] Iteration 25232, lr = 0.001
I0525 05:27:30.459414 22762 solver.cpp:237] Iteration 25398, loss = 1.43497
I0525 05:27:30.459451 22762 solver.cpp:253]     Train net output #0: loss = 1.43497 (* 1 = 1.43497 loss)
I0525 05:27:30.459470 22762 sgd_solver.cpp:106] Iteration 25398, lr = 0.001
I0525 05:28:00.175583 22762 solver.cpp:237] Iteration 25564, loss = 1.35573
I0525 05:28:00.175761 22762 solver.cpp:253]     Train net output #0: loss = 1.35573 (* 1 = 1.35573 loss)
I0525 05:28:00.175781 22762 sgd_solver.cpp:106] Iteration 25564, lr = 0.001
I0525 05:28:09.028607 22762 solver.cpp:237] Iteration 25730, loss = 1.16159
I0525 05:28:09.028645 22762 solver.cpp:253]     Train net output #0: loss = 1.16159 (* 1 = 1.16159 loss)
I0525 05:28:09.028662 22762 sgd_solver.cpp:106] Iteration 25730, lr = 0.001
I0525 05:28:17.880609 22762 solver.cpp:237] Iteration 25896, loss = 1.47264
I0525 05:28:17.880646 22762 solver.cpp:253]     Train net output #0: loss = 1.47264 (* 1 = 1.47264 loss)
I0525 05:28:17.880664 22762 sgd_solver.cpp:106] Iteration 25896, lr = 0.001
I0525 05:28:26.738446 22762 solver.cpp:237] Iteration 26062, loss = 1.26015
I0525 05:28:26.738503 22762 solver.cpp:253]     Train net output #0: loss = 1.26015 (* 1 = 1.26015 loss)
I0525 05:28:26.738528 22762 sgd_solver.cpp:106] Iteration 26062, lr = 0.001
I0525 05:28:35.595470 22762 solver.cpp:237] Iteration 26228, loss = 1.38217
I0525 05:28:35.595628 22762 solver.cpp:253]     Train net output #0: loss = 1.38217 (* 1 = 1.38217 loss)
I0525 05:28:35.595644 22762 sgd_solver.cpp:106] Iteration 26228, lr = 0.001
I0525 05:28:44.453338 22762 solver.cpp:237] Iteration 26394, loss = 1.44751
I0525 05:28:44.453375 22762 solver.cpp:253]     Train net output #0: loss = 1.44751 (* 1 = 1.44751 loss)
I0525 05:28:44.453394 22762 sgd_solver.cpp:106] Iteration 26394, lr = 0.001
I0525 05:28:53.306531 22762 solver.cpp:237] Iteration 26560, loss = 1.42192
I0525 05:28:53.306589 22762 solver.cpp:253]     Train net output #0: loss = 1.42192 (* 1 = 1.42192 loss)
I0525 05:28:53.306614 22762 sgd_solver.cpp:106] Iteration 26560, lr = 0.001
I0525 05:28:58.381742 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_26656.caffemodel
I0525 05:28:58.457237 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_26656.solverstate
I0525 05:28:58.872997 22762 solver.cpp:341] Iteration 26664, Testing net (#0)
I0525 05:30:07.010627 22762 solver.cpp:409]     Test net output #0: accuracy = 0.831518
I0525 05:30:07.010818 22762 solver.cpp:409]     Test net output #1: loss = 0.558549 (* 1 = 0.558549 loss)
I0525 05:30:31.227995 22762 solver.cpp:237] Iteration 26726, loss = 1.29481
I0525 05:30:31.228052 22762 solver.cpp:253]     Train net output #0: loss = 1.29481 (* 1 = 1.29481 loss)
I0525 05:30:31.228070 22762 sgd_solver.cpp:106] Iteration 26726, lr = 0.001
I0525 05:30:40.070144 22762 solver.cpp:237] Iteration 26892, loss = 1.22485
I0525 05:30:40.070307 22762 solver.cpp:253]     Train net output #0: loss = 1.22485 (* 1 = 1.22485 loss)
I0525 05:30:40.070323 22762 sgd_solver.cpp:106] Iteration 26892, lr = 0.001
I0525 05:30:48.917390 22762 solver.cpp:237] Iteration 27058, loss = 1.39268
I0525 05:30:48.917433 22762 solver.cpp:253]     Train net output #0: loss = 1.39268 (* 1 = 1.39268 loss)
I0525 05:30:48.917449 22762 sgd_solver.cpp:106] Iteration 27058, lr = 0.001
I0525 05:30:57.761201 22762 solver.cpp:237] Iteration 27224, loss = 1.32585
I0525 05:30:57.761260 22762 solver.cpp:253]     Train net output #0: loss = 1.32585 (* 1 = 1.32585 loss)
I0525 05:30:57.761286 22762 sgd_solver.cpp:106] Iteration 27224, lr = 0.001
I0525 05:31:06.611553 22762 solver.cpp:237] Iteration 27390, loss = 1.19575
I0525 05:31:06.611589 22762 solver.cpp:253]     Train net output #0: loss = 1.19575 (* 1 = 1.19575 loss)
I0525 05:31:06.611608 22762 sgd_solver.cpp:106] Iteration 27390, lr = 0.001
I0525 05:31:15.458001 22762 solver.cpp:237] Iteration 27556, loss = 1.29946
I0525 05:31:15.458160 22762 solver.cpp:253]     Train net output #0: loss = 1.29946 (* 1 = 1.29946 loss)
I0525 05:31:15.458178 22762 sgd_solver.cpp:106] Iteration 27556, lr = 0.001
I0525 05:31:24.306324 22762 solver.cpp:237] Iteration 27722, loss = 1.28437
I0525 05:31:24.306378 22762 solver.cpp:253]     Train net output #0: loss = 1.28437 (* 1 = 1.28437 loss)
I0525 05:31:24.306403 22762 sgd_solver.cpp:106] Iteration 27722, lr = 0.001
I0525 05:31:54.014436 22762 solver.cpp:237] Iteration 27888, loss = 1.23532
I0525 05:31:54.014616 22762 solver.cpp:253]     Train net output #0: loss = 1.23532 (* 1 = 1.23532 loss)
I0525 05:31:54.014632 22762 sgd_solver.cpp:106] Iteration 27888, lr = 0.001
I0525 05:32:02.861724 22762 solver.cpp:237] Iteration 28054, loss = 1.23468
I0525 05:32:02.861763 22762 solver.cpp:253]     Train net output #0: loss = 1.23468 (* 1 = 1.23468 loss)
I0525 05:32:02.861780 22762 sgd_solver.cpp:106] Iteration 28054, lr = 0.001
I0525 05:32:11.707909 22762 solver.cpp:237] Iteration 28220, loss = 1.25779
I0525 05:32:11.707962 22762 solver.cpp:253]     Train net output #0: loss = 1.25779 (* 1 = 1.25779 loss)
I0525 05:32:11.707989 22762 sgd_solver.cpp:106] Iteration 28220, lr = 0.001
I0525 05:32:17.086617 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_28322.caffemodel
I0525 05:32:17.166229 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_28322.solverstate
I0525 05:32:20.617687 22762 solver.cpp:237] Iteration 28386, loss = 1.27978
I0525 05:32:20.617743 22762 solver.cpp:253]     Train net output #0: loss = 1.27978 (* 1 = 1.27978 loss)
I0525 05:32:20.617768 22762 sgd_solver.cpp:106] Iteration 28386, lr = 0.001
I0525 05:32:29.463748 22762 solver.cpp:237] Iteration 28552, loss = 1.42898
I0525 05:32:29.463918 22762 solver.cpp:253]     Train net output #0: loss = 1.42898 (* 1 = 1.42898 loss)
I0525 05:32:29.463934 22762 sgd_solver.cpp:106] Iteration 28552, lr = 0.001
I0525 05:32:38.300573 22762 solver.cpp:237] Iteration 28718, loss = 1.40479
I0525 05:32:38.300631 22762 solver.cpp:253]     Train net output #0: loss = 1.40479 (* 1 = 1.40479 loss)
I0525 05:32:38.300655 22762 sgd_solver.cpp:106] Iteration 28718, lr = 0.001
I0525 05:32:47.154337 22762 solver.cpp:237] Iteration 28884, loss = 1.12031
I0525 05:32:47.154376 22762 solver.cpp:253]     Train net output #0: loss = 1.12031 (* 1 = 1.12031 loss)
I0525 05:32:47.154393 22762 sgd_solver.cpp:106] Iteration 28884, lr = 0.001
I0525 05:33:16.897270 22762 solver.cpp:237] Iteration 29050, loss = 1.32564
I0525 05:33:16.897455 22762 solver.cpp:253]     Train net output #0: loss = 1.32564 (* 1 = 1.32564 loss)
I0525 05:33:16.897472 22762 sgd_solver.cpp:106] Iteration 29050, lr = 0.001
I0525 05:33:25.743069 22762 solver.cpp:237] Iteration 29216, loss = 1.24107
I0525 05:33:25.743122 22762 solver.cpp:253]     Train net output #0: loss = 1.24107 (* 1 = 1.24107 loss)
I0525 05:33:25.743144 22762 sgd_solver.cpp:106] Iteration 29216, lr = 0.001
I0525 05:33:34.576540 22762 solver.cpp:237] Iteration 29382, loss = 1.3636
I0525 05:33:34.576577 22762 solver.cpp:253]     Train net output #0: loss = 1.3636 (* 1 = 1.3636 loss)
I0525 05:33:34.576596 22762 sgd_solver.cpp:106] Iteration 29382, lr = 0.001
I0525 05:33:43.429790 22762 solver.cpp:237] Iteration 29548, loss = 1.4354
I0525 05:33:43.429826 22762 solver.cpp:253]     Train net output #0: loss = 1.4354 (* 1 = 1.4354 loss)
I0525 05:33:43.429844 22762 sgd_solver.cpp:106] Iteration 29548, lr = 0.001
I0525 05:33:52.269757 22762 solver.cpp:237] Iteration 29714, loss = 1.17636
I0525 05:33:52.269943 22762 solver.cpp:253]     Train net output #0: loss = 1.17636 (* 1 = 1.17636 loss)
I0525 05:33:52.269961 22762 sgd_solver.cpp:106] Iteration 29714, lr = 0.001
I0525 05:34:01.125198 22762 solver.cpp:237] Iteration 29880, loss = 1.13303
I0525 05:34:01.125236 22762 solver.cpp:253]     Train net output #0: loss = 1.13303 (* 1 = 1.13303 loss)
I0525 05:34:01.125253 22762 sgd_solver.cpp:106] Iteration 29880, lr = 0.001
I0525 05:34:06.825381 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_29988.caffemodel
I0525 05:34:06.900643 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_29988.solverstate
I0525 05:34:07.370803 22762 solver.cpp:341] Iteration 29997, Testing net (#0)
I0525 05:34:54.639441 22762 solver.cpp:409]     Test net output #0: accuracy = 0.841517
I0525 05:34:54.639619 22762 solver.cpp:409]     Test net output #1: loss = 0.520145 (* 1 = 0.520145 loss)
I0525 05:35:18.130362 22762 solver.cpp:237] Iteration 30046, loss = 1.44967
I0525 05:35:18.130419 22762 solver.cpp:253]     Train net output #0: loss = 1.44967 (* 1 = 1.44967 loss)
I0525 05:35:18.130442 22762 sgd_solver.cpp:106] Iteration 30046, lr = 0.001
I0525 05:35:26.975601 22762 solver.cpp:237] Iteration 30212, loss = 1.29868
I0525 05:35:26.975772 22762 solver.cpp:253]     Train net output #0: loss = 1.29868 (* 1 = 1.29868 loss)
I0525 05:35:26.975790 22762 sgd_solver.cpp:106] Iteration 30212, lr = 0.001
I0525 05:35:35.828172 22762 solver.cpp:237] Iteration 30378, loss = 1.39423
I0525 05:35:35.828225 22762 solver.cpp:253]     Train net output #0: loss = 1.39423 (* 1 = 1.39423 loss)
I0525 05:35:35.828245 22762 sgd_solver.cpp:106] Iteration 30378, lr = 0.001
I0525 05:35:44.678426 22762 solver.cpp:237] Iteration 30544, loss = 1.28697
I0525 05:35:44.678463 22762 solver.cpp:253]     Train net output #0: loss = 1.28697 (* 1 = 1.28697 loss)
I0525 05:35:44.678480 22762 sgd_solver.cpp:106] Iteration 30544, lr = 0.001
I0525 05:35:53.525571 22762 solver.cpp:237] Iteration 30710, loss = 1.35254
I0525 05:35:53.525614 22762 solver.cpp:253]     Train net output #0: loss = 1.35254 (* 1 = 1.35254 loss)
I0525 05:35:53.525629 22762 sgd_solver.cpp:106] Iteration 30710, lr = 0.001
I0525 05:36:02.360029 22762 solver.cpp:237] Iteration 30876, loss = 1.2402
I0525 05:36:02.360218 22762 solver.cpp:253]     Train net output #0: loss = 1.2402 (* 1 = 1.2402 loss)
I0525 05:36:02.360234 22762 sgd_solver.cpp:106] Iteration 30876, lr = 0.001
I0525 05:36:11.208153 22762 solver.cpp:237] Iteration 31042, loss = 1.37911
I0525 05:36:11.208190 22762 solver.cpp:253]     Train net output #0: loss = 1.37911 (* 1 = 1.37911 loss)
I0525 05:36:11.208209 22762 sgd_solver.cpp:106] Iteration 31042, lr = 0.001
I0525 05:36:40.940642 22762 solver.cpp:237] Iteration 31208, loss = 1.15026
I0525 05:36:40.940824 22762 solver.cpp:253]     Train net output #0: loss = 1.15026 (* 1 = 1.15026 loss)
I0525 05:36:40.940841 22762 sgd_solver.cpp:106] Iteration 31208, lr = 0.001
I0525 05:36:49.786057 22762 solver.cpp:237] Iteration 31374, loss = 1.28152
I0525 05:36:49.786113 22762 solver.cpp:253]     Train net output #0: loss = 1.28152 (* 1 = 1.28152 loss)
I0525 05:36:49.786133 22762 sgd_solver.cpp:106] Iteration 31374, lr = 0.001
I0525 05:36:58.624892 22762 solver.cpp:237] Iteration 31540, loss = 1.33321
I0525 05:36:58.624929 22762 solver.cpp:253]     Train net output #0: loss = 1.33321 (* 1 = 1.33321 loss)
I0525 05:36:58.624948 22762 sgd_solver.cpp:106] Iteration 31540, lr = 0.001
I0525 05:37:04.640359 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_31654.caffemodel
I0525 05:37:04.719298 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_31654.solverstate
I0525 05:37:07.535553 22762 solver.cpp:237] Iteration 31706, loss = 1.20968
I0525 05:37:07.535610 22762 solver.cpp:253]     Train net output #0: loss = 1.20968 (* 1 = 1.20968 loss)
I0525 05:37:07.535634 22762 sgd_solver.cpp:106] Iteration 31706, lr = 0.001
I0525 05:37:16.382069 22762 solver.cpp:237] Iteration 31872, loss = 1.32114
I0525 05:37:16.382249 22762 solver.cpp:253]     Train net output #0: loss = 1.32114 (* 1 = 1.32114 loss)
I0525 05:37:16.382267 22762 sgd_solver.cpp:106] Iteration 31872, lr = 0.001
I0525 05:37:25.230015 22762 solver.cpp:237] Iteration 32038, loss = 1.2673
I0525 05:37:25.230051 22762 solver.cpp:253]     Train net output #0: loss = 1.2673 (* 1 = 1.2673 loss)
I0525 05:37:25.230069 22762 sgd_solver.cpp:106] Iteration 32038, lr = 0.001
I0525 05:37:34.079669 22762 solver.cpp:237] Iteration 32204, loss = 1.39286
I0525 05:37:34.079725 22762 solver.cpp:253]     Train net output #0: loss = 1.39286 (* 1 = 1.39286 loss)
I0525 05:37:34.079756 22762 sgd_solver.cpp:106] Iteration 32204, lr = 0.001
I0525 05:38:03.789651 22762 solver.cpp:237] Iteration 32370, loss = 1.43172
I0525 05:38:03.789837 22762 solver.cpp:253]     Train net output #0: loss = 1.43172 (* 1 = 1.43172 loss)
I0525 05:38:03.789855 22762 sgd_solver.cpp:106] Iteration 32370, lr = 0.001
I0525 05:38:12.626920 22762 solver.cpp:237] Iteration 32536, loss = 1.20692
I0525 05:38:12.626957 22762 solver.cpp:253]     Train net output #0: loss = 1.20692 (* 1 = 1.20692 loss)
I0525 05:38:12.626974 22762 sgd_solver.cpp:106] Iteration 32536, lr = 0.001
I0525 05:38:21.471652 22762 solver.cpp:237] Iteration 32702, loss = 1.37666
I0525 05:38:21.471689 22762 solver.cpp:253]     Train net output #0: loss = 1.37666 (* 1 = 1.37666 loss)
I0525 05:38:21.471706 22762 sgd_solver.cpp:106] Iteration 32702, lr = 0.001
I0525 05:38:30.326071 22762 solver.cpp:237] Iteration 32868, loss = 1.24304
I0525 05:38:30.326125 22762 solver.cpp:253]     Train net output #0: loss = 1.24304 (* 1 = 1.24304 loss)
I0525 05:38:30.326153 22762 sgd_solver.cpp:106] Iteration 32868, lr = 0.001
I0525 05:38:39.166008 22762 solver.cpp:237] Iteration 33034, loss = 1.49635
I0525 05:38:39.166180 22762 solver.cpp:253]     Train net output #0: loss = 1.49635 (* 1 = 1.49635 loss)
I0525 05:38:39.166198 22762 sgd_solver.cpp:106] Iteration 33034, lr = 0.001
I0525 05:38:48.013447 22762 solver.cpp:237] Iteration 33200, loss = 1.46756
I0525 05:38:48.013484 22762 solver.cpp:253]     Train net output #0: loss = 1.46756 (* 1 = 1.46756 loss)
I0525 05:38:48.013502 22762 sgd_solver.cpp:106] Iteration 33200, lr = 0.001
I0525 05:38:54.362474 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_33320.caffemodel
I0525 05:38:54.438369 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_33320.solverstate
I0525 05:38:54.962829 22762 solver.cpp:341] Iteration 33330, Testing net (#0)
I0525 05:40:03.039222 22762 solver.cpp:409]     Test net output #0: accuracy = 0.847039
I0525 05:40:03.039404 22762 solver.cpp:409]     Test net output #1: loss = 0.531641 (* 1 = 0.531641 loss)
I0525 05:40:25.874269 22762 solver.cpp:237] Iteration 33366, loss = 1.35825
I0525 05:40:25.874330 22762 solver.cpp:253]     Train net output #0: loss = 1.35825 (* 1 = 1.35825 loss)
I0525 05:40:25.874348 22762 sgd_solver.cpp:106] Iteration 33366, lr = 0.001
I0525 05:40:34.725023 22762 solver.cpp:237] Iteration 33532, loss = 1.33516
I0525 05:40:34.725203 22762 solver.cpp:253]     Train net output #0: loss = 1.33516 (* 1 = 1.33516 loss)
I0525 05:40:34.725219 22762 sgd_solver.cpp:106] Iteration 33532, lr = 0.001
I0525 05:40:43.576848 22762 solver.cpp:237] Iteration 33698, loss = 1.39586
I0525 05:40:43.576884 22762 solver.cpp:253]     Train net output #0: loss = 1.39586 (* 1 = 1.39586 loss)
I0525 05:40:43.576902 22762 sgd_solver.cpp:106] Iteration 33698, lr = 0.001
I0525 05:40:52.422116 22762 solver.cpp:237] Iteration 33864, loss = 1.45221
I0525 05:40:52.422152 22762 solver.cpp:253]     Train net output #0: loss = 1.45221 (* 1 = 1.45221 loss)
I0525 05:40:52.422170 22762 sgd_solver.cpp:106] Iteration 33864, lr = 0.001
I0525 05:41:01.267135 22762 solver.cpp:237] Iteration 34030, loss = 1.30209
I0525 05:41:01.267190 22762 solver.cpp:253]     Train net output #0: loss = 1.30209 (* 1 = 1.30209 loss)
I0525 05:41:01.267215 22762 sgd_solver.cpp:106] Iteration 34030, lr = 0.001
I0525 05:41:10.106046 22762 solver.cpp:237] Iteration 34196, loss = 1.27235
I0525 05:41:10.106207 22762 solver.cpp:253]     Train net output #0: loss = 1.27235 (* 1 = 1.27235 loss)
I0525 05:41:10.106223 22762 sgd_solver.cpp:106] Iteration 34196, lr = 0.001
I0525 05:41:18.948884 22762 solver.cpp:237] Iteration 34362, loss = 1.23021
I0525 05:41:18.948938 22762 solver.cpp:253]     Train net output #0: loss = 1.23021 (* 1 = 1.23021 loss)
I0525 05:41:18.948958 22762 sgd_solver.cpp:106] Iteration 34362, lr = 0.001
I0525 05:41:48.619318 22762 solver.cpp:237] Iteration 34528, loss = 1.29407
I0525 05:41:48.619503 22762 solver.cpp:253]     Train net output #0: loss = 1.29407 (* 1 = 1.29407 loss)
I0525 05:41:48.619524 22762 sgd_solver.cpp:106] Iteration 34528, lr = 0.001
I0525 05:41:57.474762 22762 solver.cpp:237] Iteration 34694, loss = 1.05707
I0525 05:41:57.474799 22762 solver.cpp:253]     Train net output #0: loss = 1.05707 (* 1 = 1.05707 loss)
I0525 05:41:57.474817 22762 sgd_solver.cpp:106] Iteration 34694, lr = 0.001
I0525 05:42:06.325260 22762 solver.cpp:237] Iteration 34860, loss = 1.55595
I0525 05:42:06.325297 22762 solver.cpp:253]     Train net output #0: loss = 1.55595 (* 1 = 1.55595 loss)
I0525 05:42:06.325315 22762 sgd_solver.cpp:106] Iteration 34860, lr = 0.001
I0525 05:42:12.990223 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_34986.caffemodel
I0525 05:42:13.064889 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_34986.solverstate
I0525 05:42:15.241257 22762 solver.cpp:237] Iteration 35026, loss = 1.25931
I0525 05:42:15.241312 22762 solver.cpp:253]     Train net output #0: loss = 1.25931 (* 1 = 1.25931 loss)
I0525 05:42:15.241340 22762 sgd_solver.cpp:106] Iteration 35026, lr = 0.001
I0525 05:42:24.094987 22762 solver.cpp:237] Iteration 35192, loss = 1.29732
I0525 05:42:24.095165 22762 solver.cpp:253]     Train net output #0: loss = 1.29732 (* 1 = 1.29732 loss)
I0525 05:42:24.095183 22762 sgd_solver.cpp:106] Iteration 35192, lr = 0.001
I0525 05:42:32.946583 22762 solver.cpp:237] Iteration 35358, loss = 1.21927
I0525 05:42:32.946620 22762 solver.cpp:253]     Train net output #0: loss = 1.21927 (* 1 = 1.21927 loss)
I0525 05:42:32.946638 22762 sgd_solver.cpp:106] Iteration 35358, lr = 0.001
I0525 05:42:41.793678 22762 solver.cpp:237] Iteration 35524, loss = 1.3445
I0525 05:42:41.793722 22762 solver.cpp:253]     Train net output #0: loss = 1.3445 (* 1 = 1.3445 loss)
I0525 05:42:41.793751 22762 sgd_solver.cpp:106] Iteration 35524, lr = 0.001
I0525 05:43:11.464679 22762 solver.cpp:237] Iteration 35690, loss = 1.19495
I0525 05:43:11.464867 22762 solver.cpp:253]     Train net output #0: loss = 1.19495 (* 1 = 1.19495 loss)
I0525 05:43:11.464885 22762 sgd_solver.cpp:106] Iteration 35690, lr = 0.001
I0525 05:43:20.310694 22762 solver.cpp:237] Iteration 35856, loss = 1.25996
I0525 05:43:20.310731 22762 solver.cpp:253]     Train net output #0: loss = 1.25996 (* 1 = 1.25996 loss)
I0525 05:43:20.310748 22762 sgd_solver.cpp:106] Iteration 35856, lr = 0.001
I0525 05:43:29.157696 22762 solver.cpp:237] Iteration 36022, loss = 1.28853
I0525 05:43:29.157757 22762 solver.cpp:253]     Train net output #0: loss = 1.28853 (* 1 = 1.28853 loss)
I0525 05:43:29.157781 22762 sgd_solver.cpp:106] Iteration 36022, lr = 0.001
I0525 05:43:38.001890 22762 solver.cpp:237] Iteration 36188, loss = 1.3018
I0525 05:43:38.001929 22762 solver.cpp:253]     Train net output #0: loss = 1.3018 (* 1 = 1.3018 loss)
I0525 05:43:38.001947 22762 sgd_solver.cpp:106] Iteration 36188, lr = 0.001
I0525 05:43:46.855124 22762 solver.cpp:237] Iteration 36354, loss = 1.32894
I0525 05:43:46.855286 22762 solver.cpp:253]     Train net output #0: loss = 1.32894 (* 1 = 1.32894 loss)
I0525 05:43:46.855304 22762 sgd_solver.cpp:106] Iteration 36354, lr = 0.001
I0525 05:43:55.705772 22762 solver.cpp:237] Iteration 36520, loss = 1.1127
I0525 05:43:55.705827 22762 solver.cpp:253]     Train net output #0: loss = 1.1127 (* 1 = 1.1127 loss)
I0525 05:43:55.705853 22762 sgd_solver.cpp:106] Iteration 36520, lr = 0.001
I0525 05:44:02.686416 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_36652.caffemodel
I0525 05:44:02.761467 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_36652.solverstate
I0525 05:44:03.338461 22762 solver.cpp:341] Iteration 36663, Testing net (#0)
I0525 05:44:50.236258 22762 solver.cpp:409]     Test net output #0: accuracy = 0.84952
I0525 05:44:50.236445 22762 solver.cpp:409]     Test net output #1: loss = 0.492255 (* 1 = 0.492255 loss)
I0525 05:45:12.320693 22762 solver.cpp:237] Iteration 36686, loss = 1.55341
I0525 05:45:12.320752 22762 solver.cpp:253]     Train net output #0: loss = 1.55341 (* 1 = 1.55341 loss)
I0525 05:45:12.320770 22762 sgd_solver.cpp:106] Iteration 36686, lr = 0.001
I0525 05:45:21.181229 22762 solver.cpp:237] Iteration 36852, loss = 1.47553
I0525 05:45:21.181406 22762 solver.cpp:253]     Train net output #0: loss = 1.47553 (* 1 = 1.47553 loss)
I0525 05:45:21.181423 22762 sgd_solver.cpp:106] Iteration 36852, lr = 0.001
I0525 05:45:30.033910 22762 solver.cpp:237] Iteration 37018, loss = 1.16801
I0525 05:45:30.033967 22762 solver.cpp:253]     Train net output #0: loss = 1.16801 (* 1 = 1.16801 loss)
I0525 05:45:30.033995 22762 sgd_solver.cpp:106] Iteration 37018, lr = 0.001
I0525 05:45:38.899705 22762 solver.cpp:237] Iteration 37184, loss = 1.02175
I0525 05:45:38.899744 22762 solver.cpp:253]     Train net output #0: loss = 1.02175 (* 1 = 1.02175 loss)
I0525 05:45:38.899761 22762 sgd_solver.cpp:106] Iteration 37184, lr = 0.001
I0525 05:45:47.754604 22762 solver.cpp:237] Iteration 37350, loss = 1.40212
I0525 05:45:47.754640 22762 solver.cpp:253]     Train net output #0: loss = 1.40212 (* 1 = 1.40212 loss)
I0525 05:45:47.754659 22762 sgd_solver.cpp:106] Iteration 37350, lr = 0.001
I0525 05:45:56.613468 22762 solver.cpp:237] Iteration 37516, loss = 1.28786
I0525 05:45:56.613658 22762 solver.cpp:253]     Train net output #0: loss = 1.28786 (* 1 = 1.28786 loss)
I0525 05:45:56.613675 22762 sgd_solver.cpp:106] Iteration 37516, lr = 0.001
I0525 05:46:05.462561 22762 solver.cpp:237] Iteration 37682, loss = 1.18729
I0525 05:46:05.462597 22762 solver.cpp:253]     Train net output #0: loss = 1.18729 (* 1 = 1.18729 loss)
I0525 05:46:05.462616 22762 sgd_solver.cpp:106] Iteration 37682, lr = 0.001
I0525 05:46:35.209671 22762 solver.cpp:237] Iteration 37848, loss = 1.12376
I0525 05:46:35.209856 22762 solver.cpp:253]     Train net output #0: loss = 1.12376 (* 1 = 1.12376 loss)
I0525 05:46:35.209873 22762 sgd_solver.cpp:106] Iteration 37848, lr = 0.001
I0525 05:46:44.075201 22762 solver.cpp:237] Iteration 38014, loss = 1.30501
I0525 05:46:44.075258 22762 solver.cpp:253]     Train net output #0: loss = 1.30501 (* 1 = 1.30501 loss)
I0525 05:46:44.075284 22762 sgd_solver.cpp:106] Iteration 38014, lr = 0.001
I0525 05:46:52.932437 22762 solver.cpp:237] Iteration 38180, loss = 1.23261
I0525 05:46:52.932473 22762 solver.cpp:253]     Train net output #0: loss = 1.23261 (* 1 = 1.23261 loss)
I0525 05:46:52.932492 22762 sgd_solver.cpp:106] Iteration 38180, lr = 0.001
I0525 05:47:00.245437 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_38318.caffemodel
I0525 05:47:00.321354 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_38318.solverstate
I0525 05:47:01.854858 22762 solver.cpp:237] Iteration 38346, loss = 1.2198
I0525 05:47:01.854913 22762 solver.cpp:253]     Train net output #0: loss = 1.2198 (* 1 = 1.2198 loss)
I0525 05:47:01.854940 22762 sgd_solver.cpp:106] Iteration 38346, lr = 0.001
I0525 05:47:10.720319 22762 solver.cpp:237] Iteration 38512, loss = 1.27587
I0525 05:47:10.720505 22762 solver.cpp:253]     Train net output #0: loss = 1.27587 (* 1 = 1.27587 loss)
I0525 05:47:10.720522 22762 sgd_solver.cpp:106] Iteration 38512, lr = 0.001
I0525 05:47:19.580888 22762 solver.cpp:237] Iteration 38678, loss = 1.23199
I0525 05:47:19.580924 22762 solver.cpp:253]     Train net output #0: loss = 1.23199 (* 1 = 1.23199 loss)
I0525 05:47:19.580941 22762 sgd_solver.cpp:106] Iteration 38678, lr = 0.001
I0525 05:47:28.440354 22762 solver.cpp:237] Iteration 38844, loss = 1.21504
I0525 05:47:28.440390 22762 solver.cpp:253]     Train net output #0: loss = 1.21504 (* 1 = 1.21504 loss)
I0525 05:47:28.440408 22762 sgd_solver.cpp:106] Iteration 38844, lr = 0.001
I0525 05:47:58.189141 22762 solver.cpp:237] Iteration 39010, loss = 1.14833
I0525 05:47:58.189342 22762 solver.cpp:253]     Train net output #0: loss = 1.14833 (* 1 = 1.14833 loss)
I0525 05:47:58.189360 22762 sgd_solver.cpp:106] Iteration 39010, lr = 0.001
I0525 05:48:07.047829 22762 solver.cpp:237] Iteration 39176, loss = 1.24409
I0525 05:48:07.047888 22762 solver.cpp:253]     Train net output #0: loss = 1.24409 (* 1 = 1.24409 loss)
I0525 05:48:07.047912 22762 sgd_solver.cpp:106] Iteration 39176, lr = 0.001
I0525 05:48:15.900625 22762 solver.cpp:237] Iteration 39342, loss = 1.34596
I0525 05:48:15.900662 22762 solver.cpp:253]     Train net output #0: loss = 1.34596 (* 1 = 1.34596 loss)
I0525 05:48:15.900681 22762 sgd_solver.cpp:106] Iteration 39342, lr = 0.001
I0525 05:48:24.759898 22762 solver.cpp:237] Iteration 39508, loss = 1.25596
I0525 05:48:24.759954 22762 solver.cpp:253]     Train net output #0: loss = 1.25596 (* 1 = 1.25596 loss)
I0525 05:48:24.759982 22762 sgd_solver.cpp:106] Iteration 39508, lr = 0.001
I0525 05:48:33.608322 22762 solver.cpp:237] Iteration 39674, loss = 1.12418
I0525 05:48:33.608497 22762 solver.cpp:253]     Train net output #0: loss = 1.12418 (* 1 = 1.12418 loss)
I0525 05:48:33.608515 22762 sgd_solver.cpp:106] Iteration 39674, lr = 0.001
I0525 05:48:42.468372 22762 solver.cpp:237] Iteration 39840, loss = 1.15592
I0525 05:48:42.468408 22762 solver.cpp:253]     Train net output #0: loss = 1.15592 (* 1 = 1.15592 loss)
I0525 05:48:42.468426 22762 sgd_solver.cpp:106] Iteration 39840, lr = 0.001
I0525 05:48:50.106331 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_39984.caffemodel
I0525 05:48:50.182536 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_39984.solverstate
I0525 05:48:50.814908 22762 solver.cpp:341] Iteration 39996, Testing net (#0)
I0525 05:49:58.877581 22762 solver.cpp:409]     Test net output #0: accuracy = 0.854703
I0525 05:49:58.877770 22762 solver.cpp:409]     Test net output #1: loss = 0.499867 (* 1 = 0.499867 loss)
I0525 05:50:20.273078 22762 solver.cpp:237] Iteration 40006, loss = 1.36113
I0525 05:50:20.273138 22762 solver.cpp:253]     Train net output #0: loss = 1.36113 (* 1 = 1.36113 loss)
I0525 05:50:20.273157 22762 sgd_solver.cpp:106] Iteration 40006, lr = 0.001
I0525 05:50:29.122097 22762 solver.cpp:237] Iteration 40172, loss = 1.24903
I0525 05:50:29.122279 22762 solver.cpp:253]     Train net output #0: loss = 1.24903 (* 1 = 1.24903 loss)
I0525 05:50:29.122298 22762 sgd_solver.cpp:106] Iteration 40172, lr = 0.001
I0525 05:50:37.963203 22762 solver.cpp:237] Iteration 40338, loss = 1.31907
I0525 05:50:37.963240 22762 solver.cpp:253]     Train net output #0: loss = 1.31907 (* 1 = 1.31907 loss)
I0525 05:50:37.963258 22762 sgd_solver.cpp:106] Iteration 40338, lr = 0.001
I0525 05:50:46.805809 22762 solver.cpp:237] Iteration 40504, loss = 1.17514
I0525 05:50:46.805845 22762 solver.cpp:253]     Train net output #0: loss = 1.17514 (* 1 = 1.17514 loss)
I0525 05:50:46.805863 22762 sgd_solver.cpp:106] Iteration 40504, lr = 0.001
I0525 05:50:55.653093 22762 solver.cpp:237] Iteration 40670, loss = 1.15057
I0525 05:50:55.653146 22762 solver.cpp:253]     Train net output #0: loss = 1.15057 (* 1 = 1.15057 loss)
I0525 05:50:55.653175 22762 sgd_solver.cpp:106] Iteration 40670, lr = 0.001
I0525 05:51:04.497373 22762 solver.cpp:237] Iteration 40836, loss = 1.26363
I0525 05:51:04.497546 22762 solver.cpp:253]     Train net output #0: loss = 1.26363 (* 1 = 1.26363 loss)
I0525 05:51:04.497563 22762 sgd_solver.cpp:106] Iteration 40836, lr = 0.001
I0525 05:51:13.333379 22762 solver.cpp:237] Iteration 41002, loss = 1.49153
I0525 05:51:13.333415 22762 solver.cpp:253]     Train net output #0: loss = 1.49153 (* 1 = 1.49153 loss)
I0525 05:51:13.333433 22762 sgd_solver.cpp:106] Iteration 41002, lr = 0.001
I0525 05:51:43.042788 22762 solver.cpp:237] Iteration 41168, loss = 1.28963
I0525 05:51:43.042979 22762 solver.cpp:253]     Train net output #0: loss = 1.28963 (* 1 = 1.28963 loss)
I0525 05:51:43.042996 22762 sgd_solver.cpp:106] Iteration 41168, lr = 0.001
I0525 05:51:51.892555 22762 solver.cpp:237] Iteration 41334, loss = 1.2022
I0525 05:51:51.892601 22762 solver.cpp:253]     Train net output #0: loss = 1.2022 (* 1 = 1.2022 loss)
I0525 05:51:51.892628 22762 sgd_solver.cpp:106] Iteration 41334, lr = 0.001
I0525 05:52:00.740216 22762 solver.cpp:237] Iteration 41500, loss = 1.26334
I0525 05:52:00.740252 22762 solver.cpp:253]     Train net output #0: loss = 1.26334 (* 1 = 1.26334 loss)
I0525 05:52:00.740279 22762 sgd_solver.cpp:106] Iteration 41500, lr = 0.001
I0525 05:52:08.678912 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_41650.caffemodel
I0525 05:52:08.756155 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_41650.solverstate
I0525 05:52:09.654533 22762 solver.cpp:237] Iteration 41666, loss = 1.30994
I0525 05:52:09.654594 22762 solver.cpp:253]     Train net output #0: loss = 1.30994 (* 1 = 1.30994 loss)
I0525 05:52:09.654618 22762 sgd_solver.cpp:106] Iteration 41666, lr = 0.001
I0525 05:52:18.501294 22762 solver.cpp:237] Iteration 41832, loss = 1.31602
I0525 05:52:18.501469 22762 solver.cpp:253]     Train net output #0: loss = 1.31602 (* 1 = 1.31602 loss)
I0525 05:52:18.501487 22762 sgd_solver.cpp:106] Iteration 41832, lr = 0.001
I0525 05:52:27.343350 22762 solver.cpp:237] Iteration 41998, loss = 1.29408
I0525 05:52:27.343387 22762 solver.cpp:253]     Train net output #0: loss = 1.29408 (* 1 = 1.29408 loss)
I0525 05:52:27.343405 22762 sgd_solver.cpp:106] Iteration 41998, lr = 0.001
I0525 05:52:36.189901 22762 solver.cpp:237] Iteration 42164, loss = 1.14945
I0525 05:52:36.189963 22762 solver.cpp:253]     Train net output #0: loss = 1.14945 (* 1 = 1.14945 loss)
I0525 05:52:36.189987 22762 sgd_solver.cpp:106] Iteration 42164, lr = 0.001
I0525 05:53:05.972499 22762 solver.cpp:237] Iteration 42330, loss = 1.20371
I0525 05:53:05.972689 22762 solver.cpp:253]     Train net output #0: loss = 1.20371 (* 1 = 1.20371 loss)
I0525 05:53:05.972708 22762 sgd_solver.cpp:106] Iteration 42330, lr = 0.001
I0525 05:53:14.813419 22762 solver.cpp:237] Iteration 42496, loss = 1.24609
I0525 05:53:14.813457 22762 solver.cpp:253]     Train net output #0: loss = 1.24609 (* 1 = 1.24609 loss)
I0525 05:53:14.813474 22762 sgd_solver.cpp:106] Iteration 42496, lr = 0.001
I0525 05:53:23.670855 22762 solver.cpp:237] Iteration 42662, loss = 1.21617
I0525 05:53:23.670891 22762 solver.cpp:253]     Train net output #0: loss = 1.21617 (* 1 = 1.21617 loss)
I0525 05:53:23.670908 22762 sgd_solver.cpp:106] Iteration 42662, lr = 0.001
I0525 05:53:32.523016 22762 solver.cpp:237] Iteration 42828, loss = 1.33516
I0525 05:53:32.523072 22762 solver.cpp:253]     Train net output #0: loss = 1.33516 (* 1 = 1.33516 loss)
I0525 05:53:32.523090 22762 sgd_solver.cpp:106] Iteration 42828, lr = 0.001
I0525 05:53:41.375823 22762 solver.cpp:237] Iteration 42994, loss = 1.26615
I0525 05:53:41.375991 22762 solver.cpp:253]     Train net output #0: loss = 1.26615 (* 1 = 1.26615 loss)
I0525 05:53:41.376008 22762 sgd_solver.cpp:106] Iteration 42994, lr = 0.001
I0525 05:53:50.223083 22762 solver.cpp:237] Iteration 43160, loss = 1.27928
I0525 05:53:50.223136 22762 solver.cpp:253]     Train net output #0: loss = 1.27928 (* 1 = 1.27928 loss)
I0525 05:53:50.223165 22762 sgd_solver.cpp:106] Iteration 43160, lr = 0.001
I0525 05:53:58.485165 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_43316.caffemodel
I0525 05:53:58.560163 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_43316.solverstate
I0525 05:53:59.137073 22762 solver.cpp:237] Iteration 43326, loss = 1.04717
I0525 05:53:59.137126 22762 solver.cpp:253]     Train net output #0: loss = 1.04717 (* 1 = 1.04717 loss)
I0525 05:53:59.137151 22762 sgd_solver.cpp:106] Iteration 43326, lr = 0.001
I0525 05:53:59.244362 22762 solver.cpp:341] Iteration 43329, Testing net (#0)
I0525 05:54:46.513782 22762 solver.cpp:409]     Test net output #0: accuracy = 0.852096
I0525 05:54:46.513990 22762 solver.cpp:409]     Test net output #1: loss = 0.463247 (* 1 = 0.463247 loss)
I0525 05:55:16.092772 22762 solver.cpp:237] Iteration 43492, loss = 1.24772
I0525 05:55:16.092829 22762 solver.cpp:253]     Train net output #0: loss = 1.24772 (* 1 = 1.24772 loss)
I0525 05:55:16.092854 22762 sgd_solver.cpp:106] Iteration 43492, lr = 0.001
I0525 05:55:24.943567 22762 solver.cpp:237] Iteration 43658, loss = 1.43425
I0525 05:55:24.943734 22762 solver.cpp:253]     Train net output #0: loss = 1.43425 (* 1 = 1.43425 loss)
I0525 05:55:24.943752 22762 sgd_solver.cpp:106] Iteration 43658, lr = 0.001
I0525 05:55:33.791023 22762 solver.cpp:237] Iteration 43824, loss = 1.2677
I0525 05:55:33.791077 22762 solver.cpp:253]     Train net output #0: loss = 1.2677 (* 1 = 1.2677 loss)
I0525 05:55:33.791101 22762 sgd_solver.cpp:106] Iteration 43824, lr = 0.001
I0525 05:55:42.638207 22762 solver.cpp:237] Iteration 43990, loss = 1.41054
I0525 05:55:42.638245 22762 solver.cpp:253]     Train net output #0: loss = 1.41054 (* 1 = 1.41054 loss)
I0525 05:55:42.638262 22762 sgd_solver.cpp:106] Iteration 43990, lr = 0.001
I0525 05:55:51.473867 22762 solver.cpp:237] Iteration 44156, loss = 1.24206
I0525 05:55:51.473904 22762 solver.cpp:253]     Train net output #0: loss = 1.24206 (* 1 = 1.24206 loss)
I0525 05:55:51.473922 22762 sgd_solver.cpp:106] Iteration 44156, lr = 0.001
I0525 05:56:00.314899 22762 solver.cpp:237] Iteration 44322, loss = 1.18459
I0525 05:56:00.315085 22762 solver.cpp:253]     Train net output #0: loss = 1.18459 (* 1 = 1.18459 loss)
I0525 05:56:00.315102 22762 sgd_solver.cpp:106] Iteration 44322, lr = 0.001
I0525 05:56:30.071980 22762 solver.cpp:237] Iteration 44488, loss = 1.33912
I0525 05:56:30.072042 22762 solver.cpp:253]     Train net output #0: loss = 1.33912 (* 1 = 1.33912 loss)
I0525 05:56:30.072062 22762 sgd_solver.cpp:106] Iteration 44488, lr = 0.001
I0525 05:56:38.915768 22762 solver.cpp:237] Iteration 44654, loss = 1.35669
I0525 05:56:38.915940 22762 solver.cpp:253]     Train net output #0: loss = 1.35669 (* 1 = 1.35669 loss)
I0525 05:56:38.915957 22762 sgd_solver.cpp:106] Iteration 44654, lr = 0.001
I0525 05:56:47.768065 22762 solver.cpp:237] Iteration 44820, loss = 1.07346
I0525 05:56:47.768123 22762 solver.cpp:253]     Train net output #0: loss = 1.07346 (* 1 = 1.07346 loss)
I0525 05:56:47.768147 22762 sgd_solver.cpp:106] Iteration 44820, lr = 0.001
I0525 05:56:56.353643 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_44982.caffemodel
I0525 05:56:56.429332 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_44982.solverstate
I0525 05:56:56.685478 22762 solver.cpp:237] Iteration 44986, loss = 1.17504
I0525 05:56:56.685533 22762 solver.cpp:253]     Train net output #0: loss = 1.17504 (* 1 = 1.17504 loss)
I0525 05:56:56.685557 22762 sgd_solver.cpp:106] Iteration 44986, lr = 0.001
I0525 05:57:05.527227 22762 solver.cpp:237] Iteration 45152, loss = 1.29719
I0525 05:57:05.527264 22762 solver.cpp:253]     Train net output #0: loss = 1.29719 (* 1 = 1.29719 loss)
I0525 05:57:05.527283 22762 sgd_solver.cpp:106] Iteration 45152, lr = 0.001
I0525 05:57:14.380625 22762 solver.cpp:237] Iteration 45318, loss = 1.30374
I0525 05:57:14.380815 22762 solver.cpp:253]     Train net output #0: loss = 1.30374 (* 1 = 1.30374 loss)
I0525 05:57:14.380832 22762 sgd_solver.cpp:106] Iteration 45318, lr = 0.001
I0525 05:57:23.230042 22762 solver.cpp:237] Iteration 45484, loss = 1.36183
I0525 05:57:23.230079 22762 solver.cpp:253]     Train net output #0: loss = 1.36183 (* 1 = 1.36183 loss)
I0525 05:57:23.230098 22762 sgd_solver.cpp:106] Iteration 45484, lr = 0.001
I0525 05:57:52.958597 22762 solver.cpp:237] Iteration 45650, loss = 1.23422
I0525 05:57:52.958799 22762 solver.cpp:253]     Train net output #0: loss = 1.23422 (* 1 = 1.23422 loss)
I0525 05:57:52.958817 22762 sgd_solver.cpp:106] Iteration 45650, lr = 0.001
I0525 05:58:01.807220 22762 solver.cpp:237] Iteration 45816, loss = 1.32446
I0525 05:58:01.807274 22762 solver.cpp:253]     Train net output #0: loss = 1.32446 (* 1 = 1.32446 loss)
I0525 05:58:01.807299 22762 sgd_solver.cpp:106] Iteration 45816, lr = 0.001
I0525 05:58:10.674494 22762 solver.cpp:237] Iteration 45982, loss = 1.32331
I0525 05:58:10.674531 22762 solver.cpp:253]     Train net output #0: loss = 1.32331 (* 1 = 1.32331 loss)
I0525 05:58:10.674549 22762 sgd_solver.cpp:106] Iteration 45982, lr = 0.001
I0525 05:58:19.529695 22762 solver.cpp:237] Iteration 46148, loss = 1.32435
I0525 05:58:19.529731 22762 solver.cpp:253]     Train net output #0: loss = 1.32435 (* 1 = 1.32435 loss)
I0525 05:58:19.529748 22762 sgd_solver.cpp:106] Iteration 46148, lr = 0.001
I0525 05:58:28.386507 22762 solver.cpp:237] Iteration 46314, loss = 1.19692
I0525 05:58:28.386692 22762 solver.cpp:253]     Train net output #0: loss = 1.19692 (* 1 = 1.19692 loss)
I0525 05:58:28.386708 22762 sgd_solver.cpp:106] Iteration 46314, lr = 0.001
I0525 05:58:37.242228 22762 solver.cpp:237] Iteration 46480, loss = 1.48613
I0525 05:58:37.242264 22762 solver.cpp:253]     Train net output #0: loss = 1.48613 (* 1 = 1.48613 loss)
I0525 05:58:37.242281 22762 sgd_solver.cpp:106] Iteration 46480, lr = 0.001
I0525 05:58:46.107385 22762 solver.cpp:237] Iteration 46646, loss = 1.08665
I0525 05:58:46.107422 22762 solver.cpp:253]     Train net output #0: loss = 1.08665 (* 1 = 1.08665 loss)
I0525 05:58:46.107439 22762 sgd_solver.cpp:106] Iteration 46646, lr = 0.001
I0525 05:58:46.160711 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_46648.caffemodel
I0525 05:58:46.235999 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_46648.solverstate
I0525 05:58:46.976040 22762 solver.cpp:341] Iteration 46662, Testing net (#0)
I0525 05:59:55.084980 22762 solver.cpp:409]     Test net output #0: accuracy = 0.856371
I0525 05:59:55.085171 22762 solver.cpp:409]     Test net output #1: loss = 0.448225 (* 1 = 0.448225 loss)
I0525 06:00:23.939507 22762 solver.cpp:237] Iteration 46812, loss = 1.31829
I0525 06:00:23.939565 22762 solver.cpp:253]     Train net output #0: loss = 1.31829 (* 1 = 1.31829 loss)
I0525 06:00:23.939589 22762 sgd_solver.cpp:106] Iteration 46812, lr = 0.001
I0525 06:00:32.794992 22762 solver.cpp:237] Iteration 46978, loss = 1.21505
I0525 06:00:32.795181 22762 solver.cpp:253]     Train net output #0: loss = 1.21505 (* 1 = 1.21505 loss)
I0525 06:00:32.795199 22762 sgd_solver.cpp:106] Iteration 46978, lr = 0.001
I0525 06:00:41.651885 22762 solver.cpp:237] Iteration 47144, loss = 1.33132
I0525 06:00:41.651922 22762 solver.cpp:253]     Train net output #0: loss = 1.33132 (* 1 = 1.33132 loss)
I0525 06:00:41.651940 22762 sgd_solver.cpp:106] Iteration 47144, lr = 0.001
I0525 06:00:50.506747 22762 solver.cpp:237] Iteration 47310, loss = 1.36091
I0525 06:00:50.506783 22762 solver.cpp:253]     Train net output #0: loss = 1.36091 (* 1 = 1.36091 loss)
I0525 06:00:50.506801 22762 sgd_solver.cpp:106] Iteration 47310, lr = 0.001
I0525 06:00:59.374596 22762 solver.cpp:237] Iteration 47476, loss = 1.20095
I0525 06:00:59.374655 22762 solver.cpp:253]     Train net output #0: loss = 1.20095 (* 1 = 1.20095 loss)
I0525 06:00:59.374675 22762 sgd_solver.cpp:106] Iteration 47476, lr = 0.001
I0525 06:01:08.228463 22762 solver.cpp:237] Iteration 47642, loss = 1.32572
I0525 06:01:08.228632 22762 solver.cpp:253]     Train net output #0: loss = 1.32572 (* 1 = 1.32572 loss)
I0525 06:01:08.228649 22762 sgd_solver.cpp:106] Iteration 47642, lr = 0.001
I0525 06:01:37.929420 22762 solver.cpp:237] Iteration 47808, loss = 1.38873
I0525 06:01:37.929477 22762 solver.cpp:253]     Train net output #0: loss = 1.38873 (* 1 = 1.38873 loss)
I0525 06:01:37.929502 22762 sgd_solver.cpp:106] Iteration 47808, lr = 0.001
I0525 06:01:46.785010 22762 solver.cpp:237] Iteration 47974, loss = 1.46116
I0525 06:01:46.785210 22762 solver.cpp:253]     Train net output #0: loss = 1.46116 (* 1 = 1.46116 loss)
I0525 06:01:46.785228 22762 sgd_solver.cpp:106] Iteration 47974, lr = 0.001
I0525 06:01:55.632899 22762 solver.cpp:237] Iteration 48140, loss = 1.14537
I0525 06:01:55.632937 22762 solver.cpp:253]     Train net output #0: loss = 1.14537 (* 1 = 1.14537 loss)
I0525 06:01:55.632954 22762 sgd_solver.cpp:106] Iteration 48140, lr = 0.001
I0525 06:02:04.473140 22762 solver.cpp:237] Iteration 48306, loss = 1.38026
I0525 06:02:04.473177 22762 solver.cpp:253]     Train net output #0: loss = 1.38026 (* 1 = 1.38026 loss)
I0525 06:02:04.473194 22762 sgd_solver.cpp:106] Iteration 48306, lr = 0.001
I0525 06:02:04.846400 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_48314.caffemodel
I0525 06:02:04.925285 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_48314.solverstate
I0525 06:02:13.392200 22762 solver.cpp:237] Iteration 48472, loss = 0.959506
I0525 06:02:13.392268 22762 solver.cpp:253]     Train net output #0: loss = 0.959506 (* 1 = 0.959506 loss)
I0525 06:02:13.392287 22762 sgd_solver.cpp:106] Iteration 48472, lr = 0.001
I0525 06:02:22.245487 22762 solver.cpp:237] Iteration 48638, loss = 1.18472
I0525 06:02:22.245661 22762 solver.cpp:253]     Train net output #0: loss = 1.18472 (* 1 = 1.18472 loss)
I0525 06:02:22.245678 22762 sgd_solver.cpp:106] Iteration 48638, lr = 0.001
I0525 06:02:31.082223 22762 solver.cpp:237] Iteration 48804, loss = 1.22161
I0525 06:02:31.082259 22762 solver.cpp:253]     Train net output #0: loss = 1.22161 (* 1 = 1.22161 loss)
I0525 06:02:31.082278 22762 sgd_solver.cpp:106] Iteration 48804, lr = 0.001
I0525 06:03:00.796571 22762 solver.cpp:237] Iteration 48970, loss = 1.19974
I0525 06:03:00.796757 22762 solver.cpp:253]     Train net output #0: loss = 1.19974 (* 1 = 1.19974 loss)
I0525 06:03:00.796775 22762 sgd_solver.cpp:106] Iteration 48970, lr = 0.001
I0525 06:03:09.639173 22762 solver.cpp:237] Iteration 49136, loss = 1.13164
I0525 06:03:09.639210 22762 solver.cpp:253]     Train net output #0: loss = 1.13164 (* 1 = 1.13164 loss)
I0525 06:03:09.639228 22762 sgd_solver.cpp:106] Iteration 49136, lr = 0.001
I0525 06:03:18.485854 22762 solver.cpp:237] Iteration 49302, loss = 1.15988
I0525 06:03:18.485890 22762 solver.cpp:253]     Train net output #0: loss = 1.15988 (* 1 = 1.15988 loss)
I0525 06:03:18.485908 22762 sgd_solver.cpp:106] Iteration 49302, lr = 0.001
I0525 06:03:27.336668 22762 solver.cpp:237] Iteration 49468, loss = 1.38496
I0525 06:03:27.336720 22762 solver.cpp:253]     Train net output #0: loss = 1.38496 (* 1 = 1.38496 loss)
I0525 06:03:27.336737 22762 sgd_solver.cpp:106] Iteration 49468, lr = 0.001
I0525 06:03:36.193470 22762 solver.cpp:237] Iteration 49634, loss = 1.4427
I0525 06:03:36.193639 22762 solver.cpp:253]     Train net output #0: loss = 1.4427 (* 1 = 1.4427 loss)
I0525 06:03:36.193656 22762 sgd_solver.cpp:106] Iteration 49634, lr = 0.001
I0525 06:03:45.043382 22762 solver.cpp:237] Iteration 49800, loss = 1.2987
I0525 06:03:45.043419 22762 solver.cpp:253]     Train net output #0: loss = 1.2987 (* 1 = 1.2987 loss)
I0525 06:03:45.043437 22762 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0525 06:03:53.893673 22762 solver.cpp:237] Iteration 49966, loss = 1.12747
I0525 06:03:53.893730 22762 solver.cpp:253]     Train net output #0: loss = 1.12747 (* 1 = 1.12747 loss)
I0525 06:03:53.893754 22762 sgd_solver.cpp:106] Iteration 49966, lr = 0.001
I0525 06:03:54.585152 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_49980.caffemodel
I0525 06:03:54.662106 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_49980.solverstate
I0525 06:03:55.453519 22762 solver.cpp:341] Iteration 49995, Testing net (#0)
I0525 06:04:42.349751 22762 solver.cpp:409]     Test net output #0: accuracy = 0.859859
I0525 06:04:42.349953 22762 solver.cpp:409]     Test net output #1: loss = 0.495554 (* 1 = 0.495554 loss)
I0525 06:05:10.569689 22762 solver.cpp:237] Iteration 50132, loss = 1.08241
I0525 06:05:10.569751 22762 solver.cpp:253]     Train net output #0: loss = 1.08241 (* 1 = 1.08241 loss)
I0525 06:05:10.569774 22762 sgd_solver.cpp:106] Iteration 50132, lr = 0.001
I0525 06:05:19.417384 22762 solver.cpp:237] Iteration 50298, loss = 0.98732
I0525 06:05:19.417557 22762 solver.cpp:253]     Train net output #0: loss = 0.98732 (* 1 = 0.98732 loss)
I0525 06:05:19.417574 22762 sgd_solver.cpp:106] Iteration 50298, lr = 0.001
I0525 06:05:28.268729 22762 solver.cpp:237] Iteration 50464, loss = 1.21997
I0525 06:05:28.268766 22762 solver.cpp:253]     Train net output #0: loss = 1.21997 (* 1 = 1.21997 loss)
I0525 06:05:28.268784 22762 sgd_solver.cpp:106] Iteration 50464, lr = 0.001
I0525 06:05:37.124009 22762 solver.cpp:237] Iteration 50630, loss = 1.15265
I0525 06:05:37.124064 22762 solver.cpp:253]     Train net output #0: loss = 1.15265 (* 1 = 1.15265 loss)
I0525 06:05:37.124083 22762 sgd_solver.cpp:106] Iteration 50630, lr = 0.001
I0525 06:05:45.983876 22762 solver.cpp:237] Iteration 50796, loss = 1.55371
I0525 06:05:45.983913 22762 solver.cpp:253]     Train net output #0: loss = 1.55371 (* 1 = 1.55371 loss)
I0525 06:05:45.983932 22762 sgd_solver.cpp:106] Iteration 50796, lr = 0.001
I0525 06:05:54.847790 22762 solver.cpp:237] Iteration 50962, loss = 1.03274
I0525 06:05:54.847975 22762 solver.cpp:253]     Train net output #0: loss = 1.03274 (* 1 = 1.03274 loss)
I0525 06:05:54.847991 22762 sgd_solver.cpp:106] Iteration 50962, lr = 0.001
I0525 06:06:24.601014 22762 solver.cpp:237] Iteration 51128, loss = 1.36087
I0525 06:06:24.601074 22762 solver.cpp:253]     Train net output #0: loss = 1.36087 (* 1 = 1.36087 loss)
I0525 06:06:24.601101 22762 sgd_solver.cpp:106] Iteration 51128, lr = 0.001
I0525 06:06:33.449370 22762 solver.cpp:237] Iteration 51294, loss = 1.20271
I0525 06:06:33.449545 22762 solver.cpp:253]     Train net output #0: loss = 1.20271 (* 1 = 1.20271 loss)
I0525 06:06:33.449563 22762 sgd_solver.cpp:106] Iteration 51294, lr = 0.001
I0525 06:06:42.298725 22762 solver.cpp:237] Iteration 51460, loss = 1.27622
I0525 06:06:42.298761 22762 solver.cpp:253]     Train net output #0: loss = 1.27622 (* 1 = 1.27622 loss)
I0525 06:06:42.298780 22762 sgd_solver.cpp:106] Iteration 51460, lr = 0.001
I0525 06:06:51.143533 22762 solver.cpp:237] Iteration 51626, loss = 1.21228
I0525 06:06:51.143586 22762 solver.cpp:253]     Train net output #0: loss = 1.21228 (* 1 = 1.21228 loss)
I0525 06:06:51.143615 22762 sgd_solver.cpp:106] Iteration 51626, lr = 0.001
I0525 06:06:52.157516 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_51646.caffemodel
I0525 06:06:52.233391 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_51646.solverstate
I0525 06:07:00.060508 22762 solver.cpp:237] Iteration 51792, loss = 1.18642
I0525 06:07:00.060562 22762 solver.cpp:253]     Train net output #0: loss = 1.18642 (* 1 = 1.18642 loss)
I0525 06:07:00.060588 22762 sgd_solver.cpp:106] Iteration 51792, lr = 0.001
I0525 06:07:08.907806 22762 solver.cpp:237] Iteration 51958, loss = 1.26805
I0525 06:07:08.908001 22762 solver.cpp:253]     Train net output #0: loss = 1.26805 (* 1 = 1.26805 loss)
I0525 06:07:08.908020 22762 sgd_solver.cpp:106] Iteration 51958, lr = 0.001
I0525 06:07:17.753974 22762 solver.cpp:237] Iteration 52124, loss = 0.972477
I0525 06:07:17.754014 22762 solver.cpp:253]     Train net output #0: loss = 0.972477 (* 1 = 0.972477 loss)
I0525 06:07:17.754030 22762 sgd_solver.cpp:106] Iteration 52124, lr = 0.001
I0525 06:07:47.467579 22762 solver.cpp:237] Iteration 52290, loss = 1.09399
I0525 06:07:47.467783 22762 solver.cpp:253]     Train net output #0: loss = 1.09399 (* 1 = 1.09399 loss)
I0525 06:07:47.467802 22762 sgd_solver.cpp:106] Iteration 52290, lr = 0.001
I0525 06:07:56.322147 22762 solver.cpp:237] Iteration 52456, loss = 1.084
I0525 06:07:56.322185 22762 solver.cpp:253]     Train net output #0: loss = 1.084 (* 1 = 1.084 loss)
I0525 06:07:56.322202 22762 sgd_solver.cpp:106] Iteration 52456, lr = 0.001
I0525 06:08:05.172116 22762 solver.cpp:237] Iteration 52622, loss = 1.20972
I0525 06:08:05.172173 22762 solver.cpp:253]     Train net output #0: loss = 1.20972 (* 1 = 1.20972 loss)
I0525 06:08:05.172196 22762 sgd_solver.cpp:106] Iteration 52622, lr = 0.001
I0525 06:08:14.011257 22762 solver.cpp:237] Iteration 52788, loss = 1.36038
I0525 06:08:14.011296 22762 solver.cpp:253]     Train net output #0: loss = 1.36038 (* 1 = 1.36038 loss)
I0525 06:08:14.011313 22762 sgd_solver.cpp:106] Iteration 52788, lr = 0.001
I0525 06:08:22.860853 22762 solver.cpp:237] Iteration 52954, loss = 1.30609
I0525 06:08:22.861029 22762 solver.cpp:253]     Train net output #0: loss = 1.30609 (* 1 = 1.30609 loss)
I0525 06:08:22.861047 22762 sgd_solver.cpp:106] Iteration 52954, lr = 0.001
I0525 06:08:31.699378 22762 solver.cpp:237] Iteration 53120, loss = 1.20772
I0525 06:08:31.699430 22762 solver.cpp:253]     Train net output #0: loss = 1.20772 (* 1 = 1.20772 loss)
I0525 06:08:31.699457 22762 sgd_solver.cpp:106] Iteration 53120, lr = 0.001
I0525 06:08:40.550009 22762 solver.cpp:237] Iteration 53286, loss = 1.25283
I0525 06:08:40.550045 22762 solver.cpp:253]     Train net output #0: loss = 1.25283 (* 1 = 1.25283 loss)
I0525 06:08:40.550063 22762 sgd_solver.cpp:106] Iteration 53286, lr = 0.001
I0525 06:08:41.883332 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_53312.caffemodel
I0525 06:08:41.958402 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_53312.solverstate
I0525 06:08:42.798892 22762 solver.cpp:341] Iteration 53328, Testing net (#0)
I0525 06:09:50.828196 22762 solver.cpp:409]     Test net output #0: accuracy = 0.859959
I0525 06:09:50.828394 22762 solver.cpp:409]     Test net output #1: loss = 0.446109 (* 1 = 0.446109 loss)
I0525 06:10:18.274500 22762 solver.cpp:237] Iteration 53452, loss = 1.31236
I0525 06:10:18.274557 22762 solver.cpp:253]     Train net output #0: loss = 1.31236 (* 1 = 1.31236 loss)
I0525 06:10:18.274581 22762 sgd_solver.cpp:106] Iteration 53452, lr = 0.001
I0525 06:10:27.136296 22762 solver.cpp:237] Iteration 53618, loss = 1.2602
I0525 06:10:27.136471 22762 solver.cpp:253]     Train net output #0: loss = 1.2602 (* 1 = 1.2602 loss)
I0525 06:10:27.136488 22762 sgd_solver.cpp:106] Iteration 53618, lr = 0.001
I0525 06:10:35.984886 22762 solver.cpp:237] Iteration 53784, loss = 1.15275
I0525 06:10:35.984942 22762 solver.cpp:253]     Train net output #0: loss = 1.15275 (* 1 = 1.15275 loss)
I0525 06:10:35.984967 22762 sgd_solver.cpp:106] Iteration 53784, lr = 0.001
I0525 06:10:44.841282 22762 solver.cpp:237] Iteration 53950, loss = 1.21139
I0525 06:10:44.841320 22762 solver.cpp:253]     Train net output #0: loss = 1.21139 (* 1 = 1.21139 loss)
I0525 06:10:44.841337 22762 sgd_solver.cpp:106] Iteration 53950, lr = 0.001
I0525 06:10:53.691496 22762 solver.cpp:237] Iteration 54116, loss = 1.20363
I0525 06:10:53.691534 22762 solver.cpp:253]     Train net output #0: loss = 1.20363 (* 1 = 1.20363 loss)
I0525 06:10:53.691551 22762 sgd_solver.cpp:106] Iteration 54116, lr = 0.001
I0525 06:11:02.553069 22762 solver.cpp:237] Iteration 54282, loss = 1.21776
I0525 06:11:02.553256 22762 solver.cpp:253]     Train net output #0: loss = 1.21776 (* 1 = 1.21776 loss)
I0525 06:11:02.553275 22762 sgd_solver.cpp:106] Iteration 54282, lr = 0.001
I0525 06:11:32.276928 22762 solver.cpp:237] Iteration 54448, loss = 1.12582
I0525 06:11:32.276988 22762 solver.cpp:253]     Train net output #0: loss = 1.12582 (* 1 = 1.12582 loss)
I0525 06:11:32.277006 22762 sgd_solver.cpp:106] Iteration 54448, lr = 0.001
I0525 06:11:41.127954 22762 solver.cpp:237] Iteration 54614, loss = 1.40156
I0525 06:11:41.128131 22762 solver.cpp:253]     Train net output #0: loss = 1.40156 (* 1 = 1.40156 loss)
I0525 06:11:41.128147 22762 sgd_solver.cpp:106] Iteration 54614, lr = 0.001
I0525 06:11:49.985932 22762 solver.cpp:237] Iteration 54780, loss = 1.31006
I0525 06:11:49.985987 22762 solver.cpp:253]     Train net output #0: loss = 1.31006 (* 1 = 1.31006 loss)
I0525 06:11:49.986007 22762 sgd_solver.cpp:106] Iteration 54780, lr = 0.001
I0525 06:11:58.853160 22762 solver.cpp:237] Iteration 54946, loss = 1.21197
I0525 06:11:58.853196 22762 solver.cpp:253]     Train net output #0: loss = 1.21197 (* 1 = 1.21197 loss)
I0525 06:11:58.853214 22762 sgd_solver.cpp:106] Iteration 54946, lr = 0.001
I0525 06:12:00.502153 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_54978.caffemodel
I0525 06:12:00.577816 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_54978.solverstate
I0525 06:12:07.774508 22762 solver.cpp:237] Iteration 55112, loss = 1.04108
I0525 06:12:07.774564 22762 solver.cpp:253]     Train net output #0: loss = 1.04108 (* 1 = 1.04108 loss)
I0525 06:12:07.774590 22762 sgd_solver.cpp:106] Iteration 55112, lr = 0.001
I0525 06:12:16.622001 22762 solver.cpp:237] Iteration 55278, loss = 1.32363
I0525 06:12:16.622192 22762 solver.cpp:253]     Train net output #0: loss = 1.32363 (* 1 = 1.32363 loss)
I0525 06:12:16.622210 22762 sgd_solver.cpp:106] Iteration 55278, lr = 0.001
I0525 06:12:25.487232 22762 solver.cpp:237] Iteration 55444, loss = 1.17187
I0525 06:12:25.487269 22762 solver.cpp:253]     Train net output #0: loss = 1.17187 (* 1 = 1.17187 loss)
I0525 06:12:25.487287 22762 sgd_solver.cpp:106] Iteration 55444, lr = 0.001
I0525 06:12:55.221953 22762 solver.cpp:237] Iteration 55610, loss = 1.20881
I0525 06:12:55.222151 22762 solver.cpp:253]     Train net output #0: loss = 1.20881 (* 1 = 1.20881 loss)
I0525 06:12:55.222169 22762 sgd_solver.cpp:106] Iteration 55610, lr = 0.001
I0525 06:13:04.077509 22762 solver.cpp:237] Iteration 55776, loss = 1.29884
I0525 06:13:04.077563 22762 solver.cpp:253]     Train net output #0: loss = 1.29884 (* 1 = 1.29884 loss)
I0525 06:13:04.077590 22762 sgd_solver.cpp:106] Iteration 55776, lr = 0.001
I0525 06:13:12.927430 22762 solver.cpp:237] Iteration 55942, loss = 1.12835
I0525 06:13:12.927466 22762 solver.cpp:253]     Train net output #0: loss = 1.12835 (* 1 = 1.12835 loss)
I0525 06:13:12.927484 22762 sgd_solver.cpp:106] Iteration 55942, lr = 0.001
I0525 06:13:21.789587 22762 solver.cpp:237] Iteration 56108, loss = 1.47334
I0525 06:13:21.789625 22762 solver.cpp:253]     Train net output #0: loss = 1.47334 (* 1 = 1.47334 loss)
I0525 06:13:21.789643 22762 sgd_solver.cpp:106] Iteration 56108, lr = 0.001
I0525 06:13:30.645741 22762 solver.cpp:237] Iteration 56274, loss = 1.31507
I0525 06:13:30.645936 22762 solver.cpp:253]     Train net output #0: loss = 1.31507 (* 1 = 1.31507 loss)
I0525 06:13:30.645952 22762 sgd_solver.cpp:106] Iteration 56274, lr = 0.001
I0525 06:13:39.498512 22762 solver.cpp:237] Iteration 56440, loss = 1.2646
I0525 06:13:39.498548 22762 solver.cpp:253]     Train net output #0: loss = 1.2646 (* 1 = 1.2646 loss)
I0525 06:13:39.498567 22762 sgd_solver.cpp:106] Iteration 56440, lr = 0.001
I0525 06:13:48.362473 22762 solver.cpp:237] Iteration 56606, loss = 1.45763
I0525 06:13:48.362509 22762 solver.cpp:253]     Train net output #0: loss = 1.45763 (* 1 = 1.45763 loss)
I0525 06:13:48.362529 22762 sgd_solver.cpp:106] Iteration 56606, lr = 0.001
I0525 06:13:50.333319 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_56644.caffemodel
I0525 06:13:50.407665 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_56644.solverstate
I0525 06:13:51.304697 22762 solver.cpp:341] Iteration 56661, Testing net (#0)
I0525 06:14:38.539692 22762 solver.cpp:409]     Test net output #0: accuracy = 0.864248
I0525 06:14:38.539894 22762 solver.cpp:409]     Test net output #1: loss = 0.465496 (* 1 = 0.465496 loss)
I0525 06:15:05.302050 22762 solver.cpp:237] Iteration 56772, loss = 1.30434
I0525 06:15:05.302109 22762 solver.cpp:253]     Train net output #0: loss = 1.30434 (* 1 = 1.30434 loss)
I0525 06:15:05.302125 22762 sgd_solver.cpp:106] Iteration 56772, lr = 0.001
I0525 06:15:14.160444 22762 solver.cpp:237] Iteration 56938, loss = 1.33454
I0525 06:15:14.160621 22762 solver.cpp:253]     Train net output #0: loss = 1.33454 (* 1 = 1.33454 loss)
I0525 06:15:14.160639 22762 sgd_solver.cpp:106] Iteration 56938, lr = 0.001
I0525 06:15:23.020061 22762 solver.cpp:237] Iteration 57104, loss = 1.31145
I0525 06:15:23.020098 22762 solver.cpp:253]     Train net output #0: loss = 1.31145 (* 1 = 1.31145 loss)
I0525 06:15:23.020117 22762 sgd_solver.cpp:106] Iteration 57104, lr = 0.001
I0525 06:15:31.857729 22762 solver.cpp:237] Iteration 57270, loss = 1.05891
I0525 06:15:31.857789 22762 solver.cpp:253]     Train net output #0: loss = 1.05891 (* 1 = 1.05891 loss)
I0525 06:15:31.857812 22762 sgd_solver.cpp:106] Iteration 57270, lr = 0.001
I0525 06:15:40.707967 22762 solver.cpp:237] Iteration 57436, loss = 1.10042
I0525 06:15:40.708003 22762 solver.cpp:253]     Train net output #0: loss = 1.10042 (* 1 = 1.10042 loss)
I0525 06:15:40.708021 22762 sgd_solver.cpp:106] Iteration 57436, lr = 0.001
I0525 06:15:49.548784 22762 solver.cpp:237] Iteration 57602, loss = 1.52669
I0525 06:15:49.548967 22762 solver.cpp:253]     Train net output #0: loss = 1.52669 (* 1 = 1.52669 loss)
I0525 06:15:49.548985 22762 sgd_solver.cpp:106] Iteration 57602, lr = 0.001
I0525 06:15:58.397423 22762 solver.cpp:237] Iteration 57768, loss = 1.17067
I0525 06:15:58.397477 22762 solver.cpp:253]     Train net output #0: loss = 1.17067 (* 1 = 1.17067 loss)
I0525 06:15:58.397506 22762 sgd_solver.cpp:106] Iteration 57768, lr = 0.001
I0525 06:16:28.104251 22762 solver.cpp:237] Iteration 57934, loss = 1.32854
I0525 06:16:28.104452 22762 solver.cpp:253]     Train net output #0: loss = 1.32854 (* 1 = 1.32854 loss)
I0525 06:16:28.104470 22762 sgd_solver.cpp:106] Iteration 57934, lr = 0.001
I0525 06:16:36.946830 22762 solver.cpp:237] Iteration 58100, loss = 1.37432
I0525 06:16:36.946869 22762 solver.cpp:253]     Train net output #0: loss = 1.37432 (* 1 = 1.37432 loss)
I0525 06:16:36.946885 22762 sgd_solver.cpp:106] Iteration 58100, lr = 0.001
I0525 06:16:45.797055 22762 solver.cpp:237] Iteration 58266, loss = 1.02456
I0525 06:16:45.797112 22762 solver.cpp:253]     Train net output #0: loss = 1.02456 (* 1 = 1.02456 loss)
I0525 06:16:45.797137 22762 sgd_solver.cpp:106] Iteration 58266, lr = 0.001
I0525 06:16:48.090438 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_58310.caffemodel
I0525 06:16:48.166388 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_58310.solverstate
I0525 06:16:54.709724 22762 solver.cpp:237] Iteration 58432, loss = 1.34422
I0525 06:16:54.709779 22762 solver.cpp:253]     Train net output #0: loss = 1.34422 (* 1 = 1.34422 loss)
I0525 06:16:54.709805 22762 sgd_solver.cpp:106] Iteration 58432, lr = 0.001
I0525 06:17:03.556962 22762 solver.cpp:237] Iteration 58598, loss = 1.34682
I0525 06:17:03.557148 22762 solver.cpp:253]     Train net output #0: loss = 1.34682 (* 1 = 1.34682 loss)
I0525 06:17:03.557165 22762 sgd_solver.cpp:106] Iteration 58598, lr = 0.001
I0525 06:17:12.397296 22762 solver.cpp:237] Iteration 58764, loss = 1.20849
I0525 06:17:12.397354 22762 solver.cpp:253]     Train net output #0: loss = 1.20849 (* 1 = 1.20849 loss)
I0525 06:17:12.397379 22762 sgd_solver.cpp:106] Iteration 58764, lr = 0.001
I0525 06:17:42.116823 22762 solver.cpp:237] Iteration 58930, loss = 1.25612
I0525 06:17:42.117033 22762 solver.cpp:253]     Train net output #0: loss = 1.25612 (* 1 = 1.25612 loss)
I0525 06:17:42.117050 22762 sgd_solver.cpp:106] Iteration 58930, lr = 0.001
I0525 06:17:50.968189 22762 solver.cpp:237] Iteration 59096, loss = 1.45081
I0525 06:17:50.968226 22762 solver.cpp:253]     Train net output #0: loss = 1.45081 (* 1 = 1.45081 loss)
I0525 06:17:50.968245 22762 sgd_solver.cpp:106] Iteration 59096, lr = 0.001
I0525 06:17:59.821480 22762 solver.cpp:237] Iteration 59262, loss = 1.14989
I0525 06:17:59.821534 22762 solver.cpp:253]     Train net output #0: loss = 1.14989 (* 1 = 1.14989 loss)
I0525 06:17:59.821554 22762 sgd_solver.cpp:106] Iteration 59262, lr = 0.001
I0525 06:18:08.664160 22762 solver.cpp:237] Iteration 59428, loss = 1.21955
I0525 06:18:08.664197 22762 solver.cpp:253]     Train net output #0: loss = 1.21955 (* 1 = 1.21955 loss)
I0525 06:18:08.664216 22762 sgd_solver.cpp:106] Iteration 59428, lr = 0.001
I0525 06:18:17.516644 22762 solver.cpp:237] Iteration 59594, loss = 1.29844
I0525 06:18:17.516829 22762 solver.cpp:253]     Train net output #0: loss = 1.29844 (* 1 = 1.29844 loss)
I0525 06:18:17.516846 22762 sgd_solver.cpp:106] Iteration 59594, lr = 0.001
I0525 06:18:26.366287 22762 solver.cpp:237] Iteration 59760, loss = 1.47214
I0525 06:18:26.366348 22762 solver.cpp:253]     Train net output #0: loss = 1.47214 (* 1 = 1.47214 loss)
I0525 06:18:26.366366 22762 sgd_solver.cpp:106] Iteration 59760, lr = 0.001
I0525 06:18:35.208695 22762 solver.cpp:237] Iteration 59926, loss = 1.11328
I0525 06:18:35.208731 22762 solver.cpp:253]     Train net output #0: loss = 1.11328 (* 1 = 1.11328 loss)
I0525 06:18:35.208750 22762 sgd_solver.cpp:106] Iteration 59926, lr = 0.001
I0525 06:18:37.819677 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_59976.caffemodel
I0525 06:18:37.896687 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_59976.solverstate
I0525 06:18:38.849671 22762 solver.cpp:341] Iteration 59994, Testing net (#0)
I0525 06:19:46.935740 22762 solver.cpp:409]     Test net output #0: accuracy = 0.864802
I0525 06:19:46.935938 22762 solver.cpp:409]     Test net output #1: loss = 0.430865 (* 1 = 0.430865 loss)
I0525 06:20:13.009227 22762 solver.cpp:237] Iteration 60092, loss = 1.11844
I0525 06:20:13.009287 22762 solver.cpp:253]     Train net output #0: loss = 1.11844 (* 1 = 1.11844 loss)
I0525 06:20:13.009306 22762 sgd_solver.cpp:106] Iteration 60092, lr = 0.001
I0525 06:20:21.859376 22762 solver.cpp:237] Iteration 60258, loss = 1.16767
I0525 06:20:21.859555 22762 solver.cpp:253]     Train net output #0: loss = 1.16767 (* 1 = 1.16767 loss)
I0525 06:20:21.859571 22762 sgd_solver.cpp:106] Iteration 60258, lr = 0.001
I0525 06:20:30.713420 22762 solver.cpp:237] Iteration 60424, loss = 1.24965
I0525 06:20:30.713477 22762 solver.cpp:253]     Train net output #0: loss = 1.24965 (* 1 = 1.24965 loss)
I0525 06:20:30.713505 22762 sgd_solver.cpp:106] Iteration 60424, lr = 0.001
I0525 06:20:39.569358 22762 solver.cpp:237] Iteration 60590, loss = 1.23422
I0525 06:20:39.569396 22762 solver.cpp:253]     Train net output #0: loss = 1.23422 (* 1 = 1.23422 loss)
I0525 06:20:39.569413 22762 sgd_solver.cpp:106] Iteration 60590, lr = 0.001
I0525 06:20:48.430671 22762 solver.cpp:237] Iteration 60756, loss = 1.09063
I0525 06:20:48.430708 22762 solver.cpp:253]     Train net output #0: loss = 1.09063 (* 1 = 1.09063 loss)
I0525 06:20:48.430727 22762 sgd_solver.cpp:106] Iteration 60756, lr = 0.001
I0525 06:20:57.293748 22762 solver.cpp:237] Iteration 60922, loss = 1.33574
I0525 06:20:57.293956 22762 solver.cpp:253]     Train net output #0: loss = 1.33574 (* 1 = 1.33574 loss)
I0525 06:20:57.293972 22762 sgd_solver.cpp:106] Iteration 60922, lr = 0.001
I0525 06:21:06.149971 22762 solver.cpp:237] Iteration 61088, loss = 1.28922
I0525 06:21:06.150007 22762 solver.cpp:253]     Train net output #0: loss = 1.28922 (* 1 = 1.28922 loss)
I0525 06:21:06.150027 22762 sgd_solver.cpp:106] Iteration 61088, lr = 0.001
I0525 06:21:35.814467 22762 solver.cpp:237] Iteration 61254, loss = 1.17745
I0525 06:21:35.814668 22762 solver.cpp:253]     Train net output #0: loss = 1.17745 (* 1 = 1.17745 loss)
I0525 06:21:35.814685 22762 sgd_solver.cpp:106] Iteration 61254, lr = 0.001
I0525 06:21:44.660989 22762 solver.cpp:237] Iteration 61420, loss = 1.19374
I0525 06:21:44.661046 22762 solver.cpp:253]     Train net output #0: loss = 1.19374 (* 1 = 1.19374 loss)
I0525 06:21:44.661070 22762 sgd_solver.cpp:106] Iteration 61420, lr = 0.001
I0525 06:21:53.520016 22762 solver.cpp:237] Iteration 61586, loss = 1.40771
I0525 06:21:53.520054 22762 solver.cpp:253]     Train net output #0: loss = 1.40771 (* 1 = 1.40771 loss)
I0525 06:21:53.520072 22762 sgd_solver.cpp:106] Iteration 61586, lr = 0.001
I0525 06:21:56.452065 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_61642.caffemodel
I0525 06:21:56.526898 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_61642.solverstate
I0525 06:22:02.435389 22762 solver.cpp:237] Iteration 61752, loss = 1.13403
I0525 06:22:02.435443 22762 solver.cpp:253]     Train net output #0: loss = 1.13403 (* 1 = 1.13403 loss)
I0525 06:22:02.435468 22762 sgd_solver.cpp:106] Iteration 61752, lr = 0.001
I0525 06:22:11.294860 22762 solver.cpp:237] Iteration 61918, loss = 1.27345
I0525 06:22:11.295056 22762 solver.cpp:253]     Train net output #0: loss = 1.27345 (* 1 = 1.27345 loss)
I0525 06:22:11.295074 22762 sgd_solver.cpp:106] Iteration 61918, lr = 0.001
I0525 06:22:20.154964 22762 solver.cpp:237] Iteration 62084, loss = 1.09954
I0525 06:22:20.155002 22762 solver.cpp:253]     Train net output #0: loss = 1.09954 (* 1 = 1.09954 loss)
I0525 06:22:20.155020 22762 sgd_solver.cpp:106] Iteration 62084, lr = 0.001
I0525 06:22:49.902878 22762 solver.cpp:237] Iteration 62250, loss = 1.19067
I0525 06:22:49.903079 22762 solver.cpp:253]     Train net output #0: loss = 1.19067 (* 1 = 1.19067 loss)
I0525 06:22:49.903096 22762 sgd_solver.cpp:106] Iteration 62250, lr = 0.001
I0525 06:22:58.759305 22762 solver.cpp:237] Iteration 62416, loss = 0.981378
I0525 06:22:58.759343 22762 solver.cpp:253]     Train net output #0: loss = 0.981378 (* 1 = 0.981378 loss)
I0525 06:22:58.759361 22762 sgd_solver.cpp:106] Iteration 62416, lr = 0.001
I0525 06:23:07.627153 22762 solver.cpp:237] Iteration 62582, loss = 1.09421
I0525 06:23:07.627205 22762 solver.cpp:253]     Train net output #0: loss = 1.09421 (* 1 = 1.09421 loss)
I0525 06:23:07.627230 22762 sgd_solver.cpp:106] Iteration 62582, lr = 0.001
I0525 06:23:16.478318 22762 solver.cpp:237] Iteration 62748, loss = 1.0704
I0525 06:23:16.478355 22762 solver.cpp:253]     Train net output #0: loss = 1.0704 (* 1 = 1.0704 loss)
I0525 06:23:16.478374 22762 sgd_solver.cpp:106] Iteration 62748, lr = 0.001
I0525 06:23:25.329591 22762 solver.cpp:237] Iteration 62914, loss = 1.47234
I0525 06:23:25.329787 22762 solver.cpp:253]     Train net output #0: loss = 1.47234 (* 1 = 1.47234 loss)
I0525 06:23:25.329804 22762 sgd_solver.cpp:106] Iteration 62914, lr = 0.001
I0525 06:23:34.179868 22762 solver.cpp:237] Iteration 63080, loss = 1.38465
I0525 06:23:34.179908 22762 solver.cpp:253]     Train net output #0: loss = 1.38465 (* 1 = 1.38465 loss)
I0525 06:23:34.179924 22762 sgd_solver.cpp:106] Iteration 63080, lr = 0.001
I0525 06:23:43.032115 22762 solver.cpp:237] Iteration 63246, loss = 1.12826
I0525 06:23:43.032151 22762 solver.cpp:253]     Train net output #0: loss = 1.12826 (* 1 = 1.12826 loss)
I0525 06:23:43.032169 22762 sgd_solver.cpp:106] Iteration 63246, lr = 0.001
I0525 06:23:46.286185 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_63308.caffemodel
I0525 06:23:46.360780 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_63308.solverstate
I0525 06:23:47.365367 22762 solver.cpp:341] Iteration 63327, Testing net (#0)
I0525 06:24:34.299643 22762 solver.cpp:409]     Test net output #0: accuracy = 0.864788
I0525 06:24:34.299854 22762 solver.cpp:409]     Test net output #1: loss = 0.417257 (* 1 = 0.417257 loss)
I0525 06:24:59.741546 22762 solver.cpp:237] Iteration 63412, loss = 1.13543
I0525 06:24:59.741606 22762 solver.cpp:253]     Train net output #0: loss = 1.13543 (* 1 = 1.13543 loss)
I0525 06:24:59.741626 22762 sgd_solver.cpp:106] Iteration 63412, lr = 0.001
I0525 06:25:08.585137 22762 solver.cpp:237] Iteration 63578, loss = 1.24672
I0525 06:25:08.585347 22762 solver.cpp:253]     Train net output #0: loss = 1.24672 (* 1 = 1.24672 loss)
I0525 06:25:08.585366 22762 sgd_solver.cpp:106] Iteration 63578, lr = 0.001
I0525 06:25:17.432061 22762 solver.cpp:237] Iteration 63744, loss = 1.22031
I0525 06:25:17.432098 22762 solver.cpp:253]     Train net output #0: loss = 1.22031 (* 1 = 1.22031 loss)
I0525 06:25:17.432116 22762 sgd_solver.cpp:106] Iteration 63744, lr = 0.001
I0525 06:25:26.281826 22762 solver.cpp:237] Iteration 63910, loss = 1.18113
I0525 06:25:26.281863 22762 solver.cpp:253]     Train net output #0: loss = 1.18113 (* 1 = 1.18113 loss)
I0525 06:25:26.281882 22762 sgd_solver.cpp:106] Iteration 63910, lr = 0.001
I0525 06:25:35.140192 22762 solver.cpp:237] Iteration 64076, loss = 1.23505
I0525 06:25:35.140244 22762 solver.cpp:253]     Train net output #0: loss = 1.23505 (* 1 = 1.23505 loss)
I0525 06:25:35.140281 22762 sgd_solver.cpp:106] Iteration 64076, lr = 0.001
I0525 06:25:43.981806 22762 solver.cpp:237] Iteration 64242, loss = 1.11178
I0525 06:25:43.981983 22762 solver.cpp:253]     Train net output #0: loss = 1.11178 (* 1 = 1.11178 loss)
I0525 06:25:43.982000 22762 sgd_solver.cpp:106] Iteration 64242, lr = 0.001
I0525 06:25:52.823549 22762 solver.cpp:237] Iteration 64408, loss = 1.27637
I0525 06:25:52.823585 22762 solver.cpp:253]     Train net output #0: loss = 1.27637 (* 1 = 1.27637 loss)
I0525 06:25:52.823603 22762 sgd_solver.cpp:106] Iteration 64408, lr = 0.001
I0525 06:26:22.588213 22762 solver.cpp:237] Iteration 64574, loss = 1.4862
I0525 06:26:22.588420 22762 solver.cpp:253]     Train net output #0: loss = 1.4862 (* 1 = 1.4862 loss)
I0525 06:26:22.588439 22762 sgd_solver.cpp:106] Iteration 64574, lr = 0.001
I0525 06:26:31.431551 22762 solver.cpp:237] Iteration 64740, loss = 1.21555
I0525 06:26:31.431589 22762 solver.cpp:253]     Train net output #0: loss = 1.21555 (* 1 = 1.21555 loss)
I0525 06:26:31.431607 22762 sgd_solver.cpp:106] Iteration 64740, lr = 0.001
I0525 06:26:40.270607 22762 solver.cpp:237] Iteration 64906, loss = 0.977953
I0525 06:26:40.270644 22762 solver.cpp:253]     Train net output #0: loss = 0.977953 (* 1 = 0.977953 loss)
I0525 06:26:40.270663 22762 sgd_solver.cpp:106] Iteration 64906, lr = 0.001
I0525 06:26:43.841835 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_64974.caffemodel
I0525 06:26:43.916757 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_64974.solverstate
I0525 06:26:49.184633 22762 solver.cpp:237] Iteration 65072, loss = 1.30972
I0525 06:26:49.184689 22762 solver.cpp:253]     Train net output #0: loss = 1.30972 (* 1 = 1.30972 loss)
I0525 06:26:49.184715 22762 sgd_solver.cpp:106] Iteration 65072, lr = 0.001
I0525 06:26:58.018995 22762 solver.cpp:237] Iteration 65238, loss = 1.44512
I0525 06:26:58.019183 22762 solver.cpp:253]     Train net output #0: loss = 1.44512 (* 1 = 1.44512 loss)
I0525 06:26:58.019201 22762 sgd_solver.cpp:106] Iteration 65238, lr = 0.001
I0525 06:27:06.862190 22762 solver.cpp:237] Iteration 65404, loss = 1.41088
I0525 06:27:06.862226 22762 solver.cpp:253]     Train net output #0: loss = 1.41088 (* 1 = 1.41088 loss)
I0525 06:27:06.862246 22762 sgd_solver.cpp:106] Iteration 65404, lr = 0.001
I0525 06:27:36.577589 22762 solver.cpp:237] Iteration 65570, loss = 1.14327
I0525 06:27:36.577793 22762 solver.cpp:253]     Train net output #0: loss = 1.14327 (* 1 = 1.14327 loss)
I0525 06:27:36.577813 22762 sgd_solver.cpp:106] Iteration 65570, lr = 0.001
I0525 06:27:45.420567 22762 solver.cpp:237] Iteration 65736, loss = 1.25623
I0525 06:27:45.420606 22762 solver.cpp:253]     Train net output #0: loss = 1.25623 (* 1 = 1.25623 loss)
I0525 06:27:45.420624 22762 sgd_solver.cpp:106] Iteration 65736, lr = 0.001
I0525 06:27:54.262903 22762 solver.cpp:237] Iteration 65902, loss = 1.38472
I0525 06:27:54.262940 22762 solver.cpp:253]     Train net output #0: loss = 1.38472 (* 1 = 1.38472 loss)
I0525 06:27:54.262964 22762 sgd_solver.cpp:106] Iteration 65902, lr = 0.001
I0525 06:28:03.113576 22762 solver.cpp:237] Iteration 66068, loss = 1.38101
I0525 06:28:03.113636 22762 solver.cpp:253]     Train net output #0: loss = 1.38101 (* 1 = 1.38101 loss)
I0525 06:28:03.113661 22762 sgd_solver.cpp:106] Iteration 66068, lr = 0.001
I0525 06:28:11.966408 22762 solver.cpp:237] Iteration 66234, loss = 1.20067
I0525 06:28:11.966596 22762 solver.cpp:253]     Train net output #0: loss = 1.20067 (* 1 = 1.20067 loss)
I0525 06:28:11.966614 22762 sgd_solver.cpp:106] Iteration 66234, lr = 0.001
I0525 06:28:20.812129 22762 solver.cpp:237] Iteration 66400, loss = 1.27842
I0525 06:28:20.812166 22762 solver.cpp:253]     Train net output #0: loss = 1.27842 (* 1 = 1.27842 loss)
I0525 06:28:20.812183 22762 sgd_solver.cpp:106] Iteration 66400, lr = 0.001
I0525 06:28:29.652884 22762 solver.cpp:237] Iteration 66566, loss = 1.22917
I0525 06:28:29.652942 22762 solver.cpp:253]     Train net output #0: loss = 1.22917 (* 1 = 1.22917 loss)
I0525 06:28:29.652962 22762 sgd_solver.cpp:106] Iteration 66566, lr = 0.001
I0525 06:28:33.542176 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_66640.caffemodel
I0525 06:28:33.618080 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_66640.solverstate
I0525 06:28:34.675515 22762 solver.cpp:341] Iteration 66660, Testing net (#0)
I0525 06:29:42.746178 22762 solver.cpp:409]     Test net output #0: accuracy = 0.868397
I0525 06:29:42.746378 22762 solver.cpp:409]     Test net output #1: loss = 0.432006 (* 1 = 0.432006 loss)
I0525 06:30:07.474891 22762 solver.cpp:237] Iteration 66732, loss = 1.2667
I0525 06:30:07.474951 22762 solver.cpp:253]     Train net output #0: loss = 1.2667 (* 1 = 1.2667 loss)
I0525 06:30:07.474970 22762 sgd_solver.cpp:106] Iteration 66732, lr = 0.001
I0525 06:30:16.316303 22762 solver.cpp:237] Iteration 66898, loss = 1.27862
I0525 06:30:16.316488 22762 solver.cpp:253]     Train net output #0: loss = 1.27862 (* 1 = 1.27862 loss)
I0525 06:30:16.316504 22762 sgd_solver.cpp:106] Iteration 66898, lr = 0.001
I0525 06:30:25.156842 22762 solver.cpp:237] Iteration 67064, loss = 1.16701
I0525 06:30:25.156879 22762 solver.cpp:253]     Train net output #0: loss = 1.16701 (* 1 = 1.16701 loss)
I0525 06:30:25.156898 22762 sgd_solver.cpp:106] Iteration 67064, lr = 0.001
I0525 06:30:34.005843 22762 solver.cpp:237] Iteration 67230, loss = 1.21205
I0525 06:30:34.005897 22762 solver.cpp:253]     Train net output #0: loss = 1.21205 (* 1 = 1.21205 loss)
I0525 06:30:34.005923 22762 sgd_solver.cpp:106] Iteration 67230, lr = 0.001
I0525 06:30:42.851320 22762 solver.cpp:237] Iteration 67396, loss = 1.27839
I0525 06:30:42.851356 22762 solver.cpp:253]     Train net output #0: loss = 1.27839 (* 1 = 1.27839 loss)
I0525 06:30:42.851375 22762 sgd_solver.cpp:106] Iteration 67396, lr = 0.001
I0525 06:30:51.695315 22762 solver.cpp:237] Iteration 67562, loss = 1.33628
I0525 06:30:51.695514 22762 solver.cpp:253]     Train net output #0: loss = 1.33628 (* 1 = 1.33628 loss)
I0525 06:30:51.695531 22762 sgd_solver.cpp:106] Iteration 67562, lr = 0.001
I0525 06:31:00.533782 22762 solver.cpp:237] Iteration 67728, loss = 1.23421
I0525 06:31:00.533838 22762 solver.cpp:253]     Train net output #0: loss = 1.23421 (* 1 = 1.23421 loss)
I0525 06:31:00.533864 22762 sgd_solver.cpp:106] Iteration 67728, lr = 0.001
I0525 06:31:30.241258 22762 solver.cpp:237] Iteration 67894, loss = 1.17698
I0525 06:31:30.241472 22762 solver.cpp:253]     Train net output #0: loss = 1.17698 (* 1 = 1.17698 loss)
I0525 06:31:30.241490 22762 sgd_solver.cpp:106] Iteration 67894, lr = 0.001
I0525 06:31:39.086351 22762 solver.cpp:237] Iteration 68060, loss = 1.21214
I0525 06:31:39.086387 22762 solver.cpp:253]     Train net output #0: loss = 1.21214 (* 1 = 1.21214 loss)
I0525 06:31:39.086405 22762 sgd_solver.cpp:106] Iteration 68060, lr = 0.001
I0525 06:31:47.932211 22762 solver.cpp:237] Iteration 68226, loss = 1.33676
I0525 06:31:47.932270 22762 solver.cpp:253]     Train net output #0: loss = 1.33676 (* 1 = 1.33676 loss)
I0525 06:31:47.932288 22762 sgd_solver.cpp:106] Iteration 68226, lr = 0.001
I0525 06:31:52.140094 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_68306.caffemodel
I0525 06:31:52.214249 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_68306.solverstate
I0525 06:31:56.836339 22762 solver.cpp:237] Iteration 68392, loss = 1.29438
I0525 06:31:56.836393 22762 solver.cpp:253]     Train net output #0: loss = 1.29438 (* 1 = 1.29438 loss)
I0525 06:31:56.836419 22762 sgd_solver.cpp:106] Iteration 68392, lr = 0.001
I0525 06:32:05.676717 22762 solver.cpp:237] Iteration 68558, loss = 1.17737
I0525 06:32:05.676898 22762 solver.cpp:253]     Train net output #0: loss = 1.17737 (* 1 = 1.17737 loss)
I0525 06:32:05.676915 22762 sgd_solver.cpp:106] Iteration 68558, lr = 0.001
I0525 06:32:14.541431 22762 solver.cpp:237] Iteration 68724, loss = 1.26281
I0525 06:32:14.541486 22762 solver.cpp:253]     Train net output #0: loss = 1.26281 (* 1 = 1.26281 loss)
I0525 06:32:14.541510 22762 sgd_solver.cpp:106] Iteration 68724, lr = 0.001
I0525 06:32:44.222652 22762 solver.cpp:237] Iteration 68890, loss = 1.23901
I0525 06:32:44.222858 22762 solver.cpp:253]     Train net output #0: loss = 1.23901 (* 1 = 1.23901 loss)
I0525 06:32:44.222877 22762 sgd_solver.cpp:106] Iteration 68890, lr = 0.001
I0525 06:32:53.065271 22762 solver.cpp:237] Iteration 69056, loss = 1.22668
I0525 06:32:53.065309 22762 solver.cpp:253]     Train net output #0: loss = 1.22668 (* 1 = 1.22668 loss)
I0525 06:32:53.065327 22762 sgd_solver.cpp:106] Iteration 69056, lr = 0.001
I0525 06:33:01.908814 22762 solver.cpp:237] Iteration 69222, loss = 1.17007
I0525 06:33:01.908872 22762 solver.cpp:253]     Train net output #0: loss = 1.17007 (* 1 = 1.17007 loss)
I0525 06:33:01.908897 22762 sgd_solver.cpp:106] Iteration 69222, lr = 0.001
I0525 06:33:10.759196 22762 solver.cpp:237] Iteration 69388, loss = 1.32991
I0525 06:33:10.759232 22762 solver.cpp:253]     Train net output #0: loss = 1.32991 (* 1 = 1.32991 loss)
I0525 06:33:10.759249 22762 sgd_solver.cpp:106] Iteration 69388, lr = 0.001
I0525 06:33:19.603338 22762 solver.cpp:237] Iteration 69554, loss = 1.18613
I0525 06:33:19.603531 22762 solver.cpp:253]     Train net output #0: loss = 1.18613 (* 1 = 1.18613 loss)
I0525 06:33:19.603549 22762 sgd_solver.cpp:106] Iteration 69554, lr = 0.001
I0525 06:33:28.457748 22762 solver.cpp:237] Iteration 69720, loss = 1.19477
I0525 06:33:28.457808 22762 solver.cpp:253]     Train net output #0: loss = 1.19477 (* 1 = 1.19477 loss)
I0525 06:33:28.457833 22762 sgd_solver.cpp:106] Iteration 69720, lr = 0.001
I0525 06:33:37.304955 22762 solver.cpp:237] Iteration 69886, loss = 1.1101
I0525 06:33:37.304992 22762 solver.cpp:253]     Train net output #0: loss = 1.1101 (* 1 = 1.1101 loss)
I0525 06:33:37.305009 22762 sgd_solver.cpp:106] Iteration 69886, lr = 0.001
I0525 06:33:41.827989 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_69972.caffemodel
I0525 06:33:41.903458 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_69972.solverstate
I0525 06:33:43.014317 22762 solver.cpp:341] Iteration 69993, Testing net (#0)
I0525 06:34:30.293289 22762 solver.cpp:409]     Test net output #0: accuracy = 0.870891
I0525 06:34:30.293493 22762 solver.cpp:409]     Test net output #1: loss = 0.41621 (* 1 = 0.41621 loss)
I0525 06:34:54.328109 22762 solver.cpp:237] Iteration 70052, loss = 1.09288
I0525 06:34:54.328168 22762 solver.cpp:253]     Train net output #0: loss = 1.09288 (* 1 = 1.09288 loss)
I0525 06:34:54.328187 22762 sgd_solver.cpp:106] Iteration 70052, lr = 0.001
I0525 06:35:03.179831 22762 solver.cpp:237] Iteration 70218, loss = 1.26294
I0525 06:35:03.180016 22762 solver.cpp:253]     Train net output #0: loss = 1.26294 (* 1 = 1.26294 loss)
I0525 06:35:03.180033 22762 sgd_solver.cpp:106] Iteration 70218, lr = 0.001
I0525 06:35:12.036757 22762 solver.cpp:237] Iteration 70384, loss = 1.28412
I0525 06:35:12.036816 22762 solver.cpp:253]     Train net output #0: loss = 1.28412 (* 1 = 1.28412 loss)
I0525 06:35:12.036841 22762 sgd_solver.cpp:106] Iteration 70384, lr = 0.001
I0525 06:35:20.892814 22762 solver.cpp:237] Iteration 70550, loss = 1.23855
I0525 06:35:20.892853 22762 solver.cpp:253]     Train net output #0: loss = 1.23855 (* 1 = 1.23855 loss)
I0525 06:35:20.892869 22762 sgd_solver.cpp:106] Iteration 70550, lr = 0.001
I0525 06:35:29.763579 22762 solver.cpp:237] Iteration 70716, loss = 1.16141
I0525 06:35:29.763638 22762 solver.cpp:253]     Train net output #0: loss = 1.16141 (* 1 = 1.16141 loss)
I0525 06:35:29.763664 22762 sgd_solver.cpp:106] Iteration 70716, lr = 0.001
I0525 06:35:38.612172 22762 solver.cpp:237] Iteration 70882, loss = 1.05815
I0525 06:35:38.612357 22762 solver.cpp:253]     Train net output #0: loss = 1.05815 (* 1 = 1.05815 loss)
I0525 06:35:38.612375 22762 sgd_solver.cpp:106] Iteration 70882, lr = 0.001
I0525 06:35:47.449800 22762 solver.cpp:237] Iteration 71048, loss = 1.30666
I0525 06:35:47.449838 22762 solver.cpp:253]     Train net output #0: loss = 1.30666 (* 1 = 1.30666 loss)
I0525 06:35:47.449856 22762 sgd_solver.cpp:106] Iteration 71048, lr = 0.001
I0525 06:36:17.165988 22762 solver.cpp:237] Iteration 71214, loss = 1.23502
I0525 06:36:17.166195 22762 solver.cpp:253]     Train net output #0: loss = 1.23502 (* 1 = 1.23502 loss)
I0525 06:36:17.166213 22762 sgd_solver.cpp:106] Iteration 71214, lr = 0.001
I0525 06:36:26.012852 22762 solver.cpp:237] Iteration 71380, loss = 1.22989
I0525 06:36:26.012908 22762 solver.cpp:253]     Train net output #0: loss = 1.22989 (* 1 = 1.22989 loss)
I0525 06:36:26.012933 22762 sgd_solver.cpp:106] Iteration 71380, lr = 0.001
I0525 06:36:34.868434 22762 solver.cpp:237] Iteration 71546, loss = 1.26499
I0525 06:36:34.868471 22762 solver.cpp:253]     Train net output #0: loss = 1.26499 (* 1 = 1.26499 loss)
I0525 06:36:34.868489 22762 sgd_solver.cpp:106] Iteration 71546, lr = 0.001
I0525 06:36:39.717941 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_71638.caffemodel
I0525 06:36:39.792598 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_71638.solverstate
I0525 06:36:43.779989 22762 solver.cpp:237] Iteration 71712, loss = 1.59638
I0525 06:36:43.780046 22762 solver.cpp:253]     Train net output #0: loss = 1.59638 (* 1 = 1.59638 loss)
I0525 06:36:43.780064 22762 sgd_solver.cpp:106] Iteration 71712, lr = 0.001
I0525 06:36:52.628454 22762 solver.cpp:237] Iteration 71878, loss = 1.19001
I0525 06:36:52.628651 22762 solver.cpp:253]     Train net output #0: loss = 1.19001 (* 1 = 1.19001 loss)
I0525 06:36:52.628669 22762 sgd_solver.cpp:106] Iteration 71878, lr = 0.001
I0525 06:37:01.481063 22762 solver.cpp:237] Iteration 72044, loss = 1.20617
I0525 06:37:01.481101 22762 solver.cpp:253]     Train net output #0: loss = 1.20617 (* 1 = 1.20617 loss)
I0525 06:37:01.481118 22762 sgd_solver.cpp:106] Iteration 72044, lr = 0.001
I0525 06:37:10.322123 22762 solver.cpp:237] Iteration 72210, loss = 1.30886
I0525 06:37:10.322178 22762 solver.cpp:253]     Train net output #0: loss = 1.30886 (* 1 = 1.30886 loss)
I0525 06:37:10.322204 22762 sgd_solver.cpp:106] Iteration 72210, lr = 0.001
I0525 06:37:40.012063 22762 solver.cpp:237] Iteration 72376, loss = 1.3731
I0525 06:37:40.012274 22762 solver.cpp:253]     Train net output #0: loss = 1.3731 (* 1 = 1.3731 loss)
I0525 06:37:40.012291 22762 sgd_solver.cpp:106] Iteration 72376, lr = 0.001
I0525 06:37:48.856294 22762 solver.cpp:237] Iteration 72542, loss = 1.26314
I0525 06:37:48.856331 22762 solver.cpp:253]     Train net output #0: loss = 1.26314 (* 1 = 1.26314 loss)
I0525 06:37:48.856354 22762 sgd_solver.cpp:106] Iteration 72542, lr = 0.001
I0525 06:37:57.702738 22762 solver.cpp:237] Iteration 72708, loss = 1.02568
I0525 06:37:57.702774 22762 solver.cpp:253]     Train net output #0: loss = 1.02568 (* 1 = 1.02568 loss)
I0525 06:37:57.702791 22762 sgd_solver.cpp:106] Iteration 72708, lr = 0.001
I0525 06:38:06.551208 22762 solver.cpp:237] Iteration 72874, loss = 1.34899
I0525 06:38:06.551252 22762 solver.cpp:253]     Train net output #0: loss = 1.34899 (* 1 = 1.34899 loss)
I0525 06:38:06.551280 22762 sgd_solver.cpp:106] Iteration 72874, lr = 0.001
I0525 06:38:15.399646 22762 solver.cpp:237] Iteration 73040, loss = 1.10115
I0525 06:38:15.399828 22762 solver.cpp:253]     Train net output #0: loss = 1.10115 (* 1 = 1.10115 loss)
I0525 06:38:15.399845 22762 sgd_solver.cpp:106] Iteration 73040, lr = 0.001
I0525 06:38:24.249415 22762 solver.cpp:237] Iteration 73206, loss = 1.17164
I0525 06:38:24.249471 22762 solver.cpp:253]     Train net output #0: loss = 1.17164 (* 1 = 1.17164 loss)
I0525 06:38:24.249496 22762 sgd_solver.cpp:106] Iteration 73206, lr = 0.001
I0525 06:38:29.421632 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_73304.caffemodel
I0525 06:38:29.495983 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_73304.solverstate
I0525 06:38:30.660734 22762 solver.cpp:341] Iteration 73326, Testing net (#0)
I0525 06:39:38.738653 22762 solver.cpp:409]     Test net output #0: accuracy = 0.872378
I0525 06:39:38.738857 22762 solver.cpp:409]     Test net output #1: loss = 0.42905 (* 1 = 0.42905 loss)
I0525 06:40:02.048849 22762 solver.cpp:237] Iteration 73372, loss = 1.28612
I0525 06:40:02.048909 22762 solver.cpp:253]     Train net output #0: loss = 1.28612 (* 1 = 1.28612 loss)
I0525 06:40:02.048928 22762 sgd_solver.cpp:106] Iteration 73372, lr = 0.001
I0525 06:40:10.902034 22762 solver.cpp:237] Iteration 73538, loss = 1.07202
I0525 06:40:10.902245 22762 solver.cpp:253]     Train net output #0: loss = 1.07202 (* 1 = 1.07202 loss)
I0525 06:40:10.902262 22762 sgd_solver.cpp:106] Iteration 73538, lr = 0.001
I0525 06:40:19.751010 22762 solver.cpp:237] Iteration 73704, loss = 0.911031
I0525 06:40:19.751047 22762 solver.cpp:253]     Train net output #0: loss = 0.911031 (* 1 = 0.911031 loss)
I0525 06:40:19.751065 22762 sgd_solver.cpp:106] Iteration 73704, lr = 0.001
I0525 06:40:28.605010 22762 solver.cpp:237] Iteration 73870, loss = 1.33046
I0525 06:40:28.605047 22762 solver.cpp:253]     Train net output #0: loss = 1.33046 (* 1 = 1.33046 loss)
I0525 06:40:28.605064 22762 sgd_solver.cpp:106] Iteration 73870, lr = 0.001
I0525 06:40:37.458798 22762 solver.cpp:237] Iteration 74036, loss = 1.24793
I0525 06:40:37.458850 22762 solver.cpp:253]     Train net output #0: loss = 1.24793 (* 1 = 1.24793 loss)
I0525 06:40:37.458876 22762 sgd_solver.cpp:106] Iteration 74036, lr = 0.001
I0525 06:40:46.311290 22762 solver.cpp:237] Iteration 74202, loss = 1.15102
I0525 06:40:46.311476 22762 solver.cpp:253]     Train net output #0: loss = 1.15102 (* 1 = 1.15102 loss)
I0525 06:40:46.311492 22762 sgd_solver.cpp:106] Iteration 74202, lr = 0.001
I0525 06:40:55.162166 22762 solver.cpp:237] Iteration 74368, loss = 1.21835
I0525 06:40:55.162220 22762 solver.cpp:253]     Train net output #0: loss = 1.21835 (* 1 = 1.21835 loss)
I0525 06:40:55.162246 22762 sgd_solver.cpp:106] Iteration 74368, lr = 0.001
I0525 06:41:24.870615 22762 solver.cpp:237] Iteration 74534, loss = 1.39394
I0525 06:41:24.870831 22762 solver.cpp:253]     Train net output #0: loss = 1.39394 (* 1 = 1.39394 loss)
I0525 06:41:24.870848 22762 sgd_solver.cpp:106] Iteration 74534, lr = 0.001
I0525 06:41:33.719956 22762 solver.cpp:237] Iteration 74700, loss = 1.19585
I0525 06:41:33.719995 22762 solver.cpp:253]     Train net output #0: loss = 1.19585 (* 1 = 1.19585 loss)
I0525 06:41:33.720012 22762 sgd_solver.cpp:106] Iteration 74700, lr = 0.001
I0525 06:41:42.569561 22762 solver.cpp:237] Iteration 74866, loss = 1.15803
I0525 06:41:42.569597 22762 solver.cpp:253]     Train net output #0: loss = 1.15803 (* 1 = 1.15803 loss)
I0525 06:41:42.569615 22762 sgd_solver.cpp:106] Iteration 74866, lr = 0.001
I0525 06:41:48.063334 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_74970.caffemodel
I0525 06:41:48.139667 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_74970.solverstate
I0525 06:41:51.493187 22762 solver.cpp:237] Iteration 75032, loss = 1.1614
I0525 06:41:51.493243 22762 solver.cpp:253]     Train net output #0: loss = 1.1614 (* 1 = 1.1614 loss)
I0525 06:41:51.493270 22762 sgd_solver.cpp:106] Iteration 75032, lr = 0.001
I0525 06:42:00.353571 22762 solver.cpp:237] Iteration 75198, loss = 1.09438
I0525 06:42:00.353760 22762 solver.cpp:253]     Train net output #0: loss = 1.09438 (* 1 = 1.09438 loss)
I0525 06:42:00.353776 22762 sgd_solver.cpp:106] Iteration 75198, lr = 0.001
I0525 06:42:09.206511 22762 solver.cpp:237] Iteration 75364, loss = 1.25789
I0525 06:42:09.206568 22762 solver.cpp:253]     Train net output #0: loss = 1.25789 (* 1 = 1.25789 loss)
I0525 06:42:09.206598 22762 sgd_solver.cpp:106] Iteration 75364, lr = 0.001
I0525 06:42:18.058225 22762 solver.cpp:237] Iteration 75530, loss = 1.23211
I0525 06:42:18.058262 22762 solver.cpp:253]     Train net output #0: loss = 1.23211 (* 1 = 1.23211 loss)
I0525 06:42:18.058279 22762 sgd_solver.cpp:106] Iteration 75530, lr = 0.001
I0525 06:42:47.761790 22762 solver.cpp:237] Iteration 75696, loss = 1.29076
I0525 06:42:47.761997 22762 solver.cpp:253]     Train net output #0: loss = 1.29076 (* 1 = 1.29076 loss)
I0525 06:42:47.762014 22762 sgd_solver.cpp:106] Iteration 75696, lr = 0.001
I0525 06:42:56.620703 22762 solver.cpp:237] Iteration 75862, loss = 1.4488
I0525 06:42:56.620739 22762 solver.cpp:253]     Train net output #0: loss = 1.4488 (* 1 = 1.4488 loss)
I0525 06:42:56.620759 22762 sgd_solver.cpp:106] Iteration 75862, lr = 0.001
I0525 06:43:05.471285 22762 solver.cpp:237] Iteration 76028, loss = 1.39596
I0525 06:43:05.471338 22762 solver.cpp:253]     Train net output #0: loss = 1.39596 (* 1 = 1.39596 loss)
I0525 06:43:05.471369 22762 sgd_solver.cpp:106] Iteration 76028, lr = 0.001
I0525 06:43:14.308902 22762 solver.cpp:237] Iteration 76194, loss = 1.15001
I0525 06:43:14.308940 22762 solver.cpp:253]     Train net output #0: loss = 1.15001 (* 1 = 1.15001 loss)
I0525 06:43:14.308957 22762 sgd_solver.cpp:106] Iteration 76194, lr = 0.001
I0525 06:43:23.155308 22762 solver.cpp:237] Iteration 76360, loss = 1.15182
I0525 06:43:23.155503 22762 solver.cpp:253]     Train net output #0: loss = 1.15182 (* 1 = 1.15182 loss)
I0525 06:43:23.155519 22762 sgd_solver.cpp:106] Iteration 76360, lr = 0.001
I0525 06:43:32.001889 22762 solver.cpp:237] Iteration 76526, loss = 1.25275
I0525 06:43:32.001946 22762 solver.cpp:253]     Train net output #0: loss = 1.25275 (* 1 = 1.25275 loss)
I0525 06:43:32.001965 22762 sgd_solver.cpp:106] Iteration 76526, lr = 0.001
I0525 06:43:37.810448 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_76636.caffemodel
I0525 06:43:37.885113 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_76636.solverstate
I0525 06:43:39.099411 22762 solver.cpp:341] Iteration 76659, Testing net (#0)
I0525 06:44:26.021138 22762 solver.cpp:409]     Test net output #0: accuracy = 0.873213
I0525 06:44:26.021349 22762 solver.cpp:409]     Test net output #1: loss = 0.411 (* 1 = 0.411 loss)
I0525 06:44:48.693130 22762 solver.cpp:237] Iteration 76692, loss = 1.13677
I0525 06:44:48.693192 22762 solver.cpp:253]     Train net output #0: loss = 1.13677 (* 1 = 1.13677 loss)
I0525 06:44:48.693210 22762 sgd_solver.cpp:106] Iteration 76692, lr = 0.001
I0525 06:44:57.547425 22762 solver.cpp:237] Iteration 76858, loss = 1.51284
I0525 06:44:57.547613 22762 solver.cpp:253]     Train net output #0: loss = 1.51284 (* 1 = 1.51284 loss)
I0525 06:44:57.547631 22762 sgd_solver.cpp:106] Iteration 76858, lr = 0.001
I0525 06:45:06.407500 22762 solver.cpp:237] Iteration 77024, loss = 1.3305
I0525 06:45:06.407558 22762 solver.cpp:253]     Train net output #0: loss = 1.3305 (* 1 = 1.3305 loss)
I0525 06:45:06.407582 22762 sgd_solver.cpp:106] Iteration 77024, lr = 0.001
I0525 06:45:15.262842 22762 solver.cpp:237] Iteration 77190, loss = 1.25544
I0525 06:45:15.262879 22762 solver.cpp:253]     Train net output #0: loss = 1.25544 (* 1 = 1.25544 loss)
I0525 06:45:15.262897 22762 sgd_solver.cpp:106] Iteration 77190, lr = 0.001
I0525 06:45:24.105779 22762 solver.cpp:237] Iteration 77356, loss = 1.07067
I0525 06:45:24.105816 22762 solver.cpp:253]     Train net output #0: loss = 1.07067 (* 1 = 1.07067 loss)
I0525 06:45:24.105834 22762 sgd_solver.cpp:106] Iteration 77356, lr = 0.001
I0525 06:45:32.955118 22762 solver.cpp:237] Iteration 77522, loss = 1.48553
I0525 06:45:32.955327 22762 solver.cpp:253]     Train net output #0: loss = 1.48553 (* 1 = 1.48553 loss)
I0525 06:45:32.955346 22762 sgd_solver.cpp:106] Iteration 77522, lr = 0.001
I0525 06:45:41.809505 22762 solver.cpp:237] Iteration 77688, loss = 1.31311
I0525 06:45:41.809542 22762 solver.cpp:253]     Train net output #0: loss = 1.31311 (* 1 = 1.31311 loss)
I0525 06:45:41.809559 22762 sgd_solver.cpp:106] Iteration 77688, lr = 0.001
I0525 06:46:11.561180 22762 solver.cpp:237] Iteration 77854, loss = 1.18959
I0525 06:46:11.561390 22762 solver.cpp:253]     Train net output #0: loss = 1.18959 (* 1 = 1.18959 loss)
I0525 06:46:11.561408 22762 sgd_solver.cpp:106] Iteration 77854, lr = 0.001
I0525 06:46:20.416484 22762 solver.cpp:237] Iteration 78020, loss = 1.31423
I0525 06:46:20.416543 22762 solver.cpp:253]     Train net output #0: loss = 1.31423 (* 1 = 1.31423 loss)
I0525 06:46:20.416566 22762 sgd_solver.cpp:106] Iteration 78020, lr = 0.001
I0525 06:46:29.273587 22762 solver.cpp:237] Iteration 78186, loss = 1.08177
I0525 06:46:29.273623 22762 solver.cpp:253]     Train net output #0: loss = 1.08177 (* 1 = 1.08177 loss)
I0525 06:46:29.273643 22762 sgd_solver.cpp:106] Iteration 78186, lr = 0.001
I0525 06:46:35.418905 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_78302.caffemodel
I0525 06:46:35.539099 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_78302.solverstate
I0525 06:46:38.251255 22762 solver.cpp:237] Iteration 78352, loss = 1.27728
I0525 06:46:38.251310 22762 solver.cpp:253]     Train net output #0: loss = 1.27728 (* 1 = 1.27728 loss)
I0525 06:46:38.251334 22762 sgd_solver.cpp:106] Iteration 78352, lr = 0.001
I0525 06:46:47.102319 22762 solver.cpp:237] Iteration 78518, loss = 1.01144
I0525 06:46:47.102533 22762 solver.cpp:253]     Train net output #0: loss = 1.01144 (* 1 = 1.01144 loss)
I0525 06:46:47.102551 22762 sgd_solver.cpp:106] Iteration 78518, lr = 0.001
I0525 06:46:55.961885 22762 solver.cpp:237] Iteration 78684, loss = 1.15129
I0525 06:46:55.961922 22762 solver.cpp:253]     Train net output #0: loss = 1.15129 (* 1 = 1.15129 loss)
I0525 06:46:55.961941 22762 sgd_solver.cpp:106] Iteration 78684, lr = 0.001
I0525 06:47:04.817400 22762 solver.cpp:237] Iteration 78850, loss = 1.29118
I0525 06:47:04.817437 22762 solver.cpp:253]     Train net output #0: loss = 1.29118 (* 1 = 1.29118 loss)
I0525 06:47:04.817456 22762 sgd_solver.cpp:106] Iteration 78850, lr = 0.001
I0525 06:47:34.557198 22762 solver.cpp:237] Iteration 79016, loss = 1.26362
I0525 06:47:34.557401 22762 solver.cpp:253]     Train net output #0: loss = 1.26362 (* 1 = 1.26362 loss)
I0525 06:47:34.557420 22762 sgd_solver.cpp:106] Iteration 79016, lr = 0.001
I0525 06:47:43.420509 22762 solver.cpp:237] Iteration 79182, loss = 1.31168
I0525 06:47:43.420547 22762 solver.cpp:253]     Train net output #0: loss = 1.31168 (* 1 = 1.31168 loss)
I0525 06:47:43.420564 22762 sgd_solver.cpp:106] Iteration 79182, lr = 0.001
I0525 06:47:52.281733 22762 solver.cpp:237] Iteration 79348, loss = 1.18625
I0525 06:47:52.281771 22762 solver.cpp:253]     Train net output #0: loss = 1.18625 (* 1 = 1.18625 loss)
I0525 06:47:52.281795 22762 sgd_solver.cpp:106] Iteration 79348, lr = 0.001
I0525 06:48:01.149042 22762 solver.cpp:237] Iteration 79514, loss = 1.15393
I0525 06:48:01.149101 22762 solver.cpp:253]     Train net output #0: loss = 1.15393 (* 1 = 1.15393 loss)
I0525 06:48:01.149127 22762 sgd_solver.cpp:106] Iteration 79514, lr = 0.001
I0525 06:48:10.009927 22762 solver.cpp:237] Iteration 79680, loss = 1.2162
I0525 06:48:10.010123 22762 solver.cpp:253]     Train net output #0: loss = 1.2162 (* 1 = 1.2162 loss)
I0525 06:48:10.010139 22762 sgd_solver.cpp:106] Iteration 79680, lr = 0.001
I0525 06:48:18.866885 22762 solver.cpp:237] Iteration 79846, loss = 1.00236
I0525 06:48:18.866922 22762 solver.cpp:253]     Train net output #0: loss = 1.00236 (* 1 = 1.00236 loss)
I0525 06:48:18.866940 22762 sgd_solver.cpp:106] Iteration 79846, lr = 0.001
I0525 06:48:25.326752 22762 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_79968.caffemodel
I0525 06:48:25.401605 22762 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_90_lr_0.0010_2016-05-20T15.49.20.538439_iter_79968.solverstate
I0525 06:48:26.674849 22762 solver.cpp:341] Iteration 79992, Testing net (#0)
aprun: Apid 11262726: Caught signal Terminated, sending to application
*** Aborted at 1464173348 (unix time) try "date -d @1464173348" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x58e7) received by PID 22762 (TID 0x2aaac746f900) from PID 22759; stack trace: ***
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
=>> PBS: job killed: walltime 7226 exceeded limit 7200
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @           0x60ee80 caffe::caffe_gpu_memcpy()
    @           0x5eb930 caffe::SyncedMemory::to_gpu()
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @           0x5eab39 caffe::SyncedMemory::gpu_data()
    @           0x49ae02 caffe::Blob<>::gpu_data()
    @           0x630967 caffe::InnerProductLayer<>::Forward_gpu()
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @           0x5ca001 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11262726: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11262726: Caught signal Terminated, sending to application
aprun: Apid 11262726: Caught signal Terminated, sending to application
aprun: Apid 11262726: Caught signal Terminated, sending to application
aprun: Apid 11262726: Caught signal Terminated, sending to application
aprun: Apid 11262726: Caught signal Terminated, sending to application
aprun: Apid 11262726: Caught signal Terminated, sending to application
