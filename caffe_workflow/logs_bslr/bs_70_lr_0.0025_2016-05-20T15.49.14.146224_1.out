2805630
I0520 18:13:17.789866 23162 caffe.cpp:184] Using GPUs 0
I0520 18:13:18.215888 23162 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2142
test_interval: 4285
base_lr: 0.0025
display: 214
max_iter: 214280
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 2142
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224.prototxt"
I0520 18:13:18.217689 23162 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224.prototxt
I0520 18:13:18.229358 23162 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0520 18:13:18.229418 23162 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0520 18:13:18.229764 23162 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0520 18:13:18.229945 23162 layer_factory.hpp:77] Creating layer data_hdf5
I0520 18:13:18.229969 23162 net.cpp:106] Creating Layer data_hdf5
I0520 18:13:18.229984 23162 net.cpp:411] data_hdf5 -> data
I0520 18:13:18.230016 23162 net.cpp:411] data_hdf5 -> label
I0520 18:13:18.230049 23162 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0520 18:13:18.245065 23162 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0520 18:13:18.266558 23162 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0520 18:13:39.887646 23162 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0520 18:13:39.892722 23162 net.cpp:150] Setting up data_hdf5
I0520 18:13:39.892762 23162 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0520 18:13:39.892777 23162 net.cpp:157] Top shape: 70 (70)
I0520 18:13:39.892791 23162 net.cpp:165] Memory required for data: 1778280
I0520 18:13:39.892804 23162 layer_factory.hpp:77] Creating layer conv1
I0520 18:13:39.892838 23162 net.cpp:106] Creating Layer conv1
I0520 18:13:39.892849 23162 net.cpp:454] conv1 <- data
I0520 18:13:39.892869 23162 net.cpp:411] conv1 -> conv1
I0520 18:13:42.972292 23162 net.cpp:150] Setting up conv1
I0520 18:13:42.972338 23162 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0520 18:13:42.972349 23162 net.cpp:165] Memory required for data: 21131880
I0520 18:13:42.972378 23162 layer_factory.hpp:77] Creating layer relu1
I0520 18:13:42.972399 23162 net.cpp:106] Creating Layer relu1
I0520 18:13:42.972410 23162 net.cpp:454] relu1 <- conv1
I0520 18:13:42.972424 23162 net.cpp:397] relu1 -> conv1 (in-place)
I0520 18:13:42.972940 23162 net.cpp:150] Setting up relu1
I0520 18:13:42.972957 23162 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0520 18:13:42.972968 23162 net.cpp:165] Memory required for data: 40485480
I0520 18:13:42.972978 23162 layer_factory.hpp:77] Creating layer pool1
I0520 18:13:42.972995 23162 net.cpp:106] Creating Layer pool1
I0520 18:13:42.973006 23162 net.cpp:454] pool1 <- conv1
I0520 18:13:42.973018 23162 net.cpp:411] pool1 -> pool1
I0520 18:13:42.973098 23162 net.cpp:150] Setting up pool1
I0520 18:13:42.973111 23162 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0520 18:13:42.973121 23162 net.cpp:165] Memory required for data: 50162280
I0520 18:13:42.973132 23162 layer_factory.hpp:77] Creating layer conv2
I0520 18:13:42.973155 23162 net.cpp:106] Creating Layer conv2
I0520 18:13:42.973165 23162 net.cpp:454] conv2 <- pool1
I0520 18:13:42.973178 23162 net.cpp:411] conv2 -> conv2
I0520 18:13:42.975905 23162 net.cpp:150] Setting up conv2
I0520 18:13:42.975932 23162 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0520 18:13:42.975944 23162 net.cpp:165] Memory required for data: 64072680
I0520 18:13:42.975962 23162 layer_factory.hpp:77] Creating layer relu2
I0520 18:13:42.975976 23162 net.cpp:106] Creating Layer relu2
I0520 18:13:42.975987 23162 net.cpp:454] relu2 <- conv2
I0520 18:13:42.975999 23162 net.cpp:397] relu2 -> conv2 (in-place)
I0520 18:13:42.976341 23162 net.cpp:150] Setting up relu2
I0520 18:13:42.976354 23162 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0520 18:13:42.976364 23162 net.cpp:165] Memory required for data: 77983080
I0520 18:13:42.976375 23162 layer_factory.hpp:77] Creating layer pool2
I0520 18:13:42.976387 23162 net.cpp:106] Creating Layer pool2
I0520 18:13:42.976397 23162 net.cpp:454] pool2 <- conv2
I0520 18:13:42.976410 23162 net.cpp:411] pool2 -> pool2
I0520 18:13:42.976492 23162 net.cpp:150] Setting up pool2
I0520 18:13:42.976505 23162 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0520 18:13:42.976516 23162 net.cpp:165] Memory required for data: 84938280
I0520 18:13:42.976523 23162 layer_factory.hpp:77] Creating layer conv3
I0520 18:13:42.976542 23162 net.cpp:106] Creating Layer conv3
I0520 18:13:42.976552 23162 net.cpp:454] conv3 <- pool2
I0520 18:13:42.976565 23162 net.cpp:411] conv3 -> conv3
I0520 18:13:42.978477 23162 net.cpp:150] Setting up conv3
I0520 18:13:42.978497 23162 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0520 18:13:42.978507 23162 net.cpp:165] Memory required for data: 92527400
I0520 18:13:42.978525 23162 layer_factory.hpp:77] Creating layer relu3
I0520 18:13:42.978541 23162 net.cpp:106] Creating Layer relu3
I0520 18:13:42.978550 23162 net.cpp:454] relu3 <- conv3
I0520 18:13:42.978564 23162 net.cpp:397] relu3 -> conv3 (in-place)
I0520 18:13:42.979028 23162 net.cpp:150] Setting up relu3
I0520 18:13:42.979045 23162 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0520 18:13:42.979055 23162 net.cpp:165] Memory required for data: 100116520
I0520 18:13:42.979066 23162 layer_factory.hpp:77] Creating layer pool3
I0520 18:13:42.979079 23162 net.cpp:106] Creating Layer pool3
I0520 18:13:42.979089 23162 net.cpp:454] pool3 <- conv3
I0520 18:13:42.979101 23162 net.cpp:411] pool3 -> pool3
I0520 18:13:42.979169 23162 net.cpp:150] Setting up pool3
I0520 18:13:42.979182 23162 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0520 18:13:42.979192 23162 net.cpp:165] Memory required for data: 103911080
I0520 18:13:42.979202 23162 layer_factory.hpp:77] Creating layer conv4
I0520 18:13:42.979218 23162 net.cpp:106] Creating Layer conv4
I0520 18:13:42.979228 23162 net.cpp:454] conv4 <- pool3
I0520 18:13:42.979243 23162 net.cpp:411] conv4 -> conv4
I0520 18:13:42.982002 23162 net.cpp:150] Setting up conv4
I0520 18:13:42.982030 23162 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0520 18:13:42.982041 23162 net.cpp:165] Memory required for data: 106451240
I0520 18:13:42.982059 23162 layer_factory.hpp:77] Creating layer relu4
I0520 18:13:42.982072 23162 net.cpp:106] Creating Layer relu4
I0520 18:13:42.982084 23162 net.cpp:454] relu4 <- conv4
I0520 18:13:42.982096 23162 net.cpp:397] relu4 -> conv4 (in-place)
I0520 18:13:42.982566 23162 net.cpp:150] Setting up relu4
I0520 18:13:42.982583 23162 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0520 18:13:42.982594 23162 net.cpp:165] Memory required for data: 108991400
I0520 18:13:42.982604 23162 layer_factory.hpp:77] Creating layer pool4
I0520 18:13:42.982617 23162 net.cpp:106] Creating Layer pool4
I0520 18:13:42.982627 23162 net.cpp:454] pool4 <- conv4
I0520 18:13:42.982641 23162 net.cpp:411] pool4 -> pool4
I0520 18:13:42.982709 23162 net.cpp:150] Setting up pool4
I0520 18:13:42.982723 23162 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0520 18:13:42.982733 23162 net.cpp:165] Memory required for data: 110261480
I0520 18:13:42.982745 23162 layer_factory.hpp:77] Creating layer ip1
I0520 18:13:42.982765 23162 net.cpp:106] Creating Layer ip1
I0520 18:13:42.982775 23162 net.cpp:454] ip1 <- pool4
I0520 18:13:42.982789 23162 net.cpp:411] ip1 -> ip1
I0520 18:13:42.998174 23162 net.cpp:150] Setting up ip1
I0520 18:13:42.998200 23162 net.cpp:157] Top shape: 70 196 (13720)
I0520 18:13:42.998214 23162 net.cpp:165] Memory required for data: 110316360
I0520 18:13:42.998241 23162 layer_factory.hpp:77] Creating layer relu5
I0520 18:13:42.998256 23162 net.cpp:106] Creating Layer relu5
I0520 18:13:42.998266 23162 net.cpp:454] relu5 <- ip1
I0520 18:13:42.998280 23162 net.cpp:397] relu5 -> ip1 (in-place)
I0520 18:13:42.998620 23162 net.cpp:150] Setting up relu5
I0520 18:13:42.998633 23162 net.cpp:157] Top shape: 70 196 (13720)
I0520 18:13:42.998643 23162 net.cpp:165] Memory required for data: 110371240
I0520 18:13:42.998654 23162 layer_factory.hpp:77] Creating layer drop1
I0520 18:13:42.998675 23162 net.cpp:106] Creating Layer drop1
I0520 18:13:42.998685 23162 net.cpp:454] drop1 <- ip1
I0520 18:13:42.998698 23162 net.cpp:397] drop1 -> ip1 (in-place)
I0520 18:13:42.998759 23162 net.cpp:150] Setting up drop1
I0520 18:13:42.998772 23162 net.cpp:157] Top shape: 70 196 (13720)
I0520 18:13:42.998782 23162 net.cpp:165] Memory required for data: 110426120
I0520 18:13:42.998792 23162 layer_factory.hpp:77] Creating layer ip2
I0520 18:13:42.998811 23162 net.cpp:106] Creating Layer ip2
I0520 18:13:42.998821 23162 net.cpp:454] ip2 <- ip1
I0520 18:13:42.998833 23162 net.cpp:411] ip2 -> ip2
I0520 18:13:42.999295 23162 net.cpp:150] Setting up ip2
I0520 18:13:42.999308 23162 net.cpp:157] Top shape: 70 98 (6860)
I0520 18:13:42.999318 23162 net.cpp:165] Memory required for data: 110453560
I0520 18:13:42.999333 23162 layer_factory.hpp:77] Creating layer relu6
I0520 18:13:42.999346 23162 net.cpp:106] Creating Layer relu6
I0520 18:13:42.999356 23162 net.cpp:454] relu6 <- ip2
I0520 18:13:42.999367 23162 net.cpp:397] relu6 -> ip2 (in-place)
I0520 18:13:42.999882 23162 net.cpp:150] Setting up relu6
I0520 18:13:42.999898 23162 net.cpp:157] Top shape: 70 98 (6860)
I0520 18:13:42.999909 23162 net.cpp:165] Memory required for data: 110481000
I0520 18:13:42.999919 23162 layer_factory.hpp:77] Creating layer drop2
I0520 18:13:42.999933 23162 net.cpp:106] Creating Layer drop2
I0520 18:13:42.999943 23162 net.cpp:454] drop2 <- ip2
I0520 18:13:42.999954 23162 net.cpp:397] drop2 -> ip2 (in-place)
I0520 18:13:42.999997 23162 net.cpp:150] Setting up drop2
I0520 18:13:43.000010 23162 net.cpp:157] Top shape: 70 98 (6860)
I0520 18:13:43.000020 23162 net.cpp:165] Memory required for data: 110508440
I0520 18:13:43.000030 23162 layer_factory.hpp:77] Creating layer ip3
I0520 18:13:43.000044 23162 net.cpp:106] Creating Layer ip3
I0520 18:13:43.000053 23162 net.cpp:454] ip3 <- ip2
I0520 18:13:43.000066 23162 net.cpp:411] ip3 -> ip3
I0520 18:13:43.000284 23162 net.cpp:150] Setting up ip3
I0520 18:13:43.000296 23162 net.cpp:157] Top shape: 70 11 (770)
I0520 18:13:43.000306 23162 net.cpp:165] Memory required for data: 110511520
I0520 18:13:43.000322 23162 layer_factory.hpp:77] Creating layer drop3
I0520 18:13:43.000334 23162 net.cpp:106] Creating Layer drop3
I0520 18:13:43.000344 23162 net.cpp:454] drop3 <- ip3
I0520 18:13:43.000356 23162 net.cpp:397] drop3 -> ip3 (in-place)
I0520 18:13:43.000396 23162 net.cpp:150] Setting up drop3
I0520 18:13:43.000409 23162 net.cpp:157] Top shape: 70 11 (770)
I0520 18:13:43.000421 23162 net.cpp:165] Memory required for data: 110514600
I0520 18:13:43.000429 23162 layer_factory.hpp:77] Creating layer loss
I0520 18:13:43.000448 23162 net.cpp:106] Creating Layer loss
I0520 18:13:43.000458 23162 net.cpp:454] loss <- ip3
I0520 18:13:43.000469 23162 net.cpp:454] loss <- label
I0520 18:13:43.000483 23162 net.cpp:411] loss -> loss
I0520 18:13:43.000499 23162 layer_factory.hpp:77] Creating layer loss
I0520 18:13:43.001140 23162 net.cpp:150] Setting up loss
I0520 18:13:43.001162 23162 net.cpp:157] Top shape: (1)
I0520 18:13:43.001175 23162 net.cpp:160]     with loss weight 1
I0520 18:13:43.001219 23162 net.cpp:165] Memory required for data: 110514604
I0520 18:13:43.001230 23162 net.cpp:226] loss needs backward computation.
I0520 18:13:43.001240 23162 net.cpp:226] drop3 needs backward computation.
I0520 18:13:43.001250 23162 net.cpp:226] ip3 needs backward computation.
I0520 18:13:43.001260 23162 net.cpp:226] drop2 needs backward computation.
I0520 18:13:43.001271 23162 net.cpp:226] relu6 needs backward computation.
I0520 18:13:43.001281 23162 net.cpp:226] ip2 needs backward computation.
I0520 18:13:43.001291 23162 net.cpp:226] drop1 needs backward computation.
I0520 18:13:43.001301 23162 net.cpp:226] relu5 needs backward computation.
I0520 18:13:43.001309 23162 net.cpp:226] ip1 needs backward computation.
I0520 18:13:43.001319 23162 net.cpp:226] pool4 needs backward computation.
I0520 18:13:43.001330 23162 net.cpp:226] relu4 needs backward computation.
I0520 18:13:43.001340 23162 net.cpp:226] conv4 needs backward computation.
I0520 18:13:43.001350 23162 net.cpp:226] pool3 needs backward computation.
I0520 18:13:43.001361 23162 net.cpp:226] relu3 needs backward computation.
I0520 18:13:43.001380 23162 net.cpp:226] conv3 needs backward computation.
I0520 18:13:43.001392 23162 net.cpp:226] pool2 needs backward computation.
I0520 18:13:43.001402 23162 net.cpp:226] relu2 needs backward computation.
I0520 18:13:43.001412 23162 net.cpp:226] conv2 needs backward computation.
I0520 18:13:43.001423 23162 net.cpp:226] pool1 needs backward computation.
I0520 18:13:43.001433 23162 net.cpp:226] relu1 needs backward computation.
I0520 18:13:43.001443 23162 net.cpp:226] conv1 needs backward computation.
I0520 18:13:43.001454 23162 net.cpp:228] data_hdf5 does not need backward computation.
I0520 18:13:43.001464 23162 net.cpp:270] This network produces output loss
I0520 18:13:43.001488 23162 net.cpp:283] Network initialization done.
I0520 18:13:43.003305 23162 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224.prototxt
I0520 18:13:43.003376 23162 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0520 18:13:43.003734 23162 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 70
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0520 18:13:43.003921 23162 layer_factory.hpp:77] Creating layer data_hdf5
I0520 18:13:43.003937 23162 net.cpp:106] Creating Layer data_hdf5
I0520 18:13:43.003949 23162 net.cpp:411] data_hdf5 -> data
I0520 18:13:43.003965 23162 net.cpp:411] data_hdf5 -> label
I0520 18:13:43.003981 23162 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0520 18:13:43.011852 23162 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0520 18:14:04.396180 23162 net.cpp:150] Setting up data_hdf5
I0520 18:14:04.396356 23162 net.cpp:157] Top shape: 70 1 127 50 (444500)
I0520 18:14:04.396371 23162 net.cpp:157] Top shape: 70 (70)
I0520 18:14:04.396383 23162 net.cpp:165] Memory required for data: 1778280
I0520 18:14:04.396396 23162 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0520 18:14:04.396423 23162 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0520 18:14:04.396435 23162 net.cpp:454] label_data_hdf5_1_split <- label
I0520 18:14:04.396450 23162 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0520 18:14:04.396471 23162 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0520 18:14:04.396543 23162 net.cpp:150] Setting up label_data_hdf5_1_split
I0520 18:14:04.396558 23162 net.cpp:157] Top shape: 70 (70)
I0520 18:14:04.396569 23162 net.cpp:157] Top shape: 70 (70)
I0520 18:14:04.396579 23162 net.cpp:165] Memory required for data: 1778840
I0520 18:14:04.396589 23162 layer_factory.hpp:77] Creating layer conv1
I0520 18:14:04.396611 23162 net.cpp:106] Creating Layer conv1
I0520 18:14:04.396621 23162 net.cpp:454] conv1 <- data
I0520 18:14:04.396636 23162 net.cpp:411] conv1 -> conv1
I0520 18:14:04.398547 23162 net.cpp:150] Setting up conv1
I0520 18:14:04.398566 23162 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0520 18:14:04.398581 23162 net.cpp:165] Memory required for data: 21132440
I0520 18:14:04.398602 23162 layer_factory.hpp:77] Creating layer relu1
I0520 18:14:04.398617 23162 net.cpp:106] Creating Layer relu1
I0520 18:14:04.398627 23162 net.cpp:454] relu1 <- conv1
I0520 18:14:04.398640 23162 net.cpp:397] relu1 -> conv1 (in-place)
I0520 18:14:04.399137 23162 net.cpp:150] Setting up relu1
I0520 18:14:04.399153 23162 net.cpp:157] Top shape: 70 12 120 48 (4838400)
I0520 18:14:04.399163 23162 net.cpp:165] Memory required for data: 40486040
I0520 18:14:04.399174 23162 layer_factory.hpp:77] Creating layer pool1
I0520 18:14:04.399190 23162 net.cpp:106] Creating Layer pool1
I0520 18:14:04.399200 23162 net.cpp:454] pool1 <- conv1
I0520 18:14:04.399214 23162 net.cpp:411] pool1 -> pool1
I0520 18:14:04.399287 23162 net.cpp:150] Setting up pool1
I0520 18:14:04.399301 23162 net.cpp:157] Top shape: 70 12 60 48 (2419200)
I0520 18:14:04.399310 23162 net.cpp:165] Memory required for data: 50162840
I0520 18:14:04.399323 23162 layer_factory.hpp:77] Creating layer conv2
I0520 18:14:04.399340 23162 net.cpp:106] Creating Layer conv2
I0520 18:14:04.399351 23162 net.cpp:454] conv2 <- pool1
I0520 18:14:04.399365 23162 net.cpp:411] conv2 -> conv2
I0520 18:14:04.401283 23162 net.cpp:150] Setting up conv2
I0520 18:14:04.401305 23162 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0520 18:14:04.401319 23162 net.cpp:165] Memory required for data: 64073240
I0520 18:14:04.401336 23162 layer_factory.hpp:77] Creating layer relu2
I0520 18:14:04.401350 23162 net.cpp:106] Creating Layer relu2
I0520 18:14:04.401360 23162 net.cpp:454] relu2 <- conv2
I0520 18:14:04.401372 23162 net.cpp:397] relu2 -> conv2 (in-place)
I0520 18:14:04.401703 23162 net.cpp:150] Setting up relu2
I0520 18:14:04.401716 23162 net.cpp:157] Top shape: 70 20 54 46 (3477600)
I0520 18:14:04.401727 23162 net.cpp:165] Memory required for data: 77983640
I0520 18:14:04.401737 23162 layer_factory.hpp:77] Creating layer pool2
I0520 18:14:04.401751 23162 net.cpp:106] Creating Layer pool2
I0520 18:14:04.401762 23162 net.cpp:454] pool2 <- conv2
I0520 18:14:04.401773 23162 net.cpp:411] pool2 -> pool2
I0520 18:14:04.401845 23162 net.cpp:150] Setting up pool2
I0520 18:14:04.401859 23162 net.cpp:157] Top shape: 70 20 27 46 (1738800)
I0520 18:14:04.401867 23162 net.cpp:165] Memory required for data: 84938840
I0520 18:14:04.401877 23162 layer_factory.hpp:77] Creating layer conv3
I0520 18:14:04.401896 23162 net.cpp:106] Creating Layer conv3
I0520 18:14:04.401906 23162 net.cpp:454] conv3 <- pool2
I0520 18:14:04.401921 23162 net.cpp:411] conv3 -> conv3
I0520 18:14:04.403892 23162 net.cpp:150] Setting up conv3
I0520 18:14:04.403914 23162 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0520 18:14:04.403926 23162 net.cpp:165] Memory required for data: 92527960
I0520 18:14:04.403959 23162 layer_factory.hpp:77] Creating layer relu3
I0520 18:14:04.403972 23162 net.cpp:106] Creating Layer relu3
I0520 18:14:04.403982 23162 net.cpp:454] relu3 <- conv3
I0520 18:14:04.403995 23162 net.cpp:397] relu3 -> conv3 (in-place)
I0520 18:14:04.404472 23162 net.cpp:150] Setting up relu3
I0520 18:14:04.404489 23162 net.cpp:157] Top shape: 70 28 22 44 (1897280)
I0520 18:14:04.404500 23162 net.cpp:165] Memory required for data: 100117080
I0520 18:14:04.404510 23162 layer_factory.hpp:77] Creating layer pool3
I0520 18:14:04.404522 23162 net.cpp:106] Creating Layer pool3
I0520 18:14:04.404532 23162 net.cpp:454] pool3 <- conv3
I0520 18:14:04.404546 23162 net.cpp:411] pool3 -> pool3
I0520 18:14:04.404618 23162 net.cpp:150] Setting up pool3
I0520 18:14:04.404633 23162 net.cpp:157] Top shape: 70 28 11 44 (948640)
I0520 18:14:04.404641 23162 net.cpp:165] Memory required for data: 103911640
I0520 18:14:04.404649 23162 layer_factory.hpp:77] Creating layer conv4
I0520 18:14:04.404667 23162 net.cpp:106] Creating Layer conv4
I0520 18:14:04.404678 23162 net.cpp:454] conv4 <- pool3
I0520 18:14:04.404693 23162 net.cpp:411] conv4 -> conv4
I0520 18:14:04.406751 23162 net.cpp:150] Setting up conv4
I0520 18:14:04.406774 23162 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0520 18:14:04.406786 23162 net.cpp:165] Memory required for data: 106451800
I0520 18:14:04.406801 23162 layer_factory.hpp:77] Creating layer relu4
I0520 18:14:04.406815 23162 net.cpp:106] Creating Layer relu4
I0520 18:14:04.406824 23162 net.cpp:454] relu4 <- conv4
I0520 18:14:04.406837 23162 net.cpp:397] relu4 -> conv4 (in-place)
I0520 18:14:04.407306 23162 net.cpp:150] Setting up relu4
I0520 18:14:04.407322 23162 net.cpp:157] Top shape: 70 36 6 42 (635040)
I0520 18:14:04.407332 23162 net.cpp:165] Memory required for data: 108991960
I0520 18:14:04.407342 23162 layer_factory.hpp:77] Creating layer pool4
I0520 18:14:04.407356 23162 net.cpp:106] Creating Layer pool4
I0520 18:14:04.407366 23162 net.cpp:454] pool4 <- conv4
I0520 18:14:04.407378 23162 net.cpp:411] pool4 -> pool4
I0520 18:14:04.407449 23162 net.cpp:150] Setting up pool4
I0520 18:14:04.407462 23162 net.cpp:157] Top shape: 70 36 3 42 (317520)
I0520 18:14:04.407472 23162 net.cpp:165] Memory required for data: 110262040
I0520 18:14:04.407482 23162 layer_factory.hpp:77] Creating layer ip1
I0520 18:14:04.407498 23162 net.cpp:106] Creating Layer ip1
I0520 18:14:04.407508 23162 net.cpp:454] ip1 <- pool4
I0520 18:14:04.407522 23162 net.cpp:411] ip1 -> ip1
I0520 18:14:04.422969 23162 net.cpp:150] Setting up ip1
I0520 18:14:04.422997 23162 net.cpp:157] Top shape: 70 196 (13720)
I0520 18:14:04.423008 23162 net.cpp:165] Memory required for data: 110316920
I0520 18:14:04.423032 23162 layer_factory.hpp:77] Creating layer relu5
I0520 18:14:04.423046 23162 net.cpp:106] Creating Layer relu5
I0520 18:14:04.423058 23162 net.cpp:454] relu5 <- ip1
I0520 18:14:04.423070 23162 net.cpp:397] relu5 -> ip1 (in-place)
I0520 18:14:04.423416 23162 net.cpp:150] Setting up relu5
I0520 18:14:04.423430 23162 net.cpp:157] Top shape: 70 196 (13720)
I0520 18:14:04.423440 23162 net.cpp:165] Memory required for data: 110371800
I0520 18:14:04.423450 23162 layer_factory.hpp:77] Creating layer drop1
I0520 18:14:04.423470 23162 net.cpp:106] Creating Layer drop1
I0520 18:14:04.423480 23162 net.cpp:454] drop1 <- ip1
I0520 18:14:04.423493 23162 net.cpp:397] drop1 -> ip1 (in-place)
I0520 18:14:04.423540 23162 net.cpp:150] Setting up drop1
I0520 18:14:04.423554 23162 net.cpp:157] Top shape: 70 196 (13720)
I0520 18:14:04.423564 23162 net.cpp:165] Memory required for data: 110426680
I0520 18:14:04.423574 23162 layer_factory.hpp:77] Creating layer ip2
I0520 18:14:04.423588 23162 net.cpp:106] Creating Layer ip2
I0520 18:14:04.423599 23162 net.cpp:454] ip2 <- ip1
I0520 18:14:04.423610 23162 net.cpp:411] ip2 -> ip2
I0520 18:14:04.424090 23162 net.cpp:150] Setting up ip2
I0520 18:14:04.424103 23162 net.cpp:157] Top shape: 70 98 (6860)
I0520 18:14:04.424113 23162 net.cpp:165] Memory required for data: 110454120
I0520 18:14:04.424129 23162 layer_factory.hpp:77] Creating layer relu6
I0520 18:14:04.424155 23162 net.cpp:106] Creating Layer relu6
I0520 18:14:04.424165 23162 net.cpp:454] relu6 <- ip2
I0520 18:14:04.424178 23162 net.cpp:397] relu6 -> ip2 (in-place)
I0520 18:14:04.424715 23162 net.cpp:150] Setting up relu6
I0520 18:14:04.424737 23162 net.cpp:157] Top shape: 70 98 (6860)
I0520 18:14:04.424747 23162 net.cpp:165] Memory required for data: 110481560
I0520 18:14:04.424757 23162 layer_factory.hpp:77] Creating layer drop2
I0520 18:14:04.424772 23162 net.cpp:106] Creating Layer drop2
I0520 18:14:04.424782 23162 net.cpp:454] drop2 <- ip2
I0520 18:14:04.424795 23162 net.cpp:397] drop2 -> ip2 (in-place)
I0520 18:14:04.424840 23162 net.cpp:150] Setting up drop2
I0520 18:14:04.424854 23162 net.cpp:157] Top shape: 70 98 (6860)
I0520 18:14:04.424863 23162 net.cpp:165] Memory required for data: 110509000
I0520 18:14:04.424872 23162 layer_factory.hpp:77] Creating layer ip3
I0520 18:14:04.424887 23162 net.cpp:106] Creating Layer ip3
I0520 18:14:04.424896 23162 net.cpp:454] ip3 <- ip2
I0520 18:14:04.424911 23162 net.cpp:411] ip3 -> ip3
I0520 18:14:04.425133 23162 net.cpp:150] Setting up ip3
I0520 18:14:04.425146 23162 net.cpp:157] Top shape: 70 11 (770)
I0520 18:14:04.425156 23162 net.cpp:165] Memory required for data: 110512080
I0520 18:14:04.425171 23162 layer_factory.hpp:77] Creating layer drop3
I0520 18:14:04.425184 23162 net.cpp:106] Creating Layer drop3
I0520 18:14:04.425194 23162 net.cpp:454] drop3 <- ip3
I0520 18:14:04.425207 23162 net.cpp:397] drop3 -> ip3 (in-place)
I0520 18:14:04.425249 23162 net.cpp:150] Setting up drop3
I0520 18:14:04.425262 23162 net.cpp:157] Top shape: 70 11 (770)
I0520 18:14:04.425272 23162 net.cpp:165] Memory required for data: 110515160
I0520 18:14:04.425282 23162 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0520 18:14:04.425295 23162 net.cpp:106] Creating Layer ip3_drop3_0_split
I0520 18:14:04.425304 23162 net.cpp:454] ip3_drop3_0_split <- ip3
I0520 18:14:04.425318 23162 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0520 18:14:04.425333 23162 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0520 18:14:04.425406 23162 net.cpp:150] Setting up ip3_drop3_0_split
I0520 18:14:04.425420 23162 net.cpp:157] Top shape: 70 11 (770)
I0520 18:14:04.425432 23162 net.cpp:157] Top shape: 70 11 (770)
I0520 18:14:04.425442 23162 net.cpp:165] Memory required for data: 110521320
I0520 18:14:04.425452 23162 layer_factory.hpp:77] Creating layer accuracy
I0520 18:14:04.425473 23162 net.cpp:106] Creating Layer accuracy
I0520 18:14:04.425483 23162 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0520 18:14:04.425495 23162 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0520 18:14:04.425508 23162 net.cpp:411] accuracy -> accuracy
I0520 18:14:04.425532 23162 net.cpp:150] Setting up accuracy
I0520 18:14:04.425545 23162 net.cpp:157] Top shape: (1)
I0520 18:14:04.425554 23162 net.cpp:165] Memory required for data: 110521324
I0520 18:14:04.425565 23162 layer_factory.hpp:77] Creating layer loss
I0520 18:14:04.425578 23162 net.cpp:106] Creating Layer loss
I0520 18:14:04.425590 23162 net.cpp:454] loss <- ip3_drop3_0_split_1
I0520 18:14:04.425601 23162 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0520 18:14:04.425613 23162 net.cpp:411] loss -> loss
I0520 18:14:04.425631 23162 layer_factory.hpp:77] Creating layer loss
I0520 18:14:04.426116 23162 net.cpp:150] Setting up loss
I0520 18:14:04.426131 23162 net.cpp:157] Top shape: (1)
I0520 18:14:04.426141 23162 net.cpp:160]     with loss weight 1
I0520 18:14:04.426162 23162 net.cpp:165] Memory required for data: 110521328
I0520 18:14:04.426172 23162 net.cpp:226] loss needs backward computation.
I0520 18:14:04.426182 23162 net.cpp:228] accuracy does not need backward computation.
I0520 18:14:04.426193 23162 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0520 18:14:04.426204 23162 net.cpp:226] drop3 needs backward computation.
I0520 18:14:04.426214 23162 net.cpp:226] ip3 needs backward computation.
I0520 18:14:04.426225 23162 net.cpp:226] drop2 needs backward computation.
I0520 18:14:04.426234 23162 net.cpp:226] relu6 needs backward computation.
I0520 18:14:04.426252 23162 net.cpp:226] ip2 needs backward computation.
I0520 18:14:04.426262 23162 net.cpp:226] drop1 needs backward computation.
I0520 18:14:04.426271 23162 net.cpp:226] relu5 needs backward computation.
I0520 18:14:04.426281 23162 net.cpp:226] ip1 needs backward computation.
I0520 18:14:04.426290 23162 net.cpp:226] pool4 needs backward computation.
I0520 18:14:04.426301 23162 net.cpp:226] relu4 needs backward computation.
I0520 18:14:04.426311 23162 net.cpp:226] conv4 needs backward computation.
I0520 18:14:04.426321 23162 net.cpp:226] pool3 needs backward computation.
I0520 18:14:04.426331 23162 net.cpp:226] relu3 needs backward computation.
I0520 18:14:04.426342 23162 net.cpp:226] conv3 needs backward computation.
I0520 18:14:04.426352 23162 net.cpp:226] pool2 needs backward computation.
I0520 18:14:04.426362 23162 net.cpp:226] relu2 needs backward computation.
I0520 18:14:04.426373 23162 net.cpp:226] conv2 needs backward computation.
I0520 18:14:04.426383 23162 net.cpp:226] pool1 needs backward computation.
I0520 18:14:04.426393 23162 net.cpp:226] relu1 needs backward computation.
I0520 18:14:04.426403 23162 net.cpp:226] conv1 needs backward computation.
I0520 18:14:04.426414 23162 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0520 18:14:04.426425 23162 net.cpp:228] data_hdf5 does not need backward computation.
I0520 18:14:04.426435 23162 net.cpp:270] This network produces output accuracy
I0520 18:14:04.426443 23162 net.cpp:270] This network produces output loss
I0520 18:14:04.426473 23162 net.cpp:283] Network initialization done.
I0520 18:14:04.426606 23162 solver.cpp:60] Solver scaffolding done.
I0520 18:14:04.427739 23162 caffe.cpp:212] Starting Optimization
I0520 18:14:04.427758 23162 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0520 18:14:04.427772 23162 solver.cpp:289] Learning Rate Policy: fixed
I0520 18:14:04.429003 23162 solver.cpp:341] Iteration 0, Testing net (#0)
I0520 18:14:53.288394 23162 solver.cpp:409]     Test net output #0: accuracy = 0.136401
I0520 18:14:53.288560 23162 solver.cpp:409]     Test net output #1: loss = 2.39638 (* 1 = 2.39638 loss)
I0520 18:14:53.316467 23162 solver.cpp:237] Iteration 0, loss = 2.39854
I0520 18:14:53.316503 23162 solver.cpp:253]     Train net output #0: loss = 2.39854 (* 1 = 2.39854 loss)
I0520 18:14:53.316520 23162 sgd_solver.cpp:106] Iteration 0, lr = 0.0025
I0520 18:15:02.211851 23162 solver.cpp:237] Iteration 214, loss = 2.24144
I0520 18:15:02.211886 23162 solver.cpp:253]     Train net output #0: loss = 2.24144 (* 1 = 2.24144 loss)
I0520 18:15:02.211905 23162 sgd_solver.cpp:106] Iteration 214, lr = 0.0025
I0520 18:15:11.111389 23162 solver.cpp:237] Iteration 428, loss = 2.08992
I0520 18:15:11.111438 23162 solver.cpp:253]     Train net output #0: loss = 2.08992 (* 1 = 2.08992 loss)
I0520 18:15:11.111454 23162 sgd_solver.cpp:106] Iteration 428, lr = 0.0025
I0520 18:15:20.008605 23162 solver.cpp:237] Iteration 642, loss = 2.07316
I0520 18:15:20.008641 23162 solver.cpp:253]     Train net output #0: loss = 2.07316 (* 1 = 2.07316 loss)
I0520 18:15:20.008658 23162 sgd_solver.cpp:106] Iteration 642, lr = 0.0025
I0520 18:15:28.910424 23162 solver.cpp:237] Iteration 856, loss = 1.89422
I0520 18:15:28.910572 23162 solver.cpp:253]     Train net output #0: loss = 1.89422 (* 1 = 1.89422 loss)
I0520 18:15:28.910585 23162 sgd_solver.cpp:106] Iteration 856, lr = 0.0025
I0520 18:15:37.813174 23162 solver.cpp:237] Iteration 1070, loss = 1.76101
I0520 18:15:37.813221 23162 solver.cpp:253]     Train net output #0: loss = 1.76101 (* 1 = 1.76101 loss)
I0520 18:15:37.813237 23162 sgd_solver.cpp:106] Iteration 1070, lr = 0.0025
I0520 18:15:46.718696 23162 solver.cpp:237] Iteration 1284, loss = 1.89923
I0520 18:15:46.718732 23162 solver.cpp:253]     Train net output #0: loss = 1.89923 (* 1 = 1.89923 loss)
I0520 18:15:46.718749 23162 sgd_solver.cpp:106] Iteration 1284, lr = 0.0025
I0520 18:16:17.755503 23162 solver.cpp:237] Iteration 1498, loss = 1.8785
I0520 18:16:17.755668 23162 solver.cpp:253]     Train net output #0: loss = 1.8785 (* 1 = 1.8785 loss)
I0520 18:16:17.755683 23162 sgd_solver.cpp:106] Iteration 1498, lr = 0.0025
I0520 18:16:26.652474 23162 solver.cpp:237] Iteration 1712, loss = 1.65008
I0520 18:16:26.652526 23162 solver.cpp:253]     Train net output #0: loss = 1.65008 (* 1 = 1.65008 loss)
I0520 18:16:26.652544 23162 sgd_solver.cpp:106] Iteration 1712, lr = 0.0025
I0520 18:16:35.555613 23162 solver.cpp:237] Iteration 1926, loss = 1.62012
I0520 18:16:35.555649 23162 solver.cpp:253]     Train net output #0: loss = 1.62012 (* 1 = 1.62012 loss)
I0520 18:16:35.555665 23162 sgd_solver.cpp:106] Iteration 1926, lr = 0.0025
I0520 18:16:44.463018 23162 solver.cpp:237] Iteration 2140, loss = 1.81317
I0520 18:16:44.463053 23162 solver.cpp:253]     Train net output #0: loss = 1.81317 (* 1 = 1.81317 loss)
I0520 18:16:44.463071 23162 sgd_solver.cpp:106] Iteration 2140, lr = 0.0025
I0520 18:16:44.505354 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_2142.caffemodel
I0520 18:16:44.575923 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_2142.solverstate
I0520 18:16:53.431234 23162 solver.cpp:237] Iteration 2354, loss = 1.62929
I0520 18:16:53.431396 23162 solver.cpp:253]     Train net output #0: loss = 1.62929 (* 1 = 1.62929 loss)
I0520 18:16:53.431409 23162 sgd_solver.cpp:106] Iteration 2354, lr = 0.0025
I0520 18:17:02.324547 23162 solver.cpp:237] Iteration 2568, loss = 1.58816
I0520 18:17:02.324581 23162 solver.cpp:253]     Train net output #0: loss = 1.58816 (* 1 = 1.58816 loss)
I0520 18:17:02.324597 23162 sgd_solver.cpp:106] Iteration 2568, lr = 0.0025
I0520 18:17:11.224805 23162 solver.cpp:237] Iteration 2782, loss = 1.55884
I0520 18:17:11.224840 23162 solver.cpp:253]     Train net output #0: loss = 1.55884 (* 1 = 1.55884 loss)
I0520 18:17:11.224854 23162 sgd_solver.cpp:106] Iteration 2782, lr = 0.0025
I0520 18:17:42.251801 23162 solver.cpp:237] Iteration 2996, loss = 1.62166
I0520 18:17:42.251958 23162 solver.cpp:253]     Train net output #0: loss = 1.62166 (* 1 = 1.62166 loss)
I0520 18:17:42.251973 23162 sgd_solver.cpp:106] Iteration 2996, lr = 0.0025
I0520 18:17:51.147416 23162 solver.cpp:237] Iteration 3210, loss = 1.58775
I0520 18:17:51.147451 23162 solver.cpp:253]     Train net output #0: loss = 1.58775 (* 1 = 1.58775 loss)
I0520 18:17:51.147469 23162 sgd_solver.cpp:106] Iteration 3210, lr = 0.0025
I0520 18:18:00.045382 23162 solver.cpp:237] Iteration 3424, loss = 1.36523
I0520 18:18:00.045418 23162 solver.cpp:253]     Train net output #0: loss = 1.36523 (* 1 = 1.36523 loss)
I0520 18:18:00.045435 23162 sgd_solver.cpp:106] Iteration 3424, lr = 0.0025
I0520 18:18:08.944064 23162 solver.cpp:237] Iteration 3638, loss = 1.5148
I0520 18:18:08.944103 23162 solver.cpp:253]     Train net output #0: loss = 1.5148 (* 1 = 1.5148 loss)
I0520 18:18:08.944124 23162 sgd_solver.cpp:106] Iteration 3638, lr = 0.0025
I0520 18:18:17.846622 23162 solver.cpp:237] Iteration 3852, loss = 1.47487
I0520 18:18:17.846770 23162 solver.cpp:253]     Train net output #0: loss = 1.47487 (* 1 = 1.47487 loss)
I0520 18:18:17.846784 23162 sgd_solver.cpp:106] Iteration 3852, lr = 0.0025
I0520 18:18:26.749507 23162 solver.cpp:237] Iteration 4066, loss = 1.53741
I0520 18:18:26.749543 23162 solver.cpp:253]     Train net output #0: loss = 1.53741 (* 1 = 1.53741 loss)
I0520 18:18:26.749557 23162 sgd_solver.cpp:106] Iteration 4066, lr = 0.0025
I0520 18:18:35.648252 23162 solver.cpp:237] Iteration 4280, loss = 1.40875
I0520 18:18:35.648298 23162 solver.cpp:253]     Train net output #0: loss = 1.40875 (* 1 = 1.40875 loss)
I0520 18:18:35.648315 23162 sgd_solver.cpp:106] Iteration 4280, lr = 0.0025
I0520 18:18:35.774054 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_4284.caffemodel
I0520 18:18:35.840698 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_4284.solverstate
I0520 18:18:35.885162 23162 solver.cpp:341] Iteration 4285, Testing net (#0)
I0520 18:19:23.823492 23162 solver.cpp:409]     Test net output #0: accuracy = 0.763203
I0520 18:19:23.823657 23162 solver.cpp:409]     Test net output #1: loss = 0.867556 (* 1 = 0.867556 loss)
I0520 18:19:54.637307 23162 solver.cpp:237] Iteration 4494, loss = 1.46035
I0520 18:19:54.637467 23162 solver.cpp:253]     Train net output #0: loss = 1.46035 (* 1 = 1.46035 loss)
I0520 18:19:54.637483 23162 sgd_solver.cpp:106] Iteration 4494, lr = 0.0025
I0520 18:20:03.510409 23162 solver.cpp:237] Iteration 4708, loss = 1.32353
I0520 18:20:03.510444 23162 solver.cpp:253]     Train net output #0: loss = 1.32353 (* 1 = 1.32353 loss)
I0520 18:20:03.510462 23162 sgd_solver.cpp:106] Iteration 4708, lr = 0.0025
I0520 18:20:12.387116 23162 solver.cpp:237] Iteration 4922, loss = 1.74787
I0520 18:20:12.387161 23162 solver.cpp:253]     Train net output #0: loss = 1.74787 (* 1 = 1.74787 loss)
I0520 18:20:12.387177 23162 sgd_solver.cpp:106] Iteration 4922, lr = 0.0025
I0520 18:20:21.263641 23162 solver.cpp:237] Iteration 5136, loss = 1.46976
I0520 18:20:21.263677 23162 solver.cpp:253]     Train net output #0: loss = 1.46976 (* 1 = 1.46976 loss)
I0520 18:20:21.263692 23162 sgd_solver.cpp:106] Iteration 5136, lr = 0.0025
I0520 18:20:30.140800 23162 solver.cpp:237] Iteration 5350, loss = 1.61337
I0520 18:20:30.140933 23162 solver.cpp:253]     Train net output #0: loss = 1.61337 (* 1 = 1.61337 loss)
I0520 18:20:30.140945 23162 sgd_solver.cpp:106] Iteration 5350, lr = 0.0025
I0520 18:20:39.021013 23162 solver.cpp:237] Iteration 5564, loss = 1.46208
I0520 18:20:39.021056 23162 solver.cpp:253]     Train net output #0: loss = 1.46208 (* 1 = 1.46208 loss)
I0520 18:20:39.021076 23162 sgd_solver.cpp:106] Iteration 5564, lr = 0.0025
I0520 18:21:10.059335 23162 solver.cpp:237] Iteration 5778, loss = 1.3008
I0520 18:21:10.059504 23162 solver.cpp:253]     Train net output #0: loss = 1.3008 (* 1 = 1.3008 loss)
I0520 18:21:10.059520 23162 sgd_solver.cpp:106] Iteration 5778, lr = 0.0025
I0520 18:21:18.933037 23162 solver.cpp:237] Iteration 5992, loss = 1.31053
I0520 18:21:18.933073 23162 solver.cpp:253]     Train net output #0: loss = 1.31053 (* 1 = 1.31053 loss)
I0520 18:21:18.933089 23162 sgd_solver.cpp:106] Iteration 5992, lr = 0.0025
I0520 18:21:27.811082 23162 solver.cpp:237] Iteration 6206, loss = 1.40886
I0520 18:21:27.811128 23162 solver.cpp:253]     Train net output #0: loss = 1.40886 (* 1 = 1.40886 loss)
I0520 18:21:27.811147 23162 sgd_solver.cpp:106] Iteration 6206, lr = 0.0025
I0520 18:21:36.689589 23162 solver.cpp:237] Iteration 6420, loss = 1.45574
I0520 18:21:36.689625 23162 solver.cpp:253]     Train net output #0: loss = 1.45574 (* 1 = 1.45574 loss)
I0520 18:21:36.689641 23162 sgd_solver.cpp:106] Iteration 6420, lr = 0.0025
I0520 18:21:36.897418 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_6426.caffemodel
I0520 18:21:36.965899 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_6426.solverstate
I0520 18:21:45.633416 23162 solver.cpp:237] Iteration 6634, loss = 1.48805
I0520 18:21:45.633586 23162 solver.cpp:253]     Train net output #0: loss = 1.48805 (* 1 = 1.48805 loss)
I0520 18:21:45.633600 23162 sgd_solver.cpp:106] Iteration 6634, lr = 0.0025
I0520 18:21:54.508224 23162 solver.cpp:237] Iteration 6848, loss = 1.38184
I0520 18:21:54.508273 23162 solver.cpp:253]     Train net output #0: loss = 1.38184 (* 1 = 1.38184 loss)
I0520 18:21:54.508296 23162 sgd_solver.cpp:106] Iteration 6848, lr = 0.0025
I0520 18:22:03.384747 23162 solver.cpp:237] Iteration 7062, loss = 1.39332
I0520 18:22:03.384784 23162 solver.cpp:253]     Train net output #0: loss = 1.39332 (* 1 = 1.39332 loss)
I0520 18:22:03.384799 23162 sgd_solver.cpp:106] Iteration 7062, lr = 0.0025
I0520 18:22:34.483021 23162 solver.cpp:237] Iteration 7276, loss = 1.63003
I0520 18:22:34.483191 23162 solver.cpp:253]     Train net output #0: loss = 1.63003 (* 1 = 1.63003 loss)
I0520 18:22:34.483206 23162 sgd_solver.cpp:106] Iteration 7276, lr = 0.0025
I0520 18:22:43.367791 23162 solver.cpp:237] Iteration 7490, loss = 1.28295
I0520 18:22:43.367841 23162 solver.cpp:253]     Train net output #0: loss = 1.28295 (* 1 = 1.28295 loss)
I0520 18:22:43.367857 23162 sgd_solver.cpp:106] Iteration 7490, lr = 0.0025
I0520 18:22:52.245652 23162 solver.cpp:237] Iteration 7704, loss = 1.49713
I0520 18:22:52.245688 23162 solver.cpp:253]     Train net output #0: loss = 1.49713 (* 1 = 1.49713 loss)
I0520 18:22:52.245702 23162 sgd_solver.cpp:106] Iteration 7704, lr = 0.0025
I0520 18:23:01.122181 23162 solver.cpp:237] Iteration 7918, loss = 1.38079
I0520 18:23:01.122216 23162 solver.cpp:253]     Train net output #0: loss = 1.38079 (* 1 = 1.38079 loss)
I0520 18:23:01.122234 23162 sgd_solver.cpp:106] Iteration 7918, lr = 0.0025
I0520 18:23:09.998373 23162 solver.cpp:237] Iteration 8132, loss = 1.30256
I0520 18:23:09.998523 23162 solver.cpp:253]     Train net output #0: loss = 1.30256 (* 1 = 1.30256 loss)
I0520 18:23:09.998538 23162 sgd_solver.cpp:106] Iteration 8132, lr = 0.0025
I0520 18:23:18.872221 23162 solver.cpp:237] Iteration 8346, loss = 1.37478
I0520 18:23:18.872261 23162 solver.cpp:253]     Train net output #0: loss = 1.37478 (* 1 = 1.37478 loss)
I0520 18:23:18.872279 23162 sgd_solver.cpp:106] Iteration 8346, lr = 0.0025
I0520 18:23:27.751636 23162 solver.cpp:237] Iteration 8560, loss = 1.30199
I0520 18:23:27.751691 23162 solver.cpp:253]     Train net output #0: loss = 1.30199 (* 1 = 1.30199 loss)
I0520 18:23:27.751705 23162 sgd_solver.cpp:106] Iteration 8560, lr = 0.0025
I0520 18:23:28.043102 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_8568.caffemodel
I0520 18:23:28.112202 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_8568.solverstate
I0520 18:23:28.195255 23162 solver.cpp:341] Iteration 8570, Testing net (#0)
I0520 18:24:36.980235 23162 solver.cpp:409]     Test net output #0: accuracy = 0.823748
I0520 18:24:36.980419 23162 solver.cpp:409]     Test net output #1: loss = 0.630987 (* 1 = 0.630987 loss)
I0520 18:25:07.671200 23162 solver.cpp:237] Iteration 8774, loss = 1.47669
I0520 18:25:07.671365 23162 solver.cpp:253]     Train net output #0: loss = 1.47669 (* 1 = 1.47669 loss)
I0520 18:25:07.671378 23162 sgd_solver.cpp:106] Iteration 8774, lr = 0.0025
I0520 18:25:16.584934 23162 solver.cpp:237] Iteration 8988, loss = 1.54134
I0520 18:25:16.584969 23162 solver.cpp:253]     Train net output #0: loss = 1.54134 (* 1 = 1.54134 loss)
I0520 18:25:16.584987 23162 sgd_solver.cpp:106] Iteration 8988, lr = 0.0025
I0520 18:25:25.494856 23162 solver.cpp:237] Iteration 9202, loss = 1.32813
I0520 18:25:25.494891 23162 solver.cpp:253]     Train net output #0: loss = 1.32813 (* 1 = 1.32813 loss)
I0520 18:25:25.494907 23162 sgd_solver.cpp:106] Iteration 9202, lr = 0.0025
I0520 18:25:34.404256 23162 solver.cpp:237] Iteration 9416, loss = 1.25627
I0520 18:25:34.404314 23162 solver.cpp:253]     Train net output #0: loss = 1.25627 (* 1 = 1.25627 loss)
I0520 18:25:34.404328 23162 sgd_solver.cpp:106] Iteration 9416, lr = 0.0025
I0520 18:25:43.316747 23162 solver.cpp:237] Iteration 9630, loss = 1.21018
I0520 18:25:43.316889 23162 solver.cpp:253]     Train net output #0: loss = 1.21018 (* 1 = 1.21018 loss)
I0520 18:25:43.316901 23162 sgd_solver.cpp:106] Iteration 9630, lr = 0.0025
I0520 18:25:52.226614 23162 solver.cpp:237] Iteration 9844, loss = 1.3741
I0520 18:25:52.226649 23162 solver.cpp:253]     Train net output #0: loss = 1.3741 (* 1 = 1.3741 loss)
I0520 18:25:52.226665 23162 sgd_solver.cpp:106] Iteration 9844, lr = 0.0025
I0520 18:26:23.258471 23162 solver.cpp:237] Iteration 10058, loss = 1.48605
I0520 18:26:23.258642 23162 solver.cpp:253]     Train net output #0: loss = 1.48605 (* 1 = 1.48605 loss)
I0520 18:26:23.258657 23162 sgd_solver.cpp:106] Iteration 10058, lr = 0.0025
I0520 18:26:32.160941 23162 solver.cpp:237] Iteration 10272, loss = 1.29447
I0520 18:26:32.160976 23162 solver.cpp:253]     Train net output #0: loss = 1.29447 (* 1 = 1.29447 loss)
I0520 18:26:32.160994 23162 sgd_solver.cpp:106] Iteration 10272, lr = 0.0025
I0520 18:26:41.074205 23162 solver.cpp:237] Iteration 10486, loss = 1.45786
I0520 18:26:41.074240 23162 solver.cpp:253]     Train net output #0: loss = 1.45786 (* 1 = 1.45786 loss)
I0520 18:26:41.074257 23162 sgd_solver.cpp:106] Iteration 10486, lr = 0.0025
I0520 18:26:49.986999 23162 solver.cpp:237] Iteration 10700, loss = 1.37734
I0520 18:26:49.987052 23162 solver.cpp:253]     Train net output #0: loss = 1.37734 (* 1 = 1.37734 loss)
I0520 18:26:49.987068 23162 sgd_solver.cpp:106] Iteration 10700, lr = 0.0025
I0520 18:26:50.363497 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_10710.caffemodel
I0520 18:26:50.432807 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_10710.solverstate
I0520 18:26:58.973738 23162 solver.cpp:237] Iteration 10914, loss = 1.34338
I0520 18:26:58.973901 23162 solver.cpp:253]     Train net output #0: loss = 1.34338 (* 1 = 1.34338 loss)
I0520 18:26:58.973915 23162 sgd_solver.cpp:106] Iteration 10914, lr = 0.0025
I0520 18:27:07.886541 23162 solver.cpp:237] Iteration 11128, loss = 1.20995
I0520 18:27:07.886576 23162 solver.cpp:253]     Train net output #0: loss = 1.20995 (* 1 = 1.20995 loss)
I0520 18:27:07.886593 23162 sgd_solver.cpp:106] Iteration 11128, lr = 0.0025
I0520 18:27:16.806771 23162 solver.cpp:237] Iteration 11342, loss = 1.11363
I0520 18:27:16.806824 23162 solver.cpp:253]     Train net output #0: loss = 1.11363 (* 1 = 1.11363 loss)
I0520 18:27:16.806840 23162 sgd_solver.cpp:106] Iteration 11342, lr = 0.0025
I0520 18:27:47.861928 23162 solver.cpp:237] Iteration 11556, loss = 1.48299
I0520 18:27:47.862102 23162 solver.cpp:253]     Train net output #0: loss = 1.48299 (* 1 = 1.48299 loss)
I0520 18:27:47.862118 23162 sgd_solver.cpp:106] Iteration 11556, lr = 0.0025
I0520 18:27:56.776489 23162 solver.cpp:237] Iteration 11770, loss = 1.25006
I0520 18:27:56.776522 23162 solver.cpp:253]     Train net output #0: loss = 1.25006 (* 1 = 1.25006 loss)
I0520 18:27:56.776540 23162 sgd_solver.cpp:106] Iteration 11770, lr = 0.0025
I0520 18:28:05.696434 23162 solver.cpp:237] Iteration 11984, loss = 1.30834
I0520 18:28:05.696486 23162 solver.cpp:253]     Train net output #0: loss = 1.30834 (* 1 = 1.30834 loss)
I0520 18:28:05.696503 23162 sgd_solver.cpp:106] Iteration 11984, lr = 0.0025
I0520 18:28:14.620038 23162 solver.cpp:237] Iteration 12198, loss = 1.49151
I0520 18:28:14.620072 23162 solver.cpp:253]     Train net output #0: loss = 1.49151 (* 1 = 1.49151 loss)
I0520 18:28:14.620090 23162 sgd_solver.cpp:106] Iteration 12198, lr = 0.0025
I0520 18:28:23.537878 23162 solver.cpp:237] Iteration 12412, loss = 1.05735
I0520 18:28:23.538022 23162 solver.cpp:253]     Train net output #0: loss = 1.05735 (* 1 = 1.05735 loss)
I0520 18:28:23.538036 23162 sgd_solver.cpp:106] Iteration 12412, lr = 0.0025
I0520 18:28:32.454493 23162 solver.cpp:237] Iteration 12626, loss = 1.27215
I0520 18:28:32.454535 23162 solver.cpp:253]     Train net output #0: loss = 1.27215 (* 1 = 1.27215 loss)
I0520 18:28:32.454556 23162 sgd_solver.cpp:106] Iteration 12626, lr = 0.0025
I0520 18:28:41.364800 23162 solver.cpp:237] Iteration 12840, loss = 1.07251
I0520 18:28:41.364835 23162 solver.cpp:253]     Train net output #0: loss = 1.07251 (* 1 = 1.07251 loss)
I0520 18:28:41.364852 23162 sgd_solver.cpp:106] Iteration 12840, lr = 0.0025
I0520 18:28:41.821123 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_12852.caffemodel
I0520 18:28:41.887418 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_12852.solverstate
I0520 18:28:42.008971 23162 solver.cpp:341] Iteration 12855, Testing net (#0)
I0520 18:29:29.648497 23162 solver.cpp:409]     Test net output #0: accuracy = 0.843597
I0520 18:29:29.648669 23162 solver.cpp:409]     Test net output #1: loss = 0.535195 (* 1 = 0.535195 loss)
I0520 18:30:00.082449 23162 solver.cpp:237] Iteration 13054, loss = 1.34319
I0520 18:30:00.082622 23162 solver.cpp:253]     Train net output #0: loss = 1.34319 (* 1 = 1.34319 loss)
I0520 18:30:00.082636 23162 sgd_solver.cpp:106] Iteration 13054, lr = 0.0025
I0520 18:30:08.970139 23162 solver.cpp:237] Iteration 13268, loss = 1.41507
I0520 18:30:08.970188 23162 solver.cpp:253]     Train net output #0: loss = 1.41507 (* 1 = 1.41507 loss)
I0520 18:30:08.970206 23162 sgd_solver.cpp:106] Iteration 13268, lr = 0.0025
I0520 18:30:17.851867 23162 solver.cpp:237] Iteration 13482, loss = 1.02066
I0520 18:30:17.851902 23162 solver.cpp:253]     Train net output #0: loss = 1.02066 (* 1 = 1.02066 loss)
I0520 18:30:17.851919 23162 sgd_solver.cpp:106] Iteration 13482, lr = 0.0025
I0520 18:30:26.737467 23162 solver.cpp:237] Iteration 13696, loss = 1.34084
I0520 18:30:26.737500 23162 solver.cpp:253]     Train net output #0: loss = 1.34084 (* 1 = 1.34084 loss)
I0520 18:30:26.737519 23162 sgd_solver.cpp:106] Iteration 13696, lr = 0.0025
I0520 18:30:35.626704 23162 solver.cpp:237] Iteration 13910, loss = 1.19128
I0520 18:30:35.626858 23162 solver.cpp:253]     Train net output #0: loss = 1.19128 (* 1 = 1.19128 loss)
I0520 18:30:35.626873 23162 sgd_solver.cpp:106] Iteration 13910, lr = 0.0025
I0520 18:30:44.511216 23162 solver.cpp:237] Iteration 14124, loss = 1.42144
I0520 18:30:44.511251 23162 solver.cpp:253]     Train net output #0: loss = 1.42144 (* 1 = 1.42144 loss)
I0520 18:30:44.511270 23162 sgd_solver.cpp:106] Iteration 14124, lr = 0.0025
I0520 18:31:15.588176 23162 solver.cpp:237] Iteration 14338, loss = 1.33947
I0520 18:31:15.588356 23162 solver.cpp:253]     Train net output #0: loss = 1.33947 (* 1 = 1.33947 loss)
I0520 18:31:15.588371 23162 sgd_solver.cpp:106] Iteration 14338, lr = 0.0025
I0520 18:31:24.479095 23162 solver.cpp:237] Iteration 14552, loss = 1.30809
I0520 18:31:24.479138 23162 solver.cpp:253]     Train net output #0: loss = 1.30809 (* 1 = 1.30809 loss)
I0520 18:31:24.479159 23162 sgd_solver.cpp:106] Iteration 14552, lr = 0.0025
I0520 18:31:33.369627 23162 solver.cpp:237] Iteration 14766, loss = 1.31428
I0520 18:31:33.369664 23162 solver.cpp:253]     Train net output #0: loss = 1.31428 (* 1 = 1.31428 loss)
I0520 18:31:33.369679 23162 sgd_solver.cpp:106] Iteration 14766, lr = 0.0025
I0520 18:31:42.259395 23162 solver.cpp:237] Iteration 14980, loss = 1.26491
I0520 18:31:42.259431 23162 solver.cpp:253]     Train net output #0: loss = 1.26491 (* 1 = 1.26491 loss)
I0520 18:31:42.259446 23162 sgd_solver.cpp:106] Iteration 14980, lr = 0.0025
I0520 18:31:42.799558 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_14994.caffemodel
I0520 18:31:42.871320 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_14994.solverstate
I0520 18:31:51.212558 23162 solver.cpp:237] Iteration 15194, loss = 1.12058
I0520 18:31:51.212738 23162 solver.cpp:253]     Train net output #0: loss = 1.12058 (* 1 = 1.12058 loss)
I0520 18:31:51.212752 23162 sgd_solver.cpp:106] Iteration 15194, lr = 0.0025
I0520 18:32:00.091624 23162 solver.cpp:237] Iteration 15408, loss = 1.34234
I0520 18:32:00.091660 23162 solver.cpp:253]     Train net output #0: loss = 1.34234 (* 1 = 1.34234 loss)
I0520 18:32:00.091675 23162 sgd_solver.cpp:106] Iteration 15408, lr = 0.0025
I0520 18:32:08.975693 23162 solver.cpp:237] Iteration 15622, loss = 1.1097
I0520 18:32:08.975729 23162 solver.cpp:253]     Train net output #0: loss = 1.1097 (* 1 = 1.1097 loss)
I0520 18:32:08.975746 23162 sgd_solver.cpp:106] Iteration 15622, lr = 0.0025
I0520 18:32:40.089649 23162 solver.cpp:237] Iteration 15836, loss = 1.67208
I0520 18:32:40.089818 23162 solver.cpp:253]     Train net output #0: loss = 1.67208 (* 1 = 1.67208 loss)
I0520 18:32:40.089834 23162 sgd_solver.cpp:106] Iteration 15836, lr = 0.0025
I0520 18:32:48.973935 23162 solver.cpp:237] Iteration 16050, loss = 1.32056
I0520 18:32:48.973970 23162 solver.cpp:253]     Train net output #0: loss = 1.32056 (* 1 = 1.32056 loss)
I0520 18:32:48.973989 23162 sgd_solver.cpp:106] Iteration 16050, lr = 0.0025
I0520 18:32:57.862627 23162 solver.cpp:237] Iteration 16264, loss = 1.24413
I0520 18:32:57.862663 23162 solver.cpp:253]     Train net output #0: loss = 1.24413 (* 1 = 1.24413 loss)
I0520 18:32:57.862679 23162 sgd_solver.cpp:106] Iteration 16264, lr = 0.0025
I0520 18:33:06.751278 23162 solver.cpp:237] Iteration 16478, loss = 1.46396
I0520 18:33:06.751332 23162 solver.cpp:253]     Train net output #0: loss = 1.46396 (* 1 = 1.46396 loss)
I0520 18:33:06.751346 23162 sgd_solver.cpp:106] Iteration 16478, lr = 0.0025
I0520 18:33:15.638734 23162 solver.cpp:237] Iteration 16692, loss = 1.15662
I0520 18:33:15.638877 23162 solver.cpp:253]     Train net output #0: loss = 1.15662 (* 1 = 1.15662 loss)
I0520 18:33:15.638891 23162 sgd_solver.cpp:106] Iteration 16692, lr = 0.0025
I0520 18:33:24.522456 23162 solver.cpp:237] Iteration 16906, loss = 1.25089
I0520 18:33:24.522492 23162 solver.cpp:253]     Train net output #0: loss = 1.25089 (* 1 = 1.25089 loss)
I0520 18:33:24.522508 23162 sgd_solver.cpp:106] Iteration 16906, lr = 0.0025
I0520 18:33:33.413728 23162 solver.cpp:237] Iteration 17120, loss = 1.26661
I0520 18:33:33.413772 23162 solver.cpp:253]     Train net output #0: loss = 1.26661 (* 1 = 1.26661 loss)
I0520 18:33:33.413789 23162 sgd_solver.cpp:106] Iteration 17120, lr = 0.0025
I0520 18:33:34.035390 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_17136.caffemodel
I0520 18:33:34.101662 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_17136.solverstate
I0520 18:33:34.266484 23162 solver.cpp:341] Iteration 17140, Testing net (#0)
I0520 18:34:43.111290 23162 solver.cpp:409]     Test net output #0: accuracy = 0.861338
I0520 18:34:43.111472 23162 solver.cpp:409]     Test net output #1: loss = 0.479297 (* 1 = 0.479297 loss)
I0520 18:35:13.411739 23162 solver.cpp:237] Iteration 17334, loss = 1.56201
I0520 18:35:13.411912 23162 solver.cpp:253]     Train net output #0: loss = 1.56201 (* 1 = 1.56201 loss)
I0520 18:35:13.411928 23162 sgd_solver.cpp:106] Iteration 17334, lr = 0.0025
I0520 18:35:22.310314 23162 solver.cpp:237] Iteration 17548, loss = 1.59187
I0520 18:35:22.310350 23162 solver.cpp:253]     Train net output #0: loss = 1.59187 (* 1 = 1.59187 loss)
I0520 18:35:22.310365 23162 sgd_solver.cpp:106] Iteration 17548, lr = 0.0025
I0520 18:35:31.205229 23162 solver.cpp:237] Iteration 17762, loss = 1.24312
I0520 18:35:31.205262 23162 solver.cpp:253]     Train net output #0: loss = 1.24312 (* 1 = 1.24312 loss)
I0520 18:35:31.205279 23162 sgd_solver.cpp:106] Iteration 17762, lr = 0.0025
I0520 18:35:40.098368 23162 solver.cpp:237] Iteration 17976, loss = 1.17895
I0520 18:35:40.098412 23162 solver.cpp:253]     Train net output #0: loss = 1.17895 (* 1 = 1.17895 loss)
I0520 18:35:40.098433 23162 sgd_solver.cpp:106] Iteration 17976, lr = 0.0025
I0520 18:35:48.987318 23162 solver.cpp:237] Iteration 18190, loss = 1.23692
I0520 18:35:48.987462 23162 solver.cpp:253]     Train net output #0: loss = 1.23692 (* 1 = 1.23692 loss)
I0520 18:35:48.987476 23162 sgd_solver.cpp:106] Iteration 18190, lr = 0.0025
I0520 18:35:57.885385 23162 solver.cpp:237] Iteration 18404, loss = 1.2126
I0520 18:35:57.885429 23162 solver.cpp:253]     Train net output #0: loss = 1.2126 (* 1 = 1.2126 loss)
I0520 18:35:57.885448 23162 sgd_solver.cpp:106] Iteration 18404, lr = 0.0025
I0520 18:36:29.013963 23162 solver.cpp:237] Iteration 18618, loss = 1.21177
I0520 18:36:29.014137 23162 solver.cpp:253]     Train net output #0: loss = 1.21177 (* 1 = 1.21177 loss)
I0520 18:36:29.014152 23162 sgd_solver.cpp:106] Iteration 18618, lr = 0.0025
I0520 18:36:37.916040 23162 solver.cpp:237] Iteration 18832, loss = 1.24894
I0520 18:36:37.916075 23162 solver.cpp:253]     Train net output #0: loss = 1.24894 (* 1 = 1.24894 loss)
I0520 18:36:37.916092 23162 sgd_solver.cpp:106] Iteration 18832, lr = 0.0025
I0520 18:36:46.813879 23162 solver.cpp:237] Iteration 19046, loss = 1.24583
I0520 18:36:46.813915 23162 solver.cpp:253]     Train net output #0: loss = 1.24583 (* 1 = 1.24583 loss)
I0520 18:36:46.813930 23162 sgd_solver.cpp:106] Iteration 19046, lr = 0.0025
I0520 18:36:55.705992 23162 solver.cpp:237] Iteration 19260, loss = 1.45893
I0520 18:36:55.706043 23162 solver.cpp:253]     Train net output #0: loss = 1.45893 (* 1 = 1.45893 loss)
I0520 18:36:55.706058 23162 sgd_solver.cpp:106] Iteration 19260, lr = 0.0025
I0520 18:36:56.412068 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_19278.caffemodel
I0520 18:36:56.480976 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_19278.solverstate
I0520 18:37:04.668922 23162 solver.cpp:237] Iteration 19474, loss = 1.41629
I0520 18:37:04.669090 23162 solver.cpp:253]     Train net output #0: loss = 1.41629 (* 1 = 1.41629 loss)
I0520 18:37:04.669103 23162 sgd_solver.cpp:106] Iteration 19474, lr = 0.0025
I0520 18:37:13.568162 23162 solver.cpp:237] Iteration 19688, loss = 1.13286
I0520 18:37:13.568210 23162 solver.cpp:253]     Train net output #0: loss = 1.13286 (* 1 = 1.13286 loss)
I0520 18:37:13.568231 23162 sgd_solver.cpp:106] Iteration 19688, lr = 0.0025
I0520 18:37:22.464504 23162 solver.cpp:237] Iteration 19902, loss = 1.21786
I0520 18:37:22.464540 23162 solver.cpp:253]     Train net output #0: loss = 1.21786 (* 1 = 1.21786 loss)
I0520 18:37:22.464557 23162 sgd_solver.cpp:106] Iteration 19902, lr = 0.0025
I0520 18:37:53.564259 23162 solver.cpp:237] Iteration 20116, loss = 1.13715
I0520 18:37:53.564448 23162 solver.cpp:253]     Train net output #0: loss = 1.13715 (* 1 = 1.13715 loss)
I0520 18:37:53.564463 23162 sgd_solver.cpp:106] Iteration 20116, lr = 0.0025
I0520 18:38:02.456310 23162 solver.cpp:237] Iteration 20330, loss = 1.38885
I0520 18:38:02.456369 23162 solver.cpp:253]     Train net output #0: loss = 1.38885 (* 1 = 1.38885 loss)
I0520 18:38:02.456385 23162 sgd_solver.cpp:106] Iteration 20330, lr = 0.0025
I0520 18:38:11.362819 23162 solver.cpp:237] Iteration 20544, loss = 1.38952
I0520 18:38:11.362855 23162 solver.cpp:253]     Train net output #0: loss = 1.38952 (* 1 = 1.38952 loss)
I0520 18:38:11.362872 23162 sgd_solver.cpp:106] Iteration 20544, lr = 0.0025
I0520 18:38:20.247938 23162 solver.cpp:237] Iteration 20758, loss = 1.15974
I0520 18:38:20.247973 23162 solver.cpp:253]     Train net output #0: loss = 1.15974 (* 1 = 1.15974 loss)
I0520 18:38:20.247989 23162 sgd_solver.cpp:106] Iteration 20758, lr = 0.0025
I0520 18:38:29.144229 23162 solver.cpp:237] Iteration 20972, loss = 1.39022
I0520 18:38:29.144389 23162 solver.cpp:253]     Train net output #0: loss = 1.39022 (* 1 = 1.39022 loss)
I0520 18:38:29.144403 23162 sgd_solver.cpp:106] Iteration 20972, lr = 0.0025
I0520 18:38:38.045867 23162 solver.cpp:237] Iteration 21186, loss = 1.2423
I0520 18:38:38.045902 23162 solver.cpp:253]     Train net output #0: loss = 1.2423 (* 1 = 1.2423 loss)
I0520 18:38:38.045920 23162 sgd_solver.cpp:106] Iteration 21186, lr = 0.0025
I0520 18:38:46.944738 23162 solver.cpp:237] Iteration 21400, loss = 1.25984
I0520 18:38:46.944774 23162 solver.cpp:253]     Train net output #0: loss = 1.25984 (* 1 = 1.25984 loss)
I0520 18:38:46.944790 23162 sgd_solver.cpp:106] Iteration 21400, lr = 0.0025
I0520 18:38:47.735190 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_21420.caffemodel
I0520 18:38:47.805042 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_21420.solverstate
I0520 18:38:48.013265 23162 solver.cpp:341] Iteration 21425, Testing net (#0)
I0520 18:39:35.996219 23162 solver.cpp:409]     Test net output #0: accuracy = 0.862211
I0520 18:39:35.996394 23162 solver.cpp:409]     Test net output #1: loss = 0.440165 (* 1 = 0.440165 loss)
I0520 18:40:04.799044 23162 solver.cpp:237] Iteration 21614, loss = 1.14622
I0520 18:40:04.799095 23162 solver.cpp:253]     Train net output #0: loss = 1.14622 (* 1 = 1.14622 loss)
I0520 18:40:04.799114 23162 sgd_solver.cpp:106] Iteration 21614, lr = 0.0025
I0520 18:40:13.719303 23162 solver.cpp:237] Iteration 21828, loss = 1.26762
I0520 18:40:13.719468 23162 solver.cpp:253]     Train net output #0: loss = 1.26762 (* 1 = 1.26762 loss)
I0520 18:40:13.719482 23162 sgd_solver.cpp:106] Iteration 21828, lr = 0.0025
I0520 18:40:22.633011 23162 solver.cpp:237] Iteration 22042, loss = 1.10548
I0520 18:40:22.633046 23162 solver.cpp:253]     Train net output #0: loss = 1.10548 (* 1 = 1.10548 loss)
I0520 18:40:22.633064 23162 sgd_solver.cpp:106] Iteration 22042, lr = 0.0025
I0520 18:40:31.546507 23162 solver.cpp:237] Iteration 22256, loss = 1.48613
I0520 18:40:31.546543 23162 solver.cpp:253]     Train net output #0: loss = 1.48613 (* 1 = 1.48613 loss)
I0520 18:40:31.546556 23162 sgd_solver.cpp:106] Iteration 22256, lr = 0.0025
I0520 18:40:40.458957 23162 solver.cpp:237] Iteration 22470, loss = 0.920672
I0520 18:40:40.459002 23162 solver.cpp:253]     Train net output #0: loss = 0.920672 (* 1 = 0.920672 loss)
I0520 18:40:40.459022 23162 sgd_solver.cpp:106] Iteration 22470, lr = 0.0025
I0520 18:40:49.381078 23162 solver.cpp:237] Iteration 22684, loss = 1.19566
I0520 18:40:49.381234 23162 solver.cpp:253]     Train net output #0: loss = 1.19566 (* 1 = 1.19566 loss)
I0520 18:40:49.381247 23162 sgd_solver.cpp:106] Iteration 22684, lr = 0.0025
I0520 18:41:19.170352 23162 solver.cpp:237] Iteration 22898, loss = 1.34922
I0520 18:41:19.170403 23162 solver.cpp:253]     Train net output #0: loss = 1.34922 (* 1 = 1.34922 loss)
I0520 18:41:19.170423 23162 sgd_solver.cpp:106] Iteration 22898, lr = 0.0025
I0520 18:41:28.135489 23162 solver.cpp:237] Iteration 23112, loss = 1.24771
I0520 18:41:28.135653 23162 solver.cpp:253]     Train net output #0: loss = 1.24771 (* 1 = 1.24771 loss)
I0520 18:41:28.135668 23162 sgd_solver.cpp:106] Iteration 23112, lr = 0.0025
I0520 18:41:37.047979 23162 solver.cpp:237] Iteration 23326, loss = 1.40117
I0520 18:41:37.048015 23162 solver.cpp:253]     Train net output #0: loss = 1.40117 (* 1 = 1.40117 loss)
I0520 18:41:37.048032 23162 sgd_solver.cpp:106] Iteration 23326, lr = 0.0025
I0520 18:41:45.958523 23162 solver.cpp:237] Iteration 23540, loss = 1.29228
I0520 18:41:45.958557 23162 solver.cpp:253]     Train net output #0: loss = 1.29228 (* 1 = 1.29228 loss)
I0520 18:41:45.958573 23162 sgd_solver.cpp:106] Iteration 23540, lr = 0.0025
I0520 18:41:46.832172 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_23562.caffemodel
I0520 18:41:46.898819 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_23562.solverstate
I0520 18:41:54.941011 23162 solver.cpp:237] Iteration 23754, loss = 1.19048
I0520 18:41:54.941063 23162 solver.cpp:253]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I0520 18:41:54.941079 23162 sgd_solver.cpp:106] Iteration 23754, lr = 0.0025
I0520 18:42:03.852154 23162 solver.cpp:237] Iteration 23968, loss = 1.20345
I0520 18:42:03.852308 23162 solver.cpp:253]     Train net output #0: loss = 1.20345 (* 1 = 1.20345 loss)
I0520 18:42:03.852322 23162 sgd_solver.cpp:106] Iteration 23968, lr = 0.0025
I0520 18:42:12.775730 23162 solver.cpp:237] Iteration 24182, loss = 1.36717
I0520 18:42:12.775782 23162 solver.cpp:253]     Train net output #0: loss = 1.36717 (* 1 = 1.36717 loss)
I0520 18:42:12.775795 23162 sgd_solver.cpp:106] Iteration 24182, lr = 0.0025
I0520 18:42:42.580401 23162 solver.cpp:237] Iteration 24396, loss = 1.02786
I0520 18:42:42.580585 23162 solver.cpp:253]     Train net output #0: loss = 1.02786 (* 1 = 1.02786 loss)
I0520 18:42:42.580600 23162 sgd_solver.cpp:106] Iteration 24396, lr = 0.0025
I0520 18:42:51.496173 23162 solver.cpp:237] Iteration 24610, loss = 1.14988
I0520 18:42:51.496207 23162 solver.cpp:253]     Train net output #0: loss = 1.14988 (* 1 = 1.14988 loss)
I0520 18:42:51.496225 23162 sgd_solver.cpp:106] Iteration 24610, lr = 0.0025
I0520 18:43:00.413326 23162 solver.cpp:237] Iteration 24824, loss = 1.18694
I0520 18:43:00.413359 23162 solver.cpp:253]     Train net output #0: loss = 1.18694 (* 1 = 1.18694 loss)
I0520 18:43:00.413378 23162 sgd_solver.cpp:106] Iteration 24824, lr = 0.0025
I0520 18:43:09.334944 23162 solver.cpp:237] Iteration 25038, loss = 0.995843
I0520 18:43:09.334987 23162 solver.cpp:253]     Train net output #0: loss = 0.995843 (* 1 = 0.995843 loss)
I0520 18:43:09.335008 23162 sgd_solver.cpp:106] Iteration 25038, lr = 0.0025
I0520 18:43:18.250850 23162 solver.cpp:237] Iteration 25252, loss = 1.33212
I0520 18:43:18.250995 23162 solver.cpp:253]     Train net output #0: loss = 1.33212 (* 1 = 1.33212 loss)
I0520 18:43:18.251009 23162 sgd_solver.cpp:106] Iteration 25252, lr = 0.0025
I0520 18:43:27.169126 23162 solver.cpp:237] Iteration 25466, loss = 1.12947
I0520 18:43:27.169160 23162 solver.cpp:253]     Train net output #0: loss = 1.12947 (* 1 = 1.12947 loss)
I0520 18:43:27.169178 23162 sgd_solver.cpp:106] Iteration 25466, lr = 0.0025
I0520 18:43:36.086738 23162 solver.cpp:237] Iteration 25680, loss = 1.20704
I0520 18:43:36.086783 23162 solver.cpp:253]     Train net output #0: loss = 1.20704 (* 1 = 1.20704 loss)
I0520 18:43:36.086802 23162 sgd_solver.cpp:106] Iteration 25680, lr = 0.0025
I0520 18:43:37.045960 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_25704.caffemodel
I0520 18:43:37.112478 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_25704.solverstate
I0520 18:43:37.360239 23162 solver.cpp:341] Iteration 25710, Testing net (#0)
I0520 18:44:46.178922 23162 solver.cpp:409]     Test net output #0: accuracy = 0.870361
I0520 18:44:46.179112 23162 solver.cpp:409]     Test net output #1: loss = 0.404569 (* 1 = 0.404569 loss)
I0520 18:45:14.703723 23162 solver.cpp:237] Iteration 25894, loss = 1.07795
I0520 18:45:14.703774 23162 solver.cpp:253]     Train net output #0: loss = 1.07795 (* 1 = 1.07795 loss)
I0520 18:45:14.703794 23162 sgd_solver.cpp:106] Iteration 25894, lr = 0.0025
I0520 18:45:23.597539 23162 solver.cpp:237] Iteration 26108, loss = 1.28679
I0520 18:45:23.597705 23162 solver.cpp:253]     Train net output #0: loss = 1.28679 (* 1 = 1.28679 loss)
I0520 18:45:23.597718 23162 sgd_solver.cpp:106] Iteration 26108, lr = 0.0025
I0520 18:45:32.484441 23162 solver.cpp:237] Iteration 26322, loss = 1.09849
I0520 18:45:32.484488 23162 solver.cpp:253]     Train net output #0: loss = 1.09849 (* 1 = 1.09849 loss)
I0520 18:45:32.484506 23162 sgd_solver.cpp:106] Iteration 26322, lr = 0.0025
I0520 18:45:41.375608 23162 solver.cpp:237] Iteration 26536, loss = 1.11974
I0520 18:45:41.375643 23162 solver.cpp:253]     Train net output #0: loss = 1.11974 (* 1 = 1.11974 loss)
I0520 18:45:41.375659 23162 sgd_solver.cpp:106] Iteration 26536, lr = 0.0025
I0520 18:45:50.265898 23162 solver.cpp:237] Iteration 26750, loss = 1.01991
I0520 18:45:50.265934 23162 solver.cpp:253]     Train net output #0: loss = 1.01991 (* 1 = 1.01991 loss)
I0520 18:45:50.265947 23162 sgd_solver.cpp:106] Iteration 26750, lr = 0.0025
I0520 18:45:59.150723 23162 solver.cpp:237] Iteration 26964, loss = 1.18989
I0520 18:45:59.150890 23162 solver.cpp:253]     Train net output #0: loss = 1.18989 (* 1 = 1.18989 loss)
I0520 18:45:59.150904 23162 sgd_solver.cpp:106] Iteration 26964, lr = 0.0025
I0520 18:46:28.941895 23162 solver.cpp:237] Iteration 27178, loss = 1.15404
I0520 18:46:28.941946 23162 solver.cpp:253]     Train net output #0: loss = 1.15404 (* 1 = 1.15404 loss)
I0520 18:46:28.941964 23162 sgd_solver.cpp:106] Iteration 27178, lr = 0.0025
I0520 18:46:37.829315 23162 solver.cpp:237] Iteration 27392, loss = 1.22301
I0520 18:46:37.829470 23162 solver.cpp:253]     Train net output #0: loss = 1.22301 (* 1 = 1.22301 loss)
I0520 18:46:37.829483 23162 sgd_solver.cpp:106] Iteration 27392, lr = 0.0025
I0520 18:46:46.715253 23162 solver.cpp:237] Iteration 27606, loss = 1.26661
I0520 18:46:46.715288 23162 solver.cpp:253]     Train net output #0: loss = 1.26661 (* 1 = 1.26661 loss)
I0520 18:46:46.715303 23162 sgd_solver.cpp:106] Iteration 27606, lr = 0.0025
I0520 18:46:55.605810 23162 solver.cpp:237] Iteration 27820, loss = 1.18731
I0520 18:46:55.605857 23162 solver.cpp:253]     Train net output #0: loss = 1.18731 (* 1 = 1.18731 loss)
I0520 18:46:55.605871 23162 sgd_solver.cpp:106] Iteration 27820, lr = 0.0025
I0520 18:46:56.645192 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_27846.caffemodel
I0520 18:46:56.711971 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_27846.solverstate
I0520 18:47:04.562093 23162 solver.cpp:237] Iteration 28034, loss = 1.13763
I0520 18:47:04.562139 23162 solver.cpp:253]     Train net output #0: loss = 1.13763 (* 1 = 1.13763 loss)
I0520 18:47:04.562157 23162 sgd_solver.cpp:106] Iteration 28034, lr = 0.0025
I0520 18:47:13.447492 23162 solver.cpp:237] Iteration 28248, loss = 1.12047
I0520 18:47:13.447664 23162 solver.cpp:253]     Train net output #0: loss = 1.12047 (* 1 = 1.12047 loss)
I0520 18:47:13.447677 23162 sgd_solver.cpp:106] Iteration 28248, lr = 0.0025
I0520 18:47:22.336310 23162 solver.cpp:237] Iteration 28462, loss = 1.46641
I0520 18:47:22.336345 23162 solver.cpp:253]     Train net output #0: loss = 1.46641 (* 1 = 1.46641 loss)
I0520 18:47:22.336360 23162 sgd_solver.cpp:106] Iteration 28462, lr = 0.0025
I0520 18:47:52.085057 23162 solver.cpp:237] Iteration 28676, loss = 1.30322
I0520 18:47:52.085233 23162 solver.cpp:253]     Train net output #0: loss = 1.30322 (* 1 = 1.30322 loss)
I0520 18:47:52.085247 23162 sgd_solver.cpp:106] Iteration 28676, lr = 0.0025
I0520 18:48:00.972256 23162 solver.cpp:237] Iteration 28890, loss = 1.23709
I0520 18:48:00.972292 23162 solver.cpp:253]     Train net output #0: loss = 1.23709 (* 1 = 1.23709 loss)
I0520 18:48:00.972307 23162 sgd_solver.cpp:106] Iteration 28890, lr = 0.0025
I0520 18:48:09.860210 23162 solver.cpp:237] Iteration 29104, loss = 1.00453
I0520 18:48:09.860256 23162 solver.cpp:253]     Train net output #0: loss = 1.00453 (* 1 = 1.00453 loss)
I0520 18:48:09.860275 23162 sgd_solver.cpp:106] Iteration 29104, lr = 0.0025
I0520 18:48:18.744460 23162 solver.cpp:237] Iteration 29318, loss = 1.08954
I0520 18:48:18.744495 23162 solver.cpp:253]     Train net output #0: loss = 1.08954 (* 1 = 1.08954 loss)
I0520 18:48:18.744509 23162 sgd_solver.cpp:106] Iteration 29318, lr = 0.0025
I0520 18:48:27.626348 23162 solver.cpp:237] Iteration 29532, loss = 1.13242
I0520 18:48:27.626502 23162 solver.cpp:253]     Train net output #0: loss = 1.13242 (* 1 = 1.13242 loss)
I0520 18:48:27.626515 23162 sgd_solver.cpp:106] Iteration 29532, lr = 0.0025
I0520 18:48:36.514382 23162 solver.cpp:237] Iteration 29746, loss = 1.13131
I0520 18:48:36.514416 23162 solver.cpp:253]     Train net output #0: loss = 1.13131 (* 1 = 1.13131 loss)
I0520 18:48:36.514431 23162 sgd_solver.cpp:106] Iteration 29746, lr = 0.0025
I0520 18:48:45.401182 23162 solver.cpp:237] Iteration 29960, loss = 1.23354
I0520 18:48:45.401217 23162 solver.cpp:253]     Train net output #0: loss = 1.23354 (* 1 = 1.23354 loss)
I0520 18:48:45.401232 23162 sgd_solver.cpp:106] Iteration 29960, lr = 0.0025
I0520 18:48:46.525794 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_29988.caffemodel
I0520 18:48:46.592066 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_29988.solverstate
I0520 18:48:46.882082 23162 solver.cpp:341] Iteration 29995, Testing net (#0)
I0520 18:49:34.473908 23162 solver.cpp:409]     Test net output #0: accuracy = 0.874123
I0520 18:49:34.474084 23162 solver.cpp:409]     Test net output #1: loss = 0.420622 (* 1 = 0.420622 loss)
I0520 18:50:02.791434 23162 solver.cpp:237] Iteration 30174, loss = 1.20631
I0520 18:50:02.791488 23162 solver.cpp:253]     Train net output #0: loss = 1.20631 (* 1 = 1.20631 loss)
I0520 18:50:02.791503 23162 sgd_solver.cpp:106] Iteration 30174, lr = 0.0025
I0520 18:50:11.675935 23162 solver.cpp:237] Iteration 30388, loss = 1.18681
I0520 18:50:11.676101 23162 solver.cpp:253]     Train net output #0: loss = 1.18681 (* 1 = 1.18681 loss)
I0520 18:50:11.676115 23162 sgd_solver.cpp:106] Iteration 30388, lr = 0.0025
I0520 18:50:20.563585 23162 solver.cpp:237] Iteration 30602, loss = 1.08302
I0520 18:50:20.563621 23162 solver.cpp:253]     Train net output #0: loss = 1.08302 (* 1 = 1.08302 loss)
I0520 18:50:20.563635 23162 sgd_solver.cpp:106] Iteration 30602, lr = 0.0025
I0520 18:50:29.454962 23162 solver.cpp:237] Iteration 30816, loss = 1.11265
I0520 18:50:29.454996 23162 solver.cpp:253]     Train net output #0: loss = 1.11265 (* 1 = 1.11265 loss)
I0520 18:50:29.455011 23162 sgd_solver.cpp:106] Iteration 30816, lr = 0.0025
I0520 18:50:38.348253 23162 solver.cpp:237] Iteration 31030, loss = 1.18161
I0520 18:50:38.348300 23162 solver.cpp:253]     Train net output #0: loss = 1.18161 (* 1 = 1.18161 loss)
I0520 18:50:38.348315 23162 sgd_solver.cpp:106] Iteration 31030, lr = 0.0025
I0520 18:50:47.241713 23162 solver.cpp:237] Iteration 31244, loss = 1.16769
I0520 18:50:47.241873 23162 solver.cpp:253]     Train net output #0: loss = 1.16769 (* 1 = 1.16769 loss)
I0520 18:50:47.241886 23162 sgd_solver.cpp:106] Iteration 31244, lr = 0.0025
I0520 18:51:16.978631 23162 solver.cpp:237] Iteration 31458, loss = 1.38058
I0520 18:51:16.978685 23162 solver.cpp:253]     Train net output #0: loss = 1.38058 (* 1 = 1.38058 loss)
I0520 18:51:16.978699 23162 sgd_solver.cpp:106] Iteration 31458, lr = 0.0025
I0520 18:51:25.862057 23162 solver.cpp:237] Iteration 31672, loss = 1.00489
I0520 18:51:25.862223 23162 solver.cpp:253]     Train net output #0: loss = 1.00489 (* 1 = 1.00489 loss)
I0520 18:51:25.862237 23162 sgd_solver.cpp:106] Iteration 31672, lr = 0.0025
I0520 18:51:34.747843 23162 solver.cpp:237] Iteration 31886, loss = 1.21693
I0520 18:51:34.747877 23162 solver.cpp:253]     Train net output #0: loss = 1.21693 (* 1 = 1.21693 loss)
I0520 18:51:34.747892 23162 sgd_solver.cpp:106] Iteration 31886, lr = 0.0025
I0520 18:51:43.632815 23162 solver.cpp:237] Iteration 32100, loss = 0.837205
I0520 18:51:43.632851 23162 solver.cpp:253]     Train net output #0: loss = 0.837205 (* 1 = 0.837205 loss)
I0520 18:51:43.632865 23162 sgd_solver.cpp:106] Iteration 32100, lr = 0.0025
I0520 18:51:44.835860 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_32130.caffemodel
I0520 18:51:44.904789 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_32130.solverstate
I0520 18:51:52.588541 23162 solver.cpp:237] Iteration 32314, loss = 1.26954
I0520 18:51:52.588593 23162 solver.cpp:253]     Train net output #0: loss = 1.26954 (* 1 = 1.26954 loss)
I0520 18:51:52.588608 23162 sgd_solver.cpp:106] Iteration 32314, lr = 0.0025
I0520 18:52:01.471354 23162 solver.cpp:237] Iteration 32528, loss = 1.28368
I0520 18:52:01.471508 23162 solver.cpp:253]     Train net output #0: loss = 1.28368 (* 1 = 1.28368 loss)
I0520 18:52:01.471523 23162 sgd_solver.cpp:106] Iteration 32528, lr = 0.0025
I0520 18:52:10.356425 23162 solver.cpp:237] Iteration 32742, loss = 0.995176
I0520 18:52:10.356459 23162 solver.cpp:253]     Train net output #0: loss = 0.995176 (* 1 = 0.995176 loss)
I0520 18:52:10.356475 23162 sgd_solver.cpp:106] Iteration 32742, lr = 0.0025
I0520 18:52:40.073596 23162 solver.cpp:237] Iteration 32956, loss = 1.24897
I0520 18:52:40.073787 23162 solver.cpp:253]     Train net output #0: loss = 1.24897 (* 1 = 1.24897 loss)
I0520 18:52:40.073802 23162 sgd_solver.cpp:106] Iteration 32956, lr = 0.0025
I0520 18:52:48.959370 23162 solver.cpp:237] Iteration 33170, loss = 1.0872
I0520 18:52:48.959404 23162 solver.cpp:253]     Train net output #0: loss = 1.0872 (* 1 = 1.0872 loss)
I0520 18:52:48.959420 23162 sgd_solver.cpp:106] Iteration 33170, lr = 0.0025
I0520 18:52:57.846601 23162 solver.cpp:237] Iteration 33384, loss = 1.21087
I0520 18:52:57.846637 23162 solver.cpp:253]     Train net output #0: loss = 1.21087 (* 1 = 1.21087 loss)
I0520 18:52:57.846650 23162 sgd_solver.cpp:106] Iteration 33384, lr = 0.0025
I0520 18:53:06.736124 23162 solver.cpp:237] Iteration 33598, loss = 1.22055
I0520 18:53:06.736169 23162 solver.cpp:253]     Train net output #0: loss = 1.22055 (* 1 = 1.22055 loss)
I0520 18:53:06.736188 23162 sgd_solver.cpp:106] Iteration 33598, lr = 0.0025
I0520 18:53:15.617441 23162 solver.cpp:237] Iteration 33812, loss = 1.14194
I0520 18:53:15.617614 23162 solver.cpp:253]     Train net output #0: loss = 1.14194 (* 1 = 1.14194 loss)
I0520 18:53:15.617627 23162 sgd_solver.cpp:106] Iteration 33812, lr = 0.0025
I0520 18:53:24.496683 23162 solver.cpp:237] Iteration 34026, loss = 1.28155
I0520 18:53:24.496717 23162 solver.cpp:253]     Train net output #0: loss = 1.28155 (* 1 = 1.28155 loss)
I0520 18:53:24.496733 23162 sgd_solver.cpp:106] Iteration 34026, lr = 0.0025
I0520 18:53:33.380964 23162 solver.cpp:237] Iteration 34240, loss = 1.25491
I0520 18:53:33.381016 23162 solver.cpp:253]     Train net output #0: loss = 1.25491 (* 1 = 1.25491 loss)
I0520 18:53:33.381029 23162 sgd_solver.cpp:106] Iteration 34240, lr = 0.0025
I0520 18:53:34.669973 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_34272.caffemodel
I0520 18:53:34.736485 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_34272.solverstate
I0520 18:53:35.065825 23162 solver.cpp:341] Iteration 34280, Testing net (#0)
I0520 18:54:43.805507 23162 solver.cpp:409]     Test net output #0: accuracy = 0.87569
I0520 18:54:43.805685 23162 solver.cpp:409]     Test net output #1: loss = 0.393297 (* 1 = 0.393297 loss)
I0520 18:55:11.888919 23162 solver.cpp:237] Iteration 34454, loss = 1.32772
I0520 18:55:11.888973 23162 solver.cpp:253]     Train net output #0: loss = 1.32772 (* 1 = 1.32772 loss)
I0520 18:55:11.888988 23162 sgd_solver.cpp:106] Iteration 34454, lr = 0.0025
I0520 18:55:20.761649 23162 solver.cpp:237] Iteration 34668, loss = 1.12501
I0520 18:55:20.761806 23162 solver.cpp:253]     Train net output #0: loss = 1.12501 (* 1 = 1.12501 loss)
I0520 18:55:20.761818 23162 sgd_solver.cpp:106] Iteration 34668, lr = 0.0025
I0520 18:55:29.631889 23162 solver.cpp:237] Iteration 34882, loss = 1.03713
I0520 18:55:29.631924 23162 solver.cpp:253]     Train net output #0: loss = 1.03713 (* 1 = 1.03713 loss)
I0520 18:55:29.631938 23162 sgd_solver.cpp:106] Iteration 34882, lr = 0.0025
I0520 18:55:38.507601 23162 solver.cpp:237] Iteration 35096, loss = 1.36886
I0520 18:55:38.507649 23162 solver.cpp:253]     Train net output #0: loss = 1.36886 (* 1 = 1.36886 loss)
I0520 18:55:38.507668 23162 sgd_solver.cpp:106] Iteration 35096, lr = 0.0025
I0520 18:55:47.386698 23162 solver.cpp:237] Iteration 35310, loss = 1.35986
I0520 18:55:47.386734 23162 solver.cpp:253]     Train net output #0: loss = 1.35986 (* 1 = 1.35986 loss)
I0520 18:55:47.386747 23162 sgd_solver.cpp:106] Iteration 35310, lr = 0.0025
I0520 18:55:56.266710 23162 solver.cpp:237] Iteration 35524, loss = 1.44086
I0520 18:55:56.266863 23162 solver.cpp:253]     Train net output #0: loss = 1.44086 (* 1 = 1.44086 loss)
I0520 18:55:56.266876 23162 sgd_solver.cpp:106] Iteration 35524, lr = 0.0025
I0520 18:56:25.991433 23162 solver.cpp:237] Iteration 35738, loss = 1.50767
I0520 18:56:25.991484 23162 solver.cpp:253]     Train net output #0: loss = 1.50767 (* 1 = 1.50767 loss)
I0520 18:56:25.991503 23162 sgd_solver.cpp:106] Iteration 35738, lr = 0.0025
I0520 18:56:34.859151 23162 solver.cpp:237] Iteration 35952, loss = 1.13827
I0520 18:56:34.859304 23162 solver.cpp:253]     Train net output #0: loss = 1.13827 (* 1 = 1.13827 loss)
I0520 18:56:34.859318 23162 sgd_solver.cpp:106] Iteration 35952, lr = 0.0025
I0520 18:56:43.731333 23162 solver.cpp:237] Iteration 36166, loss = 1.19494
I0520 18:56:43.731369 23162 solver.cpp:253]     Train net output #0: loss = 1.19494 (* 1 = 1.19494 loss)
I0520 18:56:43.731384 23162 sgd_solver.cpp:106] Iteration 36166, lr = 0.0025
I0520 18:56:52.612094 23162 solver.cpp:237] Iteration 36380, loss = 1.07931
I0520 18:56:52.612145 23162 solver.cpp:253]     Train net output #0: loss = 1.07931 (* 1 = 1.07931 loss)
I0520 18:56:52.612160 23162 sgd_solver.cpp:106] Iteration 36380, lr = 0.0025
I0520 18:56:53.978857 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_36414.caffemodel
I0520 18:56:54.044651 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_36414.solverstate
I0520 18:57:01.559716 23162 solver.cpp:237] Iteration 36594, loss = 1.0348
I0520 18:57:01.559763 23162 solver.cpp:253]     Train net output #0: loss = 1.0348 (* 1 = 1.0348 loss)
I0520 18:57:01.559780 23162 sgd_solver.cpp:106] Iteration 36594, lr = 0.0025
I0520 18:57:10.441329 23162 solver.cpp:237] Iteration 36808, loss = 0.963443
I0520 18:57:10.441498 23162 solver.cpp:253]     Train net output #0: loss = 0.963443 (* 1 = 0.963443 loss)
I0520 18:57:10.441511 23162 sgd_solver.cpp:106] Iteration 36808, lr = 0.0025
I0520 18:57:19.323176 23162 solver.cpp:237] Iteration 37022, loss = 1.41979
I0520 18:57:19.323220 23162 solver.cpp:253]     Train net output #0: loss = 1.41979 (* 1 = 1.41979 loss)
I0520 18:57:19.323238 23162 sgd_solver.cpp:106] Iteration 37022, lr = 0.0025
I0520 18:57:49.046495 23162 solver.cpp:237] Iteration 37236, loss = 1.16986
I0520 18:57:49.046676 23162 solver.cpp:253]     Train net output #0: loss = 1.16986 (* 1 = 1.16986 loss)
I0520 18:57:49.046691 23162 sgd_solver.cpp:106] Iteration 37236, lr = 0.0025
I0520 18:57:57.924366 23162 solver.cpp:237] Iteration 37450, loss = 1.13732
I0520 18:57:57.924401 23162 solver.cpp:253]     Train net output #0: loss = 1.13732 (* 1 = 1.13732 loss)
I0520 18:57:57.924417 23162 sgd_solver.cpp:106] Iteration 37450, lr = 0.0025
I0520 18:58:06.797767 23162 solver.cpp:237] Iteration 37664, loss = 1.23072
I0520 18:58:06.797809 23162 solver.cpp:253]     Train net output #0: loss = 1.23072 (* 1 = 1.23072 loss)
I0520 18:58:06.797827 23162 sgd_solver.cpp:106] Iteration 37664, lr = 0.0025
I0520 18:58:15.671241 23162 solver.cpp:237] Iteration 37878, loss = 1.23647
I0520 18:58:15.671275 23162 solver.cpp:253]     Train net output #0: loss = 1.23647 (* 1 = 1.23647 loss)
I0520 18:58:15.671288 23162 sgd_solver.cpp:106] Iteration 37878, lr = 0.0025
I0520 18:58:24.544198 23162 solver.cpp:237] Iteration 38092, loss = 1.38142
I0520 18:58:24.544363 23162 solver.cpp:253]     Train net output #0: loss = 1.38142 (* 1 = 1.38142 loss)
I0520 18:58:24.544376 23162 sgd_solver.cpp:106] Iteration 38092, lr = 0.0025
I0520 18:58:33.421993 23162 solver.cpp:237] Iteration 38306, loss = 1.25473
I0520 18:58:33.422034 23162 solver.cpp:253]     Train net output #0: loss = 1.25473 (* 1 = 1.25473 loss)
I0520 18:58:33.422052 23162 sgd_solver.cpp:106] Iteration 38306, lr = 0.0025
I0520 18:58:42.298880 23162 solver.cpp:237] Iteration 38520, loss = 1.33165
I0520 18:58:42.298915 23162 solver.cpp:253]     Train net output #0: loss = 1.33165 (* 1 = 1.33165 loss)
I0520 18:58:42.298928 23162 sgd_solver.cpp:106] Iteration 38520, lr = 0.0025
I0520 18:58:43.750460 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_38556.caffemodel
I0520 18:58:43.816871 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_38556.solverstate
I0520 18:58:44.189617 23162 solver.cpp:341] Iteration 38565, Testing net (#0)
I0520 18:59:32.087604 23162 solver.cpp:409]     Test net output #0: accuracy = 0.879479
I0520 18:59:32.087780 23162 solver.cpp:409]     Test net output #1: loss = 0.395078 (* 1 = 0.395078 loss)
I0520 18:59:59.957509 23162 solver.cpp:237] Iteration 38734, loss = 1.12918
I0520 18:59:59.957563 23162 solver.cpp:253]     Train net output #0: loss = 1.12918 (* 1 = 1.12918 loss)
I0520 18:59:59.957577 23162 sgd_solver.cpp:106] Iteration 38734, lr = 0.0025
I0520 19:00:08.857051 23162 solver.cpp:237] Iteration 38948, loss = 1.05323
I0520 19:00:08.857234 23162 solver.cpp:253]     Train net output #0: loss = 1.05323 (* 1 = 1.05323 loss)
I0520 19:00:08.857249 23162 sgd_solver.cpp:106] Iteration 38948, lr = 0.0025
I0520 19:00:17.756599 23162 solver.cpp:237] Iteration 39162, loss = 1.24241
I0520 19:00:17.756634 23162 solver.cpp:253]     Train net output #0: loss = 1.24241 (* 1 = 1.24241 loss)
I0520 19:00:17.756649 23162 sgd_solver.cpp:106] Iteration 39162, lr = 0.0025
I0520 19:00:26.652511 23162 solver.cpp:237] Iteration 39376, loss = 0.988043
I0520 19:00:26.652547 23162 solver.cpp:253]     Train net output #0: loss = 0.988043 (* 1 = 0.988043 loss)
I0520 19:00:26.652560 23162 sgd_solver.cpp:106] Iteration 39376, lr = 0.0025
I0520 19:00:35.546900 23162 solver.cpp:237] Iteration 39590, loss = 1.34577
I0520 19:00:35.546939 23162 solver.cpp:253]     Train net output #0: loss = 1.34577 (* 1 = 1.34577 loss)
I0520 19:00:35.546960 23162 sgd_solver.cpp:106] Iteration 39590, lr = 0.0025
I0520 19:00:44.436733 23162 solver.cpp:237] Iteration 39804, loss = 1.23328
I0520 19:00:44.436887 23162 solver.cpp:253]     Train net output #0: loss = 1.23328 (* 1 = 1.23328 loss)
I0520 19:00:44.436900 23162 sgd_solver.cpp:106] Iteration 39804, lr = 0.0025
I0520 19:01:14.190771 23162 solver.cpp:237] Iteration 40018, loss = 1.18282
I0520 19:01:14.190826 23162 solver.cpp:253]     Train net output #0: loss = 1.18282 (* 1 = 1.18282 loss)
I0520 19:01:14.190840 23162 sgd_solver.cpp:106] Iteration 40018, lr = 0.0025
I0520 19:01:23.089578 23162 solver.cpp:237] Iteration 40232, loss = 1.31629
I0520 19:01:23.089764 23162 solver.cpp:253]     Train net output #0: loss = 1.31629 (* 1 = 1.31629 loss)
I0520 19:01:23.089778 23162 sgd_solver.cpp:106] Iteration 40232, lr = 0.0025
I0520 19:01:31.986234 23162 solver.cpp:237] Iteration 40446, loss = 1.15625
I0520 19:01:31.986265 23162 solver.cpp:253]     Train net output #0: loss = 1.15625 (* 1 = 1.15625 loss)
I0520 19:01:31.986279 23162 sgd_solver.cpp:106] Iteration 40446, lr = 0.0025
I0520 19:01:40.879715 23162 solver.cpp:237] Iteration 40660, loss = 1.12483
I0520 19:01:40.879751 23162 solver.cpp:253]     Train net output #0: loss = 1.12483 (* 1 = 1.12483 loss)
I0520 19:01:40.879765 23162 sgd_solver.cpp:106] Iteration 40660, lr = 0.0025
I0520 19:01:42.418470 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_40698.caffemodel
I0520 19:01:42.487184 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_40698.solverstate
I0520 19:01:49.849851 23162 solver.cpp:237] Iteration 40874, loss = 1.2031
I0520 19:01:49.849907 23162 solver.cpp:253]     Train net output #0: loss = 1.2031 (* 1 = 1.2031 loss)
I0520 19:01:49.849920 23162 sgd_solver.cpp:106] Iteration 40874, lr = 0.0025
I0520 19:01:58.747844 23162 solver.cpp:237] Iteration 41088, loss = 1.0638
I0520 19:01:58.748005 23162 solver.cpp:253]     Train net output #0: loss = 1.0638 (* 1 = 1.0638 loss)
I0520 19:01:58.748018 23162 sgd_solver.cpp:106] Iteration 41088, lr = 0.0025
I0520 19:02:07.642447 23162 solver.cpp:237] Iteration 41302, loss = 1.28731
I0520 19:02:07.642482 23162 solver.cpp:253]     Train net output #0: loss = 1.28731 (* 1 = 1.28731 loss)
I0520 19:02:07.642496 23162 sgd_solver.cpp:106] Iteration 41302, lr = 0.0025
I0520 19:02:37.420816 23162 solver.cpp:237] Iteration 41516, loss = 1.04299
I0520 19:02:37.420990 23162 solver.cpp:253]     Train net output #0: loss = 1.04299 (* 1 = 1.04299 loss)
I0520 19:02:37.421005 23162 sgd_solver.cpp:106] Iteration 41516, lr = 0.0025
I0520 19:02:46.308100 23162 solver.cpp:237] Iteration 41730, loss = 1.1633
I0520 19:02:46.308136 23162 solver.cpp:253]     Train net output #0: loss = 1.1633 (* 1 = 1.1633 loss)
I0520 19:02:46.308151 23162 sgd_solver.cpp:106] Iteration 41730, lr = 0.0025
I0520 19:02:55.206446 23162 solver.cpp:237] Iteration 41944, loss = 1.43645
I0520 19:02:55.206482 23162 solver.cpp:253]     Train net output #0: loss = 1.43645 (* 1 = 1.43645 loss)
I0520 19:02:55.206497 23162 sgd_solver.cpp:106] Iteration 41944, lr = 0.0025
I0520 19:03:04.096427 23162 solver.cpp:237] Iteration 42158, loss = 1.27791
I0520 19:03:04.096477 23162 solver.cpp:253]     Train net output #0: loss = 1.27791 (* 1 = 1.27791 loss)
I0520 19:03:04.096493 23162 sgd_solver.cpp:106] Iteration 42158, lr = 0.0025
I0520 19:03:12.991509 23162 solver.cpp:237] Iteration 42372, loss = 1.07096
I0520 19:03:12.991670 23162 solver.cpp:253]     Train net output #0: loss = 1.07096 (* 1 = 1.07096 loss)
I0520 19:03:12.991683 23162 sgd_solver.cpp:106] Iteration 42372, lr = 0.0025
I0520 19:03:21.887289 23162 solver.cpp:237] Iteration 42586, loss = 1.43951
I0520 19:03:21.887322 23162 solver.cpp:253]     Train net output #0: loss = 1.43951 (* 1 = 1.43951 loss)
I0520 19:03:21.887338 23162 sgd_solver.cpp:106] Iteration 42586, lr = 0.0025
I0520 19:03:30.779876 23162 solver.cpp:237] Iteration 42800, loss = 1.15191
I0520 19:03:30.779927 23162 solver.cpp:253]     Train net output #0: loss = 1.15191 (* 1 = 1.15191 loss)
I0520 19:03:30.779942 23162 sgd_solver.cpp:106] Iteration 42800, lr = 0.0025
I0520 19:03:32.399194 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_42840.caffemodel
I0520 19:03:32.468370 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_42840.solverstate
I0520 19:03:32.884129 23162 solver.cpp:341] Iteration 42850, Testing net (#0)
I0520 19:04:41.696889 23162 solver.cpp:409]     Test net output #0: accuracy = 0.876624
I0520 19:04:41.697070 23162 solver.cpp:409]     Test net output #1: loss = 0.420522 (* 1 = 0.420522 loss)
I0520 19:05:09.394912 23162 solver.cpp:237] Iteration 43014, loss = 1.15891
I0520 19:05:09.394963 23162 solver.cpp:253]     Train net output #0: loss = 1.15891 (* 1 = 1.15891 loss)
I0520 19:05:09.394981 23162 sgd_solver.cpp:106] Iteration 43014, lr = 0.0025
I0520 19:05:18.275717 23162 solver.cpp:237] Iteration 43228, loss = 1.27914
I0520 19:05:18.275872 23162 solver.cpp:253]     Train net output #0: loss = 1.27914 (* 1 = 1.27914 loss)
I0520 19:05:18.275887 23162 sgd_solver.cpp:106] Iteration 43228, lr = 0.0025
I0520 19:05:27.163476 23162 solver.cpp:237] Iteration 43442, loss = 1.06623
I0520 19:05:27.163511 23162 solver.cpp:253]     Train net output #0: loss = 1.06623 (* 1 = 1.06623 loss)
I0520 19:05:27.163527 23162 sgd_solver.cpp:106] Iteration 43442, lr = 0.0025
I0520 19:05:36.045245 23162 solver.cpp:237] Iteration 43656, loss = 1.36477
I0520 19:05:36.045289 23162 solver.cpp:253]     Train net output #0: loss = 1.36477 (* 1 = 1.36477 loss)
I0520 19:05:36.045307 23162 sgd_solver.cpp:106] Iteration 43656, lr = 0.0025
I0520 19:05:44.936094 23162 solver.cpp:237] Iteration 43870, loss = 1.11318
I0520 19:05:44.936128 23162 solver.cpp:253]     Train net output #0: loss = 1.11318 (* 1 = 1.11318 loss)
I0520 19:05:44.936144 23162 sgd_solver.cpp:106] Iteration 43870, lr = 0.0025
I0520 19:05:53.823137 23162 solver.cpp:237] Iteration 44084, loss = 1.05647
I0520 19:05:53.823292 23162 solver.cpp:253]     Train net output #0: loss = 1.05647 (* 1 = 1.05647 loss)
I0520 19:05:53.823305 23162 sgd_solver.cpp:106] Iteration 44084, lr = 0.0025
I0520 19:06:23.548059 23162 solver.cpp:237] Iteration 44298, loss = 1.18346
I0520 19:06:23.548115 23162 solver.cpp:253]     Train net output #0: loss = 1.18346 (* 1 = 1.18346 loss)
I0520 19:06:23.548130 23162 sgd_solver.cpp:106] Iteration 44298, lr = 0.0025
I0520 19:06:32.435024 23162 solver.cpp:237] Iteration 44512, loss = 1.41782
I0520 19:06:32.435186 23162 solver.cpp:253]     Train net output #0: loss = 1.41782 (* 1 = 1.41782 loss)
I0520 19:06:32.435199 23162 sgd_solver.cpp:106] Iteration 44512, lr = 0.0025
I0520 19:06:41.325109 23162 solver.cpp:237] Iteration 44726, loss = 1.10257
I0520 19:06:41.325145 23162 solver.cpp:253]     Train net output #0: loss = 1.10257 (* 1 = 1.10257 loss)
I0520 19:06:41.325160 23162 sgd_solver.cpp:106] Iteration 44726, lr = 0.0025
I0520 19:06:50.203971 23162 solver.cpp:237] Iteration 44940, loss = 1.26939
I0520 19:06:50.204023 23162 solver.cpp:253]     Train net output #0: loss = 1.26939 (* 1 = 1.26939 loss)
I0520 19:06:50.204037 23162 sgd_solver.cpp:106] Iteration 44940, lr = 0.0025
I0520 19:06:51.905941 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_44982.caffemodel
I0520 19:06:51.972019 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_44982.solverstate
I0520 19:06:59.159678 23162 solver.cpp:237] Iteration 45154, loss = 1.21021
I0520 19:06:59.159729 23162 solver.cpp:253]     Train net output #0: loss = 1.21021 (* 1 = 1.21021 loss)
I0520 19:06:59.159744 23162 sgd_solver.cpp:106] Iteration 45154, lr = 0.0025
I0520 19:07:08.047874 23162 solver.cpp:237] Iteration 45368, loss = 1.10626
I0520 19:07:08.048045 23162 solver.cpp:253]     Train net output #0: loss = 1.10626 (* 1 = 1.10626 loss)
I0520 19:07:08.048059 23162 sgd_solver.cpp:106] Iteration 45368, lr = 0.0025
I0520 19:07:16.935431 23162 solver.cpp:237] Iteration 45582, loss = 1.11411
I0520 19:07:16.935477 23162 solver.cpp:253]     Train net output #0: loss = 1.11411 (* 1 = 1.11411 loss)
I0520 19:07:16.935494 23162 sgd_solver.cpp:106] Iteration 45582, lr = 0.0025
I0520 19:07:46.674455 23162 solver.cpp:237] Iteration 45796, loss = 0.995166
I0520 19:07:46.674640 23162 solver.cpp:253]     Train net output #0: loss = 0.995166 (* 1 = 0.995166 loss)
I0520 19:07:46.674655 23162 sgd_solver.cpp:106] Iteration 45796, lr = 0.0025
I0520 19:07:55.563194 23162 solver.cpp:237] Iteration 46010, loss = 1.18116
I0520 19:07:55.563228 23162 solver.cpp:253]     Train net output #0: loss = 1.18116 (* 1 = 1.18116 loss)
I0520 19:07:55.563244 23162 sgd_solver.cpp:106] Iteration 46010, lr = 0.0025
I0520 19:08:04.453132 23162 solver.cpp:237] Iteration 46224, loss = 1.10723
I0520 19:08:04.453181 23162 solver.cpp:253]     Train net output #0: loss = 1.10723 (* 1 = 1.10723 loss)
I0520 19:08:04.453197 23162 sgd_solver.cpp:106] Iteration 46224, lr = 0.0025
I0520 19:08:13.339229 23162 solver.cpp:237] Iteration 46438, loss = 1.33116
I0520 19:08:13.339264 23162 solver.cpp:253]     Train net output #0: loss = 1.33116 (* 1 = 1.33116 loss)
I0520 19:08:13.339280 23162 sgd_solver.cpp:106] Iteration 46438, lr = 0.0025
I0520 19:08:22.222156 23162 solver.cpp:237] Iteration 46652, loss = 1.08945
I0520 19:08:22.222311 23162 solver.cpp:253]     Train net output #0: loss = 1.08945 (* 1 = 1.08945 loss)
I0520 19:08:22.222326 23162 sgd_solver.cpp:106] Iteration 46652, lr = 0.0025
I0520 19:08:31.105902 23162 solver.cpp:237] Iteration 46866, loss = 1.10908
I0520 19:08:31.105942 23162 solver.cpp:253]     Train net output #0: loss = 1.10908 (* 1 = 1.10908 loss)
I0520 19:08:31.105954 23162 sgd_solver.cpp:106] Iteration 46866, lr = 0.0025
I0520 19:08:39.990924 23162 solver.cpp:237] Iteration 47080, loss = 1.14886
I0520 19:08:39.990962 23162 solver.cpp:253]     Train net output #0: loss = 1.14886 (* 1 = 1.14886 loss)
I0520 19:08:39.990975 23162 sgd_solver.cpp:106] Iteration 47080, lr = 0.0025
I0520 19:08:41.779675 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_47124.caffemodel
I0520 19:08:41.846246 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_47124.solverstate
I0520 19:08:42.299516 23162 solver.cpp:341] Iteration 47135, Testing net (#0)
I0520 19:09:29.920341 23162 solver.cpp:409]     Test net output #0: accuracy = 0.884527
I0520 19:09:29.920518 23162 solver.cpp:409]     Test net output #1: loss = 0.377996 (* 1 = 0.377996 loss)
I0520 19:09:57.397088 23162 solver.cpp:237] Iteration 47294, loss = 1.01673
I0520 19:09:57.397141 23162 solver.cpp:253]     Train net output #0: loss = 1.01673 (* 1 = 1.01673 loss)
I0520 19:09:57.397156 23162 sgd_solver.cpp:106] Iteration 47294, lr = 0.0025
I0520 19:10:06.291020 23162 solver.cpp:237] Iteration 47508, loss = 1.09135
I0520 19:10:06.291194 23162 solver.cpp:253]     Train net output #0: loss = 1.09135 (* 1 = 1.09135 loss)
I0520 19:10:06.291208 23162 sgd_solver.cpp:106] Iteration 47508, lr = 0.0025
I0520 19:10:15.181149 23162 solver.cpp:237] Iteration 47722, loss = 1.27204
I0520 19:10:15.181195 23162 solver.cpp:253]     Train net output #0: loss = 1.27204 (* 1 = 1.27204 loss)
I0520 19:10:15.181211 23162 sgd_solver.cpp:106] Iteration 47722, lr = 0.0025
I0520 19:10:24.080237 23162 solver.cpp:237] Iteration 47936, loss = 1.11779
I0520 19:10:24.080272 23162 solver.cpp:253]     Train net output #0: loss = 1.11779 (* 1 = 1.11779 loss)
I0520 19:10:24.080287 23162 sgd_solver.cpp:106] Iteration 47936, lr = 0.0025
I0520 19:10:32.974581 23162 solver.cpp:237] Iteration 48150, loss = 1.24744
I0520 19:10:32.974627 23162 solver.cpp:253]     Train net output #0: loss = 1.24744 (* 1 = 1.24744 loss)
I0520 19:10:32.974644 23162 sgd_solver.cpp:106] Iteration 48150, lr = 0.0025
I0520 19:10:41.871340 23162 solver.cpp:237] Iteration 48364, loss = 1.20106
I0520 19:10:41.871497 23162 solver.cpp:253]     Train net output #0: loss = 1.20106 (* 1 = 1.20106 loss)
I0520 19:10:41.871510 23162 sgd_solver.cpp:106] Iteration 48364, lr = 0.0025
I0520 19:11:11.615716 23162 solver.cpp:237] Iteration 48578, loss = 1.42365
I0520 19:11:11.615772 23162 solver.cpp:253]     Train net output #0: loss = 1.42365 (* 1 = 1.42365 loss)
I0520 19:11:11.615787 23162 sgd_solver.cpp:106] Iteration 48578, lr = 0.0025
I0520 19:11:20.513195 23162 solver.cpp:237] Iteration 48792, loss = 1.14635
I0520 19:11:20.513360 23162 solver.cpp:253]     Train net output #0: loss = 1.14635 (* 1 = 1.14635 loss)
I0520 19:11:20.513373 23162 sgd_solver.cpp:106] Iteration 48792, lr = 0.0025
I0520 19:11:29.403472 23162 solver.cpp:237] Iteration 49006, loss = 0.917147
I0520 19:11:29.403523 23162 solver.cpp:253]     Train net output #0: loss = 0.917147 (* 1 = 0.917147 loss)
I0520 19:11:29.403537 23162 sgd_solver.cpp:106] Iteration 49006, lr = 0.0025
I0520 19:11:38.294081 23162 solver.cpp:237] Iteration 49220, loss = 1.20852
I0520 19:11:38.294117 23162 solver.cpp:253]     Train net output #0: loss = 1.20852 (* 1 = 1.20852 loss)
I0520 19:11:38.294131 23162 sgd_solver.cpp:106] Iteration 49220, lr = 0.0025
I0520 19:11:40.163159 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_49266.caffemodel
I0520 19:11:40.230607 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_49266.solverstate
I0520 19:11:47.259927 23162 solver.cpp:237] Iteration 49434, loss = 1.4758
I0520 19:11:47.259979 23162 solver.cpp:253]     Train net output #0: loss = 1.4758 (* 1 = 1.4758 loss)
I0520 19:11:47.259991 23162 sgd_solver.cpp:106] Iteration 49434, lr = 0.0025
I0520 19:11:56.153944 23162 solver.cpp:237] Iteration 49648, loss = 1.09858
I0520 19:11:56.154119 23162 solver.cpp:253]     Train net output #0: loss = 1.09858 (* 1 = 1.09858 loss)
I0520 19:11:56.154134 23162 sgd_solver.cpp:106] Iteration 49648, lr = 0.0025
I0520 19:12:05.034979 23162 solver.cpp:237] Iteration 49862, loss = 1.11664
I0520 19:12:05.035014 23162 solver.cpp:253]     Train net output #0: loss = 1.11664 (* 1 = 1.11664 loss)
I0520 19:12:05.035030 23162 sgd_solver.cpp:106] Iteration 49862, lr = 0.0025
I0520 19:12:34.799851 23162 solver.cpp:237] Iteration 50076, loss = 1.14683
I0520 19:12:34.800035 23162 solver.cpp:253]     Train net output #0: loss = 1.14683 (* 1 = 1.14683 loss)
I0520 19:12:34.800050 23162 sgd_solver.cpp:106] Iteration 50076, lr = 0.0025
I0520 19:12:43.700110 23162 solver.cpp:237] Iteration 50290, loss = 1.16864
I0520 19:12:43.700158 23162 solver.cpp:253]     Train net output #0: loss = 1.16864 (* 1 = 1.16864 loss)
I0520 19:12:43.700176 23162 sgd_solver.cpp:106] Iteration 50290, lr = 0.0025
I0520 19:12:52.587833 23162 solver.cpp:237] Iteration 50504, loss = 1.17897
I0520 19:12:52.587869 23162 solver.cpp:253]     Train net output #0: loss = 1.17897 (* 1 = 1.17897 loss)
I0520 19:12:52.587884 23162 sgd_solver.cpp:106] Iteration 50504, lr = 0.0025
I0520 19:13:01.491186 23162 solver.cpp:237] Iteration 50718, loss = 1.23938
I0520 19:13:01.491222 23162 solver.cpp:253]     Train net output #0: loss = 1.23938 (* 1 = 1.23938 loss)
I0520 19:13:01.491235 23162 sgd_solver.cpp:106] Iteration 50718, lr = 0.0025
I0520 19:13:10.384318 23162 solver.cpp:237] Iteration 50932, loss = 0.918107
I0520 19:13:10.384496 23162 solver.cpp:253]     Train net output #0: loss = 0.918107 (* 1 = 0.918107 loss)
I0520 19:13:10.384510 23162 sgd_solver.cpp:106] Iteration 50932, lr = 0.0025
I0520 19:13:19.271729 23162 solver.cpp:237] Iteration 51146, loss = 1.38823
I0520 19:13:19.271764 23162 solver.cpp:253]     Train net output #0: loss = 1.38823 (* 1 = 1.38823 loss)
I0520 19:13:19.271780 23162 sgd_solver.cpp:106] Iteration 51146, lr = 0.0025
I0520 19:13:28.166122 23162 solver.cpp:237] Iteration 51360, loss = 1.36224
I0520 19:13:28.166164 23162 solver.cpp:253]     Train net output #0: loss = 1.36224 (* 1 = 1.36224 loss)
I0520 19:13:28.166177 23162 sgd_solver.cpp:106] Iteration 51360, lr = 0.0025
I0520 19:13:30.119693 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_51408.caffemodel
I0520 19:13:30.186136 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_51408.solverstate
I0520 19:13:30.682947 23162 solver.cpp:341] Iteration 51420, Testing net (#0)
I0520 19:14:39.433100 23162 solver.cpp:409]     Test net output #0: accuracy = 0.886395
I0520 19:14:39.433286 23162 solver.cpp:409]     Test net output #1: loss = 0.358309 (* 1 = 0.358309 loss)
I0520 19:15:06.717480 23162 solver.cpp:237] Iteration 51574, loss = 1.18757
I0520 19:15:06.717535 23162 solver.cpp:253]     Train net output #0: loss = 1.18757 (* 1 = 1.18757 loss)
I0520 19:15:06.717550 23162 sgd_solver.cpp:106] Iteration 51574, lr = 0.0025
I0520 19:15:15.639212 23162 solver.cpp:237] Iteration 51788, loss = 1.17718
I0520 19:15:15.639389 23162 solver.cpp:253]     Train net output #0: loss = 1.17718 (* 1 = 1.17718 loss)
I0520 19:15:15.639402 23162 sgd_solver.cpp:106] Iteration 51788, lr = 0.0025
I0520 19:15:24.564409 23162 solver.cpp:237] Iteration 52002, loss = 0.770921
I0520 19:15:24.564443 23162 solver.cpp:253]     Train net output #0: loss = 0.770921 (* 1 = 0.770921 loss)
I0520 19:15:24.564458 23162 sgd_solver.cpp:106] Iteration 52002, lr = 0.0025
I0520 19:15:33.485716 23162 solver.cpp:237] Iteration 52216, loss = 1.09558
I0520 19:15:33.485769 23162 solver.cpp:253]     Train net output #0: loss = 1.09558 (* 1 = 1.09558 loss)
I0520 19:15:33.485783 23162 sgd_solver.cpp:106] Iteration 52216, lr = 0.0025
I0520 19:15:42.403347 23162 solver.cpp:237] Iteration 52430, loss = 1.13253
I0520 19:15:42.403383 23162 solver.cpp:253]     Train net output #0: loss = 1.13253 (* 1 = 1.13253 loss)
I0520 19:15:42.403395 23162 sgd_solver.cpp:106] Iteration 52430, lr = 0.0025
I0520 19:15:51.313135 23162 solver.cpp:237] Iteration 52644, loss = 1.15348
I0520 19:15:51.313297 23162 solver.cpp:253]     Train net output #0: loss = 1.15348 (* 1 = 1.15348 loss)
I0520 19:15:51.313309 23162 sgd_solver.cpp:106] Iteration 52644, lr = 0.0025
I0520 19:16:21.080726 23162 solver.cpp:237] Iteration 52858, loss = 1.03776
I0520 19:16:21.080783 23162 solver.cpp:253]     Train net output #0: loss = 1.03776 (* 1 = 1.03776 loss)
I0520 19:16:21.080798 23162 sgd_solver.cpp:106] Iteration 52858, lr = 0.0025
I0520 19:16:29.993140 23162 solver.cpp:237] Iteration 53072, loss = 1.12473
I0520 19:16:29.993326 23162 solver.cpp:253]     Train net output #0: loss = 1.12473 (* 1 = 1.12473 loss)
I0520 19:16:29.993341 23162 sgd_solver.cpp:106] Iteration 53072, lr = 0.0025
I0520 19:16:38.897418 23162 solver.cpp:237] Iteration 53286, loss = 1.20929
I0520 19:16:38.897452 23162 solver.cpp:253]     Train net output #0: loss = 1.20929 (* 1 = 1.20929 loss)
I0520 19:16:38.897469 23162 sgd_solver.cpp:106] Iteration 53286, lr = 0.0025
I0520 19:16:47.814339 23162 solver.cpp:237] Iteration 53500, loss = 1.27098
I0520 19:16:47.814393 23162 solver.cpp:253]     Train net output #0: loss = 1.27098 (* 1 = 1.27098 loss)
I0520 19:16:47.814406 23162 sgd_solver.cpp:106] Iteration 53500, lr = 0.0025
I0520 19:16:49.857339 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_53550.caffemodel
I0520 19:16:49.926825 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_53550.solverstate
I0520 19:16:56.797566 23162 solver.cpp:237] Iteration 53714, loss = 1.08942
I0520 19:16:56.797619 23162 solver.cpp:253]     Train net output #0: loss = 1.08942 (* 1 = 1.08942 loss)
I0520 19:16:56.797636 23162 sgd_solver.cpp:106] Iteration 53714, lr = 0.0025
I0520 19:17:05.709806 23162 solver.cpp:237] Iteration 53928, loss = 1.06746
I0520 19:17:05.709975 23162 solver.cpp:253]     Train net output #0: loss = 1.06746 (* 1 = 1.06746 loss)
I0520 19:17:05.709988 23162 sgd_solver.cpp:106] Iteration 53928, lr = 0.0025
I0520 19:17:14.621917 23162 solver.cpp:237] Iteration 54142, loss = 1.10141
I0520 19:17:14.621969 23162 solver.cpp:253]     Train net output #0: loss = 1.10141 (* 1 = 1.10141 loss)
I0520 19:17:14.621986 23162 sgd_solver.cpp:106] Iteration 54142, lr = 0.0025
I0520 19:17:44.443342 23162 solver.cpp:237] Iteration 54356, loss = 0.994438
I0520 19:17:44.443531 23162 solver.cpp:253]     Train net output #0: loss = 0.994438 (* 1 = 0.994438 loss)
I0520 19:17:44.443545 23162 sgd_solver.cpp:106] Iteration 54356, lr = 0.0025
I0520 19:17:53.359908 23162 solver.cpp:237] Iteration 54570, loss = 0.982575
I0520 19:17:53.359946 23162 solver.cpp:253]     Train net output #0: loss = 0.982575 (* 1 = 0.982575 loss)
I0520 19:17:53.359961 23162 sgd_solver.cpp:106] Iteration 54570, lr = 0.0025
I0520 19:18:02.275131 23162 solver.cpp:237] Iteration 54784, loss = 1.1274
I0520 19:18:02.275167 23162 solver.cpp:253]     Train net output #0: loss = 1.1274 (* 1 = 1.1274 loss)
I0520 19:18:02.275182 23162 sgd_solver.cpp:106] Iteration 54784, lr = 0.0025
I0520 19:18:11.193487 23162 solver.cpp:237] Iteration 54998, loss = 1.09909
I0520 19:18:11.193528 23162 solver.cpp:253]     Train net output #0: loss = 1.09909 (* 1 = 1.09909 loss)
I0520 19:18:11.193547 23162 sgd_solver.cpp:106] Iteration 54998, lr = 0.0025
I0520 19:18:20.114264 23162 solver.cpp:237] Iteration 55212, loss = 0.945587
I0520 19:18:20.114421 23162 solver.cpp:253]     Train net output #0: loss = 0.945587 (* 1 = 0.945587 loss)
I0520 19:18:20.114435 23162 sgd_solver.cpp:106] Iteration 55212, lr = 0.0025
I0520 19:18:29.031548 23162 solver.cpp:237] Iteration 55426, loss = 0.925544
I0520 19:18:29.031602 23162 solver.cpp:253]     Train net output #0: loss = 0.925544 (* 1 = 0.925544 loss)
I0520 19:18:29.031617 23162 sgd_solver.cpp:106] Iteration 55426, lr = 0.0025
I0520 19:18:37.955262 23162 solver.cpp:237] Iteration 55640, loss = 1.12112
I0520 19:18:37.955298 23162 solver.cpp:253]     Train net output #0: loss = 1.12112 (* 1 = 1.12112 loss)
I0520 19:18:37.955313 23162 sgd_solver.cpp:106] Iteration 55640, lr = 0.0025
I0520 19:18:40.079185 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_55692.caffemodel
I0520 19:18:40.147286 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_55692.solverstate
I0520 19:18:40.687835 23162 solver.cpp:341] Iteration 55705, Testing net (#0)
I0520 19:19:28.649346 23162 solver.cpp:409]     Test net output #0: accuracy = 0.888209
I0520 19:19:28.649543 23162 solver.cpp:409]     Test net output #1: loss = 0.355969 (* 1 = 0.355969 loss)
I0520 19:19:55.733304 23162 solver.cpp:237] Iteration 55854, loss = 0.979477
I0520 19:19:55.733361 23162 solver.cpp:253]     Train net output #0: loss = 0.979477 (* 1 = 0.979477 loss)
I0520 19:19:55.733374 23162 sgd_solver.cpp:106] Iteration 55854, lr = 0.0025
I0520 19:20:04.620154 23162 solver.cpp:237] Iteration 56068, loss = 1.12036
I0520 19:20:04.620331 23162 solver.cpp:253]     Train net output #0: loss = 1.12036 (* 1 = 1.12036 loss)
I0520 19:20:04.620343 23162 sgd_solver.cpp:106] Iteration 56068, lr = 0.0025
I0520 19:20:13.514752 23162 solver.cpp:237] Iteration 56282, loss = 1.17405
I0520 19:20:13.514796 23162 solver.cpp:253]     Train net output #0: loss = 1.17405 (* 1 = 1.17405 loss)
I0520 19:20:13.514817 23162 sgd_solver.cpp:106] Iteration 56282, lr = 0.0025
I0520 19:20:22.401465 23162 solver.cpp:237] Iteration 56496, loss = 1.16541
I0520 19:20:22.401501 23162 solver.cpp:253]     Train net output #0: loss = 1.16541 (* 1 = 1.16541 loss)
I0520 19:20:22.401515 23162 sgd_solver.cpp:106] Iteration 56496, lr = 0.0025
I0520 19:20:31.294435 23162 solver.cpp:237] Iteration 56710, loss = 1.31785
I0520 19:20:31.294471 23162 solver.cpp:253]     Train net output #0: loss = 1.31785 (* 1 = 1.31785 loss)
I0520 19:20:31.294486 23162 sgd_solver.cpp:106] Iteration 56710, lr = 0.0025
I0520 19:20:40.177914 23162 solver.cpp:237] Iteration 56924, loss = 1.21048
I0520 19:20:40.178087 23162 solver.cpp:253]     Train net output #0: loss = 1.21048 (* 1 = 1.21048 loss)
I0520 19:20:40.178102 23162 sgd_solver.cpp:106] Iteration 56924, lr = 0.0025
I0520 19:20:49.071920 23162 solver.cpp:237] Iteration 57138, loss = 1.31866
I0520 19:20:49.071954 23162 solver.cpp:253]     Train net output #0: loss = 1.31866 (* 1 = 1.31866 loss)
I0520 19:20:49.071970 23162 sgd_solver.cpp:106] Iteration 57138, lr = 0.0025
I0520 19:21:18.835436 23162 solver.cpp:237] Iteration 57352, loss = 1.18782
I0520 19:21:18.835624 23162 solver.cpp:253]     Train net output #0: loss = 1.18782 (* 1 = 1.18782 loss)
I0520 19:21:18.835638 23162 sgd_solver.cpp:106] Iteration 57352, lr = 0.0025
I0520 19:21:27.722021 23162 solver.cpp:237] Iteration 57566, loss = 1.13357
I0520 19:21:27.722074 23162 solver.cpp:253]     Train net output #0: loss = 1.13357 (* 1 = 1.13357 loss)
I0520 19:21:27.722087 23162 sgd_solver.cpp:106] Iteration 57566, lr = 0.0025
I0520 19:21:36.609004 23162 solver.cpp:237] Iteration 57780, loss = 1.16408
I0520 19:21:36.609040 23162 solver.cpp:253]     Train net output #0: loss = 1.16408 (* 1 = 1.16408 loss)
I0520 19:21:36.609055 23162 sgd_solver.cpp:106] Iteration 57780, lr = 0.0025
I0520 19:21:38.810242 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_57834.caffemodel
I0520 19:21:38.876757 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_57834.solverstate
I0520 19:21:45.565898 23162 solver.cpp:237] Iteration 57994, loss = 1.23599
I0520 19:21:45.565945 23162 solver.cpp:253]     Train net output #0: loss = 1.23599 (* 1 = 1.23599 loss)
I0520 19:21:45.565963 23162 sgd_solver.cpp:106] Iteration 57994, lr = 0.0025
I0520 19:21:54.456678 23162 solver.cpp:237] Iteration 58208, loss = 1.35774
I0520 19:21:54.456851 23162 solver.cpp:253]     Train net output #0: loss = 1.35774 (* 1 = 1.35774 loss)
I0520 19:21:54.456866 23162 sgd_solver.cpp:106] Iteration 58208, lr = 0.0025
I0520 19:22:03.338767 23162 solver.cpp:237] Iteration 58422, loss = 0.933109
I0520 19:22:03.338801 23162 solver.cpp:253]     Train net output #0: loss = 0.933109 (* 1 = 0.933109 loss)
I0520 19:22:03.338817 23162 sgd_solver.cpp:106] Iteration 58422, lr = 0.0025
I0520 19:22:33.073712 23162 solver.cpp:237] Iteration 58636, loss = 1.40755
I0520 19:22:33.073912 23162 solver.cpp:253]     Train net output #0: loss = 1.40755 (* 1 = 1.40755 loss)
I0520 19:22:33.073927 23162 sgd_solver.cpp:106] Iteration 58636, lr = 0.0025
I0520 19:22:41.965142 23162 solver.cpp:237] Iteration 58850, loss = 1.21068
I0520 19:22:41.965188 23162 solver.cpp:253]     Train net output #0: loss = 1.21068 (* 1 = 1.21068 loss)
I0520 19:22:41.965201 23162 sgd_solver.cpp:106] Iteration 58850, lr = 0.0025
I0520 19:22:50.853113 23162 solver.cpp:237] Iteration 59064, loss = 1.14795
I0520 19:22:50.853149 23162 solver.cpp:253]     Train net output #0: loss = 1.14795 (* 1 = 1.14795 loss)
I0520 19:22:50.853163 23162 sgd_solver.cpp:106] Iteration 59064, lr = 0.0025
I0520 19:22:59.733052 23162 solver.cpp:237] Iteration 59278, loss = 1.0873
I0520 19:22:59.733086 23162 solver.cpp:253]     Train net output #0: loss = 1.0873 (* 1 = 1.0873 loss)
I0520 19:22:59.733103 23162 sgd_solver.cpp:106] Iteration 59278, lr = 0.0025
I0520 19:23:08.621381 23162 solver.cpp:237] Iteration 59492, loss = 1.10006
I0520 19:23:08.621563 23162 solver.cpp:253]     Train net output #0: loss = 1.10006 (* 1 = 1.10006 loss)
I0520 19:23:08.621577 23162 sgd_solver.cpp:106] Iteration 59492, lr = 0.0025
I0520 19:23:17.511135 23162 solver.cpp:237] Iteration 59706, loss = 1.40282
I0520 19:23:17.511170 23162 solver.cpp:253]     Train net output #0: loss = 1.40282 (* 1 = 1.40282 loss)
I0520 19:23:17.511186 23162 sgd_solver.cpp:106] Iteration 59706, lr = 0.0025
I0520 19:23:26.400723 23162 solver.cpp:237] Iteration 59920, loss = 1.12191
I0520 19:23:26.400759 23162 solver.cpp:253]     Train net output #0: loss = 1.12191 (* 1 = 1.12191 loss)
I0520 19:23:26.400774 23162 sgd_solver.cpp:106] Iteration 59920, lr = 0.0025
I0520 19:23:28.685720 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_59976.caffemodel
I0520 19:23:28.751690 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_59976.solverstate
I0520 19:23:29.333389 23162 solver.cpp:341] Iteration 59990, Testing net (#0)
I0520 19:24:38.130612 23162 solver.cpp:409]     Test net output #0: accuracy = 0.886468
I0520 19:24:38.130801 23162 solver.cpp:409]     Test net output #1: loss = 0.358157 (* 1 = 0.358157 loss)
I0520 19:25:05.023124 23162 solver.cpp:237] Iteration 60134, loss = 1.24673
I0520 19:25:05.023178 23162 solver.cpp:253]     Train net output #0: loss = 1.24673 (* 1 = 1.24673 loss)
I0520 19:25:05.023193 23162 sgd_solver.cpp:106] Iteration 60134, lr = 0.0025
I0520 19:25:13.912432 23162 solver.cpp:237] Iteration 60348, loss = 1.1544
I0520 19:25:13.912611 23162 solver.cpp:253]     Train net output #0: loss = 1.1544 (* 1 = 1.1544 loss)
I0520 19:25:13.912624 23162 sgd_solver.cpp:106] Iteration 60348, lr = 0.0025
I0520 19:25:22.789999 23162 solver.cpp:237] Iteration 60562, loss = 1.4311
I0520 19:25:22.790035 23162 solver.cpp:253]     Train net output #0: loss = 1.4311 (* 1 = 1.4311 loss)
I0520 19:25:22.790047 23162 sgd_solver.cpp:106] Iteration 60562, lr = 0.0025
I0520 19:25:31.670449 23162 solver.cpp:237] Iteration 60776, loss = 1.06962
I0520 19:25:31.670485 23162 solver.cpp:253]     Train net output #0: loss = 1.06962 (* 1 = 1.06962 loss)
I0520 19:25:31.670500 23162 sgd_solver.cpp:106] Iteration 60776, lr = 0.0025
I0520 19:25:40.559746 23162 solver.cpp:237] Iteration 60990, loss = 1.34458
I0520 19:25:40.559792 23162 solver.cpp:253]     Train net output #0: loss = 1.34458 (* 1 = 1.34458 loss)
I0520 19:25:40.559809 23162 sgd_solver.cpp:106] Iteration 60990, lr = 0.0025
I0520 19:25:49.443948 23162 solver.cpp:237] Iteration 61204, loss = 1.06298
I0520 19:25:49.444113 23162 solver.cpp:253]     Train net output #0: loss = 1.06298 (* 1 = 1.06298 loss)
I0520 19:25:49.444126 23162 sgd_solver.cpp:106] Iteration 61204, lr = 0.0025
I0520 19:25:58.315564 23162 solver.cpp:237] Iteration 61418, loss = 1.24911
I0520 19:25:58.315618 23162 solver.cpp:253]     Train net output #0: loss = 1.24911 (* 1 = 1.24911 loss)
I0520 19:25:58.315632 23162 sgd_solver.cpp:106] Iteration 61418, lr = 0.0025
I0520 19:26:28.065740 23162 solver.cpp:237] Iteration 61632, loss = 1.29592
I0520 19:26:28.065937 23162 solver.cpp:253]     Train net output #0: loss = 1.29592 (* 1 = 1.29592 loss)
I0520 19:26:28.065950 23162 sgd_solver.cpp:106] Iteration 61632, lr = 0.0025
I0520 19:26:36.951828 23162 solver.cpp:237] Iteration 61846, loss = 1.22898
I0520 19:26:36.951861 23162 solver.cpp:253]     Train net output #0: loss = 1.22898 (* 1 = 1.22898 loss)
I0520 19:26:36.951875 23162 sgd_solver.cpp:106] Iteration 61846, lr = 0.0025
I0520 19:26:45.831460 23162 solver.cpp:237] Iteration 62060, loss = 1.21406
I0520 19:26:45.831496 23162 solver.cpp:253]     Train net output #0: loss = 1.21406 (* 1 = 1.21406 loss)
I0520 19:26:45.831509 23162 sgd_solver.cpp:106] Iteration 62060, lr = 0.0025
I0520 19:26:48.195099 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_62118.caffemodel
I0520 19:26:48.264480 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_62118.solverstate
I0520 19:26:54.782543 23162 solver.cpp:237] Iteration 62274, loss = 1.233
I0520 19:26:54.782593 23162 solver.cpp:253]     Train net output #0: loss = 1.233 (* 1 = 1.233 loss)
I0520 19:26:54.782609 23162 sgd_solver.cpp:106] Iteration 62274, lr = 0.0025
I0520 19:27:03.672724 23162 solver.cpp:237] Iteration 62488, loss = 1.18538
I0520 19:27:03.672894 23162 solver.cpp:253]     Train net output #0: loss = 1.18538 (* 1 = 1.18538 loss)
I0520 19:27:03.672906 23162 sgd_solver.cpp:106] Iteration 62488, lr = 0.0025
I0520 19:27:12.567111 23162 solver.cpp:237] Iteration 62702, loss = 1.50041
I0520 19:27:12.567157 23162 solver.cpp:253]     Train net output #0: loss = 1.50041 (* 1 = 1.50041 loss)
I0520 19:27:12.567173 23162 sgd_solver.cpp:106] Iteration 62702, lr = 0.0025
I0520 19:27:42.296291 23162 solver.cpp:237] Iteration 62916, loss = 1.26476
I0520 19:27:42.296478 23162 solver.cpp:253]     Train net output #0: loss = 1.26476 (* 1 = 1.26476 loss)
I0520 19:27:42.296492 23162 sgd_solver.cpp:106] Iteration 62916, lr = 0.0025
I0520 19:27:51.175391 23162 solver.cpp:237] Iteration 63130, loss = 1.75775
I0520 19:27:51.175426 23162 solver.cpp:253]     Train net output #0: loss = 1.75775 (* 1 = 1.75775 loss)
I0520 19:27:51.175441 23162 sgd_solver.cpp:106] Iteration 63130, lr = 0.0025
I0520 19:28:00.065847 23162 solver.cpp:237] Iteration 63344, loss = 1.00068
I0520 19:28:00.065883 23162 solver.cpp:253]     Train net output #0: loss = 1.00068 (* 1 = 1.00068 loss)
I0520 19:28:00.065898 23162 sgd_solver.cpp:106] Iteration 63344, lr = 0.0025
I0520 19:28:08.954195 23162 solver.cpp:237] Iteration 63558, loss = 1.05478
I0520 19:28:08.954239 23162 solver.cpp:253]     Train net output #0: loss = 1.05478 (* 1 = 1.05478 loss)
I0520 19:28:08.954259 23162 sgd_solver.cpp:106] Iteration 63558, lr = 0.0025
I0520 19:28:17.834743 23162 solver.cpp:237] Iteration 63772, loss = 1.26979
I0520 19:28:17.834908 23162 solver.cpp:253]     Train net output #0: loss = 1.26979 (* 1 = 1.26979 loss)
I0520 19:28:17.834920 23162 sgd_solver.cpp:106] Iteration 63772, lr = 0.0025
I0520 19:28:26.722515 23162 solver.cpp:237] Iteration 63986, loss = 1.11055
I0520 19:28:26.722545 23162 solver.cpp:253]     Train net output #0: loss = 1.11055 (* 1 = 1.11055 loss)
I0520 19:28:26.722559 23162 sgd_solver.cpp:106] Iteration 63986, lr = 0.0025
I0520 19:28:35.608820 23162 solver.cpp:237] Iteration 64200, loss = 1.3499
I0520 19:28:35.608860 23162 solver.cpp:253]     Train net output #0: loss = 1.3499 (* 1 = 1.3499 loss)
I0520 19:28:35.608872 23162 sgd_solver.cpp:106] Iteration 64200, lr = 0.0025
I0520 19:28:38.059734 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_64260.caffemodel
I0520 19:28:38.128262 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_64260.solverstate
I0520 19:28:38.750934 23162 solver.cpp:341] Iteration 64275, Testing net (#0)
I0520 19:29:26.348606 23162 solver.cpp:409]     Test net output #0: accuracy = 0.888115
I0520 19:29:26.348801 23162 solver.cpp:409]     Test net output #1: loss = 0.356733 (* 1 = 0.356733 loss)
I0520 19:29:52.998420 23162 solver.cpp:237] Iteration 64414, loss = 1.22566
I0520 19:29:52.998474 23162 solver.cpp:253]     Train net output #0: loss = 1.22566 (* 1 = 1.22566 loss)
I0520 19:29:52.998489 23162 sgd_solver.cpp:106] Iteration 64414, lr = 0.0025
I0520 19:30:01.881219 23162 solver.cpp:237] Iteration 64628, loss = 1.0509
I0520 19:30:01.881386 23162 solver.cpp:253]     Train net output #0: loss = 1.0509 (* 1 = 1.0509 loss)
I0520 19:30:01.881400 23162 sgd_solver.cpp:106] Iteration 64628, lr = 0.0025
I0520 19:30:10.763180 23162 solver.cpp:237] Iteration 64842, loss = 1.18027
I0520 19:30:10.763222 23162 solver.cpp:253]     Train net output #0: loss = 1.18027 (* 1 = 1.18027 loss)
I0520 19:30:10.763242 23162 sgd_solver.cpp:106] Iteration 64842, lr = 0.0025
I0520 19:30:19.637953 23162 solver.cpp:237] Iteration 65056, loss = 1.14154
I0520 19:30:19.637989 23162 solver.cpp:253]     Train net output #0: loss = 1.14154 (* 1 = 1.14154 loss)
I0520 19:30:19.638002 23162 sgd_solver.cpp:106] Iteration 65056, lr = 0.0025
I0520 19:30:28.515101 23162 solver.cpp:237] Iteration 65270, loss = 1.10573
I0520 19:30:28.515137 23162 solver.cpp:253]     Train net output #0: loss = 1.10573 (* 1 = 1.10573 loss)
I0520 19:30:28.515151 23162 sgd_solver.cpp:106] Iteration 65270, lr = 0.0025
I0520 19:30:37.397049 23162 solver.cpp:237] Iteration 65484, loss = 1.06803
I0520 19:30:37.397244 23162 solver.cpp:253]     Train net output #0: loss = 1.06803 (* 1 = 1.06803 loss)
I0520 19:30:37.397258 23162 sgd_solver.cpp:106] Iteration 65484, lr = 0.0025
I0520 19:30:46.265403 23162 solver.cpp:237] Iteration 65698, loss = 1.3471
I0520 19:30:46.265437 23162 solver.cpp:253]     Train net output #0: loss = 1.3471 (* 1 = 1.3471 loss)
I0520 19:30:46.265453 23162 sgd_solver.cpp:106] Iteration 65698, lr = 0.0025
I0520 19:31:16.049212 23162 solver.cpp:237] Iteration 65912, loss = 0.848403
I0520 19:31:16.049406 23162 solver.cpp:253]     Train net output #0: loss = 0.848403 (* 1 = 0.848403 loss)
I0520 19:31:16.049419 23162 sgd_solver.cpp:106] Iteration 65912, lr = 0.0025
I0520 19:31:24.925222 23162 solver.cpp:237] Iteration 66126, loss = 0.981814
I0520 19:31:24.925268 23162 solver.cpp:253]     Train net output #0: loss = 0.981814 (* 1 = 0.981814 loss)
I0520 19:31:24.925287 23162 sgd_solver.cpp:106] Iteration 66126, lr = 0.0025
I0520 19:31:33.806299 23162 solver.cpp:237] Iteration 66340, loss = 1.09586
I0520 19:31:33.806335 23162 solver.cpp:253]     Train net output #0: loss = 1.09586 (* 1 = 1.09586 loss)
I0520 19:31:33.806349 23162 sgd_solver.cpp:106] Iteration 66340, lr = 0.0025
I0520 19:31:36.341397 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_66402.caffemodel
I0520 19:31:36.407193 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_66402.solverstate
I0520 19:31:42.754308 23162 solver.cpp:237] Iteration 66554, loss = 1.0656
I0520 19:31:42.754354 23162 solver.cpp:253]     Train net output #0: loss = 1.0656 (* 1 = 1.0656 loss)
I0520 19:31:42.754366 23162 sgd_solver.cpp:106] Iteration 66554, lr = 0.0025
I0520 19:31:51.636111 23162 solver.cpp:237] Iteration 66768, loss = 1.15817
I0520 19:31:51.636313 23162 solver.cpp:253]     Train net output #0: loss = 1.15817 (* 1 = 1.15817 loss)
I0520 19:31:51.636327 23162 sgd_solver.cpp:106] Iteration 66768, lr = 0.0025
I0520 19:32:00.516451 23162 solver.cpp:237] Iteration 66982, loss = 1.19248
I0520 19:32:00.516486 23162 solver.cpp:253]     Train net output #0: loss = 1.19248 (* 1 = 1.19248 loss)
I0520 19:32:00.516501 23162 sgd_solver.cpp:106] Iteration 66982, lr = 0.0025
I0520 19:32:30.331176 23162 solver.cpp:237] Iteration 67196, loss = 1.41076
I0520 19:32:30.331364 23162 solver.cpp:253]     Train net output #0: loss = 1.41076 (* 1 = 1.41076 loss)
I0520 19:32:30.331378 23162 sgd_solver.cpp:106] Iteration 67196, lr = 0.0025
I0520 19:32:39.205698 23162 solver.cpp:237] Iteration 67410, loss = 1.05885
I0520 19:32:39.205746 23162 solver.cpp:253]     Train net output #0: loss = 1.05885 (* 1 = 1.05885 loss)
I0520 19:32:39.205765 23162 sgd_solver.cpp:106] Iteration 67410, lr = 0.0025
I0520 19:32:48.084614 23162 solver.cpp:237] Iteration 67624, loss = 1.21847
I0520 19:32:48.084650 23162 solver.cpp:253]     Train net output #0: loss = 1.21847 (* 1 = 1.21847 loss)
I0520 19:32:48.084664 23162 sgd_solver.cpp:106] Iteration 67624, lr = 0.0025
I0520 19:32:56.955689 23162 solver.cpp:237] Iteration 67838, loss = 1.05901
I0520 19:32:56.955724 23162 solver.cpp:253]     Train net output #0: loss = 1.05901 (* 1 = 1.05901 loss)
I0520 19:32:56.955739 23162 sgd_solver.cpp:106] Iteration 67838, lr = 0.0025
I0520 19:33:05.835059 23162 solver.cpp:237] Iteration 68052, loss = 1.04599
I0520 19:33:05.835243 23162 solver.cpp:253]     Train net output #0: loss = 1.04599 (* 1 = 1.04599 loss)
I0520 19:33:05.835258 23162 sgd_solver.cpp:106] Iteration 68052, lr = 0.0025
I0520 19:33:14.717833 23162 solver.cpp:237] Iteration 68266, loss = 1.0997
I0520 19:33:14.717866 23162 solver.cpp:253]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0520 19:33:14.717881 23162 sgd_solver.cpp:106] Iteration 68266, lr = 0.0025
I0520 19:33:23.596654 23162 solver.cpp:237] Iteration 68480, loss = 1.06074
I0520 19:33:23.596689 23162 solver.cpp:253]     Train net output #0: loss = 1.06074 (* 1 = 1.06074 loss)
I0520 19:33:23.596704 23162 sgd_solver.cpp:106] Iteration 68480, lr = 0.0025
I0520 19:33:26.210116 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_68544.caffemodel
I0520 19:33:26.285327 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_68544.solverstate
I0520 19:33:26.947134 23162 solver.cpp:341] Iteration 68560, Testing net (#0)
I0520 19:34:36.026573 23162 solver.cpp:409]     Test net output #0: accuracy = 0.888496
I0520 19:34:36.026769 23162 solver.cpp:409]     Test net output #1: loss = 0.375502 (* 1 = 0.375502 loss)
I0520 19:35:02.482858 23162 solver.cpp:237] Iteration 68694, loss = 1.22138
I0520 19:35:02.482913 23162 solver.cpp:253]     Train net output #0: loss = 1.22138 (* 1 = 1.22138 loss)
I0520 19:35:02.482928 23162 sgd_solver.cpp:106] Iteration 68694, lr = 0.0025
I0520 19:35:11.376957 23162 solver.cpp:237] Iteration 68908, loss = 1.12307
I0520 19:35:11.377145 23162 solver.cpp:253]     Train net output #0: loss = 1.12307 (* 1 = 1.12307 loss)
I0520 19:35:11.377158 23162 sgd_solver.cpp:106] Iteration 68908, lr = 0.0025
I0520 19:35:20.278128 23162 solver.cpp:237] Iteration 69122, loss = 1.12946
I0520 19:35:20.278163 23162 solver.cpp:253]     Train net output #0: loss = 1.12946 (* 1 = 1.12946 loss)
I0520 19:35:20.278178 23162 sgd_solver.cpp:106] Iteration 69122, lr = 0.0025
I0520 19:35:29.174332 23162 solver.cpp:237] Iteration 69336, loss = 1.35631
I0520 19:35:29.174370 23162 solver.cpp:253]     Train net output #0: loss = 1.35631 (* 1 = 1.35631 loss)
I0520 19:35:29.174383 23162 sgd_solver.cpp:106] Iteration 69336, lr = 0.0025
I0520 19:35:38.076311 23162 solver.cpp:237] Iteration 69550, loss = 1.32896
I0520 19:35:38.076360 23162 solver.cpp:253]     Train net output #0: loss = 1.32896 (* 1 = 1.32896 loss)
I0520 19:35:38.076378 23162 sgd_solver.cpp:106] Iteration 69550, lr = 0.0025
I0520 19:35:46.970254 23162 solver.cpp:237] Iteration 69764, loss = 1.47705
I0520 19:35:46.970443 23162 solver.cpp:253]     Train net output #0: loss = 1.47705 (* 1 = 1.47705 loss)
I0520 19:35:46.970458 23162 sgd_solver.cpp:106] Iteration 69764, lr = 0.0025
I0520 19:35:55.865780 23162 solver.cpp:237] Iteration 69978, loss = 1.24657
I0520 19:35:55.865814 23162 solver.cpp:253]     Train net output #0: loss = 1.24657 (* 1 = 1.24657 loss)
I0520 19:35:55.865829 23162 sgd_solver.cpp:106] Iteration 69978, lr = 0.0025
I0520 19:36:25.704116 23162 solver.cpp:237] Iteration 70192, loss = 1.02392
I0520 19:36:25.704319 23162 solver.cpp:253]     Train net output #0: loss = 1.02392 (* 1 = 1.02392 loss)
I0520 19:36:25.704334 23162 sgd_solver.cpp:106] Iteration 70192, lr = 0.0025
I0520 19:36:34.604701 23162 solver.cpp:237] Iteration 70406, loss = 0.977512
I0520 19:36:34.604737 23162 solver.cpp:253]     Train net output #0: loss = 0.977512 (* 1 = 0.977512 loss)
I0520 19:36:34.604753 23162 sgd_solver.cpp:106] Iteration 70406, lr = 0.0025
I0520 19:36:43.505836 23162 solver.cpp:237] Iteration 70620, loss = 1.25346
I0520 19:36:43.505872 23162 solver.cpp:253]     Train net output #0: loss = 1.25346 (* 1 = 1.25346 loss)
I0520 19:36:43.505887 23162 sgd_solver.cpp:106] Iteration 70620, lr = 0.0025
I0520 19:36:46.211629 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_70686.caffemodel
I0520 19:36:46.278225 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_70686.solverstate
I0520 19:36:52.468101 23162 solver.cpp:237] Iteration 70834, loss = 1.22877
I0520 19:36:52.468153 23162 solver.cpp:253]     Train net output #0: loss = 1.22877 (* 1 = 1.22877 loss)
I0520 19:36:52.468168 23162 sgd_solver.cpp:106] Iteration 70834, lr = 0.0025
I0520 19:37:01.368156 23162 solver.cpp:237] Iteration 71048, loss = 1.0885
I0520 19:37:01.368335 23162 solver.cpp:253]     Train net output #0: loss = 1.0885 (* 1 = 1.0885 loss)
I0520 19:37:01.368352 23162 sgd_solver.cpp:106] Iteration 71048, lr = 0.0025
I0520 19:37:10.266957 23162 solver.cpp:237] Iteration 71262, loss = 1.07522
I0520 19:37:10.266990 23162 solver.cpp:253]     Train net output #0: loss = 1.07522 (* 1 = 1.07522 loss)
I0520 19:37:10.267007 23162 sgd_solver.cpp:106] Iteration 71262, lr = 0.0025
I0520 19:37:40.055949 23162 solver.cpp:237] Iteration 71476, loss = 1.18533
I0520 19:37:40.056146 23162 solver.cpp:253]     Train net output #0: loss = 1.18533 (* 1 = 1.18533 loss)
I0520 19:37:40.056160 23162 sgd_solver.cpp:106] Iteration 71476, lr = 0.0025
I0520 19:37:48.952615 23162 solver.cpp:237] Iteration 71690, loss = 1.09465
I0520 19:37:48.952651 23162 solver.cpp:253]     Train net output #0: loss = 1.09465 (* 1 = 1.09465 loss)
I0520 19:37:48.952666 23162 sgd_solver.cpp:106] Iteration 71690, lr = 0.0025
I0520 19:37:57.851567 23162 solver.cpp:237] Iteration 71904, loss = 1.06099
I0520 19:37:57.851603 23162 solver.cpp:253]     Train net output #0: loss = 1.06099 (* 1 = 1.06099 loss)
I0520 19:37:57.851616 23162 sgd_solver.cpp:106] Iteration 71904, lr = 0.0025
I0520 19:38:06.744380 23162 solver.cpp:237] Iteration 72118, loss = 1.27569
I0520 19:38:06.744428 23162 solver.cpp:253]     Train net output #0: loss = 1.27569 (* 1 = 1.27569 loss)
I0520 19:38:06.744443 23162 sgd_solver.cpp:106] Iteration 72118, lr = 0.0025
I0520 19:38:15.638406 23162 solver.cpp:237] Iteration 72332, loss = 0.855916
I0520 19:38:15.638574 23162 solver.cpp:253]     Train net output #0: loss = 0.855916 (* 1 = 0.855916 loss)
I0520 19:38:15.638588 23162 sgd_solver.cpp:106] Iteration 72332, lr = 0.0025
I0520 19:38:24.531733 23162 solver.cpp:237] Iteration 72546, loss = 0.97394
I0520 19:38:24.531769 23162 solver.cpp:253]     Train net output #0: loss = 0.97394 (* 1 = 0.97394 loss)
I0520 19:38:24.531783 23162 sgd_solver.cpp:106] Iteration 72546, lr = 0.0025
I0520 19:38:33.429713 23162 solver.cpp:237] Iteration 72760, loss = 1.16847
I0520 19:38:33.429759 23162 solver.cpp:253]     Train net output #0: loss = 1.16847 (* 1 = 1.16847 loss)
I0520 19:38:33.429780 23162 sgd_solver.cpp:106] Iteration 72760, lr = 0.0025
I0520 19:38:36.213299 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_72828.caffemodel
I0520 19:38:36.280064 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_72828.solverstate
I0520 19:38:36.983763 23162 solver.cpp:341] Iteration 72845, Testing net (#0)
I0520 19:39:24.963732 23162 solver.cpp:409]     Test net output #0: accuracy = 0.890916
I0520 19:39:24.963932 23162 solver.cpp:409]     Test net output #1: loss = 0.37204 (* 1 = 0.37204 loss)
I0520 19:39:51.221607 23162 solver.cpp:237] Iteration 72974, loss = 0.927632
I0520 19:39:51.221663 23162 solver.cpp:253]     Train net output #0: loss = 0.927632 (* 1 = 0.927632 loss)
I0520 19:39:51.221678 23162 sgd_solver.cpp:106] Iteration 72974, lr = 0.0025
I0520 19:40:00.108981 23162 solver.cpp:237] Iteration 73188, loss = 1.17627
I0520 19:40:00.109153 23162 solver.cpp:253]     Train net output #0: loss = 1.17627 (* 1 = 1.17627 loss)
I0520 19:40:00.109166 23162 sgd_solver.cpp:106] Iteration 73188, lr = 0.0025
I0520 19:40:08.998675 23162 solver.cpp:237] Iteration 73402, loss = 1.32114
I0520 19:40:08.998723 23162 solver.cpp:253]     Train net output #0: loss = 1.32114 (* 1 = 1.32114 loss)
I0520 19:40:08.998738 23162 sgd_solver.cpp:106] Iteration 73402, lr = 0.0025
I0520 19:40:17.880117 23162 solver.cpp:237] Iteration 73616, loss = 1.25448
I0520 19:40:17.880154 23162 solver.cpp:253]     Train net output #0: loss = 1.25448 (* 1 = 1.25448 loss)
I0520 19:40:17.880169 23162 sgd_solver.cpp:106] Iteration 73616, lr = 0.0025
I0520 19:40:26.770041 23162 solver.cpp:237] Iteration 73830, loss = 0.989637
I0520 19:40:26.770077 23162 solver.cpp:253]     Train net output #0: loss = 0.989637 (* 1 = 0.989637 loss)
I0520 19:40:26.770092 23162 sgd_solver.cpp:106] Iteration 73830, lr = 0.0025
I0520 19:40:35.662853 23162 solver.cpp:237] Iteration 74044, loss = 1.17305
I0520 19:40:35.663036 23162 solver.cpp:253]     Train net output #0: loss = 1.17305 (* 1 = 1.17305 loss)
I0520 19:40:35.663051 23162 sgd_solver.cpp:106] Iteration 74044, lr = 0.0025
I0520 19:40:44.554224 23162 solver.cpp:237] Iteration 74258, loss = 0.986382
I0520 19:40:44.554260 23162 solver.cpp:253]     Train net output #0: loss = 0.986382 (* 1 = 0.986382 loss)
I0520 19:40:44.554273 23162 sgd_solver.cpp:106] Iteration 74258, lr = 0.0025
I0520 19:41:14.350543 23162 solver.cpp:237] Iteration 74472, loss = 1.24416
I0520 19:41:14.350739 23162 solver.cpp:253]     Train net output #0: loss = 1.24416 (* 1 = 1.24416 loss)
I0520 19:41:14.350752 23162 sgd_solver.cpp:106] Iteration 74472, lr = 0.0025
I0520 19:41:23.232385 23162 solver.cpp:237] Iteration 74686, loss = 0.980653
I0520 19:41:23.232430 23162 solver.cpp:253]     Train net output #0: loss = 0.980653 (* 1 = 0.980653 loss)
I0520 19:41:23.232450 23162 sgd_solver.cpp:106] Iteration 74686, lr = 0.0025
I0520 19:41:32.112098 23162 solver.cpp:237] Iteration 74900, loss = 1.16561
I0520 19:41:32.112134 23162 solver.cpp:253]     Train net output #0: loss = 1.16561 (* 1 = 1.16561 loss)
I0520 19:41:32.112149 23162 sgd_solver.cpp:106] Iteration 74900, lr = 0.0025
I0520 19:41:34.976104 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_74970.caffemodel
I0520 19:41:35.045214 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_74970.solverstate
I0520 19:41:41.067247 23162 solver.cpp:237] Iteration 75114, loss = 1.17973
I0520 19:41:41.067303 23162 solver.cpp:253]     Train net output #0: loss = 1.17973 (* 1 = 1.17973 loss)
I0520 19:41:41.067317 23162 sgd_solver.cpp:106] Iteration 75114, lr = 0.0025
I0520 19:41:49.946547 23162 solver.cpp:237] Iteration 75328, loss = 1.20766
I0520 19:41:49.946751 23162 solver.cpp:253]     Train net output #0: loss = 1.20766 (* 1 = 1.20766 loss)
I0520 19:41:49.946765 23162 sgd_solver.cpp:106] Iteration 75328, lr = 0.0025
I0520 19:41:58.829452 23162 solver.cpp:237] Iteration 75542, loss = 1.06414
I0520 19:41:58.829486 23162 solver.cpp:253]     Train net output #0: loss = 1.06414 (* 1 = 1.06414 loss)
I0520 19:41:58.829501 23162 sgd_solver.cpp:106] Iteration 75542, lr = 0.0025
I0520 19:42:28.599781 23162 solver.cpp:237] Iteration 75756, loss = 1.41652
I0520 19:42:28.599979 23162 solver.cpp:253]     Train net output #0: loss = 1.41652 (* 1 = 1.41652 loss)
I0520 19:42:28.599993 23162 sgd_solver.cpp:106] Iteration 75756, lr = 0.0025
I0520 19:42:37.489157 23162 solver.cpp:237] Iteration 75970, loss = 1.11989
I0520 19:42:37.489204 23162 solver.cpp:253]     Train net output #0: loss = 1.11989 (* 1 = 1.11989 loss)
I0520 19:42:37.489220 23162 sgd_solver.cpp:106] Iteration 75970, lr = 0.0025
I0520 19:42:46.373847 23162 solver.cpp:237] Iteration 76184, loss = 1.22111
I0520 19:42:46.373883 23162 solver.cpp:253]     Train net output #0: loss = 1.22111 (* 1 = 1.22111 loss)
I0520 19:42:46.373896 23162 sgd_solver.cpp:106] Iteration 76184, lr = 0.0025
I0520 19:42:55.260305 23162 solver.cpp:237] Iteration 76398, loss = 1.00417
I0520 19:42:55.260340 23162 solver.cpp:253]     Train net output #0: loss = 1.00417 (* 1 = 1.00417 loss)
I0520 19:42:55.260356 23162 sgd_solver.cpp:106] Iteration 76398, lr = 0.0025
I0520 19:43:04.147914 23162 solver.cpp:237] Iteration 76612, loss = 1.25356
I0520 19:43:04.148098 23162 solver.cpp:253]     Train net output #0: loss = 1.25356 (* 1 = 1.25356 loss)
I0520 19:43:04.148113 23162 sgd_solver.cpp:106] Iteration 76612, lr = 0.0025
I0520 19:43:13.035342 23162 solver.cpp:237] Iteration 76826, loss = 1.08861
I0520 19:43:13.035377 23162 solver.cpp:253]     Train net output #0: loss = 1.08861 (* 1 = 1.08861 loss)
I0520 19:43:13.035393 23162 sgd_solver.cpp:106] Iteration 76826, lr = 0.0025
I0520 19:43:21.917136 23162 solver.cpp:237] Iteration 77040, loss = 1.12035
I0520 19:43:21.917171 23162 solver.cpp:253]     Train net output #0: loss = 1.12035 (* 1 = 1.12035 loss)
I0520 19:43:21.917186 23162 sgd_solver.cpp:106] Iteration 77040, lr = 0.0025
I0520 19:43:24.865903 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_77112.caffemodel
I0520 19:43:24.934281 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_77112.solverstate
I0520 19:43:25.682611 23162 solver.cpp:341] Iteration 77130, Testing net (#0)
I0520 19:44:34.557840 23162 solver.cpp:409]     Test net output #0: accuracy = 0.892817
I0520 19:44:34.558048 23162 solver.cpp:409]     Test net output #1: loss = 0.336888 (* 1 = 0.336888 loss)
I0520 19:45:00.632396 23162 solver.cpp:237] Iteration 77254, loss = 1.03794
I0520 19:45:00.632452 23162 solver.cpp:253]     Train net output #0: loss = 1.03794 (* 1 = 1.03794 loss)
I0520 19:45:00.632465 23162 sgd_solver.cpp:106] Iteration 77254, lr = 0.0025
I0520 19:45:09.532352 23162 solver.cpp:237] Iteration 77468, loss = 1.03456
I0520 19:45:09.532526 23162 solver.cpp:253]     Train net output #0: loss = 1.03456 (* 1 = 1.03456 loss)
I0520 19:45:09.532539 23162 sgd_solver.cpp:106] Iteration 77468, lr = 0.0025
I0520 19:45:18.436265 23162 solver.cpp:237] Iteration 77682, loss = 1.1297
I0520 19:45:18.436300 23162 solver.cpp:253]     Train net output #0: loss = 1.1297 (* 1 = 1.1297 loss)
I0520 19:45:18.436314 23162 sgd_solver.cpp:106] Iteration 77682, lr = 0.0025
I0520 19:45:27.336046 23162 solver.cpp:237] Iteration 77896, loss = 1.13367
I0520 19:45:27.336081 23162 solver.cpp:253]     Train net output #0: loss = 1.13367 (* 1 = 1.13367 loss)
I0520 19:45:27.336094 23162 sgd_solver.cpp:106] Iteration 77896, lr = 0.0025
I0520 19:45:36.232374 23162 solver.cpp:237] Iteration 78110, loss = 1.1203
I0520 19:45:36.232422 23162 solver.cpp:253]     Train net output #0: loss = 1.1203 (* 1 = 1.1203 loss)
I0520 19:45:36.232437 23162 sgd_solver.cpp:106] Iteration 78110, lr = 0.0025
I0520 19:45:45.121028 23162 solver.cpp:237] Iteration 78324, loss = 0.946887
I0520 19:45:45.121215 23162 solver.cpp:253]     Train net output #0: loss = 0.946887 (* 1 = 0.946887 loss)
I0520 19:45:45.121228 23162 sgd_solver.cpp:106] Iteration 78324, lr = 0.0025
I0520 19:45:54.015621 23162 solver.cpp:237] Iteration 78538, loss = 1.37746
I0520 19:45:54.015655 23162 solver.cpp:253]     Train net output #0: loss = 1.37746 (* 1 = 1.37746 loss)
I0520 19:45:54.015671 23162 sgd_solver.cpp:106] Iteration 78538, lr = 0.0025
I0520 19:46:23.797157 23162 solver.cpp:237] Iteration 78752, loss = 1.23337
I0520 19:46:23.797358 23162 solver.cpp:253]     Train net output #0: loss = 1.23337 (* 1 = 1.23337 loss)
I0520 19:46:23.797372 23162 sgd_solver.cpp:106] Iteration 78752, lr = 0.0025
I0520 19:46:32.681825 23162 solver.cpp:237] Iteration 78966, loss = 1.17317
I0520 19:46:32.681860 23162 solver.cpp:253]     Train net output #0: loss = 1.17317 (* 1 = 1.17317 loss)
I0520 19:46:32.681875 23162 sgd_solver.cpp:106] Iteration 78966, lr = 0.0025
I0520 19:46:41.569124 23162 solver.cpp:237] Iteration 79180, loss = 1.03985
I0520 19:46:41.569160 23162 solver.cpp:253]     Train net output #0: loss = 1.03985 (* 1 = 1.03985 loss)
I0520 19:46:41.569175 23162 sgd_solver.cpp:106] Iteration 79180, lr = 0.0025
I0520 19:46:44.601908 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_79254.caffemodel
I0520 19:46:44.667793 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_79254.solverstate
I0520 19:46:50.525876 23162 solver.cpp:237] Iteration 79394, loss = 1.06809
I0520 19:46:50.525926 23162 solver.cpp:253]     Train net output #0: loss = 1.06809 (* 1 = 1.06809 loss)
I0520 19:46:50.525945 23162 sgd_solver.cpp:106] Iteration 79394, lr = 0.0025
I0520 19:46:59.420985 23162 solver.cpp:237] Iteration 79608, loss = 1.32795
I0520 19:46:59.421161 23162 solver.cpp:253]     Train net output #0: loss = 1.32795 (* 1 = 1.32795 loss)
I0520 19:46:59.421175 23162 sgd_solver.cpp:106] Iteration 79608, lr = 0.0025
I0520 19:47:08.317665 23162 solver.cpp:237] Iteration 79822, loss = 1.10723
I0520 19:47:08.317699 23162 solver.cpp:253]     Train net output #0: loss = 1.10723 (* 1 = 1.10723 loss)
I0520 19:47:08.317715 23162 sgd_solver.cpp:106] Iteration 79822, lr = 0.0025
I0520 19:47:38.153961 23162 solver.cpp:237] Iteration 80036, loss = 1.16991
I0520 19:47:38.154165 23162 solver.cpp:253]     Train net output #0: loss = 1.16991 (* 1 = 1.16991 loss)
I0520 19:47:38.154180 23162 sgd_solver.cpp:106] Iteration 80036, lr = 0.0025
I0520 19:47:47.055681 23162 solver.cpp:237] Iteration 80250, loss = 1.18851
I0520 19:47:47.055716 23162 solver.cpp:253]     Train net output #0: loss = 1.18851 (* 1 = 1.18851 loss)
I0520 19:47:47.055732 23162 sgd_solver.cpp:106] Iteration 80250, lr = 0.0025
I0520 19:47:55.947700 23162 solver.cpp:237] Iteration 80464, loss = 1.2085
I0520 19:47:55.947736 23162 solver.cpp:253]     Train net output #0: loss = 1.2085 (* 1 = 1.2085 loss)
I0520 19:47:55.947749 23162 sgd_solver.cpp:106] Iteration 80464, lr = 0.0025
I0520 19:48:04.842097 23162 solver.cpp:237] Iteration 80678, loss = 1.31696
I0520 19:48:04.842149 23162 solver.cpp:253]     Train net output #0: loss = 1.31696 (* 1 = 1.31696 loss)
I0520 19:48:04.842164 23162 sgd_solver.cpp:106] Iteration 80678, lr = 0.0025
I0520 19:48:13.744756 23162 solver.cpp:237] Iteration 80892, loss = 1.13276
I0520 19:48:13.744942 23162 solver.cpp:253]     Train net output #0: loss = 1.13276 (* 1 = 1.13276 loss)
I0520 19:48:13.744956 23162 sgd_solver.cpp:106] Iteration 80892, lr = 0.0025
I0520 19:48:22.639569 23162 solver.cpp:237] Iteration 81106, loss = 1.03356
I0520 19:48:22.639605 23162 solver.cpp:253]     Train net output #0: loss = 1.03356 (* 1 = 1.03356 loss)
I0520 19:48:22.639619 23162 sgd_solver.cpp:106] Iteration 81106, lr = 0.0025
I0520 19:48:31.533300 23162 solver.cpp:237] Iteration 81320, loss = 1.00711
I0520 19:48:31.533350 23162 solver.cpp:253]     Train net output #0: loss = 1.00711 (* 1 = 1.00711 loss)
I0520 19:48:31.533365 23162 sgd_solver.cpp:106] Iteration 81320, lr = 0.0025
I0520 19:48:34.647225 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_81396.caffemodel
I0520 19:48:34.713075 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_81396.solverstate
I0520 19:48:35.501793 23162 solver.cpp:341] Iteration 81415, Testing net (#0)
I0520 19:49:23.174650 23162 solver.cpp:409]     Test net output #0: accuracy = 0.889755
I0520 19:49:23.174844 23162 solver.cpp:409]     Test net output #1: loss = 0.355584 (* 1 = 0.355584 loss)
I0520 19:49:49.043783 23162 solver.cpp:237] Iteration 81534, loss = 1.19874
I0520 19:49:49.043839 23162 solver.cpp:253]     Train net output #0: loss = 1.19874 (* 1 = 1.19874 loss)
I0520 19:49:49.043853 23162 sgd_solver.cpp:106] Iteration 81534, lr = 0.0025
I0520 19:49:57.965570 23162 solver.cpp:237] Iteration 81748, loss = 0.952058
I0520 19:49:57.965744 23162 solver.cpp:253]     Train net output #0: loss = 0.952058 (* 1 = 0.952058 loss)
I0520 19:49:57.965759 23162 sgd_solver.cpp:106] Iteration 81748, lr = 0.0025
I0520 19:50:06.876173 23162 solver.cpp:237] Iteration 81962, loss = 1.28667
I0520 19:50:06.876209 23162 solver.cpp:253]     Train net output #0: loss = 1.28667 (* 1 = 1.28667 loss)
I0520 19:50:06.876224 23162 sgd_solver.cpp:106] Iteration 81962, lr = 0.0025
I0520 19:50:15.791982 23162 solver.cpp:237] Iteration 82176, loss = 1.31223
I0520 19:50:15.792021 23162 solver.cpp:253]     Train net output #0: loss = 1.31223 (* 1 = 1.31223 loss)
I0520 19:50:15.792037 23162 sgd_solver.cpp:106] Iteration 82176, lr = 0.0025
I0520 19:50:24.712659 23162 solver.cpp:237] Iteration 82390, loss = 1.14596
I0520 19:50:24.712694 23162 solver.cpp:253]     Train net output #0: loss = 1.14596 (* 1 = 1.14596 loss)
I0520 19:50:24.712708 23162 sgd_solver.cpp:106] Iteration 82390, lr = 0.0025
I0520 19:50:33.637697 23162 solver.cpp:237] Iteration 82604, loss = 1.44826
I0520 19:50:33.637884 23162 solver.cpp:253]     Train net output #0: loss = 1.44826 (* 1 = 1.44826 loss)
I0520 19:50:33.637898 23162 sgd_solver.cpp:106] Iteration 82604, lr = 0.0025
I0520 19:50:42.556506 23162 solver.cpp:237] Iteration 82818, loss = 1.18077
I0520 19:50:42.556541 23162 solver.cpp:253]     Train net output #0: loss = 1.18077 (* 1 = 1.18077 loss)
I0520 19:50:42.556556 23162 sgd_solver.cpp:106] Iteration 82818, lr = 0.0025
I0520 19:51:12.346272 23162 solver.cpp:237] Iteration 83032, loss = 1.00925
I0520 19:51:12.346470 23162 solver.cpp:253]     Train net output #0: loss = 1.00925 (* 1 = 1.00925 loss)
I0520 19:51:12.346484 23162 sgd_solver.cpp:106] Iteration 83032, lr = 0.0025
I0520 19:51:21.264843 23162 solver.cpp:237] Iteration 83246, loss = 0.888948
I0520 19:51:21.264878 23162 solver.cpp:253]     Train net output #0: loss = 0.888948 (* 1 = 0.888948 loss)
I0520 19:51:21.264894 23162 sgd_solver.cpp:106] Iteration 83246, lr = 0.0025
I0520 19:51:30.183938 23162 solver.cpp:237] Iteration 83460, loss = 0.84698
I0520 19:51:30.183979 23162 solver.cpp:253]     Train net output #0: loss = 0.84698 (* 1 = 0.84698 loss)
I0520 19:51:30.184000 23162 sgd_solver.cpp:106] Iteration 83460, lr = 0.0025
I0520 19:51:33.396245 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_83538.caffemodel
I0520 19:51:33.463202 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_83538.solverstate
I0520 19:51:39.170003 23162 solver.cpp:237] Iteration 83674, loss = 1.14396
I0520 19:51:39.170054 23162 solver.cpp:253]     Train net output #0: loss = 1.14396 (* 1 = 1.14396 loss)
I0520 19:51:39.170069 23162 sgd_solver.cpp:106] Iteration 83674, lr = 0.0025
I0520 19:51:48.086081 23162 solver.cpp:237] Iteration 83888, loss = 1.06896
I0520 19:51:48.086293 23162 solver.cpp:253]     Train net output #0: loss = 1.06896 (* 1 = 1.06896 loss)
I0520 19:51:48.086308 23162 sgd_solver.cpp:106] Iteration 83888, lr = 0.0025
I0520 19:51:56.998334 23162 solver.cpp:237] Iteration 84102, loss = 1.12326
I0520 19:51:56.998370 23162 solver.cpp:253]     Train net output #0: loss = 1.12326 (* 1 = 1.12326 loss)
I0520 19:51:56.998385 23162 sgd_solver.cpp:106] Iteration 84102, lr = 0.0025
I0520 19:52:26.806272 23162 solver.cpp:237] Iteration 84316, loss = 0.906295
I0520 19:52:26.806475 23162 solver.cpp:253]     Train net output #0: loss = 0.906295 (* 1 = 0.906295 loss)
I0520 19:52:26.806491 23162 sgd_solver.cpp:106] Iteration 84316, lr = 0.0025
I0520 19:52:35.722388 23162 solver.cpp:237] Iteration 84530, loss = 1.138
I0520 19:52:35.722424 23162 solver.cpp:253]     Train net output #0: loss = 1.138 (* 1 = 1.138 loss)
I0520 19:52:35.722439 23162 sgd_solver.cpp:106] Iteration 84530, lr = 0.0025
I0520 19:52:44.646423 23162 solver.cpp:237] Iteration 84744, loss = 1.1714
I0520 19:52:44.646476 23162 solver.cpp:253]     Train net output #0: loss = 1.1714 (* 1 = 1.1714 loss)
I0520 19:52:44.646492 23162 sgd_solver.cpp:106] Iteration 84744, lr = 0.0025
I0520 19:52:53.562620 23162 solver.cpp:237] Iteration 84958, loss = 1.09006
I0520 19:52:53.562656 23162 solver.cpp:253]     Train net output #0: loss = 1.09006 (* 1 = 1.09006 loss)
I0520 19:52:53.562669 23162 sgd_solver.cpp:106] Iteration 84958, lr = 0.0025
I0520 19:53:02.479059 23162 solver.cpp:237] Iteration 85172, loss = 1.01647
I0520 19:53:02.479250 23162 solver.cpp:253]     Train net output #0: loss = 1.01647 (* 1 = 1.01647 loss)
I0520 19:53:02.479265 23162 sgd_solver.cpp:106] Iteration 85172, lr = 0.0025
I0520 19:53:11.395900 23162 solver.cpp:237] Iteration 85386, loss = 1.07846
I0520 19:53:11.395934 23162 solver.cpp:253]     Train net output #0: loss = 1.07846 (* 1 = 1.07846 loss)
I0520 19:53:11.395949 23162 sgd_solver.cpp:106] Iteration 85386, lr = 0.0025
I0520 19:53:20.309630 23162 solver.cpp:237] Iteration 85600, loss = 1.00703
I0520 19:53:20.309665 23162 solver.cpp:253]     Train net output #0: loss = 1.00703 (* 1 = 1.00703 loss)
I0520 19:53:20.309680 23162 sgd_solver.cpp:106] Iteration 85600, lr = 0.0025
I0520 19:53:23.606447 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_85680.caffemodel
I0520 19:53:23.675750 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_85680.solverstate
I0520 19:53:24.508389 23162 solver.cpp:341] Iteration 85700, Testing net (#0)
I0520 19:54:33.346148 23162 solver.cpp:409]     Test net output #0: accuracy = 0.893704
I0520 19:54:33.346345 23162 solver.cpp:409]     Test net output #1: loss = 0.333103 (* 1 = 0.333103 loss)
I0520 19:54:58.973907 23162 solver.cpp:237] Iteration 85814, loss = 1.06445
I0520 19:54:58.973961 23162 solver.cpp:253]     Train net output #0: loss = 1.06445 (* 1 = 1.06445 loss)
I0520 19:54:58.973975 23162 sgd_solver.cpp:106] Iteration 85814, lr = 0.0025
I0520 19:55:07.859567 23162 solver.cpp:237] Iteration 86028, loss = 1.13475
I0520 19:55:07.859779 23162 solver.cpp:253]     Train net output #0: loss = 1.13475 (* 1 = 1.13475 loss)
I0520 19:55:07.859793 23162 sgd_solver.cpp:106] Iteration 86028, lr = 0.0025
I0520 19:55:16.750843 23162 solver.cpp:237] Iteration 86242, loss = 1.03556
I0520 19:55:16.750877 23162 solver.cpp:253]     Train net output #0: loss = 1.03556 (* 1 = 1.03556 loss)
I0520 19:55:16.750892 23162 sgd_solver.cpp:106] Iteration 86242, lr = 0.0025
I0520 19:55:25.634544 23162 solver.cpp:237] Iteration 86456, loss = 1.3062
I0520 19:55:25.634579 23162 solver.cpp:253]     Train net output #0: loss = 1.3062 (* 1 = 1.3062 loss)
I0520 19:55:25.634593 23162 sgd_solver.cpp:106] Iteration 86456, lr = 0.0025
I0520 19:55:34.522852 23162 solver.cpp:237] Iteration 86670, loss = 1.36541
I0520 19:55:34.522896 23162 solver.cpp:253]     Train net output #0: loss = 1.36541 (* 1 = 1.36541 loss)
I0520 19:55:34.522907 23162 sgd_solver.cpp:106] Iteration 86670, lr = 0.0025
I0520 19:55:43.406458 23162 solver.cpp:237] Iteration 86884, loss = 1.09451
I0520 19:55:43.406635 23162 solver.cpp:253]     Train net output #0: loss = 1.09451 (* 1 = 1.09451 loss)
I0520 19:55:43.406647 23162 sgd_solver.cpp:106] Iteration 86884, lr = 0.0025
I0520 19:55:52.296881 23162 solver.cpp:237] Iteration 87098, loss = 1.06493
I0520 19:55:52.296916 23162 solver.cpp:253]     Train net output #0: loss = 1.06493 (* 1 = 1.06493 loss)
I0520 19:55:52.296931 23162 sgd_solver.cpp:106] Iteration 87098, lr = 0.0025
I0520 19:56:22.027266 23162 solver.cpp:237] Iteration 87312, loss = 1.05541
I0520 19:56:22.027463 23162 solver.cpp:253]     Train net output #0: loss = 1.05541 (* 1 = 1.05541 loss)
I0520 19:56:22.027477 23162 sgd_solver.cpp:106] Iteration 87312, lr = 0.0025
I0520 19:56:30.908516 23162 solver.cpp:237] Iteration 87526, loss = 1.28928
I0520 19:56:30.908563 23162 solver.cpp:253]     Train net output #0: loss = 1.28928 (* 1 = 1.28928 loss)
I0520 19:56:30.908583 23162 sgd_solver.cpp:106] Iteration 87526, lr = 0.0025
I0520 19:56:39.791163 23162 solver.cpp:237] Iteration 87740, loss = 1.20098
I0520 19:56:39.791199 23162 solver.cpp:253]     Train net output #0: loss = 1.20098 (* 1 = 1.20098 loss)
I0520 19:56:39.791213 23162 sgd_solver.cpp:106] Iteration 87740, lr = 0.0025
I0520 19:56:43.154920 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_87822.caffemodel
I0520 19:56:43.221514 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_87822.solverstate
I0520 19:56:48.742010 23162 solver.cpp:237] Iteration 87954, loss = 1.05516
I0520 19:56:48.742061 23162 solver.cpp:253]     Train net output #0: loss = 1.05516 (* 1 = 1.05516 loss)
I0520 19:56:48.742080 23162 sgd_solver.cpp:106] Iteration 87954, lr = 0.0025
I0520 19:56:57.636919 23162 solver.cpp:237] Iteration 88168, loss = 1.18165
I0520 19:56:57.637109 23162 solver.cpp:253]     Train net output #0: loss = 1.18165 (* 1 = 1.18165 loss)
I0520 19:56:57.637122 23162 sgd_solver.cpp:106] Iteration 88168, lr = 0.0025
I0520 19:57:06.527729 23162 solver.cpp:237] Iteration 88382, loss = 0.943132
I0520 19:57:06.527763 23162 solver.cpp:253]     Train net output #0: loss = 0.943132 (* 1 = 0.943132 loss)
I0520 19:57:06.527781 23162 sgd_solver.cpp:106] Iteration 88382, lr = 0.0025
I0520 19:57:36.335453 23162 solver.cpp:237] Iteration 88596, loss = 1.01094
I0520 19:57:36.335656 23162 solver.cpp:253]     Train net output #0: loss = 1.01094 (* 1 = 1.01094 loss)
I0520 19:57:36.335670 23162 sgd_solver.cpp:106] Iteration 88596, lr = 0.0025
I0520 19:57:45.259235 23162 solver.cpp:237] Iteration 88810, loss = 1.1898
I0520 19:57:45.259282 23162 solver.cpp:253]     Train net output #0: loss = 1.1898 (* 1 = 1.1898 loss)
I0520 19:57:45.259299 23162 sgd_solver.cpp:106] Iteration 88810, lr = 0.0025
I0520 19:57:54.147706 23162 solver.cpp:237] Iteration 89024, loss = 1.15149
I0520 19:57:54.147742 23162 solver.cpp:253]     Train net output #0: loss = 1.15149 (* 1 = 1.15149 loss)
I0520 19:57:54.147758 23162 sgd_solver.cpp:106] Iteration 89024, lr = 0.0025
I0520 19:58:03.040532 23162 solver.cpp:237] Iteration 89238, loss = 1.57599
I0520 19:58:03.040570 23162 solver.cpp:253]     Train net output #0: loss = 1.57599 (* 1 = 1.57599 loss)
I0520 19:58:03.040586 23162 sgd_solver.cpp:106] Iteration 89238, lr = 0.0025
I0520 19:58:11.937079 23162 solver.cpp:237] Iteration 89452, loss = 1.26447
I0520 19:58:11.937265 23162 solver.cpp:253]     Train net output #0: loss = 1.26447 (* 1 = 1.26447 loss)
I0520 19:58:11.937278 23162 sgd_solver.cpp:106] Iteration 89452, lr = 0.0025
I0520 19:58:20.818794 23162 solver.cpp:237] Iteration 89666, loss = 1.3379
I0520 19:58:20.818828 23162 solver.cpp:253]     Train net output #0: loss = 1.3379 (* 1 = 1.3379 loss)
I0520 19:58:20.818843 23162 sgd_solver.cpp:106] Iteration 89666, lr = 0.0025
I0520 19:58:29.707782 23162 solver.cpp:237] Iteration 89880, loss = 0.898187
I0520 19:58:29.707823 23162 solver.cpp:253]     Train net output #0: loss = 0.898187 (* 1 = 0.898187 loss)
I0520 19:58:29.707842 23162 sgd_solver.cpp:106] Iteration 89880, lr = 0.0025
I0520 19:58:33.154454 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_89964.caffemodel
I0520 19:58:33.220633 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_89964.solverstate
I0520 19:58:34.090155 23162 solver.cpp:341] Iteration 89985, Testing net (#0)
I0520 19:59:22.098088 23162 solver.cpp:409]     Test net output #0: accuracy = 0.894231
I0520 19:59:22.098294 23162 solver.cpp:409]     Test net output #1: loss = 0.348017 (* 1 = 0.348017 loss)
I0520 19:59:47.527031 23162 solver.cpp:237] Iteration 90094, loss = 0.947694
I0520 19:59:47.527087 23162 solver.cpp:253]     Train net output #0: loss = 0.947694 (* 1 = 0.947694 loss)
I0520 19:59:47.527102 23162 sgd_solver.cpp:106] Iteration 90094, lr = 0.0025
I0520 19:59:56.413362 23162 solver.cpp:237] Iteration 90308, loss = 1.17352
I0520 19:59:56.413549 23162 solver.cpp:253]     Train net output #0: loss = 1.17352 (* 1 = 1.17352 loss)
I0520 19:59:56.413563 23162 sgd_solver.cpp:106] Iteration 90308, lr = 0.0025
I0520 20:00:05.300412 23162 solver.cpp:237] Iteration 90522, loss = 1.27547
I0520 20:00:05.300447 23162 solver.cpp:253]     Train net output #0: loss = 1.27547 (* 1 = 1.27547 loss)
I0520 20:00:05.300464 23162 sgd_solver.cpp:106] Iteration 90522, lr = 0.0025
I0520 20:00:14.189714 23162 solver.cpp:237] Iteration 90736, loss = 1.3523
I0520 20:00:14.189765 23162 solver.cpp:253]     Train net output #0: loss = 1.3523 (* 1 = 1.3523 loss)
I0520 20:00:14.189784 23162 sgd_solver.cpp:106] Iteration 90736, lr = 0.0025
I0520 20:00:23.080711 23162 solver.cpp:237] Iteration 90950, loss = 1.19517
I0520 20:00:23.080747 23162 solver.cpp:253]     Train net output #0: loss = 1.19517 (* 1 = 1.19517 loss)
I0520 20:00:23.080765 23162 sgd_solver.cpp:106] Iteration 90950, lr = 0.0025
I0520 20:00:31.961232 23162 solver.cpp:237] Iteration 91164, loss = 1.15247
I0520 20:00:31.961410 23162 solver.cpp:253]     Train net output #0: loss = 1.15247 (* 1 = 1.15247 loss)
I0520 20:00:31.961424 23162 sgd_solver.cpp:106] Iteration 91164, lr = 0.0025
I0520 20:00:40.846155 23162 solver.cpp:237] Iteration 91378, loss = 0.996967
I0520 20:00:40.846200 23162 solver.cpp:253]     Train net output #0: loss = 0.996967 (* 1 = 0.996967 loss)
I0520 20:00:40.846217 23162 sgd_solver.cpp:106] Iteration 91378, lr = 0.0025
I0520 20:01:10.619329 23162 solver.cpp:237] Iteration 91592, loss = 1.01678
I0520 20:01:10.619532 23162 solver.cpp:253]     Train net output #0: loss = 1.01678 (* 1 = 1.01678 loss)
I0520 20:01:10.619546 23162 sgd_solver.cpp:106] Iteration 91592, lr = 0.0025
I0520 20:01:19.503198 23162 solver.cpp:237] Iteration 91806, loss = 1.24029
I0520 20:01:19.503233 23162 solver.cpp:253]     Train net output #0: loss = 1.24029 (* 1 = 1.24029 loss)
I0520 20:01:19.503250 23162 sgd_solver.cpp:106] Iteration 91806, lr = 0.0025
I0520 20:01:28.392387 23162 solver.cpp:237] Iteration 92020, loss = 0.96995
I0520 20:01:28.392431 23162 solver.cpp:253]     Train net output #0: loss = 0.96995 (* 1 = 0.96995 loss)
I0520 20:01:28.392452 23162 sgd_solver.cpp:106] Iteration 92020, lr = 0.0025
I0520 20:01:31.921715 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_92106.caffemodel
I0520 20:01:31.987377 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_92106.solverstate
I0520 20:01:37.344625 23162 solver.cpp:237] Iteration 92234, loss = 1.14668
I0520 20:01:37.344676 23162 solver.cpp:253]     Train net output #0: loss = 1.14668 (* 1 = 1.14668 loss)
I0520 20:01:37.344692 23162 sgd_solver.cpp:106] Iteration 92234, lr = 0.0025
I0520 20:01:46.237510 23162 solver.cpp:237] Iteration 92448, loss = 1.28398
I0520 20:01:46.237699 23162 solver.cpp:253]     Train net output #0: loss = 1.28398 (* 1 = 1.28398 loss)
I0520 20:01:46.237714 23162 sgd_solver.cpp:106] Iteration 92448, lr = 0.0025
I0520 20:01:55.119025 23162 solver.cpp:237] Iteration 92662, loss = 0.976521
I0520 20:01:55.119076 23162 solver.cpp:253]     Train net output #0: loss = 0.976521 (* 1 = 0.976521 loss)
I0520 20:01:55.119091 23162 sgd_solver.cpp:106] Iteration 92662, lr = 0.0025
I0520 20:02:24.904896 23162 solver.cpp:237] Iteration 92876, loss = 1.1589
I0520 20:02:24.905100 23162 solver.cpp:253]     Train net output #0: loss = 1.1589 (* 1 = 1.1589 loss)
I0520 20:02:24.905115 23162 sgd_solver.cpp:106] Iteration 92876, lr = 0.0025
I0520 20:02:33.786885 23162 solver.cpp:237] Iteration 93090, loss = 0.914656
I0520 20:02:33.786921 23162 solver.cpp:253]     Train net output #0: loss = 0.914656 (* 1 = 0.914656 loss)
I0520 20:02:33.786937 23162 sgd_solver.cpp:106] Iteration 93090, lr = 0.0025
I0520 20:02:42.673353 23162 solver.cpp:237] Iteration 93304, loss = 1.15518
I0520 20:02:42.673394 23162 solver.cpp:253]     Train net output #0: loss = 1.15518 (* 1 = 1.15518 loss)
I0520 20:02:42.673415 23162 sgd_solver.cpp:106] Iteration 93304, lr = 0.0025
I0520 20:02:51.558573 23162 solver.cpp:237] Iteration 93518, loss = 1.06671
I0520 20:02:51.558609 23162 solver.cpp:253]     Train net output #0: loss = 1.06671 (* 1 = 1.06671 loss)
I0520 20:02:51.558624 23162 sgd_solver.cpp:106] Iteration 93518, lr = 0.0025
I0520 20:03:00.444428 23162 solver.cpp:237] Iteration 93732, loss = 1.08592
I0520 20:03:00.444604 23162 solver.cpp:253]     Train net output #0: loss = 1.08592 (* 1 = 1.08592 loss)
I0520 20:03:00.444617 23162 sgd_solver.cpp:106] Iteration 93732, lr = 0.0025
I0520 20:03:09.329582 23162 solver.cpp:237] Iteration 93946, loss = 1.22429
I0520 20:03:09.329625 23162 solver.cpp:253]     Train net output #0: loss = 1.22429 (* 1 = 1.22429 loss)
I0520 20:03:09.329639 23162 sgd_solver.cpp:106] Iteration 93946, lr = 0.0025
I0520 20:03:18.215983 23162 solver.cpp:237] Iteration 94160, loss = 1.00826
I0520 20:03:18.216018 23162 solver.cpp:253]     Train net output #0: loss = 1.00826 (* 1 = 1.00826 loss)
I0520 20:03:18.216032 23162 sgd_solver.cpp:106] Iteration 94160, lr = 0.0025
I0520 20:03:21.830063 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_94248.caffemodel
I0520 20:03:21.896805 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_94248.solverstate
I0520 20:03:22.808400 23162 solver.cpp:341] Iteration 94270, Testing net (#0)
I0520 20:04:31.676260 23162 solver.cpp:409]     Test net output #0: accuracy = 0.895451
I0520 20:04:31.676477 23162 solver.cpp:409]     Test net output #1: loss = 0.353119 (* 1 = 0.353119 loss)
I0520 20:04:56.911862 23162 solver.cpp:237] Iteration 94374, loss = 0.988189
I0520 20:04:56.911916 23162 solver.cpp:253]     Train net output #0: loss = 0.988189 (* 1 = 0.988189 loss)
I0520 20:04:56.911934 23162 sgd_solver.cpp:106] Iteration 94374, lr = 0.0025
I0520 20:05:05.786660 23162 solver.cpp:237] Iteration 94588, loss = 1.25917
I0520 20:05:05.786846 23162 solver.cpp:253]     Train net output #0: loss = 1.25917 (* 1 = 1.25917 loss)
I0520 20:05:05.786860 23162 sgd_solver.cpp:106] Iteration 94588, lr = 0.0025
I0520 20:05:14.662418 23162 solver.cpp:237] Iteration 94802, loss = 1.0649
I0520 20:05:14.662464 23162 solver.cpp:253]     Train net output #0: loss = 1.0649 (* 1 = 1.0649 loss)
I0520 20:05:14.662482 23162 sgd_solver.cpp:106] Iteration 94802, lr = 0.0025
I0520 20:05:23.537843 23162 solver.cpp:237] Iteration 95016, loss = 1.22907
I0520 20:05:23.537878 23162 solver.cpp:253]     Train net output #0: loss = 1.22907 (* 1 = 1.22907 loss)
I0520 20:05:23.537894 23162 sgd_solver.cpp:106] Iteration 95016, lr = 0.0025
I0520 20:05:32.419639 23162 solver.cpp:237] Iteration 95230, loss = 1.21249
I0520 20:05:32.419682 23162 solver.cpp:253]     Train net output #0: loss = 1.21249 (* 1 = 1.21249 loss)
I0520 20:05:32.419701 23162 sgd_solver.cpp:106] Iteration 95230, lr = 0.0025
I0520 20:05:41.301952 23162 solver.cpp:237] Iteration 95444, loss = 1.09871
I0520 20:05:41.302129 23162 solver.cpp:253]     Train net output #0: loss = 1.09871 (* 1 = 1.09871 loss)
I0520 20:05:41.302142 23162 sgd_solver.cpp:106] Iteration 95444, lr = 0.0025
I0520 20:05:50.177115 23162 solver.cpp:237] Iteration 95658, loss = 1.06518
I0520 20:05:50.177150 23162 solver.cpp:253]     Train net output #0: loss = 1.06518 (* 1 = 1.06518 loss)
I0520 20:05:50.177167 23162 sgd_solver.cpp:106] Iteration 95658, lr = 0.0025
I0520 20:06:19.921386 23162 solver.cpp:237] Iteration 95872, loss = 1.15201
I0520 20:06:19.921586 23162 solver.cpp:253]     Train net output #0: loss = 1.15201 (* 1 = 1.15201 loss)
I0520 20:06:19.921600 23162 sgd_solver.cpp:106] Iteration 95872, lr = 0.0025
I0520 20:06:28.801127 23162 solver.cpp:237] Iteration 96086, loss = 1.12582
I0520 20:06:28.801175 23162 solver.cpp:253]     Train net output #0: loss = 1.12582 (* 1 = 1.12582 loss)
I0520 20:06:28.801192 23162 sgd_solver.cpp:106] Iteration 96086, lr = 0.0025
I0520 20:06:37.680857 23162 solver.cpp:237] Iteration 96300, loss = 1.11413
I0520 20:06:37.680893 23162 solver.cpp:253]     Train net output #0: loss = 1.11413 (* 1 = 1.11413 loss)
I0520 20:06:37.680907 23162 sgd_solver.cpp:106] Iteration 96300, lr = 0.0025
I0520 20:06:41.369801 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_96390.caffemodel
I0520 20:06:41.437914 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_96390.solverstate
I0520 20:06:46.625143 23162 solver.cpp:237] Iteration 96514, loss = 1.26284
I0520 20:06:46.625195 23162 solver.cpp:253]     Train net output #0: loss = 1.26284 (* 1 = 1.26284 loss)
I0520 20:06:46.625211 23162 sgd_solver.cpp:106] Iteration 96514, lr = 0.0025
I0520 20:06:55.511425 23162 solver.cpp:237] Iteration 96728, loss = 1.203
I0520 20:06:55.511632 23162 solver.cpp:253]     Train net output #0: loss = 1.203 (* 1 = 1.203 loss)
I0520 20:06:55.511646 23162 sgd_solver.cpp:106] Iteration 96728, lr = 0.0025
I0520 20:07:04.389217 23162 solver.cpp:237] Iteration 96942, loss = 0.994614
I0520 20:07:04.389253 23162 solver.cpp:253]     Train net output #0: loss = 0.994614 (* 1 = 0.994614 loss)
I0520 20:07:04.389267 23162 sgd_solver.cpp:106] Iteration 96942, lr = 0.0025
I0520 20:07:34.172459 23162 solver.cpp:237] Iteration 97156, loss = 1.0966
I0520 20:07:34.172667 23162 solver.cpp:253]     Train net output #0: loss = 1.0966 (* 1 = 1.0966 loss)
I0520 20:07:34.172680 23162 sgd_solver.cpp:106] Iteration 97156, lr = 0.0025
I0520 20:07:43.049614 23162 solver.cpp:237] Iteration 97370, loss = 1.24645
I0520 20:07:43.049655 23162 solver.cpp:253]     Train net output #0: loss = 1.24645 (* 1 = 1.24645 loss)
I0520 20:07:43.049677 23162 sgd_solver.cpp:106] Iteration 97370, lr = 0.0025
I0520 20:07:51.925503 23162 solver.cpp:237] Iteration 97584, loss = 1.10616
I0520 20:07:51.925539 23162 solver.cpp:253]     Train net output #0: loss = 1.10616 (* 1 = 1.10616 loss)
I0520 20:07:51.925554 23162 sgd_solver.cpp:106] Iteration 97584, lr = 0.0025
I0520 20:08:00.804096 23162 solver.cpp:237] Iteration 97798, loss = 1.17881
I0520 20:08:00.804131 23162 solver.cpp:253]     Train net output #0: loss = 1.17881 (* 1 = 1.17881 loss)
I0520 20:08:00.804147 23162 sgd_solver.cpp:106] Iteration 97798, lr = 0.0025
I0520 20:08:09.683450 23162 solver.cpp:237] Iteration 98012, loss = 1.22786
I0520 20:08:09.683651 23162 solver.cpp:253]     Train net output #0: loss = 1.22786 (* 1 = 1.22786 loss)
I0520 20:08:09.683665 23162 sgd_solver.cpp:106] Iteration 98012, lr = 0.0025
I0520 20:08:18.554954 23162 solver.cpp:237] Iteration 98226, loss = 1.38123
I0520 20:08:18.554988 23162 solver.cpp:253]     Train net output #0: loss = 1.38123 (* 1 = 1.38123 loss)
I0520 20:08:18.555006 23162 sgd_solver.cpp:106] Iteration 98226, lr = 0.0025
I0520 20:08:27.432862 23162 solver.cpp:237] Iteration 98440, loss = 0.925713
I0520 20:08:27.432904 23162 solver.cpp:253]     Train net output #0: loss = 0.925713 (* 1 = 0.925713 loss)
I0520 20:08:27.432924 23162 sgd_solver.cpp:106] Iteration 98440, lr = 0.0025
I0520 20:08:31.208271 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_98532.caffemodel
I0520 20:08:31.274549 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_98532.solverstate
I0520 20:08:32.227051 23162 solver.cpp:341] Iteration 98555, Testing net (#0)
I0520 20:09:19.853914 23162 solver.cpp:409]     Test net output #0: accuracy = 0.89812
I0520 20:09:19.854115 23162 solver.cpp:409]     Test net output #1: loss = 0.335629 (* 1 = 0.335629 loss)
I0520 20:09:44.859464 23162 solver.cpp:237] Iteration 98654, loss = 0.926886
I0520 20:09:44.859518 23162 solver.cpp:253]     Train net output #0: loss = 0.926886 (* 1 = 0.926886 loss)
I0520 20:09:44.859537 23162 sgd_solver.cpp:106] Iteration 98654, lr = 0.0025
I0520 20:09:53.756624 23162 solver.cpp:237] Iteration 98868, loss = 1.02451
I0520 20:09:53.756808 23162 solver.cpp:253]     Train net output #0: loss = 1.02451 (* 1 = 1.02451 loss)
I0520 20:09:53.756821 23162 sgd_solver.cpp:106] Iteration 98868, lr = 0.0025
I0520 20:10:02.652890 23162 solver.cpp:237] Iteration 99082, loss = 1.04033
I0520 20:10:02.652925 23162 solver.cpp:253]     Train net output #0: loss = 1.04033 (* 1 = 1.04033 loss)
I0520 20:10:02.652942 23162 sgd_solver.cpp:106] Iteration 99082, lr = 0.0025
I0520 20:10:11.552336 23162 solver.cpp:237] Iteration 99296, loss = 1.09832
I0520 20:10:11.552382 23162 solver.cpp:253]     Train net output #0: loss = 1.09832 (* 1 = 1.09832 loss)
I0520 20:10:11.552403 23162 sgd_solver.cpp:106] Iteration 99296, lr = 0.0025
I0520 20:10:20.448319 23162 solver.cpp:237] Iteration 99510, loss = 1.22419
I0520 20:10:20.448355 23162 solver.cpp:253]     Train net output #0: loss = 1.22419 (* 1 = 1.22419 loss)
I0520 20:10:20.448371 23162 sgd_solver.cpp:106] Iteration 99510, lr = 0.0025
I0520 20:10:29.346393 23162 solver.cpp:237] Iteration 99724, loss = 1.18093
I0520 20:10:29.346575 23162 solver.cpp:253]     Train net output #0: loss = 1.18093 (* 1 = 1.18093 loss)
I0520 20:10:29.346587 23162 sgd_solver.cpp:106] Iteration 99724, lr = 0.0025
I0520 20:10:38.242736 23162 solver.cpp:237] Iteration 99938, loss = 1.15365
I0520 20:10:38.242784 23162 solver.cpp:253]     Train net output #0: loss = 1.15365 (* 1 = 1.15365 loss)
I0520 20:10:38.242799 23162 sgd_solver.cpp:106] Iteration 99938, lr = 0.0025
I0520 20:11:08.027551 23162 solver.cpp:237] Iteration 100152, loss = 1.12927
I0520 20:11:08.027763 23162 solver.cpp:253]     Train net output #0: loss = 1.12927 (* 1 = 1.12927 loss)
I0520 20:11:08.027778 23162 sgd_solver.cpp:106] Iteration 100152, lr = 0.0025
I0520 20:11:16.926201 23162 solver.cpp:237] Iteration 100366, loss = 1.32221
I0520 20:11:16.926235 23162 solver.cpp:253]     Train net output #0: loss = 1.32221 (* 1 = 1.32221 loss)
I0520 20:11:16.926249 23162 sgd_solver.cpp:106] Iteration 100366, lr = 0.0025
I0520 20:11:25.824404 23162 solver.cpp:237] Iteration 100580, loss = 1.07848
I0520 20:11:25.824450 23162 solver.cpp:253]     Train net output #0: loss = 1.07848 (* 1 = 1.07848 loss)
I0520 20:11:25.824467 23162 sgd_solver.cpp:106] Iteration 100580, lr = 0.0025
I0520 20:11:29.687057 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_100674.caffemodel
I0520 20:11:29.754070 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_100674.solverstate
I0520 20:11:34.784076 23162 solver.cpp:237] Iteration 100794, loss = 1.18168
I0520 20:11:34.784123 23162 solver.cpp:253]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0520 20:11:34.784143 23162 sgd_solver.cpp:106] Iteration 100794, lr = 0.0025
I0520 20:11:43.682039 23162 solver.cpp:237] Iteration 101008, loss = 1.22621
I0520 20:11:43.682226 23162 solver.cpp:253]     Train net output #0: loss = 1.22621 (* 1 = 1.22621 loss)
I0520 20:11:43.682240 23162 sgd_solver.cpp:106] Iteration 101008, lr = 0.0025
I0520 20:11:52.580379 23162 solver.cpp:237] Iteration 101222, loss = 1.19277
I0520 20:11:52.580426 23162 solver.cpp:253]     Train net output #0: loss = 1.19277 (* 1 = 1.19277 loss)
I0520 20:11:52.580443 23162 sgd_solver.cpp:106] Iteration 101222, lr = 0.0025
I0520 20:12:22.381372 23162 solver.cpp:237] Iteration 101436, loss = 1.26786
I0520 20:12:22.381584 23162 solver.cpp:253]     Train net output #0: loss = 1.26786 (* 1 = 1.26786 loss)
I0520 20:12:22.381598 23162 sgd_solver.cpp:106] Iteration 101436, lr = 0.0025
I0520 20:12:31.278610 23162 solver.cpp:237] Iteration 101650, loss = 1.04078
I0520 20:12:31.278645 23162 solver.cpp:253]     Train net output #0: loss = 1.04078 (* 1 = 1.04078 loss)
I0520 20:12:31.278662 23162 sgd_solver.cpp:106] Iteration 101650, lr = 0.0025
I0520 20:12:40.178597 23162 solver.cpp:237] Iteration 101864, loss = 0.97711
I0520 20:12:40.178644 23162 solver.cpp:253]     Train net output #0: loss = 0.97711 (* 1 = 0.97711 loss)
I0520 20:12:40.178663 23162 sgd_solver.cpp:106] Iteration 101864, lr = 0.0025
I0520 20:12:49.072703 23162 solver.cpp:237] Iteration 102078, loss = 1.10531
I0520 20:12:49.072739 23162 solver.cpp:253]     Train net output #0: loss = 1.10531 (* 1 = 1.10531 loss)
I0520 20:12:49.072756 23162 sgd_solver.cpp:106] Iteration 102078, lr = 0.0025
I0520 20:12:57.965054 23162 solver.cpp:237] Iteration 102292, loss = 1.11656
I0520 20:12:57.965234 23162 solver.cpp:253]     Train net output #0: loss = 1.11656 (* 1 = 1.11656 loss)
I0520 20:12:57.965247 23162 sgd_solver.cpp:106] Iteration 102292, lr = 0.0025
I0520 20:13:06.853936 23162 solver.cpp:237] Iteration 102506, loss = 1.38882
I0520 20:13:06.853976 23162 solver.cpp:253]     Train net output #0: loss = 1.38882 (* 1 = 1.38882 loss)
I0520 20:13:06.853996 23162 sgd_solver.cpp:106] Iteration 102506, lr = 0.0025
I0520 20:13:15.747961 23162 solver.cpp:237] Iteration 102720, loss = 1.29156
I0520 20:13:15.747997 23162 solver.cpp:253]     Train net output #0: loss = 1.29156 (* 1 = 1.29156 loss)
I0520 20:13:15.748009 23162 sgd_solver.cpp:106] Iteration 102720, lr = 0.0025
I0520 20:13:19.699120 23162 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_102816.caffemodel
I0520 20:13:19.765496 23162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_70_lr_0.0025_2016-05-20T15.49.14.146224_iter_102816.solverstate
I0520 20:13:20.762385 23162 solver.cpp:341] Iteration 102840, Testing net (#0)
aprun: Apid 11234213: Caught signal Terminated, sending to application
*** Aborted at 1463789624 (unix time) try "date -d @1463789624" if you are using GNU date ***
PC: @     0x2aaac5e9bb3b (unknown)
*** SIGTERM (@0x5a77) received by PID 23162 (TID 0x2aaac746f900) from PID 23159; stack trace: ***
    @     0x2aaab7c78850 (unknown)
=>> PBS: job killed: walltime 7239 exceeded limit 7200
aprun: Apid 11234213: Caught signal Terminated, sending to application
    @     0x2aaac5e9bb3b (unknown)
aprun: Apid 11234213: Caught signal Terminated, sending to application
    @     0x2aaac5e9c9d5 inflate
    @     0x2aaab1450a9d H5Z_filter_deflate
    @     0x2aaab144fcf1 H5Z_pipeline
aprun: Apid 11234213: Caught signal Terminated, sending to application
    @     0x2aaab128ac92 H5D__chunk_lock
    @     0x2aaab128be08 H5D__chunk_read
    @     0x2aaab129e5ec H5D__read
    @     0x2aaab129ec5c H5Dread
    @     0x2aaab0ff545c H5LTread_dataset_float
aprun: Apid 11234213: Caught signal Terminated, sending to application
    @           0x4cd99a caffe::hdf5_load_nd_dataset<>()
    @           0x5b8d0e caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @           0x626f33 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11234213: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5c956f caffe::Solver<>::Test()
    @           0x5c9ebe caffe::Solver<>::TestAll()
    @           0x5ca001 caffe::Solver<>::Step()
aprun: Apid 11234213: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11234213: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
aprun: Apid 11234213: Caught signal Terminated, sending to application
