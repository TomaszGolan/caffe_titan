2811349
I0526 07:01:58.848670  6929 caffe.cpp:184] Using GPUs 0
I0526 07:01:59.274865  6929 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.003
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925.prototxt"
I0526 07:01:59.291720  6929 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925.prototxt
I0526 07:01:59.324368  6929 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 07:01:59.324425  6929 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 07:01:59.324784  6929 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 07:01:59.324965  6929 layer_factory.hpp:77] Creating layer data_hdf5
I0526 07:01:59.324990  6929 net.cpp:106] Creating Layer data_hdf5
I0526 07:01:59.325004  6929 net.cpp:411] data_hdf5 -> data
I0526 07:01:59.325037  6929 net.cpp:411] data_hdf5 -> label
I0526 07:01:59.325070  6929 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 07:01:59.341233  6929 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 07:01:59.355104  6929 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 07:02:20.951289  6929 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 07:02:20.963094  6929 net.cpp:150] Setting up data_hdf5
I0526 07:02:20.963136  6929 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 07:02:20.963151  6929 net.cpp:157] Top shape: 10 (10)
I0526 07:02:20.963165  6929 net.cpp:165] Memory required for data: 254040
I0526 07:02:20.963178  6929 layer_factory.hpp:77] Creating layer conv1
I0526 07:02:20.963212  6929 net.cpp:106] Creating Layer conv1
I0526 07:02:20.963222  6929 net.cpp:454] conv1 <- data
I0526 07:02:20.963245  6929 net.cpp:411] conv1 -> conv1
I0526 07:02:23.800268  6929 net.cpp:150] Setting up conv1
I0526 07:02:23.800313  6929 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:02:23.800325  6929 net.cpp:165] Memory required for data: 3018840
I0526 07:02:23.800354  6929 layer_factory.hpp:77] Creating layer relu1
I0526 07:02:23.800375  6929 net.cpp:106] Creating Layer relu1
I0526 07:02:23.800387  6929 net.cpp:454] relu1 <- conv1
I0526 07:02:23.800401  6929 net.cpp:397] relu1 -> conv1 (in-place)
I0526 07:02:23.800921  6929 net.cpp:150] Setting up relu1
I0526 07:02:23.800938  6929 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:02:23.800948  6929 net.cpp:165] Memory required for data: 5783640
I0526 07:02:23.800958  6929 layer_factory.hpp:77] Creating layer pool1
I0526 07:02:23.800977  6929 net.cpp:106] Creating Layer pool1
I0526 07:02:23.800987  6929 net.cpp:454] pool1 <- conv1
I0526 07:02:23.801002  6929 net.cpp:411] pool1 -> pool1
I0526 07:02:23.801080  6929 net.cpp:150] Setting up pool1
I0526 07:02:23.801095  6929 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 07:02:23.801105  6929 net.cpp:165] Memory required for data: 7166040
I0526 07:02:23.801115  6929 layer_factory.hpp:77] Creating layer conv2
I0526 07:02:23.801137  6929 net.cpp:106] Creating Layer conv2
I0526 07:02:23.801149  6929 net.cpp:454] conv2 <- pool1
I0526 07:02:23.801163  6929 net.cpp:411] conv2 -> conv2
I0526 07:02:23.803838  6929 net.cpp:150] Setting up conv2
I0526 07:02:23.803866  6929 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:02:23.803877  6929 net.cpp:165] Memory required for data: 9153240
I0526 07:02:23.803895  6929 layer_factory.hpp:77] Creating layer relu2
I0526 07:02:23.803910  6929 net.cpp:106] Creating Layer relu2
I0526 07:02:23.803920  6929 net.cpp:454] relu2 <- conv2
I0526 07:02:23.803932  6929 net.cpp:397] relu2 -> conv2 (in-place)
I0526 07:02:23.804277  6929 net.cpp:150] Setting up relu2
I0526 07:02:23.804291  6929 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:02:23.804301  6929 net.cpp:165] Memory required for data: 11140440
I0526 07:02:23.804311  6929 layer_factory.hpp:77] Creating layer pool2
I0526 07:02:23.804323  6929 net.cpp:106] Creating Layer pool2
I0526 07:02:23.804333  6929 net.cpp:454] pool2 <- conv2
I0526 07:02:23.804347  6929 net.cpp:411] pool2 -> pool2
I0526 07:02:23.804430  6929 net.cpp:150] Setting up pool2
I0526 07:02:23.804443  6929 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 07:02:23.804453  6929 net.cpp:165] Memory required for data: 12134040
I0526 07:02:23.804461  6929 layer_factory.hpp:77] Creating layer conv3
I0526 07:02:23.804478  6929 net.cpp:106] Creating Layer conv3
I0526 07:02:23.804489  6929 net.cpp:454] conv3 <- pool2
I0526 07:02:23.804502  6929 net.cpp:411] conv3 -> conv3
I0526 07:02:23.806589  6929 net.cpp:150] Setting up conv3
I0526 07:02:23.806613  6929 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:02:23.806625  6929 net.cpp:165] Memory required for data: 13218200
I0526 07:02:23.806643  6929 layer_factory.hpp:77] Creating layer relu3
I0526 07:02:23.806660  6929 net.cpp:106] Creating Layer relu3
I0526 07:02:23.806670  6929 net.cpp:454] relu3 <- conv3
I0526 07:02:23.806684  6929 net.cpp:397] relu3 -> conv3 (in-place)
I0526 07:02:23.807152  6929 net.cpp:150] Setting up relu3
I0526 07:02:23.807168  6929 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:02:23.807178  6929 net.cpp:165] Memory required for data: 14302360
I0526 07:02:23.807189  6929 layer_factory.hpp:77] Creating layer pool3
I0526 07:02:23.807202  6929 net.cpp:106] Creating Layer pool3
I0526 07:02:23.807212  6929 net.cpp:454] pool3 <- conv3
I0526 07:02:23.807225  6929 net.cpp:411] pool3 -> pool3
I0526 07:02:23.807292  6929 net.cpp:150] Setting up pool3
I0526 07:02:23.807306  6929 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 07:02:23.807315  6929 net.cpp:165] Memory required for data: 14844440
I0526 07:02:23.807324  6929 layer_factory.hpp:77] Creating layer conv4
I0526 07:02:23.807342  6929 net.cpp:106] Creating Layer conv4
I0526 07:02:23.807353  6929 net.cpp:454] conv4 <- pool3
I0526 07:02:23.807365  6929 net.cpp:411] conv4 -> conv4
I0526 07:02:23.810096  6929 net.cpp:150] Setting up conv4
I0526 07:02:23.810119  6929 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:02:23.810129  6929 net.cpp:165] Memory required for data: 15207320
I0526 07:02:23.810145  6929 layer_factory.hpp:77] Creating layer relu4
I0526 07:02:23.810159  6929 net.cpp:106] Creating Layer relu4
I0526 07:02:23.810168  6929 net.cpp:454] relu4 <- conv4
I0526 07:02:23.810183  6929 net.cpp:397] relu4 -> conv4 (in-place)
I0526 07:02:23.810647  6929 net.cpp:150] Setting up relu4
I0526 07:02:23.810662  6929 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:02:23.810673  6929 net.cpp:165] Memory required for data: 15570200
I0526 07:02:23.810683  6929 layer_factory.hpp:77] Creating layer pool4
I0526 07:02:23.810695  6929 net.cpp:106] Creating Layer pool4
I0526 07:02:23.810705  6929 net.cpp:454] pool4 <- conv4
I0526 07:02:23.810719  6929 net.cpp:411] pool4 -> pool4
I0526 07:02:23.810787  6929 net.cpp:150] Setting up pool4
I0526 07:02:23.810801  6929 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 07:02:23.810811  6929 net.cpp:165] Memory required for data: 15751640
I0526 07:02:23.810820  6929 layer_factory.hpp:77] Creating layer ip1
I0526 07:02:23.810842  6929 net.cpp:106] Creating Layer ip1
I0526 07:02:23.810852  6929 net.cpp:454] ip1 <- pool4
I0526 07:02:23.810864  6929 net.cpp:411] ip1 -> ip1
I0526 07:02:23.826326  6929 net.cpp:150] Setting up ip1
I0526 07:02:23.826349  6929 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:02:23.826360  6929 net.cpp:165] Memory required for data: 15759480
I0526 07:02:23.826382  6929 layer_factory.hpp:77] Creating layer relu5
I0526 07:02:23.826397  6929 net.cpp:106] Creating Layer relu5
I0526 07:02:23.826407  6929 net.cpp:454] relu5 <- ip1
I0526 07:02:23.826421  6929 net.cpp:397] relu5 -> ip1 (in-place)
I0526 07:02:23.826766  6929 net.cpp:150] Setting up relu5
I0526 07:02:23.826778  6929 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:02:23.826788  6929 net.cpp:165] Memory required for data: 15767320
I0526 07:02:23.826798  6929 layer_factory.hpp:77] Creating layer drop1
I0526 07:02:23.826820  6929 net.cpp:106] Creating Layer drop1
I0526 07:02:23.826830  6929 net.cpp:454] drop1 <- ip1
I0526 07:02:23.826843  6929 net.cpp:397] drop1 -> ip1 (in-place)
I0526 07:02:23.826901  6929 net.cpp:150] Setting up drop1
I0526 07:02:23.826915  6929 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:02:23.826925  6929 net.cpp:165] Memory required for data: 15775160
I0526 07:02:23.826935  6929 layer_factory.hpp:77] Creating layer ip2
I0526 07:02:23.826952  6929 net.cpp:106] Creating Layer ip2
I0526 07:02:23.826963  6929 net.cpp:454] ip2 <- ip1
I0526 07:02:23.826977  6929 net.cpp:411] ip2 -> ip2
I0526 07:02:23.827442  6929 net.cpp:150] Setting up ip2
I0526 07:02:23.827455  6929 net.cpp:157] Top shape: 10 98 (980)
I0526 07:02:23.827466  6929 net.cpp:165] Memory required for data: 15779080
I0526 07:02:23.827481  6929 layer_factory.hpp:77] Creating layer relu6
I0526 07:02:23.827493  6929 net.cpp:106] Creating Layer relu6
I0526 07:02:23.827503  6929 net.cpp:454] relu6 <- ip2
I0526 07:02:23.827515  6929 net.cpp:397] relu6 -> ip2 (in-place)
I0526 07:02:23.828029  6929 net.cpp:150] Setting up relu6
I0526 07:02:23.828045  6929 net.cpp:157] Top shape: 10 98 (980)
I0526 07:02:23.828055  6929 net.cpp:165] Memory required for data: 15783000
I0526 07:02:23.828065  6929 layer_factory.hpp:77] Creating layer drop2
I0526 07:02:23.828078  6929 net.cpp:106] Creating Layer drop2
I0526 07:02:23.828095  6929 net.cpp:454] drop2 <- ip2
I0526 07:02:23.828109  6929 net.cpp:397] drop2 -> ip2 (in-place)
I0526 07:02:23.828152  6929 net.cpp:150] Setting up drop2
I0526 07:02:23.828166  6929 net.cpp:157] Top shape: 10 98 (980)
I0526 07:02:23.828176  6929 net.cpp:165] Memory required for data: 15786920
I0526 07:02:23.828186  6929 layer_factory.hpp:77] Creating layer ip3
I0526 07:02:23.828198  6929 net.cpp:106] Creating Layer ip3
I0526 07:02:23.828208  6929 net.cpp:454] ip3 <- ip2
I0526 07:02:23.828222  6929 net.cpp:411] ip3 -> ip3
I0526 07:02:23.828430  6929 net.cpp:150] Setting up ip3
I0526 07:02:23.828444  6929 net.cpp:157] Top shape: 10 11 (110)
I0526 07:02:23.828454  6929 net.cpp:165] Memory required for data: 15787360
I0526 07:02:23.828469  6929 layer_factory.hpp:77] Creating layer drop3
I0526 07:02:23.828481  6929 net.cpp:106] Creating Layer drop3
I0526 07:02:23.828491  6929 net.cpp:454] drop3 <- ip3
I0526 07:02:23.828503  6929 net.cpp:397] drop3 -> ip3 (in-place)
I0526 07:02:23.828542  6929 net.cpp:150] Setting up drop3
I0526 07:02:23.828555  6929 net.cpp:157] Top shape: 10 11 (110)
I0526 07:02:23.828564  6929 net.cpp:165] Memory required for data: 15787800
I0526 07:02:23.828574  6929 layer_factory.hpp:77] Creating layer loss
I0526 07:02:23.828594  6929 net.cpp:106] Creating Layer loss
I0526 07:02:23.828604  6929 net.cpp:454] loss <- ip3
I0526 07:02:23.828615  6929 net.cpp:454] loss <- label
I0526 07:02:23.828629  6929 net.cpp:411] loss -> loss
I0526 07:02:23.828645  6929 layer_factory.hpp:77] Creating layer loss
I0526 07:02:23.829284  6929 net.cpp:150] Setting up loss
I0526 07:02:23.829305  6929 net.cpp:157] Top shape: (1)
I0526 07:02:23.829319  6929 net.cpp:160]     with loss weight 1
I0526 07:02:23.829360  6929 net.cpp:165] Memory required for data: 15787804
I0526 07:02:23.829371  6929 net.cpp:226] loss needs backward computation.
I0526 07:02:23.829382  6929 net.cpp:226] drop3 needs backward computation.
I0526 07:02:23.829392  6929 net.cpp:226] ip3 needs backward computation.
I0526 07:02:23.829402  6929 net.cpp:226] drop2 needs backward computation.
I0526 07:02:23.829412  6929 net.cpp:226] relu6 needs backward computation.
I0526 07:02:23.829422  6929 net.cpp:226] ip2 needs backward computation.
I0526 07:02:23.829433  6929 net.cpp:226] drop1 needs backward computation.
I0526 07:02:23.829442  6929 net.cpp:226] relu5 needs backward computation.
I0526 07:02:23.829452  6929 net.cpp:226] ip1 needs backward computation.
I0526 07:02:23.829463  6929 net.cpp:226] pool4 needs backward computation.
I0526 07:02:23.829473  6929 net.cpp:226] relu4 needs backward computation.
I0526 07:02:23.829483  6929 net.cpp:226] conv4 needs backward computation.
I0526 07:02:23.829493  6929 net.cpp:226] pool3 needs backward computation.
I0526 07:02:23.829504  6929 net.cpp:226] relu3 needs backward computation.
I0526 07:02:23.829514  6929 net.cpp:226] conv3 needs backward computation.
I0526 07:02:23.829533  6929 net.cpp:226] pool2 needs backward computation.
I0526 07:02:23.829545  6929 net.cpp:226] relu2 needs backward computation.
I0526 07:02:23.829555  6929 net.cpp:226] conv2 needs backward computation.
I0526 07:02:23.829566  6929 net.cpp:226] pool1 needs backward computation.
I0526 07:02:23.829577  6929 net.cpp:226] relu1 needs backward computation.
I0526 07:02:23.829587  6929 net.cpp:226] conv1 needs backward computation.
I0526 07:02:23.829598  6929 net.cpp:228] data_hdf5 does not need backward computation.
I0526 07:02:23.829608  6929 net.cpp:270] This network produces output loss
I0526 07:02:23.829632  6929 net.cpp:283] Network initialization done.
I0526 07:02:23.837723  6929 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925.prototxt
I0526 07:02:23.837801  6929 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 07:02:23.838160  6929 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 07:02:23.838353  6929 layer_factory.hpp:77] Creating layer data_hdf5
I0526 07:02:23.838369  6929 net.cpp:106] Creating Layer data_hdf5
I0526 07:02:23.838381  6929 net.cpp:411] data_hdf5 -> data
I0526 07:02:23.838398  6929 net.cpp:411] data_hdf5 -> label
I0526 07:02:23.838414  6929 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 07:02:23.849486  6929 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 07:02:45.263113  6929 net.cpp:150] Setting up data_hdf5
I0526 07:02:45.263278  6929 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 07:02:45.263293  6929 net.cpp:157] Top shape: 10 (10)
I0526 07:02:45.263303  6929 net.cpp:165] Memory required for data: 254040
I0526 07:02:45.263316  6929 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 07:02:45.263345  6929 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 07:02:45.263356  6929 net.cpp:454] label_data_hdf5_1_split <- label
I0526 07:02:45.263370  6929 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 07:02:45.263392  6929 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 07:02:45.263464  6929 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 07:02:45.263478  6929 net.cpp:157] Top shape: 10 (10)
I0526 07:02:45.263490  6929 net.cpp:157] Top shape: 10 (10)
I0526 07:02:45.263500  6929 net.cpp:165] Memory required for data: 254120
I0526 07:02:45.263510  6929 layer_factory.hpp:77] Creating layer conv1
I0526 07:02:45.263530  6929 net.cpp:106] Creating Layer conv1
I0526 07:02:45.263541  6929 net.cpp:454] conv1 <- data
I0526 07:02:45.263556  6929 net.cpp:411] conv1 -> conv1
I0526 07:02:45.265488  6929 net.cpp:150] Setting up conv1
I0526 07:02:45.265512  6929 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:02:45.265524  6929 net.cpp:165] Memory required for data: 3018920
I0526 07:02:45.265545  6929 layer_factory.hpp:77] Creating layer relu1
I0526 07:02:45.265559  6929 net.cpp:106] Creating Layer relu1
I0526 07:02:45.265569  6929 net.cpp:454] relu1 <- conv1
I0526 07:02:45.265583  6929 net.cpp:397] relu1 -> conv1 (in-place)
I0526 07:02:45.266093  6929 net.cpp:150] Setting up relu1
I0526 07:02:45.266109  6929 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 07:02:45.266119  6929 net.cpp:165] Memory required for data: 5783720
I0526 07:02:45.266130  6929 layer_factory.hpp:77] Creating layer pool1
I0526 07:02:45.266145  6929 net.cpp:106] Creating Layer pool1
I0526 07:02:45.266155  6929 net.cpp:454] pool1 <- conv1
I0526 07:02:45.266170  6929 net.cpp:411] pool1 -> pool1
I0526 07:02:45.266243  6929 net.cpp:150] Setting up pool1
I0526 07:02:45.266257  6929 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 07:02:45.266266  6929 net.cpp:165] Memory required for data: 7166120
I0526 07:02:45.266278  6929 layer_factory.hpp:77] Creating layer conv2
I0526 07:02:45.266297  6929 net.cpp:106] Creating Layer conv2
I0526 07:02:45.266307  6929 net.cpp:454] conv2 <- pool1
I0526 07:02:45.266320  6929 net.cpp:411] conv2 -> conv2
I0526 07:02:45.268231  6929 net.cpp:150] Setting up conv2
I0526 07:02:45.268254  6929 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:02:45.268267  6929 net.cpp:165] Memory required for data: 9153320
I0526 07:02:45.268285  6929 layer_factory.hpp:77] Creating layer relu2
I0526 07:02:45.268298  6929 net.cpp:106] Creating Layer relu2
I0526 07:02:45.268308  6929 net.cpp:454] relu2 <- conv2
I0526 07:02:45.268321  6929 net.cpp:397] relu2 -> conv2 (in-place)
I0526 07:02:45.268656  6929 net.cpp:150] Setting up relu2
I0526 07:02:45.268669  6929 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 07:02:45.268679  6929 net.cpp:165] Memory required for data: 11140520
I0526 07:02:45.268689  6929 layer_factory.hpp:77] Creating layer pool2
I0526 07:02:45.268703  6929 net.cpp:106] Creating Layer pool2
I0526 07:02:45.268713  6929 net.cpp:454] pool2 <- conv2
I0526 07:02:45.268725  6929 net.cpp:411] pool2 -> pool2
I0526 07:02:45.268800  6929 net.cpp:150] Setting up pool2
I0526 07:02:45.268813  6929 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 07:02:45.268823  6929 net.cpp:165] Memory required for data: 12134120
I0526 07:02:45.268833  6929 layer_factory.hpp:77] Creating layer conv3
I0526 07:02:45.268853  6929 net.cpp:106] Creating Layer conv3
I0526 07:02:45.268863  6929 net.cpp:454] conv3 <- pool2
I0526 07:02:45.268878  6929 net.cpp:411] conv3 -> conv3
I0526 07:02:45.270872  6929 net.cpp:150] Setting up conv3
I0526 07:02:45.270896  6929 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:02:45.270908  6929 net.cpp:165] Memory required for data: 13218280
I0526 07:02:45.270926  6929 layer_factory.hpp:77] Creating layer relu3
I0526 07:02:45.270953  6929 net.cpp:106] Creating Layer relu3
I0526 07:02:45.270963  6929 net.cpp:454] relu3 <- conv3
I0526 07:02:45.270977  6929 net.cpp:397] relu3 -> conv3 (in-place)
I0526 07:02:45.271446  6929 net.cpp:150] Setting up relu3
I0526 07:02:45.271462  6929 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 07:02:45.271472  6929 net.cpp:165] Memory required for data: 14302440
I0526 07:02:45.271483  6929 layer_factory.hpp:77] Creating layer pool3
I0526 07:02:45.271497  6929 net.cpp:106] Creating Layer pool3
I0526 07:02:45.271507  6929 net.cpp:454] pool3 <- conv3
I0526 07:02:45.271522  6929 net.cpp:411] pool3 -> pool3
I0526 07:02:45.271594  6929 net.cpp:150] Setting up pool3
I0526 07:02:45.271607  6929 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 07:02:45.271616  6929 net.cpp:165] Memory required for data: 14844520
I0526 07:02:45.271625  6929 layer_factory.hpp:77] Creating layer conv4
I0526 07:02:45.271642  6929 net.cpp:106] Creating Layer conv4
I0526 07:02:45.271653  6929 net.cpp:454] conv4 <- pool3
I0526 07:02:45.271668  6929 net.cpp:411] conv4 -> conv4
I0526 07:02:45.273725  6929 net.cpp:150] Setting up conv4
I0526 07:02:45.273748  6929 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:02:45.273758  6929 net.cpp:165] Memory required for data: 15207400
I0526 07:02:45.273777  6929 layer_factory.hpp:77] Creating layer relu4
I0526 07:02:45.273790  6929 net.cpp:106] Creating Layer relu4
I0526 07:02:45.273800  6929 net.cpp:454] relu4 <- conv4
I0526 07:02:45.273813  6929 net.cpp:397] relu4 -> conv4 (in-place)
I0526 07:02:45.274278  6929 net.cpp:150] Setting up relu4
I0526 07:02:45.274294  6929 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 07:02:45.274304  6929 net.cpp:165] Memory required for data: 15570280
I0526 07:02:45.274314  6929 layer_factory.hpp:77] Creating layer pool4
I0526 07:02:45.274328  6929 net.cpp:106] Creating Layer pool4
I0526 07:02:45.274338  6929 net.cpp:454] pool4 <- conv4
I0526 07:02:45.274350  6929 net.cpp:411] pool4 -> pool4
I0526 07:02:45.274422  6929 net.cpp:150] Setting up pool4
I0526 07:02:45.274435  6929 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 07:02:45.274446  6929 net.cpp:165] Memory required for data: 15751720
I0526 07:02:45.274452  6929 layer_factory.hpp:77] Creating layer ip1
I0526 07:02:45.274468  6929 net.cpp:106] Creating Layer ip1
I0526 07:02:45.274478  6929 net.cpp:454] ip1 <- pool4
I0526 07:02:45.274492  6929 net.cpp:411] ip1 -> ip1
I0526 07:02:45.289883  6929 net.cpp:150] Setting up ip1
I0526 07:02:45.289912  6929 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:02:45.289924  6929 net.cpp:165] Memory required for data: 15759560
I0526 07:02:45.289950  6929 layer_factory.hpp:77] Creating layer relu5
I0526 07:02:45.289966  6929 net.cpp:106] Creating Layer relu5
I0526 07:02:45.289976  6929 net.cpp:454] relu5 <- ip1
I0526 07:02:45.289990  6929 net.cpp:397] relu5 -> ip1 (in-place)
I0526 07:02:45.290338  6929 net.cpp:150] Setting up relu5
I0526 07:02:45.290352  6929 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:02:45.290362  6929 net.cpp:165] Memory required for data: 15767400
I0526 07:02:45.290372  6929 layer_factory.hpp:77] Creating layer drop1
I0526 07:02:45.290390  6929 net.cpp:106] Creating Layer drop1
I0526 07:02:45.290401  6929 net.cpp:454] drop1 <- ip1
I0526 07:02:45.290415  6929 net.cpp:397] drop1 -> ip1 (in-place)
I0526 07:02:45.290458  6929 net.cpp:150] Setting up drop1
I0526 07:02:45.290472  6929 net.cpp:157] Top shape: 10 196 (1960)
I0526 07:02:45.290480  6929 net.cpp:165] Memory required for data: 15775240
I0526 07:02:45.290490  6929 layer_factory.hpp:77] Creating layer ip2
I0526 07:02:45.290505  6929 net.cpp:106] Creating Layer ip2
I0526 07:02:45.290516  6929 net.cpp:454] ip2 <- ip1
I0526 07:02:45.290529  6929 net.cpp:411] ip2 -> ip2
I0526 07:02:45.291010  6929 net.cpp:150] Setting up ip2
I0526 07:02:45.291023  6929 net.cpp:157] Top shape: 10 98 (980)
I0526 07:02:45.291033  6929 net.cpp:165] Memory required for data: 15779160
I0526 07:02:45.291049  6929 layer_factory.hpp:77] Creating layer relu6
I0526 07:02:45.291074  6929 net.cpp:106] Creating Layer relu6
I0526 07:02:45.291084  6929 net.cpp:454] relu6 <- ip2
I0526 07:02:45.291097  6929 net.cpp:397] relu6 -> ip2 (in-place)
I0526 07:02:45.291627  6929 net.cpp:150] Setting up relu6
I0526 07:02:45.291643  6929 net.cpp:157] Top shape: 10 98 (980)
I0526 07:02:45.291652  6929 net.cpp:165] Memory required for data: 15783080
I0526 07:02:45.291663  6929 layer_factory.hpp:77] Creating layer drop2
I0526 07:02:45.291676  6929 net.cpp:106] Creating Layer drop2
I0526 07:02:45.291687  6929 net.cpp:454] drop2 <- ip2
I0526 07:02:45.291699  6929 net.cpp:397] drop2 -> ip2 (in-place)
I0526 07:02:45.291743  6929 net.cpp:150] Setting up drop2
I0526 07:02:45.291756  6929 net.cpp:157] Top shape: 10 98 (980)
I0526 07:02:45.291765  6929 net.cpp:165] Memory required for data: 15787000
I0526 07:02:45.291775  6929 layer_factory.hpp:77] Creating layer ip3
I0526 07:02:45.291790  6929 net.cpp:106] Creating Layer ip3
I0526 07:02:45.291800  6929 net.cpp:454] ip3 <- ip2
I0526 07:02:45.291813  6929 net.cpp:411] ip3 -> ip3
I0526 07:02:45.292034  6929 net.cpp:150] Setting up ip3
I0526 07:02:45.292047  6929 net.cpp:157] Top shape: 10 11 (110)
I0526 07:02:45.292057  6929 net.cpp:165] Memory required for data: 15787440
I0526 07:02:45.292073  6929 layer_factory.hpp:77] Creating layer drop3
I0526 07:02:45.292100  6929 net.cpp:106] Creating Layer drop3
I0526 07:02:45.292110  6929 net.cpp:454] drop3 <- ip3
I0526 07:02:45.292124  6929 net.cpp:397] drop3 -> ip3 (in-place)
I0526 07:02:45.292165  6929 net.cpp:150] Setting up drop3
I0526 07:02:45.292177  6929 net.cpp:157] Top shape: 10 11 (110)
I0526 07:02:45.292187  6929 net.cpp:165] Memory required for data: 15787880
I0526 07:02:45.292197  6929 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 07:02:45.292210  6929 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 07:02:45.292220  6929 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 07:02:45.292234  6929 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 07:02:45.292249  6929 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 07:02:45.292322  6929 net.cpp:150] Setting up ip3_drop3_0_split
I0526 07:02:45.292335  6929 net.cpp:157] Top shape: 10 11 (110)
I0526 07:02:45.292348  6929 net.cpp:157] Top shape: 10 11 (110)
I0526 07:02:45.292358  6929 net.cpp:165] Memory required for data: 15788760
I0526 07:02:45.292368  6929 layer_factory.hpp:77] Creating layer accuracy
I0526 07:02:45.292389  6929 net.cpp:106] Creating Layer accuracy
I0526 07:02:45.292399  6929 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 07:02:45.292412  6929 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 07:02:45.292425  6929 net.cpp:411] accuracy -> accuracy
I0526 07:02:45.292450  6929 net.cpp:150] Setting up accuracy
I0526 07:02:45.292462  6929 net.cpp:157] Top shape: (1)
I0526 07:02:45.292472  6929 net.cpp:165] Memory required for data: 15788764
I0526 07:02:45.292482  6929 layer_factory.hpp:77] Creating layer loss
I0526 07:02:45.292496  6929 net.cpp:106] Creating Layer loss
I0526 07:02:45.292505  6929 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 07:02:45.292516  6929 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 07:02:45.292529  6929 net.cpp:411] loss -> loss
I0526 07:02:45.292547  6929 layer_factory.hpp:77] Creating layer loss
I0526 07:02:45.293028  6929 net.cpp:150] Setting up loss
I0526 07:02:45.293042  6929 net.cpp:157] Top shape: (1)
I0526 07:02:45.293052  6929 net.cpp:160]     with loss weight 1
I0526 07:02:45.293071  6929 net.cpp:165] Memory required for data: 15788768
I0526 07:02:45.293081  6929 net.cpp:226] loss needs backward computation.
I0526 07:02:45.293092  6929 net.cpp:228] accuracy does not need backward computation.
I0526 07:02:45.293104  6929 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 07:02:45.293114  6929 net.cpp:226] drop3 needs backward computation.
I0526 07:02:45.293123  6929 net.cpp:226] ip3 needs backward computation.
I0526 07:02:45.293133  6929 net.cpp:226] drop2 needs backward computation.
I0526 07:02:45.293143  6929 net.cpp:226] relu6 needs backward computation.
I0526 07:02:45.293161  6929 net.cpp:226] ip2 needs backward computation.
I0526 07:02:45.293172  6929 net.cpp:226] drop1 needs backward computation.
I0526 07:02:45.293181  6929 net.cpp:226] relu5 needs backward computation.
I0526 07:02:45.293191  6929 net.cpp:226] ip1 needs backward computation.
I0526 07:02:45.293201  6929 net.cpp:226] pool4 needs backward computation.
I0526 07:02:45.293211  6929 net.cpp:226] relu4 needs backward computation.
I0526 07:02:45.293221  6929 net.cpp:226] conv4 needs backward computation.
I0526 07:02:45.293232  6929 net.cpp:226] pool3 needs backward computation.
I0526 07:02:45.293243  6929 net.cpp:226] relu3 needs backward computation.
I0526 07:02:45.293252  6929 net.cpp:226] conv3 needs backward computation.
I0526 07:02:45.293263  6929 net.cpp:226] pool2 needs backward computation.
I0526 07:02:45.293273  6929 net.cpp:226] relu2 needs backward computation.
I0526 07:02:45.293283  6929 net.cpp:226] conv2 needs backward computation.
I0526 07:02:45.293293  6929 net.cpp:226] pool1 needs backward computation.
I0526 07:02:45.293303  6929 net.cpp:226] relu1 needs backward computation.
I0526 07:02:45.293313  6929 net.cpp:226] conv1 needs backward computation.
I0526 07:02:45.293325  6929 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 07:02:45.293337  6929 net.cpp:228] data_hdf5 does not need backward computation.
I0526 07:02:45.293346  6929 net.cpp:270] This network produces output accuracy
I0526 07:02:45.293359  6929 net.cpp:270] This network produces output loss
I0526 07:02:45.293387  6929 net.cpp:283] Network initialization done.
I0526 07:02:45.293521  6929 solver.cpp:60] Solver scaffolding done.
I0526 07:02:45.294659  6929 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_450000.solverstate
I0526 07:02:45.513595  6929 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 07:02:45.519088  6929 caffe.cpp:212] Starting Optimization
I0526 07:02:45.519127  6929 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 07:02:45.519139  6929 solver.cpp:289] Learning Rate Policy: fixed
I0526 07:02:45.520354  6929 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 07:03:46.138918  6929 solver.cpp:409]     Test net output #0: accuracy = 0.879441
I0526 07:03:46.139073  6929 solver.cpp:409]     Test net output #1: loss = 0.396098 (* 1 = 0.396098 loss)
I0526 07:03:46.156823  6929 solver.cpp:237] Iteration 450000, loss = 1.04606
I0526 07:03:46.156859  6929 solver.cpp:253]     Train net output #0: loss = 1.04606 (* 1 = 1.04606 loss)
I0526 07:03:46.156877  6929 sgd_solver.cpp:106] Iteration 450000, lr = 0.003
I0526 07:04:02.928968  6929 solver.cpp:237] Iteration 451500, loss = 0.791043
I0526 07:04:02.929016  6929 solver.cpp:253]     Train net output #0: loss = 0.791042 (* 1 = 0.791042 loss)
I0526 07:04:02.929030  6929 sgd_solver.cpp:106] Iteration 451500, lr = 0.003
I0526 07:04:19.689162  6929 solver.cpp:237] Iteration 453000, loss = 1.15268
I0526 07:04:19.689321  6929 solver.cpp:253]     Train net output #0: loss = 1.15267 (* 1 = 1.15267 loss)
I0526 07:04:19.689337  6929 sgd_solver.cpp:106] Iteration 453000, lr = 0.003
I0526 07:04:36.521009  6929 solver.cpp:237] Iteration 454500, loss = 1.48017
I0526 07:04:36.521045  6929 solver.cpp:253]     Train net output #0: loss = 1.48016 (* 1 = 1.48016 loss)
I0526 07:04:36.521059  6929 sgd_solver.cpp:106] Iteration 454500, lr = 0.003
I0526 07:04:53.440044  6929 solver.cpp:237] Iteration 456000, loss = 0.714068
I0526 07:04:53.440196  6929 solver.cpp:253]     Train net output #0: loss = 0.714067 (* 1 = 0.714067 loss)
I0526 07:04:53.440212  6929 sgd_solver.cpp:106] Iteration 456000, lr = 0.003
I0526 07:05:10.249332  6929 solver.cpp:237] Iteration 457500, loss = 0.866859
I0526 07:05:10.249374  6929 solver.cpp:253]     Train net output #0: loss = 0.866857 (* 1 = 0.866857 loss)
I0526 07:05:10.249390  6929 sgd_solver.cpp:106] Iteration 457500, lr = 0.003
I0526 07:05:27.159893  6929 solver.cpp:237] Iteration 459000, loss = 1.60226
I0526 07:05:27.160027  6929 solver.cpp:253]     Train net output #0: loss = 1.60226 (* 1 = 1.60226 loss)
I0526 07:05:27.160040  6929 sgd_solver.cpp:106] Iteration 459000, lr = 0.003
I0526 07:06:06.278631  6929 solver.cpp:237] Iteration 460500, loss = 0.59902
I0526 07:06:06.278794  6929 solver.cpp:253]     Train net output #0: loss = 0.599019 (* 1 = 0.599019 loss)
I0526 07:06:06.278808  6929 sgd_solver.cpp:106] Iteration 460500, lr = 0.003
I0526 07:06:23.143872  6929 solver.cpp:237] Iteration 462000, loss = 0.648785
I0526 07:06:23.143908  6929 solver.cpp:253]     Train net output #0: loss = 0.648783 (* 1 = 0.648783 loss)
I0526 07:06:23.143924  6929 sgd_solver.cpp:106] Iteration 462000, lr = 0.003
I0526 07:06:39.973656  6929 solver.cpp:237] Iteration 463500, loss = 0.699704
I0526 07:06:39.973804  6929 solver.cpp:253]     Train net output #0: loss = 0.699703 (* 1 = 0.699703 loss)
I0526 07:06:39.973820  6929 sgd_solver.cpp:106] Iteration 463500, lr = 0.003
I0526 07:06:56.846627  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_465000.caffemodel
I0526 07:06:56.904992  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_465000.solverstate
I0526 07:06:56.945055  6929 solver.cpp:237] Iteration 465000, loss = 0.381197
I0526 07:06:56.945109  6929 solver.cpp:253]     Train net output #0: loss = 0.381195 (* 1 = 0.381195 loss)
I0526 07:06:56.945124  6929 sgd_solver.cpp:106] Iteration 465000, lr = 0.003
I0526 07:07:13.797734  6929 solver.cpp:237] Iteration 466500, loss = 1.02559
I0526 07:07:13.797894  6929 solver.cpp:253]     Train net output #0: loss = 1.02559 (* 1 = 1.02559 loss)
I0526 07:07:13.797909  6929 sgd_solver.cpp:106] Iteration 466500, lr = 0.003
I0526 07:07:30.664926  6929 solver.cpp:237] Iteration 468000, loss = 0.733834
I0526 07:07:30.664961  6929 solver.cpp:253]     Train net output #0: loss = 0.733833 (* 1 = 0.733833 loss)
I0526 07:07:30.664975  6929 sgd_solver.cpp:106] Iteration 468000, lr = 0.003
I0526 07:07:47.521967  6929 solver.cpp:237] Iteration 469500, loss = 1.36317
I0526 07:07:47.522132  6929 solver.cpp:253]     Train net output #0: loss = 1.36316 (* 1 = 1.36316 loss)
I0526 07:07:47.522148  6929 sgd_solver.cpp:106] Iteration 469500, lr = 0.003
I0526 07:08:26.653533  6929 solver.cpp:237] Iteration 471000, loss = 1.50587
I0526 07:08:26.653709  6929 solver.cpp:253]     Train net output #0: loss = 1.50587 (* 1 = 1.50587 loss)
I0526 07:08:26.653724  6929 sgd_solver.cpp:106] Iteration 471000, lr = 0.003
I0526 07:08:43.483247  6929 solver.cpp:237] Iteration 472500, loss = 0.848081
I0526 07:08:43.483290  6929 solver.cpp:253]     Train net output #0: loss = 0.84808 (* 1 = 0.84808 loss)
I0526 07:08:43.483306  6929 sgd_solver.cpp:106] Iteration 472500, lr = 0.003
I0526 07:09:00.343245  6929 solver.cpp:237] Iteration 474000, loss = 1.73431
I0526 07:09:00.343384  6929 solver.cpp:253]     Train net output #0: loss = 1.73431 (* 1 = 1.73431 loss)
I0526 07:09:00.343399  6929 sgd_solver.cpp:106] Iteration 474000, lr = 0.003
I0526 07:09:17.208858  6929 solver.cpp:237] Iteration 475500, loss = 0.904736
I0526 07:09:17.208894  6929 solver.cpp:253]     Train net output #0: loss = 0.904735 (* 1 = 0.904735 loss)
I0526 07:09:17.208909  6929 sgd_solver.cpp:106] Iteration 475500, lr = 0.003
I0526 07:09:34.093040  6929 solver.cpp:237] Iteration 477000, loss = 1.04881
I0526 07:09:34.093202  6929 solver.cpp:253]     Train net output #0: loss = 1.04881 (* 1 = 1.04881 loss)
I0526 07:09:34.093217  6929 sgd_solver.cpp:106] Iteration 477000, lr = 0.003
I0526 07:09:50.998636  6929 solver.cpp:237] Iteration 478500, loss = 1.29327
I0526 07:09:50.998677  6929 solver.cpp:253]     Train net output #0: loss = 1.29326 (* 1 = 1.29326 loss)
I0526 07:09:50.998690  6929 sgd_solver.cpp:106] Iteration 478500, lr = 0.003
I0526 07:10:07.887774  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_480000.caffemodel
I0526 07:10:07.948467  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_480000.solverstate
I0526 07:10:07.987197  6929 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 07:11:07.675699  6929 solver.cpp:409]     Test net output #0: accuracy = 0.890841
I0526 07:11:07.675853  6929 solver.cpp:409]     Test net output #1: loss = 0.341574 (* 1 = 0.341574 loss)
I0526 07:11:29.952394  6929 solver.cpp:237] Iteration 480000, loss = 0.968929
I0526 07:11:29.952445  6929 solver.cpp:253]     Train net output #0: loss = 0.968928 (* 1 = 0.968928 loss)
I0526 07:11:29.952461  6929 sgd_solver.cpp:106] Iteration 480000, lr = 0.003
I0526 07:11:46.585366  6929 solver.cpp:237] Iteration 481500, loss = 1.65087
I0526 07:11:46.585515  6929 solver.cpp:253]     Train net output #0: loss = 1.65087 (* 1 = 1.65087 loss)
I0526 07:11:46.585531  6929 sgd_solver.cpp:106] Iteration 481500, lr = 0.003
I0526 07:12:03.214371  6929 solver.cpp:237] Iteration 483000, loss = 1.30856
I0526 07:12:03.214414  6929 solver.cpp:253]     Train net output #0: loss = 1.30856 (* 1 = 1.30856 loss)
I0526 07:12:03.214428  6929 sgd_solver.cpp:106] Iteration 483000, lr = 0.003
I0526 07:12:19.812723  6929 solver.cpp:237] Iteration 484500, loss = 0.828892
I0526 07:12:19.812875  6929 solver.cpp:253]     Train net output #0: loss = 0.828892 (* 1 = 0.828892 loss)
I0526 07:12:19.812888  6929 sgd_solver.cpp:106] Iteration 484500, lr = 0.003
I0526 07:12:36.431291  6929 solver.cpp:237] Iteration 486000, loss = 1.27642
I0526 07:12:36.431327  6929 solver.cpp:253]     Train net output #0: loss = 1.27642 (* 1 = 1.27642 loss)
I0526 07:12:36.431341  6929 sgd_solver.cpp:106] Iteration 486000, lr = 0.003
I0526 07:12:53.046483  6929 solver.cpp:237] Iteration 487500, loss = 1.34225
I0526 07:12:53.046634  6929 solver.cpp:253]     Train net output #0: loss = 1.34225 (* 1 = 1.34225 loss)
I0526 07:12:53.046649  6929 sgd_solver.cpp:106] Iteration 487500, lr = 0.003
I0526 07:13:09.692296  6929 solver.cpp:237] Iteration 489000, loss = 1.26326
I0526 07:13:09.692343  6929 solver.cpp:253]     Train net output #0: loss = 1.26326 (* 1 = 1.26326 loss)
I0526 07:13:09.692358  6929 sgd_solver.cpp:106] Iteration 489000, lr = 0.003
I0526 07:13:48.559962  6929 solver.cpp:237] Iteration 490500, loss = 1.31291
I0526 07:13:48.560148  6929 solver.cpp:253]     Train net output #0: loss = 1.31291 (* 1 = 1.31291 loss)
I0526 07:13:48.560163  6929 sgd_solver.cpp:106] Iteration 490500, lr = 0.003
I0526 07:14:05.184397  6929 solver.cpp:237] Iteration 492000, loss = 0.998455
I0526 07:14:05.184447  6929 solver.cpp:253]     Train net output #0: loss = 0.998455 (* 1 = 0.998455 loss)
I0526 07:14:05.184461  6929 sgd_solver.cpp:106] Iteration 492000, lr = 0.003
I0526 07:14:21.795328  6929 solver.cpp:237] Iteration 493500, loss = 1.51129
I0526 07:14:21.795495  6929 solver.cpp:253]     Train net output #0: loss = 1.51129 (* 1 = 1.51129 loss)
I0526 07:14:21.795508  6929 sgd_solver.cpp:106] Iteration 493500, lr = 0.003
I0526 07:14:38.427994  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_495000.caffemodel
I0526 07:14:38.486583  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_495000.solverstate
I0526 07:14:38.527581  6929 solver.cpp:237] Iteration 495000, loss = 0.917296
I0526 07:14:38.527631  6929 solver.cpp:253]     Train net output #0: loss = 0.917295 (* 1 = 0.917295 loss)
I0526 07:14:38.527650  6929 sgd_solver.cpp:106] Iteration 495000, lr = 0.003
I0526 07:14:55.179242  6929 solver.cpp:237] Iteration 496500, loss = 1.44228
I0526 07:14:55.179399  6929 solver.cpp:253]     Train net output #0: loss = 1.44228 (* 1 = 1.44228 loss)
I0526 07:14:55.179414  6929 sgd_solver.cpp:106] Iteration 496500, lr = 0.003
I0526 07:15:11.799691  6929 solver.cpp:237] Iteration 498000, loss = 1.4602
I0526 07:15:11.799741  6929 solver.cpp:253]     Train net output #0: loss = 1.46019 (* 1 = 1.46019 loss)
I0526 07:15:11.799757  6929 sgd_solver.cpp:106] Iteration 498000, lr = 0.003
I0526 07:15:28.428815  6929 solver.cpp:237] Iteration 499500, loss = 0.762321
I0526 07:15:28.428958  6929 solver.cpp:253]     Train net output #0: loss = 0.76232 (* 1 = 0.76232 loss)
I0526 07:15:28.428973  6929 sgd_solver.cpp:106] Iteration 499500, lr = 0.003
I0526 07:16:07.250965  6929 solver.cpp:237] Iteration 501000, loss = 1.52339
I0526 07:16:07.251137  6929 solver.cpp:253]     Train net output #0: loss = 1.52339 (* 1 = 1.52339 loss)
I0526 07:16:07.251152  6929 sgd_solver.cpp:106] Iteration 501000, lr = 0.003
I0526 07:16:23.885710  6929 solver.cpp:237] Iteration 502500, loss = 1.2941
I0526 07:16:23.885759  6929 solver.cpp:253]     Train net output #0: loss = 1.2941 (* 1 = 1.2941 loss)
I0526 07:16:23.885772  6929 sgd_solver.cpp:106] Iteration 502500, lr = 0.003
I0526 07:16:40.527256  6929 solver.cpp:237] Iteration 504000, loss = 1.14964
I0526 07:16:40.527396  6929 solver.cpp:253]     Train net output #0: loss = 1.14964 (* 1 = 1.14964 loss)
I0526 07:16:40.527410  6929 sgd_solver.cpp:106] Iteration 504000, lr = 0.003
I0526 07:16:57.116650  6929 solver.cpp:237] Iteration 505500, loss = 1.37656
I0526 07:16:57.116698  6929 solver.cpp:253]     Train net output #0: loss = 1.37656 (* 1 = 1.37656 loss)
I0526 07:16:57.116710  6929 sgd_solver.cpp:106] Iteration 505500, lr = 0.003
I0526 07:17:13.753317  6929 solver.cpp:237] Iteration 507000, loss = 0.975785
I0526 07:17:13.753458  6929 solver.cpp:253]     Train net output #0: loss = 0.975782 (* 1 = 0.975782 loss)
I0526 07:17:13.753473  6929 sgd_solver.cpp:106] Iteration 507000, lr = 0.003
I0526 07:17:30.361349  6929 solver.cpp:237] Iteration 508500, loss = 1.4977
I0526 07:17:30.361385  6929 solver.cpp:253]     Train net output #0: loss = 1.4977 (* 1 = 1.4977 loss)
I0526 07:17:30.361398  6929 sgd_solver.cpp:106] Iteration 508500, lr = 0.003
I0526 07:17:46.972622  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_510000.caffemodel
I0526 07:17:47.028071  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_510000.solverstate
I0526 07:17:47.063493  6929 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 07:19:06.940294  6929 solver.cpp:409]     Test net output #0: accuracy = 0.889051
I0526 07:19:06.940454  6929 solver.cpp:409]     Test net output #1: loss = 0.36134 (* 1 = 0.36134 loss)
I0526 07:19:29.182384  6929 solver.cpp:237] Iteration 510000, loss = 1.0119
I0526 07:19:29.182435  6929 solver.cpp:253]     Train net output #0: loss = 1.01189 (* 1 = 1.01189 loss)
I0526 07:19:29.182451  6929 sgd_solver.cpp:106] Iteration 510000, lr = 0.003
I0526 07:19:45.934947  6929 solver.cpp:237] Iteration 511500, loss = 1.1702
I0526 07:19:45.935107  6929 solver.cpp:253]     Train net output #0: loss = 1.17019 (* 1 = 1.17019 loss)
I0526 07:19:45.935122  6929 sgd_solver.cpp:106] Iteration 511500, lr = 0.003
I0526 07:20:02.721544  6929 solver.cpp:237] Iteration 513000, loss = 1.01733
I0526 07:20:02.721580  6929 solver.cpp:253]     Train net output #0: loss = 1.01733 (* 1 = 1.01733 loss)
I0526 07:20:02.721595  6929 sgd_solver.cpp:106] Iteration 513000, lr = 0.003
I0526 07:20:19.514567  6929 solver.cpp:237] Iteration 514500, loss = 1.55891
I0526 07:20:19.514720  6929 solver.cpp:253]     Train net output #0: loss = 1.55891 (* 1 = 1.55891 loss)
I0526 07:20:19.514736  6929 sgd_solver.cpp:106] Iteration 514500, lr = 0.003
I0526 07:20:36.309995  6929 solver.cpp:237] Iteration 516000, loss = 1.12532
I0526 07:20:36.310037  6929 solver.cpp:253]     Train net output #0: loss = 1.12532 (* 1 = 1.12532 loss)
I0526 07:20:36.310051  6929 sgd_solver.cpp:106] Iteration 516000, lr = 0.003
I0526 07:20:53.107385  6929 solver.cpp:237] Iteration 517500, loss = 1.80383
I0526 07:20:53.107525  6929 solver.cpp:253]     Train net output #0: loss = 1.80382 (* 1 = 1.80382 loss)
I0526 07:20:53.107540  6929 sgd_solver.cpp:106] Iteration 517500, lr = 0.003
I0526 07:21:09.926777  6929 solver.cpp:237] Iteration 519000, loss = 0.881591
I0526 07:21:09.926825  6929 solver.cpp:253]     Train net output #0: loss = 0.881587 (* 1 = 0.881587 loss)
I0526 07:21:09.926838  6929 sgd_solver.cpp:106] Iteration 519000, lr = 0.003
I0526 07:21:48.912478  6929 solver.cpp:237] Iteration 520500, loss = 1.18685
I0526 07:21:48.912642  6929 solver.cpp:253]     Train net output #0: loss = 1.18685 (* 1 = 1.18685 loss)
I0526 07:21:48.912655  6929 sgd_solver.cpp:106] Iteration 520500, lr = 0.003
I0526 07:22:05.675082  6929 solver.cpp:237] Iteration 522000, loss = 0.812188
I0526 07:22:05.675119  6929 solver.cpp:253]     Train net output #0: loss = 0.812186 (* 1 = 0.812186 loss)
I0526 07:22:05.675133  6929 sgd_solver.cpp:106] Iteration 522000, lr = 0.003
I0526 07:22:22.445705  6929 solver.cpp:237] Iteration 523500, loss = 1.33535
I0526 07:22:22.445858  6929 solver.cpp:253]     Train net output #0: loss = 1.33535 (* 1 = 1.33535 loss)
I0526 07:22:22.445873  6929 sgd_solver.cpp:106] Iteration 523500, lr = 0.003
I0526 07:22:39.179945  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_525000.caffemodel
I0526 07:22:39.236443  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_525000.solverstate
I0526 07:22:39.279335  6929 solver.cpp:237] Iteration 525000, loss = 1.35016
I0526 07:22:39.279384  6929 solver.cpp:253]     Train net output #0: loss = 1.35016 (* 1 = 1.35016 loss)
I0526 07:22:39.279399  6929 sgd_solver.cpp:106] Iteration 525000, lr = 0.003
I0526 07:22:56.063591  6929 solver.cpp:237] Iteration 526500, loss = 1.78203
I0526 07:22:56.063736  6929 solver.cpp:253]     Train net output #0: loss = 1.78203 (* 1 = 1.78203 loss)
I0526 07:22:56.063750  6929 sgd_solver.cpp:106] Iteration 526500, lr = 0.003
I0526 07:23:12.981935  6929 solver.cpp:237] Iteration 528000, loss = 1.00533
I0526 07:23:12.981986  6929 solver.cpp:253]     Train net output #0: loss = 1.00533 (* 1 = 1.00533 loss)
I0526 07:23:12.981999  6929 sgd_solver.cpp:106] Iteration 528000, lr = 0.003
I0526 07:23:30.054319  6929 solver.cpp:237] Iteration 529500, loss = 1.12264
I0526 07:23:30.054489  6929 solver.cpp:253]     Train net output #0: loss = 1.12264 (* 1 = 1.12264 loss)
I0526 07:23:30.054504  6929 sgd_solver.cpp:106] Iteration 529500, lr = 0.003
I0526 07:24:09.348191  6929 solver.cpp:237] Iteration 531000, loss = 1.00575
I0526 07:24:09.348359  6929 solver.cpp:253]     Train net output #0: loss = 1.00574 (* 1 = 1.00574 loss)
I0526 07:24:09.348373  6929 sgd_solver.cpp:106] Iteration 531000, lr = 0.003
I0526 07:24:26.422694  6929 solver.cpp:237] Iteration 532500, loss = 1.46503
I0526 07:24:26.422742  6929 solver.cpp:253]     Train net output #0: loss = 1.46502 (* 1 = 1.46502 loss)
I0526 07:24:26.422758  6929 sgd_solver.cpp:106] Iteration 532500, lr = 0.003
I0526 07:24:43.480823  6929 solver.cpp:237] Iteration 534000, loss = 1.03465
I0526 07:24:43.480958  6929 solver.cpp:253]     Train net output #0: loss = 1.03464 (* 1 = 1.03464 loss)
I0526 07:24:43.480973  6929 sgd_solver.cpp:106] Iteration 534000, lr = 0.003
I0526 07:25:00.547037  6929 solver.cpp:237] Iteration 535500, loss = 1.34612
I0526 07:25:00.547073  6929 solver.cpp:253]     Train net output #0: loss = 1.34612 (* 1 = 1.34612 loss)
I0526 07:25:00.547087  6929 sgd_solver.cpp:106] Iteration 535500, lr = 0.003
I0526 07:25:17.603476  6929 solver.cpp:237] Iteration 537000, loss = 1.61147
I0526 07:25:17.603643  6929 solver.cpp:253]     Train net output #0: loss = 1.61147 (* 1 = 1.61147 loss)
I0526 07:25:17.603657  6929 sgd_solver.cpp:106] Iteration 537000, lr = 0.003
I0526 07:25:34.687628  6929 solver.cpp:237] Iteration 538500, loss = 0.770951
I0526 07:25:34.687670  6929 solver.cpp:253]     Train net output #0: loss = 0.77095 (* 1 = 0.77095 loss)
I0526 07:25:34.687685  6929 sgd_solver.cpp:106] Iteration 538500, lr = 0.003
I0526 07:25:51.758697  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_540000.caffemodel
I0526 07:25:51.804805  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_540000.solverstate
I0526 07:25:51.830796  6929 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 07:26:50.952551  6929 solver.cpp:409]     Test net output #0: accuracy = 0.896756
I0526 07:26:50.952711  6929 solver.cpp:409]     Test net output #1: loss = 0.343464 (* 1 = 0.343464 loss)
I0526 07:27:13.172540  6929 solver.cpp:237] Iteration 540000, loss = 1.26573
I0526 07:27:13.172593  6929 solver.cpp:253]     Train net output #0: loss = 1.26573 (* 1 = 1.26573 loss)
I0526 07:27:13.172608  6929 sgd_solver.cpp:106] Iteration 540000, lr = 0.003
I0526 07:27:29.795734  6929 solver.cpp:237] Iteration 541500, loss = 0.885567
I0526 07:27:29.795902  6929 solver.cpp:253]     Train net output #0: loss = 0.885564 (* 1 = 0.885564 loss)
I0526 07:27:29.795915  6929 sgd_solver.cpp:106] Iteration 541500, lr = 0.003
I0526 07:27:46.433043  6929 solver.cpp:237] Iteration 543000, loss = 1.46229
I0526 07:27:46.433085  6929 solver.cpp:253]     Train net output #0: loss = 1.46229 (* 1 = 1.46229 loss)
I0526 07:27:46.433099  6929 sgd_solver.cpp:106] Iteration 543000, lr = 0.003
I0526 07:28:03.075712  6929 solver.cpp:237] Iteration 544500, loss = 1.0963
I0526 07:28:03.075850  6929 solver.cpp:253]     Train net output #0: loss = 1.0963 (* 1 = 1.0963 loss)
I0526 07:28:03.075863  6929 sgd_solver.cpp:106] Iteration 544500, lr = 0.003
I0526 07:28:19.687258  6929 solver.cpp:237] Iteration 546000, loss = 1.43033
I0526 07:28:19.687304  6929 solver.cpp:253]     Train net output #0: loss = 1.43033 (* 1 = 1.43033 loss)
I0526 07:28:19.687320  6929 sgd_solver.cpp:106] Iteration 546000, lr = 0.003
I0526 07:28:36.320396  6929 solver.cpp:237] Iteration 547500, loss = 0.994792
I0526 07:28:36.320569  6929 solver.cpp:253]     Train net output #0: loss = 0.994788 (* 1 = 0.994788 loss)
I0526 07:28:36.320583  6929 sgd_solver.cpp:106] Iteration 547500, lr = 0.003
I0526 07:28:52.963124  6929 solver.cpp:237] Iteration 549000, loss = 0.910996
I0526 07:28:52.963160  6929 solver.cpp:253]     Train net output #0: loss = 0.910992 (* 1 = 0.910992 loss)
I0526 07:28:52.963173  6929 sgd_solver.cpp:106] Iteration 549000, lr = 0.003
I0526 07:29:31.765892  6929 solver.cpp:237] Iteration 550500, loss = 1.54064
I0526 07:29:31.766065  6929 solver.cpp:253]     Train net output #0: loss = 1.54064 (* 1 = 1.54064 loss)
I0526 07:29:31.766082  6929 sgd_solver.cpp:106] Iteration 550500, lr = 0.003
I0526 07:29:48.416437  6929 solver.cpp:237] Iteration 552000, loss = 0.798866
I0526 07:29:48.416482  6929 solver.cpp:253]     Train net output #0: loss = 0.798863 (* 1 = 0.798863 loss)
I0526 07:29:48.416501  6929 sgd_solver.cpp:106] Iteration 552000, lr = 0.003
I0526 07:30:05.070690  6929 solver.cpp:237] Iteration 553500, loss = 0.614148
I0526 07:30:05.070832  6929 solver.cpp:253]     Train net output #0: loss = 0.614145 (* 1 = 0.614145 loss)
I0526 07:30:05.070847  6929 sgd_solver.cpp:106] Iteration 553500, lr = 0.003
I0526 07:30:21.694509  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_555000.caffemodel
I0526 07:30:21.745872  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_555000.solverstate
I0526 07:30:21.774292  6929 solver.cpp:237] Iteration 555000, loss = 1.28394
I0526 07:30:21.774334  6929 solver.cpp:253]     Train net output #0: loss = 1.28393 (* 1 = 1.28393 loss)
I0526 07:30:21.774348  6929 sgd_solver.cpp:106] Iteration 555000, lr = 0.003
I0526 07:30:38.422353  6929 solver.cpp:237] Iteration 556500, loss = 1.16214
I0526 07:30:38.422515  6929 solver.cpp:253]     Train net output #0: loss = 1.16213 (* 1 = 1.16213 loss)
I0526 07:30:38.422530  6929 sgd_solver.cpp:106] Iteration 556500, lr = 0.003
I0526 07:30:55.062522  6929 solver.cpp:237] Iteration 558000, loss = 0.932046
I0526 07:30:55.062558  6929 solver.cpp:253]     Train net output #0: loss = 0.932043 (* 1 = 0.932043 loss)
I0526 07:30:55.062575  6929 sgd_solver.cpp:106] Iteration 558000, lr = 0.003
I0526 07:31:11.708050  6929 solver.cpp:237] Iteration 559500, loss = 0.756382
I0526 07:31:11.708205  6929 solver.cpp:253]     Train net output #0: loss = 0.756379 (* 1 = 0.756379 loss)
I0526 07:31:11.708221  6929 sgd_solver.cpp:106] Iteration 559500, lr = 0.003
I0526 07:31:50.582156  6929 solver.cpp:237] Iteration 561000, loss = 1.47955
I0526 07:31:50.582326  6929 solver.cpp:253]     Train net output #0: loss = 1.47954 (* 1 = 1.47954 loss)
I0526 07:31:50.582340  6929 sgd_solver.cpp:106] Iteration 561000, lr = 0.003
I0526 07:32:07.228842  6929 solver.cpp:237] Iteration 562500, loss = 2.16286
I0526 07:32:07.228876  6929 solver.cpp:253]     Train net output #0: loss = 2.16286 (* 1 = 2.16286 loss)
I0526 07:32:07.228894  6929 sgd_solver.cpp:106] Iteration 562500, lr = 0.003
I0526 07:32:23.848305  6929 solver.cpp:237] Iteration 564000, loss = 2.27446
I0526 07:32:23.848461  6929 solver.cpp:253]     Train net output #0: loss = 2.27446 (* 1 = 2.27446 loss)
I0526 07:32:23.848476  6929 sgd_solver.cpp:106] Iteration 564000, lr = 0.003
I0526 07:32:40.493697  6929 solver.cpp:237] Iteration 565500, loss = 0.682992
I0526 07:32:40.493747  6929 solver.cpp:253]     Train net output #0: loss = 0.682988 (* 1 = 0.682988 loss)
I0526 07:32:40.493762  6929 sgd_solver.cpp:106] Iteration 565500, lr = 0.003
I0526 07:32:57.148810  6929 solver.cpp:237] Iteration 567000, loss = 0.596347
I0526 07:32:57.148954  6929 solver.cpp:253]     Train net output #0: loss = 0.596345 (* 1 = 0.596345 loss)
I0526 07:32:57.148968  6929 sgd_solver.cpp:106] Iteration 567000, lr = 0.003
I0526 07:33:13.792103  6929 solver.cpp:237] Iteration 568500, loss = 1.32086
I0526 07:33:13.792147  6929 solver.cpp:253]     Train net output #0: loss = 1.32086 (* 1 = 1.32086 loss)
I0526 07:33:13.792160  6929 sgd_solver.cpp:106] Iteration 568500, lr = 0.003
I0526 07:33:30.438422  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_570000.caffemodel
I0526 07:33:30.484001  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_570000.solverstate
I0526 07:33:30.509377  6929 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 07:34:50.922000  6929 solver.cpp:409]     Test net output #0: accuracy = 0.89355
I0526 07:34:50.922164  6929 solver.cpp:409]     Test net output #1: loss = 0.327984 (* 1 = 0.327984 loss)
I0526 07:35:13.097087  6929 solver.cpp:237] Iteration 570000, loss = 1.91748
I0526 07:35:13.097141  6929 solver.cpp:253]     Train net output #0: loss = 1.91747 (* 1 = 1.91747 loss)
I0526 07:35:13.097157  6929 sgd_solver.cpp:106] Iteration 570000, lr = 0.003
I0526 07:35:29.952441  6929 solver.cpp:237] Iteration 571500, loss = 0.772372
I0526 07:35:29.952597  6929 solver.cpp:253]     Train net output #0: loss = 0.772368 (* 1 = 0.772368 loss)
I0526 07:35:29.952612  6929 sgd_solver.cpp:106] Iteration 571500, lr = 0.003
I0526 07:35:47.081920  6929 solver.cpp:237] Iteration 573000, loss = 1.43762
I0526 07:35:47.081962  6929 solver.cpp:253]     Train net output #0: loss = 1.43762 (* 1 = 1.43762 loss)
I0526 07:35:47.081981  6929 sgd_solver.cpp:106] Iteration 573000, lr = 0.003
I0526 07:36:04.332738  6929 solver.cpp:237] Iteration 574500, loss = 1.12442
I0526 07:36:04.332898  6929 solver.cpp:253]     Train net output #0: loss = 1.12442 (* 1 = 1.12442 loss)
I0526 07:36:04.332912  6929 sgd_solver.cpp:106] Iteration 574500, lr = 0.003
I0526 07:36:21.515868  6929 solver.cpp:237] Iteration 576000, loss = 1.02589
I0526 07:36:21.515904  6929 solver.cpp:253]     Train net output #0: loss = 1.02588 (* 1 = 1.02588 loss)
I0526 07:36:21.515918  6929 sgd_solver.cpp:106] Iteration 576000, lr = 0.003
I0526 07:36:38.728301  6929 solver.cpp:237] Iteration 577500, loss = 0.898202
I0526 07:36:38.728454  6929 solver.cpp:253]     Train net output #0: loss = 0.898198 (* 1 = 0.898198 loss)
I0526 07:36:38.728469  6929 sgd_solver.cpp:106] Iteration 577500, lr = 0.003
I0526 07:36:55.923636  6929 solver.cpp:237] Iteration 579000, loss = 0.896207
I0526 07:36:55.923681  6929 solver.cpp:253]     Train net output #0: loss = 0.896203 (* 1 = 0.896203 loss)
I0526 07:36:55.923694  6929 sgd_solver.cpp:106] Iteration 579000, lr = 0.003
I0526 07:37:35.308379  6929 solver.cpp:237] Iteration 580500, loss = 0.799084
I0526 07:37:35.308550  6929 solver.cpp:253]     Train net output #0: loss = 0.79908 (* 1 = 0.79908 loss)
I0526 07:37:35.308568  6929 sgd_solver.cpp:106] Iteration 580500, lr = 0.003
I0526 07:37:52.529108  6929 solver.cpp:237] Iteration 582000, loss = 1.03455
I0526 07:37:52.529153  6929 solver.cpp:253]     Train net output #0: loss = 1.03455 (* 1 = 1.03455 loss)
I0526 07:37:52.529167  6929 sgd_solver.cpp:106] Iteration 582000, lr = 0.003
I0526 07:38:09.728569  6929 solver.cpp:237] Iteration 583500, loss = 1.06381
I0526 07:38:09.728721  6929 solver.cpp:253]     Train net output #0: loss = 1.06381 (* 1 = 1.06381 loss)
I0526 07:38:09.728735  6929 sgd_solver.cpp:106] Iteration 583500, lr = 0.003
I0526 07:38:26.924090  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_585000.caffemodel
I0526 07:38:26.972796  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_585000.solverstate
I0526 07:38:27.003684  6929 solver.cpp:237] Iteration 585000, loss = 2.32272
I0526 07:38:27.003734  6929 solver.cpp:253]     Train net output #0: loss = 2.32271 (* 1 = 2.32271 loss)
I0526 07:38:27.003749  6929 sgd_solver.cpp:106] Iteration 585000, lr = 0.003
I0526 07:38:44.213678  6929 solver.cpp:237] Iteration 586500, loss = 0.972783
I0526 07:38:44.213853  6929 solver.cpp:253]     Train net output #0: loss = 0.97278 (* 1 = 0.97278 loss)
I0526 07:38:44.213870  6929 sgd_solver.cpp:106] Iteration 586500, lr = 0.003
I0526 07:39:01.433217  6929 solver.cpp:237] Iteration 588000, loss = 4.13855
I0526 07:39:01.433264  6929 solver.cpp:253]     Train net output #0: loss = 4.13855 (* 1 = 4.13855 loss)
I0526 07:39:01.433279  6929 sgd_solver.cpp:106] Iteration 588000, lr = 0.003
I0526 07:39:18.643311  6929 solver.cpp:237] Iteration 589500, loss = 1.07721
I0526 07:39:18.643472  6929 solver.cpp:253]     Train net output #0: loss = 1.07721 (* 1 = 1.07721 loss)
I0526 07:39:18.643486  6929 sgd_solver.cpp:106] Iteration 589500, lr = 0.003
I0526 07:39:58.106137  6929 solver.cpp:237] Iteration 591000, loss = 0.685025
I0526 07:39:58.106308  6929 solver.cpp:253]     Train net output #0: loss = 0.685022 (* 1 = 0.685022 loss)
I0526 07:39:58.106324  6929 sgd_solver.cpp:106] Iteration 591000, lr = 0.003
I0526 07:40:15.335685  6929 solver.cpp:237] Iteration 592500, loss = 1.14066
I0526 07:40:15.335731  6929 solver.cpp:253]     Train net output #0: loss = 1.14066 (* 1 = 1.14066 loss)
I0526 07:40:15.335746  6929 sgd_solver.cpp:106] Iteration 592500, lr = 0.003
I0526 07:40:32.510313  6929 solver.cpp:237] Iteration 594000, loss = 0.997283
I0526 07:40:32.510460  6929 solver.cpp:253]     Train net output #0: loss = 0.997278 (* 1 = 0.997278 loss)
I0526 07:40:32.510475  6929 sgd_solver.cpp:106] Iteration 594000, lr = 0.003
I0526 07:40:49.453680  6929 solver.cpp:237] Iteration 595500, loss = 0.710603
I0526 07:40:49.453728  6929 solver.cpp:253]     Train net output #0: loss = 0.710599 (* 1 = 0.710599 loss)
I0526 07:40:49.453742  6929 sgd_solver.cpp:106] Iteration 595500, lr = 0.003
I0526 07:41:06.393832  6929 solver.cpp:237] Iteration 597000, loss = 0.889554
I0526 07:41:06.394008  6929 solver.cpp:253]     Train net output #0: loss = 0.88955 (* 1 = 0.88955 loss)
I0526 07:41:06.394023  6929 sgd_solver.cpp:106] Iteration 597000, lr = 0.003
I0526 07:41:23.342762  6929 solver.cpp:237] Iteration 598500, loss = 0.731287
I0526 07:41:23.342799  6929 solver.cpp:253]     Train net output #0: loss = 0.731284 (* 1 = 0.731284 loss)
I0526 07:41:23.342813  6929 sgd_solver.cpp:106] Iteration 598500, lr = 0.003
I0526 07:41:40.285053  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_600000.caffemodel
I0526 07:41:40.333744  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_600000.solverstate
I0526 07:41:40.361573  6929 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 07:42:39.683135  6929 solver.cpp:409]     Test net output #0: accuracy = 0.895531
I0526 07:42:39.683298  6929 solver.cpp:409]     Test net output #1: loss = 0.344447 (* 1 = 0.344447 loss)
I0526 07:43:00.570189  6929 solver.cpp:237] Iteration 600000, loss = 0.646751
I0526 07:43:00.570243  6929 solver.cpp:253]     Train net output #0: loss = 0.646747 (* 1 = 0.646747 loss)
I0526 07:43:00.570258  6929 sgd_solver.cpp:106] Iteration 600000, lr = 0.003
I0526 07:43:17.438673  6929 solver.cpp:237] Iteration 601500, loss = 1.07127
I0526 07:43:17.438834  6929 solver.cpp:253]     Train net output #0: loss = 1.07127 (* 1 = 1.07127 loss)
I0526 07:43:17.438849  6929 sgd_solver.cpp:106] Iteration 601500, lr = 0.003
I0526 07:43:34.344722  6929 solver.cpp:237] Iteration 603000, loss = 1.75004
I0526 07:43:34.344763  6929 solver.cpp:253]     Train net output #0: loss = 1.75003 (* 1 = 1.75003 loss)
I0526 07:43:34.344779  6929 sgd_solver.cpp:106] Iteration 603000, lr = 0.003
I0526 07:43:51.174448  6929 solver.cpp:237] Iteration 604500, loss = 1.62185
I0526 07:43:51.174605  6929 solver.cpp:253]     Train net output #0: loss = 1.62185 (* 1 = 1.62185 loss)
I0526 07:43:51.174620  6929 sgd_solver.cpp:106] Iteration 604500, lr = 0.003
I0526 07:44:08.078141  6929 solver.cpp:237] Iteration 606000, loss = 0.794386
I0526 07:44:08.078191  6929 solver.cpp:253]     Train net output #0: loss = 0.794383 (* 1 = 0.794383 loss)
I0526 07:44:08.078205  6929 sgd_solver.cpp:106] Iteration 606000, lr = 0.003
I0526 07:44:24.736016  6929 solver.cpp:237] Iteration 607500, loss = 0.916413
I0526 07:44:24.736179  6929 solver.cpp:253]     Train net output #0: loss = 0.91641 (* 1 = 0.91641 loss)
I0526 07:44:24.736194  6929 sgd_solver.cpp:106] Iteration 607500, lr = 0.003
I0526 07:44:41.380307  6929 solver.cpp:237] Iteration 609000, loss = 1.03892
I0526 07:44:41.380342  6929 solver.cpp:253]     Train net output #0: loss = 1.03892 (* 1 = 1.03892 loss)
I0526 07:44:41.380357  6929 sgd_solver.cpp:106] Iteration 609000, lr = 0.003
I0526 07:45:18.889067  6929 solver.cpp:237] Iteration 610500, loss = 0.708314
I0526 07:45:18.889246  6929 solver.cpp:253]     Train net output #0: loss = 0.708311 (* 1 = 0.708311 loss)
I0526 07:45:18.889261  6929 sgd_solver.cpp:106] Iteration 610500, lr = 0.003
I0526 07:45:35.496906  6929 solver.cpp:237] Iteration 612000, loss = 1.08645
I0526 07:45:35.496953  6929 solver.cpp:253]     Train net output #0: loss = 1.08645 (* 1 = 1.08645 loss)
I0526 07:45:35.496966  6929 sgd_solver.cpp:106] Iteration 612000, lr = 0.003
I0526 07:45:52.127364  6929 solver.cpp:237] Iteration 613500, loss = 1.09017
I0526 07:45:52.127512  6929 solver.cpp:253]     Train net output #0: loss = 1.09017 (* 1 = 1.09017 loss)
I0526 07:45:52.127526  6929 sgd_solver.cpp:106] Iteration 613500, lr = 0.003
I0526 07:46:08.772750  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_615000.caffemodel
I0526 07:46:08.819715  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_615000.solverstate
I0526 07:46:08.848027  6929 solver.cpp:237] Iteration 615000, loss = 1.29013
I0526 07:46:08.848073  6929 solver.cpp:253]     Train net output #0: loss = 1.29013 (* 1 = 1.29013 loss)
I0526 07:46:08.848100  6929 sgd_solver.cpp:106] Iteration 615000, lr = 0.003
I0526 07:46:25.519623  6929 solver.cpp:237] Iteration 616500, loss = 1.00478
I0526 07:46:25.519793  6929 solver.cpp:253]     Train net output #0: loss = 1.00478 (* 1 = 1.00478 loss)
I0526 07:46:25.519809  6929 sgd_solver.cpp:106] Iteration 616500, lr = 0.003
I0526 07:46:42.452492  6929 solver.cpp:237] Iteration 618000, loss = 1.1675
I0526 07:46:42.452527  6929 solver.cpp:253]     Train net output #0: loss = 1.1675 (* 1 = 1.1675 loss)
I0526 07:46:42.452543  6929 sgd_solver.cpp:106] Iteration 618000, lr = 0.003
I0526 07:46:59.408962  6929 solver.cpp:237] Iteration 619500, loss = 0.962251
I0526 07:46:59.409123  6929 solver.cpp:253]     Train net output #0: loss = 0.962249 (* 1 = 0.962249 loss)
I0526 07:46:59.409139  6929 sgd_solver.cpp:106] Iteration 619500, lr = 0.003
I0526 07:47:37.276818  6929 solver.cpp:237] Iteration 621000, loss = 1.72221
I0526 07:47:37.276988  6929 solver.cpp:253]     Train net output #0: loss = 1.72221 (* 1 = 1.72221 loss)
I0526 07:47:37.277003  6929 sgd_solver.cpp:106] Iteration 621000, lr = 0.003
I0526 07:47:54.234882  6929 solver.cpp:237] Iteration 622500, loss = 0.993855
I0526 07:47:54.234931  6929 solver.cpp:253]     Train net output #0: loss = 0.993853 (* 1 = 0.993853 loss)
I0526 07:47:54.234946  6929 sgd_solver.cpp:106] Iteration 622500, lr = 0.003
I0526 07:48:11.204035  6929 solver.cpp:237] Iteration 624000, loss = 1.15849
I0526 07:48:11.204197  6929 solver.cpp:253]     Train net output #0: loss = 1.15848 (* 1 = 1.15848 loss)
I0526 07:48:11.204211  6929 sgd_solver.cpp:106] Iteration 624000, lr = 0.003
I0526 07:48:28.130697  6929 solver.cpp:237] Iteration 625500, loss = 0.999433
I0526 07:48:28.130733  6929 solver.cpp:253]     Train net output #0: loss = 0.999431 (* 1 = 0.999431 loss)
I0526 07:48:28.130748  6929 sgd_solver.cpp:106] Iteration 625500, lr = 0.003
I0526 07:48:45.082453  6929 solver.cpp:237] Iteration 627000, loss = 1.09684
I0526 07:48:45.082623  6929 solver.cpp:253]     Train net output #0: loss = 1.09684 (* 1 = 1.09684 loss)
I0526 07:48:45.082638  6929 sgd_solver.cpp:106] Iteration 627000, lr = 0.003
I0526 07:49:02.031349  6929 solver.cpp:237] Iteration 628500, loss = 1.83784
I0526 07:49:02.031396  6929 solver.cpp:253]     Train net output #0: loss = 1.83784 (* 1 = 1.83784 loss)
I0526 07:49:02.031411  6929 sgd_solver.cpp:106] Iteration 628500, lr = 0.003
I0526 07:49:18.966610  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_630000.caffemodel
I0526 07:49:19.012971  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_630000.solverstate
I0526 07:49:19.038502  6929 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 07:50:39.257195  6929 solver.cpp:409]     Test net output #0: accuracy = 0.89919
I0526 07:50:39.257360  6929 solver.cpp:409]     Test net output #1: loss = 0.331352 (* 1 = 0.331352 loss)
I0526 07:51:00.119079  6929 solver.cpp:237] Iteration 630000, loss = 0.734354
I0526 07:51:00.119133  6929 solver.cpp:253]     Train net output #0: loss = 0.734352 (* 1 = 0.734352 loss)
I0526 07:51:00.119149  6929 sgd_solver.cpp:106] Iteration 630000, lr = 0.003
I0526 07:51:16.758998  6929 solver.cpp:237] Iteration 631500, loss = 1.23601
I0526 07:51:16.759153  6929 solver.cpp:253]     Train net output #0: loss = 1.23601 (* 1 = 1.23601 loss)
I0526 07:51:16.759168  6929 sgd_solver.cpp:106] Iteration 631500, lr = 0.003
I0526 07:51:33.394521  6929 solver.cpp:237] Iteration 633000, loss = 0.964069
I0526 07:51:33.394570  6929 solver.cpp:253]     Train net output #0: loss = 0.964066 (* 1 = 0.964066 loss)
I0526 07:51:33.394584  6929 sgd_solver.cpp:106] Iteration 633000, lr = 0.003
I0526 07:51:50.036667  6929 solver.cpp:237] Iteration 634500, loss = 1.23129
I0526 07:51:50.036829  6929 solver.cpp:253]     Train net output #0: loss = 1.23129 (* 1 = 1.23129 loss)
I0526 07:51:50.036844  6929 sgd_solver.cpp:106] Iteration 634500, lr = 0.003
I0526 07:52:06.671032  6929 solver.cpp:237] Iteration 636000, loss = 1.45271
I0526 07:52:06.671068  6929 solver.cpp:253]     Train net output #0: loss = 1.4527 (* 1 = 1.4527 loss)
I0526 07:52:06.671082  6929 sgd_solver.cpp:106] Iteration 636000, lr = 0.003
I0526 07:52:23.277401  6929 solver.cpp:237] Iteration 637500, loss = 1.18245
I0526 07:52:23.277559  6929 solver.cpp:253]     Train net output #0: loss = 1.18244 (* 1 = 1.18244 loss)
I0526 07:52:23.277575  6929 sgd_solver.cpp:106] Iteration 637500, lr = 0.003
I0526 07:52:39.931475  6929 solver.cpp:237] Iteration 639000, loss = 0.96058
I0526 07:52:39.931525  6929 solver.cpp:253]     Train net output #0: loss = 0.960575 (* 1 = 0.960575 loss)
I0526 07:52:39.931540  6929 sgd_solver.cpp:106] Iteration 639000, lr = 0.003
I0526 07:53:17.448168  6929 solver.cpp:237] Iteration 640500, loss = 1.0361
I0526 07:53:17.448339  6929 solver.cpp:253]     Train net output #0: loss = 1.0361 (* 1 = 1.0361 loss)
I0526 07:53:17.448355  6929 sgd_solver.cpp:106] Iteration 640500, lr = 0.003
I0526 07:53:34.132580  6929 solver.cpp:237] Iteration 642000, loss = 1.37104
I0526 07:53:34.132627  6929 solver.cpp:253]     Train net output #0: loss = 1.37103 (* 1 = 1.37103 loss)
I0526 07:53:34.132640  6929 sgd_solver.cpp:106] Iteration 642000, lr = 0.003
I0526 07:53:50.921202  6929 solver.cpp:237] Iteration 643500, loss = 1.43079
I0526 07:53:50.921351  6929 solver.cpp:253]     Train net output #0: loss = 1.43078 (* 1 = 1.43078 loss)
I0526 07:53:50.921365  6929 sgd_solver.cpp:106] Iteration 643500, lr = 0.003
I0526 07:54:07.687201  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_645000.caffemodel
I0526 07:54:07.732880  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_645000.solverstate
I0526 07:54:07.764425  6929 solver.cpp:237] Iteration 645000, loss = 1.04016
I0526 07:54:07.764474  6929 solver.cpp:253]     Train net output #0: loss = 1.04016 (* 1 = 1.04016 loss)
I0526 07:54:07.764488  6929 sgd_solver.cpp:106] Iteration 645000, lr = 0.003
I0526 07:54:24.549989  6929 solver.cpp:237] Iteration 646500, loss = 0.607067
I0526 07:54:24.550171  6929 solver.cpp:253]     Train net output #0: loss = 0.607063 (* 1 = 0.607063 loss)
I0526 07:54:24.550186  6929 sgd_solver.cpp:106] Iteration 646500, lr = 0.003
I0526 07:54:41.304397  6929 solver.cpp:237] Iteration 648000, loss = 1.01645
I0526 07:54:41.304433  6929 solver.cpp:253]     Train net output #0: loss = 1.01644 (* 1 = 1.01644 loss)
I0526 07:54:41.304447  6929 sgd_solver.cpp:106] Iteration 648000, lr = 0.003
I0526 07:54:58.071395  6929 solver.cpp:237] Iteration 649500, loss = 1.13161
I0526 07:54:58.071562  6929 solver.cpp:253]     Train net output #0: loss = 1.1316 (* 1 = 1.1316 loss)
I0526 07:54:58.071578  6929 sgd_solver.cpp:106] Iteration 649500, lr = 0.003
I0526 07:55:35.759888  6929 solver.cpp:237] Iteration 651000, loss = 0.916758
I0526 07:55:35.760064  6929 solver.cpp:253]     Train net output #0: loss = 0.916753 (* 1 = 0.916753 loss)
I0526 07:55:35.760078  6929 sgd_solver.cpp:106] Iteration 651000, lr = 0.003
I0526 07:55:52.535415  6929 solver.cpp:237] Iteration 652500, loss = 0.400223
I0526 07:55:52.535451  6929 solver.cpp:253]     Train net output #0: loss = 0.400219 (* 1 = 0.400219 loss)
I0526 07:55:52.535465  6929 sgd_solver.cpp:106] Iteration 652500, lr = 0.003
I0526 07:56:09.217329  6929 solver.cpp:237] Iteration 654000, loss = 1.14437
I0526 07:56:09.217492  6929 solver.cpp:253]     Train net output #0: loss = 1.14437 (* 1 = 1.14437 loss)
I0526 07:56:09.217506  6929 sgd_solver.cpp:106] Iteration 654000, lr = 0.003
I0526 07:56:25.868490  6929 solver.cpp:237] Iteration 655500, loss = 0.917734
I0526 07:56:25.868533  6929 solver.cpp:253]     Train net output #0: loss = 0.917729 (* 1 = 0.917729 loss)
I0526 07:56:25.868548  6929 sgd_solver.cpp:106] Iteration 655500, lr = 0.003
I0526 07:56:42.522644  6929 solver.cpp:237] Iteration 657000, loss = 1.39326
I0526 07:56:42.522792  6929 solver.cpp:253]     Train net output #0: loss = 1.39326 (* 1 = 1.39326 loss)
I0526 07:56:42.522809  6929 sgd_solver.cpp:106] Iteration 657000, lr = 0.003
I0526 07:56:59.135349  6929 solver.cpp:237] Iteration 658500, loss = 1.12051
I0526 07:56:59.135388  6929 solver.cpp:253]     Train net output #0: loss = 1.1205 (* 1 = 1.1205 loss)
I0526 07:56:59.135402  6929 sgd_solver.cpp:106] Iteration 658500, lr = 0.003
I0526 07:57:15.769318  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_660000.caffemodel
I0526 07:57:15.816195  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_660000.solverstate
I0526 07:57:15.842913  6929 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 07:58:14.745811  6929 solver.cpp:409]     Test net output #0: accuracy = 0.892404
I0526 07:58:14.745978  6929 solver.cpp:409]     Test net output #1: loss = 0.352948 (* 1 = 0.352948 loss)
I0526 07:58:35.657349  6929 solver.cpp:237] Iteration 660000, loss = 0.81577
I0526 07:58:35.657403  6929 solver.cpp:253]     Train net output #0: loss = 0.815765 (* 1 = 0.815765 loss)
I0526 07:58:35.657421  6929 sgd_solver.cpp:106] Iteration 660000, lr = 0.003
I0526 07:58:52.574870  6929 solver.cpp:237] Iteration 661500, loss = 0.799169
I0526 07:58:52.575031  6929 solver.cpp:253]     Train net output #0: loss = 0.799163 (* 1 = 0.799163 loss)
I0526 07:58:52.575047  6929 sgd_solver.cpp:106] Iteration 661500, lr = 0.003
I0526 07:59:09.536033  6929 solver.cpp:237] Iteration 663000, loss = 1.26045
I0526 07:59:09.536080  6929 solver.cpp:253]     Train net output #0: loss = 1.26044 (* 1 = 1.26044 loss)
I0526 07:59:09.536103  6929 sgd_solver.cpp:106] Iteration 663000, lr = 0.003
I0526 07:59:26.486907  6929 solver.cpp:237] Iteration 664500, loss = 1.41169
I0526 07:59:26.487081  6929 solver.cpp:253]     Train net output #0: loss = 1.41168 (* 1 = 1.41168 loss)
I0526 07:59:26.487097  6929 sgd_solver.cpp:106] Iteration 664500, lr = 0.003
I0526 07:59:43.404614  6929 solver.cpp:237] Iteration 666000, loss = 1.25382
I0526 07:59:43.404659  6929 solver.cpp:253]     Train net output #0: loss = 1.25381 (* 1 = 1.25381 loss)
I0526 07:59:43.404680  6929 sgd_solver.cpp:106] Iteration 666000, lr = 0.003
I0526 08:00:00.375819  6929 solver.cpp:237] Iteration 667500, loss = 1.27467
I0526 08:00:00.375972  6929 solver.cpp:253]     Train net output #0: loss = 1.27466 (* 1 = 1.27466 loss)
I0526 08:00:00.375987  6929 sgd_solver.cpp:106] Iteration 667500, lr = 0.003
I0526 08:00:17.292165  6929 solver.cpp:237] Iteration 669000, loss = 1.21648
I0526 08:00:17.292213  6929 solver.cpp:253]     Train net output #0: loss = 1.21647 (* 1 = 1.21647 loss)
I0526 08:00:17.292228  6929 sgd_solver.cpp:106] Iteration 669000, lr = 0.003
I0526 08:00:55.140177  6929 solver.cpp:237] Iteration 670500, loss = 1.38635
I0526 08:00:55.140352  6929 solver.cpp:253]     Train net output #0: loss = 1.38634 (* 1 = 1.38634 loss)
I0526 08:00:55.140368  6929 sgd_solver.cpp:106] Iteration 670500, lr = 0.003
I0526 08:01:12.076685  6929 solver.cpp:237] Iteration 672000, loss = 0.944098
I0526 08:01:12.076733  6929 solver.cpp:253]     Train net output #0: loss = 0.94409 (* 1 = 0.94409 loss)
I0526 08:01:12.076748  6929 sgd_solver.cpp:106] Iteration 672000, lr = 0.003
I0526 08:01:29.020859  6929 solver.cpp:237] Iteration 673500, loss = 1.66007
I0526 08:01:29.021020  6929 solver.cpp:253]     Train net output #0: loss = 1.66006 (* 1 = 1.66006 loss)
I0526 08:01:29.021035  6929 sgd_solver.cpp:106] Iteration 673500, lr = 0.003
I0526 08:01:45.965008  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_675000.caffemodel
I0526 08:01:46.012593  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_675000.solverstate
I0526 08:01:46.043617  6929 solver.cpp:237] Iteration 675000, loss = 1.19547
I0526 08:01:46.043668  6929 solver.cpp:253]     Train net output #0: loss = 1.19546 (* 1 = 1.19546 loss)
I0526 08:01:46.043683  6929 sgd_solver.cpp:106] Iteration 675000, lr = 0.003
I0526 08:02:02.998261  6929 solver.cpp:237] Iteration 676500, loss = 1.23328
I0526 08:02:02.998422  6929 solver.cpp:253]     Train net output #0: loss = 1.23327 (* 1 = 1.23327 loss)
I0526 08:02:02.998436  6929 sgd_solver.cpp:106] Iteration 676500, lr = 0.003
I0526 08:02:19.969663  6929 solver.cpp:237] Iteration 678000, loss = 0.894066
I0526 08:02:19.969708  6929 solver.cpp:253]     Train net output #0: loss = 0.894059 (* 1 = 0.894059 loss)
I0526 08:02:19.969722  6929 sgd_solver.cpp:106] Iteration 678000, lr = 0.003
I0526 08:02:36.910527  6929 solver.cpp:237] Iteration 679500, loss = 0.844015
I0526 08:02:36.910686  6929 solver.cpp:253]     Train net output #0: loss = 0.844007 (* 1 = 0.844007 loss)
I0526 08:02:36.910701  6929 sgd_solver.cpp:106] Iteration 679500, lr = 0.003
I0526 08:03:14.703683  6929 solver.cpp:237] Iteration 681000, loss = 1.06455
I0526 08:03:14.703856  6929 solver.cpp:253]     Train net output #0: loss = 1.06454 (* 1 = 1.06454 loss)
I0526 08:03:14.703871  6929 sgd_solver.cpp:106] Iteration 681000, lr = 0.003
I0526 08:03:31.646852  6929 solver.cpp:237] Iteration 682500, loss = 0.895947
I0526 08:03:31.646895  6929 solver.cpp:253]     Train net output #0: loss = 0.895939 (* 1 = 0.895939 loss)
I0526 08:03:31.646914  6929 sgd_solver.cpp:106] Iteration 682500, lr = 0.003
I0526 08:03:48.591871  6929 solver.cpp:237] Iteration 684000, loss = 1.14212
I0526 08:03:48.592032  6929 solver.cpp:253]     Train net output #0: loss = 1.14211 (* 1 = 1.14211 loss)
I0526 08:03:48.592047  6929 sgd_solver.cpp:106] Iteration 684000, lr = 0.003
I0526 08:04:05.563427  6929 solver.cpp:237] Iteration 685500, loss = 1.1254
I0526 08:04:05.563468  6929 solver.cpp:253]     Train net output #0: loss = 1.1254 (* 1 = 1.1254 loss)
I0526 08:04:05.563482  6929 sgd_solver.cpp:106] Iteration 685500, lr = 0.003
I0526 08:04:22.506534  6929 solver.cpp:237] Iteration 687000, loss = 1.01683
I0526 08:04:22.506690  6929 solver.cpp:253]     Train net output #0: loss = 1.01682 (* 1 = 1.01682 loss)
I0526 08:04:22.506705  6929 sgd_solver.cpp:106] Iteration 687000, lr = 0.003
I0526 08:04:39.467238  6929 solver.cpp:237] Iteration 688500, loss = 0.547745
I0526 08:04:39.467275  6929 solver.cpp:253]     Train net output #0: loss = 0.547736 (* 1 = 0.547736 loss)
I0526 08:04:39.467289  6929 sgd_solver.cpp:106] Iteration 688500, lr = 0.003
I0526 08:04:56.389214  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_690000.caffemodel
I0526 08:04:56.435729  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_690000.solverstate
I0526 08:04:56.461251  6929 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 08:06:17.010233  6929 solver.cpp:409]     Test net output #0: accuracy = 0.896045
I0526 08:06:17.010406  6929 solver.cpp:409]     Test net output #1: loss = 0.325343 (* 1 = 0.325343 loss)
I0526 08:06:37.855458  6929 solver.cpp:237] Iteration 690000, loss = 1.19773
I0526 08:06:37.855510  6929 solver.cpp:253]     Train net output #0: loss = 1.19772 (* 1 = 1.19772 loss)
I0526 08:06:37.855525  6929 sgd_solver.cpp:106] Iteration 690000, lr = 0.003
I0526 08:06:54.925451  6929 solver.cpp:237] Iteration 691500, loss = 0.573532
I0526 08:06:54.925616  6929 solver.cpp:253]     Train net output #0: loss = 0.573523 (* 1 = 0.573523 loss)
I0526 08:06:54.925631  6929 sgd_solver.cpp:106] Iteration 691500, lr = 0.003
I0526 08:07:11.971861  6929 solver.cpp:237] Iteration 693000, loss = 2.10683
I0526 08:07:11.971897  6929 solver.cpp:253]     Train net output #0: loss = 2.10682 (* 1 = 2.10682 loss)
I0526 08:07:11.971911  6929 sgd_solver.cpp:106] Iteration 693000, lr = 0.003
I0526 08:07:29.015092  6929 solver.cpp:237] Iteration 694500, loss = 1.56601
I0526 08:07:29.015250  6929 solver.cpp:253]     Train net output #0: loss = 1.566 (* 1 = 1.566 loss)
I0526 08:07:29.015266  6929 sgd_solver.cpp:106] Iteration 694500, lr = 0.003
I0526 08:07:45.982554  6929 solver.cpp:237] Iteration 696000, loss = 0.757388
I0526 08:07:45.982601  6929 solver.cpp:253]     Train net output #0: loss = 0.75738 (* 1 = 0.75738 loss)
I0526 08:07:45.982615  6929 sgd_solver.cpp:106] Iteration 696000, lr = 0.003
I0526 08:08:02.875799  6929 solver.cpp:237] Iteration 697500, loss = 1.25892
I0526 08:08:02.875952  6929 solver.cpp:253]     Train net output #0: loss = 1.25892 (* 1 = 1.25892 loss)
I0526 08:08:02.875967  6929 sgd_solver.cpp:106] Iteration 697500, lr = 0.003
I0526 08:08:19.755650  6929 solver.cpp:237] Iteration 699000, loss = 0.732802
I0526 08:08:19.755698  6929 solver.cpp:253]     Train net output #0: loss = 0.732794 (* 1 = 0.732794 loss)
I0526 08:08:19.755712  6929 sgd_solver.cpp:106] Iteration 699000, lr = 0.003
I0526 08:08:57.479822  6929 solver.cpp:237] Iteration 700500, loss = 1.50285
I0526 08:08:57.479992  6929 solver.cpp:253]     Train net output #0: loss = 1.50284 (* 1 = 1.50284 loss)
I0526 08:08:57.480006  6929 sgd_solver.cpp:106] Iteration 700500, lr = 0.003
I0526 08:09:14.387583  6929 solver.cpp:237] Iteration 702000, loss = 1.334
I0526 08:09:14.387620  6929 solver.cpp:253]     Train net output #0: loss = 1.33399 (* 1 = 1.33399 loss)
I0526 08:09:14.387634  6929 sgd_solver.cpp:106] Iteration 702000, lr = 0.003
I0526 08:09:31.261610  6929 solver.cpp:237] Iteration 703500, loss = 1.09668
I0526 08:09:31.261785  6929 solver.cpp:253]     Train net output #0: loss = 1.09667 (* 1 = 1.09667 loss)
I0526 08:09:31.261800  6929 sgd_solver.cpp:106] Iteration 703500, lr = 0.003
I0526 08:09:48.192459  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_705000.caffemodel
I0526 08:09:48.238901  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_705000.solverstate
I0526 08:09:48.267653  6929 solver.cpp:237] Iteration 705000, loss = 1.00081
I0526 08:09:48.267699  6929 solver.cpp:253]     Train net output #0: loss = 1.0008 (* 1 = 1.0008 loss)
I0526 08:09:48.267714  6929 sgd_solver.cpp:106] Iteration 705000, lr = 0.003
I0526 08:10:05.232591  6929 solver.cpp:237] Iteration 706500, loss = 1.17854
I0526 08:10:05.232749  6929 solver.cpp:253]     Train net output #0: loss = 1.17853 (* 1 = 1.17853 loss)
I0526 08:10:05.232764  6929 sgd_solver.cpp:106] Iteration 706500, lr = 0.003
I0526 08:10:22.278266  6929 solver.cpp:237] Iteration 708000, loss = 1.28217
I0526 08:10:22.278316  6929 solver.cpp:253]     Train net output #0: loss = 1.28216 (* 1 = 1.28216 loss)
I0526 08:10:22.278329  6929 sgd_solver.cpp:106] Iteration 708000, lr = 0.003
I0526 08:10:39.333894  6929 solver.cpp:237] Iteration 709500, loss = 1.25012
I0526 08:10:39.334059  6929 solver.cpp:253]     Train net output #0: loss = 1.25011 (* 1 = 1.25011 loss)
I0526 08:10:39.334074  6929 sgd_solver.cpp:106] Iteration 709500, lr = 0.003
I0526 08:11:17.298741  6929 solver.cpp:237] Iteration 711000, loss = 1.10755
I0526 08:11:17.298918  6929 solver.cpp:253]     Train net output #0: loss = 1.10754 (* 1 = 1.10754 loss)
I0526 08:11:17.298933  6929 sgd_solver.cpp:106] Iteration 711000, lr = 0.003
I0526 08:11:34.403635  6929 solver.cpp:237] Iteration 712500, loss = 1.84533
I0526 08:11:34.403681  6929 solver.cpp:253]     Train net output #0: loss = 1.84532 (* 1 = 1.84532 loss)
I0526 08:11:34.403697  6929 sgd_solver.cpp:106] Iteration 712500, lr = 0.003
I0526 08:11:51.478677  6929 solver.cpp:237] Iteration 714000, loss = 1.35165
I0526 08:11:51.478844  6929 solver.cpp:253]     Train net output #0: loss = 1.35164 (* 1 = 1.35164 loss)
I0526 08:11:51.478859  6929 sgd_solver.cpp:106] Iteration 714000, lr = 0.003
I0526 08:12:08.540628  6929 solver.cpp:237] Iteration 715500, loss = 1.09271
I0526 08:12:08.540665  6929 solver.cpp:253]     Train net output #0: loss = 1.0927 (* 1 = 1.0927 loss)
I0526 08:12:08.540678  6929 sgd_solver.cpp:106] Iteration 715500, lr = 0.003
I0526 08:12:25.430019  6929 solver.cpp:237] Iteration 717000, loss = 1.07257
I0526 08:12:25.430187  6929 solver.cpp:253]     Train net output #0: loss = 1.07256 (* 1 = 1.07256 loss)
I0526 08:12:25.430203  6929 sgd_solver.cpp:106] Iteration 717000, lr = 0.003
I0526 08:12:42.279882  6929 solver.cpp:237] Iteration 718500, loss = 1.41641
I0526 08:12:42.279927  6929 solver.cpp:253]     Train net output #0: loss = 1.4164 (* 1 = 1.4164 loss)
I0526 08:12:42.279940  6929 sgd_solver.cpp:106] Iteration 718500, lr = 0.003
I0526 08:12:59.097861  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_720000.caffemodel
I0526 08:12:59.144156  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_720000.solverstate
I0526 08:12:59.169364  6929 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 08:13:58.495612  6929 solver.cpp:409]     Test net output #0: accuracy = 0.89829
I0526 08:13:58.495780  6929 solver.cpp:409]     Test net output #1: loss = 0.32713 (* 1 = 0.32713 loss)
I0526 08:14:19.353466  6929 solver.cpp:237] Iteration 720000, loss = 1.51037
I0526 08:14:19.353520  6929 solver.cpp:253]     Train net output #0: loss = 1.51036 (* 1 = 1.51036 loss)
I0526 08:14:19.353535  6929 sgd_solver.cpp:106] Iteration 720000, lr = 0.003
I0526 08:14:36.305950  6929 solver.cpp:237] Iteration 721500, loss = 1.53198
I0526 08:14:36.306120  6929 solver.cpp:253]     Train net output #0: loss = 1.53198 (* 1 = 1.53198 loss)
I0526 08:14:36.306134  6929 sgd_solver.cpp:106] Iteration 721500, lr = 0.003
I0526 08:14:53.265271  6929 solver.cpp:237] Iteration 723000, loss = 0.620941
I0526 08:14:53.265319  6929 solver.cpp:253]     Train net output #0: loss = 0.620933 (* 1 = 0.620933 loss)
I0526 08:14:53.265336  6929 sgd_solver.cpp:106] Iteration 723000, lr = 0.003
I0526 08:15:10.229728  6929 solver.cpp:237] Iteration 724500, loss = 0.903966
I0526 08:15:10.229894  6929 solver.cpp:253]     Train net output #0: loss = 0.903959 (* 1 = 0.903959 loss)
I0526 08:15:10.229908  6929 sgd_solver.cpp:106] Iteration 724500, lr = 0.003
I0526 08:15:27.182802  6929 solver.cpp:237] Iteration 726000, loss = 0.906164
I0526 08:15:27.182838  6929 solver.cpp:253]     Train net output #0: loss = 0.906158 (* 1 = 0.906158 loss)
I0526 08:15:27.182855  6929 sgd_solver.cpp:106] Iteration 726000, lr = 0.003
I0526 08:15:44.155648  6929 solver.cpp:237] Iteration 727500, loss = 1.09231
I0526 08:15:44.155817  6929 solver.cpp:253]     Train net output #0: loss = 1.0923 (* 1 = 1.0923 loss)
I0526 08:15:44.155833  6929 sgd_solver.cpp:106] Iteration 727500, lr = 0.003
I0526 08:16:01.130622  6929 solver.cpp:237] Iteration 729000, loss = 1.0303
I0526 08:16:01.130671  6929 solver.cpp:253]     Train net output #0: loss = 1.03029 (* 1 = 1.03029 loss)
I0526 08:16:01.130684  6929 sgd_solver.cpp:106] Iteration 729000, lr = 0.003
I0526 08:16:38.935644  6929 solver.cpp:237] Iteration 730500, loss = 1.49381
I0526 08:16:38.935819  6929 solver.cpp:253]     Train net output #0: loss = 1.4938 (* 1 = 1.4938 loss)
I0526 08:16:38.935835  6929 sgd_solver.cpp:106] Iteration 730500, lr = 0.003
I0526 08:16:55.874594  6929 solver.cpp:237] Iteration 732000, loss = 0.959128
I0526 08:16:55.874644  6929 solver.cpp:253]     Train net output #0: loss = 0.959122 (* 1 = 0.959122 loss)
I0526 08:16:55.874660  6929 sgd_solver.cpp:106] Iteration 732000, lr = 0.003
I0526 08:17:12.826416  6929 solver.cpp:237] Iteration 733500, loss = 1.15537
I0526 08:17:12.826570  6929 solver.cpp:253]     Train net output #0: loss = 1.15537 (* 1 = 1.15537 loss)
I0526 08:17:12.826584  6929 sgd_solver.cpp:106] Iteration 733500, lr = 0.003
I0526 08:17:29.778344  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_735000.caffemodel
I0526 08:17:29.828264  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_735000.solverstate
I0526 08:17:29.859338  6929 solver.cpp:237] Iteration 735000, loss = 2.06374
I0526 08:17:29.859388  6929 solver.cpp:253]     Train net output #0: loss = 2.06374 (* 1 = 2.06374 loss)
I0526 08:17:29.859403  6929 sgd_solver.cpp:106] Iteration 735000, lr = 0.003
I0526 08:17:46.827067  6929 solver.cpp:237] Iteration 736500, loss = 0.881586
I0526 08:17:46.827239  6929 solver.cpp:253]     Train net output #0: loss = 0.88158 (* 1 = 0.88158 loss)
I0526 08:17:46.827255  6929 sgd_solver.cpp:106] Iteration 736500, lr = 0.003
I0526 08:18:03.789772  6929 solver.cpp:237] Iteration 738000, loss = 2.04378
I0526 08:18:03.789821  6929 solver.cpp:253]     Train net output #0: loss = 2.04377 (* 1 = 2.04377 loss)
I0526 08:18:03.789835  6929 sgd_solver.cpp:106] Iteration 738000, lr = 0.003
I0526 08:18:20.748728  6929 solver.cpp:237] Iteration 739500, loss = 0.582614
I0526 08:18:20.748883  6929 solver.cpp:253]     Train net output #0: loss = 0.582606 (* 1 = 0.582606 loss)
I0526 08:18:20.748898  6929 sgd_solver.cpp:106] Iteration 739500, lr = 0.003
I0526 08:18:58.566301  6929 solver.cpp:237] Iteration 741000, loss = 1.14268
I0526 08:18:58.566488  6929 solver.cpp:253]     Train net output #0: loss = 1.14267 (* 1 = 1.14267 loss)
I0526 08:18:58.566501  6929 sgd_solver.cpp:106] Iteration 741000, lr = 0.003
I0526 08:19:15.497397  6929 solver.cpp:237] Iteration 742500, loss = 1.27489
I0526 08:19:15.497433  6929 solver.cpp:253]     Train net output #0: loss = 1.27488 (* 1 = 1.27488 loss)
I0526 08:19:15.497447  6929 sgd_solver.cpp:106] Iteration 742500, lr = 0.003
I0526 08:19:32.456209  6929 solver.cpp:237] Iteration 744000, loss = 0.946504
I0526 08:19:32.456387  6929 solver.cpp:253]     Train net output #0: loss = 0.946497 (* 1 = 0.946497 loss)
I0526 08:19:32.456401  6929 sgd_solver.cpp:106] Iteration 744000, lr = 0.003
I0526 08:19:49.419404  6929 solver.cpp:237] Iteration 745500, loss = 1.10097
I0526 08:19:49.419445  6929 solver.cpp:253]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0526 08:19:49.419461  6929 sgd_solver.cpp:106] Iteration 745500, lr = 0.003
I0526 08:20:06.366668  6929 solver.cpp:237] Iteration 747000, loss = 1.78081
I0526 08:20:06.366832  6929 solver.cpp:253]     Train net output #0: loss = 1.7808 (* 1 = 1.7808 loss)
I0526 08:20:06.366845  6929 sgd_solver.cpp:106] Iteration 747000, lr = 0.003
I0526 08:20:23.290769  6929 solver.cpp:237] Iteration 748500, loss = 0.92114
I0526 08:20:23.290819  6929 solver.cpp:253]     Train net output #0: loss = 0.921133 (* 1 = 0.921133 loss)
I0526 08:20:23.290833  6929 sgd_solver.cpp:106] Iteration 748500, lr = 0.003
I0526 08:20:40.153821  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_750000.caffemodel
I0526 08:20:40.201979  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_750000.solverstate
I0526 08:20:40.277227  6929 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 08:22:00.500370  6929 solver.cpp:409]     Test net output #0: accuracy = 0.896795
I0526 08:22:00.500560  6929 solver.cpp:409]     Test net output #1: loss = 0.322407 (* 1 = 0.322407 loss)
I0526 08:22:21.431627  6929 solver.cpp:237] Iteration 750000, loss = 0.686787
I0526 08:22:21.431681  6929 solver.cpp:253]     Train net output #0: loss = 0.68678 (* 1 = 0.68678 loss)
I0526 08:22:21.431696  6929 sgd_solver.cpp:106] Iteration 750000, lr = 0.003
I0526 08:22:38.061897  6929 solver.cpp:237] Iteration 751500, loss = 1.31896
I0526 08:22:38.062054  6929 solver.cpp:253]     Train net output #0: loss = 1.31895 (* 1 = 1.31895 loss)
I0526 08:22:38.062069  6929 sgd_solver.cpp:106] Iteration 751500, lr = 0.003
I0526 08:22:54.669396  6929 solver.cpp:237] Iteration 753000, loss = 1.46742
I0526 08:22:54.669441  6929 solver.cpp:253]     Train net output #0: loss = 1.46741 (* 1 = 1.46741 loss)
I0526 08:22:54.669455  6929 sgd_solver.cpp:106] Iteration 753000, lr = 0.003
I0526 08:23:11.299047  6929 solver.cpp:237] Iteration 754500, loss = 1.83991
I0526 08:23:11.299217  6929 solver.cpp:253]     Train net output #0: loss = 1.83991 (* 1 = 1.83991 loss)
I0526 08:23:11.299233  6929 sgd_solver.cpp:106] Iteration 754500, lr = 0.003
I0526 08:23:27.934156  6929 solver.cpp:237] Iteration 756000, loss = 1.31453
I0526 08:23:27.934192  6929 solver.cpp:253]     Train net output #0: loss = 1.31452 (* 1 = 1.31452 loss)
I0526 08:23:27.934206  6929 sgd_solver.cpp:106] Iteration 756000, lr = 0.003
I0526 08:23:44.586145  6929 solver.cpp:237] Iteration 757500, loss = 1.02837
I0526 08:23:44.586315  6929 solver.cpp:253]     Train net output #0: loss = 1.02836 (* 1 = 1.02836 loss)
I0526 08:23:44.586331  6929 sgd_solver.cpp:106] Iteration 757500, lr = 0.003
I0526 08:24:01.222232  6929 solver.cpp:237] Iteration 759000, loss = 1.09649
I0526 08:24:01.222281  6929 solver.cpp:253]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0526 08:24:01.222295  6929 sgd_solver.cpp:106] Iteration 759000, lr = 0.003
I0526 08:24:39.322512  6929 solver.cpp:237] Iteration 760500, loss = 1.09031
I0526 08:24:39.322700  6929 solver.cpp:253]     Train net output #0: loss = 1.0903 (* 1 = 1.0903 loss)
I0526 08:24:39.322716  6929 sgd_solver.cpp:106] Iteration 760500, lr = 0.003
I0526 08:24:55.943845  6929 solver.cpp:237] Iteration 762000, loss = 1.87498
I0526 08:24:55.943894  6929 solver.cpp:253]     Train net output #0: loss = 1.87497 (* 1 = 1.87497 loss)
I0526 08:24:55.943908  6929 sgd_solver.cpp:106] Iteration 762000, lr = 0.003
I0526 08:25:12.540609  6929 solver.cpp:237] Iteration 763500, loss = 1.3503
I0526 08:25:12.540781  6929 solver.cpp:253]     Train net output #0: loss = 1.35029 (* 1 = 1.35029 loss)
I0526 08:25:12.540796  6929 sgd_solver.cpp:106] Iteration 763500, lr = 0.003
I0526 08:25:29.163926  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_765000.caffemodel
I0526 08:25:29.217962  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_765000.solverstate
I0526 08:25:29.273293  6929 solver.cpp:237] Iteration 765000, loss = 1.11076
I0526 08:25:29.273339  6929 solver.cpp:253]     Train net output #0: loss = 1.11075 (* 1 = 1.11075 loss)
I0526 08:25:29.273355  6929 sgd_solver.cpp:106] Iteration 765000, lr = 0.003
I0526 08:25:45.883091  6929 solver.cpp:237] Iteration 766500, loss = 0.861178
I0526 08:25:45.883258  6929 solver.cpp:253]     Train net output #0: loss = 0.86117 (* 1 = 0.86117 loss)
I0526 08:25:45.883276  6929 sgd_solver.cpp:106] Iteration 766500, lr = 0.003
I0526 08:26:02.515455  6929 solver.cpp:237] Iteration 768000, loss = 0.887529
I0526 08:26:02.515502  6929 solver.cpp:253]     Train net output #0: loss = 0.887521 (* 1 = 0.887521 loss)
I0526 08:26:02.515518  6929 sgd_solver.cpp:106] Iteration 768000, lr = 0.003
I0526 08:26:19.137058  6929 solver.cpp:237] Iteration 769500, loss = 1.22168
I0526 08:26:19.137215  6929 solver.cpp:253]     Train net output #0: loss = 1.22167 (* 1 = 1.22167 loss)
I0526 08:26:19.137231  6929 sgd_solver.cpp:106] Iteration 769500, lr = 0.003
I0526 08:26:57.044021  6929 solver.cpp:237] Iteration 771000, loss = 1.18263
I0526 08:26:57.044216  6929 solver.cpp:253]     Train net output #0: loss = 1.18262 (* 1 = 1.18262 loss)
I0526 08:26:57.044234  6929 sgd_solver.cpp:106] Iteration 771000, lr = 0.003
I0526 08:27:13.675566  6929 solver.cpp:237] Iteration 772500, loss = 1.60377
I0526 08:27:13.675607  6929 solver.cpp:253]     Train net output #0: loss = 1.60376 (* 1 = 1.60376 loss)
I0526 08:27:13.675622  6929 sgd_solver.cpp:106] Iteration 772500, lr = 0.003
I0526 08:27:30.299648  6929 solver.cpp:237] Iteration 774000, loss = 1.57513
I0526 08:27:30.299816  6929 solver.cpp:253]     Train net output #0: loss = 1.57512 (* 1 = 1.57512 loss)
I0526 08:27:30.299830  6929 sgd_solver.cpp:106] Iteration 774000, lr = 0.003
I0526 08:27:46.924626  6929 solver.cpp:237] Iteration 775500, loss = 1.45436
I0526 08:27:46.924674  6929 solver.cpp:253]     Train net output #0: loss = 1.45436 (* 1 = 1.45436 loss)
I0526 08:27:46.924690  6929 sgd_solver.cpp:106] Iteration 775500, lr = 0.003
I0526 08:28:03.535476  6929 solver.cpp:237] Iteration 777000, loss = 1.13319
I0526 08:28:03.535647  6929 solver.cpp:253]     Train net output #0: loss = 1.13318 (* 1 = 1.13318 loss)
I0526 08:28:03.535661  6929 sgd_solver.cpp:106] Iteration 777000, lr = 0.003
I0526 08:28:20.155174  6929 solver.cpp:237] Iteration 778500, loss = 1.50268
I0526 08:28:20.155210  6929 solver.cpp:253]     Train net output #0: loss = 1.50268 (* 1 = 1.50268 loss)
I0526 08:28:20.155223  6929 sgd_solver.cpp:106] Iteration 778500, lr = 0.003
I0526 08:28:37.031363  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_780000.caffemodel
I0526 08:28:37.078954  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_780000.solverstate
I0526 08:28:37.144054  6929 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 08:29:36.471163  6929 solver.cpp:409]     Test net output #0: accuracy = 0.899344
I0526 08:29:36.471338  6929 solver.cpp:409]     Test net output #1: loss = 0.318533 (* 1 = 0.318533 loss)
I0526 08:29:57.394287  6929 solver.cpp:237] Iteration 780000, loss = 1.01601
I0526 08:29:57.394340  6929 solver.cpp:253]     Train net output #0: loss = 1.016 (* 1 = 1.016 loss)
I0526 08:29:57.394353  6929 sgd_solver.cpp:106] Iteration 780000, lr = 0.003
I0526 08:30:14.030241  6929 solver.cpp:237] Iteration 781500, loss = 1.47995
I0526 08:30:14.030411  6929 solver.cpp:253]     Train net output #0: loss = 1.47994 (* 1 = 1.47994 loss)
I0526 08:30:14.030426  6929 sgd_solver.cpp:106] Iteration 781500, lr = 0.003
I0526 08:30:30.650691  6929 solver.cpp:237] Iteration 783000, loss = 1.17808
I0526 08:30:30.650725  6929 solver.cpp:253]     Train net output #0: loss = 1.17807 (* 1 = 1.17807 loss)
I0526 08:30:30.650739  6929 sgd_solver.cpp:106] Iteration 783000, lr = 0.003
I0526 08:30:47.278920  6929 solver.cpp:237] Iteration 784500, loss = 1.66165
I0526 08:30:47.279083  6929 solver.cpp:253]     Train net output #0: loss = 1.66164 (* 1 = 1.66164 loss)
I0526 08:30:47.279096  6929 sgd_solver.cpp:106] Iteration 784500, lr = 0.003
I0526 08:31:03.901262  6929 solver.cpp:237] Iteration 786000, loss = 1.37459
I0526 08:31:03.901301  6929 solver.cpp:253]     Train net output #0: loss = 1.37458 (* 1 = 1.37458 loss)
I0526 08:31:03.901317  6929 sgd_solver.cpp:106] Iteration 786000, lr = 0.003
I0526 08:31:20.546298  6929 solver.cpp:237] Iteration 787500, loss = 1.4147
I0526 08:31:20.546450  6929 solver.cpp:253]     Train net output #0: loss = 1.41469 (* 1 = 1.41469 loss)
I0526 08:31:20.546464  6929 sgd_solver.cpp:106] Iteration 787500, lr = 0.003
I0526 08:31:37.201355  6929 solver.cpp:237] Iteration 789000, loss = 0.630273
I0526 08:31:37.201397  6929 solver.cpp:253]     Train net output #0: loss = 0.630263 (* 1 = 0.630263 loss)
I0526 08:31:37.201413  6929 sgd_solver.cpp:106] Iteration 789000, lr = 0.003
I0526 08:32:14.769810  6929 solver.cpp:237] Iteration 790500, loss = 1.03756
I0526 08:32:14.769987  6929 solver.cpp:253]     Train net output #0: loss = 1.03756 (* 1 = 1.03756 loss)
I0526 08:32:14.770004  6929 sgd_solver.cpp:106] Iteration 790500, lr = 0.003
I0526 08:32:31.666888  6929 solver.cpp:237] Iteration 792000, loss = 1.25021
I0526 08:32:31.666924  6929 solver.cpp:253]     Train net output #0: loss = 1.2502 (* 1 = 1.2502 loss)
I0526 08:32:31.666939  6929 sgd_solver.cpp:106] Iteration 792000, lr = 0.003
I0526 08:32:48.562062  6929 solver.cpp:237] Iteration 793500, loss = 0.952783
I0526 08:32:48.562232  6929 solver.cpp:253]     Train net output #0: loss = 0.952773 (* 1 = 0.952773 loss)
I0526 08:32:48.562247  6929 sgd_solver.cpp:106] Iteration 793500, lr = 0.003
I0526 08:33:05.436939  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_795000.caffemodel
I0526 08:33:05.800019  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_795000.solverstate
I0526 08:33:05.877357  6929 solver.cpp:237] Iteration 795000, loss = 1.36186
I0526 08:33:05.877400  6929 solver.cpp:253]     Train net output #0: loss = 1.36185 (* 1 = 1.36185 loss)
I0526 08:33:05.877416  6929 sgd_solver.cpp:106] Iteration 795000, lr = 0.003
I0526 08:33:22.732453  6929 solver.cpp:237] Iteration 796500, loss = 1.34724
I0526 08:33:22.732614  6929 solver.cpp:253]     Train net output #0: loss = 1.34723 (* 1 = 1.34723 loss)
I0526 08:33:22.732628  6929 sgd_solver.cpp:106] Iteration 796500, lr = 0.003
I0526 08:33:39.619336  6929 solver.cpp:237] Iteration 798000, loss = 0.672107
I0526 08:33:39.619387  6929 solver.cpp:253]     Train net output #0: loss = 0.672097 (* 1 = 0.672097 loss)
I0526 08:33:39.619402  6929 sgd_solver.cpp:106] Iteration 798000, lr = 0.003
I0526 08:33:56.477330  6929 solver.cpp:237] Iteration 799500, loss = 0.467238
I0526 08:33:56.477514  6929 solver.cpp:253]     Train net output #0: loss = 0.467228 (* 1 = 0.467228 loss)
I0526 08:33:56.477529  6929 sgd_solver.cpp:106] Iteration 799500, lr = 0.003
I0526 08:34:36.143319  6929 solver.cpp:237] Iteration 801000, loss = 1.36435
I0526 08:34:36.143498  6929 solver.cpp:253]     Train net output #0: loss = 1.36434 (* 1 = 1.36434 loss)
I0526 08:34:36.143514  6929 sgd_solver.cpp:106] Iteration 801000, lr = 0.003
I0526 08:34:52.943557  6929 solver.cpp:237] Iteration 802500, loss = 0.851486
I0526 08:34:52.943603  6929 solver.cpp:253]     Train net output #0: loss = 0.851478 (* 1 = 0.851478 loss)
I0526 08:34:52.943617  6929 sgd_solver.cpp:106] Iteration 802500, lr = 0.003
I0526 08:35:09.806710  6929 solver.cpp:237] Iteration 804000, loss = 1.33722
I0526 08:35:09.806897  6929 solver.cpp:253]     Train net output #0: loss = 1.33721 (* 1 = 1.33721 loss)
I0526 08:35:09.806911  6929 sgd_solver.cpp:106] Iteration 804000, lr = 0.003
I0526 08:35:26.670832  6929 solver.cpp:237] Iteration 805500, loss = 0.80449
I0526 08:35:26.670868  6929 solver.cpp:253]     Train net output #0: loss = 0.804481 (* 1 = 0.804481 loss)
I0526 08:35:26.670882  6929 sgd_solver.cpp:106] Iteration 805500, lr = 0.003
I0526 08:35:43.552331  6929 solver.cpp:237] Iteration 807000, loss = 0.982563
I0526 08:35:43.552515  6929 solver.cpp:253]     Train net output #0: loss = 0.982553 (* 1 = 0.982553 loss)
I0526 08:35:43.552530  6929 sgd_solver.cpp:106] Iteration 807000, lr = 0.003
I0526 08:36:00.383237  6929 solver.cpp:237] Iteration 808500, loss = 1.05828
I0526 08:36:00.383285  6929 solver.cpp:253]     Train net output #0: loss = 1.05827 (* 1 = 1.05827 loss)
I0526 08:36:00.383298  6929 sgd_solver.cpp:106] Iteration 808500, lr = 0.003
I0526 08:36:17.218838  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_810000.caffemodel
I0526 08:36:19.192399  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_810000.solverstate
I0526 08:36:19.270732  6929 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 08:37:40.576282  6929 solver.cpp:409]     Test net output #0: accuracy = 0.89703
I0526 08:37:40.576457  6929 solver.cpp:409]     Test net output #1: loss = 0.33916 (* 1 = 0.33916 loss)
I0526 08:38:01.464004  6929 solver.cpp:237] Iteration 810000, loss = 1.50441
I0526 08:38:01.464057  6929 solver.cpp:253]     Train net output #0: loss = 1.5044 (* 1 = 1.5044 loss)
I0526 08:38:01.464074  6929 sgd_solver.cpp:106] Iteration 810000, lr = 0.003
I0526 08:38:18.684705  6929 solver.cpp:237] Iteration 811500, loss = 1.1681
I0526 08:38:18.684881  6929 solver.cpp:253]     Train net output #0: loss = 1.16809 (* 1 = 1.16809 loss)
I0526 08:38:18.684897  6929 sgd_solver.cpp:106] Iteration 811500, lr = 0.003
I0526 08:38:35.906011  6929 solver.cpp:237] Iteration 813000, loss = 0.927338
I0526 08:38:35.906060  6929 solver.cpp:253]     Train net output #0: loss = 0.927328 (* 1 = 0.927328 loss)
I0526 08:38:35.906074  6929 sgd_solver.cpp:106] Iteration 813000, lr = 0.003
I0526 08:38:53.106158  6929 solver.cpp:237] Iteration 814500, loss = 1.17693
I0526 08:38:53.106315  6929 solver.cpp:253]     Train net output #0: loss = 1.17692 (* 1 = 1.17692 loss)
I0526 08:38:53.106329  6929 sgd_solver.cpp:106] Iteration 814500, lr = 0.003
I0526 08:39:10.158854  6929 solver.cpp:237] Iteration 816000, loss = 0.653796
I0526 08:39:10.158897  6929 solver.cpp:253]     Train net output #0: loss = 0.653784 (* 1 = 0.653784 loss)
I0526 08:39:10.158910  6929 sgd_solver.cpp:106] Iteration 816000, lr = 0.003
I0526 08:39:27.193840  6929 solver.cpp:237] Iteration 817500, loss = 1.26317
I0526 08:39:27.194033  6929 solver.cpp:253]     Train net output #0: loss = 1.26316 (* 1 = 1.26316 loss)
I0526 08:39:27.194048  6929 sgd_solver.cpp:106] Iteration 817500, lr = 0.003
I0526 08:39:44.252224  6929 solver.cpp:237] Iteration 819000, loss = 1.12714
I0526 08:39:44.252269  6929 solver.cpp:253]     Train net output #0: loss = 1.12713 (* 1 = 1.12713 loss)
I0526 08:39:44.252285  6929 sgd_solver.cpp:106] Iteration 819000, lr = 0.003
I0526 08:40:22.201184  6929 solver.cpp:237] Iteration 820500, loss = 0.925587
I0526 08:40:22.201365  6929 solver.cpp:253]     Train net output #0: loss = 0.925576 (* 1 = 0.925576 loss)
I0526 08:40:22.201380  6929 sgd_solver.cpp:106] Iteration 820500, lr = 0.003
I0526 08:40:39.238010  6929 solver.cpp:237] Iteration 822000, loss = 1.41541
I0526 08:40:39.238056  6929 solver.cpp:253]     Train net output #0: loss = 1.4154 (* 1 = 1.4154 loss)
I0526 08:40:39.238075  6929 sgd_solver.cpp:106] Iteration 822000, lr = 0.003
I0526 08:40:56.287091  6929 solver.cpp:237] Iteration 823500, loss = 1.79001
I0526 08:40:56.287242  6929 solver.cpp:253]     Train net output #0: loss = 1.79 (* 1 = 1.79 loss)
I0526 08:40:56.287256  6929 sgd_solver.cpp:106] Iteration 823500, lr = 0.003
I0526 08:41:13.309078  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_825000.caffemodel
I0526 08:41:13.361863  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_825000.solverstate
I0526 08:41:13.396538  6929 solver.cpp:237] Iteration 825000, loss = 1.03295
I0526 08:41:13.396584  6929 solver.cpp:253]     Train net output #0: loss = 1.03294 (* 1 = 1.03294 loss)
I0526 08:41:13.396601  6929 sgd_solver.cpp:106] Iteration 825000, lr = 0.003
I0526 08:41:30.456970  6929 solver.cpp:237] Iteration 826500, loss = 1.58356
I0526 08:41:30.457149  6929 solver.cpp:253]     Train net output #0: loss = 1.58355 (* 1 = 1.58355 loss)
I0526 08:41:30.457164  6929 sgd_solver.cpp:106] Iteration 826500, lr = 0.003
I0526 08:41:47.505596  6929 solver.cpp:237] Iteration 828000, loss = 0.926446
I0526 08:41:47.505632  6929 solver.cpp:253]     Train net output #0: loss = 0.926436 (* 1 = 0.926436 loss)
I0526 08:41:47.505647  6929 sgd_solver.cpp:106] Iteration 828000, lr = 0.003
I0526 08:42:04.527437  6929 solver.cpp:237] Iteration 829500, loss = 0.732045
I0526 08:42:04.527607  6929 solver.cpp:253]     Train net output #0: loss = 0.732035 (* 1 = 0.732035 loss)
I0526 08:42:04.527623  6929 sgd_solver.cpp:106] Iteration 829500, lr = 0.003
I0526 08:42:42.478451  6929 solver.cpp:237] Iteration 831000, loss = 0.926392
I0526 08:42:42.478628  6929 solver.cpp:253]     Train net output #0: loss = 0.926382 (* 1 = 0.926382 loss)
I0526 08:42:42.478643  6929 sgd_solver.cpp:106] Iteration 831000, lr = 0.003
I0526 08:42:59.544689  6929 solver.cpp:237] Iteration 832500, loss = 1.45859
I0526 08:42:59.544725  6929 solver.cpp:253]     Train net output #0: loss = 1.45857 (* 1 = 1.45857 loss)
I0526 08:42:59.544739  6929 sgd_solver.cpp:106] Iteration 832500, lr = 0.003
I0526 08:43:16.604990  6929 solver.cpp:237] Iteration 834000, loss = 0.831247
I0526 08:43:16.605150  6929 solver.cpp:253]     Train net output #0: loss = 0.831237 (* 1 = 0.831237 loss)
I0526 08:43:16.605165  6929 sgd_solver.cpp:106] Iteration 834000, lr = 0.003
I0526 08:43:33.688107  6929 solver.cpp:237] Iteration 835500, loss = 0.787586
I0526 08:43:33.688150  6929 solver.cpp:253]     Train net output #0: loss = 0.787576 (* 1 = 0.787576 loss)
I0526 08:43:33.688166  6929 sgd_solver.cpp:106] Iteration 835500, lr = 0.003
I0526 08:43:50.759274  6929 solver.cpp:237] Iteration 837000, loss = 1.09118
I0526 08:43:50.759433  6929 solver.cpp:253]     Train net output #0: loss = 1.09117 (* 1 = 1.09117 loss)
I0526 08:43:50.759445  6929 sgd_solver.cpp:106] Iteration 837000, lr = 0.003
I0526 08:44:07.772505  6929 solver.cpp:237] Iteration 838500, loss = 0.92882
I0526 08:44:07.772552  6929 solver.cpp:253]     Train net output #0: loss = 0.928812 (* 1 = 0.928812 loss)
I0526 08:44:07.772567  6929 sgd_solver.cpp:106] Iteration 838500, lr = 0.003
I0526 08:44:24.827608  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_840000.caffemodel
I0526 08:44:24.888556  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_840000.solverstate
I0526 08:44:24.924213  6929 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 08:45:24.139240  6929 solver.cpp:409]     Test net output #0: accuracy = 0.897431
I0526 08:45:24.139417  6929 solver.cpp:409]     Test net output #1: loss = 0.322615 (* 1 = 0.322615 loss)
I0526 08:45:45.025451  6929 solver.cpp:237] Iteration 840000, loss = 0.432429
I0526 08:45:45.025503  6929 solver.cpp:253]     Train net output #0: loss = 0.43242 (* 1 = 0.43242 loss)
I0526 08:45:45.025519  6929 sgd_solver.cpp:106] Iteration 840000, lr = 0.003
I0526 08:46:01.900076  6929 solver.cpp:237] Iteration 841500, loss = 0.873696
I0526 08:46:01.900260  6929 solver.cpp:253]     Train net output #0: loss = 0.873688 (* 1 = 0.873688 loss)
I0526 08:46:01.900274  6929 sgd_solver.cpp:106] Iteration 841500, lr = 0.003
I0526 08:46:18.853646  6929 solver.cpp:237] Iteration 843000, loss = 0.991836
I0526 08:46:18.853683  6929 solver.cpp:253]     Train net output #0: loss = 0.991828 (* 1 = 0.991828 loss)
I0526 08:46:18.853696  6929 sgd_solver.cpp:106] Iteration 843000, lr = 0.003
I0526 08:46:35.794970  6929 solver.cpp:237] Iteration 844500, loss = 0.989043
I0526 08:46:35.795140  6929 solver.cpp:253]     Train net output #0: loss = 0.989035 (* 1 = 0.989035 loss)
I0526 08:46:35.795156  6929 sgd_solver.cpp:106] Iteration 844500, lr = 0.003
I0526 08:46:52.743031  6929 solver.cpp:237] Iteration 846000, loss = 0.779199
I0526 08:46:52.743074  6929 solver.cpp:253]     Train net output #0: loss = 0.779192 (* 1 = 0.779192 loss)
I0526 08:46:52.743089  6929 sgd_solver.cpp:106] Iteration 846000, lr = 0.003
I0526 08:47:09.705994  6929 solver.cpp:237] Iteration 847500, loss = 1.29132
I0526 08:47:09.706153  6929 solver.cpp:253]     Train net output #0: loss = 1.29131 (* 1 = 1.29131 loss)
I0526 08:47:09.706167  6929 sgd_solver.cpp:106] Iteration 847500, lr = 0.003
I0526 08:47:26.663300  6929 solver.cpp:237] Iteration 849000, loss = 0.62664
I0526 08:47:26.663349  6929 solver.cpp:253]     Train net output #0: loss = 0.626633 (* 1 = 0.626633 loss)
I0526 08:47:26.663364  6929 sgd_solver.cpp:106] Iteration 849000, lr = 0.003
I0526 08:48:04.471293  6929 solver.cpp:237] Iteration 850500, loss = 0.979768
I0526 08:48:04.471474  6929 solver.cpp:253]     Train net output #0: loss = 0.97976 (* 1 = 0.97976 loss)
I0526 08:48:04.471489  6929 sgd_solver.cpp:106] Iteration 850500, lr = 0.003
I0526 08:48:21.423683  6929 solver.cpp:237] Iteration 852000, loss = 1.0662
I0526 08:48:21.423719  6929 solver.cpp:253]     Train net output #0: loss = 1.06619 (* 1 = 1.06619 loss)
I0526 08:48:21.423737  6929 sgd_solver.cpp:106] Iteration 852000, lr = 0.003
I0526 08:48:38.398294  6929 solver.cpp:237] Iteration 853500, loss = 0.708031
I0526 08:48:38.398459  6929 solver.cpp:253]     Train net output #0: loss = 0.708023 (* 1 = 0.708023 loss)
I0526 08:48:38.398474  6929 sgd_solver.cpp:106] Iteration 853500, lr = 0.003
I0526 08:48:55.360888  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_855000.caffemodel
I0526 08:48:55.415608  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_855000.solverstate
I0526 08:48:55.453366  6929 solver.cpp:237] Iteration 855000, loss = 1.87536
I0526 08:48:55.453413  6929 solver.cpp:253]     Train net output #0: loss = 1.87535 (* 1 = 1.87535 loss)
I0526 08:48:55.453428  6929 sgd_solver.cpp:106] Iteration 855000, lr = 0.003
I0526 08:49:12.660727  6929 solver.cpp:237] Iteration 856500, loss = 1.50309
I0526 08:49:12.660902  6929 solver.cpp:253]     Train net output #0: loss = 1.50308 (* 1 = 1.50308 loss)
I0526 08:49:12.660917  6929 sgd_solver.cpp:106] Iteration 856500, lr = 0.003
I0526 08:49:29.875830  6929 solver.cpp:237] Iteration 858000, loss = 0.821021
I0526 08:49:29.875876  6929 solver.cpp:253]     Train net output #0: loss = 0.821015 (* 1 = 0.821015 loss)
I0526 08:49:29.875890  6929 sgd_solver.cpp:106] Iteration 858000, lr = 0.003
I0526 08:49:47.047097  6929 solver.cpp:237] Iteration 859500, loss = 0.977143
I0526 08:49:47.047267  6929 solver.cpp:253]     Train net output #0: loss = 0.977136 (* 1 = 0.977136 loss)
I0526 08:49:47.047281  6929 sgd_solver.cpp:106] Iteration 859500, lr = 0.003
I0526 08:50:25.192759  6929 solver.cpp:237] Iteration 861000, loss = 1.31354
I0526 08:50:25.192939  6929 solver.cpp:253]     Train net output #0: loss = 1.31353 (* 1 = 1.31353 loss)
I0526 08:50:25.192955  6929 sgd_solver.cpp:106] Iteration 861000, lr = 0.003
I0526 08:50:42.390947  6929 solver.cpp:237] Iteration 862500, loss = 2.40299
I0526 08:50:42.390995  6929 solver.cpp:253]     Train net output #0: loss = 2.40298 (* 1 = 2.40298 loss)
I0526 08:50:42.391010  6929 sgd_solver.cpp:106] Iteration 862500, lr = 0.003
I0526 08:50:59.597046  6929 solver.cpp:237] Iteration 864000, loss = 1.65225
I0526 08:50:59.597219  6929 solver.cpp:253]     Train net output #0: loss = 1.65224 (* 1 = 1.65224 loss)
I0526 08:50:59.597234  6929 sgd_solver.cpp:106] Iteration 864000, lr = 0.003
I0526 08:51:16.811347  6929 solver.cpp:237] Iteration 865500, loss = 1.26829
I0526 08:51:16.811383  6929 solver.cpp:253]     Train net output #0: loss = 1.26828 (* 1 = 1.26828 loss)
I0526 08:51:16.811398  6929 sgd_solver.cpp:106] Iteration 865500, lr = 0.003
I0526 08:51:34.016722  6929 solver.cpp:237] Iteration 867000, loss = 1.45731
I0526 08:51:34.016894  6929 solver.cpp:253]     Train net output #0: loss = 1.4573 (* 1 = 1.4573 loss)
I0526 08:51:34.016908  6929 sgd_solver.cpp:106] Iteration 867000, lr = 0.003
I0526 08:51:51.211149  6929 solver.cpp:237] Iteration 868500, loss = 1.76469
I0526 08:51:51.211189  6929 solver.cpp:253]     Train net output #0: loss = 1.76469 (* 1 = 1.76469 loss)
I0526 08:51:51.211208  6929 sgd_solver.cpp:106] Iteration 868500, lr = 0.003
I0526 08:52:08.444581  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_870000.caffemodel
I0526 08:52:08.497521  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_870000.solverstate
I0526 08:52:08.532843  6929 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 08:53:28.675117  6929 solver.cpp:409]     Test net output #0: accuracy = 0.894177
I0526 08:53:28.675297  6929 solver.cpp:409]     Test net output #1: loss = 0.337891 (* 1 = 0.337891 loss)
I0526 08:53:49.610047  6929 solver.cpp:237] Iteration 870000, loss = 1.1505
I0526 08:53:49.610098  6929 solver.cpp:253]     Train net output #0: loss = 1.15049 (* 1 = 1.15049 loss)
I0526 08:53:49.610113  6929 sgd_solver.cpp:106] Iteration 870000, lr = 0.003
I0526 08:54:06.222156  6929 solver.cpp:237] Iteration 871500, loss = 1.41243
I0526 08:54:06.222335  6929 solver.cpp:253]     Train net output #0: loss = 1.41242 (* 1 = 1.41242 loss)
I0526 08:54:06.222349  6929 sgd_solver.cpp:106] Iteration 871500, lr = 0.003
I0526 08:54:22.856070  6929 solver.cpp:237] Iteration 873000, loss = 1.01398
I0526 08:54:22.856125  6929 solver.cpp:253]     Train net output #0: loss = 1.01397 (* 1 = 1.01397 loss)
I0526 08:54:22.856139  6929 sgd_solver.cpp:106] Iteration 873000, lr = 0.003
I0526 08:54:39.478857  6929 solver.cpp:237] Iteration 874500, loss = 1.37436
I0526 08:54:39.479032  6929 solver.cpp:253]     Train net output #0: loss = 1.37435 (* 1 = 1.37435 loss)
I0526 08:54:39.479048  6929 sgd_solver.cpp:106] Iteration 874500, lr = 0.003
I0526 08:54:56.254297  6929 solver.cpp:237] Iteration 876000, loss = 0.887903
I0526 08:54:56.254345  6929 solver.cpp:253]     Train net output #0: loss = 0.887895 (* 1 = 0.887895 loss)
I0526 08:54:56.254359  6929 sgd_solver.cpp:106] Iteration 876000, lr = 0.003
I0526 08:55:13.151361  6929 solver.cpp:237] Iteration 877500, loss = 0.854512
I0526 08:55:13.151536  6929 solver.cpp:253]     Train net output #0: loss = 0.854504 (* 1 = 0.854504 loss)
I0526 08:55:13.151551  6929 sgd_solver.cpp:106] Iteration 877500, lr = 0.003
I0526 08:55:30.032703  6929 solver.cpp:237] Iteration 879000, loss = 1.24726
I0526 08:55:30.032739  6929 solver.cpp:253]     Train net output #0: loss = 1.24725 (* 1 = 1.24725 loss)
I0526 08:55:30.032753  6929 sgd_solver.cpp:106] Iteration 879000, lr = 0.003
I0526 08:56:07.775730  6929 solver.cpp:237] Iteration 880500, loss = 1.18867
I0526 08:56:07.775914  6929 solver.cpp:253]     Train net output #0: loss = 1.18866 (* 1 = 1.18866 loss)
I0526 08:56:07.775930  6929 sgd_solver.cpp:106] Iteration 880500, lr = 0.003
I0526 08:56:24.660487  6929 solver.cpp:237] Iteration 882000, loss = 1.39502
I0526 08:56:24.660529  6929 solver.cpp:253]     Train net output #0: loss = 1.39501 (* 1 = 1.39501 loss)
I0526 08:56:24.660544  6929 sgd_solver.cpp:106] Iteration 882000, lr = 0.003
I0526 08:56:41.555421  6929 solver.cpp:237] Iteration 883500, loss = 1.59713
I0526 08:56:41.555583  6929 solver.cpp:253]     Train net output #0: loss = 1.59713 (* 1 = 1.59713 loss)
I0526 08:56:41.555596  6929 sgd_solver.cpp:106] Iteration 883500, lr = 0.003
I0526 08:56:58.433686  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_885000.caffemodel
I0526 08:56:58.491951  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_885000.solverstate
I0526 08:56:58.533268  6929 solver.cpp:237] Iteration 885000, loss = 2.14655
I0526 08:56:58.533318  6929 solver.cpp:253]     Train net output #0: loss = 2.14654 (* 1 = 2.14654 loss)
I0526 08:56:58.533334  6929 sgd_solver.cpp:106] Iteration 885000, lr = 0.003
I0526 08:57:15.413161  6929 solver.cpp:237] Iteration 886500, loss = 0.952222
I0526 08:57:15.413357  6929 solver.cpp:253]     Train net output #0: loss = 0.952213 (* 1 = 0.952213 loss)
I0526 08:57:15.413372  6929 sgd_solver.cpp:106] Iteration 886500, lr = 0.003
I0526 08:57:32.327682  6929 solver.cpp:237] Iteration 888000, loss = 2.62735
I0526 08:57:32.327718  6929 solver.cpp:253]     Train net output #0: loss = 2.62734 (* 1 = 2.62734 loss)
I0526 08:57:32.327733  6929 sgd_solver.cpp:106] Iteration 888000, lr = 0.003
I0526 08:57:49.187242  6929 solver.cpp:237] Iteration 889500, loss = 1.03663
I0526 08:57:49.187410  6929 solver.cpp:253]     Train net output #0: loss = 1.03662 (* 1 = 1.03662 loss)
I0526 08:57:49.187424  6929 sgd_solver.cpp:106] Iteration 889500, lr = 0.003
I0526 08:58:26.866238  6929 solver.cpp:237] Iteration 891000, loss = 0.914877
I0526 08:58:26.866421  6929 solver.cpp:253]     Train net output #0: loss = 0.914869 (* 1 = 0.914869 loss)
I0526 08:58:26.866437  6929 sgd_solver.cpp:106] Iteration 891000, lr = 0.003
I0526 08:58:43.502300  6929 solver.cpp:237] Iteration 892500, loss = 1.67564
I0526 08:58:43.502346  6929 solver.cpp:253]     Train net output #0: loss = 1.67563 (* 1 = 1.67563 loss)
I0526 08:58:43.502359  6929 sgd_solver.cpp:106] Iteration 892500, lr = 0.003
I0526 08:59:00.115767  6929 solver.cpp:237] Iteration 894000, loss = 1.33844
I0526 08:59:00.115942  6929 solver.cpp:253]     Train net output #0: loss = 1.33843 (* 1 = 1.33843 loss)
I0526 08:59:00.115957  6929 sgd_solver.cpp:106] Iteration 894000, lr = 0.003
I0526 08:59:16.764188  6929 solver.cpp:237] Iteration 895500, loss = 1.50705
I0526 08:59:16.764224  6929 solver.cpp:253]     Train net output #0: loss = 1.50704 (* 1 = 1.50704 loss)
I0526 08:59:16.764237  6929 sgd_solver.cpp:106] Iteration 895500, lr = 0.003
I0526 08:59:33.381144  6929 solver.cpp:237] Iteration 897000, loss = 1.28038
I0526 08:59:33.381330  6929 solver.cpp:253]     Train net output #0: loss = 1.28038 (* 1 = 1.28038 loss)
I0526 08:59:33.381345  6929 sgd_solver.cpp:106] Iteration 897000, lr = 0.003
I0526 08:59:50.020995  6929 solver.cpp:237] Iteration 898500, loss = 0.853182
I0526 08:59:50.021044  6929 solver.cpp:253]     Train net output #0: loss = 0.853175 (* 1 = 0.853175 loss)
I0526 08:59:50.021059  6929 sgd_solver.cpp:106] Iteration 898500, lr = 0.003
I0526 09:00:06.729552  6929 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_900000.caffemodel
I0526 09:00:06.787506  6929 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_900000.solverstate
I0526 09:00:06.823076  6929 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 09:01:06.010685  6929 solver.cpp:409]     Test net output #0: accuracy = 0.898629
I0526 09:01:06.010886  6929 solver.cpp:409]     Test net output #1: loss = 0.336596 (* 1 = 0.336596 loss)
I0526 09:01:26.919359  6929 solver.cpp:237] Iteration 900000, loss = 1.28634
I0526 09:01:26.919411  6929 solver.cpp:253]     Train net output #0: loss = 1.28633 (* 1 = 1.28633 loss)
I0526 09:01:26.919428  6929 sgd_solver.cpp:106] Iteration 900000, lr = 0.003
I0526 09:01:43.787894  6929 solver.cpp:237] Iteration 901500, loss = 0.796533
I0526 09:01:43.788066  6929 solver.cpp:253]     Train net output #0: loss = 0.796524 (* 1 = 0.796524 loss)
I0526 09:01:43.788080  6929 sgd_solver.cpp:106] Iteration 901500, lr = 0.003
I0526 09:02:00.589682  6929 solver.cpp:237] Iteration 903000, loss = 1.40791
I0526 09:02:00.589731  6929 solver.cpp:253]     Train net output #0: loss = 1.40791 (* 1 = 1.40791 loss)
I0526 09:02:00.589745  6929 sgd_solver.cpp:106] Iteration 903000, lr = 0.003
=>> PBS: job killed: walltime 7213 exceeded limit 7200
aprun: Apid 11267228: Caught signal Terminated, sending to application
*** Aborted at 1464267720 (unix time) try "date -d @1464267720" if you are using GNU date ***
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
*** SIGTERM (@0x1b0e) received by PID 6929 (TID 0x2aaac746f900) from PID 6926; stack trace: ***
    @     0x2aaab7c78850 (unknown)
    @     0x2aaaaaaca834 ([vdso]+0x833)
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11267228: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11267228: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11267228: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
    @     0x2aaab7ea4c36 __libc_start_main
aprun: Apid 11267228: Caught signal Terminated, sending to application
    @           0x438669 (unknown)
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
aprun: Apid 11267228: Caught signal Terminated, sending to application
_pmiu_daemon(SIGCHLD): [NID 03791] [c8-1c0s7n1] [Thu May 26 09:02:02 2016] PE RANK 0 exit signal Terminated
Application 11267228 exit codes: 143
Application 11267228 resources: utime ~6298s, stime ~895s, Rss ~5329992, inblocks ~10491400, outblocks ~474918
