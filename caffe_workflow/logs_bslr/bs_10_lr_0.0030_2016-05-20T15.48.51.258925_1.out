2806828
I0521 15:39:27.327937  8221 caffe.cpp:184] Using GPUs 0
I0521 15:39:27.771935  8221 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.003
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925.prototxt"
I0521 15:39:27.773550  8221 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925.prototxt
I0521 15:39:27.795583  8221 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0521 15:39:27.795644  8221 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0521 15:39:27.796002  8221 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 15:39:27.796180  8221 layer_factory.hpp:77] Creating layer data_hdf5
I0521 15:39:27.796203  8221 net.cpp:106] Creating Layer data_hdf5
I0521 15:39:27.796217  8221 net.cpp:411] data_hdf5 -> data
I0521 15:39:27.796250  8221 net.cpp:411] data_hdf5 -> label
I0521 15:39:27.796283  8221 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0521 15:39:27.812479  8221 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0521 15:39:27.814698  8221 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 15:39:49.304841  8221 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0521 15:39:49.309958  8221 net.cpp:150] Setting up data_hdf5
I0521 15:39:49.309998  8221 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 15:39:49.310014  8221 net.cpp:157] Top shape: 10 (10)
I0521 15:39:49.310026  8221 net.cpp:165] Memory required for data: 254040
I0521 15:39:49.310039  8221 layer_factory.hpp:77] Creating layer conv1
I0521 15:39:49.310073  8221 net.cpp:106] Creating Layer conv1
I0521 15:39:49.310084  8221 net.cpp:454] conv1 <- data
I0521 15:39:49.310104  8221 net.cpp:411] conv1 -> conv1
I0521 15:39:50.373136  8221 net.cpp:150] Setting up conv1
I0521 15:39:50.373180  8221 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 15:39:50.373191  8221 net.cpp:165] Memory required for data: 3018840
I0521 15:39:50.373221  8221 layer_factory.hpp:77] Creating layer relu1
I0521 15:39:50.373242  8221 net.cpp:106] Creating Layer relu1
I0521 15:39:50.373253  8221 net.cpp:454] relu1 <- conv1
I0521 15:39:50.373266  8221 net.cpp:397] relu1 -> conv1 (in-place)
I0521 15:39:50.373790  8221 net.cpp:150] Setting up relu1
I0521 15:39:50.373805  8221 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 15:39:50.373816  8221 net.cpp:165] Memory required for data: 5783640
I0521 15:39:50.373826  8221 layer_factory.hpp:77] Creating layer pool1
I0521 15:39:50.373843  8221 net.cpp:106] Creating Layer pool1
I0521 15:39:50.373853  8221 net.cpp:454] pool1 <- conv1
I0521 15:39:50.373867  8221 net.cpp:411] pool1 -> pool1
I0521 15:39:50.373945  8221 net.cpp:150] Setting up pool1
I0521 15:39:50.373960  8221 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 15:39:50.373970  8221 net.cpp:165] Memory required for data: 7166040
I0521 15:39:50.373980  8221 layer_factory.hpp:77] Creating layer conv2
I0521 15:39:50.373998  8221 net.cpp:106] Creating Layer conv2
I0521 15:39:50.374009  8221 net.cpp:454] conv2 <- pool1
I0521 15:39:50.374023  8221 net.cpp:411] conv2 -> conv2
I0521 15:39:50.376721  8221 net.cpp:150] Setting up conv2
I0521 15:39:50.376749  8221 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 15:39:50.376760  8221 net.cpp:165] Memory required for data: 9153240
I0521 15:39:50.376780  8221 layer_factory.hpp:77] Creating layer relu2
I0521 15:39:50.376794  8221 net.cpp:106] Creating Layer relu2
I0521 15:39:50.376804  8221 net.cpp:454] relu2 <- conv2
I0521 15:39:50.376817  8221 net.cpp:397] relu2 -> conv2 (in-place)
I0521 15:39:50.377148  8221 net.cpp:150] Setting up relu2
I0521 15:39:50.377162  8221 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 15:39:50.377172  8221 net.cpp:165] Memory required for data: 11140440
I0521 15:39:50.377182  8221 layer_factory.hpp:77] Creating layer pool2
I0521 15:39:50.377194  8221 net.cpp:106] Creating Layer pool2
I0521 15:39:50.377204  8221 net.cpp:454] pool2 <- conv2
I0521 15:39:50.377216  8221 net.cpp:411] pool2 -> pool2
I0521 15:39:50.377296  8221 net.cpp:150] Setting up pool2
I0521 15:39:50.377310  8221 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 15:39:50.377321  8221 net.cpp:165] Memory required for data: 12134040
I0521 15:39:50.377331  8221 layer_factory.hpp:77] Creating layer conv3
I0521 15:39:50.377349  8221 net.cpp:106] Creating Layer conv3
I0521 15:39:50.377359  8221 net.cpp:454] conv3 <- pool2
I0521 15:39:50.377372  8221 net.cpp:411] conv3 -> conv3
I0521 15:39:50.379467  8221 net.cpp:150] Setting up conv3
I0521 15:39:50.379490  8221 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 15:39:50.379503  8221 net.cpp:165] Memory required for data: 13218200
I0521 15:39:50.379521  8221 layer_factory.hpp:77] Creating layer relu3
I0521 15:39:50.379537  8221 net.cpp:106] Creating Layer relu3
I0521 15:39:50.379547  8221 net.cpp:454] relu3 <- conv3
I0521 15:39:50.379559  8221 net.cpp:397] relu3 -> conv3 (in-place)
I0521 15:39:50.380038  8221 net.cpp:150] Setting up relu3
I0521 15:39:50.380056  8221 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 15:39:50.380066  8221 net.cpp:165] Memory required for data: 14302360
I0521 15:39:50.380076  8221 layer_factory.hpp:77] Creating layer pool3
I0521 15:39:50.380089  8221 net.cpp:106] Creating Layer pool3
I0521 15:39:50.380100  8221 net.cpp:454] pool3 <- conv3
I0521 15:39:50.380111  8221 net.cpp:411] pool3 -> pool3
I0521 15:39:50.380179  8221 net.cpp:150] Setting up pool3
I0521 15:39:50.380192  8221 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 15:39:50.380203  8221 net.cpp:165] Memory required for data: 14844440
I0521 15:39:50.380213  8221 layer_factory.hpp:77] Creating layer conv4
I0521 15:39:50.380228  8221 net.cpp:106] Creating Layer conv4
I0521 15:39:50.380239  8221 net.cpp:454] conv4 <- pool3
I0521 15:39:50.380252  8221 net.cpp:411] conv4 -> conv4
I0521 15:39:50.382968  8221 net.cpp:150] Setting up conv4
I0521 15:39:50.382997  8221 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 15:39:50.383007  8221 net.cpp:165] Memory required for data: 15207320
I0521 15:39:50.383023  8221 layer_factory.hpp:77] Creating layer relu4
I0521 15:39:50.383036  8221 net.cpp:106] Creating Layer relu4
I0521 15:39:50.383046  8221 net.cpp:454] relu4 <- conv4
I0521 15:39:50.383059  8221 net.cpp:397] relu4 -> conv4 (in-place)
I0521 15:39:50.383525  8221 net.cpp:150] Setting up relu4
I0521 15:39:50.383541  8221 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 15:39:50.383551  8221 net.cpp:165] Memory required for data: 15570200
I0521 15:39:50.383563  8221 layer_factory.hpp:77] Creating layer pool4
I0521 15:39:50.383574  8221 net.cpp:106] Creating Layer pool4
I0521 15:39:50.383584  8221 net.cpp:454] pool4 <- conv4
I0521 15:39:50.383597  8221 net.cpp:411] pool4 -> pool4
I0521 15:39:50.383666  8221 net.cpp:150] Setting up pool4
I0521 15:39:50.383678  8221 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 15:39:50.383688  8221 net.cpp:165] Memory required for data: 15751640
I0521 15:39:50.383698  8221 layer_factory.hpp:77] Creating layer ip1
I0521 15:39:50.383718  8221 net.cpp:106] Creating Layer ip1
I0521 15:39:50.383728  8221 net.cpp:454] ip1 <- pool4
I0521 15:39:50.383740  8221 net.cpp:411] ip1 -> ip1
I0521 15:39:50.399163  8221 net.cpp:150] Setting up ip1
I0521 15:39:50.399191  8221 net.cpp:157] Top shape: 10 196 (1960)
I0521 15:39:50.399206  8221 net.cpp:165] Memory required for data: 15759480
I0521 15:39:50.399230  8221 layer_factory.hpp:77] Creating layer relu5
I0521 15:39:50.399245  8221 net.cpp:106] Creating Layer relu5
I0521 15:39:50.399255  8221 net.cpp:454] relu5 <- ip1
I0521 15:39:50.399266  8221 net.cpp:397] relu5 -> ip1 (in-place)
I0521 15:39:50.399611  8221 net.cpp:150] Setting up relu5
I0521 15:39:50.399624  8221 net.cpp:157] Top shape: 10 196 (1960)
I0521 15:39:50.399634  8221 net.cpp:165] Memory required for data: 15767320
I0521 15:39:50.399646  8221 layer_factory.hpp:77] Creating layer drop1
I0521 15:39:50.399667  8221 net.cpp:106] Creating Layer drop1
I0521 15:39:50.399677  8221 net.cpp:454] drop1 <- ip1
I0521 15:39:50.399689  8221 net.cpp:397] drop1 -> ip1 (in-place)
I0521 15:39:50.399749  8221 net.cpp:150] Setting up drop1
I0521 15:39:50.399762  8221 net.cpp:157] Top shape: 10 196 (1960)
I0521 15:39:50.399772  8221 net.cpp:165] Memory required for data: 15775160
I0521 15:39:50.399782  8221 layer_factory.hpp:77] Creating layer ip2
I0521 15:39:50.399801  8221 net.cpp:106] Creating Layer ip2
I0521 15:39:50.399817  8221 net.cpp:454] ip2 <- ip1
I0521 15:39:50.399830  8221 net.cpp:411] ip2 -> ip2
I0521 15:39:50.400295  8221 net.cpp:150] Setting up ip2
I0521 15:39:50.400308  8221 net.cpp:157] Top shape: 10 98 (980)
I0521 15:39:50.400318  8221 net.cpp:165] Memory required for data: 15779080
I0521 15:39:50.400334  8221 layer_factory.hpp:77] Creating layer relu6
I0521 15:39:50.400346  8221 net.cpp:106] Creating Layer relu6
I0521 15:39:50.400355  8221 net.cpp:454] relu6 <- ip2
I0521 15:39:50.400367  8221 net.cpp:397] relu6 -> ip2 (in-place)
I0521 15:39:50.400890  8221 net.cpp:150] Setting up relu6
I0521 15:39:50.400907  8221 net.cpp:157] Top shape: 10 98 (980)
I0521 15:39:50.400916  8221 net.cpp:165] Memory required for data: 15783000
I0521 15:39:50.400926  8221 layer_factory.hpp:77] Creating layer drop2
I0521 15:39:50.400938  8221 net.cpp:106] Creating Layer drop2
I0521 15:39:50.400949  8221 net.cpp:454] drop2 <- ip2
I0521 15:39:50.400960  8221 net.cpp:397] drop2 -> ip2 (in-place)
I0521 15:39:50.401002  8221 net.cpp:150] Setting up drop2
I0521 15:39:50.401015  8221 net.cpp:157] Top shape: 10 98 (980)
I0521 15:39:50.401026  8221 net.cpp:165] Memory required for data: 15786920
I0521 15:39:50.401036  8221 layer_factory.hpp:77] Creating layer ip3
I0521 15:39:50.401048  8221 net.cpp:106] Creating Layer ip3
I0521 15:39:50.401057  8221 net.cpp:454] ip3 <- ip2
I0521 15:39:50.401070  8221 net.cpp:411] ip3 -> ip3
I0521 15:39:50.401278  8221 net.cpp:150] Setting up ip3
I0521 15:39:50.401289  8221 net.cpp:157] Top shape: 10 11 (110)
I0521 15:39:50.401299  8221 net.cpp:165] Memory required for data: 15787360
I0521 15:39:50.401314  8221 layer_factory.hpp:77] Creating layer drop3
I0521 15:39:50.401326  8221 net.cpp:106] Creating Layer drop3
I0521 15:39:50.401337  8221 net.cpp:454] drop3 <- ip3
I0521 15:39:50.401350  8221 net.cpp:397] drop3 -> ip3 (in-place)
I0521 15:39:50.401388  8221 net.cpp:150] Setting up drop3
I0521 15:39:50.401401  8221 net.cpp:157] Top shape: 10 11 (110)
I0521 15:39:50.401410  8221 net.cpp:165] Memory required for data: 15787800
I0521 15:39:50.401420  8221 layer_factory.hpp:77] Creating layer loss
I0521 15:39:50.401439  8221 net.cpp:106] Creating Layer loss
I0521 15:39:50.401449  8221 net.cpp:454] loss <- ip3
I0521 15:39:50.401460  8221 net.cpp:454] loss <- label
I0521 15:39:50.401473  8221 net.cpp:411] loss -> loss
I0521 15:39:50.401489  8221 layer_factory.hpp:77] Creating layer loss
I0521 15:39:50.402127  8221 net.cpp:150] Setting up loss
I0521 15:39:50.402142  8221 net.cpp:157] Top shape: (1)
I0521 15:39:50.402156  8221 net.cpp:160]     with loss weight 1
I0521 15:39:50.402199  8221 net.cpp:165] Memory required for data: 15787804
I0521 15:39:50.402209  8221 net.cpp:226] loss needs backward computation.
I0521 15:39:50.402220  8221 net.cpp:226] drop3 needs backward computation.
I0521 15:39:50.402228  8221 net.cpp:226] ip3 needs backward computation.
I0521 15:39:50.402238  8221 net.cpp:226] drop2 needs backward computation.
I0521 15:39:50.402248  8221 net.cpp:226] relu6 needs backward computation.
I0521 15:39:50.402258  8221 net.cpp:226] ip2 needs backward computation.
I0521 15:39:50.402268  8221 net.cpp:226] drop1 needs backward computation.
I0521 15:39:50.402277  8221 net.cpp:226] relu5 needs backward computation.
I0521 15:39:50.402287  8221 net.cpp:226] ip1 needs backward computation.
I0521 15:39:50.402297  8221 net.cpp:226] pool4 needs backward computation.
I0521 15:39:50.402307  8221 net.cpp:226] relu4 needs backward computation.
I0521 15:39:50.402318  8221 net.cpp:226] conv4 needs backward computation.
I0521 15:39:50.402328  8221 net.cpp:226] pool3 needs backward computation.
I0521 15:39:50.402338  8221 net.cpp:226] relu3 needs backward computation.
I0521 15:39:50.402348  8221 net.cpp:226] conv3 needs backward computation.
I0521 15:39:50.402366  8221 net.cpp:226] pool2 needs backward computation.
I0521 15:39:50.402377  8221 net.cpp:226] relu2 needs backward computation.
I0521 15:39:50.402387  8221 net.cpp:226] conv2 needs backward computation.
I0521 15:39:50.402398  8221 net.cpp:226] pool1 needs backward computation.
I0521 15:39:50.402408  8221 net.cpp:226] relu1 needs backward computation.
I0521 15:39:50.402418  8221 net.cpp:226] conv1 needs backward computation.
I0521 15:39:50.402429  8221 net.cpp:228] data_hdf5 does not need backward computation.
I0521 15:39:50.402439  8221 net.cpp:270] This network produces output loss
I0521 15:39:50.402462  8221 net.cpp:283] Network initialization done.
I0521 15:39:50.404132  8221 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925.prototxt
I0521 15:39:50.404204  8221 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0521 15:39:50.404556  8221 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0521 15:39:50.404744  8221 layer_factory.hpp:77] Creating layer data_hdf5
I0521 15:39:50.404759  8221 net.cpp:106] Creating Layer data_hdf5
I0521 15:39:50.404772  8221 net.cpp:411] data_hdf5 -> data
I0521 15:39:50.404788  8221 net.cpp:411] data_hdf5 -> label
I0521 15:39:50.404803  8221 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0521 15:39:50.406101  8221 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0521 15:40:11.779224  8221 net.cpp:150] Setting up data_hdf5
I0521 15:40:11.779387  8221 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0521 15:40:11.779402  8221 net.cpp:157] Top shape: 10 (10)
I0521 15:40:11.779417  8221 net.cpp:165] Memory required for data: 254040
I0521 15:40:11.779429  8221 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0521 15:40:11.779458  8221 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0521 15:40:11.779467  8221 net.cpp:454] label_data_hdf5_1_split <- label
I0521 15:40:11.779482  8221 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0521 15:40:11.779503  8221 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0521 15:40:11.779577  8221 net.cpp:150] Setting up label_data_hdf5_1_split
I0521 15:40:11.779590  8221 net.cpp:157] Top shape: 10 (10)
I0521 15:40:11.779603  8221 net.cpp:157] Top shape: 10 (10)
I0521 15:40:11.779611  8221 net.cpp:165] Memory required for data: 254120
I0521 15:40:11.779621  8221 layer_factory.hpp:77] Creating layer conv1
I0521 15:40:11.779644  8221 net.cpp:106] Creating Layer conv1
I0521 15:40:11.779654  8221 net.cpp:454] conv1 <- data
I0521 15:40:11.779670  8221 net.cpp:411] conv1 -> conv1
I0521 15:40:11.781646  8221 net.cpp:150] Setting up conv1
I0521 15:40:11.781672  8221 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 15:40:11.781682  8221 net.cpp:165] Memory required for data: 3018920
I0521 15:40:11.781702  8221 layer_factory.hpp:77] Creating layer relu1
I0521 15:40:11.781716  8221 net.cpp:106] Creating Layer relu1
I0521 15:40:11.781726  8221 net.cpp:454] relu1 <- conv1
I0521 15:40:11.781739  8221 net.cpp:397] relu1 -> conv1 (in-place)
I0521 15:40:11.782245  8221 net.cpp:150] Setting up relu1
I0521 15:40:11.782261  8221 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0521 15:40:11.782271  8221 net.cpp:165] Memory required for data: 5783720
I0521 15:40:11.782281  8221 layer_factory.hpp:77] Creating layer pool1
I0521 15:40:11.782297  8221 net.cpp:106] Creating Layer pool1
I0521 15:40:11.782307  8221 net.cpp:454] pool1 <- conv1
I0521 15:40:11.782320  8221 net.cpp:411] pool1 -> pool1
I0521 15:40:11.782395  8221 net.cpp:150] Setting up pool1
I0521 15:40:11.782408  8221 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0521 15:40:11.782418  8221 net.cpp:165] Memory required for data: 7166120
I0521 15:40:11.782426  8221 layer_factory.hpp:77] Creating layer conv2
I0521 15:40:11.782444  8221 net.cpp:106] Creating Layer conv2
I0521 15:40:11.782454  8221 net.cpp:454] conv2 <- pool1
I0521 15:40:11.782469  8221 net.cpp:411] conv2 -> conv2
I0521 15:40:11.784396  8221 net.cpp:150] Setting up conv2
I0521 15:40:11.784418  8221 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 15:40:11.784430  8221 net.cpp:165] Memory required for data: 9153320
I0521 15:40:11.784448  8221 layer_factory.hpp:77] Creating layer relu2
I0521 15:40:11.784462  8221 net.cpp:106] Creating Layer relu2
I0521 15:40:11.784472  8221 net.cpp:454] relu2 <- conv2
I0521 15:40:11.784484  8221 net.cpp:397] relu2 -> conv2 (in-place)
I0521 15:40:11.784821  8221 net.cpp:150] Setting up relu2
I0521 15:40:11.784833  8221 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0521 15:40:11.784844  8221 net.cpp:165] Memory required for data: 11140520
I0521 15:40:11.784854  8221 layer_factory.hpp:77] Creating layer pool2
I0521 15:40:11.784868  8221 net.cpp:106] Creating Layer pool2
I0521 15:40:11.784878  8221 net.cpp:454] pool2 <- conv2
I0521 15:40:11.784889  8221 net.cpp:411] pool2 -> pool2
I0521 15:40:11.784962  8221 net.cpp:150] Setting up pool2
I0521 15:40:11.784976  8221 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0521 15:40:11.784986  8221 net.cpp:165] Memory required for data: 12134120
I0521 15:40:11.784996  8221 layer_factory.hpp:77] Creating layer conv3
I0521 15:40:11.785012  8221 net.cpp:106] Creating Layer conv3
I0521 15:40:11.785022  8221 net.cpp:454] conv3 <- pool2
I0521 15:40:11.785037  8221 net.cpp:411] conv3 -> conv3
I0521 15:40:11.787035  8221 net.cpp:150] Setting up conv3
I0521 15:40:11.787058  8221 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 15:40:11.787070  8221 net.cpp:165] Memory required for data: 13218280
I0521 15:40:11.787088  8221 layer_factory.hpp:77] Creating layer relu3
I0521 15:40:11.787114  8221 net.cpp:106] Creating Layer relu3
I0521 15:40:11.787124  8221 net.cpp:454] relu3 <- conv3
I0521 15:40:11.787138  8221 net.cpp:397] relu3 -> conv3 (in-place)
I0521 15:40:11.787611  8221 net.cpp:150] Setting up relu3
I0521 15:40:11.787627  8221 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0521 15:40:11.787637  8221 net.cpp:165] Memory required for data: 14302440
I0521 15:40:11.787647  8221 layer_factory.hpp:77] Creating layer pool3
I0521 15:40:11.787660  8221 net.cpp:106] Creating Layer pool3
I0521 15:40:11.787670  8221 net.cpp:454] pool3 <- conv3
I0521 15:40:11.787683  8221 net.cpp:411] pool3 -> pool3
I0521 15:40:11.787755  8221 net.cpp:150] Setting up pool3
I0521 15:40:11.787768  8221 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0521 15:40:11.787778  8221 net.cpp:165] Memory required for data: 14844520
I0521 15:40:11.787787  8221 layer_factory.hpp:77] Creating layer conv4
I0521 15:40:11.787803  8221 net.cpp:106] Creating Layer conv4
I0521 15:40:11.787822  8221 net.cpp:454] conv4 <- pool3
I0521 15:40:11.787837  8221 net.cpp:411] conv4 -> conv4
I0521 15:40:11.789901  8221 net.cpp:150] Setting up conv4
I0521 15:40:11.789918  8221 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 15:40:11.789929  8221 net.cpp:165] Memory required for data: 15207400
I0521 15:40:11.789944  8221 layer_factory.hpp:77] Creating layer relu4
I0521 15:40:11.789958  8221 net.cpp:106] Creating Layer relu4
I0521 15:40:11.789968  8221 net.cpp:454] relu4 <- conv4
I0521 15:40:11.789980  8221 net.cpp:397] relu4 -> conv4 (in-place)
I0521 15:40:11.790447  8221 net.cpp:150] Setting up relu4
I0521 15:40:11.790463  8221 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0521 15:40:11.790473  8221 net.cpp:165] Memory required for data: 15570280
I0521 15:40:11.790483  8221 layer_factory.hpp:77] Creating layer pool4
I0521 15:40:11.790496  8221 net.cpp:106] Creating Layer pool4
I0521 15:40:11.790506  8221 net.cpp:454] pool4 <- conv4
I0521 15:40:11.790518  8221 net.cpp:411] pool4 -> pool4
I0521 15:40:11.790590  8221 net.cpp:150] Setting up pool4
I0521 15:40:11.790601  8221 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0521 15:40:11.790611  8221 net.cpp:165] Memory required for data: 15751720
I0521 15:40:11.790621  8221 layer_factory.hpp:77] Creating layer ip1
I0521 15:40:11.790635  8221 net.cpp:106] Creating Layer ip1
I0521 15:40:11.790645  8221 net.cpp:454] ip1 <- pool4
I0521 15:40:11.790659  8221 net.cpp:411] ip1 -> ip1
I0521 15:40:11.806124  8221 net.cpp:150] Setting up ip1
I0521 15:40:11.806154  8221 net.cpp:157] Top shape: 10 196 (1960)
I0521 15:40:11.806164  8221 net.cpp:165] Memory required for data: 15759560
I0521 15:40:11.806186  8221 layer_factory.hpp:77] Creating layer relu5
I0521 15:40:11.806201  8221 net.cpp:106] Creating Layer relu5
I0521 15:40:11.806211  8221 net.cpp:454] relu5 <- ip1
I0521 15:40:11.806224  8221 net.cpp:397] relu5 -> ip1 (in-place)
I0521 15:40:11.806573  8221 net.cpp:150] Setting up relu5
I0521 15:40:11.806587  8221 net.cpp:157] Top shape: 10 196 (1960)
I0521 15:40:11.806596  8221 net.cpp:165] Memory required for data: 15767400
I0521 15:40:11.806607  8221 layer_factory.hpp:77] Creating layer drop1
I0521 15:40:11.806625  8221 net.cpp:106] Creating Layer drop1
I0521 15:40:11.806635  8221 net.cpp:454] drop1 <- ip1
I0521 15:40:11.806648  8221 net.cpp:397] drop1 -> ip1 (in-place)
I0521 15:40:11.806694  8221 net.cpp:150] Setting up drop1
I0521 15:40:11.806706  8221 net.cpp:157] Top shape: 10 196 (1960)
I0521 15:40:11.806718  8221 net.cpp:165] Memory required for data: 15775240
I0521 15:40:11.806727  8221 layer_factory.hpp:77] Creating layer ip2
I0521 15:40:11.806742  8221 net.cpp:106] Creating Layer ip2
I0521 15:40:11.806752  8221 net.cpp:454] ip2 <- ip1
I0521 15:40:11.806766  8221 net.cpp:411] ip2 -> ip2
I0521 15:40:11.807242  8221 net.cpp:150] Setting up ip2
I0521 15:40:11.807255  8221 net.cpp:157] Top shape: 10 98 (980)
I0521 15:40:11.807265  8221 net.cpp:165] Memory required for data: 15779160
I0521 15:40:11.807281  8221 layer_factory.hpp:77] Creating layer relu6
I0521 15:40:11.807306  8221 net.cpp:106] Creating Layer relu6
I0521 15:40:11.807315  8221 net.cpp:454] relu6 <- ip2
I0521 15:40:11.807328  8221 net.cpp:397] relu6 -> ip2 (in-place)
I0521 15:40:11.807878  8221 net.cpp:150] Setting up relu6
I0521 15:40:11.807898  8221 net.cpp:157] Top shape: 10 98 (980)
I0521 15:40:11.807909  8221 net.cpp:165] Memory required for data: 15783080
I0521 15:40:11.807917  8221 layer_factory.hpp:77] Creating layer drop2
I0521 15:40:11.807931  8221 net.cpp:106] Creating Layer drop2
I0521 15:40:11.807941  8221 net.cpp:454] drop2 <- ip2
I0521 15:40:11.807955  8221 net.cpp:397] drop2 -> ip2 (in-place)
I0521 15:40:11.807998  8221 net.cpp:150] Setting up drop2
I0521 15:40:11.808012  8221 net.cpp:157] Top shape: 10 98 (980)
I0521 15:40:11.808022  8221 net.cpp:165] Memory required for data: 15787000
I0521 15:40:11.808032  8221 layer_factory.hpp:77] Creating layer ip3
I0521 15:40:11.808046  8221 net.cpp:106] Creating Layer ip3
I0521 15:40:11.808056  8221 net.cpp:454] ip3 <- ip2
I0521 15:40:11.808070  8221 net.cpp:411] ip3 -> ip3
I0521 15:40:11.808290  8221 net.cpp:150] Setting up ip3
I0521 15:40:11.808303  8221 net.cpp:157] Top shape: 10 11 (110)
I0521 15:40:11.808313  8221 net.cpp:165] Memory required for data: 15787440
I0521 15:40:11.808328  8221 layer_factory.hpp:77] Creating layer drop3
I0521 15:40:11.808342  8221 net.cpp:106] Creating Layer drop3
I0521 15:40:11.808352  8221 net.cpp:454] drop3 <- ip3
I0521 15:40:11.808364  8221 net.cpp:397] drop3 -> ip3 (in-place)
I0521 15:40:11.808405  8221 net.cpp:150] Setting up drop3
I0521 15:40:11.808418  8221 net.cpp:157] Top shape: 10 11 (110)
I0521 15:40:11.808429  8221 net.cpp:165] Memory required for data: 15787880
I0521 15:40:11.808437  8221 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0521 15:40:11.808451  8221 net.cpp:106] Creating Layer ip3_drop3_0_split
I0521 15:40:11.808461  8221 net.cpp:454] ip3_drop3_0_split <- ip3
I0521 15:40:11.808473  8221 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0521 15:40:11.808488  8221 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0521 15:40:11.808562  8221 net.cpp:150] Setting up ip3_drop3_0_split
I0521 15:40:11.808574  8221 net.cpp:157] Top shape: 10 11 (110)
I0521 15:40:11.808586  8221 net.cpp:157] Top shape: 10 11 (110)
I0521 15:40:11.808596  8221 net.cpp:165] Memory required for data: 15788760
I0521 15:40:11.808604  8221 layer_factory.hpp:77] Creating layer accuracy
I0521 15:40:11.808625  8221 net.cpp:106] Creating Layer accuracy
I0521 15:40:11.808636  8221 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0521 15:40:11.808647  8221 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0521 15:40:11.808660  8221 net.cpp:411] accuracy -> accuracy
I0521 15:40:11.808684  8221 net.cpp:150] Setting up accuracy
I0521 15:40:11.808696  8221 net.cpp:157] Top shape: (1)
I0521 15:40:11.808706  8221 net.cpp:165] Memory required for data: 15788764
I0521 15:40:11.808717  8221 layer_factory.hpp:77] Creating layer loss
I0521 15:40:11.808730  8221 net.cpp:106] Creating Layer loss
I0521 15:40:11.808740  8221 net.cpp:454] loss <- ip3_drop3_0_split_1
I0521 15:40:11.808751  8221 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0521 15:40:11.808763  8221 net.cpp:411] loss -> loss
I0521 15:40:11.808781  8221 layer_factory.hpp:77] Creating layer loss
I0521 15:40:11.809264  8221 net.cpp:150] Setting up loss
I0521 15:40:11.809278  8221 net.cpp:157] Top shape: (1)
I0521 15:40:11.809288  8221 net.cpp:160]     with loss weight 1
I0521 15:40:11.809305  8221 net.cpp:165] Memory required for data: 15788768
I0521 15:40:11.809316  8221 net.cpp:226] loss needs backward computation.
I0521 15:40:11.809327  8221 net.cpp:228] accuracy does not need backward computation.
I0521 15:40:11.809339  8221 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0521 15:40:11.809350  8221 net.cpp:226] drop3 needs backward computation.
I0521 15:40:11.809360  8221 net.cpp:226] ip3 needs backward computation.
I0521 15:40:11.809370  8221 net.cpp:226] drop2 needs backward computation.
I0521 15:40:11.809381  8221 net.cpp:226] relu6 needs backward computation.
I0521 15:40:11.809398  8221 net.cpp:226] ip2 needs backward computation.
I0521 15:40:11.809408  8221 net.cpp:226] drop1 needs backward computation.
I0521 15:40:11.809418  8221 net.cpp:226] relu5 needs backward computation.
I0521 15:40:11.809427  8221 net.cpp:226] ip1 needs backward computation.
I0521 15:40:11.809437  8221 net.cpp:226] pool4 needs backward computation.
I0521 15:40:11.809448  8221 net.cpp:226] relu4 needs backward computation.
I0521 15:40:11.809458  8221 net.cpp:226] conv4 needs backward computation.
I0521 15:40:11.809468  8221 net.cpp:226] pool3 needs backward computation.
I0521 15:40:11.809479  8221 net.cpp:226] relu3 needs backward computation.
I0521 15:40:11.809489  8221 net.cpp:226] conv3 needs backward computation.
I0521 15:40:11.809499  8221 net.cpp:226] pool2 needs backward computation.
I0521 15:40:11.809509  8221 net.cpp:226] relu2 needs backward computation.
I0521 15:40:11.809520  8221 net.cpp:226] conv2 needs backward computation.
I0521 15:40:11.809530  8221 net.cpp:226] pool1 needs backward computation.
I0521 15:40:11.809540  8221 net.cpp:226] relu1 needs backward computation.
I0521 15:40:11.809551  8221 net.cpp:226] conv1 needs backward computation.
I0521 15:40:11.809561  8221 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0521 15:40:11.809573  8221 net.cpp:228] data_hdf5 does not need backward computation.
I0521 15:40:11.809582  8221 net.cpp:270] This network produces output accuracy
I0521 15:40:11.809593  8221 net.cpp:270] This network produces output loss
I0521 15:40:11.809622  8221 net.cpp:283] Network initialization done.
I0521 15:40:11.809756  8221 solver.cpp:60] Solver scaffolding done.
I0521 15:40:11.810892  8221 caffe.cpp:212] Starting Optimization
I0521 15:40:11.810910  8221 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0521 15:40:11.810925  8221 solver.cpp:289] Learning Rate Policy: fixed
I0521 15:40:11.812002  8221 solver.cpp:341] Iteration 0, Testing net (#0)
I0521 15:41:12.282981  8221 solver.cpp:409]     Test net output #0: accuracy = 0.0922006
I0521 15:41:12.283139  8221 solver.cpp:409]     Test net output #1: loss = 2.39656 (* 1 = 2.39656 loss)
I0521 15:41:12.300897  8221 solver.cpp:237] Iteration 0, loss = 2.39072
I0521 15:41:12.300933  8221 solver.cpp:253]     Train net output #0: loss = 2.39072 (* 1 = 2.39072 loss)
I0521 15:41:12.300951  8221 sgd_solver.cpp:106] Iteration 0, lr = 0.003
I0521 15:41:29.058217  8221 solver.cpp:237] Iteration 1500, loss = 2.048
I0521 15:41:29.058264  8221 solver.cpp:253]     Train net output #0: loss = 2.048 (* 1 = 2.048 loss)
I0521 15:41:29.058281  8221 sgd_solver.cpp:106] Iteration 1500, lr = 0.003
I0521 15:41:45.810132  8221 solver.cpp:237] Iteration 3000, loss = 1.95707
I0521 15:41:45.810292  8221 solver.cpp:253]     Train net output #0: loss = 1.95707 (* 1 = 1.95707 loss)
I0521 15:41:45.810307  8221 sgd_solver.cpp:106] Iteration 3000, lr = 0.003
I0521 15:42:02.601833  8221 solver.cpp:237] Iteration 4500, loss = 1.19457
I0521 15:42:02.601871  8221 solver.cpp:253]     Train net output #0: loss = 1.19457 (* 1 = 1.19457 loss)
I0521 15:42:02.601884  8221 sgd_solver.cpp:106] Iteration 4500, lr = 0.003
I0521 15:42:19.385066  8221 solver.cpp:237] Iteration 6000, loss = 1.61781
I0521 15:42:19.385218  8221 solver.cpp:253]     Train net output #0: loss = 1.61781 (* 1 = 1.61781 loss)
I0521 15:42:19.385233  8221 sgd_solver.cpp:106] Iteration 6000, lr = 0.003
I0521 15:42:36.161037  8221 solver.cpp:237] Iteration 7500, loss = 1.68387
I0521 15:42:36.161077  8221 solver.cpp:253]     Train net output #0: loss = 1.68387 (* 1 = 1.68387 loss)
I0521 15:42:36.161098  8221 sgd_solver.cpp:106] Iteration 7500, lr = 0.003
I0521 15:42:52.915037  8221 solver.cpp:237] Iteration 9000, loss = 1.30757
I0521 15:42:52.915170  8221 solver.cpp:253]     Train net output #0: loss = 1.30757 (* 1 = 1.30757 loss)
I0521 15:42:52.915184  8221 sgd_solver.cpp:106] Iteration 9000, lr = 0.003
I0521 15:43:31.757645  8221 solver.cpp:237] Iteration 10500, loss = 1.35738
I0521 15:43:31.757803  8221 solver.cpp:253]     Train net output #0: loss = 1.35738 (* 1 = 1.35738 loss)
I0521 15:43:31.757817  8221 sgd_solver.cpp:106] Iteration 10500, lr = 0.003
I0521 15:43:48.525044  8221 solver.cpp:237] Iteration 12000, loss = 1.36965
I0521 15:43:48.525081  8221 solver.cpp:253]     Train net output #0: loss = 1.36965 (* 1 = 1.36965 loss)
I0521 15:43:48.525096  8221 sgd_solver.cpp:106] Iteration 12000, lr = 0.003
I0521 15:44:05.257779  8221 solver.cpp:237] Iteration 13500, loss = 1.79228
I0521 15:44:05.257926  8221 solver.cpp:253]     Train net output #0: loss = 1.79228 (* 1 = 1.79228 loss)
I0521 15:44:05.257941  8221 sgd_solver.cpp:106] Iteration 13500, lr = 0.003
I0521 15:44:22.018705  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_15000.caffemodel
I0521 15:44:22.068186  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_15000.solverstate
I0521 15:44:22.096949  8221 solver.cpp:237] Iteration 15000, loss = 1.16149
I0521 15:44:22.096993  8221 solver.cpp:253]     Train net output #0: loss = 1.16149 (* 1 = 1.16149 loss)
I0521 15:44:22.097007  8221 sgd_solver.cpp:106] Iteration 15000, lr = 0.003
I0521 15:44:38.840454  8221 solver.cpp:237] Iteration 16500, loss = 1.35647
I0521 15:44:38.851269  8221 solver.cpp:253]     Train net output #0: loss = 1.35647 (* 1 = 1.35647 loss)
I0521 15:44:38.851284  8221 sgd_solver.cpp:106] Iteration 16500, lr = 0.003
I0521 15:44:55.617188  8221 solver.cpp:237] Iteration 18000, loss = 0.849795
I0521 15:44:55.617226  8221 solver.cpp:253]     Train net output #0: loss = 0.849795 (* 1 = 0.849795 loss)
I0521 15:44:55.617244  8221 sgd_solver.cpp:106] Iteration 18000, lr = 0.003
I0521 15:45:12.401386  8221 solver.cpp:237] Iteration 19500, loss = 1.94445
I0521 15:45:12.401531  8221 solver.cpp:253]     Train net output #0: loss = 1.94445 (* 1 = 1.94445 loss)
I0521 15:45:12.401546  8221 sgd_solver.cpp:106] Iteration 19500, lr = 0.003
I0521 15:45:51.318153  8221 solver.cpp:237] Iteration 21000, loss = 1.53282
I0521 15:45:51.318315  8221 solver.cpp:253]     Train net output #0: loss = 1.53282 (* 1 = 1.53282 loss)
I0521 15:45:51.318331  8221 sgd_solver.cpp:106] Iteration 21000, lr = 0.003
I0521 15:46:08.080797  8221 solver.cpp:237] Iteration 22500, loss = 1.33965
I0521 15:46:08.080845  8221 solver.cpp:253]     Train net output #0: loss = 1.33965 (* 1 = 1.33965 loss)
I0521 15:46:08.080860  8221 sgd_solver.cpp:106] Iteration 22500, lr = 0.003
I0521 15:46:24.871685  8221 solver.cpp:237] Iteration 24000, loss = 1.43662
I0521 15:46:24.871860  8221 solver.cpp:253]     Train net output #0: loss = 1.43662 (* 1 = 1.43662 loss)
I0521 15:46:24.871876  8221 sgd_solver.cpp:106] Iteration 24000, lr = 0.003
I0521 15:46:41.633077  8221 solver.cpp:237] Iteration 25500, loss = 0.769772
I0521 15:46:41.633113  8221 solver.cpp:253]     Train net output #0: loss = 0.769771 (* 1 = 0.769771 loss)
I0521 15:46:41.633127  8221 sgd_solver.cpp:106] Iteration 25500, lr = 0.003
I0521 15:46:58.400725  8221 solver.cpp:237] Iteration 27000, loss = 1.42373
I0521 15:46:58.400882  8221 solver.cpp:253]     Train net output #0: loss = 1.42373 (* 1 = 1.42373 loss)
I0521 15:46:58.400897  8221 sgd_solver.cpp:106] Iteration 27000, lr = 0.003
I0521 15:47:15.157805  8221 solver.cpp:237] Iteration 28500, loss = 1.1327
I0521 15:47:15.157851  8221 solver.cpp:253]     Train net output #0: loss = 1.1327 (* 1 = 1.1327 loss)
I0521 15:47:15.157867  8221 sgd_solver.cpp:106] Iteration 28500, lr = 0.003
I0521 15:47:31.932860  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_30000.caffemodel
I0521 15:47:31.978554  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_30000.solverstate
I0521 15:47:32.004873  8221 solver.cpp:341] Iteration 30000, Testing net (#0)
I0521 15:48:31.453954  8221 solver.cpp:409]     Test net output #0: accuracy = 0.846657
I0521 15:48:31.454113  8221 solver.cpp:409]     Test net output #1: loss = 0.564549 (* 1 = 0.564549 loss)
I0521 15:48:53.541823  8221 solver.cpp:237] Iteration 30000, loss = 1.31156
I0521 15:48:53.541877  8221 solver.cpp:253]     Train net output #0: loss = 1.31156 (* 1 = 1.31156 loss)
I0521 15:48:53.541893  8221 sgd_solver.cpp:106] Iteration 30000, lr = 0.003
I0521 15:49:10.156738  8221 solver.cpp:237] Iteration 31500, loss = 0.970186
I0521 15:49:10.156888  8221 solver.cpp:253]     Train net output #0: loss = 0.970185 (* 1 = 0.970185 loss)
I0521 15:49:10.156900  8221 sgd_solver.cpp:106] Iteration 31500, lr = 0.003
I0521 15:49:26.788997  8221 solver.cpp:237] Iteration 33000, loss = 1.85161
I0521 15:49:26.789046  8221 solver.cpp:253]     Train net output #0: loss = 1.85161 (* 1 = 1.85161 loss)
I0521 15:49:26.789059  8221 sgd_solver.cpp:106] Iteration 33000, lr = 0.003
I0521 15:49:43.379050  8221 solver.cpp:237] Iteration 34500, loss = 1.40927
I0521 15:49:43.379202  8221 solver.cpp:253]     Train net output #0: loss = 1.40927 (* 1 = 1.40927 loss)
I0521 15:49:43.379217  8221 sgd_solver.cpp:106] Iteration 34500, lr = 0.003
I0521 15:49:59.992880  8221 solver.cpp:237] Iteration 36000, loss = 1.27026
I0521 15:49:59.992916  8221 solver.cpp:253]     Train net output #0: loss = 1.27026 (* 1 = 1.27026 loss)
I0521 15:49:59.992931  8221 sgd_solver.cpp:106] Iteration 36000, lr = 0.003
I0521 15:50:16.620486  8221 solver.cpp:237] Iteration 37500, loss = 1.60606
I0521 15:50:16.620635  8221 solver.cpp:253]     Train net output #0: loss = 1.60606 (* 1 = 1.60606 loss)
I0521 15:50:16.620648  8221 sgd_solver.cpp:106] Iteration 37500, lr = 0.003
I0521 15:50:33.229564  8221 solver.cpp:237] Iteration 39000, loss = 1.11118
I0521 15:50:33.229610  8221 solver.cpp:253]     Train net output #0: loss = 1.11118 (* 1 = 1.11118 loss)
I0521 15:50:33.229624  8221 sgd_solver.cpp:106] Iteration 39000, lr = 0.003
I0521 15:51:11.981683  8221 solver.cpp:237] Iteration 40500, loss = 1.87444
I0521 15:51:11.981853  8221 solver.cpp:253]     Train net output #0: loss = 1.87444 (* 1 = 1.87444 loss)
I0521 15:51:11.981868  8221 sgd_solver.cpp:106] Iteration 40500, lr = 0.003
I0521 15:51:28.609103  8221 solver.cpp:237] Iteration 42000, loss = 1.19031
I0521 15:51:28.609153  8221 solver.cpp:253]     Train net output #0: loss = 1.1903 (* 1 = 1.1903 loss)
I0521 15:51:28.609166  8221 sgd_solver.cpp:106] Iteration 42000, lr = 0.003
I0521 15:51:45.231464  8221 solver.cpp:237] Iteration 43500, loss = 1.59249
I0521 15:51:45.231628  8221 solver.cpp:253]     Train net output #0: loss = 1.59248 (* 1 = 1.59248 loss)
I0521 15:51:45.231642  8221 sgd_solver.cpp:106] Iteration 43500, lr = 0.003
I0521 15:52:01.827304  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_45000.caffemodel
I0521 15:52:01.876384  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_45000.solverstate
I0521 15:52:01.908323  8221 solver.cpp:237] Iteration 45000, loss = 1.21626
I0521 15:52:01.908371  8221 solver.cpp:253]     Train net output #0: loss = 1.21626 (* 1 = 1.21626 loss)
I0521 15:52:01.908386  8221 sgd_solver.cpp:106] Iteration 45000, lr = 0.003
I0521 15:52:18.514462  8221 solver.cpp:237] Iteration 46500, loss = 1.12402
I0521 15:52:18.514621  8221 solver.cpp:253]     Train net output #0: loss = 1.12401 (* 1 = 1.12401 loss)
I0521 15:52:18.514636  8221 sgd_solver.cpp:106] Iteration 46500, lr = 0.003
I0521 15:52:35.155637  8221 solver.cpp:237] Iteration 48000, loss = 1.20633
I0521 15:52:35.155685  8221 solver.cpp:253]     Train net output #0: loss = 1.20633 (* 1 = 1.20633 loss)
I0521 15:52:35.155702  8221 sgd_solver.cpp:106] Iteration 48000, lr = 0.003
I0521 15:52:51.779148  8221 solver.cpp:237] Iteration 49500, loss = 1.2106
I0521 15:52:51.779287  8221 solver.cpp:253]     Train net output #0: loss = 1.2106 (* 1 = 1.2106 loss)
I0521 15:52:51.779301  8221 sgd_solver.cpp:106] Iteration 49500, lr = 0.003
I0521 15:53:30.545058  8221 solver.cpp:237] Iteration 51000, loss = 1.81002
I0521 15:53:30.545218  8221 solver.cpp:253]     Train net output #0: loss = 1.81002 (* 1 = 1.81002 loss)
I0521 15:53:30.545233  8221 sgd_solver.cpp:106] Iteration 51000, lr = 0.003
I0521 15:53:47.136332  8221 solver.cpp:237] Iteration 52500, loss = 1.01994
I0521 15:53:47.136368  8221 solver.cpp:253]     Train net output #0: loss = 1.01994 (* 1 = 1.01994 loss)
I0521 15:53:47.136384  8221 sgd_solver.cpp:106] Iteration 52500, lr = 0.003
I0521 15:54:03.738495  8221 solver.cpp:237] Iteration 54000, loss = 1.30442
I0521 15:54:03.738647  8221 solver.cpp:253]     Train net output #0: loss = 1.30442 (* 1 = 1.30442 loss)
I0521 15:54:03.738662  8221 sgd_solver.cpp:106] Iteration 54000, lr = 0.003
I0521 15:54:20.374503  8221 solver.cpp:237] Iteration 55500, loss = 1.01044
I0521 15:54:20.374550  8221 solver.cpp:253]     Train net output #0: loss = 1.01044 (* 1 = 1.01044 loss)
I0521 15:54:20.374567  8221 sgd_solver.cpp:106] Iteration 55500, lr = 0.003
I0521 15:54:37.006881  8221 solver.cpp:237] Iteration 57000, loss = 1.46662
I0521 15:54:37.007021  8221 solver.cpp:253]     Train net output #0: loss = 1.46662 (* 1 = 1.46662 loss)
I0521 15:54:37.007037  8221 sgd_solver.cpp:106] Iteration 57000, lr = 0.003
I0521 15:54:53.625414  8221 solver.cpp:237] Iteration 58500, loss = 0.947187
I0521 15:54:53.625459  8221 solver.cpp:253]     Train net output #0: loss = 0.947183 (* 1 = 0.947183 loss)
I0521 15:54:53.625475  8221 sgd_solver.cpp:106] Iteration 58500, lr = 0.003
I0521 15:55:10.245904  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_60000.caffemodel
I0521 15:55:10.293870  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_60000.solverstate
I0521 15:55:10.322557  8221 solver.cpp:341] Iteration 60000, Testing net (#0)
I0521 15:56:30.848651  8221 solver.cpp:409]     Test net output #0: accuracy = 0.867777
I0521 15:56:30.848808  8221 solver.cpp:409]     Test net output #1: loss = 0.453858 (* 1 = 0.453858 loss)
I0521 15:56:52.982187  8221 solver.cpp:237] Iteration 60000, loss = 1.35605
I0521 15:56:52.982241  8221 solver.cpp:253]     Train net output #0: loss = 1.35605 (* 1 = 1.35605 loss)
I0521 15:56:52.982259  8221 sgd_solver.cpp:106] Iteration 60000, lr = 0.003
I0521 15:57:09.806618  8221 solver.cpp:237] Iteration 61500, loss = 0.799456
I0521 15:57:09.806787  8221 solver.cpp:253]     Train net output #0: loss = 0.799453 (* 1 = 0.799453 loss)
I0521 15:57:09.806800  8221 sgd_solver.cpp:106] Iteration 61500, lr = 0.003
I0521 15:57:26.692919  8221 solver.cpp:237] Iteration 63000, loss = 1.10833
I0521 15:57:26.692955  8221 solver.cpp:253]     Train net output #0: loss = 1.10833 (* 1 = 1.10833 loss)
I0521 15:57:26.692970  8221 sgd_solver.cpp:106] Iteration 63000, lr = 0.003
I0521 15:57:43.546525  8221 solver.cpp:237] Iteration 64500, loss = 1.43247
I0521 15:57:43.546676  8221 solver.cpp:253]     Train net output #0: loss = 1.43246 (* 1 = 1.43246 loss)
I0521 15:57:43.546690  8221 sgd_solver.cpp:106] Iteration 64500, lr = 0.003
I0521 15:58:00.405472  8221 solver.cpp:237] Iteration 66000, loss = 0.362481
I0521 15:58:00.405517  8221 solver.cpp:253]     Train net output #0: loss = 0.362478 (* 1 = 0.362478 loss)
I0521 15:58:00.405534  8221 sgd_solver.cpp:106] Iteration 66000, lr = 0.003
I0521 15:58:17.339843  8221 solver.cpp:237] Iteration 67500, loss = 1.12765
I0521 15:58:17.339982  8221 solver.cpp:253]     Train net output #0: loss = 1.12765 (* 1 = 1.12765 loss)
I0521 15:58:17.339995  8221 sgd_solver.cpp:106] Iteration 67500, lr = 0.003
I0521 15:58:34.263403  8221 solver.cpp:237] Iteration 69000, loss = 1.11422
I0521 15:58:34.263449  8221 solver.cpp:253]     Train net output #0: loss = 1.11422 (* 1 = 1.11422 loss)
I0521 15:58:34.263463  8221 sgd_solver.cpp:106] Iteration 69000, lr = 0.003
I0521 15:59:13.240893  8221 solver.cpp:237] Iteration 70500, loss = 1.53814
I0521 15:59:13.241058  8221 solver.cpp:253]     Train net output #0: loss = 1.53814 (* 1 = 1.53814 loss)
I0521 15:59:13.241072  8221 sgd_solver.cpp:106] Iteration 70500, lr = 0.003
I0521 15:59:30.132460  8221 solver.cpp:237] Iteration 72000, loss = 0.962404
I0521 15:59:30.132506  8221 solver.cpp:253]     Train net output #0: loss = 0.9624 (* 1 = 0.9624 loss)
I0521 15:59:30.132522  8221 sgd_solver.cpp:106] Iteration 72000, lr = 0.003
I0521 15:59:47.022810  8221 solver.cpp:237] Iteration 73500, loss = 1.15994
I0521 15:59:47.022961  8221 solver.cpp:253]     Train net output #0: loss = 1.15994 (* 1 = 1.15994 loss)
I0521 15:59:47.022975  8221 sgd_solver.cpp:106] Iteration 73500, lr = 0.003
I0521 16:00:03.847906  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_75000.caffemodel
I0521 16:00:03.895102  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_75000.solverstate
I0521 16:00:03.926996  8221 solver.cpp:237] Iteration 75000, loss = 0.624483
I0521 16:00:03.927048  8221 solver.cpp:253]     Train net output #0: loss = 0.624478 (* 1 = 0.624478 loss)
I0521 16:00:03.927062  8221 sgd_solver.cpp:106] Iteration 75000, lr = 0.003
I0521 16:00:20.738095  8221 solver.cpp:237] Iteration 76500, loss = 0.991704
I0521 16:00:20.738240  8221 solver.cpp:253]     Train net output #0: loss = 0.991699 (* 1 = 0.991699 loss)
I0521 16:00:20.738255  8221 sgd_solver.cpp:106] Iteration 76500, lr = 0.003
I0521 16:00:37.532651  8221 solver.cpp:237] Iteration 78000, loss = 1.74628
I0521 16:00:37.532703  8221 solver.cpp:253]     Train net output #0: loss = 1.74628 (* 1 = 1.74628 loss)
I0521 16:00:37.532716  8221 sgd_solver.cpp:106] Iteration 78000, lr = 0.003
I0521 16:00:54.459245  8221 solver.cpp:237] Iteration 79500, loss = 0.988133
I0521 16:00:54.459401  8221 solver.cpp:253]     Train net output #0: loss = 0.988129 (* 1 = 0.988129 loss)
I0521 16:00:54.459415  8221 sgd_solver.cpp:106] Iteration 79500, lr = 0.003
I0521 16:01:33.561838  8221 solver.cpp:237] Iteration 81000, loss = 1.5723
I0521 16:01:33.562014  8221 solver.cpp:253]     Train net output #0: loss = 1.57229 (* 1 = 1.57229 loss)
I0521 16:01:33.562029  8221 sgd_solver.cpp:106] Iteration 81000, lr = 0.003
I0521 16:01:50.509786  8221 solver.cpp:237] Iteration 82500, loss = 0.697272
I0521 16:01:50.509832  8221 solver.cpp:253]     Train net output #0: loss = 0.697268 (* 1 = 0.697268 loss)
I0521 16:01:50.509850  8221 sgd_solver.cpp:106] Iteration 82500, lr = 0.003
I0521 16:02:07.466727  8221 solver.cpp:237] Iteration 84000, loss = 1.68337
I0521 16:02:07.466871  8221 solver.cpp:253]     Train net output #0: loss = 1.68336 (* 1 = 1.68336 loss)
I0521 16:02:07.466884  8221 sgd_solver.cpp:106] Iteration 84000, lr = 0.003
I0521 16:02:24.399605  8221 solver.cpp:237] Iteration 85500, loss = 1.71987
I0521 16:02:24.399649  8221 solver.cpp:253]     Train net output #0: loss = 1.71987 (* 1 = 1.71987 loss)
I0521 16:02:24.399665  8221 sgd_solver.cpp:106] Iteration 85500, lr = 0.003
I0521 16:02:41.326848  8221 solver.cpp:237] Iteration 87000, loss = 1.03204
I0521 16:02:41.327000  8221 solver.cpp:253]     Train net output #0: loss = 1.03204 (* 1 = 1.03204 loss)
I0521 16:02:41.327014  8221 sgd_solver.cpp:106] Iteration 87000, lr = 0.003
I0521 16:02:58.259546  8221 solver.cpp:237] Iteration 88500, loss = 1.08246
I0521 16:02:58.259583  8221 solver.cpp:253]     Train net output #0: loss = 1.08245 (* 1 = 1.08245 loss)
I0521 16:02:58.259599  8221 sgd_solver.cpp:106] Iteration 88500, lr = 0.003
I0521 16:03:14.885020  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_90000.caffemodel
I0521 16:03:14.931543  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_90000.solverstate
I0521 16:03:14.958011  8221 solver.cpp:341] Iteration 90000, Testing net (#0)
I0521 16:04:14.103333  8221 solver.cpp:409]     Test net output #0: accuracy = 0.875912
I0521 16:04:14.103510  8221 solver.cpp:409]     Test net output #1: loss = 0.410384 (* 1 = 0.410384 loss)
I0521 16:04:36.257647  8221 solver.cpp:237] Iteration 90000, loss = 1.74014
I0521 16:04:36.257696  8221 solver.cpp:253]     Train net output #0: loss = 1.74014 (* 1 = 1.74014 loss)
I0521 16:04:36.257715  8221 sgd_solver.cpp:106] Iteration 90000, lr = 0.003
I0521 16:04:53.147833  8221 solver.cpp:237] Iteration 91500, loss = 1.69822
I0521 16:04:53.147991  8221 solver.cpp:253]     Train net output #0: loss = 1.69821 (* 1 = 1.69821 loss)
I0521 16:04:53.148005  8221 sgd_solver.cpp:106] Iteration 91500, lr = 0.003
I0521 16:05:10.001461  8221 solver.cpp:237] Iteration 93000, loss = 1.08305
I0521 16:05:10.001508  8221 solver.cpp:253]     Train net output #0: loss = 1.08304 (* 1 = 1.08304 loss)
I0521 16:05:10.001523  8221 sgd_solver.cpp:106] Iteration 93000, lr = 0.003
I0521 16:05:26.864070  8221 solver.cpp:237] Iteration 94500, loss = 1.93628
I0521 16:05:26.864213  8221 solver.cpp:253]     Train net output #0: loss = 1.93628 (* 1 = 1.93628 loss)
I0521 16:05:26.864228  8221 sgd_solver.cpp:106] Iteration 94500, lr = 0.003
I0521 16:05:43.762208  8221 solver.cpp:237] Iteration 96000, loss = 0.873865
I0521 16:05:43.762254  8221 solver.cpp:253]     Train net output #0: loss = 0.87386 (* 1 = 0.87386 loss)
I0521 16:05:43.762269  8221 sgd_solver.cpp:106] Iteration 96000, lr = 0.003
I0521 16:06:00.630231  8221 solver.cpp:237] Iteration 97500, loss = 0.704767
I0521 16:06:00.630390  8221 solver.cpp:253]     Train net output #0: loss = 0.704762 (* 1 = 0.704762 loss)
I0521 16:06:00.630404  8221 sgd_solver.cpp:106] Iteration 97500, lr = 0.003
I0521 16:06:17.495440  8221 solver.cpp:237] Iteration 99000, loss = 1.67474
I0521 16:06:17.495477  8221 solver.cpp:253]     Train net output #0: loss = 1.67473 (* 1 = 1.67473 loss)
I0521 16:06:17.495493  8221 sgd_solver.cpp:106] Iteration 99000, lr = 0.003
I0521 16:06:56.527020  8221 solver.cpp:237] Iteration 100500, loss = 1.38553
I0521 16:06:56.527196  8221 solver.cpp:253]     Train net output #0: loss = 1.38553 (* 1 = 1.38553 loss)
I0521 16:06:56.527211  8221 sgd_solver.cpp:106] Iteration 100500, lr = 0.003
I0521 16:07:13.363097  8221 solver.cpp:237] Iteration 102000, loss = 0.911371
I0521 16:07:13.363147  8221 solver.cpp:253]     Train net output #0: loss = 0.911367 (* 1 = 0.911367 loss)
I0521 16:07:13.363159  8221 sgd_solver.cpp:106] Iteration 102000, lr = 0.003
I0521 16:07:30.157493  8221 solver.cpp:237] Iteration 103500, loss = 1.14729
I0521 16:07:30.157639  8221 solver.cpp:253]     Train net output #0: loss = 1.14728 (* 1 = 1.14728 loss)
I0521 16:07:30.157652  8221 sgd_solver.cpp:106] Iteration 103500, lr = 0.003
I0521 16:07:47.013681  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_105000.caffemodel
I0521 16:07:47.063904  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_105000.solverstate
I0521 16:07:47.092413  8221 solver.cpp:237] Iteration 105000, loss = 0.842623
I0521 16:07:47.092458  8221 solver.cpp:253]     Train net output #0: loss = 0.84262 (* 1 = 0.84262 loss)
I0521 16:07:47.092475  8221 sgd_solver.cpp:106] Iteration 105000, lr = 0.003
I0521 16:08:03.981552  8221 solver.cpp:237] Iteration 106500, loss = 1.01639
I0521 16:08:03.981741  8221 solver.cpp:253]     Train net output #0: loss = 1.01639 (* 1 = 1.01639 loss)
I0521 16:08:03.981755  8221 sgd_solver.cpp:106] Iteration 106500, lr = 0.003
I0521 16:08:20.856575  8221 solver.cpp:237] Iteration 108000, loss = 1.15656
I0521 16:08:20.856609  8221 solver.cpp:253]     Train net output #0: loss = 1.15656 (* 1 = 1.15656 loss)
I0521 16:08:20.856627  8221 sgd_solver.cpp:106] Iteration 108000, lr = 0.003
I0521 16:08:37.778151  8221 solver.cpp:237] Iteration 109500, loss = 1.17533
I0521 16:08:37.778301  8221 solver.cpp:253]     Train net output #0: loss = 1.17532 (* 1 = 1.17532 loss)
I0521 16:08:37.778316  8221 sgd_solver.cpp:106] Iteration 109500, lr = 0.003
I0521 16:09:16.729029  8221 solver.cpp:237] Iteration 111000, loss = 1.38598
I0521 16:09:16.729195  8221 solver.cpp:253]     Train net output #0: loss = 1.38598 (* 1 = 1.38598 loss)
I0521 16:09:16.729209  8221 sgd_solver.cpp:106] Iteration 111000, lr = 0.003
I0521 16:09:33.580370  8221 solver.cpp:237] Iteration 112500, loss = 1.86259
I0521 16:09:33.580405  8221 solver.cpp:253]     Train net output #0: loss = 1.86258 (* 1 = 1.86258 loss)
I0521 16:09:33.580422  8221 sgd_solver.cpp:106] Iteration 112500, lr = 0.003
I0521 16:09:50.418690  8221 solver.cpp:237] Iteration 114000, loss = 1.41143
I0521 16:09:50.418838  8221 solver.cpp:253]     Train net output #0: loss = 1.41142 (* 1 = 1.41142 loss)
I0521 16:09:50.418853  8221 sgd_solver.cpp:106] Iteration 114000, lr = 0.003
I0521 16:10:07.304106  8221 solver.cpp:237] Iteration 115500, loss = 1.06632
I0521 16:10:07.304152  8221 solver.cpp:253]     Train net output #0: loss = 1.06631 (* 1 = 1.06631 loss)
I0521 16:10:07.304167  8221 sgd_solver.cpp:106] Iteration 115500, lr = 0.003
I0521 16:10:24.037052  8221 solver.cpp:237] Iteration 117000, loss = 1.14586
I0521 16:10:24.037195  8221 solver.cpp:253]     Train net output #0: loss = 1.14585 (* 1 = 1.14585 loss)
I0521 16:10:24.037209  8221 sgd_solver.cpp:106] Iteration 117000, lr = 0.003
I0521 16:10:40.619432  8221 solver.cpp:237] Iteration 118500, loss = 0.681549
I0521 16:10:40.619485  8221 solver.cpp:253]     Train net output #0: loss = 0.681544 (* 1 = 0.681544 loss)
I0521 16:10:40.619499  8221 sgd_solver.cpp:106] Iteration 118500, lr = 0.003
I0521 16:10:57.223685  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_120000.caffemodel
I0521 16:10:57.269510  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_120000.solverstate
I0521 16:10:57.294982  8221 solver.cpp:341] Iteration 120000, Testing net (#0)
I0521 16:12:17.394970  8221 solver.cpp:409]     Test net output #0: accuracy = 0.87702
I0521 16:12:17.395141  8221 solver.cpp:409]     Test net output #1: loss = 0.405118 (* 1 = 0.405118 loss)
I0521 16:12:39.532609  8221 solver.cpp:237] Iteration 120000, loss = 2.54569
I0521 16:12:39.532661  8221 solver.cpp:253]     Train net output #0: loss = 2.54569 (* 1 = 2.54569 loss)
I0521 16:12:39.532676  8221 sgd_solver.cpp:106] Iteration 120000, lr = 0.003
I0521 16:12:56.304479  8221 solver.cpp:237] Iteration 121500, loss = 1.261
I0521 16:12:56.304633  8221 solver.cpp:253]     Train net output #0: loss = 1.26099 (* 1 = 1.26099 loss)
I0521 16:12:56.304647  8221 sgd_solver.cpp:106] Iteration 121500, lr = 0.003
I0521 16:13:13.056126  8221 solver.cpp:237] Iteration 123000, loss = 1.20017
I0521 16:13:13.056174  8221 solver.cpp:253]     Train net output #0: loss = 1.20017 (* 1 = 1.20017 loss)
I0521 16:13:13.056188  8221 sgd_solver.cpp:106] Iteration 123000, lr = 0.003
I0521 16:13:29.843335  8221 solver.cpp:237] Iteration 124500, loss = 1.28015
I0521 16:13:29.843488  8221 solver.cpp:253]     Train net output #0: loss = 1.28014 (* 1 = 1.28014 loss)
I0521 16:13:29.843502  8221 sgd_solver.cpp:106] Iteration 124500, lr = 0.003
I0521 16:13:46.630395  8221 solver.cpp:237] Iteration 126000, loss = 0.656197
I0521 16:13:46.630432  8221 solver.cpp:253]     Train net output #0: loss = 0.656192 (* 1 = 0.656192 loss)
I0521 16:13:46.630448  8221 sgd_solver.cpp:106] Iteration 126000, lr = 0.003
I0521 16:14:03.255122  8221 solver.cpp:237] Iteration 127500, loss = 1.25158
I0521 16:14:03.255285  8221 solver.cpp:253]     Train net output #0: loss = 1.25158 (* 1 = 1.25158 loss)
I0521 16:14:03.255300  8221 sgd_solver.cpp:106] Iteration 127500, lr = 0.003
I0521 16:14:19.928127  8221 solver.cpp:237] Iteration 129000, loss = 0.876276
I0521 16:14:19.928176  8221 solver.cpp:253]     Train net output #0: loss = 0.876271 (* 1 = 0.876271 loss)
I0521 16:14:19.928190  8221 sgd_solver.cpp:106] Iteration 129000, lr = 0.003
I0521 16:14:59.201279  8221 solver.cpp:237] Iteration 130500, loss = 1.00084
I0521 16:14:59.201447  8221 solver.cpp:253]     Train net output #0: loss = 1.00083 (* 1 = 1.00083 loss)
I0521 16:14:59.201460  8221 sgd_solver.cpp:106] Iteration 130500, lr = 0.003
I0521 16:15:16.403040  8221 solver.cpp:237] Iteration 132000, loss = 0.823981
I0521 16:15:16.403089  8221 solver.cpp:253]     Train net output #0: loss = 0.823976 (* 1 = 0.823976 loss)
I0521 16:15:16.403101  8221 sgd_solver.cpp:106] Iteration 132000, lr = 0.003
I0521 16:15:33.552294  8221 solver.cpp:237] Iteration 133500, loss = 0.739664
I0521 16:15:33.552451  8221 solver.cpp:253]     Train net output #0: loss = 0.739659 (* 1 = 0.739659 loss)
I0521 16:15:33.552465  8221 sgd_solver.cpp:106] Iteration 133500, lr = 0.003
I0521 16:15:50.722348  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_135000.caffemodel
I0521 16:15:50.770632  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_135000.solverstate
I0521 16:15:50.801579  8221 solver.cpp:237] Iteration 135000, loss = 1.68276
I0521 16:15:50.801630  8221 solver.cpp:253]     Train net output #0: loss = 1.68275 (* 1 = 1.68275 loss)
I0521 16:15:50.801645  8221 sgd_solver.cpp:106] Iteration 135000, lr = 0.003
I0521 16:16:08.007899  8221 solver.cpp:237] Iteration 136500, loss = 0.656931
I0521 16:16:08.008060  8221 solver.cpp:253]     Train net output #0: loss = 0.656926 (* 1 = 0.656926 loss)
I0521 16:16:08.008075  8221 sgd_solver.cpp:106] Iteration 136500, lr = 0.003
I0521 16:16:25.201689  8221 solver.cpp:237] Iteration 138000, loss = 1.1124
I0521 16:16:25.201736  8221 solver.cpp:253]     Train net output #0: loss = 1.11239 (* 1 = 1.11239 loss)
I0521 16:16:25.201750  8221 sgd_solver.cpp:106] Iteration 138000, lr = 0.003
I0521 16:16:42.366909  8221 solver.cpp:237] Iteration 139500, loss = 1.59447
I0521 16:16:42.367068  8221 solver.cpp:253]     Train net output #0: loss = 1.59447 (* 1 = 1.59447 loss)
I0521 16:16:42.367080  8221 sgd_solver.cpp:106] Iteration 139500, lr = 0.003
I0521 16:17:21.733656  8221 solver.cpp:237] Iteration 141000, loss = 1.12785
I0521 16:17:21.733825  8221 solver.cpp:253]     Train net output #0: loss = 1.12784 (* 1 = 1.12784 loss)
I0521 16:17:21.733839  8221 sgd_solver.cpp:106] Iteration 141000, lr = 0.003
I0521 16:17:38.921088  8221 solver.cpp:237] Iteration 142500, loss = 1.69235
I0521 16:17:38.921139  8221 solver.cpp:253]     Train net output #0: loss = 1.69235 (* 1 = 1.69235 loss)
I0521 16:17:38.921151  8221 sgd_solver.cpp:106] Iteration 142500, lr = 0.003
I0521 16:17:56.094681  8221 solver.cpp:237] Iteration 144000, loss = 1.91114
I0521 16:17:56.094830  8221 solver.cpp:253]     Train net output #0: loss = 1.91113 (* 1 = 1.91113 loss)
I0521 16:17:56.094843  8221 sgd_solver.cpp:106] Iteration 144000, lr = 0.003
I0521 16:18:13.280715  8221 solver.cpp:237] Iteration 145500, loss = 1.5096
I0521 16:18:13.280760  8221 solver.cpp:253]     Train net output #0: loss = 1.50959 (* 1 = 1.50959 loss)
I0521 16:18:13.280772  8221 sgd_solver.cpp:106] Iteration 145500, lr = 0.003
I0521 16:18:30.480198  8221 solver.cpp:237] Iteration 147000, loss = 1.65143
I0521 16:18:30.480360  8221 solver.cpp:253]     Train net output #0: loss = 1.65143 (* 1 = 1.65143 loss)
I0521 16:18:30.480375  8221 sgd_solver.cpp:106] Iteration 147000, lr = 0.003
I0521 16:18:47.661803  8221 solver.cpp:237] Iteration 148500, loss = 0.810646
I0521 16:18:47.661841  8221 solver.cpp:253]     Train net output #0: loss = 0.810641 (* 1 = 0.810641 loss)
I0521 16:18:47.661856  8221 sgd_solver.cpp:106] Iteration 148500, lr = 0.003
I0521 16:19:04.832761  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_150000.caffemodel
I0521 16:19:04.881664  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_150000.solverstate
I0521 16:19:04.909384  8221 solver.cpp:341] Iteration 150000, Testing net (#0)
I0521 16:20:04.541465  8221 solver.cpp:409]     Test net output #0: accuracy = 0.884713
I0521 16:20:04.541627  8221 solver.cpp:409]     Test net output #1: loss = 0.377773 (* 1 = 0.377773 loss)
I0521 16:20:25.432226  8221 solver.cpp:237] Iteration 150000, loss = 1.15372
I0521 16:20:25.432277  8221 solver.cpp:253]     Train net output #0: loss = 1.15372 (* 1 = 1.15372 loss)
I0521 16:20:25.432292  8221 sgd_solver.cpp:106] Iteration 150000, lr = 0.003
I0521 16:20:42.453178  8221 solver.cpp:237] Iteration 151500, loss = 0.673122
I0521 16:20:42.453359  8221 solver.cpp:253]     Train net output #0: loss = 0.673118 (* 1 = 0.673118 loss)
I0521 16:20:42.453375  8221 sgd_solver.cpp:106] Iteration 151500, lr = 0.003
I0521 16:20:59.495053  8221 solver.cpp:237] Iteration 153000, loss = 1.85268
I0521 16:20:59.495098  8221 solver.cpp:253]     Train net output #0: loss = 1.85268 (* 1 = 1.85268 loss)
I0521 16:20:59.495115  8221 sgd_solver.cpp:106] Iteration 153000, lr = 0.003
I0521 16:21:16.509088  8221 solver.cpp:237] Iteration 154500, loss = 2.06729
I0521 16:21:16.509233  8221 solver.cpp:253]     Train net output #0: loss = 2.06729 (* 1 = 2.06729 loss)
I0521 16:21:16.509248  8221 sgd_solver.cpp:106] Iteration 154500, lr = 0.003
I0521 16:21:33.540681  8221 solver.cpp:237] Iteration 156000, loss = 1.09776
I0521 16:21:33.540726  8221 solver.cpp:253]     Train net output #0: loss = 1.09775 (* 1 = 1.09775 loss)
I0521 16:21:33.540741  8221 sgd_solver.cpp:106] Iteration 156000, lr = 0.003
I0521 16:21:50.577167  8221 solver.cpp:237] Iteration 157500, loss = 0.796861
I0521 16:21:50.577342  8221 solver.cpp:253]     Train net output #0: loss = 0.796855 (* 1 = 0.796855 loss)
I0521 16:21:50.577356  8221 sgd_solver.cpp:106] Iteration 157500, lr = 0.003
I0521 16:22:07.645974  8221 solver.cpp:237] Iteration 159000, loss = 1.3345
I0521 16:22:07.646011  8221 solver.cpp:253]     Train net output #0: loss = 1.33449 (* 1 = 1.33449 loss)
I0521 16:22:07.646024  8221 sgd_solver.cpp:106] Iteration 159000, lr = 0.003
I0521 16:22:45.333672  8221 solver.cpp:237] Iteration 160500, loss = 1.12088
I0521 16:22:45.333842  8221 solver.cpp:253]     Train net output #0: loss = 1.12088 (* 1 = 1.12088 loss)
I0521 16:22:45.333858  8221 sgd_solver.cpp:106] Iteration 160500, lr = 0.003
I0521 16:23:02.103477  8221 solver.cpp:237] Iteration 162000, loss = 1.23063
I0521 16:23:02.103524  8221 solver.cpp:253]     Train net output #0: loss = 1.23062 (* 1 = 1.23062 loss)
I0521 16:23:02.103541  8221 sgd_solver.cpp:106] Iteration 162000, lr = 0.003
I0521 16:23:18.901119  8221 solver.cpp:237] Iteration 163500, loss = 1.68937
I0521 16:23:18.901268  8221 solver.cpp:253]     Train net output #0: loss = 1.68937 (* 1 = 1.68937 loss)
I0521 16:23:18.901283  8221 sgd_solver.cpp:106] Iteration 163500, lr = 0.003
I0521 16:23:35.694293  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_165000.caffemodel
I0521 16:23:35.740840  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_165000.solverstate
I0521 16:23:35.769824  8221 solver.cpp:237] Iteration 165000, loss = 1.17782
I0521 16:23:35.769870  8221 solver.cpp:253]     Train net output #0: loss = 1.17782 (* 1 = 1.17782 loss)
I0521 16:23:35.769884  8221 sgd_solver.cpp:106] Iteration 165000, lr = 0.003
I0521 16:23:52.540490  8221 solver.cpp:237] Iteration 166500, loss = 1.2688
I0521 16:23:52.540654  8221 solver.cpp:253]     Train net output #0: loss = 1.26879 (* 1 = 1.26879 loss)
I0521 16:23:52.540668  8221 sgd_solver.cpp:106] Iteration 166500, lr = 0.003
I0521 16:24:09.295755  8221 solver.cpp:237] Iteration 168000, loss = 1.01143
I0521 16:24:09.295791  8221 solver.cpp:253]     Train net output #0: loss = 1.01143 (* 1 = 1.01143 loss)
I0521 16:24:09.295814  8221 sgd_solver.cpp:106] Iteration 168000, lr = 0.003
I0521 16:24:26.176808  8221 solver.cpp:237] Iteration 169500, loss = 1.13301
I0521 16:24:26.176964  8221 solver.cpp:253]     Train net output #0: loss = 1.13301 (* 1 = 1.13301 loss)
I0521 16:24:26.176978  8221 sgd_solver.cpp:106] Iteration 169500, lr = 0.003
I0521 16:25:03.981340  8221 solver.cpp:237] Iteration 171000, loss = 1.15414
I0521 16:25:03.981501  8221 solver.cpp:253]     Train net output #0: loss = 1.15414 (* 1 = 1.15414 loss)
I0521 16:25:03.981516  8221 sgd_solver.cpp:106] Iteration 171000, lr = 0.003
I0521 16:25:20.942935  8221 solver.cpp:237] Iteration 172500, loss = 0.802786
I0521 16:25:20.942971  8221 solver.cpp:253]     Train net output #0: loss = 0.802781 (* 1 = 0.802781 loss)
I0521 16:25:20.942988  8221 sgd_solver.cpp:106] Iteration 172500, lr = 0.003
I0521 16:25:37.909585  8221 solver.cpp:237] Iteration 174000, loss = 1.20342
I0521 16:25:37.909735  8221 solver.cpp:253]     Train net output #0: loss = 1.20342 (* 1 = 1.20342 loss)
I0521 16:25:37.909749  8221 sgd_solver.cpp:106] Iteration 174000, lr = 0.003
I0521 16:25:54.886958  8221 solver.cpp:237] Iteration 175500, loss = 1.02156
I0521 16:25:54.887002  8221 solver.cpp:253]     Train net output #0: loss = 1.02156 (* 1 = 1.02156 loss)
I0521 16:25:54.887019  8221 sgd_solver.cpp:106] Iteration 175500, lr = 0.003
I0521 16:26:11.820809  8221 solver.cpp:237] Iteration 177000, loss = 1.02118
I0521 16:26:11.820955  8221 solver.cpp:253]     Train net output #0: loss = 1.02117 (* 1 = 1.02117 loss)
I0521 16:26:11.820968  8221 sgd_solver.cpp:106] Iteration 177000, lr = 0.003
I0521 16:26:28.760448  8221 solver.cpp:237] Iteration 178500, loss = 1.257
I0521 16:26:28.760494  8221 solver.cpp:253]     Train net output #0: loss = 1.257 (* 1 = 1.257 loss)
I0521 16:26:28.760507  8221 sgd_solver.cpp:106] Iteration 178500, lr = 0.003
I0521 16:26:45.726080  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_180000.caffemodel
I0521 16:26:45.771352  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_180000.solverstate
I0521 16:26:45.796897  8221 solver.cpp:341] Iteration 180000, Testing net (#0)
I0521 16:28:06.070204  8221 solver.cpp:409]     Test net output #0: accuracy = 0.883347
I0521 16:28:06.070377  8221 solver.cpp:409]     Test net output #1: loss = 0.378709 (* 1 = 0.378709 loss)
I0521 16:28:26.935956  8221 solver.cpp:237] Iteration 180000, loss = 0.636418
I0521 16:28:26.936009  8221 solver.cpp:253]     Train net output #0: loss = 0.636412 (* 1 = 0.636412 loss)
I0521 16:28:26.936027  8221 sgd_solver.cpp:106] Iteration 180000, lr = 0.003
I0521 16:28:43.546608  8221 solver.cpp:237] Iteration 181500, loss = 0.844398
I0521 16:28:43.546767  8221 solver.cpp:253]     Train net output #0: loss = 0.844392 (* 1 = 0.844392 loss)
I0521 16:28:43.546780  8221 sgd_solver.cpp:106] Iteration 181500, lr = 0.003
I0521 16:29:00.149541  8221 solver.cpp:237] Iteration 183000, loss = 0.790921
I0521 16:29:00.149590  8221 solver.cpp:253]     Train net output #0: loss = 0.790916 (* 1 = 0.790916 loss)
I0521 16:29:00.149605  8221 sgd_solver.cpp:106] Iteration 183000, lr = 0.003
I0521 16:29:16.752934  8221 solver.cpp:237] Iteration 184500, loss = 0.755411
I0521 16:29:16.753096  8221 solver.cpp:253]     Train net output #0: loss = 0.755404 (* 1 = 0.755404 loss)
I0521 16:29:16.753111  8221 sgd_solver.cpp:106] Iteration 184500, lr = 0.003
I0521 16:29:33.361472  8221 solver.cpp:237] Iteration 186000, loss = 1.14508
I0521 16:29:33.361510  8221 solver.cpp:253]     Train net output #0: loss = 1.14507 (* 1 = 1.14507 loss)
I0521 16:29:33.361523  8221 sgd_solver.cpp:106] Iteration 186000, lr = 0.003
I0521 16:29:49.993855  8221 solver.cpp:237] Iteration 187500, loss = 1.21168
I0521 16:29:49.994024  8221 solver.cpp:253]     Train net output #0: loss = 1.21167 (* 1 = 1.21167 loss)
I0521 16:29:49.994038  8221 sgd_solver.cpp:106] Iteration 187500, lr = 0.003
I0521 16:30:06.717232  8221 solver.cpp:237] Iteration 189000, loss = 1.0894
I0521 16:30:06.717278  8221 solver.cpp:253]     Train net output #0: loss = 1.08939 (* 1 = 1.08939 loss)
I0521 16:30:06.717293  8221 sgd_solver.cpp:106] Iteration 189000, lr = 0.003
I0521 16:30:44.730162  8221 solver.cpp:237] Iteration 190500, loss = 1.35967
I0521 16:30:44.730330  8221 solver.cpp:253]     Train net output #0: loss = 1.35967 (* 1 = 1.35967 loss)
I0521 16:30:44.730345  8221 sgd_solver.cpp:106] Iteration 190500, lr = 0.003
I0521 16:31:01.893065  8221 solver.cpp:237] Iteration 192000, loss = 1.49212
I0521 16:31:01.893115  8221 solver.cpp:253]     Train net output #0: loss = 1.49211 (* 1 = 1.49211 loss)
I0521 16:31:01.893127  8221 sgd_solver.cpp:106] Iteration 192000, lr = 0.003
I0521 16:31:19.075202  8221 solver.cpp:237] Iteration 193500, loss = 1.73229
I0521 16:31:19.075362  8221 solver.cpp:253]     Train net output #0: loss = 1.73229 (* 1 = 1.73229 loss)
I0521 16:31:19.075376  8221 sgd_solver.cpp:106] Iteration 193500, lr = 0.003
I0521 16:31:36.251972  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_195000.caffemodel
I0521 16:31:36.297981  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_195000.solverstate
I0521 16:31:36.327134  8221 solver.cpp:237] Iteration 195000, loss = 1.2196
I0521 16:31:36.327180  8221 solver.cpp:253]     Train net output #0: loss = 1.21959 (* 1 = 1.21959 loss)
I0521 16:31:36.327194  8221 sgd_solver.cpp:106] Iteration 195000, lr = 0.003
I0521 16:31:53.458294  8221 solver.cpp:237] Iteration 196500, loss = 2.29119
I0521 16:31:53.458472  8221 solver.cpp:253]     Train net output #0: loss = 2.29119 (* 1 = 2.29119 loss)
I0521 16:31:53.458487  8221 sgd_solver.cpp:106] Iteration 196500, lr = 0.003
I0521 16:32:10.658522  8221 solver.cpp:237] Iteration 198000, loss = 0.958321
I0521 16:32:10.658572  8221 solver.cpp:253]     Train net output #0: loss = 0.958316 (* 1 = 0.958316 loss)
I0521 16:32:10.658588  8221 sgd_solver.cpp:106] Iteration 198000, lr = 0.003
I0521 16:32:27.833732  8221 solver.cpp:237] Iteration 199500, loss = 0.780438
I0521 16:32:27.833883  8221 solver.cpp:253]     Train net output #0: loss = 0.780433 (* 1 = 0.780433 loss)
I0521 16:32:27.833896  8221 sgd_solver.cpp:106] Iteration 199500, lr = 0.003
I0521 16:33:05.868824  8221 solver.cpp:237] Iteration 201000, loss = 1.06224
I0521 16:33:05.868995  8221 solver.cpp:253]     Train net output #0: loss = 1.06224 (* 1 = 1.06224 loss)
I0521 16:33:05.869009  8221 sgd_solver.cpp:106] Iteration 201000, lr = 0.003
I0521 16:33:23.056254  8221 solver.cpp:237] Iteration 202500, loss = 1.10347
I0521 16:33:23.056290  8221 solver.cpp:253]     Train net output #0: loss = 1.10347 (* 1 = 1.10347 loss)
I0521 16:33:23.056308  8221 sgd_solver.cpp:106] Iteration 202500, lr = 0.003
I0521 16:33:40.201422  8221 solver.cpp:237] Iteration 204000, loss = 1.33437
I0521 16:33:40.201581  8221 solver.cpp:253]     Train net output #0: loss = 1.33436 (* 1 = 1.33436 loss)
I0521 16:33:40.201596  8221 sgd_solver.cpp:106] Iteration 204000, lr = 0.003
I0521 16:33:57.357244  8221 solver.cpp:237] Iteration 205500, loss = 1.20146
I0521 16:33:57.357287  8221 solver.cpp:253]     Train net output #0: loss = 1.20146 (* 1 = 1.20146 loss)
I0521 16:33:57.357305  8221 sgd_solver.cpp:106] Iteration 205500, lr = 0.003
I0521 16:34:14.567368  8221 solver.cpp:237] Iteration 207000, loss = 1.30754
I0521 16:34:14.567529  8221 solver.cpp:253]     Train net output #0: loss = 1.30754 (* 1 = 1.30754 loss)
I0521 16:34:14.567543  8221 sgd_solver.cpp:106] Iteration 207000, lr = 0.003
I0521 16:34:31.724431  8221 solver.cpp:237] Iteration 208500, loss = 1.21647
I0521 16:34:31.724467  8221 solver.cpp:253]     Train net output #0: loss = 1.21646 (* 1 = 1.21646 loss)
I0521 16:34:31.724483  8221 sgd_solver.cpp:106] Iteration 208500, lr = 0.003
I0521 16:34:48.936769  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_210000.caffemodel
I0521 16:34:48.983122  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_210000.solverstate
I0521 16:34:49.013478  8221 solver.cpp:341] Iteration 210000, Testing net (#0)
I0521 16:35:48.217224  8221 solver.cpp:409]     Test net output #0: accuracy = 0.886823
I0521 16:35:48.217392  8221 solver.cpp:409]     Test net output #1: loss = 0.367755 (* 1 = 0.367755 loss)
I0521 16:36:09.042856  8221 solver.cpp:237] Iteration 210000, loss = 0.970941
I0521 16:36:09.042911  8221 solver.cpp:253]     Train net output #0: loss = 0.970936 (* 1 = 0.970936 loss)
I0521 16:36:09.042927  8221 sgd_solver.cpp:106] Iteration 210000, lr = 0.003
I0521 16:36:25.805001  8221 solver.cpp:237] Iteration 211500, loss = 1.36291
I0521 16:36:25.805168  8221 solver.cpp:253]     Train net output #0: loss = 1.36291 (* 1 = 1.36291 loss)
I0521 16:36:25.805182  8221 sgd_solver.cpp:106] Iteration 211500, lr = 0.003
I0521 16:36:42.562206  8221 solver.cpp:237] Iteration 213000, loss = 1.57589
I0521 16:36:42.562242  8221 solver.cpp:253]     Train net output #0: loss = 1.57589 (* 1 = 1.57589 loss)
I0521 16:36:42.562258  8221 sgd_solver.cpp:106] Iteration 213000, lr = 0.003
I0521 16:36:59.325543  8221 solver.cpp:237] Iteration 214500, loss = 1.19053
I0521 16:36:59.325708  8221 solver.cpp:253]     Train net output #0: loss = 1.19052 (* 1 = 1.19052 loss)
I0521 16:36:59.325723  8221 sgd_solver.cpp:106] Iteration 214500, lr = 0.003
I0521 16:37:16.098635  8221 solver.cpp:237] Iteration 216000, loss = 0.858279
I0521 16:37:16.098683  8221 solver.cpp:253]     Train net output #0: loss = 0.858275 (* 1 = 0.858275 loss)
I0521 16:37:16.098700  8221 sgd_solver.cpp:106] Iteration 216000, lr = 0.003
I0521 16:37:32.899952  8221 solver.cpp:237] Iteration 217500, loss = 1.58954
I0521 16:37:32.900115  8221 solver.cpp:253]     Train net output #0: loss = 1.58954 (* 1 = 1.58954 loss)
I0521 16:37:32.900128  8221 sgd_solver.cpp:106] Iteration 217500, lr = 0.003
I0521 16:37:49.685837  8221 solver.cpp:237] Iteration 219000, loss = 1.53874
I0521 16:37:49.685883  8221 solver.cpp:253]     Train net output #0: loss = 1.53874 (* 1 = 1.53874 loss)
I0521 16:37:49.685899  8221 sgd_solver.cpp:106] Iteration 219000, lr = 0.003
I0521 16:38:27.379595  8221 solver.cpp:237] Iteration 220500, loss = 1.30986
I0521 16:38:27.379770  8221 solver.cpp:253]     Train net output #0: loss = 1.30986 (* 1 = 1.30986 loss)
I0521 16:38:27.379786  8221 sgd_solver.cpp:106] Iteration 220500, lr = 0.003
I0521 16:38:44.180783  8221 solver.cpp:237] Iteration 222000, loss = 1.16248
I0521 16:38:44.180819  8221 solver.cpp:253]     Train net output #0: loss = 1.16247 (* 1 = 1.16247 loss)
I0521 16:38:44.180831  8221 sgd_solver.cpp:106] Iteration 222000, lr = 0.003
I0521 16:39:01.110887  8221 solver.cpp:237] Iteration 223500, loss = 0.96673
I0521 16:39:01.111047  8221 solver.cpp:253]     Train net output #0: loss = 0.966727 (* 1 = 0.966727 loss)
I0521 16:39:01.111063  8221 sgd_solver.cpp:106] Iteration 223500, lr = 0.003
I0521 16:39:17.988044  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_225000.caffemodel
I0521 16:39:18.037035  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_225000.solverstate
I0521 16:39:18.068300  8221 solver.cpp:237] Iteration 225000, loss = 1.30346
I0521 16:39:18.068346  8221 solver.cpp:253]     Train net output #0: loss = 1.30346 (* 1 = 1.30346 loss)
I0521 16:39:18.068362  8221 sgd_solver.cpp:106] Iteration 225000, lr = 0.003
I0521 16:39:34.954105  8221 solver.cpp:237] Iteration 226500, loss = 1.39662
I0521 16:39:34.954272  8221 solver.cpp:253]     Train net output #0: loss = 1.39662 (* 1 = 1.39662 loss)
I0521 16:39:34.954287  8221 sgd_solver.cpp:106] Iteration 226500, lr = 0.003
I0521 16:39:51.917570  8221 solver.cpp:237] Iteration 228000, loss = 0.960068
I0521 16:39:51.917623  8221 solver.cpp:253]     Train net output #0: loss = 0.960065 (* 1 = 0.960065 loss)
I0521 16:39:51.917636  8221 sgd_solver.cpp:106] Iteration 228000, lr = 0.003
I0521 16:40:08.892215  8221 solver.cpp:237] Iteration 229500, loss = 1.25831
I0521 16:40:08.892381  8221 solver.cpp:253]     Train net output #0: loss = 1.2583 (* 1 = 1.2583 loss)
I0521 16:40:08.892395  8221 sgd_solver.cpp:106] Iteration 229500, lr = 0.003
I0521 16:40:46.687541  8221 solver.cpp:237] Iteration 231000, loss = 0.540157
I0521 16:40:46.687714  8221 solver.cpp:253]     Train net output #0: loss = 0.540154 (* 1 = 0.540154 loss)
I0521 16:40:46.687729  8221 sgd_solver.cpp:106] Iteration 231000, lr = 0.003
I0521 16:41:03.625391  8221 solver.cpp:237] Iteration 232500, loss = 1.41733
I0521 16:41:03.625437  8221 solver.cpp:253]     Train net output #0: loss = 1.41733 (* 1 = 1.41733 loss)
I0521 16:41:03.625452  8221 sgd_solver.cpp:106] Iteration 232500, lr = 0.003
I0521 16:41:20.544386  8221 solver.cpp:237] Iteration 234000, loss = 0.973638
I0521 16:41:20.544551  8221 solver.cpp:253]     Train net output #0: loss = 0.973634 (* 1 = 0.973634 loss)
I0521 16:41:20.544565  8221 sgd_solver.cpp:106] Iteration 234000, lr = 0.003
I0521 16:41:37.510821  8221 solver.cpp:237] Iteration 235500, loss = 1.1066
I0521 16:41:37.510857  8221 solver.cpp:253]     Train net output #0: loss = 1.1066 (* 1 = 1.1066 loss)
I0521 16:41:37.510872  8221 sgd_solver.cpp:106] Iteration 235500, lr = 0.003
I0521 16:41:54.466094  8221 solver.cpp:237] Iteration 237000, loss = 0.771004
I0521 16:41:54.466267  8221 solver.cpp:253]     Train net output #0: loss = 0.771 (* 1 = 0.771 loss)
I0521 16:41:54.466284  8221 sgd_solver.cpp:106] Iteration 237000, lr = 0.003
I0521 16:42:11.405689  8221 solver.cpp:237] Iteration 238500, loss = 0.637191
I0521 16:42:11.405731  8221 solver.cpp:253]     Train net output #0: loss = 0.637186 (* 1 = 0.637186 loss)
I0521 16:42:11.405750  8221 sgd_solver.cpp:106] Iteration 238500, lr = 0.003
I0521 16:42:28.341076  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_240000.caffemodel
I0521 16:42:28.387024  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_240000.solverstate
I0521 16:42:28.412149  8221 solver.cpp:341] Iteration 240000, Testing net (#0)
I0521 16:43:48.668804  8221 solver.cpp:409]     Test net output #0: accuracy = 0.883911
I0521 16:43:48.668973  8221 solver.cpp:409]     Test net output #1: loss = 0.393546 (* 1 = 0.393546 loss)
I0521 16:44:09.523291  8221 solver.cpp:237] Iteration 240000, loss = 1.4571
I0521 16:44:09.523344  8221 solver.cpp:253]     Train net output #0: loss = 1.4571 (* 1 = 1.4571 loss)
I0521 16:44:09.523360  8221 sgd_solver.cpp:106] Iteration 240000, lr = 0.003
I0521 16:44:26.702078  8221 solver.cpp:237] Iteration 241500, loss = 0.575446
I0521 16:44:26.702247  8221 solver.cpp:253]     Train net output #0: loss = 0.57544 (* 1 = 0.57544 loss)
I0521 16:44:26.702262  8221 sgd_solver.cpp:106] Iteration 241500, lr = 0.003
I0521 16:44:43.867647  8221 solver.cpp:237] Iteration 243000, loss = 1.85816
I0521 16:44:43.867697  8221 solver.cpp:253]     Train net output #0: loss = 1.85816 (* 1 = 1.85816 loss)
I0521 16:44:43.867710  8221 sgd_solver.cpp:106] Iteration 243000, lr = 0.003
I0521 16:45:01.050418  8221 solver.cpp:237] Iteration 244500, loss = 1.17785
I0521 16:45:01.050572  8221 solver.cpp:253]     Train net output #0: loss = 1.17785 (* 1 = 1.17785 loss)
I0521 16:45:01.050586  8221 sgd_solver.cpp:106] Iteration 244500, lr = 0.003
I0521 16:45:18.251159  8221 solver.cpp:237] Iteration 246000, loss = 1.34581
I0521 16:45:18.251209  8221 solver.cpp:253]     Train net output #0: loss = 1.3458 (* 1 = 1.3458 loss)
I0521 16:45:18.251224  8221 sgd_solver.cpp:106] Iteration 246000, lr = 0.003
I0521 16:45:35.375742  8221 solver.cpp:237] Iteration 247500, loss = 1.10703
I0521 16:45:35.375915  8221 solver.cpp:253]     Train net output #0: loss = 1.10702 (* 1 = 1.10702 loss)
I0521 16:45:35.375928  8221 sgd_solver.cpp:106] Iteration 247500, lr = 0.003
I0521 16:45:52.561188  8221 solver.cpp:237] Iteration 249000, loss = 1.12614
I0521 16:45:52.561225  8221 solver.cpp:253]     Train net output #0: loss = 1.12613 (* 1 = 1.12613 loss)
I0521 16:45:52.561240  8221 sgd_solver.cpp:106] Iteration 249000, lr = 0.003
I0521 16:46:30.626950  8221 solver.cpp:237] Iteration 250500, loss = 1.35064
I0521 16:46:30.627122  8221 solver.cpp:253]     Train net output #0: loss = 1.35064 (* 1 = 1.35064 loss)
I0521 16:46:30.627136  8221 sgd_solver.cpp:106] Iteration 250500, lr = 0.003
I0521 16:46:47.792536  8221 solver.cpp:237] Iteration 252000, loss = 0.955692
I0521 16:46:47.792580  8221 solver.cpp:253]     Train net output #0: loss = 0.955686 (* 1 = 0.955686 loss)
I0521 16:46:47.792596  8221 sgd_solver.cpp:106] Iteration 252000, lr = 0.003
I0521 16:47:04.953862  8221 solver.cpp:237] Iteration 253500, loss = 1.15672
I0521 16:47:04.954015  8221 solver.cpp:253]     Train net output #0: loss = 1.15671 (* 1 = 1.15671 loss)
I0521 16:47:04.954028  8221 sgd_solver.cpp:106] Iteration 253500, lr = 0.003
I0521 16:47:22.106571  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_255000.caffemodel
I0521 16:47:22.152542  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_255000.solverstate
I0521 16:47:22.180945  8221 solver.cpp:237] Iteration 255000, loss = 0.997488
I0521 16:47:22.180990  8221 solver.cpp:253]     Train net output #0: loss = 0.997483 (* 1 = 0.997483 loss)
I0521 16:47:22.181005  8221 sgd_solver.cpp:106] Iteration 255000, lr = 0.003
I0521 16:47:39.345762  8221 solver.cpp:237] Iteration 256500, loss = 0.94723
I0521 16:47:39.345940  8221 solver.cpp:253]     Train net output #0: loss = 0.947226 (* 1 = 0.947226 loss)
I0521 16:47:39.345955  8221 sgd_solver.cpp:106] Iteration 256500, lr = 0.003
I0521 16:47:56.559229  8221 solver.cpp:237] Iteration 258000, loss = 0.403395
I0521 16:47:56.559267  8221 solver.cpp:253]     Train net output #0: loss = 0.403391 (* 1 = 0.403391 loss)
I0521 16:47:56.559281  8221 sgd_solver.cpp:106] Iteration 258000, lr = 0.003
I0521 16:48:13.743582  8221 solver.cpp:237] Iteration 259500, loss = 1.07512
I0521 16:48:13.743742  8221 solver.cpp:253]     Train net output #0: loss = 1.07512 (* 1 = 1.07512 loss)
I0521 16:48:13.743755  8221 sgd_solver.cpp:106] Iteration 259500, lr = 0.003
I0521 16:48:51.765142  8221 solver.cpp:237] Iteration 261000, loss = 1.18688
I0521 16:48:51.765316  8221 solver.cpp:253]     Train net output #0: loss = 1.18688 (* 1 = 1.18688 loss)
I0521 16:48:51.765331  8221 sgd_solver.cpp:106] Iteration 261000, lr = 0.003
I0521 16:49:08.638329  8221 solver.cpp:237] Iteration 262500, loss = 1.9584
I0521 16:49:08.638365  8221 solver.cpp:253]     Train net output #0: loss = 1.9584 (* 1 = 1.9584 loss)
I0521 16:49:08.638378  8221 sgd_solver.cpp:106] Iteration 262500, lr = 0.003
I0521 16:49:25.504251  8221 solver.cpp:237] Iteration 264000, loss = 2.29861
I0521 16:49:25.504410  8221 solver.cpp:253]     Train net output #0: loss = 2.29861 (* 1 = 2.29861 loss)
I0521 16:49:25.504423  8221 sgd_solver.cpp:106] Iteration 264000, lr = 0.003
I0521 16:49:42.321458  8221 solver.cpp:237] Iteration 265500, loss = 1.01913
I0521 16:49:42.321494  8221 solver.cpp:253]     Train net output #0: loss = 1.01913 (* 1 = 1.01913 loss)
I0521 16:49:42.321516  8221 sgd_solver.cpp:106] Iteration 265500, lr = 0.003
I0521 16:49:59.207974  8221 solver.cpp:237] Iteration 267000, loss = 1.34823
I0521 16:49:59.208124  8221 solver.cpp:253]     Train net output #0: loss = 1.34823 (* 1 = 1.34823 loss)
I0521 16:49:59.208138  8221 sgd_solver.cpp:106] Iteration 267000, lr = 0.003
I0521 16:50:16.068238  8221 solver.cpp:237] Iteration 268500, loss = 1.41162
I0521 16:50:16.068279  8221 solver.cpp:253]     Train net output #0: loss = 1.41161 (* 1 = 1.41161 loss)
I0521 16:50:16.068291  8221 sgd_solver.cpp:106] Iteration 268500, lr = 0.003
I0521 16:50:32.954102  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_270000.caffemodel
I0521 16:50:32.999428  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_270000.solverstate
I0521 16:50:33.024722  8221 solver.cpp:341] Iteration 270000, Testing net (#0)
I0521 16:51:32.101706  8221 solver.cpp:409]     Test net output #0: accuracy = 0.889224
I0521 16:51:32.101886  8221 solver.cpp:409]     Test net output #1: loss = 0.350449 (* 1 = 0.350449 loss)
I0521 16:51:52.948642  8221 solver.cpp:237] Iteration 270000, loss = 1.62379
I0521 16:51:52.948691  8221 solver.cpp:253]     Train net output #0: loss = 1.62379 (* 1 = 1.62379 loss)
I0521 16:51:52.948706  8221 sgd_solver.cpp:106] Iteration 270000, lr = 0.003
I0521 16:52:09.718744  8221 solver.cpp:237] Iteration 271500, loss = 2.13557
I0521 16:52:09.718915  8221 solver.cpp:253]     Train net output #0: loss = 2.13556 (* 1 = 2.13556 loss)
I0521 16:52:09.718930  8221 sgd_solver.cpp:106] Iteration 271500, lr = 0.003
I0521 16:52:26.490759  8221 solver.cpp:237] Iteration 273000, loss = 1.76096
I0521 16:52:26.490795  8221 solver.cpp:253]     Train net output #0: loss = 1.76095 (* 1 = 1.76095 loss)
I0521 16:52:26.490813  8221 sgd_solver.cpp:106] Iteration 273000, lr = 0.003
I0521 16:52:43.254856  8221 solver.cpp:237] Iteration 274500, loss = 0.925403
I0521 16:52:43.255030  8221 solver.cpp:253]     Train net output #0: loss = 0.925398 (* 1 = 0.925398 loss)
I0521 16:52:43.255044  8221 sgd_solver.cpp:106] Iteration 274500, lr = 0.003
I0521 16:53:00.048009  8221 solver.cpp:237] Iteration 276000, loss = 1.3414
I0521 16:53:00.048049  8221 solver.cpp:253]     Train net output #0: loss = 1.3414 (* 1 = 1.3414 loss)
I0521 16:53:00.048068  8221 sgd_solver.cpp:106] Iteration 276000, lr = 0.003
I0521 16:53:16.647122  8221 solver.cpp:237] Iteration 277500, loss = 1.28122
I0521 16:53:16.647274  8221 solver.cpp:253]     Train net output #0: loss = 1.28121 (* 1 = 1.28121 loss)
I0521 16:53:16.647289  8221 sgd_solver.cpp:106] Iteration 277500, lr = 0.003
I0521 16:53:33.287195  8221 solver.cpp:237] Iteration 279000, loss = 1.04799
I0521 16:53:33.287243  8221 solver.cpp:253]     Train net output #0: loss = 1.04798 (* 1 = 1.04798 loss)
I0521 16:53:33.287259  8221 sgd_solver.cpp:106] Iteration 279000, lr = 0.003
I0521 16:54:10.775872  8221 solver.cpp:237] Iteration 280500, loss = 1.49678
I0521 16:54:10.776046  8221 solver.cpp:253]     Train net output #0: loss = 1.49678 (* 1 = 1.49678 loss)
I0521 16:54:10.776060  8221 sgd_solver.cpp:106] Iteration 280500, lr = 0.003
I0521 16:54:27.400530  8221 solver.cpp:237] Iteration 282000, loss = 0.846412
I0521 16:54:27.400579  8221 solver.cpp:253]     Train net output #0: loss = 0.846408 (* 1 = 0.846408 loss)
I0521 16:54:27.400594  8221 sgd_solver.cpp:106] Iteration 282000, lr = 0.003
I0521 16:54:44.040470  8221 solver.cpp:237] Iteration 283500, loss = 1.02873
I0521 16:54:44.040635  8221 solver.cpp:253]     Train net output #0: loss = 1.02873 (* 1 = 1.02873 loss)
I0521 16:54:44.040649  8221 sgd_solver.cpp:106] Iteration 283500, lr = 0.003
I0521 16:55:00.631649  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_285000.caffemodel
I0521 16:55:00.680052  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_285000.solverstate
I0521 16:55:00.711215  8221 solver.cpp:237] Iteration 285000, loss = 3.7618
I0521 16:55:00.711261  8221 solver.cpp:253]     Train net output #0: loss = 3.7618 (* 1 = 3.7618 loss)
I0521 16:55:00.711278  8221 sgd_solver.cpp:106] Iteration 285000, lr = 0.003
I0521 16:55:17.320297  8221 solver.cpp:237] Iteration 286500, loss = 1.07222
I0521 16:55:17.320469  8221 solver.cpp:253]     Train net output #0: loss = 1.07222 (* 1 = 1.07222 loss)
I0521 16:55:17.320483  8221 sgd_solver.cpp:106] Iteration 286500, lr = 0.003
I0521 16:55:33.920301  8221 solver.cpp:237] Iteration 288000, loss = 2.73752
I0521 16:55:33.920352  8221 solver.cpp:253]     Train net output #0: loss = 2.73752 (* 1 = 2.73752 loss)
I0521 16:55:33.920367  8221 sgd_solver.cpp:106] Iteration 288000, lr = 0.003
I0521 16:55:50.519445  8221 solver.cpp:237] Iteration 289500, loss = 1.74003
I0521 16:55:50.519605  8221 solver.cpp:253]     Train net output #0: loss = 1.74003 (* 1 = 1.74003 loss)
I0521 16:55:50.519620  8221 sgd_solver.cpp:106] Iteration 289500, lr = 0.003
I0521 16:56:28.371311  8221 solver.cpp:237] Iteration 291000, loss = 0.968056
I0521 16:56:28.371490  8221 solver.cpp:253]     Train net output #0: loss = 0.968054 (* 1 = 0.968054 loss)
I0521 16:56:28.371505  8221 sgd_solver.cpp:106] Iteration 291000, lr = 0.003
I0521 16:56:45.426308  8221 solver.cpp:237] Iteration 292500, loss = 1.01425
I0521 16:56:45.426353  8221 solver.cpp:253]     Train net output #0: loss = 1.01424 (* 1 = 1.01424 loss)
I0521 16:56:45.426369  8221 sgd_solver.cpp:106] Iteration 292500, lr = 0.003
I0521 16:57:02.458603  8221 solver.cpp:237] Iteration 294000, loss = 1.66087
I0521 16:57:02.458770  8221 solver.cpp:253]     Train net output #0: loss = 1.66086 (* 1 = 1.66086 loss)
I0521 16:57:02.458786  8221 sgd_solver.cpp:106] Iteration 294000, lr = 0.003
I0521 16:57:19.527216  8221 solver.cpp:237] Iteration 295500, loss = 1.13853
I0521 16:57:19.527259  8221 solver.cpp:253]     Train net output #0: loss = 1.13853 (* 1 = 1.13853 loss)
I0521 16:57:19.527273  8221 sgd_solver.cpp:106] Iteration 295500, lr = 0.003
I0521 16:57:36.542279  8221 solver.cpp:237] Iteration 297000, loss = 1.44088
I0521 16:57:36.542440  8221 solver.cpp:253]     Train net output #0: loss = 1.44088 (* 1 = 1.44088 loss)
I0521 16:57:36.542454  8221 sgd_solver.cpp:106] Iteration 297000, lr = 0.003
I0521 16:57:53.561250  8221 solver.cpp:237] Iteration 298500, loss = 1.25797
I0521 16:57:53.561285  8221 solver.cpp:253]     Train net output #0: loss = 1.25797 (* 1 = 1.25797 loss)
I0521 16:57:53.561302  8221 sgd_solver.cpp:106] Iteration 298500, lr = 0.003
I0521 16:58:10.594501  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_300000.caffemodel
I0521 16:58:10.643369  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_300000.solverstate
I0521 16:58:10.670951  8221 solver.cpp:341] Iteration 300000, Testing net (#0)
I0521 16:59:30.713165  8221 solver.cpp:409]     Test net output #0: accuracy = 0.892257
I0521 16:59:30.713340  8221 solver.cpp:409]     Test net output #1: loss = 0.349805 (* 1 = 0.349805 loss)
I0521 16:59:51.565585  8221 solver.cpp:237] Iteration 300000, loss = 1.35171
I0521 16:59:51.565636  8221 solver.cpp:253]     Train net output #0: loss = 1.35171 (* 1 = 1.35171 loss)
I0521 16:59:51.565654  8221 sgd_solver.cpp:106] Iteration 300000, lr = 0.003
I0521 17:00:08.190979  8221 solver.cpp:237] Iteration 301500, loss = 1.37427
I0521 17:00:08.191148  8221 solver.cpp:253]     Train net output #0: loss = 1.37426 (* 1 = 1.37426 loss)
I0521 17:00:08.191162  8221 sgd_solver.cpp:106] Iteration 301500, lr = 0.003
I0521 17:00:24.821610  8221 solver.cpp:237] Iteration 303000, loss = 0.989619
I0521 17:00:24.821647  8221 solver.cpp:253]     Train net output #0: loss = 0.989613 (* 1 = 0.989613 loss)
I0521 17:00:24.821662  8221 sgd_solver.cpp:106] Iteration 303000, lr = 0.003
I0521 17:00:41.428355  8221 solver.cpp:237] Iteration 304500, loss = 1.37987
I0521 17:00:41.428524  8221 solver.cpp:253]     Train net output #0: loss = 1.37987 (* 1 = 1.37987 loss)
I0521 17:00:41.428537  8221 sgd_solver.cpp:106] Iteration 304500, lr = 0.003
I0521 17:00:58.020035  8221 solver.cpp:237] Iteration 306000, loss = 0.877021
I0521 17:00:58.020084  8221 solver.cpp:253]     Train net output #0: loss = 0.877015 (* 1 = 0.877015 loss)
I0521 17:00:58.020100  8221 sgd_solver.cpp:106] Iteration 306000, lr = 0.003
I0521 17:01:14.640425  8221 solver.cpp:237] Iteration 307500, loss = 1.00227
I0521 17:01:14.640583  8221 solver.cpp:253]     Train net output #0: loss = 1.00227 (* 1 = 1.00227 loss)
I0521 17:01:14.640596  8221 sgd_solver.cpp:106] Iteration 307500, lr = 0.003
I0521 17:01:31.272078  8221 solver.cpp:237] Iteration 309000, loss = 1.38669
I0521 17:01:31.272125  8221 solver.cpp:253]     Train net output #0: loss = 1.38669 (* 1 = 1.38669 loss)
I0521 17:01:31.272137  8221 sgd_solver.cpp:106] Iteration 309000, lr = 0.003
I0521 17:02:08.712734  8221 solver.cpp:237] Iteration 310500, loss = 1.60823
I0521 17:02:08.712909  8221 solver.cpp:253]     Train net output #0: loss = 1.60823 (* 1 = 1.60823 loss)
I0521 17:02:08.712924  8221 sgd_solver.cpp:106] Iteration 310500, lr = 0.003
I0521 17:02:25.324875  8221 solver.cpp:237] Iteration 312000, loss = 1.48061
I0521 17:02:25.324920  8221 solver.cpp:253]     Train net output #0: loss = 1.48061 (* 1 = 1.48061 loss)
I0521 17:02:25.324936  8221 sgd_solver.cpp:106] Iteration 312000, lr = 0.003
I0521 17:02:41.917708  8221 solver.cpp:237] Iteration 313500, loss = 1.53919
I0521 17:02:41.917901  8221 solver.cpp:253]     Train net output #0: loss = 1.53919 (* 1 = 1.53919 loss)
I0521 17:02:41.917917  8221 sgd_solver.cpp:106] Iteration 313500, lr = 0.003
I0521 17:02:58.493985  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_315000.caffemodel
I0521 17:02:58.539351  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_315000.solverstate
I0521 17:02:58.568400  8221 solver.cpp:237] Iteration 315000, loss = 0.712496
I0521 17:02:58.568441  8221 solver.cpp:253]     Train net output #0: loss = 0.712492 (* 1 = 0.712492 loss)
I0521 17:02:58.568461  8221 sgd_solver.cpp:106] Iteration 315000, lr = 0.003
I0521 17:03:15.165194  8221 solver.cpp:237] Iteration 316500, loss = 1.02709
I0521 17:03:15.165365  8221 solver.cpp:253]     Train net output #0: loss = 1.02709 (* 1 = 1.02709 loss)
I0521 17:03:15.165380  8221 sgd_solver.cpp:106] Iteration 316500, lr = 0.003
I0521 17:03:31.811115  8221 solver.cpp:237] Iteration 318000, loss = 0.771356
I0521 17:03:31.811164  8221 solver.cpp:253]     Train net output #0: loss = 0.771352 (* 1 = 0.771352 loss)
I0521 17:03:31.811179  8221 sgd_solver.cpp:106] Iteration 318000, lr = 0.003
I0521 17:03:48.435299  8221 solver.cpp:237] Iteration 319500, loss = 1.1942
I0521 17:03:48.435458  8221 solver.cpp:253]     Train net output #0: loss = 1.1942 (* 1 = 1.1942 loss)
I0521 17:03:48.435472  8221 sgd_solver.cpp:106] Iteration 319500, lr = 0.003
I0521 17:04:25.942209  8221 solver.cpp:237] Iteration 321000, loss = 1.67817
I0521 17:04:25.942387  8221 solver.cpp:253]     Train net output #0: loss = 1.67817 (* 1 = 1.67817 loss)
I0521 17:04:25.942402  8221 sgd_solver.cpp:106] Iteration 321000, lr = 0.003
I0521 17:04:42.580519  8221 solver.cpp:237] Iteration 322500, loss = 0.584371
I0521 17:04:42.580565  8221 solver.cpp:253]     Train net output #0: loss = 0.584369 (* 1 = 0.584369 loss)
I0521 17:04:42.580580  8221 sgd_solver.cpp:106] Iteration 322500, lr = 0.003
I0521 17:04:59.191135  8221 solver.cpp:237] Iteration 324000, loss = 1.40273
I0521 17:04:59.191292  8221 solver.cpp:253]     Train net output #0: loss = 1.40273 (* 1 = 1.40273 loss)
I0521 17:04:59.191308  8221 sgd_solver.cpp:106] Iteration 324000, lr = 0.003
I0521 17:05:15.800479  8221 solver.cpp:237] Iteration 325500, loss = 1.30593
I0521 17:05:15.800523  8221 solver.cpp:253]     Train net output #0: loss = 1.30593 (* 1 = 1.30593 loss)
I0521 17:05:15.800539  8221 sgd_solver.cpp:106] Iteration 325500, lr = 0.003
I0521 17:05:32.465380  8221 solver.cpp:237] Iteration 327000, loss = 1.33218
I0521 17:05:32.465561  8221 solver.cpp:253]     Train net output #0: loss = 1.33218 (* 1 = 1.33218 loss)
I0521 17:05:32.465576  8221 sgd_solver.cpp:106] Iteration 327000, lr = 0.003
I0521 17:05:49.085176  8221 solver.cpp:237] Iteration 328500, loss = 1.7226
I0521 17:05:49.085212  8221 solver.cpp:253]     Train net output #0: loss = 1.72259 (* 1 = 1.72259 loss)
I0521 17:05:49.085230  8221 sgd_solver.cpp:106] Iteration 328500, lr = 0.003
I0521 17:06:05.708701  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_330000.caffemodel
I0521 17:06:05.754118  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_330000.solverstate
I0521 17:06:05.779029  8221 solver.cpp:341] Iteration 330000, Testing net (#0)
I0521 17:07:05.099253  8221 solver.cpp:409]     Test net output #0: accuracy = 0.894383
I0521 17:07:05.099426  8221 solver.cpp:409]     Test net output #1: loss = 0.330496 (* 1 = 0.330496 loss)
I0521 17:07:25.947427  8221 solver.cpp:237] Iteration 330000, loss = 0.766145
I0521 17:07:25.947481  8221 solver.cpp:253]     Train net output #0: loss = 0.766141 (* 1 = 0.766141 loss)
I0521 17:07:25.947496  8221 sgd_solver.cpp:106] Iteration 330000, lr = 0.003
I0521 17:07:42.563992  8221 solver.cpp:237] Iteration 331500, loss = 1.20581
I0521 17:07:42.564182  8221 solver.cpp:253]     Train net output #0: loss = 1.20581 (* 1 = 1.20581 loss)
I0521 17:07:42.564196  8221 sgd_solver.cpp:106] Iteration 331500, lr = 0.003
I0521 17:07:59.178102  8221 solver.cpp:237] Iteration 333000, loss = 1.34232
I0521 17:07:59.178141  8221 solver.cpp:253]     Train net output #0: loss = 1.34231 (* 1 = 1.34231 loss)
I0521 17:07:59.178158  8221 sgd_solver.cpp:106] Iteration 333000, lr = 0.003
I0521 17:08:15.811259  8221 solver.cpp:237] Iteration 334500, loss = 1.10403
I0521 17:08:15.811416  8221 solver.cpp:253]     Train net output #0: loss = 1.10403 (* 1 = 1.10403 loss)
I0521 17:08:15.811430  8221 sgd_solver.cpp:106] Iteration 334500, lr = 0.003
I0521 17:08:32.422873  8221 solver.cpp:237] Iteration 336000, loss = 0.815843
I0521 17:08:32.422924  8221 solver.cpp:253]     Train net output #0: loss = 0.815842 (* 1 = 0.815842 loss)
I0521 17:08:32.422936  8221 sgd_solver.cpp:106] Iteration 336000, lr = 0.003
I0521 17:08:49.048077  8221 solver.cpp:237] Iteration 337500, loss = 1.04387
I0521 17:08:49.048240  8221 solver.cpp:253]     Train net output #0: loss = 1.04387 (* 1 = 1.04387 loss)
I0521 17:08:49.048254  8221 sgd_solver.cpp:106] Iteration 337500, lr = 0.003
I0521 17:09:05.620482  8221 solver.cpp:237] Iteration 339000, loss = 1.37755
I0521 17:09:05.620517  8221 solver.cpp:253]     Train net output #0: loss = 1.37755 (* 1 = 1.37755 loss)
I0521 17:09:05.620535  8221 sgd_solver.cpp:106] Iteration 339000, lr = 0.003
I0521 17:09:43.226542  8221 solver.cpp:237] Iteration 340500, loss = 1.5753
I0521 17:09:43.226722  8221 solver.cpp:253]     Train net output #0: loss = 1.5753 (* 1 = 1.5753 loss)
I0521 17:09:43.226735  8221 sgd_solver.cpp:106] Iteration 340500, lr = 0.003
I0521 17:10:00.099771  8221 solver.cpp:237] Iteration 342000, loss = 1.47187
I0521 17:10:00.099805  8221 solver.cpp:253]     Train net output #0: loss = 1.47187 (* 1 = 1.47187 loss)
I0521 17:10:00.099830  8221 sgd_solver.cpp:106] Iteration 342000, lr = 0.003
I0521 17:10:16.982885  8221 solver.cpp:237] Iteration 343500, loss = 1.44465
I0521 17:10:16.983053  8221 solver.cpp:253]     Train net output #0: loss = 1.44465 (* 1 = 1.44465 loss)
I0521 17:10:16.983067  8221 sgd_solver.cpp:106] Iteration 343500, lr = 0.003
I0521 17:10:33.871422  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_345000.caffemodel
I0521 17:10:33.917353  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_345000.solverstate
I0521 17:10:33.945796  8221 solver.cpp:237] Iteration 345000, loss = 0.698938
I0521 17:10:33.945842  8221 solver.cpp:253]     Train net output #0: loss = 0.698934 (* 1 = 0.698934 loss)
I0521 17:10:33.945857  8221 sgd_solver.cpp:106] Iteration 345000, lr = 0.003
I0521 17:10:50.817416  8221 solver.cpp:237] Iteration 346500, loss = 1.08038
I0521 17:10:50.817577  8221 solver.cpp:253]     Train net output #0: loss = 1.08038 (* 1 = 1.08038 loss)
I0521 17:10:50.817594  8221 sgd_solver.cpp:106] Iteration 346500, lr = 0.003
I0521 17:11:07.650542  8221 solver.cpp:237] Iteration 348000, loss = 1.4557
I0521 17:11:07.650586  8221 solver.cpp:253]     Train net output #0: loss = 1.45569 (* 1 = 1.45569 loss)
I0521 17:11:07.650604  8221 sgd_solver.cpp:106] Iteration 348000, lr = 0.003
I0521 17:11:24.514189  8221 solver.cpp:237] Iteration 349500, loss = 1.29577
I0521 17:11:24.514358  8221 solver.cpp:253]     Train net output #0: loss = 1.29577 (* 1 = 1.29577 loss)
I0521 17:11:24.514371  8221 sgd_solver.cpp:106] Iteration 349500, lr = 0.003
I0521 17:12:02.218780  8221 solver.cpp:237] Iteration 351000, loss = 1.09594
I0521 17:12:02.218971  8221 solver.cpp:253]     Train net output #0: loss = 1.09593 (* 1 = 1.09593 loss)
I0521 17:12:02.218986  8221 sgd_solver.cpp:106] Iteration 351000, lr = 0.003
I0521 17:12:19.045563  8221 solver.cpp:237] Iteration 352500, loss = 0.602542
I0521 17:12:19.045611  8221 solver.cpp:253]     Train net output #0: loss = 0.602538 (* 1 = 0.602538 loss)
I0521 17:12:19.045625  8221 sgd_solver.cpp:106] Iteration 352500, lr = 0.003
I0521 17:12:35.897279  8221 solver.cpp:237] Iteration 354000, loss = 1.29036
I0521 17:12:35.897456  8221 solver.cpp:253]     Train net output #0: loss = 1.29036 (* 1 = 1.29036 loss)
I0521 17:12:35.897470  8221 sgd_solver.cpp:106] Iteration 354000, lr = 0.003
I0521 17:12:52.805248  8221 solver.cpp:237] Iteration 355500, loss = 0.862248
I0521 17:12:52.805285  8221 solver.cpp:253]     Train net output #0: loss = 0.862243 (* 1 = 0.862243 loss)
I0521 17:12:52.805301  8221 sgd_solver.cpp:106] Iteration 355500, lr = 0.003
I0521 17:13:09.657263  8221 solver.cpp:237] Iteration 357000, loss = 1.58242
I0521 17:13:09.657433  8221 solver.cpp:253]     Train net output #0: loss = 1.58242 (* 1 = 1.58242 loss)
I0521 17:13:09.657446  8221 sgd_solver.cpp:106] Iteration 357000, lr = 0.003
I0521 17:13:26.462172  8221 solver.cpp:237] Iteration 358500, loss = 0.675178
I0521 17:13:26.462213  8221 solver.cpp:253]     Train net output #0: loss = 0.675172 (* 1 = 0.675172 loss)
I0521 17:13:26.462229  8221 sgd_solver.cpp:106] Iteration 358500, lr = 0.003
I0521 17:13:43.324108  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_360000.caffemodel
I0521 17:13:43.370297  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_360000.solverstate
I0521 17:13:43.395994  8221 solver.cpp:341] Iteration 360000, Testing net (#0)
I0521 17:15:03.728660  8221 solver.cpp:409]     Test net output #0: accuracy = 0.885187
I0521 17:15:03.728835  8221 solver.cpp:409]     Test net output #1: loss = 0.362947 (* 1 = 0.362947 loss)
I0521 17:15:24.623922  8221 solver.cpp:237] Iteration 360000, loss = 1.29841
I0521 17:15:24.623975  8221 solver.cpp:253]     Train net output #0: loss = 1.29841 (* 1 = 1.29841 loss)
I0521 17:15:24.623991  8221 sgd_solver.cpp:106] Iteration 360000, lr = 0.003
I0521 17:15:41.242625  8221 solver.cpp:237] Iteration 361500, loss = 1.03042
I0521 17:15:41.242796  8221 solver.cpp:253]     Train net output #0: loss = 1.03041 (* 1 = 1.03041 loss)
I0521 17:15:41.242810  8221 sgd_solver.cpp:106] Iteration 361500, lr = 0.003
I0521 17:15:57.825120  8221 solver.cpp:237] Iteration 363000, loss = 1.74395
I0521 17:15:57.825162  8221 solver.cpp:253]     Train net output #0: loss = 1.74394 (* 1 = 1.74394 loss)
I0521 17:15:57.825179  8221 sgd_solver.cpp:106] Iteration 363000, lr = 0.003
I0521 17:16:14.405453  8221 solver.cpp:237] Iteration 364500, loss = 1.10915
I0521 17:16:14.405608  8221 solver.cpp:253]     Train net output #0: loss = 1.10915 (* 1 = 1.10915 loss)
I0521 17:16:14.405622  8221 sgd_solver.cpp:106] Iteration 364500, lr = 0.003
I0521 17:16:30.976277  8221 solver.cpp:237] Iteration 366000, loss = 1.15718
I0521 17:16:30.976325  8221 solver.cpp:253]     Train net output #0: loss = 1.15718 (* 1 = 1.15718 loss)
I0521 17:16:30.976338  8221 sgd_solver.cpp:106] Iteration 366000, lr = 0.003
I0521 17:16:47.591362  8221 solver.cpp:237] Iteration 367500, loss = 0.622524
I0521 17:16:47.591534  8221 solver.cpp:253]     Train net output #0: loss = 0.622519 (* 1 = 0.622519 loss)
I0521 17:16:47.591548  8221 sgd_solver.cpp:106] Iteration 367500, lr = 0.003
I0521 17:17:04.210043  8221 solver.cpp:237] Iteration 369000, loss = 1.19515
I0521 17:17:04.210079  8221 solver.cpp:253]     Train net output #0: loss = 1.19514 (* 1 = 1.19514 loss)
I0521 17:17:04.210096  8221 sgd_solver.cpp:106] Iteration 369000, lr = 0.003
I0521 17:17:41.690847  8221 solver.cpp:237] Iteration 370500, loss = 1.50039
I0521 17:17:41.691037  8221 solver.cpp:253]     Train net output #0: loss = 1.50038 (* 1 = 1.50038 loss)
I0521 17:17:41.691051  8221 sgd_solver.cpp:106] Iteration 370500, lr = 0.003
I0521 17:17:58.316509  8221 solver.cpp:237] Iteration 372000, loss = 0.568904
I0521 17:17:58.316547  8221 solver.cpp:253]     Train net output #0: loss = 0.568897 (* 1 = 0.568897 loss)
I0521 17:17:58.316561  8221 sgd_solver.cpp:106] Iteration 372000, lr = 0.003
I0521 17:18:14.946553  8221 solver.cpp:237] Iteration 373500, loss = 1.73853
I0521 17:18:14.946730  8221 solver.cpp:253]     Train net output #0: loss = 1.73853 (* 1 = 1.73853 loss)
I0521 17:18:14.946745  8221 sgd_solver.cpp:106] Iteration 373500, lr = 0.003
I0521 17:18:31.526594  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_375000.caffemodel
I0521 17:18:31.574568  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_375000.solverstate
I0521 17:18:31.605712  8221 solver.cpp:237] Iteration 375000, loss = 1.01252
I0521 17:18:31.605762  8221 solver.cpp:253]     Train net output #0: loss = 1.01252 (* 1 = 1.01252 loss)
I0521 17:18:31.605777  8221 sgd_solver.cpp:106] Iteration 375000, lr = 0.003
I0521 17:18:48.220971  8221 solver.cpp:237] Iteration 376500, loss = 1.27631
I0521 17:18:48.221138  8221 solver.cpp:253]     Train net output #0: loss = 1.27631 (* 1 = 1.27631 loss)
I0521 17:18:48.221153  8221 sgd_solver.cpp:106] Iteration 376500, lr = 0.003
I0521 17:19:05.146997  8221 solver.cpp:237] Iteration 378000, loss = 1.06302
I0521 17:19:05.147048  8221 solver.cpp:253]     Train net output #0: loss = 1.06301 (* 1 = 1.06301 loss)
I0521 17:19:05.147063  8221 sgd_solver.cpp:106] Iteration 378000, lr = 0.003
I0521 17:19:22.005939  8221 solver.cpp:237] Iteration 379500, loss = 1.03426
I0521 17:19:22.006110  8221 solver.cpp:253]     Train net output #0: loss = 1.03425 (* 1 = 1.03425 loss)
I0521 17:19:22.006124  8221 sgd_solver.cpp:106] Iteration 379500, lr = 0.003
I0521 17:19:59.760781  8221 solver.cpp:237] Iteration 381000, loss = 1.14661
I0521 17:19:59.760959  8221 solver.cpp:253]     Train net output #0: loss = 1.1466 (* 1 = 1.1466 loss)
I0521 17:19:59.760974  8221 sgd_solver.cpp:106] Iteration 381000, lr = 0.003
I0521 17:20:16.653765  8221 solver.cpp:237] Iteration 382500, loss = 0.531837
I0521 17:20:16.653811  8221 solver.cpp:253]     Train net output #0: loss = 0.53183 (* 1 = 0.53183 loss)
I0521 17:20:16.653828  8221 sgd_solver.cpp:106] Iteration 382500, lr = 0.003
I0521 17:20:33.523697  8221 solver.cpp:237] Iteration 384000, loss = 1.117
I0521 17:20:33.523883  8221 solver.cpp:253]     Train net output #0: loss = 1.11699 (* 1 = 1.11699 loss)
I0521 17:20:33.523897  8221 sgd_solver.cpp:106] Iteration 384000, lr = 0.003
I0521 17:20:50.444538  8221 solver.cpp:237] Iteration 385500, loss = 1.67312
I0521 17:20:50.444574  8221 solver.cpp:253]     Train net output #0: loss = 1.67311 (* 1 = 1.67311 loss)
I0521 17:20:50.444591  8221 sgd_solver.cpp:106] Iteration 385500, lr = 0.003
I0521 17:21:07.292526  8221 solver.cpp:237] Iteration 387000, loss = 0.988152
I0521 17:21:07.292695  8221 solver.cpp:253]     Train net output #0: loss = 0.988145 (* 1 = 0.988145 loss)
I0521 17:21:07.292711  8221 sgd_solver.cpp:106] Iteration 387000, lr = 0.003
I0521 17:21:24.150624  8221 solver.cpp:237] Iteration 388500, loss = 0.89482
I0521 17:21:24.150670  8221 solver.cpp:253]     Train net output #0: loss = 0.894813 (* 1 = 0.894813 loss)
I0521 17:21:24.150686  8221 sgd_solver.cpp:106] Iteration 388500, lr = 0.003
I0521 17:21:41.004959  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_390000.caffemodel
I0521 17:21:41.050850  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_390000.solverstate
I0521 17:21:41.075647  8221 solver.cpp:341] Iteration 390000, Testing net (#0)
I0521 17:22:40.674530  8221 solver.cpp:409]     Test net output #0: accuracy = 0.895584
I0521 17:22:40.674707  8221 solver.cpp:409]     Test net output #1: loss = 0.335268 (* 1 = 0.335268 loss)
I0521 17:23:01.529716  8221 solver.cpp:237] Iteration 390000, loss = 0.99259
I0521 17:23:01.529768  8221 solver.cpp:253]     Train net output #0: loss = 0.992582 (* 1 = 0.992582 loss)
I0521 17:23:01.529783  8221 sgd_solver.cpp:106] Iteration 390000, lr = 0.003
I0521 17:23:18.539294  8221 solver.cpp:237] Iteration 391500, loss = 0.969661
I0521 17:23:18.539460  8221 solver.cpp:253]     Train net output #0: loss = 0.969654 (* 1 = 0.969654 loss)
I0521 17:23:18.539474  8221 sgd_solver.cpp:106] Iteration 391500, lr = 0.003
I0521 17:23:35.559520  8221 solver.cpp:237] Iteration 393000, loss = 2.0267
I0521 17:23:35.559568  8221 solver.cpp:253]     Train net output #0: loss = 2.02669 (* 1 = 2.02669 loss)
I0521 17:23:35.559582  8221 sgd_solver.cpp:106] Iteration 393000, lr = 0.003
I0521 17:23:52.613453  8221 solver.cpp:237] Iteration 394500, loss = 1.45734
I0521 17:23:52.613626  8221 solver.cpp:253]     Train net output #0: loss = 1.45733 (* 1 = 1.45733 loss)
I0521 17:23:52.613639  8221 sgd_solver.cpp:106] Iteration 394500, lr = 0.003
I0521 17:24:09.667683  8221 solver.cpp:237] Iteration 396000, loss = 1.29206
I0521 17:24:09.667719  8221 solver.cpp:253]     Train net output #0: loss = 1.29205 (* 1 = 1.29205 loss)
I0521 17:24:09.667735  8221 sgd_solver.cpp:106] Iteration 396000, lr = 0.003
I0521 17:24:26.728840  8221 solver.cpp:237] Iteration 397500, loss = 0.723147
I0521 17:24:26.729018  8221 solver.cpp:253]     Train net output #0: loss = 0.723139 (* 1 = 0.723139 loss)
I0521 17:24:26.729033  8221 sgd_solver.cpp:106] Iteration 397500, lr = 0.003
I0521 17:24:43.739434  8221 solver.cpp:237] Iteration 399000, loss = 0.942956
I0521 17:24:43.739483  8221 solver.cpp:253]     Train net output #0: loss = 0.942948 (* 1 = 0.942948 loss)
I0521 17:24:43.739497  8221 sgd_solver.cpp:106] Iteration 399000, lr = 0.003
I0521 17:25:21.604086  8221 solver.cpp:237] Iteration 400500, loss = 1.20587
I0521 17:25:21.604267  8221 solver.cpp:253]     Train net output #0: loss = 1.20586 (* 1 = 1.20586 loss)
I0521 17:25:21.604284  8221 sgd_solver.cpp:106] Iteration 400500, lr = 0.003
I0521 17:25:38.609529  8221 solver.cpp:237] Iteration 402000, loss = 0.822106
I0521 17:25:38.609575  8221 solver.cpp:253]     Train net output #0: loss = 0.822097 (* 1 = 0.822097 loss)
I0521 17:25:38.609591  8221 sgd_solver.cpp:106] Iteration 402000, lr = 0.003
I0521 17:25:55.638427  8221 solver.cpp:237] Iteration 403500, loss = 0.820774
I0521 17:25:55.638600  8221 solver.cpp:253]     Train net output #0: loss = 0.820765 (* 1 = 0.820765 loss)
I0521 17:25:55.638614  8221 sgd_solver.cpp:106] Iteration 403500, lr = 0.003
I0521 17:26:12.651281  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_405000.caffemodel
I0521 17:26:12.697336  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_405000.solverstate
I0521 17:26:12.725994  8221 solver.cpp:237] Iteration 405000, loss = 1.00772
I0521 17:26:12.726039  8221 solver.cpp:253]     Train net output #0: loss = 1.00771 (* 1 = 1.00771 loss)
I0521 17:26:12.726058  8221 sgd_solver.cpp:106] Iteration 405000, lr = 0.003
I0521 17:26:29.747681  8221 solver.cpp:237] Iteration 406500, loss = 1.01701
I0521 17:26:29.747865  8221 solver.cpp:253]     Train net output #0: loss = 1.017 (* 1 = 1.017 loss)
I0521 17:26:29.747879  8221 sgd_solver.cpp:106] Iteration 406500, lr = 0.003
I0521 17:26:46.791800  8221 solver.cpp:237] Iteration 408000, loss = 0.986196
I0521 17:26:46.791854  8221 solver.cpp:253]     Train net output #0: loss = 0.986187 (* 1 = 0.986187 loss)
I0521 17:26:46.791868  8221 sgd_solver.cpp:106] Iteration 408000, lr = 0.003
I0521 17:27:03.824511  8221 solver.cpp:237] Iteration 409500, loss = 0.544213
I0521 17:27:03.824688  8221 solver.cpp:253]     Train net output #0: loss = 0.544203 (* 1 = 0.544203 loss)
I0521 17:27:03.824703  8221 sgd_solver.cpp:106] Iteration 409500, lr = 0.003
I0521 17:27:41.553371  8221 solver.cpp:237] Iteration 411000, loss = 1.2434
I0521 17:27:41.553555  8221 solver.cpp:253]     Train net output #0: loss = 1.24339 (* 1 = 1.24339 loss)
I0521 17:27:41.553570  8221 sgd_solver.cpp:106] Iteration 411000, lr = 0.003
I0521 17:27:58.179306  8221 solver.cpp:237] Iteration 412500, loss = 3.41271
I0521 17:27:58.179343  8221 solver.cpp:253]     Train net output #0: loss = 3.4127 (* 1 = 3.4127 loss)
I0521 17:27:58.179359  8221 sgd_solver.cpp:106] Iteration 412500, lr = 0.003
I0521 17:28:15.200182  8221 solver.cpp:237] Iteration 414000, loss = 1.67943
I0521 17:28:15.200356  8221 solver.cpp:253]     Train net output #0: loss = 1.67942 (* 1 = 1.67942 loss)
I0521 17:28:15.200369  8221 sgd_solver.cpp:106] Iteration 414000, lr = 0.003
I0521 17:28:32.236385  8221 solver.cpp:237] Iteration 415500, loss = 1.65206
I0521 17:28:32.236428  8221 solver.cpp:253]     Train net output #0: loss = 1.65205 (* 1 = 1.65205 loss)
I0521 17:28:32.236444  8221 sgd_solver.cpp:106] Iteration 415500, lr = 0.003
I0521 17:28:49.284109  8221 solver.cpp:237] Iteration 417000, loss = 1.37795
I0521 17:28:49.284287  8221 solver.cpp:253]     Train net output #0: loss = 1.37794 (* 1 = 1.37794 loss)
I0521 17:28:49.284302  8221 sgd_solver.cpp:106] Iteration 417000, lr = 0.003
I0521 17:29:06.361397  8221 solver.cpp:237] Iteration 418500, loss = 0.934906
I0521 17:29:06.361434  8221 solver.cpp:253]     Train net output #0: loss = 0.934896 (* 1 = 0.934896 loss)
I0521 17:29:06.361449  8221 sgd_solver.cpp:106] Iteration 418500, lr = 0.003
I0521 17:29:23.396447  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_420000.caffemodel
I0521 17:29:23.442028  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_420000.solverstate
I0521 17:29:23.467308  8221 solver.cpp:341] Iteration 420000, Testing net (#0)
I0521 17:30:43.956091  8221 solver.cpp:409]     Test net output #0: accuracy = 0.893293
I0521 17:30:43.956274  8221 solver.cpp:409]     Test net output #1: loss = 0.333612 (* 1 = 0.333612 loss)
I0521 17:31:04.818812  8221 solver.cpp:237] Iteration 420000, loss = 1.98972
I0521 17:31:04.818863  8221 solver.cpp:253]     Train net output #0: loss = 1.98971 (* 1 = 1.98971 loss)
I0521 17:31:04.818877  8221 sgd_solver.cpp:106] Iteration 420000, lr = 0.003
I0521 17:31:21.461462  8221 solver.cpp:237] Iteration 421500, loss = 1.21774
I0521 17:31:21.461642  8221 solver.cpp:253]     Train net output #0: loss = 1.21773 (* 1 = 1.21773 loss)
I0521 17:31:21.461657  8221 sgd_solver.cpp:106] Iteration 421500, lr = 0.003
I0521 17:31:38.486961  8221 solver.cpp:237] Iteration 423000, loss = 0.853209
I0521 17:31:38.486997  8221 solver.cpp:253]     Train net output #0: loss = 0.8532 (* 1 = 0.8532 loss)
I0521 17:31:38.487012  8221 sgd_solver.cpp:106] Iteration 423000, lr = 0.003
I0521 17:31:55.521533  8221 solver.cpp:237] Iteration 424500, loss = 1.11266
I0521 17:31:55.521710  8221 solver.cpp:253]     Train net output #0: loss = 1.11266 (* 1 = 1.11266 loss)
I0521 17:31:55.521724  8221 sgd_solver.cpp:106] Iteration 424500, lr = 0.003
I0521 17:32:12.493019  8221 solver.cpp:237] Iteration 426000, loss = 1.19053
I0521 17:32:12.493067  8221 solver.cpp:253]     Train net output #0: loss = 1.19052 (* 1 = 1.19052 loss)
I0521 17:32:12.493083  8221 sgd_solver.cpp:106] Iteration 426000, lr = 0.003
I0521 17:32:29.292203  8221 solver.cpp:237] Iteration 427500, loss = 1.27977
I0521 17:32:29.292382  8221 solver.cpp:253]     Train net output #0: loss = 1.27977 (* 1 = 1.27977 loss)
I0521 17:32:29.292395  8221 sgd_solver.cpp:106] Iteration 427500, lr = 0.003
I0521 17:32:46.062225  8221 solver.cpp:237] Iteration 429000, loss = 0.438231
I0521 17:32:46.062273  8221 solver.cpp:253]     Train net output #0: loss = 0.438222 (* 1 = 0.438222 loss)
I0521 17:32:46.062286  8221 sgd_solver.cpp:106] Iteration 429000, lr = 0.003
I0521 17:33:23.711218  8221 solver.cpp:237] Iteration 430500, loss = 1.22055
I0521 17:33:23.711405  8221 solver.cpp:253]     Train net output #0: loss = 1.22054 (* 1 = 1.22054 loss)
I0521 17:33:23.711421  8221 sgd_solver.cpp:106] Iteration 430500, lr = 0.003
I0521 17:33:40.506438  8221 solver.cpp:237] Iteration 432000, loss = 1.23341
I0521 17:33:40.506484  8221 solver.cpp:253]     Train net output #0: loss = 1.2334 (* 1 = 1.2334 loss)
I0521 17:33:40.506499  8221 sgd_solver.cpp:106] Iteration 432000, lr = 0.003
I0521 17:33:57.309936  8221 solver.cpp:237] Iteration 433500, loss = 1.18102
I0521 17:33:57.310114  8221 solver.cpp:253]     Train net output #0: loss = 1.18101 (* 1 = 1.18101 loss)
I0521 17:33:57.310129  8221 sgd_solver.cpp:106] Iteration 433500, lr = 0.003
I0521 17:34:14.049003  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_435000.caffemodel
I0521 17:34:14.097291  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_435000.solverstate
I0521 17:34:14.128005  8221 solver.cpp:237] Iteration 435000, loss = 1.57904
I0521 17:34:14.128054  8221 solver.cpp:253]     Train net output #0: loss = 1.57903 (* 1 = 1.57903 loss)
I0521 17:34:14.128070  8221 sgd_solver.cpp:106] Iteration 435000, lr = 0.003
I0521 17:34:30.873167  8221 solver.cpp:237] Iteration 436500, loss = 1.08271
I0521 17:34:30.873335  8221 solver.cpp:253]     Train net output #0: loss = 1.08271 (* 1 = 1.08271 loss)
I0521 17:34:30.873349  8221 sgd_solver.cpp:106] Iteration 436500, lr = 0.003
I0521 17:34:47.640321  8221 solver.cpp:237] Iteration 438000, loss = 2.53023
I0521 17:34:47.640367  8221 solver.cpp:253]     Train net output #0: loss = 2.53022 (* 1 = 2.53022 loss)
I0521 17:34:47.640383  8221 sgd_solver.cpp:106] Iteration 438000, lr = 0.003
I0521 17:35:04.418617  8221 solver.cpp:237] Iteration 439500, loss = 1.08493
I0521 17:35:04.418794  8221 solver.cpp:253]     Train net output #0: loss = 1.08492 (* 1 = 1.08492 loss)
I0521 17:35:04.418809  8221 sgd_solver.cpp:106] Iteration 439500, lr = 0.003
I0521 17:35:42.119560  8221 solver.cpp:237] Iteration 441000, loss = 0.939365
I0521 17:35:42.119747  8221 solver.cpp:253]     Train net output #0: loss = 0.939358 (* 1 = 0.939358 loss)
I0521 17:35:42.119763  8221 sgd_solver.cpp:106] Iteration 441000, lr = 0.003
I0521 17:35:58.883534  8221 solver.cpp:237] Iteration 442500, loss = 2.13816
I0521 17:35:58.883584  8221 solver.cpp:253]     Train net output #0: loss = 2.13816 (* 1 = 2.13816 loss)
I0521 17:35:58.883597  8221 sgd_solver.cpp:106] Iteration 442500, lr = 0.003
I0521 17:36:15.673270  8221 solver.cpp:237] Iteration 444000, loss = 1.10427
I0521 17:36:15.673434  8221 solver.cpp:253]     Train net output #0: loss = 1.10426 (* 1 = 1.10426 loss)
I0521 17:36:15.673449  8221 sgd_solver.cpp:106] Iteration 444000, lr = 0.003
I0521 17:36:32.420013  8221 solver.cpp:237] Iteration 445500, loss = 1.30946
I0521 17:36:32.420061  8221 solver.cpp:253]     Train net output #0: loss = 1.30946 (* 1 = 1.30946 loss)
I0521 17:36:32.420075  8221 sgd_solver.cpp:106] Iteration 445500, lr = 0.003
I0521 17:36:49.195861  8221 solver.cpp:237] Iteration 447000, loss = 0.90099
I0521 17:36:49.196038  8221 solver.cpp:253]     Train net output #0: loss = 0.900982 (* 1 = 0.900982 loss)
I0521 17:36:49.196053  8221 sgd_solver.cpp:106] Iteration 447000, lr = 0.003
I0521 17:37:05.951011  8221 solver.cpp:237] Iteration 448500, loss = 0.762287
I0521 17:37:05.951048  8221 solver.cpp:253]     Train net output #0: loss = 0.762279 (* 1 = 0.762279 loss)
I0521 17:37:05.951066  8221 sgd_solver.cpp:106] Iteration 448500, lr = 0.003
I0521 17:37:22.742835  8221 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_450000.caffemodel
I0521 17:37:22.791100  8221 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0030_2016-05-20T15.48.51.258925_iter_450000.solverstate
I0521 17:37:22.818614  8221 solver.cpp:341] Iteration 450000, Testing net (#0)
I0521 17:38:21.873347  8221 solver.cpp:409]     Test net output #0: accuracy = 0.880752
I0521 17:38:21.873528  8221 solver.cpp:409]     Test net output #1: loss = 0.394906 (* 1 = 0.394906 loss)
I0521 17:38:42.772917  8221 solver.cpp:237] Iteration 450000, loss = 1.17774
I0521 17:38:42.772969  8221 solver.cpp:253]     Train net output #0: loss = 1.17773 (* 1 = 1.17773 loss)
I0521 17:38:42.772984  8221 sgd_solver.cpp:106] Iteration 450000, lr = 0.003
I0521 17:38:59.826256  8221 solver.cpp:237] Iteration 451500, loss = 1.28075
I0521 17:38:59.826436  8221 solver.cpp:253]     Train net output #0: loss = 1.28074 (* 1 = 1.28074 loss)
I0521 17:38:59.826450  8221 sgd_solver.cpp:106] Iteration 451500, lr = 0.003
I0521 17:39:16.862685  8221 solver.cpp:237] Iteration 453000, loss = 1.54851
I0521 17:39:16.862733  8221 solver.cpp:253]     Train net output #0: loss = 1.5485 (* 1 = 1.5485 loss)
I0521 17:39:16.862752  8221 sgd_solver.cpp:106] Iteration 453000, lr = 0.003
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
*** Aborted at 1463866768 (unix time) try "date -d @1463866768" if you are using GNU date ***
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
PC: @     0x2aaab9276640 (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
*** SIGTERM (@0x201a) received by PID 8221 (TID 0x2aaac746f900) from PID 8218; stack trace: ***
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab9276640 (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab930eb7d (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab928a408 (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab91e97a1 (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
=>> PBS: job killed: walltime 7211 exceeded limit 7200
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab91e98af (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab928ea34 (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab928ec2c (unknown)
    @     0x2aaab926d723 (unknown)
aprun: Apid 11239661: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
