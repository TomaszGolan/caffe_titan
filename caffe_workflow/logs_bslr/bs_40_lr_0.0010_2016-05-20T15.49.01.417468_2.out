2813068
I0527 07:46:40.236382 19848 caffe.cpp:184] Using GPUs 0
I0527 07:46:40.664219 19848 solver.cpp:48] Initializing solver from parameters: 
test_iter: 3750
test_interval: 7500
base_lr: 0.001
display: 375
max_iter: 375000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 3750
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468.prototxt"
I0527 07:46:40.666173 19848 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468.prototxt
I0527 07:46:40.682699 19848 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0527 07:46:40.682762 19848 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0527 07:46:40.683112 19848 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 07:46:40.683293 19848 layer_factory.hpp:77] Creating layer data_hdf5
I0527 07:46:40.683318 19848 net.cpp:106] Creating Layer data_hdf5
I0527 07:46:40.683332 19848 net.cpp:411] data_hdf5 -> data
I0527 07:46:40.683367 19848 net.cpp:411] data_hdf5 -> label
I0527 07:46:40.683398 19848 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0527 07:46:40.684728 19848 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0527 07:46:40.687762 19848 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0527 07:47:02.241320 19848 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0527 07:47:02.246444 19848 net.cpp:150] Setting up data_hdf5
I0527 07:47:02.246484 19848 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 07:47:02.246498 19848 net.cpp:157] Top shape: 40 (40)
I0527 07:47:02.246511 19848 net.cpp:165] Memory required for data: 1016160
I0527 07:47:02.246526 19848 layer_factory.hpp:77] Creating layer conv1
I0527 07:47:02.246559 19848 net.cpp:106] Creating Layer conv1
I0527 07:47:02.246570 19848 net.cpp:454] conv1 <- data
I0527 07:47:02.246592 19848 net.cpp:411] conv1 -> conv1
I0527 07:47:02.609587 19848 net.cpp:150] Setting up conv1
I0527 07:47:02.609635 19848 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:47:02.609647 19848 net.cpp:165] Memory required for data: 12075360
I0527 07:47:02.609674 19848 layer_factory.hpp:77] Creating layer relu1
I0527 07:47:02.609696 19848 net.cpp:106] Creating Layer relu1
I0527 07:47:02.609707 19848 net.cpp:454] relu1 <- conv1
I0527 07:47:02.609721 19848 net.cpp:397] relu1 -> conv1 (in-place)
I0527 07:47:02.610235 19848 net.cpp:150] Setting up relu1
I0527 07:47:02.610251 19848 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:47:02.610261 19848 net.cpp:165] Memory required for data: 23134560
I0527 07:47:02.610272 19848 layer_factory.hpp:77] Creating layer pool1
I0527 07:47:02.610288 19848 net.cpp:106] Creating Layer pool1
I0527 07:47:02.610298 19848 net.cpp:454] pool1 <- conv1
I0527 07:47:02.610311 19848 net.cpp:411] pool1 -> pool1
I0527 07:47:02.610393 19848 net.cpp:150] Setting up pool1
I0527 07:47:02.610406 19848 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 07:47:02.610416 19848 net.cpp:165] Memory required for data: 28664160
I0527 07:47:02.610424 19848 layer_factory.hpp:77] Creating layer conv2
I0527 07:47:02.610447 19848 net.cpp:106] Creating Layer conv2
I0527 07:47:02.610457 19848 net.cpp:454] conv2 <- pool1
I0527 07:47:02.610469 19848 net.cpp:411] conv2 -> conv2
I0527 07:47:02.613164 19848 net.cpp:150] Setting up conv2
I0527 07:47:02.613188 19848 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:47:02.613203 19848 net.cpp:165] Memory required for data: 36612960
I0527 07:47:02.613221 19848 layer_factory.hpp:77] Creating layer relu2
I0527 07:47:02.613236 19848 net.cpp:106] Creating Layer relu2
I0527 07:47:02.613246 19848 net.cpp:454] relu2 <- conv2
I0527 07:47:02.613260 19848 net.cpp:397] relu2 -> conv2 (in-place)
I0527 07:47:02.613587 19848 net.cpp:150] Setting up relu2
I0527 07:47:02.613602 19848 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:47:02.613612 19848 net.cpp:165] Memory required for data: 44561760
I0527 07:47:02.613622 19848 layer_factory.hpp:77] Creating layer pool2
I0527 07:47:02.613636 19848 net.cpp:106] Creating Layer pool2
I0527 07:47:02.613646 19848 net.cpp:454] pool2 <- conv2
I0527 07:47:02.613658 19848 net.cpp:411] pool2 -> pool2
I0527 07:47:02.613739 19848 net.cpp:150] Setting up pool2
I0527 07:47:02.613752 19848 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 07:47:02.613762 19848 net.cpp:165] Memory required for data: 48536160
I0527 07:47:02.613773 19848 layer_factory.hpp:77] Creating layer conv3
I0527 07:47:02.613791 19848 net.cpp:106] Creating Layer conv3
I0527 07:47:02.613802 19848 net.cpp:454] conv3 <- pool2
I0527 07:47:02.613816 19848 net.cpp:411] conv3 -> conv3
I0527 07:47:02.615756 19848 net.cpp:150] Setting up conv3
I0527 07:47:02.615779 19848 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:47:02.615792 19848 net.cpp:165] Memory required for data: 52872800
I0527 07:47:02.615809 19848 layer_factory.hpp:77] Creating layer relu3
I0527 07:47:02.615826 19848 net.cpp:106] Creating Layer relu3
I0527 07:47:02.615836 19848 net.cpp:454] relu3 <- conv3
I0527 07:47:02.615849 19848 net.cpp:397] relu3 -> conv3 (in-place)
I0527 07:47:02.616317 19848 net.cpp:150] Setting up relu3
I0527 07:47:02.616334 19848 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:47:02.616344 19848 net.cpp:165] Memory required for data: 57209440
I0527 07:47:02.616354 19848 layer_factory.hpp:77] Creating layer pool3
I0527 07:47:02.616369 19848 net.cpp:106] Creating Layer pool3
I0527 07:47:02.616377 19848 net.cpp:454] pool3 <- conv3
I0527 07:47:02.616390 19848 net.cpp:411] pool3 -> pool3
I0527 07:47:02.616456 19848 net.cpp:150] Setting up pool3
I0527 07:47:02.616471 19848 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 07:47:02.616479 19848 net.cpp:165] Memory required for data: 59377760
I0527 07:47:02.616487 19848 layer_factory.hpp:77] Creating layer conv4
I0527 07:47:02.616505 19848 net.cpp:106] Creating Layer conv4
I0527 07:47:02.616516 19848 net.cpp:454] conv4 <- pool3
I0527 07:47:02.616530 19848 net.cpp:411] conv4 -> conv4
I0527 07:47:02.619288 19848 net.cpp:150] Setting up conv4
I0527 07:47:02.619316 19848 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:47:02.619328 19848 net.cpp:165] Memory required for data: 60829280
I0527 07:47:02.619343 19848 layer_factory.hpp:77] Creating layer relu4
I0527 07:47:02.619357 19848 net.cpp:106] Creating Layer relu4
I0527 07:47:02.619367 19848 net.cpp:454] relu4 <- conv4
I0527 07:47:02.619380 19848 net.cpp:397] relu4 -> conv4 (in-place)
I0527 07:47:02.619856 19848 net.cpp:150] Setting up relu4
I0527 07:47:02.619873 19848 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:47:02.619882 19848 net.cpp:165] Memory required for data: 62280800
I0527 07:47:02.619894 19848 layer_factory.hpp:77] Creating layer pool4
I0527 07:47:02.619906 19848 net.cpp:106] Creating Layer pool4
I0527 07:47:02.619915 19848 net.cpp:454] pool4 <- conv4
I0527 07:47:02.619928 19848 net.cpp:411] pool4 -> pool4
I0527 07:47:02.619997 19848 net.cpp:150] Setting up pool4
I0527 07:47:02.620010 19848 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 07:47:02.620020 19848 net.cpp:165] Memory required for data: 63006560
I0527 07:47:02.620031 19848 layer_factory.hpp:77] Creating layer ip1
I0527 07:47:02.620051 19848 net.cpp:106] Creating Layer ip1
I0527 07:47:02.620062 19848 net.cpp:454] ip1 <- pool4
I0527 07:47:02.620075 19848 net.cpp:411] ip1 -> ip1
I0527 07:47:02.635469 19848 net.cpp:150] Setting up ip1
I0527 07:47:02.635499 19848 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:47:02.635510 19848 net.cpp:165] Memory required for data: 63037920
I0527 07:47:02.635534 19848 layer_factory.hpp:77] Creating layer relu5
I0527 07:47:02.635547 19848 net.cpp:106] Creating Layer relu5
I0527 07:47:02.635557 19848 net.cpp:454] relu5 <- ip1
I0527 07:47:02.635571 19848 net.cpp:397] relu5 -> ip1 (in-place)
I0527 07:47:02.635910 19848 net.cpp:150] Setting up relu5
I0527 07:47:02.635924 19848 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:47:02.635934 19848 net.cpp:165] Memory required for data: 63069280
I0527 07:47:02.635946 19848 layer_factory.hpp:77] Creating layer drop1
I0527 07:47:02.635967 19848 net.cpp:106] Creating Layer drop1
I0527 07:47:02.635977 19848 net.cpp:454] drop1 <- ip1
I0527 07:47:02.635989 19848 net.cpp:397] drop1 -> ip1 (in-place)
I0527 07:47:02.636049 19848 net.cpp:150] Setting up drop1
I0527 07:47:02.636061 19848 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:47:02.636071 19848 net.cpp:165] Memory required for data: 63100640
I0527 07:47:02.636082 19848 layer_factory.hpp:77] Creating layer ip2
I0527 07:47:02.636101 19848 net.cpp:106] Creating Layer ip2
I0527 07:47:02.636111 19848 net.cpp:454] ip2 <- ip1
I0527 07:47:02.636124 19848 net.cpp:411] ip2 -> ip2
I0527 07:47:02.636585 19848 net.cpp:150] Setting up ip2
I0527 07:47:02.636600 19848 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:47:02.636608 19848 net.cpp:165] Memory required for data: 63116320
I0527 07:47:02.636623 19848 layer_factory.hpp:77] Creating layer relu6
I0527 07:47:02.636636 19848 net.cpp:106] Creating Layer relu6
I0527 07:47:02.636646 19848 net.cpp:454] relu6 <- ip2
I0527 07:47:02.636657 19848 net.cpp:397] relu6 -> ip2 (in-place)
I0527 07:47:02.637179 19848 net.cpp:150] Setting up relu6
I0527 07:47:02.637197 19848 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:47:02.637207 19848 net.cpp:165] Memory required for data: 63132000
I0527 07:47:02.637217 19848 layer_factory.hpp:77] Creating layer drop2
I0527 07:47:02.637229 19848 net.cpp:106] Creating Layer drop2
I0527 07:47:02.637239 19848 net.cpp:454] drop2 <- ip2
I0527 07:47:02.637253 19848 net.cpp:397] drop2 -> ip2 (in-place)
I0527 07:47:02.637295 19848 net.cpp:150] Setting up drop2
I0527 07:47:02.637307 19848 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:47:02.637317 19848 net.cpp:165] Memory required for data: 63147680
I0527 07:47:02.637327 19848 layer_factory.hpp:77] Creating layer ip3
I0527 07:47:02.637341 19848 net.cpp:106] Creating Layer ip3
I0527 07:47:02.637351 19848 net.cpp:454] ip3 <- ip2
I0527 07:47:02.637363 19848 net.cpp:411] ip3 -> ip3
I0527 07:47:02.637575 19848 net.cpp:150] Setting up ip3
I0527 07:47:02.637588 19848 net.cpp:157] Top shape: 40 11 (440)
I0527 07:47:02.637598 19848 net.cpp:165] Memory required for data: 63149440
I0527 07:47:02.637614 19848 layer_factory.hpp:77] Creating layer drop3
I0527 07:47:02.637625 19848 net.cpp:106] Creating Layer drop3
I0527 07:47:02.637635 19848 net.cpp:454] drop3 <- ip3
I0527 07:47:02.637647 19848 net.cpp:397] drop3 -> ip3 (in-place)
I0527 07:47:02.637687 19848 net.cpp:150] Setting up drop3
I0527 07:47:02.637701 19848 net.cpp:157] Top shape: 40 11 (440)
I0527 07:47:02.637711 19848 net.cpp:165] Memory required for data: 63151200
I0527 07:47:02.637720 19848 layer_factory.hpp:77] Creating layer loss
I0527 07:47:02.637739 19848 net.cpp:106] Creating Layer loss
I0527 07:47:02.637749 19848 net.cpp:454] loss <- ip3
I0527 07:47:02.637760 19848 net.cpp:454] loss <- label
I0527 07:47:02.637773 19848 net.cpp:411] loss -> loss
I0527 07:47:02.637790 19848 layer_factory.hpp:77] Creating layer loss
I0527 07:47:02.638430 19848 net.cpp:150] Setting up loss
I0527 07:47:02.638451 19848 net.cpp:157] Top shape: (1)
I0527 07:47:02.638465 19848 net.cpp:160]     with loss weight 1
I0527 07:47:02.638507 19848 net.cpp:165] Memory required for data: 63151204
I0527 07:47:02.638519 19848 net.cpp:226] loss needs backward computation.
I0527 07:47:02.638528 19848 net.cpp:226] drop3 needs backward computation.
I0527 07:47:02.638537 19848 net.cpp:226] ip3 needs backward computation.
I0527 07:47:02.638548 19848 net.cpp:226] drop2 needs backward computation.
I0527 07:47:02.638557 19848 net.cpp:226] relu6 needs backward computation.
I0527 07:47:02.638567 19848 net.cpp:226] ip2 needs backward computation.
I0527 07:47:02.638577 19848 net.cpp:226] drop1 needs backward computation.
I0527 07:47:02.638587 19848 net.cpp:226] relu5 needs backward computation.
I0527 07:47:02.638597 19848 net.cpp:226] ip1 needs backward computation.
I0527 07:47:02.638607 19848 net.cpp:226] pool4 needs backward computation.
I0527 07:47:02.638617 19848 net.cpp:226] relu4 needs backward computation.
I0527 07:47:02.638628 19848 net.cpp:226] conv4 needs backward computation.
I0527 07:47:02.638638 19848 net.cpp:226] pool3 needs backward computation.
I0527 07:47:02.638648 19848 net.cpp:226] relu3 needs backward computation.
I0527 07:47:02.638659 19848 net.cpp:226] conv3 needs backward computation.
I0527 07:47:02.638677 19848 net.cpp:226] pool2 needs backward computation.
I0527 07:47:02.638689 19848 net.cpp:226] relu2 needs backward computation.
I0527 07:47:02.638698 19848 net.cpp:226] conv2 needs backward computation.
I0527 07:47:02.638717 19848 net.cpp:226] pool1 needs backward computation.
I0527 07:47:02.638728 19848 net.cpp:226] relu1 needs backward computation.
I0527 07:47:02.638738 19848 net.cpp:226] conv1 needs backward computation.
I0527 07:47:02.638749 19848 net.cpp:228] data_hdf5 does not need backward computation.
I0527 07:47:02.638759 19848 net.cpp:270] This network produces output loss
I0527 07:47:02.638783 19848 net.cpp:283] Network initialization done.
I0527 07:47:02.640478 19848 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468.prototxt
I0527 07:47:02.640550 19848 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0527 07:47:02.640904 19848 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 40
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0527 07:47:02.641093 19848 layer_factory.hpp:77] Creating layer data_hdf5
I0527 07:47:02.641109 19848 net.cpp:106] Creating Layer data_hdf5
I0527 07:47:02.641121 19848 net.cpp:411] data_hdf5 -> data
I0527 07:47:02.641139 19848 net.cpp:411] data_hdf5 -> label
I0527 07:47:02.641155 19848 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0527 07:47:02.642379 19848 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0527 07:47:23.987643 19848 net.cpp:150] Setting up data_hdf5
I0527 07:47:23.987808 19848 net.cpp:157] Top shape: 40 1 127 50 (254000)
I0527 07:47:23.987823 19848 net.cpp:157] Top shape: 40 (40)
I0527 07:47:23.987833 19848 net.cpp:165] Memory required for data: 1016160
I0527 07:47:23.987848 19848 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0527 07:47:23.987875 19848 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0527 07:47:23.987886 19848 net.cpp:454] label_data_hdf5_1_split <- label
I0527 07:47:23.987901 19848 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0527 07:47:23.987922 19848 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0527 07:47:23.987995 19848 net.cpp:150] Setting up label_data_hdf5_1_split
I0527 07:47:23.988009 19848 net.cpp:157] Top shape: 40 (40)
I0527 07:47:23.988021 19848 net.cpp:157] Top shape: 40 (40)
I0527 07:47:23.988030 19848 net.cpp:165] Memory required for data: 1016480
I0527 07:47:23.988040 19848 layer_factory.hpp:77] Creating layer conv1
I0527 07:47:23.988064 19848 net.cpp:106] Creating Layer conv1
I0527 07:47:23.988073 19848 net.cpp:454] conv1 <- data
I0527 07:47:23.988088 19848 net.cpp:411] conv1 -> conv1
I0527 07:47:23.990056 19848 net.cpp:150] Setting up conv1
I0527 07:47:23.990082 19848 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:47:23.990093 19848 net.cpp:165] Memory required for data: 12075680
I0527 07:47:23.990114 19848 layer_factory.hpp:77] Creating layer relu1
I0527 07:47:23.990129 19848 net.cpp:106] Creating Layer relu1
I0527 07:47:23.990139 19848 net.cpp:454] relu1 <- conv1
I0527 07:47:23.990152 19848 net.cpp:397] relu1 -> conv1 (in-place)
I0527 07:47:23.990648 19848 net.cpp:150] Setting up relu1
I0527 07:47:23.990664 19848 net.cpp:157] Top shape: 40 12 120 48 (2764800)
I0527 07:47:23.990674 19848 net.cpp:165] Memory required for data: 23134880
I0527 07:47:23.990684 19848 layer_factory.hpp:77] Creating layer pool1
I0527 07:47:23.990701 19848 net.cpp:106] Creating Layer pool1
I0527 07:47:23.990718 19848 net.cpp:454] pool1 <- conv1
I0527 07:47:23.990732 19848 net.cpp:411] pool1 -> pool1
I0527 07:47:23.990808 19848 net.cpp:150] Setting up pool1
I0527 07:47:23.990823 19848 net.cpp:157] Top shape: 40 12 60 48 (1382400)
I0527 07:47:23.990833 19848 net.cpp:165] Memory required for data: 28664480
I0527 07:47:23.990842 19848 layer_factory.hpp:77] Creating layer conv2
I0527 07:47:23.990859 19848 net.cpp:106] Creating Layer conv2
I0527 07:47:23.990869 19848 net.cpp:454] conv2 <- pool1
I0527 07:47:23.990883 19848 net.cpp:411] conv2 -> conv2
I0527 07:47:23.992799 19848 net.cpp:150] Setting up conv2
I0527 07:47:23.992815 19848 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:47:23.992827 19848 net.cpp:165] Memory required for data: 36613280
I0527 07:47:23.992846 19848 layer_factory.hpp:77] Creating layer relu2
I0527 07:47:23.992858 19848 net.cpp:106] Creating Layer relu2
I0527 07:47:23.992868 19848 net.cpp:454] relu2 <- conv2
I0527 07:47:23.992882 19848 net.cpp:397] relu2 -> conv2 (in-place)
I0527 07:47:23.993213 19848 net.cpp:150] Setting up relu2
I0527 07:47:23.993227 19848 net.cpp:157] Top shape: 40 20 54 46 (1987200)
I0527 07:47:23.993237 19848 net.cpp:165] Memory required for data: 44562080
I0527 07:47:23.993247 19848 layer_factory.hpp:77] Creating layer pool2
I0527 07:47:23.993259 19848 net.cpp:106] Creating Layer pool2
I0527 07:47:23.993269 19848 net.cpp:454] pool2 <- conv2
I0527 07:47:23.993283 19848 net.cpp:411] pool2 -> pool2
I0527 07:47:23.993355 19848 net.cpp:150] Setting up pool2
I0527 07:47:23.993367 19848 net.cpp:157] Top shape: 40 20 27 46 (993600)
I0527 07:47:23.993377 19848 net.cpp:165] Memory required for data: 48536480
I0527 07:47:23.993387 19848 layer_factory.hpp:77] Creating layer conv3
I0527 07:47:23.993403 19848 net.cpp:106] Creating Layer conv3
I0527 07:47:23.993414 19848 net.cpp:454] conv3 <- pool2
I0527 07:47:23.993428 19848 net.cpp:411] conv3 -> conv3
I0527 07:47:23.995404 19848 net.cpp:150] Setting up conv3
I0527 07:47:23.995429 19848 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:47:23.995440 19848 net.cpp:165] Memory required for data: 52873120
I0527 07:47:23.995472 19848 layer_factory.hpp:77] Creating layer relu3
I0527 07:47:23.995486 19848 net.cpp:106] Creating Layer relu3
I0527 07:47:23.995496 19848 net.cpp:454] relu3 <- conv3
I0527 07:47:23.995509 19848 net.cpp:397] relu3 -> conv3 (in-place)
I0527 07:47:23.995981 19848 net.cpp:150] Setting up relu3
I0527 07:47:23.995997 19848 net.cpp:157] Top shape: 40 28 22 44 (1084160)
I0527 07:47:23.996008 19848 net.cpp:165] Memory required for data: 57209760
I0527 07:47:23.996018 19848 layer_factory.hpp:77] Creating layer pool3
I0527 07:47:23.996032 19848 net.cpp:106] Creating Layer pool3
I0527 07:47:23.996042 19848 net.cpp:454] pool3 <- conv3
I0527 07:47:23.996054 19848 net.cpp:411] pool3 -> pool3
I0527 07:47:23.996126 19848 net.cpp:150] Setting up pool3
I0527 07:47:23.996140 19848 net.cpp:157] Top shape: 40 28 11 44 (542080)
I0527 07:47:23.996150 19848 net.cpp:165] Memory required for data: 59378080
I0527 07:47:23.996158 19848 layer_factory.hpp:77] Creating layer conv4
I0527 07:47:23.996176 19848 net.cpp:106] Creating Layer conv4
I0527 07:47:23.996186 19848 net.cpp:454] conv4 <- pool3
I0527 07:47:23.996201 19848 net.cpp:411] conv4 -> conv4
I0527 07:47:23.998255 19848 net.cpp:150] Setting up conv4
I0527 07:47:23.998277 19848 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:47:23.998289 19848 net.cpp:165] Memory required for data: 60829600
I0527 07:47:23.998304 19848 layer_factory.hpp:77] Creating layer relu4
I0527 07:47:23.998317 19848 net.cpp:106] Creating Layer relu4
I0527 07:47:23.998327 19848 net.cpp:454] relu4 <- conv4
I0527 07:47:23.998340 19848 net.cpp:397] relu4 -> conv4 (in-place)
I0527 07:47:23.998816 19848 net.cpp:150] Setting up relu4
I0527 07:47:23.998831 19848 net.cpp:157] Top shape: 40 36 6 42 (362880)
I0527 07:47:23.998842 19848 net.cpp:165] Memory required for data: 62281120
I0527 07:47:23.998852 19848 layer_factory.hpp:77] Creating layer pool4
I0527 07:47:23.998867 19848 net.cpp:106] Creating Layer pool4
I0527 07:47:23.998877 19848 net.cpp:454] pool4 <- conv4
I0527 07:47:23.998889 19848 net.cpp:411] pool4 -> pool4
I0527 07:47:23.998961 19848 net.cpp:150] Setting up pool4
I0527 07:47:23.998975 19848 net.cpp:157] Top shape: 40 36 3 42 (181440)
I0527 07:47:23.998985 19848 net.cpp:165] Memory required for data: 63006880
I0527 07:47:23.998994 19848 layer_factory.hpp:77] Creating layer ip1
I0527 07:47:23.999011 19848 net.cpp:106] Creating Layer ip1
I0527 07:47:23.999020 19848 net.cpp:454] ip1 <- pool4
I0527 07:47:23.999034 19848 net.cpp:411] ip1 -> ip1
I0527 07:47:24.014386 19848 net.cpp:150] Setting up ip1
I0527 07:47:24.014415 19848 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:47:24.014426 19848 net.cpp:165] Memory required for data: 63038240
I0527 07:47:24.014448 19848 layer_factory.hpp:77] Creating layer relu5
I0527 07:47:24.014463 19848 net.cpp:106] Creating Layer relu5
I0527 07:47:24.014473 19848 net.cpp:454] relu5 <- ip1
I0527 07:47:24.014488 19848 net.cpp:397] relu5 -> ip1 (in-place)
I0527 07:47:24.014842 19848 net.cpp:150] Setting up relu5
I0527 07:47:24.014855 19848 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:47:24.014865 19848 net.cpp:165] Memory required for data: 63069600
I0527 07:47:24.014876 19848 layer_factory.hpp:77] Creating layer drop1
I0527 07:47:24.014894 19848 net.cpp:106] Creating Layer drop1
I0527 07:47:24.014904 19848 net.cpp:454] drop1 <- ip1
I0527 07:47:24.014917 19848 net.cpp:397] drop1 -> ip1 (in-place)
I0527 07:47:24.014962 19848 net.cpp:150] Setting up drop1
I0527 07:47:24.014976 19848 net.cpp:157] Top shape: 40 196 (7840)
I0527 07:47:24.014986 19848 net.cpp:165] Memory required for data: 63100960
I0527 07:47:24.014994 19848 layer_factory.hpp:77] Creating layer ip2
I0527 07:47:24.015009 19848 net.cpp:106] Creating Layer ip2
I0527 07:47:24.015018 19848 net.cpp:454] ip2 <- ip1
I0527 07:47:24.015033 19848 net.cpp:411] ip2 -> ip2
I0527 07:47:24.015513 19848 net.cpp:150] Setting up ip2
I0527 07:47:24.015527 19848 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:47:24.015537 19848 net.cpp:165] Memory required for data: 63116640
I0527 07:47:24.015552 19848 layer_factory.hpp:77] Creating layer relu6
I0527 07:47:24.015578 19848 net.cpp:106] Creating Layer relu6
I0527 07:47:24.015588 19848 net.cpp:454] relu6 <- ip2
I0527 07:47:24.015601 19848 net.cpp:397] relu6 -> ip2 (in-place)
I0527 07:47:24.016141 19848 net.cpp:150] Setting up relu6
I0527 07:47:24.016157 19848 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:47:24.016167 19848 net.cpp:165] Memory required for data: 63132320
I0527 07:47:24.016178 19848 layer_factory.hpp:77] Creating layer drop2
I0527 07:47:24.016191 19848 net.cpp:106] Creating Layer drop2
I0527 07:47:24.016201 19848 net.cpp:454] drop2 <- ip2
I0527 07:47:24.016216 19848 net.cpp:397] drop2 -> ip2 (in-place)
I0527 07:47:24.016259 19848 net.cpp:150] Setting up drop2
I0527 07:47:24.016273 19848 net.cpp:157] Top shape: 40 98 (3920)
I0527 07:47:24.016283 19848 net.cpp:165] Memory required for data: 63148000
I0527 07:47:24.016294 19848 layer_factory.hpp:77] Creating layer ip3
I0527 07:47:24.016307 19848 net.cpp:106] Creating Layer ip3
I0527 07:47:24.016317 19848 net.cpp:454] ip3 <- ip2
I0527 07:47:24.016332 19848 net.cpp:411] ip3 -> ip3
I0527 07:47:24.016557 19848 net.cpp:150] Setting up ip3
I0527 07:47:24.016571 19848 net.cpp:157] Top shape: 40 11 (440)
I0527 07:47:24.016580 19848 net.cpp:165] Memory required for data: 63149760
I0527 07:47:24.016595 19848 layer_factory.hpp:77] Creating layer drop3
I0527 07:47:24.016609 19848 net.cpp:106] Creating Layer drop3
I0527 07:47:24.016619 19848 net.cpp:454] drop3 <- ip3
I0527 07:47:24.016633 19848 net.cpp:397] drop3 -> ip3 (in-place)
I0527 07:47:24.016674 19848 net.cpp:150] Setting up drop3
I0527 07:47:24.016687 19848 net.cpp:157] Top shape: 40 11 (440)
I0527 07:47:24.016697 19848 net.cpp:165] Memory required for data: 63151520
I0527 07:47:24.016706 19848 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0527 07:47:24.016721 19848 net.cpp:106] Creating Layer ip3_drop3_0_split
I0527 07:47:24.016729 19848 net.cpp:454] ip3_drop3_0_split <- ip3
I0527 07:47:24.016743 19848 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0527 07:47:24.016758 19848 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0527 07:47:24.016832 19848 net.cpp:150] Setting up ip3_drop3_0_split
I0527 07:47:24.016845 19848 net.cpp:157] Top shape: 40 11 (440)
I0527 07:47:24.016856 19848 net.cpp:157] Top shape: 40 11 (440)
I0527 07:47:24.016867 19848 net.cpp:165] Memory required for data: 63155040
I0527 07:47:24.016877 19848 layer_factory.hpp:77] Creating layer accuracy
I0527 07:47:24.016898 19848 net.cpp:106] Creating Layer accuracy
I0527 07:47:24.016908 19848 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0527 07:47:24.016919 19848 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0527 07:47:24.016933 19848 net.cpp:411] accuracy -> accuracy
I0527 07:47:24.016957 19848 net.cpp:150] Setting up accuracy
I0527 07:47:24.016969 19848 net.cpp:157] Top shape: (1)
I0527 07:47:24.016979 19848 net.cpp:165] Memory required for data: 63155044
I0527 07:47:24.016988 19848 layer_factory.hpp:77] Creating layer loss
I0527 07:47:24.017002 19848 net.cpp:106] Creating Layer loss
I0527 07:47:24.017012 19848 net.cpp:454] loss <- ip3_drop3_0_split_1
I0527 07:47:24.017024 19848 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0527 07:47:24.017036 19848 net.cpp:411] loss -> loss
I0527 07:47:24.017055 19848 layer_factory.hpp:77] Creating layer loss
I0527 07:47:24.017539 19848 net.cpp:150] Setting up loss
I0527 07:47:24.017554 19848 net.cpp:157] Top shape: (1)
I0527 07:47:24.017563 19848 net.cpp:160]     with loss weight 1
I0527 07:47:24.017582 19848 net.cpp:165] Memory required for data: 63155048
I0527 07:47:24.017592 19848 net.cpp:226] loss needs backward computation.
I0527 07:47:24.017603 19848 net.cpp:228] accuracy does not need backward computation.
I0527 07:47:24.017614 19848 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0527 07:47:24.017626 19848 net.cpp:226] drop3 needs backward computation.
I0527 07:47:24.017635 19848 net.cpp:226] ip3 needs backward computation.
I0527 07:47:24.017645 19848 net.cpp:226] drop2 needs backward computation.
I0527 07:47:24.017657 19848 net.cpp:226] relu6 needs backward computation.
I0527 07:47:24.017673 19848 net.cpp:226] ip2 needs backward computation.
I0527 07:47:24.017684 19848 net.cpp:226] drop1 needs backward computation.
I0527 07:47:24.017693 19848 net.cpp:226] relu5 needs backward computation.
I0527 07:47:24.017704 19848 net.cpp:226] ip1 needs backward computation.
I0527 07:47:24.017714 19848 net.cpp:226] pool4 needs backward computation.
I0527 07:47:24.017724 19848 net.cpp:226] relu4 needs backward computation.
I0527 07:47:24.017735 19848 net.cpp:226] conv4 needs backward computation.
I0527 07:47:24.017745 19848 net.cpp:226] pool3 needs backward computation.
I0527 07:47:24.017755 19848 net.cpp:226] relu3 needs backward computation.
I0527 07:47:24.017766 19848 net.cpp:226] conv3 needs backward computation.
I0527 07:47:24.017776 19848 net.cpp:226] pool2 needs backward computation.
I0527 07:47:24.017786 19848 net.cpp:226] relu2 needs backward computation.
I0527 07:47:24.017797 19848 net.cpp:226] conv2 needs backward computation.
I0527 07:47:24.017807 19848 net.cpp:226] pool1 needs backward computation.
I0527 07:47:24.017817 19848 net.cpp:226] relu1 needs backward computation.
I0527 07:47:24.017827 19848 net.cpp:226] conv1 needs backward computation.
I0527 07:47:24.017838 19848 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0527 07:47:24.017851 19848 net.cpp:228] data_hdf5 does not need backward computation.
I0527 07:47:24.017861 19848 net.cpp:270] This network produces output accuracy
I0527 07:47:24.017873 19848 net.cpp:270] This network produces output loss
I0527 07:47:24.017900 19848 net.cpp:283] Network initialization done.
I0527 07:47:24.018033 19848 solver.cpp:60] Solver scaffolding done.
I0527 07:47:24.019178 19848 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_165000.solverstate
I0527 07:47:24.235785 19848 sgd_solver.cpp:318] SGDSolver: restoring history
I0527 07:47:24.241255 19848 caffe.cpp:212] Starting Optimization
I0527 07:47:24.241289 19848 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0527 07:47:24.241300 19848 solver.cpp:289] Learning Rate Policy: fixed
I0527 07:47:24.242672 19848 solver.cpp:341] Iteration 165000, Testing net (#0)
I0527 07:48:13.712030 19848 solver.cpp:409]     Test net output #0: accuracy = 0.892027
I0527 07:48:13.712184 19848 solver.cpp:409]     Test net output #1: loss = 0.356962 (* 1 = 0.356962 loss)
I0527 07:48:13.734772 19848 solver.cpp:237] Iteration 165000, loss = 1.36413
I0527 07:48:13.734808 19848 solver.cpp:253]     Train net output #0: loss = 1.36413 (* 1 = 1.36413 loss)
I0527 07:48:13.734827 19848 sgd_solver.cpp:106] Iteration 165000, lr = 0.001
I0527 07:48:23.597096 19848 solver.cpp:237] Iteration 165375, loss = 1.13288
I0527 07:48:23.597132 19848 solver.cpp:253]     Train net output #0: loss = 1.13288 (* 1 = 1.13288 loss)
I0527 07:48:23.597146 19848 sgd_solver.cpp:106] Iteration 165375, lr = 0.001
I0527 07:48:33.460847 19848 solver.cpp:237] Iteration 165750, loss = 1.44514
I0527 07:48:33.460881 19848 solver.cpp:253]     Train net output #0: loss = 1.44514 (* 1 = 1.44514 loss)
I0527 07:48:33.460898 19848 sgd_solver.cpp:106] Iteration 165750, lr = 0.001
I0527 07:48:43.321976 19848 solver.cpp:237] Iteration 166125, loss = 1.2612
I0527 07:48:43.322019 19848 solver.cpp:253]     Train net output #0: loss = 1.2612 (* 1 = 1.2612 loss)
I0527 07:48:43.322033 19848 sgd_solver.cpp:106] Iteration 166125, lr = 0.001
I0527 07:48:53.185740 19848 solver.cpp:237] Iteration 166500, loss = 0.965735
I0527 07:48:53.185889 19848 solver.cpp:253]     Train net output #0: loss = 0.965735 (* 1 = 0.965735 loss)
I0527 07:48:53.185904 19848 sgd_solver.cpp:106] Iteration 166500, lr = 0.001
I0527 07:49:03.050000 19848 solver.cpp:237] Iteration 166875, loss = 1.09933
I0527 07:49:03.050047 19848 solver.cpp:253]     Train net output #0: loss = 1.09933 (* 1 = 1.09933 loss)
I0527 07:49:03.050063 19848 sgd_solver.cpp:106] Iteration 166875, lr = 0.001
I0527 07:49:12.915808 19848 solver.cpp:237] Iteration 167250, loss = 1.03431
I0527 07:49:12.915844 19848 solver.cpp:253]     Train net output #0: loss = 1.03431 (* 1 = 1.03431 loss)
I0527 07:49:12.915861 19848 sgd_solver.cpp:106] Iteration 167250, lr = 0.001
I0527 07:49:44.905308 19848 solver.cpp:237] Iteration 167625, loss = 1.10403
I0527 07:49:44.905472 19848 solver.cpp:253]     Train net output #0: loss = 1.10403 (* 1 = 1.10403 loss)
I0527 07:49:44.905488 19848 sgd_solver.cpp:106] Iteration 167625, lr = 0.001
I0527 07:49:54.761328 19848 solver.cpp:237] Iteration 168000, loss = 1.04426
I0527 07:49:54.761374 19848 solver.cpp:253]     Train net output #0: loss = 1.04426 (* 1 = 1.04426 loss)
I0527 07:49:54.761391 19848 sgd_solver.cpp:106] Iteration 168000, lr = 0.001
I0527 07:50:04.625949 19848 solver.cpp:237] Iteration 168375, loss = 1.21743
I0527 07:50:04.625985 19848 solver.cpp:253]     Train net output #0: loss = 1.21743 (* 1 = 1.21743 loss)
I0527 07:50:04.625999 19848 sgd_solver.cpp:106] Iteration 168375, lr = 0.001
I0527 07:50:14.452767 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_168750.caffemodel
I0527 07:50:14.510610 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_168750.solverstate
I0527 07:50:14.544595 19848 solver.cpp:237] Iteration 168750, loss = 1.06794
I0527 07:50:14.544641 19848 solver.cpp:253]     Train net output #0: loss = 1.06794 (* 1 = 1.06794 loss)
I0527 07:50:14.544656 19848 sgd_solver.cpp:106] Iteration 168750, lr = 0.001
I0527 07:50:24.398890 19848 solver.cpp:237] Iteration 169125, loss = 1.14625
I0527 07:50:24.399042 19848 solver.cpp:253]     Train net output #0: loss = 1.14625 (* 1 = 1.14625 loss)
I0527 07:50:24.399056 19848 sgd_solver.cpp:106] Iteration 169125, lr = 0.001
I0527 07:50:34.262644 19848 solver.cpp:237] Iteration 169500, loss = 1.40948
I0527 07:50:34.262678 19848 solver.cpp:253]     Train net output #0: loss = 1.40948 (* 1 = 1.40948 loss)
I0527 07:50:34.262696 19848 sgd_solver.cpp:106] Iteration 169500, lr = 0.001
I0527 07:50:44.123890 19848 solver.cpp:237] Iteration 169875, loss = 1.00268
I0527 07:50:44.123936 19848 solver.cpp:253]     Train net output #0: loss = 1.00268 (* 1 = 1.00268 loss)
I0527 07:50:44.123950 19848 sgd_solver.cpp:106] Iteration 169875, lr = 0.001
I0527 07:51:16.128839 19848 solver.cpp:237] Iteration 170250, loss = 1.22745
I0527 07:51:16.128999 19848 solver.cpp:253]     Train net output #0: loss = 1.22745 (* 1 = 1.22745 loss)
I0527 07:51:16.129015 19848 sgd_solver.cpp:106] Iteration 170250, lr = 0.001
I0527 07:51:25.991758 19848 solver.cpp:237] Iteration 170625, loss = 1.09537
I0527 07:51:25.991792 19848 solver.cpp:253]     Train net output #0: loss = 1.09537 (* 1 = 1.09537 loss)
I0527 07:51:25.991807 19848 sgd_solver.cpp:106] Iteration 170625, lr = 0.001
I0527 07:51:35.856187 19848 solver.cpp:237] Iteration 171000, loss = 1.3034
I0527 07:51:35.856230 19848 solver.cpp:253]     Train net output #0: loss = 1.3034 (* 1 = 1.3034 loss)
I0527 07:51:35.856247 19848 sgd_solver.cpp:106] Iteration 171000, lr = 0.001
I0527 07:51:45.710425 19848 solver.cpp:237] Iteration 171375, loss = 1.23078
I0527 07:51:45.710461 19848 solver.cpp:253]     Train net output #0: loss = 1.23078 (* 1 = 1.23078 loss)
I0527 07:51:45.710474 19848 sgd_solver.cpp:106] Iteration 171375, lr = 0.001
I0527 07:51:55.570724 19848 solver.cpp:237] Iteration 171750, loss = 0.832054
I0527 07:51:55.570864 19848 solver.cpp:253]     Train net output #0: loss = 0.832054 (* 1 = 0.832054 loss)
I0527 07:51:55.570878 19848 sgd_solver.cpp:106] Iteration 171750, lr = 0.001
I0527 07:52:05.433161 19848 solver.cpp:237] Iteration 172125, loss = 1.04215
I0527 07:52:05.433204 19848 solver.cpp:253]     Train net output #0: loss = 1.04215 (* 1 = 1.04215 loss)
I0527 07:52:05.433219 19848 sgd_solver.cpp:106] Iteration 172125, lr = 0.001
I0527 07:52:15.268934 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_172500.caffemodel
I0527 07:52:15.325970 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_172500.solverstate
I0527 07:52:15.356736 19848 solver.cpp:341] Iteration 172500, Testing net (#0)
I0527 07:53:03.899404 19848 solver.cpp:409]     Test net output #0: accuracy = 0.88946
I0527 07:53:03.899564 19848 solver.cpp:409]     Test net output #1: loss = 0.34497 (* 1 = 0.34497 loss)
I0527 07:53:25.984098 19848 solver.cpp:237] Iteration 172500, loss = 1.05367
I0527 07:53:25.984151 19848 solver.cpp:253]     Train net output #0: loss = 1.05367 (* 1 = 1.05367 loss)
I0527 07:53:25.984168 19848 sgd_solver.cpp:106] Iteration 172500, lr = 0.001
I0527 07:53:35.881209 19848 solver.cpp:237] Iteration 172875, loss = 1.12925
I0527 07:53:35.881358 19848 solver.cpp:253]     Train net output #0: loss = 1.12925 (* 1 = 1.12925 loss)
I0527 07:53:35.881372 19848 sgd_solver.cpp:106] Iteration 172875, lr = 0.001
I0527 07:53:45.781677 19848 solver.cpp:237] Iteration 173250, loss = 1.38687
I0527 07:53:45.781714 19848 solver.cpp:253]     Train net output #0: loss = 1.38687 (* 1 = 1.38687 loss)
I0527 07:53:45.781733 19848 sgd_solver.cpp:106] Iteration 173250, lr = 0.001
I0527 07:53:55.676365 19848 solver.cpp:237] Iteration 173625, loss = 1.35615
I0527 07:53:55.676401 19848 solver.cpp:253]     Train net output #0: loss = 1.35615 (* 1 = 1.35615 loss)
I0527 07:53:55.676414 19848 sgd_solver.cpp:106] Iteration 173625, lr = 0.001
I0527 07:54:05.575047 19848 solver.cpp:237] Iteration 174000, loss = 1.16156
I0527 07:54:05.575091 19848 solver.cpp:253]     Train net output #0: loss = 1.16156 (* 1 = 1.16156 loss)
I0527 07:54:05.575109 19848 sgd_solver.cpp:106] Iteration 174000, lr = 0.001
I0527 07:54:15.463605 19848 solver.cpp:237] Iteration 174375, loss = 1.36085
I0527 07:54:15.463744 19848 solver.cpp:253]     Train net output #0: loss = 1.36085 (* 1 = 1.36085 loss)
I0527 07:54:15.463759 19848 sgd_solver.cpp:106] Iteration 174375, lr = 0.001
I0527 07:54:25.357790 19848 solver.cpp:237] Iteration 174750, loss = 1.14643
I0527 07:54:25.357825 19848 solver.cpp:253]     Train net output #0: loss = 1.14643 (* 1 = 1.14643 loss)
I0527 07:54:25.357842 19848 sgd_solver.cpp:106] Iteration 174750, lr = 0.001
I0527 07:54:57.401607 19848 solver.cpp:237] Iteration 175125, loss = 1.14838
I0527 07:54:57.401780 19848 solver.cpp:253]     Train net output #0: loss = 1.14838 (* 1 = 1.14838 loss)
I0527 07:54:57.401796 19848 sgd_solver.cpp:106] Iteration 175125, lr = 0.001
I0527 07:55:07.295331 19848 solver.cpp:237] Iteration 175500, loss = 1.05822
I0527 07:55:07.295367 19848 solver.cpp:253]     Train net output #0: loss = 1.05822 (* 1 = 1.05822 loss)
I0527 07:55:07.295380 19848 sgd_solver.cpp:106] Iteration 175500, lr = 0.001
I0527 07:55:17.194270 19848 solver.cpp:237] Iteration 175875, loss = 1.21846
I0527 07:55:17.194319 19848 solver.cpp:253]     Train net output #0: loss = 1.21846 (* 1 = 1.21846 loss)
I0527 07:55:17.194332 19848 sgd_solver.cpp:106] Iteration 175875, lr = 0.001
I0527 07:55:27.068025 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_176250.caffemodel
I0527 07:55:27.127164 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_176250.solverstate
I0527 07:55:27.162901 19848 solver.cpp:237] Iteration 176250, loss = 1.14991
I0527 07:55:27.162946 19848 solver.cpp:253]     Train net output #0: loss = 1.14991 (* 1 = 1.14991 loss)
I0527 07:55:27.162968 19848 sgd_solver.cpp:106] Iteration 176250, lr = 0.001
I0527 07:55:37.056968 19848 solver.cpp:237] Iteration 176625, loss = 1.11808
I0527 07:55:37.057113 19848 solver.cpp:253]     Train net output #0: loss = 1.11808 (* 1 = 1.11808 loss)
I0527 07:55:37.057127 19848 sgd_solver.cpp:106] Iteration 176625, lr = 0.001
I0527 07:55:46.951019 19848 solver.cpp:237] Iteration 177000, loss = 1.12444
I0527 07:55:46.951059 19848 solver.cpp:253]     Train net output #0: loss = 1.12444 (* 1 = 1.12444 loss)
I0527 07:55:46.951081 19848 sgd_solver.cpp:106] Iteration 177000, lr = 0.001
I0527 07:55:56.849290 19848 solver.cpp:237] Iteration 177375, loss = 1.19475
I0527 07:55:56.849325 19848 solver.cpp:253]     Train net output #0: loss = 1.19475 (* 1 = 1.19475 loss)
I0527 07:55:56.849342 19848 sgd_solver.cpp:106] Iteration 177375, lr = 0.001
I0527 07:56:28.858170 19848 solver.cpp:237] Iteration 177750, loss = 1.3698
I0527 07:56:28.858330 19848 solver.cpp:253]     Train net output #0: loss = 1.3698 (* 1 = 1.3698 loss)
I0527 07:56:28.858347 19848 sgd_solver.cpp:106] Iteration 177750, lr = 0.001
I0527 07:56:38.754817 19848 solver.cpp:237] Iteration 178125, loss = 1.22413
I0527 07:56:38.754859 19848 solver.cpp:253]     Train net output #0: loss = 1.22413 (* 1 = 1.22413 loss)
I0527 07:56:38.754876 19848 sgd_solver.cpp:106] Iteration 178125, lr = 0.001
I0527 07:56:48.647189 19848 solver.cpp:237] Iteration 178500, loss = 1.00106
I0527 07:56:48.647223 19848 solver.cpp:253]     Train net output #0: loss = 1.00106 (* 1 = 1.00106 loss)
I0527 07:56:48.647240 19848 sgd_solver.cpp:106] Iteration 178500, lr = 0.001
I0527 07:56:58.544008 19848 solver.cpp:237] Iteration 178875, loss = 1.33219
I0527 07:56:58.544044 19848 solver.cpp:253]     Train net output #0: loss = 1.33219 (* 1 = 1.33219 loss)
I0527 07:56:58.544064 19848 sgd_solver.cpp:106] Iteration 178875, lr = 0.001
I0527 07:57:08.441992 19848 solver.cpp:237] Iteration 179250, loss = 1.46709
I0527 07:57:08.442129 19848 solver.cpp:253]     Train net output #0: loss = 1.46709 (* 1 = 1.46709 loss)
I0527 07:57:08.442143 19848 sgd_solver.cpp:106] Iteration 179250, lr = 0.001
I0527 07:57:18.340819 19848 solver.cpp:237] Iteration 179625, loss = 1.24838
I0527 07:57:18.340853 19848 solver.cpp:253]     Train net output #0: loss = 1.24838 (* 1 = 1.24838 loss)
I0527 07:57:18.340872 19848 sgd_solver.cpp:106] Iteration 179625, lr = 0.001
I0527 07:57:28.218439 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_180000.caffemodel
I0527 07:57:28.277457 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_180000.solverstate
I0527 07:57:28.304855 19848 solver.cpp:341] Iteration 180000, Testing net (#0)
I0527 07:58:37.671656 19848 solver.cpp:409]     Test net output #0: accuracy = 0.894421
I0527 07:58:37.671818 19848 solver.cpp:409]     Test net output #1: loss = 0.349761 (* 1 = 0.349761 loss)
I0527 07:58:59.806746 19848 solver.cpp:237] Iteration 180000, loss = 1.11699
I0527 07:58:59.806799 19848 solver.cpp:253]     Train net output #0: loss = 1.11699 (* 1 = 1.11699 loss)
I0527 07:58:59.806816 19848 sgd_solver.cpp:106] Iteration 180000, lr = 0.001
I0527 07:59:09.623798 19848 solver.cpp:237] Iteration 180375, loss = 1.16962
I0527 07:59:09.623958 19848 solver.cpp:253]     Train net output #0: loss = 1.16962 (* 1 = 1.16962 loss)
I0527 07:59:09.623972 19848 sgd_solver.cpp:106] Iteration 180375, lr = 0.001
I0527 07:59:19.432850 19848 solver.cpp:237] Iteration 180750, loss = 1.10016
I0527 07:59:19.432885 19848 solver.cpp:253]     Train net output #0: loss = 1.10016 (* 1 = 1.10016 loss)
I0527 07:59:19.432903 19848 sgd_solver.cpp:106] Iteration 180750, lr = 0.001
I0527 07:59:29.252583 19848 solver.cpp:237] Iteration 181125, loss = 0.949459
I0527 07:59:29.252634 19848 solver.cpp:253]     Train net output #0: loss = 0.949459 (* 1 = 0.949459 loss)
I0527 07:59:29.252647 19848 sgd_solver.cpp:106] Iteration 181125, lr = 0.001
I0527 07:59:39.069584 19848 solver.cpp:237] Iteration 181500, loss = 1.30193
I0527 07:59:39.069619 19848 solver.cpp:253]     Train net output #0: loss = 1.30193 (* 1 = 1.30193 loss)
I0527 07:59:39.069636 19848 sgd_solver.cpp:106] Iteration 181500, lr = 0.001
I0527 07:59:48.885411 19848 solver.cpp:237] Iteration 181875, loss = 1.0369
I0527 07:59:48.885555 19848 solver.cpp:253]     Train net output #0: loss = 1.0369 (* 1 = 1.0369 loss)
I0527 07:59:48.885567 19848 sgd_solver.cpp:106] Iteration 181875, lr = 0.001
I0527 07:59:58.704417 19848 solver.cpp:237] Iteration 182250, loss = 1.44679
I0527 07:59:58.704458 19848 solver.cpp:253]     Train net output #0: loss = 1.44679 (* 1 = 1.44679 loss)
I0527 07:59:58.704479 19848 sgd_solver.cpp:106] Iteration 182250, lr = 0.001
I0527 08:00:30.637197 19848 solver.cpp:237] Iteration 182625, loss = 1.49375
I0527 08:00:30.637358 19848 solver.cpp:253]     Train net output #0: loss = 1.49375 (* 1 = 1.49375 loss)
I0527 08:00:30.637373 19848 sgd_solver.cpp:106] Iteration 182625, lr = 0.001
I0527 08:00:40.456584 19848 solver.cpp:237] Iteration 183000, loss = 1.05899
I0527 08:00:40.456619 19848 solver.cpp:253]     Train net output #0: loss = 1.05899 (* 1 = 1.05899 loss)
I0527 08:00:40.456636 19848 sgd_solver.cpp:106] Iteration 183000, lr = 0.001
I0527 08:00:50.276655 19848 solver.cpp:237] Iteration 183375, loss = 1.08486
I0527 08:00:50.276703 19848 solver.cpp:253]     Train net output #0: loss = 1.08486 (* 1 = 1.08486 loss)
I0527 08:00:50.276717 19848 sgd_solver.cpp:106] Iteration 183375, lr = 0.001
I0527 08:01:00.070232 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_183750.caffemodel
I0527 08:01:00.128525 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_183750.solverstate
I0527 08:01:00.164842 19848 solver.cpp:237] Iteration 183750, loss = 1.07922
I0527 08:01:00.164893 19848 solver.cpp:253]     Train net output #0: loss = 1.07922 (* 1 = 1.07922 loss)
I0527 08:01:00.164909 19848 sgd_solver.cpp:106] Iteration 183750, lr = 0.001
I0527 08:01:09.978399 19848 solver.cpp:237] Iteration 184125, loss = 0.966068
I0527 08:01:09.978554 19848 solver.cpp:253]     Train net output #0: loss = 0.966068 (* 1 = 0.966068 loss)
I0527 08:01:09.978567 19848 sgd_solver.cpp:106] Iteration 184125, lr = 0.001
I0527 08:01:19.794108 19848 solver.cpp:237] Iteration 184500, loss = 1.5489
I0527 08:01:19.794143 19848 solver.cpp:253]     Train net output #0: loss = 1.5489 (* 1 = 1.5489 loss)
I0527 08:01:19.794162 19848 sgd_solver.cpp:106] Iteration 184500, lr = 0.001
I0527 08:01:29.613123 19848 solver.cpp:237] Iteration 184875, loss = 1.2229
I0527 08:01:29.613159 19848 solver.cpp:253]     Train net output #0: loss = 1.2229 (* 1 = 1.2229 loss)
I0527 08:01:29.613175 19848 sgd_solver.cpp:106] Iteration 184875, lr = 0.001
I0527 08:02:01.598428 19848 solver.cpp:237] Iteration 185250, loss = 1.3119
I0527 08:02:01.598595 19848 solver.cpp:253]     Train net output #0: loss = 1.3119 (* 1 = 1.3119 loss)
I0527 08:02:01.598610 19848 sgd_solver.cpp:106] Iteration 185250, lr = 0.001
I0527 08:02:11.437077 19848 solver.cpp:237] Iteration 185625, loss = 0.956269
I0527 08:02:11.437111 19848 solver.cpp:253]     Train net output #0: loss = 0.956269 (* 1 = 0.956269 loss)
I0527 08:02:11.437125 19848 sgd_solver.cpp:106] Iteration 185625, lr = 0.001
I0527 08:02:21.269963 19848 solver.cpp:237] Iteration 186000, loss = 1.26328
I0527 08:02:21.269999 19848 solver.cpp:253]     Train net output #0: loss = 1.26328 (* 1 = 1.26328 loss)
I0527 08:02:21.270012 19848 sgd_solver.cpp:106] Iteration 186000, lr = 0.001
I0527 08:02:31.105603 19848 solver.cpp:237] Iteration 186375, loss = 1.18833
I0527 08:02:31.105643 19848 solver.cpp:253]     Train net output #0: loss = 1.18833 (* 1 = 1.18833 loss)
I0527 08:02:31.105666 19848 sgd_solver.cpp:106] Iteration 186375, lr = 0.001
I0527 08:02:40.935881 19848 solver.cpp:237] Iteration 186750, loss = 1.47665
I0527 08:02:40.936039 19848 solver.cpp:253]     Train net output #0: loss = 1.47665 (* 1 = 1.47665 loss)
I0527 08:02:40.936053 19848 sgd_solver.cpp:106] Iteration 186750, lr = 0.001
I0527 08:02:50.769229 19848 solver.cpp:237] Iteration 187125, loss = 1.18153
I0527 08:02:50.769274 19848 solver.cpp:253]     Train net output #0: loss = 1.18153 (* 1 = 1.18153 loss)
I0527 08:02:50.769291 19848 sgd_solver.cpp:106] Iteration 187125, lr = 0.001
I0527 08:03:00.569777 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_187500.caffemodel
I0527 08:03:00.625893 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_187500.solverstate
I0527 08:03:00.651253 19848 solver.cpp:341] Iteration 187500, Testing net (#0)
I0527 08:03:48.879318 19848 solver.cpp:409]     Test net output #0: accuracy = 0.893213
I0527 08:03:48.879477 19848 solver.cpp:409]     Test net output #1: loss = 0.335207 (* 1 = 0.335207 loss)
I0527 08:04:11.048146 19848 solver.cpp:237] Iteration 187500, loss = 0.962868
I0527 08:04:11.048202 19848 solver.cpp:253]     Train net output #0: loss = 0.962868 (* 1 = 0.962868 loss)
I0527 08:04:11.048218 19848 sgd_solver.cpp:106] Iteration 187500, lr = 0.001
I0527 08:04:20.813207 19848 solver.cpp:237] Iteration 187875, loss = 1.06226
I0527 08:04:20.813361 19848 solver.cpp:253]     Train net output #0: loss = 1.06226 (* 1 = 1.06226 loss)
I0527 08:04:20.813375 19848 sgd_solver.cpp:106] Iteration 187875, lr = 0.001
I0527 08:04:30.586256 19848 solver.cpp:237] Iteration 188250, loss = 1.30117
I0527 08:04:30.586293 19848 solver.cpp:253]     Train net output #0: loss = 1.30117 (* 1 = 1.30117 loss)
I0527 08:04:30.586314 19848 sgd_solver.cpp:106] Iteration 188250, lr = 0.001
I0527 08:04:40.354110 19848 solver.cpp:237] Iteration 188625, loss = 1.3817
I0527 08:04:40.354145 19848 solver.cpp:253]     Train net output #0: loss = 1.3817 (* 1 = 1.3817 loss)
I0527 08:04:40.354162 19848 sgd_solver.cpp:106] Iteration 188625, lr = 0.001
I0527 08:04:50.124511 19848 solver.cpp:237] Iteration 189000, loss = 1.13566
I0527 08:04:50.124547 19848 solver.cpp:253]     Train net output #0: loss = 1.13566 (* 1 = 1.13566 loss)
I0527 08:04:50.124562 19848 sgd_solver.cpp:106] Iteration 189000, lr = 0.001
I0527 08:04:59.897821 19848 solver.cpp:237] Iteration 189375, loss = 1.13538
I0527 08:04:59.897976 19848 solver.cpp:253]     Train net output #0: loss = 1.13538 (* 1 = 1.13538 loss)
I0527 08:04:59.897990 19848 sgd_solver.cpp:106] Iteration 189375, lr = 0.001
I0527 08:05:09.672168 19848 solver.cpp:237] Iteration 189750, loss = 0.915453
I0527 08:05:09.672202 19848 solver.cpp:253]     Train net output #0: loss = 0.915453 (* 1 = 0.915453 loss)
I0527 08:05:09.672219 19848 sgd_solver.cpp:106] Iteration 189750, lr = 0.001
I0527 08:05:41.614807 19848 solver.cpp:237] Iteration 190125, loss = 1.0134
I0527 08:05:41.614976 19848 solver.cpp:253]     Train net output #0: loss = 1.0134 (* 1 = 1.0134 loss)
I0527 08:05:41.614991 19848 sgd_solver.cpp:106] Iteration 190125, lr = 0.001
I0527 08:05:51.388893 19848 solver.cpp:237] Iteration 190500, loss = 0.976087
I0527 08:05:51.388936 19848 solver.cpp:253]     Train net output #0: loss = 0.976087 (* 1 = 0.976087 loss)
I0527 08:05:51.388950 19848 sgd_solver.cpp:106] Iteration 190500, lr = 0.001
I0527 08:06:01.164705 19848 solver.cpp:237] Iteration 190875, loss = 1.15285
I0527 08:06:01.164741 19848 solver.cpp:253]     Train net output #0: loss = 1.15285 (* 1 = 1.15285 loss)
I0527 08:06:01.164754 19848 sgd_solver.cpp:106] Iteration 190875, lr = 0.001
I0527 08:06:10.909493 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_191250.caffemodel
I0527 08:06:10.965523 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_191250.solverstate
I0527 08:06:11.000042 19848 solver.cpp:237] Iteration 191250, loss = 0.88337
I0527 08:06:11.000089 19848 solver.cpp:253]     Train net output #0: loss = 0.88337 (* 1 = 0.88337 loss)
I0527 08:06:11.000103 19848 sgd_solver.cpp:106] Iteration 191250, lr = 0.001
I0527 08:06:20.770190 19848 solver.cpp:237] Iteration 191625, loss = 1.17768
I0527 08:06:20.770339 19848 solver.cpp:253]     Train net output #0: loss = 1.17768 (* 1 = 1.17768 loss)
I0527 08:06:20.770354 19848 sgd_solver.cpp:106] Iteration 191625, lr = 0.001
I0527 08:06:30.537375 19848 solver.cpp:237] Iteration 192000, loss = 1.13011
I0527 08:06:30.537410 19848 solver.cpp:253]     Train net output #0: loss = 1.13011 (* 1 = 1.13011 loss)
I0527 08:06:30.537425 19848 sgd_solver.cpp:106] Iteration 192000, lr = 0.001
I0527 08:06:40.308086 19848 solver.cpp:237] Iteration 192375, loss = 0.985682
I0527 08:06:40.308131 19848 solver.cpp:253]     Train net output #0: loss = 0.985682 (* 1 = 0.985682 loss)
I0527 08:06:40.308148 19848 sgd_solver.cpp:106] Iteration 192375, lr = 0.001
I0527 08:07:12.227679 19848 solver.cpp:237] Iteration 192750, loss = 1.41587
I0527 08:07:12.227849 19848 solver.cpp:253]     Train net output #0: loss = 1.41587 (* 1 = 1.41587 loss)
I0527 08:07:12.227864 19848 sgd_solver.cpp:106] Iteration 192750, lr = 0.001
I0527 08:07:21.998621 19848 solver.cpp:237] Iteration 193125, loss = 1.2995
I0527 08:07:21.998654 19848 solver.cpp:253]     Train net output #0: loss = 1.2995 (* 1 = 1.2995 loss)
I0527 08:07:21.998672 19848 sgd_solver.cpp:106] Iteration 193125, lr = 0.001
I0527 08:07:31.769047 19848 solver.cpp:237] Iteration 193500, loss = 1.01354
I0527 08:07:31.769088 19848 solver.cpp:253]     Train net output #0: loss = 1.01354 (* 1 = 1.01354 loss)
I0527 08:07:31.769104 19848 sgd_solver.cpp:106] Iteration 193500, lr = 0.001
I0527 08:07:41.539309 19848 solver.cpp:237] Iteration 193875, loss = 1.34632
I0527 08:07:41.539342 19848 solver.cpp:253]     Train net output #0: loss = 1.34632 (* 1 = 1.34632 loss)
I0527 08:07:41.539361 19848 sgd_solver.cpp:106] Iteration 193875, lr = 0.001
I0527 08:07:51.311893 19848 solver.cpp:237] Iteration 194250, loss = 1.39558
I0527 08:07:51.312049 19848 solver.cpp:253]     Train net output #0: loss = 1.39558 (* 1 = 1.39558 loss)
I0527 08:07:51.312063 19848 sgd_solver.cpp:106] Iteration 194250, lr = 0.001
I0527 08:08:01.082615 19848 solver.cpp:237] Iteration 194625, loss = 1.10635
I0527 08:08:01.082650 19848 solver.cpp:253]     Train net output #0: loss = 1.10635 (* 1 = 1.10635 loss)
I0527 08:08:01.082664 19848 sgd_solver.cpp:106] Iteration 194625, lr = 0.001
I0527 08:08:10.823830 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_195000.caffemodel
I0527 08:08:10.879842 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_195000.solverstate
I0527 08:08:10.905510 19848 solver.cpp:341] Iteration 195000, Testing net (#0)
I0527 08:09:20.184322 19848 solver.cpp:409]     Test net output #0: accuracy = 0.893052
I0527 08:09:20.184506 19848 solver.cpp:409]     Test net output #1: loss = 0.333957 (* 1 = 0.333957 loss)
I0527 08:09:42.337188 19848 solver.cpp:237] Iteration 195000, loss = 1.09784
I0527 08:09:42.337241 19848 solver.cpp:253]     Train net output #0: loss = 1.09784 (* 1 = 1.09784 loss)
I0527 08:09:42.337258 19848 sgd_solver.cpp:106] Iteration 195000, lr = 0.001
I0527 08:09:52.071214 19848 solver.cpp:237] Iteration 195375, loss = 0.896591
I0527 08:09:52.071380 19848 solver.cpp:253]     Train net output #0: loss = 0.896591 (* 1 = 0.896591 loss)
I0527 08:09:52.071394 19848 sgd_solver.cpp:106] Iteration 195375, lr = 0.001
I0527 08:10:01.813530 19848 solver.cpp:237] Iteration 195750, loss = 1.21496
I0527 08:10:01.813565 19848 solver.cpp:253]     Train net output #0: loss = 1.21496 (* 1 = 1.21496 loss)
I0527 08:10:01.813580 19848 sgd_solver.cpp:106] Iteration 195750, lr = 0.001
I0527 08:10:11.602980 19848 solver.cpp:237] Iteration 196125, loss = 1.21229
I0527 08:10:11.603016 19848 solver.cpp:253]     Train net output #0: loss = 1.21229 (* 1 = 1.21229 loss)
I0527 08:10:11.603032 19848 sgd_solver.cpp:106] Iteration 196125, lr = 0.001
I0527 08:10:21.387140 19848 solver.cpp:237] Iteration 196500, loss = 1.06435
I0527 08:10:21.387188 19848 solver.cpp:253]     Train net output #0: loss = 1.06435 (* 1 = 1.06435 loss)
I0527 08:10:21.387203 19848 sgd_solver.cpp:106] Iteration 196500, lr = 0.001
I0527 08:10:31.176859 19848 solver.cpp:237] Iteration 196875, loss = 1.23915
I0527 08:10:31.177003 19848 solver.cpp:253]     Train net output #0: loss = 1.23915 (* 1 = 1.23915 loss)
I0527 08:10:31.177017 19848 sgd_solver.cpp:106] Iteration 196875, lr = 0.001
I0527 08:10:40.967022 19848 solver.cpp:237] Iteration 197250, loss = 0.987817
I0527 08:10:40.967057 19848 solver.cpp:253]     Train net output #0: loss = 0.987817 (* 1 = 0.987817 loss)
I0527 08:10:40.967074 19848 sgd_solver.cpp:106] Iteration 197250, lr = 0.001
I0527 08:11:12.947530 19848 solver.cpp:237] Iteration 197625, loss = 1.1604
I0527 08:11:12.947700 19848 solver.cpp:253]     Train net output #0: loss = 1.1604 (* 1 = 1.1604 loss)
I0527 08:11:12.947715 19848 sgd_solver.cpp:106] Iteration 197625, lr = 0.001
I0527 08:11:22.735183 19848 solver.cpp:237] Iteration 198000, loss = 0.965488
I0527 08:11:22.735218 19848 solver.cpp:253]     Train net output #0: loss = 0.965488 (* 1 = 0.965488 loss)
I0527 08:11:22.735235 19848 sgd_solver.cpp:106] Iteration 198000, lr = 0.001
I0527 08:11:32.520855 19848 solver.cpp:237] Iteration 198375, loss = 0.985415
I0527 08:11:32.520895 19848 solver.cpp:253]     Train net output #0: loss = 0.985415 (* 1 = 0.985415 loss)
I0527 08:11:32.520912 19848 sgd_solver.cpp:106] Iteration 198375, lr = 0.001
I0527 08:11:42.216850 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_198750.caffemodel
I0527 08:11:42.275674 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_198750.solverstate
I0527 08:11:42.311704 19848 solver.cpp:237] Iteration 198750, loss = 1.22971
I0527 08:11:42.311753 19848 solver.cpp:253]     Train net output #0: loss = 1.22971 (* 1 = 1.22971 loss)
I0527 08:11:42.311770 19848 sgd_solver.cpp:106] Iteration 198750, lr = 0.001
I0527 08:11:52.038565 19848 solver.cpp:237] Iteration 199125, loss = 1.03127
I0527 08:11:52.038729 19848 solver.cpp:253]     Train net output #0: loss = 1.03127 (* 1 = 1.03127 loss)
I0527 08:11:52.038743 19848 sgd_solver.cpp:106] Iteration 199125, lr = 0.001
I0527 08:12:01.765095 19848 solver.cpp:237] Iteration 199500, loss = 1.54769
I0527 08:12:01.765138 19848 solver.cpp:253]     Train net output #0: loss = 1.54769 (* 1 = 1.54769 loss)
I0527 08:12:01.765154 19848 sgd_solver.cpp:106] Iteration 199500, lr = 0.001
I0527 08:12:11.497016 19848 solver.cpp:237] Iteration 199875, loss = 1.29412
I0527 08:12:11.497051 19848 solver.cpp:253]     Train net output #0: loss = 1.29412 (* 1 = 1.29412 loss)
I0527 08:12:11.497066 19848 sgd_solver.cpp:106] Iteration 199875, lr = 0.001
I0527 08:12:43.384842 19848 solver.cpp:237] Iteration 200250, loss = 1.21429
I0527 08:12:43.385009 19848 solver.cpp:253]     Train net output #0: loss = 1.21429 (* 1 = 1.21429 loss)
I0527 08:12:43.385022 19848 sgd_solver.cpp:106] Iteration 200250, lr = 0.001
I0527 08:12:53.111698 19848 solver.cpp:237] Iteration 200625, loss = 1.27229
I0527 08:12:53.111740 19848 solver.cpp:253]     Train net output #0: loss = 1.27229 (* 1 = 1.27229 loss)
I0527 08:12:53.111757 19848 sgd_solver.cpp:106] Iteration 200625, lr = 0.001
I0527 08:13:02.841109 19848 solver.cpp:237] Iteration 201000, loss = 1.1692
I0527 08:13:02.841145 19848 solver.cpp:253]     Train net output #0: loss = 1.1692 (* 1 = 1.1692 loss)
I0527 08:13:02.841161 19848 sgd_solver.cpp:106] Iteration 201000, lr = 0.001
I0527 08:13:12.565239 19848 solver.cpp:237] Iteration 201375, loss = 1.29147
I0527 08:13:12.565284 19848 solver.cpp:253]     Train net output #0: loss = 1.29147 (* 1 = 1.29147 loss)
I0527 08:13:12.565299 19848 sgd_solver.cpp:106] Iteration 201375, lr = 0.001
I0527 08:13:22.293628 19848 solver.cpp:237] Iteration 201750, loss = 0.91023
I0527 08:13:22.293776 19848 solver.cpp:253]     Train net output #0: loss = 0.91023 (* 1 = 0.91023 loss)
I0527 08:13:22.293789 19848 sgd_solver.cpp:106] Iteration 201750, lr = 0.001
I0527 08:13:32.018492 19848 solver.cpp:237] Iteration 202125, loss = 1.47352
I0527 08:13:32.018527 19848 solver.cpp:253]     Train net output #0: loss = 1.47352 (* 1 = 1.47352 loss)
I0527 08:13:32.018542 19848 sgd_solver.cpp:106] Iteration 202125, lr = 0.001
I0527 08:13:41.718611 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_202500.caffemodel
I0527 08:13:41.777279 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_202500.solverstate
I0527 08:13:41.805229 19848 solver.cpp:341] Iteration 202500, Testing net (#0)
I0527 08:14:30.362246 19848 solver.cpp:409]     Test net output #0: accuracy = 0.8959
I0527 08:14:30.362411 19848 solver.cpp:409]     Test net output #1: loss = 0.331477 (* 1 = 0.331477 loss)
I0527 08:14:51.283411 19848 solver.cpp:237] Iteration 202500, loss = 1.12308
I0527 08:14:51.283463 19848 solver.cpp:253]     Train net output #0: loss = 1.12308 (* 1 = 1.12308 loss)
I0527 08:14:51.283478 19848 sgd_solver.cpp:106] Iteration 202500, lr = 0.001
I0527 08:15:01.118383 19848 solver.cpp:237] Iteration 202875, loss = 0.906037
I0527 08:15:01.118537 19848 solver.cpp:253]     Train net output #0: loss = 0.906037 (* 1 = 0.906037 loss)
I0527 08:15:01.118551 19848 sgd_solver.cpp:106] Iteration 202875, lr = 0.001
I0527 08:15:10.951678 19848 solver.cpp:237] Iteration 203250, loss = 1.07541
I0527 08:15:10.951714 19848 solver.cpp:253]     Train net output #0: loss = 1.07541 (* 1 = 1.07541 loss)
I0527 08:15:10.951731 19848 sgd_solver.cpp:106] Iteration 203250, lr = 0.001
I0527 08:15:20.791023 19848 solver.cpp:237] Iteration 203625, loss = 1.10916
I0527 08:15:20.791064 19848 solver.cpp:253]     Train net output #0: loss = 1.10916 (* 1 = 1.10916 loss)
I0527 08:15:20.791085 19848 sgd_solver.cpp:106] Iteration 203625, lr = 0.001
I0527 08:15:30.633026 19848 solver.cpp:237] Iteration 204000, loss = 1.07271
I0527 08:15:30.633062 19848 solver.cpp:253]     Train net output #0: loss = 1.07271 (* 1 = 1.07271 loss)
I0527 08:15:30.633075 19848 sgd_solver.cpp:106] Iteration 204000, lr = 0.001
I0527 08:15:40.465836 19848 solver.cpp:237] Iteration 204375, loss = 1.08523
I0527 08:15:40.465994 19848 solver.cpp:253]     Train net output #0: loss = 1.08523 (* 1 = 1.08523 loss)
I0527 08:15:40.466007 19848 sgd_solver.cpp:106] Iteration 204375, lr = 0.001
I0527 08:15:50.306802 19848 solver.cpp:237] Iteration 204750, loss = 1.13718
I0527 08:15:50.306838 19848 solver.cpp:253]     Train net output #0: loss = 1.13718 (* 1 = 1.13718 loss)
I0527 08:15:50.306859 19848 sgd_solver.cpp:106] Iteration 204750, lr = 0.001
I0527 08:16:21.045007 19848 solver.cpp:237] Iteration 205125, loss = 1.16088
I0527 08:16:21.045177 19848 solver.cpp:253]     Train net output #0: loss = 1.16088 (* 1 = 1.16088 loss)
I0527 08:16:21.045192 19848 sgd_solver.cpp:106] Iteration 205125, lr = 0.001
I0527 08:16:30.888619 19848 solver.cpp:237] Iteration 205500, loss = 0.871978
I0527 08:16:30.888654 19848 solver.cpp:253]     Train net output #0: loss = 0.871978 (* 1 = 0.871978 loss)
I0527 08:16:30.888669 19848 sgd_solver.cpp:106] Iteration 205500, lr = 0.001
I0527 08:16:40.731180 19848 solver.cpp:237] Iteration 205875, loss = 1.90296
I0527 08:16:40.731230 19848 solver.cpp:253]     Train net output #0: loss = 1.90296 (* 1 = 1.90296 loss)
I0527 08:16:40.731245 19848 sgd_solver.cpp:106] Iteration 205875, lr = 0.001
I0527 08:16:50.537744 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_206250.caffemodel
I0527 08:16:50.594357 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_206250.solverstate
I0527 08:16:50.628082 19848 solver.cpp:237] Iteration 206250, loss = 1.10869
I0527 08:16:50.628123 19848 solver.cpp:253]     Train net output #0: loss = 1.10869 (* 1 = 1.10869 loss)
I0527 08:16:50.628144 19848 sgd_solver.cpp:106] Iteration 206250, lr = 0.001
I0527 08:17:00.464356 19848 solver.cpp:237] Iteration 206625, loss = 1.09058
I0527 08:17:00.464519 19848 solver.cpp:253]     Train net output #0: loss = 1.09058 (* 1 = 1.09058 loss)
I0527 08:17:00.464534 19848 sgd_solver.cpp:106] Iteration 206625, lr = 0.001
I0527 08:17:10.299859 19848 solver.cpp:237] Iteration 207000, loss = 1.51611
I0527 08:17:10.299893 19848 solver.cpp:253]     Train net output #0: loss = 1.51611 (* 1 = 1.51611 loss)
I0527 08:17:10.299911 19848 sgd_solver.cpp:106] Iteration 207000, lr = 0.001
I0527 08:17:20.134716 19848 solver.cpp:237] Iteration 207375, loss = 1.03339
I0527 08:17:20.134745 19848 solver.cpp:253]     Train net output #0: loss = 1.03339 (* 1 = 1.03339 loss)
I0527 08:17:20.134760 19848 sgd_solver.cpp:106] Iteration 207375, lr = 0.001
I0527 08:17:50.838305 19848 solver.cpp:237] Iteration 207750, loss = 0.979753
I0527 08:17:50.838472 19848 solver.cpp:253]     Train net output #0: loss = 0.979753 (* 1 = 0.979753 loss)
I0527 08:17:50.838488 19848 sgd_solver.cpp:106] Iteration 207750, lr = 0.001
I0527 08:18:00.671260 19848 solver.cpp:237] Iteration 208125, loss = 1.05459
I0527 08:18:00.671294 19848 solver.cpp:253]     Train net output #0: loss = 1.05459 (* 1 = 1.05459 loss)
I0527 08:18:00.671313 19848 sgd_solver.cpp:106] Iteration 208125, lr = 0.001
I0527 08:18:10.506606 19848 solver.cpp:237] Iteration 208500, loss = 1.49088
I0527 08:18:10.506642 19848 solver.cpp:253]     Train net output #0: loss = 1.49088 (* 1 = 1.49088 loss)
I0527 08:18:10.506659 19848 sgd_solver.cpp:106] Iteration 208500, lr = 0.001
I0527 08:18:20.342036 19848 solver.cpp:237] Iteration 208875, loss = 0.863275
I0527 08:18:20.342084 19848 solver.cpp:253]     Train net output #0: loss = 0.863275 (* 1 = 0.863275 loss)
I0527 08:18:20.342098 19848 sgd_solver.cpp:106] Iteration 208875, lr = 0.001
I0527 08:18:30.173069 19848 solver.cpp:237] Iteration 209250, loss = 1.07929
I0527 08:18:30.173228 19848 solver.cpp:253]     Train net output #0: loss = 1.07929 (* 1 = 1.07929 loss)
I0527 08:18:30.173243 19848 sgd_solver.cpp:106] Iteration 209250, lr = 0.001
I0527 08:18:40.014508 19848 solver.cpp:237] Iteration 209625, loss = 0.99851
I0527 08:18:40.014555 19848 solver.cpp:253]     Train net output #0: loss = 0.99851 (* 1 = 0.99851 loss)
I0527 08:18:40.014571 19848 sgd_solver.cpp:106] Iteration 209625, lr = 0.001
I0527 08:18:49.821399 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_210000.caffemodel
I0527 08:18:49.878337 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_210000.solverstate
I0527 08:18:49.904464 19848 solver.cpp:341] Iteration 210000, Testing net (#0)
I0527 08:19:59.254431 19848 solver.cpp:409]     Test net output #0: accuracy = 0.897165
I0527 08:19:59.254600 19848 solver.cpp:409]     Test net output #1: loss = 0.322012 (* 1 = 0.322012 loss)
I0527 08:20:20.145514 19848 solver.cpp:237] Iteration 210000, loss = 0.996096
I0527 08:20:20.145568 19848 solver.cpp:253]     Train net output #0: loss = 0.996096 (* 1 = 0.996096 loss)
I0527 08:20:20.145583 19848 sgd_solver.cpp:106] Iteration 210000, lr = 0.001
I0527 08:20:30.024842 19848 solver.cpp:237] Iteration 210375, loss = 1.25071
I0527 08:20:30.024993 19848 solver.cpp:253]     Train net output #0: loss = 1.25071 (* 1 = 1.25071 loss)
I0527 08:20:30.025007 19848 sgd_solver.cpp:106] Iteration 210375, lr = 0.001
I0527 08:20:39.907481 19848 solver.cpp:237] Iteration 210750, loss = 1.04097
I0527 08:20:39.907518 19848 solver.cpp:253]     Train net output #0: loss = 1.04097 (* 1 = 1.04097 loss)
I0527 08:20:39.907532 19848 sgd_solver.cpp:106] Iteration 210750, lr = 0.001
I0527 08:20:49.784243 19848 solver.cpp:237] Iteration 211125, loss = 1.20868
I0527 08:20:49.784286 19848 solver.cpp:253]     Train net output #0: loss = 1.20868 (* 1 = 1.20868 loss)
I0527 08:20:49.784303 19848 sgd_solver.cpp:106] Iteration 211125, lr = 0.001
I0527 08:20:59.667547 19848 solver.cpp:237] Iteration 211500, loss = 1.01109
I0527 08:20:59.667583 19848 solver.cpp:253]     Train net output #0: loss = 1.01109 (* 1 = 1.01109 loss)
I0527 08:20:59.667599 19848 sgd_solver.cpp:106] Iteration 211500, lr = 0.001
I0527 08:21:09.546464 19848 solver.cpp:237] Iteration 211875, loss = 1.06728
I0527 08:21:09.546619 19848 solver.cpp:253]     Train net output #0: loss = 1.06728 (* 1 = 1.06728 loss)
I0527 08:21:09.546633 19848 sgd_solver.cpp:106] Iteration 211875, lr = 0.001
I0527 08:21:19.420090 19848 solver.cpp:237] Iteration 212250, loss = 0.856365
I0527 08:21:19.420125 19848 solver.cpp:253]     Train net output #0: loss = 0.856365 (* 1 = 0.856365 loss)
I0527 08:21:19.420140 19848 sgd_solver.cpp:106] Iteration 212250, lr = 0.001
I0527 08:21:50.170094 19848 solver.cpp:237] Iteration 212625, loss = 1.09756
I0527 08:21:50.170276 19848 solver.cpp:253]     Train net output #0: loss = 1.09756 (* 1 = 1.09756 loss)
I0527 08:21:50.170291 19848 sgd_solver.cpp:106] Iteration 212625, lr = 0.001
I0527 08:22:00.052183 19848 solver.cpp:237] Iteration 213000, loss = 1.17084
I0527 08:22:00.052220 19848 solver.cpp:253]     Train net output #0: loss = 1.17084 (* 1 = 1.17084 loss)
I0527 08:22:00.052242 19848 sgd_solver.cpp:106] Iteration 213000, lr = 0.001
I0527 08:22:09.925861 19848 solver.cpp:237] Iteration 213375, loss = 1.4433
I0527 08:22:09.925897 19848 solver.cpp:253]     Train net output #0: loss = 1.4433 (* 1 = 1.4433 loss)
I0527 08:22:09.925914 19848 sgd_solver.cpp:106] Iteration 213375, lr = 0.001
I0527 08:22:19.773747 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_213750.caffemodel
I0527 08:22:19.830116 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_213750.solverstate
I0527 08:22:19.863522 19848 solver.cpp:237] Iteration 213750, loss = 0.933255
I0527 08:22:19.863564 19848 solver.cpp:253]     Train net output #0: loss = 0.933255 (* 1 = 0.933255 loss)
I0527 08:22:19.863581 19848 sgd_solver.cpp:106] Iteration 213750, lr = 0.001
I0527 08:22:29.742017 19848 solver.cpp:237] Iteration 214125, loss = 1.16464
I0527 08:22:29.742184 19848 solver.cpp:253]     Train net output #0: loss = 1.16464 (* 1 = 1.16464 loss)
I0527 08:22:29.742199 19848 sgd_solver.cpp:106] Iteration 214125, lr = 0.001
I0527 08:22:39.619969 19848 solver.cpp:237] Iteration 214500, loss = 0.764944
I0527 08:22:39.620004 19848 solver.cpp:253]     Train net output #0: loss = 0.764944 (* 1 = 0.764944 loss)
I0527 08:22:39.620023 19848 sgd_solver.cpp:106] Iteration 214500, lr = 0.001
I0527 08:22:49.501015 19848 solver.cpp:237] Iteration 214875, loss = 1.2114
I0527 08:22:49.501055 19848 solver.cpp:253]     Train net output #0: loss = 1.2114 (* 1 = 1.2114 loss)
I0527 08:22:49.501071 19848 sgd_solver.cpp:106] Iteration 214875, lr = 0.001
I0527 08:23:20.255234 19848 solver.cpp:237] Iteration 215250, loss = 1.24556
I0527 08:23:20.255409 19848 solver.cpp:253]     Train net output #0: loss = 1.24556 (* 1 = 1.24556 loss)
I0527 08:23:20.255425 19848 sgd_solver.cpp:106] Iteration 215250, lr = 0.001
I0527 08:23:30.127595 19848 solver.cpp:237] Iteration 215625, loss = 1.15739
I0527 08:23:30.127630 19848 solver.cpp:253]     Train net output #0: loss = 1.15739 (* 1 = 1.15739 loss)
I0527 08:23:30.127643 19848 sgd_solver.cpp:106] Iteration 215625, lr = 0.001
I0527 08:23:40.011116 19848 solver.cpp:237] Iteration 216000, loss = 1.36595
I0527 08:23:40.011162 19848 solver.cpp:253]     Train net output #0: loss = 1.36595 (* 1 = 1.36595 loss)
I0527 08:23:40.011176 19848 sgd_solver.cpp:106] Iteration 216000, lr = 0.001
I0527 08:23:49.893092 19848 solver.cpp:237] Iteration 216375, loss = 1.21657
I0527 08:23:49.893127 19848 solver.cpp:253]     Train net output #0: loss = 1.21657 (* 1 = 1.21657 loss)
I0527 08:23:49.893143 19848 sgd_solver.cpp:106] Iteration 216375, lr = 0.001
I0527 08:23:59.772132 19848 solver.cpp:237] Iteration 216750, loss = 1.06809
I0527 08:23:59.772282 19848 solver.cpp:253]     Train net output #0: loss = 1.06809 (* 1 = 1.06809 loss)
I0527 08:23:59.772295 19848 sgd_solver.cpp:106] Iteration 216750, lr = 0.001
I0527 08:24:09.649220 19848 solver.cpp:237] Iteration 217125, loss = 1.06761
I0527 08:24:09.649267 19848 solver.cpp:253]     Train net output #0: loss = 1.06761 (* 1 = 1.06761 loss)
I0527 08:24:09.649281 19848 sgd_solver.cpp:106] Iteration 217125, lr = 0.001
I0527 08:24:19.501580 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_217500.caffemodel
I0527 08:24:19.558389 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_217500.solverstate
I0527 08:24:19.584180 19848 solver.cpp:341] Iteration 217500, Testing net (#0)
I0527 08:25:07.774415 19848 solver.cpp:409]     Test net output #0: accuracy = 0.894413
I0527 08:25:07.774580 19848 solver.cpp:409]     Test net output #1: loss = 0.358259 (* 1 = 0.358259 loss)
I0527 08:25:28.667822 19848 solver.cpp:237] Iteration 217500, loss = 1.11741
I0527 08:25:28.667876 19848 solver.cpp:253]     Train net output #0: loss = 1.11741 (* 1 = 1.11741 loss)
I0527 08:25:28.667891 19848 sgd_solver.cpp:106] Iteration 217500, lr = 0.001
I0527 08:25:38.364590 19848 solver.cpp:237] Iteration 217875, loss = 1.11063
I0527 08:25:38.364750 19848 solver.cpp:253]     Train net output #0: loss = 1.11063 (* 1 = 1.11063 loss)
I0527 08:25:38.364764 19848 sgd_solver.cpp:106] Iteration 217875, lr = 0.001
I0527 08:25:48.055954 19848 solver.cpp:237] Iteration 218250, loss = 1.42738
I0527 08:25:48.055999 19848 solver.cpp:253]     Train net output #0: loss = 1.42738 (* 1 = 1.42738 loss)
I0527 08:25:48.056017 19848 sgd_solver.cpp:106] Iteration 218250, lr = 0.001
I0527 08:25:57.761162 19848 solver.cpp:237] Iteration 218625, loss = 1.17922
I0527 08:25:57.761198 19848 solver.cpp:253]     Train net output #0: loss = 1.17922 (* 1 = 1.17922 loss)
I0527 08:25:57.761211 19848 sgd_solver.cpp:106] Iteration 218625, lr = 0.001
I0527 08:26:07.452111 19848 solver.cpp:237] Iteration 219000, loss = 1.3881
I0527 08:26:07.452158 19848 solver.cpp:253]     Train net output #0: loss = 1.3881 (* 1 = 1.3881 loss)
I0527 08:26:07.452172 19848 sgd_solver.cpp:106] Iteration 219000, lr = 0.001
I0527 08:26:17.142737 19848 solver.cpp:237] Iteration 219375, loss = 1.09655
I0527 08:26:17.142892 19848 solver.cpp:253]     Train net output #0: loss = 1.09655 (* 1 = 1.09655 loss)
I0527 08:26:17.142905 19848 sgd_solver.cpp:106] Iteration 219375, lr = 0.001
I0527 08:26:26.837622 19848 solver.cpp:237] Iteration 219750, loss = 1.12026
I0527 08:26:26.837657 19848 solver.cpp:253]     Train net output #0: loss = 1.12026 (* 1 = 1.12026 loss)
I0527 08:26:26.837676 19848 sgd_solver.cpp:106] Iteration 219750, lr = 0.001
I0527 08:26:57.438755 19848 solver.cpp:237] Iteration 220125, loss = 1.19334
I0527 08:26:57.438931 19848 solver.cpp:253]     Train net output #0: loss = 1.19334 (* 1 = 1.19334 loss)
I0527 08:26:57.438946 19848 sgd_solver.cpp:106] Iteration 220125, lr = 0.001
I0527 08:27:07.133458 19848 solver.cpp:237] Iteration 220500, loss = 1.23709
I0527 08:27:07.133493 19848 solver.cpp:253]     Train net output #0: loss = 1.23709 (* 1 = 1.23709 loss)
I0527 08:27:07.133507 19848 sgd_solver.cpp:106] Iteration 220500, lr = 0.001
I0527 08:27:16.821432 19848 solver.cpp:237] Iteration 220875, loss = 1.13905
I0527 08:27:16.821467 19848 solver.cpp:253]     Train net output #0: loss = 1.13905 (* 1 = 1.13905 loss)
I0527 08:27:16.821485 19848 sgd_solver.cpp:106] Iteration 220875, lr = 0.001
I0527 08:27:26.490218 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_221250.caffemodel
I0527 08:27:26.548071 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_221250.solverstate
I0527 08:27:26.583858 19848 solver.cpp:237] Iteration 221250, loss = 1.24401
I0527 08:27:26.583907 19848 solver.cpp:253]     Train net output #0: loss = 1.24401 (* 1 = 1.24401 loss)
I0527 08:27:26.583923 19848 sgd_solver.cpp:106] Iteration 221250, lr = 0.001
I0527 08:27:36.279608 19848 solver.cpp:237] Iteration 221625, loss = 1.39186
I0527 08:27:36.279774 19848 solver.cpp:253]     Train net output #0: loss = 1.39186 (* 1 = 1.39186 loss)
I0527 08:27:36.279788 19848 sgd_solver.cpp:106] Iteration 221625, lr = 0.001
I0527 08:27:45.971190 19848 solver.cpp:237] Iteration 222000, loss = 1.44266
I0527 08:27:45.971225 19848 solver.cpp:253]     Train net output #0: loss = 1.44266 (* 1 = 1.44266 loss)
I0527 08:27:45.971238 19848 sgd_solver.cpp:106] Iteration 222000, lr = 0.001
I0527 08:27:55.673549 19848 solver.cpp:237] Iteration 222375, loss = 1.32743
I0527 08:27:55.673595 19848 solver.cpp:253]     Train net output #0: loss = 1.32743 (* 1 = 1.32743 loss)
I0527 08:27:55.673614 19848 sgd_solver.cpp:106] Iteration 222375, lr = 0.001
I0527 08:28:26.242234 19848 solver.cpp:237] Iteration 222750, loss = 1.3703
I0527 08:28:26.242408 19848 solver.cpp:253]     Train net output #0: loss = 1.3703 (* 1 = 1.3703 loss)
I0527 08:28:26.242424 19848 sgd_solver.cpp:106] Iteration 222750, lr = 0.001
I0527 08:28:35.934219 19848 solver.cpp:237] Iteration 223125, loss = 1.15849
I0527 08:28:35.934254 19848 solver.cpp:253]     Train net output #0: loss = 1.15849 (* 1 = 1.15849 loss)
I0527 08:28:35.934268 19848 sgd_solver.cpp:106] Iteration 223125, lr = 0.001
I0527 08:28:45.661301 19848 solver.cpp:237] Iteration 223500, loss = 1.21554
I0527 08:28:45.661350 19848 solver.cpp:253]     Train net output #0: loss = 1.21554 (* 1 = 1.21554 loss)
I0527 08:28:45.661365 19848 sgd_solver.cpp:106] Iteration 223500, lr = 0.001
I0527 08:28:55.388286 19848 solver.cpp:237] Iteration 223875, loss = 1.05839
I0527 08:28:55.388321 19848 solver.cpp:253]     Train net output #0: loss = 1.05839 (* 1 = 1.05839 loss)
I0527 08:28:55.388335 19848 sgd_solver.cpp:106] Iteration 223875, lr = 0.001
I0527 08:29:05.121845 19848 solver.cpp:237] Iteration 224250, loss = 1.115
I0527 08:29:05.122016 19848 solver.cpp:253]     Train net output #0: loss = 1.115 (* 1 = 1.115 loss)
I0527 08:29:05.122030 19848 sgd_solver.cpp:106] Iteration 224250, lr = 0.001
I0527 08:29:14.850477 19848 solver.cpp:237] Iteration 224625, loss = 0.743354
I0527 08:29:14.850512 19848 solver.cpp:253]     Train net output #0: loss = 0.743354 (* 1 = 0.743354 loss)
I0527 08:29:14.850529 19848 sgd_solver.cpp:106] Iteration 224625, lr = 0.001
I0527 08:29:24.559226 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_225000.caffemodel
I0527 08:29:24.615846 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_225000.solverstate
I0527 08:29:24.641360 19848 solver.cpp:341] Iteration 225000, Testing net (#0)
I0527 08:30:34.037433 19848 solver.cpp:409]     Test net output #0: accuracy = 0.895494
I0527 08:30:34.037601 19848 solver.cpp:409]     Test net output #1: loss = 0.321112 (* 1 = 0.321112 loss)
I0527 08:30:54.906481 19848 solver.cpp:237] Iteration 225000, loss = 0.637835
I0527 08:30:54.906533 19848 solver.cpp:253]     Train net output #0: loss = 0.637835 (* 1 = 0.637835 loss)
I0527 08:30:54.906549 19848 sgd_solver.cpp:106] Iteration 225000, lr = 0.001
I0527 08:31:04.845002 19848 solver.cpp:237] Iteration 225375, loss = 1.0785
I0527 08:31:04.845158 19848 solver.cpp:253]     Train net output #0: loss = 1.0785 (* 1 = 1.0785 loss)
I0527 08:31:04.845173 19848 sgd_solver.cpp:106] Iteration 225375, lr = 0.001
I0527 08:31:14.774612 19848 solver.cpp:237] Iteration 225750, loss = 1.24216
I0527 08:31:14.774658 19848 solver.cpp:253]     Train net output #0: loss = 1.24216 (* 1 = 1.24216 loss)
I0527 08:31:14.774677 19848 sgd_solver.cpp:106] Iteration 225750, lr = 0.001
I0527 08:31:24.708683 19848 solver.cpp:237] Iteration 226125, loss = 1.25271
I0527 08:31:24.708719 19848 solver.cpp:253]     Train net output #0: loss = 1.25271 (* 1 = 1.25271 loss)
I0527 08:31:24.708734 19848 sgd_solver.cpp:106] Iteration 226125, lr = 0.001
I0527 08:31:34.640609 19848 solver.cpp:237] Iteration 226500, loss = 1.25407
I0527 08:31:34.640652 19848 solver.cpp:253]     Train net output #0: loss = 1.25407 (* 1 = 1.25407 loss)
I0527 08:31:34.640671 19848 sgd_solver.cpp:106] Iteration 226500, lr = 0.001
I0527 08:31:44.570457 19848 solver.cpp:237] Iteration 226875, loss = 1.29094
I0527 08:31:44.570621 19848 solver.cpp:253]     Train net output #0: loss = 1.29094 (* 1 = 1.29094 loss)
I0527 08:31:44.570634 19848 sgd_solver.cpp:106] Iteration 226875, lr = 0.001
I0527 08:31:54.503909 19848 solver.cpp:237] Iteration 227250, loss = 0.965182
I0527 08:31:54.503944 19848 solver.cpp:253]     Train net output #0: loss = 0.965182 (* 1 = 0.965182 loss)
I0527 08:31:54.503962 19848 sgd_solver.cpp:106] Iteration 227250, lr = 0.001
I0527 08:32:25.299532 19848 solver.cpp:237] Iteration 227625, loss = 1.35878
I0527 08:32:25.299707 19848 solver.cpp:253]     Train net output #0: loss = 1.35878 (* 1 = 1.35878 loss)
I0527 08:32:25.299723 19848 sgd_solver.cpp:106] Iteration 227625, lr = 0.001
I0527 08:32:35.229660 19848 solver.cpp:237] Iteration 228000, loss = 1.08058
I0527 08:32:35.229693 19848 solver.cpp:253]     Train net output #0: loss = 1.08058 (* 1 = 1.08058 loss)
I0527 08:32:35.229707 19848 sgd_solver.cpp:106] Iteration 228000, lr = 0.001
I0527 08:32:45.160509 19848 solver.cpp:237] Iteration 228375, loss = 0.755918
I0527 08:32:45.160545 19848 solver.cpp:253]     Train net output #0: loss = 0.755918 (* 1 = 0.755918 loss)
I0527 08:32:45.160562 19848 sgd_solver.cpp:106] Iteration 228375, lr = 0.001
I0527 08:32:55.073078 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_228750.caffemodel
I0527 08:32:55.130198 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_228750.solverstate
I0527 08:32:55.163972 19848 solver.cpp:237] Iteration 228750, loss = 1.11916
I0527 08:32:55.164016 19848 solver.cpp:253]     Train net output #0: loss = 1.11916 (* 1 = 1.11916 loss)
I0527 08:32:55.164036 19848 sgd_solver.cpp:106] Iteration 228750, lr = 0.001
I0527 08:33:05.092088 19848 solver.cpp:237] Iteration 229125, loss = 1.07522
I0527 08:33:05.092254 19848 solver.cpp:253]     Train net output #0: loss = 1.07522 (* 1 = 1.07522 loss)
I0527 08:33:05.092268 19848 sgd_solver.cpp:106] Iteration 229125, lr = 0.001
I0527 08:33:15.027777 19848 solver.cpp:237] Iteration 229500, loss = 1.52061
I0527 08:33:15.027815 19848 solver.cpp:253]     Train net output #0: loss = 1.52061 (* 1 = 1.52061 loss)
I0527 08:33:15.027837 19848 sgd_solver.cpp:106] Iteration 229500, lr = 0.001
I0527 08:33:24.963876 19848 solver.cpp:237] Iteration 229875, loss = 0.650975
I0527 08:33:24.963912 19848 solver.cpp:253]     Train net output #0: loss = 0.650975 (* 1 = 0.650975 loss)
I0527 08:33:24.963927 19848 sgd_solver.cpp:106] Iteration 229875, lr = 0.001
I0527 08:33:55.777765 19848 solver.cpp:237] Iteration 230250, loss = 1.07241
I0527 08:33:55.777945 19848 solver.cpp:253]     Train net output #0: loss = 1.07241 (* 1 = 1.07241 loss)
I0527 08:33:55.777961 19848 sgd_solver.cpp:106] Iteration 230250, lr = 0.001
I0527 08:34:05.711318 19848 solver.cpp:237] Iteration 230625, loss = 1.10967
I0527 08:34:05.711357 19848 solver.cpp:253]     Train net output #0: loss = 1.10967 (* 1 = 1.10967 loss)
I0527 08:34:05.711376 19848 sgd_solver.cpp:106] Iteration 230625, lr = 0.001
I0527 08:34:15.647189 19848 solver.cpp:237] Iteration 231000, loss = 0.969016
I0527 08:34:15.647224 19848 solver.cpp:253]     Train net output #0: loss = 0.969016 (* 1 = 0.969016 loss)
I0527 08:34:15.647238 19848 sgd_solver.cpp:106] Iteration 231000, lr = 0.001
I0527 08:34:25.579569 19848 solver.cpp:237] Iteration 231375, loss = 1.06528
I0527 08:34:25.579605 19848 solver.cpp:253]     Train net output #0: loss = 1.06528 (* 1 = 1.06528 loss)
I0527 08:34:25.579618 19848 sgd_solver.cpp:106] Iteration 231375, lr = 0.001
I0527 08:34:35.513319 19848 solver.cpp:237] Iteration 231750, loss = 0.930382
I0527 08:34:35.513484 19848 solver.cpp:253]     Train net output #0: loss = 0.930382 (* 1 = 0.930382 loss)
I0527 08:34:35.513497 19848 sgd_solver.cpp:106] Iteration 231750, lr = 0.001
I0527 08:34:45.450623 19848 solver.cpp:237] Iteration 232125, loss = 1.22496
I0527 08:34:45.450656 19848 solver.cpp:253]     Train net output #0: loss = 1.22496 (* 1 = 1.22496 loss)
I0527 08:34:45.450675 19848 sgd_solver.cpp:106] Iteration 232125, lr = 0.001
I0527 08:34:55.360519 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_232500.caffemodel
I0527 08:34:55.417479 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_232500.solverstate
I0527 08:34:55.443899 19848 solver.cpp:341] Iteration 232500, Testing net (#0)
I0527 08:35:43.970738 19848 solver.cpp:409]     Test net output #0: accuracy = 0.896945
I0527 08:35:43.970911 19848 solver.cpp:409]     Test net output #1: loss = 0.324351 (* 1 = 0.324351 loss)
I0527 08:36:04.847044 19848 solver.cpp:237] Iteration 232500, loss = 1.34179
I0527 08:36:04.847097 19848 solver.cpp:253]     Train net output #0: loss = 1.34179 (* 1 = 1.34179 loss)
I0527 08:36:04.847111 19848 sgd_solver.cpp:106] Iteration 232500, lr = 0.001
I0527 08:36:14.666786 19848 solver.cpp:237] Iteration 232875, loss = 1.24739
I0527 08:36:14.666960 19848 solver.cpp:253]     Train net output #0: loss = 1.24739 (* 1 = 1.24739 loss)
I0527 08:36:14.666975 19848 sgd_solver.cpp:106] Iteration 232875, lr = 0.001
I0527 08:36:24.480895 19848 solver.cpp:237] Iteration 233250, loss = 0.716885
I0527 08:36:24.480931 19848 solver.cpp:253]     Train net output #0: loss = 0.716885 (* 1 = 0.716885 loss)
I0527 08:36:24.480948 19848 sgd_solver.cpp:106] Iteration 233250, lr = 0.001
I0527 08:36:34.295845 19848 solver.cpp:237] Iteration 233625, loss = 1.05443
I0527 08:36:34.295889 19848 solver.cpp:253]     Train net output #0: loss = 1.05443 (* 1 = 1.05443 loss)
I0527 08:36:34.295903 19848 sgd_solver.cpp:106] Iteration 233625, lr = 0.001
I0527 08:36:44.111599 19848 solver.cpp:237] Iteration 234000, loss = 1.16607
I0527 08:36:44.111635 19848 solver.cpp:253]     Train net output #0: loss = 1.16607 (* 1 = 1.16607 loss)
I0527 08:36:44.111652 19848 sgd_solver.cpp:106] Iteration 234000, lr = 0.001
I0527 08:36:53.927341 19848 solver.cpp:237] Iteration 234375, loss = 0.893661
I0527 08:36:53.927507 19848 solver.cpp:253]     Train net output #0: loss = 0.893661 (* 1 = 0.893661 loss)
I0527 08:36:53.927521 19848 sgd_solver.cpp:106] Iteration 234375, lr = 0.001
I0527 08:37:03.740102 19848 solver.cpp:237] Iteration 234750, loss = 0.94231
I0527 08:37:03.740149 19848 solver.cpp:253]     Train net output #0: loss = 0.94231 (* 1 = 0.94231 loss)
I0527 08:37:03.740164 19848 sgd_solver.cpp:106] Iteration 234750, lr = 0.001
I0527 08:37:34.411329 19848 solver.cpp:237] Iteration 235125, loss = 1.06512
I0527 08:37:34.411509 19848 solver.cpp:253]     Train net output #0: loss = 1.06512 (* 1 = 1.06512 loss)
I0527 08:37:34.411525 19848 sgd_solver.cpp:106] Iteration 235125, lr = 0.001
I0527 08:37:44.226050 19848 solver.cpp:237] Iteration 235500, loss = 1.49891
I0527 08:37:44.226085 19848 solver.cpp:253]     Train net output #0: loss = 1.49891 (* 1 = 1.49891 loss)
I0527 08:37:44.226102 19848 sgd_solver.cpp:106] Iteration 235500, lr = 0.001
I0527 08:37:54.038184 19848 solver.cpp:237] Iteration 235875, loss = 1.00866
I0527 08:37:54.038228 19848 solver.cpp:253]     Train net output #0: loss = 1.00866 (* 1 = 1.00866 loss)
I0527 08:37:54.038244 19848 sgd_solver.cpp:106] Iteration 235875, lr = 0.001
I0527 08:38:03.824544 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_236250.caffemodel
I0527 08:38:03.882212 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_236250.solverstate
I0527 08:38:03.917778 19848 solver.cpp:237] Iteration 236250, loss = 0.939567
I0527 08:38:03.917829 19848 solver.cpp:253]     Train net output #0: loss = 0.939567 (* 1 = 0.939567 loss)
I0527 08:38:03.917843 19848 sgd_solver.cpp:106] Iteration 236250, lr = 0.001
I0527 08:38:13.731319 19848 solver.cpp:237] Iteration 236625, loss = 1.0158
I0527 08:38:13.731487 19848 solver.cpp:253]     Train net output #0: loss = 1.0158 (* 1 = 1.0158 loss)
I0527 08:38:13.731500 19848 sgd_solver.cpp:106] Iteration 236625, lr = 0.001
I0527 08:38:23.545055 19848 solver.cpp:237] Iteration 237000, loss = 1.73624
I0527 08:38:23.545090 19848 solver.cpp:253]     Train net output #0: loss = 1.73624 (* 1 = 1.73624 loss)
I0527 08:38:23.545105 19848 sgd_solver.cpp:106] Iteration 237000, lr = 0.001
I0527 08:38:33.357036 19848 solver.cpp:237] Iteration 237375, loss = 1.54154
I0527 08:38:33.357071 19848 solver.cpp:253]     Train net output #0: loss = 1.54154 (* 1 = 1.54154 loss)
I0527 08:38:33.357089 19848 sgd_solver.cpp:106] Iteration 237375, lr = 0.001
I0527 08:39:04.096647 19848 solver.cpp:237] Iteration 237750, loss = 0.984624
I0527 08:39:04.096834 19848 solver.cpp:253]     Train net output #0: loss = 0.984624 (* 1 = 0.984624 loss)
I0527 08:39:04.096849 19848 sgd_solver.cpp:106] Iteration 237750, lr = 0.001
I0527 08:39:13.911972 19848 solver.cpp:237] Iteration 238125, loss = 1.29339
I0527 08:39:13.912006 19848 solver.cpp:253]     Train net output #0: loss = 1.29339 (* 1 = 1.29339 loss)
I0527 08:39:13.912024 19848 sgd_solver.cpp:106] Iteration 238125, lr = 0.001
I0527 08:39:23.721385 19848 solver.cpp:237] Iteration 238500, loss = 1.21715
I0527 08:39:23.721421 19848 solver.cpp:253]     Train net output #0: loss = 1.21715 (* 1 = 1.21715 loss)
I0527 08:39:23.721437 19848 sgd_solver.cpp:106] Iteration 238500, lr = 0.001
I0527 08:39:33.533841 19848 solver.cpp:237] Iteration 238875, loss = 1.17497
I0527 08:39:33.533884 19848 solver.cpp:253]     Train net output #0: loss = 1.17497 (* 1 = 1.17497 loss)
I0527 08:39:33.533897 19848 sgd_solver.cpp:106] Iteration 238875, lr = 0.001
I0527 08:39:43.348662 19848 solver.cpp:237] Iteration 239250, loss = 1.20727
I0527 08:39:43.348819 19848 solver.cpp:253]     Train net output #0: loss = 1.20727 (* 1 = 1.20727 loss)
I0527 08:39:43.348832 19848 sgd_solver.cpp:106] Iteration 239250, lr = 0.001
I0527 08:39:53.161336 19848 solver.cpp:237] Iteration 239625, loss = 1.42409
I0527 08:39:53.161381 19848 solver.cpp:253]     Train net output #0: loss = 1.42409 (* 1 = 1.42409 loss)
I0527 08:39:53.161396 19848 sgd_solver.cpp:106] Iteration 239625, lr = 0.001
I0527 08:40:02.950244 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_240000.caffemodel
I0527 08:40:03.008414 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_240000.solverstate
I0527 08:40:03.036345 19848 solver.cpp:341] Iteration 240000, Testing net (#0)
I0527 08:41:12.449550 19848 solver.cpp:409]     Test net output #0: accuracy = 0.896972
I0527 08:41:12.449724 19848 solver.cpp:409]     Test net output #1: loss = 0.336047 (* 1 = 0.336047 loss)
I0527 08:41:33.341429 19848 solver.cpp:237] Iteration 240000, loss = 1.1606
I0527 08:41:33.341481 19848 solver.cpp:253]     Train net output #0: loss = 1.1606 (* 1 = 1.1606 loss)
I0527 08:41:33.341498 19848 sgd_solver.cpp:106] Iteration 240000, lr = 0.001
I0527 08:41:43.215242 19848 solver.cpp:237] Iteration 240375, loss = 0.856055
I0527 08:41:43.215404 19848 solver.cpp:253]     Train net output #0: loss = 0.856055 (* 1 = 0.856055 loss)
I0527 08:41:43.215418 19848 sgd_solver.cpp:106] Iteration 240375, lr = 0.001
I0527 08:41:53.097668 19848 solver.cpp:237] Iteration 240750, loss = 1.09006
I0527 08:41:53.097702 19848 solver.cpp:253]     Train net output #0: loss = 1.09006 (* 1 = 1.09006 loss)
I0527 08:41:53.097720 19848 sgd_solver.cpp:106] Iteration 240750, lr = 0.001
I0527 08:42:02.979468 19848 solver.cpp:237] Iteration 241125, loss = 1.0787
I0527 08:42:02.979513 19848 solver.cpp:253]     Train net output #0: loss = 1.0787 (* 1 = 1.0787 loss)
I0527 08:42:02.979532 19848 sgd_solver.cpp:106] Iteration 241125, lr = 0.001
I0527 08:42:12.851060 19848 solver.cpp:237] Iteration 241500, loss = 1.22594
I0527 08:42:12.851096 19848 solver.cpp:253]     Train net output #0: loss = 1.22594 (* 1 = 1.22594 loss)
I0527 08:42:12.851114 19848 sgd_solver.cpp:106] Iteration 241500, lr = 0.001
I0527 08:42:22.720206 19848 solver.cpp:237] Iteration 241875, loss = 1.19626
I0527 08:42:22.720369 19848 solver.cpp:253]     Train net output #0: loss = 1.19626 (* 1 = 1.19626 loss)
I0527 08:42:22.720383 19848 sgd_solver.cpp:106] Iteration 241875, lr = 0.001
I0527 08:42:32.596246 19848 solver.cpp:237] Iteration 242250, loss = 1.17245
I0527 08:42:32.596281 19848 solver.cpp:253]     Train net output #0: loss = 1.17245 (* 1 = 1.17245 loss)
I0527 08:42:32.596297 19848 sgd_solver.cpp:106] Iteration 242250, lr = 0.001
I0527 08:43:03.350275 19848 solver.cpp:237] Iteration 242625, loss = 1.08601
I0527 08:43:03.350463 19848 solver.cpp:253]     Train net output #0: loss = 1.08601 (* 1 = 1.08601 loss)
I0527 08:43:03.350478 19848 sgd_solver.cpp:106] Iteration 242625, lr = 0.001
I0527 08:43:13.227195 19848 solver.cpp:237] Iteration 243000, loss = 0.918925
I0527 08:43:13.227241 19848 solver.cpp:253]     Train net output #0: loss = 0.918925 (* 1 = 0.918925 loss)
I0527 08:43:13.227259 19848 sgd_solver.cpp:106] Iteration 243000, lr = 0.001
I0527 08:43:23.100999 19848 solver.cpp:237] Iteration 243375, loss = 1.7543
I0527 08:43:23.101035 19848 solver.cpp:253]     Train net output #0: loss = 1.7543 (* 1 = 1.7543 loss)
I0527 08:43:23.101052 19848 sgd_solver.cpp:106] Iteration 243375, lr = 0.001
I0527 08:43:32.948487 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_243750.caffemodel
I0527 08:43:33.005668 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_243750.solverstate
I0527 08:43:33.039443 19848 solver.cpp:237] Iteration 243750, loss = 1.34269
I0527 08:43:33.039489 19848 solver.cpp:253]     Train net output #0: loss = 1.34269 (* 1 = 1.34269 loss)
I0527 08:43:33.039505 19848 sgd_solver.cpp:106] Iteration 243750, lr = 0.001
I0527 08:43:42.914660 19848 solver.cpp:237] Iteration 244125, loss = 1.26572
I0527 08:43:42.914844 19848 solver.cpp:253]     Train net output #0: loss = 1.26572 (* 1 = 1.26572 loss)
I0527 08:43:42.914858 19848 sgd_solver.cpp:106] Iteration 244125, lr = 0.001
I0527 08:43:52.783854 19848 solver.cpp:237] Iteration 244500, loss = 1.29057
I0527 08:43:52.783890 19848 solver.cpp:253]     Train net output #0: loss = 1.29057 (* 1 = 1.29057 loss)
I0527 08:43:52.783907 19848 sgd_solver.cpp:106] Iteration 244500, lr = 0.001
I0527 08:44:02.655046 19848 solver.cpp:237] Iteration 244875, loss = 1.37959
I0527 08:44:02.655093 19848 solver.cpp:253]     Train net output #0: loss = 1.37959 (* 1 = 1.37959 loss)
I0527 08:44:02.655109 19848 sgd_solver.cpp:106] Iteration 244875, lr = 0.001
I0527 08:44:33.378173 19848 solver.cpp:237] Iteration 245250, loss = 1.31595
I0527 08:44:33.378348 19848 solver.cpp:253]     Train net output #0: loss = 1.31595 (* 1 = 1.31595 loss)
I0527 08:44:33.378363 19848 sgd_solver.cpp:106] Iteration 245250, lr = 0.001
I0527 08:44:43.255022 19848 solver.cpp:237] Iteration 245625, loss = 1.08437
I0527 08:44:43.255055 19848 solver.cpp:253]     Train net output #0: loss = 1.08437 (* 1 = 1.08437 loss)
I0527 08:44:43.255069 19848 sgd_solver.cpp:106] Iteration 245625, lr = 0.001
I0527 08:44:53.121593 19848 solver.cpp:237] Iteration 246000, loss = 1.50983
I0527 08:44:53.121635 19848 solver.cpp:253]     Train net output #0: loss = 1.50983 (* 1 = 1.50983 loss)
I0527 08:44:53.121657 19848 sgd_solver.cpp:106] Iteration 246000, lr = 0.001
I0527 08:45:03.001984 19848 solver.cpp:237] Iteration 246375, loss = 0.898838
I0527 08:45:03.002022 19848 solver.cpp:253]     Train net output #0: loss = 0.898838 (* 1 = 0.898838 loss)
I0527 08:45:03.002038 19848 sgd_solver.cpp:106] Iteration 246375, lr = 0.001
I0527 08:45:12.873356 19848 solver.cpp:237] Iteration 246750, loss = 1.29048
I0527 08:45:12.873513 19848 solver.cpp:253]     Train net output #0: loss = 1.29048 (* 1 = 1.29048 loss)
I0527 08:45:12.873527 19848 sgd_solver.cpp:106] Iteration 246750, lr = 0.001
I0527 08:45:22.753281 19848 solver.cpp:237] Iteration 247125, loss = 1.27243
I0527 08:45:22.753325 19848 solver.cpp:253]     Train net output #0: loss = 1.27243 (* 1 = 1.27243 loss)
I0527 08:45:22.753343 19848 sgd_solver.cpp:106] Iteration 247125, lr = 0.001
I0527 08:45:32.591768 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_247500.caffemodel
I0527 08:45:32.648614 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_247500.solverstate
I0527 08:45:32.674080 19848 solver.cpp:341] Iteration 247500, Testing net (#0)
I0527 08:46:20.895259 19848 solver.cpp:409]     Test net output #0: accuracy = 0.899866
I0527 08:46:20.895445 19848 solver.cpp:409]     Test net output #1: loss = 0.316499 (* 1 = 0.316499 loss)
I0527 08:46:41.793555 19848 solver.cpp:237] Iteration 247500, loss = 1.05859
I0527 08:46:41.793606 19848 solver.cpp:253]     Train net output #0: loss = 1.05859 (* 1 = 1.05859 loss)
I0527 08:46:41.793622 19848 sgd_solver.cpp:106] Iteration 247500, lr = 0.001
I0527 08:46:51.523560 19848 solver.cpp:237] Iteration 247875, loss = 0.943046
I0527 08:46:51.523725 19848 solver.cpp:253]     Train net output #0: loss = 0.943046 (* 1 = 0.943046 loss)
I0527 08:46:51.523738 19848 sgd_solver.cpp:106] Iteration 247875, lr = 0.001
I0527 08:47:01.262336 19848 solver.cpp:237] Iteration 248250, loss = 1.1171
I0527 08:47:01.262382 19848 solver.cpp:253]     Train net output #0: loss = 1.1171 (* 1 = 1.1171 loss)
I0527 08:47:01.262398 19848 sgd_solver.cpp:106] Iteration 248250, lr = 0.001
I0527 08:47:10.999588 19848 solver.cpp:237] Iteration 248625, loss = 1.17861
I0527 08:47:10.999624 19848 solver.cpp:253]     Train net output #0: loss = 1.17861 (* 1 = 1.17861 loss)
I0527 08:47:10.999640 19848 sgd_solver.cpp:106] Iteration 248625, lr = 0.001
I0527 08:47:20.731297 19848 solver.cpp:237] Iteration 249000, loss = 0.973647
I0527 08:47:20.731334 19848 solver.cpp:253]     Train net output #0: loss = 0.973647 (* 1 = 0.973647 loss)
I0527 08:47:20.731351 19848 sgd_solver.cpp:106] Iteration 249000, lr = 0.001
I0527 08:47:30.462358 19848 solver.cpp:237] Iteration 249375, loss = 1.21283
I0527 08:47:30.462530 19848 solver.cpp:253]     Train net output #0: loss = 1.21283 (* 1 = 1.21283 loss)
I0527 08:47:30.462544 19848 sgd_solver.cpp:106] Iteration 249375, lr = 0.001
I0527 08:47:40.187186 19848 solver.cpp:237] Iteration 249750, loss = 1.14341
I0527 08:47:40.187221 19848 solver.cpp:253]     Train net output #0: loss = 1.14341 (* 1 = 1.14341 loss)
I0527 08:47:40.187237 19848 sgd_solver.cpp:106] Iteration 249750, lr = 0.001
I0527 08:48:10.800736 19848 solver.cpp:237] Iteration 250125, loss = 1.42249
I0527 08:48:10.800917 19848 solver.cpp:253]     Train net output #0: loss = 1.42249 (* 1 = 1.42249 loss)
I0527 08:48:10.800933 19848 sgd_solver.cpp:106] Iteration 250125, lr = 0.001
I0527 08:48:20.524111 19848 solver.cpp:237] Iteration 250500, loss = 1.06165
I0527 08:48:20.524152 19848 solver.cpp:253]     Train net output #0: loss = 1.06165 (* 1 = 1.06165 loss)
I0527 08:48:20.524173 19848 sgd_solver.cpp:106] Iteration 250500, lr = 0.001
I0527 08:48:30.254767 19848 solver.cpp:237] Iteration 250875, loss = 1.39802
I0527 08:48:30.254802 19848 solver.cpp:253]     Train net output #0: loss = 1.39802 (* 1 = 1.39802 loss)
I0527 08:48:30.254817 19848 sgd_solver.cpp:106] Iteration 250875, lr = 0.001
I0527 08:48:39.955977 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_251250.caffemodel
I0527 08:48:40.012760 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_251250.solverstate
I0527 08:48:40.046798 19848 solver.cpp:237] Iteration 251250, loss = 1.19907
I0527 08:48:40.046844 19848 solver.cpp:253]     Train net output #0: loss = 1.19907 (* 1 = 1.19907 loss)
I0527 08:48:40.046859 19848 sgd_solver.cpp:106] Iteration 251250, lr = 0.001
I0527 08:48:49.776329 19848 solver.cpp:237] Iteration 251625, loss = 1.22486
I0527 08:48:49.776490 19848 solver.cpp:253]     Train net output #0: loss = 1.22486 (* 1 = 1.22486 loss)
I0527 08:48:49.776504 19848 sgd_solver.cpp:106] Iteration 251625, lr = 0.001
I0527 08:48:59.503810 19848 solver.cpp:237] Iteration 252000, loss = 1.05867
I0527 08:48:59.503844 19848 solver.cpp:253]     Train net output #0: loss = 1.05867 (* 1 = 1.05867 loss)
I0527 08:48:59.503862 19848 sgd_solver.cpp:106] Iteration 252000, lr = 0.001
I0527 08:49:09.236045 19848 solver.cpp:237] Iteration 252375, loss = 1.20732
I0527 08:49:09.236090 19848 solver.cpp:253]     Train net output #0: loss = 1.20732 (* 1 = 1.20732 loss)
I0527 08:49:09.236109 19848 sgd_solver.cpp:106] Iteration 252375, lr = 0.001
I0527 08:49:39.858479 19848 solver.cpp:237] Iteration 252750, loss = 1.27805
I0527 08:49:39.858664 19848 solver.cpp:253]     Train net output #0: loss = 1.27805 (* 1 = 1.27805 loss)
I0527 08:49:39.858680 19848 sgd_solver.cpp:106] Iteration 252750, lr = 0.001
I0527 08:49:49.586560 19848 solver.cpp:237] Iteration 253125, loss = 1.10303
I0527 08:49:49.586594 19848 solver.cpp:253]     Train net output #0: loss = 1.10303 (* 1 = 1.10303 loss)
I0527 08:49:49.586609 19848 sgd_solver.cpp:106] Iteration 253125, lr = 0.001
I0527 08:49:59.307273 19848 solver.cpp:237] Iteration 253500, loss = 0.823795
I0527 08:49:59.307319 19848 solver.cpp:253]     Train net output #0: loss = 0.823795 (* 1 = 0.823795 loss)
I0527 08:49:59.307335 19848 sgd_solver.cpp:106] Iteration 253500, lr = 0.001
I0527 08:50:09.036371 19848 solver.cpp:237] Iteration 253875, loss = 0.927827
I0527 08:50:09.036408 19848 solver.cpp:253]     Train net output #0: loss = 0.927827 (* 1 = 0.927827 loss)
I0527 08:50:09.036424 19848 sgd_solver.cpp:106] Iteration 253875, lr = 0.001
I0527 08:50:18.770272 19848 solver.cpp:237] Iteration 254250, loss = 1.09968
I0527 08:50:18.770448 19848 solver.cpp:253]     Train net output #0: loss = 1.09968 (* 1 = 1.09968 loss)
I0527 08:50:18.770462 19848 sgd_solver.cpp:106] Iteration 254250, lr = 0.001
I0527 08:50:28.507995 19848 solver.cpp:237] Iteration 254625, loss = 0.973631
I0527 08:50:28.508031 19848 solver.cpp:253]     Train net output #0: loss = 0.973631 (* 1 = 0.973631 loss)
I0527 08:50:28.508049 19848 sgd_solver.cpp:106] Iteration 254625, lr = 0.001
I0527 08:50:38.215065 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_255000.caffemodel
I0527 08:50:38.271848 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_255000.solverstate
I0527 08:50:38.297999 19848 solver.cpp:341] Iteration 255000, Testing net (#0)
I0527 08:51:47.734040 19848 solver.cpp:409]     Test net output #0: accuracy = 0.896834
I0527 08:51:47.734220 19848 solver.cpp:409]     Test net output #1: loss = 0.339674 (* 1 = 0.339674 loss)
I0527 08:52:08.651715 19848 solver.cpp:237] Iteration 255000, loss = 1.00447
I0527 08:52:08.651767 19848 solver.cpp:253]     Train net output #0: loss = 1.00447 (* 1 = 1.00447 loss)
I0527 08:52:08.651780 19848 sgd_solver.cpp:106] Iteration 255000, lr = 0.001
I0527 08:52:18.451349 19848 solver.cpp:237] Iteration 255375, loss = 1.02354
I0527 08:52:18.451513 19848 solver.cpp:253]     Train net output #0: loss = 1.02354 (* 1 = 1.02354 loss)
I0527 08:52:18.451525 19848 sgd_solver.cpp:106] Iteration 255375, lr = 0.001
I0527 08:52:28.255218 19848 solver.cpp:237] Iteration 255750, loss = 1.15562
I0527 08:52:28.255259 19848 solver.cpp:253]     Train net output #0: loss = 1.15562 (* 1 = 1.15562 loss)
I0527 08:52:28.255280 19848 sgd_solver.cpp:106] Iteration 255750, lr = 0.001
I0527 08:52:38.053390 19848 solver.cpp:237] Iteration 256125, loss = 1.24557
I0527 08:52:38.053426 19848 solver.cpp:253]     Train net output #0: loss = 1.24557 (* 1 = 1.24557 loss)
I0527 08:52:38.053439 19848 sgd_solver.cpp:106] Iteration 256125, lr = 0.001
I0527 08:52:47.855515 19848 solver.cpp:237] Iteration 256500, loss = 1.48102
I0527 08:52:47.855564 19848 solver.cpp:253]     Train net output #0: loss = 1.48102 (* 1 = 1.48102 loss)
I0527 08:52:47.855579 19848 sgd_solver.cpp:106] Iteration 256500, lr = 0.001
I0527 08:52:57.657989 19848 solver.cpp:237] Iteration 256875, loss = 1.34872
I0527 08:52:57.658164 19848 solver.cpp:253]     Train net output #0: loss = 1.34872 (* 1 = 1.34872 loss)
I0527 08:52:57.658177 19848 sgd_solver.cpp:106] Iteration 256875, lr = 0.001
I0527 08:53:07.460336 19848 solver.cpp:237] Iteration 257250, loss = 0.908175
I0527 08:53:07.460371 19848 solver.cpp:253]     Train net output #0: loss = 0.908175 (* 1 = 0.908175 loss)
I0527 08:53:07.460388 19848 sgd_solver.cpp:106] Iteration 257250, lr = 0.001
I0527 08:53:38.140939 19848 solver.cpp:237] Iteration 257625, loss = 1.3904
I0527 08:53:38.141120 19848 solver.cpp:253]     Train net output #0: loss = 1.3904 (* 1 = 1.3904 loss)
I0527 08:53:38.141135 19848 sgd_solver.cpp:106] Iteration 257625, lr = 0.001
I0527 08:53:47.943369 19848 solver.cpp:237] Iteration 258000, loss = 1.07234
I0527 08:53:47.943404 19848 solver.cpp:253]     Train net output #0: loss = 1.07234 (* 1 = 1.07234 loss)
I0527 08:53:47.943421 19848 sgd_solver.cpp:106] Iteration 258000, lr = 0.001
I0527 08:53:57.747467 19848 solver.cpp:237] Iteration 258375, loss = 0.885546
I0527 08:53:57.747503 19848 solver.cpp:253]     Train net output #0: loss = 0.885546 (* 1 = 0.885546 loss)
I0527 08:53:57.747519 19848 sgd_solver.cpp:106] Iteration 258375, lr = 0.001
I0527 08:54:07.525053 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_258750.caffemodel
I0527 08:54:07.584300 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_258750.solverstate
I0527 08:54:07.620508 19848 solver.cpp:237] Iteration 258750, loss = 1.10377
I0527 08:54:07.620558 19848 solver.cpp:253]     Train net output #0: loss = 1.10377 (* 1 = 1.10377 loss)
I0527 08:54:07.620573 19848 sgd_solver.cpp:106] Iteration 258750, lr = 0.001
I0527 08:54:17.426779 19848 solver.cpp:237] Iteration 259125, loss = 1.11983
I0527 08:54:17.426944 19848 solver.cpp:253]     Train net output #0: loss = 1.11983 (* 1 = 1.11983 loss)
I0527 08:54:17.426957 19848 sgd_solver.cpp:106] Iteration 259125, lr = 0.001
I0527 08:54:27.228967 19848 solver.cpp:237] Iteration 259500, loss = 1.55251
I0527 08:54:27.229018 19848 solver.cpp:253]     Train net output #0: loss = 1.55251 (* 1 = 1.55251 loss)
I0527 08:54:27.229032 19848 sgd_solver.cpp:106] Iteration 259500, lr = 0.001
I0527 08:54:37.032572 19848 solver.cpp:237] Iteration 259875, loss = 0.987012
I0527 08:54:37.032608 19848 solver.cpp:253]     Train net output #0: loss = 0.987012 (* 1 = 0.987012 loss)
I0527 08:54:37.032624 19848 sgd_solver.cpp:106] Iteration 259875, lr = 0.001
I0527 08:55:07.758891 19848 solver.cpp:237] Iteration 260250, loss = 1.21879
I0527 08:55:07.759119 19848 solver.cpp:253]     Train net output #0: loss = 1.21879 (* 1 = 1.21879 loss)
I0527 08:55:07.759135 19848 sgd_solver.cpp:106] Iteration 260250, lr = 0.001
I0527 08:55:17.561172 19848 solver.cpp:237] Iteration 260625, loss = 1.14233
I0527 08:55:17.561220 19848 solver.cpp:253]     Train net output #0: loss = 1.14233 (* 1 = 1.14233 loss)
I0527 08:55:17.561234 19848 sgd_solver.cpp:106] Iteration 260625, lr = 0.001
I0527 08:55:27.362704 19848 solver.cpp:237] Iteration 261000, loss = 1.24716
I0527 08:55:27.362745 19848 solver.cpp:253]     Train net output #0: loss = 1.24716 (* 1 = 1.24716 loss)
I0527 08:55:27.362757 19848 sgd_solver.cpp:106] Iteration 261000, lr = 0.001
I0527 08:55:37.165779 19848 solver.cpp:237] Iteration 261375, loss = 1.2336
I0527 08:55:37.165814 19848 solver.cpp:253]     Train net output #0: loss = 1.2336 (* 1 = 1.2336 loss)
I0527 08:55:37.165828 19848 sgd_solver.cpp:106] Iteration 261375, lr = 0.001
I0527 08:55:46.970475 19848 solver.cpp:237] Iteration 261750, loss = 1.40107
I0527 08:55:46.970650 19848 solver.cpp:253]     Train net output #0: loss = 1.40107 (* 1 = 1.40107 loss)
I0527 08:55:46.970664 19848 sgd_solver.cpp:106] Iteration 261750, lr = 0.001
I0527 08:55:56.773015 19848 solver.cpp:237] Iteration 262125, loss = 0.892411
I0527 08:55:56.773051 19848 solver.cpp:253]     Train net output #0: loss = 0.892411 (* 1 = 0.892411 loss)
I0527 08:55:56.773066 19848 sgd_solver.cpp:106] Iteration 262125, lr = 0.001
I0527 08:56:06.552147 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_262500.caffemodel
I0527 08:56:06.609045 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_262500.solverstate
I0527 08:56:06.635269 19848 solver.cpp:341] Iteration 262500, Testing net (#0)
I0527 08:56:55.196486 19848 solver.cpp:409]     Test net output #0: accuracy = 0.900554
I0527 08:56:55.196676 19848 solver.cpp:409]     Test net output #1: loss = 0.318676 (* 1 = 0.318676 loss)
I0527 08:57:16.072646 19848 solver.cpp:237] Iteration 262500, loss = 1.2867
I0527 08:57:16.072697 19848 solver.cpp:253]     Train net output #0: loss = 1.2867 (* 1 = 1.2867 loss)
I0527 08:57:16.072712 19848 sgd_solver.cpp:106] Iteration 262500, lr = 0.001
I0527 08:57:25.956133 19848 solver.cpp:237] Iteration 262875, loss = 1.05942
I0527 08:57:25.956311 19848 solver.cpp:253]     Train net output #0: loss = 1.05942 (* 1 = 1.05942 loss)
I0527 08:57:25.956326 19848 sgd_solver.cpp:106] Iteration 262875, lr = 0.001
I0527 08:57:35.845145 19848 solver.cpp:237] Iteration 263250, loss = 1.15466
I0527 08:57:35.845180 19848 solver.cpp:253]     Train net output #0: loss = 1.15466 (* 1 = 1.15466 loss)
I0527 08:57:35.845194 19848 sgd_solver.cpp:106] Iteration 263250, lr = 0.001
I0527 08:57:45.724465 19848 solver.cpp:237] Iteration 263625, loss = 1.34198
I0527 08:57:45.724499 19848 solver.cpp:253]     Train net output #0: loss = 1.34198 (* 1 = 1.34198 loss)
I0527 08:57:45.724517 19848 sgd_solver.cpp:106] Iteration 263625, lr = 0.001
I0527 08:57:55.608811 19848 solver.cpp:237] Iteration 264000, loss = 1.21541
I0527 08:57:55.608860 19848 solver.cpp:253]     Train net output #0: loss = 1.21541 (* 1 = 1.21541 loss)
I0527 08:57:55.608875 19848 sgd_solver.cpp:106] Iteration 264000, lr = 0.001
I0527 08:58:05.492674 19848 solver.cpp:237] Iteration 264375, loss = 1.13041
I0527 08:58:05.492835 19848 solver.cpp:253]     Train net output #0: loss = 1.13041 (* 1 = 1.13041 loss)
I0527 08:58:05.492849 19848 sgd_solver.cpp:106] Iteration 264375, lr = 0.001
I0527 08:58:15.377540 19848 solver.cpp:237] Iteration 264750, loss = 1.05718
I0527 08:58:15.377580 19848 solver.cpp:253]     Train net output #0: loss = 1.05718 (* 1 = 1.05718 loss)
I0527 08:58:15.377600 19848 sgd_solver.cpp:106] Iteration 264750, lr = 0.001
I0527 08:58:46.132900 19848 solver.cpp:237] Iteration 265125, loss = 1.15006
I0527 08:58:46.133083 19848 solver.cpp:253]     Train net output #0: loss = 1.15006 (* 1 = 1.15006 loss)
I0527 08:58:46.133098 19848 sgd_solver.cpp:106] Iteration 265125, lr = 0.001
I0527 08:58:56.015516 19848 solver.cpp:237] Iteration 265500, loss = 0.946969
I0527 08:58:56.015552 19848 solver.cpp:253]     Train net output #0: loss = 0.946969 (* 1 = 0.946969 loss)
I0527 08:58:56.015568 19848 sgd_solver.cpp:106] Iteration 265500, lr = 0.001
I0527 08:59:05.896821 19848 solver.cpp:237] Iteration 265875, loss = 1.13713
I0527 08:59:05.896862 19848 solver.cpp:253]     Train net output #0: loss = 1.13713 (* 1 = 1.13713 loss)
I0527 08:59:05.896877 19848 sgd_solver.cpp:106] Iteration 265875, lr = 0.001
I0527 08:59:15.752732 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_266250.caffemodel
I0527 08:59:15.810106 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_266250.solverstate
I0527 08:59:15.843869 19848 solver.cpp:237] Iteration 266250, loss = 1.11605
I0527 08:59:15.843912 19848 solver.cpp:253]     Train net output #0: loss = 1.11605 (* 1 = 1.11605 loss)
I0527 08:59:15.843930 19848 sgd_solver.cpp:106] Iteration 266250, lr = 0.001
I0527 08:59:25.728081 19848 solver.cpp:237] Iteration 266625, loss = 1.1296
I0527 08:59:25.728266 19848 solver.cpp:253]     Train net output #0: loss = 1.1296 (* 1 = 1.1296 loss)
I0527 08:59:25.728279 19848 sgd_solver.cpp:106] Iteration 266625, lr = 0.001
I0527 08:59:35.609783 19848 solver.cpp:237] Iteration 267000, loss = 1.10994
I0527 08:59:35.609823 19848 solver.cpp:253]     Train net output #0: loss = 1.10994 (* 1 = 1.10994 loss)
I0527 08:59:35.609844 19848 sgd_solver.cpp:106] Iteration 267000, lr = 0.001
I0527 08:59:45.495543 19848 solver.cpp:237] Iteration 267375, loss = 1.10919
I0527 08:59:45.495576 19848 solver.cpp:253]     Train net output #0: loss = 1.10919 (* 1 = 1.10919 loss)
I0527 08:59:45.495591 19848 sgd_solver.cpp:106] Iteration 267375, lr = 0.001
I0527 09:00:16.282315 19848 solver.cpp:237] Iteration 267750, loss = 1.03886
I0527 09:00:16.282511 19848 solver.cpp:253]     Train net output #0: loss = 1.03886 (* 1 = 1.03886 loss)
I0527 09:00:16.282527 19848 sgd_solver.cpp:106] Iteration 267750, lr = 0.001
I0527 09:00:26.167034 19848 solver.cpp:237] Iteration 268125, loss = 1.42236
I0527 09:00:26.167078 19848 solver.cpp:253]     Train net output #0: loss = 1.42236 (* 1 = 1.42236 loss)
I0527 09:00:26.167093 19848 sgd_solver.cpp:106] Iteration 268125, lr = 0.001
I0527 09:00:36.047557 19848 solver.cpp:237] Iteration 268500, loss = 1.11502
I0527 09:00:36.047593 19848 solver.cpp:253]     Train net output #0: loss = 1.11502 (* 1 = 1.11502 loss)
I0527 09:00:36.047608 19848 sgd_solver.cpp:106] Iteration 268500, lr = 0.001
I0527 09:00:45.926662 19848 solver.cpp:237] Iteration 268875, loss = 1.08737
I0527 09:00:45.926723 19848 solver.cpp:253]     Train net output #0: loss = 1.08737 (* 1 = 1.08737 loss)
I0527 09:00:45.926738 19848 sgd_solver.cpp:106] Iteration 268875, lr = 0.001
I0527 09:00:55.806252 19848 solver.cpp:237] Iteration 269250, loss = 1.14206
I0527 09:00:55.806416 19848 solver.cpp:253]     Train net output #0: loss = 1.14206 (* 1 = 1.14206 loss)
I0527 09:00:55.806429 19848 sgd_solver.cpp:106] Iteration 269250, lr = 0.001
I0527 09:01:05.689473 19848 solver.cpp:237] Iteration 269625, loss = 1.14654
I0527 09:01:05.689507 19848 solver.cpp:253]     Train net output #0: loss = 1.14654 (* 1 = 1.14654 loss)
I0527 09:01:05.689522 19848 sgd_solver.cpp:106] Iteration 269625, lr = 0.001
I0527 09:01:15.542569 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_270000.caffemodel
I0527 09:01:15.599545 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_270000.solverstate
I0527 09:01:15.625349 19848 solver.cpp:341] Iteration 270000, Testing net (#0)
I0527 09:02:24.928536 19848 solver.cpp:409]     Test net output #0: accuracy = 0.900432
I0527 09:02:24.928715 19848 solver.cpp:409]     Test net output #1: loss = 0.310717 (* 1 = 0.310717 loss)
I0527 09:02:45.791280 19848 solver.cpp:237] Iteration 270000, loss = 1.04753
I0527 09:02:45.791333 19848 solver.cpp:253]     Train net output #0: loss = 1.04753 (* 1 = 1.04753 loss)
I0527 09:02:45.791347 19848 sgd_solver.cpp:106] Iteration 270000, lr = 0.001
I0527 09:02:55.660796 19848 solver.cpp:237] Iteration 270375, loss = 1.04523
I0527 09:02:55.660971 19848 solver.cpp:253]     Train net output #0: loss = 1.04523 (* 1 = 1.04523 loss)
I0527 09:02:55.660985 19848 sgd_solver.cpp:106] Iteration 270375, lr = 0.001
I0527 09:03:05.542315 19848 solver.cpp:237] Iteration 270750, loss = 1.01694
I0527 09:03:05.542351 19848 solver.cpp:253]     Train net output #0: loss = 1.01694 (* 1 = 1.01694 loss)
I0527 09:03:05.542364 19848 sgd_solver.cpp:106] Iteration 270750, lr = 0.001
I0527 09:03:15.413501 19848 solver.cpp:237] Iteration 271125, loss = 1.04891
I0527 09:03:15.413547 19848 solver.cpp:253]     Train net output #0: loss = 1.04891 (* 1 = 1.04891 loss)
I0527 09:03:15.413563 19848 sgd_solver.cpp:106] Iteration 271125, lr = 0.001
I0527 09:03:25.282987 19848 solver.cpp:237] Iteration 271500, loss = 1.16035
I0527 09:03:25.283022 19848 solver.cpp:253]     Train net output #0: loss = 1.16035 (* 1 = 1.16035 loss)
I0527 09:03:25.283036 19848 sgd_solver.cpp:106] Iteration 271500, lr = 0.001
I0527 09:03:35.157799 19848 solver.cpp:237] Iteration 271875, loss = 0.981192
I0527 09:03:35.157974 19848 solver.cpp:253]     Train net output #0: loss = 0.981193 (* 1 = 0.981193 loss)
I0527 09:03:35.157990 19848 sgd_solver.cpp:106] Iteration 271875, lr = 0.001
I0527 09:03:45.026029 19848 solver.cpp:237] Iteration 272250, loss = 0.952037
I0527 09:03:45.026079 19848 solver.cpp:253]     Train net output #0: loss = 0.952037 (* 1 = 0.952037 loss)
I0527 09:03:45.026095 19848 sgd_solver.cpp:106] Iteration 272250, lr = 0.001
I0527 09:04:15.748967 19848 solver.cpp:237] Iteration 272625, loss = 1.37524
I0527 09:04:15.749155 19848 solver.cpp:253]     Train net output #0: loss = 1.37524 (* 1 = 1.37524 loss)
I0527 09:04:15.749171 19848 sgd_solver.cpp:106] Iteration 272625, lr = 0.001
I0527 09:04:25.622792 19848 solver.cpp:237] Iteration 273000, loss = 1.27455
I0527 09:04:25.622826 19848 solver.cpp:253]     Train net output #0: loss = 1.27455 (* 1 = 1.27455 loss)
I0527 09:04:25.622840 19848 sgd_solver.cpp:106] Iteration 273000, lr = 0.001
I0527 09:04:35.501482 19848 solver.cpp:237] Iteration 273375, loss = 1.24394
I0527 09:04:35.501528 19848 solver.cpp:253]     Train net output #0: loss = 1.24394 (* 1 = 1.24394 loss)
I0527 09:04:35.501540 19848 sgd_solver.cpp:106] Iteration 273375, lr = 0.001
I0527 09:04:45.350692 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_273750.caffemodel
I0527 09:04:45.410456 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_273750.solverstate
I0527 09:04:45.446544 19848 solver.cpp:237] Iteration 273750, loss = 1.4311
I0527 09:04:45.446593 19848 solver.cpp:253]     Train net output #0: loss = 1.4311 (* 1 = 1.4311 loss)
I0527 09:04:45.446609 19848 sgd_solver.cpp:106] Iteration 273750, lr = 0.001
I0527 09:04:55.328114 19848 solver.cpp:237] Iteration 274125, loss = 0.991444
I0527 09:04:55.328294 19848 solver.cpp:253]     Train net output #0: loss = 0.991444 (* 1 = 0.991444 loss)
I0527 09:04:55.328307 19848 sgd_solver.cpp:106] Iteration 274125, lr = 0.001
I0527 09:05:05.209681 19848 solver.cpp:237] Iteration 274500, loss = 1.2133
I0527 09:05:05.209714 19848 solver.cpp:253]     Train net output #0: loss = 1.2133 (* 1 = 1.2133 loss)
I0527 09:05:05.209728 19848 sgd_solver.cpp:106] Iteration 274500, lr = 0.001
I0527 09:05:15.088356 19848 solver.cpp:237] Iteration 274875, loss = 1.16632
I0527 09:05:15.088392 19848 solver.cpp:253]     Train net output #0: loss = 1.16632 (* 1 = 1.16632 loss)
I0527 09:05:15.088405 19848 sgd_solver.cpp:106] Iteration 274875, lr = 0.001
I0527 09:05:45.833027 19848 solver.cpp:237] Iteration 275250, loss = 0.912093
I0527 09:05:45.833212 19848 solver.cpp:253]     Train net output #0: loss = 0.912093 (* 1 = 0.912093 loss)
I0527 09:05:45.833228 19848 sgd_solver.cpp:106] Iteration 275250, lr = 0.001
I0527 09:05:55.702855 19848 solver.cpp:237] Iteration 275625, loss = 1.54202
I0527 09:05:55.702890 19848 solver.cpp:253]     Train net output #0: loss = 1.54202 (* 1 = 1.54202 loss)
I0527 09:05:55.702904 19848 sgd_solver.cpp:106] Iteration 275625, lr = 0.001
I0527 09:06:05.572865 19848 solver.cpp:237] Iteration 276000, loss = 0.978366
I0527 09:06:05.572901 19848 solver.cpp:253]     Train net output #0: loss = 0.978366 (* 1 = 0.978366 loss)
I0527 09:06:05.572917 19848 sgd_solver.cpp:106] Iteration 276000, lr = 0.001
I0527 09:06:15.448143 19848 solver.cpp:237] Iteration 276375, loss = 1.16713
I0527 09:06:15.448185 19848 solver.cpp:253]     Train net output #0: loss = 1.16713 (* 1 = 1.16713 loss)
I0527 09:06:15.448202 19848 sgd_solver.cpp:106] Iteration 276375, lr = 0.001
I0527 09:06:25.324090 19848 solver.cpp:237] Iteration 276750, loss = 1.44449
I0527 09:06:25.324265 19848 solver.cpp:253]     Train net output #0: loss = 1.44449 (* 1 = 1.44449 loss)
I0527 09:06:25.324280 19848 sgd_solver.cpp:106] Iteration 276750, lr = 0.001
I0527 09:06:35.202291 19848 solver.cpp:237] Iteration 277125, loss = 1.50841
I0527 09:06:35.202334 19848 solver.cpp:253]     Train net output #0: loss = 1.50841 (* 1 = 1.50841 loss)
I0527 09:06:35.202353 19848 sgd_solver.cpp:106] Iteration 277125, lr = 0.001
I0527 09:06:45.048678 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_277500.caffemodel
I0527 09:06:45.107807 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_277500.solverstate
I0527 09:06:45.135304 19848 solver.cpp:341] Iteration 277500, Testing net (#0)
I0527 09:07:33.364215 19848 solver.cpp:409]     Test net output #0: accuracy = 0.898993
I0527 09:07:33.364399 19848 solver.cpp:409]     Test net output #1: loss = 0.324868 (* 1 = 0.324868 loss)
I0527 09:07:54.256044 19848 solver.cpp:237] Iteration 277500, loss = 1.08537
I0527 09:07:54.256098 19848 solver.cpp:253]     Train net output #0: loss = 1.08537 (* 1 = 1.08537 loss)
I0527 09:07:54.256111 19848 sgd_solver.cpp:106] Iteration 277500, lr = 0.001
I0527 09:08:03.991811 19848 solver.cpp:237] Iteration 277875, loss = 1.01573
I0527 09:08:03.991981 19848 solver.cpp:253]     Train net output #0: loss = 1.01573 (* 1 = 1.01573 loss)
I0527 09:08:03.991996 19848 sgd_solver.cpp:106] Iteration 277875, lr = 0.001
I0527 09:08:13.723614 19848 solver.cpp:237] Iteration 278250, loss = 1.19915
I0527 09:08:13.723657 19848 solver.cpp:253]     Train net output #0: loss = 1.19916 (* 1 = 1.19916 loss)
I0527 09:08:13.723675 19848 sgd_solver.cpp:106] Iteration 278250, lr = 0.001
I0527 09:08:23.436947 19848 solver.cpp:237] Iteration 278625, loss = 0.897195
I0527 09:08:23.436985 19848 solver.cpp:253]     Train net output #0: loss = 0.897195 (* 1 = 0.897195 loss)
I0527 09:08:23.437000 19848 sgd_solver.cpp:106] Iteration 278625, lr = 0.001
I0527 09:08:33.138552 19848 solver.cpp:237] Iteration 279000, loss = 1.11109
I0527 09:08:33.138588 19848 solver.cpp:253]     Train net output #0: loss = 1.11109 (* 1 = 1.11109 loss)
I0527 09:08:33.138602 19848 sgd_solver.cpp:106] Iteration 279000, lr = 0.001
I0527 09:08:42.847355 19848 solver.cpp:237] Iteration 279375, loss = 0.994745
I0527 09:08:42.847537 19848 solver.cpp:253]     Train net output #0: loss = 0.994745 (* 1 = 0.994745 loss)
I0527 09:08:42.847551 19848 sgd_solver.cpp:106] Iteration 279375, lr = 0.001
I0527 09:08:52.542876 19848 solver.cpp:237] Iteration 279750, loss = 1.05432
I0527 09:08:52.542911 19848 solver.cpp:253]     Train net output #0: loss = 1.05432 (* 1 = 1.05432 loss)
I0527 09:08:52.542927 19848 sgd_solver.cpp:106] Iteration 279750, lr = 0.001
I0527 09:09:23.145325 19848 solver.cpp:237] Iteration 280125, loss = 1.16083
I0527 09:09:23.145510 19848 solver.cpp:253]     Train net output #0: loss = 1.16083 (* 1 = 1.16083 loss)
I0527 09:09:23.145525 19848 sgd_solver.cpp:106] Iteration 280125, lr = 0.001
I0527 09:09:32.857867 19848 solver.cpp:237] Iteration 280500, loss = 1.19828
I0527 09:09:32.857913 19848 solver.cpp:253]     Train net output #0: loss = 1.19828 (* 1 = 1.19828 loss)
I0527 09:09:32.857933 19848 sgd_solver.cpp:106] Iteration 280500, lr = 0.001
I0527 09:09:42.563184 19848 solver.cpp:237] Iteration 280875, loss = 1.74857
I0527 09:09:42.563220 19848 solver.cpp:253]     Train net output #0: loss = 1.74857 (* 1 = 1.74857 loss)
I0527 09:09:42.563237 19848 sgd_solver.cpp:106] Iteration 280875, lr = 0.001
I0527 09:09:52.241435 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_281250.caffemodel
I0527 09:09:52.298120 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_281250.solverstate
I0527 09:09:52.331796 19848 solver.cpp:237] Iteration 281250, loss = 1.09394
I0527 09:09:52.331836 19848 solver.cpp:253]     Train net output #0: loss = 1.09394 (* 1 = 1.09394 loss)
I0527 09:09:52.331859 19848 sgd_solver.cpp:106] Iteration 281250, lr = 0.001
I0527 09:10:02.043728 19848 solver.cpp:237] Iteration 281625, loss = 1.21168
I0527 09:10:02.043907 19848 solver.cpp:253]     Train net output #0: loss = 1.21168 (* 1 = 1.21168 loss)
I0527 09:10:02.043922 19848 sgd_solver.cpp:106] Iteration 281625, lr = 0.001
I0527 09:10:11.751066 19848 solver.cpp:237] Iteration 282000, loss = 1.01253
I0527 09:10:11.751101 19848 solver.cpp:253]     Train net output #0: loss = 1.01253 (* 1 = 1.01253 loss)
I0527 09:10:11.751119 19848 sgd_solver.cpp:106] Iteration 282000, lr = 0.001
I0527 09:10:21.457583 19848 solver.cpp:237] Iteration 282375, loss = 1.06236
I0527 09:10:21.457625 19848 solver.cpp:253]     Train net output #0: loss = 1.06236 (* 1 = 1.06236 loss)
I0527 09:10:21.457643 19848 sgd_solver.cpp:106] Iteration 282375, lr = 0.001
I0527 09:10:52.031035 19848 solver.cpp:237] Iteration 282750, loss = 0.87645
I0527 09:10:52.031226 19848 solver.cpp:253]     Train net output #0: loss = 0.876451 (* 1 = 0.876451 loss)
I0527 09:10:52.031241 19848 sgd_solver.cpp:106] Iteration 282750, lr = 0.001
I0527 09:11:01.732293 19848 solver.cpp:237] Iteration 283125, loss = 1.08688
I0527 09:11:01.732327 19848 solver.cpp:253]     Train net output #0: loss = 1.08688 (* 1 = 1.08688 loss)
I0527 09:11:01.732342 19848 sgd_solver.cpp:106] Iteration 283125, lr = 0.001
I0527 09:11:11.435724 19848 solver.cpp:237] Iteration 283500, loss = 1.10734
I0527 09:11:11.435773 19848 solver.cpp:253]     Train net output #0: loss = 1.10734 (* 1 = 1.10734 loss)
I0527 09:11:11.435787 19848 sgd_solver.cpp:106] Iteration 283500, lr = 0.001
I0527 09:11:21.143407 19848 solver.cpp:237] Iteration 283875, loss = 1.23011
I0527 09:11:21.143443 19848 solver.cpp:253]     Train net output #0: loss = 1.23011 (* 1 = 1.23011 loss)
I0527 09:11:21.143457 19848 sgd_solver.cpp:106] Iteration 283875, lr = 0.001
I0527 09:11:30.847642 19848 solver.cpp:237] Iteration 284250, loss = 1.22662
I0527 09:11:30.847810 19848 solver.cpp:253]     Train net output #0: loss = 1.22662 (* 1 = 1.22662 loss)
I0527 09:11:30.847823 19848 sgd_solver.cpp:106] Iteration 284250, lr = 0.001
I0527 09:11:40.553267 19848 solver.cpp:237] Iteration 284625, loss = 1.12206
I0527 09:11:40.553313 19848 solver.cpp:253]     Train net output #0: loss = 1.12206 (* 1 = 1.12206 loss)
I0527 09:11:40.553326 19848 sgd_solver.cpp:106] Iteration 284625, lr = 0.001
I0527 09:11:50.232767 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_285000.caffemodel
I0527 09:11:50.288655 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_285000.solverstate
I0527 09:11:50.314134 19848 solver.cpp:341] Iteration 285000, Testing net (#0)
I0527 09:12:59.778446 19848 solver.cpp:409]     Test net output #0: accuracy = 0.897734
I0527 09:12:59.778633 19848 solver.cpp:409]     Test net output #1: loss = 0.311532 (* 1 = 0.311532 loss)
I0527 09:13:20.665750 19848 solver.cpp:237] Iteration 285000, loss = 0.955773
I0527 09:13:20.665802 19848 solver.cpp:253]     Train net output #0: loss = 0.955773 (* 1 = 0.955773 loss)
I0527 09:13:20.665819 19848 sgd_solver.cpp:106] Iteration 285000, lr = 0.001
I0527 09:13:30.587771 19848 solver.cpp:237] Iteration 285375, loss = 1.30953
I0527 09:13:30.587941 19848 solver.cpp:253]     Train net output #0: loss = 1.30953 (* 1 = 1.30953 loss)
I0527 09:13:30.587955 19848 sgd_solver.cpp:106] Iteration 285375, lr = 0.001
I0527 09:13:40.519279 19848 solver.cpp:237] Iteration 285750, loss = 1.04394
I0527 09:13:40.519326 19848 solver.cpp:253]     Train net output #0: loss = 1.04394 (* 1 = 1.04394 loss)
I0527 09:13:40.519343 19848 sgd_solver.cpp:106] Iteration 285750, lr = 0.001
I0527 09:13:50.447695 19848 solver.cpp:237] Iteration 286125, loss = 1.25968
I0527 09:13:50.447731 19848 solver.cpp:253]     Train net output #0: loss = 1.25968 (* 1 = 1.25968 loss)
I0527 09:13:50.447744 19848 sgd_solver.cpp:106] Iteration 286125, lr = 0.001
I0527 09:14:00.376674 19848 solver.cpp:237] Iteration 286500, loss = 0.995081
I0527 09:14:00.376711 19848 solver.cpp:253]     Train net output #0: loss = 0.995081 (* 1 = 0.995081 loss)
I0527 09:14:00.376724 19848 sgd_solver.cpp:106] Iteration 286500, lr = 0.001
I0527 09:14:10.300079 19848 solver.cpp:237] Iteration 286875, loss = 1.40522
I0527 09:14:10.300268 19848 solver.cpp:253]     Train net output #0: loss = 1.40522 (* 1 = 1.40522 loss)
I0527 09:14:10.300282 19848 sgd_solver.cpp:106] Iteration 286875, lr = 0.001
I0527 09:14:20.224243 19848 solver.cpp:237] Iteration 287250, loss = 1.08474
I0527 09:14:20.224277 19848 solver.cpp:253]     Train net output #0: loss = 1.08474 (* 1 = 1.08474 loss)
I0527 09:14:20.224292 19848 sgd_solver.cpp:106] Iteration 287250, lr = 0.001
I0527 09:14:51.045959 19848 solver.cpp:237] Iteration 287625, loss = 1.1203
I0527 09:14:51.046150 19848 solver.cpp:253]     Train net output #0: loss = 1.1203 (* 1 = 1.1203 loss)
I0527 09:14:51.046166 19848 sgd_solver.cpp:106] Iteration 287625, lr = 0.001
I0527 09:15:00.965481 19848 solver.cpp:237] Iteration 288000, loss = 1.02231
I0527 09:15:00.965525 19848 solver.cpp:253]     Train net output #0: loss = 1.02231 (* 1 = 1.02231 loss)
I0527 09:15:00.965540 19848 sgd_solver.cpp:106] Iteration 288000, lr = 0.001
I0527 09:15:10.890321 19848 solver.cpp:237] Iteration 288375, loss = 0.906452
I0527 09:15:10.890357 19848 solver.cpp:253]     Train net output #0: loss = 0.906452 (* 1 = 0.906452 loss)
I0527 09:15:10.890373 19848 sgd_solver.cpp:106] Iteration 288375, lr = 0.001
I0527 09:15:20.787982 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_288750.caffemodel
I0527 09:15:20.844493 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_288750.solverstate
I0527 09:15:20.877966 19848 solver.cpp:237] Iteration 288750, loss = 1.08248
I0527 09:15:20.878011 19848 solver.cpp:253]     Train net output #0: loss = 1.08248 (* 1 = 1.08248 loss)
I0527 09:15:20.878029 19848 sgd_solver.cpp:106] Iteration 288750, lr = 0.001
I0527 09:15:30.816781 19848 solver.cpp:237] Iteration 289125, loss = 0.926025
I0527 09:15:30.816952 19848 solver.cpp:253]     Train net output #0: loss = 0.926025 (* 1 = 0.926025 loss)
I0527 09:15:30.816967 19848 sgd_solver.cpp:106] Iteration 289125, lr = 0.001
I0527 09:15:40.747995 19848 solver.cpp:237] Iteration 289500, loss = 0.847791
I0527 09:15:40.748031 19848 solver.cpp:253]     Train net output #0: loss = 0.847791 (* 1 = 0.847791 loss)
I0527 09:15:40.748049 19848 sgd_solver.cpp:106] Iteration 289500, lr = 0.001
I0527 09:15:50.675484 19848 solver.cpp:237] Iteration 289875, loss = 0.789383
I0527 09:15:50.675525 19848 solver.cpp:253]     Train net output #0: loss = 0.789383 (* 1 = 0.789383 loss)
I0527 09:15:50.675546 19848 sgd_solver.cpp:106] Iteration 289875, lr = 0.001
I0527 09:16:21.494431 19848 solver.cpp:237] Iteration 290250, loss = 1.07346
I0527 09:16:21.494629 19848 solver.cpp:253]     Train net output #0: loss = 1.07346 (* 1 = 1.07346 loss)
I0527 09:16:21.494645 19848 sgd_solver.cpp:106] Iteration 290250, lr = 0.001
I0527 09:16:31.422782 19848 solver.cpp:237] Iteration 290625, loss = 1.26493
I0527 09:16:31.422817 19848 solver.cpp:253]     Train net output #0: loss = 1.26493 (* 1 = 1.26493 loss)
I0527 09:16:31.422832 19848 sgd_solver.cpp:106] Iteration 290625, lr = 0.001
I0527 09:16:41.348646 19848 solver.cpp:237] Iteration 291000, loss = 1.16504
I0527 09:16:41.348692 19848 solver.cpp:253]     Train net output #0: loss = 1.16504 (* 1 = 1.16504 loss)
I0527 09:16:41.348707 19848 sgd_solver.cpp:106] Iteration 291000, lr = 0.001
I0527 09:16:51.275815 19848 solver.cpp:237] Iteration 291375, loss = 0.899837
I0527 09:16:51.275852 19848 solver.cpp:253]     Train net output #0: loss = 0.899837 (* 1 = 0.899837 loss)
I0527 09:16:51.275866 19848 sgd_solver.cpp:106] Iteration 291375, lr = 0.001
I0527 09:17:01.205612 19848 solver.cpp:237] Iteration 291750, loss = 1.09856
I0527 09:17:01.205802 19848 solver.cpp:253]     Train net output #0: loss = 1.09856 (* 1 = 1.09856 loss)
I0527 09:17:01.205817 19848 sgd_solver.cpp:106] Iteration 291750, lr = 0.001
I0527 09:17:11.126912 19848 solver.cpp:237] Iteration 292125, loss = 0.872461
I0527 09:17:11.126948 19848 solver.cpp:253]     Train net output #0: loss = 0.872461 (* 1 = 0.872461 loss)
I0527 09:17:11.126963 19848 sgd_solver.cpp:106] Iteration 292125, lr = 0.001
I0527 09:17:21.023277 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_292500.caffemodel
I0527 09:17:21.080263 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_292500.solverstate
I0527 09:17:21.105875 19848 solver.cpp:341] Iteration 292500, Testing net (#0)
I0527 09:18:09.680009 19848 solver.cpp:409]     Test net output #0: accuracy = 0.900298
I0527 09:18:09.680197 19848 solver.cpp:409]     Test net output #1: loss = 0.324324 (* 1 = 0.324324 loss)
I0527 09:18:30.580677 19848 solver.cpp:237] Iteration 292500, loss = 1.02237
I0527 09:18:30.580730 19848 solver.cpp:253]     Train net output #0: loss = 1.02237 (* 1 = 1.02237 loss)
I0527 09:18:30.580746 19848 sgd_solver.cpp:106] Iteration 292500, lr = 0.001
I0527 09:18:40.310212 19848 solver.cpp:237] Iteration 292875, loss = 1.24146
I0527 09:18:40.310395 19848 solver.cpp:253]     Train net output #0: loss = 1.24146 (* 1 = 1.24146 loss)
I0527 09:18:40.310410 19848 sgd_solver.cpp:106] Iteration 292875, lr = 0.001
I0527 09:18:50.034237 19848 solver.cpp:237] Iteration 293250, loss = 1.47073
I0527 09:18:50.034273 19848 solver.cpp:253]     Train net output #0: loss = 1.47073 (* 1 = 1.47073 loss)
I0527 09:18:50.034286 19848 sgd_solver.cpp:106] Iteration 293250, lr = 0.001
I0527 09:18:59.762259 19848 solver.cpp:237] Iteration 293625, loss = 1.05656
I0527 09:18:59.762293 19848 solver.cpp:253]     Train net output #0: loss = 1.05656 (* 1 = 1.05656 loss)
I0527 09:18:59.762307 19848 sgd_solver.cpp:106] Iteration 293625, lr = 0.001
I0527 09:19:09.490286 19848 solver.cpp:237] Iteration 294000, loss = 1.06159
I0527 09:19:09.490330 19848 solver.cpp:253]     Train net output #0: loss = 1.06159 (* 1 = 1.06159 loss)
I0527 09:19:09.490346 19848 sgd_solver.cpp:106] Iteration 294000, lr = 0.001
I0527 09:19:19.220228 19848 solver.cpp:237] Iteration 294375, loss = 1.22288
I0527 09:19:19.220398 19848 solver.cpp:253]     Train net output #0: loss = 1.22288 (* 1 = 1.22288 loss)
I0527 09:19:19.220412 19848 sgd_solver.cpp:106] Iteration 294375, lr = 0.001
I0527 09:19:28.949461 19848 solver.cpp:237] Iteration 294750, loss = 1.57073
I0527 09:19:28.949506 19848 solver.cpp:253]     Train net output #0: loss = 1.57073 (* 1 = 1.57073 loss)
I0527 09:19:28.949523 19848 sgd_solver.cpp:106] Iteration 294750, lr = 0.001
I0527 09:19:59.550329 19848 solver.cpp:237] Iteration 295125, loss = 1.0634
I0527 09:19:59.550521 19848 solver.cpp:253]     Train net output #0: loss = 1.0634 (* 1 = 1.0634 loss)
I0527 09:19:59.550537 19848 sgd_solver.cpp:106] Iteration 295125, lr = 0.001
I0527 09:20:09.283535 19848 solver.cpp:237] Iteration 295500, loss = 1.16255
I0527 09:20:09.283568 19848 solver.cpp:253]     Train net output #0: loss = 1.16255 (* 1 = 1.16255 loss)
I0527 09:20:09.283582 19848 sgd_solver.cpp:106] Iteration 295500, lr = 0.001
I0527 09:20:19.009905 19848 solver.cpp:237] Iteration 295875, loss = 0.908769
I0527 09:20:19.009949 19848 solver.cpp:253]     Train net output #0: loss = 0.908769 (* 1 = 0.908769 loss)
I0527 09:20:19.009966 19848 sgd_solver.cpp:106] Iteration 295875, lr = 0.001
I0527 09:20:28.710916 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_296250.caffemodel
I0527 09:20:28.772379 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_296250.solverstate
I0527 09:20:28.808174 19848 solver.cpp:237] Iteration 296250, loss = 1.18015
I0527 09:20:28.808228 19848 solver.cpp:253]     Train net output #0: loss = 1.18015 (* 1 = 1.18015 loss)
I0527 09:20:28.808243 19848 sgd_solver.cpp:106] Iteration 296250, lr = 0.001
I0527 09:20:38.538558 19848 solver.cpp:237] Iteration 296625, loss = 1.12738
I0527 09:20:38.538754 19848 solver.cpp:253]     Train net output #0: loss = 1.12738 (* 1 = 1.12738 loss)
I0527 09:20:38.538769 19848 sgd_solver.cpp:106] Iteration 296625, lr = 0.001
I0527 09:20:48.263211 19848 solver.cpp:237] Iteration 297000, loss = 1.33606
I0527 09:20:48.263255 19848 solver.cpp:253]     Train net output #0: loss = 1.33606 (* 1 = 1.33606 loss)
I0527 09:20:48.263276 19848 sgd_solver.cpp:106] Iteration 297000, lr = 0.001
I0527 09:20:57.989614 19848 solver.cpp:237] Iteration 297375, loss = 1.08111
I0527 09:20:57.989650 19848 solver.cpp:253]     Train net output #0: loss = 1.08111 (* 1 = 1.08111 loss)
I0527 09:20:57.989662 19848 sgd_solver.cpp:106] Iteration 297375, lr = 0.001
I0527 09:21:28.593302 19848 solver.cpp:237] Iteration 297750, loss = 0.887648
I0527 09:21:28.593493 19848 solver.cpp:253]     Train net output #0: loss = 0.887648 (* 1 = 0.887648 loss)
I0527 09:21:28.593509 19848 sgd_solver.cpp:106] Iteration 297750, lr = 0.001
I0527 09:21:38.323087 19848 solver.cpp:237] Iteration 298125, loss = 1.309
I0527 09:21:38.323127 19848 solver.cpp:253]     Train net output #0: loss = 1.309 (* 1 = 1.309 loss)
I0527 09:21:38.323142 19848 sgd_solver.cpp:106] Iteration 298125, lr = 0.001
I0527 09:21:48.050992 19848 solver.cpp:237] Iteration 298500, loss = 1.20814
I0527 09:21:48.051023 19848 solver.cpp:253]     Train net output #0: loss = 1.20814 (* 1 = 1.20814 loss)
I0527 09:21:48.051035 19848 sgd_solver.cpp:106] Iteration 298500, lr = 0.001
I0527 09:21:57.780433 19848 solver.cpp:237] Iteration 298875, loss = 1.37413
I0527 09:21:57.780472 19848 solver.cpp:253]     Train net output #0: loss = 1.37413 (* 1 = 1.37413 loss)
I0527 09:21:57.780485 19848 sgd_solver.cpp:106] Iteration 298875, lr = 0.001
I0527 09:22:07.515158 19848 solver.cpp:237] Iteration 299250, loss = 1.24507
I0527 09:22:07.515326 19848 solver.cpp:253]     Train net output #0: loss = 1.24507 (* 1 = 1.24507 loss)
I0527 09:22:07.515339 19848 sgd_solver.cpp:106] Iteration 299250, lr = 0.001
I0527 09:22:17.241691 19848 solver.cpp:237] Iteration 299625, loss = 0.905294
I0527 09:22:17.241729 19848 solver.cpp:253]     Train net output #0: loss = 0.905294 (* 1 = 0.905294 loss)
I0527 09:22:17.241741 19848 sgd_solver.cpp:106] Iteration 299625, lr = 0.001
I0527 09:22:26.943827 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_300000.caffemodel
I0527 09:22:27.005177 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_300000.solverstate
I0527 09:22:27.036608 19848 solver.cpp:341] Iteration 300000, Testing net (#0)
I0527 09:23:36.504616 19848 solver.cpp:409]     Test net output #0: accuracy = 0.901773
I0527 09:23:36.504817 19848 solver.cpp:409]     Test net output #1: loss = 0.31083 (* 1 = 0.31083 loss)
I0527 09:23:57.390645 19848 solver.cpp:237] Iteration 300000, loss = 0.909844
I0527 09:23:57.390697 19848 solver.cpp:253]     Train net output #0: loss = 0.909844 (* 1 = 0.909844 loss)
I0527 09:23:57.390718 19848 sgd_solver.cpp:106] Iteration 300000, lr = 0.001
I0527 09:24:07.275302 19848 solver.cpp:237] Iteration 300375, loss = 1.12673
I0527 09:24:07.275490 19848 solver.cpp:253]     Train net output #0: loss = 1.12673 (* 1 = 1.12673 loss)
I0527 09:24:07.275504 19848 sgd_solver.cpp:106] Iteration 300375, lr = 0.001
I0527 09:24:17.164314 19848 solver.cpp:237] Iteration 300750, loss = 1.14076
I0527 09:24:17.164347 19848 solver.cpp:253]     Train net output #0: loss = 1.14076 (* 1 = 1.14076 loss)
I0527 09:24:17.164364 19848 sgd_solver.cpp:106] Iteration 300750, lr = 0.001
I0527 09:24:27.045522 19848 solver.cpp:237] Iteration 301125, loss = 1.41395
I0527 09:24:27.045554 19848 solver.cpp:253]     Train net output #0: loss = 1.41395 (* 1 = 1.41395 loss)
I0527 09:24:27.045568 19848 sgd_solver.cpp:106] Iteration 301125, lr = 0.001
I0527 09:24:36.925544 19848 solver.cpp:237] Iteration 301500, loss = 1.43885
I0527 09:24:36.925580 19848 solver.cpp:253]     Train net output #0: loss = 1.43885 (* 1 = 1.43885 loss)
I0527 09:24:36.925595 19848 sgd_solver.cpp:106] Iteration 301500, lr = 0.001
I0527 09:24:46.809871 19848 solver.cpp:237] Iteration 301875, loss = 0.981762
I0527 09:24:46.810044 19848 solver.cpp:253]     Train net output #0: loss = 0.981763 (* 1 = 0.981763 loss)
I0527 09:24:46.810056 19848 sgd_solver.cpp:106] Iteration 301875, lr = 0.001
I0527 09:24:56.703109 19848 solver.cpp:237] Iteration 302250, loss = 1.05934
I0527 09:24:56.703150 19848 solver.cpp:253]     Train net output #0: loss = 1.05934 (* 1 = 1.05934 loss)
I0527 09:24:56.703168 19848 sgd_solver.cpp:106] Iteration 302250, lr = 0.001
I0527 09:25:27.457866 19848 solver.cpp:237] Iteration 302625, loss = 1.00975
I0527 09:25:27.458060 19848 solver.cpp:253]     Train net output #0: loss = 1.00975 (* 1 = 1.00975 loss)
I0527 09:25:27.458076 19848 sgd_solver.cpp:106] Iteration 302625, lr = 0.001
I0527 09:25:37.346683 19848 solver.cpp:237] Iteration 303000, loss = 1.02533
I0527 09:25:37.346722 19848 solver.cpp:253]     Train net output #0: loss = 1.02533 (* 1 = 1.02533 loss)
I0527 09:25:37.346736 19848 sgd_solver.cpp:106] Iteration 303000, lr = 0.001
I0527 09:25:47.227766 19848 solver.cpp:237] Iteration 303375, loss = 1.0971
I0527 09:25:47.227805 19848 solver.cpp:253]     Train net output #0: loss = 1.0971 (* 1 = 1.0971 loss)
I0527 09:25:47.227824 19848 sgd_solver.cpp:106] Iteration 303375, lr = 0.001
I0527 09:25:57.081806 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_303750.caffemodel
I0527 09:25:57.139228 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_303750.solverstate
I0527 09:25:57.173498 19848 solver.cpp:237] Iteration 303750, loss = 1.26126
I0527 09:25:57.173540 19848 solver.cpp:253]     Train net output #0: loss = 1.26126 (* 1 = 1.26126 loss)
I0527 09:25:57.173558 19848 sgd_solver.cpp:106] Iteration 303750, lr = 0.001
I0527 09:26:07.059551 19848 solver.cpp:237] Iteration 304125, loss = 1.23807
I0527 09:26:07.059728 19848 solver.cpp:253]     Train net output #0: loss = 1.23808 (* 1 = 1.23808 loss)
I0527 09:26:07.059742 19848 sgd_solver.cpp:106] Iteration 304125, lr = 0.001
I0527 09:26:16.940335 19848 solver.cpp:237] Iteration 304500, loss = 1.12573
I0527 09:26:16.940371 19848 solver.cpp:253]     Train net output #0: loss = 1.12573 (* 1 = 1.12573 loss)
I0527 09:26:16.940387 19848 sgd_solver.cpp:106] Iteration 304500, lr = 0.001
I0527 09:26:26.821390 19848 solver.cpp:237] Iteration 304875, loss = 1.10213
I0527 09:26:26.821426 19848 solver.cpp:253]     Train net output #0: loss = 1.10213 (* 1 = 1.10213 loss)
I0527 09:26:26.821439 19848 sgd_solver.cpp:106] Iteration 304875, lr = 0.001
I0527 09:26:57.601543 19848 solver.cpp:237] Iteration 305250, loss = 1.07824
I0527 09:26:57.601739 19848 solver.cpp:253]     Train net output #0: loss = 1.07824 (* 1 = 1.07824 loss)
I0527 09:26:57.601754 19848 sgd_solver.cpp:106] Iteration 305250, lr = 0.001
I0527 09:27:07.487360 19848 solver.cpp:237] Iteration 305625, loss = 1.17597
I0527 09:27:07.487396 19848 solver.cpp:253]     Train net output #0: loss = 1.17597 (* 1 = 1.17597 loss)
I0527 09:27:07.487411 19848 sgd_solver.cpp:106] Iteration 305625, lr = 0.001
I0527 09:27:17.370846 19848 solver.cpp:237] Iteration 306000, loss = 1.09008
I0527 09:27:17.370883 19848 solver.cpp:253]     Train net output #0: loss = 1.09008 (* 1 = 1.09008 loss)
I0527 09:27:17.370898 19848 sgd_solver.cpp:106] Iteration 306000, lr = 0.001
I0527 09:27:27.262836 19848 solver.cpp:237] Iteration 306375, loss = 0.924966
I0527 09:27:27.262881 19848 solver.cpp:253]     Train net output #0: loss = 0.924966 (* 1 = 0.924966 loss)
I0527 09:27:27.262897 19848 sgd_solver.cpp:106] Iteration 306375, lr = 0.001
I0527 09:27:37.145099 19848 solver.cpp:237] Iteration 306750, loss = 1.321
I0527 09:27:37.145270 19848 solver.cpp:253]     Train net output #0: loss = 1.321 (* 1 = 1.321 loss)
I0527 09:27:37.145284 19848 sgd_solver.cpp:106] Iteration 306750, lr = 0.001
I0527 09:27:47.039218 19848 solver.cpp:237] Iteration 307125, loss = 1.14291
I0527 09:27:47.039252 19848 solver.cpp:253]     Train net output #0: loss = 1.14291 (* 1 = 1.14291 loss)
I0527 09:27:47.039268 19848 sgd_solver.cpp:106] Iteration 307125, lr = 0.001
I0527 09:27:56.899827 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_307500.caffemodel
I0527 09:27:56.957160 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_307500.solverstate
I0527 09:27:56.983415 19848 solver.cpp:341] Iteration 307500, Testing net (#0)
I0527 09:28:45.213821 19848 solver.cpp:409]     Test net output #0: accuracy = 0.898592
I0527 09:28:45.214021 19848 solver.cpp:409]     Test net output #1: loss = 0.316142 (* 1 = 0.316142 loss)
I0527 09:29:06.100968 19848 solver.cpp:237] Iteration 307500, loss = 1.28084
I0527 09:29:06.101021 19848 solver.cpp:253]     Train net output #0: loss = 1.28084 (* 1 = 1.28084 loss)
I0527 09:29:06.101037 19848 sgd_solver.cpp:106] Iteration 307500, lr = 0.001
I0527 09:29:15.807390 19848 solver.cpp:237] Iteration 307875, loss = 1.10124
I0527 09:29:15.807569 19848 solver.cpp:253]     Train net output #0: loss = 1.10124 (* 1 = 1.10124 loss)
I0527 09:29:15.807582 19848 sgd_solver.cpp:106] Iteration 307875, lr = 0.001
I0527 09:29:25.514726 19848 solver.cpp:237] Iteration 308250, loss = 0.946742
I0527 09:29:25.514762 19848 solver.cpp:253]     Train net output #0: loss = 0.946743 (* 1 = 0.946743 loss)
I0527 09:29:25.514775 19848 sgd_solver.cpp:106] Iteration 308250, lr = 0.001
I0527 09:29:35.222882 19848 solver.cpp:237] Iteration 308625, loss = 1.0157
I0527 09:29:35.222924 19848 solver.cpp:253]     Train net output #0: loss = 1.0157 (* 1 = 1.0157 loss)
I0527 09:29:35.222939 19848 sgd_solver.cpp:106] Iteration 308625, lr = 0.001
I0527 09:29:44.932159 19848 solver.cpp:237] Iteration 309000, loss = 0.917327
I0527 09:29:44.932196 19848 solver.cpp:253]     Train net output #0: loss = 0.917328 (* 1 = 0.917328 loss)
I0527 09:29:44.932212 19848 sgd_solver.cpp:106] Iteration 309000, lr = 0.001
I0527 09:29:54.633100 19848 solver.cpp:237] Iteration 309375, loss = 1.22418
I0527 09:29:54.633285 19848 solver.cpp:253]     Train net output #0: loss = 1.22418 (* 1 = 1.22418 loss)
I0527 09:29:54.633299 19848 sgd_solver.cpp:106] Iteration 309375, lr = 0.001
I0527 09:30:04.339653 19848 solver.cpp:237] Iteration 309750, loss = 0.997669
I0527 09:30:04.339689 19848 solver.cpp:253]     Train net output #0: loss = 0.997669 (* 1 = 0.997669 loss)
I0527 09:30:04.339705 19848 sgd_solver.cpp:106] Iteration 309750, lr = 0.001
I0527 09:30:34.922025 19848 solver.cpp:237] Iteration 310125, loss = 1.0922
I0527 09:30:34.922225 19848 solver.cpp:253]     Train net output #0: loss = 1.0922 (* 1 = 1.0922 loss)
I0527 09:30:34.922240 19848 sgd_solver.cpp:106] Iteration 310125, lr = 0.001
I0527 09:30:44.627068 19848 solver.cpp:237] Iteration 310500, loss = 1.13936
I0527 09:30:44.627107 19848 solver.cpp:253]     Train net output #0: loss = 1.13936 (* 1 = 1.13936 loss)
I0527 09:30:44.627130 19848 sgd_solver.cpp:106] Iteration 310500, lr = 0.001
I0527 09:30:54.326602 19848 solver.cpp:237] Iteration 310875, loss = 1.60583
I0527 09:30:54.326637 19848 solver.cpp:253]     Train net output #0: loss = 1.60583 (* 1 = 1.60583 loss)
I0527 09:30:54.326650 19848 sgd_solver.cpp:106] Iteration 310875, lr = 0.001
I0527 09:31:04.005709 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_311250.caffemodel
I0527 09:31:04.062108 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_311250.solverstate
I0527 09:31:04.095566 19848 solver.cpp:237] Iteration 311250, loss = 1.17644
I0527 09:31:04.095608 19848 solver.cpp:253]     Train net output #0: loss = 1.17644 (* 1 = 1.17644 loss)
I0527 09:31:04.095625 19848 sgd_solver.cpp:106] Iteration 311250, lr = 0.001
I0527 09:31:13.809048 19848 solver.cpp:237] Iteration 311625, loss = 1.05274
I0527 09:31:13.809237 19848 solver.cpp:253]     Train net output #0: loss = 1.05274 (* 1 = 1.05274 loss)
I0527 09:31:13.809252 19848 sgd_solver.cpp:106] Iteration 311625, lr = 0.001
I0527 09:31:23.513278 19848 solver.cpp:237] Iteration 312000, loss = 1.55045
I0527 09:31:23.513312 19848 solver.cpp:253]     Train net output #0: loss = 1.55045 (* 1 = 1.55045 loss)
I0527 09:31:23.513326 19848 sgd_solver.cpp:106] Iteration 312000, lr = 0.001
I0527 09:31:33.227589 19848 solver.cpp:237] Iteration 312375, loss = 1.31207
I0527 09:31:33.227632 19848 solver.cpp:253]     Train net output #0: loss = 1.31207 (* 1 = 1.31207 loss)
I0527 09:31:33.227649 19848 sgd_solver.cpp:106] Iteration 312375, lr = 0.001
I0527 09:32:03.841228 19848 solver.cpp:237] Iteration 312750, loss = 1.01603
I0527 09:32:03.841423 19848 solver.cpp:253]     Train net output #0: loss = 1.01603 (* 1 = 1.01603 loss)
I0527 09:32:03.841439 19848 sgd_solver.cpp:106] Iteration 312750, lr = 0.001
I0527 09:32:13.541823 19848 solver.cpp:237] Iteration 313125, loss = 1.15454
I0527 09:32:13.541858 19848 solver.cpp:253]     Train net output #0: loss = 1.15454 (* 1 = 1.15454 loss)
I0527 09:32:13.541875 19848 sgd_solver.cpp:106] Iteration 313125, lr = 0.001
I0527 09:32:23.244624 19848 solver.cpp:237] Iteration 313500, loss = 1.0689
I0527 09:32:23.244668 19848 solver.cpp:253]     Train net output #0: loss = 1.0689 (* 1 = 1.0689 loss)
I0527 09:32:23.244686 19848 sgd_solver.cpp:106] Iteration 313500, lr = 0.001
I0527 09:32:32.956554 19848 solver.cpp:237] Iteration 313875, loss = 1.22955
I0527 09:32:32.956589 19848 solver.cpp:253]     Train net output #0: loss = 1.22955 (* 1 = 1.22955 loss)
I0527 09:32:32.956606 19848 sgd_solver.cpp:106] Iteration 313875, lr = 0.001
I0527 09:32:42.658721 19848 solver.cpp:237] Iteration 314250, loss = 1.04538
I0527 09:32:42.658895 19848 solver.cpp:253]     Train net output #0: loss = 1.04538 (* 1 = 1.04538 loss)
I0527 09:32:42.658908 19848 sgd_solver.cpp:106] Iteration 314250, lr = 0.001
I0527 09:32:52.360949 19848 solver.cpp:237] Iteration 314625, loss = 1.37447
I0527 09:32:52.360996 19848 solver.cpp:253]     Train net output #0: loss = 1.37447 (* 1 = 1.37447 loss)
I0527 09:32:52.361012 19848 sgd_solver.cpp:106] Iteration 314625, lr = 0.001
I0527 09:33:02.044769 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_315000.caffemodel
I0527 09:33:02.105242 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_315000.solverstate
I0527 09:33:02.132805 19848 solver.cpp:341] Iteration 315000, Testing net (#0)
I0527 09:34:11.502430 19848 solver.cpp:409]     Test net output #0: accuracy = 0.901992
I0527 09:34:11.502637 19848 solver.cpp:409]     Test net output #1: loss = 0.310791 (* 1 = 0.310791 loss)
I0527 09:34:32.366526 19848 solver.cpp:237] Iteration 315000, loss = 1.14982
I0527 09:34:32.366580 19848 solver.cpp:253]     Train net output #0: loss = 1.14982 (* 1 = 1.14982 loss)
I0527 09:34:32.366596 19848 sgd_solver.cpp:106] Iteration 315000, lr = 0.001
I0527 09:34:42.291823 19848 solver.cpp:237] Iteration 315375, loss = 1.15168
I0527 09:34:42.292004 19848 solver.cpp:253]     Train net output #0: loss = 1.15168 (* 1 = 1.15168 loss)
I0527 09:34:42.292018 19848 sgd_solver.cpp:106] Iteration 315375, lr = 0.001
I0527 09:34:52.221827 19848 solver.cpp:237] Iteration 315750, loss = 1.09283
I0527 09:34:52.221873 19848 solver.cpp:253]     Train net output #0: loss = 1.09283 (* 1 = 1.09283 loss)
I0527 09:34:52.221887 19848 sgd_solver.cpp:106] Iteration 315750, lr = 0.001
I0527 09:35:02.146868 19848 solver.cpp:237] Iteration 316125, loss = 0.838306
I0527 09:35:02.146905 19848 solver.cpp:253]     Train net output #0: loss = 0.838306 (* 1 = 0.838306 loss)
I0527 09:35:02.146920 19848 sgd_solver.cpp:106] Iteration 316125, lr = 0.001
I0527 09:35:12.063599 19848 solver.cpp:237] Iteration 316500, loss = 0.908456
I0527 09:35:12.063637 19848 solver.cpp:253]     Train net output #0: loss = 0.908456 (* 1 = 0.908456 loss)
I0527 09:35:12.063652 19848 sgd_solver.cpp:106] Iteration 316500, lr = 0.001
I0527 09:35:21.990999 19848 solver.cpp:237] Iteration 316875, loss = 1.14339
I0527 09:35:21.991186 19848 solver.cpp:253]     Train net output #0: loss = 1.14339 (* 1 = 1.14339 loss)
I0527 09:35:21.991200 19848 sgd_solver.cpp:106] Iteration 316875, lr = 0.001
I0527 09:35:31.925503 19848 solver.cpp:237] Iteration 317250, loss = 1.11296
I0527 09:35:31.925537 19848 solver.cpp:253]     Train net output #0: loss = 1.11296 (* 1 = 1.11296 loss)
I0527 09:35:31.925551 19848 sgd_solver.cpp:106] Iteration 317250, lr = 0.001
I0527 09:36:02.711285 19848 solver.cpp:237] Iteration 317625, loss = 0.994451
I0527 09:36:02.711484 19848 solver.cpp:253]     Train net output #0: loss = 0.994451 (* 1 = 0.994451 loss)
I0527 09:36:02.711500 19848 sgd_solver.cpp:106] Iteration 317625, lr = 0.001
I0527 09:36:12.630705 19848 solver.cpp:237] Iteration 318000, loss = 0.905862
I0527 09:36:12.630756 19848 solver.cpp:253]     Train net output #0: loss = 0.905862 (* 1 = 0.905862 loss)
I0527 09:36:12.630770 19848 sgd_solver.cpp:106] Iteration 318000, lr = 0.001
I0527 09:36:22.544574 19848 solver.cpp:237] Iteration 318375, loss = 1.37212
I0527 09:36:22.544610 19848 solver.cpp:253]     Train net output #0: loss = 1.37212 (* 1 = 1.37212 loss)
I0527 09:36:22.544625 19848 sgd_solver.cpp:106] Iteration 318375, lr = 0.001
I0527 09:36:32.425793 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_318750.caffemodel
I0527 09:36:32.482556 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_318750.solverstate
I0527 09:36:32.516465 19848 solver.cpp:237] Iteration 318750, loss = 0.958659
I0527 09:36:32.516511 19848 solver.cpp:253]     Train net output #0: loss = 0.958659 (* 1 = 0.958659 loss)
I0527 09:36:32.516526 19848 sgd_solver.cpp:106] Iteration 318750, lr = 0.001
I0527 09:36:42.427067 19848 solver.cpp:237] Iteration 319125, loss = 1.15557
I0527 09:36:42.427245 19848 solver.cpp:253]     Train net output #0: loss = 1.15557 (* 1 = 1.15557 loss)
I0527 09:36:42.427259 19848 sgd_solver.cpp:106] Iteration 319125, lr = 0.001
I0527 09:36:52.331416 19848 solver.cpp:237] Iteration 319500, loss = 1.07587
I0527 09:36:52.331450 19848 solver.cpp:253]     Train net output #0: loss = 1.07587 (* 1 = 1.07587 loss)
I0527 09:36:52.331468 19848 sgd_solver.cpp:106] Iteration 319500, lr = 0.001
I0527 09:37:02.246525 19848 solver.cpp:237] Iteration 319875, loss = 1.28534
I0527 09:37:02.246572 19848 solver.cpp:253]     Train net output #0: loss = 1.28534 (* 1 = 1.28534 loss)
I0527 09:37:02.246585 19848 sgd_solver.cpp:106] Iteration 319875, lr = 0.001
I0527 09:37:33.028261 19848 solver.cpp:237] Iteration 320250, loss = 1.19869
I0527 09:37:33.028463 19848 solver.cpp:253]     Train net output #0: loss = 1.19869 (* 1 = 1.19869 loss)
I0527 09:37:33.028479 19848 sgd_solver.cpp:106] Iteration 320250, lr = 0.001
I0527 09:37:42.939713 19848 solver.cpp:237] Iteration 320625, loss = 1.09826
I0527 09:37:42.939748 19848 solver.cpp:253]     Train net output #0: loss = 1.09826 (* 1 = 1.09826 loss)
I0527 09:37:42.939762 19848 sgd_solver.cpp:106] Iteration 320625, lr = 0.001
I0527 09:37:52.852362 19848 solver.cpp:237] Iteration 321000, loss = 1.04195
I0527 09:37:52.852412 19848 solver.cpp:253]     Train net output #0: loss = 1.04195 (* 1 = 1.04195 loss)
I0527 09:37:52.852427 19848 sgd_solver.cpp:106] Iteration 321000, lr = 0.001
I0527 09:38:02.769829 19848 solver.cpp:237] Iteration 321375, loss = 0.87721
I0527 09:38:02.769865 19848 solver.cpp:253]     Train net output #0: loss = 0.87721 (* 1 = 0.87721 loss)
I0527 09:38:02.769879 19848 sgd_solver.cpp:106] Iteration 321375, lr = 0.001
I0527 09:38:12.684614 19848 solver.cpp:237] Iteration 321750, loss = 1.20167
I0527 09:38:12.684804 19848 solver.cpp:253]     Train net output #0: loss = 1.20167 (* 1 = 1.20167 loss)
I0527 09:38:12.684819 19848 sgd_solver.cpp:106] Iteration 321750, lr = 0.001
I0527 09:38:22.595226 19848 solver.cpp:237] Iteration 322125, loss = 1.2693
I0527 09:38:22.595260 19848 solver.cpp:253]     Train net output #0: loss = 1.2693 (* 1 = 1.2693 loss)
I0527 09:38:22.595278 19848 sgd_solver.cpp:106] Iteration 322125, lr = 0.001
I0527 09:38:32.479658 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_322500.caffemodel
I0527 09:38:32.536515 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_322500.solverstate
I0527 09:38:32.561625 19848 solver.cpp:341] Iteration 322500, Testing net (#0)
I0527 09:39:21.092505 19848 solver.cpp:409]     Test net output #0: accuracy = 0.90074
I0527 09:39:21.092705 19848 solver.cpp:409]     Test net output #1: loss = 0.306966 (* 1 = 0.306966 loss)
I0527 09:39:41.971596 19848 solver.cpp:237] Iteration 322500, loss = 1.50076
I0527 09:39:41.971648 19848 solver.cpp:253]     Train net output #0: loss = 1.50076 (* 1 = 1.50076 loss)
I0527 09:39:41.971663 19848 sgd_solver.cpp:106] Iteration 322500, lr = 0.001
I0527 09:39:51.739244 19848 solver.cpp:237] Iteration 322875, loss = 1.09601
I0527 09:39:51.739436 19848 solver.cpp:253]     Train net output #0: loss = 1.09601 (* 1 = 1.09601 loss)
I0527 09:39:51.739450 19848 sgd_solver.cpp:106] Iteration 322875, lr = 0.001
I0527 09:40:01.504004 19848 solver.cpp:237] Iteration 323250, loss = 1.07719
I0527 09:40:01.504045 19848 solver.cpp:253]     Train net output #0: loss = 1.07719 (* 1 = 1.07719 loss)
I0527 09:40:01.504061 19848 sgd_solver.cpp:106] Iteration 323250, lr = 0.001
I0527 09:40:11.270978 19848 solver.cpp:237] Iteration 323625, loss = 0.978452
I0527 09:40:11.271010 19848 solver.cpp:253]     Train net output #0: loss = 0.978452 (* 1 = 0.978452 loss)
I0527 09:40:11.271023 19848 sgd_solver.cpp:106] Iteration 323625, lr = 0.001
I0527 09:40:21.043707 19848 solver.cpp:237] Iteration 324000, loss = 1.19818
I0527 09:40:21.043750 19848 solver.cpp:253]     Train net output #0: loss = 1.19818 (* 1 = 1.19818 loss)
I0527 09:40:21.043766 19848 sgd_solver.cpp:106] Iteration 324000, lr = 0.001
I0527 09:40:30.803189 19848 solver.cpp:237] Iteration 324375, loss = 1.17465
I0527 09:40:30.803377 19848 solver.cpp:253]     Train net output #0: loss = 1.17465 (* 1 = 1.17465 loss)
I0527 09:40:30.803391 19848 sgd_solver.cpp:106] Iteration 324375, lr = 0.001
I0527 09:40:40.569566 19848 solver.cpp:237] Iteration 324750, loss = 0.86374
I0527 09:40:40.569600 19848 solver.cpp:253]     Train net output #0: loss = 0.86374 (* 1 = 0.86374 loss)
I0527 09:40:40.569617 19848 sgd_solver.cpp:106] Iteration 324750, lr = 0.001
I0527 09:41:11.222455 19848 solver.cpp:237] Iteration 325125, loss = 1.0422
I0527 09:41:11.222656 19848 solver.cpp:253]     Train net output #0: loss = 1.0422 (* 1 = 1.0422 loss)
I0527 09:41:11.222671 19848 sgd_solver.cpp:106] Iteration 325125, lr = 0.001
I0527 09:41:20.988844 19848 solver.cpp:237] Iteration 325500, loss = 0.875734
I0527 09:41:20.988879 19848 solver.cpp:253]     Train net output #0: loss = 0.875735 (* 1 = 0.875735 loss)
I0527 09:41:20.988898 19848 sgd_solver.cpp:106] Iteration 325500, lr = 0.001
I0527 09:41:30.757715 19848 solver.cpp:237] Iteration 325875, loss = 1.52777
I0527 09:41:30.757750 19848 solver.cpp:253]     Train net output #0: loss = 1.52777 (* 1 = 1.52777 loss)
I0527 09:41:30.757763 19848 sgd_solver.cpp:106] Iteration 325875, lr = 0.001
I0527 09:41:40.524755 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_326250.caffemodel
I0527 09:41:40.581305 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_326250.solverstate
I0527 09:41:40.614998 19848 solver.cpp:237] Iteration 326250, loss = 1.17462
I0527 09:41:40.615041 19848 solver.cpp:253]     Train net output #0: loss = 1.17462 (* 1 = 1.17462 loss)
I0527 09:41:40.615061 19848 sgd_solver.cpp:106] Iteration 326250, lr = 0.001
I0527 09:41:50.449684 19848 solver.cpp:237] Iteration 326625, loss = 1.2951
I0527 09:41:50.449867 19848 solver.cpp:253]     Train net output #0: loss = 1.2951 (* 1 = 1.2951 loss)
I0527 09:41:50.449879 19848 sgd_solver.cpp:106] Iteration 326625, lr = 0.001
I0527 09:42:00.284523 19848 solver.cpp:237] Iteration 327000, loss = 1.24104
I0527 09:42:00.284569 19848 solver.cpp:253]     Train net output #0: loss = 1.24104 (* 1 = 1.24104 loss)
I0527 09:42:00.284585 19848 sgd_solver.cpp:106] Iteration 327000, lr = 0.001
I0527 09:42:10.115514 19848 solver.cpp:237] Iteration 327375, loss = 1.22907
I0527 09:42:10.115547 19848 solver.cpp:253]     Train net output #0: loss = 1.22907 (* 1 = 1.22907 loss)
I0527 09:42:10.115562 19848 sgd_solver.cpp:106] Iteration 327375, lr = 0.001
I0527 09:42:40.834441 19848 solver.cpp:237] Iteration 327750, loss = 1.11513
I0527 09:42:40.834651 19848 solver.cpp:253]     Train net output #0: loss = 1.11513 (* 1 = 1.11513 loss)
I0527 09:42:40.834666 19848 sgd_solver.cpp:106] Iteration 327750, lr = 0.001
I0527 09:42:50.665946 19848 solver.cpp:237] Iteration 328125, loss = 1.11144
I0527 09:42:50.665989 19848 solver.cpp:253]     Train net output #0: loss = 1.11144 (* 1 = 1.11144 loss)
I0527 09:42:50.666007 19848 sgd_solver.cpp:106] Iteration 328125, lr = 0.001
I0527 09:43:00.500324 19848 solver.cpp:237] Iteration 328500, loss = 1.31091
I0527 09:43:00.500360 19848 solver.cpp:253]     Train net output #0: loss = 1.31091 (* 1 = 1.31091 loss)
I0527 09:43:00.500376 19848 sgd_solver.cpp:106] Iteration 328500, lr = 0.001
I0527 09:43:10.331310 19848 solver.cpp:237] Iteration 328875, loss = 1.0456
I0527 09:43:10.331346 19848 solver.cpp:253]     Train net output #0: loss = 1.0456 (* 1 = 1.0456 loss)
I0527 09:43:10.331362 19848 sgd_solver.cpp:106] Iteration 328875, lr = 0.001
I0527 09:43:20.164569 19848 solver.cpp:237] Iteration 329250, loss = 1.17735
I0527 09:43:20.164762 19848 solver.cpp:253]     Train net output #0: loss = 1.17735 (* 1 = 1.17735 loss)
I0527 09:43:20.164777 19848 sgd_solver.cpp:106] Iteration 329250, lr = 0.001
I0527 09:43:29.993151 19848 solver.cpp:237] Iteration 329625, loss = 0.991837
I0527 09:43:29.993186 19848 solver.cpp:253]     Train net output #0: loss = 0.991837 (* 1 = 0.991837 loss)
I0527 09:43:29.993202 19848 sgd_solver.cpp:106] Iteration 329625, lr = 0.001
I0527 09:43:39.798501 19848 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_330000.caffemodel
I0527 09:43:39.855762 19848 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_40_lr_0.0010_2016-05-20T15.49.01.417468_iter_330000.solverstate
I0527 09:43:39.881549 19848 solver.cpp:341] Iteration 330000, Testing net (#0)
I0527 09:44:49.259201 19848 solver.cpp:409]     Test net output #0: accuracy = 0.901354
I0527 09:44:49.259409 19848 solver.cpp:409]     Test net output #1: loss = 0.326804 (* 1 = 0.326804 loss)
I0527 09:45:10.128142 19848 solver.cpp:237] Iteration 330000, loss = 0.826767
I0527 09:45:10.128196 19848 solver.cpp:253]     Train net output #0: loss = 0.826767 (* 1 = 0.826767 loss)
I0527 09:45:10.128211 19848 sgd_solver.cpp:106] Iteration 330000, lr = 0.001
I0527 09:45:20.057329 19848 solver.cpp:237] Iteration 330375, loss = 0.997177
I0527 09:45:20.057524 19848 solver.cpp:253]     Train net output #0: loss = 0.997177 (* 1 = 0.997177 loss)
I0527 09:45:20.057538 19848 sgd_solver.cpp:106] Iteration 330375, lr = 0.001
I0527 09:45:29.986595 19848 solver.cpp:237] Iteration 330750, loss = 1.16111
I0527 09:45:29.986629 19848 solver.cpp:253]     Train net output #0: loss = 1.16111 (* 1 = 1.16111 loss)
I0527 09:45:29.986644 19848 sgd_solver.cpp:106] Iteration 330750, lr = 0.001
I0527 09:45:39.918488 19848 solver.cpp:237] Iteration 331125, loss = 1.00563
I0527 09:45:39.918524 19848 solver.cpp:253]     Train net output #0: loss = 1.00563 (* 1 = 1.00563 loss)
I0527 09:45:39.918539 19848 sgd_solver.cpp:106] Iteration 331125, lr = 0.001
I0527 09:45:49.844148 19848 solver.cpp:237] Iteration 331500, loss = 1.27896
I0527 09:45:49.844192 19848 solver.cpp:253]     Train net output #0: loss = 1.27896 (* 1 = 1.27896 loss)
I0527 09:45:49.844209 19848 sgd_solver.cpp:106] Iteration 331500, lr = 0.001
I0527 09:45:59.770401 19848 solver.cpp:237] Iteration 331875, loss = 1.34148
I0527 09:45:59.770579 19848 solver.cpp:253]     Train net output #0: loss = 1.34148 (* 1 = 1.34148 loss)
I0527 09:45:59.770593 19848 sgd_solver.cpp:106] Iteration 331875, lr = 0.001
I0527 09:46:09.695854 19848 solver.cpp:237] Iteration 332250, loss = 1.01164
I0527 09:46:09.695900 19848 solver.cpp:253]     Train net output #0: loss = 1.01164 (* 1 = 1.01164 loss)
I0527 09:46:09.695917 19848 sgd_solver.cpp:106] Iteration 332250, lr = 0.001
I0527 09:46:40.473302 19848 solver.cpp:237] Iteration 332625, loss = 1.11489
I0527 09:46:40.473505 19848 solver.cpp:253]     Train net output #0: loss = 1.11489 (* 1 = 1.11489 loss)
I0527 09:46:40.473520 19848 sgd_solver.cpp:106] Iteration 332625, lr = 0.001
aprun: Apid 11272504: Caught signal Terminated, sending to application
*** Aborted at 1464356809 (unix time) try "date -d @1464356809" if you are using GNU date ***
PC: @     0x2aaab9173aa0 (unknown)
aprun: Apid 11272504: Caught signal Terminated, sending to application
*** SIGTERM (@0x4d85) received by PID 19848 (TID 0x2aaac746f900) from PID 19845; stack trace: ***
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
    @     0x2aaab9173aa0 (unknown)
    @     0x2aaab9898f3e (unknown)
=>> PBS: job killed: walltime 7218 exceeded limit 7200
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
    @     0x2aaab926d723 (unknown)
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
    @     0x2aaab91d5562 (unknown)
    @     0x2aaab91d56ba (unknown)
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @     0x2aaab91b8715 cuMemcpy
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @           0x5caba5 caffe::Solver<>::Solve()
    @           0x43b3b8 train()
    @           0x43020c main
aprun: Apid 11272504: Caught signal Terminated, sending to application
    @     0x2aaab7ea4c36 __libc_start_main
    @           0x438669 (unknown)
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
aprun: Apid 11272504: Caught signal Terminated, sending to application
