2811319
I0526 05:30:59.400218 30759 caffe.cpp:184] Using GPUs 0
I0526 05:30:59.833765 30759 solver.cpp:48] Initializing solver from parameters: 
test_iter: 15000
test_interval: 30000
base_lr: 0.002
display: 1500
max_iter: 1500000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0001
snapshot: 15000
snapshot_prefix: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054"
solver_mode: GPU
device_id: 0
net: "/lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054.prototxt"
I0526 05:30:59.835603 30759 solver.cpp:91] Creating training net from net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054.prototxt
I0526 05:30:59.853822 30759 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_hdf5
I0526 05:30:59.853885 30759 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 05:30:59.854264 30759 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TRAIN
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 05:30:59.854467 30759 layer_factory.hpp:77] Creating layer data_hdf5
I0526 05:30:59.854497 30759 net.cpp:106] Creating Layer data_hdf5
I0526 05:30:59.854521 30759 net.cpp:411] data_hdf5 -> data
I0526 05:30:59.854555 30759 net.cpp:411] data_hdf5 -> label
I0526 05:30:59.854593 30759 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.trainlist
I0526 05:30:59.855978 30759 hdf5_data_layer.cpp:93] Number of HDF5 files: 15
I0526 05:30:59.858233 30759 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0526 05:31:21.365656 30759 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0526 05:31:21.370860 30759 net.cpp:150] Setting up data_hdf5
I0526 05:31:21.370901 30759 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 05:31:21.370918 30759 net.cpp:157] Top shape: 10 (10)
I0526 05:31:21.370931 30759 net.cpp:165] Memory required for data: 254040
I0526 05:31:21.370949 30759 layer_factory.hpp:77] Creating layer conv1
I0526 05:31:21.370995 30759 net.cpp:106] Creating Layer conv1
I0526 05:31:21.371009 30759 net.cpp:454] conv1 <- data
I0526 05:31:21.371037 30759 net.cpp:411] conv1 -> conv1
I0526 05:31:22.978472 30759 net.cpp:150] Setting up conv1
I0526 05:31:22.978524 30759 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 05:31:22.978538 30759 net.cpp:165] Memory required for data: 3018840
I0526 05:31:22.978569 30759 layer_factory.hpp:77] Creating layer relu1
I0526 05:31:22.978592 30759 net.cpp:106] Creating Layer relu1
I0526 05:31:22.978611 30759 net.cpp:454] relu1 <- conv1
I0526 05:31:22.978646 30759 net.cpp:397] relu1 -> conv1 (in-place)
I0526 05:31:22.979179 30759 net.cpp:150] Setting up relu1
I0526 05:31:22.979202 30759 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 05:31:22.979217 30759 net.cpp:165] Memory required for data: 5783640
I0526 05:31:22.979229 30759 layer_factory.hpp:77] Creating layer pool1
I0526 05:31:22.979259 30759 net.cpp:106] Creating Layer pool1
I0526 05:31:22.979274 30759 net.cpp:454] pool1 <- conv1
I0526 05:31:22.979290 30759 net.cpp:411] pool1 -> pool1
I0526 05:31:22.979382 30759 net.cpp:150] Setting up pool1
I0526 05:31:22.979400 30759 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 05:31:22.979415 30759 net.cpp:165] Memory required for data: 7166040
I0526 05:31:22.979435 30759 layer_factory.hpp:77] Creating layer conv2
I0526 05:31:22.979459 30759 net.cpp:106] Creating Layer conv2
I0526 05:31:22.979475 30759 net.cpp:454] conv2 <- pool1
I0526 05:31:22.979490 30759 net.cpp:411] conv2 -> conv2
I0526 05:31:22.982210 30759 net.cpp:150] Setting up conv2
I0526 05:31:22.982241 30759 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 05:31:22.982257 30759 net.cpp:165] Memory required for data: 9153240
I0526 05:31:22.982285 30759 layer_factory.hpp:77] Creating layer relu2
I0526 05:31:22.982312 30759 net.cpp:106] Creating Layer relu2
I0526 05:31:22.982326 30759 net.cpp:454] relu2 <- conv2
I0526 05:31:22.982342 30759 net.cpp:397] relu2 -> conv2 (in-place)
I0526 05:31:22.982700 30759 net.cpp:150] Setting up relu2
I0526 05:31:22.982720 30759 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 05:31:22.982734 30759 net.cpp:165] Memory required for data: 11140440
I0526 05:31:22.982749 30759 layer_factory.hpp:77] Creating layer pool2
I0526 05:31:22.982772 30759 net.cpp:106] Creating Layer pool2
I0526 05:31:22.982785 30759 net.cpp:454] pool2 <- conv2
I0526 05:31:22.982801 30759 net.cpp:411] pool2 -> pool2
I0526 05:31:22.982897 30759 net.cpp:150] Setting up pool2
I0526 05:31:22.982915 30759 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 05:31:22.982930 30759 net.cpp:165] Memory required for data: 12134040
I0526 05:31:22.982949 30759 layer_factory.hpp:77] Creating layer conv3
I0526 05:31:22.982970 30759 net.cpp:106] Creating Layer conv3
I0526 05:31:22.982990 30759 net.cpp:454] conv3 <- pool2
I0526 05:31:22.983006 30759 net.cpp:411] conv3 -> conv3
I0526 05:31:22.985137 30759 net.cpp:150] Setting up conv3
I0526 05:31:22.985163 30759 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 05:31:22.985183 30759 net.cpp:165] Memory required for data: 13218200
I0526 05:31:22.985206 30759 layer_factory.hpp:77] Creating layer relu3
I0526 05:31:22.985229 30759 net.cpp:106] Creating Layer relu3
I0526 05:31:22.985252 30759 net.cpp:454] relu3 <- conv3
I0526 05:31:22.985268 30759 net.cpp:397] relu3 -> conv3 (in-place)
I0526 05:31:22.985759 30759 net.cpp:150] Setting up relu3
I0526 05:31:22.985785 30759 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 05:31:22.985797 30759 net.cpp:165] Memory required for data: 14302360
I0526 05:31:22.985813 30759 layer_factory.hpp:77] Creating layer pool3
I0526 05:31:22.985838 30759 net.cpp:106] Creating Layer pool3
I0526 05:31:22.985852 30759 net.cpp:454] pool3 <- conv3
I0526 05:31:22.985868 30759 net.cpp:411] pool3 -> pool3
I0526 05:31:22.985950 30759 net.cpp:150] Setting up pool3
I0526 05:31:22.985970 30759 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 05:31:22.985981 30759 net.cpp:165] Memory required for data: 14844440
I0526 05:31:22.985996 30759 layer_factory.hpp:77] Creating layer conv4
I0526 05:31:22.986022 30759 net.cpp:106] Creating Layer conv4
I0526 05:31:22.986035 30759 net.cpp:454] conv4 <- pool3
I0526 05:31:22.986058 30759 net.cpp:411] conv4 -> conv4
I0526 05:31:22.988807 30759 net.cpp:150] Setting up conv4
I0526 05:31:22.988839 30759 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 05:31:22.988858 30759 net.cpp:165] Memory required for data: 15207320
I0526 05:31:22.988878 30759 layer_factory.hpp:77] Creating layer relu4
I0526 05:31:22.988899 30759 net.cpp:106] Creating Layer relu4
I0526 05:31:22.988924 30759 net.cpp:454] relu4 <- conv4
I0526 05:31:22.988940 30759 net.cpp:397] relu4 -> conv4 (in-place)
I0526 05:31:22.989428 30759 net.cpp:150] Setting up relu4
I0526 05:31:22.989459 30759 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 05:31:22.989473 30759 net.cpp:165] Memory required for data: 15570200
I0526 05:31:22.989490 30759 layer_factory.hpp:77] Creating layer pool4
I0526 05:31:22.989514 30759 net.cpp:106] Creating Layer pool4
I0526 05:31:22.989528 30759 net.cpp:454] pool4 <- conv4
I0526 05:31:22.989550 30759 net.cpp:411] pool4 -> pool4
I0526 05:31:22.989634 30759 net.cpp:150] Setting up pool4
I0526 05:31:22.989650 30759 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 05:31:22.989665 30759 net.cpp:165] Memory required for data: 15751640
I0526 05:31:22.989677 30759 layer_factory.hpp:77] Creating layer ip1
I0526 05:31:22.989707 30759 net.cpp:106] Creating Layer ip1
I0526 05:31:22.989720 30759 net.cpp:454] ip1 <- pool4
I0526 05:31:22.989738 30759 net.cpp:411] ip1 -> ip1
I0526 05:31:23.005269 30759 net.cpp:150] Setting up ip1
I0526 05:31:23.005300 30759 net.cpp:157] Top shape: 10 196 (1960)
I0526 05:31:23.005321 30759 net.cpp:165] Memory required for data: 15759480
I0526 05:31:23.005347 30759 layer_factory.hpp:77] Creating layer relu5
I0526 05:31:23.005368 30759 net.cpp:106] Creating Layer relu5
I0526 05:31:23.005393 30759 net.cpp:454] relu5 <- ip1
I0526 05:31:23.005410 30759 net.cpp:397] relu5 -> ip1 (in-place)
I0526 05:31:23.005775 30759 net.cpp:150] Setting up relu5
I0526 05:31:23.005795 30759 net.cpp:157] Top shape: 10 196 (1960)
I0526 05:31:23.005808 30759 net.cpp:165] Memory required for data: 15767320
I0526 05:31:23.005821 30759 layer_factory.hpp:77] Creating layer drop1
I0526 05:31:23.005854 30759 net.cpp:106] Creating Layer drop1
I0526 05:31:23.005868 30759 net.cpp:454] drop1 <- ip1
I0526 05:31:23.005883 30759 net.cpp:397] drop1 -> ip1 (in-place)
I0526 05:31:23.005957 30759 net.cpp:150] Setting up drop1
I0526 05:31:23.005973 30759 net.cpp:157] Top shape: 10 196 (1960)
I0526 05:31:23.005985 30759 net.cpp:165] Memory required for data: 15775160
I0526 05:31:23.006000 30759 layer_factory.hpp:77] Creating layer ip2
I0526 05:31:23.006021 30759 net.cpp:106] Creating Layer ip2
I0526 05:31:23.006041 30759 net.cpp:454] ip2 <- ip1
I0526 05:31:23.006057 30759 net.cpp:411] ip2 -> ip2
I0526 05:31:23.006547 30759 net.cpp:150] Setting up ip2
I0526 05:31:23.006567 30759 net.cpp:157] Top shape: 10 98 (980)
I0526 05:31:23.006579 30759 net.cpp:165] Memory required for data: 15779080
I0526 05:31:23.006599 30759 layer_factory.hpp:77] Creating layer relu6
I0526 05:31:23.006621 30759 net.cpp:106] Creating Layer relu6
I0526 05:31:23.006634 30759 net.cpp:454] relu6 <- ip2
I0526 05:31:23.006649 30759 net.cpp:397] relu6 -> ip2 (in-place)
I0526 05:31:23.007200 30759 net.cpp:150] Setting up relu6
I0526 05:31:23.007223 30759 net.cpp:157] Top shape: 10 98 (980)
I0526 05:31:23.007236 30759 net.cpp:165] Memory required for data: 15783000
I0526 05:31:23.007251 30759 layer_factory.hpp:77] Creating layer drop2
I0526 05:31:23.007267 30759 net.cpp:106] Creating Layer drop2
I0526 05:31:23.007287 30759 net.cpp:454] drop2 <- ip2
I0526 05:31:23.007303 30759 net.cpp:397] drop2 -> ip2 (in-place)
I0526 05:31:23.007354 30759 net.cpp:150] Setting up drop2
I0526 05:31:23.007376 30759 net.cpp:157] Top shape: 10 98 (980)
I0526 05:31:23.007390 30759 net.cpp:165] Memory required for data: 15786920
I0526 05:31:23.007407 30759 layer_factory.hpp:77] Creating layer ip3
I0526 05:31:23.007423 30759 net.cpp:106] Creating Layer ip3
I0526 05:31:23.007436 30759 net.cpp:454] ip3 <- ip2
I0526 05:31:23.007453 30759 net.cpp:411] ip3 -> ip3
I0526 05:31:23.007683 30759 net.cpp:150] Setting up ip3
I0526 05:31:23.007701 30759 net.cpp:157] Top shape: 10 11 (110)
I0526 05:31:23.007714 30759 net.cpp:165] Memory required for data: 15787360
I0526 05:31:23.007735 30759 layer_factory.hpp:77] Creating layer drop3
I0526 05:31:23.007757 30759 net.cpp:106] Creating Layer drop3
I0526 05:31:23.007771 30759 net.cpp:454] drop3 <- ip3
I0526 05:31:23.007786 30759 net.cpp:397] drop3 -> ip3 (in-place)
I0526 05:31:23.007833 30759 net.cpp:150] Setting up drop3
I0526 05:31:23.007855 30759 net.cpp:157] Top shape: 10 11 (110)
I0526 05:31:23.007868 30759 net.cpp:165] Memory required for data: 15787800
I0526 05:31:23.007886 30759 layer_factory.hpp:77] Creating layer loss
I0526 05:31:23.007907 30759 net.cpp:106] Creating Layer loss
I0526 05:31:23.007922 30759 net.cpp:454] loss <- ip3
I0526 05:31:23.007936 30759 net.cpp:454] loss <- label
I0526 05:31:23.007958 30759 net.cpp:411] loss -> loss
I0526 05:31:23.007978 30759 layer_factory.hpp:77] Creating layer loss
I0526 05:31:23.008646 30759 net.cpp:150] Setting up loss
I0526 05:31:23.008667 30759 net.cpp:157] Top shape: (1)
I0526 05:31:23.008683 30759 net.cpp:160]     with loss weight 1
I0526 05:31:23.008744 30759 net.cpp:165] Memory required for data: 15787804
I0526 05:31:23.008759 30759 net.cpp:226] loss needs backward computation.
I0526 05:31:23.008774 30759 net.cpp:226] drop3 needs backward computation.
I0526 05:31:23.008790 30759 net.cpp:226] ip3 needs backward computation.
I0526 05:31:23.008803 30759 net.cpp:226] drop2 needs backward computation.
I0526 05:31:23.008816 30759 net.cpp:226] relu6 needs backward computation.
I0526 05:31:23.008831 30759 net.cpp:226] ip2 needs backward computation.
I0526 05:31:23.008843 30759 net.cpp:226] drop1 needs backward computation.
I0526 05:31:23.008863 30759 net.cpp:226] relu5 needs backward computation.
I0526 05:31:23.008875 30759 net.cpp:226] ip1 needs backward computation.
I0526 05:31:23.008891 30759 net.cpp:226] pool4 needs backward computation.
I0526 05:31:23.008905 30759 net.cpp:226] relu4 needs backward computation.
I0526 05:31:23.008918 30759 net.cpp:226] conv4 needs backward computation.
I0526 05:31:23.008930 30759 net.cpp:226] pool3 needs backward computation.
I0526 05:31:23.008945 30759 net.cpp:226] relu3 needs backward computation.
I0526 05:31:23.008965 30759 net.cpp:226] conv3 needs backward computation.
I0526 05:31:23.008988 30759 net.cpp:226] pool2 needs backward computation.
I0526 05:31:23.009004 30759 net.cpp:226] relu2 needs backward computation.
I0526 05:31:23.009017 30759 net.cpp:226] conv2 needs backward computation.
I0526 05:31:23.009029 30759 net.cpp:226] pool1 needs backward computation.
I0526 05:31:23.009042 30759 net.cpp:226] relu1 needs backward computation.
I0526 05:31:23.009058 30759 net.cpp:226] conv1 needs backward computation.
I0526 05:31:23.009079 30759 net.cpp:228] data_hdf5 does not need backward computation.
I0526 05:31:23.009093 30759 net.cpp:270] This network produces output loss
I0526 05:31:23.009119 30759 net.cpp:283] Network initialization done.
I0526 05:31:23.010869 30759 solver.cpp:181] Creating test net (#0) specified by net file: /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/logs_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054.prototxt
I0526 05:31:23.010948 30759 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_hdf5
I0526 05:31:23.011329 30759 net.cpp:49] Initializing net from parameters: 
name: "caffe_test_127x50_x_unshifted"
state {
  phase: TEST
}
layer {
  name: "data_hdf5"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist"
    batch_size: 10
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 12
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 3
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 20
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 7
    kernel_w: 3
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 28
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 36
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 6
    kernel_w: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 1
    stride_h: 2
    stride_w: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "ip1"
  inner_product_param {
    num_output: 196
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 98
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "ip3"
  top: "ip3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0526 05:31:23.011554 30759 layer_factory.hpp:77] Creating layer data_hdf5
I0526 05:31:23.011574 30759 net.cpp:106] Creating Layer data_hdf5
I0526 05:31:23.011590 30759 net.cpp:411] data_hdf5 -> data
I0526 05:31:23.011612 30759 net.cpp:411] data_hdf5 -> label
I0526 05:31:23.011631 30759 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /lustre/atlas/proj-shared/hep105/caffe_titan/minosmatch_nukecczdefs_127x50_x_unshifted_me1Bmc.testlist
I0526 05:31:23.031599 30759 hdf5_data_layer.cpp:93] Number of HDF5 files: 3
I0526 05:31:44.419921 30759 net.cpp:150] Setting up data_hdf5
I0526 05:31:44.420106 30759 net.cpp:157] Top shape: 10 1 127 50 (63500)
I0526 05:31:44.420125 30759 net.cpp:157] Top shape: 10 (10)
I0526 05:31:44.420138 30759 net.cpp:165] Memory required for data: 254040
I0526 05:31:44.420153 30759 layer_factory.hpp:77] Creating layer label_data_hdf5_1_split
I0526 05:31:44.420186 30759 net.cpp:106] Creating Layer label_data_hdf5_1_split
I0526 05:31:44.420199 30759 net.cpp:454] label_data_hdf5_1_split <- label
I0526 05:31:44.420235 30759 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_0
I0526 05:31:44.420259 30759 net.cpp:411] label_data_hdf5_1_split -> label_data_hdf5_1_split_1
I0526 05:31:44.420346 30759 net.cpp:150] Setting up label_data_hdf5_1_split
I0526 05:31:44.420364 30759 net.cpp:157] Top shape: 10 (10)
I0526 05:31:44.420379 30759 net.cpp:157] Top shape: 10 (10)
I0526 05:31:44.420392 30759 net.cpp:165] Memory required for data: 254120
I0526 05:31:44.420403 30759 layer_factory.hpp:77] Creating layer conv1
I0526 05:31:44.420436 30759 net.cpp:106] Creating Layer conv1
I0526 05:31:44.420450 30759 net.cpp:454] conv1 <- data
I0526 05:31:44.420467 30759 net.cpp:411] conv1 -> conv1
I0526 05:31:44.422444 30759 net.cpp:150] Setting up conv1
I0526 05:31:44.422471 30759 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 05:31:44.422492 30759 net.cpp:165] Memory required for data: 3018920
I0526 05:31:44.422515 30759 layer_factory.hpp:77] Creating layer relu1
I0526 05:31:44.422546 30759 net.cpp:106] Creating Layer relu1
I0526 05:31:44.422559 30759 net.cpp:454] relu1 <- conv1
I0526 05:31:44.422576 30759 net.cpp:397] relu1 -> conv1 (in-place)
I0526 05:31:44.423101 30759 net.cpp:150] Setting up relu1
I0526 05:31:44.423125 30759 net.cpp:157] Top shape: 10 12 120 48 (691200)
I0526 05:31:44.423138 30759 net.cpp:165] Memory required for data: 5783720
I0526 05:31:44.423151 30759 layer_factory.hpp:77] Creating layer pool1
I0526 05:31:44.423180 30759 net.cpp:106] Creating Layer pool1
I0526 05:31:44.423194 30759 net.cpp:454] pool1 <- conv1
I0526 05:31:44.423212 30759 net.cpp:411] pool1 -> pool1
I0526 05:31:44.423301 30759 net.cpp:150] Setting up pool1
I0526 05:31:44.423318 30759 net.cpp:157] Top shape: 10 12 60 48 (345600)
I0526 05:31:44.423333 30759 net.cpp:165] Memory required for data: 7166120
I0526 05:31:44.423352 30759 layer_factory.hpp:77] Creating layer conv2
I0526 05:31:44.423372 30759 net.cpp:106] Creating Layer conv2
I0526 05:31:44.423395 30759 net.cpp:454] conv2 <- pool1
I0526 05:31:44.423413 30759 net.cpp:411] conv2 -> conv2
I0526 05:31:44.425354 30759 net.cpp:150] Setting up conv2
I0526 05:31:44.425379 30759 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 05:31:44.425398 30759 net.cpp:165] Memory required for data: 9153320
I0526 05:31:44.425421 30759 layer_factory.hpp:77] Creating layer relu2
I0526 05:31:44.425441 30759 net.cpp:106] Creating Layer relu2
I0526 05:31:44.425477 30759 net.cpp:454] relu2 <- conv2
I0526 05:31:44.425498 30759 net.cpp:397] relu2 -> conv2 (in-place)
I0526 05:31:44.425859 30759 net.cpp:150] Setting up relu2
I0526 05:31:44.425879 30759 net.cpp:157] Top shape: 10 20 54 46 (496800)
I0526 05:31:44.425892 30759 net.cpp:165] Memory required for data: 11140520
I0526 05:31:44.425909 30759 layer_factory.hpp:77] Creating layer pool2
I0526 05:31:44.425931 30759 net.cpp:106] Creating Layer pool2
I0526 05:31:44.425945 30759 net.cpp:454] pool2 <- conv2
I0526 05:31:44.425961 30759 net.cpp:411] pool2 -> pool2
I0526 05:31:44.426049 30759 net.cpp:150] Setting up pool2
I0526 05:31:44.426066 30759 net.cpp:157] Top shape: 10 20 27 46 (248400)
I0526 05:31:44.426079 30759 net.cpp:165] Memory required for data: 12134120
I0526 05:31:44.426093 30759 layer_factory.hpp:77] Creating layer conv3
I0526 05:31:44.426121 30759 net.cpp:106] Creating Layer conv3
I0526 05:31:44.426136 30759 net.cpp:454] conv3 <- pool2
I0526 05:31:44.426152 30759 net.cpp:411] conv3 -> conv3
I0526 05:31:44.428186 30759 net.cpp:150] Setting up conv3
I0526 05:31:44.428212 30759 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 05:31:44.428231 30759 net.cpp:165] Memory required for data: 13218280
I0526 05:31:44.428254 30759 layer_factory.hpp:77] Creating layer relu3
I0526 05:31:44.428297 30759 net.cpp:106] Creating Layer relu3
I0526 05:31:44.428310 30759 net.cpp:454] relu3 <- conv3
I0526 05:31:44.428326 30759 net.cpp:397] relu3 -> conv3 (in-place)
I0526 05:31:44.428831 30759 net.cpp:150] Setting up relu3
I0526 05:31:44.428854 30759 net.cpp:157] Top shape: 10 28 22 44 (271040)
I0526 05:31:44.428869 30759 net.cpp:165] Memory required for data: 14302440
I0526 05:31:44.428884 30759 layer_factory.hpp:77] Creating layer pool3
I0526 05:31:44.428900 30759 net.cpp:106] Creating Layer pool3
I0526 05:31:44.428921 30759 net.cpp:454] pool3 <- conv3
I0526 05:31:44.428938 30759 net.cpp:411] pool3 -> pool3
I0526 05:31:44.429023 30759 net.cpp:150] Setting up pool3
I0526 05:31:44.429041 30759 net.cpp:157] Top shape: 10 28 11 44 (135520)
I0526 05:31:44.429056 30759 net.cpp:165] Memory required for data: 14844520
I0526 05:31:44.429067 30759 layer_factory.hpp:77] Creating layer conv4
I0526 05:31:44.429090 30759 net.cpp:106] Creating Layer conv4
I0526 05:31:44.429110 30759 net.cpp:454] conv4 <- pool3
I0526 05:31:44.429126 30759 net.cpp:411] conv4 -> conv4
I0526 05:31:44.431224 30759 net.cpp:150] Setting up conv4
I0526 05:31:44.431249 30759 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 05:31:44.431269 30759 net.cpp:165] Memory required for data: 15207400
I0526 05:31:44.431288 30759 layer_factory.hpp:77] Creating layer relu4
I0526 05:31:44.431309 30759 net.cpp:106] Creating Layer relu4
I0526 05:31:44.431323 30759 net.cpp:454] relu4 <- conv4
I0526 05:31:44.431347 30759 net.cpp:397] relu4 -> conv4 (in-place)
I0526 05:31:44.431843 30759 net.cpp:150] Setting up relu4
I0526 05:31:44.431866 30759 net.cpp:157] Top shape: 10 36 6 42 (90720)
I0526 05:31:44.431879 30759 net.cpp:165] Memory required for data: 15570280
I0526 05:31:44.431895 30759 layer_factory.hpp:77] Creating layer pool4
I0526 05:31:44.431918 30759 net.cpp:106] Creating Layer pool4
I0526 05:31:44.431931 30759 net.cpp:454] pool4 <- conv4
I0526 05:31:44.431948 30759 net.cpp:411] pool4 -> pool4
I0526 05:31:44.432035 30759 net.cpp:150] Setting up pool4
I0526 05:31:44.432054 30759 net.cpp:157] Top shape: 10 36 3 42 (45360)
I0526 05:31:44.432067 30759 net.cpp:165] Memory required for data: 15751720
I0526 05:31:44.432080 30759 layer_factory.hpp:77] Creating layer ip1
I0526 05:31:44.432106 30759 net.cpp:106] Creating Layer ip1
I0526 05:31:44.432118 30759 net.cpp:454] ip1 <- pool4
I0526 05:31:44.432135 30759 net.cpp:411] ip1 -> ip1
I0526 05:31:44.447598 30759 net.cpp:150] Setting up ip1
I0526 05:31:44.447629 30759 net.cpp:157] Top shape: 10 196 (1960)
I0526 05:31:44.447651 30759 net.cpp:165] Memory required for data: 15759560
I0526 05:31:44.447679 30759 layer_factory.hpp:77] Creating layer relu5
I0526 05:31:44.447700 30759 net.cpp:106] Creating Layer relu5
I0526 05:31:44.447723 30759 net.cpp:454] relu5 <- ip1
I0526 05:31:44.447741 30759 net.cpp:397] relu5 -> ip1 (in-place)
I0526 05:31:44.448107 30759 net.cpp:150] Setting up relu5
I0526 05:31:44.448125 30759 net.cpp:157] Top shape: 10 196 (1960)
I0526 05:31:44.448138 30759 net.cpp:165] Memory required for data: 15767400
I0526 05:31:44.448151 30759 layer_factory.hpp:77] Creating layer drop1
I0526 05:31:44.448182 30759 net.cpp:106] Creating Layer drop1
I0526 05:31:44.448196 30759 net.cpp:454] drop1 <- ip1
I0526 05:31:44.448212 30759 net.cpp:397] drop1 -> ip1 (in-place)
I0526 05:31:44.448271 30759 net.cpp:150] Setting up drop1
I0526 05:31:44.448287 30759 net.cpp:157] Top shape: 10 196 (1960)
I0526 05:31:44.448299 30759 net.cpp:165] Memory required for data: 15775240
I0526 05:31:44.448313 30759 layer_factory.hpp:77] Creating layer ip2
I0526 05:31:44.448333 30759 net.cpp:106] Creating Layer ip2
I0526 05:31:44.448346 30759 net.cpp:454] ip2 <- ip1
I0526 05:31:44.448371 30759 net.cpp:411] ip2 -> ip2
I0526 05:31:44.448870 30759 net.cpp:150] Setting up ip2
I0526 05:31:44.448889 30759 net.cpp:157] Top shape: 10 98 (980)
I0526 05:31:44.448902 30759 net.cpp:165] Memory required for data: 15779160
I0526 05:31:44.448923 30759 layer_factory.hpp:77] Creating layer relu6
I0526 05:31:44.448958 30759 net.cpp:106] Creating Layer relu6
I0526 05:31:44.448971 30759 net.cpp:454] relu6 <- ip2
I0526 05:31:44.448987 30759 net.cpp:397] relu6 -> ip2 (in-place)
I0526 05:31:44.449555 30759 net.cpp:150] Setting up relu6
I0526 05:31:44.449579 30759 net.cpp:157] Top shape: 10 98 (980)
I0526 05:31:44.449591 30759 net.cpp:165] Memory required for data: 15783080
I0526 05:31:44.449604 30759 layer_factory.hpp:77] Creating layer drop2
I0526 05:31:44.449623 30759 net.cpp:106] Creating Layer drop2
I0526 05:31:44.449645 30759 net.cpp:454] drop2 <- ip2
I0526 05:31:44.449662 30759 net.cpp:397] drop2 -> ip2 (in-place)
I0526 05:31:44.449714 30759 net.cpp:150] Setting up drop2
I0526 05:31:44.449738 30759 net.cpp:157] Top shape: 10 98 (980)
I0526 05:31:44.449749 30759 net.cpp:165] Memory required for data: 15787000
I0526 05:31:44.449769 30759 layer_factory.hpp:77] Creating layer ip3
I0526 05:31:44.449785 30759 net.cpp:106] Creating Layer ip3
I0526 05:31:44.449797 30759 net.cpp:454] ip3 <- ip2
I0526 05:31:44.449816 30759 net.cpp:411] ip3 -> ip3
I0526 05:31:44.450059 30759 net.cpp:150] Setting up ip3
I0526 05:31:44.450079 30759 net.cpp:157] Top shape: 10 11 (110)
I0526 05:31:44.450091 30759 net.cpp:165] Memory required for data: 15787440
I0526 05:31:44.450112 30759 layer_factory.hpp:77] Creating layer drop3
I0526 05:31:44.450135 30759 net.cpp:106] Creating Layer drop3
I0526 05:31:44.450148 30759 net.cpp:454] drop3 <- ip3
I0526 05:31:44.450165 30759 net.cpp:397] drop3 -> ip3 (in-place)
I0526 05:31:44.450212 30759 net.cpp:150] Setting up drop3
I0526 05:31:44.450235 30759 net.cpp:157] Top shape: 10 11 (110)
I0526 05:31:44.450248 30759 net.cpp:165] Memory required for data: 15787880
I0526 05:31:44.450263 30759 layer_factory.hpp:77] Creating layer ip3_drop3_0_split
I0526 05:31:44.450278 30759 net.cpp:106] Creating Layer ip3_drop3_0_split
I0526 05:31:44.450294 30759 net.cpp:454] ip3_drop3_0_split <- ip3
I0526 05:31:44.450316 30759 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_0
I0526 05:31:44.450335 30759 net.cpp:411] ip3_drop3_0_split -> ip3_drop3_0_split_1
I0526 05:31:44.450424 30759 net.cpp:150] Setting up ip3_drop3_0_split
I0526 05:31:44.450443 30759 net.cpp:157] Top shape: 10 11 (110)
I0526 05:31:44.450461 30759 net.cpp:157] Top shape: 10 11 (110)
I0526 05:31:44.450474 30759 net.cpp:165] Memory required for data: 15788760
I0526 05:31:44.450492 30759 layer_factory.hpp:77] Creating layer accuracy
I0526 05:31:44.450515 30759 net.cpp:106] Creating Layer accuracy
I0526 05:31:44.450528 30759 net.cpp:454] accuracy <- ip3_drop3_0_split_0
I0526 05:31:44.450542 30759 net.cpp:454] accuracy <- label_data_hdf5_1_split_0
I0526 05:31:44.450562 30759 net.cpp:411] accuracy -> accuracy
I0526 05:31:44.450594 30759 net.cpp:150] Setting up accuracy
I0526 05:31:44.450616 30759 net.cpp:157] Top shape: (1)
I0526 05:31:44.450628 30759 net.cpp:165] Memory required for data: 15788764
I0526 05:31:44.450640 30759 layer_factory.hpp:77] Creating layer loss
I0526 05:31:44.450659 30759 net.cpp:106] Creating Layer loss
I0526 05:31:44.450678 30759 net.cpp:454] loss <- ip3_drop3_0_split_1
I0526 05:31:44.450692 30759 net.cpp:454] loss <- label_data_hdf5_1_split_1
I0526 05:31:44.450708 30759 net.cpp:411] loss -> loss
I0526 05:31:44.450729 30759 layer_factory.hpp:77] Creating layer loss
I0526 05:31:44.451238 30759 net.cpp:150] Setting up loss
I0526 05:31:44.451258 30759 net.cpp:157] Top shape: (1)
I0526 05:31:44.451272 30759 net.cpp:160]     with loss weight 1
I0526 05:31:44.451297 30759 net.cpp:165] Memory required for data: 15788768
I0526 05:31:44.451318 30759 net.cpp:226] loss needs backward computation.
I0526 05:31:44.451333 30759 net.cpp:228] accuracy does not need backward computation.
I0526 05:31:44.451350 30759 net.cpp:226] ip3_drop3_0_split needs backward computation.
I0526 05:31:44.451364 30759 net.cpp:226] drop3 needs backward computation.
I0526 05:31:44.451375 30759 net.cpp:226] ip3 needs backward computation.
I0526 05:31:44.451391 30759 net.cpp:226] drop2 needs backward computation.
I0526 05:31:44.451409 30759 net.cpp:226] relu6 needs backward computation.
I0526 05:31:44.451431 30759 net.cpp:226] ip2 needs backward computation.
I0526 05:31:44.451447 30759 net.cpp:226] drop1 needs backward computation.
I0526 05:31:44.451460 30759 net.cpp:226] relu5 needs backward computation.
I0526 05:31:44.451472 30759 net.cpp:226] ip1 needs backward computation.
I0526 05:31:44.451488 30759 net.cpp:226] pool4 needs backward computation.
I0526 05:31:44.451499 30759 net.cpp:226] relu4 needs backward computation.
I0526 05:31:44.451519 30759 net.cpp:226] conv4 needs backward computation.
I0526 05:31:44.451534 30759 net.cpp:226] pool3 needs backward computation.
I0526 05:31:44.451550 30759 net.cpp:226] relu3 needs backward computation.
I0526 05:31:44.451563 30759 net.cpp:226] conv3 needs backward computation.
I0526 05:31:44.451575 30759 net.cpp:226] pool2 needs backward computation.
I0526 05:31:44.451588 30759 net.cpp:226] relu2 needs backward computation.
I0526 05:31:44.451603 30759 net.cpp:226] conv2 needs backward computation.
I0526 05:31:44.451617 30759 net.cpp:226] pool1 needs backward computation.
I0526 05:31:44.451637 30759 net.cpp:226] relu1 needs backward computation.
I0526 05:31:44.451649 30759 net.cpp:226] conv1 needs backward computation.
I0526 05:31:44.451666 30759 net.cpp:228] label_data_hdf5_1_split does not need backward computation.
I0526 05:31:44.451680 30759 net.cpp:228] data_hdf5 does not need backward computation.
I0526 05:31:44.451691 30759 net.cpp:270] This network produces output accuracy
I0526 05:31:44.451707 30759 net.cpp:270] This network produces output loss
I0526 05:31:44.451737 30759 net.cpp:283] Network initialization done.
I0526 05:31:44.451874 30759 solver.cpp:60] Solver scaffolding done.
I0526 05:31:44.453017 30759 caffe.cpp:202] Resuming from /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_450000.solverstate
I0526 05:31:44.661931 30759 sgd_solver.cpp:318] SGDSolver: restoring history
I0526 05:31:44.667353 30759 caffe.cpp:212] Starting Optimization
I0526 05:31:44.667404 30759 solver.cpp:288] Solving caffe_test_127x50_x_unshifted
I0526 05:31:44.667418 30759 solver.cpp:289] Learning Rate Policy: fixed
I0526 05:31:44.668659 30759 solver.cpp:341] Iteration 450000, Testing net (#0)
I0526 05:32:45.252853 30759 solver.cpp:409]     Test net output #0: accuracy = 0.892795
I0526 05:32:45.253015 30759 solver.cpp:409]     Test net output #1: loss = 0.3851 (* 1 = 0.3851 loss)
I0526 05:32:45.270784 30759 solver.cpp:237] Iteration 450000, loss = 1.32196
I0526 05:32:45.270823 30759 solver.cpp:253]     Train net output #0: loss = 1.32196 (* 1 = 1.32196 loss)
I0526 05:32:45.270844 30759 sgd_solver.cpp:106] Iteration 450000, lr = 0.002
I0526 05:33:02.436671 30759 solver.cpp:237] Iteration 451500, loss = 1.23262
I0526 05:33:02.436728 30759 solver.cpp:253]     Train net output #0: loss = 1.23262 (* 1 = 1.23262 loss)
I0526 05:33:02.436748 30759 sgd_solver.cpp:106] Iteration 451500, lr = 0.002
I0526 05:33:19.416528 30759 solver.cpp:237] Iteration 453000, loss = 0.923134
I0526 05:33:19.416700 30759 solver.cpp:253]     Train net output #0: loss = 0.923134 (* 1 = 0.923134 loss)
I0526 05:33:19.416719 30759 sgd_solver.cpp:106] Iteration 453000, lr = 0.002
I0526 05:33:36.215986 30759 solver.cpp:237] Iteration 454500, loss = 1.29426
I0526 05:33:36.216025 30759 solver.cpp:253]     Train net output #0: loss = 1.29426 (* 1 = 1.29426 loss)
I0526 05:33:36.216042 30759 sgd_solver.cpp:106] Iteration 454500, lr = 0.002
I0526 05:33:52.869055 30759 solver.cpp:237] Iteration 456000, loss = 1.17803
I0526 05:33:52.869215 30759 solver.cpp:253]     Train net output #0: loss = 1.17803 (* 1 = 1.17803 loss)
I0526 05:33:52.869231 30759 sgd_solver.cpp:106] Iteration 456000, lr = 0.002
I0526 05:34:09.571434 30759 solver.cpp:237] Iteration 457500, loss = 1.05868
I0526 05:34:09.571491 30759 solver.cpp:253]     Train net output #0: loss = 1.05868 (* 1 = 1.05868 loss)
I0526 05:34:09.571508 30759 sgd_solver.cpp:106] Iteration 457500, lr = 0.002
I0526 05:34:26.333541 30759 solver.cpp:237] Iteration 459000, loss = 1.23576
I0526 05:34:26.333685 30759 solver.cpp:253]     Train net output #0: loss = 1.23576 (* 1 = 1.23576 loss)
I0526 05:34:26.333703 30759 sgd_solver.cpp:106] Iteration 459000, lr = 0.002
I0526 05:35:05.429488 30759 solver.cpp:237] Iteration 460500, loss = 1.14234
I0526 05:35:05.429654 30759 solver.cpp:253]     Train net output #0: loss = 1.14234 (* 1 = 1.14234 loss)
I0526 05:35:05.429673 30759 sgd_solver.cpp:106] Iteration 460500, lr = 0.002
I0526 05:35:22.355437 30759 solver.cpp:237] Iteration 462000, loss = 1.75411
I0526 05:35:22.355486 30759 solver.cpp:253]     Train net output #0: loss = 1.75411 (* 1 = 1.75411 loss)
I0526 05:35:22.355504 30759 sgd_solver.cpp:106] Iteration 462000, lr = 0.002
I0526 05:35:39.208551 30759 solver.cpp:237] Iteration 463500, loss = 1.13641
I0526 05:35:39.208705 30759 solver.cpp:253]     Train net output #0: loss = 1.13641 (* 1 = 1.13641 loss)
I0526 05:35:39.208722 30759 sgd_solver.cpp:106] Iteration 463500, lr = 0.002
I0526 05:35:56.149255 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_465000.caffemodel
I0526 05:35:56.197129 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_465000.solverstate
I0526 05:35:56.227587 30759 solver.cpp:237] Iteration 465000, loss = 1.09731
I0526 05:35:56.227645 30759 solver.cpp:253]     Train net output #0: loss = 1.09731 (* 1 = 1.09731 loss)
I0526 05:35:56.227664 30759 sgd_solver.cpp:106] Iteration 465000, lr = 0.002
I0526 05:36:13.313262 30759 solver.cpp:237] Iteration 466500, loss = 1.11219
I0526 05:36:13.313427 30759 solver.cpp:253]     Train net output #0: loss = 1.11219 (* 1 = 1.11219 loss)
I0526 05:36:13.313459 30759 sgd_solver.cpp:106] Iteration 466500, lr = 0.002
I0526 05:36:30.527537 30759 solver.cpp:237] Iteration 468000, loss = 1.02008
I0526 05:36:30.527578 30759 solver.cpp:253]     Train net output #0: loss = 1.02008 (* 1 = 1.02008 loss)
I0526 05:36:30.527597 30759 sgd_solver.cpp:106] Iteration 468000, lr = 0.002
I0526 05:36:47.521816 30759 solver.cpp:237] Iteration 469500, loss = 1.17247
I0526 05:36:47.521971 30759 solver.cpp:253]     Train net output #0: loss = 1.17248 (* 1 = 1.17248 loss)
I0526 05:36:47.521988 30759 sgd_solver.cpp:106] Iteration 469500, lr = 0.002
I0526 05:37:27.378548 30759 solver.cpp:237] Iteration 471000, loss = 1.0833
I0526 05:37:27.378731 30759 solver.cpp:253]     Train net output #0: loss = 1.08331 (* 1 = 1.08331 loss)
I0526 05:37:27.378749 30759 sgd_solver.cpp:106] Iteration 471000, lr = 0.002
I0526 05:37:44.015182 30759 solver.cpp:237] Iteration 472500, loss = 0.927292
I0526 05:37:44.015220 30759 solver.cpp:253]     Train net output #0: loss = 0.927293 (* 1 = 0.927293 loss)
I0526 05:37:44.015239 30759 sgd_solver.cpp:106] Iteration 472500, lr = 0.002
I0526 05:38:00.847740 30759 solver.cpp:237] Iteration 474000, loss = 0.7201
I0526 05:38:00.847903 30759 solver.cpp:253]     Train net output #0: loss = 0.720101 (* 1 = 0.720101 loss)
I0526 05:38:00.847920 30759 sgd_solver.cpp:106] Iteration 474000, lr = 0.002
I0526 05:38:17.905892 30759 solver.cpp:237] Iteration 475500, loss = 0.892174
I0526 05:38:17.905951 30759 solver.cpp:253]     Train net output #0: loss = 0.892176 (* 1 = 0.892176 loss)
I0526 05:38:17.905977 30759 sgd_solver.cpp:106] Iteration 475500, lr = 0.002
I0526 05:38:35.098871 30759 solver.cpp:237] Iteration 477000, loss = 0.879419
I0526 05:38:35.099017 30759 solver.cpp:253]     Train net output #0: loss = 0.879421 (* 1 = 0.879421 loss)
I0526 05:38:35.099035 30759 sgd_solver.cpp:106] Iteration 477000, lr = 0.002
I0526 05:38:51.781960 30759 solver.cpp:237] Iteration 478500, loss = 1.10663
I0526 05:38:51.782018 30759 solver.cpp:253]     Train net output #0: loss = 1.10663 (* 1 = 1.10663 loss)
I0526 05:38:51.782035 30759 sgd_solver.cpp:106] Iteration 478500, lr = 0.002
I0526 05:39:08.461624 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_480000.caffemodel
I0526 05:39:08.509870 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_480000.solverstate
I0526 05:39:08.538884 30759 solver.cpp:341] Iteration 480000, Testing net (#0)
I0526 05:40:08.088601 30759 solver.cpp:409]     Test net output #0: accuracy = 0.900818
I0526 05:40:08.088764 30759 solver.cpp:409]     Test net output #1: loss = 0.305539 (* 1 = 0.305539 loss)
I0526 05:40:30.233024 30759 solver.cpp:237] Iteration 480000, loss = 0.68093
I0526 05:40:30.233093 30759 solver.cpp:253]     Train net output #0: loss = 0.680933 (* 1 = 0.680933 loss)
I0526 05:40:30.233113 30759 sgd_solver.cpp:106] Iteration 480000, lr = 0.002
I0526 05:40:46.896422 30759 solver.cpp:237] Iteration 481500, loss = 0.969618
I0526 05:40:46.896596 30759 solver.cpp:253]     Train net output #0: loss = 0.96962 (* 1 = 0.96962 loss)
I0526 05:40:46.896613 30759 sgd_solver.cpp:106] Iteration 481500, lr = 0.002
I0526 05:41:03.560427 30759 solver.cpp:237] Iteration 483000, loss = 0.820142
I0526 05:41:03.560467 30759 solver.cpp:253]     Train net output #0: loss = 0.820144 (* 1 = 0.820144 loss)
I0526 05:41:03.560487 30759 sgd_solver.cpp:106] Iteration 483000, lr = 0.002
I0526 05:41:20.527822 30759 solver.cpp:237] Iteration 484500, loss = 1.48532
I0526 05:41:20.527981 30759 solver.cpp:253]     Train net output #0: loss = 1.48532 (* 1 = 1.48532 loss)
I0526 05:41:20.527999 30759 sgd_solver.cpp:106] Iteration 484500, lr = 0.002
I0526 05:41:37.494740 30759 solver.cpp:237] Iteration 486000, loss = 1.3045
I0526 05:41:37.494797 30759 solver.cpp:253]     Train net output #0: loss = 1.30451 (* 1 = 1.30451 loss)
I0526 05:41:37.494822 30759 sgd_solver.cpp:106] Iteration 486000, lr = 0.002
I0526 05:41:54.284927 30759 solver.cpp:237] Iteration 487500, loss = 1.22107
I0526 05:41:54.285073 30759 solver.cpp:253]     Train net output #0: loss = 1.22108 (* 1 = 1.22108 loss)
I0526 05:41:54.285089 30759 sgd_solver.cpp:106] Iteration 487500, lr = 0.002
I0526 05:42:11.274657 30759 solver.cpp:237] Iteration 489000, loss = 1.02636
I0526 05:42:11.274715 30759 solver.cpp:253]     Train net output #0: loss = 1.02637 (* 1 = 1.02637 loss)
I0526 05:42:11.274732 30759 sgd_solver.cpp:106] Iteration 489000, lr = 0.002
I0526 05:42:50.416996 30759 solver.cpp:237] Iteration 490500, loss = 1.2988
I0526 05:42:50.417181 30759 solver.cpp:253]     Train net output #0: loss = 1.2988 (* 1 = 1.2988 loss)
I0526 05:42:50.417198 30759 sgd_solver.cpp:106] Iteration 490500, lr = 0.002
I0526 05:43:07.316226 30759 solver.cpp:237] Iteration 492000, loss = 0.938749
I0526 05:43:07.316267 30759 solver.cpp:253]     Train net output #0: loss = 0.938753 (* 1 = 0.938753 loss)
I0526 05:43:07.316284 30759 sgd_solver.cpp:106] Iteration 492000, lr = 0.002
I0526 05:43:24.261173 30759 solver.cpp:237] Iteration 493500, loss = 0.980679
I0526 05:43:24.261337 30759 solver.cpp:253]     Train net output #0: loss = 0.980684 (* 1 = 0.980684 loss)
I0526 05:43:24.261354 30759 sgd_solver.cpp:106] Iteration 493500, lr = 0.002
I0526 05:43:41.286811 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_495000.caffemodel
I0526 05:43:41.336210 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_495000.solverstate
I0526 05:43:41.367538 30759 solver.cpp:237] Iteration 495000, loss = 0.942206
I0526 05:43:41.367600 30759 solver.cpp:253]     Train net output #0: loss = 0.94221 (* 1 = 0.94221 loss)
I0526 05:43:41.367627 30759 sgd_solver.cpp:106] Iteration 495000, lr = 0.002
I0526 05:43:58.596010 30759 solver.cpp:237] Iteration 496500, loss = 1.03203
I0526 05:43:58.596161 30759 solver.cpp:253]     Train net output #0: loss = 1.03203 (* 1 = 1.03203 loss)
I0526 05:43:58.596179 30759 sgd_solver.cpp:106] Iteration 496500, lr = 0.002
I0526 05:44:15.822110 30759 solver.cpp:237] Iteration 498000, loss = 0.911566
I0526 05:44:15.822170 30759 solver.cpp:253]     Train net output #0: loss = 0.911571 (* 1 = 0.911571 loss)
I0526 05:44:15.822187 30759 sgd_solver.cpp:106] Iteration 498000, lr = 0.002
I0526 05:44:32.975198 30759 solver.cpp:237] Iteration 499500, loss = 0.706025
I0526 05:44:32.975364 30759 solver.cpp:253]     Train net output #0: loss = 0.70603 (* 1 = 0.70603 loss)
I0526 05:44:32.975383 30759 sgd_solver.cpp:106] Iteration 499500, lr = 0.002
I0526 05:45:12.134100 30759 solver.cpp:237] Iteration 501000, loss = 1.20771
I0526 05:45:12.134270 30759 solver.cpp:253]     Train net output #0: loss = 1.20772 (* 1 = 1.20772 loss)
I0526 05:45:12.134287 30759 sgd_solver.cpp:106] Iteration 501000, lr = 0.002
I0526 05:45:29.021967 30759 solver.cpp:237] Iteration 502500, loss = 0.970655
I0526 05:45:29.022027 30759 solver.cpp:253]     Train net output #0: loss = 0.97066 (* 1 = 0.97066 loss)
I0526 05:45:29.022045 30759 sgd_solver.cpp:106] Iteration 502500, lr = 0.002
I0526 05:45:45.817167 30759 solver.cpp:237] Iteration 504000, loss = 0.860221
I0526 05:45:45.817334 30759 solver.cpp:253]     Train net output #0: loss = 0.860225 (* 1 = 0.860225 loss)
I0526 05:45:45.817353 30759 sgd_solver.cpp:106] Iteration 504000, lr = 0.002
I0526 05:46:02.422859 30759 solver.cpp:237] Iteration 505500, loss = 1.45969
I0526 05:46:02.422897 30759 solver.cpp:253]     Train net output #0: loss = 1.45969 (* 1 = 1.45969 loss)
I0526 05:46:02.422916 30759 sgd_solver.cpp:106] Iteration 505500, lr = 0.002
I0526 05:46:19.375522 30759 solver.cpp:237] Iteration 507000, loss = 1.04163
I0526 05:46:19.375685 30759 solver.cpp:253]     Train net output #0: loss = 1.04163 (* 1 = 1.04163 loss)
I0526 05:46:19.375704 30759 sgd_solver.cpp:106] Iteration 507000, lr = 0.002
I0526 05:46:36.471820 30759 solver.cpp:237] Iteration 508500, loss = 1.34136
I0526 05:46:36.471876 30759 solver.cpp:253]     Train net output #0: loss = 1.34137 (* 1 = 1.34137 loss)
I0526 05:46:36.471896 30759 sgd_solver.cpp:106] Iteration 508500, lr = 0.002
I0526 05:46:53.643306 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_510000.caffemodel
I0526 05:46:53.691943 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_510000.solverstate
I0526 05:46:53.719780 30759 solver.cpp:341] Iteration 510000, Testing net (#0)
I0526 05:48:14.216964 30759 solver.cpp:409]     Test net output #0: accuracy = 0.901751
I0526 05:48:14.217141 30759 solver.cpp:409]     Test net output #1: loss = 0.346308 (* 1 = 0.346308 loss)
I0526 05:48:36.394659 30759 solver.cpp:237] Iteration 510000, loss = 1.219
I0526 05:48:36.394726 30759 solver.cpp:253]     Train net output #0: loss = 1.219 (* 1 = 1.219 loss)
I0526 05:48:36.394745 30759 sgd_solver.cpp:106] Iteration 510000, lr = 0.002
I0526 05:48:53.475283 30759 solver.cpp:237] Iteration 511500, loss = 0.675854
I0526 05:48:53.475460 30759 solver.cpp:253]     Train net output #0: loss = 0.675859 (* 1 = 0.675859 loss)
I0526 05:48:53.475477 30759 sgd_solver.cpp:106] Iteration 511500, lr = 0.002
I0526 05:49:10.609330 30759 solver.cpp:237] Iteration 513000, loss = 0.589921
I0526 05:49:10.609390 30759 solver.cpp:253]     Train net output #0: loss = 0.589926 (* 1 = 0.589926 loss)
I0526 05:49:10.609407 30759 sgd_solver.cpp:106] Iteration 513000, lr = 0.002
I0526 05:49:27.810279 30759 solver.cpp:237] Iteration 514500, loss = 1.32187
I0526 05:49:27.810447 30759 solver.cpp:253]     Train net output #0: loss = 1.32188 (* 1 = 1.32188 loss)
I0526 05:49:27.810466 30759 sgd_solver.cpp:106] Iteration 514500, lr = 0.002
I0526 05:49:44.787698 30759 solver.cpp:237] Iteration 516000, loss = 1.12951
I0526 05:49:44.787736 30759 solver.cpp:253]     Train net output #0: loss = 1.12951 (* 1 = 1.12951 loss)
I0526 05:49:44.787755 30759 sgd_solver.cpp:106] Iteration 516000, lr = 0.002
I0526 05:50:01.714938 30759 solver.cpp:237] Iteration 517500, loss = 0.688634
I0526 05:50:01.715106 30759 solver.cpp:253]     Train net output #0: loss = 0.68864 (* 1 = 0.68864 loss)
I0526 05:50:01.715122 30759 sgd_solver.cpp:106] Iteration 517500, lr = 0.002
I0526 05:50:18.557588 30759 solver.cpp:237] Iteration 519000, loss = 0.754713
I0526 05:50:18.557651 30759 solver.cpp:253]     Train net output #0: loss = 0.754719 (* 1 = 0.754719 loss)
I0526 05:50:18.557674 30759 sgd_solver.cpp:106] Iteration 519000, lr = 0.002
I0526 05:50:57.338322 30759 solver.cpp:237] Iteration 520500, loss = 1.63097
I0526 05:50:57.338497 30759 solver.cpp:253]     Train net output #0: loss = 1.63098 (* 1 = 1.63098 loss)
I0526 05:50:57.338515 30759 sgd_solver.cpp:106] Iteration 520500, lr = 0.002
I0526 05:51:14.058291 30759 solver.cpp:237] Iteration 522000, loss = 1.65551
I0526 05:51:14.058347 30759 solver.cpp:253]     Train net output #0: loss = 1.65552 (* 1 = 1.65552 loss)
I0526 05:51:14.058367 30759 sgd_solver.cpp:106] Iteration 522000, lr = 0.002
I0526 05:51:30.868008 30759 solver.cpp:237] Iteration 523500, loss = 0.972485
I0526 05:51:30.868155 30759 solver.cpp:253]     Train net output #0: loss = 0.972493 (* 1 = 0.972493 loss)
I0526 05:51:30.868171 30759 sgd_solver.cpp:106] Iteration 523500, lr = 0.002
I0526 05:51:47.499560 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_525000.caffemodel
I0526 05:51:47.548066 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_525000.solverstate
I0526 05:51:47.579692 30759 solver.cpp:237] Iteration 525000, loss = 0.980037
I0526 05:51:47.579758 30759 solver.cpp:253]     Train net output #0: loss = 0.980044 (* 1 = 0.980044 loss)
I0526 05:51:47.579778 30759 sgd_solver.cpp:106] Iteration 525000, lr = 0.002
I0526 05:52:04.214177 30759 solver.cpp:237] Iteration 526500, loss = 2.40005
I0526 05:52:04.214346 30759 solver.cpp:253]     Train net output #0: loss = 2.40005 (* 1 = 2.40005 loss)
I0526 05:52:04.214364 30759 sgd_solver.cpp:106] Iteration 526500, lr = 0.002
I0526 05:52:20.843082 30759 solver.cpp:237] Iteration 528000, loss = 1.67667
I0526 05:52:20.843124 30759 solver.cpp:253]     Train net output #0: loss = 1.67668 (* 1 = 1.67668 loss)
I0526 05:52:20.843143 30759 sgd_solver.cpp:106] Iteration 528000, lr = 0.002
I0526 05:52:37.602749 30759 solver.cpp:237] Iteration 529500, loss = 0.756418
I0526 05:52:37.602927 30759 solver.cpp:253]     Train net output #0: loss = 0.756426 (* 1 = 0.756426 loss)
I0526 05:52:37.602946 30759 sgd_solver.cpp:106] Iteration 529500, lr = 0.002
I0526 05:53:16.467655 30759 solver.cpp:237] Iteration 531000, loss = 1.25754
I0526 05:53:16.467831 30759 solver.cpp:253]     Train net output #0: loss = 1.25754 (* 1 = 1.25754 loss)
I0526 05:53:16.467850 30759 sgd_solver.cpp:106] Iteration 531000, lr = 0.002
I0526 05:53:33.106851 30759 solver.cpp:237] Iteration 532500, loss = 0.788051
I0526 05:53:33.106891 30759 solver.cpp:253]     Train net output #0: loss = 0.78806 (* 1 = 0.78806 loss)
I0526 05:53:33.106909 30759 sgd_solver.cpp:106] Iteration 532500, lr = 0.002
I0526 05:53:49.738832 30759 solver.cpp:237] Iteration 534000, loss = 1.10803
I0526 05:53:49.738999 30759 solver.cpp:253]     Train net output #0: loss = 1.10804 (* 1 = 1.10804 loss)
I0526 05:53:49.739017 30759 sgd_solver.cpp:106] Iteration 534000, lr = 0.002
I0526 05:54:06.497596 30759 solver.cpp:237] Iteration 535500, loss = 1.73128
I0526 05:54:06.497653 30759 solver.cpp:253]     Train net output #0: loss = 1.73128 (* 1 = 1.73128 loss)
I0526 05:54:06.497679 30759 sgd_solver.cpp:106] Iteration 535500, lr = 0.002
I0526 05:54:23.552974 30759 solver.cpp:237] Iteration 537000, loss = 1.05193
I0526 05:54:23.553124 30759 solver.cpp:253]     Train net output #0: loss = 1.05194 (* 1 = 1.05194 loss)
I0526 05:54:23.553140 30759 sgd_solver.cpp:106] Iteration 537000, lr = 0.002
I0526 05:54:40.453841 30759 solver.cpp:237] Iteration 538500, loss = 1.02739
I0526 05:54:40.453891 30759 solver.cpp:253]     Train net output #0: loss = 1.0274 (* 1 = 1.0274 loss)
I0526 05:54:40.453908 30759 sgd_solver.cpp:106] Iteration 538500, lr = 0.002
I0526 05:54:57.227499 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_540000.caffemodel
I0526 05:54:57.274322 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_540000.solverstate
I0526 05:54:57.300081 30759 solver.cpp:341] Iteration 540000, Testing net (#0)
I0526 05:55:56.472585 30759 solver.cpp:409]     Test net output #0: accuracy = 0.900731
I0526 05:55:56.472754 30759 solver.cpp:409]     Test net output #1: loss = 0.31845 (* 1 = 0.31845 loss)
I0526 05:56:18.640462 30759 solver.cpp:237] Iteration 540000, loss = 1.1393
I0526 05:56:18.640527 30759 solver.cpp:253]     Train net output #0: loss = 1.13931 (* 1 = 1.13931 loss)
I0526 05:56:18.640554 30759 sgd_solver.cpp:106] Iteration 540000, lr = 0.002
I0526 05:56:35.621611 30759 solver.cpp:237] Iteration 541500, loss = 0.858087
I0526 05:56:35.621784 30759 solver.cpp:253]     Train net output #0: loss = 0.858094 (* 1 = 0.858094 loss)
I0526 05:56:35.621801 30759 sgd_solver.cpp:106] Iteration 541500, lr = 0.002
I0526 05:56:52.242029 30759 solver.cpp:237] Iteration 543000, loss = 1.60487
I0526 05:56:52.242069 30759 solver.cpp:253]     Train net output #0: loss = 1.60487 (* 1 = 1.60487 loss)
I0526 05:56:52.242085 30759 sgd_solver.cpp:106] Iteration 543000, lr = 0.002
I0526 05:57:08.855595 30759 solver.cpp:237] Iteration 544500, loss = 0.93484
I0526 05:57:08.855763 30759 solver.cpp:253]     Train net output #0: loss = 0.934847 (* 1 = 0.934847 loss)
I0526 05:57:08.855782 30759 sgd_solver.cpp:106] Iteration 544500, lr = 0.002
I0526 05:57:25.518399 30759 solver.cpp:237] Iteration 546000, loss = 1.45055
I0526 05:57:25.518456 30759 solver.cpp:253]     Train net output #0: loss = 1.45056 (* 1 = 1.45056 loss)
I0526 05:57:25.518483 30759 sgd_solver.cpp:106] Iteration 546000, lr = 0.002
I0526 05:57:42.297562 30759 solver.cpp:237] Iteration 547500, loss = 1.25813
I0526 05:57:42.297721 30759 solver.cpp:253]     Train net output #0: loss = 1.25813 (* 1 = 1.25813 loss)
I0526 05:57:42.297739 30759 sgd_solver.cpp:106] Iteration 547500, lr = 0.002
I0526 05:57:58.953488 30759 solver.cpp:237] Iteration 549000, loss = 1.04276
I0526 05:57:58.953547 30759 solver.cpp:253]     Train net output #0: loss = 1.04277 (* 1 = 1.04277 loss)
I0526 05:57:58.953565 30759 sgd_solver.cpp:106] Iteration 549000, lr = 0.002
I0526 05:58:37.686936 30759 solver.cpp:237] Iteration 550500, loss = 1.15568
I0526 05:58:37.687126 30759 solver.cpp:253]     Train net output #0: loss = 1.15569 (* 1 = 1.15569 loss)
I0526 05:58:37.687144 30759 sgd_solver.cpp:106] Iteration 550500, lr = 0.002
I0526 05:58:54.313240 30759 solver.cpp:237] Iteration 552000, loss = 0.737117
I0526 05:58:54.313279 30759 solver.cpp:253]     Train net output #0: loss = 0.737125 (* 1 = 0.737125 loss)
I0526 05:58:54.313297 30759 sgd_solver.cpp:106] Iteration 552000, lr = 0.002
I0526 05:59:11.191382 30759 solver.cpp:237] Iteration 553500, loss = 0.759672
I0526 05:59:11.191550 30759 solver.cpp:253]     Train net output #0: loss = 0.75968 (* 1 = 0.75968 loss)
I0526 05:59:11.191568 30759 sgd_solver.cpp:106] Iteration 553500, lr = 0.002
I0526 05:59:28.244076 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_555000.caffemodel
I0526 05:59:28.289973 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_555000.solverstate
I0526 05:59:28.319015 30759 solver.cpp:237] Iteration 555000, loss = 1.39146
I0526 05:59:28.319072 30759 solver.cpp:253]     Train net output #0: loss = 1.39147 (* 1 = 1.39147 loss)
I0526 05:59:28.319092 30759 sgd_solver.cpp:106] Iteration 555000, lr = 0.002
I0526 05:59:45.237056 30759 solver.cpp:237] Iteration 556500, loss = 1.23779
I0526 05:59:45.237210 30759 solver.cpp:253]     Train net output #0: loss = 1.2378 (* 1 = 1.2378 loss)
I0526 05:59:45.237226 30759 sgd_solver.cpp:106] Iteration 556500, lr = 0.002
I0526 06:00:02.081398 30759 solver.cpp:237] Iteration 558000, loss = 1.03786
I0526 06:00:02.081470 30759 solver.cpp:253]     Train net output #0: loss = 1.03787 (* 1 = 1.03787 loss)
I0526 06:00:02.081496 30759 sgd_solver.cpp:106] Iteration 558000, lr = 0.002
I0526 06:00:18.908247 30759 solver.cpp:237] Iteration 559500, loss = 0.935087
I0526 06:00:18.908419 30759 solver.cpp:253]     Train net output #0: loss = 0.935094 (* 1 = 0.935094 loss)
I0526 06:00:18.908437 30759 sgd_solver.cpp:106] Iteration 559500, lr = 0.002
I0526 06:00:58.230836 30759 solver.cpp:237] Iteration 561000, loss = 1.16276
I0526 06:00:58.231005 30759 solver.cpp:253]     Train net output #0: loss = 1.16277 (* 1 = 1.16277 loss)
I0526 06:00:58.231024 30759 sgd_solver.cpp:106] Iteration 561000, lr = 0.002
I0526 06:01:15.320049 30759 solver.cpp:237] Iteration 562500, loss = 2.44485
I0526 06:01:15.320107 30759 solver.cpp:253]     Train net output #0: loss = 2.44486 (* 1 = 2.44486 loss)
I0526 06:01:15.320125 30759 sgd_solver.cpp:106] Iteration 562500, lr = 0.002
I0526 06:01:32.286429 30759 solver.cpp:237] Iteration 564000, loss = 1.21949
I0526 06:01:32.286597 30759 solver.cpp:253]     Train net output #0: loss = 1.21949 (* 1 = 1.21949 loss)
I0526 06:01:32.286617 30759 sgd_solver.cpp:106] Iteration 564000, lr = 0.002
I0526 06:01:48.930490 30759 solver.cpp:237] Iteration 565500, loss = 0.881995
I0526 06:01:48.930529 30759 solver.cpp:253]     Train net output #0: loss = 0.882002 (* 1 = 0.882002 loss)
I0526 06:01:48.930546 30759 sgd_solver.cpp:106] Iteration 565500, lr = 0.002
I0526 06:02:05.647861 30759 solver.cpp:237] Iteration 567000, loss = 1.09215
I0526 06:02:05.648030 30759 solver.cpp:253]     Train net output #0: loss = 1.09216 (* 1 = 1.09216 loss)
I0526 06:02:05.648046 30759 sgd_solver.cpp:106] Iteration 567000, lr = 0.002
I0526 06:02:22.450132 30759 solver.cpp:237] Iteration 568500, loss = 1.05978
I0526 06:02:22.450191 30759 solver.cpp:253]     Train net output #0: loss = 1.05979 (* 1 = 1.05979 loss)
I0526 06:02:22.450215 30759 sgd_solver.cpp:106] Iteration 568500, lr = 0.002
I0526 06:02:39.408445 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_570000.caffemodel
I0526 06:02:39.454689 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_570000.solverstate
I0526 06:02:39.481114 30759 solver.cpp:341] Iteration 570000, Testing net (#0)
I0526 06:03:59.805752 30759 solver.cpp:409]     Test net output #0: accuracy = 0.901379
I0526 06:03:59.805927 30759 solver.cpp:409]     Test net output #1: loss = 0.31677 (* 1 = 0.31677 loss)
I0526 06:04:21.984458 30759 solver.cpp:237] Iteration 570000, loss = 1.64186
I0526 06:04:21.984524 30759 solver.cpp:253]     Train net output #0: loss = 1.64187 (* 1 = 1.64187 loss)
I0526 06:04:21.984551 30759 sgd_solver.cpp:106] Iteration 570000, lr = 0.002
I0526 06:04:38.771370 30759 solver.cpp:237] Iteration 571500, loss = 1.12543
I0526 06:04:38.771525 30759 solver.cpp:253]     Train net output #0: loss = 1.12544 (* 1 = 1.12544 loss)
I0526 06:04:38.771543 30759 sgd_solver.cpp:106] Iteration 571500, lr = 0.002
I0526 06:04:55.434042 30759 solver.cpp:237] Iteration 573000, loss = 0.404338
I0526 06:04:55.434101 30759 solver.cpp:253]     Train net output #0: loss = 0.404345 (* 1 = 0.404345 loss)
I0526 06:04:55.434128 30759 sgd_solver.cpp:106] Iteration 573000, lr = 0.002
I0526 06:05:12.270303 30759 solver.cpp:237] Iteration 574500, loss = 0.96592
I0526 06:05:12.270455 30759 solver.cpp:253]     Train net output #0: loss = 0.965927 (* 1 = 0.965927 loss)
I0526 06:05:12.270473 30759 sgd_solver.cpp:106] Iteration 574500, lr = 0.002
I0526 06:05:29.069890 30759 solver.cpp:237] Iteration 576000, loss = 0.45725
I0526 06:05:29.069944 30759 solver.cpp:253]     Train net output #0: loss = 0.457256 (* 1 = 0.457256 loss)
I0526 06:05:29.069962 30759 sgd_solver.cpp:106] Iteration 576000, lr = 0.002
I0526 06:05:45.979897 30759 solver.cpp:237] Iteration 577500, loss = 1.77951
I0526 06:05:45.980062 30759 solver.cpp:253]     Train net output #0: loss = 1.77952 (* 1 = 1.77952 loss)
I0526 06:05:45.980079 30759 sgd_solver.cpp:106] Iteration 577500, lr = 0.002
I0526 06:06:03.175173 30759 solver.cpp:237] Iteration 579000, loss = 0.9506
I0526 06:06:03.175215 30759 solver.cpp:253]     Train net output #0: loss = 0.950606 (* 1 = 0.950606 loss)
I0526 06:06:03.175231 30759 sgd_solver.cpp:106] Iteration 579000, lr = 0.002
I0526 06:06:42.281416 30759 solver.cpp:237] Iteration 580500, loss = 0.922841
I0526 06:06:42.281602 30759 solver.cpp:253]     Train net output #0: loss = 0.922847 (* 1 = 0.922847 loss)
I0526 06:06:42.281620 30759 sgd_solver.cpp:106] Iteration 580500, lr = 0.002
I0526 06:06:59.214483 30759 solver.cpp:237] Iteration 582000, loss = 0.914527
I0526 06:06:59.214542 30759 solver.cpp:253]     Train net output #0: loss = 0.914533 (* 1 = 0.914533 loss)
I0526 06:06:59.214567 30759 sgd_solver.cpp:106] Iteration 582000, lr = 0.002
I0526 06:07:16.031461 30759 solver.cpp:237] Iteration 583500, loss = 1.54286
I0526 06:07:16.031615 30759 solver.cpp:253]     Train net output #0: loss = 1.54287 (* 1 = 1.54287 loss)
I0526 06:07:16.031630 30759 sgd_solver.cpp:106] Iteration 583500, lr = 0.002
I0526 06:07:33.099233 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_585000.caffemodel
I0526 06:07:33.147944 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_585000.solverstate
I0526 06:07:33.179482 30759 solver.cpp:237] Iteration 585000, loss = 2.20721
I0526 06:07:33.179548 30759 solver.cpp:253]     Train net output #0: loss = 2.20722 (* 1 = 2.20722 loss)
I0526 06:07:33.179565 30759 sgd_solver.cpp:106] Iteration 585000, lr = 0.002
I0526 06:07:50.282744 30759 solver.cpp:237] Iteration 586500, loss = 1.00333
I0526 06:07:50.282932 30759 solver.cpp:253]     Train net output #0: loss = 1.00334 (* 1 = 1.00334 loss)
I0526 06:07:50.282950 30759 sgd_solver.cpp:106] Iteration 586500, lr = 0.002
I0526 06:08:07.071200 30759 solver.cpp:237] Iteration 588000, loss = 1.91949
I0526 06:08:07.071241 30759 solver.cpp:253]     Train net output #0: loss = 1.9195 (* 1 = 1.9195 loss)
I0526 06:08:07.071265 30759 sgd_solver.cpp:106] Iteration 588000, lr = 0.002
I0526 06:08:24.052446 30759 solver.cpp:237] Iteration 589500, loss = 1.27477
I0526 06:08:24.052618 30759 solver.cpp:253]     Train net output #0: loss = 1.27478 (* 1 = 1.27478 loss)
I0526 06:08:24.052636 30759 sgd_solver.cpp:106] Iteration 589500, lr = 0.002
I0526 06:09:03.212183 30759 solver.cpp:237] Iteration 591000, loss = 0.585669
I0526 06:09:03.212368 30759 solver.cpp:253]     Train net output #0: loss = 0.585675 (* 1 = 0.585675 loss)
I0526 06:09:03.212388 30759 sgd_solver.cpp:106] Iteration 591000, lr = 0.002
I0526 06:09:19.818934 30759 solver.cpp:237] Iteration 592500, loss = 1.49021
I0526 06:09:19.818972 30759 solver.cpp:253]     Train net output #0: loss = 1.49022 (* 1 = 1.49022 loss)
I0526 06:09:19.818991 30759 sgd_solver.cpp:106] Iteration 592500, lr = 0.002
I0526 06:09:36.634044 30759 solver.cpp:237] Iteration 594000, loss = 1.49955
I0526 06:09:36.634215 30759 solver.cpp:253]     Train net output #0: loss = 1.49955 (* 1 = 1.49955 loss)
I0526 06:09:36.634232 30759 sgd_solver.cpp:106] Iteration 594000, lr = 0.002
I0526 06:09:53.557487 30759 solver.cpp:237] Iteration 595500, loss = 1.13796
I0526 06:09:53.557544 30759 solver.cpp:253]     Train net output #0: loss = 1.13797 (* 1 = 1.13797 loss)
I0526 06:09:53.557574 30759 sgd_solver.cpp:106] Iteration 595500, lr = 0.002
I0526 06:10:10.172617 30759 solver.cpp:237] Iteration 597000, loss = 1.66468
I0526 06:10:10.172770 30759 solver.cpp:253]     Train net output #0: loss = 1.66469 (* 1 = 1.66469 loss)
I0526 06:10:10.172786 30759 sgd_solver.cpp:106] Iteration 597000, lr = 0.002
I0526 06:10:26.891944 30759 solver.cpp:237] Iteration 598500, loss = 1.02568
I0526 06:10:26.892001 30759 solver.cpp:253]     Train net output #0: loss = 1.02568 (* 1 = 1.02568 loss)
I0526 06:10:26.892019 30759 sgd_solver.cpp:106] Iteration 598500, lr = 0.002
I0526 06:10:43.656363 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_600000.caffemodel
I0526 06:10:43.707470 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_600000.solverstate
I0526 06:10:43.735678 30759 solver.cpp:341] Iteration 600000, Testing net (#0)
I0526 06:11:42.887796 30759 solver.cpp:409]     Test net output #0: accuracy = 0.899222
I0526 06:11:42.887965 30759 solver.cpp:409]     Test net output #1: loss = 0.332029 (* 1 = 0.332029 loss)
I0526 06:12:03.722556 30759 solver.cpp:237] Iteration 600000, loss = 0.602983
I0526 06:12:03.722620 30759 solver.cpp:253]     Train net output #0: loss = 0.602988 (* 1 = 0.602988 loss)
I0526 06:12:03.722650 30759 sgd_solver.cpp:106] Iteration 600000, lr = 0.002
I0526 06:12:20.670315 30759 solver.cpp:237] Iteration 601500, loss = 0.694103
I0526 06:12:20.670472 30759 solver.cpp:253]     Train net output #0: loss = 0.694108 (* 1 = 0.694108 loss)
I0526 06:12:20.670490 30759 sgd_solver.cpp:106] Iteration 601500, lr = 0.002
I0526 06:12:37.339745 30759 solver.cpp:237] Iteration 603000, loss = 1.19242
I0526 06:12:37.339800 30759 solver.cpp:253]     Train net output #0: loss = 1.19242 (* 1 = 1.19242 loss)
I0526 06:12:37.339818 30759 sgd_solver.cpp:106] Iteration 603000, lr = 0.002
I0526 06:12:54.046372 30759 solver.cpp:237] Iteration 604500, loss = 1.20083
I0526 06:12:54.046552 30759 solver.cpp:253]     Train net output #0: loss = 1.20084 (* 1 = 1.20084 loss)
I0526 06:12:54.046571 30759 sgd_solver.cpp:106] Iteration 604500, lr = 0.002
I0526 06:13:10.932835 30759 solver.cpp:237] Iteration 606000, loss = 1.15889
I0526 06:13:10.932875 30759 solver.cpp:253]     Train net output #0: loss = 1.15889 (* 1 = 1.15889 loss)
I0526 06:13:10.932893 30759 sgd_solver.cpp:106] Iteration 606000, lr = 0.002
I0526 06:13:27.534102 30759 solver.cpp:237] Iteration 607500, loss = 0.705805
I0526 06:13:27.534273 30759 solver.cpp:253]     Train net output #0: loss = 0.705811 (* 1 = 0.705811 loss)
I0526 06:13:27.534291 30759 sgd_solver.cpp:106] Iteration 607500, lr = 0.002
I0526 06:13:44.369143 30759 solver.cpp:237] Iteration 609000, loss = 1.3389
I0526 06:13:44.369197 30759 solver.cpp:253]     Train net output #0: loss = 1.3389 (* 1 = 1.3389 loss)
I0526 06:13:44.369215 30759 sgd_solver.cpp:106] Iteration 609000, lr = 0.002
I0526 06:14:22.198644 30759 solver.cpp:237] Iteration 610500, loss = 0.887731
I0526 06:14:22.198824 30759 solver.cpp:253]     Train net output #0: loss = 0.887737 (* 1 = 0.887737 loss)
I0526 06:14:22.198843 30759 sgd_solver.cpp:106] Iteration 610500, lr = 0.002
I0526 06:14:38.938966 30759 solver.cpp:237] Iteration 612000, loss = 1.53631
I0526 06:14:38.939023 30759 solver.cpp:253]     Train net output #0: loss = 1.53631 (* 1 = 1.53631 loss)
I0526 06:14:38.939040 30759 sgd_solver.cpp:106] Iteration 612000, lr = 0.002
I0526 06:14:55.560699 30759 solver.cpp:237] Iteration 613500, loss = 1.06631
I0526 06:14:55.560874 30759 solver.cpp:253]     Train net output #0: loss = 1.06632 (* 1 = 1.06632 loss)
I0526 06:14:55.560891 30759 sgd_solver.cpp:106] Iteration 613500, lr = 0.002
I0526 06:15:12.171092 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_615000.caffemodel
I0526 06:15:12.216536 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_615000.solverstate
I0526 06:15:12.245589 30759 solver.cpp:237] Iteration 615000, loss = 1.16262
I0526 06:15:12.245646 30759 solver.cpp:253]     Train net output #0: loss = 1.16263 (* 1 = 1.16263 loss)
I0526 06:15:12.245672 30759 sgd_solver.cpp:106] Iteration 615000, lr = 0.002
I0526 06:15:29.127953 30759 solver.cpp:237] Iteration 616500, loss = 0.663065
I0526 06:15:29.128137 30759 solver.cpp:253]     Train net output #0: loss = 0.663071 (* 1 = 0.663071 loss)
I0526 06:15:29.128155 30759 sgd_solver.cpp:106] Iteration 616500, lr = 0.002
I0526 06:15:46.079510 30759 solver.cpp:237] Iteration 618000, loss = 1.15938
I0526 06:15:46.079571 30759 solver.cpp:253]     Train net output #0: loss = 1.15938 (* 1 = 1.15938 loss)
I0526 06:15:46.079594 30759 sgd_solver.cpp:106] Iteration 618000, lr = 0.002
I0526 06:16:02.866101 30759 solver.cpp:237] Iteration 619500, loss = 0.979845
I0526 06:16:02.866256 30759 solver.cpp:253]     Train net output #0: loss = 0.979851 (* 1 = 0.979851 loss)
I0526 06:16:02.866273 30759 sgd_solver.cpp:106] Iteration 619500, lr = 0.002
I0526 06:16:40.611232 30759 solver.cpp:237] Iteration 621000, loss = 1.0718
I0526 06:16:40.611407 30759 solver.cpp:253]     Train net output #0: loss = 1.07181 (* 1 = 1.07181 loss)
I0526 06:16:40.611425 30759 sgd_solver.cpp:106] Iteration 621000, lr = 0.002
I0526 06:16:57.643079 30759 solver.cpp:237] Iteration 622500, loss = 0.962243
I0526 06:16:57.643137 30759 solver.cpp:253]     Train net output #0: loss = 0.962248 (* 1 = 0.962248 loss)
I0526 06:16:57.643167 30759 sgd_solver.cpp:106] Iteration 622500, lr = 0.002
I0526 06:17:14.402390 30759 solver.cpp:237] Iteration 624000, loss = 0.757942
I0526 06:17:14.402545 30759 solver.cpp:253]     Train net output #0: loss = 0.757947 (* 1 = 0.757947 loss)
I0526 06:17:14.402562 30759 sgd_solver.cpp:106] Iteration 624000, lr = 0.002
I0526 06:17:31.436610 30759 solver.cpp:237] Iteration 625500, loss = 1.47236
I0526 06:17:31.436666 30759 solver.cpp:253]     Train net output #0: loss = 1.47237 (* 1 = 1.47237 loss)
I0526 06:17:31.436684 30759 sgd_solver.cpp:106] Iteration 625500, lr = 0.002
I0526 06:17:48.618966 30759 solver.cpp:237] Iteration 627000, loss = 1.24095
I0526 06:17:48.619151 30759 solver.cpp:253]     Train net output #0: loss = 1.24096 (* 1 = 1.24096 loss)
I0526 06:17:48.619169 30759 sgd_solver.cpp:106] Iteration 627000, lr = 0.002
I0526 06:18:05.512964 30759 solver.cpp:237] Iteration 628500, loss = 0.998074
I0526 06:18:05.513005 30759 solver.cpp:253]     Train net output #0: loss = 0.998079 (* 1 = 0.998079 loss)
I0526 06:18:05.513021 30759 sgd_solver.cpp:106] Iteration 628500, lr = 0.002
I0526 06:18:22.222354 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_630000.caffemodel
I0526 06:18:22.269240 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_630000.solverstate
I0526 06:18:22.295433 30759 solver.cpp:341] Iteration 630000, Testing net (#0)
I0526 06:19:42.531568 30759 solver.cpp:409]     Test net output #0: accuracy = 0.900367
I0526 06:19:42.531743 30759 solver.cpp:409]     Test net output #1: loss = 0.314183 (* 1 = 0.314183 loss)
I0526 06:20:03.335872 30759 solver.cpp:237] Iteration 630000, loss = 0.898249
I0526 06:20:03.335935 30759 solver.cpp:253]     Train net output #0: loss = 0.898254 (* 1 = 0.898254 loss)
I0526 06:20:03.335961 30759 sgd_solver.cpp:106] Iteration 630000, lr = 0.002
I0526 06:20:20.288848 30759 solver.cpp:237] Iteration 631500, loss = 0.838501
I0526 06:20:20.289026 30759 solver.cpp:253]     Train net output #0: loss = 0.838505 (* 1 = 0.838505 loss)
I0526 06:20:20.289043 30759 sgd_solver.cpp:106] Iteration 631500, lr = 0.002
I0526 06:20:36.910435 30759 solver.cpp:237] Iteration 633000, loss = 1.07662
I0526 06:20:36.910473 30759 solver.cpp:253]     Train net output #0: loss = 1.07663 (* 1 = 1.07663 loss)
I0526 06:20:36.910492 30759 sgd_solver.cpp:106] Iteration 633000, lr = 0.002
I0526 06:20:53.545469 30759 solver.cpp:237] Iteration 634500, loss = 1.26663
I0526 06:20:53.545634 30759 solver.cpp:253]     Train net output #0: loss = 1.26664 (* 1 = 1.26664 loss)
I0526 06:20:53.545651 30759 sgd_solver.cpp:106] Iteration 634500, lr = 0.002
I0526 06:21:10.179714 30759 solver.cpp:237] Iteration 636000, loss = 1.6451
I0526 06:21:10.179767 30759 solver.cpp:253]     Train net output #0: loss = 1.6451 (* 1 = 1.6451 loss)
I0526 06:21:10.179791 30759 sgd_solver.cpp:106] Iteration 636000, lr = 0.002
I0526 06:21:27.001405 30759 solver.cpp:237] Iteration 637500, loss = 1.22752
I0526 06:21:27.001564 30759 solver.cpp:253]     Train net output #0: loss = 1.22752 (* 1 = 1.22752 loss)
I0526 06:21:27.001581 30759 sgd_solver.cpp:106] Iteration 637500, lr = 0.002
I0526 06:21:44.057682 30759 solver.cpp:237] Iteration 639000, loss = 1.24911
I0526 06:21:44.057735 30759 solver.cpp:253]     Train net output #0: loss = 1.24912 (* 1 = 1.24912 loss)
I0526 06:21:44.057754 30759 sgd_solver.cpp:106] Iteration 639000, lr = 0.002
I0526 06:22:22.056161 30759 solver.cpp:237] Iteration 640500, loss = 1.2076
I0526 06:22:22.056335 30759 solver.cpp:253]     Train net output #0: loss = 1.2076 (* 1 = 1.2076 loss)
I0526 06:22:22.056354 30759 sgd_solver.cpp:106] Iteration 640500, lr = 0.002
I0526 06:22:39.028132 30759 solver.cpp:237] Iteration 642000, loss = 0.715221
I0526 06:22:39.028172 30759 solver.cpp:253]     Train net output #0: loss = 0.715224 (* 1 = 0.715224 loss)
I0526 06:22:39.028189 30759 sgd_solver.cpp:106] Iteration 642000, lr = 0.002
I0526 06:22:55.816247 30759 solver.cpp:237] Iteration 643500, loss = 1.47447
I0526 06:22:55.816417 30759 solver.cpp:253]     Train net output #0: loss = 1.47447 (* 1 = 1.47447 loss)
I0526 06:22:55.816434 30759 sgd_solver.cpp:106] Iteration 643500, lr = 0.002
I0526 06:23:12.482724 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_645000.caffemodel
I0526 06:23:12.531579 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_645000.solverstate
I0526 06:23:12.561771 30759 solver.cpp:237] Iteration 645000, loss = 0.944
I0526 06:23:12.561836 30759 solver.cpp:253]     Train net output #0: loss = 0.944004 (* 1 = 0.944004 loss)
I0526 06:23:12.561857 30759 sgd_solver.cpp:106] Iteration 645000, lr = 0.002
I0526 06:23:29.767243 30759 solver.cpp:237] Iteration 646500, loss = 1.09202
I0526 06:23:29.767411 30759 solver.cpp:253]     Train net output #0: loss = 1.09202 (* 1 = 1.09202 loss)
I0526 06:23:29.767429 30759 sgd_solver.cpp:106] Iteration 646500, lr = 0.002
I0526 06:23:46.730557 30759 solver.cpp:237] Iteration 648000, loss = 0.674789
I0526 06:23:46.730618 30759 solver.cpp:253]     Train net output #0: loss = 0.674794 (* 1 = 0.674794 loss)
I0526 06:23:46.730636 30759 sgd_solver.cpp:106] Iteration 648000, lr = 0.002
I0526 06:24:03.541507 30759 solver.cpp:237] Iteration 649500, loss = 0.735098
I0526 06:24:03.541684 30759 solver.cpp:253]     Train net output #0: loss = 0.735102 (* 1 = 0.735102 loss)
I0526 06:24:03.541702 30759 sgd_solver.cpp:106] Iteration 649500, lr = 0.002
I0526 06:24:41.540671 30759 solver.cpp:237] Iteration 651000, loss = 1.13422
I0526 06:24:41.540854 30759 solver.cpp:253]     Train net output #0: loss = 1.13422 (* 1 = 1.13422 loss)
I0526 06:24:41.540873 30759 sgd_solver.cpp:106] Iteration 651000, lr = 0.002
I0526 06:24:58.514915 30759 solver.cpp:237] Iteration 652500, loss = 1.06212
I0526 06:24:58.514972 30759 solver.cpp:253]     Train net output #0: loss = 1.06212 (* 1 = 1.06212 loss)
I0526 06:24:58.515002 30759 sgd_solver.cpp:106] Iteration 652500, lr = 0.002
I0526 06:25:15.154947 30759 solver.cpp:237] Iteration 654000, loss = 0.997968
I0526 06:25:15.155104 30759 solver.cpp:253]     Train net output #0: loss = 0.997973 (* 1 = 0.997973 loss)
I0526 06:25:15.155122 30759 sgd_solver.cpp:106] Iteration 654000, lr = 0.002
I0526 06:25:32.016443 30759 solver.cpp:237] Iteration 655500, loss = 1.33109
I0526 06:25:32.016501 30759 solver.cpp:253]     Train net output #0: loss = 1.3311 (* 1 = 1.3311 loss)
I0526 06:25:32.016518 30759 sgd_solver.cpp:106] Iteration 655500, lr = 0.002
I0526 06:25:48.856958 30759 solver.cpp:237] Iteration 657000, loss = 1.51652
I0526 06:25:48.857141 30759 solver.cpp:253]     Train net output #0: loss = 1.51653 (* 1 = 1.51653 loss)
I0526 06:25:48.857158 30759 sgd_solver.cpp:106] Iteration 657000, lr = 0.002
I0526 06:26:05.639771 30759 solver.cpp:237] Iteration 658500, loss = 1.35316
I0526 06:26:05.639814 30759 solver.cpp:253]     Train net output #0: loss = 1.35317 (* 1 = 1.35317 loss)
I0526 06:26:05.639832 30759 sgd_solver.cpp:106] Iteration 658500, lr = 0.002
I0526 06:26:22.286744 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_660000.caffemodel
I0526 06:26:22.333843 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_660000.solverstate
I0526 06:26:22.360945 30759 solver.cpp:341] Iteration 660000, Testing net (#0)
I0526 06:27:21.731009 30759 solver.cpp:409]     Test net output #0: accuracy = 0.903173
I0526 06:27:21.731184 30759 solver.cpp:409]     Test net output #1: loss = 0.328296 (* 1 = 0.328296 loss)
I0526 06:27:42.551925 30759 solver.cpp:237] Iteration 660000, loss = 0.617705
I0526 06:27:42.551990 30759 solver.cpp:253]     Train net output #0: loss = 0.617709 (* 1 = 0.617709 loss)
I0526 06:27:42.552017 30759 sgd_solver.cpp:106] Iteration 660000, lr = 0.002
I0526 06:27:59.292901 30759 solver.cpp:237] Iteration 661500, loss = 0.745529
I0526 06:27:59.293079 30759 solver.cpp:253]     Train net output #0: loss = 0.745533 (* 1 = 0.745533 loss)
I0526 06:27:59.293097 30759 sgd_solver.cpp:106] Iteration 661500, lr = 0.002
I0526 06:28:16.030494 30759 solver.cpp:237] Iteration 663000, loss = 1.05848
I0526 06:28:16.030550 30759 solver.cpp:253]     Train net output #0: loss = 1.05848 (* 1 = 1.05848 loss)
I0526 06:28:16.030578 30759 sgd_solver.cpp:106] Iteration 663000, lr = 0.002
I0526 06:28:33.241860 30759 solver.cpp:237] Iteration 664500, loss = 0.71287
I0526 06:28:33.242030 30759 solver.cpp:253]     Train net output #0: loss = 0.712873 (* 1 = 0.712873 loss)
I0526 06:28:33.242048 30759 sgd_solver.cpp:106] Iteration 664500, lr = 0.002
I0526 06:28:50.169543 30759 solver.cpp:237] Iteration 666000, loss = 1.10541
I0526 06:28:50.169603 30759 solver.cpp:253]     Train net output #0: loss = 1.10542 (* 1 = 1.10542 loss)
I0526 06:28:50.169621 30759 sgd_solver.cpp:106] Iteration 666000, lr = 0.002
I0526 06:29:06.989954 30759 solver.cpp:237] Iteration 667500, loss = 0.920502
I0526 06:29:06.990134 30759 solver.cpp:253]     Train net output #0: loss = 0.920506 (* 1 = 0.920506 loss)
I0526 06:29:06.990151 30759 sgd_solver.cpp:106] Iteration 667500, lr = 0.002
I0526 06:29:23.636633 30759 solver.cpp:237] Iteration 669000, loss = 1.05247
I0526 06:29:23.636673 30759 solver.cpp:253]     Train net output #0: loss = 1.05247 (* 1 = 1.05247 loss)
I0526 06:29:23.636690 30759 sgd_solver.cpp:106] Iteration 669000, lr = 0.002
I0526 06:30:01.270294 30759 solver.cpp:237] Iteration 670500, loss = 1.25179
I0526 06:30:01.270476 30759 solver.cpp:253]     Train net output #0: loss = 1.25179 (* 1 = 1.25179 loss)
I0526 06:30:01.270494 30759 sgd_solver.cpp:106] Iteration 670500, lr = 0.002
I0526 06:30:18.164463 30759 solver.cpp:237] Iteration 672000, loss = 1.24462
I0526 06:30:18.164517 30759 solver.cpp:253]     Train net output #0: loss = 1.24462 (* 1 = 1.24462 loss)
I0526 06:30:18.164535 30759 sgd_solver.cpp:106] Iteration 672000, lr = 0.002
I0526 06:30:35.206982 30759 solver.cpp:237] Iteration 673500, loss = 0.461968
I0526 06:30:35.207140 30759 solver.cpp:253]     Train net output #0: loss = 0.461973 (* 1 = 0.461973 loss)
I0526 06:30:35.207157 30759 sgd_solver.cpp:106] Iteration 673500, lr = 0.002
I0526 06:30:52.073479 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_675000.caffemodel
I0526 06:30:52.121994 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_675000.solverstate
I0526 06:30:52.153483 30759 solver.cpp:237] Iteration 675000, loss = 1.54463
I0526 06:30:52.153542 30759 solver.cpp:253]     Train net output #0: loss = 1.54464 (* 1 = 1.54464 loss)
I0526 06:30:52.153569 30759 sgd_solver.cpp:106] Iteration 675000, lr = 0.002
I0526 06:31:08.986575 30759 solver.cpp:237] Iteration 676500, loss = 1.1299
I0526 06:31:08.986752 30759 solver.cpp:253]     Train net output #0: loss = 1.12991 (* 1 = 1.12991 loss)
I0526 06:31:08.986770 30759 sgd_solver.cpp:106] Iteration 676500, lr = 0.002
I0526 06:31:26.049003 30759 solver.cpp:237] Iteration 678000, loss = 0.921792
I0526 06:31:26.049046 30759 solver.cpp:253]     Train net output #0: loss = 0.921798 (* 1 = 0.921798 loss)
I0526 06:31:26.049063 30759 sgd_solver.cpp:106] Iteration 678000, lr = 0.002
I0526 06:31:42.944903 30759 solver.cpp:237] Iteration 679500, loss = 0.959862
I0526 06:31:42.945080 30759 solver.cpp:253]     Train net output #0: loss = 0.959868 (* 1 = 0.959868 loss)
I0526 06:31:42.945097 30759 sgd_solver.cpp:106] Iteration 679500, lr = 0.002
I0526 06:32:20.670171 30759 solver.cpp:237] Iteration 681000, loss = 1.31561
I0526 06:32:20.670356 30759 solver.cpp:253]     Train net output #0: loss = 1.31562 (* 1 = 1.31562 loss)
I0526 06:32:20.670374 30759 sgd_solver.cpp:106] Iteration 681000, lr = 0.002
I0526 06:32:37.618216 30759 solver.cpp:237] Iteration 682500, loss = 0.878874
I0526 06:32:37.618276 30759 solver.cpp:253]     Train net output #0: loss = 0.878879 (* 1 = 0.878879 loss)
I0526 06:32:37.618294 30759 sgd_solver.cpp:106] Iteration 682500, lr = 0.002
I0526 06:32:54.706858 30759 solver.cpp:237] Iteration 684000, loss = 1.4827
I0526 06:32:54.707046 30759 solver.cpp:253]     Train net output #0: loss = 1.48271 (* 1 = 1.48271 loss)
I0526 06:32:54.707063 30759 sgd_solver.cpp:106] Iteration 684000, lr = 0.002
I0526 06:33:11.893491 30759 solver.cpp:237] Iteration 685500, loss = 1.20669
I0526 06:33:11.893550 30759 solver.cpp:253]     Train net output #0: loss = 1.2067 (* 1 = 1.2067 loss)
I0526 06:33:11.893580 30759 sgd_solver.cpp:106] Iteration 685500, lr = 0.002
I0526 06:33:28.864348 30759 solver.cpp:237] Iteration 687000, loss = 1.75844
I0526 06:33:28.864509 30759 solver.cpp:253]     Train net output #0: loss = 1.75845 (* 1 = 1.75845 loss)
I0526 06:33:28.864526 30759 sgd_solver.cpp:106] Iteration 687000, lr = 0.002
I0526 06:33:45.813004 30759 solver.cpp:237] Iteration 688500, loss = 0.554942
I0526 06:33:45.813065 30759 solver.cpp:253]     Train net output #0: loss = 0.554948 (* 1 = 0.554948 loss)
I0526 06:33:45.813081 30759 sgd_solver.cpp:106] Iteration 688500, lr = 0.002
I0526 06:34:02.767403 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_690000.caffemodel
I0526 06:34:02.813542 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_690000.solverstate
I0526 06:34:02.839107 30759 solver.cpp:341] Iteration 690000, Testing net (#0)
I0526 06:35:23.259351 30759 solver.cpp:409]     Test net output #0: accuracy = 0.901858
I0526 06:35:23.259529 30759 solver.cpp:409]     Test net output #1: loss = 0.316372 (* 1 = 0.316372 loss)
I0526 06:35:44.104157 30759 solver.cpp:237] Iteration 690000, loss = 1.13744
I0526 06:35:44.104221 30759 solver.cpp:253]     Train net output #0: loss = 1.13745 (* 1 = 1.13745 loss)
I0526 06:35:44.104250 30759 sgd_solver.cpp:106] Iteration 690000, lr = 0.002
I0526 06:36:00.929517 30759 solver.cpp:237] Iteration 691500, loss = 0.876463
I0526 06:36:00.929675 30759 solver.cpp:253]     Train net output #0: loss = 0.876468 (* 1 = 0.876468 loss)
I0526 06:36:00.929692 30759 sgd_solver.cpp:106] Iteration 691500, lr = 0.002
I0526 06:36:17.877255 30759 solver.cpp:237] Iteration 693000, loss = 1.37578
I0526 06:36:17.877315 30759 solver.cpp:253]     Train net output #0: loss = 1.37578 (* 1 = 1.37578 loss)
I0526 06:36:17.877333 30759 sgd_solver.cpp:106] Iteration 693000, lr = 0.002
I0526 06:36:34.988971 30759 solver.cpp:237] Iteration 694500, loss = 1.12448
I0526 06:36:34.989151 30759 solver.cpp:253]     Train net output #0: loss = 1.12448 (* 1 = 1.12448 loss)
I0526 06:36:34.989171 30759 sgd_solver.cpp:106] Iteration 694500, lr = 0.002
I0526 06:36:52.209223 30759 solver.cpp:237] Iteration 696000, loss = 0.649076
I0526 06:36:52.209262 30759 solver.cpp:253]     Train net output #0: loss = 0.649081 (* 1 = 0.649081 loss)
I0526 06:36:52.209280 30759 sgd_solver.cpp:106] Iteration 696000, lr = 0.002
I0526 06:37:08.994738 30759 solver.cpp:237] Iteration 697500, loss = 1.34551
I0526 06:37:08.994916 30759 solver.cpp:253]     Train net output #0: loss = 1.34552 (* 1 = 1.34552 loss)
I0526 06:37:08.994933 30759 sgd_solver.cpp:106] Iteration 697500, lr = 0.002
I0526 06:37:25.674901 30759 solver.cpp:237] Iteration 699000, loss = 1.27764
I0526 06:37:25.674955 30759 solver.cpp:253]     Train net output #0: loss = 1.27764 (* 1 = 1.27764 loss)
I0526 06:37:25.674973 30759 sgd_solver.cpp:106] Iteration 699000, lr = 0.002
I0526 06:38:03.317991 30759 solver.cpp:237] Iteration 700500, loss = 0.940234
I0526 06:38:03.318173 30759 solver.cpp:253]     Train net output #0: loss = 0.940237 (* 1 = 0.940237 loss)
I0526 06:38:03.318192 30759 sgd_solver.cpp:106] Iteration 700500, lr = 0.002
I0526 06:38:20.069969 30759 solver.cpp:237] Iteration 702000, loss = 1.11452
I0526 06:38:20.070026 30759 solver.cpp:253]     Train net output #0: loss = 1.11453 (* 1 = 1.11453 loss)
I0526 06:38:20.070044 30759 sgd_solver.cpp:106] Iteration 702000, lr = 0.002
I0526 06:38:36.671142 30759 solver.cpp:237] Iteration 703500, loss = 1.55064
I0526 06:38:36.671313 30759 solver.cpp:253]     Train net output #0: loss = 1.55064 (* 1 = 1.55064 loss)
I0526 06:38:36.671329 30759 sgd_solver.cpp:106] Iteration 703500, lr = 0.002
I0526 06:38:53.731374 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_705000.caffemodel
I0526 06:38:53.786778 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_705000.solverstate
I0526 06:38:53.821545 30759 solver.cpp:237] Iteration 705000, loss = 0.953117
I0526 06:38:53.821609 30759 solver.cpp:253]     Train net output #0: loss = 0.953119 (* 1 = 0.953119 loss)
I0526 06:38:53.821627 30759 sgd_solver.cpp:106] Iteration 705000, lr = 0.002
I0526 06:39:10.903812 30759 solver.cpp:237] Iteration 706500, loss = 0.772045
I0526 06:39:10.903997 30759 solver.cpp:253]     Train net output #0: loss = 0.772047 (* 1 = 0.772047 loss)
I0526 06:39:10.904014 30759 sgd_solver.cpp:106] Iteration 706500, lr = 0.002
I0526 06:39:27.953119 30759 solver.cpp:237] Iteration 708000, loss = 0.992485
I0526 06:39:27.953181 30759 solver.cpp:253]     Train net output #0: loss = 0.992487 (* 1 = 0.992487 loss)
I0526 06:39:27.953207 30759 sgd_solver.cpp:106] Iteration 708000, lr = 0.002
I0526 06:39:45.186470 30759 solver.cpp:237] Iteration 709500, loss = 1.19786
I0526 06:39:45.186632 30759 solver.cpp:253]     Train net output #0: loss = 1.19786 (* 1 = 1.19786 loss)
I0526 06:39:45.186648 30759 sgd_solver.cpp:106] Iteration 709500, lr = 0.002
I0526 06:40:23.177233 30759 solver.cpp:237] Iteration 711000, loss = 1.00297
I0526 06:40:23.177417 30759 solver.cpp:253]     Train net output #0: loss = 1.00297 (* 1 = 1.00297 loss)
I0526 06:40:23.177433 30759 sgd_solver.cpp:106] Iteration 711000, lr = 0.002
I0526 06:40:40.206578 30759 solver.cpp:237] Iteration 712500, loss = 1.86356
I0526 06:40:40.206616 30759 solver.cpp:253]     Train net output #0: loss = 1.86356 (* 1 = 1.86356 loss)
I0526 06:40:40.206635 30759 sgd_solver.cpp:106] Iteration 712500, lr = 0.002
I0526 06:40:57.199995 30759 solver.cpp:237] Iteration 714000, loss = 1.87862
I0526 06:40:57.200173 30759 solver.cpp:253]     Train net output #0: loss = 1.87862 (* 1 = 1.87862 loss)
I0526 06:40:57.200191 30759 sgd_solver.cpp:106] Iteration 714000, lr = 0.002
I0526 06:41:14.097460 30759 solver.cpp:237] Iteration 715500, loss = 1.21208
I0526 06:41:14.097512 30759 solver.cpp:253]     Train net output #0: loss = 1.21208 (* 1 = 1.21208 loss)
I0526 06:41:14.097529 30759 sgd_solver.cpp:106] Iteration 715500, lr = 0.002
I0526 06:41:30.895567 30759 solver.cpp:237] Iteration 717000, loss = 0.96838
I0526 06:41:30.895725 30759 solver.cpp:253]     Train net output #0: loss = 0.96838 (* 1 = 0.96838 loss)
I0526 06:41:30.895741 30759 sgd_solver.cpp:106] Iteration 717000, lr = 0.002
I0526 06:41:47.785444 30759 solver.cpp:237] Iteration 718500, loss = 1.30854
I0526 06:41:47.785503 30759 solver.cpp:253]     Train net output #0: loss = 1.30854 (* 1 = 1.30854 loss)
I0526 06:41:47.785521 30759 sgd_solver.cpp:106] Iteration 718500, lr = 0.002
I0526 06:42:04.555248 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_720000.caffemodel
I0526 06:42:04.613524 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_720000.solverstate
I0526 06:42:04.649709 30759 solver.cpp:341] Iteration 720000, Testing net (#0)
I0526 06:43:04.317314 30759 solver.cpp:409]     Test net output #0: accuracy = 0.901058
I0526 06:43:04.317523 30759 solver.cpp:409]     Test net output #1: loss = 0.316286 (* 1 = 0.316286 loss)
I0526 06:43:25.158504 30759 solver.cpp:237] Iteration 720000, loss = 1.886
I0526 06:43:25.158567 30759 solver.cpp:253]     Train net output #0: loss = 1.886 (* 1 = 1.886 loss)
I0526 06:43:25.158596 30759 sgd_solver.cpp:106] Iteration 720000, lr = 0.002
I0526 06:43:42.139298 30759 solver.cpp:237] Iteration 721500, loss = 1.73113
I0526 06:43:42.139485 30759 solver.cpp:253]     Train net output #0: loss = 1.73113 (* 1 = 1.73113 loss)
I0526 06:43:42.139503 30759 sgd_solver.cpp:106] Iteration 721500, lr = 0.002
I0526 06:43:58.777828 30759 solver.cpp:237] Iteration 723000, loss = 0.690186
I0526 06:43:58.777866 30759 solver.cpp:253]     Train net output #0: loss = 0.690187 (* 1 = 0.690187 loss)
I0526 06:43:58.777885 30759 sgd_solver.cpp:106] Iteration 723000, lr = 0.002
I0526 06:44:15.684803 30759 solver.cpp:237] Iteration 724500, loss = 1.1643
I0526 06:44:15.684980 30759 solver.cpp:253]     Train net output #0: loss = 1.1643 (* 1 = 1.1643 loss)
I0526 06:44:15.684998 30759 sgd_solver.cpp:106] Iteration 724500, lr = 0.002
I0526 06:44:32.716476 30759 solver.cpp:237] Iteration 726000, loss = 1.24815
I0526 06:44:32.716531 30759 solver.cpp:253]     Train net output #0: loss = 1.24815 (* 1 = 1.24815 loss)
I0526 06:44:32.716552 30759 sgd_solver.cpp:106] Iteration 726000, lr = 0.002
I0526 06:44:49.928370 30759 solver.cpp:237] Iteration 727500, loss = 0.972656
I0526 06:44:49.928534 30759 solver.cpp:253]     Train net output #0: loss = 0.972656 (* 1 = 0.972656 loss)
I0526 06:44:49.928552 30759 sgd_solver.cpp:106] Iteration 727500, lr = 0.002
I0526 06:45:07.143877 30759 solver.cpp:237] Iteration 729000, loss = 0.649037
I0526 06:45:07.143934 30759 solver.cpp:253]     Train net output #0: loss = 0.649037 (* 1 = 0.649037 loss)
I0526 06:45:07.143951 30759 sgd_solver.cpp:106] Iteration 729000, lr = 0.002
I0526 06:45:45.064249 30759 solver.cpp:237] Iteration 730500, loss = 0.998112
I0526 06:45:45.064435 30759 solver.cpp:253]     Train net output #0: loss = 0.998113 (* 1 = 0.998113 loss)
I0526 06:45:45.064453 30759 sgd_solver.cpp:106] Iteration 730500, lr = 0.002
I0526 06:46:02.114518 30759 solver.cpp:237] Iteration 732000, loss = 1.25915
I0526 06:46:02.114557 30759 solver.cpp:253]     Train net output #0: loss = 1.25915 (* 1 = 1.25915 loss)
I0526 06:46:02.114574 30759 sgd_solver.cpp:106] Iteration 732000, lr = 0.002
I0526 06:46:18.854071 30759 solver.cpp:237] Iteration 733500, loss = 0.836966
I0526 06:46:18.854249 30759 solver.cpp:253]     Train net output #0: loss = 0.836968 (* 1 = 0.836968 loss)
I0526 06:46:18.854266 30759 sgd_solver.cpp:106] Iteration 733500, lr = 0.002
I0526 06:46:35.509066 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_735000.caffemodel
I0526 06:46:35.563292 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_735000.solverstate
I0526 06:46:35.601996 30759 solver.cpp:237] Iteration 735000, loss = 2.25826
I0526 06:46:35.602056 30759 solver.cpp:253]     Train net output #0: loss = 2.25826 (* 1 = 2.25826 loss)
I0526 06:46:35.602073 30759 sgd_solver.cpp:106] Iteration 735000, lr = 0.002
I0526 06:46:52.414605 30759 solver.cpp:237] Iteration 736500, loss = 0.950043
I0526 06:46:52.414772 30759 solver.cpp:253]     Train net output #0: loss = 0.950047 (* 1 = 0.950047 loss)
I0526 06:46:52.414789 30759 sgd_solver.cpp:106] Iteration 736500, lr = 0.002
I0526 06:47:09.507342 30759 solver.cpp:237] Iteration 738000, loss = 1.56465
I0526 06:47:09.507398 30759 solver.cpp:253]     Train net output #0: loss = 1.56465 (* 1 = 1.56465 loss)
I0526 06:47:09.507416 30759 sgd_solver.cpp:106] Iteration 738000, lr = 0.002
I0526 06:47:26.686100 30759 solver.cpp:237] Iteration 739500, loss = 0.689876
I0526 06:47:26.686282 30759 solver.cpp:253]     Train net output #0: loss = 0.689881 (* 1 = 0.689881 loss)
I0526 06:47:26.686300 30759 sgd_solver.cpp:106] Iteration 739500, lr = 0.002
I0526 06:48:04.613387 30759 solver.cpp:237] Iteration 741000, loss = 0.345405
I0526 06:48:04.613591 30759 solver.cpp:253]     Train net output #0: loss = 0.34541 (* 1 = 0.34541 loss)
I0526 06:48:04.613610 30759 sgd_solver.cpp:106] Iteration 741000, lr = 0.002
I0526 06:48:21.530442 30759 solver.cpp:237] Iteration 742500, loss = 1.5402
I0526 06:48:21.530499 30759 solver.cpp:253]     Train net output #0: loss = 1.5402 (* 1 = 1.5402 loss)
I0526 06:48:21.530516 30759 sgd_solver.cpp:106] Iteration 742500, lr = 0.002
I0526 06:48:38.355325 30759 solver.cpp:237] Iteration 744000, loss = 1.12122
I0526 06:48:38.355509 30759 solver.cpp:253]     Train net output #0: loss = 1.12122 (* 1 = 1.12122 loss)
I0526 06:48:38.355527 30759 sgd_solver.cpp:106] Iteration 744000, lr = 0.002
I0526 06:48:55.252352 30759 solver.cpp:237] Iteration 745500, loss = 1.61838
I0526 06:48:55.252391 30759 solver.cpp:253]     Train net output #0: loss = 1.61839 (* 1 = 1.61839 loss)
I0526 06:48:55.252408 30759 sgd_solver.cpp:106] Iteration 745500, lr = 0.002
I0526 06:49:11.999990 30759 solver.cpp:237] Iteration 747000, loss = 1.29433
I0526 06:49:12.000169 30759 solver.cpp:253]     Train net output #0: loss = 1.29433 (* 1 = 1.29433 loss)
I0526 06:49:12.000185 30759 sgd_solver.cpp:106] Iteration 747000, lr = 0.002
I0526 06:49:28.716598 30759 solver.cpp:237] Iteration 748500, loss = 0.48062
I0526 06:49:28.716658 30759 solver.cpp:253]     Train net output #0: loss = 0.480623 (* 1 = 0.480623 loss)
I0526 06:49:28.716683 30759 sgd_solver.cpp:106] Iteration 748500, lr = 0.002
I0526 06:49:45.913543 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_750000.caffemodel
I0526 06:49:45.972009 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_750000.solverstate
I0526 06:49:46.012523 30759 solver.cpp:341] Iteration 750000, Testing net (#0)
I0526 06:51:06.417897 30759 solver.cpp:409]     Test net output #0: accuracy = 0.903259
I0526 06:51:06.418081 30759 solver.cpp:409]     Test net output #1: loss = 0.3118 (* 1 = 0.3118 loss)
I0526 06:51:27.244925 30759 solver.cpp:237] Iteration 750000, loss = 1.0511
I0526 06:51:27.244987 30759 solver.cpp:253]     Train net output #0: loss = 1.05111 (* 1 = 1.05111 loss)
I0526 06:51:27.245012 30759 sgd_solver.cpp:106] Iteration 750000, lr = 0.002
I0526 06:51:44.072533 30759 solver.cpp:237] Iteration 751500, loss = 1.30466
I0526 06:51:44.072710 30759 solver.cpp:253]     Train net output #0: loss = 1.30466 (* 1 = 1.30466 loss)
I0526 06:51:44.072727 30759 sgd_solver.cpp:106] Iteration 751500, lr = 0.002
I0526 06:52:00.908345 30759 solver.cpp:237] Iteration 753000, loss = 1.21626
I0526 06:52:00.908393 30759 solver.cpp:253]     Train net output #0: loss = 1.21627 (* 1 = 1.21627 loss)
I0526 06:52:00.908419 30759 sgd_solver.cpp:106] Iteration 753000, lr = 0.002
I0526 06:52:17.541610 30759 solver.cpp:237] Iteration 754500, loss = 1.16322
I0526 06:52:17.541769 30759 solver.cpp:253]     Train net output #0: loss = 1.16323 (* 1 = 1.16323 loss)
I0526 06:52:17.541786 30759 sgd_solver.cpp:106] Iteration 754500, lr = 0.002
I0526 06:52:34.140699 30759 solver.cpp:237] Iteration 756000, loss = 1.07349
I0526 06:52:34.140751 30759 solver.cpp:253]     Train net output #0: loss = 1.0735 (* 1 = 1.0735 loss)
I0526 06:52:34.140769 30759 sgd_solver.cpp:106] Iteration 756000, lr = 0.002
I0526 06:52:50.866466 30759 solver.cpp:237] Iteration 757500, loss = 0.827754
I0526 06:52:50.866641 30759 solver.cpp:253]     Train net output #0: loss = 0.827757 (* 1 = 0.827757 loss)
I0526 06:52:50.866659 30759 sgd_solver.cpp:106] Iteration 757500, lr = 0.002
I0526 06:53:07.868654 30759 solver.cpp:237] Iteration 759000, loss = 1.10632
I0526 06:53:07.868691 30759 solver.cpp:253]     Train net output #0: loss = 1.10632 (* 1 = 1.10632 loss)
I0526 06:53:07.868710 30759 sgd_solver.cpp:106] Iteration 759000, lr = 0.002
I0526 06:53:45.716652 30759 solver.cpp:237] Iteration 760500, loss = 0.723015
I0526 06:53:45.716846 30759 solver.cpp:253]     Train net output #0: loss = 0.723018 (* 1 = 0.723018 loss)
I0526 06:53:45.716864 30759 sgd_solver.cpp:106] Iteration 760500, lr = 0.002
I0526 06:54:02.757036 30759 solver.cpp:237] Iteration 762000, loss = 1.48935
I0526 06:54:02.757091 30759 solver.cpp:253]     Train net output #0: loss = 1.48935 (* 1 = 1.48935 loss)
I0526 06:54:02.757109 30759 sgd_solver.cpp:106] Iteration 762000, lr = 0.002
I0526 06:54:19.576575 30759 solver.cpp:237] Iteration 763500, loss = 1.1824
I0526 06:54:19.576740 30759 solver.cpp:253]     Train net output #0: loss = 1.18241 (* 1 = 1.18241 loss)
I0526 06:54:19.576757 30759 sgd_solver.cpp:106] Iteration 763500, lr = 0.002
I0526 06:54:36.254428 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_765000.caffemodel
I0526 06:54:36.310096 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_765000.solverstate
I0526 06:54:36.345314 30759 solver.cpp:237] Iteration 765000, loss = 1.34488
I0526 06:54:36.345371 30759 solver.cpp:253]     Train net output #0: loss = 1.34489 (* 1 = 1.34489 loss)
I0526 06:54:36.345397 30759 sgd_solver.cpp:106] Iteration 765000, lr = 0.002
I0526 06:54:53.026451 30759 solver.cpp:237] Iteration 766500, loss = 1.12034
I0526 06:54:53.026638 30759 solver.cpp:253]     Train net output #0: loss = 1.12035 (* 1 = 1.12035 loss)
I0526 06:54:53.026655 30759 sgd_solver.cpp:106] Iteration 766500, lr = 0.002
I0526 06:55:09.983172 30759 solver.cpp:237] Iteration 768000, loss = 0.630608
I0526 06:55:09.983213 30759 solver.cpp:253]     Train net output #0: loss = 0.630611 (* 1 = 0.630611 loss)
I0526 06:55:09.983230 30759 sgd_solver.cpp:106] Iteration 768000, lr = 0.002
I0526 06:55:26.749874 30759 solver.cpp:237] Iteration 769500, loss = 1.23816
I0526 06:55:26.750052 30759 solver.cpp:253]     Train net output #0: loss = 1.23817 (* 1 = 1.23817 loss)
I0526 06:55:26.750071 30759 sgd_solver.cpp:106] Iteration 769500, lr = 0.002
I0526 06:56:04.218386 30759 solver.cpp:237] Iteration 771000, loss = 1.20489
I0526 06:56:04.218571 30759 solver.cpp:253]     Train net output #0: loss = 1.20489 (* 1 = 1.20489 loss)
I0526 06:56:04.218588 30759 sgd_solver.cpp:106] Iteration 771000, lr = 0.002
I0526 06:56:21.073428 30759 solver.cpp:237] Iteration 772500, loss = 0.828068
I0526 06:56:21.073494 30759 solver.cpp:253]     Train net output #0: loss = 0.828072 (* 1 = 0.828072 loss)
I0526 06:56:21.073513 30759 sgd_solver.cpp:106] Iteration 772500, lr = 0.002
I0526 06:56:38.036867 30759 solver.cpp:237] Iteration 774000, loss = 0.989098
I0526 06:56:38.037052 30759 solver.cpp:253]     Train net output #0: loss = 0.989102 (* 1 = 0.989102 loss)
I0526 06:56:38.037070 30759 sgd_solver.cpp:106] Iteration 774000, lr = 0.002
I0526 06:56:55.092952 30759 solver.cpp:237] Iteration 775500, loss = 1.25777
I0526 06:56:55.092990 30759 solver.cpp:253]     Train net output #0: loss = 1.25777 (* 1 = 1.25777 loss)
I0526 06:56:55.093009 30759 sgd_solver.cpp:106] Iteration 775500, lr = 0.002
I0526 06:57:11.890813 30759 solver.cpp:237] Iteration 777000, loss = 0.574228
I0526 06:57:11.891015 30759 solver.cpp:253]     Train net output #0: loss = 0.574233 (* 1 = 0.574233 loss)
I0526 06:57:11.891032 30759 sgd_solver.cpp:106] Iteration 777000, lr = 0.002
I0526 06:57:28.848316 30759 solver.cpp:237] Iteration 778500, loss = 1.28204
I0526 06:57:28.848374 30759 solver.cpp:253]     Train net output #0: loss = 1.28204 (* 1 = 1.28204 loss)
I0526 06:57:28.848392 30759 sgd_solver.cpp:106] Iteration 778500, lr = 0.002
I0526 06:57:46.058342 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_780000.caffemodel
I0526 06:57:46.111981 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_780000.solverstate
I0526 06:57:46.146838 30759 solver.cpp:341] Iteration 780000, Testing net (#0)
I0526 06:58:45.445941 30759 solver.cpp:409]     Test net output #0: accuracy = 0.903425
I0526 06:58:45.446131 30759 solver.cpp:409]     Test net output #1: loss = 0.312472 (* 1 = 0.312472 loss)
I0526 06:59:06.279252 30759 solver.cpp:237] Iteration 780000, loss = 1.48044
I0526 06:59:06.279312 30759 solver.cpp:253]     Train net output #0: loss = 1.48045 (* 1 = 1.48045 loss)
I0526 06:59:06.279338 30759 sgd_solver.cpp:106] Iteration 780000, lr = 0.002
I0526 06:59:23.178427 30759 solver.cpp:237] Iteration 781500, loss = 0.99968
I0526 06:59:23.178611 30759 solver.cpp:253]     Train net output #0: loss = 0.999685 (* 1 = 0.999685 loss)
I0526 06:59:23.178627 30759 sgd_solver.cpp:106] Iteration 781500, lr = 0.002
I0526 06:59:40.126209 30759 solver.cpp:237] Iteration 783000, loss = 0.863824
I0526 06:59:40.126269 30759 solver.cpp:253]     Train net output #0: loss = 0.863829 (* 1 = 0.863829 loss)
I0526 06:59:40.126286 30759 sgd_solver.cpp:106] Iteration 783000, lr = 0.002
I0526 06:59:57.081498 30759 solver.cpp:237] Iteration 784500, loss = 1.15137
I0526 06:59:57.081676 30759 solver.cpp:253]     Train net output #0: loss = 1.15137 (* 1 = 1.15137 loss)
I0526 06:59:57.081694 30759 sgd_solver.cpp:106] Iteration 784500, lr = 0.002
I0526 07:00:13.977592 30759 solver.cpp:237] Iteration 786000, loss = 1.56523
I0526 07:00:13.977629 30759 solver.cpp:253]     Train net output #0: loss = 1.56523 (* 1 = 1.56523 loss)
I0526 07:00:13.977653 30759 sgd_solver.cpp:106] Iteration 786000, lr = 0.002
I0526 07:00:31.149533 30759 solver.cpp:237] Iteration 787500, loss = 0.8872
I0526 07:00:31.149715 30759 solver.cpp:253]     Train net output #0: loss = 0.887205 (* 1 = 0.887205 loss)
I0526 07:00:31.149732 30759 sgd_solver.cpp:106] Iteration 787500, lr = 0.002
I0526 07:00:48.140715 30759 solver.cpp:237] Iteration 789000, loss = 1.17354
I0526 07:00:48.140775 30759 solver.cpp:253]     Train net output #0: loss = 1.17354 (* 1 = 1.17354 loss)
I0526 07:00:48.140799 30759 sgd_solver.cpp:106] Iteration 789000, lr = 0.002
I0526 07:01:25.666188 30759 solver.cpp:237] Iteration 790500, loss = 1.76545
I0526 07:01:25.666378 30759 solver.cpp:253]     Train net output #0: loss = 1.76546 (* 1 = 1.76546 loss)
I0526 07:01:25.666396 30759 sgd_solver.cpp:106] Iteration 790500, lr = 0.002
I0526 07:01:42.670125 30759 solver.cpp:237] Iteration 792000, loss = 0.95614
I0526 07:01:42.670184 30759 solver.cpp:253]     Train net output #0: loss = 0.956145 (* 1 = 0.956145 loss)
I0526 07:01:42.670202 30759 sgd_solver.cpp:106] Iteration 792000, lr = 0.002
I0526 07:01:59.791993 30759 solver.cpp:237] Iteration 793500, loss = 1.25263
I0526 07:01:59.792179 30759 solver.cpp:253]     Train net output #0: loss = 1.25264 (* 1 = 1.25264 loss)
I0526 07:01:59.792197 30759 sgd_solver.cpp:106] Iteration 793500, lr = 0.002
I0526 07:02:16.785425 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_795000.caffemodel
I0526 07:02:16.838166 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_795000.solverstate
I0526 07:02:16.878633 30759 solver.cpp:237] Iteration 795000, loss = 0.844083
I0526 07:02:16.878691 30759 solver.cpp:253]     Train net output #0: loss = 0.844087 (* 1 = 0.844087 loss)
I0526 07:02:16.878711 30759 sgd_solver.cpp:106] Iteration 795000, lr = 0.002
I0526 07:02:33.604419 30759 solver.cpp:237] Iteration 796500, loss = 0.99864
I0526 07:02:33.604606 30759 solver.cpp:253]     Train net output #0: loss = 0.998644 (* 1 = 0.998644 loss)
I0526 07:02:33.604624 30759 sgd_solver.cpp:106] Iteration 796500, lr = 0.002
I0526 07:02:50.388260 30759 solver.cpp:237] Iteration 798000, loss = 1.40259
I0526 07:02:50.388319 30759 solver.cpp:253]     Train net output #0: loss = 1.4026 (* 1 = 1.4026 loss)
I0526 07:02:50.388339 30759 sgd_solver.cpp:106] Iteration 798000, lr = 0.002
I0526 07:03:07.579475 30759 solver.cpp:237] Iteration 799500, loss = 0.728719
I0526 07:03:07.579656 30759 solver.cpp:253]     Train net output #0: loss = 0.728724 (* 1 = 0.728724 loss)
I0526 07:03:07.579674 30759 sgd_solver.cpp:106] Iteration 799500, lr = 0.002
I0526 07:03:45.399130 30759 solver.cpp:237] Iteration 801000, loss = 0.611292
I0526 07:03:45.399320 30759 solver.cpp:253]     Train net output #0: loss = 0.611296 (* 1 = 0.611296 loss)
I0526 07:03:45.399338 30759 sgd_solver.cpp:106] Iteration 801000, lr = 0.002
I0526 07:04:02.422972 30759 solver.cpp:237] Iteration 802500, loss = 0.212375
I0526 07:04:02.423030 30759 solver.cpp:253]     Train net output #0: loss = 0.212378 (* 1 = 0.212378 loss)
I0526 07:04:02.423058 30759 sgd_solver.cpp:106] Iteration 802500, lr = 0.002
I0526 07:04:19.041648 30759 solver.cpp:237] Iteration 804000, loss = 1.0944
I0526 07:04:19.041828 30759 solver.cpp:253]     Train net output #0: loss = 1.0944 (* 1 = 1.0944 loss)
I0526 07:04:19.041846 30759 sgd_solver.cpp:106] Iteration 804000, lr = 0.002
I0526 07:04:35.873766 30759 solver.cpp:237] Iteration 805500, loss = 0.973166
I0526 07:04:35.873826 30759 solver.cpp:253]     Train net output #0: loss = 0.97317 (* 1 = 0.97317 loss)
I0526 07:04:35.873850 30759 sgd_solver.cpp:106] Iteration 805500, lr = 0.002
I0526 07:04:52.846968 30759 solver.cpp:237] Iteration 807000, loss = 1.40754
I0526 07:04:52.847153 30759 solver.cpp:253]     Train net output #0: loss = 1.40755 (* 1 = 1.40755 loss)
I0526 07:04:52.847172 30759 sgd_solver.cpp:106] Iteration 807000, lr = 0.002
I0526 07:05:09.677094 30759 solver.cpp:237] Iteration 808500, loss = 0.858474
I0526 07:05:09.677135 30759 solver.cpp:253]     Train net output #0: loss = 0.858479 (* 1 = 0.858479 loss)
I0526 07:05:09.677152 30759 sgd_solver.cpp:106] Iteration 808500, lr = 0.002
I0526 07:05:26.368677 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_810000.caffemodel
I0526 07:05:26.425179 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_810000.solverstate
I0526 07:05:26.460243 30759 solver.cpp:341] Iteration 810000, Testing net (#0)
I0526 07:06:46.599076 30759 solver.cpp:409]     Test net output #0: accuracy = 0.904445
I0526 07:06:46.599261 30759 solver.cpp:409]     Test net output #1: loss = 0.314329 (* 1 = 0.314329 loss)
I0526 07:07:07.427510 30759 solver.cpp:237] Iteration 810000, loss = 0.803266
I0526 07:07:07.427577 30759 solver.cpp:253]     Train net output #0: loss = 0.80327 (* 1 = 0.80327 loss)
I0526 07:07:07.427605 30759 sgd_solver.cpp:106] Iteration 810000, lr = 0.002
I0526 07:07:24.076086 30759 solver.cpp:237] Iteration 811500, loss = 0.708909
I0526 07:07:24.076275 30759 solver.cpp:253]     Train net output #0: loss = 0.708914 (* 1 = 0.708914 loss)
I0526 07:07:24.076293 30759 sgd_solver.cpp:106] Iteration 811500, lr = 0.002
I0526 07:07:40.865231 30759 solver.cpp:237] Iteration 813000, loss = 1.28786
I0526 07:07:40.865268 30759 solver.cpp:253]     Train net output #0: loss = 1.28787 (* 1 = 1.28787 loss)
I0526 07:07:40.865288 30759 sgd_solver.cpp:106] Iteration 813000, lr = 0.002
I0526 07:07:57.539997 30759 solver.cpp:237] Iteration 814500, loss = 0.953896
I0526 07:07:57.540180 30759 solver.cpp:253]     Train net output #0: loss = 0.9539 (* 1 = 0.9539 loss)
I0526 07:07:57.540199 30759 sgd_solver.cpp:106] Iteration 814500, lr = 0.002
I0526 07:08:14.261770 30759 solver.cpp:237] Iteration 816000, loss = 1.02993
I0526 07:08:14.261826 30759 solver.cpp:253]     Train net output #0: loss = 1.02994 (* 1 = 1.02994 loss)
I0526 07:08:14.261843 30759 sgd_solver.cpp:106] Iteration 816000, lr = 0.002
I0526 07:08:31.454807 30759 solver.cpp:237] Iteration 817500, loss = 0.684868
I0526 07:08:31.454984 30759 solver.cpp:253]     Train net output #0: loss = 0.684873 (* 1 = 0.684873 loss)
I0526 07:08:31.455001 30759 sgd_solver.cpp:106] Iteration 817500, lr = 0.002
I0526 07:08:48.261575 30759 solver.cpp:237] Iteration 819000, loss = 0.802138
I0526 07:08:48.261631 30759 solver.cpp:253]     Train net output #0: loss = 0.802142 (* 1 = 0.802142 loss)
I0526 07:08:48.261649 30759 sgd_solver.cpp:106] Iteration 819000, lr = 0.002
I0526 07:09:25.770177 30759 solver.cpp:237] Iteration 820500, loss = 1.99169
I0526 07:09:25.770365 30759 solver.cpp:253]     Train net output #0: loss = 1.9917 (* 1 = 1.9917 loss)
I0526 07:09:25.770383 30759 sgd_solver.cpp:106] Iteration 820500, lr = 0.002
I0526 07:09:42.518578 30759 solver.cpp:237] Iteration 822000, loss = 1.34401
I0526 07:09:42.518636 30759 solver.cpp:253]     Train net output #0: loss = 1.34401 (* 1 = 1.34401 loss)
I0526 07:09:42.518654 30759 sgd_solver.cpp:106] Iteration 822000, lr = 0.002
I0526 07:09:59.504504 30759 solver.cpp:237] Iteration 823500, loss = 0.776382
I0526 07:09:59.504693 30759 solver.cpp:253]     Train net output #0: loss = 0.776385 (* 1 = 0.776385 loss)
I0526 07:09:59.504711 30759 sgd_solver.cpp:106] Iteration 823500, lr = 0.002
I0526 07:10:16.714051 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_825000.caffemodel
I0526 07:10:16.791846 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_825000.solverstate
I0526 07:10:16.832872 30759 solver.cpp:237] Iteration 825000, loss = 0.248662
I0526 07:10:16.832939 30759 solver.cpp:253]     Train net output #0: loss = 0.248665 (* 1 = 0.248665 loss)
I0526 07:10:16.832957 30759 sgd_solver.cpp:106] Iteration 825000, lr = 0.002
I0526 07:10:34.056915 30759 solver.cpp:237] Iteration 826500, loss = 1.58126
I0526 07:10:34.057088 30759 solver.cpp:253]     Train net output #0: loss = 1.58126 (* 1 = 1.58126 loss)
I0526 07:10:34.057104 30759 sgd_solver.cpp:106] Iteration 826500, lr = 0.002
I0526 07:10:51.071583 30759 solver.cpp:237] Iteration 828000, loss = 0.9269
I0526 07:10:51.071641 30759 solver.cpp:253]     Train net output #0: loss = 0.926902 (* 1 = 0.926902 loss)
I0526 07:10:51.071658 30759 sgd_solver.cpp:106] Iteration 828000, lr = 0.002
I0526 07:11:07.841696 30759 solver.cpp:237] Iteration 829500, loss = 1.53751
I0526 07:11:07.841883 30759 solver.cpp:253]     Train net output #0: loss = 1.53751 (* 1 = 1.53751 loss)
I0526 07:11:07.841902 30759 sgd_solver.cpp:106] Iteration 829500, lr = 0.002
I0526 07:11:45.324203 30759 solver.cpp:237] Iteration 831000, loss = 1.31743
I0526 07:11:45.324390 30759 solver.cpp:253]     Train net output #0: loss = 1.31743 (* 1 = 1.31743 loss)
I0526 07:11:45.324409 30759 sgd_solver.cpp:106] Iteration 831000, lr = 0.002
I0526 07:12:01.936156 30759 solver.cpp:237] Iteration 832500, loss = 1.64285
I0526 07:12:01.936213 30759 solver.cpp:253]     Train net output #0: loss = 1.64285 (* 1 = 1.64285 loss)
I0526 07:12:01.936244 30759 sgd_solver.cpp:106] Iteration 832500, lr = 0.002
I0526 07:12:18.567704 30759 solver.cpp:237] Iteration 834000, loss = 1.49235
I0526 07:12:18.567870 30759 solver.cpp:253]     Train net output #0: loss = 1.49235 (* 1 = 1.49235 loss)
I0526 07:12:18.567888 30759 sgd_solver.cpp:106] Iteration 834000, lr = 0.002
I0526 07:12:35.374050 30759 solver.cpp:237] Iteration 835500, loss = 1.18069
I0526 07:12:35.374106 30759 solver.cpp:253]     Train net output #0: loss = 1.18069 (* 1 = 1.18069 loss)
I0526 07:12:35.374124 30759 sgd_solver.cpp:106] Iteration 835500, lr = 0.002
I0526 07:12:52.245617 30759 solver.cpp:237] Iteration 837000, loss = 1.07651
I0526 07:12:52.245801 30759 solver.cpp:253]     Train net output #0: loss = 1.07651 (* 1 = 1.07651 loss)
I0526 07:12:52.245818 30759 sgd_solver.cpp:106] Iteration 837000, lr = 0.002
I0526 07:13:09.026145 30759 solver.cpp:237] Iteration 838500, loss = 1.20929
I0526 07:13:09.026183 30759 solver.cpp:253]     Train net output #0: loss = 1.20929 (* 1 = 1.20929 loss)
I0526 07:13:09.026202 30759 sgd_solver.cpp:106] Iteration 838500, lr = 0.002
I0526 07:13:25.661952 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_840000.caffemodel
I0526 07:13:25.714509 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_840000.solverstate
I0526 07:13:25.750382 30759 solver.cpp:341] Iteration 840000, Testing net (#0)
I0526 07:14:25.157521 30759 solver.cpp:409]     Test net output #0: accuracy = 0.903295
I0526 07:14:25.157709 30759 solver.cpp:409]     Test net output #1: loss = 0.319704 (* 1 = 0.319704 loss)
I0526 07:14:45.964741 30759 solver.cpp:237] Iteration 840000, loss = 1.18486
I0526 07:14:45.964802 30759 solver.cpp:253]     Train net output #0: loss = 1.18486 (* 1 = 1.18486 loss)
I0526 07:14:45.964828 30759 sgd_solver.cpp:106] Iteration 840000, lr = 0.002
I0526 07:15:02.781466 30759 solver.cpp:237] Iteration 841500, loss = 0.379414
I0526 07:15:02.781662 30759 solver.cpp:253]     Train net output #0: loss = 0.379417 (* 1 = 0.379417 loss)
I0526 07:15:02.781679 30759 sgd_solver.cpp:106] Iteration 841500, lr = 0.002
I0526 07:15:19.466640 30759 solver.cpp:237] Iteration 843000, loss = 1.52011
I0526 07:15:19.466701 30759 solver.cpp:253]     Train net output #0: loss = 1.52011 (* 1 = 1.52011 loss)
I0526 07:15:19.466727 30759 sgd_solver.cpp:106] Iteration 843000, lr = 0.002
I0526 07:15:36.526531 30759 solver.cpp:237] Iteration 844500, loss = 1.01994
I0526 07:15:36.526701 30759 solver.cpp:253]     Train net output #0: loss = 1.01994 (* 1 = 1.01994 loss)
I0526 07:15:36.526718 30759 sgd_solver.cpp:106] Iteration 844500, lr = 0.002
I0526 07:15:53.414485 30759 solver.cpp:237] Iteration 846000, loss = 1.15555
I0526 07:15:53.414543 30759 solver.cpp:253]     Train net output #0: loss = 1.15555 (* 1 = 1.15555 loss)
I0526 07:15:53.414561 30759 sgd_solver.cpp:106] Iteration 846000, lr = 0.002
I0526 07:16:10.260422 30759 solver.cpp:237] Iteration 847500, loss = 1.28746
I0526 07:16:10.260607 30759 solver.cpp:253]     Train net output #0: loss = 1.28747 (* 1 = 1.28747 loss)
I0526 07:16:10.260623 30759 sgd_solver.cpp:106] Iteration 847500, lr = 0.002
I0526 07:16:27.226557 30759 solver.cpp:237] Iteration 849000, loss = 1.13989
I0526 07:16:27.226595 30759 solver.cpp:253]     Train net output #0: loss = 1.13989 (* 1 = 1.13989 loss)
I0526 07:16:27.226613 30759 sgd_solver.cpp:106] Iteration 849000, lr = 0.002
I0526 07:17:04.764353 30759 solver.cpp:237] Iteration 850500, loss = 1.08031
I0526 07:17:04.764549 30759 solver.cpp:253]     Train net output #0: loss = 1.08031 (* 1 = 1.08031 loss)
I0526 07:17:04.764565 30759 sgd_solver.cpp:106] Iteration 850500, lr = 0.002
I0526 07:17:21.405215 30759 solver.cpp:237] Iteration 852000, loss = 0.79744
I0526 07:17:21.405256 30759 solver.cpp:253]     Train net output #0: loss = 0.797441 (* 1 = 0.797441 loss)
I0526 07:17:21.405274 30759 sgd_solver.cpp:106] Iteration 852000, lr = 0.002
I0526 07:17:38.583577 30759 solver.cpp:237] Iteration 853500, loss = 0.668035
I0526 07:17:38.583768 30759 solver.cpp:253]     Train net output #0: loss = 0.668037 (* 1 = 0.668037 loss)
I0526 07:17:38.583786 30759 sgd_solver.cpp:106] Iteration 853500, lr = 0.002
I0526 07:17:55.462954 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_855000.caffemodel
I0526 07:17:55.516716 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_855000.solverstate
I0526 07:17:55.552196 30759 solver.cpp:237] Iteration 855000, loss = 2.25758
I0526 07:17:55.552253 30759 solver.cpp:253]     Train net output #0: loss = 2.25758 (* 1 = 2.25758 loss)
I0526 07:17:55.552279 30759 sgd_solver.cpp:106] Iteration 855000, lr = 0.002
I0526 07:18:12.196262 30759 solver.cpp:237] Iteration 856500, loss = 0.309575
I0526 07:18:12.196462 30759 solver.cpp:253]     Train net output #0: loss = 0.309577 (* 1 = 0.309577 loss)
I0526 07:18:12.196480 30759 sgd_solver.cpp:106] Iteration 856500, lr = 0.002
I0526 07:18:28.983546 30759 solver.cpp:237] Iteration 858000, loss = 0.722104
I0526 07:18:28.983585 30759 solver.cpp:253]     Train net output #0: loss = 0.722106 (* 1 = 0.722106 loss)
I0526 07:18:28.983605 30759 sgd_solver.cpp:106] Iteration 858000, lr = 0.002
I0526 07:18:45.829360 30759 solver.cpp:237] Iteration 859500, loss = 0.516792
I0526 07:18:45.829557 30759 solver.cpp:253]     Train net output #0: loss = 0.516794 (* 1 = 0.516794 loss)
I0526 07:18:45.829576 30759 sgd_solver.cpp:106] Iteration 859500, lr = 0.002
I0526 07:19:23.454732 30759 solver.cpp:237] Iteration 861000, loss = 1.12606
I0526 07:19:23.454922 30759 solver.cpp:253]     Train net output #0: loss = 1.12606 (* 1 = 1.12606 loss)
I0526 07:19:23.454941 30759 sgd_solver.cpp:106] Iteration 861000, lr = 0.002
I0526 07:19:40.370084 30759 solver.cpp:237] Iteration 862500, loss = 2.48953
I0526 07:19:40.370137 30759 solver.cpp:253]     Train net output #0: loss = 2.48953 (* 1 = 2.48953 loss)
I0526 07:19:40.370156 30759 sgd_solver.cpp:106] Iteration 862500, lr = 0.002
I0526 07:19:57.389816 30759 solver.cpp:237] Iteration 864000, loss = 1.30345
I0526 07:19:57.390005 30759 solver.cpp:253]     Train net output #0: loss = 1.30345 (* 1 = 1.30345 loss)
I0526 07:19:57.390023 30759 sgd_solver.cpp:106] Iteration 864000, lr = 0.002
I0526 07:20:14.437959 30759 solver.cpp:237] Iteration 865500, loss = 0.893753
I0526 07:20:14.438001 30759 solver.cpp:253]     Train net output #0: loss = 0.893755 (* 1 = 0.893755 loss)
I0526 07:20:14.438019 30759 sgd_solver.cpp:106] Iteration 865500, lr = 0.002
I0526 07:20:31.126611 30759 solver.cpp:237] Iteration 867000, loss = 1.36246
I0526 07:20:31.126799 30759 solver.cpp:253]     Train net output #0: loss = 1.36246 (* 1 = 1.36246 loss)
I0526 07:20:31.126817 30759 sgd_solver.cpp:106] Iteration 867000, lr = 0.002
I0526 07:20:47.984808 30759 solver.cpp:237] Iteration 868500, loss = 0.990774
I0526 07:20:47.984869 30759 solver.cpp:253]     Train net output #0: loss = 0.990776 (* 1 = 0.990776 loss)
I0526 07:20:47.984894 30759 sgd_solver.cpp:106] Iteration 868500, lr = 0.002
I0526 07:21:05.180485 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_870000.caffemodel
I0526 07:21:05.234159 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_870000.solverstate
I0526 07:21:05.274543 30759 solver.cpp:341] Iteration 870000, Testing net (#0)
I0526 07:22:25.667063 30759 solver.cpp:409]     Test net output #0: accuracy = 0.902873
I0526 07:22:25.667251 30759 solver.cpp:409]     Test net output #1: loss = 0.315856 (* 1 = 0.315856 loss)
I0526 07:22:46.501312 30759 solver.cpp:237] Iteration 870000, loss = 1.59887
I0526 07:22:46.501376 30759 solver.cpp:253]     Train net output #0: loss = 1.59887 (* 1 = 1.59887 loss)
I0526 07:22:46.501396 30759 sgd_solver.cpp:106] Iteration 870000, lr = 0.002
I0526 07:23:03.148809 30759 solver.cpp:237] Iteration 871500, loss = 1.47563
I0526 07:23:03.148998 30759 solver.cpp:253]     Train net output #0: loss = 1.47563 (* 1 = 1.47563 loss)
I0526 07:23:03.149016 30759 sgd_solver.cpp:106] Iteration 871500, lr = 0.002
I0526 07:23:19.849115 30759 solver.cpp:237] Iteration 873000, loss = 0.481547
I0526 07:23:19.849171 30759 solver.cpp:253]     Train net output #0: loss = 0.481546 (* 1 = 0.481546 loss)
I0526 07:23:19.849190 30759 sgd_solver.cpp:106] Iteration 873000, lr = 0.002
I0526 07:23:36.727535 30759 solver.cpp:237] Iteration 874500, loss = 1.57054
I0526 07:23:36.727716 30759 solver.cpp:253]     Train net output #0: loss = 1.57054 (* 1 = 1.57054 loss)
I0526 07:23:36.727733 30759 sgd_solver.cpp:106] Iteration 874500, lr = 0.002
I0526 07:23:53.350952 30759 solver.cpp:237] Iteration 876000, loss = 1.08998
I0526 07:23:53.351002 30759 solver.cpp:253]     Train net output #0: loss = 1.08998 (* 1 = 1.08998 loss)
I0526 07:23:53.351019 30759 sgd_solver.cpp:106] Iteration 876000, lr = 0.002
I0526 07:24:10.283190 30759 solver.cpp:237] Iteration 877500, loss = 1.23159
I0526 07:24:10.283376 30759 solver.cpp:253]     Train net output #0: loss = 1.23159 (* 1 = 1.23159 loss)
I0526 07:24:10.283393 30759 sgd_solver.cpp:106] Iteration 877500, lr = 0.002
I0526 07:24:27.453088 30759 solver.cpp:237] Iteration 879000, loss = 1.21201
I0526 07:24:27.453138 30759 solver.cpp:253]     Train net output #0: loss = 1.21201 (* 1 = 1.21201 loss)
I0526 07:24:27.453164 30759 sgd_solver.cpp:106] Iteration 879000, lr = 0.002
I0526 07:25:04.886749 30759 solver.cpp:237] Iteration 880500, loss = 1.33114
I0526 07:25:04.886940 30759 solver.cpp:253]     Train net output #0: loss = 1.33114 (* 1 = 1.33114 loss)
I0526 07:25:04.886957 30759 sgd_solver.cpp:106] Iteration 880500, lr = 0.002
I0526 07:25:21.505434 30759 solver.cpp:237] Iteration 882000, loss = 1.55979
I0526 07:25:21.505497 30759 solver.cpp:253]     Train net output #0: loss = 1.55979 (* 1 = 1.55979 loss)
I0526 07:25:21.505522 30759 sgd_solver.cpp:106] Iteration 882000, lr = 0.002
I0526 07:25:38.101441 30759 solver.cpp:237] Iteration 883500, loss = 1.03784
I0526 07:25:38.101611 30759 solver.cpp:253]     Train net output #0: loss = 1.03784 (* 1 = 1.03784 loss)
I0526 07:25:38.101629 30759 sgd_solver.cpp:106] Iteration 883500, lr = 0.002
I0526 07:25:54.946928 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_885000.caffemodel
I0526 07:25:54.995996 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_885000.solverstate
I0526 07:25:55.027125 30759 solver.cpp:237] Iteration 885000, loss = 2.68198
I0526 07:25:55.027186 30759 solver.cpp:253]     Train net output #0: loss = 2.68198 (* 1 = 2.68198 loss)
I0526 07:25:55.027215 30759 sgd_solver.cpp:106] Iteration 885000, lr = 0.002
I0526 07:26:11.865757 30759 solver.cpp:237] Iteration 886500, loss = 1.03053
I0526 07:26:11.865953 30759 solver.cpp:253]     Train net output #0: loss = 1.03053 (* 1 = 1.03053 loss)
I0526 07:26:11.865972 30759 sgd_solver.cpp:106] Iteration 886500, lr = 0.002
I0526 07:26:28.441015 30759 solver.cpp:237] Iteration 888000, loss = 2.55558
I0526 07:26:28.441053 30759 solver.cpp:253]     Train net output #0: loss = 2.55558 (* 1 = 2.55558 loss)
I0526 07:26:28.441072 30759 sgd_solver.cpp:106] Iteration 888000, lr = 0.002
I0526 07:26:45.048451 30759 solver.cpp:237] Iteration 889500, loss = 0.931933
I0526 07:26:45.048640 30759 solver.cpp:253]     Train net output #0: loss = 0.931931 (* 1 = 0.931931 loss)
I0526 07:26:45.048656 30759 sgd_solver.cpp:106] Iteration 889500, lr = 0.002
I0526 07:27:22.539409 30759 solver.cpp:237] Iteration 891000, loss = 1.0145
I0526 07:27:22.539604 30759 solver.cpp:253]     Train net output #0: loss = 1.0145 (* 1 = 1.0145 loss)
I0526 07:27:22.539623 30759 sgd_solver.cpp:106] Iteration 891000, lr = 0.002
I0526 07:27:39.746976 30759 solver.cpp:237] Iteration 892500, loss = 1.04043
I0526 07:27:39.747015 30759 solver.cpp:253]     Train net output #0: loss = 1.04043 (* 1 = 1.04043 loss)
I0526 07:27:39.747033 30759 sgd_solver.cpp:106] Iteration 892500, lr = 0.002
I0526 07:27:56.778470 30759 solver.cpp:237] Iteration 894000, loss = 0.931332
I0526 07:27:56.778651 30759 solver.cpp:253]     Train net output #0: loss = 0.93133 (* 1 = 0.93133 loss)
I0526 07:27:56.778669 30759 sgd_solver.cpp:106] Iteration 894000, lr = 0.002
I0526 07:28:13.749184 30759 solver.cpp:237] Iteration 895500, loss = 1.7694
I0526 07:28:13.749235 30759 solver.cpp:253]     Train net output #0: loss = 1.7694 (* 1 = 1.7694 loss)
I0526 07:28:13.749261 30759 sgd_solver.cpp:106] Iteration 895500, lr = 0.002
I0526 07:28:30.657590 30759 solver.cpp:237] Iteration 897000, loss = 1.24677
I0526 07:28:30.657771 30759 solver.cpp:253]     Train net output #0: loss = 1.24676 (* 1 = 1.24676 loss)
I0526 07:28:30.657788 30759 sgd_solver.cpp:106] Iteration 897000, lr = 0.002
I0526 07:28:47.568862 30759 solver.cpp:237] Iteration 898500, loss = 1.22505
I0526 07:28:47.568912 30759 solver.cpp:253]     Train net output #0: loss = 1.22505 (* 1 = 1.22505 loss)
I0526 07:28:47.568930 30759 sgd_solver.cpp:106] Iteration 898500, lr = 0.002
I0526 07:29:04.561813 30759 solver.cpp:459] Snapshotting to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_900000.caffemodel
I0526 07:29:04.610585 30759 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /lustre/atlas/proj-shared/hep105/caffe_titan/caffe_workflow/snapshots_bslr/bs_10_lr_0.0020_2016-05-20T15.48.50.413054_iter_900000.solverstate
I0526 07:29:04.638862 30759 solver.cpp:341] Iteration 900000, Testing net (#0)
I0526 07:30:03.992039 30759 solver.cpp:409]     Test net output #0: accuracy = 0.902197
I0526 07:30:03.992238 30759 solver.cpp:409]     Test net output #1: loss = 0.325454 (* 1 = 0.325454 loss)
I0526 07:30:24.860107 30759 solver.cpp:237] Iteration 900000, loss = 1.05525
I0526 07:30:24.860172 30759 solver.cpp:253]     Train net output #0: loss = 1.05524 (* 1 = 1.05524 loss)
I0526 07:30:24.860200 30759 sgd_solver.cpp:106] Iteration 900000, lr = 0.002
I0526 07:30:41.901463 30759 solver.cpp:237] Iteration 901500, loss = 1.38496
I0526 07:30:41.901659 30759 solver.cpp:253]     Train net output #0: loss = 1.38496 (* 1 = 1.38496 loss)
I0526 07:30:41.901677 30759 sgd_solver.cpp:106] Iteration 901500, lr = 0.002
I0526 07:30:58.836277 30759 solver.cpp:237] Iteration 903000, loss = 1.23381
I0526 07:30:58.836316 30759 solver.cpp:253]     Train net output #0: loss = 1.23381 (* 1 = 1.23381 loss)
I0526 07:30:58.836333 30759 sgd_solver.cpp:106] Iteration 903000, lr = 0.002
I0526 07:31:15.627877 30759 solver.cpp:237] Iteration 904500, loss = 1.31417
I0526 07:31:15.628067 30759 solver.cpp:253]     Train net output #0: loss = 1.31416 (* 1 = 1.31416 loss)
I0526 07:31:15.628084 30759 sgd_solver.cpp:106] Iteration 904500, lr = 0.002
aprun: Apid 11266920: Caught signal Terminated, sending to application
aprun: Apid 11266920: Caught signal Terminated, sending to application
*** Aborted at 1464262289 (unix time) try "date -d @1464262289" if you are using GNU date ***
aprun: Apid 11266920: Caught signal Terminated, sending to application
PC: @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11266920: Caught signal Terminated, sending to application
*** SIGTERM (@0x7824) received by PID 30759 (TID 0x2aaac746f900) from PID 30756; stack trace: ***
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab7c78850 (unknown)
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaaaaaca834 ([vdso]+0x833)
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab82072d0 maybe_syscall_gettime_cpu
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab82074b0 __GI_clock_gettime
aprun: Apid 11266920: Caught signal Terminated, sending to application
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab9898f3e (unknown)
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab928ec5b (unknown)
aprun: Apid 11266920: Caught signal Terminated, sending to application
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab926d723 (unknown)
=>> PBS: job killed: walltime 7241 exceeded limit 7200
aprun: Apid 11266920: Caught signal Terminated, sending to application
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab92655e1 (unknown)
aprun: Apid 11266920: Caught signal Terminated, sending to application
aprun: Apid 11266920: Caught signal Terminated, sending to application
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab9266356 (unknown)
aprun: Apid 11266920: Caught signal Terminated, sending to application
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab91d5562 (unknown)
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaab91d56ba (unknown)
    @     0x2aaab91b8715 cuMemcpy
aprun: Apid 11266920: Caught signal Terminated, sending to application
    @     0x2aaaaacf9e92 (unknown)
    @     0x2aaaaacde306 (unknown)
    @     0x2aaaaad00328 cudaMemcpy
    @           0x4d6a10 caffe::caffe_copy<>()
    @           0x626ea9 caffe::HDF5DataLayer<>::Forward_gpu()
    @           0x5efe82 caffe::Net<>::ForwardFromTo()
    @           0x5eff97 caffe::Net<>::ForwardPrefilled()
    @           0x5ca109 caffe::Solver<>::Step()
